Tài liệu PDF đã được chuyển đổi từ PDF sang TXT
Đường dẫn nguồn: /home/admin88/arxiv-downloader/coding/2306.03324.pdf
Kích thước tệp: 2342899 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Các Mô hình Ngôn ngữ Lớn có Hiệu quả như thế nào trong
Việc Tạo ra Đặc tả Phần mềm?
Danning Xie∗‡, Byoungwoo Yoo†‡, Nan Jiang∗, Mijung Kim†¶, Lin Tan∗, Xiangyu Zhang∗, Judy S. Lee§
∗Đại học Purdue, West Lafayette, IN, Hoa Kỳ
{xie342, jiang719, lintan}@purdue.edu, xyzhang@cs.purdue.edu
†UNIST, Ulsan, Hàn Quốc
{captainnemo9292, mijungk}@unist.ac.kr
§ADP, Roseland, NJ, Hoa Kỳ
judy.lee@adp.com

Tóm tắt—Đặc tả phần mềm rất quan trọng đối với nhiều nhiệm vụ Kỹ thuật Phần mềm (SE) như phát hiện lỗi và tạo ra bài kiểm tra. Nhiều phương pháp hiện có được đề xuất để trích xuất các đặc tả được định nghĩa dưới dạng ngôn ngữ tự nhiên (ví dụ: bình luận) thành dạng có thể đọc được bằng máy (ví dụ: logic bậc một). Tuy nhiên, các phương pháp hiện có gặp phải hạn chế về khả năng tổng quát hóa và đòi hỏi nỗ lực thủ công. Sự xuất hiện gần đây của các Mô hình Ngôn ngữ Lớn (LLMs), đã được áp dụng thành công cho nhiều nhiệm vụ SE, mở ra một hướng triển vọng để tự động hóa quá trình này. Trong bài báo này, chúng tôi tiến hành nghiên cứu thực nghiệm đầu tiên để đánh giá khả năng của LLMs trong việc tạo ra đặc tả phần mềm từ bình luận hoặc tài liệu phần mềm. Chúng tôi đánh giá hiệu suất của LLMs với Học Few-Shot (FSL) và so sánh hiệu suất của 13 LLMs tiên tiến với các phương pháp truyền thống trên ba bộ dữ liệu công khai. Ngoài ra, chúng tôi tiến hành chẩn đoán so sánh các trường hợp thất bại từ cả LLMs và phương pháp truyền thống, xác định điểm mạnh và điểm yếu độc đáo của chúng. Nghiên cứu của chúng tôi đưa ra những hiểu biết có giá trị cho nghiên cứu tương lai nhằm cải thiện việc tạo ra đặc tả.

Từ khóa chỉ mục—đặc tả phần mềm, mô hình ngôn ngữ lớn, học few-shot

I. GIỚI THIỆU

Đặc tả phần mềm chính xác và toàn diện là cần thiết để đảm bảo tính đúng đắn, độ tin cậy và chất lượng của hệ thống phần mềm [1]–[4]. Các đặc tả phần mềm phổ biến bao gồm điều kiện tiền đề và hậu tố cho một hàm mục tiêu mô tả các ràng buộc của tham số đầu vào và các hành vi hoặc giá trị đầu ra mong đợi. Chúng thường được yêu cầu hoặc quan trọng để tạo ra các trường hợp kiểm tra và oracle kiểm tra hiệu quả, thực thi tượng trưng, và nhận dạng hành vi bất thường [3], [5]–[7].

Nhiều phương pháp đã được đề xuất để thúc đẩy tự động hóa trong việc trích xuất đặc tả từ văn bản phần mềm (ví dụ: tài liệu hoặc bình luận) thành các dạng có thể đọc được bằng máy, bao gồm các phương pháp dựa trên quy tắc [1], [3], [8], phương pháp dựa trên ML [4], [9], [10], phương pháp dựa trên tìm kiếm [11], v.v. Ví dụ, Jdoctor [1] tận dụng việc khớp mẫu, từ vựng và ngữ nghĩa để dịch bình luận mã thành đặc tả có thể đọc được bằng máy của điều kiện tiền đề/hậu tố, cho phép tạo ra bài kiểm tra tự động dẫn đến ít báo động giả và khám phá ra nhiều lỗi hơn. Một số nỗ lực khác đã được thực hiện để cải thiện thêm các quá trình này trong nhiều lĩnh vực khác nhau [9], [11]–[13].

Tuy nhiên, hầu hết công việc hiện có đều cụ thể theo lĩnh vực, dựa vào phương pháp heuristic [1], [8], [10] hoặc một lượng lớn dữ liệu được chú thích thủ công [3], [11]. Sự phụ thuộc này khiến việc tổng quát hóa các phương pháp này sang các lĩnh vực khác trở nên thách thức.

Với sự xuất hiện của các Mô hình Ngôn ngữ Lớn (LLMs), được tiền huấn luyện trên một lượng lớn tài liệu và mã nguồn [14]–[19], chúng đã được áp dụng cho nhiều nhiệm vụ Kỹ thuật Phần mềm (SE) khác nhau như tạo mã [15], [20]–[25], sửa chữa chương trình [26], [27], và lý luận [28]. Các mô hình này đã thể hiện hiệu suất cạnh tranh so với các phương pháp truyền thống [15]–[17], [26], [29]. Do việc trích xuất đặc tả phần mềm chủ yếu liên quan đến việc phân tích và trích xuất từ văn bản phần mềm, chẳng hạn như bình luận hoặc tài liệu, và việc dịch ngôn ngữ tự nhiên thành đặc tả (bán) chính thức, hai câu hỏi nghiên cứu tự nhiên nảy sinh: (1) LLMs có hiệu quả trong việc tạo ra đặc tả phần mềm từ văn bản phần mềm không? (2) Điểm mạnh và điểm yếu vốn có của LLMs trong việc tạo ra đặc tả phần mềm so với các phương pháp truyền thống là gì?

A. Nghiên cứu của chúng tôi

Để lấp đầy khoảng trống này, chúng tôi tiến hành nghiên cứu thực nghiệm đầu tiên để đánh giá khả năng của LLMs trong việc tạo ra đặc tả phần mềm, so sánh với các phương pháp truyền thống. Đầu tiên, do sự khan hiếm dữ liệu được gán nhãn trong việc trích xuất đặc tả phần mềm, chúng tôi tận dụng LLMs với Học Few-Shot (FSL) [30], một kỹ thuật cho phép LLMs tổng quát từ một số lượng ví dụ hạn chế. Thứ hai, chúng tôi khám phá tiềm năng của việc kết hợp LLMs và FSL bằng cách điều tra các chiến lược xây dựng prompt khác nhau và đánh giá hiệu quả của chúng. Thứ ba, chúng tôi tiến hành chẩn đoán so sánh sâu về các trường hợp thất bại từ cả LLMs và phương pháp truyền thống. Điều này cho phép chúng tôi xác định điểm mạnh và điểm yếu độc đáo của chúng, cung cấp những hiểu biết có giá trị để hướng dẫn nghiên cứu tương lai và cải thiện ứng dụng LLM. Thứ tư, chúng tôi tiến hành các thí nghiệm rộng rãi, liên quan đến 13 LLMs tiên tiến, và đánh giá hiệu suất và hiệu quả chi phí của chúng để hỗ trợ lựa chọn mô hình trong việc tạo ra đặc tả phần mềm. Thiết lập nghiên cứu và các phát hiện của chúng tôi được trình bày dưới đây:

• FSL với các ví dụ ngẫu nhiên vượt trội hơn các phương pháp truyền thống: Để đánh giá hiệu suất của LLMs với FSL, trước tiên chúng tôi thu thập ba bộ dữ liệu có sẵn từ nghiên cứu trích xuất đặc tả trước đây, chứa tài liệu và bình luận phần mềm, cũng như các đặc tả ground-truth tương ứng. Chúng tôi bắt đầu với một phương pháp xây dựng prompt cơ bản lựa chọn ngẫu nhiên các ví dụ cho FSL. Sau đó chúng tôi so sánh kết quả với các kỹ thuật trích xuất đặc tả tiên tiến. Phát hiện 1 của chúng tôi cho thấy rằng với 10 – 60 ví dụ được chọn ngẫu nhiên, kết quả của LLMs có thể so sánh được (thấp hơn 2.1%) hoặc tốt hơn (cao hơn 0.8 – 4.3%) so với các kỹ thuật trích xuất đặc tả tiên tiến.

• Chiến lược prompt tiên tiến mở rộng khoảng cách hiệu suất: Để khám phá thêm tiềm năng của LLMs với FSL cho việc tạo ra đặc tả, chúng tôi đánh giá và so sánh các chiến lược xây dựng prompt khác nhau về tác động của chúng đến hiệu suất của LLMs. Các chiến lược xây dựng prompt này bao gồm lựa chọn ngẫu nhiên đã đề cập ở trên và một chiến lược lựa chọn dựa trên ngữ nghĩa. Phát hiện 2 cho thấy rằng với một phương pháp xây dựng prompt phức tạp hơn, khoảng cách hiệu suất giữa LLMs và các phương pháp truyền thống được mở rộng (đến 1.9 – 10.5%).

• LLMs và các kỹ thuật truyền thống thể hiện điểm mạnh và điểm yếu độc đáo: Trong khi LLMs vượt trội hơn các phương pháp truyền thống tổng thể, phân tích các trường hợp thất bại của chúng tôi tiết lộ sự khác biệt đáng chú ý trong các mẫu thất bại của chúng – Phát hiện 3: các phương pháp truyền thống thường tạo ra đầu ra trống, trong khi LLMs có xu hướng tạo ra các đặc tả không hoàn chỉnh hoặc có dạng không đúng. Sự biến đổi trong các thất bại này thúc đẩy chúng tôi phân tích các khả năng riêng biệt của LLMs và các phương pháp truyền thống. Do đó chúng tôi tiến hành chẩn đoán so sánh sâu về các trường hợp thất bại từ cả hai phía và điều tra nguyên nhân gốc rễ của chúng. Chúng tôi đã xác định một số thách thức độc đáo cho LLMs, chẳng hạn như prompts không hiệu quả và thiếu kiến thức lĩnh vực, chiếm 75% các thất bại độc đáo của chúng. Ngược lại, các phương pháp truyền thống thất bại độc đáo 90% do các quy tắc không đủ hoặc không chính xác được rút ra từ các bộ dữ liệu hạn chế. (Phát hiện 4 – 5)

• CodeLlama-13B và StarCoder2-15B mã nguồn mở là các mô hình cạnh tranh nhất: Cuối cùng, với phổ rộng các LLMs về tính sẵn có mã nguồn mở, chi phí và kích thước mô hình, việc hiểu khả năng của chúng trở nên cấp thiết. Chúng tôi thực hiện các thí nghiệm nghiêm ngặt trên 13 LLMs phổ biến tiên tiến, ví dụ: CodeLlama-13B, GPT-4, v.v., khác nhau về thiết kế và kích thước, và đánh giá hiệu suất và hiệu quả chi phí của chúng trong việc tạo ra đặc tả phần mềm. Đáng chú ý, Phát hiện 6 – 9 của chúng tôi cho thấy hầu hết LLMs đạt được hiệu suất tốt hơn hoặc tương đương so với các kỹ thuật truyền thống. CodeLlama-13B và StarCoder2-15B là mô hình cạnh tranh nhất tổng thể trong số 13 mô hình được đánh giá để tạo ra đặc tả, với hiệu suất cao, tính linh hoạt mã nguồn mở và hỗ trợ prompt dài. Hiệu suất mạnh mẽ của chúng làm cho các mô hình thương mại (ví dụ: GPT-4) trở nên kém hấp dẫn hơn do kích thước và chi phí.

• Xác định các lĩnh vực để cải thiện trong tương lai: Những phát hiện này cho phép chúng tôi xác định các thách thức để cải thiện thêm trong các ứng dụng LLM, tức là các phương pháp lai, tích hợp LLMs và các phương pháp truyền thống, và cải thiện hiệu quả prompts.

B. Đóng góp

Bài báo này đưa ra các đóng góp chính sau:

1) Chúng tôi tiến hành nghiên cứu thực nghiệm đầu tiên so sánh hiệu quả của LLMs và các phương pháp truyền thống trong việc tạo ra đặc tả phần mềm từ bình luận hoặc tài liệu và phát hiện rằng LLMs với FSL đạt được kết quả có thể so sánh được (thấp hơn 2.1%) hoặc tốt hơn (cao hơn 0.8 – 4.3%) so với các phương pháp truyền thống chỉ với 10 – 60 ví dụ được chọn ngẫu nhiên (Phần V-A).

2) Chúng tôi đánh giá tác động của các chiến lược xây dựng prompt khác nhau đến hiệu suất FSL và phát hiện rằng chiến lược tiên tiến có thể mở rộng thêm khoảng cách hiệu suất giữa phương pháp LLM và các phương pháp truyền thống (đến 1.9 – 10.5%) (Phần V-B).

3) Chúng tôi trình bày một chẩn đoán thất bại toàn diện, làm nổi bật điểm mạnh và điểm yếu độc đáo của cả phương pháp truyền thống và LLMs, hướng dẫn nghiên cứu tương lai (Phần VI).

4) Chúng tôi thí nghiệm rộng rãi trên 13 LLMs tiên tiến, đánh giá hiệu suất và hiệu quả chi phí của chúng (Phần VII).

5) Chúng tôi thảo luận về các hướng tương lai cho LLMs trong việc tạo ra đặc tả phần mềm bao gồm các phương pháp lai và thiết kế prompt nâng cao (Phần VIII).

6) Chúng tôi phát hành các artifacts trong [31].

II. BỐI CẢNH

1) Đặc tả Phần mềm: Đặc tả phần mềm mô tả các chức năng, hành vi và cách sử dụng phần mềm, bao gồm điều kiện tiền đề và hậu tố cho các hàm để đảm bảo sử dụng đúng cách. Ví dụ, API tf.nn.max_pool3d của TensorFlow yêu cầu tham số input phải là một "5-D Tensor", nếu không sẽ dẫn đến ngoại lệ. Đặc tả rất quan trọng cho các nhiệm vụ như tạo ra bài kiểm tra [1], [3], phân tích chương trình [11], phát hiện lỗi [2], [10], [13], và tổng hợp mã [32]. Chúng thường từ tài liệu hoặc bình luận dưới dạng ngôn ngữ tự nhiên, đòi hỏi trích xuất thành các định dạng chính thức có thể đọc được bằng máy cho các nhiệm vụ downstream.

Nhiều phương pháp khác nhau [4], [8], [10], [13] đã được phát triển để trích xuất các đặc tả như vậy, nhưng chúng dựa vào phương pháp heuristic cụ thể theo lĩnh vực hoặc dữ liệu được gán nhãn, hạn chế khả năng tổng quát hóa của chúng. Ví dụ, Jdoctor [1] sử dụng các mẫu được tạo thủ công với tiền/hậu xử lý, đòi hỏi chuyên môn lập trình và lĩnh vực.

2) Mô hình Ngôn ngữ Lớn (LLMs) và Học Few-Shot (FSL): LLMs, được tiền huấn luyện trên các corpus rộng lớn của ngôn ngữ tự nhiên và mã, thu được kiến thức tổng quát thông qua các nhiệm vụ như dự đoán span bị che và dự đoán token tiếp theo [18], [19], [33], [34]. Để điều chỉnh các LLMs được tiền huấn luyện vào các nhiệm vụ tùy chỉnh, fine-tuning [19], [26], [35], đòi hỏi dữ liệu được gán nhãn đáng kể, và prompting [18], điều chỉnh LLMs sử dụng các ví dụ cụ thể theo nhiệm vụ mà không sửa đổi trọng số, là các phương pháp phổ biến.

FSL nâng cao hiệu suất LLM trên các nhiệm vụ downstream với dữ liệu được gán nhãn hạn chế [18], [30], [36]. Trong in-context FSL [18], [37], các ví dụ được cung cấp trong đầu vào, cho phép mô hình tổng quát mà không thay đổi trọng số. Điều này làm cho prompting trở thành một phương pháp thực tế và hiệu quả cho việc tạo ra đặc tả.

III. THIẾT LẬP NGHIÊN CỨU

Hình 1 trình bày tổng quan về nghiên cứu của chúng tôi. Chúng tôi thu thập các bộ dữ liệu có sẵn từ công việc trích xuất đặc tả trước đây, chứa tài liệu hoặc bình luận phần mềm và các đặc tả ground-truth tương ứng. Sau đó chúng tôi trả lời bốn câu hỏi nghiên cứu (RQs):

RQ1: LLMs với FSL hoạt động như thế nào so với các phương pháp dựa trên quy tắc truyền thống trong việc trích xuất đặc tả phần mềm? Chúng tôi áp dụng LLM benchmark cho các bộ dữ liệu đã thu thập và so sánh hiệu suất của nó với các phương pháp truyền thống. Chúng tôi sử dụng một chiến lược xây dựng prompt cơ bản, random retrieval, để xây dựng prompts với các ví dụ ngẫu nhiên (Phần III-B2a), huấn luyện LLMs tạo ra đặc tả qua các ví dụ.

RQ2: Các chiến lược xây dựng prompt ảnh hưởng như thế nào đến hiệu suất của các phương pháp LLM? Chúng tôi so sánh hiệu suất của các chiến lược xây dựng prompt khác nhau, tức là Random Retrieval và Semantic Retrieval. Semantic retrieval chọn các ví dụ dựa trên sự tương tự ngữ nghĩa với ngữ cảnh mục tiêu (Phần III-B2b).

RQ3: Điểm mạnh và điểm yếu độc đáo của LLMs và các phương pháp truyền thống là gì? Để cung cấp hiểu biết tốt hơn về khả năng của các phương pháp khác nhau và làm sáng tỏ nghiên cứu tương lai, chúng tôi tiến hành chẩn đoán thất bại so sánh. Cụ thể, chúng tôi lấy mẫu một tập hợp các trường hợp mà phương pháp LLM thành công trong khi phương pháp truyền thống thất bại và ngược lại. Chúng tôi phân tích các triệu chứng và nguyên nhân gốc rễ của những thất bại này, và xác định điểm mạnh và hạn chế độc đáo của chúng.

RQ4: Các LLMs khác nhau so sánh như thế nào về hiệu suất và chi phí của chúng để tạo ra đặc tả phần mềm? Để đánh giá hiệu suất và hiệu quả chi phí, chúng tôi tiến hành các thí nghiệm rộng rãi với 13 LLMs tiên tiến có kích thước, thiết kế khác nhau, v.v. Chúng tôi sử dụng chiến lược xây dựng prompt hiệu suất tốt nhất ("Best Retrieval" trong Hình 1) dựa trên kết quả của RQ2.

A. Trích xuất Đặc tả Hiện có và Dữ liệu

Chúng tôi nghiên cứu ba phương pháp dựa trên quy tắc tiên tiến để trích xuất đặc tả, Jdoctor [1], DocTer [3], và CallMeMaybe [10], cũng như các bộ dữ liệu tương ứng của chúng, chứa các bình luận hoặc tài liệu được chú thích với các đặc tả liên quan. Để tránh nhầm lẫn, chúng tôi sử dụng các thuật ngữ Jdoctor-data, DocTer-data, và CallMeMaybe-data để chỉ các bộ dữ liệu, trong khi Jdoctor, DocTer, và CallMeMaybe chỉ ba phương pháp. Bảng I trình bày số lượng điểm dữ liệu trong mỗi bộ dữ liệu. Hàng "#Annotation" liệt kê số lượng cặp tài liệu-đặc tả được chú thích.

1) Jdoctor-data và Jdoctor: Jdoctor-data chứa điều kiện tiền đề và hậu tố được viết dưới dạng biểu thức Java có thể thực thi, được dịch từ bình luận Javadoc của các thẻ @return, @param, và @throws. Hình 2 cung cấp một ví dụ liên quan đến điều kiện hậu tố cho hàm isNullOrEmpty. Jdoctor sử dụng sự kết hợp của việc khớp mẫu, từ vựng và ngữ nghĩa để xác định các thành phần chính, chẳng hạn như các cặp ⟨subject, predicate⟩, sau đó được chuyển đổi thành các biểu thức Java có thể thực thi thông qua các phương pháp heuristic được định nghĩa thủ công.

2) DocTer-data và DocTer: DocTer-data chứa các đặc tả cụ thể cho DL được trích xuất từ tài liệu API của TensorFlow, PyTorch, và MXNet. Đặc tả được phân loại thành bốn loại: dtype (kiểu dữ liệu), structure (cấu trúc dữ liệu), shape (hình dạng tham số hoặc số chiều), và valid value (phạm vi hợp lệ hoặc enums). Hình 3 cho thấy một ví dụ điểm dữ liệu. DocTer trích xuất ràng buộc sử dụng các quy tắc cú pháp được xây dựng từ các mô tả API được chú thích.

3) CallMeMaybe-data và CallMeMaybe: CallMeMaybe-data chứa các ràng buộc thời gian được biểu diễn dưới dạng chuỗi sự kiện, được dịch từ các mô tả ngôn ngữ tự nhiên trong bình luận mã. Hình 4 cung cấp một ví dụ về một hàm Java, bao gồm chữ ký, bình luận và các đặc tả được dịch nắm bắt quan hệ thời gian giữa các sự kiện this.isEmpty() và this.clear(). Quá trình trích xuất của CallMeMaybe liên quan đến việc xác định các mệnh đề liên quan đến các phụ thuộc thời gian và dịch chúng thành các ràng buộc thời gian sử dụng phân tích ngữ nghĩa và dịch thuật dựa trên heuristic.

B. Tạo ra Đặc tả với LLMs

Để trích xuất đặc tả sử dụng một LLM, chúng tôi xây dựng prompts với các ví dụ, tức là thông qua few-shot learning.

1) Few-Shot Learning (FSL): Xem xét một bộ dữ liệu D = {(xi, yi)|D|i=1}, trong đó x đại diện cho ngữ cảnh (ví dụ: tài liệu hoặc bình luận) và y đại diện cho đặc tả phần mềm mục tiêu. Đối với mỗi điểm dữ liệu (xtarget, ytarget), chúng tôi chọn K ví dụ từ các điểm dữ liệu khác trong D, loại trừ mục tiêu, sử dụng leave-one-out cross-validation [38]–[40]. Những K ví dụ này, cùng với xtarget, tạo thành prompt được sử dụng bởi LLM để tạo ra đầu ra yout, sau đó được so sánh với ground-truth ytarget.

2) Xây dựng Prompt FSL: Hình 5 cho thấy các prompt đơn giản hóa cho mỗi bộ dữ liệu. Đối với Jdoctor-data và CallMeMaybe-data, mỗi K ví dụ bao gồm chữ ký hàm, bình luận và điều kiện tương ứng, với mục tiêu được nối thêm. Đối với DocTer-data, prompt bao gồm chữ ký hàm, mô tả tham số và các ràng buộc được chú thích.

Chúng tôi xử lý ba loại thẻ của Jdoctor-data (Bảng I) và DocTer-data từ ba thư viện như các bộ dữ liệu con riêng biệt. Ví dụ, đối với một mục tiêu của thẻ @param, chúng tôi chỉ chọn K ví dụ từ 242 điểm dữ liệu khác của thẻ @param, loại trừ chính nó. Tương tự, trong DocTer-data, đối với một mục tiêu, chúng tôi chọn các ví dụ từ cùng thư viện, loại trừ chính nó.

Chúng tôi nghiên cứu hai chiến lược thường được sử dụng để chọn K ví dụ: random retrieval và semantic retrieval.

a) Random Retrieval: Nó chọn K ví dụ ngẫu nhiên từ bộ dữ liệu, loại trừ mục tiêu, tức là D\ {(xtarget, ytarget)}. Ví dụ, với K = 20, 20 instance ngẫu nhiên được chọn làm prompts, loại trừ mục tiêu.

b) Semantic Retrieval (SR): Nó chọn các ví dụ tương tự về mặt ngữ nghĩa với mục tiêu, được chứng minh là hiệu quả hơn random retrieval [41], [42]. Chúng tôi sử dụng RoBERTa-large [43] do hiệu suất mạnh mẽ của nó trên bộ dữ liệu STS [44]. Tác động của các mô hình retrieval khác nhau không được nghiên cứu, vì nghiên cứu trước đây cho thấy sự khác biệt tối thiểu về hiệu suất [45].

3) Hậu xử lý Đầu ra LLM: Đối với Jdoctor-data, các kết quả hoàn thiện LLM có thể đúng về mặt ngữ nghĩa nhưng không giống hệt với các đặc tả được chú thích. Hình 6 cho thấy một ví dụ trong đó cả hai đặc tả được chú thích (được làm nổi bật bằng màu vàng) và được tạo bởi LLM (màu xanh) đều truyền đạt cùng một điều kiện nhưng khác nhau về mặt cú pháp. Các đặc tả tương đương nhưng khác nhau về cú pháp như vậy thường xuyên xảy ra trong kết quả LLM và làm cho việc đánh giá tự động trở nên thách thức, đặc biệt khi cần kiến thức cụ thể theo lĩnh vực (ví dụ: độ dài mảng không âm). Do đó, chúng tôi kiểm tra thủ công các kết quả hoàn thiện được tạo cho Jdoctor-data và báo cáo cả độ chính xác thô của perfect match và độ chính xác cuối cùng sau khi sửa chữa thủ công. Hai tác giả tiến hành đánh giá độc lập, giải quyết bất đồng với người thứ ba.

Lưu ý rằng vì Jdoctor sử dụng phương pháp dựa trên mẫu, nó không yêu cầu hậu xử lý như vậy vì định dạng đầu ra bị ràng buộc bởi phương pháp heuristic. Đối với DocTer-data và CallMeMaybe-data, chúng tôi sử dụng perfect match, vì hậu xử lý không cần thiết cho DocTer-data (đặc tả không có thứ tự) và CallMeMaybe-data (đầu ra xác định).

C. Mô hình Ngôn ngữ Lớn Được nghiên cứu

Bảng II tóm tắt 13 LLMs từ sáu series mà chúng tôi nghiên cứu trong bài báo này, bao gồm các LLMs tiên tiến generic, code-specific, open-sourced, và commercial. Đối với các mô hình open-source, chúng tôi tập trung vào các mô hình nhỏ hơn 15B do hạn chế về tài nguyên. Chúng tôi không tập trung vào các mô hình có kích thước nhỏ (ví dụ: 1B) vì các thí nghiệm sơ bộ của chúng tôi cho thấy hiệu suất không lý tưởng của chúng. Chúng tôi chạy các mô hình open-source cục bộ sử dụng 4 GPU Nvidia RTX A6000 với bộ nhớ 48GB.

D. LLM Benchmark

Chúng tôi chọn sử dụng CodeLlama-13B làm LLM benchmark cho nghiên cứu RQs 1–3 (Hình 1). CodeLlama-13B là một trong những LLM mã open-source tiên tiến, đảm bảo khả năng tái tạo kết quả của chúng tôi. Ngoài ra, nó hỗ trợ nhiều token đầu vào hơn (Bảng II), cho phép một phạm vi rộng các thiết lập thí nghiệm, chẳng hạn như số lượng ví dụ khác nhau trong prompt.

Sau khi xác định các chiến lược xây dựng prompt tốt nhất ("Best Retrieval" trong Hình 1) sử dụng CodeLlama-13B, chúng tôi áp dụng nó cho tất cả các LLMs khác được liệt kê trong Bảng II cho nghiên cứu RQ4.

IV. CÀI ĐẶT THÍ NGHIỆM

A. Cài đặt Mô hình

Theo thiết kế thí nghiệm của chúng tôi, chúng tôi cắt bớt các ví dụ từ đầu prompts để phù hợp với giới hạn token của mỗi mô hình (như được hiển thị trong Bảng II). Nếu số token trung vị trong prompts vượt quá giới hạn, chúng tôi bỏ qua thí nghiệm đó. Ví dụ, chúng tôi bỏ qua thí nghiệm cho Jdoctor-data khi K = 60 cho CodeGen2 (với giới hạn token 2,048) vì số token trung vị trong prompts là 3,737. Để cung cấp kết quả toàn diện, chúng tôi chạy mô hình benchmark (CodeLlama-13B) cho RQ1 và RQ2 trong tất cả các thiết lập. Nhiệt độ của tất cả các mô hình được đặt ở 0 để giảm thiểu tính ngẫu nhiên.

B. Độ chính xác và Chỉ số F1

Để đánh giá tính đúng đắn của các đặc tả được tạo cho Jdoctor-data và CallMeMaybe-data, chúng tôi sử dụng độ chính xác, được định nghĩa là tỷ lệ các đặc tả được tạo đúng trên tổng số đặc tả được chú thích.

Đối với DocTer-data, chúng tôi theo công việc trước đây [3] và sử dụng precision, recall, và F1 để đánh giá kết quả được tạo cho mỗi danh mục đặc tả (ví dụ: dtype). Đối với danh mục t, cho Ct là số lượng đặc tả được tạo đúng, Nt là tổng số đặc tả được chú thích trong bộ dữ liệu, và Gt biểu thị số lượng đặc tả được tạo cho danh mục t. Chúng tôi định nghĩa precision là Pt = Ct/Gt, recall là Rt = Ct/Nt, và điểm F1 là Ft = 2·Pt·Rt/(Pt+Rt). Chúng tôi báo cáo precision, recall, và F1 tổng thể trên tất cả bốn danh mục (dtype, structure, shape, và valid value) cho mỗi thư viện (ví dụ: TensorFlow).

Như đã thảo luận trong Phần III-B2, chúng tôi xử lý Jdoctor-data của các loại thẻ khác nhau và DocTer-data của các thư viện khác nhau như các bộ dữ liệu riêng biệt. Chúng tôi báo cáo các chỉ số độ chính xác và F1 cho chúng riêng biệt, cũng như tổng thể.

V. KẾT QUẢ ĐÁNH GIÁ

A. RQ1: Khả năng Trích xuất Đặc tả

Chúng tôi đánh giá LLMs trên Jdoctor-data, DocTer-data, và CallMeMaybe-data sử dụng chiến lược random retrieval để xây dựng prompt (Phần III-B2a) với CodeLlama-13B làm mô hình chủ đề (Phần III-D). Kết quả cho cả CodeLlama-13B và các phương pháp baseline (Jdoctor, DocTer, và CallMeMaybe) được trình bày trong Bảng III, IV, và V. Trong các bảng, chúng tôi làm nổi bật (in đậm) kết quả của CodeLlama-13B vượt qua các phương pháp baseline với ít ví dụ nhất được sử dụng.

Như được mô tả trong Phần III-B3, chúng tôi hậu xử lý thủ công đặc tả được tạo cho Jdoctor-data và trình bày độ chính xác thô (được tính tự động với perfect match) trong cột "Raw" và độ chính xác cuối cùng (sau khi sửa chữa thủ công) trong cột "Processed" trong Bảng III. Đối với Jdoctor (hàng Jdoctor), hai giá trị này giống nhau. Các cột "K" đại diện cho số lượng ví dụ trong prompts.

a) Tóm tắt Kết quả: CodeLlama-13B thể hiện hiệu suất mạnh mẽ trên tất cả các bộ dữ liệu. Đối với Jdoctor-data (Bảng III), nó đạt được độ chính xác 84.0% chỉ sử dụng 20 ví dụ được chọn ngẫu nhiên cho mỗi loại bình luận, vượt qua Jdoctor (83.0%). Nó cũng vượt trội hơn Jdoctor cho @throws và khớp hiệu suất của nó cho bình luận @param. Đối với DocTer-data (Bảng IV), nó đạt được điểm F1 79.5% với 60 ví dụ cho mỗi thư viện, chỉ thấp hơn DocTer (81.6%) 2.1%, mặc dù DocTer cần 2,696 ví dụ được chú thích. Đối với CallMeMaybe-data (Bảng V), CodeLlama-13B đạt được độ chính xác 70.8% với 60 ví dụ, vượt trội hơn CallMeMaybe 0.8%.

Phát hiện 1: CodeLlama-13B, với một số lượng nhỏ (20 – 60) ví dụ được chọn ngẫu nhiên đạt được kết quả có thể so sánh (thấp hơn 2.1%) với DocTer và vượt trội hơn kỹ thuật trích xuất đặc tả tiên tiến Jdoctor và CallMeMaybe 0.8 – 4.3%.

B. RQ2: Chiến lược Xây dựng Prompt

Bảng VI, VII, và VIII tiết lộ rằng CodeLlama-13B, khi sử dụng chiến lược SR, vượt trội hơn tất cả các phương pháp baseline (Jdoctor, DocTer, và CallMeMaybe), ngay cả với chỉ 10 ví dụ được chọn trong prompt từ mỗi loại/danh mục.

Hình 7 thể hiện hiệu quả của các chiến lược random và SR trên các kích thước prompt. Chiến lược SR liên tục vượt trội hơn cả chiến lược random và các kỹ thuật đặc tả truyền thống trên các kích thước prompt khác nhau, làm nổi bật tầm quan trọng của một chiến lược xây dựng prompt phù hợp để cải thiện hiệu suất FSL.

Phát hiện 2: Chiến lược semantic retrieval cải thiện thêm hiệu suất của CodeLlama-13B, dẫn đến cải thiện 6.0 – 10.5% so với Jdoctor, tăng 2.7 – 5.6% so với DocTer, và tăng 1.9 – 6.4% so với CallMeMaybe.

VI. RQ3: CHẨN ĐOÁN THẤT BẠI SO SÁNH

Dưới ánh sáng của hiệu suất xuất sắc của LLM so với các kỹ thuật truyền thống, việc đi sâu vào điểm mạnh và hạn chế của chúng là rất quan trọng. Chúng tôi kiểm tra thủ công các trường hợp thất bại của cả phương pháp dựa trên LLM (ví dụ: CodeLlama-13B) và các phương pháp baseline (tức là Jdoctor, DocTer, và CallMeMaybe), và nghiên cứu các triệu chứng thất bại và nguyên nhân gốc rễ của chúng theo cách so sánh, nhằm cung cấp hiểu biết và hướng dẫn cho các kỹ thuật tương lai. Do hạn chế về không gian, chúng tôi trình bày kết quả cho bộ dữ liệu Jdoctor-data, với hai bộ dữ liệu khác có sẵn trong tài liệu bổ sung [31]. Các kết luận có giá trị trên tất cả các bộ dữ liệu, không có sự khác biệt đáng kể nào được quan sát.

Hình 8 trình bày hiệu suất so sánh của phương pháp LLM dựa trên CodeLlama-13B (L) và phương pháp baseline Jdoctor (J) dưới dạng biểu đồ Venn. Số trong phần giao nhau (L∩J) biểu thị các trường hợp cả hai phương pháp đều đúng, trong khi số trong phần L∪J cho biết các trường hợp cả hai đều thất bại. Kết quả được trình bày được rút ra từ thí nghiệm sử dụng CodeLlama-13B với SR và K = 60 trong RQ2 (Bảng VI).

Hình 8 cho thấy rằng cả LLM và Jdoctor đều hoạt động tốt trên phần lớn các trường hợp (80.0%), cho thấy rằng LLM nhanh chóng học được hầu hết các quy tắc trích xuất đặc tả từ một số lượng nhỏ ví dụ trong prompts. LLM có nhiều (10.7%) trường hợp đúng độc đáo hơn Jdoctor, cho thấy khả năng tổng quát hóa của LLMs từ việc tiền huấn luyện rộng rãi. Có một vài trường hợp cả hai phương pháp đều thất bại, có thể do những khó khăn vốn có như văn bản phần mềm không đầy đủ.

Để hiểu rõ hơn về ưu và nhược điểm của các phương pháp khác nhau, chúng tôi điều tra các triệu chứng và nguyên nhân cơ bản của các trường hợp thất bại. Chúng tôi lấy mẫu ngẫu nhiên 30 trường hợp từ mỗi phần của Hình 8 trong đó ít nhất một trong các phương pháp thất bại, tức là L∩J, L∩J, và L∪J. Đối với các phần có ít hơn 30 trường hợp (ví dụ: L∩J), chúng tôi lấy mẫu tất cả các trường hợp thất bại.

Kết quả lấy mẫu tạo ra 147 trường hợp thất bại của CodeLlama-13B và 135 của các phương pháp baseline trên ba bộ dữ liệu, với biên độ sai số 6% ở mức tin cậy 90%. Hai tác giả phân loại các trường hợp này một cách độc lập với tác giả thứ ba giải quyết bất đồng.

A. Phân tích Triệu chứng Thất bại

Chúng tôi tiến hành phân tích thêm về phân phối các triệu chứng thất bại của cả LLMs và các phương pháp truyền thống. Các triệu chứng thất bại được phân loại thành bốn danh mục, "ill-formed", "incorrect", "incomplete", và "empty". Danh mục "ill-formed" đề cập đến các đặc tả được tạo ra có dạng không hợp lệ. "Incorrect" chỉ ra các lỗi đặc tả, trong khi "Incomplete" biểu thị đặc tả là một tập con nghiêm ngặt của ground truth. "Empty" biểu thị một đặc tả bị thiếu. Kết quả đầy đủ và nhiều ví dụ hơn có thể được tìm thấy trong artifacts [31].

Chúng tôi có những quan sát sau:

a) LLMs có khả năng tạo ra các đặc tả ill-formed và incomplete cao hơn: Một phần nhỏ (0–3%) các thất bại của CodeLlama-13B là ill-formed, không giống như các phương pháp dựa trên quy tắc truyền thống đảm bảo đầu ra hợp lệ. Ngoài ra, LLMs có khả năng tạo ra các đặc tả incomplete cao hơn 8% so với các phương pháp dựa trên quy tắc, có thể trích xuất đáng tin cậy tất cả các loại bằng cách khớp trực tiếp các chuỗi. Ngược lại, các LLMs generative sử dụng sampling để giải mã đầu ra từ một phân phối, đôi khi có thể bỏ lỡ các token.

b) Các kỹ thuật truyền thống có khả năng tạo ra đặc tả empty cao hơn nhiều so với LLMs: Đối với tất cả ba bộ dữ liệu, thất bại phổ biến nhất của các phương pháp baseline (dựa trên quy tắc) là "Empty" (67%), trong đó không có đặc tả nào được tạo ra do các quy tắc không thể áp dụng. Ngược lại, LLMs tạo ra kết quả bằng cách dự đoán các token bị thiếu và chỉ sẽ tạo ra kết quả trống khi "empty" là kết quả hợp lệ. Mặc dù có tỷ lệ empty thấp hơn, LLM có xu hướng tạo ra các đặc tả incomplete và ill-formed như đã thảo luận trong (a).

Phát hiện 3: So với LLMs, các phương pháp trích xuất đặc tả truyền thống có khả năng tạo ra đặc tả empty cao hơn nhiều, trong khi LLMs có khả năng tạo ra đặc tả ill-formed hoặc incomplete cao hơn.

B. Phân tích Nguyên nhân Gốc rễ

Trong phần này, chúng tôi phân loại các nguyên nhân gốc rễ của thất bại và nghiên cứu phân phối của chúng. Cuối cùng, chúng tôi thực hiện một nghiên cứu so sánh dựa trên các phần trong biểu đồ Venn (Hình 8).

1) Nguyên nhân Gốc rễ Thất bại LLM: Vì kết quả LLM khó diễn giải, nói chung khó xác định nguyên nhân gốc rễ của các trường hợp thất bại của LLMs. Chúng tôi sử dụng phương pháp counterfactual [55], [56]: một phương pháp có cấu trúc để xác định các yếu tố nguyên nhân bằng cách thay đổi một biến tại một thời điểm để quan sát tác động đến kết quả. Cụ thể, chúng tôi xác định nguyên nhân gốc rễ bằng cách tìm cách khắc phục nó. Bản chất của việc khắc phục cho biết nguyên nhân gốc rễ. Trong một số trường hợp, thất bại có thể được khắc phục theo nhiều cách. Chúng tôi coi cách yêu cầu ít nỗ lực nhất là nguyên nhân gốc rễ và phân loại chúng thành năm danh mục. Hình 9a trình bày phân phối của các nguyên nhân gốc rễ của CodeLlama-13B trong các phần khác nhau của biểu đồ Venn (Hình 8). Bây giờ chúng tôi giải thích năm danh mục.

Prompts Không hiệu quả: Có nghĩa là thất bại là do tính không hiệu quả của các ví dụ trong prompt, ngay cả với SR. Mặc dù SR cải thiện đáng kể hiệu suất của FSL (Phần V-B), đôi khi nó thiếu khả năng chọn các ví dụ phù hợp. Nếu chúng ta có thể khắc phục một trường hợp thất bại bằng cách chọn thủ công các ví dụ liên quan hơn cho prompt, hoặc đơn giản là thay đổi thứ tự của các ví dụ trong prompt gốc, chúng tôi coi thất bại là do prompts không hiệu quả.

Theo thanh "CodeLlama-13B (L)" từ Hình 9a, 26% thất bại của CodeLlama-13B trên Jdoctor-data là do lý do này. Chúng tôi thấy rằng thứ tự của các ví dụ đóng một vai trò quan trọng, vì 21% các trường hợp thất bại trong danh mục này được giải quyết bằng cách sắp xếp lại thứ tự của các ví dụ.

Hình 10 trình bày một phần của prompt cho tham số mục tiêu sp_input. CodeLlama-13B thất bại trong việc tạo ra đặc tả ndim:>=2, không được nêu rõ trong mô tả và yêu cầu CodeLlama-13B hiểu mối quan hệ ngầm giữa N và phạm vi giá trị của nó, tức là "N≥=2". Việc thêm một ví dụ với các ràng buộc ngầm như vậy cho phép CodeLlama-13B tạo ra đặc tả đúng.

Thiếu Kiến thức Lĩnh vực: Điều này đề cập đến các thất bại của LLM do thiếu kiến thức lĩnh vực. Ví dụ, trong Hình 11, CodeLlama-13B tạo ra một đặc tả sử dụng một hàm không tồn tại, isInDanger, thay vì searchForDanger. Vấn đề này phát sinh khi LLM thiếu ngữ cảnh liên quan, chẳng hạn như các phương thức trong lớp, trong khi Jdoctor sử dụng một phương pháp dựa trên tìm kiếm kiểm tra tất cả các phương thức trong các lớp liên quan. Kết quả này tiết lộ hạn chế của LLMs so với các phương pháp dựa trên tìm kiếm truyền thống: thiếu kiến thức lĩnh vực.

Để xác thực giả thuyết của chúng tôi, chúng tôi kết hợp thủ công kiến thức lĩnh vực liên quan vào prompt, cùng với các ví dụ được cung cấp. CodeLlama-13B sau đó thành công tạo ra đặc tả chính xác, sử dụng hàm đúng (màu xanh lá cây).

Hình 9 cho thấy rằng 50% thất bại của CodeLlama-13B là do thiếu kiến thức lĩnh vực.

Tập trung Sai: Nó biểu thị các trường hợp LLMs thất bại trong việc tập trung vào các từ khóa quan trọng hoặc bị hướng dẫn sai hoặc chuyển hướng bởi nội dung khác. Ví dụ, Hình 12 cho thấy LLM thất bại trong việc tạo ra đặc tả đúng từ tài liệu gốc (màu vàng), numeric, chỉ định kiểu dữ liệu của tensor đầu vào. Bằng cách sử dụng một mô tả được sửa đổi nhẹ chỉ đơn giản là trích dẫn từ khóa, LLM thành công tạo ra đặc tả. Hình 9 tiết lộ rằng 13% thất bại của CodeLlama-13B là do tập trung sai.

Để xác định các thất bại như vậy, chúng tôi áp dụng ba chiến lược đột biến đầu vào: các sửa đổi nhỏ bằng cách đơn giản thêm dấu ngoặc kép vào các từ khóa; viết lại câu trong khi bảo toàn cùng cấu trúc cú pháp (ví dụ: thay đổi "A hoặc B" thành "B hoặc A"); và xóa nội dung dư thừa để giúp LLM tập trung vào các phần cần thiết. Cả ba chiến lược đều liên quan đến các đột biến đơn giản và bảo toàn ngữ nghĩa và không có tác động đến các phương pháp dựa trên quy tắc như DocTer vì chúng dựa vào cấu trúc cú pháp. Chúng tôi thấy rằng 42% các trường hợp như vậy có thể được giải quyết bằng cách chỉ trích dẫn (các) từ khóa.

Được Diễn đạt Kém: Nó đề cập đến các trường hợp tài liệu hoặc bình luận gốc mơ hồ, được viết kém hoặc khó hiểu. Viết lại câu để làm rõ ý nghĩa của nó cho phép LLMs tạo ra câu trả lời đúng. Theo Hình 9, nó đóng góp 6% thất bại của CodeLlama-13B.

Khác: Chúng tôi nhóm các danh mục ít phổ biến hơn thành "khác", bao gồm "tài liệu mâu thuẫn" và "không rõ ràng", chiếm 6% thất bại của CodeLlama-13B. Cái trước đề cập đến các bình luận hoặc tài liệu có lỗi hoặc tự mâu thuẫn, gây ra sự khác biệt giữa các chú thích bộ dữ liệu và các đặc tả được tạo bởi LLM. "Không rõ ràng" chỉ ra các thất bại với nguyên nhân gốc rễ không rõ ràng, mà chúng tôi không thể khắc phục mặc dù có nhiều nỗ lực.

Phát hiện 4: Hai nguyên nhân gốc rễ chủ đạo kết hợp (prompts không hiệu quả và thiếu kiến thức lĩnh vực) dẫn đến 76% thất bại của CodeLlama-13B.

2) Nguyên nhân Gốc rễ Thất bại Phương pháp Baseline: Chúng tôi điều tra thủ công các trường hợp thất bại được lấy mẫu cho Jdoctor, DocTer, và CallMeMaybe và xác định ba nguyên nhân gốc rễ: quy tắc bị thiếu, hiểu ngữ nghĩa không hoàn chỉnh, và quy tắc không chính xác. Phân phối trên Jdoctor-data có trong Hình 9b.

Quy tắc Bị thiếu: Nó đề cập đến việc thiếu các quy tắc hoặc mẫu liên quan, thường dẫn đến đặc tả "empty" (Phần VI-A). Đáng chú ý là 93% các trường hợp thất bại của phương pháp baseline thuộc danh mục này, bộc lộ một hạn chế của các phương pháp dựa trên quy tắc: phụ thuộc nhiều vào các quy tắc được định nghĩa thủ công hoặc hạn chế.

Hiểu Ngữ nghĩa Không hoàn chỉnh: Điều này xảy ra khi các phương pháp dựa trên quy tắc khớp một phần của câu nhưng thất bại trong việc nắm bắt ngữ nghĩa đầy đủ của nó, dẫn đến kết quả không chính xác. Ví dụ, DocTer trích xuất một đặc tả cấu trúc vector từ "Trình khởi tạo cho vector bias" nhưng bỏ qua ngữ cảnh đầy đủ hoặc mối quan hệ phần tử, ảnh hưởng đến tính đúng đắn. Điều này chiếm 7% thất bại trên ba bộ dữ liệu.

Quy tắc Không chính xác: Danh mục này biểu thị các trường hợp các quy tắc được áp dụng không chính xác. Danh mục thất bại này độc đáo với DocTer trong ba công cụ chúng tôi đánh giá và do đó không được hiển thị trong hình. DocTer tự động xây dựng các quy tắc (ánh xạ từ các mẫu cú pháp đến đặc tả) dựa trên sự xuất hiện đồng thời của chúng trong bộ dữ liệu được chú thích, có thể tiềm ẩn giới thiệu các quy tắc không chính xác, dẫn đến các trích xuất không chính xác. 10% các trường hợp thất bại của DocTer là do quy tắc không chính xác, trong khi Jdoctor và CallMeMaybe không có bất kỳ thất bại nào như vậy vì các quy tắc của chúng đều được định nghĩa thủ công.

3) Phân tích Nguyên nhân Gốc rễ So sánh: Chúng tôi so sánh phân phối nguyên nhân gốc rễ của CodeLlama-13B (Hình 9a), với những của các phương pháp baseline (Hình 9b).

Trong các trường hợp phương pháp baseline thành công (thanh "CodeLlama-13B (L∩J)"), các nguyên nhân thất bại chủ đạo của CodeLlama-13B là prompts không hiệu quả, thiếu kiến thức lĩnh vực, và tập trung sai. Đáng chú ý, tập trung sai đặc biệt phổ biến ở đây, trái ngược với phần L∪J trong đó cả hai phương pháp đều thất bại. Đối với các trường hợp CodeLlama-13B thành công (thanh "Jdoctor (L∩J)") và phương pháp baseline thất bại, chúng tôi quan sát rằng các thất bại baseline độc đáo chủ yếu do quy tắc bị thiếu và hiểu ngữ nghĩa không hoàn chỉnh. Nghĩa là, khi prompts và văn bản phần mềm có chất lượng cao, LLMs thể hiện khả năng tổng quát hóa xuất sắc, không bị ràng buộc bởi các tập quy tắc. Chúng đưa ra dự đoán dựa trên toàn bộ mô tả thay vì những mô tả một phần. Đáng chú ý, 10% thất bại độc đáo của DocTer là do quy tắc không chính xác, tất cả đều có thể được xử lý bởi CodeLlama-13B. Chúng tôi nghi ngờ rằng bất kỳ kỹ thuật suy luận quy tắc tự động nào cũng có thể gặp phải các vấn đề như vậy nếu không có sửa chữa của con người.

Phát hiện 5: So với các phương pháp truyền thống, CodeLlama-13B gặp khó khăn với prompts không hiệu quả và thiếu kiến thức lĩnh vực, gây ra 75% thất bại độc đáo của nó. Tuy nhiên, LLMs thể hiện khả năng tổng quát hóa xuất sắc, trong khi các phương pháp dựa trên quy tắc thường dựa vào các quy tắc không đủ hoặc không chính xác được trích xuất từ các bộ dữ liệu hạn chế.

VII. RQ4: SO SÁNH MÔ HÌNH

Bảng IX, X, và XI so sánh hiệu suất và chi phí của 13 LLMs với các phương pháp baseline (Jdoctor, DocTer, và CallMeMaybe). Chúng tôi chỉ liệt kê kết quả tốt nhất cho mỗi mô hình với SR, và kết quả đầy đủ có thể được tìm thấy trong artifacts [31]. Thời gian phản hồi của mô hình để tạo ra đặc tả, tùy thuộc vào nhiều yếu tố khác nhau như môi trường, được bỏ qua. Nói chung, thời gian phản hồi khá nhanh cho việc sử dụng thực tế, dao động từ 0.6 đến 26.6 giây. Do hạn chế token được thảo luận trong Phần IV-A, một số thí nghiệm bị bỏ qua. Nhiều thí nghiệm hơn trên DocTer-data bị bỏ qua vì prompts cho DocTer-data dài hơn nhiều so với các bộ dữ liệu khác, làm cho chúng không thể áp dụng cho một số thiết lập nhất định.

Nhìn chung, các LLMs generic với ít nhất 10 ví dụ lĩnh vực đạt được hiệu suất tốt hơn hoặc tương đương như các kỹ thuật trích xuất đặc tả tiên tiến được xây dựng tùy chỉnh như DocTer. Cụ thể, 13, 10, và 9 trong số 13 mô hình vượt trội hơn các kỹ thuật truyền thống Jdoctor, DocTer, và CallMeMaybe.

Phát hiện 6: Hầu hết LLMs đạt được hiệu suất tốt hơn hoặc tương đương như các kỹ thuật trích xuất đặc tả truyền thống được xây dựng tùy chỉnh.

a) Các Mô hình Hiệu suất Tốt nhất: Trong số 13 mô hình, CodeLlama-13B và StarCoder2-15B đạt được hiệu suất tốt nhất trên tất cả các bộ dữ liệu, với điểm F1 87.9% (Bảng X) và độ chính xác 93.5% (Bảng IX) và 76.4% (Bảng XI).

Phát hiện 7: CodeLlama-13B và StarCoder2-15B là các mô hình open-source cạnh tranh nhất để trích xuất đặc tả, với hiệu suất trong số cao nhất, chi phí $0 và hỗ trợ prompt dài, tạo điều kiện cho khả năng tiếp cận, thích ứng và tùy chỉnh của nó.

b) Các Mô hình Thương mại (GPT-3.5 và GPT-4): GPT-3.5 và GPT-4 ($0.0015 và $0.03 trên 1,000 tokens) đạt được hiệu suất kém hơn một chút so với các mô hình hiệu suất tốt nhất (ví dụ: CodeLlama-13B) với cùng số lượng ví dụ. So với CodeLlama-13B và StarCoder2-15B, miễn phí, open-source và có ít tham số hơn nhiều (Bảng II), các mô hình thương mại (ví dụ: GPT-4) không thêm được F1 hoặc độ chính xác nào.

Cụ thể, tổng chi phí $32.8 của GPT-4 (cho K = 10−60) trên CallMeMaybe-data gây ra sự suy giảm độ chính xác 5.6%.

Mặc dù có chi phí và rủi ro của các mô hình thương mại, chẳng hạn như phí sử dụng và mối quan tâm về khả năng tiếp cận và tính liên tục của nghiên cứu và ứng dụng, chúng thường thuận tiện hơn, chỉ yêu cầu một cuộc gọi API với yêu cầu phần cứng tối thiểu. Ngược lại, các mô hình open-source như CodeLlama-13B thông qua Hugging Face APIs yêu cầu phần cứng đáng kể hơn (ví dụ: GPUs) và chuyên môn kỹ thuật để cấu hình và tối ưu hóa. Cả hai tùy chọn đều mang lại lợi thế riêng biệt, cho phép người dùng lựa chọn dựa trên nhu cầu, tài nguyên và ngân sách của họ.

Phát hiện 8: Các mô hình thương mại (ví dụ: GPT-4) mang lại sự tiện lợi và hiệu suất hàng đầu nhưng với chi phí cao hơn và rủi ro như khả năng tiếp cận, trong khi các mô hình open-source có hiệu quả chi phí và là lựa chọn thay thế linh hoạt nhưng yêu cầu chuyên môn kỹ thuật và phần cứng lớn hơn.

c) Các Mô hình Open-Source Khác (CodeLlama-7B, deepseek-coder-6.7B, Llama3, Llama2, StarCoder2-7B, StarCoder, và CodeGen2): StarCoder2-7B và CodeLlama-7B mang lại hiệu suất cao, hơi thấp hơn mô hình hiệu suất tốt nhất (0.7% – 1.7%), trình bày nó như một lựa chọn thay thế khả thi, nhỏ hơn cho CodeLlama-13B và StarCoder2-15B. Ngược lại, Llama2, mặc dù có cùng kích thước mô hình với CodeLlama (7B và 13B), hoạt động kém hơn 3.0% – 5.7%, làm cho nó ít phù hợp cho nhiệm vụ này. StarCoder-16B và Llama3 thể hiện hiệu suất mạnh mẽ của chúng bằng cách vượt trội hơn các phương pháp baseline 1.9 – 10.0%. Mặt khác, CodeGen2 có hiệu suất kém hơn trong nhiệm vụ. deepseek-coder-6.7B hoạt động kém hơn CallMeMaybe 3.7%.

Phát hiện 9: CodeLlama-13B và StarCoder2-15B mang lại hiệu suất tốt nhất về tạo ra đặc tả phần mềm trong số các mô hình open-source được kiểm tra. Codellama-7B, StarCoder2-7B, StarCoder-16B, và LLama3-8B là những lựa chọn thay thế open-source hợp lý.

VIII. THÁCH THỨC VÀ HƯỚNG TƯƠNG LAI

Phân tích các trường hợp thất bại của chúng tôi làm nổi bật một số thách thức, chỉ ra các hướng nghiên cứu tương lai trong hai lĩnh vực:

a) Các Phương pháp Lai: Phân tích nguyên nhân gốc rễ (ví dụ: Phần VI-B3) cho thấy rằng việc kết hợp các điểm mạnh bổ sung của LLMs và các phương pháp truyền thống có thể cải thiện việc tạo ra đặc tả. Các phương pháp lai có thể khai thác khả năng tổng quát hóa của LLMs cùng với độ chính xác cụ thể theo lĩnh vực của các kỹ thuật truyền thống để giải quyết các khoảng trống như thiếu kiến thức lĩnh vực. Công việc đầy hứa hẹn đã bắt đầu trong lĩnh vực này, tích hợp LLMs với kiểm tra phần mềm, phân tích chương trình [21], [22], [57], và tạo ra tăng cường retrieval [24], [25].

b) Cải thiện Hiệu quả Prompt: Cải thiện prompts là một hướng chính khác để nâng cao hiệu suất LLM trong việc trích xuất đặc tả. Nghiên cứu gần đây về việc tạo ra các prompt biểu cảm hơn, có thể tùy chỉnh và cụ thể theo lĩnh vực [58]–[60] cho thấy tiềm năng trong việc hướng dẫn LLMs để có độ chính xác tốt hơn.

IX. NGUY CƠ ĐỐI VỚI TÍNH HỢP LỆ

a) Đánh giá Thủ công: Để giải quyết vấn đề đặc tả tương đương trong Jdoctor-data (Phần III-B3), chúng tôi đánh giá thủ công kết quả cho RQ1, RQ2, và RQ4, và phân tích các trường hợp thất bại được lấy mẫu trong RQ3. Để giảm thiểu thiên vị, hai tác giả tiến hành đánh giá độc lập với 5.9% bất đồng, giải quyết bất đồng với tác giả thứ ba.

b) Phân tích trên Các Trường hợp Được lấy mẫu: Trong RQ3 (Phần VI), chúng tôi tiến hành phân tích so sánh trên một tập hợp các trường hợp được lấy mẫu ngẫu nhiên. Phương pháp lấy mẫu này có thể tiềm ẩn hạn chế khả năng tổng quát hóa các kết luận của chúng tôi cho toàn bộ dân số dữ liệu. Để giảm thiểu mối quan tâm này, chúng tôi mở rộng phân tích để bao gồm các trường hợp thất bại từ 2 mô hình bổ sung, GPT-3.5 và StarCoder (Phần VI-C), trong đó chúng tôi quan sát các mẫu nhất quán, do đó củng cố tính mạnh mẽ của các phát hiện của chúng tôi.

c) Rò rỉ Dữ liệu: Sử dụng các bộ dữ liệu công khai giới thiệu các rủi ro tiềm ẩn về rò rỉ dữ liệu. Để giải quyết điều này, chúng tôi phân tích độ nhạy hiệu suất đối với số lượng ví dụ trong prompts (RQ1 và RQ2) và tiến hành các thí nghiệm học zero-shot (ZSL) và one-shot (OSL). ZSL cho thấy hiệu suất cực kỳ kém (0–0.2% độ chính xác/F1), và hiệu suất của OSL thấp hơn FSL 28.9—77.2%, nhấn mạnh vai trò của học in-context.

X. CÔNG VIỆC LIÊN QUAN

1) Bộ dữ liệu Đặc tả Phần mềm và Phương pháp Trích xuất: Các kỹ thuật truyền thống để trích xuất đặc tả phần mềm từ văn bản, chẳng hạn như các phương pháp dựa trên quy tắc [1]–[4], [8], [13] hoặc dựa trên ML [1], [4], [12], cho thấy khả năng tổng quát hóa hạn chế trên các lĩnh vực và yêu cầu nỗ lực thủ công và kiến thức lĩnh vực. Công việc của chúng tôi là đầu tiên nghiên cứu khả năng của LLMs trong nhiệm vụ này, tận dụng FSL mang lại khả năng tổng quát hóa được cải thiện và yêu cầu ít dữ liệu được chú thích. Chúng tôi đánh giá LLMs trên ba bộ dữ liệu (Phần III-A). Ngoài Jdoctor, các kỹ thuật như @tcomment [8], Toradocu [2], và C2S [11] cũng trích xuất đặc tả từ Javadoc. Chúng bị loại khỏi nghiên cứu này vì C2S không có sẵn và những cái khác đã lỗi thời hoặc kém hiệu quả hơn [1], [11]. Advance [12] và DRONE [13] bị loại do thiếu đặc tả ground-truth.

2) Mô hình Ngôn ngữ Lớn (LLMs): LLMs đã được phát triển và sử dụng cho một loạt rộng các nhiệm vụ hiểu ngôn ngữ tự nhiên như trả lời câu hỏi [18], [19], [35], [61]–[63] và các nhiệm vụ tạo ra ngôn ngữ tự nhiên như tóm tắt văn bản [18] và dịch máy [18], [35], [62]. LLMs như CodeLlama-13B đã thể hiện khả năng mạnh mẽ của chúng trong nhiều lĩnh vực. Chúng tôi đánh giá 13 LLMs tiên tiến, khác nhau về thiết kế, kích thước, v.v., và thảo luận chúng trong Phần III. Trong khi các LLMs khác tồn tại, chúng không được khám phá trong nghiên cứu này vì chúng không phù hợp cho nhiệm vụ của chúng tôi [19], kém hiệu quả hơn [17], [62]–[64], hoặc không thể vừa với thiết bị của chúng tôi [65].

3) Ứng dụng của LLMs cho các nhiệm vụ SE: LLMs cũng đã được áp dụng hiệu quả cho các nhiệm vụ SE như hoàn thành mã [15], [24], [25], [48], [53], tạo ra trường hợp kiểm tra [21], [22], [66], [67], sửa chữa chương trình [27], [68], và bảo mật phần mềm [69]–[71], thường vượt trội hơn các phương pháp truyền thống. Tuy nhiên, LLMs đã cho thấy hạn chế trong các lĩnh vực như tóm tắt mã [72], gợi ý mã [73], và Q&A phần mềm [74]. Ví dụ, các nhà phát triển thường xuyên vượt trội hơn LLMs trong các nhiệm vụ liên quan đến mã, làm nổi bật nhu cầu đánh giá toàn diện LLMs trong việc tạo ra đặc tả phần mềm để xác định điểm mạnh và điểm yếu của chúng trong bối cảnh SE cụ thể này.

XI. KẾT LUẬN

Chúng tôi trình bày nghiên cứu thực nghiệm đầu tiên đánh giá hiệu quả của 13 LLMs để tạo ra đặc tả phần mềm. Các phát hiện của chúng tôi tiết lộ rằng hầu hết LLMs đạt được hiệu suất tốt hơn hoặc tương đương so với các phương pháp truyền thống. Hai trong số các mô hình hiệu suất tốt nhất, CodeLlama-13B và StarCoder2-15B, như các mô hình open-source, vượt trội hơn các phương pháp truyền thống 5.6 – 10.5% với các ví dụ tương tự về mặt ngữ nghĩa. Hiệu suất mạnh mẽ của chúng làm cho các mô hình thương mại closed-source (ví dụ: GPT4) trở nên kém hấp dẫn hơn do kích thước và chi phí. Ngoài ra, chúng tôi tiến hành chẩn đoán thất bại toàn diện và xác định điểm mạnh và điểm yếu của cả phương pháp truyền thống và LLMs. Hai hạn chế chủ đạo của LLMs là prompts không hiệu quả và thiếu kiến thức lĩnh vực. Nghiên cứu của chúng tôi đưa ra hiểu biết cho nghiên cứu tương lai để cải thiện hiệu suất của LLMs về tạo ra đặc tả bao gồm các phương pháp lai kết hợp các phương pháp truyền thống và LLMs, và cải thiện hiệu quả prompts.

XII. LỜI CẢM ỪN

Các tác giả cảm ơn các nhà đánh giá ẩn danh vì phản hồi vô giá của họ và Guannan Wei vì đầu vào của anh ấy về bản thảo đầu. Nghiên cứu được hỗ trợ một phần bởi các giải thưởng NSF 1901242 và 2006688. Nó cũng được hỗ trợ một phần bởi các khoản tài trợ National Research Foundation được tài trợ bởi chính phủ Hàn Quốc (MSIT) (Số 2022R1A2C10911913 và 2022H1D3A2A0109297911), và các khoản tài trợ Institute of Information & Communications Technology Planning & Evaluation (IITP) được tài trợ bởi MSIT (Số RS-2023-00222830, RS-2024-00337414, và 2020-0-1336).

TÀI LIỆU THAM KHẢO

[1] A. Blasi, A. Goffi, K. Kuznetsov, A. Gorla, M. D. Ernst, M. Pezzè, và S. D. Castellanos, "Translating code comments to procedure specifications," Proceedings of the 27th ACM SIGSOFT International Symposium on Software Testing and Analysis, 2018.

[2] A. Goffi, A. Gorla, M. D. Ernst, và M. Pezzè, "Automatic generation of oracles for exceptional behaviors," trong Proceedings of the 25th international symposium on software testing and analysis, 2016, tr. 213–224.

[3] D. Xie, Y. Li, M. Kim, H. V. Pham, L. Tan, X. Zhang, và M. W. Godfrey, "Docter: documentation-guided fuzzing for testing deep learning api functions," Proceedings of the 31st ACM SIGSOFT International Symposium on Software Testing and Analysis, 2021.

[4] L. Tan, D. Yuan, G. Krishna, và Y. Zhou, "/*icomment: bugs or bad comments?*/," trong Symposium on Operating Systems Principles, 2007.

[5] E. Wong, L. Zhang, S. Wang, T. Liu, và L. Tan, "Dase: Document-assisted symbolic execution for improving automated software testing," 2015 IEEE/ACM 37th IEEE International Conference on Software Engineering, tập 1, tr. 620–631, 2015.

[6] C. Boyapati, S. Khurshid, và D. Marinov, "Korat: Automated testing based on java predicates," SIGSOFT Software Engineering Notes, tập 27, số 4, tr. 123–133, 2002.

[7] C. Cadar, D. Dunbar, và D. Engler, "KLEE: Unassisted and automatic generation of high-coverage tests for complex systems programs," trong Proceedings of the 8th USENIX conference on Operating systems design and implementation, 2008, tr. 209–224.

[8] S. H. Tan, D. Marinov, L. Tan, và G. T. Leavens, "@tcomment: Testing javadoc comments to detect comment-code inconsistencies," 2012 IEEE Fifth International Conference on Software Testing, Verification and Validation, tr. 260–269, 2012.

[9] R. Pandita, X. Xiao, H. Zhong, T. Xie, S. Oney, và A. Paradkar, "Inferring method specifications from natural language api descriptions," trong 2012 34th international conference on software engineering (ICSE). IEEE, 2012, tr. 815–825.

[10] A. Blasi, A. Gorla, M. D. Ernst, và M. Pezzè, "Call me maybe: Using nlp to automatically generate unit test cases respecting temporal constraints," trong Proceedings of the 37th IEEE/ACM International Conference on Automated Software Engineering, 2022, tr. 1–11.

[11] J. Zhai, Y. Shi, M. Pan, G. Zhou, Y. Liu, C. Fang, S. Ma, L. Tan, và X. Zhang, "C2s: translating natural language comments to formal program specifications," Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering, 2020.

[12] T. Lv, R. Li, Y. Yang, K. Chen, X. Liao, X. Wang, P. Hu, và L. Xing, "Rtfm! automatic assumption discovery and verification derivation from library document for api misuse detection," Proceedings of the 2020 ACM SIGSAC Conference on Computer and Communications Security, 2020.

[13] Y. Zhou, C. Wang, X. Yan, T. Chen, S. Panichella, và H. C. Gall, "Automatic detection and repair recommendation of directive defects in java api documentation," IEEE Transactions on Software Engineering, tập 46, tr. 1004–1023, 2020.

[14] M. Chen, J. Tworek, H. Jun, Q. Yuan, H. P. de Oliveira Pinto, J. Kaplan, H. Edwards, Y. Burda, N. Joseph, G. Brockman, A. Ray, R. Puri, G. Krueger, M. Petrov, H. Khlaaf, G. Sastry, P. Mishkin, B. Chan, S. Gray, N. Ryder, M. Pavlov, A. Power, L. Kaiser, M. Bavarian, C. Winter, P. Tillet, F. P. Such, D. Cummings, M. Plappert, F. Chantzis, E. Barnes, A. Herbert-Voss, W. H. Guss, A. Nichol, A. Paino, N. Tezak, J. Tang, I. Babuschkin, S. Balaji, S. Jain, W. Saunders, C. Hesse, A. N. Carr, J. Leike, J. Achiam, V. Misra, E. Morikawa, A. Radford, M. Knight, M. Brundage, M. Murati, K. Mayer, P. Welinder, B. McGrew, D. Amodei, S. McCandlish, I. Sutskever, và W. Zaremba, "Evaluating large language models trained on code," CoRR, tập abs/2107.03374, 2021. [Trực tuyến]. Có sẵn: https://arxiv.org/abs/2107.03374

[15] E. Nijkamp, B. Pang, H. Hayashi, L. Tu, H. Wang, Y. Zhou, S. Savarese, và C. Xiong, "A conversational paradigm for program synthesis," arXiv preprint, 2022.

[16] D. Fried, A. Aghajanyan, J. Lin, S. Wang, E. Wallace, F. Shi, R. Zhong, W.-t. Yih, L. Zettlemoyer, và M. Lewis, "Incoder: A generative model for code infilling and synthesis," 2022. [Trực tuyến]. Có sẵn: https://arxiv.org/abs/2204.05999

[17] W. Yue, W. Weishi, J. Shafiq, và C. H. Steven, "Codet5: Identifier-aware unified pre-trained encoder-decoder models for code understanding and generation," trong Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, EMNLP 2021, 2021.

[18] T. B. Brown, B. Mann, N. Ryder, M. Subbiah, J. Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam, G. Sastry, A. Askell, S. Agarwal, A. Herbert-Voss, G. Krueger, T. Henighan, R. Child, A. Ramesh, D. M. Ziegler, J. Wu, C. Winter, C. Hesse, M. Chen, E. Sigler, M. Litwin, S. Gray, B. Chess, J. Clark, C. Berner, S. McCandlish, A. Radford, I. Sutskever, và D. Amodei, "Language models are few-shot learners," CoRR, tập abs/2005.14165, 2020. [Trực tuyến]. Có sẵn: https://arxiv.org/abs/2005.14165

[19] J. Devlin, M. Chang, K. Lee, và K. Toutanova, "BERT: pre-training of deep bidirectional transformers for language understanding," CoRR, tập abs/1810.04805, 2018. [Trực tuyến]. Có sẵn: http://arxiv.org/abs/1810.04805

[20] J. Liu, C. S. Xia, Y. Wang, và L. Zhang, "Is your code generated by chatgpt really correct? rigorous evaluation of large language models for code generation," arXiv preprint arXiv:2305.01210, 2023.

[21] Z. Yuan, Y. Lou, M. Liu, S. Ding, K. Wang, Y. Chen, và X. Peng, "No more manual tests? evaluating and improving chatgpt for unit test generation," arXiv preprint arXiv:2305.04207, 2023.

[22] B. Chen, F. Zhang, A. Nguyen, D. Zan, Z. Lin, J.-G. Lou, và W. Chen, "Codet: Code generation with generated tests," arXiv preprint arXiv:2207.10397, 2022.

[23] M. Schäfer, S. Nadi, A. Eghbali, và F. Tip, "Adaptive test generation using a large language model," arXiv preprint arXiv:2302.06527, 2023.

[24] Y. Ding, Z. Wang, W. Ahmad, H. Ding, M. Tan, N. Jain, M. K. Ramanathan, R. Nallapati, P. Bhatia, D. Roth và cộng sự, "Crosscodeeval: A diverse and multilingual benchmark for cross-file code completion," Advances in Neural Information Processing Systems, tập 36, 2024.

[25] F. Zhang, B. Chen, Y. Zhang, J. Keung, J. Liu, D. Zan, Y. Mao, J.-G. Lou, và W. Chen, "Repocoder: Repository-level code completion through iterative retrieval and generation," arXiv preprint arXiv:2303.12570, 2023.

[26] N. Jiang, T. Lutellier, và L. Tan, "Impact of code language models on automated program repair," trong 2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE), 2023.

[27] Y. Zhang, H. Ruan, Z. Fan, và A. Roychoudhury, "Autocoderover: Autonomous program improvement," trong Proceedings of the 33rd ACM SIGSOFT International Symposium on Software Testing and Analysis, 2024, tr. 1592–1604.

[28] K. Pei, D. Bieber, K. Shi, C. Sutton, và P. Yin, "Can large language models reason about program invariants?" 2023.

[29] W. Ahmad, S. Chakraborty, B. Ray, và K.-W. Chang, "Unified pre-training for program understanding and generation," trong Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. Trực tuyến: Association for Computational Linguistics, Tháng 6 2021, tr. 2655–2668. [Trực tuyến]. Có sẵn: https://aclanthology.org/2021.naacl-main.211

[30] T. B. Brown, B. Mann, N. Ryder, M. Subbiah, J. Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam, G. Sastry, A. Askell, S. Agarwal, A. Herbert-Voss, G. Krueger, T. J. Henighan, R. Child, A. Ramesh, D. M. Ziegler, J. Wu, C. Winter, C. Hesse, M. Chen, E. Sigler, M. Litwin, S. Gray, B. Chess, J. Clark, C. Berner, S. McCandlish, A. Radford, I. Sutskever, và D. Amodei, "Language models are few-shot learners," ArXiv, tập abs/2005.14165, 2020.

[31] "Artifacts," 2024. [Trực tuyến]. Có sẵn: https://github.com/lt-asset/llm4spec

[32] R. David, L. Coniglio, M. Ceccato và cộng sự, "Qsynth-a program synthesis based approach for binary code deobfuscation," trong BAR 2020 Workshop, 2020.

[33] M. Lewis, Y. Liu, N. Goyal, M. Ghazvininejad, A. Mohamed, O. Levy, V. Stoyanov, và L. Zettlemoyer, "Bart: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension," trong Annual Meeting of the Association for Computational Linguistics, 2019.

[34] A. Radford, J. Wu, R. Child, D. Luan, D. Amodei, và I. Sutskever, "Language models are unsupervised multitask learners," 2019.

[35] C. Raffel, N. Shazeer, A. Roberts, K. Lee, S. Narang, M. Matena, Y. Zhou, W. Li, và P. J. Liu, "Exploring the limits of transfer learning with a unified text-to-text transformer," CoRR, tập abs/1910.10683, 2019. [Trực tuyến]. Có sẵn: http://arxiv.org/abs/1910.10683

[36] P. Riley, N. Constant, M. Guo, G. Kumar, D. Uthus, và Z. Parekh, "Textsettr: Few-shot text style extraction and tunable targeted restyling," 01 2021, tr. 3786–3800.

[37] S. M. Xie, A. Raghunathan, P. Liang, và T. Ma, "An explanation of in-context learning as implicit bayesian inference," trong International Conference on Learning Representations, 2022. [Trực tuyến]. Có sẵn: https://openreview.net/forum?id=RdJVFCHjUMI

[38] L. Breiman và P. Spector, "Submodel selection and evaluation in regression. the x-random case," International statistical review/revue internationale de Statistique, tr. 291–319, 1992.

[39] T. Hastie, R. Tibshirani, và J. Friedman, The Elements of Statistical Learning, ser. Springer Series in Statistics. New York, NY, USA: Springer New York Inc., 2001.

[40] M. Magnusson, M. Andersen, J. Jonasson, và A. Vehtari, "Bayesian leave-one-out cross-validation for large data," trong Proceedings of the 36th International Conference on Machine Learning, ser. Proceedings of Machine Learning Research, K. Chaudhuri và R. Salakhutdinov, Eds., tập 97. PMLR, 09–15 Tháng 6 2019, tr. 4244–4253. [Trực tuyến]. Có sẵn: https://proceedings.mlr.press/v97/magnusson19a.html

[41] O. Rubin, J. Herzig, và J. Berant, "Learning to retrieve prompts for in-context learning," ArXiv, tập abs/2112.08633, 2021.

[42] J. Liu, D. Shen, Y. Zhang, B. Dolan, L. Carin, và W. Chen, "What makes good in-context examples for gpt-3?" arXiv preprint arXiv:2101.06804, 2021.

[43] "all-roberta-large-v1," https://huggingface.co/sentence-transformers/all-roberta-large-v1, Truy cập: 2023.

[44] N. Reimers và I. Gurevych, "Sentence-bert: Sentence embeddings using siamese bert-networks," trong Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics, 11 2019. [Trực tuyến]. Có sẵn: http://arxiv.org/abs/1908.10084

[45] R. Shin, C. H. Lin, S. Thomson, C. C. Chen, S. Roy, E. A. Platanios, A. Pauls, D. Klein, J. Eisner, và B. V. Durme, "Constrained language models yield few-shot semantic parsers," ArXiv, tập abs/2104.08768, 2021.

[46] OpenAI, "Gpt-4," 2024. [Trực tuyến]. Có sẵn: https://platform.openai.com/docs/models/gpt-%204#gpt-4-turbo-and-gpt-4

[47] ——, "Gpt-3.5," 2024. [Trực tuyến]. Có sẵn: https://platform.openai.com/docs/models/gpt-%204#gpt-3-5-turbo

[48] B. Roziere, J. Gehring, F. Gloeckle, S. Sootla, I. Gat, X. E. Tan, Y. Adi, J. Liu, T. Remez, J. Rapin và cộng sự, "Code llama: Open foundation models for code," arXiv preprint arXiv:2308.12950, 2023.

[49] A. Dubey, A. Jauhri, A. Pandey, A. Kadian, A. Al-Dahle, A. Letman, A. Mathur, A. Schelten, A. Yang, A. Fan và cộng sự, "The llama 3 herd of models," arXiv preprint arXiv:2407.21783, 2024.

[50] H. Touvron, L. Martin, K. Stone, P. Albert, A. Almahairi, Y. Babaei, N. Bashlykov, S. Batra, P. Bhargava, S. Bhosale và cộng sự, "Llama 2: Open foundation and fine-tuned chat models," arXiv preprint arXiv:2307.09288, 2023.

[51] D. Guo, Q. Zhu, D. Yang, Z. Xie, K. Dong, W. Zhang, G. Chen, X. Bi, Y. Wu, Y. Li và cộng sự, "Deepseek-coder: When the large language model meets programming–the rise of code intelligence," arXiv preprint arXiv:2401.14196, 2024.

[52] A. Lozhkov, R. Li, L. B. Allal, F. Cassano, J. Lamy-Poirier, N. Tazi, A. Tang, D. Pykhtar, J. Liu, Y. Wei và cộng sự, "Starcoder 2 and the stack v2: The next generation," arXiv preprint arXiv:2402.19173, 2024.

[53] R. Li, L. B. Allal, Y. Zi, N. Muennighoff, D. Kocetkov, C. Mou, M. Marone, C. Akiki, J. Li, J. Chim và cộng sự, "Starcoder: may the source be with you!" arXiv preprint arXiv:2305.06161, 2023.

[54] E. Nijkamp, H. Hayashi, C. Xiong, S. Savarese, và Y. Zhou, "Codegen2: Lessons for training llms on programming and natural languages," arXiv preprint arXiv:2305.02309, 2023.

[55] P. R. Rosenbaum, P. Rosenbaum, và Briskman, Design of observational studies. Springer, 2010, tập 10.

[56] L. G. Neuberg, "Causality: models, reasoning, and inference, by judea pearl, cambridge university press, 2000," Econometric Theory, tập 19, số 4, tr. 675–685, 2003.

[57] C. Lemieux, J. P. Inala, S. K. Lahiri, và S. Sen, "Codamosa: Escaping coverage plateaus in test generation with pre-trained large language models," trong International conference on software engineering (ICSE), 2023.

[58] S. Abukhalaf, M. Hamdaqa, và F. Khomh, "On codex prompt engineering for ocl generation: An empirical study," arXiv preprint arXiv:2303.16244, 2023.

[59] L. Beurer-Kellner, M. Fischer, và M. Vechev, "Prompting is programming: A query language for large language models," Proceedings of the ACM on Programming Languages, tập 7, số PLDI, tr. 1946–1969, 2023.

[60] C. Wang, Y. Yang, C. Gao, Y. Peng, H. Zhang, và M. R. Lyu, "No more fine-tuning? an experimental evaluation of prompt tuning in code intelligence," trong Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering, 2022, tr. 382–394.

[61] Y. Liu, M. Ott, N. Goyal, J. Du, M. Joshi, D. Chen, O. Levy, M. Lewis, L. Zettlemoyer, và V. Stoyanov, "Roberta: A robustly optimized BERT pretraining approach," CoRR, tập abs/1907.11692, 2019. [Trực tuyến]. Có sẵn: http://arxiv.org/abs/1907.11692

[62] B. Wang và A. Komatsuzaki, "GPT-J-6B: A 6 Billion Parameter Autoregressive Language Model," https://github.com/kingoflolz/mesh-transformer-jax, Tháng 5 2021.

[63] S. Black, G. Leo, P. Wang, C. Leahy, và S. Biderman, "GPT-Neo: Large Scale Autoregressive Language Modeling with Mesh-Tensorflow," Tháng 3 2021. [Trực tuyến]. Có sẵn: https://doi.org/10.5281/zenodo.5297715

[64] H. Touvron, T. Lavril, G. Izacard, X. Martinet, M.-A. Lachaux, T. Lacroix, B. Rozière, N. Goyal, E. Hambro, F. Azhar và cộng sự, "Llama: Open and efficient foundation language models," arXiv preprint arXiv:2302.13971, 2023.

[65] S. Black, S. R. Biderman, E. Hallahan, Q. G. Anthony, L. Gao, L. Golding, H. He, C. Leahy, K. McDonell, J. Phang, M. M. Pieler, U. S. Prashanth, S. Purohit, L. Reynolds, J. Tow, B. Wang, và S. Weinbach, "Gpt-neox-20b: An open-source autoregressive language model," ArXiv, tập abs/2204.06745, 2022.

[66] Y. Deng, C. S. Xia, H. Peng, C. Yang, và L. Zhang, "Large language models are zero-shot fuzzers: Fuzzing deep-learning libraries via large language models," trong Proceedings of the 32nd ACM SIGSOFT International Symposium on Software Testing and Analysis, 2023, tr. 423–435.

[67] S. Kang, J. Yoon, và S. Yoo, "Large language models are few-shot testers: Exploring llm-based general bug reproduction," trong 2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE), 2023.

[68] H. Ruan, Y. Zhang, và A. Roychoudhury, "Specrover: Code intent extraction via llms," arXiv preprint arXiv:2408.02232, 2024.

[69] X. Xu, Z. Zhang, Z. Su, Z. Huang, S. Feng, Y. Ye, N. Jiang, D. Xie, S. Cheng, L. Tan và cộng sự, "Leveraging generative models to recover variable names from stripped binary," arXiv preprint arXiv:2306.02546, 2023.

[70] D. Xie, Z. Zhang, N. Jiang, X. Xu, L. Tan, và X. Zhang, "Resym: Harnessing llms to recover variable and data structure symbols from stripped binaries," trong Proceedings of the 2024 on ACM SIGSAC Conference on Computer and Communications Security, 2024, tr. 4554–4568.

[71] Z. Su, X. Xu, Z. Huang, Z. Zhang, Y. Ye, J. Huang, và X. Zhang, "Codeart: Better code models by attention regularization when symbols are lacking," Proc. ACM Softw. Eng., tập 1, số FSE, Tháng 7 2024. [Trực tuyến]. Có sẵn: https://doi.org/10.1145/3643752

[72] W. Sun, C. Fang, Y. You, Y. Miao, Y. Liu, Y. Li, G. Deng, S. Huang, Y. Chen, Q. Zhang và cộng sự, "Automatic code summarization via chatgpt: How far are we?" arXiv preprint arXiv:2305.12865, 2023.

[73] A. M. Dakhel, V. Majdinasab, A. Nikanjam, F. Khomh, M. C. Desmarais, và Z. M. J. Jiang, "Github copilot ai pair programmer: Asset or liability?" Journal of Systems and Software, tập 203, tr. 111734, 2023.

[74] B. Xu, T.-D. Nguyen, T. Le-Cong, T. Hoang, J. Liu, K. Kim, C. Gong, C. Niu, C. Wang, B. Le và cộng sự, "Are we ready to embrace generative ai for software q&a?" arXiv preprint arXiv:2307.09765, 2023.

Bảng 1: Số lượng sửa chữa đúng trên lỗi single-hunk Defects4J 1.2 và lỗi single-line Defects4J 2.0

Công cụ Phương pháp #Sửa chữa Đúng
Defects4J 1.2 Defects4J 2.0 Tổng
CoCoNuT NMT 30 - -
DLFix NMT 32 - -
PraPR Template 35 - -
TBar Template 41 7 48
CURE NMT 43 - -
RewardRepair NMT 45 24 69
Recoder NMT 51 10 61
AlphaRepair LLM 52 34 86
Repilot LLM 66 50 116

RepilotRewardRepairAlphaRepairRecoderCURE
87RepilotRewardRepairAlphaRepairRecoderOthers
a) với baseline LLM và NMT tốt nhất b) với tất cả công cụ APR

Hình 6: Biểu đồ Venn sửa chữa đúng trên Defects4J 1.2

tất cả các công cụ APR trước đó. Hình 6a cho thấy biểu đồ Venn của các lỗi duy nhất được sửa cho các công cụ APR dựa trên LLM và NMT hiệu suất hàng đầu trong đó Repilot có thể đạt được số lượng cao nhất 8 lỗi duy nhất. Hơn nữa, Hình 6b so sánh các lỗi duy nhất được sửa cho tất cả các baseline hiệu suất hàng đầu và với tất cả các công cụ APR khác được kết hợp (Others). Chúng tôi quan sát thấy rằng Repilot có thể sửa 7 lỗi mà không có baseline nào khác có thể sửa được cho đến nay.

Để chứng minh khả năng của Repilot trong việc sửa các lỗi khó, Hình 7 cho thấy một lỗi duy nhất (Closure-133) từ Defects4J 1.2 mà chỉ Repilot có thể sửa. Lỗi này được sửa bằng cách thêm câu lệnh gán mới sử dụng biến toàn cục NO_UNREAD_TOKEN khó tạo ra vì nó không xuất hiện trong ngữ cảnh xung quanh của vị trí lỗi. Repilot đầu tiên sử dụng CodeT5 để tạo ra tiền tố ban đầu của unread. Sau đó sử dụng Công cụ Hoàn thiện, Repilot nhận ra rằng Token là sự tiếp tục đúng ngữ nghĩa duy nhất và trực tiếp thực hiện hoàn thiện tích cực để trả về unreadToken. Tương tự đối với việc tạo ra NO_UNREAD_TOKEN, Repilot đầu tiên tạo ra NO_ và sau đó sử dụng hoàn thiện tích cực để trực tiếp tạo ra định danh hiếm này mà không cần lặp đi lặp lại lấy mẫu LLM. Khó để các công cụ APR dựa trên LLM và NMT trước đây tạo ra bản sửa này vì LLM hoặc mô hình NMT có thể không thể hoàn thiện định danh hiếm này vì nó yêu cầu nhiều bước liên tục để tạo ra. Ngược lại, Repilot, thông qua việc sử dụng hoàn thiện tích cực, có thể trực tiếp tạo ra định danh hiếm này chỉ với tiền tố định danh ban đầu để nhanh chóng đạt được bản vá đúng này.

private String getRemainingJSDocLine() {            
String result = stream. getRemainingJSDocLine ();            
unreadToken = NO_UNREAD_TOKEN;            
return result;            
}

unreadToken = NO_UNREAD_TOKEN; +

Bug-ID: Closure-133 
Quá trình Tạo Bản vá LLM Công cụ Hoàn thiện 

Hình 7: Sửa lỗi duy nhất bởi Repilot trên Defects4J 1.2

Defects4J 2.0. Chúng tôi tiếp tục đánh giá Repilot với các baseline được đánh giá trên các lỗi single-line trong Defects4J 2.0. Đối với các lỗi này, chúng tôi theo phương pháp trước đó cho APR kiểu cloze [67] để sử dụng các mẫu sửa chữa. Thay vì thay thế toàn bộ dòng lỗi bằng mã được tạo ra bởi mô hình, các mẫu này một cách có hệ thống giữ các phần của dòng lỗi (ví dụ: tiền tố hoặc hậu tố, tham số phương thức và cuộc gọi) để giảm lượng mã mà LLM cần tạo ra. Chúng tôi áp dụng các mẫu sửa chữa này chỉ cho các lỗi single-line Defects4J 2.0 vì chúng được thiết kế cho các lỗi single-line. Bảng 1 cũng cho thấy số lượng sửa chữa đúng trên Defects4J 2.0 so với các baseline. Chúng tôi quan sát thấy rằng Repilot có thể sửa số lượng lỗi cao nhất 50 (nhiều hơn 16 so với baseline tốt nhất tiếp theo) trên Defects4J 2.0. Sự cải thiện này so với các baseline hiện có cho thấy rằng Repilot có thể tổng quát hóa cho hai phiên bản của bộ dữ liệu Defects4J và chứng minh sức mạnh của các mẫu sửa chữa để tăng cường hiệu suất của các công cụ APR dựa trên LLM.

Hình 8 cho thấy một lỗi duy nhất từ Defects4J 2.0 mà chỉ Repilot có thể sửa. Đầu tiên, Repilot tạo ra bản vá đến vị trí caret. Công cụ Hoàn thiện sau đó nắm bắt kiểu chính xác của đối tượng từ Token.EndTag toString. Sử dụng thông tin này, Repilot đúng cách loại bỏ các token không phải là một phần của lớp String (ví dụ: name và text). Do đó, bản vá được tạo ra chứa một phương thức lớp String hợp lệ của toLowerCase() sửa đúng lỗi này. Tương tự như bản sửa lỗi duy nhất trước đó trong Defects4J 1.2, các công cụ APR dựa trên LLM trước đây có thể lãng phí nhiều thời gian tạo ra các tiếp tục không đúng ngữ nghĩa vì chúng không có quyền truy cập vào thông tin kiểu. Hơn nữa, các công cụ APR dựa trên NMT như CURE [29], xấp xỉ quá mức danh sách các định danh hợp lệ bằng cách tĩnh lấy tất cả các trường có thể truy cập, có thể không tạo ra bản sửa này vì một định danh bị loại bỏ (ví dụ: name) cũng có thể hợp lệ cho một kiểu đối tượng khác. Repilot sử dụng Công cụ Hoàn thiện để phân tích các chương trình một phần và nhận ra việc truyền kiểu phức tạp để loại bỏ hiệu quả.

private void popStackToClose(Token.EndTag endTag) { 
String elName = endTag.name(); 
String elName = endTag.name().toLowerCase(); 
Element firstFound = null ;+

Bug-ID: Jsoup-77 
Quá trình Tạo Bản vá -

String elName = endTag.name(). text        
name 
...        
toLower      
Type: Token.EndTag Type: String 
✓
✕
✕

Công cụ Hoàn thiện 

Hình 8: Sửa lỗi duy nhất bởi Repilot trên Defects4J 2.0

Bảng 2: So sánh với các công cụ APR hiện có về tỷ lệ biên dịch trên Defects4J 1.2. "-" biểu thị dữ liệu không có sẵn.

Công cụ % Bản vá Có thể Biên dịch
Top-30 Top-100 Top-1000 Top-5000
SequenceR 33% - - -
CoCoNuT 24% 15% 6% 3%
CURE 39% 28% 14% 9%
AlphaRepair 25% 22% 16% 13%
RewardRepair 45% 38% 33%1-
Repilot 66% 62% 58% 59%

1Đây là tỷ lệ top 200 cho RewardRepair vì nó không bao gồm top 1000

6.2 RQ2: Phân tích Tỷ lệ Biên dịch
Chúng tôi đánh giá tỷ lệ biên dịch của các bản vá được tạo ra bởi Repilot so với các kỹ thuật APR dựa trên học trước đây. Bảng 2 cho thấy tỷ lệ phần trăm của các bản vá có thể biên dịch trên bộ dữ liệu Defects4J 1.2. Chúng tôi quan sát thấy rằng trên tất cả số lượng bản vá được tạo ra, Repilot cải thiện đáng kể tỷ lệ phần trăm của các bản vá có thể biên dịch so với các công cụ trước đây. Chúng tôi đầu tiên nhận thấy rằng các công cụ APR dựa trên LLM (Repilot và AlphaRepair), có thể duy trì tỷ lệ biên dịch của chúng so với các công cụ dựa trên NMT (CoCoNuT và CURE) nơi tỷ lệ biên dịch giảm mạnh khi chúng tôi tăng số lượng bản vá. Điều này cho thấy khả năng của LLM để tạo ra lượng lớn các bản vá hợp lý. Repilot có thể duy trì tỷ lệ biên dịch gần 60% ở 1000 bản vá được tạo ra trong khi phương pháp trước đó chỉ hơn 30% một chút.

So với CURE [29], nơi một ước lượng quá mức của các định danh hợp lệ được thu thập thông qua phân tích tĩnh và được sử dụng để loại bỏ các token không hợp lệ được tạo ra bởi mô hình NMT, Repilot tận dụng Công cụ Hoàn thiện mạnh mẽ để theo dõi ngữ cảnh hiện tại để có được một bước loại bỏ chính xác hơn. Hơn nữa, so với RewardRepair [72], nơi tỷ lệ biên dịch được tăng cường thông qua việc phạt các bản vá không thể biên dịch trong quá trình huấn luyện, Repilot trực tiếp sử dụng một LLM kết hợp với một Công cụ Hoàn thiện để tránh chi phí cao này của việc huấn luyện một mô hình mới. Ngoài ra, Repilot sử dụng khả năng hoàn thiện tích cực của Công cụ Hoàn thiện để trực tiếp tạo ra các định danh hiếm này để tiếp tục tăng cường tỷ lệ biên dịch. Do đó, Repilot có thể đạt được tỷ lệ phần trăm cao nhất của các bản vá có thể biên dịch trên tất cả bốn cài đặt khác nhau.

6.3 RQ3: Nghiên cứu Ablation
Để nghiên cứu đóng góp của mỗi thành phần của Repilot đối với hiệu quả tổng thể của nó, chúng tôi tiến hành một nghiên cứu ablation nhằm mục đích chứng minh các giả thuyết sau:

•Algorithm 2 (GuidedPrune) giúp LLM đạt được các bản vá hợp lệ (có thể biên dịch) hiệu quả hơn trên một không gian tìm kiếm được loại bỏ.
•Ghi nhớ (§4.3) giảm tần suất truy vấn Công cụ Hoàn thiện, do đó tăng tốc việc tổng hợp bản vá.
•Hoàn thiện tích cực cung cấp hướng dẫn tổng hợp thêm và giúp Repilot đạt được nhiều bản vá hợp lệ hơn một cách hiệu quả.
•Tỷ lệ hợp lý của các bản vá trở nên cao hơn cùng với tỷ lệ biên dịch.

Để đưa ra cơ sở cho các giả thuyết này, chúng tôi thiết lập bốn biến thể sau:

•Repilot∅ chỉ sử dụng LLM cơ bản (CodeT5) để tổng hợp bản vá.
•Repilot_p áp dụng loại bỏ được định nghĩa trong Algorithm 2.
•Repilot^m_p tận dụng ghi nhớ (§4.3) trên cơ sở loại bỏ.
•Repilot sử dụng hoàn thiện tích cực để hướng dẫn thêm.

và đánh giá chúng bằng cách so sánh chúng với hiệu quả của chúng trong việc tạo ra các bản vá có thể biên dịch, hợp lý, và đúng.

Bảng 3 cho thấy thời gian tạo (theo giây trên mỗi bản vá), đóng góp về tỷ lệ phần trăm của các bản vá có thể biên dịch và hợp lý trong tất cả các bản vá duy nhất được tạo ra, số lượng sửa chữa hợp lý, và số lượng sửa chữa đúng cho mỗi biến thể trong bốn biến thể trên các lỗi single-hunk Defects4J 1.2. Chúng tôi đầu tiên quan sát thấy rằng chỉ sử dụng LLM cơ bản cho APR (Repilot∅), chúng tôi đạt được tỷ lệ biên dịch thấp nhất ở 43.2%. Bằng cách thêm việc loại bỏ được cung cấp bởi Công cụ Hoàn thiện, chúng tôi có thể cải thiện đáng kể tỷ lệ biên dịch lên 60.7%, số lượng sửa chữa hợp lý từ 56 lên 62, và số lượng sửa chữa đúng từ 37 lên 41. Cải thiện bổ sung được thực hiện bằng cách thêm kỹ thuật hoàn thiện tích cực để đạt được Repilot đầy đủ với tỷ lệ biên dịch cao nhất ở 63.4%, tỷ lệ hợp lý 5.21%, số lượng sửa chữa hợp lý nhiều nhất ở 63, và sửa chữa đúng nhiều nhất ở 42.

Nhìn vào thời gian tạo bản vá, bắt đầu từ Repilot∅, việc thêm loại bỏ thông qua Công cụ Hoàn thiện phát sinh overhead hơn 25%. Tuy nhiên, điều này có thể được giảm đáng kể bằng cách sử dụng ghi nhớ (Repilot_p) để đạt được khoảng 10% overhead bằng cách tránh truy vấn Công cụ Hoàn thiện một khi chúng ta biết một định danh không hợp lệ. Hơn nữa, hoàn thiện tích cực có thể tiếp tục giảm overhead xuống 7% vì thay vì phải lấy mẫu LLM cho mỗi bước trong việc tạo, chúng ta có thể hoàn thiện tích cực một định danh.

Kết quả là, tất cả các thành phần đóng góp vào hiệu quả tổng thể của Repilot. Repilot có thể liên tục tăng tỷ lệ biên dịch và hợp lý, cũng như tạo ra nhiều sửa chữa hợp lý/đúng hơn trong khi phát sinh overhead tối thiểu so với việc trực tiếp sử dụng LLM để tổng hợp bản vá.

Bảng 3: Đóng góp thành phần của Repilot

Biến thể Thời gian Tạo %Bản vá Có thể Biên dịch %Bản vá Hợp lý #Sửa chữa Hợp lý #Sửa chữa Đúng
Repilot∅ 0.232s 43.2% 3.95% 56 37
Repilot_p 0.294s 60.7% 5.02% 62 41
Repilot^m_p 0.255s 58.7% 4.82% 60 40
Repilot 0.248s 63.4% 5.21% 63 42

6.4 RQ4: Tính Tổng quát hóa
Để chứng minh tính tổng quát hóa của Repilot trên các chủ đề lỗi và mô hình khác nhau, một mặt, chúng tôi tiếp tục đánh giá Repilot với CodeT5 trên tất cả các lỗi single-hunk của Defects4J 2.0. Mặt khác, chúng tôi bổ sung khởi tạo và đánh giá Repilot với một mô hình InCoder-6.7B lớn hơn. Giống hệt như RQ3, chúng tôi cũng tiến hành 500 mẫu trong RQ4 do chi phí cao của APR.

Bảng 4 cho thấy so sánh giữa baseline Repilot∅ và phương pháp Repilot đầy đủ của chúng tôi trên các chủ đề lỗi và mô hình khác nhau. Chúng tôi xem xét cùng một tập các lỗi single-hunk Defects4J 1.2 như trong RQ3 và một tập bổ sung các lỗi single-hunk Defects4J 2.0.

Sau khi điều tra, chúng tôi có thể thấy rằng Repilot với CodeT5 vượt trội hơn baseline trên Defects4J 1.2 như được minh họa trong RQ3. Hơn nữa, trên Defects4J 2.0, nó cũng có thể đạt được 18.1 điểm phần trăm (pp) nhiều hơn có thể biên dịch và 3.0 pp nhiều hơn bản vá hợp lý, cũng như 6 sửa chữa hợp lý và 4 sửa chữa đúng nhiều hơn, với overhead 7.4%.

Trong khi đó, khi Repilot được khởi tạo với InCoder, nó vẫn tạo ra nhiều bản vá có thể biên dịch và hợp lý hơn, cũng như nhiều sửa chữa hợp lý và đúng hơn trên cả Defects4J 1.2 và Defects4J 2.0 so với baseline InCoder. Cuối cùng nó đưa ra 6 sửa chữa đúng nhiều hơn trên Defects4J 1.2 và 1 nhiều hơn trên Defects4J 2.0.

Một sự khác biệt lớn so sánh Repilot với InCoder và CodeT5 là khi Repilot được trang bị InCoder, một mô hình lớn hơn nhiều so với CodeT5, nó phát sinh overhead không đáng kể. Điều này là do so với chi phí cao của việc lấy mẫu tự hồi quy sử dụng các mô hình lớn hơn, chi phí bổ sung từ việc truy vấn Công cụ Hoàn thiện nhỏ hơn nhiều và do đó làm tầm thường hóa overhead của Repilot khi được áp dụng trên các mô hình lớn hơn. Ngoài ra, mô hình InCoder lớn hơn, cho dù nó có được áp dụng với Repilot hay không, có thể liên tục sửa nhiều lỗi hơn trên cả Defects4J 1.2 và 2.0 so với CodeT5, tiếp tục xác nhận phát hiện trước đó rằng các LLM lớn hơn thường hoạt động tốt hơn cho APR [66].

Nhìn chung, kết quả thực nghiệm cho thấy rằng Repilot có thể tổng quát hóa cho các tập lỗi khác nhau (cả lỗi single-hunk trong Defects4J 1.2 và 2.0) cũng như các LLM lớn hơn (InCoder)

Bảng 4: Tính tổng quát hóa của Repilot trên cả chủ đề lỗi và mô hình

Biến thể Mô hình Chủ đề Lỗi Thời gian Tạo %Bản vá Có thể Biên dịch %Bản vá Hợp lý #Sửa chữa Hợp lý #Sửa chữa Đúng
Repilot∅ CodeT5-large Defects4J 1.2 0.232s 43.2% 3.95% 56 37
Repilot CodeT5-large Defects4J 1.2 0.248s 63.4% 5.21% 63 42
Repilot∅ CodeT5-large Defects4J 2.0 0.230s 46.7% 9.02% 59 41
Repilot CodeT5-large Defects4J 2.0 0.247s 64.8% 12.02% 65 45
Repilot∅ InCoder-6.7B Defects4J 1.2 1.70s 32.4% 3.85% 70 48
Repilot InCoder-6.7B Defects4J 1.2 1.70s 47.2% 4.96% 78 54
Repilot∅ InCoder-6.7B Defects4J 2.0 1.67s 34.6% 5.06% 67 45
Repilot InCoder-6.7B Defects4J 2.0 1.69s 48.0% 6.87% 68 46

7 HẠN CHẾ

Đầu tiên, để phát huy toàn bộ tiềm năng của Repilot, điều quan trọng là Công cụ Hoàn thiện có thể cung cấp hướng dẫn hữu ích trong khi vẫn nghiêm ngặt (Định nghĩa 3.4). Tuy nhiên, nói chung khó khăn hơn để cân bằng tính hữu ích và nghiêm ngặt của một Công cụ Hoàn thiện trong nhiều ngôn ngữ lập trình kiểu động, như Python, so với Java được nghiên cứu trong bài báo này, là một ngôn ngữ lập trình kiểu tĩnh. Trong khi đó, có một xu hướng ngày càng tăng của các ngôn ngữ kiểu động áp dụng hỗ trợ cho type hints [12,49,54]. Xem xét điều này, chúng tôi tin rằng Repilot vẫn có thể cung cấp lợi thế đáng kể trong các môi trường như vậy.

Một hạn chế khác của Repilot nằm trong đánh giá. Một mặt, mặc dù đúng là sự tăng lên trong tỷ lệ biên dịch của

Repilot có thể dẫn đến việc khám phá nhiều sửa chữa hợp lý và đúng hơn, điều quan trọng cần lưu ý là tỷ lệ biên dịch cao đáng kể không nhất thiết chuyển thành sự tăng lên tỷ lệ thuận lớn trong các sửa chữa hợp lý và đúng. Mặt khác, Repilot chỉ được đánh giá với CodeT5 cho RQ1 và RQ2 với ngân sách lấy mẫu 5000. CodeT5 là một LLM khá "nhỏ" so với những LLM có hàng tỷ tham số. Mặc dù chúng tôi tiếp tục bao gồm InCoder-6.7B như một LLM hàng tỷ tham số trong RQ4, do chi phí thời gian, chúng tôi chỉ lấy mẫu 500 lần mỗi lỗi, có thể không đủ để phản ánh phân phối của các bản vá được tạo ra. Nhìn chung, phạm vi đánh giá của chúng tôi xem xét hai LLM (CodeT5 và InCoder) và một ngôn ngữ lập trình (Java) vẫn hẹp cho rằng Repilot là một khung tổng quát có thể được khởi tạo với bất kỳ cặp LLM và Công cụ Hoàn thiện nào cho một ngôn ngữ lập trình nào đó.

Cuối cùng, bất chấp các ví dụ chúng tôi hiển thị trong bài báo, đánh giá của chúng tôi thiếu bằng chứng thực nghiệm mạnh mẽ để hỗ trợ tuyên bố rằng LLM gặp khó khăn trong việc tạo ra các token hiếm và cách Repilot giải quyết vấn đề. Bên cạnh đó, đánh giá của chúng tôi giới hạn ứng dụng của Repilot đối với việc tổng hợp bản vá, mặc dù chúng tôi tuyên bố rằng Repilot có thể được áp dụng cho các tác vụ tạo mã khác. Trong tương lai, chúng tôi sẽ áp dụng và đánh giá Repilot trên các tác vụ tạo mã đa dạng hơn.

8 MỐI ĐE DỌA ĐỐI VỚI TÍNH HỢP LỆ

Nội bộ. Chúng tôi chia sẻ cùng mối đe dọa chính về tính hợp lệ nội bộ với các công cụ APR trước đây nơi chúng tôi phải kiểm tra thủ công từng bản vá hợp lý để xác định tính đúng đắn của bản vá. Chúng tôi giải quyết điều này bằng cách phân tích cẩn thận từng bản vá để xác định xem nó có tương đương ngữ nghĩa với bản vá nhà phát triển tham chiếu hay không. Hơn nữa, chúng tôi đã phát hành tập đầy đủ các bản vá đúng của chúng tôi để đánh giá công khai [62].

Việc sử dụng mô hình CodeT5 của chúng tôi tạo ra một mối đe dọa nội bộ khác nơi bộ dữ liệu huấn luyện mã nguồn mở của các dự án GitHub [27] có thể trùng lặp với đánh giá của chúng tôi về Defects4J. Chúng tôi theo các công trình trước [66,67] và giải quyết điều này bằng cách tính toán các sửa lỗi đúng của Repilot từ Defects4J là một phần của dữ liệu huấn luyện CodeT5. Tổng cộng, 7 trong số 66 và 6 trong số 50 trùng lặp với dữ liệu huấn luyện trên Defects4J 1.2 và 2.0 tương ứng. Để so sánh công bằng, nếu chúng tôi loại trừ 7 và 6 lỗi này và so sánh chúng với các công cụ baseline trước đây trên các lỗi còn lại, chúng tôi vẫn có thể đạt được sửa lỗi cao nhất ở 59 và 44 (baseline tốt nhất ở 45 và 29). Cùng mối đe dọa áp dụng cho việc sử dụng InCoder, nhưng vì dữ liệu huấn luyện chi tiết của nó không được tiết lộ, chúng tôi không thể giải quyết rõ ràng vấn đề này. Để giảm thiểu vấn đề, chúng tôi chỉ đánh giá InCoder trong RQ4, nơi tất cả các biến thể đối mặt với cùng rò rỉ tiềm năng.

Hơn nữa, việc triển khai đã sửa đổi của chúng tôi về completion engine yêu cầu kiểm tra thủ công để đảm bảo thuộc tính tính đúng đắn. Trong thực tế, đây là một cơ sở tin cậy đáng kể có thể gây ra false positive trong quá trình loại bỏ. Tuy nhiên, định lý của chúng tôi vẫn cung cấp một đảm bảo một phần và có thể giải thích tính không đúng đắn. Đồng thời, kết quả đánh giá của chúng tôi chứng minh các tuyên bố của chúng tôi và chứng minh tính thực tiễn của Repilot.

Cuối cùng, trong đánh giá của chúng tôi, chúng tôi theo quy ước được sử dụng trong các công trình trước để trực tiếp báo cáo kết quả sửa lỗi mà không tái tạo chúng, điều này tạo ra mối đe dọa đối với độ tin cậy của kết quả. Trong khi đó, chúng tôi chỉ chạy mỗi thí nghiệm của chúng tôi một lần, có thể gây ra thêm thiên lệch thống kê.

Ngoại bộ. Mối đe dọa chính về tính hợp lệ ngoại bộ đến từ bộ dữ liệu đánh giá của chúng tôi nơi hiệu suất của Repilot có thể không tổng quát hóa cho các bộ dữ liệu khác. Để giải quyết điều này, chúng tôi so sánh Repilot với các baseline tiên tiến trên cả Defects4J 1.2 và 2.0 để cho thấy rằng hiệu suất được duy trì trên cả hai phiên bản. Để giải quyết điều này thêm nữa, chúng tôi dự định đánh giá Repilot trên các bộ dữ liệu APR bổ sung cũng trên các ngôn ngữ lập trình khác nhau.

9 KẾT LUẬN

Chúng tôi đề xuất Repilot — phương pháp APR đầu tiên kết hợp việc sử dụng trực tiếp LLM (ví dụ: CodeT5 và InCoder) với hướng dẫn linh hoạt được cung cấp bởi Công cụ Hoàn thiện. Trong quá trình tạo token tự hồi quy, Repilot truy vấn Công cụ Hoàn thiện không chỉ để loại bỏ các token không hợp lệ mà còn để chủ động hoàn thiện chương trình một phần hiện tại được tạo ra, do đó giảm không gian tìm kiếm của LLM. Đánh giá của chúng tôi trên một tập con của bộ dữ liệu Defects4J 1.2 và 2.0 được nghiên cứu rộng rãi cho thấy Repilot có thể đạt được kết quả tiên tiến. Hơn nữa, Repilot, thông qua việc sử dụng Công cụ Hoàn thiện, có thể tạo ra nhiều bản vá hợp lệ và có thể biên dịch hơn so với các công cụ trước đây với overhead tối thiểu so với việc trực tiếp sử dụng LLM cho APR.

KHẢ NĂNG TIẾP CẬN DỮ LIỆU

Chúng tôi đã mở nguồn Repilot, có thể được truy cập trên GitHub tại https://github.com/ise-uiuc/Repilot. Ngoài ra, một artifact bất biến cho Repilot có sẵn công khai trên Zenodo [62].

LỜI CẢM ơN

Chúng tôi cảm ơn tất cả các reviewer vì những bình luận sâu sắc của họ. Chúng tôi cũng cảm ơn Yifeng Ding vì cuộc thảo luận hữu ích của anh ấy về công trình này. Công trình này được hỗ trợ một phần bởi các grant NSF CCF-2131943 và CCF-2141474, cũng như Kwai Inc.

--- TRANG 12 ---
ESEC/FSE '23, December 3–9, 2023, San Francisco, CA, USA Yuxiang Wei, Chunqiu Steven Xia, and Lingming Zhang

TÀI LIỆU THAM KHẢO
[1] 2023. Eclipse JDT LS. https://projects.eclipse.org/projects/eclipse.jdt.ls.
[2] Armen Aghajanyan, Bernie Huang, Candace Ross, Vladimir Karpukhin, Hu Xu, Naman Goyal, Dmytro Okhonko, Mandar Joshi, Gargi Ghosh, Mike Lewis, và Luke Zettlemoyer. 2022. CM3: A Causal Masked Multimodal Model of the Internet. CoRR abs/2201.07520 (2022). arXiv:2201.07520 https://arxiv.org/abs/2201.07520
[3]Wasi Uddin Ahmad, Saikat Chakraborty, Baishakhi Ray, và Kai-Wei Chang. 2021. Unified Pre-training for Program Understanding and Generation. arXiv:2103.06333 [cs.CL]
[4]Jacob Austin, Augustus Odena, Maxwell I. Nye, Maarten Bosma, Henryk Michalewski, David Dohan, Ellen Jiang, Carrie J. Cai, Michael Terry, Quoc V. Le, và Charles Sutton. 2021. Program Synthesis with Large Language Models. CoRR abs/2108.07732 (2021). arXiv:2108.07732 https://arxiv.org/abs/2108.07732
[5]Shraddha Barke, Michael B. James, và Nadia Polikarpova. 2023. Grounded Copilot: How Programmers Interact with Code-Generating Models. Proc. ACM Program. Lang. 7, OOPSLA1, Article 78 (apr 2023), 27 trang. https://doi.org/10.1145/3586030
[6]Earl T. Barr, Yuriy Brun, Premkumar Devanbu, Mark Harman, và Federica Sarro. 2014. The Plastic Surgery Hypothesis. Trong Proceedings of the 22nd ACM SIGSOFT International Symposium on Foundations of Software Engineering (Hong Kong, China) (FSE 2014). Association for Computing Machinery, New York, NY, USA, 306–317. https://doi.org/10.1145/2635868.2635898
[7]Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, và Dario Amodei. 2020. Language Models are Few-Shot Learners. CoRR abs/2005.14165 (2020). arXiv:2005.14165 https://arxiv.org/abs/2005.14165
[8]Jialun Cao, Meiziniu Li, Ming Wen, và Shing-Chi Cheung. 2023. A study on Prompt Design, Advantages and Limitations of ChatGPT for Deep Learning Program Repair. CoRR abs/2304.08191 (2023). https://doi.org/10.48550/ARXIV.2304.08191 arXiv:2304.08191
[9]Liushan Chen, Yu Pei, và Carlo A. Furia. 2017. Contract-based program repair without the contracts. Trong 2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE). 637–647. https://doi.org/10.1109/ASE.2017.8115674
[10] Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, Alex Ray, Raul Puri, Gretchen Krueger, Michael Petrov, Heidy Khlaaf, Girish Sastry, Pamela Mishkin, Brooke Chan, Scott Gray, Nick Ryder, Mikhail Pavlov, Alethea Power, Lukasz Kaiser, Mohammad Bavarian, Clemens Winter, Philippe Tillet, Felipe Petroski Such, Dave Cummings, Matthias Plappert, Fotios Chantzis, Elizabeth Barnes, Ariel Herbert-Voss, William Hebgen Guss, Alex Nichol, Alex Paino, Nikolas Tezak, Jie Tang, Igor Babuschkin, Suchir Balaji, Shantanu Jain, William Saunders, Christopher Hesse, Andrew N. Carr, Jan Leike, Josh Achiam, Vedant Misra, Evan Morikawa, Alec Radford, Matthew Knight, Miles Brundage, Mira Murati, Katie Mayer, Peter Welinder, Bob McGrew, Dario Amodei, Sam McCandlish, Ilya Sutskever, và Wojciech Zaremba. 2021. Evaluating Large Language Models Trained on Code. arXiv:2107.03374 [cs.LG]
[11] Zimin Chen, Steve Kommrusch, Michele Tufano, Louis-Noël Pouchet, Denys Poshyvanyk, và Martin Monperrus. 2021. SequenceR: Sequence-to-Sequence Learning for End-to-End Program Repair. IEEE Transactions on Software Engineering 47, 9 (2021), 1943–1959. https://doi.org/10.1109/TSE.2019.2940179
[12] Clojure 2023. Typed Clojure: An Optional Type System for Clojure. https://typedclojure.org.
[13] Favio DeMarco, Jifeng Xuan, Daniel Le Berre, và Martin Monperrus. 2014. Automatic Repair of Buggy If Conditions and Missing Preconditions with SMT. Trong Proceedings of the 6th International Workshop on Constraints in Software Testing, Verification, and Analysis (Hyderabad, India) (CSTVA 2014). Association for Computing Machinery, New York, NY, USA, 30–39. https://doi.org/10.1145/2593735.2593740
[14] Yinlin Deng, Chunqiu Steven Xia, Haoran Peng, Chenyuan Yang, và Lingming Zhang. 2023. Large Language Models Are Zero-Shot Fuzzers: Fuzzing Deep-Learning Libraries via Large Language Models. Trong Proceedings of the 32nd ACM SIGSOFT International Symposium on Software Testing and Analysis (Seattle, WA, USA) (ISSTA 2023). Association for Computing Machinery, New York, NY, USA, 423–435. https://doi.org/10.1145/3597926.3598067
[15] Jacob Devlin, Ming-Wei Chang, Kenton Lee, và Kristina Toutanova. 2019. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. Trong Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers). Association for Computational Linguistics, Minneapolis, Minnesota, 4171–4186. https://doi.org/10.18653/v1/N19-1423
[16] Yangruibo Ding, Zijian Wang, Wasi Uddin Ahmad, Hantian Ding, Ming Tan, Nihal Jain, Murali Krishna Ramanathan, Ramesh Nallapati, Parminder Bhatia, Dan Roth, và Bing Xiang. 2023. CrossCodeEval: A Diverse and Multilingual Benchmark for Cross-File Code Completion. arXiv:2310.11248 [cs.LG]
[17] Zhangyin Feng, Daya Guo, Duyu Tang, Nan Duan, Xiaocheng Feng, Ming Gong, Linjun Shou, Bing Qin, Ting Liu, Daxin Jiang, và Ming Zhou. 2020. CodeBERT: A Pre-Trained Model for Programming and Natural Languages. CoRR abs/2002.08155. arXiv:2002.08155 https://arxiv.org/abs/2002.08155
[18] Eclipse Foundation và Yuxiang Wei. 2023. UniverseFly/eclipse.jdt.ls: Modified Eclipse JDT LS 1.0.3. https://doi.org/10.5281/zenodo.8278193
[19] Daniel Fried, Armen Aghajanyan, Jessy Lin, Sida Wang, Eric Wallace, Freda Shi, Ruiqi Zhong, Scott Yih, Luke Zettlemoyer, và Mike Lewis. 2023. InCoder: A Generative Model for Code Infilling and Synthesis. Trong The Eleventh International Conference on Learning Representations. https://openreview.net/forum?id=hQwb-lbM6EL
[20] Luca Gazzola, Daniela Micucci, và Leonardo Mariani. 2019. Automatic Software Repair: A Survey. IEEE Transactions on Software Engineering 45, 1 (2019), 34–67. https://doi.org/10.1109/TSE.2017.2755013
[21] Ali Ghanbari, Samuel Benton, và Lingming Zhang. 2019. Practical Program Repair via Bytecode Mutation. Trong Proceedings of the 28th ACM SIGSOFT International Symposium on Software Testing and Analysis (Beijing, China) (ISSTA 2019). Association for Computing Machinery, New York, NY, USA, 19–30. https://doi.org/10.1145/3293882.3330559
[22] GithubCopilot 2023. GitHub Copilot: Your AI pair programmer. https://github.com/features/copilot.
[23] Daya Guo, Shuo Ren, Shuai Lu, Zhangyin Feng, Duyu Tang, Shujie LIU, Long Zhou, Nan Duan, Alexey Svyatkovskiy, Shengyu Fu, Michele Tufano, Shao Kun Deng, Colin Clement, Dawn Drain, Neel Sundaresan, Jian Yin, Daxin Jiang, và Ming Zhou. 2021. GraphCodeBERT: Pre-training Code Representations with Data Flow. Trong International Conference on Learning Representations. https://openreview.net/forum?id=jLoC4ez43PZ
[24] Ari Holtzman, Jan Buys, Li Du, Maxwell Forbes, và Yejin Choi. 2020. The Curious Case of Neural Text Degeneration. Trong International Conference on Learning Representations. https://openreview.net/forum?id=rygGQyrFvH
[25] Jinru Hua, Mengshi Zhang, Kaiyuan Wang, và Sarfraz Khurshid. 2018. SketchFix: A Tool for Automated Program Repair Approach Using Lazy Candidate Generation. Trong Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering (Lake Buena Vista, FL, USA) (ESEC/FSE 2018). Association for Computing Machinery, New York, NY, USA, 888–891. https://doi.org/10.1145/3236024.3264600
[26] HuggingFace 2023. Hugging Face. https://huggingface.co.
[27] Hamel Husain, Ho-Hsiang Wu, Tiferet Gazit, Miltiadis Allamanis, và Marc Brockschmidt. 2019. CodeSearchNet Challenge: Evaluating the State of Semantic Code Search. CoRR abs/1909.09436 (2019). arXiv:1909.09436 http://arxiv.org/abs/1909.09436
[28] Jiajun Jiang, Yingfei Xiong, Hongyu Zhang, Qing Gao, và Xiangqun Chen. 2018. Shaping Program Repair Space with Existing Patches and Similar Code. Trong ISSTA 2018 (Amsterdam, Netherlands). Association for Computing Machinery, New York, NY, USA, 298–309. https://doi.org/10.1145/3213846.3213871
[29] Nan Jiang, Thibaud Lutellier, và Lin Tan. 2021. CURE: Code-Aware Neural Machine Translation for Automatic Program Repair. Trong Proceedings of the 43rd International Conference on Software Engineering (Madrid, Spain) (ICSE '21). IEEE Press, 1161–1173. https://doi.org/10.1109/ICSE43902.2021.00107
[30] Yanjie Jiang, Hui Liu, Nan Niu, Lu Zhang, và Yamin Hu. 2021. Extracting Concise Bug-Fixing Patches from Human-Written Patches in Version Control Systems. Trong Proceedings of the 43rd International Conference on Software Engineering (Madrid, Spain) (ICSE '21). IEEE Press, 686–698. https://doi.org/10.1109/ICSE43902.2021.00069
[31] Harshit Joshi, José Cambronero, Sumit Gulwani, Vu Le, Ivan Radicek, và Gust Verbruggen. 2023. Repair Is Nearly Generation: Multilingual Program Repair with LLMs. AAAI. https://www.microsoft.com/en-us/research/publication/repair-is-nearly-generation-multilingual-program-repair-with-llms/
[32] René Just, Darioush Jalali, và Michael D. Ernst. 2014. Defects4J: A Database of Existing Faults to Enable Controlled Testing Studies for Java Programs. Trong Proceedings of the 2014 International Symposium on Software Testing and Analysis (San Jose, CA, USA) (ISSTA 2014). Association for Computing Machinery, New York, NY, USA, 437–440. https://doi.org/10.1145/2610384.2628055
[33] Sophia D Kolak, Ruben Martins, Claire Le Goues, và Vincent Josua Hellendoorn. 2022. Patch Generation with Language Models: Feasibility and Scaling Behavior. Trong Deep Learning for Code Workshop. https://openreview.net/forum?id=rHlzJh_b1-5
[34] Anil Koyuncu, Kui Liu, Tegawendé F. Bissyandé, Dongsun Kim, Jacques Klein, Martin Monperrus, và Yves Le Traon. 2020. FixMiner: Mining Relevant Fix Patterns for Automated Program Repair. Empirical Softw. Engg. 25, 3 (may 2020), 1980–2024. https://doi.org/10.1007/s10664-019-09780-z
[35] Xuan-Bach D. Le, Duc-Hiep Chu, David Lo, Claire Le Goues, và Willem Visser. 2017. S3: Syntax- and Semantic-Guided Repair Synthesis via Programming by Examples. Trong Proceedings of the 2017 11th Joint Meeting on Foundations of Software Engineering (Paderborn, Germany) (ESEC/FSE 2017). Association for Computing Machinery, New York, NY, USA, 593–604. https://doi.org/10.1145/3106237.3106309

--- TRANG 13 ---
Copiloting the Copilots: Fusing Large Language Models with Completion Engines for Automated Program Repair ESEC/FSE '23, December 3–9, 2023, San Francisco, CA, USA

[36] Xuan Bach D. Le, David Lo, và Claire Le Goues. 2016. History Driven Program Repair. Trong SANER (2016), Vol. 1. 213–224. https://doi.org/10.1109/SANER.2016.76
[37] Claire Le Goues, ThanhVu Nguyen, Stephanie Forrest, và Westley Weimer. 2012. GenProg: A Generic Method for Automatic Software Repair. IEEE Transactions on Software Engineering 38, 1 (2012), 54–72. https://doi.org/10.1109/TSE.2011.104
[38] Yujia Li, David Choi, Junyoung Chung, Nate Kushman, Julian Schrittwieser, Rémi Leblond, Tom Eccles, James Keeling, Felix Gimeno, Agustin Dal Lago, Thomas Hubert, Peter Choy, Cyprien de Masson d'Autume, Igor Babuschkin, Xinyun Chen, Po-Sen Huang, Johannes Welbl, Sven Gowal, Alexey Cherepanov, James Molloy, Daniel J. Mankowitz, Esme Sutherland Robson, Pushmeet Kohli, Nando de Freitas, Koray Kavukcuoglu, và Oriol Vinyals. 2022. Competition-level code generation with AlphaCode. Science 378, 6624 (2022), 1092–1097. https://doi.org/10.1126/science.abq1158 arXiv:https://www.science.org/doi/pdf/10.1126/science.abq1158
[39] Yi Li, Shaohua Wang, và Tien N. Nguyen. 2020. DLFix: Context-Based Code Transformation Learning for Automated Program Repair. Trong Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering (Seoul, South Korea) (ICSE '20). Association for Computing Machinery, New York, NY, USA, 602–614. https://doi.org/10.1145/3377811.3380345
[40] Jiawei Liu, Chunqiu Steven Xia, Yuyao Wang, và Lingming Zhang. 2023. Is Your Code Generated by ChatGPT Really Correct? Rigorous Evaluation of Large Language Models for Code Generation. arXiv:2305.01210 [cs.SE]
[41] Kui Liu, Anil Koyuncu, Dongsun Kim, và Tegawendé F. Bissyandé. 2019. TBar: Revisiting Template-Based Automated Program Repair. Trong Proceedings of the 28th ACM SIGSOFT International Symposium on Software Testing and Analysis (Beijing, China) (ISSTA 2019). Association for Computing Machinery, New York, NY, USA, 31–42. https://doi.org/10.1145/3293882.3330577
[42] Kui Liu, Jingtang Zhang, Li Li, Anil Koyuncu, Dongsun Kim, Chunpeng Ge, Zhe Liu, Jacques Klein, và Tegawendé F. Bissyandé. 2023. Reliable Fix Patterns Inferred from Static Checkers for Automated Program Repair. ACM Trans. Softw. Eng. Methodol. 32, 4, Article 96 (may 2023), 38 trang. https://doi.org/10.1145/3579637
[43] Fan Long và Martin Rinard. 2015. Staged Program Repair with Condition Synthesis. Trong Proceedings of the 2015 10th Joint Meeting on Foundations of Software Engineering (Bergamo, Italy) (ESEC/FSE 2015). Association for Computing Machinery, New York, NY, USA, 166–178. https://doi.org/10.1145/2786805.2786811
[44] Thibaud Lutellier, Hung Viet Pham, Lawrence Pang, Yitong Li, Moshi Wei, và Lin Tan. 2020. CoCoNuT: Combining Context-Aware Neural Translation Models Using Ensemble for Program Repair. Trong Proceedings of the 29th ACM SIGSOFT International Symposium on Software Testing and Analysis (Virtual Event, USA) (ISSTA 2020). Association for Computing Machinery, New York, NY, USA, 101–114. https://doi.org/10.1145/3395363.3397369
[45] Matias Martinez, Thomas Durieux, Romain Sommerard, Jifeng Xuan, và Martin Monperrus. 2017. Automatic Repair of Real Bugs in Java: A Large-Scale Experiment on the Defects4j Dataset. Empirical Softw. Engg. 22, 4 (aug 2017), 1936–1964. https://doi.org/10.1007/s10664-016-9470-4
[46] Matias Martinez và Martin Monperrus. 2016. ASTOR: A Program Repair Library for Java (Demo). Trong Proceedings of the 25th International Symposium on Software Testing and Analysis (Saarbrücken, Germany) (ISSTA 2016). Association for Computing Machinery, New York, NY, USA, 441–444. https://doi.org/10.1145/2931037.2948705
[47] Sergey Mechtaev, Jooyong Yi, và Abhik Roychoudhury. 2016. Angelix: Scalable Multiline Program Patch Synthesis via Symbolic Analysis. Trong Proceedings of the 38th International Conference on Software Engineering (Austin, Texas) (ICSE '16). Association for Computing Machinery, New York, NY, USA, 691–701. https://doi.org/10.1145/2884781.2884807
[48] Microsoft 2023. Language Server Protocol. https://microsoft.github.io/language-server-protocol.
[49] Microsoft 2023. TypeScript. https://www.typescriptlang.org.
[50] Erik Nijkamp, Hiroaki Hayashi, Caiming Xiong, Silvio Savarese, và Yingbo Zhou. 2023. CodeGen2: Lessons for Training LLMs on Programming and Natural Languages. arXiv:2305.02309 [cs.LG]
[51] Erik Nijkamp, Bo Pang, Hiroaki Hayashi, Lifu Tu, Huan Wang, Yingbo Zhou, Silvio Savarese, và Caiming Xiong. 2022. CodeGen: An Open Large Language Model for Code with Multi-Turn Program Synthesis. arXiv:2203.13474.
[52] Gabriel Poesia, Alex Polozov, Vu Le, Ashish Tiwari, Gustavo Soares, Christopher Meek, và Sumit Gulwani. 2022. Synchromesh: Reliable Code Generation from Pre-trained Language Models. Trong International Conference on Learning Representations. https://openreview.net/forum?id=KmtVD97J43e
[53] Julian Aron Prenner, Hlib Babii, và Romain Robbes. 2022. Can OpenAI's Codex Fix Bugs? An Evaluation on QuixBugs. Trong APR '22 (Pittsburgh, Pennsylvania). Association for Computing Machinery, New York, NY, USA, 69–75. https://doi.org/10.1145/3524459.3527351
[54] Python 2023. Type Hints in Python. https://peps.python.org/pep-0484/.
[55] Rico Sennrich, Barry Haddow, và Alexandra Birch. 2016. Neural Machine Translation of Rare Words with Subword Units. Trong Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). Association for Computational Linguistics, Berlin, Germany, 1715–1725. https://doi.org/10.18653/v1/P16-1162
[56] Dominik Sobania, Martin Briesch, Carol Hanna, và Justyna Petke. 2023. An Analysis of the Automatic Bug Fixing Performance of ChatGPT. arXiv:2301.08653 [cs.SE]
[57] Ilya Sutskever, Oriol Vinyals, và Quoc V Le. 2014. Sequence to Sequence Learning with Neural Networks. Trong Advances in Neural Information Processing Systems, Z. Ghahramani, M. Welling, C. Cortes, N. Lawrence, và K.Q. Weinberger (Eds.), Vol. 27. Curran Associates, Inc. https://proceedings.neurips.cc/paper_files/paper/2014/file/a14ac55a4f27472c5d894ec1c3c743d2-Paper.pdf
[58] Michele Tufano, Cody Watson, Gabriele Bavota, Massimiliano Di Penta, Martin White, và Denys Poshyvanyk. 2019. An Empirical Study on Learning Bug-Fixing Patches in the Wild via Neural Machine Translation. ACM Trans. Softw. Eng. Methodol. 28, 4, Article 19 (sep 2019), 29 trang. https://doi.org/10.1145/3340544
[59] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, và Illia Polosukhin. 2017. Attention is All You Need. Trong Proceedings of the 31st International Conference on Neural Information Processing Systems (Long Beach, California, USA) (NIPS'17). Curran Associates Inc., Red Hook, NY, USA, 6000–6010.
[60] Yue Wang, Hung Le, Akhilesh Deepak Gotmare, Nghi D. Q. Bui, Junnan Li, và Steven C. H. Hoi. 2023. CodeT5+: Open Code Large Language Models for Code Understanding and Generation. arXiv:2305.07922 [cs.CL]
[61] Yue Wang, Weishi Wang, Shafiq Joty, và Steven C.H. Hoi. 2021. CodeT5: Identifier-aware Unified Pre-trained Encoder-Decoder Models for Code Understanding and Generation. Trong Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics, Online and Punta Cana, Dominican Republic, 8696–8708. https://doi.org/10.18653/v1/2021.emnlp-main.685
[62] Yuxiang Wei, Chunqiu Steven Xia, và Lingming Zhang. 2023. ESEC/FSE'23 Artifact for "Copiloting the Copilots: Fusing Large Language Models with Completion Engines for Automated Program Repair". https://doi.org/10.5281/zenodo.8281250
[63] Ming Wen, Junjie Chen, Rongxin Wu, Dan Hao, và Shing-Chi Cheung. 2018. Context-Aware Patch Generation for Better Automated Program Repair. Trong Proceedings of the 40th International Conference on Software Engineering (Gothenburg, Sweden) (ICSE '18). Association for Computing Machinery, New York, NY, USA, 1–11. https://doi.org/10.1145/3180155.3180233
[64] Chunqiu Steven Xia, Yifeng Ding, và Lingming Zhang. 2023. Revisiting the Plastic Surgery Hypothesis via Large Language Models. arXiv:2303.10494 [cs.SE]
[65] Chunqiu Steven Xia, Matteo Paltenghi, Jia Le Tian, Michael Pradel, và Lingming Zhang. 2023. Universal Fuzzing via Large Language Models. arXiv:2308.04748 [cs.SE]
[66] Chunqiu Steven Xia, Yuxiang Wei, và Lingming Zhang. 2023. Automated Program Repair in the Era of Large Pre-Trained Language Models. Trong Proceedings of the 45th International Conference on Software Engineering (Melbourne, Victoria, Australia) (ICSE '23). IEEE Press, 1482–1494. https://doi.org/10.1109/ICSE48619.2023.00129
[67] Chunqiu Steven Xia và Lingming Zhang. 2022. Less Training, More Repairing Please: Revisiting Automated Program Repair via Zero-Shot Learning. Trong Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering (Singapore, Singapore) (ESEC/FSE 2022). Association for Computing Machinery, New York, NY, USA, 959–971. https://doi.org/10.1145/3540250.3549101
[68] Chunqiu Steven Xia và Lingming Zhang. 2023. Conversational Automated Program Repair. CoRR abs/2301.13246 (2023). https://doi.org/10.48550/ARXIV.2301.13246 arXiv:2301.13246
[69] Chunqiu Steven Xia và Lingming Zhang. 2023. Keep the Conversation Going: Fixing 162 out of 337 bugs for $0.42 each using ChatGPT. arXiv:2304.00385 [cs.SE]
[70] Frank F. Xu, Uri Alon, Graham Neubig, và Vincent Josua Hellendoorn. 2022. A Systematic Evaluation of Large Language Models of Code. Trong Proceedings of the 6th ACM SIGPLAN International Symposium on Machine Programming (San Diego, CA, USA) (MAPS 2022). Association for Computing Machinery, New York, NY, USA, 1–10. https://doi.org/10.1145/3520312.3534862
[71] Zhilin Yang, Zihang Dai, Yiming Yang, Jaime Carbonell, Ruslan Salakhutdinov, và Quoc V. Le. 2019. XLNet: Generalized Autoregressive Pretraining for Language Understanding. Curran Associates Inc., Red Hook, NY, USA.
[72] He Ye, Matias Martinez, và Martin Monperrus. 2022. Neural Program Repair with Execution-Based Backpropagation. Trong Proceedings of the 44th International Conference on Software Engineering (Pittsburgh, Pennsylvania) (ICSE '22). Association for Computing Machinery, New York, NY, USA, 1506–1518. https://doi.org/10.1145/3510003.3510222
[73] Fengji Zhang, Bei Chen, Yue Zhang, Jacky Keung, Jin Liu, Daoguang Zan, Yi Mao, Jian-Guang Lou, và Weizhu Chen. 2023. RepoCoder: Repository-Level Code Completion Through Iterative Retrieval and Generation. arXiv:2303.12570 [cs.CL]
[74] Qihao Zhu, Zeyu Sun, Yuan-an Xiao, Wenjie Zhang, Kang Yuan, Yingfei Xiong, và Lu Zhang. 2021. A Syntax-Guided Edit Decoder for Neural Program Repair. Trong ESEC/FSE 2021 (Athens, Greece). Association for Computing Machinery, New York, NY, USA, 341–353. https://doi.org/10.1145/3468264.3468544

Nhận ngày 2023-02-02; chấp nhận ngày 2023-07-27

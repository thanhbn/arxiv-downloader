# 2404.14662.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/coding/2404.14662.pdf
# Kích thước tệp: 1637298 byte

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
2024-4-24
NExT: Dạy các Mô hình Ngôn ngữ Lớn
Suy luận về Thực thi Mã
Ansong Ni1 2, Miltiadis Allamanis1, Arman Cohan2, Yinlin Deng1 3, Kensen Shi1, Charles Sutton1và
Pengcheng Yin1
1Google DeepMind,2Đại học Yale,3Đại học Illinois tại Urbana-Champaign
Một kỹ năng cơ bản của các nhà phát triển con người là khả năng hiểu và suy luận về việc thực thi chương trình. Ví dụ, một lập trình viên có thể mô phỏng tinh thần việc thực thi mã bằng ngôn ngữ tự nhiên để gỡ lỗi và sửa chữa mã (tức là gỡ lỗi vịt cao su). Tuy nhiên, các mô hình ngôn ngữ lớn (LLM) của mã thường được huấn luyện trên dạng văn bản bề mặt của chương trình, do đó có thể thiếu hiểu biết ngữ nghĩa về cách chương trình thực thi trong thời gian chạy. Để giải quyết vấn đề này, chúng tôi đề xuất NE xT, một phương pháp dạy LLM kiểm tra các dấu vết thực thi của chương trình (trạng thái biến của các dòng đã thực thi) và suy luận về hành vi thời gian chạy của chúng thông qua các lý luận chuỗi suy nghĩ (CoT). Cụ thể, NE xT sử dụng tự huấn luyện để khởi tạo một tập dữ liệu huấn luyện tổng hợp các lý luận nhận thức thực thi dẫn đến các giải pháp nhiệm vụ chính xác (ví dụ: chương trình đã sửa) mà không cần chú thích thủ công tốn công. Các thí nghiệm trên các nhiệm vụ sửa chữa chương trình dựa trên MbppvàHumanEval cho thấy NE xT cải thiện tỷ lệ sửa chữa của mô hình PaLM 2 lần lượt 26,1% và14,3%tuyệt đối, với chất lượng lý luận được cải thiện đáng kể được xác minh bởi các chỉ số tự động và người đánh giá con người. Mô hình của chúng tôi cũng có thể tổng quát hóa cho các tình huống mà dấu vết chương trình không có trong thời gian kiểm tra.
1. Giới thiệu
Những năm gần đây đã chứng kiến sự phát triển mạnh mẽ của các mô hình ngôn ngữ lớn (LLM) được huấn luyện trên mã (Anil et al., 2023; Austin et al., 2021; Chen et al., 2021a; Li et al., 2023; Roziere et al., 2023; Touvron et al., 2023). Trong khi những LLM này đạt được hiệu suất ấn tượng trong việc hỗ trợ các nhà phát triển viết (Chen et al., 2021a), chỉnh sửa (Fakhoury et al., 2023), giải thích (Hu et al., 2018), và xem xét (Li et al., 2022) mã, chúng vẫn gặp khó khăn trong các nhiệm vụ kỹ thuật phần mềm phức tạp hơn đòi hỏi suy luận về hành vi thực thi thời gian chạy của chương trình (Ma et al., 2023). Mặt khác, không phải lúc nào cũng đủ để mô hình đề xuất các giải pháp mã tốt, mà thường cần thiết phải cung cấp lời giải thích cho các nhà phát triển để ghi lại những gì thay đổi và tại sao cần thiết. Những lời giải thích này có thể giúp các nhà phát triển hiểu rõ hơn các giải pháp mã từ mô hình và đưa ra quyết định có thông tin hơn. (Cito et al., 2022; Kang et al., 2023; Ross et al., 2023).

Ví dụ, sửa chữa chương trình (Chen et al., 2018; Le Goues et al., 2019; Li et al., 2020) là nhiệm vụ sửa lỗi trong chương trình. Các nhà phát triển con người thường học cách gỡ lỗi và sửa mã bằng cách tương tác với trình thông dịch mã hoặc trình gỡ lỗi để kiểm tra trạng thái biến của các dòng đã thực thi (Siegmund et al., 2014). Thực hành như vậy giúp họ có được mô hình tinh thần về việc thực thi chương trình (Heinonen et al., 2022), để họ có thể mô phỏng tinh thần việc thực thi mã theo cách trừu tượng hơn bằng ngôn ngữ tự nhiên như trong gỡ lỗi vịt cao su (Hunt and Thomas, 1999). Do đó, một mô hình sửa chữa chương trình sẽ hữu ích hơn cho các nhà phát triển nếu mô hình có thể thực hiện suy luận tương tự về việc thực thi chương trình để giải thích lỗi cho các lập trình viên.

Với cảm hứng này, mục tiêu của chúng tôi là cải thiện khả năng suy luận về việc thực thi chương trình của LLM khi giải quyết các nhiệm vụ lập trình. Trong bài báo này, chúng tôi đề xuất Điều chỉnh Thực thi Tự nhiên (NE xT), nhằm dạy LLM suy luận với việc thực thi mã bằng cách kiểm tra dấu vết thực thi chương trình và suy luận về hành vi thời gian chạy của mã bằng ngôn ngữ tự nhiên (NL). Ở mức độ tổng quát, đối với một nhiệm vụ lập trình

Tác giả liên hệ: Ansong Ni ⟨ansong.ni@yale.edu ⟩, Pengcheng Yin⟨pcyin@google.com ⟩
©2024 Google DeepMind. Tất cả quyền được bảo lưuarXiv:2404.14662v1  [cs.LG]  23 Apr 2024

--- TRANG 2 ---
NExT: Dạy các Mô hình Ngôn ngữ Lớn Suy luận về Thực thi Mã
Lý luận CoT…Đầu ra Mãdef extract_values(string):str_list = string.replace('"','').split(",")return str_listĐặc tả vấn đề yêu cầu trích xuất giá trị giữa dấu ngoặc kép của một chuỗi.Bây giờ hãy xem chương trình. Chương trình đầu tiên sử dụng replace() để loại bỏ tất cả dấu ngoặc kép, sau đó sử dụng split() để chia chuỗi bằng dấu phẩy. Điều này có vẻ hoạt động tốt cho khẳng định thứ hai và thứ ba. Nhưng đối với khẳng định đầu tiên, giá trị trả về là ['Python', ' PHP', ' Java'] trong khi đầu ra mong đợi là ['Python', 'PHP', 'Java'].Lý do là chuỗi đầu vào có khoảng trắng trước và sau mỗi dấu phẩy, và split() sẽ chia chuỗi bằng dấu phẩy và cũng giữ lại khoảng trắng.Đây là phiên bản đã sửa sử dụng re.findall() để trích xuất các chuỗi con giữa dấu ngoặc kép:import redef extract_values(string):str_list = re.findall('"(.*?)"', string)return str_listlọc tính đúng đắnhuấn luyệnlấy mẫu

Executor 𝓔
LLMs 𝑷𝜽(𝒊)kiểm tra
Ví dụ Lý luận + Sửa chữa(Được tạo bởi PaLM-2-L + NExT)NExTVòng lặp(Lấy mẫu ↦Lọc ↦Huấn luyện)def extract_values(string): # (0) string='"Python", "PHP", "Java"';str_list = string.replace('"','').split(",") # (1) str_list=['Python', ' PHP', ' Java'];return str_list # (2) __return__=['Python', ' PHP', ' Java'];assert extract_values('"Python", "PHP", "Java"')==['Python', 'PHP', 'Java']\# (3) __exception__ = AssertionError()assert extract_values('"Python", "PHP", "Java"')==['Python', 'PHP', 'Java']# Viết một hàm để trích xuất giá trị giữa dấu ngoặc kép của một chuỗi.Hướng dẫn NL 𝒙mã lỗi 𝒚#trường hợp kiểm tra 𝒕𝟏dấu vết𝝐lý luận𝒓'
đầu ra mã 𝒚(Promptđặc tả chương trìnhmã lỗitrường hợp kiểm tradấu vết……………

Hình 1|NExT tinh chỉnh một LLM để tự nhiên hóa dấu vết thực thi thành các lý luận chuỗi suy nghĩ để giải quyết các nhiệm vụ lập trình. Nó thực hiện tự huấn luyện lặp từ giám sát yếu, bằng cách học từ các mẫu dẫn đến giải pháp nhiệm vụ chính xác.

nhiệm vụ, ý tưởng chính là huấn luyện một mô hình để tạo ra các lý luận NL trung gian, như trong suy luận chuỗi suy nghĩ (Wei et al., 2022a), nhưng cung cấp cho mô hình một dấu vết thực thi của chương trình được đề cập, để lý luận có thể chính xác hơn và dựa trên ngữ nghĩa chương trình. Dạy LLM suy luận về việc thực thi chương trình bằng NL không chỉ mang lại khả năng diễn giải tốt hơn, mà còn có thể tăng tính đa dạng của các giải pháp được dự đoán bởi mô hình (Yin et al., 2023).

Hình 1 minh họa phương pháp đề xuất của chúng tôi khi áp dụng cho sửa chữa chương trình. Được cung cấp một hướng dẫn nhiệm vụ NL (𝑥 trong Hình 1) và một chương trình lỗi (˜𝑦), cũng như dấu vết thực thi của chương trình (𝜖), một LLM giải quyết nhiệm vụ (ví dụ: dự đoán mã đã sửa ˆ𝑦) bằng suy luận chuỗi suy nghĩ (CoT) để tạo ra một lý luận ngôn ngữ tự nhiên (ˆ𝑟) tận dụng thông tin thực thi1. Trực quan, dấu vết chương trình mã hóa thông tin gỡ lỗi hữu ích như trạng thái biến từng dòng (ví dụ: giá trị của str_list trong 𝜖, Hình 1) hoặc bất kỳ ngoại lệ nào được ném ra, có thể hữu ích cho LLM để xác định và sửa lỗi bằng cách suy luận trên kết quả thực thi mong đợi và thực tế (ví dụ: "văn bản được tô sáng" trong ˆ𝑟). Để giúp LLM hiểu dấu vết thực thi, NE xT đại diện cho dấu vết như các bình luận mã nội tuyến nhỏ gọn (ví dụ: # (1) str_list= ... trong 𝜖, thêm trong §3), mà không làm gián đoạn cấu trúc chương trình gốc.

Trong khi dấu vết thực thi nắm bắt hành vi thời gian chạy có thông tin, chúng tôi thấy thách thức đối với LLM để tận dụng hiệu quả chúng ngay lập tức thông qua prompting CoT (§3). Do đó chúng tôi chọn tinh chỉnh LLM trên các lý luận CoT chất lượng cao suy luận về việc thực thi chương trình (§4). NE xT sử dụng tự huấn luyện giám sát yếu (Zelikman et al., 2022) để khởi tạo một tập huấn luyện tổng hợp bằng cách lấy mẫu các lý luận dẫn đến giải pháp nhiệm vụ chính xác (ví dụ: mã đã sửa ˆ𝑦 trong Hình 1) được xác minh bởi các kiểm tra đơn vị (Ye et al., 2022). Sử dụng kiểm tra đơn vị như giám sát yếu, NE xT học cách khám phá các lý luận NL nhận thức thực thi cụ thể cho nhiệm vụ mà không cần dựa vào chú thích thủ công tốn công của lý luận (Chung et al., 2022; Lightman et al., 2023; Longpre et al., 2023) hoặc chưng cất dữ liệu như vậy từ các mô hình giáo viên mạnh hơn (Fu et al., 2023; Gunasekar et al., 2023; Mitra et al., 2023; Mukherjee et al., 2023). NE xT thực hiện vòng tự huấn luyện này cho nhiều lần lặp (Anthony et al., 2017; Dasigi et al., 2019), giải quyết các nhiệm vụ thách thức hơn với tỷ lệ thành công và chất lượng lý luận được cải thiện (§5).

1Trong khi có nhiều loại thông tin thực thi mà chúng ta có thể cung cấp cho LLM (ví dụ: đọc/ghi biến, môi trường thời gian chạy), trong công việc này chúng tôi giới hạn thông tin thực thi cho trạng thái chương trình và giá trị biến từ dấu vết thực thi, đây là thông tin phổ biến mà các nhà phát triển (con người) cũng sử dụng.
2

--- TRANG 3 ---
NExT: Dạy các Mô hình Ngôn ngữ Lớn Suy luận về Thực thi Mã
1def separate_odd_and_even(lst): # (0) lst=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10];
2 odd_list = [] # (1) odd_list=[];
3 even_list = [] # (2) even_list=[];
4 for n in lst: # (3) n=1; (5) n=2; (7) n=3; ...; (21) n=10;
5 if n %
6 even_list.append(n) # (4) even_list=[1]; (8) even_list=[1, 3]; ...; (20) even_list=[1, 3, 5, 7, 9];
7 else:
8 odd_list.append(n) # (6) odd_list=[2]; (10) odd_list=[2, 4]; ...; (22) odd_list=[2, 4, 6, 8, 10];
9 return odd_list, even_list # (23) __return__=([2, 4, 6, 8, 10], [1, 3, 5, 7, 9])
10
11separate_odd_and_even([1,2,3,4,5,6,7,8,9,10]) == [1,3,5,7,9], [2,4,6,8,10]

Hình 2|NExT đại diện cho dấu vết thực thi như các bình luận nội tuyến. Chi tiết hơn trong §2 và Phụ lục A.1.

Chúng tôi đánh giá NE xT với mô hình PaLM2-L (Anil et al., 2023) trên hai nhiệm vụ sửa chữa chương trình Python. Các thí nghiệm (§5) cho thấy NE xT cải thiện đáng kể khả năng suy luận về việc thực thi chương trình bằng ngôn ngữ tự nhiên của PaLM 2, cải thiện tỷ lệ sửa chữa chương trình trên Mbpp-R 26,1% và HumanEvalFix-Plus 14,3% tuyệt đối tương ứng. Khi so sánh với phương pháp sửa chữa chương trình tự huấn luyện mạnh mà không dự đoán lý luận NL (Ye et al., 2022), mô hình của chúng tôi đạt độ chính xác tương đương với tính đa dạng mẫu được cải thiện đáng kể. Thú vị là, trong khi mô hình của chúng tôi học suy luận với thông tin thực thi có sẵn trong dấu vết chương trình đầu vào, nó cũng tổng quát hóa cho tình huống ngoài phân phối nơi dấu vết thực thi không có sẵn tại thời gian kiểm tra. Cuối cùng, để đo lường chất lượng lý luận được tạo bởi mô hình, chúng tôi đề xuất phương pháp đánh giá dựa trên proxy, xấp xỉ chất lượng lý luận sử dụng hiệu suất của LLM nhỏ hơn khi được nhắc giải quyết nhiệm vụ gốc theo những lý luận đó từ mô hình của chúng tôi. Thông qua cả đánh giá dựa trên proxy và chú thích con người, chúng tôi chứng minh rằng NE xT tạo ra lý luận NL hữu ích giải thích nguyên nhân lỗi trong khi đề xuất sửa chữa tiềm năng. Các lý luận được tạo có chất lượng cao hơn đáng kể so với những lý luận từ mô hình PaLM 2-L cơ sở.

2. Nhiệm vụ: Sửa chữa Chương trình với Dấu vết

Ở đây chúng tôi giới thiệu nhiệm vụ sửa chữa chương trình với dấu vết thực thi sử dụng suy luận chuỗi suy nghĩ.

Sửa chữa Chương trình với Dấu vết Thực thi. Như trong Hình 1, được cung cấp một hướng dẫn 𝑥 và một giải pháp mã lỗi ˜𝑦, sửa chữa chương trình tự động (Le Goues et al., 2019) nhằm tạo ra một chương trình đã sửa ˆ𝑦 sao cho ˆ𝑦 vượt qua tất cả các trường hợp kiểm tra 𝑡∈𝑇 trong một executor E, tức là E(ˆ𝑦,𝑇)=1 trong khi E(˜𝑦,𝑇)=0. Trong bài báo này chúng tôi tập trung vào nhiệm vụ sửa chữa chương trình sử dụng dấu vết thực thi (Bouzenia et al., 2023). Cụ thể, một dấu vết chương trình 𝜖 là một chuỗi các trạng thái biến trung gian sau khi thực thi mỗi câu lệnh trong ˜𝑦 đối với một trường hợp kiểm tra 𝑡. Trực quan, dấu vết ghi lại việc tính toán của một chương trình, và có thể cung cấp thông tin gỡ lỗi hữu ích (ví dụ: ngoại lệ) để sửa chữa ˜𝑦.

Để sử dụng LLM sửa chữa chương trình với dấu vết, chúng tôi nối hướng dẫn nhiệm vụ, mã lỗi, các trường hợp kiểm tra, và dấu vết thực thi của chúng như một prompt (Hình 1). Để giúp LLM hiểu dấu vết chương trình, chúng tôi thiết kế một đại diện dấu vết thân thiện với prompt bằng cách định dạng 𝜖 như các bình luận mã nội tuyến nhỏ gọn (tức là 𝜖 trong Hình 1), như đã thảo luận sau.

Suy luận CoT với Thực thi. Chúng tôi tập trung vào sử dụng suy luận chuỗi suy nghĩ (Wei et al., 2022b) để giải quyết các vấn đề sửa chữa chương trình bằng cách suy luận với thực thi, trong đó một LLM được nhắc tạo ra một lý luận NL ˆ𝑟 cùng với một chương trình đã sửa ˆ𝑦 như trong Hình 1. Cụ thể, chúng tôi xem xét các lý luận chứa các bước suy luận để xác định và giải thích lỗi trong mã gốc (ví dụ: đoạn thứ hai trong ˆ𝑟, Hình 1), cũng như đề xuất sửa mã lỗi (ví dụ: "một phiên bản đã sửa sử dụng re.findall()" trong ˆ𝑟). Vì các lý luận được tạo bằng dấu vết, chúng thường bao gồm suy luận hữu ích về việc thực thi chương trình giúp định vị lỗi, chẳng hạn như xác định một phản thực tế giữa các giá trị biến mong đợi và thực tế của một câu lệnh (ví dụ: "văn bản được tô sáng" trong ˆ𝑟). Những lời

3

--- TRANG 4 ---
NExT: Dạy các Mô hình Ngôn ngữ Lớn Suy luận về Thực thi Mã
Mixtral DeepSeek StarCoderTrung bình Benchmarks Phương pháp Prompting PaLM 2-L GPT-3.5 GPT-48x7B Coder 33B 15.5B
Vanilla w/ trace 27.5 41.8 62.6 16.1 23.9 13.3 30.9
+CoT 26.6 46.4 62.8 21.1 18.2 12.6 31.3 +0.4 Mbpp-R
+CoT;−trace 19.0 47.1 51.3 18.1 12.9 10.6 26.5−4.8
Vanilla w/ trace 59.1 70.1 88.4 32.9 57.3 29.3 56.2
+CoT 48.8 75.6 84.8 34.1 30.5 16.5 48.4−7.8 HeFix+
+CoT;−trace 43.3 72.0 82.9 25.6 22.6 18.3 44.1−4.3

Bảng 1|Độ chính xác sửa chữa với prompting ít mẫu (3) sử dụng giải mã tham lam. Kết quả tệ hơn hàng trước đó được gạch chân màu đỏ.

giải thích như vậy có thể hữu ích cho các nhà phát triển để hiểu lỗi trong mã gốc và các giải pháp sửa chữa của mô hình (Kang et al., 2023). Do đó chúng tôi nhằm cải thiện chất lượng lý luận NL cùng với tỷ lệ sửa chữa bằng cách dạy LLM suy luận với thông tin thực thi.

Một Đại diện Dấu vết Thân thiện với LLM. Dấu vết thực thi thô được thu thập tại thời gian chạy chứa trạng thái biến đầy đủ cho mỗi câu lệnh được thực thi.2 Mã hóa tất cả thông tin như vậy trong prompt không khả thi do giới hạn ngữ cảnh và chi phí tính toán của LLM. Để giải quyết vấn đề này và làm thông tin thực thi dễ hiểu hơn cho LLM, chúng tôi đề xuất định dạng đại diện dấu vết nội tuyến, mã hóa trạng thái biến như các bình luận nội tuyến của chương trình được theo dõi. Hình 2 cho thấy một ví dụ. Cụ thể, mỗi bình luận nội tuyến chỉ mã hóa các biến đã thay đổi sau khi thực thi dòng đó. Vì các câu lệnh có thể được gọi nhiều lần theo thứ tự không rõ ràng (ví dụ: trong vòng lặp như dòng 4 đến 8 trong Hình 2), chúng tôi lập chỉ mục trạng thái biến dựa trên thứ tự thực thi (ví dụ: (3) n=1; và (4) even_list=[1]), và có thể tái tạo dấu chân thực thi gốc bằng cách theo dõi những trạng thái biến đó theo thứ tự. Chúng tôi nén thêm thông tin dấu vết cho vòng lặp bằng cách bỏ qua trạng thái biến trong các lần lặp trung gian (ví dụ: "..." trong dòng 4, 6, và 8). Trực quan, bằng cách hiển thị trạng thái như các bình luận giả trong mã gốc mà không làm gián đoạn cấu trúc chương trình, đại diện dấu vết của chúng tôi nhỏ gọn hơn đáng kể so với các phương pháp hiện có mở rộng các dòng mã đã thực thi và ghép chúng với trạng thái biến từng dòng (c.f., Bouzenia et al., 2023; Nye et al., 2021),3 trong khi cho phép LLM tận dụng đại diện mã đã học để hiểu hiệu ứng thực thi bổ sung của mỗi câu lệnh. Chi tiết triển khai về xử lý cấu trúc điều khiển phức tạp được thảo luận trong Phụ lục A.1.

3. Nghiên cứu Sơ bộ: LLM có thể suy luận với dấu vết chương trình bằng ngôn ngữ tự nhiên không?

Trước khi giới thiệu NE xT, chúng tôi đầu tiên tiến hành một nghiên cứu sơ bộ để khám phá liệu LLM có thể suy luận với dấu vết thực thi bằng ngôn ngữ tự nhiên ngay lập tức mà không cần huấn luyện bổ sung. Trả lời câu hỏi này sẽ thúc đẩy phương pháp tinh chỉnh của chúng tôi để cải thiện kỹ năng suy luận như vậy. Cụ thể, chúng tôi theo đại diện dấu vết trong §2 và prompt ít mẫu cho LLM giải quyết các nhiệm vụ sửa chữa chương trình sử dụng suy luận CoT.

Mô hình. Chúng tôi đánh giá các mô hình đa năng sau: PaLM2 (Anil et al., 2023), GPT (OpenAI, 2023)4, và Mixtral (Jiang et al., 2024). Chúng tôi cũng kiểm tra hai LLM cụ thể cho mã: StarCoder (Li et al., 2023) và DeepSeek Coder (Guo et al., 2024). Bảng 1 báo cáo kết quả trên hai bộ dữ liệu sửa chữa chương trình Python (xem §5 để biết chi tiết).

2Chúng tôi sử dụng hook sys.settrace() trong Python.
3Như một so sánh, 95% ví dụ trong benchmark Mbpp-R của chúng tôi có thể vừa vào cửa sổ ngữ cảnh 2K sử dụng đại diện nội tuyến của chúng tôi, trong khi chỉ 60% trong số chúng có thể vừa vào cửa sổ tương tự sử dụng định dạng dấu vết Scratchpad trong Nye et al. (2021). Một so sánh chi tiết hơn được hiển thị trong Bảng 7.
4Chúng tôi sử dụng gpt-3.5-turbo-1106 và gpt-4-1106-preview.
4

--- TRANG 5 ---
NExT: Dạy các Mô hình Ngôn ngữ Lớn Suy luận về Thực thi Mã

LLM gặp khó khăn trong suy luận CoT với dấu vết. Chúng tôi quan sát kết quả trái chiều khi so sánh prompting vanilla với dấu vết mà không có CoT (Vanilla w/ trace trong Bảng 1) và prompting CoT với lý luận (+CoT). Đáng ngạc nhiên, prompting CoT thậm chí tệ hơn trên HumanEvalFix-Plus, với mức giảm trung bình −7.8% so với prompting vanilla, đặc biệt đối với LLM cụ thể cho mã (57.3↦→30.5 cho DeepSeek Coder và 29.3↦→16.5 cho StarCoder). Sau khi kiểm tra các lý luận được dự đoán bởi PaLM 2-L, chúng tôi quan sát rằng mô hình chịu các vấn đề ảo giác mạnh, chẳng hạn như đề cập đến ngoại lệ không được phản ánh trong dấu vết đã cho. Thật vậy, như chúng tôi sẽ hiển thị sau trong §5.2, tỷ lệ chính xác tổng thể của việc giải thích lỗi trong chương trình đầu vào trong số những lý luận được lấy mẫu từ PaLM 2-L chỉ khoảng 30%. Hơn nữa, suy luận CoT thậm chí thách thức hơn đối với những mô hình khi chúng tôi loại bỏ dấu vết thực thi khỏi đầu vào (+CoT;−trace), dẫn đến mức giảm hiệu suất trung bình 4.8% trên Mbpp-R và 4.3% trên HumanEvalFix-Plus. Những kết quả này cho thấy rằng trong khi đại diện dấu vết của chúng tôi hữu ích cho LLM hiểu và tận dụng thông tin thực thi để sửa chữa chương trình (vì "−trace" dẫn đến kết quả tệ hơn), chúng vẫn có thể thiếu sót trong suy luận CoT sử dụng ngôn ngữ tự nhiên với những dấu vết chương trình đó. Phát hiện này do đó thúc đẩy chúng tôi cải thiện LLM trong suy luận với thực thi thông qua tinh chỉnh, mà chúng tôi triển khai trong §4.

4. NE xT: Điều chỉnh Thực thi Tự nhiên

Chúng tôi trình bày NE xT, một phương pháp tự huấn luyện để tinh chỉnh LLM suy luận với việc thực thi chương trình sử dụng lý luận tổng hợp.

Tổng quan về NE xT. Hình 1 minh họa NE xT, với thuật toán của nó được chi tiết trong Thuật toán 1. NE xT dựa trên các phương pháp suy luận tự huấn luyện hiện có (Uesato et al., 2022; Zelikman et al., 2022), sử dụng lặp chuyên gia để cải thiện LLM cơ sở bằng lý luận tổng hợp được lấy mẫu từ mô hình. Được cung cấp một tập huấn luyện D của các nhiệm vụ sửa chữa với dấu vết thực thi, NE xT đầu tiên lấy mẫu các lý luận NL ứng viên và giải pháp mã đã sửa từ LLM. Những giải pháp ứng viên được lọc bằng chẩn đoán thực thi kiểm tra đơn vị, và những giải pháp vượt qua tất cả trường hợp kiểm tra sau đó được sử dụng để cập nhật mô hình thông qua tinh chỉnh. Vòng lặp lấy mẫu-lọc-huấn luyện này được thực hiện cho nhiều lần lặp, cải thiện lý luận của mô hình và tỷ lệ thành công sửa chữa sau mỗi lần lặp.

Lấy mẫu lý luận và giải pháp mã. Đối với mỗi lần lặp 𝑖, chúng tôi lấy mẫu lý luận ˆ𝑟 và sửa chữa ˆ𝑦 cùng nhau từ mô hình hiện tại 𝑃𝜃(𝑖) (Dòng 5, Thuật toán 1). Chúng tôi sử dụng prompting ít mẫu (§3) khi 𝑖=0 và prompting zero-shot với các mô hình đã huấn luyện cho các lần lặp sau. Trái ngược với các phương pháp tự huấn luyện hiện có tận dụng tất cả các vấn đề huấn luyện, NE xT chỉ lấy mẫu giải pháp ứng viên từ tập con các vấn đề trong D thách thức đối với mô hình cơ sở 𝑃𝜃(0) để giải quyết (Dòng 1). Cụ thể, được cung cấp một metric M(·), chúng tôi chỉ sử dụng các vấn đề 𝑑∈D nếu metric của 𝑃𝜃(0) trên 𝑑 dưới ngưỡng 𝑚. Tham khảo §5 để biết thêm chi tiết về M(·) và 𝑚 của nhiệm vụ sửa chữa chương trình của chúng tôi. Tập trung vào lấy mẫu giải pháp từ những vấn đề khó không chỉ giảm đáng kể chi phí lấy mẫu, mà còn cải thiện độ chính xác sửa chữa chương trình, vì nó giúp mô hình học cách giải quyết các vấn đề thách thức hơn. Xem Phụ lục C để phân tích chi tiết hơn.

Lọc giải pháp ứng viên. Được cung cấp một tập ứng viên các lý luận NL được lấy mẫu và sửa chữa mã của chúng, NE xT sử dụng kết quả thực thi kiểm tra đơn vị để xác định lý luận hợp lý dẫn đến sửa chữa chính xác để học (Dòng 6). Sử dụng chẩn đoán thực thi kiểm tra như hàm thưởng nhị phân là tự nhiên đối với các nhiệm vụ sửa chữa chương trình vì mỗi vấn đề sửa chữa trong bộ dữ liệu của chúng tôi đi kèm với kiểm tra đơn vị để kiểm tra tính chính xác chức năng của các sửa chữa được đề xuất (Ye et al., 2022). Trong khi chúng tôi nhận xét rằng tiêu chí lọc này không trực tiếp xem xét chất lượng lý luận, chúng tôi chứng minh thực nghiệm trong §5 rằng chất lượng lý luận cải thiện khi học tiếp tục.5

5Chất lượng lý luận và sửa chữa có thể đạt đỉnh ở lần lặp 𝑖 khác nhau.
5

--- TRANG 6 ---
NExT: Dạy các Mô hình Ngôn ngữ Lớn Suy luận về Thực thi Mã

Thuật toán 1 Điều chỉnh Thực thi Tự nhiên (NE xT)
Đầu vào: Tập huấn luyện D={(𝑥𝑗,˜𝑦𝑗,𝑇𝑗,𝜖𝑗)}|D|
𝑗=1(§2); Tập phát triển D𝑑𝑒𝑣; LLM cơ sở 𝑃𝜃(0); Số lần lặp 𝐼; Executor E; Metric đánh giá M và ngưỡng 𝑚
1:D𝐻←{𝑑|𝑑∈D,M(𝑃𝜃(0),𝑑)< 𝑚}// Xác định các vấn đề khó D𝐻 với metric M(·)< 𝑚
2:for𝑖=0to𝐼do
3:B(𝑖)←{}
4:for(𝑥𝑗,˜𝑦𝑗,𝑇𝑗,𝜖𝑗)inD𝐻do
5:𝑆(𝑖)
𝑗∼𝑃𝜃(𝑖)(𝑟,𝑦|𝑥𝑗,˜𝑦𝑗,𝑇𝑗,𝜖𝑗)// Lấy mẫu lý luận 𝑟 và sửa chữa 𝑦 sử dụng dấu vết 𝜖𝑗.
6:B(𝑖)←B(𝑖)∪{(ˆ𝑟,ˆ𝑦)|(ˆ𝑟,ˆ𝑦)∈𝑆(𝑖)
𝑗,E(ˆ𝑦,𝑇𝑗)=1}// Lọc với trường hợp kiểm tra 𝑇𝑗 và thêm vào B(𝑖).
7:end for
8:𝜃(𝑖+1)←arg max 𝜃𝔼B(𝑖)[𝑃𝜃(ˆ𝑟,ˆ𝑦|𝑥,˜𝑦,𝑇,𝜖)]// Tinh chỉnh mô hình 𝑃𝜃(0) với dữ liệu trong B(𝑖).
9:end for
10:𝑖∗←arg max 𝑖Í
𝑑∼D𝑑𝑒𝑣M(𝑃𝜃(𝑖),𝑑)/|D𝑑𝑒𝑣|// Chọn checkpoint tốt nhất 𝑖∗
Đầu ra: mô hình 𝑃𝜃(𝑖∗)

Huấn luyện mô hình. Sau khi thu thập một tập các ví dụ huấn luyện B(𝑖), chúng tôi tinh chỉnh mô hình để tối đa hóa xác suất tạo ra lý luận mục tiêu và sửa chữa mã được cung cấp đầu vào nhiệm vụ (Dòng 8). Theo Zelikman et al. (2022), chúng tôi luôn tinh chỉnh mô hình từ checkpoint ban đầu 𝑃𝜃(0) để tránh over-fitting với các trường hợp được lấy mẫu từ các lần lặp sớm có thể chất lượng thấp hơn.

Thảo luận. NExT có thể được xem như một phiên bản cụ thể của phương pháp khởi tạo lý luận được đề xuất trong Zelikman et al. (2022) (§ 3.1), tổng hợp lý luận tiềm ẩn với câu trả lời chính xác cho các nhiệm vụ suy luận toán học và logic. Tuy nhiên, NE xT tập trung vào hiểu chương trình bằng cách suy luận với dấu vết thực thi, điều quan trọng để giải quyết các nhiệm vụ lập trình thách thức đòi hỏi hiểu thông tin thực thi, chẳng hạn như sửa chữa chương trình (§5). Bên cạnh đó, NE xT mô hình cả lý luận và chương trình (sửa chữa mã) như các biến tiềm ẩn. Sử dụng kết quả thực thi kiểm tra đơn vị như giám sát yếu, NE xT có thể khám phá các chiến lược có thể để suy luận với thực thi và khám phá lý luận hợp lý hướng đến giải quyết nhiệm vụ downstream cụ thể. Như chúng tôi hiển thị trong Phụ lục D, lý luận được tạo bởi NExT sử dụng nhiều mẫu suy luận khác nhau để định vị và giải thích lỗi trong bộ dữ liệu sửa chữa của chúng tôi. Cuối cùng, trong khi chúng tôi áp dụng NE xT cho sửa chữa chương trình, framework của chúng tôi là tổng quát và có thể được mở rộng cho các nhiệm vụ lập trình khác đòi hỏi suy luận về thực thi, chẳng hạn như tạo mã với ngữ cảnh thực thi một phần (Yin et al., 2023) hoặc suy luận kết quả thực thi chương trình (Nye et al., 2021), mà chúng tôi để lại như công việc tương lai quan trọng.

5. Thí nghiệm

Mô hình. Chúng tôi đánh giá NE xT sử dụng PaLM 2-L (Unicorn) như LLM cơ sở (Anil et al., 2023). API tinh chỉnh của nó có thể truy cập công khai trên nền tảng Google Cloud Vertex AI.

Bộ dữ liệu. Chúng tôi sử dụng hai benchmark sửa chữa chương trình Python, Mbpp-R và HumanEvalFix-Plus (HeFix+ sau đây). Mbpp-R là một benchmark sửa chữa mới mà chúng tôi tạo từ Mbpp (Austin et al., 2021), một bộ dữ liệu tạo mã Python cấp hàm phổ biến. Chúng tôi tạo Mbpp-R bằng cách thu thập các giải pháp mã không chính xác được tạo bởi LLM cho các vấn đề Mbpp, với tổng cộng 10,047 nhiệm vụ sửa chữa để huấn luyện và 1,468 nhiệm vụ (từ một tập các vấn đề Mbpp riêng biệt) trong phát triển để đánh giá (Phụ lục B.1). Ngoài Mbpp-R, chúng tôi cũng đánh giá trên HeFix+. HeFix+ được bắt nguồn từ HumanEvalFix (Muennighoff et al., 2023) bao gồm 164 chương trình lỗi cho các vấn đề trong bộ dữ liệu HumanEval (Chen et al., 2021a). Chúng tôi mở rộng thêm HumanEvalFix với các bộ kiểm tra nghiêm ngặt hơn từ EvalPlus (Liu et al., 2023) để có được HeFix+. Trong khi cả bộ dữ liệu gốc Mbpp và HumanEval đều có tính năng tạo mã thuật toán cấp hàm
6

--- TRANG 7 ---
NExT: Dạy các Mô hình Ngôn ngữ Lớn Suy luận về Thực thi Mã

Tỷ lệ Sửa chữa End-to-end Đánh giá dựa Proxy (pass@𝑘 trên LM nhỏ hơn)
Mô hình pass@1 pass@5 pass@10 pass@25 pass@1pass@5pass@10 pass@25
GPT-4; 3-shot 63.2 75.1 78.5 82.7 44.8 66.5 72.5 77.8
GPT-3.5; 3-shot 42.9 65.0 70.7 76.7 26.6 48.8 57.0 66.4
PaLM 2-L; 3-shot 23.2 45.7 54.7 65.0 22.5 43.4 51.9 61.5
PaLM 2-L+NExT; 0-shot 49.3 +26.168.1+22.473.5+18.879.4+14.428.8+6.349.9+6.557.3+5.4 65.5+4.0

Bảng 2|Cải tiến của NE xT trên mô hình PaLM 2-L (chỉ số dưới) trên Mbpp-R. Kết quả GPT-3.5/4 để tham khảo.

9.710.011.911.512.612.318.213.521.117.546.429.862.844.826.623.250.528.6010203040506070
End-to-End Pass@1Proxy-based Pass@1Mistral-7BOctoCoder-15.5BStarCoder-15.5BDeepSeekCoder-33BMixtral-8x7BGPT-3.5GPT-4PaLM-2-LPaLM-2-L + NExT

Hình 3|Kết quả giải mã tham lam trên Mbpp-R trên PaLM 2-L+NExT và các LLM hiện có.

các vấn đề, vấn đề từ hai bộ dữ liệu có thể vẫn khác nhau về chủ đề, thuật toán hoặc cấu trúc dữ liệu được sử dụng. Do đó, chúng tôi sử dụng HeFix+ để đo khả năng tổng quát hóa mà không cần tinh chỉnh thêm.

Đánh giá Sửa chữa Mã. Chúng tôi sử dụng pass@𝑘 (Chen et al., 2021a; Kulal et al., 2019), được định nghĩa là phần của các nhiệm vụ sửa chữa được giải quyết sử dụng 𝑘 mẫu (𝑘≤25), để đo tính chính xác chức năng end-to-end của các chương trình đã sửa với kiểm tra.

Đánh giá Chất lượng Lý luận. Tách biệt chất lượng lý luận CoT trung gian và hiệu suất nhiệm vụ downstream (sửa chữa chương trình pass@𝑘) là một câu hỏi nghiên cứu không tầm thường trong suy luận LLM (Prasad et al., 2023), với hầu hết các công việc về cải thiện suy luận CoT vẫn leo đồi hướng tới hiệu suất nhiệm vụ downstream mà không đánh giá chất lượng lý luận trung gian (ví dụ: Lightman et al. (2023)). Để tách biệt đánh giá chất lượng lý luận khỏi độ chính xác sửa chữa end-to-end, chúng tôi đề xuất một metric đánh giá dựa proxy ngoại tại cho lý luận. Cụ thể, được cung cấp một lý luận 𝑟, chúng tôi prompt một LLM nhỏ hơn để giải quyết nhiệm vụ sửa chữa gốc có điều kiện trên 𝑟, và sử dụng tính chính xác của sửa chữa mã được dự đoán (sử dụng giải mã tham lam) để xấp xỉ chất lượng của 𝑟. Trực quan, LLM nhỏ hơn sẽ dựa nhiều hơn vào thông tin từ lý luận và có thể nhạy cảm hơn với lỗi của nó. Do đó, hiệu suất của chúng có thể là chỉ báo tốt hơn về chất lượng lý luận. Chúng tôi báo cáo điểm trung bình trên hai biến thể PaLM 2 cho đánh giá dựa proxy: 1) một mô hình ngôn ngữ đa năng nhỏ hơn PaLM 2-S; và 2) PaLM 2-S∗ chuyên về lập trình (Anil et al., 2023). Lưu ý rằng trong khi chúng tôi chủ yếu sử dụng metric dựa proxy để đánh giá lý luận, chúng tôi cũng thực hiện đánh giá con người về chất lượng lý luận (§5.2), với kết quả phù hợp với đánh giá dựa proxy của chúng tôi.

Siêu tham số. Chúng tôi thực hiện lấy mẫu nhiệt độ (𝑇=0.8) với kích thước mẫu 32 cho huấn luyện (|𝑆𝑗|=32 trong Thuật toán 1) và đánh giá pass@𝑘. Trong lần lặp đầu tiên trong Thuật toán 1, chúng tôi sử dụng pass@1 được ước tính với 32 mẫu này làm metric lọc M(·) để tìm các vấn đề thách thức có M(·)≤ 10% để huấn luyện. Chúng tôi thực hiện 10 lần lặp huấn luyện NE xT và chọn mô hình tốt nhất sử dụng pass@1 trên tập phát triển.

7

--- TRANG 8 ---
NExT: Dạy các Mô hình Ngôn ngữ Lớn Suy luận về Thực thi Mã

102030405060708090100
02468405060708090100
02468Train -Pass@1Dev -Pass@10102030405060
024684050607080
02468End-to-end:Proxy-based:
Train -Pass@10Dev -Pass@1

Hình 4|Các ablation về loại bỏ lý luận và/hoặc dấu vết trong quá trình huấn luyện lặp của NE xT. Lưu ý rằng các giá trị min/max khác nhau được lấy cho trục 𝑦 để làm rõ giữa các đường cong khác nhau nhưng khoảng cách đường lưới nhất quán được sử dụng để so sánh dễ dàng hơn.

5.1. Kết quả Chính

Trong các thí nghiệm của chúng tôi, chúng tôi so sánh mô hình của chúng tôi với các LLM mạnh (được sử dụng trong §3), phân tích tác động của lý luận và dấu vết chương trình, và thực hiện các thí nghiệm tổng quát hóa trên HeFix+ và đánh giá con người về chất lượng lý luận.

NExT cải thiện tỷ lệ sửa chữa chương trình. Chúng tôi đầu tiên so sánh hiệu suất sửa chữa chương trình end-to-end của PaLM 2-L trước và sau huấn luyện NE xT (PaLM 2-L+NExT) trong Bảng 2 (Trái). NE xT dẫn đến cải thiện đáng kể về tỷ lệ sửa chữa end-to-end trên toàn bộ, với cải thiện tuyệt đối 26.1% trên pass@1. Thú vị là, mức tăng trên pass@𝑘 thường cao hơn đối với 𝑘 nhỏ hơn. Điều này có thể cho thấy rằng mô hình trở nên tự tin hơn về sửa chữa chương trình sau huấn luyện NE xT, trong khi tính đa dạng mẫu cũng cải thiện, như được chỉ ra bởi pass@25 được cải thiện. Để tham khảo, chúng tôi cũng bao gồm kết quả từ các mô hình GPT. Đáng chú ý, PaLM 2-L +NExT vượt trội GPT-3.5 trên tất cả metric pass@𝑘.

NExT cải thiện chất lượng lý luận. Bảng 2 (Phải) hiển thị cải thiện của PaLM 2-L +NExT trên đánh giá dựa proxy của chúng tôi, nơi chúng tôi xấp xỉ chất lượng lý luận sử dụng hiệu suất của LM nhỏ hơn khi có điều kiện trên những lý luận đó. Một lần nữa, NE xT mang lại cải thiện nhất quán trên tất cả metric pass@𝑘. Điều này cho thấy rằng NE xT cải thiện kỹ năng suy luận của PaLM 2-L với thực thi để giải quyết các vấn đề Mbpp-R, dẫn đến lý luận hữu ích hơn cho LM nhỏ hơn. Trong Phụ lục D, chúng tôi trình bày một nghiên cứu trường hợp để chứng minh các chiến lược suy luận khác nhau mà PaLM 2-L +NExT áp dụng để sửa chữa chương trình sử dụng thông tin thực thi. Như chúng tôi sẽ hiển thị sau trong §5.2, metric dựa proxy của chúng tôi cũng nhất quán với đánh giá con người, và lý luận từ PaLM 2-L +NExT được người chú thích ưa thích mạnh so với những lý luận từ PaLM 2-L.

PaLM 2-L+NExT vượt trội các LLM mạnh. Chúng tôi so sánh PaLM 2-L +NExT với một loạt LLM mạnh từ nghiên cứu sơ bộ (§3) trong Hình 3. PaLM 2-L +NExT vượt trội các LLM mã nguồn mở mạnh tối thiểu 29.4% và 11.1% trên kết quả pass@1 end-to-end và dựa proxy tương ứng, trong khi ngang bằng với GPT-3.5. Những kết quả này cho thấy rằng PaLM 2-L +NExT là một mô hình cạnh tranh trong sửa chữa chương trình bằng cách suy luận với thực thi.

Học suy luận bằng ngôn ngữ tự nhiên cải thiện tổng quát hóa và tính đa dạng mẫu. Để chứng minh thêm tầm quan trọng của việc sử dụng suy luận CoT trong tự huấn luyện NE xT, chúng tôi so sánh PaLM 2-L+NExT với một mô hình sửa chữa chương trình tự huấn luyện mạnh được triển khai trong NE xT, tạo ra sửa chữa mã trực tiếp sử dụng thông tin thực thi thời gian chạy mà không có suy luận CoT. Ablation này giống SelfAPR (Ye et al., 2022), cũng áp dụng tự huấn luyện để tổng hợp dữ liệu lặp sử dụng chẩn đoán kiểm tra đơn vị, trong khi ablation của chúng tôi sử dụng dấu vết với thông tin thực thi phong phú hơn. Hình 4 hiển thị hiệu suất mô hình w.r.t. các lần lặp huấn luyện NE xT. Khi được huấn luyện mà không có suy luận CoT (NExT
8

--- TRANG 9 ---
NExT: Dạy các Mô hình Ngôn ngữ Lớn Suy luận về Thực thi Mã

Kiểm tra w/ Dấu vết Kiểm tra w/o Dấu vết
Phương pháp E2E Proxy E2E Proxy
PaLM 2-L 23.2 22.5 19.0 14.8
+NExT (w/ trace) 49.3 +26.128.8+6.340.8+21.819.5+4.7
+NExT w/o trace− − 44.1+25.123.9+9.1

Bảng 3|PaLM 2-L+NExT được huấn luyện với dấu vết vượt trội PaLM 2-L khi dấu vết không có tại thời gian kiểm tra như hiển thị trong kết quả được tô sáng. Kết quả trên Mbpp-R; Kiểm tra w/ Dấu vết: kết quả từ Bảng 2.

w/o rationale), PaLM 2-L hội tụ nhanh hơn nhiều trên tập huấn luyện, điều này không đáng ngạc nhiên vì mô hình chỉ học tạo sửa chữa mã mà không có nhiệm vụ suy luận bổ sung như giải thích lỗi bằng NL. Tuy nhiên, trên tập Dev, PaLM 2-L+NExT vẫn vượt trội baseline này trong pass@10 với độ chính xác pass@1 tương đương, và khoảng cách trên pass@10 trở nên lớn hơn với nhiều lần lặp hơn. Điều này cho thấy rằng bằng cách suy luận bằng ngôn ngữ tự nhiên, PaLM 2-L +NExT tổng quát hóa tốt hơn nhiều cho các vấn đề Mbpp-R chưa thấy với tính đa dạng mẫu lớn hơn. Trong Hình 6 của Phụ lục C, chúng tôi cũng hiển thị rằng mức tăng từ PaLM 2-L+NExT so với ablation này trên pass@𝑘 thậm chí rõ rệt hơn đối với 𝑘 >10 lớn hơn, cho thấy rằng học suy luận trong lý luận CoT cải thiện tính đa dạng mẫu trong sửa chữa chương trình, tương tự như các phát hiện trên các nhiệm vụ tạo mã khác (Yin et al., 2023).

Suy luận với dấu vết thực thi là quan trọng. Để hiểu tầm quan trọng của việc tận dụng dấu vết chương trình để suy luận với thực thi, chúng tôi so sánh với một ablation của NE xT mà không sử dụng dấu vết chương trình, theo cùng quy trình trong Thuật toán 1 ngoại trừ việc dấu vết 𝜖 không được sử dụng để tạo lý luận trong Dòng 5 (NExT w/o traces, Hình 4). Biến thể này cũng có thể được xem như một ứng dụng trực tiếp của phương pháp khởi tạo tạo lý luận trong Zelikman et al. (2022), huấn luyện một mô hình trên lý luận được lấy mẫu dẫn đến giải pháp nhiệm vụ chính xác mà không dựa vào thông tin thực thi bổ sung. Không có dấu vết, PaLM 2-L luôn tệ hơn PaLM 2-L +NExT trên tập Dev qua các lần lặp, cả về tỷ lệ sửa chữa end-to-end và metric dựa proxy. Điều này cho thấy rằng suy luận với thông tin thực thi là quan trọng đối với PaLM 2-L trong các nhiệm vụ sửa chữa chương trình. Thú vị là, trong khi khoảng cách trên tập phát triển là đáng kể, hai mô hình đạt điểm tương tự trên tập huấn luyện, cho thấy rằng suy luận với dấu vết thực thi có sẵn cũng giúp mô hình tổng quát hóa tốt hơn cho các nhiệm vụ chưa thấy tại thời gian kiểm tra.

Mô hình của chúng tôi hoạt động mà không có dấu vết tại thời gian kiểm tra. Trong khi dấu vết chương trình quan trọng để suy luận với thực thi, thông tin thực thi như vậy có thể không luôn có sẵn tại thời gian kiểm tra (ví dụ: khi thực thi cực kỳ tốn kém). Để kiểm tra căng thẳng PaLM 2-L +NExT trong các tình huống mà thông tin thực thi không có, chúng tôi loại bỏ dấu vết thực thi khỏi đầu vào của nó tại thời gian kiểm tra trong Bảng 3. PaLM 2-L+NExT vẫn mang lại tỷ lệ sửa chữa end-to-end 40.8%, là cải thiện 21.8% so với baseline PaLM 2-L 3-shot và chỉ thấp hơn 3.3% so với NE xT được huấn luyện mà không có dấu vết, được kiểm tra trong phân phối. Kết quả từ đánh giá dựa proxy của lý luận cũng nhất quán với tỷ lệ sửa chữa.

Mô hình của chúng tôi tổng quát hóa cho HeFix+ tại thời gian kiểm tra. Để đánh giá thêm khả năng tổng quát hóa của PaLM 2-L +NExT, chúng tôi kiểm tra mô hình của chúng tôi (được huấn luyện trên Mbpp-R) trên HeFix+. Bảng 4 tóm tắt kết quả. NE xT đạt tổng quát hóa hợp lý trên HeFix+, vượt trội mô hình PaLM 2-L cơ sở với biên độ lớn (tức là 14.3% trên tỷ lệ sửa chữa end-to-end và 6.0% trên đánh giá proxy). Phù hợp với các phát hiện trước đó của chúng tôi trên Mbpp-R trong Hình 4, suy luận với dấu vết thực thi (c.f. w/o traces) cải thiện tỷ lệ sửa chữa và chất lượng lý luận. Hơn nữa, chúng tôi nhận xét rằng với học lặp, PaLM 2-L+NExT ngang bằng với phương pháp sửa chữa chương trình mạnh mà không có suy luận CoT (w/o rationale), tương tự như kết quả trên Mbpp-R. Điều này trái ngược với nghiên cứu sơ bộ của chúng tôi trong §3, nơi PaLM2-L với prompting CoT tệ hơn nhiều so với prompting vanilla mà không sử dụng lý luận. Nhìn chung, những kết quả này chỉ ra rằng PaLM 2-L +NExT có thể tổng quát hóa mạnh mẽ cho các nhiệm vụ sửa chữa ngoài phân phối
9

--- TRANG 10 ---
NExT: Dạy các Mô hình Ngôn ngữ Lớn Suy luận về Thực thi Mã

Mô hình /pass@1 End-to-End Proxy-based
Baseline w/ 3-shot prompting
Mistral-7B∗12.8 16.5
OctoCoder-15.5B∗17.7 17.7
StarCoder-15.5B∗14.6 13.1
DeepSeekCoder-33B∗28.0 18.3
Mixtral-8x7B∗32.3 30.8
GPT-4 77.6 56.6
GPT-3.5 59.4 41.8
PaLM-2-L 32.2 31.9
PaLM-2-L w/o tracing†30.3 30.4
PaLM 2-L+NExT 42.5+10.338.0+6.1
w/o tracing†38.1+7.830.6+0.2
w/o rationale 44.5 +12.3−
w/o tracing + rationale†31.4+1.1−

Bảng 4|Kết quả tổng quát hóa trên HeFix+. Các mô hình PaLM 2-L+NExT chỉ được huấn luyện với Mbpp-R. ∗thu được bằng giải mã tham lam; †không có dấu vết được cung cấp tại thời gian kiểm tra.

Giải thích lỗi? Đề xuất sửa chữa?
Tổng thể Tốt nhất?
GPT-3.5 43 2635 44 1644 51.9% 34.6%
PaLM 2-L 27 2453 31 568 34.9% 6.7%
+NExT 48 2432 42 656 50.5% 32.7%

Bảng 5|Kết quả chú thích con người về chất lượng lý luận. Các mô hình cơ sở sử dụng prompting 3-shot. Số dưới câu hỏi là số lượng đánh giá.

mà không cần tinh chỉnh cụ thể cho bộ dữ liệu bổ sung.

5.2. Đánh giá Con người về Chất lượng Lý luận

Đánh giá dựa proxy của chúng tôi gợi ý giá trị ngoại tại của lý luận CoT từ PaLM 2-L +NExT. Chúng tôi tiến hành thêm đánh giá nội tại bằng cách đánh giá thủ công chất lượng lý luận được dự đoán bởi mô hình trên 104 nhiệm vụ sửa chữa Mbpp-R được lấy mẫu từ tập Dev. Cụ thể, chúng tôi yêu cầu người đánh giá đánh giá chất lượng lý luận được tạo bởi ba mô hình (PaLM 2-L +NExT, PaLM 2-L và GPT-3.5) trong một thiết lập side-by-side ba chiều. Mỗi lý luận được đánh giá theo hai khía cạnh: (1) tính hữu ích trong việc giải thích lỗi (𝑄1, ví dụ: hai đoạn đầu trong ˆ𝑟, Hình 1), và (2) tính hữu ích trong việc đề xuất sửa chữa mã (𝑄2, ví dụ: "một phiên bản đã sửa sử dụng ..." trong ˆ𝑟). Mỗi câu hỏi có câu trả lời ba thang đo (
 Hoàn toàn chính xác và rất hữu ích;
 Một phần chính xác với lỗi nhỏ nhưng vẫn hữu ích;
 Không chính xác và không hữu ích). Chúng tôi cũng tính điểm tổng thể của chất lượng lý luận sử dụng giá trị số {+1,0.5,0} cho ba thang đo và lấy trung bình qua 𝑄1 và 𝑄2. Cuối cùng, chúng tôi yêu cầu người đánh giá chọn một lựa chọn tốt nhất duy nhất nếu không có sự hòa rõ ràng. Chi tiết thêm về pipeline đánh giá con người của chúng tôi được mô tả trong Phụ lục B.3.

Bảng 5 tóm tắt kết quả. So với mô hình PaLM 2 cơ sở, PaLM 2-L +NExT tạo ra lý luận chất lượng cao hơn đáng kể với giải thích chính xác về lỗi và đề xuất sửa chữa. Ngoài ra, so với GPT-3.5, PaLM 2-L +NExT cũng có nhiều lý luận hơn với giải thích lỗi chính xác, trong khi thú vị là, GPT-3.5 tạo ra nhiều lý luận hơn với đề xuất sửa chữa một phần chính xác. Chúng tôi giả thuyết rằng bao gồm thêm exemplar với đề xuất sửa chữa chi tiết trong prompt ít mẫu của chúng tôi trong quá trình huấn luyện NE xT (Phụ lục E) sẽ giúp giảm thiểu vấn đề này. Tuy nhiên, điểm tổng thể và lựa chọn tốt nhất được gán bởi người đánh giá cho thấy rằng lý luận được dự đoán bởi PaLM 2-L +NExT có chất lượng cao hơn đáng kể so với những lý luận từ PaLM 2-L, và ngang bằng với dự đoán từ GPT-3.5. Nhìn chung, phát hiện này phù hợp với kết quả đánh giá proxy trong Hình 3 (GPT 3.5 ≈ PaLM 2-L+NExT ≫ PaLM 2-L), gợi ý rằng metric sau là một surrogate hợp lý cho chất lượng lý luận. Trong Phụ lục D, chúng tôi trình bày các lý luận được tạo ví dụ hiển thị nhiều mẫu suy luận khác nhau.

6. Công việc Liên quan

Suy luận về Thực thi Chương trình Một số dòng nghiên cứu đã khám phá các phương pháp học để suy luận về việc thực thi chương trình. Các hệ thống tổng hợp chương trình thường tận dụng trạng thái thực thi của các chương trình được tạo một phần (Chen et al., 2021b; Shi et al., 2022; Shin et al., 2018; Wang et al., 2018) hoặc các mục tiêu thực thi tiếp theo (Shi et al., 2024) để hướng dẫn tìm kiếm trong các mô hình sequence-to-sequence. Cũng có công việc về huấn luyện mạng neural để mô phỏng việc thực thi chương trình, như một trình thông dịch đã học (Bieber et al., 2020; Nye et al., 2021; Zaremba and Sutskever, 2014), thường với kiến trúc neural chuyên dụng để mô hình luồng dữ liệu của việc thực thi chương trình (Bieber et al., 2022; Bosnjak et al., 2016; Gaunt et al., 2016; Graves et al., 2014). Thay vì sử dụng kiến trúc cụ thể cho domain để mã hóa và suy luận về việc thực thi chương trình, công việc của chúng tôi tập trung vào dạy LLM suy luận với thực thi bằng ngôn ngữ tự nhiên. Cụ thể, Scratchpad (Nye et al., 2021) và Self-Debugging (Chen et al., 2023) là hai công việc đáng chú ý cũng mô hình dấu vết thực thi sử dụng LLM. Sự khác biệt cốt lõi là những phương pháp này tập trung vào dự đoán chuỗi suy luận chứa thông tin dấu vết, chẳng hạn như các dòng đã thực thi với trạng thái biến (Nye et al., 2021) hoặc tóm tắt ngôn ngữ tự nhiên của chúng (Chen et al., 2023). Mặt khác, NE xT nhằm tận dụng dấu vết thực thi hiện có từ một thời gian chạy để hỗ trợ quá trình suy luận, thường dẫn đến lý luận nhỏ gọn hơn được điều chỉnh cho các nhiệm vụ downstream. Chúng tôi trình bày so sánh chi tiết hơn và thảo luận về NE xT và những công việc liên quan này trong Phụ lục A.3.

Sửa chữa Chương trình Một số công việc trong sửa chữa chương trình đã tận dụng thông tin thực thi như dấu vết (Bouzenia et al., 2023; Gupta et al., 2020) hoặc chẩn đoán kiểm tra (Xia and Zhang, 2023; Ye et al., 2022). Khác với Bouzenia et al. (2023) đại diện dấu vết bằng cách trực tiếp ghép các dòng đã thực thi mở rộng với trạng thái biến của chúng, NE xT inline các trạng thái biến được lập chỉ mục như bình luận mã, hiệu quả hơn về token trong khi bảo tồn cấu trúc mã gốc. Tương tự như NE xT, Ye et al. (2022) xây dựng dữ liệu tự huấn luyện tổng hợp sử dụng kết quả thực thi kiểm tra, trong khi phương pháp của chúng tôi tạo ra cả lý luận NL và chương trình đã sửa với khả năng diễn giải tốt hơn. Gần đây, LLM đã được áp dụng cho sửa chữa chương trình (Fan et al., 2022; Jiang et al., 2023; Paul et al., 2023; Sobania et al., 2023; Xia and Zhang, 2022; Xia et al., 2023). Trong số đó, Kang et al. (2023) sử dụng vòng suy luận CoT kiểu ReAct (Yao et al., 2022) để dự đoán hành động sửa chữa dựa trên phản hồi tương tác từ debugger, trong khi NExT tập trung vào điều chỉnh LLM để suy luận với thông tin thực thi có sẵn mà không có phản hồi trung gian. Cuối cùng, như một dòng nghiên cứu liên quan, các phương pháp tự cải thiện lặp tinh chỉnh giải pháp mã của mô hình sử dụng suy luận CoT qua phản hồi tự cung cấp (Madaan et al., 2023) hoặc dựa trên kiểm tra (Chen et al., 2023; Olausson et al., 2023). Thay vì dựa vào tín hiệu thực thi cấp cao như thông báo lỗi, NE xT huấn luyện LLM suy luận với dấu vết chương trình từng bước. Lý luận có thể học của chúng tôi cũng linh hoạt hơn mà không theo template suy luận được định nghĩa trước. Bên cạnh đó, vì dấu vết đã nắm bắt ngữ nghĩa thực thi phong phú, lý luận kết quả có thể ngắn gọn hơn và hướng đến nhiệm vụ downstream (ví dụ: giải thích lỗi), mà không có các bước suy luận dư thừa để theo dõi chương trình bởi chính mô hình để khôi phục thông tin thực thi hữu ích.

Suy luận CoT Có giám sát LLM có thể giải quyết vấn đề chính xác hơn khi được hướng dẫn làm việc từng bước trong một chuỗi suy nghĩ hoặc scratchpad (Nye et al., 2021; Rajani et al., 2019; Shwartz et al., 2020; Wei et al., 2022a). Cải tiến về phương pháp này liên quan đến tinh chỉnh LLM trên dữ liệu suy luận chuỗi suy nghĩ. Dữ liệu CoT như vậy được tuyển chọn thủ công (Chung et al.,
11

--- TRANG 12 ---
NExT: Dạy các Mô hình Ngôn ngữ Lớn Suy luận về Thực thi Mã

2022; Lightman et al., 2023; Longpre et al., 2023), hoặc chưng cất từ các mô hình giáo viên có khả năng hơn (Fu et al., 2023; Gunasekar et al., 2023; Mitra et al., 2023; Mukherjee et al., 2023). Thay vì dựa vào dữ liệu được gắn nhãn hoặc chưng cất, NE xT sử dụng tự huấn luyện để lặp khởi tạo một bộ dữ liệu tổng hợp của lý luận chất lượng cao với chú thích thủ công tối thiểu. Công việc của chúng tôi khác với công việc trước đây sử dụng bootstrapping (Hoffman et al., 2023; Zelikman et al., 2022) về loại lý luận và việc sử dụng thông tin thực thi; xem §4 để thảo luận thêm. Trong khi chúng tôi sử dụng tính chính xác của sửa chữa chương trình để lọc lý luận, điều này gợi nhớ đến giám sát kết quả; cũng có thể sử dụng giám sát quy trình với chú thích con người (Lightman et al., 2023; Uesato et al., 2022), hoặc có được giám sát như vậy tự động bằng cách ước tính chất lượng của mỗi bước sử dụng Monte Carlo Tree Search (Wang et al., 2024) và bằng cách xác định các tiền tố chương trình đúng một phần (Ni et al., 2022). Cuối cùng, nghiên cứu hiện có đã điều tra tinh chỉnh LLM để dự đoán thông tin thực thi trực tiếp, chẳng hạn như dự đoán dấu vết thực thi từng dòng (Nye et al., 2021), thuộc tính runtime trừu tượng (Pei et al., 2023), hoặc đầu ra cuối cùng (Bieber et al., 2020; Zaremba and Sutskever, 2014). NE xT giải quyết một vấn đề khác; thay vì dự đoán thông tin thực thi, NE xT lấy nó như đã cho, và thay vào đó học khám phá lý luận NL linh hoạt cụ thể cho nhiệm vụ hỗ trợ nhiệm vụ lập trình downstream.

7. Kết luận

Trong bài báo này chúng tôi trình bày NE xT, một phương pháp tự huấn luyện để tinh chỉnh LLM suy luận với việc thực thi chương trình được cung cấp dấu vết. Chúng tôi chứng minh rằng PaLM 2-L được huấn luyện sử dụng NE xT mang lại lý luận ngôn ngữ tự nhiên chất lượng cao và đạt tỷ lệ thành công mạnh hơn trên hai nhiệm vụ sửa chữa chương trình. Như công việc tương lai, chúng tôi dự định áp dụng NE xT cho một loạt nhiệm vụ hiểu chương trình rộng hơn trong khi mở rộng đại diện dấu vết để hỗ trợ thêm các ngôn ngữ lập trình.

Lời cảm ơn

Chúng tôi muốn bày tỏ lòng biết ơn chân thành đến Martín Abadi, Xinyun Chen, Hanjun Dai, Kexin Pei và các thành viên của nhóm Learning for Code tại Google DeepMind vì phản hồi vô giá của họ. Chúng tôi cũng biết ơn Austin Tarango vì sự hỗ trợ của anh ấy cho công việc này.

Tài liệu tham khảo

R. Anil, A. M. Dai, O. Firat, M. Johnson, D. Lepikhin, A. Passos, S. Shakeri, E. Taropa, P. Bailey, Z. Chen, et al. PaLM 2 technical report. arXiv preprint arXiv:2305.10403, 2023.

T. W. Anthony, Z. Tian, và D. Barber. Thinking fast and slow with deep learning and tree search. Trong Neural Information Processing Systems (NeurIPS), 2017.

J. Austin, A. Odena, M. Nye, M. Bosma, H. Michalewski, D. Dohan, E. Jiang, C. Cai, M. Terry, Q. Le, et al. Program synthesis with large language models. arXiv preprint arXiv:2108.07732, 2021.

D. Bieber, C. Sutton, H. Larochelle, và D. Tarlow. Learning to execute programs with instruction pointer attention graph neural networks. Trong Advances in Neural Information Processing Systems (NeurIPS), Oct. 2020.

D. Bieber, R. Goel, D. Zheng, H. Larochelle, và D. Tarlow. Static prediction of runtime errors by learning to execute programs with external resource descriptions. ArXiv, abs/2203.03771, 2022.

M. Bosnjak, T. Rocktäschel, J. Naradowsky, và S. Riedel. Programming with a differentiable Forth interpreter. ArXiv, abs/1605.06640, 2016.

12

--- TRANG 13 ---
NExT: Dạy các Mô hình Ngôn ngữ Lớn Suy luận về Thực thi Mã

I. Bouzenia, Y. Ding, K. Pei, B. Ray, và M. Pradel. TraceFixer: Execution trace-driven program repair. ArXiv, abs/2304.12743, 2023.

M. Chen, J. Tworek, H. Jun, Q. Yuan, H. P. d. O. Pinto, J. Kaplan, H. Edwards, Y. Burda, N. Joseph, G. Brockman, et al. Evaluating large language models trained on code. arXiv preprint arXiv:2107.03374, 2021a.

X. Chen, D. X. Song, và Y. Tian. Latent execution for neural program synthesis beyond domain-specific languages. ArXiv, abs/2107.00101, 2021b.

X. Chen, M. Lin, N. Schärli, và D. Zhou. Teaching large language models to self-debug. arXiv preprint arXiv:2304.05128, 2023.

Z. Chen, S. Kommrusch, M. Tufano, L.-N. Pouchet, D. Poshyvanyk, và M. Martin. SequenceR: Sequence-to-sequence learning for end-to-end program repair. IEEE Transactions on Software Engineering, 47:1943–1959, 2018.

H. W. Chung, L. Hou, S. Longpre, B. Zoph, Y. Tay, W. Fedus, E. Li, X. Wang, M. Dehghani, S. Brahma, A. Webson, S. S. Gu, Z. Dai, M. Suzgun, X. Chen, A. Chowdhery, D. Valter, S. Narang, G. Mishra, A. W. Yu, V. Zhao, Y. Huang, A. M. Dai, H. Yu, S. Petrov, E. H. hsin Chi, J. Dean, J. Devlin, A. Roberts, D. Zhou, Q. V. Le, và J. Wei. Scaling instruction-finetuned language models. ArXiv, abs/2210.11416, 2022.

J. Cito, I. Dillig, V. Murali, và S. Chandra. Counterfactual explanations for models of code. International Conference on Software Engineering (ICSE), 2022.

P. Dasigi, M. Gardner, S. Murty, L. Zettlemoyer, và E. H. Hovy. Iterative search for weakly supervised semantic parsing. Trong North American Chapter of the Association for Computational Linguistics (NAACL), 2019.

S. Fakhoury, S. Chakraborty, M. Musuvathi, và S. K. Lahiri. Towards generating functionally correct code edits from natural language issue descriptions. ArXiv, abs/2304.03816, 2023.

Z. Fan, X. Gao, M. Mirchev, A. Roychoudhury, và S. H. Tan. Automated repair of programs from large language models. 2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE), pages 1469–1481, 2022.

Y. Fu, H.-C. Peng, L. Ou, A. Sabharwal, và T. Khot. Specializing smaller language models towards multi-step reasoning. Trong International Conference on Machine Learning (ICML), 2023.

A. L. Gaunt, M. Brockschmidt, N. Kushman, và D. Tarlow. Differentiable programs with neural libraries. Trong International Conference on Machine Learning (ICML), 2016.

A. Graves, G. Wayne, và I. Danihelka. Neural turing machines. ArXiv, abs/1410.5401, 2014.

S. Gunasekar, Y. Zhang, J. Aneja, C. C. T. Mendes, A. D. Giorno, S. Gopi, M. Javaheripi, P. C. Kauffmann, G. de Rosa, O. Saarikivi, A. Salim, S. Shah, H. S. Behl, X. Wang, S. Bubeck, R. Eldan, A. T. Kalai, Y. T. Lee, và Y.-F. Li. Textbooks are all you need. ArXiv, abs/2306.11644, 2023.

D. Guo, Q. Zhu, D. Yang, Z. Xie, K. Dong, W. Zhang, G. Chen, X. Bi, Y. Wu, Y. K. Li, F. Luo, Y. Xiong, và W. Liang. DeepSeek-Coder: When the large language model meets programming – the rise of code intelligence, 2024.

K. Gupta, P. E. Christensen, X. Chen, và D. X. Song. Synthesize, execute and debug: Learning to repair for neural program synthesis. ArXiv, abs/2007.08095, 2020.

13

--- TRANG 14 ---
NExT: Dạy các Mô hình Ngôn ngữ Lớn Suy luận về Thực thi Mã

A. Heinonen, B. Lehtelä, A. Hellas, và F. Fagerholm. Synthesizing research on programmers' mental models of programs, tasks and concepts - a systematic literature review. Inf. Softw. Technol., 164: 107300, 2022.

M. D. Hoffman, D. Phan, D. Dohan, S. Douglas, T. A. Le, A. T. Parisi, P. Sountsov, C. Sutton, S. Vikram, và R. A. Saurous. Training Chain-of-Thought via Latent-Variable inference. Trong Conference on Neural Information Processing Systems (NeurIPS), 2023.

X. Hu, G. Li, X. Xia, D. Lo, và Z. Jin. Deep code comment generation. 2018 IEEE/ACM 26th International Conference on Program Comprehension (ICPC), pages 200–20010, 2018.

A. Hunt và D. Thomas. The pragmatic programmer: From journeyman to master. 1999.

A. Q. Jiang, A. Sablayrolles, A. Roux, A. Mensch, B. Savary, C. Bamford, D. S. Chaplot, D. d. l. Casas, E. B. Hanna, F. Bressand, et al. Mixtral of experts. arXiv preprint arXiv:2401.04088, 2024.

N. Jiang, K. Liu, T. Lutellier, và L. Tan. Impact of code language models on automated program repair. 2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE), pages 1430–1442, 2023.

S. Kang, B. Chen, S. Yoo, và J.-G. Lou. Explainable automated debugging via large language model-driven scientific debugging. ArXiv, abs/2304.02195, 2023.

S. Kulal, P. Pasupat, K. Chandra, M. Lee, O. Padon, A. Aiken, và P. S. Liang. SPoC: Search-based pseudocode to code. Advances in Neural Information Processing Systems (NeurIPS), 32, 2019.

C. Le Goues, M. Pradel, và A. Roychoudhury. Automated program repair. Communications of the ACM, 62(12):56–65, 2019.

R. Li, L. B. Allal, Y. Zi, N. Muennighoff, D. Kocetkov, C. Mou, M. Marone, C. Akiki, J. Li, J. Chim, et al. StarCoder: may the source be with you! arXiv preprint arXiv:2305.06161, 2023.

Y. Li, S. Wang, và T. N. Nguyen. DLFix: Context-based code transformation learning for automated program repair. 2020 IEEE/ACM 42nd International Conference on Software Engineering (ICSE), pages 602–614, 2020.

Z. Li, S. Lu, D. Guo, N. Duan, S. Jannu, G. Jenks, D. Majumder, J. Green, A. Svyatkovskiy, S. Fu, và N. Sundaresan. Automating code review activities by large-scale pre-training. Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering, 2022.

C. Liang, M. Norouzi, J. Berant, Q. V. Le, và N. Lao. Memory augmented policy optimization for program synthesis and semantic parsing. Advances in Neural Information Processing Systems (NeurIPS), 31, 2018.

H. Lightman, V. Kosaraju, Y. Burda, H. Edwards, B. Baker, T. Lee, J. Leike, J. Schulman, I. Sutskever, và K. Cobbe. Let's verify step by step. arXiv preprint arXiv:2305.20050, 2023.

J. Liu, C. S. Xia, Y. Wang, và L. Zhang. Is your code generated by chatgpt really correct? rigorous evaluation of large language models for code generation. arXiv preprint arXiv:2305.01210, 2023.

S. Longpre, L. Hou, T. Vu, A. Webson, H. W. Chung, Y. Tay, D. Zhou, Q. V. Le, B. Zoph, J. Wei, và A. Roberts. The flan collection: Designing data and methods for effective instruction tuning. Trong International Conference on Machine Learning (ICML), 2023.

14

--- TRANG 15 ---
NExT: Dạy các Mô hình Ngôn ngữ Lớn Suy luận về Thực thi Mã

W. Ma, S. Liu, W. Wang, Q. Hu, Y. Liu, C. Zhang, L. Nie, và Y. Liu. ChatGPT: Understanding code syntax and semantics. 2023.

A. Madaan, N. Tandon, P. Gupta, S. Hallinan, L. Gao, S. Wiegreffe, U. Alon, N. Dziri, S. Prabhumoye, Y. Yang, S. Welleck, B. P. Majumder, S. Gupta, A. Yazdanbakhsh, và P. Clark. Self-refine: Iterative refinement with self-feedback. ArXiv, abs/2303.17651, 2023.

A. Mitra, L. D. Corro, S. Mahajan, A. Codas, C. Simoes, S. Agrawal, X. Chen, A. Razdaibiedina, E. Jones, K. Aggarwal, H. Palangi, G. Zheng, C. Rosset, H. Khanpour, và A. Awadallah. Orca 2: Teaching small language models how to reason. ArXiv, abs/2311.11045, 2023.

N. Muennighoff, Q. Liu, A. Zebaze, Q. Zheng, B. Hui, T. Y. Zhuo, S. Singh, X. Tang, L. Von Werra, và S. Longpre. OctoPack: Instruction tuning code large language models. arXiv preprint arXiv:2308.07124, 2023.

S. Mukherjee, A. Mitra, G. Jawahar, S. Agarwal, H. Palangi, và A. H. Awadallah. Orca: Progressive learning from complex explanation traces of GPT-4. ArXiv, abs/2306.02707, 2023.

A. Ni, P. Yin, và G. Neubig. Merging weak and active supervision for semantic parsing. Trong Proceedings of the AAAI Conference on Artificial Intelligence (AAAI), volume 34, pages 8536–8543, 2020.

A. Ni, J. P. Inala, C. Wang, A. Polozov, C. Meek, D. Radev, và J. Gao. Learning math reasoning from self-sampled correct and partially-correct solutions. Trong The Eleventh International Conference on Learning Representations (ICLR), 2022.

A. Ni, S. Iyer, D. Radev, V. Stoyanov, W.-t. Yih, S. Wang, và X. V. Lin. LEVER: Learning to verify language-to-code generation with execution. Trong International Conference on Machine Learning (ICML), pages 26106–26128. PMLR, 2023.

M. Nye, A. J. Andreassen, G. Gur-Ari, H. Michalewski, J. Austin, D. Bieber, D. Dohan, A. Lewkowycz, M. Bosma, D. Luan, et al. Show your work: Scratchpads for intermediate computation with language models. arXiv preprint arXiv:2112.00114, 2021.

T. X. Olausson, J. P. Inala, C. Wang, J. Gao, và A. Solar-Lezama. Demystifying GPT self-repair for code generation. arXiv preprint arXiv:2306.09896, 2023.

OpenAI. GPT-4 technical report, 2023.

R. Paul, M. M. Hossain, M. L. Siddiq, M. Hasan, A. Iqbal, và J. C. S. Santos. Enhancing automated program repair through fine-tuning and prompt engineering. 2023.

K. Pei, D. Bieber, K. Shi, C. Sutton, và P. Yin. Can large language models reason about program invariants? Trong International Conference on Machine Learning (ICML), 2023.

A. Prasad, S. Saha, X. Zhou, và M. Bansal. Receval: Evaluating reasoning chains via correctness and informativeness. arXiv preprint arXiv:2304.10703, 2023.

N. F. Rajani, B. McCann, C. Xiong, và R. Socher. Explain yourself! leveraging language models for commonsense reasoning. Trong Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics (ACL), pages 4932–4942, Florence, Italy, July 2019. Association for Computational Linguistics. doi: 10.18653/v1/P19-1487.

S. I. Ross, F. Martinez, S. Houde, M. J. Muller, và J. D. Weisz. The programmer's assistant: Conversational interaction with a large language model for software development. Proceedings of the 28th International Conference on Intelligent User Interfaces, 2023.

15

--- TRANG 16 ---
NExT: Dạy các Mô hình Ngôn ngữ Lớn Suy luận về Thực thi Mã

B. Roziere, J. Gehring, F. Gloeckle, S. Sootla, I. Gat, X. E. Tan, Y. Adi, J. Liu, T. Remez, J. Rapin, et al. Code Llama: Open foundation models for code. arXiv preprint arXiv:2308.12950, 2023.

K. Shi, H. Dai, K. Ellis, và C. Sutton. CrossBeam: Learning to search in bottom-up program synthesis. Trong International Conference on Learning Representations (ICLR), 2022.

K. Shi, J. Hong, Y. Deng, P. Yin, M. Zaheer, và C. Sutton. ExeDec: Execution decomposition for compositional generalization in neural program synthesis. Trong International Conference on Learning Representations (ICLR), 2024.

E. C. Shin, I. Polosukhin, và D. Song. Improving neural program synthesis with inferred execution traces. Trong S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, và R. Garnett, editors, Advances in Neural Information Processing Systems (NeurIPS), volume 31. Curran Associates, Inc., 2018.

V. Shwartz, P. West, R. Le Bras, C. Bhagavatula, và Y. Choi. Unsupervised commonsense question answering with self-talk. Trong Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 4615–4629, Online, Nov. 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.emnlp-main.373.

B. Siegmund, M. Perscheid, M. Taeumel, và R. Hirschfeld. Studying the advancement in debugging practice of professional software developers. Trong 2014 IEEE International Symposium on Software Reliability Engineering Workshops, pages 269–274, 2014. doi: 10.1109/ISSREW.2014.36.

D. Sobania, M. Briesch, C. Hanna, và J. Petke. An analysis of the automatic bug fixing performance of ChatGPT. 2023 IEEE/ACM International Workshop on Automated Program Repair (APR), pages 23–30, 2023.

H. Touvron, L. Martin, K. Stone, P. Albert, A. Almahairi, Y. Babaei, N. Bashlykov, S. Batra, P. Bhargava, S. Bhosale, et al. Llama 2: Open foundation and fine-tuned chat models. arXiv preprint arXiv:2307.09288, 2023.

J. Uesato, N. Kushman, R. Kumar, F. Song, N. Siegel, L. Wang, A. Creswell, G. Irving, và I. Higgins. Solving math word problems with process- and outcome-based feedback. ArXiv, abs/2211.14275, 2022.

C. Wang, K. Tatwawadi, M. Brockschmidt, P.-S. Huang, Y. Mao, O. Polozov, và R. Singh. Robust text-to-SQL generation with execution-guided decoding. arXiv: Computation and Language, 2018.

P. Wang, L. Li, Z. Shao, R. X. Xu, D. Dai, Y. Li, D. Chen, Y. Wu, và Z. Sui. Math-shepherd: Verify and reinforce llms step-by-step without human annotations. ArXiv, abs/2312.08935, 2024.

J. Wei, X. Wang, D. Schuurmans, M. Bosma, E. Chi, Q. Le, và D. Zhou. Chain of thought prompting elicits reasoning in large language models. "arXiv preprint arXiv:2201.11903", Jan. 2022a.

J. Wei, X. Wang, D. Schuurmans, M. Bosma, F. Xia, E. Chi, Q. V. Le, D. Zhou, et al. Chain-of-thought prompting elicits reasoning in large language models. Advances in Neural Information Processing Systems (NeurIPS), 35:24824–24837, 2022b.

C. Xia và L. Zhang. Less training, more repairing please: revisiting automated program repair via zero-shot learning. Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering, 2022.

C. Xia và L. Zhang. Keep the conversation going: Fixing 162 out of 337 bugs for $0.42 each using ChatGPT. ArXiv, abs/2304.00385, 2023.

16

--- TRANG 17 ---
NExT: Dạy các Mô hình Ngôn ngữ Lớn Suy luận về Thực thi Mã

C. Xia, Y. Wei, và L. Zhang. Automated program repair in the era of large pre-trained language models. 2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE), pages 1482–1494, 2023.

S. Yao, J. Zhao, D. Yu, N. Du, I. Shafran, K. Narasimhan, và Y. Cao. ReAct: Synergizing reasoning and acting in language models. ArXiv, abs/2210.03629, 2022.

H. Ye, M. Martinez, X. Luo, T. Zhang, và M. Martin. SelfAPR: Self-supervised program repair with test execution diagnostics. Proceedings of the 37th IEEE/ACM International Conference on Automated Software Engineering (ASE), 2022.

P. Yin, W.-D. Li, K. Xiao, A. Rao, Y. Wen, K. Shi, J. Howland, P. Bailey, M. Catasta, H. Michalewski, O. Polozov, và C. Sutton. Natural language to code generation in interactive data science notebooks. Trong A. Rogers, J. Boyd-Graber, và N. Okazaki, editors, Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (ACL), pages 126–173, Toronto, Canada, July 2023. Association for Computational Linguistics. doi: 10.18653/v1/2023.acl-long.9.

W. Zaremba và I. Sutskever. Learning to execute. ArXiv, abs/1410.4615, 2014.

E. Zelikman, Y. Wu, J. Mu, và N. Goodman. STaR: Bootstrapping reasoning with reasoning. Advances in Neural Information Processing Systems (NeurIPS), 35:15476–15488, 2022.

17

--- TRANG 18 ---
NExT: Dạy các Mô hình Ngôn ngữ Lớn Suy luận về Thực thi Mã

A. Chi tiết Bổ sung của NE xT

A.1. Chi tiết cho Đại diện Dấu vết Nội tuyến

Định nghĩa. Một chương trình 𝑦∈Y bao gồm một chuỗi các câu lệnh {𝑢1,...,𝑢𝑚}. Và một trạng thái chương trình ℎ là một ánh xạ giữa các định danh (tức là tên biến) và giá trị, tức là ℎ∈{𝑘↦→𝑣|𝑘∈K,𝑣∈V}. Được cung cấp một đầu vào cho chương trình, một dấu vết thực thi được định nghĩa là một chuỗi các trạng thái chương trình, tức là 𝜖={ℎ1,...,ℎ𝑡}, là kết quả sau khi thực thi các câu lệnh với thứ tự thực thi, tức là {𝑢𝑒1,𝑢𝑒2,...,𝑢𝑒𝑡}. Theo cách này, mối quan hệ giữa các câu lệnh chương trình và trạng thái thực thi có thể được xem như một hàm ánh xạ từ trạng thái đến câu lệnh, tức là ℎ𝑖↦→𝑢𝑒𝑖, bởi vì mỗi câu lệnh có thể được thực thi nhiều lần do vòng lặp hoặc đệ quy.

Đại diện trạng thái chương trình. Đối với các chương trình điển hình, hầu hết các giá trị biến sẽ giữ nguyên giữa hai trạng thái liền kề ℎ𝑖−1 và ℎ𝑖. Do đó để tiết kiệm token, chúng tôi đại diện cho một trạng thái ℎ𝑖 chỉ bằng các biến đã thay đổi giá trị so với trạng thái trước đó ℎ𝑖−1. Và chúng tôi sử dụng một đại diện trạng thái biến cụ thể hóa, tức là sử dụng ngữ pháp cho một hàm init trong Python (ví dụ: lst=[1, 2, 3]). Lưu ý rằng có thể một câu lệnh không có tác dụng lên bất kỳ biến có thể theo dõi nào (ví dụ: "pass", hoặc "print", hoặc "lst[i]=lst[i]"). Để phân biệt trường hợp này với các câu lệnh không được đến (ví dụ: nhánh "else" không được thực thi tiếp theo), chúng tôi thêm chuỗi "NO_CHANGE" thay thế. Ngoài trạng thái biến, chúng tôi đánh số tất cả các trạng thái theo thứ tự thực thi và thêm số thứ tự vào đầu trạng thái, ví dụ: "(1) odd_list=[]" trong Hình 2.

Đại diện dấu vết nội tuyến. Để có được đại diện dấu vết nội tuyến, trước tiên chúng tôi nhóm các trạng thái chương trình trong một dấu vết 𝜖 theo các câu lệnh chương trình tương ứng để thu thập một chuỗi trạng thái cho cùng một câu lệnh 𝑢𝑖 là 𝐻𝑖={ℎ𝑗|𝑢𝑒𝑗=𝑢𝑖}, và chúng tôi sắp xếp các trạng thái trong 𝐻𝑖 theo thứ tự thực thi. Đối với các câu lệnh bên trong thân vòng lặp, hoặc một hàm được gọi đệ quy, số lượng trạng thái tương ứng có thể rất lớn. Để tiết kiệm thêm token, nếu |𝐻𝑖|>3, chúng tôi sẽ chỉ kết hợp hai trạng thái đầu tiên và trạng thái cuối cùng, và bỏ qua những trạng thái ở giữa. Sau đó, chúng tôi chỉ đơn giản nối tất cả các đại diện trạng thái với dấu chấm phẩy ";" làm dấu phân cách, và thêm nó sau chính câu lệnh 𝑢𝑖 theo sau dấu thăng "#" để chú thích nó như một bình luận nội tuyến. Một ví dụ về đại diện kết quả là "even_list.append(n) # (4) even_list=[1]; (8) even_list=[1, 3]; ...; (20) even_list=[1, 3, 5, 7, 9];", như được hiển thị trong Hình 2.

Hạn chế. Trước tiên, framework theo dõi của chúng tôi hiện tại không mở rộng ra ngoài các chương trình Python gốc, do đó không thể theo dõi mã không được viết bằng Python (ví dụ: mã C trong numpy). Một hạn chế khác của đại diện theo dõi của chúng tôi là đối với các điều kiện "if", mặc dù sẽ tốt hơn nếu để lại dấu vết của "(1) True; (2) True; (3); False;", hiện tại framework theo dõi của chúng tôi dựa trên hook "sys.settrace()" của Python không nắm bắt được điều này. Tuy nhiên, vì chúng tôi đã gắn nhãn tất cả các trạng thái theo thứ tự thực thi, LLM có thể suy luận các điều kiện bằng việc nhánh nhất định được thực hiện. Một hạn chế khác là đại diện của Bộ sưu tập. Hiện tại chúng tôi vẫn trình bày tất cả các phần tử trong một bộ sưu tập, và thực nghiệm nó hoạt động tốt với các benchmark như Mbpp-R và HeFix+. Tuy nhiên, có thể cần các heuristic nhất định để bỏ qua các phần tử nhất định (ví dụ: như cái chúng tôi sử dụng để bỏ qua các trạng thái nhất định trong vòng lặp) để hiệu quả hơn về token. Đối với các đối tượng phức tạp hơn (ví dụ: Tensor, DataFrame), trong khi chúng ta có thể định nghĩa heuristic để đại diện cho các thuộc tính chính của những đối tượng đó trong dấu vết (ví dụ: "một tensor float có shape 128 x 64", "một Dataframe với các cột Name, Math, ..."), có lẽ một ý tưởng thú vị hơn sẽ là để các mô hình quyết định thuộc tính nào chúng sẽ kiểm tra và tạo mã liên quan (ví dụ: "tensor.shape" hoặc "df.head(3)") để kiểm tra chúng trong debugger hoặc interpreter (ví dụ: pdb). Ý tưởng tương tự có thể được áp dụng cho các chương trình dài hơn, vì mô hình có thể quyết định có chọn lọc dòng mã nào để kiểm tra và tạo dấu vết cho, tương tự như cách các nhà phát triển con người gỡ lỗi chương trình. Chúng tôi sẽ để lại những hướng tương lai thú vị này.

18

--- TRANG 19 ---
NExT: Dạy các Mô hình Ngôn ngữ Lớn Suy luận về Thực thi Mã

Phương pháp Sử dụng Dấu vết Định dạng Lý luận Tinh chỉnh Mô hình
NExT Đầu vào Ngôn ngữ Tự nhiên Có
Scratchpad (Nye et al., 2021) Đầu ra Đại diện Scratchpad Có
Self-Debugging (Chen et al., 2023) Đầu ra Ngôn ngữ Tự nhiên Không

Bảng 6|So sánh giữa các phương pháp được đề xuất trong NE xT, Scratchpad, và Self-Debugging.

Đại diện Dấu vết Ngưỡng Độ dài (# Token)
128 256 512 1,024 2,048 4,096 8,192 16,384
Nội tuyến (của chúng tôi) 0.1% 7.3% 37.5% 78.9% 95.1% 98.5% 99.2% 99.5%
Scratchpad 0.0% 0.2% 15.1% 38.2% 60.1% 76.1% 85.1% 92.1%

Bảng 7|Tỷ lệ phần trăm các ví dụ Mbpp-R có thể vừa vào các cửa sổ ngữ cảnh khác nhau sử dụng các đại diện dấu vết khác nhau (tức là của chúng tôi và Nye et al. (2021)). Dấu vết của cả ba kiểm tra được bao gồm.

A.2. Chi tiết cho Tự huấn luyện Lặp

Khởi tạo lý luận và sửa chữa thông qua lấy mẫu nhiệt độ. Để tránh vấn đề "khởi động lạnh" tiềm năng (Liang et al., 2018; Ni et al., 2020), cho lần lặp đầu tiên, chúng tôi sử dụng prompting ít mẫu với ba exemplar (được hiển thị trong Phụ lục E) và đặt kích thước mẫu là 96. Đối với tất cả các lần lặp sau, chúng tôi sử dụng prompting zero-shot vì mô hình đã được điều chỉnh theo phong cách của lý luận và sửa chữa sau vòng tinh chỉnh đầu tiên, và chúng tôi đặt kích thước mẫu là 32. Chúng tôi đặt nhiệt độ lấy mẫu 𝑇=0.8 cho tất cả các lần lặp.

Lọc lý luận và sửa chữa. Được cung cấp các đầu vào trong prompt, chúng tôi lấy mẫu lý luận và sửa chữa cùng nhau. Để tách lý luận ngôn ngữ tự nhiên và sửa chữa chương trình, chúng tôi sử dụng biểu thức chính quy trong Python để trích xuất nội dung giữa hai bộ ba dấu backtick (```), thường được sử dụng để chú thích các khối mã trong markdown.6 Sau khi chúng tôi lọc ra các lý luận và sửa chữa không chính xác sử dụng các trường hợp kiểm tra, chúng tôi tạo tập huấn luyện bằng cách lấy mẫu con các cặp "(lý luận, sửa chữa)" chính xác để cho phép tối đa 3 sửa chữa chính xác với lý luận của chúng cho mỗi vấn đề trong Mbpp-R. Điều này là để cân bằng số lượng lý luận và sửa chữa cho mỗi vấn đề và tránh các ví dụ từ một số ví dụ nhất định (thường là những ví dụ dễ hơn) được đại diện quá mức trong tập huấn luyện.

A.3. Thảo luận với Công việc Trước đây

Ở đây chúng tôi thảo luận NE xT trong bối cảnh hai công việc quan trọng trước đây trong lĩnh vực suy luận về việc thực thi chương trình, cụ thể là Scratchpad (Nye et al., 2021) và Self-Debugging Chen et al. (2023). So sánh như vậy cũng được đặc trưng bởi Bảng 6.

Scratchpad và NE xT. Tương tự như NE xT, Nye et al. (2021) cũng đề xuất sử dụng dấu vết thực thi để giúp LLM suy luận về việc thực thi chương trình. Tuy nhiên, Nye et al. (2021) nhằm tạo ra những dấu vết này như các bước suy luận trung gian tại thời gian suy luận, thông qua prompting ít mẫu hoặc tinh chỉnh mô hình. Nhưng trong NE xT, chúng tôi sử dụng dấu vết thực thi như một phần của đầu vào cho LLM, để chúng có thể trực tiếp sử dụng trạng thái thực thi để củng cố lý luận ngôn ngữ tự nhiên được tạo. Hơn nữa, chúng tôi chọn sử dụng ngôn ngữ tự nhiên như định dạng chính để suy luận, linh hoạt hơn và dễ hiểu hơn cho các lập trình viên con người. Chúng tôi cũng thực hiện so sánh độ dài đại diện dấu vết nội tuyến được đề xuất của chúng tôi với đại diện scratchpad được đề xuất trong Bảng 7, và kết quả cho thấy đại diện dấu vết nội tuyến được đề xuất của chúng tôi nhỏ gọn hơn nhiều so với scratchpad.

Self-Debugging và NE xT. Self-Debugging (Chen et al., 2023) là một phương pháp tinh thần cũng thực hiện suy luận CoT qua việc thực thi chương trình để xác định lỗi trong giải pháp mã. Khác với NExT, Self-Debugging có thể tùy chọn tận dụng thông báo lỗi thực thi cấp cao để khởi tạo suy luận CoT, trong khi phương pháp của chúng tôi huấn luyện LLM suy luận với dấu vết thực thi cụ thể từng bước. Ngoài ra, Self-Debugging cũng giới thiệu một dạng lý luận CoT cụ thể giống như dấu vết từng bước bằng ngôn ngữ tự nhiên. Đáng chú ý, những lý luận như vậy được tạo bởi LLM để hỗ trợ mô hình định vị lỗi bằng cách mô phỏng thực thi theo cách từng bước. Chúng không phải là dấu vết thực thi thực sự được tạo bằng cách thực sự chạy chương trình. Như chúng tôi đã thảo luận trong §6, ngược lại, mô hình của chúng tôi dựa vào dấu vết hiện có từ việc thực thi chương trình. Vì những dấu vết đó đã nắm bắt thông tin thực thi phong phú, trực quan, lý luận CoT kết quả trong NE xT có thể ngắn gọn hơn và "đúng trọng tâm" mà không có các bước suy luận dư thừa để "theo dõi" chương trình từng bước bởi chính mô hình để khôi phục thông tin thực thi hữu ích.

Cuối cùng, chúng tôi nhận xét rằng thiết lập "Test w/o Trace" của chúng tôi trong §5.1 chia sẻ tinh thần tương tự với thiết lập trong Self-Debugging, vì cả hai phương pháp đều thực hiện suy luận CoT về thực thi mà không có dấu vết thực thi vàng. Từ kết quả trong Bảng 3, NE xT cũng cải thiện đáng kể khả năng sửa chữa chương trình của mô hình ngay cả khi không sử dụng dấu vết thực thi vàng tại thời gian kiểm tra. Điều này có thể gợi ý rằng NE xT có thể cải thiện kỹ năng tự gỡ lỗi của LLM thông qua huấn luyện lặp, mà chúng tôi để lại như công việc tương lai thú vị để khám phá.

B. Chi tiết Thiết lập Thí nghiệm

B.1. Tạo Mbpp-R

Bộ dữ liệu Mbpp gốc Austin et al. (2021) bao gồm ba phần chia, tức là tập train/dev/test của 374/90/500 vấn đề lập trình Python. Để tăng số lượng ví dụ huấn luyện, trước tiên chúng tôi thực hiện phân chia lại bộ dữ liệu Mbpp gốc, bằng cách chuyển một nửa dữ liệu kiểm tra vào phần chia huấn luyện, kết quả là 624/90/250 vấn đề trong bộ dữ liệu được phân chia lại. Sau đó đối với mỗi vấn đề Mbpp trong tập train và dev được phân chia lại, chúng tôi thu thập một tập các giải pháp thất bại từ đầu ra mô hình được phát hành trong Ni et al. (2023). Cụ thể hơn, chúng tôi lấy 100 mẫu cho mỗi vấn đề, lọc ra những giải pháp chính xác, và giữ lại những giải pháp không vượt qua tất cả các kiểm tra. Vì các vấn đề khác nhau có số lượng giải pháp lỗi khác nhau, chúng tôi cân bằng điều này bằng cách giữ tối đa 20 giải pháp lỗi cho mỗi vấn đề Mbpp.7 Điều này mang lại bộ dữ liệu Mbpp-R, với 10,047 nhiệm vụ sửa chữa trong tập huấn luyện và 1,468 ví dụ trong tập dev.

B.2. Sử dụng trường hợp kiểm tra.

Đối với mỗi nhiệm vụ sửa chữa chương trình, thường có một tập các trường hợp kiểm tra mở được sử dụng cho mục đích gỡ lỗi, cũng như một tập các trường hợp kiểm tra ẩn chỉ được sử dụng để đánh giá tính chính xác. Khi chúng tôi tạo dấu vết sử dụng trường hợp kiểm tra, chúng tôi chỉ sử dụng các trường hợp kiểm tra mở và chỉ cung cấp các trường hợp kiểm tra mở cho mô hình như một phần của prompt. Sau đó khi chúng tôi đánh giá sửa chữa được tạo, chúng tôi sử dụng tất cả trường hợp kiểm tra (tức là kiểm tra mở + ẩn) và chỉ coi một sửa chữa là chính xác khi nó vượt qua tất cả trường hợp kiểm tra. Trong khi bộ dữ liệu HumanEval tạo sự phân biệt này giữa trường hợp kiểm tra mở và kiểm tra, bộ dữ liệu Mbpp không tạo sự phân biệt như vậy. Do đó đối với Mbpp-R, chúng tôi sử dụng tất cả trường hợp kiểm tra cả làm đầu vào và trong quá trình đánh giá. Trong khi điều này có thể dẫn đến kết quả dương tính giả khi các sửa chữa được overfitted với trường hợp kiểm tra, và chúng tôi đã tìm thấy trường hợp như vậy trong quá trình chú thích con người.

Hình 5|Hướng dẫn cho người chú thích con người khi chú thích chất lượng lý luận được tạo bởi mô hình.

21

--- TRANG 22 ---
NExT: Dạy các Mô hình Ngôn ngữ Lớn Suy luận về Thực thi Mã

B.3. Chi tiết Chú thích Con người về Chất lượng Lý luận

Chúng tôi chú thích dự đoán mô hình trên 104 nhiệm vụ sửa chữa Mbpp-R được lấy mẫu từ tập Dev. Những nhiệm vụ sửa chữa đó được lấy mẫu ngẫu nhiên trong khi đảm bảo rằng chúng bao phủ tất cả 90 vấn đề dev Mbpp. Tất cả các nhiệm vụ được sàng lọc trước để là các vấn đề sửa chữa chương trình hợp lệ. Chú thích được thực hiện trong thiết lập side-by-side ba chiều. Các mô hình được ẩn danh và thứ tự của chúng được ngẫu nhiên hóa. Người đánh giá được yêu cầu đánh giá chất lượng lý luận từ ba mô hình (PaLM 2-L +NExT, PaLM 2-L và GPT-3.5) trên cùng một vấn đề Mbpp-R. Mỗi lý luận được đánh giá từ hai khía cạnh: (1) tính hữu ích trong việc giải thích lỗi (𝑄1: Lý luận có giải thích chính xác lỗi trong mã gốc không? ví dụ: hai đoạn đầu trong ˆ𝑟, Hình 1), và (2) tính hữu ích trong việc đề xuất sửa chữa mã (𝑄2: Lý luận có đề xuất sửa chữa chính xác và hữu ích không? ví dụ: "một phiên bản đã sửa sử dụng ..." trong ˆ𝑟, Hình 1).8 Mỗi câu hỏi có câu trả lời ba thang đo (
 Hoàn toàn chính xác và rất hữu ích;
 Một phần chính xác với lỗi nhỏ nhưng vẫn hữu ích;
 Không chính xác và không hữu ích). Trong một nghiên cứu thí điểm, chúng tôi thấy rằng các đề xuất sửa chữa thường có thể dư thừa nếu lý luận đã chứa giải thích chi tiết về lỗi sao cho nhà phát triển có thể dễ dàng sửa mã mà không cần đề xuất sửa chữa rõ ràng (ví dụ: Ví dụ 2, Phụ lục D). Do đó, đối với 𝑄2, chúng tôi cũng coi những trường hợp như vậy là chính xác (
) nếu một mô hình không đề xuất sửa chữa trong lý luận của nó nhưng sửa chữa rõ ràng sau giải thích lỗi. Chúng tôi liệt kê hướng dẫn chú thích của chúng tôi trong Hình 5. Lưu ý rằng đối với 𝑄2, cả câu trả lời (1) và (3) đều được tính là câu trả lời chính xác (
).

C. Kết quả Thí nghiệm Bổ sung

Ở đây chúng tôi hiển thị đường cong học của NE xT và tất cả các ablation của nó trong Hình 6. Chúng tôi cũng hiển thị kết quả đầy đủ cho Mbpp-R và HeFix+ lần lượt trong Bảng 8 và Bảng 9.

Học lý luận CoT cải thiện thêm pass@25. Từ §5.1, chúng tôi đề cập rằng học suy luận bằng ngôn ngữ tự nhiên cải thiện tính đa dạng mẫu, đăng ký pass@10 cao hơn so với baseline tinh chỉnh chỉ để tạo sửa chữa (NExT w/o Rationale). Từ Bảng 8 và Bảng 9, chúng ta có thể quan sát rằng lợi thế hiệu suất như vậy thậm chí lớn hơn với pass@25, với cải thiện 7.6% trên Mbpp-R và 6.8% trên HeFix+.

Huấn luyện chỉ trên các ví dụ khó. Một phần của pipeline lọc dữ liệu của chúng tôi là chỉ thực hiện lấy mẫu và huấn luyện trên các mẫu từ vấn đề khó (§4). Ở đây chúng tôi thảo luận thêm về lợi ích và vấn đề tiềm năng của việc làm như vậy, bằng cách trình bày kết quả trên một ablation "w/o hard-only", nơi mô hình học từ lý luận và sửa chữa từ cả ví dụ khó và dễ. Về hiệu quả, bằng cách chỉ lấy mẫu trên ví dụ khó, khoảng một nửa số vấn đề, chúng ta có thể tăng tốc đáng kể quá trình lấy mẫu. Và từ kết quả trong Hình 6, chỉ huấn luyện với ví dụ khó cũng mang lại lợi ích hiệu suất dưới framework tự huấn luyện lặp. Cụ thể hơn, chúng tôi nhận thấy một khoảng cách không tầm thường giữa đường cong huấn luyện của baseline "w/o hard-only" này và phần còn lại của các ablation, đặc biệt đối với hiệu suất pass@10 và pass@25 trên tập huấn luyện. Điều này có nghĩa là mô hình được huấn luyện trên cả ví dụ dễ và khó dẫn đến nhiều vấn đề hơn trong tập huấn luyện không được giải quyết (tức là không có mẫu nào chính xác), và không có tín hiệu học nào có thể đến từ những vấn đề như vậy. Điều này cũng phản ánh trên hiệu suất tập dev. Trong khi đáng chú ý rằng hiệu suất pass@1 end-to-end cho "w/o hard-only" hơi tốt hơn NE xT chỉ được huấn luyện trên các ví dụ khó, nó hoạt động tệ hơn trong tất cả các đánh giá khác, với xu hướng khoảng cách lớn hơn với giá trị 𝑘 cao hơn cho pass@𝑘, đặc biệt đối với đánh giá dựa proxy. Điều này cho thấy rằng huấn luyện trên các ví dụ khó không chỉ cải thiện hiệu quả mẫu, mà còn cải thiện tỷ lệ sửa chữa tổng quát cũng như chất lượng lý luận được tạo.

22

--- TRANG 23 ---
NExT: Dạy các Mô hình Ngôn ngữ Lớn Suy luận về Thực thi Mã

Pass@1Pass@5Pass@10Pass@25Train
Dev -E2E Fix Rate
Dev -ProxyFix Rate102030405060708090100
02468
102030405060
02468
010203040
02468405060708090100
02468
4050607080
02468
2030405060
02468405060708090100
02468
4050607080
02468
3040506070
024685060708090100
02468
5060708090
02468
4050607080
02468

Hình 6|Hiệu suất pass@𝑘 trên tập train và dev của Mbpp-R cho NE xT và tất cả các ablation của nó.

Kết quả đánh giá dựa proxy nhất quán với các mô hình proxy khác nhau. Trong đánh giá dựa proxy trước đây §5.1, chúng tôi báo cáo tỷ lệ sửa chữa dựa proxy bằng cách lấy trung bình trên hiệu suất sử dụng PaLM 2-S và PaLM 2-S∗ làm mô hình proxy. Trong Bảng 8 và Bảng 9, chúng tôi hiển thị kết quả tách biệt cho các mô hình proxy khác nhau. Từ những kết quả này, chúng ta có thể quan sát rằng chất lượng lý luận tương đối được đánh giá bởi các mô hình proxy khác nhau phần lớn nhất quán, với mô hình proxy mạnh hơn (PaLM 2-S∗) có tỷ lệ sửa chữa dựa proxy tốt hơn. Ngoài tính nhất quán mà chúng tôi hiển thị với chú thích con người, điều này cho thấy tính mạnh mẽ của phương pháp đánh giá dựa proxy được đề xuất của chúng tôi để đo lường chất lượng lý luận CoT.

D. Nghiên cứu Trường hợp

Trong phần này chúng tôi trình bày một tập các ví dụ để thể hiện cách PaLM 2-L +NExT suy luận với việc thực thi chương trình để giải quyết các vấn đề Mbpp-R. Chúng tôi khám phá một số mẫu suy luận mà mô hình thể hiện tận dụng thông tin dấu vết để xác định và giải thích lỗi trong chương trình. Đầu tiên, như được hiển thị trong Ví dụ 1, mô hình có thể tham chiếu đến ngoại lệ hoặc thông báo lỗi trong dấu vết (ví dụ trong Dấu vết 2) để giải thích lỗi trong mã. Tiếp theo, Ví dụ 2 cho thấy rằng mô hình cũng có thể tận dụng trạng thái biến trong dấu vết (ví dụ: trong Dấu vết 2) và so sánh chúng với giá trị mong đợi để định vị nguyên nhân lỗi. Bên cạnh đó, các chú thích NO_CHANGE cho các biến có giá trị được bảo tồn sau khi thực thi một bước cũng có thể giúp mô hình giải thích quá trình thực thi trong lý luận (ví dụ: (3)NO_CHANGE↦→ "danh sách con đầu tiên đã được sắp xếp"). Có lẽ một tình huống thú vị hơn là khi mô hình suy luận qua nhiều bước tính toán để theo dõi nguyên nhân lỗi. Trong Ví dụ 3, mô hình cố gắng theo dõi việc tính toán của các bước 2 - 4 trong Dấu vết 1 để giải thích tại sao tổng là một số thực thay vì số nguyên. Một ví dụ khác là Ví dụ 4, nơi mô hình tóm tắt các lần lặp vòng lặp trong
23

--- TRANG 24 ---
NExT: Dạy các Mô hình Ngôn ngữ Lớn Suy luận về Thực thi Mã

Mô hìnhTỷ lệ Sửa chữa End-to-End Tỷ lệ Sửa chữa dựa Proxy (PaLM 2–S) Tỷ lệ Sửa chữa dựa Proxy (PaLM 2–S∗)
GD pass@𝑘w/ Sampling GD pass@𝑘w/ Sampling GD pass@𝑘w/ Sampling
Acc.𝑘=1𝑘=5𝑘=10𝑘=25 Acc. 𝑘=1𝑘=5𝑘=10𝑘=25 Acc. 𝑘=1𝑘=5𝑘=10𝑘=25
GPT–3.5 46.4 42.9 65.0 70.7 76.7 27.9 24.7 46.1 54.5 64.6 31.8 28.5 51.5 59.5 68.2
GPT–3.5 w/o trace 47.1 46.8 65.9 70.7 75.7 27.2 25.6 47.0 55.5 64.7 30.9 30.2 53.0 60.7 68.8
GPT–4 62.8 63.2 75.1 78.5 82.7 41.8 42.2 64.5 71.0 76.6 47.8 47.4 68.5 73.9 79.0
GPT–4 w/o trace 51.3 44.8 68.5 73.4 78.5 29.4 27.1 54.2 63.4 72.2 34.9 32.0 60.3 68.5 75.7
PaLM 2-L 26.6 23.2 45.7 54.7 65.0 21.5 21.1 41.1 49.5 59.2 24.9 23.9 45.8 54.3 63.8
PaLM 2-L w/o trace 19.0 16.3 42.1 52.8 64.8 14.7 13.7 33.9 44.1 56.7 17.4 15.9 38.3 48.9 61.6
PaLM 2-L w/o rationale 27.5 25.7 44.5 51.7 60.0 – – – – – – – – – –
PaLM 2-L w/o rationale + trace 23.8 23.1 45.8 54.6 64.5 – – – – – – – – – –
NExT 50.5 49.3 68.1 73.5 79.4 25.3 26.1 46.8 54.4 62.9 31.8 31.6 53.0 60.2 68.1
test w/o trace 41.1 40.8 61.8 68.9 76.4 17.6 17.5 35.6 43.5 53.4 21.0 21.5 42.2 50.6 60.1
NExT w/o hard–only 52.9 52.1 65.0 68.8 73.4 23.5 25.1 38.6 44.0 50.9 30.0 29.7 44.1 49.7 55.9
test w/o trace 41.9 42.2 58.1 63.2 69.2 16.3 17.8 32.1 37.9 45.0 18.7 21.0 36.7 43.0 50.5
NExT w/o rationale 51.8 51.1 63.9 67.9 71.8 – – – – – – – – – –
test w/o trace 43.7 43.0 57.2 61.7 66.3 – – – – – – – – – –
NExT w/o trace 44.5 44.1 63.0 68.5 75.0 22.3 21.8 42.3 50.1 59.2 25.9 25.9 48.0 55.4 63.2
NExT w/o rationale w/o trace 46.3 44.9 58.9 63.2 67.8 – – – – – – – – – –

Bảng 8|Kết quả đầy đủ trên Mbpp-R. "GD Acc." biểu thị pass@1 được đánh giá với giải mã tham lam. Tất cả các mô hình trong nửa trên được prompt ít mẫu trong khi nửa dưới hiển thị kết quả của NE xT và các ablation của nó.

Mô hìnhTỷ lệ Sửa chữa End-to-End Tỷ lệ Sửa chữa dựa Proxy (PaLM 2–S) Tỷ lệ Sửa chữa dựa Proxy (PaLM 2–S∗)
GD pass@𝑘w/ Sampling GD pass@𝑘w/ Sampling GD pass@𝑘w/ Sampling
Acc.𝑘=1𝑘=5𝑘=10𝑘=25 Acc. 𝑘=1𝑘=5𝑘=10𝑘=25 Acc. 𝑘=1𝑘=5𝑘=10𝑘=25
GPT-3.5 68.9 59.4 84.5 89.2 93.0 42.1 39.0 66.1 73.4 80.2 46.3 44.6 71.6 78.8 86.8
GPT-3.5 w/o trace 65.2 65.4 85.3 89.2 92.6 45.7 41.7 68.2 76.3 84.5 50.0 47.2 73.8 81.1 88.6
GPT-4 79.9 77.6 89.3 91.1 92.9 56.1 55.4 75.7 80.8 85.8 61.0 57.7 77.5 82.7 87.4
GPT-4 w/o trace 79.3 68.9 88.3 90.7 92.9 54.9 46.1 72.3 79.0 86.1 59.8 48.7 74.4 80.8 87.5
PaLM 2-L 43.3 32.2 64.3 73.8 81.5 32.9 28.9 59.0 69.2 79.1 43.3 34.9 65.8 74.3 82.9
PaLM 2-L w/o trace 38.4 30.3 61.9 72.9 83.3 25.6 27.8 56.2 66.0 76.6 31.1 33.0 63.5 72.7 81.8
PaLM 2-L w/o rationale 53.0 45.3 71.5 78.9 85.4 – – – – – – – – – –
PaLM 2-L w/o rationale + trace 48.2 43.2 71.4 80.0 87.7 – – – – – – – – – –
NExT 46.3 42.5 62.6 69.1 76.5 31.7 34.8 54.8 62.4 70.2 40.9 41.3 61.8 68.9 76.4
test w/o trace 42.7 41.2 62.9 70.6 79.5 26.8 26.4 48.0 56.1 64.2 36.0 32.6 55.7 64.4 72.8
NExT w/o hard-only 48.8 47.7 64.8 70.4 76.6 32.9 37.2 50.8 55.5 61.9 41.5 42.4 56.3 60.8 66.9
test w/o trace 47.6 44.2 64.4 70.4 75.5 31.7 33.3 46.9 51.4 57.3 38.4 38.5 54.6 59.2 63.9
NExT w/o rationale 47.6 44.5 58.9 63.7 69.4 – – – – – – – – – –
test w/o trace 46.3 44.7 60.4 65.2 70.2 – – – – – – – – – –
NExT w/o trace 40.9 38.1 59.1 65.3 71.5 29.3 26.9 52.1 61.1 71.5 33.5 34.4 63.1 70.8 77.4
NExT w/o rationale w/o trace 30.5 31.4 44.6 49.0 54.1 – – – – – – – – – –

Bảng 9|Kết quả đầy đủ trên HeFix+. Ký hiệu tương tự từ Bảng 8 áp dụng.

các bước 2 - 9 của Dấu vết 1 để giải thích nguyên nhân của phần tử cuối cùng bị thiếu trong danh sách kết quả. Thú vị là, trong khi mô hình có thể suy luận qua nhiều bước thực thi trong lý luận của nó, khi chuỗi suy luận trở nên dài hơn, nó có nhiều khả năng chứa lỗi logic nhỏ, như được tô sáng trong lý luận của Ví dụ 3 và 4.

Bên cạnh lỗi logic nhỏ trong suy luận CoT, chúng tôi cũng xác định một số chế độ lỗi rõ rệt hơn. Đầu tiên, ngay cả khi lý luận NL trông hợp lệ, sửa chữa mã thực tế có thể không chính xác (Ví dụ 4). Thứ hai, đối với các trường hợp có nhiều lỗi trong chương trình, mô hình có thể chỉ tập trung vào các lỗi rõ ràng hơn trong quá trình suy luận (ví dụ: giải thích lý do IndexError trong Dấu vết 2 của Ví dụ 5), trong khi bỏ qua các lỗi tinh tế khác bị chôn vùi trong dấu vết (ví dụ: Đầu ra không chính xác trong Dấu vết 1 và Dấu vết 3 gây ra bởi freq_arr được khởi tạo bằng zero). Điều này có thể đặc biệt có vấn đề khi có lỗi ẩn không được ghi lại trong dấu vết, có thể xảy ra khi một chương trình lỗi bị crash giữa chừng thực thi và phần còn lại của mã không được bao phủ trong dấu vết. Vì mô hình có thể dựa nhiều hơn vào thông tin dấu vết sau tinh chỉnh, nó có thể dễ bỏ lỡ những lỗi ngầm như vậy hơn. Ví dụ, trong Ví dụ 6 mô hình chỉ chú ý đến TypeError trong dấu vết, mà không phát hiện rằng mã tính toán chỉ số cuối trong tuple đầu ra bị lệch một.

24

--- TRANG 25 ---
NExT: Dạy các Mô hình Ngôn ngữ Lớn Suy luận về Thực thi Mã

Ví dụ 1: Một ví dụ nơi mô hình của chúng tôi giải thích ngoại lệ trong dấu vết
Nhiệm vụ: Viết một hàm để loại bỏ các số 0 đầu tiên từ một địa chỉ ip
Mã Lỗi:
def removezero_ip(ip):
ip_list = ip.split(".")
for i in range(4):
ip_list[i] = str(int(ip_list[i]))
return ".".join(ip_list)
Trường hợp Kiểm tra:
assert removezero_ip("216.08.094.196")==('216.8.94.196')
assert removezero_ip("12.01.024")==('12.1.24')
assert removezero_ip("216.08.094.0196")==('216.8.94.196')
Dấu vết:
# Dấu vết 1:
def removezero_ip(ip): # (0) ip='216.08.094.196';
ip_list = ip.split(".") # (1) ip_list=['216','08','094','196'];
for i in range(4): # (2) i=0; (4) i=1; (6) i=2; ...; (10) NO_CHANGE;
ip_list[i] = str(int(ip_list[i])) # (3) NO_CHANGE; (5) ip_list=['216','8','094','196']; (7) ip_list
=['216','8','94','196']; (9) NO_CHANGE;
return ".".join(ip_list) # (11) __return__='216.8.94.196';
assert removezero_ip("216.08.094.196")==('216.8.94.196')
# Dấu vết 2:
def removezero_ip(ip): # (0) ip='12.01.024';
ip_list = ip.split(".") # (1) ip_list=['12','01','024'];
for i in range(4): # (2) i=0; (4) i=1; (6) i=2; (8) i=3;
ip_list[i] = str(int(ip_list[i])) # (3) NO_CHANGE; (5) ip_list=['12','1','024']; (7) ip_list=['12',
'1','24']; (9) __exception__ = IndexError('list index out of range')
return ".".join(ip_list)
assert removezero_ip("12.01.024")==('12.1.24')
# Dấu vết 3:
def removezero_ip(ip): # (0) ip='216.08.094.0196';
ip_list = ip.split(".") # (1) ip_list=['216','08','094','0196'];
for i in range(4): # (2) i=0; (4) i=1; (6) i=2; ...; (10) NO_CHANGE;
ip_list[i] = str(int(ip_list[i])) # (3) NO_CHANGE; (5) ip_list=['216','8','094','0196']; (7)
ip_list=['216','8','94','0196']; (9) ip_list=['216','8','94','196'];
return ".".join(ip_list) # (11) __return__='216.8.94.196';
assert removezero_ip("216.08.094.0196")==('216.8.94.196')
Lý luận và Giải pháp Mã: (sửa chữa mã đúng
)
Đặc tả vấn đề yêu cầu viết một hàm để loại bỏ các số 0 đầu tiên từ một địa chỉ IP.
Bây giờ hãy xem chương trình. Chương trình đầu tiên chia địa chỉ IP thành một danh sách các chuỗi, sau đó lặp qua danh sách để chuyển đổi mỗi chuỗi thành số nguyên, rồi trở lại thành chuỗi. Điều này sẽ loại bỏ các số 0 đầu tiên. Tuy nhiên, vấn đề là nó lặp qua danh sách 4 lần, nhưng độ dài của danh sách có thể không phải là 4. Ví dụ, khi 'ip="12.01.024"', độ dài của danh sách chỉ là 3. Do đó khi 'i=3', nó sẽ ném một 'IndexError'.
Đây là một sửa chữa đơn giản:
def removezero_ip(ip):
ip_list = ip.split(".")
for i in range(len(ip_list)):
ip_list[i] = str(int(ip_list[i])).lstrip('0')
return ".".join(ip_list)

Ví dụ 2: Một ví dụ nơi mô hình của chúng tôi sử dụng trạng thái biến để giải quyết nhiệm vụ
Nhiệm vụ: Viết một hàm để sắp xếp mỗi danh sách con chuỗi trong một danh sách các danh sách cho trước

25

--- TRANG 26 ---
NExT: Dạy các Mô hình Ngôn ngữ Lớn Suy luận về Thực thi Mã

def sort_sublists(words):
words.sort(key = len)
for w in words:
w.sort()
return words
Trường hợp Kiểm tra:
assert sort_sublists([['green','orange'], ['black','white'], ['white','black','orange']])==[['green','
orange'], ['black','white'], ['black','orange','white']]
assert sort_sublists([['green','orange'], ['black'], ['green','orange'], ['white']])==[['green','orange'], [
'black'], ['green','orange'], ['white']]
assert sort_sublists([['a','b'],['d','c'],['g','h'] , ['f','e']])==[['a','b'], ['c','d'], ['g','h'], ['e','
f']]
Dấu vết:
# Dấu vết 1:
def sort_sublists(words): # (0) words=[['green','orange'], ['black','white'], ['white','black','orange']];
words.sort(key = len) # (1) NO_CHANGE;
for w in words: # (2) w=['green','orange']; (4) w=['black','white']; (6) w=['white','black','orange'];
(8) NO_CHANGE;
w.sort() # (3) NO_CHANGE; (5) NO_CHANGE; (7) w=['black','orange','white'], words=[['green','orange
'], ['black','white'], ['black','orange','white']];
return words # (9) __return__=[['green','orange'], ['black','white'], ['black','orange','white']];
assert sort_sublists([['green','orange'], ['black','white'], ['white','black','orange']])==[['green','
orange'], ['black','white'], ['black','orange','white']]
# Dấu vết 2:
def sort_sublists(words): # (0) words=[['green','orange'], ['black'], ['green','orange'], ['white']];
words.sort(key = len) # (1) words=[['black'], ['white'], ['green', 'orange'], ['green', 'orange']];
for w in words: # (2) w=['black']; (4) w=['white']; (6) w=['green','orange']; ...; (10) NO_CHANGE;
w.sort() # (3) NO_CHANGE; (5) NO_CHANGE; (7) NO_CHANGE; (9) NO_CHANGE;
return words # (11) __return__=[['black'], ['white'], ['green','orange'], ['green','orange']];
assert sort_sublists([['green','orange'], ['black'], ['green','orange'], ['white']])==[['green','orange'], [
'black'], ['green','orange'], ['white']] # (12) __exception__ = AssertionError()
# Dấu vết 3:
def sort_sublists(words): # (0) words=[['a','b'], ['d','c'], ['g','h'], ['f','e']];
words.sort(key = len) # (1) NO_CHANGE;
for w in words: # (2) w=['a','b']; (4) w=['d','c']; (6) w=['g','h']; ...; (10) NO_CHANGE;
w.sort() # (3) NO_CHANGE; (5) w=['c','d'], words=[['a','b'], ['c','d'], ['g','h'], ['f','e']];
(7) NO_CHANGE; (9) w=['e','f'], words=[['a','b'], ['c','d'], ['g','h'], ['e','f']];
return words # (11) __return__=[['a','b'], ['c','d'], ['g','h'], ['e','f']];
assert sort_sublists([['a','b'],['d','c'],['g','h'] , ['f','e']])==[['a','b'], ['c','d'], ['g','h'], ['e','
f']]
Lý luận và Giải pháp Mã: (sửa chữa mã đúng
)
Đặc tả vấn đề yêu cầu sắp xếp mỗi danh sách con chuỗi trong một danh sách các danh sách cho trước.
Bây giờ hãy xem chương trình. Chương trình đầu tiên sắp xếp danh sách các danh sách theo độ dài của mỗi danh sách con, sau đó sắp xếp mỗi danh sách con. Khẳng định đầu tiên vượt qua vì danh sách con đầu tiên đã được sắp xếp, và danh sách con thứ hai cũng được sắp xếp, và danh sách con thứ ba được sắp xếp trong vòng for.
Khẳng định thứ hai thất bại vì danh sách các danh sách được sắp xếp theo độ dài của mỗi danh sách con, và do đó giá trị trả về không giống như đầu vào. Khẳng định thứ ba vượt qua vì danh sách con đầu tiên và cuối cùng đã được sắp xếp, và danh sách con thứ hai và thứ ba được sắp xếp trong vòng for.
Vấn đề là chương trình sắp xếp danh sách các danh sách theo độ dài của mỗi danh sách con, điều này không được yêu cầu bởi đặc tả vấn đề. Do đó chúng ta có thể đơn giản loại bỏ dòng đầu tiên của hàm.
Đây là mã đã sửa:
def sort_sublists(words):
for w in words:
w.sort()
return words

26

--- TRANG 27 ---
NExT: Dạy các Mô hình Ngôn ngữ Lớn Suy luận về Thực thi Mã

Ví dụ 3: Một ví dụ nơi PaLM 2-L +NExT suy luận qua nhiều bước thực thi
Nhiệm vụ: Viết một hàm để tính tổng của một số nguyên không âm
Mã Lỗi:
def sum_digits(number):
sum = 0
while(number):
sum += number %
number = number / 10
return sum
Trường hợp Kiểm tra:
assert sum_digits(345)==12
assert sum_digits(12)==3
assert sum_digits(97)==16
Dấu vết:
# Dấu vết 1:
def sum_digits(number): # (0) number=345;
sum = 0 # (1) sum=0;
while(number):
sum += number %
number = number / 10 # (3) number=34.5; (5) number=3.45; (7) number=0.34500000000000003; ...; (655)
number=0.0;
return sum # (656) __return__=13.33333333333333;
assert sum_digits(345)==12 # (657) __exception__ = AssertionError()
# Dấu vết 2:
def sum_digits(number): # (0) number=12;
sum = 0 # (1) sum=0;
while(number):
sum += number %
number = number / 10 # (3) number=1.2; (5) number=0.12; (7) number=0.012; ...; (651) number=0.0;
return sum # (652) __return__=3.3333333333333335;
assert sum_digits(12)==3 # (653) __exception__ = AssertionError()
# Dấu vết 3:
def sum_digits(number): # (0) number=97;
sum = 0 # (1) sum=0;
while(number):
sum += number %
number = number / 10 # (3) number=9.7; (5) number=0.97; (7) number=0.097; ...; (653) number=0.0;
return sum # (654) __return__=17.77777777777777;
assert sum_digits(97)==16 # (655) __exception__ = AssertionError()
Lý luận và Giải pháp Mã: (sửa chữa mã đúng
)
Đặc tả vấn đề yêu cầu viết một hàm để tính tổng của tất cả các chữ số trong một số nguyên không âm.
Bây giờ hãy xem chương trình. Chương trình có vẻ đúng ở cái nhìn đầu tiên. Nó đầu tiên khởi tạo tổng bằng 0, sau đó sử dụng vòng while để lấy từng chữ số trong số và thêm vào tổng. Tuy nhiên, nếu chúng ta xem đầu ra của chương trình, chúng ta sẽ thấy rằng tổng không phải là số nguyên.
Điều này là do chương trình không chuyển đổi số thành số nguyên trước khi lấy các chữ số. Ví dụ, đối với khẳng định đầu tiên, khi 'number=345', chữ số đầu tiên '5' được thêm vào tổng và 'sum=5'. Sau đó 'number' được cập nhật thành '34.5', và chữ số thứ hai '4' được thêm vào tổng và 'sum=9.5'. Và cứ thế.
Đây là phiên bản đã sửa:
def sum_digits(number):
number = int(number)
sum = 0
while(number):
sum += number %
number = number // 10
return sum

27

--- TRANG 28 ---
NExT: Dạy các Mô hình Ngôn ngữ Lớn Suy luận về Thực thi Mã

Ví dụ 4: Một ví dụ nơi PaLM 2-L +NExT suy luận qua nhiều bước thực thi
Nhiệm vụ: Viết một hàm để chuyển đổi tuple thành danh sách bằng cách thêm chuỗi cho trước sau mỗi phần tử.
Mã Lỗi:
def add_str(test_tuple, add_str):
res = list(test_tuple)
for i in range(1,len(test_tuple)):
res.insert(i ∗2−1,add_str)
return res
Trường hợp Kiểm tra:
assert add_str((5, 6, 7, 4, 9) , "FDF") == [5, 'FDF', 6, 'FDF', 7, 'FDF', 4, 'FDF', 9, 'FDF']
assert add_str((7, 8, 9, 10) , "PF") == [7, 'PF', 8, 'PF', 9, 'PF', 10, 'PF']
assert add_str((11, 14, 12, 1, 4) , "JH") == [11, 'JH', 14, 'JH', 12, 'JH', 1, 'JH', 4, 'JH']
Dấu vết:
# Dấu vết 1:
def add_str(test_tuple, add_str):
# Viết mã của bạn ở đây
res = list(test_tuple) # (1) res=[5, 6, 7, 4, 9];
for i in range(1,len(test_tuple)): # (2) i=1; (4) i=2; (6) i=3; ...; (10) NO_CHANGE;
res.insert(i ∗2−1,add_str) # (3) res=[5, 'FDF', 6, 7, 4, 9]; (5) res=[5, 'FDF', 6, 'FDF', 7, 4, 9];
(7) res=[5, 'FDF', 6, 'FDF', 7, 'FDF', 4, 9]; (9) res=[5, 'FDF', 6, 'FDF', 7, 'FDF', 4, 'FDF', 9];
return res # (11) __return__=[5, 'FDF', 6, 'FDF', 7, 'FDF', 4, 'FDF', 9];
assert add_str((5, 6, 7, 4, 9) , "FDF") == [5, 'FDF', 6, 'FDF', 7, 'FDF', 4, 'FDF', 9, 'FDF'] # (12)
__exception__ = AssertionError()
# Dấu vết 2:
def add_str(test_tuple, add_str):
# Viết mã của bạn ở đây
res = list(test_tuple) # (1) res=[7, 8, 9, 10];
for i in range(1,len(test_tuple)): # (2) i=1; (4) i=2; (6) i=3; (8) NO_CHANGE;
res.insert(i ∗2−1,add_str) # (3) res=[7, 'PF', 8, 9, 10]; (5) res=[7, 'PF', 8, 'PF', 9, 10]; (7) res
=[7, 'PF', 8, 'PF', 9, 'PF', 10];
return res # (9) __return__=[7, 'PF', 8, 'PF', 9, 'PF', 10];
assert add_str((7, 8, 9, 10) , "PF") == [7, 'PF', 8, 'PF', 9, 'PF', 10, 'PF'] # (10) __exception__ =
AssertionError()
# Dấu vết 3:
def add_str(test_tuple, add_str):
# Viết mã của bạn ở đây
res = list(test_tuple) # (1) res=[11, 14, 12, 1, 4];
for i in range(1,len(test_tuple)): # (2) i=1; (4) i=2; (6) i=3; ...; (10) NO_CHANGE;
res.insert(i ∗2−1,add_str) # (3) res=[11, 'JH', 14, 12, 1, 4]; (5) res=[11, 'JH', 14, 'JH', 12, 1, 4];
(7) res=[11, 'JH', 14, 'JH', 12, 'JH', 1, 4]; (9) res=[11, 'JH', 14, 'JH', 12, 'JH', 1, 'JH', 4];
return res # (11) __return__=[11, 'JH', 14, 'JH', 12, 'JH', 1, 'JH', 4];
assert add_str((11, 14, 12, 1, 4) , "JH") == [11, 'JH', 14, 'JH', 12, 'JH', 1, 'JH', 4, 'JH'] # (12)
__exception__ = AssertionError()
Lý luận và Giải pháp Mã: (sửa chữa mã sai
)
Đặc tả vấn đề yêu cầu chuyển đổi một tuple thành danh sách và thêm một chuỗi cho trước sau mỗi phần tử.
Bây giờ hãy xem chương trình. Chương trình đầu tiên chuyển đổi tuple thành danh sách, điều này tốt. Sau đó nó lặp từ 1 đến độ dài của danh sách, và chèn chuỗi cho trước tại chỉ số `i∗2−1`. Điều này có vẻ đúng ở cái nhìn đầu tiên, nhưng vấn đề là nó sẽ không thêm chuỗi sau phần tử cuối cùng. Ví dụ, khi 'test_tuple=(5, 6, 7, 4, 9)', độ dài của danh sách là 5, và vòng for sẽ lặp từ 1 đến 4. Do đó chuỗi sẽ được chèn tại chỉ số 1, 3, 5, và 7, tương ứng với sau phần tử thứ hai, thứ tư, và thứ sáu. Chuỗi sẽ không được chèn sau phần tử cuối cùng (tức là phần tử thứ chín).
Đây là một sửa chữa đơn giản:

28

--- TRANG 29 ---
NExT: Dạy các Mô hình Ngôn ngữ Lớn Suy luận về Thực thi Mã

def add_str(test_tuple, add_str):
res = list(test_tuple)
for i in range(len(test_tuple)):
res.insert(i ∗2,add_str)
return res

Ví dụ 5: Một ví dụ nơi PaLM 2-L +NExT thất bại trong việc xác định tất cả lỗi trong chương trình
Nhiệm vụ: Viết một hàm python để tìm sự khác biệt giữa tần suất cao nhất và thấp nhất trong một mảng cho trước.
Mã Lỗi:
def find_Diff(nums, n):
freq_arr = [0 for i in range(n)]
for i in range(len(nums)):
freq_arr[nums[i]] = freq_arr[nums[i]] + 1
return max(freq_arr) −min(freq_arr)
Trường hợp Kiểm tra:
assert find_Diff([1,1,2,2,7,8,4,5,1,4],10) == 2
assert find_Diff([1,7,9,2,3,3,1,3,3],9) == 3
assert find_Diff([1,2,1,2],4) == 0
Dấu vết:
# Dấu vết 1:
def find_Diff(nums, n): # (0) n=10, nums=[1, 1, 2, 2, 7, 8, 4, 5, 1, 4]; (1) .0=<range_iterator object>;
freq_arr = [0 for i in range(n)] # (2) i=0; (3) i=1; (4) i=2; ...; (13) freq_arr=[0, 0, 0, 0, 0, 0, 0, 0,
0, 0];
for i in range(len(nums)): # (14) i=0; (16) i=1; (18) i=2; ...; (34) NO_CHANGE;
freq_arr[nums[i]] = freq_arr[nums[i]] + 1 # (15) freq_arr=[0, 1, 0, 0, 0, 0, 0, 0, 0, 0]; (17)
freq_arr=[0, 2, 0, 0, 0, 0, 0, 0, 0, 0]; (19) freq_arr=[0, 2, 1, 0, 0, 0, 0, 0, 0, 0]; ...; (33) freq_arr=[0,
3, 2, 0, 2, 1, 0, 1, 1, 0];
return max(freq_arr) −min(freq_arr) # (35) __return__=3;
assert find_Diff([1,1,2,2,7,8,4,5,1,4],10) == 2 # (36) __exception__ = AssertionError()
# Dấu vết 2:
def find_Diff(nums, n): # (0) n=9, nums=[1, 7, 9, 2, 3, 3, 1, 3, 3]; (1) .0=<range_iterator object>;
freq_arr = [0 for i in range(n)] # (2) i=0; (3) i=1; (4) i=2; ...; (12) freq_arr=[0, 0, 0, 0, 0, 0, 0, 0,
0];
for i in range(len(nums)): # (13) i=0; (15) i=1; (17) i=2;
freq_arr[nums[i]] = freq_arr[nums[i]] + 1 # (14) freq_arr=[0, 1, 0, 0, 0, 0, 0, 0, 0]; (16) freq_arr
=[0, 1, 0, 0, 0, 0, 0, 1, 0]; (18) __exception__ = IndexError('list index out of range')
return max(freq_arr) −min(freq_arr)
assert find_Diff([1,7,9,2,3,3,1,3,3],9) == 3
# Dấu vết 3:
def find_Diff(nums, n): # (0) n=4, nums=[1, 2, 1, 2]; (1) .0=<range_iterator object>;
freq_arr = [0 for i in range(n)] # (2) i=0; (3) i=1; (4) i=2; ...; (7) freq_arr=[0, 0, 0, 0];
for i in range(len(nums)): # (8) i=0; (10) i=1; (12) i=2; ...; (16) NO_CHANGE;
freq_arr[nums[i]] = freq_arr[nums[i]] + 1 # (9) freq_arr=[0, 1, 0, 0]; (11) freq_arr=[0, 1, 1, 0];
(13) freq_arr=[0, 2, 1, 0]; (15) freq_arr=[0, 2, 2, 0];
return max(freq_arr) −min(freq_arr) # (17) __return__=2;
assert find_Diff([1,2,1,2],4) == 0 # (18) __exception__ = AssertionError()
Lý luận và Giải pháp Mã: (sửa chữa mã sai
)

29

--- TRANG 30 ---
NExT: Dạy các Mô hình Ngôn ngữ Lớn Suy luận về Thực thi Mã

Đặc tả vấn đề yêu cầu tìm sự khác biệt giữa tần suất cao nhất và thấp nhất trong một mảng cho trước.
Bây giờ hãy xem chương trình. Chương trình đầu tiên tạo một mảng tần suất có độ dài `n`, sau đó lặp qua mảng đầu vào để đếm tần suất của mỗi số. Sau đó nó trả về sự khác biệt giữa tần suất tối đa và tối thiểu trong mảng tần suất.
Chương trình trông tốt ở cái nhìn đầu tiên.
Tuy nhiên, vấn đề là độ dài của mảng tần suất là 'n', là độ dài của mảng đầu vào. Tuy nhiên, các số trong mảng đầu vào có thể lớn hơn 'n', và do đó mảng tần suất sẽ không thể chứa tất cả các số trong mảng đầu vào. Ví dụ, trong khẳng định thứ hai, mảng đầu vào là `[1, 7, 9, 2, 3, 3, 1, 3, 3]`, và độ dài của mảng tần suất cũng là `9`. Khi `nums[i]=9`, nó sẽ cố gắng truy cập `freq_arr[9]`, nằm ngoài phạm vi, và do đó một `IndexError` được ném ra.
Đây là một sửa chữa đơn giản:
def find_Diff(nums, n):
freq_arr = {}
for i in range(len(nums)):
if nums[i] in freq_arr:
freq_arr[nums[i]] += 1
else:
freq_arr[nums[i]] = 1
max_freq = 0
min_freq = 0
for num, freq in freq_arr.items():
if freq > max_freq:
max_freq = freq
if freq < min_freq or min_freq == 0:
min_freq = freq
return max_freq −min_freq

Ví dụ 6: Một ví dụ nơi PaLM 2-L +NExT thất bại trong việc xác định một lỗi không được tiết lộ trong dấu vết
Nhiệm vụ: Viết một hàm để tìm kiếm một chuỗi ký tự trong một chuỗi và cũng tìm vị trí trong chuỗi gốc nơi mẫu xuất hiện.
Mã Lỗi:
def search_literal(pattern, text):
match = tuple(text.find(pattern), text.find(pattern) + len(pattern) - 1)
return match
Trường hợp Kiểm tra:
assert search_literal('python','python programming language')==(0,6)
assert search_literal('programming','python programming language')==(7,18)
assert search_literal('language','python programming language')==(19,27)
Dấu vết:

30

--- TRANG 31 ---
NExT: Dạy các Mô hình Ngôn ngữ Lớn Suy luận về Thực thi Mã

# Dấu vết 1:
def search_literal(pattern, text):
match = tuple(text.find(pattern), text.find(pattern) + len(pattern) −1) # (1) __exception__ = TypeError
('tuple expected at most 1 argument, got 2')
return match
assert search_literal('python','python programming language')==(0,6)
# Dấu vết 2:
def search_literal(pattern, text):
match = tuple(text.find(pattern), text.find(pattern) + len(pattern) −1) # (1) __exception__ = TypeError
('tuple expected at most 1 argument, got 2')
return match
assert search_literal('programming','python programming language')==(7,18)
# Dấu vết 3:
def search_literal(pattern, text):
match = tuple(text.find(pattern), text.find(pattern) + len(pattern) −1) # (1) __exception__ = TypeError
('tuple expected at most 1 argument, got 2')
return match
assert search_literal('language','python programming language')==(19,27)
Lý luận và Giải pháp Mã: (sửa chữa mã sai
)
Bây giờ hãy xem chương trình. Chương trình trông tốt ở cái nhìn đầu tiên vì `text.find(pattern)` là cách đúng để tìm vị trí của một chuỗi ký tự trong một chuỗi cho trước. Nhưng vấn đề là nó không sử dụng hàm `tuple()` đúng cách. Hàm `tuple()` nhận một iterable duy nhất làm đầu vào, và trả về một tuple với các phần tử từ iterable. Nhưng trong chương trình, nó nhận hai đối số, điều này sẽ ném một 'TypeError' của 'tuple expected at most 1 argument, got 2'.
Đây là một sửa chữa đơn giản:
def search_literal(pattern, text):
match = tuple(text.find(pattern),)
match = match + (text.find(pattern) + len(pattern) −1,)
return match

31

--- TRANG 32 ---
NExT: Dạy các Mô hình Ngôn ngữ Lớn Suy luận về Thực thi Mã

E. Prompt Đầy đủ

Ở đây chúng tôi hiển thị hướng dẫn và cả ba ví dụ ít mẫu được sử dụng trong công việc này. Lý luận và sửa chữa trong các ví dụ ít mẫu được chú thích thủ công bởi các tác giả. Mỗi exemplar có ba kiểm tra đơn vị và dấu vết của chúng.

1Chúng ta đang lập trình cặp đôi, tôi sẽ cung cấp cho bạn định nghĩa vấn đề và triển khai của tôi,
không vượt qua tất cả trường hợp kiểm tra. Và bạn cần giúp tôi sửa mã của tôi.↩→
2
3# Ví dụ 1
4
5Đây là đặc tả bằng ngôn ngữ tự nhiên và chương trình mà tôi đã viết:
6```
7# Viết một hàm để tìm các phần tử tương tự từ hai danh sách tuple đã cho.
8def similar_elements(t1, t2):
9 s1 = set(t1)
10 s2 = set(t2)
11 return s1.intersection(s2)
12
13```
14 Đây là các khẳng định tôi cần vượt qua:
15```
16 assert similar_elements((3, 4, 5, 6),(5, 7, 4, 10)) == (4, 5)
17 assert similar_elements((1, 2, 3, 4),(5, 4, 3, 7)) == (3, 4)
18 assert similar_elements((11, 12, 14, 13),(17, 15, 14, 13)) == (13, 14)
19```
20
21 Đây là một *cheatsheet* cho dấu vết thực thi vàng cho mỗi khẳng định, sử dụng thông tin
ở đây nhưng giả vờ rằng bạn đã thực hiện tất cả suy luận về thực thi.↩→
22
23 #################### cheatsheet bắt đầu ####################
24 def similar_elements(t1, t2): # (0) t1=(3, 4, 5, 6), t2=(5, 7, 4, 10);
25 s1 = set(t1) # (1) s1={3, 4, 5, 6};
26 s2 = set(t2) # (2) s2={10, 4, 5, 7};
27 return s1.intersection(s2) # (3) __return__={4, 5}
28
29
30 assert similar_elements((3, 4, 5, 6),(5, 7, 4, 10)) == (4, 5) #
31 --------------------
32 def similar_elements(t1, t2): # (0) t1=(1, 2, 3, 4), t2=(5, 4, 3, 7);
33 s1 = set(t1) # (1) s1={1, 2, 3, 4};
34 s2 = set(t2) # (2) s2={3, 4, 5, 7};
35 return s1.intersection(s2) # (3) __return__={3, 4}
36
37
38 assert similar_elements((1, 2, 3, 4),(5, 4, 3, 7)) == (3, 4) #
39 --------------------
40 def similar_elements(t1, t2): # (0) t1=(11, 12, 14, 13), t2=(17, 15, 14, 13);
41 s1 = set(t1) # (1) s1={11, 12, 13, 14};
42 s2 = set(t2) # (2) s2={17, 13, 14, 15};
43 return s1.intersection(s2) # (3) __return__={13, 14}
44
45
46 assert similar_elements((11, 12, 14, 13),(17, 15, 14, 13)) == (13, 14) #
47 #################### cheatsheet kết thúc ####################
48
49 Với thông tin trên, bạn có thể cho tôi biết tại sao mã của tôi sai, và cũng cung cấp một phiên bản đã sửa không?↩→
50
51 Đặc tả vấn đề yêu cầu tìm các phần tử tương tự trong hai tuple, từ khẳng định chúng ta có thể
thấy rằng nó về cơ bản muốn các phần tử chung từ hai tuple. Nó cũng có vẻ như
các phần tử chung nên được trả về trong một tuple với thứ tự tăng dần.↩→
↩→
52
53 Bây giờ hãy xem chương trình. Trong khi việc sử dụng `intersection()` để tìm
các phần tử chung giữa hai set là đúng và hiệu quả, nó cũng sẽ trả về một set. Lấy khẳng định đầu tiên làm
ví dụ, `s1` đầu tiên sẽ được chuyển đổi thành một set như `{3, 4, 5, 6}` và tương tự cho
`s2`, sau đó giá trị trả về sẽ là `{4, 5}`. Mặc dù các phần tử đúng, giá trị trả về mong đợi
là một tuple chứ không phải set. Do đó chúng ta chỉ cần chuyển đổi thêm các set thành
tuple sử dụng `tuple()`.↩→
↩→
↩→
↩→
↩→

32

--- TRANG 33 ---
NExT: Dạy các Mô hình Ngôn ngữ Lớn Suy luận về Thực thi Mã

54
55 Đây là mã đã sửa:
56 ```
57 def similar_elements(t1, t2):
58 s1 = set(t1)
59 s2 = set(t2)
60 return tuple(s1.intersection(s2))
61 ```
62
63 # Ví dụ 2
64
65 Đây là đặc tả bằng ngôn ngữ tự nhiên và chương trình mà tôi đã viết:
66 ```
67 # Viết một hàm python để xác định các số không nguyên tố.
68 def is_not_prime(n):
69 if n==1:
70 return False
71 else:
72 for i in range(2,n//2+1):
73 if n%
74 return False
75 else:
76 return True
77 ```
78 Đây là các khẳng định tôi cần vượt qua:
79 ```
80 assert is_not_prime(2) == False
81 assert is_not_prime(10) == True
82 assert is_not_prime(35) == True
83 ```
84
85 Đây là một *cheatsheet* cho dấu vết thực thi vàng cho mỗi khẳng định, sử dụng thông tin
ở đây nhưng giả vờ rằng bạn đã thực hiện tất cả suy luận về thực thi.↩→
86
87 #################### cheatsheet bắt đầu ####################
88 def is_not_prime(n): # (0) n=2;
89 if n==1: #
90 return False
91 else:
92 for i in range(2,n//2+1): # (1) __return__=None
93 if n%
94 return False
95 else:
96 return True
97
98
99 assert is_not_prime(2) == False #
100 --------------------
101 def is_not_prime(n): # (0) n=10;
102 if n==1: #
103 return False
104 else:
105 for i in range(2,n//2+1): # (1) i=2;
106 if n%
107 return False # (2) __return__=False
108 else:
109 return True
110
111
112 assert is_not_prime(10) == True #
113 --------------------
114 def is_not_prime(n): # (0) n=35;
115 if n==1: #
116 return False
117 else:
118 for i in range(2,n//2+1): # (1) i=2;
119 if n%
120 return False
121 else:
122 return True # (2) __return__=True

33

--- TRANG 34 ---
NExT: Dạy các Mô hình Ngôn ngữ Lớn Suy luận về Thực thi Mã

123
124
125 assert is_not_prime(35) == True #
126 #################### cheatsheet kết thúc ####################
127
128 Với thông tin trên, bạn có thể cho tôi biết tại sao mã của tôi sai, và cũng cung cấp một phiên bản đã sửa không?↩→
129
130 Đặc tả vấn đề yêu cầu viết một hàm Python xác định các số không nguyên tố. Các số không nguyên tố
là các số chia hết cho các số khác ngoài 1 và chính nó. Lưu ý rằng 0 và 1
cũng là các số không nguyên tố.↩→
↩→
131
132 Bây giờ hãy kiểm tra chương trình. Hãy chạy chương trình qua một số ví dụ. Đối với khẳng định đầu tiên,
khi `n=2`, nó sẽ vào nhánh `else`, và sau đó trong vòng for, vì điều kiện
là `i in range(2, n//2+1)`, là `range(2, 2)`, nó thực tế sẽ không vào
vòng lặp vì điều kiện không được đáp ứng ngay từ đầu. Và sau đó nó sẽ đến cuối
hàm, và giá trị trả về sẽ là `None`. Và đối với khẳng định thứ ba, khi `n=35`,
nó cũng vào nhánh `else`, và sau đó vào vòng lặp với `i=2` vì `n//2+1=18 > 2`.
Sau đó ở bước tiếp theo, vì `n%↩→
↩→
↩→
↩→
↩→
↩→
133
134 Trong khi không rõ ràng cách sửa chương trình này, một cách khác để triển khai
hàm `is_not_prime()` chỉ là đầu tiên tạo một hàm trợ giúp để xác định số
nguyên tố là `is_prime()`, và sau đó đơn giản `return not is_prime(x)`.↩→
↩→
135
136 Đây là một triển khai lại:
137 ```
138 def is_prime(x):
139 if x <= 1:
140 return False
141 else:
142 for i in range(2,x):
143 if x%
144 return False
145 return True
146
147 def is_not_prime(x):
148 return not is_prime(x)
149 ```
150
151 # Ví dụ 3
152
153 Đây là đặc tả bằng ngôn ngữ tự nhiên và chương trình mà tôi đã viết:
154 ```
155 # Viết một hàm để tìm các số nguyên lớn nhất từ một danh sách các số cho trước sử dụng thuật toán
hàng đợi heap.↩→
156 def heap_queue_largest(list1,n):
157 largest=heapq.nlargest(n,list1)
158 return largest
159
160 ```
161 Đây là các khẳng định tôi cần vượt qua:
162 ```
163 assert heap_queue_largest([25, 35, 22, 85, 14, 65, 75, 22, 58],3)==[85, 75, 65]
164 assert heap_queue_largest([25, 35, 22, 85, 14, 65, 75, 22, 58],2)==[85, 75]
165 assert heap_queue_largest([25, 35, 22, 85, 14, 65, 75, 22, 58],5)==[85, 75, 65, 58, 35]
166 ```
167
168 Đây là một *cheatsheet* cho dấu vết thực thi vàng cho mỗi khẳng định, sử dụng thông tin
ở đây nhưng giả vờ rằng bạn đã thực hiện tất cả suy luận về thực thi.↩→
169
170 #################### cheatsheet bắt đầu ####################
171 def heap_queue_largest(list1,n): # (0) list1=[25, 35, 22, 85, 14, 65, 75, 22, 58], n=3;
172 largest=heapq.nlargest(n,list1) # (1) __exception__ = NameError("name 'heapq' is not
defined")↩→
173 return largest
174
175
176 assert heap_queue_largest([25, 35, 22, 85, 14, 65, 75, 22, 58],3)==[85, 75, 65]
177 --------------------
178 def heap_queue_largest(list1,n): # (0) list1=[25, 35, 22, 85, 14, 65, 75, 22, 58], n=2;

34

--- TRANG 35 ---
NExT: Dạy các Mô hình Ngôn ngữ Lớn Suy luận về Thực thi Mã

179 largest=heapq.nlargest(n,list1) # (1) __exception__ = NameError("name 'heapq' is not
defined")↩→
180 return largest
181
182
183 assert heap_queue_largest([25, 35, 22, 85, 14, 65, 75, 22, 58],2)==[85, 75]
184 --------------------
185 def heap_queue_largest(list1,n): # (0) list1=[25, 35, 22, 85, 14, 65, 75, 22, 58], n=5;
186 largest=heapq.nlargest(n,list1) # (1) __exception__ = NameError("name 'heapq' is not
defined")↩→
187 return largest
188
189
190 assert heap_queue_largest([25, 35, 22, 85, 14, 65, 75, 22, 58],5)==[85, 75, 65, 58, 35]
191 #################### cheatsheet kết thúc ####################
192
193 Với thông tin trên, bạn có thể cho tôi biết tại sao mã của tôi sai, và cũng cung cấp một phiên bản đã sửa không?↩→
194
195 Đặc tả vấn đề yêu cầu tìm `n` số nguyên lớn nhất trong một danh sách cho trước. Nó cũng gợi ý rằng
hàng đợi heap nên được sử dụng.↩→
196
197 Bây giờ hãy xem chương trình. Chương trình trông tốt ở cái nhìn đầu tiên vì `heapq.nlargest()`
là cách đúng để lấy `n` số nguyên lớn nhất từ một iterable (ví dụ: một danh sách). Nhưng
vấn đề là nó không import gói `heapq` trước. Do đó cả ba khẳng định sẽ
thất bại ở dòng đầu tiên của hàm, và ném một `NameError` của `name 'heapq' is not
defined`.↩→
↩→
↩→
↩→
198
199 Đây là một sửa chữa đơn giản:
200 ```
201 import heapq
202 def heap_queue_largest(list1,n):
203 largest=heapq.nlargest(n,list1)
204 return largest
205 ```
35

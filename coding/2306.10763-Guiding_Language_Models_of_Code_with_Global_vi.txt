# 2306.10763.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/coding/2306.10763.pdf
# Kích thước tệp: 2700028 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
Hướng dẫn các Mô hình Ngôn ngữ của Mã nguồn với Ngữ cảnh Toàn cục sử dụng các Monitor
Lakshya A Agrawal
Microsoft Research
Bangalore, Ấn Độ
t-lakagrawal@microsoft.comAditya Kanade
Microsoft Research
Bangalore, Ấn Độ
kanadeaditya@microsoft.com
Navin Goyal
Microsoft Research
Bangalore, Ấn Độ
navingo@microsoft.comShuvendu K. Lahiri
Microsoft Research
Redmond, Hoa Kỳ
shuvendu.lahiri@microsoft.com
Sriram K. Rajamani
Microsoft Research
Bangalore, Ấn Độ
sriram@microsoft.com

Tóm tắt
Các mô hình ngôn ngữ của mã nguồn (LMs) hoạt động tốt khi mã nguồn xung quanh cung cấp đủ ngữ cảnh. Điều này không đúng khi cần thiết phải sử dụng các kiểu, chức năng hoặc APIs được định nghĩa ở nơi khác trong kho lưu trữ hoặc thư viện liên kết, đặc biệt là những thứ không được thấy trong quá trình huấn luyện. LMs gặp phải hạn chế về nhận thức ngữ cảnh toàn cục như vậy và cuối cùng là ảo giác.

Các môi trường phát triển tích hợp (IDEs) hỗ trợ các nhà phát triển hiểu ngữ cảnh kho lưu trữ bằng cách sử dụng phân tích tĩnh. Chúng tôi mở rộng sự hỗ trợ này, được các nhà phát triển thưởng thức, cho LMs. Chúng tôi đề xuất giải mã được hướng dẫn bởi monitor (MGD) trong đó một monitor sử dụng phân tích tĩnh để hướng dẫn việc giải mã. Chúng tôi xây dựng một bộ dữ liệu cấp kho lưu trữ PRAGMATIC CODE cho việc hoàn thành phương thức trong Java và đánh giá MGD trên đó. Trên các mô hình có quy mô tham số khác nhau, bằng cách giám sát việc tham chiếu đối tượng nhất quán về kiểu, MGD liên tục cải thiện tỷ lệ biên dịch và sự đồng ý với sự thật cơ bản. Hơn nữa, LMs có ít tham số hơn, khi được tăng cường với MGD, có thể vượt trội hơn các LMs lớn hơn. Với MGD, SantaCoder-1.1B đạt được tỷ lệ biên dịch tốt hơn và khớp định danh tiếp theo so với mô hình text-davinci-003 lớn hơn nhiều.

Chúng tôi cũng tiến hành một nghiên cứu khả năng tổng quát hóa để đánh giá khả năng của MGD tổng quát hóa cho nhiều ngôn ngữ lập trình (Java, C# và Rust), các kịch bản mã hóa (ví dụ: số lượng đối số chính xác cho các lời gọi phương thức), và để thực thi các ràng buộc ngữ nghĩa phong phú hơn (ví dụ: các giao thức API có trạng thái). Dữ liệu và triển khai của chúng tôi có sẵn tại https://github.com/microsoft/monitors4codegen.

1 Giới thiệu
Các mô hình ngôn ngữ của mã nguồn (LMs), như trong Chen et al. (2021); Nijkamp et al. (2023); Allal et al. (2023) và nhiều cái khác, đang cách mạng hóa việc tạo mã nguồn. Nhiều dịch vụ thương mại dựa trên LMs, như GitHub Copilot, Amazon Code Whisperer và Replit, hiện đã có sẵn. Các LMs

Xuất hiện trong Hội nghị lần thứ 37 về Hệ thống Xử lý Thông tin Neural (NeurIPS 2023) với tên "Monitor-Guided Decoding of Code LMs with Static Analysis of Repository Context"arXiv:2306.10763v2 [cs.CL] 3 Nov 2023

--- TRANG 2 ---
t e x t - d a v i n c i - 0 0 3 và S a n t a C o d e r
S a n t a C o d e r với m o n i t o r g u i d e d d e c o d i n gPhương thức cần hoàn thành
(a) Ví dụ trong đó text-davinci-003 và SantaCoder tạo ra các định danh sai, nhưng SantaCoder với MGD tạo ra các định danh chính xác.
Method
parseServer
Stmts
... ExprStmt
...RetStmt
return Deref
MethodInvocation [UNKNOWN] Kiểu Đã Giải quyết
ServerNode.Builder
"ServerNode.Builder.newServerNode()"(b) AST một phần được chú thích cho mã ở bên trái.

Hình 1: Ví dụ động cơ để minh họa giải mã được hướng dẫn bởi monitor (MGD).

hoạt động tốt khi mã nguồn xung quanh trong vùng lân cận của việc tạo ra cung cấp đủ ngữ cảnh. Điều kiện này không thỏa mãn khi cần thiết phải sử dụng các kiểu, chức năng hoặc APIs được định nghĩa trong một mô-đun khác trong kho lưu trữ hoặc thư viện bên ngoài, đặc biệt là những thứ không được thấy trong quá trình huấn luyện. Trong trường hợp thiếu nhận thức về ngữ cảnh toàn cục như vậy, các LMs cuối cùng ảo giác, ví dụ: sử dụng các kiểu được định nghĩa trong các tệp khác một cách không chính xác. Hơn nữa, thiếu ngữ cảnh kho lưu trữ, các LMs có thể thiếu nhận thức về thông tin ngữ nghĩa khác như số lượng đối số cần thiết bởi một phương thức được gọi, hoặc các ràng buộc thứ tự trên các lời gọi phương thức (giao thức API) cần được tuân theo. Thường thì, thông tin kiểu và ngữ nghĩa như vậy có thể đến từ các artifact được tạo ra tại thời điểm xây dựng, như Project Lombok (lom, 2009) và ProtoBuf (pro, 2008), và do đó có thể thậm chí không có mặt như ngữ cảnh mã nguồn trong kho lưu trữ.

Như một ví dụ, hãy xem xét mã một phần (phương thức cần hoàn thành) trong Hình 1(a). Để hoàn thành mã này, một LM phải tạo ra các định danh nhất quán với kiểu của đối tượng được trả về bởi ServerNode.Builder.newServerNode(). Phương thức newServerNode và kiểu trả về của nó, lớp ServerNode.Builder, được định nghĩa trong một tệp khác. Nếu một LM không có thông tin về kiểu ServerNode.Builder, nó cuối cùng ảo giác.

Chúng tôi hiển thị một hoàn thành được tạo ra bởi các mô hình OpenAI text-davinci-003 (Ouyang et al., 2022) và SantaCoder (Allal et al., 2023) trong hộp được trang trí với ✖ trong Hình 1(a). Việc hoàn thành sử dụng các định danh host và port, không tồn tại trong kiểu ServerNode.Builder. Mã được tạo ra do đó dẫn đến lỗi biên dịch "symbol not found". Việc thiếu nhận thức về thông tin ngữ nghĩa khác từ ngữ cảnh toàn cục có thể dẫn đến các loại lỗi khác như lỗi thời gian biên dịch (ví dụ: "actual and formal argument lists differ in length" khi sử dụng số lượng đối số sai) hoặc lỗi thời gian chạy (ví dụ: IllegalStateException khi vi phạm giao thức API).

Các môi trường phát triển tích hợp (IDEs) đã đi đầu trong việc hỗ trợ các nhà phát triển. Cảm hứng của chúng tôi là việc sử dụng phân tích tĩnh bởi IDEs để mang ngữ cảnh toàn cục đến tầm tay của các nhà phát triển. Nhiều phân tích được tích hợp trong IDEs (Fuhrer, 2013) để suy luận và thực thi các ràng buộc ngữ nghĩa trên mã đang phát triển, ví dụ: giải quyết def-use, tham chiếu ký hiệu, và phân cấp kiểu. Gần đây, đã có sự gia tăng trong việc sử dụng Giao thức Máy chủ Ngôn ngữ (LSP) (lsp), là một tiêu chuẩn công nghiệp mở về giao tiếp giữa IDEs và các công cụ cụ thể cho ngôn ngữ lập trình như các bộ phân tích tĩnh và trình biên dịch, được gọi là Máy chủ Ngôn ngữ. Có một số lượng lớn Máy chủ Ngôn ngữ có sẵn, nhắm mục tiêu hầu hết các ngôn ngữ lập trình (lan, 2023), và cung cấp nhiều thông tin cú pháp và ngữ nghĩa. Trong công việc này, chúng tôi tập trung vào phân tích hoàn thành mã hướng kiểu có sẵn thông qua LSP theo cách bất khả tri ngôn ngữ, để cung cấp hướng dẫn cho một LM.

Chúng tôi đề xuất một khái niệm về các monitor như một giao diện có trạng thái giữa LMs và phân tích tĩnh. Một monitor quan sát mã được tạo ra bởi một LM và truy vấn phân tích tĩnh tại các điểm kích hoạt được định nghĩa trước. Các gợi ý được trả về bởi phân tích tĩnh được chuyển đổi thành các mặt nạ được sử dụng để định hình lại các logits (hoặc tương đương, xác suất tạo token) được tạo ra bởi LM trong các bước giải mã tiếp theo. Chúng tôi gọi phương pháp của chúng tôi là giải mã được hướng dẫn bởi monitor (MGD). Không như một LM, một phân tích tĩnh hoạt động trên toàn bộ kho lưu trữ và các phụ thuộc của nó. Trong khi LM tạo ra các hoàn thành bằng cách điều kiện hóa trên ngữ cảnh cục bộ, phân tích tĩnh đảm bảo tính nhất quán với phần còn lại của mã trong kho lưu trữ. Thông qua MGD, chúng tôi mang hai cái này lại với nhau mà không cần huấn luyện lại LM, và tạo ra một bổ sung nhỏ và mô-đun cho giai đoạn giải mã của LM.

2

--- TRANG 3 ---
Hình 1(a) cũng hiển thị mã được tạo ra bởi mô hình SantaCoder với MGD trong hộp được trang trí với ✓. Mã này sử dụng các định danh thực sự được định nghĩa trong lớp ServerNode.Builder. Nó biên dịch và khớp với sự thật cơ bản. Để so sánh, cùng mô hình SantaCoder không có MGD tạo ra mã lỗi được hiển thị trong hộp được trang trí với ✖.

Một số phương pháp gần đây sử dụng phân tích tĩnh (Shrivastava et al., 2022; Ding et al., 2022; Pei et al., 2023) hoặc truy xuất (Zhang et al., 2023) để trích xuất các đoạn mã có liên quan từ ngữ cảnh toàn cục. Các phương pháp này mở rộng prompt (Shrivastava et al., 2022; Pei et al., 2023; Zhang et al., 2023) hoặc yêu cầu các sửa đổi kiến trúc (Ding et al., 2022) và huấn luyện bổ sung (Ding et al., 2022; Pei et al., 2023). Để so sánh, chúng tôi cung cấp hướng dẫn cấp token cho một LM đông lạnh bằng cách gọi phân tích tĩnh theo yêu cầu. Phương pháp của chúng tôi bổ sung cho các phương pháp này vì chúng điều kiện hóa việc tạo ra bằng cách sửa đổi đầu vào cho LM, trong khi chúng tôi áp dụng các ràng buộc phía đầu ra bằng cách định hình lại các logits.

Chúng tôi đóng góp như sau trong bài báo này:
• Giải mã Được hướng dẫn bởi Monitor (MGD) như một giao diện có trạng thái giữa LMs và phân tích tĩnh. Một monitor theo dõi LM tạo mã, truy vấn phân tích tĩnh trong nền, và sử dụng thông tin từ phân tích tĩnh để hướng dẫn hiệu quả giai đoạn giải mã của LMs.
• PRAGMATIC CODE, một bộ dữ liệu được phát hành công khai của các kho lưu trữ mã Java hoàn chỉnh với môi trường phát triển và phụ thuộc của chúng.
• Khởi tạo MGD cho việc tạo mã có các tham chiếu định danh nhất quán về kiểu.
• Đánh giá quy mô lớn trên PRAGMATIC CODE cho thấy: (1) MGD liên tục cải thiện khả năng của một LM (qua các quy mô tham số khác nhau) để tạo ra các định danh nhất quán về kiểu, tỷ lệ biên dịch và sự đồng ý với sự thật cơ bản. (2) Hơn nữa, LMs có ít tham số hơn, kết hợp với MGD, có thể vượt trội hơn các LMs lớn hơn. Ví dụ, SantaCoder-1.1B với MGD đạt được tỷ lệ biên dịch tốt hơn và khớp định danh tiếp theo so với mô hình text-davinci-003 lớn hơn nhiều, khi cả hai có ngân sách 1 tạo ra mỗi cái. Với ngân sách 4 tạo ra, nó cũng vượt qua sự đồng ý với sự thật cơ bản của text-davinci-003. (3) Chúng tôi cũng đánh giá cách MGD bổ sung cho các chiến lược tăng cường prompt và giải mã khác nhau.
• Microbenchmark để chứng minh khả năng tổng quát hóa của MGD cho (1) các ngôn ngữ lập trình khác nhau, (2) các kịch bản mã hóa, và (3) sử dụng các kỹ thuật phân tích tĩnh khác để hướng dẫn với các thuộc tính ngữ nghĩa phong phú. Đáng chú ý, chúng tôi chứng minh rằng các LMs nhỏ có thể được hướng dẫn để tuân thủ các thuộc tính tĩnh phong phú như thỏa mãn các giao thức API có trạng thái.
• Chúng tôi mở nguồn triển khai của chúng tôi và cung cấp một thư viện Python có thể mở rộng được gọi là multilspy với các ràng buộc phân tích tĩnh cho nhiều ngôn ngữ qua LSP, phù hợp cho việc giám sát LMs. Nó có thể được sử dụng cho các kịch bản AI4Code khác cũng vậy.

2 Giải mã Được hướng dẫn bởi Monitor
Bối cảnh. Phân tích tĩnh của mã (Nielson et al., 2015) được sử dụng rộng rãi trong ngành công nghiệp trong các ứng dụng khác nhau như phát hiện lỗi và tối ưu hóa mã. Trong khi phân tích thường được thực hiện trên mã hoàn chỉnh, IDEs đã lâu áp dụng phân tích tĩnh trên mã chưa hoàn chỉnh đang phát triển (Reps et al., 1983; Dagenais & Hendren, 2008), sử dụng các thuật toán cho việc phân tích cú pháp tăng dần và phân tích ngữ nghĩa (ví dụ: suy luận kiểu) của mã một phần (Hedin, 1992; Wagner, 1997; Maddox III, 1997). Những phân tích này hiện đã trở thành một phần tiêu chuẩn của các máy chủ ngôn ngữ.

Một trừu tượng hóa chính được sử dụng trong phân tích mã một phần là các cây cú pháp trừu tượng một phần (ASTs) với các nút đặc biệt để chỉ ra các phần chưa hoàn chỉnh của mã. Những ASTs này được trang trí thêm bởi thông tin ngữ nghĩa thông qua các ngữ pháp thuộc tính (Reps et al., 1983) trang trí mỗi nút AST với các thuộc tính nắm bắt ngữ nghĩa tĩnh không được nắm bắt trong ngữ pháp phi ngữ cảnh (như tính nhất quán của các kiểu trong các biểu thức trong một phép gán). Điều này có thể dao động từ việc tính toán phân cấp kiểu cho các ngôn ngữ hướng đối tượng, ràng buộc các biến trong các nút AST với các khai báo của chúng, giải quyết các kiểu của biểu thức cũng như tính toán các mối quan hệ def-use cho các nút AST đã giải quyết (Fuhrer, 2013).

Hình 1(b) hiển thị AST một phần cho mã chưa hoàn chỉnh trong Hình 1(a). Tất cả các câu lệnh cho đến câu lệnh return chưa hoàn chỉnh được phân tích cú pháp hoàn toàn và các cây con tương ứng với chúng được xây dựng. Cây con cho câu lệnh return bao gồm một nút [UNKNOWN] chỉ ra phần chưa hoàn chỉnh. Như hiển thị trong Hình 1(b), một phân tích ngữ nghĩa tăng dần giải quyết kiểu của biểu thức một phần ServerNode.Builder.newServerNode() thành ServerNode.Builder. Sau đó, chúng tôi hiển thị cách sử dụng thông tin kiểu này để xây dựng một monitor, sau đó có thể được sử dụng để hướng dẫn một LM tạo ra các hoàn thành định danh nhất quán về kiểu.

3

--- TRANG 4 ---
Các Khái niệm Cơ bản và Ký hiệu. Xem xét một LM Lθ hoạt động trên một từ vựng V. Gọi x1, . . . , xn là mã một phần đã được tạo ra bởi LM và xn+1 là một token ứng cử viên tiếp theo. Mặc dù một prompt vanilla (tự hồi quy) chỉ bao gồm x1, . . . , xn, ngày nay nhiều phương pháp tăng cường nó với thông tin bổ sung. Chúng tôi sử dụng p để chỉ prompt bổ sung này, ví dụ: thông tin hậu tố được sử dụng trong prompting fill-in-the-middle (Donahue et al., 2020; Fried et al., 2022; Bavarian et al., 2022).

Một thuộc tính φ chỉ định các ràng buộc mà một đoạn mã cần thỏa mãn. Một phân tích tĩnh Aφ kiểm tra xem mã một phần có thỏa mãn φ hay không. Nếu có, nó trả về các gợi ý để mở rộng nó sao cho mã được mở rộng tiếp tục thỏa mãn φ. Phân tích tĩnh hoạt động trên ngữ cảnh kho lưu trữ C không chỉ bao gồm mã trải rộng trên nhiều tệp trong kho lưu trữ, mà còn các phụ thuộc bên ngoài và các artifact trung gian (ví dụ: các ràng buộc mã) được tạo ra trong quá trình xây dựng. Ngữ cảnh kho lưu trữ như vậy thường rất lớn, đa dạng và phức tạp. Bao gồm trực tiếp nó như một đầu vào cho LM sẽ dẫn đến phình to và chuyển gánh nặng chưng cất thông tin hữu ích từ nó cho LM.

Một monitor Mφ cho một thuộc tính φ là một tuple (Aφ, s0, S, pre, update, maskgen). Monitor bắt đầu trong trạng thái chờ s0. Nếu mã một phần thỏa mãn điều kiện tiên quyết pre thì monitor được kích hoạt và nó gọi Aφ trên mã một phần. Monitor duy trì các gợi ý được trả về bởi Aφ trong trạng thái của nó và sử dụng chúng để hướng dẫn việc lấy mẫu token tiếp theo xn+1. Gọi S là tập hợp các trạng thái và s, s′ ∈ S tương ứng là các trạng thái hiện tại và tiếp theo của monitor. Với mỗi token được lấy mẫu xn+1, monitor cập nhật trạng thái của nó bằng cách sử dụng một hàm update(s, xn+1) thành một trạng thái mới s′, theo dõi các gợi ý còn lại sau khi token xn+1 được xuất ra. Khi các gợi ý được cạn kiệt, nó quay trở lại trạng thái chờ s0. Chúng tôi giải thích hàm maskgen bên dưới.

Quy trình Giải mã. Thông thường, token tiếp theo xn+1 có thể là bất kỳ token nào từ từ vựng V, được lấy mẫu dựa trên các logits ℓ được xác định bởi LM. Không như giải mã thông thường, trong giải mã được hướng dẫn bởi monitor, chúng tôi giám sát việc tạo mã bằng cách sử dụng một monitor Mφ cho một thuộc tính φ. Chúng tôi ký hiệu sự kết hợp của Lθ và Mφ bằng Lθ||Mφ, có nghĩa là cả LM và monitor đều chạy đồng thời và lấy mẫu các token cùng nhau. Việc giải mã được điều kiện hóa trên mã một phần x1, . . . , xn, ngữ cảnh kho lưu trữ C, prompt p và trạng thái hiện tại s của monitor.

Phương trình (1) nói rằng bất cứ khi nào monitor ở trong trạng thái chờ s0, chúng tôi lấy mẫu xn+1 theo các logits ℓ được xác định bởi LM (Phương trình (2)). Nếu không, các logits được kết hợp với một mặt nạ m sử dụng một hàm ⊕ sao cho nếu m[x] = 0 thì ℓ[x] được đặt lại thành một giá trị âm lớn −K và được để nguyên nếu không. Mặt nạ này được tính toán bởi hàm maskgen trong Phương trình (3) được hướng dẫn bởi trạng thái hiện tại s của monitor. Phương trình (4) định nghĩa cách trạng thái của monitor phát triển. Khi điều kiện tiên quyết pre(s; x1, . . . , xn) đánh giá thành true, trạng thái tiếp theo s′ của monitor được xác định bởi các gợi ý được trả về bởi phân tích tĩnh Aφ. Nếu không, nó được xác định bởi hàm update.

(Lθ||Mφ)(xn+1|x1, . . . , xn; C, p, s) =
softmax(ℓ)[xn+1] nếu s=s0 là trạng thái chờ
softmax(ℓ⊕m)[xn+1] nếu không(1)
ℓ=Lθ(· |x1, . . . , xn; p) (2)
m=maskgen(s, V) (3)
s′=
Aφ(x1, . . . , xn; C) nếu s=s0∧pre(s; x1, . . . , xn)
update(s, xn+1) nếu không(4)

Các chi tiết cụ thể của trạng thái monitor, và các hàm pre, update và maskgen phụ thuộc vào phân tích tĩnh Aφ được sử dụng bởi monitor. Công thức của chúng tôi là tổng quát và thậm chí cho phép kết hợp nhiều phân tích tĩnh bằng cách lấy tích của không gian trạng thái của các monitor tương ứng của chúng. Trong phần sau, chúng tôi thảo luận về một khởi tạo cụ thể của khung giải mã được hướng dẫn bởi monitor này.

Giám sát cho Việc sử dụng Định danh Nhất quán về Kiểu. Khi một đối tượng obj của một kiểu T được tham chiếu, token tiếp theo (hoặc tổng quát hơn, chuỗi các subtoken) nên tham chiếu đến một định danh của một trường hoặc phương thức được định nghĩa bởi kiểu T. Nếu không, nó có thể dẫn đến lỗi "symbol not found". Kiểu T có thể được định nghĩa trong một gói khác, tệp được nhập hoặc trong một thư viện. Trừ khi T đến từ một thư viện phổ biến được thấy trong quá trình huấn luyện, LM có thể không có kiến thức về T. Monitor Mφ của chúng tôi được kích hoạt khi mã một phần x1, . . . , xn kết thúc bằng một biểu thức tham chiếu đối tượng một phần "obj." trong đó "." là phép toán tham chiếu. Đây là điều kiện tiên quyết pre mà chúng tôi sử dụng. Chúng tôi sử dụng một phân tích tĩnh Aφ trả về tất cả các định danh nhất quán về kiểu có thể được tham chiếu thông qua obj. Để làm điều này, Aφ thực hiện một phân tích toàn cục trên mã một phần, các tệp được nhập, thư viện được sử dụng, và phân cấp lớp để suy luận kiểu T của obj và các định danh có thể truy cập thông qua T. Tập hợp các định danh nhất quán về kiểu được trả về bởi Aφ tạo thành trạng thái của monitor (xem Phương trình (4)).

4

--- TRANG 5 ---
Cho một trạng thái s và từ vựng V của LM, maskgen xác định tất cả các token trong V nhất quán với các gợi ý trong s. Các định danh được trả về bởi phân tích tĩnh là các token theo ngôn ngữ lập trình, trong khi từ vựng V có thể sử dụng không gian subtoken riêng của nó (Schuster & Nakajima, 2012; Kudo & Richardson, 2018). Mặt nạ m (Phương trình (3)) được tạo ra bằng cách khớp chuỗi. Đối với tất cả các token t ∈ V tạo thành tiền tố của các định danh trong s, giá trị mặt nạ m[t] được đặt thành 1, chỉ ra rằng chúng có thể được lấy mẫu. Gọi E là tập hợp các ký hiệu đặc biệt chỉ ra kết thúc của một tên định danh, ví dụ: ký hiệu '(' trong 'getName(' hoặc ',' trong 'x,'. Gọi w là một chuỗi trong s và Σ là tập hợp tất cả các ký tự có thể. Nếu một token t ∈ V khớp với biểu thức chính quy w·E·Σ* thì giá trị mặt nạ m[t] của nó cũng được đặt thành 1. Đối với tất cả các token khác t trong V, giá trị mặt nạ m[t] được đặt thành 0.

Gọi xn+1 là token tiếp theo được lấy mẫu theo phương trình thứ hai trong Phương trình (1). Nếu xn+1 chứa một ký hiệu từ E, chỉ ra rằng một tên định danh hoàn chỉnh đã được tạo ra phù hợp với tập hợp được trả về bởi Aφ, monitor quay trở lại trạng thái chờ để chờ kích hoạt tiếp theo. Nếu không, token xn+1 phải là một tiền tố của một thành viên trong s. Hàm update loại bỏ các thành viên trong s không được bắt đầu bởi xn+1, và những thành viên được bắt đầu bởi xn+1 được cập nhật bằng cách cắt bỏ chuỗi tiền tố xn+1. Tập hợp các chuỗi ký tự kết quả tạo thành trạng thái tiếp theo s′ (xem phương trình thứ hai trong Phương trình (4)).

Nếu Aφ trả về một tập hợp rỗng ngay từ đầu, chúng tôi bỏ qua lần chạy hiện tại. Lưu ý rằng một định danh duy nhất có thể cần được tạo ra bằng cách sử dụng nhiều token. Hình 4 (xem Phụ lục A) hiển thị sự tương tác giữa LM và monitor cho ví dụ trong Hình 1, và cụ thể minh họa cách các tên định danh hoàn chỉnh được đề xuất bởi phân tích tĩnh được cắt bỏ dần bởi monitor thành các hậu tố tương ứng trong mỗi trạng thái liên tiếp khi các tiền tố được tạo ra như các token.

3 Thiết lập Thực nghiệm
Tạo Bộ dữ liệu. Để đánh giá MGD, chúng tôi cần các kho lưu trữ thực tế với môi trường xây dựng và phụ thuộc của chúng. Hầu hết các bộ dữ liệu đã xuất bản đều độc lập, ngoại trừ CoderEval (Yu et al., 2023) và PyEnvs (Pei et al., 2023), cả hai đều không có sẵn công khai tại thời điểm viết bài này. Do đó chúng tôi đã tuyển chọn PRAGMATIC CODE, một bộ dữ liệu của các dự án Java nguồn mở thực tế hoàn chỉnh với môi trường phát triển và phụ thuộc của chúng. Chúng tôi đảm bảo rằng các kho lưu trữ này chỉ được phát hành công khai sau ngày cắt bộ dữ liệu huấn luyện đã xác định (31 tháng 3 năm 2022) của các mô hình mà chúng tôi sử dụng để đánh giá MGD.

Từ PRAGMATIC CODE, chúng tôi xác định một tập hợp các thể hiện nhiệm vụ hoàn thành cấp phương thức, tạo ra DOTPROMPTS như một benchmark hoàn thành mã cấp phương thức. Mỗi testcase trong DOTPROMPTS bao gồm một prompt cho đến một vị trí tham chiếu (sử dụng toán tử "." trong Java) trong một phương thức mục tiêu, và nhiệm vụ là hoàn thành phần còn lại của phương thức. Chúng tôi đảm bảo độ phức tạp đủ trong các phương thức mục tiêu đã xác định trong DOTPROMPTS bằng cách bao gồm các phương thức thỏa mãn một tập hợp các bộ lọc độ phức tạp (ví dụ: phương thức nên có ít nhất 7 dòng mã) được mô tả chi tiết trong phụ lục B. Tổng thể, PRAGMATIC CODE bao gồm 100 kho lưu trữ, và DOTPROMPTS bao gồm 1420 phương thức và 10538 prompt tham chiếu. Phụ lục B cung cấp chi tiết thêm.

Mô hình. Chúng tôi nghiên cứu hiệu ứng của việc thực hiện MGD trên việc tạo mã với triển khai HuggingFace Transformers (Wolf et al., 2020) của họ mô hình Salesforce CodeGen (CodeGen-{350M, 2B, 6B}-Multi, viết tắt là CG-{350M, 2B, 6B} sau đây) (Nijkamp et al., 2023) và BigCode SantaCoder-1.1B (SC hoặc SantaCoder sau đây) (Allal et al., 2023). Chúng tôi cũng đánh giá OpenAI text-davinci-003 (TD-3 sau đây) với và không có MGD, có sẵn trên Azure.

Chiến lược Prompting. Chúng tôi nghiên cứu hiệu ứng của các kỹ thuật tăng cường prompt khác nhau khi kết hợp với MGD: (1) Standard: Bao gồm nội dung tệp cục bộ cho đến điểm tham chiếu và cắt bỏ từ bên trái để phù hợp với ngân sách prompt. (2) classExprTypes: Đối với một phương thức mục tiêu cho trước thuộc về một lớp C, xác định kiểu của tất cả các biểu thức xuất hiện trong C (sau khi che dấu phương thức mục tiêu để ngăn rò rỉ) và bao gồm nội dung tệp được nối của tất cả các tệp định nghĩa kiểu đã xác định, cắt bỏ từ bên trái khi cần thiết. Chúng tôi gán ngân sách 20% token của tổng ngân sách prompt cho classExprTypes. (3) RLPG: Sử dụng kỹ thuật tăng cường prompt được đề xuất trong Shrivastava et al. (2022). Chúng tôi sử dụng mã nguồn đã phát hành và các checkpoint mô hình của họ để điều chỉnh RLPG cho DOTPROMPTS.

5

--- TRANG 6 ---
Bảng 1: Tóm tắt kết quả với ngân sách 6 thế hệ mỗi mô hình: Các số trong ngoặc là cải thiện tương đối của cấu hình "-MGD" so với mô hình cơ sở tương ứng.

Config \ (Metric, score@6) CR NIM ISM PM
CG-350M 52.43 76.94 31.86 26.86
CG-350M-MGD 65.37 (24.69%) 83.80 (8.92%) 34.31 (7.70%) 28.69 (6.82%)
CG-2B 57.01 81.11 36.38 30.95
CG-2B-MGD 70.91 (24.38%) 87.32 (7.66%) 39.03 (7.29%) 33.06 (6.82%)
CG-6B 58.64 81.55 37.17 31.69
CG-6B-MGD 72.28 (23.25%) 87.35 (7.11%) 39.55 (6.41%) 33.56 (5.89%)
SC 59.97 82.40 38.14 32.10
SC-MGD 73.03 (21.77%) 88.42 (7.31%) 40.69 (6.68%) 34.25 (6.72%)
SC-classExprTypes 64.57 84.91 39.67 33.55
SC-classExprTypes-MGD 75.01 (16.18%) 89.37 (5.25%) 41.56 (4.78%) 34.98 (4.26%)
SC-RLPG 66.39 85.42 42.35 36.21
SC-RLPG-MGD 78.14 (17.70%) 89.89 (5.23%) 44.47 (5.00%) 37.97 (4.87%)
SC-FIM 68.23 85.56 42.22 36.12
SC-FIM-MGD 80.19 (17.52%) 89.89 (5.07%) 44.50 (5.39%) 37.91 (4.95%)
SC-FIM-classExprTypes 70.97 86.99 42.67 36.36
SC-FIM-classExprTypes-MGD 80.33 (13.18%) 90.42 (3.94%) 44.18 (3.54%) 37.75 (3.82%)
TD-3 62.66 86.18 44.97 38.77
TD-3-MGD 74.26 (18.52%) 91.19 (5.81%) 47.33 (5.24%) 39.94 (3.03%)

Chiến lược Giải mã. Chúng tôi thực nghiệm với hai chiến lược giải mã: (1) Tự hồi quy: cho giải mã từ trái sang phải. (2) Fill-in-the-middle: Sử dụng thiết lập fill-in-the middle (FIM) được triển khai trong SantaCoder (Allal et al., 2023).

Chỉ số. Chúng tôi sử dụng các chỉ số sau để đo chất lượng của mã được tạo ra: (1) Tỷ lệ Biên dịch (CR): Chúng tôi thay thế phương thức sự thật cơ bản bằng phương thức được tạo ra trong ngữ cảnh của kho lưu trữ hoàn chỉnh và gọi một bản xây dựng sạch. Chúng tôi gán điểm 1 nếu việc biên dịch thành công, và 0 nếu không. (2) Khớp với sự thật cơ bản: Chúng tôi sử dụng ba chỉ số cụ thể để đo mức độ gần gũi của việc tạo ra khớp với sự thật cơ bản, cụ thể là (a): Khớp Định danh Tiếp theo (NIM): Nếu token Java đầu tiên được tạo ra bởi LM khớp với sự thật cơ bản, chúng tôi gán điểm 1, 0 nếu không; (b) Khớp Chuỗi Định danh (ISM): Khớp tiền tố dài nhất giữa tập hợp có thứ tự của các tên định danh trong sự thật cơ bản và hoàn thành được tạo ra, được chuẩn hóa bởi số lượng định danh trong sự thật cơ bản; và (c) Khớp Tiền tố (PM): Khớp tiền tố dài nhất giữa tập hợp có thứ tự của các token Java (như được lấy từ Java Lexer) giữa sự thật cơ bản và hoàn thành được tạo ra, được chuẩn hóa bởi số lượng token trong sự thật cơ bản. Ngoại trừ NIM, tất cả các chỉ số khác - cụ thể là CR, ISM và PM - đánh giá việc tạo ra cấp phương thức hoàn chỉnh bởi mô hình.

Trong các thực nghiệm của chúng tôi, đối với tất cả các cấu hình mô hình đã đánh giá, chúng tôi sử dụng nucleus sampling (Holtzman et al., 2020) với giá trị top-p là 0.95 để tạo ra n = 6 mẫu độc lập. Đối với ngân sách k ∈ [1, n] mẫu, chúng tôi tính toán điểm tổng hợp score@k (xem Phụ lục D). Trên các chỉ số có giá trị rời rạc (CR và NIM), nó giống hệt với pass@k,n (Chen et al., 2021), ước tính số lần mong đợi danh sách k ứng cử viên chứa ít nhất một biên dịch thành công hoặc khớp với định danh sự thật cơ bản. Trên các chỉ số có giá trị thực (ISM và PM), nó ước tính kỳ vọng của giá trị tối đa của chỉ số tương ứng cho k cơ hội.

Thư viện Python cho MGD. Chúng tôi đang phát hành một thư viện Python có thể mở rộng, multilspy, cho việc giao tiếp giữa LMs và các máy chủ ngôn ngữ sử dụng LSP. Nó có thể được sử dụng với nhiều ngôn ngữ lập trình, phân tích tĩnh và LMs. Nó cũng hỗ trợ một cơ chế xấp xỉ cho MGD của các LMs hộp đen với hỗ trợ che dấu logit hạn chế. Vui lòng tham khảo Phụ lục C để biết thêm chi tiết.

4 Đánh giá
Bảng 1 hiển thị tóm tắt kết quả cho tất cả các thực nghiệm và chỉ số của chúng tôi. Đối với các cấu hình "-MGD", chúng tôi cũng báo cáo cải thiện tương đối so với mô hình cơ sở trong ngoặc, trong đó mô hình cơ sở là cùng cấu hình mô hình không có MGD. Dưới đây, chúng tôi trình bày một đánh giá chi tiết.

4.1 Hiệu ứng của MGD trên Các mô hình qua Quy mô Tham số và Kiến trúc
Chúng tôi trình bày kết quả cho tất cả các mô hình trên các prompt Standard được mô tả trong Phần 3.

6

--- TRANG 7 ---
(a) CR (b) NIM
(c) ISM (d) PM

Hình 2: score@k cho các mô hình với MGD và prompt Standard so sánh với các mô hình cơ sở. Các giá trị k ∈ [1,6] được đánh dấu trên trục X.

Tỷ lệ Biên dịch. Như hiển thị trong Hình 2a, tất cả các mô hình cơ sở với MGD, bao gồm mô hình nhỏ nhất CodeGen-350M cho k ≥ 4, vượt trội hơn mô hình lớn nhất text-davinci-003, với biên độ tương đối tối đa 16.55% đạt được bởi SantaCoder. Tất cả các mô hình với MGD vượt trội hơn các mô hình cơ sở tương ứng của chúng về Tỷ lệ Biên dịch, với cải thiện tương đối dao động từ 21.77%-24.69%. TD-3-MGD vượt trội hơn TD-3 với biên độ tương đối 18.52%.

Khớp Định danh Tiếp theo. Như thấy trong Hình 2b, tất cả các mô hình với MGD vượt trội hơn các mô hình cơ sở tương ứng, với cải thiện tương đối từ 7.11%-8.92%. Mô hình nhỏ nhất CodeGen-350M với MGD vượt trội hơn CodeGen-6B lớn hơn nhiều với cải thiện tương đối 2.76%. SantaCoder với MGD vượt trội hơn CodeGen-6B lớn hơn với biên độ tương đối 8.42%, và thậm chí mô hình lớn nhất text-davinci-003 với 2.60%. TD-3-MGD vượt trội hơn TD-3 với biên độ tương đối 5.81%.

Khớp Chuỗi Định danh. Hình 2c hiển thị rằng tất cả các mô hình với MGD vượt trội hơn các mô hình cơ sở tương ứng của chúng về ISM, hiển thị cải thiện tương đối dao động từ 6.41%-7.70%. SantaCoder và CodeGen-2B với MGD vượt trội hơn CodeGen-6B lớn hơn với biên độ tương đối 9.47% và 5.00% tương ứng. TD-3-MGD vượt trội hơn TD-3 với biên độ tương đối 5.24%

Khớp Tiền tố. Hình 2d hiển thị phần trăm khớp tiền tố với sự thật cơ bản. Tất cả các mô hình với MGD vượt trội hơn các mô hình cơ sở tương ứng của chúng với cải thiện tương đối từ 5.89%-6.82%. Cả SantaCoder và CodeGen-2B với MGD đều vượt trội hơn CodeGen-6B lớn hơn với biên độ tương đối 8.08% và 4.30%. TD-3-MGD vượt trội hơn TD-3 với biên độ tương đối 3.03%.

7

--- TRANG 8 ---
SC-MGD so với TD-3. SC là một mô hình 1.1B tham số trong khi TD-3 có 175B tham số. Là một mô hình lớn hơn nhiều và có thể do các khác biệt khác trong huấn luyện, TD-3 làm tốt hơn SC trên tất cả các chỉ số. Thú vị là, với MGD, SC-MGD vượt trội hơn TD-3 về CR (Hình 2a) và NIM (Hình 2b). ISM và PM là các chỉ số cấp phương thức và lợi thế tương đối của mô hình lớn hơn vẫn chiếm ưu thế. Thậm chí vậy, với một sự gia tăng nhỏ trong ngân sách lấy mẫu, từ k = 1 đến k = 4, SC-MGD đã có thể vượt qua hiệu suất của TD-3 với k = 1 về ISM (Hình 2c) và PM (Hình 2d).

Tóm tắt. MGD cải thiện khả năng biên dịch của mã một cách đáng kể, qua các kiến trúc và quy mô tham số, dẫn đến thậm chí CodeGen-350M nhỏ nhất với MGD vượt trội hơn LM lớn nhất, text-davinci-003. Chúng tôi cũng thấy cải thiện trong tất cả các chỉ số đồng ý với sự thật cơ bản. Đáng chú ý, các LMs nhỏ hơn với MGD vượt trội hơn các LMs lớn hơn (CodeGen-350M với MGD vượt trội hơn text-davinci-003 về CR và NIM, CodeGen-2B với MGD vượt trội hơn CodeGen-6B về ISM và PM) trên tất cả các chỉ số.

4.2 Hiệu ứng của MGD và Chiến lược Tăng cường Prompt
Chúng tôi chọn mô hình cơ sở hoạt động tốt nhất, SantaCoder, từ Phần 4.1 để nghiên cứu hiệu ứng của prompting khi kết hợp với MGD. Hình 3 hiển thị kết quả cho SantaCoder-{Standard, classExprTypes, RLPG} và TD-3, so sánh với SantaCoder với các prompt tương ứng và MGD.

Tỷ lệ Biên dịch. Hình 3a hiển thị kết quả cho Tỷ lệ Biên dịch. Chúng tôi quan sát cải thiện trong tỷ lệ biên dịch với cả hai kỹ thuật prompting, classExprTypes và RLPG, với RLPG vượt trội nhẹ so với classExprTypes. Chúng tôi lưu ý rằng SantaCoder với prompt Standard và MGD có thể cải thiện tương đối so với cả RLPG và tăng cường classExprTypes lần lượt là 10.01% và 13.11%. Hơn nữa, SantaCoder với RLPG và MGD có thể vượt trội hơn SantaCoder-RLPG và SantaCoder-classExprTypes với biên độ tương đối 17.70% và 21.02% tương ứng, trong khi tăng biên độ cải thiện tương đối so với text-davinci-003 lên 24.70%.

Khớp Định danh Tiếp theo. Như thấy trong Hình 3b, tương tự như biên dịch, cả tăng cường prompt RLPG và classExprTypes đều dẫn đến cải thiện so với mô hình cơ sở. Tuy nhiên, SantaCoder với một trong hai tăng cường prompt kém hiệu suất hơn text-davinci-003. SantaCoder với MGD vượt trội hơn TD-3, và do đó, cả SantaCoder-RLPG và SantaCoder-classExprTypes với cải thiện tương đối 2.60%, 3.51% và 4.14% tương ứng. SantaCoder với prompting và MGD vượt trội hơn các baseline tương ứng của chúng (SantaCoder với prompting) với biên độ tương đối trong khoảng 5.23%-5.25%. Chúng tôi lưu ý rằng SantaCoder với RLPG và MGD tăng cải thiện tương đối so với mô hình lớn nhất, text-davinci-003 lên 4.31%.

Khớp Chuỗi Định danh. Về ISM, SantaCoder với tăng cường prompt và MGD có thể vượt trội hơn baseline tương ứng của nó với cải thiện tương đối 4.78%-5.00%, trong khi cả hai tăng cường prompt đều dẫn đến cải thiện so với mô hình cơ sở. SantaCoder với RLPG và MGD có thể giảm đáng kể khoảng cách với text-davinci-003, kém hiệu suất chỉ 1.11%.

Khớp Tiền tố. Như thấy trong Hình 3d, SantaCoder với tăng cường prompt và MGD có thể vượt trội hơn baseline tương ứng của nó với 4.26%-4.87%.

Tóm tắt. Trong khi các kỹ thuật tăng cường prompt giúp cải thiện hiệu suất trên tất cả các chỉ số, chúng tôi thấy cải thiện thêm với tăng cường MGD, và kết luận rằng các đóng góp bởi tăng cường prompt và MGD là bổ sung. Đáng chú ý, SantaCoder-RLPG với MGD cải thiện biên độ tương đối cho tỷ lệ biên dịch so với text-davinci-003 lên 24.70% so với cải thiện 16.55% đạt được bởi SC-MGD, hoặc cải thiện 5.95% đạt được bởi SC-RLPG.

4.3 Hiệu ứng của MGD trên Giải mã Fill-in-the-middle (FIM)
Trong số các mô hình cơ sở, SantaCoder hỗ trợ kiểu FIM. Chúng tôi đánh giá SantaCoder với các chiến lược giải mã tự hồi quy và FIM và text-davinci-003, và so sánh chúng với các cấu hình tương ứng của SantaCoder với MGD. Tương tự như quan sát của chúng tôi với tăng cường prompt, trong khi kiểu FIM dẫn đến cải thiện trên tất cả các chỉ số, chúng tôi thấy cải thiện tiếp tục khi sử dụng cả FIM và MGD. Do hạn chế về không gian, kết quả chi tiết ở Phụ lục E. Được thúc đẩy bởi tính chất bổ sung của FIM và MGD, chúng tôi đánh giá thêm SC-FIM-classExprTypes-MGD, kết hợp cả tăng cường prompt và kiểu FIM. Phù hợp với những phát hiện của chúng tôi, nó dẫn đến cải thiện thêm so với SC-FIM-classExprTypes, như thấy trong Hình 5 (Phụ lục E).

8

--- TRANG 9 ---
(a) CR (b) NIM
(c) ISM (d) PM

Hình 3: score@k cho các mô hình với MGD và tăng cường prompt so sánh với các mô hình cơ sở.

4.4 Hiệu ứng của Độ phức tạp Định danh trên Khớp Định danh Tiếp theo
Tên định danh trong các kho lưu trữ có thể trở nên cụ thể và dài (Karampatsis et al., 2020). Do điều này, trong khi các APIs thường được sử dụng có thể được token hóa thành các token đơn lẻ, các định danh cụ thể cho ngữ cảnh của các kho lưu trữ riêng lẻ, đặc biệt trong các thiết lập riêng tư, có thể mở rộng qua nhiều subtoken trong từ vựng LM. Chúng tôi định nghĩa độ phức tạp của một định danh là số trung bình của các subtoken cần thiết để giải mã nó. Chúng tôi hiển thị rằng khả năng của LMs dự đoán chính xác tên định danh giảm mạnh với sự gia tăng độ phức tạp định danh, trong khi tăng cường chúng với MGD cải thiện hiệu suất của chúng. MGD cung cấp một cải thiện trong khoảng 21.79%-27.91% so với mô hình cơ sở không có MGD, qua các quy mô tham số, cho độ phức tạp định danh cao nhất, chiếm hơn 36% các phương thức trong DOTPROMPTS. Kết quả chi tiết có sẵn trong Phụ lục F.

5 Nghiên cứu Khả năng Tổng quát hóa
Chúng tôi tuyển chọn MGDMICROBENCH như một micro benchmark (10 ví dụ), trải rộng 3 ngôn ngữ lập trình (Java, C#, Rust), 4 kịch bản mã hóa, và yêu cầu sử dụng 2 phân tích tĩnh khác nhau, để đánh giá khả năng tổng quát hóa của MGD. Kết quả chi tiết được thảo luận trong Phụ lục H.

Các Ngôn ngữ Lập trình Khác nhau. MGD sử dụng các phân tích tĩnh giúp suy luận và thực thi các ràng buộc ngữ nghĩa trên mã đang phát triển. Những phân tích như vậy có sẵn thông qua Giao thức Máy chủ Ngôn ngữ (LSP) (lsp) cho hầu hết các ngôn ngữ lập trình, ví dụ: clangd cho C/C++ (cla, 2020), Jedi cho Python (Roeca, 2019) và Rust Analyzer cho Rust (rus, 2018). Monitor được sử dụng trong MGD có thể được khởi tạo như một client mỏng xung quanh LSP. Hỗ trợ các ngôn ngữ mới là dễ dàng và không đòi hỏi thay đổi giao diện phân tích tĩnh của monitor. Do đó, MGD có thể áp dụng cho hầu hết các ngôn ngữ lập trình. Kết quả trên MGDMICROBENCH chứng minh MGD cho Java, C# và Rust.

Các Kịch bản Mã hóa Khác nhau. Một monitor dưới MGD kích hoạt khi một điều kiện tiên quyết được chỉ định được đáp ứng trong quá trình tạo mã. Tính linh hoạt trong việc định nghĩa các điều kiện tiên quyết cho phép MGD được áp dụng cho nhiều kịch bản mã, như sau: 1) Khởi tạo các lớp hợp lệ: Một monitor kích hoạt trên 'new', gọi một phân tích tĩnh xác định các lớp có thể khởi tạo từ ngữ cảnh cục bộ & toàn cục để đảm bảo chỉ các lớp hợp lệ được khởi tạo. 2) switch over enum: Một câu lệnh switch over enum sử dụng các enum được đặt tên trong case <val> để chọn nhánh trong C# và Java. Một monitor kích hoạt trên 'case' được sử dụng để tạo ra các enum hợp lệ. 3) Số lượng đối số chính xác: Một monitor dựa trên stack được triển khai để hướng dẫn cho việc tạo ra số lượng đối số đúng cho các phương thức, cũng xử lý các lời gọi hàm lồng nhau. 4) Giám sát chung cho nhiều thuộc tính: Không như các ví dụ trước đó giám sát cho một thuộc tính tĩnh duy nhất, chúng tôi khởi tạo 2 monitor chung: a) hướng dẫn chung cho các tham chiếu kiểu chính xác & cùng với số lượng đối số đúng, b) hướng dẫn chung cho các nhánh switch enum hợp lệ & tham chiếu kiểu chính xác. MGDMICROBENCH (phụ lục H.2) cung cấp kết quả trên tất cả các kịch bản này.

Các Phân tích Tĩnh Khác nhau. MGD có thể sử dụng kết quả từ các phân tích tĩnh khác nhau để hướng dẫn việc tạo mã với LMs. Chúng tôi chứng minh MGD trên các thuộc tính sau trong MGDMICROBENCH: 1) Typestates (Strom & Yemini, 1986): Nhiều APIs có trạng thái, và yêu cầu người gọi tuân theo thứ tự cụ thể của các lời gọi như một phần của hợp đồng API. Ví dụ, một kiểu đại diện cho một handle tệp sẽ có một hợp đồng cấm các lời gọi đến read sau khi close đã được gọi. Những hợp đồng như vậy có thể được biểu thị như các máy trạng thái hữu hạn (FSMs), được gọi là typestates. 2) Session Types (Jespersen et al., 2015) đảm bảo rằng các thông điệp giữa các chương trình đồng thời được gửi và nhận theo thứ tự mong đợi, tuân theo một giao thức, và được chỉ định như các FSMs giao tiếp. Trong MGDMICROBENCH, chúng tôi chứng minh một monitor cho Rust sử dụng các phân tích thiết kế typestate và session-type.

6 Thảo luận
Hạn chế. Mặc dù phân tích tĩnh là một lĩnh vực trưởng thành với nền tảng lý thuyết mạnh mẽ và một số triển khai công cụ mạnh mẽ, việc phân tích các chương trình một phần và chưa hoàn chỉnh vẫn là một vấn đề khó khăn. Trên thực tế, các trình chỉnh sửa như Eclipse và Visual Studio hỗ trợ phân tích tĩnh với các heuristic. Mặc dù những heuristic này được thiết kế tốt và được sử dụng rộng rãi, chúng có thể vừa không chính xác (chúng có thể đưa ra các gợi ý không chính xác) và không đầy đủ (chúng có thể bỏ sót các gợi ý chính xác). Thỏa mãn các đặc tả đúng đắn chức năng như các điều kiện tiên quyết/hậu và bất biến nằm ngoài phạm vi của công việc này. Do đó, mặc dù kết quả của chúng tôi từ việc hướng dẫn LMs sử dụng những phân tích này (thông qua MGD) cho thấy cải thiện trong các chỉ số chất lượng, các bước bổ sung như thử nghiệm và kiểm tra của con người là cần thiết để đảm bảo tính chính xác của mã được tạo ra.

Tác động Xã hội. Phần mềm ảnh hưởng toàn diện đến tất cả các khía cạnh cuộc sống của chúng ta. Với LMs được triển khai rộng rãi như các copilot và trợ lý thông minh để giúp các nhà phát triển viết mã, việc phát triển các công cụ như MGD để cải thiện chất lượng mã được tạo ra bởi LMs là cực kỳ quan trọng (ngay cả khi con người xem xét và chấp nhận các gợi ý được đưa ra bởi LMs). Không có những công cụ như vậy, chúng ta có nguy cơ đưa ra các lỗi trong mã do các gợi ý không chính xác được đưa ra bởi LMs, điều này có tiềm năng tác động tiêu cực đến tất cả cuộc sống của chúng ta.

Lượng Tính toán. Các thực nghiệm của chúng tôi không liên quan đến bất kỳ huấn luyện nào, và chúng tôi chỉ thực hiện suy luận. Chúng tôi đã sử dụng các máy có cấu hình sau: (1) CPU: 24-core AMD Epyc với 220GB RAM, GPU: Nvidia A100 80GB. (2) CPU: Intel Xeon(R) Platinum 8168 với 290GB RAM, GPU: Nvidia Tesla V100 16GB. Đối với các thực nghiệm đánh giá text-davinci-003, chúng tôi đã sử dụng Azure API.

7 Công việc Liên quan
Các Mô hình Được tiền huấn luyện của Mã. Nhiều mô hình được tiền huấn luyện mạnh mẽ đã được thiết kế cho mã. Chúng bao gồm các mô hình chỉ encoder như CodeBERT (Feng et al., 2020), GraphCodeBERT Guo et al. (2020) và CuBERT (Kanade et al., 2020); các mô hình encoder-decoder như PLBART (Ahmad et al., 2021), CodeT5 (Wang et al., 2021) và AlphaCode (Li et al., 2022); hoặc các mô hình chỉ decoder như Codex (Chen et al., 2021), GPT-J (Wang & Komatsuzaki, 2021), Austin et al. (2021), GPT-Neo (Black et al., 2021), GPT-NeoX (Black et al., 2022), CodeParrot (Tunstall et al., 2022), PolyCoder (Xu et al., 2022), Incoder (Fried et al., 2022), CodeGen (Nijkamp et al., 2023), SantaCoder (Allal et al., 2023) và StarCoder (Li et al., 2023); hoặc các mô hình thống nhất như UniXCoder (Guo et al., 2022). Giải mã được hướng dẫn bởi monitor của chúng tôi chỉ hoạt động với logits và do đó có thể được sử dụng với bất kỳ mô hình nào.

Ngữ cảnh Toàn cục của Mã. Hellendoorn & Devanbu (2017) xây dựng một mô hình n-gram với bộ nhớ cache để theo dõi ngữ cảnh cấp thư mục. Xu et al. (2021) sử dụng tính địa phương dựa trên cấu trúc thư mục trong mô hình hóa được tăng cường truy xuất (Khandelwal et al., 2019). Nhiều phương pháp sử dụng phân tích tĩnh hoặc các thế hệ trước đó (Zhang et al., 2023) để trích xuất mã có liên quan. Chúng sử dụng ngữ cảnh có liên quan để tăng cường prompt (Shrivastava et al., 2022; Pei et al., 2023; Zhang et al., 2023) hoặc embeddings (Pashakhanloo et al., 2022; Ding et al., 2022) được trình bày như đầu vào cho LM. Do giới hạn về kích thước prompt hoặc embedding, những phương pháp này lọc thông tin thông qua random walks (Pashakhanloo et al., 2022), phân loại (Shrivastava et al., 2022) hoặc sử dụng các chiến lược cắt tỉa cố định (Ding et al., 2022). Vì chúng tôi không tăng cường prompt cũng không sử dụng embeddings bổ sung, chúng tôi không cần cắt tỉa ngữ cảnh toàn cục. Chúng tôi để phân tích tĩnh tạo ra các gợi ý hoàn thành sử dụng toàn bộ ngữ cảnh cấp kho lưu trữ. Zan et al. (2022) và Zhou et al. (2022) truy xuất thông tin từ tài liệu thư viện cho tăng cường prompt. Phân tích tĩnh của chúng tôi phân tích các thư viện cùng với mã nguồn cấp kho lưu trữ. Một số kỹ thuật này yêu cầu sửa đổi kiến trúc (Pashakhanloo et al., 2022; Ding et al., 2022) hoặc fine-tuning (Zan et al., 2022; Ding et al., 2022; Pei et al., 2023). Chúng tôi sử dụng một giao diện đơn giản giữa logits và phân tích tĩnh với một LM đông lạnh. Hầu hết những phương pháp này, ngoại trừ (Xu et al., 2021; Zhang et al., 2023), sử dụng truy xuất a priori một lần. Ngược lại, chúng tôi cung cấp hướng dẫn cấp token bằng cách gọi phân tích tĩnh theo yêu cầu. Phương pháp của chúng tôi bổ sung cho tất cả các phương pháp trên vì tất cả chúng đều cố gắng điều kiện hóa việc tạo ra bằng cách sửa đổi đầu vào cho LM trong khi chúng tôi áp dụng các ràng buộc phía đầu ra bằng cách định hình lại các logits.

Các Ràng buộc Cú pháp và Ngữ nghĩa. Có hai dòng công việc chính để thực thi các ràng buộc cú pháp và ngữ nghĩa trên việc tạo mã, dựa trên mô hình hóa chuyên biệt và thông qua giải mã có ràng buộc. GNN2NAG (Brockschmidt et al., 2019) và NSG (Mukherjee et al., 2021) là các ví dụ của dòng đầu tiên và sử dụng các ngữ pháp thuộc tính. Chúng được đánh giá tương ứng trên các biểu thức không sử dụng các phương thức do người dùng định nghĩa hoặc trên các phương thức với ngữ cảnh cấp lớp. Chúng tôi xem xét ngữ cảnh kho lưu trữ cho việc hoàn thành cấp phương thức. Không như những phương pháp này, công việc của chúng tôi có thể áp dụng cho các LMs sẵn có. PICARD (Scholak et al., 2021) và Synchromesh (Poesia et al., 2022) là các phương pháp giải mã có ràng buộc tương tự như của chúng tôi. Chúng sử dụng phân tích cú pháp tăng dần cho tính hợp lệ cú pháp và thiết kế các kiểm tra ngữ nghĩa cụ thể cho miền để đảm bảo tính hợp lệ ngữ nghĩa. Cả hai đều được đánh giá trên SQL, và Synchromesh bổ sung xem xét các ngôn ngữ cụ thể cho miền cho việc trực quan hóa và các ứng dụng lịch. Để so sánh, chúng tôi nhắm mục tiêu việc tạo ra các ngôn ngữ lập trình mục đích chung với tập trung vào các ràng buộc ngữ nghĩa như tính nhất quán kiểu, giao thức API, v.v. sử dụng phân tích tĩnh trên ngữ cảnh kho lưu trữ.

8 Kết luận và Công việc Tương lai
Trong công việc này, chúng tôi hiển thị cách sử dụng thông tin toàn kho lưu trữ được tính toán bởi phân tích tĩnh (cụ thể, phân tích dựa trên kiểu) sử dụng một monitor có trạng thái như một giao diện, để cải thiện chất lượng mã được tạo ra bởi LMs. Kết quả thực nghiệm của chúng tôi hiển thị tiềm năng cho cải thiện chất lượng đáng kể cho việc tạo mã sử dụng phương pháp này. Phương pháp của chúng tôi bổ sung cho các kỹ thuật tăng cường prompt. Nó cho phép các mô hình nhỏ hơn đạt được hiệu suất tốt hơn hoặc cạnh tranh so với các mô hình lớn hơn nhiều. Điều này có thể mở ra khả năng sử dụng các mô hình nhỏ hơn trực tiếp trong IDEs, cùng với monitor của chúng tôi, như một thay thế cho việc sử dụng các LMs lớn được lưu trữ từ xa (LLMs), giảm chi phí suy luận và cải thiện quyền riêng tư. Phương pháp của chúng tôi là tổng quát và có thể áp dụng cho các kịch bản mã hóa khác nhau nơi LMs được sử dụng để tạo ra, như tái cấu trúc mã, sửa chữa mã, hoặc hoàn thành mã, ngay cả khi các kho lưu trữ ở trạng thái tạm thời. Chúng tôi dự định mở rộng phạm vi của MGD cho nhiều ngôn ngữ hơn và các phân tích ngữ nghĩa sâu hơn như các điều kiện tiên quyết/hậu mà có thể cần các phương pháp giải mã có ràng buộc nâng cao (bao gồm backtracking và beam-search).

Lời cảm ơn
Chúng tôi cảm ơn các tác giả RLPG và của các LMs (CG, SC, TD-3) được sử dụng trong công việc của chúng tôi. Chúng tôi biết ơn Sheng Chen và Shi Chen từ Microsoft, và tác giả của OLSP, Predrag Nikolic, vì sự giúp đỡ hào phóng của họ trong việc trả lời các câu hỏi của chúng tôi về giao tiếp với LSP. Bài báo của chúng tôi cũng được hưởng lợi đáng kể từ phản hồi xây dựng của các người đánh giá.

11

--- TRANG 12 ---
Tài liệu tham khảo
Trang chính thức cho Giao thức Máy chủ Ngôn ngữ. URL https://microsoft.github.io/language-server-protocol/.
Protocol Buffers. https://protobuf.dev/, 2008. Truy cập: 14 tháng 5, 2023.
Project Lombok. https://projectlombok.org/, 2009. Truy cập: 14 tháng 5, 2023.
Eclipse JDT LS, tháng 9 năm 2016. URL https://projects.eclipse.org/projects/eclipse.jdt.ls.
rust-analyzer, 2018. URL https://rust-analyzer.github.io/.
What is clangd?, 2020. URL https://clangd.llvm.org/.
Language Server Implementations. https://microsoft.github.io/language-server-protocol/implementors/servers/, 2023. Truy cập: 14 tháng 5, 2023.
Ahmad, W. U., Chakraborty, S., Ray, B., và Chang, K.-W. Unified pre-training for program understanding and generation, 2021.
Allal, L. B., Li, R., Kocetkov, D., Mou, C., Akiki, C., Ferrandis, C. M., Muennighoff, N., Mishra, M., Gu, A., Dey, M., và những người khác. SantaCoder: don't reach for the stars! arXiv preprint arXiv:2301.03988, 2023.
Austin, J., Odena, A., Nye, M., Bosma, M., Michalewski, H., Dohan, D., Jiang, E., Cai, C., Terry, M., Le, Q., và Sutton, C. Program Synthesis with Large Language Models, tháng 8 năm 2021. URL http://arxiv.org/abs/2108.07732. arXiv:2108.07732 [cs].
Bavarian, M., Jun, H., Tezak, N., Schulman, J., McLeavey, C., Tworek, J., và Chen, M. Efficient training of language models to fill in the middle, 2022.
Black, S., Gao, L., Wang, P., Leahy, C., và Biderman, S. Gpt-neo: Large scale autoregressive language modeling with mesh-tensorflow. If you use this software, please cite it using these metadata, 58, 2021.
Black, S., Biderman, S., Hallahan, E., Anthony, Q., Gao, L., Golding, L., He, H., Leahy, C., McDonell, K., Phang, J., và những người khác. Gpt-neox-20b: An open-source autoregressive language model. arXiv preprint arXiv:2204.06745, 2022.
Brockschmidt, M., Allamanis, M., Gaunt, A. L., và Polozov, O. Generative Code Modeling with Graphs. In International Conference on Learning Representations, 2019. URL https://openreview.net/forum?id=Bke4KsA5FX.
Chen, M., Tworek, J., Jun, H., Yuan, Q., Pinto, H. P. d. O., Kaplan, J., Edwards, H., Burda, Y., Joseph, N., Brockman, G., và những người khác. Evaluating large language models trained on code. arXiv preprint arXiv:2107.03374, 2021.
Crichton, W. Typed design patterns for the functional era. In Proceedings of the 1st ACM SIGPLAN International Workshop on Functional Software Architecture, FUNARCH 2023, pp. 40–48, New York, NY, USA, 2023. Association for Computing Machinery. ISBN 9798400702976. doi: 10.1145/3609025.3609477. URL https://doi.org/10.1145/3609025.3609477.
Crichton, W., Navarro, J., Semeniuta, D., Zeng, S., và Gupta, S. Session types, tháng 11 năm 2019. URL https://stanford-cs242.github.io/f19/lectures/09-1-session-types.html.
Dagenais, B. và Hendren, L. Enabling static analysis for partial java programs. In Proceedings of the 23rd ACM SIGPLAN conference on Object-oriented programming systems languages and applications, pp. 313–328, 2008.
Ding, Y., Wang, Z., Ahmad, W. U., Ramanathan, M. K., Nallapati, R., Bhatia, P., Roth, D., và Xiang, B. CoCoMIC: Code Completion By Jointly Modeling In-file and Cross-file Context, tháng 12 năm 2022. URL http://arxiv.org/abs/2212.10007. arXiv:2212.10007 [cs].

12

--- TRANG 13 ---
Donahue, C., Lee, M., và Liang, P. Enabling language models to fill in the blanks. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pp. 2492–2501, Online, tháng 7 năm 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.acl-main.225. URL https://aclanthology.org/2020.acl-main.225.

Duarte, J. và Ravara, A. Retrofitting typestates into rust. In Proceedings of the 25th Brazilian Symposium on Programming Languages, SBLP '21, pp. 83–91, New York, NY, USA, 2021. Association for Computing Machinery. ISBN 9781450390620. doi: 10.1145/3475061.3475082. URL https://doi.org/10.1145/3475061.3475082.

Feng, Z., Guo, D., Tang, D., Duan, N., Feng, X., Gong, M., Shou, L., Qin, B., Liu, T., Jiang, D., và những người khác. Codebert: A pre-trained model for programming and natural languages. arXiv preprint arXiv:2002.08155, 2020.

Fried, D., Aghajanyan, A., Lin, J., Wang, S., Wallace, E., Shi, F., Zhong, R., Yih, W.-t., Zettlemoyer, L., và Lewis, M. Incoder: A generative model for code infilling and synthesis. arXiv preprint arXiv:2204.05999, 2022.

Fuhrer, R. M. Leveraging static analysis in an ide. Generative and Transformational Techniques in Software Engineering IV: International Summer School, GTTSE 2011, Braga, Portugal, July 3-9, 2011. Revised Papers, pp. 101–158, 2013.

Guo, D., Ren, S., Lu, S., Feng, Z., Tang, D., Liu, S., Zhou, L., Duan, N., Svyatkovskiy, A., Fu, S., và những người khác. Graphcodebert: Pre-training code representations with data flow. arXiv preprint arXiv:2009.08366, 2020.

Guo, D., Lu, S., Duan, N., Wang, Y., Zhou, M., và Yin, J. Unixcoder: Unified cross-modal pre-training for code representation, 2022.

Hedin, G. Incremental semantic analysis. Department of Computer Sciences, 1992.

Hellendoorn, V. J. và Devanbu, P. Are deep neural networks the best choice for modeling source code? In Proceedings of the 2017 11th Joint Meeting on Foundations of Software Engineering, pp. 763–773, 2017.

Holtzman, A., Buys, J., Du, L., Forbes, M., và Choi, Y. The Curious Case of Neural Text Degeneration. In International Conference on Learning Representations, 2020. URL https://openreview.net/forum?id=rygGQyrFvH.

Jespersen, T. B. L., Munksgaard, P., và Larsen, K. F. Session types for rust. In Proceedings of the 11th ACM SIGPLAN Workshop on Generic Programming, WGP 2015, pp. 13–22, New York, NY, USA, 2015. Association for Computing Machinery. ISBN 9781450338103. doi: 10.1145/2808098.2808100. URL https://doi.org/10.1145/2808098.2808100.

Kanade, A., Maniatis, P., Balakrishnan, G., và Shi, K. Learning and evaluating contextual embedding of source code. In International conference on machine learning, pp. 5110–5121. PMLR, 2020.

Karampatsis, R.-M., Babii, H., Robbes, R., Sutton, C., và Janes, A. Big code!= big vocabulary: Open-vocabulary models for source code. In Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering, pp. 1073–1085, 2020.

Khandelwal, U., Levy, O., Jurafsky, D., Zettlemoyer, L., và Lewis, M. Generalization through memorization: Nearest neighbor language models. arXiv preprint arXiv:1911.00172, 2019.

Kudo, T. và Richardson, J. Sentencepiece: A simple and language independent subword tokenizer and detokenizer for neural text processing. arXiv preprint arXiv:1808.06226, 2018.

Li, R., Allal, L. B., Zi, Y., Muennighoff, N., Kocetkov, D., Mou, C., Marone, M., Akiki, C., Li, J., Chim, J., et al. Starcoder: may the source be with you! arXiv preprint arXiv:2305.06161, 2023.

Li, Y., Choi, D., Chung, J., Kushman, N., Schrittwieser, J., Leblond, R., Eccles, T., Keeling, J., Gimeno, F., Lago, A. D., Hubert, T., Choy, P., d'Autume, C. d. M., Babuschkin, I., Chen, X., Huang, P.-S., Welbl, J., Gowal, S., Cherepanov, A., Molloy, J., Mankowitz, D. J., Robson, E. S., Kohli, P., Freitas, N. d., Kavukcuoglu, K., và Vinyals, O. Competition-level code generation with AlphaCode. Science, 378(6624):1092–1097, 2022. doi: 10.1126/science.abq1158. URL https://www.science.org/doi/abs/10.1126/science.abq1158. _eprint: https://www.science.org/doi/pdf/10.1126/science.abq1158.

Maddox III, W. H. Incremental static semantic analysis. University of California, Berkeley, 1997.

Mishra, A., Kanade, A., và Srikant, Y. N. Asynchrony-aware static analysis of android applications. In 2016 ACM/IEEE International Conference on Formal Methods and Models for System Design (MEMOCODE), pp. 163–172, 2016. doi: 10.1109/MEMCOD.2016.7797761.

Mukherjee, R., Wen, Y., Chaudhari, D., Reps, T., Chaudhuri, S., và Jermaine, C. Neural Program Generation Modulo Static Analysis. In Beygelzimer, A., Dauphin, Y., Liang, P., và Vaughan, J. W. (eds.), Advances in Neural Information Processing Systems, 2021. URL https://openreview.net/forum?id=yaksQCYcRs.

Nielson, F., Nielson, H. R., và Hankin, C. Principles of program analysis. Springer, 2015.

Nijkamp, E., Pang, B., Hayashi, H., Tu, L., Wang, H., Zhou, Y., Savarese, S., và Xiong, C. CodeGen: An Open Large Language Model for Code with Multi-Turn Program Synthesis. In The Eleventh International Conference on Learning Representations, 2023. URL https://openreview.net/forum?id=iaYcJKpY2B_.

Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C. L., Mishkin, P., Zhang, C., Agarwal, S., Slama, K., Ray, A., Schulman, J., Hilton, J., Kelton, F., Miller, L., Simens, M., Askell, A., Welinder, P., Christiano, P., Leike, J., và Lowe, R. Training language models to follow instructions with human feedback, 2022.

Pashakhanloo, P., Naik, A., Wang, Y., Dai, H., Maniatis, P., và Naik, M. Codetrek: Flexible modeling of code using an extensible relational representation. 2022.

Pei, H., Zhao, J., Lausen, L., Zha, S., và Karypis, G. Better context makes better code language models: A case study on function call argument completion. In AAAI, 2023. URL https://www.amazon.science/publications/better-context-makes-better-code-language-models-a-case-study-on-function-call-argument-completion.

Poesia, G., Polozov, A., Le, V., Tiwari, A., Soares, G., Meek, C., và Gulwani, S. Synchromesh: Reliable code generation from pre-trained language models. In ICLR 2022, tháng 4 năm 2022. URL https://www.microsoft.com/en-us/research/publication/synchromesh-reliable-code-generation-from-pre-trained-language-models/.

Reps, T., Teitelbaum, T., và Demers, A. Incremental context-dependent analysis for language-based editors. ACM Transactions on Programming Languages and Systems (TOPLAS), 5(3):449–477, 1983.

Roeca, S. jedi-language-server, 2019. URL https://github.com/pappasam/jedi-language-server.

Rust on Embedded Devices Working Group et al. The embedded rust book, 2018. URL https://doc.rust-lang.org/beta/embedded-book/static-guarantees/design-contracts.html.

Scholak, T., Schucher, N., và Bahdanau, D. PICARD: Parsing Incrementally for Constrained Auto-Regressive Decoding from Language Models. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pp. 9895–9901, Online and Punta Cana, Dominican Republic, tháng 11 năm 2021. Association for Computational Linguistics. doi: 10.18653/v1/2021.emnlp-main.779. URL https://aclanthology.org/2021.emnlp-main.779.

Schuster, M. và Nakajima, K. Japanese and korean voice search. In 2012 IEEE international conference on acoustics, speech and signal processing (ICASSP), pp. 5149–5152. IEEE, 2012.

Sennrich, R., Haddow, B., và Birch, A. Neural Machine Translation of Rare Words with Subword Units. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 1715–1725, Berlin, Germany, tháng 8 năm 2016. Association for Computational Linguistics. doi: 10.18653/v1/P16-1162. URL https://aclanthology.org/P16-1162.

14

--- TRANG 15 ---
Shrivastava, D., Larochelle, H., và Tarlow, D. Repository-level prompt generation for large language models of code. arXiv preprint arXiv:2206.12839, 2022.

Strom, R. E. và Yemini, S. Typestate: A programming language concept for enhancing software reliability. IEEE Transactions on Software Engineering, SE-12:157–171, 1986. URL https://api.semanticscholar.org/CorpusID:15575346.

Tunstall, L., Von Werra, L., và Wolf, T. Natural language processing with transformers. " O'Reilly Media, Inc.", 2022.

Wagner, T. A. Practical algorithms for incremental software development environments. University of California, Berkeley, 1997.

Wang, B. và Komatsuzaki, A. GPT-J-6B: A 6 billion parameter autoregressive language model, 2021.

Wang, Y., Wang, W., Joty, S. R., và Hoi, S. C. H. CodeT5: Identifier-aware Unified Pre-trained Encoder-Decoder Models for Code Understanding and Generation. ArXiv, abs/2109.00859, 2021.

Wolf, T., Debut, L., Sanh, V., Chaumond, J., Delangue, C., Moi, A., Cistac, P., Rault, T., Louf, R., Funtowicz, M., Davison, J., Shleifer, S., von Platen, P., Ma, C., Jernite, Y., Plu, J., Xu, C., Le Scao, T., Gugger, S., Drame, M., Lhoest, Q., và Rush, A. Transformers: State-of-the-Art Natural Language Processing. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, pp. 38–45, Online, tháng 10 năm 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.emnlp-demos.6. URL https://aclanthology.org/2020.emnlp-demos.6.

Xu, F. F., He, J., Neubig, G., và Hellendoorn, V. J. Capturing structural locality in non-parametric language models. arXiv preprint arXiv:2110.02870, 2021.

Xu, F. F., Alon, U., Neubig, G., và Hellendoorn, V. J. A Systematic Evaluation of Large Language Models of Code. In Proceedings of the 6th ACM SIGPLAN International Symposium on Machine Programming, MAPS 2022, pp. 1–10, New York, NY, USA, 2022. Association for Computing Machinery. ISBN 978-1-4503-9273-0. doi: 10.1145/3520312.3534862. URL https://doi.org/10.1145/3520312.3534862. event-place: San Diego, CA, USA.

Yu, H., Shen, B., Ran, D., Zhang, J., Zhang, Q., Ma, Y., Liang, G., Li, Y., Xie, T., và Wang, Q. CoderEval: A Benchmark of Pragmatic Code Generation with Generative Pre-trained Models, tháng 2 năm 2023. URL http://arxiv.org/abs/2302.00288. arXiv:2302.00288 [cs].

Zan, D., Chen, B., Lin, Z., Guan, B., Yongji, W., và Lou, J.-G. When Language Model Meets Private Library. In Findings of the Association for Computational Linguistics: EMNLP 2022, pp. 277–288, Abu Dhabi, United Arab Emirates, tháng 12 năm 2022. Association for Computational Linguistics. URL https://aclanthology.org/2022.findings-emnlp.21.

Zhang, F., Chen, B., Zhang, Y., Liu, J., Zan, D., Mao, Y., Lou, J.-G., và Chen, W. RepoCoder: Repository-Level Code Completion Through Iterative Retrieval and Generation. arXiv preprint arXiv:2303.12570, 2023.

Zhou, S., Alon, U., Xu, F. F., Jiang, Z., và Neubig, G. Docprompting: Generating code by retrieving the docs. In The Eleventh International Conference on Learning Representations, 2022.

15

--- TRANG 16 ---
Phụ lục: Hướng dẫn các Mô hình Ngôn ngữ của Mã nguồn với Ngữ cảnh Toàn cục sử dụng các Monitor

Mục lục
• Monitor cho Ví dụ Chạy
• Chi tiết Tuyển chọn Bộ dữ liệu
• Thiết lập Thực nghiệm - Chi tiết Bổ sung
• Tính toán score@k
• Hiệu ứng của MGD trên Giải mã Fill-in-the-middle (FIM) - Kết quả Hoàn chỉnh
• Hiệu ứng của Độ phức tạp Định danh trên Khớp Định danh Tiếp theo - Kết quả Hoàn chỉnh
• Tác động của MGD trên Thời gian Suy luận
• Các khía cạnh Khả năng tổng quát hóa của MGD
• Truy vấn CodeQL để Xác định Phương thức Mục tiêu Đánh giá
• Ví dụ về tạo mã với MGD

A Monitor cho Ví dụ Chạy

s0
'...ServerNode.Builder.newServerNode().'Mô hình Ngôn ngữ
Lθ
prex1, x2, ..., xn
Saiupdate(s1, 'with')
s1maskgen(s1,V)xn+1 = 'with'
s2Mô hình Ngôn ngữ
Lθ
xn+2 = 'Ip'
update(s2, 'Ip')
s3maskgen(s2,V)Lấy mẫu Lấy mẫu
Logits Đã sửa đổi
 Logits Đã sửa đổi
Logits
Vector
Nhị phânĐúng
Mô hình Ngôn ngữ
Lθ
xn+3 = '('Lấy mẫuLogits Đã sửa đổi
update(s 3, '(')
Không có Gợi ý
Đang chờmaskgen(s3,V)

Hình 4: Monitor để hướng dẫn việc tạo ra các định danh nhất quán về kiểu cho mã trong Hình 1.

Hình 4 hiển thị cách monitor tương tác với bộ giải mã LM cho ví dụ trong Hình 1. Ban đầu, monitor, Mφ ở trong trạng thái chờ s0. Cho đầu vào hoàn thành mã, x1, x2, ..., xn, Mφ đầu tiên đánh giá pre(s0, x1, ..., xn). Vì xn='.' (ký hiệu dấu chấm chỉ ra việc tham chiếu đối tượng trong Java), pre(s0, x1, ..., xn) đánh giá thành true, và tiếp theo, phù hợp với Phương trình (4), phân tích tĩnh Aφ được gọi, xác định prompt đầu vào phù hợp với thuộc tính φ, và giải quyết kiểu cho điểm hoàn thành thành ServerNode.Builder, như hiển thị trong AST được chú thích trong Hình 1(b). Aφ sau đó trả về tập hợp các định danh nhất quán với kiểu đã giải quyết – { withIp, withPort, newServerNode, ... }, chuyển đổi monitor Mφ sang trạng thái s1. Mφ sau đó tính toán m=maskgen(s1, V), che dấu, ví dụ, token host (như được suy luận bởi SantaCoder trong Hình 1(b)). Đồng thời, đầu vào được token hóa và LM Lθ cung cấp các logits suy luận, ℓ cho token tiếp theo. Các logits đầu ra ℓ từ Lθ và mặt nạ m được kết hợp như ℓ⊕m để thu được các logits đã sửa đổi, sau đó được softmax và một token được lấy mẫu – with trong trường hợp này. Monitor sau đó gọi update(s1, with) để chuyển đổi sang s2. Lưu ý rằng với việc chuyển đổi trạng thái, newServerNode bị loại bỏ khỏi tập hợp các định danh, vì token được lấy mẫu with không tạo tiền tố cho nó. Lθ cung cấp logits cho token tiếp theo, và sự kết hợp của Lθ và Mφ được lặp lại để thu được các logits đã sửa đổi, và cuối cùng chúng tôi thu được token được lấy mẫu Ip. Vì Ip là một tiền tố của một thành viên trong s2, update(s2, Ip) chuyển đổi sang s3, với s3={ϵ}, một singleton bao gồm chuỗi rỗng. Lưu ý rằng token '(' nhất quán với các gợi ý trong trạng thái s3, vì nó khớp với biểu thức chính quy w·E·Σ*, trong đó w=ϵ. Sau việc lấy mẫu token '(', monitor chuyển đổi trở lại trạng thái chờ s0.

1

--- TRANG 17 ---
B Chi tiết Tuyển chọn Bộ dữ liệu

Để đánh giá việc tạo mã thực dụng, chúng tôi yêu cầu các kho lưu trữ thực tế, với môi trường hoàn chỉnh và phụ thuộc của chúng. Hầu hết các bộ dữ liệu công khai cho việc tạo mã không đáp ứng yêu cầu này, do tập trung vào việc tạo mã độc lập, ngoại trừ CoderEval gần đây (Yu et al., 2023) và PyEnvs (Pei et al., 2023), cả hai đều không có sẵn công khai tại thời điểm viết bài này. Hơn nữa, CoderEval chỉ đánh giá 10 kho lưu trữ Java và 43 kho lưu trữ Python. Vì những bộ dữ liệu này không lọc các kho lưu trữ theo ngày tạo của chúng, các kho lưu trữ thử nghiệm có thể là một phần của tập huấn luyện cho các LMs được đánh giá. Xem xét những điều này, chúng tôi mô tả việc tuyển chọn PRAGMATIC CODE, một bộ dữ liệu của các dự án Java nguồn mở thực tế hoàn chỉnh với môi trường phát triển và phụ thuộc của chúng. Chúng tôi đảm bảo rằng các kho lưu trữ huấn luyện chỉ được phát hành công khai sau ngày cắt bộ dữ liệu huấn luyện đã xác định (31 tháng 3 năm 2022) cho các họ mô hình CodeGen (Nijkamp et al., 2023), SantaCoder (Allal et al., 2023), và text-davinci-003 (GPT-3.5) (Ouyang et al., 2022). Tất cả các kho lưu trữ trong PRAGMATIC CODE đều có thể xây dựng được với các hệ thống xây dựng tương ứng của chúng. Môi trường phát triển cũng cung cấp hỗ trợ cho phân tích trên mã template được tạo ra với các hệ thống như ProtoBuf (pro, 2008) và Lombok (lom, 2009). Hơn nữa, chúng tôi tạo ra DOTPROMPTS từ PRAGMATIC CODE để đánh giá việc tạo mã trong một thiết lập thực dụng.

PRAGMATIC CODE. Chúng tôi truy vấn GitHub API vào ngày 25 tháng 3 năm 2023 để có được danh sách 1000 kho lưu trữ Java được đánh giá cao nhất trên GitHub được tạo ra sau ngày cắt đã xác định là 31 tháng 3 năm 2022. Sau đó chúng tôi cố gắng tải về ảnh chụp mới nhất của mỗi kho lưu trữ Java được đánh giá cao nhất trong số 1000 kho lưu trữ và đã có thể tải về 731 kho lưu trữ từ GitHub. Chúng tôi tạo ra một môi trường xây dựng cho các dự án Java bao gồm Oracle Java Development Kit 17.0.6, Apache Ant 1.10.13, Apache Maven 3.8.7, Gradle 7.3.3, và GitHub CodeQL CLI 2.12.5. Trong môi trường xây dựng này, chúng tôi gọi lệnh CodeQL database create¹ cho mọi kho lưu trữ phần mềm được lấy từ GitHub. Quy trình tạo cơ sở dữ liệu CodeQL xác định hệ thống xây dựng được sử dụng trong kho lưu trữ và gọi lệnh cho một bản xây dựng sạch. Các hệ thống xây dựng tương ứng sử dụng thông tin phụ thuộc cấp dự án được lưu trữ trong các tệp cấu hình như pom.xml và build.gradle để lấy các phụ thuộc và lưu trữ chúng cục bộ. Tiếp theo, chúng tôi lọc các kho lưu trữ có giấy phép cho phép, và lọc ra các kho lưu trữ mà việc tạo cơ sở dữ liệu CodeQL thất bại, vì điều đó chỉ ra rằng kho lưu trữ hoặc sử dụng một hệ thống xây dựng không được nhận dạng, một số phụ thuộc của nó không được thỏa mãn, hoặc kho lưu trữ đang ở trạng thái tạm thời. Chúng tôi còn lại 302 kho lưu trữ GitHub sau khi lọc cho các bản xây dựng thành công. Chúng tôi lưu trữ cơ sở dữ liệu CodeQL được tạo ra cho mỗi kho lưu trữ này. Cuối cùng, chúng tôi gọi việc khởi tạo Eclipse JDT.LS² trên mỗi kho lưu trữ, và lọc các kho lưu trữ nơi JDT.LS có thể được khởi tạo thành công. Danh sách được lọc cuối cùng gồm 100 kho lưu trữ, cùng với các cơ sở dữ liệu CodeQL của chúng, tạo thành bộ dữ liệu PRAGMATIC CODE.

DOTPROMPTS. Yu et al. (2023) cho thấy rằng các hàm độc lập chiếm ít hơn 30% các dự án nguồn mở trong số 100 dự án nguồn mở phổ biến nhất trên GitHub, với hầu hết các hàm tham chiếu đến APIs của bên thứ ba hoặc biến/hằng số được định nghĩa trong ngữ cảnh cross-file. Do đó, chúng tôi tạo ra DOTPROMPTS để đánh giá việc tạo mã trong một thiết lập thực dụng và nhằm đánh giá trên các dự án thực tế, không hạn chế việc tạo hàm độc lập. Mỗi thể hiện nhiệm vụ trong DOTPROMPTS bao gồm một prompt cho đến một vị trí tham chiếu (toán tử tham chiếu '.' trong Java) trong một phương thức mục tiêu, và nhiệm vụ là hoàn thành phần còn lại của phương thức. Vì các vị trí tham chiếu có thể là các điểm xuất hiện của các thực thể cross-file trong mã nguồn, khả năng của mô hình sử dụng ngữ cảnh cross-file có thể được đánh giá bằng cách sử dụng DOTPROMPTS.

Chi tiết Tuyển chọn. Chúng tôi xác định các tệp lớp không phải test không được tự động tạo ra và có ít nhất 1 phụ thuộc cross-file trong kho lưu trữ. Từ những tệp này, chúng tôi xác định các phương thức không phải là khởi tạo lớp và đối tượng và có ≥2 câu lệnh cấp cao nhất trải rộng ≥7 dòng mã nguồn, để đảm bảo độ phức tạp đủ trong các phương thức mục tiêu. Số dòng mã trung bình trong hoàn thành sự thật cơ bản trong DOTPROMPTS là 12.7. Chúng tôi sử dụng Truy vấn CodeQL được liệt kê trong phần I để xác định các phương thức mục tiêu từ mỗi kho lưu trữ trong PRAGMATIC CODE dựa trên các tiêu chí trên. Như được hiển thị bởi Shrivastava et al. (2022), các kho lưu trữ khá không đồng đều về kích thước của chúng, vì vậy để tránh các kho lưu trữ riêng lẻ chi phối việc đánh giá của chúng tôi, chúng tôi giới hạn bao gồm tối đa 20 phương thức từ mỗi kho lưu trữ như được xác định bởi truy vấn CodeQL. Để mô phỏng kịch bản sử dụng thực tế, nơi một nhà phát triển có thể gọi hoàn thành mã tại các điểm khác nhau trong một phương thức, chúng tôi xác định tối đa 10 vị trí tham chiếu được phân phối đồng đều trong mỗi phương thức đã xác định. Mỗi vị trí tham chiếu như vậy trở thành một điểm dữ liệu cho DOTPROMPTS.

C Chi tiết Thiết lập Thực nghiệm - Bổ sung

Triển khai Monitor. Giao thức Máy chủ Ngôn ngữ (LSP) (lsp), là một tiêu chuẩn công nghiệp mở về giao tiếp giữa IDEs và các công cụ cụ thể cho ngôn ngữ lập trình như các bộ phân tích tĩnh và trình biên dịch, được gọi là máy chủ ngôn ngữ. Eclipse JDT.LS (ecl, 2016) là một máy chủ ngôn ngữ cho Java, Rust Analyzer cung cấp hỗ trợ cho Rust, OmniSharp hỗ trợ C# và JEDI hỗ trợ Python. Tất cả các máy chủ ngôn ngữ cung cấp truy cập đến kết quả của các phân tích tĩnh khác nhau qua cùng một API. Những điều này có thể được truy cập bằng cách triển khai một Language Server Client. Chúng tôi triển khai một language server client có thể mở rộng và đa nền tảng, multilspy với mục đích làm cho việc thiết lập và sử dụng các máy chủ ngôn ngữ này theo cách bất khả tri ngôn ngữ trở nên dễ dàng. Tại thời điểm viết bài này, multilspy đã được thử nghiệm để hoạt động với các máy chủ ngôn ngữ cho Java, Python, Rust và C#, và chúng tôi dự định mở rộng hỗ trợ cho nhiều ngôn ngữ lập trình và máy chủ ngôn ngữ hơn.

Sử dụng multilspy, chúng tôi cụ thể khởi tạo Eclipse JDT.LS như một engine triển khai phân tích tĩnh Aφ để kiểm tra tính nhất quán kiểu của các định danh. Đáng chú ý, Eclipse JDT.LS hỗ trợ lý luận với các artifact thời gian xây dựng như những cái được lấy từ Project Lombok (lom, 2009) và ProtoBuf (pro, 2008), do đó cho phép nó xem xét một cái nhìn rộng về kho lưu trữ mã trong các kết quả phân tích tĩnh mà nó cung cấp. Chúng tôi triển khai monitor Mφ của chúng tôi như một lớp mỏng xung quanh một LM, phù hợp với Phần 2, như một language server client giao tiếp với Eclipse JDT.LS. Vì triển khai của chúng tôi dựa trên LSP, và LSP tương thích với hầu hết các ngôn ngữ lập trình chính, triển khai của chúng tôi có thể dễ dàng được chuyển sang các ngôn ngữ khác ngoài Java, với việc sử dụng multilspy.

Siêu tham số. Chúng tôi sử dụng nucleus sampling (Holtzman et al., 2020) với giá trị top-p là 0.95 để tạo ra 6 mẫu tổng cộng—1 mẫu mỗi với nhiệt độ 0.2 và 0.4, và 2 mẫu mỗi với nhiệt độ 0.6 và 0.8. Chúng tôi cố định ngân sách prompt là (2048-512)=1536 token, và ngân sách tạo ra là 512 token, cho tổng kích thước cửa sổ ngữ cảnh là 2048. Nếu văn bản vượt quá ngân sách prompt, chúng tôi cắt bỏ từ bên trái cho các prompt standard và classExprTypes, và từ bên phải cho FIM. Đối với tăng cường classExprTypes với giải mã tự hồi quy, chúng tôi dành ngân sách 20% của tổng ngân sách prompting cho classExprTypes, và phần còn lại cho prompt tự hồi quy. Đối với giải mã FIM không có tăng cường prompt, chúng tôi dành 50% của tổng ngân sách prompting cho hậu tố. Đối với giải mã FIM với tăng cường prompt classExprTypes, chúng tôi dành 20% của tổng ngân sách prompting cho classExprTypes, 40% cho hậu tố, và phần còn lại cho prompt tự hồi quy.

D Tính toán score@k

Gọi S={s1, s2, ..., sn} là một multiset đại diện cho điểm số chỉ số được lấy qua n thử nghiệm độc lập. Không mất tính tổng quát, chúng tôi sắp xếp S theo thứ tự giảm dần đơn điệu như S≥ = (s≥1, s≥2, ..., s≥n). Chúng tôi tính toán score@k,n theo phương trình dưới đây:

score@k,n=1n∑(n-k+1)i=1 (n-i choose k-1)S≥[i] =1n∑T∈(S choose k)max(T) (5)

(S choose k)={V|V⊆S,|V|=k} (6)

trong đó 1≤k≤n, và (S choose k) là tập hợp tất cả các tập con của S có lực lượng k.

3

--- TRANG 18 ---
(a) CR (b) NIM
(c) ISM (d) PM

Hình 5: score@k cho các mô hình với MGD và FIM so sánh với các mô hình cơ sở

E Hiệu ứng của MGD trên Giải mã Fill-in-the-middle (FIM) - Kết quả Hoàn chỉnh

Trong số các mô hình cơ sở, SantaCoder hỗ trợ kiểu FIM. Hình 5 hiển thị kết quả cho SantaCoder với các chiến lược giải mã tự hồi quy và FIM và text-davinci-003, so sánh với các cấu hình tương ứng của SantaCoder với MGD.

Tỷ lệ Biên dịch. Hình 5a hiển thị rằng SantaCoder với MGD vượt trội hơn SantaCoder-FIM với biên độ tương đối 7.04%. Chúng tôi thấy cải thiện đáng kể trong tỷ lệ biên dịch, khi SantaCoder-FIM được tăng cường với MGD, dẫn đến việc nó vượt trội hơn text-davinci-003 với biên độ tương đối 27.97%. SantaCoder-FIM với MGD cải thiện tương đối so với SantaCoder-FIM với 17.52%.

Khớp Định danh Tiếp theo. Hình 5b hiển thị rằng kiểu FIM thúc đẩy khớp định danh tiếp theo nhưng vẫn kém hiệu suất hơn text-davinci-003 và tương ứng, SantaCoder với MGD. Tăng cường SantaCoder-FIM với MGD dẫn đến cải thiện tương đối 5.07%.

Khớp Chuỗi Định danh. Về ISM, SantaCoder-FIM với MGD cải thiện so với SantaCoder-FIM với 5.39%, thu hẹp khoảng cách với text-davinci-003, kém hiệu suất chỉ 1.06%.

Khớp Tiền tố. Hình 5d hiển thị rằng SantaCoder-FIM cải thiện so với SantaCoder, nhưng vẫn kém hiệu suất hơn text-davinci-003 với biên độ tương đối 6.83%. SantaCoder-FIM với MGD vượt trội hơn SantaCoder-FIM với 4.95% hiển thị cải thiện tiếp tục, trong khi giảm khoảng cách với text-davinci-003, kém hiệu suất chỉ 2.21%.

4

--- TRANG 19 ---
Tóm tắt. Tương tự như quan sát của chúng tôi với tăng cường prompt, trong khi kiểu FIM dẫn đến cải thiện trên tất cả các chỉ số, chúng tôi thấy cải thiện tiếp tục khi sử dụng cả FIM và MGD.

SC-FIM-classExprTypes-MGD. Được thúc đẩy bởi tính chất bổ sung của MGD, chúng tôi đánh giá thêm SC-FIM-classExprTypes-MGD, kết hợp cả tăng cường prompt và kiểu FIM, và phù hợp với những phát hiện của chúng tôi, nó dẫn đến cải thiện thêm so với SC-FIM-classExprTypes, như thấy trong Hình 5. Chúng tôi sử dụng classExprTypes với FIM vì RLPG cũng chọn một tập con của các dòng post trong tăng cường prompt trong một số lượng lớn trường hợp.

F Hiệu ứng của Độ phức tạp Định danh trên Khớp Định danh Tiếp theo - Kết quả Hoàn chỉnh

(a) Phân phối các phương thức theo định danh phức tạp nhất (b) Prompt tiêu chuẩn
(c) Tăng cường prompt (d) FIM

Hình 6: (NIM, score@6) qua độ phức tạp định danh tiếp theo

Độ phức tạp Định danh. Tên định danh trong các kho lưu trữ mã thường có thể trở nên cụ thể và dài (Karampatsis et al., 2020). Từ vựng của các LMs như CodeGen và SantaCoder thường được tạo ra bằng cách huấn luyện một tokenizer BPE trên toàn bộ hoặc một mẫu của bộ dữ liệu pretraining (Sennrich et al., 2016). Do điều này, trong khi các APIs thường được sử dụng có thể được token hóa thành các token đơn lẻ, các định danh cụ thể cho ngữ cảnh của các kho lưu trữ riêng lẻ, đặc biệt trong các thiết lập riêng tư, có thể mở rộng qua nhiều subtoken trong từ vựng LM, làm cho việc tạo ra chính xác của chúng khó khăn cho LM (cả do số lượng bước giải mã tăng lên dẫn đến không gian tìm kiếm lớn hơn và cũng do tính hiếm tương đối của tên định danh). Chúng tôi định nghĩa độ phức tạp của một định danh là số trung bình của các subtoken cần thiết để giải mã nó, sử dụng các tokenizer của tất cả các mô hình đang nghiên cứu (CG, SC, TD-3). Khoảng 36.97% các phương thức trong bộ dữ liệu DOTPROMPTS có ít nhất 1 định danh có độ phức tạp [4, 18) như hiển thị trong Hình 6a, và do đó, để một mô hình tạo ra những phương thức đó một cách chính xác, điều quan trọng là mô hình có thể tạo ra tên định danh phức tạp.

Khớp Định danh Tiếp theo. Hình 6 hiển thị kết quả cho chỉ số NIM, qua độ phức tạp tăng dần của định danh sự thật cơ bản tiếp theo. Chúng tôi lưu ý rằng tất cả các mô hình hiển thị sự suy giảm mạnh trong hiệu suất với sự gia tăng độ phức tạp định danh. Cùng xu hướng đúng với tăng cường prompt cũng như kiểu FIM. Tăng cường các mô hình cơ sở với MGD dẫn đến cải thiện đáng kể trong khả năng của mô hình dự đoán định danh tiếp theo cho trường hợp định danh phức tạp nhất [4, 18) với cải thiện tương đối trong khoảng 21%-28%. Mô hình nhỏ nhất, CodeGen-350M với MGD đạt được sự ngang bằng với mô hình lớn nhất, text-davinci-003 và vượt trội hơn CodeGen-6B lớn hơn nhiều với biên độ tương đối 11.95%. CodeGen-2B với MGD vượt trội hơn CodeGen-6B và text-davinci-003 với biên độ tương đối 22.14% và 9.79% tương ứng. SantaCoder với MGD cải thiện so với text-davinci-003 với biên độ tương đối 11.53%. Chúng tôi tiếp tục quan sát rằng cả tăng cường prompt và kiểu FIM với MGD dẫn đến tỷ lệ suy giảm giảm dần, như có thể thấy trong các đường cong cho SC-FIM-MGD trong Hình 6d. SantaCoder-FIM với MGD vượt trội hơn text-davinci-003 và SantaCoder-FIM với biên độ tương đối 16.11% và 17.04% tương ứng.

Tóm tắt. Khả năng của LMs dự đoán chính xác tên định danh giảm mạnh với sự gia tăng độ phức tạp định danh. Tất cả các mô hình với MGD vượt trội hơn các mô hình cơ sở tương ứng của chúng với cải thiện tương đối lớn trong khoảng 21%-28%, với các LMs nhỏ hơn vượt trội hơn các LMs lớn hơn nhiều (CodeGen-350M-MGD đạt được sự ngang bằng với text-davinci-003, và vượt trội hơn CodeGen-6B, CodeGen-2B-MGD vượt trội hơn CodeGen-6B). Trong khi tăng cường prompt và kiểu FIM dẫn đến cải thiện so với baseline, chúng cũng gặp phải sự giảm mạnh qua độ phức tạp định danh, nhưng tăng cường chúng với MGD dẫn đến cải thiện lớn tương tự như quan sát với các mô hình cơ sở (cải thiện tương đối trong khoảng 15.92%-18.59%).

G Tác động của MGD trên Thời gian Suy luận

Để nghiên cứu tác động của việc thêm MGD trên thời gian suy luận, chúng tôi so sánh thời gian tạo mã bởi mô hình CodeGen-6B và CodeGen-6B với MGD. Chúng tôi chọn 500 prompt từ DOTPROMPTS và tạo ra tối đa 512 token với CodeGen-6B cũng như CodeGen-6B với MGD. Việc suy luận được thực hiện với triển khai HuggingFace của mô hình trên cấu hình máy (1) như mô tả trong Phần 6. Chúng tôi sử dụng cùng sơ đồ giải mã như mô tả trong Phần 3. Sau khi tạo ra, chúng tôi lọc ra các trường hợp nơi số lượng token được tạo ra bởi CodeGen-6B và Codegen-6B với MGD không giống nhau, để đảm bảo sự ngang bằng cả trong kích thước của prompt đầu vào và số lượng token được tạo ra. Chúng tôi còn lại 161 thể hiện, nơi kích thước của prompt đầu vào, cũng như số lượng token được tạo ra, giống nhau cho cả hai mô hình. Bảng 2 hiển thị thống kê liên quan đến thời gian suy luận cho cả hai mô hình tính bằng giây. Chúng tôi quan sát sự chậm lại trung bình 83.16% trong thời gian giải mã cho CodeGen-6B với MGD. Chúng tôi lưu ý rằng có thể có nhiều cơ hội để tối ưu hóa triển khai của chúng tôi mặc dù chúng tôi chưa khám phá chúng.

6

--- TRANG 20 ---
Bảng 2: Thống kê về thời gian suy luận so sánh CodeGen-6B và Codegen-6B với MGD. Thời gian tính bằng giây.

CodeGen-6B CodeGen-6B-MGD
Trung bình 22.57 41.34
Chậm lại trung bình 83.16%
Độ lệch chuẩn 12.44 22.39
Tối thiểu 0.94 1.14
Tứ phân vị thứ nhất 21.23 26.76
Trung vị 25.48 44.56
Tứ phân vị thứ hai 25.86 58.20
Tối đa 79.06 111.73

H Nghiên cứu Khả năng Tổng quát hóa: Kết quả Microbenchmark

Bảng 3 trình bày kết quả trên MGDMICROBENCH, chi tiết các kịch bản chúng tôi đã đánh giá để nghiên cứu khả năng tổng quát hóa của MGD.

H.1 Các Ngôn ngữ Lập trình Khác nhau

Trong MGDMICROBENCH, CI1, NA1, VD1, J2 là các kịch bản mã hóa trong Java, SE1, SE2 và J1 là các kịch bản mã hóa trong C#, và TS1, TS2 và ST1 là các kịch bản mã hóa trong Rust mà các monitor dưới khung MGD, nhắm mục tiêu các ngôn ngữ cụ thể được xây dựng. Phần 4 cung cấp đánh giá chi tiết của một monitor cho Java. Do đó, tập thể, phần 4 và MGDMICROBENCH chứng minh rằng MGD khả thi cho Java, C# và Rust.

H.2 Các Kịch bản Mã hóa Khác nhau

Khởi tạo các lớp hợp lệ. Kịch bản CI1 (viết tắt của "class instantiation") xem xét mã demo cho một thiết lập trường đại học, nơi Person được khai báo như một lớp trừu tượng, được mở rộng cụ thể bởi các lớp Student và Teacher. Trong kịch bản này, mã prompt được thiết lập để khai báo một đối tượng p1 kiểu Person như sau: 'Person p1 = new '. Nhiệm vụ cho LM là hoàn thành mã một cách sinh động, gán một khởi tạo cụ thể của Person. Theo từ khóa 'new', một constructor nên được gọi. Cấu hình SC, không có MGD, gọi constructor không tồn tại Person(...) (không tồn tại vì nó là một lớp trừu tượng), trong khi SC-MGD, với một monitor phân biệt giữa các lớp trừu tượng và cụ thể gọi Student(...), hợp lệ theo kịch bản.

switch over enum. Các kịch bản SE1, SE2 (viết tắt của "switch over enum") và J1 (viết tắt của "joint monitoring") là các kịch bản đại diện được lấy từ một phần mềm mô phỏng thực tế được viết bằng C#. Trong các kịch bản SE1 và SE2, mã prompt đã được thiết lập để 'switch(...)' trên các giá trị enum kiểu 'AccessSize' và 'Intrinsic' tương ứng. Các cấu hình mô hình được sử dụng là SC và SC-MGD. Trong khi SC tạo ra nhánh 'case' '1', là vi phạm kiểu enum, SC-MGD tạo ra chính xác nhánh case 'AccessSize.Byte' kiểu chính xác trong khi cũng nhất quán với sự thật cơ bản. Trong SE2, trong khi SC có thể lấy được tên kiểu của giá trị enum chính xác, tức là nó tạo ra 'Intrinsic', giá trị enum dưới kiểu enum mà nó tạo ra không tồn tại, tức là ký hiệu 'X86Comisdgt' không tồn tại, và do đó không hợp lệ. SC-MGD tạo ra một nhánh case hợp lệ, 'Intrinsic.X86Comisdlt', nhất quán với sự thật cơ bản. Kịch bản SE2 không được giải quyết hoàn toàn do việc tham chiếu không hợp lệ của '.LessThan' bởi SC-MGD, do thiếu giám sát cho các tham chiếu, được giải quyết trong kịch bản J1 bên dưới, trong thảo luận về giám sát chung.

Số lượng đối số hợp lệ cho các phương thức. Các kịch bản NA1 (viết tắt của "number of arguments"), VD1 (viết tắt của "valid dereferences") và J2 được dẫn xuất bằng cách sửa đổi API cơ bản được trình bày trong Hình 1a (trong bài báo chính). Nhiệm vụ là sử dụng API fluent ServerNode.Builder để tạo ra một thể hiện của ServerNode. Đối với những kịch bản này, chúng tôi thay thế các phương thức riêng lẻ withIp(ip) và withPort(port) (như thấy trong Hình 1a) bằng một phương thức duy nhất withIpPort(ip, port) sau đó build() có thể được gọi để khởi tạo đối tượng ServerNode. Trong kịch bản NA1, mã prompt đã được thiết lập với một lời gọi mở đến phương thức withIpPort(, và nhiệm vụ cho LM là viết mã một cách sinh động để truyền các đối số chính xác cho phương thức. Cấu hình SC, không có MGD tạo ra một đối số duy nhất, và đóng lời gọi phương thức, do đó vi phạm API của phương thức withIpPort. Nó tiếp tục tạo ra một lời gọi đến phương thức không tồn tại withPort. Cấu hình SC-MGD được hướng dẫn bởi một monitor cho số lượng đối số hợp lệ, tạo ra hai đối số, tương ứng với ip và port, phù hợp với hợp đồng của withIpPort. Hơn nữa, nó gọi phương thức build().

Trong kịch bản VD1, thiết lập tương tự như NA1, ngoại trừ việc lời gọi đến phương thức withIpPort không được thực hiện, và thay vào đó, nhiệm vụ cho LM là tạo ra lời gọi đến phương thức đúng withIpPort, và sau đó tạo ra các đối số cho nó. Không như NA1, trong kịch bản này, chúng tôi chỉ sử dụng monitor tham chiếu. Trong khi cấu hình cơ sở, SC không có MGD, tạo ra một lời gọi đến 'hostAddress' không tồn tại, SC-MGD với monitor cho tham chiếu gọi phương thức đúng, 'withIpPort'. Tuy nhiên, không có monitor cho số lượng đối số đúng, nó chỉ tạo ra một đối số, do đó vi phạm API. Nó tiếp tục gọi withIpPort lần thứ hai, là một tham chiếu kiểu chính xác, tuy nhiên, không phải là phản hồi mong đợi theo sự thật cơ bản, vì nó là một lời gọi dư thừa. Kịch bản VD1 không được giải quyết hoàn toàn do số lượng đối số không hợp lệ bởi SC-MGD, và sẽ được giải quyết trong kịch bản J2 bên dưới.

Giám sát chung cho nhiều thuộc tính. Khung MGD có thể sử dụng kết quả từ nhiều monitor đồng thời để hướng dẫn việc tạo mã để tuân theo nhiều thuộc tính. Các kịch bản J1 và J2 khám phá 2 thể hiện khác nhau của joint-monitor hoạt động đồng thời. J1 là cùng kịch bản mã hóa như SE2. Trong SE2, monitor chỉ giám sát cho việc tạo ra các nhánh 'case' hợp lệ kiểu, trong khi ở J1, monitor cho các nhánh case hợp lệ và monitor cho tham chiếu hợp lệ kiểu được sử dụng chung để thực hiện giải mã. Sự khác biệt có thể được lưu ý trong việc tạo ra tham chiếu chính xác 'X86Condition.Below' trong J1 (được đánh dấu màu xanh lá cây) cho SC-MGD, trước đây là 'X86Condition.LessThan' trong SE2, dẫn đến lỗi ký hiệu không tồn tại. Trong J1, SC-MGD với joint monitor có thể tạo ra cả nhánh case chính xác, cũng như một tham chiếu hợp lệ.

Kịch bản J2 là cùng kịch bản mã hóa như VD1. Trong VD1, chỉ monitor cho tham chiếu hợp lệ được sử dụng trong SC-MGD, trong khi ở J2, các monitor cho tham chiếu hợp lệ và monitor cho số lượng đối số chính xác cho các phương thức, cả hai được sử dụng chung với SC-MGD. Sự khác biệt có thể được lưu ý trong số lượng đối số chính xác (2) được tạo ra bởi SC-MGD trong J2. Hơn nữa, không như trong VD1, SC-MGD trong J2 tiếp theo gọi build(), phù hợp với sự thật cơ bản, có thể do ngữ cảnh mã được cải thiện mà việc tạo ra số lượng đối số đúng đã cung cấp.

H.3 Các Phân tích Tĩnh và Ràng buộc Phong phú hơn

Mỗi kịch bản mã hóa khác nhau được thảo luận trong MGDMICROBENCH yêu cầu một phân tích tĩnh khác nhau được thực hiện, và do đó, MGD có thể áp dụng với nhiều kỹ thuật phân tích tĩnh. Trong phần này, chúng tôi tập trung vào các thuộc tính phong phú hơn có thể được thực thi với MGD. Sử dụng không chính xác tên ký hiệu là một lớp lỗi rộng, và nguyên nhân gốc rễ của nhiều lỗi thời gian biên dịch và thời gian chạy. Sử dụng không hợp lệ các tên ký hiệu/phương thức đã định nghĩa cũng có thể dẫn đến các lỗi thời gian biên dịch và thời gian chạy khác nhau, và do đó, chỉ có các ký hiệu trong ngữ cảnh có thể không hữu ích. Đối với các kịch bản sau, chúng tôi sử dụng các cấu hình SC-FIM-classExprTypes và SC-FIM-classExprTypes-MGD, mà chúng tôi thấy là các cấu hình mạnh nhất do ngữ cảnh bổ sung, trong đánh giá chi tiết trong phần 4.

Xem xét các kịch bản sau:

Giao thức Typestate. Android MediaPlayer có các ràng buộc phức tạp về thứ tự của các lời gọi API³ có thể khó cho thậm chí các nhà phát triển lý luận về (Mishra et al., 2016). Vi phạm thời gian chạy của các hợp đồng như vậy dẫn đến các ngoại lệ như 'IllegalStateException'. Mishra et al. (2016) đề xuất việc sử dụng phân tích typestate (Strom & Yemini, 1986) để phát hiện vi phạm của các giao thức như vậy, thông qua các kỹ thuật phân tích tĩnh, và ngăn chặn các lỗi tại thời gian chạy. Duarte & Ravara (2021) cho thấy rằng các giao thức typestate có thể được thực thi bởi phân tích phong phú được hỗ trợ trong hệ thống kiểu Rust. Chúng tôi sử dụng điều này, và khởi tạo một monitor để hướng dẫn LMs tạo ra các lời gọi API hợp lệ typestate.

TS1: Nhiệm vụ trong kịch bản TS1 (viết tắt của "typestate") là hoàn thành một cách sinh động mã được viết một phần lặp lại phát các bài hát trong một playlist sử dụng Android MediaPlayer API. Việc hoàn thành được gọi tại một điểm nơi đối tượng MediaPlayer ở trạng thái Stopped. Trong khi cấu hình cơ sở tạo ra một lời gọi đến stop();, vi phạm giao thức API, vì MediaPlayer đã ở trạng thái Stopped tại điểm hoàn thành, cùng cấu hình mô hình với MGD tạo ra reset(); là chuyển đổi hợp pháp duy nhất tại trạng thái theo giao thức được triển khai.

TS2: Crichton (2023) và Rust on Embedded Devices Working Group et al. (2018) mô tả việc biểu diễn các trạng thái pin GPIO và các chuyển đổi giữa chúng như một giao thức typestate. Chúng tôi sử dụng Rust API được cung cấp trong Rust on Embedded Devices Working Group et al. (2018) và giao nhiệm vụ cho LM hoàn thành mã được viết một phần, khởi tạo một pin GPIO và chuyển đổi sang trạng thái input_high_z. Trong khi cấu hình cơ sở tạo ra một lời gọi đến set_input_pull_up(); chuyển đổi sang trạng thái input_pulled_high, cùng mô hình được tăng cường với MGD gọi set_input_high_z(); dẫn đến trạng thái mong muốn.

Giao thức SessionType. Session types có thể được sử dụng để nắm bắt các ràng buộc thứ tự về giao tiếp hai bên (Crichton et al., 2019) như các máy trạng thái hữu hạn giao tiếp. Jespersen et al. (2015) đề xuất rằng hệ thống kiểu Rust có thể được sử dụng để thực thi hợp đồng session type tại thời gian biên dịch. Chúng tôi sử dụng phương pháp được đề xuất, và xây dựng một monitor, hướng dẫn LMs tạo ra các lời gọi phương thức phù hợp với hợp đồng.

ST1: Tương tác với máy ATM là một ví dụ thường được sử dụng cho giao thức giao tiếp hai chiều. Chúng tôi sử dụng chủ nghĩa session type cho máy ATM, được mô tả trong (Jespersen et al., 2015). Nhiệm vụ cho LM là hoàn thành mã được viết một phần sử dụng session type API, để gửi tiền và in số dư mới. Ở phía client, sau xác thực và chọn hành động gửi tiền (từ menu ATM), mô hình cơ sở tạo ra một lời gọi đến recv();, sẽ chờ ATM gửi một giá trị, trong khi giao thức mong đợi client "gửi" giá trị gửi. Mô hình cơ sở được tăng cường với MGD có thể tạo ra chính xác lời gọi đến send(0).recv();, đầu tiên gửi số tiền cần gửi, và sau đó chờ ATM giao tiếp số dư mới, sẽ được báo cáo cho người dùng. Chúng tôi lưu ý rằng với MGD, mô hình có thể tạo ra mã tuân theo giao thức một cách thích hợp.

³https://developer.android.com/reference/android/media/MediaPlayer

9

--- TRANG 21 ---
Bảng 3: Kết quả trên MGDMICROBENCH

ID MÔ TẢ KHÍA CẠNH TỔNG QUÁT HÓA KHÔNG CÓ MGD VỚI MGD

Kịch bản mã — Khởi tạo lớp hợp lệ
CI1 Trường đại học - Khởi tạo và gán cho lớp trừu tượng Kịch bản Mã, Java Person p1 = new Person("John", ...) Person p1 = new Student("John", ...)

Kịch bản mã — Hằng số enum hợp lệ trong câu lệnh switch
SE1 Mô phỏng - switch over enum AccessSize Kịch bản Mã, C# case 1 : ... case AccessSize.Byte : ...
SE2 Mô phỏng - switch over enum Intrinsic Kịch bản Mã, C# case Intrinsic.X86Comisdgt : ... X86Condition.GreaterThan case Intrinsic.X86Comisdlt : ... X86Condition.LessThan

Kịch bản mã — Số lượng đối số chính xác trong lời gọi phương thức
NA1 Fluent API - Parse Server Kịch bản Mã, Java arr[0] ).withPort(...) arr[0].trim() , Integer.parseInt( arr[1].trim()) ).build()

Kịch bản mã — tham chiếu kiểu chính xác
VD1 Fluent API - Parse Server Kịch bản Mã, Java .hostAddress (arr[0]).port(Integer.parseInt(arr[1])) .withIpPort (arr[0] ).withIpPort(arr[1] )

Giám sát chung cho hằng số enum hợp lệ trong switch và tham chiếu kiểu chính xác
J1 Mô phỏng - switch over enum Intrinsic Kịch bản Mã, C# case Intrinsic.X86Comisdgt : ... X86Condition.GreaterThan case Intrinsic.X86Comisdlt : ... X86Condition.Below

Giám sát chung cho tham chiếu kiểu chính xác và số lượng đối số
J2 Fluent API - Parse Server Kịch bản Mã, Java .hostAddress (arr[0]).port(Integer.parseInt(arr[1])) .withIpPort( arr[0].trim() , Integer.parseInt( arr[1].trim()) ).build()

Phân tích Tĩnh — Giao thức API Typestate
TS1 Android MediaPlayer Typestate, Rust stop(); reset();
TS2 GPIO Pins Typestate, Rust set_input_pull_up(); set_input_high_z();

Phân tích Tĩnh — Giao thức giao tiếp 2-bên SessionType
ST1 Gửi tiền vào ATM SessionTypes, Rust recv(); send(0).recv();

8

--- TRANG 22 ---
I Truy vấn CodeQL để Xác định Phương thức Mục tiêu Đánh giá

/**
* @id java/examples/find_target_methods
* @name find_target_methods
* @description Xác định phương thức mục tiêu từ kho lưu trữ Java cùng với thông tin classExprTypes cho bộ dữ liệu DotPrompts
*/
import java
predicate filterClass(Class c) {
not(c instanceof TestClass) and
c.fromSource() and
not c.getFile().getRelativePath().matches("%generated%") and
not(c.getFile().getRelativePath().matches("%test%")) and
not(c.getFile().getRelativePath().matches("%target%")) and
not(c.getFile().getRelativePath().matches("%build%")) and
count(Method m1 | m1 = c.getAMethod() and filterMethod(m1) | m1) >= 1
}
predicate filterMethod(Method m) {
m.fromSource() and
not(m instanceof TestMethod) and
not(m.hasName("<clinit>")) and
not(m.hasName("<obinit>")) and
m.getBody().getNumStmt() >= 2 and
(m.getBody().getLocation().getEndLine() -
m.getBody().getLocation().getStartLine()) >= 7
}
predicate typeDeclaredInFile(Type t, File file) {
(t.fromSource() and t.getFile() = file) or
(t.getErasure().fromSource() and t.getErasure().getFile() = file)
}
// Tìm tệp classExprTypes sao cho chúng chứa định nghĩa kiểu của bất kỳ biểu thức nào được định nghĩa trong bất kỳ callable nào trong lớp ngoại trừ target_m
predicate filterClassExprTypeFile(Class c, Method target_m, File classFile, File classExprTypesFile){
classExprTypesFile != classFile and
(
// classExprTypesFile chứa định nghĩa kiểu của một kiểu được nhập đơn lẻ
exists(Type t, ImportType impt |
impt.fromSource() and
c.getFile() = impt.getFile() and
t = impt.getImportedType() and
typeDeclaredInFile(t, classExprTypesFile)
) or
// classExprTypesFile chứa định nghĩa kiểu của kiểu trả về hoặc kiểu param của phương thức mục tiêu
exists(Type t |
(t = target_m.getAParamType() or t = target_m.getReturnType()) and
typeDeclaredInFile(t, classExprTypesFile)
) or
// classExprTypesFile chứa định nghĩa kiểu của kiểu của bất kỳ biểu thức nào trong một callable (không phải phương thức mục tiêu) trong lớp c, hoặc kiểu trả về của một callable hoặc bất kỳ tham số nào của nó
exists(Expr e, Type t, Callable m |
m = c.getACallable() and
m != target_m and
(
(
e.getAnEnclosingStmt() = m.getBody().getAStmt()
and
e.getType() = t
) or
t = m.getAParamType() or t = m.getReturnType()
) and
typeDeclaredInFile(t, classExprTypesFile)
) or
// classExprTypesFile chứa định nghĩa kiểu của bất kỳ kiểu trường nào
exists(Type t, Field f |
c.getAField() = f and
f.getType() = t and
typeDeclaredInFile(t, classExprTypesFile)
)
)
}
predicate expressionOfTypeContainedInBlock(Expr e, Type t, BlockStmt b) {
e.getAnEnclosingStmt() = b.getAStmt() and
e.getType() = t
}
from File classFile, File classExprTypesFile, Class c, Method m, BlockStmt b, int startLine, int startCol, int endLine, int endCol
where
// Ràng buộc biến
m = c.getAMethod() and
b = m.getBody() and
classFile = c.getFile() and
// Áp dụng bộ lọc
filterClass(c) and
filterMethod(m) and
filterClassExprTypeFile(c, m, classFile, classExprTypesFile) and
// Ràng buộc vị trí ranh giới phương thức
startLine = b.getLocation().getStartLine() and
startCol = b.getLocation().getStartColumn() and
endLine = b.getLocation().getEndLine() and
endCol = b.getLocation().getEndColumn()
select
classFile.getAbsolutePath(),
classFile.getRelativePath(),
classExprTypesFile.getAbsolutePath(),
classExprTypesFile.getRelativePath(),
startLine,

10

--- TRANG 23 ---
startCol,
endLine,
endCol

J Ví dụ về Tạo Mã với MGD

Chúng tôi trình bày các ví dụ về tạo mã với MGD và so sánh chúng với các thế hệ không có tăng cường MGD. Sự xuất hiện của các dấu hiệu màu đỏ dưới tên định danh chỉ ra rằng tên định danh không nhất quán kiểu với đối tượng/lớp mục tiêu cho toán tử tham chiếu. Chúng tôi làm nổi bật các định danh chính xác được tạo ra với tăng cường MGD bằng màu xanh lá cây nhạt.

Prompt
Sự thật Cơ bản
TD-3
SC
SC-MGD

Hình 7: TD-3 và SC tạo ra tên định danh không hợp lệ: getName, getDesc cho đối tượng mục tiêu envTypeEnum và success cho lớp mục tiêu ListResult. Tăng cường SC với MGD dẫn đến việc tạo ra các định danh chính xác: getDescription, of cho các đối tượng tương ứng, dẫn đến sự đồng ý hoàn toàn với sự thật cơ bản.

12

--- TRANG 24 ---
Prompt
Sự thật Cơ bản
TD-3
SC
SC-MGD
SC-classExprTypes
SC-classExprTypes-MGD

Hình 8: SC và TD-3 tạo ra tên định danh: ACCOUNT_NOT_FOUND, không hợp lệ cho lớp mục tiêu. Đoạn mã được trình bày ở trên là từ một trong những tệp có mặt trong tăng cường classExprTypes. Tăng cường SC với classExprTypes dẫn mô hình tạo ra tên định danh ACCOUNT_NUMBER_EMPTY, nhất quán với kiểu: ValidationMessages, và do đó có thể biên dịch. Tuy nhiên, nó vẫn không khớp với sự thật cơ bản. Tăng cường cả SC và SC-classExprTypes với MGD dẫn mô hình tạo ra tên định danh chính xác: ACCOUNT_NUMBER_NOT_EXIST, đạt được sự đồng ý với sự thật cơ bản.

Prompt
Sự thật Cơ bản
TD-3
SC
SC-MGD

Hình 9: TD-3 và SC tạo ra mã khớp với sự thật cơ bản, ngoại trừ tên định danh cho các đối tượng mục tiêu: advancedSettings, advancedSettingsComponent. Tăng cường SC với MGD dẫn đến việc tạo ra tên định danh chính xác, và do đó đồng ý với sự thật cơ bản.

13

--- TRANG 25 ---
Prompt
Sự thật Cơ bản
TD-3
SC
SC-MGD
SC-FIM
SC-FIM-MGD

Hình 10: TD-3 và SC đều tạo ra mã với tên định danh không hợp lệ. SC được tăng cường với MGD có thể sử dụng tên định danh chính xác và do đó tạo ra mã có thể biên dịch. Tuy nhiên, mã được tạo ra không sử dụng lớp ngoại lệ đã định nghĩa: ZolaServerConnectionFailedException cho xử lý ngoại lệ. Tăng cường SC với Fill-in-the-middle cung cấp cho mô hình ngữ cảnh cần thiết để thực hiện xử lý ngoại lệ, tuy nhiên, mô hình vẫn ảo giác tên định danh getQueueName cho đối tượng mục tiêu message. Do đó, để có được một thế hệ chính xác, SC được tăng cường với cả FIM và MGD, và cấu hình này có thể khớp với sự thật cơ bản.

Prompt
Sự thật Cơ bản
TD-3
SC
SC-MGD
SC-classExprTypes
SC-classExprTypes-MGD

Hình 11: Ví dụ về tạo ra với tăng cường prompt classExprTypes.

14

--- TRANG 26 ---
Prompt
Sự thật Cơ bản
TD-3
SC
SC-MGD
SC-RLPG
SC-RLPG-MGD

Hình 12: Ví dụ về tạo ra với tăng cường prompt RLPG. Tăng cường SC với RLPG dẫn đến việc tạo ra toDtos so với toDTOList, nơi cả hai đều là tên định danh không hợp lệ cho đối tượng mục tiêu. Tăng cường cả hai cấu hình với MGD dẫn đến việc tạo ra định danh chính xác và khớp với sự thật cơ bản.

Prompt
Sự thật Cơ bản
TD-3
SC
SC-MGD

Hình 13: TD-3 và SC tạo ra tên định danh: ATTR, GROUP_KEY tương ứng cho lớp mục tiêu Constant, cả hai đều không hợp lệ. Tăng cường MGD dẫn đến việc tạo ra định danh chính xác: UPDATEABLEPRICE.

15

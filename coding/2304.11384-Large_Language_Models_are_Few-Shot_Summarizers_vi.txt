# 2304.11384.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/coding/2304.11384.pdf
# Kích thước tệp: 1412622 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Các Mô hình Ngôn ngữ Lớn là Các Tóm tắt viên Few-Shot:
Tạo sinh Bình luận Đa-ý định thông qua Học tập Trong Ngữ cảnh
Mingyang Geng
gengmingyang13@nudt.edu.cn
Khoa Khoa học Máy tính,
Đại học Quốc phòng Công nghệ
Changsha, Trung QuốcShangwen Wang
wangshangwen13@nudt.edu.cn
Khoa Khoa học Máy tính,
Đại học Quốc phòng Công nghệ
Changsha, Trung QuốcDezun Dong
dong@nudt.edu.cn
Khoa Khoa học Máy tính,
Đại học Quốc phòng Công nghệ
Changsha, Trung Quốc
Haotian Wang
wanghaotian13@nudt.edu.cn
Khoa Khoa học Máy tính,
Đại học Quốc phòng Công nghệ
Changsha, Trung QuốcGe Li
lige@pku.edu.cn
Phòng thí nghiệm Trọng điểm Công nghệ Phần mềm Độ tin cậy Cao, Đại học Bắc Kinh
Bắc Kinh, Trung QuốcZhi Jin
zhijin@pku.edu.cn
Phòng thí nghiệm Trọng điểm Công nghệ Phần mềm Độ tin cậy Cao, Đại học Bắc Kinh
Bắc Kinh, Trung Quốc
Xiaoguang Mao
xgmao@nudt.edu.cn
Khoa Khoa học Máy tính,
Đại học Quốc phòng Công nghệ
Changsha, Trung QuốcXiangke Liao
xkliao@nudt.edu.cn
Khoa Khoa học Máy tính,
Đại học Quốc phòng Công nghệ
Changsha, Trung Quốc
TÓM TẮT
Tạo sinh bình luận mã nhằm mục đích tạo ra các mô tả ngôn ngữ tự nhiên cho một đoạn mã để hỗ trợ các hoạt động hiểu chương trình của các nhà phát triển. Mặc dù đã được nghiên cứu trong thời gian dài, một nút thắt cổ chai đối với các phương pháp hiện tại là khi được cho một đoạn mã, chúng chỉ có thể tạo sinh một bình luận trong khi các nhà phát triển thường cần biết thông tin từ các góc độ đa dạng như chức năng của đoạn mã này là gì và cách sử dụng nó. Để giải quyết hạn chế này, nghiên cứu này điều tra thực nghiệm tính khả thi của việc sử dụng các mô hình ngôn ngữ lớn (LLMs) để tạo sinh các bình luận có thể đáp ứng các ý định đa dạng của nhà phát triển. Trực giác của chúng tôi dựa trên các sự kiện rằng (1) mã và bình luận cặp đôi được sử dụng trong quá trình tiền huấn luyện của LLMs để xây dựng kết nối ngữ nghĩa giữa ngôn ngữ tự nhiên và ngôn ngữ lập trình, và (2) các bình luận trong các dự án thực tế, được thu thập cho việc tiền huấn luyện, thường chứa các ý định khác nhau của nhà phát triển. Chúng tôi

†Shangwen Wang và Dezun Dong là các tác giả liên hệ.
Shangwen Wang và Xiaoguang Mao thuộc Phòng thí nghiệm Trọng điểm Kỹ thuật Phần mềm cho Hệ thống Phức tạp.
Công trình này được hỗ trợ bởi Dự án Chương trình Nghiên cứu và Phát triển Trọng điểm Quốc gia "Fusion Điện toán Dị nhất của Tài nguyên Xuyên miền" Số.2022YFB4501702.
Được phép tạo bản sao kỹ thuật số hoặc bản cứng của tất cả hoặc một phần công trình này để sử dụng cá nhân hoặc lớp học miễn phí với điều kiện các bản sao không được tạo ra hoặc phân phối vì lợi nhuận hoặc lợi thế thương mại và các bản sao mang thông báo này và trích dẫn đầy đủ trên trang đầu tiên. Bản quyền cho các thành phần của công trình này thuộc sở hữu của người khác ngoài ACM phải được tôn trọng. Tóm tắt với ghi công được cho phép. Để sao chép khác, hoặc tái xuất bản, để đăng trên máy chủ hoặc để phân phối lại danh sách, yêu cầu sự cho phép cụ thể trước và/hoặc phí. Yêu cầu quyền từ permissions@acm.org.
ICSE 2024, Tháng 4 2024, Lisbon, Bồ Đào Nha
©2024 Hiệp hội Máy tính.
ACM ISBN 978-x-xxxx-xxxx-x/YY/MM. . . $15.00
https://doi.org/10.1145/xxxxxxx.xxxxxxxdo đó giả định rằng các LLMs đã có thể hiểu mã từ các góc độ khác nhau sau khi tiền huấn luyện. Thật vậy, các thí nghiệm trên hai bộ dữ liệu quy mô lớn chứng minh tính hợp lý của những hiểu biết của chúng tôi: bằng cách áp dụng mô hình học tập trong ngữ cảnh và cung cấp các gợi ý đầy đủ cho LLM (ví dụ, cung cấp cho nó mười hoặc nhiều ví dụ hơn), LLM có thể vượt trội đáng kể so với phương pháp học có giám sát hiện đại nhất về tạo sinh bình luận với nhiều ý định. Kết quả cũng cho thấy rằng các chiến lược tùy chỉnh để xây dựng gợi ý và các chiến lược hậu xử lý để sắp xếp lại kết quả đều có thể thúc đẩy hiệu suất của LLM, điều này soi sáng các hướng nghiên cứu tương lai cho việc sử dụng LLMs để đạt được tạo sinh bình luận.
CCS CONCEPTS
•Phần mềm và kỹ thuật của nó →Công cụ bảo trì phần mềm ; Bảo trì phần mềm ;Tiến hóa phần mềm .
TỪ KHÓA
Tóm tắt Mã, Mô hình Ngôn ngữ Lớn, Học tập Trong Ngữ cảnh
Định dạng Tham chiếu ACM:
Mingyang Geng, Shangwen Wang, Dezun Dong, Haotian Wang, Ge Li, Zhi Jin, Xiaoguang Mao, và Xiangke Liao. 2024. Các Mô hình Ngôn ngữ Lớn là Các Tóm tắt viên Few-Shot: Tạo sinh Bình luận Đa-ý định thông qua Học tập Trong Ngữ cảnh . Trong Kỷ yếu Hội nghị Quốc tế lần thứ 46 về Kỹ thuật Phần mềm (ICSE 2024). ACM, New York, NY, USA, 13 trang. https:
//doi.org/10.1145/xxxxxxx.xxxxxxx
1 GIỚI THIỆU
Tạo sinh bình luận mã (còn gọi là tóm tắt mã) nhắm đến tham vọng tự động tạo ra một mô tả ngôn ngữ tự nhiên ngắn gọn và trôi chảy của mã nguồn. Nó được coi là một cách quan trọngarXiv:2304.11384v3  [cs.SE]  14 Jun 2023

--- TRANG 2 ---
ICSE 2024, Tháng 4 2024, Lisbon, Bồ Đào Nha Mingyang Geng, Shangwen Wang, Dezun Dong, Haotian Wang, Ge Li, Zhi Jin, Xiaoguang Mao, và Xiangke Liao
để hỗ trợ hiểu chương trình vì các nhà phát triển thường quên hoặc không có thời gian viết các bình luận như vậy, và do đó có tiềm năng thúc đẩy các hoạt động phát triển và bảo trì phần mềm. Qua các năm, một số nghiên cứu đã được dành để tiến bộ hiện trạng trong lĩnh vực này [ 4,28,32]. Ví dụ, các kỹ thuật truy xuất thông tin, tập trung vào việc trích xuất một số token quan trọng từ mã, được sử dụng trong giai đoạn đầu [ 25,58], tiếp theo là một số công trình gần đây áp dụng các kỹ thuật học sâu tiên tiến cho nhiệm vụ này, chẳng hạn như mô hình dịch máy thần kinh (NMT) [5, 28].

Mặc dù đã đạt được tiến bộ to lớn trong lĩnh vực này, một vấn đề quan trọng làm giảm tính thực tiễn của các phương pháp tạo sinh bình luận mã hiện tại là chúng chỉ có thể tạo sinh các bình luận mô tả một khía cạnh của một đoạn mã cho trước (và do đó là ánh xạ một-một). Tuy nhiên, trong thực tế, các nhà phát triển thường viết bình luận với các ý định đa dạng để tóm tắt mã từ các góc độ khác nhau (ví dụ, chức năng chính của mã là gì và chúng ta có thể sử dụng nó như thế nào). Ví dụ, Zhai et al. [75] đã kiểm tra thủ công các bình luận từ các dự án thực tế và xác định sáu loại ý định ẩn trong các bình luận (như được hiển thị trong Bảng 1). Mu et al. [47] đã thống kê các dự án Java có sao cao nhất trên GitHub và phát hiện rằng khoảng 67% các phương thức chứa nhiều hơn một ý định trong bình luận của chúng. Các quan sát trên cho thấy điều mà các nhà phát triển thực sự cần là ánh xạ một-nhiều (tức là tạo sinh nhiều bình luận tóm tắt mã cho trước từ các góc độ khác nhau), được gọi là nhiệm vụ tạo sinh bình luận đa-ý định trong bài báo này.

Để giải quyết nhiệm vụ nêu trên, Mu et al. [47] đã đề xuất một phương pháp có tên DOME, trong đó cơ chế chú ý được sử dụng để tập trung vào các phần khác nhau của mã cho các ý định khác nhau. Tuy nhiên, DOME dựa trên học có giám sát, điều này hạn chế hiệu quả của nó do lượng dữ liệu có sẵn để huấn luyện. Để giải quyết vấn đề thiếu dữ liệu, chúng tôi đề xuất mượn vũ khí của các mô hình ngôn ngữ lớn (LLMs) [ 8], được tiền huấn luyện trên một kho dữ liệu với quy mô rất lớn theo cách tự giám sát và đã nắm bắt được nhiều kiến thức miền trong quá trình như vậy. Việc áp dụng LLMs cho nhiệm vụ tạo sinh bình luận đa-ý định được thúc đẩy bởi hai yếu tố. Thứ nhất, các LLMs được thiết kế cho miền mã thường được tiền huấn luyện bằng cách sử dụng mã và các bình luận cặp đôi liên quan để thiết lập kết nối ngữ nghĩa giữa ngôn ngữ lập trình và ngôn ngữ tự nhiên [ 19,67]. Ví dụ, nhiệm vụ tiền huấn luyện được sử dụng phổ biến, mô hình hóa ngôn ngữ có mặt nạ [15,19,24], được thiết kế cụ thể để căn chỉnh các biểu diễn ngôn ngữ lập trình và ngôn ngữ tự nhiên. Thứ hai, nghiên cứu hiện tại đã cho thấy rằng các bình luận mã từ các dự án thực tế, tạo thành kho dữ liệu huấn luyện cho LLMs, thường chứa nhiều ý định [47]. Kết quả là, trong quá trình tiền huấn luyện, LLMs được huấn luyện để hiểu mã từ các góc độ khác nhau, có khả năng cho phép chúng nắm bắt các ngữ nghĩa mã khác nhau. Do đó, bằng cách khai thác đầy đủ khả năng của các LLMs đã được tiền huấn luyện, chúng ta có thể đạt được hiệu suất tốt trên nhiệm vụ tạo sinh bình luận đa-ý định.

Gần đây, học tập trong ngữ cảnh đã được chứng minh là một cách hiệu quả để khai thác kiến thức miền ẩn trong các LLMs [8,11,48,60], vì định dạng đầu vào cho mô hình có thể nhất quán với định dạng trong quá trình tiền huấn luyện. Lấy cảm hứng từ các nghiên cứu này, chúng tôi nhằm điều tra tính khả thi của việc giải quyết nhiệm vụ tạo sinh bình luận đa-ý định với học tập trong ngữ cảnh. Nói chung, học tập trong ngữ cảnh yêu cầu cung cấp một gợi ý cho mô hình bao gồm một hướng dẫn ngôn ngữ tự nhiên mô tả thông tin chi tiết của nhiệm vụ, (tùy chọn) một số ví dụ minh họa cách thức nhiệm vụ có thể được thực hiện tốt, và một truy vấn cần được giải quyết. Do đó, một câu hỏi theo sau là rằng, với học tập trong ngữ cảnh, làm thế nào chúng ta có thể thu được kết quả tốt hơn từ các LLMs (ví dụ, liệu có thể thông qua việc thiết kế các gợi ý có thể hướng dẫn LLMs hướng tới đầu ra mong muốn). Để cung cấp bằng chứng thực nghiệm về các câu hỏi nêu trên, chúng tôi điều tra các khía cạnh sau trong nghiên cứu này: (a) Liệu các LLMs có thể hỗ trợ hoàn thành nhiệm vụ tạo sinh bình luận đa-ý định bằng cách sử dụng mô hình học tập trong ngữ cảnh? (b) Liệu chúng ta có thể cải thiện hiệu suất của LLMs bằng cách thiết kế các chiến lược lựa chọn minh họa tùy chỉnh? và (c) Liệu chúng ta có thể cải thiện hiệu suất của LLMs bằng cách thiết kế các chiến lược tùy chỉnh để hậu xử lý các kết quả thu được?

Để làm điều đó, chúng tôi thực hiện các thí nghiệm mở rộng trên hai bộ dữ liệu ngôn ngữ Java quy mô lớn, đó là Funcom [ 36] và TLC [ 30]. Chúng tôi sử dụng mô hình OpenAI Codex làm LLM đại diện vì hiệu suất vượt trội của nó trong một số nhiệm vụ trí tuệ mã [48, 54]. Nghiên cứu của chúng tôi đưa ra những phát hiện quan trọng sau:

F1:Khi LLM không được gợi ý đầy đủ (tức là số lượng ví dụ minh họa ít hơn 10), tiềm năng của LLMs có thể không được khai thác đầy đủ và hiệu quả là dưới tối ưu so với phương pháp học có giám sát hiện đại nhất, DOME; ngược lại, khi số lượng ví dụ minh họa đạt mười, LLM được gợi ý đầy đủ hơn và hiệu suất của nó vượt qua phương pháp DOME.

F2:Các chiến lược lựa chọn minh họa có thể giúp LLMs hiểu rõ hơn nhiệm vụ đang diễn ra và do đó tăng cường hiệu quả của chúng ở mức độ lớn: khi số lượng ví dụ là mười và các đoạn mã giống nhất với đoạn mã đích được sử dụng làm ví dụ minh họa, các giá trị BLEU của Codex có thể được tăng lên 97% và 131% trên hai bộ dữ liệu, tương ứng, so với lựa chọn ngẫu nhiên.

F3:Các đầu ra của LLMs có thể được sắp xếp lại dựa trên các heuristic đơn giản để đạt được cải thiện hiệu suất thêm: so với cài đặt thí nghiệm được đề cập ở trên, các giá trị BLEU của Codex có thể được cải thiện thêm 9,9% và 9,6%, tương ứng, trên hai bộ dữ liệu nếu bình luận của mã kho tương tự như mã đích có thể được sử dụng để hướng dẫn sắp xếp lại đầu ra.

Nghiên cứu của chúng tôi chứng minh rằng LLMs có khả năng được áp dụng vào tạo sinh bình luận đa-ý định vì nó xây dựng các đường cơ sở hiệu suất mạnh trên nhiệm vụ này, điều này nên được các nhà thiết kế công cụ xem xét trong đánh giá tương lai. Những hàm ý tiếp theo bao gồm việc thiết kế các chiến lược lựa chọn minh họa tốt hơn cũng như các chiến lược sắp xếp lại đều là những hướng nghiên cứu đầy hứa hẹn.

2 BỐI CẢNH VÀ CÁC CÔNG TRÌNH LIÊN QUAN
2.1 Tạo sinh Bình luận
Tạo sinh bình luận mã tự động, nhằm mục đích tóm tắt mã bằng các mô tả ngôn ngữ tự nhiên ngắn gọn, là một nhiệm vụ quan trọng để

--- TRANG 3 ---
Các Mô hình Ngôn ngữ Lớn là Các Tóm tắt viên Few-Shot:
Tạo sinh Bình luận Đa-ý định thông qua Học tập Trong Ngữ cảnh ICSE 2024, Tháng 4 2024, Lisbon, Bồ Đào Nha

Bảng 1: Phân loại ý định của các bình luận mã [12, 75].
Loại Định nghĩa Ví dụ
What Mô tả chức năng của một phương thức"Kiểm tra xem các đơn vị ô tại tọa độ cho trước có được hiển thị trên màn hình không"
WhyGiải thích lý do tại sao một phương thức được cung cấp hoặc lý do thiết kế của phương thức"Chuẩn bị để bắt đầu thực hiện các cuộc gọi đến các callback hiện đang được đăng ký"
How-to-useMô tả cách sử dụng hoặc thiết lập dự kiến của việc sử dụng một phương thức"Mã được thực thi trước phương thức bị chặn"
How-it-is-done Mô tả chi tiết triển khai của một phương thức"Kết thúc bảng hiện tại, loại bỏ nó và đẩy đỉnh ngăn xếp để trở thành bảng hiện tại mới"
PropertyKhẳng định các thuộc tính của một phương thức bao gồm các điều kiện tiên quyết hoặc điều kiện hậu quyết của một phương thức"Trả về true nếu giá trị là một chuỗi khớp với regex"
Others Bình luận không xác định hoặc mơ hồ "Tôi đã hoàn thành với mô hình, giải phóng tài nguyên "

hỗ trợ hiểu chương trình. Nhiều phương pháp đã được đề xuất để xây dựng một tập hợp các quy tắc phức tạp được định nghĩa thủ công, dựa trên đó các bình luận có thể được tạo ra theo các mẫu cụ thể [25,27]. Với sự tiến bộ gần đây của học sâu, một dòng nghiên cứu nóng đã đề xuất áp dụng các mạng thần kinh sâu (DNNs) cho nhiệm vụ này. Bằng cách mô hình hóa mã làm đầu vào và bình luận làm đầu ra, các phương pháp tạo sinh bình luận thần kinh (NCG) như vậy tự động học một hàm, thường là một mô hình DNN như mô hình dịch máy thần kinh, có thể tạo ra đầu ra khi được cho đầu vào. Mô hình DNN như vậy được học bằng cách sử dụng dữ liệu cặp mã-bình luận quy mô lớn hiện có. CodeNN [ 32] là một nỗ lực sớm theo hướng này chỉ sử dụng các chuỗi token mã, tiếp theo là các phương pháp khác nhau sử dụng cấu trúc AST [ 4,28,29], kiến thức API [ 30], thông tin kiểu [ 9], ngữ cảnh toàn cục [ 7,26,66], học tăng cường [ 22,62,65], học đa nhiệm vụ [ 72], học kép [ 68,73], các mô hình ngôn ngữ đã được tiền huấn luyện [ 19,21,67], và các phương pháp lai [ 69,77]. Ngoài ra, một số công trình cũng tập trung vào tạo sinh các bình luận mới nhất và thông tin dựa trên các bình luận lỗi thời (còn gọi là cập nhật bình luận) [39, 40].

Tuy nhiên, các phương pháp nêu trên chỉ có thể tạo sinh các bình luận mô tả một khía cạnh của một đoạn mã cho trước, điều này hạn chế tính thực tiễn của chúng vì các nhà phát triển thường thể hiện nhiều ý định khi bình luận mã [ 12,47,75]. Có nghĩa là, việc chỉ tạo sinh các bình luận mô tả một khía cạnh cụ thể của một đoạn mã (ví dụ, chức năng của mã) có thể không đáp ứng các yêu cầu của nhà phát triển về việc tóm tắt mã một cách toàn diện (ví dụ, cách sử dụng mã). Cụ thể, theo các nghiên cứu trước đây [12,47,75], các nhà phát triển thường có sáu loại ý định khi bình luận mã, tức là what ,why,how-to-use ,how-it-is-done , property , và others . Trong Bảng 1, chúng tôi liệt kê định nghĩa chi tiết và ví dụ cho mỗi loại. Thực tế là các nhà phát triển thường thể hiện nhiều ý định trong các bình luận đặt ra các mối đe dọa đối với tính thực tiễn của các kỹ thuật tạo sinh bình luận ý định đơn hiện tại. Để giải quyết thách thức này, Mu et al. [47] đề xuất một phương pháp tạo sinh bình luận mã hướng ý định nhà phát triển DOME, nhằm mục đích tạo ra một bình luận nhất quán với một ý định cho trước. Nó hoạt động bằng cách tận dụng cơ chế chú ý được hướng dẫn bởi ý định cho trước để tập trung vào thông tin liên quan nhất từ mã. Theo hiểu biết tốt nhất của chúng tôi, DOME hiện tại là kỹ thuật duy nhất có thể tạo sinh các bình luận đa dạng khi được cho các loại ý định khác nhau.

2.2 Các Mô hình Ngôn ngữ Lớn
Các mô hình ngôn ngữ lớn (LLMs) được huấn luyện trên các kho dữ liệu khổng lồ không có nhãn đã được chứng minh là hoạt động tốt trên một loạt rộng các nhiệm vụ, bao gồm tạo sinh ngôn ngữ tự nhiên, phân tích ngữ nghĩa, và tạo sinh mã [ 8,16,56]. Lý do cho sức mạnh của chúng có thể được kết luận là chúng không cần dữ liệu huấn luyện cụ thể cho nhiệm vụ và có thể được tiền huấn luyện trên dữ liệu trong tự nhiên khổng lồ theo cách tự giám sát (còn gọi là tiền huấn luyện), để có thể nắm bắt đủ kiến thức miền. Người tiên phong của hướng này, mô hình GPT [ 55], được đề xuất lần đầu vào năm 2018. Sau đó, một số nghiên cứu tiếp theo liên tục tăng cường hiệu suất hiện đại bằng cách điều chỉnh kiến trúc mô hình (ví dụ, BERT [ 16]) hoặc tăng tổng số tham số (ví dụ, GPT-3 [8]).

Codex, được phát hành bởi OpenAI, là một LLM dựa trên kiến trúc GPT-3 (tức là chứa một bộ giải mã dựa trên Transformer) [ 2]. Nó cung cấp năng lượng cho GitHub Copilot, một lập trình viên AI cặp tạo ra toàn bộ hàm mã khi được cho một mô tả ngôn ngữ tự nhiên. Codex được huấn luyện trên một kho mã khổng lồ chứa các ví dụ cặp mã-bình luận từ nhiều ngôn ngữ lập trình bao gồm Python, JavaScript, C/C++, Go, Perl, PHP, Ruby, Swift, TypeScript, SQL và Shell. Tương tự như GPT-3, Codex áp dụng cách thức tự hồi quy trong quá trình tiền huấn luyện, trong đó khi được cho một chuỗi token mã/bình luận, nó được huấn luyện để dự đoán token tiếp theo và token được dự đoán được sử dụng đệ quy làm đầu vào cho dự đoán tiếp theo cho đến khi kết thúc chuỗi. Trong nghiên cứu của chúng tôi, chúng tôi sử dụng Codex làm LLM đại diện vì nó là một LLM phổ biến trong lĩnh vực kỹ thuật phần mềm và đã được nghiên cứu rộng rãi trong tài liệu [10, 14, 18, 34, 49, 52, 54, 78].

2.3 Học tập Trong Ngữ cảnh
Trước đây, để áp dụng một mô hình đã được tiền huấn luyện trên các nhiệm vụ hạ lưu, người dùng cần huấn luyện thêm nó trên dữ liệu có nhãn của các nhiệm vụ hạ lưu theo cách có giám sát (còn gọi là tinh chỉnh) [ 16,43]. So với huấn luyện một mô hình từ đầu, mô hình này có thể khai thác kiến thức được học bởi mô hình đã được tiền huấn luyện và do đó đạt được hiệu suất tốt hơn [ 38,44]. Tuy nhiên, mô hình như vậy chủ yếu có hai hạn chế. Thứ nhất, dữ liệu được sử dụng cho tiền huấn luyện và tinh chỉnh có định dạng khác nhau, điều này làm cho kiến thức đã học của mô hình không thể được tận dụng đầy đủ trong quá trình tinh chỉnh [ 63]. Thứ hai, quá trình tinh chỉnh có thể cực kỳ tốn thời gian và tài nguyên, đặc biệt khi nói đến các mô hình ngôn ngữ lớn thường chứa hàng tỷ tham số [8].

Để giải quyết các hạn chế nêu trên, học tập trong ngữ cảnhgần đây được đề xuất và nhanh chóng trở thành một điểm nóng nghiên cứu sau đó [ 8]. Mô hình như vậy biểu thị rằng một vài ví dụ huấn luyện và/hoặc mô tả nhiệm vụ cùng với một truy vấn nhà phát triển cần được trả lời được gửi vào một mô hình ngôn ngữ lớn để tạo ra một phản hồi của truy vấn, mà không có bất kỳ cập nhật tham số nào. Về cơ bản, trong mô hình học tập trong ngữ cảnh, một gợi ý cần được cung cấp

--- TRANG 4 ---
ICSE 2024, Tháng 4 2024, Lisbon, Bồ Đào Nha Mingyang Geng, Shangwen Wang, Dezun Dong, Haotian Wang, Ge Li, Zhi Jin, Xiaoguang Mao, và Xiangke Liao

cho một nhiệm vụ trí tuệ mã, ví dụ, tóm tắt mã. Bằng cách sử dụng các gợi ý, các mô hình ngôn ngữ lớn được chứng minh là hiệu quả trong các nhiệm vụ khác nhau mà mô hình không được huấn luyện rõ ràng, mà không cần dữ liệu cụ thể cho nhiệm vụ [63].

Nói chung, cơ sở lý luận của học tập trong ngữ cảnh là vì các mô hình ngôn ngữ lớn đã được huấn luyện trên các kho dữ liệu có quy mô rất lớn, chúng phải đã hấp thụ nhiều kiến thức miền và do đó được kỳ vọng sẽ tổng quát hóa tốt cho các nhiệm vụ chưa thấy mà không cần tinh chỉnh [ 8]. Nghiên cứu của chúng tôi chia sẻ một động lực tương tự. Cụ thể, xem xét rằng (1) các mô hình ngôn ngữ lớn, ví dụ, Codex, được huấn luyện trên một kho dữ liệu quy mô lớn chứa lượng khổng lồ dữ liệu cặp mã-bình luận từ thế giới thực, và (2) các bình luận thế giới thực thường chứa các loại ý định khác nhau của nhà phát triển, chúng tôi giả định rằng các mô hình ngôn ngữ lớn có khả năng hiểu mã từ các góc độ khác nhau và do đó có tiềm năng tạo sinh các bình luận với các ý định đa dạng khi được cho một đoạn mã. Bằng cách sử dụng học tập trong ngữ cảnh, các tiềm năng như vậy của LLMs có thể được khai thác.

3 THIẾT KẾ NGHIÊN CỨU
3.1 Các Câu hỏi Nghiên cứu
Mục tiêu của nghiên cứu chúng tôi là điều tra hiệu quả của các mô hình ngôn ngữ lớn trong tạo sinh bình luận đa-ý định bằng cách sử dụng mô hình học tập trong ngữ cảnh. Để làm điều này, chúng tôi đề xuất trả lời các câu hỏi nghiên cứu sau.

•RQ1: Hiệu quả của Codex trong tạo sinh bình luận đa-ý định sử dụng học zero-shot, one-shot, và few-shot là gì? Là RQ đầu tiên, chúng tôi nhằm mục đích điều tra tính khả thi của việc giải quyết vấn đề tạo sinh bình luận đa-ý định với học tập trong ngữ cảnh. Cụ thể, chúng tôi không sử dụng bất kỳ thiết kế tùy chỉnh nào và chỉ chọn các minh họa mã một cách ngẫu nhiên. Mục tiêu của chúng tôi là điều tra mức độ hiệu quả của học tập trong ngữ cảnh vani so với phương pháp DOME hiện đại nhất. Kết quả cũng có thể phản ánh mức độ mà số lượng minh họa (tức là zero-shot, one-shot, và few-shot) ảnh hưởng đến hiệu quả.

•RQ2: Liệu hiệu quả có thể được cải thiện bằng các lựa chọn minh họa dựa trên truy xuất? Một số công trình gần đây đã chứng minh rằng chất lượng của các minh họa trong gợi ý có thể ảnh hưởng đáng kể đến hiệu quả của học tập trong ngữ cảnh [45,48,60]. Lấy cảm hứng từ các nghiên cứu này, chúng tôi đề xuất điều tra liệu các phương pháp lựa chọn minh họa tùy chỉnh có thể giúp cải thiện hiệu suất của mô hình hay không. Cụ thể, để trả lời câu hỏi này, chúng tôi thiết kế hai phương pháp dựa trên truy xuất để chọn các ví dụ mã tương tự như mã được chỉ định trong truy vấn nhà phát triển, và đánh giá hiệu quả của chúng.

•RQ3: Liệu hiệu quả có thể được cải thiện bằng các chiến lược sắp xếp lại? Một mô hình ngôn ngữ lớn trải qua một quá trình lấy mẫu để thu được các đầu ra [ 11,49,61,78]. Có nghĩa là, một nhà phát triển có thể thu được các kết quả khác nhau từ mô hình cho đầu vào giống hệt nhau. Trong RQ này, chúng tôi tiếp tục điều tra tính khả thi của việc thúc đẩy hiệu suất của mô hình theo cách hậu xử lý: bằng cách đầu tiên thu được một số kết quả và sau đó sắp xếp lại chúng thông qua một heuristic được định nghĩa trước. Trả lời câu hỏi như vậy có thể cung cấp hướng dẫn cho việc áp dụng phương pháp trong thực tế: nó có thể làm cho chúng ta rõ ràng về mức độ chúng ta có thể thu được kết quả có chất lượng hơn bằng cách lấy mẫu nhiều đầu ra.

3.2 Mẫu Gợi ý cho Tạo sinh Bình luận Đa-ý định
Chính thức, một gợi ý được định nghĩa là 𝑃={𝑥test+CD+NL}, trong đó NL là một mẫu ngôn ngữ tự nhiên, CD={(𝑥𝑖,𝑦𝑖)}𝑛𝑖=1là một tập hợp các minh họa mã được tạo thành bởi chuỗi mã đầu vào (𝑥𝑖)và chuỗi đầu ra mong muốn (𝑦𝑖), và 𝑥testlà một truy vấn nhà phát triển cần được suy luận. Cụ thể, nếu 𝑖=0có nghĩa là không có minh họa mã, cài đặt được gọi là học zero-shot ; nếu𝑖=1có nghĩa là chỉ có một minh họa mã, cài đặt được gọi là học one-shot ; và học few-shot có nghĩa là có một số minh họa mã. Ngoài ra, có một ràng buộc rằng size(P)≤ context-window, có nghĩa là gợi ý phải phù hợp trong giới hạn cửa sổ ngữ cảnh của mô hình ngôn ngữ.1

Hình 1 minh họa một mẫu gợi ý cho nhiệm vụ tạo sinh bình luận đa-ý định. Gợi ý đầu vào chứa hai phần: các minh họa mã CDvà truy vấn 𝑥test. Các hướng dẫn ngôn ngữ tự nhiên được biểu thị bằng các dòng bắt đầu bằng token đặc biệt "#". Trong dòng đầu tiên của gợi ý, chúng tôi đầu tiên nói với mô hình ngôn ngữ lập trình cụ thể mà nó đang làm việc (ví dụ, Java) và sau đó ý định mong muốn của bình luận, như được làm nổi bật bằng màu đỏ, được chỉ định bằng cách tuân theo các định nghĩa được hiển thị trong Bảng 1. Cụ thể, đối với ý định "what", chúng tôi thêm gợi ý "Mô tả chức năng của phương thức"; đối với ý định "why", chúng tôi thêm gợi ý "Giải thích lý do tại sao phương thức được cung cấp hoặc lý do thiết kế của phương thức"; đối với ý định "how-to-use", chúng tôi thêm gợi ý "Mô tả cách sử dụng hoặc thiết lập dự kiến của việc sử dụng phương thức"; đối với ý định "how-it-is-done", chúng tôi thêm gợi ý "Mô tả chi tiết triển khai của phương thức"; đối với ý định "property", chúng tôi thêm gợi ý "Khẳng định các thuộc tính của phương thức bao gồm các điều kiện tiên quyết hoặc điều kiện hậu quyết của phương thức". Trong ví dụ này, gợi ý được minh họa nhằm mục đích tạo sinh một bình luận đáp ứng ý định "what". Dòng đầu tiên sau đó được theo sau bởi một số minh họa mã có thể giúp LLM hiểu hành vi mong đợi và mỗi minh họa chứa một đoạn mã và một bình luận tương ứng trong loại ý định mong muốn. Mỗi minh họa mã được tách bằng một dấu phân cách "###". Cuối cùng, mô hình được yêu cầu xuất ra bình luận mong muốn của mã truy vấn, được hiển thị ở cuối hình.

3.3 Truy xuất Minh họa
Lưu ý rằng các minh họa mã được sử dụng trong RQ1 được chọn ngẫu nhiên từ một kho. Trong khi đó trong RQ2, chúng tôi nhằm mục đích điều tra liệu lựa chọn minh họa tùy chỉnh có thể tăng cường hiệu quả hay không. Do đó, chúng tôi thiết kế hai chiến lược để truy xuất các ví dụ minh họa mã tương tự từ kho mà các bình luận của chúng có ý định thuộc về loại mong muốn. Cơ sở lý luận là một vài minh họa tương tự như mục tiêu có thể giúp mô hình hiểu rõ hơn hành vi mong muốn [ 45,48,60]. Toàn bộ quá trình của mô hình như vậy được hiển thị trong Hình 2: khi được cho một đoạn mã và loại ý định yêu cầu, chúng tôi chọn các ví dụ mã tương tự như mục tiêu và sử dụng mã được truy xuất cùng với các

1Các mô hình ngôn ngữ giới hạn lượng thông tin ngữ cảnh có thể được đưa vào mô hình; cửa sổ ngữ cảnh cho Codex được giới hạn ở 8,000 token

--- TRANG 5 ---
Các Mô hình Ngôn ngữ Lớn là Các Tóm tắt viên Few-Shot:
Tạo sinh Bình luận Đa-ý định thông qua Học tập Trong Ngữ cảnh ICSE 2024, Tháng 4 2024, Lisbon, Bồ Đào Nha

Hình 1: Mẫu gợi ý tóm tắt mã đa-ý định.

Hình 2: Tổng quan về tóm tắt mã dựa trên học tập trong ngữ cảnh của chúng tôi.

bình luận của chúng để xây dựng một gợi ý có mẫu được hiển thị trong Hình 1. Gợi ý được sử dụng để truy vấn mô hình và thu được kết quả. Chúng tôi tiếp theo giới thiệu hai chiến lược truy xuất chi tiết.

•Dựa trên Token: Chiến lược được sử dụng phổ biến nhất để xác định mã tương tự là tập trung vào sự trùng lặp về các token mã [ 23,33,76]. Lấy cảm hứng từ các nghiên cứu này, chiến lược truy xuất đầu tiên của chúng tôi cũng dựa trên thông tin cấp độ token, tức là xếp hạng các đoạn mã từ kho mã dựa trên độ tương tự token của chúng với mã đích. Cụ thể, chúng tôi đầu tiên tiền xử lý đoạn mã đích và các đoạn mã trong kho mã được truy xuất bằng cách loại bỏ các từ khóa được định nghĩa trong ngôn ngữ lập trình (tức là Java trong nghiên cứu của chúng tôi). Trực giác đằng sau là các token được sử dụng thường xuyên như vậy có thể mang lại tác dụng phụ cho việc tính toán độ tương tự vì một số lượng lớn các đoạn mã sẽ chứa chúng, lấy cảm hứng từ nghiên cứu gần đây [ 17]. Sau đó, chúng tôi tiếp tục phân tách các định danh thành các sub-token để tận dụng đầy đủ thông tin ngữ nghĩa ẩn trong tên định danh [ 53]. Cụ thể, quá trình như vậy được thực hiện bằng cách sử dụng quy ước đặt tên camel case và dấu gạch dưới của ngôn ngữ Java. Cuối cùng, chúng tôi chuyển đổi tất cả các sub-token thành chữ thường. Đối với độ tương tự dựa trên token giữa một đoạn mã ứng viên và mã đích (𝑠𝑡𝑜𝑘𝑒𝑛 ), chúng tôi khai thác Hệ số Jaccard [ 50] cho việc tính toán, được định nghĩa như sau: 𝑠token =|tokens target∩tokens candidate|
|tokens target∪tokens candidate|
trong đó 𝑡𝑜𝑘𝑒𝑛𝑠 𝑡𝑎𝑟𝑔𝑒𝑡 biểu thị danh sách sub-token của mã đích và𝑡𝑜𝑘𝑒𝑛𝑠 𝑐𝑎𝑛𝑑𝑖𝑑𝑎𝑡𝑒 biểu thị danh sách sub-token của mã ứng viên. Giá trị của 𝑠𝑡𝑜𝑘𝑒𝑛 dao động từ 0 đến 1. Giá trị lớn hơn của 𝑠𝑡𝑜𝑘𝑒𝑛 cho thấy độ tương tự cao hơn giữa mã đích và mã ứng viên từ tập hợp được truy xuất.

•Dựa trên Ngữ nghĩa: Các nghiên cứu gần đây trong lĩnh vực phát hiện clone cũng đã tiết lộ rằng ngoài độ tương tự token mã cấp độ từ vựng, việc hiểu ngữ nghĩa mã cũng quan trọng để tìm mã tương tự [ 64,74]. Do đó, chiến lược thứ hai của chúng tôi dựa vào

--- TRANG 6 ---
ICSE 2024, Tháng 4 2024, Lisbon, Bồ Đào Nha Mingyang Geng, Shangwen Wang, Dezun Dong, Haotian Wang, Ge Li, Zhi Jin, Xiaoguang Mao, và Xiangke Liao

ngữ nghĩa mã để truy xuất các đoạn mã tương tự. Cụ thể, chúng tôi khai thác mô hình biến đổi câu đã được tiền huấn luyện [57], đã được chứng minh là có khả năng nắm bắt chính xác ngữ nghĩa của các đoạn mã bởi một nghiên cứu gần đây [ 48], để mã hóa các đoạn mã thành các vector chứa thông tin ngữ nghĩa tương ứng.2Độ tương tự cosine được khai thác để truy xuất các đoạn mã ứng viên tương tự có vector gần với vector của đoạn mã đích trong không gian vector.

3.4 Chiến lược Sắp xếp lại
Để sắp xếp lại các bình luận được tạo sinh, trực giác của chúng tôi là các đoạn mã tương tự thường chia sẻ các bình luận tương tự, đây là một thông thường trong tài liệu [ 37,69–71]. Do đó, chiến lược của chúng tôi là sắp xếp lại các bình luận được tạo sinh dựa trên độ tương tự của chúng với bình luận của đoạn mã trong kho truy xuất tương tự như mã đích. Cụ thể, chúng tôi sử dụng bình luận của đoạn mã tương tự nhất với mã đích làm tham chiếu và cũng tính toán độ tương tự bình luận từ hai góc độ, tức là dựa trên token và dựa trên ngữ nghĩa. Đối với chiến lược dựa trên token, chúng tôi tập trung vào thông tin cấp độ token, vì các token trong bình luận thường là các từ ngôn ngữ tự nhiên có ngữ nghĩa rõ ràng. Đối với dựa trên ngữ nghĩa, chúng tôi khai thác lại mô hình biến đổi câu đã được tiền huấn luyện [ 57], nhúng toàn bộ bình luận vào một vector ngữ nghĩa, và tính toán độ tương tự cosine.

3.5 Bộ dữ liệu
Trong nghiên cứu này, chúng tôi sử dụng các bộ dữ liệu tạo sinh bình luận đa-ý định được phát hành bởi nghiên cứu trước đây [ 47] làm bộ dữ liệu đánh giá của chúng tôi. Cụ thể, chúng tôi sử dụng hai bộ dữ liệu của ngôn ngữ lập trình Java, tức là các bộ dữ liệu Funcom [ 36] và TLC [ 30], cả hai đều là các bộ dữ liệu được sử dụng rộng rãi nhất cho nhiệm vụ tạo sinh bình luận mã [3,13,20,35,77]. Funcom chứa 2.1M cặp mã-bình luận từ 29K dự án Java, được thu thập bởi Lopes et al. [1] và được làm sạch thêm bởi LeClair et al. [36]. TLC chứa 87,136 cặp mã-bình luận được thu thập từ hơn 9K dự án Java được tạo từ 2015 đến 2016 với ít nhất 20 sao. Các loại ý định của mỗi bình luận trong hai bộ dữ liệu này được gán nhãn bởi Mu et al. [47]: họ đầu tiên mời năm chuyên gia miền để gán nhãn thủ công ý định của 8K đoạn mã và sau đó tinh chỉnh mô hình CodeBERT [ 19] trên dữ liệu được gán nhãn, được phục vụ như một bộ phân loại. Kết quả cho thấy mô hình được tinh chỉnh có thể đạt được điểm F1 khoảng 90%, đây là một giá trị tương đối cao. Cuối cùng, các tác giả áp dụng mô hình được tinh chỉnh để dự đoán loại ý định của mỗi bình luận trong các bộ dữ liệu và sử dụng kết quả dự đoán làm nhãn sự thật cơ bản. Vì việc gán nhãn thủ công các bộ dữ liệu quy mô lớn như vậy sẽ không khả thi, chúng tôi tái sử dụng kết quả được cung cấp của họ trong nghiên cứu của chúng tôi. Ngoài ra, phân vùng huấn luyện/xác thực/kiểm tra của các bộ dữ liệu được cố định và thống kê của hai bộ dữ liệu này được hiển thị trong Bảng 2. Lưu ý rằng trong bảng, chúng tôi không hiển thị thống kê của các tập xác thực của hai bộ dữ liệu. Điều này là do phương pháp của chúng tôi không cần huấn luyện một mô hình. Ngược lại, chúng tôi chỉ truy xuất các ví dụ mã từ các tập huấn luyện (bằng cách tuân theo Mu et al. [47]) với hoặc không có tùy chỉnh

2Chúng tôi sử dụng mô hình st-codesearch-distilroberta-base được phát hành tại https://huggingf ace.co/flax-sentence-embeddings/st-codesearch-distilroberta-base, được tiền huấn luyện trên bộ dữ liệu CodeSearchNet [31]

Bảng 2: Thống kê của các bộ dữ liệu đánh giá của chúng tôi.
Bộ dữ liệuFuncom TLC
Huấn luyện Kiểm tra Huấn luyện Kiểm tra
What 685,992 44,330 28,991 2,724
Why 152,026 8,402 5,935 381
How-to-use 24,648 1,233 838 48
How-it-is-done 146,571 6,466 11,478 687
Property 166,459 8,326 5,016 396
Tổng 1,175,696 68,757 52,258 4,236

chiến lược và đánh giá hiệu quả trên các tập kiểm tra. Do đó, các tập xác thực không được sử dụng trong nghiên cứu này. Tuân theo các nghiên cứu hiện tại [ 12,47], chúng tôi cũng loại trừ các bình luận từ loại ý định others trong đánh giá của chúng tôi vì các bình luận này được coi là không xác định hoặc mơ hồ.

3.6 Các Chỉ số Đánh giá
Để đánh giá hiệu suất của mô hình Codex trong tóm tắt mã, chúng tôi khai thác các chỉ số phổ biến bao gồm BLEU [ 51], ROUGE-L [ 42] và METEOR [ 6]. BLEU (Bilingual Evaluation Understudy) [ 51] là một chỉ số đánh giá được sử dụng phổ biến trong các nghiên cứu tạo sinh bình luận mã [ 28,32,47,62], đo lường độ tương tự giữa một câu với một tập hợp các câu tham chiếu bằng cách sử dụng điểm chính xác n-gram thành phần. ROUGE biểu thị Recall-oriented Understudy for Gisting Evaluation [ 42]. Nó tính toán số lượng của một số đơn vị trùng lặp như n-gram, cặp từ, và chuỗi. ROUGE có một số biến thể khác nhau mà chúng tôi xem xét biến thể phổ biến nhất ROUGE-L [ 7,41,47], được tính toán dựa trên chuỗi con chung dài nhất (LCS). METEOR [6], biểu thị Metric for Evaluation of Translation with Explicit ORdering, là một chỉ số được sử dụng rộng rãi khác để đánh giá chất lượng của các tóm tắt mã được tạo sinh [ 29,47,65]. METEOR đánh giá tóm tắt được tạo sinh bằng cách căn chỉnh nó với tóm tắt tham chiếu và tính toán điểm tương tự dựa trên khớp unigram.

3.7 Cài đặt Thí nghiệm
Trong các thí nghiệm của chúng tôi, ngoài các cài đặt zero-shot và one-shot, chúng tôi chọn sử dụng năm và mười minh họa mã cho cài đặt few-shot. Chúng tôi không thể sử dụng quá nhiều minh họa mã vì độ dài đầu vào bị hạn chế bởi giới hạn cửa sổ ngữ cảnh. Do đó, chúng tôi quyết định cung cấp cho mô hình tối đa mười ví dụ. Đường cơ sở để so sánh là DOME [ 47] vì đây là phương pháp duy nhất có thể giải quyết nhiệm vụ tạo sinh bình luận đa-ý định. Để chạy các thí nghiệm của chúng tôi, chúng tôi sử dụng mô hình Codex mới nhất code-davinci-002 .3Chúng tôi đặt nhiệt độ là giá trị mặc định, 0.5, để nhận được một câu trả lời được xác định rõ từ Codex. Chúng tôi chạy tất cả các thí nghiệm trên máy Hygon C86 7385 32-core CPU 2.50GHz với RAM 2TB. Hệ điều hành chạy là Ubuntu 18.04.

Quan trọng là lưu ý rằng cả kết quả của RQ1 và RQ2 đều chịu ảnh hưởng của tính ngẫu nhiên. RQ2 bị ảnh hưởng bởi quá trình lấy mẫu, trong khi RQ1 còn bị ảnh hưởng thêm bởi việc lựa chọn các minh họa. Để giải quyết vấn đề này, chúng tôi lặp lại mỗi cài đặt một trăm lần và báo cáo các giá trị trung bình trong bài báo. Do đó, kết quả của RQ1 và RQ2 có thể được coi là hiệu quả trung bình kỳ vọng của Codex dưới các cài đặt cụ thể. Ngược lại, RQ3 điều tra

3https://platform.openai.com/docs/models/codex

--- TRANG 7 ---
Các Mô hình Ngôn ngữ Lớn là Các Tóm tắt viên Few-Shot:
Tạo sinh Bình luận Đa-ý định thông qua Học tập Trong Ngữ cảnh ICSE 2024, Tháng 4 2024, Lisbon, Bồ Đào Nha

Bảng 3: Kết quả của Codex trong tạo sinh bình luận đa-ý định sử dụng học zero-shot, one-shot, và few-shot (tính bằng %).
Ý định PhươngphápFuncom TLC
BLEU ROUGE-L METEOR BLEU ROUGE-L METEOR
WhatDOME 33.3 41.7 20.5 25.4 39.6 18.2
Codex-0-shot 19.3 23.5 10.8 17.8 16.4 15.5
Codex-1-shot 23.8 27.6 21.5 22.5 20.6 17.4
Codex-5-shot 27.3 41.8 24.9 25.7 37.4 19.9
Codex-10-shot 34.5 58.6 26.8 32.4 45.6 23.1
WhyDOME 33.0 42.3 20.5 21.9 35.3 15.7
Codex-0-shot 21.7 20.3 11.4 19.6 17.8 9.6
Codex-1-shot 22.9 28.8 12.9 20.8 23.2 11.9
Codex-5-shot 27.5 45.8 16.9 24.1 40.6 13.5
Codex-10-shot 34.8 76.1 22.6 26.2 64.6 15.8
How-to-useDOME 31.6 39.3 19.3 17.1 26.1 12.3
Codex-0-shot 22.3 11.1 16.8 21.2 10.9 12.2
Codex-1-shot 23.1 18.9 17.5 21.8 16.6 14.4
Codex-5-shot 27.9 48.6 19.8 24.4 40.5 15.7
Codex-10-shot 33.3 84.6 22.3 26.9 76.4 17.3
How-it-is-doneDOME 26.9 39.5 17.6 20.4 36.6 14.7
Codex-0-shot 18.9 37.9 9.8 16.8 32.1 9.6
Codex-1-shot 21.0 39.6 13.5 19.1 36.4 12.1
Codex-5-shot 24.8 49.2 16.2 21.1 52.7 12.8
Codex-10-shot 28.4 79.3 19.5 21.9 66.7 14.9
PropertyDOME 34.1 49.4 24.3 26.0 45.7 21.2
Codex-0-shot 23.7 33.3 13.2 18.8 28.8 9.5
Codex-1-shot 24.7 38.4 15.8 21.3 33.6 12.4
Codex-5-shot 29.7 79.2 25.2 26.5 78.4 22.3
Codex-10-shot 36.2 81.9 29.4 28.7 80.3 24.7
Trung bìnhDOME 31.8 42.5 20.5 22.2 36.7 16.5
Codex-0-shot 21.2 25.2 12.4 18.8 21.2 11.3
Codex-1-shot 23.1 30.7 16.2 21.1 26.1 13.6
Codex-5-shot 27.4 52.9 20.6 24.4 49.9 16.8
Codex-10-shot 33.4 76.1 24.1 27.2 66.7 19.2

liệu kết quả tốt hơn có thể đạt được bằng cách tận dụng tính đa dạng của kết quả lấy mẫu hay không. Để hoàn thành điều này, chúng tôi lặp lại các thí nghiệm một trăm lần và áp dụng chiến lược sắp xếp lại của chúng tôi dựa trên các kết quả thu được. Kết quả của RQ này do đó có thể được coi là hiệu quả tối ưu có thể đạt được của Codex.

4 KẾT QUẢ NGHIÊN CỨU
4.1 RQ1: Hiệu quả của Học tập Trong Ngữ cảnh Vani
Bảng 3 liệt kê kết quả của DOME và Codex trên nhiệm vụ tạo sinh bình luận đa-ý định. Đối với Codex, kết quả của việc sử dụng 0, 1, 5, và 10 ví dụ minh họa được minh họa tương ứng. Nói chung, chúng tôi quan sát thấy rằng hiệu quả của học tập trong ngữ cảnh sẽ tốt hơn khi số lượng minh họa mã tăng lên. Ví dụ, đối với ý định "what", giá trị BLEU của Codex là 19.3% khi không sử dụng minh họa mã nào trong khi giá trị này tăng lên 34.5% khi sử dụng mười ví dụ, trên bộ dữ liệu Funcom. Điều này nằm trong kỳ vọng của chúng tôi vì nhiều ví dụ hơn sẽ cung cấp nhiều hướng dẫn hơn cho mô hình về nhiệm vụ đang diễn ra. Khi so sánh với DOME hiện đại nhất, chúng tôi lưu ý rằng hiệu quả của học zero-shot và one-shot thấp hơn so với DOME. Ví dụ, các giá trị BLEU trung bình của học zero-shot trên hai bộ dữ liệu lần lượt là 21.2% và 18.8%, trong khi các giá trị tương ứng của DOME là 31.8% và 22.2%. Điều này cho thấy rằng không có đủ minh họa mã, tiềm năng của LLMs trong nhiệm vụ tạo sinh bình luận đa-ý định có thể không được tận dụng đầy đủ.

Phát hiện-1. Học zero-shot và one-shot có thể không khai thác đầy đủ tiềm năng của LLMs và hiệu quả của chúng là dưới tối ưu so với phương pháp DOME.

Khi số lượng minh họa mã lên đến năm, chúng tôi quan sát thấy hiệu quả của Codex có khả năng cạnh tranh với DOME: các giá trị về các chỉ số ROUGE-L và METEOR cao hơn so với DOME trong khi các giá trị BLEU thấp hơn một chút. Một lý do tiềm ẩn là chỉ số BLEU tập trung quá mức vào việc đo lường sự trùng lặp n-gram. Cụ thể, nó yêu cầu tính nhất quán nghiêm ngặt (tức là các n-gram phải giống hệt nhau), điều này khó khăn cho các mô hình chưa được tinh chỉnh để đạt được sự căn chỉnh hoàn hảo với các tham chiếu. Ngược lại, các chỉ số ROUGE-L và METEOR giải phóng yêu cầu này bằng cách tập trung vào chuỗi con chung dài nhất và xem xét các tính năng khác như thứ tự từ ngoài n-gram, tương ứng. Tuy nhiên, khi số lượng minh họa mã đạt mười, Codex vượt trội hơn DOME một cách nhất quán về tất cả ba chỉ số và hai bộ dữ liệu. Cụ thể, các giá trị trung bình của Codex về ba chỉ số lần lượt là 33.4%/76.1%/24.1% và 27.2%/66.7%/19.2% trên bộ dữ liệu Funcom và TLC. Hiệu suất như vậy vượt trội hơn DOME hiện đại nhất lần lượt 5.0%/79.1%/17.6% và 22.5%/81.8%/16.4% trên hai bộ dữ liệu. Chúng tôi cũng phát hiện rằng hiệu suất của các phương pháp khác nhau thay đổi qua các loại ý định: nói chung, tất cả các phương pháp có hiệu suất tương đối thấp trên loại "how-it-is-done". Phát hiện như vậy phù hợp với kết quả từ nghiên cứu hiện tại [12].

Phát hiện-2. Khi LLM được gợi ý đầy đủ, hiệu suất của nó sẽ vượt qua phương pháp học có giám sát hiện đại nhất. Ví dụ, khi số lượng minh họa là mười, các giá trị ROUGE-L trung bình của Codex trên hai bộ dữ liệu lần lượt là 76.1%/66.7%, vượt trội hơn DOME 79.1%/81.8%.

4.2 RQ2: Hiệu quả của Lựa chọn Minh họa
Kết quả của các chiến lược lựa chọn minh họa dựa trên truy xuất khác nhau được hiển thị trong Bảng 4. Cài đặt zero-shot được loại trừ khỏi bảng này vì nó không sử dụng bất kỳ minh họa mã nào. Chúng tôi quan sát thấy rằng việc lựa chọn minh họa dựa trên cả độ tương tự token và ngữ nghĩa đều cải thiện đáng kể hiệu suất so với lựa chọn ngẫu nhiên vani. Ví dụ, khi số lượng ví dụ được chọn là mười, các giá trị BLEU của Codex trên bộ dữ liệu Funcom và TLC lần lượt là 33.4% và 27.2%; trong khi các giá trị này tăng lên 64.5% (65.9%) và 60.7% (62.8%) khi các ví dụ được chọn dựa trên độ tương tự token (ngữ nghĩa), với các cải thiện tương đối lần lượt là 93% (97%) và 123% (131%). Chúng tôi cũng lưu ý rằng các cải thiện hiệu suất như vậy là phổ quát (tức là có thể quan sát được trên mỗi bộ dữ liệu bất kể sử dụng bao nhiêu ví dụ mã). Hơn nữa, chúng tôi lưu ý rằng nếu các ví dụ tương tự được cung cấp, hiệu suất của học 1-shot thậm chí còn tốt hơn so với học vani 10-shot (ví dụ, các giá trị BLEU trên bộ dữ liệu Funcom lần lượt là 39.2% và 33.4%). Kết quả như vậy cho thấy tầm quan trọng của chất lượng minh họa trong học tập trong ngữ cảnh: hiệu suất của mô hình có thể được cải thiện nếu gợi ý cho trước tương tự như nhiệm vụ đang diễn ra.

Phân tích trường hợp. Để phân tích định tính, chúng tôi trình bày một trường hợp để cho thấy cách lựa chọn dựa trên ngữ nghĩa giúp sửa chữa bình luận được tạo sinh của Codex, được hiển thị trong Hình 3. Cho mã kiểm tra có bình luận oracle là "Plays previous video in playlist", Codex với lựa chọn ngẫu nhiên tạo sinh một bình luận không liên quan về ngữ nghĩa "Plays the next song or video". Bình luận này không phù hợp vì tính từ "next" là sai (oracle là "previous") và

--- TRANG 8 ---
ICSE 2024, Tháng 4 2024, Lisbon, Bồ Đào Nha Mingyang Geng, Shangwen Wang, Dezun Dong, Haotian Wang, Ge Li, Zhi Jin, Xiaoguang Mao, và Xiangke Liao

Bảng 4: Kết quả của các chiến lược lựa chọn minh họa dựa trên truy xuất khác nhau (tính bằng %).
Ý định PhươngphápFuncom TLC
BLEU ROUGE-L METEOR BLEU ROUGE-L METEOR
WhatCodex-1-shot 23.8 27.6 21.5 22.5 20.6 17.4
Codex-1-shot ( 𝑆𝑒𝑙𝑒𝑐𝑡𝑖𝑜𝑛 𝑡𝑜𝑘𝑒𝑛 ) 39.5 84.6 35.0 35.6 79.9 31.4
Codex-1-shot ( 𝑆𝑒𝑙𝑒𝑐𝑡𝑖𝑜𝑛 𝑠𝑒𝑚𝑎𝑛𝑡𝑖𝑐 ) 36.7 74.5 36.1 33.9 71.6 32.8
Codex-5-shot 27.3 41.8 24.9 25.7 37.4 19.9
Codex-5-shot ( 𝑆𝑒𝑙𝑒𝑐𝑡𝑖𝑜𝑛 𝑡𝑜𝑘𝑒𝑛 ) 41.0 82.3 41.3 38.6 76.8 37.7
Codex-5-shot ( 𝑆𝑒𝑙𝑒𝑐𝑡𝑖𝑜𝑛 𝑠𝑒𝑚𝑎𝑛𝑡𝑖𝑐 )41.1 82.9 39.3 39.1 78.9 38.3
Codex-10-shot 34.5 58.6 26.8 32.4 45.6 23.1
Codex-10-shot ( 𝑆𝑒𝑙𝑒𝑐𝑡𝑖𝑜𝑛 𝑡𝑜𝑘𝑒𝑛 ) 50.5 90.0 48.4 44.8 82.6 43.9
Codex-10-shot ( 𝑆𝑒𝑙𝑒𝑐𝑡𝑖𝑜𝑛 𝑠𝑒𝑚𝑎𝑛𝑡𝑖𝑐 )40.4 84.1 38.7 40.2 79.5 38.2
WhyCodex-1-shot 22.9 28.8 12.9 20.8 23.2 11.9
Codex-1-shot ( 𝑆𝑒𝑙𝑒𝑐𝑡𝑖𝑜𝑛 𝑡𝑜𝑘𝑒𝑛 ) 32.8 72.8 27.7 30.7 68.4 25.5
Codex-1-shot ( 𝑆𝑒𝑙𝑒𝑐𝑡𝑖𝑜𝑛 𝑠𝑒𝑚𝑎𝑛𝑡𝑖𝑐 )33.2 70.9 28.0 31.6 66.8 26.2
Codex-5-shot 24.2 45.5 14.7 24.1 40.6 13.5
Codex-5-shot ( 𝑆𝑒𝑙𝑒𝑐𝑡𝑖𝑜𝑛 𝑡𝑜𝑘𝑒𝑛 ) 37.8 85.0 32.9 34.5 78.7 29.8
Codex-5-shot ( 𝑆𝑒𝑙𝑒𝑐𝑡𝑖𝑜𝑛 𝑠𝑒𝑚𝑎𝑛𝑡𝑖𝑐 ) 37.7 82.1 32.5 35.1 79.3 30.2
Codex-10-shot 34.8 76.1 22.6 26.2 64.6 15.8
Codex-10-shot ( 𝑆𝑒𝑙𝑒𝑐𝑡𝑖𝑜𝑛 𝑡𝑜𝑘𝑒𝑛 ) 74.9 90.0 75.1 72.1 81.4 68.9
Codex-10-shot ( 𝑆𝑒𝑙𝑒𝑐𝑡𝑖𝑜𝑛 𝑠𝑒𝑚𝑎𝑛𝑡𝑖𝑐 )75.0 89.4 74.7 72.4 81.9 73.0
How-to-useCodex-1-shot 23.1 18.9 17.5 21.8 16.6 14.4
Codex-1-shot ( 𝑆𝑒𝑙𝑒𝑐𝑡𝑖𝑜𝑛 𝑡𝑜𝑘𝑒𝑛 ) 56.3 88.3 53.7 52.2 81.6 42.8
Codex-1-shot ( 𝑆𝑒𝑙𝑒𝑐𝑡𝑖𝑜𝑛 𝑠𝑒𝑚𝑎𝑛𝑡𝑖𝑐 ) 52.4 74.4 47.1 46.8 71.5 42.3
Codex-5-shot 24.2 48.1 18.9 24.4 40.5 15.7
Codex-5-shot ( 𝑆𝑒𝑙𝑒𝑐𝑡𝑖𝑜𝑛 𝑡𝑜𝑘𝑒𝑛 ) 48.0 86.4 45.9 43.6 80.3 37.2
Codex-5-shot ( 𝑆𝑒𝑙𝑒𝑐𝑡𝑖𝑜𝑛 𝑠𝑒𝑚𝑎𝑛𝑡𝑖𝑐 )68.7 86.2 63.6 66.4 84.5 58.4
Codex-10-shot 33.3 84.6 22.3 26.9 76.4 17.3
Codex-10-shot ( 𝑆𝑒𝑙𝑒𝑐𝑡𝑖𝑜𝑛 𝑡𝑜𝑘𝑒𝑛 ) 69.6 91.2 70.7 66.4 84.3 68.2
Codex-10-shot ( 𝑆𝑒𝑙𝑒𝑐𝑡𝑖𝑜𝑛 𝑠𝑒𝑚𝑎𝑛𝑡𝑖𝑐 )76.3 91.2 77.4 71.6 85.4 73.6
How-it-is-doneCodex-1-shot 21.0 39.6 13.5 19.1 36.4 12.1
Codex-1-shot ( 𝑆𝑒𝑙𝑒𝑐𝑡𝑖𝑜𝑛 𝑡𝑜𝑘𝑒𝑛 ) 31.9 72.9 25.8 28.6 69.4 24.7
Codex-1-shot ( 𝑆𝑒𝑙𝑒𝑐𝑡𝑖𝑜𝑛 𝑠𝑒𝑚𝑎𝑛𝑡𝑖𝑐 ) 30.5 69.6 27.6 28.2 68.7 25.9
Codex-5-shot 22.5 48.9 13.7 21.1 52.7 12.8
Codex-5-shot ( 𝑆𝑒𝑙𝑒𝑐𝑡𝑖𝑜𝑛 𝑡𝑜𝑘𝑒𝑛 ) 33.7 85.7 30.8 29.7 78.4 26.8
Codex-5-shot ( 𝑆𝑒𝑙𝑒𝑐𝑡𝑖𝑜𝑛 𝑠𝑒𝑚𝑎𝑛𝑡𝑖𝑐 ) 32.9 80.0 27.5 28.3 73.9 25.1
Codex-10-shot 28.4 79.3 19.5 21.9 66.7 14.9
Codex-10-shot ( 𝑆𝑒𝑙𝑒𝑐𝑡𝑖𝑜𝑛 𝑡𝑜𝑘𝑒𝑛 ) 47.9 84.6 49.6 45.2 80.8 47.7
Codex-10-shot ( 𝑆𝑒𝑙𝑒𝑐𝑡𝑖𝑜𝑛 𝑠𝑒𝑚𝑎𝑛𝑡𝑖𝑐 )51.6 86.4 50.8 48.9 82.9 47.9
PropertyCodex-1-shot 24.7 38.4 15.8 21.3 33.6 12.4
Codex-1-shot ( 𝑆𝑒𝑙𝑒𝑐𝑡𝑖𝑜𝑛 𝑡𝑜𝑘𝑒𝑛 ) 35.7 67.7 33.1 33.2 64.9 30.8
Codex-1-shot ( 𝑆𝑒𝑙𝑒𝑐𝑡𝑖𝑜𝑛 𝑠𝑒𝑚𝑎𝑛𝑡𝑖𝑐 )36.4 80.0 35.9 34.9 62.8 32.4
Codex-5-shot 29.7 79.2 25.2 26.5 78.4 22.3
Codex-5-shot ( 𝑆𝑒𝑙𝑒𝑐𝑡𝑖𝑜𝑛 𝑡𝑜𝑘𝑒𝑛 ) 45.1 89.2 43.2 41.5 85.4 40.6
Codex-5-shot ( 𝑆𝑒𝑙𝑒𝑐𝑡𝑖𝑜𝑛 𝑠𝑒𝑚𝑎𝑛𝑡𝑖𝑐 ) 43.9 82.7 40.3 39.6 82.1 38.1
Codex-10-shot 36.2 81.9 29.4 28.7 80.3 24.7
Codex-10-shot ( 𝑆𝑒𝑙𝑒𝑐𝑡𝑖𝑜𝑛 𝑡𝑜𝑘𝑒𝑛 ) 79.6 84.2 75.7 74.8 83.9 68.9
Codex-10-shot ( 𝑆𝑒𝑙𝑒𝑐𝑡𝑖𝑜𝑛 𝑠𝑒𝑚𝑎𝑛𝑡𝑖𝑐 )86.3 95.8 87.4 81.0 86.4 80.8
Trung bìnhCodex-1-shot 23.1 30.7 16.2 21.1 26.1 13.6
Codex-1-shot ( 𝑆𝑒𝑙𝑒𝑐𝑡𝑖𝑜𝑛 𝑡𝑜𝑘𝑒𝑛 ) 39.2 77.3 35.1 36.1 72.8 31.0
Codex-1-shot ( 𝑆𝑒𝑙𝑒𝑐𝑡𝑖𝑜𝑛 𝑠𝑒𝑚𝑎𝑛𝑡𝑖𝑐 ) 37.8 73.9 35.0 35.1 68.3 31.9
Codex-5-shot 27.4 52.9 20.6 24.4 49.9 16.8
Codex-5-shot ( 𝑆𝑒𝑙𝑒𝑐𝑡𝑖𝑜𝑛 𝑡𝑜𝑘𝑒𝑛 ) 41.1 85.7 38.8 37.6 79.9 34.4
Codex-5-shot ( 𝑆𝑒𝑙𝑒𝑐𝑡𝑖𝑜𝑛 𝑠𝑒𝑚𝑎𝑛𝑡𝑖𝑐 )44.9 82.8 40.6 41.7 79.7 38.0
Codex-10-shot 33.4 76.1 24.1 27.2 66.7 19.2
Codex-10-shot ( 𝑆𝑒𝑙𝑒𝑐𝑡𝑖𝑜𝑛 𝑡𝑜𝑘𝑒𝑛 ) 64.5 88.0 63.9 60.7 82.6 59.5
Codex-10-shot ( 𝑆𝑒𝑙𝑒𝑐𝑡𝑖𝑜𝑛 𝑠𝑒𝑚𝑎𝑛𝑡𝑖𝑐 )65.9 89.4 65.8 62.8 83.2 62.7

sẽ do đó gây hiểu lầm cho người bảo trị tiềm năng của mã. May mắn thay, sau khi sử dụng chiến lược lựa chọn minh họa dựa trên ngữ nghĩa, Codex tạo sinh một bình luận giống hệt về ngữ nghĩa với oracle, tức là "Plays the previous video in your playlist". Điểm BLEU đạt được đạt 73.1%, đây là một hiệu suất tương đối cao. Bằng cách điều tra mã tương tự nhất về ngữ nghĩa trong kho (được liệt kê ở cuối hình), chúng tôi phát hiện rằng một lý do tiềm ẩn cho thành công của Codex là ví dụ mã cho thấy nó tính từ có thể đến từ tên phương thức. Cụ thể, bình luận cho mã tương tự về ngữ nghĩa là "Play the first item" và "first" là một token từ tên phương thức. Với ví dụ này trong tâm trí, Codex tạo sinh tính từ đúng "previous", cũng có thể được trích xuất từ tên phương thức.

Phát hiện-3. Cả hai chiến lược lựa chọn minh họa dựa trên token và dựa trên ngữ nghĩa đều có thể cải thiện hiệu quả của Codex ở mức độ lớn.Khi so sánh giữa hai chiến lược lựa chọn, chúng tôi phát hiện rằng không có chiến lược nào có thể vượt trội nhất quán so với chiến lược khác trong tất cả các cài đặt. Ví dụ, khi sử dụng học one-shot, hiệu suất của lựa chọn dựa trên token tốt hơn so với lựa chọn dựa trên ngữ nghĩa trung bình; và ngược lại khi sử dụng học few-shot (tức là số lượng ví dụ là năm hoặc mười). Hơn nữa, ngay cả khi lựa chọn dựa trên ngữ nghĩa nói chung có hiệu suất tốt hơn khi số lượng ví dụ là mười, nó cũng có thể bị vượt qua bởi lựa chọn dựa trên token trong một số cài đặt nhất định. Ví dụ, trên ý định what, các giá trị BLEU của lựa chọn dựa trên token lần lượt là 50.5% và 44.8% trên hai bộ dữ liệu, vượt qua những giá trị của lựa chọn dựa trên ngữ nghĩa, lần lượt là 40.4% và 40.2%.

Phát hiện-4. Không có chiến lược lựa chọn minh họa nào có thể vượt trội nhất quán so với lựa chọn thay thế của nó. Hiệu quả phụ thuộc vào các cài đặt chi tiết (ví dụ, số lượng ví dụ và ý định).

--- TRANG 9 ---
Các Mô hình Ngôn ngữ Lớn là Các Tóm tắt viên Few-Shot:
Tạo sinh Bình luận Đa-ý định thông qua Học tập Trong Ngữ cảnh ICSE 2024, Tháng 4 2024, Lisbon, Bồ Đào Nha

Bảng 5: Kết quả của các chiến lược sắp xếp lại khác nhau (tính bằng %).
Ý định PhươngphápFuncom TLC
BLEU ROUGE-L METEOR BLEU ROUGE-L METEOR
whatCodex-1-shot 23.8 27.6 21.5 22.5 20.6 17.4
Codex-1-shot ( 𝑅𝑒𝑟𝑎𝑛𝑘 𝑡𝑜𝑘𝑒𝑛 ) 32.2 76.1 33.3 28.9 72.7 29.3
Codex-1-shot ( 𝑅𝑒𝑟𝑎𝑛𝑘 𝑠𝑒𝑚𝑎𝑛𝑡𝑖𝑐 ) 29.7 76.5 26.7 27.1 71.9 24.8
Codex-1-shot ( 𝑆𝑒𝑙𝑒𝑐𝑡𝑖𝑜𝑛 𝑡𝑜𝑘𝑒𝑛 ) 39.5 84.6 35.0 35.6 79.9 31.4
Codex-1-shot ( 𝑆𝑒𝑙𝑒𝑐𝑡𝑖𝑜𝑛 𝑡𝑜𝑘𝑒𝑛+𝑅𝑒𝑟𝑎𝑛𝑘 𝑡𝑜𝑘𝑒𝑛 ) 44.4 84.9 43.4 41.8 77.6 38.5
Codex-1-shot ( 𝑆𝑒𝑙𝑒𝑐𝑡𝑖𝑜𝑛 𝑡𝑜𝑘𝑒𝑛+𝑅𝑒𝑟𝑎𝑛𝑘 𝑠𝑒𝑚𝑎𝑛𝑡𝑖𝑐 ) 45.8 85.2 44.9 42.6 75.8 40.8
Codex-10-shot 34.5 58.6 26.8 32.4 45.6 23.1
Codex-10-shot ( 𝑅𝑒𝑟𝑎𝑛𝑘 𝑡𝑜𝑘𝑒𝑛 ) 36.9 84.5 29.3 34.8 76.9 26.6
Codex-10-shot ( 𝑅𝑒𝑟𝑎𝑛𝑘 𝑠𝑒𝑚𝑎𝑛𝑡𝑖𝑐 ) 39.7 85.6 36.5 37.1 81.0 31.8
Codex-10-shot ( 𝑆𝑒𝑙𝑒𝑐𝑡𝑖𝑜𝑛 𝑠𝑒𝑚𝑎𝑛𝑡𝑖𝑐 ) 40.4 84.1 38.7 40.2 79.5 38.2
Codex-10-shot ( 𝑆𝑒𝑙𝑒𝑐𝑡𝑖𝑜𝑛 𝑠𝑒𝑚𝑎𝑛𝑡𝑖𝑐+𝑅𝑒𝑟𝑎𝑛𝑘 𝑡𝑜𝑘𝑒𝑛 ) 58.6 87.2 61.3 56.3 82.9 58.4
Codex-10-shot ( 𝑆𝑒𝑙𝑒𝑐𝑡𝑖𝑜𝑛 𝑠𝑒𝑚𝑎𝑛𝑡𝑖𝑐+𝑅𝑒𝑟𝑎𝑛𝑘 𝑠𝑒𝑚𝑎𝑛𝑡𝑖𝑐 )60.2 89.4 64.1 58.3 85.2 60.9
whyCodex002-1-shot 22.9 28.8 12.9 20.8 23.2 11.9
Codex-1-shot ( 𝑅𝑒𝑟𝑎𝑛𝑘 𝑡𝑜𝑘𝑒𝑛 ) 23.5 67.6 17.7 22.6 62.7 19.4
Codex-1-shot ( 𝑅𝑒𝑟𝑎𝑛𝑘 𝑠𝑒𝑚𝑎𝑛𝑡𝑖𝑐 ) 29.2 68.0 25.7 26.7 63.3 20.1
Codex-1-shot ( 𝑆𝑒𝑙𝑒𝑐𝑡𝑖𝑜𝑛 𝑡𝑜𝑘𝑒𝑛 ) 32.8 72.8 27.7 30.7 68.4 25.5
Codex-1-shot ( 𝑆𝑒𝑙𝑒𝑐𝑡𝑖𝑜𝑛 𝑡𝑜𝑘𝑒𝑛+𝑅𝑒𝑟𝑎𝑛𝑘 𝑡𝑜𝑘𝑒𝑛 ) 36.4 81.0 31.6 34.4 77.1 28.9
Codex-1-shot ( 𝑆𝑒𝑙𝑒𝑐𝑡𝑖𝑜𝑛 𝑡𝑜𝑘𝑒𝑛+𝑅𝑒𝑟𝑎𝑛𝑘 𝑠𝑒𝑚𝑎𝑛𝑡𝑖𝑐 ) 38.6 83.4 35.9 36.9 80.2 30.3
Codex-10-shot 34.8 76.1 22.6 26.2 64.6 15.8
Codex-10-shot ( 𝑅𝑒𝑟𝑎𝑛𝑘 𝑡𝑜𝑘𝑒𝑛 ) 36.8 91.0 24.8 31.2 86.1 20.9
Codex-10-shot ( 𝑅𝑒𝑟𝑎𝑛𝑘 𝑠𝑒𝑚𝑎𝑛𝑡𝑖𝑐 ) 35.3 90.9 23.2 30.4 85.2 20.1
Codex-10-shot ( 𝑆𝑒𝑙𝑒𝑐𝑡𝑖𝑜𝑛 𝑠𝑒𝑚𝑎𝑛𝑡𝑖𝑐 ) 75.0 89.4 74.7 72.4 81.9 73.0
Codex-10-shot ( 𝑆𝑒𝑙𝑒𝑐𝑡𝑖𝑜𝑛 𝑠𝑒𝑚𝑎𝑛𝑡𝑖𝑐+𝑅𝑒𝑟𝑎𝑛𝑘 𝑡𝑜𝑘𝑒𝑛 ) 78.3 92.4 76.6 74.8 88.7 74.1
Codex-10-shot ( 𝑆𝑒𝑙𝑒𝑐𝑡𝑖𝑜𝑛 𝑠𝑒𝑚𝑎𝑛𝑡𝑖𝑐+𝑅𝑒𝑟𝑎𝑛𝑘 𝑠𝑒𝑚𝑎𝑛𝑡𝑖𝑐 )76.2 90.6 75.3 73.5 86.2 73.6
How-to-useCodex-1-shot 23.1 18.9 17.5 21.8 16.6 14.4
Codex-1-shot ( 𝑅𝑒𝑟𝑎𝑛𝑘 𝑡𝑜𝑘𝑒𝑛 ) 25.1 62.0 19.7 24.2 58.8 17.6
Codex-1-shot ( 𝑅𝑒𝑟𝑎𝑛𝑘 𝑠𝑒𝑚𝑎𝑛𝑡𝑖𝑐 ) 28.5 63.6 22.9 26.1 61.3 18.8
Codex-1-shot ( 𝑆𝑒𝑙𝑒𝑐𝑡𝑖𝑜𝑛 𝑡𝑜𝑘𝑒𝑛 ) 56.3 88.3 53.7 52.2 81.6 42.8
Codex-1-shot ( 𝑆𝑒𝑙𝑒𝑐𝑡𝑖𝑜𝑛 𝑡𝑜𝑘𝑒𝑛+𝑅𝑒𝑟𝑎𝑛𝑘 𝑡𝑜𝑘𝑒𝑛 ) 63.8 90.7 66.3 60.6 85.3 59.7
Codex-1-shot ( 𝑆𝑒𝑙𝑒𝑐𝑡𝑖𝑜𝑛 𝑡𝑜𝑘𝑒𝑛+𝑅𝑒𝑟𝑎𝑛𝑘 𝑠𝑒𝑚𝑎𝑛𝑡𝑖𝑐 ) 61.1 85.7 60.6 58.4 83.6 57.2
Codex-10-shot 33.3 84.6 22.3 26.9 76.4 17.3
Codex-10-shot ( 𝑟𝑒𝑟𝑎𝑛𝑘 𝑡𝑜𝑘𝑒𝑛 ) 32.7 86.6 27.0 30.9 82.4 23.2
Codex-10-shot ( 𝑟𝑒𝑟𝑎𝑛𝑘 𝑠𝑒𝑚𝑎𝑛𝑡𝑖𝑐 ) 35.2 85.6 24.2 32.8 81.5 21.6
Codex-10-shot ( 𝑆𝑒𝑙𝑒𝑐𝑡𝑖𝑜𝑛 𝑠𝑒𝑚𝑎𝑛𝑡𝑖𝑐 ) 76.3 91.2 77.4 71.6 85.4 73.6
Codex-10-shot ( 𝑆𝑒𝑙𝑒𝑐𝑡𝑖𝑜𝑛 𝑠𝑒𝑚𝑎𝑛𝑡𝑖𝑐+𝑅𝑒𝑟𝑎𝑛𝑘 𝑡𝑜𝑘𝑒𝑛 ) 78.8 93.5 74.2 71.9 85.1 73.9
Codex-10-shot ( 𝑆𝑒𝑙𝑒𝑐𝑡𝑖𝑜𝑛 𝑠𝑒𝑚𝑎𝑛𝑡𝑖𝑐+𝑅𝑒𝑟𝑎𝑛𝑘 𝑠𝑒𝑚𝑎𝑛𝑡𝑖𝑐 )79.1 93.9 75.2 72.3 85.7 74.5
How-it-is-doneCodex-1-shot 21.0 39.6 13.5 19.1 36.4 12.1
Codex-1-shot ( 𝑟𝑒𝑟𝑎𝑛𝑘 𝑡𝑜𝑘𝑒𝑛 ) 29.8 79.3 22.2 27.5 74.8 20.9
Codex-1-shot ( 𝑟𝑒𝑟𝑎𝑛𝑘 𝑠𝑒𝑚𝑎𝑛𝑡𝑖𝑐 ) 29.4 77.3 21.7 26.8 73.1 19.8
Codex-1-shot ( 𝑆𝑒𝑙𝑒𝑐𝑡𝑖𝑜𝑛 𝑡𝑜𝑘𝑒𝑛 ) 31.9 72.9 25.8 28.6 69.4 24.7
Codex-1-shot ( 𝑆𝑒𝑙𝑒𝑐𝑡𝑖𝑜𝑛 𝑡𝑜𝑘𝑒𝑛+𝑅𝑒𝑟𝑎𝑛𝑘 𝑡𝑜𝑘𝑒𝑛 ) 33.8 79.1 28.9 32.2 77.4 26.3
Codex-1-shot ( 𝑆𝑒𝑙𝑒𝑐𝑡𝑖𝑜𝑛 𝑡𝑜𝑘𝑒𝑛+𝑅𝑒𝑟𝑎𝑛𝑘 𝑠𝑒𝑚𝑎𝑛𝑡𝑖𝑐 ) 33.0 77.6 27.1 31.4 75.2 25.8
Codex-10-shot 28.4 79.3 19.5 21.9 66.7 14.9
Codex-10-shot ( 𝑟𝑒𝑟𝑎𝑛𝑘 𝑡𝑜𝑘𝑒𝑛 ) 30.6 95.3 24.7 28.1 90.8 23.2
Codex-10-shot ( 𝑟𝑒𝑟𝑎𝑛𝑘 𝑠𝑒𝑚𝑎𝑛𝑡𝑖𝑐 ) 30.0 95.2 22.3 27.6 90.1 20.1
Codex-10-shot ( 𝑆𝑒𝑙𝑒𝑐𝑡𝑖𝑜𝑛 𝑠𝑒𝑚𝑎𝑛𝑡𝑖𝑐 ) 51.6 86.4 50.8 48.9 82.9 47.9
Codex-10-shot ( 𝑆𝑒𝑙𝑒𝑐𝑡𝑖𝑜𝑛 𝑠𝑒𝑚𝑎𝑛𝑡𝑖𝑐+𝑅𝑒𝑟𝑎𝑛𝑘 𝑡𝑜𝑘𝑒𝑛 ) 59.2 89.3 57.4 56.1 85.6 53.5
Codex-10-shot ( 𝑆𝑒𝑙𝑒𝑐𝑡𝑖𝑜𝑛 𝑠𝑒𝑚𝑎𝑛𝑡𝑖𝑐+𝑅𝑒𝑟𝑎𝑛𝑘 𝑠𝑒𝑚𝑎𝑛𝑡𝑖𝑐 )57.6 88.1 55.2 55.3 83.1 53.2
PropertyCodex-1-shot 24.7 38.4 15.8 21.3 33.6 12.4
Codex-1-shot ( 𝑟𝑒𝑟𝑎𝑛𝑘 𝑡𝑜𝑘𝑒𝑛 ) 34.8 59.8 33.2 30.6 51.2 28.7
Codex-1-shot ( 𝑟𝑒𝑟𝑎𝑛𝑘 𝑠𝑒𝑚𝑎𝑛𝑡𝑖𝑐 ) 34.2 59.5 32.1 29.5 49.8 27.6
Codex-1-shot ( 𝑆𝑒𝑙𝑒𝑐𝑡𝑖𝑜𝑛 𝑡𝑜𝑘𝑒𝑛 ) 35.7 67.7 33.1 33.2 64.9 30.8
Codex-1-shot ( 𝑆𝑒𝑙𝑒𝑐𝑡𝑖𝑜𝑛 𝑡𝑜𝑘𝑒𝑛+𝑅𝑒𝑟𝑎𝑛𝑘 𝑡𝑜𝑘𝑒𝑛 ) 41.6 74.2 39.2 38.4 69.6 35.9
Codex-1-shot ( 𝑆𝑒𝑙𝑒𝑐𝑡𝑖𝑜𝑛 𝑡𝑜𝑘𝑒𝑛+𝑅𝑒𝑟𝑎𝑛𝑘 𝑠𝑒𝑚𝑎𝑛𝑡𝑖𝑐 ) 40.1 72.1 36.0 37.7 67.2 34.3
Codex-10-shot 36.2 81.9 29.4 28.7 80.3 24.7
Codex-10-shot ( 𝑟𝑒𝑟𝑎𝑛𝑘 𝑡𝑜𝑘𝑒𝑛 ) 38.4 84.2 31.2 35.2 82.7 28.6
Codex-10-shot ( 𝑟𝑒𝑟𝑎𝑛𝑘 𝑠𝑒𝑚𝑎𝑛𝑡𝑖𝑐 ) 36.2 78.4 30.9 34.1 81.2 27.4
Codex-10-shot ( 𝑆𝑒𝑙𝑒𝑐𝑡𝑖𝑜𝑛 𝑠𝑒𝑚𝑎𝑛𝑡𝑖𝑐 ) 86.3 95.8 87.4 81.0 86.4 80.8
Codex-10-shot ( 𝑆𝑒𝑙𝑒𝑐𝑡𝑖𝑜𝑛 𝑠𝑒𝑚𝑎𝑛𝑡𝑖𝑐+𝑅𝑒𝑟𝑎𝑛𝑘 𝑡𝑜𝑘𝑒𝑛 ) 87.2 96.4 88.7 84.9 89.1 83.2
Codex-10-shot ( 𝑆𝑒𝑙𝑒𝑐𝑡𝑖𝑜𝑛 𝑠𝑒𝑚𝑎𝑛𝑡𝑖𝑐+𝑅𝑒𝑟𝑎𝑛𝑘 𝑠𝑒𝑚𝑎𝑛𝑡𝑖𝑐 )86.8 96.1 87.9 82.5 88.2 82.1
Trung bìnhCodex-1-shot 23.1 30.7 16.2 21.1 26.1 13.6
Codex-1-shot ( 𝑟𝑒𝑟𝑎𝑛𝑘 𝑡𝑜𝑘𝑒𝑛 ) 29.1 68.9 25.2 26.8 64.0 23.2
Codex-1-shot ( 𝑟𝑒𝑟𝑎𝑛𝑘 𝑠𝑒𝑚𝑎𝑛𝑡𝑖𝑐 ) 30.2 69.0 25.8 27.2 63.9 22.2
Codex-1-shot ( 𝑆𝑒𝑙𝑒𝑐𝑡𝑖𝑜𝑛 𝑡𝑜𝑘𝑒𝑛 ) 39.2 77.3 35.1 36.1 72.8 31.0
Codex-1-shot ( 𝑆𝑒𝑙𝑒𝑐𝑡𝑖𝑜𝑛 𝑡𝑜𝑘𝑒𝑛+𝑅𝑒𝑟𝑎𝑛𝑘 𝑡𝑜𝑘𝑒𝑛 ) 44.0 82.0 41.9 41.5 77.4 37.9
Codex-1-shot ( 𝑆𝑒𝑙𝑒𝑐𝑡𝑖𝑜𝑛 𝑡𝑜𝑘𝑒𝑛+𝑅𝑒𝑟𝑎𝑛𝑘 𝑠𝑒𝑚𝑎𝑛𝑡𝑖𝑐 ) 43.7 80.8 40.9 41.4 76.4 37.7
Codex-10-shot 33.4 76.1 24.1 27.2 66.7 19.2
Codex-10-shot ( 𝑟𝑒𝑟𝑎𝑛𝑘 𝑡𝑜𝑘𝑒𝑛 ) 35.1 88.3 27.4 32.0 83.8 24.5
Codex-10-shot ( 𝑟𝑒𝑟𝑎𝑛𝑘 𝑠𝑒𝑚𝑎𝑛𝑡𝑖𝑐 ) 35.3 87.1 27.4 32.4 83.8 24.2
Codex-10-shot ( 𝑆𝑒𝑙𝑒𝑐𝑡𝑖𝑜𝑛 𝑠𝑒𝑚𝑎𝑛𝑡𝑖𝑐 ) 65.9 89.4 65.8 62.8 83.2 62.7
Codex-10-shot ( 𝑆𝑒𝑙𝑒𝑐𝑡𝑖𝑜𝑛 𝑠𝑒𝑚𝑎𝑛𝑡𝑖𝑐+𝑅𝑒𝑟𝑎𝑛𝑘 𝑡𝑜𝑘𝑒𝑛 ) 72.4 91.8 71.6 68.8 86.3 68.6
Codex-10-shot ( 𝑆𝑒𝑙𝑒𝑐𝑡𝑖𝑜𝑛 𝑠𝑒𝑚𝑎𝑛𝑡𝑖𝑐+𝑅𝑒𝑟𝑎𝑛𝑘 𝑠𝑒𝑚𝑎𝑛𝑡𝑖𝑐 )72.0 91.6 71.5 68.4 85.7 68.9

4.3 RQ3: Hiệu quả của Sắp xếp lại
Kết quả của các chiến lược sắp xếp lại khác nhau được hiển thị trong Bảng 5. Do hạn chế về không gian, chúng tôi liệt kê kết quả của học 1-shot và 10-shot. Đối với 1-shot, chúng tôi cũng kết hợp các chiến lược sắp xếp lại khác nhau với lựa chọn minh họa dựa trên token vì theo kết quả từ phần trên, chiến lược lựa chọn này đạt được kết quả tốt hơn trên 1-shot. Tương tự, đối với 10-shot, chúng tôi kết hợp các chiến lược sắp xếp lại khác nhau với lựa chọn minh họa dựa trên ngữ nghĩa.

--- TRANG 10 ---
ICSE 2024, Tháng 4 2024, Lisbon, Bồ Đào Nha Mingyang Geng, Shangwen Wang, Dezun Dong, Haotian Wang, Ge Li, Zhi Jin, Xiaoguang Mao, và Xiangke Liao

1 // Mã Kiểm tra:
2 private void playPrevious() {
3 if (mediaType == ItemType.YOUTUBE_MEDIA_TYPE_VIDEO) {
4 restartVideo();
5 return;
6 }
7 if (currentSongIndex - 1 >= 0) {
8 currentSongIndex--;
9 } else {
10 currentSongIndex = youTubeVideos.size() - 1;
11 }
12 videoItem = youTubeVideos.get(youTubeVideos.size() - 1);
13 playVideo();
14 }
15 // Bình luận Sự thật Cơ bản: Phát video trước trong danh sách phát.
16 // Codex-1-shot: Phát bài hát hoặc video tiếp theo.
17 // Codex-1-shot (Lựa chọn): Phát video trước trong danh sách phát của bạn.
18 ----------------------------------------------------------------------------
19 // Mã Tương tự Ngữ nghĩa Top-1
20 // Bình luận: Phát mục đầu tiên trong hàng đợi âm thanh.
21 private void playFirstInQueue() {
22 AudioQueueItem queueItem = mAudioQueue.poll();
23 try {
24 mMediaPlayer.setDataSource(this, queueItem.mUri);
25 } catch (IOException e) {
26 e.printStackTrace();
27 endPlayback();
28 return;
29 }
30 mMediaPlayer.setOnCompletionListener(queueItem.mListener);
31 try {
32 mMediaPlayer.prepare();
33 } catch (IOException e) {
34 e.printStackTrace();
35 endPlayback();
36 return;
37 }
38 mMediaPlayer.start();
39 }

Hình 3: Một ví dụ minh họa để cho thấy cách lựa chọn dựa trên ngữ nghĩa giúp cải thiện tạo sinh bình luận so với lựa chọn ngẫu nhiên.

Kết quả cho thấy cả hai chiến lược sắp xếp lại đều giúp thúc đẩy hiệu suất của Codex một chút. Ví dụ, đối với học 1-shot, chiến lược sắp xếp lại dựa trên token tăng các giá trị BLEU trên bộ dữ liệu Funcom và TLC từ 23.1% và 21.1% lên 29.1% và 26.8%, trong khi chiến lược dựa trên ngữ nghĩa tiếp tục đạt 30.2% và 27.2% trên hai bộ dữ liệu. Chúng tôi cũng lưu ý rằng sắp xếp lại có thể tăng cường kết quả bất kể việc lựa chọn minh họa có được sử dụng hay không. Biến thể mô hình hoạt động tốt nhất, tức là học 10-shot với lựa chọn minh họa dựa trên ngữ nghĩa và sắp xếp lại dựa trên token, đạt điểm BLEU trung bình 72.4% và 68.8% trên hai bộ dữ liệu, vượt trội hơn DOME hiện đại nhất lần lượt 128% và 210% (xem Bảng 3).

Phân tích trường hợp. Chúng tôi trình bày một trường hợp khác để cho thấy cách chiến lược sắp xếp lại giúp chọn các bình luận có chất lượng hơn, được hiển thị trong Hình 4. Trong hình này, chúng tôi minh họa top-5 bình luận được tạo sinh từ Codex. Bình luận được tạo sinh đầu tiên mơ hồ về ngữ nghĩa vì nó không giải thích rõ ràng ý nghĩa của các từ DURABLE_EXPLICIT vàDURABLE_IMPLICIT . Tương tự, bình luận được tạo sinh thứ hai cũng có thể gây hiểu lầm cho các nhà phát triển vì không rõ Endpoint là gì, không xuất hiện trong mã nguồn. Bình luận được tạo sinh thứ ba và thứ tư chia sẻ ý nghĩa tương tự nhưng được thể hiện theo những cách khác nhau, và cả hai đều giống hệt về ngữ nghĩa với bình luận oracle. Sau khi sử dụng lựa chọn mã tương tự dựa trên token, một đoạn mã với bình luận "Xác định liệu có ... hay không" được sử dụng để giúp sắp xếp lại kết quả ban đầu. Do mức độ trùng lặp token lớn với bình luận tham chiếu, bình luận được tạo sinh thứ tư từ Codex được sử dụng làm kết quả cuối cùng theo chiến lược sắp xếp lại dựa trên token. So với

1 // Mã Kiểm tra:
2 public boolean isDurableSubscriber() {
3 return !StringsUtils.isEmpty(m_durableSubscriptionName);
4 }
5 // Bình luận Sự thật Cơ bản: Xác định xem người đăng ký có bền vững hay không.
6 ----------------------------------------------------------------------------
7 /*
8 Top-5 Bình luận Được Tạo sinh Codex-1-shot:
9 1.Trả về true nếu đăng ký này có loại đăng ký DURABLE_EXPLICIT hoặc DURABLE_IMPLICIT.
10 2.Cho biết liệu Endpoint có phải là người đăng ký bền vững hay không.
11 3.Trả về TRUE nếu đây là đăng ký bền vững và FALSE ngược lại.
12 4.Xác định liệu người đăng ký có bền vững hay không.
13 5.Một khách hàng bền vững có thể cài đặt khách hàng đã nói không.
14 */
15 ----------------------------------------------------------------------------
16 // Mã Tương tự Từ vựng Top-1
17 // Bình luận: Xác định liệu đăng ký này có cho tất cả luồng hay cho một luồng cụ thể hay không.
18 public boolean isSubscribedToAll() {
19 return isNullOrEmpty(streamId);
20 }
21 ----------------------------------------------------------------------------
22 // Kết quả top-1 sau khi sắp xếp lại dựa trên token:
23 // Xác định liệu người đăng ký có bền vững hay không.

Hình 4: Một ví dụ minh họa để cho thấy cách chiến lược sắp xếp lại của chúng tôi giúp cải thiện tạo sinh bình luận.

kết quả top-1 ban đầu, giá trị BLEU được tăng từ 23.4% lên 68.6%.

Phát hiện-5. Cả hai chiến lược sắp xếp lại dựa trên token và dựa trên ngữ nghĩa đều có thể tăng cường thêm hiệu suất của Codex.

Đối với so sánh giữa hai chiến lược sắp xếp lại, chúng tôi lại quan sát thấy rằng không có chiến lược nào có thể vượt trội nhất quán so với lựa chọn thay thế của nó. Nói chung, sắp xếp lại dựa trên token hoạt động tốt hơn khi kết hợp với lựa chọn minh họa trong khi sắp xếp lại dựa trên ngữ nghĩa hoạt động tốt hơn khi không áp dụng lựa chọn minh họa. Tuy nhiên, có một số trường hợp ngoại lệ. Ví dụ, đối với loại ý định "what", sắp xếp lại dựa trên ngữ nghĩa hoạt động tốt hơn khi kết hợp với lựa chọn minh họa.

Phát hiện-6. Không có chiến lược sắp xếp lại nào có thể vượt trội nhất quán so với lựa chọn thay thế của nó.

5 THẢO LUẬN
5.1 Đánh giá Con người
Trong khi các chỉ số như BLEU, ROUGE-L, và METEOR có thể đánh giá sự khác biệt từ vựng giữa các bình luận được tạo sinh và oracle, chúng không đủ để phản ánh sự khác biệt ngữ nghĩa. Do đó, để đánh giá thêm chất lượng của các bình luận được tạo sinh bởi các phương pháp khác nhau, chúng tôi tiến hành đánh giá con người. Cụ thể, chúng tôi tuyển dụng sáu người tham gia với ít nhất năm năm kinh nghiệm trong phát triển Java. Những người tham gia bao gồm ba nghiên cứu sinh tiến sĩ và ba nhà nghiên cứu cao cấp không phải là đồng tác giả của bài báo này. Chúng tôi chọn ngẫu nhiên 100 đoạn mã (20 từ mỗi loại ý định) để thực hiện nghiên cứu người dùng này. Đối với mỗi đoạn mã, chúng tôi cho người tham gia xem bình luận oracle và kết quả từ bốn phương pháp, cụ thể là DOME, Codex-10-shot, Codex-10-shot với lựa chọn dựa trên ngữ nghĩa, và Codex-10-shot với lựa chọn dựa trên ngữ nghĩa và sắp xếp lại dựa trên token, điều này dẫn đến 400 bình luận được tạo sinh làm đối tượng đánh giá của chúng tôi. Để đảm bảo công bằng, những người tham gia không biết các bình luận được tạo sinh từ đâu. Mỗi người tham gia được yêu cầu đánh giá tất cả 400 bình luận từ

--- TRANG 11 ---
Các Mô hình Ngôn ngữ Lớn là Các Tóm tắt viên Few-Shot:
Tạo sinh Bình luận Đa-ý định thông qua Học tập Trong Ngữ cảnh ICSE 2024, Tháng 4 2024, Lisbon, Bồ Đào Nha

Bảng 6: Kết quả thống kê của nghiên cứu người dùng của chúng tôi.
Phương pháp Trung bình Độ lệch chuẩn
Tự nhiênDOME 3.9 0.8
Codex-10-shot 4.2 0.7
Codex-10-shot ( 𝑆𝑒𝑙𝑒𝑐𝑡𝑖𝑜𝑛 𝑠𝑒𝑚𝑎𝑛𝑡𝑖𝑐 ) 4.3 0.8
Codex-10-shot ( 𝑆𝑒𝑙𝑒𝑐𝑡𝑖𝑜𝑛 𝑠𝑒𝑚𝑎𝑛𝑡𝑖𝑐 +𝑅𝑒𝑟𝑎𝑛𝑘 𝑡𝑜𝑘𝑒𝑛 )4.3 0.7
Đầy đủDOME 3.3 1.3
Codex-10-shot 3.5 1.1
Codex-10-shot ( 𝑆𝑒𝑙𝑒𝑐𝑡𝑖𝑜𝑛 𝑠𝑒𝑚𝑎𝑛𝑡𝑖𝑐 ) 3.8 1.2
Codex-10-shot ( 𝑆𝑒𝑙𝑒𝑐𝑡𝑖𝑜𝑛 𝑠𝑒𝑚𝑎𝑛𝑡𝑖𝑐 +𝑅𝑒𝑟𝑎𝑛𝑘 𝑡𝑜𝑘𝑒𝑛 )4.1 0.9
Hữu íchDOME 3.0 1.4
Codex-10-shot 3.1 1.3
Codex-10-shot ( 𝑆𝑒𝑙𝑒𝑐𝑡𝑖𝑜𝑛 𝑠𝑒𝑚𝑎𝑛𝑡𝑖𝑐 ) 3.7 1.1
Codex-10-shot ( 𝑆𝑒𝑙𝑒𝑐𝑡𝑖𝑜𝑛 𝑠𝑒𝑚𝑎𝑛𝑡𝑖𝑐 +𝑅𝑒𝑟𝑎𝑛𝑘 𝑡𝑜𝑘𝑒𝑛 )3.8 1.3

ba khía cạnh: (1) Tự nhiên phản ánh tính trôi chảy của các bình luận được tạo sinh từ góc độ ngữ pháp; (2) Đầy đủ phản ánh tính phong phú thông tin của các bình luận được tạo sinh; và (3) Hữu ích phản ánh cách các bình luận được tạo sinh có thể giúp các nhà phát triển, trên thang điểm Likert 5 điểm (1 cho kém, 2 cho cận biên, 3 cho chấp nhận được, 4 cho tốt, và 5 cho xuất sắc). Cài đặt thí nghiệm như vậy tuân theo các nghiên cứu hiện tại [46, 59].

Kết quả của nghiên cứu người dùng của chúng tôi được liệt kê trong Bảng 6. Chúng tôi quan sát thấy rằng các giá trị chỉ số cao hơn dẫn đến điểm số cao hơn được đánh giá bởi những người tham gia. Cụ thể, biến thể mô hình hoạt động tốt nhất trong đánh giá định lượng của chúng tôi, tức là học 10-shot với lựa chọn minh họa dựa trên ngữ nghĩa và sắp xếp lại dựa trên token, cũng đạt được điểm số cao nhất từ những người tham gia (tức là 4.3, 4.1, và 3.8 về ba khía cạnh, tương ứng). Chúng tôi cũng lưu ý rằng LLMs giỏi trong việc tạo sinh các mô tả NL trôi chảy, vì tất cả các biến thể mô hình đạt được điểm số cao hơn 4 về thuộc tính tự nhiên. Ngược lại, tất cả điểm số đạt được về thuộc tính hữu ích đều thấp hơn 4, điều này cho thấy vẫn còn chỗ để cải thiện tính hữu ích của các bình luận được tạo sinh.

5.2 Hàm ý
Các mô hình ngôn ngữ lớn là các tóm tắt viên few-shot. Điều tra thực nghiệm của chúng tôi cho thấy rằng LLMs có khả năng tạo sinh các bình luận mã chất lượng cao với các ý định đa dạng. Kết quả cho thấy rằng biến thể mô hình hoạt động tốt nhất, tức là Codex-10-shot với lựa chọn minh họa dựa trên ngữ nghĩa và sắp xếp lại dựa trên token, vượt trội hơn phương pháp DOME hiện đại nhất ở mức độ lớn trên hai bộ dữ liệu (ví dụ, vượt trội hơn DOME 128%/210% về chỉ số BLEU trên bộ dữ liệu Funcom/TLC). Điều này cho thấy rằng trong thực tế, các nhà phát triển có thể tham khảo LLMs để giúp họ tự động tạo sinh các bình luận với các ý định khác nhau. LLMs do đó có tiềm năng lớn để hỗ trợ các hoạt động hiểu chương trình. Đối với các nhà nghiên cứu, điều này cũng cho thấy rằng việc so sánh với LLMs là cần thiết khi đánh giá một phương pháp tóm tắt mã mới được đề xuất.

Về tầm quan trọng của chất lượng gợi ý. Kết quả của chúng tôi cho thấy rằng chất lượng của gợi ý được cung cấp cho LLMs có thể ảnh hưởng đáng kể đến kết quả được tạo sinh. Cụ thể, cung cấp cho LLMs các ví dụ tương tự như mã đích có thể giúp chúng tạo sinh kết quả có chất lượng hơn. Điều này kêu gọi sự chú ý nhiều hơn đến quá trình lựa chọn minh họa. Tuy nhiên, đối với chiến lược lựa chọn, kết quả của chúng tôi cũng cho thấy rằng không có viên đạn bạc: lựa chọn mã tương tự dựa trên token và dựa trên ngữ nghĩa bổ sung cho nhau. Điều này có nghĩa là nhiều nỗ lực nghiên cứu hơn có thể được dành để thiết kế một chiến lược lựa chọn tốt hơn.

Nhiều nỗ lực hơn, nhiều lợi ích hơn. Do quá trình lấy mẫu, LLMs có thể tạo sinh nhiều kết quả cho một đầu vào cụ thể. Kết quả của chúng tôi (ví dụ, trường hợp trong Hình 4) cho thấy rằng đôi khi một bình luận tương tự như oracle có thể không được tạo sinh ngay từ đầu. Do đó, trong thực tế, các nhà phát triển có thể truy vấn LLMs nhiều lần hơn nếu họ cảm thấy các bình luận được tạo sinh không đủ tốt. Đối với các nhà nghiên cứu, cách tự động sắp xếp lại kết quả của LLMs cũng đáng được khám phá sâu hơn và nỗ lực ban đầu của chúng tôi với hai heuristic đơn giản đạt được kết quả đầy hứa hẹn.

5.3 Các Mối đe dọa đối với Tính hợp lệ
Tính hợp lệ nội bộ. Codex được huấn luyện trên các dự án mã nguồn mở và do đó có thể có rò rỉ dữ liệu, tức là Codex có thể đã thấy các bình luận cho các trường hợp kiểm tra trong quá trình tiền huấn luyện của nó. Tuy nhiên, chúng tôi quan sát thấy rằng Codex không hoạt động hiệu quả trong cài đặt zero-shot, điều này cho thấy rằng đầu ra của mô hình không được tạo sinh do ghi nhớ. Mối đe dọa như vậy cũng được các nghiên cứu khác về các mô hình ngôn ngữ lớn đối mặt [ 48], và để giải quyết hoàn toàn mối đe dọa này yêu cầu huấn luyện lại mô hình từ đầu, điều này hiện tại sẽ không khả thi xem xét hạn chế của tài nguyên tính toán.

Như đã giới thiệu, kết quả của chúng tôi bị ảnh hưởng bởi tính ngẫu nhiên gây ra bởi quá trình lấy mẫu mô hình hoặc lựa chọn minh họa. Để giảm thiểu mối đe dọa này cũng như giữ chi phí thời gian của các thí nghiệm ở mức hợp lý, chúng tôi lặp lại mỗi thí nghiệm một trăm lần. Tuy nhiên, một trăm có thể không loại bỏ hoàn toàn tính ngẫu nhiên và chúng tôi để lại nhiều thí nghiệm hơn như công việc tương lai.

Tính hợp lệ ngoại bộ. Mối đe dọa đầu tiên đối với việc áp dụng quan sát của chúng tôi trong thực tế là không rõ liệu các nhà phát triển có thể tìm thấy các đoạn mã tương tự như mã đích để xây dựng gợi ý tốt hơn cho LLMs hay không. Tuy nhiên, kết quả của chúng tôi cũng cho thấy rằng trong cài đặt 10-shot, hiệu suất của Codex vượt qua DOME hiện đại nhất ngay cả khi các minh họa được chọn ngẫu nhiên.

Một mối đe dọa khác là chúng tôi chỉ tập trung vào ngôn ngữ lập trình Java. Cài đặt này bị hạn chế bởi tính khả dụng của bộ dữ liệu bình luận đa-ý định trong tài liệu. Mối đe dọa này được giảm thiểu xem xét rằng hai bộ dữ liệu có quy mô lớn và Java là ngôn ngữ được nghiên cứu rộng rãi nhất trong lĩnh vực tạo sinh bình luận [28, 36, 47].

6 KẾT LUẬN
Nghiên cứu thực nghiệm của chúng tôi chủ yếu điều tra liệu có khả thi sử dụng LLMs để giải quyết tạo sinh bình luận đa-ý định và tiếp tục cách cải thiện hiệu quả của LLMs trong nhiệm vụ này. Kết quả của chúng tôi đưa ra câu trả lời tích cực cho điểm đầu tiên: bằng cách sử dụng học few-shot trong ngữ cảnh, hiệu suất của Codex vượt qua phương pháp học có giám sát hiện đại nhất. Chúng tôi cũng chứng minh rằng cả lựa chọn minh họa và sắp xếp lại kết quả đều có thể giúp thúc đẩy hiệu suất của Codex. Nghiên cứu của chúng tôi thiết lập các đường cơ sở mới cho nhiệm vụ tạo sinh bình luận đa-ý định cũng như chỉ ra các hướng nghiên cứu đáng được điều tra sâu hơn.

7 TÍNH KHÁCH DỤNG CỦA DỮ LIỆU
Tất cả mã và dữ liệu trong nghiên cứu này đều có sẵn công khai tại:
https://github.com/gmy2013/LLM_Comment_Generation .

--- TRANG 12 ---
ICSE 2024, Tháng 4 2024, Lisbon, Bồ Đào Nha Mingyang Geng, Shangwen Wang, Dezun Dong, Haotian Wang, Ge Li, Zhi Jin, Xiaoguang Mao, và Xiangke Liao

TÀI LIỆU THAM KHẢO
[1] 2010. Bộ dữ liệu Funcom Gốc. (2010). http://www.ics.uci.edu/lopes/datasets/.
[2]2022. Mô hình Codex. (2022). https://beta.openai.com/docs/models/codex-
seriesprivate-beta.
[3]Wasi Uddin Ahmad, Saikat Chakraborty, Baishakhi Ray, và Kai-Wei Chang. 2020.
Một phương pháp dựa trên transformer cho tóm tắt mã nguồn. arXiv preprint
arXiv:2005.00653 (2020).
[4]Uri Alon, Shaked Brody, Omer Levy, và Eran Yahav. 2018. code2seq: Tạo
sinh chuỗi từ các biểu diễn có cấu trúc của mã. arXiv preprint
arXiv:1808.01400 (2018).
[5]Uri Alon, Shaked Brody, Omer Levy, và Eran Yahav. 2019. code2seq: Tạo sinh
Chuỗi từ Biểu diễn Có cấu trúc của Mã. Trong Kỷ yếu Hội nghị Quốc tế lần thứ 7 về Học tập Biểu diễn . OpenReview.net.
[6]Satanjeev Banerjee và Alon Lavie. 2005. METEOR: Một chỉ số tự động cho
đánh giá MT với tương quan cải thiện với các phán quyết của con người. Trong Kỷ yếu hội thảo acl về các biện pháp đánh giá nội tại và ngoại tại cho dịch máy và/hoặc tóm tắt . 65–72.
[7]Aakash Bansal, Sakib Haque, và Collin McMillan. 2021. Mã hóa cấp độ dự án
cho tóm tắt mã nguồn thần kinh của các chương trình con. Trong Hội nghị Quốc tế IEEE/ACM lần thứ 29 năm 2021 về Hiểu Chương trình (ICPC) . IEEE, 253–264.
[8]Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan,
Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda
Askell, et al .2020. Các mô hình ngôn ngữ là những người học few-shot. Tiến bộ trong hệ thống xử lý thông tin thần kinh 33 (2020), 1877–1901.
[9]Ruichu Cai, Zhihao Liang, Boyan Xu, Zijian Li, Yuexing Hao, và Yao Chen.
2020. TAG: Hướng dẫn phụ trợ kiểu cho tạo sinh bình luận mã. arXiv preprint
arXiv:2005.02835 (2020).
[10] Bei Chen, Fengji Zhang, Anh Nguyen, Daoguang Zan, Zeqi Lin, Jian-Guang Lou,
và Weizhu Chen. 2022. Codet: Tạo sinh mã với các bài kiểm tra được tạo sinh. arXiv
preprint arXiv:2207.10397 (2022).
[11] Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira
Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman,
et al.2021. Đánh giá các mô hình ngôn ngữ lớn được huấn luyện trên mã. arXiv preprint
arXiv:2107.03374 (2021).
[12] Qiuyuan Chen, Xin Xia, Han Hu, David Lo, và Shanping Li. 2021. Tại sao mô hình tóm tắt mã của tôi không hoạt động: Cải thiện bình luận mã với dự đoán loại. ACM Transactions on Software Engineering and Methodology
(TOSEM) 30, 2 (2021), 1–29.
[13] Junyan Cheng, Iordanis Fostiropoulos, và Barry Boehm. 2021. GN-Transformer:
Hợp nhất Biểu diễn Chuỗi và Đồ thị cho Tóm tắt Mã Cải thiện.
arXiv preprint arXiv:2111.08874 (2021).
[14] Arghavan Moradi Dakhel, Vahid Majdinasab, Amin Nikanjam, Foutse Khomh,
Michel C Desmarais, Zhen Ming, et al .2022. GitHub Copilot AI lập trình viên cặp:
Tài sản hay Trách nhiệm pháp lý? arXiv preprint arXiv:2206.15331 (2022).
[15] Jacob Devlin, Ming-Wei Chang, Kenton Lee, và Kristina Toutanova. 2019. BERT:
Tiền huấn luyện Transformer Hai chiều Sâu cho Hiểu Ngôn ngữ. Trong
Kỷ yếu Hội nghị năm 2019 của Chương Bắc Mỹ của Hiệp hội Ngôn ngữ học Tính toán: Công nghệ Ngôn ngữ Con người . 4171–4186. https:
//doi.org/10.18653/v1/n19-1423
[16] Jacob Devlin, Ming-Wei Chang, Kenton Lee, và Kristina Toutanova. 2018. Bert:
Tiền huấn luyện transformer hai chiều sâu cho hiểu ngôn ngữ. arXiv
preprint arXiv:1810.04805 (2018).
[17] Aryaz Eghbali và Michael Pradel. 2022. CrystalBLEU: đo lường chính xác và hiệu quả độ tương tự của mã. Trong Hội nghị Quốc tế IEEE/ACM lần thứ 37 về
Kỹ thuật Phần mềm Tự động . 1–12.
[18] Zhiyu Fan, Xiang Gao, Abhik Roychoudhury, và Shin Hwei Tan. 2022. Cải thiện mã được tạo sinh tự động từ Codex thông qua Sửa chữa Chương trình Tự động. arXiv
preprint arXiv:2205.10583 (2022).
[19] Zhangyin Feng, Daya Guo, Duyu Tang, Nan Duan, Xiaocheng Feng, Ming Gong,
Linjun Shou, Bing Qin, Ting Liu, Daxin Jiang, et al .2020. Codebert: Một mô hình được tiền huấn luyện cho ngôn ngữ lập trình và ngôn ngữ tự nhiên. arXiv preprint arXiv:2002.08155
(2020).
[20] Shuzheng Gao, Cuiyun Gao, Yulan He, Jichuan Zeng, Lunyiu Nie, Xin Xia, và
Michael Lyu. 2023. Transformer Hướng dẫn Cấu trúc Mã cho Tóm tắt Mã Nguồn. ACM Transactions on Software Engineering and Methodology 32, 1
(2023), 1–32.
[21] Mingyang Geng, Shangwen Wang, Dezun Dong, Shanzhi Gu, Fang Peng, Weijian
Ruan, và Xiangke Liao. 2022. Phân tích tương tác ngữ nghĩa mã-bình luận tinh chế. Trong Kỷ yếu Hội nghị Quốc tế IEEE/ACM lần thứ 30 về Hiểu Chương trình . 585–596.
[22] Mingyang Geng, Shangwen Wang, Dezun Dong, Haotian Wang, Shaomeng Cao,
Kechi Zhang, và Zhi Jin. 2023. Tóm tắt Mã dựa trên Diễn giải. Trong
Kỷ yếu Hội nghị Quốc tế IEEE/ACM lần thứ 31 về Hiểu Chương trình .
[23] Yaroslav Golubev, Viktor Poletansky, Nikita Povarov, và Timofey Bryksin. 2021.
Phát hiện clone mã dựa trên token đa ngưỡng. Trong Hội nghị Quốc tế IEEE 2021 về Phân tích Phần mềm, Tiến hóa và Kỹ thuật lại (SANER) . IEEE,496–500.
[24] Daya Guo, Shuo Ren, Shuai Lu, Zhangyin Feng, Duyu Tang, Shujie Liu, Long
Zhou, Nan Duan, Alexey Svyatkovskiy, Shengyu Fu, et al .2021. GraphCodeBERT:
Tiền huấn luyện Biểu diễn Mã với Luồng Dữ liệu. Trong ICLR .
[25] Sonia Haiduc, Jairo Aponte, Laura Moreno, và Andrian Marcus. 2010. Về việc sử dụng các kỹ thuật tóm tắt văn bản tự động để tóm tắt mã nguồn.
Trong Hội nghị Làm việc lần thứ 17 năm 2010 về Kỹ thuật Ngược . IEEE, 35–44.
[26] Sakib Haque, Alexander LeClair, Lingfei Wu, và Collin McMillan. 2020. Tóm tắt tự động cải thiện của các chương trình con thông qua chú ý đến ngữ cảnh tệp. Trong
Kỷ yếu Hội nghị Quốc tế lần thứ 17 về Khai thác Kho lưu trữ Phần mềm .
300–310.
[27] Emily Hill, Lori Pollock, và K Vijay-Shanker. 2009. Tự động nắm bắt ngữ cảnh mã nguồn của các truy vấn nl cho bảo trì và tái sử dụng phần mềm. Trong
Hội nghị Quốc tế IEEE lần thứ 31 năm 2009 về Kỹ thuật Phần mềm . IEEE, 232–242.
[28] Xing Hu, Ge Li, Xin Xia, David Lo, và Zhi Jin. 2018. Tạo sinh bình luận mã sâu. Trong Kỷ yếu hội nghị lần thứ 26 về hiểu chương trình . 200–
210.
[29] Xing Hu, Ge Li, Xin Xia, David Lo, và Zhi Jin. 2020. Tạo sinh bình luận mã sâu với thông tin từ vựng và cú pháp lai. Kỹ thuật Phần mềm Thực nghiệm 25 (2020), 2179–2217.
[30] Xing Hu, Ge Li, Xin Xia, David Lo, Shuai Lu, và Zhi Jin. 2018. Tóm tắt mã nguồn với kiến thức api được chuyển giao. (2018).
[31] Hamel Husain, Ho-Hsiang Wu, Tiferet Gazit, Miltiadis Allamanis, và Marc
Brockschmidt. 2019. Thử thách codesearchnet: Đánh giá trạng thái tìm kiếm mã ngữ nghĩa. arXiv preprint arXiv:1909.09436 (2019).
[32] Srinivasan Iyer, Ioannis Konstas, Alvin Cheung, và Luke Zettlemoyer. 2016.
Tóm tắt mã nguồn bằng mô hình chú ý thần kinh. Trong Kỷ yếu Cuộc họp Thường niên lần thứ 54 của Hiệp hội Ngôn ngữ học Tính toán (Tập 1:
Bài báo Dài) . 2073–2083.
[33] Toshihiro Kamiya, Shinji Kusumoto, và Katsuro Inoue. 2002. CCFinder: Một hệ thống phát hiện clone mã dựa trên token đa ngôn ngữ cho mã nguồn quy mô lớn. Giao dịch IEEE về kỹ thuật phần mềm 28, 7 (2002), 654–670.
[34] Sophia D Kolak, Ruben Martins, Claire Le Goues, và Vincent Josua Hellendoorn.
2022. Tạo sinh Bản vá với Mô hình Ngôn ngữ: Tính khả thi và Hành vi Mở rộng.
Trong Hội thảo Học sâu cho Mã .
[35] Alexander LeClair, Aakash Bansal, và Collin McMillan. 2021. Mô hình tập hợp cho tóm tắt mã nguồn thần kinh của các chương trình con. Trong Hội nghị Quốc tế IEEE 2021 về Bảo trì và Tiến hóa Phần mềm (ICSME) . IEEE, 286–297.
[36] Alexander LeClair, Siyuan Jiang, và Collin McMillan. 2019. Một mô hình thần kinh để tạo sinh tóm tắt ngôn ngữ tự nhiên của các chương trình con chương trình. Trong
Hội nghị Quốc tế IEEE/ACM lần thứ 41 năm 2019 về Kỹ thuật Phần mềm (ICSE) . IEEE,
795–806.
[37] Jia Li, Yongmin Li, Ge Li, Xing Hu, Xin Xia, và Zhi Jin. 2021. Editsum: Một khung truy xuất và chỉnh sửa cho tóm tắt mã nguồn. Trong Hội nghị Quốc tế IEEE/ACM lần thứ 36 năm 2021 về Kỹ thuật Phần mềm Tự động (ASE) . IEEE, 155–
166.
[38] Lingwei Li, Li Yang, Huaxi Jiang, Jun Yan, Tiejian Luo, Zihan Hua, Geng Liang,
và Chun Zuo. 2022. AUGER: tự động tạo sinh bình luận đánh giá với mô hình tiền huấn luyện. Trong Kỷ yếu Hội nghị Kỹ thuật Phần mềm Châu Âu ACM lần thứ 30 và Hội nghị về Nền tảng Kỹ thuật Phần mềm .
1009–1021.
[39] Bo Lin, Shangwen Wang, Kui Liu, Xiaoguang Mao, và Tegawendé F. Bissyandé.
2021. Cập nhật Bình luận Tự động: Chúng ta đã đi được bao xa?. Trong Kỷ yếu Hội nghị Quốc tế IEEE/ACM lần thứ 29 về Hiểu Chương trình (ICPC) . 36–46.
https://doi.org/10.1109/ICPC52881.2021.00013
[40] Bo Lin, Shangwen Wang, Zhongxin Liu, Xin Xia, và Xiaoguang Mao. 2023.
Cập nhật Bình luận Dự đoán với Heuristic và Học thần kinh Dựa trên Đường dẫn AST: Một Phương pháp Hai pha. Giao dịch IEEE về Kỹ thuật Phần mềm 49,
4 (2023), 1640–1660. https://doi.org/10.1109/TSE.2022.3185458
[41] Chen Lin, Zhichao Ouyang, Junqing Zhuang, Jianqiang Chen, Hui Li, và Rongxin
Wu. 2021. Cải thiện tóm tắt mã với việc phân tách cây cú pháp trừu tượng theo khối. Trong Hội nghị Quốc tế IEEE/ACM lần thứ 29 năm 2021 về Hiểu Chương trình (ICPC) . IEEE, 184–195.
[42] Chin-Yew Lin. 2004. Rouge: Một gói cho đánh giá tự động của tóm tắt.
Trong Tóm tắt văn bản phân nhánh . 74–81.
[43] Pengfei Liu, Xipeng Qiu, và Xuanjing Huang. 2016. Mạng thần kinh hồi quy cho phân loại văn bản với học đa nhiệm vụ. arXiv preprint arXiv:1605.05101
(2016).
[44] Antonio Mastropaolo, Nathan Cooper, David Nader Palacio, Simone Scalabrino,
Denys Poshyvanyk, Rocco Oliveto, và Gabriele Bavota. 2022. Sử dụng Học chuyển giao cho Các nhiệm vụ Liên quan đến Mã. Giao dịch IEEE về Kỹ thuật Phần mềm
(2022).
[45] Sewon Min, Xinxi Lyu, Ari Holtzman, Mikel Artetxe, Mike Lewis, Hannaneh
Hajishirzi, và Luke Zettlemoyer. 2022. Suy nghĩ lại Vai trò của Minh họa:
Điều gì Làm cho Học tập Trong Ngữ cảnh Hoạt động? arXiv preprint arXiv:2202.12837 (2022).
[46] Fangwen Mu, Xiao Chen, Lin Shi, Song Wang, và Qing Wang. 2022. Tạo sinh Bình luận Tự động thông qua Thảo luận Đa lần. Trong Hội nghị Quốc tế IEEE/ACM lần thứ 37 về Kỹ thuật Phần mềm Tự động . 1–12.

--- TRANG 13 ---
Các Mô hình Ngôn ngữ Lớn là Các Tóm tắt viên Few-Shot:
Tạo sinh Bình luận Đa-ý định thông qua Học tập Trong Ngữ cảnh ICSE 2024, Tháng 4 2024, Lisbon, Bồ Đào Nha

[47] Fangwen Mu, Xiao Chen, Lin Shi, Song Wang, và Qing Wang. 2023. Tạo sinh Bình luận Mã Hướng dẫn Ý định Nhà phát triển. arXiv preprint arXiv:2302.07055 (2023).
[48] Noor Nashid, Mifta Sintaha, và Ali Mesbah. 2023. Lựa chọn Gợi ý Dựa trên Truy xuất cho Học Few-Shot Liên quan đến Mã. Trong Hội nghị Quốc tế IEEE/ACM lần thứ 45 năm 2023 về Kỹ thuật Phần mềm (ICSE) . IEEE.
[49] Ansong Ni, Srini Iyer, Dragomir Radev, Ves Stoyanov, Wen-tau Yih, Sida I Wang,
và Xi Victoria Lin. 2023. LEVER: Học cách Xác minh Tạo sinh Ngôn ngữ-to-Mã với Thực thi. arXiv preprint arXiv:2302.08468 (2023).
[50] Suphakit Niwattanakul, Jatsada Singthongchai, Ekkachai Naenudorn, và Supachanun Wanapu. 2013. Sử dụng hệ số Jaccard cho độ tương tự từ khóa.
Trong Kỷ yếu hội nghị đa quốc tế của các kỹ sư và nhà khoa học máy tính , Tập. 1. 380–384.
[51] Kishore Papineni, Salim Roukos, Todd Ward, và Wei-Jing Zhu. 2002. Bleu: một phương pháp cho đánh giá tự động của dịch máy. Trong Kỷ yếu cuộc họp thường niên lần thứ 40 của Hiệp hội Ngôn ngữ học Tính toán . 311–318.
[52] Hammond Pearce, Baleegh Ahmad, Benjamin Tan, Brendan Dolan-Gavitt, và
Ramesh Karri. 2022. Ngủ gật tại bàn phím? đánh giá bảo mật của các đóng góp mã của github copilot. Trong Hội nghị IEEE 2022 về Bảo mật và Quyền riêng tư
(SP). IEEE, 754–768.
[53] Michael Pradel và Koushik Sen. 2018. Deepbugs: Một phương pháp học để phát hiện lỗi dựa trên tên. Kỷ yếu ACM về Ngôn ngữ Lập trình 2,
OOPSLA (2018), 1–25.
[54] Julian Aron Prenner, Hlib Babii, và Romain Robbes. 2022. Codex của OpenAI có thể sửa lỗi không? một đánh giá trên QuixBugs. Trong Kỷ yếu Hội thảo Quốc tế lần thứ ba về Sửa chữa Chương trình Tự động . 69–75.
[55] Alec Radford, Karthik Narasimhan, Tim Salimans, và Ilya Sutskever. 2018. Cải thiện hiểu ngôn ngữ bằng tiền huấn luyện tạo sinh. (2018).
[56] Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang,
Michael Matena, Yanqi Zhou, Wei Li, và Peter J Liu. 2020. Khám phá giới hạn của học chuyển giao với một transformer văn bản-to-văn bản thống nhất. Tạp chí Nghiên cứu Học máy 21, 1 (2020), 5485–5551.
[57] Nils Reimers và Iryna Gurevych. 2019. Sentence-bert: Nhúng câu bằng mạng bert siamese. arXiv preprint arXiv:1908.10084 (2019).
[58] Paige Rodeghero, Collin McMillan, Paul W McBurney, Nigel Bosch, và Sidney
D'Mello. 2014. Cải thiện tóm tắt mã nguồn tự động thông qua nghiên cứu theo dõi mắt của lập trình viên. Trong Kỷ yếu hội nghị quốc tế lần thứ 36 về Kỹ thuật phần mềm . 390–401.
[59] Devjeet Roy, Sarah Fakhoury, và Venera Arnaoudova. 2021. Đánh giá lại các chỉ số đánh giá tự động cho nhiệm vụ tóm tắt mã. Trong Kỷ yếu Cuộc họp Chung ACM lần thứ 29 về Hội nghị Kỹ thuật Phần mềm Châu Âu và Hội nghị về Nền tảng Kỹ thuật Phần mềm . 1105–1116.
[60] Ohad Rubin, Jonathan Herzig, và Jonathan Berant. 2021. Học cách truy xuất gợi ý cho học tập trong ngữ cảnh. arXiv preprint arXiv:2112.08633 (2021).
[61] Freda Shi, Daniel Fried, Marjan Ghazvininejad, Luke Zettlemoyer, và Sida I
Wang. 2022. Dịch ngôn ngữ tự nhiên sang mã với thực thi. arXiv preprint
arXiv:2204.11454 (2022).
[62] Yao Wan, Zhou Zhao, Min Yang, Guandong Xu, Haochao Ying, Jian Wu, và
Philip S Yu. 2018. Cải thiện tóm tắt mã nguồn tự động thông qua học tăng cường sâu. Trong Kỷ yếu hội nghị quốc tế ACM/IEEE lần thứ 33 về kỹ thuật phần mềm tự động . 397–407.
[63] Chaozheng Wang, Yuanhang Yang, Cuiyun Gao, Yun Peng, Hongyu Zhang,
và Michael R. Lyu. 2022. Không Còn Tinh chỉnh? Một Đánh giá Thực nghiệm của Điều chỉnh Gợi ý trong Trí tuệ Mã. Trong Kỷ yếu Hội nghị Kỹ thuật Phần mềm Châu Âu ACM lần thứ 30 và Hội nghị về Nền tảng Kỹ thuật Phần mềm (Singapore, Singapore) (ESEC/FSE 2022) . Hiệp hội Máy tính, New York, NY, USA, 382–394. https://doi.org/10.1145/35
40250.3549113
[64] Wenhan Wang, Ge Li, Bo Ma, Xin Xia, và Zhi Jin. 2020. Phát hiện clone mã với mạng thần kinh đồ thị và cây cú pháp trừu tượng tăng cường luồng. Trong Hội nghị Quốc tế IEEE lần thứ 27 năm 2020 về Phân tích Phần mềm, Tiến hóa và Kỹ thuật lại
(SANER) . IEEE, 261–271.
[65] Wenhua Wang, Yuqun Zhang, Yulei Sui, Yao Wan, Zhou Zhao, Jian Wu, S Yu
Philip, và Guandong Xu. 2020. Tóm tắt mã nguồn hướng dẫn học tăng cường sử dụng chú ý phân cấp. Giao dịch IEEE về kỹ thuật phần mềm
48, 1 (2020), 102–119.
[66] Yanlin Wang, Ensheng Shi, Lun Du, Xiaodi Yang, Yuxuan Hu, Shi Han, Hongyu
Zhang, và Dongmei Zhang. 2021. Cocosum: Tóm tắt mã theo ngữ cảnh với mạng thần kinh đồ thị đa quan hệ. arXiv preprint arXiv:2107.01933
(2021).
[67] Yue Wang, Weishi Wang, Shafiq Joty, và Steven CH Hoi. 2021. Codet5: Các mô hình mã hóa-giải mã thống nhất được tiền huấn luyện nhận biết định danh cho hiểu và tạo sinh mã. arXiv preprint arXiv:2109.00859 (2021).
[68] Bolin Wei, Ge Li, Xin Xia, Zhiyi Fu, và Zhi Jin. 2019. Tạo sinh mã như một nhiệm vụ kép của tóm tắt mã. Tiến bộ trong hệ thống xử lý thông tin thần kinh
32 (2019).
[69] Bolin Wei, Yongmin Li, Ge Li, Xin Xia, và Zhi Jin. 2020. Truy xuất và tinh chỉnh: tạo sinh bình luận thần kinh dựa trên mẫu. Trong Kỷ yếu Hội nghị Quốc tế IEEE/ACM lần thứ 35 về Kỹ thuật Phần mềm Tự động . 349–360.
[70] Edmund Wong, Taiyue Liu, và Lin Tan. 2015. Clocom: Khai thác mã nguồn hiện có cho tạo sinh bình luận tự động. Trong Hội nghị Quốc tế IEEE lần thứ 22 năm 2015 về Phân tích Phần mềm, Tiến hóa, và Kỹ thuật lại (SANER) . IEEE, 380–389.
[71] Edmund Wong, Jinqiu Yang, và Lin Tan. 2013. Autocomment: Khai thác các trang câu hỏi và trả lời cho tạo sinh bình luận tự động. Trong Hội nghị Quốc tế IEEE/ACM lần thứ 28 năm 2013 về Kỹ thuật Phần mềm Tự động (ASE) . IEEE, 562–
567.
[72] Rui Xie, Wei Ye, Jinan Sun, và Shikun Zhang. 2021. Khai thác tên phương thức để cải thiện tóm tắt mã: Một phương pháp học đa nhiệm vụ thảo luận. Trong
Hội nghị Quốc tế IEEE/ACM lần thứ 29 năm 2021 về Hiểu Chương trình (ICPC) .
IEEE, 138–148.
[73] Wei Ye, Rui Xie, Jinglei Zhang, Tianxiang Hu, Xiaoyin Wang, và Shikun Zhang.
2020. Tận dụng tạo sinh mã để cải thiện truy xuất và tóm tắt mã thông qua học kép. Trong Kỷ yếu Hội nghị Web 2020 . 2309–2319.
[74] Chen Zeng, Yue Yu, Shanshan Li, Xin Xia, Zhiming Wang, Mingyang Geng,
Linxiao Bai, Wei Dong, và Xiangke Liao. 2022. deGraphCS: Nhúng Đồ thị Luồng Dựa trên Biến cho Tìm kiếm Mã Thần kinh. Giao dịch ACM về Kỹ thuật Phần mềm và Phương pháp (TOSEM) (2022).
[75] Juan Zhai, Xiangzhe Xu, Yu Shi, Guanhong Tao, Minxue Pan, Shiqing Ma, Lei
Xu, Weifeng Zhang, Lin Tan, và Xiangyu Zhang. 2020. CPC: Tự động phân loại và truyền bá bình luận ngôn ngữ tự nhiên thông qua phân tích chương trình. Trong
Kỷ yếu Hội nghị Quốc tế ACM/IEEE lần thứ 42 về Kỹ thuật Phần mềm. 1359–1371.
[76] Aiping Zhang, Liming Fang, Chunpeng Ge, Piji Li, và Zhe Liu. 2023. Transformer hiệu quả với bộ học token mã cho phát hiện clone mã. Tạp chí Hệ thống và Phần mềm 197 (2023), 111557.
[77] Jian Zhang, Xu Wang, Hongyu Zhang, Hailong Sun, và Xudong Liu. 2020.
Tóm tắt mã nguồn thần kinh dựa trên truy xuất. Trong Kỷ yếu
Hội nghị Quốc tế ACM/IEEE lần thứ 42 về Kỹ thuật Phần mềm . 1385–1397.
[78] Tianyi Zhang, Tao Yu, Tatsunori B Hashimoto, Mike Lewis, Wen-tau Yih, Daniel
Fried, và Sida I Wang. 2022. Sắp xếp lại Người đánh giá Mã cho Tạo sinh Mã.
arXiv preprint arXiv:2211.16490 (2022).

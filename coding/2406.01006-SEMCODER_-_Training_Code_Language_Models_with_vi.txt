# 2406.01006.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/coding/2406.01006.pdf
# Kích thước file: 2826514 bytes

===============================================
NỘI DUNG FILE PDF
===============================================

--- TRANG 1 ---
SEMCODER : Huấn luyện các Mô hình Ngôn ngữ Mã nguồn với
Lập luận Ngữ nghĩa Toàn diện
Yangruibo Ding
Đại học Columbia
yrbding@cs.columbia.eduJinjun Peng
Đại học Columbia
jinjun@cs.columbia.eduMarcus J. Min
Đại học Columbia
jm5025@columbia.edu
Gail Kaiser
Đại học Columbia
kaiser@cs.columbia.eduJunfeng Yang
Đại học Columbia
junfeng@cs.columbia.eduBaishakhi Ray
Đại học Columbia
rayb@cs.columbia.edu
Tóm tắt
Các Mô hình Ngôn ngữ Lớn về Mã nguồn (Code LLMs) đã xuất sắc trong các nhiệm vụ như hoàn thiện mã nhưng thường bỏ lỡ ngữ nghĩa sâu hơn như tác động thực thi và trạng thái động. Bài báo này nhằm thu hẹp khoảng cách giữa sự phụ thuộc của Code LLMs vào dữ liệu văn bản tĩnh và nhu cầu hiểu ngữ nghĩa cho các nhiệm vụ phức tạp như gỡ lỗi và sửa chữa chương trình. Chúng tôi giới thiệu một chiến lược mới, lập luận độc thoại, để huấn luyện Code LLMs lập luận về ngữ nghĩa toàn diện, bao gồm mô tả chức năng cấp cao, tác động thực thi cục bộ của các câu lệnh riêng lẻ, và hành vi đầu vào/đầu ra tổng thể, từ đó liên kết văn bản mã tĩnh với trạng thái thực thi động. Chúng tôi bắt đầu bằng việc thu thập PYX, một tập dữ liệu Python sạch gồm các mẫu mã có thể thực thi hoàn toàn với mô tả chức năng và trường hợp kiểm tra. Chúng tôi đề xuất huấn luyện Code LLMs không chỉ để viết mã mà còn để hiểu ngữ nghĩa mã bằng cách lập luận về các thuộc tính chính, ràng buộc và hành vi thực thi sử dụng ngôn ngữ tự nhiên, bắt chước việc gỡ lỗi bằng lời nói của con người, tức là gỡ lỗi rubber-duck. Cách tiếp cận này dẫn đến việc phát triển SEMCODER, một Code LLM chỉ với 6.7B tham số, cho thấy hiệu suất cạnh tranh với GPT-3.5-turbo trong các nhiệm vụ tạo mã và lập luận thực thi. SEMCODER đạt 79.3% trên HumanEval (GPT-3.5-turbo: 76.8%), 63.6% trên CRUXEval-I (GPT-3.5-turbo: 50.3%), và 63.9% trên CRUXEval-O (GPT-3.5-turbo: 59.0%). Chúng tôi cũng nghiên cứu hiệu quả của lập luận thực thi kiểu độc thoại của SEMCODER so với lập luận scratchpad cụ thể, cho thấy cách tiếp cận của chúng tôi tích hợp ngữ nghĩa từ nhiều chiều một cách mượt mà hơn. Cuối cùng, chúng tôi chứng minh tiềm năng áp dụng ngữ nghĩa đã học để cải thiện khả năng gỡ lỗi và tự cải tiến của Code LLMs. Dữ liệu, mã và mô hình của chúng tôi có sẵn tại: https://github.com/ARiSE-Lab/SemCoder.

1 Giới thiệu
Những tiến bộ gần đây trong các mô hình ngôn ngữ mã (Code LMs) [1–5] đã cách mạng hóa lĩnh vực lập trình [6–8]. Những mô hình này, được huấn luyện chủ yếu trên các tập dữ liệu lớn của văn bản liên quan đến lập trình như mã nguồn và docstrings [9], xuất sắc trong việc tự động hóa các nhiệm vụ như tạo mã.
Thật không may, sự phụ thuộc vào dữ liệu văn bản tĩnh hạn chế khả năng của các Code LMs hiện tại trong việc hiểu chương trình thực sự đang làm gì, đặc biệt là lập luận về ngữ nghĩa sâu hơn vốn có trong việc thực thi mã. Việc thiếu hiểu biết về ngữ nghĩa không ngạc nhiên khi thường dẫn đến hiệu suất kém trong việc gỡ lỗi và sửa chữa lỗi trong mã được tạo [10]. Code LMs gặp khó khăn với việc lập luận về ngữ nghĩa chương trình trong cả môi trường tĩnh và động. Trong môi trường tĩnh, thách thức nằm ở việc hiểu hành vi dự định của mã mà không chạy nó, đòi hỏi sự hiểu biết sâu sắc về cú pháp mã và các thuộc tính ngữ nghĩa tĩnh (ví dụ: đồ thị phụ thuộc chương trình, v.v.) [11,12]. Môi trường động bao gồm quan sát và diễn giải hành vi của mã trong quá trình thực thi, bao gồm theo dõi thay đổi biến, xác định lỗi thời gian chạy và phát hiện vấn đề hiệu suất [13]. Ngay cả khi các dấu vết thực thi được tiết lộ cho mô hình, [13] quan sát thấy Code LMs không thể tương tác hiệu quả với các thực thi thật, gặp khó khăn trong việc tận dụng các dấu vết thực thi động để gỡ lỗi.
Năm mươi năm trước, Terry Winograd đã hình dung ra lập trình viên AI tương lai: "Chìa khóa cho lập trình tương lai nằm ở những hệ thống hiểu những gì chúng đang làm [14]". Trong bài báo này, chúng tôi khám phá việc xây dựng một hệ thống lập trình như vậy, được hỗ trợ bởi các mô hình ngôn ngữ, không chỉ để viết chương trình mà còn để hiểu những gì chúng đang làm (hay còn gọi là ngữ nghĩa). Hiểu biết chính của chúng tôi là Code LMs nên bắt chước cách các nhà phát triển thực dụng làm việc: bắt đầu với các đặc tả tổng quát, chia chúng thành các nhiệm vụ con với các thuộc tính và ràng buộc mong đợi, triển khai mã từng dòng một trong khi lập luận về tác động của từng dòng, và kiểm tra tính đúng đắn tổng thể bằng cách xem xét các tác động thực thi [15]. Để đạt được điều này, chúng tôi giới thiệu một chiến lược mới để huấn luyện Code LMs lập luận về ngữ nghĩa chương trình toàn diện.

Chúng tôi huấn luyện SEMCODER, một Code LM có nhận thức ngữ nghĩa mới. Chúng tôi kết hợp các phương thức khác nhau của ngữ nghĩa chương trình: (i) Mô tả Chức năng Cấp cao: Chúng tôi huấn luyện SEMCODER để hiểu mô tả chức năng cấp cao theo hai chiều bằng cách vừa tạo mã từ ngôn ngữ tự nhiên vừa tóm tắt mã thành ngôn ngữ tự nhiên. Điều này bao gồm việc dạy mô hình nắm bắt mục đích của chương trình, giống như cách một nhà phát triển con người phác thảo ngữ nghĩa gần đúng cấp cao của phần mềm; (ii) Thuộc tính và Ràng buộc Chính: chúng tôi huấn luyện SEMCODER để trích xuất các thuộc tính chức năng và ràng buộc của chương trình, những thứ nên được duy trì cho tất cả các tình huống và trường hợp đặc biệt. (iii) Hành vi Thực thi Tổng thể: chúng tôi huấn luyện SEMCODER để hiểu tác động cục bộ của các câu lệnh mã riêng lẻ, nhận ra cách mỗi dòng ảnh hưởng đến biến, luồng điều khiển và sử dụng bộ nhớ. Bằng cách nắm bắt những tác động này, mô hình có thể dự đoán ngữ nghĩa thực thi mã tốt hơn. Chúng tôi huấn luyện mô hình để học cả ngữ nghĩa trừu tượng và cụ thể, dạy nó mục đích chung của một câu lệnh và minh họa bằng các ví dụ cụ thể.

Tuyển chọn Tập dữ liệu Mã có thể Thực thi Chúng tôi thu thập PYX, một tập dữ liệu tổng hợp nắm bắt ngữ nghĩa chương trình toàn diện với các mẫu mã có thể thực thi và kiểm tra đơn vị. Lấy cảm hứng từ các tập dữ liệu hiện có [16,17], chúng tôi sử dụng một LLM mạnh mẽ để tổng hợp các cặp NL-to-code. Để đảm bảo chất lượng, PYX chỉ bao gồm các mẫu có thể thực thi. Nó cũng tạo ra các kiểm tra đơn vị và dấu vết thực thi chi tiết, ghi lại trạng thái chương trình sau mỗi câu lệnh. Từ PYX, chúng tôi tiếp tục xây dựng một tập dữ liệu gỡ lỗi, PYX-R. PYX-R bao gồm các đoạn mã lỗi được tạo bởi Code LMs, các lý luận gỡ lỗi tương ứng, và các kế hoạch cải tiến [13] dẫn đến các bản vá. Bằng cách tinh chỉnh Code LMs trên PYX-R, chúng tôi nhằm phát triển các trợ lý lập trình gỡ lỗi và vá lỗi mã lỗi theo cách giống con người, thúc đẩy khả năng của Code LMs hiện tại trong lập trình lặp.

Học Ngữ nghĩa Chương trình Để học ngữ nghĩa chương trình, chúng tôi đề xuất lập luận độc thoại: Code LMs cố gắng hiểu và giải thích ngữ nghĩa mã cho chính chúng. Code LMs sẽ tóm tắt các chức năng chương trình, làm nổi bật các thuộc tính và ràng buộc chính, và lập luận thực thi mã từng bước, lấy cảm hứng từ gỡ lỗi rubber duck [15]. Lập luận thực thi mã sẽ được thực hiện theo hai hướng: (i) độc thoại tiến: SEMCODER sử dụng mã nguồn và đầu vào để mô phỏng thực thi bằng lời nói, giải thích tác động của từng dòng, các dòng được thực thi, thay đổi biến và đầu ra cuối cùng, và (ii) độc thoại lùi: cho đầu ra cuối cùng, SEMCODER lập luận về các trạng thái trước đó có thể có một cách trừu tượng, nắm bắt các đặc tính thiết yếu mà không cần liệt kê chính xác. Lập luận trừu tượng này rất quan trọng để hiểu các thao tác phức tạp như sắp xếp hoặc tổng hợp, nơi trạng thái trước đó không thể được xác định duy nhất. Nhìn chung, lập luận độc thoại trang bị cho Code LMs một sự hiểu biết giống con người về luồng điều khiển, chuyển đổi trạng thái và các thao tác phức tạp, thu hẹp khoảng cách giữa phân tích mã tĩnh và lập luận thực thi động.

Chúng tôi cho thấy rằng, bằng cách huấn luyện trên cách tiếp cận này, SEMCODER có thể tạo, lập luận về thực thi, gỡ lỗi và cải tiến mã một cách trực quan và hiệu quả hơn, đẩy các ranh giới của những gì Code LMs hiện tại có thể đạt được trong các nhiệm vụ kỹ thuật phần mềm khác nhau.

Hiệu suất của SEMCODER SEMCODER, dù chỉ có 6.7B tham số, thể hiện hiệu suất xuất sắc trong các nhiệm vụ tạo mã và lập luận thực thi, vượt qua các mô hình lớn hơn như GPT-3.5-turbo và nhiều mô hình mã nguồn mở khác. Đối với tạo mã, các biến thể SEMCODER đạt pass@1 79.3% trên HumanEval [1], vượt trội GPT-3.5-turbo với 76.8%, và với 27.5% trên LiveCodeBench-Lite [18], vượt trội GPT-3.5-turbo với 23.9%. Đối với lập luận thực thi, các biến thể SEMCODER ghi điểm 63.6%, 65.1%, 61.2% trên CRUXEval-I, CRUXEval-O, và LiveCodeBench-CodeExecution, tương ứng, vượt trội đáng kể các mô hình cơ sở bao gồm

--- TRANG 2 ---
GPT-3.5-turbo và thể hiện sự hiểu biết vượt trội về việc thực thi chương trình. Kỹ thuật lập luận độc thoại sáng tạo, nơi mô hình diễn đạt ngữ nghĩa mã từ các chức năng cấp cao đến chi tiết thực thi cấp thấp, cải thiện đáng kể lập luận thực thi, vượt trội các định dạng lập luận dấu vết hiện có như scratchpad [2] và NExT [13]. Cách tiếp cận lập luận độc thoại cũng cho phép SEMCODER xử lý linh hoạt ngữ nghĩa trừu tượng và trạng thái chương trình không xác định, điều mà các phương pháp hiện có gặp khó khăn. Ngoài ra, SEMCODER xuất sắc trong gỡ lỗi và tự cải tiến, cải thiện độ chính xác tạo mã một cách lặp đi lặp lại bằng cách tự gỡ lỗi rubber-duck bằng lời nói mà không cần truy vết động. Chúng tôi thực nghiệm tiết lộ rằng lập luận độc thoại tĩnh của SEMCODER có hiệu quả tương đương với việc đính kèm dấu vết thật [13] để sửa lỗi. Bên cạnh hiệu quả, lập luận độc thoại có những ưu điểm độc đáo theo thiết kế: (1) nó là lập luận hoàn toàn tĩnh và không yêu cầu truy vết động, (2) nó nén lập luận thực thi bằng cách tập trung vào các thuộc tính chính liên quan đến lỗi thay vì kiểm tra tất cả trạng thái chương trình dư thừa và giá trị biến cụ thể, và (3) nó cung cấp lời giải thích có thể đọc được cho con người để hiểu tốt hơn.

Đóng góp chính của chúng tôi là phát triển SEMCODER, một Code LM có nhận thức ngữ nghĩa được thiết kế để nâng cao hiểu biết và lập luận về ngữ nghĩa chương trình. Chúng tôi giới thiệu Lập luận Độc thoại, một cách tiếp cận lập luận mã mới kết nối mã nguồn tĩnh với hành vi thời gian chạy của nó thông qua mô tả chi tiết bằng lời về các thuộc tính mã và hành vi thời gian chạy. Để tiết lộ ngữ nghĩa chương trình toàn diện ở các cấp độ khác nhau, chúng tôi tuyển chọn PYX, một bộ sưu tập các mẫu mã có thể thực thi với mô tả chức năng và dấu vết thực thi. SEMCODER thể hiện hiệu suất vượt trội trong các nhiệm vụ tạo mã và lập luận thực thi, vượt qua các mô hình mã nguồn mở lớn hơn. SEMCODER cũng xuất sắc trong gỡ lỗi và tự cải tiến bằng cách tận dụng kiến thức từ việc huấn luyện có nhận thức ngữ nghĩa của nó. Công trình của chúng tôi nhấn mạnh tiềm năng tích hợp hiểu biết ngữ nghĩa sâu vào Code LMs để cải thiện hiệu quả của chúng trong các nhiệm vụ lập trình phức tạp.

2 Ngữ nghĩa Chương trình
Ngữ nghĩa chương trình đề cập đến ý nghĩa hoặc hành vi của một chương trình máy tính, mô tả những gì nó làm khi chạy, bao gồm xử lý đầu vào, tính toán và đầu ra [19,20]. Hiểu ngữ nghĩa chương trình là quan trọng để đảm bảo chương trình hoạt động đúng và đáp ứng mục đích dự định.

--- TRANG 3 ---
Hình 1: Chiến lược huấn luyện của SEMCODER với các phương thức khác nhau của ngữ nghĩa chương trình. Chúng tôi chỉ định mục tiêu tổng thể của một nhiệm vụ, tức là ngữ nghĩa gần đúng (hộp xanh), chẳng hạn như "truy xuất năng lượng tiềm năng của các nguyên tử và thực hiện sắp xếp" tiếp theo là giải pháp mã tương ứng (hộp hồng). Sau đó chúng tôi chú thích ngữ nghĩa mã trừu tượng như những thuộc tính và ràng buộc chính (hộp đỏ) được duy trì bất kể đầu vào. Ngoài ngữ nghĩa tĩnh, chúng tôi cũng ghép mã với các trường hợp kiểm tra, chẳng hạn như "Cho [10.5, 8.2, 10.5, 7.1, 8.2], trả về [3, 1, 0]". Chúng tôi tiếp tục chú thích ngữ nghĩa hoạt động động với các độc thoại tiến và lùi (hộp vàng, và thêm trong Phần 4.2). SEMCODER học từ tất cả thông tin để không chỉ tạo mã mà lập luận toàn diện về ngữ nghĩa của nó.

Ngữ nghĩa chương trình có thể được biểu diễn trong các phương thức khác nhau. Mô tả cấp cao phác thảo chức năng dự định của chương trình, trong khi ngữ nghĩa chi tiết mô tả các hành động và tác động phụ của mỗi dòng mã, bao gồm thao tác dữ liệu và thay đổi trạng thái. Sự hiểu biết chi tiết này giúp các nhà phát triển viết mã tốt hơn và hỗ trợ trong việc xem xét mã, gỡ lỗi và giao tiếp nhóm. Ngữ nghĩa chi tiết có thể là cụ thể hoặc trừu tượng. Ngữ nghĩa cụ thể (ví dụ: dấu vết chương trình) nắm bắt các tác động thực thi thực tế, trong khi ngữ nghĩa trừu tượng tập trung vào các mối quan hệ đầu vào-đầu ra chính và tác động chương trình tổng thể, trừu tượng hóa các chi tiết cấp thấp [21,22]. Theo tài liệu hiện có về ngữ nghĩa chương trình [19, 20], chúng tôi tuyển chọn các ngữ nghĩa sau.

Ngữ nghĩa Gần đúng mô tả các mục tiêu tổng thể của chương trình, thường được diễn đạt thông qua docstrings hoặc tài liệu [23, 24]. Những mô tả Ngôn ngữ Tự nhiên này cung cấp tổng quan về mục tiêu và kết quả dự kiến của chương trình, đảm bảo rằng việc triển khai phù hợp với các chức năng cấp cao dự định (hộp xanh trong Hình 1).

Ngữ nghĩa Ký hiệu đại diện cho chức năng và logic phức tạp theo cách mà cả con người và máy móc có thể diễn giải một cách nhất quán. Nó đề cập đến lớp ý nghĩa được rút ra từ các ký hiệu, cú pháp và cấu trúc của mã nguồn (hộp hồng trong Hình 1). Nó mô tả cách mã đại diện cho chức năng và logic cấp cao bằng cách tập trung vào những cấu trúc trong mã nguồn tượng trưng cho các hành vi, khái niệm hoặc thao tác cụ thể trong thiết kế chương trình.

Ngữ nghĩa Hoạt động mô tả cách các bước riêng lẻ trong mã nguồn thực thi [25,19,20]. Nó tập trung vào việc mô tả việc thực thi cụ thể của chương trình theo cách từng bước, chi tiết cách mỗi hành động biến đổi trạng thái của chương trình. Cách tiếp cận này đặc biệt hữu ích để lập luận về hành vi động của các ngôn ngữ lập trình (hộp vàng trong Hình 1).

Ngữ nghĩa Trừu tượng là cách mô tả hành vi chương trình ở mức độ trừu tượng cao hơn [26,27, 21,22]. Không giống như ngữ nghĩa cụ thể, cung cấp mô tả chi tiết về việc thực thi chương trình trên các đầu vào cụ thể, ngữ nghĩa trừu tượng tập trung vào các khía cạnh thiết yếu của hành vi chương trình trong khi bỏ qua các chi tiết cấp thấp. Cách tiếp cận này để lập luận về các thuộc tính và ràng buộc chương trình (hộp đỏ trong Hình 1) luôn được duy trì.

3 PYX: Tập dữ liệu Huấn luyện Có nhận thức Ngữ nghĩa
Nắm bắt ngữ nghĩa chương trình yêu cầu thực thi mã nguồn với các kiểm tra đơn vị. Các tập dữ liệu thế giới thực thách thức do cấu hình đa dạng, thiếu kiểm tra đơn vị và tài liệu hạn chế [28]. Do đó, chúng tôi sử dụng tập dữ liệu tổng hợp để nắm bắt ngữ nghĩa chương trình. Ở đây, chúng tôi chi tiết quá trình thu thập dữ liệu chất lượng cao để học ngữ nghĩa mã đa phương thức. Tương tự như [16,17], chúng tôi đầu tiên tổng hợp các cặp NL to Code. Sau đó, chúng tôi sử dụng trình thông dịch Python để lọc ra các mẫu khuyết tật, đảm bảo bao phủ ngữ nghĩa toàn diện. Xem Phụ lục F để biết thêm chi tiết và phân tích, bao gồm Hình 4 mô tả quy trình thu thập dữ liệu.

3.1 Tổng hợp Mã có thể Thực thi
Tổng hợp dữ liệu hướng dẫn (NL to code) với các LLM hiện có là phổ biến để có được các tập dữ liệu lớn cho việc tinh chỉnh hướng dẫn CodeLLMs [16,17]. Tuy nhiên, các phương pháp hiện tại không đảm bảo chất lượng của mã được tạo. Ví dụ, trong số 43.1k giải pháp Python từ [16], khoảng 11.6k (26.9%) không thể thực thi mặc dù có hướng dẫn tạo mã "đúng" và "độc lập" (Bảng 7 trong Phụ lục F hiển thị 10 loại lỗi hàng đầu). Để xây dựng SEMCODER, chúng tôi huấn luyện nó chỉ với dữ liệu có thể thực thi, vì dữ liệu tốt dẫn đến tạo tốt hơn [29,30]. Chúng tôi cải thiện quy trình tạo dữ liệu OSS-INSTRUCT [16], gợi ý một LLM tạo nhiệm vụ lập trình và giải pháp lấy cảm hứng từ một đoạn mã gốc. Thay vì lấy mẫu ngẫu nhiên các dòng từ các chương trình hiện có, chúng tôi phân tích chúng thành ASTs và lấy mẫu cây con để có được các gốc có thể phân tích. Chúng tôi thực thi mã được tạo, chỉ giữ lại các mẫu được thực thi thành công, và sử dụng khả năng gỡ lỗi của mô hình tạo để thử lại cho đến khi mã chạy đúng. Với sự giám sát chi phí thấp từ trình thông dịch Python, chúng tôi xây dựng một tập dữ liệu tinh chỉnh hướng dẫn chất lượng cao hơn để huấn luyện mô hình có nhận thức ngữ nghĩa. Bước I của Hình 4 trong Phụ lục F tóm tắt quá trình này. Bảng 2 trong Phụ lục F so sánh PYX của chúng tôi với OSS-INSTRUCT chi tiết.

3.2 Tập dữ liệu với Ngữ nghĩa Hoạt động
Chúng tôi chọn một tập con của PYX để xây dựng dữ liệu học lập luận thực thi (Xem Bước-II của Hình 4 trong Phụ lục F).

--- TRANG 4 ---
Hình 2: Độc thoại tiến mô phỏng việc thực thi từng bước, và độc thoại lùi suy luận các trạng thái chương trình trước đó bằng cách đưa ra giả định và kiểm tra với các ràng buộc quan sát được.

Lựa chọn Dữ liệu Chúng tôi áp dụng các tiêu chí lọc sau để chọn các chương trình có luồng thực thi sạch từ tập dữ liệu có thể thực thi của chúng tôi: (i) Chỉ bao gồm các chương trình không có tương tác tài nguyên bên ngoài (ví dụ: đầu vào bàn phím, thay đổi hệ thống file), vì biểu diễn dấu vết của chúng tôi chỉ nắm bắt thay đổi trạng thái biến. (ii) Các chương trình phải không có tính ngẫu nhiên, đảm bảo hành vi có thể dự đoán.

Tạo Đầu vào Tập dữ liệu có thể thực thi của chúng tôi thường có một hoặc hai đầu vào ví dụ mỗi chương trình. Để mô hình hóa ngữ nghĩa hoạt động chính xác và tránh thiên vị, chúng tôi cần một tập đầu vào đa dạng để tiết lộ các dấu vết thực thi khác nhau. Chúng tôi mở rộng tập đầu vào sử dụng đột biến nhận biết kiểu và tạo đầu vào dựa trên LLM, tương tự như [31] như được chi tiết trong Phụ lục F.

3.3 PYX-R: Huấn luyện Code LLMs để Gỡ lỗi Rubber-duck và Tự cải tiến
Chúng tôi xây dựng một tập dữ liệu gỡ lỗi, PYX-R, để huấn luyện Code LLMs cho gỡ lỗi và tự cải tiến, nhằm cải thiện khả năng lập trình lặp của chúng. Chúng tôi thu thập các giải pháp lỗi bằng cách lấy mẫu LLM cho các vấn đề trong PYX và giữ những phản hồi thất bại ít nhất một trong các kiểm tra. Chúng tôi thực hiện lấy mẫu từ chối với LLM để thu thập các lý luận gỡ lỗi rubber-duck cho các chương trình lỗi và tập đầu vào của chúng. PYX-R chỉ bao gồm những lý luận dẫn đến các bản vá đúng, được xác minh bằng kiểm tra khác biệt so với sự thật cơ sở. Chúng tôi cung cấp một ví dụ về dữ liệu PyX-R trong Phụ lục F.

4 SEMCODER: Học Ngữ nghĩa Toàn diện

4.1 Ngôn ngữ Tự nhiên sang Mã
Chúng tôi huấn luyện SEMCODER để dịch mô tả chức năng cấp cao thành mã có thể thực thi, được biết đến như nhiệm vụ ngôn ngữ tự nhiên sang mã [16,17]. Sử dụng các mẫu PYX, chúng tôi cung cấp mô tả vấn đề được định nghĩa rõ ràng chỉ định (1) mục tiêu tổng thể của nhiệm vụ, (2) ràng buộc triển khai, và (3) kết quả mong đợi với các trường hợp kiểm tra. Những mô tả này cung cấp cái nhìn tổng thể về nhiệm vụ, tạo nền tảng cho sự hiểu biết của mô hình.

4.2 Lập luận Độc thoại để Hiểu Toàn diện Ngữ nghĩa Mã
Chúng tôi huấn luyện SEMCODER để hiểu ngữ nghĩa mã thông qua lập luận độc thoại: Cho mã nguồn và đầu vào/đầu ra có thể thực thi, mô hình cần lập luận mã từ trừu tượng cấp cao đến chi tiết cấp thấp, từ góc độ tĩnh đến góc độ động. Lưu ý rằng mô tả ngôn ngữ tự nhiên gốc của vấn đề sẽ không được cung cấp để tạo độc thoại.

Đầu tiên, SEMCODER tóm tắt các chức năng cấp cao để hiểu ngữ nghĩa gần đúng. Sau đó, SEMCODER sẽ giải thích ngữ nghĩa trừu tượng như các thuộc tính và ràng buộc chính luôn được duy trì cho tất cả các thực thi. Cuối cùng, SEMCODER mô tả ngữ nghĩa hoạt động bằng cách diễn đạt thay đổi trạng thái trong quá trình thực thi cho đầu vào/đầu ra thực thi được cung cấp. Lấy cảm hứng từ gỡ lỗi rubber-duck, cách tiếp cận này giải thích chuyển đổi trạng thái chương trình mượt mà hơn các định dạng có cấu trúc như Scratchpad [32], tránh các trạng thái chương trình dư thừa (ví dụ: mảng numpy với hàng trăm phần tử) và giá trị cụ thể (ví dụ: số thực) trong khi tập trung vào các thuộc tính chính đóng góp vào hiểu biết mã. Chúng tôi chi tiết hiệu quả như vậy trong Phần 6.2. Chúng tôi cung cấp các độc thoại một phần để minh họa trong Hình 2 và độc thoại đầy đủ trong Phụ lục G.

--- TRANG 5 ---
4.2.1 Độc thoại Tiến
Chúng tôi cung cấp SEMCODER với mã nguồn và đầu vào, và nó học lập luận về ngữ nghĩa hoạt động bằng cách mô phỏng thực thi từng bước bằng lời nói và dự đoán đầu ra thực thi (Hình 2 hộp vàng).

Bao phủ Thực thi Để đảm bảo hiểu biết toàn diện, độc thoại tiến bao phủ những dòng có tác động phụ, đóng góp vào hiểu biết luồng điều khiển kỹ lưỡng và thực thi việc duyệt mã chi tiết, tương tự như quy trình gỡ lỗi của nhà phát triển.

Thứ tự Thực thi Tự nhiên Để bắt chước việc thực thi mã tự nhiên, độc thoại tiến theo thứ tự lập luận tự nhiên. Đối với vòng lặp, nó giải thích mỗi lần lặp với các giá trị cụ thể, xử lý các dòng được thực thi nhiều lần khác nhau. Điều này đảm bảo đường dẫn thực thi chính xác, nhận biết ngữ cảnh, tương tự như cách các nhà phát triển mô phỏng hành vi thực thi trong đầu, giúp phát hiện các vấn đề như vòng lặp vô hạn hoặc xử lý điều kiện không đúng.

Chuyển đổi Trạng thái Chương trình Hiểu tác động phụ của mã là quan trọng để nắm bắt sự tiến hóa trạng thái chương trình. Độc thoại tiến chỉ ra thay đổi trong giá trị biến khi một dòng được thực thi, nâng cao khả năng mô phỏng tác động thực thi thực tế. Sự tập trung vào tác động phụ này giúp nắm bắt ngữ nghĩa động, cung cấp lời giải thích chi tiết, từng bước về thay đổi trạng thái, do đó cải thiện gỡ lỗi và cải tiến dựa trên hành vi quan sát được.

Đầu ra Cuối cùng Cuối cùng, mô hình dự đoán đầu ra cuối cùng của chương trình sau khi giải thích quá trình thực thi để xác thực tính đúng đắn của logic trung gian.

4.2.2 Độc thoại Lùi
Trong khi thực thi tiến chủ yếu là xác định, trạng thái chương trình trước đó không thể luôn được xác định từ trạng thái hiện tại, chẳng hạn như một danh sách chưa sắp xếp từ phiên bản đã sắp xếp của nó. Do đó, chúng tôi thiết kế độc thoại lùi để linh hoạt trừu tượng (Xem Hình 2, hộp xanh).

Ràng buộc Trung gian Trừu tượng Trong lập luận độc thoại lùi của chúng tôi, chúng tôi sử dụng các ràng buộc trung gian trừu tượng khi các trạng thái chương trình trước đó không thể được xác định duy nhất từ trạng thái hiện tại, chẳng hạn như sau khi sắp xếp hoặc tổng hợp. Chúng tôi huấn luyện mô hình mô tả những ràng buộc này một cách trừu tượng. Sự trừu tượng này nắm bắt các đặc tính và mẫu thiết yếu, cho phép mô hình lập luận về nhiều trạng thái trước đó có thể có. Cách tiếp cận này nâng cao tính linh hoạt và khái quát hóa của mô hình, cải thiện khả năng xử lý các nhiệm vụ lập luận chương trình đa dạng và phức tạp.

Đầu vào Cụ thể Đối với một đầu ra cho trước, mô hình học dự đoán các giá trị đầu vào cụ thể thỏa mãn các ràng buộc trừu tượng đầu vào. Bước này thu hẹp khoảng cách giữa lập luận trừu tượng và thực thi cụ thể. Điều này đảm bảo nó hiểu các mẫu và có thể tạo ra các ví dụ thực tế, nâng cao tính mạnh mẽ cho các nhiệm vụ thế giới thực như gỡ lỗi và kiểm tra. Khả năng này phản ánh cách các nhà phát triển con người thực hiện lập luận ngược để gỡ lỗi [33].

4.2.3 Chú thích Độc thoại Sử dụng LLM
Để chú thích độc thoại cần thiết cho việc huấn luyện SEMCODER, chúng tôi sử dụng phương pháp lấy mẫu từ chối [34,35] thông qua một mô hình ngôn ngữ lớn. Chúng tôi tận dụng sức mạnh của LLM để tự động chú thích nhiều mẫu cho việc huấn luyện SEMCODER, trong khi chúng tôi có tiêu chuẩn vàng dựa trên thực thi để xác minh chất lượng của các độc thoại được chú thích, đảm bảo chúng có thông tin và giá trị, từ đó nâng cao khả năng lập luận về việc thực thi chương trình của SEMCODER cả tiến và lùi.

Đối với chú thích độc thoại tiến, chúng tôi đưa các mẫu mã từ tập dữ liệu PyX của chúng tôi vào một LLM, gợi ý nó tạo ra lời giải thích chi tiết về thay đổi trạng thái và logic chuyển đổi, kết thúc bằng dự đoán đầu ra cuối cùng. Sau đó chúng tôi thực thi mã; nếu đầu ra thực tế khớp với dự đoán của LLM, chúng tôi chấp nhận độc thoại, đảm bảo nó phản ánh chính xác việc thực thi chương trình. Nếu đầu ra không khớp, độc thoại bị từ chối. Phương pháp này đảm bảo độc thoại toàn diện và phù hợp để huấn luyện SEMCODER. Chúng tôi tuân theo chiến lược tương tự cho chú thích độc thoại lùi.

Để nâng cao quy trình chú thích độc thoại của chúng tôi, chúng tôi cung cấp cho LLM các ví dụ few-shot khi tạo độc thoại tiến và lùi. Những ví dụ này tuân theo các quy tắc được xác định của chúng tôi, chi tiết rõ ràng các dòng thực thi, thay đổi biến và các bước lập luận cho độc thoại tiến, và các ràng buộc trừu tượng với các ví dụ cụ thể cho độc thoại lùi. Hướng dẫn này đảm bảo LLM tuân thủ các bước lập luận có cấu trúc của chúng tôi. Chúng tôi cũng sử dụng hướng dẫn hệ thống để đảm bảo LLM tuân theo các quy trình được minh họa trong các ví dụ few-shot.

--- TRANG 6 ---
4.3 Huấn luyện Kết hợp với Ngữ nghĩa Toàn diện
SEMCODER được huấn luyện với dữ liệu kết hợp của các mẫu ngôn-ngữ-tự-nhiên-sang-mã, độc thoại tiến, và độc thoại lùi, sử dụng mục tiêu dự đoán token tiếp theo tiêu chuẩn [36]. Việc huấn luyện của chúng tôi có sự nhấn mạnh vào việc học ngữ nghĩa chương trình, nơi mất mát huấn luyện chỉ được tích lũy bởi mất mát cross-entropy trên các token mã và độc thoại cùng nhau. Chúng tôi cũng bao gồm tiền tố cụ thể cho nhiệm vụ như một phần của đầu vào mô hình để mô hình nhận thức tốt hơn về loại ngữ nghĩa chương trình nào nó nên học để nắm bắt và dự đoán cho mẫu hiện tại. Xem Phụ lục H cho các tiền tố cụ thể.

5 Thực nghiệm
Tạo Mã và Lập luận Thực thi Để đánh giá tạo mã, chúng tôi xem xét EvalPlus [31] và nhiệm vụ tạo mã trong LiveCodeBench-Lite (LCB-Lite viết tắt) [18]. Để lập luận thực thi, chúng tôi sử dụng CRUXEval [37] và nhiệm vụ thực thi mã trong LiveCodeBench (LCB-Exec viết tắt) [18]. Chúng tôi gợi ý các mô hình cơ sở thực hiện lập luận chuỗi suy nghĩ [38] được thúc đẩy bởi các ví dụ two-shot, và gợi ý zero-shot SEMCODER thực hiện lập luận độc thoại. Các suy luận đều tuân theo cài đặt gốc của benchmark.

Gỡ lỗi Rubber-duck và Tự cải tiến Chúng tôi đánh giá khả năng lập trình lặp trong một cài đặt tương tự như tự cải tiến/tự gỡ lỗi [39,40] —mô hình tạo mã, kiểm tra nó, gỡ lỗi rubber-duck giải pháp sai, và cải tiến mã của chúng dựa trên phân tích nguyên nhân gốc. Sử dụng EvalPlus [31], chúng tôi thực hiện năm lần cải tiến lặp sử dụng giải mã tham lam. Chúng tôi đánh giá mô hình với cả cài đặt gợi ý zero-shot và tinh chỉnh sử dụng PyX-R.

Mô hình SEMCODER tải phiên bản cơ sở 6.7B của DeepSeekCoder làm checkpoint ban đầu và tiếp tục tối ưu hóa nó với việc huấn luyện ngữ nghĩa chương trình được đề xuất. Tương tự như Magicoder [16], chúng tôi huấn luyện hai phiên bản của SEMCODER, phiên bản cơ sở và SEMCODER-S tiên tiến hơn. Phiên bản cơ sở của SEMCODER được huấn luyện hoàn toàn với PYX. SEMCODER-S tiên tiến được huấn luyện với tập dữ liệu mở rộng bao gồm PYX, Evol-instruct [16], và một phần CodeContest [41]. Evol-instruct là phiên bản đã được khử nhiễm của evol-codealpaca-v1 [42], chứa nhiều dữ liệu tuân theo hướng dẫn. Để tăng tính đa dạng của các vấn đề mã hóa, chúng tôi lấy mẫu các giải pháp từ CodeContest [41], dẫn đến 4.3k vấn đề với ít nhất một giải pháp đúng được tạo bởi LLM.

Cấu hình và Cài đặt Thực nghiệm Tất cả các biến thể SEMCODER được huấn luyện trong 2 epochs trên một máy chủ với tám GPU NVIDIA RTX A6000, sử dụng tốc độ học 5e-5 với suy giảm cosine xuống 5e-6 trong quá trình huấn luyện ngữ nghĩa chương trình. Để tinh chỉnh tự cải tiến, SEMCODER và các Code LLMs cơ sở được huấn luyện trong 2 epochs với tốc độ học 1e-5. Chúng tôi sử dụng kích thước batch 512, độ dài ngữ cảnh tối đa 2,048. Tương tự như [16], chúng tôi sử dụng GPT-3.5-turbo để tổng hợp các vấn đề mã hóa. Để giảm thiểu chi phí, chúng tôi sử dụng GPT-4o-mini để tạo giải pháp mã và văn bản lập luận độc thoại, thường là các chuỗi dài hơn so với mô tả vấn đề.

6 Đánh giá
6.1 Hiệu suất Tổng thể
Trong phần này, chúng tôi báo cáo hiệu suất tổng thể của SEMCODER cho các nhiệm vụ tạo mã và lập luận thực thi và so sánh với các Code LLMs cơ sở.

Cơ sở và Chỉ số Đánh giá Chúng tôi xem xét bốn họ Code LLMs mã nguồn mở làm cơ sở: Code Llama [4], StarCoder2 [5], DeepSeekCoder [3], và Magicoder [16]. Mặc dù SEMCODER chỉ có 6.7B tham số, chúng tôi bao gồm các biến thể 6.7B, 7B, và 13B, cả phiên bản cơ sở và instruct, nếu có sẵn công khai, tổng cộng 13 mô hình mã nguồn mở. Chúng tôi cũng so sánh SEMCODER với GPT-3.5-turbo cho tạo mã và lập luận thực thi để đo khoảng cách hiệu suất với các mô hình nguồn đóng. Kết quả được báo cáo với pass@1.

SEMCODER Đạt Hiệu suất Vượt trội trong Tạo Mã và Lập luận Thực thi Chúng tôi hiển thị kết quả đánh giá chính trong Bảng 1. SEMCODER báo cáo hiệu suất vượt trội trong lập luận thực thi, tốt hơn đáng kể so với các cơ sở mã nguồn mở khác, bao gồm những cái có

--- TRANG 7 ---
Bảng 1: Hiệu suất tổng thể của SEMCODER. Đối với tạo mã, các số bên ngoài và bên trong dấu ngoặc đơn "()" chỉ ra các phiên bản cơ sở và plus của EvalPlus, tương ứng. Tất cả kết quả được báo cáo với pass@1. CXEval chỉ ra CRUXEval, và LCB chỉ ra LiveCodeBench.

[Bảng hiển thị so sánh hiệu suất của các mô hình khác nhau]

2×nhiều tham số hơn. Chúng tôi cũng thu thập kết quả cho các mô hình lớn hơn (ví dụ: CodeLlama-34B) từ benchmark để so sánh với SEMCODER trong Bảng 6 Phụ lục.

So sánh SEMCODER với checkpoint ban đầu của nó, DeepSeekCoder-6.7B, chiến lược huấn luyện nặng về ngữ nghĩa của chúng tôi mang lại khả năng lập luận thực thi mạnh mẽ hơn nhiều, dẫn đến cải thiện tuyệt đối 23.0% cho dự đoán đầu vào và cải thiện tuyệt đối 23.9% và 23.6% cho CRUXEval-O và LCB-Exec, tương ứng. Đặc biệt, cả hai biến thể của SEMCODER đều vượt trội GPT-3.5-turbo cho lập luận thực thi với biên độ đáng kể.

SEMCODER cũng thể hiện hiệu suất đáng chú ý trong tạo mã: SEMCODER đạt 79.9 pass@1 trong MBPP, vượt trội tất cả các cơ sở mã nguồn mở, và phiên bản tiên tiến SEMCODER-S đạt pass@1 79.3 và 74.4 cho HumanEval cơ sở và plus, tương ứng, đánh bại đáng kể các mô hình khác, bao gồm GPT-3.5-turbo. Những kết quả ấn tượng này hỗ trợ tầm nhìn của Terry Winograd năm 1973 [14] rằng việc huấn luyện mô hình hiểu kỹ lưỡng các chương trình tạo ra các trợ lý lập trình đáng tin cậy và chính xác hơn.

Lập luận Thực thi Yêu cầu Hiểu biết Toàn diện về Ngữ nghĩa Mã Chúng tôi hiển thị kết quả dự đoán đầu vào/đầu ra không có lập luận trong Bảng 5 Phụ lục. Thú vị là, khi so sánh kết quả với lập luận vs. không có lập luận, chúng tôi thấy rằng chuỗi suy nghĩ tự do khó có thể giúp mô hình lập luận về thực thi, ngay cả khi nó tốn nhiều thời gian suy luận hơn để tạo nhiều token hơn. Ngược lại, lập luận độc thoại cải thiện đáng kể khả năng lập luận thực thi lên đến 21.7% cải thiện tuyệt đối trong dự đoán đầu ra. Điều này tiết lộ thực nghiệm rằng hiểu biết kỹ lưỡng về thực thi mã yêu cầu lập luận có hệ thống về ngữ nghĩa toàn diện.

6.2 Hiệu quả của Lập luận Độc thoại
Trong phần này, chúng tôi thực hiện các nghiên cứu loại bỏ để chứng minh hiệu quả của lập luận độc thoại.

Cơ sở Chúng tôi xem xét hai cách tiếp cận lập luận thực thi cơ sở: scratchpad [2] và định dạng dấu vết của NeXT [13]. NeXT thêm thứ tự số vào thay đổi trạng thái và bỏ qua các trạng thái vòng lặp trung gian. Chúng tôi cũng tạo một mẫu để nén các dấu vết thực thi, thay thế lập luận độc thoại bằng các trạng thái chương trình cụ thể. Các ví dụ có trong Phụ lục I. Ngoài ra, chúng tôi báo cáo kết quả gợi ý few-shot trên Code LM cơ sở sử dụng lập luận chuỗi suy nghĩ [38] không có dữ liệu lập luận thực thi của chúng tôi.

Thực nghiệm Chúng tôi đầu tiên xây dựng các định dạng khác nhau của lập luận thực thi sử dụng các mẫu PYX giống nhau để xây dựng độc thoại. Sau đó chúng tôi tinh chỉnh deepseek-coder-6.7b-base trên những

--- TRANG 8 ---
Bảng 2: Nghiên cứu loại bỏ cho dự đoán đầu vào và đầu ra với các loại lập luận thực thi khác nhau.

[Bảng hiển thị so sánh hiệu quả của các phương pháp khác nhau]

dữ liệu lập luận thực thi khác nhau này trong 3 epochs và so sánh kết quả của chúng về dự đoán đầu vào và đầu ra sử dụng CRUXEval.

Lập luận Độc thoại Hiệu quả hơn việc Học Trạng thái Chương trình Cụ thể Kết quả trong Bảng 2 cho thấy rằng, trong khi tất cả các cơ sở đều cải thiện lập luận thực thi, lập luận độc thoại của chúng tôi vượt trội chúng trong dự đoán đầu vào và đầu ra với biên độ rõ ràng. Lý do chính là các độc thoại mô tả chuyển đổi trạng thái một cách mượt mà bằng ngôn ngữ tự nhiên trong khi chỉ theo dõi các thuộc tính và giá trị chính, điều này dễ dàng hơn cho code LLMs học và hiểu và do đó nâng cao lập luận thực thi. Ngược lại, các cơ sở chỉ cung cấp các trạng thái cụ thể với thông tin và giá trị dư thừa trong khi không giải thích các mối quan hệ nhân quả của những chuyển đổi này, vì vậy code LLMs gặp khó khăn trong việc nắm bắt mối tương quan giữa chúng.

Khi chúng tôi kiểm tra thủ công các độc thoại, được cấu trúc để đảm bảo kết quả đúng (Phần 4.2.3), chúng tôi quan sát thấy logic trung gian đôi khi có thể bị sai lệch – mô hình đôi khi đưa ra các giả định sai về thuộc tính mã nhưng vẫn đạt được kết quả đúng. Ngược lại, tất cả các cơ sở được đảm bảo có các bước trung gian đúng, vì chúng là các dấu vết thực thi thực tế (Xem Phụ lục A cho hạn chế và công việc tương lai). Tuy nhiên, theo thực nghiệm, mô hình học hiệu quả hơn từ các độc thoại. Điều này nhấn mạnh lợi ích tiềm năng của việc nhấn mạnh tính đúng đắn của thuộc tính chính và định dạng dữ liệu thân thiện với mô hình khi huấn luyện kết hợp code LLMs với các ngữ nghĩa riêng biệt.

6.3 Gỡ lỗi và Tự cải tiến
Chúng tôi định dạng quy trình gỡ lỗi như việc giải thích bằng lời và tĩnh tại sao lỗi xảy ra [15] để đánh giá khả năng lập luận của code LMs thay vì khả năng sử dụng công cụ thực hiện thực thi động với bộ theo dõi hoặc trình gỡ lỗi. Sau đó mô hình nên sửa lỗi theo lập luận của chính nó, tức là tự cải tiến. Chúng tôi cung cấp một ví dụ trong Phụ lục F (Ví dụ-2) để minh họa cách thực hiện nhiệm vụ này.

Thực nghiệm Chúng tôi xem xét bốn code LMs tinh chỉnh hướng dẫn hiện đại làm cơ sở: Llama-3.1-Instruct-8B [43], DeepSeekCoder-Instruct-6.7B, Magicoder-DS-6.7B, và Magicoder-S-DS-6.7B. Chúng tôi đánh giá khả năng gỡ lỗi tĩnh và tự cải tiến của chúng trên EvalPlus với năm lần lặp. Chúng tôi đầu tiên đánh giá với gợi ý zero-shot và sau đó cũng tinh chỉnh với PYX-R để minh họa giá trị của nó.

Bảng 3: Hiệu suất của gỡ lỗi và tự cải tiến lặp

[Hai bảng hiển thị kết quả với gợi ý zero-shot và tinh chỉnh với PYX-R]

SEMCODER Báo cáo Hiệu suất Hứa hẹn trong Gỡ lỗi và Tự cải tiến Trong Bảng 3, SEMCODER-S vượt trội tất cả các cơ sở, đáng chú ý hơn trong cài đặt zero-shot. Kết quả này minh họa rằng lập luận độc thoại của SEMCODER bổ sung cho việc tinh chỉnh hướng dẫn đa mục đích với khả năng lập luận ngữ nghĩa mã. Phụ lục D chứng minh việc cải tiến mã liên tục của SEMCODER qua các lần lặp, thể hiện tiềm năng của ngữ nghĩa chương trình đã học cho các nhiệm vụ lập trình phức tạp.

--- TRANG 9 ---
PYX-R Cải thiện Khả năng Lập trình Lặp Tinh chỉnh Code LMs trên PYX-R cải thiện đáng kể hiệu suất lập trình lặp do lý luận gỡ lỗi kiểu độc thoại và các bản vá được căn chỉnh tốt. PYX-R giúp Code LMs hiểu và phân tích lỗi từ mã nguồn và dấu vết thực thi, nhằm truyền cảm hứng cho khả năng lập trình lặp tốt hơn. Chúng tôi nhận thấy rằng PYX-R cung cấp cải thiện hạn chế cho các biến thể SEMCODER và Llama-3.1-Inst, và chúng tôi suy đoán rằng những mô hình này đã được huấn luyện với lập luận chất lượng cao, và những lỗi thỉnh thoảng trong lý luận gỡ lỗi PyX-R hạn chế những mô hình này trở nên tốt hơn đáng kể (Xem Phụ lục A).

Lập luận Độc thoại vs. Dấu vết Thực thi để Gỡ lỗi Chúng tôi thực hiện các thực nghiệm bổ sung bằng cách thay thế phần lập luận độc thoại (Xem "### Mô phỏng Thực thi" trong Phụ lục F Ví dụ 2) trong lý luận gỡ lỗi bằng dấu vết thật, tuân theo định dạng của NExT [13] và tinh chỉnh code LMs lại. Kết quả có trong Phụ lục C.1. Chúng tôi nhận thấy rằng lập luận độc thoại có hiệu quả tương đương với việc đính kèm dấu vết thực thi. Bên cạnh hiệu quả, lập luận độc thoại có những ưu điểm độc đáo theo thiết kế: (1) nó là lập luận hoàn toàn tĩnh và không yêu cầu truy vết động, (2) nó nén lập luận thực thi bằng cách tập trung vào các thuộc tính chính liên quan đến lỗi thay vì kiểm tra tất cả trạng thái chương trình dư thừa và giá trị biến cụ thể, và (3) nó cung cấp lời giải thích có thể đọc được cho con người để hiểu tốt hơn.

7 Công trình Liên quan
Code LLMs và Dữ liệu Huấn luyện Nhiều Code LLMs mã nguồn mở, như CodeGen [44], StarCoder [45,5], Code Llama [4], và DeepSeek Coder [3], được đề xuất. Các mô hình chuyên biệt [32,1,41] cũng được phát triển cho các nhiệm vụ như tạo mã, tóm tắt, dự đoán đầu ra và lập trình cạnh tranh theo sau thành công của GPT-3 [46]. Những mô hình này chỉ được huấn luyện trên mã nguồn và văn bản liên quan, thiếu ngữ cảnh thực thi. Điều này hạn chế hiểu biết về ngữ nghĩa chương trình của chúng, dẫn đến các vấn đề bảo mật và thất bại gỡ lỗi. Chúng tôi nhằm thu hẹp khoảng cách này bằng cách huấn luyện Code LMs trên cả mã nguồn tĩnh và dấu vết thực thi động. Một hướng nghiên cứu trực giao tuyển chọn dữ liệu tuân theo hướng dẫn tổng hợp để nâng cao hiệu suất Code LLM. Code Alpaca [47] có 20k cặp hướng dẫn-phản hồi, Evol-Instruct-Code [17] mở rộng lên 80k cặp, và OSS-Instruct [16] bao gồm 75k cặp đa dạng từ tập dữ liệu Stack [9]. Tuy nhiên, những tập dữ liệu này tập trung vào các nhiệm vụ ngôn-ngữ-tự-nhiên-sang-mã với ít bao phủ về thực thi mã và giải pháp chưa được xác minh. Để cải thiện tính đúng đắn, Zheng et al. [48] tạo ra một tập dữ liệu cuộc trò chuyện nhiều lượt với thông báo lỗi trình biên dịch, và Wei et al. [49] kết hợp thực thi bằng cách tạo các trường hợp kiểm tra và lọc các cặp không hợp lệ. Tuy nhiên, không có tập dữ liệu nào bao gồm mô phỏng và hiểu dấu vết thực thi. Chúng tôi nhằm lấp đầy khoảng trống này (xem Phần 3).

Học và Lập luận về Thực thi Chương trình Trước LLMs, [50,51] dự đoán đầu ra chương trình đơn giản sử dụng RNNs, GNNs, transformers nhỏ và máy Turing thần kinh. Austin et al. [32] tinh chỉnh LLMs để dự đoán đầu ra thực thi với cải thiện hiệu suất tối thiểu. Các mô hình sớm dự đoán đầu ra cuối cùng mà không tiết lộ dấu vết thực thi. Nye et al. [2] giới thiệu phương pháp Scratchpad cho kết quả trung gian, và những người khác [52,53] tinh chỉnh UniXcoder [54] cho dấu vết thực thi nhưng không đánh giá cho các nhiệm vụ tạo mã. Chúng tôi tinh chỉnh một Code LLM để hiểu ngữ nghĩa chương trình, xuất sắc trong tạo mã, dự đoán đầu ra và dự đoán đầu vào (xem Phần 4).

Một cách tiếp cận khác sử dụng phản hồi thực thi để gỡ lỗi Code LLMs. Self-Debugging [39] cho thấy rằng lời giải thích ngôn ngữ tự nhiên hoặc kết quả kiểm tra đơn vị giúp tự cải tiến, nhưng dấu vết thực thi giảm hiệu suất. LeTI [55] và CYCLE [40] tinh chỉnh với phản hồi thực thi để cải thiện hiệu suất, đặc biệt cho các mô hình nhỏ hơn. NExT [13] tạo ra lý luận gỡ lỗi để giảm thiểu tác động tiêu cực của dấu vết thực thi. Công trình của chúng tôi cho thấy rằng một mô hình được huấn luyện về tạo mã, dự đoán đầu ra và dự đoán đầu vào xuất sắc trong việc hiểu phản hồi thực thi và tự cải tiến (xem Bảng 3).

8 Kết luận
Chúng tôi huấn luyện SEMCODER để đồng thời học các phương thức khác nhau của ngữ nghĩa chương trình: Gần đúng, Ký hiệu, Hoạt động và Trừu tượng. Chúng tôi cho thấy rằng việc huấn luyện kết hợp hướng ngữ nghĩa như vậy nuôi dưỡng hiểu biết toàn diện về ngữ nghĩa chương trình — SEMCODER hoặc SEMCODER-S đạt hiệu suất SOTA, trong số tất cả các mô hình mã nguồn mở dưới 15B, không chỉ trong tạo mã và dự đoán đầu vào/đầu ra mà còn các nhiệm vụ yêu cầu kiến thức sâu về cả mã nguồn và lập luận thực thi như gỡ lỗi và tự cải tiến.

--- TRANG 10 ---
Lời cảm ơn
Công trình này được hỗ trợ một phần bởi DARPA/NIWC-Pacific N66001-21-C-4018, nhiều giải thưởng Google Cyber NYC, một giải thưởng Columbia SEAS/EVPR Stimulus, NSF CNS–1845995, CNS-2247370, CCF-2221943, CCF-2313055, CCF-1845893, và CCF-2107405. Bất kỳ ý kiến, phát hiện, kết luận hoặc khuyến nghị nào được thể hiện ở đây là của các tác giả và không nhất thiết phản ánh quan điểm của DARPA hoặc NSF.

Tài liệu tham khảo
[1]Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, Alex Ray, Raul Puri, Gretchen Krueger, Michael Petrov, Heidy Khlaaf, Girish Sastry, Pamela Mishkin, Brooke Chan, Scott Gray, Nick Ryder, Mikhail Pavlov, Alethea Power, Lukasz Kaiser, Mohammad Bavarian, Clemens Winter, Philippe Tillet, Felipe Petroski Such, Dave Cummings, Matthias Plappert, Fotios Chantzis, Elizabeth Barnes, Ariel Herbert-V oss, William Hebgen Guss, Alex Nichol, Alex Paino, Nikolas Tezak, Jie Tang, Igor Babuschkin, Suchir Balaji, Shantanu Jain, William Saunders, Christopher Hesse, Andrew N. Carr, Jan Leike, Josh Achiam, Vedant Misra, Evan Morikawa, Alec Radford, Matthew Knight, Miles Brundage, Mira Murati, Katie Mayer, Peter Welinder, Bob McGrew, Dario Amodei, Sam McCandlish, Ilya Sutskever, và Wojciech Zaremba. Evaluating large language models trained on code, 2021.

[2]Maxwell Nye, Anders Johan Andreassen, Guy Gur-Ari, Henryk Michalewski, Jacob Austin, David Bieber, David Dohan, Aitor Lewkowycz, Maarten Bosma, David Luan, Charles Sutton, và Augustus Odena. Show your work: Scratchpads for intermediate computation with language models, 2021.

[3]Daya Guo, Qihao Zhu, Dejian Yang, Zhenda Xie, Kai Dong, Wentao Zhang, Guanting Chen, Xiao Bi, Y. Wu, Y. K. Li, Fuli Luo, Yingfei Xiong, và Wenfeng Liang. Deepseek-coder: When the large language model meets programming – the rise of code intelligence, 2024.

[4]Baptiste Rozière, Jonas Gehring, Fabian Gloeckle, Sten Sootla, Itai Gat, Xiaoqing Ellen Tan, Yossi Adi, Jingyu Liu, Romain Sauvestre, Tal Remez, Jérémy Rapin, Artyom Kozhevnikov, Ivan Evtimov, Joanna Bitton, Manish Bhatt, Cristian Canton Ferrer, Aaron Grattafiori, Wenhan Xiong, Alexandre Défossez, Jade Copet, Faisal Azhar, Hugo Touvron, Louis Martin, Nicolas Usunier, Thomas Scialom, và Gabriel Synnaeve. Code llama: Open foundation models for code, 2024.

[5]Anton Lozhkov, Raymond Li, Loubna Ben Allal, Federico Cassano, Joel Lamy-Poirier, Nouamane Tazi, Ao Tang, Dmytro Pykhtar, Jiawei Liu, Yuxiang Wei, Tianyang Liu, Max Tian, Denis Kocetkov, Arthur Zucker, Younes Belkada, Zijian Wang, Qian Liu, Dmitry Abulkhanov, Indraneil Paul, Zhuang Li, Wen-Ding Li, Megan Risdal, Jia Li, Jian Zhu, Terry Yue Zhuo, Evgenii Zheltonozhskii, Nii Osae Osae Dade, Wenhao Yu, Lucas Krauß, Naman Jain, Yixuan Su, Xuanli He, Manan Dey, Edoardo Abati, Yekun Chai, Niklas Muennighoff, Xiangru Tang, Muhtasham Oblokulov, Christopher Akiki, Marc Marone, Chenghao Mou, Mayank Mishra, Alex Gu, Binyuan Hui, Tri Dao, Armel Zebaze, Olivier Dehaene, Nicolas Patry, Canwen Xu, Julian McAuley, Han Hu, Torsten Scholak, Sebastien Paquet, Jennifer Robinson, Carolyn Jane Anderson, Nicolas Chapados, Mostofa Patwary, Nima Tajbakhsh, Yacine Jernite, Carlos Muñoz Ferrandis, Lingming Zhang, Sean Hughes, Thomas Wolf, Arjun Guha, Leandro von Werra, và Harm de Vries. Starcoder 2 and the stack v2: The next generation, 2024.

[6]GitHub. Github copilot: Your ai pair programmer. https://github.com/features/copilot , 2021.

[7]Amazon. Amazon codewhisperer: Your ai-powered productivity tool for the ide and command line. https://aws.amazon.com/codewhisperer/ , 2022.

[8] OpenAI. Chatgpt. https://chatgpt.com/ , 2022.

[9]Denis Kocetkov, Raymond Li, Loubna Ben Allal, Jia Li, Chenghao Mou, Carlos Muñoz Ferrandis, Yacine Jernite, Margaret Mitchell, Sean Hughes, Thomas Wolf, et al. The stack: 3 tb of permissively licensed source code. arXiv preprint arXiv:2211.15533, 2022.

--- TRANG 11 ---
[10] Alex Gu, Wen-Ding Li, Naman Jain, Theo X. Olausson, Celine Lee, Koushik Sen, và Armando Solar-Lezama. The counterfeit conundrum: Can code language models grasp the nuances of their incorrect generations?, 2024.

[11] Nathaniel Ayewah, William Pugh, David Hovemeyer, J. David Morgenthaler, và John Penix. Using static analysis to find bugs. IEEE Software, 25(5):22–29, 2008.

[12] Brittany Johnson, Yoonki Song, Emerson Murphy-Hill, và Robert Bowdidge. Why don't software developers use static analysis tools to find bugs? In 2013 35th International Conference onSoftware Engineering (ICSE), pages 672–681, 2013.

[13] Ansong Ni, Miltiadis Allamanis, Arman Cohan, Yinlin Deng, Kensen Shi, Charles Sutton, và Pengcheng Yin. Next: Teaching large language models to reason about code execution, 2024.

[14] Terry Winograd. Breaking the complexity barrier again. In Proceedings ofthe1973 Meeting onProgramming Languages andInformation Retrieval , SIGPLAN '73, page 13–30, New York, NY , USA, 1973. Association for Computing Machinery.

[15] Andrew Hunt và David Thomas. Thepragmatic programmer: from journeyman tomaster . Addison-Wesley Longman Publishing Co., Inc., USA, 2000.

[16] Yuxiang Wei, Zhe Wang, Jiawei Liu, Yifeng Ding, và Lingming Zhang. Magicoder: Source code is all you need. arXiv preprint arXiv:2312.02120, 2023.

[17] Ziyang Luo, Can Xu, Pu Zhao, Qingfeng Sun, Xiubo Geng, Wenxiang Hu, Chongyang Tao, Jing Ma, Qingwei Lin, và Daxin Jiang. Wizardcoder: Empowering code large language models with evol-instruct. arXiv preprint arXiv:2306.08568, 2023.

[18] Naman Jain, King Han, Alex Gu, Wen-Ding Li, Fanjia Yan, Tianjun Zhang, Sida Wang, Armando Solar-Lezama, Koushik Sen, và Ion Stoica. Livecodebench: Holistic and contamination free evaluation of large language models for code. arXiv preprint arXiv:2403.07974, 2024.

[19] Matthew Hennessy. The semantics ofprogramming languages: anelementary introduction using structural operational semantics. John Wiley & Sons, Inc., 1990.

[20] Glynn Winskel. Theformal semantics ofprogramming languages: anintroduction . MIT press, 1993.

[21] Carl A Gunter. Semantics ofprogramming languages: structures andtechniques . MIT press, 1992.

[22] Joseph E Stoy. Denotational semantics: theScott-Strachey approach toprogramming language theory. MIT press, 1981.

[23] Steve McConnell. Code complete. Pearson Education, 2004.

[24] David Thomas và Andrew Hunt. The Pragmatic Programmer: your journey tomastery . Addison-Wesley Professional, 2019.

[25] Gordon D Plotkin. Astructural approach tooperational semantics. Aarhus university, 1981.

[26] Flemming Nielson, Hanne R Nielson, và Chris Hankin. Principles ofprogram analysis . springer, 2015.

[27] Patrick Cousot và Radhia Cousot. Abstract interpretation: a unified lattice model for static analysis of programs by construction or approximation of fixpoints. In Proceedings ofthe4th ACM SIGACT-SIGPLAN symposium onPrinciples ofprogramming languages , pages 238– 252, 1977.

[28] Marcus J Min, Yangruibo Ding, Luca Buratti, Saurabh Pujar, Gail Kaiser, Suman Jana, và Baishakhi Ray. Beyond accuracy: Evaluating self-consistency of code llms. In TheTwelfth International Conference onLearning Representations, 2023.

--- TRANG 12 ---
[29] Suriya Gunasekar, Yi Zhang, Jyoti Aneja, Caio César Teodoro Mendes, Allie Del Giorno, Sivakanth Gopi, Mojan Javaheripi, Piero Kauffmann, Gustavo de Rosa, Olli Saarikivi, et al. Textbooks are all you need. arXiv preprint arXiv:2306.11644, 2023.

[30] Yue Yu, Yuchen Zhuang, Jieyu Zhang, Yu Meng, Alexander J Ratner, Ranjay Krishna, Jiaming Shen, và Chao Zhang. Large language model as attributed training data generator: A tale of diversity and bias. Advances inNeural Information Processing Systems, 36, 2024.

[31] Jiawei Liu, Chunqiu Steven Xia, Yuyao Wang, và Lingming Zhang. Is your code generated by chatgpt really correct? rigorous evaluation of large language models for code generation. Advances inNeural Information Processing Systems, 36, 2024.

[32] Jacob Austin, Augustus Odena, Maxwell Nye, Maarten Bosma, Henryk Michalewski, David Dohan, Ellen Jiang, Carrie Cai, Michael Terry, Quoc Le, et al. Program synthesis with large language models. ArXiv preprint, abs/2108.07732, 2021.

[33] Marcel Böhme, Ezekiel O. Soremekun, Sudipta Chattopadhyay, Emamurho Ugherughe, và Andreas Zeller. Where is the bug and how is it fixed? an experiment with practitioners. InProceedings ofthe2017 11th Joint Meeting onFoundations ofSoftware Engineering , ESEC/FSE 2017, page 117–128, New York, NY , USA, 2017. Association for Computing Machinery.

[34] George Casella, Christian P. Robert, và Martin T. Wells. Generalized accept-reject sampling schemes. Lecture Notes-Monograph Series, 45:342–347, 2004.

[35] Radford M. Neal. Slice sampling, 2000.

[36] Alec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, và Ilya Sutskever. Language models are unsupervised multitask learners. OpenAI preprint, 2019.

[37] Alex Gu, Baptiste Rozière, Hugh Leather, Armando Solar-Lezama, Gabriel Synnaeve, và Sida I. Wang. Cruxeval: A benchmark for code reasoning, understanding and execution. arXiv preprint arXiv:2401.03065, 2024.

[38] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed Chi, Quoc Le, và Denny Zhou. Chain-of-thought prompting elicits reasoning in large language models, 2023.

[39] Xinyun Chen, Maxwell Lin, Nathanael Schärli, và Denny Zhou. Teaching large language models to self-debug, 2023.

[40] Yangruibo Ding, Marcus J. Min, Gail Kaiser, và Baishakhi Ray. Cycle: Learning to self-refine the code generation, 2024.

[41] Yujia Li, David Choi, Junyoung Chung, Nate Kushman, Julian Schrittwieser, Rémi Leblond, Tom Eccles, James Keeling, Felix Gimeno, Agustin Dal Lago, et al. Competition-level code generation with alphacode. ArXiv preprint, abs/2203.07814, 2022.

[42] theblackcat102. The evolved code alpaca dataset. https://huggingface.co/datasets/ theblackcat102/evol-codealpaca-v1 , 2023.

[43] Meta Llama Team. The llama 3 herd of models, 2024.

[44] Erik Nijkamp, Bo Pang, Hiroaki Hayashi, Lifu Tu, Huan Wang, Yingbo Zhou, Silvio Savarese, và Caiming Xiong. Codegen: An open large language model for code with multi-turn program synthesis. In International Conference onLearning Representations, pages 1–25, 2023.

[45] Raymond Li, Loubna Ben Allal, Yangtian Zi, Niklas Muennighoff, Denis Kocetkov, Chenghao Mou, Marc Marone, Christopher Akiki, Jia Li, Jenny Chim, et al. Starcoder: may the source be with you! arXiv preprint arXiv:2305.06161, 2023.

--- TRANG 13 ---
[46] Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-V oss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, và Dario Amodei. Language models are few-shot learners. In Hugo Larochelle, Marc'Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, và Hsuan-Tien Lin, editors, Advances inNeural Information Processing Systems 33:Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual , pages 1–25, 2020.

[47] Sahil Chaudhary. Code alpaca: An instruction-following llama model for code generation. https://github.com/sahil280114/codealpaca , 2023.

[48] Tianyu Zheng, Ge Zhang, Tianhao Shen, Xueling Liu, Bill Yuchen Lin, Jie Fu, Wenhu Chen, và Xiang Yue. Opencodeinterpreter: Integrating code generation with execution and refinement, 2024.

[49] Yuxiang Wei, Federico Cassano, Jiawei Liu, Yifeng Ding, Naman Jain, Harm de Vries, Leandro von Werra, Arjun Guha, và Lingming Zhang. Starcoder2-instruct: Fully transparent and permissive self-alignment for code generation, 2024.

[50] Wojciech Zaremba và Ilya Sutskever. Learning to execute, 2015.

[51] Alex Graves, Greg Wayne, và Ivo Danihelka. Neural turing machines, 2014.

[52] Chenxiao Liu, Shuai Lu, Weizhu Chen, Daxin Jiang, Alexey Svyatkovskiy, Shengyu Fu, Neel Sundaresan, và Nan Duan. Code execution with pre-trained language models, 2023.

[53] Yangruibo Ding, Benjamin Steenhoek, Kexin Pei, Gail Kaiser, Wei Le, và Baishakhi Ray. Traced: Execution-aware pre-training for source code. In Proceedings ofthe46th IEEE/ACM International Conference onSoftware Engineering, pages 1–12, 2024.

[54] Daya Guo, Shuai Lu, Nan Duan, Yanlin Wang, Ming Zhou, và Jian Yin. Unixcoder: Unified cross-modal pre-training for code representation. arXiv preprint arXiv:2203.03850, 2022.

[55] Xingyao Wang, Hao Peng, Reyhaneh Jabbarvand, và Heng Ji. Leti: Learning to generate from textual interactions, 2024.

[56] Hunter Lightman, Vineet Kosaraju, Yuri Burda, Harrison Edwards, Bowen Baker, Teddy Lee, Jan Leike, John Schulman, Ilya Sutskever, và Karl Cobbe. Let's verify step by step. In The Twelfth International Conference onLearning Representations, 2024.

[57] bigcode-project/bigcode-dataset. https://github.com/bigcode-project/ bigcode-dataset . (Truy cập ngày 17/05/2024).

--- TRANG 14 ---
A Hạn chế và Công việc Tương lai
Giám sát Quy trình cho Các Bước Lập luận Trung gian Chúng tôi xem xét thủ công các độc thoại trong PYX và lý luận gỡ lỗi rubber-duck trong PYX-R, được cấu trúc để đảm bảo kết quả đúng (xem Phần 4.2.3). Trong khi các câu trả lời cuối cùng là chính xác, chúng tôi quan sát thấy rằng các bước lập luận trung gian đôi khi bị sai lệch. Đôi khi, mô hình đưa ra các giả định không đúng về thuộc tính mã nhưng vẫn đạt được kết quả đúng, tức là đầu vào/đầu ra thực thi đúng và bản vá đúng. Về mặt khái niệm, những sai lầm tinh tế trong các bước lập luận trung gian có thể có tác động tiêu cực đến việc cải thiện hơn nữa khả năng lập luận mã của mô hình.

Chúng tôi khuyến khích công việc tương lai đề xuất các phương pháp giám sát quy trình tự động và hiệu quả [56] đặc biệt cho lập luận mã, điều này sẽ hữu ích để cải thiện hơn nữa chất lượng độc thoại trong PYX.

Tuyển chọn Chú thích Độc thoại Dữ liệu chú thích độc thoại (Phần 4.2.3) rất quan trọng để SEMCODER xuất sắc trong các nhiệm vụ dự đoán đầu ra và dự đoán đầu vào. Tuy nhiên, chúng tôi dựa vào một LLM mạnh mẽ hơn, GPT-3.5-Turbo hoặc GPT-4o-mini để tạo ra những chú thích này và sử dụng lấy mẫu từ chối từ các phản hồi của nó, vì mô hình cơ sở của chúng tôi tương đối nhỏ với 6.7B tham số.

Chúng tôi khuyến khích công việc tương lai thử việc huấn luyện kết hợp hướng ngữ nghĩa của chúng tôi trên một mô hình cơ sở lớn hơn, để có thể tạo ra các chú thích độc thoại sử dụng chính mô hình cơ sở như Ni et al. [13] đã làm để bootstrap lập luận chất lượng cao cho tự cải tiến.

Kết hợp Lập luận Thực thi vào Tạo Mã Chúng tôi chứng minh rằng việc huấn luyện trên các nhiệm vụ dự đoán đầu vào và đầu ra có lợi gián tiếp cho cả tạo mã từ ngôn-ngữ-tự-nhiên và các nhiệm vụ tiếp theo như tự cải tiến. Tuy nhiên, có một cách trực tiếp hơn để cải thiện hơn nữa hiệu suất trong tạo mã và tự cải tiến — chúng ta có thể yêu cầu mô hình đầu tiên tự xác minh giải pháp của chính mình bằng cách tạo độc thoại tiến (Phần 4.2.1) cho các trường hợp kiểm tra được đưa ra trong đặc tả ngôn ngữ tự nhiên trước khi hoàn thiện giải pháp.

Chúng tôi khuyến khích công việc tương lai khám phá khả năng sử dụng khả năng lập luận thực thi của chính mô hình để hỗ trợ trực tiếp quá trình tạo mã và tự cải tiến của nó.

B Tác động Rộng hơn
Tác động Xã hội Trong công trình này, chúng tôi huấn luyện các Code LMs có nhận thức ngữ nghĩa. Chúng tôi công khai tất cả dữ liệu, mã và checkpoint mô hình. Sản phẩm có thể được sử dụng để triển khai các trợ lý lập trình tự động cải thiện năng suất của các nhà phát triển. Có thể nhưng không chắc rằng các Code LMs sẽ tạo ra mã lỗi hoặc sai, nhưng chúng tôi đề xuất sử dụng các mô hình của chúng tôi như "copilot" để hỗ trợ các nhà phát triển con người thay vì hoàn toàn dựa vào mô hình để tự động hóa hoàn toàn.

Biện pháp Bảo vệ Dữ liệu của chúng tôi được tổng hợp sử dụng một LLM thương mại, tức là GPT-3.5-turbo, đã được căn chỉnh bởi công ty phát hành, OpenAI, để tránh rò rỉ thông tin cá nhân hoặc độc hại. Chúng tôi coi dữ liệu của chúng tôi có rủi ro tối thiểu bị lạm dụng do bản năng tổng hợp của nó.

C Thêm Kết quả Đánh giá
C.1 Gỡ lỗi và Tự cải tiến với Dấu vết Thực thi Thật

Bảng 4: Gỡ lỗi và tự cải tiến với dấu vết thật theo định dạng của NExT [13].

[Bảng hiển thị kết quả so sánh]

--- TRANG 15 ---
C.2 Dự đoán Đầu vào/Đầu ra Không có Lập luận
Trong Bảng 5, chúng tôi trình bày kết quả của dự đoán trực tiếp cho đầu vào và đầu ra thực thi không có lập luận.

Bảng 5: Hiệu suất của dự đoán trực tiếp cho đầu vào/đầu ra thực thi không có lập luận.

[Bảng hiển thị kết quả so sánh các mô hình]

C.3 So sánh với Các Mô hình Mã nguồn Mở Lớn hơn và Mô hình Nguồn Đóng

Bảng 6: Hiệu suất tổng thể của SEMCODER so với các Code LLMs khác. Đối với tạo mã, các số bên ngoài và bên trong dấu ngoặc đơn "()" chỉ ra các phiên bản cơ sở và plus của EvalPlus, tương ứng. Đối với lập luận thực thi, phía trái và phía phải của dấu gạch chéo "/" chỉ ra dự đoán trực tiếp và dự đoán với lập luận, tương ứng. Tất cả kết quả được báo cáo với pass@1.

[Bảng hiển thị so sánh chi tiết với các mô hình lớn hơn]

D SEMCODER Liên tục Cải tiến Chất lượng Mã
Chúng tôi nghiên cứu độ chính xác tạo mã của SEMCODER ở mỗi bước cải tiến với các nhiệt độ khác nhau. Kết quả được vẽ trong Hình 3. Chúng tôi quan sát thấy rằng SEMCODER có khả năng liên tục cải tiến các lỗi của chính mình, và sự gia tăng không dừng lại khi nhiệt độ cao, điều này cho thấy SEMCODER có khả năng gỡ lỗi và tự cải tiến mạnh mẽ và nhiệt độ cao tận dụng tốt hơn những khả năng đó cho lập trình lặp.

--- TRANG 16 ---
(a) HumanEval (b) MBPP
Hình 3: Hiệu suất zero-shot của SEMCODER-S trong tự cải tiến ở mỗi bước thời gian với các chiến lược lấy mẫu khác nhau.

E Phân tích Khả năng Thực thi của OSS-INSTRUCT
Bảng 7: 10 loại lỗi hàng đầu của mã Python không thể thực thi trong OSS-Instruct[16]

[Bảng hiển thị các loại lỗi và số lượng trường hợp]

Chúng tôi thực thi tất cả các mẫu Python trong OSS-INSTRUCT [16] để phân tích khả năng thực thi của chúng. Để có kết quả chính xác hơn, chúng tôi cố gắng giảm thiểu ModuleNotFoundError bằng cách cài đặt 75 phụ thuộc thiếu hàng đầu theo kết quả chạy trước. Bảng 7 hiển thị phân tích của 10 loại lỗi hàng đầu.

F Chi tiết về PYX
Toàn bộ pipeline thu thập dữ liệu được hiển thị trong Hình 4. Ở đây chúng tôi cũng ghi lại thêm chi tiết về PYX.

Prompt cho Tổng hợp Dữ liệu Chúng tôi tuân theo prompt trong OSS-INSTRUCT cho tổng hợp dữ liệu, nhưng với hai sửa đổi: 1) Đối với thiết kế vấn đề, hướng dẫn mô hình tránh tương tác với tài nguyên bên ngoài hoặc yêu cầu thư viện bên thứ ba không phổ biến để tăng xác suất có được mã có thể thực thi. 2) Đối với việc đưa ra giải pháp, hướng dẫn mô hình hiển thị quá trình suy nghĩ trước khi viết mã để tạo ra ngôn ngữ tự nhiên được căn chỉnh hơn cùng với mã trong tập dữ liệu. Bảng 10 chi tiết các prompt của chúng tôi với một ví dụ trong PYX.

Mở rộng Tập Đầu vào Để mở rộng tập đầu vào, chúng tôi đầu tiên khởi tạo corpus đầu vào với tất cả các đầu vào hợp lệ đã biết. Sau đó, đối với đột biến nhận biết kiểu, chúng tôi thay đổi các đầu vào đã biết dựa trên heuristics cụ thể theo kiểu. Đối với tạo dựa trên LLM, chúng tôi gợi ý mô hình với hàm và một số đầu vào đã biết để tạo thêm. Chúng tôi xác minh các đầu vào mới bằng cách thực thi chúng, chỉ giữ lại những đầu vào thực thi thành công mà không có ngoại lệ. Chúng tôi xen kẽ giữa đột biến nhận biết kiểu và tạo dựa trên LLM cho đến khi đạt ngưỡng được xác định trước, kết hợp hiệu quả của đột biến với tính mạnh mẽ của tạo LLM. Các đầu vào được tạo và đầu ra của chúng phục vụ như các kiểm tra đơn vị cho nhiệm vụ được mô tả bằng NL trong các bước tiếp theo.

--- TRANG 17 ---
[Hình 4: PYX: Chiến lược Thu thập Dữ liệu Huấn luyện Có nhận thức Thực thi]

Bảng 8: So sánh giữa OSS-INSTRUCT và PYX của chúng tôi.

[Bảng hiển thị so sánh các chỉ số]

Bao phủ Đầu vào Phương pháp tạo đầu vào của chúng tôi chỉ xem xét tính đa dạng về mặt giá trị biến nhưng không cố gắng thực hiện đầy đủ các đường dẫn thực thi khác nhau trong mã có thể thực thi, như những gì kiểm tra hướng bao phủ thường làm. Tuy nhiên, tập dữ liệu của chúng tôi chỉ bao gồm các chương trình hàm đơn tương đối ngắn không có các nhánh phức tạp. Chúng tôi thấy rằng các đầu vào được tạo của chúng tôi có thể đạt được bao phủ nhánh trung bình và bao phủ dòng trung bình lần lượt là 93%, 96%, cho thấy cách tiếp cận của chúng tôi nhẹ nhưng hiệu quả cho cài đặt hiện tại.

Mã gốc Có thể Phân tích và Thực thi Được Một điểm khác biệt đáng chú ý giữa OSS-INSTRUCT và PYX là chúng tôi chỉ chọn mã gốc có thể phân tích để lấy mẫu các thách thức lập trình và giải pháp mã, dẫn đến tỷ lệ thu hoạch hơi cao hơn cho mã có thể thực thi. Chúng tôi cũng cố gắng định lượng tác động của sự khác biệt này, và kết quả trong Bảng 8. Chúng ta có thể thấy rằng việc huấn luyện trên PYX chỉ hoạt động tốt hơn một chút so với OSS-INSTRUCT và tập con Python của nó. Do đó, chúng tôi kết luận rằng việc huấn luyện chỉ với mã có thể thực thi không nhất thiết cải thiện hiệu suất ngôn ngữ tự nhiên sang mã, nhưng công việc của chúng tôi yêu cầu tính năng này để tiết lộ ngữ nghĩa đầy đủ của mã.

Khử trùng Dữ liệu Chúng tôi tuân theo quy trình khử nhiễm dữ liệu của [16] và [57] để làm sạch tập dữ liệu của chúng tôi. Để kiểm tra sự tương đồng giữa tập dữ liệu tinh chỉnh hướng dẫn của chúng tôi và các benchmark kiểm tra, chúng tôi đánh giá "độ tương đồng chỉnh sửa" giữa chúng, cụ thể bằng cách chia tỷ lệ chỉ số fuzz.partial_token_sort_ratio được cung cấp bởi thư viện fuzz. Đối với mỗi mẫu trong tập dữ liệu của chúng tôi, độ tương đồng của nó với một benchmark được tính như độ tương đồng cosine tối đa với bất kỳ mẫu nào trong benchmark. Chúng tôi áp dụng cùng phân tích cho OSS-INSTRUCT để so sánh. Hình 5 cho thấy rằng độ tương đồng giữa tập dữ liệu của chúng tôi và hai benchmark ngang bằng với OSS-INSTRUCT, nơi phần lớn có độ tương đồng dưới 0.4, cho thấy rằng việc cải thiện hiệu suất do tập dữ liệu của chúng tôi mang lại không phải từ rò rỉ dữ liệu hoặc bắt chước dữ liệu benchmark.

Danh mục Để nghiên cứu tác động của việc lọc khả năng thực thi, chúng tôi phân loại tất cả các mẫu trong tập dữ liệu của chúng tôi theo [16] được hiển thị bởi Hình 6. So với OSS-INSTRUCT, phân phối danh mục thay đổi bằng cách tăng các vấn đề thuật toán và cấu trúc dữ liệu, các vấn đề khoa học dữ liệu và máy học, và các vấn đề toán học và tính toán, và giảm các danh mục còn lại, điều này được mong đợi vì các tương tác với tài nguyên bên ngoài thường được yêu cầu trong các tình huống như cơ sở dữ liệu, thiết kế web và UI không được phép trong môi trường thực thi của chúng tôi.

--- TRANG 18 ---
[Hình 5: Độ tương đồng chỉnh sửa giữa PYX và hai benchmark phổ biến]

[Hình 6: Phân phối danh mục của PYX]

Thống kê Dữ liệu Chúng tôi thực hiện khử nhiễm trên PYX, và các mẫu độc thoại (chúng tôi loại bỏ các mẫu chia sẻ cùng cặp đầu vào và đầu ra với CRUXEval). PYX bao gồm 32,489 cặp ngôn ngữ tự nhiên sang mã. Chúng tôi tạo ra 29,945 độc thoại tiến và 31,022 độc thoại lùi sử dụng lấy mẫu từ chối. SEMCODER được huấn luyện với 93.4k mẫu, và SEMCODER-S với 214.1k mẫu. PYX-R chứa 18,473 mẫu gỡ lỗi, mỗi mẫu với mô tả gốc, mã lỗi, lý luận gỡ lỗi và bản vá cuối cùng.

Ví dụ 1: Một ví dụ về tạo mẫu PYX

[Đưa ra ví dụ chi tiết về prompt và phản hồi mô hình]

Ví dụ 2: Một ví dụ về gỡ lỗi rubber-duck và sửa lỗi PYX-R

[Đưa ra ví dụ chi tiết về quy trình gỡ lỗi]

--- TRANG 19 ---
[Tiếp tục ví dụ về quy trình gỡ lỗi với lý luận chi tiết]

--- TRANG 20 ---
[Phần cuối của ví dụ gỡ lỗi với mã đã sửa]

--- TRANG 21 ---
[Tiếp tục với mã đã sửa và ví dụ về lập luận độc thoại]

G Ví dụ Chi tiết về Độc thoại
Chúng tôi cung cấp các ví dụ cho lập luận độc thoại tiến và lùi chi tiết.

Ví dụ Lập luận Độc thoại

[Đưa ra ví dụ chi tiết về mã và độc thoại tiến]

--- TRANG 22 ---
[Tiếp tục ví dụ độc thoại tiến]

--- TRANG 23 ---
[Ví dụ về độc thoại lùi]

--- TRANG 24 ---
[Tiếp tục ví dụ độc thoại lùi]

--- TRANG 25 ---
H Tiền tố Cụ thể cho Nhiệm vụ
Chúng tôi thêm các tiền tố cụ thể cho nhiệm vụ vào các mẫu huấn luyện để hướng dẫn mô hình thực hiện các loại lập luận ngữ nghĩa khác nhau.

[Liệt kê các tiền tố cho từng loại nhiệm vụ]

--- TRANG 26 ---
[Tiếp tục các tiền tố và ví dụ về định dạng dấu vết cơ sở]

I Định dạng Dấu vết Cơ sở
Chúng tôi trình bày các định dạng dấu vết cơ sở như chúng tôi đã thảo luận và so sánh trong Phần 6.2.

[Đưa ra các ví dụ về định dạng dấu vết khác nhau: Scratchpad, NeXT Scratchpad, và Concise Trace]

--- TRANG 27 ---
[Kết thúc với định dạng dấu vết ngắn gọn]

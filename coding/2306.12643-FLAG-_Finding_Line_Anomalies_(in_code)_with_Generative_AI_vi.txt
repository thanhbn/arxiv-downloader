# 2306.12643.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/coding/2306.12643.pdf
# Kích thước tệp: 599702 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
FLAG: Tìm kiếm Bất thường Dòng (trong mã) với AI Sinh tạo
Baleegh Ahmad
Đại học New YorkBenjamin Tan
Đại học CalgaryRamesh Karri
Đại học New York
Hammond Pearce
Đại học New South Wales

Tóm tắt
Mã chứa các lỗi bảo mật và chức năng. Quá trình xác định và định vị chúng là khó khăn và dựa vào lao động con người. Trong công trình này, chúng tôi trình bày một phương pháp mới lạ (FLAG) để hỗ trợ các nhà gỡ lỗi con người. FLAG dựa trên khả năng từ vựng của AI sinh tạo, cụ thể là các Mô hình Ngôn ngữ Lớn (LLM). Ở đây, chúng tôi nhập một tệp mã sau đó trích xuất và tái tạo từng dòng trong tệp đó để tự so sánh. Bằng cách so sánh mã gốc với phiên bản thay thế được LLM tạo ra, chúng tôi có thể đánh dấu những khác biệt đáng chú ý như các bất thường để kiểm tra thêm, với các tính năng như khoảng cách từ bình luận và độ tin cậy của LLM cũng hỗ trợ việc phân loại này. Điều này giảm không gian tìm kiếm kiểm tra cho nhà thiết kế. Không giống như các phương pháp tự động khác trong lĩnh vực này, FLAG không phụ thuộc vào ngôn ngữ, có thể hoạt động trên mã không hoàn chỉnh (và thậm chí không biên dịch được) và không yêu cầu tạo ra các thuộc tính bảo mật, kiểm tra chức năng hoặc định nghĩa quy tắc. Trong công trình này, chúng tôi khám phá các tính năng giúp LLM trong việc phân loại này và đánh giá hiệu suất của FLAG trên các lỗi đã biết. Chúng tôi sử dụng 121 điểm chuẩn trên C, Python và Verilog; với mỗi điểm chuẩn chứa một điểm yếu bảo mật hoặc chức năng đã biết. Chúng tôi tiến hành các thí nghiệm sử dụng hai LLM hiện đại nhất trong code-davinci-002 và gpt-3.5-turbo của OpenAI, nhưng phương pháp của chúng tôi có thể được sử dụng bởi các mô hình khác. FLAG có thể xác định 101 trong số các khiếm khuyết và giúp giảm không gian tìm kiếm xuống 12−17% mã nguồn.

1 Giới thiệu
Lỗi xảy ra trong mã khi có sự khác biệt giữa ý định của nhà phát triển và việc triển khai của họ. Những lỗi này có thể gây ra các lỗ hổng bảo mật hoặc thiếu sót chức năng. Việc tìm ra chúng là một quá trình tốn công sức—mặc dù các công cụ hỗ trợ tồn tại, chúng thường chỉ hoạt động khi các chương trình đã hoàn thành hoàn toàn (hoặc ít nhất có thể biên dịch được), và sẽ chỉ tập trung vào một tập hợp con của ngôn ngữ hoặc lớp lỗi. Do đó, trong quá trình phát triển, các nhà phát triển và nhóm của họ nên thường xuyên kiểm tra công việc của mình, và do đó các phương pháp sẽ kết hợp đánh giá thủ công với kiểm tra tự động [4], phân tích tĩnh [8], và fuzzing [20] để giúp xác định các vấn đề tiềm ẩn. Mã phải được kiểm tra theo các ý định được nắm bắt một cách nội tại, rõ ràng trong trường hợp các tạo phẩm như kiểm tra, khẳng định, hoặc quy tắc (ví dụ, truy vấn khi sử dụng CodeQL [18]) hoặc ngầm định (khi thực thi mã để tìm sự cố trong fuzzing).

Cho rằng các trường hợp mã lỗi hiếm gặp so với mã đúng (mã công nghiệp trung bình được ước tính chứa 0,5 và 25 lỗi trên 1.000 dòng [24]), chúng tôi giả định rằng ý định của nhà phát triển chủ yếu được nắm bắt trong mã nguồn và bình luận với những sai sót thỉnh thoảng cần được tìm ra và xử lý. Hãy tưởng tượng một nhà phát triển muốn xem xét mã của họ một cách thủ công; nếu một chương trình chỉ bao gồm một vài dòng mã và bình luận, điều này có lẽ khả thi cho cả người mới bắt đầu và chuyên gia. Khi các dự án phát triển, điều này trở nên ngày càng thách thức do quy mô. Việc tìm cách thu hẹp các khu vực có vấn đề tiềm ẩn trong mã để xem xét có thể giúp các nhà phát triển, đặc biệt là dưới áp lực thời gian. Liệu ý định của mã nguồn và bình luận có thể được sử dụng để đánh dấu các vấn đề trong mã, thu hẹp phạm vi đánh giá thủ công cần thiết? Để trả lời điều này, chúng tôi điều tra việc sử dụng AI Sinh tạo, cụ thể là các mô hình ngôn ngữ lớn (LLM), để FLAG các bất thường trong mã.

LLM như GPT-3 [5] và Codex [7] thể hiện khả năng đáng kể cho một số nhiệm vụ từ vựng bao gồm viết mã. Chúng tạo ra đầu ra dựa trên sự tiếp tục của đầu vào của chúng—một loại 'tự động hoàn thành thông minh'. Những đầu vào này có thể là mã và bình luận hiện có, và các mô hình sẽ tạo ra mã phù hợp có xác suất cao. Điều này mang lại một khả năng thú vị: nếu (a) các dòng mã lỗi là thiểu số trong những dòng có mặt, và (b) phần lớn mã phù hợp với ý định của tác giả, liệu có khả thi để sử dụng LLM để đo lường xem một dòng mã nhất định có phải là ngoại lệ không? Nếu vậy, đây là một dấu hiệu mạnh mẽ rằng dòng đó là bất thường và có khả năng bị lỗi.

Sử dụng trực giác này, chúng tôi đề xuất một phương pháp mới lạ trong đó chúng tôi sử dụng LLM để tạo ra các dòng mã thay thế cho mã và bình luận hiện có; những phiên bản thay thế này được so sánh với mã của nhà phát triển để xác định các khác biệt tiềm ẩn. Công trình gần đây đã thúc đẩy việc khám phá LLM, cả về tác động của chúng đối với bảo mật (ví dụ, trong việc giới thiệu lỗ hổng [26] và nghiên cứu người dùng [33]) và việc sử dụng chúng để cải thiện bảo mật (ví dụ, sửa chữa lỗi [27]). Công trình này cung cấp những hiểu biết bổ sung về việc liệu LLM có thể được sử dụng để giúp xác định lỗi cả dưới dạng lỗ hổng bảo mật và thiếu sót chức năng. Đóng góp của chúng tôi như sau:

• Chúng tôi đề xuất FLAG, một khung cho việc sử dụng mới lạ LLM trong việc phát hiện lỗi bằng cách so sánh mã gốc với mã được LLM tạo ra. Chi tiết về các kỹ thuật được sử dụng trong công cụ được đề cập trong Phần 3.

• Chúng tôi khám phá các tính năng của mã nguồn và thông tin từ LLM để phân loại mã là lỗi hoặc không. Hiệu quả của những tính năng này được phân tích bằng cách thực hiện các thí nghiệm cho các LLM chính trong nhiều chế độ khác nhau trên nhiều ngôn ngữ trong Phần 5, với thảo luận thêm trong Phần 6.

• Công cụ và kết quả được mở nguồn tại [32].

2 Bối cảnh
Trong phần này, chúng tôi thảo luận về phát hiện lỗi, cách LLM hoạt động và thông tin có sẵn trong mã nguồn mà LLM có thể sử dụng. Điều này truyền đạt động lực tại sao FLAG cần thiết trước khi thảo luận chi tiết về việc triển khai của nó trong Phần 3.

2.1 Mô hình Ngôn ngữ Lớn (LLM)
LLM (bao gồm GPT-2 [30], GPT-3 [5], và Codex [7]) dựa trên kiến trúc Transformer [40]. Chúng có thể được coi là "các mô hình dự đoán chuỗi có thể mở rộng" [7] có khả năng thực hiện một loạt các nhiệm vụ từ vựng. Khi được cung cấp một lời nhắc bao gồm một chuỗi token, chúng tạo ra tập hợp token có xác suất cao nhất để tiếp tục hoặc hoàn thành chuỗi, tương tự như một tính năng tự động hoàn thành thông minh. Trong bối cảnh này, token đề cập đến các chuỗi thông thường dài khoảng bốn ký tự và được gán một định danh duy nhất trong kích thước từ vựng do người dùng định nghĩa. Mã hóa cặp byte (BPE) [15] này cho phép LLM xử lý một lượng lớn văn bản trong cửa sổ đầu vào có kích thước cố định của chúng. Do đó, hầu hết LLM hoạt động trên token thay vì các ký tự riêng lẻ.

Một khi được đào tạo trên các ví dụ phù hợp, một LLM có thể được sử dụng để điền vào phần thân của một hàm dựa trên chữ ký và/hoặc bình luận của nó [7]. Trong trường hợp các mô hình thương mại mà chúng tôi chọn để điều tra, kho ngữ liệu này được tạo thành từ hàng tỷ dòng mã nguồn mở được thu thập từ internet (ví dụ GitHub). LLM có kích thước và khả năng khác nhau. Trong công trình này, chúng tôi đánh giá 2 LLM của OpenAI, code-davinci-002 và gpt-3.5-turbo. code-davinci-002 là một mô hình Codex được tối ưu hóa cho các nhiệm vụ hoàn thành mã. Chúng tôi sử dụng nó trong hai chế độ hoàn thành, không có và có hậu tố, được gọi là tự động hoàn thành và chèn, tương ứng. gpt-3.5-turbo cải thiện trên GPT-3 và có thể hiểu cũng như tạo ra ngôn ngữ tự nhiên hoặc mã. Chúng tôi sử dụng nó trong hai chế độ, không có hướng dẫn nào hoặc với hướng dẫn tạo ra dòng mã tiếp theo, được gọi là tự động hoàn thành và hoàn thành có hướng dẫn tương ứng.

2.2 Vai trò của bình luận
Bình luận trong mã thường bị bỏ qua cho phân tích mã tĩnh. Điều này là do chất lượng của bình luận rất thay đổi, và chúng không đóng vai trò trong chức năng thực tế của chương trình. Tuy nhiên, chúng là một nguồn tài liệu tốt cho hành vi dự định của chương trình [36]. Giống như một con người sử dụng bình luận để suy luận về mã, các công cụ như LLM cũng sở hữu khả năng tương tự.

Một số nỗ lực đã sử dụng bình luận trong việc cố gắng phát hiện điểm yếu trong mã. Công trình liên quan nhất là icomment [37] sử dụng Xử lý Ngôn ngữ Tự nhiên để tự động phân tích bình luận và phát hiện sự không nhất quán giữa bình luận và mã nguồn. Họ lý luận rằng những sự không nhất quán này có thể chứa lỗi vì bình luận đúng nhưng việc triển khai mã tương ứng sai. Mặt khác, mã có thể đúng, nhưng bình luận kém. icomment lấy bình luận và tạo thành quy tắc cho mã nguồn để vượt qua. Việc thất bại của những quy tắc này được báo cáo như sự không nhất quán. Một công trình liên quan khác là @tComment [38] tập trung vào bình luận Javadoc. Họ sử dụng cùng một hiểu biết về sự không nhất quán giữa bình luận và mã để lấy các tệp mã nguồn cho Java để suy ra các thuộc tính cho các phương thức và sau đó tạo ra các kiểm tra ngẫu nhiên cho những phương thức này. Việc thất bại của những kiểm tra này được báo cáo như sự không nhất quán. FLAG lấy hiểu biết về sự không nhất quán giữa bình luận và mã nhưng thay vì tạo ra quy tắc hoặc kiểm tra, tạo ra mã thay thế để so sánh với mã gốc. Hơn nữa, FLAG sử dụng mã trước đó cộng với bình luận cho hoạt động của nó.

2.3 Phát hiện lỗi
Các trình phát hiện tĩnh được sử dụng trong nhiều hình thức khác nhau trên nhiều công ty phần mềm. Chúng thường được sử dụng trong giai đoạn phát triển trước khi triển khai để bắt lỗi trong mã. Error Prone của Google [29] bắt các lỗi lập trình thông thường trong Java. Infer của Facebook [19] làm điều tương tự cho mã Java và C/C++/Objective C. Và các công cụ nổi tiếng khác bao gồm SpotBugs [35] và CodeQL [18]. Chúng thường hoạt động bằng cách tiến hành phân tích trên Cây Cú pháp Trừu tượng (AST) và/hoặc biểu đồ luồng dữ liệu của mã [16]. Những cấu trúc này được duyệt qua với một tập hợp các trình kiểm tra phức tạp được sử dụng để chỉ ra hành vi không đúng của mã ví dụ, CodeQL có thể được sử dụng để tạo ra một truy vấn kiểm tra xem có tồn tại một đường dẫn giữa hai nút mà không nên có hay không. Hành vi không đúng này có thể là một mẫu trong AST hoặc một số luồng trong biểu đồ luồng dữ liệu. Các trình phát hiện cũng có thể suy ra quy tắc từ lịch sử phiên bản và bình luận mã nguồn. Trong khi các trình phát hiện tĩnh có thể tổng quát hóa trên các cơ sở dữ liệu của cùng một ngôn ngữ, chúng yêu cầu tạo ra một tập hợp lớn các mẫu và luồng lỗi đã biết để phát hiện lỗi. Hơn nữa, chúng chỉ có thể tìm ra lỗi trong cơ sở kiến thức hạn chế này về các mẫu và luồng.

Kiểm tra đơn vị là phương pháp khác thường được sử dụng trong cuộc đấu tranh để xác định các khiếm khuyết trong mã [14, 31]. Thách thức rõ ràng với kiểm tra đơn vị là yêu cầu nghiêm ngặt về kiến thức về chức năng của chương trình. Giải pháp được sử dụng là phát triển các kiểm tra đơn vị được tạo tự động. Phạm vi bao phủ mã thông qua phương pháp này vẫn hạn chế, và ngay cả khi có phạm vi bao phủ, các lỗi đôi khi không được tiết lộ [34]. Ngoài ra, kiểm tra đơn vị không phục vụ cho việc khẳng định bảo mật của mã.

2.4 Trình phát hiện dựa trên Học máy
Các nhà nghiên cứu đã sử dụng các kỹ thuật dựa trên mô hình ngôn ngữ để cố gắng phát hiện lỗi. Bugram [41] sử dụng các mô hình Ngôn ngữ N-gram để có được các chuỗi cho token trong các chương trình. Những chuỗi token này được khám phá theo xác suất của chúng trong mô hình đã học, và những cái có xác suất thấp hơn được đánh dấu là lỗi có thể xảy ra. Hoppity [13] là một phương pháp dựa trên học tập dựa vào các biến đổi đồ thị để phát hiện và sửa lỗi. Mô hình đồ thị của mã nguồn được sử dụng để đưa ra một loạt dự đoán về vị trí của các nút lỗi và các chỉnh sửa đồ thị tương ứng để tạo ra một bản sửa. EnSpec [6] là một phương pháp sử dụng entropy mã (một chỉ số được thiết kế để đại diện cho tính tự nhiên của mã có nguồn gốc từ một mô hình ngôn ngữ thống kê) để định vị lỗi. Họ sử dụng trực giác rằng mã lỗi có xu hướng có entropy cao hơn để tạo điều kiện cho việc định vị. Trong một công trình khác, các giải pháp của lỗi và một mô hình ngôn ngữ dựa trên mạng bộ nhớ ngắn hạn dài (LSTM) được sử dụng để phát hiện lỗi [39]. Các nhà nghiên cứu của công trình này đã đào tạo mô hình của họ trên Aizu Online Judge (AOJ) [3], chứa hàng triệu dòng mã nguồn.

Gần đây hơn, LLM đã được khám phá cho mục đích này. Sự khác biệt giữa LLM và các mô hình ngôn ngữ khác là kích thước dữ liệu đào tạo và độ phức tạp của mạng. FuzzGPT [11] sử dụng LLM như các fuzzer trường hợp cạnh bằng cách chuẩn bị LLM để tạo ra các chương trình bất thường để fuzzing. Đầu tiên, họ cho phép LLM học trực tiếp từ các lỗi báo cáo lịch sử và sau đó tạo ra các đoạn mã kích hoạt lỗi tương tự để tìm ra lỗi mới. Họ sử dụng các mô hình Codex và CodeGen để phát hiện lỗi trong các thư viện DL phổ biến PyTorch và TensorFlow. Trong một công trình khác, Li et al. [21] cho thấy cách ChatGPT có thể được sử dụng thông qua prompting khác biệt để phát hiện lỗi trong cơ sở dữ liệu Quixbugs [22]. Điều này bao gồm việc tạo ra các thiết kế tham chiếu cho một vấn đề sử dụng ChatGPT. Đối với một đầu vào kiểm tra nhất định, nếu các thiết kế tham chiếu tạo ra cùng một đầu ra, nhưng phiên bản lỗi tạo ra một đầu ra khác, trường hợp kiểm tra được xác định là trường hợp kiểm tra gây ra thất bại. DeepBugs [28] sử dụng các yếu tố ngôn ngữ tự nhiên trong mã để triển khai một công cụ phát hiện lỗi học máy dựa trên tên. Ý tưởng chính là chuyển đổi tên hàm và định danh thành embeddings được học bởi mạng để bảo tồn thông tin ngữ nghĩa. Họ áp dụng phương pháp của mình cho một kho tài liệu JavaScript. Trong khi những nỗ lực này là một bước tiến trong việc sử dụng LLM để phát hiện lỗi, chúng hoặc nhắm vào một tập hợp con thích hợp của mã hoặc yêu cầu thông tin như trường hợp kiểm tra cho một chương trình. Khả năng của LLM để sửa lỗi không được đánh giá một cách tổng quát, tức là, không sử dụng thông tin hoặc kiến thức nào bên ngoài mã nguồn.

2.5 Tại sao FLAG?
Những hạn chế được đề cập cho các trình phát hiện tĩnh và trình phát hiện học máy để lại chỗ cho một công cụ không yêu cầu nỗ lực lớn để thiết lập quy tắc bảo mật và kiểm tra và có thể áp dụng trên nhiều ngôn ngữ lập trình. Thông qua các thí nghiệm khác nhau của chúng tôi, chúng tôi đã chứng minh rằng phương pháp kiểm tra của chúng tôi không phụ thuộc vào ngôn ngữ mã. Những hiểu biết của chúng tôi có thể được sử dụng để tận dụng các LLM có sẵn hoạt động trên nhiều ngôn ngữ khác nhau để cung cấp phản hồi mã. FLAG cũng không yêu cầu mã phải được biên dịch hoặc thậm chí đúng cú pháp, cho phép nó hoạt động trên mã không hoàn chỉnh. Điều này cho phép kiểm tra lỗ hổng ở các giai đoạn thiết kế sớm hơn so với các trình kiểm tra tĩnh truyền thống. Ngoài ra, FLAG không yêu cầu tạo ra quy tắc bảo mật và kiểm tra. Đây là một lợi thế lớn vì các kiểm tra bảo mật về bản chất là không đầy đủ và yêu cầu rất nhiều thời gian và chuyên môn lĩnh vực để thiết kế. Điều này đặc biệt đúng đối với phần cứng nơi các công cụ chính thức đã được chứng minh là thất bại trong việc phát hiện rất nhiều lỗi bảo mật RTL [12].

3 Phương pháp FLAG
Trình kiểm tra tính nhất quán FLAG dựa vào khả năng độc đáo của LLM để viết mã. Nó có phương pháp được hiển thị trong Hình 1. Đối với mỗi dòng trong mã nguồn, FLAG tạo ra một lời nhắc tương ứng bao gồm phần mã trước dòng (tiền tố) và tùy chọn, mã sau dòng mã (hậu tố). Lời nhắc bao gồm mã và bình luận là đầu vào cho LLM, LLM xuất ra một dòng mã hoặc bình luận. Dòng được tạo ra này được so sánh với dòng gốc để tạo ra các tính năng được sử dụng trong việc phân loại dòng gốc là lỗi hoặc không. Những tính năng này cung cấp hoặc là một ước tính định lượng về sự khác biệt giữa hai dòng hoặc mức độ tin cậy của dòng được LLM tạo ra. Chúng được thảo luận trong Phần 3.3. Các dòng được phân loại là có khả năng lỗi được đánh dấu cho nhà thiết kế. Luồng FLAG cho một dòng nhất định có quy trình 4 bước gồm tạo lời nhắc, tạo dòng, trích xuất tính năng và phân loại.

Để bắt đầu kiểm tra tính nhất quán trên một tệp, chúng ta phải cung cấp cho FLAG một dòng để bắt đầu kiểm tra. Điều này được thực hiện để cung cấp cho LLM đủ bối cảnh để bắt đầu tạo ra mã và bình luận có liên quan. Thông thường, chúng tôi đưa ra số dòng bắt đầu sau các định nghĩa tiêu đề, bình luận ban đầu và khai báo các mô-đun và tín hiệu nội bộ. Trong một số trường hợp, khi khiếm khuyết là một phần của các tín hiệu được khai báo, chúng tôi tạo ra một ngoại lệ để bắt đầu từ đầu tệp. Ngoài ra, tệp được tiền xử lý để bỏ qua các dòng trống và để xác định xem có bình luận nào hiện diện trước dòng để bắt đầu kiểm tra hay không.

3.1 Tạo lời nhắc
Tạo lời nhắc lấy mã nguồn và dòng cần được phân loại làm đầu vào và tạo ra lời nhắc làm đầu ra. Lời nhắc này được gửi đến LLM để tạo dòng. Một ví dụ được hiển thị trong Hình 2a. Tệp được hiển thị từ nguồn C1 cho khiếm khuyết chứa CWE-125. Lời nhắc được tạo cho dòng 12 bao gồm tiền tố bao phủ dòng 1-11 và hậu tố bao phủ dòng 13-15. Quá trình này được lặp lại cho mỗi dòng trong tệp. Khi trình kiểm tra FLAG tiến hành từng dòng một, tiền tố tăng trong khi hậu tố giảm.

Chúng tôi giới hạn độ dài tiền tố và hậu tố tối đa 50 dòng để duy trì trong giới hạn token của LLM. Lời nhắc được điều chỉnh để khơi gợi phản hồi tốt hơn từ LLM ví dụ, nếu LLM tạo ra bình luận khi nó nên tạo ra mã, chúng tôi thêm vài ký tự đầu tiên của dòng mã gốc vào tiền tố. Quá trình này có thể được lặp lại nhiều lần cho đến khi có được phản hồi hợp lệ và yêu cầu phản hồi từ việc tạo dòng. Đây là lý do tại sao nó được thảo luận trong Phần 3.2. Hậu tố chỉ được sử dụng khi mô hình hỗ trợ chế độ chèn.

3.2 Tạo dòng
Tạo dòng lấy lời nhắc làm đầu vào và xuất ra một dòng mã hoặc bình luận được LLM tạo ra. Ví dụ, dòng được tạo cho lời nhắc trong Hình 2a được hiển thị trong Hình 2b. Trong trường hợp này, phản hồi của LLM khác với dòng mã gốc. Nó được đánh dấu để kiểm tra, tiết lộ rằng dòng mã gốc chứa khiếm khuyết bảo mật CWE-125, tức là đọc ngoài giới hạn. LLM được sử dụng cho ví dụ này là gpt-3.5-turbo ở chế độ tự động hoàn thành. Chi tiết các thí nghiệm được trình bày trong Phần 5.

LLM được hướng dẫn để tạo ra đầu ra hợp lý vì đôi khi LLM có thể trả về một dòng trống hoặc trả về bình luận thay vì mã. Quá trình này được mô tả trong Thuật toán 1. orig_lines là một danh sách các dòng trong tệp gốc. Giả sử rằng danh sách được lập chỉ mục bắt đầu từ 1. loc là số dòng mà chúng ta muốn LLM tạo ra. num_lines là tổng số dòng trong tệp gốc (sau khi được tiền xử lý). Chúng tôi khởi tạo tiền tố và hậu tố như các chuỗi trống và sử dụng max_pre_len và max_suf_len như giới hạn kích thước của chúng, tương ứng. Điều này được thực hiện như một nỗ lực để giữ kích thước token của lời nhắc hợp lý. Đối với các thí nghiệm của chúng tôi, chúng tôi đặt giới hạn là 50. Việc gán nội dung phù hợp từ tệp gốc cho tiền tố và hậu tố được hiển thị trong dòng 2-7. Để khắc phục các đầu ra thỉnh thoảng không sử dụng được, chúng tôi nhắc LLM tạo ra phản hồi lần nữa, tối đa max_attempts lần. Điều này được hiển thị trong khối Try và Catch trong dòng 15-19. Dòng 17 và 19 tăng số lần thử và quay lại đầu khối Try tại dòng 10. Trong lần thử đầu tiên, một LLM được nhắc để tạo ra phản hồi với tiền tố và hậu tố đã cho. Trong lần thử thứ hai và thứ ba, chúng tôi cung cấp hỗ trợ để khơi gợi phản hồi không trống. Điều này được thực hiện bằng cách thêm 5 ký tự đầu tiên của dòng mà LLM đang cố gắng tạo ra vào tiền tố. Hỗ trợ này được hiển thị trong dòng 12. Nếu có bất kỳ lỗi nào trong khối try, lỗi được ghi chú trong dòng 14 trước khi quay lại dòng 10. Nếu không có lỗi và các điều kiện trong dòng 16 và 18 không đúng, dòng 20 được thực thi. Điều này khẳng định tín hiệu rằng một dòng đã được tạo ra thành công và vòng lặp while được thoát. Đối với tất cả các hoàn thành, chúng tôi sử dụng nhiệt độ 0, giới hạn max_token 150, giá trị top_p là 1, và ký tự cuối dòng làm token dừng.

3.3 Trích xuất tính năng
Trích xuất tính năng lấy các dòng mã gốc và lỗi làm đầu vào và xuất ra các tính năng. Đây là các giá trị định lượng được sử dụng để phân loại dòng gốc là có khả năng lỗi hay không. Chúng đại diện cho sự khác biệt giữa hai dòng hoặc độ tin cậy của mã được tạo ra.

3.3.1 Tính năng
Khoảng cách Levenshtein (ld) là khoảng cách chỉnh sửa giữa hai chuỗi. Nó xem xét ba phép toán: thêm, xóa và thay thế. Tổng số phép toán cần thiết để chuyển đổi một chuỗi thành chuỗi khác là Khoảng cách Levenshtein. Một khớp hoàn hảo dẫn đến điểm số 0. Chúng tôi sử dụng ld để so sánh các dòng mã. Vì mục tiêu là đánh dấu các khiếm khuyết trong mã, chúng tôi sử dụng ld làm tiêu chí chính để xác định khiếm khuyết.

BLEU tức là Điểm Đánh giá Song ngữ [25], là một chỉ số để đánh giá một câu ứng cử viên với một câu tham chiếu. Một khớp hoàn hảo dẫn đến điểm số 1.0, trong khi một không khớp hoàn hảo dẫn đến điểm số 0.0. Chúng tôi sử dụng nó để so sánh bình luận vì chúng giống ngôn ngữ tự nhiên. Chúng tôi thu thập điểm BLEU-1 đến BLEU-4 tích lũy nhưng thấy rằng chỉ BLEU-1 tạo ra các con số có ý nghĩa. BLEU-2, BLEU-3 và BLEU-4 có số lượng rất nhỏ, không hữu ích. Đối với phần còn lại của bài báo này, BLEU đề cập đến BLEU-1.

Khoảng cách từ bình luận (dfc) chỉ ra dòng mã cách bình luận gần nhất trước nó bao xa. Nếu dòng cũng chứa bình luận, dfc có giá trị 0. Nếu không có bình luận trước dòng, dfc không có giá trị. Chúng tôi chỉ xem xét bình luận trước mã là có liên quan đến mã vì đó thường là cách mã được viết.

logprob trong bối cảnh tạo mã bởi LLM là log của xác suất của token được tạo ra. Nếu một token có nhiều khả năng được tạo ra, nó sẽ có logprob cao hơn với giá trị tối đa có thể là 0. Nếu một token ít có khả năng được tạo ra, nó sẽ có logprob thấp hơn, tức là một giá trị âm với độ lớn cao hơn. Một LLM có xu hướng "chọn" một token với xác suất cao hơn. Đối với một dòng được tạo ra, chúng tôi lấy trung bình của logprobs của các token được tạo ra, mà chúng tôi gọi là logprob từ đây trở đi. logprob gần 0 chỉ ra độ tin cậy cao hơn trong việc tạo ra, trong khi một giá trị âm hơn chỉ ra độ tin cậy ít hơn.

3.3.2 Trích xuất
Để có được các giá trị tính năng này, các dòng gốc và được tạo ra được loại bỏ để bỏ các khoảng trắng cuối. Nếu một trong các dòng là sự kết hợp của mã và bình luận, mã và bình luận được tách ra để so sánh. Mã của dòng gốc được so sánh với mã của dòng được tạo ra để tính toán ld. Bình luận của dòng gốc được so sánh với bình luận của dòng được tạo ra để tạo ra chỉ số BLEU. Ngoài ra, nếu dòng gốc là bình luận, vị trí của bình luận trước đó gần nhất được cập nhật thành dòng hiện tại, và dfc được tính toán. Các dòng được tạo ra và tính năng thu được, ví dụ, trong Hình 2, được hiển thị trong Bảng 1. Đối với ví dụ được hiển thị, LLM gpt-3.5-turbo được sử dụng ở chế độ tự động hoàn thành. Không thể có được giá trị logprob cho gpt-3.5-turbo thông qua API công khai nên những giá trị đó không được hiển thị. Giá trị logprob có sẵn cho các thí nghiệm với code-davinci-002.

3.4 Phân loại
Phân loại cho một tệp nhất định lấy các tính năng làm đầu vào và chọn các dòng để đánh dấu dựa trên một số điều kiện. Những điều kiện này được gọi là tiêu chí, và các dòng được đánh dấu được gọi là reported_lines. Các điều kiện có thể bao gồm hoặc loại trừ. Các điều kiện bao gồm được thiết kế để đưa các dòng vào tập hợp reported_lines. Các điều kiện loại trừ được sử dụng để loại bỏ các dòng khỏi reported_lines. Các điều kiện bao gồm sử dụng hai ngưỡng trong khung FLAG của chúng tôi, tức là Giới hạn Trên Khoảng cách Levenshtein (ld_limit) và Giới hạn Trên Khoảng cách từ Bình luận (dfc_limit). Những ngưỡng này được chọn vì các lý do được nêu chi tiết dưới đây. ld_limit và dfc_limit hoạt động cùng nhau để tạo ra các tiêu chí khác nhau.

Tại sao ld_limit? ld chỉ ra sự khác biệt giữa hai đoạn mã. Nếu ld là 0, các đoạn mã giống hệt nhau. Điều này có nghĩa là LLM không có gợi ý thay thế, vì vậy không có lý do để đánh dấu mã này. Nếu ld lớn hơn 0, các đoạn mã khác nhau, chỉ ra rằng LLM đang chỉ ra một phiên bản thay thế cho dòng mã gốc. Điều này có thể đáng để đánh dấu. Nhưng nếu ld là một số rất cao, nó có thể chỉ ra rằng LLM đang tạo ra thứ gì đó hoàn toàn khác. Dựa trên hiểu biết rằng một phiên bản lỗi của mã thường rất giống với phiên bản đã sửa, chúng tôi sử dụng một giới hạn trên cho ld để nhắm vào mã được tạo ra khác nhau nhưng không quá khác.

Tại sao dfc_limit? dfc chỉ ra dòng mã cách bình luận gần nhất trước nó bao xa. Nếu có bình luận gần mã, tức là dfc có giá trị thấp, chúng tôi giả thuyết rằng LLM sẽ tạo ra mã với thông tin có liên quan, vì vậy chúng tôi tin tưởng nó hơn. Nếu dfc lớn hơn dfc_limit, bình luận có khả năng không liên quan đến dòng mã, và chúng tôi loại bỏ nó. Việc sử dụng dfc làm dịu tiêu chí của chúng tôi để chọn các dòng để đánh dấu vì một dòng mã có ld lớn hơn ld_limit vẫn có thể được đánh dấu nếu nó có dfc nhỏ hơn dfc_limit.

Một tiêu chí đơn giản C0 sử dụng ld_limit làm ngưỡng của nó.
C0(ld_limit): 0<ld<=ld_limit

Một tiêu chí phức tạp hơn C1 sử dụng cả hai ngưỡng,
C1(ld_limit,dfc_limit):
0<ld AND (ld<=ld_limit OR 0<dfc<dfc_limit)

Tiêu chí cuối cùng C2 sử dụng cả hai ngưỡng và sử dụng hàm reduce_fp() để loại bỏ dương tính giả.
C2(ld_limit,dfc_limit):
0<ld AND (ld<=ld_limit OR 0<dfc<dfc_limit)
AND reduce_fp()

Tác dụng phụ của việc phát hiện khiếm khuyết là một số lượng đáng kể dương tính giả trong reported_lines. Chúng tôi giải quyết điều này bằng cách áp dụng một vài biện pháp trong reduce_fp(). Quá trình này kiểm tra reported_lines để loại bỏ một số dòng được đánh dấu có khả năng là dương tính giả. Biện pháp đầu tiên là tính toán lại ld sau khi loại bỏ khoảng trắng trong các dòng được tạo ra và gốc. Điều này loại bỏ dương tính giả nơi ld đếm khoảng trắng, ví dụ, always(@posedge clk) và always (@posedge clk). Thứ hai là kiểm tra xem dòng gốc chỉ có từ khóa hay không. Nếu đây là trường hợp, dòng đó được loại bỏ khỏi reported_lines vì một từ khóa đơn giản không thể bị lỗi. Thứ ba sử dụng giá trị logprob làm ngưỡng để loại trừ. Nếu LLM có giá trị logprob âm lớn cho dòng được tạo ra, nó được loại bỏ khỏi reported_lines vì nó chỉ ra rằng LLM không tin tưởng vào gợi ý của mình. Chúng tôi sử dụng ngưỡng <−0.5 cho các thí nghiệm của chúng tôi với code-davinci-002 để loại bỏ các dòng. Phân loại ví dụ được hiển thị trong Hình 2 sử dụng C2(20,10) được hiển thị trong cột Flagged? của Bảng 1. Trong số 2 dòng được đánh dấu, một dòng chứa khiếm khuyết gốc (được tô màu hồng), trong khi dòng kia là dương tính giả.

4 Tập dữ liệu điểm chuẩn
Để đánh giá tính khả thi của việc sử dụng LLM để đánh dấu sự không nhất quán trong bình luận hoặc mã, chúng tôi thí nghiệm trên một tập hợp các khiếm khuyết ví dụ trong C, Python và Verilog từ nhiều nguồn khác nhau, được tóm tắt trong Bảng 2. Chúng tôi thu thập cả khiếm khuyết liên quan đến bảo mật và chức năng. Nguồn C1, P1 và V1 bao gồm các khiếm khuyết bảo mật, trong khi nguồn C2, P2 và V2 có các khiếm khuyết gây ra vấn đề chức năng. Một số khiếm khuyết liên quan đến bảo mật được mô tả trong Bảng 3, và các khiếm khuyết bảo mật và chức năng còn lại được mô tả trong Phụ lục A. 19 trong số 35 khiếm khuyết bảo mật có điểm yếu hiện diện trong danh sách 25 CWE hàng đầu của MITRE. Liệt kê Điểm yếu Thông thường (CWE) là các danh mục vấn đề bảo mật có thể biểu hiện trong mã [9]. Mỗi khiếm khuyết có tệp mã nguồn và số dòng tương ứng chứa khiếm khuyết. Chúng tôi thu thập 121 khiếm khuyết; 43 cho C, 34 cho Python và 44 cho Verilog.

4.1 Nguồn C
C1 chứa các lỗ hổng bảo mật được tuyển chọn bởi các tác giả của [26, 27]. Chúng tôi chọn 12 CVE thực tế và 5 trường hợp CWE được điều tra trong những công trình đó. Lỗ hổng và Phơi bày Thông thường (CVE) là một từ điển phân loại lỗ hổng. Một phơi bày cụ thể trong thế giới thực được ghi lại và được đưa ra một định danh. Chúng tôi đã điều tra cve-2018-19664, cve-2012-2806, cve-2016-5321, cve-2014-8128, cve-2014-8128, cve-2016-10094, cve-2017-7601, cve-2016-3623, cve-2017-7595, cve-2016-1838, cve-2012-5134 và cve-2017-5969. Chi tiết của mỗi CVE có thể được lấy từ Cơ sở Dữ liệu Lỗ hổng Quốc gia NIST [10]. Đối với CWE, chúng tôi bao gồm cwe-119 và cwe-125, được lấy cảm hứng từ các ví dụ MITRE, và cwe-416, cwe-476, cwe-732, được lấy từ các ví dụ CodeQL.

C2 chứa các khiếm khuyết trong các bài tập được sinh viên nộp [43]. Có 74 bài tập độc đáo trải dài trên 10 tuần. Chúng tôi chọn 30 trong số những bài tập này với các chủ đề bao gồm Biểu thức Đơn giản, Vòng lặp, Mảng Số nguyên, Mảng Ký tự (Chuỗi) và Hàm, Mảng Đa chiều, Đệ quy, Con trỏ, Thuật toán (sắp xếp, hoán vị, câu đố), và Cấu trúc (Kiểu dữ liệu do Người dùng Định nghĩa). Đối với mỗi bài tập được chọn, chúng tôi chọn một bài nộp của sinh viên có lỗi có thể xác định rõ ràng. Điều này được thực hiện bằng cách so sánh phiên bản lỗi với phiên bản đúng trong kho lưu trữ được đăng bởi các tác giả của công trình. Mỗi bài tập độc đáo cũng chứa một phiên bản đúng của mã với bình luận ở đầu mô tả chức năng dự định của mã. Chúng tôi sử dụng những bình luận này và thêm chúng làm tiền tố cho các tệp mã nguồn có liên quan mà chúng tôi phân tích.

4.2 Nguồn Python
P1 sử dụng công trình của các tác giả để sử dụng Github Copilot để hoàn thành mã dựa trên các kịch bản được phát triển cho các CWE được chọn [26, 27]. Chúng tôi xem xét các hoàn thành được đánh dấu là chứa điểm yếu bởi các tác giả và chọn một cho mỗi CWE cho công trình của chúng tôi. Chúng tôi bao gồm cwe-79, cwe-20, cwe-22, cwe-78, cwe-89, cwe-200, cwe-306, cwe-434, cwe-502, cwe-522, cwe-732 và cwe-798.

P2 có các khiếm khuyết được ghi chú trong các dự án Python thực tế bằng cách phân tích lịch sử kiểm soát phiên bản của chúng [42]. Điều này được thực hiện bằng cách xác định các cam kết trên Github có ý định sửa lỗi. Chúng tôi chọn một hoặc hai lỗi được xác định trong các dự án youtube-dl, tqdm, fastapi, luigi, scrapy, black, nvbn, spacy, keras, pysnooper, cookiecutter và ansible. Các khiếm khuyết bao gồm một loạt nguyên nhân, bao gồm biểu thức regex sai, đối tượng trả về không chính xác, token phân tách không chính xác được sử dụng, gán không chính xác, giá trị tham số không chính xác, lệnh os không chính xác, đối số hàm không chính xác, tính toán không chính xác, điều kiện lỗi sai, thiếu mã hóa tệp, phần tử được thêm vào danh sách không chính xác, đường dẫn tệp không chính xác trong lệnh os và những cái khác. Đối với mỗi khiếm khuyết này, chúng tôi cô lập tệp mã nguồn chứa lỗi và vị trí của nó bằng cách phân tích tệp bug_patch.txt cho lỗi.

4.3 Nguồn Verilog
V1 chứa các khiếm khuyết dưới dạng lỗ hổng bảo mật được thu thập bởi các tác giả từ 3 nguồn [1]. Nguồn đầu tiên là CWE phần cứng của MITRE, từ đó họ thiết kế 4 mô-đun với CWE hiện diện (một thanh ghi khóa, một logic đặt lại cho thanh ghi, một trình kiểm tra truy cập, và một thiết bị ngoại vi TrustZone). Nguồn thứ hai là OpenTitan SoC [23], nơi các tác giả chèn lỗi vào RTL của 3 mô-đun (Bộ điều khiển ROM, Bộ điều khiển Bộ nhớ Có thể Lập trình Một lần, và giao diện cho Trình quản lý Khóa KMAC). Nguồn thứ ba là lỗi trong Hack@DAC 2021 SoC [17] sử dụng lõi Ariane với lỗi hiện diện cho cuộc thi săn lỗi. Các lỗi nằm trong các mô-đun Regfile Thanh ghi Điều khiển và Trạng thái, Truy cập Bộ nhớ Trực tiếp, và giao diện AES.

V2 chứa các khiếm khuyết chức năng trong 11 dự án Verilog [2]. Những dự án này bao gồm bộ giải mã 3-to-8, bộ đếm 4-bit có tràn, t-flip flop, máy trạng thái hữu hạn, thanh ghi dịch trái 8-bit, bộ ghép kênh 4-to-1, bus nối tiếp hai chiều i2c, hàm băm mật mã sha3, lõi cho thuật toán ghép cặp bilinear Tate cho đường cong elliptic, Lõi cho sửa lỗi Reed Solomon và bộ điều khiển SDRAM. Các khiếm khuyết bao gồm lỗi số, danh sách nhạy cảm không chính xác, gán không chính xác, đặt lại không chính xác, gán chặn thay vì không chặn, tăng sai bộ đếm và bỏ qua kiểm tra tràn bộ đệm.

5 Thí nghiệm và Kết quả
Để đánh giá phương pháp kiểm tra tính nhất quán FLAG, chúng tôi thiết kế các thí nghiệm sử dụng 2 LLM của OpenAI. LLM đầu tiên là code-davinci-002 được tối ưu hóa cho các nhiệm vụ hoàn thành mã. Đối với code-davinci-002, không có lời nhắc hệ thống, nhưng nó hỗ trợ khả năng chèn nếu một hậu tố được đưa ra ngoài tiền tố. Chúng tôi chạy 2 thí nghiệm với code-davinci-002, ở chế độ tự động hoàn thành (không có hậu tố) và chèn (có hậu tố). LLM thứ hai là gpt-3.5-turbo. Nó cải thiện trên GPT-3 và có thể hiểu và tạo ra ngôn ngữ tự nhiên hoặc mã. Tại thời điểm của bản thảo này, nó là "mô hình GPT-3.5 có khả năng nhất". Đây là một mô hình hướng dẫn có vai trò được suy ra dựa trên lời nhắc hệ thống được đưa ra. Sau khi lời nhắc hệ thống được đưa ra, mô hình sau đó được đưa ra thông điệp chỉ định nhiệm vụ. Chúng tôi tiến hành hai thí nghiệm với gpt-3.5-turbo. Thí nghiệm đầu tiên được thực hiện mà không có lời nhắc hệ thống nào. Chúng tôi gọi chế độ này là tự động hoàn thành. Thí nghiệm thứ hai đưa ra lời nhắc hệ thống sau: "Bạn là một trợ lý lập trình AI có kỹ năng. Hoàn thành dòng mã tiếp theo." Chế độ này là hoàn thành có hướng dẫn.

Một thí nghiệm bao gồm việc chọn một tập hợp cụ thể của LLM và chế độ, ví dụ, code-davinci-002 ở chế độ chèn, và sử dụng nó để thực thi phương pháp kiểm tra tính nhất quán của chúng tôi trên tất cả 121 điểm chuẩn. Tổng cộng, chúng tôi chạy 4 thí nghiệm cho các kết hợp có thể có của 2 LLM và 2 chế độ hoàn thành của chúng. Để đánh giá sự thành công của một thí nghiệm, chúng tôi tập trung vào 3 chỉ số. Đầu tiên là Số khiếm khuyết được phát hiện (DD). Đối với một tập hợp đầu vào nhất định, DD là tổng số khiếm khuyết được xác định chính xác. Nó thực sự là Dương tính Thật (TP) và có giá trị tối đa có thể là 121, tức là tổng số khiếm khuyết trên tất cả các nguồn. Thứ hai là Tỷ lệ Dương tính Giả (FPR). Đối với một tập hợp đầu vào nhất định, FPR là tỷ lệ giữa số dòng được đánh dấu không chính xác và tổng số dòng. Thứ ba là Tỷ lệ Dương tính Thật (TPR) hoặc Recall tức là tỷ lệ giữa dương tính thật và tổng số dương tính. Đây là DD/tổng số khiếm khuyết.

5.1 Kết quả
Kết quả được trình bày trong Bảng 4. Chúng tôi chia nhỏ kết quả cho mỗi thí nghiệm theo nguồn và tiêu chí để trình bày góc nhìn sắc thái. Đối với C, chúng tôi chia nhỏ C1 thành C1-CVE và C1-CWE vì sự khác biệt về kích thước và kết quả của chúng bằng trình kiểm tra FLAG. Bằng cách hiển thị ảnh chụp nhanh của các tiêu chí khác nhau, chúng tôi minh họa cách kết quả thay đổi dựa trên độ phức tạp. Cuối cùng, chúng tôi đề xuất tiêu chí 2 vì nó cân bằng TPR và FPR và sử dụng các tính năng bao gồm và loại trừ từ Phần 3.3.1.

gpt-3.5-turbo có khả năng phát hiện khiếm khuyết lớn hơn, nhưng code-davinci-002 có ít dương tính giả hơn. Đối với tiêu chí 2, gpt-3.5-turbo hoạt động tốt hơn code-davinci-002 về TPR. Nó có thể phát hiện 90 khiếm khuyết ở chế độ tự động hoàn thành và 77 ở chế độ chèn có hướng dẫn, trong khi code-davinci-002 phát hiện 76 ở chế độ tự động hoàn thành và 78 ở chế độ chèn. code-davinci-002 hoạt động tốt hơn về FPR. Nó có FPR thấp hơn là 0.121 ở chế độ tự động hoàn thành và 0.141 ở chế độ chèn so với 0.172 và 0.181 cho gpt-3.5-turbo ở chế độ hoàn thành có hướng dẫn và tự động hoàn thành, tương ứng. Các tiêu chí lấy các giá trị cụ thể cho ld_limit và dfc_limit. Điều này không cần phải như vậy vì chúng có thể lấy một loạt giá trị có thể tác động đến kết quả. Chúng tôi thảo luận những mối quan hệ này và hiểu biết về bản chất của dương tính thật và dương tính giả trong Phần 5.3.

5.2 Đi sâu hơn vào Lỗi Bảo mật
Vì chúng tôi quan tâm đến các ứng dụng bảo mật của FLAG, chúng tôi chia nhỏ việc phát hiện lỗi bảo mật trong Hình 3. Việc chia nhỏ cho các khiếm khuyết chức năng được hiển thị trong Phụ lục A. 16 trong số 35 lỗi bảo mật được phát hiện bởi cả hai LLM ở cả hai chế độ, và 29 được phát hiện bởi ít nhất một LLM ở một chế độ. gpt-3.5-turbo ở chế độ tự động hoàn thành hoạt động tốt nhất, phát hiện 26 so với 22, 19 và 19 cho gpt-3.5-turbo ở chế độ hoàn thành có hướng dẫn, code-davinci-002 ở chế độ tự động hoàn thành và code-davinci-002 ở chế độ chèn tương ứng. Lỗi bảo mật Python là những lỗi được LLM phát hiện tốt nhất. Tất cả các khiếm khuyết cho Python đều được xác định. Tiếp theo là Verilog và C, tương ứng. Kiểm tra kỹ hơn cho phép chúng tôi phát triển một số hiểu biết về lý do tại sao điều này có thể xảy ra. Đầu tiên, kích thước của các tệp nguồn P1 nhỏ hơn so với các nguồn khác. Nó có kích thước tệp trung bình 17 dòng so với 1426 của C1 và 249 của V1. Ngoài ra, kích thước tệp nhỏ cho phép LLM nhận toàn bộ mã nguồn trước lỗi như một phần của lời nhắc, cung cấp cho nó bối cảnh hoàn chỉnh về chức năng dự định của các tệp. Thứ hai, các điểm chuẩn trong P1 được thiết kế đặc biệt bởi Pearce et al. [26, 27] để đánh giá bảo mật trong khi các điểm chuẩn trong V1 và C1 là sự kết hợp của những cái được thiết kế rõ ràng cho bảo mật và các ví dụ thực tế. 6 trong số các điểm chuẩn trong V1 là từ mã trong triển khai thực tế của SoC, và 8 điểm chuẩn trong C1 là từ CVE thực tế. Điều này cũng giải thích tại sao FLAG hoạt động kém trên C1-CVE, tức là C1-1 - C1-8.

Chúng tôi quan tâm đến việc so sánh hiệu suất của FLAG giữa lỗi chức năng và bảo mật. Dựa trên dữ liệu trong Hình 4, người ta có thể suy ra rằng FLAG phát hiện lỗi chức năng tốt hơn lỗi bảo mật. Xem xét kết quả tại C2(20,10), lỗi chức năng có TPR trung bình cao hơn là 0.689 so với lỗi bảo mật ở 0.676. Chúng cũng có FPR trung bình thấp hơn là 0.176 so với lỗi bảo mật ở 0.271. Nhìn kỹ hơn cho thấy Python là một ngoại lệ với TPR cao hơn cho P1 so với P2. Đối với gpt-3.5-turbo, TPR cho P1 gấp đôi P2, chỉ ra rằng gpt-3.5-turbo hoạt động tốt trong việc phát hiện lỗi bảo mật trong Python. Chúng tôi loại trừ dữ liệu cho C1-CVE khỏi phân tích vì số dòng cho những điểm chuẩn này nhiều lần lớn hơn các điểm khác, làm lệch trung bình về phía C1-CVE.

5.3 Phân tích Chi tiết
Việc tinh chỉnh tiêu chí từ C0 đến C2 tác động đến DD và FPR như thế nào? Chuyển từ C0 đến C1, cả DD và FPR đều tăng. Điều này là do ld_limit được nới lỏng đáng kể từ 10 đến 20, và dfc_limit được sử dụng để bao gồm các dòng có thể vượt quá ld_limit. Trung bình, DD tăng từ 51 đến 84 trong khi FPR tăng từ 0.106 đến 0.18. Chuyển từ tiêu chí C1 đến C2, cả DD và FPR đều giảm. Điều này là do hàm reduce_fp() loại bỏ các dòng được đánh dấu khỏi reported_lines. Một số dương tính giả đã được loại bỏ, nhưng một số dương tính thật cũng vậy. Trung bình, DD giảm từ 85 đến 80 trong khi FPR giảm từ 0.18 đến 0.154. Trong khi DD giảm 4.76%, FPR giảm 14.6%. Điều này cho thấy tầm quan trọng của reduce_fp() trong việc cải thiện hiệu suất của kiểm tra tính nhất quán. Các xu hướng được hiển thị trong Hình 5.

Các chế độ hoàn thành khác nhau tác động đến DD và FPR như thế nào? Theo trực giác, chúng ta có thể nghĩ rằng chế độ chèn nên hoạt động tốt hơn chế độ tự động hoàn thành, vì LLM có quyền truy cập vào nhiều thông tin hơn dưới dạng hậu tố, ngoài tiền tố. Ngoài ra, việc hướng dẫn gpt-3.5-turbo tạo ra "dòng mã tiếp theo" ở chế độ hoàn thành có hướng dẫn sẽ hoạt động tốt hơn chế độ tự động hoàn thành vì khả năng tạo ra mã thay vì giải thích mã sẽ cao hơn. Hình 6 so sánh hiệu suất của các chế độ hoàn thành khác nhau tại C2(20,10). Đối với code-davinci, chế độ chèn cho phép chúng ta phát hiện thêm 2 khiếm khuyết nhưng với chi phí tăng 16.5% FPR. Đây có lẽ không phải là một sự đánh đổi đủ có giá trị, có nghĩa là không có nhiều lợi ích từ việc sử dụng chế độ chèn. Đối với gpt-3.5-turbo, chế độ hoàn thành có hướng dẫn hoạt động kém hơn đáng kể so với đối tác tự động hoàn thành của nó. Nó phát hiện ít hơn 13 khiếm khuyết trong khi chỉ giảm FPR 4.97%.

ld_limit và dfc_limit tác động đến DD và FPR như thế nào? Hai yếu tố xác định chính của việc đánh dấu các dòng trong phương pháp kiểm tra của chúng tôi là ld_limit và dfc_limit. Vì chúng có thể lấy bất kỳ giá trị liên tục nào, cần có phân tích sâu hơn ngoài việc xem xét các giá trị cụ thể được thảo luận trong tiêu chí C0 đến C2. Chúng tôi tiến hành quét qua hai giới hạn cho mô hình code-davinci-002 ở chế độ tự động hoàn thành để xem tác động của chúng đối với DD và FPR. Hình 7a và Hình 7b hiển thị cách DD và FPR thay đổi tương ứng tại các kết hợp khác nhau của ld_limit và dfc_limit trong phạm vi từ 0 đến 30 cho ld_limit và 0 đến 50 cho dfc_limit. Chúng tôi quan sát thấy rằng ld_upper_limit có ảnh hưởng chi phối hơn nhiều đến DD và FPR. Một thay đổi trong ld_upper_limit mang lại thay đổi lớn hơn trong cả DD và FPR so với một thay đổi bằng nhau trong dfc_limit. Kết quả là, DD và FPR cũng bão hòa sớm hơn khi tăng ld_limit. DD bão hòa lỏng lẻo tại ld_limit của 30 vì có tác động hạn chế của việc thay đổi dfc_limit ở giá trị đó. Tương tự, FPR bão hòa lỏng lẻo tại ld_limit của 20. Những bản đồ nhiệt này là một phần, nhưng mở rộng chúng cho ld_limit =50 tiết lộ rằng các giá trị tối đa có thể cho DD và FPR lần lượt là 90 và 0.14. Chúng tôi cũng quan sát thấy rằng DD và FPR nhạy cảm hơn ở các giá trị nhỏ hơn của ld_limit và dfc_limit. Chúng ta có thể đạt được 80% giá trị tối đa của DD, tức là 72 tại ld_limit của 15 và dfc_limit của 10. Tương tự, chúng ta có thể đạt được 80% giá trị tối đa của FPR tức là 0.11 tại ld_limit của 15 và dfc_limit của 25. Phân tích này giúp có được ước tính về các phạm vi nên được xem xét khi thiết kế các công cụ tương tự.

Điều này có thể được khám phá thêm bằng cách phóng to các giá trị nhỏ hơn cho dfc_limit và mở rộng các giá trị cho ld_limit lên 100 như được hiển thị trong Hình 8. Đối với một dfc_limit cụ thể, khi chúng ta tăng ld_limit, cả DD và FPR đều tăng. Trong khi tốc độ tăng cho cả hai đều giảm (được hiển thị bởi gradient giảm), có một điểm sau đó tốc độ tăng trong DD ít hơn đáng kể so với FPR. Đây là điểm mà lợi ích của việc có được nhiều khiếm khuyết hơn sẽ bị áp đảo bởi chi phí tăng dương tính giả. Ngược lại, một giá trị nhỏ hơn nhiều của ld_limit sẽ đơn giản là không tìm thấy đủ khiếm khuyết. Vùng được đánh dấu trong Hình 8 chỉ ra các giá trị mà phương pháp kiểm tra tính nhất quán cung cấp kết quả "tốt" tức là giữa 10 và 30. Một khám phá tương tự với việc giữ ld_limit không đổi và quét dfc_limit cung cấp những hiểu biết tương tự. Tuy nhiên, các giá trị cho DD và FPR không đủ khác biệt cho các giá trị khác nhau của ld_limit để một biểu diễn đồ họa có thể minh họa.

Tự nhiên, một câu hỏi có thể được đặt ra về sự kết hợp tối ưu của ld_limit và dfc_limit là gì? Số lượng dương tính giả mà một lập trình viên sẵn sàng chấp nhận để có lợi ích của việc phát hiện nhiều lỗi hơn là vấn đề chủ quan. Chúng tôi đã minh họa sự đánh đổi giữa TPR và FPR trong các bản đồ nhiệt. Một cách để quyết định giới hạn nào để sử dụng có thể là trước tiên nhìn vào số lượng dương tính giả bạn sẵn sàng chịu đựng. Ví dụ, nếu bạn sẵn sàng xem xét 7 dòng trên 100 cho mỗi lỗi được phát hiện, tức là FPR của 0.07, bạn có thể chọn (ld_limit,dfc_limit) của (5,10) như được hiển thị trong Hình 7b. Ở những giới hạn này, bạn sẽ có thể định vị 58 trong số 121 khiếm khuyết được bao phủ trong các điểm chuẩn của chúng tôi vì đó là giá trị tương ứng trong Hình 7a.

LLM tốt hơn như thế nào so với đoán ngẫu nhiên? Để minh họa sự thành công của kiểm tra tính nhất quán như một bộ phân loại, chúng tôi biểu diễn TPR và FPR dưới dạng đường cong Đặc tính Hoạt động Receiver (ROC) tại các ngưỡng khác nhau cho ld_limit. Chúng tôi sử dụng code-davinci002 ở chế độ tự động hoàn thành cho mục đích này. Trong các thí nghiệm của chúng tôi, chúng tôi đặt giới hạn dưới cứng cho ld là 0. Điều này có nghĩa là một số dòng có ld bằng không sẽ không bao giờ được tính là dương tính thật hoặc dương tính giả, dẫn đến đường cong ROC không đầy đủ. Tình huống này được biểu diễn trong Hình 9a, nơi TPR và FPR bị giới hạn. Tuy nhiên, đường cong ROC nằm trên đường TPR==FPR cho thấy rằng phương pháp phân loại của chúng tôi tốt hơn việc đoán. Để hoàn thiện, nếu chúng ta sử dụng giới hạn dưới tại -1 và giới hạn trên tại 1000, chúng ta có thể có được TPR và FPR bằng 1 vì tất cả các dòng sẽ được đánh dấu là chứa khiếm khuyết. Điều này được biểu diễn trong Hình 9b.

Lỗi của một ngôn ngữ có dễ phát hiện hơn các ngôn ngữ khác không? Dựa trên dữ liệu trong Hình 10, chúng ta có thể kết luận rằng trình kiểm tra tính nhất quán FLAG hoạt động tốt nhất trên C và tệ nhất trên Python. Mặc dù C có TPR thấp hơn một chút so với Verilog cho cả hai LLM, nó có FPR thấp hơn đáng kể. Trong khi TPR thấp hơn 10.5%, FPR ít hơn 48.4% so với Verilog. Python có TPR thấp nhất và chỉ FPR thấp thứ hai cho cả hai LLM. Điều này đáng ngạc nhiên vì chúng tôi mong đợi lượng Python nguồn mở lớn hơn trong dữ liệu đào tạo sẽ dịch thành hiệu suất tốt hơn so với Verilog. Điều này có lẽ là do 22 trong số các điểm chuẩn cho Python là ví dụ thực tế so với chỉ 6 cho Verilog.

Bình luận giúp ích như thế nào? Chúng tôi biểu thị vai trò của bình luận bằng cách phân tích điểm dfc và BLEU cho dương tính thật và dương tính giả. dfc biểu thị sự gần gũi của một dòng với bình luận, trong khi điểm BLEU biểu thị chất lượng của bình luận được LLM tạo ra. Hình 11 hiển thị cách dfc khác nhau giữa dương tính thật và dương tính giả. Dữ liệu ở đây không bao gồm các trường hợp mà dfc không có sẵn, tức là khi không có bình luận trước dòng liên quan. Hầu hết dữ liệu trong cả hai trường hợp nằm trong phạm vi cho các giá trị nhỏ nhất của dfc. Điều này là do bình luận thường được viết trong các điểm chuẩn mà chúng tôi nghiên cứu. dfc cho dương tính thật có trung bình thấp hơn là 18.4 so với dương tính giả ở 327.9. LLM làm tốt hơn công việc phân loại khi dòng liên quan gần hơn với bình luận. dfc cho dương tính thật có độ lệch chuẩn nhỏ hơn nhiều là 47.7 so với dương tính giả ở 632.1. Do đó dương tính giả bao phủ một phạm vi giá trị lớn hơn nhiều.

Điểm dfc trung bình hoặc điểm bleu trung bình có tương quan với sự thành công của trình kiểm tra không? Hình 12 hiển thị cách điểm BLEU của bình luận trước đó khác nhau giữa dương tính thật và dương tính giả. Dữ liệu không bao gồm các dòng mà không có bình luận trước dòng hoặc khi LLM không thể tạo ra bình luận. Đối với một dòng mã được phân tích, FLAG theo dõi bình luận gần nhất trước nó. FLAG so sánh bình luận được LLM tạo ra tại dòng này với bình luận gốc để tính toán điểm BLEU của bình luận trước đó. Một giá trị cao chỉ ra rằng LLM đang đi đúng hướng theo ý định của lập trình viên. Điểm BLEU của bình luận trước đó cho dương tính thật có trung bình tương tự là 0.407 so với dương tính giả ở 0.473. Điều này cho thấy rằng điểm BLEU của bình luận trước đó không đóng vai trò quan trọng trong phân loại. Điểm BLEU của bình luận trước đó cho dương tính thật có độ lệch chuẩn tương tự là 0.193 so với dương tính giả ở 0.236.

6 Thảo luận
Trong phần trước, chúng tôi đã khám phá xem liệu có sự khác biệt đáng kể giữa dương tính thật và dương tính giả dựa trên thông tin như dfc hoặc điểm BLEU của bình luận trước đó hay không. Phân tích này được thực hiện ở mức độ chi tiết của các dòng. Tuy nhiên, có chỗ cho phân tích như vậy ở mức độ chi tiết của tệp hoặc điểm chuẩn. Có mối quan hệ giữa các thuộc tính của tệp, như số lượng bình luận, kích thước điểm chuẩn, v.v., với khả năng một khiếm khuyết được phát hiện cho điểm chuẩn đó không? Chúng tôi điều tra mối quan hệ này cho các thuộc tính sau của mỗi điểm chuẩn: ld trung bình, dfc trung bình, BLEU trung bình, logprobs trung bình, số lượng bình luận và số dòng (kích thước). Kết quả được hiển thị trong Hình 13. Các biểu đồ hộp tiết lộ rằng dfc trung bình, số lượng bình luận và số dòng có phân phối khác biệt đáng kể cho các điểm chuẩn nơi khiếm khuyết được phát hiện so với những nơi không được phát hiện. Dfc trung bình thấp hơn, số lượng bình luận nhiều hơn và số dòng ít hơn tăng khả năng khiếm khuyết được phát hiện. Tuy nhiên, ld trung bình, BLEU trung bình và logprobs trung bình không tạo ra sự khác biệt này.

FLAG dựa vào ý tưởng cơ bản rằng một dòng chứa khiếm khuyết có khả năng được viết theo cách khác bởi LLM tức là ld>0. Trong các thí nghiệm của chúng tôi, tuy nhiên, điều này không phải lúc nào cũng như vậy. Có 11 điểm chuẩn mà ld bằng 0 cho cả hai LLM ở cả hai chế độ của chúng cho C2(20,10), vì LLM tạo ra mã giống hệt như mã gốc. 8 trong số chúng từ nguồn V2, 2 từ C1 và 1 từ P2. Do đó, LLM đôi khi tạo ra mã lỗi chức năng cho Verilog nhưng nói chung tạo ra mã thay thế khi đối mặt với khiếm khuyết.

Một hạn chế của FLAG là việc đi từng dòng một cho hầu như mọi dòng trong mã nguồn không mở rộng về thời gian. Trong khi các tệp nhỏ hơn ∼100 dòng được kiểm tra trong vòng dưới một phút, việc quét một tệp với hàng nghìn dòng có thể mất khoảng một giờ. Để giải quyết điều này, người ta có thể ưu tiên tạo ra một tập hợp con của các dòng. Điều này có thể được thực hiện bằng cách kiểm tra các vùng nhạy cảm bảo mật của mã nguồn, ví dụ, kiểm tra các điều kiện if và các câu lệnh bên trong khối if. Một phương pháp khác là bỏ qua các dòng không có nhiều nội dung, ví dụ, một dòng chỉ có từ khóa.

Một hạn chế khác là FPR cao. FPR cho các thí nghiệm của chúng tôi dao động từ 0.121 đến 0.172, có nghĩa là đối với một tệp mã nguồn 100 dòng với một khiếm khuyết, khoảng 12-17 dòng sẽ bị đánh dấu sai. Công việc tương lai sẽ tập trung vào việc giảm thêm các dòng được đánh dấu. Một phương pháp là xem xét các tính năng cho các vùng mã nguồn thay vì các dòng cho tiêu chí phân loại, ví dụ, không đánh dấu khiếm khuyết giữa dòng x và y cho tệp z vì logprobs trung bình cho vùng này chỉ ra rằng LLM không tin tưởng vào các gợi ý của mình.

FLAG có thể hỗ trợ nhà thiết kế bằng cách tập trung việc tìm kiếm lỗi chỉ vào 12−17% mã nguồn. Hơn nữa, các nỗ lực giảm dương tính giả nên được đối xử cẩn thận vì chúng có thể loại bỏ một số dương tính thật. Phương pháp của FLAG để loại bỏ dương tính giả khi chuyển từ tiêu chí C1 đến C2 đã giảm số lượng khiếm khuyết được phát hiện trung bình 3.75. Một ví dụ được hiển thị trong Bảng 5. Khiếm khuyết là dòng được đánh dấu màu hồng mà LLM tạo ra mã thay thế có ld là 10 và dfc là 3. Nó được đánh dấu bởi FLAG như một mối quan tâm khi sử dụng C1(20,10) nhưng không khi sử dụng C2(20,10). Điều này là do C2 sử dụng reduce_fp(), loại bỏ một dòng khiếm khuyết vì nó có logprob <−0.5. FLAG hứa hẹn cho việc phát hiện lỗi khi LLM cải thiện. Với kích thước dữ liệu lớn hơn và tinh chỉnh, các LLM mới hơn có thể tạo ra mã và gợi ý mã tốt hơn.

7 Kết luận và Công việc tương lai
Nhìn chung, 101 trong số 121 khiếm khuyết được phát hiện bởi ít nhất một chế độ của 2 LLM. Trung bình, cho 4 kết hợp chế độ và LLM, 80 khiếm khuyết được phát hiện với FPR là 0.154 sử dụng tiêu chí C2. Điều này mang lại uy tín cho kiểm tra tính nhất quán bằng FLAG như một trình phát hiện lỗi và bộ định vị không gian tìm kiếm. Chúng tôi thấy rằng gpt-3.5-turbo có khả năng phát hiện lỗi tốt hơn nhưng FPR cao hơn code-davinci-002. FLAG tốt hơn một chút đối với lỗi chức năng so với lỗi liên quan đến bảo mật. Chúng tôi thấy rằng khoảng cách Levenshtein giữa mã gốc và mã được LLM tạo ra là tính năng phân loại chi phối trong số những tính năng chúng tôi khám phá. Tuy nhiên, bình luận đóng vai trò quan trọng trong hiệu suất của FLAG vì các dòng mã với khoảng cách nhỏ hơn từ bình luận được phân loại với sự thành công tốt hơn. Cuối cùng, FLAG hoạt động tốt nhất trên C và tệ nhất trên Python cho các điểm chuẩn chúng tôi nghiên cứu.

Vì FLAG mới lạ trong việc triển khai, một số hướng công việc tương lai có thể được hình thành. Nhiều tính năng hơn trong mã và LLM có thể được sử dụng trong phân loại ví dụ, điểm BLEU cho mã và điểm embedding cho mã và bình luận. Với một tập hợp lớn hơn các tính năng phân loại và một tập hợp lớn hơn dương tính thật và dương tính giả dưới dạng điểm chuẩn, các bộ phân loại ML có thể được đào tạo để xác định tiêu chí cho phân loại. Các phiên bản tương lai của FLAG có thể phân tích mã và bình luận theo khối thay vì dòng. Một ý tưởng thú vị khác là chạy nhiều LLM và đánh dấu một dòng dựa trên sự kết hợp của các tính năng.

Lời cảm ơn
Công trình nghiên cứu này được hỗ trợ một phần bởi quà tặng từ Intel Corporation. Công trình này không cấu thành sự chứng thực của Intel đối với một sản phẩm hoặc nhà cung cấp. Chúng tôi ghi nhận sự hỗ trợ của Hội đồng Nghiên cứu Khoa học Tự nhiên và Kỹ thuật của Canada (NSERC), RGPIN-2022-03027.

Tính khả dụng
Các tạo phẩm (mã nguồn FLAG, đầu ra LLM) được tạo ra và trình bày trong nghiên cứu này tại [32].

Tài liệu tham khảo
[1]Baleegh Ahmad, Shailja Thakur, Benjamin Tan, Ramesh Karri, và Hammond Pearce. Fixing Hardware Security Bugs with Large Language Models, Tháng 2 2023. arXiv:2302.01215 [cs].

[2]Hammad Ahmad, Yu Huang, và Westley Weimer. CirFix: automatically repairing defects in hardware design code. Trong Proceedings of the 27th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, ASPLOS '22, trang 990–1003, New York, NY, USA, Tháng 2 2022. Association for Computing Machinery.

[3] Aizu. Aizu Online Judge, 2015. Truy cập ngày 2023-06-06.https://onlinejudge.u-aizu.ac.jp/home.

[4]Stefan Berner, Roland Weber, và Rudolf K. Keller. Observations and lessons learned from automated testing. Trong Proceedings of the 27th international conference on Software engineering, ICSE '05, trang 571–579, New York, NY, USA, Tháng 5 2005. Association for Computing Machinery.

[5]Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, và Dario Amodei. Language Models are Few-Shot Learners. Trong H. Larochelle, M. Ranzato, R. Hadsell, M. F. Balcan, và H. Lin, biên tập, Advances in Neural Information Processing Systems, tập 33, trang 1877–1901. Curran Associates, Inc., 2020.

[6]Saikat Chakraborty, Yujian Li, Matt Irvine, Ripon Saha, và Baishakhi Ray. Entropy Guided Spectrum Based Bug Localization Using Statistical Language Model, Tháng 2 2018. arXiv:1802.06947 [cs].

[7]Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, Alex Ray, Raul Puri, Gretchen Krueger, Michael Petrov, Heidy Khlaaf, Girish Sastry, Pamela Mishkin, Brooke Chan, Scott Gray, Nick Ryder, Mikhail Pavlov, Alethea Power, Lukasz Kaiser, Mohammad Bavarian, Clemens Winter, Philippe Tillet, Felipe Petroski Such, Dave Cummings, Matthias Plappert, Fotios Chantzis, Elizabeth Barnes, Ariel Herbert-Voss, William Hebgen Guss, Alex Nichol, Alex Paino, Nikolas Tezak, Jie Tang, Igor Babuschkin, Suchir Balaji, Shantanu Jain, William Saunders, Christopher Hesse, Andrew N. Carr, Jan Leike, Josh Achiam, Vedant Misra, Evan Morikawa, Alec Radford, Matthew Knight, Miles Brundage, Mira Murati, Katie Mayer, Peter Welinder, Bob McGrew, Dario Amodei, Sam McCandlish, Ilya Sutskever, và Wojciech Zaremba. Evaluating Large Language Models Trained on Code, Tháng 7 2021. arXiv:2107.03374 [cs].

[8]Brian Chess và Gary McGraw. Static analysis for security. IEEE Security & Privacy, 2(6):76–79, Tháng 11 2004.

[9]The MITRE Corporation. CWE - CWE-1194: Hardware Design (4.1), 2022. https://cwe.mitre.org/data/definitions/1194.html.

[10] National Vulnerability Database. NVD - Home, 2023. Truy cập ngày 2023-06-06. https://nvd.nist.gov/.

[11] Yinlin Deng, Chunqiu Steven Xia, Chenyuan Yang, Shizhuo Dylan Zhang, Shujing Yang, và Lingming Zhang. Large Language Models are Edge-Case Fuzzers: Testing Deep Learning Libraries via FuzzGPT, Tháng 4 2023. arXiv:2304.02014 [cs].

[12] Ghada Dessouky, David Gens, Patrick Haney, Garrett Persyn, Arun Kanuparthi, Hareesh Khattri, Jason Fung, Ahmad-Reza Sadeghi, và Jeyavijayan Rajendran. HardFails: Insights into Software-Exploitable Hardware Bugs. Trong Proceedings of the 28th USENIX Conference on Security Symposium, SEC'19, trang 213–230, Santa Clara, CA, USA, 2019. USENIX Association.

[13] Elizabeth Dinella, Hanjun Dai, Ziyang Li, Mayur Naik, Le Song, và Ke Wang. Hoppity: Learning graph transformations to detect and fix bugs in programs. Trong International Conference on Learning Representations (ICLR), 2020.

[14] EvoSuite. Release V1.2.0 ·EvoSuite/evosuite, 2021. Truy cập 2023-05-30. https://github.com/EvoSuite/evosuite/releases/tag/v1.2.0.

[15] Philip Gage. A New Algorithm for Data Compression. C Users Journal, 12(2):23–38, Tháng 2 1994.

[16] Andrew Habib và Michael Pradel. How many of all bugs do we find? a study of static bug detectors. Trong Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering, ASE '18, trang 317–328, New York, NY, USA, Tháng 9 2018. Association for Computing Machinery.

[17] HACK@EVENT. HACK@DAC21 – HACK@EVENT, 2022. https://hackatevent.org/hackdac21/.

[18] Github Inc. CodeQL for research, 2021. https://securitylab.github.com/tools/codeql/.

[19] Infer. Infer, 2021. Truy cập 2023-06-06. https://github.com/facebook/infer.

[20] Jun Li, Bodong Zhao, và Chao Zhang. Fuzzing: a survey. Cybersecurity, 1(1):6, Tháng 12 2018.

[21] Tsz-On Li, Wenxi Zong, Yibo Wang, Haoye Tian, Ying Wang, Shing-Chi Cheung, và Jeff Kramer. Finding Failure-Inducing Test Cases with ChatGPT, Tháng 4 2023. arXiv:2304.11686 [cs].

[22] Derrick Lin, James Koppel, Angela Chen, và Armando Solar-Lezama. QuixBugs: a multi-lingual program repair benchmark set based on the quixey challenge. Trong Proceedings Companion of the 2017 ACM SIGPLAN International Conference on Systems, Programming, Languages, and Applications: Software for Humanity, SPLASH Companion 2017, trang 55–56, New York, NY, USA, Tháng 10 2017. Association for Computing Machinery.

[23] lowRISC contributors. Open source silicon root of trust (RoT) | OpenTitan, 2023. https://opentitan.org/.

[24] Steve McConnell. Code complete. Microsoft Press, Redmond, Wash, ấn bản thứ 2, 2004.

[25] Kishore Papineni, Salim Roukos, Todd Ward, và Wei-Jing Zhu. BLEU: a method for automatic evaluation of machine translation. Trong Proceedings of the 40th Annual Meeting on Association for Computational Linguistics, ACL '02, trang 311–318, USA, Tháng 7 2002. Association for Computational Linguistics.

[26] Hammond Pearce, Baleegh Ahmad, Benjamin Tan, Brendan Dolan-Gavitt, và Ramesh Karri. Asleep at the Keyboard? Assessing the Security of GitHub Copilot's Code Contributions. Trong 2022 IEEE Symposium on Security and Privacy (SP), trang 754–768, Tháng 5 2022. ISSN: 2375-1207.

[27] Hammond Pearce, Benjamin Tan, Baleegh Ahmad, Ramesh Karri, và Brendan Dolan-Gavitt. Examining Zero-Shot Vulnerability Repair with Large Language Models. Trong 2023 IEEE Symposium on Security and Privacy (SP), trang 2339–2356. IEEE Computer Society, 2023.

[28] Michael Pradel và Koushik Sen. DeepBugs: a learning approach to name-based bug detection. Proceedings of the ACM on Programming Languages, 2(OOPSLA):147:1–147:25, Tháng 10 2018.

[29] Error Prone. Error Prone, 2023. Truy cập 2023-05-30. https://github.com/google/error-prone.

[30] Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, và Ilya Sutskever. Language Models are Unsupervised Multitask Learners. trang 1–24, 2019. https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf.

[31] Randoop. Randoop: Automatic unit test generation for Java, 2023. Truy cập 2023-05-30. https://randoop.github.io/randoop/.

[32] Anonymized for review. Artifacts for "FLAG: Finding Line Anomalies (in code) with Generative AI", Tháng 6 2023. https://zenodo.org/record/8012211.

[33] Gustavo Sandoval, Hammond Pearce, Teo Nys, Ramesh Karri, Siddharth Garg, và Brendan Dolan-Gavitt. Lost at C: A User Study on the Security Implications of Large Language Model Code Assistants. USENIX Security Symposium, 2023.

[34] Sina Shamshiri, René Just, José Miguel Rojas, Gordon Fraser, Phil McMinn, và Andrea Arcuri. Do Automatically Generated Unit Tests Find Real Faults? An Empirical Study of Effectiveness and Challenges (T). Trong 2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE), trang 201–211, Tháng 11 2015.

[35] SpotBugs. SpotBugs, 2022. Truy cập 2023-05-30. https://spotbugs.github.io/.

[36] Daniela Steidl, Benjamin Hummel, và Elmar Juergens. Quality analysis of source code comments. Trong 2013 21st International Conference on Program Comprehension (ICPC), trang 83–92, Tháng 5 2013. ISSN: 1092-8138.

[37] Lin Tan, Ding Yuan, Gopal Krishna, và Yuanyuan Zhou. /*icomment: bugs or bad comments?*/. ACM SIGOPS Operating Systems Review, 41(6):145–158, Tháng 10 2007.

[38] Shin Hwei Tan, Darko Marinov, Lin Tan, và Gary T. Leavens. @tComment: Testing Javadoc Comments to Detect Comment-Code Inconsistencies. Trong Verification and Validation 2012 IEEE Fifth International Conference on Software Testing, trang 260–269, Tháng 4 2012. ISSN: 2159-4848.

[39] Yunosuke Teshima và Yutaka Watanobe. Bug Detection Based on LSTM Networks and Solution Codes. Trong 2018 IEEE International Conference on Systems, Man, and Cybernetics (SMC), trang 3541–3546, Tháng 10 2018. ISSN: 2577-1655.

[40] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, và Illia Polosukhin. Attention is All you Need. Trong Advances in Neural Information Processing Systems, tập 30. Curran Associates, Inc., 2017.

[41] Song Wang, Devin Chollak, Dana Movshovitz-Attias, và Lin Tan. Bugram: bug detection with n-gram language models. Trong Proceedings of the 31st IEEE/ACM International Conference on Automated Software Engineering, ASE '16, trang 708–719, New York, NY, USA, Tháng 8 2016. Association for Computing Machinery.

[42] Ratnadira Widyasari, Sheng Qin Sim, Camellia Lok, Haodi Qi, Jack Phan, Qijin Tay, Constance Tan, Fiona Wee, Jodie Ethelda Tan, Yuheng Yieh, Brian Goh, Ferdian Thung, Hong Jin Kang, Thong Hoang, David Lo, và Eng Lieh Ouh. BugsInPy: a database of existing bugs in Python programs to enable controlled testing and debugging studies. Trong Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering, ESEC/FSE 2020, trang 1556–1560, New York, NY, USA, Tháng 11 2020. Association for Computing Machinery.

[43] Jooyong Yi, Umair Z. Ahmed, Amey Karkare, Shin Hwei Tan, và Abhik Roychoudhury. A feasibility study of using automated program repair for introductory programming assignments. Trong Proceedings of the 2017 11th Joint Meeting on Foundations of Software Engineering, ESEC/FSE 2017, trang 740–751, New York, NY, USA, Tháng 8 2017. Association for Computing Machinery.

A Phụ lục
Bảng 6 là bảng đầy đủ cho các lỗi liên quan đến bảo mật được kiểm tra trong công trình này. Mô tả cho các điểm chuẩn khiếm khuyết chức năng được sử dụng và ID tương ứng của chúng được trình bày trong Bảng 7. Trong Hình 14, chúng tôi trình bày sự chia nhỏ của các kết hợp LLM và chế độ của chúng có thể phát hiện mỗi khiếm khuyết được thu thập.

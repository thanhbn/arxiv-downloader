# Thống Nhất Quan Điểm của NLP và Kỹ Thuật Phần Mềm: Khảo Sát về Các Mô Hình Ngôn Ngữ cho Code

## Thông Tin Tác Giả
- **Ziyin Zhang** - Đại học Giao thông Thượng Hải (daenerystargaryen@sjtu.edu.cn)
- **Chaoyu Chen** - Ant Group  
- **Bingchang Liu** - Ant Group
- **Cong Liao** - Ant Group
- **Zi Gong** - Ant Group
- **Hang Yu*** - Ant Group (hyu.hugo@antgroup.com)
- **Jianguo Li*** - Ant Group (lijg.zero@antgroup.com)  
- **Rui Wang*** - Đại học Giao thông Thượng Hải (wangrui12@sjtu.edu.cn)

*Tác giả liên hệ

## Tóm Tắt

Trong nghiên cứu này, chúng tôi xem xét một cách có hệ thống những tiến bộ gần đây trong kỹ thuật phần mềm với các mô hình ngôn ngữ, bao gồm hơn 70 mô hình, hơn 40 nhiệm vụ đánh giá, hơn 180 bộ dữ liệu, và 900 công trình liên quan. Khác với các nghiên cứu trước đây, chúng tôi tích hợp kỹ thuật phần mềm (SE) với xử lý ngôn ngữ tự nhiên (NLP) bằng cách thảo luận quan điểm của cả hai bên: SE áp dụng các mô hình ngôn ngữ cho tự động hóa phát triển, trong khi NLP sử dụng các nhiệm vụ SE để đánh giá mô hình ngôn ngữ. Chúng tôi phân tích các mô hình xử lý code thành các mô hình ngôn ngữ tổng quát được đại diện bởi họ GPT và các mô hình chuyên biệt được tiền huấn luyện đặc biệt trên code, thường với các mục tiêu được điều chỉnh riêng.

Chúng tôi thảo luận về mối quan hệ và sự khác biệt giữa các mô hình này, và làm nổi bật sự chuyển đổi lịch sử của việc mô hình hóa code từ các mô hình thống kê và RNN sang Transformer tiền huấn luyện và LLM, đây chính xác là con đường mà NLP đã trải qua.

Chúng tôi cũng vượt ra ngoài lập trình và xem xét ứng dụng của LLM trong các hoạt động kỹ thuật phần mềm khác bao gồm kỹ thuật yêu cầu, thử nghiệm, triển khai, và vận hành trong nỗ lực cung cấp một cái nhìn toàn cục về NLP trong SE, và xác định những thách thức chính cũng như hướng phát triển tiềm năng trong lĩnh vực này. Chúng tôi duy trì khảo sát này mở và cập nhật trên GitHub tại https://github.com/codefuse-ai/Awesome-Code-LLM.

## 1. Giới Thiệu

Mô hình hóa ngôn ngữ đã tiến bộ đáng kể trong những năm gần đây với sự ra đời của các Transformer tiền huấn luyện (Vaswani et al., 2017) như BERT (Devlin et al., 2019) và GPT (Radford et al., 2018). Khi các mô hình ngôn ngữ lớn (LLM) được mở rộng quy mô lên hàng trăm tỷ tham số và bắt đầu thể hiện những dấu hiệu sớm của trí tuệ nhân tạo tổng quát (Brown et al., 2020; Chowdhery et al., 2023; OpenAI, 2023), các ứng dụng của chúng cũng đã vượt ra ngoài xử lý văn bản. Được tiên phong bởi Codex (Chen et al., 2021b), LLM đã đạt được những kết quả ấn tượng trong xử lý code, tạo ra các sản phẩm thương mại như GitHub Copilot và các mô hình code mã nguồn mở nhiều tỷ tham số như StarCoder (Li et al., 2023h) và Code LLaMA (Rozière et al., 2023).

Tuy nhiên, việc ứng dụng Transformer tiền huấn luyện trong kỹ thuật phần mềm có thể được truy tìm từ trước khi các mô hình tự hồi quy chỉ giải mã trở nên thống trị (Feng et al., 2020; Liu et al., 2020), và cũng vượt ra ngoài xử lý code (Arora et al., 2023; Feng et al., 2024; Ma et al., 2024). Tuy nhiên, lĩnh vực này vẫn chưa có một đánh giá toàn diện. Trong nỗ lực kết nối khoảng cách giữa cộng đồng xử lý ngôn ngữ tự nhiên (NLP) và cộng đồng kỹ thuật phần mềm (SE) về chủ đề ứng dụng mô hình ngôn ngữ, chúng tôi thực hiện một khảo sát toàn cảnh về các mô hình ngôn ngữ cho SE trong nghiên cứu này, bao gồm hơn 70 mô hình, hơn 40 nhiệm vụ hạ nguồn, hơn 180 bộ dữ liệu, và 900 công trình liên quan. Với trọng tâm là các mô hình ngôn ngữ code, chúng tôi phân tích sự phát triển của chúng, thảo luận sự khác biệt của chúng so với các mô hình ngôn ngữ tổng quát, và làm nổi bật việc tích hợp các tính năng đặc thù của code như cây cú pháp trừu tượng hoặc luồng dữ liệu, cũng như các kỹ thuật mới nhất được điều chỉnh từ NLP.

Liên quan đến nghiên cứu của chúng tôi, chúng tôi biết về một số khảo sát về các chủ đề tương tự, với ba nghiên cứu đồng thời với chúng tôi (Hou et al., 2023; Zheng et al., 2023b; She et al., 2023). Tuy nhiên, những nghiên cứu này tập trung vào một bên NLP (Zan et al., 2023; Xu & Zhu, 2022) hoặc bên SE (Niu et al., 2023; Hou et al., 2023; Zheng et al., 2023b; She et al., 2023), và không bao gồm các mô hình, nhiệm vụ, và thách thức từ bên kia. Ví dụ, Zan et al. (2023) tập trung vào LLM cho việc tạo code từ văn bản, trong khi ít thảo luận về các ứng dụng khác trong cộng đồng kỹ thuật phần mềm. Ngược lại, Hou et al. (2023) và She et al. (2023) xem xét toàn diện các nghiên cứu từ các hội nghị SE như ASE và ICSE, nhưng chỉ trích dẫn một số ít nghiên cứu từ các hội nghị học sâu và NLP như ACL, EMNLP, NeurIPS, và ICLR.

Do đó, dựa trên những nghiên cứu này, chúng tôi nỗ lực hợp nhất quan điểm từ cả hai cộng đồng, và làm nổi bật mối quan hệ giữa NLP và SE: SE áp dụng các mô hình ngôn ngữ cho các nhiệm vụ khác nhau để tự động hóa, trong khi NLP sử dụng các nhiệm vụ từ SE để đánh giá mô hình ngôn ngữ. Chúng tôi quan sát thấy rằng các chủ đề tiên tiến từ mô hình hóa ngôn ngữ gần đây đã được giới thiệu vào xử lý code, bao gồm điều chỉnh theo hướng dẫn (Honovich et al., 2023; Xu et al., 2024; Luo et al., 2023), các mục tiêu điền khuyết (Tay et al., 2023b; Li et al., 2023h; Rozière et al., 2023), tái xem xét các quy luật mở rộng (Hoffmann et al., 2022; Gunasekar et al., 2023; Li et al., 2023i), cải tiến kiến trúc (Shazeer, 2019; Su et al., 2024; Dao et al., 2022), và các agent tự động (Qian et al., 2023; Hong et al., 2023), trong khi đổi lại các yêu cầu SE, được đại diện bởi lập trình (Chen et al., 2021b), đang cung cấp các bài kiểm tra thực tế cho những công nghệ này và thúc đẩy sự phát triển của LLM tiến tới sản xuất và triển khai.

Chúng tôi tin rằng một đánh giá có hệ thống về những tiến bộ này sẽ có lợi cho cả hai cộng đồng. Hơn nữa, khác với các đánh giá hiện tại tập trung vào các nhiệm vụ liên quan đến lập trình, chúng tôi cũng là những người đầu tiên vượt ra ngoài lập trình một cách rõ ràng và cung cấp một cái nhìn toàn cục về các ứng dụng LLM trong toàn bộ vòng đời phát triển phần mềm, bao gồm các giai đoạn riêng biệt như kỹ thuật yêu cầu, triển khai, và vận hành.

Phần còn lại của nghiên cứu này được tổ chức theo phân loại được trình bày trong Hình 1. Trong Mục 2, trước tiên chúng tôi đặt bối cảnh cho các nhiệm vụ hạ nguồn trong kỹ thuật phần mềm, làm nổi bật trọng tâm vào các nhiệm vụ liên quan đến lập trình. Sau đó, trong Mục 3, chúng tôi cung cấp các kiến thức cơ bản về mô hình hóa ngôn ngữ và các mô hình Transformer, và trong Mục 4, chúng tôi thảo luận về vô số LLM đã chứng minh khả năng lập trình. Trong Mục 5, chúng tôi xem xét các mô hình chuyên biệt và thường nhỏ hơn theo kiến trúc của chúng, với sự chú ý đặc biệt đến việc ứng dụng gần đây các mục tiêu điền khuyết, điều chỉnh theo hướng dẫn, học tăng cường, và cải tiến kỹ thuật. Sau đó, trong Mục 6, chúng tôi thảo luận các tính năng độc đáo của code không có sẵn cho ngôn ngữ tự nhiên nhưng đã được sử dụng để hỗ trợ xử lý code. Trong Mục 7, chúng tôi xem xét việc tích hợp gần đây nhất giữa LLM và phát triển phần mềm, trước khi cuối cùng kết luận nghiên cứu này trong Mục 8 và làm nổi bật những thách thức hiện tại trong xử lý code.

# 2. Các Nhiệm Vụ Hạ Nguồn trong Kỹ Thuật Phần Mềm

Trong thập kỷ qua, cộng đồng kỹ thuật phần mềm (SE) đã tìm ra các ứng dụng của mô hình ngôn ngữ trong nhiều nhiệm vụ hạ nguồn khác nhau. CodeXGLUE (Lu et al., 2021) tổng hợp hầu hết các nhiệm vụ liên quan đến code thành một benchmark duy nhất, trong khi HumanEval (Chen et al., 2021b) đã đưa tổng hợp NL-to-code vào tâm điểm trong cộng đồng NLP, từ đó trở thành một nhiệm vụ tiêu chuẩn để đánh giá LLM (Hình 2). Tuy nhiên, các nhiệm vụ khác, đặc biệt là những nhiệm vụ không trực tiếp liên quan đến lập trình, vẫn chưa được nghiên cứu kỹ lưỡng.

Trong phần này, trước tiên chúng tôi giới thiệu ngắn gọn từng nhiệm vụ SE truyền thống và việc ứng dụng các mô hình ngôn ngữ tiền huấn luyện trong chúng ở mục 2.1, và cung cấp danh sách toàn diện các công trình liên quan cho mỗi nhiệm vụ. Sau đó, chúng tôi xem xét các chỉ số đánh giá ở mục 2.2 và khảo sát tổng hợp chương trình chi tiết hơn ở mục 2.3. Cuối cùng, chúng tôi cũng thảo luận xu hướng mới nhất của lập trình cấp repository ở mục 2.4. Trong Phụ lục A và B, chúng tôi lần lượt liệt kê các benchmark cho mỗi nhiệm vụ hạ nguồn và hiệu suất của các mô hình ngôn ngữ trên chúng.

## 2.1 Các Nhiệm Vụ Hạ Nguồn trong SE

Thông lệ trong kỹ thuật phần mềm là phân loại các nhiệm vụ hạ nguồn theo tính chất đầu vào/đầu ra của chúng, chẳng hạn như các nhiệm vụ NL-to-PL (còn được gọi là text-to-code) và các nhiệm vụ PL-to-NL (tức là code-to-text) (Lu et al., 2021). Tuy nhiên, vì chúng tôi tập trung vào toàn bộ vòng đời phát triển phần mềm, chúng tôi áp dụng một phân loại khác trong nghiên cứu này, và phân loại các nhiệm vụ hạ nguồn theo các giai đoạn trong phát triển phần mềm: kỹ thuật yêu cầu (2.1.1), phát triển (2.1.2), thử nghiệm và phân tích (2.1.3), triển khai và vận hành (2.1.4), và cuối cùng là một số nhiệm vụ mới được đề xuất gần đây để đánh giá LLM (2.1.5). Chúng tôi lưu ý rằng phân loại này được xen kẽ với sự phân chia hiểu biết-tạo sinh trong NLP, vì mỗi danh mục có thể chứa cả nhiệm vụ hiểu biết và tạo sinh, như được thảo luận trong 2.1.6.

### 2.1.1 Kỹ Thuật Yêu Cầu

Kỹ thuật yêu cầu đề cập đến việc đặc tả, phân tích, và xác thực các yêu cầu phần mềm, mô hình hóa phần mềm, và thiết kế UI/UX. Các công trình liên quan được liệt kê trong Hình 3.

- **Phân tích yêu cầu** đề cập đến quá trình trích xuất, tóm tắt, phân loại, và xác thực các yêu cầu phần mềm. Hầu hết các công trình sớm trong lĩnh vực này dựa vào các công nghệ NLP thống kê như gắn thẻ POS (Part-of-Speech) và phân tích cú pháp phụ thuộc để trích xuất các hành động từ yêu cầu, trong khi các công trình gần đây hơn sử dụng LLM để trực tiếp phân loại, tóm tắt, hoặc trích xuất các mệnh đề yêu cầu. Zhao et al. (2020) cung cấp một khảo sát chi tiết về phân tích yêu cầu.

- **Thiết kế UI/UX**, viết tắt của thiết kế Giao diện Người dùng và Trải nghiệm Người dùng, là một bước cơ bản trong phát triển phần mềm. Trong khi nhiều công trình về thiết kế UI sử dụng các công nghệ thị giác máy tính cho thiết kế layout (Cheng et al., 2023; Kulkarni et al., 2023; Feng et al., 2023b), chúng tôi chỉ tập trung vào giao điểm của nhiệm vụ này và các công nghệ NLP, chẳng hạn như sử dụng mô hình ngôn ngữ để tạo ra các ngôn ngữ đánh dấu.

- **Tạo mô hình** nhằm tạo ra các mô hình phần mềm trong các ngôn ngữ mô hình hóa như UML (Unified Modeling Language). Abdelnabi et al. (2021a) và Ahmed et al. (2022) cung cấp các đánh giá toàn diện về nhiệm vụ này trước sự trỗi dậy của LLM.

### 2.1.2 Phát triển

Giai đoạn phát triển là giai đoạn diễn ra hầu hết các hoạt động lập trình, và cũng là giai đoạn có nhiều ứng dụng LLM nhất. Chúng tôi tiếp tục phân loại giai đoạn này thành các hoạt động khác nhau như tìm kiếm code, tạo code, chỉnh sửa code, gợi ý code, và giải thích code. Các công trình liên quan được liệt kê trong Hình 4 và 5.

#### Tìm Kiếm Code

- **Tìm kiếm NL-to-code**, còn được gọi là tìm kiếm text-to-code, nhằm truy xuất code có liên quan dựa trên các truy vấn ngôn ngữ tự nhiên, hoặc khai thác các cặp text-code song song từ một corpus không có chú thích. Nhiệm vụ này thường được thực hiện bằng cách tính toán một chỉ số tương đồng giữa embedding của truy vấn và code ứng viên, và các embedding ngữ cảnh được tạo ra bởi các mô hình ngôn ngữ hai chiều - như BERT - đã được chứng minh là cực kỳ hữu ích. Grazia & Pradel (2023) và Xie et al. (2023a) cung cấp các đánh giá toàn diện về chủ đề này.

- **Tìm kiếm Code-to-code** là một nhiệm vụ tương tự trong đó đầu vào là một đoạn code hiện có, thường ở một ngôn ngữ lập trình khác với mục tiêu. Tìm kiếm code-to-code có thể được tái công thức hóa như việc tìm các bản sao của truy vấn trong nhóm mục tiêu, và do đó tương đương với phát hiện bản sao ở một mức độ nào đó.

- **Khai thác API** đề cập đến quá trình tìm kiếm các API tương tự trong các thư viện khác nhau, có thể ở các ngôn ngữ lập trình khác nhau. Khai thác API truyền thống được giải quyết bằng cách tính toán các chỉ số tương đồng giữa API nguồn và mục tiêu sử dụng các mô hình truy xuất thông tin, nhưng khi các mô hình tạo sinh trở nên mạnh mẽ hơn, cũng đáng để khám phá việc tạo ra trực tiếp API mục tiêu như một nhiệm vụ sequence-to-sequence. Một nhiệm vụ liên quan chặt chẽ khác là khai thác thành ngữ (Allamanis & Sutton, 2014), trong đó mục tiêu là khám phá các mẫu code được sử dụng phổ biến, điều này làm lộ ra nhu cầu tiềm năng cho các API mới (Sivaraman et al., 2022).

#### Tạo Code

- **Tổng hợp chương trình** nhằm tạo code (thường là một hàm hoặc phương thức) dựa trên mô tả ngôn ngữ tự nhiên. Nhiệm vụ này có thể được xem như một phiên bản cập nhật của truy xuất NL-to-code sử dụng các mô hình tạo sinh thay vì các mô hình truy xuất. Dịch máy thống kê (SMT) và dịch máy thần kinh (NMT) đã được áp dụng rộng rãi cho nhiệm vụ này, thường với các bộ giải mã được tăng cường tận dụng các quy tắc ngữ pháp độc đáo của ngôn ngữ lập trình (Yin & Neubig, 2017; Rabinovich et al., 2017). Tuy nhiên, các mô hình ngôn ngữ tiền huấn luyện dựa trên kiến trúc Transformer đã thay đổi cuộc chơi bằng cách tạo ra trực tiếp mã nguồn theo phong cách mô hình hóa ngôn ngữ tự hồi quy, thậm chí không cần điều chỉnh cụ thể cho nhiệm vụ (Chen et al., 2021b). Chúng tôi thảo luận nhiệm vụ này chi tiết hơn trong Mục 2.3.

- **Hoàn thành code** nhằm hoàn thành một đoạn code dựa trên tiền tố của nó, và vẫn là một trong những ứng dụng phổ biến nhất của các mô hình ngôn ngữ code trong IDE đến nay. Đây về cơ bản là mô hình hóa ngôn ngữ được áp dụng cho code (mà chúng tôi gọi là "mô hình hóa code"), và các công nghệ liên quan đã được giới thiệu dần dần: n-gram, RNN, và Transformer. Tuy nhiên, do tính chất có cấu trúc của ngôn ngữ lập trình, nhiều công trình sớm nhận thấy các mô hình thống kê được hỗ trợ ngữ pháp hoạt động tốt hơn (Bielik et al., 2016; Hellendoorn & Devanbu, 2017), và các mô hình thần kinh chỉ trở nên thống trị sau năm 2018.

- **Điền khuyết code** là một nhiệm vụ được đề xuất gần đây, sau khi tiền huấn luyện fill-in-the-middle (Bavarian et al., 2022) trở nên phổ biến. Đây là một tổng quát hóa của hoàn thành code, trong đó không chỉ ngữ cảnh bên trái mà còn ngữ cảnh bên phải được cung cấp.

- **Text-to-SQL** là một trường hợp đặc biệt của tổng hợp chương trình, trong đó mô hình được giao nhiệm vụ tạo ra các lệnh SQL từ các truy vấn ngôn ngữ tự nhiên. Đây đã là một chủ đề được quan tâm đặc biệt trong cộng đồng NLP (như có thể thấy từ Hình 4), và một giả thuyết cho điều này là bản chất khai báo và ngữ pháp hạn chế của SQL làm cho việc tối ưu hóa dễ dàng hơn so với các ngôn ngữ lập trình mệnh lệnh như C và Python (Marcus et al., 2019; 2020). Chúng tôi tham khảo Kumar et al. (2022); Deng et al. (2022a); Qin et al. (2022a); Katsogiannis-Meimarakis & Koutrika (2023) cho các khảo sát về chủ đề này.

#### Chỉnh Sửa Code

- **Dịch code** nhằm dịch một đoạn code (thường là một hàm hoặc phương thức) sang một ngôn ngữ lập trình khác. Mối quan hệ giữa dịch code và tìm kiếm code đa ngôn ngữ tương tự như mối quan hệ giữa tổng hợp chương trình và truy xuất text-to-code, và các mô hình SMT/NMT cũng đã được áp dụng rộng rãi cho nhiệm vụ này. Một trong những ứng dụng quan trọng của dịch code là di chuyển các dự án cũ được viết bằng các ngôn ngữ lỗi thời. Tuy nhiên, chúng ta vẫn chưa chứng kiến những ứng dụng như vậy ở quy mô lớn trong kỷ nguyên LLM, vì cửa sổ ngữ cảnh của ngay cả những mô hình ngôn ngữ mạnh nhất cũng khá hạn chế khi đối mặt với những dự án như vậy. Malyala et al. (2023) cung cấp một khảo sát ngắn về nhiệm vụ này từ góc độ SE.

- **Sửa chữa chương trình**, còn được biết đến như sửa lỗi, nhằm sửa một đoạn code có lỗi. Giống như dịch code, đây là một nhiệm vụ tạo sinh sequence-to-sequence truyền thống, và có rất nhiều khảo sát về chủ đề này (Gazzola et al., 2018; Monperrus, 2018; Zhong et al., 2022; Zhang et al., 2023d; Huang et al., 2023a).

#### Gợi Ý Code

- **Dự đoán kiểu** nhằm dự đoán kiểu của các biến trong các ngôn ngữ lập trình động như Python và JavaScript. Nó đã được sử dụng như một mục tiêu tiền huấn luyện cho các mô hình ngôn ngữ code (Wang et al., 2022e), trong đó nó thường được đơn giản hóa thành một nhiệm vụ gắn thẻ nhị phân để dự đoán token nào trong code là định danh (Wang et al., 2021d;f).

- **Dự đoán định danh** là nhiệm vụ dự đoán tên định danh trong code. Vì những tên này được coi là chứa thông tin ngữ nghĩa quan trọng, nhiệm vụ này đã được sử dụng cho tóm tắt code (Allamanis et al., 2016b), cũng như tiền huấn luyện các mô hình code (Wang et al., 2021f; Niu et al., 2022). Một trường hợp đặc biệt của dự đoán định danh là dự đoán tên phương thức.

- **Bài kiểm tra điền khuyết** là một nhiệm vụ được đề xuất gần đây cho hiểu biết code, sau sự trỗi dậy của tiền huấn luyện kiểu BERT. Do ngữ nghĩa độc đáo của ngôn ngữ lập trình, một số từ khóa thường được chọn cho bài kiểm tra này, chẳng hạn như min và max (Feng et al., 2020).

#### Giải Thích Code

- **Tóm tắt code**, **tạo comment**, và **tài liệu code** đều nhằm tạo ra các giải thích cho code để tạo điều kiện hiểu code, nhưng với trọng tâm hơi khác nhau. Tóm tắt code tạo ra một tóm tắt ngôn ngữ tự nhiên của code đã cho, trong khi tạo comment tạo ra các comment. Hai thuật ngữ này thường được sử dụng thay thế cho nhau trong tài liệu, và đối tượng mục tiêu của chúng thường là các lập trình viên. Mặt khác, tài liệu code có cấu trúc hơn, bao gồm thông tin chi tiết hơn.

# 3. Kiến Thức Cơ Bản về Mô Hình Hóa Ngôn Ngữ

Vì code cuối cùng là một tập con của ngôn ngữ tự nhiên, các mô hình ngôn ngữ đã được sử dụng rộng rãi để giải quyết các nhiệm vụ được liệt kê trong Mục 2. Trước khi đi sâu vào chính các mô hình ngôn ngữ, trước tiên chúng tôi xem xét ngắn gọn các kiến thức cơ bản về mô hình hóa ngôn ngữ dựa trên Transformer trong phần này theo các lựa chọn chung về mục tiêu huấn luyện, và cũng một số thiết kế triển khai.

## 3.1 Mô Hình Hóa Ngôn Ngữ Nhân Quả

Các mô hình ngôn ngữ đơn hướng (còn được gọi là mô hình ngôn ngữ nhân quả) phân tích xác suất của một câu thành tích của xác suất có điều kiện của mỗi token với quy tắc chuỗi. Một đoạn văn bản đầu vào x = [x₁, x₂, ..., xₙ] gồm n token được mô hình hóa như sau:

P(x) = ∏ᵢ₌₁ⁿ pθ(xᵢ|x₁:ᵢ₋₁)     (3)

trong đó x₁:ᵢ₋₁ là viết tắt của các token trước xᵢ trong đầu vào, và θ là các tham số của mô hình. Với các bộ giải mã Transformer như GPT (Radford et al., 2018; 2019; Brown et al., 2020) và LLaMA (Touvron et al., 2023a;b), xác suất có điều kiện trong (3) được mô hình hóa bằng cách thêm một mặt nạ attention vào ma trận attention của mỗi khối Transformer, đảm bảo rằng xᵢ chỉ có thể chú ý đến các token trước đó. Trong quá trình huấn luyện, mất mát entropy chéo trên tất cả các token trong đầu vào được tính toán song song, trong khi tại thời điểm suy luận, mỗi token mới được tạo ra một cách tự hồi quy. Để biết thêm chi tiết về kiến trúc Transformer, chúng tôi tham khảo Vaswani et al. (2017).

## 3.2 Mô Hình Hóa Ngôn Ngữ Có Mặt Nạ

Khác với các mô hình ngôn ngữ nhân quả, các mô hình ngôn ngữ hai chiều được huấn luyện để có được biểu diễn ngữ cảnh tốt hơn của văn bản thay vì tạo ra văn bản một cách tự hồi quy. Trong Transformer vanilla, phần encoder được phép chú ý đến ngữ cảnh bên trái cũng như bên phải của một token cho mục đích này. BERT (Devlin et al., 2019) tiến thêm một bước và chỉ tiền huấn luyện một encoder Transformer. Một tập hợp M các token được chọn ngẫu nhiên trong đầu vào được thay thế bằng một token đặc biệt [MASK] để có được một đầu vào nhiễu x̂, ví dụ [[CLS], x₁, [MASK], x₃, [MASK], x₅, [EOS]], và mô hình được huấn luyện để khôi phục các token gốc bằng cách tối đa hóa:

∏ₘ∈M pθ(m|x̂)     (4)

Mặc dù mục tiêu này yêu cầu mô hình phải có hiểu biết sâu sắc về văn bản đầu vào để tái tạo lại nó, nhưng nó gặp phải vấn đề hiệu quả huấn luyện thấp, vì chỉ một tập hợp nhỏ các token (thường là 15%) được che mặt (và do đó được "huấn luyện trên"). Để giải quyết vấn đề này, Clark et al. (2020) đề xuất ELECTRA, được huấn luyện để phân biệt liệu mỗi token trong đầu vào có được thay thế bởi một mô hình giống BERT hay không, từ đó tính toán mất mát trên tất cả các token đầu vào.

## 3.3 Mục Tiêu Khử Nhiễu

LM nhân quả kiểu GPT và LM hai chiều kiểu BERT mỗi loại đều có điểm mạnh và điểm yếu riêng. Trong khi GPT có thể được sử dụng cho việc tạo sinh tự hồi quy, nó thiếu biểu diễn hai chiều của văn bản đầu vào, và do đó không phù hợp cho các nhiệm vụ tạo sinh sequence-to-sequence (seq2seq) như dịch thuật và tóm tắt. Mặt khác, BERT có thể tạo ra các biểu diễn hai chiều, nhưng chỉ được tiền huấn luyện cho việc điền mặt nạ, không phải tạo sinh.

Kiến trúc encoder-decoder Transformer vanilla kết hợp các ưu điểm tương ứng của GPT và BERT. T5 (Raffel et al., 2020) là một mô hình như vậy được tiền huấn luyện với span corruption, có thể được coi là một biến thể của MLM. Trong quá trình tiền huấn luyện, các đoạn văn bản trong đầu vào được thay thế bằng các token sentinel, đóng vai trò tương tự như [MASK] trong BERT. Đầu vào nhiễu đầu tiên được xử lý bởi encoder với attention hai chiều, và các đoạn bị che mặt sau đó được tạo ra một cách tự hồi quy bởi decoder. 

Chính thức, nếu k đoạn được lấy mẫu để làm hỏng trong đầu vào x, đầu vào nhiễu x̂ sau đó được xây dựng bằng cách thay thế mỗi đoạn bằng một token đặc biệt <extra_id_i>, với i = 1,2,...,k, và mục tiêu y được xây dựng bằng cách nối tất cả các đoạn được thêm vào trước với các sentinel tương ứng: [<extra_id_1>, span 1, ..., <extra_id_k>, span k]. Mô hình sau đó được huấn luyện với một mục tiêu seq2seq tiêu chuẩn, bằng cách tối đa hóa:

pθ(y|x̂) = ∏ᵢ₌₁ⁿʸ pθ(yᵢ|x̂, y₁:ᵢ₋₁)     (5)

Lester et al. (2021) cho thấy rằng các mô hình được tiền huấn luyện với các mục tiêu như vậy có thể được điều chỉnh cho mô hình hóa ngôn ngữ tự hồi quy với tiền huấn luyện bổ sung sử dụng mục tiêu mô hình hóa ngôn ngữ tiền tố, tức là chia văn bản thành hai phần, xử lý phần đầu tiên với encoder và tạo ra phần thứ hai với decoder.

Tay et al. (2023b) lập luận rằng span corruption cũng có liên quan chặt chẽ đến CLM, vì người ta có thể che mặt toàn bộ văn bản đầu vào như một đoạn duy nhất và huấn luyện decoder để tạo ra nó một cách tự hồi quy. Được truyền cảm hứng bởi mối quan hệ này, họ đề xuất UL2, là sự kết hợp của nhiều mục tiêu span corruption khác nhau về tỷ lệ làm hỏng và độ dài đoạn. Áp dụng nó cho cả mô hình encoder-decoder và mô hình chỉ có decoder, họ thấy rằng các mô hình encoder-decoder hoạt động tốt hơn dưới cùng một ràng buộc ngân sách tính toán. Các nghiên cứu khác cũng đã phát hiện rằng các mô hình encoder-decoder như vậy nói chung hoạt động tốt hơn so với các mô hình chỉ có decoder nhân quả (Wang et al., 2022c; Soltan et al., 2022).

## 3.4 Mục Tiêu Phụ Trợ

Các mục tiêu mô hình hóa ngôn ngữ, như CLM và MLM đã thảo luận trước đây, chủ yếu huấn luyện mô hình để nắm bắt thông tin cấp token và không hiệu quả trong việc mô hình hóa cấu trúc tài liệu. Do đó, các mục tiêu phụ trợ thường được thêm vào để giúp các mô hình học thông tin toàn cục như vậy. BERT được tiền huấn luyện với dự đoán câu tiếp theo (NSP) cùng với MLM, được công thức hóa như một nhiệm vụ phân loại nhị phân để dự đoán liệu hai đoạn trong đầu vào có kề nhau trong corpus gốc hay không. Lan et al. (2020) đề xuất một nhiệm vụ dự đoán thứ tự câu (SOP) thách thức hơn, trong đó các mẫu âm được xây dựng bằng cách hoán đổi thứ tự của hai câu kề nhau thay vì lấy mẫu một câu ngẫu nhiên từ các tài liệu khác.

Tương tự, Raffel et al. (2020) trộn các mẫu hạ nguồn có giám sát như GLUE (Wang et al., 2018a) vào bộ dữ liệu tiền huấn luyện của T5 để thực hiện tiền huấn luyện đa nhiệm vụ. Tuy nhiên, điều đáng chú ý là vì họ thống nhất tất cả các nhiệm vụ thành định dạng text-to-text, mục tiêu huấn luyện giống nhau cho tiền huấn luyện tự giám sát của họ.

# 4. Các Mô Hình Ngôn Ngữ Tổng Quát cho Code

Kể từ khi các mô hình ngôn ngữ được mở rộng quy mô lên hàng trăm tỷ tham số (Brown et al., 2020; Chowdhery et al., 2023), nhiều mô hình trong số đó đã thể hiện khả năng lập trình không tầm thường, ngay cả khi chúng không được thiết kế hoặc huấn luyện đặc biệt cho code. Được tiên phong bởi Codex, các nhà nghiên cứu cũng đã phát hiện ra rằng việc tiền huấn luyện liên tục trên code có thể cải thiện đáng kể hiệu suất của các mô hình ngôn ngữ trên code.

## 4.1 Các Mô Hình Ngôn Ngữ Sẵn Có

Các mô hình ngôn ngữ lớn thường được tiền huấn luyện trên hàng nghìn tỷ token theo các quy luật mở rộng (Kaplan et al., 2020; Hoffmann et al., 2022), và một lượng dữ liệu văn bản như vậy thường là một hỗn hợp đa dạng với một phần không nhỏ là code. Ví dụ, The Pile (Gao et al., 2021) bao gồm 95GB code được thu thập từ GitHub trong tổng số 800GB dữ liệu thô, trong khi bộ dữ liệu tiền huấn luyện đa ngôn ngữ ROOTS (Laurençon et al., 2022) cũng chứa 163GB code trải rộng trên 13 ngôn ngữ lập trình trong hỗn hợp 1.6TB của nó. Là hai trong số những bộ dữ liệu tiền huấn luyện mã nguồn mở lớn nhất, chúng đã hỗ trợ nhiều mô hình ngôn ngữ có khả năng lập trình.

Ví dụ, GPT-J (Wang & Komatsuzaki, 2021) được Chen et al. (2021b) báo cáo là thể hiện hiệu suất không tầm thường trên HumanEval, trong khi Scao et al. (2022) báo cáo kết quả tương tự cho GPT-NeoX (Black et al., 2022) và BLOOM. LLaMA (Touvron et al., 2023a), có bộ dữ liệu tiền huấn luyện bao gồm 328GB code từ GitHub, đạt được hiệu suất pass@1 là 23.7 trên HumanEval, và người kế nhiệm LLaMA 2 (Touvron et al., 2023b) đạt được điểm số còn cao hơn là 29.9.

Mặt khác, các mô hình mã nguồn đóng thường hoạt động tốt hơn. LaMDA (Thoppilan et al., 2022) và PaLM (Chowdhery et al., 2023), có bộ dữ liệu tiền huấn luyện chứa lần lượt 12.5% và 5% code, đạt được hiệu suất pass@1 là 14.0 và 26.2 trên HumanEval, trong khi GPT-4 (OpenAI, 2023) thiết lập kỷ lục đáng kinh ngạc là 67.0 (và một phiên bản sớm được Bubeck et al. (2023) báo cáo là 82) mà cho đến gần đây vẫn cao hơn bất kỳ mô hình chuyên biệt nào được tiền huấn luyện hoặc điều chỉnh theo hướng dẫn cho code.

Gần đây hơn, xu hướng chung là huấn luyện các mô hình nhỏ hơn với bộ dữ liệu lớn hơn, theo quy luật mở rộng đã được sửa đổi (Hoffmann et al., 2022). Ví dụ, Baichuan 2 (Yang et al., 2023a) là một mô hình 13B được huấn luyện trên 2.6T token, trong khi Qwen (Bai et al., 2023) là một mô hình 14B được huấn luyện trên 3T token. Chúng đạt được lần lượt 17.1 và 32.3 pass@1 trên HumanEval.

Tuy nhiên, Li et al. (2023i) chứng minh rằng các mô hình nhỏ đến 1.3B có thể có được khả năng lập trình tương đương với các mô hình lớn hơn nhiều trong khi vẫn duy trì hiệu suất hợp lý trong xử lý văn bản tổng quát và thậm chí thể hiện một số khả năng nổi lên (Wei et al., 2022c) như lý luận chuỗi suy nghĩ (Wei et al., 2022d). Mô hình của họ, Phi-1.5, được huấn luyện trên 21B token dữ liệu sách giáo khoa được tạo ra bởi ChatGPT, và 100B token dữ liệu web được lọc từ Stack Overflow và Refined Web (Penedo et al., 2023), và đạt được hiệu suất pass@1 là 41.4 trên HumanEval.

Một xu hướng nổi lên khác là các mô hình hỗn hợp chuyên gia (Lepikhin et al., 2021; Fedus et al., 2022; Du et al., 2022). Đáng chú ý, Jiang et al. (2024a) gần đây giới thiệu Mixtral 8x7B, trong đó chỉ 13B tham số được kích hoạt cho mỗi token trong quá trình suy luận, nhưng đạt được 40.2 trên HumanEval và vượt qua các mô hình dense lớn hơn nhiều như LLaMA 2. Tương tự, Dai et al. (2024a) trình bày DeepSeekMoE, trong đó chỉ 2.8B tham số được kích hoạt trong một mô hình 16B, ghi được 26.8 điểm trên HumanEval.

Hiệu suất chính xác của các mô hình này được trình bày trong Bảng 1.

## 4.2 Các Mô Hình Ngôn Ngữ với Tiền Huấn Luyện Bổ Sung trên Code

Cùng với benchmark mang tính bước ngoặt HumanEval, Chen et al. (2021b) đã khởi động kỷ nguyên LLM cho code với Codex, là các checkpoint GPT-3 được tiền huấn luyện trên 100B token code bổ sung và là một trong những mô hình nhiều tỷ tham số sớm nhất cho code. Theo công trình của họ, các nhà nghiên cứu khác cũng đã chuyên biệt hóa LLM của họ trên code với tiền huấn luyện bổ sung.

Chowdhery et al. (2023) huấn luyện PaLM trên 7.8B token code bổ sung để có được PaLM-Coder, thiết lập state-of-the-art mới trên HumanEval và MBPP (Bảng 1) mà chỉ bị phá vỡ sau đó bởi người kế nhiệm PaLM 2-S*, phiên bản nhỏ nhất của PaLM 2 (Anil et al., 2023b) được huấn luyện thêm trên một lượng code không được tiết lộ. Tương tự, Lewkowycz et al. (2022) huấn luyện PaLM trên 38.5B token của các bài báo arXiv và nội dung toán học, trong khi Rozière et al. (2023) huấn luyện LLaMA 2 (Touvron et al., 2023b) trên hơn 500B token code để có được Code LLaMA, có hiệu suất trên HumanEval vượt qua tất cả các LM trước đó ngoại trừ GPT-4 (Bảng 1).

Liu et al. (2023b) tiếp tục huấn luyện Code LLaMA với điều chỉnh đa nhiệm vụ (MFT) để giới thiệu CodeFuse-CodeLLaMA, đạt được 74.4 pass@1 trên HumanEval và thậm chí vượt qua hiệu suất của GPT-4 được công bố trong OpenAI (2023).

Mặc dù hầu như tất cả các mô hình này đều là bộ giải mã Transformer được tiền huấn luyện với CLM, một số sửa đổi kiến trúc đã được giới thiệu trong quá trình này, như chúng tôi đã lưu ý trong Mục 3.5. Tất cả các mô hình này sử dụng pre-norm, và GPT-J giới thiệu parallel attention, sau đó được PaLM, GPT-NeoX, và Phi-1.5 áp dụng. PaLM giới thiệu MQA và RoPE vào LLM, và RoPE hiện được sử dụng bởi hầu hết các mô hình ngôn ngữ, bao gồm GPT-NeoX, hai thế hệ LLaMA, Qwen, và phiên bản 7B của Baichuan 2. Tuy nhiên, BLOOM và phiên bản 13B của Baichuan 2 sử dụng ALiBi cho embedding vị trí, trong khi LLaMA 2 và Code LLaMA áp dụng GQA thay vì MHA hoặc MQA.

Trong Mục 5, chúng tôi cho thấy rằng các mô hình chuyên biệt được tiền huấn luyện độc quyền trên code cũng đã theo sát những tiến bộ này.

# 5. Các Mô Hình Ngôn Ngữ Chuyên Biệt cho Code

Khi các Transformer tiền huấn luyện như GPT và BERT đạt được thành công đáng kể trong xử lý ngôn ngữ tự nhiên, các kiến trúc mô hình, mô hình học tập, và mục tiêu huấn luyện như vậy đã sớm được cộng đồng kỹ thuật phần mềm áp dụng để tạo ra các mô hình chuyên biệt cho hiểu biết và tạo sinh code. Trong phần này, trước tiên chúng tôi xem xét các bộ dữ liệu phổ biến được sử dụng để tiền huấn luyện các mô hình ngôn ngữ code (Mục 5.1), và sau đó đi sâu vào họ phức tạp của các LM code theo kiến trúc mô hình của chúng: các mô hình chỉ có encoder (Mục 5.2), các mô hình encoder-decoder (Mục 5.3), các mô hình chỉ có decoder (Mục 5.4), UniLM (Mục 5.5), và các mô hình khuếch tán (Mục 5.6). Cuối cùng, trong Mục 5.7, chúng tôi cũng minh họa xu hướng hiện tại của việc áp dụng các kỹ thuật gần đây hơn trong NLP, như điều chỉnh theo hướng dẫn (Wei et al., 2022b; Sanh et al., 2022; Chung et al., 2022) và học tăng cường (Ouyang et al., 2022) vào xử lý code.

## 5.1 Bộ Dữ Liệu Huấn Luyện cho Code

Trong khi dữ liệu văn bản để tiền huấn luyện các mô hình ngôn ngữ thường được thu thập từ web và phải trải qua quá trình tiền xử lý tỉ mỉ và thường là tích cực (Raffel et al., 2020), dữ liệu code đến một cách tự nhiên như các tài liệu hoàn chỉnh từ các repository GitHub công khai. Thậm chí còn tốt hơn, chúng đi kèm với các chỉ số chất lượng sẵn có như số lượng sao hoặc fork (mặc dù Allal et al. (2023) cho rằng số sao tương quan kém với hiệu suất hạ nguồn). Kết quả là, nhiều bộ dữ liệu tiền huấn luyện code quy mô lớn đã được giới thiệu, bao gồm CodeSearchNet (Husain et al., 2019), CodeParrot (Tunstall et al., 2022), và the Stack (Kocetkov et al., 2023), tổng cộng lần lượt 20GB, 50GB và 3TB các tài liệu code (Bảng 2).

Mặc dù các bộ dữ liệu này được dành cho việc huấn luyện các mô hình code, cần lưu ý rằng code cuối cùng là một dạng đặc biệt của ngôn ngữ tự nhiên, vì từ vựng của hầu hết các ngôn ngữ lập trình là một tập con nhỏ của tiếng Anh. Bên cạnh đó, code chất lượng cao thường được xen kẽ với các comment hoặc tài liệu ngôn ngữ tự nhiên, điều này cũng cho phép các mô hình có được kiến thức nhất định về biểu diễn văn bản tổng quát. Thực tế, trong số 6.5M hàm trong CodeSearchNet, 2.3M được ghép đôi với tài liệu ngôn ngữ tự nhiên, cho phép các mô hình huấn luyện rõ ràng trên dữ liệu đa phương thức như vậy.

So với ngôn ngữ tự nhiên, một sản phẩm phụ khác của việc thu thập code từ GitHub là lịch sử commit, bao gồm code trước commit, code sau commit, và một thông điệp ngắn mô tả commit, có thể phục vụ một cách lỏng lẻo như một hướng dẫn cho các mô hình ngôn ngữ. Muennighoff et al. (2024) tận dụng tính năng này và xây dựng một bộ dữ liệu 2GB CommitPackFT chứa 742K mẫu dữ liệu hướng dẫn cho code, loại bỏ nhu cầu lao động con người rộng rãi cần thiết để xây dựng các hướng dẫn ngôn ngữ tự nhiên (Sanh et al., 2022; Wang et al., 2022g).

Ngoài huấn luyện đa phương thức và điều chỉnh theo hướng dẫn, một xu hướng gần đây khác trong việc xây dựng bộ dữ liệu code là tổng hợp dữ liệu với các mô hình mạnh mẽ như ChatGPT. Mặc dù phương pháp này ban đầu được đề xuất để tạo dữ liệu hướng dẫn trong ngôn ngữ tự nhiên (Wang et al., 2023g; Honovich et al., 2023), Gunasekar et al. (2023) tiến thêm một bước và tổng hợp 1B token sách giáo khoa Python và bài tập lập trình để tiền huấn luyện một mô hình 1.3B, đạt được kết quả state-of-the-art trên HumanEval có thể so sánh với các mô hình lớn hơn nhiều được huấn luyện trên các bộ dữ liệu lớn hơn đáng kể.

## 5.2 Encoders

Các Transformer encoder tiền huấn luyện như BERT (Devlin et al., 2019), RoBERTa (Liu et al., 2019d), và ELECTRA (Clark et al., 2020) đã đạt được kết quả ấn tượng trong các nhiệm vụ hiểu ngôn ngữ tự nhiên, và những phương pháp này đã sớm được giới thiệu vào xử lý code sau sự ra đời của chúng. Kanade et al. (2020) sao chép quy trình huấn luyện của BERT trên một corpus code để tạo ra CuBERT, thể hiện hiệu suất vượt trội so với LSTM (Hochreiter & Schmidhuber, 1997) và các Transformer không tiền huấn luyện.

Feng et al. (2020), mặt khác, huấn luyện CodeBERT với MLM và RTD của ELECTRA trên CodeSearchNet. Họ cũng sử dụng các cặp text-code rõ ràng trong CodeSearchNet, và sử dụng chúng lần lượt như đoạn thứ nhất và thứ hai trong đầu vào của BERT. Khi sử dụng CodeBERT để khởi tạo phần encoder của một Transformer vanilla cho các nhiệm vụ tạo sinh sequence-to-sequence như tóm tắt code, họ quan sát được một cải thiện hiệu suất vừa phải so với các baseline không tiền huấn luyện.

Ngoài những mục tiêu huấn luyện tiêu chuẩn này, nhiều mục tiêu phụ trợ được thiết kế đặc biệt cho code cũng đã được giới thiệu. GraphCodeBERT (Guo et al., 2021a) và SynCoBERT (Wang et al., 2021d) đều trích xuất đồ thị từ mã nguồn (đồ thị luồng dữ liệu và cây cú pháp trừu tượng, tương ứng) và huấn luyện các mô hình để dự đoán các mối quan hệ tô pô giữa các nút, trong khi SynCoBERT và Code-MVP (Wang et al., 2022e) cũng thêm suy luận kiểu vào giai đoạn tiền huấn luyện của họ dưới dạng gắn thẻ.

Một mục tiêu phổ biến khác là học tương phản: SynCoBERT và Code-MVP tương phản giữa các góc nhìn khác nhau của đầu vào (như code, comment, AST, và code đã biến đổi), trong khi DISCO (Ding et al., 2022a) xây dựng các cặp mẫu dương bằng các phép biến đổi bảo toàn ngữ nghĩa như làm mờ, và các cặp âm bằng cách tiêm các lỗi nhân tạo.

## 5.3 Encoder-Decoders

Trong NLP, các Transformer encoder-decoder tiền huấn luyện như T5 (Raffel et al., 2020) và BART (Lewis et al., 2020) cũng đã để lại dấu ấn đáng chú ý trong sự tiến bộ của mô hình hóa ngôn ngữ trong vài năm qua. Ví dụ, T5 thống nhất tất cả các nhiệm vụ văn bản thành định dạng sequence to sequence và thiết lập các kỷ lục mới trên GLUE (Wang et al., 2018a) và SuperGLUE (Wang et al., 2019). So với các mô hình chỉ có encoder, encoder-decoder tự nhiên mạnh mẽ hơn vì chúng có thể được sử dụng cho tạo sinh văn bản có điều kiện, trong khi phần encoder của chúng luôn có thể được tách ra để thực hiện các nhiệm vụ yêu cầu kiến trúc chỉ có encoder, như hồi quy (Tay et al., 2023b).

Được truyền cảm hứng bởi những ưu điểm này của kiến trúc encoder-decoder, nhiều mô hình như vậy đã được đề xuất cho xử lý code. PyMT5 (Clement et al., 2020) và Mastropaolo et al. (2021) sao chép quá trình tiền huấn luyện và điều chỉnh đa nhiệm vụ của T5 trên corpus code, trong khi Ahmad et al. (2021) giới thiệu PLBART, một BART được tiền huấn luyện trên 655GB dữ liệu kết hợp của Java, Python, và ngôn ngữ tự nhiên.

Lachaux et al. (2021) lập luận rằng MLM có thể là một nhiệm vụ quá dễ dàng đối với ngôn ngữ lập trình vì tên định danh thường xuất hiện nhiều lần trong một cửa sổ ngữ cảnh duy nhất, và đề xuất một mục tiêu tiền huấn luyện khử làm mờ, trong đó mô hình được huấn luyện để chuyển đổi code đã làm mờ trở lại dạng gốc của nó.

Dựa trên những công trình sớm này, Wang et al. (2021f) đề xuất CodeT5, được tiền huấn luyện luân phiên với 1) span corruption gốc của T5; 2) gắn thẻ định danh (trong đó mỗi token trong đầu vào code được gắn thẻ là định danh hoặc không phải định danh); 3) dự đoán định danh được che mặt (một dạng đặc biệt của span corruption trong đó tất cả định danh được che mặt); và 4) tạo sinh text-to-code & code-to-text.

Người kế nhiệm của nó, CodeT5+ (Wang et al., 2023h), lấy cảm hứng từ UL2 (Tay et al., 2023b) và giới thiệu mô hình hóa ngôn ngữ nhân quả (CLM) vào tiền huấn luyện, cùng với các mục tiêu tương phản bổ sung dựa trên khớp text-code.

## 5.4 Decoders

Sau sự ra mắt mang tính bước ngoặt của GPT-3 (Brown et al., 2020) và việc khám phá ra học trong ngữ cảnh, các mô hình Transformer chỉ có decoder đã trở nên thống trị trong mô hình hóa ngôn ngữ (Rae et al., 2021; Hoffmann et al., 2022; Chowdhery et al., 2023; Scao et al., 2022; Touvron et al., 2023a;b, trong số những mô hình khác). Nhiều mô hình được tiền huấn luyện tương tự với CLM cũng đã xuất hiện trong xử lý code, như GPT-C (Svyatkovskiy et al., 2020), CodeGPT (Lu et al., 2021), PolyCoder (Xu et al., 2022), CodeGen (Nijkamp et al., 2023b), PyCodeGPT (Zan et al., 2022), Pangu-Coder (Christopoulou et al., 2022), CodeGeeX (Zheng et al., 2023a), Jam (Su et al., 2023a), Phi-1 (Gunasekar et al., 2023), và CodeFuse (Di et al., 2023).

Trong số những mô hình này, một số mục tiêu huấn luyện thay thế đã được thử nghiệm, như MLM và Masked CLM trong Pangu-Coder, nhưng được thấy là hoạt động kém hơn so với huấn luyện chỉ với CLM. Đáng chú ý, Gunasekar et al. (2023) trình bày Phi-1, một mô hình nhỏ 1.3B được huấn luyện trên một bộ dữ liệu chỉ có 7B token bao gồm 6B token từ StackOverflow và 1B dữ liệu tổng hợp được tạo bởi ChatGPT nhưng đạt được 50.6 pass@1 trên HumanEval và 55.5 pass@1 trên MBPP, có thể so sánh với các mô hình lớn hơn nhiều (cả về kích thước mô hình và kích thước dữ liệu huấn luyện) như Code LLaMA hoặc PaLM 2.

Mặc dù Christopoulou et al. (2022) báo cáo các mục tiêu khử nhiễu hoạt động kém trong các mô hình chỉ có decoder, đã có những công trình khác kết hợp thành công việc khử nhiễu hoặc tiền huấn luyện đa nhiệm vụ với kiến trúc decoder. InCoder (Fried et al., 2023), SantaCoder (Allal et al., 2023), StarCoder (Li et al., 2023h), DeepSeek Coder (Guo et al., 2024), và CodeShell (Xie et al., 2024) được huấn luyện với mục tiêu fill-in-the-middle (FIM), còn được gọi là causal masking bởi Fried et al. (2023), về cơ bản là span corruption (Raffel et al., 2020) được áp dụng cho kiến trúc chỉ có decoder.

Một trong những ưu điểm rõ ràng của các mục tiêu infilling này là chúng tiêm vào các mô hình khả năng điền vào các chỗ trống ở giữa code đầu vào tại thời điểm suy luận, trong khi CLM chỉ cho phép tạo sinh tự hồi quy. Như Bảng 4 cho thấy, tuy nhiên, những mục tiêu này cũng dẫn đến hiệu suất cao hơn trong các nhiệm vụ hạ nguồn khi so sánh với các mô hình chỉ có CLM như CodeGen, mặc dù lợi ích chính xác của huấn luyện infilling vẫn còn gây tranh cãi (Nijkamp et al., 2023a).

## 5.5 UniLMs

Theo UniLM (Dong et al., 2019) trong NLP, một số công trình trong xử lý code cũng đã tiền huấn luyện họ thứ tư này của các mô hình Transformer trên code. CugLM (Liu et al., 2020) được huấn luyện với cả CLM và MLM + NSP thông qua các mặt nạ attention luân phiên, trong khi UniXcoder được huấn luyện với CLM, MLM, Span Corruption (theo kiểu Prefix LM) cùng với các mục tiêu phụ trợ bao gồm học tương phản và tạo sinh tương hỗ text-code. Tuy nhiên, cả hai mô hình đều có kích thước tương đối nhỏ, và liệu kiến trúc này có phù hợp với xử lý code hay không vẫn chưa được khám phá ở quy mô lớn.

## 5.6 Mô Hình Khuếch Tán

Hiện tại kiến trúc Transformer thống trị việc tạo sinh văn bản, nhưng một số công trình (Li et al., 2022d; Lin et al., 2023) cũng đã áp dụng Mô hình Khuếch tán (Ho et al., 2020) từ thị giác máy tính cho tạo sinh văn bản. Gần đây CodeFusion (Singh et al., 2023) cũng giới thiệu các mô hình khuếch tán vào mô hình hóa code, và chứng minh rằng một mô hình khuếch tán 75M có thể vượt trội hơn StarCoder, CodeT5+, và GPT-3 trên ba bộ dữ liệu tổng hợp code.

## 5.7 Điều Chỉnh theo Hướng Dẫn và Học Tăng Cường cho Code

Trong xử lý ngôn ngữ tự nhiên, việc huấn luyện các mô hình trên một tập hợp đa dạng các nhiệm vụ với tiền tố hướng dẫn, được gọi là điều chỉnh theo hướng dẫn, đã được chứng minh là mở khóa khả năng tổng quát hóa đa nhiệm vụ (Ouyang et al., 2022; Chung et al., 2022; Iyer et al., 2022). Ban đầu, những mẫu dữ liệu hướng dẫn này được biên dịch thủ công hoặc thu thập từ đám đông (Wei et al., 2022b; Sanh et al., 2022), nhưng các nghiên cứu sau đó phát hiện ra rằng các hướng dẫn được tạo bởi LLM là đủ (Wang et al., 2023g; Honovich et al., 2023).

Theo những công trình này trong ngôn ngữ tự nhiên, các nhà nghiên cứu từ cộng đồng code cũng đã áp dụng điều chỉnh hướng dẫn cho các mô hình của họ. Wang et al. (2023h) điều chỉnh CodeT5+ với 20K dữ liệu hướng dẫn được tạo bởi InstructGPT (Ouyang et al., 2022) để có được InstructCodeT5+. WizardCoder (Luo et al., 2023) theo các phương pháp của WizardLM (Xu et al., 2024) để phát triển 20K mẫu code Alpaca (Taori et al., 2023) thành một bộ dữ liệu 78K và sử dụng nó để điều chỉnh StarCoder.

Trong NLP, một công nghệ khác liên quan chặt chẽ đến điều chỉnh hướng dẫn là học tăng cường từ phản hồi con người (RLHF), đã đóng một vai trò quan trọng trong việc căn chỉnh LLM với các giá trị con người (Ouyang et al., 2022; Bai et al., 2022). Ưu điểm của học tăng cường là nó có thể kết hợp các tín hiệu phần thưởng không khả vi vào huấn luyện, như BLEU (Bahdanau et al., 2017) và sở thích con người (Christiano et al., 2017), nhưng phản hồi con người cần thiết trong việc căn chỉnh LLM thường liên quan đến lao động rộng rãi trong việc chú thích.

So sánh, việc áp dụng học tăng cường cho các mô hình code có một lợi thế tự nhiên, vì các trình biên dịch có thể được sử dụng để tự động tạo phản hồi cho các mẫu code được tạo ra bởi các mô hình ngôn ngữ.

# 6. Các Tính Năng Code cho Mô Hình Ngôn Ngữ

Một sự khác biệt chính giữa ngôn ngữ lập trình và ngôn ngữ tự nhiên là ngôn ngữ lập trình được định nghĩa một cách nhân tạo để chính xác và không mơ hồ, và cần được biên dịch (hoặc thông dịch) mà không có lỗi trước khi thực thi. Điều này cho phép linh hoạt hơn nhiều trong việc thiết kế các mục tiêu tiền huấn luyện trên code, bên cạnh các thao tác từ vựng như CLM, MLM, và Span Corruption.

Một xu hướng tương tự có thể được quan sát trong những năm cuối trước khi mạng thần kinh được giới thiệu vào tài liệu NLP chính thống (Sutskever et al., 2014; Bahdanau et al., 2015), khi các nhà nghiên cứu trong cộng đồng MT đã sử dụng các góc nhìn thay thế của văn bản như các tính năng cú pháp để cải thiện hiệu suất của các hệ thống SMT (Galley et al., 2006; Chiang, 2007). Tuy nhiên, những tính năng này không áp dụng được phổ biến hoặc thậm chí được thống nhất, và thường dẫn đến các hệ thống cực kỳ phức tạp (ví dụ, kích thước của bộ nhãn gắn thẻ từ loại tiếng Anh có thể dao động từ hàng chục đến hàng trăm).

Tuy nhiên, ngôn ngữ lập trình hoạt động tốt hơn nhiều trong những khía cạnh này. Mỗi ngôn ngữ lập trình chính thống, như C, Python, và Java, đi kèm với các bộ công cụ trình biên dịch sẵn có cho phép trích xuất dễ dàng và chính xác thông tin ngữ nghĩa như Cây Cú Pháp Trừu Tượng (AST), Biểu Diễn Trung Gian độc lập ngôn ngữ (IR), và thông tin phụ trợ như kiểu của mỗi token và đồ thị luồng điều khiển/dữ liệu (CFG/DFG). Do đó, trong bối cảnh mô hình hóa ngôn ngữ dựa trên Transformer cho code, nhiều công trình đã kết hợp những tính năng này vào quy trình huấn luyện của họ.

## 6.1 Cây Cú Pháp Trừu Tượng và Biểu Diễn Trung Gian

AST là một trong những kết quả trung gian phổ biến nhất của quá trình biên dịch, trong đó một chương trình được phân tích thành một cây các phép toán và toán hạng của chúng. Trước khi Transformer được phổ biến trong cộng đồng xử lý code, đã có các công trình như InferCode (Bui et al., 2021a) xử lý những biểu diễn này với các kiến trúc mạng đặc biệt như Tree-Based CNN và thực hiện tiền huấn luyện tự giám sát bằng cách dự đoán các cây con.

TreeBERT (Jiang et al., 2021b) là một trong những nỗ lực đầu tiên đưa AST vào framework tiền huấn luyện-điều chỉnh dựa trên Transformer. Đây là một Transformer encoder-decoder được tiền huấn luyện với Tree MLM và Node Order Prediction, trong đó encoder nhận một tập hợp các đường dẫn thành phần trong AST làm đầu vào (với mỗi token là một đường dẫn, là sự nối của các biểu diễn nút của nó) trong khi decoder nhận code làm đầu vào.

Tuy nhiên, phương pháp được sử dụng bởi TreeBERT phức tạp và không mở rộng tốt. Các công trình sau đó chủ yếu chọn xử lý AST thành một chuỗi văn bản trước và coi nó như một phần bình thường của đầu vào. Ví dụ, Wang et al. (2021d) xử lý AST bằng duyệt theo chiều sâu trước và nối nó với code và comment, sau đó huấn luyện SynCoBERT (khác với TreeBERT, thực sự là một mô hình chỉ có encoder giống BERT) với bốn mục tiêu: 1) MLM; 2) gắn thẻ định danh; 3) dự đoán cạnh AST (dự đoán liệu có tồn tại cạnh giữa hai nút AST từ tích vô hướng của các biểu diễn nút này hay không); và 4) học tương phản trên i) các cặp code và AST, cũng như ii) các cặp text và code-AST.

Tương tự, SPT-Code (Niu et al., 2022), một Transformer encoder-decoder, nhận việc nối code, AST được tuần tự hóa, và text làm đầu vào, và được tiền huấn luyện với 1) span corruption; 2) dự đoán code-AST (NSP với một đoạn là code và một đoạn là AST); và 3) tạo tên phương thức, một dạng đặc biệt của span corruption trong đó tên phương thức được che mặt.

Trong pipeline biên dịch, AST thường được theo sau bởi các biểu diễn trung gian độc lập ngôn ngữ, như LLVM IR (Lattner & Adve, 2004). Tính độc lập của những tính năng như vậy khỏi các ngôn ngữ lập trình cụ thể làm cho chúng trở thành các ứng cử viên phù hợp cho các trục xoay dịch thuật, như tiếng Anh trong dịch máy của các ngôn ngữ tự nhiên ít tài nguyên (Leng et al., 2019). Szafraniec et al. (2023) tận dụng đặc điểm này và mở rộng Transcoder (Rozière et al., 2020) với mô hình hóa ngôn ngữ dịch thuật (Conneau & Lample, 2019) trên code và IR, cũng như tạo IR từ code. Họ cũng khảo sát các mục tiêu khác như decompilation IR (tức là tạo code từ IR) và IR pivot (tức là tạo trực tiếp code trong một ngôn ngữ từ IR của ngôn ngữ khác), cả hai đều cho thấy kết quả đầy hứa hẹn.

## 6.2 Luồng Điều Khiển và Luồng Dữ Liệu

Mặc dù AST và IR đã được chứng minh là thông tin hữu ích trong một số nhiệm vụ như dịch code, chúng có tính chất tĩnh, giống như mã nguồn, và có thể không nắm bắt được các thuộc tính ngữ nghĩa của code chỉ được tiết lộ tại thời điểm chạy (Wang & Su, 2020). Tuy nhiên, những ngữ nghĩa như vậy được chứa trong các tính năng động như luồng điều khiển và luồng dữ liệu. Tương tự như AST, các mạng chuyên biệt đã được sử dụng để xử lý thông tin như vậy trước sự trỗi dậy của các Transformer tiền huấn luyện, như Message Passing Neural Network được sử dụng bởi ProGraML (Cummins et al., 2021). Tuy nhiên, khác với AST, ngay cả sau khi các Transformer tiền huấn luyện trở nên thống trị, ít công trình đã nhìn theo hướng này.

GraphCodeBERT (Guo et al., 2021a) là một trong những công trình như vậy, tạo ra các token đặc biệt và embedding vị trí cho các biến trong đồ thị luồng, và nối chuỗi biến sau text và mã nguồn để xây dựng đầu vào mô hình, với các mặt nạ attention được điều chỉnh trên các đoạn code và biến: các token từ đoạn code và đoạn biến có thể chú ý lẫn nhau nếu và chỉ nếu biến được xác định từ token code, và đối với các token trong đoạn biến, vi được phép chú ý đến vj nếu có cạnh trực tiếp từ vj đến vi trong luồng dữ liệu. Mô hình sau đó được tiền huấn luyện với MLM kết hợp với dự đoán cạnh và căn chỉnh nút, cả hai đều được thực hiện bằng phân loại nhị phân từ tích vô hướng của các biểu diễn của hai token (một từ đoạn code và một từ đoạn biến cho căn chỉnh nút, và cả hai từ đoạn biến cho dự đoán cạnh).

## 6.3 Kiểu

Ngoài AST, IR, và luồng dữ liệu, thông tin kiểu cũng đã được sử dụng để hỗ trợ các mô hình ngôn ngữ trong việc xử lý code. Ví dụ, CugLM (Liu et al., 2020) sử dụng thông tin kiểu trong quá trình điều chỉnh để hỗ trợ việc dự đoán các token cho MLM đơn hướng (tức là MLM với mặt nạ attention đơn hướng): kiểu của một token được che mặt trước tiên được dự đoán từ biểu diễn của lớp Transformer cuối cùng, và sau đó chính token được dự đoán dựa trên cả biểu diễn ẩn và kiểu được dự đoán. Ngược lại, cả CodeT5 (Wang et al., 2021f) và SynCoBERT (Wang et al., 2021d) đều bao gồm gắn thẻ định danh trong các mục tiêu tiền huấn luyện của họ, có thể được xem như dự đoán kiểu thô.

## 6.4 Biến Đổi Chương Trình

Như chúng tôi đã chỉ ra trong Mục 5.3, các phép biến đổi chương trình bảo toàn chức năng đã được chứng minh là những kỹ thuật quan trọng trong việc tiền huấn luyện các mô hình ngôn ngữ code. Làm mờ là một thể hiện của biến đổi chương trình, và những biến đổi khác bao gồm biến đổi vòng lặp (for-while), biến đổi điều kiện (if-switch), tiêm code chết (ví dụ if True: pass), và hoán đổi câu lệnh.

DOBF (Lachaux et al., 2021) và NatGen (Chakraborty et al., 2022a) là hai mô hình ngôn ngữ code được tiền huấn luyện để khôi phục chương trình gốc từ những phép biến đổi như vậy, trong khi Wang et al. (2022a) cũng áp dụng các phép biến đổi chương trình trong giai đoạn điều chỉnh của các mô hình ngôn ngữ để làm cho chúng mạnh mẽ hơn đối với các mẫu thử nghiệm đã biến đổi.

Đáng chú ý, Wang et al. (2022e) tích hợp nhiều tính năng được đề cập ở trên vào Code-MVP: mã nguồn, docstring, AST, CFG, và mã nguồn đã biến đổi thông qua đổi tên định danh, hoán đổi vòng lặp, và chèn code chết. Mô hình, được khởi tạo từ GraphCodeBERT, sau đó được huấn luyện với MLM, dự đoán kiểu tinh vi, và học tương phản trên các góc nhìn khác nhau, như text vs. code, code vs. AST, và code vs. CFG.

# 7. LLM trong Phát Triển Phần Mềm

Khi các mô hình ngôn ngữ thiết lập những kỷ lục mới trên các benchmark kỹ thuật phần mềm, các công nghệ kỹ thuật phần mềm cũng đang mở rộng ranh giới của các mô hình ngôn ngữ ngược lại, và do đó đã dẫn chúng vào các chu kỳ phát triển thực tế.

## 7.1 LLM được Mở Rộng với Công Cụ Lập Trình

Nghiên cứu trong cộng đồng NLP đã chỉ ra rằng LLM có thể học cách sử dụng các công cụ bên ngoài như máy tính, hệ thống MT, và công cụ tìm kiếm (Thoppilan et al., 2022; Schick et al., 2023). Do đó, trình thông dịch đã được sử dụng để tăng cường LLM trong các nhiệm vụ lý luận phức tạp. PAL (Gao et al., 2023b) và PoT (Chen et al., 2023e) đều mở rộng Codex với các trình thông dịch Python cho tính toán số học, trong khi ViperGPT (Surís et al., 2023) mở rộng nó hơn nữa bằng cách gọi các API thị giác để trích xuất thông tin từ đầu vào hình ảnh và trả lời các câu hỏi liên quan.

Tuy nhiên, LLM không phải lúc nào cũng tạo ra code có thể được thông dịch và thực thi, và cũng đã có một dòng nghiên cứu khám phá khả năng mô phỏng trình thông dịch bằng chính LLM. Nye et al. (2021) huấn luyện LLM để mô phỏng việc thực thi các chương trình bằng cách xuất trạng thái chương trình ở mỗi bước. Gần đây hơn, Li et al. (2023a) đề xuất Chain-of-Code, trong đó một trình thông dịch thực sự thực thi code được tạo ra cho đến khi có lỗi xảy ra, lúc đó LLM tiếp quản để mô phỏng việc thực thi. Chae et al. (2024) tương tự đề xuất framework Think-and-Execute, trong đó LLM tạo ra pseudo code và sau đó mô phỏng việc thực thi nó để giải quyết các nhiệm vụ lý luận.

Ngoài việc giảm bớt gánh nặng tính toán số học trong các nhiệm vụ lý luận trừu tượng, trình thông dịch (cùng với unit test) cũng cung cấp phản hồi về quá trình tạo sinh code, cho phép tạo sinh và tinh chỉnh code tương tác. Các công trình như vậy bao gồm Self-Edit (Zhang et al., 2023c), LeTI (Wang et al., 2023f), OpenCodeInterpreter (Zheng et al., 2024), ProCoder (Bi et al., 2024), Cycle (Ding et al., 2024), và SOAP (Huang et al., 2024), chạy code được tạo ra bởi mô hình với unit test để cung cấp phản hồi cho việc tinh chỉnh thêm.

Ngoài ra, CodeT (Chen et al., 2023a), TiCoder (Bareiß et al., 2022), và CONLINE (He et al., 2024) cũng sử dụng chính LLM để tạo ra unit test, trong khi Self-Refine (Madaan et al., 2023) gửi code được tạo ra đến một LLM thay vì trình thông dịch để nhận phản hồi. Zhou et al. (2023a) cho thấy rằng plugin trình thông dịch của OpenAI cho phép GPT-4 tự debug, trong khi InterCode (Yang et al., 2023d) cung cấp một benchmark để đánh giá lập trình tương tác.

Một chủ đề liên quan chặt chẽ đến việc sử dụng công cụ trong nghiên cứu LLM là lập kế hoạch như các agent thông minh, đã được chứng minh là tăng cường khả năng của LLM cả về mặt lý thuyết và thực nghiệm (Feng et al., 2023a). Ruan et al. (2023) phát hiện rằng LLM có thể lập kế hoạch để giải quyết các nhiệm vụ phức tạp sử dụng các bộ tạo SQL và Python bên ngoài, trong khi CodePlan (Bairi et al., 2023) chứng minh họ có thể thực hiện lập trình cấp repository thông qua lập kế hoạch thích ứng.

Một dòng công trình khác sử dụng LLM để tạo ra các hệ thống đa agent cho tạo sinh code, như tự hợp tác (Dong et al., 2023), ChatDev (Qian et al., 2023), MetaGPT (Hong et al., 2023), LCG (Lin et al., 2024), MAGIS (Tao et al., 2024), và SoA (Ishibashi & Nishimura, 2024). Trong những framework này, nhiều LLM được prompt để đóng các vai trò khác biệt như lập trình viên, người đánh giá, và quản lý. Những vai trò này tương tác với nhau, chia nhỏ việc tạo sinh code thành các giai đoạn khác nhau (ví dụ: thiết kế, lập trình, thử nghiệm, và tài liệu hóa), và hợp tác để hoàn thành các nhiệm vụ phức tạp.

## 7.2 LLM được Tích Hợp vào Phát Triển Phần Mềm

Với sự gia tăng khả năng lập trình tương tác của LLM, các nhà nghiên cứu cũng đã bắt đầu tích hợp chúng vào từng quy trình của phát triển phần mềm.

Hoàn thành code tự động là một trong những ứng dụng sớm nhất của các mô hình ngôn ngữ trong phát triển phần mềm, vì chúng chỉ yêu cầu khả năng dự đoán token tiếp theo. Ngay cả trước khi các mô hình ngôn ngữ được mở rộng lên hàng tỷ tham số, đã có sự tích hợp của các hệ thống hoàn thành như Pythia (Svyatkovskiy et al., 2019) và IntelliCode (Svyatkovskiy et al., 2020) vào các IDE phổ biến.

Tuy nhiên, gần đây, việc ứng dụng các mô hình ngôn ngữ code đã vượt ra ngoài việc hoàn thành code đơn giản. GitHub Copilot có lẽ là một trong những trợ lý AI code phổ biến nhất, với các tính năng đa dạng bao gồm tạo sinh code, phát hiện lỗ hổng, và quản lý giấy phép, trong khi CodeFuse (Di et al., 2023) cũng tích hợp tạo sinh code, dịch code, comment code, và tạo testcase vào một extension IDE duy nhất. Tuy nhiên, khi các mô hình ngôn ngữ code trở nên lớn hơn, việc triển khai phía client và hiệu suất thời gian thực của chúng cũng đặt ra những thách thức mới.

Khi LLM tiếp tục tiến bộ, việc xây dựng ứng dụng trên chúng cũng đang phát triển thành một nhiệm vụ quan trọng. Nhiều framework mã nguồn mở cho những ứng dụng như vậy đã được phát hành, bao gồm LangChain, AutoGPT, và WorkGPT. Những framework này cung cấp các trừu tượng hóa trên các mô hình ngôn ngữ cho các nhà phát triển, và đang tích cực cách mạng hóa toàn bộ quy trình phát triển phần mềm ngay cả khi khảo sát này đang được hoàn thiện.

## 7.3 Phân Tích Code được Tạo ra bởi LLM

Khi các trợ lý AI code trở nên phổ biến, nhiều công trình gần đây cũng đã tập trung vào việc kiểm tra code được tạo ra bởi AI từ các khía cạnh khác nhau, bao gồm tính đúng đắn (Nguyen & Nadi, 2022; Yetistiren et al., 2023), lỗi (Jesse et al., 2023; Tambon et al., 2024), lỗ hổng (Asare et al., 2023; Sandoval et al., 2023; Perry et al., 2023; Hamer et al., 2024), tính mạnh mẽ cú pháp (Sarker et al., 2024), hiệu quả (Niu et al., 2024), và ảo giác (Liu et al., 2024).

Các nghiên cứu của Asare et al. (2023) và Sandoval et al. (2023) cho thấy rằng các trợ lý AI code không gây ra rủi ro bảo mật thêm so với các lập trình viên con người, và Hamer et al. (2024) cũng phát hiện rằng các phản hồi của ChatGPT đối với các câu hỏi liên quan đến bảo mật chứa ít lỗ hổng hơn so với các câu trả lời từ StackOverflow. Ngược lại, Perry et al. (2023) thấy rằng người dùng viết code kém an toàn hơn đáng kể khi được hỗ trợ bởi AI.

Về mặt độ phức tạp của code, Nguyen & Nadi (2022) thấy GitHub Copilot tạo ra code có độ phức tạp thấp mà không có sự khác biệt có ý nghĩa thống kê giữa các ngôn ngữ, trong khi Liu et al. (2023n) thấy ChatGPT tạo ra code phức tạp nhất trong C và code ít phức tạp nhất trong Python. Nhìn chung, các trợ lý AI code vẫn đang trong giai đoạn sơ khai và liên tục phát triển, và tác động của chúng đối với phát triển phần mềm vẫn chưa được điều tra một cách có hệ thống.

# 8. Kết Luận và Thách Thức

Trong nghiên cứu này, chúng tôi đã xem xét một cách có hệ thống lịch sử của các mô hình ngôn ngữ Transformer tiền huấn luyện trong xử lý code và các nhiệm vụ kỹ thuật phần mềm khác. Sự tiến bộ trong mô hình hóa code nói chung theo con đường lịch sử của NLP, phát triển từ các mô hình SMT, đến các mô hình NMT, và sau đó đến việc điều chỉnh các Transformer tiền huấn luyện và cuối cùng đến ứng dụng few-shot của LLM và thậm chí các agent tự động trong sản xuất thực tế.

Khác với ngôn ngữ tự nhiên, bản chất của code làm cho việc trích xuất thông tin phụ trợ từ các góc nhìn thay thế trở nên dễ dàng, và sử dụng trình thông dịch và unit test để có phản hồi tự động.

Với những điều này trong tâm trí, chúng tôi xác định một số thách thức trong việc phát triển hiện tại của mô hình hóa code:

**- Các benchmark toàn diện và thách thức hơn.** Benchmark HumanEval được sử dụng rộng rãi đóng vai trò chính trong sự phát triển của Code LLM. Tuy nhiên, nó tương đối nhỏ và bảng điểm của nó đã được thao túng gần như hoàn hảo, và cộng đồng khao khát một tiêu chuẩn mới để đánh giá LLM. HumanEval và các benchmark tương tự khác tập trung vào việc tạo ra các hàm Python độc lập từ các docstring có cấu trúc tốt, điều này không phản ánh hành vi người dùng thực tế.

Trong các tình huống thực tế, yêu cầu phần mềm hiếm khi được cô đọng thành một docstring duy nhất, và LLM phải học cách giao tiếp hiệu quả để làm rõ khi không chắc chắn về yêu cầu. Ngoài ra, các hàm độc lập hiếm khi được sử dụng trong sản xuất, nơi phần mềm có các phụ thuộc phức tạp trong một repository. Do đó, các benchmark thế hệ tiếp theo cũng nên tính đến ngữ cảnh đa file như vậy, và các benchmark gần đây như SWE-bench (Jimenez et al., 2023) đại diện cho những nỗ lực đầy hứa hẹn theo hướng này.

**- Đánh giá và ứng dụng LLM vượt ra ngoài tạo sinh code truyền thống.** Như chúng tôi đã chỉ ra trong Mục 2, đánh giá hiện tại về khả năng lập trình của LLM trong cộng đồng NLP tập trung vào tạo sinh code, trong khi bỏ qua các hoạt động khác trong kỹ thuật phần mềm, như mô hình hóa phần mềm và thử nghiệm. Từ góc độ ứng dụng, ứng dụng phổ biến nhất của LLM trong kỹ thuật phần mềm là các plugin IDE, cung cấp cho các nhà phát triển các gợi ý code, trong khi các giai đoạn khác trong phát triển phần mềm mà chúng tôi đã đề cập trong Mục 2 cũng phần lớn bị bỏ qua.

**- Thu thập dữ liệu chất lượng cao.** Với Gunasekar et al. (2023) đạt được hiệu suất SOTA với một mô hình 1.3B được huấn luyện trên dữ liệu sách giáo khoa, chúng tôi tin rằng việc lựa chọn dữ liệu huấn luyện và sử dụng dữ liệu tổng hợp sẽ càng trở nên nổi bật trong tương lai gần, cho cả tiền huấn luyện tự giám sát và điều chỉnh có giám sát.

**- Tích hợp các tính năng code vào mô hình ngôn ngữ.** Như chúng tôi đã lưu ý trong Mục 6.2, CFG và DFG vẫn chưa được sử dụng ở quy mô lớn trong mô hình hóa ngôn ngữ code. Những công trình ít ỏi sử dụng luồng dữ liệu thực hiện thay đổi đến các mặt nạ attention của mô hình, điều này hạn chế nghiêm trọng khả năng tổng quát hóa đa nhiệm vụ và khả năng mở rộng của chúng. Chúng tôi tin rằng việc tích hợp liền mạch các tính năng như vậy vào đầu vào văn bản đáng để nghiên cứu trong tương lai.

**- Vượt ra ngoài mô hình lập trình mệnh lệnh.** Trong Mục 2.1.7, chúng tôi đã chỉ ra rằng hầu hết nghiên cứu hiện tại về code LLM tập trung vào các ngôn ngữ lập trình mệnh lệnh phổ biến như C và Python, trong khi bỏ qua các ngôn ngữ khai báo và hàm trừ SQL. Tuy nhiên, mô hình của các ngôn ngữ khai báo và hàm làm cho chúng phù hợp hơn với ngôn ngữ tự nhiên, và do đó đáng được chú ý nghiên cứu hơn trong tương lai.

**- Các kiến trúc mô hình và mục tiêu huấn luyện thay thế.** Trong Bảng 3, chúng tôi đã chỉ ra rằng nhiều mô hình ngôn ngữ code được tiền huấn luyện với các mục tiêu phụ trợ cụ thể cho code, nhưng những mô hình này đều thuộc họ chỉ có encoder hoặc encoder-decoder, trong khi các mô hình chỉ có decoder vẫn chưa được tăng cường với các mục tiêu thay thế. Ngoài ra, như được tiên phong bởi Singh et al. (2023), chúng tôi tin rằng các mô hình khuếch tán sẽ tìm thấy chỗ đứng trong mô hình hóa code trong tương lai.

**- Các vấn đề an toàn và đạo đức liên quan đến code LLM.** Khi các mô hình ngôn ngữ phát triển mạnh mẽ, chúng cũng gây ra những lo ngại về an toàn bao gồm nhưng không giới hạn ở ô nhiễm dữ liệu, tạo sinh độc hại hoặc thiên vị, rò rỉ thông tin cá nhân, và ảo giác. Trong phát triển phần mềm, những mô hình này nên được triển khai với sự thận trọng đặc biệt, vì code được tạo ra bởi chúng có thể chứa rủi ro bảo mật dẫn đến kết quả thảm khốc.

Dữ liệu tiền huấn luyện cũng đang trở thành một chủ đề nhạy cảm về đạo đức, và Kocetkov et al. (2023) thực hiện một bước có ý nghĩa hướng tới vấn đề này bằng cách cho phép các nhà phát triển loại bỏ code của họ khỏi the Stack. Khi dữ liệu huấn luyện tổng hợp trở nên phổ biến, các nhà nghiên cứu cũng nên tiến hành thận trọng về thực hành như vậy, vì hậu quả của việc huấn luyện các mô hình AI với dữ liệu được tạo ra bởi AI vẫn chưa được điều tra ở quy mô lớn.

---

Với việc trình bày khảo sát này, chúng tôi hy vọng cung cấp một cái nhìn toàn cục về ứng dụng của các mô hình ngôn ngữ trong kỹ thuật phần mềm và kết nối nghiên cứu từ hai cộng đồng. Chúng tôi tin rằng làn sóng LLM hiện tại cuối cùng sẽ được chuyển đổi thành các ứng dụng thực tế, và dẫn dắt nhân loại đến một tương lai tươi sáng hơn.

## Lời Cảm Ơn

Nghiên cứu này được hỗ trợ bởi Ant Group.
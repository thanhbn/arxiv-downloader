Về Việc Sử Dụng Học Liên Tục cho Khái Quát Hóa Ngoài Phân Phối trong Các Mô Hình Ngôn Ngữ Được Đào Tạo Trước của Mã Nguồn

Martin Weyssow
DIRO, Đại học Montreal
Montreal, Canada
martin.weyssow@umontreal.ca

Xin Zhou  
Đại học Quản lý Singapore
Singapore
xinzhou.2020@phdcs.smu.edu.sg

Kisub Kim∗
Đại học Quản lý Singapore  
Singapore
kisubkim@smu.edu.sg

David Lo
Đại học Quản lý Singapore
Singapore
davidlo@smu.edu.sg

Houari Sahraoui
DIRO, Đại học Montreal
Montreal, Canada
sahraouh@iro.umontreal.ca

TÓM TẮT

Các mô hình ngôn ngữ được đào tạo trước (PLMs) đã trở thành một kỹ thuật phổ biến trong học sâu cho mã nguồn, sử dụng quy trình hai giai đoạn đào tạo trước và tinh chỉnh để có được kiến thức tổng quát về mã nguồn và chuyên môn hóa trong nhiều nhiệm vụ hạ nguồn khác nhau. Tuy nhiên, bản chất động của các cơ sở mã phần mềm đặt ra thách thức đối với hiệu quả và tính mạnh mẽ của PLMs. Đặc biệt, các tình huống thực tế có thể dẫn đến sự khác biệt đáng kể giữa phân phối của dữ liệu đào tạo trước và dữ liệu thử nghiệm, tức là dịch chuyển phân phối, dẫn đến suy giảm hiệu suất của PLM trên các nhiệm vụ hạ nguồn. Trong bài báo này, chúng tôi nhấn mạnh nhu cầu thích ứng PLMs của mã nguồn với dữ liệu phần mềm có phân phối thay đổi theo thời gian, một vấn đề quan trọng đã bị bỏ qua trong các nghiên cứu trước đây. Động lực của nghiên cứu này là xem xét PLM trong môi trường không ổn định, nơi dữ liệu tinh chỉnh phát triển theo thời gian theo kịch bản phát triển phần mềm. Cụ thể, chúng tôi thiết kế một kịch bản mà mô hình cần học từ một luồng chương trình chứa các APIs mới, chưa được thấy theo thời gian. Chúng tôi nghiên cứu hai kiến trúc PLM được sử dụng rộng rãi, tức là một bộ giải mã GPT2 và một bộ mã hóa RoBERTa, trên hai nhiệm vụ hạ nguồn, dự đoán lời gọi API và dự đoán sử dụng API. Chúng tôi chứng minh rằng kỹ thuật tinh chỉnh thường được sử dụng nhất từ các nghiên cứu trước không đủ mạnh mẽ để xử lý bản chất động của APIs, dẫn đến mất kiến thức đã học trước đó, tức là quên lãng thảm khốc. Để giải quyết những vấn đề này, chúng tôi triển khai năm phương pháp học liên tục, bao gồm các phương pháp dựa trên phát lại và dựa trên chính quy hóa. Những phát hiện của chúng tôi chứng minh rằng việc sử dụng các phương pháp đơn giản này hiệu quả giảm thiểu quên lãng thảm khốc trong PLMs trên cả hai nhiệm vụ hạ nguồn trong khi đạt được hiệu suất tương đương hoặc vượt trội.

∗Tác giả liên hệ.

Được phép tạo bản sao kỹ thuật số hoặc bản cứng của toàn bộ hoặc một phần công trình này cho mục đích sử dụng cá nhân hoặc trong lớp học mà không tính phí với điều kiện các bản sao không được tạo ra hoặc phân phối vì lợi nhuận hoặc lợi thế thương mại và các bản sao phải mang thông báo này và trích dẫn đầy đủ trên trang đầu tiên. Bản quyền đối với các thành phần của công trình này thuộc về những người khác ngoài (các) tác giả phải được tôn trọng. Trích dẫn có ghi công được phép. Để sao chép khác hoặc tái xuất bản, đăng trên máy chủ hoặc phân phối lại trong danh sách, cần có sự cho phép cụ thể trước và/hoặc phí. Yêu cầu quyền từ permissions@acm.org.

ESEC/FSE '23, 3–9 tháng 12, 2023, San Francisco, CA, USA
©2023 Bản quyền thuộc về (các) chủ sở hữu/tác giả. Quyền xuất bản được cấp phép cho ACM.
ACM ISBN 979-8-4007-0327-0/23/12... $15.00
https://doi.org/10.1145/3611643.3616244

CÁC KHÁI NIỆM CCS
• Phần mềm và kỹ thuật của nó → Thư viện phần mềm và kho lưu trữ; • Phương pháp tính toán → Xử lý ngôn ngữ tự nhiên.

TỪ KHÓA
học sâu cho mã nguồn, mô hình ngôn ngữ được đào tạo trước, học liên tục, khái quát hóa ngoài phân phối

Định dạng Tham khảo ACM:
Martin Weyssow, Xin Zhou, Kisub Kim, David Lo, và Houari Sahraoui. 2023. Về Việc Sử Dụng Học Liên Tục cho Khái Quát Hóa Ngoài Phân Phối trong Các Mô Hình Ngôn Ngữ Được Đào Tạo Trước của Mã Nguồn. Trong Kỷ yếu Hội nghị Kỹ thuật Phần mềm Châu Âu Chung ACM lần thứ 31 và Hội thảo về Cơ sở Kỹ thuật Phần mềm (ESEC/FSE '23), 3–9 tháng 12, 2023, San Francisco, CA, USA. ACM, New York, NY, USA, 13 trang.
https://doi.org/10.1145/3611643.3616244

1 GIỚI THIỆU

Nghiên cứu trước đây [11,19,70] về học biểu diễn mã nguồn tận dụng quy trình hai giai đoạn phổ biến để đào tạo và chuyên môn hóa hiệu quả các mô hình ngôn ngữ được đào tạo trước (PLMs) cho các nhiệm vụ hạ nguồn liên quan đến mã nguồn. Giai đoạn đầu tiên, tức là đào tạo trước, bao gồm việc tối ưu hóa mô hình bằng cách sử dụng học tự giám sát trên một tập dữ liệu lớn để có được kiến thức tổng quát về mã nguồn. Giai đoạn đào tạo trước này cho phép mô hình thích ứng với các nhiệm vụ hạ nguồn trong giai đoạn thứ hai, tức là tinh chỉnh. Các nghiên cứu trước đây [1,19,72] thường tận dụng các phương pháp học chuyển giao cổ điển, bao gồm việc "chuyển giao" kiến thức được đào tạo trước cho nhiệm vụ đích bằng cách tinh chỉnh mô hình trên hàm mất mát và dữ liệu cụ thể cho nhiệm vụ. Phương pháp này đã thành công trong các lĩnh vực xử lý ngôn ngữ tự nhiên (NLP) [8,16] và học sâu cho mã nguồn [11, 19].

Trong góc nhìn này, các nghiên cứu trước đây [13,63] chủ yếu tập trung vào các cài đặt ổn định, bỏ qua nhu cầu thực tế cho các mô hình thích ứng với môi trường và dữ liệu thay đổi theo thời gian. Hầu hết nghiên cứu trước đây [1,19,22] đã đề xuất sử dụng học chuyển giao để tinh chỉnh mô hình trong môi trường tĩnh thay vì giải quyết bản chất động của các tình huống thực tế. Trong thực tế, các ngôn ngữ lập trình, thư viện phần mềm và APIs có xu hướng thay đổi và phát triển [28,46,48], dẫn đến sự dịch chuyển trong phân phối của dữ liệu phần mềm cơ bản theo thời gian, cũng được biết đến như dịch chuyển khái niệm [40,65]. Bằng cách bỏ qua sự phát triển thực tế của các cơ sở mã phần mềm, các nghiên cứu hiện có [11,63] đã tập trung vào việc tinh chỉnh và thử nghiệm các mô hình được đào tạo trước của mã nguồn bằng cách sử dụng các tập dữ liệu ổn định.

Trong thực tế, sự phát triển phần mềm có thể dẫn đến sự khác biệt đáng chú ý giữa dữ liệu đào tạo và thử nghiệm, tức là dịch chuyển phân phối, điều này thường không có mặt trong các tập dữ liệu ổn định này. Hiện tượng này cũng xảy ra khi mô hình được đưa vào sản xuất và phải đối phó với dữ liệu thực tế [4,26]. Chúng tôi lập luận rằng việc tạo ra các tập dữ liệu phản ánh các kịch bản phát triển phần mềm thực tế và dịch chuyển phân phối là rất quan trọng để đánh giá đúng khả năng khái quát hóa ngoài phân phối (OOD) của các mô hình mã nguồn [53]. Khái quát hóa OOD đo lường khả năng của mô hình để khái quát hóa cho dữ liệu mới, chưa thấy với phân phối khác biệt đáng kể so với dữ liệu đào tạo. Do đó, việc đánh giá cách PLMs của mã nguồn khái quát hóa cho dữ liệu phần mềm OOD trong các kịch bản phát triển phần mềm xuất hiện như một vấn đề quan trọng.

Các nghiên cứu hiện có về khái quát hóa OOD đã thiết kế các tập dữ liệu dựa trên các dịch chuyển phân phối khác nhau trong dữ liệu mã nguồn [25,30]. Tuy nhiên, họ không giải quyết vấn đề thích ứng liên tục một mô hình được đào tạo trước của mã nguồn với các luồng dữ liệu OOD. Mục tiêu chính của nghiên cứu của chúng tôi là khám phá các phương pháp để mô hình thích ứng tốt hơn với các kịch bản phát triển phần mềm. Trong bối cảnh này, chúng tôi đặt câu hỏi: làm thế nào để tinh chỉnh liên tục hiệu quả một mô hình được đào tạo trước của mã nguồn để thích ứng với dữ liệu mới trong khi vẫn xem xét dữ liệu quá khứ? (xem Hình 1). Trong những năm qua, học liên tục (CL) [47,65] đã xuất hiện để giải quyết vấn đề này, điều này có liên quan đến một loạt các lĩnh vực nghiên cứu, bao gồm thị giác máy tính [6,34,38,55] và NLP [7,9,56].

Mặc dù các phương pháp học chuyển giao không được thiết kế riêng cho các kịch bản học liên tục, chúng vẫn có thể hoạt động để tinh chỉnh mô hình trên các luồng dữ liệu. Tuy nhiên, các phương pháp này thiếu tính mạnh mẽ, dẫn đến các hiện tượng không mong muốn như quên thông tin quá khứ, được gọi là quên lãng thảm khốc [20,43]. Tồn tại các chiến lược khác, chẳng hạn như đào tạo lại mô hình từ đầu bằng dữ liệu mới, cũng không thực tế do cường độ tính toán khổng lồ trong giai đoạn đào tạo trước. Được thúc đẩy bởi những vấn đề này của các mô hình hiện có, chúng tôi cố gắng điều tra các kỹ thuật tinh chỉnh mạnh mẽ và có thể mở rộng hơn. Chúng tôi đưa ra giả thuyết rằng các kỹ thuật học liên tục có thể mang lại lợi ích đáng kể so với học chuyển giao cổ điển trong bối cảnh này.

Trong bài báo này, chúng tôi đi sâu vào hành vi của PLMs của mã nguồn trong một kịch bản tinh chỉnh liên tục, như được mô tả trong Hình 1. Mục tiêu của chúng tôi có hai mặt: (1) đánh giá khả năng khái quát hóa ngoài phân phối của PLMs của mã nguồn và (2) điều tra các chiến lược tinh chỉnh liên tục hiệu quả để tinh chỉnh các mô hình khi có mặt một luồng dữ liệu OOD. Cụ thể, chúng tôi giải quyết những thách thức này trong một kịch bản phản ánh cách các cơ sở mã phần mềm điển hình có thể phát triển trong thực tế. Để làm điều này, chúng tôi tạo ra năm tập dữ liệu miền OOD, mỗi tập giới thiệu các APIs mới, chưa được thấy bởi các mô hình trong giai đoạn đào tạo trước của chúng. Các tập dữ liệu OOD này nhằm mô phỏng một luồng dữ liệu cho tinh chỉnh liên tục, và mỗi tập dữ liệu đòi hỏi một dịch chuyển phân phối đáng kể so với dữ liệu đào tạo trước. Như vậy, cài đặt của chúng tôi thiết lập một vấn đề khái quát hóa OOD. Chúng tôi xem xét hai kiến trúc mô hình được sử dụng rộng rãi: một bộ giải mã giống GPT2 [49] và một bộ mã hóa giống RoBERTa [37] được đào tạo trước trên mã nguồn. Để loại bỏ bất kỳ rò rỉ dữ liệu nào giữa dữ liệu đào tạo trước và tinh chỉnh, chúng tôi quyết định đào tạo trước các mô hình của chúng tôi từ đầu. Chúng tôi không nghiên cứu các PLMs phổ biến hiện có như CodeBERT [19] hoặc CodeT5 [62] vì chúng có thể dễ bị rò rỉ dữ liệu tiềm ẩn, tức là thấy dữ liệu OOD trong đào tạo trước, mà chúng tôi không thể kiểm soát chính xác. Chúng tôi đánh giá các mô hình trên hai nhiệm vụ hạ nguồn: dự đoán lời gọi API và dự đoán sử dụng API. Trong nhiệm vụ đầu tiên, mô hình cố gắng dự đoán các lời gọi API dẫn đến một token mã duy nhất, được đưa ra các token mã xuất hiện trước vị trí gọi. Mặt khác, nhiệm vụ thứ hai bao gồm việc tạo ra toàn bộ việc sử dụng API dẫn đến một chuỗi các token mã với cùng định dạng đầu vào như nhiệm vụ trước. Cùng nhau, hai nhiệm vụ này cung cấp một đánh giá toàn diện về hiệu suất của mô hình trong các kịch bản tạo mã khác nhau.

Chúng tôi bắt đầu bằng việc điều tra tác động của dữ liệu OOD đối với hiệu suất của bộ giải mã giống GPT2 trên cả hai nhiệm vụ hạ nguồn trong một cài đặt zero-shot, tức là không tinh chỉnh mô hình trên dữ liệu OOD mới. Chúng tôi phát hiện rằng mô hình liên tục thất bại trong việc khái quát hóa cho dữ liệu OOD bằng cách nổi bật các khoảng cách đáng kể trong hiệu suất so với dữ liệu trong phân phối trên sáu chỉ số đánh giá (ví dụ, giảm tới 75% trong điểm BLEU). Phát hiện này mạnh mẽ gợi ý rằng bản thân đào tạo trước là không đủ và không thể giải quyết khái quát hóa OOD trong PLMs của mã nguồn. Sau đó chúng tôi đánh giá hiệu suất của các mô hình trong kịch bản tinh chỉnh liên tục bằng cách sử dụng học chuyển giao cổ điển và quan sát quên lãng thảm khốc đáng chú ý. Để giải quyết vấn đề này, chúng tôi triển khai một phương pháp tinh chỉnh tích lũy đơn giản nhưng không hiệu quả về mặt tính toán bằng cách sử dụng một bộ đệm phát lại có kích thước vô hạn. Kết quả cho thấy phương pháp này giảm thiểu đáng kể việc quên lãng. Cuối cùng, chúng tôi so sánh hiệu suất của học chuyển giao cổ điển với các phương pháp học liên tục dựa trên phát lại và dựa trên chính quy hóa. Các phương pháp phát lại được coi là các chiến lược khó đánh bại cho học liên tục và bao gồm việc duy trì một bộ đệm phát lại nhỏ chứa các mẫu từ dữ liệu đã thấy trước đó. Trong quá trình tinh chỉnh, chúng tôi sử dụng bộ đệm phát lại kết hợp với tập đào tạo OOD hiện tại để tinh chỉnh PLM. Chúng tôi khám phá các phương pháp dựa trên chính quy hóa, bao gồm EWC [34], SI [71] và RWalk [10], thêm các thuật ngữ chính quy hóa vào hàm mất mát tại thời điểm tinh chỉnh để ngăn chặn các thay đổi rộng rãi trong các tham số quan trọng của PLM. Chúng tôi chọn những phương pháp đó vì chúng hiệu quả về mặt tính toán, nổi tiếng và được coi là các đường cơ sở mạnh trong văn học học liên tục. Chúng tôi khám phá rằng những phương pháp học liên tục đó giảm đáng kể việc quên lãng trong khi đạt được hiệu quả tương tự hoặc vượt trội trên cả hai nhiệm vụ.

Theo hiểu biết tốt nhất của chúng tôi, công trình này tạo thành sáng kiến đầu tiên để nghiên cứu tinh chỉnh liên tục cho khái quát hóa OOD của PLMs của mã nguồn. Chúng tôi tin rằng tác động của học liên tục trong lĩnh vực nghiên cứu này có tiềm năng lan rộng, đặc biệt do sự phát triển cố hữu của dữ liệu phần mềm theo thời gian, và chúng tôi thảo luận khía cạnh này chi tiết hơn trong phần thảo luận của bài báo (xem Phần 5). Những đóng góp của chúng tôi có thể được tóm tắt như sau:

(1) Chúng tôi chứng minh rằng PLMs của mã nguồn thất bại trong việc khái quát hóa cho dữ liệu OOD và làm nổi bật nhu cầu điều tra thêm trong lĩnh vực này.

(2) Chúng tôi tiến hành một nghiên cứu về hành vi của hai kiến trúc mô hình được đào tạo trước của mã nguồn trong một môi trường học liên tục, cho thấy rằng học chuyển giao cổ điển thiếu tính mạnh mẽ và dễ bị quên lãng thảm khốc.

(3) Chúng tôi so sánh năm phương pháp học liên tục, bao gồm các phương pháp dựa trên phát lại và dựa trên chính quy hóa, trong kịch bản tinh chỉnh liên tục của chúng tôi. Chúng tôi cho thấy sự vượt trội của học liên tục so với học chuyển giao cổ điển.

(4) Chúng tôi cung cấp một tập dữ liệu quy mô lớn về các đoạn mã Java và chuỗi sử dụng API của chúng, bao gồm dữ liệu đào tạo trước và một quy trình để trích xuất dữ liệu OOD.

Tổ chức. Trong Phần 2, chúng tôi thảo luận các khái niệm cơ bản về học liên tục. Trong Phần 3, chúng tôi đi qua thiết kế thí nghiệm của chúng tôi. Chúng tôi trình bày kết quả của các thí nghiệm trong Phần 4. Trong Phần 5, chúng tôi thảo luận các mối đe dọa đối với tính hợp lệ của nghiên cứu, cũng như tác động rộng hơn tiềm năng và hướng nghiên cứu tương lai. Chúng tôi giới thiệu các công trình liên quan về khái quát hóa ngoài phân phối và học liên tục cho các mô hình ngôn ngữ được đào tạo trước trong Phần 6. Cuối cùng, chúng tôi thảo luận một số công việc tương lai và kết luận công trình này trong Phần 7.

2 CÁC KHÁI NIỆM CƠ BẢN VỀ HỌC LIÊN TỤC

Các PLMs hiện có như BERT [16] hoặc GPT [8] thường hoạt động trong các cài đặt học chuyển giao. Bằng cách sử dụng quy trình hai giai đoạn đào tạo trước/tinh chỉnh, các mô hình này có thể được chuyên môn hóa cho một loạt các nhiệm vụ hạ nguồn. Tuy nhiên, trong cài đặt này, dữ liệu được sử dụng cho đào tạo trước hoặc tinh chỉnh thường được giả định là ổn định, điều này không phản ánh các tình huống thực tế. Trong thực tế, các phương pháp học chuyển giao vẫn có thể được áp dụng cho dữ liệu không ổn định, chẳng hạn như một luồng dữ liệu, nhưng kỹ thuật này dễ bị quên lãng thảm khốc [20, 43].

Để giải quyết các vấn đề trên, các nghiên cứu trước đây [2,20,24,34,36,59] giới thiệu khái niệm học liên tục và thiết kế các kỹ thuật cụ thể để giảm thiểu quên lãng thảm khốc. Giả định chính cho học liên tục là mạng nơ-ron nên có khả năng thích ứng với dữ liệu hoặc nhiệm vụ mới trong khi duy trì sự ổn định trên dữ liệu hoặc nhiệm vụ trước đó, thường được gọi là tình trạng khó xử tính dẻo-ổn định. Xem xét học liên tục đặc biệt thú vị cho các vấn đề khái quát hóa OOD, vì các phương pháp học liên tục tập trung vào việc duy trì sự cân bằng tính dẻo-ổn định tốt. Tổng cộng, nó có tiềm năng nâng cao khả năng khái quát hóa của PLMs cho một loạt dữ liệu rộng hơn. Các phương pháp học liên tục thường hoạt động trong các kịch bản hạn chế, và Hadsell et al. [24] phác thảo một danh sách toàn diện các mục tiêu để cân bằng trong các kịch bản học liên tục.

Tồn tại ba danh mục chính của các phương pháp cho học liên tục như được định nghĩa trong một nghiên cứu trước đây [15]. Các phương pháp dựa trên phát lại lưu trữ các mẫu từ các trải nghiệm trước đó, tức là luồng dữ liệu trước đó, trong một bộ đệm phát lại hoặc sử dụng các phương pháp tạo sinh để tạo ra các ví dụ tương tự như những ví dụ của các trải nghiệm trước đó. Bộ đệm phát lại được sử dụng kết hợp với dữ liệu trải nghiệm hiện tại để đào tạo mô hình. Các phương pháp dựa trên phát lại giúp mạng có được sự ổn định bằng cách cho phép mạng đào tạo trên các mẫu trước đó, tức là được lưu trữ trong bộ đệm phát lại trong khi thích ứng với dữ liệu mới. Các phương pháp dựa trên chính quy hóa thêm một thuật ngữ chính quy hóa vào hàm mất mát để ngăn chặn quên lãng thảm khốc bằng cách phạt các thay đổi đối với các tham số mạng nơ-ron quan trọng. Các ví dụ về phương pháp dựa trên chính quy hóa bao gồm EWC [34], SI [71] và RWalk [10]. Cuối cùng, các phương pháp cô lập tham số sử dụng các kiến trúc động để kết hợp kiến thức từ các trải nghiệm trước đó để giảm thiểu can thiệp [52].

3 THIẾT KẾ THÍ NGHIỆM

Trong phần này, chúng tôi mô tả thiết lập thí nghiệm của nghiên cứu. Chúng tôi cẩn thận kiểm soát cài đặt dữ liệu và mô hình để triển khai kịch bản ngoài phân phối. Đầu tiên chúng tôi phác thảo việc xây dựng tập dữ liệu và tạo ra dữ liệu OOD cho tinh chỉnh liên tục. Tiếp theo, chúng tôi thảo luận quy trình đào tạo trước của các mô hình, các nhiệm vụ hạ nguồn đích và các chỉ số đánh giá. Chúng tôi trình bày kết quả của các thí nghiệm trong Phần 4.

3.1 Xây Dựng Tập Dữ Liệu

Đào tạo trước các mô hình ngôn ngữ từ đầu đòi hỏi một lượng lớn dữ liệu để mất mát của mô hình hội tụ. Với ý nghĩ đó, chúng tôi xây dựng tập dữ liệu lớn bằng cách sử dụng các chương trình được thu thập từ GitHub sử dụng Google BigQuery¹. Cụ thể, chúng tôi tập trung vào các chương trình Java và bắt đầu bằng việc thu thập tất cả các tệp java được lưu trữ trong các kho GitHub. Tiếp theo, chúng tôi sử dụng Groum [45] để trích xuất tất cả các phương thức được định nghĩa trong các tệp java cùng với chuỗi sử dụng API của chúng. Chúng tôi trích xuất các chuỗi sử dụng API để tạo điều kiện cho việc chia tách dữ liệu và lấy vị trí của mỗi vị trí API bên trong các phương thức để triển khai các nhiệm vụ hạ nguồn. Mỗi mẫu bao gồm tất cả các token của một phương thức. Để tránh thiên vị trùng lặp trong các thí nghiệm [3], chúng tôi loại bỏ trùng lặp trong tập dữ liệu bằng cách so sánh hash của mỗi phương thức. Tập dữ liệu kết quả chứa hơn 68M phương thức Java. Đối với các thí nghiệm của chúng tôi, chúng tôi xáo trộn 68M phương thức này và ngẫu nhiên chọn 10M phương thức để tạo thành tập dữ liệu ban đầu. Hình 2 minh họa cách chúng tôi tiếp tục chia tách dữ liệu cho các thí nghiệm. Vì chúng tôi chọn đào tạo trước PLMs từ đầu, chúng tôi phải chia dữ liệu thành dữ liệu trong phân phối (ID), được sử dụng cho đào tạo trước mô hình, và dữ liệu OOD, được sử dụng cho tinh chỉnh liên tục. Chúng tôi cũng cần trích xuất đúng dữ liệu OOD để phù hợp với kịch bản của chúng tôi bao gồm việc giới thiệu các APIs mới, chưa được thấy theo thời gian cho PLM trong quá trình tinh chỉnh.

¹https://cloud.google.com/bigquery

Tập Dữ Liệu Ngoài Phân Phối – D_OOD. Chúng tôi tạo ra năm tập dữ liệu OOD, D¹_OOD,...,D⁵_OOD. Mỗi tập dữ liệu OOD đại diện cho một miền duy nhất bao gồm chức năng cấp cao của APIs. Ví dụ, chúng tôi có một miền Security bao gồm các APIs liên quan đến lập trình mã bảo mật và một miền Guava chỉ bao gồm các APIs từ thư viện Guava². Để tạo mỗi tập dữ liệu OOD, chúng tôi ngẫu nhiên chọn 10 giao diện từ các gói/thư viện liên quan đến miền của chúng. Cuối cùng, chúng tôi liên kết với mỗi tập dữ liệu miền tất cả các APIs trong các giao diện đã chọn, loại trừ các phương thức xây dựng lớp. Bảng 1 tóm tắt tập dữ liệu D_OOD, chứa 147.245 mẫu tổng cộng.

Để tạo thành mỗi tập dữ liệu OOD, chúng tôi chọn các mẫu từ nhóm 10 triệu phương thức Java thao tác ít nhất một trong các API liên quan của chúng. Trong các thí nghiệm, chúng tôi thực hiện tinh chỉnh liên tục trên các tập đào tạo liên quan đến tập dữ liệu OOD D¹_OOD,...,D⁵_OOD một cách tuần tự. Do đó, để ngăn chặn rò rỉ dữ liệu, chúng tôi loại trừ các mẫu thao tác APIs từ nhiều miền. Việc loại bỏ các mẫu này loại bỏ một mối đe dọa đáng kể đối với tính hợp lệ của kịch bản OOD và đảm bảo rằng các APIs được giới thiệu như dự định trong quá trình tinh chỉnh. Để có được các tập thử nghiệm đại diện, chúng tôi ngẫu nhiên chọn 10% các mẫu thao tác mỗi API trong mỗi tập dữ liệu OOD và sử dụng các mẫu đã chọn để tạo thành tập thử nghiệm miền tương ứng.

Tập Dữ Liệu Trong Phân Phối – D_ID. Chúng tôi có được D_ID bằng cách loại bỏ các mẫu trong D_OOD từ dữ liệu ban đầu. Sau đó, chúng tôi xáo trộn D_ID và ngẫu nhiên chọn 50.000 mẫu cho thử nghiệm (D_ID_test). D_ID_PT chứa các mẫu còn lại cho đào tạo trước, và chúng tôi ngẫu nhiên chọn 100.000 cho xác thực mô hình (D_ID_PT_valid). Đặc biệt, những mẫu đó cho phép chúng tôi giám sát sự phát triển của mất mát của mô hình trên một tập xác thực độc lập để tránh overfitting dữ liệu đào tạo trước. Tổng cộng, tập đào tạo trước D_ID_PT_train chứa hơn 9M mẫu để đào tạo trước các mô hình.

²https://github.com/google/guava

3.2 Thiết Lập Mô Hình và Nhiệm Vụ

Trong công trình này, chúng tôi xem xét hai kiến trúc học sâu được sử dụng rộng rãi cho mã nguồn: một bộ mã hóa giống RoBERTa [37] và một bộ giải mã giống GPT2 [49]. Chúng tôi cố ý loại trừ việc sử dụng các mô hình ngôn ngữ lớn (LLMs) trong nghiên cứu do các tài nguyên tính toán đáng kể cần thiết cho việc đào tạo trước của chúng. Để giải quyết toàn diện kịch bản OOD của chúng tôi, việc đào tạo trước một mô hình từ đầu trước khi tinh chỉnh liên tục nó trên mã chứa các APIs mới, chưa được thấy là điều cấp thiết. Do đó, chúng tôi chọn đánh giá hai kiến trúc mô hình nhỏ hơn, cụ thể là RoBERTa và GPT-2, được sử dụng làm mô hình nền tảng cho PLMs như CodeBERT [19] hoặc cho các mô hình tạo sinh.

Bộ Giải Mã – M_dec. Mô hình bộ giải mã dựa trên kiến trúc GPT-2, với cùng siêu tham số, và được đào tạo trước bằng mục tiêu mô hình hóa ngôn ngữ nhân quả, tức là dự đoán token tiếp theo từ trái sang phải. Vì chúng tôi tiến hành các thí nghiệm dưới tài nguyên hạn chế, chúng tôi triển khai một phiên bản nhỏ của GPT-2 với 110 triệu tham số có thể đào tạo và đào tạo trước mô hình trong 100.000 bước. Chúng tôi sử dụng dừng sớm để chọn checkpoint mô hình tốt nhất, dựa trên mất mát trên tập xác thực D_ID_PT_valid.

Bộ Mã Hóa – M_enc. Mô hình bộ mã hóa dựa trên kiến trúc RoBERTa, với cùng siêu tham số, và được đào tạo trước bằng mục tiêu mô hình hóa ngôn ngữ có mặt nạ. Chúng tôi triển khai một phiên bản cơ bản của RoBERTa. Mô hình có 125 triệu tham số có thể đào tạo và được đào tạo trước tương tự như mô hình bộ giải mã, với dừng sớm được sử dụng để chọn checkpoint tốt nhất. Lưu ý rằng ngược lại với M_dec, kiến trúc của bộ mã hóa không phù hợp cho các nhiệm vụ tạo sinh. Do đó, chúng tôi thêm một đầu mô hình hóa ngôn ngữ được khởi tạo ngẫu nhiên lên trên nó cho tinh chỉnh bằng các tập dữ liệu OOD. Kết quả là, chúng tôi mong đợi M_enc kém ổn định hơn M_dec và dễ bị quên lãng thảm khốc hơn vì đầu mô hình hóa ngôn ngữ không được đào tạo trước. Sự so sánh này cung cấp những hiểu biết có giá trị về tính mạnh mẽ của hai kiến trúc khác nhau.

Các Nhiệm Vụ Hạ Nguồn. Chúng tôi sử dụng hai nhiệm vụ hạ nguồn để đánh giá khả năng của PLMs mã nguồn trong việc học và thích ứng với dữ liệu phần mềm mới giới thiệu các APIs mới, chưa được thấy theo thời gian. Hình 3 minh họa cả hai nhiệm vụ. Đối với dự đoán lời gọi API, mô hình lấy đầu vào tất cả các token của phương thức đứng trước vị trí gọi của API và tạo ra các ứng viên top-k. Đối với dự đoán sử dụng API, mô hình lấy đầu vào cùng các token như nhiệm vụ dự đoán lời gọi API, nhưng cố gắng tạo ra toàn bộ việc sử dụng API (tên giao diện, tên phương thức, tham số và các token cú pháp), tạo thành một nhiệm vụ thách thức hơn. Lý do để đánh giá PLMs trên hai nhiệm vụ hạ nguồn này là chọn các nhiệm vụ mà kiến thức trước về APIs có vẻ quyết định để thực hiện hiệu quả nhiệm vụ. Do đó, lựa chọn cho hai nhiệm vụ này có liên quan cao đến kịch bản OOD liên tục của chúng tôi, và nó cho phép chúng tôi đo lường trực tiếp tác động của APIs OOD đối với hiệu quả của PLMs.

Các Chỉ Số Đánh Giá. Chúng tôi đo lường hiệu suất của các mô hình trên cả hai nhiệm vụ hạ nguồn với các chỉ số được sử dụng trong các nghiên cứu trước. Đối với dự đoán lời gọi API, chúng tôi báo cáo Exact Match@k (EM@k), cung cấp tỷ lệ phần trăm dự đoán chính xác khi xem xét danh sách k ứng viên. Đối với dự đoán sử dụng API, chúng tôi báo cáo điểm BLEU, Exact Match (EM), và CodeBLEU [50].

Để đo lường cách các mô hình hoạt động trong môi trường học liên tục, chúng tôi sử dụng hai siêu chỉ số được điều chỉnh từ các nghiên cứu trước [10, 32]: các chỉ số Trung bình (A) và Quên lãng (F). Chúng tôi định nghĩa trung bình A_M của một chỉ số M trên một tập dữ liệu thử nghiệm D^i_OOD là:

A_M = 1/T ∑(j=i to T) M_j(D^i_OOD),

trong đó j tham chiếu đến các bước học tăng dần tiếp theo sau bước thứ i được bao gồm. M_j biểu thị một chỉ số đánh giá, ví dụ, EM@k, được tính toán tại bước thời gian j trên tập thử nghiệm và T biểu thị số lượng tối đa các bước tinh chỉnh, tức là năm trong trường hợp của chúng tôi. Chỉ số Trung bình chỉ cung cấp thông tin về độ chính xác của mô hình nhưng không cung cấp bất kỳ hiểu biết nào về khả năng giảm thiểu quên lãng thảm khốc. Chúng tôi định nghĩa quên lãng F^k_M của một chỉ số M trên một tập dữ liệu thử nghiệm D^i_OOD tại bước thời gian k là:

F^k_M = M_i(D^i_OOD) - M_k(D^i_OOD), i < k.

Đây là sự khác biệt giữa lần đầu tiên chỉ số được tính toán, tức là sau khi tinh chỉnh mô hình trên D^i_OOD tại bước thời gian i, và chỉ số được tính toán tại bước thời gian k. F^k_M cung cấp thông tin về tính ổn định của mô hình, tức là khả năng không quên từ quá khứ. Do đó, F^k_M càng thấp càng tốt.

Chi Tiết Triển Khai. Để đào tạo trước M_dec và M_enc, chúng tôi sử dụng bốn GPU Tesla V100-SXM2-32GB. Mất khoảng 7 ngày để đào tạo trước M_dec, và 2 ngày để đào tạo trước M_enc. Đối với tinh chỉnh và suy luận, chúng tôi sử dụng một GPU Tesla V100-SXM2-32GB duy nhất. Chúng tôi sử dụng thư viện của Huggingface [67] để triển khai các mô hình và lưu trữ các tập dữ liệu. Để triển khai các phương pháp học liên tục, chúng tôi sử dụng Avalanche [39]. Chúng tôi cung cấp tất cả chi tiết triển khai của các thí nghiệm và phát hành dữ liệu công khai trong gói sao chép của chúng tôi (xem phần Tính Sẵn Có Dữ Liệu).

4 KẾT QUẢ THÍ NGHIỆM

4.1 M_dec Khái Quát Hóa như thế nào cho Dữ Liệu ID và OOD trong Zero-Shot?

Trong thí nghiệm này, chúng tôi đánh giá hiệu suất của mô hình M_dec trên dữ liệu thử nghiệm ID và OOD trong cài đặt zero-shot cho cả hai nhiệm vụ hạ nguồn. Chúng tôi không thí nghiệm với M_enc vì mô hình không có khả năng tạo mã trước khi tinh chỉnh và do đó không thể hoạt động trong cài đặt zero-shot. Mục đích của thí nghiệm này có hai mặt. Đầu tiên, nó nhằm xác thực thiết lập thí nghiệm của nghiên cứu. Nếu chúng tôi quan sát những khác biệt đáng kể trong các chỉ số đánh giá thu được trên các tập dữ liệu ID và OOD, điều đó sẽ gợi ý rằng kịch bản OOD của chúng tôi được hình thành tốt và hợp lý. Thứ hai, những khoảng cách đáng kể giữa dữ liệu thử nghiệm ID và OOD ngụ ý rằng PLMs như M_dec vẫn cần sử dụng các kỹ thuật học chuyển giao mạnh mẽ hoặc học liên tục để khái quát hóa cho dữ liệu mới mà không quên về dữ liệu quá khứ.

Dự Đoán Lời Gọi API. Bảng 2 báo cáo EM@1, EM@5 và EM@10 trên các tập dữ liệu thử nghiệm ID và OOD. Kết quả cho thấy mô hình hoạt động tốt trên dữ liệu ID, đạt gần 73% trong EM@1. Tuy nhiên, khi được thử nghiệm trên dữ liệu OOD, hiệu suất giảm đáng kể. Sự suy giảm hiệu suất ít nghiêm trọng hơn khi xem xét nhiều ứng viên lời gọi API hơn, nhưng nó vẫn là một vấn đề đáng kể. Hơn nữa, các biến thể trong sự suy giảm hiệu suất được quan sát trên các tập dữ liệu OOD khác nhau. Ví dụ, mô hình hoạt động tốt hơn trên miền Security (D²_OOD) so với các miền như Android (D³_OOD) hoặc Web (D⁴_OOD), có thể chứa nhiều lời gọi API cụ thể miền hơn.

Dự Đoán Sử Dụng API. Bảng 3 báo cáo điểm BLEU, EM và điểm CodeBLEU trên cả tập dữ liệu thử nghiệm ID và OOD. Kết quả chỉ ra rằng mô hình hoạt động kém trên dữ liệu OOD so với dữ liệu ID, với sự giảm đáng kể trong tất cả các chỉ số đánh giá. Ngoài ra, chúng tôi nhận thấy rằng các chỉ số EM và CodeBLEU thay đổi tương tự như các chỉ số EM@k trên nhiệm vụ dự đoán lời gọi API. Các miền Android và Web trải qua những sự sụt giảm nghiêm trọng nhất, trong khi miền Security trải qua sự sụt giảm ít nghiêm trọng nhất.

Kết quả của chúng tôi chứng minh rằng mô hình M_dec (không có tinh chỉnh) không thể khái quát hóa cho dữ liệu OOD trong khi cho thấy hiệu suất mạnh trên dữ liệu ID. Những phát hiện của chúng tôi cũng hỗ trợ tính hợp lệ của tập dữ liệu OOD như một bài kiểm tra thực tế và có ý nghĩa về khả năng của mô hình thích ứng với dữ liệu mới trong môi trường liên tục.

4.2 Các Mô Hình Có Quên Về Dữ Liệu Quá Khứ Khi Sử Dụng Học Chuyển Giao Cổ Điển Không?

Trong phần này, chúng tôi đánh giá cách học chuyển giao cổ điển, tức là sử dụng tinh chỉnh như trong các nghiên cứu trước, hoạt động trong kịch bản học liên tục. Chúng tôi tinh chỉnh các mô hình M_dec và M_enc tuần tự trên luồng các tập dữ liệu OOD D¹_OOD,...,D⁵_OOD. Chúng tôi gọi phương pháp này là "tinh chỉnh ngây thơ", một thuật ngữ phổ biến được sử dụng trong văn học học liên tục để chỉ học chuyển giao cổ điển, vì nó không sử dụng các cơ chế để giải quyết quên lãng thảm khốc. Chúng tôi báo cáo kết quả theo EM@1 cho dự đoán lời gọi API và EM cho dự đoán sử dụng API. Hình 4 minh họa sự phát triển của các chỉ số EM@1 và EM trên các tập thử nghiệm OOD trong suốt các bước tinh chỉnh cho cả hai mô hình. Mỗi cột của bản đồ nhiệt tham chiếu đến sự phát triển của hiệu suất của mô hình trên một tập thử nghiệm cụ thể, và mỗi hàng tham chiếu đến một bước tinh chỉnh tăng dần mới. Lưu ý rằng chúng tôi không tính toán chỉ số trên một tập thử nghiệm mà tập đào tạo tương ứng chưa được mô hình thấy. Để định lượng quên lãng thảm khốc, chúng tôi báo cáo các chỉ số Quên lãng (F) của các chỉ số EM@1 và EM trong Bảng 4. Chúng tôi không báo cáo tất cả các giá trị cho mọi chỉ số được giới thiệu trước đó vì chúng tôi có giới hạn trang nghiêm ngặt, và báo cáo chúng trong gói sao chép của chúng tôi.

Chi Tiết Tinh Chỉnh. Tại mỗi bước thời gian t, chúng tôi tinh chỉnh các checkpoint mô hình từ bước thời gian trước đó trên tập dữ liệu D^t_OOD. Chúng tôi chọn 10% các mẫu đào tạo từ mỗi tập dữ liệu OOD làm tập xác thực. Đối với mỗi tinh chỉnh, chúng tôi đặt số epoch đào tạo là 10 và sử dụng dừng sớm bằng cách giám sát sự phát triển của mất mát xác thực với độ kiên nhẫn là hai epoch. Chúng tôi giữ các checkpoint tốt nhất của các mô hình tại mỗi bước tinh chỉnh t và tính toán các chỉ số nhiệm vụ trên các tập thử nghiệm trước đó và hiện tại.

Hiệu Suất của M_dec và M_enc. Trong Hình 4, mỗi bản đồ nhiệt mô tả sự phát triển của một chỉ số trên các tập thử nghiệm cho một mô hình duy nhất trên một nhiệm vụ. Các giá trị đường chéo trong các bản đồ nhiệt chỉ ra chỉ số được tính toán trên tập thử nghiệm của tập dữ liệu OOD hiện tại. Chúng tôi quan sát quên lãng thảm khốc đáng kể cho cả hai nhiệm vụ và mô hình và tất cả các miền và chỉ số. Nghĩa là, chúng tôi quan sát sự suy giảm của các chỉ số trong tất cả các cột, chỉ ra rằng mô hình quên các miền trước đó khi được tinh chỉnh trên một miền mới. Ví dụ, EM@1 trên D¹_OOD (General) giảm từ 57.37% xuống 51.73% cho M_dec. Một ví dụ khác là EM trên D²_OOD (Security) giảm từ 40.79% xuống 18.05% cho mô hình M_enc. Một cái nhìn vào các bản đồ nhiệt gợi ý rằng việc quên lãng nghiêm trọng hơn đối với bộ mã hóa M_enc. Nhìn chung, khi chúng tôi tăng số lượng bước tinh chỉnh, việc quên lãng càng tăng cường trong hầu hết các trường hợp. Ngoài ra, đối với bộ giải mã, sự suy giảm trong các chỉ số sau một bước tinh chỉnh ít đáng kể hơn so với bộ mã hóa. Ví dụ, sau một bước tinh chỉnh, EM@1 trên D²_OOD giảm từ 60.93% xuống 57.66% (-3.27%) cho bộ giải mã. Trong khi nó giảm từ 58.37% xuống 32.94% (-25.43%) cho bộ mã hóa. Điều này có nghĩa là cần nhiều bước tinh chỉnh hơn để bộ giải mã quên về dữ liệu quá khứ nghiêm trọng hơn, trong khi đối với bộ mã hóa, một bước tinh chỉnh đã đủ để cho thấy sự suy giảm đáng kể trong hiệu suất. Quan sát này xác nhận trực giác của chúng tôi được thể hiện trong Phần 3.2 rằng M_enc có thể kém ổn định hơn M_dec do đầu mô hình hóa ngôn ngữ bổ sung được khởi tạo ngẫu nhiên.

Các Chỉ Số Quên Lãng. Trong Bảng 4, chúng tôi tính toán chỉ số Quên lãng cho các chỉ số EM@1 và EM và cho cả hai mô hình. Lưu ý rằng chúng tôi tính toán chỉ số F tại bước thời gian cuối cùng của tinh chỉnh liên tục. Theo các bản đồ nhiệt của Hình 4, chỉ số F⁵ của một miền là sự khác biệt giữa giá trị đầu tiên và cuối cùng của cột tương ứng. Sự khác biệt này đại diện cho lượng quên lãng đã xảy ra trên mỗi miền OOD trong quá trình tinh chỉnh. Δt trong bảng chỉ ra mô hình được tinh chỉnh gần đây như thế nào trên một tập dữ liệu miền cụ thể. Chúng tôi nhận thấy rằng đối với bộ giải mã M_dec, việc quên lãng ít nghiêm trọng hơn đối với EM@1 (được sử dụng trong dự đoán lời gọi API) so với EM (được sử dụng trong dự đoán sử dụng API). Sự khác biệt có thể được quy cho thực tế là nhiệm vụ dự đoán lời gọi API dễ dàng hơn đáng kể so với nhiệm vụ dự đoán sử dụng API. Nói chung, chúng tôi quan sát việc quên lãng nghiêm trọng hơn đối với bộ mã hóa, điều này càng xác nhận trực giác của chúng tôi về sự thiếu ổn định của M_enc.

Kết quả và quan sát của chúng tôi minh họa rằng vấn đề quên về dữ liệu quá khứ là một vấn đề lớn đối với cả hai mô hình được nghiên cứu và nghiêm trọng hơn đáng kể đối với mô hình M_enc. Ngay cả với số lượng bước tinh chỉnh thấp, quên lãng thảm khốc đã nổi bật. Bằng cách xem xét nhiều bước tinh chỉnh hơn, chúng ta có thể mong đợi vấn đề sẽ trở nên tồi tệ hơn.

Chúng tôi kết luận rằng học chuyển giao cổ điển, phương pháp tinh chỉnh được sử dụng phổ biến nhất trong các nghiên cứu trước, là không đủ và không đủ mạnh mẽ để cho phép mô hình thích ứng với dữ liệu mới trong khi giữ lại kiến thức về dữ liệu quá khứ.

4.3 Các Phương Pháp Học Liên Tục So Sánh như thế nào với Học Chuyển Giao Cổ Điển?

Để giải quyết vấn đề quên lãng thảm khốc được nêu bật trong các thí nghiệm trước đây, chúng tôi đề xuất tận dụng một số phương pháp học liên tục thường được sử dụng từ văn học. Trong thí nghiệm này, phương pháp tinh chỉnh ngây thơ là đường cơ sở giới hạn dưới, vì nó không có cơ chế được thiết kế để giảm thiểu quên lãng thảm khốc. Chúng tôi bắt đầu bằng việc giới thiệu một phương pháp giới hạn trên, được gọi là "tinh chỉnh tích lũy", bao gồm việc lưu trữ tất cả các mẫu đào tạo từ mỗi tập đào tạo OOD một cách tích lũy. Với phương pháp này, chúng tôi thực hiện tinh chỉnh liên tục bằng cách sử dụng tất cả các mẫu từ các bước tinh chỉnh trước đó bổ sung cho các mẫu hiện tại. Phương pháp này thường là giới hạn trên trong các cài đặt học liên tục vì bằng cách lưu trữ tất cả các mẫu từ dữ liệu trước đó, mô hình có thể tối ưu hóa việc học của nó để khái quát hóa tốt hơn cho toàn bộ luồng dữ liệu. Tuy nhiên, phương pháp tinh chỉnh tích lũy không sử dụng được trong thực tế vì một vài lý do: (1) chúng ta có thể không luôn có quyền truy cập vào tất cả dữ liệu trước đó tại bất kỳ thời điểm nào, và (2) nó đòi hỏi lưu trữ tất cả các mẫu trước đó và nhiều tính toán hơn đáng kể trong quá trình tinh chỉnh. Phương pháp giới hạn trên này nhằm giảm thiểu việc quên lãng trong khi đạt được hiệu suất tổng thể tốt nhất. Chúng tôi so sánh các phương pháp tích lũy và ngây thơ trong Hình 5 và Hình 6. Tiếp theo, chúng tôi giới thiệu các phương pháp CL bổ sung, bao gồm một phương pháp dựa trên phát lại và ba phương pháp dựa trên chính quy hóa: EWC [34], SI [71], và RWalk [10]. Một ưu điểm của ba phương pháp này so với phương pháp phát lại là chúng không yêu cầu lưu trữ các mẫu từ dữ liệu trước đó trong khi tinh chỉnh. Chúng tôi báo cáo các chỉ số Trung bình (A) và Quên lãng (F) cho cả hai nhiệm vụ và mô hình trên các chỉ số EM@1 và EM trong Bảng 5 và Bảng 6. Lưu ý rằng không có chỉ số Quên lãng cho Guava vì nó là miền cuối cùng mà PLMs được tinh chỉnh.

Chi Tiết Tinh Chỉnh. Chúng tôi sử dụng cùng quy trình tinh chỉnh như trong thí nghiệm trước đó. Đối với đường cơ sở phát lại, chúng tôi đặt kích thước bộ đệm là 200, tức là số lượng mẫu được lưu trữ từ các tập đào tạo OOD quá khứ. Chúng tôi cung cấp tất cả siêu tham số và chi tiết thêm về các triển khai trong gói sao chép của chúng tôi.

Tinh Chỉnh Tích Lũy. Trong Hình 5, chúng tôi so sánh các phương pháp ngây thơ và tích lũy cho nhiệm vụ dự đoán lời gọi API (EM@1) trên cả mô hình bộ giải mã và bộ mã hóa. Mỗi đường cong minh họa sự phát triển của EM@1 trên một tập thử nghiệm OOD cụ thể. Hình tiếp tục chứng minh cách phương pháp ngây thơ (phần dưới bên trái của hình) với bộ mã hóa dẫn đến việc quên lãng đáng kể hơn so với bộ giải mã, như đã thảo luận trước đây. Ở bên trái của Hình 5, chúng tôi quan sát rằng phương pháp tinh chỉnh tích lũy hiệu quả loại bỏ vấn đề quên lãng thảm khốc cho cả hai mô hình. Cụ thể, EM@1 không giảm theo thời gian và thậm chí tăng trong suốt quá trình tinh chỉnh, cho thấy sự cải thiện trong quá trình tinh chỉnh liên tục, cũng được biết đến như chuyển giao tích cực. Trong Hình 6, chúng tôi thực hiện cùng các quan sát cho nhiệm vụ dự đoán sử dụng API trên chỉ số EM.

Các Phương Pháp Học Liên Tục. Bảng 5 báo cáo các chỉ số Trung bình và Quên lãng của EM@1 trên mỗi tập thử nghiệm OOD cho M_dec và M_enc, với phương pháp tinh chỉnh ngây thơ làm đường cơ sở. Tương tự như Phần 4.2, chúng tôi tính toán chỉ số F ở cuối tinh chỉnh liên tục. Đầu tiên, chúng tôi quan sát rằng đối với cả hai mô hình, phương pháp tinh chỉnh tích lũy là tùy chọn tốt nhất để giảm thiểu quên lãng thảm khốc và thường dẫn đến A_EM@1 tốt nhất. Với phương pháp tích lũy, chỉ số F⁵_EM@1 luôn âm, điều này chỉ ra một chuyển giao tích cực (một sự tăng trong EM@1). Ví dụ, chúng tôi nhận được -8.02 trong F⁵_EM@1 cho M_dec trong miền Security, tức là một sự tăng +8.02 trong chỉ số thông qua tinh chỉnh. Tuy nhiên, chúng tôi quan sát những khoảng cách lớn giữa A_EM@1 thu được bằng phương pháp tích lũy và phương pháp ngây thơ trên tập dữ liệu Guava (bước tinh chỉnh cuối cùng). Chúng tôi đưa ra giả thuyết rằng với một bộ đệm phát lại ngày càng tăng, các mô hình không còn có thể học từ dữ liệu mới và do đó mất khả năng thích ứng theo thời gian. Ngoài việc tốn kém về mặt tính toán, phương pháp tinh chỉnh tích lũy không thể mở rộng và mạnh mẽ, như đã đề cập trước đây. Nhìn chung, tất cả các phương pháp CL khác, ngoại trừ EWC, đều giảm đáng kể việc quên lãng và cho thấy A_EM@1 trung bình vượt trội so với phương pháp ngây thơ. Phương pháp Replay thường tạo ra A_EM@1 tốt nhất hoặc tốt thứ hai. Không có phương pháp tích lũy, RWalk là phương pháp tốt nhất để giảm thiểu việc quên lãng cho M_dec, trong khi SI tốt hơn cho M_enc. Trong Bảng 6, chúng tôi báo cáo kết quả cho nhiệm vụ dự đoán sử dụng API. Chúng tôi quan sát các xu hướng tương tự, ngoại trừ phương pháp Replay ít hiệu quả hơn cho cả hai mô hình. Tuy nhiên, RWalk và SI là các phương pháp tốt nhất cho M_dec và M_enc, tương ứng.

Trong thí nghiệm cuối cùng này, chúng tôi chứng minh rằng các phương pháp học liên tục, bao gồm hai phương pháp dựa trên phát lại (Replay và Cumulative) và hai phương pháp dựa trên chính quy hóa (SI và RWalk) hiệu quả giảm quên lãng thảm khốc trong khi đạt được hiệu quả tương tự hoặc vượt trội so với học chuyển giao cổ điển trên cả hai nhiệm vụ.

5 THẢO LUẬN

Trong phần này, chúng tôi giải quyết một số mối đe dọa đối với tính hợp lệ của nghiên cứu. Sau đó chúng tôi thảo luận tác động rộng hơn của nghiên cứu và các cơ hội khác nhau cho công việc tương lai.

5.1 Các Mối Đe Dọa Đối Với Tính Hợp Lệ

Các Mối Đe Dọa Đối Với Tính Hợp Lệ Bên Ngoài. Chúng tôi xác định một mối đe dọa chính liên quan đến khía cạnh đơn ngôn ngữ của tập dữ liệu. Kịch bản OOD của chúng tôi yêu cầu trích xuất các chuỗi sử dụng API từ mã nguồn. Do đó, việc tích hợp nhiều ngôn ngữ lập trình đòi hỏi nỗ lực bổ sung đáng kể, điều mà chúng tôi cố ý để dành cho công việc tương lai. Ngoài ra, việc xây dựng tập dữ liệu của chúng tôi không bao gồm bất kỳ thiết kế cụ thể ngôn ngữ lập trình nào và tránh bất kỳ rò rỉ dữ liệu nào giữa dữ liệu ID và OOD. Do đó, rất có thể kết quả của chúng tôi không bị ảnh hưởng bởi ngôn ngữ lập trình của dữ liệu.

Một mối đe dọa khác liên quan đến dữ liệu là lựa chọn các miền OOD và APIs. Để giảm thiểu mối đe dọa này, chúng tôi chọn năm miền bao gồm các loại chương trình khác nhau. Cụ thể, chúng tôi chọn 10 giao diện ngẫu nhiên cho mỗi miền. Kết quả của chúng tôi cho thấy quên lãng thảm khốc được quan sát nhất quán cho tất cả các miền, và việc lựa chọn các giao diện khác nhau sẽ dẫn đến các cường độ khác nhau trong việc quên lãng. Chúng tôi để việc nghiên cứu khía cạnh định tính này cho công việc tương lai.

Lựa chọn các nhiệm vụ hạ nguồn trình bày một mối đe dọa bên ngoài khác đối với tính hợp lệ của nghiên cứu. Chúng tôi sử dụng hai nhiệm vụ tạo sinh, dự đoán lời gọi API và dự đoán sử dụng API. Chúng tôi tập trung vào các nhiệm vụ liên quan đến APIs vì APIs là một phần quan trọng của phân phối các token mã trong chương trình và cung cấp nhiều thông tin về ngữ nghĩa của chương trình. Chúng tôi quan sát quên lãng thảm khốc đáng kể trong hai nhiệm vụ liên quan đến API này và đưa ra giả thuyết rằng quên lãng thảm khốc có thể xuất hiện trong các nhiệm vụ SE khác do tầm quan trọng của APIs trong mã. Ví dụ, nghiên cứu trước đây phát hiện rằng APIs đóng vai trò quan trọng trong việc viết tóm tắt mã [31], phát hiện bản sao mã [44], truy xuất mã được đưa ra một truy vấn [42], v.v. Chúng tôi để việc điều tra hiện tượng OOD trong các nhiệm vụ khác làm công việc tương lai.

Chúng tôi xác định một mối đe dọa bên ngoài đối với tính hợp lệ liên quan đến số lượng hạn chế các bước tinh chỉnh trong các cài đặt tinh chỉnh liên tục của chúng tôi. Trong thực tế, một PLM được triển khai trong môi trường sản xuất thực tế có thể đối mặt với một số lượng lớn hơn các bước tinh chỉnh trong suốt thời gian tồn tại của nó. Trong bài báo này, chúng tôi cho thấy rằng cả hai PLMs đều gặp phải quên lãng thảm khốc nghiêm trọng, mặc dù chúng tôi chỉ xem xét năm bước tinh chỉnh. Chúng tôi cũng chứng minh rằng nhiều bước hơn thường dẫn đến việc quên nhiều hơn về dữ liệu quá khứ.

Cuối cùng, việc lựa chọn kích thước của PLMs, về số lượng tham số có thể đào tạo, tạo thành một mối đe dọa tiềm ẩn đối với tính hợp lệ của nghiên cứu. Trong khi việc tăng số lượng tham số vẫn có thể dẫn đến các vấn đề khái quát hóa OOD do thiết kế tập dữ liệu của chúng tôi, vẫn không chắc chắn liệu quên lãng thảm khốc có xảy ra với cùng mức độ đối với các mô hình lớn hơn hay không. Các thí nghiệm của chúng tôi được thực hiện dưới tài nguyên tính toán hạn chế, điều này yêu cầu chúng tôi xem xét các kiến trúc với số lượng tham số hạn chế. Để giảm thiểu mối đe dọa này, chúng tôi tối đa hóa kích thước của các mô hình xem xét tài nguyên hạn chế của chúng tôi. Chúng tôi đào tạo trước PLMs với 110M và 125M tham số nằm trong phạm vi của PLMs như CodeBERT [19], CodeT5 [62] hoặc CodeGPT [41].

Các Mối Đe Dọa Đối Với Tính Hợp Lệ Bên Trong. Các lựa chọn siêu tham số cho các phương pháp CL của chúng tôi tạo thành mối đe dọa chính đối với tính hợp lệ bên trong. Chúng tôi chọn siêu tham số dựa trên các giá trị được sử dụng trong các nghiên cứu trước về học liên tục [10,32,34,71]. Các siêu tham số này có thể được tối ưu hóa cho kịch bản của chúng tôi bằng cách sử dụng các phương pháp tìm kiếm, có xu hướng có chi phí tính toán cao. Tuy nhiên, khía cạnh này không quan trọng đối với nghiên cứu vì chúng tôi đã cho thấy các ưu điểm của việc kết hợp các kỹ thuật học liên tục với các giá trị siêu tham số hợp lý.

Các Mối Đe Dọa Đối Với Tính Hợp Lệ Cấu Trúc. Chúng tôi xác định một mối đe dọa đối với tính hợp lệ cấu trúc liên quan đến việc lựa chọn các chỉ số đánh giá. Chúng tôi giảm thiểu mối đe dọa này bằng cách chọn các chỉ số được sử dụng rộng rãi trong các nghiên cứu trước để đánh giá các nhiệm vụ tạo mã [50,68]. Ngoài ra, chúng tôi điều chỉnh các chỉ số học liên tục từ các nghiên cứu trước [10,32] để đánh giá kịch bản tinh chỉnh liên tục của chúng tôi.

5.2 Tác Động Rộng Hơn và Cơ Hội

Nghiên cứu của chúng tôi làm sáng tỏ hiệu suất của PLMs của mã trong một cài đặt học liên tục cho khái quát hóa ngoài phân phối. Chúng tôi tin rằng việc khám phá ban đầu này về học liên tục cho mã (CL4Code) sẽ truyền cảm hứng cho việc điều tra thêm trong lĩnh vực quan trọng này. Những phát hiện của chúng tôi nêu bật hai lĩnh vực tiềm năng cho nghiên cứu tương lai: cải thiện việc tạo tập dữ liệu và benchmark, và mở rộng ứng dụng của CL4Code cho một loạt các trường hợp sử dụng rộng hơn.

Tập Dữ Liệu và Benchmarks. Những phát hiện của chúng tôi trong Phần 4.1 nêu bật sự khác biệt đáng kể trong hiệu suất của PLM giữa dữ liệu ID và OOD. Kết quả của chúng tôi, cùng với một nghiên cứu trước đây [72], chỉ ra rằng việc đánh giá PLMs trên dữ liệu ID thường dẫn đến các chỉ số thổi phồng và dẫn đến kết luận quá lạc quan về hiệu suất. Do đó, việc phát triển các tập dữ liệu OOD cho mã là rất quan trọng để đánh giá khả năng khái quát hóa thực tế của PLMs, như đã nhấn mạnh trước đây [69,72]. Hơn nữa, việc căn chỉnh thiết kế tập dữ liệu với các kịch bản học liên tục mang lại tiềm năng đánh giá khả năng của PLM thích ứng với môi trường thay đổi, điều này rất quan trọng cho việc triển khai thực tế.

Cải thiện benchmarks cho PLMs của mã là một hướng nghiên cứu đầy hứa hẹn khác cho tương lai. Các benchmarks như CodeXGlue [41] đóng vai trò quan trọng bằng cách cung cấp các đánh giá tiêu chuẩn hóa của các mô hình mã và cho phép kết quả thí nghiệm có thể tái tạo. Tuy nhiên, khi nghiên cứu như vậy tiến triển với tốc độ nhanh, các benchmarks được sử dụng rộng rãi thường trở nên lỗi thời nhanh chóng. Đặc biệt, Kiela et al. [33] cho thấy rằng các benchmarks như GLUE [60] trong NLP bão hòa, có nghĩa là các cột mốc được đặt ra bởi benchmark đã đạt được. Do đó, các nỗ lực liên tục để nâng cao benchmarks trong học sâu cho mã là rất quan trọng trong việc thiết lập các mục tiêu cụ thể và thúc đẩy nghiên cứu để nâng cao hiệu suất của các mô hình được đánh giá. Gần đây, Yang et al. [69] đề xuất GLUE-X, một benchmark toàn diện bao gồm 13 tập dữ liệu để kiểm tra PLMs trên dữ liệu OOD trên tám nhiệm vụ NLP. Benchmark bao gồm các tập dữ liệu OOD khác biệt với những tập trong benchmark GLUE gốc. Phát triển các benchmarks OOD cho mã tương tự như GLUE-X [69] sẽ đóng góp rất lớn cho sự phát triển của nghiên cứu về khái quát hóa OOD cho PLMs của mã. Một phương pháp tiềm năng là biên soạn một tập hợp mới các tập dữ liệu OOD không được bao gồm trong benchmark CodeXGlue hiện có, và sử dụng chúng để kiểm tra PLMs của mã. Hơn nữa, việc khám phá thiết kế các kịch bản OOD cụ thể cho các thay đổi phần mềm, như đã được chứng minh trong nghiên cứu hiện tại, có thể cung cấp một nền tảng có giá trị cho các sáng kiến benchmark mã tương lai. Tập dữ liệu và phương pháp của chúng tôi để trích xuất các mẫu OOD cho các kịch bản phát triển API có thể phục vụ như một điểm khởi đầu cho những nỗ lực này.

Học Liên Tục cho Mã. Những phát hiện của chúng tôi trong Phần 4.2 nêu bật thách thức của quên lãng thảm khốc mà PLMs của mã gặp phải trong một kịch bản tinh chỉnh liên tục với dữ liệu OOD. Nghiên cứu của chúng tôi phục vụ như một điểm khởi đầu để khám phá khả năng thích ứng của PLMs của mã trong nhiều kịch bản học liên tục khác nhau. Ví dụ, các kịch bản này có thể dựa trên thích ứng miền, nơi PLMs phải thích ứng với các loại dữ liệu mới như các ngôn ngữ lập trình mới, chưa được thấy hoặc các kho mã như đã thảo luận trong các nghiên cứu trước [25,30,35]. Ngoài ra, việc kết hợp học liên tục vào một khung học đa nhiệm vụ có liên quan cao đến kỹ thuật phần mềm, với số lượng nhiệm vụ hạ nguồn đa dạng liên quan.

Trong Phần 4.3, kết quả của chúng tôi chứng minh hiệu quả của các phương pháp học liên tục trong việc giảm thiểu quên lãng thảm khốc trong PLMs của mã. Chúng tôi chọn khám phá các phương pháp được sử dụng rộng rãi này như một bước đầu tiên trong nghiên cứu về học liên tục cho mã. Trong tương lai, các kỹ thuật tinh vi hơn từ NLP, như đã thảo luận trong Phần 6.2, có thể được đánh giá. Hơn nữa, việc tạo ra các phương pháp học liên tục được thiết kế riêng cho mã nguồn có tiềm năng giảm thiểu thêm quên lãng thảm khốc trong PLMs của mã.

Cuối cùng, chúng tôi không tập trung nghiên cứu vào các mô hình ngôn ngữ lớn (LLMs) vì nó sẽ đòi hỏi một lượng tài nguyên tính toán khổng lồ để đào tạo trước một LLM từ đầu dưới kịch bản OOD của chúng tôi. Tuy nhiên, chúng tôi dự đoán rằng việc thích ứng liên tục LLMs với các tập dữ liệu và benchmarks mới nổi tạo thành một con đường thú vị cho công việc tương lai. Trong bối cảnh này, và vì việc tinh chỉnh đầy đủ LLMs tốn kém về mặt tính toán, chúng tôi tin rằng việc kết hợp học liên tục với các kỹ thuật tinh chỉnh hiệu quả tham số (PEFT) có thể có lợi để nâng cao thêm khả năng của LLMs. Các kỹ thuật PEFT này đã cho thấy kết quả đầy hứa hẹn trong LLMs cho trí tuệ mã [12, 61, 64].

6 CÔNG TRÌNH LIÊN QUAN

6.1 Khái Quát Hóa Ngoài Phân Phối

Xử Lý Ngôn Ngữ Tự Nhiên. Các nghiên cứu gần đây đã tiết lộ rằng PLMs dễ bị tạo ra các dự đoán không chính xác khi gặp phải dữ liệu OOD [27,54]. Trong NLP, vấn đề này có thể biểu hiện trong các tình huống mà miền của dữ liệu thử nghiệm khác với dữ liệu đào tạo trước [23]. Một phương pháp để giải quyết vấn đề này là tinh chỉnh PLMs trên các tập dữ liệu cụ thể miền bằng các kỹ thuật học chuyển giao hiệu quả. Ví dụ, [29,51] chứng minh rằng các phương pháp như vậy giúp PLMs học kiến thức cụ thể miền và cải thiện khái quát hóa của chúng cho các miền chưa được thấy. Ngoài ra, các tập dữ liệu và benchmarks mới cho phép nghiên cứu thêm về thích ứng miền PLM. Ví dụ, Williams et al. [66] giới thiệu tập dữ liệu MultiNLI, chứa dữ liệu văn bản từ nhiều miền khác nhau cho thích ứng miền PLM. Conneau et al. [14] đề xuất một tập dữ liệu NLI đa ngôn ngữ để đánh giá khả năng chuyển giao đa ngôn ngữ của PLMs. Gần đây, Yang et al. [69] giới thiệu GLUE-X, một benchmark để đánh giá khả năng của PLMs khái quát hóa cho dữ liệu OOD.

Học Sâu cho Mã. Nghiên cứu về khái quát hóa OOD của PLMs của mã là một lĩnh vực nghiên cứu mới nổi. Đánh giá khả năng khái quát hóa của chúng và thiết kế các kỹ thuật hiệu quả để cải thiện tính mạnh mẽ của chúng cho các kịch bản OOD là cần thiết cho khả năng sử dụng thực tế của PLMs của mã [72]. Nghiên cứu trước đây trong lĩnh vực này đã tập trung vào việc thiết kế các tập dữ liệu OOD mô phỏng các dịch chuyển phân phối cụ thể của dữ liệu chương trình. Koh et al. [35] trình bày PY150-Wilds, một tập dữ liệu Python trong đó dữ liệu thử nghiệm bao gồm các kho mã không xuất hiện trong dữ liệu đào tạo. Các tác giả chứng minh khoảng cách hiệu suất giữa mô hình trên dữ liệu ID và OOD. Tuy nhiên, điều quan trọng cần lưu ý là mặc dù lựa chọn thiết kế là hợp lý, nó có thể không phản ánh các hiện tượng OOD mạnh vì phân phối của các token mã trên các kho khác nhau vẫn có thể rất tương tự. Gần đây hơn, Hu et al. [30] đề xuất một benchmark để đánh giá hiệu suất của các mô hình mã dưới các kịch bản dịch chuyển phân phối khác nhau, bao gồm dịch chuyển lập trình viên, thời gian, hoặc phân phối token. Trong nghiên cứu của họ, các tác giả phát hiện rằng PLMs như CodeBERT mạnh mẽ chống lại dịch chuyển phân phối. Tuy nhiên, họ chứng minh điều đó trên một nhiệm vụ phân loại đơn giản với các tập dữ liệu nhỏ. Ngoài ra, các tác giả không kiểm soát dữ liệu đào tạo trước của các PLMs được nghiên cứu, điều này có thể dẫn đến rò rỉ dữ liệu quan trọng giữa dữ liệu đào tạo trước và dữ liệu thử nghiệm OOD. Vấn đề rò rỉ dữ liệu này rất quan trọng vì một số dữ liệu thử nghiệm có thể đã được mô hình thấy trong quá trình đào tạo trước. Nhìn chung, đây là một mối đe dọa chính đối với tính hợp lệ của kịch bản OOD có thể dẫn đến việc thu được các chỉ số thổi phồng trên dữ liệu thử nghiệm OOD. Cuối cùng, Hajipour et al. [25] phân tích hiệu suất của PLMs của mã trên một kịch bản OOD dựa trên cú pháp, dựa trên ngữ nghĩa và dựa trên độ phức tạp và nêu bật rằng các mô hình thể hiện khả năng khái quát hóa kém khi đối mặt với các mẫu OOD. Tuy nhiên, điều quan trọng cần chỉ ra rằng các kịch bản OOD được sử dụng trong nghiên cứu này có thể quá nhân tạo. Ví dụ, trong kịch bản dựa trên cú pháp, một số token cụ thể ngôn ngữ được che trong đào tạo để nghiên cứu cách mô hình khái quát hóa cho các token ngôn ngữ chưa được thấy. Một kịch bản như vậy không thực tế vì nó không phản ánh bản chất của dữ liệu OOD mà PLM của mã có thể gặp phải trong thế giới thực. Ngoài ra, không có động lực thực tế nào để che các token cụ thể trong khi đào tạo mô hình.

Trong nghiên cứu này, chúng tôi đề xuất một tập dữ liệu OOD mô tả chính xác bản chất động của các cơ sở mã phần mềm trong thế giới thực. Cụ thể, chúng tôi tập trung vào kịch bản mà PLM phải thích ứng với các APIs mới, chưa được thấy theo thời gian, một vấn đề được thiết lập tốt trong văn học [46,48]. Để đảm bảo tính hợp lệ của các thí nghiệm, chúng tôi kiểm soát kỹ lưỡng thiết lập PLM để ngăn chặn bất kỳ rò rỉ dữ liệu nào giữa dữ liệu đào tạo trước, tinh chỉnh và thử nghiệm. Điều này cho phép chúng tôi tạo ra một kịch bản khái quát hóa OOD gần với thực tế nhất có thể, một khía cạnh đã bị bỏ qua trong các nghiên cứu trước đây.

6.2 Học Liên Tục cho Các Mô Hình Ngôn Ngữ Được Đào Tạo Trước

Học liên tục đã được nghiên cứu để thích ứng các mô hình ngôn ngữ được đào tạo trước dựa trên kiến trúc Transformer [57] với các miền hoặc nhiệm vụ mới trong NLP. Ví dụ, Cao et al. [9] đề xuất một phương pháp để liên tục học từ các lớp sự kiện mới trong dữ liệu văn bản để phát hiện chúng mà không làm suy giảm độ chính xác theo thời gian. Douillard et al. [17] giới thiệu DyTox, một phương pháp sử dụng một transformer mã hóa-giải mã cho nhiều nhiệm vụ bằng cách mở rộng mạng với các token đặc biệt cụ thể nhiệm vụ, cho phép học liên tục các nhiệm vụ mới với bộ nhớ và tính toán thấp. Ermis et al. [18] đề xuất một phương pháp hiệu quả bộ nhớ cho transformers để liên tục học các nhiệm vụ mới bằng cách chia sẻ thông tin giữa các nhiệm vụ và mở rộng mạng với các mô-đun cụ thể nhiệm vụ. Tương tự, Vladymyrov et al. [58] đề xuất kiến trúc HyperTransformer để liên tục học các nhiệm vụ mới bằng cách tạo ra trọng số mạng nơ-ron tích chập cụ thể nhiệm vụ trong một cài đặt học few-shot và cập nhật trọng số cụ thể nhiệm vụ để tránh quên lãng thảm khốc. Cuối cùng, Jie et al. [32] tận dụng học liên tục để tránh dịch chuyển biểu diễn trong PLMs bằng cách đề xuất một phương pháp tinh chỉnh phân cấp mới ngăn chặn các thay đổi quá mức trong không gian biểu diễn của mạng nơ-ron trong một cài đặt tinh chỉnh liên tục.

Những tiến bộ gần đây trong NLP nêu bật nhu cầu quan trọng cho PLMs thích ứng với môi trường thay đổi và duy trì hiệu suất của chúng trên dữ liệu và nhiệm vụ mới. Trong lĩnh vực kỹ thuật phần mềm, việc áp dụng học liên tục cho PLMs của mã là cần thiết để phát triển các phương pháp cho phép mô hình thích ứng mạnh mẽ với các cơ sở mã và nhiệm vụ mới theo thời gian. Theo hiểu biết tốt nhất của chúng tôi, chỉ có một vài nghiên cứu trước đây sử dụng học liên tục trong bối cảnh trí tuệ mã. Baudry et al. [5] chứng minh lợi ích của việc tận dụng học liên tục để sửa lỗi khi xem xét một luồng liên tục thay đổi mã với các nền tảng phát triển tích hợp liên tục. Phạm vi nghiên cứu của chúng tôi khác với nghiên cứu trước đây này ở nhiều khía cạnh. Đầu tiên, trái ngược với nghiên cứu trước đây này, nghiên cứu của chúng tôi tập trung vào các kiến trúc PLM mở rộng khả năng áp dụng tiềm năng của phương pháp của chúng tôi cho một loạt nhiệm vụ rộng hơn. Thứ hai, chúng tôi so sánh nhiều kỹ thuật học liên tục trong kịch bản OOD với PLMs, trong khi nghiên cứu trước đây này chỉ xem xét một kịch bản học liên tục mà không tận dụng các kỹ thuật học liên tục như bộ đệm phát lại hoặc EWC. Gần đây hơn, Gao et al. [21] có những phát hiện tương tự như chúng tôi bằng cách cho thấy rằng PLMs gặp phải quên lãng thảm khốc trong các kịch bản học liên tục và các phương pháp dựa trên phát lại cho phép giảm thiểu hiệu quả việc quên lãng. Chúng tôi tin rằng những nghiên cứu trước đây này và nghiên cứu của chúng tôi mở đường bằng cách giới thiệu các phương pháp đầu tiên về việc sử dụng học liên tục cho PLMs của mã.

7 KẾT LUẬN VÀ CÔNG VIỆC TƯƠNG LAI

Nghiên cứu của chúng tôi vạch trần những hạn chế của các mô hình ngôn ngữ được đào tạo trước của mã trong việc xử lý dữ liệu ngoài phân phối trong một kịch bản tinh chỉnh liên tục. Kết quả của chúng tôi tiết lộ rằng dữ liệu OOD giảm đáng kể hiệu quả của PLMs trong hai nhiệm vụ hạ nguồn liên quan đến API so với dữ liệu ID. Những phát hiện của chúng tôi chỉ ra rằng học chuyển giao cổ điển thất bại trong việc thích ứng PLMs với các APIs mới, chưa được thấy trong kịch bản phát triển này. Ngoài ra, chúng tôi quan sát các trường hợp quên lãng thảm khốc, thúc đẩy chúng tôi khám phá các phương pháp giải quyết vấn đề này. Trong các thí nghiệm cuối cùng, chúng tôi chứng minh rằng các kỹ thuật học liên tục dựa trên phát lại và dựa trên chính quy hóa có thể hiệu quả giảm thiểu quên lãng thảm khốc trong khi giữ lại hoặc nâng cao hiệu suất của PLMs trong cả hai nhiệm vụ hạ nguồn. Trong công việc tương lai, chúng tôi dự định khám phá thêm các kịch bản OOD để đánh giá thêm khả năng khái quát hóa của PLMs của mã và phát triển các benchmarks khái quát hóa OOD liên quan cho mã. Ngoài ra, chúng tôi lên kế hoạch triển khai các phương pháp học liên tục tiên tiến hơn được thiết kế riêng cho mã nguồn để nâng cao khả năng thích ứng của PLMs của mã. Cuối cùng, chúng tôi nhằm điều tra các phương pháp phát hiện OOD để tự động xác định dữ liệu OOD trong PLMs, từ đó cải thiện hiệu suất của chúng.

TÍNH SẴN CÓ DỮ LIỆU

Chúng tôi phát hành công khai tất cả mã, dữ liệu và mô hình để tái tạo các thí nghiệm của nghiên cứu. Kho lưu trữ sau đây chứa hướng dẫn về cách thu thập dữ liệu và đào tạo trước, tinh chỉnh và thử nghiệm PLMs: https://github.com/martin-wey/cl-code-apis

TÀI LIỆU THAM KHẢO

[1] Wasi Ahmad, Saikat Chakraborty, Baishakhi Ray, và Kai-Wei Chang. 2021. Đào Tạo Trước Thống Nhất cho Hiểu Biết và Tạo Chương Trình. Trong Kỷ yếu Hội nghị 2021 của Chương Bắc Mỹ của Hội Ngôn ngữ học Tính toán: Công nghệ Ngôn ngữ Con người. Hội Ngôn ngữ học Tính toán, Trực tuyến, 2655–2668. https://doi.org/10.18653/v1/2021.naacl-main.211

[2] Rahaf Aljundi, Francesca Babiloni, Mohamed Elhoseiny, Marcus Rohrbach, và Tinne Tuytelaars. 2018. Synap bộ nhớ nhận thức: Học cái gì (không) để quên. Trong Kỷ yếu hội nghị Châu Âu về thị giác máy tính (ECCV). 139–154.

[3] Miltiadis Allamanis. 2019. Những Tác Động Bất Lợi của Trùng Lặp Mã trong Các Mô Hình Học Máy của Mã. Trong Kỷ yếu Hội thảo Quốc tế ACM SIGPLAN 2019 về Ý tưởng Mới, Mô hình Mới, và Phản ánh về Lập trình và Phần mềm (Athens, Hy Lạp) (Onward! 2019). Hội Máy tính, New York, NY, USA, 143–153. https://doi.org/10.1145/3359591.3359735

[4] Gareth Ari Aye, Seohyun Kim, và Hongyu Li. 2021. Học Tự động Hoàn thành từ Tập Dữ liệu Thế giới Thực. Trong Hội nghị Quốc tế IEEE/ACM lần thứ 43 về Kỹ thuật Phần mềm 2021: Kỹ thuật Phần mềm trong Thực tế (ICSE-SEIP). 131–139. https://doi.org/10.1109/ICSE-SEIP52600.2021.00022

[5] Benoit Baudry, Zimin Chen, Khashayar Etemadi, Han Fu, Davide Ginelli, Steve Kommrusch, Matias Martinez, Martin Monperrus, Javier Ron, He Ye, và Zhongxing Yu. 2021. Một Robot Sửa Phần mềm Dựa trên Học Liên tục. IEEE Software 38, 4 (2021), 28–35. https://doi.org/10.1109/MS.2021.3070743

[6] Chaitanya Baweja, Ben Glocker, và Konstantinos Kamnitsas. 2018. Hướng tới học liên tục trong hình ảnh y tế. arXiv preprint arXiv:1811.02496 (2018).

[7] Magdalena Biesialska, Katarzyna Biesialska, và Marta R. Costa-jussà. 2020. Học Suốt đời Liên tục trong Xử lý Ngôn ngữ Tự nhiên: Một Khảo sát. Trong Kỷ yếu Hội nghị Quốc tế lần thứ 28 về Ngôn ngữ học Tính toán. Ủy ban Quốc tế về Ngôn ngữ học Tính toán, Barcelona, Tây Ban Nha (Trực tuyến), 6523–6541. https://doi.org/10.18653/v1/2020.coling-main.574

[8] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. 2020. Các Mô hình Ngôn ngữ là Những Người học Few-Shot. Trong Tiến bộ trong Hệ thống Xử lý Thông tin Nơ-ron, H. Larochelle, M. Ranzato, R. Hadsell, M.F. Balcan, và H. Lin (Eds.), Tập 33. Curran Associates, Inc., 1877–1901. https://proceedings.neurips.cc/paper_files/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf

[9] Pengfei Cao, Yubo Chen, Jun Zhao, và Taifeng Wang. 2020. Phát hiện Sự kiện Tăng dần thông qua Mạng Hợp nhất Kiến thức. Trong Kỷ yếu Hội nghị 2020 về Phương pháp Thực nghiệm trong Xử lý Ngôn ngữ Tự nhiên (EMNLP). Hội Ngôn ngữ học Tính toán, Trực tuyến, 707–717. https://doi.org/10.18653/v1/2020.emnlp-main.52

[10] Arslan Chaudhry, Puneet K Dokania, Thalaiyasingam Ajanthan, và Philip HS Torr. 2018. Bước đi Riemannian cho học tăng dần: Hiểu biết về việc quên và không khoan nhượng. Trong Kỷ yếu Hội nghị Châu Âu về Thị giác Máy tính (ECCV). 532–547.

[11] Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, et al. 2021. Đánh giá các mô hình ngôn ngữ lớn được đào tạo trên mã. arXiv preprint arXiv:2107.03374 (2021).

[12] YunSeok Choi và Jee-Hyong Lee. 2023. CodePrompt: Tinh chỉnh Tiền tố Không phụ thuộc Nhiệm vụ cho Tạo Chương trình và Ngôn ngữ. Trong Kết quả của Hội Ngôn ngữ học Tính toán: ACL 2023. 5282–5297.

[13] Matteo Ciniselli, Nathan Cooper, Luca Pascarella, Denys Poshyvanyk, Massimiliano Di Penta, và Gabriele Bavota. 2021. Một Nghiên cứu Thực nghiệm về Việc Sử dụng Các Mô hình BERT cho Hoàn thành Mã. Trong Hội nghị Quốc tế IEEE/ACM lần thứ 18 về Khai thác Kho Phần mềm 2021 (MSR). 108–119. https://doi.org/10.1109/MSR52588.2021.00024

[14] Alexis Conneau, Guillaume Lample, Ruty Rinott, Adina Williams, Samuel R Bowman, Holger Schwenk, và Veselin Stoyanov. 2018. XNLI: Đánh giá biểu diễn câu đa ngôn ngữ. arXiv preprint arXiv:1809.05053 (2018).

[15] Matthias De Lange, Rahaf Aljundi, Marc Masana, Sarah Parisot, Xu Jia, Ales Leonardis, Gregory Slabaugh, và Tinne Tuytelaars. 2019. Học liên tục: Một nghiên cứu so sánh về cách thách thức việc quên trong các nhiệm vụ phân loại. arXiv preprint arXiv:1909.08383 2, 6 (2019), 2.

[16] Jacob Devlin, Ming-Wei Chang, Kenton Lee, và Kristina Toutanova. 2018. Bert: Đào tạo trước của transformers hai chiều sâu cho hiểu biết ngôn ngữ. arXiv preprint arXiv:1810.04805 (2018).

[17] Arthur Douillard, Alexandre Ramé, Guillaume Couairon, và Matthieu Cord. 2022. Dytox: Transformers cho học liên tục với mở rộng token động. Trong Kỷ yếu Hội nghị IEEE/CVF về Thị giác Máy tính và Nhận dạng Mẫu. 9285–9295.

[18] Beyza Ermis, Giovanni Zappella, Martin Wistuba, Aditya Rawal, và Cedric Archambeau. 2022. Học Liên tục Hiệu quả Bộ nhớ với Transformers. Trong Tiến bộ trong Hệ thống Xử lý Thông tin Nơ-ron, S. Koyejo, S. Mohamed, A. Agarwal, D. Belgrave, K. Cho, và A. Oh (Eds.), Tập 35. Curran Associates, Inc., 10629–10642. https://proceedings.neurips.cc/paper_files/paper/2022/file/4522de4178bddb36b49aa26efad537cf-Paper-Conference.pdf

[19] Zhangyin Feng, Daya Guo, Duyu Tang, Nan Duan, Xiaocheng Feng, Ming Gong, Linjun Shou, Bing Qin, Ting Liu, Daxin Jiang, và Ming Zhou. 2020. CodeBERT: Một Mô hình Được Đào tạo Trước cho Lập trình và Ngôn ngữ Tự nhiên. Trong Kết quả của Hội Ngôn ngữ học Tính toán: EMNLP 2020. Hội Ngôn ngữ học Tính toán, Trực tuyến, 1536–1547. https://doi.org/10.18653/v1/2020.findings-emnlp.139

[20] Robert M French. 1999. Quên lãng thảm khốc trong mạng nối kết. Xu hướng trong khoa học nhận thức 3, 4 (1999), 128–135.

[21] Shuzheng Gao, Hongyu Zhang, Cuiyun Gao, và Chaozheng Wang. 2023. Theo kịp Dữ liệu Ngày càng Tăng: Hướng tới Học Liên tục của Các Mô hình Trí tuệ Mã. arXiv preprint arXiv:2302.03482 (2023).

[22] Daya Guo, Shuai Lu, Nan Duan, Yanlin Wang, Ming Zhou, và Jian Yin. 2022. UniXcoder: Đào tạo Trước Đa phương thức Thống nhất cho Biểu diễn Mã. Trong Kỷ yếu Cuộc họp Thường niên lần thứ 60 của Hội Ngôn ngữ học Tính toán (Tập 1: Bài báo Dài). Hội Ngôn ngữ học Tính toán, Dublin, Ireland, 7212–7225. https://doi.org/10.18653/v1/2022.acl-long.499

[23] Suchin Gururangan, Ana Marasović, Swabha Swayamdipta, Kyle Lo, Iz Beltagy, Doug Downey, và Noah A. Smith. 2020. Đừng Ngừng Đào tạo Trước: Thích ứng Các Mô hình Ngôn ngữ với Miền và Nhiệm vụ. Trong Kỷ yếu Cuộc họp Thường niên lần thứ 58 của Hội Ngôn ngữ học Tính toán. Hội Ngôn ngữ học Tính toán, Trực tuyến, 8342–8360. https://doi.org/10.18653/v1/2020.acl-main.740

[24] Raia Hadsell, Dushyant Rao, Andrei A Rusu, và Razvan Pascanu. 2020. Chấp nhận thay đổi: Học liên tục trong mạng nơ-ron sâu. Xu hướng trong khoa học nhận thức 24, 12 (2020), 1028–1040. https://doi.org/10.1016/j.tics.2020.09.004

[25] Hossein Hajipour, Ning Yu, Cristian-Alexandru Staicu, và Mario Fritz. 2022. SimSCOOD: Phân tích Hệ thống Hành vi Ngoài Phân phối của Các Mô hình Mã nguồn. arXiv preprint arXiv:2210.04802 (2022).

[26] Vincent J. Hellendoorn, Sebastian Proksch, Harald C. Gall, và Alberto Bacchelli. 2019. Khi Hoàn thành Mã Thất bại: Một Nghiên cứu Trường hợp về Hoàn thành Thế giới Thực. Trong Hội nghị Quốc tế IEEE/ACM lần thứ 41 về Kỹ thuật Phần mềm 2019 (ICSE). 960–970. https://doi.org/10.1109/ICSE.2019.00101

[27] Dan Hendrycks, Xiaoyuan Liu, Eric Wallace, Adam Dziedzic, Rishabh Krishnan, và Dawn Song. 2020. Transformers Được đào tạo Trước Cải thiện Tính mạnh mẽ Ngoài Phân phối. Trong Kỷ yếu Cuộc họp Thường niên lần thứ 58 của Hội Ngôn ngữ học Tính toán. Hội Ngôn ngữ học Tính toán, Trực tuyến, 2744–2751. https://doi.org/10.18653/v1/2020.acl-main.244

[28] Thong Hoang, Hong Jin Kang, David Lo, và Julia Lawall. 2020. CC2Vec: Biểu diễn Phân tán của Thay đổi Mã. Trong Kỷ yếu Hội nghị Quốc tế ACM/IEEE lần thứ 42 về Kỹ thuật Phần mềm (Seoul, Hàn Quốc) (ICSE '20). Hội Máy tính, New York, NY, USA, 518–529. https://doi.org/10.1145/3377811.3380361

[29] Jeremy Howard và Sebastian Ruder. 2018. Tinh chỉnh Mô hình Ngôn ngữ Toàn cầu cho Phân loại Văn bản. Trong Kỷ yếu Cuộc họp Thường niên lần thứ 56 của Hội Ngôn ngữ học Tính toán (Tập 1: Bài báo Dài). Hội Ngôn ngữ học Tính toán, Melbourne, Australia, 328–339. https://doi.org/10.18653/v1/P18-1031

[30] Qiang Hu, Yuejun Guo, Xiaofei Xie, Maxime Cordy, Lei Ma, Mike Papadakis, và Yves Le Traon. 2022. CodeS: Một Tập dữ liệu Benchmark Dịch chuyển Phân phối cho Học Mã nguồn. arXiv preprint arXiv:2206.05480 (2022).

[31] Xing Hu, Ge Li, Xin Xia, David Lo, Shuai Lu, và Zhi Jin. 2018. Tóm tắt Mã nguồn với Kiến thức API Được chuyển giao. Trong Kỷ yếu Hội nghị Quốc tế lần thứ 27 về Trí tuệ Nhân tạo (Stockholm, Thụy Điển) (IJCAI'18). AAAI Press, 2269–2275.

[32] S. Jie, Z. Deng, và Z. Li. 2022. Giảm thiểu Dịch chuyển Biểu diễn cho Tinh chỉnh Liên tục. Trong Hội thảo IEEE/CVF 2022 về Thị giác Máy tính và Nhận dạng Mẫu (CVPRW). IEEE Computer Society, Los Alamitos, CA, USA, 3809–3818. https://doi.org/10.1109/CVPRW56347.2022.00426

[33] Douwe Kiela, Max Bartolo, Yixin Nie, Divyansh Kaushik, Atticus Geiger, Zhengxuan Wu, Bertie Vidgen, Grusha Prasad, Amanpreet Singh, Pratik Ringshia, et al. 2021. Dynabench: Suy nghĩ lại về benchmarking trong NLP. arXiv preprint arXiv:2104.14337 (2021).

[34] James Kirkpatrick, Razvan Pascanu, Neil Rabinowitz, Joel Veness, Guillaume Desjardins, Andrei A Rusu, Kieran Milan, John Quan, Tiago Ramalho, Agnieszka Grabska-Barwinska, et al. 2017. Vượt qua quên lãng thảm khốc trong mạng nơ-ron. Kỷ yếu của viện hàn lâm khoa học quốc gia 114, 13 (2017), 3521–3526. https://doi.org/10.1073/pnas.1611835114

[35] Pang Wei Koh, Shiori Sagawa, Henrik Marklund, Sang Michael Xie, Marvin Zhang, Akshay Balsubramani, Weihua Hu, Michihiro Yasunaga, Richard Lanas Phillips, Irena Gao, et al. 2021. Wilds: Một benchmark của dịch chuyển phân phối trong tự nhiên. Trong Hội nghị Quốc tế về Học Máy. PMLR, 5637–5664.

[36] Zhizhong Li và Derek Hoiem. 2017. Học mà không quên. IEEE transactions on pattern analysis and machine intelligence 40, 12 (2017), 2935–2947. https://doi.org/10.1109/TPAMI.2017.2773081

[37] Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, và Veselin Stoyanov. 2019. Roberta: Một phương pháp đào tạo trước bert được tối ưu hóa mạnh mẽ. arXiv preprint arXiv:1907.11692 (2019).

[38] Vincenzo Lomonaco và Davide Maltoni. 2017. CORe50: một Tập dữ liệu và Benchmark Mới cho Nhận dạng Đối tượng Liên tục. Trong Kỷ yếu Hội nghị Thường niên lần thứ 1 về Học Robot (Kỷ yếu của Nghiên cứu Học Máy, Tập 78), Sergey Levine, Vincent Vanhoucke, và Ken Goldberg (Eds.). PMLR, 17–26. https://proceedings.mlr.press/v78/lomonaco17a.html

[39] Vincenzo Lomonaco, Lorenzo Pellegrini, Andrea Cossu, Antonio Carta, Gabriele Graffieti, Tyler L. Hayes, Matthias De Lange, Marc Masana, Jary Pomponi, Gido van de Ven, Martin Mundt, Qi She, Keiland Cooper, Jeremy Forest, Eden Belouadah, Simone Calderara, German I. Parisi, Fabio Cuzzolin, Andreas Tolias, Simone Scardapane, Luca Antiga, Subutai Amhad, Adrian Popescu, Christopher Kanan, Joost van de Weijer, Tinne Tuytelaars, Davide Bacciu, và Davide Maltoni. 2021. Avalanche: một Thư viện Từ đầu đến cuối cho Học Liên tục. Trong Kỷ yếu Hội nghị IEEE về Thị giác Máy tính và Nhận dạng Mẫu (Hội thảo Học Liên tục lần thứ 2 trong Thị giác Máy tính).

[40] Jie Lu, Anjin Liu, Fan Dong, Feng Gu, Joao Gama, và Guangquan Zhang. 2018. Học dưới dịch chuyển khái niệm: Một đánh giá. IEEE Transactions on Knowledge and Data Engineering 31, 12 (2018), 2346–2363.

[41] Shuai Lu, Daya Guo, Shuo Ren, Junjie Huang, Alexey Svyatkovskiy, Ambrosio Blanco, Colin Clement, Dawn Drain, Daxin Jiang, Duyu Tang, et al. 2021. CodeXGLUE: Một Tập dữ liệu Benchmark Học Máy cho Hiểu biết và Tạo Mã. Trong Hội nghị lần thứ ba mươi lăm về Hệ thống Xử lý Thông tin Nơ-ron Tập dữ liệu và Benchmarks Track (Vòng 1).

[42] Fei Lv, Hongyu Zhang, Jian-guang Lou, Shaowei Wang, Dongmei Zhang, và Jianjun Zhao. 2015. CodeHow: Tìm kiếm Mã Hiệu quả Dựa trên Hiểu biết API và Mô hình Boolean Mở rộng (E). Trong Hội nghị Quốc tế IEEE/ACM lần thứ 30 về Kỹ thuật Phần mềm Tự động 2015 (ASE). 260–270. https://doi.org/10.1109/ASE.2015.42

[43] Michael McCloskey và Neal J. Cohen. 1989. Can thiệp Thảm khốc trong Mạng Kết nối: Vấn đề Học Tuần tự. Tâm lý học của Học và Động lực, Tập 24. Academic Press, 109–165. https://doi.org/10.1016/S0079-7421(08)60536-8

[44] Kawser Wazed Nafi, Tonny Shekha Kar, Banani Roy, Chanchal K. Roy, và Kevin A. Schneider. 2019. CLCDSA: Phát hiện Bản sao Mã Đa ngôn ngữ sử dụng Đặc điểm Cú pháp và Tài liệu API. Trong Hội nghị Quốc tế IEEE/ACM lần thứ 34 về Kỹ thuật Phần mềm Tự động 2019 (ASE). 1026–1037. https://doi.org/10.1109/ASE.2019.00099

[45] Tung Thanh Nguyen, Hoan Anh Nguyen, Nam H. Pham, Jafar M. Al-Kofahi, và Tien N. Nguyen. 2009. Khai thác Dựa trên Đồ thị của Nhiều Mẫu Sử dụng Đối tượng. Trong Kỷ yếu Cuộc họp Chung lần thứ 7 của Hội nghị Kỹ thuật Phần mềm Châu Âu và Hội thảo ACM SIGSOFT về Cơ sở của Kỹ thuật Phần mềm (Amsterdam, Hà Lan) (ESEC/FSE '09). Hội Máy tính, New York, NY, USA, 383–392. https://doi.org/10.1145/1595696.1595767

[46] Marius Nita và David Notkin. 2010. Sử dụng ghép đôi để thích ứng chương trình với APIs thay thế. Trong Hội nghị Quốc tế ACM/IEEE lần thứ 32 về Kỹ thuật Phần mềm 2010, Tập 1. IEEE, 205–214.

[47] German I. Parisi, Ronald Kemker, Jose L. Part, Christopher Kanan, và Stefan Wermter. 2019. Học suốt đời liên tục với mạng nơ-ron: Một đánh giá. Neural Networks 113 (2019), 54–71. https://doi.org/10.1016/j.neunet.2019.01.012

[48] Sebastian Proksch, Sven Amann, Sarah Nadi, và Mira Mezini. 2016. Đánh giá các đánh giá của hệ thống khuyến nghị mã: một kiểm tra thực tế. Trong Hội nghị Quốc tế IEEE/ACM lần thứ 31 về Kỹ thuật Phần mềm Tự động 2016 (ASE). IEEE, 111–121.

[49] Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al. 2019. Các mô hình ngôn ngữ là những người học đa nhiệm vụ không giám sát. OpenAI blog 1, 8 (2019), 9.

[50] Shuo Ren, Daya Guo, Shuai Lu, Long Zhou, Shujie Liu, Duyu Tang, Neel Sundaresan, Ming Zhou, Ambrosio Blanco, và Shuai Ma. 2020. Codebleu: một phương pháp đánh giá tự động tổng hợp mã. arXiv preprint arXiv:2009.10297 (2020).

[51] Sebastian Ruder, Matthew E. Peters, Swabha Swayamdipta, và Thomas Wolf. 2019. Học Chuyển giao trong Xử lý Ngôn ngữ Tự nhiên. Trong Kỷ yếu Hội nghị 2019 của Chương Bắc Mỹ của Hội Ngôn ngữ học Tính toán: Hướng dẫn. Hội Ngôn ngữ học Tính toán, Minneapolis, Minnesota, 15–18. https://doi.org/10.18653/v1/N19-5004

[52] Andrei A Rusu, Neil C Rabinowitz, Guillaume Desjardins, Hubert Soyer, James Kirkpatrick, Koray Kavukcuoglu, Razvan Pascanu, và Raia Hadsell. 2016. Mạng nơ-ron tiến bộ. arXiv preprint arXiv:1606.04671 (2016).

[53] Zheyan Shen, Jiashuo Liu, Yue He, Xingxuan Zhang, Renzhe Xu, Han Yu, và Peng Cui. 2021. Hướng tới khái quát hóa ngoài phân phối: Một khảo sát. arXiv preprint arXiv:2108.13624 (2021).

[54] Yuge Shi, Imant Daunhawer, Julia E Vogt, Philip Torr, và Amartya Sanyal. 2022. Các mô hình được đào tạo trước mạnh mẽ như thế nào đối với dịch chuyển phân phối? Trong ICML 2022: Hội thảo về Tương quan Giả, Bất biến và Ổn định. https://openreview.net/forum?id=zKDcZBVVEWm

[55] Xiaoyu Tao, Xiaopeng Hong, Xinyuan Chang, Songlin Dong, Xing Wei, và Yihong Gong. 2020. Học tăng dần lớp few-shot. Trong Kỷ yếu Hội nghị IEEE/CVF về Thị giác Máy tính và Nhận dạng Mẫu. 12183–12192.

[56] Brian Thompson, Jeremy Gwinnup, Huda Khayrallah, Kevin Duh, và Philipp Koehn. 2019. Vượt qua Quên lãng Thảm khốc Trong Thích ứng Miền của Dịch Máy Nơ-ron. Trong Kỷ yếu Hội nghị 2019 của Chương Bắc Mỹ của Hội Ngôn ngữ học Tính toán: Công nghệ Ngôn ngữ Con người, Tập 1 (Bài báo Dài và Ngắn). Hội Ngôn ngữ học Tính toán, Minneapolis, Minnesota, 2062–2068. https://doi.org/10.18653/v1/N19-1209

[57] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, và Illia Polosukhin. 2017. Attention is All you Need. Trong Tiến bộ trong Hệ thống Xử lý Thông tin Nơ-ron, I. Guyon, U. Von Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, và R. Garnett (Eds.), Tập 30. Curran Associates, Inc.

[58] Max Vladymyrov, Andrey Zhmoginov, và Mark Sandler. 2023. Học Liên tục Few-Shot Sử dụng HyperTransformers. arXiv preprint arXiv:2301.04584 (2023).

[59] Li Wan, Matthew Zeiler, Sixin Zhang, Yann LeCun, và Rob Fergus. 2013. Chính quy hóa Mạng Nơ-ron Sử dụng Dropconnect. Trong Kỷ yếu Hội nghị Quốc tế lần thứ 30 về Học Máy Quốc tế - Tập 28 (Atlanta, GA, USA) (ICML'13). JMLR.org, III–1058–III–1066.

[60] Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, và Samuel R Bowman. 2018. GLUE: Một nền tảng benchmark và phân tích đa nhiệm vụ cho hiểu biết ngôn ngữ tự nhiên. arXiv preprint arXiv:1804.07461 (2018).

[61] Chaozheng Wang, Yuanhang Yang, Cuiyun Gao, Yun Peng, Hongyu Zhang, và Michael R Lyu. 2022. Không còn tinh chỉnh nữa? một đánh giá thực nghiệm về tinh chỉnh prompt trong trí tuệ mã. Trong Kỷ yếu Hội nghị Kỹ thuật Phần mềm Châu Âu Chung ACM lần thứ 30 và Hội thảo về Cơ sở của Kỹ thuật Phần mềm. 382–394.

[62] Yue Wang, Weishi Wang, Shafiq Joty, và Steven C.H. Hoi. 2021. CodeT5: Các Mô hình Mã hóa-Giải mã Được Đào tạo Trước Thống nhất Nhận biết Định danh cho Hiểu biết và Tạo Mã. Trong Kỷ yếu Hội nghị 2021 về Phương pháp Thực nghiệm trong Xử lý Ngôn ngữ Tự nhiên. Hội Ngôn ngữ học Tính toán, Trực tuyến và Punta Cana, Cộng hòa Dominican, 8696–8708. https://doi.org/10.18653/v1/2021.emnlp-main.685

[63] Cody Watson, Nathan Cooper, David Nader Palacio, Kevin Moran, và Denys Poshyvanyk. 2022. Một đánh giá văn học hệ thống về việc sử dụng học sâu trong nghiên cứu kỹ thuật phần mềm. ACM Transactions on Software Engineering and Methodology (TOSEM) 31, 2 (2022), 1–58. https://doi.org/10.1145/3485275

[64] Martin Weyssow, Xin Zhou, Kisub Kim, David Lo, và Houari Sahraoui. 2023. Khám phá Các Kỹ thuật Tinh chỉnh Hiệu quả Tham số cho Tạo Mã với Các Mô hình Ngôn ngữ Lớn. arXiv:2308.10462 [cs.SE]

[65] Gerhard Widmer và Miroslav Kubat. 1996. Học trong sự hiện diện của dịch chuyển khái niệm và bối cảnh ẩn. Machine learning 23, 1 (1996), 69–101. https://doi.org/10.1023/A:1018046501280

[66] Adina Williams, Nikita Nangia, và Samuel R Bowman. 2017. Một corpus thách thức bao phủ rộng cho hiểu biết câu thông qua suy luận. arXiv preprint arXiv:1704.05426 (2017).

[67] Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Rémi Louf, Morgan Funtowicz, et al. 2019. Transformers của Huggingface: Xử lý ngôn ngữ tự nhiên tiên tiến. arXiv preprint arXiv:1910.03771 (2019).

[68] Frank F Xu, Uri Alon, Graham Neubig, và Vincent Josua Hellendoorn. 2022. Một đánh giá hệ thống của các mô hình ngôn ngữ lớn của mã. Trong Kỷ yếu Hội thảo Quốc tế ACM SIGPLAN lần thứ 6 về Lập trình Máy. 1–10.

[69] Linyi Yang, Shuibai Zhang, Libo Qin, Yafu Li, Yidong Wang, Hanmeng Liu, Jindong Wang, Xing Xie, và Yue Zhang. 2022. GLUE-X: Đánh giá Các Mô hình Hiểu biết Ngôn ngữ Tự nhiên từ Góc độ Khái quát hóa Ngoài phân phối. arXiv preprint arXiv:2211.08073 (2022).

[70] Zhengran Zeng, Hanzhuo Tan, Haotian Zhang, Jing Li, Yuqun Zhang, và Lingming Zhang. 2022. Một nghiên cứu rộng rãi về các mô hình được đào tạo trước cho hiểu biết và tạo chương trình. Trong Kỷ yếu Hội thảo Quốc tế ACM SIGSOFT lần thứ 31 về Kiểm thử và Phân tích Phần mềm. 39–51. https://doi.org/10.1145/3533767.3534390

[71] Friedemann Zenke, Ben Poole, và Surya Ganguli. 2017. Học liên tục thông qua trí tuệ synap. Trong Hội nghị Quốc tế về Học Máy. PMLR, 3987–3995.

[72] Xin Zhou, DongGyun Han, và David Lo. 2021. Đánh giá khả năng khái quát hóa của CodeBERT. Trong Hội nghị IEEE 2021 về Bảo trì và Phát triển Phần mềm (ICSME). IEEE, 425–436.

Nhận 2023-02-02; chấp nhận 2023-07-27

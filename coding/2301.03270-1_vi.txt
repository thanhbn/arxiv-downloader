# 2301.03270.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/coding/2301.03270.pdf
# Kích thước file: 2949930 bytes

===============================================
NỘI DUNG FILE PDF
===============================================

--- TRANG 1 ---
1
Một Khảo sát về Sửa chữa Chương trình Tự động dựa trên Học máy
QUANJUN ZHANG, Phòng thí nghiệm Trọng điểm Nhà nước về Công nghệ Phần mềm Mới, Đại học Nam Kinh, Trung Quốc
CHUNRONG FANG∗, Phòng thí nghiệm Trọng điểm Nhà nước về Công nghệ Phần mềm Mới, Đại học Nam Kinh, Trung Quốc
YUXIANG MA, Phòng thí nghiệm Trọng điểm Nhà nước về Công nghệ Phần mềm Mới, Đại học Nam Kinh, Trung Quốc
WEISONG SUN, Phòng thí nghiệm Trọng điểm Nhà nước về Công nghệ Phần mềm Mới, Đại học Nam Kinh, Trung Quốc
ZHENYU CHEN∗, Phòng thí nghiệm Trọng điểm Nhà nước về Công nghệ Phần mềm Mới, Đại học Nam Kinh, Trung Quốc

Sửa chữa chương trình tự động (APR) nhằm mục đích sửa lỗi phần mềm một cách tự động và đóng vai trò quan trọng trong phát triển và bảo trì phần mềm. Với những tiến bộ gần đây trong học sâu (DL), ngày càng nhiều kỹ thuật APR đã được đề xuất để tận dụng mạng neural để học các mẫu sửa lỗi từ các kho mã nguồn mở khổng lồ. Các kỹ thuật dựa trên học máy này thường coi APR như một tác vụ dịch máy neural (NMT), nơi các đoạn mã lỗi (tức là ngôn ngữ nguồn) được dịch thành các đoạn mã đã sửa (tức là ngôn ngữ đích) một cách tự động. Nhờ khả năng mạnh mẽ của DL trong việc học các mối quan hệ ẩn từ các bộ dữ liệu sửa lỗi trước đó, các kỹ thuật APR dựa trên học máy đã đạt được hiệu suất đáng kể.

Trong bài báo này, chúng tôi cung cấp một khảo sát có hệ thống để tóm tắt tình trạng nghiên cứu hiện đại trong cộng đồng APR dựa trên học máy. Chúng tôi minh họa quy trình làm việc chung của các kỹ thuật APR dựa trên học máy và trình bày chi tiết các thành phần quan trọng, bao gồm định vị lỗi, tạo bản vá, xếp hạng bản vá, xác thực bản vá và các giai đoạn đánh giá tính đúng đắn của bản vá. Sau đó chúng tôi thảo luận về các bộ dữ liệu được áp dụng rộng rãi và các chỉ số đánh giá cũng như phác thảo các nghiên cứu thực nghiệm hiện có. Chúng tôi thảo luận về một số khía cạnh quan trọng của các kỹ thuật APR dựa trên học máy, chẳng hạn như lĩnh vực sửa chữa, triển khai công nghiệp và vấn đề khoa học mở. Chúng tôi nêu bật một số hướng dẫn thực tế về việc áp dụng các kỹ thuật DL cho các nghiên cứu APR trong tương lai, chẳng hạn như khám phá việc tạo bản vá có thể giải thích và sử dụng các tính năng mã. Nhìn chung, bài báo của chúng tôi có thể giúp các nhà nghiên cứu có được hiểu biết toàn diện về những thành tựu của các kỹ thuật APR dựa trên học máy hiện có và thúc đẩy ứng dụng thực tế của các kỹ thuật này. Các tạo phẩm của chúng tôi được công khai tại kho lưu trữ: https://github.com/iSEngLab/AwesomeLearningAPR.

Khái niệm CCS: •Phần mềm và kỹ thuật của nó →Kiểm thử và gỡ lỗi phần mềm; Kiểm thử và gỡ lỗi phần mềm.

Từ khóa và Cụm từ bổ sung: Sửa chữa Chương trình Tự động, Học Sâu, Dịch Máy Neural, AI và Kỹ thuật Phần mềm

Định dạng Tham khảo ACM:
Quanjun Zhang, Chunrong Fang, Yuxiang Ma, Weisong Sun, và Zhenyu Chen. 2023. Một Khảo sát về Sửa chữa Chương trình Tự động dựa trên Học máy. ACM Trans. Softw. Eng. Methodol. 0, 0, Bài viết 1 (2023), 69 trang. https://doi.org/10.1145/nnnnnnn.nnnnnnn

∗Chunrong Fang và Zhenyu Chen là các tác giả liên hệ.

Địa chỉ tác giả: Quanjun Zhang, quanjun.zhang@smail.nju.edu.cn, Phòng thí nghiệm Trọng điểm Nhà nước về Công nghệ Phần mềm Mới, Đại học Nam Kinh, Nam Kinh, Giang Tô, Trung Quốc, 210093; Chunrong Fang, fangchunrong@nju.edu.cn, Phòng thí nghiệm Trọng điểm Nhà nước về Công nghệ Phần mềm Mới, Đại học Nam Kinh, Nam Kinh, Giang Tô, Trung Quốc, 210093; Yuxiang Ma, 502022320009@smail.nju.edu.cn, Phòng thí nghiệm Trọng điểm Nhà nước về Công nghệ Phần mềm Mới, Đại học Nam Kinh, Nam Kinh, Giang Tô, Trung Quốc, 210093; Weisong Sun, weisongsun@smail.nju.edu.cn, Phòng thí nghiệm Trọng điểm Nhà nước về Công nghệ Phần mềm Mới, Đại học Nam Kinh, Nam Kinh, Giang Tô, Trung Quốc, 210093; Zhenyu Chen, zychen@nju.edu.cn, Phòng thí nghiệm Trọng điểm Nhà nước về Công nghệ Phần mềm Mới, Đại học Nam Kinh, Nam Kinh, Giang Tô, Trung Quốc, 210093.

Quyền được cấp để tạo các bản sao kỹ thuật số hoặc bằng giấy của toàn bộ hoặc một phần tác phẩm này cho mục đích sử dụng cá nhân hoặc lớp học mà không tính phí với điều kiện các bản sao không được tạo ra hoặc phân phối để kiếm lợi nhuận hoặc lợi thế thương mại và các bản sao phải ghi rõ thông báo này và trích dẫn đầy đủ trên trang đầu. Bản quyền cho các thành phần của tác phẩm này thuộc sở hữu của các bên khác ngoài ACM phải được tôn trọng. Trích dẫn có ghi công là được phép. Để sao chép khác, hoặc tái xuất bản, để đăng trên máy chủ hoặc để phân phối lại cho danh sách, cần có sự cho phép cụ thể trước và/hoặc một khoản phí. Yêu cầu quyền từ permissions@acm.org.

©2022 Hiệp hội Máy tính.
1049-331X/2023/0-ART1 $15.00
https://doi.org/10.1145/nnnnnnn.nnnnnnn

ACM Trans. Softw. Eng. Methodol., Vol. 0, No. 0, Bài viết 1. Ngày xuất bản: 2023.arXiv:2301.03270v3 [cs.SE] 1 Nov 2023

--- TRANG 2 ---
1:2 Quanjun Zhang, Chunrong Fang, Yuxiang Ma, Weisong Sun, và Zhenyu Chen

1 GIỚI THIỆU

Các hệ thống phần mềm hiện đại liên tục phát triển với những lỗi không thể tránh khỏi do việc loại bỏ các tính năng cũ, thêm các chức năng mới và tái cấu trúc kiến trúc hệ thống [194]. Những lỗi không thể tránh khỏi này đã được công nhận rộng rãi là cực kỳ tốn kém và mang tính phá hoại, chẳng hạn như tốn hàng tỷ đô la hàng năm trên toàn thế giới [20,202]. Số lượng lỗi được ghi nhận tăng với tốc độ khủng khiếp do quy mô và độ phức tạp ngày càng tăng của các hệ thống phần mềm [53]. Việc sửa chữa các lỗi đã phát hiện một cách thủ công trong quá trình phát triển và bảo trì phần mềm là một nhiệm vụ cực kỳ tốn thời gian và dễ xảy ra lỗi. Ví dụ, các báo cáo trước đây cho thấy việc gỡ lỗi phần mềm chiếm hơn 50% chi phí trong phát triển phần mềm [21]. Xem xét tương lai đầy hứa hẹn trong việc giảm bớt nỗ lực sửa chữa thủ công, sửa chữa chương trình tự động (APR), nhằm mục đích tự động sửa lỗi phần mềm mà không cần can thiệp của con người, đã trở thành một lĩnh vực rất tích cực trong học thuật và công nghiệp.

Là một lĩnh vực nghiên cứu đầy hứa hẹn, APR đã được nghiên cứu rộng rãi trong tài liệu và đã đạt được tiến bộ đáng kể về số lượng lỗi được sửa chữa đúng cách [135]. Một đánh giá APR sống [136] báo cáo rằng ngày càng nhiều bài báo được xuất bản mỗi năm với nhiều công cụ APR được triển khai tinh xảo khác nhau được phát hành. Trong thập kỷ qua, các nhà nghiên cứu đã đề xuất nhiều kỹ thuật APR khác nhau để tạo ra các bản vá [108] [13] [195], bao gồm dựa trên heuristic, dựa trên ràng buộc và dựa trên mẫu. Trong số các kỹ thuật truyền thống này, APR dựa trên mẫu sử dụng các mẫu sửa chữa được định nghĩa trước để chuyển đổi các đoạn mã lỗi thành các đoạn mã đúng và đã được công nhận rộng rãi là hiện đại [107,208,209]. Tuy nhiên, các kỹ thuật dựa trên mẫu hiện có chủ yếu dựa vào các mẫu sửa chữa được thiết kế thủ công, điều này đòi hỏi nỗ lực lớn và kiến thức chuyên môn để tạo ra trong thực tế. Bên cạnh đó, các mẫu này thường được thiết kế cho các loại lỗi cụ thể (ví dụ: ngoại lệ con trỏ null) và do đó rất khó áp dụng cho các lỗi chưa từng thấy, hạn chế hiệu quả sửa chữa.

Gần đây, được truyền cảm hứng từ sự tiến bộ của học sâu (DL), nhiều kỹ thuật APR dựa trên học máy đã được đề xuất để học các mẫu sửa lỗi một cách tự động từ các kho mã nguồn lớn [184]. So với các kỹ thuật APR truyền thống, các kỹ thuật dựa trên học máy có thể được áp dụng cho một phạm vi rộng hơn các tình huống (ví dụ: đa ngôn ngữ [209] và nhiều khối đa dòng [28]) với các cặp đoạn mã lỗi và đoạn mã đã sửa tương ứng. Ví dụ, CIRCLE [228] có thể tạo ra các bản vá trên nhiều ngôn ngữ lập trình với các bộ dữ liệu huấn luyện đa ngôn ngữ. Các kỹ thuật dựa trên học máy này xử lý vấn đề sửa chữa chương trình như một tác vụ dịch máy neural (NMT) [73,115,208,209,228], dịch một chuỗi mã từ ngôn ngữ nguồn (tức là các đoạn mã lỗi) thành ngôn ngữ đích (tức là các đoạn mã đúng). Các mô hình sửa chữa NMT hiện có thường được xây dựng trên kiến trúc mã hóa-giải mã [187]. Bộ mã hóa trích xuất trạng thái ẩn của các đoạn mã lỗi với ngữ cảnh cần thiết, và bộ giải mã nhận trạng thái ẩn của bộ mã hóa và tạo ra các đoạn mã đúng [70,98,111]. Nhờ khả năng mạnh mẽ của DL trong việc học các mối quan hệ ẩn và phức tạp từ các kho mã khổng lồ, các kỹ thuật APR dựa trên học máy đã đạt được hiệu suất đáng kể trong vài năm qua.

Tiến bộ ấn tượng của APR dựa trên học máy đã cho thấy những lợi ích đáng kể của việc khai thác DL cho APR và tiếp tục tiết lộ tương lai đầy hứa hẹn của nó trong nghiên cứu tiếp theo. Tuy nhiên, một khối lượng lớn các nghiên cứu hiện có từ các tổ chức khác nhau (ví dụ: học thuật và công nghiệp) và các cộng đồng (ví dụ: kỹ thuật phần mềm và trí tuệ nhân tạo) khiến các nhà nghiên cứu quan tâm khó hiểu được hiện đại và cải thiện dựa trên chúng. Quan trọng hơn, so với các kỹ thuật truyền thống, các kỹ thuật dựa trên học máy phụ thuộc rất nhiều vào chất lượng của các kho mã và kiến trúc mô hình, đặt ra một số thách thức (ví dụ: biểu diễn mã và xếp hạng bản vá) trong việc phát triển các mô hình sửa chữa NMT trưởng thành. Ví dụ, hầu hết các kỹ thuật dựa trên học máy áp dụng các bộ dữ liệu huấn luyện khác nhau, và tồn tại nhiều chiến lược khác nhau để xử lý các đoạn mã (ví dụ: ngữ cảnh mã, trừu tượng hóa và tokenization). Bên cạnh đó, các nhà nghiên cứu thiết kế các biểu diễn mã khác nhau (ví dụ: chuỗi, cây và đồ thị) để trích xuất các tính năng mã, điều này đòi hỏi các kiến trúc mã hóa-giải mã tương ứng (ví dụ: RNN, LSTM và transformer) để học các mẫu chuyển đổi. Hơn nữa, các chỉ số dựa trên thực thi (ví dụ: các bản vá hợp lý và đúng) và dựa trên so khớp (ví dụ: độ chính xác và BLUE) được áp dụng trong các nghiên cứu khác nhau. Những lựa chọn thiết kế đa dạng như vậy cản trở các nhà phát triển thực hiện nghiên cứu tiếp theo theo hướng APR dựa trên học máy.

Trong bài báo này, chúng tôi tóm tắt các công trình hiện có và cung cấp một cái nhìn hồi tưởng về lĩnh vực APR dựa trên học máy sau nhiều năm phát triển. Các nhà nghiên cứu cộng đồng có thể có hiểu biết kỹ lưỡng về những ưu điểm và hạn chế của các kỹ thuật APR dựa trên học máy hiện có. Chúng tôi minh họa quy trình làm việc điển hình của APR dựa trên học máy và thảo luận về các kỹ thuật chi tiết khác nhau đã xuất hiện trong các bài báo chúng tôi thu thập. Dựa trên phân tích của chúng tôi, chúng tôi chỉ ra những thách thức hiện tại và đề xuất các hướng có thể cho nghiên cứu APR dựa trên học máy trong tương lai. Nhìn chung, công trình của chúng tôi cung cấp một đánh giá toàn diện về tiến bộ hiện tại của cộng đồng APR dựa trên học máy, cho phép các nhà nghiên cứu có được cái nhìn tổng quan về lĩnh vực đang phát triển mạnh này và tiến bộ hướng tới các thực hành tiên tiến.

Đóng góp. Tóm lại, những đóng góp chính của bài báo này như sau:

• Phương pháp Khảo sát. Chúng tôi tiến hành phân tích chi tiết 112 nghiên cứu liên quan đã sử dụng các kỹ thuật DL về xu hướng xuất bản, phân bố địa điểm xuất bản và ngôn ngữ.

• APR dựa trên Học máy. Chúng tôi mô tả khung điển hình của việc tận dụng những tiến bộ trong các kỹ thuật DL để sửa chữa lỗi phần mềm và thảo luận về các yếu tố chính, bao gồm định vị lỗi, tiền xử lý dữ liệu, tạo bản vá, xếp hạng bản vá, xác thực bản vá và tính đúng đắn của bản vá.

• Bộ dữ liệu và Chỉ số. Chúng tôi thực hiện phân tích toàn diện về các yếu tố quan trọng ảnh hưởng đến hiệu suất của các mô hình DL trong APR, bao gồm 53 bộ dữ liệu được thu thập và các chỉ số đánh giá trong hai danh mục.

• Nghiên cứu thực nghiệm. Chúng tôi trình bày chi tiết các nghiên cứu thực nghiệm hiện có được thực hiện để hiểu rõ hơn về quá trình APR dựa trên học máy và tạo điều kiện cho các nghiên cứu trong tương lai.

• Một số Thảo luận. Chúng tôi thảo luận về một số lĩnh vực quan trọng khác (ví dụ: lỗ hổng bảo mật và lỗi cú pháp) nơi các kỹ thuật APR dựa trên học máy được áp dụng, cũng như một số triển khai công nghiệp đã biết. Chúng tôi chứng minh xu hướng sử dụng các mô hình được đào tạo trước trên APR gần đây. Chúng tôi liệt kê các công cụ dựa trên học máy có sẵn và tiết lộ vấn đề khoa học mở cơ bản.

• Triển vọng và thách thức. Chúng tôi chỉ ra các thách thức nghiên cứu mở của việc sử dụng DL trong APR và cung cấp một số hướng dẫn thực tế về việc áp dụng DL cho các nghiên cứu APR dựa trên học máy trong tương lai.

So sánh với Các Khảo sát Hiện có. Gazzola et al. [53] trình bày một khảo sát để tổ chức các kỹ thuật sửa chữa được xuất bản đến tháng 1 năm 2017. Monperrus et al. [135] trình bày một thư mục các bài báo về sửa chữa hành vi và trạng thái. Không giống như các khảo sát hiện có chủ yếu bao gồm các kỹ thuật truyền thống, công trình của chúng tôi tập trung vào APR dựa trên học máy, đặc biệt là việc tích hợp các kỹ thuật DL trong giai đoạn sửa chữa (ví dụ: tạo bản vá và tính đúng đắn), lĩnh vực sửa chữa (ví dụ: lỗ hổng và lỗi cú pháp), và thách thức. Bên cạnh đó, khảo sát của chúng tôi tóm tắt các nghiên cứu hiện có đến tháng 11 năm 2022.

Tổ chức Bài báo. Phần còn lại của bài báo này được tổ chức như sau. Phần 2 trình bày phương pháp nghiên cứu về cách chúng tôi thu thập các bài báo liên quan từ một số cơ sở dữ liệu theo các từ khóa cụ thể. Phần 3 giới thiệu một số khái niệm chung gặp phải trong lĩnh vực APR dựa trên học máy. Phần 4 trình bày quy trình làm việc điển hình của APR dựa trên học máy và thảo luận chi tiết về các thành phần quan trọng của quy trình làm việc, cũng như một số phương pháp đại diện trên các lĩnh vực sửa chữa khác nhau. Phần 5 tập trung vào APR dựa trên mô hình được đào tạo trước, đây là chủ đề nóng gần đây trong cộng đồng APR dựa trên học máy. Phần 6 mở rộng thảo luận về đánh giá thực nghiệm, bao gồm các bộ dữ liệu chung, các chỉ số đánh giá tiêu chuẩn và các nghiên cứu thực nghiệm hiện có của các kỹ thuật APR dựa trên học máy. Phần 7 trình bày chi tiết một số thảo luận, bao gồm triển khai công nghiệp, APR truyền thống được trang bị các kỹ thuật dựa trên học máy, và vấn đề khoa học mở quan trọng. Phần 8 cung cấp một số hướng dẫn thực tế. Phần 9 đưa ra kết luận.

ACM Trans. Softw. Eng. Methodol., Vol. 0, No. 0, Bài viết 1. Ngày xuất bản: 2023.

--- TRANG 3 ---
Một Khảo sát về Sửa chữa Chương trình Tự động dựa trên Học máy 1:3

Google Scholar Thư viện Kỹ thuật số ACM Thư viện Kỹ thuật số IEEE Nhóm 1 từ khóa liên quan đến sửa chữa Nhóm 2 từ khóa liên quan đến DL

thảo luận và lựa chọn sửa chữa chương trình; sửa lỗi; ... sâu; học; máy; ... Tìm kiếm Tự động

lọc theo năm 342 bài báo

lọc theo số trang (loại bỏ trùng lặp) 283 bài báo

thêm các trích dẫn bị bỏ sót 112 bài báo

lọc bài báo không liên quan 87 bài báo Snowballing

Hình 1. Quy trình làm việc chung của việc thu thập bài báo

Khả năng Sẵn có. Tất cả các tạo phẩm của nghiên cứu này đều có sẵn trong kho lưu trữ công cộng sau: https://github.com/iSEngLab/AwesomeLearningAPR

2 PHƯƠNG PHÁP KHẢO SÁT

Trong phần này, chúng tôi trình bày chi tiết về phương pháp đánh giá tài liệu có hệ thống của chúng tôi theo Petersen et al. [153] và Kitchenham et al. [82].

Quy trình Tìm kiếm. Đối với khảo sát này, chúng tôi lựa chọn các bài báo bằng cách chủ yếu tìm kiếm kho lưu trữ Google Scholar, Thư viện Kỹ thuật số ACM và Thư viện Kỹ thuật số IEEE Explorer vào cuối tháng 11 năm 2022. Theo các khảo sát DL cho SE hiện có [193,220], chúng tôi chia các từ khóa tìm kiếm được sử dụng để tìm kiếm bài báo thành hai nhóm: (1) một nhóm liên quan đến APR chứa một số từ khóa thường được sử dụng liên quan đến sửa chữa chương trình; và (2) một nhóm liên quan đến DL chứa một số từ khóa liên quan đến học sâu hoặc học máy. Xem xét một số lượng đáng kể các bài báo liên quan từ cả cộng đồng SE và AI, theo Zhang et al. [230], đầu tiên chúng tôi cố gắng thu thập một số bài báo từ trang web được điều khiển bởi cộng đồng¹ và đánh giá sống về APR của Monperrus [136], sau đó kết luận một số từ thường xuyên trong tiêu đề của các bài báo này. Chiến lược tìm kiếm có thể nắm bắt được các nghiên cứu liên quan nhất trong khi đạt được hiệu quả tốt hơn so với tìm kiếm thủ công hoàn toàn. Cuối cùng, chúng tôi xác định một chuỗi tìm kiếm bao gồm một số thuật ngữ liên quan đến DL xuất hiện thường xuyên trong các bài báo APR sử dụng các kỹ thuật DL, được liệt kê như sau.

("program repair" OR "software repair" OR "automatic repair" OR "code repair" OR "bug repair" OR "bug fix" OR "code fix" OR "automatic fix" OR "patch generation" OR "fix generation" OR "code transformation" OR "code edit" OR "fix error") AND ("neural" OR "machine" OR "deep" OR "learning" OR "transformer/transformers" OR "model/models" OR "transfer" OR "supervised")

Lựa chọn Nghiên cứu. Khi các nghiên cứu có khả năng liên quan dựa trên chiến lược tìm kiếm của chúng tôi được thu thập, chúng tôi thực hiện giai đoạn lọc và loại bỏ trùng lặp để loại trừ các bài báo không phù hợp với mục tiêu nghiên cứu. Đầu tiên chúng tôi cố gắng lọc ra các bài báo trước năm 2016, xem xét rằng Long et al. [111] đề xuất nghiên cứu APR dựa trên học máy đầu tiên vào năm 2016. Sau đó chúng tôi lọc ra bất kỳ bài báo nào ít hơn 7 trang và các bài báo trùng lặp, kết quả là tổng cộng 283 bài báo. Sau đó chúng tôi xem xét kỹ lưỡng các bài báo còn lại một cách thủ công để quyết định xem chúng có liên quan đến lĩnh vực APR dựa trên học máy hay không. Chúng tôi đã thu được 87 bài báo cuối cùng. Để đảm bảo rằng các bài báo được thu thập càng toàn diện càng tốt, chúng tôi tiếp tục thực hiện thực hành phổ biến snowballing để bao gồm thủ công các bài báo liên quan khác bị bỏ sót trong quá trình tìm kiếm của chúng tôi [200]. Cụ thể, chúng tôi xem xét mọi tham chiếu trong các bài báo được thu thập và xác định xem có tham chiếu nào trong số đó liên quan đến nghiên cứu của chúng tôi hay không. Ví dụ, tiêu đề của SampleFix [60] không chứa bất kỳ từ khóa nào chúng tôi đề cập ở trên trong hai nhóm, nhưng đây là một phương pháp APR nhắm mục tiêu lỗi cú pháp, vì vậy chúng tôi đưa nó vào khảo sát của mình. Chúng tôi đã phân tích thủ công tất cả các bài báo được trích dẫn này bằng cách quét các bài báo và cuối cùng thu thập được 112 bài báo trong khảo sát của chúng tôi. Quy trình làm việc chung về cách chúng tôi thu thập các bài báo được thể hiện trong Hình 1.

[Tiếp tục với biểu đồ cho thấy số lượng bài báo theo năm từ 2016-2022 và phân bố ngôn ngữ lập trình]

Quan sát Xu hướng. Hình 2 cho thấy các bài báo được thu thập từ năm 2016 đến 2022. Có thể thấy rằng số lượng bài báo APR dựa trên học máy đã tăng nhanh chóng kể từ năm 2020, cho thấy nhiều nhà nghiên cứu hơn đang xem xét DL như một giải pháp đầy hứa hẹn để sửa lỗi phần mềm. Một lý do đằng sau hiện tượng này là các kỹ thuật APR truyền thống đã đạt đến một ngưỡng [115,218] và các nhà nghiên cứu hy vọng tìm ra một cách hoàn toàn mới để giải quyết vấn đề. Một lý do không thể bỏ qua khác là DL đã chứng minh tiềm năng của nó trong nhiều tác vụ khác nhau, bao gồm dịch ngôn ngữ tự nhiên, điều này tương tự như sửa lỗi ở một mức độ nào đó. Hình 3 trình bày tổng quan về các ngôn ngữ lập trình được nhắm mục tiêu bởi các kỹ thuật APR dựa trên học máy trong khảo sát của chúng tôi. Chúng ta có thể thấy Java chiếm một tỷ lệ lớn, điều này có thể hiểu được vì Java được áp dụng rộng rãi trong các hệ thống phần mềm hiện đại ngày nay và là ngôn ngữ được nhắm mục tiêu nhiều nhất trong các bộ dữ liệu trưởng thành hiện có (ví dụ: Defects4J [76]). Chúng tôi cũng thấy rằng các bài báo được thu thập bao gồm một loạt các ngôn ngữ lập trình (tức là Java, JavaScript, Python, C và C++). Ví dụ, tồn tại một số bài báo [115,228] liên quan đến sửa chữa nhiều ngôn ngữ lập trình. Lý do có thể là các kỹ thuật APR dựa trên học máy thường coi APR như một vấn đề NMT, độc lập với các ngôn ngữ lập trình.

3 KIẾN THỨC NỀN TẢNG VÀ KHÁI NIỆM

Trong phần này, chúng tôi sẽ giới thiệu một số thông tin nền tảng và các khái niệm chung trong lĩnh vực APR dựa trên học máy.

3.1 Sửa chữa Chương trình Tự động

Mục tiêu chính của các kỹ thuật APR là xác định và sửa lỗi phần mềm mà không cần can thiệp của con người. Trong quá trình phát triển và bảo trì phần mềm, sau khi một chức năng được thiết kế được triển khai, các nhà phát triển thường viết một số bộ kiểm thử (ví dụ: các trường hợp kiểm thử Junit) để kiểm tra chức năng. Nếu tồn tại các bộ kiểm thử khiến chức năng thất bại, các nhà phát triển áp dụng các bộ kiểm thử thất bại để phân tích các triệu chứng và nguyên nhân gốc rễ của lỗi, và cố gắng sửa lỗi bằng cách thực hiện một số thay đổi đối với các phần tử mã đáng ngờ. Một cách tổng quát hơn, theo Nilizadeh et al. [144], chúng ta có thể đưa ra định nghĩa sau.

Định nghĩa 3.1. ✍APR: Cho một chương trình lỗi 𝑃, đặc tả tương ứng 𝑆 mà 𝑃 không thỏa mãn, các toán tử chuyển đổi 𝑂 và khoảng cách chỉnh sửa tối đa được phép 𝜖, APR có thể được hình thức hóa như một hàm 𝐴𝑃𝑅(𝑃,𝑆,𝑂,𝜖). 𝑃𝑇 là tập hợp tất cả các biến thể chương trình có thể có của nó bằng cách liệt kê tất cả các toán tử 𝑂 trên 𝑃. Vấn đề của APR là tìm một biến thể chương trình 𝑃′(𝑃′∈𝑃𝑇) thỏa mãn 𝑆 và các thay đổi thỏa mãn 𝜖(𝑑𝑖𝑠𝑡𝑎𝑛𝑐𝑒(𝑃,𝑃′)≤𝜖).

Đặc tả 𝑆 biểu thị một mối quan hệ giữa đầu vào và đầu ra và hầu hết các kỹ thuật APR thường áp dụng một bộ kiểm thử như một đặc tả. Nói cách khác, APR nhằm mục đích tìm ra một thay đổi tối thiểu đối với 𝑃 để vượt qua tất cả các bộ kiểm thử có sẵn. Khoảng cách chỉnh sửa tối đa 𝜖 giới hạn phạm vi thay đổi dựa trên giả thuyết lập trình viên có năng lực [147], giả định rằng các lập trình viên có kinh nghiệm có khả năng viết các chương trình gần như đúng và hầu hết các lỗi có thể được sửa bằng các thay đổi nhỏ. Ví dụ, nếu 𝜖 được đặt thành 0, 𝐴𝑃𝑅(𝑃,𝑆,𝑂, 0) trở thành một vấn đề xác thực chương trình nhằm mục đích xác định xem 𝑃 có thỏa mãn 𝑆 hay không. Ngược lại, nếu 𝜖 được đặt thành ∞, 𝐴𝑃𝑅(𝑃,𝑆,𝑂,𝜖) trở thành một vấn đề tổng hợp chương trình nhằm mục đích tổng hợp một chương trình để thỏa mãn 𝑆.

Quy trình làm việc điển hình của các kỹ thuật APR được minh họa trong Hình 4, thường bao gồm ba phần: (1) các kỹ thuật định vị lỗi sẵn có được áp dụng để phác thảo các đoạn mã lỗi [1] [9]; (2) các đoạn này được sửa đổi dựa trên một tập hợp các quy tắc hoặc mẫu chuyển đổi để tạo ra các biến thể chương trình mới khác nhau (tức là các bản vá ứng viên); (3) bộ kiểm thử gốc được áp dụng như oracle để xác minh tất cả các bản vá ứng viên. Cụ thể, một bản vá ứng viên vượt qua bộ kiểm thử gốc được gọi là bản vá hợp lý. Một bản vá hợp lý, cũng tương đương về mặt ngữ nghĩa với bản vá của nhà phát triển, biểu thị một bản vá đúng.

Tuy nhiên, các đặc tả như vậy (tức là bộ kiểm thử) vốn dĩ không hoàn chỉnh vì các chương trình có miền vô hạn. Việc đảm bảo tính đúng đắn của các bản vá hợp lý (tức là vấn đề overfitting) do các bộ kiểm thử yếu trong thực tế là một thách thức cơ bản. Các nghiên cứu hiện có đã chứng minh rằng việc xác định thủ công các bản vá overfitting tốn thời gian và có thể gây hại đến hiệu suất gỡ lỗi của các nhà phát triển [170,177]. Vấn đề overfitting là một thách thức quan trọng trong cả kỹ thuật APR truyền thống và dựa trên học máy. Chúng tôi sẽ thảo luận về vấn đề này trong Phần 4.7.

3.1.1 Kỹ thuật Tạo Bản vá. Trong tài liệu, nhiều kỹ thuật APR truyền thống đã được đề xuất để tạo bản vá từ các khía cạnh khác nhau, có thể được phân loại thành ba lớp. Chúng tôi liệt kê chúng như sau.

• Kỹ thuật sửa chữa dựa trên heuristic. Các kỹ thuật này thường áp dụng các chiến lược heuristic (ví dụ: thuật toán di truyền) để xây dựng không gian tìm kiếm từ các bản vá trước đó và tạo ra các bản vá hợp lệ bằng cách khám phá không gian tìm kiếm [93,123,229]. Ví dụ, SimFix [70] xây dựng một không gian tìm kiếm trừu tượng từ các bản vá hiện có và một không gian tìm kiếm cụ thể từ các đoạn mã tương tự trong dự án lỗi. SimFix sau đó sử dụng giao điểm của hai không gian tìm kiếm trên để tìm kiếm bản vá cuối cùng bằng heuristic cơ bản (ví dụ: khoảng cách cú pháp).

• Kỹ thuật sửa chữa dựa trên ràng buộc. Các kỹ thuật này thường tập trung vào một biểu thức điều kiện duy nhất và sử dụng các kỹ thuật giải ràng buộc hoặc tổng hợp tiên tiến để tổng hợp các bản vá ứng viên [44,124,129]. Ví dụ, Nopol [215] dựa vào một bộ giải SMT để giải quyết vấn đề tổng hợp điều kiện sau khi xác định các vị trí tiềm năng của các bản vá bằng định vị lỗi angelic và thu thập các dấu vết thực thi kiểm thử của chương trình. Bên cạnh đó, Cardumen [124] tổng hợp các bản vá ứng viên ở cấp độ biểu thức với các mẫu được khai thác từ chương trình đang sửa chữa để thay thế biểu thức lỗi.

• Kỹ thuật sửa chữa dựa trên mẫu. Các kỹ thuật này thường thiết kế một số mẫu sửa chữa bằng cách phân tích thủ công các lỗi phần mềm cụ thể và tạo bản vá bằng cách áp dụng các mẫu như vậy cho các đoạn mã lỗi [85,106,107]. Ví dụ, TBar [107] xem xét lại hiệu quả của các kỹ thuật APR dựa trên mẫu bằng cách tóm tắt có hệ thống nhiều mẫu sửa chữa từ tài liệu.

Ngoài các kỹ thuật APR truyền thống ở trên, các nhà nghiên cứu cố gắng sửa lỗi phần mềm được làm phong phú bởi các kỹ thuật DL do các kho mã nguồn mở quy mô lớn [184,242]. Các kỹ thuật dựa trên học máy như vậy đã chứng minh kết quả đầy hứa hẹn và đang nhận được sự chú ý ngày càng tăng gần đây, đây là trọng tâm của công trình chúng tôi (được giới thiệu trong Phần 3.2).

3.2 Dịch Máy Neural

Sequence-to-sequence (Seq2Seq) là một khung DL tiên tiến được sử dụng rộng rãi trong một số tác vụ NLP (ví dụ: dịch máy [74] và tóm tắt văn bản [138]). Một mô hình Seq2Seq thường bao gồm hai thành phần (tức là một bộ mã hóa và một bộ giải mã) để học ánh xạ giữa hai chuỗi. Lấy cảm hứng từ thành công của các mô hình Seq2Seq trong các tác vụ tạo văn bản, sửa chữa chương trình có thể được hình thức hóa như một tác vụ NMT. Vấn đề APR dựa trên học máy được định nghĩa chính thức như sau:

Định nghĩa 3.2. ✍APR dựa trên Học máy: Cho một đoạn mã lỗi 𝑋𝑖=[𝑥1,...,𝑥 𝑛] với 𝑛 token mã và một đoạn mã đã sửa 𝑌𝑖=[𝑦1,...,𝑦 𝑚] với 𝑚 token mã, vấn đề sửa chữa chương trình được hình thức hóa để tối đa hóa xác suất có điều kiện (tức là khả năng 𝑌 là bản sửa chữa đúng): 𝑃(𝑌|𝑋)=Π𝑚
𝑖=1𝑃(𝑦𝑖|𝑦1,...,𝑦 𝑖−1;𝑥1,...,𝑥 𝑛).

Nói cách khác, mục tiêu của một mô hình sửa chữa NMT là học ánh xạ giữa một đoạn mã lỗi 𝑋 và một đoạn mã đã sửa 𝑌. Sau đó các tham số của mô hình được cập nhật bằng cách sử dụng bộ dữ liệu huấn luyện, để tối ưu hóa ánh xạ (tức là tối đa hóa xác suất có điều kiện 𝑃).

Trong tài liệu, kiến trúc mạng neural hồi quy (RNN) được sử dụng rộng rãi trong các kỹ thuật APR dựa trên học máy hiện có [27,58,183,184]. Bên cạnh đó, các nhà nghiên cứu sử dụng kiến trúc bộ nhớ ngắn hạn dài (LSTM) để nắm bắt các phụ thuộc tầm xa giữa các chuỗi mã [23,130]. Gần đây, như một biến thể của mô hình Seq2Seq, Transformer [187] đã được coi là kiến trúc sửa chữa NMT hiện đại do cơ chế tự chú ý [28, 31, 51].

4 APR DỰRA TRÊN HỌC MÁY

Trong phần này, chúng tôi sẽ thảo luận về quy trình làm việc của các công cụ APR dựa trên học máy và giới thiệu một số kỹ thuật APR dựa trên học máy phổ biến với một số ví dụ.

4.1 Quy trình Làm việc Tổng thể

Hình 5 minh họa khung điển hình của các kỹ thuật APR dựa trên học máy hiện có. Khung này có thể được chia thành sáu giai đoạn một cách tổng quát: định vị lỗi, tiền xử lý dữ liệu, mã hóa đầu vào, giải mã đầu ra, xếp hạng bản vá, xác thực bản vá và đánh giá tính đúng đắn của bản vá. Bây giờ chúng tôi thảo luận chi tiết các giai đoạn như sau.

① Trong giai đoạn định vị lỗi, một chương trình lỗi được cho trước làm đầu vào và một danh sách các phần tử mã đáng ngờ (ví dụ: câu lệnh hoặc phương thức) được trả về [204], được trình bày chi tiết trong Phần 4.2.

② Trong giai đoạn tiền xử lý dữ liệu, một đoạn mã lỗi phần mềm được cho trước (ví dụ: câu lệnh lỗi) làm đầu vào và các token mã đã được xử lý được trả về. Theo các nghiên cứu APR dựa trên học máy hiện có [28,31], thường tồn tại ba cách tiềm năng để tiền xử lý mã lỗi: ngữ cảnh mã, trừu tượng hóa và tokenization. Đầu tiên, thông tin ngữ cảnh mã đề cập đến các dòng không lỗi khác có liên quan trong chương trình lỗi [139]. Công trình trước đây đã chứng minh rằng các mô hình sửa chữa dựa trên NMT tiết lộ các thay đổi mã đa dạng để sửa lỗi dưới các ngữ cảnh khác nhau [27]. Thứ hai, trừu tượng hóa mã đổi tên một số từ đặc biệt (ví dụ: chuỗi và số literal) thành một tập hợp các token được định nghĩa trước, điều này đã được chứng minh là một phương pháp hiệu quả trong việc giảm kích thước từ vựng [184]. Thứ ba, tokenization mã chia mã nguồn thành các từ hoặc từ con, sau đó được chuyển đổi thành id thông qua một bảng tra cứu [51]. Những phương pháp tiền xử lý này được trình bày chi tiết trong Phần 4.3.

③ Trong giai đoạn tạo bản vá, các token mã đã được xử lý đầu tiên được đưa vào một stack word embedding để tạo ra các vector biểu diễn, có thể nắm bắt ý nghĩa ngữ nghĩa của các token mã và vị trí của chúng trong mã lỗi. Sau đó một stack encoder được triển khai để suy ra trạng thái ẩn của encoder, được truyền tiếp vào một stack decoder. Tương tự như stack encoder, một stack decoder được triển khai để nhận các trạng thái ẩn được cung cấp bởi stack encoder và các token được tạo trước đó làm đầu vào, và trả về phân phối xác suất của từ vựng. Tồn tại hai mô hình huấn luyện để học các mẫu sửa lỗi một cách tự động, tức là học không giám sát [32,184] và học tự giám sát [223,226], được trình bày chi tiết trong Phần 4.4.

④ Trong giai đoạn xếp hạng bản vá, sau khi mô hình sửa chữa dựa trên NMT được huấn luyện tốt, một chiến lược xếp hạng (ví dụ: beam search) được tận dụng để ưu tiên các bản vá ứng viên như kết quả dự đoán dựa trên phân phối xác suất của từ vựng [170]. Cụ thể, beam search [7,27,228] là một thực hành phổ biến để chọn ra một số bản vá ứng viên có điểm số cao nhất bằng cách xếp hạng lặp đi lặp lại các token có khả năng top-𝑘 dựa trên điểm số khả năng ước tính của chúng, được trình bày chi tiết trong Phần 4.5.

⑤ Trong giai đoạn xác thực bản vá, các bản vá ứng viên được tạo ra sau đó được xác minh bởi đặc tả chương trình có sẵn, chẳng hạn như bộ kiểm thử chức năng hoặc công cụ phân tích tĩnh [14], được trình bày chi tiết trong Phần 4.6.

⑥ Trong giai đoạn đánh giá tính đúng đắn của bản vá, các bản vá hợp lý (tức là vượt qua đặc tả hiện có) được đánh giá để dự đoán tính đúng đắn của chúng (tức là liệu các bản vá hợp lý có bị overfitting hay không) [195], cuối cùng được kiểm tra thủ công bởi các nhà phát triển để triển khai trong pipeline phần mềm, được trình bày chi tiết trong Phần 4.7.

4.2 Định vị Lỗi

Định vị lỗi nhằm mục đích chẩn đoán các phần tử chương trình lỗi (ví dụ: câu lệnh và phương thức) mà không cần can thiệp của con người và đã được nghiên cứu rộng rãi để tạo điều kiện cho quá trình sửa chữa chương trình [204]. Là một bước khởi đầu quan trọng trong pipeline APR dựa trên học máy, định vị lỗi cung cấp cho mô hình sửa chữa thông tin về vị trí lỗi phần mềm và ảnh hưởng trực tiếp đến hiệu suất của mô hình sửa chữa. Ví dụ, độ chính xác sửa chữa dưới định vị lỗi bình thường thường thấp hơn so với hoàn cảnh dưới định vị lỗi hoàn hảo.

Trong tài liệu, các kỹ thuật định vị lỗi thường tận dụng nhiều thông tin phân tích tĩnh hoặc thực thi động để tính toán điểm số nghi ngờ (tức là xác suất bị lỗi) cho mỗi phần tử chương trình. Các phần tử chương trình sau đó được xếp hạng theo thứ tự giảm dần của điểm số nghi ngờ, dựa trên đó các kỹ thuật APR có thể được áp dụng tiếp. Các nhà nghiên cứu đã đề xuất nhiều kỹ thuật định vị lỗi khác nhau, chẳng hạn như dựa trên phổ [152,233], dựa trên đột biến [96,148], dựa trên cắt lát [12,120] và dựa trên học máy [97,112]. Trong số đó, định vị lỗi dựa trên phổ (SBFL) đã được sử dụng rộng rãi như một cơ chế chung để định vị các câu lệnh có khả năng bị lỗi trong tài liệu APR.

4.2.1 Kỹ thuật Định vị. Tương tự như các kỹ thuật APR truyền thống, một số kỹ thuật APR dựa trên học máy dựa vào các phương pháp định vị lỗi SBFL hiện có để định vị lỗi đã tiết lộ. Ví dụ, DLFix [98] áp dụng thuật toán Ochiai để xác định một dòng lỗi và trích xuất tất cả các nút AST (bao gồm cả các nút trung gian) liên quan đến dòng lỗi đó như một cây con được thay thế để tạo bản vá. Recoder [242] cũng giả định rằng vị trí lỗi của một lỗi không được biết đến với các công cụ APR và sử dụng thuật toán Ochiai với GZoltar [162], được sử dụng rộng rãi trong các công cụ APR hiện có, chẳng hạn như RewardRepair [227] và AlphaRepair [209]. Các kỹ thuật SBFL như vậy khai thác thông tin thời gian chạy để nhận biết các phần tử chương trình có khả năng bị lỗi khi chương trình lỗi được thực thi bởi bộ kiểm thử có sẵn. Insight quan trọng là (1) các phần tử chương trình được thực thi bởi nhiều bộ kiểm thử thất bại và ít bộ kiểm thử vượt qua có khả năng bị lỗi; và (2) các phần tử chương trình được thực thi bởi nhiều bộ kiểm thử vượt qua và ít bộ kiểm thử thất bại có khả năng đúng. Cụ thể, SBFL tạo ra một danh sách các phần tử chương trình được xếp hạng theo khả năng bị lỗi dựa trên phân tích các thực thể chương trình được bao phủ bởi các kiểm thử vượt qua và thất bại (ví dụ: Ochiai và Tarantula [105]).

Tuy nhiên, Liu et al. [105] đã chứng minh rằng các kỹ thuật định vị lỗi có thể gây ra một bias đáng kể trong việc đánh giá các kỹ thuật APR. Phần lớn các kỹ thuật APR dựa trên học máy xem xét việc sửa chữa lỗi phần mềm dưới các kỹ thuật định vị lỗi dựa trên hoàn hảo. Các kỹ thuật định vị lỗi dựa trên hoàn hảo giả định rằng vị trí thực sự của lỗi được biết. Do đó, định vị lỗi dựa trên hoàn hảo có thể cung cấp một đánh giá công bằng về các kỹ thuật APR và việc đánh giá độc lập với các kỹ thuật định vị. Ví dụ, CoCoNut [115] kiểm tra thủ công các cặp sửa lỗi trong benchmark Defects4J và trích xuất các câu lệnh đã thay đổi như đầu vào cho mô hình sửa chữa. Tiếp theo, các kỹ thuật APR dựa trên học máy gần đây áp dụng phương pháp xử lý tương tự hoặc tương tự để thực hiện định vị hoàn hảo, chẳng hạn như CIRCLE [228], CURE [73], SelfAPR [226] và AlphaRepair [209].

Bên cạnh đó, tồn tại một số kỹ thuật cố gắng thực hiện định vị lỗi một cách độc lập. Ví dụ, DeepFix [58] đề xuất một phương pháp từ đầu đến cuối trong đó mạng báo cáo một danh sách xếp hạng các dòng có khả năng lỗi với cơ chế beam search. Tương tự, Prophet [111] thiết kế một thuật toán định vị lỗi để trả về một danh sách xếp hạng các dòng ứng viên chương trình để sửa đổi bằng cách phân tích các dấu vết thực thi động của bộ kiểm thử. Szalontai et al. [172] đầu tiên định vị các đoạn mã không thành ngữ bằng mạng LSTM và dự đoán mẫu không thành ngữ bằng mạng neural feed-forward, được sửa bằng một lựa chọn thay thế chất lượng cao. Gần đây, Meng et al. [130] xây dựng một kỹ thuật định vị lỗi mới dựa trên các tính năng ngữ nghĩa sâu và kiến thức được chuyển giao, sau đó được đưa vào một mô hình ưu tiên mẫu sửa chữa và một kỹ thuật APR dựa trên mẫu TBar [107].

4.2.2 Granularity Định vị. Các kỹ thuật APR xem xét các phần tử chương trình ở các granularity khác nhau, do đó xác định phạm vi của định vị lỗi. Nói cách khác, APR và định vị lỗi thường hoạt động ở cùng mức granularity. Ví dụ, nếu các kỹ thuật APR tập trung vào việc sửa chữa các câu lệnh lỗi (hoặc phương thức), định vị lỗi cũng hoạt động ở mức câu lệnh chương trình (hoặc phương thức). Trong tài liệu, phần lớn các kỹ thuật định vị lỗi được áp dụng trong các kỹ thuật APR dựa trên học máy thường ghi lại dòng của một đoạn mã lỗi [73,98,99,115,228,242]. Cũng tồn tại ít công trình xem xét granularity khác. Ví dụ, Tufano et al. [184] áp dụng mô hình sửa chữa dựa trên NMT để học việc dịch từ mã lỗi sang mã đã sửa ở mức phương thức.

✎Tóm tắt ▶ Là một bước tiên quyết trong quy trình làm việc APR dựa trên học máy, định vị lỗi có tác động đáng kể đến hiệu suất của việc tạo bản vá, không thể tạo ra bản vá đúng với phần tử mã đáng ngờ sai. Hầu hết các kỹ thuật APR dựa trên học máy tuân theo thực hành phổ biến trong lĩnh vực APR truyền thống để tạo bản vá bằng cách tích hợp các kỹ thuật định vị lỗi dựa trên phổ. Cũng có một số kỹ thuật sửa chữa bắt đầu sử dụng định vị hoàn hảo (tức là phần tử mã lỗi ground-truth), để tránh nhiễu được giới thiệu bởi các kỹ thuật định vị lỗi sẵn có. Bên cạnh đó, nhờ khả năng hiểu mã của các mô hình DL, một số kỹ thuật APR dựa trên học máy có thể tạo bản vá với định vị lỗi thô (ví dụ: chỉ phương thức lỗi được cung cấp). ◀

4.3 Tiền xử lý Dữ liệu

Giai đoạn tiền xử lý dữ liệu nhằm mục đích phân tích và phân tích cú pháp các đoạn mã lỗi đã xác định, sau đó được truyền vào các mạng neural để huấn luyện và suy luận. Trong giai đoạn tiền xử lý dữ liệu, một đoạn mã lỗi phần mềm được cho trước (ví dụ: một hàm lỗi) làm đầu vào và các token mã đã được xử lý được trả về. Theo các nghiên cứu sửa chữa dựa trên học máy hiện có [28,31], giai đoạn tiền xử lý dữ liệu thường bao gồm ba phần: ngữ cảnh mã, trừu tượng hóa mã và tokenization mã.

4.3.1 Ngữ cảnh Mã. Ngữ cảnh mã thường đề cập đến các câu lệnh đúng khác xung quanh các dòng lỗi. Trong tình huống sửa chữa thủ công, ngữ cảnh của mã lỗi đóng vai trò quan trọng trong việc hiểu hành vi lỗi và lý luận về các bản sửa chữa tiềm năng. Các nhà phát triển thường xác định các dòng lỗi, sau đó phân tích cách chúng tương tác với phần còn lại của việc thực thi phương thức, và quan sát ngữ cảnh (ví dụ: biến và các phương thức khác) để đưa ra bản sửa chữa có thể và chọn một số token từ ngữ cảnh để tạo ra dòng đã sửa [83]. Trong APR dựa trên học máy, mô hình NMT bắt chước quá trình này bằng cách trích xuất ngữ cảnh mã và dòng lỗi thành một biểu diễn mã nhất định để bảo tồn ngữ cảnh cần thiết cho phép mô hình dự đoán các bản sửa chữa có thể.

Các kỹ thuật APR dựa trên học máy hiện có thường xem xét mã nguồn xung quanh có liên quan đến câu lệnh lỗi như ngữ cảnh. Các kỹ thuật này thường sử dụng ngữ cảnh theo nhiều cách khác nhau, chẳng hạn như trích xuất mã gần câu lệnh lỗi trong phương thức lỗi, lớp và thậm chí file. Một mặt, ngữ cảnh rộng chứa nhiều thành phần sửa chữa cần thiết, trong khi kích thước từ vựng lớn như vậy gây ra nhiễu ảnh hưởng tiêu cực đến hiệu suất sửa chữa của mô hình NMT do vấn đề phụ thuộc dài hạn phức tạp trong các mô hình NMT [27]. Cụ thể, phụ thuộc dài hạn đề cập đến tình huống mà ý nghĩa của một token phụ thuộc vào token khác cách xa nó trong một đoạn mã [187]. Kết quả là, các mô hình sửa chữa NMT thường gặp khó khăn trong việc nắm bắt các phụ thuộc dài hạn khi xử lý các token xuất hiện trên các đoạn mã dài [228]. Mặt khác, ngữ cảnh hẹp chứa quá ít thông tin để nắm bắt ngữ nghĩa thích hợp của câu lệnh lỗi và dẫn đến việc tạo bản vá không chính xác do thiếu từ vựng cần thiết. Dường như có mối quan hệ đánh đổi giữa kích thước từ vựng và kích thước ngữ cảnh. Khảo sát của chúng tôi kết luận ngữ cảnh mã của các nghiên cứu APR dựa trên học máy hiện có thành bốn granularity: không có ngữ cảnh, ngữ cảnh cấp dòng, ngữ cảnh cấp phương thức và ngữ cảnh cấp lớp.

• Không có ngữ cảnh. Granularity này đề cập đến tình huống mà các mô hình sửa chữa NMT chỉ nhận các câu lệnh lỗi mà không có bất kỳ đoạn mã bổ sung nào làm đầu vào [40,63,125]. Ví dụ, Mashhadi et al. [125] xem xét các lỗi câu lệnh đơn từ bộ dữ liệu ManySStuBs4J và trích xuất câu lệnh lỗi như phía nguồn và câu lệnh đã sửa như phía đích từ các commit sửa lỗi. Ding et al. [40] cung cấp cho các mô hình NMT một dòng chương trình duy nhất chứa một câu lệnh lỗi. Tuy nhiên, công trình trước đây chứng minh rằng việc sửa gần 90% lỗi đòi hỏi từ vựng mới liên quan đến mã lỗi. Do đó, các mô hình sửa chữa NMT gặp khó khăn trong việc nắm bắt đủ thông tin chỉ từ các câu lệnh lỗi.

• Ngữ cảnh cấp câu lệnh. Granularity này đề cập đến tình huống mà các mô hình sửa chữa NMT nhận các câu lệnh lỗi và một số câu lệnh mà mã lỗi và một số câu lệnh xung quanh đúng làm đầu vào [15,31]. Ví dụ, TFix [15] trích xuất hai câu lệnh lân cận của mã lỗi như ngữ cảnh mã. Chi et al. [31] trích xuất các thay đổi mã cấp câu lệnh bằng lệnh "git diff" và sử dụng các phụ thuộc luồng dữ liệu để nắm bắt thông tin quan trọng hơn xung quanh ngữ cảnh.

• Ngữ cảnh cấp phương thức. Granularity này đề cập đến tình huống mà các mô hình NMT nhận toàn bộ phương thức mà các câu lệnh lỗi thuộc về làm đầu vào [115,184,228]. Đây là loại ngữ cảnh được sử dụng phổ biến nhất trong tài liệu vì nó thường chứa đủ thông tin để sửa chữa lỗi, chẳng hạn như loại biến và chức năng của phương thức này. Ví dụ, Tufano et al. [183] tập trung vào ngữ cảnh cấp phương thức vì (1) chức năng cần được sửa thường được triển khai trong các phương thức chương trình; (2) các phương thức cung cấp cho mạng neural thông tin ngữ cảnh phong phú có ý nghĩa, chẳng hạn như literal và biến. Tương tự, CoCoNuT [23] trích xuất toàn bộ phương thức của mã lỗi như ngữ cảnh, được mã hóa như một đầu vào riêng biệt.

• Ngữ cảnh cấp lớp. Granularity này đề cập đến tình huống mà các mô hình sửa chữa NMT nhận lớp mà các câu lệnh lỗi thuộc về làm đầu vào. Đây là một ngữ cảnh tương đối rộng, trong khi nó có thể cung cấp cho mô hình thông tin phong phú. Ví dụ, SequenceR [27] xem xét ngữ cảnh cấp lớp và thực hiện ngữ cảnh lỗi trừu tượng từ lớp lỗi, nắm bắt ngữ cảnh quan trọng nhất xung quanh mã nguồn lỗi và giảm độ phức tạp của chuỗi đầu vào xuống 1.000 token. Hoppity [39] nhận toàn bộ file lỗi như ngữ cảnh với giới hạn độ dài 500 nút trong AST.

4.3.2 Trừu tượng hóa Mã. Trừu tượng hóa mã nhằm mục đích giới hạn số lượng từ mà các mô hình NMT cần xử lý bằng cách đổi tên các từ thô (ví dụ: tên hàm và chuỗi literal) thành một tập hợp các token được định nghĩa trước. Công trình trước đây chứng minh rằng thật khó khăn cho các mô hình NMT để học các mẫu chuyển đổi sửa lỗi do từ vựng lớn của mã nguồn [184]. Cụ thể, các mô hình NMT thường sử dụng chiến lược giải mã beam-search để xuất các ứng viên sửa chữa bằng phân phối xác suất trên tất cả các từ. Không gian tìm kiếm có thể cực kỳ lớn với nhiều từ có thể có trong mã nguồn, dẫn đến việc tạo bản vá không hiệu quả.

Trong khảo sát của chúng tôi, một số lượng đáng kể các bài báo dựa trên học máy mà chúng tôi thu thập sử dụng mã nguồn trừu tượng để giải quyết vấn đề này. Thao tác trừu tượng hóa như vậy có nghĩa là mã nguồn gốc không được đưa trực tiếp vào mô hình NMT. Nhờ mã được trừu tượng hóa, chúng ta có thể (1) giảm kích thước từ vựng đáng kể và tần suất của các token cụ thể; (2) lọc ra thông tin không liên quan và cải thiện hiệu quả của mô hình NMT. Nói chung, các yếu tố tự nhiên (ví dụ: định danh và literal) trong mã nguồn được đổi tên, trong khi thông tin ngữ nghĩa cốt lõi (ví dụ: thành ngữ) nên được bảo tồn. Ví dụ, Tufano et al. [184] đề xuất phương pháp trừu tượng hóa mã đầu tiên trong lĩnh vực APR dựa trên học máy bằng cách (1) áp dụng một lexer để tokenize mã nguồn thô như một dòng token dựa trên Another Tool for Language Recognition (ANTLR) [151]; (2) truyền dòng token vào một parser để xác định vai trò của mỗi định danh và literal (ví dụ: liệu nó đại diện cho một biến, phương thức hay tên loại); (3) thay thế mỗi định danh và literal bằng một ID duy nhất để tạo ra mã nguồn trừu tượng. Bên cạnh đó, họ trích xuất các thành ngữ (tức là các token xuất hiện nhiều lần) và giữ các token văn bản gốc của chúng trong quá trình trừu tượng hóa vì các thành ngữ như vậy chứa thông tin ngữ nghĩa có lợi. Ví dụ trừu tượng hóa mã điển hình được trình bày trong Hình 6. Tương tự, CoCoNut [115] và CURE [73] chỉ trừu tượng hóa chuỗi và số literal ngoại trừ các số thường xuyên (ví dụ: 0 và 1). DLFix [98] áp dụng một chiến lược trừu tượng hóa mới để alpha-rename các biến, để học bản sửa chữa giữa các phương thức với các tình huống tương tự trong khi có tên biến khác nhau. DLFix cũng giữ loại của biến để tránh xung đột tên tình cờ và duy trì bảng ánh xạ để khôi phục tên thực tế. Recoder [242] trừu tượng hóa các định danh không thường xuyên bằng placeholder để làm cho mạng neural học tạo ra placeholder cho các định danh này.

Mặc dù nhiều kỹ thuật APR dựa trên học máy áp dụng chiến lược trừu tượng hóa mã (chẳng hạn như Tufano et al. [184]) để giới hạn kích thước từ vựng và làm cho transformer tập trung vào việc học các mẫu chung từ các thay đổi mã khác nhau, chúng tôi vẫn thấy một số kỹ thuật sửa chữa thích mã nguồn thô [228,242] vì nó chứa thông tin ngữ nghĩa. Ví dụ, các nhà phát triển có thể đặt tên một hàm là SetHeightValue để chỉ ra rằng hàm này có thể đặt giá trị chiều cao như họ muốn. Nếu tên này được trừu tượng hóa trực tiếp thành func_1, thông tin ngữ nghĩa quan trọng sẽ bị bỏ lỡ, dẫn đến huấn luyện sửa chữa không tối ưu. Do đó, thay vì đổi tên các định danh hiếm thông qua một quá trình trừu tượng hóa tùy chỉnh, SequenceR [27] sử dụng cơ chế copy để tạo các bản vá ứng viên với một tập hợp lớn các token. Trong lập trình, các nhà phát triển không bị hạn chế bởi một từ vựng đặt (ví dụ: tiếng Anh) khi định nghĩa tên cho biến hoặc phương thức, dẫn đến một từ vựng cực kỳ lớn với nhiều token hiếm. Cơ chế copy tìm cách sao chép một số token đầu vào hiếm vào đầu ra và hiệu quả trong việc giảm kích thước từ vựng cần thiết [27]. Bên cạnh đó, Chen et al. [28] áp dụng mã nguồn thô vì họ nghĩ mã trừu tượng có thể ẩn thông tin có giá trị về biến có thể được học bởi word embedding. Một chiến lược tương tự với Chen et al. [28] cũng được triển khai trong các kỹ thuật APR dựa trên học máy khác, chẳng hạn như trong CODIT [23], CIRCLE [228] và TFix [15].

4.3.3 Tokenization Mã. Tokenization mã nhằm mục đích chia mã nguồn thành một dòng token, sau đó được chuyển đổi thành id thông qua một bảng tra cứu². Những số id này được sử dụng bởi các mô hình sửa chữa để xử lý và huấn luyện tiếp. Một phương pháp tokenization đơn giản có thể được thực hiện bằng cách chia mã nguồn thành các ký tự riêng lẻ. Khái niệm cốt lõi của tokenization cấp ký tự này là mặc dù mã nguồn có nhiều từ khác nhau, nó có số lượng ký tự hạn chế. Phương pháp này đơn giản và dẫn đến một từ vựng cực kỳ nhỏ. Tuy nhiên, nó dẫn đến một chuỗi tokenized tương đối dài với việc chia mỗi từ thành tất cả các ký tự. Quan trọng hơn, rất khó cho các mô hình sửa chữa để có được biểu diễn đầu vào có ý nghĩa vì chỉ riêng các ký tự không có ý nghĩa ngữ nghĩa. Nói chung, tồn tại hai granularity chính của tokenizer mã được sử dụng trong các kỹ thuật APR dựa trên học máy hiện có: tokenization cấp từ [51] và tokenization cấp từ con [31].

Tokenization cấp từ có nghĩa là một câu được chia theo các từ của nó (ví dụ: phân tách bằng khoảng trắng), được sử dụng rộng rãi trong các tác vụ NLP [158]. Tuy nhiên, khác với ngôn ngữ tự nhiên (ví dụ: từ điển tiếng Anh), các từ (ví dụ: tên biến và phương thức) trong ngôn ngữ lập trình có thể được tạo ra bởi các nhà phát triển một cách tùy ý. Kết quả là, có thể tồn tại một số từ hiếm không có sẵn trong từ vựng (tức là vấn đề out-of-vocabulary), dẫn đến các token không xác định trong việc tạo bản vá. Để giải quyết vấn đề này, VRepair [28] sử dụng tokenization cấp từ để tokenize mã nguồn C và cơ chế copy để xử lý vấn đề out-of-vocabulary. Tương tự, CoCoNut [115] thiết kế một thuật toán tokenization phân tách bằng khoảng trắng nhận biết mã cụ thể cho ngôn ngữ lập trình bằng cách (1) tách các toán tử khỏi biến vì chúng có thể không được phân tách bằng khoảng trắng; (2) xem xét dấu gạch dưới, chữ camel và số như các phân tách vì nhiều từ được tạo thành từ nhiều từ mà không có phân tách (ví dụ: SetHeightValue); (3) giới thiệu một token mới <CAMEL> để đánh dấu nơi xảy ra việc chia camel case để tái tạo mã nguồn từ danh sách các token được tạo ra một cách chính xác.

Tokenization cấp từ con chia các token hiếm thành nhiều từ con thay vì trực tiếp thêm token đầy đủ vào từ vựng. Bên cạnh đó, các từ thường xuyên không nên được chia thành các từ con nhỏ hơn. Loại granularity này có thể giảm kích thước từ vựng đáng kể và được sử dụng rộng rãi trong lĩnh vực APR dựa trên học máy. Về mặt kỹ thuật, tồn tại một số kỹ thuật tokenization cấp từ con, chẳng hạn như byte-pair encoding (BPE), byte-level byte-pair encoding (BBPE) [168] và SentencePiece [87], được liệt kê như sau.

(1) Tokenizer BPE thường cần được huấn luyện trên một bộ dữ liệu cho trước bằng cách (1) tận dụng một pre-tokenizer để chia bộ dữ liệu thành các từ bằng tokenization phân tách bằng khoảng trắng; (2) tạo ra một tập hợp các từ duy nhất và đếm tần suất của mỗi từ trong bộ dữ liệu; (3) xây dựng một từ vựng cơ sở với tất cả các ký hiệu xuất hiện trong tập hợp các từ duy nhất và học các quy tắc hợp nhất để tạo thành một ký hiệu mới từ hai ký hiệu của từ vựng cơ sở; (4) lặp lại quá trình trên cho đến khi từ vựng được giảm xuống một kích thước hợp lý, đây là một siêu tham số được định nghĩa trước, trước khi huấn luyện tokenizer. Ví dụ, VulRepair [51] sử dụng thuật toán BPE để huấn luyện một tokenizer từ con trên tám ngôn ngữ lập trình khác nhau (tức là Ruby, JavaScript, Go, Python, Java, PHP, C, C#) [197] và phù hợp để tokenize mã nguồn. Trong tài liệu APR dựa trên học máy, phần lớn các nghiên cứu sửa chữa áp dụng BPE như kỹ thuật tokenization, chẳng hạn như CURE [73], CoCoNut [115], SeqTrans [31]. Kết quả đã chứng minh hiệu quả của BPE trong việc giảm kích thước từ vựng và giảm thiểu vấn đề OOV bằng cách trích xuất các từ con thường xuyên nhất và hợp nhất cặp byte thường xuyên nhất một cách lặp đi lặp lại.

(2) BBPE tinh chỉnh BPE bằng cách sử dụng byte như từ vựng cơ sở, đảm bảo rằng mọi ký tự cơ sở được bao gồm với kích thước từ vựng thích hợp. Ví dụ, AlphaRepair [209] xây dựng một tokenizer dựa trên BBPE để giảm kích thước từ vựng bằng cách chia các từ dài không phổ biến thành các từ con có ý nghĩa.

(3) SentencePiece chứa khoảng trắng trong từ vựng cơ sở và sử dụng thuật toán BPE hiện có (ví dụ: BPE) để tạo ra từ vựng mong muốn bằng cách coi mã nguồn như một dòng đầu vào thô. Trong tài liệu, trước khi đưa mã nguồn vào mạng neural, một số kỹ thuật APR dựa trên học máy sử dụng SentencePiece để chia các từ thành một chuỗi các subtoken, chẳng hạn như SelfAPR [226], RewardRepair [227] và CIRCLE [228].

✎Tóm tắt ▶ Tiền xử lý dữ liệu chịu trách nhiệm xử lý các đoạn mã thành định dạng phù hợp và đưa nó vào các mô hình sửa chữa NMT để huấn luyện. Các kỹ thuật APR dựa trên học máy khác nhau sử dụng các phương pháp tiền xử lý dữ liệu đa dạng, dẫn đến các cài đặt thực nghiệm phức tạp trong tài liệu. Ví dụ, trừu tượng hóa mã liên quan đến mã thô hoặc mã trừu tượng; ngữ cảnh mã liên quan đến không có ngữ cảnh, cấp câu lệnh, cấp phương thức và cấp lớp; tokenization mã liên quan đến tokenizer BPE, BBPE và SentencePiece. Một mặt, những cấu hình khác nhau này có thể gây ra bias trong việc đánh giá các kỹ thuật APR dựa trên học máy hiện có. Mặt khác, sự kết hợp tối ưu của những cấu hình này đòi hỏi khám phá thêm, và cũng quan trọng là xem xét sự tương tác của chúng với các yếu tố khác, chẳng hạn như kiến trúc mô hình và các loại lỗi phần mềm đang được sửa. ◀

4.4 Tạo Bản vá

Trong ngữ cảnh APR dựa trên học máy, để áp dụng các mô hình sửa chữa NMT cho các ngôn ngữ lập trình bậc cao, các đoạn mã cần được chuyển đổi thành các vector embedding. Sau đó một mô hình sửa chữa NMT được xây dựng trên kiến trúc encoder-decoder [187] để học các mẫu sửa chữa một cách tự động. Cuối cùng, ánh xạ từ mã lỗi sang mã đã sửa được tối ưu hóa bằng cách cập nhật các tham số của mô hình được thiết kế. Do đó, việc xác định (1) cách biểu diễn mã nguồn (với định dạng nào) như đầu vào cho word embedding, được gọi là biểu diễn mã; và (2) cách thiết kế kiến trúc cụ thể (với mạng neural nào) như encoder-decoder để học chuyển đổi sửa chữa, được gọi là kiến trúc mô hình là rất quan trọng.

Trong tài liệu, nhiều chiến lược khác nhau đã được đề xuất để biểu diễn mã nguồn như đầu vào cho các mô hình sửa chữa NMT, có thể được phân loại thành ba lớp: biểu diễn dựa trên chuỗi, dựa trên cây và dựa trên đồ thị.

4.4.1 Tạo dựa trên Chuỗi. Các kỹ thuật này chia mã nguồn văn bản như một chuỗi token và coi APR như một tác vụ dịch token-to-token dựa trên mô hình Seq2Sep.

Biểu diễn Mã. Xem xét các dòng lỗi và ngữ cảnh, thường tồn tại bốn cách khác nhau để sắp xếp theo trình tự các token mã văn bản.

(1) Biểu diễn thô.
Tương tự như NMT, dịch một câu từ một ngôn ngữ nguồn (ví dụ: tiếng Anh) sang ngôn ngữ đích khác (ví dụ: tiếng Trung), hầu hết các kỹ thuật dựa trên chuỗi trực tiếp đưa mô hình với đoạn mã lỗi [184]. Ví dụ, Tufano et al. [184] trích xuất phương thức lỗi và huấn luyện một mô hình NMT để dịch phương thức-to-phương thức. Kích thước của đoạn mã này phụ thuộc vào lựa chọn của mã lỗi và ngữ cảnh mã. Tuy nhiên, biểu diễn thô không nhận thức được sự khác biệt giữa mã lỗi và ngữ cảnh mã, vì hai phần này được gửi vào encoder cùng nhau. Kết quả là, các quy tắc chuyển đổi có thể được áp dụng trong một số dòng đúng, hạn chế hiệu suất sửa chữa.

(2) Biểu diễn ngữ cảnh.
Biểu diễn ngữ cảnh chia mã lỗi và ngữ cảnh mã, sau đó đưa chúng vào hai encoder riêng biệt. Trong hoàn cảnh này, mô hình nhận thức được sự khác biệt giữa mã lỗi và ngữ cảnh tương ứng. Ví dụ, Lutellier et al. [73,115] cố gắng mã hóa hai phần này một cách riêng biệt và sau đó hợp nhất các vector mã hóa. Tuy nhiên, thật thách thức để hợp nhất hai vector mã hóa được tách riêng và loại bỏ khoảng cách ngữ nghĩa giữa hai encoder.

(3) Biểu diễn prompt.
Biểu diễn prompt đề cập đến định dạng đầu vào text-in-text-out và có thể nối các thành phần đầu vào khác nhau một cách hiệu quả với một số prompt có tiền tố [158]. Prompt có tiền tố là một đoạn token được chèn vào đầu vào, để tác vụ gốc có thể được hình thức hóa như một tác vụ mô hình hóa ngôn ngữ. Ví dụ, Yuan et al. [228] sử dụng mẫu prompt được thiết kế thủ công để chuyển đổi mã lỗi và ngữ cảnh tương ứng thành định dạng fill-in-the-blank thống nhất. Cụ thể, họ sử dụng "Buggy line:" và "Context:" để biểu thị mã lỗi và ngữ cảnh mã, và sau đó sử dụng "The fixed code is:" để hướng dẫn mô hình NMT tạo ra các bản vá ứng viên theo đầu vào trước đó. Cơ chế này đã được chứng minh hiệu quả trong việc bắc cầu khoảng cách giữa các tác vụ được đào tạo trước và tác vụ downstream, tạo điều kiện cho việc fine-tuning các mô hình được đào tạo trước cho APR.

(4) Biểu diễn mask.
Biểu diễn mask thay thế mã lỗi bằng các token mask và truy vấn các mô hình NMT để điền vào các mask với các dòng mã đúng. Cơ chế này xem vấn đề APR như một tác vụ cloze và thường áp dụng mô hình được đào tạo trước như mô hình truy vấn trong APR dựa trên học máy. Ví dụ, Xia et al. [209] chuyển đổi mã lỗi gốc thành một comment và tạo ra nhiều dòng mask với các mẫu. Đầu vào được biểu diễn bởi comment mã lỗi, ngữ cảnh trước mã lỗi, dòng mask và ngữ cảnh sau mã lỗi. Cụ thể, mã lỗi được mask ngẫu nhiên từ một token đến toàn bộ dòng, và các nhà nghiên cứu mong đợi tạo ra mọi bản vá có thể cho các tình huống khác nhau trong kích thước bản vá ứng viên hạn chế. So với ba chiến lược biểu diễn trên, biểu diễn mask có thể áp dụng các mô hình được đào tạo trước để dự đoán các token được mask ngẫu nhiên để thực hiện APR kiểu cloze mà không cần bất kỳ huấn luyện bổ sung nào trên bộ dữ liệu sửa lỗi.

Kiến trúc Mô hình. Các kỹ thuật dựa trên chuỗi thường coi mã nguồn như một chuỗi token và áp dụng các kiến trúc sequence-to-sequence hiện có trong lĩnh vực NLP thay vì thiết kế các kiến trúc mạng mới. Ví dụ, CoCoNut [115] áp dụng hai encoder hoàn toàn tích chập (FConv) để biểu diễn các dòng lỗi và ngữ cảnh một cách riêng biệt. Một kiến trúc encoder phổ biến là long short-term memory (LSTM), và nó giải quyết vấn đề phụ thuộc dài hạn của mô-đun RNN bằng cách giới thiệu cơ chế gate và đảm bảo rằng bộ nhớ ngắn hạn không bị bỏ qua. Ví dụ, SequenceR [27] dựa trên kiến trúc encoder-decoder LSTM với cơ chế copy. Là một loại kiến trúc DL mạnh mẽ, transformer có thể mô hình hóa các phụ thuộc toàn cục giữa đầu vào và đầu ra một cách hiệu quả nhờ cơ chế attention và đã được áp dụng trong các nghiên cứu APR hiện có, chẳng hạn như Bug-Transformer [221], SeqTrans [31] và VRepair [28].

Gần đây, việc sử dụng các mô hình được đào tạo trước đã dần thu hút sự chú ý của các nhà nghiên cứu trong cộng đồng APR dựa trên học máy. Các mô hình như vậy đầu tiên được đào tạo trước bằng huấn luyện tự giám sát trên một kho lưu trữ không nhãn quy mô lớn (ví dụ: CodeSearchNet [69]), và sau đó được chuyển giao để có lợi cho nhiều tác vụ downstream bằng cách fine-tuning trên một kho lưu trữ có nhãn hạn chế. Ví dụ, Mashhadi et al. [125] sử dụng CodeBERT, một mô hình ngôn ngữ được đào tạo trước hai phương thức cho cả ngôn ngữ tự nhiên và lập trình, để sửa lỗi Java một dòng bằng cách fine-tuning trên các bộ dữ liệu ManySStuBs4J small và large [92]. CURE [73] áp dụng một mô hình GPT được đào tạo trước để tiếp tục sửa đổi một kiến trúc APR dựa trên NMT (tức là CoCoNut). CIRCLE [228] đề xuất một khung sửa chữa chương trình dựa trên T5 được trang bị khả năng học liên tục trên nhiều ngôn ngữ. Chúng tôi sẽ thảo luận về việc áp dụng các mô hình được đào tạo trước trong Phần 5.

4.4.2 Tạo dựa trên Cây. Các kỹ thuật APR dựa trên chuỗi thường áp dụng các mô hình Seq2Seq để tạo bản vá. Tuy nhiên, các kỹ thuật này bỏ qua thông tin cấu trúc mã vì chúng được thiết kế cho NLP, khác biệt đáng kể so với ngôn ngữ lập trình với các quy tắc cú pháp và ngữ pháp nghiêm ngặt. Các bản vá được tạo ra của các kỹ thuật này có thể gặp lỗi cú pháp khiến trình biên dịch thất bại. Kết quả là, các nhà nghiên cứu gần đây đề xuất nhiều kỹ thuật tạo dựa trên cây khác nhau bằng cách xem xét cấu trúc cú pháp của mã nguồn. Các kỹ thuật này coi vấn đề APR như một tác vụ học chuyển đổi cây.

Biểu diễn Mã. Một giải pháp phổ biến là phân tích mã nguồn thành AST và áp dụng mô hình nhận biết cây để thực hiện tạo bản vá, tức là biểu diễn nhận biết cấu trúc. Ví dụ, cho một cặp phương thức sửa lỗi 𝑀𝑏 và 𝑀𝑓 đại diện cho phương thức lỗi và đã sửa, DLFix [98] đầu tiên trích xuất một AST lỗi cho 𝑀𝑏 (tức là 𝑇𝑏), một AST đã sửa cho 𝑀𝑓 (tức là 𝑇𝑓), một sub-AST lỗi (tức là 𝑇𝑠𝑏) và một sub-AST đã sửa (tức là 𝑇𝑠𝑓) giữa 𝑇𝑏 và 𝑇𝑓. DLFix sau đó áp dụng một mô hình tóm tắt hiện có để mã hóa 𝑇𝑠𝑏 như một nút đơn 𝑆𝑠𝑏. Cuối cùng, phương thức lỗi 𝑀𝑏 có thể được biểu diễn như một cây ngữ cảnh bằng cách thay thế 𝑇𝑠𝑏 trong 𝑇𝑏 bằng 𝑆𝑠𝑏 và một cây thay đổi con 𝑇𝑠𝑏. Phương thức đã sửa 𝑀𝑓 được biểu diễn theo cách tương tự.

Vì biểu diễn dựa trên cây chứa thông tin cấu trúc, không thể được triển khai trực tiếp cho các mô hình neural dựa trên chuỗi. Do đó, một chiến lược biểu diễn mã bổ sung được sử dụng để phân tích biểu diễn cây như một chuỗi duyệt tuần tự, tức là biểu diễn duyệt tuần tự. Ví dụ, Tang et al. [176] phân tích mã nguồn thành biểu diễn AST, sau đó được dịch thành một chuỗi quy tắc. Chuỗi quy tắc có thể được xử lý bởi transformer vanilla [187] trong khi nắm bắt thông tin ngữ pháp và cú pháp. Tương tự, CODIT [23] đầu tiên biểu diễn các đoạn mã như AST bằng cách (1) xác định các nút AST đã chỉnh sửa (tức là chèn, xóa và cập nhật); (2) chọn cây con tối thiểu của mỗi AST và (3) thu thập ngữ cảnh chỉnh sửa bằng cách bao gồm các nút kết nối gốc của phương thức với gốc của cây đã thay đổi. CODIT sau đó sử dụng một mô hình dựa trên cây để học các thay đổi cấu trúc dưới dạng một chuỗi ngữ pháp, cuối cùng được sử dụng để dự đoán chuỗi mã đã sửa với mô hình Seq2Seq tiêu chuẩn.

Kiến trúc Mô hình. Hầu hết các mô hình APR dựa trên NMT coi tạo bản vá như một dịch máy từ mã lỗi sang mã đã sửa. Tuy nhiên, các mô hình như vậy không thể nắm bắt thông tin của cấu trúc mã và gặp khó khăn trong việc xử lý ngữ cảnh của mã. Các encoder dựa trên cây xem xét các tính năng cấu trúc của mã nguồn, chẳng hạn như AST. Ví dụ, DLFix [98] biểu diễn mã nguồn như AST và sử dụng các mô hình RNN dựa trên cây để mã hóa cây ngữ cảnh và cây thay đổi con. Bên cạnh đó, Devlin et al. [38] mã hóa AST với LSTM hai chiều tuần tự bằng cách liệt kê một duyệt depth-first của các nút.

4.4.3 Tạo dựa trên Đồ thị. Các kỹ thuật này chuyển đổi mã nguồn thành biểu diễn đồ thị với thông tin ngữ cảnh và hình thành vấn đề APR dưới dạng học một chuỗi chuyển đổi đồ thị dựa trên các mô hình dựa trên đồ thị. Thay vì trực tiếp thao tác mã nguồn, các kỹ thuật APR dựa trên đồ thị như vậy nhằm mục đích học một chuỗi chuyển đổi trên biểu diễn đồ thị tương ứng với phiên bản được sửa chữa của mã gốc.

Biểu diễn Mã. Để nắm bắt các mối quan hệ lân cận giữa các nút AST, Recoder [242] coi AST như một đồ thị có hướng nơi các nút biểu thị các nút AST và các cạnh biểu thị mối quan hệ giữa mỗi nút và con cái cũng như anh em bên trái của nó. Bên cạnh đó, Xu et al. [214] xem xét cấu trúc ngữ cảnh bằng các phụ thuộc dữ liệu và điều khiển được nắm bắt bởi một đồ thị phụ thuộc dữ liệu (tức là DDG) và một đồ thị phụ thuộc điều khiển (tức là CDG).

Kiến trúc Mô hình. Các kỹ thuật APR dựa trên đồ thị hiện có thường thiết kế mạng neural đồ thị và các biến thể của chúng để nắm bắt biểu diễn đồ thị và thực hiện tạo bản vá. Ví dụ, Hoppity [39] áp dụng một mạng neural đồ thị có cổng (GGNN) để coi AST như một đồ thị, nơi một bản vá ứng viên được tạo ra bởi một chuỗi dự đoán, bao gồm vị trí của các nút đồ thị và các chỉnh sửa đồ thị tương ứng. Bên cạnh đó, Xu et al. [214] thiết kế một mạng neural đồ thị (GNN) để có được biểu diễn đồ thị bằng cách đầu tiên chuyển đổi DDG và CDG thành hai biểu diễn đồ thị và sau đó hợp nhất chúng.

✎Tóm tắt ▶ Là giai đoạn quan trọng nhất trong quy trình làm việc sửa chữa, phần lớn các kỹ thuật APR dựa trên học máy hiện có tập trung vào tạo bản vá. Các kỹ thuật tạo bản vá này thường có thể được chia thành hai phần: biểu diễn mã và kiến trúc mô hình tương ứng. Câu hỏi nghiên cứu chính nằm ở cách biểu diễn các đoạn mã một cách thích hợp và xác định kiến trúc mô hình có thể học hiệu quả mối quan hệ chuyển đổi giữa mã lỗi và mã đúng. Lấy cảm hứng từ NLP, các kỹ thuật sửa chữa ban đầu thường biểu diễn mã nguồn như một chuỗi token, và chuyển đổi vấn đề APR thành một tác vụ NMT trên mô hình sequence-to-sequence. Các kỹ thuật tiếp theo biểu diễn mã nguồn như biểu diễn cây hoặc đồ thị và áp dụng các mô hình nhận biết cây (ví dụ: tree-LSTM) hoặc các mô hình nhận biết đồ thị (ví dụ: GGNN) để thực hiện tạo bản vá. Tài liệu không chứng minh biểu diễn mã hoặc kiến trúc mô hình nào thể hiện hiệu suất tốt nhất. Một thí nghiệm kiểm soát sâu có thể được tiến hành để điều tra hiệu suất giữa các biểu diễn mã khác nhau và các kiến trúc mô hình tương ứng. ◀

4.5 Xếp hạng Bản vá

Việc tạo bản vá là một quá trình tìm kiếm để tìm maximum trong không gian tổ hợp. Cho độ dài đầu ra tối đa l và kích thước từ vựng V, tổng số bản vá ứng viên mà decoder có thể tạo ra đạt 𝑉𝑙, tất cả đều không thể xác thực trong thực tế. Các nhà phát triển có thể dành một lượng nỗ lực đáng kể để đánh giá tính đúng đắn của các bản vá ứng viên được tạo ra một cách thủ công. Trong tình huống như vậy, chỉ kiểm tra ít ứng viên sửa chữa hơn (ví dụ: Top-1 và Top-5) có xác suất cao là đúng thì thực tế hơn và giảm nỗ lực thủ công có giá trị. Kết quả là, một chiến lược xếp hạng bản vá rất quan trọng để đảm bảo hiệu quả suy luận của mô hình và giảm bớt gánh nặng xác thực bản vá.

Beam search là một thuật toán tìm kiếm heuristic hiệu quả để xếp hạng các đầu ra trong các ứng dụng NMT trước đây [197] và là chiến lược xếp hạng bản vá phổ biến nhất trong các nghiên cứu APR dựa trên học máy, chẳng hạn như CIRCLE [228], SelfAPR [226], RewardRepair [227] và Recoder [242]. Cụ thể, tại mỗi lần lặp, thuật toán beam search chọn 𝑘 token có khả năng nhất (tương ứng với kích thước beam 𝑘) và xếp hạng chúng theo điểm số ước tính khả năng của 𝑑 bước dự đoán tiếp theo (tương ứng với độ sâu tìm kiếm 𝑑). Việc lặp lại tiếp tục cho đến khi một điều kiện dừng được đáp ứng, chẳng hạn như đạt đến độ dài chuỗi nhất định hoặc tất cả các chuỗi kết thúc bằng một token kết thúc chuỗi. Cuối cùng, các bản vá ứng viên có điểm số cao nhất top 𝑘 được tạo ra và xếp hạng để xác thực tiếp theo trong quy trình tiếp theo của quy trình làm việc APR dựa trên học máy tổng thể. Beam search cung cấp một sự đánh đổi tuyệt vời giữa độ chính xác sửa chữa và chi phí suy luận thông qua lựa chọn linh hoạt kích thước beam.

Tuy nhiên, beam search vanilla chỉ xem xét log probability để tạo ra token tiếp theo trong khi bỏ qua thông tin liên quan đến mã, chẳng hạn như biến. Do đó, nó có thể tạo ra các bản vá có điểm số cao với biến không xác định, dẫn đến các bản vá ứng viên không thể biên dịch. Ngoài việc áp dụng trực tiếp chiến lược beam search hiện có, các nhà nghiên cứu thiết kế một số chiến lược mới để lọc ra các bản vá có xác suất thấp. Ví dụ, CURE [73] thiết kế một chiến lược beam search nhận biết mã để tạo ra các bản vá có thể biên dịch và đúng hơn dựa trên các thành phần kiểm tra định danh hợp lệ và kiểm soát độ dài. Chiến lược nhận biết mã đầu tiên thực hiện phân tích tĩnh để xác định tất cả các token hợp lệ được sử dụng để tạo chuỗi và sau đó nhắc beam search tạo ra các chuỗi có độ dài tương tự với dòng lỗi. DLFix [98] đầu tiên rút ra các bản vá ứng viên có thể bằng cách lọc phân tích chương trình và xếp hạng danh sách các bản vá có thể bằng một mô hình phân loại nhị phân dựa trên CNN. Bộ phân loại áp dụng một mô hình Word2Vec như stack encoder ở mức ký tự, tiếp theo là một stack CNN như stack học (chứa lớp Convolutional, pooling và các lớp fully connected), và một hàm softmax như stack phân loại. Sau đó DLFix xếp hạng danh sách các bản vá đã cho dựa trên khả năng của chúng là một bản vá đúng. Hơn nữa, DEAR [99] áp dụng một tập hợp các bộ lọc để xác minh ngữ nghĩa chương trình và xếp hạng các bản vá ứng viên theo cách tương tự như DLFix.

Ngoài beam search được sử dụng rộng rãi và các biến thể của chúng, cũng có một số phương pháp xếp hạng bản vá tự thiết kế như một thành phần trong việc tạo bản vá. Từ sớm năm 2016, Long et al. [111] đề xuất Prophet, huấn luyện một mô hình xếp hạng để gán xác suất cao cho các bản vá đúng dựa trên các tính năng được thiết kế (được trình bày chi tiết trong Phần 7.2). Gần đây, AlphaRepair [209] thiết kế một chiến lược xếp hạng bản vá dựa trên mô hình ngôn ngữ có mask. Cụ thể, cho một bản vá ứng viên, AlphaRepair tính điểm số ưu tiên của nó bằng cách (1) trích xuất tất cả các token được tạo ra; (2) mask chỉ một trong các token; (3) truy vấn CodeBERT để có được xác suất có điều kiện của token đó; (4) lặp lại quy trình tương tự cho tất cả các token mask trước đó khác; và (5) tính điểm số kết hợp là trung bình của các xác suất token riêng lẻ.

✎Tóm tắt ▶ Xếp hạng bản vá tìm cách ưu tiên các bản vá ứng viên với xác suất cao hơn là đúng trong không gian tìm kiếm. Như một chiến lược tham lam, beam search được áp dụng rộng rãi trong các kỹ thuật APR dựa trên học máy hiện có để giữ 𝑘 token tối ưu tại mỗi lần lặp theo điểm số ước tính khả năng. Bên cạnh đó, một số chiến lược xếp hạng bản vá tiên tiến (ví dụ: chiến lược beam search nhận biết mã để xem xét các định danh hợp lệ) được đề xuất để xác định các bản vá có xác suất cao nhưng chất lượng thấp, chẳng hạn như các bản vá ứng viên không thể biên dịch. Nhìn chung, phần lớn các kỹ thuật APR dựa trên học máy hiện có tuân theo chiến lược beam search vanilla và tài liệu không thấy nghiên cứu có hệ thống để đi sâu vào tác động của các chiến lược xếp hạng bản vá đối với hiệu suất sửa chữa. Như một hướng dẫn cho công trình tương lai, sau khi tóm tắt các công trình xếp hạng bản vá hiện có, chúng tôi khuyến nghị rằng một kỹ thuật xếp hạng bản vá hợp lý cần xem xét ba khía cạnh: ① hiệu quả, tức là nó nên có không gian tìm kiếm đủ lớn để bao gồm các bản vá đúng; ② hiệu suất, tức là nó nên có tốc độ truy xuất nhanh để tìm bản vá đúng trong thời gian hợp lý; và ③ ưu tiên, tức là nó nên ưu tiên bản vá có khả năng đúng cao hơn dựa trên thông tin mã bổ sung, chẳng hạn như các tính năng cú pháp và ngữ nghĩa mã. ◀

4.6 Xác thực Bản vá

Xác thực bản vá nhận một danh sách xếp hạng các bản vá ứng viên được tạo ra bởi các mô hình NMT làm đầu vào và trả về các bản vá hợp lý để triển khai, đây là một giai đoạn quan trọng trong pipeline APR dựa trên học máy. Tuy nhiên, các nhà phát triển có thể dành một lượng nỗ lực đáng kể để kiểm tra các bản vá ứng viên một cách thủ công. Do đó, các nhà nghiên cứu thường biên dịch lại chương trình lỗi với bản vá được tạo ra để kiểm tra xem nó có thể vượt qua bộ kiểm thử có sẵn hay không. Trong tình huống như vậy, hàng trăm hoặc thậm chí hàng nghìn bản vá ứng viên có thể được lọc tự động (ví dụ: 1000 bản vá ứng viên mỗi lỗi trong CIRCLE [228]), điều này có thể có lợi cho việc áp dụng trong thực tế.

Tương tự như các kỹ thuật APR truyền thống, hầu hết các kỹ thuật dựa trên học máy áp dụng chiến lược xác thực dựa trên kiểm thử (tức là thực thi các bộ kiểm thử có sẵn đối với mỗi bản vá ứng viên) để đánh giá tính đúng đắn của bản vá [73,98,99,115,228,242]. Ví dụ, CIRCLE [228] lọc ra các bản vá ứng viên không biên dịch được hoặc không vượt qua các bộ kiểm thử có sẵn. Thường tồn tại hai tiêu chí cho quá trình xác thực: (1) các bộ kiểm thử vượt qua làm cho chương trình lỗi vượt qua nên vẫn vượt qua trên chương trình đã vá; và (2) các bộ kiểm thử kích hoạt lỗi thất bại trên chương trình lỗi nên vượt qua trên chương trình đã vá. Tất cả các bản vá ứng viên được kiểm tra cho đến khi một bản vá hợp lý (tức là bản vá vượt qua tất cả bộ kiểm thử) được tìm thấy. Cuối cùng, CIRCLE dừng quá trình xác thực và báo cáo bản vá hợp lý để điều tra thủ công. Các chiến lược xác thực dựa trên kiểm thử tương tự cũng được sử dụng bởi các phương pháp APR dựa trên học máy khác, chẳng hạn như Recoder [242], CoCoNut [115] và CURE [73].

Tuy nhiên, có thể cực kỳ tốn thời gian để biên dịch một số lượng lớn bản vá ứng viên và lặp lại tất cả việc thực thi kiểm thử để xác định các bản vá hợp lý. Ví dụ, CURE [73] tạo ra 10.000 bản vá ứng viên mỗi lỗi và xác thực 5.000 bản vá hàng đầu xem xét thời gian overhead. Tương tự, AlphaRepair [209] trả về tối đa 5.000 bản vá ứng viên cho mỗi lỗi. Để giảm chi phí xác thực, một số kỹ thuật APR dựa trên học máy trả về một số lượng chấp nhận được các bản vá ứng viên. Ví dụ, RewardRepair cấu hình kích thước beam là 200 và xuất ra 200 bản vá tốt nhất mỗi lỗi. Tương tự, SelfAPR áp dụng kích thước beam search là 50 và Recoder tạo ra 100 bản vá ứng viên hợp lệ để xác thực. Bên cạnh đó, tương tự như các kỹ thuật APR truyền thống [70,107], tồn tại một số kỹ thuật dựa trên học máy giới hạn thời gian tối đa để xác thực. Ví dụ, DEAR [99] và DLFix [98] đặt giới hạn thời gian chạy 5 giờ để tạo và xác thực bản vá.

Ngoài các chiến lược trên trong xác thực bản vá, cộng đồng APR dựa trên học máy được hưởng lợi từ một số tối ưu hóa để tăng tốc thực thi chương trình động. Ví dụ, AlphaRepair [209] áp dụng công cụ UniAPR [25] để xác thực các bản vá ứng viên on-the-fly. Ví dụ, lấy cảm hứng từ công trình PraPR [54], Chen et al. [25] trình bày UniAPR như khung xác thực bản vá on-the-fly thống nhất đầu tiên để tăng tốc các kỹ thuật APR cho các ngôn ngữ dựa trên JVM ở cả mức mã nguồn và byte-code. Họ tận dụng cơ chế JVM HotSwap và công nghệ Java Agent để triển khai khung này. Bên cạnh đó, họ áp dụng kỹ thuật đặt lại JVM dựa trên khung thao tác byte-code ASM. Vì công trình trước đây cho thấy rằng xác thực bản vá on-the-fly có thể không chính xác, họ đặt lại trạng thái JVM ngay sau mỗi lần thực thi bản vá để giải quyết vấn đề như vậy. Trực giao với UniAPR, Bento et al. [14] giới thiệu SeAPR, công cụ xác thực bản vá tự tăng cường đầu tiên. Dựa trên ý tưởng rằng các bản vá tương tự với các bản vá chất lượng cao/thấp trước đó nên được thúc đẩy/hạ cấp, họ tận dụng thông tin thực thi bản vá về sự tương tự của nó với các bản vá đã thực thi để cập nhật điểm số ưu tiên của mỗi bản vá. Việc đánh giá cho thấy SeAPR có thể giảm đáng kể thời gian xác thực bản vá và hiệu suất của nó ổn định dưới các công thức khác nhau để tính toán ưu tiên bản vá. Bên cạnh đó, tài liệu đã chứng kiến sự xuất hiện của một số nghiên cứu xác thực bản vá. Ví dụ, từ sớm năm 2012, Qi et al. [155] đề xuất WAutoRepair, một hệ thống sửa chữa kết hợp Genprog với một kỹ thuật biên dịch lại được gọi là weak recompilation để giảm chi phí thời gian và làm cho sửa chữa chương trình hiệu quả hơn. WAutoRepair xem một chương trình như một tập hợp các thành phần và cho mỗi bản vá ứng viên, chỉ một thành phần được sửa đổi. Sau đó, thành phần đã thay đổi được biên dịch thành một thư viện chia sẻ để giảm chi phí thời gian. Năm 2013, lấy cảm hứng từ ưu tiên kiểm thử hồi quy, Qi et al. [156] đề xuất TrpAutoRepair để ưu tiên việc thực thi trường hợp kiểm thử dựa trên thông tin lỗi trong quá trình sửa chữa. Mặc dù những công trình này đã đạt được kết quả đáng khen ngợi, hầu hết chúng đều được áp dụng cho các kỹ thuật APR truyền thống, ví dụ: GenProg [93]. Tuy nhiên, xem xét rằng giai đoạn xác thực bản vá được thiết kế để biên dịch và thực thi bản vá ứng viên, độc lập với các kỹ thuật tạo bản vá cụ thể, các kỹ thuật xác thực bản vá như vậy có tiềm năng được mở rộng cho các kỹ thuật sửa chữa dựa trên học máy trong tương lai.

✎Tóm tắt ▶ Thực thi động là một thực hành phổ biến để tự động xác thực khả năng biên dịch của mã và tính đúng đắn chức năng của các chương trình trong cộng đồng SE. Tuy nhiên, việc biên dịch và thực thi các chương trình như vậy tốn thời gian, đặc biệt trong lĩnh vực APR nơi có hàng nghìn bản vá ứng viên và một khối lượng lớn các trường hợp kiểm thử chức năng liên quan. Hầu hết các kỹ thuật APR dựa trên học máy dựa vào chiến lược xác thực dựa trên kiểm thử để xác định các bản vá hợp lý, đây là một bước tiêu chuẩn trong cả cộng đồng APR truyền thống và dựa trên học máy. Bên cạnh đó, gần đây đã có một số kỹ thuật tiên tiến được đề xuất đặc biệt để xác thực các bản vá ứng viên này nhanh hơn, chẳng hạn như JVM HotSwap. Hiện tại, không có sự khác biệt rõ rệt trong nghiên cứu xác thực bản vá giữa cộng đồng APR truyền thống và dựa trên học máy. Lý do có thể nằm ở chỗ, giai đoạn xác thực bản vá nhằm mục đích xác định các bản vá chất lượng cao vượt qua các trường hợp kiểm thử có sẵn. Mục tiêu này có thể được đạt được bằng cách thực thi trực tiếp các trường hợp kiểm thử, mà không quan tâm đến việc các bản vá đến từ kỹ thuật APR truyền thống hay dựa trên học máy. Chúng tôi khuyến khích nhiều nghiên cứu hơn về xác thực bản vá cụ thể cho các kỹ thuật APR dựa trên học máy, được thảo luận trong Phần 8. ◀

4.7 Tính đúng đắn của Bản vá

Tính đúng đắn của bản vá là một giai đoạn bổ sung để các nhà phát triển lọc thêm các bản vá overfitting sau xác thực bản vá, nhằm cải thiện chất lượng các bản vá được trả về. Như đã thảo luận trong Phần 4.6, phần lớn các kỹ thuật APR dựa trên học máy hiện có thường tận dụng các bộ kiểm thử do nhà phát triển viết như đặc tả chương trình để đánh giá tính đúng đắn của các bản vá được tạo ra. Tuy nhiên, bộ kiểm thử là một đặc tả không hoàn chỉnh vì nó chỉ mô tả một phần không gian hành vi của chương trình. Kết quả là, việc đạt được độ chính xác cao cho các bản vá được trả về do đặc tả chương trình không hoàn chỉnh là một thách thức cơ bản [90]. Bản vá hợp lý vượt qua các bộ kiểm thử có sẵn có thể không tổng quát hóa cho các bộ kiểm thử tiềm năng khác, dẫn đến một thách thức lâu dài của APR (tức là vấn đề overfitting) [90, 234].

Ví dụ, Qi et al. [157] đã chứng minh rằng phần lớn các bản vá overfitting được tạo ra bởi các phương pháp APR trước đây (ví dụ: GenProg [93]) cho 105 lỗi ngôn ngữ C tương đương với một sửa đổi duy nhất xóa chức năng lỗi và không thực sự sửa các lỗi đã phát hiện. Trong hoàn cảnh này, việc lọc thủ công các bản vá overfitting tốn rất nhiều thời gian và nỗ lực, thậm chí dẫn đến hiệu suất gỡ lỗi tiêu cực [177,238]. Khác với một số kỹ thuật APR truyền thống hướng dẫn quá trình sửa chữa để tạo ra các bản vá có xác suất cao là đúng, các kỹ thuật DL dẫn đến một cơ chế sửa chữa từ đầu đến cuối và các bản vá được tạo ra theo cách hộp đen. Vấn đề overfitting trong APR dựa trên học máy nghiêm trọng và nặng nề hơn [198].

Trong tài liệu, các nhà nghiên cứu đã đề xuất một khối lượng lớn các kỹ thuật đánh giá tính đúng đắn bản vá tự động (APCA) để xác định xem một bản vá hợp lý có thực sự đúng hay overfitting [179]. Xiong et al. [212] đề xuất PATCH-SIM để xác định các bản vá đúng dựa trên sự tương tự của các dấu vết thực thi trường hợp kiểm thử trên các chương trình lỗi và đã vá. PATCH-SIM đã được công nhận như một công trình nền tảng trong lĩnh vực này [179], cung cấp hướng dẫn quan trọng cho việc hình thành và phát triển các công trình tiếp theo [217,224]. Thường có hai loại kỹ thuật APCA truyền thống dựa trên các tính năng bản vá được sử dụng: tĩnh và động [195]. Loại trước tập trung vào các mẫu chuyển đổi hoặc sự tương tự cú pháp tĩnh (ví dụ: Anti-pattern [174]), trong khi loại sau dựa vào các kết quả thực thi động bằng các bộ kiểm thử bổ sung từ các công cụ tạo kiểm thử tự động (ví dụ: PATCH-SIM [212]). Gần đây, lấy cảm hứng từ các benchmark bản vá quy mô lớn được phát hành, một số kỹ thuật APCA dựa trên học máy đã được đề xuất để dự đoán tính đúng đắn bản vá với sự hỗ trợ của các mô hình DL [178,179,224]. Nói chung, các kỹ thuật APCA dựa trên học máy như vậy trích xuất các tính năng mã (ví dụ: biểu diễn tĩnh hoặc dấu vết thực thi động) và xây dựng một mô hình phân loại để thực hiện dự đoán tính đúng đắn bản vá trực tiếp. Chúng tôi xem tính đúng đắn bản vá như một thành phần thiết yếu của pipeline APR dựa trên học máy và tập trung vào các kỹ thuật APCA như vậy sử dụng các mô hình DL.

[Tiếp tục với bảng và mô tả chi tiết về các nghiên cứu APCA dựa trên học máy...]

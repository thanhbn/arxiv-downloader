# 2308.11396.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/coding/2308.11396.pdf
# Kích thước tệp: 620931 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Bản thảo không tên số
(sẽ được chèn bởi biên tập viên)
Hướng tới Hiểu biết về các Mô hình Ngôn ngữ Lớn trong Các Nhiệm vụ Kỹ thuật Phần mềm
Zibin Zheng ·Kaiwen Ning ·Qingyuan
Zhong ·Jiachi Chen ·Wenqing Chen ·
Lianghong Guo ·Weicheng Wang ·
Yanlin Wang
Nhận: ngày / Chấp nhận: ngày
Jiachi Chen là tác giả liên hệ.
Zibin Zheng
Khoa Kỹ thuật Phần mềm, Đại học Sun Yat-sen, Trung Quốc
Phòng thí nghiệm Trọng điểm Zhuhai về Mô hình Ngôn ngữ Lớn Đáng tin cậy
E-mail: zhzibin@mail.sysu.edu.cn
Kaiwen Ning
Khoa Kỹ thuật Phần mềm, Đại học Sun Yat-sen, Trung Quốc
Phòng thí nghiệm Pengcheng, Trung Quốc
Phòng thí nghiệm Trọng điểm Zhuhai về Mô hình Ngôn ngữ Lớn Đáng tin cậy
E-mail: ningkw@mail2.sysu.edu.cn
Qingyuan Zhong
Khoa Kỹ thuật Phần mềm, Đại học Sun Yat-sen, Trung Quốc
Phòng thí nghiệm Trọng điểm Zhuhai về Mô hình Ngôn ngữ Lớn Đáng tin cậy
E-mail: zhongqy39@mail2.sysu.edu.cn
Jiachi Chen
Khoa Kỹ thuật Phần mềm, Đại học Sun Yat-sen, Trung Quốc
Phòng thí nghiệm Trọng điểm Zhuhai về Mô hình Ngôn ngữ Lớn Đáng tin cậy
E-mail: chenjch86@mail.sysu.edu.cn
Wenqing Chen
Khoa Kỹ thuật Phần mềm, Đại học Sun Yat-sen, Trung Quốc
Phòng thí nghiệm Trọng điểm Zhuhai về Mô hình Ngôn ngữ Lớn Đáng tin cậy
E-mail: chenwq95@mail.sysu.edu.cn
Lianghong Guo
Khoa Kỹ thuật Phần mềm, Đại học Sun Yat-sen, Trung Quốc
Phòng thí nghiệm Trọng điểm Zhuhai về Mô hình Ngôn ngữ Lớn Đáng tin cậy
E-mail: guolh8@mail2.sysu.edu.cn
Weicheng Wang
Khoa Kỹ thuật Phần mềm, Đại học Sun Yat-sen, Trung Quốc
Phòng thí nghiệm Trọng điểm Zhuhai về Mô hình Ngôn ngữ Lớn Đáng tin cậy
E-mail: wangwch7@mail2.sysu.edu.cn
Yanlin Wang
Khoa Kỹ thuật Phần mềm, Đại học Sun Yat-sen, Trung Quốc
1arXiv:2308.11396v3  [cs.SE]  10 Dec 2024

--- TRANG 2 ---
Tóm tắt Các Mô hình Ngôn ngữ Lớn (LLMs) đã thu hút sự chú ý và nghiên cứu rộng rãi do hiệu suất đáng kinh ngạc của chúng trong các nhiệm vụ tạo văn bản và lý luận. Các sản phẩm phái sinh, như ChatGPT, đã được triển khai rộng rãi và rất được săn đón. Trong khi đó, việc đánh giá và tối ưu hóa LLMs trong các nhiệm vụ kỹ thuật phần mềm, chẳng hạn như tạo mã, đã trở thành một trọng tâm nghiên cứu. Tuy nhiên, vẫn còn thiếu nghiên cứu có hệ thống về việc áp dụng và đánh giá LLMs trong kỹ thuật phần mềm. Do đó, bài báo này điều tra và tổng hợp toàn diện nghiên cứu và sản phẩm kết hợp LLMs với kỹ thuật phần mềm, nhằm trả lời hai câu hỏi: (1) Các tích hợp hiện tại của LLMs với kỹ thuật phần mềm là gì? (2) LLMs có thể xử lý hiệu quả các nhiệm vụ kỹ thuật phần mềm không? Để tìm câu trả lời, chúng tôi đã thu thập tài liệu liên quan càng rộng rãi càng tốt từ bảy cơ sở dữ liệu chính và chọn lọc 123 bài báo kịp thời được xuất bản bắt đầu từ năm 2022 để phân tích. Chúng tôi đã phân loại các bài báo này một cách chi tiết và xem xét tình trạng nghiên cứu hiện tại của LLMs từ góc độ bảy nhiệm vụ kỹ thuật phần mềm chính, hy vọng điều này sẽ giúp các nhà nghiên cứu nắm bắt tốt hơn xu hướng nghiên cứu và giải quyết các vấn đề khi áp dụng LLMs. Trong khi đó, chúng tôi cũng đã tổ chức và trình bày các bài báo có nội dung đánh giá để tiết lộ hiệu suất và hiệu quả của LLMs trong các nhiệm vụ kỹ thuật phần mềm khác nhau, hướng dẫn các nhà nghiên cứu và nhà phát triển tối ưu hóa.
Từ khóa Nghiên cứu Thực nghiệm · Tổng quan Tài liệu · Mô hình Ngôn ngữ Lớn · Kỹ thuật Phần mềm

1 Giới thiệu
Các mô hình ngôn ngữ lớn (LLMs) đề cập đến các mô hình ngôn ngữ mạng neuron được huấn luyện trên dữ liệu văn bản khổng lồ, với kích thước mô hình đạt đến hàng trăm tỷ hoặc nhiều hơn tham số (Zhao et al., 2023b). Các LLMs tiên tiến nhất cho đến nay, chẳng hạn như GPT-4 (Liu et al., 2023e; Savelka et al., 2023) và LaMDA (Thoppilan et al., 2022), đã thể hiện khả năng hiểu và tạo ngôn ngữ đáng chú ý, có thể thực hiện tốt trên nhiều nhiệm vụ xử lý ngôn ngữ tự nhiên, chẳng hạn như tóm tắt văn bản (Tang et al., 2023a). Các sản phẩm và ứng dụng phái sinh của LLMs, chẳng hạn như ChatGPT (Gozalo-Brizuela và Garrido-Merchan, 2023) và Claude (tse Huang et al., 2023), cũng đã thu hút sự chú ý rộng rãi trong cả cộng đồng học thuật và công nghiệp. Với hiệu suất xuất sắc của LLMs, ngày càng có nhiều sự tập trung vào việc khám phá tiềm năng của chúng trong các nhiệm vụ kỹ thuật phần mềm, tìm kiếm các cơ hội mới để giải quyết các thách thức trong lĩnh vực kỹ thuật phần mềm (Zan et al., 2023).

Mục tiêu chính của kỹ thuật phần mềm là phát triển các sản phẩm phần mềm chất lượng cao và dễ bảo trì (Kotti et al., 2023). Quá trình này bao gồm nhiều giai đoạn, bao gồm phân tích yêu cầu, thiết kế, phát triển, kiểm thử,

Phòng thí nghiệm Trọng điểm Zhuhai về Mô hình Ngôn ngữ Lớn Đáng tin cậy
E-mail: wangylin36@mail.sysu.edu.cn
2

--- TRANG 3 ---
và bảo trì (Hoffmann et al., 2023). Trong suốt quá trình này, các kỹ sư cần xử lý các nhiệm vụ kỹ thuật phần mềm khác nhau, chẳng hạn như hiểu các yêu cầu phức tạp, viết mã chính xác và đáng tin cậy, xây dựng các trường hợp kiểm thử toàn diện, v.v. Nói chung, các nhiệm vụ kỹ thuật phần mềm này thường dựa vào chuyên môn và kinh nghiệm của các kỹ sư phần mềm. Sự phụ thuộc này không chỉ phát sinh chi phí nguồn nhân lực đáng kể, mà còn tăng độ khó khăn của việc phát triển và bảo trì phần mềm. Ngoài ra, với độ phức tạp ngày càng tăng của nhu cầu người dùng và sự xuất hiện của các loại ứng dụng mới, các kỹ sư cũng phải đối mặt với những thách thức bổ sung khi xử lý các nhiệm vụ kỹ thuật phần mềm, chẳng hạn như phát triển hợp tác, nâng cao chất lượng phần mềm và rút ngắn chu kỳ phát triển (Ferrario và Winter, 2023).

Do đó, nghiên cứu cách nâng cao mức độ tự động hóa trong các nhiệm vụ kỹ thuật phần mềm để đạt được sản xuất và bảo trì phần mềm hiệu quả hơn là một chủ đề quan trọng và được thảo luận rộng rãi. Hiện tại, nhiều nỗ lực được dành cho việc phát triển các công cụ và thuật toán liên quan để hỗ trợ các kỹ sư hoàn thành các nhiệm vụ kỹ thuật phần mềm này. Ví dụ, tạo mã tự động (Feng et al., 2021), tạo trường hợp kiểm thử tự động (Wang et al., 2022a), và phát hiện lỗ hổng (Liu et al., 2023g) là một số lĩnh vực tập trung. Tuy nhiên, các phương pháp tự động hóa riêng lẻ này thường gặp phải những thách thức khi được áp dụng rộng rãi (Wang et al., 2023f), và một số giải pháp tự động hiện có có thể gây ra các vấn đề hoặc lỗi mới. Ví dụ, mã được tạo tự động có thể chứa các lỗ hổng tiềm ẩn (Thakur et al., 2023a), các trường hợp kiểm thử được tạo tự động thường không đạt được phạm vi bao phủ toàn diện (Lemieux et al., 2023), v.v.

May mắn thay, LLMs có tiềm năng lớn để giải quyết các vấn đề trên do hiệu suất xuất sắc của chúng trong các nhiệm vụ phức tạp như tạo văn bản. LLMs thường cần được huấn luyện trên một kho ngữ liệu quy mô lớn chứa cơ sở mã với nhiều đoạn (Wei et al., 2022). Điều này cho phép nó học tốt hơn cú pháp và ngữ nghĩa mã, và có tiềm năng được trang bị tốt hơn cho các nhiệm vụ như hoàn thành mã và tóm tắt mã (Wang et al., 2023e). Hiện tại, khi ngày càng nhiều LLMs được thiết kế cho các nhiệm vụ kỹ thuật phần mềm được triển khai (Huaggingface, 2021; Nijkamp et al., 2023; Zheng et al., 2023; Wang et al., 2021; Li et al., 2022c; Chai et al., 2022; Wang et al., 2023e), nhiều công trình nghiên cứu tập trung vào ứng dụng của LLMs trong lĩnh vực kỹ thuật phần mềm (Ahmad et al., 2023a; Zhang et al., 2023b; Li et al., 2023a; Barke et al., 2023a; Zhuo et al., 2023; Gozalo-Brizuela và Garrido-Merchan, 2023). Khả năng của LLMs như tạo mã chất lượng cao và các trường hợp kiểm thử có độ bao phủ cao đã trở thành một chủ đề nóng trong lĩnh vực kỹ thuật phần mềm (Zan et al., 2023). Tuy nhiên, trong tài liệu hiện có, các đánh giá có hệ thống và khảo sát đầy đủ đã được thực hiện về các ứng dụng LLMs trong các lĩnh vực như giáo dục (Leinonen et al., 2023b), nhưng vẫn thiếu một đánh giá có hệ thống về ứng dụng và đánh giá LLMs trong lĩnh vực kỹ thuật phần mềm.
3

--- TRANG 4 ---
Trong nghiên cứu này, mục tiêu của chúng tôi là thực hiện một đánh giá toàn diện về chủ đề giao thoa giữa LLMs và kỹ thuật phần mềm. Để tạo điều kiện cho việc này, chúng tôi ban đầu đã thu thập càng nhiều tài liệu liên quan càng tốt từ sáu cơ sở dữ liệu học thuật chính, cụ thể là ACM Digital Library¹, IEEE Xplore Digital Library², dblp³, Elsevier Science Direct⁴, Google Scholar⁵, và arXiv⁶. Thông qua phương pháp phân loại thẻ (Reese et al., 2018), chúng tôi đã loại bỏ tài liệu trùng lặp và không liên quan. Chúng tôi tập trung vào các bài báo được xuất bản sau năm 2022 vì định nghĩa và quy mô của "Lớn" trong LLMs đã phát triển, khiến tài liệu trước đó có thể lỗi thời. Theo các bài báo được thu thập, chúng tôi định nghĩa các mô hình ngôn ngữ dựa trên transformer có số lượng tham số lớn hơn hoặc bằng 0,8 tỷ (0,8b) là Mô hình Ngôn ngữ Lớn (LLMs). Sau quá trình sàng lọc, chúng tôi đã có được 123 bài báo nghiên cứu liên quan và hợp lệ. Với nghiên cứu này, chúng tôi nhằm giải quyết hai câu hỏi sau:

RQ1: Các công trình hiện tại tập trung vào việc kết hợp LLMs và kỹ thuật phần mềm là gì?

Để trả lời những câu hỏi này, chúng tôi đã phân loại 123 bài báo được chọn theo các nhiệm vụ kỹ thuật phần mềm liên quan. Dựa trên nội dung cụ thể của các nhiệm vụ kỹ thuật phần mềm, chẳng hạn như tạo mã và phát hiện lỗ hổng, chúng tôi đã chia chúng thành bảy danh mục. Đó là Tạo Mã, Tóm tắt Mã, Dịch mã, Phát hiện Lỗ hổng, Đánh giá Mã, Quản lý Mã và Tương tác Hỏi & Đáp. Đối với mỗi danh mục, chúng tôi elaborat về định nghĩa và ví dụ của chúng, có thể giúp các nhà nghiên cứu tiếp tục khám phá và giải quyết các vấn đề tiềm ẩn khi áp dụng LLMs vào các nhiệm vụ kỹ thuật phần mềm.

RQ2: LLMs có thực sự giúp thực hiện tốt hơn các nhiệm vụ kỹ thuật phần mềm hiện tại không?

Mặc dù LLMs đã thể hiện hiệu suất xuất sắc trong các nhiệm vụ tạo văn bản, hiệu suất của chúng trong các nhiệm vụ kỹ thuật phần mềm như tạo mã cần được xác thực thêm. Để giải quyết vấn đề này, chúng tôi đã thực hiện một lựa chọn tài liệu chứa các đánh giá liên quan đến LLMs. Xem xét rằng các LLMs được chọn và các nhiệm vụ kỹ thuật phần mềm trong các công trình này có thể khác nhau, chúng tôi cũng đã tổ chức và biên soạn thông tin này trong quá trình sàng lọc. Các phát hiện của chúng tôi chỉ ra rằng hiện tại, LLMs xuất sắc trong các nhiệm vụ đòi hỏi hiểu biết về cú pháp, chẳng hạn như tóm tắt mã và sửa chữa mã. Tuy nhiên, hiệu suất của chúng có xu hướng kém thỏa mãn hơn trong các nhiệm vụ đòi hỏi hiểu biết về ngữ nghĩa mã, chẳng hạn như tạo mã và phát hiện lỗ hổng. Tuy nhiên, chúng tôi cũng quan sát thấy rằng LLMs tiếp tục tiến bộ với mỗi phiên bản và lần lặp mô hình, cho thấy chúng vẫn sở hữu tiềm năng để đạt được hiệu suất tốt hơn trong tương lai.

¹https://dl.acm.org/
²https://ieeexplore.ieee.org/Xplore/home.jsp
³https://dblp.uni-trier.de/
⁴https://www.sciencedirect.com/
⁵https://scholar.google.com
⁶https://arxiv.org/
4

--- TRANG 5 ---
Những đóng góp chính của bài báo này là:

• Chúng tôi đã đánh giá có hệ thống các công trình tiên tiến trong giao điểm của kỹ thuật phần mềm và LLM, một chủ đề được thảo luận nhiều. Chúng tôi đã chọn lọc thủ công 123 công trình liên quan từ nhiều bài báo trong sáu cơ sở dữ liệu và thực hiện tổ chức và phân loại chi tiết. (Mã nguồn mở, https://github.com/KevinHeiwa/LLM-SE-Paper-List);

• Chúng tôi đã phân loại các nhiệm vụ này thủ công thành bảy loại dựa trên các nhiệm vụ kỹ thuật phần mềm khác nhau. Đối với mỗi danh mục, chúng tôi đã cung cấp các ví dụ ứng dụng của LLM và đi sâu vào các giải thích chi tiết. Điều này có thể hỗ trợ các nhà nghiên cứu xác định và giải quyết tốt hơn các thách thức tiềm ẩn khi áp dụng LLM vào các nhiệm vụ kỹ thuật phần mềm;

• Chúng tôi đã thu thập và biên soạn toàn diện hiệu suất của LLM trong các nhiệm vụ kỹ thuật phần mềm khác nhau. Chúng tôi đã cung cấp một trình bày và phân tích về hiệu suất của LLM trong các nhiệm vụ kỹ thuật phần mềm này, cũng như những lý do cho sự khác biệt được quan sát giữa các nghiên cứu khác nhau. Điều này có thể hỗ trợ các nhà phát triển tối ưu hóa LLM hiệu quả hơn.

Tổ chức của bài báo này như sau. Trong Phần 2, chúng tôi cung cấp kiến thức nền tảng về LLMs; Trong Phần 4, chúng tôi tóm tắt và phân loại tài liệu được thu thập và đề xuất câu trả lời cho câu hỏi nghiên cứu 1 (RQ1); Trong Phần 5, chúng tôi giải quyết câu hỏi nghiên cứu 2 (RQ2); Trong Phần 6, chúng tôi biên soạn hiệu suất của các LLMs khác nhau trên các benchmark và tài liệu khác nhau để giải quyết câu hỏi nghiên cứu 3 (RQ3); Cuối cùng, trong Phần 8, chúng tôi tóm tắt toàn bộ bài báo.

2 Kiến thức nền tảng

Trong phần này, chúng tôi sẽ giới thiệu kiến thức nền tảng về các mô hình ngôn ngữ lớn, bao gồm mô hình transformer, kiến trúc của các mô hình ngôn ngữ lớn, và các khả năng nổi bật của chúng.

2.1 Transformer

Hiện tại, các mô hình ngôn ngữ lớn chủ đạo được dựa trên mô hình Transformer (Vaswani et al., 2017), chẳng hạn như GPT-3 (Brown et al., 2020) và PaLM (Chowdhery et al., 2022). So với các cấu trúc mô hình học sâu truyền thống như mạng neuron hồi quy (RNNs) và mạng neuron tích chập (CNNs), mô hình Transformer dựa vào cơ chế attention, cho phép tính toán song song và nắm bắt hiệu quả hơn các phụ thuộc tầm xa. Điều này cung cấp nền tảng để huấn luyện hiệu quả các mô hình ngôn ngữ lớn trên dữ liệu văn bản quy mô lớn.

Mô hình Transformer lần đầu tiên được giới thiệu bởi Vaswani et al (Vaswani et al., 2017) vào năm 2017, là một mô hình sequence-to-sequence bao gồm một encoder và

5

--- TRANG 6 ---
một decoder. Cả encoder và decoder đều được tạo thành từ nhiều khối giống hệt nhau được xếp chồng lên nhau. Mỗi khối trong encoder chủ yếu bao gồm một mô-đun multi-head self-attention và một mạng feed-forward theo vị trí (FFN), với các kết nối dư (He et al., 2016) và chuẩn hóa lớp (Ba et al., 2016) được áp dụng để cho phép xây dựng mô hình sâu hơn. (Lin et al., 2022a) Trong decoder, các mô-đun cross-attention được chèn giữa các mô-đun multi-head self-attention và các FFN theo vị trí, cho phép kết hợp thông tin từ encoder. Đáng chú ý, các mô-đun self-attention trong decoder được sửa đổi để ngăn chặn việc chú ý đến các vị trí tiếp theo.

Thành phần cốt lõi của Transformer là cơ chế attention, cho phép mô hình cân nhắc tầm quan trọng của các từ hoặc token khác nhau trong một chuỗi khi tạo ra hoặc hiểu ngữ cảnh. Bằng cách chú ý đến các phần liên quan của chuỗi đầu vào, mô hình Transformer có thể mô hình hóa hiệu quả các mối quan hệ giữa các từ và nắm bắt thông tin ngữ cảnh phong phú. Ngoài ra, cơ chế attention không bao gồm các hoạt động tuần tự, cho phép tính toán song song và dẫn đến hiệu quả cao hơn trong quá trình huấn luyện và suy luận trong mô hình Transformer.

2.2 Kiến trúc Mô hình

Kiến trúc Transformer, được đề xuất bởi Vaswani et al. vào năm 2017 (Vaswani et al., 2017), đã nổi lên như lựa chọn hàng đầu để phát triển các mô hình ngôn ngữ lớn (LLMs) do khả năng song song hóa và dung lượng đặc biệt của nó (Zhao et al., 2023b). Khả năng mở rộng này cho phép các mô hình ngôn ngữ được mở rộng để bao gồm hàng trăm hoặc thậm chí hàng nghìn tỷ tham số, cho phép chúng nắm bắt các mẫu ngôn ngữ phức tạp hơn và cải thiện hiệu suất trên các nhiệm vụ khác nhau. Nói chung, các mô hình ngôn ngữ lớn có thể được phân loại thành ba loại kiến trúc chính: cấu trúc encoder-decoder, causal-decoder, và prefix decoder (Zhao et al., 2023b), mỗi loại có đặc điểm và ứng dụng riêng.

Kiến trúc Encoder-decoder: Transformer vanilla được đề xuất trong (Vaswani et al., 2017) dựa trên kiến trúc encoder-decoder, bao gồm các thành phần encoder và decoder riêng biệt. Encoder xử lý chuỗi đầu vào và nắm bắt biểu diễn tiềm ẩn của nó, sau đó được decoder sử dụng để tạo ra chuỗi đầu ra một cách tự hồi quy. Kiến trúc này phù hợp với các nhiệm vụ liên quan đến ánh xạ sequence-to-sequence, chẳng hạn như dịch máy, tóm tắt văn bản và tạo đối thoại. Mô hình tiền huấn luyện Encoder-decoder. Các mô hình tiền huấn luyện encoder-decoder, chẳng hạn như BART (Lewis et al., 2019) và T5 (Raffel et al., 2020), đã thể hiện hiệu suất xuất sắc trên các nhiệm vụ downstream khác nhau. Tuy nhiên, với sự phát triển của LLM, chỉ có một số ít mô hình ngôn ngữ lớn dựa trên kiến trúc encoder-decoder, chẳng hạn như Flan-T5 (Chung et al., 2022) và CodeT5+ (Wang et al., 2023f).

Kiến trúc Causal Decoder: Kiến trúc causal decoder thường được triển khai như một ngăn xếp các lớp decoder. Nó sử dụng một ma trận mặt nạ chéo, cho phép mỗi token chỉ có quyền truy cập vào thông tin từ các token trước đó. Ràng buộc này đảm bảo một quá trình tạo ra một chiều và tự hồi quy. Mô hình series GPT, ban đầu được giới thiệu bởi OpenAI (Radford et al., 2018, 2019; Brown et al., 2020), đại diện cho một trong những ví dụ nổi bật nhất của kiến trúc causal decoder. Mặc dù GPT (Radford et al., 2018) và GPT-2 (Radford et al., 2018) không thể hiện cùng mức độ hiệu suất như GPT-3 (Brown et al., 2020), với sự gia tăng kích thước mô hình và lượng dữ liệu được sử dụng để tiền huấn luyện, GPT-3 (Brown et al., 2020) đã thể hiện khả năng few-shot đáng chú ý mà các mô hình trước đó không sở hữu. Ngày nay, kiến trúc causal decoder đã trở thành lựa chọn phổ biến cho các kiến trúc mô hình ngôn ngữ lớn, tạo ra một loạt các LLMs mạnh mẽ như PaLM (Chowdhery et al., 2022), LLaMA (Touvron et al., 2023), OPT (Zhang et al., 2022c), Bloom (Scao et al., 2022). Kiến trúc causal decoder và kiến trúc prefix decoder, sẽ được thảo luận tiếp theo, được gọi chung là kiến trúc decoder-only (Zhao et al., 2023b).

Kiến trúc Prefix Decoder: Prefix decoder, tương tự như kiến trúc causal decoder, bao gồm các lớp decoder. Tuy nhiên, sự khác biệt chính nằm ở cơ chế attention của chúng. Prefix decoder sử dụng attention hai chiều cho các token tiền tố, kết hợp thông tin từ cả các token trước và sau. Ngược lại, attention một chiều chỉ được áp dụng cho các token được tạo ra, đảm bảo dòng thông tin một chiều trong quá trình tạo ra. Sự kết hợp các cơ chế attention trong prefix decoder cho phép tạo ra linh hoạt và được kiểm soát, có điều kiện trên cả tiền tố và các token được tạo ra. Một số mô hình được biết đến dựa trên kiến trúc prefix decoder bao gồm U-PaLM (Tay et al., 2022) và GLM-130B (Zeng et al., 2022a).

2.3 Khả năng Nổi bật

Theo quy luật tỷ lệ của các mô hình ngôn ngữ lớn (Kaplan et al., 2020), khi các tham số mô hình và dữ liệu huấn luyện tăng lên, khả năng và năng lực của mô hình cũng được cải thiện. Khi việc tỷ lệ vượt quá một ngưỡng nhất định, LLMs thể hiện các khả năng nổi bật không có mặt trong các mô hình nhỏ hơn (Wei et al., 2022). Những khả năng nổi bật này được coi là đặc điểm đáng chú ý nhất phân biệt các mô hình lớn với các đối tác nhỏ hơn của chúng. Chẳng hạn như in-context learning (Brown et al., 2020), instruction following (Sanh et al., 2021; Ouyang et al., 2022; Wei et al., 2021), và step-by-step reasoning (Shanahan, 2022).

3 Phương pháp

Trong phần này, chúng tôi giới thiệu các bước chi tiết để thực hiện một đánh giá tài liệu. Chúng tôi tuân theo phương pháp được cung cấp bởi (Kitchenham, 2007; Watson et al.,

7

--- TRANG 8 ---
2022) cho đánh giá tài liệu. Nói chung, nó bao gồm ba bước: tìm kiếm tài liệu, sàng lọc tài liệu, và phân tích dữ liệu. Như được thể hiện trong Hình 1.

Từ khóa tìm kiếm Tài liệu
Tìm kiếm Tài liệu
Lựa chọn
Bảy tiêu chí loại trừ Phân tích
Dữ liệu
Quy trình thu thập và sàng lọc tài liệu: thu thập tài liệu quy mô lớn và sàng lọc chính xác tài liệu liên quan

Sáu công cụ tìm kiếm
Bao gồm
tài liệu đã xuất bản
và tài liệu preprint

Phân tích ngữ cảnh thủ công
Sử dụng phương pháp phân loại thẻ để kiểm tra dữ liệu

Đọc bài báo
Phân loại
tài liệu
Thảo luận và
Kết luận thống nhất

Hình 1 Tổng quan về thiết kế phương pháp.

3.1 Tìm kiếm Tài liệu

Dựa trên đánh giá tài liệu trước đó (Chen et al., 2021), chúng tôi đã chọn sáu công cụ tìm kiếm: ACM Digital Library, IEEE Xplore Digital Library, dblp, Elsevier Science Direct, Google Scholar, và arXiv. Những công cụ tìm kiếm này cho phép chúng tôi tìm các bài báo nghiên cứu được đánh giá đồng đẳng được xuất bản trong các tạp chí, hội nghị, workshop và hội thảo. Ngoài ra, chúng cung cấp quyền truy cập vào một số lượng đáng kể các bài báo preprint và những phát triển công nghiệp mới nhất.

Chúng tôi đã thực hiện tìm kiếm sử dụng sáu từ khóa sau: "SE LLM," "Software Engineering Large Language Model," "Software Engineering LLM," "SE Large Language Model," "Code LLM," và "Code Large Language Model" trên sáu cơ sở dữ liệu bài báo nói trên. Kết quả thu được được trình bày trong Bảng 1. Đáng chú ý là có thể có một số lượng đáng kể các bài báo trùng lặp và bài viết không liên quan kết quả từ các tìm kiếm từ khóa khác nhau trong cùng một công cụ hoặc cùng từ khóa trên các công cụ khác nhau. Do đó, chúng tôi cần sàng lọc và chọn lọc thủ công các bài báo này, được gọi là sàng lọc tài liệu hoặc lựa chọn tài liệu.

3.2 Lựa chọn Tài liệu

Trong giai đoạn này, chúng tôi cần loại bỏ không chỉ các bài báo trùng lặp mà còn cả những bài không liên quan. Ví dụ, một số bài báo có thể tập trung chủ yếu vào LLM hoặc lĩnh vực kỹ thuật phần mềm nhưng không đề cập đến LLM hoặc "Large Language Model" trong tóm tắt của chúng. Ngoài ra, vì định nghĩa "Large" trong LLM có thể thay đổi, một số tài liệu trước đó có thể đã được coi là LLM vào thời điểm đó nhưng có thể không đáp ứng tiêu chí từ góc độ hiện tại (Zhao et al.,

8

--- TRANG 9 ---
Bảng 1 Số lượng tìm kiếm từ khóa trả về bởi mỗi công cụ tìm kiếm.

SE
LLM Software
Engineering
Large
Language
Model Software
Engineering
LLM SE Large
Language
Model Code
LLM Code
Large
Language
Model
ACM
Digital
Library 4983 55907 39032 54532 27894 54990
IEEE
Xplore
Digital
Library 0 240 7 14 14 328
dblp 8 4 1 105 7 62
Elsevier
Science
Direct 56 11273 54 7063 64 20649
Google
Scholar 10500 16400 4020 25400 11400 17700
arXiv 5 182 70 17 463 1461

2023b; Lin et al., 2022a; Zan et al., 2023; Meade et al., 2022; Li et al., 2022a; Wang et al., 2023a). Do đó, chúng tôi đã loại trừ nghiên cứu được thực hiện trước năm 2022. Chúng tôi áp dụng bảy tiêu chí loại trừ sau để sàng lọc tài liệu:

Tiêu chí loại trừ
• Các nghiên cứu không được viết bằng tiếng Anh.
• Luận văn Thạc sĩ hoặc Tiến sĩ.
• Bài báo keynote.
• Các nghiên cứu không liên quan đến LLM.
• Các nghiên cứu không liên quan đến kỹ thuật phần mềm.
• Tài liệu trùng lặp.
• Các nghiên cứu đến năm 2022 (không bao gồm 2022).

Để chứng minh lý do đằng sau việc loại trừ các công trình trước năm 2022, chúng tôi đã thu thập và tổ chức một số bài báo quan trọng về các mô hình ngôn ngữ (LMs) được xuất bản trong các hội nghị kỹ thuật phần mềm hàng đầu, cụ thể là ICSE, ISSTA, FSE, và ASE, từ năm 2017 đến 2022. Kết quả được trình bày trong Bảng 2, nơi chúng tôi tìm thấy tổng cộng 19 bài báo liên quan.

9

--- TRANG 10 ---
Từ Bảng 2, chúng ta có thể quan sát những điều sau: Thứ nhất, mặc dù kiến trúc Transformer được giới thiệu vào năm 2017, việc áp dụng các mô hình ngôn ngữ tiền huấn luyện (PLMs) dựa trên Transformer trong các nhiệm vụ SE bắt đầu vào khoảng năm 2021. Thứ hai, các bài báo trước đó chủ yếu tập trung vào "các mô hình ngôn ngữ tiền huấn luyện" hơn là LLMs. Hai khái niệm này có sự khác biệt rõ rệt. Cuối cùng, LLMs bắt đầu nhận được sự chú ý và dần được áp dụng vào các nhiệm vụ kỹ thuật phần mềm vào khoảng năm 2022.

Hơn nữa, chúng ta có thể thấy rằng trọng tâm nghiên cứu về PLMs và LLMs trong các nhiệm vụ SE khá khác nhau. Ví dụ, trong Bảng 3, chúng ta có thể quan sát rằng các nhiệm vụ tạo mã là một chủ đề quan trọng trong nghiên cứu LLM nhưng hiếm khi được đề cập trong các nghiên cứu được thực hiện trước năm 2022. Điều này do thực tế là kiến trúc PLM phổ biến trước năm 2022 là Encoder-Decoder, khác đáng kể so với kiến trúc decoder-only thường được sử dụng trong LLMs hiện tại. Đây là lý do tại sao chúng tôi chỉ tập trung vào các công trình sau năm 2022.

Bảng 2 Các bài báo về mô hình ngôn ngữ tiền huấn luyện từ năm 2017 đến 2022 trong các hội nghị kỹ thuật phần mềm hàng đầu.

ISSTA ICSE ASE FSE
2017 0 0 0 0
2018 0 0 0 0
2019 0 0 1 0
2020 0 0 0 0
2021 0 2 2 0
2022 2 7 4 2

Trong nghiên cứu này, chúng tôi đặc biệt tập trung vào giao điểm của LLM và kỹ thuật phần mềm. Do đó, chúng tôi sẽ loại trừ các bài báo chỉ tập trung vào LLM hoặc kỹ thuật phần mềm. Chúng tôi quan tâm đến các chủ đề sau:

Chủ đề bao gồm
• LLM trong Kỹ thuật Phần mềm.
• Ứng dụng của LLM trong Kỹ thuật Phần mềm (ví dụ, tạo mã).
• Nghiên cứu Thực nghiệm về LLM trong các Nhiệm vụ Kỹ thuật Phần mềm

Để cải thiện độ chính xác của quá trình sàng lọc tài liệu, chúng tôi sẽ sử dụng phương pháp phân loại thẻ để đánh giá dữ liệu thu thập được. Phân loại thẻ là một kỹ thuật phổ biến được sử dụng để đánh giá dữ liệu và rút ra các danh mục từ nó. Có ba loại phương pháp phân loại thẻ: phân loại thẻ mở, phân loại thẻ đóng, và phân loại thẻ lai. Trong ba loại này, phân loại thẻ đóng bao gồm các danh mục được định nghĩa trước (Kitchenham, 2007). Trong trường hợp của chúng tôi, chúng tôi áp dụng phân loại thẻ đóng để chọn các bài báo liên quan vì chúng tôi chỉ có hai danh mục: liên quan và không liên quan. Mỗi thẻ sẽ có một tiêu đề (tiêu đề bài báo) và một mô tả (tóm tắt bài báo). Bằng cách sử dụng phương pháp này, chúng tôi có thể đánh giá và phân loại các bài báo một cách có hệ thống dựa trên mức độ liên quan của chúng đến nghiên cứu của chúng tôi.

Sáu nhà nghiên cứu có kinh nghiệm, bao gồm một người không phải đồng tác giả, đã độc lập thực hiện một đánh giá kỹ lưỡng về kết quả công cụ tìm kiếm từ sáu cơ sở dữ liệu. Sau khi tổ chức các bài báo riêng lẻ, họ tham gia vào một cuộc thảo luận hợp tác để điều chỉnh các phát hiện của họ. Thông qua quá trình nghiêm ngặt này, cuối cùng chúng tôi đã xác định được 123 bài báo liên quan đáp ứng tiêu chí để đưa vào nghiên cứu của chúng tôi.

3.3 Phân tích Dữ liệu

Định nghĩa "lớn" trong LLM thay đổi theo thời gian. Vì lý do này, chúng tôi đã lọc ra các công trình không đáp ứng định nghĩa LLM trong (Zhao et al., 2023b) và đảm bảo rằng tất cả các công trình như vậy sẽ được công khai sau năm 2022. Chúng tôi sử dụng phân loại thẻ mở để giúp tìm câu trả lời cho hai RQ này. Chúng tôi đọc bài báo cẩn thận và tìm kiếm kỹ lưỡng câu trả lời cho hai câu hỏi tương tự được thể hiện trong Bảng 4, tức là, (1). Các công trình hiện tại tập trung vào việc kết hợp LLMs và kỹ thuật phần mềm là gì? (2). LLMs có thực sự giúp thực hiện tốt hơn các nhiệm vụ kỹ thuật phần mềm hiện tại không? Nếu chúng tôi không thể tìm thấy bất kỳ câu trả lời nào từ một bài báo, thì bài báo đó sẽ bị xóa khỏi danh sách của chúng tôi.

Đối với câu trả lời cho (1), chúng tôi chủ yếu kiểm tra xem các bài báo có đề cập đến việc áp dụng LLM trong các nhiệm vụ kỹ thuật phần mềm hay không. Chúng tôi tổ chức thông tin này và phân loại tài liệu dựa trên các loại nhiệm vụ. Số lượng bài báo được bao gồm cho mỗi nhiệm vụ được thể hiện trong Hình 2. Việc lựa chọn phân loại nhiệm vụ kỹ thuật phần mềm của chúng tôi dựa trên nội dung chính của các bài báo được khảo sát. Đối với một nhiệm vụ kỹ thuật phần mềm cụ thể, nếu chỉ có hai bài báo liên quan đến nhiệm vụ đó, chúng tôi phân loại nó riêng biệt. Ngược lại, chúng tôi nhóm nó dưới "Công việc khác."

Để xác thực phân loại của chúng tôi, chúng tôi tổ chức các bài báo nghiên cứu từ ICSE 2024⁷, một hội nghị được công nhận cao trong lĩnh vực kỹ thuật phần mềm, như được thể hiện trong Bảng 3. Chúng ta có thể quan sát rằng có tổng cộng 40 bài báo liên quan đến LLM trong ICSE 2024, có thể được phân loại thành bảy lớp được đề cập trong bài báo. Điều này cho thấy rằng các nhiệm vụ kỹ thuật phần mềm mà chúng tôi đã chọn hiện đang là những nhiệm vụ nổi bật nhất trong nghiên cứu LLM và SE và bao gồm một phần đáng kể các nhiệm vụ kỹ thuật phần mềm. Hơn nữa, liên quan đến benchmarking, datasets, và công việc tương tự, chúng tôi không phân loại chúng như các nhiệm vụ kỹ thuật phần mềm. Thay vào đó, chúng tôi phân loại chúng dựa trên mục tiêu nghiên cứu của chúng. Ví dụ, một benchmark cho tạo mã vẫn sẽ thuộc về nhiệm vụ tạo mã. Các định nghĩa của các nhiệm vụ khác nhau được cung cấp trong Bảng 5.

⁷https://conf.researchr.org/track/icse-2024/icse-2024-research-track?#event-overview

11

--- TRANG 12 ---
Bảng 3 Các bài báo liên quan đến LLM trong ICSE 2024.

Nhiệm vụ Số lượng Bài báo Ghi chú
Tạo Mã 13 Bao gồm cải thiện mã
Tương tác Hỏi & Đáp 5 /
Dịch Mã 1 /
Tóm tắt Mã 4 Bao gồm hiểu mã
Đánh giá Mã 3 Bao gồm nhân bản mã
Phát hiện Lỗ hổng 9 Bao gồm kiểm thử
Quản lý Mã 4 Bao gồm nhật ký
Công việc khác 1 /
Tổng cộng 40 /

Hình 2 Số lượng tài liệu về các nhiệm vụ kỹ thuật phần mềm khác nhau.

Chúng ta có thể thấy rằng đây là một số lượng tương đối lớn các nghiên cứu định hướng Tạo Mã với 24 bài báo; ngược lại, định hướng Dịch Mã là ít nhất, với 3 bài báo. Số lượng bài báo trong 6 nhiệm vụ kỹ thuật phần mềm còn lại tương tự nhau, với ít nhất là công việc định hướng Quản lý Mã, với 6 bài báo. Và các nhiệm vụ định hướng Phát hiện Lỗ hổng là nhiều nhất với 17 bài báo. Chi tiết của các nhiệm vụ này được trình bày trong phần 4.

Đối với câu trả lời cho (2), chúng tôi tập trung vào việc đọc xem các bài báo có cung cấp ý kiến quan trọng hoặc rõ ràng về hiệu suất của LLM trong kỹ thuật phần mềm hay không. Đặc biệt, chúng tôi kiểm tra các nghiên cứu trường hợp thực nghiệm và các bài báo khảo sát trong vấn đề này.

12

--- TRANG 13 ---
Bảng 4 Thu thập Dữ liệu cho mỗi RQ.

RQs Loại Dữ liệu Chúng tôi Thu thập
RQ1 Các công trình hiện tại tập trung vào việc kết hợp LLMs và kỹ thuật phần mềm là gì? Chẳng hạn như tóm tắt mã, dịch mã, tạo mã, tương tác với các nhà phát triển phần mềm, v.v.
RQ2 LLMs có thực sự giúp thực hiện tốt hơn các nhiệm vụ kỹ thuật phần mềm hiện tại không? Chẳng hạn như tình trạng hiệu suất, khuyết điểm, tiềm năng, hoàn thành, thiếu sót, v.v.

4 LLMs trong Các Nhiệm vụ Kỹ thuật Phần mềm

Trong phần này, chúng tôi chủ yếu trả lời RQ1. Chúng tôi phân loại công việc được thu thập thành bảy danh mục dựa trên các nhiệm vụ khác nhau, và sau đó cung cấp giải thích riêng biệt cho mỗi danh mục, như được thể hiện trong Bảng 5.

Trong bài báo này, chúng tôi coi các mô hình có số lượng tham số lớn hơn hoặc bằng 0,8 tỷ (0,8b) là Mô hình Ngôn ngữ Lớn (LLMs). Chúng tôi đến định nghĩa này dựa trên điều tra của chúng tôi về phần lớn các bài báo LLM mã nguồn mở từ ICSE 2024, như được thể hiện trong Bảng 6. Chúng ta có thể thấy rằng, ngoại trừ các mô hình của OpenAI, không phải mã nguồn mở, chúng tôi không thể xác định số lượng tham số của chúng. Trong số các mô hình mã nguồn mở, mô hình có số lượng tham số nhỏ nhất là Flan-T5-small, với 80 triệu (80M) tham số. Do đó, chúng tôi đã định nghĩa LLM dựa trên mô hình này làm tiêu chuẩn. Trong số các bài báo được đánh giá đồng đẳng mà chúng tôi điều tra, số lượng tham số nhỏ nhất được sử dụng cho LLM là 80M ((Ma et al., 2024a), Flan-T5-small).

4.1 Tạo Mã

Định nghĩa: Tạo mã, còn được gọi là tổng hợp chương trình, là quá trình tự động tạo mã nguồn dựa trên yêu cầu của người dùng và các ràng buộc được chỉ định (Chen et al., 2023a). Trong hầu hết các trường hợp, nó liên quan đến việc chuyển đổi văn bản thành mã. Khi áp dụng LLM để tạo mã, LLM sẽ tự động tạo mã dựa trên các yêu cầu được cung cấp bởi người dùng. Cần lưu ý rằng hoàn thành mã, tái cấu trúc mã, và tăng cường mã cũng thuộc về danh mục các nhiệm vụ tạo mã.

Tạo mã truyền thống thường bao gồm hai bước: đầu tiên, phân tích các yêu cầu và ràng buộc của người dùng và chuyển đổi chúng thành một biểu diễn trung gian, chẳng hạn như cây cú pháp trừu tượng (AST) (Hu et al., 2023b) hoặc biểu diễn trung gian (IR) (Li et al., 2022d); sau đó, tạo mã đích dựa trên biểu diễn trung gian này. Bước đầu tiên là hiểu yêu cầu, bao gồm việc chuyển đổi ngôn ngữ tự nhiên thành một biểu diễn chính thức, có thể hiểu được bởi máy tính; bước thứ hai là tổng hợp mã,

13

--- TRANG 14 ---
Bảng 5 Định nghĩa của Bảy Loại Nhiệm vụ Kỹ thuật Phần mềm và Vai trò của LLMs.

Nhiệm vụ Định nghĩa Vai trò có thể của LLMs
Tạo Mã Tự động tạo mã nguồn dựa trên yêu cầu của người dùng và các ràng buộc được chỉ định. Bao gồm hoàn thành mã, tăng cường mã, và các nhiệm vụ liên quan khác. (hỗ trợ) Tạo mã hoặc cung cấp cho các nhà phát triển ý tưởng và 'điểm khởi đầu' lập trình, v.v.
Tóm tắt Mã Tự động tạo các chú thích mã rõ ràng, chính xác, và hữu ích để hỗ trợ các nhà phát triển hiểu và bảo trì mã. Bao gồm các nhiệm vụ như hiểu mã. Tóm tắt mã hỗ trợ với các mức độ chi tiết khác nhau (như các hàm) hoặc giải thích ý định của mã, v.v.
Dịch mã Chuyển đổi mã giữa các ngôn ngữ lập trình khác nhau mà không thay đổi chức năng hoặc logic của nó. Hỗ trợ chuyển đổi mã, Kỹ thuật ngược, v.v.
Phát hiện Lỗ hổng Xác định và sửa các lỗi mã có thể gây ra sự cố chương trình, suy giảm hiệu suất, hoặc vấn đề bảo mật. Bao gồm các nhiệm vụ như khai thác lỗ hổng, khắc phục lỗ hổng và kiểm thử mã. Kiểm tra các lỗ hổng tiềm ẩn trong mã, v.v.
Đánh giá Mã Thực hiện phân tích tĩnh trên mã để xác định các vấn đề tiềm ẩn và điểm cải thiện. Bao gồm các nhiệm vụ như Nhân bản Mã, Mùi Mã, v.v. Tạo các trường hợp kiểm thử hoặc kiểm tra hiệu suất mã, khả năng sử dụng, và các chỉ số khác, v.v.
Quản lý Mã Quản lý thông tin như phiên bản mã và nhà phát triển. Chứa các nhiệm vụ liên quan đến nhật ký Phát triển hợp tác nhóm, kiểm soát phiên bản, v.v
Tương tác Hỏi & Đáp Tương tác giữa các nhà phát triển phần mềm và LLM Trợ lý chương trình, Kỹ thuật prompt, v.v
Công việc khác Một số công việc khác, như nghiên cứu các vấn đề bản quyền và đạo đức trong mã được tạo bởi LLM. Không rõ.

bao gồm việc tạo mã dựa trên biểu diễn này (Jiang et al., 2023a).

Tạo mã phụ thuộc rất nhiều vào tìm kiếm và suy luận, tìm kiếm và lý luận một cách có hệ thống để tìm mã thỏa mãn các yêu cầu đã cho trong toàn bộ không gian mã (Zheng et al., 2023). LLMs đã thể hiện khả năng ấn tượng trong các nhiệm vụ tạo văn bản, thu hút các nỗ lực nghiên cứu đáng kể để đánh giá và cải thiện hiệu suất của LLM trong các nhiệm vụ tạo mã (Li et al., 2023b).

14

--- TRANG 15 ---
Bảng 6 LLM với số lượng tham số tối thiểu của các bài báo trong ICSE 2024.

Bài báo LLM với số lượng tham số tối thiểu trong bài báo
(Ma et al., 2024b) Flan-T5-small-80M
(Xu et al., 2024a) text-embedding-babbage-001
(Jiang et al., 2023b) GPT-3.5
(Geng et al., 2023) code-davinci-002
(Li et al., 2023g) codet5-base-232M
(Yang et al., 2023c) CodeParrot-small-110M
(Ding et al., 2023) UnixCoder
(Choudhuri et al., 2023) ChatGPT
(Guo et al., 2023) ChatGPT
(Pan et al., 2024) GPT-4
(Yang et al., 2023a) CodeGen-Multi-16B
(Zhang et al., 2024) PanGu-Coder-300M
(Liu et al., 2023f) ChatGPT
(Feng and Chen, 2023) ChatGPT
(Xu et al., 2024b) GPT-3
(Ahmed et al., 2024) code-davinci-002

Những nỗ lực nghiên cứu này có thể được phân loại thô vào hai chủ đề chính. Chủ đề đầu tiên chủ yếu đánh giá hoặc thảo luận về khả năng của LLMs trong các nhiệm vụ tạo mã hoặc các ngữ cảnh cụ thể của tạo mã (Houde et al., 2022; Sarsa et al., 2022; Buscemi, 2023a,b). Các góc độ đánh giá khác nhau, với một số tập trung vào tính chính xác của tạo mã trong các ngôn ngữ lập trình khác nhau (Bareiß et al., 2022; Thakur et al., 2023a; Kande et al., 2023), trong khi những nghiên cứu khác đề xuất các khung benchmark mới hoặc phương pháp kiểm thử để đánh giá tốt hơn mã được tạo bởi LLMs (Liu et al., 2023b; Vaithilingam et al., 2022), cung cấp hướng dẫn để cải thiện LLMs trong nhiệm vụ này.

Tuy nhiên, điều quan trọng cần lưu ý là không có công nghệ hiện tại nào, bao gồm cả LLMs, có thể đảm bảo rằng mã được tạo tự động luôn hoàn toàn có thể sử dụng được, vì có thể có các lỗi rõ ràng hoặc tinh vi trong mã. Do đó, chủ đề thứ hai của những nỗ lực nghiên cứu này là nâng cao khả năng tạo mã của LLMs. Điều này bao gồm tự động sửa lỗi trong mã được tạo bởi LLMs (Ni et al., 2023; Jain et al., 2022b; Dinh et al., 2023), cải thiện chất lượng mã được tạo bởi LLMs (Zhang et al., 2023a; Wang et al., 2023d; Barke et al., 2023a; Mouselinos et al., 2023; Lahiri et al., 2022; Dong et al., 2023; Jiang et al., 2023a), giải quyết các mối quan tâm về bảo mật và độ tin cậy (Poesia et al., 2022; Zhu and Zhang, 2023; Ke et al., 2023), nâng cao hiệu quả của tạo mã LLM (Li et al., 2023e; Wang et al., 2023b; Murali et al., 2023; Weyssow et al., 2023; Zhong and Wang, 2023; Tanaka et al., 2023),

15

--- TRANG 16 ---
kỹ thuật watermarking cho tạo mã (Lee et al., 2023; Wang et al., 2023c), và trong số các nghiên cứu khác.

4.2 Tóm tắt Mã

Định nghĩa: Tóm tắt mã là một kỹ thuật quan trọng để hiểu chương trình và tạo tài liệu tự động. Khi sử dụng LLM để tóm tắt mã, mục tiêu chính của nhiệm vụ này là tự động tạo các chú thích mã rõ ràng, chính xác, và hữu ích để hỗ trợ các nhà phát triển hiểu và bảo trì mã. Cần lưu ý rằng các nhiệm vụ tóm tắt mã bao gồm cả nhiệm vụ hiểu mã và tóm tắt mã.

Tóm tắt mã có thể được thực hiện ở các mức độ chi tiết khác nhau, chẳng hạn như mức dòng, mức hàm, hoặc mức mô-đun. Các mức tóm tắt khác nhau yêu cầu xử lý thông tin ngữ cảnh khác nhau. Ví dụ, tóm tắt mức hàm có thể cần hiểu các đầu vào, đầu ra, chức năng, và mối quan hệ gọi của các hàm, trong khi tóm tắt mức mô-đun có thể yêu cầu hiểu chức năng và giao diện với các mô-đun khác.

Các phương pháp tóm tắt mã truyền thống chủ yếu dựa vào các quy tắc và mẫu, sử dụng các quy tắc và mẫu cụ thể để trích xuất và biểu diễn thông tin chính từ mã. Tuy nhiên, những phương pháp này thường yêu cầu một lượng lớn công việc thủ công và có khả năng thích ứng kém với các ngôn ngữ lập trình và framework mới. Với sự tiến bộ của máy học, các phương pháp tóm tắt mã dựa trên mạng neuron đã nhận được sự chú ý. Những phương pháp này sử dụng mạng neuron để học ánh xạ phức tạp giữa mã và văn bản. Ngoài ra, một số phương pháp sử dụng kiến trúc encoder-decoder, trong đó encoder được sử dụng để hiểu mã nguồn và decoder được sử dụng để tạo mô tả ngôn ngữ tự nhiên.

Việc sử dụng Mô hình Ngôn ngữ Lớn (LLMs) là một hướng nghiên cứu gần đây trong tóm tắt mã. Những mô hình này, chẳng hạn như series GPT của OpenAI, cũng đã nhận được sự chú ý đáng kể trong nhiệm vụ cụ thể của tóm tắt mã. Một số công trình đánh giá khả năng tóm tắt mã của các LLMs khác nhau, chẳng hạn như ChatGPT (Sun et al., 2023), Codex (Sarsa et al., 2022; Leinonen et al., 2023b), GPT-3 (MacNeil et al., 2022c), trong số những công trình khác. Các công trình khác đánh giá khả năng của LLMs trong tóm tắt mã từ các góc độ khác nhau, chẳng hạn như khả năng lý luận nhân quả (Liu et al., 2023d), hiệu quả với huấn luyện tối thiểu (Ahmed and Devanbu, 2022), và khả năng diễn giải (Leinonen et al., 2023a). Mặc dù những công trình này cung cấp kết luận không đầy đủ, chúng thường công nhận tiềm năng mạnh mẽ của LLMs.

Cũng có những công trình sử dụng LLMs để tóm tắt mã để xây dựng tài liệu, tạo các trường hợp kiểm thử, hoặc giải quyết các hạn chế trong tóm tắt mã dựa trên LLM (Khan and Uddin, 2023; Zhang et al., 2023b). Ví dụ, nâng cao tính robust của tóm tắt mã dựa trên LLM (Zhuo et al.,

16

--- TRANG 17 ---
2023) hoặc cải thiện khả năng tương tác với các nhà phát triển (MacNeil et al., 2022a).

4.3 Dịch Mã

Định nghĩa: Dịch mã, còn được gọi là chuyển đổi mã, đề cập đến quá trình chuyển đổi mã giữa các ngôn ngữ lập trình khác nhau mà không thay đổi chức năng hoặc logic của nó. Khi sử dụng LLM để chuyển đổi mã, LLM sẽ lấy mã đã cho và yêu cầu chuyển đổi từ người dùng và chuyển đổi mã sang ngôn ngữ đích.

Các phương pháp dịch mã truyền thống thường yêu cầu công việc thủ công đáng kể, triển khai các quy tắc cú pháp và ngữ nghĩa cụ thể thông qua hard coding. Hơn nữa, đối với các ngôn ngữ lập trình mới hoặc ít phổ biến, có thể cần phải phát triển lại và bảo trì các quy tắc dịch. Hiện tại, khả năng dịch ngôn ngữ tự nhiên ấn tượng được thể hiện bởi LLMs đã được công nhận (Zhang et al., 2023c). Tuy nhiên, có sự tập trung hạn chế vào hiệu suất của LLMs trong các nhiệm vụ chuyển đổi mã trong nghiên cứu hiện tại. Pan et al. (Pan et al., 2023) trình bày một nghiên cứu thực nghiệm quy mô lớn để điều tra khả năng của LLMs, bao gồm LLMs tổng quát và mã, để dịch mã trong năm ngôn ngữ, đó là C, C++, Go, Java, và Python.

Pearce et al. (Pearce et al., 2022b) nghiên cứu khả năng của LLMs trong kỹ thuật ngược phần mềm. Nghiên cứu khám phá khả năng của Codex trong việc xác định mục đích, chức năng, và tên biến hoặc giá trị quan trọng trong mã, do đó đánh giá khả năng decompilation của LLMs. Ngoài ra, Lin et al. (Lin et al., 2022b) đề xuất một phương pháp Biểu diễn Mã Liên ngôn ngữ với tiền huấn luyện quy mô lớn (XCode) và tiếp tục giới thiệu kiến trúc Shared Encoder-Decoder (SED).

Hiện tại, có tương đối ít nghiên cứu về LLMs trong các nhiệm vụ dịch mã, và việc áp dụng LLMs vào các nhiệm vụ dịch mã vẫn phải đối mặt với nhiều thách thức. Thứ nhất, tính chính xác và độ chính xác của mã là rất quan trọng, vì ngay cả những lỗi dịch nhỏ cũng có thể khiến mã được tạo ra không hoạt động. Thứ hai, việc thu thập một lượng lớn các cặp mã nguồn và mã đích chất lượng cao là thách thức, điều này có thể hạn chế khả năng học và tổng quát hóa của mô hình. Thứ ba, cần nghiên cứu thêm về việc đánh giá hiệu suất của các mô hình dịch mã, vì trong nhiều trường hợp, có thể có nhiều triển khai khác nhau của cùng một chức năng trong mã. Những vấn đề này yêu cầu khám phá và giải quyết thêm trong nghiên cứu tương lai.

4.4 Phát hiện và Sửa chữa Lỗ hổng

Định nghĩa: Phát hiện và sửa chữa lỗ hổng mã là một nhiệm vụ quan trọng trong lĩnh vực kỹ thuật phần mềm, rất quan trọng để cải thiện độ tin cậy và bảo mật của phần mềm. Mục tiêu chính của nhiệm vụ này là xác định và sửa các

17

--- TRANG 18 ---
lỗi mã có thể gây ra sự cố chương trình, suy giảm hiệu suất, hoặc vấn đề bảo mật. Khi sử dụng LLM để phát hiện lỗ hổng, LLM phân tích mã đích để tìm lỗ hổng, cung cấp báo cáo lỗ hổng, hoặc sửa các lỗ hổng được phát hiện. Đáng chú ý là trong phạm vi định nghĩa của bài báo này, các nhiệm vụ như khai thác lỗ hổng và tạo trường hợp kiểm thử cũng thuộc về nhiệm vụ này.

Do tầm quan trọng của nhiệm vụ này, các phương pháp phát hiện dựa trên phần mềm và phần cứng khác nhau đã được phát triển. Các phương pháp phát hiện lỗ hổng truyền thống chủ yếu bao gồm phân tích tĩnh và phân tích động. Phân tích tĩnh phân tích mã nguồn trước khi thực thi chương trình để xác định các lỗi và lỗ hổng tiềm ẩn, trong khi phân tích động phân tích hành vi chương trình trong thời gian chạy để xác định các lỗi và lỗ hổng thực tế. Những phương pháp này có ưu điểm và nhược điểm riêng: phân tích tĩnh có thể bao phủ tất cả các đường dẫn mã nhưng có thể tạo ra một số lượng lớn false positives, trong khi phân tích động có thể chính xác chỉ ra các lỗi thực tế nhưng có thể bỏ sót các lỗi không được kích hoạt trong các trường hợp kiểm thử.

Gần đây, LLMs đã được sử dụng trong các nhiệm vụ phát hiện và sửa chữa lỗ hổng mã do khả năng hiểu ngữ nghĩa tiên tiến của chúng, hiệu quả trong việc giải quyết các lỗ sai logic và vấn đề ngôn ngữ trong ngôn ngữ tự nhiên. Tương tự, trong nhiệm vụ này, nghiên cứu hiện tại có thể được phân loại thô thành ba loại. Loại đầu tiên đánh giá khả năng của các LLMs khác nhau trong nhiệm vụ này (Olausson et al., 2023; Prenner et al., 2022; Pearce et al., 2022a; Madaan et al., 2023; Noever, 2023), ví dụ, Khoury et al. (Khoury et al., 2023) đánh giá bảo mật của ChatGPT trong các nhiệm vụ tạo mã. Loại thứ hai tập trung vào việc cải thiện tính chính xác và hiệu suất của LLMs trong phát hiện lỗ hổng (Xia and Zhang, 2023a,b), chẳng hạn như kết hợp LLMs với các kỹ thuật xác minh chính thức (Charalambous et al., 2023), kết hợp các chỉnh sửa liên quan trước đó (Gupta et al., 2023), thuật toán tự debug (Chen et al., 2023b), trong số những nghiên cứu khác. Loại thứ ba áp dụng LLMs vào khai thác lỗ hổng hoặc các nhiệm vụ liên quan khác (Ahmad et al., 2023b; Chan et al., 2023; Fan et al., 2023b; Xia et al., 2022), bao gồm công việc decompilation (Xu et al., 2023), phân tích bảo mật của thiết kế phần cứng (Ahmad et al., 2023c), và kiểm thử black-box (Li et al., 2023f).

4.5 Đánh giá Mã

Định nghĩa: Đánh giá mã là một nhiệm vụ quan trọng trong kỹ thuật phần mềm giúp đảm bảo chất lượng mã, độ tin cậy, và chức năng mong đợi. Đánh giá mã nhằm thực hiện phân tích tĩnh trên mã để xác định các vấn đề tiềm ẩn và điểm cải thiện. Khi sử dụng LLM để đánh giá mã, LLM phân tích bản chất của mã đã cho dựa trên các yêu cầu, chẳng hạn như phát hiện đạo văn mã hoặc đánh giá việc tuân thủ các tiêu chuẩn coding của mã. Do đó, các nhiệm vụ như nhân bản mã và phát hiện mùi mã cũng thuộc về danh mục này trong phạm vi định nghĩa của bài báo này.

18

--- TRANG 19 ---
Kiểm thử mã liên quan đến việc thực thi mã và kiểm tra xem hành vi của nó có phù hợp với kỳ vọng để xác thực tính chính xác của nó. Tuy nhiên, kiểm thử mã có thể tốn thời gian và lao động. Việc khám phá ứng dụng của LLMs để tự động tạo các trường hợp kiểm thử hiệu quả dựa trên một mã đã cho hoặc trực tiếp đánh giá chất lượng của một mã đã cho đã thu hút sự chú ý nghiên cứu đáng kể.

Trong nghiên cứu hiện tại về việc áp dụng LLMs vào kiểm thử mã, một phần đáng kể công việc tập trung vào tạo trường hợp kiểm thử. Ví dụ, các nghiên cứu thực nghiệm đã khám phá khả năng tạo kiểm thử đơn vị của LLMs như ChatGPT (Yuan et al., 2023; Tang et al., 2023b) hoặc sử dụng LLMs để tạo các trường hợp kiểm thử (Zhao et al., 2023a; Lemieux et al., 2023; Chen et al., 2022a; Tu et al., 2023; Li et al., 2023d).

Ngoài ra, một số công trình đã đề xuất các khung kiểm thử mã sử dụng LLMs dựa trên các tình huống sử dụng khác nhau (Kang et al., 2022; Zhuo, 2023), chẳng hạn như kết hợp LLMs với fuzz testing (Hu et al., 2023a) hoặc kiểm thử black-box (Li et al., 2023f). Hơn nữa, một số ít công trình đã phát triển các trợ lý kiểm thử dựa trên LLM hoặc mô hình kiểm thử mã (Feldt et al., 2023; Lee et al., 2022a).

4.6 Quản lý Mã

Định nghĩa: Quản lý mã là một khía cạnh quan trọng của quá trình phát triển và bảo trì kỹ thuật phần mềm. Khi sử dụng LLM để quản lý mã, LLM phân tích mã đã cho dựa trên các yêu cầu, chẳng hạn như kiểm soát phiên bản (Maruf et al., 2021), quản lý hợp tác (Potluri et al., 2022), và quản lý phát hành mã nguồn trong quá trình phát triển phần mềm (Jing et al., 2021).

Quản lý mã phức tạp và đầy thách thức. Phát triển song song và hợp tác có thể dẫn đến xung đột mã. Hơn nữa, trong các dự án quy mô lớn, quản lý nhánh và lặp phiên bản làm tăng đáng kể độ khó khăn của quản lý mã. Các công cụ quản lý mã truyền thống, chẳng hạn như Git (Escamilla et al., 2023), cung cấp một bộ lệnh và quy tắc mạnh mẽ để xử lý các nhiệm vụ kiểm soát phiên bản và quản lý nhánh. Tuy nhiên, việc sử dụng những công cụ này vẫn yêu cầu các nhà phát triển có chuyên môn, đặc biệt khi xử lý các xung đột merge phức tạp và quản lý nhánh.

Do các thách thức khác nhau trong các nhiệm vụ quản lý mã, một số công trình tiên tiến nhằm tận dụng sức mạnh của LLMs để giảm bớt độ phức tạp của quá trình quản lý mã, và thậm chí đạt được quản lý mã tự động mà không cần can thiệp thủ công (Xiao et al., 2023; Bi et al., 2023). Ví dụ, Toufique et al. (Ahmed et al., 2023) đánh giá hiệu quả của LLMs trong việc hỗ trợ các kỹ sư quản lý các sự cố bảo mật trong dịch vụ đám mây, trong khi Shrivastava et al. (Shrivastava et al., 2023a) giải quyết vấn đề các mô hình LLM gặp khó khăn trong việc hiểu ngữ cảnh có mặt trong các repository. Ngoài ra, một số công trình dựa trên LLMs đã phát triển các công cụ hoặc framework quản lý mã để hỗ trợ

19

--- TRANG 20 ---
các nhà quản lý mã, hỗ trợ trong quản lý phiên bản (Gao et al., 2023) và đào tạo nhân sự (Lanciano. et al., 2023).

4.7 Tương tác Hỏi & Đáp

Định nghĩa: Tương tác giữa con người và công cụ luôn là một trọng tâm trong lĩnh vực kỹ thuật phần mềm, vì tương tác tốt có thể nâng cao hiệu suất công việc (Xu et al., 2017). Việc ứng dụng và nghiên cứu rộng rãi của LLM đã dẫn đến sự xuất hiện của nhiệm vụ này như một lĩnh vực nghiên cứu tương đối độc lập. Trong phạm vi được định nghĩa trong bài báo này, kỹ thuật prompt cũng được coi là một phần của nhiệm vụ này.

Trước khi LLMs được ứng dụng rộng rãi, một cách quan trọng để các nhà phát triển có được thông tin và giải quyết vấn đề là thông qua các trang web Hỏi & Đáp, ví dụ, Stack Overflow⁸ (Zhang et al., 2022b). Sự xuất hiện của LLMs đã thay đổi điều này bằng cách có thể trả lời các câu hỏi của người dùng, bao gồm kiến thức chuyên môn trong kỹ thuật phần mềm. Là một công cụ mới đầy hứa hẹn để giúp các nhà phát triển giải quyết các vấn đề mã, LLMs cũng đã tạo ra nhiều nghiên cứu về cách cải thiện hiệu quả và thuận tiện của Tương tác Hỏi & Đáp (Gao et al., 2022). Hơn nữa, vì đầu ra được tạo bởi LLMs bị ảnh hưởng bởi cấu trúc và nội dung của các prompt do người dùng cung cấp, nghiên cứu về prompt, được biết đến như kỹ thuật prompt (White et al., 2023a).

Điều quan trọng cần lưu ý là phần này tập trung vào các điều tra liên quan đến Tương tác Hỏi & Đáp và kỹ thuật prompt trong bối cảnh kỹ thuật phần mềm.

Nhóm công việc này cũng có thể được phân loại thành hai loại chính. Loại đầu tiên tập trung vào tương tác giữa các chuyên gia phần mềm (nhà phát triển, người mới bắt đầu, v.v.) và LLMs, và bao gồm việc phát triển các hệ thống prototype hoặc framework tương tác (Ross et al., 2023; Zamfirescu-Pereira et al., 2023; Cai et al., 2023). Trong số đó, Zamfirescu-Pereira et al. (Zamfirescu-Pereira et al., 2023) thảo luận về vai trò của các chuyên gia không phải AI trong "kỹ thuật cue của người dùng" và thiết kế BotDesigner, một công cụ thiết kế chatbot dựa trên cue; Ross et al. (Ross et al., 2023) thể hiện vai trò và tiềm năng của tương tác nhà phát triển-LLM cho các quy trình như phát triển phần mềm, thông qua phỏng vấn 42 nhà phát triển phần mềm; và Cai et al. (Cai et al., 2023) mô tả Low-code LLM, một framework cho tương tác người-LLM, để hỗ trợ tốt hơn lập trình trực quan.

Loại thứ hai bao gồm công việc định hướng nghiên cứu, có thể được chia thêm thành nhiều hướng. Hướng đầu tiên đánh giá tương tác giữa LLMs và các nhà phát triển phần mềm (Barke et al., 2023b), chẳng hạn như liệu LLMs có giải quyết các phần tương tự của mô tả ngôn ngữ tự nhiên như các nhà phát triển (Kou et al., 2023), hoặc liệu chúng có thể hoạt động như một DevBot (Ahmad et al., 2023a).

⁸www.stackoverflow.com/

20

--- TRANG 21 ---
Hướng thứ hai chủ yếu tập trung vào kỹ thuật prompt (White et al., 2023b,a; Shrivastava et al., 2023b), nhằm thiết kế các định dạng prompt hiệu quả hơn hoặc tự động điền nội dung prompt dựa trên các subtask và mục tiêu khác nhau. Hướng thứ ba giải quyết các vấn đề bảo mật và hiệu quả trong tương tác LLM với các nhà phát triển (Sarkar et al., 2022; Sandoval et al., 2023).

4.8 Công việc khác

Ngoài các chủ đề nói trên, có những công việc khác kết hợp LLMs với kỹ thuật phần mềm. Những công việc này hoặc thảo luận hiệu suất của LLMs trong các subtask cụ thể (Ozkaya, 2023; Sadik et al., 2023; Xing et al., 2023), chẳng hạn như trực quan hóa (Maddigan and Susnjak, 2023), trích xuất thông tin (Li et al., 2023a,c), và mô hình hóa (Nichols et al., 2023), đề xuất giải pháp riêng cho các vấn đề hiện có, chẳng hạn như giải quyết các vấn đề hiệu suất (Jain et al., 2023), phát triển công cụ hoặc datasets, chẳng hạn như datasets mã-văn bản (Manh et al., 2023; Liu et al., 2023c), hoặc xác định các vấn đề liên quan đến LLMs (Treude and Hata, 2023; Khlaaf et al., 2022). Ngoài ra, một số công việc tập trung vào khám phá tiềm năng và ứng dụng của LLMs trong lĩnh vực giáo dục (MacNeil et al., 2022b).

5 Hiệu suất của LLM trong Các Nhiệm vụ SE

Trong phần này, chúng tôi chủ yếu thảo luận RQ2. Đầu tiên, chúng tôi sàng lọc các bài báo từ bộ sưu tập của chúng tôi đánh giá hiệu suất của LLMs trong các nhiệm vụ kỹ thuật phần mềm. Tiếp theo, chúng tôi trích xuất các LLMs được sử dụng và các nhiệm vụ kỹ thuật phần mềm được nhắm mục tiêu trong những công trình này. Cuối cùng, một số công trình trong Phần 4 cũng đánh giá và thảo luận hiệu suất của LLMs trong một số nhiệm vụ cụ thể. Do đó, chúng tôi sẽ tóm tắt những công trình này ở đây và nhấn mạnh kết quả đánh giá của chúng.

Một phần đáng kể công việc đã được thực hiện đã phân tích thực nghiệm hiệu suất của ChatGPT, một trong những mô hình LLM phổ biến nhất, như một trợ lý lập trình (Tian et al., 2023; Sridhara et al., 2023; Li et al., 2023d; Liu et al., 2023a). Những nghiên cứu này đã phát hiện rằng hiệu suất của ChatGPT khác nhau giữa các nhiệm vụ khác nhau. Ví dụ, nó hoạt động tốt trong các nhiệm vụ như tóm tắt nhật ký, giải quyết tham chiếu, và tóm tắt mã, nhưng gặp khó khăn trong phát hiện lỗ hổng và tạo trường hợp kiểm thử. Đặc biệt trong phát hiện lỗ hổng, ChatGPT gặp khó khăn trong việc xác định sự khác biệt mã tinh vi khi hai phiên bản có cú pháp tương tự (Li et al., 2023d). Trong một số nhiệm vụ như Text-to-SQL (Liu et al., 2023a), trả lời các câu hỏi kiểm thử phần mềm (Jalil et al., 2023), và tạo trường hợp kiểm thử (Tang et al., 2023b), mặc dù ChatGPT không đạt được hiệu suất xuất sắc, các tác giả vẫn duy trì quan điểm tích cực. Một số nghiên cứu cũng làm nổi bật các hạn chế của phạm vi attention của ChatGPT (Sridhara et al., 2023).

Hơn nữa, một số công trình phân tích hiệu suất của ChatGPT trong các nhiệm vụ kỹ thuật phần mềm từ các góc độ khác nhau. Ví dụ, Ma et al. (Ma et al.,

21

--- TRANG 22 ---
Bảng 7 Phần 1 - Sự tự tin của tác giả về LLMs trong các nhiệm vụ kỹ thuật phần mềm.

Bài báo Nguồn LLM(s) Chủ đề đánh giá Sự tự tin của tác giả
(Tian et al., 2023) preprint ChatGPT tạo mã, sửa chữa chương trình, và tóm tắt mã Sự tự tin cao
(Sridhara et al., 2023) preprint ChatGPT 15 nhiệm vụ kỹ thuật phần mềm thông thường Làm tốt: tóm tắt nhật ký, phân tích đại từ, tóm tắt mã (tạo tên phương thức) phát hiện nhân bản mã, v.v Không làm tốt: phát hiện lỗ hổng mã, v.v
(Ma et al., 2023) preprint ChatGPT hiểu cú pháp, hiểu hành vi tĩnh, hiểu hành vi động, khả năng hiểu cú pháp mã, và khả năng hiểu cấu trúc ngữ nghĩa Làm tốt: Hiểu cú pháp mã Không làm tốt: Hiểu ngữ nghĩa mã
(Hellas et al., 2023) preprint Codex, và GPT-3.5 diễn giải mã Sự tự tin cao
(Li et al., 2023d) preprint ChatGPT phát hiện khuyết điểm mã Sự tự tin thấp
(Pearce et al., 2022b) preprint Codex kỹ thuật ngược phần mềm Sự tự tin thấp
(gangz, 2023) preprint ChatGPT tạo trường hợp kiểm thử Sự tự tin cao
(Pearce et al., 2022a) preprint Codex phát hiện khuyết điểm mã Sự tự tin thấp
(Bareiß et al., 2022) preprint Codex tạo mã Sự tự tin cao
(Tang et al., 2023b) preprint ChatGPT tạo trường hợp kiểm thử Sự tự tin thấp
(Sarsa et al., 2022) ICER Codex diễn giải mã Sự tự tin cao
(Jalil et al., 2023) ICSTW ChatGPT kiểm thử phần mềm Sự tự tin cao
(Savelka et al., 2023) preprint GPT-4 tạo mã Sự tự tin cao và tiến bộ rõ ràng

22

--- TRANG 23 ---
Bảng 8 Phần 2 - Sự tự tin của tác giả về LLMs trong các nhiệm vụ kỹ thuật phần mềm.

Bài báo Nguồn LLM(s) Chủ đề đánh giá Sự tự tin của tác giả
(Zhuo et al., 2023) preprint Codex diễn giải mã Sự tự tin thấp (tính robust)
(Feiyu, 2023) preprint GPT-4 phân tích mã Sự tự tin thấp
(Fan et al., 2023b) preprint Codex sửa chữa chương trình Sự tự tin cao
(Xia et al., 2022) preprint GPT-Neo-125M/1.3B/2.7B, GPT-J-6.7B, GPT-NeoX-20B, Codex-12B, CodeT5-220M và INCODER-1.3B/6.7B sửa chữa chương trình Sự tự tin cao
(Shirafuji et al., 2023) preprint Codex-12B, CodeGen-16B, InstructGPT, và ChatGPT tạo mã Sự tự tin thấp (tính robust)
(Feng et al., 2023) ISAC ChatGPT tạo mã Mơ hồ
(Kande et al., 2023) preprint code-davinci-002 tạo mã Sự tự tin thấp
(Thakur et al., 2023b) DATE CodeGen-2B/6B/16B, và Codex tạo mã Sự tự tin thấp
(Khoury et al., 2023) preprint ChatGPT tạo mã Sự tự tin cao
(Prenner et al., 2022) IWAPR Codex sửa chữa chương trình Sự tự tin cao
(Vaithilingam et al., 2022) CHI Codex sửa chữa chương trình Sự tự tin thấp
(Liu et al., 2023a) preprint ChatGPT Text-to-SQL Sự tự tin cao
(Rajkumar et al., 2022) preprint Codex Text-to-SQL Sự tự tin cao
(Noever, 2023) preprint GPT-4 Phát hiện lỗ hổng Sự tự tin cao

23

--- TRANG 24 ---
Bảng 9 Datasets và metric đánh giá trong các bài báo.

Bài báo Dataset Metric đánh giá
(Tian et al., 2023) Leetcode+Refactory Tỷ lệ chính xác
(Sridhara et al., 2023) Multi-dataset Tỷ lệ thành công
(Ma et al., 2023) Dataset mới Hiệu quả
(Hellas et al., 2023) Dataset mới Tỷ lệ thành công
(Li et al., 2023d) QuixBugs Tỷ lệ chính xác
(Pearce et al., 2022b) Program Source Templates Tỷ lệ chính xác
(gangz, 2023) Nghiên cứu ví dụ Hiệu quả
(Pearce et al., 2022a) CWE-787&89+ExtractFix Hiệu quả
(Bareiß et al., 2022) MeMo+ Dataset mới Tỷ lệ chính xác
(Tang et al., 2023b) Defects4J+Dataset mới Tỷ lệ chính xác, Tính robust
(Sarsa et al., 2022) Dataset mới Hợp lý, Mới lạ, Giải pháp
(Jalil et al., 2023) Dataset mới Tỷ lệ chính xác
(Savelka et al., 2023) MCQ Tỷ lệ chính xác
(Zhuo et al., 2023) AdvGLUE+GeoQuery+Scholar Tính robust
(Feiyu, 2023) Nghiên cứu ví dụ Tỷ lệ chính xác
(Fan et al., 2023b) LMdefects Hiệu quả, Tỷ lệ chính xác, Tính robust
(Xia et al., 2022) Defects4J+QuixBugs+ManyBugs Tỷ lệ chính xác
(Shirafuji et al., 2023) AOJ Tỷ lệ giải quyết
(Feng et al., 2023) Dataset mới Chất lượng
(Kande et al., 2023) Bộ benchmark mới Hiệu quả (Điểm)
(Thakur et al., 2023b) Dataset mới Chất lượng
(Khoury et al., 2023) Dataset mới Bảo mật
(Prenner et al., 2022) QuixBugs Tỷ lệ chính xác
(Vaithilingam et al., 2022) CWE-787&89+HumanEval Hiệu quả
(Liu et al., 2023a) 9 dataset Hiệu quả
(Rajkumar et al., 2022) GeoQuery+Scholar Tỷ lệ chính xác
(Noever, 2023) Dataset mới Hiệu quả (Điểm)

2023) điều tra sự hiểu biết của ChatGPT về cú pháp mã và cấu trúc ngữ nghĩa, kết luận rằng mặc dù ChatGPT xuất sắc trong việc hiểu cú pháp mã (ví dụ, Cây Cú pháp Trừu tượng), nó gặp khó khăn trong việc hiểu ngữ nghĩa mã, đặc biệt là ngữ nghĩa động. Feng et al. (Feng et al., 2023) khám phá khả năng tạo mã của ChatGPT thông qua việc phân tích các bình luận trên Twitter và Reddit, kiểm tra quan điểm của mọi người về khả năng tạo mã của ChatGPT.

Cũng có những đánh giá chi tiết về hiệu suất của LLMs trong các nhiệm vụ cụ thể, chẳng hạn như kỹ thuật ngược (Pearce et al., 2022b), giải thích mã (Zhuo et al., 2023), phân tích mã (Feiyu, 2023), và sửa chữa lỗ hổng (Pearce et al., 2022a). Những nghiên cứu này thường đưa ra những kết luận quan trọng hơn, cho rằng LLMs vẫn còn thua kém các phương pháp tiên tiến nhất trong những nhiệm vụ này. Tuy nhiên, hai công trình đánh giá LLMs trong sửa chữa chương trình tự động (Fan et al., 2023b; Xia et al., 2022) trình bày những phát hiện rất tích cực. Ngoài ra, một số đánh giá về các nhiệm vụ cụ thể đưa ra kết luận tích cực hơn hoặc khẳng định tiềm năng của LLMs trong những nhiệm vụ đó, chẳng hạn như tạo mã (Vaithilingam et al., 2022; Kande et al., 2023; Thakur et al., 2023b) và sửa lỗi (Prenner et al., 2022). (gangz, 2023) đánh giá khả năng của các mô hình lớn trong việc tạo các trường hợp kiểm thử

24

--- TRANG 25 ---
Bảng 10 Mô hình và Cấu trúc mô hình trong các bài báo.

Mô hình Cấu trúc mô hình
Codex Decoder-Only (Causal Decoder)
ChatGPT/GPT-3.5 Decoder-Only (Causal Decoder)
GPT-4 Decoder-Only (Causal Decoder)
GPT-Neo Decoder-Only (Causal Decoder)
GPT-J Decoder-Only (Causal Decoder)
GPT-NeoX Decoder-Only (Causal Decoder)
CodeT5 Encoder-decoder
INCODER Encoder-decoder
CodeGen Decoder-Only (Causal Decoder)
InstructGPT Decoder-Only (Causal Decoder)
Flan-T5 Encoder-decoder
UnixCoder Encoder-decoder

trên một trò chơi đơn giản, báo cáo kết quả tích cực. (Bareiß et al., 2022) thừa nhận hiệu suất của LLMs trong khả năng tạo mã.

Hơn nữa, một phần đáng kể nghiên cứu đánh giá hiệu suất của LLMs trong giáo dục và các khóa học lập trình (Leinonen et al., 2023a; Hellas et al., 2023; Sarsa et al., 2022; Savelka et al., 2023), với phản hồi tích cực. Ngoài ra, so với GPT-3, GPT-4 đã có những tiến bộ đáng kể (Savelka et al., 2023).

Một số ít công trình tập trung vào các vấn đề tính robust và bảo mật của LLMs trong việc giải quyết các vấn đề lập trình (Shirafuji et al., 2023; Khoury et al., 2023), và họ cũng đã có những phát hiện quan trọng.

Chúng tôi tổ chức các kết luận rút ra từ công việc ở trên, như được thể hiện trong Bảng 7 và Bảng 8.

Chúng tôi chủ yếu sàng lọc kết quả đánh giá từ các phần tóm tắt và kết luận của các bài báo. Do sự không nhất quán trong phương pháp và tiêu chí đánh giá LLMs giữa các bài báo khác nhau, chúng tôi không thể chuẩn hóa trực tiếp việc đánh giá hiệu suất của một LLM. Chúng tôi chuyển đổi kết quả từ các bài báo gốc thành "sự tự tin của tác giả" về hiệu suất của LLMs trong việc hoàn thành các nhiệm vụ SE. Chúng tôi phân loại kết quả thành: Sự tự tin cao, Sự tự tin thấp và Mơ hồ. Tức là, nếu các tác giả coi hiệu suất của LLMs là tốt, đó là "Sự tự tin cao"; nếu các tác giả coi hiệu suất của LLMs là hạn chế, đó là "Sự tự tin thấp"; Nếu các tác giả không thể xác định hiệu suất của LLM, thì đó là "Mơ hồ".

Đáng chú ý là Sự tự tin của tác giả và :::::::Sự :::tự:::::::tin ::::của::::::::tác:::::giả tương ứng chỉ ra rằng, mặc dù (các) LLM được đánh giá trong bài báo không nhận được Sự tự tin cao về nhiệm vụ, bài báo vẫn cung cấp thái độ tích cực đối với tiềm năng tương lai của nó; và rằng mặc dù LLMs hiện đang hoạt động tốt, vẫn có những hạn chế hoặc thậm chí không đủ tốt.

25

--- TRANG 26 ---
Ngoài ra, chúng tôi đã trình bày các datasets và metrics đánh giá được sử dụng trong các bài báo nói trên, như được thể hiện trong Bảng 9.

Từ bảng và các bài báo trên, chúng ta có thể đến một kết luận sơ bộ:

Phát hiện
• Tạo mã, là một nhiệm vụ đầy thách thức, các LLMs hiện tại thường không đạt được mức "sẵn sàng sử dụng". Sự tự tin của tác giả đối với LLMs trong nhiệm vụ này là không đủ. Tuy nhiên, đáng khích lệ, một số bài báo (Kande et al., 2023; Thakur et al., 2023b), mặc dù kết luận đánh giá không khẳng định LLMs, vẫn đưa ra thái độ tích cực;

• Về các nhiệm vụ như sửa chữa chương trình, Text-to-SQL, các tác giả thường có sự tự tin cao về hiệu suất của LLMs.

• Trong phát hiện lỗ hổng chương trình, các tác giả thường có sự tự tin thấp về hiệu suất của LLMs.

• Mặc dù có sự mâu thuẫn trong kết luận của (gangz, 2023) và (Tang et al., 2023b) về LLMs trong nhiệm vụ tạo trường hợp kiểm thử, cả hai đều bày tỏ thái độ tương đối tích cực, vẫn tin rằng LLMs có tiềm năng trong nhiệm vụ này;

• Trong các nhiệm vụ như tóm tắt mã và giải thích mã, LLMs thường hoạt động tốt, nhưng thiếu tính robust;

• Theo kết quả của (Savelka et al., 2023), các LLMs mới hơn đã có những cải tiến đáng kể trong nhiệm vụ tạo mã.

Tóm lại, chúng ta có thể đến một kết luận cơ bản: LLMs hoạt động tốt và nhận được sự tự tin cao từ các tác giả về một số nhiệm vụ kỹ thuật phần mềm đòi hỏi hiểu biết về cú pháp mã, chẳng hạn như tóm tắt mã và sửa chữa mã; về một số nhiệm vụ đòi hỏi hiểu biết về ngữ nghĩa mã, chẳng hạn như tạo mã và phát hiện lỗ hổng, chúng thường không hoạt động đủ tốt; LLMs tiếp tục cải thiện với việc lặp lại các phiên bản/mô hình, và vẫn sở hữu tiềm năng lớn.

Do đó, ở giai đoạn hiện tại, LLMs vẫn không thể hoàn toàn đạt được mức độ của các lập trình viên con người chuyên nghiệp trong việc xử lý các nhiệm vụ kỹ thuật phần mềm, nhưng chúng có thể phục vụ như những trợ lý cho các nhà phát triển phần mềm, chẳng hạn như trả lời các câu hỏi phát triển và cung cấp các ví dụ mã.

6 Công việc liên quan

6.1 Các công trình khác về đánh giá LLM

Tiềm năng to lớn của LLM đã thu hút nhiều điều tra về các ứng dụng của nó, hoặc trong lĩnh vực LLM bản thân hoặc trong các lĩnh vực cụ thể. Trong phần này, chúng tôi sẽ trình bày những nỗ lực nghiên cứu này và giải thích sự khác biệt của chúng so với công việc của chúng tôi. Công việc của chúng tôi tập trung vào việc điều tra, phân tích, và biên soạn có hệ thống tiến trình nghiên cứu của LLM trong bối cảnh các nhiệm vụ kỹ thuật phần mềm.

Zhao et al. (Zhao et al., 2023b) là một bài báo chi tiết giới thiệu kiến thức nền tảng, lịch sử phát triển, lộ trình kỹ thuật, và những tiến bộ mới nhất của Mô hình Ngôn ngữ Lớn (LLM). Bài báo chủ yếu tập trung vào các mô hình quy mô lớn (với kích thước lớn hơn 10B) và không bao gồm các mô hình ngôn ngữ tiền huấn luyện sớm như BERT và GPT-2. Nghiên cứu chủ yếu xoay quanh bốn khía cạnh chính của LLM: tiền huấn luyện, fine-tuning, ứng dụng, và đánh giá hiệu suất. Ngoài ra, tác giả coi một số nhiệm vụ trong lĩnh vực kỹ thuật phần mềm như khả năng cơ bản của LLM, ví dụ, coi Tổng hợp Mã như một phần của khả năng Tạo Ngôn ngữ. Do đó, bài báo không đi sâu vào thảo luận và tóm tắt toàn diện về ứng dụng, hiệu suất, và hạn chế của LLM trong các nhiệm vụ kỹ thuật phần mềm.

Gozalo-Brizuela et al. (Gozalo-Brizuela and Garrido-Merchan, 2023), mặt khác, phân loại các mô hình AI tạo sinh dựa trên định dạng đầu vào và đầu ra của chúng, chia chúng thành chín danh mục như được thể hiện trong Bảng 11. Bài báo thể hiện khả năng của các mô hình AI tạo sinh thông qua những phân loại này. Mặc dù tác giả tin rằng những mô hình này sở hữu sự sáng tạo và tiềm năng đáng kể, ông cũng thừa nhận nhiều ràng buộc mà chúng phải đối mặt, đặc biệt về mặt thu thập dữ liệu. Ngoài ra, mối quan tâm được nêu ra về việc tiêu thụ tài nguyên tính toán đáng kể trong quá trình huấn luyện và chi phí thời gian xây dựng mô hình. Mặc dù tóm tắt khả năng của một số mô hình AI tạo sinh, bài báo không tập trung vào LLM, cũng không thảo luận hiệu suất của LLM trong các nhiệm vụ cụ thể, bao gồm cả các nhiệm vụ kỹ thuật phần mềm.

Bảng 11 Một phân loại học các mô hình AI tạo sinh phổ biến nhất trong (Gozalo-Brizuela and Garrido-Merchan, 2023)

Danh mục mô hình AI tạo sinh Ví dụ
Mô hình Text-to-image DALL·E 2, IMAGEN, Muse
Mô hình Text-to-3D Dreamfusion, Magic3D
Mô hình Image-to-Text Flamingo, VisualGPT
Mô hình Text-to-Video Phenaki, Soundify
Mô hình Text-to-Audio AudioLM, Jukebox, Whisper
Mô hình Text-to-Text ChatGPT, LaMDA, PEER
Mô hình Text-to-Code Codex, Alphacode
Mô hình Text-to-Science Galactica, Minerva
Mô hình khác AlphaTensor, GATO, ChatBCG

27

--- TRANG 28 ---
Liu et al. (Liu et al., 2023e) cung cấp một đánh giá toàn diện về ChatGPT và GPT4, làm nổi bật các ứng dụng tiềm năng và đóng góp của chúng trong lĩnh vực Xử lý Ngôn ngữ Tự nhiên (NLP). Trong khi đó, nó phác thảo một số vấn đề đạo đức tiềm ẩn liên quan đến việc phát triển và sử dụng LLMs, ủng hộ việc tập trung vào giải quyết những mối quan tâm đạo đức này, khám phá các ứng dụng mới, và đảm bảo việc sử dụng có trách nhiệm ChatGPT và GPT-4. Fan et al. (Fan et al., 2023a) tuyên bố rằng họ đã thực hiện phân tích thư mục của hơn 5.000 bài báo nghiên cứu LLM từ năm 2017 đến đầu năm 2023, điều tra các ứng dụng của chúng trong các lĩnh vực khác nhau. Bài báo kêu gọi tăng cường hợp tác giữa các bên liên quan, chẳng hạn như các cơ quan chính phủ, đại học, công ty, nhà cung cấp dịch vụ hạ tầng, v.v., để phát triển và áp dụng LLMs một cách có trách nhiệm.

Wei et al. (Wei et al., 2023) cung cấp một tổng quan toàn diện về các mô hình ngôn ngữ truyền thống (CLMs) và những người kế thừa của chúng, các mô hình ngôn ngữ tiền huấn luyện (PLMs). CLMs được thiết kế để dự đoán xác suất chuỗi ngôn ngữ theo cách nhân quả, trong khi PLMs có thể được fine-tuned cho mô hình hóa chuỗi nhân quả và các ứng dụng downstream. Mặc dù bài báo không đi sâu vào ứng dụng của các mô hình lớn trong lĩnh vực kỹ thuật phần mềm, nó cung cấp một tổng quan xuất sắc về tình trạng hiện tại và tiến trình phát triển của các mô hình lớn, và chỉ ra rõ ràng các hướng nghiên cứu tương lai cho những mô hình này.

Ngoài ra, một số công trình nghiên cứu đã đánh giá và phân tích thực nghiệm việc ứng dụng của LLM trong một lĩnh vực cụ thể hoặc các nhiệm vụ đặc biệt.

Li et al. (Li et al., 2022a) cung cấp một tổng quan về các thành tựu nghiên cứu đại diện trong tạo văn bản dựa trên PLMs, đánh giá các metrics đánh giá khác nhau, thư viện mã nguồn mở, và các ứng dụng phổ biến, với mục đích hỗ trợ các chuyên gia thực hành trong việc đánh giá, lựa chọn, và sử dụng PLMs phù hợp, và đề xuất một số hướng nghiên cứu tương lai. Yang et al. (Yang et al., 2023b) điều tra việc ứng dụng của PLMs dựa trên Transformer cho nhiệm vụ Tạo Văn bản Có kiểm soát (CTG), tóm tắt các ứng dụng điển hình, phương pháp chính, và hệ thống đánh giá của PLMs trong CTG. Min et al. (Min et al., 2023) khám phá ba mô hình xu hướng sử dụng các mô hình ngôn ngữ tiền huấn luyện cho NLP, đó là Pre-train then Fine-tune, Prompt-based Learning, và NLP as Text Generation. Đồng thời, bài báo đề cập rằng sự hiểu biết lý thuyết của họ về những mô hình này còn sơ bộ.

Wang et al. (Wang et al., 2023a) chủ yếu tóm tắt tiến bộ mới nhất của PLMs trong lĩnh vực y sinh và các ứng dụng của chúng trong các nhiệm vụ y sinh downstream, và thảo luận về xu hướng và hướng phát triển. Để phản hồi các hệ thống đề xuất dựa trên LLM hiện có, Wu et al. (Wu et al., 2023) đề xuất một phân loại chia những mô hình này thành hai mô hình chính, cụ thể là, Discriminative LLM for Recommendation (DLLM4Rec) và Generative LLM for Recommendation (GLLM4Rec). Bài báo đánh giá và phân tích có hệ thống các hệ thống đề xuất dựa trên LLM hiện có trong hai mô hình này và thảo luận về phương pháp và hiệu suất của chúng.

28

--- TRANG 29 ---
Nghiên cứu khác chủ yếu điều tra và phân tích những thiếu sót của LLMs trong các ứng dụng của chúng. Ví dụ, Meade et al. (Meade et al., 2022) khảo sát và tóm tắt các kỹ thuật giảm thiểu bias trong các mô hình ngôn ngữ tiền huấn luyện. Bài báo nghiên cứu thực nghiệm năm kỹ thuật giảm thiểu bias phổ biến hiện tại và đề xuất ba benchmark bias nội tại để định lượng hiệu quả của mỗi kỹ thuật. Huang et al. (Huang and Chang, 2023) mô tả toàn diện khả năng lý luận của LLMs, bao gồm các công nghệ để cải thiện và tạo ra khả năng lý luận trong những mô hình này, các phương pháp và benchmark để đánh giá khả năng lý luận, và đề xuất cho các hướng tương lai. Vì LLMs đôi khi cung cấp những dự đoán không thực tế nhưng có vẻ hợp lý (được gọi là hallucinations, xem (Welleck et al., 2020)), Mialon et al. (Mialon et al., 2023) đánh giá hai phương pháp để nâng cao khả năng của LLMs, cụ thể là, bằng cách tận dụng kỹ năng lý luận và gọi các công cụ bên ngoài, nhằm cải thiện ngữ cảnh và hạn chế hallucinations. Xu et al. (Xu and McAuley, 2023) chú ý đặc biệt đến giai đoạn suy luận trong quá trình xây dựng LLMs và đánh giá tình trạng hiện tại của các kỹ thuật nén và tăng tốc mô hình, bao gồm benchmarks, metrics, và phương pháp.

Zan et al. (Zan et al., 2023) điều tra hiệu suất của 27 mô hình lớn trong lĩnh vực tạo mã từ mô tả ngôn ngữ tự nhiên (hoặc NL2Code). Đóng góp chính của bài báo là một so sánh trực quan về khả năng NL2Code của LLMs trên benchmark HumanEval. Tuy nhiên, nghiên cứu của nó chỉ giới hạn ở nhiệm vụ kỹ thuật phần mềm là tạo mã. Nó không tóm tắt các ứng dụng khác của LLMs trong tạo mã, cũng không điều tra các nhiệm vụ kỹ thuật phần mềm khác, chẳng hạn như chuyển đổi mã.

Wong et al. (Wong et al., 2023) giới thiệu một số phương pháp Học dựa trên Mô hình Ngôn ngữ (LLM) phổ biến và các ứng dụng của chúng trong các nhiệm vụ downstream liên quan đến lập trình hỗ trợ AI. Các nhiệm vụ được đề cập trong bài báo bao gồm tạo mã, hoàn thành mã, dịch mã, tinh chỉnh mã, tóm tắt mã, phát hiện khuyết điểm, và phát hiện nhân bản. Tuy nhiên, đáng chú ý là các phương pháp hỗ trợ AI được thảo luận trong bài báo này không giới hạn ở LLM mà còn bao gồm các kỹ thuật AI khác nhau. Hơn nữa, trọng tâm của bài báo chỉ là các nhiệm vụ lập trình hỗ trợ AI.

(Watson et al., 2022) cung cấp một đánh giá tài liệu có hệ thống về giao điểm giữa SE và học sâu (DL). Nó bao gồm 128 tài liệu tham khảo bao phủ các lĩnh vực và nhiệm vụ SE đa dạng. Bài báo trình bày một lộ trình nghiên cứu chi tiết, mô tả tình trạng hiện tại và ứng dụng của các kỹ thuật DL trong các nhiệm vụ SE. Nó cũng phân tích và thảo luận các hướng tương lai cho giao điểm của nghiên cứu DL và SE. Động lực và phân loại các nhiệm vụ SE được cung cấp trong bài báo đưa ra những hiểu biết có giá trị cho bài báo của chúng tôi. Sự khác biệt nằm ở chỗ bài báo được đánh giá tập trung vào DL, trong khi bài báo của chúng tôi đặc biệt đánh giá LLMs.

29

--- TRANG 30 ---
6.2 Mô hình tiền huấn luyện cho Các Nhiệm vụ Kỹ thuật Phần mềm

Các công trình trước đây đã áp dụng các mô hình ngôn ngữ tiền huấn luyện (PLM) vào các nhiệm vụ kỹ thuật phần mềm, cung cấp nền tảng vững chắc và hướng dẫn cho việc ứng dụng hiện tại của PLMs trong các nhiệm vụ SE. Ví dụ, (Chen et al., 2022b) đã sử dụng một mô hình ngôn ngữ tiền huấn luyện để tạo tên biến. (Lee et al., 2022b) sử dụng một PLM để phân loại lỗi. (Zhang et al., 2022d) giới thiệu DietCode, một phương pháp nhẹ tận dụng các mô hình tiền huấn luyện lớn để tạo mã nguồn. (Li et al., 2022b) sử dụng một PLM để tạo chú thích tự động. Ngoài ra, đã có những công trình tập trung vào prompt learning, chẳng hạn như (Luo et al., 2022).

Cũng có một số công trình đã đánh giá hiệu suất của PLMs trong các nhiệm vụ kỹ thuật phần mềm. (Zeng et al., 2022b) nghiên cứu khả năng của các mô hình tiền huấn luyện trong hiểu mã và điều tra tính robust của các mô hình tiền huấn luyện bằng cách kiểm tra hiệu suất của chúng dưới các cuộc tấn công đối nghịch. (Zhang et al., 2022a) khám phá tính khả thi của việc sử dụng các mô hình tiền huấn luyện để sửa chữa tự động các xung đột merge (cả văn bản và ngữ nghĩa). (Mastropaolo et al., 2021) thực hiện phân tích thực nghiệm về hiệu suất của mô hình T5 trong các nhiệm vụ liên quan đến mã. (Lin et al., 2021) so sánh và đánh giá độ chính xác và hiệu quả của ba kiến trúc BERT trong việc liên kết các vấn đề và commits cho bug triaging trong các dự án mã nguồn mở. (Hernández López et al., 2022) đánh giá xem các mô hình ngôn ngữ tiền huấn luyện có mã hóa toàn bộ cấu trúc ngữ pháp của các ngôn ngữ lập trình hay không. (Karmakar and Robbes, 2021) sử dụng probes để xác định xem các mô hình có thiếu một số thuộc tính mã nhất định (hiểu biết) hay không. (Wan et al., 2022) thực hiện phân tích mã nguồn của các mô hình mã quy mô lớn để trình bày các tính năng diễn giải của Code LLMs. (Tufano et al., 2022) xác thực khả năng của mô hình T5 trong việc tự động hóa các nhiệm vụ đánh giá mã và cung cấp kết luận tích cực, thể hiện sự vượt trội của nó so với các mô hình DL trước đó.

Do số lượng tham số tương đối nhỏ hơn của PLMs so với LLMs, chúng có thể thiếu khả năng tạo mã mạnh mẽ, dẫn đến các vấn đề tiềm ẩn trong mã được tạo ra. Để giải quyết điều này, một số công trình đã kết hợp PLMs với các kỹ thuật phân tích chương trình để nâng cao hiệu suất của chúng trong các nhiệm vụ SE. (Jain et al., 2022a) sử dụng các kỹ thuật hậu xử lý dựa trên phân tích chương trình để cải thiện độ tin cậy của tạo mã LLM. (Wang et al., 2022b) đề xuất một phương pháp cầu nối giữa các mô hình tiền huấn luyện và các nhiệm vụ liên quan đến mã để nâng cao khả năng của các mô hình tiền huấn luyện trong các nhiệm vụ như hiểu mã. (Niu et al., 2022) giới thiệu SPT-Code, một mô hình tiền huấn luyện sequence-to-sequence được thiết kế đặc biệt cho mã nguồn. (Yang et al., 2022) tấn công LLMs bằng cách sử dụng các phép biến đổi đầu vào đối nghịch để hướng dẫn các mô hình tạo ra đầu ra không chính xác. (Nguyen et al., 2019) trình bày AutoSC cho các nhiệm vụ hoàn thành mã. (Liu et al., 2021) giới thiệu CugLM, và (Shi et al., 2022) đề xuất một kỹ thuật nén mô hình để tạo điều kiện cho việc sử dụng tốt hơn Code LLMs bởi các nhà phát triển.

30

--- TRANG 31 ---
7 Mối đe dọa tính hợp lệ

7.1 Tính hợp lệ nội bộ

Phần 2 và Phần 4 dựa vào việc sàng lọc thủ công các bài báo và phân tích nội dung bài báo, tương ứng. Do đó, có thể có tính chủ quan nội bộ trong kết quả của những sàng lọc và phân tích này. Để giảm thiểu bias chủ quan và nâng cao độ tin cậy của kết quả, chúng tôi đã sử dụng một giao thức nhiều người trong cả hai phần, nơi nhiều người tham gia thực hiện phân tích riêng biệt và điều chỉnh kết quả để đảm bảo rằng bất kỳ bất đồng nào đều được giải quyết đầy đủ. Đáng chú ý, các người tham gia trong những nhiệm vụ này (bao gồm cả những người không phải đồng tác giả) đều có hơn 3 năm kinh nghiệm nghiên cứu kỹ thuật phần mềm.

Trong Phần 3, Phương pháp phân loại các nhiệm vụ SE của chúng tôi phục vụ như một khám phá giai đoạn đầu để cấu trúc tốt hơn lĩnh vực mới nổi này. Chúng tôi thừa nhận rằng phân loại của chúng tôi có thể không bao gồm đầy đủ tất cả các khía cạnh của các nhiệm vụ kỹ thuật phần mềm, và chúng tôi đồng ý rằng một phân loại như vậy nên được dựa trên thực tế và ánh xạ đến các bài báo nghiên cứu thực tế, thay vì chỉ được rút ra từ các danh mục hội nghị. Tuy nhiên, chúng tôi tin rằng phân loại của chúng tôi vẫn nắm bắt được một phần đáng kể các nhiệm vụ quan trọng nhất trong kỹ thuật phần mềm.

Trong Phần 5, chúng tôi tập trung vào hiệu suất của LLM trong các nhiệm vụ SE. Tuy nhiên, có thể có sự khác biệt trong các công trình khác nhau về góc độ đánh giá LLM, chẳng hạn như sử dụng các datasets khác nhau và định hướng đến các nhiệm vụ SE khác nhau. Vì vậy có thể có sự khác biệt trong kết quả trong các tài liệu khác nhau. Để giảm thiểu tác động này, chúng tôi tổ chức thông tin về kết quả đánh giá, datasets đánh giá, và góc độ đánh giá của các công trình khác nhau để giúp độc giả hiểu về sự biến đổi của các công trình khác nhau.

7.2 Tính hợp lệ ngoại bộ

Hiện tại, công nghệ LLM đang phát triển nhanh chóng, cũng như nghiên cứu LLM trong lĩnh vực kỹ thuật phần mềm. Mặc dù các phát hiện của chúng tôi không thể bao gồm các công trình tương lai, công việc của chúng tôi vẫn có giá trị trong việc tiết lộ hướng hiện tại của LLM về các nhiệm vụ SE. Trong khi đó, việc phân loại của chúng tôi về LLM trong các nhiệm vụ SE vẫn áp dụng được trong phạm vi nghiên cứu hiện tại.

Mối đe dọa ngoại bộ thứ hai liên quan đến những ranh giới tinh vi tồn tại giữa các nhiệm vụ kỹ thuật phần mềm, chẳng hạn như nhân bản mã và mùi mã. Những nhiệm vụ này có thể liên quan đến nhiều lĩnh vực kỹ thuật phần mềm, điều này tạo ra sự mơ hồ tiềm ẩn trong phân loại của chúng. Để giảm thiểu mối đe dọa này, chúng tôi đã cung cấp định nghĩa rõ ràng cho mỗi nhiệm vụ kỹ thuật phần mềm và làm rõ phạm vi được bao phủ bởi các phân loại nhiệm vụ. Ví dụ, chúng tôi đã định nghĩa các nhiệm vụ nhân bản mã và mùi mã trong lĩnh vực đánh giá mã.

Một mối đe dọa ngoại bộ khác là những hạn chế vốn có của chính quá trình đánh giá tài liệu. Do tính không thực tế của việc xác minh độ chính xác của mọi công trình được đánh giá trong tài liệu, có thể có một số bias trong kết quả được trình bày cho RQ2. Để giảm thiểu tác động của mối đe dọa này, chúng tôi đã cung cấp thông tin chi tiết về chi tiết đánh giá của mỗi công trình được khảo sát cho RQ2.

31

--- TRANG 32 ---
Điều này bao gồm thông tin như dataset được sử dụng, trọng tâm của đánh giá, mục tiêu của đánh giá, và kết quả đánh giá. Chúng tôi tin rằng nếu LLM liên tục hoạt động kém trong hầu như tất cả các nghiên cứu đánh giá cho một nhiệm vụ cụ thể, có thể kết luận sơ bộ rằng LLM hoạt động kém trong nhiệm vụ đó. Ngược lại, nếu tất cả các nghiên cứu đánh giá cung cấp đánh giá tích cực cho một nhiệm vụ SE cụ thể, chúng ta có thể kết luận rằng LLM hoạt động tốt trong nhiệm vụ đó. Chúng tôi đã cung cấp một tóm tắt công bằng về đánh giá LLM trên các nhiệm vụ SE khác nhau. Hơn nữa, chúng tôi giải quyết bất kỳ đánh giá mâu thuẫn nào được tìm thấy trong nhóm nghiên cứu đánh giá hiện tại trong kết luận của chúng tôi.

8 Kết luận và Công việc Tương lai

Bài báo này đánh giá toàn diện các ứng dụng của Mô hình Ngôn ngữ Lớn (LLMs) trong kỹ thuật phần mềm. Thứ nhất, chúng tôi đã thu thập và sàng lọc 123 công trình và tài liệu liên quan đến giao điểm của kỹ thuật phần mềm và LLM. Thứ hai, bằng cách phân loại tài liệu được chọn dựa trên các nhiệm vụ kỹ thuật phần mềm, chúng tôi đã tiết lộ trọng tâm nghiên cứu và xác định những thiếu sót hiện có trong việc tích hợp LLM với các nhiệm vụ kỹ thuật phần mềm khác nhau. Cuối cùng, chúng tôi đã kiểm tra và tóm tắt cẩn thận các bài báo đánh giá hiệu suất của LLMs trong các nhiệm vụ kỹ thuật phần mềm, tiết lộ khả năng và hạn chế của chúng và cung cấp hướng dẫn cho nghiên cứu và tối ưu hóa tương lai.

Các công trình hiện tại cũng tiết lộ một số hướng tương lai đáng thảo luận: (1) Chúng ta có thể thấy rằng một phần lớn công việc trong Phần 4 đề xuất các phương pháp để cải thiện hiệu suất của LLMs trong một hoặc nhiều nhiệm vụ kỹ thuật phần mềm. Mặc dù hầu hết chúng không cung cấp đánh giá hoặc thảo luận chi tiết về hiệu suất của LLMs trong những nhiệm vụ này, điều này có thể gợi ý rằng hiệu suất hiện tại của LLMs trong những nhiệm vụ này không đủ tốt hoặc không ổn định; (2) Hầu hết các đánh giá hiện tại dựa trên các mô hình lớn tổng quát, chẳng hạn như ChatGPT, và các đánh giá chi tiết về các mô hình lớn tập trung vào mã như Codex vẫn còn thiếu; (3) Chúng ta có cần fine-tune các mô hình lớn cho các nhiệm vụ kỹ thuật phần mềm cụ thể để tạo ra các sản phẩm mô hình lớn được điều chỉnh cho các nhiệm vụ cụ thể không? Chúng tôi sẽ dần tìm kiếm câu trả lời cho những câu hỏi này trong tương lai.

9 Xung đột Lợi ích

Các tác giả tuyên bố rằng họ không có xung đột lợi ích nào tồn tại trong việc nộp bản thảo này, và bản thảo được tất cả các tác giả phê duyệt để xuất bản. Tôi muốn tuyên bố thay mặt cho các đồng tác giả của tôi rằng công việc được mô tả là nghiên cứu nguyên bản chưa được xuất bản trước đó và không đang được xem xét để xuất bản ở nơi khác. Tất cả các tác giả được liệt kê đều đã phê duyệt bản thảo.

32

--- TRANG 33 ---
Chúng tôi tuyên bố rằng chúng tôi không có bất kỳ lợi ích thương mại hoặc liên kết nào đại diện cho xung đột lợi ích liên quan đến công việc được nộp.

10 Tuyên bố về tính sẵn có của dữ liệu

Danh sách tài liệu được khảo sát trong bài báo này là mã nguồn mở và có sẵn tại https://github.com/KevinHeiwa/LLM-SE-Paper-List.

Lời cảm ơn Công việc này được hỗ trợ bởi Quỹ Khoa học Tự nhiên Quốc gia Trung Quốc theo Grant 62306344, và Quỹ Nghiên cứu Cơ bản và Ứng dụng Cơ bản Guangdong theo Grant 2024A1515010253.

Tài liệu tham khảo
[Danh sách các tài liệu tham khảo tiếp theo - phần này chứa rất nhiều tài liệu tham khảo học thuật]

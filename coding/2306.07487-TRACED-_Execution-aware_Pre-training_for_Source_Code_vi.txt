# TRACED: Huấn luyện trước có nhận thức thực thi cho mã nguồn

Yangruibo Ding
Đại học Columbia
New York, NY, USA

Ben Steenhoek
Đại học bang Iowa
Ames, IA, USA

Kexin Pei
Đại học Columbia
New York, NY, USA

Gail Kaiser
Đại học Columbia
New York, NY, USA

Wei Le
Đại học bang Iowa
Ames, IA, USA

Baishakhi Ray
Đại học Columbia
New York, NY, USA

TÓM TẮT
Hầu hết các mô hình ngôn ngữ được huấn luyện trước hiện tại cho mã nguồn tập trung vào việc học văn bản mã tĩnh, thường được tăng cường với các cấu trúc mã tĩnh (cây cú pháp trừu tượng, đồ thị phụ thuộc, v.v.). Tuy nhiên, ngữ nghĩa chương trình sẽ không được lộ ra hoàn toàn trước khi thực thi thực sự. Không có sự hiểu biết về việc thực thi chương trình, các mô hình được huấn luyện trước tĩnh thất bại trong việc nắm bắt toàn diện các thuộc tính mã động, chẳng hạn như phủ sóng nhánh và các giá trị biến thời gian chạy, và do đó chúng kém hiệu quả hơn trong các tác vụ hiểu mã, như truy xuất các bản sao ngữ nghĩa và phát hiện lỗ hổng phần mềm.

Để thu hẹp khoảng cách giữa bản chất tĩnh của các mô hình ngôn ngữ và các đặc điểm động của chương trình, chúng tôi giới thiệu TRACED, một chiến lược huấn luyện trước có nhận thức thực thi cho mã nguồn. Cụ thể, chúng tôi huấn luyện trước các mô hình ngôn ngữ mã với sự kết hợp của mã nguồn, đầu vào có thể thực thi và các dấu vết thực thi tương ứng. Mục tiêu của chúng tôi là dạy các mô hình mã logic thực thi phức tạp trong quá trình huấn luyện trước, cho phép mô hình ước tính tĩnh các thuộc tính mã động mà không cần thực thi mã nhiều lần trong quá trình tinh chỉnh cụ thể theo tác vụ.

Để minh họa hiệu quả của phương pháp được đề xuất, chúng tôi tinh chỉnh và đánh giá TRACED trên ba tác vụ hạ nguồn: ước tính thực thi tĩnh, truy xuất bản sao và phát hiện lỗ hổng. Kết quả thực nghiệm cho thấy TRACED cải thiện tương đối các mô hình mã được huấn luyện trước tĩnh 12,4% cho dự đoán đường dẫn thực thi hoàn chỉnh và 25,2% cho dự đoán giá trị biến thời gian chạy. TRACED cũng vượt trội đáng kể so với các mô hình được huấn luyện trước tĩnh trong truy xuất bản sao và phát hiện lỗ hổng trên bốn bộ đánh giá công khai.

1 GIỚI THIỆU
Học máy (ML) cho mã nguồn đã cho phép nhiều tác vụ kỹ thuật phần mềm, chẳng hạn như sửa chữa chương trình tự động, tìm lỗi và tái cấu trúc. Gần đây, thực hành phổ biến của việc huấn luyện các mô hình ML để hiểu mã nguồn dựa trên việc huấn luyện trước một mô hình ngôn ngữ dựa trên Transformer trên mã nguồn. Các phương pháp này xem các chương trình mã nguồn như văn bản tĩnh, đôi khi được tăng cường với các cấu trúc cụ thể của chương trình như cây cú pháp trừu tượng và đồ thị phụ thuộc, và điều chỉnh các chiến lược huấn luyện trước cho ngôn ngữ tự nhiên để học các biểu diễn chương trình.

Tuy nhiên, nhiều tác vụ hiểu mã nguồn đòi hỏi sự hiểu biết toàn diện hơn về hành vi chương trình. Ví dụ, phát hiện các bản sao ngữ nghĩa liên quan đến việc xác định xem hai đoạn mã có hành vi tương tự dưới các đầu vào tương tự hay không, ngay cả khi cấu trúc của chúng rõ ràng khác nhau. Tương tự, phát hiện lỗ hổng thường đòi hỏi các nhà phát triển phân tích xem một vị trí có thể gây vấn đề có thể được thực thi hay không và những loại luồng giá trị nào có thể lộ ra bất kỳ lỗ hổng nào. Trong khi các mô hình mã hiện tại chủ yếu được huấn luyện để nắm bắt các thuộc tính mã tĩnh, chúng không hiệu quả trong việc lý luận về hành vi chương trình. Thực tế, nhiều ngữ nghĩa chương trình sâu hơn chỉ biểu hiện khi mã được thực thi. Do đó, chúng có xu hướng hoạt động kém khi đối mặt với các tác vụ đòi hỏi hiểu biết ngữ nghĩa sâu hơn.

Hình 1: Một ví dụ động cơ từ thử thách lập trình số 3597 của CodeNet tiết lộ rằng các mô hình ngôn ngữ mã được huấn luyện trước tĩnh, bất kể kích thước của chúng, không thể lý luận về phủ sóng nhánh cho một đầu vào cụ thể, trong khi TRACED, được tăng cường với các tính năng thực thi chương trình, xác định chính xác đường dẫn thực thi.

Các ví dụ động cơ. Hình 1 trình bày một ví dụ với logic thực thi đơn giản để minh họa sự thất bại của các mô hình mã được huấn luyện trước tĩnh trong dự đoán phủ sóng nhánh. Chúng tôi truy vấn ba mô hình mã được huấn luyện trước, CodeX (code-davinci-002), UnixCoder và TRACED (của chúng tôi), để dự đoán phủ sóng nhánh, theo các đầu vào chương trình đã cho. Đối với CodeX, chúng tôi nhắc mô hình với các câu hỏi được thiết kế cẩn thận, tương tự như, để yêu cầu dự đoán phủ sóng nhánh trong thiết lập zero-shot. Cụ thể, chúng tôi tăng cường các lời nhắc bằng cách thêm nhận xét ở cuối dòng 12 và 16: // Dòng này có được thực thi không? Có hay không?. Để cung cấp thêm gợi ý về luồng dữ liệu, chúng tôi thêm một nhận xét ở cuối dòng 10: // A là -1, vì nó chấp nhận giá trị thứ hai của đầu vào. Thật không may, ngay cả khi được cung cấp các gợi ý bổ sung về luồng dữ liệu cần thiết cho dự đoán nhánh, CodeX vẫn thất bại trong việc dự đoán các nhãn phủ sóng chính xác, cho thấy nó không thể diễn giải việc thực thi đơn giản này.

Bên cạnh việc nhắc zero-shot, chúng tôi cũng nghiên cứu liệu việc tinh chỉnh các mô hình mã được huấn luyện trước để dự đoán thực thi có thể dẫn đến dự đoán nhánh tốt hơn hay không. Cụ thể, chúng tôi tinh chỉnh một mô hình mã được huấn luyện trước phổ biến khác, UnixCoder, để dự đoán thực thi nhánh trong khi đảm bảo ví dụ động cơ không được nhìn thấy trong quá trình huấn luyện. Từ kết quả suy luận trong Hình 1, chúng tôi nhận thấy rằng UnixCoder không thể dự đoán các nhánh được bao phủ ngay cả sau khi được tinh chỉnh. Nó dự đoán không có nhánh nào sẽ được bao phủ, cho thấy rằng nó không có hiểu biết cơ bản rằng, đối với ví dụ cụ thể này, ít nhất một nhánh sẽ luôn được thực hiện trên một đầu vào hợp lệ.

Phương pháp của chúng tôi. Để giải quyết hạn chế của các mô hình mã được huấn luyện trước tĩnh, chúng tôi đề xuất TRACED, một chiến lược huấn luyện trước có nhận thức thực thi để nắm bắt các góc độ tĩnh và động của mã nguồn. Cụ thể, chúng tôi huấn luyện trước mô hình ngôn ngữ dựa trên Transformer với các mục tiêu đa tác vụ về dự đoán mã nguồn, trạng thái chương trình và phủ sóng thực thi, buộc mô hình phải lý luận về cả hành vi thời gian chạy của chương trình và tính tự nhiên của mã nguồn cùng một lúc. Chúng tôi giải quyết một số thách thức kỹ thuật, chẳng hạn như biểu diễn trạng thái thực thi chương trình, mã hóa các giá trị biến thời gian chạy và biểu diễn phủ sóng mã, để thực hiện chiến lược huấn luyện trước.

Biểu diễn trạng thái chương trình. Trong quá trình thực thi chương trình, các biến được sử dụng để lưu trữ dữ liệu được chương trình sử dụng. Các biến này có thể có các loại khác nhau, chẳng hạn như số nguyên, số dấu phẩy động, con trỏ và mảng. Khi chương trình thực thi, các giá trị của các biến này thay đổi, phản ánh những thay đổi trong trạng thái của chương trình. Do đó, các nhà phát triển phần mềm thường theo dõi các giá trị biến, thông qua các công cụ gỡ lỗi, để quan sát các sự thật thực thi và hiểu các hành vi động của chương trình.

Trong công trình này, chúng tôi định nghĩa trạng thái chương trình tại một bước thời gian cụ thể của việc thực thi là tập hợp các giá trị của mọi biến được định nghĩa trong phạm vi hiện tại. Nói cách khác, trạng thái chương trình tương đương với bảng ánh xạ giá trị của trình gỡ lỗi, được giám sát bởi nhà phát triển khi chương trình được tạm dừng bởi một điểm dừng cụ thể.

Lượng tử hóa giá trị. Trong khi các giá trị biến thời gian chạy được theo dõi như các giá trị cụ thể, việc học trực tiếp chúng mang lại thách thức cho các mô hình học máy. Các giá trị cụ thể trải rộng trên một phạm vi rộng các giá trị có thể, đặc biệt khi xem xét các kiểu dữ liệu khác nhau (số nguyên, số dấu phẩy động, mảng, con trỏ, v.v.), dẫn đến một phân phối dữ liệu phức tạp, nhiều chiều nhưng thưa thớt. Độ phức tạp và tính thưa thớt dữ liệu tăng này thách thức mô hình học các mẫu và mối quan hệ giữa các giá trị biến, vì nó phải xử lý nhiều đầu vào duy nhất, điều này khiến mô hình quá khớp và ghi nhớ các trường hợp cụ thể thay vì khái quát hóa thành các mẫu rộng hơn. Ngoài ra, nhiễu, ngoại lệ và bất thường của các giá trị cụ thể cũng làm sai lệch quá trình học của mô hình. Chúng tôi sẽ minh họa thực nghiệm những hạn chế này trong §6.3.

Để giảm độ phức tạp dữ liệu và tăng mật độ, chúng tôi định nghĩa ba mười danh mục giá trị, bao phủ một phạm vi rộng các loại biến, để ánh xạ các giá trị biến liên tục nhưng thưa thớt thành các bin rời rạc. Chúng tôi gọi quá trình này là lượng tử hóa giá trị, tương tự về thiết kế với lượng tử hóa trong xử lý tín hiệu. Sự đơn giản hóa này có thể giúp mô hình có khả năng chống nhiễu và ngoại lệ tốt hơn, cho phép nó tập trung vào việc học các mẫu thực thi cơ bản và mối quan hệ giữa các biến, thay vì nhạy cảm với các trường hợp cụ thể hoặc bất thường.

Biểu diễn phủ sóng thực thi. Trong khi các nhãn trạng thái chương trình cung cấp thông tin quan trọng về trạng thái hiện tại của chương trình, chúng không nắm bắt thông tin về cách chương trình đến được trạng thái đó. Để thúc đẩy việc huấn luyện với các tính năng thực thi toàn diện hơn, bên cạnh các giá trị biến, chúng tôi cũng ghi lại phủ sóng thực thi trong quá trình thực thi, về mặt dòng nào được thực thi và dòng nào không, và xây dựng các tính năng phủ sóng thực thi cho mô hình học.

Kết quả. Chúng tôi tinh chỉnh và đánh giá hiệu suất của TRACED sử dụng ba tác vụ: ước tính thực thi tĩnh, truy xuất bản sao và phát hiện lỗ hổng. Về dự đoán tĩnh các việc thực thi chương trình, TRACED cải thiện đáng kể các mô hình mã được huấn luyện trước tĩnh 12,4% cho dự đoán đường dẫn thực thi và 25,2% cho dự đoán giá trị biến thời gian chạy. TRACED cũng đạt được kết quả tốt nhất trong các tác vụ hiểu mã: TRACED báo cáo 91,2% MAP@R trên CodeXGLUE-POJ104, 50,4% F1 trên ReVeal và 65,9% độ chính xác trên CodeXGLUE-defect-detection.

Đóng góp. Chúng tôi đưa ra những đóng góp sau:
• Chúng tôi trình bày một biểu diễn đơn giản và gọn gàng của việc thực thi chương trình, bao gồm các trạng thái chương trình và phủ sóng thực thi, để hướng dẫn hiệu quả các mô hình mã học ngữ nghĩa chương trình và lý luận về hành vi chương trình.
• Chúng tôi đề xuất một chiến lược huấn luyện trước đa tác vụ mới để học cùng lúc các thuộc tính mã tĩnh và động. Kết quả là, mô hình được huấn luyện trước với phương pháp của chúng tôi sẽ được trao quyền với nhận thức thực thi tốt.
• Chúng tôi huấn luyện trước TRACED với biểu diễn dấu vết được đề xuất và chiến lược có nhận thức thực thi và đánh giá hiệu suất của nó trên một số tác vụ hạ nguồn. Kết quả thí nghiệm chứng minh rằng TRACED vượt trội đáng kể so với các mô hình mã được huấn luyện trước tĩnh trong các tác vụ này.
• Chúng tôi sẽ công khai phát hành dữ liệu, mã và các mô hình được huấn luyện trước của chúng tôi để thúc đẩy khoa học mở.

2 TỔNG QUAN
Hình 2 cho thấy tổng quan về TRACED, bao gồm ba giai đoạn chính: (1) theo dõi mã nguồn và kỹ thuật tính năng, (2) huấn luyện trước có nhận thức thực thi sử dụng các dấu vết chương trình, và (3) tải các trọng số được huấn luyện trước và thực hiện tinh chỉnh cụ thể theo tác vụ.

Giai đoạn 1: Theo dõi và kỹ thuật tính năng. Mục tiêu của giai đoạn này là chuẩn bị dữ liệu cho huấn luyện trước. Quá trình bắt đầu với việc cung cấp một chương trình nguồn và các đầu vào có thể thực thi của nó. Bước đầu tiên là thực thi chương trình với mỗi đầu vào để tạo ra các dấu vết tương ứng. Các dấu vết ghi lại các giá trị biến thời gian chạy, cùng với phủ sóng thực thi, ghi lại toàn bộ lịch sử thực thi của chương trình và tiết lộ những thay đổi đối với trạng thái chương trình trong suốt quá trình thực thi. Để giảm độ phức tạp và tính thưa thớt của dữ liệu, và làm cho việc học các mẫu và mối quan hệ giữa các giá trị biến dễ dàng hơn cho mô hình, chúng tôi lượng tử hóa các giá trị thời gian chạy cụ thể được ghi lại trong các dấu vết thành các phạm vi giá trị được định nghĩa trước. Quá trình lượng tử hóa ánh xạ các giá trị liên tục thành một tập hợp cố định các bin rời rạc. Bằng cách lượng tử hóa các giá trị, chúng tôi tạo ra một tập hợp hữu hạn các đầu ra có thể được sử dụng làm nhãn sự thật cơ bản trong quá trình huấn luyện. Sau khi lượng tử hóa, chúng tôi tạo ra các nhãn trạng thái chương trình và các nhãn phủ sóng thực thi sẽ giúp mô hình nắm bắt các việc thực thi chương trình. Bộ dữ liệu cuối cùng kết thúc với một tập hợp các mẫu và nhãn, trong đó mỗi mẫu bao gồm mã nguồn với đầu vào chương trình của nó và các nhãn đại diện cho dấu vết thực thi của mẫu này.

Giai đoạn 2: Huấn luyện trước có nhận thức thực thi với dấu vết. Chúng tôi sử dụng các mẫu và nhãn được xử lý trước thu được từ Giai đoạn 1 để thực hiện huấn luyện trước có giám sát. Cụ thể, chúng tôi sử dụng một mô hình dựa trên Transformer-encoder để học các dấu vết chương trình và cải thiện sự hiểu biết của mô hình về việc thực thi chương trình. Mô hình có thể được huấn luyện từ đầu hoặc được tải bởi các trọng số được huấn luyện trước của các mô hình ngôn ngữ mã hiện có. Để đạt được mục tiêu tạo ra biểu diễn mã có nhận thức thực thi, chúng tôi đề xuất ba mục tiêu huấn luyện trước. Mục tiêu đầu tiên là học tạo ra mã nguồn. Chúng tôi tin rằng hiểu tính tự nhiên của văn bản mã là cơ bản để mô hình nắm bắt các tín hiệu phức tạp hơn như việc thực thi chương trình. Mục tiêu này được thực hiện với mô hình ngôn ngữ được che (MLM), che một tỷ lệ nhất định các token trong mã nguồn và huấn luyện mô hình để tái tạo các token bị che dựa trên ngữ cảnh xung quanh. Mục tiêu thứ hai là học dự đoán các trạng thái chương trình. Bằng cách dự đoán các nhãn trạng thái chương trình được tạo ra trong Giai đoạn 1, mô hình học cách nắm bắt các luồng dữ liệu và các tác động phụ của việc thực thi mã. Mục tiêu thứ ba là dự đoán phủ sóng thực thi. Bằng cách dự đoán các nhãn phủ sóng thực thi được tạo ra bởi Giai đoạn 1, mô hình học cách nắm bắt luồng điều khiển động và giúp mô hình hiểu cách trạng thái chương trình được đạt tới và phát triển.

Giai đoạn 3: Tinh chỉnh cụ thể theo tác vụ. Cuối cùng, chúng tôi áp dụng TRACED vào một số tác vụ hạ nguồn. Chúng tôi tải các trọng số được huấn luyện trước của TRACED, tinh chỉnh mô hình cho một tác vụ cụ thể và tiếp tục cập nhật các trọng số mô hình. Tinh chỉnh không yêu cầu chương trình được thực thi; thay vào đó, TRACED sẽ lý luận về việc thực thi một cách tĩnh với các tín hiệu thực thi đã học của nó trong quá trình huấn luyện trước, và học để hoàn thành tác vụ tương ứng. Trong nhiều ứng dụng hữu ích, chúng ta sẽ không có dấu vết chương trình có sẵn. Chúng tôi xem xét ba tác vụ hạ nguồn cho TRACED: ước tính thực thi tĩnh, bao gồm phủ sóng thực thi và dự đoán giá trị biến thời gian chạy, truy xuất bản sao và phát hiện lỗ hổng.

3 THEO DÕI VÀ KỸ THUẬT TÍNH NĂNG
Trong phần này, chúng tôi giới thiệu cách TRACED xây dựng các tính năng có thể học được từ dấu vết chương trình để các mô hình học việc thực thi chương trình.

3.1 Biểu diễn trạng thái chương trình
Để bắt chước cách mà các nhà phát triển con người theo dõi các giá trị biến để hiểu hành vi chương trình, chúng tôi đề xuất huấn luyện các mô hình thần kinh với nhật ký các giá trị biến thời gian chạy để nhận biết các mẫu thực thi và suy luận các hành vi chương trình động theo cách tương tự như trực giác con người. Bằng cách ghi nhật ký các giá trị biến trong quá trình thực thi, chúng ta có thể biểu diễn các trạng thái chương trình dưới dạng gọn gàng và dễ hiểu hơn mà các mạng thần kinh sâu có thể quản lý được để xử lý.

Chúng tôi xây dựng trạng thái chương trình bằng cách chụp ảnh các giá trị biến tại các điểm chương trình trong quá trình thực thi. Khi chúng tôi chụp ảnh tại một bước thời gian cụ thể, tương tự như thời điểm chương trình được tạm dừng bởi một điểm dừng gỡ lỗi được đặt ngay sau dòng l, chúng tôi duy trì một ánh xạ giá trị, M, để ánh xạ biến với giá trị hiện tại của nó, tương tự như bảng ánh xạ giá trị của trình gỡ lỗi. Để ghi lại trạng thái chương trình, chúng tôi chụp ảnh giá trị sau mỗi dòng thực thi và ghi lại các giá trị hiện tại của các biến.

Định nghĩa: Trạng thái chương trình. Một cách chính thức, chúng tôi định nghĩa trạng thái chương trình sau khi thực thi một dòng cụ thể, l, là s(l), được biểu diễn như một tập hợp các giá trị biến tại thời điểm này:
s(l) = {M(v,l)|v∈V, l∈L}
V đại diện cho tập hợp tất cả các biến được theo dõi, và L là tập hợp các dòng có mã nguồn. Hình 3 cho thấy một ví dụ minh họa của một chương trình giai thừa đơn giản và các nhận xét sau mã nguồn chỉ ra trạng thái chương trình sau khi thực thi dòng đó. Ngoài ra, chúng tôi không ghi lại trạng thái chương trình cho các dòng không có mã có thể thực thi, chẳng hạn như dòng 8 của Hình 3.

1 // INPUT: 4
2 int factorial() {
3 int x, y; // { 'x': 32767, 'y': 32767}
4 x = atoi(argv[1]); // { 'x': 4, 'y': 32767}
5 if(x < 0) { // { 'x': 4, 'y': 32767}
6 y = -1;
7 return y;
8 }
9 y = 1; // { 'x': 4, 'y': 1}
10 for (int i = 1; i <= x; i++) // { 'x': 4, 'y': 24, 'i': 5}
11 {
12 y *= i; // { 'x': 4, 'y': 24, 'i': 5}
13 }
14 return y; // { 'x': 4, 'y': 24, 'i': 5}
15 }

Hình 3: Trạng thái chương trình với các giá trị thời gian chạy cụ thể.

Lưu ý rằng một dòng mã nguồn có thể được thực thi nhiều lần do vòng lặp hoặc đệ quy. Trong khi một biểu diễn chi tiết hơn về việc thực thi chương trình có thể cung cấp những hiểu biết bổ sung, nó cũng tăng độ phức tạp và yêu cầu tính toán của mô hình. Như một sự đánh đổi giữa độ phức tạp và hiệu suất, chúng tôi sử dụng lần thực thi cuối cùng xảy ra của mỗi dòng để hoàn thiện các trạng thái chương trình, sao cho s(l) tiếp tục được cập nhật cho đến khi việc thực thi kết thúc.

Chúng tôi áp dụng sự đánh đổi như vậy dựa trên các quan sát về việc thực thi thực. Cụ thể, các giá trị xảy ra cuối cùng thường đủ để nắm bắt kết quả của vòng lặp và đệ quy. Ví dụ, khi gọi một hàm đệ quy, chỉ (các) giá trị xảy ra cuối cùng của (các) biến được trả về sẽ được lấy để thực hiện việc thực thi tiếp theo của người gọi. Tương tự, các giá trị cuối cùng khi vòng lặp kết thúc sẽ tham gia vào việc thực thi tương lai. Như được hiển thị trong dòng 12 của Hình 3, biến y được nhân bên trong một vòng lặp để tính giai thừa. Giá trị của nó thay đổi trong mỗi lần lặp, nhưng ít có thông tin hơn để lý luận về hành vi tổng thể của chương trình, vì chỉ giá trị cuối cùng được sử dụng làm giá trị trả về (dòng 14). Do đó, chúng tôi sẽ biểu diễn y sử dụng giá trị từ lần thực thi cuối cùng xảy ra của vòng lặp.

3.2 Giá trị biến được lượng tử hóa
Như chúng tôi đã giới thiệu trong §1, phân phối các giá trị cụ thể là thưa thớt và phức tạp, do đó khó cho một mô hình thống kê để khớp. Ngoài ra, các giá trị cụ thể không phải lúc nào cũng cần thiết. Một số hành vi chương trình phổ biến đi kèm với các giá trị biến cực lớn hoặc nhỏ – ví dụ, trong C, các biến chưa được khởi tạo thường được đặt thành không hoặc các biến lớn bất thường, nhưng các giá trị cụ thể không có ý nghĩa vì chúng chỉ phụ thuộc vào dữ liệu còn lại trên ngăn xếp, có thể lớn hoặc nhỏ một cách ngẫu nhiên. Mô hình có thể biểu diễn các hành vi như vậy bằng cách ước tính các phạm vi giá trị của biến mà không cần dự đoán chính xác các giá trị cụ thể của chúng không mang thông tin hoặc ý nghĩa. Hình 3 hiển thị một số trường hợp này: sau khi thực thi dòng 3, x và y chưa được khởi tạo và được khởi tạo ngẫu nhiên là 32.767, không có ý nghĩa cụ thể nhưng chỉ làm cho dữ liệu huấn luyện nhiễu và thưa thớt.

Bảng 1: Thiết kế của TRACED về các giá trị biến được lượng tử hóa.

Kiểu dữ liệu | Kiểu giá trị | Giá trị cụ thể | Giá trị được lượng tử hóa
--- | --- | --- | ---
Cơ bản | Số nguyên | 0 < v ≤ 10,000 | Dương thường
| | 10,000 < v | Dương lớn
| | 0 | Không
| | -10,000 ≤ v < 0 | Âm thường
| | v < -10,000 | Âm lớn
| Float/Double | 0.0 < v ≤ 1.0 | Dương nhỏ
| | 1.0 < v ≤ 10,000.0 | Dương thường
| | 10,000.0 < v | Dương lớn
| | 0.0 | Không
| | -1.0 < v < 0 | Âm nhỏ
| | -10,000.0 ≤ v < -1.0 | Âm thường
| | v < -10,000.0 | Âm lớn
| Ký tự | '\0' | Null
| | v ∈ {a-zA-Z} | Chữ cái
| | v ≠ '\0'; v ∉ {a-zA-Z} | Không phải chữ cái
| Boolean | 0 | Sai
| | 1 | Đúng
| Void | - | Void
Mảng | Số nguyên | [v₁, v₂, ..., vₙ]; quantize(vᵢ) ∈ Số nguyên | Đã khởi tạo
| | | Chưa khởi tạo
| Float/Double | [v₁, v₂, ..., vₙ]; quantize(vᵢ) ∈ Float/Double | Đã khởi tạo
| | | Chưa khởi tạo
| Ký tự | "⟨string⟩" | Đã khởi tạo
| | | Chưa khởi tạo
Con trỏ | Số nguyên | 0x0 | Null
| | Không phải 0x0 | Không null
| Float/Double | 0x0 | Null
| | Không phải 0x0 | Không null
| Ký tự | 0x0 | Null
| | Không phải 0x0 | Không null

Để giảm độ phức tạp dữ liệu và tăng mật độ, chúng tôi định nghĩa 30 danh mục cho các giá trị được lượng tử hóa trong Bảng 1. Để biểu diễn toàn diện các giá trị biến, các danh mục được lượng tử hóa được đề xuất xem xét cả kiểu, tức là các kiểu dữ liệu và kiểu giá trị, được định nghĩa tĩnh, và các giá trị thời gian chạy động. Các danh mục được lượng tử hóa của chúng tôi bao phủ các kiểu biến và kiểu giá trị phổ biến nhất, mà chúng tôi thấy đủ để nắm bắt các hành vi và mối quan hệ thực thi chương trình quan trọng. Bằng cách tập trung vào các kiểu giá trị thường xuyên nhất, chúng ta có thể nắm bắt các tính năng thiết yếu của việc thực thi chương trình. Điều này làm cho phương pháp của chúng tôi hiệu quả trong việc nắm bắt các hành vi và mẫu thực thi chương trình được khái quát hóa. Chúng tôi minh họa thực nghiệm hiệu quả của chiến lược lượng tử hóa trong § 6.3.

3.3 Xây dựng nhãn có thể học cho các mô hình mã
Chúng tôi sử dụng huấn luyện trước có giám sát với dấu vết. Chúng tôi xây dựng nhãn cho các mô hình mã để học hai góc độ chính của việc thực thi: trạng thái chương trình và phủ sóng thực thi.

Nhãn trạng thái chương trình. Như chúng tôi đã thảo luận trong các phần trước, trước tiên chúng tôi theo dõi các biến chương trình trong quá trình thực thi và ghi lại các giá trị thời gian chạy của chúng. Sau đó chúng tôi lượng tử hóa các giá trị này thành các danh mục được định nghĩa trước. Quá trình này dẫn đến một chuỗi các trạng thái chương trình, mỗi trạng thái được biểu diễn bởi một tập hợp các giá trị biến được lượng tử hóa (như được hiển thị trong Hình 3), và chúng tôi xây dựng các tính năng có thể học cho mô hình mã dựa trên các trạng thái chương trình này. Cụ thể, chúng tôi xây dựng nhãn cho các biến có thể được lượng tử hóa thành các danh mục của Bảng 1 và huấn luyện mô hình để dự đoán các nhãn này cho các biểu diễn mã nguồn của chúng (§ 4.1.2). Nhãn cho mỗi biến được biểu diễn như một bộ ba: (kiểu dữ liệu, kiểu giá trị, giá trị được lượng tử hóa). Ví dụ, trong Hình 3, nhãn của biến X xảy ra tại dòng 3 là (Cơ bản, Số nguyên, Dương lớn), vì giá trị hiện tại của X là 32.767. Chúng tôi xây dựng các nhãn như vậy cho tất cả các lần xuất hiện của các biến hợp lệ có thể được lượng tử hóa, và tập hợp kết hợp tất cả các nhãn được coi là nhãn trạng thái chương trình của mẫu mã.

Nhãn phủ sóng thực thi. Để thống nhất thiết kế của chúng tôi và giảm độ phức tạp của quá trình học của mô hình, chúng tôi cũng xây dựng nhãn phủ sóng thực thi cho mỗi lần xuất hiện của biến, phù hợp với nhãn trạng thái chương trình. Cụ thể, chúng tôi biểu diễn phủ sóng của một biến với một nhãn nhị phân, "Có" hoặc "Không". Các biến trong dòng được thực thi sẽ được gắn nhãn "Có", và những biến trong các dòng chưa thực thi sẽ được gắn nhãn "Không" và được gán thêm với giá trị được lượng tử hóa "Không xác định" trong khi vẫn giữ nhãn của chúng cho kiểu dữ liệu và kiểu giá trị của chúng. Ví dụ, trong Hình 3, Dòng 6 không được thực thi, vì vậy y tại dòng này có nhãn phủ sóng "Không" và nhãn trạng thái chương trình (Cơ bản, Số nguyên, Không xác định), trong khi y tại dòng 9 có nhãn phủ sóng "Có" và nhãn trạng thái chương trình (Cơ bản, Số nguyên, Dương thường).

4 MÔ HÌNH
Trong phần này, chúng tôi giải thích chi tiết về các thành phần của TRACED và các mục tiêu học trong quá trình huấn luyện trước và tinh chỉnh.

Kiến trúc mô hình. Hình 4 cho thấy kiến trúc cấp cao của việc huấn luyện trước TRACED. Xương sống của TRACED là một bộ mã hóa Transformer 12 lớp, tương tự như BERT và RoBERTa, học các biểu diễn mã chung. Trên đỉnh các lớp Transformer xương sống, TRACED xếp nhiều lớp perceptron đa lớp (MLP) làm đầu dự đoán cho các tác vụ khác nhau.

Trong quá trình huấn luyện trước, như được hiển thị trong Hình 4, TRACED áp dụng một đầu dự đoán mô hình ngôn ngữ, tức là lớp LM, để dự đoán token bị che cho biểu diễn được ngữ cảnh hóa của nó, một đầu dự đoán trạng thái chương trình để dự đoán các nhãn trạng thái chương trình mà chúng tôi đã định nghĩa trong § 3.3, và một đầu phủ sóng thực thi để dự đoán các nhãn phủ sóng thực thi. Đối với việc tinh chỉnh cụ thể theo tác vụ, các lớp Transformer xương sống được tải với các trọng số được huấn luyện trước, trong khi các đầu dự đoán được thay thế bằng một đầu mới được khởi tạo tùy chỉnh cho tác vụ hạ nguồn cụ thể.

Hình 4: Kiến trúc mô hình cấp cao của TRACED. Trong các nhãn cho các lớp trạng thái chương trình, NEG_REG có nghĩa là "Âm thường", UNK có nghĩa là "Không xác định", và POS_REG có nghĩa là "Dương thường", mà chúng tôi đã định nghĩa trong Bảng 1.

4.1 Huấn luyện trước có nhận thức thực thi

4.1.1 Đầu vào mô hình của huấn luyện trước. Mỗi mẫu huấn luyện trước bao gồm mã nguồn của một chương trình có thể thực thi và một đầu vào có thể thực thi hợp lệ. Như được hiển thị trong Hình 4, đầu vào có thể thực thi và mã nguồn được làm phẳng và nối với nhau thành một chuỗi. Để phân biệt đầu vào khỏi mã nguồn, vì chúng là các phương thức khác nhau, TRACED sử dụng các token [SEP] đặc biệt để tách chúng và chỉ ra các vị trí riêng lẻ. Để giảm bớt mối quan ngại về từ vựng ngoài từ vựng của các ngôn ngữ lập trình, TRACED lấy một tokenizer từ con được huấn luyện trước SentencePiece với kích thước từ vựng 50.000. Nó sử dụng tokenizer này để chia chuỗi được nối thành một chuỗi mới của các token con.

Một cách chính thức, chúng tôi định nghĩa các đầu vào có thể thực thi là E = {e₁,...,eᵢ} và mã nguồn được làm phẳng là C = {c₁,...,cⱼ}, thì đầu vào mô hình cuối cùng sẽ là I = {[CLS], e₁,...,eᵢ, [SEP], [SEP], c₁,...,cⱼ, [SEP]}. TRACED cắt bớt các đầu vào có thể thực thi và mã nguồn riêng biệt nếu chúng quá dài. TRACED đặt độ dài tối đa của chuỗi đầu vào có thể thực thi là 64 token, và mã nguồn là 960 token. Những con số này được chọn dựa trên thống kê độ dài đầu vào có thể thực thi của bộ dữ liệu huấn luyện trước của chúng tôi (§5.2.1), và phù hợp với phần còn lại của đầu vào mô hình với mã nguồn.

Lưu ý rằng các dấu vết thực thi không phải là một phần của đầu vào mô hình, mà được sử dụng làm nhãn sự thật cơ bản cho mô hình dự đoán trong quá trình huấn luyện trước.

4.1.2 Học biểu diễn mã có nhận thức thực thi với dấu vết. TRACED được huấn luyện trước với nhiều mục tiêu để cùng nắm bắt các góc độ tĩnh và động của mã nguồn.

Học văn bản mã. Học văn bản mã là bước thiết yếu đầu tiên hướng tới việc hiểu việc thực thi của một chương trình, vì văn bản mã là nguồn chính để nắm bắt tính tự nhiên của mã và các thuộc tính tĩnh khác. Chúng tôi thực hiện mục tiêu học văn bản mã bằng cách điều chỉnh mục tiêu mô hình ngôn ngữ được che. Cụ thể, cho chuỗi đầu vào mô hình I, TRACED ngẫu nhiên chọn 15% token chỉ từ phần chuỗi mã nguồn C và thay thế bằng token [MASK] đặc biệt (ví dụ, printf trong Hình 4 bị che). Nó để nguyên chuỗi đầu vào có thể thực thi E. Mô hình được huấn luyện để mã hóa ngữ cảnh của [MASK] thành biểu diễn mã của nó, r_masked, và tái tạo các token bị che cụ thể có điều kiện trên biểu diễn. Chúng tôi biểu diễn mất mát của việc học văn bản mã là:

L_code-text = Σ_masked -log P(c_masked|r_masked) (1)

Trong Hình 4, lớp LM (Mô hình ngôn ngữ) nhận biểu diễn token bị che được tạo ra bởi lớp Transformer cuối cùng. Lớp LM sau đó dự đoán các token cụ thể bằng cách ánh xạ biểu diễn token thành xác suất của mỗi token trong từ vựng, sử dụng một lớp MLP (Perceptron đa lớp). Quá trình này có thể được coi như một tác vụ phân loại, trong đó số lượng lớp bằng kích thước của từ vựng. Mục tiêu là học một ánh xạ từ biểu diễn token bị che đến token có khả năng nhất trong từ vựng, cho ngữ cảnh của nó.

Học trạng thái chương trình. Mục tiêu huấn luyện trước thứ hai, dự đoán trạng thái chương trình (PSP), được thiết kế để cho phép mô hình học hành vi thực thi chương trình bằng cách dự đoán các nhãn trạng thái chương trình của các biến được theo dõi. Các nhãn trạng thái chương trình này, như được định nghĩa trong §3.3, chứa thông tin về các kiểu dữ liệu, kiểu giá trị và giá trị được lượng tử hóa của các biến ở cuối việc thực thi chương trình. Cụ thể, TRACED trước tiên xác định các token biến trong chuỗi mã nguồn, được ký hiệu là {c_var|c_var∈V} ⊆ C, trong đó V là tập hợp tất cả các biến được theo dõi và C là chuỗi mã nguồn. Sau đó nó trích xuất biểu diễn r_var của mỗi token biến và đưa nó vào lớp trạng thái chương trình. Lớp trạng thái chương trình dự đoán khả năng kết hợp của biến là kiểu dữ liệu sự thật cơ bản d_var, kiểu giá trị t_var và giá trị được lượng tử hóa q_var. Lưu ý rằng nếu một biến được tokenize thành nhiều token con, tất cả các token con thuộc về sẽ chia sẻ cùng một nhãn trạng thái chương trình. Cuối cùng, TRACED tính toán mất mát của PSP như tổng của các mất mát của tất cả các token biến được sử dụng để dự đoán trạng thái chương trình của chúng. Về mặt toán học, mất mát được biểu diễn như sau:

L_program-state = Σ_var -log P(d_var, t_var, q_var|r_var) (2)

Học phủ sóng biến. Mục tiêu huấn luyện trước thứ ba, dự đoán phủ sóng biến (VCP), nhằm học phủ sóng thực thi, điều này rất quan trọng để hiểu luồng điều khiển của mã cho một đầu vào cụ thể. Tương tự như mục tiêu PSP, VCP nhắm mục tiêu thực hiện dự đoán cho các token biến. Nhãn của phủ sóng biến là nhị phân, trong đó 1 đại diện cho dòng mà biến này thuộc về được bao phủ, ngược lại là 0. Ngoài ra, các token con thuộc về cùng một biến sẽ được gán cùng một nhãn phủ sóng. Mất mát của VCP như sau:

L_var-cov = Σ_var -log P(cov_var|r_var) (3)

Cuối cùng, TRACED kết hợp các mất mát của cả ba mục tiêu và tính tổng của chúng làm mất mát cuối cùng của một mẫu huấn luyện trước. Nó lan truyền ngược gradient qua cả các lớp dự đoán và các lớp Transformer xương sống để cập nhật trọng số của chúng. Chúng tôi ký hiệu tập hợp đầy đủ các tham số có thể học của TRACED là θ và biểu diễn mất mát như sau:

L(θ) = L_code-text(θ) + L_program-state(θ) + L_var-cov(θ) (4)

4.2 Tinh chỉnh cụ thể theo tác vụ
TRACED tải các trọng số mô hình của các lớp Transformers, được huấn luyện trước để tạo ra các biểu diễn mã có nhận thức thực thi, và tiếp tục tinh chỉnh mô hình cho các tác vụ hạ nguồn. Chúng tôi xem xét ba tác vụ hạ nguồn làm ứng dụng chính cho TRACED: (1) Ước tính tĩnh về việc thực thi chương trình bao gồm cả dự đoán phủ sóng thực thi và dự đoán giá trị biến thời gian chạy; (2) Truy xuất bản sao ngữ nghĩa; (3) Phát hiện lỗ hổng.

Ước tính thực thi tĩnh. Mục tiêu của chúng tôi về huấn luyện trước là mã hóa các mẫu thực thi vào biểu diễn mã, vì vậy mô hình có thể ước tính việc thực thi chương trình một cách tĩnh. Như một ứng dụng trực tiếp, TRACED tinh chỉnh mô hình để dự đoán (1) phủ sóng thực thi và (2) giá trị biến thời gian chạy sử dụng mã nguồn và đầu vào chương trình. TRACED đánh giá mô hình được tinh chỉnh để ước tính việc thực thi của các chương trình chưa nhìn thấy theo cách tương tự.

Cụ thể, đối với dự đoán phủ sóng thực thi, TRACED xác định tất cả các câu lệnh phân nhánh để định vị các nhánh B = {b₁, b₂,..., bₘ}, trong mã nguồn. Nó huấn luyện mô hình để dự đoán một nhãn nhị phân, 0 có nghĩa là nhánh không được bao phủ bởi việc thực thi hiện tại và 1 có nghĩa là được bao phủ, cho mỗi bᵢ∈B. Để thuận tiện cho mô hình thực hiện dự đoán, token đặc biệt [MASK] được chèn vào đầu mỗi nhánh. Ví dụ, if-else sau có hai nhánh được xử lý trước cho dự đoán nhánh: if (điều kiện) {[MASK] ...} else {[MASK] ... }. Trong quá trình tinh chỉnh, các lớp Transformer học cách mã hóa thông tin nhánh vào biểu diễn token [MASK] tương ứng với attention hai chiều tích hợp và mã hóa vị trí. Sau đó đầu phân loại lấy các biểu diễn [MASK] để dự đoán xem một nhánh có được bao phủ bởi việc thực thi hiện tại hay không. Đối với dự đoán giá trị biến, TRACED xác định các biến V = {v₁, v₂,..., vₙ} và huấn luyện mô hình để dự đoán các giá trị được lượng tử hóa của chúng (§3.2) trong quá trình thực thi.

Truy xuất bản sao ngữ nghĩa. Phát hiện các bản sao ngữ nghĩa có ý nghĩa quan trọng đối với bảo trì phần mềm, nhưng rất thử thách trong thực tế vì sự chồng chéo về token và cấu trúc cú pháp giữa các bản sao ngữ nghĩa có thể khá hạn chế. Tác vụ này đòi hỏi mô hình ước tính hành vi chương trình mà không thực thi các chương trình và nắm bắt sự tương tự giữa chúng. Nó đánh giá khả năng lý luận ngữ nghĩa của mô hình để xác định sự tương tự mã và truy xuất các bản sao: cho một chương trình làm truy vấn, và một tập hợp tùy ý các chương trình làm ứng viên, mô hình cần xác định các bản sao ngữ nghĩa của truy vấn từ có thể hàng nghìn ứng viên.

Phát hiện lỗ hổng. Phát hiện lỗ hổng là một tác vụ quan trọng trong bảo mật phần mềm, nhằm xác định các lỗ hổng bảo mật tiềm ẩn trong mã phần mềm có thể bị khai thác bởi kẻ tấn công. Các lỗ hổng có thể tồn tại do nhiều lý do khác nhau, bao gồm lỗi lập trình, khiếm khuyết thiết kế hoặc vấn đề cấu hình. Phát hiện các lỗ hổng này sớm trong chu kỳ phát triển phần mềm có thể ngăn chặn các cuộc tấn công tiềm ẩn, giảm thiểu rủi ro và tiết kiệm tài nguyên. Chúng tôi tinh chỉnh mô hình được huấn luyện trước của TRACED trên các bộ dữ liệu bao gồm các mẫu mã dễ bị tổn thương và không dễ bị tổn thương, vì vậy mô hình học cách phân loại các hàm mã là dễ bị tổn thương hoặc không dễ bị tổn thương bằng cách ước tính hành vi thực thi của chúng.

5 THIẾT LẬP THỰC NGHIỆM

5.1 Thu thập dấu vết
Trong phần này, chúng tôi giải thích cách chúng tôi theo dõi thông tin động trong các chương trình để tạo ra các dấu vết cụ thể, cho mã nguồn và đầu vào chương trình.

Đầu tiên, chúng tôi biên dịch chương trình sử dụng gcc với các tùy chọn -g -O0. Tùy chọn -g bảo tồn thông tin gỡ lỗi, cần thiết để đọc các biến và vị trí mã nguồn sử dụng trình gỡ lỗi, và tùy chọn -O0 vô hiệu hóa tối ưu hóa trình biên dịch, có thể tối ưu hóa một số biến do đó ngăn chúng được đọc tại thời gian chạy. Chúng tôi sử dụng tùy chọn này vì chúng tôi tìm cách mô hình hóa ngữ nghĩa của mã nguồn về mặt giá trị biến thay vì mã máy được tối ưu hóa.

Thứ hai, chúng tôi tải chương trình với đầu vào tiêu chuẩn được chuyển hướng đến stdin và gắn trình gỡ lỗi gdb, sử dụng API Python để thực hiện lệnh theo dõi. Bắt đầu từ điểm nhập (main), chúng tôi thực thi chương trình từng dòng một sử dụng lệnh step. Tại mỗi dòng, chúng tôi in ra các giá trị cụ thể của tất cả các biến trong phạm vi. Chúng tôi cũng đặt các điểm dừng tại điểm nhập của mỗi hàm do người dùng định nghĩa, nơi chúng tôi ghi lại các giá trị của mỗi tham số. Đối với các kiểu số, chúng tôi chỉ đơn giản ghi lại biểu diễn chuỗi của chúng. Đối với các kiểu char và char * (chuỗi), chúng tôi ghi lại các giá trị có thể đọc được của con người của chars/chuỗi. Chúng tôi sử dụng pretty-printer của gdb để in các kiểu struct và các kiểu mảng được phân bổ tĩnh, chẳng hạn như int[<size>]. Đối với các kiểu con trỏ, chúng tôi in địa chỉ bộ nhớ của con trỏ dưới dạng mã hex. Chúng tôi chỉ theo dõi các hàm được định nghĩa trong mã nguồn và bỏ qua tất cả các hàm thư viện tiêu chuẩn.

5.2 Bộ dữ liệu

5.2.1 Bộ dữ liệu huấn luyện trước. Bộ dữ liệu CodeNet của IBM bao gồm 4.053 thử thách lập trình cho một số ngôn ngữ lập trình từ các nền tảng AIZU Online Judge và AtCoder, và mỗi vấn đề có tối đa hàng nghìn triển khai được gửi bởi các lập trình viên khác nhau. Trong công trình này, chúng tôi tập trung vào ngôn ngữ C làm nguồn tài nguyên chính cho việc huấn luyện trước và các tác vụ hạ nguồn, vì vậy chúng tôi xây dựng bộ dữ liệu huấn luyện trước của mình với các thử thách lập trình có giải pháp C. Bên cạnh số lượng lớn các mẫu và độ phức tạp của các thử thách lập trình, chúng tôi chọn CodeNet để xây dựng bộ dữ liệu của mình vì nó duy trì ít nhất một và nhiều nhất hai mười đầu vào có thể thực thi cho mỗi thử thách, vì vậy chúng tôi có thể thực thi và theo dõi các triển khai của thử thách, và do đó xây dựng các nhãn thực thi của chúng tôi cho mô hình học.

Trong số 1.900 thử thách lập trình với giải pháp C, chúng tôi chọn 1.805 trong số chúng để xây dựng bộ dữ liệu huấn luyện trước và để lại 95 vấn đề khác làm các vấn đề giữ lại để đánh giá khả năng của mô hình cho tác vụ ước tính thực thi tĩnh hạ nguồn. Chia các mẫu một cách nghiêm ngặt theo thử thách có hiệu quả tránh vấn đề rò rỉ dữ liệu từ tập huấn luyện sang tập giữ lại. Chúng tôi lấy mẫu ngẫu nhiên tối đa 200 dấu vết thực thi cho mỗi thử thách, và điều này kết thúc với 121.319 dấu vết huấn luyện.

5.2.2 Các tác vụ hạ nguồn. Trong phần này, chúng tôi giới thiệu các bộ dữ liệu chúng tôi sử dụng cho mỗi tác vụ hạ nguồn và giải thích các chỉ số đánh giá tương ứng. Thống kê của các bộ dữ liệu này trong Bảng 2.

Ước tính thực thi tĩnh. Chúng tôi xây dựng bộ dữ liệu cho tác vụ này sử dụng CodeNet. Chúng tôi xây dựng các mẫu huấn luyện từ 1.805 thử thách đã được chọn bởi việc huấn luyện trước, và xây dựng các mẫu đánh giá từ 95 thử thách giữ lại để tránh ghi nhớ mô hình và rò rỉ dữ liệu.

Chỉ số. Đối với dự đoán phủ sóng thực thi, chúng tôi xem xét các chỉ số đánh giá trong hai độ chi tiết: đường dẫn thực thi đầy đủ và phủ sóng nhánh. Cụ thể, đối với một mẫu với m nhánh, chúng tôi ký hiệu tập hợp đầy đủ các nhãn của chúng là L_B = {l_b1, l_b2,..., l_bm}, và tập hợp dự đoán mô hình là L̂_B = {l̂_b1, l̂_b2,..., l̂_bm}. Nếu L_B == L̂_B, chúng tôi coi dự đoán là khớp với đường dẫn thực thi đầy đủ. Đối với phủ sóng nhánh, chúng tôi tính toán sự xuất hiện của l_bi == l̂_bi, trong đó 1≤i≤m, và báo cáo độ chính xác, độ chính xác, độ nhớ và F1. Tương tự, đối với n giá trị biến được lượng tử hóa trong chương trình, Q_V = {q_v1, q_v2,..., q_vm}, mô hình của chúng tôi thực hiện dự đoán là Q̂_V = {q̂_v1, q̂_v2,..., q̂_vm}. Nếu Q_V == Q̂_V, chúng tôi nói mô hình dự đoán chính xác việc thực thi đầy đủ. Đối với khớp giá trị riêng lẻ, chúng tôi tính toán sự xuất hiện của q_vi == q̂_vi và báo cáo độ chính xác.

Truy xuất bản sao ngữ nghĩa. Chúng tôi sử dụng CodeXGLUE-POJ104 làm bộ dữ liệu cho tác vụ này. CodeXGLUE-POJ104 chứa 104 thử thách lập trình, và mỗi cái có 500 giải pháp C/C++ được gửi bởi các lập trình viên khác nhau. CodeXGLUE tái tạo nó như một điểm chuẩn công khai bằng cách chia bộ dữ liệu thành các tập Train (64 thử thách), Dev (16 thử thách) và Test (24 thử thách), không có thử thách chồng chéo giữa hai tập nào.

Chỉ số. MAP@R (Mean Average Precision @ R) là chỉ số chính của tác vụ này, nơi chúng tôi tuân theo thiết kế của điểm chuẩn CodeXGLUE. Average precision at R là một chỉ số phổ biến để đánh giá chất lượng truy xuất thông tin; nó đo lường điểm precision trung bình của một tập hợp các ứng viên bản sao top-R được trình bày để đáp ứng một chương trình truy vấn. "R" cho CodeXGLUE là 499 vì nó có 500 giải pháp cho mỗi thử thách.

Phát hiện lỗ hổng. Chúng tôi sử dụng ba bộ dữ liệu có sẵn công khai: REVEAL (RV), D2A và CodeXGLUE-Devign (CXG). Bộ dữ liệu REVEAL được quản lý bởi Chakraborty et al. để mô phỏng một kịch bản thế giới thực nơi lỗi tương đối hiếm, dẫn đến tỷ lệ khoảng 1:10 giữa các mẫu lỗi và lành tính. Bộ dữ liệu D2A là một bộ dữ liệu cân bằng tập trung vào các commit sửa lỗi. Nó gắn nhãn phiên bản trước của các hàm được sửa đổi là lỗi và phiên bản đã sửa là lành tính. Cuối cùng, bộ dữ liệu CodeXGLUE-Devign, được giới thiệu bởi Zhou et al., cũng là một bộ dữ liệu cân bằng đã được tái tạo như một điểm chuẩn công khai bởi CodeXGLUE, đảm bảo rằng tất cả các mô hình có thể được đánh giá sử dụng cùng các phân chia train/valid/test.

Chỉ số. REVEAL là một bộ dữ liệu không cân bằng, vì vậy chúng tôi sử dụng F1 làm chỉ số đánh giá. D2A và Devign là các bộ dữ liệu cân bằng, vì vậy chúng tôi tuân theo điểm chuẩn gốc để báo cáo độ chính xác phân loại.

Bảng 2: Chi tiết của các bộ dữ liệu tác vụ hạ nguồn.

Tác vụ | Bộ dữ liệu | Train | Valid | Test
--- | --- | --- | --- | ---
Ước tính thực thi | CodeNet | 121,319 | 13,116 | 13,116
Phát hiện bản sao | CXG-POJ104 | 32,000 | 8,000 | 12,000
Phát hiện lỗ hổng | REVEAL | 15,867 | 2,268 | 4,535
| D2A | 4,644 | 597 | 619
| CXG-Devign | 21,854 | 2,732 | 2,732

5.3 Cấu hình mô hình
Xương sống của TRACED là một kiến trúc RoBERTa BASE tiêu chuẩn với 12 lớp Transformer-encoder, và mỗi lớp có 12 đầu attention và chiều ẩn là 768. TRACED được khởi tạo với các trọng số được huấn luyện trước từ UnixCoder, và chúng tôi sử dụng tokenizer BPE của nó để chia các token hiếm thành các token con BPE. Độ dài chuỗi tối đa là 1024 token BPE, và chuỗi dài hơn sẽ bị cắt bớt. Khi mẫu mã được ghép với các đầu vào có thể thực thi, độ dài tối đa cho đầu vào có thể thực thi là 64, và mã nguồn là 960. Các thí nghiệm của chúng tôi được tiến hành trên 2×24GB NVIDIA GeForce RTX-3090 GPU. Chúng tôi tiếp tục huấn luyện trước mô hình trong 10 epoch để học việc thực thi chương trình với hai tỷ lệ học, 5e-5 và 2e-5, và báo cáo các mô hình hoạt động tốt nhất cho các tác vụ hạ nguồn. Đối với tất cả các tác vụ tinh chỉnh, chúng tôi sử dụng tỷ lệ học 8e-6. Tỷ lệ học thường giảm cho các giai đoạn sau, vì vậy TRACED tuân theo cùng thiết kế. Chúng tôi sử dụng bộ tối ưu Adam với sự suy giảm tỷ lệ học tuyến tính. Mô hình của chúng tôi được thực hiện chủ yếu với Pytorch và Huggingface.

6 ĐÁNH GIÁ
Trong phần này, chúng tôi đặt ra bốn câu hỏi nghiên cứu sau:
• RQ1: TRACED hiệu quả như thế nào trong việc ước tính tĩnh việc thực thi chương trình?
• RQ2: Chiến lược huấn luyện được đề xuất của chúng tôi đóng góp như thế nào vào việc học việc thực thi chương trình?
• RQ3: Các giá trị được lượng tử hóa được đề xuất của chúng tôi cho các chương trình có hiệu quả trong việc hướng dẫn mô hình học việc thực thi chương trình không?
• RQ4: TRACED hoạt động như thế nào so với các đường cơ sở được huấn luyện trước tĩnh cho các tác vụ hiểu mã?

6.1 RQ1. Hiệu quả của TRACED trong ước tính tĩnh về thực thi
Trong phần này, chúng tôi chứng minh hiệu quả của TRACED trong việc ước tính tĩnh việc thực thi chương trình. Đánh giá thử thách và thực tế hơn so với việc huấn luyện trước của TRACED vì nó đòi hỏi mô hình dự đoán không chỉ cho các biến riêng lẻ mà còn cho các nhánh và đường dẫn thực thi đầy đủ.

Đường cơ sở. Trong RQ này, chúng tôi chủ yếu so sánh TRACED có nhận thức thực thi với UnixCoder. Bây giờ chúng tôi giải thích lý do cho sự lựa chọn này. Đầu tiên, TRACED được khởi tạo với các trọng số UnixCoder được huấn luyện trước, vì vậy so sánh TRACED với hiệu suất UnixCoder là một đánh giá trực tiếp về tác động của việc huấn luyện trước được đề xuất của chúng tôi. Thứ hai, UnixCoder báo cáo hiệu suất tiên tiến trong nhiều tác vụ, bao gồm phát hiện bản sao, tìm kiếm và tóm tắt mã, và tạo và hoàn thành mã, vượt trội đáng kể so với các mô hình mã được huấn luyện trước khác, chẳng hạn như CodeBERT và GraphCodeBERT. Thứ ba, nó tiêu thụ tối đa 1.024 token, trong khi hầu hết các mô hình mã được huấn luyện trước lấy tối đa 512 token. Bằng cách tiêu thụ chuỗi dài hơn, UnixCoder có thể xử lý các chương trình dài hơn và thực hiện dự đoán hoàn chỉnh mà không cắt bớt mã trong nhiều trường hợp. Vì TRACED cũng được thiết kế để tiêu thụ 1.024 token, không công bằng khi so sánh nó trong tác vụ này với các đường cơ sở có độ dài tối đa 512, vì các đường cơ sở sẽ nhất thiết xem xét ít nhánh hơn để dự đoán.

Bảng 3: Hiệu suất về ước tính thực thi tĩnh.

Mô hình | Phủ sóng | Giá trị thời gian chạy
--- | --- | ---
| Đường dẫn đầy đủ Acc | Nhánh Acc | Prec | Rec | F1 | Thực thi đầy đủ Acc | Var Acc
UnixCoder | 63.7 | 79.7 | 81.7 | 85.4 | 83.5 | 39.3 | 87.8
TRACED | 71.6 | 83.1 | 84.6 | 88.1 | 86.3 | 49.2 | 89.2
-w/o MLM | 70.4 | 82.6 | 85.3 | 86.0 | 85.6 | 49.0 | 89.2
-w/o PSP | 69.0 | 81.4 | 83.0 | 86.9 | 84.9 | 44.0 | 87.4
-w/o VCP | 66.1 | 80.3 | 82.4 | 85.6 | 84.0 | 46.7 | 89.0
-MLM-only | 65.6 | 81.0 | 83.1 | 86.0 | 84.6 | 43.0 | 87.5

Kết quả. Sự so sánh được hiển thị trong Bảng 3, Hàng 1 so với Hàng 2. TRACED vượt trội đáng kể so với UnixCoder trong việc ước tính tĩnh phủ sóng thực thi và giá trị động của các biến, đặc biệt khi độ chi tiết đánh giá là thô, tức là đường dẫn thực thi đầy đủ (cột Full Path trong Bảng 3) và các giá trị thời gian chạy của việc thực thi đầy đủ (cột Full Exec trong Bảng 3). TRACED dự đoán chính xác các đường dẫn thực thi hoàn chỉnh cho 71,6% mẫu giữ lại và dự đoán chính xác tất cả giá trị biến cho 49,2% việc thực thi, cho thấy việc huấn luyện trước có nhận thức thực thi cải thiện hiệu suất của UnixCoder 12,4% và 25,2%, tương ứng.

Nghiên cứu trường hợp với các ví dụ định tính. Chúng tôi trình bày hai ví dụ định tính trong Hình 5 và 6 để so sánh cụ thể TRACED với UnixCoder trong dự đoán phủ sóng thực thi và giá trị thời gian chạy, tương ứng. Cả hai mẫu đều có logic thực thi đơn giản từ góc độ con người, nhưng UnixCoder được huấn luyện trước tĩnh vẫn thất bại trong việc ước tính chính xác chúng. Hình 5 minh họa rằng UnixCoder không nhạy cảm với các đầu vào khác nhau kích hoạt phủ sóng thực thi khác nhau, trong khi TRACED có thể xác định các mối quan hệ số học giữa các giá trị khác nhau. Hình 6 minh họa khả năng của TRACED trong việc lộ ra các hành vi chương trình bất thường.

//Input: 19 100
#include <stdio.h>
int main(){
int A, N, T, B;
scanf("%d %d", &N, &A);
T = N * N;
B = T - A;
if(A > 0) {printf("%d", B);} // Branch-1
else {printf("%d", T);} // Branch-2
return 0;
}

Dự đoán UnixCoder (Sai)
Branch-1: Không được thực thi
Branch-2: Không được thực thi

Dự đoán TRACED (Đúng)
Branch-1: Được thực thi
Branch-2: Không được thực thi

Hình 5: Ví dụ định tính về dự đoán phủ sóng thực thi. Mã nguồn giống như Hình 1, nhưng đầu vào kích hoạt một đường dẫn thực thi khác. TRACED chính xác lật dự đoán trong khi UnixCoder vẫn giữ nguyên dự đoán.

//Input: 4 4320 4320 4320
#include <stdio.h>
int main ( void ) {
int n, a, max = 0, sum = 0, i;
for (i = 0; i < n; i++){ // Giá trị được lượng tử hóa của n?
scanf("\%d", &a);
if(a > max) max = a;
sum += a;
}
printf("\%d\\n" , sum - max / 2);
return 0;
}

Dự đoán UnixCoder (Sai)
n: Không

Dự đoán TRACED (Đúng)
n: Âm lớn

Hình 6: Ví dụ định tính về dự đoán giá trị thời gian chạy. Mẫu chứa một lỗ hổng loại CWE-457 "Sử dụng biến chưa khởi tạo". Biến n chưa khởi tạo, được gán ngẫu nhiên là -32767, được sử dụng trong for-loop. TRACED thành công lộ ra hành vi bất thường này một cách tĩnh bằng cách xác định n là giá trị "Âm lớn" trong khi UnixCoder thất bại. Dự đoán của các biến khác được ẩn để minh họa tốt hơn.

Kết quả-1: Với số lượng tham số có thể học tương tự, TRACED vượt trội so với mô hình mã được huấn luyện trước tiên tiến trong tác vụ ước tính tĩnh việc thực thi chương trình. Việc huấn luyện trước được đề xuất của chúng tôi thành công mã hóa nhận thức thực thi vào các biểu diễn mã của TRACED.

6.2 RQ2. Hiệu quả của các mục tiêu huấn luyện trước của TRACED
Một trong những đóng góp chính của bài báo này là đề xuất huấn luyện trước đa tác vụ để học hiệu quả các biểu diễn mã có nhận thức thực thi. Trong RQ này, chúng tôi nghiên cứu hiệu quả và đóng góp của mỗi mục tiêu của TRACED, và do đó minh họa tầm quan trọng của các tác vụ múltiple.

Để tiến hành các thí nghiệm này, chúng tôi loại bỏ một mục tiêu huấn luyện trước mỗi lần và huấn luyện trước biến thể với thiết lập hoàn toàn giống như mô hình chính. Sau đó chúng tôi tinh chỉnh biến thể trên tác vụ ước tính thực thi tĩnh và so sánh hiệu suất với mô hình chính. Chúng tôi cũng xem xét một biến thể được huấn luyện trước trên bộ dữ liệu của chúng tôi nhưng chỉ với các mục tiêu MLM. Kết quả được hiển thị trong Hàng 3-6 của Bảng 3. Loại bỏ bất kỳ mục tiêu nào đều làm tổn hại hiệu suất của TRACED, cho thấy rằng việc học toàn diện cả thuộc tính mã tĩnh và động hiệu quả hơn việc học một góc độ đơn lẻ.

Kết quả-2: Huấn luyện trước đa tác vụ của TRACED giúp mô hình học toàn diện cả khía cạnh tĩnh và động của mã nguồn. Loại bỏ bất kỳ một trong ba mục tiêu huấn luyện trước của TRACED đều làm tổn hại đáng kể hiệu suất của mô hình trong việc ước tính tĩnh việc thực thi chương trình.

6.3 RQ3. Hiệu quả của các giá trị biến được lượng tử hóa của TRACED
Một đóng góp khác của bài báo này là biểu diễn đơn giản và gọn gàng của việc thực thi chương trình giúp các mô hình mã nắm bắt các thuộc tính mã động. Trong RQ này, chúng tôi tiết lộ thực nghiệm rằng thiết kế các giá trị biến được lượng tử hóa đặc biệt đóng góp vào việc học hiệu quả của các mô hình mã, vì nó giảm tính thưa thớt dữ liệu của các giá trị biến nhưng vẫn định nghĩa các danh mục giá trị đủ chi tiết để phân biệt các giá trị khác nhau.

Để cô lập đánh giá các giá trị được lượng tử hóa của TRACED, chúng tôi huấn luyện trước một số biến thể bằng cách chỉ tái tạo các nhãn giá trị được lượng tử hóa, tức là q_var trong Phương trình 2, sử dụng các chiến lược trừu tượng hóa giá trị khác nhau. Ví dụ, khi chúng tôi huấn luyện trước một biến thể nghiên cứu tác động của các giá trị cụ thể, chúng tôi thay thế q_var được định nghĩa của TRACED bằng các giá trị được theo dõi cụ thể. Vì các chiến lược khác nhau trừu tượng hóa các giá trị ở các độ chi tiết khác nhau, không khả thi để so sánh chúng cho tác vụ dự đoán giá trị, vì chiến lược thô sẽ có lợi. Do đó, chúng tôi chỉ tinh chỉnh các biến thể được nghiên cứu cho dự đoán phủ sóng thực thi.

Đường cơ sở. Đầu tiên, chúng tôi xem xét so sánh với các giá trị cụ thể, vì đây là chiến lược trực quan nhất để biểu diễn các giá trị biến. Sau đó, chúng tôi xem xét hai trừu tượng hóa dữ liệu từ LExecutor: thô và tinh. Chúng chia sẻ trực giác cấp cao tương tự với chúng tôi, ánh xạ các giá trị cụ thể thành các bin được định nghĩa trước để giảm độ phức tạp dữ liệu và do đó giúp việc học của mô hình. Lưu ý rằng trừu tượng hóa dữ liệu của LExecutor phục vụ một mục tiêu khác với TRACED, và tập trung vào Python trong khi TRACED tập trung vào C, vì vậy chúng tôi không thể tái sử dụng trực tiếp các bin được định nghĩa trước của họ. Vì định nghĩa của họ về trừu tượng hóa dữ liệu rõ ràng và đơn giản, chúng tôi tái thực hiện trừu tượng hóa dữ liệu của họ cho ngôn ngữ C và tích hợp nó vào khung của chúng tôi để so sánh. Chúng tôi thảo luận và so sánh LExecutor với TRACED chi tiết hơn trong phần Công trình liên quan (§7).

Kết quả. Sự so sánh của các trừu tượng hóa giá trị được hiển thị trong Hình 7. Không ngạc nhiên, các giá trị cụ thể báo cáo hiệu suất kém so với các trừu tượng hóa dữ liệu khác, tiết lộ thực nghiệm những khó khăn cho các mô hình mã để khớp các phân phối dữ liệu thưa thớt và phức tạp.

Hình 7: So sánh thiết kế của TRACED về các giá trị biến được lượng tử hóa với các chiến lược trừu tượng hóa giá trị khác.

Thú vị là, chúng tôi nhận thấy cả hai trừu tượng hóa của LExecutor đều hoạt động hơi kém hơn TRACED. Chúng tôi suy đoán rằng LExecutor không nhạy cảm như TRACED đối với các mối quan hệ số trong các câu lệnh điều kiện, vì chúng không phân biệt giữa các giá trị nhỏ, thường xuyên và lớn. Lưu ý rằng phủ sóng thực thi không phải là trọng tâm chính của LExecutor, vì vậy các danh mục tinh hơn không cần thiết để phục vụ mục tiêu của nó, trong khi chúng được chứng minh thực nghiệm là cần thiết cho phạm vi của TRACED.

Kết quả-3: Các giá trị biến được lượng tử hóa của TRACED đóng góp trực tiếp vào hiệu quả của việc huấn luyện trước có nhận thức thực thi của nó. Nó giảm tính thưa thớt dữ liệu của các giá trị cụ thể nhưng định nghĩa các danh mục giá trị đủ chi tiết để phân biệt các giá trị khác nhau để lý luận về các đường dẫn thực thi.

6.4 RQ4. Hiệu suất của TRACED trong các tác vụ hiểu mã
Trong RQ này, chúng tôi nghiên cứu hiệu suất của TRACED trên hai tác vụ hiểu mã: truy xuất bản sao ngữ nghĩa và phát hiện lỗ hổng cấp hàm. Lưu ý rằng các mẫu cho các tác vụ này không được ghép với các đầu vào có thể thực thi, vì vậy mô hình cần lý luận về ngữ nghĩa mã chung để thực hiện dự đoán.

Đường cơ sở. Chúng tôi xem xét năm mô hình mã được huấn luyện trước với kích thước tham số tương tự như TRACED. CodeBERT huấn luyện trước một mô hình RoBERTa với các tác vụ MLM và phát hiện token được thay thế (RTD). GraphCodeBERT được khởi tạo với CodeBERT và tiếp tục huấn luyện trước với các đồ thị luồng dữ liệu được tăng cường để học các phụ thuộc dữ liệu tĩnh. PLBART và CodeT5 cả hai đều áp dụng kiến trúc thần kinh seq2seq, trong đó PLBART điều chỉnh mô hình BART để học dịch và tóm tắt mã, và CodeT5 điều chỉnh để dự đoán các token mã bị thiếu và định vị các định danh. Chúng tôi cũng, một lần nữa, xem xét UnixCoder làm đường cơ sở.

Kết quả. Chúng tôi hiển thị kết quả trong Bảng 4. Mặc dù các mẫu trong các điểm chuẩn này không có đầu vào có thể thực thi, TRACED vẫn vượt trội so với các mô hình được huấn luyện trước tĩnh với một biên độ rõ ràng. Chúng tôi suy đoán lý do là TRACED có thể ước tính các hành vi thực thi chung mà không có đầu vào cụ thể, và ngữ nghĩa chương trình liên quan đến hai tác vụ hiểu mã này có thể được nắm bắt tốt hơn với cảm giác chung như vậy. Cụ thể, truy xuất bản sao đòi hỏi mô hình xác định sự tương tự hành vi của mã vì các bản sao ngữ nghĩa chủ yếu khác nhau về văn bản mã và cú pháp. Ngoài ra, mã dễ bị tổn thương với các dị thường tiềm ẩn có thể được TRACED xác định trực tiếp trong một số trường hợp như Hình 6.

Bảng 4: So sánh truy xuất bản sao và phát hiện lỗi.

Tác vụ | Truy xuất bản sao | Phát hiện lỗ hổng
--- | --- | ---
Bộ dữ liệu | POJ-104 | RV | D2A | CXG
Chỉ số | MAP@R | F1 | Acc | Acc
CodeBERT | 82.7 | 47.3 | 59.2 | 63.4
GraphCodeBERT | 86.7 | 46.6 | 61.0 | 62.9
PLBART-base | 75.9 | 46.9 | 61.7 | 63.3
CodeT5-base* | 65.9 | 46.5 | 62.1 | 64.4
UnixCoder | 89.5 | 47.4 | 61.2 | 65.3
TRACED | 91.2 | 50.4 | 62.1 | 65.9

*CodeT5-base có 223M tham số, khoảng gấp đôi so với các đường cơ sở khác và TRACED. Chúng tôi báo cáo hiệu suất của nó vì CodeT5-small chỉ có 60M tham số và hoạt động kém, và CodeT5 không cung cấp mô hình ∼110M.

Kết quả-4: TRACED vượt trội so với các mô hình được huấn luyện trước tĩnh trong các tác vụ truy xuất bản sao và phát hiện lỗ hổng, cho thấy ước tính chung về thực thi của TRACED giúp nó nắm bắt ngữ nghĩa mã hiệu quả hơn.

7 CÔNG TRÌNH LIÊN QUAN
Các mô hình được huấn luyện trước cho mã nguồn. Cộng đồng nghiên cứu đã thể hiện sự quan tâm ngày càng tăng trong việc phát triển các mô hình Transformer được huấn luyện trước cho mã nguồn. Các mô hình này có thể được phân loại rộng rãi thành ba kiến trúc chính: Chỉ mã hóa, Chỉ giải mã và Mã hóa-giải mã. Các mô hình chỉ mã hóa chủ yếu sử dụng mục tiêu MLM và các tác vụ hiểu chuỗi (ví dụ, dự đoán câu lệnh tiếp theo và tương phản ngữ nghĩa). Kiến trúc này xuất sắc trong việc hiểu các tính năng mã tĩnh. Mặt khác, các mô hình chỉ giải mã thường được huấn luyện bằng cách dự đoán các token mã theo cách từ trái sang phải. Kiến trúc này tập trung vào việc tạo ra văn bản mã dựa trên các mẫu đã học. Các mô hình mã hóa-giải mã kết hợp điểm mạnh của cả mô hình chỉ mã hóa và chỉ giải mã và được huấn luyện trước sử dụng các tác vụ khác nhau, bao gồm tự động mã hóa khử nhiễu để tái tạo các token được hoán vị sai, dự đoán các định danh thiếu trong mã và khôi phục tên phương thức từ mã nguồn.

Các mô hình này chủ yếu tập trung vào việc học các khía cạnh tĩnh của mã nguồn nhưng thường bỏ lỡ việc nắm bắt các thuộc tính động của việc thực thi mã. Hạn chế này hạn chế các mô hình này khỏi việc suy luận chính xác các hành vi thời gian chạy, các vấn đề gỡ lỗi và hiểu các trạng thái chương trình phức tạp.

Mô hình hóa việc thực thi chương trình. Pei et al. đề xuất một loạt công trình tiên phong để học việc thực thi của các chương trình nhị phân với các mô hình dựa trên Transformer. Họ sử dụng các giá trị cụ thể từ các thanh ghi, có thể thực hiện được trong phạm vi của họ vì các chương trình nhị phân có không gian nhỏ hơn của các giá trị và hiệu ứng có thể so với mã nguồn. Mặt khác, công trình của chúng tôi tập trung vào mã hóa việc thực thi ở cấp độ mã nguồn bằng cách bắt chước thực hành mã của các nhà phát triển. Các biến trong mã nguồn có các kiểu dữ liệu và giá trị phức tạp hơn so với các thanh ghi máy. Chúng tôi giới thiệu các giá trị được lượng tử hóa để giảm độ phức tạp và tính thưa thớt dữ liệu.

Một số công trình đã cố gắng học thực thi chương trình như một mục tiêu trực tiếp. Souza và Pradel cũng đề xuất LExecutor để dự đoán các giá trị thiếu trong quá trình thực thi. Trong khi nó chia sẻ trực giác tương tự về việc ánh xạ các giá trị cụ thể thành các danh mục rời rạc, LExecutor khác biệt với TRACED trong một số góc độ. Đầu tiên, LExecutor chỉ tập trung vào dự đoán các giá trị, trong khi TRACED đề xuất một chiến lược huấn luyện trước chung để mã hóa nhận thức thực thi toàn diện, không chỉ giá trị mà còn phủ sóng thực thi, vào biểu diễn mã. Bên cạnh đó, để tạo ra các biểu diễn mã với chất lượng tốt hơn, TRACED cùng học cả văn bản mã và việc thực thi động thay vì gắn bó với một góc độ duy nhất. Do các mục tiêu và thiết kế khác biệt, chúng tôi minh họa thực nghiệm trong RQ3 (§6.3) rằng các trừu tượng hóa giá trị của LExecutor không hoàn toàn phù hợp với phạm vi của chúng tôi.

Nie et al. chú thích các chương trình với thông tin về việc thực thi có thể của chương trình mà không thực thi mã nhưng chỉ cung cấp thông tin có sẵn tĩnh. Ngược lại, một số công trình yêu cầu các dấu vết động làm đầu vào. Chúng tôi cho thấy rằng việc huấn luyện trước của TRACED có thể mã hóa nhận thức thực thi vào biểu diễn mã và ước tính ngữ nghĩa động chỉ với thông tin tĩnh.

8 CÁC MỐI ĐE DỌA ĐỐI VỚI TÍNH HỢP LỆ
Tính hợp lệ nội bộ. Đầu tiên, thiết kế hiện tại của giá trị được lượng tử hóa không bao phủ tất cả các biến trong chương trình do độ phức tạp của cấu trúc dữ liệu, phạm vi giá trị và/hoặc phân bổ bộ nhớ của chúng. Thứ hai, hiện tại, chúng tôi chỉ theo dõi chương trình bằng cách cung cấp cho nó các đầu vào hợp lệ và có thể thực thi không sẽ kết thúc chương trình hoặc gây ra lỗi. Điều này có thể làm cho mô hình kém có khả năng nắm bắt hành vi kết thúc chương trình và gây ra lỗi.

Tính hợp lệ bên ngoài. Hiện tại, TRACED chỉ hỗ trợ ngôn ngữ lập trình C. Hạn chế này là do sự phụ thuộc vào khả năng của trình theo dõi được sử dụng để ghi lại lịch sử thực thi, có thể không sẵn có hoặc hiệu quả như nhau cho các ngôn ngữ lập trình khác. Để mở rộng khả năng áp dụng của TRACED, cần đảm bảo rằng trình theo dõi được sử dụng có thể nắm bắt chính xác và nhất quán thông tin cần thiết trên các ngôn ngữ khác nhau. Điều chỉnh TRACED cho nhiều ngôn ngữ sẽ yêu cầu phát triển hoặc điều chỉnh các trình theo dõi có thể xử lý hiệu quả sự phức tạp của từng ngôn ngữ và tạo ra kết quả có thể so sánh, cho phép phân tích nhất quán hành vi mã trên một phạm vi rộng hơn các ngôn ngữ lập trình.

9 KẾT LUẬN
Trong bài báo này, chúng tôi đề xuất TRACED, một mô hình được huấn luyện trước có nhận thức thực thi cùng học các thuộc tính mã tĩnh và động, để giải quyết hạn chế của các mô hình mã được huấn luyện trước tĩnh hiện có. Đánh giá tiết lộ thực nghiệm rằng TRACED hiệu quả hơn trong việc ước tính thực thi mã một cách tĩnh so với các mô hình được huấn luyện trước tĩnh. TRACED cũng thành công chuyển nhận thức thực thi sang các tác vụ hiểu mã.

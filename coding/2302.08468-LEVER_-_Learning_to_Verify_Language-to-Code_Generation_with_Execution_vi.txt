# 2302.08468.pdf
# ÄÆ°á»£c chuyá»ƒn Ä‘á»•i tá»« PDF sang TXT
# ÄÆ°á»ng dáº«n nguá»“n: /home/admin88/arxiv-downloader/coding/2302.08468.pdf
# KÃ­ch thÆ°á»›c tá»‡p: 1891989 bytes

===============================================
Ná»˜I DUNG Tá»†P PDF
===============================================

--- TRANG 1 ---
LEVER : Há»c cÃ¡ch XÃ¡c minh Sinh code tá»« NgÃ´n ngá»¯ vá»›i Thá»±c thi
Ansong Ni1â€ Srini Iyer2Dragomir Radev1Ves Stoyanov2Wen-tau Yih2Sida I. Wang2 *Xi Victoria Lin2 *

TÃ³m táº¯t
Sá»± ra Ä‘á»i cá»§a cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn 
code (code LLMs) Ä‘Ã£ dáº«n Ä‘áº¿n tiáº¿n bá»™ Ä‘Ã¡ng ká»ƒ trong sinh code 
tá»« ngÃ´n ngá»¯ tá»± nhiÃªn. CÃ¡c phÆ°Æ¡ng phÃ¡p tiÃªn tiáº¿n nháº¥t trong 
lÄ©nh vá»±c nÃ y káº¿t há»£p giáº£i mÃ£ LLM vá»›i viá»‡c cáº¯t tá»‰a máº«u vÃ  
xáº¿p háº¡ng láº¡i sá»­ dá»¥ng cÃ¡c test case hoáº·c heuristics dá»±a trÃªn 
káº¿t quáº£ thá»±c thi. Tuy nhiÃªn, viá»‡c thu tháº­p test cases cho 
nhiá»u á»©ng dá»¥ng thá»±c táº¿ cá»§a ngÃ´n ngá»¯-sang-code lÃ  thÃ¡ch thá»©c, 
vÃ  heuristics khÃ´ng thá»ƒ náº¯m báº¯t tá»‘t cÃ¡c Ä‘áº·c trÆ°ng ngá»¯ nghÄ©a 
cá»§a káº¿t quáº£ thá»±c thi, nhÆ° kiá»ƒu dá»¯ liá»‡u vÃ  pháº¡m vi giÃ¡ trá»‹, 
vá»‘n thÆ°á»ng chá»‰ ra tÃ­nh Ä‘Ãºng Ä‘áº¯n cá»§a chÆ°Æ¡ng trÃ¬nh. Trong 
cÃ´ng trÃ¬nh nÃ y, chÃºng tÃ´i Ä‘á» xuáº¥t LEVER , má»™t phÆ°Æ¡ng phÃ¡p 
Ä‘Æ¡n giáº£n Ä‘á»ƒ cáº£i thiá»‡n sinh code tá»« ngÃ´n ngá»¯ báº±ng cÃ¡ch há»c 
xÃ¡c minh cÃ¡c chÆ°Æ¡ng trÃ¬nh Ä‘Æ°á»£c sinh ra vá»›i káº¿t quáº£ thá»±c thi 
cá»§a chÃºng. Cá»¥ thá»ƒ, chÃºng tÃ´i huáº¥n luyá»‡n cÃ¡c verifier Ä‘á»ƒ xÃ¡c 
Ä‘á»‹nh xem má»™t chÆ°Æ¡ng trÃ¬nh Ä‘Æ°á»£c láº¥y máº«u tá»« LLMs cÃ³ Ä‘Ãºng hay 
khÃ´ng dá»±a trÃªn Ä‘áº§u vÃ o ngÃ´n ngá»¯ tá»± nhiÃªn, chÃ­nh chÆ°Æ¡ng trÃ¬nh 
Ä‘Ã³ vÃ  káº¿t quáº£ thá»±c thi cá»§a nÃ³. CÃ¡c chÆ°Æ¡ng trÃ¬nh Ä‘Æ°á»£c láº¥y máº«u 
Ä‘Æ°á»£c xáº¿p háº¡ng láº¡i báº±ng cÃ¡ch káº¿t há»£p Ä‘iá»ƒm xÃ¡c minh vá»›i xÃ¡c 
suáº¥t sinh cá»§a LLM, vÃ  marginalize trÃªn cÃ¡c chÆ°Æ¡ng trÃ¬nh cÃ³ 
cÃ¹ng káº¿t quáº£ thá»±c thi. TrÃªn bá»‘n dataset thuá»™c cÃ¡c lÄ©nh vá»±c 
table QA, math QA vÃ  láº­p trÃ¬nh Python cÆ¡ báº£n, LEVER liÃªn 
tá»¥c cáº£i thiá»‡n so vá»›i cÃ¡c code LLMs cÆ¡ sá»Ÿ (4.6% Ä‘áº¿n 10.9% 
vá»›i code-davinci-002) vÃ  Ä‘áº¡t Ä‘Æ°á»£c káº¿t quáº£ state-of-the-art 
má»›i trÃªn táº¥t cáº£ chÃºng.

1. Giá»›i thiá»‡u
Kháº£ nÄƒng Ã¡nh xáº¡ ngÃ´n ngá»¯ tá»± nhiÃªn sang code thá»±c thi Ä‘Æ°á»£c 
lÃ  ná»n táº£ng cá»§a nhiá»u á»©ng dá»¥ng AI nhÆ° giao diá»‡n cÆ¡ sá»Ÿ dá»¯ 
liá»‡u (Pasupat & Liang, 2015; Yu et al., 2018; Shi et al., 
2020), Ä‘iá»u khiá»ƒn robot (Zhou et al., 2021; Shridhar et al., 
2020) vÃ  trá»£ lÃ½ áº£o (Agashe et al., 2019; Lai et al., 2022). 
Nhá»¯ng tiáº¿n bá»™ gáº§n Ä‘Ã¢y vá» cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n (LLMs) 
(Brown et al., 2020; Wei et al., 2021; Chowdhery et al., 
2022), Ä‘áº·c biá»‡t lÃ  nhá»¯ng mÃ´ hÃ¬nh Ä‘Æ°á»£c pre-train trÃªn code 
(code LLMs) (Chen et al., 2021a; Fried et al., 2022; Nijkamp 
et al., 2022; Li et al., 2022a), Ä‘Ã£ cho tháº¥y tiá»m nÄƒng lá»›n 
trong cÃ¡c tÃ¡c vá»¥ nÃ y vá»›i há»c few-shot trong ngá»¯ cáº£nh (Shi 
et al., 2022; Chen et al., 2022a; Zhang et al., 2022). Tuy 
nhiÃªn hiá»‡u suáº¥t cá»§a chÃºng váº«n cÃ²n xa hoÃ n háº£o (Chen et al., 
2021a). XÃ©t Ä‘áº¿n chi phÃ­ tÃ­nh toÃ¡n Ä‘á»ƒ finetune cÃ¡c mÃ´ hÃ¬nh 
nhÆ° váº­y, viá»‡c khÃ¡m phÃ¡ cÃ¡c cÃ¡ch Ä‘á»ƒ cáº£i thiá»‡n chÃºng mÃ  khÃ´ng 
thay Ä‘á»•i tham sá»‘ lÃ  háº¥p dáº«n.

Má»™t quan sÃ¡t then chá»‘t lÃ  trong khi LLMs gáº·p khÃ³ khÄƒn vá»›i 
Ä‘á»™ chÃ­nh xÃ¡c trong setting few-shot, nÃ³ thÆ°á»ng táº¡o ra Ä‘áº§u 
ra Ä‘Ãºng khi Ä‘á»§ sá»‘ máº«u Ä‘Æ°á»£c rÃºt ra. CÃ¡c cÃ´ng trÃ¬nh trÆ°á»›c Ä‘Ã¢y 
Ä‘Ã£ cho tháº¥y ráº±ng majority voting vÃ  lá»c báº±ng test cases cÃ³ 
thá»ƒ tÄƒng Ä‘Ã¡ng ká»ƒ hiá»‡u suáº¥t cá»§a chÃºng khi cÃ¡c máº«u Ä‘Æ°á»£c rÃºt 
ra á»Ÿ quy mÃ´ lá»›n (Chen et al., 2021a; Austin et al., 2021; 
Li et al., 2022a). Shen et al. (2021) vÃ  Cobbe et al. (2021) 
tiáº¿p tá»¥c chá»©ng minh hiá»‡u quáº£ cá»§a viá»‡c huáº¥n luyá»‡n má»™t verifier 
vÃ  sá»­ dá»¥ng Ä‘iá»ƒm xÃ¡c minh Ä‘á»ƒ xáº¿p háº¡ng láº¡i cÃ¡c giáº£i phÃ¡p á»©ng 
viÃªn cho cÃ¡c bÃ i toÃ¡n toÃ¡n há»c tháº¿ giá»›i. So vá»›i cÃ¡c phÆ°Æ¡ng 
phÃ¡p chá»‰ dá»±a vÃ o tÃ­nh nháº¥t quÃ¡n thá»±c thi vÃ  cáº¯t tá»‰a lá»—i, 
cÃ¡c verifier Ä‘Æ°á»£c huáº¥n luyá»‡n cÃ³ thá»ƒ sá»­ dá»¥ng cÃ¡c Ä‘áº·c trÆ°ng 
ngá»¯ nghÄ©a phong phÃº trong cÃ¡c giáº£i phÃ¡p mÃ´ hÃ¬nh, nhÆ° kiá»ƒu 
dá»¯ liá»‡u, pháº¡m vi giÃ¡ trá»‹, vÃ  thuá»™c tÃ­nh biáº¿n, cÃ³ thá»ƒ lÃ  chá»‰ 
bÃ¡o máº¡nh vá» tÃ­nh Ä‘Ãºng Ä‘áº¯n cá»§a cÃ¡c chÆ°Æ¡ng trÃ¬nh. Trong khi 
Cobbe et al. (2021) vÃ  cÃ¡c cÃ´ng trÃ¬nh tiáº¿p theo (Li et al., 
2022b; Kadavath et al., 2022) táº­p trung vÃ o xÃ¡c minh cÃ¡c 
giáº£i phÃ¡p ngÃ´n ngá»¯ tá»± nhiÃªn bá»Ÿi LMs, má»™t cÃ¢u há»i tá»± nhiÃªn 
lÃ  liá»‡u cÃ¹ng phÆ°Æ¡ng phÃ¡p cÃ³ thá»ƒ Ä‘Æ°á»£c Ã¡p dá»¥ng cho cÃ¡c giáº£i 
phÃ¡p chÆ°Æ¡ng trÃ¬nh hay khÃ´ng.

Trong cÃ´ng trÃ¬nh nÃ y, chÃºng tÃ´i Ä‘á» xuáº¥t há»c xÃ¡c minh (LEVER 
ğŸŒğŸ¤–) sinh code tá»« ngÃ´n ngá»¯ bá»Ÿi cÃ¡c code LLMs, vá»›i sá»± giÃºp 
Ä‘á»¡ cá»§a thá»±c thi. Cá»¥ thá»ƒ hÆ¡n, chÃºng tÃ´i huáº¥n luyá»‡n má»™t verifier 
há»c cÃ¡ch phÃ¢n biá»‡t vÃ  tá»« chá»‘i cÃ¡c chÆ°Æ¡ng trÃ¬nh khÃ´ng Ä‘Ãºng 
dá»±a trÃªn biá»ƒu diá»…n káº¿t há»£p cá»§a mÃ´ táº£ ngÃ´n ngá»¯ tá»± nhiÃªn, 
dáº¡ng bá» máº·t chÆ°Æ¡ng trÃ¬nh vÃ  káº¿t quáº£ thá»±c thi cá»§a nÃ³. ChÃºng 
tÃ´i tiáº¿p tá»¥c káº¿t há»£p xÃ¡c suáº¥t xÃ¡c minh vá»›i xÃ¡c suáº¥t sinh cá»§a 
LLM vÃ  marginalize trÃªn cÃ¡c chÆ°Æ¡ng trÃ¬nh cÃ³ cÃ¹ng káº¿t quáº£ 
thá»±c thi. ChÃºng tÃ´i sá»­ dá»¥ng xÃ¡c suáº¥t tá»•ng há»£p nÃ y lÃ m Ä‘iá»ƒm 
xáº¿p háº¡ng láº¡i vÃ  xuáº¥t ra cÃ¡c chÆ°Æ¡ng trÃ¬nh thá»±c thi Ä‘á»ƒ cÃ³ káº¿t 
quáº£ cÃ³ xÃ¡c suáº¥t cao nháº¥t.

ChÃºng tÃ´i tiáº¿n hÃ nh cÃ¡c thÃ­ nghiá»‡m má»Ÿ rá»™ng trÃªn bá»‘n benchmark 
ngÃ´n ngá»¯-sang-code khÃ¡c nhau thuá»™c cÃ¡c lÄ©nh vá»±c text-to-SQL 
semantic parsing, table QA, math reasoning vÃ  láº­p trÃ¬nh 
Python cÆ¡ báº£n. Káº¿t quáº£ thÃ­ nghiá»‡m vá»›i ba code LLMs khÃ¡c 
nhau cho tháº¥y LEVER liÃªn tá»¥c cáº£i thiá»‡n Ä‘á»™ chÃ­nh xÃ¡c thá»±c thi 
cá»§a cÃ¡c chÆ°Æ¡ng trÃ¬nh Ä‘Æ°á»£c sinh ra. ÄÃ¡ng chÃº Ã½, LEVER káº¿t 
há»£p vá»›i code-davinci-002 cáº£i thiá»‡n so vá»›i cÃ¡c baseline máº¡nh 
sá»­ dá»¥ng cáº¯t tá»‰a lá»—i thá»±c thi tá»« 4.6% Ä‘áº¿n 10.9%, vÃ  Ä‘áº¡t Ä‘Æ°á»£c 
káº¿t quáº£ state-of-the-art má»›i trÃªn táº¥t cáº£ bá»‘n benchmark, mÃ  
khÃ´ng sá»­ dá»¥ng kiáº¿n trÃºc mÃ´ hÃ¬nh cá»¥ thá»ƒ cho tÃ¡c vá»¥ hoáº·c phÆ°Æ¡ng 
phÃ¡p prompting. CÃ¡c nghiÃªn cá»©u ablation cho tháº¥y káº¿t quáº£ 
thá»±c thi lÃ  then chá»‘t cho viá»‡c xÃ¡c minh vÃ  LEVER cÅ©ng mang 
láº¡i cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ trong cÃ¡c setting Ã­t tÃ i nguyÃªn vÃ  
weakly-supervised.12

2. PhÆ°Æ¡ng phÃ¡p
BÃ¢y giá» chÃºng tÃ´i giá»›i thiá»‡u cÃ´ng thá»©c chi tiáº¿t vÃ  quy trÃ¬nh 
huáº¥n luyá»‡n cá»§a LEVER. CÃ¡c thÃ nh pháº§n chÃ­nh Ä‘Æ°á»£c minh há»a 
trong HÃ¬nh 1.

2.1. Sinh Code tá»« NgÃ´n ngá»¯ vá»›i Code LLMs
Äáº§u vÃ o cho má»™t tÃ¡c vá»¥ ngÃ´n ngá»¯-sang-code thÆ°á»ng bao gá»“m 
mÃ´ táº£ ngÃ´n ngá»¯ tá»± nhiÃªn (NL) vÃ  tÃ¹y chá»n má»™t sá»‘ ngá»¯ cáº£nh 
láº­p trÃ¬nh (vÃ­ dá»¥, kho dá»¯ liá»‡u, assertions, v.v.). ChÃºng ta 
kÃ½ hiá»‡u Ä‘áº§u vÃ o nhÆ° váº­y lÃ  x. Cho x, má»™t mÃ´ hÃ¬nh sinh 
P(y|x) sinh ra má»™t chÆ°Æ¡ng trÃ¬nh y sau Ä‘Ã³ Ä‘Æ°á»£c thá»±c thi thÃ´ng 
qua má»™t executor E(Â·) Ä‘á»ƒ thu Ä‘Æ°á»£c káº¿t quáº£3 E(y). Äá»‘i vá»›i 
há»c few-shot vá»›i LMs lá»›n, viá»‡c sinh cÅ©ng thÆ°á»ng Ä‘Æ°á»£c Ä‘iá»u 
kiá»‡n trÃªn má»™t táº­p cá»‘ Ä‘á»‹nh m exemplars, {(xi, yi)}i<m. Do 
Ä‘Ã³ sinh code tá»« ngÃ´n ngá»¯ few-shot vá»›i code LLMs cÃ³ thá»ƒ Ä‘Æ°á»£c 
cÃ´ng thá»©c hÃ³a nhÆ°:

PLM(y|x) = P(y|prompt(x,{(xi, yi)}i<m)), (1)

trong Ä‘Ã³ prompt(x,{(xi, yi)}i<m) lÃ  má»™t biá»ƒu diá»…n chuá»—i 
cá»§a Ä‘áº§u vÃ o tá»•ng thá»ƒ. TÃ¬m kiáº¿m greedy thÆ°á»ng Ä‘Æ°á»£c sá»­ dá»¥ng 
Ä‘á»ƒ tÃ¬m chÆ°Æ¡ng trÃ¬nh cÃ³ xÃ¡c suáº¥t sinh (gáº§n Ä‘Ãºng) cao nháº¥t, 
tá»©c lÃ , Ë†ygreedy â‰ˆ arg max y PLM(y|x).

2.2. Xáº¿p háº¡ng láº¡i cÃ¡c á»¨ng viÃªn ChÆ°Æ¡ng trÃ¬nh
Quan sÃ¡t then chá»‘t thÃºc Ä‘áº©y phÆ°Æ¡ng phÃ¡p cá»§a chÃºng tÃ´i lÃ  
má»™t táº­p máº«u cÃ³ kÃ­ch thÆ°á»›c há»£p lÃ½ tá»« PLM(y|x) thÆ°á»ng bao 
gá»“m cÃ¡c chÆ°Æ¡ng trÃ¬nh Ä‘Ãºng. Äiá»u nÃ y gá»£i Ã½ ráº±ng xáº¿p háº¡ng láº¡i 
cÃ¡c á»©ng viÃªn chÆ°Æ¡ng trÃ¬nh cÃ³ thá»ƒ mang láº¡i cáº£i thiá»‡n káº¿t quáº£ 
Ä‘Ã¡ng ká»ƒ. Ã tÆ°á»Ÿng cá»§a xáº¿p háº¡ng láº¡i discriminative (Shen et al., 
2004; Collins & Koo, 2005) lÃ  há»c má»™t hÃ m scoring R(x,Ë†y) 
Ä‘o lÆ°á»ng kháº£ nÄƒng Ë†y lÃ  Ä‘áº§u ra tá»‘t nháº¥t cho Ä‘áº§u vÃ o x. Cho 
R(Â·), bá»™ xáº¿p háº¡ng láº¡i xuáº¥t ra chÆ°Æ¡ng trÃ¬nh cÃ³ Ä‘iá»ƒm xáº¿p háº¡ng 
láº¡i cao nháº¥t trong táº­p á»©ng viÃªn S:

Ë†yrerank = arg max Ë†yâˆˆS R(x,Ë†y) (2)

Tiáº¿p theo chÃºng tÃ´i giá»›i thiá»‡u cÃ¡ch chÃºng tÃ´i Ã¡p dá»¥ng má»™t 
verifier Ä‘Æ°á»£c huáº¥n luyá»‡n Ä‘á»ƒ xÃ¡c minh vÃ  xáº¿p háº¡ng láº¡i cÃ¡c 
á»©ng viÃªn chÆ°Æ¡ng trÃ¬nh Ä‘Æ°á»£c láº¥y máº«u tá»« code LLMs sao cho 
Ë†yrerank tá»‘t hÆ¡n Ë†ygreedy.

Láº¥y máº«u ChÆ°Æ¡ng trÃ¬nh tá»« Code LLMs. Cho Ä‘áº§u vÃ o x, thay vÃ¬ 
thá»±c hiá»‡n tÃ¬m kiáº¿m greedy, chÃºng tÃ´i thu Ä‘Æ°á»£c k chÆ°Æ¡ng trÃ¬nh 
tá»« PLM(y|x) vá»›i temperature sampling, tá»©c lÃ , {Ë†yi}k i=1âˆ¼ 
PLM(y|x). VÃ¬ cÃ¹ng chÆ°Æ¡ng trÃ¬nh cÃ³ thá»ƒ Ä‘Æ°á»£c láº¥y máº«u nhiá»u 
hÆ¡n má»™t láº§n, chÃºng tÃ´i thá»±c hiá»‡n deduplication Ä‘á»ƒ táº¡o thÃ nh 
má»™t táº­p n á»©ng viÃªn chÆ°Æ¡ng trÃ¬nh duy nháº¥t S={Ë†yi}n i=1, trong 
Ä‘Ã³ nâ‰¤k. ChÃºng tÃ´i chá»n lÃ m sampling thay vÃ¬ beam search chá»§ 
yáº¿u vÃ¬ hai lÃ½ do: 1) cÃ´ng trÃ¬nh gáº§n Ä‘Ã¢y cho tháº¥y ráº±ng beam 
search cho sinh code thÆ°á»ng dáº«n Ä‘áº¿n hiá»‡u suáº¥t tá»“i tá»‡ hÆ¡n do 
cÃ¡c chÆ°Æ¡ng trÃ¬nh degenerated (Austin et al., 2021; Zhang et al., 
2022); vÃ  2) beam search khÃ´ng cÃ³ sáºµn hoáº·c Ä‘Æ°á»£c triá»ƒn khai 
hiá»‡u quáº£ cho táº¥t cáº£ LLMs mÃ  chÃºng tÃ´i test trÃªn (vÃ­ dá»¥, Codex).

XÃ¡c minh vá»›i Thá»±c thi. ChÃºng tÃ´i sá»­ dá»¥ng má»™t phÃ©p ná»‘i Ä‘Æ¡n 
giáº£n cá»§a mÃ´ táº£ váº¥n Ä‘á» x, chÆ°Æ¡ng trÃ¬nh á»©ng viÃªn Ë†y vÃ  má»™t 
biá»ƒu diá»…n cá»§a káº¿t quáº£ thá»±c thi E(Ë†y) lÃ m Ä‘áº§u vÃ o cho bá»™ 
xáº¿p háº¡ng láº¡i. Láº¥y cáº£m há»©ng tá»« cÃ´ng trÃ¬nh gáº§n Ä‘Ã¢y (Cobbe et al., 
2021; Li et al., 2022b), chÃºng tÃ´i tham sá»‘ hÃ³a bá»™ xáº¿p háº¡ng 
láº¡i discriminative cá»§a chÃºng tÃ´i nhÆ° má»™t mÃ´ hÃ¬nh xÃ¡c minh 
(tá»©c lÃ , phÃ¢n loáº¡i nhá»‹ phÃ¢n) PÎ¸(v|x,Ë†y,E(Ë†y)), trong Ä‘Ã³ 
vâˆˆ {0,1}. Trong thá»±c táº¿, bá»™ xáº¿p háº¡ng láº¡i cÃ³ thá»ƒ Ä‘Æ°á»£c triá»ƒn 
khai sá»­ dá»¥ng báº¥t ká»³ kiáº¿n trÃºc phÃ¢n loáº¡i nhá»‹ phÃ¢n nÃ o. ChÃºng 
tÃ´i bÃ¡o cÃ¡o cÃ¡c thÃ­ nghiá»‡m sá»­ dá»¥ng T5 (Raffel et al., 2020) 
vÃ  RoBERTa (Liu et al., 2019) trong Â§B.2.

Cho má»™t Ä‘áº§u vÃ o x vÃ  má»™t chÆ°Æ¡ng trÃ¬nh á»©ng viÃªn Ë†yâˆˆS, chÃºng 
tÃ´i thu Ä‘Æ°á»£c xÃ¡c suáº¥t xáº¿p háº¡ng láº¡i nhÆ° xÃ¡c suáº¥t káº¿t há»£p cá»§a 
sinh vÃ  vÆ°á»£t qua xÃ¡c minh:

PR(Ë†y, v=1|x) = PLM(Ë†y|x)Â·PÎ¸(v=1|x,Ë†y,E(Ë†y)) (3)

Tá»•ng há»£p Káº¿t quáº£ Thá»±c thi. VÃ¬ cÃ¡c chÆ°Æ¡ng trÃ¬nh cÃ³ cÃ¹ng 
ngá»¯ nghÄ©a cÃ³ thá»ƒ cÃ³ cÃ¡c dáº¡ng bá» máº·t khÃ¡c nhau, chÃºng tÃ´i 
tiáº¿p tá»¥c tá»•ng há»£p xÃ¡c suáº¥t xáº¿p háº¡ng láº¡i cá»§a cÃ¡c chÆ°Æ¡ng trÃ¬nh 
trong S thá»±c thi cÃ¹ng káº¿t quáº£. Báº±ng cÃ¡ch nÃ y, chÃºng tÃ´i ná»›i 
lá»ng sá»± phá»¥ thuá»™c vÃ o dáº¡ng bá» máº·t vÃ  táº­p trung vÃ o káº¿t quáº£ 
thá»±c thi thay tháº¿. HÃ m scoring cuá»‘i cÃ¹ng cho xáº¿p háº¡ng láº¡i 
do Ä‘Ã³ lÃ :

R(x,Ë†y) = PR(E(Ë†y), v=1|x) = âˆ‘ yâˆˆS,E(y)=E(Ë†y) PR(y, v=1|x)

VÃ¬ cÃ³ thá»ƒ cÃ³ nhiá»u chÆ°Æ¡ng trÃ¬nh chia sáº» cÃ¹ng káº¿t quáº£ thá»±c 
thi cÃ³ xÃ¡c suáº¥t cao nháº¥t, chÃºng tÃ´i phÃ¡ vá»¡ tie ngáº«u nhiÃªn 
trong trÆ°á»ng há»£p nÃ y khi xuáº¥t ra cÃ¡c chÆ°Æ¡ng trÃ¬nh.

2.3. Há»c cÃ¡c Verifiers
CÃ¡c pháº§n trÆ°á»›c mÃ´ táº£ cÃ¡ch sá»­ dá»¥ng má»™t verifier táº¡i thá»i 
Ä‘iá»ƒm suy luáº­n. Tiáº¿p theo chÃºng tÃ´i giá»›i thiá»‡u quy trÃ¬nh huáº¥n 
luyá»‡n cá»§a nÃ³.

Táº¡o Dá»¯ liá»‡u Huáº¥n luyá»‡n. Äá»‘i vá»›i cÃ¡c dataset ngÃ´n ngá»¯-sang-code, 
má»—i vÃ­ dá»¥ thÆ°á»ng lÃ  má»™t triplet (x, yâˆ—, zâˆ—), trong Ä‘Ã³ 
zâˆ—=E(yâˆ—) lÃ  káº¿t quáº£ thá»±c thi vÃ ng vÃ  yâˆ— lÃ  chÆ°Æ¡ng trÃ¬nh 
vÃ ng. VÃ¬ viá»‡c chÃº thÃ­ch cÃ¡c chÆ°Æ¡ng trÃ¬nh Ä‘Ã²i há»i chuyÃªn mÃ´n 
lÄ©nh vá»±c, Ä‘á»‘i vá»›i má»™t sá»‘ dataset mÃ  káº¿t quáº£ cuá»‘i cÃ¹ng cÃ³ 
thá»ƒ Ä‘Æ°á»£c thu tháº­p trá»±c tiáº¿p, chá»‰ zâˆ— nhÆ°ng khÃ´ng cÃ³ yâˆ— Ä‘Æ°á»£c 
cung cáº¥p Ä‘á»ƒ há»c (Artzi & Zettlemoyer, 2013; Cheng & Lapata, 
2018; Goldman et al., 2018). Äiá»u nÃ y Ä‘Æ°á»£c biáº¿t Ä‘áº¿n nhÆ° 
setting weakly-supervised. Äá»ƒ thu tháº­p dá»¯ liá»‡u huáº¥n luyá»‡n, 
chÃºng tÃ´i thu Ä‘Æ°á»£c má»™t táº­p n á»©ng viÃªn chÆ°Æ¡ng trÃ¬nh duy nháº¥t 
Ë†S={Ë†yi}n i=1 cho má»—i Ä‘áº§u vÃ o x trong táº­p huáº¥n luyá»‡n, báº±ng 
cÃ¡ch trÆ°á»›c tiÃªn láº¥y máº«u k chÆ°Æ¡ng trÃ¬nh tá»« PLM(Ë†y|x) vÃ  sau 
Ä‘Ã³ loáº¡i bá» táº¥t cáº£ cÃ¡c chÆ°Æ¡ng trÃ¬nh trÃ¹ng láº·p, tÆ°Æ¡ng tá»± nhÆ° 
thá»i Ä‘iá»ƒm suy luáº­n. Sau Ä‘Ã³ cho má»—i á»©ng viÃªn chÆ°Æ¡ng trÃ¬nh 
Ë†yâˆˆS, chÃºng tÃ´i thu Ä‘Æ°á»£c nhÃ£n xÃ¡c minh nhá»‹ phÃ¢n cá»§a nÃ³ báº±ng 
cÃ¡ch so sÃ¡nh káº¿t quáº£ thá»±c thi Ë†z=E(Ë†y) vá»›i káº¿t quáº£ thá»±c thi 
vÃ ng4 zâˆ—, tá»©c lÃ , v= 1(Ë†z=zâˆ—). Äá»‘i vá»›i cÃ¡c dataset chá»©a 
chÆ°Æ¡ng trÃ¬nh vÃ ng yâˆ—, chÃºng tÃ´i thÃªm (x, yâˆ—, zâˆ—, v=1) nhÆ° 
má»™t vÃ­ dá»¥ huáº¥n luyá»‡n xÃ¡c minh bá»• sung, vÃ  chÃºng tÃ´i bá» qua 
bÆ°á»›c nÃ y cho cÃ¡c dataset weakly-supervised. Báº±ng cÃ¡ch nÃ y, 
chÃºng tÃ´i táº¡o ra má»™t táº­p cÃ¡c vÃ­ dá»¥ huáº¥n luyá»‡n xÃ¡c minh 
{(x,Ë†yi,Ë†zi, vi)|Ë†yiâˆˆS} cho má»—i Ä‘áº§u vÃ o x.

Má»¥c tiÃªu Há»c. Cho táº­p cÃ¡c vÃ­ dá»¥ huáº¥n luyá»‡n xÃ¡c minh nÃ y, 
chÃºng tÃ´i cÃ´ng thá»©c hÃ³a loss cho Ä‘áº§u vÃ o x vá»›i hÃ m negative 
log-likelihood, Ä‘Æ°á»£c chuáº©n hÃ³a bá»Ÿi sá»‘ lÆ°á»£ng á»©ng viÃªn chÆ°Æ¡ng 
trÃ¬nh

LÎ¸(x, S) = âˆ’1/|S|Â·âˆ‘ Ë†yiâˆˆS log PÎ¸(vi|x,Ë†yi,Ë†zi) (4)

BÆ°á»›c chuáº©n hÃ³a lÃ  quan trá»ng Ä‘á»ƒ ngÄƒn má»™t vÃ­ dá»¥ cÃ³ sá»‘ lÆ°á»£ng 
lá»›n á»©ng viÃªn chÆ°Æ¡ng trÃ¬nh duy nháº¥t thá»‘ng trá»‹ viá»‡c há»c.

3. Thiáº¿t láº­p ThÃ­ nghiá»‡m
3.1. Datasets
ChÃºng tÃ´i tiáº¿n hÃ nh thÃ­ nghiá»‡m trÃªn bá»‘n dataset ngÃ´n ngá»¯-sang-code 
thuá»™c cÃ¡c lÄ©nh vá»±c semantic parsing, table QA, math reasoning 
vÃ  láº­p trÃ¬nh python cÆ¡ báº£n. CÃ¡c setting chÃ­nh cá»§a bá»‘n dataset 
nÃ y Ä‘Æ°á»£c hiá»ƒn thá»‹ trong Báº£ng 1. CÃ¡c setting chi tiáº¿t hÆ¡n 
cho xÃ¡c minh trong Báº£ng 7 cá»§a Phá»¥ lá»¥c.

â–·Spider (Yu et al., 2018) lÃ  má»™t dataset semantic parsing 
vá» sinh truy váº¥n SQL tá»« cÃ¢u há»i ngÃ´n ngá»¯ tá»± nhiÃªn. Vá»›i 7k 
dá»¯ liá»‡u huáº¥n luyá»‡n song song, nÃ³ cÅ©ng lÃ½ tÆ°á»Ÿng cho finetuning 
generators;

â–·WikiTableQuestions (WikiTQ) (Pasupat & Liang, 2015) lÃ  
má»™t dataset tráº£ lá»i cÃ¢u há»i báº£ng, mÃ  chÃºng tÃ´i cá»‘ gáº¯ng giáº£i 
quyáº¿t báº±ng cÃ¡ch sinh vÃ  thá»±c thi cÃ¡c truy váº¥n SQL trÃªn cÃ¡c 
báº£ng nguá»“n. ChÃºng tÃ´i sá»­ dá»¥ng cÃ¡c báº£ng Ä‘Æ°á»£c tiá»n xá»­ lÃ½ tá»« 
Shi et al. (2020) vÃ  Ã¡p dá»¥ng cÃ¡c truy váº¥n SQL Ä‘Æ°á»£c chÃº thÃ­ch 
cá»§a há» Ä‘á»ƒ thÃªm chÆ°Æ¡ng trÃ¬nh vÃ ng cho dataset ban Ä‘áº§u 
weakly-supervised;

â–·GSM8k (Cobbe et al., 2021) lÃ  má»™t benchmark Ä‘á»ƒ giáº£i cÃ¡c 
bÃ i toÃ¡n tá»« toÃ¡n há»c cáº¥p Ä‘á»™ tiá»ƒu há»c. Theo cÃ´ng trÃ¬nh trÆ°á»›c 
Ä‘Ã¢y (Chowdhery et al., 2022; Chen et al., 2022b; Gao et al., 
2022), chÃºng tÃ´i tiáº¿p cáº­n benchmark nÃ y báº±ng cÃ¡ch sinh cÃ¡c 
chÆ°Æ¡ng trÃ¬nh Python tá»« cÃ¢u há»i trong NL, vá»‘n sáº½ táº¡o ra cÃ¢u 
tráº£ lá»i Ä‘Ãºng khi thá»±c thi. Dataset gá»‘c chá»‰ cÃ³ ngÃ´n ngá»¯ tá»± 
nhiÃªn vÃ  khÃ´ng cÃ³ giáº£i phÃ¡p chÆ°Æ¡ng trÃ¬nh, do Ä‘Ã³ nÃ³ 
weakly-supervised cho ngÃ´n ngá»¯-sang-code;

â–·MBPP (Austin et al., 2021) chá»©a cÃ¡c chÆ°Æ¡ng trÃ¬nh láº­p trÃ¬nh 
Python cÆ¡ báº£n Ä‘Æ°á»£c phÃ¡t biá»ƒu báº±ng ngÃ´n ngá»¯ tá»± nhiÃªn. Má»—i 
vÃ­ dá»¥ Ä‘Æ°á»£c trang bá»‹ 3 test cases Ä‘á»ƒ kiá»ƒm tra tÃ­nh Ä‘Ãºng Ä‘áº¯n 
cá»§a cÃ¡c chÆ°Æ¡ng trÃ¬nh. Theo cÃ´ng trÃ¬nh trÆ°á»›c Ä‘Ã¢y (Shi et al., 
2022; Zhang et al., 2022), chÃºng tÃ´i sá»­ dá»¥ng test case Ä‘áº§u 
tiÃªn nhÆ° má»™t pháº§n cá»§a prompt cho mÃ´ hÃ¬nh Ä‘á»ƒ sinh chá»¯ kÃ½ 
hÃ m Ä‘Ãºng vÃ  sá»­ dá»¥ng cáº£ ba Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ tÃ­nh Ä‘Ãºng Ä‘áº¯n.

3.2. Code LLMs
ChÃºng tÃ´i Ä‘Ã¡nh giÃ¡ LEVER vá»›i ba code LLMs khÃ¡c nhau:

â–·Codex (Chen et al., 2021a) lÃ  má»™t há» code LLMs cÃ³ cÃ¡c 
kÃ­ch thÆ°á»›c khÃ¡c nhau Ä‘Æ°á»£c phÃ¡t triá»ƒn bá»Ÿi OpenAI. Cá»¥ thá»ƒ, 
chÃºng tÃ´i sá»­ dá»¥ng API code-davinci-0025 thÃ´ng qua Python 
bindings chÃ­nh thá»©c cá»§a nÃ³.

â–·InCoder (Fried et al., 2022) lÃ  má»™t há» code LLMs lÃªn Ä‘áº¿n 
6B tham sá»‘ Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn má»™t corpus lá»›n code vá»›i 
giáº¥y phÃ©p permissive. ChÃºng tÃ´i thÃ­ nghiá»‡m vá»›i InCoder-6B 
vÃ  sá»­ dá»¥ng nÃ³ cho sinh tá»« trÃ¡i sang pháº£i.

â–·CodeGen (Nijkamp et al., 2022) lÃ  má»™t há» code LLMs vÃ  
chÃºng tÃ´i Ä‘Ã¡nh giÃ¡ phiÃªn báº£n CodeGen-16B-multi. Máº·c dÃ¹ 
cÃ¡c tá»‡p SQL khÃ´ng Ä‘Æ°á»£c bao gá»“m trong corpus huáº¥n luyá»‡n 
cho CodeGen, chÃºng tÃ´i tháº¥y nÃ³ váº«n hoáº¡t Ä‘á»™ng khÃ¡ tá»‘t trÃªn 
cÃ¡c tÃ¡c vá»¥ sinh SQL cÃ³ thá»ƒ vÃ¬ cÃ¡c truy váº¥n SQL Ä‘Æ°á»£c trá»™n 
láº«n vá»›i cÃ¡c tá»‡p nguá»“n cá»§a cÃ¡c ngÃ´n ngá»¯ láº­p trÃ¬nh khÃ¡c.

3.3. Baselines vÃ  Metric ÄÃ¡nh giÃ¡
Baselines. ChÃºng tÃ´i so sÃ¡nh LEVER vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p 
baseline sau Ä‘Ã¢y Ä‘á»ƒ sinh chÆ°Æ¡ng trÃ¬nh sá»­ dá»¥ng code LLMs.

â–·Greedy: Chá»n token cÃ³ kháº£ nÄƒng cao nháº¥t má»—i bÆ°á»›c giáº£i mÃ£.

â–·Maximum Likelihood (ML): Tá»« k á»©ng viÃªn chÆ°Æ¡ng trÃ¬nh Ä‘Æ°á»£c 
láº¥y máº«u, chá»n chÆ°Æ¡ng trÃ¬nh cÃ³ log-probability sinh cao nháº¥t, 
tá»©c lÃ , log PLM(Ë†y|x) (hoáº·c log-probability sinh chuáº©n hÃ³a 
nhÆ° log PLM(Ë†y|x)/|Ë†y|). ChÃºng tÃ´i xÃ¡c Ä‘á»‹nh thá»±c nghiá»‡m 
sá»­ dá»¥ng táº­p phÃ¡t triá»ƒn cÃ³ nÃªn sá»­ dá»¥ng xÃ¡c suáº¥t chuáº©n hÃ³a 
cho má»—i dataset. Chi tiáº¿t hÆ¡n cÃ³ thá»ƒ Ä‘Æ°á»£c tÃ¬m tháº¥y trong 
Phá»¥ lá»¥c A.

â–·Error Pruning + ML (EP + ML): Cáº¯t tá»‰a cÃ¡c á»©ng viÃªn chÆ°Æ¡ng 
trÃ¬nh cÃ³ lá»—i thá»±c thi; sau Ä‘Ã³ chá»n chÆ°Æ¡ng trÃ¬nh cÃ³ maximum 
likelihood;

â–·Error Pruning + Voting (EP + Voting): Bá» phiáº¿u Ä‘a sá»‘ trÃªn 
káº¿t quáº£ thá»±c thi trong cÃ¡c chÆ°Æ¡ng trÃ¬nh khÃ´ng lá»—i, vÃ  chá»n 
káº¿t quáº£ thá»±c thi Ä‘Æ°á»£c bá» phiáº¿u nhiá»u nháº¥t vÃ  cÃ¡c chÆ°Æ¡ng 
trÃ¬nh tÆ°Æ¡ng á»©ng cá»§a nÃ³.

ChÃºng tÃ´i táº­p trung so sÃ¡nh vá»›i baseline EP+ML, vÃ¬ Ä‘Ã¢y lÃ  
má»™t phÆ°Æ¡ng phÃ¡p xáº¿p háº¡ng láº¡i Ä‘Æ¡n giáº£n khai thÃ¡c thá»±c thi 
vÃ  mang láº¡i káº¿t quáº£ cáº¡nh tranh nháº¥t quÃ¡n trÃªn cÃ¡c dataset 
vÃ  code LLMs khÃ¡c nhau.

Metric Ä‘Ã¡nh giÃ¡. Theo cÃ´ng trÃ¬nh trÆ°á»›c Ä‘Ã¢y (Xie et al., 2022; 
Liu et al., 2021; Ni et al., 2022; Zhang et al., 2022), chÃºng 
tÃ´i sá»­ dá»¥ng Ä‘á»™ chÃ­nh xÃ¡c thá»±c thi lÃ m metric Ä‘Ã¡nh giÃ¡ chÃ­nh 
cho táº¥t cáº£ datasets, Ä‘o lÆ°á»ng tá»· lá»‡ pháº§n trÄƒm cÃ¡c vÃ­ dá»¥ 
mang láº¡i káº¿t quáº£ thá»±c thi vÃ ng hoáº·c vÆ°á»£t qua táº¥t cáº£ test cases.

3.4. Chi tiáº¿t Triá»ƒn khai
Huáº¥n luyá»‡n verifier. ChÃºng tÃ´i táº¡o dá»¯ liá»‡u huáº¥n luyá»‡n xÃ¡c 
minh báº±ng cÃ¡ch láº¥y máº«u tá»« LLMs trÃªn táº­p huáº¥n luyá»‡n, sá»­ 
dá»¥ng ngÃ¢n sÃ¡ch láº¥y máº«u Ä‘Æ°á»£c mÃ´ táº£ trong Báº£ng 1. Thá»‘ng kÃª 
thÃªm cá»§a dá»¯ liá»‡u huáº¥n luyá»‡n káº¿t quáº£ cÃ³ thá»ƒ Ä‘Æ°á»£c tÃ¬m tháº¥y 
trong Báº£ng 7 trong Phá»¥ lá»¥c. Khi há»c cÃ¡c verifiers, nhÆ° Ä‘Æ°á»£c 
hiá»ƒn thá»‹ trong Eq. 4, loss huáº¥n luyá»‡n Ä‘Æ°á»£c tÃ­nh báº±ng cÃ¡ch 
láº¥y trung bÃ¬nh trÃªn táº¥t cáº£ cÃ¡c máº«u chÆ°Æ¡ng trÃ¬nh cho má»—i vÃ­ 
dá»¥. VÃ¬ chÃºng tÃ´i batch cÃ¡c máº«u chÆ°Æ¡ng trÃ¬nh cho cÃ¹ng vÃ­ dá»¥ 
láº¡i vá»›i nhau, kÃ­ch thÆ°á»›c batch hiá»‡u quáº£ cÅ©ng sáº½ Ä‘Æ°á»£c nhÃ¢n 
vá»›i kÃ­ch thÆ°á»›c máº«u. Äiá»u nÃ y cÃ³ thá»ƒ gÃ¢y váº¥n Ä‘á» khi kÃ­ch 
thÆ°á»›c máº«u trá»Ÿ nÃªn lá»›n (lÃªn Ä‘áº¿n 100 trong thÃ­ nghiá»‡m cá»§a 
chÃºng tÃ´i) vÃ¬ chÃºng cÃ³ thá»ƒ khÃ´ng thá»ƒ vá»«a vÃ o bá»™ nhá»› GPU 
cÃ¹ng lÃºc. Do Ä‘Ã³, chÃºng tÃ´i down-sample cÃ¡c chÆ°Æ¡ng trÃ¬nh 
Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ há»c má»—i vÃ­ dá»¥ trong má»—i iteration. Viá»‡c 
down-sampling ngáº«u nhiÃªn xáº£y ra á»Ÿ Ä‘áº§u má»—i epoch huáº¥n 
luyá»‡n Ä‘á»ƒ cÃ¡c verifiers cÃ³ thá»ƒ tháº¥y cÃ¡c chÆ°Æ¡ng trÃ¬nh khÃ¡c 
nhau má»—i epoch. KÃ­ch thÆ°á»›c batch chi tiáº¿t vÃ  há»‡ sá»‘ 
downsampling cÃ³ thá»ƒ Ä‘Æ°á»£c tÃ¬m tháº¥y trong Báº£ng 7 trong Phá»¥ lá»¥c.

Biá»ƒu diá»…n káº¿t quáº£ thá»±c thi. Äáº§u vÃ o cho verifier lÃ  má»™t 
phÃ©p ná»‘i cá»§a Ä‘áº§u vÃ o tÃ¡c vá»¥, á»©ng viÃªn chÆ°Æ¡ng trÃ¬nh vÃ  káº¿t 
quáº£ thá»±c thi cá»§a nÃ³. Äá»‘i vá»›i Spider vÃ  WikiTQ, chÃºng tÃ´i 
sá»­ dá»¥ng cÃ¡c báº£ng káº¿t quáº£ Ä‘Æ°á»£c tuyáº¿n tÃ­nh hÃ³a tá»« thá»±c thi 
SQL lÃ m káº¿t quáº£ thá»±c thi. Äá»‘i vá»›i GSM8k, chÃºng tÃ´i sá»­ 
dá»¥ng giÃ¡ trá»‹ cá»§a biáº¿n cÃ³ tÃªn "answer" sau khi thá»±c thi chÆ°Æ¡ng 
trÃ¬nh lÃ m káº¿t quáº£ thá»±c thi. Äá»‘i vá»›i MBPP, chÃºng tÃ´i sá»­ 
dá»¥ng kiá»ƒu vÃ  giÃ¡ trá»‹ (Ä‘Æ°á»£c cast thÃ nh chuá»—i) Ä‘Æ°á»£c tráº£ vá» 
bá»Ÿi cÃ¡c hÃ m. Táº¥t cáº£ lá»—i thá»±c thi Ä‘Æ°á»£c biá»ƒu diá»…n nhÆ° "ERROR: 
[reason]", cháº³ng háº¡n nhÆ° "ERROR: Time out". VÃ­ dá»¥ vá» 
nhá»¯ng Ä‘áº§u vÃ o verifier nÃ y cho cÃ¡c dataset khÃ¡c nhau cÃ³ 
thá»ƒ Ä‘Æ°á»£c tÃ¬m tháº¥y trong Báº£ng 11.

Lá»±a chá»n mÃ´ hÃ¬nh verifier. ChÃºng tÃ´i sá»­ dá»¥ng táº­p phÃ¡t triá»ƒn 
Ä‘á»ƒ chá»n mÃ´ hÃ¬nh verifier tá»‘t nháº¥t. ChÃºng tÃ´i chá»n T5-base 
cho Spider, T5-large cho WikiTQ vÃ  MBPP, vÃ  RoBERTa-large 
cho GSM8k lÃ m LM cÆ¡ sá»Ÿ cho cÃ¡c verifiers sá»­ dá»¥ng trong 
cÃ¡c thÃ­ nghiá»‡m chÃ­nh6. Quy trÃ¬nh lá»±a chá»n Ä‘Æ°á»£c chi tiáº¿t 
trong Â§B.2. Äá»‘i vá»›i cÃ¡c mÃ´ hÃ¬nh T5 (Raffel et al., 2020), 
chÃºng tÃ´i huáº¥n luyá»‡n chÃºng Ä‘á»ƒ xuáº¥t ra token "yes/no" cho 
má»—i vÃ­ dá»¥ tÃ­ch cá»±c/tiÃªu cá»±c Ä‘Æ°á»£c cho Ä‘áº§u vÃ o verifier, vÃ  
chÃºng tÃ´i láº¥y xÃ¡c suáº¥t sinh "yes" lÃ m xÃ¡c suáº¥t xÃ¡c minh 
trong suy luáº­n. Äá»‘i vá»›i RoBERTa (Liu et al., 2019), chÃºng 
tÃ´i thÃªm má»™t lá»›p tuyáº¿n tÃ­nh trÃªn Ä‘á»‰nh head [CLS], theo thá»±c 
hÃ nh tiÃªu chuáº©n cá»§a phÃ¢n loáº¡i chuá»—i vá»›i cÃ¡c mÃ´ hÃ¬nh chá»‰-encoder 
(Devlin et al., 2019).

Chi tiáº¿t vá» láº¥y máº«u LLM, xÃ¢y dá»±ng prompt few-shot vÃ  thiáº¿t 
láº­p cá»¥ thá»ƒ cho dataset cÃ³ thá»ƒ Ä‘Æ°á»£c tÃ¬m tháº¥y trong Phá»¥ lá»¥c A.

4. Káº¿t quáº£ ChÃ­nh
ChÃºng tÃ´i hiá»ƒn thá»‹ hiá»‡u suáº¥t cá»§a LEVER káº¿t há»£p vá»›i Codex-Davinci 
vÃ  so sÃ¡nh nÃ³ vá»›i hiá»‡u suáº¥t finetuning vÃ  few-shot state-of-the-art 
tá»« cÃ´ng trÃ¬nh trÆ°á»›c Ä‘Ã¢y cho Spider (Báº£ng 2), WikiTQ (Báº£ng 3), 
GSM8k (Báº£ng 4) vÃ  MBPP (Báº£ng 5). NgoÃ i ra, chÃºng tÃ´i cÅ©ng 
Ä‘Ã¡nh giÃ¡ LEVER vá»›i cÃ¡c mÃ´ hÃ¬nh InCoder vÃ  CodeGen trÃªn Spider 
vÃ  GSM8k (Báº£ng 6).

4.1. Hiá»‡u quáº£ cá»§a LEVER.
LEVER liÃªn tá»¥c cáº£i thiá»‡n hiá»‡u suáº¥t cá»§a táº¥t cáº£ code LLMs 
trÃªn táº¥t cáº£ tÃ¡c vá»¥, mang láº¡i cáº£i thiá»‡n tá»« 6.6% (Spider) Ä‘áº¿n 
17.3% (WikiTQ) so vá»›i cÃ¡c baseline giáº£i mÃ£ greedy cho 
Codex-Davinci. Äá»‘i vá»›i cÃ¡c mÃ´ hÃ¬nh yáº¿u hÆ¡n nhÆ° InCoder 
vÃ  CodeGen, chÃºng tÃ´i quan sÃ¡t cáº£i thiá»‡n lÃªn Ä‘áº¿n 30.0% cho 
Spider vÃ  15.0% cho GSM8k. HÆ¡n ná»¯a, LEVER káº¿t há»£p vá»›i 
Codex-Davinci cÅ©ng Ä‘áº¡t Ä‘Æ°á»£c káº¿t quáº£ state-of-the-art má»›i 
trÃªn táº¥t cáº£ bá»‘n datasets, vá»›i cáº£i thiá»‡n tá»« 1.2% (WikiTQ) 
Ä‘áº¿n 2.0% (MBPP). TrÃªn dataset text-to-SQL thÃ¡ch thá»©c, 
Spider, nÆ¡i state-of-the-art trÆ°á»›c Ä‘Ã¢y Ä‘Æ°á»£c Ä‘áº¡t Ä‘Æ°á»£c báº±ng 
cÃ¡ch finetuning má»™t mÃ´ hÃ¬nh T5-3B Ä‘Æ°á»£c tÄƒng cÆ°á»ng vá»›i 
relational-aware self-attention, chÃºng tÃ´i Ä‘áº¡t Ä‘Æ°á»£c káº¿t quáº£ 
tá»‘t hÆ¡n vá»›i Codex-Davinci + LEVER, nÆ¡i verifier Ä‘Æ°á»£c finetuned 
sá»­ dá»¥ng mÃ´ hÃ¬nh T5-base. LEVER cÅ©ng cáº£i thiá»‡n káº¿t quáº£ 
tá»‘t nháº¥t trÆ°á»›c Ä‘Ã¢y trÃªn Spider sá»­ dá»¥ng InCoder vÃ  CodeGen, 
láº§n lÆ°á»£t 13.2% vÃ  20.6%.

5. PhÃ¢n tÃ­ch
5.1. Má»Ÿ rá»™ng VÃ­ dá»¥ Huáº¥n luyá»‡n
ChÃºng tÃ´i hiá»ƒn thá»‹ cÃ¡ch hiá»‡u suáº¥t cá»§a LEVER thay Ä‘á»•i vá»›i 
Ã­t vÃ­ dá»¥ huáº¥n luyá»‡n hÆ¡n trong HÃ¬nh 3, sá»­ dá»¥ng Spider lÃ m 
vÃ­ dá»¥. Káº¿t quáº£ thÃªm trÃªn WikiTQ vÃ  GSM8k trong Â§B.3. 
CÃ¡c cáº£i thiá»‡n vá»›i LEVER so vá»›i LLMs cÆ¡ sá»Ÿ váº«n nháº¥t quÃ¡n 
ngay cáº£ khi chá»‰ cÃ³ 250 vÃ­ dá»¥ Ä‘Æ°á»£c Ä‘Æ°a ra, vá»›i cáº£i thiá»‡n tá»« 
1.7% Ä‘áº¿n 10.0% trÃªn cÃ¡c datasets vÃ  LLMs khÃ¡c nhau. Äiá»u 
nÃ y cho tháº¥y LEVER cÃ³ thá»ƒ hoáº¡t Ä‘á»™ng trong cÃ¡c setting Ã­t 
tÃ i nguyÃªn. HÆ¡n ná»¯a, xu hÆ°á»›ng cÅ©ng khÃ¡c nhau cho cÃ¡c 
datasets vÃ  code LLMs khÃ¡c nhau, vÃ­ dá»¥, khi sá»­ dá»¥ng Codex 
lÃ m LLM, hiá»‡u suáº¥t cá»§a LEVER giáº£m 6.4% cho WikiTQ vÃ  
chá»‰ 3.2% cho Spider. Tuy nhiÃªn, cÅ©ng trÃªn Spider, hiá»‡u 
suáº¥t giáº£m 6.9% vÃ  5.3% cho InCoder vÃ  CodeGen. Äiá»u nÃ y 
cho tháº¥y cÃ³ nhiá»u vÃ­ dá»¥ huáº¥n luyá»‡n hÆ¡n cho LEVER cÃ³ tÃ¡c 
Ä‘á»™ng lá»›n hÆ¡n Ä‘á»‘i vá»›i cÃ¡c datasets khÃ³ hÆ¡n vÃ  LMs yáº¿u hÆ¡n.

Vá»›i HÃ¬nh 3, chÃºng tÃ´i cÅ©ng so sÃ¡nh hiá»‡u suáº¥t cá»§a LEVER 
vá»›i cÃ¡c mÃ´ hÃ¬nh T5 Ä‘Æ°á»£c finetuned trá»±c tiáº¿p Ä‘á»ƒ sinh cho 
cÃ¹ng sá»‘ lÆ°á»£ng vÃ­ dá»¥ huáº¥n luyá»‡n. Trong khi xÃ¡c minh cÃ³ thá»ƒ 
Ä‘Æ°á»£c há»c vá»›i chá»‰ hÃ ng trÄƒm vÃ­ dá»¥, hiá»‡u suáº¥t cá»§a cÃ¡c mÃ´ 
hÃ¬nh T5 finetuned giáº£m máº¡nh khi cÃ³ Ã­t vÃ­ dá»¥ huáº¥n luyá»‡n 
hÆ¡n. NhÆ° má»™t vÃ­ dá»¥, cho 500 vÃ­ dá»¥, má»™t verifier T5-base 
trÃªn InCoder/CodeGen vÆ°á»£t trá»™i hÆ¡n generator T5-3B finetuned 
khoáº£ng 7%.

5.2. Má»Ÿ rá»™ng KÃ­ch thÆ°á»›c Máº«u
VÃ¬ viá»‡c rÃºt máº«u tá»« LLMs cÃ³ thá»ƒ tá»‘n kÃ©m vá» máº·t tÃ­nh toÃ¡n, 
á»Ÿ Ä‘Ã¢y chÃºng tÃ´i nghiÃªn cá»©u cÃ¡ch kÃ­ch thÆ°á»›c máº«u trong thá»i 
gian huáº¥n luyá»‡n vÃ  suy luáº­n áº£nh hÆ°á»Ÿng Ä‘áº¿n hiá»‡u suáº¥t. NhÆ° 
chÃºng ta cÃ³ thá»ƒ tháº¥y tá»« HÃ¬nh 4a, trong thá»i gian suy luáº­n, 
khi giáº£m kÃ­ch thÆ°á»›c máº«u tá»« 50 xuá»‘ng 10 chÆ°Æ¡ng trÃ¬nh má»—i 
vÃ­ dá»¥, hiá»‡u suáº¥t cá»§a LEVER giáº£m 1.8% (Spider) Ä‘áº¿n 5.2% 
(WikiTQ). Äiá»u nÃ y chá»‰ ra ráº±ng LEVER nháº¡y cáº£m vá»›i kÃ­ch 
thÆ°á»›c máº«u táº¡i thá»i Ä‘iá»ƒm suy luáº­n, Ä‘iá»u nÃ y Ä‘Æ°á»£c mong Ä‘á»£i 
vÃ¬ nÃ³ cÅ©ng áº£nh hÆ°á»Ÿng máº¡nh Ä‘áº¿n káº¿t quáº£ oracle (tá»©c lÃ , 
upper-bound cho xáº¿p háº¡ng láº¡i). Äá»ƒ so sÃ¡nh, HÃ¬nh 4b cho 
tháº¥y LEVER ráº¥t khÃ´ng nháº¡y cáº£m vá»›i kÃ­ch thÆ°á»›c máº«u Ä‘á»ƒ 
cung cáº¥p dá»¯ liá»‡u huáº¥n luyá»‡n, vá»›i khoáº£ng cÃ¡ch hiá»‡u suáº¥t 
Ä‘á»u dÆ°á»›i 1% cho ba datasets. Tá»•ng thá»ƒ, káº¿t quáº£ cho tháº¥y 
ngÃ¢n sÃ¡ch láº¥y máº«u cao hÆ¡n giÃºp Ã­ch hÆ¡n táº¡i thá»i Ä‘iá»ƒm test.

5.3. Hiá»‡u chuáº©n Verifier vÃ  Generator
ChÃºng tÃ´i nghiÃªn cá»©u má»©c Ä‘á»™ hiá»‡u chuáº©n tá»‘t cá»§a verifier 
vÃ  generator trong viá»‡c nháº­n diá»‡n cÃ¡c chÆ°Æ¡ng trÃ¬nh Ä‘Ãºng. 
LÃ½ tÆ°á»Ÿng, cÃ¡c máº«u chÆ°Æ¡ng trÃ¬nh Ä‘Ãºng sáº½ Ä‘Æ°á»£c Ä‘Æ°a ra xÃ¡c 
suáº¥t cao hÆ¡n do Ä‘Ã³ chÃºng ta sáº½ quan sÃ¡t tá»· lá»‡ pháº§n trÄƒm 
cao hÆ¡n cÃ¡c chÆ°Æ¡ng trÃ¬nh Ä‘Ãºng khi nÃ³ gáº§n vá»›i Ä‘á»‰nh. Äá»ƒ 
lÃ m Ä‘iá»u nÃ y, chÃºng tÃ´i sáº¯p xáº¿p Ä‘iá»ƒm dá»± Ä‘oÃ¡n cá»§a verifier, 
generator vÃ  LEVER (nhÆ° trong Eq. 3), vÃ  di chuyá»ƒn ngÆ°á»¡ng 
percentile vÃ  Ä‘o lÆ°á»ng tá»· lá»‡ pháº§n trÄƒm chÆ°Æ¡ng trÃ¬nh Ä‘Ãºng 
trong cÃ¡c chÆ°Æ¡ng trÃ¬nh Ä‘Æ°á»£c xáº¿p háº¡ng cao. Theo HÃ¬nh 5, 
cÃ¡c verifiers nÃ³i chung Ä‘Æ°á»£c hiá»‡u chuáº©n tá»‘t hÆ¡n so vá»›i 
generators, Ä‘áº·c biá»‡t khi ngÆ°á»¡ng á»Ÿ percentiles tháº¥p hÆ¡n. 
Äiá»u nÃ y chá»‰ ra ráº±ng dá»… dÃ ng hÆ¡n cho cÃ¡c verifiers nháº­n 
diá»‡n nhá»¯ng lá»—i rÃµ rÃ ng trong cÃ¡c chÆ°Æ¡ng trÃ¬nh vá»›i káº¿t quáº£ 
thá»±c thi nhÆ° má»™t pháº§n Ä‘áº§u vÃ o cá»§a chÃºng. ThÃº vá»‹, khi phÃ¢n 
biá»‡t giá»¯a cÃ¡c chÆ°Æ¡ng trÃ¬nh Ä‘Æ°á»£c xáº¿p háº¡ng cao, cÃ¡c verifiers 
Ä‘Æ°á»£c hiá»‡u chuáº©n kÃ©m trong ba trong sá»‘ bá»‘n datasets Ä‘Æ°á»£c 
test7. Tuy nhiÃªn, cÃ¡c generators nÃ³i chung Ä‘Æ°á»£c hiá»‡u chuáº©n 
tá»‘t hÆ¡n trong vÃ¹ng nÃ y, vÃ  káº¿t há»£p xÃ¡c suáº¥t cá»§a verifier 
vÃ  generator mang láº¡i káº¿t quáº£ tá»‘t nháº¥t trÃªn táº¥t cáº£ bá»‘n 
benchmarks. Cá»¥ thá»ƒ hÆ¡n, trÃªn dataset GSM8k, nÆ¡i hiá»‡u 
chuáº©n cá»§a cáº£ hai mÃ´ hÃ¬nh khÃ¡ kÃ©m cho cÃ¡c chÆ°Æ¡ng trÃ¬nh 
Ä‘Æ°á»£c xáº¿p háº¡ng cao, xÃ¡c suáº¥t káº¿t há»£p cá»§a chÃºng báº¥t ngá» 
Ä‘Æ°á»£c hiá»‡u chuáº©n tá»‘t, cho tháº¥y hai mÃ´ hÃ¬nh bá»• sung cho 
nhau trÃªn dataset nÃ y.

5.4. PhÃ¢n tÃ­ch Äá»‹nh lÆ°á»£ng
ChÃºng tÃ´i trÃ¬nh bÃ y má»™t phÃ¢n tÃ­ch Ä‘á»‹nh lÆ°á»£ng vá» lÃ½ do LEVER 
thÃ nh cÃ´ng hoáº·c tháº¥t báº¡i trong viá»‡c cáº£i thiá»‡n hiá»‡u suáº¥t cá»§a 
LLMs. Theo HÃ¬nh 6, khi LEVER xáº¿p háº¡ng láº¡i má»™t chÆ°Æ¡ng 
trÃ¬nh Ä‘á»ƒ thay tháº¿ chÆ°Æ¡ng trÃ¬nh khÃ¡c cÃ³ xÃ¡c suáº¥t sinh cao 
hÆ¡n, thÆ°á»ng lÃ  vÃ¬ káº¿t quáº£ thá»±c thi cung cáº¥p thÃ´ng tin quan 
trá»ng nhÆ° lá»—i thá»±c thi, kiá»ƒu biáº¿n vÃ  pháº¡m vi. Äiá»u nÃ y 
nháº¥t quÃ¡n vá»›i phÃ¡t hiá»‡n cá»§a chÃºng tÃ´i trong Â§4.2 vá» táº§m 
quan trá»ng cá»§a káº¿t quáº£ thá»±c thi Ä‘á»‘i vá»›i LEVER. CÅ©ng Ä‘Ã¡ng 
chÃº Ã½ ráº±ng cÃ³ nhá»¯ng trÆ°á»ng há»£p khi LEVER váº«n cÃ³ thá»ƒ xáº¿p 
háº¡ng láº¡i chÆ°Æ¡ng trÃ¬nh Ä‘Ãºng khi káº¿t quáº£ thá»±c thi khÃ´ng lá»—i 
cÃ³ cÃ¹ng kiá»ƒu vÃ  pháº¡m vi vá»›i chÆ°Æ¡ng trÃ¬nh greedy, tá»©c lÃ , 
trong danh má»¥c "others". Giáº£ thuyáº¿t cá»§a chÃºng tÃ´i lÃ  Ä‘Ã¢y 
lÃ  khi chÃ­nh chÆ°Æ¡ng trÃ¬nh trá»Ÿ thÃ nh Ä‘áº·c trÆ°ng chÃ­nh cho 
cÃ¡c verifiers khai thÃ¡c. NgoÃ i ra, khi LEVER tháº¥t báº¡i trong 
viá»‡c xáº¿p háº¡ng cÃ¡c chÆ°Æ¡ng trÃ¬nh Ä‘Ãºng lÃªn Ä‘á»‰nh, lÃ½ do phá»• 
biáº¿n nháº¥t lÃ  khÃ´ng tÃ¬m tháº¥y chÆ°Æ¡ng trÃ¬nh Ä‘Ãºng trong cÃ¡c 
máº«u (tá»©c lÃ , upper-bound Ä‘Æ°á»£c Ä‘áº¡t tá»›i), Ä‘iá»u nÃ y Ä‘áº·c biá»‡t 
lÃ  trÆ°á»ng há»£p cho cÃ¡c LMs yáº¿u hÆ¡n. LÃ½ do phá»• biáº¿n thá»© 
hai cho LEVER tháº¥t báº¡i lÃ  káº¿t quáº£ thá»±c thi cá»§a chÆ°Æ¡ng 
trÃ¬nh khÃ´ng Ä‘Ãºng khi xáº¿p háº¡ng láº¡i cÃ³ cÃ¹ng kiá»ƒu vÃ  pháº¡m 
vi nhÆ° chÆ°Æ¡ng trÃ¬nh Ä‘Ãºng trong cÃ¡c máº«u. Trong trÆ°á»ng há»£p 
nÃ y, káº¿t quáº£ thá»±c thi khÃ´ng cung cáº¥p thÃ´ng tin phong phÃº 
cho cÃ¡c verifiers do Ä‘Ã³ LEVER tháº¥t báº¡i trong viá»‡c cáº£i thiá»‡n 
code LLMs.

6. CÃ´ng trÃ¬nh LiÃªn quan
Sinh Code tá»« NgÃ´n ngá»¯. Viá»‡c dá»‹ch ngÃ´n ngá»¯ tá»± nhiÃªn sang 
code lÃ  má»™t thÃ¡ch thá»©c lÃ¢u Ä‘á»i qua táº¥t cáº£ thá»i Ä‘áº¡i cá»§a 
trÃ­ tuá»‡ nhÃ¢n táº¡o, bao gá»“m cÃ¡c há»‡ thá»‘ng dá»±a trÃªn quy táº¯c 
(Woods, 1973; Templeton & Burger, 1983), dá»± Ä‘oÃ¡n cÃ³ cáº¥u 
trÃºc (Zelle & Mooney, 1996; Zettlemoyer & Collins, 2005; 
Gulwani & Marron, 2014) vÃ  deep learning (Xiao et al., 
2016; Dong & Lapata, 2016; Rabinovich et al., 2017; Zhong 
et al., 2017; Lin et al., 2017). Gáº§n Ä‘Ã¢y, cÃ¡c mÃ´ hÃ¬nh ngÃ´n 
ngá»¯ code Ä‘Æ°á»£c pre-train (Chen et al., 2021a; Wang et al., 
2021; Fried et al., 2022; Nijkamp et al., 2022; OpenAI, 
2022) Ä‘Ã£ chá»©ng minh hiá»‡u suáº¥t máº¡nh máº½ Ä‘Ã¡ng ngáº¡c nhiÃªn 
trong váº¥n Ä‘á» nÃ y trÃªn cÃ¡c ngÃ´n ngá»¯ láº­p trÃ¬nh (Lin et al., 
2018; Yu et al., 2018; Austin et al., 2021; Cobbe et al., 
2021; Li et al., 2022a). Má»™t sá»‘ phÆ°Æ¡ng phÃ¡p Ä‘Æ°á»£c Ä‘á» xuáº¥t 
Ä‘á»ƒ tinh chá»‰nh lá»±a chá»n máº«u LLM, bao gá»“m thá»±c thi test 
case (Li et al., 2022a), tÆ°Æ¡ng tá»± cross-sample (Chen et al., 
2021a; Li et al., 2022a; Shi et al., 2022) vÃ  lá»c dá»±a trÃªn 
maximum mutual information (Zhang et al., 2022). CÃ´ng 
trÃ¬nh cá»§a chÃºng tÃ´i Ä‘á» xuáº¥t má»™t module xÃ¡c minh cÃ³ thá»ƒ 
há»c Ä‘Æ°á»£c Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ Ä‘áº§u ra máº«u cá»§a LLMs Ä‘á»ƒ cáº£i thiá»‡n 
thÃªm hiá»‡u suáº¥t cá»§a chÃºng.

Sinh Code vá»›i Thá»±c thi. CÃ´ng trÃ¬nh sinh code trÆ°á»›c Ä‘Ã¢y 
Ä‘Ã£ khai thÃ¡c káº¿t quáº£ thá»±c thi theo nhá»¯ng cÃ¡ch khÃ¡c nhau. 
CÃ¡c phÆ°Æ¡ng phÃ¡p há»c weakly-supervised (Berant et al., 
2013; Pasupat & Liang, 2015; Guu et al., 2017) mÃ´ hÃ¬nh 
hÃ³a cÃ¡c chÆ°Æ¡ng trÃ¬nh nhÆ° cÃ¡c biáº¿n tiá»m áº©n vÃ  sá»­ dá»¥ng káº¿t 
quáº£ thá»±c thi Ä‘á»ƒ dáº«n xuáº¥t tÃ­n hiá»‡u giÃ¡m sÃ¡t. Káº¿t quáº£ thá»±c 
thi trung gian Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ hÆ°á»›ng dáº«n tÃ¬m kiáº¿m chÆ°Æ¡ng 
trÃ¬nh cáº£ trong thá»i gian huáº¥n luyá»‡n (Chen et al., 2019; 
2021b) vÃ  suy luáº­n (Wang et al., 2018). Khi láº¥y máº«u á»Ÿ 
quy mÃ´ lá»›n, majority voting dá»±a trÃªn káº¿t quáº£ thá»±c thi Ä‘Ã£ 
Ä‘Æ°á»£c cho tháº¥y hiá»‡u quáº£ cho lá»±a chá»n á»©ng viÃªn (Li et al., 
2022a; Cobbe et al., 2021). Shi et al. (2022) tá»•ng quÃ¡t 
hÃ³a nguyÃªn táº¯c nÃ y báº±ng cÃ¡ch chá»n cÃ¡c máº«u cÃ³ consensus 
tá»‘i Ä‘a vá»›i cÃ¡c máº«u khÃ¡c trong káº¿t quáº£ thá»±c thi. ChÃºng tÃ´i 
Ä‘á» xuáº¥t huáº¥n luyá»‡n má»™t mÃ´ hÃ¬nh xÃ¡c minh Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ tÃ­nh 
Ä‘Ãºng Ä‘áº¯n cá»§a sinh code cÃ³ tÃ­nh Ä‘áº¿n káº¿t quáº£ thá»±c thi.

Há»c XÃ¡c minh. CÃ´ng trÃ¬nh trÆ°á»›c Ä‘Ã¢y Ä‘Ã£ cho tháº¥y hiá»‡u quáº£ 
cá»§a cÃ¡c verifiers Ä‘Æ°á»£c há»c cho lá»c máº«u trong cÃ¡c lÄ©nh vá»±c 
nhÆ° math QA (Shen et al., 2021; Cobbe et al., 2021) vÃ  
commonsense QA (Li et al., 2022b), nÆ¡i giáº£i phÃ¡p chá»§ yáº¿u 
Ä‘Æ°á»£c mÃ´ táº£ báº±ng ngÃ´n ngá»¯ tá»± nhiÃªn. Trong khi viá»‡c huáº¥n 
luyá»‡n cÃ¡c verifiers Ä‘á»™c láº­p vá»›i generator phá»• biáº¿n hÆ¡n 
(Cobbe et al., 2021; Li et al., 2022b), Shen et al. (2021) 
finetuned cáº£ hai cÃ¹ng lÃºc. CÃ´ng trÃ¬nh trÆ°á»›c Ä‘Ã¢y cÅ©ng Ä‘Ã£ 
sá»­ dá»¥ng cÃ¡c LMs cÆ¡ sá»Ÿ khÃ¡c nhau cho cÃ¡c verifiers. Cobbe 
et al. (2021) sá»­ dá»¥ng GPT-3 (Brown et al., 2020) trong 
khi Li et al. (2022b) sá»­ dá»¥ng DeBERTa (He et al., 2020). 
BÃªn cáº¡nh cÃ¡c verifiers cá»¥ thá»ƒ cho tÃ¡c vá»¥, Kadavath et al. 
(2022) cho tháº¥y cÃ¡c LMs lá»›n cÃ³ thá»ƒ tá»± xÃ¡c minh Ä‘áº§u ra cá»§a 
chÃºng trong setting few-shot cho má»™t loáº¡t cÃ¡c tÃ¡c vá»¥. Chen 
et al. (2022a) vÃ  cÃ¡c cÃ´ng trÃ¬nh khÃ¡c (Tufano et al., 2020; 
Li et al., 2022a) sá»­ dá»¥ng LMs Ä‘á»ƒ sinh test cases thay vÃ¬ 
trá»±c tiáº¿p Ä‘Ã¡nh giÃ¡ tÃ­nh Ä‘Ãºng Ä‘áº¯n cá»§a cÃ¡c chÆ°Æ¡ng trÃ¬nh Ä‘áº§u 
ra. Äá»ƒ so sÃ¡nh, setting cá»§a LEVER gáº§n vá»›i Li et al. (2022b) 
vÃ¬ chÃºng tÃ´i huáº¥n luyá»‡n verifier riÃªng biá»‡t vÃ  sá»­ dá»¥ng LM 
nhá» hÆ¡n nhiá»u cho nÃ³ (khoáº£ng 0.5% kÃ­ch thÆ°á»›c tham sá»‘ 
generator). ChÃºng tÃ´i bÃ¡o cÃ¡o táº­p Ä‘Ã¡nh giÃ¡ toÃ n diá»‡n Ä‘áº§u 
tiÃªn trÃªn cÃ¡c tÃ¡c vá»¥ ngÃ´n ngá»¯-sang-code, sá»­ dá»¥ng káº¿t quáº£ 
thá»±c thi chÆ°Æ¡ng trÃ¬nh8.

Xáº¿p háº¡ng láº¡i Discriminative. CÃ¡c phÆ°Æ¡ng phÃ¡p xáº¿p háº¡ng 
láº¡i discriminative tá»« lÃ¢u Ä‘Ã£ Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ cáº£i thiá»‡n thÃªm 
hiá»‡u suáº¥t cá»§a cÃ¡c tÃ¡c vá»¥ sinh chuá»—i, bao gá»“m tÃ³m táº¯t (Wan 
et al., 2015), dá»‹ch mÃ¡y (Shen et al., 2004; Lee et al., 2021), 
sinh pháº£n há»“i Ä‘á»‘i thoáº¡i (Olabiyi et al., 2018) vÃ  gáº§n Ä‘Ã¢y 
hÆ¡n, sinh code (Yin & Neubig, 2019). LEVER cÃ³ thá»ƒ Ä‘Æ°á»£c 
xem nhÆ° má»™t framework xáº¿p háº¡ng láº¡i discriminative.

7. Háº¡n cháº¿
Trong cÃ´ng trÃ¬nh nÃ y, chÃºng tÃ´i sá»­ dá»¥ng thÃ´ng tin thá»±c thi 
Ä‘á»ƒ xÃ¡c minh cÃ¡c chÆ°Æ¡ng trÃ¬nh trong LEVER. Tuy nhiÃªn, viá»‡c 
thá»±c thi cÃ¡c chÆ°Æ¡ng trÃ¬nh phá»¥ thuá»™c vÃ o Ã­t nháº¥t má»™t táº­p 
Ä‘áº§u vÃ o (vÃ­ dá»¥, Ä‘á»‘i sá»‘ cho má»™t hÃ m) vÃ  ngá»¯ cáº£nh thá»±c thi 
Ä‘áº§y Ä‘á»§ (vÃ­ dá»¥, cÆ¡ sá»Ÿ dá»¯ liá»‡u), cÃ³ thá»ƒ khÃ´ng Ä‘Æ°á»£c cung cáº¥p 
cho má»™t sá»‘ á»©ng dá»¥ng nháº¥t Ä‘á»‹nh. HÆ¡n ná»¯a, chÃºng ta khÃ´ng 
thá»ƒ luÃ´n giáº£ Ä‘á»‹nh ráº±ng cÃ¡c chÆ°Æ¡ng trÃ¬nh Ä‘Æ°á»£c sinh bá»Ÿi mÃ´ 
hÃ¬nh lÃ  an toÃ n Ä‘á»ƒ thá»±c thi. NgoÃ i ra, chÃºng tÃ´i sá»­ dá»¥ng 
PASS@1 lÃ m metric Ä‘Ã¡nh giÃ¡ chÃ­nh trong cÃ¡c thÃ­ nghiá»‡m. 
Trong khi nÃ³ lÃ½ tÆ°á»Ÿng cho cÃ¡c á»©ng dá»¥ng nhÆ° text-to-SQL 
vÃ  math reasoning nÆ¡i ngÆ°á»i dÃ¹ng chá»‰ tÃ¬m kiáº¿m cÃ¢u tráº£ 
lá»i cho cÃ¢u há»i cá»§a há», cÃ¡c metrics nhÆ° PASS@k hoáº·c N@k 
cÃ³ thá»ƒ cung cáº¥p gÃ³c nhÃ¬n khÃ¡c nhau cho cÃ¡c tÃ¡c vá»¥ láº­p 
trÃ¬nh tá»•ng quÃ¡t nhÆ° MBPP.

8. Káº¿t luáº­n
ChÃºng tÃ´i Ä‘á» xuáº¥t LEVER, má»™t phÆ°Æ¡ng phÃ¡p Ä‘Æ¡n giáº£n Ä‘á»ƒ 
cáº£i thiá»‡n code LLMs trÃªn cÃ¡c tÃ¡c vá»¥ ngÃ´n ngá»¯-sang-code, 
báº±ng cÃ¡ch há»c cÃ¡c mÃ´ hÃ¬nh xÃ¡c minh riÃªng biá»‡t Ä‘á»ƒ Ä‘Ã¡nh 
giÃ¡ tÃ­nh Ä‘Ãºng Ä‘áº¯n cá»§a cÃ¡c chÆ°Æ¡ng trÃ¬nh Ä‘Æ°á»£c sinh ra, cÃ³ 
tÃ­nh Ä‘áº¿n káº¿t quáº£ thá»±c thi cá»§a chÃºng. ChÃºng tÃ´i cho tháº¥y 
ráº±ng cÃ³ thá»ƒ huáº¥n luyá»‡n cÃ¡c verifiers khoáº£ng 0.5% kÃ­ch 
thÆ°á»›c cá»§a generators sá»­ dá»¥ng cÃ¡c dataset benchmark cÃ³ 
giÃ¡m sÃ¡t. Thay vÃ¬ trá»±c tiáº¿p thá»±c hiá»‡n rejection sampling 
dá»±a trÃªn Ä‘áº§u ra verifier, chÃºng tÃ´i cho tháº¥y tá»‘t hÆ¡n lÃ  
trá»™n xÃ¡c suáº¥t sinh vÃ  xÃ¡c minh cho xáº¿p háº¡ng láº¡i máº«u. 
LEVER liÃªn tá»¥c cáº£i thiá»‡n hiá»‡u suáº¥t cá»§a code LLMs trÃªn bá»‘n 
tÃ¡c vá»¥ ngÃ´n ngá»¯-sang-code, vÃ  Ä‘áº¡t Ä‘Æ°á»£c káº¿t quáº£ state-of-the-art 
má»›i trÃªn táº¥t cáº£ chÃºng. PhÃ¢n tÃ­ch thÃªm cho tháº¥y káº¿t quáº£ 
thá»±c thi chÆ°Æ¡ng trÃ¬nh lÃ  then chá»‘t cho xÃ¡c minh vÃ  phÆ°Æ¡ng 
phÃ¡p Ä‘Æ°á»£c Ä‘á» xuáº¥t cÃ³ thá»ƒ tá»•ng quÃ¡t hÃ³a trÃªn cÃ¡c LLMs khÃ¡c nhau.

Lá»i cáº£m Æ¡n
CÃ¡c tÃ¡c giáº£ muá»‘n cáº£m Æ¡n Xi Ye, Tianyi Zhang, Mengzhou 
Xia, Luke Zettlemoyer, vÃ  cÃ¡c nhÃ  Ä‘Ã¡nh giÃ¡ áº©n danh cho 
cuá»™c tháº£o luáº­n vÃ  bÃ¬nh luáº­n há»¯u Ã­ch.

TÃ i liá»‡u tham kháº£o
[TÃ´i sáº½ dá»‹ch pháº§n References náº¿u cáº§n, nhÆ°ng nÃ³ ráº¥t dÃ i vÃ  chá»§ yáº¿u lÃ  cÃ¡c tÃªn riÃªng vÃ  tiÃªu Ä‘á» cÃ´ng trÃ¬nh khoa há»c]

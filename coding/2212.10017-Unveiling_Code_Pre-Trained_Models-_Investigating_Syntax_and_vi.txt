# 2212.10017.pdf
# ÄÃ£ chuyá»ƒn Ä‘á»•i tá»« PDF sang TXT
# ÄÆ°á»ng dáº«n nguá»“n: /home/admin88/arxiv-downloader/coding/2212.10017.pdf
# KÃ­ch thÆ°á»›c tá»‡p: 1454270 bytes

===============================================
Ná»˜I DUNG Tá»†P PDF
===============================================

--- TRANG 1 ---
KhÃ¡m PhÃ¡ CÃ¡c MÃ´ HÃ¬nh Tiá»n Huáº¥n Luyá»‡n MÃ£: NghiÃªn Cá»©u Kháº£ NÄƒng CÃº PhÃ¡p vÃ  Ngá»¯ NghÄ©a

WEI MA, Äáº¡i há»c CÃ´ng nghá»‡ Nanyang, Singapore
SHANGQING LIUâˆ—, Äáº¡i há»c CÃ´ng nghá»‡ Nanyang, Singapore
MENGJIE ZHAO, Äáº¡i há»c Ludwig Maximilian Munich, Äá»©c
XIAOFEI XIE, Äáº¡i há»c Quáº£n lÃ½ Singapore, Singapore
WENHAN WANG, Äáº¡i há»c Alberta, Canada
QIANG HU, Äáº¡i há»c Tokyo, Nháº­t Báº£n
JIE ZHANG, PhÃ²ng thÃ­ nghiá»‡m Noah's Ark, Huawei, Trung Quá»‘c
YANG LIU, Äáº¡i há»c CÃ´ng nghá»‡ Nanyang, Singapore

Nhá»¯ng tiáº¿n bá»™ Ä‘Ã¡ng ká»ƒ Ä‘Ã£ Ä‘Æ°á»£c Ä‘áº¡t Ä‘Æ°á»£c trong lÄ©nh vá»±c trÃ­ tuá»‡ mÃ£ thÃ´ng qua cÃ¡c mÃ´ hÃ¬nh mÃ£ nhÃºng kiáº¿n thá»©c vá» ngÃ´n ngá»¯ láº­p trÃ¬nh. NghiÃªn cá»©u trÆ°á»›c Ä‘Ã¢y Ä‘Ã£ xem xÃ©t má»©c Ä‘á»™ hiá»ƒu biáº¿t cÃº phÃ¡p mÃ£ cá»§a cÃ¡c mÃ´ hÃ¬nh nÃ y, tuy nhiÃªn viá»‡c hiá»ƒu ngá»¯ nghÄ©a mÃ£ cá»§a chÃºng váº«n cáº§n Ä‘Æ°á»£c khÃ¡m phÃ¡. HÆ¡n ná»¯a, cÃ¡c phÃ¢n tÃ­ch hiá»‡n táº¡i thÆ°á»ng liÃªn káº¿t sá»‘ lÆ°á»£ng cáº¡nh trong cÃ¢y cÃº phÃ¡p trá»«u tÆ°á»£ng (AST) vá»›i khoáº£ng cÃ¡ch cÃº phÃ¡p. ChÃºng cÅ©ng thÆ°á»ng yÃªu cáº§u giáº£m khÃ´ng gian chiá»u cao cá»§a cÃ¡c mÃ´ hÃ¬nh há»c sÃ¢u xuá»‘ng chiá»u tháº¥p hÆ¡n, cÃ³ thá»ƒ dáº«n Ä‘áº¿n sá»± khÃ´ng chÃ­nh xÃ¡c. ChÃºng tÃ´i phÃ¢n tÃ­ch toÃ n diá»‡n báº£y mÃ´ hÃ¬nh mÃ£ Ä‘á»ƒ Ä‘iá»u tra cÃ¡ch cÃ¡c mÃ´ hÃ¬nh mÃ£ biá»ƒu diá»…n cÃº phÃ¡p vÃ  ngá»¯ nghÄ©a mÃ£. Äiá»u nÃ y bao gá»“m bá»‘n mÃ´ hÃ¬nh tiá»n huáº¥n luyá»‡n mÃ£ ná»•i báº­t (CodeBERT, GraphCodeBERT, CodeT5, vÃ  UnixCoder) vÃ  ba mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n (StarCoder, CodeLlama, vÃ  CodeT5+). ChÃºng tÃ´i Ä‘Ã£ phÃ¡t triá»ƒn bá»‘n nhiá»‡m vá»¥ thÄƒm dÃ² Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ kháº£ nÄƒng há»c cÃº phÃ¡p vÃ  ngá»¯ nghÄ©a mÃ£ cá»§a cÃ¡c mÃ´ hÃ¬nh. CÃ¡c nhiá»‡m vá»¥ nÃ y táº­p trung vÃ o viá»‡c tÃ¡i táº¡o cÃ¡c cáº¥u trÃºc cÃº phÃ¡p vÃ  ngá»¯ nghÄ©a mÃ£â€”nhÆ° CÃ¢y CÃº phÃ¡p Trá»«u tÆ°á»£ng (AST), Äá»“ thá»‹ Luá»“ng Äiá»u khiá»ƒn (CFG), Äá»“ thá»‹ Phá»¥ thuá»™c Äiá»u khiá»ƒn (CDG), vÃ  Äá»“ thá»‹ Phá»¥ thuá»™c Dá»¯ liá»‡u (DDG)â€”trong khÃ´ng gian biá»ƒu diá»…n cá»§a cÃ¡c mÃ´ hÃ¬nh. Nhá»¯ng cáº¥u trÃºc nÃ y lÃ  ná»n táº£ng Ä‘á»ƒ hiá»ƒu mÃ£. NgoÃ i ra, chÃºng tÃ´i khÃ¡m phÃ¡ vai trÃ² cá»§a cÃ¡c token cÃº phÃ¡p trong má»—i biá»ƒu diá»…n token vÃ  cÃ¡c phá»¥ thuá»™c má»Ÿ rá»™ng giá»¯a cÃ¡c token mÃ£. HÆ¡n ná»¯a, chÃºng tÃ´i xem xÃ©t phÃ¢n phá»‘i trá»ng sá»‘ chÃº Ã½ liÃªn quan Ä‘áº¿n cÃ¡c cáº¥u trÃºc ngá»¯ nghÄ©a mÃ£. ThÃ´ng qua phÃ¢n tÃ­ch chi tiáº¿t, káº¿t quáº£ cá»§a chÃºng tÃ´i nháº¥n máº¡nh Ä‘iá»ƒm máº¡nh vÃ  Ä‘iá»ƒm yáº¿u cá»§a cÃ¡c mÃ´ hÃ¬nh mÃ£ khÃ¡c nhau trong viá»‡c lÃ m chá»§ cÃº phÃ¡p vÃ  ngá»¯ nghÄ©a mÃ£. CÃ¡c phÃ¡t hiá»‡n cho tháº¥y ráº±ng nhá»¯ng mÃ´ hÃ¬nh nÃ y cÃ³ kháº£ nÄƒng náº¯m báº¯t cÃº phÃ¡p mÃ£, hiá»‡u quáº£ trong viá»‡c náº¯m báº¯t cÃ¡c má»‘i quan há»‡ vÃ  vai trÃ² cá»§a cÃ¡c token cÃº phÃ¡p. Tuy nhiÃªn, kháº£ nÄƒng mÃ£ hÃ³a ngá»¯ nghÄ©a mÃ£ cá»§a chÃºng cho tháº¥y sá»± biáº¿n Ä‘á»•i nhiá»u hÆ¡n. CodeT5 vÃ  CodeBERT xuáº¥t sáº¯c trong viá»‡c náº¯m báº¯t cÃ¡c phá»¥ thuá»™c Ä‘iá»u khiá»ƒn vÃ  dá»¯ liá»‡u, trong khi UnixCoder hoáº¡t Ä‘á»™ng kÃ©m hiá»‡u quáº£ hÆ¡n. ChÃºng tÃ´i cÅ©ng tháº¥y ráº±ng cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n (LLM) khÃ´ng vÆ°á»£t trá»™i hÆ¡n cÃ¡c mÃ´ hÃ¬nh tiá»n huáº¥n luyá»‡n má»™t cÃ¡ch Ä‘Ã¡ng ká»ƒ. ThÃº vá»‹ lÃ , cÃ¡c táº§ng nÃ´ng cá»§a LLM thá»ƒ hiá»‡n hiá»‡u suáº¥t tá»‘t hÆ¡n so vá»›i cÃ¡c táº§ng sÃ¢u cá»§a chÃºng. PhÃ¢n tÃ­ch trá»ng sá»‘ chÃº Ã½ cá»§a chÃºng tÃ´i cho tháº¥y ráº±ng cÃ¡c Ä‘áº§u chÃº Ã½ khÃ¡c nhau Ä‘Æ°á»£c chuyÃªn mÃ´n hÃ³a cho cÃ¡c vai trÃ² riÃªng biá»‡t trong viá»‡c mÃ£ hÃ³a ngá»¯ nghÄ©a mÃ£. NghiÃªn cá»©u cá»§a chÃºng tÃ´i nháº¥n máº¡nh sá»± cáº§n thiáº¿t cho nhá»¯ng cáº£i tiáº¿n thÃªm trong cÃ¡c mÃ´ hÃ¬nh mÃ£ Ä‘á»ƒ nÃ¢ng cao kháº£ nÄƒng há»c ngá»¯ nghÄ©a mÃ£ má»™t cÃ¡ch hiá»‡u quáº£.

âˆ—TÃ¡c giáº£ liÃªn láº¡c.
Äá»‹a chá»‰ tÃ¡c giáº£: Wei Ma, Äáº¡i há»c CÃ´ng nghá»‡ Nanyang, Singapore, ma_wei@ntu.edu.sg; Shangqing Liu, Äáº¡i há»c CÃ´ng nghá»‡ Nanyang, Singapore, liu.shangqing@ntu.edu.sg; Mengjie Zhao, Äáº¡i há»c Ludwig Maximilian Munich, Munich, Äá»©c, mzhaolmu@gmail.com; Xiaofei Xie, Äáº¡i há»c Quáº£n lÃ½ Singapore, Singapore, xfxie@smu.edu.sg; Wenhan Wang, Äáº¡i há»c Alberta, Edmonton, Canada, wenhan12@ualberta.ca; Qiang Hu, Äáº¡i há»c Tokyo, Tokyo, Nháº­t Báº£n, qianghu0515@gmail.com; Jie Zhang, PhÃ²ng thÃ­ nghiá»‡m Noah's Ark, Huawei, TÃ¢y An, Trung Quá»‘c, clark.zhang@huawei.com; Yang Liu, Äáº¡i há»c CÃ´ng nghá»‡ Nanyang, Singapore, yangliu@ntu.edu.sg.

Quyá»n táº¡o báº£n sao ká»¹ thuáº­t sá»‘ hoáº·c báº£n cá»©ng cá»§a táº¥t cáº£ hoáº·c má»™t pháº§n cÃ´ng trÃ¬nh nÃ y Ä‘á»ƒ sá»­ dá»¥ng cÃ¡ nhÃ¢n hoáº·c trong lá»›p há»c Ä‘Æ°á»£c cáº¥p miá»…n phÃ­ vá»›i Ä‘iá»u kiá»‡n cÃ¡c báº£n sao khÃ´ng Ä‘Æ°á»£c táº¡o ra hoáº·c phÃ¢n phá»‘i vÃ¬ lá»£i nhuáº­n hoáº·c lá»£i tháº¿ thÆ°Æ¡ng máº¡i vÃ  cÃ¡c báº£n sao pháº£i mang thÃ´ng bÃ¡o nÃ y vÃ  trÃ­ch dáº«n Ä‘áº§y Ä‘á»§ trÃªn trang Ä‘áº§u tiÃªn. Báº£n quyá»n cho cÃ¡c thÃ nh pháº§n cá»§a cÃ´ng trÃ¬nh nÃ y thuá»™c sá»Ÿ há»¯u cá»§a ngÆ°á»i khÃ¡c ngoÃ i (cÃ¡c) tÃ¡c giáº£ pháº£i Ä‘Æ°á»£c tÃ´n trá»ng. Viá»‡c tÃ³m táº¯t cÃ³ ghi nguá»“n Ä‘Æ°á»£c cho phÃ©p. Äá»ƒ sao chÃ©p khÃ¡c, hoáº·c tÃ¡i xuáº¥t báº£n, Ä‘á»ƒ Ä‘Äƒng trÃªn mÃ¡y chá»§ hoáº·c Ä‘á»ƒ phÃ¢n phá»‘i láº¡i cho cÃ¡c danh sÃ¡ch, yÃªu cáº§u sá»± cho phÃ©p cá»¥ thá»ƒ trÆ°á»›c vÃ /hoáº·c má»™t khoáº£n phÃ­. YÃªu cáº§u quyá»n tá»« permissions@acm.org.
Â©2018 Báº£n quyá»n thuá»™c vá» chá»§ sá»Ÿ há»¯u/tÃ¡c giáº£. Quyá»n xuáº¥t báº£n Ä‘Æ°á»£c cáº¥p phÃ©p cho ACM.
ACM 0004-5411/2018/8-ART111
https://doi.org/XXXXXXX.XXXXXXX
J. ACM, Vol. 37, No. 4, Article 111. NgÃ y xuáº¥t báº£n: ThÃ¡ng 8 2018.arXiv:2212.10017v3 [cs.SE] 17 ThÃ¡ng 4 2024

--- TRANG 2 ---
111:2 W. Ma, S. Liu vÃ  M. Zhao et al.

NghiÃªn cá»©u nÃ y lÃ m phong phÃº thÃªm hiá»ƒu biáº¿t cá»§a chÃºng ta vá» kháº£ nÄƒng cá»§a cÃ¡c mÃ´ hÃ¬nh mÃ£ trong viá»‡c phÃ¢n tÃ­ch cÃº phÃ¡p vÃ  ngá»¯ nghÄ©a. CÃ¡c phÃ¡t hiá»‡n cá»§a chÃºng tÃ´i cung cáº¥p nhá»¯ng hiá»ƒu biáº¿t cÃ³ giÃ¡ trá»‹ cho viá»‡c cáº£i tiáº¿n mÃ´ hÃ¬nh mÃ£ trong tÆ°Æ¡ng lai, giÃºp tá»‘i Æ°u hÃ³a á»©ng dá»¥ng cá»§a chÃºng trong nhiá»u nhiá»‡m vá»¥ liÃªn quan Ä‘áº¿n mÃ£.

Äá»‹nh dáº¡ng Tham chiáº¿u ACM:
Wei Ma, Shangqing Liu, Mengjie Zhao, Xiaofei Xie, Wenhan Wang, Qiang Hu, Jie Zhang, vÃ  Yang Liu. 2018. KhÃ¡m PhÃ¡ CÃ¡c MÃ´ HÃ¬nh Tiá»n Huáº¥n Luyá»‡n MÃ£: NghiÃªn Cá»©u Kháº£ NÄƒng CÃº PhÃ¡p vÃ  Ngá»¯ NghÄ©a. J. ACM 37, 4, Article 111 (ThÃ¡ng 8 2018), 29 trang. https://doi.org/XXXXXXX.XXXXXXX

1 GIá»šI THIá»†U

Nhiá»u mÃ´ hÃ¬nh mÃ£ [2,4,13,17,29,31,41,42,63,71] Ä‘Ã£ Ä‘Æ°á»£c Ä‘á» xuáº¥t Ä‘á»ƒ thÃºc Ä‘áº©y máº¡nh máº½ sá»± phÃ¡t triá»ƒn cá»§a trÃ­ tuá»‡ mÃ£. Nhiá»u phÆ°Æ¡ng phÃ¡p ká»¹ thuáº­t pháº§n má»m dá»±a trÃªn viá»‡c tinh chá»‰nh cÃ¡c mÃ´ hÃ¬nh tiá»n huáº¥n luyá»‡n nÃ y, nhÆ° phÃ¡t hiá»‡n mÃ£ trÃ¹ng láº·p, phÃ¡t hiá»‡n lá»— há»•ng vÃ  hoÃ n thÃ nh mÃ£. Gáº§n Ä‘Ã¢y, cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n (LLM) Ä‘Ã£ Ä‘Æ°á»£c chá»©ng minh cÃ³ kháº£ nÄƒng ná»•i báº­t [72] mÃ  cÃ¡c mÃ´ hÃ¬nh tiá»n huáº¥n luyá»‡n khÃ´ng cÃ³. CÃ´ng nghá»‡ nÃ y lÃ m cho viá»‡c tá»± Ä‘á»™ng táº¡o pháº§n má»m trá»Ÿ nÃªn kháº£ thi, nhÆ° MetaGPT [19]. Máº·c dÃ¹ cÃ¡c mÃ´ hÃ¬nh nÃ y Ä‘Ã£ Ä‘Æ°á»£c chá»©ng minh hiá»‡u quáº£ trÃªn nhiá»u nhiá»‡m vá»¥ liÃªn quan Ä‘áº¿n mÃ£, má»™t váº¥n Ä‘á» cÆ¡ báº£n váº«n chÆ°a Ä‘Æ°á»£c giáº£i quyáº¿t Ä‘á»‘i vá»›i nhá»¯ng mÃ´ hÃ¬nh mÃ£ nÃ y vá» cÃ¡ch chÃºng hiá»ƒu mÃ£. ÄÃ¡ng ká»ƒ, cÃ¡c nghiÃªn cá»©u gáº§n Ä‘Ã¢y [14,28,75] chá»‰ ra ráº±ng cÃ¡c mÃ´ hÃ¬nh mÃ£ khÃ´ng thá»ƒ Ä‘Æ°a ra káº¿t quáº£ há»£p lÃ½ náº¿u sá»­ dá»¥ng cÃ¡c thá»§ thuáº­t thay tháº¿ hoáº·c chÃ¨n token. Äá»‘i vá»›i cÃ¡c mÃ´ hÃ¬nh mÃ£, chÃºng ta nÃªn xem xÃ©t sÃ¢u sáº¯c kháº£ nÄƒng há»c cÃ¡c Ä‘áº·c Ä‘iá»ƒm cÆ¡ báº£n cá»§a mÃ£, "CÃ¡c mÃ´ hÃ¬nh mÃ£ nÃ y cÃ³ thá»ƒ há»c Ä‘Æ°á»£c loáº¡i kiáº¿n thá»©c mÃ£ nÃ o?". Má»™t chÆ°Æ¡ng trÃ¬nh bao gá»“m cÃ¡c tÃ­nh nÄƒng cÃº phÃ¡p (vÃ­ dá»¥: AST) vÃ  thÃ´ng tin ngá»¯ nghÄ©a (vÃ­ dá»¥: phá»¥ thuá»™c dá»¯ liá»‡u); do Ä‘Ã³, váº¥n Ä‘á» nÃ y cÃ³ thá»ƒ Ä‘Æ°á»£c phÃ¢n tÃ¡ch thÃªm thÃ nh "CÃ¡c mÃ´ hÃ¬nh mÃ£ cÃ³ thá»ƒ náº¯m báº¯t cÃº phÃ¡p chÆ°Æ¡ng trÃ¬nh tá»‘t khÃ´ng?" vÃ  "CÃ¡c mÃ´ hÃ¬nh mÃ£ cÃ³ thá»ƒ há»c Ä‘Æ°á»£c loáº¡i ngá»¯ nghÄ©a chÆ°Æ¡ng trÃ¬nh nÃ o?". CÃ¡c nghiÃªn cá»©u trÆ°á»›c Ä‘Ã£ báº¯t Ä‘áº§u khÃ¡m phÃ¡ nhá»¯ng cÃ¢u há»i Ä‘Æ°á»£c nÃªu ra, Ä‘áº·c biá»‡t lÃ  cÃ¢u há»i phá»¥ Ä‘áº§u tiÃªn. Tuy nhiÃªn, hiá»ƒu biáº¿t sÃ¢u sáº¯c hÆ¡n vá» kiáº¿n thá»©c Ä‘Æ°á»£c cÃ¡c mÃ´ hÃ¬nh mÃ£ thu Ä‘Æ°á»£c váº«n cÃ²n khÃ³ náº¯m báº¯t. Trong khi nghiÃªn cá»©u cá»§a Wan et al. [69] vÃ  HernÃ¡ndez LÃ³pez et al. [18] cho tháº¥y ráº±ng cÃ¡c mÃ´ hÃ¬nh tiá»n huáº¥n luyá»‡n mÃ£ cÃ³ thá»ƒ náº¯m báº¯t cÃº phÃ¡p chÆ°Æ¡ng trÃ¬nh, phÃ¢n tÃ­ch cá»§a há» khÃ´ng má»Ÿ rá»™ng Ä‘áº¿n ngá»¯ nghÄ©a chÆ°Æ¡ng trÃ¬nh. CÅ©ng quan trá»ng cáº§n lÆ°u Ã½ ráº±ng nhá»¯ng nghiÃªn cá»©u nÃ y cÃ³ hai giáº£ Ä‘á»‹nh: 1) sá»‘ lÆ°á»£ng liÃªn káº¿t giá»¯a cÃ¡c nÃºt cÃ³ liÃªn quan Ä‘áº¿n cÃº phÃ¡p mÃ£; 2) tá»“n táº¡i má»‘i quan há»‡ tuyáº¿n tÃ­nh giá»¯a biá»ƒu diá»…n mÃ£ trong khÃ´ng gian chiá»u cao vÃ  chiá»u tháº¥p. Tuy nhiÃªn, nhá»¯ng giáº£ Ä‘á»‹nh nÃ y cÃ³ má»™t sá»‘ háº¡n cháº¿: 1) sá»‘ lÆ°á»£ng liÃªn káº¿t khÃ´ng nháº¥t thiáº¿t pháº£i liÃªn quan Ä‘áº¿n cÃº phÃ¡p mÃ£. 2) khoáº£ng cÃ¡ch nhá» hÆ¡n trong vÄƒn báº£n mÃ£ thÃ´ khÃ´ng cÃ³ nghÄ©a lÃ  Ä‘á»™ gáº§n cÃº phÃ¡p trong khÃ´ng gian biá»ƒu diá»…n. HÆ¡n ná»¯a, Troshin vÃ  Chirkova [66] xem xÃ©t cáº£ cÃº phÃ¡p vÃ  ngá»¯ nghÄ©a mÃ£ thÃ´ng qua cÃ¡c nhiá»‡m vá»¥ khÃ¡c nhau. Tuy nhiÃªn, cÃ´ng trÃ¬nh nÃ y tuÃ¢n theo má»™t phÆ°Æ¡ng phÃ¡p tÆ°Æ¡ng tá»± vá»›i cÃ¡c nghiÃªn cá»©u trÆ°á»›c Ä‘Ã³ khi phÃ¢n tÃ­ch cÃº phÃ¡p. NÃ³ cÅ©ng khÃ´ng Ä‘iá»u tra ká»¹ lÆ°á»¡ng cÃ¡c ngá»¯ nghÄ©a khÃ¡c nhau vá»‘n cÃ³ trong láº­p trÃ¬nh. Quan trá»ng hÆ¡n, khÃ´ng cÃ³ nghiÃªn cá»©u nÃ o vá» bá»™ giáº£i mÃ£ transformer, Ä‘Ã¢y lÃ  kiáº¿n trÃºc cá»§a háº§u háº¿t cÃ¡c LLM, nhÆ° cÃ¡c há» StarCoder [34] vÃ  Llama [58].

Nhá»¯ng cÃ¢u há»i nÃ y cÃ³ Ã½ nghÄ©a quan trá»ng Ä‘á»ƒ chÃºng ta xem xÃ©t cÃ¡c á»©ng dá»¥ng cá»§a mÃ´ hÃ¬nh mÃ£ trong ká»¹ thuáº­t pháº§n má»m. Náº¿u cÃ¡c mÃ´ hÃ¬nh mÃ£ cÃ³ thá»ƒ hiá»ƒu mÃ£ gáº§n nhÆ° hoÃ n háº£o, Ä‘áº§u ra cá»§a cÃ¡c mÃ´ hÃ¬nh mÃ£ cÃ³ thá»ƒ Ä‘Æ°á»£c tin tÆ°á»Ÿng vÃ  viá»‡c táº¡o pháº§n má»m tá»± Ä‘á»™ng lÃ  kháº£ thi. Äá»ƒ giáº£i quyáº¿t nhá»¯ng thÃ¡ch thá»©c nÃªu trÃªn, trong bÃ i bÃ¡o nÃ y, chÃºng tÃ´i Ä‘iá»u tra toÃ n diá»‡n bá»‘n mÃ´ hÃ¬nh tiá»n huáº¥n luyá»‡n mÃ£ Ä‘Æ°á»£c Ã¡p dá»¥ng rá»™ng rÃ£i: CodeBERT [13] (Chá»‰ mÃ£ hÃ³a), GraphCodeBERT [17] (Chá»‰ mÃ£ hÃ³a), CodeT5 [71] (MÃ£ hÃ³a-giáº£i mÃ£) vÃ  UnixCoder [16] (Kiá»ƒu UniLM). ChÃºng tÃ´i cÅ©ng bao gá»“m ba mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n (LLM), StarCoder [34], CodeLlama [58] vÃ  CodeT5+ [70].

Bá»‘n nhiá»‡m vá»¥ thÄƒm dÃ² Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ phÃ¢n tÃ­ch kháº£ nÄƒng cá»§a cÃ¡c mÃ´ hÃ¬nh trong viá»‡c há»c cÃº phÃ¡p vÃ  ngá»¯ nghÄ©a mÃ£. Cá»¥ thá»ƒ, chÃºng tÃ´i sá»­ dá»¥ng hai nhiá»‡m vá»¥ thÄƒm dÃ² cÃº phÃ¡p, cá»¥ thá»ƒ lÃ  dá»± Ä‘oÃ¡n cáº·p nÃºt cÃº phÃ¡p vÃ  dá»± Ä‘oÃ¡n gáº¯n tháº» cÃº phÃ¡p token. Cáº£ hai nhiá»‡m vá»¥ Ä‘á»u nháº±m thao tÃ¡c CÃ¢y CÃº phÃ¡p Trá»«u tÆ°á»£ng (AST) Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ kháº£ nÄƒng cá»§a cÃ¡c mÃ´ hÃ¬nh tiá»n huáº¥n luyá»‡n trong viá»‡c há»c cÃº phÃ¡p mÃ£ vÃ¬ AST mang táº¥t cáº£ thÃ´ng tin cÃº phÃ¡p cá»§a mÃ£. Dá»± Ä‘oÃ¡n cáº·p nÃºt cÃº phÃ¡p nháº±m xÃ¡c Ä‘á»‹nh liá»‡u

J. ACM, Vol. 37, No. 4, Article 111. NgÃ y xuáº¥t báº£n: ThÃ¡ng 8 2018.

--- TRANG 3 ---
KhÃ¡m PhÃ¡ CÃ¡c MÃ´ HÃ¬nh Tiá»n Huáº¥n Luyá»‡n MÃ£: NghiÃªn Cá»©u Kháº£ NÄƒng CÃº PhÃ¡p vÃ  Ngá»¯ NghÄ©a 111:3

cÃ¡c biá»ƒu diá»…n vector cá»§a hai Ä‘oáº¡n gáº§n nhau vá» cÃº phÃ¡p cÃ³ thá»ƒ hiá»‡n sá»± tÆ°Æ¡ng tá»± cÃº phÃ¡p hay khÃ´ng trong khi dá»± Ä‘oÃ¡n gáº¯n tháº» cÃº phÃ¡p token nháº±m xÃ¡c Ä‘á»‹nh liá»‡u biá»ƒu diá»…n vector cÃ³ náº¯m báº¯t quy táº¯c cÃº phÃ¡p cá»§a token riÃªng láº» hay khÃ´ng. Dá»± Ä‘oÃ¡n cáº·p nÃºt cÃº phÃ¡p lÃ  Ä‘á»ƒ khÃ´i phá»¥c cáº¥u trÃºc AST tá»« biá»ƒu diá»…n vector, vÃ  dá»± Ä‘oÃ¡n gáº¯n tháº» cÃº phÃ¡p token lÃ  Ä‘á»ƒ gÃ¡n vai trÃ² cÃº phÃ¡p cho má»—i token mÃ£ trong khÃ´ng gian biá»ƒu diá»…n. Cáº£ hai thÃ´ng tin cÃº phÃ¡p Ä‘á»u quan trá»ng Ä‘á»ƒ cÃ¡c mÃ´ hÃ¬nh mÃ£ hiá»ƒu cÃº phÃ¡p mÃ£ á»Ÿ cáº¥p Ä‘á»™ toÃ n cá»¥c vÃ  cá»¥c bá»™. Ã Ä‘á»‹nh Ä‘áº±ng sau hai nhiá»‡m vá»¥ cÃº phÃ¡p lÃ  biá»ƒu diá»…n vector token mÃ£ nÃªn giá»¯ cÃ¡c thuá»™c tÃ­nh cÃº phÃ¡p tá»“n táº¡i trong mÃ£: má»‘i quan há»‡ cÃº phÃ¡p giá»¯a cÃ¡c token mÃ£ vÃ  thuá»™c tÃ­nh cÃº phÃ¡p cá»§a má»—i token mÃ£.

NgoÃ i phÃ¢n tÃ­ch cÃº phÃ¡p, chÃºng tÃ´i tiáº¿p tá»¥c thiáº¿t káº¿ hai nhiá»‡m vá»¥ thÄƒm dÃ² ngá»¯ nghÄ©a, cá»¥ thá»ƒ lÃ  dá»± Ä‘oÃ¡n quan há»‡ ngá»¯ nghÄ©a vÃ  dá»± Ä‘oÃ¡n lan truyá»n ngá»¯ nghÄ©a. Cáº£ hai nhiá»‡m vá»¥ Ä‘á»u Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ Ä‘iá»u tra má»©c Ä‘á»™ mÃ  cÃ¡c mÃ´ hÃ¬nh mÃ£ cÃ³ thá»ƒ há»c hiá»‡u quáº£ cÃ¡c khÃ­a cáº¡nh khÃ¡c nhau cá»§a ngá»¯ nghÄ©a mÃ£. Dá»± Ä‘oÃ¡n quan há»‡ ngá»¯ nghÄ©a lÃ  Ä‘á»ƒ khÃ´i phá»¥c cÃ¡c cáº¥u trÃºc ngá»¯ nghÄ©a mÃ£ quan trá»ng trong khÃ´ng gian biá»ƒu diá»…n, bao gá»“m Äá»“ thá»‹ Phá»¥ thuá»™c Dá»¯ liá»‡u (DDG), Äá»“ thá»‹ Phá»¥ thuá»™c Äiá»u khiá»ƒn (CDG) vÃ  Äá»“ thá»‹ Luá»“ng Äiá»u khiá»ƒn (CFG). Nhá»¯ng cáº¥u trÃºc ngá»¯ nghÄ©a nÃ y cÃ³ thá»ƒ biá»ƒu diá»…n viá»‡c thá»±c thi mÃ£ vÃ  cÃ¡c tráº¡ng thÃ¡i bÃªn trong. Dá»± Ä‘oÃ¡n lan truyá»n ngá»¯ nghÄ©a lÃ  Ä‘á»ƒ xem liá»‡u chÃºng ta cÃ³ thá»ƒ quan sÃ¡t má»‘i quan há»‡ phá»¥ thuá»™c dÃ i trong khÃ´ng gian vector hay khÃ´ng vÃ¬ má»™t biáº¿n cÃ³ thá»ƒ Ä‘Æ°á»£c khai bÃ¡o trong cÃ¢u lá»‡nh Ä‘áº§u tiÃªn nhÆ°ng Ä‘Æ°á»£c sá»­ dá»¥ng á»Ÿ cuá»‘i. Cuá»‘i cÃ¹ng, chÃºng tÃ´i thá»±c hiá»‡n phÃ¢n tÃ­ch thá»‘ng kÃª cho cÃ¡c trá»ng sá»‘ chÃº Ã½ Ä‘á»ƒ hiá»ƒu toÃ n diá»‡n vai trÃ² vÃ  phÃ¢n phá»‘i chÃº Ã½ trong viá»‡c há»c ngá»¯ nghÄ©a cá»§a mÃ£.

PhÃ¢n tÃ­ch cÃº phÃ¡p cá»§a chÃºng tÃ´i cho tháº¥y ráº±ng 1) cÃ¡c mÃ´ hÃ¬nh mÃ£ hiá»‡u quáº£ náº¯m báº¯t cÃ¡c má»‘i quan há»‡ cÃº phÃ¡p giá»¯a cÃ¡c cáº·p token vÃ  thuá»™c tÃ­nh nÃ y dá»… quan sÃ¡t hÆ¡n trong cÃ¡c táº§ng áº©n nÃ´ng, cho tháº¥y hiá»ƒu biáº¿t máº¡nh máº½ vá» cÃº phÃ¡p mÃ£ á»Ÿ cáº¥p Ä‘á»™ cáº¥u trÃºc; 2) cÃ¡c mÃ´ hÃ¬nh mÃ£ thÃ nh tháº¡o trong viá»‡c xÃ¡c Ä‘á»‹nh vai trÃ² cÃº phÃ¡p cá»§a cÃ¡c token riÃªng láº» vÃ  thuá»™c tÃ­nh nÃ y dá»… quan sÃ¡t hÆ¡n trong cÃ¡c táº§ng áº©n sÃ¢u. Tuy nhiÃªn, cÃ¡c mÃ´ hÃ¬nh tiá»n huáº¥n luyá»‡n mÃ£ cho tháº¥y hiá»‡u suáº¥t vÆ°á»£t trá»™i so vá»›i LLM Ä‘á»‘i vá»›i gáº¯n tháº» cÃº phÃ¡p, cho tháº¥y cÃ¡c Ä‘áº·c Ä‘iá»ƒm cÃº phÃ¡p khÃ³ quan sÃ¡t hÆ¡n trong biá»ƒu diá»…n mÃ£ tá»« LLM. Sá»± dá»… dÃ ng quan sÃ¡t khÃ´ng liÃªn quan trá»±c tiáº¿p Ä‘áº¿n hiá»‡u suáº¥t cá»§a mÃ´ hÃ¬nh trÃªn cÃ¡c nhiá»‡m vá»¥ downstream, vÃ¬ nÃ³ phá»¥ thuá»™c vÃ o nhiá»u yáº¿u tá»‘, nhÆ° cháº¥t lÆ°á»£ng dá»¯ liá»‡u vÃ  phÆ°Æ¡ng phÃ¡p tinh chá»‰nh. Tuy nhiÃªn, nÃ³ cÃ³ thá»ƒ chá»‰ ra khÃ³ khÄƒn trong viá»‡c xÃ¢y dá»±ng vÃ  tinh chá»‰nh má»™t mÃ´ hÃ¬nh tá»‘t cho nhiá»‡m vá»¥ downstream dá»±a trÃªn LLM. Trong thá»±c táº¿, má»i ngÆ°á»i Ä‘Ã£ thá»­ vÃ  tháº­m chÃ­ phÃ¡t hiá»‡n ráº±ng hiá»‡u suáº¥t cá»§a cÃ¡c mÃ´ hÃ¬nh nhá» truyá»n thá»‘ng tá»‘t hÆ¡n cÃ¡c mÃ´ hÃ¬nh lá»›n trong má»™t sá»‘ trÆ°á»ng há»£p [8, 27].

PhÃ¢n tÃ­ch ngá»¯ nghÄ©a cá»§a chÃºng tÃ´i cho tháº¥y hiá»‡u quáº£ khÃ¡c nhau trong kháº£ nÄƒng cá»§a cÃ¡c mÃ´ hÃ¬nh mÃ£ Ä‘á»ƒ dá»± Ä‘oÃ¡n cÃ¡c má»‘i quan há»‡ ngá»¯ nghÄ©a. CÃ¡c mÃ´ hÃ¬nh hiá»‡n táº¡i cung cáº¥p má»™t sá»‘ hiá»ƒu biáº¿t tinh táº¿ vá» ngá»¯ nghÄ©a mÃ£, nhÆ° phá»¥ thuá»™c dá»¯ liá»‡u, nhÆ°ng cÅ©ng lÃ m ná»•i báº­t cÃ¡c lÄ©nh vá»±c cáº§n cáº£i thiá»‡n, Ä‘áº·c biá»‡t trong viá»‡c náº¯m báº¯t cÃ¡c cáº¥u trÃºc ngá»¯ nghÄ©a phá»©c táº¡p. So vá»›i hiá»‡u suáº¥t cá»§a cÃ¡c nhiá»‡m vá»¥ cÃº phÃ¡p, hiá»‡u suáº¥t cá»§a cÃ¡c mÃ´ hÃ¬nh mÃ£ trong ngá»¯ nghÄ©a tÆ°Æ¡ng Ä‘á»‘i tháº¥p. Äá»‘i vá»›i CodeT5+, sá»± khÃ¡c biá»‡t hiá»‡u suáº¥t giá»¯a bá»™ mÃ£ hÃ³a vÃ  bá»™ giáº£i mÃ£ ráº¥t lá»›n. ChÃºng tÃ´i nghÄ© Ä‘iá»u nÃ y cÃ³ thá»ƒ Ä‘Æ°á»£c gÃ¢y ra bá»Ÿi cÃ¡c cÆ¡ cháº¿ hoáº¡t Ä‘á»™ng khÃ¡c nhau cá»§a bá»™ mÃ£ hÃ³a vÃ  bá»™ giáº£i mÃ£. Bá»™ mÃ£ hÃ³a táº­p trung nhiá»u hÆ¡n vÃ o viá»‡c lá»“ng thÃ´ng tin toÃ n cá»¥c. Bá»™ giáº£i mÃ£ táº­p trung nhiá»u hÆ¡n vÃ o viá»‡c táº¡o token tiáº¿p theo dá»±a trÃªn vÄƒn báº£n trÆ°á»›c Ä‘Ã³. Sá»± khÃ¡c biá»‡t nÃ y Ä‘áº·c biá»‡t rÃµ rÃ ng khi phÃ¢n tÃ­ch cÆ¡ cháº¿ chÃº Ã½. Khi chÃºng tÃ´i tiáº¿n hÃ nh phÃ¢n tÃ­ch chÃº Ã½ dá»±a trÃªn cÃ¡c phá»¥ thuá»™c Ä‘iá»u khiá»ƒn, chÃºng tÃ´i phÃ¡t hiá»‡n ráº±ng Ä‘á»‘i vá»›i kiáº¿n trÃºc bá»™ giáº£i mÃ£, Ä‘Ã³ng gÃ³p trá»ng sá»‘ cá»§a cÃ¡c token cÃ³ phá»¥ thuá»™c Ä‘iá»u khiá»ƒn nhá» hÆ¡n Ä‘Ã³ng gÃ³p trá»ng sá»‘ cá»§a cÃ¡c phá»¥ thuá»™c khÃ´ng Ä‘iá»u khiá»ƒn. ChÃºng tÃ´i tin ráº±ng Ä‘iá»u nÃ y lÃ  do bá»™ mÃ£ hÃ³a táº­p trung vÃ o viá»‡c mÃ£ hÃ³a thÃ´ng tin toÃ n cá»¥c, nhÆ°ng bá»™ giáº£i mÃ£ táº­p trung nhiá»u hÆ¡n vÃ o cÃ¡c token trÆ°á»›c Ä‘Ã³ vÃ  thÃ´ng tin khÃ´ng phá»¥ thuá»™c Ä‘iá»u khiá»ƒn khÃ¡c, dáº«n Ä‘áº¿n cÃ¡c phÃ¢n phá»‘i trá»ng sá»‘ khÃ¡c nhau.

ThÃ´ng qua phÃ¢n tÃ­ch toÃ n diá»‡n, cÃ´ng trÃ¬nh cá»§a chÃºng tÃ´i chá»‰ ra ráº±ng cÃ¡c mÃ´ hÃ¬nh mÃ£ váº«n cáº§n Ä‘Æ°á»£c cáº£i thiá»‡n Ä‘á»ƒ há»c cÃº phÃ¡p vÃ  ngá»¯ nghÄ©a mÃ£, lÃ m cho nhá»¯ng thuá»™c tÃ­nh nÃ y dá»… quan sÃ¡t hÆ¡n, tá»« Ä‘Ã³ giáº£m khÃ³ khÄƒn trong viá»‡c xÃ¢y dá»±ng mÃ´ hÃ¬nh nhiá»‡m vá»¥ downstream. Viá»‡c cáº£i thiá»‡n nÃªn táº­p trung vÃ o cÃ¡ch tÃ­ch há»£p cÃº phÃ¡p vÃ  ngá»¯ nghÄ©a mÃ£ vÃ o cÃ¡c mÃ´ hÃ¬nh mÃ£. Äiá»u nÃ y cÃ³ thá»ƒ cáº§n cÃ¡c chiáº¿n lÆ°á»£c huáº¥n luyá»‡n má»›i cÃ³ thá»ƒ tÃ­ch há»£p toÃ n bá»™ cáº¥u trÃºc mÃ£ thay vÃ¬ lÃ m pháº³ng nhá»¯ng cáº¥u trÃºc nÃ y. Máº·c dÃ¹ kháº£ nÄƒng mÃ´ hÃ¬nh

J. ACM, Vol. 37, No. 4, Article 111. NgÃ y xuáº¥t báº£n: ThÃ¡ng 8 2018.

--- TRANG 4 ---
111:4 W. Ma, S. Liu vÃ  M. Zhao et al.

Ä‘Æ°á»£c má»Ÿ rá»™ng theo kÃ­ch thÆ°á»›c cá»§a nÃ³ [30,81], viá»‡c giáº£i phÃ³ng kháº£ nÄƒng cá»§a nÃ³ lÃ  thÃ¡ch thá»©c vÃ  cáº§n má»™t cÃ´ng viá»‡c bá»• sung khÃ´ng táº§m thÆ°á»ng Ä‘á»ƒ lÃ m cho cÃ¡c tÃ­nh nÄƒng dá»… quan sÃ¡t hÆ¡n trong khÃ´ng gian biá»ƒu diá»…n cho cÃ¡c nhiá»‡m vá»¥ downstream.

TÃ³m láº¡i, cÃ´ng trÃ¬nh cá»§a chÃºng tÃ´i cÃ³ nhá»¯ng Ä‘Ã³ng gÃ³p sau:

â€¢ ChÃºng tÃ´i Ä‘á» xuáº¥t cÃ¡c nhiá»‡m vá»¥ thÄƒm dÃ³ cÃº phÃ¡p vÃ  ngá»¯ nghÄ©a Ä‘á»ƒ phÃ¢n tÃ­ch kháº£ nÄƒng cá»§a mÃ´ hÃ¬nh mÃ£ trong viá»‡c hiá»ƒu cÃº phÃ¡p vÃ  ngá»¯ nghÄ©a báº±ng cÃ¡ch trá»±c tiáº¿p khÃ´i phá»¥c cÃ¡c cáº¥u trÃºc cÃº phÃ¡p vÃ  ngá»¯ nghÄ©a mÃ£ (AST, CFG, CDG vÃ  DDG) tá»« biá»ƒu diá»…n mÃ£. ChÃºng tÃ´i nghiÃªn cá»©u phÃ¢n phá»‘i cÃ¡c trá»ng sá»‘ chÃº Ã½ liÃªn quan Ä‘áº¿n ngá»¯ nghÄ©a mÃ£.

â€¢ ChÃºng tÃ´i tiáº¿t lá»™ ráº±ng má»‘i quan há»‡ cÃº phÃ¡p dá»… quan sÃ¡t hÆ¡n trong cÃ¡c táº§ng áº©n nÃ´ng, trong khi cÃº phÃ¡p vai trÃ² token dá»… quan sÃ¡t hÆ¡n trong cÃ¡c táº§ng sÃ¢u. CÃ¡c mÃ´ hÃ¬nh mÃ£ cÃ³ hiá»‡u suáº¥t vÆ°á»£t trá»™i cho biá»ƒu diá»…n cÃº phÃ¡p so vá»›i biá»ƒu diá»…n ngá»¯ nghÄ©a. Äá»“ng thá»i, cÃ¡c mÃ´ hÃ¬nh mÃ£ cÃ³ hiá»‡u suáº¥t kÃ©m hÆ¡n Ä‘á»‘i vá»›i CFG so vá»›i cÃ¡c cáº¥u trÃºc ngá»¯ nghÄ©a khÃ¡c, Ä‘iá»u nÃ y yÃªu cáº§u cÃ¡c mÃ´ hÃ¬nh mÃ£ Ä‘Æ°á»£c tÄƒng cÆ°á»ng Ä‘á»ƒ biá»ƒu diá»…n ngá»¯ nghÄ©a CFG. CÃ¡c táº§ng áº©n khÃ¡c nhau cho tháº¥y cÃ¡c má»©c Ä‘á»™ quan sÃ¡t khÃ¡c nhau cho cÃ¡c loáº¡i cÃº phÃ¡p vÃ  ngá»¯ nghÄ©a mÃ£ khÃ¡c nhau.

â€¢ ChÃºng tÃ´i Ä‘áº§u tiÃªn bao gá»“m cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n vÃ  cho tháº¥y ráº±ng hiá»‡u suáº¥t cá»§a chÃºng trÃªn cÃ¡c nhiá»‡m vá»¥ thÄƒm dÃ² khÃ´ng cÃ³ lá»£i tháº¿ lá»›n so vá»›i cÃ¡c mÃ´ hÃ¬nh tiá»n huáº¥n luyá»‡n, xem xÃ©t sá»‘ lÆ°á»£ng tham sá»‘ khá»•ng lá»“ cá»§a chÃºng. Äiá»u nÃ y pháº£n Ã¡nh ráº±ng cÃº phÃ¡p vÃ  ngá»¯ nghÄ©a mÃ£ bá»‹ áº©n vÃ  khÃ´ng rÃµ rÃ ng trong biá»ƒu diá»…n cá»§a LLM.

ChÃºng tÃ´i hy vá»ng nhá»¯ng hiá»ƒu biáº¿t nÃ y cÃ³ thá»ƒ truyá»n cáº£m há»©ng cho cÃ¡c nhÃ  nghiÃªn cá»©u Ä‘Ã o táº¡o cÃ¡c mÃ´ hÃ¬nh mÃ£ máº¡nh máº½ hÆ¡n. Khi sá»­ dá»¥ng nhá»¯ng mÃ´ hÃ¬nh nÃ y, viá»‡c thiáº¿t káº¿ cÃ¡c quy trÃ¬nh cÃ´ng viá»‡c Ä‘Æ°á»£c hÆ°á»›ng dáº«n bá»Ÿi sá»± hiá»ƒu biáº¿t vá» nhá»¯ng mÃ´ hÃ¬nh nÃ y lÃ  cáº§n thiáº¿t, xem xÃ©t liá»‡u viá»‡c tÃ­ch há»£p cÃ¡c tÃ­nh nÄƒng mÃ£ bá»• sung cÃ³ Ä‘Æ°á»£c báº£o Ä‘áº£m hay khÃ´ng. Máº·c dÃ¹ nhiá»u yáº¿u tá»‘, bao gá»“m cháº¥t lÆ°á»£ng dá»¯ liá»‡u, Ä‘á»™ phá»©c táº¡p cá»§a cÃ¡c mÃ´ hÃ¬nh nhiá»‡m vá»¥ downstream vÃ  phÆ°Æ¡ng phÃ¡p tÃ­ch há»£p tÃ­nh nÄƒng áº£nh hÆ°á»Ÿng Ä‘áº¿n hiá»‡u suáº¥t mÃ´ hÃ¬nh trong cÃ¡c nhiá»‡m vá»¥ downstream, cÃ´ng trÃ¬nh cá»§a chÃºng tÃ´i cÃ³ thá»ƒ cung cáº¥p má»™t sá»‘ hÆ°á»›ng dáº«n cho thiáº¿t káº¿ mÃ´ hÃ¬nh vÃ  dá»¯ liá»‡u cá»§a há». CÃ¡c mÃ´ hÃ¬nh thiáº¿u hiá»ƒu biáº¿t ngá»¯ nghÄ©a cáº§n xem xÃ©t tÄƒng cÆ°á»ng thÃ´ng tin ngá»¯ nghÄ©a thÃ´ng qua tÃ­ch há»£p tÃ­nh nÄƒng khi giáº£i quyáº¿t cÃ¡c nhiá»‡m vá»¥ downstream. CÃ´ng trÃ¬nh cá»§a chÃºng tÃ´i nháº¥n máº¡nh ráº±ng khÃ´ng báº¯t buá»™c pháº£i sá»­ dá»¥ng Ä‘áº§u ra cá»§a táº§ng cuá»‘i - cÃ¡c táº§ng trung gian cÃ³ thá»ƒ biá»ƒu Ä‘áº¡t cÃº phÃ¡p vÃ  ngá»¯ nghÄ©a má»™t cÃ¡ch Ä‘áº§y Ä‘á»§. Táº¥t cáº£ mÃ£ vÃ  dá»¯ liá»‡u cÃ³ thá»ƒ Ä‘Æ°á»£c tÃ¬m tháº¥y táº¡i kho lÆ°u trá»¯Â¹.

2 Äá»˜NG Lá»°C

Kháº£ nÄƒng cá»§a cÃ¡c mÃ´ hÃ¬nh mÃ£ tiá»n huáº¥n luyá»‡n Ä‘Ã£ Ä‘Æ°á»£c tháº£o luáº­n rá»™ng rÃ£i trong cÃ¡c nghiÃªn cá»©u trÆ°á»›c Ä‘Ã¢y [18,66,69]. Tuy nhiÃªn, phÃ¢n tÃ­ch cá»§a há» dá»±a trÃªn giáº£ Ä‘á»‹nh ráº±ng cÃº phÃ¡p gáº§n hÆ¡n giá»¯a hai token trong mÃ£ sáº½ dáº«n Ä‘áº¿n khoáº£ng cÃ¡ch cÃº phÃ¡p nhá» hÆ¡n, Ä‘Æ°á»£c Ä‘o báº±ng sá»‘ cáº¡nh giá»¯a cÃ¡c nÃºt trong AST [69], vÃ  tÆ°Æ¡ng á»©ng, khoáº£ng cÃ¡ch nhá» hÆ¡n trong biá»ƒu diá»…n vector, nhÆ° khoáº£ng cÃ¡ch Euclidean Ä‘Æ°á»£c mÃ£ hÃ³a bá»Ÿi mÃ´ hÃ¬nh mÃ£. NÃ³i cÃ¡ch khÃ¡c, giáº£ Ä‘á»‹nh nÃ³i ráº±ng "cÃº phÃ¡p gáº§n hÆ¡n" dáº«n Ä‘áº¿n "khoáº£ng cÃ¡ch cáº¡nh nhá» hÆ¡n trong AST" mÃ  láº§n lÆ°á»£t dáº«n Ä‘áº¿n "khoáº£ng cÃ¡ch biá»ƒu diá»…n nhá» hÆ¡n." Tuy nhiÃªn, thá»© nháº¥t, "khoáº£ng cÃ¡ch cáº¡nh nhá» hÆ¡n trong AST" khÃ´ng nháº¥t thiáº¿t cÃ³ nghÄ©a lÃ  "cÃº phÃ¡p gáº§n". Thá»© hai, khÃ´ng gian biá»ƒu diá»…n vector mÃ£ lÃ  má»™t khÃ´ng gian chiá»u cao. VÃ­ dá»¥, CodeBERT táº¡o thÃ nh khÃ´ng gian 768 chiá»u nhÆ°ng khoáº£ng cÃ¡ch nÃºt trong AST lÃ  khÃ´ng gian chiá»u tháº¥p. Do Ä‘Ã³, cÃ¡c phÆ°Æ¡ng phÃ¡p khoáº£ng cÃ¡ch truyá»n thá»‘ng Ä‘Æ°á»£c sá»­ dá»¥ng trong nhá»¯ng cÃ´ng trÃ¬nh nÃ y sáº½ khÃ´ng hoáº¡t Ä‘á»™ng tá»‘t do lá»i nguyá»n cá»§a chiá»u cao [1,52]. Thá»© nháº¥t, Ã¡nh xáº¡ khoáº£ng cÃ¡ch tá»« khÃ´ng gian chiá»u cao sang khÃ´ng gian chiá»u tháº¥p cÃ³ thá»ƒ khÃ´ng chÃ­nh xÃ¡c, tá»©c lÃ  khoáº£ng cÃ¡ch nhá» hÆ¡n trong AST cÃ³ thá»ƒ khÃ´ng cháº¯c cháº¯n biá»ƒu diá»…n khoáº£ng cÃ¡ch euclidean nhá» hÆ¡n trong khÃ´ng gian chiá»u cao. Thá»© hai, khoáº£ng cÃ¡ch cáº¡nh nhá» giá»¯a hai nÃºt trong AST khÃ´ng Ä‘áº£m báº£o má»‘i quan há»‡ cÃº phÃ¡p gáº§n. Sá»± thiÃªn vá»‹ nÃ y cÃ³ thá»ƒ lÃ m cho káº¿t luáº­n vÃ  phÆ°Æ¡ng phÃ¡p cá»§a há» khÃ´ng Ä‘Æ°á»£c tá»•ng quÃ¡t hÃ³a vÃ  cÃ³ thá»ƒ cáº£n trá»Ÿ sá»± hiá»ƒu biáº¿t cá»§a chÃºng ta vá» cÃ¡ch cÃ¡c mÃ´ hÃ¬nh mÃ£

Â¹https://github.com/Marvinmw/probing_analysis_tosem.git

J. ACM, Vol. 37, No. 4, Article 111. NgÃ y xuáº¥t báº£n: ThÃ¡ng 8 2018.

--- TRANG 5 ---
KhÃ¡m PhÃ¡ CÃ¡c MÃ´ HÃ¬nh Tiá»n Huáº¥n Luyá»‡n MÃ£: NghiÃªn Cá»©u Kháº£ NÄƒng CÃº PhÃ¡p vÃ  Ngá»¯ NghÄ©a 111:5

[THIS IS FIGURE: Shows a code snippet and AST tree diagram labeled "HÃ m DefifreturnreturncompareModule>baabdef max (a ,b)#return maximum valuedefmax(a,b){if ( a > b ): returnaelse:returnb}AST"]

HÃ¬nh 1. Má»™t Ä‘oáº¡n mÃ£ Ä‘Æ¡n giáº£n vá»›i AST cá»§a nÃ³.

[THIS IS FIGURE: Shows distance measurements "85.45" and "65.78"]

HÃ¬nh 2. Khoáº£ng cÃ¡ch Euclidean cá»§a cÃ¡c biá»ƒu diá»…n token.

mÃ£ hÃ³a cÃº phÃ¡p. CÅ©ng nhÆ°, nÃ³ Æ°á»›c tÃ­nh sai sá»± tÆ°Æ¡ng tá»± cÃº phÃ¡p mÃ£ vÃ  cÃ³ thá»ƒ dáº«n Ä‘áº¿n thiáº¿u phÃ¢n tÃ­ch cáº¥u trÃºc cÃº phÃ¡p cho cÃ¡c mÃ´ hÃ¬nh mÃ£. Káº¿t luáº­n cÃ³ thá»ƒ khÃ´ng há»¯u Ã­ch Ä‘á»ƒ cáº£i thiá»‡n hiá»‡u suáº¥t mÃ´ hÃ¬nh. ChÃºng tÃ´i cung cáº¥p hai vÃ­ dá»¥ Ä‘á»ƒ minh há»a tá»‘t hÆ¡n.

HÃ¬nh 1 lÃ  vÃ­ dá»¥ Ä‘áº§u tiÃªn vÃ  cung cáº¥p má»™t hÃ¬nh áº£nh cá»§a má»™t hÃ m Ä‘Æ°á»£c phÃ¢n tÃ­ch thÃ nh AST. ChÃºng ta cÃ³ thá»ƒ tháº¥y ráº±ng khoáº£ng cÃ¡ch nÃºt giá»¯a biáº¿n "a" vÃ  "b" tá»« Ä‘iá»u kiá»‡n if (Ä‘Æ°á»£c Ä‘Ã¡nh dáº¥u trong hÃ¬nh vuÃ´ng mÃ u xanh lÃ¡ cÃ¢y) lÃ  2 hop trong khi khoáº£ng cÃ¡ch nÃºt giá»¯a biáº¿n "a" nÃ y (hÃ¬nh vuÃ´ng mÃ u xanh lÃ¡ cÃ¢y) vÃ  biáº¿n "a" (hÃ¬nh vuÃ´ng mÃ u cam) tá»« cÃ¢u lá»‡nh return lÃ  4 hop. Do Ä‘Ã³, chÃºng ta cÃ³ thá»ƒ tháº¥y ráº±ng trong khÃ´ng gian chiá»u tháº¥p, biáº¿n "a" tá»« Ä‘iá»u kiá»‡n if gáº§n vá»›i biáº¿n "b" vÃ  chÃºng gáº§n nhau vá» cÃº phÃ¡p hÆ¡n biáº¿n "a" tá»« cÃ¢u lá»‡nh return. Tuy nhiÃªn, káº¿t luáº­n ngÆ°á»£c láº¡i trong khÃ´ng gian chiá»u cao. ChÃºng tÃ´i mÃ£ hÃ³a hÃ m nÃ y báº±ng CodeBERT vÃ  tÃ­nh khoáº£ng cÃ¡ch euclidean giá»¯a cÃ¡c biá»ƒu diá»…n vector token cho nhá»¯ng biáº¿n nÃ y. NhÆ° Ä‘Æ°á»£c hiá»ƒn thá»‹ trong HÃ¬nh 2, chÃºng ta cÃ³ thá»ƒ tháº¥y ráº±ng khoáº£ng cÃ¡ch tá»« biáº¿n "a" (hÃ¬nh vuÃ´ng mÃ u xanh lÃ¡ cÃ¢y) Ä‘áº¿n biáº¿n "b" (hÃ¬nh vuÃ´ng mÃ u xanh lÃ¡ cÃ¢y) tá»« Ä‘iá»u kiá»‡n if lÃ  85.45 trong khi khoáº£ng cÃ¡ch tá»« nÃ³ Ä‘áº¿n biáº¿n "a" (hÃ¬nh vuÃ´ng mÃ u cam) tá»« cÃ¢u lá»‡nh return lÃ  65.78. Do Ä‘Ã³, thÃ´ng qua vÃ­ dá»¥ nÃ y, chÃºng tÃ´i tháº¥y ráº±ng cÃ¡c khoáº£ng cÃ¡ch trong khÃ´ng gian tháº¥p vÃ  khÃ´ng gian cao khÃ´ng nháº¥t quÃ¡n, vÃ  chÃºng cÃ³ thá»ƒ khÃ´ng cÃ³ má»‘i quan há»‡ tÃ­ch cá»±c.

Äá»‘i vá»›i vÃ­ dá»¥ khÃ¡c, HÃ¬nh 3 chá»©ng minh ráº±ng biáº¿n Ä‘á»‘i sá»‘ hÃ m "b" cÃ³ 4 hop Ä‘áº¿n "return" trong cÃ¢u lá»‡nh cuá»‘i cá»§a hÃ m nÃ y, vÃ  nÃ³ chia sáº» cÃ¹ng khoáº£ng cÃ¡ch vá»›i biáº¿n Ä‘á»‘i sá»‘ hÃ m "c". Tuy nhiÃªn, "b" nÃªn gáº§n hÆ¡n vá» cÃº phÃ¡p vá»›i "c" vÃ¬ chÃºng lÃ  cÃ¡c Ä‘á»‘i sá»‘ hÃ m.

J. ACM, Vol. 37, No. 4, Article 111. NgÃ y xuáº¥t báº£n: ThÃ¡ng 8 2018.

--- TRANG 6 ---
111:6 W. Ma, S. Liu vÃ  M. Zhao et al.

HÆ¡n ná»¯a, nhá»¯ng cÃ´ng trÃ¬nh nÃ y chá»§ yáº¿u táº­p trung vÃ o khÃ¡m phÃ¡ kháº£ nÄƒng cá»§a cÃ¡c mÃ´ hÃ¬nh tiá»n huáº¥n luyá»‡n mÃ£ trong viá»‡c há»c cÃº phÃ¡p mÃ£. CÃ¡c tháº£o luáº­n sÃ¢u sáº¯c vá» ngá»¯ nghÄ©a mÃ£ Ä‘Ã£ há»c (vÃ­ dá»¥: phÃ¢n tÃ­ch phá»¥ thuá»™c Ä‘iá»u khiá»ƒn/dá»¯ liá»‡u) bá»‹ thiáº¿u. Troshin vÃ  Chirkova [66] sá»­ dá»¥ng má»™t sá»‘ nhiá»‡m vá»¥ liÃªn quan Ä‘áº¿n ngá»¯ nghÄ©a trong khi chÃºng khÃ´ng chá»‰ liÃªn quan Ä‘áº¿n má»™t thuá»™c tÃ­nh mÃ£ duy nháº¥t thÆ°á»ng Ä‘Æ°á»£c yÃªu cáº§u bá»Ÿi phÃ¢n tÃ­ch thÄƒm dÃ², sá»± Ä‘a dáº¡ng cá»§a ngá»¯ nghÄ©a chÆ°Æ¡ng trÃ¬nh cÅ©ng bá»‹ bá» qua vÃ  thiáº¿u phÃ¢n tÃ­ch sÃ¢u. Tháº£o luáº­n vá» ngá»¯ nghÄ©a mÃ£ lÃ  má»™t pháº§n thiáº¿t yáº¿u vÃ  khÃ´ng thá»ƒ bá» qua vÃ¬ nÃ³ táº¡o thÃ nh ná»n táº£ng cho nhiá»u nhiá»‡m vá»¥ liÃªn quan Ä‘áº¿n mÃ£ [9, 36, 38, 39, 80]. Nhá»¯ng cÃ´ng trÃ¬nh nÃ y cÅ©ng thiáº¿u phÃ¢n tÃ­ch vá» LLM.

Äá»ƒ kháº¯c phá»¥c nhá»¯ng váº¥n Ä‘á» trÃªn, chÃºng ta cáº§n khÃ¡m phÃ¡ cÃ¡c phÆ°Æ¡ng phÃ¡p tá»‘t hÆ¡n mÃ  khÃ´ng cÃ³ giáº£ Ä‘á»‹nh ráº±ng sá»‘ cáº¡nh giá»¯a cÃ¡c nÃºt cÃ³ liÃªn quan Ä‘áº¿n cÃº phÃ¡p mÃ£. MÃ£ lÃ  má»™t cáº¥u trÃºc dá»¯ liá»‡u ráº¥t Ä‘áº·c biá»‡t. TrÆ°á»›c háº¿t, nÃ³ cÃ³ Ä‘á»‹nh nghÄ©a cÃº phÃ¡p nghiÃªm ngáº·t; táº¥t cáº£ mÃ£ pháº£i tuÃ¢n thá»§ nhá»¯ng quy táº¯c cÃº phÃ¡p nÃ y. Táº¥t cáº£ tÃªn Ä‘Æ°á»£c sá»­ dá»¥ng trong mÃ£ chá»‰ cáº§n tuÃ¢n theo cÃ¡c quy táº¯c Ä‘áº·t tÃªn cá»¥ thá»ƒ. Tuy nhiÃªn, Ä‘á»ƒ thuáº­n tiá»‡n cho viá»‡c Ä‘á»c cá»§a con ngÆ°á»i, con ngÆ°á»i thÆ°á»ng chÃº thÃ­ch mÃ£ báº±ng tÃªn Ä‘á»ƒ dá»… Ä‘á»c vÃ  hiá»ƒu. Nhá»¯ng quy táº¯c cÃº phÃ¡p nÃ y cÃ³ thá»ƒ Ä‘Æ°á»£c biá»ƒu Ä‘áº¡t má»™t cÃ¡ch cÃ³ cáº¥u trÃºc bá»Ÿi cÃ¢y cÃº phÃ¡p trá»«u tÆ°á»£ng (AST). Dá»±a trÃªn nhá»¯ng quy táº¯c cÃº phÃ¡p Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh nÃ y, mÃ£ cÅ©ng biá»ƒu Ä‘áº¡t thÃ´ng tin ngá»¯ nghÄ©a sÃ¢u sáº¯c hÆ¡n. MÃ£ cÃ³ chá»©c nÄƒng nháº¥t Ä‘á»‹nh, cÃ³ thá»ƒ thá»±c thi Ä‘Æ°á»£c vÃ  thá»±c hiá»‡n logic cá»¥ thá»ƒ. ThÃ´ng tin ngá»¯ nghÄ©a nÃ y bao gá»“m luá»“ng Ä‘iá»u khiá»ƒn, luá»“ng dá»¯ liá»‡u vÃ  cÃ¡c phá»¥ thuá»™c. Háº§u nhÆ° táº¥t cáº£ cÃ¡c váº¥n Ä‘á» liÃªn quan Ä‘áº¿n mÃ£ Ä‘á»u yÃªu cáº§u thÃ´ng tin nÃ y Ä‘á»ƒ giáº£i quyáº¿t. Luá»“ng Ä‘iá»u khiá»ƒn mÃ´ táº£ logic cá»¥ thá»ƒ cá»§a mÃ£, biá»ƒu Ä‘áº¡t chá»©c nÄƒng Ä‘Æ°á»£c thá»±c hiá»‡n bá»Ÿi mÃ£. Luá»“ng dá»¯ liá»‡u vÃ  cÃ¡c phá»¥ thuá»™c biá»ƒu Ä‘áº¡t má»‘i liÃªn káº¿t ngá»¯ nghÄ©a giá»¯a cÃ¡c pháº§n khÃ¡c nhau cá»§a mÃ£. ChÃºng ráº¥t quan trá»ng cho cháº¥t lÆ°á»£ng mÃ£, vÃ  phÃ¡t hiá»‡n vÃ  sá»­a chá»¯a lá»— há»•ng khuyáº¿t Ä‘iá»ƒm. ChÃºng ta cÃ³ thá»ƒ tháº¥y ráº±ng AST, Äá»“ thá»‹ Luá»“ng Äiá»u khiá»ƒn (CFG), Äá»“ thá»‹ Phá»¥ thuá»™c Äiá»u khiá»ƒn (CDG), vÃ  Äá»“ thá»‹ Phá»¥ thuá»™c Dá»¯ liá»‡u (DDG) lÃ  cÃ¡c biá»ƒu Ä‘áº¡t cÃ³ cáº¥u trÃºc cá»§a cÃº phÃ¡p vÃ  ngá»¯ nghÄ©a mÃ£. CÃ¡c token mÃ£ cÃ³ cÃ¡c má»‘i quan há»‡ hoáº·c thuá»™c tÃ­nh cÃº phÃ¡p vÃ  ngá»¯ nghÄ©a khÃ¡c nhau dá»±a trÃªn nhá»¯ng cáº¥u trÃºc nÃ y. Nhá»¯ng má»‘i quan há»‡ vÃ  thuá»™c tÃ­nh nÃ y quan trá»ng Ä‘á»ƒ hiá»ƒu mÃ£ vÃ  nÃªn Ä‘Æ°á»£c biá»ƒu diá»…n trong khÃ´ng gian vector Ä‘Ã£ há»c cá»§a cÃ¡c mÃ´ hÃ¬nh mÃ£. Kháº£ nÄƒng cá»§a má»™t mÃ´ hÃ¬nh mÃ£ lÃ  Ã¡nh xáº¡ cÃ¡c Ä‘áº·c Ä‘iá»ƒm cá»§a mÃ£ vÃ o khÃ´ng gian vector. Äá»‘i vá»›i má»™t mÃ´ hÃ¬nh mÃ£ tá»‘t, khÃ´ng gian Ä‘áº·c trÆ°ng cá»§a nÃ³ nÃªn giá»¯ táº¥t cáº£ cÃ¡c Ä‘áº·c Ä‘iá»ƒm cá»§a mÃ£ cÃ ng nhiá»u cÃ ng tá»‘t. CÃ¡c nhiá»‡m vá»¥ thÄƒm dÃ² mÃ  chÃºng tÃ´i thiáº¿t káº¿ lÃ  Ä‘á»ƒ tÃ¡i táº¡o nhá»¯ng má»‘i quan há»‡ cáº¥u trÃºc dá»¯ liá»‡u nÃ y trong khÃ´ng gian Ä‘áº·c trÆ°ng vector.

Do Ä‘Ã³, Ä‘á»ƒ phÃ¢n tÃ­ch cÃº phÃ¡p, chÃºng tÃ´i cá»‘ gáº¯ng tÃ¡i táº¡o AST (dá»± Ä‘oÃ¡n cáº·p nÃºt cÃº phÃ¡p) vÃ  dá»± Ä‘oÃ¡n nhÃ£n cÃº phÃ¡p cá»§a cÃ¡c token mÃ£ (gáº¯n tháº» cÃº phÃ¡p token). AST mang táº¥t cáº£ thÃ´ng tin cÃº phÃ¡p cá»§a mÃ£. Dá»± Ä‘oÃ¡n cáº·p nÃºt cÃº phÃ¡p cÃ³ thá»ƒ pháº£n Ã¡nh cÃ¡ch cÃ¡c mÃ´ hÃ¬nh mÃ£ há»c cáº¥u trÃºc cÃº phÃ¡p báº±ng cÃ¡ch tÃ¡i táº¡o AST trong khÃ´ng gian biá»ƒu diá»…n. Gáº¯n tháº» cÃº phÃ¡p token lÃ  Ä‘á»ƒ xem liá»‡u vai trÃ² cÃº phÃ¡p cá»§a má»—i token cÃ³ Ä‘Æ°á»£c mÃ£ hÃ³a trong biá»ƒu diá»…n hay khÃ´ng, Ä‘Ã¢y lÃ  má»™t thuá»™c tÃ­nh cÃº phÃ¡p vi mÃ´. Cáº£ hai Ä‘á»u quan trá»ng Ä‘á»ƒ cÃ¡c mÃ´ hÃ¬nh mÃ£ há»c cÃº phÃ¡p mÃ£. Äá»ƒ phÃ¢n tÃ­ch ngá»¯ nghÄ©a, chÃºng tÃ´i tÃ¡i táº¡o cáº¥u trÃºc ngá»¯ nghÄ©a mÃ£ (dá»± Ä‘oÃ¡n lan truyá»n ngá»¯ nghÄ©a) bao gá»“m Ä‘á»“ thá»‹ phá»¥ thuá»™c Ä‘iá»u khiá»ƒn (CDG), Ä‘á»“ thá»‹ phá»¥ thuá»™c dá»¯ liá»‡u (DDG) vÃ  Ä‘á»“ thá»‹ luá»“ng Ä‘iá»u khiá»ƒn (CFG). ChÃºng tÃ´i cÅ©ng bao gá»“m phá»¥ thuá»™c Ä‘iá»u khiá»ƒn vÃ  dá»¯ liá»‡u vá»›i khoáº£ng cÃ¡ch dÃ i (dá»± Ä‘oÃ¡n lan truyá»n ngá»¯ nghÄ©a). Ba cáº¥u trÃºc ngá»¯ nghÄ©a, CDG, DDG vÃ  CFG, lÃ  cÃ¡c khÃ¡i niá»‡m cá»‘t lÃµi trong phÃ¢n tÃ­ch chÆ°Æ¡ng trÃ¬nh, tá»‘i Æ°u hÃ³a, thanh cÃ´ng cá»¥ vÃ  nhiá»u nhiá»‡m vá»¥ ká»¹ thuáº­t pháº§n má»m khÃ¡c. Phá»¥ thuá»™c dÃ i lÃ  má»™t Ä‘áº·c Ä‘iá»ƒm Ä‘áº·c biá»‡t cá»§a chÆ°Æ¡ng trÃ¬nh. Má»™t ngÆ°á»i cÃ³ thá»ƒ khai bÃ¡o má»™t biáº¿n á»Ÿ Ä‘áº§u nhÆ°ng sá»­ dá»¥ng nÃ³ sau hÃ ng trÄƒm dÃ²ng. Hiá»ƒu chÃºng quan trá»ng Ä‘á»‘i vá»›i cÃ¡c mÃ´ hÃ¬nh mÃ£. Chi tiáº¿t cÃ³ thá»ƒ Ä‘Æ°á»£c tÃ¬m tháº¥y trong Pháº§n 3.

3 PHÆ¯Æ NG PHÃP LUáº¬N

Trong pháº§n nÃ y, chÃºng tÃ´i giá»›i thiá»‡u phÃ¢n tÃ­ch cá»§a chÃºng tÃ´i vá» cÃ¡c phÆ°Æ¡ng phÃ¡p thÄƒm dÃ² cho cÃº phÃ¡p vÃ  ngá»¯ nghÄ©a mÃ£.

3.1 Kiáº¿n Thá»©c SÆ¡ Bá»™

CÃ¡c nhÃ  nghiÃªn cá»©u ká»¹ thuáº­t pháº§n má»m thá»i ká»³ Ä‘áº§u Ä‘Ã£ sá»­ dá»¥ng ká»¹ thuáº­t Ä‘áº·c trÆ°ng dá»±a trÃªn kiáº¿n thá»©c thá»±c nghiá»‡m cá»§a chuyÃªn gia Ä‘á»ƒ trÃ­ch xuáº¥t cÃ¡c Ä‘áº·c trÆ°ng mÃ£ lÃ m Ä‘áº§u vÃ o cho cÃ¡c thuáº­t toÃ¡n há»c mÃ¡y. ThÃ´ng thÆ°á»ng, cÃ¡c chuyÃªn gia thiáº¿t káº¿ cÃ¡c quy táº¯c trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng dá»±a trÃªn cÃ¡c nhiá»‡m vá»¥ cá»¥ thá»ƒ cáº§n giáº£i quyáº¿t, nhÆ° sá»‘ lÆ°á»£ng vÃ²ng láº·p vÃ 

J. ACM, Vol. 37, No. 4, Article 111. NgÃ y xuáº¥t báº£n: ThÃ¡ng 8 2018.

--- TRANG 7 ---
KhÃ¡m PhÃ¡ CÃ¡c MÃ´ HÃ¬nh Tiá»n Huáº¥n Luyá»‡n MÃ£: NghiÃªn Cá»©u Kháº£ NÄƒng CÃº PhÃ¡p vÃ  Ngá»¯ NghÄ©a 111:7

Ä‘á»™ phá»©c táº¡p mÃ£. Nhá»¯ng Ä‘áº·c trÆ°ng dá»±a trÃªn quy táº¯c nÃ y cÃ³ tÃ­nh diá»…n giáº£i cao nhÆ°ng bá»‹ háº¡n cháº¿ bá»Ÿi kinh nghiá»‡m cá»§a cÃ¡c chuyÃªn gia vÃ  khÃ´ng thá»ƒ bao quÃ¡t cáº¥u trÃºc cÃº phÃ¡p vÃ  ngá»¯ nghÄ©a mÃ£. Trong nhá»¯ng nÄƒm gáº§n Ä‘Ã¢y, vá»›i sá»± trá»—i dáº­y cá»§a Transformer vÃ  sá»± xuáº¥t hiá»‡n cá»§a CodeBERT, cÃ¡c nhÃ  nghiÃªn cá»©u ká»¹ thuáº­t pháº§n má»m cÃ³ thá»ƒ trÃ­ch xuáº¥t cÃ¡c Ä‘áº·c trÆ°ng mÃ£ dá»±a trÃªn kháº£ nÄƒng mÃ£ hÃ³a cá»§a cÃ¡c mÃ´ hÃ¬nh tiá»n huáº¥n luyá»‡n, giáº£m Ä‘Ã¡ng ká»ƒ sá»± phá»¥ thuá»™c vÃ o kinh nghiá»‡m vÃ  kiáº¿n thá»©c chuyÃªn gia. Transformer vá»›i kiáº¿n trÃºc mÃ£ hÃ³a-giáº£i mÃ£ Ä‘Æ°á»£c Ä‘á» xuáº¥t vÃ o nÄƒm 2017 [68]. Bá»™ mÃ£ hÃ³a vÃ  bá»™ giáº£i mÃ£ Ä‘Æ°á»£c xáº¿p chá»“ng bá»Ÿi nhiá»u táº§ng mÃ£ hÃ³a vÃ  giáº£i mÃ£ tÆ°Æ¡ng á»©ng. Cáº£ hai Ä‘á»u chá»©a cÃ¡c cÆ¡ cháº¿ tÃ­nh toÃ¡n vÃ  phÃ¢n bá»• chÃº Ã½ phá»©c táº¡p. Sá»± khÃ¡c biá»‡t giá»¯a táº§ng mÃ£ hÃ³a vÃ  táº§ng giáº£i mÃ£ lÃ  táº§ng mÃ£ hÃ³a xem xÃ©t bá»‘i cáº£nh cá»§a mÃ´ hÃ¬nh; táº§ng giáº£i mÃ£ chá»‰ xem xÃ©t bá»‘i cáº£nh Ä‘áº§u ra cá»§a mÃ´ hÃ¬nh. CÃ¡c mÃ´ hÃ¬nh mÃ£ tiá»n huáº¥n luyá»‡n sáº½ sá»­ dá»¥ng dá»¯ liá»‡u mÃ£ khá»•ng lá»“ Ä‘Æ°á»£c thu tháº­p tá»« Internet nhÆ° GitHub vÃ  Stack Overflow. CÃ¡c mÃ´ hÃ¬nh mÃ£ tiá»n huáº¥n luyá»‡n cÃ³ thá»ƒ Ä‘Æ°á»£c nhÃ³m thÃ nh ba nhÃ³m vá» kiáº¿n trÃºc máº¡ng cá»§a chÃºng. NhÃ³m Ä‘áº§u tiÃªn sá»­ dá»¥ng bá»™ mÃ£ hÃ³a transformer nhÆ° CodeBERT. NhÃ³m thá»© hai sá»­ dá»¥ng bá»™ giáº£i mÃ£ transformer nhÆ° CodeGPT. NhÃ³m thá»© ba sá»­ dá»¥ng bá»™ mÃ£ hÃ³a-giáº£i mÃ£ transformer nhÆ° CodeT5.

TrÆ°á»›c khi tiá»n huáº¥n luyá»‡n, chÃºng ta cáº§n huáº¥n luyá»‡n má»™t tokenizer dá»±a trÃªn vÄƒn báº£n mÃ£ Ä‘á»ƒ há»c cÃ¡ch phÃ¢n Ä‘oáº¡n vÄƒn báº£n mÃ£, nhÆ° thuáº­t toÃ¡n tokenization Byte-Pair Encoding (BPE)Â². Khi sá»­ dá»¥ng Transformer Ä‘á»ƒ há»c Ä‘áº·c trÆ°ng, mÃ£ vÄƒn báº£n gá»‘c sáº½ Ä‘Æ°á»£c tokenize vÃ  chÃºng ta sáº½ nháº­n Ä‘Æ°á»£c má»™t chuá»—i cÃ¡c token mÃ£. Sau Ä‘Ã³, chÃºng ta chuyá»ƒn Ä‘á»•i nÃ³ thÃ nh chá»‰ sá»‘ tÆ°Æ¡ng á»©ng trong táº§ng nhÃºng. Äiá»u nÃ y hoÃ n thÃ nh viá»‡c chuyá»ƒn Ä‘á»•i tá»« mÃ£ thÃ´ sang vector. MÃ´ hÃ¬nh sau Ä‘Ã³ Ä‘Æ°á»£c tá»‘i Æ°u hÃ³a dá»±a trÃªn mÃ´ hÃ¬nh huáº¥n luyá»‡n Ä‘Æ°á»£c thá»±c hiá»‡n. So vá»›i cÃ¡c mÃ´ hÃ¬nh tiá»n huáº¥n luyá»‡n truyá»n thá»‘ng, LLM cÅ©ng lÃ  kiáº¿n trÃºc transformer nhÆ°ng cÃ³ sá»‘ lÆ°á»£ng tham sá»‘ khá»•ng lá»“ vÃ  lÆ°á»£ng dá»¯ liá»‡u huáº¥n luyá»‡n khá»•ng lá»“. LLM Ä‘Æ°á»£c Ä‘iá»u chá»‰nh theo sá»Ÿ thÃ­ch cá»§a con ngÆ°á»i. VÃ¬ viá»‡c tinh chá»‰nh toÃ n bá»™ tham sá»‘ cá»§a LLM ráº¥t tá»‘n kÃ©m, chÃºng ta thÆ°á»ng sá»­ dá»¥ng LoRA [22], há»c few-shot vÃ  tinh chá»‰nh prompt Ä‘á»ƒ giáº£i quyáº¿t cÃ¡c nhiá»‡m vá»¥ downstream. Má»™t sá»‘ nghiÃªn cá»©u cho tháº¥y ráº±ng nÃ³ cÃ³ kháº£ nÄƒng ná»•i báº­t vÃ  tá»•ng quÃ¡t hÃ³a [72]. CÃ¡c nhÃ  nghiÃªn cá»©u trong ká»¹ thuáº­t pháº§n má»m Ä‘Ã£ phÃ¡t hiá»‡n ráº±ng cÃ¡c mÃ´ hÃ¬nh lá»›n cÃ³ kháº£ nÄƒng táº¡o vÃ  phÃ¢n tÃ­ch mÃ£ tá»‘t [10, 11, 76].

CÃ¡c phÆ°Æ¡ng phÃ¡p trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng dá»±a trÃªn mÃ´ hÃ¬nh mÃ£ cÃ³ má»™t tiá»n Ä‘á»: cÃ¡c Ä‘áº·c trÆ°ng cáº¥u trÃºc cá»§a mÃ£ Ä‘Æ°á»£c bao gá»“m trong khÃ´ng gian Ä‘áº·c trÆ°ng cá»§a mÃ´ hÃ¬nh mÃ£. CÃ¡c mÃ´ hÃ¬nh mÃ£ huáº¥n luyá»‡n chÃ­nh hiá»‡n táº¡i dá»±a trÃªn mÃ´ hÃ¬nh ngÃ´n ngá»¯ cÃ³ máº·t náº¡ (MLM), mÃ´ hÃ¬nh ngÃ´n ngá»¯ nhÃ¢n quáº£ (CLM) vÃ  cÃ¡c biáº¿n thá»ƒ khÃ¡c cá»§a hai mÃ´ hÃ¬nh trÆ°á»›c. NÃ³i Ä‘Æ¡n giáº£n, MLM cÃ³ nghÄ©a lÃ  che giáº¥u ngáº«u nhiÃªn cÃ¡c token mÃ£ vÃ  sau Ä‘Ã³ khÃ´i phá»¥c chÃºng. Sá»± khÃ¡c biá»‡t lÃ  CLM dá»± Ä‘oÃ¡n token tiáº¿p theo dá»±a trÃªn nhá»¯ng token á»Ÿ trÃªn. Nhá»¯ng phÆ°Æ¡ng phÃ¡p tiá»n huáº¥n luyá»‡n nÃ y khÃ´ng Ä‘Æ°á»£c Ä‘iá»u chá»‰nh Ä‘á»ƒ há»c cÃ¡c Ä‘áº·c trÆ°ng mÃ£. Trong háº§u háº¿t cÃ¡c trÆ°á»ng há»£p, chÃºng ta chuyá»ƒn Ä‘á»•i mÃ£ thÃ nh Ä‘á»‹nh dáº¡ng vÄƒn báº£n mÃ  chÃºng yÃªu cáº§u. Viá»‡c phÃ¢n tÃ­ch vÃ  hiá»ƒu khÃ´ng gian Ä‘áº·c trÆ°ng cá»§a cÃ¡c mÃ´ hÃ¬nh mÃ£ lÃ  má»™t thÃ¡ch thá»©c.

3.2 MÃ´ HÃ¬nh PhÃ¢n TÃ­ch ThÄƒm DÃ²

PhÃ¢n tÃ­ch thÄƒm dÃ² lÃ  má»™t phÆ°Æ¡ng phÃ¡p nghiÃªn cá»©u Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ hiá»ƒu vÃ  Ä‘Ã¡nh giÃ¡ kiáº¿n thá»©c vÃ  thÃ´ng tin mÃ£ hÃ³a trong cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯. PhÆ°Æ¡ng phÃ¡p phÃ¢n tÃ­ch nÃ y tiáº¿t lá»™ sá»± thÃ nh tháº¡o cá»§a mÃ´ hÃ¬nh Ä‘á»‘i vá»›i cÃ¡c loáº¡i thÃ´ng tin ngÃ´n ngá»¯ cá»¥ thá»ƒ trong quÃ¡ trÃ¬nh há»c cá»§a nÃ³ báº±ng cÃ¡ch thiáº¿t káº¿ vÃ  Ã¡p dá»¥ng má»™t loáº¡t cÃ¡c nhiá»‡m vá»¥ thÄƒm dÃ². CÃ¡c nhiá»‡m vá»¥ thÄƒm dÃ² thÆ°á»ng lÃ  nhá»¯ng nhiá»‡m vá»¥ Ä‘Æ¡n giáº£n, cÃ³ má»¥c tiÃªu Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘áº·c biá»‡t Ä‘á»ƒ kiá»ƒm tra hiá»ƒu biáº¿t cá»§a mÃ´ hÃ¬nh vá» má»™t thuá»™c tÃ­nh ngÃ´n ngá»¯ cá»¥ thá»ƒ, nhÆ° cáº¥u trÃºc ngá»¯ phÃ¡p, Ã½ nghÄ©a tá»« vÃ  má»‘i quan há»‡ cÃ¢u. Trong nghiÃªn cá»©u cá»§a chÃºng tÃ´i, Ä‘á»‘i vá»›i táº¥t cáº£ cÃ¡c nhiá»‡m vá»¥ thÄƒm dÃ² Ä‘Æ°á»£c thiáº¿t káº¿, chÃºng tÃ´i sá»­ dá»¥ng bá»™ phÃ¢n loáº¡i thÄƒm dÃ² cáº¡nh [64] nhÆ° Ä‘Æ°á»£c mÃ´ táº£ trong HÃ¬nh 4. PhÃ¹ há»£p vá»›i cÃ¡c cÃ´ng trÃ¬nh trÆ°á»›c Ä‘Ã¢y [6,55,64,67] trong tÃ i liá»‡u thÄƒm dÃ², chÃºng tÃ´i giá»¯ cÃ¡c tham sá»‘ cá»§a mÃ´ hÃ¬nh mÃ£ tiá»n huáº¥n luyá»‡n cá»‘ Ä‘á»‹nh, cÃ³ nghÄ©a lÃ  chÃºng sáº½ khÃ´ng Ä‘Æ°á»£c cáº­p nháº­t trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n. Äá»‘i vá»›i má»™t Ä‘áº§u vÃ o mÃ£ Ä‘Ã£ cho ğ‘¥, chÃºng tÃ´i sá»­ dá»¥ng tokenizer Ä‘á»ƒ tokenize ğ‘¥ thÃ nh má»™t chuá»—i token vá»›i hai token báº¯t Ä‘áº§u vÃ  káº¿t thÃºc Ä‘áº·c biá»‡t nhÆ° Ä‘Æ°á»£c biá»ƒu thá»‹ á»Ÿ dÆ°á»›i cÃ¹ng cá»§a HÃ¬nh 4.

Â²https://huggingface.co/learn/nlp-course/en/chapter6/5

J. ACM, Vol. 37, No. 4, Article 111. NgÃ y xuáº¥t báº£n: ThÃ¡ng 8 2018.

--- TRANG 8 ---
111:8 W. Ma, S. Liu vÃ  M. Zhao et al.

[THIS IS FIGURE: Diagram showing syntax tree with nodes and relationships labeled "comvaraintc+bassignc>b=mulvaraintb*bifassignadd=returnareturnafuncargsintf(int b, int c){int a = b + c;if ( b > c ):{int a = b * b;return a;} return a;}ASTargbintargcint"]

HÃ¬nh 3. Dá»± ÄoÃ¡n Cáº·p NÃºt CÃº PhÃ¡p.

[THIS IS FIGURE: Flow diagram showing model architecture with components like "ğ¶ğ¿ğ‘†ğ‘¥!ğ‘¥"ğ‘¥"#!ğ‘¥$ğ‘¥$#!ğ‘¥%ğ¸ğ‘ğ·", "Input tokens", "Contextual Representation", "Attention Pooling", "MLP", "Span Representation", "Probing Classifier"]

HÃ¬nh 4. MÃ´ hÃ¬nh phÃ¢n tÃ­ch.

Ban Ä‘áº§u, chÃºng ta cÃ³ thá»ƒ thu Ä‘Æ°á»£c biá»ƒu diá»…n bá»‘i cáº£nh ğ‘Ÿğ‘– cá»§a má»—i táº§ng áº©n cho má»—i token ğ‘¥ğ‘– tá»« cÃ¡c mÃ´ hÃ¬nh mÃ£. Tiáº¿p theo, chÃºng tÃ´i trÃ­ch xuáº¥t cÃ¡c Ä‘oáº¡n token mÃ£ cá»¥ thá»ƒ cÃ³ liÃªn quan Ä‘áº¿n nÃºt Ä‘á»“ thá»‹ hoáº·c cÃ¢y mÃ  chÃºng tÃ´i quan tÃ¢m, vÃ  chÃºng Ä‘Æ°á»£c biá»ƒu thá»‹ lÃ  ğ‘ 1 vÃ  ğ‘ 2 trong HÃ¬nh 4. Má»™t Ä‘oáº¡n token mÃ£ Ä‘áº¡i diá»‡n cho má»™t pháº§n mÃ£ tá»« má»™t nÃºt trong AST hoáº·c Ä‘á»“ thá»‹ phá»¥ thuá»™c. Äá»™ dÃ i cá»§a má»™t Ä‘oáº¡n token khÃ¡c nhau vÃ  cÃ³ thá»ƒ chá»©a sá»‘ lÆ°á»£ng token khÃ¡c nhau. Sau Ä‘Ã³, nhá»¯ng Ä‘oáº¡n token nÃ y Ä‘Æ°á»£c truyá»n qua má»™t attention pool, Ã¡nh xáº¡ chÃºng thÃ nh má»™t vector cÃ³ kÃ­ch thÆ°á»›c cá»‘ Ä‘á»‹nh. Attention pool lÃ  má»™t táº§ng chÃº Ã½ cÃ³ thá»ƒ tá»± Ä‘á»™ng gÃ¡n trá»ng sá»‘ khÃ¡c nhau cho má»—i biá»ƒu diá»…n token trong Ä‘oáº¡n token, vÃ  sau Ä‘Ã³ tá»•ng há»£p chÃºng. Cuá»‘i cÃ¹ng, vector káº¿t quáº£ Ä‘Æ°á»£c chuyá»ƒn tiáº¿p Ä‘áº¿n bá»™ phÃ¢n loáº¡i thÄƒm dÃ², Ä‘Æ°á»£c thá»±c hiá»‡n nhÆ° má»™t bá»™ phÃ¢n loáº¡i perceptron Ä‘a táº§ng (MLP) cho phÃ¢n loáº¡i. Bá»™ phÃ¢n loáº¡i MLP cÃ³ thá»ƒ huáº¥n luyá»‡n Ä‘Æ°á»£c vÃ  Ä‘Æ°á»£c biá»ƒu thá»‹ báº±ng kÃ½ hiá»‡u ğ¶. CÃ¡c vector Ä‘áº·c trÆ°ng cÃ³ kÃ­ch thÆ°á»›c cá»‘ Ä‘á»‹nh cá»§a hai Ä‘oáº¡n token Ä‘Ã³ng vai trÃ² lÃ m Ä‘áº§u vÃ o cho ğ¶, vÃ  bá»™ phÃ¢n loáº¡i xÃ¡c Ä‘á»‹nh liá»‡u hai Ä‘oáº¡n token cÃ³ má»‘i quan há»‡ cÃº phÃ¡p hoáº·c ngá»¯ nghÄ©a hay khÃ´ng. ChÃºng tÃ´i sá»­ dá»¥ng cÃ¡c Ä‘oáº¡n token vÃ¬ cÃ¡c pháº§n mÃ£ cÃ³ liÃªn quan vá» máº·t cÃº phÃ¡p hoáº·c ngá»¯ nghÄ©a Ä‘Æ°á»£c tokenize thÃ nh hai danh sÃ¡ch token cÃ³ Ä‘á»™ dÃ i khÃ¡c nhau tÆ°Æ¡ng á»©ng. Nhá»¯ng danh sÃ¡ch token nÃ y Ä‘Æ°á»£c gá»i lÃ  cÃ¡c Ä‘oáº¡n token, sau Ä‘Ã³ Ä‘Æ°á»£c chuyá»ƒn Ä‘á»•i thÃ nh vector cÃ³ kÃ­ch thÆ°á»›c cá»‘ Ä‘á»‹nh bá»Ÿi attention pool.

3.3 ThÄƒm DÃ² CÃº PhÃ¡p

Äá»ƒ giáº£i quyáº¿t nhá»¯ng sá»± khÃ´ng chÃ­nh xÃ¡c cÃ³ thá»ƒ xáº£y ra tá»« viá»‡c chuyá»ƒn Ä‘á»•i khÃ´ng gian chiá»u cao sang khÃ´ng gian chiá»u tháº¥p, cÅ©ng nhÆ° thiáº¿u má»‘i quan há»‡ cÃ³ thá»ƒ cÃ³ giá»¯a khoáº£ng cÃ¡ch trong AST vÃ  khoáº£ng cÃ¡ch cÃº phÃ¡p nhÆ° Ä‘Æ°á»£c chá»‰ ra trong pháº§n Ä‘á»™ng lá»±c, chÃºng tÃ´i giá»›i thiá»‡u hai nhiá»‡m vá»¥ thÄƒm dÃ² cÃº phÃ¡p: dá»± Ä‘oÃ¡n cáº·p-nÃºt-cÃº phÃ¡p vÃ  gáº¯n tháº»-cÃº phÃ¡p-token. Nhá»¯ng nhiá»‡m vá»¥ nÃ y trá»±c tiáº¿p dá»± Ä‘oÃ¡n cÃ¡c thuá»™c tÃ­nh cá»§a cÃ¡c nÃºt trong AST. Hai nhiá»‡m vá»¥ bá»• sung cho nhau. Nhiá»‡m vá»¥ Ä‘áº§u tiÃªn nháº±m dá»± Ä‘oÃ¡n má»‘i quan há»‡ káº¿t ná»‘i-cÃº phÃ¡p giá»¯a cÃ¡c token mÃ£, trong khi nhiá»‡m vá»¥ thá»© hai táº­p trung vÃ o xem xÃ©t vai trÃ² cÃº phÃ¡p cá»§a cÃ¡c token mÃ£ riÃªng láº». CÃ¡c token mÃ£ lÃ  nhá»¯ng tá»« mÃ£ cÆ¡ báº£n sau khi mÃ£ Ä‘Æ°á»£c tokenize vÃ  má»—i nÃºt chá»©a Ã­t token mÃ£. ThÃ´ng qua nhiá»‡m vá»¥ Ä‘áº§u tiÃªn, chÃºng ta cÃ³ thá»ƒ tÃ¡i táº¡o AST cho biá»ƒu diá»…n token mÃ£ tá»« cÃ¡c mÃ´ hÃ¬nh mÃ£. Náº¿u cÃ¡c biá»ƒu diá»…n token mÃ£ khÃ´ng chá»©a thÃ´ng tin vá» cáº¥u trÃºc AST, viá»‡c tÃ¡i táº¡o AST lÃ  khÃ´ng thá»ƒ. ThÃ´ng qua nhiá»‡m vá»¥ thá»© hai, chÃºng ta cÃ³ thá»ƒ tÃ¬m ra liá»‡u cÃ¡c biá»ƒu diá»…n token mÃ£ cÃ³ chá»©a cÃ¡c quy táº¯c cÃº phÃ¡p tÆ°Æ¡ng á»©ng Ä‘Æ°á»£c gÃ¡n bá»Ÿi quy táº¯c ngÃ´n ngá»¯ láº­p trÃ¬nh hay khÃ´ng.

3.3.1 Dá»± ÄoÃ¡n Cáº·p NÃºt CÃº PhÃ¡p. Cho má»™t mÃ£ nguá»“n, chÃºng ta cÃ³ thá»ƒ phÃ¢n tÃ­ch nÃ³ Ä‘á»ƒ thu Ä‘Æ°á»£c AST vÃ  tiáº¿p tá»¥c chia AST nÃ y thÃ nh cÃ¡c cÃ¢y con khÃ¡c nhau. Má»—i cÃ¢y con lÃ  má»™t biá»ƒu thá»©c cÃº phÃ¡p tá»« mÃ£ gá»‘c vÃ  chÃºng tÃ´i Ä‘áº·t tÃªn nÃ³ lÃ  má»™t Ä‘Æ¡n vá»‹ cÃº phÃ¡p. Bá»Ÿi vÃ¬ má»—i Ä‘Æ¡n vá»‹ cÃº phÃ¡p Ä‘áº¡i diá»‡n cho má»™t biá»ƒu thá»©c cÃº phÃ¡p hoÃ n chá»‰nh tá»« mÃ£, do Ä‘Ã³ cÃ¡c nÃºt trong má»™t Ä‘Æ¡n vá»‹ cÃ³ cÃº phÃ¡p-gáº§n. Nhiá»‡m vá»¥ nÃ y Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ dá»± Ä‘oÃ¡n báº¥t ká»³ cáº·p nÃºt nÃ o trong AST thuá»™c vá» má»™t cÃ¢y con. AST Ä‘Æ°á»£c táº¡o bá»Ÿi bá»™ phÃ¢n tÃ­ch cÃº phÃ¡p vÃ  chá»©a táº¥t cáº£ thÃ´ng tin cÃº phÃ¡p cá»§a mÃ£. Äá»‘i vá»›i cÃ¡c mÃ´ hÃ¬nh mÃ£, chÃºng nÃªn giá»¯ láº¡i cáº¥u trÃºc cÃº phÃ¡p nhÆ° váº­y trong khÃ´ng gian vector. Náº¿u chÃºng khÃ´ng thá»ƒ, Ä‘iá»u Ä‘Ã³ cho tháº¥y ráº±ng mÃ´ hÃ¬nh khÃ´ng cÃ³ kháº£ nÄƒng mÃ£ hÃ³a cÃº phÃ¡p mÃ£ má»™t cÃ¡ch hiá»‡u quáº£. ThÃ´ng qua nhiá»‡m vá»¥ nÃ y, chÃºng tÃ´i nháº±m xÃ¡c minh liá»‡u mÃ´ hÃ¬nh mÃ£ cÃ³ thá»ƒ náº¯m báº¯t vÃ  hiá»ƒu cáº¥u trÃºc cÃº phÃ¡p nÃ y tá»« mÃ£ nguá»“n hay khÃ´ng, vÃ  sau Ä‘Ã³ tÃ¡i táº¡o thÃ´ng tin cÃº phÃ¡p trong khÃ´ng gian vector mÃ  nÃ³ Ä‘áº¡i diá»‡n. Cá»¥ thá»ƒ, chÃºng tÃ´i trÃ¬nh bÃ y má»™t vÃ­ dá»¥ Ä‘á»ƒ minh há»a tá»‘t hÆ¡n. NhÆ° Ä‘Æ°á»£c hiá»ƒn thá»‹ trong HÃ¬nh 3, cÃ³ má»™t hÃ m cÃ³ AST tÆ°Æ¡ng á»©ng Ä‘Æ°á»£c trÃ¬nh bÃ y bÃªn pháº£i. Äá»‘i vá»›i AST nÃ y, chÃºng tÃ´i chia nÃ³ thÃ nh cÃ¡c Ä‘Æ¡n vá»‹ khÃ¡c nhau Ä‘Æ°á»£c Ä‘Ã¡nh dáº¥u báº±ng cÃ¡c mÃ u khÃ¡c nhau. VÃ­ dá»¥, nÃºt cá»§a "=" trong Ä‘Æ¡n vá»‹ mÃ u Ä‘á», nÃªn cÃ³ cÃº phÃ¡p gáº§n vá»›i nÃºt bÃªn trÃ¡i cá»§a nÃ³ trong Ä‘Æ¡n vá»‹ nÃ y tá»©c lÃ  nÃºt cá»§a "int" vÃ  "a". Do Ä‘Ã³, chÃºng Ä‘Æ°á»£c gáº¯n nhÃ£n vá»›i 1 nhÆ° cÃ¡c máº«u tÃ­ch cá»±c. Äá»‘i vá»›i cÃ¡c nÃºt cá»§a "int" vÃ  "a" trong Ä‘Æ¡n vá»‹ khÃ¡c (Ä‘Æ°á»£c Ä‘Ã¡nh dáº¥u báº±ng mÃ u xanh lÃ¡ cÃ¢y), vÃ¬ chÃºng thuá»™c vá» Ä‘Æ¡n vá»‹ khÃ¡c, chÃºng Ä‘Æ°á»£c gáº¯n nhÃ£n vá»›i 0 nhÆ° cÃ¡c máº«u tiÃªu cá»±c. HÃ¬nh thá»©c, nhiá»‡m vá»¥ nÃ y cÃ³ thá»ƒ Ä‘Æ°á»£c biá»ƒu thá»©c nhÆ° sau:

ğ¶(ğ‘›0,ğ‘›1)=(
1ğ‘›0âˆˆğ‘‡ğ‘–âˆ©ğ‘›1âˆˆğ‘‡ğ‘–
0ğ‘›0âˆˆğ‘‡ğ‘–âˆ©ğ‘›1âˆˆğ‘‡ğ‘—

trong Ä‘Ã³ ğ‘‡ğ‘– vÃ  ğ‘‡ğ‘— (ğ‘–â‰ ğ‘—) lÃ  hai Ä‘Æ¡n vá»‹ cÃº phÃ¡p khÃ¡c nhau trong AST vÃ  ğ‘›0 vÃ  ğ‘›1 lÃ  cÃ¡c nÃºt trong Ä‘Æ¡n vá»‹. ChÃºng tÃ´i huáº¥n luyá»‡n má»™t bá»™ phÃ¢n loáº¡i thÄƒm dÃ² nhá»‹ phÃ¢n ğ¶ Ä‘á»ƒ há»c liá»‡u báº¥t ká»³ cáº·p nÃºt nÃ o cÃ³ cÃº phÃ¡p-gáº§n dá»±a trÃªn cÃ¡c biá»ƒu diá»…n nÃºt Ä‘Æ°á»£c tÃ­nh tá»« biá»ƒu diá»…n token cá»§a cÃ¡c mÃ´ hÃ¬nh mÃ£ bá»Ÿi attention pool (HÃ¬nh 4).

3.3.2 Gáº¯n Tháº» CÃº PhÃ¡p Token. Nhiá»‡m vá»¥ Ä‘áº§u tiÃªn kiá»ƒm tra sá»± tÆ°Æ¡ng tá»± cÃº phÃ¡p giá»¯a cÃ¡c nÃºt AST khÃ¡c nhau. NgoÃ i sá»± tÆ°Æ¡ng tá»± cÃº phÃ¡p, táº¥t cáº£ cÃ¡c token Ä‘Æ°á»£c gÃ¡n má»™t vai trÃ² cÃº phÃ¡p bá»Ÿi quy táº¯c ngÃ´n ngá»¯ láº­p trÃ¬nh. Äá»ƒ kiá»ƒm tra liá»‡u cÃ¡c mÃ´ hÃ¬nh mÃ£ cÃ³ thá»ƒ há»c vai trÃ² cÃº phÃ¡p token riÃªng láº» hay khÃ´ng, chÃºng tÃ´i Ä‘á» xuáº¥t má»™t nhiá»‡m vá»¥ phÃ¢n loáº¡i Ä‘a lá»›p, cá»¥ thá»ƒ lÃ  gáº¯n tháº» cÃº phÃ¡p token, vÃ  nhiá»‡m vá»¥ nÃ y yÃªu cáº§u biá»ƒu diá»…n mÃ£ tá»‘t hÆ¡n vÃ  tinh táº¿ hÆ¡n Ä‘á»ƒ gáº¯n tháº» vai trÃ² cÃº phÃ¡p cá»§a má»—i token mÃ£. Äiá»u nÃ y Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ thÃ¡ch thá»©c vÃ  Ä‘Ã¡nh giÃ¡ Ä‘á»™ sÃ¢u hiá»ƒu biáº¿t vá» ngÃ´n ngá»¯ láº­p trÃ¬nh Ä‘á»‘i vá»›i cÃ¡c mÃ´ hÃ¬nh mÃ£. Má»™t mÃ´ hÃ¬nh mÃ£ cÃ³ thá»ƒ thá»±c hiá»‡n thÃ nh cÃ´ng gáº¯n tháº» cÃº phÃ¡p token cÃ³ thá»ƒ há»¯u Ã­ch hÆ¡n trong cÃ¡c á»©ng dá»¥ng mÃ£ hÃ³a phá»©c táº¡p, nhÆ° táº¡o mÃ£.

VÃ¬ má»—i nÃºt AST cÃ³ loáº¡i nÃºt cá»§a nÃ³, má»™t Ã½ tÆ°á»Ÿng trá»±c tiáº¿p lÃ  sá»­ dá»¥ng loáº¡i nÃºt Ä‘á»ƒ gáº¯n tháº». Tuy nhiÃªn, nhá»¯ng nhÃ£n cÃº phÃ¡p nÃ y ráº¥t trá»«u tÆ°á»£ng, vÃ­ dá»¥, tÃªn biáº¿n Ä‘Æ°á»£c gáº¯n nhÃ£n vá»›i "identifier" bá»Ÿi quy táº¯c cÃº phÃ¡p, nhÆ°ng nÃ³ cÃ³ Ã½ nghÄ©a cÃº phÃ¡p khÃ¡c nhau trong bá»‘i cáº£nh. Náº¿u nÃ³ trong khai bÃ¡o hÃ m, nÃ³ thá»±c sá»± lÃ  má»™t Ä‘á»‘i sá»‘ cho hÃ m nÃ y; tÆ°Æ¡ng tá»±, náº¿u nÃ³ trong viá»‡c gá»i lá»›p, nÃ³ lÃ  má»™t thuá»™c tÃ­nh lá»›p. Do Ä‘Ã³, chÃºng ta cáº§n thiáº¿t káº¿ cÃ¡c nhÃ£n cá»¥ thá»ƒ cho nhá»¯ng token trá»«u tÆ°á»£ng nÃ y. Ban Ä‘áº§u chÃºng tÃ´i xem xÃ©t loáº¡i cÃº phÃ¡p cá»§a cÃ¡c nÃºt lÃ¡ trong AST. Tiáº¿p theo, chÃºng tÃ´i tham kháº£o cÃ¡c loáº¡i nÃºt cha cá»§a chÃºng Ä‘á»ƒ xÃ¢y dá»±ng cÃ¡c nhÃ£n cá»¥ thá»ƒ. Cá»¥ thá»ƒ, chÃºng tÃ´i thiáº¿t káº¿ 36 nhÃ£n gáº¯n tháº» cho Java vÃ  33 nhÃ£n cho C/C++. ChÃºng tÃ´i lá»c cÃ¡c nhÃ£n cÃ³ táº§n suáº¥t tháº¥p (ğ‘“ğ‘Ÿğ‘’<200) cho Java250 vÃ  POJ-104. CÃ¡c nhÃ£n chÃºng tÃ´i sá»­ dá»¥ng Ä‘Æ°á»£c mÃ´ táº£ trong Báº£ng 1.

J. ACM, Vol. 37, No. 4, Article 111. NgÃ y xuáº¥t báº£n: ThÃ¡ng 8 2018.

--- TRANG 9 ---
KhÃ¡m PhÃ¡ CÃ¡c MÃ´ HÃ¬nh Tiá»n Huáº¥n Luyá»‡n MÃ£: NghiÃªn Cá»©u Kháº£ NÄƒng CÃº PhÃ¡p vÃ  Ngá»¯ NghÄ©a 111:9

Báº£ng 1. CÃ¡c nhÃ£n cá»§a Gáº¯n Tháº» CÃº PhÃ¡p Token cho Java250 vÃ  POJ-104.

Java250
modifiers local_variable_declaration variable_declarator formal_parameters
array_type dimensions formal_parameter block
object_creation_expression argument_list field_access integral_type
method_invocation while_statement parenthesized_expression if_statement
expression_statement break_statement update_expression assignment_expression
identifier for_statement binary_expression return_statement
array_creation_expression dimensions_expr array_access ERROR
unary_expression throw_statement enhanced_for_statement ternary_expression
cast_expression generic_type type_arguments array_initializer

POJ-104
declaration array_declarator function_definition parameter_list
parameter_declaration compound_statement for_statement assignment_expression
binary_expression update_expression subscript_expression expression_statement
if_statement parenthesized_expression return_statement call_expression
argument_list string_literal pointer_expression init_declarator
function_declarator cast_expression type_descriptor break_statement
comma_expression initializer_list char_literal pointer_declarator
continue_statement while_statement field_expression sizeof_expression
case_statement

[THIS IS FIGURE: Diagram showing token syntax tagging with "If-StatPEBEBEBEPEBFAFAMIALBEBEALESif(a<c){Systemoutprint(a*x);}" and corresponding labels]

HÃ¬nh 5. Gáº¯n Tháº» CÃº PhÃ¡p Token.

Báº£ng 2. CÃ¡c nhÃ£n gáº¯n tháº» cho cÃ¡c token Ä‘Æ°á»£c sá»­ dá»¥ng trong HÃ¬nh 5.

NhÃ£n MÃ´ táº£
PE Biá»ƒu thá»©c ngoáº·c Ä‘Æ¡n
BE Biá»ƒu thá»©c nhá»‹ phÃ¢n
B Khá»‘i
FA Truy cáº­p trÆ°á»ng
MI Gá»i phÆ°Æ¡ng thá»©c
AL Danh sÃ¡ch Ä‘á»‘i sá»‘
ES CÃ¢u lá»‡nh biá»ƒu thá»©c

ChÃºng tÃ´i trÃ¬nh bÃ y má»™t vÃ­ dá»¥ vá»›i nhÃ£n cÃº phÃ¡p tÆ°Æ¡ng á»©ng trong HÃ¬nh 5. ThÃ´ng tin chi tiáº¿t cá»§a cÃ¡c nhÃ£n trong vÃ­ dá»¥ nÃ y Ä‘Æ°á»£c hiá»ƒn thá»‹ trong Báº£ng 2. Cá»¥ thá»ƒ, chÃºng ta cÃ³ thá»ƒ tháº¥y ráº±ng cÃ¡c token "(" vÃ  ")" cÃ³ cÃ¡c nhÃ£n cÃº phÃ¡p khÃ¡c nhau trong cÃ¡c bá»‘i cáº£nh khÃ¡c nhau. Dáº¥u ngoáº·c Ä‘Æ¡n "( )" Ä‘Æ°á»£c gáº¯n nhÃ£n vá»›i "PE" trong Ä‘iá»u kiá»‡n if, trong khi dáº¥u ngoáº·c Ä‘Æ¡n "( )" tá»« viá»‡c gá»i phÆ°Æ¡ng thá»©c Ä‘Æ°á»£c gáº¯n nhÃ£n vá»›i "AL". ChÃºng tÃ´i thiáº¿t káº¿ nhiá»‡m vá»¥ nÃ y Ä‘á»ƒ khÃ¡m phÃ¡ liá»‡u nhá»¯ng mÃ´ hÃ¬nh nÃ y cÃ³ thá»ƒ há»c cÃº phÃ¡p mÃ£ Ä‘Ãºng cÃ¡ch tá»« ngá»¯ phÃ¡p láº­p trÃ¬nh hay khÃ´ng.

3.4 ThÄƒm DÃ² Ngá»¯ NghÄ©a

CÃ¡c cÃ´ng trÃ¬nh trÆ°á»›c Ä‘Ã¢y chá»§ yáº¿u táº­p trung vÃ o phÃ¢n tÃ­ch kháº£ nÄƒng cá»§a cÃ¡c mÃ´ hÃ¬nh mÃ£ tiá»n huáº¥n luyá»‡n trong viá»‡c há»c cÃº phÃ¡p mÃ£. Tuy nhiÃªn, phÃ¢n tÃ­ch ngá»¯ nghÄ©a mÃ£ cÅ©ng cáº§n thiáº¿t. NhÃ³m nÃ y Ä‘Ã¡nh giÃ¡ kháº£ nÄƒng cá»§a mÃ´ hÃ¬nh mÃ£ Ä‘á»ƒ hiá»ƒu Ã½ nghÄ©a vÃ  hÃ nh vi cá»§a cÃ¡c Ä‘oáº¡n mÃ£. Trong pháº§n nÃ y,

J. ACM, Vol. 37, No. 4, Article 111. NgÃ y xuáº¥t báº£n: ThÃ¡ng 8 2018.

--- TRANG 10 ---
111:10 W. Ma, S. Liu vÃ  M. Zhao et al.

chÃºng tÃ´i Ä‘á» xuáº¥t hai nhiá»‡m vá»¥ thÄƒm dÃ² Ä‘á»ƒ phÃ¢n tÃ­ch ngá»¯ nghÄ©a cá»§a mÃ£ Ä‘Ã£ há»c. Äáº§u tiÃªn lÃ  dá»± Ä‘oÃ¡n quan há»‡ ngá»¯ nghÄ©a cho cÃ¡c Ä‘á»“ thá»‹ phá»¥ thuá»™c (CDG, DDG vÃ  CFG). Dá»±a trÃªn dá»± Ä‘oÃ¡n, chÃºng ta cÃ³ thá»ƒ tÃ¡i táº¡o cáº¥u trÃºc cá»§a cÃ¡c Ä‘á»“ thá»‹ phá»¥ thuá»™c. CÃ¡c Ä‘á»“ thá»‹ phá»¥ thuá»™c mÃ´ táº£ cÃ¡c má»‘i quan há»‡ phá»©c táº¡p nhÆ° phá»¥ thuá»™c Ä‘iá»u khiá»ƒn vÃ  dá»¯ liá»‡u, ráº¥t quan trá»ng Ä‘á»ƒ hiá»ƒu cÃ¡ch cÃ¡c pháº§n khÃ¡c nhau cá»§a chÆ°Æ¡ng trÃ¬nh tÆ°Æ¡ng tÃ¡c. Nhiá»‡m vá»¥ thá»© hai lÃ  dá»± Ä‘oÃ¡n lan truyá»n ngá»¯ nghÄ©a. Hiá»ƒu luá»“ng Ä‘iá»u khiá»ƒn vÃ  dá»¯ liá»‡u lÃ  má»™t khÃ­a cáº¡nh nÃ¢ng cao cá»§a phÃ¢n tÃ­ch ngá»¯ nghÄ©a, vÆ°á»£t ra ngoÃ i phÃ¢n tÃ­ch tÄ©nh Ä‘áº¿n cÃ¡ch chÆ°Æ¡ng trÃ¬nh sáº½ hoáº¡t Ä‘á»™ng khi cháº¡y. Nhiá»‡m vá»¥ nÃ y Ä‘Ã¡nh giÃ¡ kháº£ nÄƒng cá»§a cÃ¡c mÃ´ hÃ¬nh mÃ£ Ä‘á»ƒ hiá»ƒu tÃ­nh cháº¥t Ä‘á»™ng cá»§a viá»‡c thá»±c thi mÃ£.

3.4.1 Dá»± ÄoÃ¡n Quan Há»‡ Ngá»¯ NghÄ©a. CÃ¡c Ä‘á»“ thá»‹ phá»¥ thuá»™c cá»§a má»™t chÆ°Æ¡ng trÃ¬nh cÃ³ thá»ƒ biá»ƒu diá»…n tá»‘t ngá»¯ nghÄ©a mÃ£ [20]. TÆ°Æ¡ng tá»± nhÆ° nhiá»‡m vá»¥ dá»± Ä‘oÃ¡n cáº·p nÃºt cÃº phÃ¡p trong Pháº§n 3.3.1, chÃºng tÃ´i cÅ©ng trÃ­ch xuáº¥t Ä‘á»“ thá»‹ phá»¥ thuá»™c Ä‘iá»u khiá»ƒn (CDG), Ä‘á»“ thá»‹ phá»¥ thuá»™c dá»¯ liá»‡u (DDG) vÃ  Ä‘á»“ thá»‹ luá»“ng Ä‘iá»u khiá»ƒn (CFG) Ä‘á»ƒ dá»± Ä‘oÃ¡n liá»‡u cÃ¡c mÃ´ hÃ¬nh mÃ£ cÃ³ thá»ƒ há»c ngá»¯ nghÄ©a mÃ£ hay khÃ´ng. Trong Äá»“ thá»‹ Phá»¥ thuá»™c Äiá»u khiá»ƒn (CDG), Äá»“ thá»‹ Phá»¥ thuá»™c Dá»¯ liá»‡u (DDG), vÃ  Äá»“ thá»‹ Luá»“ng Äiá»u khiá»ƒn (CFG) Ä‘Æ°á»£c xÃ¢y dá»±ng, má»—i nÃºt cÃ³ má»™t thuá»™c tÃ­nh vá»›i má»™t pháº§n mÃ£ cÃ³ thá»ƒ Ä‘Æ°á»£c tokenize thÃ nh nhiá»u token. ChÃºng tÃ´i gá»i nhá»¯ng token mÃ£ Ä‘Æ°á»£c suy ra tá»« cÃ¹ng má»™t nÃºt lÃ  Ä‘oáº¡n token. ChÃºng tÃ´i thá»‘ng nháº¥t nhá»¯ng nhiá»‡m vá»¥ nÃ y thÃ nh má»™t nhiá»‡m vá»¥ meta cá»¥ thá»ƒ lÃ  dá»± Ä‘oÃ¡n quan há»‡ ngá»¯ nghÄ©a. HÃ¬nh thá»©c, nhiá»‡m vá»¥ nÃ y cÃ³ thá»ƒ Ä‘Æ°á»£c biá»ƒu thá»©c nhÆ° sau:

ğ¶(ğ‘ 0,ğ‘ 1)=(
1âˆƒğ‘’âˆˆğº, ğ‘  0âˆˆğ‘ğ‘–âˆ©ğ‘ 1âˆˆğ‘ğ‘—âˆ©{ğ‘ğ‘–ğ‘’âˆ’ â†’ğ‘ğ‘—}
0âˆ€ğ‘’âˆˆğº, ğ‘  0âˆˆğ‘ğ‘–âˆ©ğ‘ 1âˆˆğ‘ğ‘—âˆ©{ğ‘ğ‘–Ì¸ğ‘’âˆ’ â†’ğ‘ğ‘—}

trong Ä‘Ã³ ğ‘ğ‘–,ğ‘ğ‘— lÃ  nÃºt thá»© ğ‘– vÃ  nÃºt thá»© ğ‘— trong Ä‘á»“ thá»‹ Ä‘Æ°á»£c xÃ¢y dá»±ng ğºâˆˆ{ğ¶ğ·ğº,ğ·ğ·ğº,ğ¶ğ¹ğº} vÃ  má»—i nÃºt chá»©a má»™t Ä‘oáº¡n token tá»« mÃ£ gá»‘c. ğ‘ 0 vÃ  ğ‘ 1 biá»ƒu thá»‹ cÃ¡c Ä‘oáº¡n token tÆ°Æ¡ng á»©ng cá»§a mÃ£ gá»‘c trong cÃ¡c nÃºt ğ‘ğ‘– vÃ  ğ‘ğ‘— sau tokenization. ğ‘’âˆ’ â†’ cÃ³ nghÄ©a lÃ  cÃ³ má»™t cáº¡nh giá»¯a hai nÃºt.

HÃ¬nh 6a, HÃ¬nh 6b vÃ  HÃ¬nh 6c minh há»a cÃ¡c vÃ­ dá»¥ cho ba má»‘i quan há»‡ ngá»¯ nghÄ©a. HÃ¬nh 6a cho tháº¥y má»™t vÃ­ dá»¥ phá»¥ thuá»™c Ä‘iá»u khiá»ƒn. NÃºt ğ‘4 phá»¥ thuá»™c Ä‘iá»u khiá»ƒn vÃ o nÃºt ğ‘3. Dá»±a trÃªn thá»±c táº¿ nÃ y, chÃºng tÃ´i gáº¯n nhÃ£n ráº±ng Ä‘oáº¡n token tá»« ğ‘3 phá»¥ thuá»™c Ä‘iá»u khiá»ƒn vÃ o Ä‘oáº¡n token trong ğ‘4. HÃ¬nh 6b minh há»a má»™t vÃ­ dá»¥ phá»¥ thuá»™c dá»¯ liá»‡u. NÃºt ğ‘4 phá»¥ thuá»™c dá»¯ liá»‡u vÃ o nÃºt ğ‘1. HÃ¬nh 6c cho tháº¥y má»™t vÃ­ dá»¥ cá»§a Ä‘á»“ thá»‹ luá»“ng Ä‘iá»u khiá»ƒn. ChÃºng ta cÃ³ má»™t sá»‘ thá»±c táº¿ thá»© tá»± thá»±c thi nhÆ° nÃºt ğ‘2 Ä‘Æ°á»£c thá»±c thi sau ğ‘1 ngay láº­p tá»©c. Äoáº¡n token cá»§a ğ‘2 cÃ³ má»‘i quan há»‡ luá»“ng-Ä‘iá»u khiá»ƒn vá»›i Ä‘oáº¡n token cá»§a ğ‘1.

3.4.2 Dá»± ÄoÃ¡n Lan Truyá»n Ngá»¯ NghÄ©a. ThÃ´ng tin luá»“ng dá»¯ liá»‡u Ä‘Æ°á»£c lan truyá»n trong Ä‘á»“ thá»‹ phá»¥ thuá»™c. Hai nÃºt vá»›i khoáº£ng cÃ¡ch dÃ i cÃ³ thá»ƒ phá»¥ thuá»™c dá»¯ liá»‡u má»™t cÃ¡ch ngáº§m Ä‘á»‹nh. ÄÃ³ lÃ  má»™t thá»±c táº¿ ráº±ng báº¥t ká»³ sá»­a Ä‘á»•i nÃ o trong Ä‘á»“ thá»‹ phá»¥ thuá»™c cÃ³ thá»ƒ áº£nh hÆ°á»Ÿng Ä‘áº¿n Ä‘áº§u ra chÆ°Æ¡ng trÃ¬nh. Lan truyá»n luá»“ng phá»¥ thuá»™c ngáº§m Ä‘á»‹nh lÃ  má»™t ngá»¯ nghÄ©a chÆ°Æ¡ng trÃ¬nh quan trá»ng. Nhiá»‡m vá»¥ lan truyá»n ngá»¯ nghÄ©a (bÃ­ danh inGraph) Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a bá»Ÿi

ğ¶(ğ‘ 0,ğ‘ 1)=(
1ğ‘ 0âˆˆğ‘ğ‘–âˆ©ğ‘ 1âˆˆğ‘ğ‘—âˆ©ğ‘ğ‘–âˆˆğºâˆ©ğ‘ğ‘—âˆˆğº
0ğ‘ 0âˆˆğ‘ğ‘–âˆ©ğ‘ 1âˆˆğ‘ğ‘—âˆ©ğ‘ğ‘–âˆˆğºâˆ©ğ‘ğ‘—âˆ‰ğº

trong Ä‘Ã³ Gâˆˆ{ğ¶ğ·ğº,ğ·ğ·ğº}, ğ‘ 0 vÃ  ğ‘ 1 lÃ  cÃ¡c Ä‘oáº¡n token trong cÃ¡c nÃºt cá»§a ğº. HÃ¬nh 6d cho tháº¥y má»™t vÃ­ dá»¥. Há»™p Ä‘á»• bÃ³ng lÃ m ná»•i báº­t cÃ¡c cÃ¢u lá»‡nh cÃ³ má»‘i quan há»‡ phá»¥ thuá»™c Ä‘iá»u khiá»ƒn. ChÃºng tÃ´i mong Ä‘á»£i bá»™ phÃ¢n loáº¡i thÄƒm dÃ² cÃ³ thá»ƒ nháº­n ra ráº±ng cÃ¢u lá»‡nh "printf" khÃ´ng náº±m trong Ä‘á»“ thá»‹ phá»¥ thuá»™c Ä‘iá»u khiá»ƒn.

3.5 PhÃ¢n TÃ­ch ChÃº Ã

ChÃºng tÃ´i Ä‘Ã£ tiáº¿n hÃ nh phÃ¢n tÃ­ch cÃ¡c trá»ng sá»‘ chÃº Ã½ trong má»—i Ä‘áº§u tá»±-chÃº Ã½, dá»±a trÃªn cÃ¡c má»‘i quan há»‡ ngá»¯ nghÄ©a chÆ°Æ¡ng trÃ¬nh ğºâˆˆ{ğ¶ğ¹ğº,ğ·ğ·ğº,ğ¶ğ·ğº} tá»« Pháº§n 3.4.1. Äá»‘i vá»›i má»™t Ä‘oáº¡n token nÃºt cho trÆ°á»›c

J. ACM, Vol. 37, No. 4, Article 111. NgÃ y xuáº¥t báº£n: ThÃ¡ng 8 2018.

--- TRANG 11 ---
KhÃ¡m PhÃ¡ CÃ¡c MÃ´ HÃ¬nh Tiá»n Huáº¥n Luyá»‡n MÃ£: NghiÃªn Cá»©u Kháº£ NÄƒng CÃº PhÃ¡p vÃ  Ngá»¯ NghÄ©a 111:11

[THIS IS FIGURE: Four code examples labeled (a) through (d) showing different semantic relationships:
(a) phá»¥ thuá»™c Ä‘iá»u khiá»ƒn
(b) phá»¥ thuá»™c dá»¯ liá»‡u  
(c) luá»“ng Ä‘iá»u khiá»ƒn
(d) inGraph
Each shows C-style code with numbered nodes and connecting lines]

HÃ¬nh 6. VÃ­ dá»¥ vá» thÄƒm dÃ² ngá»¯ nghÄ©a.

ğ‘ ğ‘– trong Ä‘Ã³ ğ‘– lÃ  nÃºt thá»© ğ‘– vÃ  má»™t loáº¡i má»‘i quan há»‡ ngá»¯ nghÄ©a ğº, chÃºng tÃ´i nhÃ³m cÃ¡c token Ä‘áº§u vÃ o cÃ²n láº¡i thÃ nh hai táº­p há»£p: ğ‘…0 vÃ  ğ‘…1. ğ‘…1 bao gá»“m táº¥t cáº£ cÃ¡c token cÃ³ má»‘i quan há»‡ ngá»¯ nghÄ©a vá»›i ğ‘ ğ‘– trong khi cÃ¡c token cÃ²n láº¡i táº¡o thÃ nh táº­p há»£p ğ‘…0. Sau Ä‘Ã³ chÃºng tÃ´i chia cÃ¡c trá»ng sá»‘ chÃº Ã½ cá»§a má»™t Ä‘áº§u chÃº Ã½ liÃªn quan Ä‘áº¿n ğ‘ ğ‘– thÃ nh hai táº­p há»£p, Ä‘Æ°á»£c biá»ƒu thá»‹ lÃ  ğ‘Š0 vÃ  ğ‘Š1, dá»±a trÃªn ğ‘…0 vÃ  ğ‘…1. ChÃºng tÃ´i kiá»ƒm tra sá»± khÃ¡c biá»‡t cá»§a cÃ¡c phÃ¢n phá»‘i chÃº Ã½ giá»¯a hai táº­p há»£p. Bá»Ÿi vÃ¬ chÃºng tÃ´i muá»‘n biáº¿t táº­p há»£p nÃ o Ä‘Ã³ng gÃ³p nhiá»u hÆ¡n cho biá»ƒu diá»…n mÃ£, chÃºng tÃ´i so sÃ¡nh tÃ­nh trung tÃ¢m phÃ¢n phá»‘i cá»§a hai táº­p há»£p chÃº Ã½. Náº¿u tá»•ng cÃ¡c trá»ng sá»‘ chÃº Ã½ trong ğ‘Š1 tá»« má»™t Ä‘áº§u chÃº Ã½ cá»¥ thá»ƒ lá»›n hÆ¡n tá»•ng cÃ¡c trá»ng sá»‘ chÃº Ã½ trong ğ‘Š0, Ä‘iá»u Ä‘Ã³ cho tháº¥y ráº±ng Ä‘áº§u chÃº Ã½ nÃ y Ä‘Ã³ng gÃ³p nhiá»u hÆ¡n cho viá»‡c há»c ngá»¯ nghÄ©a mÃ£ vÃ  chÃºng tÃ´i biá»ƒu thá»‹ nÃ³ lÃ  Ä‘áº§u chÃº Ã½ ngá»¯ nghÄ©a.

Äá»ƒ xÃ¡c Ä‘á»‹nh Ã½ nghÄ©a thá»‘ng kÃª, chÃºng tÃ´i Ã¡p dá»¥ng kiá»ƒm Ä‘á»‹nh t ghÃ©p cáº·p vá»›i kÃ­ch thÆ°á»›c máº«u lá»›n cho má»—i loáº¡i ngá»¯ nghÄ©a ğº. ChÃºng tÃ´i hÃ¬nh thÃ nh giáº£ thuyáº¿t null ğ»0:ğœ‡ğ‘‘=0, trong Ä‘Ã³ ğœ‡ğ‘‘ Ä‘áº¡i diá»‡n cho sá»± khÃ¡c biá»‡t trung bÃ¬nh thá»±c sá»± giá»¯a ğ‘Š1 vÃ  ğ‘Š0. Giáº£ thuyáº¿t thay tháº¿ ğ»1:ğœ‡ğ‘‘>0 cho tháº¥y ráº±ng cÃ³ má»™t sá»± khÃ¡c biá»‡t trung bÃ¬nh tÃ­ch cá»±c (ğ‘Š1 lá»›n hÆ¡n ğ‘Š0). Báº±ng cÃ¡ch tiáº¿n hÃ nh kiá»ƒm Ä‘á»‹nh nÃ y, chÃºng ta cÃ³ thá»ƒ xÃ¡c Ä‘á»‹nh liá»‡u Ä‘áº§u chÃº Ã½ cÃ³ Ä‘Ã³ng gÃ³p nhiá»u hÆ¡n cho viá»‡c há»c ngá»¯ nghÄ©a mÃ£ hay khÃ´ng. PhÃ¢n tÃ­ch cáº¥p Ä‘á»™ Ä‘áº§u nÃ y cung cáº¥p hiá»ƒu biáº¿t chi tiáº¿t hÆ¡n vá» tá»±-chÃº Ã½. Tá»•ng cá»™ng, chÃºng tÃ´i Ä‘Ã£ phÃ¢n tÃ­ch hÆ¡n 10.000 Ä‘áº§u vÃ o ngá»¯ nghÄ©a cho 4 mÃ´ hÃ¬nh mÃ£ tiá»n huáº¥n luyá»‡n vÃ  chá»n ngáº«u nhiÃªn 100 Ä‘áº§u vÃ o ngá»¯ nghÄ©a cho ba LLM.

4 THIáº¾T Láº¬P ÄÃNH GIÃ

Trong pháº§n nÃ y, chÃºng tÃ´i giá»›i thiá»‡u thiáº¿t láº­p Ä‘Ã¡nh giÃ¡, bao gá»“m tiá»n xá»­ lÃ½ dá»¯ liá»‡u, cÃ¡c mÃ´ hÃ¬nh Ä‘Ã¡nh giÃ¡ vÃ  cÃ¡c thÆ°á»›c Ä‘o Ä‘Ã¡nh giÃ¡.

4.1 Táº­p Dá»¯ Liá»‡u vÃ  Tiá»n Xá»­ LÃ½

ChÃºng tÃ´i sá»­ dá»¥ng hai táº­p dá»¯ liá»‡u, cá»¥ thá»ƒ lÃ  Java250 [56] vÃ  POJ-104 [53] cho nghiÃªn cá»©u cá»§a chÃºng tÃ´i. Cháº¥t lÆ°á»£ng dá»¯ liá»‡u cÃ³ tÃ¡c Ä‘á»™ng Ä‘Ã¡ng ká»ƒ Ä‘áº¿n phÃ¢n tÃ­ch thÄƒm dÃ². ChÃºng tÃ´i tuÃ¢n theo cÃ¡c bÆ°á»›c tiá»n xá»­ lÃ½ Ä‘Æ°á»£c nÃªu

J. ACM, Vol. 37, No. 4, Article 111. NgÃ y xuáº¥t báº£n: ThÃ¡ng 8 2018.

--- TRANG 12 ---
111:12 W. Ma, S. Liu vÃ  M. Zhao et al.

[THIS IS FIGURE: Workflow diagram showing: Raw code -> Refactor -> Refactored Code -> AST Parser -> Extract AST -> Syntax Data, and Static Analysis -> Program Graphs -> Semantic Data -> Token Alignment]

HÃ¬nh 7. Quy trÃ¬nh cÃ´ng viá»‡c tiá»n xá»­ lÃ½ dá»¯ liá»‡u.

trong HÃ¬nh 7 Ä‘á»ƒ táº¡o dá»¯ liá»‡u thÄƒm dÃ² cÃº phÃ¡p vÃ  ngá»¯ nghÄ©a cháº¥t lÆ°á»£ng cao. MÃ£ Ä‘Æ°á»£c tÃ¡i cáº¥u trÃºc sá»­ dá»¥ng cÃ´ng cá»¥ google-java-formatÂ³ vÃ  cÃ´ng cá»¥ clang-refactorâ´. TÃ¡i cáº¥u trÃºc mÃ£ Ä‘áº£m báº£o kháº£ nÄƒng Ä‘á»c cá»§a nÃ³ vÃ  táº¡o Ä‘iá»u kiá»‡n thuáº­n lá»£i cho viá»‡c cÄƒn chá»‰nh token giá»¯a cÃ¡c Ä‘á»“ thá»‹ vÃ  Ä‘áº§u vÃ o mÃ´ hÃ¬nh. Äá»ƒ Ä‘áº£m báº£o Ä‘á»™ chÃ­nh xÃ¡c cá»§a káº¿t quáº£, chÃºng tÃ´i sá»­ dá»¥ng khung phÃ¢n tÃ­ch tÄ©nh Joern vÃ  bá»™ phÃ¢n tÃ­ch ASTâµ Ä‘á»ƒ trÃ­ch xuáº¥t cÃ¡c Ä‘á»“ thá»‹ chÆ°Æ¡ng trÃ¬nh vÃ  AST. Trong trÆ°á»ng há»£p cÃ¡c Ä‘á»“ thá»‹ chÆ°Æ¡ng trÃ¬nh, chÃºng tÃ´i há»£p nháº¥t cÃ¡c nÃºt dÆ° thá»«a náº¿u mÃ£ cá»§a má»™t nÃºt lÃ  táº­p con cá»§a cÃ¡c nÃºt lÃ¢n cáº­n cá»§a nÃ³. Sau Ä‘Ã³ chÃºng tÃ´i trÃ­ch xuáº¥t cÃ¡c má»‘i quan há»‡ cÃº phÃ¡p vÃ  ngá»¯ nghÄ©a giá»¯a cÃ¡c token mÃ£ vÃ  xÃ¢y dá»±ng cÃ¡c táº­p dá»¯ liá»‡u thÄƒm dÃ².

4.2 CÃ¡c MÃ´ HÃ¬nh Thá»±c Nghiá»‡m

ChÃºng tÃ´i chá»n 7 mÃ´ hÃ¬nh mÃ£ phá»• biáº¿n vá»›i cÃ¡c kiáº¿n trÃºc Ä‘a dáº¡ng (bá»™ mÃ£ hÃ³a transformer, bá»™ giáº£i mÃ£ transformer vÃ  bá»™ mÃ£ hÃ³a-giáº£i mÃ£ transformer) Ä‘Æ°á»£c sá»­ dá»¥ng rá»™ng rÃ£i trong ká»¹ thuáº­t pháº§n má»m. 7 mÃ´ hÃ¬nh Ä‘Æ°á»£c xÃ¢y dá»±ng bá»Ÿi cÃ¡c cÃ´ng ty hoáº·c tá»• chá»©c cÃ³ uy tÃ­n: Microsoft, Meta, Salesforce vÃ  Huggingface. Táº¥t cáº£ Ä‘á»u cÃ³ sá»‘ lÆ°á»£ng táº£i xuá»‘ng lá»›n trÃªn Huggingface, vÃ  cÃ¡c bÃ i bÃ¡o tÆ°Æ¡ng á»©ng cá»§a chÃºng Ä‘á»u cÃ³ hÆ¡n 150 trÃ­ch dáº«n. Äáº§u tiÃªn, chÃºng tÃ´i tiáº¿n hÃ nh thÃ­ nghiá»‡m sá»­ dá»¥ng bá»‘n mÃ´ hÃ¬nh tiá»n huáº¥n luyá»‡n, CodeBERT (CB) [13], GraphCodeBERT (GCB) [17], UnixCoder (UC) [16] vÃ  CodeT5 (CT) [71]. CodeBERT vÃ  GraphCodeBERT sá»­ dá»¥ng bá»™ mÃ£ hÃ³a Transformer, trong khi GraphCodeBERT tÃ­ch há»£p thÃ´ng tin luá»“ng dá»¯ liá»‡u bá»• sung. UnixCoder sá»­ dá»¥ng ma tráº­n chÃº Ã½ che máº·t vá»›i cÃ¡c bá»™ Ä‘iá»u há»£p tiá»n tá»‘ Ä‘á»ƒ há»— trá»£ há»c mÃ£ hÃ³a, giáº£i mÃ£ vÃ  mÃ£ hÃ³a-giáº£i mÃ£. CodeT5 sá»­ dá»¥ng kiáº¿n trÃºc Transformer mÃ£ hÃ³a-giáº£i mÃ£. Äá»‘i vá»›i CodeT5, chÃºng tÃ´i xem xÃ©t bá»™ mÃ£ hÃ³a cá»§a nÃ³, cÃ³ thá»ƒ Ä‘Æ°á»£c so sÃ¡nh vá»›i cÃ¡c mÃ´ hÃ¬nh tiá»n huáº¥n luyá»‡n khÃ¡c trong cÃ¹ng kiáº¿n trÃºc. Nhá»¯ng mÃ´ hÃ¬nh nÃ y cÃ³ 12 táº§ng mÃ£ hÃ³a Transformer (Ä‘Æ°á»£c biá»ƒu thá»‹ lÃ  Táº§ng 1-Táº§ng 12) cá»™ng vá»›i má»™t táº§ng nhÃºng (Ä‘Æ°á»£c biá»ƒu thá»‹ lÃ  Táº§ng 0). ChÃºng tÃ´i Ã¡p dá»¥ng cÃ¡c nhiá»‡m vá»¥ thÄƒm dÃ² cá»§a chÃºng tÃ´i cho má»—i táº§ng mÃ£ hÃ³a vÃ  táº§ng nhÃºng. Äiá»u nÃ y giÃºp chÃºng ta hiá»ƒu vai trÃ² cá»§a má»—i táº§ng. Thá»© hai, chÃºng tÃ´i cÅ©ng nghiÃªn cá»©u 3 mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n (LLM), CodeLlama-7b [58] (CL), StarCoder [34] (SC) vÃ  CodeT5+ [70] (CodeT5p-770m) (CT5P+) sá»­ dá»¥ng táº­p dá»¯ liá»‡u Java. CodeLlama-7b cÃ³ 32 táº§ng áº©n vÃ  StarCoder cÃ³ 40 táº§ng áº©n. Cáº£ hai Ä‘á»u sá»­ dá»¥ng bá»™ giáº£i mÃ£ transformer. CodeT5p-770m cÃ³ 24 táº§ng mÃ£ hÃ³a áº©n vÃ  24 táº§ng giáº£i mÃ£ áº©n. ÄÃ¢y lÃ  má»™t mÃ´ hÃ¬nh ngÃ´n ngá»¯ mÃ£ má»Ÿ lá»›n dá»±a trÃªn cáº¥u trÃºc mÃ£ hÃ³a-giáº£i mÃ£ cho há» CodeT5+ [70]. Táº¥t cáº£ cÃ¡c thÃ­ nghiá»‡m Ä‘Æ°á»£c láº·p láº¡i 3 láº§n vá»›i cÃ¡c háº¡t giá»‘ng ngáº«u nhiÃªn khÃ¡c nhau.

4.3 CÃ¡c ThÆ°á»›c Äo ÄÃ¡nh GiÃ¡

ChÃºng tÃ´i sá»­ dá»¥ng há»‡ sá»‘ tÆ°Æ¡ng quan Matthew (MCC) [50] lÃ m thÆ°á»›c Ä‘o Ä‘Ã¡nh giÃ¡ cá»§a chÃºng tÃ´i. MCC lÃ  má»™t thay tháº¿ Ä‘Ã¡ng tin cáº­y cho Ä‘iá»ƒm F1 Ä‘á»‘i vá»›i phÃ¢n loáº¡i nhá»‹ phÃ¢n [5,74], vÃ  nÃ³ xem xÃ©t toÃ n bá»™ ma tráº­n confusion

Â³https://github.com/google/google-java-format.git
â´https://clang.llvm.org/docs/ClangTools.html
âµhttps://joern.io/,https://tree-sitter.github.io/tree-sitter/

J. ACM, Vol. 37, No. 4, Article 111. NgÃ y xuáº¥t báº£n: ThÃ¡ng 8 2018.

--- TRANG 13 ---
KhÃ¡m PhÃ¡ CÃ¡c MÃ´ HÃ¬nh Tiá»n Huáº¥n Luyá»‡n MÃ£: NghiÃªn Cá»©u Kháº£ NÄƒng CÃº PhÃ¡p vÃ  Ngá»¯ NghÄ©a 111:13

matrix. MCC cÃ³ thá»ƒ Ä‘Æ°á»£c tÃ­nh tá»« ma tráº­n confusion,

ğ‘€ğ¶ğ¶=ğ‘‡ğ‘ƒÃ—ğ‘‡ğ‘âˆ’ğ¹ğ‘ƒÃ—ğ¹ğ‘/âˆš(ğ‘‡ğ‘ƒ+ğ¹ğ‘ƒ)Â·(ğ‘‡ğ‘ƒ+ğ¹ğ‘)Â·(ğ‘‡ğ‘+ğ¹ğ‘ƒ)Â·(ğ‘‡ğ‘+ğ¹ğ‘)

trong Ä‘Ã³ TP lÃ  true positive, TN lÃ  true negative, FP lÃ  false positive vÃ  FN lÃ  false negative. Äá»‘i vá»›i gáº¯n tháº» cÃº phÃ¡p token, Ä‘Ã¢y lÃ  phÃ¢n loáº¡i nhiá»u lá»›p vÃ  chÃºng tÃ´i cÅ©ng hiá»ƒn thá»‹ Ä‘iá»ƒm F1 macro cá»§a nÃ³,

Macro F1 =1/ğ‘âˆ‘ğ‘–=1ğ‘ 2Ã—Precision ğ‘–Ã—Recallğ‘–/(Precision ğ‘–+Recallğ‘–)

trong Ä‘Ã³ N lÃ  sá»‘ lÆ°á»£ng lá»›p vÃ  i lÃ  lá»›p thá»© ğ‘–. ChÃºng tÃ´i chá»n Ä‘iá»ƒm F1 macro lÃ m thÆ°á»›c Ä‘o Ä‘Ã¡nh giÃ¡ cá»§a chÃºng tÃ´i do thuá»™c tÃ­nh vá»‘n cÃ³ cá»§a nÃ³ trong viá»‡c gÃ¡n Ã½ nghÄ©a bÃ¬nh Ä‘áº³ng cho má»i lá»›p trong táº­p dá»¯ liá»‡u cá»§a chÃºng tÃ´i. VÃ¬ táº¥t cáº£ cÃ¡c thÃ­ nghiá»‡m Ä‘Æ°á»£c láº·p láº¡i 3 láº§n, chÃºng tÃ´i sá»­ dá»¥ng cÃ¡c giÃ¡ trá»‹ trung bÃ¬nh Ä‘á»ƒ Ä‘Ã¡nh giÃ¡.

5 Káº¾T QUáº¢ THá»°C NGHIá»†M

Trong pháº§n nÃ y, chÃºng tÃ´i trÃ¬nh bÃ y káº¿t quáº£ phÃ¢n tÃ­ch cÃº phÃ¡p vÃ  ngá»¯ nghÄ©a mÃ£.

5.1 PhÃ¢n TÃ­ch CÃº PhÃ¡p

5.1.1 Dá»± ÄoÃ¡n Cáº·p NÃºt CÃº PhÃ¡p. HÃ¬nh 8a vÃ  HÃ¬nh 8b trÃ¬nh bÃ y káº¿t quáº£ cá»§a cÃ¡c bá»™ phÃ¢n loáº¡i thÄƒm dÃ² cho dá»± Ä‘oÃ¡n cáº·p nÃºt cÃº phÃ¡p trÃªn Java250 vÃ  POJ-104 tÆ°Æ¡ng á»©ng, Ä‘á»‘i vá»›i cÃ¡c mÃ´ hÃ¬nh mÃ£ tiá»n huáº¥n luyá»‡n, CodeBert (CB), GraphCodeBert (GCB), UnixCoder (UC) vÃ  CodeT5 (CT5). Nhá»¯ng káº¿t quáº£ nÃ y Ä‘Æ°á»£c suy ra tá»« cÃ¡c biá»ƒu diá»…n áº©n Ä‘Æ°á»£c cung cáº¥p bá»Ÿi cÃ¡c mÃ´ hÃ¬nh mÃ£. Trá»¥c X biá»ƒu thá»‹ chá»‰ sá»‘ táº§ng, trong khi trá»¥c Y biá»ƒu thá»‹ hiá»‡u suáº¥t. ğ¿ğ‘ğ‘¦ğ‘’ğ‘Ÿ 0 tÆ°Æ¡ng á»©ng vá»›i táº§ng nhÃºng, trong khi ğ¿ğ‘ğ‘¦ğ‘’ğ‘Ÿ 1-ğ¿ğ‘ğ‘¦ğ‘’ğ‘Ÿ 12 Ä‘áº¡i diá»‡n cho cÃ¡c táº§ng Transformer. ChÃºng ta cÃ³ thá»ƒ tháº¥y ráº±ng nhÃ¬n chung nhá»¯ng mÃ´ hÃ¬nh nÃ y cÃ³ thá»ƒ mÃ´ táº£ chÃ­nh xÃ¡c cÃ¡c má»‘i quan há»‡ cÃº phÃ¡p giá»¯a cÃ¡c token. VÃ­ dá»¥, MCC Ä‘áº¡t trÃªn 70% trong cÃ¡c táº§ng khÃ¡c nhau trÃªn cÃ¡c mÃ´ hÃ¬nh khÃ¡c nhau. Táº¥t cáº£ cÃ¡c mÃ´ hÃ¬nh tiá»n huáº¥n luyá»‡n Ä‘áº¡t hiá»‡u suáº¥t tá»‘t nháº¥t giá»¯a ğ¿ğ‘ğ‘¦ğ‘’ğ‘Ÿ 2 vÃ  ğ¿ğ‘ğ‘¦ğ‘’ğ‘Ÿ 4 nÃ´ng. Vá»›i Ä‘á»™ sÃ¢u cá»§a cÃ¡c táº§ng, hiá»‡u suáº¥t giáº£m dáº§n. Cá»¥ thá»ƒ hÆ¡n, GraphCodeBERT (GCB) thá»ƒ hiá»‡n hiá»‡u suáº¥t tá»‘t hÆ¡n má»™t chÃºt so vá»›i cÃ¡c mÃ´ hÃ¬nh khÃ¡c trÃªn Java250, nhÆ° Ä‘Æ°á»£c chá»©ng minh trong HÃ¬nh 8a. Tuy nhiÃªn, khi chuyá»ƒn sang POJ-104, hiá»‡n tÆ°á»£ng phá»©c táº¡p hÆ¡n. CodeT5 thá»ƒ hiá»‡n hiá»‡u suáº¥t vÆ°á»£t trá»™i so vá»›i cÃ¡c mÃ´ hÃ¬nh khÃ¡c tá»« ğ¿ğ‘ğ‘¦ğ‘’ğ‘Ÿ 4 Ä‘áº¿n ğ¿ğ‘ğ‘¦ğ‘’ğ‘Ÿ 8, tuy nhiÃªn, khi táº§ng Ä‘áº¡t 12, GraphCodeBERT Ä‘áº¡t hiá»‡u suáº¥t tá»‘t nháº¥t. Máº·c dÃ¹ UnixCoder vÃ  CodeT5 sá»­ dá»¥ng cÃ¡c chiáº¿n lÆ°á»£c tiá»n huáº¥n luyá»‡n phá»©c táº¡p hÆ¡n, táº­n dá»¥ng cÃ¡c táº­p dá»¯ liá»‡u lá»›n hÆ¡n vÃ  cÃ³ sá»‘ lÆ°á»£ng tham sá»‘ cÃ³ thá»ƒ huáº¥n luyá»‡n lá»›n hÆ¡n, lá»£i tháº¿ tÆ°Æ¡ng Ä‘á»‘i cá»§a chÃºng lÃ  tá»‘i thiá»ƒu. HÃ¬nh 8c cho tháº¥y Ä‘iá»ƒm MCC cho CodeLlama, StarCoder vÃ  CodeT5+. Má»™t quan sÃ¡t thÃº vá»‹ lÃ  ba mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n Ä‘áº¡t hiá»‡u suáº¥t tá»‘t nháº¥t trong cÃ¡c táº§ng nÃ´ng ğ¿ğ‘ğ‘¦ğ‘’ğ‘Ÿ 4 vÃ  ğ¿ğ‘ğ‘¦ğ‘’ğ‘Ÿ 5, tÆ°Æ¡ng tá»± nhÆ° cÃ¡c mÃ´ hÃ¬nh mÃ£ tiá»n huáº¥n luyá»‡n. NhÆ°ng Ä‘á»‘i vá»›i StarCoder vÃ  CodeLlama, hiá»‡u suáº¥t tÄƒng ráº¥t nhiá»u á»Ÿ táº§ng cuá»‘i cÃ¹ng khÃ¡c vá»›i cÃ¡c mÃ´ hÃ¬nh khÃ¡c. ChÃºng ta cÃ³ thá»ƒ káº¿t luáº­n ráº±ng má»‘i quan há»‡ cÃº phÃ¡p giá»¯a cÃ¡c token mÃ£ dá»… quan sÃ¡t hÆ¡n trong khÃ´ng gian biá»ƒu diá»…n cá»§a cÃ¡c táº§ng áº©n nÃ´ng. Sá»± giáº£m hiá»‡u suáº¥t cá»§a cÃ¡c biá»ƒu diá»…n sÃ¢u hÆ¡n trÃªn nhiá»‡m vá»¥ nÃ y lÃ  má»™t hiá»‡n tÆ°á»£ng thÃº vá»‹. Máº·c dÃ¹ cÃ¡c táº§ng áº©n sÃ¢u Ä‘Æ°á»£c cho lÃ  chá»©a thÃ´ng tin tá»« cÃ¡c táº§ng nÃ´ng hÆ¡n, khÃ´ng gian biá»ƒu diá»…n cá»§a chÃºng phá»©c táº¡p hÆ¡n, mÃ£ hÃ³a nhiá»u thuá»™c tÃ­nh mÃ£ khÃ¡c nhÆ° vai trÃ² token-cÃº phÃ¡p, vÃ¬ váº­y má»‘i quan há»‡ cÃº phÃ¡p-token cÃ³ thá»ƒ Ã­t ná»•i báº­t hÆ¡n.

5.1.2 Gáº¯n Tháº» CÃº PhÃ¡p Token. HÃ¬nh 9a vÃ  HÃ¬nh 9b trÃ¬nh bÃ y káº¿t quáº£ MCC cá»§a cÃ¡c bá»™ phÃ¢n loáº¡i thÄƒm dÃ² cho vai trÃ² cÃº phÃ¡p token riÃªng láº» (Gáº¯n Tháº» CÃº PhÃ¡p Token) trÃªn Java250 vÃ  POJ-104 tÆ°Æ¡ng á»©ng. HÃ¬nh 9c vÃ  HÃ¬nh 9d thá»ƒ hiá»‡n Ä‘iá»ƒm F1. CÃ¡c quan sÃ¡t cá»§a chÃºng tÃ´i cho tháº¥y ráº±ng CodeT5 vÆ°á»£t trá»™i hÆ¡n cÃ¡c mÃ´ hÃ¬nh khÃ¡c trong cÃ¡c táº§ng trung gian, cá»¥ thá»ƒ tá»« ğ¿ğ‘ğ‘¦ğ‘’ğ‘Ÿ 4 Ä‘áº¿n ğ¿ğ‘ğ‘¦ğ‘’ğ‘Ÿ 11. CodeBERT thá»ƒ hiá»‡n hiá»‡u suáº¥t tá»‘t hÆ¡n má»™t chÃºt so vá»›i GraphCodeBERT trong nhá»¯ng táº§ng trung gian nÃ y,

J. ACM, Vol. 37, No. 4, Article 111. NgÃ y xuáº¥t báº£n: ThÃ¡ng 8 2018.

--- TRANG 14 ---
111:14 W. Ma, S. Liu vÃ  M. Zhao et al.

trong khi GraphCodeBERT vÆ°á»£t trá»™i hÆ¡n cÃ¡c mÃ´ hÃ¬nh khÃ¡c á»Ÿ táº§ng cuá»‘i cÃ¹ng, tá»©c lÃ  ğ¿ğ‘ğ‘¦ğ‘’ğ‘Ÿ 12. ThÃº vá»‹ lÃ , má»™t sá»± sá»¥t giáº£m hiá»‡u suáº¥t Ä‘Æ°á»£c quan sÃ¡t cho táº¥t cáº£ cÃ¡c mÃ´ hÃ¬nh ngoáº¡i trá»« UnixCoder chuyá»ƒn tá»« ğ¿ğ‘ğ‘¦ğ‘’ğ‘Ÿ 11 Ä‘áº¿n ğ¿ğ‘ğ‘¦ğ‘’ğ‘Ÿ 12. CodeT5 Ä‘áº¡t hiá»‡u suáº¥t Ä‘á»‰nh xáº¥p xá»‰ quanh ğ¿ğ‘ğ‘¦ğ‘’ğ‘Ÿ 10. NgÆ°á»£c láº¡i, UnixCoder tá»¥t láº¡i phÃ­a sau cÃ¡c mÃ´ hÃ¬nh khÃ¡c, Ä‘áº·c biá»‡t sau ğ¿ğ‘ğ‘¦ğ‘’ğ‘Ÿ 7. Ngoáº¡i trá»« UnixCoder, hiá»‡u suáº¥t cá»§a cÃ¡c mÃ´ hÃ¬nh tiá»n huáº¥n luyá»‡n khÃ¡c cho tháº¥y xu hÆ°á»›ng tÄƒng vá»›i cÃ¡c biáº¿n Ä‘á»™ng tá»« ğ¿ğ‘ğ‘¦ğ‘’ğ‘Ÿ 0 Ä‘áº¿n ğ¿ğ‘ğ‘¦ğ‘’ğ‘Ÿ 11. HÃ¬nh 10a vÃ  HÃ¬nh 10b cho tháº¥y Ä‘iá»ƒm F1 vÃ  Ä‘iá»ƒm MCC cho LLM trÃªn táº­p dá»¯ liá»‡u Java250. Náº¿u chÃºng ta nhÃ¬n vÃ o táº¥t cáº£ cÃ¡c hÃ¬nh trong nhiá»‡m vá»¥ nÃ y, chÃºng ta tháº¥y má»™t xu hÆ°á»›ng chung lÃ  hiá»‡u suáº¥t cáº£i thiá»‡n khi Ä‘á»™ sÃ¢u cá»§a cÃ¡c táº§ng tÄƒng, vÃ  pháº§n sau á»•n Ä‘á»‹nh vá»›i má»™t sá»‘ sá»¥t giáº£m hoáº·c tÄƒng. ThÃº vá»‹ lÃ , táº¡i giao Ä‘iá»ƒm giá»¯a bá»™ mÃ£ hÃ³a vÃ  bá»™ giáº£i mÃ£, hiá»‡u suáº¥t mÃ´ hÃ¬nh giáº£m máº¡nh nhÆ°ng nhanh chÃ³ng cáº£i thiá»‡n trá»Ÿ láº¡i khi sá»‘ lÆ°á»£ng táº§ng tÄƒng. Hiá»‡n tÆ°á»£ng nÃ y cÅ©ng Ä‘Ã£ Ä‘Æ°á»£c quan sÃ¡t trong cÃ¡c thÃ­ nghiá»‡m khÃ¡c. Má»™t giáº£i thÃ­ch há»£p lÃ½ lÃ  bá»™ mÃ£ hÃ³a vÃ  bá»™ giáº£i mÃ£ hoáº¡t Ä‘á»™ng vá»›i cÃ¡c cÆ¡ cháº¿ khÃ¡c nhau. Bá»™ mÃ£ hÃ³a mÃ£ hÃ³a thÃ´ng tin thÃ nh biá»ƒu diá»…n trá»«u tÆ°á»£ng trong khi bá»™ giáº£i mÃ£ cá»‘ gáº¯ng khÃ´i phá»¥c Ä‘áº§u vÃ o tá»« biá»ƒu diá»…n trá»«u tÆ°á»£ng. Do sá»± khÃ¡c biá»‡t trong hoáº¡t Ä‘á»™ng, cÃ¡c thuá»™c tÃ­nh trong biá»ƒu diá»…n tá»« cÃ¡c táº§ng tÆ°Æ¡ng tÃ¡c lÃ  thÃ¡ch thá»©c Ä‘á»ƒ quan sÃ¡t khi di chuyá»ƒn tá»« bá»™ mÃ£ hÃ³a sang bá»™ giáº£i mÃ£. NhÆ° Ä‘Ã£ Ä‘á» cáº­p trÆ°á»›c Ä‘Ã³, gáº¯n tháº» cÃº phÃ¡p token lÃ  má»™t nhiá»‡m vá»¥ khÃ´ng táº§m thÆ°á»ng Ä‘á»ƒ gáº¯n nhÃ£n token mÃ£ vá»›i vai trÃ² cÃº phÃ¡p, vÃ  Ä‘Ã¢y lÃ  nhiá»‡m vá»¥ khÃ³ khÄƒn hÆ¡n nhiá»‡m vá»¥ trÆ°á»›c Ä‘Ã³. Thuá»™c tÃ­nh vai trÃ² cÃº phÃ¡p token Ä‘Æ°á»£c biá»ƒu diá»…n rÃµ rÃ ng hÆ¡n trong cÃ¡c táº§ng sÃ¢u hÆ¡n so vá»›i cÃ¡c táº§ng nÃ´ng.

Vá» má»‘i quan há»‡ tÆ°Æ¡ng Ä‘á»‘i cÃº phÃ¡p, nhá»¯ng mÃ´ hÃ¬nh mÃ£ tiá»n huáº¥n luyá»‡n nÃ y thá»ƒ hiá»‡n kháº£ nÄƒng tÆ°Æ¡ng Ä‘Æ°Æ¡ng. Tuy nhiÃªn, CodeT5 (chÃºng tÃ´i xem xÃ©t bá»™ mÃ£ hÃ³a cá»§a nÃ³) phÃ¢n biá»‡t báº£n thÃ¢n báº±ng cÃ¡ch biá»ƒu diá»…n vai trÃ² cÃº phÃ¡p token riÃªng láº» trong bá»‘i cáº£nh má»™t cÃ¡ch hiá»‡u quáº£ hÆ¡n. NgÆ°á»£c láº¡i, UnixCoder thá»ƒ hiá»‡n má»©c Ä‘á»™ hiá»ƒu biáº¿t cÃº phÃ¡p tháº¥p hÆ¡n so vá»›i cÃ¡c mÃ´ hÃ¬nh khÃ¡c. ChÃºng tÃ´i suy Ä‘oÃ¡n Ä‘iá»u nÃ y vÃ¬ hai lÃ½ do sau: 1) CodeBERT, GraphCodeBERT, vÃ  CodeT5-encoder Ä‘á»u sá»­ dá»¥ng mÃ´ hÃ¬nh ngÃ´n ngá»¯ cÃ³ máº·t náº¡ (MLM) hoáº·c cÃ¡c cÃ¡ch tÆ°Æ¡ng tá»± Ä‘á»ƒ há»c cÃ¡c Ä‘áº·c trÆ°ng token hai chiá»u trong khi UniXCoder tÃ­ch há»£p cÃ¡c loáº¡i nhiá»‡m vá»¥ tiá»n huáº¥n luyá»‡n khÃ¡c nhau. Máº·c dÃ¹ nÃ³ cÅ©ng sá»­ dá»¥ng MLM, cÃ¡c nhiá»‡m vá»¥ khÃ¡c nhÆ° mÃ´ hÃ¬nh ngÃ´n ngá»¯ má»™t chiá»u (ULM) vÃ  DeNoiSing (DNS) cÃ³ thá»ƒ cÃ³ tÃ¡c Ä‘á»™ng báº¥t lá»£i Ä‘áº¿n cÃ¡c nhiá»‡m vá»¥ thÄƒm dÃ²; 2) UnixCoder tÃ­ch há»£p bá»™ mÃ£ hÃ³a vÃ  bá»™ giáº£i mÃ£ báº±ng cÃ¡ch chia sáº» trá»ng sá»‘ trong khi cÃ¡c biá»ƒu diá»…n tá»« bá»™ giáº£i mÃ£ cÃ³ kháº£ nÄƒng trÃ­ch xuáº¥t thÃ´ng tin kÃ©m hÆ¡n so vá»›i biá»ƒu diá»…n bá»™ mÃ£ hÃ³a [66]. Chia sáº» trá»ng sá»‘ giá»¯a bá»™ mÃ£ hÃ³a vÃ  bá»™ giáº£i mÃ£ cÃ³ thá»ƒ lÃ m háº¡i kháº£ nÄƒng cá»§a mÃ´ hÃ¬nh trong viá»‡c trÃ­ch xuáº¥t thÃ´ng tin. Ba LLM Ä‘Æ°á»£c nghiÃªn cá»©u cho tháº¥y má»™t sá»‘ khÃ¡c biá»‡t so vá»›i bá»‘n mÃ´ hÃ¬nh tiá»n huáº¥n luyá»‡n. LLM khÃ´ng cÃ³ lá»£i tháº¿ rÃµ rÃ ng so vá»›i cÃ¡c mÃ´ hÃ¬nh tiá»n huáº¥n luyá»‡n, máº·c dÃ¹ StarCoder cÃ³ 6144 chiá»u áº©n, CodeLlama cÃ³ 4096 chiá»u áº©n vÃ  CodeT5p-770m cÃ³ 1046 chiá»u áº©n. KÃ­ch thÆ°á»›c cá»§a chÃºng cao hÆ¡n nhiá»u so vá»›i cÃ¡c mÃ´ hÃ¬nh mÃ£ tiá»n huáº¥n luyá»‡n (768). Táº¥t cáº£ Ä‘á»u cÃ³ sá»‘ lÆ°á»£ng tham sá»‘ khá»•ng lá»“. Má»™t lÃ½ do cÃ³ thá»ƒ lÃ  kÃ­ch thÆ°á»›c khÃ´ng gian biá»ƒu diá»…n quÃ¡ lá»›n vÃ  bao phá»§ quÃ¡ nhiá»u thÃ´ng tin, lÃ m cho cÃ¡c Ä‘áº·c trÆ°ng cÃº phÃ¡p nhÃºng khÃ³ quan sÃ¡t.

TÃ³m láº¡i, tá»« Pháº§n 5.1.1 vÃ  Pháº§n 5.1.2, rÃµ rÃ ng ráº±ng bá»‘n mÃ´ hÃ¬nh mÃ£ tiá»n huáº¥n luyá»‡n vÃ  3 mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n cÃ³ thá»ƒ mÃ£ hÃ³a cÃº phÃ¡p mÃ£, cáº£ vá» má»‘i quan há»‡ cÃº phÃ¡p giá»¯a cÃ¡c token (dá»± Ä‘oÃ¡n Cáº·p NÃºt CÃº phÃ¡p) vÃ  vai trÃ² cÃº phÃ¡p token riÃªng láº» (Gáº¯n Tháº» CÃº PhÃ¡p Token). CÃ¡c Ä‘áº·c trÆ°ng cÃº phÃ¡p khÃ¡c nhau cÃ³ má»©c Ä‘á»™ khÃ³ khÄƒn khÃ¡c nhau trong viá»‡c Ä‘Æ°á»£c quan sÃ¡t á»Ÿ cÃ¡c táº§ng áº©n nÃ´ng vÃ  sÃ¢u.

5.2 PhÃ¢n TÃ­ch Ngá»¯ NghÄ©a

5.2.1 Dá»± ÄoÃ¡n Quan Há»‡ Ngá»¯ NghÄ©a. HÃ¬nh 11 trÃ¬nh bÃ y hiá»‡u suáº¥t thÄƒm dÃ² cá»§a bá»‘n mÃ´ hÃ¬nh mÃ£ tiá»n huáº¥n luyá»‡n, CodeBERT (CB), GraphCodeBERT (GCB), UnixCoder (UC), vÃ  CodeT5 (CT5) trÃªn nhiá»‡m vá»¥ dá»± Ä‘oÃ¡n quan há»‡ ngá»¯ nghÄ©a. ChÃºng tÃ´i Ä‘Ã£ tiáº¿n hÃ nh so sÃ¡nh hiá»‡u suáº¥t thÄƒm dÃ² trÃªn ba ngá»¯ nghÄ©a chÆ°Æ¡ng trÃ¬nh khÃ¡c nhau: phá»¥ thuá»™c Ä‘iá»u khiá»ƒn (CDG, HÃ¬nh 11a vÃ  HÃ¬nh 11b), thÃ´ng tin luá»“ng Ä‘iá»u khiá»ƒn (CFG, HÃ¬nh 11c vÃ  HÃ¬nh 11d), vÃ  phá»¥ thuá»™c dá»¯ liá»‡u (DDG, HÃ¬nh 11e

J. ACM, Vol. 37, No. 4, Article 111. NgÃ y xuáº¥t báº£n: ThÃ¡ng 8 2018.

--- TRANG 15 ---
KhÃ¡m PhÃ¡ CÃ¡c MÃ´ HÃ¬nh Tiá»n Huáº¥n Luyá»‡n MÃ£: NghiÃªn Cá»©u Kháº£ NÄƒng CÃº PhÃ¡p vÃ  Ngá»¯ NghÄ©a 111:15

[THIS IS FIGURE: Multiple graphs showing performance metrics across different layers:
- Figure 8 (a-c): Performance (MCC) for Java250 and POJ-104 for Syntax Pair Node prediction (AST)
- Figure 9 (a-d): Performance for Java250 and POJ-104 for Token Syntax Tagging (MCC and F1)
- Figure 10 (a-b): Performance for Java250 for Syntax Pair Node prediction (AST) and Token Syntax Tagging for LLMs]

vÃ  HÃ¬nh 11f). Thá»© nháº¥t, rÃµ rÃ ng ráº±ng CodeT5 thá»ƒ hiá»‡n kháº£ nÄƒng cao nháº¥t trong viá»‡c hiá»ƒu ngá»¯ nghÄ©a chÆ°Æ¡ng trÃ¬nh, tá»©c lÃ  CDG vÃ  DDG, Ä‘áº·c biá»‡t trong vÃ i táº§ng cuá»‘i, vÃ  GraphCodeBERT Ä‘Æ°á»£c chá»©ng minh tá»‘t hÆ¡n má»™t chÃºt so vá»›i CodeT5 vá» CFG. Thá»© hai, CodeBERT cÅ©ng cÃ³ kháº£ nÄƒng mÃ£ hÃ³a ngá»¯ nghÄ©a chÆ°Æ¡ng trÃ¬nh, máº·c dÃ¹ khÃ´ng sá»­ dá»¥ng thÃ´ng tin luá»“ng dá»¯ liá»‡u trong quÃ¡ trÃ¬nh tiá»n huáº¥n luyá»‡n. VÃ­ dá»¥, MCC Ä‘áº¡t trÃªn 60% trong CDG vÃ  DDG. Äiá»u nÃ y cho tháº¥y ráº±ng nhiá»‡m vá»¥ tiá»n huáº¥n luyá»‡n MÃ´ hÃ¬nh NgÃ´n ngá»¯ CÃ³ Máº·t Náº¡ (MLM) cÃ³ thá»ƒ há»— trá»£ mÃ´ hÃ¬nh trong viá»‡c há»c ngá»¯ nghÄ©a mÃ£. UnixCoder hoáº¡t Ä‘á»™ng kÃ©m hiá»‡u quáº£ hÆ¡n trong viá»‡c biá»ƒu diá»…n ngá»¯ nghÄ©a mÃ£ so vá»›i ba mÃ´ hÃ¬nh khÃ¡c, Ä‘áº·c biá»‡t sau ğ¿ğ‘ğ‘¦ğ‘’ğ‘Ÿ 7.

J. ACM, Vol. 37, No. 4, Article 111. NgÃ y xuáº¥t báº£n: ThÃ¡ng 8 2018.

--- TRANG 16 ---
111:16 W. Ma, S. Liu vÃ  M. Zhao et al.

HÃ¬nh 12 thá»ƒ hiá»‡n hiá»‡u suáº¥t thÄƒm dÃ² cá»§a ba LLM, CodeLlama, StarCoder vÃ  CodeT5+, trÃªn ba nhiá»‡m vá»¥ hiá»ƒu ngá»¯ nghÄ©a mÃ£, CDG, CFG vÃ  DDG. So vá»›i mÃ´ hÃ¬nh mÃ£ tiá»n huáº¥n luyá»‡n, biá»ƒu diá»…n tá»« táº§ng nÃ´ng cá»§a LLM lÃ m cho viá»‡c quan sÃ¡t ba thÃ´ng tin ngá»¯ nghÄ©a cá»§a mÃ£ dá»… dÃ ng hÆ¡n. Khi chÃºng tÃ´i so sÃ¡nh StarCoder vá»›i CodeLlama vÃ  CodeT5+, chÃºng tÃ´i tháº¥y ráº±ng hiá»‡u suáº¥t cá»§a StarCoder giáº£m Ä‘Ã¡ng ká»ƒ Ä‘á»‘i vá»›i cÃ¡c táº§ng sÃ¢u. VÃ¬ cÃ¡c LLM hiá»‡n táº¡i cÃ³ kháº£ nÄƒng kháº©n cáº¥p, chÃºng ta cÃ³ thá»ƒ nghÄ© LLM Ä‘Ã£ há»c ba ngá»¯ nghÄ©a mÃ£ trong khi chÃºng khÃ´ng dá»… quan sÃ¡t. HÆ¡n ná»¯a, cÃ¡ch gÃ¢y ra biá»ƒu diá»…n ngá»¯ nghÄ©a mÃ£ cá»§a LLM Ä‘á»ƒ dá»… quan sÃ¡t hÆ¡n trong viá»‡c nháº¯c LLM, tá»« Ä‘Ã³ cáº£i thiá»‡n cháº¥t lÆ°á»£ng cÃ¢u tráº£ lá»i cá»§a mÃ´ hÃ¬nh, lÃ  má»™t chá»§ Ä‘á» Ä‘Ã¡ng nghiÃªn cá»©u trong tÆ°Æ¡ng lai.

Khi so sÃ¡nh hiá»‡u suáº¥t cá»§a cÃ¡c mÃ´ hÃ¬nh mÃ£ trÃªn CDG, CFG vÃ  DDG, rÃµ rÃ ng ráº±ng cÃ¡c mÃ´ hÃ¬nh mÃ£ thá»ƒ hiá»‡n MCC tháº¥p nháº¥t trÃªn CFG, MCC cao hÆ¡n trÃªn DDG vÃ  MCC cao nháº¥t trÃªn CDG tÆ°Æ¡ng á»©ng. Äiá»u nÃ y cho tháº¥y ráº±ng cÃ¡c mÃ´ hÃ¬nh mÃ£ gáº·p khÃ³ khÄƒn trong viá»‡c náº¯m báº¯t ngá»¯ nghÄ©a luá»“ng Ä‘iá»u khiá»ƒn (CFG) hiá»‡u quáº£ nhÆ° hai loáº¡i ngá»¯ nghÄ©a khÃ¡c. CFG lÃ  má»™t xáº¥p xá»‰ dáº¥u váº¿t thá»±c thi cá»§a chÆ°Æ¡ng trÃ¬nh. LLM Ä‘Æ°á»£c chá»‰ ra thiáº¿u kháº£ nÄƒng xá»­ lÃ½ cÃ¡c nhiá»‡m vá»¥ liÃªn quan Ä‘áº¿n thá»±c thi mÃ£ [46]. CÃ¡c nhÃ  huáº¥n luyá»‡n mÃ´ hÃ¬nh cáº§n xem xÃ©t cÃ¡ch cáº£i thiá»‡n hiá»ƒu biáº¿t vá» hÃ nh vi Ä‘á»™ng mÃ£ cá»§a LLM.

5.2.2 Lan Truyá»n Ngá»¯ NghÄ©a (inGraph). HÃ¬nh 13 minh há»a káº¿t quáº£ thÄƒm dÃ² cá»§a bá»‘n mÃ´ hÃ¬nh tiá»n huáº¥n luyá»‡n trÃªn nhiá»‡m vá»¥ inGraph. RÃµ rÃ ng ráº±ng GraphCodeBERT vÆ°á»£t trá»™i hÆ¡n cÃ¡c mÃ´ hÃ¬nh khÃ¡c vá» lan truyá»n ngá»¯ nghÄ©a cho CDG vÃ  DDG trÃªn táº­p dá»¯ liá»‡u Java250. CodeT5 tá»‘t hÆ¡n trÃªn POJ-104 vá» CDG. Tuy nhiÃªn, cáº£ GraphCodeBERT vÃ  CodeT5 Ä‘á»u thá»ƒ hiá»‡n hiá»‡u suáº¥t tÆ°Æ¡ng tá»± trÃªn POJ-104 vá» DDG. Äiá»u nÃ y cho tháº¥y ráº±ng viá»‡c lan truyá»n dá»¯ liá»‡u Ä‘Æ°á»£c sá»­ dá»¥ng bá»Ÿi GraphCodeBERT tá» ra cÃ³ lá»£i trong viá»‡c náº¯m báº¯t lan truyá»n ngá»¯ nghÄ©a trong mÃ£. HÆ¡n ná»¯a, chÃºng tÃ´i quan sÃ¡t ráº±ng CodeBERT cÃ³ thá»ƒ mÃ£ hÃ³a ngá»¯ nghÄ©a mÃ£, máº·c dÃ¹ vá»›i hiá»‡u suáº¥t tháº¥p hÆ¡n so vá»›i CodeT5 vÃ  GraphCodeBERT. Tuy nhiÃªn, UnixCoder hoáº¡t Ä‘á»™ng tá»‡ hÆ¡n cÃ¡c mÃ´ hÃ¬nh khÃ¡c, Ä‘áº·c biá»‡t sau ğ¿ğ‘ğ‘¦ğ‘’ğ‘Ÿ 7. Khi so sÃ¡nh hiá»‡u suáº¥t cá»§a cÃ¡c mÃ´ hÃ¬nh giá»¯a CDG vÃ  DDG, chÃºng ta cÃ³ thá»ƒ tháº¥y ráº±ng cÃ¡c mÃ´ hÃ¬nh thá»ƒ hiá»‡n MCC cao hÆ¡n trÃªn DDG so vá»›i CDG, cÃ³ nghÄ©a lÃ  lan truyá»n phá»¥ thuá»™c dá»¯ liá»‡u Ä‘Æ°á»£c mÃ£ hÃ³a tá»‘t hÆ¡n lan truyá»n phá»¥ thuá»™c Ä‘iá»u khiá»ƒn bá»Ÿi 4 mÃ´ hÃ¬nh mÃ£ tiá»n huáº¥n luyá»‡n nÃ y. Äá»‘i vá»›i cÃ¡c LLM, chÃºng tÃ´i quan sÃ¡t ráº±ng cÃ¡c táº§ng nÃ´ng cÃ³ hiá»‡u suáº¥t tá»‘t hÆ¡n cÃ¡c táº§ng sÃ¢u. Äá»‘i vá»›i CodeT5+, hiá»‡n tÆ°á»£ng nÃ y tháº­m chÃ­ rÃµ rÃ ng hÆ¡n vÃ  cÃ³ sá»± sá»¥t giáº£m máº¡nh giá»¯a bá»™ mÃ£ hÃ³a vÃ  bá»™ giáº£i mÃ£ (ğ¿ğ‘ğ‘¦ğ‘’ğ‘Ÿ 24 vÃ  ğ¿ğ‘ğ‘¦ğ‘’ğ‘Ÿ 25). Má»™t giáº£i thÃ­ch cÃ³ thá»ƒ lÃ  kháº£ nÄƒng cá»§a cÃ¡c biá»ƒu diá»…n mÃ£ cho bá»™ giáº£i mÃ£ Ä‘á»ƒ biá»ƒu Ä‘áº¡t cÃ¡c phá»¥ thuá»™c dÃ i bá»‹ giáº£m sÃºt vÃ¬ bá»™ giáº£i mÃ£ chá»‰ cÃ³ thá»ƒ tháº¥y thÃ´ng tin token trÆ°á»›c Ä‘Ã³, vÃ  cÃ¡c token tÆ°Æ¡ng lai bá»‹ che máº·t. Náº¿u chÃºng ta xem HÃ¬nh 12 cho phá»¥ thuá»™c ngáº¯n (xÃ¢y dá»±ng cÃ¡c Ä‘á»“ thá»‹ ngá»¯ nghÄ©a), chÃºng ta cÃ³ thá»ƒ tháº¥y ráº±ng cÃ³ sá»± sá»¥t giáº£m hiá»‡u suáº¥t giá»¯a bá»™ mÃ£ hÃ³a vÃ  bá»™ giáº£i mÃ£ (ğ¿ğ‘ğ‘¦ğ‘’ğ‘Ÿ 24 vÃ  ğ¿ğ‘ğ‘¦ğ‘’ğ‘Ÿ 25) cá»§a CodeT5+ vÃ  cÃ¡c sá»¥t giáº£m trá»Ÿ nÃªn rÃµ rÃ ng hÆ¡n Ä‘á»‘i vá»›i phá»¥ thuá»™c dÃ i.

J. ACM, Vol. 37, No. 4, Article 111. NgÃ y xuáº¥t báº£n: ThÃ¡ng 8 2018.

--- TRANG 17 ---
KhÃ¡m PhÃ¡ CÃ¡c MÃ´ HÃ¬nh Tiá»n Huáº¥n Luyá»‡n MÃ£: NghiÃªn Cá»©u Kháº£ NÄƒng CÃº PhÃ¡p vÃ  Ngá»¯ NghÄ©a 111:17

[THIS IS FIGURE: Multiple charts showing performance (MCC) graphs for various models across different layers and tasks including CDG, CFG, and DDG for Java250 and POJ-104 datasets. Charts are labeled from (a) to (f) showing different semantic relations.]

HÃ¬nh 11. Hiá»‡u suáº¥t (MCC) vá» Java250 vÃ  POJ-104 cho Quan Há»‡ Ngá»¯ NghÄ©a.

[THIS IS FIGURE: Three charts showing LLM Performance (MCC) for Java250 across different layers for CDG, CFG, and DDG semantic relations.]

HÃ¬nh 12. Hiá»‡u Suáº¥t LLM (MCC) vá» Java250 cho Quan Há»‡ Ngá»¯ NghÄ©a.

J. ACM, Vol. 37, No. 4, Article 111. NgÃ y xuáº¥t báº£n: ThÃ¡ng 8 2018.

--- TRANG 18 ---
111:18 W. Ma, S. Liu vÃ  M. Zhao et al.

[THIS IS FIGURE: Four graphs labeled (a) Java250-CDG, (b) POJ-104-CDG, (c) Java250-DDG, and (d) POJ-104-DDG showing performance metrics (MCC %) across different layers for CB, GCB, UC, and CT5 models]

HÃ¬nh 13. Hiá»‡u suáº¥t (MCC) vá» Java250 vÃ  POJ-104 cho inGraph.

[THIS IS FIGURE: Two graphs labeled (a) Java250-CDG and (b) Java250-DDG showing LLM Performance (MCC %) across layers for CL, SC, and CT5+ models]

HÃ¬nh 14. Hiá»‡u Suáº¥t LLM (MCC) vá» Java250 vÃ  POJ-104 cho inGraph.

Báº£ng 3. Sá»‘ LÆ°á»£ng Äáº§u ChÃº Ã Ngá»¯ NghÄ©a trÃªn Java250 / POJ-104.

[THIS IS TABLE: A table showing attention heads for CodeBERT, GraphCodeBERT, UnixCoder, and CodeT5 across CDG, CFG, and DDG metrics]
CodeBERT GraphCodeBERT UnixCoder CodeT5
CDG 65 / 93    71 / 86       50 / 44    77 / 91
CFG 129 / 141  136 / 139     99 / 82    130 / 128
DDG 133 / 115  135 / 124     23 / 58    111 / 120

Äá»ƒ tÃ³m táº¯t cÃ¡c phÃ¡t hiá»‡n tá»« Pháº§n 5.2.1 vÃ  Pháº§n 5.2.2, táº¥t cáº£ bá»‘n mÃ´ hÃ¬nh mÃ£ tiá»n huáº¥n luyá»‡n Ä‘á»u cÃ³ kháº£ nÄƒng há»c ngá»¯ nghÄ©a mÃ£. Tuy nhiÃªn, kháº£ nÄƒng mÃ£ hÃ³a ngá»¯ nghÄ©a cá»§a chÃºng khÃ¡c nhau qua cÃ¡c loáº¡i ngá»¯ nghÄ©a khÃ¡c nhau. Äá»‘i vá»›i nhÃ³m LLM, biá»ƒu diá»…n tá»« cÃ¡c táº§ng nÃ´ng lÃ m cho viá»‡c quan sÃ¡t ngá»¯ nghÄ©a mÃ£ dá»… dÃ ng hÆ¡n. Kháº£ nÄƒng mÃ£ hÃ³a thÃ´ng tin thá»±c thi mÃ£ nÃªn Ä‘Æ°á»£c tÄƒng cÆ°á»ng cho LLM.

5.3 PhÃ¢n TÃ­ch ChÃº Ã

Dá»±a trÃªn cÃ¡c phÃ¢n tÃ­ch Ä‘Ã£ Ä‘á» cáº­p á»Ÿ trÃªn, chÃºng tÃ´i Ä‘Ã£ quan sÃ¡t ráº±ng cÃ¡c mÃ´ hÃ¬nh mÃ£ tiá»n huáº¥n luyá»‡n vÃ  mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n (LLM) thá»ƒ hiá»‡n kháº£ nÄƒng tá»‘t hoáº·c trung bÃ¬nh trong viá»‡c há»c cÃº phÃ¡p vÃ  ngá»¯ nghÄ©a mÃ£. Äá»ƒ cÃ³ thÃªm hiá»ƒu biáº¿t vá» cÃ¡ch nhá»¯ng mÃ´ hÃ¬nh nÃ y mÃ£ hÃ³a ngá»¯ nghÄ©a, chÃºng tÃ´i Ä‘Ã£ tiáº¿n hÃ nh Ä‘iá»u tra vai trÃ² cá»§a cÃ¡c Ä‘áº§u tá»±-chÃº Ã½ trong viá»‡c há»c ngá»¯ nghÄ©a mÃ£, sá»­ dá»¥ng táº­p dá»¯ liá»‡u hÆ¡n 10.000 Ä‘áº§u vÃ o ngá»¯ nghÄ©a cho cÃ¡c mÃ´ hÃ¬nh mÃ£ tiá»n huáº¥n luyá»‡n vÃ  láº¥y máº«u ngáº«u nhiÃªn 100 Ä‘áº§u vÃ o ngá»¯ nghÄ©a cho LLM. Má»—i má»™t trong cÃ¡c mÃ´ hÃ¬nh tiá»n huáº¥n luyá»‡n cÃ³ 144 Ä‘áº§u chÃº Ã½ tá»•ng cá»™ng tÆ°Æ¡ng á»©ng. StarCoder cÃ³ 1920 Ä‘áº§u chÃº Ã½, CodeLlama cÃ³ 960 Ä‘áº§u chÃº Ã½ vÃ  CodeT5+ Decoder/Encoder cÃ³ 384 Ä‘áº§u chÃº Ã½.

J. ACM, Vol. 37, No. 4, Article 111. NgÃ y xuáº¥t báº£n: ThÃ¡ng 8 2018.

--- TRANG 19 ---
KhÃ¡m PhÃ¡ CÃ¡c MÃ´ HÃ¬nh Tiá»n Huáº¥n Luyá»‡n MÃ£: NghiÃªn Cá»©u Kháº£ NÄƒng CÃº PhÃ¡p vÃ  Ngá»¯ NghÄ©a 111:19

Báº£ng 4. Sá»‘ LÆ°á»£ng Äáº§u ChÃº Ã Ngá»¯ NghÄ©a cá»§a LLM trÃªn Java250 / POJ-104.

[THIS IS TABLE:
StarCoder  CodeLlama  CodeT5+ Decoder  CodeT5+ Encoder
CDG  0/0      0/0       0/0            199/252
CFG  1372/1844  423/830   371/340       315/319
DDG  1253/1892  100/977   318/146       247/208]

Trong Báº£ng 3 vÃ  Báº£ng 4, chÃºng tÃ´i trÃ¬nh bÃ y sá»‘ lÆ°á»£ng Ä‘áº§u chÃº Ã½ há»c ngá»¯ nghÄ©a mÃ£ má»™t cÃ¡ch Ä‘Ã¡ng ká»ƒ vá» CDG, CFG vÃ  DDG (cÃ³ Ã½ nghÄ©a thá»‘ng kÃª á»Ÿ ngÆ°á»¡ng p-value 0.01) cho cÃ¡c mÃ´ hÃ¬nh tiá»n huáº¥n luyá»‡n vÃ  LLM vá» cÃ¡c táº­p dá»¯ liá»‡u Java250 vÃ  POJ-104 tÆ°Æ¡ng á»©ng. Trong Báº£ng 3, rÃµ rÃ ng ráº±ng UnixCoder cÃ³ sá»‘ lÆ°á»£ng Ä‘áº§u chÃº Ã½ Ã­t nháº¥t dÃ nh cho ngá»¯ nghÄ©a. Äiá»u nÃ y phÃ¹ há»£p vá»›i káº¿t luáº­n trÆ°á»›c Ä‘Ã³ ráº±ng UnixCoder khÃ´ng tá»‘t hÆ¡n cÃ¡c mÃ´ hÃ¬nh khÃ¡c vá» mÃ£ hÃ³a cÃº phÃ¡p vÃ  ngá»¯ nghÄ©a mÃ£. Trong Báº£ng 4, chÃºng ta cÃ³ thá»ƒ tháº¥y ráº±ng cÃ¡c Ä‘áº§u chÃº Ã½ cÃ³ má»‘i quan há»‡ phá»¥ thuá»™c Ä‘iá»u khiá»ƒn khÃ´ng gÃ¡n trá»ng sá»‘ nhiá»u hÆ¡n cÃ¡c Ä‘áº§u chÃº Ã½ khÃ´ng cÃ³ má»‘i quan há»‡ phá»¥ thuá»™c Ä‘iá»u khiá»ƒn Ä‘á»‘i vá»›i StarCoder, CodeLlama vÃ  CodeT5+ decoder sá»­ dá»¥ng kiáº¿n trÃºc bá»™ giáº£i mÃ£ transformer. Tuy nhiÃªn, Ä‘á»‘i vá»›i CodeT5+ encoder, tá»“n táº¡i 199/252 Ä‘áº§u chÃº Ã½ cÃ³ thá»ƒ gÃ¡n trá»ng sá»‘ nhiá»u hÆ¡n cho má»‘i quan há»‡ phá»¥ thuá»™c Ä‘iá»u khiá»ƒn. ChÃºng tÃ´i nghÄ© lÃ½ do lÃ  cÃ¡c kiáº¿n trÃºc mÃ´ hÃ¬nh khÃ¡c nhau cÃ³ thá»ƒ áº£nh hÆ°á»Ÿng Ä‘áº¿n phÃ¢n phá»‘i cá»§a cÃ¡c cÆ¡ cháº¿ chÃº Ã½. Encoder vÃ  decoder trong transformer cÃ³ cÃ¡c chá»©c nÄƒng khÃ¡c nhau. Encoder cÃ³ xu hÆ°á»›ng hiá»ƒu cáº¥u trÃºc tá»•ng thá»ƒ vÃ  bá»‘i cáº£nh cá»§a Ä‘áº§u vÃ o, trong khi decoder táº­p trung vÃ o viá»‡c táº¡o ra hoáº·c dá»± Ä‘oÃ¡n token tiáº¿p theo dá»±a trÃªn hiá»ƒu biáº¿t nÃ y. Do Ä‘Ã³, Ä‘á»‘i vá»›i cÃ¡c cÃ¢u lá»‡nh phá»¥ thuá»™c Ä‘iá»u khiá»ƒn, encoder cÃ³ thá»ƒ cáº§n chÃº Ã½ nhiá»u hÆ¡n Ä‘áº¿n nhá»¯ng má»‘i quan há»‡ nÃ y Ä‘á»ƒ hiá»ƒu cáº¥u trÃºc logic cá»§a toÃ n bá»™ mÃ£, trong khi decoder cÃ³ thá»ƒ chÃº Ã½ nhiá»u hÆ¡n Ä‘áº¿n thÃ´ng tin cá»¥c bá»™ hoáº·c thÃ´ng tin ngá»¯ nghÄ©a khÃ¡c Ä‘á»ƒ táº¡o ra, dáº«n Ä‘áº¿n cÃ¡c phÃ¢n phá»‘i trá»ng sá»‘ chÃº Ã½ khÃ¡c nhau.

ChÃºng tÃ´i tiáº¿p tá»¥c Ä‘iá»u tra sá»± trÃ¹ng láº·p cá»§a cÃ¡c Ä‘áº§u chÃº Ã½ ngá»¯ nghÄ©a gÃ¡n trá»ng sá»‘ chÃº Ã½ nhiá»u hÆ¡n cho cÃ¡c token ngá»¯ nghÄ©a giá»¯a cÃ¡c táº­p dá»¯ liá»‡u Java250 vÃ  POJ-104 cho bá»‘n mÃ´ hÃ¬nh nÃ y. Káº¿t quáº£ cho tháº¥y ráº±ng má»™t mÃ´ hÃ¬nh chia sáº» cÃ¡c Ä‘áº§u chÃº Ã½ ngá»¯ nghÄ©a qua cÃ¡c ngÃ´n ngá»¯ láº­p trÃ¬nh khÃ¡c nhau. Äá»ƒ xem xÃ©t sá»± khÃ¡c biá»‡t trong cÃ¡c Ä‘áº§u chÃº Ã½ ngá»¯ nghÄ©a giá»¯a cÃ¡c táº­p dá»¯ liá»‡u Java250 vÃ  POJ-104 qua bá»‘n mÃ´ hÃ¬nh Ä‘Æ°á»£c sá»­ dá»¥ng, chÃºng tÃ´i trÃ¬nh bÃ y tá»· lá»‡ cá»§a cÃ¡c Ä‘áº§u chÃº Ã½ ngá»¯ nghÄ©a trÃ¹ng láº·p cho má»—i mÃ´ hÃ¬nh trong cáº£ hai táº­p dá»¯ liá»‡u (Báº£ng 5 vÃ  Báº£ng 6). CÃ¡c hÃ ng Java250 vÃ  POJ-104 Ä‘Æ°á»£c tÃ­nh báº±ng hai phÆ°Æ¡ng trÃ¬nh sau tÆ°Æ¡ng á»©ng,

ğ‘Ÿğ‘—ğ‘ğ‘£ğ‘ 250=|ğ‘†ğ‘—ğ‘ğ‘£ğ‘ 250âˆ©ğ‘†ğ‘ƒğ‘‚ğ½|/|ğ‘†ğ‘—ğ‘ğ‘£ğ‘ 250|

ğ‘Ÿğ‘ğ‘œğ‘—=|ğ‘†ğ‘—ğ‘ğ‘£ğ‘ 250âˆ©ğ‘†ğ‘ƒğ‘‚ğ½|/|ğ‘†ğ‘ƒğ‘‚ğ½|

trong Ä‘Ã³ ğ‘†ğ‘—ğ‘ğ‘£ğ‘ 250 vÃ  ğ‘†ğ‘ƒğ‘‚ğ½ lÃ  táº­p há»£p cÃ¡c Ä‘áº§u chÃº Ã½ ngá»¯ nghÄ©a cho cÃ¡c táº­p dá»¯ liá»‡u Java250 vÃ  POJ-104. ÄÃ¡ng ngáº¡c nhiÃªn, máº·c dÃ¹ cÃ¡c ngÃ´n ngá»¯ láº­p trÃ¬nh riÃªng biá»‡t Ä‘Æ°á»£c Ä‘áº¡i diá»‡n trong hai táº­p dá»¯ liá»‡u, má»™t sá»± trÃ¹ng láº·p Ä‘Ã¡ng ká»ƒ Ä‘Æ°á»£c quan sÃ¡t. Máº·c dÃ¹ tá»· lá»‡ trÃ¹ng láº·p ğ‘Ÿğ‘ğ‘œğ‘— cho DDG trong CodeLlama lÃ  8.29%, Ä‘iá»u nÃ y Ä‘Æ°á»£c gÃ¢y ra do ğ‘†ğ‘ƒğ‘‚ğ½ quÃ¡ lá»›n vÃ  thá»±c táº¿ Ä‘a sá»‘ cÃ¡c Ä‘áº§u chÃº Ã½ tá»« Java250 Ä‘Æ°á»£c bao gá»“m trong ğ‘†ğ‘ƒğ‘‚ğ½ (81.00%). PhÃ¡t hiá»‡n nÃ y cho tháº¥y ráº±ng má»™t sá»‘ máº«u chÃº Ã½ ngá»¯ nghÄ©a Ä‘Æ°á»£c chia sáº» giá»¯a cÃ¡c mÃ´ hÃ¬nh mÃ£ báº¥t ká»ƒ ngÃ´n ngá»¯ láº­p trÃ¬nh nÃ o Ä‘Æ°á»£c sá»­ dá»¥ng.

6 CÃ”NG TRÃŒNH LIÃŠN QUAN

6.1 CÃ¡c MÃ´ HÃ¬nh MÃ£

CÃ¡c mÃ´ hÃ¬nh tiá»n huáº¥n luyá»‡n Ä‘Ã£ Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ há»— trá»£ nhiá»u nhiá»‡m vá»¥ do kháº£ nÄƒng tá»•ng quÃ¡t hÃ³a xuáº¥t sáº¯c cá»§a chÃºng trong cÃ¡c nhiá»‡m vá»¥ xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn. Gáº§n Ä‘Ã¢y, cÃ¡c nhÃ  nghiÃªn cá»©u tiá»n huáº¥n luyá»‡n transformers [54]

J. ACM, Vol. 37, No. 4, Article 111. NgÃ y xuáº¥t báº£n: ThÃ¡ng 8 2018.

--- TRANG 20 ---
111:20 W. Ma, S. Liu vÃ  M. Zhao et al.

Báº£ng 5. Sá»± TrÃ¹ng Láº·p cá»§a CÃ¡c Äáº§u ChÃº Ã Ngá»¯ NghÄ©a trÃªn Java250 vÃ  POJ-104, Pháº§n TrÄƒm %.

[THIS IS TABLE: Shows overlap percentages for CodeBERT, GraphCodeBERT, UnixCoder, and CodeT5 across CDG, CFG, and DDG metrics with two rows (ğ‘Ÿğ½ğ‘ğ‘£ğ‘250 and ğ‘Ÿğ‘ğ‘œğ‘—)]

Báº£ng 6. Sá»± TrÃ¹ng Láº·p cá»§a CÃ¡c Äáº§u ChÃº Ã Ngá»¯ NghÄ©a LLM trÃªn Java250 vÃ  POJ-104, Pháº§n TrÄƒm %.

[THIS IS TABLE: Shows overlap percentages for StarCoder, CodeLlama, CodeT5+ Decoder, and CodeT5+ Encoder across CDG, CFG, and DDG metrics with two rows]

sá»­ dá»¥ng dá»¯ liá»‡u mÃ£ Ä‘á»ƒ giáº£i quyáº¿t cÃ¡c nhiá»‡m vá»¥ láº­p trÃ¬nh. Theo cÃ¡c chiáº¿n lÆ°á»£c tiá»n huáº¥n luyá»‡n vÃ  kiáº¿n trÃºc mÃ´ hÃ¬nh, chÃºng ta cÃ³ thá»ƒ nhÃ³m cÃ¡c mÃ´ hÃ¬nh tiá»n huáº¥n luyá»‡n thÃ nh ba (3) loáº¡i: mÃ´ hÃ¬nh tá»±-mÃ£ hÃ³a, mÃ´ hÃ¬nh tá»±-há»“i quy vÃ  mÃ´ hÃ¬nh chuá»—i-sang-chuá»—i (Seq2Seq). CÃ¡c mÃ´ hÃ¬nh tá»±-mÃ£ hÃ³a sá»­ dá»¥ng bá»™ mÃ£ hÃ³a Transformer vÃ  Ä‘Æ°á»£c tiá»n huáº¥n luyá»‡n vá»›i cÃ¡c má»¥c tiÃªu nhÆ° MÃ´ hÃ¬nh NgÃ´n ngá»¯ CÃ³ Máº·t Náº¡ (MLM). MLM che má»™t sá»‘ token trong chuá»—i mÃ£ vÃ  mong Ä‘á»£i mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n cÃ¡c token bá»‹ che sá»­ dá»¥ng thÃ´ng tin bá»‘i cáº£nh hai chiá»u, Ä‘iá»u nÃ y thá»±c táº¿ cho phÃ©p mÃ´ hÃ¬nh sá»­ dá»¥ng cÃ¡c token tÆ°Æ¡ng lai Ä‘á»ƒ dá»± Ä‘oÃ¡n cÃ¡c token máº·t náº¡ hiá»‡n táº¡i. CodeBERT [13] Ä‘Æ°á»£c tiá»n huáº¥n luyá»‡n trÃªn táº­p dá»¯ liá»‡u CodeSearchNet [26]. GraphCodeBERT [17] bao gá»“m má»™t loáº¡i Ä‘áº§u vÃ o bá»• sung, chuá»—i luá»“ng dá»¯ liá»‡u, so vá»›i CodeBERT. CodeBERT vÃ  GraphCodeBERT sá»­ dá»¥ng bá»™ mÃ£ hÃ³a cá»§a Transformer. CÃ¡c mÃ´ hÃ¬nh tá»±-há»“i quy sá»­ dá»¥ng MÃ´ hÃ¬nh NgÃ´n ngá»¯ NhÃ¢n quáº£ (CLM) hoáº·c cÃ¡c biáº¿n thá»ƒ cá»§a nÃ³ Ä‘á»ƒ tiá»n huáº¥n luyá»‡n cÃ¡c transformer theo cÃ¡ch tá»« trÃ¡i sang pháº£i. CodeGPT [42] sá»­ dá»¥ng chiáº¿n lÆ°á»£c tiá»n huáº¥n luyá»‡n nÃ y vÃ  giá»¯ bá»™ giáº£i mÃ£ transformer. CÃ¡c mÃ´ hÃ¬nh Seq2Seq, vÃ­ dá»¥ nhÆ° CodeT5 [71], sá»­ dá»¥ng cáº£ bá»™ mÃ£ hÃ³a vÃ  bá»™ giáº£i mÃ£ trong Transformer. CommitBART [40] sá»­ dá»¥ng kiáº¿n trÃºc BART [32] Ä‘á»ƒ tiá»n huáº¥n luyá»‡n mÃ´ hÃ¬nh cho cÃ¡c commit GitHub.

Gáº§n Ä‘Ã¢y, ChatGPT vÃ  cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n khÃ¡c Ä‘Ã£ nháº­n Ä‘Æ°á»£c sá»± chÃº Ã½ Ä‘Ã¡ng ká»ƒ. Káº¿t quáº£ lÃ , má»™t sá»‘ LLM Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘áº·c biá»‡t cho láº­p trÃ¬nh Ä‘Ã£ xuáº¥t hiá»‡n. StarCoder [34] vá»›i 15B tham sá»‘ Ä‘Æ°á»£c huáº¥n luyá»‡n sá»­ dá»¥ng 1 nghÃ¬n tá»· token Ä‘Æ°á»£c phÃ¡t hÃ nh. CodeLlama [58] Ä‘Æ°á»£c tinh chá»‰nh dá»±a trÃªn Llama2 [65] sá»­ dá»¥ng táº­p dá»¯ liá»‡u mÃ£. WizardCoder [43] sá»­ dá»¥ng hÆ°á»›ng dáº«n tiáº¿n hÃ³a mÃ£ Ä‘á»ƒ tinh chá»‰nh trá»ng sá»‘ mÃ´ hÃ¬nh. Táº¥t cáº£ Ä‘á»u dá»±a trÃªn bá»™ giáº£i mÃ£ transformer. KhÃ¡c vá»›i chÃºng, CodeT5+ [70] sá»­ dá»¥ng kiáº¿n trÃºc mÃ£ hÃ³a-giáº£i mÃ£ nhÆ° CodeT5 [71]. LLM cho tháº¥y kháº£ nÄƒng máº¡nh máº½ trong sá»­a chá»¯a chÆ°Æ¡ng trÃ¬nh, táº¡o mÃ£ vÃ  tÃ³m táº¯t. Hou et al. [21] vÃ  Zhang et al. [78] xem xÃ©t toÃ n diá»‡n cÃ¡c á»©ng dá»¥ng cá»§a cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n trong ká»¹ thuáº­t pháº§n má»m.

Nhá»¯ng mÃ´ hÃ¬nh mÃ£ nÃ y Ä‘Æ°á»£c sá»­ dá»¥ng rá»™ng rÃ£i Ä‘á»ƒ giáº£i quyáº¿t cÃ¡c nhiá»‡m vá»¥ ká»¹ thuáº­t pháº§n má»m khÃ¡c nhau [21,48,62,78], nhÆ° phÃ¡t hiá»‡n khuyáº¿t Ä‘iá»ƒm, tÃ³m táº¯t mÃ£, sá»­a chá»¯a lá»— há»•ng vÃ  Ä‘á»‹nh vá»‹ lá»—i. TrÆ°á»›c khi xuáº¥t hiá»‡n Há»c viÃªn MÃ´ hÃ¬nh NgÃ´n ngá»¯ (LLM), nhá»¯ng mÃ´ hÃ¬nh há»c sÃ¢u nÃ y Ä‘Æ°á»£c sá»­ dá»¥ng theo hai cÃ¡ch trong ká»¹ thuáº­t pháº§n má»m [35,73]: 1) ThÃªm má»™t mÃ´ hÃ¬nh nhiá»‡m vá»¥ lÃªn trÃªn nhá»¯ng mÃ´ hÃ¬nh mÃ£ nÃ y vÃ  tinh chá»‰nh trá»ng sá»‘ cá»§a toÃ n bá»™ mÃ´ hÃ¬nh. 2) Nhá»¯ng mÃ´ hÃ¬nh nÃ y Ä‘Æ°á»£c sá»­ dá»¥ng nhÆ° trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng, vÃ  cÃ¡c thuáº­t toÃ¡n khÃ¡c Ä‘Æ°á»£c Ã¡p dá»¥ng sau khi trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng. So vá»›i phÆ°Æ¡ng phÃ¡p Ä‘áº§u tiÃªn, phÆ°Æ¡ng phÃ¡p thá»© hai khÃ´ng yÃªu cáº§u tinh chá»‰nh trá»ng sá»‘ cá»§a mÃ´ hÃ¬nh. Sau khi xuáº¥t hiá»‡n LLM, cÃ¡c phÆ°Æ¡ng phÃ¡p há»c dá»±a trÃªn há»c trong bá»‘i cáº£nh [7] dáº§n dáº§n Ä‘Æ°á»£c cháº¥p nháº­n vÃ  sá»­ dá»¥ng. Nhá»¯ng mÃ´ hÃ¬nh nÃ y thÆ°á»ng khÃ´ng Ä‘Æ°á»£c sá»­ dá»¥ng má»™t mÃ¬nh mÃ  nhÆ° má»™t bÆ°á»›c trong quy trÃ¬nh cÃ´ng viá»‡c. HÆ¡n ná»¯a, cÃ¡c nhÃ  nghiÃªn cá»©u sáº½ sá»­ dá»¥ng kiáº¿n thá»©c lÄ©nh vá»±c Ä‘á»ƒ xÃ¡c Ä‘á»‹nh cÃ¡ch sá»­ dá»¥ng mÃ´ hÃ¬nh mÃ£ cho cÃ¡c tÃ¬nh huá»‘ng cá»¥ thá»ƒ. Máº·c dÃ¹ cÃ³ nhiá»u phÆ°Æ¡ng phÃ¡p cho cÃ¡c nhiá»‡m vá»¥ ká»¹ thuáº­t pháº§n má»m khÃ¡c nhau dá»±a trÃªn mÃ´ hÃ¬nh mÃ£ cÃ³ sáºµn ngÃ y nay vÃ  cÃ¡c nhÃ  nghiÃªn cá»©u cá»‘ gáº¯ng giáº£i thÃ­ch tá»«ng bÆ°á»›c cá»§a phÆ°Æ¡ng phÃ¡p cá»§a há» cÃ ng nhiá»u cÃ ng tá»‘t, viá»‡c sá»­ dá»¥ng mÃ´ hÃ¬nh mÃ£ nhÆ° má»™t há»™p Ä‘en cÃ³ thá»ƒ

J. ACM, Vol. 37, No. 4, Article 111. NgÃ y xuáº¥t báº£n: ThÃ¡ng 8 2018.

--- TRANG 21 ---
KhÃ¡m PhÃ¡ CÃ¡c MÃ´ HÃ¬nh Tiá»n Huáº¥n Luyá»‡n MÃ£: NghiÃªn Cá»©u Kháº£ NÄƒng CÃº PhÃ¡p vÃ  Ngá»¯ NghÄ©a 111:21

lÃ m giáº£m giÃ¡ trá»‹ nhá»¯ng lá»i giáº£i thÃ­ch nÃ y á»Ÿ má»™t má»©c Ä‘á»™ nÃ o Ä‘Ã³. CÃ´ng trÃ¬nh cá»§a chÃºng tÃ´i nháº±m giÃºp cÃ¡c ká»¹ sÆ° pháº§n má»m hiá»ƒu cÃ¡ch cÃ¡c mÃ´ hÃ¬nh hiá»ƒu cÃº phÃ¡p vÃ  ngá»¯ nghÄ©a mÃ£ cÃ ng nhiá»u cÃ ng tá»‘t.

6.2 PhÃ¢n TÃ­ch ThÄƒm DÃ² cho CÃ¡c MÃ´ HÃ¬nh MÃ£

Hiá»‡u suáº¥t áº¥n tÆ°á»£ng cá»§a cÃ¡c mÃ´ hÃ¬nh tiá»n huáº¥n luyá»‡n kÃ­ch thÃ­ch nhiá»u cÃ´ng trÃ¬nh cá»‘ gáº¯ng diá»…n giáº£i vÃ  hiá»ƒu nhá»¯ng mÃ´ hÃ¬nh há»™p Ä‘en quy mÃ´ lá»›n má»›i Ä‘Æ°á»£c phÃ¡t minh nÃ y. Nhá»¯ng cÃ´ng trÃ¬nh phÃ¢n tÃ­ch nÃ y cÃ³ thá»ƒ giÃºp ngÆ°á»i dÃ¹ng hiá»ƒu vÃ  Ã¡p dá»¥ng cÃ¡c mÃ´ hÃ¬nh tiá»n huáº¥n luyá»‡n. ThÄƒm dÃ³ [6,57,79] lÃ  má»™t trong nhá»¯ng ká»¹ thuáº­t ná»•i báº­t nháº¥t Ä‘Æ°á»£c táº­n dá»¥ng rá»™ng rÃ£i cho kháº£ nÄƒng diá»…n giáº£i. PhÃ¢n tÃ­ch thÄƒm dÃ² nháº±m cháº©n Ä‘oÃ¡n loáº¡i quy luáº­t nÃ o Ä‘Æ°á»£c mÃ£ hÃ³a trong biá»ƒu diá»…n Ä‘Æ°á»£c trÃ­ch xuáº¥t tá»« dá»¯ liá»‡u. CÆ¡ sá»Ÿ cá»§a thÄƒm dÃ² lÃ  náº¿u má»™t bá»™ phÃ¢n loáº¡i Ä‘Æ¡n giáº£n, vÃ­ dá»¥ nhÆ° bá»™ phÃ¢n loáº¡i tuyáº¿n tÃ­nh, Ä‘Æ°á»£c xÃ¢y dá»±ng dá»±a trÃªn cÃ¡c biá»ƒu diá»…n cÃ³ thá»ƒ giáº£i quyáº¿t má»™t nhiá»‡m vá»¥ Ä‘á»§ tá»‘t, thÃ¬ cÃ¡c biá»ƒu diá»…n nÃªn chá»©a cÃ¡c Ä‘áº·c trÆ°ng thÃ´ng tin vá» nhiá»‡m vá»¥ tá»« trÆ°á»›c.

CÃ¡c cÃ´ng trÃ¬nh gáº§n Ä‘Ã¢y cá»‘ gáº¯ng phÃ¢n tÃ­ch cÃ¡c mÃ´ hÃ¬nh mÃ£ tiá»n huáº¥n luyá»‡n thÃ´ng qua thÄƒm dÃ². Wan et al. [69] Ä‘Ã¡nh giÃ¡ liá»‡u cÃ¡c mÃ´ hÃ¬nh tiá»n huáº¥n luyá»‡n cÃ³ há»c cÃº phÃ¡p ngÃ´n ngá»¯ láº­p trÃ¬nh hay khÃ´ng, vÃ  há» Ä‘o sá»‘ lÆ°á»£ng cáº¡nh giá»¯a cÃ¡c token nÃºt táº¡i AST, vÃ  cá»‘ gáº¯ng há»c khoáº£ng cÃ¡ch nÃ y trong khÃ´ng gian vector. PhÆ°Æ¡ng phÃ¡p nÃ y khÃ´ng thá»ƒ khÃ´i phá»¥c cáº¥u trÃºc AST, cho khoáº£ng cÃ¡ch giá»¯a táº¥t cáº£ cÃ¡c nÃºt. Máº·c dÃ¹ sá»‘ lÆ°á»£ng cáº¡nh giá»¯a cÃ¡c nÃºt cÃ³ thá»ƒ pháº£n Ã¡nh thÃ´ng tin cÃº phÃ¡p á»Ÿ má»™t má»©c Ä‘á»™ nÃ o Ä‘Ã³, nÃ³ váº«n cÃ³ má»™t sá»‘ váº¥n Ä‘á». Thá»© nháº¥t, nÃ³ khÃ´ng thá»ƒ tÃ¡i táº¡o cáº¥u trÃºc AST trong khÃ´ng gian vector, cÃ³ nghÄ©a lÃ  nÃ³ kiá»ƒm tra má»™t pháº§n cÃº phÃ¡p mÃ£. Thá»© hai, hai token cÃ³ cÃº phÃ¡p tÆ°Æ¡ng tá»± cÃ³ sá»‘ lÆ°á»£ng cáº¡nh nhá», nhÆ°ng sá»‘ lÆ°á»£ng cáº¡nh nhá» khÃ´ng ngá»¥ Ã½ sá»± gáº§n gÅ©i cÃº phÃ¡p nhÆ° Ä‘Æ°á»£c hiá»ƒn thá»‹ trong pháº§n Ä‘á»™ng lá»±c. HernÃ¡ndez LÃ³pez et al. [18] phÃ¢n tÃ­ch cÃ¡c mÃ´ hÃ¬nh tiá»n huáº¥n luyá»‡n á»Ÿ cáº¥p Ä‘á»™ toÃ n cá»¥c AST báº±ng cÃ¡ch chiáº¿u AST vÃ o má»™t khÃ´ng gian con. CÃ´ng trÃ¬nh nÃ y chuyá»ƒn Ä‘á»•i AST thÃ nh cÃ¢y nhá»‹ phÃ¢n Ä‘á»‹nh dáº¡ng trung gian vÃ  sau Ä‘Ã³ há»c má»™t khÃ´ng gian con sá»­ dá»¥ng khoáº£ng cÃ¡ch cÃº phÃ¡p [60] Ä‘Æ°á»£c thiáº¿t káº¿ cho ngÃ´n ngá»¯ tá»± nhiÃªn. Tuy nhiÃªn, khoáº£ng cÃ¡ch cÃº phÃ¡p cho ngÃ´n ngá»¯ tá»± nhiÃªn cÃ³ thá»ƒ khÃ´ng phÃ¹ há»£p cho dá»¯ liá»‡u mÃ£ vÃ¬ Allamanis et al. [3] liá»‡t kÃª sá»± khÃ¡c biá»‡t giá»¯a mÃ£ vÃ  ngÃ´n ngá»¯ tá»± nhiÃªn, bao gá»“m sá»± khÃ¡c biá»‡t trong cÃ¢y cÃº phÃ¡p giá»¯a ngÃ´n ngá»¯ tá»± nhiÃªn vÃ  mÃ£. NgÆ°á»£c láº¡i, phÆ°Æ¡ng phÃ¡p cá»§a chÃºng tÃ´i ngáº¯n gá»n vÃ  hiá»‡u quáº£, vÃ  chÃºng tÃ´i trá»±c tiáº¿p khÃ´i phá»¥c cáº¥u trÃºc AST tá»« khÃ´ng gian vector. NgoÃ i ra, chÃºng tÃ´i tiáº¿n hÃ nh phÃ¢n tÃ­ch ngá»¯ nghÄ©a cho mÃ£.

Troshin vÃ  Chirkova [66] phÃ¡t triá»ƒn má»™t nhÃ³m cÃ¡c nhiá»‡m vá»¥ thÄƒm dÃ² Ä‘á»ƒ kiá»ƒm tra liá»‡u cÃ¡c mÃ´ hÃ¬nh tiá»n huáº¥n luyá»‡n cÃ³ há»c cáº¥u trÃºc cÃº phÃ¡p mÃ£ vÃ  thÃ´ng tin luá»“ng dá»¯ liá»‡u hay khÃ´ng. Thá»© nháº¥t, cÃ´ng trÃ¬nh nÃ y khÃ´ng xem xÃ©t toÃ n bá»™ cáº¥u trÃºc cá»§a AST vÃ  xem xÃ©t má»™t pháº§n cÃº phÃ¡p mÃ£. Thá»© hai, cÃ´ng trÃ¬nh nÃ y khÃ´ng xem xÃ©t ngá»¯ nghÄ©a luá»“ng-Ä‘iá»u khiá»ƒn vÃ  phá»¥ thuá»™c-Ä‘iá»u khiá»ƒn. Shen et al. [59] trÃ­ch xuáº¥t cáº¥u trÃºc con cÃº phÃ¡p vÃ  dá»± Ä‘oÃ¡n má»‘i quan há»‡ cÃº phÃ¡p cá»§a chÃºng. Tuy nhiÃªn, há» thiáº¿u phÃ¢n tÃ­ch ngá»¯ nghÄ©a vÃ  chá»‰ bao gá»“m bá»‘n loáº¡i cÃº phÃ¡p: gÃ¡n, gá»i hÃ m, cÃ¢u lá»‡nh if vÃ  cáº¥u trÃºc vÃ²ng láº·p. CÃ´ng trÃ¬nh má»›i nháº¥t [45] quan sÃ¡t cÃ¡c má»‘i quan há»‡ cÃº phÃ¡p vÃ  ngá»¯ nghÄ©a vÃ  cÅ©ng nghiÃªn cá»©u cÃ¡ch LLM hiá»ƒu hÃ nh vi mÃ£ dá»±a trÃªn cÃ¡c Ä‘áº§u ra Ä‘Æ°á»£c táº¡o thÃ´ng qua há»c trong bá»‘i cáº£nh Ä‘á»ƒ phÃ¢n tÃ­ch mÃ£. CÃ´ng trÃ¬nh cá»§a chÃºng tÃ´i sá»­ dá»¥ng cÃ¡c tráº¡ng thÃ¡i bÃªn trong cá»§a cÃ¡c mÃ´ hÃ¬nh mÃ£ vÃ  nghiÃªn cá»©u toÃ n diá»‡n cÃ¡ch cÃ¡c mÃ´ hÃ¬nh mÃ£ mÃ£ hÃ³a cÃº phÃ¡p vÃ  ngá»¯ nghÄ©a mÃ£ báº±ng cÃ¡ch nháº¯m Ä‘áº¿n toÃ n bá»™ cáº¥u trÃºc cá»§a AST, cÃ¡c Ä‘á»“ thá»‹ phá»¥ thuá»™c Ä‘iá»u khiá»ƒn vÃ  dá»¯ liá»‡u, vÃ  Ä‘á»“ thá»‹ luá»“ng-Ä‘iá»u khiá»ƒn.

6.3 Kiá»ƒm Thá»­ Há»c SÃ¢u

CÃ¡c mÃ´ hÃ¬nh há»c sÃ¢u Ä‘Æ°á»£c coi nhÆ° má»™t há»‡ thá»‘ng. Máº·c dÃ¹ chÃºng ta cÃ³ thá»ƒ biáº¿t trá»ng sá»‘ cá»§a mÃ´ hÃ¬nh vÃ  phÆ°Æ¡ng phÃ¡p tÃ­nh toÃ¡n ná»™i bá»™ cá»§a nÃ³, chÃºng ta khÃ´ng biáº¿t logic ná»™i táº¡i cá»§a nÃ³. Hu et al. [23] nghiÃªn cá»©u toÃ n diá»‡n vá» kiá»ƒm thá»­ há»c sÃ¢u. Kiá»ƒm thá»­ má»™t há»‡ thá»‘ng há»™p Ä‘en nhÆ° váº­y khÃ¡ thÃ¡ch thá»©c. CÃ¡c nhÃ  nghiÃªn cá»©u ká»¹ thuáº­t pháº§n má»m ban Ä‘áº§u chá»§ yáº¿u táº­p trung vÃ o phÃ¡t hiá»‡n khuyáº¿t Ä‘iá»ƒm trong cÃ¡c há»‡ thá»‘ng há»c sÃ¢u [47]. VÃ­ dá»¥, DeepMutation [44] vÃ  DeepGini [12] Ä‘á»u Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ tÃ¬m khuyáº¿t Ä‘iá»ƒm trong cÃ¡c há»‡ thá»‘ng há»c sÃ¢u. Nhá»¯ng khuyáº¿t Ä‘iá»ƒm nÃ y thÆ°á»ng Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a lÃ  cÃ¡c Ä‘áº§u vÃ o gÃ¢y ra há»‡ thá»‘ng táº¡o ra Ä‘áº§u ra khÃ´ng chÃ­nh xÃ¡c. Má»™t khi cÃ¡c khuyáº¿t Ä‘iá»ƒm há»‡ thá»‘ng Ä‘Æ°á»£c phÃ¡t hiá»‡n, cÃ¡c nhÃ  nghiÃªn cá»©u cá»‘ gáº¯ng sá»­a chá»¯a nhá»¯ng khuyáº¿t Ä‘iá»ƒm Ä‘Ã£ phÃ¡t hiá»‡n nÃ y. NgoÃ i ra, trong cÃ¡c tÃ¬nh huá»‘ng mÃ  nhiá»u mÃ´ hÃ¬nh Ä‘Æ°á»£c sá»­ dá»¥ng cho cÃ¹ng má»™t nhiá»‡m vá»¥, cÃ¡c nhÃ  nghiÃªn cá»©u Ä‘Ã£ Ä‘á» xuáº¥t cÃ¡c cÃ¡ch Ä‘á»ƒ chá»n cÃ¡c mÃ´ hÃ¬nh cháº¥t lÆ°á»£ng cao vá»›i Ã­t khuyáº¿t Ä‘iá»ƒm [24,51,61]. CÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c kiá»ƒm thá»­ thÆ°á»ng lÃ 

J. ACM, Vol. 37, No. 4, Article 111. NgÃ y xuáº¥t báº£n: ThÃ¡ng 8 2018.

--- TRANG 22 ---
111:22 W. Ma, S. Liu vÃ  M. Zhao et al.

cÃ¡c mÃ´ hÃ¬nh giáº£i quyáº¿t cÃ¡c nhiá»‡m vá»¥ cá»¥ thá»ƒ trong tÃ¬nh huá»‘ng cá»¥ thá»ƒ. BÃªn cáº¡nh Ä‘Ã³, má»™t sá»‘ nghiÃªn cá»©u táº­p trung vÃ o kiá»ƒm thá»­ hiá»‡u suáº¥t mÃ´ hÃ¬nh trong cÃ¡c tÃ¬nh huá»‘ng khÃ´ng biáº¿t. VÃ­ dá»¥, ATC (Táº­n dá»¥ng Dá»¯ liá»‡u KhÃ´ng NhÃ£n Ä‘á»ƒ Dá»± Ä‘oÃ¡n Hiá»‡u suáº¥t NgoÃ i PhÃ¢n phá»‘i) [15], Aries [25], vÃ  OODRobustBench [33] Ä‘á»u nghiÃªn cá»©u hiá»‡u suáº¥t cá»§a cÃ¡c mÃ´ hÃ¬nh trÃªn dá»¯ liá»‡u ngoÃ i phÃ¢n phá»‘i. Quan trá»ng cáº§n nháº¥n máº¡nh ráº±ng cÃ´ng trÃ¬nh cá»§a chÃºng tÃ´i khÃ´ng pháº£i Ä‘á»ƒ phÃ¡t hiá»‡n khuyáº¿t Ä‘iá»ƒm trong mÃ´ hÃ¬nh; chÃºng tÃ´i nháº±m giáº£i thÃ­ch sá»± hiá»ƒu biáº¿t vá» cÃº phÃ¡p vÃ  ngá»¯ nghÄ©a mÃ£ cho cÃ¡c mÃ´ hÃ¬nh mÃ£. PhÃ¢n tÃ­ch thÄƒm dÃ² vÃ  kiá»ƒm thá»­ khÃ¡c nhau. PhÃ¢n tÃ­ch thÄƒm dÃ² táº­p trung vÃ o hiá»ƒu cÃ¡c cÆ¡ cháº¿ ná»™i bá»™ vÃ  biá»ƒu diá»…n kiáº¿n thá»©c cá»§a cÃ¡c mÃ´ hÃ¬nh trong khi kiá»ƒm thá»­ cÃ¡c mÃ´ hÃ¬nh mÃ£ nháº±m Ä‘Ã¡nh giÃ¡ hiá»‡u suáº¥t thá»±c táº¿ cá»§a cÃ¡c mÃ´ hÃ¬nh vÃ  xÃ¡c Ä‘á»‹nh cÃ¡c khuyáº¿t Ä‘iá»ƒm tiá»m áº©n. Cáº£ hai Ä‘á»u lÃ  cÃ¡c bÆ°á»›c khÃ´ng thá»ƒ thiáº¿u trong quÃ¡ trÃ¬nh phÃ¡t triá»ƒn vÃ  Ä‘Ã¡nh giÃ¡ cÃ¡c mÃ´ hÃ¬nh mÃ£, nhÆ°ng chÃºng táº­p trung vÃ o cÃ¡c khÃ­a cáº¡nh khÃ¡c nhau.

7 Káº¾T LUáº¬N VÃ€ THáº¢O LUáº¬N

7.1 Káº¿t Luáº­n

Trong cÃ´ng trÃ¬nh nÃ y, chÃºng tÃ´i nháº±m hiá»ƒu sÃ¢u sáº¯c hÆ¡n vá» cÃ¡ch cÃ¡c mÃ´ hÃ¬nh mÃ£ xá»­ lÃ½ vÃ  hiá»ƒu cÃ¡c cáº¥u trÃºc cÃº phÃ¡p vÃ  ngá»¯ nghÄ©a mÃ£ phá»©c táº¡p. Cá»¥ thá»ƒ, chÃºng tÃ´i Ä‘iá»u tra liá»‡u nhá»¯ng mÃ´ hÃ¬nh mÃ£ nÃ y cÃ³ thá»ƒ náº¯m báº¯t chÃ­nh xÃ¡c cÃ¡c cÃ¢y cÃº phÃ¡p (AST), phá»¥ thuá»™c Ä‘iá»u khiá»ƒn (CDG), luá»“ng Ä‘iá»u khiá»ƒn (CFG), vÃ  phá»¥ thuá»™c dá»¯ liá»‡u (DDG) trong mÃ£ báº±ng cÃ¡ch tÃ¡i táº¡o nhá»¯ng cáº¥u trÃºc cÃº phÃ¡p vÃ  ngá»¯ nghÄ©a nÃ y trong khÃ´ng gian vector hay khÃ´ng. ÄÃ¢y Ä‘á»u lÃ  cÃ¡c khÃ­a cáº¡nh cÆ¡ báº£n cá»§a hiá»ƒu chÆ°Æ¡ng trÃ¬nh. ChÃºng tÃ´i thiáº¿t káº¿ má»™t loáº¡t cÃ¡c nhiá»‡m vá»¥ thÄƒm dÃ² Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ kháº£ nÄƒng cá»§a cÃ¡c mÃ´ hÃ¬nh mÃ£ trong viá»‡c xá»­ lÃ½ cÃº phÃ¡p vÃ  ngá»¯ nghÄ©a mÃ£. ChÃºng tÃ´i khÃ¡m phÃ¡ bá»‘n mÃ´ hÃ¬nh mÃ£ tiá»n huáº¥n luyá»‡n phá»• biáº¿n: CodeBERT, GraphCodeBERT, UnixCoder, vÃ  CodeT5, vÃ  giá»›i thiá»‡u ba mÃ´ hÃ¬nh ngÃ´n ngá»¯ quy mÃ´ lá»›n (LLM): CodeLlama, StarCoder, vÃ  CodeT5+, Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ hiá»‡u suáº¥t cá»§a chÃºng trong viá»‡c hiá»ƒu cÃº phÃ¡p vÃ  ngá»¯ nghÄ©a mÃ£. NgoÃ i ra, chÃºng tÃ´i quan sÃ¡t giÃ¡n tiáº¿p cÃ¡ch cÃ¡c mÃ´ hÃ¬nh xá»­ lÃ½ cÃ¡c phá»¥ thuá»™c trong mÃ£ thÃ´ng qua phÃ¢n tÃ­ch chÃº Ã½. Tá»« cÃ¡c thÃ­ nghiá»‡m cá»§a chÃºng tÃ´i, chÃºng tÃ´i thu Ä‘Æ°á»£c má»™t sá»‘ phÃ¡t hiá»‡n thÃº vá»‹. CÃ¡c mÃ´ hÃ¬nh mÃ£ tiá»n huáº¥n luyá»‡n vÃ  LLM cÃ³ thá»ƒ biá»ƒu Ä‘áº¡t cÃº phÃ¡p mÃ£ khÃ¡ tá»‘t vÃ  náº¯m báº¯t ngá»¯ nghÄ©a mÃ£ á»Ÿ má»™t má»©c Ä‘á»™ nÃ o Ä‘Ã³, Ä‘áº·c biá»‡t trong viá»‡c xá»­ lÃ½ phá»¥ thuá»™c dá»¯ liá»‡u vÃ  phá»¥ thuá»™c Ä‘iá»u khiá»ƒn. Báº±ng cÃ¡ch so sÃ¡nh hiá»‡u suáº¥t cá»§a cÃ¡c mÃ´ hÃ¬nh khÃ¡c nhau, chÃºng tÃ´i quan sÃ¡t ráº±ng cÃ¡c mÃ´ hÃ¬nh cá»¥ thá»ƒ cÃ³ lá»£i tháº¿ khÃ¡c nhau trong cÃ¡c nhiá»‡m vá»¥ thÄƒm dÃ², cho tháº¥y hiá»‡u á»©ng khÃ¡c nhau cá»§a cÃ¡c chiáº¿n lÆ°á»£c mÃ´ hÃ¬nh vÃ  táº­p dá»¯ liá»‡u huáº¥n luyá»‡n Ä‘á»‘i vá»›i sá»± hiá»ƒu biáº¿t cá»§a cÃ¡c mÃ´ hÃ¬nh vá» cÃº phÃ¡p vÃ  ngá»¯ nghÄ©a mÃ£. Máº·c dÃ¹ LLM thá»ƒ hiá»‡n kháº£ nÄƒng há»c cÃº phÃ¡p vÃ  ngá»¯ nghÄ©a mÃ£, phÃ¢n tÃ­ch hiá»‡u suáº¥t sÃ¢u sáº¯c tiáº¿t lá»™ sá»± khÃ¡c biá»‡t trong viá»‡c trÃ¬nh bÃ y sá»± hiá»ƒu biáº¿t nÃ y trong cÃ¡c táº§ng áº©n khÃ¡c nhau, cho tháº¥y kháº£ nÄƒng tá»‘i Æ°u hÃ³a cÃ¡c chiáº¿n lÆ°á»£c tiá»n huáº¥n luyá»‡n Ä‘á»ƒ cáº£i thiá»‡n xá»­ lÃ½ ngá»¯ nghÄ©a sÃ¢u. Khi chÃºng tÃ´i sá»­ dá»¥ng cÃ¡c mÃ´ hÃ¬nh mÃ£ SOTA nhÆ° CodeLlama Ä‘á»ƒ giáº£i quyáº¿t cÃ¡c nhiá»‡m vá»¥ ká»¹ thuáº­t pháº§n má»m, chÃºng tÃ´i váº«n cáº§n thiáº¿t káº¿ cáº©n tháº­n cÃ¡c mÃ´ hÃ¬nh nhiá»‡m vá»¥ downstream vÃ¬ cÃ¡c Ä‘áº·c trÆ°ng mÃ£ Ä‘Æ°á»£c trÃ­ch xuáº¥t bá»Ÿi cÃ¡c mÃ´ hÃ¬nh lá»›n bá»‹ áº©n sÃ¢u vÃ  khÃ´ng dá»… quan sÃ¡t.

7.2 Tháº£o Luáº­n

NghiÃªn cá»©u cá»§a chÃºng tÃ´i cung cáº¥p nhá»¯ng hiá»ƒu biáº¿t cÃ³ giÃ¡ trá»‹ Ä‘á»ƒ hiá»ƒu vÃ  cáº£i thiá»‡n kháº£ nÄƒng cá»§a cÃ¡c mÃ´ hÃ¬nh mÃ£ vÃ  Ä‘áº·t ra nhá»¯ng cÃ¢u há»i thÃ¡ch thá»©c vÃ  cÆ¡ há»™i cho cÃ¡c hÆ°á»›ng nghiÃªn cá»©u tÆ°Æ¡ng lai. Dá»±a trÃªn cÃ¡c phÃ¡t hiá»‡n cá»§a chÃºng tÃ´i, chÃºng tÃ´i tin ráº±ng nghiÃªn cá»©u tÆ°Æ¡ng lai nÃªn táº­p trung vÃ o má»™t sá»‘ lÄ©nh vá»±c chÃ­nh: 1). Tá»‘i Æ°u hÃ³a thÃªm kiáº¿n trÃºc vÃ  chiáº¿n lÆ°á»£c huáº¥n luyá»‡n cá»§a cÃ¡c mÃ´ hÃ¬nh mÃ£ Ä‘á»ƒ tÄƒng cÆ°á»ng kháº£ nÄƒng hiá»ƒu ngá»¯ nghÄ©a mÃ£ phá»©c táº¡p cá»§a chÃºng. Äiá»u nÃ y cÃ³ thá»ƒ bao gá»“m viá»‡c khÃ¡m phÃ¡ cÃ¡c kiáº¿n trÃºc máº¡ng tháº§n kinh má»›i, má»¥c tiÃªu huáº¥n luyá»‡n vÃ  ká»¹ thuáº­t tÄƒng cÆ°á»ng dá»¯ liá»‡u. Má»™t giáº£i phÃ¡p cÃ³ thá»ƒ lÃ  sá»­ dá»¥ng graph transformer [37,77] Ä‘á»ƒ trá»±c tiáº¿p há»c cÃ¡c cáº¥u trÃºc cÃº phÃ¡p vÃ  ngá»¯ nghÄ©a cá»§a mÃ£. Ma et al. [49] Ä‘Ã£ chá»©ng minh ráº±ng máº¡ng tháº§n kinh Ä‘á»“ thá»‹ cÃ³ thá»ƒ hoáº¡t Ä‘á»™ng cÅ©ng nhÆ° transformer nhÆ°ng vá»›i Ã­t tham sá»‘ hÆ¡n. Graph transformer káº¿t há»£p Æ°u Ä‘iá»ƒm cá»§a máº¡ng tháº§n kinh Ä‘á»“ thá»‹ vÃ  transformer: mÃ£ hÃ³a cáº¥u trÃºc Ä‘á»“ thá»‹ vÃ  há»c tá»« corpus lá»›n. 2). KhÃ¡m phÃ¡ cÃ¡c nhiá»‡m vá»¥ thÄƒm dÃ² má»›i vÃ  phÆ°Æ¡ng phÃ¡p Ä‘Ã¡nh giÃ¡ Ä‘á»ƒ tiáº¿p tá»¥c tiáº¿t lá»™ hoáº¡t Ä‘á»™ng ná»™i bá»™ cá»§a cÃ¡c mÃ´ hÃ¬nh mÃ£, Ä‘áº·c biá»‡t kháº£ nÄƒng cá»§a cÃ¡c mÃ´ hÃ¬nh dá»±a trÃªn bá»™ giáº£i mÃ£ Ä‘á»ƒ hiá»ƒu mÃ£. Äiá»u nÃ y cÃ³ thá»ƒ bao gá»“m viá»‡c phÃ¡t triá»ƒn cÃ¡c thÆ°á»›c Ä‘o má»›i Ä‘á»ƒ Ä‘o lÆ°á»ng hiá»ƒu biáº¿t mÃ£, cÅ©ng nhÆ° thiáº¿t káº¿ cÃ¡c vÃ­ dá»¥ Ä‘á»‘i nghá»‹ch Ä‘á»ƒ kiá»ƒm tra tÃ­nh máº¡nh máº½ cá»§a cÃ¡c mÃ´ hÃ¬nh mÃ£. 3). Äiá»u tra má»‘i quan há»‡ giá»¯a tÃ­nh máº¡nh máº½ cá»§a cÃ¡c mÃ´ hÃ¬nh mÃ£ vÃ  kháº£ nÄƒng hiá»ƒu ngá»¯ nghÄ©a mÃ£ cá»§a chÃºng. Äiá»u nÃ y cÃ³ thá»ƒ bao gá»“m viá»‡c nghiÃªn cá»©u cÃ¡ch cÃ¡c loáº¡i nhiá»…u vÃ  táº¥n cÃ´ng Ä‘á»‘i nghá»‹ch khÃ¡c nhau áº£nh hÆ°á»Ÿng Ä‘áº¿n hiá»‡u suáº¥t cá»§a cÃ¡c mÃ´ hÃ¬nh mÃ£ vÃ  phÃ¡t triá»ƒn cÃ¡c phÆ°Æ¡ng phÃ¡p Ä‘á»ƒ cáº£i thiá»‡n tÃ­nh máº¡nh máº½ cá»§a chÃºng trong khi duy trÃ¬ kháº£ nÄƒng hiá»ƒu mÃ£. NhÃ¬n vá» phÃ­a trÆ°á»›c, cÃ¡c mÃ´ hÃ¬nh mÃ£ ngÃ y cÃ ng Ä‘Æ°á»£c sá»­ dá»¥ng cho phÃ¡t triá»ƒn pháº§n má»m. CÃ´ng trÃ¬nh cá»§a chÃºng tÃ´i Ä‘Ã£ lÃ m ná»•i báº­t ráº±ng cÃ¡c mÃ´ hÃ¬nh mÃ£ váº«n cÃ³ nhá»¯ng thiáº¿u sÃ³t Ä‘Ã¡ng ká»ƒ trong viá»‡c hiá»ƒu ngá»¯ nghÄ©a mÃ£. Tuy nhiÃªn, ngá»¯ nghÄ©a mÃ£ cÃ³ liÃªn quan cháº·t cháº½ Ä‘áº¿n báº£o máº­t mÃ£. Do Ä‘Ã³, viá»‡c thá»±c hiá»‡n kiá»ƒm tra báº£o máº­t trÃªn mÃ£ Ä‘Æ°á»£c táº¡o bá»Ÿi cÃ¡c mÃ´ hÃ¬nh mÃ£ lÃ  ráº¥t quan trá»ng.

8 CÃC Má»I ÄE Dá»ŒA Äá»I Vá»šI TÃNH Há»¢P Lá»†

Thá»© nháº¥t, káº¿t quáº£ cá»§a phÃ¢n tÃ­ch phÃ¡t hiá»‡n bá»‹ áº£nh hÆ°á»Ÿng bá»Ÿi háº¡t giá»‘ng ngáº«u nhiÃªn vÃ  táº­p dá»¯ liá»‡u Ä‘Æ°á»£c sá»­ dá»¥ng. CÃ³ má»™t má»©c Ä‘á»™ ngáº«u nhiÃªn nháº¥t Ä‘á»‹nh cÃ³ thá»ƒ áº£nh hÆ°á»Ÿng Ä‘áº¿n hiá»‡u suáº¥t cá»§a bá»™ phÃ¢n loáº¡i phÃ¡t hiá»‡n cuá»‘i cÃ¹ng. Äá»ƒ giáº£m thiá»ƒu tÃ¡c Ä‘á»™ng cá»§a tÃ­nh ngáº«u nhiÃªn, chÃºng tÃ´i Ä‘Ã£ tiáº¿n hÃ nh nhiá»u thÃ­ nghiá»‡m vÃ  thá»±c hiá»‡n phÃ¢n tÃ­ch thá»‘ng kÃª cÃ¡c káº¿t quáº£.

Thá»© hai, chÃºng tÃ´i Ä‘Ã£ sá»­ dá»¥ng cÃ¡c cÃ´ng cá»¥ phÃ¢n tÃ­ch tÄ©nh Ä‘á»ƒ xÃ¢y dá»±ng táº­p dá»¯ liá»‡u cháº¥t lÆ°á»£ng cao Ä‘á»ƒ phÃ¢n tÃ­ch. Máº·c dÃ¹ phÆ°Æ¡ng phÃ¡p nÃ y cung cáº¥p thÃ´ng tin cÃ³ giÃ¡ trá»‹, nÃ³ cÅ©ng giá»›i thiá»‡u má»™t sá»‘ thiÃªn vá»‹ nháº¥t Ä‘á»‹nh. CÃ¡c cÃ´ng cá»¥ phÃ¢n tÃ­ch tÄ©nh cÃ³ thá»ƒ khÃ´ng náº¯m báº¯t Ä‘áº§y Ä‘á»§ cÃ¡c biáº¿n thá»ƒ tinh táº¿ trong ngá»¯ nghÄ©a Ä‘á»™ng vÃ  cÃ³ thá»ƒ bá»‹ áº£nh hÆ°á»Ÿng bá»Ÿi quy táº¯c cÃº phÃ¡p cá»§a cÃ¡c ngÃ´n ngá»¯ láº­p trÃ¬nh cá»¥ thá»ƒ. Äá»ƒ giáº£m thiÃªn vá»‹ nÃ y, chÃºng tÃ´i chá»n cÃ¡c cÃ´ng cá»¥ Ä‘Æ°á»£c nhiá»u nhÃ  nghiÃªn cá»©u sá»­ dá»¥ng Ä‘á»ƒ trÃ¡nh sai sÃ³t trong dá»¯ liá»‡u. Trong quÃ¡ trÃ¬nh so sÃ¡nh chÃ©o nhiá»‡m vá»¥, chÃºng tÃ´i trÃ­ch xuáº¥t cÃ¡c nhiá»‡m vá»¥ cÃº phÃ¡p vÃ  ngá»¯ nghÄ©a tá»« cÃ¹ng má»™t nguá»“n dá»¯ liá»‡u Ä‘á»ƒ giáº£m thiá»ƒu thiÃªn vá»‹ trong so sÃ¡nh chÃ©o nhiá»‡m vá»¥.

Thá»© ba, cÃ¡c thÆ°á»›c Ä‘o hiá»‡u suáº¥t khÃ¡c nhau cÃ³ thá»ƒ thá»ƒ hiá»‡n cÃ¡c thiÃªn vá»‹ khÃ¡c nhau. Äá»ƒ Ä‘Ã¡nh giÃ¡ cÃ¡c mÃ´ hÃ¬nh chÃ­nh xÃ¡c hÆ¡n, chÃºng tÃ´i Ä‘Ã£ sá»­ dá»¥ng há»‡ sá»‘ tÆ°Æ¡ng quan Matthews (MCC) cho phÃ¢n loáº¡i nhá»‹ phÃ¢n vÃ  Ä‘iá»ƒm F1 cho phÃ¢n loáº¡i Ä‘a lá»›p. Thá»±c táº¿, chÃºng tÃ´i Ä‘Ã£ Ä‘Ã¡nh giÃ¡ cÃ¡c mÃ´ hÃ¬nh sá»­ dá»¥ng cáº£ MCC vÃ  F1 cho táº¥t cáº£ cÃ¡c nhiá»‡m vá»¥, vÃ  cÃ¡c káº¿t luáº­n rÃºt ra tá»« cáº£ hai thÆ°á»›c Ä‘o Ä‘á»u nháº¥t quÃ¡n.

Thá»© tÆ°, máº·c dÃ¹ phÃ¢n tÃ­ch thÄƒm dÃ² cÃ³ thá»ƒ tiáº¿t lá»™ kháº£ nÄƒng há»c cá»§a cÃ¡c mÃ´ hÃ¬nh mÃ£ vá» cÃº phÃ¡p vÃ  ngá»¯ nghÄ©a, nÃ³ khÃ´ng Ä‘áº£m báº£o hiá»‡u suáº¥t nhiá»‡m vá»¥ downstream tá»‘t trong cÃ¡c á»©ng dá»¥ng thá»±c táº¿. CÃ¡c mÃ´ hÃ¬nh mÃ£ cÃ³ thá»ƒ hoáº¡t Ä‘á»™ng tá»‘t trong cÃ¡c nhiá»‡m vá»¥ thÄƒm dÃ² nhÆ°ng kÃ©m trong cÃ¡c á»©ng dá»¥ng thá»±c táº¿, Ä‘áº·c biá»‡t cÃ¡c nhiá»‡m vá»¥ yÃªu cáº§u lÃ½ luáº­n phá»©c táº¡p hoáº·c tÆ°Æ¡ng tÃ¡c Ä‘a phÆ°Æ¡ng thá»©c. Hiá»‡u suáº¥t cá»§a cÃ¡c mÃ´ hÃ¬nh nhiá»‡m vá»¥ downstream liÃªn quan khÃ´ng chá»‰ Ä‘áº¿n sá»©c máº¡nh biá»ƒu Ä‘áº¡t cá»§a mÃ´ hÃ¬nh cÆ¡ sá»Ÿ mÃ  cÃ²n Ä‘áº¿n cháº¥t lÆ°á»£ng cá»§a táº­p dá»¯ liá»‡u nhiá»‡m vá»¥ downstream vÃ  tÃ­nh máº¡nh máº½ cá»§a mÃ´ hÃ¬nh.

Thá»© nÄƒm, phÃ¢n tÃ­ch thÄƒm dÃ² lÃ  Ä‘á»ƒ quan sÃ¡t liá»‡u biá»ƒu diá»…n cÃ³ chá»©a má»™t thuá»™c tÃ­nh cá»¥ thá»ƒ tá»“n táº¡i trong Ä‘áº§u vÃ o hay khÃ´ng. Tuy nhiÃªn, hiá»‡u suáº¥t kÃ©m cá»§a phÃ¢n tÃ­ch thÄƒm dÃ² khÃ´ng cÃ³ nghÄ©a lÃ  biá»ƒu diá»…n khÃ´ng chá»©a thÃ´ng tin nhÆ° váº­y. KhÃ´ng gian biá»ƒu diá»…n lÃ  khÃ´ng gian chiá»u cao vÃ  trá»™n láº«n táº¥t cáº£ nhá»¯ng gÃ¬ Ä‘Ã£ há»c vá»›i nhau. Má»™t sá»‘ thÃ´ng tin dá»… quan sÃ¡t hÆ¡n vÃ  dá»… thÄƒm dÃ². PhÆ°Æ¡ng phÃ¡p thÄƒm dÃ² cá»§a chÃºng tÃ´i chá»‰ cÃ³ thá»ƒ Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ tráº£ lá»i liá»‡u thuá»™c tÃ­nh nÃ y cÃ³ dá»… quan sÃ¡t hÆ¡n hoáº·c Ã­t hÆ¡n hay khÃ´ng. NÃ³ bá»‹ háº¡n cháº¿ trong viá»‡c tráº£ lá»i 'cÃ³' hoáº·c 'khÃ´ng'.

Cuá»‘i cÃ¹ng nhÆ°ng khÃ´ng kÃ©m pháº§n quan trá»ng, nhiá»u mÃ´ hÃ¬nh mÃ£ Ä‘Ã£ Ä‘Æ°á»£c Ä‘á» xuáº¥t. Äá»ƒ Ä‘áº£m báº£o ráº±ng phÆ°Æ¡ng phÃ¡p Ä‘Ã¡nh giÃ¡ vÃ  káº¿t luáº­n cá»§a chÃºng tÃ´i Ä‘Æ°á»£c tá»•ng quÃ¡t hÃ³a, chÃºng tÃ´i xem xÃ©t ba kiáº¿n trÃºc khÃ¡c nhau cá»§a cÃ¡c mÃ´ hÃ¬nh mÃ£: bá»™ mÃ£ hÃ³a, bá»™ giáº£i mÃ£ vÃ  bá»™ mÃ£ hÃ³a-giáº£i mÃ£. ChÃºng tÃ´i bao gá»“m cÃ¡c mÃ´ hÃ¬nh tiá»n huáº¥n luyá»‡n truyá»n thá»‘ng vÃ  cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n tá»« cÃ¡c cÃ´ng ty hoáº·c tá»• chá»©c lá»›n, vÃ  táº¥t cáº£ nhá»¯ng mÃ´ hÃ¬nh nÃ y Ä‘Æ°á»£c sá»­ dá»¥ng rá»™ng rÃ£i nhÆ° cÃ¡c mÃ´ hÃ¬nh cÆ¡ sá»Ÿ Ä‘á»ƒ giáº£i quyáº¿t cÃ¡c nhiá»‡m vá»¥ downstream. Khi chÃºng tÃ´i thiáº¿t káº¿ phÆ°Æ¡ng phÃ¡p cá»§a mÃ¬nh, chÃºng tÃ´i khÃ´ng xem xÃ©t báº¥t ká»³ mÃ´ hÃ¬nh vÃ  ngÃ´n ngá»¯ láº­p trÃ¬nh cá»¥ thá»ƒ nÃ o, vÃ  chÃºng tÃ´i chá»‰ xem xÃ©t cÃº phÃ¡p vÃ  ngá»¯ nghÄ©a cá»§a mÃ£. AST Ä‘áº¡i diá»‡n cho táº¥t cáº£ thÃ´ng tin cÃº phÃ¡p cá»§a mÃ£. CFG Ä‘áº¡i diá»‡n cho logic/hÃ nh Ä‘á»™ng cá»§a mÃ£. DDG vÃ  CDG Ä‘áº¡i diá»‡n cho má»‘i quan há»‡ ngá»¯ nghÄ©a giá»¯a cÃ¡c pháº§n mÃ£ khÃ¡c nhau. Háº§u nhÆ° táº¥t cáº£ cÃ¡c nhiá»‡m vá»¥ SE liÃªn quan Ä‘áº¿n mÃ£ Ä‘á»u cáº§n thÃ´ng tin nÃ y. Tuy nhiÃªn, cÃ¡c mÃ´ hÃ¬nh khÃ¡c nhau cÃ³ kháº£ nÄƒng khÃ¡c nhau, vÃ  káº¿t luáº­n cá»§a chÃºng tÃ´i cÃ³ thá»ƒ khÃ´ng phÃ¹ há»£p vá»›i má»™t mÃ´ hÃ¬nh cÃ³ chiáº¿n lÆ°á»£c huáº¥n luyá»‡n vÃ  táº­p dá»¯ liá»‡u ráº¥t khÃ¡c biá»‡t.

Lá»œI Cáº¢M Æ N

NghiÃªn cá»©u nÃ y Ä‘Æ°á»£c há»— trá»£ bá»Ÿi Quá»¹ NghiÃªn cá»©u Quá»‘c gia, Singapore, vÃ  CÆ¡ quan An ninh Máº¡ng dÆ°á»›i ChÆ°Æ¡ng trÃ¬nh NghiÃªn cá»©u vÃ  PhÃ¡t triá»ƒn An ninh Máº¡ng Quá»‘c gia (NCRP25-P04-TAICeN), Quá»¹ NghiÃªn cá»©u Quá»‘c gia, Singapore, vÃ  PhÃ²ng thÃ­ nghiá»‡m Quá»‘c gia DSO dÆ°á»›i ChÆ°Æ¡ng trÃ¬nh AI Singapore (AISG Award No: AISG2-GC-2023-008), vÃ  NRF Investigatorship NRF-NRFI06-2020-0001. Báº¥t ká»³ Ã½ kiáº¿n, phÃ¡t hiá»‡n vÃ  káº¿t luáº­n hoáº·c khuyáº¿n nghá»‹ nÃ o Ä‘Æ°á»£c thá»ƒ hiá»‡n trong tÃ i liá»‡u nÃ y Ä‘á»u lÃ  cá»§a (cÃ¡c) tÃ¡c giáº£ vÃ  khÃ´ng pháº£n Ã¡nh quan Ä‘iá»ƒm cá»§a Quá»¹ NghiÃªn cá»©u Quá»‘c gia, Singapore vÃ  CÆ¡ quan An ninh Máº¡ng cá»§a Singapore.

TÃ€I LIá»†U THAM KHáº¢O

[1]Charu C. Aggarwal, Alexander Hinneburg, vÃ  Daniel A. Keim. 2001. On the Surprising Behavior of Distance Metrics in High Dimensional Spaces. In Proceedings of the 8th International Conference on Database Theory (ICDT '01). Springer-Verlag, Berlin, Heidelberg, 420â€“434.

[2]Wasi Uddin Ahmad, Saikat Chakraborty, Baishakhi Ray, vÃ  Kai-Wei Chang. 2021. Unified pre-training for program understanding and generation. arXiv preprint arXiv:2103.06333 (2021).

[3]Miltos Allamanis, Earl T. Barr, Premkumar Devanbu, vÃ  Charles Sutton. 2018. A Survey of Machine Learning for Big Code and Naturalness. Comput. Surveys 51, 4 (July 2018), 81. https://www.microsoft.com/en-us/research/publication/a-survey-of-machine-learning-for-big-code-and-naturalness/

[4]Luca Buratti, Saurabh Pujar, Mihaela Bornea, Scott McCarley, Yunhui Zheng, Gaetano Rossiello, Alessandro Morari, Jim Laredo, Veronika Thost, Yufan Zhuang, et al. 2020. Exploring software naturalness through neural language models. arXiv preprint arXiv:2006.12641 (2020).

[5]Davide Chicco vÃ  Giuseppe Jurman. 2020. The advantages of the Matthews correlation coefficient (MCC) over F1 score and accuracy in binary classification evaluation. BMC genomics 21, 1 (2020), 1â€“13.

[6]Alexis Conneau, German Kruszewski, Guillaume Lample, LoÃ¯c Barrault, vÃ  Marco Baroni. 2018. What you can cram into a single $&!#* vector: Probing sentence embeddings for linguistic properties. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). Association for Computational Linguistics, Melbourne, Australia, 2126â€“2136. https://doi.org/10.18653/v1/P18-1198

[7]Qingxiu Dong, Lei Li, Damai Dai, Ce Zheng, Zhiyong Wu, Baobao Chang, Xu Sun, Jingjing Xu, vÃ  Zhifang Sui. 2022. A survey for in-context learning. arXiv preprint arXiv:2301.00234 (2022).

[8]Shihan Dou, Junjie Shan, Haoxiang Jia, Wenhao Deng, Zhiheng Xi, Wei He, Yueming Wu, Tao Gui, Yang Liu, vÃ  Xuanjing Huang. 2023. Towards understanding the capability of large language models on code clone detection: a survey. arXiv preprint arXiv:2308.01191 (2023).

[9]Dawn Drain, Chen Wu, Alexey Svyatkovskiy, vÃ  Neel Sundaresan. 2021. Generating bug-fixes using pretrained transformers. In Proceedings of the 5th ACM SIGPLAN International Symposium on Machine Programming. 1â€“8.

[10] Xueying Du, Mingwei Liu, Kaixin Wang, Hanlin Wang, Junwei Liu, Yixuan Chen, Jiayi Feng, Chaofeng Sha, Xin Peng, vÃ  Yiling Lou. 2023. Classeval: A manually-crafted benchmark for evaluating llms on class-level code generation. arXiv preprint arXiv:2308.01861 (2023).

[11] Angela Fan, Beliz Gokkaya, Mark Harman, Mitya Lyubarskiy, Shubho Sengupta, Shin Yoo, vÃ  Jie M Zhang. 2023. Large language models for software engineering: Survey and open problems. arXiv preprint arXiv:2310.03533 (2023).

[12] Yang Feng, Qingkai Shi, Xinyu Gao, Jun Wan, Chunrong Fang, vÃ  Zhenyu Chen. 2020. DeepGini: prioritizing massive tests to enhance the robustness of deep neural networks. In Proceedings of the 29th ACM SIGSOFT International Symposium on Software Testing and Analysis (Virtual Event, USA) (ISSTA 2020). Association for Computing Machinery, New York, NY, USA, 177â€“188. https://doi.org/10.1145/3395363.3397357

[13] Zhangyin Feng, Daya Guo, Duyu Tang, Nan Duan, Xiaocheng Feng, Ming Gong, Linjun Shou, Bing Qin, Ting Liu, Daxin Jiang, et al. 2020. Codebert: A pre-trained model for programming and natural languages. arXiv preprint arXiv:2002.08155 (2020).

[14] Fengjuan Gao, Yu Wang, vÃ  Ke Wang. 2023. Discrete Adversarial Attack to Models of Code. Proc. ACM Program. Lang. 7, PLDI, Article 113 (jun 2023), 24 pages. https://doi.org/10.1145/3591227

[15] Saurabh Garg, Sivaraman Balakrishnan, Zachary C Lipton, Behnam Neyshabur, vÃ  Hanie Sedghi. 2022. Leveraging unlabeled data to predict out-of-distribution performance. arXiv preprint arXiv:2201.04234 (2022).

[16] Daya Guo, Shuai Lu, Nan Duan, Yanlin Wang, Ming Zhou, vÃ  Jian Yin. 2022. UniXcoder: Unified Cross-Modal Pre-training for Code Representation. arXiv preprint arXiv:2203.03850 (2022).

J. ACM, Vol. 37, No. 4, Article 111. NgÃ y xuáº¥t báº£n: ThÃ¡ng 8 2018.

--- TRANG 26 ---
111:26 W. Ma, S. Liu vÃ  M. Zhao et al.

[17] Daya Guo, Shuo Ren, Shuai Lu, Zhangyin Feng, Duyu Tang, Shujie Liu, Long Zhou, Nan Duan, Alexey Svyatkovskiy, Shengyu Fu, et al. 2020. Graphcodebert: Pre-training code representations with data flow. arXiv preprint arXiv:2009.08366 (2020).

[18] JosÃ© Antonio HernÃ¡ndez LÃ³pez, Martin Weyssow, JesÃºs SÃ¡nchez Cuadrado, vÃ  Houari Sahraoui. 2023. AST-Probe: Recovering abstract syntax trees from hidden representations of pre-trained language models. In Proceedings of the 37th IEEE/ACM International Conference on Automated Software Engineering (<conf-loc>, <city>Rochester</city>, <state>MI</state>, <country>USA</country>, </conf-loc>) (ASE '22). Association for Computing Machinery, New York, NY, USA, Article 11, 11 pages. https://doi.org/10.1145/3551349.3556900

[19] Sirui Hong, Mingchen Zhuge, Jonathan Chen, Xiawu Zheng, Yuheng Cheng, Ceyao Zhang, Jinlin Wang, Zili Wang, Steven Ka Shing Yau, Zijuan Lin, Liyang Zhou, Chenyu Ran, Lingfeng Xiao, Chenglin Wu, vÃ  JÃ¼rgen Schmidhuber. 2023. MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework. arXiv:2308.00352 [cs.AI]

[20] Susan Horwitz vÃ  Thomas Reps. 1992. The Use of Program Dependence Graphs in Software Engineering. In Proceedings of the 14th International Conference on Software Engineering (Melbourne, Australia) (ICSE '92). Association for Computing Machinery, New York, NY, USA, 392â€“411. https://doi.org/10.1145/143062.143156

[21] Xinyi Hou, Yanjie Zhao, Yue Liu, Zhou Yang, Kailong Wang, Li Li, Xiapu Luo, David Lo, John Grundy, vÃ  Haoyu Wang. 2023. Large language models for software engineering: A systematic literature review. arXiv preprint arXiv:2308.10620 (2023).

[22] Edward J Hu, yelong shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, vÃ  Weizhu Chen. 2022. LoRA: Low-Rank Adaptation of Large Language Models. In International Conference on Learning Representations. https://openreview.net/forum?id=nZeVKeeFYf9

[23] Qiang Hu, Yuejun Guo, Xiaofei Xie, Maxime Cordy, Lei Ma, Mike Papadakis, vÃ  Yves Le Traon. 2024. Test Optimization in DNN Testing: A Survey. ACM Trans. Softw. Eng. Methodol. (jan 2024). https://doi.org/10.1145/3643678 Just Accepted.

[24] Qiang Hu, Yuejun Guo, Xiaofei Xie, Maxime Cordy, Mike Papadakis, vÃ  Yves Le Traon. 2023. LaF: Labeling-free Model Selection for Automated Deep Neural Network Reusing. ACM Trans. Softw. Eng. Methodol. 33, 1, Article 25 (nov 2023), 28 pages. https://doi.org/10.1145/3611666

[25] Qiang Hu, Yuejun Guo, Xiaofei Xie, Maxime Cordy, Mike Papadakis, Lei Ma, vÃ  Yves Le Traon. 2023. Aries: Efficient Testing of Deep Neural Networks via Labeling-Free Accuracy Estimation. In Proceedings of the 45th International Conference on Software Engineering (Melbourne, Victoria, Australia) (ICSE '23). IEEE Press, 1776â€“1787. https://doi.org/10.1109/ICSE48619.2023.00152

[26] Hamel Husain, Ho-Hsiang Wu, Tiferet Gazit, Miltiadis Allamanis, vÃ  Marc Brockschmidt. 2019. Codesearchnet challenge: Evaluating the state of semantic code search. arXiv preprint arXiv:1909.09436 (2019).

[27] Mehdi Iraqi. [n. d.]. Comparing the Performance of LLMs: A Deep Dive into Roberta, Llama 2, and Mistral for Disaster Tweets Analysis with Lora. https://huggingface.co/blog/Lora-for-sequence-classification-with-Roberta-Llama-Mistral#comparing-the-performance-of-llms-a-deep-dive-into-roberta-llama-2-and-mistral-for-disaster-tweets-analysis-with-lora

[28] Akshita Jha vÃ  Chandan K. Reddy. 2023. CodeAttack: code-based adversarial attacks for pre-trained programming language models. In Proceedings of the Thirty-Seventh AAAI Conference on Artificial Intelligence and Thirty-Fifth Conference on Innovative Applications of Artificial Intelligence and Thirteenth Symposium on Educational Advances in Artificial Intelligence (AAAI'23/IAAI'23/EAAI'23). AAAI Press, Article 1670, 9 pages. https://doi.org/10.1609/aaai.v37i12.26739

[29] Aditya Kanade, Petros Maniatis, Gogul Balakrishnan, vÃ  Kensen Shi. 2019. Pre-trained contextual embedding of source code. (2019).

[30] Jared Kaplan, Sam McCandlish, Tom Henighan, Tom B Brown, Benjamin Chess, Rewon Child, Scott Gray, Alec Radford, Jeffrey Wu, vÃ  Dario Amodei. 2020. Scaling laws for neural language models. arXiv preprint arXiv:2001.08361 (2020).

[31] Rafael-Michael Karampatsis vÃ  Charles Sutton. 2020. Scelmo: Source code embeddings from language models. arXiv preprint arXiv:2004.13214 (2020).

[32] Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Ves Stoyanov, vÃ  Luke Zettlemoyer. 2019. Bart: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension. arXiv preprint arXiv:1910.13461 (2019).

[33] Lin Li, Yifei Wang, Chawin Sitawarin, vÃ  Michael Spratling. 2023. OODRobustBench: benchmarking and analyzing adversarial robustness under distribution shift. arXiv preprint arXiv:2310.12793 (2023).

[34] Raymond Li, Loubna Ben Allal, Yangtian Zi, Niklas Muennighoff, Denis Kocetkov, Chenghao Mou, Marc Marone, Christopher Akiki, Jia Li, Jenny Chim, et al. 2023. StarCoder: may the source be with you! arXiv preprint arXiv:2305.06161 (2023).

[35] Xiaochen Li, He Jiang, Zhilei Ren, Ge Li, vÃ  Jingxuan Zhang. 2018. Deep learning in software engineering. arXiv preprint arXiv:1805.04825 (2018).

J. ACM, Vol. 37, No. 4, Article 111. NgÃ y xuáº¥t báº£n: ThÃ¡ng 8 2018.

--- TRANG 27 ---
KhÃ¡m PhÃ¡ CÃ¡c MÃ´ HÃ¬nh Tiá»n Huáº¥n Luyá»‡n MÃ£: NghiÃªn Cá»©u Kháº£ NÄƒng CÃº PhÃ¡p vÃ  Ngá»¯ NghÄ©a 111:27

[36] Xueyang Li, Shangqing Liu, Ruitao Feng, Guozhu Meng, Xiaofei Xie, Kai Chen, vÃ  Yang Liu. 2022. TransRepair: Context-aware Program Repair for Compilation Errors. arXiv preprint arXiv:2210.03986 (2022).

[37] Yuan Li, Xiaodan Liang, Zhiting Hu, Yinbo Chen, vÃ  Eric P. Xing. 2019. Graph Transformer. https://openreview.net/forum?id=HJei-2RcK7

[38] Shangqing Liu, Yu Chen, Xiaofei Xie, Jingkai Siow, vÃ  Yang Liu. 2020. Retrieval-augmented generation for code summarization via hybrid gnn. arXiv preprint arXiv:2006.05405 (2020).

[39] Shangqing Liu, Cuiyun Gao, Sen Chen, Nie Lun Yiu, vÃ  Yang Liu. 2020. ATOM: Commit message generation based on abstract syntax tree and hybrid ranking. IEEE Transactions on Software Engineering (2020).

[40] Shangqing Liu, Yanzhou Li, vÃ  Yang Liu. 2022. CommitBART: A Large Pre-trained Model for GitHub Commits. arXiv preprint arXiv:2208.08100 (2022).

[41] Shangqing Liu, Bozhi Wu, Xiaofei Xie, Guozhu Meng, vÃ  Yang Liu. 2023. ContraBERT: Enhancing Code Pre-trained Models via Contrastive Learning. arXiv preprint arXiv:2301.09072 (2023).

[42] Shuai Lu, Daya Guo, Shuo Ren, Junjie Huang, Alexey Svyatkovskiy, Ambrosio Blanco, Colin Clement, Dawn Drain, Daxin Jiang, Duyu Tang, et al. 2021. Codexglue: A machine learning benchmark dataset for code understanding and generation. arXiv preprint arXiv:2102.04664 (2021).

[43] Ziyang Luo, Can Xu, Pu Zhao, Qingfeng Sun, Xiubo Geng, Wenxiang Hu, Chongyang Tao, Jing Ma, Qingwei Lin, vÃ  Daxin Jiang. 2023. WizardCoder: Empowering Code Large Language Models with Evol-Instruct. arXiv preprint arXiv:2306.08568 (2023).

[44] Lei Ma, Fuyuan Zhang, Jiyuan Sun, Minhui Xue, Bo Li, Felix Juefei-Xu, Chao Xie, Li Li, Yang Liu, Jianjun Zhao, et al. 2018. Deepmutation: Mutation testing of deep learning systems. In 2018 IEEE 29th international symposium on software reliability engineering (ISSRE). IEEE, 100â€“111.

[45] Wei Ma, Shangqing Liu, Zhihao Lin, Wenhan Wang, Qiang Hu, Ye Liu, Cen Zhang, Liming Nie, Li Li, vÃ  Yang Liu. 2024. LMs: Understanding Code Syntax and Semantics for Code Analysis. arXiv:2305.12138 [cs.SE]

[46] Wei Ma, Shangqing Liu, Wenhan Wang, Qiang Hu, Ye Liu, Cen Zhang, Liming Nie, vÃ  Yang Liu. 2023. The Scope of ChatGPT in Software Engineering: A Thorough Investigation. arXiv preprint arXiv:2305.12138 (2023).

[47] Wei Ma, Mike Papadakis, Anestis Tsakmalis, Maxime Cordy, vÃ  Yves Le Traon. 2021. Test Selection for Deep Learning Systems. ACM Trans. Softw. Eng. Methodol. 30, 2, Article 13 (jan 2021), 22 pages. https://doi.org/10.1145/3417330

[48] Wei Ma, Daoyuan Wu, Yuqiang Sun, Tianwen Wang, Shangqing Liu, Jian Zhang, Yue Xue, vÃ  Yang Liu. 2024. Combining Fine-Tuning and LLM-based Agents for Intuitive Smart Contract Auditing with Justifications. arXiv:2403.16073 [cs.SE]

[49] Wei Ma, Mengjie Zhao, Ezekiel Soremekun, Qiang Hu, Jie M. Zhang, Mike Papadakis, Maxime Cordy, Xiaofei Xie, vÃ  Yves Le Traon. 2022. GraphCode2Vec: generic code embedding via lexical and program dependence analyses. In Proceedings of the 19th International Conference on Mining Software Repositories (Pittsburgh, Pennsylvania) (MSR '22). Association for Computing Machinery, New York, NY, USA, 524â€“536. https://doi.org/10.1145/3524842.3528456

[50] B.W. Matthews. 1975. Comparison of the predicted and observed secondary structure of T4 phage lysozyme. Biochimica et Biophysica Acta (BBA) - Protein Structure 405, 2 (1975), 442â€“451. https://doi.org/10.1016/0005-2795(75)90109-9

[51] Linghan Meng, Yanhui Li, Lin Chen, Zhi Wang, Di Wu, Yuming Zhou, vÃ  Baowen Xu. 2021. Measuring discrimination to boost comparative testing for multiple deep learning models. In 2021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE). IEEE, 385â€“396.

[52] Evgeny M Mirkes, Jeza Allohibi, vÃ  Alexander Gorban. 2020. Fractional norms and quasinorms do not help to overcome the curse of dimensionality. Entropy 22, 10 (2020), 1105.

[53] Lili Mou, Ge Li, Lu Zhang, Tao Wang, vÃ  Zhi Jin. 2016. Convolutional neural networks over tree structures for programming language processing. In Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence. 1287â€“1293.

[54] Changan Niu, Chuanyi Li, Vincent Ng, Dongxiao Chen, Jidong Ge, vÃ  Bin Luo. 2023. An empirical comparison of pre-trained models of source code. arXiv preprint arXiv:2302.04026 (2023).

[55] Gustavo Penha vÃ  Claudia Hauff. 2020. What does BERT know about books, movies and music? Probing BERT for Conversational Recommendation. In Proceedings of the 14th ACM Conference on Recommender Systems (Virtual Event, Brazil) (RecSys '20). Association for Computing Machinery, New York, NY, USA, 388â€“397. https://doi.org/10.1145/3383313.3412249

[56] Ruchir Puri, David S Kung, Geert Janssen, Wei Zhang, Giacomo Domeniconi, Vladimir Zolotov, Julian Dolby, Jie Chen, Mihir Choudhury, Lindsey Decker, et al. 2021. CodeNet: A large-scale AI for code dataset for learning a diversity of coding tasks. arXiv preprint arXiv:2105.12655 (2021).

[57] Anna Rogers, Olga Kovaleva, vÃ  Anna Rumshisky. 2020. A Primer in BERTology: What We Know About How BERT Works. Transactions of the Association for Computational Linguistics 8 (2020), 842â€“866. https://doi.org/10.1162/tacl_a_00349

[58] Baptiste Roziere, Jonas Gehring, Fabian Gloeckle, Sten Sootla, Itai Gat, Xiaoqing Ellen Tan, Yossi Adi, Jingyu Liu, Tal Remez, JÃ©rÃ©my Rapin, et al. 2023. Code llama: Open foundation models for code. arXiv preprint arXiv:2308.12950

J. ACM, Vol. 37, No. 4, Article 111. NgÃ y xuáº¥t báº£n: ThÃ¡ng 8 2018.

--- TRANG 28 ---
111:28 W. Ma, S. Liu vÃ  M. Zhao et al.

(2023).

[59] Da Shen, Xinyun Chen, Chenguang Wang, Koushik Sen, vÃ  Dawn Song. 2022. Benchmarking Language Models for Code Syntax Understanding. In Findings of the Association for Computational Linguistics: EMNLP 2022, Yoav Goldberg, Zornitsa Kozareva, vÃ  Yue Zhang (Eds.). Association for Computational Linguistics, Abu Dhabi, United Arab Emirates, 3071â€“3093. https://doi.org/10.18653/v1/2022.findings-emnlp.224

[60] Yikang Shen, Zhouhan Lin, Athul Paul Jacob, Alessandro Sordoni, Aaron Courville, vÃ  Yoshua Bengio. 2018. Straight to the Tree: Constituency Parsing with Neural Syntactic Distance. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), Iryna Gurevych vÃ  Yusuke Miyao (Eds.). Association for Computational Linguistics, Melbourne, Australia, 1171â€“1180. https://doi.org/10.18653/v1/P18-1108

[61] Xiaoxiao Sun, Yunzhong Hou, Weijian Deng, Hongdong Li, vÃ  Liang Zheng. 2021. Ranking Models in Unlabeled New Environments. In 2021 IEEE/CVF International Conference on Computer Vision (ICCV). 11741â€“11751. https://doi.org/10.1109/ICCV48922.2021.01155

[62] Yuqiang Sun, Daoyuan Wu, Yue Xue, Han Liu, Wei Ma, Lyuye Zhang, Miaolei Shi, vÃ  Yang Liu. 2024. LLM4Vuln: A Unified Evaluation Framework for Decoupling and Enhancing LLMs' Vulnerability Reasoning. arXiv:2401.16185 [cs.CR]

[63] Alexey Svyatkovskiy, Shao Kun Deng, Shengyu Fu, vÃ  Neel Sundaresan. 2020. Intellicode compose: Code generation using transformer. In Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering. 1433â€“1443.

[64] Ian Tenney, Patrick Xia, Berlin Chen, Alex Wang, Adam Poliak, R Thomas McCoy, Najoung Kim, Benjamin Van Durme, Samuel R Bowman, Dipanjan Das, et al. 2019. What do you learn from context? probing for sentence structure in contextualized word representations. arXiv preprint arXiv:1905.06316 (2019).

[65] Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al. 2023. Llama 2: Open foundation and fine-tuned chat models. arXiv preprint arXiv:2307.09288 (2023).

[66] Sergey Troshin vÃ  Nadezhda Chirkova. 2022. Probing Pretrained Models of Source Code. arXiv preprint arXiv:2202.08975 (2022).

[67] Betty van Aken, Benjamin Winter, Alexander LÃ¶ser, vÃ  Felix A. Gers. 2019. How Does BERT Answer Questions? A Layer-Wise Analysis of Transformer Representations. In Proceedings of the 28th ACM International Conference on Information and Knowledge Management (Beijing, China) (CIKM '19). Association for Computing Machinery, New York, NY, USA, 1823â€“1832. https://doi.org/10.1145/3357384.3358028

[68] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Åukasz Kaiser, vÃ  Illia Polosukhin. 2017. Attention is all you need. Advances in neural information processing systems 30 (2017).

[69] Yao Wan, Wei Zhao, Hongyu Zhang, Yulei Sui, Guandong Xu, vÃ  Hai Jin. 2022. What Do They Capture? A Structural Analysis of Pre-Trained Language Models for Source Code. In Proceedings of the 44th International Conference on Software Engineering (Pittsburgh, Pennsylvania) (ICSE '22). Association for Computing Machinery, New York, NY, USA, 2377â€“2388. https://doi.org/10.1145/3510003.3510050

[70] Yue Wang, Hung Le, Akhilesh Deepak Gotmare, Nghi DQ Bui, Junnan Li, vÃ  Steven CH Hoi. 2023. Codet5+: Open code large language models for code understanding and generation. arXiv preprint arXiv:2305.07922 (2023).

[71] Yue Wang, Weishi Wang, Shafiq Joty, vÃ  Steven CH Hoi. 2021. Codet5: Identifier-aware unified pre-trained encoder-decoder models for code understanding and generation. arXiv preprint arXiv:2109.00859 (2021).

[72] Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, et al. 2022. Emergent abilities of large language models. arXiv preprint arXiv:2206.07682 (2022).

[73] Yanming Yang, Xin Xia, David Lo, vÃ  John Grundy. 2022. A Survey on Deep Learning for Software Engineering. ACM Comput. Surv. 54, 10s, Article 206 (sep 2022), 73 pages. https://doi.org/10.1145/3505243

[74] Jingxiu Yao vÃ  Martin Shepperd. 2020. Assessing Software Defection Prediction Performance: Why Using the Matthews Correlation Coefficient Matters. In Proceedings of the 24th International Conference on Evaluation and Assessment in Software Engineering (Trondheim, Norway) (EASE '20). Association for Computing Machinery, New York, NY, USA, 120â€“129. https://doi.org/10.1145/3383219.3383232

[75] Noam Yefet, Uri Alon, vÃ  Eran Yahav. 2020. Adversarial examples for models of code. Proc. ACM Program. Lang. 4, OOPSLA, Article 162 (nov 2020), 30 pages. https://doi.org/10.1145/3428230

[76] Zhiqiang Yuan, Yiling Lou, Mingwei Liu, Shiji Ding, Kaixin Wang, Yixuan Chen, vÃ  Xin Peng. 2023. No More Manual Tests? Evaluating and Improving ChatGPT for Unit Test Generation. arXiv preprint arXiv:2305.04207 (2023).

[77] Seongjun Yun, Minbyul Jeong, Raehyun Kim, Jaewoo Kang, vÃ  Hyunwoo J Kim. 2019. Graph transformer networks. Advances in neural information processing systems 32 (2019).

[78] Ziyin Zhang, Chaoyu Chen, Bingchang Liu, Cong Liao, Zi Gong, Hang Yu, Jianguo Li, vÃ  Rui Wang. 2023. A survey on language models for code. arXiv preprint arXiv:2311.07989 (2023).

J. ACM, Vol. 37, No. 4, Article 111. NgÃ y xuáº¥t báº£n: ThÃ¡ng 8 2018.

--- TRANG 29 ---
KhÃ¡m PhÃ¡ CÃ¡c MÃ´ HÃ¬nh Tiá»n Huáº¥n Luyá»‡n MÃ£: NghiÃªn Cá»©u Kháº£ NÄƒng CÃº PhÃ¡p vÃ  Ngá»¯ NghÄ©a 111:29

[79] Mengjie Zhao, Philipp Dufter, Yadollah Yaghoobzadeh, vÃ  Hinrich SchÃ¼tze. 2020. Quantifying the Contextualization of Word Representations with Semantic Class Probing. In Findings of the Association for Computational Linguistics: EMNLP 2020. Association for Computational Linguistics, Online, 1219â€“1234. https://doi.org/10.18653/v1/2020.findings-emnlp.109

[80] Yaqin Zhou, Shangqing Liu, Jingkai Siow, Xiaoning Du, vÃ  Yang Liu. 2019. Devign: Effective vulnerability identification by learning comprehensive program semantics via graph neural networks. In Advances in Neural Information Processing Systems. 10197â€“10207.

[81] Barret Zoph, Colin Raffel, Dale Schuurmans, Dani Yogatama, Denny Zhou, Don Metzler, Ed H. Chi, Jason Wei, Jeff Dean, Liam B. Fedus, Maarten Paul Bosma, Oriol Vinyals, Percy Liang, Sebastian Borgeaud, Tatsunori B. Hashimoto, vÃ  Yi Tay. 2022. Emergent abilities of large language models. TMLR (2022).

J. ACM, Vol. 37, No. 4, Article 111. NgÃ y xuáº¥t báº£n: ThÃ¡ng 8 2018.

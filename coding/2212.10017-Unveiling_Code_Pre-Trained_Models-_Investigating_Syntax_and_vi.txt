# 2212.10017.pdf
# Đã chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/coding/2212.10017.pdf
# Kích thước tệp: 1454270 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Khám Phá Các Mô Hình Tiền Huấn Luyện Mã: Nghiên Cứu Khả Năng Cú Pháp và Ngữ Nghĩa

WEI MA, Đại học Công nghệ Nanyang, Singapore
SHANGQING LIU∗, Đại học Công nghệ Nanyang, Singapore
MENGJIE ZHAO, Đại học Ludwig Maximilian Munich, Đức
XIAOFEI XIE, Đại học Quản lý Singapore, Singapore
WENHAN WANG, Đại học Alberta, Canada
QIANG HU, Đại học Tokyo, Nhật Bản
JIE ZHANG, Phòng thí nghiệm Noah's Ark, Huawei, Trung Quốc
YANG LIU, Đại học Công nghệ Nanyang, Singapore

Những tiến bộ đáng kể đã được đạt được trong lĩnh vực trí tuệ mã thông qua các mô hình mã nhúng kiến thức về ngôn ngữ lập trình. Nghiên cứu trước đây đã xem xét mức độ hiểu biết cú pháp mã của các mô hình này, tuy nhiên việc hiểu ngữ nghĩa mã của chúng vẫn cần được khám phá. Hơn nữa, các phân tích hiện tại thường liên kết số lượng cạnh trong cây cú pháp trừu tượng (AST) với khoảng cách cú pháp. Chúng cũng thường yêu cầu giảm không gian chiều cao của các mô hình học sâu xuống chiều thấp hơn, có thể dẫn đến sự không chính xác. Chúng tôi phân tích toàn diện bảy mô hình mã để điều tra cách các mô hình mã biểu diễn cú pháp và ngữ nghĩa mã. Điều này bao gồm bốn mô hình tiền huấn luyện mã nổi bật (CodeBERT, GraphCodeBERT, CodeT5, và UnixCoder) và ba mô hình ngôn ngữ lớn (StarCoder, CodeLlama, và CodeT5+). Chúng tôi đã phát triển bốn nhiệm vụ thăm dò để đánh giá khả năng học cú pháp và ngữ nghĩa mã của các mô hình. Các nhiệm vụ này tập trung vào việc tái tạo các cấu trúc cú pháp và ngữ nghĩa mã—như Cây Cú pháp Trừu tượng (AST), Đồ thị Luồng Điều khiển (CFG), Đồ thị Phụ thuộc Điều khiển (CDG), và Đồ thị Phụ thuộc Dữ liệu (DDG)—trong không gian biểu diễn của các mô hình. Những cấu trúc này là nền tảng để hiểu mã. Ngoài ra, chúng tôi khám phá vai trò của các token cú pháp trong mỗi biểu diễn token và các phụ thuộc mở rộng giữa các token mã. Hơn nữa, chúng tôi xem xét phân phối trọng số chú ý liên quan đến các cấu trúc ngữ nghĩa mã. Thông qua phân tích chi tiết, kết quả của chúng tôi nhấn mạnh điểm mạnh và điểm yếu của các mô hình mã khác nhau trong việc làm chủ cú pháp và ngữ nghĩa mã. Các phát hiện cho thấy rằng những mô hình này có khả năng nắm bắt cú pháp mã, hiệu quả trong việc nắm bắt các mối quan hệ và vai trò của các token cú pháp. Tuy nhiên, khả năng mã hóa ngữ nghĩa mã của chúng cho thấy sự biến đổi nhiều hơn. CodeT5 và CodeBERT xuất sắc trong việc nắm bắt các phụ thuộc điều khiển và dữ liệu, trong khi UnixCoder hoạt động kém hiệu quả hơn. Chúng tôi cũng thấy rằng các mô hình ngôn ngữ lớn (LLM) không vượt trội hơn các mô hình tiền huấn luyện một cách đáng kể. Thú vị là, các tầng nông của LLM thể hiện hiệu suất tốt hơn so với các tầng sâu của chúng. Phân tích trọng số chú ý của chúng tôi cho thấy rằng các đầu chú ý khác nhau được chuyên môn hóa cho các vai trò riêng biệt trong việc mã hóa ngữ nghĩa mã. Nghiên cứu của chúng tôi nhấn mạnh sự cần thiết cho những cải tiến thêm trong các mô hình mã để nâng cao khả năng học ngữ nghĩa mã một cách hiệu quả.

∗Tác giả liên lạc.
Địa chỉ tác giả: Wei Ma, Đại học Công nghệ Nanyang, Singapore, ma_wei@ntu.edu.sg; Shangqing Liu, Đại học Công nghệ Nanyang, Singapore, liu.shangqing@ntu.edu.sg; Mengjie Zhao, Đại học Ludwig Maximilian Munich, Munich, Đức, mzhaolmu@gmail.com; Xiaofei Xie, Đại học Quản lý Singapore, Singapore, xfxie@smu.edu.sg; Wenhan Wang, Đại học Alberta, Edmonton, Canada, wenhan12@ualberta.ca; Qiang Hu, Đại học Tokyo, Tokyo, Nhật Bản, qianghu0515@gmail.com; Jie Zhang, Phòng thí nghiệm Noah's Ark, Huawei, Tây An, Trung Quốc, clark.zhang@huawei.com; Yang Liu, Đại học Công nghệ Nanyang, Singapore, yangliu@ntu.edu.sg.

Quyền tạo bản sao kỹ thuật số hoặc bản cứng của tất cả hoặc một phần công trình này để sử dụng cá nhân hoặc trong lớp học được cấp miễn phí với điều kiện các bản sao không được tạo ra hoặc phân phối vì lợi nhuận hoặc lợi thế thương mại và các bản sao phải mang thông báo này và trích dẫn đầy đủ trên trang đầu tiên. Bản quyền cho các thành phần của công trình này thuộc sở hữu của người khác ngoài (các) tác giả phải được tôn trọng. Việc tóm tắt có ghi nguồn được cho phép. Để sao chép khác, hoặc tái xuất bản, để đăng trên máy chủ hoặc để phân phối lại cho các danh sách, yêu cầu sự cho phép cụ thể trước và/hoặc một khoản phí. Yêu cầu quyền từ permissions@acm.org.
©2018 Bản quyền thuộc về chủ sở hữu/tác giả. Quyền xuất bản được cấp phép cho ACM.
ACM 0004-5411/2018/8-ART111
https://doi.org/XXXXXXX.XXXXXXX
J. ACM, Vol. 37, No. 4, Article 111. Ngày xuất bản: Tháng 8 2018.arXiv:2212.10017v3 [cs.SE] 17 Tháng 4 2024

--- TRANG 2 ---
111:2 W. Ma, S. Liu và M. Zhao et al.

Nghiên cứu này làm phong phú thêm hiểu biết của chúng ta về khả năng của các mô hình mã trong việc phân tích cú pháp và ngữ nghĩa. Các phát hiện của chúng tôi cung cấp những hiểu biết có giá trị cho việc cải tiến mô hình mã trong tương lai, giúp tối ưu hóa ứng dụng của chúng trong nhiều nhiệm vụ liên quan đến mã.

Định dạng Tham chiếu ACM:
Wei Ma, Shangqing Liu, Mengjie Zhao, Xiaofei Xie, Wenhan Wang, Qiang Hu, Jie Zhang, và Yang Liu. 2018. Khám Phá Các Mô Hình Tiền Huấn Luyện Mã: Nghiên Cứu Khả Năng Cú Pháp và Ngữ Nghĩa. J. ACM 37, 4, Article 111 (Tháng 8 2018), 29 trang. https://doi.org/XXXXXXX.XXXXXXX

1 GIỚI THIỆU

Nhiều mô hình mã [2,4,13,17,29,31,41,42,63,71] đã được đề xuất để thúc đẩy mạnh mẽ sự phát triển của trí tuệ mã. Nhiều phương pháp kỹ thuật phần mềm dựa trên việc tinh chỉnh các mô hình tiền huấn luyện này, như phát hiện mã trùng lặp, phát hiện lỗ hổng và hoàn thành mã. Gần đây, các mô hình ngôn ngữ lớn (LLM) đã được chứng minh có khả năng nổi bật [72] mà các mô hình tiền huấn luyện không có. Công nghệ này làm cho việc tự động tạo phần mềm trở nên khả thi, như MetaGPT [19]. Mặc dù các mô hình này đã được chứng minh hiệu quả trên nhiều nhiệm vụ liên quan đến mã, một vấn đề cơ bản vẫn chưa được giải quyết đối với những mô hình mã này về cách chúng hiểu mã. Đáng kể, các nghiên cứu gần đây [14,28,75] chỉ ra rằng các mô hình mã không thể đưa ra kết quả hợp lý nếu sử dụng các thủ thuật thay thế hoặc chèn token. Đối với các mô hình mã, chúng ta nên xem xét sâu sắc khả năng học các đặc điểm cơ bản của mã, "Các mô hình mã này có thể học được loại kiến thức mã nào?". Một chương trình bao gồm các tính năng cú pháp (ví dụ: AST) và thông tin ngữ nghĩa (ví dụ: phụ thuộc dữ liệu); do đó, vấn đề này có thể được phân tách thêm thành "Các mô hình mã có thể nắm bắt cú pháp chương trình tốt không?" và "Các mô hình mã có thể học được loại ngữ nghĩa chương trình nào?". Các nghiên cứu trước đã bắt đầu khám phá những câu hỏi được nêu ra, đặc biệt là câu hỏi phụ đầu tiên. Tuy nhiên, hiểu biết sâu sắc hơn về kiến thức được các mô hình mã thu được vẫn còn khó nắm bắt. Trong khi nghiên cứu của Wan et al. [69] và Hernández López et al. [18] cho thấy rằng các mô hình tiền huấn luyện mã có thể nắm bắt cú pháp chương trình, phân tích của họ không mở rộng đến ngữ nghĩa chương trình. Cũng quan trọng cần lưu ý rằng những nghiên cứu này có hai giả định: 1) số lượng liên kết giữa các nút có liên quan đến cú pháp mã; 2) tồn tại mối quan hệ tuyến tính giữa biểu diễn mã trong không gian chiều cao và chiều thấp. Tuy nhiên, những giả định này có một số hạn chế: 1) số lượng liên kết không nhất thiết phải liên quan đến cú pháp mã. 2) khoảng cách nhỏ hơn trong văn bản mã thô không có nghĩa là độ gần cú pháp trong không gian biểu diễn. Hơn nữa, Troshin và Chirkova [66] xem xét cả cú pháp và ngữ nghĩa mã thông qua các nhiệm vụ khác nhau. Tuy nhiên, công trình này tuân theo một phương pháp tương tự với các nghiên cứu trước đó khi phân tích cú pháp. Nó cũng không điều tra kỹ lưỡng các ngữ nghĩa khác nhau vốn có trong lập trình. Quan trọng hơn, không có nghiên cứu nào về bộ giải mã transformer, đây là kiến trúc của hầu hết các LLM, như các họ StarCoder [34] và Llama [58].

Những câu hỏi này có ý nghĩa quan trọng để chúng ta xem xét các ứng dụng của mô hình mã trong kỹ thuật phần mềm. Nếu các mô hình mã có thể hiểu mã gần như hoàn hảo, đầu ra của các mô hình mã có thể được tin tưởng và việc tạo phần mềm tự động là khả thi. Để giải quyết những thách thức nêu trên, trong bài báo này, chúng tôi điều tra toàn diện bốn mô hình tiền huấn luyện mã được áp dụng rộng rãi: CodeBERT [13] (Chỉ mã hóa), GraphCodeBERT [17] (Chỉ mã hóa), CodeT5 [71] (Mã hóa-giải mã) và UnixCoder [16] (Kiểu UniLM). Chúng tôi cũng bao gồm ba mô hình ngôn ngữ lớn (LLM), StarCoder [34], CodeLlama [58] và CodeT5+ [70].

Bốn nhiệm vụ thăm dò được sử dụng để phân tích khả năng của các mô hình trong việc học cú pháp và ngữ nghĩa mã. Cụ thể, chúng tôi sử dụng hai nhiệm vụ thăm dò cú pháp, cụ thể là dự đoán cặp nút cú pháp và dự đoán gắn thẻ cú pháp token. Cả hai nhiệm vụ đều nhằm thao tác Cây Cú pháp Trừu tượng (AST) để đánh giá khả năng của các mô hình tiền huấn luyện trong việc học cú pháp mã vì AST mang tất cả thông tin cú pháp của mã. Dự đoán cặp nút cú pháp nhằm xác định liệu

J. ACM, Vol. 37, No. 4, Article 111. Ngày xuất bản: Tháng 8 2018.

--- TRANG 3 ---
Khám Phá Các Mô Hình Tiền Huấn Luyện Mã: Nghiên Cứu Khả Năng Cú Pháp và Ngữ Nghĩa 111:3

các biểu diễn vector của hai đoạn gần nhau về cú pháp có thể hiện sự tương tự cú pháp hay không trong khi dự đoán gắn thẻ cú pháp token nhằm xác định liệu biểu diễn vector có nắm bắt quy tắc cú pháp của token riêng lẻ hay không. Dự đoán cặp nút cú pháp là để khôi phục cấu trúc AST từ biểu diễn vector, và dự đoán gắn thẻ cú pháp token là để gán vai trò cú pháp cho mỗi token mã trong không gian biểu diễn. Cả hai thông tin cú pháp đều quan trọng để các mô hình mã hiểu cú pháp mã ở cấp độ toàn cục và cục bộ. Ý định đằng sau hai nhiệm vụ cú pháp là biểu diễn vector token mã nên giữ các thuộc tính cú pháp tồn tại trong mã: mối quan hệ cú pháp giữa các token mã và thuộc tính cú pháp của mỗi token mã.

Ngoài phân tích cú pháp, chúng tôi tiếp tục thiết kế hai nhiệm vụ thăm dò ngữ nghĩa, cụ thể là dự đoán quan hệ ngữ nghĩa và dự đoán lan truyền ngữ nghĩa. Cả hai nhiệm vụ đều được thiết kế để điều tra mức độ mà các mô hình mã có thể học hiệu quả các khía cạnh khác nhau của ngữ nghĩa mã. Dự đoán quan hệ ngữ nghĩa là để khôi phục các cấu trúc ngữ nghĩa mã quan trọng trong không gian biểu diễn, bao gồm Đồ thị Phụ thuộc Dữ liệu (DDG), Đồ thị Phụ thuộc Điều khiển (CDG) và Đồ thị Luồng Điều khiển (CFG). Những cấu trúc ngữ nghĩa này có thể biểu diễn việc thực thi mã và các trạng thái bên trong. Dự đoán lan truyền ngữ nghĩa là để xem liệu chúng ta có thể quan sát mối quan hệ phụ thuộc dài trong không gian vector hay không vì một biến có thể được khai báo trong câu lệnh đầu tiên nhưng được sử dụng ở cuối. Cuối cùng, chúng tôi thực hiện phân tích thống kê cho các trọng số chú ý để hiểu toàn diện vai trò và phân phối chú ý trong việc học ngữ nghĩa của mã.

Phân tích cú pháp của chúng tôi cho thấy rằng 1) các mô hình mã hiệu quả nắm bắt các mối quan hệ cú pháp giữa các cặp token và thuộc tính này dễ quan sát hơn trong các tầng ẩn nông, cho thấy hiểu biết mạnh mẽ về cú pháp mã ở cấp độ cấu trúc; 2) các mô hình mã thành thạo trong việc xác định vai trò cú pháp của các token riêng lẻ và thuộc tính này dễ quan sát hơn trong các tầng ẩn sâu. Tuy nhiên, các mô hình tiền huấn luyện mã cho thấy hiệu suất vượt trội so với LLM đối với gắn thẻ cú pháp, cho thấy các đặc điểm cú pháp khó quan sát hơn trong biểu diễn mã từ LLM. Sự dễ dàng quan sát không liên quan trực tiếp đến hiệu suất của mô hình trên các nhiệm vụ downstream, vì nó phụ thuộc vào nhiều yếu tố, như chất lượng dữ liệu và phương pháp tinh chỉnh. Tuy nhiên, nó có thể chỉ ra khó khăn trong việc xây dựng và tinh chỉnh một mô hình tốt cho nhiệm vụ downstream dựa trên LLM. Trong thực tế, mọi người đã thử và thậm chí phát hiện rằng hiệu suất của các mô hình nhỏ truyền thống tốt hơn các mô hình lớn trong một số trường hợp [8, 27].

Phân tích ngữ nghĩa của chúng tôi cho thấy hiệu quả khác nhau trong khả năng của các mô hình mã để dự đoán các mối quan hệ ngữ nghĩa. Các mô hình hiện tại cung cấp một số hiểu biết tinh tế về ngữ nghĩa mã, như phụ thuộc dữ liệu, nhưng cũng làm nổi bật các lĩnh vực cần cải thiện, đặc biệt trong việc nắm bắt các cấu trúc ngữ nghĩa phức tạp. So với hiệu suất của các nhiệm vụ cú pháp, hiệu suất của các mô hình mã trong ngữ nghĩa tương đối thấp. Đối với CodeT5+, sự khác biệt hiệu suất giữa bộ mã hóa và bộ giải mã rất lớn. Chúng tôi nghĩ điều này có thể được gây ra bởi các cơ chế hoạt động khác nhau của bộ mã hóa và bộ giải mã. Bộ mã hóa tập trung nhiều hơn vào việc lồng thông tin toàn cục. Bộ giải mã tập trung nhiều hơn vào việc tạo token tiếp theo dựa trên văn bản trước đó. Sự khác biệt này đặc biệt rõ ràng khi phân tích cơ chế chú ý. Khi chúng tôi tiến hành phân tích chú ý dựa trên các phụ thuộc điều khiển, chúng tôi phát hiện rằng đối với kiến trúc bộ giải mã, đóng góp trọng số của các token có phụ thuộc điều khiển nhỏ hơn đóng góp trọng số của các phụ thuộc không điều khiển. Chúng tôi tin rằng điều này là do bộ mã hóa tập trung vào việc mã hóa thông tin toàn cục, nhưng bộ giải mã tập trung nhiều hơn vào các token trước đó và thông tin không phụ thuộc điều khiển khác, dẫn đến các phân phối trọng số khác nhau.

Thông qua phân tích toàn diện, công trình của chúng tôi chỉ ra rằng các mô hình mã vẫn cần được cải thiện để học cú pháp và ngữ nghĩa mã, làm cho những thuộc tính này dễ quan sát hơn, từ đó giảm khó khăn trong việc xây dựng mô hình nhiệm vụ downstream. Việc cải thiện nên tập trung vào cách tích hợp cú pháp và ngữ nghĩa mã vào các mô hình mã. Điều này có thể cần các chiến lược huấn luyện mới có thể tích hợp toàn bộ cấu trúc mã thay vì làm phẳng những cấu trúc này. Mặc dù khả năng mô hình

J. ACM, Vol. 37, No. 4, Article 111. Ngày xuất bản: Tháng 8 2018.

--- TRANG 4 ---
111:4 W. Ma, S. Liu và M. Zhao et al.

được mở rộng theo kích thước của nó [30,81], việc giải phóng khả năng của nó là thách thức và cần một công việc bổ sung không tầm thường để làm cho các tính năng dễ quan sát hơn trong không gian biểu diễn cho các nhiệm vụ downstream.

Tóm lại, công trình của chúng tôi có những đóng góp sau:

• Chúng tôi đề xuất các nhiệm vụ thăm dó cú pháp và ngữ nghĩa để phân tích khả năng của mô hình mã trong việc hiểu cú pháp và ngữ nghĩa bằng cách trực tiếp khôi phục các cấu trúc cú pháp và ngữ nghĩa mã (AST, CFG, CDG và DDG) từ biểu diễn mã. Chúng tôi nghiên cứu phân phối các trọng số chú ý liên quan đến ngữ nghĩa mã.

• Chúng tôi tiết lộ rằng mối quan hệ cú pháp dễ quan sát hơn trong các tầng ẩn nông, trong khi cú pháp vai trò token dễ quan sát hơn trong các tầng sâu. Các mô hình mã có hiệu suất vượt trội cho biểu diễn cú pháp so với biểu diễn ngữ nghĩa. Đồng thời, các mô hình mã có hiệu suất kém hơn đối với CFG so với các cấu trúc ngữ nghĩa khác, điều này yêu cầu các mô hình mã được tăng cường để biểu diễn ngữ nghĩa CFG. Các tầng ẩn khác nhau cho thấy các mức độ quan sát khác nhau cho các loại cú pháp và ngữ nghĩa mã khác nhau.

• Chúng tôi đầu tiên bao gồm các mô hình ngôn ngữ lớn và cho thấy rằng hiệu suất của chúng trên các nhiệm vụ thăm dò không có lợi thế lớn so với các mô hình tiền huấn luyện, xem xét số lượng tham số khổng lồ của chúng. Điều này phản ánh rằng cú pháp và ngữ nghĩa mã bị ẩn và không rõ ràng trong biểu diễn của LLM.

Chúng tôi hy vọng những hiểu biết này có thể truyền cảm hứng cho các nhà nghiên cứu đào tạo các mô hình mã mạnh mẽ hơn. Khi sử dụng những mô hình này, việc thiết kế các quy trình công việc được hướng dẫn bởi sự hiểu biết về những mô hình này là cần thiết, xem xét liệu việc tích hợp các tính năng mã bổ sung có được bảo đảm hay không. Mặc dù nhiều yếu tố, bao gồm chất lượng dữ liệu, độ phức tạp của các mô hình nhiệm vụ downstream và phương pháp tích hợp tính năng ảnh hưởng đến hiệu suất mô hình trong các nhiệm vụ downstream, công trình của chúng tôi có thể cung cấp một số hướng dẫn cho thiết kế mô hình và dữ liệu của họ. Các mô hình thiếu hiểu biết ngữ nghĩa cần xem xét tăng cường thông tin ngữ nghĩa thông qua tích hợp tính năng khi giải quyết các nhiệm vụ downstream. Công trình của chúng tôi nhấn mạnh rằng không bắt buộc phải sử dụng đầu ra của tầng cuối - các tầng trung gian có thể biểu đạt cú pháp và ngữ nghĩa một cách đầy đủ. Tất cả mã và dữ liệu có thể được tìm thấy tại kho lưu trữ¹.

2 ĐỘNG LỰC

Khả năng của các mô hình mã tiền huấn luyện đã được thảo luận rộng rãi trong các nghiên cứu trước đây [18,66,69]. Tuy nhiên, phân tích của họ dựa trên giả định rằng cú pháp gần hơn giữa hai token trong mã sẽ dẫn đến khoảng cách cú pháp nhỏ hơn, được đo bằng số cạnh giữa các nút trong AST [69], và tương ứng, khoảng cách nhỏ hơn trong biểu diễn vector, như khoảng cách Euclidean được mã hóa bởi mô hình mã. Nói cách khác, giả định nói rằng "cú pháp gần hơn" dẫn đến "khoảng cách cạnh nhỏ hơn trong AST" mà lần lượt dẫn đến "khoảng cách biểu diễn nhỏ hơn." Tuy nhiên, thứ nhất, "khoảng cách cạnh nhỏ hơn trong AST" không nhất thiết có nghĩa là "cú pháp gần". Thứ hai, không gian biểu diễn vector mã là một không gian chiều cao. Ví dụ, CodeBERT tạo thành không gian 768 chiều nhưng khoảng cách nút trong AST là không gian chiều thấp. Do đó, các phương pháp khoảng cách truyền thống được sử dụng trong những công trình này sẽ không hoạt động tốt do lời nguyền của chiều cao [1,52]. Thứ nhất, ánh xạ khoảng cách từ không gian chiều cao sang không gian chiều thấp có thể không chính xác, tức là khoảng cách nhỏ hơn trong AST có thể không chắc chắn biểu diễn khoảng cách euclidean nhỏ hơn trong không gian chiều cao. Thứ hai, khoảng cách cạnh nhỏ giữa hai nút trong AST không đảm bảo mối quan hệ cú pháp gần. Sự thiên vị này có thể làm cho kết luận và phương pháp của họ không được tổng quát hóa và có thể cản trở sự hiểu biết của chúng ta về cách các mô hình mã

¹https://github.com/Marvinmw/probing_analysis_tosem.git

J. ACM, Vol. 37, No. 4, Article 111. Ngày xuất bản: Tháng 8 2018.

--- TRANG 5 ---
Khám Phá Các Mô Hình Tiền Huấn Luyện Mã: Nghiên Cứu Khả Năng Cú Pháp và Ngữ Nghĩa 111:5

[THIS IS FIGURE: Shows a code snippet and AST tree diagram labeled "Hàm DefifreturnreturncompareModule>baabdef max (a ,b)#return maximum valuedefmax(a,b){if ( a > b ): returnaelse:returnb}AST"]

Hình 1. Một đoạn mã đơn giản với AST của nó.

[THIS IS FIGURE: Shows distance measurements "85.45" and "65.78"]

Hình 2. Khoảng cách Euclidean của các biểu diễn token.

mã hóa cú pháp. Cũng như, nó ước tính sai sự tương tự cú pháp mã và có thể dẫn đến thiếu phân tích cấu trúc cú pháp cho các mô hình mã. Kết luận có thể không hữu ích để cải thiện hiệu suất mô hình. Chúng tôi cung cấp hai ví dụ để minh họa tốt hơn.

Hình 1 là ví dụ đầu tiên và cung cấp một hình ảnh của một hàm được phân tích thành AST. Chúng ta có thể thấy rằng khoảng cách nút giữa biến "a" và "b" từ điều kiện if (được đánh dấu trong hình vuông màu xanh lá cây) là 2 hop trong khi khoảng cách nút giữa biến "a" này (hình vuông màu xanh lá cây) và biến "a" (hình vuông màu cam) từ câu lệnh return là 4 hop. Do đó, chúng ta có thể thấy rằng trong không gian chiều thấp, biến "a" từ điều kiện if gần với biến "b" và chúng gần nhau về cú pháp hơn biến "a" từ câu lệnh return. Tuy nhiên, kết luận ngược lại trong không gian chiều cao. Chúng tôi mã hóa hàm này bằng CodeBERT và tính khoảng cách euclidean giữa các biểu diễn vector token cho những biến này. Như được hiển thị trong Hình 2, chúng ta có thể thấy rằng khoảng cách từ biến "a" (hình vuông màu xanh lá cây) đến biến "b" (hình vuông màu xanh lá cây) từ điều kiện if là 85.45 trong khi khoảng cách từ nó đến biến "a" (hình vuông màu cam) từ câu lệnh return là 65.78. Do đó, thông qua ví dụ này, chúng tôi thấy rằng các khoảng cách trong không gian thấp và không gian cao không nhất quán, và chúng có thể không có mối quan hệ tích cực.

Đối với ví dụ khác, Hình 3 chứng minh rằng biến đối số hàm "b" có 4 hop đến "return" trong câu lệnh cuối của hàm này, và nó chia sẻ cùng khoảng cách với biến đối số hàm "c". Tuy nhiên, "b" nên gần hơn về cú pháp với "c" vì chúng là các đối số hàm.

J. ACM, Vol. 37, No. 4, Article 111. Ngày xuất bản: Tháng 8 2018.

--- TRANG 6 ---
111:6 W. Ma, S. Liu và M. Zhao et al.

Hơn nữa, những công trình này chủ yếu tập trung vào khám phá khả năng của các mô hình tiền huấn luyện mã trong việc học cú pháp mã. Các thảo luận sâu sắc về ngữ nghĩa mã đã học (ví dụ: phân tích phụ thuộc điều khiển/dữ liệu) bị thiếu. Troshin và Chirkova [66] sử dụng một số nhiệm vụ liên quan đến ngữ nghĩa trong khi chúng không chỉ liên quan đến một thuộc tính mã duy nhất thường được yêu cầu bởi phân tích thăm dò, sự đa dạng của ngữ nghĩa chương trình cũng bị bỏ qua và thiếu phân tích sâu. Thảo luận về ngữ nghĩa mã là một phần thiết yếu và không thể bỏ qua vì nó tạo thành nền tảng cho nhiều nhiệm vụ liên quan đến mã [9, 36, 38, 39, 80]. Những công trình này cũng thiếu phân tích về LLM.

Để khắc phục những vấn đề trên, chúng ta cần khám phá các phương pháp tốt hơn mà không có giả định rằng số cạnh giữa các nút có liên quan đến cú pháp mã. Mã là một cấu trúc dữ liệu rất đặc biệt. Trước hết, nó có định nghĩa cú pháp nghiêm ngặt; tất cả mã phải tuân thủ những quy tắc cú pháp này. Tất cả tên được sử dụng trong mã chỉ cần tuân theo các quy tắc đặt tên cụ thể. Tuy nhiên, để thuận tiện cho việc đọc của con người, con người thường chú thích mã bằng tên để dễ đọc và hiểu. Những quy tắc cú pháp này có thể được biểu đạt một cách có cấu trúc bởi cây cú pháp trừu tượng (AST). Dựa trên những quy tắc cú pháp được xác định này, mã cũng biểu đạt thông tin ngữ nghĩa sâu sắc hơn. Mã có chức năng nhất định, có thể thực thi được và thực hiện logic cụ thể. Thông tin ngữ nghĩa này bao gồm luồng điều khiển, luồng dữ liệu và các phụ thuộc. Hầu như tất cả các vấn đề liên quan đến mã đều yêu cầu thông tin này để giải quyết. Luồng điều khiển mô tả logic cụ thể của mã, biểu đạt chức năng được thực hiện bởi mã. Luồng dữ liệu và các phụ thuộc biểu đạt mối liên kết ngữ nghĩa giữa các phần khác nhau của mã. Chúng rất quan trọng cho chất lượng mã, và phát hiện và sửa chữa lỗ hổng khuyết điểm. Chúng ta có thể thấy rằng AST, Đồ thị Luồng Điều khiển (CFG), Đồ thị Phụ thuộc Điều khiển (CDG), và Đồ thị Phụ thuộc Dữ liệu (DDG) là các biểu đạt có cấu trúc của cú pháp và ngữ nghĩa mã. Các token mã có các mối quan hệ hoặc thuộc tính cú pháp và ngữ nghĩa khác nhau dựa trên những cấu trúc này. Những mối quan hệ và thuộc tính này quan trọng để hiểu mã và nên được biểu diễn trong không gian vector đã học của các mô hình mã. Khả năng của một mô hình mã là ánh xạ các đặc điểm của mã vào không gian vector. Đối với một mô hình mã tốt, không gian đặc trưng của nó nên giữ tất cả các đặc điểm của mã càng nhiều càng tốt. Các nhiệm vụ thăm dò mà chúng tôi thiết kế là để tái tạo những mối quan hệ cấu trúc dữ liệu này trong không gian đặc trưng vector.

Do đó, để phân tích cú pháp, chúng tôi cố gắng tái tạo AST (dự đoán cặp nút cú pháp) và dự đoán nhãn cú pháp của các token mã (gắn thẻ cú pháp token). AST mang tất cả thông tin cú pháp của mã. Dự đoán cặp nút cú pháp có thể phản ánh cách các mô hình mã học cấu trúc cú pháp bằng cách tái tạo AST trong không gian biểu diễn. Gắn thẻ cú pháp token là để xem liệu vai trò cú pháp của mỗi token có được mã hóa trong biểu diễn hay không, đây là một thuộc tính cú pháp vi mô. Cả hai đều quan trọng để các mô hình mã học cú pháp mã. Để phân tích ngữ nghĩa, chúng tôi tái tạo cấu trúc ngữ nghĩa mã (dự đoán lan truyền ngữ nghĩa) bao gồm đồ thị phụ thuộc điều khiển (CDG), đồ thị phụ thuộc dữ liệu (DDG) và đồ thị luồng điều khiển (CFG). Chúng tôi cũng bao gồm phụ thuộc điều khiển và dữ liệu với khoảng cách dài (dự đoán lan truyền ngữ nghĩa). Ba cấu trúc ngữ nghĩa, CDG, DDG và CFG, là các khái niệm cốt lõi trong phân tích chương trình, tối ưu hóa, thanh công cụ và nhiều nhiệm vụ kỹ thuật phần mềm khác. Phụ thuộc dài là một đặc điểm đặc biệt của chương trình. Một người có thể khai báo một biến ở đầu nhưng sử dụng nó sau hàng trăm dòng. Hiểu chúng quan trọng đối với các mô hình mã. Chi tiết có thể được tìm thấy trong Phần 3.

3 PHƯƠNG PHÁP LUẬN

Trong phần này, chúng tôi giới thiệu phân tích của chúng tôi về các phương pháp thăm dò cho cú pháp và ngữ nghĩa mã.

3.1 Kiến Thức Sơ Bộ

Các nhà nghiên cứu kỹ thuật phần mềm thời kỳ đầu đã sử dụng kỹ thuật đặc trưng dựa trên kiến thức thực nghiệm của chuyên gia để trích xuất các đặc trưng mã làm đầu vào cho các thuật toán học máy. Thông thường, các chuyên gia thiết kế các quy tắc trích xuất đặc trưng dựa trên các nhiệm vụ cụ thể cần giải quyết, như số lượng vòng lặp và

J. ACM, Vol. 37, No. 4, Article 111. Ngày xuất bản: Tháng 8 2018.

--- TRANG 7 ---
Khám Phá Các Mô Hình Tiền Huấn Luyện Mã: Nghiên Cứu Khả Năng Cú Pháp và Ngữ Nghĩa 111:7

độ phức tạp mã. Những đặc trưng dựa trên quy tắc này có tính diễn giải cao nhưng bị hạn chế bởi kinh nghiệm của các chuyên gia và không thể bao quát cấu trúc cú pháp và ngữ nghĩa mã. Trong những năm gần đây, với sự trỗi dậy của Transformer và sự xuất hiện của CodeBERT, các nhà nghiên cứu kỹ thuật phần mềm có thể trích xuất các đặc trưng mã dựa trên khả năng mã hóa của các mô hình tiền huấn luyện, giảm đáng kể sự phụ thuộc vào kinh nghiệm và kiến thức chuyên gia. Transformer với kiến trúc mã hóa-giải mã được đề xuất vào năm 2017 [68]. Bộ mã hóa và bộ giải mã được xếp chồng bởi nhiều tầng mã hóa và giải mã tương ứng. Cả hai đều chứa các cơ chế tính toán và phân bổ chú ý phức tạp. Sự khác biệt giữa tầng mã hóa và tầng giải mã là tầng mã hóa xem xét bối cảnh của mô hình; tầng giải mã chỉ xem xét bối cảnh đầu ra của mô hình. Các mô hình mã tiền huấn luyện sẽ sử dụng dữ liệu mã khổng lồ được thu thập từ Internet như GitHub và Stack Overflow. Các mô hình mã tiền huấn luyện có thể được nhóm thành ba nhóm về kiến trúc mạng của chúng. Nhóm đầu tiên sử dụng bộ mã hóa transformer như CodeBERT. Nhóm thứ hai sử dụng bộ giải mã transformer như CodeGPT. Nhóm thứ ba sử dụng bộ mã hóa-giải mã transformer như CodeT5.

Trước khi tiền huấn luyện, chúng ta cần huấn luyện một tokenizer dựa trên văn bản mã để học cách phân đoạn văn bản mã, như thuật toán tokenization Byte-Pair Encoding (BPE)². Khi sử dụng Transformer để học đặc trưng, mã văn bản gốc sẽ được tokenize và chúng ta sẽ nhận được một chuỗi các token mã. Sau đó, chúng ta chuyển đổi nó thành chỉ số tương ứng trong tầng nhúng. Điều này hoàn thành việc chuyển đổi từ mã thô sang vector. Mô hình sau đó được tối ưu hóa dựa trên mô hình huấn luyện được thực hiện. So với các mô hình tiền huấn luyện truyền thống, LLM cũng là kiến trúc transformer nhưng có số lượng tham số khổng lồ và lượng dữ liệu huấn luyện khổng lồ. LLM được điều chỉnh theo sở thích của con người. Vì việc tinh chỉnh toàn bộ tham số của LLM rất tốn kém, chúng ta thường sử dụng LoRA [22], học few-shot và tinh chỉnh prompt để giải quyết các nhiệm vụ downstream. Một số nghiên cứu cho thấy rằng nó có khả năng nổi bật và tổng quát hóa [72]. Các nhà nghiên cứu trong kỹ thuật phần mềm đã phát hiện rằng các mô hình lớn có khả năng tạo và phân tích mã tốt [10, 11, 76].

Các phương pháp trích xuất đặc trưng dựa trên mô hình mã có một tiền đề: các đặc trưng cấu trúc của mã được bao gồm trong không gian đặc trưng của mô hình mã. Các mô hình mã huấn luyện chính hiện tại dựa trên mô hình ngôn ngữ có mặt nạ (MLM), mô hình ngôn ngữ nhân quả (CLM) và các biến thể khác của hai mô hình trước. Nói đơn giản, MLM có nghĩa là che giấu ngẫu nhiên các token mã và sau đó khôi phục chúng. Sự khác biệt là CLM dự đoán token tiếp theo dựa trên những token ở trên. Những phương pháp tiền huấn luyện này không được điều chỉnh để học các đặc trưng mã. Trong hầu hết các trường hợp, chúng ta chuyển đổi mã thành định dạng văn bản mà chúng yêu cầu. Việc phân tích và hiểu không gian đặc trưng của các mô hình mã là một thách thức.

3.2 Mô Hình Phân Tích Thăm Dò

Phân tích thăm dò là một phương pháp nghiên cứu được sử dụng để hiểu và đánh giá kiến thức và thông tin mã hóa trong các mô hình ngôn ngữ. Phương pháp phân tích này tiết lộ sự thành thạo của mô hình đối với các loại thông tin ngôn ngữ cụ thể trong quá trình học của nó bằng cách thiết kế và áp dụng một loạt các nhiệm vụ thăm dò. Các nhiệm vụ thăm dò thường là những nhiệm vụ đơn giản, có mục tiêu được thiết kế đặc biệt để kiểm tra hiểu biết của mô hình về một thuộc tính ngôn ngữ cụ thể, như cấu trúc ngữ pháp, ý nghĩa từ và mối quan hệ câu. Trong nghiên cứu của chúng tôi, đối với tất cả các nhiệm vụ thăm dò được thiết kế, chúng tôi sử dụng bộ phân loại thăm dò cạnh [64] như được mô tả trong Hình 4. Phù hợp với các công trình trước đây [6,55,64,67] trong tài liệu thăm dò, chúng tôi giữ các tham số của mô hình mã tiền huấn luyện cố định, có nghĩa là chúng sẽ không được cập nhật trong quá trình huấn luyện. Đối với một đầu vào mã đã cho 𝑥, chúng tôi sử dụng tokenizer để tokenize 𝑥 thành một chuỗi token với hai token bắt đầu và kết thúc đặc biệt như được biểu thị ở dưới cùng của Hình 4.

²https://huggingface.co/learn/nlp-course/en/chapter6/5

J. ACM, Vol. 37, No. 4, Article 111. Ngày xuất bản: Tháng 8 2018.

--- TRANG 8 ---
111:8 W. Ma, S. Liu và M. Zhao et al.

[THIS IS FIGURE: Diagram showing syntax tree with nodes and relationships labeled "comvaraintc+bassignc>b=mulvaraintb*bifassignadd=returnareturnafuncargsintf(int b, int c){int a = b + c;if ( b > c ):{int a = b * b;return a;} return a;}ASTargbintargcint"]

Hình 3. Dự Đoán Cặp Nút Cú Pháp.

[THIS IS FIGURE: Flow diagram showing model architecture with components like "𝐶𝐿𝑆𝑥!𝑥"𝑥"#!𝑥$𝑥$#!𝑥%𝐸𝑁𝐷", "Input tokens", "Contextual Representation", "Attention Pooling", "MLP", "Span Representation", "Probing Classifier"]

Hình 4. Mô hình phân tích.

Ban đầu, chúng ta có thể thu được biểu diễn bối cảnh 𝑟𝑖 của mỗi tầng ẩn cho mỗi token 𝑥𝑖 từ các mô hình mã. Tiếp theo, chúng tôi trích xuất các đoạn token mã cụ thể có liên quan đến nút đồ thị hoặc cây mà chúng tôi quan tâm, và chúng được biểu thị là 𝑠1 và 𝑠2 trong Hình 4. Một đoạn token mã đại diện cho một phần mã từ một nút trong AST hoặc đồ thị phụ thuộc. Độ dài của một đoạn token khác nhau và có thể chứa số lượng token khác nhau. Sau đó, những đoạn token này được truyền qua một attention pool, ánh xạ chúng thành một vector có kích thước cố định. Attention pool là một tầng chú ý có thể tự động gán trọng số khác nhau cho mỗi biểu diễn token trong đoạn token, và sau đó tổng hợp chúng. Cuối cùng, vector kết quả được chuyển tiếp đến bộ phân loại thăm dò, được thực hiện như một bộ phân loại perceptron đa tầng (MLP) cho phân loại. Bộ phân loại MLP có thể huấn luyện được và được biểu thị bằng ký hiệu 𝐶. Các vector đặc trưng có kích thước cố định của hai đoạn token đóng vai trò làm đầu vào cho 𝐶, và bộ phân loại xác định liệu hai đoạn token có mối quan hệ cú pháp hoặc ngữ nghĩa hay không. Chúng tôi sử dụng các đoạn token vì các phần mã có liên quan về mặt cú pháp hoặc ngữ nghĩa được tokenize thành hai danh sách token có độ dài khác nhau tương ứng. Những danh sách token này được gọi là các đoạn token, sau đó được chuyển đổi thành vector có kích thước cố định bởi attention pool.

3.3 Thăm Dò Cú Pháp

Để giải quyết những sự không chính xác có thể xảy ra từ việc chuyển đổi không gian chiều cao sang không gian chiều thấp, cũng như thiếu mối quan hệ có thể có giữa khoảng cách trong AST và khoảng cách cú pháp như được chỉ ra trong phần động lực, chúng tôi giới thiệu hai nhiệm vụ thăm dò cú pháp: dự đoán cặp-nút-cú pháp và gắn thẻ-cú pháp-token. Những nhiệm vụ này trực tiếp dự đoán các thuộc tính của các nút trong AST. Hai nhiệm vụ bổ sung cho nhau. Nhiệm vụ đầu tiên nhằm dự đoán mối quan hệ kết nối-cú pháp giữa các token mã, trong khi nhiệm vụ thứ hai tập trung vào xem xét vai trò cú pháp của các token mã riêng lẻ. Các token mã là những từ mã cơ bản sau khi mã được tokenize và mỗi nút chứa ít token mã. Thông qua nhiệm vụ đầu tiên, chúng ta có thể tái tạo AST cho biểu diễn token mã từ các mô hình mã. Nếu các biểu diễn token mã không chứa thông tin về cấu trúc AST, việc tái tạo AST là không thể. Thông qua nhiệm vụ thứ hai, chúng ta có thể tìm ra liệu các biểu diễn token mã có chứa các quy tắc cú pháp tương ứng được gán bởi quy tắc ngôn ngữ lập trình hay không.

3.3.1 Dự Đoán Cặp Nút Cú Pháp. Cho một mã nguồn, chúng ta có thể phân tích nó để thu được AST và tiếp tục chia AST này thành các cây con khác nhau. Mỗi cây con là một biểu thức cú pháp từ mã gốc và chúng tôi đặt tên nó là một đơn vị cú pháp. Bởi vì mỗi đơn vị cú pháp đại diện cho một biểu thức cú pháp hoàn chỉnh từ mã, do đó các nút trong một đơn vị có cú pháp-gần. Nhiệm vụ này được thiết kế để dự đoán bất kỳ cặp nút nào trong AST thuộc về một cây con. AST được tạo bởi bộ phân tích cú pháp và chứa tất cả thông tin cú pháp của mã. Đối với các mô hình mã, chúng nên giữ lại cấu trúc cú pháp như vậy trong không gian vector. Nếu chúng không thể, điều đó cho thấy rằng mô hình không có khả năng mã hóa cú pháp mã một cách hiệu quả. Thông qua nhiệm vụ này, chúng tôi nhằm xác minh liệu mô hình mã có thể nắm bắt và hiểu cấu trúc cú pháp này từ mã nguồn hay không, và sau đó tái tạo thông tin cú pháp trong không gian vector mà nó đại diện. Cụ thể, chúng tôi trình bày một ví dụ để minh họa tốt hơn. Như được hiển thị trong Hình 3, có một hàm có AST tương ứng được trình bày bên phải. Đối với AST này, chúng tôi chia nó thành các đơn vị khác nhau được đánh dấu bằng các màu khác nhau. Ví dụ, nút của "=" trong đơn vị màu đỏ, nên có cú pháp gần với nút bên trái của nó trong đơn vị này tức là nút của "int" và "a". Do đó, chúng được gắn nhãn với 1 như các mẫu tích cực. Đối với các nút của "int" và "a" trong đơn vị khác (được đánh dấu bằng màu xanh lá cây), vì chúng thuộc về đơn vị khác, chúng được gắn nhãn với 0 như các mẫu tiêu cực. Hình thức, nhiệm vụ này có thể được biểu thức như sau:

𝐶(𝑛0,𝑛1)=(
1𝑛0∈𝑇𝑖∩𝑛1∈𝑇𝑖
0𝑛0∈𝑇𝑖∩𝑛1∈𝑇𝑗

trong đó 𝑇𝑖 và 𝑇𝑗 (𝑖≠𝑗) là hai đơn vị cú pháp khác nhau trong AST và 𝑛0 và 𝑛1 là các nút trong đơn vị. Chúng tôi huấn luyện một bộ phân loại thăm dò nhị phân 𝐶 để học liệu bất kỳ cặp nút nào có cú pháp-gần dựa trên các biểu diễn nút được tính từ biểu diễn token của các mô hình mã bởi attention pool (Hình 4).

3.3.2 Gắn Thẻ Cú Pháp Token. Nhiệm vụ đầu tiên kiểm tra sự tương tự cú pháp giữa các nút AST khác nhau. Ngoài sự tương tự cú pháp, tất cả các token được gán một vai trò cú pháp bởi quy tắc ngôn ngữ lập trình. Để kiểm tra liệu các mô hình mã có thể học vai trò cú pháp token riêng lẻ hay không, chúng tôi đề xuất một nhiệm vụ phân loại đa lớp, cụ thể là gắn thẻ cú pháp token, và nhiệm vụ này yêu cầu biểu diễn mã tốt hơn và tinh tế hơn để gắn thẻ vai trò cú pháp của mỗi token mã. Điều này được thiết kế để thách thức và đánh giá độ sâu hiểu biết về ngôn ngữ lập trình đối với các mô hình mã. Một mô hình mã có thể thực hiện thành công gắn thẻ cú pháp token có thể hữu ích hơn trong các ứng dụng mã hóa phức tạp, như tạo mã.

Vì mỗi nút AST có loại nút của nó, một ý tưởng trực tiếp là sử dụng loại nút để gắn thẻ. Tuy nhiên, những nhãn cú pháp này rất trừu tượng, ví dụ, tên biến được gắn nhãn với "identifier" bởi quy tắc cú pháp, nhưng nó có ý nghĩa cú pháp khác nhau trong bối cảnh. Nếu nó trong khai báo hàm, nó thực sự là một đối số cho hàm này; tương tự, nếu nó trong việc gọi lớp, nó là một thuộc tính lớp. Do đó, chúng ta cần thiết kế các nhãn cụ thể cho những token trừu tượng này. Ban đầu chúng tôi xem xét loại cú pháp của các nút lá trong AST. Tiếp theo, chúng tôi tham khảo các loại nút cha của chúng để xây dựng các nhãn cụ thể. Cụ thể, chúng tôi thiết kế 36 nhãn gắn thẻ cho Java và 33 nhãn cho C/C++. Chúng tôi lọc các nhãn có tần suất thấp (𝑓𝑟𝑒<200) cho Java250 và POJ-104. Các nhãn chúng tôi sử dụng được mô tả trong Bảng 1.

J. ACM, Vol. 37, No. 4, Article 111. Ngày xuất bản: Tháng 8 2018.

--- TRANG 9 ---
Khám Phá Các Mô Hình Tiền Huấn Luyện Mã: Nghiên Cứu Khả Năng Cú Pháp và Ngữ Nghĩa 111:9

Bảng 1. Các nhãn của Gắn Thẻ Cú Pháp Token cho Java250 và POJ-104.

Java250
modifiers local_variable_declaration variable_declarator formal_parameters
array_type dimensions formal_parameter block
object_creation_expression argument_list field_access integral_type
method_invocation while_statement parenthesized_expression if_statement
expression_statement break_statement update_expression assignment_expression
identifier for_statement binary_expression return_statement
array_creation_expression dimensions_expr array_access ERROR
unary_expression throw_statement enhanced_for_statement ternary_expression
cast_expression generic_type type_arguments array_initializer

POJ-104
declaration array_declarator function_definition parameter_list
parameter_declaration compound_statement for_statement assignment_expression
binary_expression update_expression subscript_expression expression_statement
if_statement parenthesized_expression return_statement call_expression
argument_list string_literal pointer_expression init_declarator
function_declarator cast_expression type_descriptor break_statement
comma_expression initializer_list char_literal pointer_declarator
continue_statement while_statement field_expression sizeof_expression
case_statement

[THIS IS FIGURE: Diagram showing token syntax tagging with "If-StatPEBEBEBEPEBFAFAMIALBEBEALESif(a<c){Systemoutprint(a*x);}" and corresponding labels]

Hình 5. Gắn Thẻ Cú Pháp Token.

Bảng 2. Các nhãn gắn thẻ cho các token được sử dụng trong Hình 5.

Nhãn Mô tả
PE Biểu thức ngoặc đơn
BE Biểu thức nhị phân
B Khối
FA Truy cập trường
MI Gọi phương thức
AL Danh sách đối số
ES Câu lệnh biểu thức

Chúng tôi trình bày một ví dụ với nhãn cú pháp tương ứng trong Hình 5. Thông tin chi tiết của các nhãn trong ví dụ này được hiển thị trong Bảng 2. Cụ thể, chúng ta có thể thấy rằng các token "(" và ")" có các nhãn cú pháp khác nhau trong các bối cảnh khác nhau. Dấu ngoặc đơn "( )" được gắn nhãn với "PE" trong điều kiện if, trong khi dấu ngoặc đơn "( )" từ việc gọi phương thức được gắn nhãn với "AL". Chúng tôi thiết kế nhiệm vụ này để khám phá liệu những mô hình này có thể học cú pháp mã đúng cách từ ngữ pháp lập trình hay không.

3.4 Thăm Dò Ngữ Nghĩa

Các công trình trước đây chủ yếu tập trung vào phân tích khả năng của các mô hình mã tiền huấn luyện trong việc học cú pháp mã. Tuy nhiên, phân tích ngữ nghĩa mã cũng cần thiết. Nhóm này đánh giá khả năng của mô hình mã để hiểu ý nghĩa và hành vi của các đoạn mã. Trong phần này,

J. ACM, Vol. 37, No. 4, Article 111. Ngày xuất bản: Tháng 8 2018.

--- TRANG 10 ---
111:10 W. Ma, S. Liu và M. Zhao et al.

chúng tôi đề xuất hai nhiệm vụ thăm dò để phân tích ngữ nghĩa của mã đã học. Đầu tiên là dự đoán quan hệ ngữ nghĩa cho các đồ thị phụ thuộc (CDG, DDG và CFG). Dựa trên dự đoán, chúng ta có thể tái tạo cấu trúc của các đồ thị phụ thuộc. Các đồ thị phụ thuộc mô tả các mối quan hệ phức tạp như phụ thuộc điều khiển và dữ liệu, rất quan trọng để hiểu cách các phần khác nhau của chương trình tương tác. Nhiệm vụ thứ hai là dự đoán lan truyền ngữ nghĩa. Hiểu luồng điều khiển và dữ liệu là một khía cạnh nâng cao của phân tích ngữ nghĩa, vượt ra ngoài phân tích tĩnh đến cách chương trình sẽ hoạt động khi chạy. Nhiệm vụ này đánh giá khả năng của các mô hình mã để hiểu tính chất động của việc thực thi mã.

3.4.1 Dự Đoán Quan Hệ Ngữ Nghĩa. Các đồ thị phụ thuộc của một chương trình có thể biểu diễn tốt ngữ nghĩa mã [20]. Tương tự như nhiệm vụ dự đoán cặp nút cú pháp trong Phần 3.3.1, chúng tôi cũng trích xuất đồ thị phụ thuộc điều khiển (CDG), đồ thị phụ thuộc dữ liệu (DDG) và đồ thị luồng điều khiển (CFG) để dự đoán liệu các mô hình mã có thể học ngữ nghĩa mã hay không. Trong Đồ thị Phụ thuộc Điều khiển (CDG), Đồ thị Phụ thuộc Dữ liệu (DDG), và Đồ thị Luồng Điều khiển (CFG) được xây dựng, mỗi nút có một thuộc tính với một phần mã có thể được tokenize thành nhiều token. Chúng tôi gọi những token mã được suy ra từ cùng một nút là đoạn token. Chúng tôi thống nhất những nhiệm vụ này thành một nhiệm vụ meta cụ thể là dự đoán quan hệ ngữ nghĩa. Hình thức, nhiệm vụ này có thể được biểu thức như sau:

𝐶(𝑠0,𝑠1)=(
1∃𝑒∈𝐺, 𝑠 0∈𝑁𝑖∩𝑠1∈𝑁𝑗∩{𝑁𝑖𝑒− →𝑁𝑗}
0∀𝑒∈𝐺, 𝑠 0∈𝑁𝑖∩𝑠1∈𝑁𝑗∩{𝑁𝑖̸𝑒− →𝑁𝑗}

trong đó 𝑁𝑖,𝑁𝑗 là nút thứ 𝑖 và nút thứ 𝑗 trong đồ thị được xây dựng 𝐺∈{𝐶𝐷𝐺,𝐷𝐷𝐺,𝐶𝐹𝐺} và mỗi nút chứa một đoạn token từ mã gốc. 𝑠0 và 𝑠1 biểu thị các đoạn token tương ứng của mã gốc trong các nút 𝑁𝑖 và 𝑁𝑗 sau tokenization. 𝑒− → có nghĩa là có một cạnh giữa hai nút.

Hình 6a, Hình 6b và Hình 6c minh họa các ví dụ cho ba mối quan hệ ngữ nghĩa. Hình 6a cho thấy một ví dụ phụ thuộc điều khiển. Nút 𝑁4 phụ thuộc điều khiển vào nút 𝑁3. Dựa trên thực tế này, chúng tôi gắn nhãn rằng đoạn token từ 𝑁3 phụ thuộc điều khiển vào đoạn token trong 𝑁4. Hình 6b minh họa một ví dụ phụ thuộc dữ liệu. Nút 𝑁4 phụ thuộc dữ liệu vào nút 𝑁1. Hình 6c cho thấy một ví dụ của đồ thị luồng điều khiển. Chúng ta có một số thực tế thứ tự thực thi như nút 𝑁2 được thực thi sau 𝑁1 ngay lập tức. Đoạn token của 𝑁2 có mối quan hệ luồng-điều khiển với đoạn token của 𝑁1.

3.4.2 Dự Đoán Lan Truyền Ngữ Nghĩa. Thông tin luồng dữ liệu được lan truyền trong đồ thị phụ thuộc. Hai nút với khoảng cách dài có thể phụ thuộc dữ liệu một cách ngầm định. Đó là một thực tế rằng bất kỳ sửa đổi nào trong đồ thị phụ thuộc có thể ảnh hưởng đến đầu ra chương trình. Lan truyền luồng phụ thuộc ngầm định là một ngữ nghĩa chương trình quan trọng. Nhiệm vụ lan truyền ngữ nghĩa (bí danh inGraph) được định nghĩa bởi

𝐶(𝑠0,𝑠1)=(
1𝑠0∈𝑁𝑖∩𝑠1∈𝑁𝑗∩𝑁𝑖∈𝐺∩𝑁𝑗∈𝐺
0𝑠0∈𝑁𝑖∩𝑠1∈𝑁𝑗∩𝑁𝑖∈𝐺∩𝑁𝑗∉𝐺

trong đó G∈{𝐶𝐷𝐺,𝐷𝐷𝐺}, 𝑠0 và 𝑠1 là các đoạn token trong các nút của 𝐺. Hình 6d cho thấy một ví dụ. Hộp đổ bóng làm nổi bật các câu lệnh có mối quan hệ phụ thuộc điều khiển. Chúng tôi mong đợi bộ phân loại thăm dò có thể nhận ra rằng câu lệnh "printf" không nằm trong đồ thị phụ thuộc điều khiển.

3.5 Phân Tích Chú Ý

Chúng tôi đã tiến hành phân tích các trọng số chú ý trong mỗi đầu tự-chú ý, dựa trên các mối quan hệ ngữ nghĩa chương trình 𝐺∈{𝐶𝐹𝐺,𝐷𝐷𝐺,𝐶𝐷𝐺} từ Phần 3.4.1. Đối với một đoạn token nút cho trước

J. ACM, Vol. 37, No. 4, Article 111. Ngày xuất bản: Tháng 8 2018.

--- TRANG 11 ---
Khám Phá Các Mô Hình Tiền Huấn Luyện Mã: Nghiên Cứu Khả Năng Cú Pháp và Ngữ Nghĩa 111:11

[THIS IS FIGURE: Four code examples labeled (a) through (d) showing different semantic relationships:
(a) phụ thuộc điều khiển
(b) phụ thuộc dữ liệu  
(c) luồng điều khiển
(d) inGraph
Each shows C-style code with numbered nodes and connecting lines]

Hình 6. Ví dụ về thăm dò ngữ nghĩa.

𝑠𝑖 trong đó 𝑖 là nút thứ 𝑖 và một loại mối quan hệ ngữ nghĩa 𝐺, chúng tôi nhóm các token đầu vào còn lại thành hai tập hợp: 𝑅0 và 𝑅1. 𝑅1 bao gồm tất cả các token có mối quan hệ ngữ nghĩa với 𝑠𝑖 trong khi các token còn lại tạo thành tập hợp 𝑅0. Sau đó chúng tôi chia các trọng số chú ý của một đầu chú ý liên quan đến 𝑠𝑖 thành hai tập hợp, được biểu thị là 𝑊0 và 𝑊1, dựa trên 𝑅0 và 𝑅1. Chúng tôi kiểm tra sự khác biệt của các phân phối chú ý giữa hai tập hợp. Bởi vì chúng tôi muốn biết tập hợp nào đóng góp nhiều hơn cho biểu diễn mã, chúng tôi so sánh tính trung tâm phân phối của hai tập hợp chú ý. Nếu tổng các trọng số chú ý trong 𝑊1 từ một đầu chú ý cụ thể lớn hơn tổng các trọng số chú ý trong 𝑊0, điều đó cho thấy rằng đầu chú ý này đóng góp nhiều hơn cho việc học ngữ nghĩa mã và chúng tôi biểu thị nó là đầu chú ý ngữ nghĩa.

Để xác định ý nghĩa thống kê, chúng tôi áp dụng kiểm định t ghép cặp với kích thước mẫu lớn cho mỗi loại ngữ nghĩa 𝐺. Chúng tôi hình thành giả thuyết null 𝐻0:𝜇𝑑=0, trong đó 𝜇𝑑 đại diện cho sự khác biệt trung bình thực sự giữa 𝑊1 và 𝑊0. Giả thuyết thay thế 𝐻1:𝜇𝑑>0 cho thấy rằng có một sự khác biệt trung bình tích cực (𝑊1 lớn hơn 𝑊0). Bằng cách tiến hành kiểm định này, chúng ta có thể xác định liệu đầu chú ý có đóng góp nhiều hơn cho việc học ngữ nghĩa mã hay không. Phân tích cấp độ đầu này cung cấp hiểu biết chi tiết hơn về tự-chú ý. Tổng cộng, chúng tôi đã phân tích hơn 10.000 đầu vào ngữ nghĩa cho 4 mô hình mã tiền huấn luyện và chọn ngẫu nhiên 100 đầu vào ngữ nghĩa cho ba LLM.

4 THIẾT LẬP ĐÁNH GIÁ

Trong phần này, chúng tôi giới thiệu thiết lập đánh giá, bao gồm tiền xử lý dữ liệu, các mô hình đánh giá và các thước đo đánh giá.

4.1 Tập Dữ Liệu và Tiền Xử Lý

Chúng tôi sử dụng hai tập dữ liệu, cụ thể là Java250 [56] và POJ-104 [53] cho nghiên cứu của chúng tôi. Chất lượng dữ liệu có tác động đáng kể đến phân tích thăm dò. Chúng tôi tuân theo các bước tiền xử lý được nêu

J. ACM, Vol. 37, No. 4, Article 111. Ngày xuất bản: Tháng 8 2018.

--- TRANG 12 ---
111:12 W. Ma, S. Liu và M. Zhao et al.

[THIS IS FIGURE: Workflow diagram showing: Raw code -> Refactor -> Refactored Code -> AST Parser -> Extract AST -> Syntax Data, and Static Analysis -> Program Graphs -> Semantic Data -> Token Alignment]

Hình 7. Quy trình công việc tiền xử lý dữ liệu.

trong Hình 7 để tạo dữ liệu thăm dò cú pháp và ngữ nghĩa chất lượng cao. Mã được tái cấu trúc sử dụng công cụ google-java-format³ và công cụ clang-refactor⁴. Tái cấu trúc mã đảm bảo khả năng đọc của nó và tạo điều kiện thuận lợi cho việc căn chỉnh token giữa các đồ thị và đầu vào mô hình. Để đảm bảo độ chính xác của kết quả, chúng tôi sử dụng khung phân tích tĩnh Joern và bộ phân tích AST⁵ để trích xuất các đồ thị chương trình và AST. Trong trường hợp các đồ thị chương trình, chúng tôi hợp nhất các nút dư thừa nếu mã của một nút là tập con của các nút lân cận của nó. Sau đó chúng tôi trích xuất các mối quan hệ cú pháp và ngữ nghĩa giữa các token mã và xây dựng các tập dữ liệu thăm dò.

4.2 Các Mô Hình Thực Nghiệm

Chúng tôi chọn 7 mô hình mã phổ biến với các kiến trúc đa dạng (bộ mã hóa transformer, bộ giải mã transformer và bộ mã hóa-giải mã transformer) được sử dụng rộng rãi trong kỹ thuật phần mềm. 7 mô hình được xây dựng bởi các công ty hoặc tổ chức có uy tín: Microsoft, Meta, Salesforce và Huggingface. Tất cả đều có số lượng tải xuống lớn trên Huggingface, và các bài báo tương ứng của chúng đều có hơn 150 trích dẫn. Đầu tiên, chúng tôi tiến hành thí nghiệm sử dụng bốn mô hình tiền huấn luyện, CodeBERT (CB) [13], GraphCodeBERT (GCB) [17], UnixCoder (UC) [16] và CodeT5 (CT) [71]. CodeBERT và GraphCodeBERT sử dụng bộ mã hóa Transformer, trong khi GraphCodeBERT tích hợp thông tin luồng dữ liệu bổ sung. UnixCoder sử dụng ma trận chú ý che mặt với các bộ điều hợp tiền tố để hỗ trợ học mã hóa, giải mã và mã hóa-giải mã. CodeT5 sử dụng kiến trúc Transformer mã hóa-giải mã. Đối với CodeT5, chúng tôi xem xét bộ mã hóa của nó, có thể được so sánh với các mô hình tiền huấn luyện khác trong cùng kiến trúc. Những mô hình này có 12 tầng mã hóa Transformer (được biểu thị là Tầng 1-Tầng 12) cộng với một tầng nhúng (được biểu thị là Tầng 0). Chúng tôi áp dụng các nhiệm vụ thăm dò của chúng tôi cho mỗi tầng mã hóa và tầng nhúng. Điều này giúp chúng ta hiểu vai trò của mỗi tầng. Thứ hai, chúng tôi cũng nghiên cứu 3 mô hình ngôn ngữ lớn (LLM), CodeLlama-7b [58] (CL), StarCoder [34] (SC) và CodeT5+ [70] (CodeT5p-770m) (CT5P+) sử dụng tập dữ liệu Java. CodeLlama-7b có 32 tầng ẩn và StarCoder có 40 tầng ẩn. Cả hai đều sử dụng bộ giải mã transformer. CodeT5p-770m có 24 tầng mã hóa ẩn và 24 tầng giải mã ẩn. Đây là một mô hình ngôn ngữ mã mở lớn dựa trên cấu trúc mã hóa-giải mã cho họ CodeT5+ [70]. Tất cả các thí nghiệm được lặp lại 3 lần với các hạt giống ngẫu nhiên khác nhau.

4.3 Các Thước Đo Đánh Giá

Chúng tôi sử dụng hệ số tương quan Matthew (MCC) [50] làm thước đo đánh giá của chúng tôi. MCC là một thay thế đáng tin cậy cho điểm F1 đối với phân loại nhị phân [5,74], và nó xem xét toàn bộ ma trận confusion

³https://github.com/google/google-java-format.git
⁴https://clang.llvm.org/docs/ClangTools.html
⁵https://joern.io/,https://tree-sitter.github.io/tree-sitter/

J. ACM, Vol. 37, No. 4, Article 111. Ngày xuất bản: Tháng 8 2018.

--- TRANG 13 ---
Khám Phá Các Mô Hình Tiền Huấn Luyện Mã: Nghiên Cứu Khả Năng Cú Pháp và Ngữ Nghĩa 111:13

matrix. MCC có thể được tính từ ma trận confusion,

𝑀𝐶𝐶=𝑇𝑃×𝑇𝑁−𝐹𝑃×𝐹𝑁/√(𝑇𝑃+𝐹𝑃)·(𝑇𝑃+𝐹𝑁)·(𝑇𝑁+𝐹𝑃)·(𝑇𝑁+𝐹𝑁)

trong đó TP là true positive, TN là true negative, FP là false positive và FN là false negative. Đối với gắn thẻ cú pháp token, đây là phân loại nhiều lớp và chúng tôi cũng hiển thị điểm F1 macro của nó,

Macro F1 =1/𝑁∑𝑖=1𝑁 2×Precision 𝑖×Recall𝑖/(Precision 𝑖+Recall𝑖)

trong đó N là số lượng lớp và i là lớp thứ 𝑖. Chúng tôi chọn điểm F1 macro làm thước đo đánh giá của chúng tôi do thuộc tính vốn có của nó trong việc gán ý nghĩa bình đẳng cho mọi lớp trong tập dữ liệu của chúng tôi. Vì tất cả các thí nghiệm được lặp lại 3 lần, chúng tôi sử dụng các giá trị trung bình để đánh giá.

5 KẾT QUẢ THỰC NGHIỆM

Trong phần này, chúng tôi trình bày kết quả phân tích cú pháp và ngữ nghĩa mã.

5.1 Phân Tích Cú Pháp

5.1.1 Dự Đoán Cặp Nút Cú Pháp. Hình 8a và Hình 8b trình bày kết quả của các bộ phân loại thăm dò cho dự đoán cặp nút cú pháp trên Java250 và POJ-104 tương ứng, đối với các mô hình mã tiền huấn luyện, CodeBert (CB), GraphCodeBert (GCB), UnixCoder (UC) và CodeT5 (CT5). Những kết quả này được suy ra từ các biểu diễn ẩn được cung cấp bởi các mô hình mã. Trục X biểu thị chỉ số tầng, trong khi trục Y biểu thị hiệu suất. 𝐿𝑎𝑦𝑒𝑟 0 tương ứng với tầng nhúng, trong khi 𝐿𝑎𝑦𝑒𝑟 1-𝐿𝑎𝑦𝑒𝑟 12 đại diện cho các tầng Transformer. Chúng ta có thể thấy rằng nhìn chung những mô hình này có thể mô tả chính xác các mối quan hệ cú pháp giữa các token. Ví dụ, MCC đạt trên 70% trong các tầng khác nhau trên các mô hình khác nhau. Tất cả các mô hình tiền huấn luyện đạt hiệu suất tốt nhất giữa 𝐿𝑎𝑦𝑒𝑟 2 và 𝐿𝑎𝑦𝑒𝑟 4 nông. Với độ sâu của các tầng, hiệu suất giảm dần. Cụ thể hơn, GraphCodeBERT (GCB) thể hiện hiệu suất tốt hơn một chút so với các mô hình khác trên Java250, như được chứng minh trong Hình 8a. Tuy nhiên, khi chuyển sang POJ-104, hiện tượng phức tạp hơn. CodeT5 thể hiện hiệu suất vượt trội so với các mô hình khác từ 𝐿𝑎𝑦𝑒𝑟 4 đến 𝐿𝑎𝑦𝑒𝑟 8, tuy nhiên, khi tầng đạt 12, GraphCodeBERT đạt hiệu suất tốt nhất. Mặc dù UnixCoder và CodeT5 sử dụng các chiến lược tiền huấn luyện phức tạp hơn, tận dụng các tập dữ liệu lớn hơn và có số lượng tham số có thể huấn luyện lớn hơn, lợi thế tương đối của chúng là tối thiểu. Hình 8c cho thấy điểm MCC cho CodeLlama, StarCoder và CodeT5+. Một quan sát thú vị là ba mô hình ngôn ngữ lớn đạt hiệu suất tốt nhất trong các tầng nông 𝐿𝑎𝑦𝑒𝑟 4 và 𝐿𝑎𝑦𝑒𝑟 5, tương tự như các mô hình mã tiền huấn luyện. Nhưng đối với StarCoder và CodeLlama, hiệu suất tăng rất nhiều ở tầng cuối cùng khác với các mô hình khác. Chúng ta có thể kết luận rằng mối quan hệ cú pháp giữa các token mã dễ quan sát hơn trong không gian biểu diễn của các tầng ẩn nông. Sự giảm hiệu suất của các biểu diễn sâu hơn trên nhiệm vụ này là một hiện tượng thú vị. Mặc dù các tầng ẩn sâu được cho là chứa thông tin từ các tầng nông hơn, không gian biểu diễn của chúng phức tạp hơn, mã hóa nhiều thuộc tính mã khác như vai trò token-cú pháp, vì vậy mối quan hệ cú pháp-token có thể ít nổi bật hơn.

5.1.2 Gắn Thẻ Cú Pháp Token. Hình 9a và Hình 9b trình bày kết quả MCC của các bộ phân loại thăm dò cho vai trò cú pháp token riêng lẻ (Gắn Thẻ Cú Pháp Token) trên Java250 và POJ-104 tương ứng. Hình 9c và Hình 9d thể hiện điểm F1. Các quan sát của chúng tôi cho thấy rằng CodeT5 vượt trội hơn các mô hình khác trong các tầng trung gian, cụ thể từ 𝐿𝑎𝑦𝑒𝑟 4 đến 𝐿𝑎𝑦𝑒𝑟 11. CodeBERT thể hiện hiệu suất tốt hơn một chút so với GraphCodeBERT trong những tầng trung gian này,

J. ACM, Vol. 37, No. 4, Article 111. Ngày xuất bản: Tháng 8 2018.

--- TRANG 14 ---
111:14 W. Ma, S. Liu và M. Zhao et al.

trong khi GraphCodeBERT vượt trội hơn các mô hình khác ở tầng cuối cùng, tức là 𝐿𝑎𝑦𝑒𝑟 12. Thú vị là, một sự sụt giảm hiệu suất được quan sát cho tất cả các mô hình ngoại trừ UnixCoder chuyển từ 𝐿𝑎𝑦𝑒𝑟 11 đến 𝐿𝑎𝑦𝑒𝑟 12. CodeT5 đạt hiệu suất đỉnh xấp xỉ quanh 𝐿𝑎𝑦𝑒𝑟 10. Ngược lại, UnixCoder tụt lại phía sau các mô hình khác, đặc biệt sau 𝐿𝑎𝑦𝑒𝑟 7. Ngoại trừ UnixCoder, hiệu suất của các mô hình tiền huấn luyện khác cho thấy xu hướng tăng với các biến động từ 𝐿𝑎𝑦𝑒𝑟 0 đến 𝐿𝑎𝑦𝑒𝑟 11. Hình 10a và Hình 10b cho thấy điểm F1 và điểm MCC cho LLM trên tập dữ liệu Java250. Nếu chúng ta nhìn vào tất cả các hình trong nhiệm vụ này, chúng ta thấy một xu hướng chung là hiệu suất cải thiện khi độ sâu của các tầng tăng, và phần sau ổn định với một số sụt giảm hoặc tăng. Thú vị là, tại giao điểm giữa bộ mã hóa và bộ giải mã, hiệu suất mô hình giảm mạnh nhưng nhanh chóng cải thiện trở lại khi số lượng tầng tăng. Hiện tượng này cũng đã được quan sát trong các thí nghiệm khác. Một giải thích hợp lý là bộ mã hóa và bộ giải mã hoạt động với các cơ chế khác nhau. Bộ mã hóa mã hóa thông tin thành biểu diễn trừu tượng trong khi bộ giải mã cố gắng khôi phục đầu vào từ biểu diễn trừu tượng. Do sự khác biệt trong hoạt động, các thuộc tính trong biểu diễn từ các tầng tương tác là thách thức để quan sát khi di chuyển từ bộ mã hóa sang bộ giải mã. Như đã đề cập trước đó, gắn thẻ cú pháp token là một nhiệm vụ không tầm thường để gắn nhãn token mã với vai trò cú pháp, và đây là nhiệm vụ khó khăn hơn nhiệm vụ trước đó. Thuộc tính vai trò cú pháp token được biểu diễn rõ ràng hơn trong các tầng sâu hơn so với các tầng nông.

Về mối quan hệ tương đối cú pháp, những mô hình mã tiền huấn luyện này thể hiện khả năng tương đương. Tuy nhiên, CodeT5 (chúng tôi xem xét bộ mã hóa của nó) phân biệt bản thân bằng cách biểu diễn vai trò cú pháp token riêng lẻ trong bối cảnh một cách hiệu quả hơn. Ngược lại, UnixCoder thể hiện mức độ hiểu biết cú pháp thấp hơn so với các mô hình khác. Chúng tôi suy đoán điều này vì hai lý do sau: 1) CodeBERT, GraphCodeBERT, và CodeT5-encoder đều sử dụng mô hình ngôn ngữ có mặt nạ (MLM) hoặc các cách tương tự để học các đặc trưng token hai chiều trong khi UniXCoder tích hợp các loại nhiệm vụ tiền huấn luyện khác nhau. Mặc dù nó cũng sử dụng MLM, các nhiệm vụ khác như mô hình ngôn ngữ một chiều (ULM) và DeNoiSing (DNS) có thể có tác động bất lợi đến các nhiệm vụ thăm dò; 2) UnixCoder tích hợp bộ mã hóa và bộ giải mã bằng cách chia sẻ trọng số trong khi các biểu diễn từ bộ giải mã có khả năng trích xuất thông tin kém hơn so với biểu diễn bộ mã hóa [66]. Chia sẻ trọng số giữa bộ mã hóa và bộ giải mã có thể làm hại khả năng của mô hình trong việc trích xuất thông tin. Ba LLM được nghiên cứu cho thấy một số khác biệt so với bốn mô hình tiền huấn luyện. LLM không có lợi thế rõ ràng so với các mô hình tiền huấn luyện, mặc dù StarCoder có 6144 chiều ẩn, CodeLlama có 4096 chiều ẩn và CodeT5p-770m có 1046 chiều ẩn. Kích thước của chúng cao hơn nhiều so với các mô hình mã tiền huấn luyện (768). Tất cả đều có số lượng tham số khổng lồ. Một lý do có thể là kích thước không gian biểu diễn quá lớn và bao phủ quá nhiều thông tin, làm cho các đặc trưng cú pháp nhúng khó quan sát.

Tóm lại, từ Phần 5.1.1 và Phần 5.1.2, rõ ràng rằng bốn mô hình mã tiền huấn luyện và 3 mô hình ngôn ngữ lớn có thể mã hóa cú pháp mã, cả về mối quan hệ cú pháp giữa các token (dự đoán Cặp Nút Cú pháp) và vai trò cú pháp token riêng lẻ (Gắn Thẻ Cú Pháp Token). Các đặc trưng cú pháp khác nhau có mức độ khó khăn khác nhau trong việc được quan sát ở các tầng ẩn nông và sâu.

5.2 Phân Tích Ngữ Nghĩa

5.2.1 Dự Đoán Quan Hệ Ngữ Nghĩa. Hình 11 trình bày hiệu suất thăm dò của bốn mô hình mã tiền huấn luyện, CodeBERT (CB), GraphCodeBERT (GCB), UnixCoder (UC), và CodeT5 (CT5) trên nhiệm vụ dự đoán quan hệ ngữ nghĩa. Chúng tôi đã tiến hành so sánh hiệu suất thăm dò trên ba ngữ nghĩa chương trình khác nhau: phụ thuộc điều khiển (CDG, Hình 11a và Hình 11b), thông tin luồng điều khiển (CFG, Hình 11c và Hình 11d), và phụ thuộc dữ liệu (DDG, Hình 11e

J. ACM, Vol. 37, No. 4, Article 111. Ngày xuất bản: Tháng 8 2018.

--- TRANG 15 ---
Khám Phá Các Mô Hình Tiền Huấn Luyện Mã: Nghiên Cứu Khả Năng Cú Pháp và Ngữ Nghĩa 111:15

[THIS IS FIGURE: Multiple graphs showing performance metrics across different layers:
- Figure 8 (a-c): Performance (MCC) for Java250 and POJ-104 for Syntax Pair Node prediction (AST)
- Figure 9 (a-d): Performance for Java250 and POJ-104 for Token Syntax Tagging (MCC and F1)
- Figure 10 (a-b): Performance for Java250 for Syntax Pair Node prediction (AST) and Token Syntax Tagging for LLMs]

và Hình 11f). Thứ nhất, rõ ràng rằng CodeT5 thể hiện khả năng cao nhất trong việc hiểu ngữ nghĩa chương trình, tức là CDG và DDG, đặc biệt trong vài tầng cuối, và GraphCodeBERT được chứng minh tốt hơn một chút so với CodeT5 về CFG. Thứ hai, CodeBERT cũng có khả năng mã hóa ngữ nghĩa chương trình, mặc dù không sử dụng thông tin luồng dữ liệu trong quá trình tiền huấn luyện. Ví dụ, MCC đạt trên 60% trong CDG và DDG. Điều này cho thấy rằng nhiệm vụ tiền huấn luyện Mô hình Ngôn ngữ Có Mặt Nạ (MLM) có thể hỗ trợ mô hình trong việc học ngữ nghĩa mã. UnixCoder hoạt động kém hiệu quả hơn trong việc biểu diễn ngữ nghĩa mã so với ba mô hình khác, đặc biệt sau 𝐿𝑎𝑦𝑒𝑟 7.

J. ACM, Vol. 37, No. 4, Article 111. Ngày xuất bản: Tháng 8 2018.

--- TRANG 16 ---
111:16 W. Ma, S. Liu và M. Zhao et al.

Hình 12 thể hiện hiệu suất thăm dò của ba LLM, CodeLlama, StarCoder và CodeT5+, trên ba nhiệm vụ hiểu ngữ nghĩa mã, CDG, CFG và DDG. So với mô hình mã tiền huấn luyện, biểu diễn từ tầng nông của LLM làm cho việc quan sát ba thông tin ngữ nghĩa của mã dễ dàng hơn. Khi chúng tôi so sánh StarCoder với CodeLlama và CodeT5+, chúng tôi thấy rằng hiệu suất của StarCoder giảm đáng kể đối với các tầng sâu. Vì các LLM hiện tại có khả năng khẩn cấp, chúng ta có thể nghĩ LLM đã học ba ngữ nghĩa mã trong khi chúng không dễ quan sát. Hơn nữa, cách gây ra biểu diễn ngữ nghĩa mã của LLM để dễ quan sát hơn trong việc nhắc LLM, từ đó cải thiện chất lượng câu trả lời của mô hình, là một chủ đề đáng nghiên cứu trong tương lai.

Khi so sánh hiệu suất của các mô hình mã trên CDG, CFG và DDG, rõ ràng rằng các mô hình mã thể hiện MCC thấp nhất trên CFG, MCC cao hơn trên DDG và MCC cao nhất trên CDG tương ứng. Điều này cho thấy rằng các mô hình mã gặp khó khăn trong việc nắm bắt ngữ nghĩa luồng điều khiển (CFG) hiệu quả như hai loại ngữ nghĩa khác. CFG là một xấp xỉ dấu vết thực thi của chương trình. LLM được chỉ ra thiếu khả năng xử lý các nhiệm vụ liên quan đến thực thi mã [46]. Các nhà huấn luyện mô hình cần xem xét cách cải thiện hiểu biết về hành vi động mã của LLM.

5.2.2 Lan Truyền Ngữ Nghĩa (inGraph). Hình 13 minh họa kết quả thăm dò của bốn mô hình tiền huấn luyện trên nhiệm vụ inGraph. Rõ ràng rằng GraphCodeBERT vượt trội hơn các mô hình khác về lan truyền ngữ nghĩa cho CDG và DDG trên tập dữ liệu Java250. CodeT5 tốt hơn trên POJ-104 về CDG. Tuy nhiên, cả GraphCodeBERT và CodeT5 đều thể hiện hiệu suất tương tự trên POJ-104 về DDG. Điều này cho thấy rằng việc lan truyền dữ liệu được sử dụng bởi GraphCodeBERT tỏ ra có lợi trong việc nắm bắt lan truyền ngữ nghĩa trong mã. Hơn nữa, chúng tôi quan sát rằng CodeBERT có thể mã hóa ngữ nghĩa mã, mặc dù với hiệu suất thấp hơn so với CodeT5 và GraphCodeBERT. Tuy nhiên, UnixCoder hoạt động tệ hơn các mô hình khác, đặc biệt sau 𝐿𝑎𝑦𝑒𝑟 7. Khi so sánh hiệu suất của các mô hình giữa CDG và DDG, chúng ta có thể thấy rằng các mô hình thể hiện MCC cao hơn trên DDG so với CDG, có nghĩa là lan truyền phụ thuộc dữ liệu được mã hóa tốt hơn lan truyền phụ thuộc điều khiển bởi 4 mô hình mã tiền huấn luyện này. Đối với các LLM, chúng tôi quan sát rằng các tầng nông có hiệu suất tốt hơn các tầng sâu. Đối với CodeT5+, hiện tượng này thậm chí rõ ràng hơn và có sự sụt giảm mạnh giữa bộ mã hóa và bộ giải mã (𝐿𝑎𝑦𝑒𝑟 24 và 𝐿𝑎𝑦𝑒𝑟 25). Một giải thích có thể là khả năng của các biểu diễn mã cho bộ giải mã để biểu đạt các phụ thuộc dài bị giảm sút vì bộ giải mã chỉ có thể thấy thông tin token trước đó, và các token tương lai bị che mặt. Nếu chúng ta xem Hình 12 cho phụ thuộc ngắn (xây dựng các đồ thị ngữ nghĩa), chúng ta có thể thấy rằng có sự sụt giảm hiệu suất giữa bộ mã hóa và bộ giải mã (𝐿𝑎𝑦𝑒𝑟 24 và 𝐿𝑎𝑦𝑒𝑟 25) của CodeT5+ và các sụt giảm trở nên rõ ràng hơn đối với phụ thuộc dài.

J. ACM, Vol. 37, No. 4, Article 111. Ngày xuất bản: Tháng 8 2018.

--- TRANG 17 ---
Khám Phá Các Mô Hình Tiền Huấn Luyện Mã: Nghiên Cứu Khả Năng Cú Pháp và Ngữ Nghĩa 111:17

[THIS IS FIGURE: Multiple charts showing performance (MCC) graphs for various models across different layers and tasks including CDG, CFG, and DDG for Java250 and POJ-104 datasets. Charts are labeled from (a) to (f) showing different semantic relations.]

Hình 11. Hiệu suất (MCC) về Java250 và POJ-104 cho Quan Hệ Ngữ Nghĩa.

[THIS IS FIGURE: Three charts showing LLM Performance (MCC) for Java250 across different layers for CDG, CFG, and DDG semantic relations.]

Hình 12. Hiệu Suất LLM (MCC) về Java250 cho Quan Hệ Ngữ Nghĩa.

J. ACM, Vol. 37, No. 4, Article 111. Ngày xuất bản: Tháng 8 2018.

--- TRANG 18 ---
111:18 W. Ma, S. Liu và M. Zhao et al.

[THIS IS FIGURE: Four graphs labeled (a) Java250-CDG, (b) POJ-104-CDG, (c) Java250-DDG, and (d) POJ-104-DDG showing performance metrics (MCC %) across different layers for CB, GCB, UC, and CT5 models]

Hình 13. Hiệu suất (MCC) về Java250 và POJ-104 cho inGraph.

[THIS IS FIGURE: Two graphs labeled (a) Java250-CDG and (b) Java250-DDG showing LLM Performance (MCC %) across layers for CL, SC, and CT5+ models]

Hình 14. Hiệu Suất LLM (MCC) về Java250 và POJ-104 cho inGraph.

Bảng 3. Số Lượng Đầu Chú Ý Ngữ Nghĩa trên Java250 / POJ-104.

[THIS IS TABLE: A table showing attention heads for CodeBERT, GraphCodeBERT, UnixCoder, and CodeT5 across CDG, CFG, and DDG metrics]
CodeBERT GraphCodeBERT UnixCoder CodeT5
CDG 65 / 93    71 / 86       50 / 44    77 / 91
CFG 129 / 141  136 / 139     99 / 82    130 / 128
DDG 133 / 115  135 / 124     23 / 58    111 / 120

Để tóm tắt các phát hiện từ Phần 5.2.1 và Phần 5.2.2, tất cả bốn mô hình mã tiền huấn luyện đều có khả năng học ngữ nghĩa mã. Tuy nhiên, khả năng mã hóa ngữ nghĩa của chúng khác nhau qua các loại ngữ nghĩa khác nhau. Đối với nhóm LLM, biểu diễn từ các tầng nông làm cho việc quan sát ngữ nghĩa mã dễ dàng hơn. Khả năng mã hóa thông tin thực thi mã nên được tăng cường cho LLM.

5.3 Phân Tích Chú Ý

Dựa trên các phân tích đã đề cập ở trên, chúng tôi đã quan sát rằng các mô hình mã tiền huấn luyện và mô hình ngôn ngữ lớn (LLM) thể hiện khả năng tốt hoặc trung bình trong việc học cú pháp và ngữ nghĩa mã. Để có thêm hiểu biết về cách những mô hình này mã hóa ngữ nghĩa, chúng tôi đã tiến hành điều tra vai trò của các đầu tự-chú ý trong việc học ngữ nghĩa mã, sử dụng tập dữ liệu hơn 10.000 đầu vào ngữ nghĩa cho các mô hình mã tiền huấn luyện và lấy mẫu ngẫu nhiên 100 đầu vào ngữ nghĩa cho LLM. Mỗi một trong các mô hình tiền huấn luyện có 144 đầu chú ý tổng cộng tương ứng. StarCoder có 1920 đầu chú ý, CodeLlama có 960 đầu chú ý và CodeT5+ Decoder/Encoder có 384 đầu chú ý.

J. ACM, Vol. 37, No. 4, Article 111. Ngày xuất bản: Tháng 8 2018.

--- TRANG 19 ---
Khám Phá Các Mô Hình Tiền Huấn Luyện Mã: Nghiên Cứu Khả Năng Cú Pháp và Ngữ Nghĩa 111:19

Bảng 4. Số Lượng Đầu Chú Ý Ngữ Nghĩa của LLM trên Java250 / POJ-104.

[THIS IS TABLE:
StarCoder  CodeLlama  CodeT5+ Decoder  CodeT5+ Encoder
CDG  0/0      0/0       0/0            199/252
CFG  1372/1844  423/830   371/340       315/319
DDG  1253/1892  100/977   318/146       247/208]

Trong Bảng 3 và Bảng 4, chúng tôi trình bày số lượng đầu chú ý học ngữ nghĩa mã một cách đáng kể về CDG, CFG và DDG (có ý nghĩa thống kê ở ngưỡng p-value 0.01) cho các mô hình tiền huấn luyện và LLM về các tập dữ liệu Java250 và POJ-104 tương ứng. Trong Bảng 3, rõ ràng rằng UnixCoder có số lượng đầu chú ý ít nhất dành cho ngữ nghĩa. Điều này phù hợp với kết luận trước đó rằng UnixCoder không tốt hơn các mô hình khác về mã hóa cú pháp và ngữ nghĩa mã. Trong Bảng 4, chúng ta có thể thấy rằng các đầu chú ý có mối quan hệ phụ thuộc điều khiển không gán trọng số nhiều hơn các đầu chú ý không có mối quan hệ phụ thuộc điều khiển đối với StarCoder, CodeLlama và CodeT5+ decoder sử dụng kiến trúc bộ giải mã transformer. Tuy nhiên, đối với CodeT5+ encoder, tồn tại 199/252 đầu chú ý có thể gán trọng số nhiều hơn cho mối quan hệ phụ thuộc điều khiển. Chúng tôi nghĩ lý do là các kiến trúc mô hình khác nhau có thể ảnh hưởng đến phân phối của các cơ chế chú ý. Encoder và decoder trong transformer có các chức năng khác nhau. Encoder có xu hướng hiểu cấu trúc tổng thể và bối cảnh của đầu vào, trong khi decoder tập trung vào việc tạo ra hoặc dự đoán token tiếp theo dựa trên hiểu biết này. Do đó, đối với các câu lệnh phụ thuộc điều khiển, encoder có thể cần chú ý nhiều hơn đến những mối quan hệ này để hiểu cấu trúc logic của toàn bộ mã, trong khi decoder có thể chú ý nhiều hơn đến thông tin cục bộ hoặc thông tin ngữ nghĩa khác để tạo ra, dẫn đến các phân phối trọng số chú ý khác nhau.

Chúng tôi tiếp tục điều tra sự trùng lặp của các đầu chú ý ngữ nghĩa gán trọng số chú ý nhiều hơn cho các token ngữ nghĩa giữa các tập dữ liệu Java250 và POJ-104 cho bốn mô hình này. Kết quả cho thấy rằng một mô hình chia sẻ các đầu chú ý ngữ nghĩa qua các ngôn ngữ lập trình khác nhau. Để xem xét sự khác biệt trong các đầu chú ý ngữ nghĩa giữa các tập dữ liệu Java250 và POJ-104 qua bốn mô hình được sử dụng, chúng tôi trình bày tỷ lệ của các đầu chú ý ngữ nghĩa trùng lặp cho mỗi mô hình trong cả hai tập dữ liệu (Bảng 5 và Bảng 6). Các hàng Java250 và POJ-104 được tính bằng hai phương trình sau tương ứng,

𝑟𝑗𝑎𝑣𝑎 250=|𝑆𝑗𝑎𝑣𝑎 250∩𝑆𝑃𝑂𝐽|/|𝑆𝑗𝑎𝑣𝑎 250|

𝑟𝑝𝑜𝑗=|𝑆𝑗𝑎𝑣𝑎 250∩𝑆𝑃𝑂𝐽|/|𝑆𝑃𝑂𝐽|

trong đó 𝑆𝑗𝑎𝑣𝑎 250 và 𝑆𝑃𝑂𝐽 là tập hợp các đầu chú ý ngữ nghĩa cho các tập dữ liệu Java250 và POJ-104. Đáng ngạc nhiên, mặc dù các ngôn ngữ lập trình riêng biệt được đại diện trong hai tập dữ liệu, một sự trùng lặp đáng kể được quan sát. Mặc dù tỷ lệ trùng lặp 𝑟𝑝𝑜𝑗 cho DDG trong CodeLlama là 8.29%, điều này được gây ra do 𝑆𝑃𝑂𝐽 quá lớn và thực tế đa số các đầu chú ý từ Java250 được bao gồm trong 𝑆𝑃𝑂𝐽 (81.00%). Phát hiện này cho thấy rằng một số mẫu chú ý ngữ nghĩa được chia sẻ giữa các mô hình mã bất kể ngôn ngữ lập trình nào được sử dụng.

6 CÔNG TRÌNH LIÊN QUAN

6.1 Các Mô Hình Mã

Các mô hình tiền huấn luyện đã được sử dụng để hỗ trợ nhiều nhiệm vụ do khả năng tổng quát hóa xuất sắc của chúng trong các nhiệm vụ xử lý ngôn ngữ tự nhiên. Gần đây, các nhà nghiên cứu tiền huấn luyện transformers [54]

J. ACM, Vol. 37, No. 4, Article 111. Ngày xuất bản: Tháng 8 2018.

--- TRANG 20 ---
111:20 W. Ma, S. Liu và M. Zhao et al.

Bảng 5. Sự Trùng Lặp của Các Đầu Chú Ý Ngữ Nghĩa trên Java250 và POJ-104, Phần Trăm %.

[THIS IS TABLE: Shows overlap percentages for CodeBERT, GraphCodeBERT, UnixCoder, and CodeT5 across CDG, CFG, and DDG metrics with two rows (𝑟𝐽𝑎𝑣𝑎250 and 𝑟𝑝𝑜𝑗)]

Bảng 6. Sự Trùng Lặp của Các Đầu Chú Ý Ngữ Nghĩa LLM trên Java250 và POJ-104, Phần Trăm %.

[THIS IS TABLE: Shows overlap percentages for StarCoder, CodeLlama, CodeT5+ Decoder, and CodeT5+ Encoder across CDG, CFG, and DDG metrics with two rows]

sử dụng dữ liệu mã để giải quyết các nhiệm vụ lập trình. Theo các chiến lược tiền huấn luyện và kiến trúc mô hình, chúng ta có thể nhóm các mô hình tiền huấn luyện thành ba (3) loại: mô hình tự-mã hóa, mô hình tự-hồi quy và mô hình chuỗi-sang-chuỗi (Seq2Seq). Các mô hình tự-mã hóa sử dụng bộ mã hóa Transformer và được tiền huấn luyện với các mục tiêu như Mô hình Ngôn ngữ Có Mặt Nạ (MLM). MLM che một số token trong chuỗi mã và mong đợi mô hình dự đoán các token bị che sử dụng thông tin bối cảnh hai chiều, điều này thực tế cho phép mô hình sử dụng các token tương lai để dự đoán các token mặt nạ hiện tại. CodeBERT [13] được tiền huấn luyện trên tập dữ liệu CodeSearchNet [26]. GraphCodeBERT [17] bao gồm một loại đầu vào bổ sung, chuỗi luồng dữ liệu, so với CodeBERT. CodeBERT và GraphCodeBERT sử dụng bộ mã hóa của Transformer. Các mô hình tự-hồi quy sử dụng Mô hình Ngôn ngữ Nhân quả (CLM) hoặc các biến thể của nó để tiền huấn luyện các transformer theo cách từ trái sang phải. CodeGPT [42] sử dụng chiến lược tiền huấn luyện này và giữ bộ giải mã transformer. Các mô hình Seq2Seq, ví dụ như CodeT5 [71], sử dụng cả bộ mã hóa và bộ giải mã trong Transformer. CommitBART [40] sử dụng kiến trúc BART [32] để tiền huấn luyện mô hình cho các commit GitHub.

Gần đây, ChatGPT và các mô hình ngôn ngữ lớn khác đã nhận được sự chú ý đáng kể. Kết quả là, một số LLM được thiết kế đặc biệt cho lập trình đã xuất hiện. StarCoder [34] với 15B tham số được huấn luyện sử dụng 1 nghìn tỷ token được phát hành. CodeLlama [58] được tinh chỉnh dựa trên Llama2 [65] sử dụng tập dữ liệu mã. WizardCoder [43] sử dụng hướng dẫn tiến hóa mã để tinh chỉnh trọng số mô hình. Tất cả đều dựa trên bộ giải mã transformer. Khác với chúng, CodeT5+ [70] sử dụng kiến trúc mã hóa-giải mã như CodeT5 [71]. LLM cho thấy khả năng mạnh mẽ trong sửa chữa chương trình, tạo mã và tóm tắt. Hou et al. [21] và Zhang et al. [78] xem xét toàn diện các ứng dụng của các mô hình ngôn ngữ lớn trong kỹ thuật phần mềm.

Những mô hình mã này được sử dụng rộng rãi để giải quyết các nhiệm vụ kỹ thuật phần mềm khác nhau [21,48,62,78], như phát hiện khuyết điểm, tóm tắt mã, sửa chữa lỗ hổng và định vị lỗi. Trước khi xuất hiện Học viên Mô hình Ngôn ngữ (LLM), những mô hình học sâu này được sử dụng theo hai cách trong kỹ thuật phần mềm [35,73]: 1) Thêm một mô hình nhiệm vụ lên trên những mô hình mã này và tinh chỉnh trọng số của toàn bộ mô hình. 2) Những mô hình này được sử dụng như trích xuất đặc trưng, và các thuật toán khác được áp dụng sau khi trích xuất đặc trưng. So với phương pháp đầu tiên, phương pháp thứ hai không yêu cầu tinh chỉnh trọng số của mô hình. Sau khi xuất hiện LLM, các phương pháp học dựa trên học trong bối cảnh [7] dần dần được chấp nhận và sử dụng. Những mô hình này thường không được sử dụng một mình mà như một bước trong quy trình công việc. Hơn nữa, các nhà nghiên cứu sẽ sử dụng kiến thức lĩnh vực để xác định cách sử dụng mô hình mã cho các tình huống cụ thể. Mặc dù có nhiều phương pháp cho các nhiệm vụ kỹ thuật phần mềm khác nhau dựa trên mô hình mã có sẵn ngày nay và các nhà nghiên cứu cố gắng giải thích từng bước của phương pháp của họ càng nhiều càng tốt, việc sử dụng mô hình mã như một hộp đen có thể

J. ACM, Vol. 37, No. 4, Article 111. Ngày xuất bản: Tháng 8 2018.

--- TRANG 21 ---
Khám Phá Các Mô Hình Tiền Huấn Luyện Mã: Nghiên Cứu Khả Năng Cú Pháp và Ngữ Nghĩa 111:21

làm giảm giá trị những lời giải thích này ở một mức độ nào đó. Công trình của chúng tôi nhằm giúp các kỹ sư phần mềm hiểu cách các mô hình hiểu cú pháp và ngữ nghĩa mã càng nhiều càng tốt.

6.2 Phân Tích Thăm Dò cho Các Mô Hình Mã

Hiệu suất ấn tượng của các mô hình tiền huấn luyện kích thích nhiều công trình cố gắng diễn giải và hiểu những mô hình hộp đen quy mô lớn mới được phát minh này. Những công trình phân tích này có thể giúp người dùng hiểu và áp dụng các mô hình tiền huấn luyện. Thăm dó [6,57,79] là một trong những kỹ thuật nổi bật nhất được tận dụng rộng rãi cho khả năng diễn giải. Phân tích thăm dò nhằm chẩn đoán loại quy luật nào được mã hóa trong biểu diễn được trích xuất từ dữ liệu. Cơ sở của thăm dò là nếu một bộ phân loại đơn giản, ví dụ như bộ phân loại tuyến tính, được xây dựng dựa trên các biểu diễn có thể giải quyết một nhiệm vụ đủ tốt, thì các biểu diễn nên chứa các đặc trưng thông tin về nhiệm vụ từ trước.

Các công trình gần đây cố gắng phân tích các mô hình mã tiền huấn luyện thông qua thăm dò. Wan et al. [69] đánh giá liệu các mô hình tiền huấn luyện có học cú pháp ngôn ngữ lập trình hay không, và họ đo số lượng cạnh giữa các token nút tại AST, và cố gắng học khoảng cách này trong không gian vector. Phương pháp này không thể khôi phục cấu trúc AST, cho khoảng cách giữa tất cả các nút. Mặc dù số lượng cạnh giữa các nút có thể phản ánh thông tin cú pháp ở một mức độ nào đó, nó vẫn có một số vấn đề. Thứ nhất, nó không thể tái tạo cấu trúc AST trong không gian vector, có nghĩa là nó kiểm tra một phần cú pháp mã. Thứ hai, hai token có cú pháp tương tự có số lượng cạnh nhỏ, nhưng số lượng cạnh nhỏ không ngụ ý sự gần gũi cú pháp như được hiển thị trong phần động lực. Hernández López et al. [18] phân tích các mô hình tiền huấn luyện ở cấp độ toàn cục AST bằng cách chiếu AST vào một không gian con. Công trình này chuyển đổi AST thành cây nhị phân định dạng trung gian và sau đó học một không gian con sử dụng khoảng cách cú pháp [60] được thiết kế cho ngôn ngữ tự nhiên. Tuy nhiên, khoảng cách cú pháp cho ngôn ngữ tự nhiên có thể không phù hợp cho dữ liệu mã vì Allamanis et al. [3] liệt kê sự khác biệt giữa mã và ngôn ngữ tự nhiên, bao gồm sự khác biệt trong cây cú pháp giữa ngôn ngữ tự nhiên và mã. Ngược lại, phương pháp của chúng tôi ngắn gọn và hiệu quả, và chúng tôi trực tiếp khôi phục cấu trúc AST từ không gian vector. Ngoài ra, chúng tôi tiến hành phân tích ngữ nghĩa cho mã.

Troshin và Chirkova [66] phát triển một nhóm các nhiệm vụ thăm dò để kiểm tra liệu các mô hình tiền huấn luyện có học cấu trúc cú pháp mã và thông tin luồng dữ liệu hay không. Thứ nhất, công trình này không xem xét toàn bộ cấu trúc của AST và xem xét một phần cú pháp mã. Thứ hai, công trình này không xem xét ngữ nghĩa luồng-điều khiển và phụ thuộc-điều khiển. Shen et al. [59] trích xuất cấu trúc con cú pháp và dự đoán mối quan hệ cú pháp của chúng. Tuy nhiên, họ thiếu phân tích ngữ nghĩa và chỉ bao gồm bốn loại cú pháp: gán, gọi hàm, câu lệnh if và cấu trúc vòng lặp. Công trình mới nhất [45] quan sát các mối quan hệ cú pháp và ngữ nghĩa và cũng nghiên cứu cách LLM hiểu hành vi mã dựa trên các đầu ra được tạo thông qua học trong bối cảnh để phân tích mã. Công trình của chúng tôi sử dụng các trạng thái bên trong của các mô hình mã và nghiên cứu toàn diện cách các mô hình mã mã hóa cú pháp và ngữ nghĩa mã bằng cách nhắm đến toàn bộ cấu trúc của AST, các đồ thị phụ thuộc điều khiển và dữ liệu, và đồ thị luồng-điều khiển.

6.3 Kiểm Thử Học Sâu

Các mô hình học sâu được coi như một hệ thống. Mặc dù chúng ta có thể biết trọng số của mô hình và phương pháp tính toán nội bộ của nó, chúng ta không biết logic nội tại của nó. Hu et al. [23] nghiên cứu toàn diện về kiểm thử học sâu. Kiểm thử một hệ thống hộp đen như vậy khá thách thức. Các nhà nghiên cứu kỹ thuật phần mềm ban đầu chủ yếu tập trung vào phát hiện khuyết điểm trong các hệ thống học sâu [47]. Ví dụ, DeepMutation [44] và DeepGini [12] đều được sử dụng để tìm khuyết điểm trong các hệ thống học sâu. Những khuyết điểm này thường được định nghĩa là các đầu vào gây ra hệ thống tạo ra đầu ra không chính xác. Một khi các khuyết điểm hệ thống được phát hiện, các nhà nghiên cứu cố gắng sửa chữa những khuyết điểm đã phát hiện này. Ngoài ra, trong các tình huống mà nhiều mô hình được sử dụng cho cùng một nhiệm vụ, các nhà nghiên cứu đã đề xuất các cách để chọn các mô hình chất lượng cao với ít khuyết điểm [24,51,61]. Các mô hình được kiểm thử thường là

J. ACM, Vol. 37, No. 4, Article 111. Ngày xuất bản: Tháng 8 2018.

--- TRANG 22 ---
111:22 W. Ma, S. Liu và M. Zhao et al.

các mô hình giải quyết các nhiệm vụ cụ thể trong tình huống cụ thể. Bên cạnh đó, một số nghiên cứu tập trung vào kiểm thử hiệu suất mô hình trong các tình huống không biết. Ví dụ, ATC (Tận dụng Dữ liệu Không Nhãn để Dự đoán Hiệu suất Ngoài Phân phối) [15], Aries [25], và OODRobustBench [33] đều nghiên cứu hiệu suất của các mô hình trên dữ liệu ngoài phân phối. Quan trọng cần nhấn mạnh rằng công trình của chúng tôi không phải để phát hiện khuyết điểm trong mô hình; chúng tôi nhằm giải thích sự hiểu biết về cú pháp và ngữ nghĩa mã cho các mô hình mã. Phân tích thăm dò và kiểm thử khác nhau. Phân tích thăm dò tập trung vào hiểu các cơ chế nội bộ và biểu diễn kiến thức của các mô hình trong khi kiểm thử các mô hình mã nhằm đánh giá hiệu suất thực tế của các mô hình và xác định các khuyết điểm tiềm ẩn. Cả hai đều là các bước không thể thiếu trong quá trình phát triển và đánh giá các mô hình mã, nhưng chúng tập trung vào các khía cạnh khác nhau.

7 KẾT LUẬN VÀ THẢO LUẬN

7.1 Kết Luận

Trong công trình này, chúng tôi nhằm hiểu sâu sắc hơn về cách các mô hình mã xử lý và hiểu các cấu trúc cú pháp và ngữ nghĩa mã phức tạp. Cụ thể, chúng tôi điều tra liệu những mô hình mã này có thể nắm bắt chính xác các cây cú pháp (AST), phụ thuộc điều khiển (CDG), luồng điều khiển (CFG), và phụ thuộc dữ liệu (DDG) trong mã bằng cách tái tạo những cấu trúc cú pháp và ngữ nghĩa này trong không gian vector hay không. Đây đều là các khía cạnh cơ bản của hiểu chương trình. Chúng tôi thiết kế một loạt các nhiệm vụ thăm dò để đánh giá khả năng của các mô hình mã trong việc xử lý cú pháp và ngữ nghĩa mã. Chúng tôi khám phá bốn mô hình mã tiền huấn luyện phổ biến: CodeBERT, GraphCodeBERT, UnixCoder, và CodeT5, và giới thiệu ba mô hình ngôn ngữ quy mô lớn (LLM): CodeLlama, StarCoder, và CodeT5+, để đánh giá hiệu suất của chúng trong việc hiểu cú pháp và ngữ nghĩa mã. Ngoài ra, chúng tôi quan sát gián tiếp cách các mô hình xử lý các phụ thuộc trong mã thông qua phân tích chú ý. Từ các thí nghiệm của chúng tôi, chúng tôi thu được một số phát hiện thú vị. Các mô hình mã tiền huấn luyện và LLM có thể biểu đạt cú pháp mã khá tốt và nắm bắt ngữ nghĩa mã ở một mức độ nào đó, đặc biệt trong việc xử lý phụ thuộc dữ liệu và phụ thuộc điều khiển. Bằng cách so sánh hiệu suất của các mô hình khác nhau, chúng tôi quan sát rằng các mô hình cụ thể có lợi thế khác nhau trong các nhiệm vụ thăm dò, cho thấy hiệu ứng khác nhau của các chiến lược mô hình và tập dữ liệu huấn luyện đối với sự hiểu biết của các mô hình về cú pháp và ngữ nghĩa mã. Mặc dù LLM thể hiện khả năng học cú pháp và ngữ nghĩa mã, phân tích hiệu suất sâu sắc tiết lộ sự khác biệt trong việc trình bày sự hiểu biết này trong các tầng ẩn khác nhau, cho thấy khả năng tối ưu hóa các chiến lược tiền huấn luyện để cải thiện xử lý ngữ nghĩa sâu. Khi chúng tôi sử dụng các mô hình mã SOTA như CodeLlama để giải quyết các nhiệm vụ kỹ thuật phần mềm, chúng tôi vẫn cần thiết kế cẩn thận các mô hình nhiệm vụ downstream vì các đặc trưng mã được trích xuất bởi các mô hình lớn bị ẩn sâu và không dễ quan sát.

7.2 Thảo Luận

Nghiên cứu của chúng tôi cung cấp những hiểu biết có giá trị để hiểu và cải thiện khả năng của các mô hình mã và đặt ra những câu hỏi thách thức và cơ hội cho các hướng nghiên cứu tương lai. Dựa trên các phát hiện của chúng tôi, chúng tôi tin rằng nghiên cứu tương lai nên tập trung vào một số lĩnh vực chính: 1). Tối ưu hóa thêm kiến trúc và chiến lược huấn luyện của các mô hình mã để tăng cường khả năng hiểu ngữ nghĩa mã phức tạp của chúng. Điều này có thể bao gồm việc khám phá các kiến trúc mạng thần kinh mới, mục tiêu huấn luyện và kỹ thuật tăng cường dữ liệu. Một giải pháp có thể là sử dụng graph transformer [37,77] để trực tiếp học các cấu trúc cú pháp và ngữ nghĩa của mã. Ma et al. [49] đã chứng minh rằng mạng thần kinh đồ thị có thể hoạt động cũng như transformer nhưng với ít tham số hơn. Graph transformer kết hợp ưu điểm của mạng thần kinh đồ thị và transformer: mã hóa cấu trúc đồ thị và học từ corpus lớn. 2). Khám phá các nhiệm vụ thăm dò mới và phương pháp đánh giá để tiếp tục tiết lộ hoạt động nội bộ của các mô hình mã, đặc biệt khả năng của các mô hình dựa trên bộ giải mã để hiểu mã. Điều này có thể bao gồm việc phát triển các thước đo mới để đo lường hiểu biết mã, cũng như thiết kế các ví dụ đối nghịch để kiểm tra tính mạnh mẽ của các mô hình mã. 3). Điều tra mối quan hệ giữa tính mạnh mẽ của các mô hình mã và khả năng hiểu ngữ nghĩa mã của chúng. Điều này có thể bao gồm việc nghiên cứu cách các loại nhiễu và tấn công đối nghịch khác nhau ảnh hưởng đến hiệu suất của các mô hình mã và phát triển các phương pháp để cải thiện tính mạnh mẽ của chúng trong khi duy trì khả năng hiểu mã. Nhìn về phía trước, các mô hình mã ngày càng được sử dụng cho phát triển phần mềm. Công trình của chúng tôi đã làm nổi bật rằng các mô hình mã vẫn có những thiếu sót đáng kể trong việc hiểu ngữ nghĩa mã. Tuy nhiên, ngữ nghĩa mã có liên quan chặt chẽ đến bảo mật mã. Do đó, việc thực hiện kiểm tra bảo mật trên mã được tạo bởi các mô hình mã là rất quan trọng.

8 CÁC MỐI ĐE DỌA ĐỐI VỚI TÍNH HỢP LỆ

Thứ nhất, kết quả của phân tích phát hiện bị ảnh hưởng bởi hạt giống ngẫu nhiên và tập dữ liệu được sử dụng. Có một mức độ ngẫu nhiên nhất định có thể ảnh hưởng đến hiệu suất của bộ phân loại phát hiện cuối cùng. Để giảm thiểu tác động của tính ngẫu nhiên, chúng tôi đã tiến hành nhiều thí nghiệm và thực hiện phân tích thống kê các kết quả.

Thứ hai, chúng tôi đã sử dụng các công cụ phân tích tĩnh để xây dựng tập dữ liệu chất lượng cao để phân tích. Mặc dù phương pháp này cung cấp thông tin có giá trị, nó cũng giới thiệu một số thiên vị nhất định. Các công cụ phân tích tĩnh có thể không nắm bắt đầy đủ các biến thể tinh tế trong ngữ nghĩa động và có thể bị ảnh hưởng bởi quy tắc cú pháp của các ngôn ngữ lập trình cụ thể. Để giảm thiên vị này, chúng tôi chọn các công cụ được nhiều nhà nghiên cứu sử dụng để tránh sai sót trong dữ liệu. Trong quá trình so sánh chéo nhiệm vụ, chúng tôi trích xuất các nhiệm vụ cú pháp và ngữ nghĩa từ cùng một nguồn dữ liệu để giảm thiểu thiên vị trong so sánh chéo nhiệm vụ.

Thứ ba, các thước đo hiệu suất khác nhau có thể thể hiện các thiên vị khác nhau. Để đánh giá các mô hình chính xác hơn, chúng tôi đã sử dụng hệ số tương quan Matthews (MCC) cho phân loại nhị phân và điểm F1 cho phân loại đa lớp. Thực tế, chúng tôi đã đánh giá các mô hình sử dụng cả MCC và F1 cho tất cả các nhiệm vụ, và các kết luận rút ra từ cả hai thước đo đều nhất quán.

Thứ tư, mặc dù phân tích thăm dò có thể tiết lộ khả năng học của các mô hình mã về cú pháp và ngữ nghĩa, nó không đảm bảo hiệu suất nhiệm vụ downstream tốt trong các ứng dụng thực tế. Các mô hình mã có thể hoạt động tốt trong các nhiệm vụ thăm dò nhưng kém trong các ứng dụng thực tế, đặc biệt các nhiệm vụ yêu cầu lý luận phức tạp hoặc tương tác đa phương thức. Hiệu suất của các mô hình nhiệm vụ downstream liên quan không chỉ đến sức mạnh biểu đạt của mô hình cơ sở mà còn đến chất lượng của tập dữ liệu nhiệm vụ downstream và tính mạnh mẽ của mô hình.

Thứ năm, phân tích thăm dò là để quan sát liệu biểu diễn có chứa một thuộc tính cụ thể tồn tại trong đầu vào hay không. Tuy nhiên, hiệu suất kém của phân tích thăm dò không có nghĩa là biểu diễn không chứa thông tin như vậy. Không gian biểu diễn là không gian chiều cao và trộn lẫn tất cả những gì đã học với nhau. Một số thông tin dễ quan sát hơn và dễ thăm dò. Phương pháp thăm dò của chúng tôi chỉ có thể được sử dụng để trả lời liệu thuộc tính này có dễ quan sát hơn hoặc ít hơn hay không. Nó bị hạn chế trong việc trả lời 'có' hoặc 'không'.

Cuối cùng nhưng không kém phần quan trọng, nhiều mô hình mã đã được đề xuất. Để đảm bảo rằng phương pháp đánh giá và kết luận của chúng tôi được tổng quát hóa, chúng tôi xem xét ba kiến trúc khác nhau của các mô hình mã: bộ mã hóa, bộ giải mã và bộ mã hóa-giải mã. Chúng tôi bao gồm các mô hình tiền huấn luyện truyền thống và các mô hình ngôn ngữ lớn từ các công ty hoặc tổ chức lớn, và tất cả những mô hình này được sử dụng rộng rãi như các mô hình cơ sở để giải quyết các nhiệm vụ downstream. Khi chúng tôi thiết kế phương pháp của mình, chúng tôi không xem xét bất kỳ mô hình và ngôn ngữ lập trình cụ thể nào, và chúng tôi chỉ xem xét cú pháp và ngữ nghĩa của mã. AST đại diện cho tất cả thông tin cú pháp của mã. CFG đại diện cho logic/hành động của mã. DDG và CDG đại diện cho mối quan hệ ngữ nghĩa giữa các phần mã khác nhau. Hầu như tất cả các nhiệm vụ SE liên quan đến mã đều cần thông tin này. Tuy nhiên, các mô hình khác nhau có khả năng khác nhau, và kết luận của chúng tôi có thể không phù hợp với một mô hình có chiến lược huấn luyện và tập dữ liệu rất khác biệt.

LỜI CẢM ƠN

Nghiên cứu này được hỗ trợ bởi Quỹ Nghiên cứu Quốc gia, Singapore, và Cơ quan An ninh Mạng dưới Chương trình Nghiên cứu và Phát triển An ninh Mạng Quốc gia (NCRP25-P04-TAICeN), Quỹ Nghiên cứu Quốc gia, Singapore, và Phòng thí nghiệm Quốc gia DSO dưới Chương trình AI Singapore (AISG Award No: AISG2-GC-2023-008), và NRF Investigatorship NRF-NRFI06-2020-0001. Bất kỳ ý kiến, phát hiện và kết luận hoặc khuyến nghị nào được thể hiện trong tài liệu này đều là của (các) tác giả và không phản ánh quan điểm của Quỹ Nghiên cứu Quốc gia, Singapore và Cơ quan An ninh Mạng của Singapore.

TÀI LIỆU THAM KHẢO

[1]Charu C. Aggarwal, Alexander Hinneburg, và Daniel A. Keim. 2001. On the Surprising Behavior of Distance Metrics in High Dimensional Spaces. In Proceedings of the 8th International Conference on Database Theory (ICDT '01). Springer-Verlag, Berlin, Heidelberg, 420–434.

[2]Wasi Uddin Ahmad, Saikat Chakraborty, Baishakhi Ray, và Kai-Wei Chang. 2021. Unified pre-training for program understanding and generation. arXiv preprint arXiv:2103.06333 (2021).

[3]Miltos Allamanis, Earl T. Barr, Premkumar Devanbu, và Charles Sutton. 2018. A Survey of Machine Learning for Big Code and Naturalness. Comput. Surveys 51, 4 (July 2018), 81. https://www.microsoft.com/en-us/research/publication/a-survey-of-machine-learning-for-big-code-and-naturalness/

[4]Luca Buratti, Saurabh Pujar, Mihaela Bornea, Scott McCarley, Yunhui Zheng, Gaetano Rossiello, Alessandro Morari, Jim Laredo, Veronika Thost, Yufan Zhuang, et al. 2020. Exploring software naturalness through neural language models. arXiv preprint arXiv:2006.12641 (2020).

[5]Davide Chicco và Giuseppe Jurman. 2020. The advantages of the Matthews correlation coefficient (MCC) over F1 score and accuracy in binary classification evaluation. BMC genomics 21, 1 (2020), 1–13.

[6]Alexis Conneau, German Kruszewski, Guillaume Lample, Loïc Barrault, và Marco Baroni. 2018. What you can cram into a single $&!#* vector: Probing sentence embeddings for linguistic properties. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). Association for Computational Linguistics, Melbourne, Australia, 2126–2136. https://doi.org/10.18653/v1/P18-1198

[7]Qingxiu Dong, Lei Li, Damai Dai, Ce Zheng, Zhiyong Wu, Baobao Chang, Xu Sun, Jingjing Xu, và Zhifang Sui. 2022. A survey for in-context learning. arXiv preprint arXiv:2301.00234 (2022).

[8]Shihan Dou, Junjie Shan, Haoxiang Jia, Wenhao Deng, Zhiheng Xi, Wei He, Yueming Wu, Tao Gui, Yang Liu, và Xuanjing Huang. 2023. Towards understanding the capability of large language models on code clone detection: a survey. arXiv preprint arXiv:2308.01191 (2023).

[9]Dawn Drain, Chen Wu, Alexey Svyatkovskiy, và Neel Sundaresan. 2021. Generating bug-fixes using pretrained transformers. In Proceedings of the 5th ACM SIGPLAN International Symposium on Machine Programming. 1–8.

[10] Xueying Du, Mingwei Liu, Kaixin Wang, Hanlin Wang, Junwei Liu, Yixuan Chen, Jiayi Feng, Chaofeng Sha, Xin Peng, và Yiling Lou. 2023. Classeval: A manually-crafted benchmark for evaluating llms on class-level code generation. arXiv preprint arXiv:2308.01861 (2023).

[11] Angela Fan, Beliz Gokkaya, Mark Harman, Mitya Lyubarskiy, Shubho Sengupta, Shin Yoo, và Jie M Zhang. 2023. Large language models for software engineering: Survey and open problems. arXiv preprint arXiv:2310.03533 (2023).

[12] Yang Feng, Qingkai Shi, Xinyu Gao, Jun Wan, Chunrong Fang, và Zhenyu Chen. 2020. DeepGini: prioritizing massive tests to enhance the robustness of deep neural networks. In Proceedings of the 29th ACM SIGSOFT International Symposium on Software Testing and Analysis (Virtual Event, USA) (ISSTA 2020). Association for Computing Machinery, New York, NY, USA, 177–188. https://doi.org/10.1145/3395363.3397357

[13] Zhangyin Feng, Daya Guo, Duyu Tang, Nan Duan, Xiaocheng Feng, Ming Gong, Linjun Shou, Bing Qin, Ting Liu, Daxin Jiang, et al. 2020. Codebert: A pre-trained model for programming and natural languages. arXiv preprint arXiv:2002.08155 (2020).

[14] Fengjuan Gao, Yu Wang, và Ke Wang. 2023. Discrete Adversarial Attack to Models of Code. Proc. ACM Program. Lang. 7, PLDI, Article 113 (jun 2023), 24 pages. https://doi.org/10.1145/3591227

[15] Saurabh Garg, Sivaraman Balakrishnan, Zachary C Lipton, Behnam Neyshabur, và Hanie Sedghi. 2022. Leveraging unlabeled data to predict out-of-distribution performance. arXiv preprint arXiv:2201.04234 (2022).

[16] Daya Guo, Shuai Lu, Nan Duan, Yanlin Wang, Ming Zhou, và Jian Yin. 2022. UniXcoder: Unified Cross-Modal Pre-training for Code Representation. arXiv preprint arXiv:2203.03850 (2022).

J. ACM, Vol. 37, No. 4, Article 111. Ngày xuất bản: Tháng 8 2018.

--- TRANG 26 ---
111:26 W. Ma, S. Liu và M. Zhao et al.

[17] Daya Guo, Shuo Ren, Shuai Lu, Zhangyin Feng, Duyu Tang, Shujie Liu, Long Zhou, Nan Duan, Alexey Svyatkovskiy, Shengyu Fu, et al. 2020. Graphcodebert: Pre-training code representations with data flow. arXiv preprint arXiv:2009.08366 (2020).

[18] José Antonio Hernández López, Martin Weyssow, Jesús Sánchez Cuadrado, và Houari Sahraoui. 2023. AST-Probe: Recovering abstract syntax trees from hidden representations of pre-trained language models. In Proceedings of the 37th IEEE/ACM International Conference on Automated Software Engineering (<conf-loc>, <city>Rochester</city>, <state>MI</state>, <country>USA</country>, </conf-loc>) (ASE '22). Association for Computing Machinery, New York, NY, USA, Article 11, 11 pages. https://doi.org/10.1145/3551349.3556900

[19] Sirui Hong, Mingchen Zhuge, Jonathan Chen, Xiawu Zheng, Yuheng Cheng, Ceyao Zhang, Jinlin Wang, Zili Wang, Steven Ka Shing Yau, Zijuan Lin, Liyang Zhou, Chenyu Ran, Lingfeng Xiao, Chenglin Wu, và Jürgen Schmidhuber. 2023. MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework. arXiv:2308.00352 [cs.AI]

[20] Susan Horwitz và Thomas Reps. 1992. The Use of Program Dependence Graphs in Software Engineering. In Proceedings of the 14th International Conference on Software Engineering (Melbourne, Australia) (ICSE '92). Association for Computing Machinery, New York, NY, USA, 392–411. https://doi.org/10.1145/143062.143156

[21] Xinyi Hou, Yanjie Zhao, Yue Liu, Zhou Yang, Kailong Wang, Li Li, Xiapu Luo, David Lo, John Grundy, và Haoyu Wang. 2023. Large language models for software engineering: A systematic literature review. arXiv preprint arXiv:2308.10620 (2023).

[22] Edward J Hu, yelong shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, và Weizhu Chen. 2022. LoRA: Low-Rank Adaptation of Large Language Models. In International Conference on Learning Representations. https://openreview.net/forum?id=nZeVKeeFYf9

[23] Qiang Hu, Yuejun Guo, Xiaofei Xie, Maxime Cordy, Lei Ma, Mike Papadakis, và Yves Le Traon. 2024. Test Optimization in DNN Testing: A Survey. ACM Trans. Softw. Eng. Methodol. (jan 2024). https://doi.org/10.1145/3643678 Just Accepted.

[24] Qiang Hu, Yuejun Guo, Xiaofei Xie, Maxime Cordy, Mike Papadakis, và Yves Le Traon. 2023. LaF: Labeling-free Model Selection for Automated Deep Neural Network Reusing. ACM Trans. Softw. Eng. Methodol. 33, 1, Article 25 (nov 2023), 28 pages. https://doi.org/10.1145/3611666

[25] Qiang Hu, Yuejun Guo, Xiaofei Xie, Maxime Cordy, Mike Papadakis, Lei Ma, và Yves Le Traon. 2023. Aries: Efficient Testing of Deep Neural Networks via Labeling-Free Accuracy Estimation. In Proceedings of the 45th International Conference on Software Engineering (Melbourne, Victoria, Australia) (ICSE '23). IEEE Press, 1776–1787. https://doi.org/10.1109/ICSE48619.2023.00152

[26] Hamel Husain, Ho-Hsiang Wu, Tiferet Gazit, Miltiadis Allamanis, và Marc Brockschmidt. 2019. Codesearchnet challenge: Evaluating the state of semantic code search. arXiv preprint arXiv:1909.09436 (2019).

[27] Mehdi Iraqi. [n. d.]. Comparing the Performance of LLMs: A Deep Dive into Roberta, Llama 2, and Mistral for Disaster Tweets Analysis with Lora. https://huggingface.co/blog/Lora-for-sequence-classification-with-Roberta-Llama-Mistral#comparing-the-performance-of-llms-a-deep-dive-into-roberta-llama-2-and-mistral-for-disaster-tweets-analysis-with-lora

[28] Akshita Jha và Chandan K. Reddy. 2023. CodeAttack: code-based adversarial attacks for pre-trained programming language models. In Proceedings of the Thirty-Seventh AAAI Conference on Artificial Intelligence and Thirty-Fifth Conference on Innovative Applications of Artificial Intelligence and Thirteenth Symposium on Educational Advances in Artificial Intelligence (AAAI'23/IAAI'23/EAAI'23). AAAI Press, Article 1670, 9 pages. https://doi.org/10.1609/aaai.v37i12.26739

[29] Aditya Kanade, Petros Maniatis, Gogul Balakrishnan, và Kensen Shi. 2019. Pre-trained contextual embedding of source code. (2019).

[30] Jared Kaplan, Sam McCandlish, Tom Henighan, Tom B Brown, Benjamin Chess, Rewon Child, Scott Gray, Alec Radford, Jeffrey Wu, và Dario Amodei. 2020. Scaling laws for neural language models. arXiv preprint arXiv:2001.08361 (2020).

[31] Rafael-Michael Karampatsis và Charles Sutton. 2020. Scelmo: Source code embeddings from language models. arXiv preprint arXiv:2004.13214 (2020).

[32] Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Ves Stoyanov, và Luke Zettlemoyer. 2019. Bart: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension. arXiv preprint arXiv:1910.13461 (2019).

[33] Lin Li, Yifei Wang, Chawin Sitawarin, và Michael Spratling. 2023. OODRobustBench: benchmarking and analyzing adversarial robustness under distribution shift. arXiv preprint arXiv:2310.12793 (2023).

[34] Raymond Li, Loubna Ben Allal, Yangtian Zi, Niklas Muennighoff, Denis Kocetkov, Chenghao Mou, Marc Marone, Christopher Akiki, Jia Li, Jenny Chim, et al. 2023. StarCoder: may the source be with you! arXiv preprint arXiv:2305.06161 (2023).

[35] Xiaochen Li, He Jiang, Zhilei Ren, Ge Li, và Jingxuan Zhang. 2018. Deep learning in software engineering. arXiv preprint arXiv:1805.04825 (2018).

J. ACM, Vol. 37, No. 4, Article 111. Ngày xuất bản: Tháng 8 2018.

--- TRANG 27 ---
Khám Phá Các Mô Hình Tiền Huấn Luyện Mã: Nghiên Cứu Khả Năng Cú Pháp và Ngữ Nghĩa 111:27

[36] Xueyang Li, Shangqing Liu, Ruitao Feng, Guozhu Meng, Xiaofei Xie, Kai Chen, và Yang Liu. 2022. TransRepair: Context-aware Program Repair for Compilation Errors. arXiv preprint arXiv:2210.03986 (2022).

[37] Yuan Li, Xiaodan Liang, Zhiting Hu, Yinbo Chen, và Eric P. Xing. 2019. Graph Transformer. https://openreview.net/forum?id=HJei-2RcK7

[38] Shangqing Liu, Yu Chen, Xiaofei Xie, Jingkai Siow, và Yang Liu. 2020. Retrieval-augmented generation for code summarization via hybrid gnn. arXiv preprint arXiv:2006.05405 (2020).

[39] Shangqing Liu, Cuiyun Gao, Sen Chen, Nie Lun Yiu, và Yang Liu. 2020. ATOM: Commit message generation based on abstract syntax tree and hybrid ranking. IEEE Transactions on Software Engineering (2020).

[40] Shangqing Liu, Yanzhou Li, và Yang Liu. 2022. CommitBART: A Large Pre-trained Model for GitHub Commits. arXiv preprint arXiv:2208.08100 (2022).

[41] Shangqing Liu, Bozhi Wu, Xiaofei Xie, Guozhu Meng, và Yang Liu. 2023. ContraBERT: Enhancing Code Pre-trained Models via Contrastive Learning. arXiv preprint arXiv:2301.09072 (2023).

[42] Shuai Lu, Daya Guo, Shuo Ren, Junjie Huang, Alexey Svyatkovskiy, Ambrosio Blanco, Colin Clement, Dawn Drain, Daxin Jiang, Duyu Tang, et al. 2021. Codexglue: A machine learning benchmark dataset for code understanding and generation. arXiv preprint arXiv:2102.04664 (2021).

[43] Ziyang Luo, Can Xu, Pu Zhao, Qingfeng Sun, Xiubo Geng, Wenxiang Hu, Chongyang Tao, Jing Ma, Qingwei Lin, và Daxin Jiang. 2023. WizardCoder: Empowering Code Large Language Models with Evol-Instruct. arXiv preprint arXiv:2306.08568 (2023).

[44] Lei Ma, Fuyuan Zhang, Jiyuan Sun, Minhui Xue, Bo Li, Felix Juefei-Xu, Chao Xie, Li Li, Yang Liu, Jianjun Zhao, et al. 2018. Deepmutation: Mutation testing of deep learning systems. In 2018 IEEE 29th international symposium on software reliability engineering (ISSRE). IEEE, 100–111.

[45] Wei Ma, Shangqing Liu, Zhihao Lin, Wenhan Wang, Qiang Hu, Ye Liu, Cen Zhang, Liming Nie, Li Li, và Yang Liu. 2024. LMs: Understanding Code Syntax and Semantics for Code Analysis. arXiv:2305.12138 [cs.SE]

[46] Wei Ma, Shangqing Liu, Wenhan Wang, Qiang Hu, Ye Liu, Cen Zhang, Liming Nie, và Yang Liu. 2023. The Scope of ChatGPT in Software Engineering: A Thorough Investigation. arXiv preprint arXiv:2305.12138 (2023).

[47] Wei Ma, Mike Papadakis, Anestis Tsakmalis, Maxime Cordy, và Yves Le Traon. 2021. Test Selection for Deep Learning Systems. ACM Trans. Softw. Eng. Methodol. 30, 2, Article 13 (jan 2021), 22 pages. https://doi.org/10.1145/3417330

[48] Wei Ma, Daoyuan Wu, Yuqiang Sun, Tianwen Wang, Shangqing Liu, Jian Zhang, Yue Xue, và Yang Liu. 2024. Combining Fine-Tuning and LLM-based Agents for Intuitive Smart Contract Auditing with Justifications. arXiv:2403.16073 [cs.SE]

[49] Wei Ma, Mengjie Zhao, Ezekiel Soremekun, Qiang Hu, Jie M. Zhang, Mike Papadakis, Maxime Cordy, Xiaofei Xie, và Yves Le Traon. 2022. GraphCode2Vec: generic code embedding via lexical and program dependence analyses. In Proceedings of the 19th International Conference on Mining Software Repositories (Pittsburgh, Pennsylvania) (MSR '22). Association for Computing Machinery, New York, NY, USA, 524–536. https://doi.org/10.1145/3524842.3528456

[50] B.W. Matthews. 1975. Comparison of the predicted and observed secondary structure of T4 phage lysozyme. Biochimica et Biophysica Acta (BBA) - Protein Structure 405, 2 (1975), 442–451. https://doi.org/10.1016/0005-2795(75)90109-9

[51] Linghan Meng, Yanhui Li, Lin Chen, Zhi Wang, Di Wu, Yuming Zhou, và Baowen Xu. 2021. Measuring discrimination to boost comparative testing for multiple deep learning models. In 2021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE). IEEE, 385–396.

[52] Evgeny M Mirkes, Jeza Allohibi, và Alexander Gorban. 2020. Fractional norms and quasinorms do not help to overcome the curse of dimensionality. Entropy 22, 10 (2020), 1105.

[53] Lili Mou, Ge Li, Lu Zhang, Tao Wang, và Zhi Jin. 2016. Convolutional neural networks over tree structures for programming language processing. In Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence. 1287–1293.

[54] Changan Niu, Chuanyi Li, Vincent Ng, Dongxiao Chen, Jidong Ge, và Bin Luo. 2023. An empirical comparison of pre-trained models of source code. arXiv preprint arXiv:2302.04026 (2023).

[55] Gustavo Penha và Claudia Hauff. 2020. What does BERT know about books, movies and music? Probing BERT for Conversational Recommendation. In Proceedings of the 14th ACM Conference on Recommender Systems (Virtual Event, Brazil) (RecSys '20). Association for Computing Machinery, New York, NY, USA, 388–397. https://doi.org/10.1145/3383313.3412249

[56] Ruchir Puri, David S Kung, Geert Janssen, Wei Zhang, Giacomo Domeniconi, Vladimir Zolotov, Julian Dolby, Jie Chen, Mihir Choudhury, Lindsey Decker, et al. 2021. CodeNet: A large-scale AI for code dataset for learning a diversity of coding tasks. arXiv preprint arXiv:2105.12655 (2021).

[57] Anna Rogers, Olga Kovaleva, và Anna Rumshisky. 2020. A Primer in BERTology: What We Know About How BERT Works. Transactions of the Association for Computational Linguistics 8 (2020), 842–866. https://doi.org/10.1162/tacl_a_00349

[58] Baptiste Roziere, Jonas Gehring, Fabian Gloeckle, Sten Sootla, Itai Gat, Xiaoqing Ellen Tan, Yossi Adi, Jingyu Liu, Tal Remez, Jérémy Rapin, et al. 2023. Code llama: Open foundation models for code. arXiv preprint arXiv:2308.12950

J. ACM, Vol. 37, No. 4, Article 111. Ngày xuất bản: Tháng 8 2018.

--- TRANG 28 ---
111:28 W. Ma, S. Liu và M. Zhao et al.

(2023).

[59] Da Shen, Xinyun Chen, Chenguang Wang, Koushik Sen, và Dawn Song. 2022. Benchmarking Language Models for Code Syntax Understanding. In Findings of the Association for Computational Linguistics: EMNLP 2022, Yoav Goldberg, Zornitsa Kozareva, và Yue Zhang (Eds.). Association for Computational Linguistics, Abu Dhabi, United Arab Emirates, 3071–3093. https://doi.org/10.18653/v1/2022.findings-emnlp.224

[60] Yikang Shen, Zhouhan Lin, Athul Paul Jacob, Alessandro Sordoni, Aaron Courville, và Yoshua Bengio. 2018. Straight to the Tree: Constituency Parsing with Neural Syntactic Distance. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), Iryna Gurevych và Yusuke Miyao (Eds.). Association for Computational Linguistics, Melbourne, Australia, 1171–1180. https://doi.org/10.18653/v1/P18-1108

[61] Xiaoxiao Sun, Yunzhong Hou, Weijian Deng, Hongdong Li, và Liang Zheng. 2021. Ranking Models in Unlabeled New Environments. In 2021 IEEE/CVF International Conference on Computer Vision (ICCV). 11741–11751. https://doi.org/10.1109/ICCV48922.2021.01155

[62] Yuqiang Sun, Daoyuan Wu, Yue Xue, Han Liu, Wei Ma, Lyuye Zhang, Miaolei Shi, và Yang Liu. 2024. LLM4Vuln: A Unified Evaluation Framework for Decoupling and Enhancing LLMs' Vulnerability Reasoning. arXiv:2401.16185 [cs.CR]

[63] Alexey Svyatkovskiy, Shao Kun Deng, Shengyu Fu, và Neel Sundaresan. 2020. Intellicode compose: Code generation using transformer. In Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering. 1433–1443.

[64] Ian Tenney, Patrick Xia, Berlin Chen, Alex Wang, Adam Poliak, R Thomas McCoy, Najoung Kim, Benjamin Van Durme, Samuel R Bowman, Dipanjan Das, et al. 2019. What do you learn from context? probing for sentence structure in contextualized word representations. arXiv preprint arXiv:1905.06316 (2019).

[65] Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al. 2023. Llama 2: Open foundation and fine-tuned chat models. arXiv preprint arXiv:2307.09288 (2023).

[66] Sergey Troshin và Nadezhda Chirkova. 2022. Probing Pretrained Models of Source Code. arXiv preprint arXiv:2202.08975 (2022).

[67] Betty van Aken, Benjamin Winter, Alexander Löser, và Felix A. Gers. 2019. How Does BERT Answer Questions? A Layer-Wise Analysis of Transformer Representations. In Proceedings of the 28th ACM International Conference on Information and Knowledge Management (Beijing, China) (CIKM '19). Association for Computing Machinery, New York, NY, USA, 1823–1832. https://doi.org/10.1145/3357384.3358028

[68] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, và Illia Polosukhin. 2017. Attention is all you need. Advances in neural information processing systems 30 (2017).

[69] Yao Wan, Wei Zhao, Hongyu Zhang, Yulei Sui, Guandong Xu, và Hai Jin. 2022. What Do They Capture? A Structural Analysis of Pre-Trained Language Models for Source Code. In Proceedings of the 44th International Conference on Software Engineering (Pittsburgh, Pennsylvania) (ICSE '22). Association for Computing Machinery, New York, NY, USA, 2377–2388. https://doi.org/10.1145/3510003.3510050

[70] Yue Wang, Hung Le, Akhilesh Deepak Gotmare, Nghi DQ Bui, Junnan Li, và Steven CH Hoi. 2023. Codet5+: Open code large language models for code understanding and generation. arXiv preprint arXiv:2305.07922 (2023).

[71] Yue Wang, Weishi Wang, Shafiq Joty, và Steven CH Hoi. 2021. Codet5: Identifier-aware unified pre-trained encoder-decoder models for code understanding and generation. arXiv preprint arXiv:2109.00859 (2021).

[72] Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, et al. 2022. Emergent abilities of large language models. arXiv preprint arXiv:2206.07682 (2022).

[73] Yanming Yang, Xin Xia, David Lo, và John Grundy. 2022. A Survey on Deep Learning for Software Engineering. ACM Comput. Surv. 54, 10s, Article 206 (sep 2022), 73 pages. https://doi.org/10.1145/3505243

[74] Jingxiu Yao và Martin Shepperd. 2020. Assessing Software Defection Prediction Performance: Why Using the Matthews Correlation Coefficient Matters. In Proceedings of the 24th International Conference on Evaluation and Assessment in Software Engineering (Trondheim, Norway) (EASE '20). Association for Computing Machinery, New York, NY, USA, 120–129. https://doi.org/10.1145/3383219.3383232

[75] Noam Yefet, Uri Alon, và Eran Yahav. 2020. Adversarial examples for models of code. Proc. ACM Program. Lang. 4, OOPSLA, Article 162 (nov 2020), 30 pages. https://doi.org/10.1145/3428230

[76] Zhiqiang Yuan, Yiling Lou, Mingwei Liu, Shiji Ding, Kaixin Wang, Yixuan Chen, và Xin Peng. 2023. No More Manual Tests? Evaluating and Improving ChatGPT for Unit Test Generation. arXiv preprint arXiv:2305.04207 (2023).

[77] Seongjun Yun, Minbyul Jeong, Raehyun Kim, Jaewoo Kang, và Hyunwoo J Kim. 2019. Graph transformer networks. Advances in neural information processing systems 32 (2019).

[78] Ziyin Zhang, Chaoyu Chen, Bingchang Liu, Cong Liao, Zi Gong, Hang Yu, Jianguo Li, và Rui Wang. 2023. A survey on language models for code. arXiv preprint arXiv:2311.07989 (2023).

J. ACM, Vol. 37, No. 4, Article 111. Ngày xuất bản: Tháng 8 2018.

--- TRANG 29 ---
Khám Phá Các Mô Hình Tiền Huấn Luyện Mã: Nghiên Cứu Khả Năng Cú Pháp và Ngữ Nghĩa 111:29

[79] Mengjie Zhao, Philipp Dufter, Yadollah Yaghoobzadeh, và Hinrich Schütze. 2020. Quantifying the Contextualization of Word Representations with Semantic Class Probing. In Findings of the Association for Computational Linguistics: EMNLP 2020. Association for Computational Linguistics, Online, 1219–1234. https://doi.org/10.18653/v1/2020.findings-emnlp.109

[80] Yaqin Zhou, Shangqing Liu, Jingkai Siow, Xiaoning Du, và Yang Liu. 2019. Devign: Effective vulnerability identification by learning comprehensive program semantics via graph neural networks. In Advances in Neural Information Processing Systems. 10197–10207.

[81] Barret Zoph, Colin Raffel, Dale Schuurmans, Dani Yogatama, Denny Zhou, Don Metzler, Ed H. Chi, Jason Wei, Jeff Dean, Liam B. Fedus, Maarten Paul Bosma, Oriol Vinyals, Percy Liang, Sebastian Borgeaud, Tatsunori B. Hashimoto, và Yi Tay. 2022. Emergent abilities of large language models. TMLR (2022).

J. ACM, Vol. 37, No. 4, Article 111. Ngày xuất bản: Tháng 8 2018.

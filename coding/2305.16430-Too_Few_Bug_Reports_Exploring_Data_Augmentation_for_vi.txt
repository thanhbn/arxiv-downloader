# Quá ít báo cáo lỗi? Khám phá tăng cường dữ liệu để cải thiện định vị lỗi dựa trên changeset

Agnieszka Ciborowska
Đại học Virginia Commonwealth
Richmond, Virginia, USA
imranm3@vcu.eduKostadin Damevski
Đại học Virginia Commonwealth
Richmond, Virginia, USA
kdamevski@vcu.edu

TÓM TẮT
Các kiến trúc Deep Learning (DL) hiện đại dựa trên transformer (ví dụ: BERT, RoBERTa) đang thể hiện sự cải thiện hiệu suất trên nhiều tác vụ ngôn ngữ tự nhiên. Mặc dù các mô hình DL này đã cho thấy tiềm năng to lớn để sử dụng trong các ứng dụng kỹ thuật phần mềm, chúng thường bị cản trở bởi dữ liệu huấn luyện không đầy đủ. Đặc biệt bị hạn chế là các ứng dụng yêu cầu dữ liệu cụ thể của dự án, chẳng hạn như định vị lỗi, nhằm mục đích đề xuất mã để sửa một báo cáo lỗi mới được gửi. Các mô hình deep learning cho định vị lỗi yêu cầu một tập huấn luyện đáng kể gồm các báo cáo lỗi đã được sửa, mà chúng có số lượng hạn chế ngay cả trong các dự án phần mềm phổ biến và được phát triển tích cực. Trong bài báo này, chúng tôi kiểm tra tác động của việc sử dụng dữ liệu huấn luyện tổng hợp trên các mô hình DL dựa trên transformer thực hiện một biến thể phức tạp hơn của định vị lỗi, có mục tiêu truy xuất các changeset gây ra lỗi cho mỗi báo cáo lỗi. Để tạo ra dữ liệu tổng hợp chất lượng cao, chúng tôi đề xuất các toán tử tăng cường dữ liệu mới hoạt động trên các thành phần cấu thành khác nhau của báo cáo lỗi. Chúng tôi cũng mô tả một chiến lược cân bằng dữ liệu nhằm tạo ra một kho tàng các báo cáo lỗi được tăng cường phản ánh tốt hơn toàn bộ cơ sở mã nguồn, bởi vì các báo cáo lỗi hiện có được sử dụng làm dữ liệu huấn luyện thường chỉ tham chiếu một phần nhỏ của cơ sở mã. Cân bằng dữ liệu giúp mô hình hoạt động tốt hơn cho các báo cáo lỗi mới được báo cáo tham chiếu đến mã chưa từng được quan sát trước đó. Kết quả đánh giá của chúng tôi chỉ ra rằng cả tăng cường dữ liệu và cân bằng đều hiệu quả, cải thiện hiệu suất truy xuất trên cả ba mô hình dựa trên BERT mà chúng tôi nghiên cứu.

ACM Reference Format:
Agnieszka Ciborowska and Kostadin Damevski. 2023. Too Few Bug Reports? Exploring Data Augmentation for Improved Changeset-based Bug Localization. In Proceedings of ACM Conference (Conference'17). ACM, New York, NY, USA, 12 pages. https://doi.org/10.1145/nnnnnnn.nnnnnnn

1 GIỚI THIỆU
Sự xuất hiện của các kiến trúc Deep Learning (DL) mới như transformer đã thúc đẩy những cải thiện nổi bật trên nhiều tác vụ trong Xử lý Ngôn ngữ Tự nhiên (NLP), và khuyến khích việc áp dụng chúng vào các vấn đề khác nhau trong lĩnh vực kỹ thuật phần mềm. Các nhà nghiên cứu kỹ thuật phần mềm đã nghiên cứu tiềm năng của DL trong bối cảnh các vấn đề như tìm kiếm mã [13,14,21,29], dự đoán khiếm khuyết [17,28,37,55,63], và định vị lỗi [6,19,20,26,62]. Tuy nhiên, điểm yếu cơ bản của các phương pháp DL là chúng yêu cầu một lượng lớn dữ liệu được gắn nhãn để huấn luyện mô hình. Đồng thời, việc duy trì chất lượng của dữ liệu được gắn nhãn là rất quan trọng để đạt được hiệu suất tốt nhất. Mặc dù việc gắn nhãn thủ công thường là phương pháp được ưa chuộng để đảm bảo chất lượng dữ liệu cao, nhưng đó là một quá trình chậm và tốn thời gian [51], thường không khả thi khi xem xét lượng dữ liệu cần thiết để huấn luyện một mô hình DL. Mặt khác, việc khai thác tự động cho nhãn có nhiều khả năng đáp ứng nhu cầu về số lượng dữ liệu hơn, tuy nhiên với cái giá phải trả là đưa ra nhiễu dưới dạng cả dương tính giả và âm tính giả [8,53]. Do đó, việc thu thập một lượng lớn dữ liệu được gắn nhãn chất lượng tốt có thể đặt ra một thách thức đáng kể cho nhiều vấn đề và tác vụ kỹ thuật phần mềm quan trọng, đặc biệt là những vấn đề yêu cầu dữ liệu dự án đơn lẻ (tức là trong dự án) [50]. Một phương pháp gần đây để giải quyết vấn đề này là sử dụng transfer learning, tức là tiền huấn luyện một mô hình với học không giám sát trên một kho tàng lớn, tổng quát, sau đó là tinh chỉnh thông qua học có giám sát hướng tới tác vụ đích. Tuy nhiên, chiến lược này vẫn yêu cầu một tập dữ liệu không tầm thường để tinh chỉnh và, như được quan sát bởi Gururangan et al., nó dẫn đến hiệu suất dưới tối ưu so với khi một mô hình được tiền huấn luyện và tinh chỉnh trên dữ liệu trong lĩnh vực [16].

Một trong những tác vụ kỹ thuật phần mềm được hưởng lợi từ phương pháp dựa trên DL là định vị lỗi, nhằm xác định các thực thể mã có liên quan (ví dụ: lớp, phương thức hoặc changeset) cho một báo cáo lỗi nhất định mô tả sự cố phần mềm. Qua nhiều năm, các nhà nghiên cứu đã đề xuất nhiều phương pháp cho định vị lỗi dựa trên Vector Space Model (VSM) [43,56,58] và các mô hình xác suất (ví dụ: Latent Dirichlet Allocation) [7,33], đồng thời cũng nhận ra rằng nhược điểm chính của những kỹ thuật này là khả năng hạn chế trong việc xử lý khoảng cách ngữ nghĩa giữa mã nguồn gây ra lỗi và mô tả được đưa ra trong báo cáo lỗi [1,64]. Để giải quyết điều đó, các nỗ lực gần đây đã được chuyển hướng sang các kỹ thuật DL, bao gồm RNN, LSTM và cuối cùng là các mô hình dựa trên transformer [6,29]. Như được Guo et al. [14] lưu ý, tính khả dụng của dữ liệu huấn luyện là một trong những yếu tố chính hạn chế hiệu suất DL. Trong trường hợp định vị lỗi, dữ liệu huấn luyện bao gồm các cặp báo cáo lỗi và changeset giới thiệu (hoặc gây ra) của chúng, rất khó thu thập ở quy mô lớn vì một vài lý do chính. Đầu tiên, việc khớp một báo cáo lỗi với các changeset gây ra lỗi là thách thức vì các nhà phát triển hiếm khi đánh dấu các thay đổi mã thủ phạm một cách rõ ràng [30], trong khi các phương pháp tìm ra changeset gây ra lỗi tự động, dựa trên thuật toán SZZ [46], dễ bị đưa ra nhiễu [31,42]. Thứ hai, số lượng mẫu tích cực bị giới hạn bởi số lượng báo cáo lỗi đã được sửa, vốn có hạn ngay cả đối với các dự án lớn và được duy trì tích cực. Các dự án phần mềm tương đối nhỏ hơn với, ví dụ, hàng chục báo cáo lỗi đã được sửa, sẽ rất khó sử dụng. Cuối cùng, câu hỏi chính vẫn còn mở: làm thế nào để tận dụng các kỹ thuật DL cho định vị lỗi, cho sự khan hiếm dữ liệu cụ thể của dự án.

Trong lĩnh vực NLP, câu hỏi này đã được trả lời với một số thành công bằng các kỹ thuật Tăng cường Dữ liệu (DA), mà nói chung, có thể được mô tả là các chiến lược để tăng một cách nhân tạo số lượng và đa dạng của các mẫu huấn luyện dựa trên dữ liệu hiện có [11]. DA nhằm tạo ra dữ liệu tổng hợp chất lượng cao bằng cách áp dụng các biến đổi lên dữ liệu có sẵn, trong khi duy trì tính bất biến của nhãn. Kết quả là, kích thước của tập dữ liệu gốc tăng lên, điều này lần lượt cho phép huấn luyện một mô hình DL cho các lĩnh vực và tác vụ tài nguyên thấp.

Được khuyến khích bởi những tiến bộ gần đây của DA trong lĩnh vực NLP, trong công trình này, chúng tôi nhằm khám phá tăng cường dữ liệu cho các báo cáo lỗi với mục tiêu tạo ra một số lượng lớn các báo cáo lỗi tổng hợp chất lượng cao, thực tế, có thể được sử dụng sau đó để tăng kích thước của tập huấn luyện cho một mô hình DL định vị lỗi. Để đạt được điều này, chúng tôi đề xuất hai tập hợp các toán tử DA hoạt động độc lập trên văn bản ngôn ngữ tự nhiên và dữ liệu liên quan đến mã (ví dụ: token mã, stack trace và đoạn mã) trong mỗi báo cáo lỗi. Cụ thể hơn, văn bản ngôn ngữ tự nhiên được tăng cường bằng cách sử dụng các biến đổi ở mức token và đoạn văn (ví dụ: chèn từ đồng nghĩa), trong khi dữ liệu liên quan đến mã được tăng cường với các token mã từ changeset gây ra lỗi tương ứng của nó để củng cố kết nối giữa một báo cáo lỗi và các phần khác nhau của changeset giới thiệu của nó. Đồng thời, bằng cách tận dụng các báo cáo lỗi được tăng cường, chúng tôi dự định đạt được một mục tiêu quan trọng khác, cân bằng tập dữ liệu được tăng cường hướng tới các phần của mã nguồn chưa được đại diện đầy đủ trong tập huấn luyện ban đầu. Điều này giải quyết sự xuất hiện phổ biến trong các dự án phần mềm rằng các báo cáo lỗi hiện có chỉ tham chiếu một phần cụ thể của cơ sở mã, trong khi các phần khác có ít hoặc không có báo cáo lỗi, dẫn đến mô hình định vị lỗi tập trung quá mức chỉ vào một phần của cơ sở mã. Trong bài báo này, chúng tôi điều tra các Câu hỏi Nghiên cứu (RQ) sau:

RQ1: (a) Tăng cường Dữ liệu có thể cải thiện hiệu suất truy xuất của định vị lỗi dựa trên DL không? (b) Tăng cường Dữ liệu tác động như thế nào đến hiệu suất của các phương pháp định vị lỗi dựa trên DL khác nhau?

Để hiểu liệu Tăng cường Dữ liệu có phải là một chiến lược có liên quan trong định vị lỗi dựa trên DL hay không, chúng tôi xác định ba mô hình dựa trên transformer gần đây để thực hiện tác vụ này. Chúng tôi đánh giá hiệu suất của các phương pháp định vị lỗi này, có và không có DA, sử dụng một tập dữ liệu định vị lỗi tiêu chuẩn và các chỉ số thường được sử dụng để đo lường hiệu suất truy xuất thông tin. Vì tăng cường nhất thiết đưa ra số lượng dữ liệu cao hơn đáng kể, chúng tôi thêm các baseline vào đánh giá nhằm phân biệt số lượng so với chất lượng của tập dữ liệu được tăng cường. Kết quả chỉ ra rằng (1) chiến lược tăng cường dữ liệu được đề xuất cải thiện độ chính xác truy xuất từ 39% đến 82%, (2) việc tăng cường tập dữ liệu có lợi hơn so với việc tăng kích thước của tập dữ liệu huấn luyện bằng lặp lại; và (3) việc cân bằng tập dữ liệu huấn luyện dẫn đến cải thiện hiệu suất truy xuất, nhưng mức độ cải thiện phụ thuộc vào kiến trúc của mô hình DL.

RQ2: Toán tử DA nào trong số các toán tử DA được đề xuất đóng góp nhiều nhất cho hiệu suất truy xuất?

Phương pháp Tăng cường Dữ liệu trong RQ1 dựa vào các toán tử tăng cường thực hiện các loại biến đổi cụ thể (ví dụ: chèn, xóa). Trong RQ2, chúng tôi nhằm hiểu tác động của các toán tử tăng cường này lên hiệu suất truy xuất trong quá trình định vị lỗi. Để trả lời RQ2, chúng tôi thực hiện các nghiên cứu ablation, huấn luyện mỗi mô hình DL với các tập dữ liệu được tăng cường được tạo ra bằng cách sử dụng tất cả trừ một loại toán tử tăng cường. Kết quả chỉ ra rằng hầu hết các toán tử đóng góp vào hiệu suất cuối cùng, trong khi một số toán tử nhất quán hơn trên các mô hình DL khác nhau.

2 TĂNG CƯỜNG DỮ LIỆU CHO ĐỊNH VỊ LỖI

Với sự phức tạp ngày càng tăng của các phương pháp dựa trên DL cho định vị lỗi [6,15,20,26], vấn đề khan hiếm dữ liệu nổi lên trước mắt. Cụ thể hơn, trong khi các mô hình tiên tiến hơn có tiềm năng thu hẹp khoảng cách từ vựng giữa một báo cáo lỗi và mã nguồn [1,64], để thực hiện lời hứa đó, chúng yêu cầu một lượng lớn báo cáo lỗi để học ngữ nghĩa của dự án và sau đó liên kết nó với các changeset gây ra lỗi. Số lượng ví dụ huấn luyện không đủ có thể dẫn đến overfitting mô hình, ghi nhớ các mẫu hoặc cấu trúc tần số cao thay vì tổng quát hóa kiến thức [45]. DA có thể giúp giải quyết vấn đề khan hiếm dữ liệu trong định vị lỗi bằng cách tập trung vào các mục tiêu sau.

1. Tăng số lượng báo cáo lỗi. Huấn luyện một mô hình DL cho định vị lỗi yêu cầu một tập dữ liệu đáng kể bao gồm các báo cáo lỗi và changeset gây ra lỗi. Thách thức chính trong việc xây dựng tập dữ liệu như vậy là nó cụ thể cho dự án. Hầu hết các dự án phần mềm thường có ít báo cáo lỗi với chỉ báo rõ ràng về các changeset gây ra chúng [30]. Hơn nữa, tổng số báo cáo lỗi trong một dự án là giới hạn trên của số lượng thực thể huấn luyện tích cực có sẵn. Lưu ý rằng trong khi chúng ta có thể tạo ra nhiều thực thể âm (tức là một báo cáo lỗi và một changeset không gây ra lỗi), lợi ích cho mô hình DL là hạn chế vì báo cáo lỗi vẫn giống nhau trong mỗi thực thể. Hơn nữa, trong tất cả các lỗi được báo cáo, một số được đóng với trạng thái Won't fix hoặc Not a Bug [24,59], do đó chúng không có changeset tương ứng và không thể được sử dụng để huấn luyện. Để xác minh thực nghiệm quy mô của vấn đề khan hiếm dữ liệu trong dữ liệu định vị lỗi, chúng tôi đã kiểm tra Bench4BL [27], một tập dữ liệu định vị lỗi lớn. Bench4BL bao gồm 10K báo cáo lỗi và các bản sửa của chúng đến từ 51 dự án phần mềm mã nguồn mở phổ biến và được phát triển tích cực, tương đương với khoảng 200 báo cáo lỗi mỗi dự án. Xem xét rằng các dự án trong tập dữ liệu Bench4BL thường lớn và được thiết lập tốt (ví dụ: các dự án Apache Software Foundation chạy lâu dài như Camel và Hive), 200 báo cáo lỗi là một con số thấp đáng lo khi nói đến khả năng huấn luyện một mô hình DL hiệu quả.

2. Duy trì tính bất biến nhãn của báo cáo lỗi. Trong NLP, tăng cường dữ liệu chủ yếu được đánh giá trên các tác vụ phân loại, chẳng hạn như phân tích cảm xúc hoặc phân loại chủ đề, trong đó hiếm khi một từ đơn lẻ có thể đại diện cho kết quả tổng thể (tức là một cảm xúc hoặc một chủ đề). Dữ liệu trong kỹ thuật phần mềm là sự pha trộn của ngôn ngữ tự nhiên và các đoạn liên quan đến mã. Trong trường hợp định vị lỗi, sự pha trộn này thường ảnh hưởng đến các báo cáo lỗi, thường chứa không chỉ mô tả ngôn ngữ tự nhiên mà còn đề cập đến các yếu tố chương trình có liên quan, stack trace hoặc đoạn mã [1]. Việc áp dụng các biến đổi tăng cường dữ liệu có sẵn cho dữ liệu định vị lỗi có thể gây hại nhiều hơn lợi vì nó không phân biệt giữa NL và mã, cả hai đều mang lại thông tin hữu ích, nhưng dưới các hình thức và số lượng khác nhau. Bảng 1 cho thấy các ví dụ về tăng cường văn bản được thực hiện trên tóm tắt của báo cáo lỗi #55996 từ dự án Tomcat sử dụng hai toán tử tăng cường được đề xuất bởi Wei et al. [57]. Random Swap trao đổi hai từ được chọn ngẫu nhiên, trong khi Synonym Replacement thay thế một từ được chọn ngẫu nhiên bằng từ đồng nghĩa của nó. Để tìm từ đồng nghĩa, chúng tôi sử dụng BERTOverflow [49], một mô hình BERT được tiền huấn luyện trên corpus StackOverflow. Do tính ngẫu nhiên của các hoạt động tăng cường dữ liệu, chúng ta thấy các phiên bản khác nhau của tóm tắt báo cáo lỗi được tăng cường. Trong khi Random Swap 1 hoán đổi hai từ mà không ảnh hưởng đến ngữ nghĩa, Random Swap 2 trao đổi các từ có thể chỉ ra thành phần mã có liên quan, nếu một dự án chứa các lớp AsyncContext và AsyncConnector. Tương tự, trong trường hợp Synonym Replacement 1, việc thay đổi context thành session ảnh hưởng đến ngữ nghĩa ít hơn so với việc thay thế Async bằng TCP, đây là các khái niệm khác nhau. Ví dụ đồ chơi này cho thấy việc tăng cường dữ liệu có sẵn có thể dễ dàng đưa ra nhiễu ảnh hưởng đến nhãn gốc như thế nào, đặc biệt khi xử lý dữ liệu chứa các cụm từ chính liên quan đến kỹ thuật phần mềm. Do đó, việc tăng cường dữ liệu kỹ thuật phần mềm nói chung, và các báo cáo lỗi nói riêng, yêu cầu các bước bổ sung để đảm bảo tính bất biến của các điểm dữ liệu mới được tạo ra.

3. Đa dạng hóa dữ liệu huấn luyện. Mục tiêu của đa dạng hóa dữ liệu trong DA là đảm bảo rằng dữ liệu được tăng cường đưa ra "chất lượng mới" cho một tập huấn luyện, chẳng hạn như các motif, mẫu hoặc biểu thức chưa từng quan sát trước đó, dẫn một mô hình DL học ý nghĩa đằng sau dữ liệu thay vì ghi nhớ một số hình thức nhất định [34,45]. Trong trường hợp định vị lỗi, tập dữ liệu huấn luyện mô tả cách ngôn ngữ tự nhiên mô tả một lỗi kết nối với các khái niệm mã nguồn trong changeset gây ra lỗi. Thông thường, ngôn ngữ tự nhiên trong các báo cáo lỗi bao gồm Hành vi Quan sát được (OB), Hành vi Mong đợi (EB), hoặc Các bước Tái tạo (S2R) [3]. Cho rằng OB, EB và S2R đã được các nhà phát triển nhận ra là thông tin hữu ích khi sửa lỗi [1], việc tăng cường cho dữ liệu định vị lỗi nên tập trung vào việc đưa ra sự đa dạng vào những thứ này thông qua, ví dụ, diễn đạt lại các câu của chúng. Thành phần quan trọng thứ hai của việc đa dạng hóa một tập huấn luyện định vị lỗi là các kết nối giữa báo cáo lỗi và mã nguồn. Mặc dù đúng là các lỗi không được phân bố đều trong cơ sở mã nguồn, việc đại diện quá mức một thành phần mã nguồn (ví dụ: lớp, gói) trong tập huấn luyện có thể dẫn đến mô hình đổ lỗi cho thành phần cụ thể đó cho mọi lỗi. Để tính đến điều đó, trong khi tăng cường tập huấn luyện cho định vị lỗi, các bước bổ sung có thể được thực hiện để giảm thiểu rủi ro đó, thông qua, ví dụ, tạo ra nhiều báo cáo lỗi được tăng cường hơn cho những thành phần mã nguồn xuất hiện ít thường xuyên hơn trong tập huấn luyện. Tóm lại, việc đa dạng hóa dữ liệu huấn luyện nên tập trung vào: (1) sửa đổi nội dung ngôn ngữ tự nhiên của một báo cáo lỗi, và (2) đa dạng hóa cách một báo cáo lỗi kết nối với mã nguồn.

3 PHƯƠNG PHÁP

Để tạo ra các báo cáo lỗi được tăng cường đưa ra sự đa dạng và bảo tồn tính bất biến (tức là báo cáo lỗi được tăng cường vẫn khớp với cùng một changeset như báo cáo lỗi gốc), chúng tôi đề xuất một tập hợp các toán tử DA tùy chỉnh. Các báo cáo lỗi mô tả sự cố phần mềm bằng cách sử dụng các loại thông tin khác nhau, chẳng hạn như ngôn ngữ tự nhiên, đoạn mã hoặc stack trace, có thể có tác động khác nhau đến việc khớp một báo cáo lỗi với changeset gây ra của nó, do đó chúng tôi quyết định tăng cường riêng biệt thông tin ngôn ngữ tự nhiên và thông tin liên quan đến mã để đảm bảo tính bất biến của các điểm dữ liệu mới được tạo ra và tránh đưa ra nhiễu. Hình 1 minh họa quy trình làm việc của quá trình tăng cường dữ liệu của chúng tôi bắt đầu với việc trích xuất và tiền xử lý dữ liệu, tiếp theo là tăng cường với các toán tử được đề xuất, và xây dựng các báo cáo lỗi được tăng cường kết hợp dữ liệu mới được tạo ra.

3.1 Tiền xử lý dữ liệu

Như một bước đầu tiên, chúng tôi sử dụng infozilla [39], một công cụ trích xuất stack trace và đoạn mã từ nội dung báo cáo lỗi không có cấu trúc, để lại văn bản còn lại được phân loại rộng rãi là ngôn ngữ tự nhiên. Infozilla tạo ra lỗi tối thiểu vì các thí nghiệm đã cho thấy nó có độ chính xác 97%+, recall 95%+ và accuracy 97%+. Để đưa ra cấu trúc sâu hơn từ dữ liệu ngôn ngữ tự nhiên, chúng tôi trích xuất Hành vi Quan sát được (OB), Hành vi Mong đợi (EB), và Các bước Tái tạo (S2R) bằng cách sử dụng công cụ BEE [48], đã được chứng minh là rất hiệu quả trong tác vụ này (accuracy 94%+, recall 87%+, precision 70%+).

Stack trace là một nguồn gợi ý định vị có giá trị, tuy nhiên, do độ dài của chúng, chúng có xu hướng đưa ra nhiễu thông qua việc đề cập nhiều lần các lớp không nhất thiết liên quan đến một báo cáo lỗi cụ thể [6,40]. Để giảm thiểu nhiễu trong stack trace, chúng tôi giảm kích thước của chúng bằng cách chọn các dòng có khả năng chứa thông tin có liên quan nhất. Ví dụ, đối với stack trace Java, điều này dẫn đến ba nhóm: 1) các dòng đầu, bao gồm tên exception và nơi exception bắt nguồn; 2) các dòng giữa, xuất hiện sau các trace thư viện chuẩn Java và có khả năng là các dòng cuối cùng của mã ứng dụng gần nhất với lỗi; và 3) các dòng dưới, có thể hữu ích cho các exception được ném từ các thread. Việc lấy mẫu từ ba nhóm này tạo ra một công thức chung rút ngắn stack trace, bắt được các thiết kế phần mềm khác nhau, và bảo tồn thông tin quan trọng. Do đó, đối với mỗi stack trace, chúng tôi quyết định giữ lại 1 dòng đầu, 3 dòng đầu tiên tham chiếu đến mã ứng dụng, và 1 dòng dưới. Các phương pháp heuristic như thế này đã được báo cáo là hoạt động khá tốt ngay cả trên dữ liệu runtime không có cấu trúc (ví dụ: nhật ký sự cố thô với nhiều stack trace, có thể từ các ngôn ngữ lập trình khác nhau) [38].

Để tiền xử lý đoạn mã, chúng tôi quyết định lọc bỏ dấu câu vì hai lý do. Đầu tiên, trong một nghiên cứu được công bố gần đây, Paltenghi et al. [36] so sánh lý luận của các nhà phát triển và mô hình neural, và quan sát rằng các mô hình chú ý nhiều hơn đến các token cú pháp (ví dụ: dấu chấm, dấu chấm, dấu ngoặc), trong khi các nhà phát triển tập trung nhiều hơn vào chuỗi hoặc từ khóa. Cho rằng các nhà phát triển hoạt động tốt hơn, các mô hình DL nên bắt chước các nhà phát triển và chú ý ít hơn đến các token cú pháp. Lý do thứ hai để lọc dấu câu là thực dụng - giảm số lượng token để tránh vượt quá giới hạn kích thước đầu vào của các mô hình DL. Sau tiền xử lý, mỗi báo cáo lỗi được đại diện như một tập hợp OB, EB, S2R, stack trace, và đoạn mã.

3.2 Toán tử DA ngôn ngữ tự nhiên

Nhóm toán tử này được áp dụng cho OB, EB, và S2R do nội dung ngôn ngữ tự nhiên chủ yếu của chúng. Chúng tôi đề xuất sử dụng hai loại toán tử: mức token và mức đoạn văn. Được truyền cảm hứng bởi một kỹ thuật đơn giản nhưng hiệu quả gọi là Easy Data Augmentation (EDA) [57], chúng tôi đề xuất sử dụng 4 toán tử mức token.

• Dictionary Replace - chọn ngẫu nhiên một từ từ một từ điển trong lĩnh vực được xác định trước và thay thế từ đó bằng từ thay thế của nó.
• Dictionary Insert - hoạt động tương tự như Dictionary Replace, tuy nhiên thay vì thay thế từ, toán tử này chèn từ thay thế vào một vị trí ngẫu nhiên trong văn bản.
• Random Swap - chọn ngẫu nhiên hai từ và hoán đổi chúng.
• Random Delete - xóa một từ được chọn ngẫu nhiên.

Để xây dựng từ điển trong lĩnh vực để tăng cường OB, EB và S2R, chúng tôi sử dụng từ khóa từ các mẫu ngôn ngữ được thiết kế bởi Chaparro et al. [4]. Các mẫu chỉ định sự kết hợp của các phần khác nhau của lời nói với các từ khóa nhất định phải xuất hiện để phân loại một câu hoặc một đoạn văn là OB, EB hoặc S2R. Ví dụ, một trong những mẫu OB phổ biến nhất là NEG_VERB được định nghĩa là: (chủ ngữ/cụm danh từ) ([tính từ/trạng từ]) [động từ phủ định] ([bổ ngữ]), trong đó các động từ phủ định được định nghĩa là: affect, break, block, close, v.v. Từ điển trong lĩnh vực chứa tất cả các từ khóa được xác định bởi Chapparo et al. và ánh xạ mỗi từ khóa với các từ thay thế của nó, ví dụ: affect→{break, block, close, ...}. Các toán tử được hướng dẫn bởi kiến thức lĩnh vực gần đây đã được chứng minh là dẫn đến hiệu suất tốt hơn so với các phương pháp tiên tiến hơn nhưng tổng quát (ví dụ: embeddings) [25].

Như một toán tử mức đoạn văn, chúng tôi sử dụng Backtranslation để dịch các đoạn văn OB, EB hoặc S2R từ tiếng Anh sang tiếng Đức và ngược lại sang tiếng Anh [32]. Backtranslation là một hoạt động tăng cường dữ liệu phổ biến cho phép diễn đạt lại văn bản gốc.

Cuối cùng, hãy để chúng tôi mô tả cách những toán tử này được áp dụng cùng nhau để tạo ra dữ liệu được tăng cường. Đối với mỗi báo cáo lỗi và cho mỗi OB, EB, S2R, chúng tôi áp dụng tất cả các toán tử mức token 𝑛 lần, trong đó 𝑛=𝜆∗#𝑡𝑜𝑘𝑒𝑛𝑠. Các toán tử được áp dụng theo thứ tự sau: replace, insert, swap và delete. Giá trị của 𝜆 được đặt thành 0.1 cho các hoạt động insert, replace, và swap, và 0.05 cho hoạt động delete vì những tham số này đã được chứng minh thực nghiệm là tạo ra kết quả tốt nhất [66]. Tiếp theo, toán tử Backtranslation được áp dụng để diễn đạt lại văn bản đã được sửa đổi. Do tính ngẫu nhiên của các toán tử tăng cường, chất lượng của mẫu được tăng cường có thể khác nhau. Mặc dù, nói chung, văn bản ngôn ngữ tự nhiên thường giữ nguyên ngữ nghĩa của nó khi nhiễu nhỏ được đưa vào, các báo cáo lỗi là loại dữ liệu có cấu trúc hơn với các từ khóa nhất định (ví dụ: tên mã), việc loại bỏ chúng có thể có hậu quả nghiêm trọng đối với việc ánh xạ báo cáo lỗi với mã nguồn. Do đó, như một bước cuối cùng, chúng tôi sử dụng kiểm soát chất lượng bao gồm hai bước. Đầu tiên, chúng tôi kiểm tra xem OB, EB và/hoặc S2R có thể vẫn được xác định trong đoạn văn được tăng cường bằng cách sử dụng công cụ BEE hay không. Ví dụ, nếu đoạn văn gốc chứa OB và EB, thì phiên bản được tăng cường phải chứa OB và EB mới được coi là một đoạn văn hợp lệ. Chúng tôi cũng không cho phép thay đổi mẫu (ví dụ: từ OB thành EB). Thứ hai, chúng tôi đảm bảo rằng không có token mã nào bị mất trong quá trình tăng cường bằng cách so sánh số lượng token mã giữa đoạn văn được tăng cường và đoạn văn gốc.

3.3 Toán tử DA liên quan đến mã

Trong bối cảnh của bài báo này, dữ liệu liên quan đến mã đề cập đến stack trace, đoạn mã, và các token mã có mặt trong văn bản ngôn ngữ tự nhiên. Để tăng cường dữ liệu liên quan đến mã, chúng tôi đề xuất 3 toán tử token mã là các phiên bản nghiêm ngặt hơn của các toán tử ngôn ngữ tự nhiên để giảm thiểu rủi ro làm méo mó ngữ cảnh.

• Code Token Replace - chọn ngẫu nhiên một token mã và thay thế nó bằng từ thay thế của nó.
• Code Token Insert - chọn ngẫu nhiên một token mã, và chèn một từ thay thế của token mã đó vào một vị trí ngẫu nhiên cách tối đa 3 vị trí từ token mã được chọn.
• Code Token Swap - hoán đổi hai token mã được chọn ngẫu nhiên, sao cho (1) đối với stack trace, các token mã chỉ có thể được hoán đổi giữa các dòng stack liên tiếp; (2) đối với đoạn mã, một hoạt động hoán đổi phải được thực hiện trong vòng 3 token xung quanh để giảm thiểu khả năng làm méo mó ngữ nghĩa của báo cáo lỗi. Thay đổi điều này thành một giới hạn lớn hơn sẽ dẫn đến việc tạo ra nhiều mẫu đa dạng hơn, tuy nhiên, với khả năng cao hơn làm xáo trộn ngữ nghĩa của báo cáo lỗi.

Chúng tôi quyết định không bao gồm một toán tử xóa token mã vì việc loại bỏ token mã có khả năng cao hơn làm xáo trộn tính bất biến của các mẫu được tăng cường.

Để tìm từ thay thế cho một token mã, đầu tiên, đối với mỗi báo cáo lỗi, chúng tôi xây dựng một từ điển tên mã sử dụng tên lớp và phương thức xuất hiện trong các changeset gây ra lỗi tương ứng của nó. Tiếp theo, chúng tôi sử dụng khoảng cách Levenshtein để đo khoảng cách giữa token mã được chọn và tất cả các token khác trong từ điển. Khoảng cách Levenshtein là một chỉ số tương tự chuỗi định lượng tương tự thông qua số lần chỉnh sửa cần thiết để chuyển đổi một chuỗi thành chuỗi khác cho các chuỗi có độ dài tùy ý. Chúng tôi quan sát thực nghiệm rằng các token mã tương tự nhất thường có cùng dạng, và do đó, có thể đưa ra sự đa dạng rất hạn chế vào các mẫu được tăng cường. Ví dụ, xem xét token mã word với các token gần nhất top-3 là is_word, set_word, get_word, và token top-20 check_word_missing_letter. Để cho phép tăng cường đa dạng hơn, dựa trên các quan sát thực nghiệm cho một trong các dự án đánh giá, chúng tôi đã chọn một lựa chọn top-𝑘 ít bảo thủ hơn, với 𝑘 được đặt thành 20. Do đó, một từ thay thế token mã được chọn ngẫu nhiên từ 20 token mã có khoảng cách Levenshtein thấp nhất từ token mã đã cho.

3.4 Xây dựng báo cáo lỗi được tăng cường

Sau khi tăng cường, mỗi báo cáo lỗi được phân tách thành một tập hợp các mẫu gốc và được tăng cường, tức là dữ liệu ngôn ngữ tự nhiên (OB, EB, S2R), và dữ liệu liên quan đến mã (stack trace và đoạn mã). Câu hỏi còn lại là làm thế nào để xây dựng một báo cáo lỗi tổng hợp từ tất cả các mẫu có sẵn. Công việc gần đây trong dịch máy neural đã cho thấy rằng việc nối các mẫu được tăng cường đưa ra sự đa dạng cấu trúc ngăn chặn một mô hình DL học tập trung chỉ vào một phần của đầu vào, do đó dẫn đến một cải thiện mạnh mẽ trong hiệu suất của mô hình [34,61]. Chúng tôi đề xuất sử dụng một phương pháp tương tự để xây dựng các báo cáo lỗi được tăng cường. Cụ thể hơn, đầu tiên chúng tôi tái tạo cấu trúc gốc của một báo cáo lỗi bằng cách nối các mẫu được tăng cường. Tiếp theo, các mẫu được sắp xếp lại và tối đa 1 mẫu có thể được bỏ để đạt được sự đa dạng cấu trúc hơn nữa. Mặc dù việc bỏ các phần của báo cáo lỗi có thể có vẻ phản trực quan, các chiến lược DA loại bỏ token hoặc câu đã được quan sát có tác động tích cực đến các mô hình DL lớn được tiền huấn luyện [5,44]. Hình 2 cho thấy báo cáo lỗi #55171 từ dự án Tomcat và phiên bản được tăng cường của nó. Mỗi phần của báo cáo lỗi đã được tăng cường riêng biệt bằng cách sử dụng tất cả các toán tử DA tương ứng của nó. Trong trường hợp ngôn ngữ tự nhiên, chúng ta thấy các lần chèn và thay thế đúng về mặt ngữ nghĩa (ví dụ: blocked→dead), trong khi việc diễn đạt lại đoạn văn được thực hiện bởi Backtranslation ít chính xác hơn nhưng vẫn truyền đạt thông điệp chính (ví dụ: OB thứ hai trong hình). Tăng cường mã cho báo cáo lỗi này bao gồm việc tăng cường stack trace và token mã với tên mã từ changeset gây ra lỗi. Mặc dù phương pháp như vậy vốn hạn chế khả năng thêm nhiễu, nó cũng đưa ra thông tin về các thành phần mã liên quan đến báo cáo lỗi. Điều này, đến lượt nó, cho phép mô hình học các mối quan hệ này và sử dụng chúng trong quá trình suy luận. Cuối cùng, khi xây dựng báo cáo lỗi được tăng cường, OB thứ hai và stack trace đã được hoán đổi, trong khi OB thứ ba đã được bỏ, tạo ra phiên bản được tăng cường cuối cùng của báo cáo lỗi #55171.

3.5 Đảm bảo một tập dữ liệu được tăng cường cân bằng

Để tăng kích thước của tập huấn luyện định vị lỗi với tăng cường dữ liệu, phương pháp của chúng tôi là tập trung vào việc tăng cường các báo cáo lỗi, tăng số lượng cặp báo cáo lỗi và các hunk gây ra lỗi. Các nghiên cứu gần đây cho thấy rằng việc sử dụng hunk, một tập hợp các sửa đổi dòng liên tiếp nắm bắt các thay đổi trong một khu vực của tệp, tạo ra kết quả truy xuất được cải thiện so với việc sử dụng toàn bộ changeset [6,58]. Do đó, trong công trình này, chúng tôi xây dựng tập huấn luyện định vị lỗi sử dụng các cặp báo cáo lỗi và hunk được trích xuất từ các changeset gây ra lỗi.

Các lỗi ảnh hưởng đến các phần khác nhau của cơ sở mã nguồn với tần suất khác nhau [2]. Nói cách khác, các phần của mã nguồn (tức là các tệp hoặc lớp cụ thể) liên quan đến nhiều báo cáo lỗi và do đó các hunk của chúng cũng có thể được đại diện quá mức trong tập dữ liệu gốc. Ví dụ, cho một báo cáo lỗi với 𝑛 hunk giới thiệu, tăng cường dữ liệu theo hệ số 10 tạo ra 10 báo cáo lỗi mới cho mỗi hunk, dẫn đến 10𝑛 mẫu huấn luyện mới. Tuy nhiên, có một nhược điểm chính đối với phương pháp DA này. Sự mất cân bằng dữ liệu này, được tạo ra bởi sự phân bố không đều của các báo cáo lỗi và hunk trong tập huấn luyện, có thể bị DA làm trầm trọng thêm, với những tác động mạnh mẽ xuôi dòng đến mô hình DL và dự đoán của nó.

Để cung cấp bằng chứng sâu hơn, chúng tôi đã kiểm tra thực nghiệm tập dữ liệu được công bố bởi Wen et al. [58], mà chúng tôi sử dụng trong nghiên cứu của mình. Hình 3 cho thấy sự phân bố của các báo cáo lỗi (Hình 3a) và sự xuất hiện của lớp (Hình 3b) cho dự án Tomcat. Các phân bố cho thấy có bao nhiêu mẫu trong tập dữ liệu huấn luyện tham chiếu đến một báo cáo lỗi cụ thể (hoặc một lớp), trong đó một báo cáo lỗi (hoặc một lớp) có nhiều lần xuất hiện bằng số lượng hunk. Chúng tôi hiển thị các phân bố này cho ba lựa chọn khác nhau của tập dữ liệu huấn luyện: tập dữ liệu gốc không được tăng cường, một tập dữ liệu được tăng cường 10x, và một tập dữ liệu được cân bằng nhân tạo. Trong các biểu đồ, có các phiên bản được phóng to để tăng khả năng đọc ở quy mô nhỏ hơn. Trong biểu đồ cho tập huấn luyện gốc (tức là đường màu xanh lam), chúng tôi quan sát rằng 11 trong số 97 báo cáo lỗi bao phủ hơn 50% (1432 trong số 2812) các mẫu huấn luyện. Nói cách khác, 50% các mẫu trong tập huấn luyện tham chiếu đến 11 báo cáo lỗi, vì những báo cáo lỗi này có nhiều hunk giới thiệu, điều này dịch thành nhiều mục trong tập huấn luyện. Đồng thời, 39 báo cáo lỗi xuất hiện ít hơn 10 lần. Tương tự, trong số 110 lớp duy nhất đã giới thiệu một lỗi, 10 lớp hàng đầu với các hunk xuất hiện thường xuyên nhất bao phủ 34.5% (2586 trong số 7478) tất cả dữ liệu huấn luyện. Sự mất cân bằng này trong dữ liệu huấn luyện có thể có hai hậu quả tiềm ẩn đối với việc huấn luyện có giám sát của một mô hình DL. Đầu tiên, mô hình có nhiều khả năng học cấu trúc và ngữ nghĩa của các báo cáo lỗi có số lượng lớn các hunk gây ra lỗi, trong khi bỏ qua các báo cáo lỗi ít thường xuyên hơn. Thứ hai, các lớp xuất hiện nhiều nhất trong tập huấn luyện có nhiều khả năng được chọn làm gây ra lỗi bởi mô hình được huấn luyện vì chúng thường được thấy trong quá trình huấn luyện như là gây ra lỗi. Vấn đề mất cân bằng dữ liệu cũng đã được nhận ra trong các tập dữ liệu dự đoán khiếm khuyết [65].

Cách mà tăng cường làm trầm trọng thêm vấn đề phân bố dữ liệu không đều có thể được quan sát trong Hình 3, nơi đường chấm màu cam mô tả các phân bố dữ liệu trong một tập dữ liệu được tăng cường theo hệ số 10. Các báo cáo lỗi và lớp chiếm đa số trở nên thậm chí còn thống trị hơn trong tập dữ liệu được tăng cường, làm cho vấn đề mất cân bằng dữ liệu nghiêm trọng hơn so với tập dữ liệu gốc. Để giảm thiểu vấn đề này, chúng tôi đề xuất một chiến lược cân bằng dữ liệu có chủ ý chọn các mẫu để tăng cường nhằm làm mịn các phân bố của các báo cáo lỗi đối với mã nguồn. Có hai mối quan tâm chính mà một chiến lược cân bằng dữ liệu phải xem xét: (1) tăng số lượng mẫu huấn luyện cho các báo cáo lỗi không thường xuyên, và (2) đảm bảo rằng số lượng mẫu với một lớp nhất định không thống trị tập dữ liệu. Để minh họa nhu cầu cho những chiến lược này, hãy xem xét một báo cáo lỗi 𝐵1 với 20 hunk từ các lớp khác nhau, và một báo cáo lỗi 𝐵2 với một hunk từ lớp 𝐶. Nếu chiến lược cân bằng chỉ tập trung vào sự phân bố của các báo cáo lỗi, thì nó tạo ra 20 mẫu được tăng cường cho 𝐵2, mỗi lần sử dụng hunk từ lớp 𝐶, do đó 𝐶 có khả năng được đại diện quá mức trong tập huấn luyện. Để giải quyết điều này, chúng tôi đưa ra hai yếu tố tăng cường 𝛼 và 𝜔. Trong khi 𝛼 ảnh hưởng đến số lần mỗi báo cáo lỗi được tăng cường, 𝜔 hạn chế số lần mỗi lớp có thể được lặp lại trong tập dữ liệu được tăng cường.

Thuật toán 1: Cân bằng dữ liệu với các báo cáo lỗi được tăng cường
Đầu vào: 𝐷𝑡𝑟𝑎𝑖𝑛 – tập dữ liệu huấn luyện;
𝛼– yếu tố tăng cường;
𝜔– yếu tố cân bằng
Đầu ra: 𝐷𝑏𝑙– tập dữ liệu huấn luyện cân bằng
1 𝑚𝑎𝑥 𝑏𝑟←𝛼×max. # báo cáo lỗi trong 𝐷𝑡𝑟𝑎𝑖𝑛
2 𝑚𝑎𝑥 𝑐𝑙←𝜔×max. # lớp trong 𝐷𝑡𝑟𝑎𝑖𝑛
3 𝐷𝑏𝑙←𝐷𝑡𝑟𝑎𝑖𝑛
4 for 𝑏𝑟,𝐻𝑏𝑟 in 𝐷𝑡𝑟𝑎𝑖𝑛 do
5 while (số lượng của 𝑏𝑟 trong 𝐷𝑏𝑎𝑙)<𝑚𝑎𝑥 𝑏𝑟 do
6 𝑏𝑟𝑎←tăng cường 𝑏𝑟
7 ℎ𝑎←chọn hunk ℎ𝑎 từ 𝐻𝑏𝑟, trong đó
8 (số lượng của lớp cho ℎ𝑎 trong 𝐷𝑏𝑎𝑙)<𝑚𝑎𝑥 𝑐𝑙
9 Thêm 𝑏𝑟𝑎,ℎ𝑎 vào 𝐷𝑏𝑙
10 end while
11 end for
12 return 𝐷𝑏𝑙

Chuỗi các bước cho chiến lược tăng cường cân bằng dữ liệu được đề xuất được trình bày trong Thuật toán 1. Trong dòng 1-2, chúng tôi tính toán một giới hạn cho các báo cáo lỗi 𝑚𝑎𝑥𝑏𝑟 và lớp 𝑚𝑎𝑥𝑐𝑙 dựa trên các yếu tố 𝛼 và 𝜔 và số lượng tối đa lần một báo cáo lỗi và lớp duy nhất có mặt trong tập dữ liệu huấn luyện gốc. Dòng 3 sao chép các thực thể dữ liệu hiện có vào tập dữ liệu cân bằng 𝐷𝑏𝑙. Đối với mỗi báo cáo lỗi xuất hiện dưới giới hạn 𝑚𝑎𝑥𝑏𝑟, thuật toán tăng cường báo cáo lỗi (dòng 6), và chọn một hunk gây ra lỗi từ một lớp xuất hiện ít hơn 𝑚𝑎𝑥𝑐𝑙 lần trong 𝐷𝑏𝑙 (dòng 7-8), tạo ra một mẫu huấn luyện mới. Thuật toán tiếp tục thêm các mẫu mới cho một báo cáo lỗi cho đến khi (1) giới hạn 𝑚𝑎𝑥𝑏𝑟 được đạt tới, hoặc (2) các hunk gây ra lỗi từ tất cả các lớp đã đạt tới 𝑚𝑎𝑥𝑐𝑙. Kết quả của chiến lược cân bằng này được mô tả trong đường màu xanh lá cây trong Hình 3, sử dụng các giá trị 𝛼=0.7 và 𝜔=1.0. So với tập dữ liệu được tăng cường, phân bố dữ liệu của tập dữ liệu cân bằng rõ ràng mượt mà hơn, với sự đại diện đều đặn hơn nhiều của mã nguồn.

4 ĐÁNH GIÁ THỰC NGHIỆM

4.1 Tập dữ liệu và chỉ số

Để đánh giá, chúng tôi yêu cầu một tập dữ liệu chứa các báo cáo lỗi và changeset gây ra lỗi. Chúng tôi sử dụng một tập dữ liệu được công bố bởi Wen et al. [58] chứa dữ liệu được xác thực thủ công từ 6 dự án phần mềm mã nguồn mở: AspectJ, JDT, PDE, SWT, Tomcat, và ZXing. Cho rằng infozilla yêu cầu dòng mới để trích xuất đoạn mã và stack trace, và dòng mới đã được loại bỏ khỏi tất cả các báo cáo lỗi trong tập dữ liệu của Wen et al., chúng tôi đã định vị và cạo lại các báo cáo lỗi (với dòng mới) từ Bugzilla cho tất cả các dự án. Đối với ZXing, các báo cáo lỗi trong GitHub issue tracker không khớp với những báo cáo được thu thập bởi Wen et al., có khả năng do dự án đã được chuyển, và do đó ZXing đã được loại khỏi tập đánh giá. Để tạo ra một tập huấn luyện cho mỗi dự án, chúng tôi sắp xếp các báo cáo lỗi theo ngày mở và chọn nửa đầu để huấn luyện, trong khi các báo cáo lỗi còn lại tạo thành tập kiểm tra. Mỗi mẫu huấn luyện tích cực tương ứng với một cặp báo cáo lỗi và một trong các hunk gây ra của nó (được trích xuất từ changeset gây ra). Mỗi báo cáo lỗi bao gồm tóm tắt lỗi và mô tả, trong khi mỗi hunk chứa thông điệp nhật ký và thay đổi mã nguồn. Tập dữ liệu của Wen et al. được xây dựng bằng SZZ [46], xác định một changeset là gây ra lỗi nếu nó chia sẻ bất kỳ sửa đổi tệp nào với changeset sửa lỗi. Mặc dù một changeset gây ra lỗi có thể bao gồm sửa đổi của nhiều tệp, chỉ một vài trong số đó có thể liên quan đến một lỗi (như được chỉ báo bởi changeset sửa lỗi). Do đó, để đảm bảo chất lượng của các mẫu huấn luyện, chúng tôi chỉ bao gồm các hunk gây ra lỗi tham chiếu đến các lớp cũng xuất hiện trong commit sửa lỗi. Đối với mỗi mẫu tích cực, chúng tôi tạo ra một mẫu tiêu cực bằng cách chọn ngẫu nhiên một hunk từ một lớp không thuộc changeset gây ra. Sau khi hoàn thành bước này, đối với mỗi dự án chúng tôi thu được tập dữ liệu baseline của mình, 𝐷𝑜𝑟𝑖. Thống kê mô tả của các tập dữ liệu huấn luyện và kiểm tra được sử dụng trong nghiên cứu này được hiển thị trong Bảng 2. Lưu ý rằng cột cuối, # hunk, biểu thị số lượng tất cả các hunk được kiểm tra bởi mô hình trong quá trình truy xuất.

Để đánh giá hiệu suất truy xuất của các mô hình DL được huấn luyện trên các tập dữ liệu khác nhau, chúng tôi sử dụng các chỉ số sau.

Mean Reciprocal Rank: MRR đo độ chính xác truy xuất bằng cách sử dụng nghịch đảo của thứ hạng của changeset có liên quan đầu tiên trong thứ hạng được tính trung bình trên tất cả các báo cáo lỗi. Giá trị MRR càng cao, changeset gây ra lỗi càng gần đầu bảng xếp hạng.
𝑀𝑅𝑅 =1|𝐵|∑︁|𝐵|𝑖=1 1/1𝑠𝑡𝑅𝑎𝑛𝑘𝐵𝑖.

Mean Average Precision: MAP định lượng khả năng của một mô hình truy xuất tất cả các changeset có liên quan cho một báo cáo lỗi nhất định. MAP được tính như trung bình của điểm Average Precision trên tất cả các báo cáo lỗi, trong đó Average Precision cho một báo cáo lỗi dựa trên thứ hạng của tất cả các changeset có liên quan trong bảng xếp hạng. Giá trị MAP càng cao, càng nhiều changeset có liên quan được định vị ở đầu bảng xếp hạng.
𝑀𝐴𝑃 =1|𝐵|∑︁|𝐵|𝑖=1 1/𝐴𝑣𝑔𝑃𝐵𝑖.

Precision@K: P@K đo có bao nhiêu changeset top-𝐾 trong bảng xếp hạng có liên quan đến một báo cáo lỗi. Giá trị P@K càng cao, càng nhiều changeset có liên quan có thể được tìm thấy ở vị trí top-𝐾.
𝑃@𝑛=1|𝐵|∑︁|𝐵|𝑖=1 |𝑅𝑒𝑙𝐵𝑖|/𝐾.

4.2 Mô hình DL

Để đánh giá tác động của các chiến lược tăng cường dữ liệu và cân bằng được đề xuất lên hiệu suất truy xuất, chúng tôi huấn luyện và đánh giá ba kiến trúc truy xuất mã dựa trên BERT [10].

TBERT-Single [9,29,35] là phương pháp đơn giản nhất cho truy xuất thông tin với BERT. Mô hình nối một báo cáo lỗi và một hunk, và xử lý nó thông qua BERT và một lớp pooling để thu được một biểu diễn vector hợp nhất, sau đó được chuyển đến đầu phân loại để thu được điểm liên quan. Mặc dù mô hình này thường cung cấp độ chính xác truy xuất cao, nó cũng phát sinh độ trễ truy xuất đáng kể, vì một báo cáo lỗi cần được so sánh với tất cả các hunk có sẵn trong một dự án.

TBERT-Siamese [29,41] xử lý một báo cáo lỗi và một hunk tuần tự thông qua BERT và một lớp pooling, tạo ra hai vector đặc trưng, sau đó được nối và chuyển đến lớp phân loại để tạo ra điểm liên quan. Sự khác biệt chính giữa TBERT-Single và TBERT-Siamese là trong cơ hội thực hiện mã hóa ngoại tuyến của vector đặc trưng cho các hunk, do đó giảm độ trễ truy xuất.

FBL-BERT [6,22] là một kiến trúc dựa trên BERT được đề xuất gần đây cho phép truy xuất nhanh chóng trên tập hợp lớn các tài liệu (tức là các hunk). Không giống như TBERT, làm phẳng ma trận embedding thành một vector để đưa ra dự đoán, FBL-BERT tận dụng toàn bộ ma trận embedding và tính điểm liên quan giữa một báo cáo lỗi và một hunk như tổng của các độ tương tự vector tối đa giữa các embedding từ của báo cáo lỗi và hunk. Điều này, đến lượt nó, cho phép sử dụng các thuật toán tìm kiếm tương tự vector hiệu quả để tìm các hunk tương tự nhất và chỉ xếp hạng lại những hunk đó với FBL-BERT, do đó giảm đáng kể thời gian truy xuất mỗi báo cáo lỗi. Cho rằng FBL-BERT tận dụng khớp embedding token-to-token tinh vi, mô hình có nhiều khả năng sử dụng tốt hơn các từ khóa có liên quan nếu chúng xuất hiện trong báo cáo lỗi.

Mặc dù tất cả các mô hình đều dựa trên BERT, kiến trúc của chúng khác nhau ở một vài khía cạnh. TBERT-Single nối một báo cáo lỗi và một changeset, xử lý chúng cùng nhau thông qua BERT, theo sau là một lớp phân loại. TBERT-Siamese và FBL-BERT đầu tiên sử dụng BERT để mã hóa một báo cáo lỗi và một changeset riêng biệt, dẫn đến hai ma trận embedding. Sự khác biệt chính giữa TBERT-Siamese và FBL-BERT là cách chúng xử lý những ma trận này. TBERT-Siamese tổng hợp mỗi ma trận thành một vector bằng cách sử dụng một hoạt động pooling, và tiếp theo, so sánh vector embedding của một báo cáo lỗi với vector embedding changeset. Mặt khác, FBL-BERT sử dụng cả hai ma trận để tính điểm liên quan có tính đến embedding của mỗi từ.

4.3 Thiết lập đánh giá

Chúng tôi thực hiện các thí nghiệm trên một máy chủ với Dual 12-core 3.2GHz Intel Xeon và 1 NVIDIA Tesla V100 với bộ nhớ RAM 32GB chạy CUDA v.11.4. Các mô hình được thực hiện với PyTorch v.1.7.1, thư viện HuggingFace v.4.3.2, và Faiss v.1.6.5 với hỗ trợ GPU. Chúng tôi đã chọn sử dụng BERTOverflow [49] làm mô hình BERT cơ sở được tiền huấn luyện của chúng tôi, vì tương tự như dữ liệu của chúng tôi, dữ liệu StackOverflow cũng là sự pha trộn của mã và ngôn ngữ tự nhiên. Tất cả các mô hình được tinh chỉnh trong 4 epoch, sử dụng kích thước batch là 16 và bộ tối ưu hóa Adam (viết tắt từ adaptive moment estimation) [23] với tốc độ học được đặt thành 3e-6 [10]. Dựa trên số lượng token trung bình trong các báo cáo lỗi và hunk trong tập dữ liệu của chúng tôi, chúng tôi đặt giới hạn kích thước đầu vào thành 256 và 512 token cho báo cáo lỗi và hunk tương ứng. Tất cả các tài liệu đầu vào được đệm hoặc cắt ngắn đối với giới hạn kích thước đầu vào của chúng.

5 KẾT QUẢ

5.1 RQ1: (a) Tăng cường Dữ liệu có thể cải thiện hiệu suất truy xuất của định vị lỗi dựa trên DL không? (b) Tăng cường Dữ liệu tác động như thế nào đến hiệu suất của các phương pháp định vị lỗi dựa trên DL khác nhau?

Thiết lập. Để đánh giá tác động của DA đối với các mô hình dựa trên DL, chúng tôi so sánh độ chính xác truy xuất khi huấn luyện trên tập dữ liệu gốc, không được tăng cường, 𝐷𝑜𝑟𝑖, với việc huấn luyện với dữ liệu được tăng cường và cân bằng. Cụ thể hơn, đối với mỗi dự án chúng tôi xây dựng năm tập dữ liệu được tăng cường được hiển thị trong Bảng 3. 𝐷𝑎𝑢𝑔 là một tập dữ liệu được tăng cường, nhưng không cân bằng, chứa 10 mẫu bổ sung cho mỗi cặp báo cáo lỗi và hunk, trong khi 𝐷𝑏𝑙𝑖, 𝑖=1,2,3,4, là các tập dữ liệu cân bằng với các lựa chọn khác nhau cho (𝛼,𝜔) = {(0.7,1.0);(0.85,2.0);(1.0,2.0); (1.3,2.0)} tương ứng. Lý do cho những giá trị cụ thể này của 𝛼 và 𝜔 là để khám phá 𝛼 (trong các phạm vi không tạo ra nhiều dữ liệu hơn chúng ta có thể quản lý về mặt tính toán), trong khi chọn các giá trị cho 𝜔 không hạn chế hiệu ứng của 𝛼. Cho rằng tăng cường tăng số lượng mẫu tích cực, số lượng mẫu tiêu cực tăng tương ứng (tức là đối với mỗi mẫu tích cực, chúng tôi tạo ngẫu nhiên một mẫu tiêu cực). Để đảm bảo rằng sự khác biệt về hiệu suất thực sự là kết quả của DA, chứ không phải sự đa dạng được đưa ra bởi các mẫu tiêu cực mới, chúng tôi đã tạo ra một baseline bổ sung, 𝐷𝑟𝑒𝑝, lặp lại các mẫu tích cực mà không tăng cường 10 lần, và tương ứng, cũng thêm 10 mẫu tiêu cực mới. Thực tế, sự khác biệt duy nhất giữa 𝐷𝑟𝑒𝑝 và 𝐷𝑎𝑢𝑔 là thực tế rằng 𝐷𝑎𝑢𝑔 sử dụng các báo cáo lỗi được tăng cường trong khi 𝐷𝑟𝑒𝑝 lặp lại các mẫu tích cực. Tất cả các mô hình được đánh giá trên cùng một tập kiểm tra (không được tăng cường). Vì TBERT-Single yêu cầu thời gian đáng kể hơn so với các mô hình khác (ví dụ: TBERT-Single mất hơn 24 giờ để chạy trên dự án JDT), chúng tôi chỉ đánh giá nó trên một trong các tập dữ liệu cân bằng - 𝐷𝑏𝑙1- vì nó thể hiện hiệu suất tốt nhất cho TBERT-Siamese, sử dụng kiến trúc DL tương đối tương tự với TBERT-Single.

Để đánh giá ý nghĩa thống kê của sự khác biệt về hiệu suất khi huấn luyện các mô hình DL có và không có tăng cường dữ liệu, chúng tôi sử dụng kiểm định t ghép cặp của Student để tính các giá trị 𝑝 giữa các chỉ số hiệu suất của 𝐷𝑜𝑟𝑖 và tất cả các tập dữ liệu khác (tức là 𝐷𝑟𝑒𝑝, 𝐷𝑎𝑢𝑔, 𝐷𝑏𝑙∗) [47,52]. Kiểm định giả định các giá trị hiệu suất được phân phối bình thường. Chúng tôi xem xét 𝑝<0.05 là có ý nghĩa thống kê.

Kết quả. Bảng 4 cho thấy hiệu suất truy xuất của FBL-BERT, TBERT-Siamese và TBERT-Single được huấn luyện trên bốn tập dữ liệu: 𝐷𝑜𝑟𝑖, 𝐷𝑟𝑒𝑝, 𝐷𝑎𝑢𝑔 và 𝐷𝑏𝑙∗, trong đó 𝐷𝑏𝑙∗ biểu thị tập dữ liệu cân bằng có hiệu suất tốt nhất trung bình cho mô hình đã cho. Phần trên của bảng cho thấy kết quả trên các báo cáo lỗi từ tất cả các dự án, tiếp theo là kết quả theo dự án. Nói chung, chúng tôi quan sát rằng các mô hình cải thiện trên tất cả các chỉ số so với 𝐷𝑜𝑟𝑖, với cải thiện thấp nhất được ghi nhận cho 𝐷𝑟𝑒𝑝, tiếp theo là 𝐷𝑎𝑢𝑔, và với cải thiện cao nhất được ghi lại cho 𝐷𝑏𝑙∗.

Tùy thuộc vào mô hình, quy mô của sự cải thiện khác nhau. Trong khi điểm MRR cho FBL-BERT tăng từ 0.264 cho 𝐷𝑜𝑟𝑖 lên 0.367 cho 𝐷𝑏𝑙∗, khoảng một nửa sự cải thiện có thể được quy cho kích thước tập dữ liệu như được chỉ ra bởi kết quả cho 𝐷𝑟𝑒𝑝 với điểm MRR là 0.307. Hơn nữa, chúng tôi cũng quan sát rằng 𝐷𝑎𝑢𝑔 cải thiện điểm từ 0.307 cho 𝐷𝑟𝑒𝑝 lên 0.353, chỉ ra rằng việc sử dụng một tập dữ liệu được tăng cường tạo ra sự khác biệt không chỉ thông qua số lượng dữ liệu. Sự cải thiện giữa 𝐷𝑎𝑢𝑔 và 𝐷𝑏𝑙∗ là biên và bằng 0.014, chỉ ra rằng ngay cả cấu hình cân bằng tốt nhất có tác động nhỏ đối với FBL-BERT nói chung.

Huấn luyện với một tập dữ liệu cân bằng có tác động lớn hơn đối với TBERT-Single và TBERT-Siamese với sự cải thiện 0.035 và 0.092 trong điểm MRR tương ứng khi so sánh với 𝐷𝑎𝑢𝑔. Hơn nữa, cân bằng dữ liệu là đóng góp chính cho sự cải thiện trong TBERT-Siamese mà sự khác biệt có ý nghĩa thống kê chỉ được quan sát cho 𝐷𝑏𝑙∗. Trong trường hợp TBERT-Single, huấn luyện mô hình với cả 𝐷𝑎𝑢𝑔 và 𝐷𝑏𝑙∗ dẫn đến cải thiện đáng kể trên tất cả các chỉ số.

RQ1 (a): Tăng cường dữ liệu cải thiện kết quả định vị lỗi dựa trên DL trên tất cả các mô hình. Việc sử dụng cân bằng dữ liệu với tăng cường có thể cải thiện hiệu suất hơn nữa.

Bảng 5 cho thấy độ chính xác truy xuất cho FBL-BERT và TBERT-Siamese khi các mô hình được huấn luyện trên các tập dữ liệu cân bằng khác nhau, với các giá trị của 𝛼, 𝜔 và kích thước tập dữ liệu được cung cấp ở phía bên phải của bảng. Trong trường hợp FBL-BERT, 𝐷𝑏𝑙2 và 𝐷𝑏𝑙3 cung cấp hiệu suất tốt nhất trung bình, cải thiện MRR và MAP lần lượt 16.8% và 14.8% so với 𝐷𝑏𝑙1 và 𝐷𝑏𝑙4. Tuy nhiên, như đã lưu ý trước đó, sự cải thiện so với tập dữ liệu không cân bằng 𝐷𝑎𝑢𝑔 là biên. Trong trường hợp TBERT-Siamese, tập dữ liệu cân bằng nhỏ nhất, 𝐷𝑏𝑙1, tạo ra điểm MRR cao nhất là 0.328 vượt trội hơn tập dữ liệu cân bằng khác ít nhất 49%.

Sự khác biệt trong hiệu suất của các mô hình với các tập dữ liệu khác nhau có thể được quy cho (1) sự khác biệt tổng thể trong kiến trúc của các mô hình ảnh hưởng đến nhu cầu dữ liệu huấn luyện của mô hình; và (2) kích thước của mỗi dự án được đo bằng số lượng hunk (xem Bảng 2). Để hiểu rõ hơn liệu và khi nào mô hình có thể yêu cầu nhiều dữ liệu hơn, trong Hình 4 chúng tôi hiển thị điểm MRR trên tất cả các dự án đánh giá được sắp xếp theo kích thước của chúng, tức là số lượng hunk trong một dự án.

RQ1 (b): Kết quả chỉ ra rằng các kiến trúc mô hình khác nhau có thể có nhu cầu khác nhau về kích thước tập dữ liệu huấn luyện để đạt được hiệu suất tối ưu của chúng. Một số mô hình được hưởng lợi từ nhiều mẫu được tăng cường hơn, đặc biệt đối với các dự án lớn hơn.

5.2 RQ2: Toán tử DA nào trong số các toán tử DA được đề xuất đóng góp nhiều nhất cho hiệu suất truy xuất?

Thiết lập. Để hiểu rõ hơn ảnh hưởng của các toán tử tăng cường dữ liệu được đề xuất đối với hiệu quả mô hình xuôi dòng, chúng tôi thực hiện các nghiên cứu ablation trên các tập dữ liệu huấn luyện được tạo ra bằng cách sử dụng tất cả trừ một loại toán tử tăng cường. Để làm điều này, chúng tôi tạo ra 5 loại tập dữ liệu huấn luyện được tăng cường: No Backtranslation, No Insert, No Delete, No Replace và No Swap operator. Lưu ý rằng chúng tôi xem xét, ví dụ, cả Code Token Swap và Random Swap như các toán tử loại Swap. Để cân bằng các tập dữ liệu, chúng tôi sử dụng các giá trị 𝛼 và 𝜔 từ RQ1 dẫn đến hiệu suất tốt nhất cho các mô hình, tức là đối với FBL-BERT 𝛼=0.85, 𝜔=2.0, trong khi đối với các mô hình TBERT 𝛼=0.7, và 𝜔=1.0.

Kết quả. Hình 5 cho thấy điểm MRR cho các tập dữ liệu được tăng cường với 4 trong số 5 loại toán tử cũng như điểm MRR của 𝐷𝑜𝑟𝑖 và 𝐷𝑎𝑢𝑔 như các đường ngang để tham khảo. Chúng tôi lưu ý rằng hầu hết các toán tử đóng góp vào hiệu suất cuối cùng, với một ngoại lệ là toán tử Swap cho FBL-BERT. Việc thiếu tác động cho toán tử Swap có thể được quy cho kiến trúc mô hình. Cho rằng FBL-BERT tận dụng tất cả các token trong một báo cáo lỗi riêng biệt, việc hoán đổi vị trí token không ngăn cản chúng được khớp. Mặt khác, loại trừ Random Insert ảnh hưởng đến FBL-BERT nhiều nhất, chỉ ra rằng các token được chèn có giá trị đối với mô hình và cải thiện hiệu quả của nó khi khớp token embedding. Toán tử Delete là đóng góp nổi bật nhất cho hiệu suất của cả hai mô hình TBERT. Khi toán tử Delete không được phép trong quá trình tăng cường, điểm MRR của các tập dữ liệu được tăng cường giảm 0.054 và 0.055 cho TBERT-Single và TBERT-Siamese tương ứng, chỉ ra rằng phương sai gây ra bởi việc loại bỏ token ngẫu nhiên có tác động tích cực. Toán tử Delete, khi được áp dụng với mức độ vừa phải tương đối, dường như thêm vào tính mạnh mẽ của các mô hình, tức là các mô hình tạo ra các liên kết bổ sung giữa các thuật ngữ và khái niệm trong các báo cáo lỗi và changeset. Giá trị của quá trình này cũng được hỗ trợ bởi công việc gần đây trong huấn luyện đối kháng của các mô hình ngôn ngữ lớn, như BERT, để cải thiện tính mạnh mẽ của chúng chống lại các cuộc tấn công độc hại [18].

RQ2: Tất cả các toán tử DA đóng góp vào cải thiện hiệu suất với mức độ khác nhau, ngoại trừ Swap cho FBL-BERT. Toán tử Delete liên tục cải thiện hiệu suất trong cả ba mô hình.

5.3 Mối đe dọa đối với tính hợp lệ

Có một số mối đe dọa tính hợp lệ đối với các phát hiện của chúng tôi. Một mối đe dọa đối với tính hợp lệ nội bộ của nghiên cứu là các lựa chọn tham số cho các mô hình định vị lỗi dựa trên DL, đặc biệt trong bối cảnh (1) quy trình huấn luyện; (2) lựa chọn BERT-base; và (3) các tham số vốn có của mỗi mô hình. Để giảm thiểu mối đe dọa đó, trong quá trình huấn luyện chúng tôi tuân theo các khuyến nghị của các tác giả BERT [10], trong khi đối với mỗi mô hình chúng tôi sử dụng các tham số được xác định là tối ưu bởi các nghiên cứu trước đó [6,29]. Mặc dù trong nghiên cứu của chúng tôi, chúng tôi sử dụng BERTOverflow làm mô hình BERT cơ sở của chúng tôi, các lựa chọn khác tồn tại (ví dụ: CodeBERT [12]), và nhiều mô hình đang được phát triển, do đó chúng tôi để lại việc đánh giá các mô hình BERT cơ sở khác nhau trong bối cảnh định vị lỗi cho công việc tương lai.

Một mối đe dọa nội bộ khác là trong các lựa chọn của chúng tôi về các toán tử tăng cường, tham số của chúng (ví dụ: 𝜆), và cách chúng được áp dụng cùng nhau (ví dụ: xếp chồng các toán tử). Mối đe dọa này được giảm thiểu bằng cách tuân theo các thực hành tốt nhất được biết đến từ văn học tăng cường NLP tập trung vào các toán tử mức token và các tác vụ trong lĩnh vực [25,57]. Mặc dù chúng tôi khám phá một số lựa chọn tham số cho cân bằng dữ liệu trong bài báo (ví dụ: 𝛼 và 𝜔), cũng có các tham số bổ sung liên quan đến quá trình xây dựng báo cáo lỗi cũng như các toán tử tăng cường khác có thể cung cấp sự cải thiện hơn.

Các công cụ bên ngoài mà chúng tôi tận dụng để xây dựng pipeline tăng cường của chúng tôi, ví dụ: infozilla, công cụ BEE, có thể đưa ra nhiễu lan truyền đến các kết quả được báo cáo của chúng tôi. Tuy nhiên, đây là các công cụ hiện đại đã được đánh giá kỹ lưỡng nên tỷ lệ lỗi của chúng nên được hạn chế.

Hơn nữa, tính ngẫu nhiên của các toán tử tăng cường có thể đặt ra mối đe dọa đối với tính hợp lệ nội bộ. Để giảm thiểu điều đó, chúng tôi đảm bảo đặt một giá trị ban đầu trên bộ tạo số ngẫu nhiên giả của hệ thống khi xây dựng một tập dữ liệu được tăng cường cũng như khi huấn luyện một mô hình DL.

Một mối đe dọa đối với tính hợp lệ bên ngoài là chúng tôi chỉ đánh giá kỹ thuật tăng cường dữ liệu cho định vị lỗi trên một số lượng hạn chế các lỗi được thu thập từ một lựa chọn các dự án Java mã nguồn mở. Mối đe dọa này được giảm thiểu bởi thực tế rằng tập dữ liệu đã được sử dụng trong một số nghiên cứu định vị lỗi trước đó [43,58,60]. Một yếu tố giảm thiểu khác là các dự án phản ánh nhiều mục đích, phong cách phát triển và lịch sử khác nhau.

Các hạn chế trong các chỉ số đánh giá được chọn đặt ra mối đe dọa đối với tính hợp lệ kết luận vì chúng có thể không đo lường trực tiếp sự hài lòng của người dùng với các hunk thay đổi được truy xuất [54]. Mối đe dọa được giảm thiểu bởi thực tế rằng các chỉ số được chọn được biết đến rộng rãi và được chấp nhận rộng rãi là tốt nhất có sẵn để đo lường và so sánh hiệu suất của các kỹ thuật IR.

6 KẾT LUẬN VÀ CÔNG VIỆC TƯƠNG LAI

Các mô hình DL hướng tới định vị lỗi xuất sắc trong việc thu hẹp khoảng cách từ vựng giữa ngôn ngữ tự nhiên mô tả một báo cáo lỗi và ngôn ngữ lập trình định nghĩa mã nguồn. Tuy nhiên, việc huấn luyện một mô hình DL hiệu quả yêu cầu một lượng lớn dữ liệu được gắn nhãn cụ thể của dự án (tức là các cặp báo cáo lỗi và changeset gây ra lỗi), thường khó thu thập với số lượng đủ cho một dự án đơn lẻ. Để nới lỏng yêu cầu về số lượng dữ liệu, và cho phép sử dụng mô hình DL khi dữ liệu huấn luyện khan hiếm, công trình này đề xuất sử dụng tăng cường dữ liệu (DA) để tạo ra các báo cáo lỗi mới, có vẻ thực tế có thể được sử dụng để tăng đáng kể kích thước của tập huấn luyện. Để tăng cường các báo cáo lỗi, chúng tôi đề xuất các toán tử DA hoạt động độc lập tăng cường nội dung ngôn ngữ tự nhiên và liên quan đến mã của một báo cáo lỗi. Để xây dựng một tập dữ liệu huấn luyện mới sử dụng các báo cáo lỗi được tăng cường, chúng tôi đề xuất một chiến lược cân bằng dữ liệu có chọn lọc tăng cường các báo cáo lỗi để thêm nhiều mẫu huấn luyện hơn cho các phần chưa được đại diện của mã nguồn.

Kết quả chỉ ra rằng tăng cường dữ liệu được đề xuất cải thiện độ chính xác truy xuất trên tất cả các mô hình DL được nghiên cứu tăng điểm MRR từ 39% đến 82% so với tập dữ liệu gốc, không được tăng cường. Hơn nữa, khi các tập dữ liệu được tăng cường được so sánh với các tập huấn luyện được mở rộng bằng lặp lại dữ liệu, chúng tôi quan sát rằng chúng cải thiện điểm MRR từ 20% đến 36%. Tất cả các toán tử DA được đề xuất đóng góp vào hiệu suất cuối cùng, với việc xóa token mang lại tác động nhất quán nhất cho các mô hình DL khác nhau.

Đây là một trong những bài báo đầu tiên giới thiệu tăng cường dữ liệu cho kỹ thuật phần mềm. Chúng tôi tin rằng tăng cường dữ liệu như một kỹ thuật có tiềm năng cho SE bởi vì các tập dữ liệu không lớn bằng trong ML chính thống. Ngoài ra, tăng cường dữ liệu không phải là kỹ thuật phù hợp với tất cả và việc áp dụng tối ưu của nó yêu cầu các toán tử tùy chỉnh, vì vậy bài báo đóng góp trong việc thiết kế các toán tử tăng cường dữ liệu cho các báo cáo lỗi và áp dụng chúng bằng cách sử dụng một chiến lược cân bằng dữ liệu.

Mặc dù vậy, phương pháp được đề xuất yêu cầu nhiều thí nghiệm hơn để củng cố các quan sát và khuyến nghị của chúng tôi. Như công việc tương lai của chúng tôi, chúng tôi dự định (1) mở rộng các tập dữ liệu đánh giá của chúng tôi với các dự án phần mềm mới được viết bằng Java, Python và Javascript; (2) tiến hành thí nghiệm với dữ liệu được tăng cường nặng hơn, tức là bằng cách sử dụng các toán tử DA trên một số lượng lớn hơn các token; (3) thí nghiệm với các toán tử xóa khác nhau (ví dụ: loại bỏ các token mã không liên quan) cho hiệu suất tốt của Random Delete cho ngôn ngữ tự nhiên; và (4) thí nghiệm với các cấu hình khác nhau cho trình xây dựng báo cáo lỗi.

7 TÍNH KHẢ DỤNG CỦA DỮ LIỆU

Một gói sao chép bao gồm tất cả mã và script có liên quan có sẵn tại https://anonymous.4open.science/r/fbl-bert-987B.

TÀI LIỆU THAM KHẢO

[1] Nicolas Bettenburg, Sascha Just, Adrian Schröter, Cathrin Weiss, Rahul Premraj, và Thomas Zimmermann. 2008. What Makes a Good Bug Report?. In Proceedings of the 16th ACM SIGSOFT International Symposium on Foundations of Software Engineering (SIGSOFT '08/FSE-16).

[2] Gemma Catolino, Fabio Palomba, Andy Zaidman, và Filomena Ferrucci. 2019. Not all bugs are the same: Understanding, characterizing, and classifying bug types. Journal of Systems and Software (2019).

[3] O. Chaparro, J. M. Florez, và A. Marcus. 2017. Using Observed Behavior to Reformulate Queries during Text Retrieval-based Bug Localization. In 2017 IEEE International Conference on Software Maintenance and Evolution (ICSME). 376–387.

[4] Oscar Chaparro, Jing Lu, Fiorella Zampetti, Laura Moreno, Massimiliano Di Penta, Andrian Marcus, Gabriele Bavota, và Vincent Ng. 2017. Detecting Missing Information in Bug Descriptions. In Proceedings of the 2017 11th Joint Meeting on Foundations of Software Engineering (ESEC/FSE 2017).

[5] Jiaao Chen, Dinghan Shen, Weizhu Chen, và Diyi Yang. 2021. Hiddencut: Simple data augmentation for natural language understanding with better generalizability. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers). 4380–4390.

[6] Agnieszka Ciborowska và Kostadin Damevski. 2022. Fast Changeset-Based Bug Localization with BERT. In Proceedings of the 44th International Conference on Software Engineering (ICSE '22). Association for Computing Machinery, New York, NY, USA, 946–957.

[7] C. S. Corley, K. Damevski, và N. A. Kraft. 2018. Changeset-Based Topic Modeling of Software Repositories. IEEE Transactions on Software Engineering (2018).

[8] Daniel Alencar da Costa, Shane McIntosh, Weiyi Shang, Uirá Kulesza, Roberta Coelho, và Ahmed E. Hassan. 2017. A Framework for Evaluating the Results of the SZZ Approach for Identifying Bug-Introducing Changes. IEEE Transactions on Software Engineering (2017).

[9] Zhuyun Dai và Jamie Callan. 2019. Deeper Text Understanding for IR with Contextual Neural Language Modeling. In Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR'19).

[10] Jacob Devlin, Ming-Wei Chang, Kenton Lee, và Kristina Toutanova. 2019. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies.

[11] Steven Y Feng, Varun Gangal, Jason Wei, Sarath Chandar, Soroush Vosoughi, Teruko Mitamura, và Eduard Hovy. 2021. A survey of data augmentation approaches for nlp. arXiv preprint arXiv:2105.03075 (2021).

[12] Zhangyin Feng, Daya Guo, Duyu Tang, Nan Duan, Xiaocheng Feng, Ming Gong, Linjun Shou, Bing Qin, Ting Liu, Daxin Jiang, và Ming Zhou. 2020. CodeBERT: A Pre-Trained Model for Programming and Natural Languages. In Findings of the Association for Computational Linguistics: EMNLP 2020.

[13] Xiaodong Gu, Hongyu Zhang, và Sunghun Kim. 2018. Deep Code Search. In 2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE). 933–944.

[14] Jin Guo, Jinghui Cheng, và Jane Cleland-Huang. 2017. Semantically Enhanced Software Traceability Using Deep Learning Techniques. In Proceedings of the 39th International Conference on Software Engineering (ICSE '17).

[15] Rahul Gupta, Aditya Kanade, và Shirish Shevade. 2019. Neural Attribution for Semantic Bug-Localization in Student Programs. In Advances in Neural Information Processing Systems, H. Wallach, H. Larochelle, A. Beygelzimer, F. d 'Alché-Buc, E. Fox, và R. Garnett (Eds.), Vol. 32.

[16] Suchin Gururangan, Ana Marasović, Swabha Swayamdipta, Kyle Lo, Iz Beltagy, Doug Downey, và Noah A Smith. 2020. Don't stop pretraining: adapt language models to domains and tasks. arXiv preprint arXiv:2004.10964 (2020).

[17] Thong Hoang, Hoa Khanh Dam, Yasutaka Kamei, David Lo, và Naoyasu Ubayashi. 2019. DeepJIT: An End-to-End Deep Learning Framework for Just-in-Time Defect Prediction. In 2019 IEEE/ACM 16th International Conference on Mining Software Repositories (MSR). 34–45.

[18] Yu-Lun Hsieh, Minhao Cheng, Da-Cheng Juan, Wei Wei, Wen-Lian Hsu, và Cho-Jui Hsieh. 2019. On the Robustness of Self-Attentive Models. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics. Association for Computational Linguistics, Florence, Italy, 1520–1529. https://doi.org/10.18653/v1/P19-1147

[19] Xuan Huo, Ming Li, và Zhi-Hua Zhou. 2016. Learning Unified Features from Natural and Programming Languages for Locating Buggy Source Code. In Proceedings of the 25th International Joint Conference on Artificial Intelligence (IJCAI'16).

[20] X. Huo, F. Thung, M. Li, D. Lo, và S. Shi. 2019. Deep Transfer Bug Localization. IEEE Transactions on Software Engineering (2019), 1–1. https://doi.org/10.1109/TSE.2019.2920771

[21] Hamel Husain, Ho-Hsiang Wu, Tiferet Gazit, Miltiadis Allamanis, và Marc Brockschmidt. 2019. CodeSearchNet challenge: Evaluating the state of semantic code search. arXiv preprint arXiv:1909.09436 (2019).

[22] Omar Khattab và Matei Zaharia. 2020. ColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT. In Proceedings of the 43rd International ACM SIGIR conference on research and development in Information Retrieval (SIGIR '20).

[23] Diederik P. Kingma và Jimmy Ba. 2014. Adam: A Method for Stochastic Optimization. https://arxiv.org/abs/1412.6980

[24] Pavneet Singh Kochhar, Yuan Tian, và David Lo. 2014. Potential Biases in Bug Localization: Do They Matter?. In Proceedings of the 29th ACM/IEEE International Conference on Automated Software Engineering (Vasteras, Sweden) (ASE '14). 803–814.

[25] Venelin Kovatchev, Phillip Smith, Mark Lee, và Rory Devine. 2021. Can vectors read minds better than experts? Comparing data augmentation strategies for the automated scoring of children's mindreading ability. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers).

[26] An Ngoc Lam, Anh Tuan Nguyen, Hoan Anh Nguyen, và Tien N. Nguyen. 2017. Bug Localization with Combination of Deep Learning and Information Retrieval. In Proceedings of the 25th International Conference on Program Comprehension (ICPC '17). IEEE Press. https://doi.org/10.1109/ICPC.2017.24

[27] Jaekwon Lee, Dongsun Kim, Tegawendé F. Bissyandé, Woosung Jung, và Yves Le Traon. 2018. Bench4BL: Reproducibility Study on the Performance of IR-based Bug Localization. In Proceedings of the 27th ACM SIGSOFT International Symposium on Software Testing and Analysis (Amsterdam, Netherlands) (ISSTA 2018). 61–72.

[28] Jian Li, Pinjia He, Jieming Zhu, và Michael R. Lyu. 2017. Software Defect Prediction via Convolutional Neural Network. In 2017 IEEE International Conference on Software Quality, Reliability and Security (QRS). 318–328.

[29] Jinfeng Lin, Yalin Liu, Qingkai Zeng, Meng Jiang, và Jane Cleland-Huang. 2021. Traceability transformed: Generating more accurate links with pre-trained BERT models. In 2021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE). IEEE, 324–335.

[30] Vijayaraghavan Murali, Lee Gross, Rebecca Qian, và Satish Chandra. 2020. Industry-scale IR-based Bug Localization: A Perspective from Facebook. In Proceedings of the 42nd International Conference on Software Engineering (ICSE '20).

[31] E. C. Neto, D. A. da Costa, và U. Kulesza. 2018. The impact of refactoring changes on the SZZ algorithm: An empirical study. In IEEE 25th International Conference on Software Analysis, Evolution and Reengineering (SANER) (SANER 2018).

[32] Nathan Ng, Kyra Yee, Alexei Baevski, Myle Ott, Michael Auli, và Sergey Edunov. 2019. Facebook FAIR's WMT19 News Translation Task Submission. In Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1).

[33] A. T. Nguyen, T. T. Nguyen, J. Al-Kofahi, H. V. Nguyen, và T. N. Nguyen. 2011. A Topic-based Approach for Narrowing the Search Space of Buggy Files from a Bug Report. In Proceedings of the 26th IEEE/ACM International Conference on Automated Software Engineering (ASE 2011). 263–272. https://doi.org/10.1109/ASE.2011.6100062

[34] Toan Q Nguyen, Kenton Murray, và David Chiang. 2021. Data Augmentation by Concatenation for Low-Resource Translation: A Mystery and a Solution. arXiv preprint arXiv:2105.01691 (2021).

[35] Rodrigo Nogueira và Kyunghyun Cho. 2019. Passage Re-ranking with BERT. https://doi.org/10.48550/ARXIV.1901.04085

[36] Matteo Paltenghi và Michael Pradel. 2021. Thinking Like a Developer? Comparing the Attention of Humans with Neural Models of Code. In 2021 36th IEEE/ACM International Conference on Automated Software Engineering (ASE). IEEE, 867–879.

[37] Chanathip Pornprasit và Chakkrit Tantithamthavorn. 2022. DeepLineDP: Towards a Deep Learning Approach for Line-Level Defect Prediction. IEEE Transactions on Software Engineering (2022).

[38] Michael Pradel, Vijayaraghavan Murali, Rebecca Qian, Mateusz Machalica, Erik Meijer, và Satish Chandra. 2020. Scaffle: bug localization on millions of files. In Proceedings of the 29th ACM SIGSOFT International Symposium on Software Testing and Analysis.

[39] Rahul Premraj, Thomas Zimmermann, Sunghun Kim, và Nicolas Bettenburg. 2008. Extracting structural information from bug reports. In Proceedings of the 2008 international workshop on Mining software repositories - MSR 2008.

[40] Mohammad Masudur Rahman và Chanchal K Roy. 2018. Improving IR-based bug localization with context-aware query reformulation. In Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering. ACM, 621–632.

[41] Nils Reimers và Iryna Gurevych. 2019. Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks. arXiv:1908.10084 [cs.CL]

[42] Giovanni Rosa, Luca Pascarella, Simone Scalabrino, Rosalia Tufano, Gabriele Bavota, Michele Lanza, và Rocco Oliveto. 2021. Evaluating SZZ Implementations Through a Developer-informed Oracle. arXiv:2102.03300 [cs.SE]

[43] Ripon K. Saha, Matthew Lease, Sarfraz Khurshid, và Dewayne E. Perry. 2013. Improving Bug Localization Using Structured Information Retrieval. In Proceedings of the 28th IEEE/ACM International Conference on Automated Software Engineering (Silicon Valley, CA, USA) (ASE'13). 345–355.

[44] Dinghan Shen, Mingzhi Zheng, Yelong Shen, Yanru Qu, và Weizhu Chen. 2020. A Simple but Tough-to-Beat Data Augmentation Approach for Natural Language Understanding and Generation. arXiv preprint arXiv:2009.13818 (2020).

[45] Connor Shorten, Taghi M Khoshgoftaar, và Borko Furht. 2021. Text data augmentation for deep learning. Journal of big Data 8, 1 (2021), 1–34.

[46] Jacek Sliwerski, Thomas Zimmermann, và Andreas Zeller. 2005. When Do Changes Induce Fixes?. In Proceedings of the 2005 International Workshop on Mining Software Repositories (MSR '05).

[47] Mark D. Smucker, James Allan, và Ben Carterette. 2007. A Comparison of Statistical Significance Tests for Information Retrieval Evaluation. In Proceedings of the Sixteenth ACM Conference on Conference on Information and Knowledge Management (CIKM '07). 623–632.

[48] Yang Song và Oscar Chaparro. 2020. BEE: A Tool for Structuring and Analyzing Bug Reports. In Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering.

[49] Jeniya Tabassum, Mounica Maddela, Wei Xu, và Alan Ritter. 2020. Code and Named Entity Recognition in StackOverflow. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics.

[50] Huy Tu và Tim Menzies. 2021. FRUGAL: Unlocking SSL for Software Analytics. arXiv preprint arXiv:2108.09847 (2021).

[51] Huy Tu, Zhe Yu, và Tim Menzies. 2022. Better Data Labelling With EMBLEM (and how that Impacts Defect Prediction). IEEE Transactions on Software Engineering 48, 1 (2022), 278–294.

[52] Julián Urbano, Harlley Lima, và Alan Hanjalic. 2019. Statistical Significance Testing in Information Retrieval: An Empirical Analysis of Type I, Type II and Type III Errors. In Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval (Paris, France) (SIGIR'19).

[53] Bogdan Vasilescu, Yue Yu, Huaimin Wang, Premkumar Devanbu, và Vladimir Filkov. 2015. Quality and Productivity Outcomes Relating to Continuous Integration in GitHub. In Proceedings of the 2015 10th Joint Meeting on Foundations of Software Engineering (ESEC/FSE 2015).

[54] Qianqian Wang, Chris Parnin, và Alessandro Orso. 2015. Evaluating the Usefulness of IR-Based Fault Localization Techniques. In Proceedings of the 2015 International Symposium on Software Testing and Analysis (ISSTA 2015) (Baltimore, MD, USA). 1–11.

[55] Song Wang, Taiyue Liu, Jaechang Nam, và Lin Tan. 2020. Deep Semantic Feature Learning for Software Defect Prediction. IEEE Transactions on Software Engineering 46, 12 (2020).

[56] Shaowei Wang và David Lo. 2014. Version History, Similar Report, and Structure: Putting Them Together for Improved Bug Localization. In Proceedings of the 22Nd International Conference on Program Comprehension (Hyderabad, India) (ICPC 2014). 53–63.

[57] Jason Wei và Kai Zou. 2019. EDA: Easy Data Augmentation Techniques for Boosting Performance on Text Classification Tasks. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP).

[58] Ming Wen, Rongxin Wu, và Shing-Chi Cheung. 2016. Locus: Locating Bugs from Software Changes. In Proceedings of the 31st IEEE/ACM International Conference on Automated Software Engineering (Singapore, Singapore) (ASE 2016). 262–273.

[59] Ratnadira Widyasari, Stefanus Agus Haryono, Ferdian Thung, Jieke Shi, Constance Tan, Fiona Wee, Jack Phan, và David Lo. 2022. On the Influence of Biases in Bug Localization: Evaluation and Benchmark. In Proceedings of the 29th IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER), RENE Track. (SANER 2022).

[60] Chu-Pan Wong, Yingfei Xiong, Hongyu Zhang, Dan Hao, Lu Zhang, và Hong Mei. 2014. Boosting Bug-Report-Oriented Fault Localization with Segmentation and Stack-Trace Analysis. In Proceedings of the 2014 IEEE International Conference on Software Maintenance and Evolution (ICSME '14). 181–190.

[61] Xueqing Wu, Yingce Xia, Jinhua Zhu, Lijun Wu, Shufang Xie, Yang Fan, và Tao Qin. 2021. mixSeq: A Simple Data Augmentation Methodfor Neural Machine Translation. In Proceedings of the 18th International Conference on Spoken Language Translation (IWSLT 2021).

[62] Yan Xiao, Jacky Keung, Kwabena E. Bennin, và Qing Mi. 2019. Improving bug localization with word embedding and enhanced convolutional neural networks. Information and Software Technology 105 (2019).

[63] Xinli Yang, David Lo, Xin Xia, Yun Zhang, và Jianling Sun. 2015. Deep Learning for Just-in-Time Defect Prediction. In 2015 IEEE International Conference on Software Quality, Reliability and Security. 17–26. https://doi.org/10.1109/QRS.2015.14

[64] Xin Ye, Razvan Bunescu, và Chang Liu. 2014. Learning to Rank Relevant Files for Bug Reports Using Domain Knowledge. In Proceedings of the 22Nd ACM SIGSOFT International Symposium on Foundations of Software Engineering (Hong Kong, China) (FSE 2014). 689–699.

[65] Rahul Yedida và Tim Menzies. 2021. On the value of oversampling for deep learning in software defect prediction. IEEE Transactions on Software Engineering (2021).

[66] W. Zou, D. Lo, Z. Chen, X. Xia, Y. Feng, và B. Xu. 2020. How Practitioners Perceive Automated Bug Report Management Techniques. IEEE Transactions on Software Engineering 46, 8 (2020).

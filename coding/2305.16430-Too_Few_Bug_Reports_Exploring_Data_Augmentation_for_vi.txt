# QuÃ¡ Ã­t bÃ¡o cÃ¡o lá»—i? KhÃ¡m phÃ¡ tÄƒng cÆ°á»ng dá»¯ liá»‡u Ä‘á»ƒ cáº£i thiá»‡n Ä‘á»‹nh vá»‹ lá»—i dá»±a trÃªn changeset

Agnieszka Ciborowska
Äáº¡i há»c Virginia Commonwealth
Richmond, Virginia, USA
imranm3@vcu.eduKostadin Damevski
Äáº¡i há»c Virginia Commonwealth
Richmond, Virginia, USA
kdamevski@vcu.edu

TÃ“M Táº®T
CÃ¡c kiáº¿n trÃºc Deep Learning (DL) hiá»‡n Ä‘áº¡i dá»±a trÃªn transformer (vÃ­ dá»¥: BERT, RoBERTa) Ä‘ang thá»ƒ hiá»‡n sá»± cáº£i thiá»‡n hiá»‡u suáº¥t trÃªn nhiá»u tÃ¡c vá»¥ ngÃ´n ngá»¯ tá»± nhiÃªn. Máº·c dÃ¹ cÃ¡c mÃ´ hÃ¬nh DL nÃ y Ä‘Ã£ cho tháº¥y tiá»m nÄƒng to lá»›n Ä‘á»ƒ sá»­ dá»¥ng trong cÃ¡c á»©ng dá»¥ng ká»¹ thuáº­t pháº§n má»m, chÃºng thÆ°á»ng bá»‹ cáº£n trá»Ÿ bá»Ÿi dá»¯ liá»‡u huáº¥n luyá»‡n khÃ´ng Ä‘áº§y Ä‘á»§. Äáº·c biá»‡t bá»‹ háº¡n cháº¿ lÃ  cÃ¡c á»©ng dá»¥ng yÃªu cáº§u dá»¯ liá»‡u cá»¥ thá»ƒ cá»§a dá»± Ã¡n, cháº³ng háº¡n nhÆ° Ä‘á»‹nh vá»‹ lá»—i, nháº±m má»¥c Ä‘Ã­ch Ä‘á» xuáº¥t mÃ£ Ä‘á»ƒ sá»­a má»™t bÃ¡o cÃ¡o lá»—i má»›i Ä‘Æ°á»£c gá»­i. CÃ¡c mÃ´ hÃ¬nh deep learning cho Ä‘á»‹nh vá»‹ lá»—i yÃªu cáº§u má»™t táº­p huáº¥n luyá»‡n Ä‘Ã¡ng ká»ƒ gá»“m cÃ¡c bÃ¡o cÃ¡o lá»—i Ä‘Ã£ Ä‘Æ°á»£c sá»­a, mÃ  chÃºng cÃ³ sá»‘ lÆ°á»£ng háº¡n cháº¿ ngay cáº£ trong cÃ¡c dá»± Ã¡n pháº§n má»m phá»• biáº¿n vÃ  Ä‘Æ°á»£c phÃ¡t triá»ƒn tÃ­ch cá»±c. Trong bÃ i bÃ¡o nÃ y, chÃºng tÃ´i kiá»ƒm tra tÃ¡c Ä‘á»™ng cá»§a viá»‡c sá»­ dá»¥ng dá»¯ liá»‡u huáº¥n luyá»‡n tá»•ng há»£p trÃªn cÃ¡c mÃ´ hÃ¬nh DL dá»±a trÃªn transformer thá»±c hiá»‡n má»™t biáº¿n thá»ƒ phá»©c táº¡p hÆ¡n cá»§a Ä‘á»‹nh vá»‹ lá»—i, cÃ³ má»¥c tiÃªu truy xuáº¥t cÃ¡c changeset gÃ¢y ra lá»—i cho má»—i bÃ¡o cÃ¡o lá»—i. Äá»ƒ táº¡o ra dá»¯ liá»‡u tá»•ng há»£p cháº¥t lÆ°á»£ng cao, chÃºng tÃ´i Ä‘á» xuáº¥t cÃ¡c toÃ¡n tá»­ tÄƒng cÆ°á»ng dá»¯ liá»‡u má»›i hoáº¡t Ä‘á»™ng trÃªn cÃ¡c thÃ nh pháº§n cáº¥u thÃ nh khÃ¡c nhau cá»§a bÃ¡o cÃ¡o lá»—i. ChÃºng tÃ´i cÅ©ng mÃ´ táº£ má»™t chiáº¿n lÆ°á»£c cÃ¢n báº±ng dá»¯ liá»‡u nháº±m táº¡o ra má»™t kho tÃ ng cÃ¡c bÃ¡o cÃ¡o lá»—i Ä‘Æ°á»£c tÄƒng cÆ°á»ng pháº£n Ã¡nh tá»‘t hÆ¡n toÃ n bá»™ cÆ¡ sá»Ÿ mÃ£ nguá»“n, bá»Ÿi vÃ¬ cÃ¡c bÃ¡o cÃ¡o lá»—i hiá»‡n cÃ³ Ä‘Æ°á»£c sá»­ dá»¥ng lÃ m dá»¯ liá»‡u huáº¥n luyá»‡n thÆ°á»ng chá»‰ tham chiáº¿u má»™t pháº§n nhá» cá»§a cÆ¡ sá»Ÿ mÃ£. CÃ¢n báº±ng dá»¯ liá»‡u giÃºp mÃ´ hÃ¬nh hoáº¡t Ä‘á»™ng tá»‘t hÆ¡n cho cÃ¡c bÃ¡o cÃ¡o lá»—i má»›i Ä‘Æ°á»£c bÃ¡o cÃ¡o tham chiáº¿u Ä‘áº¿n mÃ£ chÆ°a tá»«ng Ä‘Æ°á»£c quan sÃ¡t trÆ°á»›c Ä‘Ã³. Káº¿t quáº£ Ä‘Ã¡nh giÃ¡ cá»§a chÃºng tÃ´i chá»‰ ra ráº±ng cáº£ tÄƒng cÆ°á»ng dá»¯ liá»‡u vÃ  cÃ¢n báº±ng Ä‘á»u hiá»‡u quáº£, cáº£i thiá»‡n hiá»‡u suáº¥t truy xuáº¥t trÃªn cáº£ ba mÃ´ hÃ¬nh dá»±a trÃªn BERT mÃ  chÃºng tÃ´i nghiÃªn cá»©u.

ACM Reference Format:
Agnieszka Ciborowska and Kostadin Damevski. 2023. Too Few Bug Reports? Exploring Data Augmentation for Improved Changeset-based Bug Localization. In Proceedings of ACM Conference (Conference'17). ACM, New York, NY, USA, 12 pages. https://doi.org/10.1145/nnnnnnn.nnnnnnn

1 GIá»šI THIá»†U
Sá»± xuáº¥t hiá»‡n cá»§a cÃ¡c kiáº¿n trÃºc Deep Learning (DL) má»›i nhÆ° transformer Ä‘Ã£ thÃºc Ä‘áº©y nhá»¯ng cáº£i thiá»‡n ná»•i báº­t trÃªn nhiá»u tÃ¡c vá»¥ trong Xá»­ lÃ½ NgÃ´n ngá»¯ Tá»± nhiÃªn (NLP), vÃ  khuyáº¿n khÃ­ch viá»‡c Ã¡p dá»¥ng chÃºng vÃ o cÃ¡c váº¥n Ä‘á» khÃ¡c nhau trong lÄ©nh vá»±c ká»¹ thuáº­t pháº§n má»m. CÃ¡c nhÃ  nghiÃªn cá»©u ká»¹ thuáº­t pháº§n má»m Ä‘Ã£ nghiÃªn cá»©u tiá»m nÄƒng cá»§a DL trong bá»‘i cáº£nh cÃ¡c váº¥n Ä‘á» nhÆ° tÃ¬m kiáº¿m mÃ£ [13,14,21,29], dá»± Ä‘oÃ¡n khiáº¿m khuyáº¿t [17,28,37,55,63], vÃ  Ä‘á»‹nh vá»‹ lá»—i [6,19,20,26,62]. Tuy nhiÃªn, Ä‘iá»ƒm yáº¿u cÆ¡ báº£n cá»§a cÃ¡c phÆ°Æ¡ng phÃ¡p DL lÃ  chÃºng yÃªu cáº§u má»™t lÆ°á»£ng lá»›n dá»¯ liá»‡u Ä‘Æ°á»£c gáº¯n nhÃ£n Ä‘á»ƒ huáº¥n luyá»‡n mÃ´ hÃ¬nh. Äá»“ng thá»i, viá»‡c duy trÃ¬ cháº¥t lÆ°á»£ng cá»§a dá»¯ liá»‡u Ä‘Æ°á»£c gáº¯n nhÃ£n lÃ  ráº¥t quan trá»ng Ä‘á»ƒ Ä‘áº¡t Ä‘Æ°á»£c hiá»‡u suáº¥t tá»‘t nháº¥t. Máº·c dÃ¹ viá»‡c gáº¯n nhÃ£n thá»§ cÃ´ng thÆ°á»ng lÃ  phÆ°Æ¡ng phÃ¡p Ä‘Æ°á»£c Æ°a chuá»™ng Ä‘á»ƒ Ä‘áº£m báº£o cháº¥t lÆ°á»£ng dá»¯ liá»‡u cao, nhÆ°ng Ä‘Ã³ lÃ  má»™t quÃ¡ trÃ¬nh cháº­m vÃ  tá»‘n thá»i gian [51], thÆ°á»ng khÃ´ng kháº£ thi khi xem xÃ©t lÆ°á»£ng dá»¯ liá»‡u cáº§n thiáº¿t Ä‘á»ƒ huáº¥n luyá»‡n má»™t mÃ´ hÃ¬nh DL. Máº·t khÃ¡c, viá»‡c khai thÃ¡c tá»± Ä‘á»™ng cho nhÃ£n cÃ³ nhiá»u kháº£ nÄƒng Ä‘Ã¡p á»©ng nhu cáº§u vá» sá»‘ lÆ°á»£ng dá»¯ liá»‡u hÆ¡n, tuy nhiÃªn vá»›i cÃ¡i giÃ¡ pháº£i tráº£ lÃ  Ä‘Æ°a ra nhiá»…u dÆ°á»›i dáº¡ng cáº£ dÆ°Æ¡ng tÃ­nh giáº£ vÃ  Ã¢m tÃ­nh giáº£ [8,53]. Do Ä‘Ã³, viá»‡c thu tháº­p má»™t lÆ°á»£ng lá»›n dá»¯ liá»‡u Ä‘Æ°á»£c gáº¯n nhÃ£n cháº¥t lÆ°á»£ng tá»‘t cÃ³ thá»ƒ Ä‘áº·t ra má»™t thÃ¡ch thá»©c Ä‘Ã¡ng ká»ƒ cho nhiá»u váº¥n Ä‘á» vÃ  tÃ¡c vá»¥ ká»¹ thuáº­t pháº§n má»m quan trá»ng, Ä‘áº·c biá»‡t lÃ  nhá»¯ng váº¥n Ä‘á» yÃªu cáº§u dá»¯ liá»‡u dá»± Ã¡n Ä‘Æ¡n láº» (tá»©c lÃ  trong dá»± Ã¡n) [50]. Má»™t phÆ°Æ¡ng phÃ¡p gáº§n Ä‘Ã¢y Ä‘á»ƒ giáº£i quyáº¿t váº¥n Ä‘á» nÃ y lÃ  sá»­ dá»¥ng transfer learning, tá»©c lÃ  tiá»n huáº¥n luyá»‡n má»™t mÃ´ hÃ¬nh vá»›i há»c khÃ´ng giÃ¡m sÃ¡t trÃªn má»™t kho tÃ ng lá»›n, tá»•ng quÃ¡t, sau Ä‘Ã³ lÃ  tinh chá»‰nh thÃ´ng qua há»c cÃ³ giÃ¡m sÃ¡t hÆ°á»›ng tá»›i tÃ¡c vá»¥ Ä‘Ã­ch. Tuy nhiÃªn, chiáº¿n lÆ°á»£c nÃ y váº«n yÃªu cáº§u má»™t táº­p dá»¯ liá»‡u khÃ´ng táº§m thÆ°á»ng Ä‘á»ƒ tinh chá»‰nh vÃ , nhÆ° Ä‘Æ°á»£c quan sÃ¡t bá»Ÿi Gururangan et al., nÃ³ dáº«n Ä‘áº¿n hiá»‡u suáº¥t dÆ°á»›i tá»‘i Æ°u so vá»›i khi má»™t mÃ´ hÃ¬nh Ä‘Æ°á»£c tiá»n huáº¥n luyá»‡n vÃ  tinh chá»‰nh trÃªn dá»¯ liá»‡u trong lÄ©nh vá»±c [16].

Má»™t trong nhá»¯ng tÃ¡c vá»¥ ká»¹ thuáº­t pháº§n má»m Ä‘Æ°á»£c hÆ°á»Ÿng lá»£i tá»« phÆ°Æ¡ng phÃ¡p dá»±a trÃªn DL lÃ  Ä‘á»‹nh vá»‹ lá»—i, nháº±m xÃ¡c Ä‘á»‹nh cÃ¡c thá»±c thá»ƒ mÃ£ cÃ³ liÃªn quan (vÃ­ dá»¥: lá»›p, phÆ°Æ¡ng thá»©c hoáº·c changeset) cho má»™t bÃ¡o cÃ¡o lá»—i nháº¥t Ä‘á»‹nh mÃ´ táº£ sá»± cá»‘ pháº§n má»m. Qua nhiá»u nÄƒm, cÃ¡c nhÃ  nghiÃªn cá»©u Ä‘Ã£ Ä‘á» xuáº¥t nhiá»u phÆ°Æ¡ng phÃ¡p cho Ä‘á»‹nh vá»‹ lá»—i dá»±a trÃªn Vector Space Model (VSM) [43,56,58] vÃ  cÃ¡c mÃ´ hÃ¬nh xÃ¡c suáº¥t (vÃ­ dá»¥: Latent Dirichlet Allocation) [7,33], Ä‘á»“ng thá»i cÅ©ng nháº­n ra ráº±ng nhÆ°á»£c Ä‘iá»ƒm chÃ­nh cá»§a nhá»¯ng ká»¹ thuáº­t nÃ y lÃ  kháº£ nÄƒng háº¡n cháº¿ trong viá»‡c xá»­ lÃ½ khoáº£ng cÃ¡ch ngá»¯ nghÄ©a giá»¯a mÃ£ nguá»“n gÃ¢y ra lá»—i vÃ  mÃ´ táº£ Ä‘Æ°á»£c Ä‘Æ°a ra trong bÃ¡o cÃ¡o lá»—i [1,64]. Äá»ƒ giáº£i quyáº¿t Ä‘iá»u Ä‘Ã³, cÃ¡c ná»— lá»±c gáº§n Ä‘Ã¢y Ä‘Ã£ Ä‘Æ°á»£c chuyá»ƒn hÆ°á»›ng sang cÃ¡c ká»¹ thuáº­t DL, bao gá»“m RNN, LSTM vÃ  cuá»‘i cÃ¹ng lÃ  cÃ¡c mÃ´ hÃ¬nh dá»±a trÃªn transformer [6,29]. NhÆ° Ä‘Æ°á»£c Guo et al. [14] lÆ°u Ã½, tÃ­nh kháº£ dá»¥ng cá»§a dá»¯ liá»‡u huáº¥n luyá»‡n lÃ  má»™t trong nhá»¯ng yáº¿u tá»‘ chÃ­nh háº¡n cháº¿ hiá»‡u suáº¥t DL. Trong trÆ°á»ng há»£p Ä‘á»‹nh vá»‹ lá»—i, dá»¯ liá»‡u huáº¥n luyá»‡n bao gá»“m cÃ¡c cáº·p bÃ¡o cÃ¡o lá»—i vÃ  changeset giá»›i thiá»‡u (hoáº·c gÃ¢y ra) cá»§a chÃºng, ráº¥t khÃ³ thu tháº­p á»Ÿ quy mÃ´ lá»›n vÃ¬ má»™t vÃ i lÃ½ do chÃ­nh. Äáº§u tiÃªn, viá»‡c khá»›p má»™t bÃ¡o cÃ¡o lá»—i vá»›i cÃ¡c changeset gÃ¢y ra lá»—i lÃ  thÃ¡ch thá»©c vÃ¬ cÃ¡c nhÃ  phÃ¡t triá»ƒn hiáº¿m khi Ä‘Ã¡nh dáº¥u cÃ¡c thay Ä‘á»•i mÃ£ thá»§ pháº¡m má»™t cÃ¡ch rÃµ rÃ ng [30], trong khi cÃ¡c phÆ°Æ¡ng phÃ¡p tÃ¬m ra changeset gÃ¢y ra lá»—i tá»± Ä‘á»™ng, dá»±a trÃªn thuáº­t toÃ¡n SZZ [46], dá»… bá»‹ Ä‘Æ°a ra nhiá»…u [31,42]. Thá»© hai, sá»‘ lÆ°á»£ng máº«u tÃ­ch cá»±c bá»‹ giá»›i háº¡n bá»Ÿi sá»‘ lÆ°á»£ng bÃ¡o cÃ¡o lá»—i Ä‘Ã£ Ä‘Æ°á»£c sá»­a, vá»‘n cÃ³ háº¡n ngay cáº£ Ä‘á»‘i vá»›i cÃ¡c dá»± Ã¡n lá»›n vÃ  Ä‘Æ°á»£c duy trÃ¬ tÃ­ch cá»±c. CÃ¡c dá»± Ã¡n pháº§n má»m tÆ°Æ¡ng Ä‘á»‘i nhá» hÆ¡n vá»›i, vÃ­ dá»¥, hÃ ng chá»¥c bÃ¡o cÃ¡o lá»—i Ä‘Ã£ Ä‘Æ°á»£c sá»­a, sáº½ ráº¥t khÃ³ sá»­ dá»¥ng. Cuá»‘i cÃ¹ng, cÃ¢u há»i chÃ­nh váº«n cÃ²n má»Ÿ: lÃ m tháº¿ nÃ o Ä‘á»ƒ táº­n dá»¥ng cÃ¡c ká»¹ thuáº­t DL cho Ä‘á»‹nh vá»‹ lá»—i, cho sá»± khan hiáº¿m dá»¯ liá»‡u cá»¥ thá»ƒ cá»§a dá»± Ã¡n.

Trong lÄ©nh vá»±c NLP, cÃ¢u há»i nÃ y Ä‘Ã£ Ä‘Æ°á»£c tráº£ lá»i vá»›i má»™t sá»‘ thÃ nh cÃ´ng báº±ng cÃ¡c ká»¹ thuáº­t TÄƒng cÆ°á»ng Dá»¯ liá»‡u (DA), mÃ  nÃ³i chung, cÃ³ thá»ƒ Ä‘Æ°á»£c mÃ´ táº£ lÃ  cÃ¡c chiáº¿n lÆ°á»£c Ä‘á»ƒ tÄƒng má»™t cÃ¡ch nhÃ¢n táº¡o sá»‘ lÆ°á»£ng vÃ  Ä‘a dáº¡ng cá»§a cÃ¡c máº«u huáº¥n luyá»‡n dá»±a trÃªn dá»¯ liá»‡u hiá»‡n cÃ³ [11]. DA nháº±m táº¡o ra dá»¯ liá»‡u tá»•ng há»£p cháº¥t lÆ°á»£ng cao báº±ng cÃ¡ch Ã¡p dá»¥ng cÃ¡c biáº¿n Ä‘á»•i lÃªn dá»¯ liá»‡u cÃ³ sáºµn, trong khi duy trÃ¬ tÃ­nh báº¥t biáº¿n cá»§a nhÃ£n. Káº¿t quáº£ lÃ , kÃ­ch thÆ°á»›c cá»§a táº­p dá»¯ liá»‡u gá»‘c tÄƒng lÃªn, Ä‘iá»u nÃ y láº§n lÆ°á»£t cho phÃ©p huáº¥n luyá»‡n má»™t mÃ´ hÃ¬nh DL cho cÃ¡c lÄ©nh vá»±c vÃ  tÃ¡c vá»¥ tÃ i nguyÃªn tháº¥p.

ÄÆ°á»£c khuyáº¿n khÃ­ch bá»Ÿi nhá»¯ng tiáº¿n bá»™ gáº§n Ä‘Ã¢y cá»§a DA trong lÄ©nh vá»±c NLP, trong cÃ´ng trÃ¬nh nÃ y, chÃºng tÃ´i nháº±m khÃ¡m phÃ¡ tÄƒng cÆ°á»ng dá»¯ liá»‡u cho cÃ¡c bÃ¡o cÃ¡o lá»—i vá»›i má»¥c tiÃªu táº¡o ra má»™t sá»‘ lÆ°á»£ng lá»›n cÃ¡c bÃ¡o cÃ¡o lá»—i tá»•ng há»£p cháº¥t lÆ°á»£ng cao, thá»±c táº¿, cÃ³ thá»ƒ Ä‘Æ°á»£c sá»­ dá»¥ng sau Ä‘Ã³ Ä‘á»ƒ tÄƒng kÃ­ch thÆ°á»›c cá»§a táº­p huáº¥n luyá»‡n cho má»™t mÃ´ hÃ¬nh DL Ä‘á»‹nh vá»‹ lá»—i. Äá»ƒ Ä‘áº¡t Ä‘Æ°á»£c Ä‘iá»u nÃ y, chÃºng tÃ´i Ä‘á» xuáº¥t hai táº­p há»£p cÃ¡c toÃ¡n tá»­ DA hoáº¡t Ä‘á»™ng Ä‘á»™c láº­p trÃªn vÄƒn báº£n ngÃ´n ngá»¯ tá»± nhiÃªn vÃ  dá»¯ liá»‡u liÃªn quan Ä‘áº¿n mÃ£ (vÃ­ dá»¥: token mÃ£, stack trace vÃ  Ä‘oáº¡n mÃ£) trong má»—i bÃ¡o cÃ¡o lá»—i. Cá»¥ thá»ƒ hÆ¡n, vÄƒn báº£n ngÃ´n ngá»¯ tá»± nhiÃªn Ä‘Æ°á»£c tÄƒng cÆ°á»ng báº±ng cÃ¡ch sá»­ dá»¥ng cÃ¡c biáº¿n Ä‘á»•i á»Ÿ má»©c token vÃ  Ä‘oáº¡n vÄƒn (vÃ­ dá»¥: chÃ¨n tá»« Ä‘á»“ng nghÄ©a), trong khi dá»¯ liá»‡u liÃªn quan Ä‘áº¿n mÃ£ Ä‘Æ°á»£c tÄƒng cÆ°á»ng vá»›i cÃ¡c token mÃ£ tá»« changeset gÃ¢y ra lá»—i tÆ°Æ¡ng á»©ng cá»§a nÃ³ Ä‘á»ƒ cá»§ng cá»‘ káº¿t ná»‘i giá»¯a má»™t bÃ¡o cÃ¡o lá»—i vÃ  cÃ¡c pháº§n khÃ¡c nhau cá»§a changeset giá»›i thiá»‡u cá»§a nÃ³. Äá»“ng thá»i, báº±ng cÃ¡ch táº­n dá»¥ng cÃ¡c bÃ¡o cÃ¡o lá»—i Ä‘Æ°á»£c tÄƒng cÆ°á»ng, chÃºng tÃ´i dá»± Ä‘á»‹nh Ä‘áº¡t Ä‘Æ°á»£c má»™t má»¥c tiÃªu quan trá»ng khÃ¡c, cÃ¢n báº±ng táº­p dá»¯ liá»‡u Ä‘Æ°á»£c tÄƒng cÆ°á»ng hÆ°á»›ng tá»›i cÃ¡c pháº§n cá»§a mÃ£ nguá»“n chÆ°a Ä‘Æ°á»£c Ä‘áº¡i diá»‡n Ä‘áº§y Ä‘á»§ trong táº­p huáº¥n luyá»‡n ban Ä‘áº§u. Äiá»u nÃ y giáº£i quyáº¿t sá»± xuáº¥t hiá»‡n phá»• biáº¿n trong cÃ¡c dá»± Ã¡n pháº§n má»m ráº±ng cÃ¡c bÃ¡o cÃ¡o lá»—i hiá»‡n cÃ³ chá»‰ tham chiáº¿u má»™t pháº§n cá»¥ thá»ƒ cá»§a cÆ¡ sá»Ÿ mÃ£, trong khi cÃ¡c pháº§n khÃ¡c cÃ³ Ã­t hoáº·c khÃ´ng cÃ³ bÃ¡o cÃ¡o lá»—i, dáº«n Ä‘áº¿n mÃ´ hÃ¬nh Ä‘á»‹nh vá»‹ lá»—i táº­p trung quÃ¡ má»©c chá»‰ vÃ o má»™t pháº§n cá»§a cÆ¡ sá»Ÿ mÃ£. Trong bÃ i bÃ¡o nÃ y, chÃºng tÃ´i Ä‘iá»u tra cÃ¡c CÃ¢u há»i NghiÃªn cá»©u (RQ) sau:

RQ1: (a) TÄƒng cÆ°á»ng Dá»¯ liá»‡u cÃ³ thá»ƒ cáº£i thiá»‡n hiá»‡u suáº¥t truy xuáº¥t cá»§a Ä‘á»‹nh vá»‹ lá»—i dá»±a trÃªn DL khÃ´ng? (b) TÄƒng cÆ°á»ng Dá»¯ liá»‡u tÃ¡c Ä‘á»™ng nhÆ° tháº¿ nÃ o Ä‘áº¿n hiá»‡u suáº¥t cá»§a cÃ¡c phÆ°Æ¡ng phÃ¡p Ä‘á»‹nh vá»‹ lá»—i dá»±a trÃªn DL khÃ¡c nhau?

Äá»ƒ hiá»ƒu liá»‡u TÄƒng cÆ°á»ng Dá»¯ liá»‡u cÃ³ pháº£i lÃ  má»™t chiáº¿n lÆ°á»£c cÃ³ liÃªn quan trong Ä‘á»‹nh vá»‹ lá»—i dá»±a trÃªn DL hay khÃ´ng, chÃºng tÃ´i xÃ¡c Ä‘á»‹nh ba mÃ´ hÃ¬nh dá»±a trÃªn transformer gáº§n Ä‘Ã¢y Ä‘á»ƒ thá»±c hiá»‡n tÃ¡c vá»¥ nÃ y. ChÃºng tÃ´i Ä‘Ã¡nh giÃ¡ hiá»‡u suáº¥t cá»§a cÃ¡c phÆ°Æ¡ng phÃ¡p Ä‘á»‹nh vá»‹ lá»—i nÃ y, cÃ³ vÃ  khÃ´ng cÃ³ DA, sá»­ dá»¥ng má»™t táº­p dá»¯ liá»‡u Ä‘á»‹nh vá»‹ lá»—i tiÃªu chuáº©n vÃ  cÃ¡c chá»‰ sá»‘ thÆ°á»ng Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ Ä‘o lÆ°á»ng hiá»‡u suáº¥t truy xuáº¥t thÃ´ng tin. VÃ¬ tÄƒng cÆ°á»ng nháº¥t thiáº¿t Ä‘Æ°a ra sá»‘ lÆ°á»£ng dá»¯ liá»‡u cao hÆ¡n Ä‘Ã¡ng ká»ƒ, chÃºng tÃ´i thÃªm cÃ¡c baseline vÃ o Ä‘Ã¡nh giÃ¡ nháº±m phÃ¢n biá»‡t sá»‘ lÆ°á»£ng so vá»›i cháº¥t lÆ°á»£ng cá»§a táº­p dá»¯ liá»‡u Ä‘Æ°á»£c tÄƒng cÆ°á»ng. Káº¿t quáº£ chá»‰ ra ráº±ng (1) chiáº¿n lÆ°á»£c tÄƒng cÆ°á»ng dá»¯ liá»‡u Ä‘Æ°á»£c Ä‘á» xuáº¥t cáº£i thiá»‡n Ä‘á»™ chÃ­nh xÃ¡c truy xuáº¥t tá»« 39% Ä‘áº¿n 82%, (2) viá»‡c tÄƒng cÆ°á»ng táº­p dá»¯ liá»‡u cÃ³ lá»£i hÆ¡n so vá»›i viá»‡c tÄƒng kÃ­ch thÆ°á»›c cá»§a táº­p dá»¯ liá»‡u huáº¥n luyá»‡n báº±ng láº·p láº¡i; vÃ  (3) viá»‡c cÃ¢n báº±ng táº­p dá»¯ liá»‡u huáº¥n luyá»‡n dáº«n Ä‘áº¿n cáº£i thiá»‡n hiá»‡u suáº¥t truy xuáº¥t, nhÆ°ng má»©c Ä‘á»™ cáº£i thiá»‡n phá»¥ thuá»™c vÃ o kiáº¿n trÃºc cá»§a mÃ´ hÃ¬nh DL.

RQ2: ToÃ¡n tá»­ DA nÃ o trong sá»‘ cÃ¡c toÃ¡n tá»­ DA Ä‘Æ°á»£c Ä‘á» xuáº¥t Ä‘Ã³ng gÃ³p nhiá»u nháº¥t cho hiá»‡u suáº¥t truy xuáº¥t?

PhÆ°Æ¡ng phÃ¡p TÄƒng cÆ°á»ng Dá»¯ liá»‡u trong RQ1 dá»±a vÃ o cÃ¡c toÃ¡n tá»­ tÄƒng cÆ°á»ng thá»±c hiá»‡n cÃ¡c loáº¡i biáº¿n Ä‘á»•i cá»¥ thá»ƒ (vÃ­ dá»¥: chÃ¨n, xÃ³a). Trong RQ2, chÃºng tÃ´i nháº±m hiá»ƒu tÃ¡c Ä‘á»™ng cá»§a cÃ¡c toÃ¡n tá»­ tÄƒng cÆ°á»ng nÃ y lÃªn hiá»‡u suáº¥t truy xuáº¥t trong quÃ¡ trÃ¬nh Ä‘á»‹nh vá»‹ lá»—i. Äá»ƒ tráº£ lá»i RQ2, chÃºng tÃ´i thá»±c hiá»‡n cÃ¡c nghiÃªn cá»©u ablation, huáº¥n luyá»‡n má»—i mÃ´ hÃ¬nh DL vá»›i cÃ¡c táº­p dá»¯ liá»‡u Ä‘Æ°á»£c tÄƒng cÆ°á»ng Ä‘Æ°á»£c táº¡o ra báº±ng cÃ¡ch sá»­ dá»¥ng táº¥t cáº£ trá»« má»™t loáº¡i toÃ¡n tá»­ tÄƒng cÆ°á»ng. Káº¿t quáº£ chá»‰ ra ráº±ng háº§u háº¿t cÃ¡c toÃ¡n tá»­ Ä‘Ã³ng gÃ³p vÃ o hiá»‡u suáº¥t cuá»‘i cÃ¹ng, trong khi má»™t sá»‘ toÃ¡n tá»­ nháº¥t quÃ¡n hÆ¡n trÃªn cÃ¡c mÃ´ hÃ¬nh DL khÃ¡c nhau.

2 TÄ‚NG CÆ¯á»œNG Dá»® LIá»†U CHO Äá»ŠNH Vá»Š Lá»–I

Vá»›i sá»± phá»©c táº¡p ngÃ y cÃ ng tÄƒng cá»§a cÃ¡c phÆ°Æ¡ng phÃ¡p dá»±a trÃªn DL cho Ä‘á»‹nh vá»‹ lá»—i [6,15,20,26], váº¥n Ä‘á» khan hiáº¿m dá»¯ liá»‡u ná»•i lÃªn trÆ°á»›c máº¯t. Cá»¥ thá»ƒ hÆ¡n, trong khi cÃ¡c mÃ´ hÃ¬nh tiÃªn tiáº¿n hÆ¡n cÃ³ tiá»m nÄƒng thu háº¹p khoáº£ng cÃ¡ch tá»« vá»±ng giá»¯a má»™t bÃ¡o cÃ¡o lá»—i vÃ  mÃ£ nguá»“n [1,64], Ä‘á»ƒ thá»±c hiá»‡n lá»i há»©a Ä‘Ã³, chÃºng yÃªu cáº§u má»™t lÆ°á»£ng lá»›n bÃ¡o cÃ¡o lá»—i Ä‘á»ƒ há»c ngá»¯ nghÄ©a cá»§a dá»± Ã¡n vÃ  sau Ä‘Ã³ liÃªn káº¿t nÃ³ vá»›i cÃ¡c changeset gÃ¢y ra lá»—i. Sá»‘ lÆ°á»£ng vÃ­ dá»¥ huáº¥n luyá»‡n khÃ´ng Ä‘á»§ cÃ³ thá»ƒ dáº«n Ä‘áº¿n overfitting mÃ´ hÃ¬nh, ghi nhá»› cÃ¡c máº«u hoáº·c cáº¥u trÃºc táº§n sá»‘ cao thay vÃ¬ tá»•ng quÃ¡t hÃ³a kiáº¿n thá»©c [45]. DA cÃ³ thá»ƒ giÃºp giáº£i quyáº¿t váº¥n Ä‘á» khan hiáº¿m dá»¯ liá»‡u trong Ä‘á»‹nh vá»‹ lá»—i báº±ng cÃ¡ch táº­p trung vÃ o cÃ¡c má»¥c tiÃªu sau.

1. TÄƒng sá»‘ lÆ°á»£ng bÃ¡o cÃ¡o lá»—i. Huáº¥n luyá»‡n má»™t mÃ´ hÃ¬nh DL cho Ä‘á»‹nh vá»‹ lá»—i yÃªu cáº§u má»™t táº­p dá»¯ liá»‡u Ä‘Ã¡ng ká»ƒ bao gá»“m cÃ¡c bÃ¡o cÃ¡o lá»—i vÃ  changeset gÃ¢y ra lá»—i. ThÃ¡ch thá»©c chÃ­nh trong viá»‡c xÃ¢y dá»±ng táº­p dá»¯ liá»‡u nhÆ° váº­y lÃ  nÃ³ cá»¥ thá»ƒ cho dá»± Ã¡n. Háº§u háº¿t cÃ¡c dá»± Ã¡n pháº§n má»m thÆ°á»ng cÃ³ Ã­t bÃ¡o cÃ¡o lá»—i vá»›i chá»‰ bÃ¡o rÃµ rÃ ng vá» cÃ¡c changeset gÃ¢y ra chÃºng [30]. HÆ¡n ná»¯a, tá»•ng sá»‘ bÃ¡o cÃ¡o lá»—i trong má»™t dá»± Ã¡n lÃ  giá»›i háº¡n trÃªn cá»§a sá»‘ lÆ°á»£ng thá»±c thá»ƒ huáº¥n luyá»‡n tÃ­ch cá»±c cÃ³ sáºµn. LÆ°u Ã½ ráº±ng trong khi chÃºng ta cÃ³ thá»ƒ táº¡o ra nhiá»u thá»±c thá»ƒ Ã¢m (tá»©c lÃ  má»™t bÃ¡o cÃ¡o lá»—i vÃ  má»™t changeset khÃ´ng gÃ¢y ra lá»—i), lá»£i Ã­ch cho mÃ´ hÃ¬nh DL lÃ  háº¡n cháº¿ vÃ¬ bÃ¡o cÃ¡o lá»—i váº«n giá»‘ng nhau trong má»—i thá»±c thá»ƒ. HÆ¡n ná»¯a, trong táº¥t cáº£ cÃ¡c lá»—i Ä‘Æ°á»£c bÃ¡o cÃ¡o, má»™t sá»‘ Ä‘Æ°á»£c Ä‘Ã³ng vá»›i tráº¡ng thÃ¡i Won't fix hoáº·c Not a Bug [24,59], do Ä‘Ã³ chÃºng khÃ´ng cÃ³ changeset tÆ°Æ¡ng á»©ng vÃ  khÃ´ng thá»ƒ Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ huáº¥n luyá»‡n. Äá»ƒ xÃ¡c minh thá»±c nghiá»‡m quy mÃ´ cá»§a váº¥n Ä‘á» khan hiáº¿m dá»¯ liá»‡u trong dá»¯ liá»‡u Ä‘á»‹nh vá»‹ lá»—i, chÃºng tÃ´i Ä‘Ã£ kiá»ƒm tra Bench4BL [27], má»™t táº­p dá»¯ liá»‡u Ä‘á»‹nh vá»‹ lá»—i lá»›n. Bench4BL bao gá»“m 10K bÃ¡o cÃ¡o lá»—i vÃ  cÃ¡c báº£n sá»­a cá»§a chÃºng Ä‘áº¿n tá»« 51 dá»± Ã¡n pháº§n má»m mÃ£ nguá»“n má»Ÿ phá»• biáº¿n vÃ  Ä‘Æ°á»£c phÃ¡t triá»ƒn tÃ­ch cá»±c, tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i khoáº£ng 200 bÃ¡o cÃ¡o lá»—i má»—i dá»± Ã¡n. Xem xÃ©t ráº±ng cÃ¡c dá»± Ã¡n trong táº­p dá»¯ liá»‡u Bench4BL thÆ°á»ng lá»›n vÃ  Ä‘Æ°á»£c thiáº¿t láº­p tá»‘t (vÃ­ dá»¥: cÃ¡c dá»± Ã¡n Apache Software Foundation cháº¡y lÃ¢u dÃ i nhÆ° Camel vÃ  Hive), 200 bÃ¡o cÃ¡o lá»—i lÃ  má»™t con sá»‘ tháº¥p Ä‘Ã¡ng lo khi nÃ³i Ä‘áº¿n kháº£ nÄƒng huáº¥n luyá»‡n má»™t mÃ´ hÃ¬nh DL hiá»‡u quáº£.

2. Duy trÃ¬ tÃ­nh báº¥t biáº¿n nhÃ£n cá»§a bÃ¡o cÃ¡o lá»—i. Trong NLP, tÄƒng cÆ°á»ng dá»¯ liá»‡u chá»§ yáº¿u Ä‘Æ°á»£c Ä‘Ã¡nh giÃ¡ trÃªn cÃ¡c tÃ¡c vá»¥ phÃ¢n loáº¡i, cháº³ng háº¡n nhÆ° phÃ¢n tÃ­ch cáº£m xÃºc hoáº·c phÃ¢n loáº¡i chá»§ Ä‘á», trong Ä‘Ã³ hiáº¿m khi má»™t tá»« Ä‘Æ¡n láº» cÃ³ thá»ƒ Ä‘áº¡i diá»‡n cho káº¿t quáº£ tá»•ng thá»ƒ (tá»©c lÃ  má»™t cáº£m xÃºc hoáº·c má»™t chá»§ Ä‘á»). Dá»¯ liá»‡u trong ká»¹ thuáº­t pháº§n má»m lÃ  sá»± pha trá»™n cá»§a ngÃ´n ngá»¯ tá»± nhiÃªn vÃ  cÃ¡c Ä‘oáº¡n liÃªn quan Ä‘áº¿n mÃ£. Trong trÆ°á»ng há»£p Ä‘á»‹nh vá»‹ lá»—i, sá»± pha trá»™n nÃ y thÆ°á»ng áº£nh hÆ°á»Ÿng Ä‘áº¿n cÃ¡c bÃ¡o cÃ¡o lá»—i, thÆ°á»ng chá»©a khÃ´ng chá»‰ mÃ´ táº£ ngÃ´n ngá»¯ tá»± nhiÃªn mÃ  cÃ²n Ä‘á» cáº­p Ä‘áº¿n cÃ¡c yáº¿u tá»‘ chÆ°Æ¡ng trÃ¬nh cÃ³ liÃªn quan, stack trace hoáº·c Ä‘oáº¡n mÃ£ [1]. Viá»‡c Ã¡p dá»¥ng cÃ¡c biáº¿n Ä‘á»•i tÄƒng cÆ°á»ng dá»¯ liá»‡u cÃ³ sáºµn cho dá»¯ liá»‡u Ä‘á»‹nh vá»‹ lá»—i cÃ³ thá»ƒ gÃ¢y háº¡i nhiá»u hÆ¡n lá»£i vÃ¬ nÃ³ khÃ´ng phÃ¢n biá»‡t giá»¯a NL vÃ  mÃ£, cáº£ hai Ä‘á»u mang láº¡i thÃ´ng tin há»¯u Ã­ch, nhÆ°ng dÆ°á»›i cÃ¡c hÃ¬nh thá»©c vÃ  sá»‘ lÆ°á»£ng khÃ¡c nhau. Báº£ng 1 cho tháº¥y cÃ¡c vÃ­ dá»¥ vá» tÄƒng cÆ°á»ng vÄƒn báº£n Ä‘Æ°á»£c thá»±c hiá»‡n trÃªn tÃ³m táº¯t cá»§a bÃ¡o cÃ¡o lá»—i #55996 tá»« dá»± Ã¡n Tomcat sá»­ dá»¥ng hai toÃ¡n tá»­ tÄƒng cÆ°á»ng Ä‘Æ°á»£c Ä‘á» xuáº¥t bá»Ÿi Wei et al. [57]. Random Swap trao Ä‘á»•i hai tá»« Ä‘Æ°á»£c chá»n ngáº«u nhiÃªn, trong khi Synonym Replacement thay tháº¿ má»™t tá»« Ä‘Æ°á»£c chá»n ngáº«u nhiÃªn báº±ng tá»« Ä‘á»“ng nghÄ©a cá»§a nÃ³. Äá»ƒ tÃ¬m tá»« Ä‘á»“ng nghÄ©a, chÃºng tÃ´i sá»­ dá»¥ng BERTOverflow [49], má»™t mÃ´ hÃ¬nh BERT Ä‘Æ°á»£c tiá»n huáº¥n luyá»‡n trÃªn corpus StackOverflow. Do tÃ­nh ngáº«u nhiÃªn cá»§a cÃ¡c hoáº¡t Ä‘á»™ng tÄƒng cÆ°á»ng dá»¯ liá»‡u, chÃºng ta tháº¥y cÃ¡c phiÃªn báº£n khÃ¡c nhau cá»§a tÃ³m táº¯t bÃ¡o cÃ¡o lá»—i Ä‘Æ°á»£c tÄƒng cÆ°á»ng. Trong khi Random Swap 1 hoÃ¡n Ä‘á»•i hai tá»« mÃ  khÃ´ng áº£nh hÆ°á»Ÿng Ä‘áº¿n ngá»¯ nghÄ©a, Random Swap 2 trao Ä‘á»•i cÃ¡c tá»« cÃ³ thá»ƒ chá»‰ ra thÃ nh pháº§n mÃ£ cÃ³ liÃªn quan, náº¿u má»™t dá»± Ã¡n chá»©a cÃ¡c lá»›p AsyncContext vÃ  AsyncConnector. TÆ°Æ¡ng tá»±, trong trÆ°á»ng há»£p Synonym Replacement 1, viá»‡c thay Ä‘á»•i context thÃ nh session áº£nh hÆ°á»Ÿng Ä‘áº¿n ngá»¯ nghÄ©a Ã­t hÆ¡n so vá»›i viá»‡c thay tháº¿ Async báº±ng TCP, Ä‘Ã¢y lÃ  cÃ¡c khÃ¡i niá»‡m khÃ¡c nhau. VÃ­ dá»¥ Ä‘á»“ chÆ¡i nÃ y cho tháº¥y viá»‡c tÄƒng cÆ°á»ng dá»¯ liá»‡u cÃ³ sáºµn cÃ³ thá»ƒ dá»… dÃ ng Ä‘Æ°a ra nhiá»…u áº£nh hÆ°á»Ÿng Ä‘áº¿n nhÃ£n gá»‘c nhÆ° tháº¿ nÃ o, Ä‘áº·c biá»‡t khi xá»­ lÃ½ dá»¯ liá»‡u chá»©a cÃ¡c cá»¥m tá»« chÃ­nh liÃªn quan Ä‘áº¿n ká»¹ thuáº­t pháº§n má»m. Do Ä‘Ã³, viá»‡c tÄƒng cÆ°á»ng dá»¯ liá»‡u ká»¹ thuáº­t pháº§n má»m nÃ³i chung, vÃ  cÃ¡c bÃ¡o cÃ¡o lá»—i nÃ³i riÃªng, yÃªu cáº§u cÃ¡c bÆ°á»›c bá»• sung Ä‘á»ƒ Ä‘áº£m báº£o tÃ­nh báº¥t biáº¿n cá»§a cÃ¡c Ä‘iá»ƒm dá»¯ liá»‡u má»›i Ä‘Æ°á»£c táº¡o ra.

3. Äa dáº¡ng hÃ³a dá»¯ liá»‡u huáº¥n luyá»‡n. Má»¥c tiÃªu cá»§a Ä‘a dáº¡ng hÃ³a dá»¯ liá»‡u trong DA lÃ  Ä‘áº£m báº£o ráº±ng dá»¯ liá»‡u Ä‘Æ°á»£c tÄƒng cÆ°á»ng Ä‘Æ°a ra "cháº¥t lÆ°á»£ng má»›i" cho má»™t táº­p huáº¥n luyá»‡n, cháº³ng háº¡n nhÆ° cÃ¡c motif, máº«u hoáº·c biá»ƒu thá»©c chÆ°a tá»«ng quan sÃ¡t trÆ°á»›c Ä‘Ã³, dáº«n má»™t mÃ´ hÃ¬nh DL há»c Ã½ nghÄ©a Ä‘áº±ng sau dá»¯ liá»‡u thay vÃ¬ ghi nhá»› má»™t sá»‘ hÃ¬nh thá»©c nháº¥t Ä‘á»‹nh [34,45]. Trong trÆ°á»ng há»£p Ä‘á»‹nh vá»‹ lá»—i, táº­p dá»¯ liá»‡u huáº¥n luyá»‡n mÃ´ táº£ cÃ¡ch ngÃ´n ngá»¯ tá»± nhiÃªn mÃ´ táº£ má»™t lá»—i káº¿t ná»‘i vá»›i cÃ¡c khÃ¡i niá»‡m mÃ£ nguá»“n trong changeset gÃ¢y ra lá»—i. ThÃ´ng thÆ°á»ng, ngÃ´n ngá»¯ tá»± nhiÃªn trong cÃ¡c bÃ¡o cÃ¡o lá»—i bao gá»“m HÃ nh vi Quan sÃ¡t Ä‘Æ°á»£c (OB), HÃ nh vi Mong Ä‘á»£i (EB), hoáº·c CÃ¡c bÆ°á»›c TÃ¡i táº¡o (S2R) [3]. Cho ráº±ng OB, EB vÃ  S2R Ä‘Ã£ Ä‘Æ°á»£c cÃ¡c nhÃ  phÃ¡t triá»ƒn nháº­n ra lÃ  thÃ´ng tin há»¯u Ã­ch khi sá»­a lá»—i [1], viá»‡c tÄƒng cÆ°á»ng cho dá»¯ liá»‡u Ä‘á»‹nh vá»‹ lá»—i nÃªn táº­p trung vÃ o viá»‡c Ä‘Æ°a ra sá»± Ä‘a dáº¡ng vÃ o nhá»¯ng thá»© nÃ y thÃ´ng qua, vÃ­ dá»¥, diá»…n Ä‘áº¡t láº¡i cÃ¡c cÃ¢u cá»§a chÃºng. ThÃ nh pháº§n quan trá»ng thá»© hai cá»§a viá»‡c Ä‘a dáº¡ng hÃ³a má»™t táº­p huáº¥n luyá»‡n Ä‘á»‹nh vá»‹ lá»—i lÃ  cÃ¡c káº¿t ná»‘i giá»¯a bÃ¡o cÃ¡o lá»—i vÃ  mÃ£ nguá»“n. Máº·c dÃ¹ Ä‘Ãºng lÃ  cÃ¡c lá»—i khÃ´ng Ä‘Æ°á»£c phÃ¢n bá»‘ Ä‘á»u trong cÆ¡ sá»Ÿ mÃ£ nguá»“n, viá»‡c Ä‘áº¡i diá»‡n quÃ¡ má»©c má»™t thÃ nh pháº§n mÃ£ nguá»“n (vÃ­ dá»¥: lá»›p, gÃ³i) trong táº­p huáº¥n luyá»‡n cÃ³ thá»ƒ dáº«n Ä‘áº¿n mÃ´ hÃ¬nh Ä‘á»• lá»—i cho thÃ nh pháº§n cá»¥ thá»ƒ Ä‘Ã³ cho má»i lá»—i. Äá»ƒ tÃ­nh Ä‘áº¿n Ä‘iá»u Ä‘Ã³, trong khi tÄƒng cÆ°á»ng táº­p huáº¥n luyá»‡n cho Ä‘á»‹nh vá»‹ lá»—i, cÃ¡c bÆ°á»›c bá»• sung cÃ³ thá»ƒ Ä‘Æ°á»£c thá»±c hiá»‡n Ä‘á»ƒ giáº£m thiá»ƒu rá»§i ro Ä‘Ã³, thÃ´ng qua, vÃ­ dá»¥, táº¡o ra nhiá»u bÃ¡o cÃ¡o lá»—i Ä‘Æ°á»£c tÄƒng cÆ°á»ng hÆ¡n cho nhá»¯ng thÃ nh pháº§n mÃ£ nguá»“n xuáº¥t hiá»‡n Ã­t thÆ°á»ng xuyÃªn hÆ¡n trong táº­p huáº¥n luyá»‡n. TÃ³m láº¡i, viá»‡c Ä‘a dáº¡ng hÃ³a dá»¯ liá»‡u huáº¥n luyá»‡n nÃªn táº­p trung vÃ o: (1) sá»­a Ä‘á»•i ná»™i dung ngÃ´n ngá»¯ tá»± nhiÃªn cá»§a má»™t bÃ¡o cÃ¡o lá»—i, vÃ  (2) Ä‘a dáº¡ng hÃ³a cÃ¡ch má»™t bÃ¡o cÃ¡o lá»—i káº¿t ná»‘i vá»›i mÃ£ nguá»“n.

3 PHÆ¯Æ NG PHÃP

Äá»ƒ táº¡o ra cÃ¡c bÃ¡o cÃ¡o lá»—i Ä‘Æ°á»£c tÄƒng cÆ°á»ng Ä‘Æ°a ra sá»± Ä‘a dáº¡ng vÃ  báº£o tá»“n tÃ­nh báº¥t biáº¿n (tá»©c lÃ  bÃ¡o cÃ¡o lá»—i Ä‘Æ°á»£c tÄƒng cÆ°á»ng váº«n khá»›p vá»›i cÃ¹ng má»™t changeset nhÆ° bÃ¡o cÃ¡o lá»—i gá»‘c), chÃºng tÃ´i Ä‘á» xuáº¥t má»™t táº­p há»£p cÃ¡c toÃ¡n tá»­ DA tÃ¹y chá»‰nh. CÃ¡c bÃ¡o cÃ¡o lá»—i mÃ´ táº£ sá»± cá»‘ pháº§n má»m báº±ng cÃ¡ch sá»­ dá»¥ng cÃ¡c loáº¡i thÃ´ng tin khÃ¡c nhau, cháº³ng háº¡n nhÆ° ngÃ´n ngá»¯ tá»± nhiÃªn, Ä‘oáº¡n mÃ£ hoáº·c stack trace, cÃ³ thá»ƒ cÃ³ tÃ¡c Ä‘á»™ng khÃ¡c nhau Ä‘áº¿n viá»‡c khá»›p má»™t bÃ¡o cÃ¡o lá»—i vá»›i changeset gÃ¢y ra cá»§a nÃ³, do Ä‘Ã³ chÃºng tÃ´i quyáº¿t Ä‘á»‹nh tÄƒng cÆ°á»ng riÃªng biá»‡t thÃ´ng tin ngÃ´n ngá»¯ tá»± nhiÃªn vÃ  thÃ´ng tin liÃªn quan Ä‘áº¿n mÃ£ Ä‘á»ƒ Ä‘áº£m báº£o tÃ­nh báº¥t biáº¿n cá»§a cÃ¡c Ä‘iá»ƒm dá»¯ liá»‡u má»›i Ä‘Æ°á»£c táº¡o ra vÃ  trÃ¡nh Ä‘Æ°a ra nhiá»…u. HÃ¬nh 1 minh há»a quy trÃ¬nh lÃ m viá»‡c cá»§a quÃ¡ trÃ¬nh tÄƒng cÆ°á»ng dá»¯ liá»‡u cá»§a chÃºng tÃ´i báº¯t Ä‘áº§u vá»›i viá»‡c trÃ­ch xuáº¥t vÃ  tiá»n xá»­ lÃ½ dá»¯ liá»‡u, tiáº¿p theo lÃ  tÄƒng cÆ°á»ng vá»›i cÃ¡c toÃ¡n tá»­ Ä‘Æ°á»£c Ä‘á» xuáº¥t, vÃ  xÃ¢y dá»±ng cÃ¡c bÃ¡o cÃ¡o lá»—i Ä‘Æ°á»£c tÄƒng cÆ°á»ng káº¿t há»£p dá»¯ liá»‡u má»›i Ä‘Æ°á»£c táº¡o ra.

3.1 Tiá»n xá»­ lÃ½ dá»¯ liá»‡u

NhÆ° má»™t bÆ°á»›c Ä‘áº§u tiÃªn, chÃºng tÃ´i sá»­ dá»¥ng infozilla [39], má»™t cÃ´ng cá»¥ trÃ­ch xuáº¥t stack trace vÃ  Ä‘oáº¡n mÃ£ tá»« ná»™i dung bÃ¡o cÃ¡o lá»—i khÃ´ng cÃ³ cáº¥u trÃºc, Ä‘á»ƒ láº¡i vÄƒn báº£n cÃ²n láº¡i Ä‘Æ°á»£c phÃ¢n loáº¡i rá»™ng rÃ£i lÃ  ngÃ´n ngá»¯ tá»± nhiÃªn. Infozilla táº¡o ra lá»—i tá»‘i thiá»ƒu vÃ¬ cÃ¡c thÃ­ nghiá»‡m Ä‘Ã£ cho tháº¥y nÃ³ cÃ³ Ä‘á»™ chÃ­nh xÃ¡c 97%+, recall 95%+ vÃ  accuracy 97%+. Äá»ƒ Ä‘Æ°a ra cáº¥u trÃºc sÃ¢u hÆ¡n tá»« dá»¯ liá»‡u ngÃ´n ngá»¯ tá»± nhiÃªn, chÃºng tÃ´i trÃ­ch xuáº¥t HÃ nh vi Quan sÃ¡t Ä‘Æ°á»£c (OB), HÃ nh vi Mong Ä‘á»£i (EB), vÃ  CÃ¡c bÆ°á»›c TÃ¡i táº¡o (S2R) báº±ng cÃ¡ch sá»­ dá»¥ng cÃ´ng cá»¥ BEE [48], Ä‘Ã£ Ä‘Æ°á»£c chá»©ng minh lÃ  ráº¥t hiá»‡u quáº£ trong tÃ¡c vá»¥ nÃ y (accuracy 94%+, recall 87%+, precision 70%+).

Stack trace lÃ  má»™t nguá»“n gá»£i Ã½ Ä‘á»‹nh vá»‹ cÃ³ giÃ¡ trá»‹, tuy nhiÃªn, do Ä‘á»™ dÃ i cá»§a chÃºng, chÃºng cÃ³ xu hÆ°á»›ng Ä‘Æ°a ra nhiá»…u thÃ´ng qua viá»‡c Ä‘á» cáº­p nhiá»u láº§n cÃ¡c lá»›p khÃ´ng nháº¥t thiáº¿t liÃªn quan Ä‘áº¿n má»™t bÃ¡o cÃ¡o lá»—i cá»¥ thá»ƒ [6,40]. Äá»ƒ giáº£m thiá»ƒu nhiá»…u trong stack trace, chÃºng tÃ´i giáº£m kÃ­ch thÆ°á»›c cá»§a chÃºng báº±ng cÃ¡ch chá»n cÃ¡c dÃ²ng cÃ³ kháº£ nÄƒng chá»©a thÃ´ng tin cÃ³ liÃªn quan nháº¥t. VÃ­ dá»¥, Ä‘á»‘i vá»›i stack trace Java, Ä‘iá»u nÃ y dáº«n Ä‘áº¿n ba nhÃ³m: 1) cÃ¡c dÃ²ng Ä‘áº§u, bao gá»“m tÃªn exception vÃ  nÆ¡i exception báº¯t nguá»“n; 2) cÃ¡c dÃ²ng giá»¯a, xuáº¥t hiá»‡n sau cÃ¡c trace thÆ° viá»‡n chuáº©n Java vÃ  cÃ³ kháº£ nÄƒng lÃ  cÃ¡c dÃ²ng cuá»‘i cÃ¹ng cá»§a mÃ£ á»©ng dá»¥ng gáº§n nháº¥t vá»›i lá»—i; vÃ  3) cÃ¡c dÃ²ng dÆ°á»›i, cÃ³ thá»ƒ há»¯u Ã­ch cho cÃ¡c exception Ä‘Æ°á»£c nÃ©m tá»« cÃ¡c thread. Viá»‡c láº¥y máº«u tá»« ba nhÃ³m nÃ y táº¡o ra má»™t cÃ´ng thá»©c chung rÃºt ngáº¯n stack trace, báº¯t Ä‘Æ°á»£c cÃ¡c thiáº¿t káº¿ pháº§n má»m khÃ¡c nhau, vÃ  báº£o tá»“n thÃ´ng tin quan trá»ng. Do Ä‘Ã³, Ä‘á»‘i vá»›i má»—i stack trace, chÃºng tÃ´i quyáº¿t Ä‘á»‹nh giá»¯ láº¡i 1 dÃ²ng Ä‘áº§u, 3 dÃ²ng Ä‘áº§u tiÃªn tham chiáº¿u Ä‘áº¿n mÃ£ á»©ng dá»¥ng, vÃ  1 dÃ²ng dÆ°á»›i. CÃ¡c phÆ°Æ¡ng phÃ¡p heuristic nhÆ° tháº¿ nÃ y Ä‘Ã£ Ä‘Æ°á»£c bÃ¡o cÃ¡o lÃ  hoáº¡t Ä‘á»™ng khÃ¡ tá»‘t ngay cáº£ trÃªn dá»¯ liá»‡u runtime khÃ´ng cÃ³ cáº¥u trÃºc (vÃ­ dá»¥: nháº­t kÃ½ sá»± cá»‘ thÃ´ vá»›i nhiá»u stack trace, cÃ³ thá»ƒ tá»« cÃ¡c ngÃ´n ngá»¯ láº­p trÃ¬nh khÃ¡c nhau) [38].

Äá»ƒ tiá»n xá»­ lÃ½ Ä‘oáº¡n mÃ£, chÃºng tÃ´i quyáº¿t Ä‘á»‹nh lá»c bá» dáº¥u cÃ¢u vÃ¬ hai lÃ½ do. Äáº§u tiÃªn, trong má»™t nghiÃªn cá»©u Ä‘Æ°á»£c cÃ´ng bá»‘ gáº§n Ä‘Ã¢y, Paltenghi et al. [36] so sÃ¡nh lÃ½ luáº­n cá»§a cÃ¡c nhÃ  phÃ¡t triá»ƒn vÃ  mÃ´ hÃ¬nh neural, vÃ  quan sÃ¡t ráº±ng cÃ¡c mÃ´ hÃ¬nh chÃº Ã½ nhiá»u hÆ¡n Ä‘áº¿n cÃ¡c token cÃº phÃ¡p (vÃ­ dá»¥: dáº¥u cháº¥m, dáº¥u cháº¥m, dáº¥u ngoáº·c), trong khi cÃ¡c nhÃ  phÃ¡t triá»ƒn táº­p trung nhiá»u hÆ¡n vÃ o chuá»—i hoáº·c tá»« khÃ³a. Cho ráº±ng cÃ¡c nhÃ  phÃ¡t triá»ƒn hoáº¡t Ä‘á»™ng tá»‘t hÆ¡n, cÃ¡c mÃ´ hÃ¬nh DL nÃªn báº¯t chÆ°á»›c cÃ¡c nhÃ  phÃ¡t triá»ƒn vÃ  chÃº Ã½ Ã­t hÆ¡n Ä‘áº¿n cÃ¡c token cÃº phÃ¡p. LÃ½ do thá»© hai Ä‘á»ƒ lá»c dáº¥u cÃ¢u lÃ  thá»±c dá»¥ng - giáº£m sá»‘ lÆ°á»£ng token Ä‘á»ƒ trÃ¡nh vÆ°á»£t quÃ¡ giá»›i háº¡n kÃ­ch thÆ°á»›c Ä‘áº§u vÃ o cá»§a cÃ¡c mÃ´ hÃ¬nh DL. Sau tiá»n xá»­ lÃ½, má»—i bÃ¡o cÃ¡o lá»—i Ä‘Æ°á»£c Ä‘áº¡i diá»‡n nhÆ° má»™t táº­p há»£p OB, EB, S2R, stack trace, vÃ  Ä‘oáº¡n mÃ£.

3.2 ToÃ¡n tá»­ DA ngÃ´n ngá»¯ tá»± nhiÃªn

NhÃ³m toÃ¡n tá»­ nÃ y Ä‘Æ°á»£c Ã¡p dá»¥ng cho OB, EB, vÃ  S2R do ná»™i dung ngÃ´n ngá»¯ tá»± nhiÃªn chá»§ yáº¿u cá»§a chÃºng. ChÃºng tÃ´i Ä‘á» xuáº¥t sá»­ dá»¥ng hai loáº¡i toÃ¡n tá»­: má»©c token vÃ  má»©c Ä‘oáº¡n vÄƒn. ÄÆ°á»£c truyá»n cáº£m há»©ng bá»Ÿi má»™t ká»¹ thuáº­t Ä‘Æ¡n giáº£n nhÆ°ng hiá»‡u quáº£ gá»i lÃ  Easy Data Augmentation (EDA) [57], chÃºng tÃ´i Ä‘á» xuáº¥t sá»­ dá»¥ng 4 toÃ¡n tá»­ má»©c token.

â€¢ Dictionary Replace - chá»n ngáº«u nhiÃªn má»™t tá»« tá»« má»™t tá»« Ä‘iá»ƒn trong lÄ©nh vá»±c Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh trÆ°á»›c vÃ  thay tháº¿ tá»« Ä‘Ã³ báº±ng tá»« thay tháº¿ cá»§a nÃ³.
â€¢ Dictionary Insert - hoáº¡t Ä‘á»™ng tÆ°Æ¡ng tá»± nhÆ° Dictionary Replace, tuy nhiÃªn thay vÃ¬ thay tháº¿ tá»«, toÃ¡n tá»­ nÃ y chÃ¨n tá»« thay tháº¿ vÃ o má»™t vá»‹ trÃ­ ngáº«u nhiÃªn trong vÄƒn báº£n.
â€¢ Random Swap - chá»n ngáº«u nhiÃªn hai tá»« vÃ  hoÃ¡n Ä‘á»•i chÃºng.
â€¢ Random Delete - xÃ³a má»™t tá»« Ä‘Æ°á»£c chá»n ngáº«u nhiÃªn.

Äá»ƒ xÃ¢y dá»±ng tá»« Ä‘iá»ƒn trong lÄ©nh vá»±c Ä‘á»ƒ tÄƒng cÆ°á»ng OB, EB vÃ  S2R, chÃºng tÃ´i sá»­ dá»¥ng tá»« khÃ³a tá»« cÃ¡c máº«u ngÃ´n ngá»¯ Ä‘Æ°á»£c thiáº¿t káº¿ bá»Ÿi Chaparro et al. [4]. CÃ¡c máº«u chá»‰ Ä‘á»‹nh sá»± káº¿t há»£p cá»§a cÃ¡c pháº§n khÃ¡c nhau cá»§a lá»i nÃ³i vá»›i cÃ¡c tá»« khÃ³a nháº¥t Ä‘á»‹nh pháº£i xuáº¥t hiá»‡n Ä‘á»ƒ phÃ¢n loáº¡i má»™t cÃ¢u hoáº·c má»™t Ä‘oáº¡n vÄƒn lÃ  OB, EB hoáº·c S2R. VÃ­ dá»¥, má»™t trong nhá»¯ng máº«u OB phá»• biáº¿n nháº¥t lÃ  NEG_VERB Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a lÃ : (chá»§ ngá»¯/cá»¥m danh tá»«) ([tÃ­nh tá»«/tráº¡ng tá»«]) [Ä‘á»™ng tá»« phá»§ Ä‘á»‹nh] ([bá»• ngá»¯]), trong Ä‘Ã³ cÃ¡c Ä‘á»™ng tá»« phá»§ Ä‘á»‹nh Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a lÃ : affect, break, block, close, v.v. Tá»« Ä‘iá»ƒn trong lÄ©nh vá»±c chá»©a táº¥t cáº£ cÃ¡c tá»« khÃ³a Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh bá»Ÿi Chapparo et al. vÃ  Ã¡nh xáº¡ má»—i tá»« khÃ³a vá»›i cÃ¡c tá»« thay tháº¿ cá»§a nÃ³, vÃ­ dá»¥: affectâ†’{break, block, close, ...}. CÃ¡c toÃ¡n tá»­ Ä‘Æ°á»£c hÆ°á»›ng dáº«n bá»Ÿi kiáº¿n thá»©c lÄ©nh vá»±c gáº§n Ä‘Ã¢y Ä‘Ã£ Ä‘Æ°á»£c chá»©ng minh lÃ  dáº«n Ä‘áº¿n hiá»‡u suáº¥t tá»‘t hÆ¡n so vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p tiÃªn tiáº¿n hÆ¡n nhÆ°ng tá»•ng quÃ¡t (vÃ­ dá»¥: embeddings) [25].

NhÆ° má»™t toÃ¡n tá»­ má»©c Ä‘oáº¡n vÄƒn, chÃºng tÃ´i sá»­ dá»¥ng Backtranslation Ä‘á»ƒ dá»‹ch cÃ¡c Ä‘oáº¡n vÄƒn OB, EB hoáº·c S2R tá»« tiáº¿ng Anh sang tiáº¿ng Äá»©c vÃ  ngÆ°á»£c láº¡i sang tiáº¿ng Anh [32]. Backtranslation lÃ  má»™t hoáº¡t Ä‘á»™ng tÄƒng cÆ°á»ng dá»¯ liá»‡u phá»• biáº¿n cho phÃ©p diá»…n Ä‘áº¡t láº¡i vÄƒn báº£n gá»‘c.

Cuá»‘i cÃ¹ng, hÃ£y Ä‘á»ƒ chÃºng tÃ´i mÃ´ táº£ cÃ¡ch nhá»¯ng toÃ¡n tá»­ nÃ y Ä‘Æ°á»£c Ã¡p dá»¥ng cÃ¹ng nhau Ä‘á»ƒ táº¡o ra dá»¯ liá»‡u Ä‘Æ°á»£c tÄƒng cÆ°á»ng. Äá»‘i vá»›i má»—i bÃ¡o cÃ¡o lá»—i vÃ  cho má»—i OB, EB, S2R, chÃºng tÃ´i Ã¡p dá»¥ng táº¥t cáº£ cÃ¡c toÃ¡n tá»­ má»©c token ğ‘› láº§n, trong Ä‘Ã³ ğ‘›=ğœ†âˆ—#ğ‘¡ğ‘œğ‘˜ğ‘’ğ‘›ğ‘ . CÃ¡c toÃ¡n tá»­ Ä‘Æ°á»£c Ã¡p dá»¥ng theo thá»© tá»± sau: replace, insert, swap vÃ  delete. GiÃ¡ trá»‹ cá»§a ğœ† Ä‘Æ°á»£c Ä‘áº·t thÃ nh 0.1 cho cÃ¡c hoáº¡t Ä‘á»™ng insert, replace, vÃ  swap, vÃ  0.05 cho hoáº¡t Ä‘á»™ng delete vÃ¬ nhá»¯ng tham sá»‘ nÃ y Ä‘Ã£ Ä‘Æ°á»£c chá»©ng minh thá»±c nghiá»‡m lÃ  táº¡o ra káº¿t quáº£ tá»‘t nháº¥t [66]. Tiáº¿p theo, toÃ¡n tá»­ Backtranslation Ä‘Æ°á»£c Ã¡p dá»¥ng Ä‘á»ƒ diá»…n Ä‘áº¡t láº¡i vÄƒn báº£n Ä‘Ã£ Ä‘Æ°á»£c sá»­a Ä‘á»•i. Do tÃ­nh ngáº«u nhiÃªn cá»§a cÃ¡c toÃ¡n tá»­ tÄƒng cÆ°á»ng, cháº¥t lÆ°á»£ng cá»§a máº«u Ä‘Æ°á»£c tÄƒng cÆ°á»ng cÃ³ thá»ƒ khÃ¡c nhau. Máº·c dÃ¹, nÃ³i chung, vÄƒn báº£n ngÃ´n ngá»¯ tá»± nhiÃªn thÆ°á»ng giá»¯ nguyÃªn ngá»¯ nghÄ©a cá»§a nÃ³ khi nhiá»…u nhá» Ä‘Æ°á»£c Ä‘Æ°a vÃ o, cÃ¡c bÃ¡o cÃ¡o lá»—i lÃ  loáº¡i dá»¯ liá»‡u cÃ³ cáº¥u trÃºc hÆ¡n vá»›i cÃ¡c tá»« khÃ³a nháº¥t Ä‘á»‹nh (vÃ­ dá»¥: tÃªn mÃ£), viá»‡c loáº¡i bá» chÃºng cÃ³ thá»ƒ cÃ³ háº­u quáº£ nghiÃªm trá»ng Ä‘á»‘i vá»›i viá»‡c Ã¡nh xáº¡ bÃ¡o cÃ¡o lá»—i vá»›i mÃ£ nguá»“n. Do Ä‘Ã³, nhÆ° má»™t bÆ°á»›c cuá»‘i cÃ¹ng, chÃºng tÃ´i sá»­ dá»¥ng kiá»ƒm soÃ¡t cháº¥t lÆ°á»£ng bao gá»“m hai bÆ°á»›c. Äáº§u tiÃªn, chÃºng tÃ´i kiá»ƒm tra xem OB, EB vÃ /hoáº·c S2R cÃ³ thá»ƒ váº«n Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh trong Ä‘oáº¡n vÄƒn Ä‘Æ°á»£c tÄƒng cÆ°á»ng báº±ng cÃ¡ch sá»­ dá»¥ng cÃ´ng cá»¥ BEE hay khÃ´ng. VÃ­ dá»¥, náº¿u Ä‘oáº¡n vÄƒn gá»‘c chá»©a OB vÃ  EB, thÃ¬ phiÃªn báº£n Ä‘Æ°á»£c tÄƒng cÆ°á»ng pháº£i chá»©a OB vÃ  EB má»›i Ä‘Æ°á»£c coi lÃ  má»™t Ä‘oáº¡n vÄƒn há»£p lá»‡. ChÃºng tÃ´i cÅ©ng khÃ´ng cho phÃ©p thay Ä‘á»•i máº«u (vÃ­ dá»¥: tá»« OB thÃ nh EB). Thá»© hai, chÃºng tÃ´i Ä‘áº£m báº£o ráº±ng khÃ´ng cÃ³ token mÃ£ nÃ o bá»‹ máº¥t trong quÃ¡ trÃ¬nh tÄƒng cÆ°á»ng báº±ng cÃ¡ch so sÃ¡nh sá»‘ lÆ°á»£ng token mÃ£ giá»¯a Ä‘oáº¡n vÄƒn Ä‘Æ°á»£c tÄƒng cÆ°á»ng vÃ  Ä‘oáº¡n vÄƒn gá»‘c.

3.3 ToÃ¡n tá»­ DA liÃªn quan Ä‘áº¿n mÃ£

Trong bá»‘i cáº£nh cá»§a bÃ i bÃ¡o nÃ y, dá»¯ liá»‡u liÃªn quan Ä‘áº¿n mÃ£ Ä‘á» cáº­p Ä‘áº¿n stack trace, Ä‘oáº¡n mÃ£, vÃ  cÃ¡c token mÃ£ cÃ³ máº·t trong vÄƒn báº£n ngÃ´n ngá»¯ tá»± nhiÃªn. Äá»ƒ tÄƒng cÆ°á»ng dá»¯ liá»‡u liÃªn quan Ä‘áº¿n mÃ£, chÃºng tÃ´i Ä‘á» xuáº¥t 3 toÃ¡n tá»­ token mÃ£ lÃ  cÃ¡c phiÃªn báº£n nghiÃªm ngáº·t hÆ¡n cá»§a cÃ¡c toÃ¡n tá»­ ngÃ´n ngá»¯ tá»± nhiÃªn Ä‘á»ƒ giáº£m thiá»ƒu rá»§i ro lÃ m mÃ©o mÃ³ ngá»¯ cáº£nh.

â€¢ Code Token Replace - chá»n ngáº«u nhiÃªn má»™t token mÃ£ vÃ  thay tháº¿ nÃ³ báº±ng tá»« thay tháº¿ cá»§a nÃ³.
â€¢ Code Token Insert - chá»n ngáº«u nhiÃªn má»™t token mÃ£, vÃ  chÃ¨n má»™t tá»« thay tháº¿ cá»§a token mÃ£ Ä‘Ã³ vÃ o má»™t vá»‹ trÃ­ ngáº«u nhiÃªn cÃ¡ch tá»‘i Ä‘a 3 vá»‹ trÃ­ tá»« token mÃ£ Ä‘Æ°á»£c chá»n.
â€¢ Code Token Swap - hoÃ¡n Ä‘á»•i hai token mÃ£ Ä‘Æ°á»£c chá»n ngáº«u nhiÃªn, sao cho (1) Ä‘á»‘i vá»›i stack trace, cÃ¡c token mÃ£ chá»‰ cÃ³ thá»ƒ Ä‘Æ°á»£c hoÃ¡n Ä‘á»•i giá»¯a cÃ¡c dÃ²ng stack liÃªn tiáº¿p; (2) Ä‘á»‘i vá»›i Ä‘oáº¡n mÃ£, má»™t hoáº¡t Ä‘á»™ng hoÃ¡n Ä‘á»•i pháº£i Ä‘Æ°á»£c thá»±c hiá»‡n trong vÃ²ng 3 token xung quanh Ä‘á»ƒ giáº£m thiá»ƒu kháº£ nÄƒng lÃ m mÃ©o mÃ³ ngá»¯ nghÄ©a cá»§a bÃ¡o cÃ¡o lá»—i. Thay Ä‘á»•i Ä‘iá»u nÃ y thÃ nh má»™t giá»›i háº¡n lá»›n hÆ¡n sáº½ dáº«n Ä‘áº¿n viá»‡c táº¡o ra nhiá»u máº«u Ä‘a dáº¡ng hÆ¡n, tuy nhiÃªn, vá»›i kháº£ nÄƒng cao hÆ¡n lÃ m xÃ¡o trá»™n ngá»¯ nghÄ©a cá»§a bÃ¡o cÃ¡o lá»—i.

ChÃºng tÃ´i quyáº¿t Ä‘á»‹nh khÃ´ng bao gá»“m má»™t toÃ¡n tá»­ xÃ³a token mÃ£ vÃ¬ viá»‡c loáº¡i bá» token mÃ£ cÃ³ kháº£ nÄƒng cao hÆ¡n lÃ m xÃ¡o trá»™n tÃ­nh báº¥t biáº¿n cá»§a cÃ¡c máº«u Ä‘Æ°á»£c tÄƒng cÆ°á»ng.

Äá»ƒ tÃ¬m tá»« thay tháº¿ cho má»™t token mÃ£, Ä‘áº§u tiÃªn, Ä‘á»‘i vá»›i má»—i bÃ¡o cÃ¡o lá»—i, chÃºng tÃ´i xÃ¢y dá»±ng má»™t tá»« Ä‘iá»ƒn tÃªn mÃ£ sá»­ dá»¥ng tÃªn lá»›p vÃ  phÆ°Æ¡ng thá»©c xuáº¥t hiá»‡n trong cÃ¡c changeset gÃ¢y ra lá»—i tÆ°Æ¡ng á»©ng cá»§a nÃ³. Tiáº¿p theo, chÃºng tÃ´i sá»­ dá»¥ng khoáº£ng cÃ¡ch Levenshtein Ä‘á»ƒ Ä‘o khoáº£ng cÃ¡ch giá»¯a token mÃ£ Ä‘Æ°á»£c chá»n vÃ  táº¥t cáº£ cÃ¡c token khÃ¡c trong tá»« Ä‘iá»ƒn. Khoáº£ng cÃ¡ch Levenshtein lÃ  má»™t chá»‰ sá»‘ tÆ°Æ¡ng tá»± chuá»—i Ä‘á»‹nh lÆ°á»£ng tÆ°Æ¡ng tá»± thÃ´ng qua sá»‘ láº§n chá»‰nh sá»­a cáº§n thiáº¿t Ä‘á»ƒ chuyá»ƒn Ä‘á»•i má»™t chuá»—i thÃ nh chuá»—i khÃ¡c cho cÃ¡c chuá»—i cÃ³ Ä‘á»™ dÃ i tÃ¹y Ã½. ChÃºng tÃ´i quan sÃ¡t thá»±c nghiá»‡m ráº±ng cÃ¡c token mÃ£ tÆ°Æ¡ng tá»± nháº¥t thÆ°á»ng cÃ³ cÃ¹ng dáº¡ng, vÃ  do Ä‘Ã³, cÃ³ thá»ƒ Ä‘Æ°a ra sá»± Ä‘a dáº¡ng ráº¥t háº¡n cháº¿ vÃ o cÃ¡c máº«u Ä‘Æ°á»£c tÄƒng cÆ°á»ng. VÃ­ dá»¥, xem xÃ©t token mÃ£ word vá»›i cÃ¡c token gáº§n nháº¥t top-3 lÃ  is_word, set_word, get_word, vÃ  token top-20 check_word_missing_letter. Äá»ƒ cho phÃ©p tÄƒng cÆ°á»ng Ä‘a dáº¡ng hÆ¡n, dá»±a trÃªn cÃ¡c quan sÃ¡t thá»±c nghiá»‡m cho má»™t trong cÃ¡c dá»± Ã¡n Ä‘Ã¡nh giÃ¡, chÃºng tÃ´i Ä‘Ã£ chá»n má»™t lá»±a chá»n top-ğ‘˜ Ã­t báº£o thá»§ hÆ¡n, vá»›i ğ‘˜ Ä‘Æ°á»£c Ä‘áº·t thÃ nh 20. Do Ä‘Ã³, má»™t tá»« thay tháº¿ token mÃ£ Ä‘Æ°á»£c chá»n ngáº«u nhiÃªn tá»« 20 token mÃ£ cÃ³ khoáº£ng cÃ¡ch Levenshtein tháº¥p nháº¥t tá»« token mÃ£ Ä‘Ã£ cho.

3.4 XÃ¢y dá»±ng bÃ¡o cÃ¡o lá»—i Ä‘Æ°á»£c tÄƒng cÆ°á»ng

Sau khi tÄƒng cÆ°á»ng, má»—i bÃ¡o cÃ¡o lá»—i Ä‘Æ°á»£c phÃ¢n tÃ¡ch thÃ nh má»™t táº­p há»£p cÃ¡c máº«u gá»‘c vÃ  Ä‘Æ°á»£c tÄƒng cÆ°á»ng, tá»©c lÃ  dá»¯ liá»‡u ngÃ´n ngá»¯ tá»± nhiÃªn (OB, EB, S2R), vÃ  dá»¯ liá»‡u liÃªn quan Ä‘áº¿n mÃ£ (stack trace vÃ  Ä‘oáº¡n mÃ£). CÃ¢u há»i cÃ²n láº¡i lÃ  lÃ m tháº¿ nÃ o Ä‘á»ƒ xÃ¢y dá»±ng má»™t bÃ¡o cÃ¡o lá»—i tá»•ng há»£p tá»« táº¥t cáº£ cÃ¡c máº«u cÃ³ sáºµn. CÃ´ng viá»‡c gáº§n Ä‘Ã¢y trong dá»‹ch mÃ¡y neural Ä‘Ã£ cho tháº¥y ráº±ng viá»‡c ná»‘i cÃ¡c máº«u Ä‘Æ°á»£c tÄƒng cÆ°á»ng Ä‘Æ°a ra sá»± Ä‘a dáº¡ng cáº¥u trÃºc ngÄƒn cháº·n má»™t mÃ´ hÃ¬nh DL há»c táº­p trung chá»‰ vÃ o má»™t pháº§n cá»§a Ä‘áº§u vÃ o, do Ä‘Ã³ dáº«n Ä‘áº¿n má»™t cáº£i thiá»‡n máº¡nh máº½ trong hiá»‡u suáº¥t cá»§a mÃ´ hÃ¬nh [34,61]. ChÃºng tÃ´i Ä‘á» xuáº¥t sá»­ dá»¥ng má»™t phÆ°Æ¡ng phÃ¡p tÆ°Æ¡ng tá»± Ä‘á»ƒ xÃ¢y dá»±ng cÃ¡c bÃ¡o cÃ¡o lá»—i Ä‘Æ°á»£c tÄƒng cÆ°á»ng. Cá»¥ thá»ƒ hÆ¡n, Ä‘áº§u tiÃªn chÃºng tÃ´i tÃ¡i táº¡o cáº¥u trÃºc gá»‘c cá»§a má»™t bÃ¡o cÃ¡o lá»—i báº±ng cÃ¡ch ná»‘i cÃ¡c máº«u Ä‘Æ°á»£c tÄƒng cÆ°á»ng. Tiáº¿p theo, cÃ¡c máº«u Ä‘Æ°á»£c sáº¯p xáº¿p láº¡i vÃ  tá»‘i Ä‘a 1 máº«u cÃ³ thá»ƒ Ä‘Æ°á»£c bá» Ä‘á»ƒ Ä‘áº¡t Ä‘Æ°á»£c sá»± Ä‘a dáº¡ng cáº¥u trÃºc hÆ¡n ná»¯a. Máº·c dÃ¹ viá»‡c bá» cÃ¡c pháº§n cá»§a bÃ¡o cÃ¡o lá»—i cÃ³ thá»ƒ cÃ³ váº» pháº£n trá»±c quan, cÃ¡c chiáº¿n lÆ°á»£c DA loáº¡i bá» token hoáº·c cÃ¢u Ä‘Ã£ Ä‘Æ°á»£c quan sÃ¡t cÃ³ tÃ¡c Ä‘á»™ng tÃ­ch cá»±c Ä‘áº¿n cÃ¡c mÃ´ hÃ¬nh DL lá»›n Ä‘Æ°á»£c tiá»n huáº¥n luyá»‡n [5,44]. HÃ¬nh 2 cho tháº¥y bÃ¡o cÃ¡o lá»—i #55171 tá»« dá»± Ã¡n Tomcat vÃ  phiÃªn báº£n Ä‘Æ°á»£c tÄƒng cÆ°á»ng cá»§a nÃ³. Má»—i pháº§n cá»§a bÃ¡o cÃ¡o lá»—i Ä‘Ã£ Ä‘Æ°á»£c tÄƒng cÆ°á»ng riÃªng biá»‡t báº±ng cÃ¡ch sá»­ dá»¥ng táº¥t cáº£ cÃ¡c toÃ¡n tá»­ DA tÆ°Æ¡ng á»©ng cá»§a nÃ³. Trong trÆ°á»ng há»£p ngÃ´n ngá»¯ tá»± nhiÃªn, chÃºng ta tháº¥y cÃ¡c láº§n chÃ¨n vÃ  thay tháº¿ Ä‘Ãºng vá» máº·t ngá»¯ nghÄ©a (vÃ­ dá»¥: blockedâ†’dead), trong khi viá»‡c diá»…n Ä‘áº¡t láº¡i Ä‘oáº¡n vÄƒn Ä‘Æ°á»£c thá»±c hiá»‡n bá»Ÿi Backtranslation Ã­t chÃ­nh xÃ¡c hÆ¡n nhÆ°ng váº«n truyá»n Ä‘áº¡t thÃ´ng Ä‘iá»‡p chÃ­nh (vÃ­ dá»¥: OB thá»© hai trong hÃ¬nh). TÄƒng cÆ°á»ng mÃ£ cho bÃ¡o cÃ¡o lá»—i nÃ y bao gá»“m viá»‡c tÄƒng cÆ°á»ng stack trace vÃ  token mÃ£ vá»›i tÃªn mÃ£ tá»« changeset gÃ¢y ra lá»—i. Máº·c dÃ¹ phÆ°Æ¡ng phÃ¡p nhÆ° váº­y vá»‘n háº¡n cháº¿ kháº£ nÄƒng thÃªm nhiá»…u, nÃ³ cÅ©ng Ä‘Æ°a ra thÃ´ng tin vá» cÃ¡c thÃ nh pháº§n mÃ£ liÃªn quan Ä‘áº¿n bÃ¡o cÃ¡o lá»—i. Äiá»u nÃ y, Ä‘áº¿n lÆ°á»£t nÃ³, cho phÃ©p mÃ´ hÃ¬nh há»c cÃ¡c má»‘i quan há»‡ nÃ y vÃ  sá»­ dá»¥ng chÃºng trong quÃ¡ trÃ¬nh suy luáº­n. Cuá»‘i cÃ¹ng, khi xÃ¢y dá»±ng bÃ¡o cÃ¡o lá»—i Ä‘Æ°á»£c tÄƒng cÆ°á»ng, OB thá»© hai vÃ  stack trace Ä‘Ã£ Ä‘Æ°á»£c hoÃ¡n Ä‘á»•i, trong khi OB thá»© ba Ä‘Ã£ Ä‘Æ°á»£c bá», táº¡o ra phiÃªn báº£n Ä‘Æ°á»£c tÄƒng cÆ°á»ng cuá»‘i cÃ¹ng cá»§a bÃ¡o cÃ¡o lá»—i #55171.

3.5 Äáº£m báº£o má»™t táº­p dá»¯ liá»‡u Ä‘Æ°á»£c tÄƒng cÆ°á»ng cÃ¢n báº±ng

Äá»ƒ tÄƒng kÃ­ch thÆ°á»›c cá»§a táº­p huáº¥n luyá»‡n Ä‘á»‹nh vá»‹ lá»—i vá»›i tÄƒng cÆ°á»ng dá»¯ liá»‡u, phÆ°Æ¡ng phÃ¡p cá»§a chÃºng tÃ´i lÃ  táº­p trung vÃ o viá»‡c tÄƒng cÆ°á»ng cÃ¡c bÃ¡o cÃ¡o lá»—i, tÄƒng sá»‘ lÆ°á»£ng cáº·p bÃ¡o cÃ¡o lá»—i vÃ  cÃ¡c hunk gÃ¢y ra lá»—i. CÃ¡c nghiÃªn cá»©u gáº§n Ä‘Ã¢y cho tháº¥y ráº±ng viá»‡c sá»­ dá»¥ng hunk, má»™t táº­p há»£p cÃ¡c sá»­a Ä‘á»•i dÃ²ng liÃªn tiáº¿p náº¯m báº¯t cÃ¡c thay Ä‘á»•i trong má»™t khu vá»±c cá»§a tá»‡p, táº¡o ra káº¿t quáº£ truy xuáº¥t Ä‘Æ°á»£c cáº£i thiá»‡n so vá»›i viá»‡c sá»­ dá»¥ng toÃ n bá»™ changeset [6,58]. Do Ä‘Ã³, trong cÃ´ng trÃ¬nh nÃ y, chÃºng tÃ´i xÃ¢y dá»±ng táº­p huáº¥n luyá»‡n Ä‘á»‹nh vá»‹ lá»—i sá»­ dá»¥ng cÃ¡c cáº·p bÃ¡o cÃ¡o lá»—i vÃ  hunk Ä‘Æ°á»£c trÃ­ch xuáº¥t tá»« cÃ¡c changeset gÃ¢y ra lá»—i.

CÃ¡c lá»—i áº£nh hÆ°á»Ÿng Ä‘áº¿n cÃ¡c pháº§n khÃ¡c nhau cá»§a cÆ¡ sá»Ÿ mÃ£ nguá»“n vá»›i táº§n suáº¥t khÃ¡c nhau [2]. NÃ³i cÃ¡ch khÃ¡c, cÃ¡c pháº§n cá»§a mÃ£ nguá»“n (tá»©c lÃ  cÃ¡c tá»‡p hoáº·c lá»›p cá»¥ thá»ƒ) liÃªn quan Ä‘áº¿n nhiá»u bÃ¡o cÃ¡o lá»—i vÃ  do Ä‘Ã³ cÃ¡c hunk cá»§a chÃºng cÅ©ng cÃ³ thá»ƒ Ä‘Æ°á»£c Ä‘áº¡i diá»‡n quÃ¡ má»©c trong táº­p dá»¯ liá»‡u gá»‘c. VÃ­ dá»¥, cho má»™t bÃ¡o cÃ¡o lá»—i vá»›i ğ‘› hunk giá»›i thiá»‡u, tÄƒng cÆ°á»ng dá»¯ liá»‡u theo há»‡ sá»‘ 10 táº¡o ra 10 bÃ¡o cÃ¡o lá»—i má»›i cho má»—i hunk, dáº«n Ä‘áº¿n 10ğ‘› máº«u huáº¥n luyá»‡n má»›i. Tuy nhiÃªn, cÃ³ má»™t nhÆ°á»£c Ä‘iá»ƒm chÃ­nh Ä‘á»‘i vá»›i phÆ°Æ¡ng phÃ¡p DA nÃ y. Sá»± máº¥t cÃ¢n báº±ng dá»¯ liá»‡u nÃ y, Ä‘Æ°á»£c táº¡o ra bá»Ÿi sá»± phÃ¢n bá»‘ khÃ´ng Ä‘á»u cá»§a cÃ¡c bÃ¡o cÃ¡o lá»—i vÃ  hunk trong táº­p huáº¥n luyá»‡n, cÃ³ thá»ƒ bá»‹ DA lÃ m tráº§m trá»ng thÃªm, vá»›i nhá»¯ng tÃ¡c Ä‘á»™ng máº¡nh máº½ xuÃ´i dÃ²ng Ä‘áº¿n mÃ´ hÃ¬nh DL vÃ  dá»± Ä‘oÃ¡n cá»§a nÃ³.

Äá»ƒ cung cáº¥p báº±ng chá»©ng sÃ¢u hÆ¡n, chÃºng tÃ´i Ä‘Ã£ kiá»ƒm tra thá»±c nghiá»‡m táº­p dá»¯ liá»‡u Ä‘Æ°á»£c cÃ´ng bá»‘ bá»Ÿi Wen et al. [58], mÃ  chÃºng tÃ´i sá»­ dá»¥ng trong nghiÃªn cá»©u cá»§a mÃ¬nh. HÃ¬nh 3 cho tháº¥y sá»± phÃ¢n bá»‘ cá»§a cÃ¡c bÃ¡o cÃ¡o lá»—i (HÃ¬nh 3a) vÃ  sá»± xuáº¥t hiá»‡n cá»§a lá»›p (HÃ¬nh 3b) cho dá»± Ã¡n Tomcat. CÃ¡c phÃ¢n bá»‘ cho tháº¥y cÃ³ bao nhiÃªu máº«u trong táº­p dá»¯ liá»‡u huáº¥n luyá»‡n tham chiáº¿u Ä‘áº¿n má»™t bÃ¡o cÃ¡o lá»—i cá»¥ thá»ƒ (hoáº·c má»™t lá»›p), trong Ä‘Ã³ má»™t bÃ¡o cÃ¡o lá»—i (hoáº·c má»™t lá»›p) cÃ³ nhiá»u láº§n xuáº¥t hiá»‡n báº±ng sá»‘ lÆ°á»£ng hunk. ChÃºng tÃ´i hiá»ƒn thá»‹ cÃ¡c phÃ¢n bá»‘ nÃ y cho ba lá»±a chá»n khÃ¡c nhau cá»§a táº­p dá»¯ liá»‡u huáº¥n luyá»‡n: táº­p dá»¯ liá»‡u gá»‘c khÃ´ng Ä‘Æ°á»£c tÄƒng cÆ°á»ng, má»™t táº­p dá»¯ liá»‡u Ä‘Æ°á»£c tÄƒng cÆ°á»ng 10x, vÃ  má»™t táº­p dá»¯ liá»‡u Ä‘Æ°á»£c cÃ¢n báº±ng nhÃ¢n táº¡o. Trong cÃ¡c biá»ƒu Ä‘á»“, cÃ³ cÃ¡c phiÃªn báº£n Ä‘Æ°á»£c phÃ³ng to Ä‘á»ƒ tÄƒng kháº£ nÄƒng Ä‘á»c á»Ÿ quy mÃ´ nhá» hÆ¡n. Trong biá»ƒu Ä‘á»“ cho táº­p huáº¥n luyá»‡n gá»‘c (tá»©c lÃ  Ä‘Æ°á»ng mÃ u xanh lam), chÃºng tÃ´i quan sÃ¡t ráº±ng 11 trong sá»‘ 97 bÃ¡o cÃ¡o lá»—i bao phá»§ hÆ¡n 50% (1432 trong sá»‘ 2812) cÃ¡c máº«u huáº¥n luyá»‡n. NÃ³i cÃ¡ch khÃ¡c, 50% cÃ¡c máº«u trong táº­p huáº¥n luyá»‡n tham chiáº¿u Ä‘áº¿n 11 bÃ¡o cÃ¡o lá»—i, vÃ¬ nhá»¯ng bÃ¡o cÃ¡o lá»—i nÃ y cÃ³ nhiá»u hunk giá»›i thiá»‡u, Ä‘iá»u nÃ y dá»‹ch thÃ nh nhiá»u má»¥c trong táº­p huáº¥n luyá»‡n. Äá»“ng thá»i, 39 bÃ¡o cÃ¡o lá»—i xuáº¥t hiá»‡n Ã­t hÆ¡n 10 láº§n. TÆ°Æ¡ng tá»±, trong sá»‘ 110 lá»›p duy nháº¥t Ä‘Ã£ giá»›i thiá»‡u má»™t lá»—i, 10 lá»›p hÃ ng Ä‘áº§u vá»›i cÃ¡c hunk xuáº¥t hiá»‡n thÆ°á»ng xuyÃªn nháº¥t bao phá»§ 34.5% (2586 trong sá»‘ 7478) táº¥t cáº£ dá»¯ liá»‡u huáº¥n luyá»‡n. Sá»± máº¥t cÃ¢n báº±ng nÃ y trong dá»¯ liá»‡u huáº¥n luyá»‡n cÃ³ thá»ƒ cÃ³ hai háº­u quáº£ tiá»m áº©n Ä‘á»‘i vá»›i viá»‡c huáº¥n luyá»‡n cÃ³ giÃ¡m sÃ¡t cá»§a má»™t mÃ´ hÃ¬nh DL. Äáº§u tiÃªn, mÃ´ hÃ¬nh cÃ³ nhiá»u kháº£ nÄƒng há»c cáº¥u trÃºc vÃ  ngá»¯ nghÄ©a cá»§a cÃ¡c bÃ¡o cÃ¡o lá»—i cÃ³ sá»‘ lÆ°á»£ng lá»›n cÃ¡c hunk gÃ¢y ra lá»—i, trong khi bá» qua cÃ¡c bÃ¡o cÃ¡o lá»—i Ã­t thÆ°á»ng xuyÃªn hÆ¡n. Thá»© hai, cÃ¡c lá»›p xuáº¥t hiá»‡n nhiá»u nháº¥t trong táº­p huáº¥n luyá»‡n cÃ³ nhiá»u kháº£ nÄƒng Ä‘Æ°á»£c chá»n lÃ m gÃ¢y ra lá»—i bá»Ÿi mÃ´ hÃ¬nh Ä‘Æ°á»£c huáº¥n luyá»‡n vÃ¬ chÃºng thÆ°á»ng Ä‘Æ°á»£c tháº¥y trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n nhÆ° lÃ  gÃ¢y ra lá»—i. Váº¥n Ä‘á» máº¥t cÃ¢n báº±ng dá»¯ liá»‡u cÅ©ng Ä‘Ã£ Ä‘Æ°á»£c nháº­n ra trong cÃ¡c táº­p dá»¯ liá»‡u dá»± Ä‘oÃ¡n khiáº¿m khuyáº¿t [65].

CÃ¡ch mÃ  tÄƒng cÆ°á»ng lÃ m tráº§m trá»ng thÃªm váº¥n Ä‘á» phÃ¢n bá»‘ dá»¯ liá»‡u khÃ´ng Ä‘á»u cÃ³ thá»ƒ Ä‘Æ°á»£c quan sÃ¡t trong HÃ¬nh 3, nÆ¡i Ä‘Æ°á»ng cháº¥m mÃ u cam mÃ´ táº£ cÃ¡c phÃ¢n bá»‘ dá»¯ liá»‡u trong má»™t táº­p dá»¯ liá»‡u Ä‘Æ°á»£c tÄƒng cÆ°á»ng theo há»‡ sá»‘ 10. CÃ¡c bÃ¡o cÃ¡o lá»—i vÃ  lá»›p chiáº¿m Ä‘a sá»‘ trá»Ÿ nÃªn tháº­m chÃ­ cÃ²n thá»‘ng trá»‹ hÆ¡n trong táº­p dá»¯ liá»‡u Ä‘Æ°á»£c tÄƒng cÆ°á»ng, lÃ m cho váº¥n Ä‘á» máº¥t cÃ¢n báº±ng dá»¯ liá»‡u nghiÃªm trá»ng hÆ¡n so vá»›i táº­p dá»¯ liá»‡u gá»‘c. Äá»ƒ giáº£m thiá»ƒu váº¥n Ä‘á» nÃ y, chÃºng tÃ´i Ä‘á» xuáº¥t má»™t chiáº¿n lÆ°á»£c cÃ¢n báº±ng dá»¯ liá»‡u cÃ³ chá»§ Ã½ chá»n cÃ¡c máº«u Ä‘á»ƒ tÄƒng cÆ°á»ng nháº±m lÃ m má»‹n cÃ¡c phÃ¢n bá»‘ cá»§a cÃ¡c bÃ¡o cÃ¡o lá»—i Ä‘á»‘i vá»›i mÃ£ nguá»“n. CÃ³ hai má»‘i quan tÃ¢m chÃ­nh mÃ  má»™t chiáº¿n lÆ°á»£c cÃ¢n báº±ng dá»¯ liá»‡u pháº£i xem xÃ©t: (1) tÄƒng sá»‘ lÆ°á»£ng máº«u huáº¥n luyá»‡n cho cÃ¡c bÃ¡o cÃ¡o lá»—i khÃ´ng thÆ°á»ng xuyÃªn, vÃ  (2) Ä‘áº£m báº£o ráº±ng sá»‘ lÆ°á»£ng máº«u vá»›i má»™t lá»›p nháº¥t Ä‘á»‹nh khÃ´ng thá»‘ng trá»‹ táº­p dá»¯ liá»‡u. Äá»ƒ minh há»a nhu cáº§u cho nhá»¯ng chiáº¿n lÆ°á»£c nÃ y, hÃ£y xem xÃ©t má»™t bÃ¡o cÃ¡o lá»—i ğµ1 vá»›i 20 hunk tá»« cÃ¡c lá»›p khÃ¡c nhau, vÃ  má»™t bÃ¡o cÃ¡o lá»—i ğµ2 vá»›i má»™t hunk tá»« lá»›p ğ¶. Náº¿u chiáº¿n lÆ°á»£c cÃ¢n báº±ng chá»‰ táº­p trung vÃ o sá»± phÃ¢n bá»‘ cá»§a cÃ¡c bÃ¡o cÃ¡o lá»—i, thÃ¬ nÃ³ táº¡o ra 20 máº«u Ä‘Æ°á»£c tÄƒng cÆ°á»ng cho ğµ2, má»—i láº§n sá»­ dá»¥ng hunk tá»« lá»›p ğ¶, do Ä‘Ã³ ğ¶ cÃ³ kháº£ nÄƒng Ä‘Æ°á»£c Ä‘áº¡i diá»‡n quÃ¡ má»©c trong táº­p huáº¥n luyá»‡n. Äá»ƒ giáº£i quyáº¿t Ä‘iá»u nÃ y, chÃºng tÃ´i Ä‘Æ°a ra hai yáº¿u tá»‘ tÄƒng cÆ°á»ng ğ›¼ vÃ  ğœ”. Trong khi ğ›¼ áº£nh hÆ°á»Ÿng Ä‘áº¿n sá»‘ láº§n má»—i bÃ¡o cÃ¡o lá»—i Ä‘Æ°á»£c tÄƒng cÆ°á»ng, ğœ” háº¡n cháº¿ sá»‘ láº§n má»—i lá»›p cÃ³ thá»ƒ Ä‘Æ°á»£c láº·p láº¡i trong táº­p dá»¯ liá»‡u Ä‘Æ°á»£c tÄƒng cÆ°á»ng.

Thuáº­t toÃ¡n 1: CÃ¢n báº±ng dá»¯ liá»‡u vá»›i cÃ¡c bÃ¡o cÃ¡o lá»—i Ä‘Æ°á»£c tÄƒng cÆ°á»ng
Äáº§u vÃ o: ğ·ğ‘¡ğ‘Ÿğ‘ğ‘–ğ‘› â€“ táº­p dá»¯ liá»‡u huáº¥n luyá»‡n;
ğ›¼â€“ yáº¿u tá»‘ tÄƒng cÆ°á»ng;
ğœ”â€“ yáº¿u tá»‘ cÃ¢n báº±ng
Äáº§u ra: ğ·ğ‘ğ‘™â€“ táº­p dá»¯ liá»‡u huáº¥n luyá»‡n cÃ¢n báº±ng
1 ğ‘šğ‘ğ‘¥ ğ‘ğ‘Ÿâ†ğ›¼Ã—max. # bÃ¡o cÃ¡o lá»—i trong ğ·ğ‘¡ğ‘Ÿğ‘ğ‘–ğ‘›
2 ğ‘šğ‘ğ‘¥ ğ‘ğ‘™â†ğœ”Ã—max. # lá»›p trong ğ·ğ‘¡ğ‘Ÿğ‘ğ‘–ğ‘›
3 ğ·ğ‘ğ‘™â†ğ·ğ‘¡ğ‘Ÿğ‘ğ‘–ğ‘›
4 for ğ‘ğ‘Ÿ,ğ»ğ‘ğ‘Ÿ in ğ·ğ‘¡ğ‘Ÿğ‘ğ‘–ğ‘› do
5 while (sá»‘ lÆ°á»£ng cá»§a ğ‘ğ‘Ÿ trong ğ·ğ‘ğ‘ğ‘™)<ğ‘šğ‘ğ‘¥ ğ‘ğ‘Ÿ do
6 ğ‘ğ‘Ÿğ‘â†tÄƒng cÆ°á»ng ğ‘ğ‘Ÿ
7 â„ğ‘â†chá»n hunk â„ğ‘ tá»« ğ»ğ‘ğ‘Ÿ, trong Ä‘Ã³
8 (sá»‘ lÆ°á»£ng cá»§a lá»›p cho â„ğ‘ trong ğ·ğ‘ğ‘ğ‘™)<ğ‘šğ‘ğ‘¥ ğ‘ğ‘™
9 ThÃªm ğ‘ğ‘Ÿğ‘,â„ğ‘ vÃ o ğ·ğ‘ğ‘™
10 end while
11 end for
12 return ğ·ğ‘ğ‘™

Chuá»—i cÃ¡c bÆ°á»›c cho chiáº¿n lÆ°á»£c tÄƒng cÆ°á»ng cÃ¢n báº±ng dá»¯ liá»‡u Ä‘Æ°á»£c Ä‘á» xuáº¥t Ä‘Æ°á»£c trÃ¬nh bÃ y trong Thuáº­t toÃ¡n 1. Trong dÃ²ng 1-2, chÃºng tÃ´i tÃ­nh toÃ¡n má»™t giá»›i háº¡n cho cÃ¡c bÃ¡o cÃ¡o lá»—i ğ‘šğ‘ğ‘¥ğ‘ğ‘Ÿ vÃ  lá»›p ğ‘šğ‘ğ‘¥ğ‘ğ‘™ dá»±a trÃªn cÃ¡c yáº¿u tá»‘ ğ›¼ vÃ  ğœ” vÃ  sá»‘ lÆ°á»£ng tá»‘i Ä‘a láº§n má»™t bÃ¡o cÃ¡o lá»—i vÃ  lá»›p duy nháº¥t cÃ³ máº·t trong táº­p dá»¯ liá»‡u huáº¥n luyá»‡n gá»‘c. DÃ²ng 3 sao chÃ©p cÃ¡c thá»±c thá»ƒ dá»¯ liá»‡u hiá»‡n cÃ³ vÃ o táº­p dá»¯ liá»‡u cÃ¢n báº±ng ğ·ğ‘ğ‘™. Äá»‘i vá»›i má»—i bÃ¡o cÃ¡o lá»—i xuáº¥t hiá»‡n dÆ°á»›i giá»›i háº¡n ğ‘šğ‘ğ‘¥ğ‘ğ‘Ÿ, thuáº­t toÃ¡n tÄƒng cÆ°á»ng bÃ¡o cÃ¡o lá»—i (dÃ²ng 6), vÃ  chá»n má»™t hunk gÃ¢y ra lá»—i tá»« má»™t lá»›p xuáº¥t hiá»‡n Ã­t hÆ¡n ğ‘šğ‘ğ‘¥ğ‘ğ‘™ láº§n trong ğ·ğ‘ğ‘™ (dÃ²ng 7-8), táº¡o ra má»™t máº«u huáº¥n luyá»‡n má»›i. Thuáº­t toÃ¡n tiáº¿p tá»¥c thÃªm cÃ¡c máº«u má»›i cho má»™t bÃ¡o cÃ¡o lá»—i cho Ä‘áº¿n khi (1) giá»›i háº¡n ğ‘šğ‘ğ‘¥ğ‘ğ‘Ÿ Ä‘Æ°á»£c Ä‘áº¡t tá»›i, hoáº·c (2) cÃ¡c hunk gÃ¢y ra lá»—i tá»« táº¥t cáº£ cÃ¡c lá»›p Ä‘Ã£ Ä‘áº¡t tá»›i ğ‘šğ‘ğ‘¥ğ‘ğ‘™. Káº¿t quáº£ cá»§a chiáº¿n lÆ°á»£c cÃ¢n báº±ng nÃ y Ä‘Æ°á»£c mÃ´ táº£ trong Ä‘Æ°á»ng mÃ u xanh lÃ¡ cÃ¢y trong HÃ¬nh 3, sá»­ dá»¥ng cÃ¡c giÃ¡ trá»‹ ğ›¼=0.7 vÃ  ğœ”=1.0. So vá»›i táº­p dá»¯ liá»‡u Ä‘Æ°á»£c tÄƒng cÆ°á»ng, phÃ¢n bá»‘ dá»¯ liá»‡u cá»§a táº­p dá»¯ liá»‡u cÃ¢n báº±ng rÃµ rÃ ng mÆ°á»£t mÃ  hÆ¡n, vá»›i sá»± Ä‘áº¡i diá»‡n Ä‘á»u Ä‘áº·n hÆ¡n nhiá»u cá»§a mÃ£ nguá»“n.

4 ÄÃNH GIÃ THá»°C NGHIá»†M

4.1 Táº­p dá»¯ liá»‡u vÃ  chá»‰ sá»‘

Äá»ƒ Ä‘Ã¡nh giÃ¡, chÃºng tÃ´i yÃªu cáº§u má»™t táº­p dá»¯ liá»‡u chá»©a cÃ¡c bÃ¡o cÃ¡o lá»—i vÃ  changeset gÃ¢y ra lá»—i. ChÃºng tÃ´i sá»­ dá»¥ng má»™t táº­p dá»¯ liá»‡u Ä‘Æ°á»£c cÃ´ng bá»‘ bá»Ÿi Wen et al. [58] chá»©a dá»¯ liá»‡u Ä‘Æ°á»£c xÃ¡c thá»±c thá»§ cÃ´ng tá»« 6 dá»± Ã¡n pháº§n má»m mÃ£ nguá»“n má»Ÿ: AspectJ, JDT, PDE, SWT, Tomcat, vÃ  ZXing. Cho ráº±ng infozilla yÃªu cáº§u dÃ²ng má»›i Ä‘á»ƒ trÃ­ch xuáº¥t Ä‘oáº¡n mÃ£ vÃ  stack trace, vÃ  dÃ²ng má»›i Ä‘Ã£ Ä‘Æ°á»£c loáº¡i bá» khá»i táº¥t cáº£ cÃ¡c bÃ¡o cÃ¡o lá»—i trong táº­p dá»¯ liá»‡u cá»§a Wen et al., chÃºng tÃ´i Ä‘Ã£ Ä‘á»‹nh vá»‹ vÃ  cáº¡o láº¡i cÃ¡c bÃ¡o cÃ¡o lá»—i (vá»›i dÃ²ng má»›i) tá»« Bugzilla cho táº¥t cáº£ cÃ¡c dá»± Ã¡n. Äá»‘i vá»›i ZXing, cÃ¡c bÃ¡o cÃ¡o lá»—i trong GitHub issue tracker khÃ´ng khá»›p vá»›i nhá»¯ng bÃ¡o cÃ¡o Ä‘Æ°á»£c thu tháº­p bá»Ÿi Wen et al., cÃ³ kháº£ nÄƒng do dá»± Ã¡n Ä‘Ã£ Ä‘Æ°á»£c chuyá»ƒn, vÃ  do Ä‘Ã³ ZXing Ä‘Ã£ Ä‘Æ°á»£c loáº¡i khá»i táº­p Ä‘Ã¡nh giÃ¡. Äá»ƒ táº¡o ra má»™t táº­p huáº¥n luyá»‡n cho má»—i dá»± Ã¡n, chÃºng tÃ´i sáº¯p xáº¿p cÃ¡c bÃ¡o cÃ¡o lá»—i theo ngÃ y má»Ÿ vÃ  chá»n ná»­a Ä‘áº§u Ä‘á»ƒ huáº¥n luyá»‡n, trong khi cÃ¡c bÃ¡o cÃ¡o lá»—i cÃ²n láº¡i táº¡o thÃ nh táº­p kiá»ƒm tra. Má»—i máº«u huáº¥n luyá»‡n tÃ­ch cá»±c tÆ°Æ¡ng á»©ng vá»›i má»™t cáº·p bÃ¡o cÃ¡o lá»—i vÃ  má»™t trong cÃ¡c hunk gÃ¢y ra cá»§a nÃ³ (Ä‘Æ°á»£c trÃ­ch xuáº¥t tá»« changeset gÃ¢y ra). Má»—i bÃ¡o cÃ¡o lá»—i bao gá»“m tÃ³m táº¯t lá»—i vÃ  mÃ´ táº£, trong khi má»—i hunk chá»©a thÃ´ng Ä‘iá»‡p nháº­t kÃ½ vÃ  thay Ä‘á»•i mÃ£ nguá»“n. Táº­p dá»¯ liá»‡u cá»§a Wen et al. Ä‘Æ°á»£c xÃ¢y dá»±ng báº±ng SZZ [46], xÃ¡c Ä‘á»‹nh má»™t changeset lÃ  gÃ¢y ra lá»—i náº¿u nÃ³ chia sáº» báº¥t ká»³ sá»­a Ä‘á»•i tá»‡p nÃ o vá»›i changeset sá»­a lá»—i. Máº·c dÃ¹ má»™t changeset gÃ¢y ra lá»—i cÃ³ thá»ƒ bao gá»“m sá»­a Ä‘á»•i cá»§a nhiá»u tá»‡p, chá»‰ má»™t vÃ i trong sá»‘ Ä‘Ã³ cÃ³ thá»ƒ liÃªn quan Ä‘áº¿n má»™t lá»—i (nhÆ° Ä‘Æ°á»£c chá»‰ bÃ¡o bá»Ÿi changeset sá»­a lá»—i). Do Ä‘Ã³, Ä‘á»ƒ Ä‘áº£m báº£o cháº¥t lÆ°á»£ng cá»§a cÃ¡c máº«u huáº¥n luyá»‡n, chÃºng tÃ´i chá»‰ bao gá»“m cÃ¡c hunk gÃ¢y ra lá»—i tham chiáº¿u Ä‘áº¿n cÃ¡c lá»›p cÅ©ng xuáº¥t hiá»‡n trong commit sá»­a lá»—i. Äá»‘i vá»›i má»—i máº«u tÃ­ch cá»±c, chÃºng tÃ´i táº¡o ra má»™t máº«u tiÃªu cá»±c báº±ng cÃ¡ch chá»n ngáº«u nhiÃªn má»™t hunk tá»« má»™t lá»›p khÃ´ng thuá»™c changeset gÃ¢y ra. Sau khi hoÃ n thÃ nh bÆ°á»›c nÃ y, Ä‘á»‘i vá»›i má»—i dá»± Ã¡n chÃºng tÃ´i thu Ä‘Æ°á»£c táº­p dá»¯ liá»‡u baseline cá»§a mÃ¬nh, ğ·ğ‘œğ‘Ÿğ‘–. Thá»‘ng kÃª mÃ´ táº£ cá»§a cÃ¡c táº­p dá»¯ liá»‡u huáº¥n luyá»‡n vÃ  kiá»ƒm tra Ä‘Æ°á»£c sá»­ dá»¥ng trong nghiÃªn cá»©u nÃ y Ä‘Æ°á»£c hiá»ƒn thá»‹ trong Báº£ng 2. LÆ°u Ã½ ráº±ng cá»™t cuá»‘i, # hunk, biá»ƒu thá»‹ sá»‘ lÆ°á»£ng táº¥t cáº£ cÃ¡c hunk Ä‘Æ°á»£c kiá»ƒm tra bá»Ÿi mÃ´ hÃ¬nh trong quÃ¡ trÃ¬nh truy xuáº¥t.

Äá»ƒ Ä‘Ã¡nh giÃ¡ hiá»‡u suáº¥t truy xuáº¥t cá»§a cÃ¡c mÃ´ hÃ¬nh DL Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn cÃ¡c táº­p dá»¯ liá»‡u khÃ¡c nhau, chÃºng tÃ´i sá»­ dá»¥ng cÃ¡c chá»‰ sá»‘ sau.

Mean Reciprocal Rank: MRR Ä‘o Ä‘á»™ chÃ­nh xÃ¡c truy xuáº¥t báº±ng cÃ¡ch sá»­ dá»¥ng nghá»‹ch Ä‘áº£o cá»§a thá»© háº¡ng cá»§a changeset cÃ³ liÃªn quan Ä‘áº§u tiÃªn trong thá»© háº¡ng Ä‘Æ°á»£c tÃ­nh trung bÃ¬nh trÃªn táº¥t cáº£ cÃ¡c bÃ¡o cÃ¡o lá»—i. GiÃ¡ trá»‹ MRR cÃ ng cao, changeset gÃ¢y ra lá»—i cÃ ng gáº§n Ä‘áº§u báº£ng xáº¿p háº¡ng.
ğ‘€ğ‘…ğ‘… =1|ğµ|âˆ‘ï¸|ğµ|ğ‘–=1 1/1ğ‘ ğ‘¡ğ‘…ğ‘ğ‘›ğ‘˜ğµğ‘–.

Mean Average Precision: MAP Ä‘á»‹nh lÆ°á»£ng kháº£ nÄƒng cá»§a má»™t mÃ´ hÃ¬nh truy xuáº¥t táº¥t cáº£ cÃ¡c changeset cÃ³ liÃªn quan cho má»™t bÃ¡o cÃ¡o lá»—i nháº¥t Ä‘á»‹nh. MAP Ä‘Æ°á»£c tÃ­nh nhÆ° trung bÃ¬nh cá»§a Ä‘iá»ƒm Average Precision trÃªn táº¥t cáº£ cÃ¡c bÃ¡o cÃ¡o lá»—i, trong Ä‘Ã³ Average Precision cho má»™t bÃ¡o cÃ¡o lá»—i dá»±a trÃªn thá»© háº¡ng cá»§a táº¥t cáº£ cÃ¡c changeset cÃ³ liÃªn quan trong báº£ng xáº¿p háº¡ng. GiÃ¡ trá»‹ MAP cÃ ng cao, cÃ ng nhiá»u changeset cÃ³ liÃªn quan Ä‘Æ°á»£c Ä‘á»‹nh vá»‹ á»Ÿ Ä‘áº§u báº£ng xáº¿p háº¡ng.
ğ‘€ğ´ğ‘ƒ =1|ğµ|âˆ‘ï¸|ğµ|ğ‘–=1 1/ğ´ğ‘£ğ‘”ğ‘ƒğµğ‘–.

Precision@K: P@K Ä‘o cÃ³ bao nhiÃªu changeset top-ğ¾ trong báº£ng xáº¿p háº¡ng cÃ³ liÃªn quan Ä‘áº¿n má»™t bÃ¡o cÃ¡o lá»—i. GiÃ¡ trá»‹ P@K cÃ ng cao, cÃ ng nhiá»u changeset cÃ³ liÃªn quan cÃ³ thá»ƒ Ä‘Æ°á»£c tÃ¬m tháº¥y á»Ÿ vá»‹ trÃ­ top-ğ¾.
ğ‘ƒ@ğ‘›=1|ğµ|âˆ‘ï¸|ğµ|ğ‘–=1 |ğ‘…ğ‘’ğ‘™ğµğ‘–|/ğ¾.

4.2 MÃ´ hÃ¬nh DL

Äá»ƒ Ä‘Ã¡nh giÃ¡ tÃ¡c Ä‘á»™ng cá»§a cÃ¡c chiáº¿n lÆ°á»£c tÄƒng cÆ°á»ng dá»¯ liá»‡u vÃ  cÃ¢n báº±ng Ä‘Æ°á»£c Ä‘á» xuáº¥t lÃªn hiá»‡u suáº¥t truy xuáº¥t, chÃºng tÃ´i huáº¥n luyá»‡n vÃ  Ä‘Ã¡nh giÃ¡ ba kiáº¿n trÃºc truy xuáº¥t mÃ£ dá»±a trÃªn BERT [10].

TBERT-Single [9,29,35] lÃ  phÆ°Æ¡ng phÃ¡p Ä‘Æ¡n giáº£n nháº¥t cho truy xuáº¥t thÃ´ng tin vá»›i BERT. MÃ´ hÃ¬nh ná»‘i má»™t bÃ¡o cÃ¡o lá»—i vÃ  má»™t hunk, vÃ  xá»­ lÃ½ nÃ³ thÃ´ng qua BERT vÃ  má»™t lá»›p pooling Ä‘á»ƒ thu Ä‘Æ°á»£c má»™t biá»ƒu diá»…n vector há»£p nháº¥t, sau Ä‘Ã³ Ä‘Æ°á»£c chuyá»ƒn Ä‘áº¿n Ä‘áº§u phÃ¢n loáº¡i Ä‘á»ƒ thu Ä‘Æ°á»£c Ä‘iá»ƒm liÃªn quan. Máº·c dÃ¹ mÃ´ hÃ¬nh nÃ y thÆ°á»ng cung cáº¥p Ä‘á»™ chÃ­nh xÃ¡c truy xuáº¥t cao, nÃ³ cÅ©ng phÃ¡t sinh Ä‘á»™ trá»… truy xuáº¥t Ä‘Ã¡ng ká»ƒ, vÃ¬ má»™t bÃ¡o cÃ¡o lá»—i cáº§n Ä‘Æ°á»£c so sÃ¡nh vá»›i táº¥t cáº£ cÃ¡c hunk cÃ³ sáºµn trong má»™t dá»± Ã¡n.

TBERT-Siamese [29,41] xá»­ lÃ½ má»™t bÃ¡o cÃ¡o lá»—i vÃ  má»™t hunk tuáº§n tá»± thÃ´ng qua BERT vÃ  má»™t lá»›p pooling, táº¡o ra hai vector Ä‘áº·c trÆ°ng, sau Ä‘Ã³ Ä‘Æ°á»£c ná»‘i vÃ  chuyá»ƒn Ä‘áº¿n lá»›p phÃ¢n loáº¡i Ä‘á»ƒ táº¡o ra Ä‘iá»ƒm liÃªn quan. Sá»± khÃ¡c biá»‡t chÃ­nh giá»¯a TBERT-Single vÃ  TBERT-Siamese lÃ  trong cÆ¡ há»™i thá»±c hiá»‡n mÃ£ hÃ³a ngoáº¡i tuyáº¿n cá»§a vector Ä‘áº·c trÆ°ng cho cÃ¡c hunk, do Ä‘Ã³ giáº£m Ä‘á»™ trá»… truy xuáº¥t.

FBL-BERT [6,22] lÃ  má»™t kiáº¿n trÃºc dá»±a trÃªn BERT Ä‘Æ°á»£c Ä‘á» xuáº¥t gáº§n Ä‘Ã¢y cho phÃ©p truy xuáº¥t nhanh chÃ³ng trÃªn táº­p há»£p lá»›n cÃ¡c tÃ i liá»‡u (tá»©c lÃ  cÃ¡c hunk). KhÃ´ng giá»‘ng nhÆ° TBERT, lÃ m pháº³ng ma tráº­n embedding thÃ nh má»™t vector Ä‘á»ƒ Ä‘Æ°a ra dá»± Ä‘oÃ¡n, FBL-BERT táº­n dá»¥ng toÃ n bá»™ ma tráº­n embedding vÃ  tÃ­nh Ä‘iá»ƒm liÃªn quan giá»¯a má»™t bÃ¡o cÃ¡o lá»—i vÃ  má»™t hunk nhÆ° tá»•ng cá»§a cÃ¡c Ä‘á»™ tÆ°Æ¡ng tá»± vector tá»‘i Ä‘a giá»¯a cÃ¡c embedding tá»« cá»§a bÃ¡o cÃ¡o lá»—i vÃ  hunk. Äiá»u nÃ y, Ä‘áº¿n lÆ°á»£t nÃ³, cho phÃ©p sá»­ dá»¥ng cÃ¡c thuáº­t toÃ¡n tÃ¬m kiáº¿m tÆ°Æ¡ng tá»± vector hiá»‡u quáº£ Ä‘á»ƒ tÃ¬m cÃ¡c hunk tÆ°Æ¡ng tá»± nháº¥t vÃ  chá»‰ xáº¿p háº¡ng láº¡i nhá»¯ng hunk Ä‘Ã³ vá»›i FBL-BERT, do Ä‘Ã³ giáº£m Ä‘Ã¡ng ká»ƒ thá»i gian truy xuáº¥t má»—i bÃ¡o cÃ¡o lá»—i. Cho ráº±ng FBL-BERT táº­n dá»¥ng khá»›p embedding token-to-token tinh vi, mÃ´ hÃ¬nh cÃ³ nhiá»u kháº£ nÄƒng sá»­ dá»¥ng tá»‘t hÆ¡n cÃ¡c tá»« khÃ³a cÃ³ liÃªn quan náº¿u chÃºng xuáº¥t hiá»‡n trong bÃ¡o cÃ¡o lá»—i.

Máº·c dÃ¹ táº¥t cáº£ cÃ¡c mÃ´ hÃ¬nh Ä‘á»u dá»±a trÃªn BERT, kiáº¿n trÃºc cá»§a chÃºng khÃ¡c nhau á»Ÿ má»™t vÃ i khÃ­a cáº¡nh. TBERT-Single ná»‘i má»™t bÃ¡o cÃ¡o lá»—i vÃ  má»™t changeset, xá»­ lÃ½ chÃºng cÃ¹ng nhau thÃ´ng qua BERT, theo sau lÃ  má»™t lá»›p phÃ¢n loáº¡i. TBERT-Siamese vÃ  FBL-BERT Ä‘áº§u tiÃªn sá»­ dá»¥ng BERT Ä‘á»ƒ mÃ£ hÃ³a má»™t bÃ¡o cÃ¡o lá»—i vÃ  má»™t changeset riÃªng biá»‡t, dáº«n Ä‘áº¿n hai ma tráº­n embedding. Sá»± khÃ¡c biá»‡t chÃ­nh giá»¯a TBERT-Siamese vÃ  FBL-BERT lÃ  cÃ¡ch chÃºng xá»­ lÃ½ nhá»¯ng ma tráº­n nÃ y. TBERT-Siamese tá»•ng há»£p má»—i ma tráº­n thÃ nh má»™t vector báº±ng cÃ¡ch sá»­ dá»¥ng má»™t hoáº¡t Ä‘á»™ng pooling, vÃ  tiáº¿p theo, so sÃ¡nh vector embedding cá»§a má»™t bÃ¡o cÃ¡o lá»—i vá»›i vector embedding changeset. Máº·t khÃ¡c, FBL-BERT sá»­ dá»¥ng cáº£ hai ma tráº­n Ä‘á»ƒ tÃ­nh Ä‘iá»ƒm liÃªn quan cÃ³ tÃ­nh Ä‘áº¿n embedding cá»§a má»—i tá»«.

4.3 Thiáº¿t láº­p Ä‘Ã¡nh giÃ¡

ChÃºng tÃ´i thá»±c hiá»‡n cÃ¡c thÃ­ nghiá»‡m trÃªn má»™t mÃ¡y chá»§ vá»›i Dual 12-core 3.2GHz Intel Xeon vÃ  1 NVIDIA Tesla V100 vá»›i bá»™ nhá»› RAM 32GB cháº¡y CUDA v.11.4. CÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c thá»±c hiá»‡n vá»›i PyTorch v.1.7.1, thÆ° viá»‡n HuggingFace v.4.3.2, vÃ  Faiss v.1.6.5 vá»›i há»— trá»£ GPU. ChÃºng tÃ´i Ä‘Ã£ chá»n sá»­ dá»¥ng BERTOverflow [49] lÃ m mÃ´ hÃ¬nh BERT cÆ¡ sá»Ÿ Ä‘Æ°á»£c tiá»n huáº¥n luyá»‡n cá»§a chÃºng tÃ´i, vÃ¬ tÆ°Æ¡ng tá»± nhÆ° dá»¯ liá»‡u cá»§a chÃºng tÃ´i, dá»¯ liá»‡u StackOverflow cÅ©ng lÃ  sá»± pha trá»™n cá»§a mÃ£ vÃ  ngÃ´n ngá»¯ tá»± nhiÃªn. Táº¥t cáº£ cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c tinh chá»‰nh trong 4 epoch, sá»­ dá»¥ng kÃ­ch thÆ°á»›c batch lÃ  16 vÃ  bá»™ tá»‘i Æ°u hÃ³a Adam (viáº¿t táº¯t tá»« adaptive moment estimation) [23] vá»›i tá»‘c Ä‘á»™ há»c Ä‘Æ°á»£c Ä‘áº·t thÃ nh 3e-6 [10]. Dá»±a trÃªn sá»‘ lÆ°á»£ng token trung bÃ¬nh trong cÃ¡c bÃ¡o cÃ¡o lá»—i vÃ  hunk trong táº­p dá»¯ liá»‡u cá»§a chÃºng tÃ´i, chÃºng tÃ´i Ä‘áº·t giá»›i háº¡n kÃ­ch thÆ°á»›c Ä‘áº§u vÃ o thÃ nh 256 vÃ  512 token cho bÃ¡o cÃ¡o lá»—i vÃ  hunk tÆ°Æ¡ng á»©ng. Táº¥t cáº£ cÃ¡c tÃ i liá»‡u Ä‘áº§u vÃ o Ä‘Æ°á»£c Ä‘á»‡m hoáº·c cáº¯t ngáº¯n Ä‘á»‘i vá»›i giá»›i háº¡n kÃ­ch thÆ°á»›c Ä‘áº§u vÃ o cá»§a chÃºng.

5 Káº¾T QUáº¢

5.1 RQ1: (a) TÄƒng cÆ°á»ng Dá»¯ liá»‡u cÃ³ thá»ƒ cáº£i thiá»‡n hiá»‡u suáº¥t truy xuáº¥t cá»§a Ä‘á»‹nh vá»‹ lá»—i dá»±a trÃªn DL khÃ´ng? (b) TÄƒng cÆ°á»ng Dá»¯ liá»‡u tÃ¡c Ä‘á»™ng nhÆ° tháº¿ nÃ o Ä‘áº¿n hiá»‡u suáº¥t cá»§a cÃ¡c phÆ°Æ¡ng phÃ¡p Ä‘á»‹nh vá»‹ lá»—i dá»±a trÃªn DL khÃ¡c nhau?

Thiáº¿t láº­p. Äá»ƒ Ä‘Ã¡nh giÃ¡ tÃ¡c Ä‘á»™ng cá»§a DA Ä‘á»‘i vá»›i cÃ¡c mÃ´ hÃ¬nh dá»±a trÃªn DL, chÃºng tÃ´i so sÃ¡nh Ä‘á»™ chÃ­nh xÃ¡c truy xuáº¥t khi huáº¥n luyá»‡n trÃªn táº­p dá»¯ liá»‡u gá»‘c, khÃ´ng Ä‘Æ°á»£c tÄƒng cÆ°á»ng, ğ·ğ‘œğ‘Ÿğ‘–, vá»›i viá»‡c huáº¥n luyá»‡n vá»›i dá»¯ liá»‡u Ä‘Æ°á»£c tÄƒng cÆ°á»ng vÃ  cÃ¢n báº±ng. Cá»¥ thá»ƒ hÆ¡n, Ä‘á»‘i vá»›i má»—i dá»± Ã¡n chÃºng tÃ´i xÃ¢y dá»±ng nÄƒm táº­p dá»¯ liá»‡u Ä‘Æ°á»£c tÄƒng cÆ°á»ng Ä‘Æ°á»£c hiá»ƒn thá»‹ trong Báº£ng 3. ğ·ğ‘ğ‘¢ğ‘” lÃ  má»™t táº­p dá»¯ liá»‡u Ä‘Æ°á»£c tÄƒng cÆ°á»ng, nhÆ°ng khÃ´ng cÃ¢n báº±ng, chá»©a 10 máº«u bá»• sung cho má»—i cáº·p bÃ¡o cÃ¡o lá»—i vÃ  hunk, trong khi ğ·ğ‘ğ‘™ğ‘–, ğ‘–=1,2,3,4, lÃ  cÃ¡c táº­p dá»¯ liá»‡u cÃ¢n báº±ng vá»›i cÃ¡c lá»±a chá»n khÃ¡c nhau cho (ğ›¼,ğœ”) = {(0.7,1.0);(0.85,2.0);(1.0,2.0); (1.3,2.0)} tÆ°Æ¡ng á»©ng. LÃ½ do cho nhá»¯ng giÃ¡ trá»‹ cá»¥ thá»ƒ nÃ y cá»§a ğ›¼ vÃ  ğœ” lÃ  Ä‘á»ƒ khÃ¡m phÃ¡ ğ›¼ (trong cÃ¡c pháº¡m vi khÃ´ng táº¡o ra nhiá»u dá»¯ liá»‡u hÆ¡n chÃºng ta cÃ³ thá»ƒ quáº£n lÃ½ vá» máº·t tÃ­nh toÃ¡n), trong khi chá»n cÃ¡c giÃ¡ trá»‹ cho ğœ” khÃ´ng háº¡n cháº¿ hiá»‡u á»©ng cá»§a ğ›¼. Cho ráº±ng tÄƒng cÆ°á»ng tÄƒng sá»‘ lÆ°á»£ng máº«u tÃ­ch cá»±c, sá»‘ lÆ°á»£ng máº«u tiÃªu cá»±c tÄƒng tÆ°Æ¡ng á»©ng (tá»©c lÃ  Ä‘á»‘i vá»›i má»—i máº«u tÃ­ch cá»±c, chÃºng tÃ´i táº¡o ngáº«u nhiÃªn má»™t máº«u tiÃªu cá»±c). Äá»ƒ Ä‘áº£m báº£o ráº±ng sá»± khÃ¡c biá»‡t vá» hiá»‡u suáº¥t thá»±c sá»± lÃ  káº¿t quáº£ cá»§a DA, chá»© khÃ´ng pháº£i sá»± Ä‘a dáº¡ng Ä‘Æ°á»£c Ä‘Æ°a ra bá»Ÿi cÃ¡c máº«u tiÃªu cá»±c má»›i, chÃºng tÃ´i Ä‘Ã£ táº¡o ra má»™t baseline bá»• sung, ğ·ğ‘Ÿğ‘’ğ‘, láº·p láº¡i cÃ¡c máº«u tÃ­ch cá»±c mÃ  khÃ´ng tÄƒng cÆ°á»ng 10 láº§n, vÃ  tÆ°Æ¡ng á»©ng, cÅ©ng thÃªm 10 máº«u tiÃªu cá»±c má»›i. Thá»±c táº¿, sá»± khÃ¡c biá»‡t duy nháº¥t giá»¯a ğ·ğ‘Ÿğ‘’ğ‘ vÃ  ğ·ğ‘ğ‘¢ğ‘” lÃ  thá»±c táº¿ ráº±ng ğ·ğ‘ğ‘¢ğ‘” sá»­ dá»¥ng cÃ¡c bÃ¡o cÃ¡o lá»—i Ä‘Æ°á»£c tÄƒng cÆ°á»ng trong khi ğ·ğ‘Ÿğ‘’ğ‘ láº·p láº¡i cÃ¡c máº«u tÃ­ch cá»±c. Táº¥t cáº£ cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c Ä‘Ã¡nh giÃ¡ trÃªn cÃ¹ng má»™t táº­p kiá»ƒm tra (khÃ´ng Ä‘Æ°á»£c tÄƒng cÆ°á»ng). VÃ¬ TBERT-Single yÃªu cáº§u thá»i gian Ä‘Ã¡ng ká»ƒ hÆ¡n so vá»›i cÃ¡c mÃ´ hÃ¬nh khÃ¡c (vÃ­ dá»¥: TBERT-Single máº¥t hÆ¡n 24 giá» Ä‘á»ƒ cháº¡y trÃªn dá»± Ã¡n JDT), chÃºng tÃ´i chá»‰ Ä‘Ã¡nh giÃ¡ nÃ³ trÃªn má»™t trong cÃ¡c táº­p dá»¯ liá»‡u cÃ¢n báº±ng - ğ·ğ‘ğ‘™1- vÃ¬ nÃ³ thá»ƒ hiá»‡n hiá»‡u suáº¥t tá»‘t nháº¥t cho TBERT-Siamese, sá»­ dá»¥ng kiáº¿n trÃºc DL tÆ°Æ¡ng Ä‘á»‘i tÆ°Æ¡ng tá»± vá»›i TBERT-Single.

Äá»ƒ Ä‘Ã¡nh giÃ¡ Ã½ nghÄ©a thá»‘ng kÃª cá»§a sá»± khÃ¡c biá»‡t vá» hiá»‡u suáº¥t khi huáº¥n luyá»‡n cÃ¡c mÃ´ hÃ¬nh DL cÃ³ vÃ  khÃ´ng cÃ³ tÄƒng cÆ°á»ng dá»¯ liá»‡u, chÃºng tÃ´i sá»­ dá»¥ng kiá»ƒm Ä‘á»‹nh t ghÃ©p cáº·p cá»§a Student Ä‘á»ƒ tÃ­nh cÃ¡c giÃ¡ trá»‹ ğ‘ giá»¯a cÃ¡c chá»‰ sá»‘ hiá»‡u suáº¥t cá»§a ğ·ğ‘œğ‘Ÿğ‘– vÃ  táº¥t cáº£ cÃ¡c táº­p dá»¯ liá»‡u khÃ¡c (tá»©c lÃ  ğ·ğ‘Ÿğ‘’ğ‘, ğ·ğ‘ğ‘¢ğ‘”, ğ·ğ‘ğ‘™âˆ—) [47,52]. Kiá»ƒm Ä‘á»‹nh giáº£ Ä‘á»‹nh cÃ¡c giÃ¡ trá»‹ hiá»‡u suáº¥t Ä‘Æ°á»£c phÃ¢n phá»‘i bÃ¬nh thÆ°á»ng. ChÃºng tÃ´i xem xÃ©t ğ‘<0.05 lÃ  cÃ³ Ã½ nghÄ©a thá»‘ng kÃª.

Káº¿t quáº£. Báº£ng 4 cho tháº¥y hiá»‡u suáº¥t truy xuáº¥t cá»§a FBL-BERT, TBERT-Siamese vÃ  TBERT-Single Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn bá»‘n táº­p dá»¯ liá»‡u: ğ·ğ‘œğ‘Ÿğ‘–, ğ·ğ‘Ÿğ‘’ğ‘, ğ·ğ‘ğ‘¢ğ‘” vÃ  ğ·ğ‘ğ‘™âˆ—, trong Ä‘Ã³ ğ·ğ‘ğ‘™âˆ— biá»ƒu thá»‹ táº­p dá»¯ liá»‡u cÃ¢n báº±ng cÃ³ hiá»‡u suáº¥t tá»‘t nháº¥t trung bÃ¬nh cho mÃ´ hÃ¬nh Ä‘Ã£ cho. Pháº§n trÃªn cá»§a báº£ng cho tháº¥y káº¿t quáº£ trÃªn cÃ¡c bÃ¡o cÃ¡o lá»—i tá»« táº¥t cáº£ cÃ¡c dá»± Ã¡n, tiáº¿p theo lÃ  káº¿t quáº£ theo dá»± Ã¡n. NÃ³i chung, chÃºng tÃ´i quan sÃ¡t ráº±ng cÃ¡c mÃ´ hÃ¬nh cáº£i thiá»‡n trÃªn táº¥t cáº£ cÃ¡c chá»‰ sá»‘ so vá»›i ğ·ğ‘œğ‘Ÿğ‘–, vá»›i cáº£i thiá»‡n tháº¥p nháº¥t Ä‘Æ°á»£c ghi nháº­n cho ğ·ğ‘Ÿğ‘’ğ‘, tiáº¿p theo lÃ  ğ·ğ‘ğ‘¢ğ‘”, vÃ  vá»›i cáº£i thiá»‡n cao nháº¥t Ä‘Æ°á»£c ghi láº¡i cho ğ·ğ‘ğ‘™âˆ—.

TÃ¹y thuá»™c vÃ o mÃ´ hÃ¬nh, quy mÃ´ cá»§a sá»± cáº£i thiá»‡n khÃ¡c nhau. Trong khi Ä‘iá»ƒm MRR cho FBL-BERT tÄƒng tá»« 0.264 cho ğ·ğ‘œğ‘Ÿğ‘– lÃªn 0.367 cho ğ·ğ‘ğ‘™âˆ—, khoáº£ng má»™t ná»­a sá»± cáº£i thiá»‡n cÃ³ thá»ƒ Ä‘Æ°á»£c quy cho kÃ­ch thÆ°á»›c táº­p dá»¯ liá»‡u nhÆ° Ä‘Æ°á»£c chá»‰ ra bá»Ÿi káº¿t quáº£ cho ğ·ğ‘Ÿğ‘’ğ‘ vá»›i Ä‘iá»ƒm MRR lÃ  0.307. HÆ¡n ná»¯a, chÃºng tÃ´i cÅ©ng quan sÃ¡t ráº±ng ğ·ğ‘ğ‘¢ğ‘” cáº£i thiá»‡n Ä‘iá»ƒm tá»« 0.307 cho ğ·ğ‘Ÿğ‘’ğ‘ lÃªn 0.353, chá»‰ ra ráº±ng viá»‡c sá»­ dá»¥ng má»™t táº­p dá»¯ liá»‡u Ä‘Æ°á»£c tÄƒng cÆ°á»ng táº¡o ra sá»± khÃ¡c biá»‡t khÃ´ng chá»‰ thÃ´ng qua sá»‘ lÆ°á»£ng dá»¯ liá»‡u. Sá»± cáº£i thiá»‡n giá»¯a ğ·ğ‘ğ‘¢ğ‘” vÃ  ğ·ğ‘ğ‘™âˆ— lÃ  biÃªn vÃ  báº±ng 0.014, chá»‰ ra ráº±ng ngay cáº£ cáº¥u hÃ¬nh cÃ¢n báº±ng tá»‘t nháº¥t cÃ³ tÃ¡c Ä‘á»™ng nhá» Ä‘á»‘i vá»›i FBL-BERT nÃ³i chung.

Huáº¥n luyá»‡n vá»›i má»™t táº­p dá»¯ liá»‡u cÃ¢n báº±ng cÃ³ tÃ¡c Ä‘á»™ng lá»›n hÆ¡n Ä‘á»‘i vá»›i TBERT-Single vÃ  TBERT-Siamese vá»›i sá»± cáº£i thiá»‡n 0.035 vÃ  0.092 trong Ä‘iá»ƒm MRR tÆ°Æ¡ng á»©ng khi so sÃ¡nh vá»›i ğ·ğ‘ğ‘¢ğ‘”. HÆ¡n ná»¯a, cÃ¢n báº±ng dá»¯ liá»‡u lÃ  Ä‘Ã³ng gÃ³p chÃ­nh cho sá»± cáº£i thiá»‡n trong TBERT-Siamese mÃ  sá»± khÃ¡c biá»‡t cÃ³ Ã½ nghÄ©a thá»‘ng kÃª chá»‰ Ä‘Æ°á»£c quan sÃ¡t cho ğ·ğ‘ğ‘™âˆ—. Trong trÆ°á»ng há»£p TBERT-Single, huáº¥n luyá»‡n mÃ´ hÃ¬nh vá»›i cáº£ ğ·ğ‘ğ‘¢ğ‘” vÃ  ğ·ğ‘ğ‘™âˆ— dáº«n Ä‘áº¿n cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ trÃªn táº¥t cáº£ cÃ¡c chá»‰ sá»‘.

RQ1 (a): TÄƒng cÆ°á»ng dá»¯ liá»‡u cáº£i thiá»‡n káº¿t quáº£ Ä‘á»‹nh vá»‹ lá»—i dá»±a trÃªn DL trÃªn táº¥t cáº£ cÃ¡c mÃ´ hÃ¬nh. Viá»‡c sá»­ dá»¥ng cÃ¢n báº±ng dá»¯ liá»‡u vá»›i tÄƒng cÆ°á»ng cÃ³ thá»ƒ cáº£i thiá»‡n hiá»‡u suáº¥t hÆ¡n ná»¯a.

Báº£ng 5 cho tháº¥y Ä‘á»™ chÃ­nh xÃ¡c truy xuáº¥t cho FBL-BERT vÃ  TBERT-Siamese khi cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn cÃ¡c táº­p dá»¯ liá»‡u cÃ¢n báº±ng khÃ¡c nhau, vá»›i cÃ¡c giÃ¡ trá»‹ cá»§a ğ›¼, ğœ” vÃ  kÃ­ch thÆ°á»›c táº­p dá»¯ liá»‡u Ä‘Æ°á»£c cung cáº¥p á»Ÿ phÃ­a bÃªn pháº£i cá»§a báº£ng. Trong trÆ°á»ng há»£p FBL-BERT, ğ·ğ‘ğ‘™2 vÃ  ğ·ğ‘ğ‘™3 cung cáº¥p hiá»‡u suáº¥t tá»‘t nháº¥t trung bÃ¬nh, cáº£i thiá»‡n MRR vÃ  MAP láº§n lÆ°á»£t 16.8% vÃ  14.8% so vá»›i ğ·ğ‘ğ‘™1 vÃ  ğ·ğ‘ğ‘™4. Tuy nhiÃªn, nhÆ° Ä‘Ã£ lÆ°u Ã½ trÆ°á»›c Ä‘Ã³, sá»± cáº£i thiá»‡n so vá»›i táº­p dá»¯ liá»‡u khÃ´ng cÃ¢n báº±ng ğ·ğ‘ğ‘¢ğ‘” lÃ  biÃªn. Trong trÆ°á»ng há»£p TBERT-Siamese, táº­p dá»¯ liá»‡u cÃ¢n báº±ng nhá» nháº¥t, ğ·ğ‘ğ‘™1, táº¡o ra Ä‘iá»ƒm MRR cao nháº¥t lÃ  0.328 vÆ°á»£t trá»™i hÆ¡n táº­p dá»¯ liá»‡u cÃ¢n báº±ng khÃ¡c Ã­t nháº¥t 49%.

Sá»± khÃ¡c biá»‡t trong hiá»‡u suáº¥t cá»§a cÃ¡c mÃ´ hÃ¬nh vá»›i cÃ¡c táº­p dá»¯ liá»‡u khÃ¡c nhau cÃ³ thá»ƒ Ä‘Æ°á»£c quy cho (1) sá»± khÃ¡c biá»‡t tá»•ng thá»ƒ trong kiáº¿n trÃºc cá»§a cÃ¡c mÃ´ hÃ¬nh áº£nh hÆ°á»Ÿng Ä‘áº¿n nhu cáº§u dá»¯ liá»‡u huáº¥n luyá»‡n cá»§a mÃ´ hÃ¬nh; vÃ  (2) kÃ­ch thÆ°á»›c cá»§a má»—i dá»± Ã¡n Ä‘Æ°á»£c Ä‘o báº±ng sá»‘ lÆ°á»£ng hunk (xem Báº£ng 2). Äá»ƒ hiá»ƒu rÃµ hÆ¡n liá»‡u vÃ  khi nÃ o mÃ´ hÃ¬nh cÃ³ thá»ƒ yÃªu cáº§u nhiá»u dá»¯ liá»‡u hÆ¡n, trong HÃ¬nh 4 chÃºng tÃ´i hiá»ƒn thá»‹ Ä‘iá»ƒm MRR trÃªn táº¥t cáº£ cÃ¡c dá»± Ã¡n Ä‘Ã¡nh giÃ¡ Ä‘Æ°á»£c sáº¯p xáº¿p theo kÃ­ch thÆ°á»›c cá»§a chÃºng, tá»©c lÃ  sá»‘ lÆ°á»£ng hunk trong má»™t dá»± Ã¡n.

RQ1 (b): Káº¿t quáº£ chá»‰ ra ráº±ng cÃ¡c kiáº¿n trÃºc mÃ´ hÃ¬nh khÃ¡c nhau cÃ³ thá»ƒ cÃ³ nhu cáº§u khÃ¡c nhau vá» kÃ­ch thÆ°á»›c táº­p dá»¯ liá»‡u huáº¥n luyá»‡n Ä‘á»ƒ Ä‘áº¡t Ä‘Æ°á»£c hiá»‡u suáº¥t tá»‘i Æ°u cá»§a chÃºng. Má»™t sá»‘ mÃ´ hÃ¬nh Ä‘Æ°á»£c hÆ°á»Ÿng lá»£i tá»« nhiá»u máº«u Ä‘Æ°á»£c tÄƒng cÆ°á»ng hÆ¡n, Ä‘áº·c biá»‡t Ä‘á»‘i vá»›i cÃ¡c dá»± Ã¡n lá»›n hÆ¡n.

5.2 RQ2: ToÃ¡n tá»­ DA nÃ o trong sá»‘ cÃ¡c toÃ¡n tá»­ DA Ä‘Æ°á»£c Ä‘á» xuáº¥t Ä‘Ã³ng gÃ³p nhiá»u nháº¥t cho hiá»‡u suáº¥t truy xuáº¥t?

Thiáº¿t láº­p. Äá»ƒ hiá»ƒu rÃµ hÆ¡n áº£nh hÆ°á»Ÿng cá»§a cÃ¡c toÃ¡n tá»­ tÄƒng cÆ°á»ng dá»¯ liá»‡u Ä‘Æ°á»£c Ä‘á» xuáº¥t Ä‘á»‘i vá»›i hiá»‡u quáº£ mÃ´ hÃ¬nh xuÃ´i dÃ²ng, chÃºng tÃ´i thá»±c hiá»‡n cÃ¡c nghiÃªn cá»©u ablation trÃªn cÃ¡c táº­p dá»¯ liá»‡u huáº¥n luyá»‡n Ä‘Æ°á»£c táº¡o ra báº±ng cÃ¡ch sá»­ dá»¥ng táº¥t cáº£ trá»« má»™t loáº¡i toÃ¡n tá»­ tÄƒng cÆ°á»ng. Äá»ƒ lÃ m Ä‘iá»u nÃ y, chÃºng tÃ´i táº¡o ra 5 loáº¡i táº­p dá»¯ liá»‡u huáº¥n luyá»‡n Ä‘Æ°á»£c tÄƒng cÆ°á»ng: No Backtranslation, No Insert, No Delete, No Replace vÃ  No Swap operator. LÆ°u Ã½ ráº±ng chÃºng tÃ´i xem xÃ©t, vÃ­ dá»¥, cáº£ Code Token Swap vÃ  Random Swap nhÆ° cÃ¡c toÃ¡n tá»­ loáº¡i Swap. Äá»ƒ cÃ¢n báº±ng cÃ¡c táº­p dá»¯ liá»‡u, chÃºng tÃ´i sá»­ dá»¥ng cÃ¡c giÃ¡ trá»‹ ğ›¼ vÃ  ğœ” tá»« RQ1 dáº«n Ä‘áº¿n hiá»‡u suáº¥t tá»‘t nháº¥t cho cÃ¡c mÃ´ hÃ¬nh, tá»©c lÃ  Ä‘á»‘i vá»›i FBL-BERT ğ›¼=0.85, ğœ”=2.0, trong khi Ä‘á»‘i vá»›i cÃ¡c mÃ´ hÃ¬nh TBERT ğ›¼=0.7, vÃ  ğœ”=1.0.

Káº¿t quáº£. HÃ¬nh 5 cho tháº¥y Ä‘iá»ƒm MRR cho cÃ¡c táº­p dá»¯ liá»‡u Ä‘Æ°á»£c tÄƒng cÆ°á»ng vá»›i 4 trong sá»‘ 5 loáº¡i toÃ¡n tá»­ cÅ©ng nhÆ° Ä‘iá»ƒm MRR cá»§a ğ·ğ‘œğ‘Ÿğ‘– vÃ  ğ·ğ‘ğ‘¢ğ‘” nhÆ° cÃ¡c Ä‘Æ°á»ng ngang Ä‘á»ƒ tham kháº£o. ChÃºng tÃ´i lÆ°u Ã½ ráº±ng háº§u háº¿t cÃ¡c toÃ¡n tá»­ Ä‘Ã³ng gÃ³p vÃ o hiá»‡u suáº¥t cuá»‘i cÃ¹ng, vá»›i má»™t ngoáº¡i lá»‡ lÃ  toÃ¡n tá»­ Swap cho FBL-BERT. Viá»‡c thiáº¿u tÃ¡c Ä‘á»™ng cho toÃ¡n tá»­ Swap cÃ³ thá»ƒ Ä‘Æ°á»£c quy cho kiáº¿n trÃºc mÃ´ hÃ¬nh. Cho ráº±ng FBL-BERT táº­n dá»¥ng táº¥t cáº£ cÃ¡c token trong má»™t bÃ¡o cÃ¡o lá»—i riÃªng biá»‡t, viá»‡c hoÃ¡n Ä‘á»•i vá»‹ trÃ­ token khÃ´ng ngÄƒn cáº£n chÃºng Ä‘Æ°á»£c khá»›p. Máº·t khÃ¡c, loáº¡i trá»« Random Insert áº£nh hÆ°á»Ÿng Ä‘áº¿n FBL-BERT nhiá»u nháº¥t, chá»‰ ra ráº±ng cÃ¡c token Ä‘Æ°á»£c chÃ¨n cÃ³ giÃ¡ trá»‹ Ä‘á»‘i vá»›i mÃ´ hÃ¬nh vÃ  cáº£i thiá»‡n hiá»‡u quáº£ cá»§a nÃ³ khi khá»›p token embedding. ToÃ¡n tá»­ Delete lÃ  Ä‘Ã³ng gÃ³p ná»•i báº­t nháº¥t cho hiá»‡u suáº¥t cá»§a cáº£ hai mÃ´ hÃ¬nh TBERT. Khi toÃ¡n tá»­ Delete khÃ´ng Ä‘Æ°á»£c phÃ©p trong quÃ¡ trÃ¬nh tÄƒng cÆ°á»ng, Ä‘iá»ƒm MRR cá»§a cÃ¡c táº­p dá»¯ liá»‡u Ä‘Æ°á»£c tÄƒng cÆ°á»ng giáº£m 0.054 vÃ  0.055 cho TBERT-Single vÃ  TBERT-Siamese tÆ°Æ¡ng á»©ng, chá»‰ ra ráº±ng phÆ°Æ¡ng sai gÃ¢y ra bá»Ÿi viá»‡c loáº¡i bá» token ngáº«u nhiÃªn cÃ³ tÃ¡c Ä‘á»™ng tÃ­ch cá»±c. ToÃ¡n tá»­ Delete, khi Ä‘Æ°á»£c Ã¡p dá»¥ng vá»›i má»©c Ä‘á»™ vá»«a pháº£i tÆ°Æ¡ng Ä‘á»‘i, dÆ°á»ng nhÆ° thÃªm vÃ o tÃ­nh máº¡nh máº½ cá»§a cÃ¡c mÃ´ hÃ¬nh, tá»©c lÃ  cÃ¡c mÃ´ hÃ¬nh táº¡o ra cÃ¡c liÃªn káº¿t bá»• sung giá»¯a cÃ¡c thuáº­t ngá»¯ vÃ  khÃ¡i niá»‡m trong cÃ¡c bÃ¡o cÃ¡o lá»—i vÃ  changeset. GiÃ¡ trá»‹ cá»§a quÃ¡ trÃ¬nh nÃ y cÅ©ng Ä‘Æ°á»£c há»— trá»£ bá»Ÿi cÃ´ng viá»‡c gáº§n Ä‘Ã¢y trong huáº¥n luyá»‡n Ä‘á»‘i khÃ¡ng cá»§a cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n, nhÆ° BERT, Ä‘á»ƒ cáº£i thiá»‡n tÃ­nh máº¡nh máº½ cá»§a chÃºng chá»‘ng láº¡i cÃ¡c cuá»™c táº¥n cÃ´ng Ä‘á»™c háº¡i [18].

RQ2: Táº¥t cáº£ cÃ¡c toÃ¡n tá»­ DA Ä‘Ã³ng gÃ³p vÃ o cáº£i thiá»‡n hiá»‡u suáº¥t vá»›i má»©c Ä‘á»™ khÃ¡c nhau, ngoáº¡i trá»« Swap cho FBL-BERT. ToÃ¡n tá»­ Delete liÃªn tá»¥c cáº£i thiá»‡n hiá»‡u suáº¥t trong cáº£ ba mÃ´ hÃ¬nh.

5.3 Má»‘i Ä‘e dá»a Ä‘á»‘i vá»›i tÃ­nh há»£p lá»‡

CÃ³ má»™t sá»‘ má»‘i Ä‘e dá»a tÃ­nh há»£p lá»‡ Ä‘á»‘i vá»›i cÃ¡c phÃ¡t hiá»‡n cá»§a chÃºng tÃ´i. Má»™t má»‘i Ä‘e dá»a Ä‘á»‘i vá»›i tÃ­nh há»£p lá»‡ ná»™i bá»™ cá»§a nghiÃªn cá»©u lÃ  cÃ¡c lá»±a chá»n tham sá»‘ cho cÃ¡c mÃ´ hÃ¬nh Ä‘á»‹nh vá»‹ lá»—i dá»±a trÃªn DL, Ä‘áº·c biá»‡t trong bá»‘i cáº£nh (1) quy trÃ¬nh huáº¥n luyá»‡n; (2) lá»±a chá»n BERT-base; vÃ  (3) cÃ¡c tham sá»‘ vá»‘n cÃ³ cá»§a má»—i mÃ´ hÃ¬nh. Äá»ƒ giáº£m thiá»ƒu má»‘i Ä‘e dá»a Ä‘Ã³, trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n chÃºng tÃ´i tuÃ¢n theo cÃ¡c khuyáº¿n nghá»‹ cá»§a cÃ¡c tÃ¡c giáº£ BERT [10], trong khi Ä‘á»‘i vá»›i má»—i mÃ´ hÃ¬nh chÃºng tÃ´i sá»­ dá»¥ng cÃ¡c tham sá»‘ Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh lÃ  tá»‘i Æ°u bá»Ÿi cÃ¡c nghiÃªn cá»©u trÆ°á»›c Ä‘Ã³ [6,29]. Máº·c dÃ¹ trong nghiÃªn cá»©u cá»§a chÃºng tÃ´i, chÃºng tÃ´i sá»­ dá»¥ng BERTOverflow lÃ m mÃ´ hÃ¬nh BERT cÆ¡ sá»Ÿ cá»§a chÃºng tÃ´i, cÃ¡c lá»±a chá»n khÃ¡c tá»“n táº¡i (vÃ­ dá»¥: CodeBERT [12]), vÃ  nhiá»u mÃ´ hÃ¬nh Ä‘ang Ä‘Æ°á»£c phÃ¡t triá»ƒn, do Ä‘Ã³ chÃºng tÃ´i Ä‘á»ƒ láº¡i viá»‡c Ä‘Ã¡nh giÃ¡ cÃ¡c mÃ´ hÃ¬nh BERT cÆ¡ sá»Ÿ khÃ¡c nhau trong bá»‘i cáº£nh Ä‘á»‹nh vá»‹ lá»—i cho cÃ´ng viá»‡c tÆ°Æ¡ng lai.

Má»™t má»‘i Ä‘e dá»a ná»™i bá»™ khÃ¡c lÃ  trong cÃ¡c lá»±a chá»n cá»§a chÃºng tÃ´i vá» cÃ¡c toÃ¡n tá»­ tÄƒng cÆ°á»ng, tham sá»‘ cá»§a chÃºng (vÃ­ dá»¥: ğœ†), vÃ  cÃ¡ch chÃºng Ä‘Æ°á»£c Ã¡p dá»¥ng cÃ¹ng nhau (vÃ­ dá»¥: xáº¿p chá»“ng cÃ¡c toÃ¡n tá»­). Má»‘i Ä‘e dá»a nÃ y Ä‘Æ°á»£c giáº£m thiá»ƒu báº±ng cÃ¡ch tuÃ¢n theo cÃ¡c thá»±c hÃ nh tá»‘t nháº¥t Ä‘Æ°á»£c biáº¿t Ä‘áº¿n tá»« vÄƒn há»c tÄƒng cÆ°á»ng NLP táº­p trung vÃ o cÃ¡c toÃ¡n tá»­ má»©c token vÃ  cÃ¡c tÃ¡c vá»¥ trong lÄ©nh vá»±c [25,57]. Máº·c dÃ¹ chÃºng tÃ´i khÃ¡m phÃ¡ má»™t sá»‘ lá»±a chá»n tham sá»‘ cho cÃ¢n báº±ng dá»¯ liá»‡u trong bÃ i bÃ¡o (vÃ­ dá»¥: ğ›¼ vÃ  ğœ”), cÅ©ng cÃ³ cÃ¡c tham sá»‘ bá»• sung liÃªn quan Ä‘áº¿n quÃ¡ trÃ¬nh xÃ¢y dá»±ng bÃ¡o cÃ¡o lá»—i cÅ©ng nhÆ° cÃ¡c toÃ¡n tá»­ tÄƒng cÆ°á»ng khÃ¡c cÃ³ thá»ƒ cung cáº¥p sá»± cáº£i thiá»‡n hÆ¡n.

CÃ¡c cÃ´ng cá»¥ bÃªn ngoÃ i mÃ  chÃºng tÃ´i táº­n dá»¥ng Ä‘á»ƒ xÃ¢y dá»±ng pipeline tÄƒng cÆ°á»ng cá»§a chÃºng tÃ´i, vÃ­ dá»¥: infozilla, cÃ´ng cá»¥ BEE, cÃ³ thá»ƒ Ä‘Æ°a ra nhiá»…u lan truyá»n Ä‘áº¿n cÃ¡c káº¿t quáº£ Ä‘Æ°á»£c bÃ¡o cÃ¡o cá»§a chÃºng tÃ´i. Tuy nhiÃªn, Ä‘Ã¢y lÃ  cÃ¡c cÃ´ng cá»¥ hiá»‡n Ä‘áº¡i Ä‘Ã£ Ä‘Æ°á»£c Ä‘Ã¡nh giÃ¡ ká»¹ lÆ°á»¡ng nÃªn tá»· lá»‡ lá»—i cá»§a chÃºng nÃªn Ä‘Æ°á»£c háº¡n cháº¿.

HÆ¡n ná»¯a, tÃ­nh ngáº«u nhiÃªn cá»§a cÃ¡c toÃ¡n tá»­ tÄƒng cÆ°á»ng cÃ³ thá»ƒ Ä‘áº·t ra má»‘i Ä‘e dá»a Ä‘á»‘i vá»›i tÃ­nh há»£p lá»‡ ná»™i bá»™. Äá»ƒ giáº£m thiá»ƒu Ä‘iá»u Ä‘Ã³, chÃºng tÃ´i Ä‘áº£m báº£o Ä‘áº·t má»™t giÃ¡ trá»‹ ban Ä‘áº§u trÃªn bá»™ táº¡o sá»‘ ngáº«u nhiÃªn giáº£ cá»§a há»‡ thá»‘ng khi xÃ¢y dá»±ng má»™t táº­p dá»¯ liá»‡u Ä‘Æ°á»£c tÄƒng cÆ°á»ng cÅ©ng nhÆ° khi huáº¥n luyá»‡n má»™t mÃ´ hÃ¬nh DL.

Má»™t má»‘i Ä‘e dá»a Ä‘á»‘i vá»›i tÃ­nh há»£p lá»‡ bÃªn ngoÃ i lÃ  chÃºng tÃ´i chá»‰ Ä‘Ã¡nh giÃ¡ ká»¹ thuáº­t tÄƒng cÆ°á»ng dá»¯ liá»‡u cho Ä‘á»‹nh vá»‹ lá»—i trÃªn má»™t sá»‘ lÆ°á»£ng háº¡n cháº¿ cÃ¡c lá»—i Ä‘Æ°á»£c thu tháº­p tá»« má»™t lá»±a chá»n cÃ¡c dá»± Ã¡n Java mÃ£ nguá»“n má»Ÿ. Má»‘i Ä‘e dá»a nÃ y Ä‘Æ°á»£c giáº£m thiá»ƒu bá»Ÿi thá»±c táº¿ ráº±ng táº­p dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c sá»­ dá»¥ng trong má»™t sá»‘ nghiÃªn cá»©u Ä‘á»‹nh vá»‹ lá»—i trÆ°á»›c Ä‘Ã³ [43,58,60]. Má»™t yáº¿u tá»‘ giáº£m thiá»ƒu khÃ¡c lÃ  cÃ¡c dá»± Ã¡n pháº£n Ã¡nh nhiá»u má»¥c Ä‘Ã­ch, phong cÃ¡ch phÃ¡t triá»ƒn vÃ  lá»‹ch sá»­ khÃ¡c nhau.

CÃ¡c háº¡n cháº¿ trong cÃ¡c chá»‰ sá»‘ Ä‘Ã¡nh giÃ¡ Ä‘Æ°á»£c chá»n Ä‘áº·t ra má»‘i Ä‘e dá»a Ä‘á»‘i vá»›i tÃ­nh há»£p lá»‡ káº¿t luáº­n vÃ¬ chÃºng cÃ³ thá»ƒ khÃ´ng Ä‘o lÆ°á»ng trá»±c tiáº¿p sá»± hÃ i lÃ²ng cá»§a ngÆ°á»i dÃ¹ng vá»›i cÃ¡c hunk thay Ä‘á»•i Ä‘Æ°á»£c truy xuáº¥t [54]. Má»‘i Ä‘e dá»a Ä‘Æ°á»£c giáº£m thiá»ƒu bá»Ÿi thá»±c táº¿ ráº±ng cÃ¡c chá»‰ sá»‘ Ä‘Æ°á»£c chá»n Ä‘Æ°á»£c biáº¿t Ä‘áº¿n rá»™ng rÃ£i vÃ  Ä‘Æ°á»£c cháº¥p nháº­n rá»™ng rÃ£i lÃ  tá»‘t nháº¥t cÃ³ sáºµn Ä‘á»ƒ Ä‘o lÆ°á»ng vÃ  so sÃ¡nh hiá»‡u suáº¥t cá»§a cÃ¡c ká»¹ thuáº­t IR.

6 Káº¾T LUáº¬N VÃ€ CÃ”NG VIá»†C TÆ¯Æ NG LAI

CÃ¡c mÃ´ hÃ¬nh DL hÆ°á»›ng tá»›i Ä‘á»‹nh vá»‹ lá»—i xuáº¥t sáº¯c trong viá»‡c thu háº¹p khoáº£ng cÃ¡ch tá»« vá»±ng giá»¯a ngÃ´n ngá»¯ tá»± nhiÃªn mÃ´ táº£ má»™t bÃ¡o cÃ¡o lá»—i vÃ  ngÃ´n ngá»¯ láº­p trÃ¬nh Ä‘á»‹nh nghÄ©a mÃ£ nguá»“n. Tuy nhiÃªn, viá»‡c huáº¥n luyá»‡n má»™t mÃ´ hÃ¬nh DL hiá»‡u quáº£ yÃªu cáº§u má»™t lÆ°á»£ng lá»›n dá»¯ liá»‡u Ä‘Æ°á»£c gáº¯n nhÃ£n cá»¥ thá»ƒ cá»§a dá»± Ã¡n (tá»©c lÃ  cÃ¡c cáº·p bÃ¡o cÃ¡o lá»—i vÃ  changeset gÃ¢y ra lá»—i), thÆ°á»ng khÃ³ thu tháº­p vá»›i sá»‘ lÆ°á»£ng Ä‘á»§ cho má»™t dá»± Ã¡n Ä‘Æ¡n láº». Äá»ƒ ná»›i lá»ng yÃªu cáº§u vá» sá»‘ lÆ°á»£ng dá»¯ liá»‡u, vÃ  cho phÃ©p sá»­ dá»¥ng mÃ´ hÃ¬nh DL khi dá»¯ liá»‡u huáº¥n luyá»‡n khan hiáº¿m, cÃ´ng trÃ¬nh nÃ y Ä‘á» xuáº¥t sá»­ dá»¥ng tÄƒng cÆ°á»ng dá»¯ liá»‡u (DA) Ä‘á»ƒ táº¡o ra cÃ¡c bÃ¡o cÃ¡o lá»—i má»›i, cÃ³ váº» thá»±c táº¿ cÃ³ thá»ƒ Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ tÄƒng Ä‘Ã¡ng ká»ƒ kÃ­ch thÆ°á»›c cá»§a táº­p huáº¥n luyá»‡n. Äá»ƒ tÄƒng cÆ°á»ng cÃ¡c bÃ¡o cÃ¡o lá»—i, chÃºng tÃ´i Ä‘á» xuáº¥t cÃ¡c toÃ¡n tá»­ DA hoáº¡t Ä‘á»™ng Ä‘á»™c láº­p tÄƒng cÆ°á»ng ná»™i dung ngÃ´n ngá»¯ tá»± nhiÃªn vÃ  liÃªn quan Ä‘áº¿n mÃ£ cá»§a má»™t bÃ¡o cÃ¡o lá»—i. Äá»ƒ xÃ¢y dá»±ng má»™t táº­p dá»¯ liá»‡u huáº¥n luyá»‡n má»›i sá»­ dá»¥ng cÃ¡c bÃ¡o cÃ¡o lá»—i Ä‘Æ°á»£c tÄƒng cÆ°á»ng, chÃºng tÃ´i Ä‘á» xuáº¥t má»™t chiáº¿n lÆ°á»£c cÃ¢n báº±ng dá»¯ liá»‡u cÃ³ chá»n lá»c tÄƒng cÆ°á»ng cÃ¡c bÃ¡o cÃ¡o lá»—i Ä‘á»ƒ thÃªm nhiá»u máº«u huáº¥n luyá»‡n hÆ¡n cho cÃ¡c pháº§n chÆ°a Ä‘Æ°á»£c Ä‘áº¡i diá»‡n cá»§a mÃ£ nguá»“n.

Káº¿t quáº£ chá»‰ ra ráº±ng tÄƒng cÆ°á»ng dá»¯ liá»‡u Ä‘Æ°á»£c Ä‘á» xuáº¥t cáº£i thiá»‡n Ä‘á»™ chÃ­nh xÃ¡c truy xuáº¥t trÃªn táº¥t cáº£ cÃ¡c mÃ´ hÃ¬nh DL Ä‘Æ°á»£c nghiÃªn cá»©u tÄƒng Ä‘iá»ƒm MRR tá»« 39% Ä‘áº¿n 82% so vá»›i táº­p dá»¯ liá»‡u gá»‘c, khÃ´ng Ä‘Æ°á»£c tÄƒng cÆ°á»ng. HÆ¡n ná»¯a, khi cÃ¡c táº­p dá»¯ liá»‡u Ä‘Æ°á»£c tÄƒng cÆ°á»ng Ä‘Æ°á»£c so sÃ¡nh vá»›i cÃ¡c táº­p huáº¥n luyá»‡n Ä‘Æ°á»£c má»Ÿ rá»™ng báº±ng láº·p láº¡i dá»¯ liá»‡u, chÃºng tÃ´i quan sÃ¡t ráº±ng chÃºng cáº£i thiá»‡n Ä‘iá»ƒm MRR tá»« 20% Ä‘áº¿n 36%. Táº¥t cáº£ cÃ¡c toÃ¡n tá»­ DA Ä‘Æ°á»£c Ä‘á» xuáº¥t Ä‘Ã³ng gÃ³p vÃ o hiá»‡u suáº¥t cuá»‘i cÃ¹ng, vá»›i viá»‡c xÃ³a token mang láº¡i tÃ¡c Ä‘á»™ng nháº¥t quÃ¡n nháº¥t cho cÃ¡c mÃ´ hÃ¬nh DL khÃ¡c nhau.

ÄÃ¢y lÃ  má»™t trong nhá»¯ng bÃ i bÃ¡o Ä‘áº§u tiÃªn giá»›i thiá»‡u tÄƒng cÆ°á»ng dá»¯ liá»‡u cho ká»¹ thuáº­t pháº§n má»m. ChÃºng tÃ´i tin ráº±ng tÄƒng cÆ°á»ng dá»¯ liá»‡u nhÆ° má»™t ká»¹ thuáº­t cÃ³ tiá»m nÄƒng cho SE bá»Ÿi vÃ¬ cÃ¡c táº­p dá»¯ liá»‡u khÃ´ng lá»›n báº±ng trong ML chÃ­nh thá»‘ng. NgoÃ i ra, tÄƒng cÆ°á»ng dá»¯ liá»‡u khÃ´ng pháº£i lÃ  ká»¹ thuáº­t phÃ¹ há»£p vá»›i táº¥t cáº£ vÃ  viá»‡c Ã¡p dá»¥ng tá»‘i Æ°u cá»§a nÃ³ yÃªu cáº§u cÃ¡c toÃ¡n tá»­ tÃ¹y chá»‰nh, vÃ¬ váº­y bÃ i bÃ¡o Ä‘Ã³ng gÃ³p trong viá»‡c thiáº¿t káº¿ cÃ¡c toÃ¡n tá»­ tÄƒng cÆ°á»ng dá»¯ liá»‡u cho cÃ¡c bÃ¡o cÃ¡o lá»—i vÃ  Ã¡p dá»¥ng chÃºng báº±ng cÃ¡ch sá»­ dá»¥ng má»™t chiáº¿n lÆ°á»£c cÃ¢n báº±ng dá»¯ liá»‡u.

Máº·c dÃ¹ váº­y, phÆ°Æ¡ng phÃ¡p Ä‘Æ°á»£c Ä‘á» xuáº¥t yÃªu cáº§u nhiá»u thÃ­ nghiá»‡m hÆ¡n Ä‘á»ƒ cá»§ng cá»‘ cÃ¡c quan sÃ¡t vÃ  khuyáº¿n nghá»‹ cá»§a chÃºng tÃ´i. NhÆ° cÃ´ng viá»‡c tÆ°Æ¡ng lai cá»§a chÃºng tÃ´i, chÃºng tÃ´i dá»± Ä‘á»‹nh (1) má»Ÿ rá»™ng cÃ¡c táº­p dá»¯ liá»‡u Ä‘Ã¡nh giÃ¡ cá»§a chÃºng tÃ´i vá»›i cÃ¡c dá»± Ã¡n pháº§n má»m má»›i Ä‘Æ°á»£c viáº¿t báº±ng Java, Python vÃ  Javascript; (2) tiáº¿n hÃ nh thÃ­ nghiá»‡m vá»›i dá»¯ liá»‡u Ä‘Æ°á»£c tÄƒng cÆ°á»ng náº·ng hÆ¡n, tá»©c lÃ  báº±ng cÃ¡ch sá»­ dá»¥ng cÃ¡c toÃ¡n tá»­ DA trÃªn má»™t sá»‘ lÆ°á»£ng lá»›n hÆ¡n cÃ¡c token; (3) thÃ­ nghiá»‡m vá»›i cÃ¡c toÃ¡n tá»­ xÃ³a khÃ¡c nhau (vÃ­ dá»¥: loáº¡i bá» cÃ¡c token mÃ£ khÃ´ng liÃªn quan) cho hiá»‡u suáº¥t tá»‘t cá»§a Random Delete cho ngÃ´n ngá»¯ tá»± nhiÃªn; vÃ  (4) thÃ­ nghiá»‡m vá»›i cÃ¡c cáº¥u hÃ¬nh khÃ¡c nhau cho trÃ¬nh xÃ¢y dá»±ng bÃ¡o cÃ¡o lá»—i.

7 TÃNH KHáº¢ Dá»¤NG Cá»¦A Dá»® LIá»†U

Má»™t gÃ³i sao chÃ©p bao gá»“m táº¥t cáº£ mÃ£ vÃ  script cÃ³ liÃªn quan cÃ³ sáºµn táº¡i https://anonymous.4open.science/r/fbl-bert-987B.

TÃ€I LIá»†U THAM KHáº¢O

[1] Nicolas Bettenburg, Sascha Just, Adrian SchrÃ¶ter, Cathrin Weiss, Rahul Premraj, vÃ  Thomas Zimmermann. 2008. What Makes a Good Bug Report?. In Proceedings of the 16th ACM SIGSOFT International Symposium on Foundations of Software Engineering (SIGSOFT '08/FSE-16).

[2] Gemma Catolino, Fabio Palomba, Andy Zaidman, vÃ  Filomena Ferrucci. 2019. Not all bugs are the same: Understanding, characterizing, and classifying bug types. Journal of Systems and Software (2019).

[3] O. Chaparro, J. M. Florez, vÃ  A. Marcus. 2017. Using Observed Behavior to Reformulate Queries during Text Retrieval-based Bug Localization. In 2017 IEEE International Conference on Software Maintenance and Evolution (ICSME). 376â€“387.

[4] Oscar Chaparro, Jing Lu, Fiorella Zampetti, Laura Moreno, Massimiliano Di Penta, Andrian Marcus, Gabriele Bavota, vÃ  Vincent Ng. 2017. Detecting Missing Information in Bug Descriptions. In Proceedings of the 2017 11th Joint Meeting on Foundations of Software Engineering (ESEC/FSE 2017).

[5] Jiaao Chen, Dinghan Shen, Weizhu Chen, vÃ  Diyi Yang. 2021. Hiddencut: Simple data augmentation for natural language understanding with better generalizability. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers). 4380â€“4390.

[6] Agnieszka Ciborowska vÃ  Kostadin Damevski. 2022. Fast Changeset-Based Bug Localization with BERT. In Proceedings of the 44th International Conference on Software Engineering (ICSE '22). Association for Computing Machinery, New York, NY, USA, 946â€“957.

[7] C. S. Corley, K. Damevski, vÃ  N. A. Kraft. 2018. Changeset-Based Topic Modeling of Software Repositories. IEEE Transactions on Software Engineering (2018).

[8] Daniel Alencar da Costa, Shane McIntosh, Weiyi Shang, UirÃ¡ Kulesza, Roberta Coelho, vÃ  Ahmed E. Hassan. 2017. A Framework for Evaluating the Results of the SZZ Approach for Identifying Bug-Introducing Changes. IEEE Transactions on Software Engineering (2017).

[9] Zhuyun Dai vÃ  Jamie Callan. 2019. Deeper Text Understanding for IR with Contextual Neural Language Modeling. In Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR'19).

[10] Jacob Devlin, Ming-Wei Chang, Kenton Lee, vÃ  Kristina Toutanova. 2019. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies.

[11] Steven Y Feng, Varun Gangal, Jason Wei, Sarath Chandar, Soroush Vosoughi, Teruko Mitamura, vÃ  Eduard Hovy. 2021. A survey of data augmentation approaches for nlp. arXiv preprint arXiv:2105.03075 (2021).

[12] Zhangyin Feng, Daya Guo, Duyu Tang, Nan Duan, Xiaocheng Feng, Ming Gong, Linjun Shou, Bing Qin, Ting Liu, Daxin Jiang, vÃ  Ming Zhou. 2020. CodeBERT: A Pre-Trained Model for Programming and Natural Languages. In Findings of the Association for Computational Linguistics: EMNLP 2020.

[13] Xiaodong Gu, Hongyu Zhang, vÃ  Sunghun Kim. 2018. Deep Code Search. In 2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE). 933â€“944.

[14] Jin Guo, Jinghui Cheng, vÃ  Jane Cleland-Huang. 2017. Semantically Enhanced Software Traceability Using Deep Learning Techniques. In Proceedings of the 39th International Conference on Software Engineering (ICSE '17).

[15] Rahul Gupta, Aditya Kanade, vÃ  Shirish Shevade. 2019. Neural Attribution for Semantic Bug-Localization in Student Programs. In Advances in Neural Information Processing Systems, H. Wallach, H. Larochelle, A. Beygelzimer, F. d 'AlchÃ©-Buc, E. Fox, vÃ  R. Garnett (Eds.), Vol. 32.

[16] Suchin Gururangan, Ana MarasoviÄ‡, Swabha Swayamdipta, Kyle Lo, Iz Beltagy, Doug Downey, vÃ  Noah A Smith. 2020. Don't stop pretraining: adapt language models to domains and tasks. arXiv preprint arXiv:2004.10964 (2020).

[17] Thong Hoang, Hoa Khanh Dam, Yasutaka Kamei, David Lo, vÃ  Naoyasu Ubayashi. 2019. DeepJIT: An End-to-End Deep Learning Framework for Just-in-Time Defect Prediction. In 2019 IEEE/ACM 16th International Conference on Mining Software Repositories (MSR). 34â€“45.

[18] Yu-Lun Hsieh, Minhao Cheng, Da-Cheng Juan, Wei Wei, Wen-Lian Hsu, vÃ  Cho-Jui Hsieh. 2019. On the Robustness of Self-Attentive Models. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics. Association for Computational Linguistics, Florence, Italy, 1520â€“1529. https://doi.org/10.18653/v1/P19-1147

[19] Xuan Huo, Ming Li, vÃ  Zhi-Hua Zhou. 2016. Learning Unified Features from Natural and Programming Languages for Locating Buggy Source Code. In Proceedings of the 25th International Joint Conference on Artificial Intelligence (IJCAI'16).

[20] X. Huo, F. Thung, M. Li, D. Lo, vÃ  S. Shi. 2019. Deep Transfer Bug Localization. IEEE Transactions on Software Engineering (2019), 1â€“1. https://doi.org/10.1109/TSE.2019.2920771

[21] Hamel Husain, Ho-Hsiang Wu, Tiferet Gazit, Miltiadis Allamanis, vÃ  Marc Brockschmidt. 2019. CodeSearchNet challenge: Evaluating the state of semantic code search. arXiv preprint arXiv:1909.09436 (2019).

[22] Omar Khattab vÃ  Matei Zaharia. 2020. ColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT. In Proceedings of the 43rd International ACM SIGIR conference on research and development in Information Retrieval (SIGIR '20).

[23] Diederik P. Kingma vÃ  Jimmy Ba. 2014. Adam: A Method for Stochastic Optimization. https://arxiv.org/abs/1412.6980

[24] Pavneet Singh Kochhar, Yuan Tian, vÃ  David Lo. 2014. Potential Biases in Bug Localization: Do They Matter?. In Proceedings of the 29th ACM/IEEE International Conference on Automated Software Engineering (Vasteras, Sweden) (ASE '14). 803â€“814.

[25] Venelin Kovatchev, Phillip Smith, Mark Lee, vÃ  Rory Devine. 2021. Can vectors read minds better than experts? Comparing data augmentation strategies for the automated scoring of children's mindreading ability. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers).

[26] An Ngoc Lam, Anh Tuan Nguyen, Hoan Anh Nguyen, vÃ  Tien N. Nguyen. 2017. Bug Localization with Combination of Deep Learning and Information Retrieval. In Proceedings of the 25th International Conference on Program Comprehension (ICPC '17). IEEE Press. https://doi.org/10.1109/ICPC.2017.24

[27] Jaekwon Lee, Dongsun Kim, TegawendÃ© F. BissyandÃ©, Woosung Jung, vÃ  Yves Le Traon. 2018. Bench4BL: Reproducibility Study on the Performance of IR-based Bug Localization. In Proceedings of the 27th ACM SIGSOFT International Symposium on Software Testing and Analysis (Amsterdam, Netherlands) (ISSTA 2018). 61â€“72.

[28] Jian Li, Pinjia He, Jieming Zhu, vÃ  Michael R. Lyu. 2017. Software Defect Prediction via Convolutional Neural Network. In 2017 IEEE International Conference on Software Quality, Reliability and Security (QRS). 318â€“328.

[29] Jinfeng Lin, Yalin Liu, Qingkai Zeng, Meng Jiang, vÃ  Jane Cleland-Huang. 2021. Traceability transformed: Generating more accurate links with pre-trained BERT models. In 2021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE). IEEE, 324â€“335.

[30] Vijayaraghavan Murali, Lee Gross, Rebecca Qian, vÃ  Satish Chandra. 2020. Industry-scale IR-based Bug Localization: A Perspective from Facebook. In Proceedings of the 42nd International Conference on Software Engineering (ICSE '20).

[31] E. C. Neto, D. A. da Costa, vÃ  U. Kulesza. 2018. The impact of refactoring changes on the SZZ algorithm: An empirical study. In IEEE 25th International Conference on Software Analysis, Evolution and Reengineering (SANER) (SANER 2018).

[32] Nathan Ng, Kyra Yee, Alexei Baevski, Myle Ott, Michael Auli, vÃ  Sergey Edunov. 2019. Facebook FAIR's WMT19 News Translation Task Submission. In Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1).

[33] A. T. Nguyen, T. T. Nguyen, J. Al-Kofahi, H. V. Nguyen, vÃ  T. N. Nguyen. 2011. A Topic-based Approach for Narrowing the Search Space of Buggy Files from a Bug Report. In Proceedings of the 26th IEEE/ACM International Conference on Automated Software Engineering (ASE 2011). 263â€“272. https://doi.org/10.1109/ASE.2011.6100062

[34] Toan Q Nguyen, Kenton Murray, vÃ  David Chiang. 2021. Data Augmentation by Concatenation for Low-Resource Translation: A Mystery and a Solution. arXiv preprint arXiv:2105.01691 (2021).

[35] Rodrigo Nogueira vÃ  Kyunghyun Cho. 2019. Passage Re-ranking with BERT. https://doi.org/10.48550/ARXIV.1901.04085

[36] Matteo Paltenghi vÃ  Michael Pradel. 2021. Thinking Like a Developer? Comparing the Attention of Humans with Neural Models of Code. In 2021 36th IEEE/ACM International Conference on Automated Software Engineering (ASE). IEEE, 867â€“879.

[37] Chanathip Pornprasit vÃ  Chakkrit Tantithamthavorn. 2022. DeepLineDP: Towards a Deep Learning Approach for Line-Level Defect Prediction. IEEE Transactions on Software Engineering (2022).

[38] Michael Pradel, Vijayaraghavan Murali, Rebecca Qian, Mateusz Machalica, Erik Meijer, vÃ  Satish Chandra. 2020. Scaffle: bug localization on millions of files. In Proceedings of the 29th ACM SIGSOFT International Symposium on Software Testing and Analysis.

[39] Rahul Premraj, Thomas Zimmermann, Sunghun Kim, vÃ  Nicolas Bettenburg. 2008. Extracting structural information from bug reports. In Proceedings of the 2008 international workshop on Mining software repositories - MSR 2008.

[40] Mohammad Masudur Rahman vÃ  Chanchal K Roy. 2018. Improving IR-based bug localization with context-aware query reformulation. In Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering. ACM, 621â€“632.

[41] Nils Reimers vÃ  Iryna Gurevych. 2019. Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks. arXiv:1908.10084 [cs.CL]

[42] Giovanni Rosa, Luca Pascarella, Simone Scalabrino, Rosalia Tufano, Gabriele Bavota, Michele Lanza, vÃ  Rocco Oliveto. 2021. Evaluating SZZ Implementations Through a Developer-informed Oracle. arXiv:2102.03300 [cs.SE]

[43] Ripon K. Saha, Matthew Lease, Sarfraz Khurshid, vÃ  Dewayne E. Perry. 2013. Improving Bug Localization Using Structured Information Retrieval. In Proceedings of the 28th IEEE/ACM International Conference on Automated Software Engineering (Silicon Valley, CA, USA) (ASE'13). 345â€“355.

[44] Dinghan Shen, Mingzhi Zheng, Yelong Shen, Yanru Qu, vÃ  Weizhu Chen. 2020. A Simple but Tough-to-Beat Data Augmentation Approach for Natural Language Understanding and Generation. arXiv preprint arXiv:2009.13818 (2020).

[45] Connor Shorten, Taghi M Khoshgoftaar, vÃ  Borko Furht. 2021. Text data augmentation for deep learning. Journal of big Data 8, 1 (2021), 1â€“34.

[46] Jacek Sliwerski, Thomas Zimmermann, vÃ  Andreas Zeller. 2005. When Do Changes Induce Fixes?. In Proceedings of the 2005 International Workshop on Mining Software Repositories (MSR '05).

[47] Mark D. Smucker, James Allan, vÃ  Ben Carterette. 2007. A Comparison of Statistical Significance Tests for Information Retrieval Evaluation. In Proceedings of the Sixteenth ACM Conference on Conference on Information and Knowledge Management (CIKM '07). 623â€“632.

[48] Yang Song vÃ  Oscar Chaparro. 2020. BEE: A Tool for Structuring and Analyzing Bug Reports. In Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering.

[49] Jeniya Tabassum, Mounica Maddela, Wei Xu, vÃ  Alan Ritter. 2020. Code and Named Entity Recognition in StackOverflow. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics.

[50] Huy Tu vÃ  Tim Menzies. 2021. FRUGAL: Unlocking SSL for Software Analytics. arXiv preprint arXiv:2108.09847 (2021).

[51] Huy Tu, Zhe Yu, vÃ  Tim Menzies. 2022. Better Data Labelling With EMBLEM (and how that Impacts Defect Prediction). IEEE Transactions on Software Engineering 48, 1 (2022), 278â€“294.

[52] JuliÃ¡n Urbano, Harlley Lima, vÃ  Alan Hanjalic. 2019. Statistical Significance Testing in Information Retrieval: An Empirical Analysis of Type I, Type II and Type III Errors. In Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval (Paris, France) (SIGIR'19).

[53] Bogdan Vasilescu, Yue Yu, Huaimin Wang, Premkumar Devanbu, vÃ  Vladimir Filkov. 2015. Quality and Productivity Outcomes Relating to Continuous Integration in GitHub. In Proceedings of the 2015 10th Joint Meeting on Foundations of Software Engineering (ESEC/FSE 2015).

[54] Qianqian Wang, Chris Parnin, vÃ  Alessandro Orso. 2015. Evaluating the Usefulness of IR-Based Fault Localization Techniques. In Proceedings of the 2015 International Symposium on Software Testing and Analysis (ISSTA 2015) (Baltimore, MD, USA). 1â€“11.

[55] Song Wang, Taiyue Liu, Jaechang Nam, vÃ  Lin Tan. 2020. Deep Semantic Feature Learning for Software Defect Prediction. IEEE Transactions on Software Engineering 46, 12 (2020).

[56] Shaowei Wang vÃ  David Lo. 2014. Version History, Similar Report, and Structure: Putting Them Together for Improved Bug Localization. In Proceedings of the 22Nd International Conference on Program Comprehension (Hyderabad, India) (ICPC 2014). 53â€“63.

[57] Jason Wei vÃ  Kai Zou. 2019. EDA: Easy Data Augmentation Techniques for Boosting Performance on Text Classification Tasks. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP).

[58] Ming Wen, Rongxin Wu, vÃ  Shing-Chi Cheung. 2016. Locus: Locating Bugs from Software Changes. In Proceedings of the 31st IEEE/ACM International Conference on Automated Software Engineering (Singapore, Singapore) (ASE 2016). 262â€“273.

[59] Ratnadira Widyasari, Stefanus Agus Haryono, Ferdian Thung, Jieke Shi, Constance Tan, Fiona Wee, Jack Phan, vÃ  David Lo. 2022. On the Influence of Biases in Bug Localization: Evaluation and Benchmark. In Proceedings of the 29th IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER), RENE Track. (SANER 2022).

[60] Chu-Pan Wong, Yingfei Xiong, Hongyu Zhang, Dan Hao, Lu Zhang, vÃ  Hong Mei. 2014. Boosting Bug-Report-Oriented Fault Localization with Segmentation and Stack-Trace Analysis. In Proceedings of the 2014 IEEE International Conference on Software Maintenance and Evolution (ICSME '14). 181â€“190.

[61] Xueqing Wu, Yingce Xia, Jinhua Zhu, Lijun Wu, Shufang Xie, Yang Fan, vÃ  Tao Qin. 2021. mixSeq: A Simple Data Augmentation Methodfor Neural Machine Translation. In Proceedings of the 18th International Conference on Spoken Language Translation (IWSLT 2021).

[62] Yan Xiao, Jacky Keung, Kwabena E. Bennin, vÃ  Qing Mi. 2019. Improving bug localization with word embedding and enhanced convolutional neural networks. Information and Software Technology 105 (2019).

[63] Xinli Yang, David Lo, Xin Xia, Yun Zhang, vÃ  Jianling Sun. 2015. Deep Learning for Just-in-Time Defect Prediction. In 2015 IEEE International Conference on Software Quality, Reliability and Security. 17â€“26. https://doi.org/10.1109/QRS.2015.14

[64] Xin Ye, Razvan Bunescu, vÃ  Chang Liu. 2014. Learning to Rank Relevant Files for Bug Reports Using Domain Knowledge. In Proceedings of the 22Nd ACM SIGSOFT International Symposium on Foundations of Software Engineering (Hong Kong, China) (FSE 2014). 689â€“699.

[65] Rahul Yedida vÃ  Tim Menzies. 2021. On the value of oversampling for deep learning in software defect prediction. IEEE Transactions on Software Engineering (2021).

[66] W. Zou, D. Lo, Z. Chen, X. Xia, Y. Feng, vÃ  B. Xu. 2020. How Practitioners Perceive Automated Bug Report Management Techniques. IEEE Transactions on Software Engineering 46, 8 (2020).

# 2305.09082.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/coding/2305.09082.pdf
# Kích thước tệp: 676415 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
Tốt, Xấu và Thiếu Sót: Sinh Mã Thần Kinh cho Các Tác Vụ Học Máy
JIHO SHIN, Đại học York, Canada
MOSHI WEI, Đại học York, Canada
JUNJIE WANG, Viện Phần mềm, Viện Hàn lâm Khoa học Trung Quốc, Trung Quốc
LIN SHI, Viện Phần mềm, Viện Hàn lâm Khoa học Trung Quốc, Trung Quốc
SONG WANG, Đại học York, Canada
Học máy (ML) đã được sử dụng ngày càng nhiều trong nhiều lĩnh vực khác nhau, trong khi việc giải quyết các tác vụ lập trình ML đặt ra những thách thức độc đáo vì bản chất và cấu trúc khác biệt cơ bản so với các tác vụ lập trình chung, đặc biệt đối với các nhà phát triển không có nền tảng ML. Sinh mã tự động tạo ra một đoạn mã từ mô tả ngôn ngữ tự nhiên có thể là một kỹ thuật đầy hứa hẹn để tăng tốc các tác vụ lập trình ML. Trong những năm gần đây, mặc dù nhiều mô hình sinh mã thần kinh dựa trên học sâu đã được đề xuất với độ chính xác cao, thực tế là hầu hết chúng chủ yếu được đánh giá trên các tác vụ lập trình chung đặt ra câu hỏi về tính hiệu quả và hữu ích của chúng trong các tác vụ lập trình ML. Trong bài báo này, chúng tôi tiến hành nghiên cứu tính hiệu quả của các mô hình sinh mã thần kinh hiện có trên các tác vụ lập trình ML. Để phân tích, chúng tôi chọn sáu mô hình sinh mã thần kinh tiên tiến và đánh giá hiệu suất của chúng trên bốn thư viện ML được sử dụng rộng rãi, với 83K cặp tác vụ lập trình ML được mô tả bằng ngôn ngữ tự nhiên mới tạo. Nghiên cứu thực nghiệm của chúng tôi tiết lộ một số khía cạnh tốt, xấu và thiếu sót của các mô hình sinh mã thần kinh trên các tác vụ ML, với một số khía cạnh chính được liệt kê dưới đây. (Tốt) Các mô hình sinh mã thần kinh hoạt động tốt hơn đáng kể trên các tác vụ ML so với các tác vụ không phải ML. (Xấu) Hầu hết mã được sinh ra không chính xác về mặt ngữ nghĩa. (Xấu) Các mô hình sinh mã không thể cải thiện đáng kể thời gian hoàn thành của nhà phát triển. (Tốt) Mã được sinh ra có thể giúp nhà phát triển viết mã chính xác hơn bằng cách cung cấp gợi ý sử dụng API đúng. (Thiếu sót) Quan sát từ nghiên cứu người dùng của chúng tôi tiết lộ các khía cạnh thiếu sót của sinh mã cho các tác vụ ML, ví dụ như phân tách sinh mã để chia để trị thành hai tác vụ: xác định chuỗi API và sinh cách sử dụng API.
Khái niệm CCS: •Phần mềm và kỹ thuật →Mô hình mã nguồn mở ;•Tổng quát và tham khảo →Nghiên cứu thực nghiệm .
Từ khóa và Cụm từ bổ sung: Sinh mã thần kinh, tác vụ học máy, phân tích thực nghiệm
Định dạng Tham khảo ACM:
Jiho Shin, Moshi Wei, Junjie Wang, Lin Shi, và Song Wang. 2022. Tốt, Xấu và Thiếu Sót: Sinh Mã Thần Kinh cho Các Tác Vụ Học Máy. 1, 1 (Tháng 5 2022), 20 trang. https://doi.org/XXXXXXX.XXXXXXX
Địa chỉ tác giả: Jiho Shin, jihoshin@yorku.ca, Đại học York, 4700 Keele St., North York, Ontario, Canada, M3J 1P3; Moshi Wei, Đại học York, 4700 Keele St., North York, Canada, moshiwei@yorku.ca; Junjie Wang, Viện Phần mềm, Viện Hàn lâm Khoa học Trung Quốc, Bắc Kinh, Trung Quốc, junjie@iscas.ac.cn; Lin Shi, Viện Phần mềm, Viện Hàn lâm Khoa học Trung Quốc, Bắc Kinh, Trung Quốc, shilin@iscas.ac.cn; Song Wang, Đại học York, 4700 Keele St., North York, Canada, wangsong@yorku.ca.
Được phép tạo bản sao kỹ thuật số hoặc bản cứng của toàn bộ hoặc một phần công trình này để sử dụng cá nhân hoặc trong lớp học mà không tính phí miễn là các bản sao không được tạo ra hoặc phân phối vì lợi nhuận hoặc lợi thế thương mại và các bản sao phải có thông báo này và trích dẫn đầy đủ trên trang đầu tiên. Bản quyền cho các thành phần của công trình này thuộc sở hữu của những người khác ngoài ACM phải được tôn trọng. Tóm tắt có ghi nguồn được phép. Để sao chép khác, hoặc tái xuất bản, để đăng trên máy chủ hoặc phân phối lại cho danh sách, yêu cầu quyền cụ thể trước và/hoặc phí. Yêu cầu quyền từ permissions@acm.org.
©2022 Hiệp hội Máy tính.
Bản thảo nộp cho ACM
Bản thảo nộp cho ACM 1arXiv:2305.09082v1  [cs.SE]  16 Tháng 5 2023

--- TRANG 2 ---
2 Shin và cộng sự.
1 GIỚI THIỆU
Gần đây, với những tiến bộ trong kỹ thuật học sâu [15,49], nhiều mô hình sinh mã thần kinh đã được đề xuất và nghiên cứu rộng rãi [16,20,38,47,56]. Hầu hết các mô hình này coi sinh mã như một tác vụ dịch máy và được xây dựng theo cách đầu cuối, tức là một kho dữ liệu các cặp mã nguồn và bình luận được sử dụng để huấn luyện mô hình, và với một tác vụ lập trình được mô tả bằng ngôn ngữ tự nhiên (NL), các mô hình sẽ sinh ra một đoạn mã nguồn.
Mặc dù nhiều mô hình sinh mã thần kinh đã đạt được độ chính xác cao trong việc sinh mã nguồn từ các tác vụ lập trình được mô tả bằng NL, hầu hết chúng chủ yếu được đánh giá trên các tác vụ lập trình chung, ít ai biết về tính hiệu quả và hữu ích của chúng đối với các tác vụ chuyên biệt theo lĩnh vực. Trong nghiên cứu này, chúng tôi điều tra Học Máy (ML), có các mô hình khác biệt đáng kể so với các tác vụ lập trình chung truyền thống (tương đối xác định hơn và ít định hướng thống kê hơn) [58]. Ngoài ra, các tác vụ lập trình ML thường yêu cầu nhiều thuật toán phức tạp, phép toán học và các thao tác xử lý dữ liệu [37, 50].
Để điều tra tính hiệu quả của các mô hình sinh mã thần kinh hiện có trên các tác vụ lập trình ML, chúng tôi sử dụng sáu mô hình sinh mã thần kinh tiên tiến làm đường cơ sở (chi tiết trong Mục 3.2) và chúng tôi chọn bốn thư viện ML được sử dụng rộng rãi, tức là Scikit-Learn¹, Keras², TensorFlow³ và PyTorch⁴ để thu thập tác vụ lập trình ML. Ngoài ra, lấy cảm hứng từ các nghiên cứu hiện có [50], chúng tôi phân loại các tác vụ lập trình ML theo các API được sử dụng thành ba danh mục khác nhau dựa trên mục đích của chúng trong quy trình ML, tức là xử lý dữ liệu, xây dựng mô hình và đánh giá (chi tiết trong Mục 2.2).
Để phân tích, chúng tôi cần một bộ dữ liệu mới về các tác vụ lập trình ML một cách toàn diện vì hầu hết các bộ dữ liệu chuẩn sinh mã hiện có được sử dụng rộng rãi, ví dụ StaQC [53], CoNaLa [54], Django [39] và ReCa [31] chủ yếu chứa các tác vụ lập trình mục đích chung. Cụ thể, chúng tôi tạo bộ dữ liệu mới liên quan đến tác vụ ML bằng cách tái sử dụng dữ liệu từ JuICe [1], tức là một bộ dữ liệu sinh mã được người biên tập tinh chỉnh bao gồm 1,5 triệu ví dụ được khai thác từ hơn 659K notebook Jupyter có sẵn công khai từ GitHub. Chúng tôi sử dụng thông tin API từ bốn thư viện ML được nghiên cứu để trích xuất các tác vụ lập trình liên quan đến ML. Lưu ý rằng, chúng tôi cũng đã thu thập một bộ dữ liệu liên quan đến tác vụ không phải ML từ JuICe [1] làm bộ dữ liệu so sánh. Sau đó chúng tôi đánh giá sáu mô hình sinh mã thần kinh tiên tiến đã chọn trên hai bộ dữ liệu (ML so với không phải ML) về độ chính xác, tính đúng đắn cú pháp và ngữ nghĩa, và tính hữu ích của mã được sinh ra. Nghiên cứu thực nghiệm của chúng tôi tiết lộ một số khía cạnh tốt, xấu và thiếu sót của các mô hình sinh mã thần kinh tiên tiến trên các tác vụ ML, với một số khía cạnh chính được liệt kê dưới đây. (Tốt) Các mô hình sinh mã thần kinh hoạt động tốt hơn đáng kể trên các tác vụ ML so với các tác vụ không phải ML. (Tốt) Mã được sinh ra có thể giúp nhà phát triển viết mã chính xác hơn bằng cách cung cấp gợi ý sử dụng API đúng. (Xấu) Hầu hết mã được sinh ra không chính xác về mặt ngữ nghĩa. (Xấu) Các mô hình sinh mã không thể cải thiện đáng kể thời gian hoàn thành của nhà phát triển. (Thiếu sót) Quan sát từ nghiên cứu người dùng của chúng tôi tiết lộ các khía cạnh thiếu sót của sinh mã cho các tác vụ ML, ví dụ như phân tách sinh mã để chia để trị thành hai tác vụ: xác định chuỗi API và sinh cách sử dụng API.
Bài báo này đóng góp như sau:
•Nghiên cứu thực nghiệm đầu tiên đánh giá sáu mô hình sinh mã thần kinh tiên tiến trên các tác vụ lập trình ML về độ chính xác, tính đúng đắn cú pháp và ngữ nghĩa, và tính hữu ích của mã được sinh ra.
•Các quan điểm thiếu sót giữa các mô hình sinh mã thần kinh tự động hiện có và các tác vụ lập trình ML thực tế, cũng như hướng nghiên cứu tương lai để cải thiện sinh mã.

¹https://scikit-learn.org/stable/
²https://keras.io/
³https://www.tensorflow.org/
⁴https://pytorch.org/
Bản thảo nộp cho ACM

--- TRANG 3 ---
Tốt, Xấu và Thiếu Sót: Sinh Mã Thần Kinh cho Các Tác Vụ Học Máy 3
•Một bộ dữ liệu mới bao gồm 83K cặp mô tả NL và mã nguồn tương ứng được triển khai bằng bốn thư viện ML, tạo điều kiện cho các nghiên cứu tiếp theo theo hướng này.
•Mã nguồn được phát hành của công cụ và bộ dữ liệu thí nghiệm của chúng tôi để giúp các nhà nghiên cứu khác sao chép và mở rộng nghiên cứu của chúng tôi⁵.
Phần còn lại của bài báo được tổ chức như sau. Mục 2 trình bày nền tảng của nghiên cứu này. Mục 3 mô tả phương pháp luận và thiết kế nghiên cứu của công trình. Mục 4 trình bày kết quả đánh giá. Mục 5 thảo luận các câu hỏi mở và các mối đe dọa đối với tính hợp lệ của công trình này. Mục 6 trình bày các nghiên cứu liên quan. Mục 7 kết luận bài báo này.
2 NỀN TẢNG
Mục này giới thiệu nền tảng của nghiên cứu này, tức là mô hình sinh mã nguồn thần kinh và các tác vụ lập trình ML.
2.1 Sinh Mã Thần Kinh
Các kỹ thuật sinh mã thần kinh khai thác các mô hình sinh thần kinh sâu để học phân phối hoặc ước lượng mật độ của mã nguồn với các biểu diễn khác nhau như chuỗi token hoặc cấu trúc cây như cây cú pháp trừu tượng (AST) [14,33]. Do sự tương đồng của biểu diễn dữ liệu, mô hình sinh mã nguồn kế thừa nhiều kỹ thuật từ các mô hình sinh NL. Trong sinh NL, nhiều tác vụ có thể được phân loại như xác định nội dung, cấu trúc văn bản, tổng hợp câu, từ vựng hóa, sinh biểu thức tham chiếu, thực hiện ngôn ngữ học, v.v. [18]. Cũng có các tác vụ khác nhau trong sinh mã nguồn như hoàn thành mã [30], tìm kiếm mã [19], tổng hợp chương trình qua quy tắc hoặc ví dụ [13], sinh mã chuyên biệt theo lĩnh vực [17] hoặc mục đích chung [8], dịch mã sang mã [3], đề xuất API [11], v.v. Mô hình sinh mà bài báo này tập trung vào là mô hình đa (lưỡng) phương thức của mã nguồn và NL, thường sử dụng kiến trúc mã hóa-giải mã đầu cuối của mô hình được sử dụng rộng rãi trong dịch máy thần kinh. Bộ mã hóa nhận chuỗi mô tả NL của một mã và ánh xạ chúng trong không gian tiềm ẩn và sau đó bộ giải mã giải mã chúng thành mã nguồn. Các lớp mã hóa-giải mã học cách ánh xạ các điểm dữ liệu tương tự của mỗi phương thức để được ánh xạ gần nhau trong không gian tiềm ẩn để nó sinh ra mã nguồn tương tự.
Để đánh giá các mô hình sinh mã, nhiều bộ dữ liệu chuẩn khác nhau đã được đề xuất. Bộ dữ liệu Django [39] đầu tiên được khai thác để sinh mã giả từ mã nguồn cho framework Django (Python-to-English). Dữ liệu chứa 18K cặp câu lệnh python và mã giả tiếng Anh tương ứng. CoNaLa [54] là một bộ dữ liệu được khai thác từ các bài đăng Stack Overflow bao gồm 3K cặp đoạn mã python được chú thích bởi con người và ý định NL của nó. StaQC [53] là một cặp mã nguồn và mô tả NL khác được khai thác từ Stack Overflow. Nó bao gồm 1,4K truy vấn Python và 1,2K SQL được khai thác bằng mạng thần kinh để kết hợp độ tương đồng văn bản. ReCa [31] là một bộ dữ liệu quy mô lớn của các yêu cầu NL và ngôn ngữ lập trình của nó. ReCa bao gồm dữ liệu cho nhiều ngôn ngữ chung, tức là C, C++, Java và Python. Nó cũng có nhiều chương trình cho cùng một yêu cầu. JuIce [1] là một bộ dữ liệu miền mở quy mô lớn mới bao gồm 1,5M cặp ví dụ mã Python và mô tả NL tương ứng được thu thập từ 659K notebook Jupyter có sẵn công khai trên GitHub. Bảng 1 hiển thị thống kê chi tiết hơn của các bộ dữ liệu hiện có này.

⁵https://zenodo.org/record/7036255
Bản thảo nộp cho ACM

--- TRANG 4 ---
4 Shin và cộng sự.
Bảng 1. Thống kê của các bộ dữ liệu chuẩn hiện có. PL biểu thị ngôn ngữ lập trình, Loc biểu thị số dòng mã trung bình, và Length biểu thị độ dài trung bình của các tác vụ NL theo token.
Bộ dữ liệu Lĩnh vực PL #Cặp Loc Length
Django chung Python 18.8K 1 14
CoNaLa chung Python 2.9K 1.1 14
StaQC chung Python/SQL 2.6k 10.1 10
ReCa chung C/Java/Python 101K 37.2 185
JuIce chung Python 1.5M 10.0 39.7
2.2 Các Tác Vụ Học Máy
Các tác vụ dựa trên học máy thường chứa các bước khác nhau, còn được gọi là quy trình của học máy [4]. Cụ thể, xây dựng một quy trình ML chứa ba bước sau. Bước đầu tiên chủ yếu về việc xử lý bộ dữ liệu cần thiết để huấn luyện mô hình. Nó bao gồm các tác vụ tiền xử lý như tải dữ liệu, lọc nhiễu, chuyển đổi định dạng, bổ sung dữ liệu, chia tỷ lệ hoặc chuẩn hóa, và kỹ thuật đặc trưng (ví dụ: chọn đặc trưng, loại bỏ, nhúng từ) [26]. Sau khi xử lý dữ liệu, người ta cần tiếp tục chỉ định thuật toán học để suy ra các mối quan hệ nắm bắt các mẫu ẩn trong bộ dữ liệu. Trong thuật toán được chỉ định, có thông tin về các tham số được học và phù hợp với dữ liệu đầu vào, hàm mất mát cần tối thiểu hóa, bộ tối ưu hóa và tốc độ học để dẫn dắt mô hình học tốt hơn, và kiến trúc mô hình chỉ định cấu trúc các lớp và nút của mạng [27]. Và cuối cùng, người ta cần đánh giá mô hình đã huấn luyện. Bước này bao gồm việc chọn các chỉ số đánh giá để đánh giá hiệu suất của các mô hình được huấn luyện, ví dụ độ chính xác, độ chính xác và độ thu hồi [22]. Các đánh giá được áp dụng cho một bộ dữ liệu chưa thấy riêng biệt khỏi dữ liệu huấn luyện để đánh giá khả năng tổng quát hóa của mô hình được huấn luyện. Trong công trình này, để hiểu tính hiệu quả của các mô hình sinh mã thần kinh hiện có trên các loại tác vụ lập trình ML khác nhau, chúng tôi phân loại các tác vụ lập trình ML thành các bước khác nhau trong quy trình ML [50].
•Xử lý dữ liệu: các tác vụ liên quan đến xử lý dữ liệu, ví dụ tải dữ liệu, chuyển đổi định dạng, chuẩn hóa, kỹ thuật đặc trưng, và biến đổi dữ liệu.
•Xây dựng mô hình: các tác vụ liên quan đến xây dựng các mô hình học máy/học sâu, có thể là các mô hình ML thông thường như mô hình phân loại, mô hình hồi quy, mô hình phân cụm, hoặc các mô hình mạng thần kinh với kiến trúc thần kinh cụ thể về loại lớp và hàm kích hoạt được sử dụng.
•Đánh giá: các tác vụ liên quan đến đánh giá hiệu suất của các mô hình học máy/học sâu đã huấn luyện, ví dụ nhận giá trị của các chỉ số đánh giá khác nhau như độ chính xác, f-measure, AUC, hoặc nhận xác suất của các thể hiện từ mô hình.
Lưu ý rằng trong khi chúng tôi tập trung vào ba loại tác vụ lập trình ML trong quy trình ML (tức là xử lý dữ liệu, xây dựng mô hình và đánh giá), có các tác vụ khác trong quy trình ML, ví dụ triển khai mô hình và giám sát hiệu suất [4]. Vì hoàn thành các tác vụ này chủ yếu yêu cầu các hàm hoặc script hỗ trợ thay vì các API từ thư viện ML, do đó chúng tôi loại trừ các tác vụ này trong nghiên cứu này.
3 THIẾT KẾ NGHIÊN CỨU
Trong mục này, chúng tôi thảo luận về thiết kế nghiên cứu thực nghiệm của chúng tôi về đánh giá hiệu suất của các mô hình sinh mã trên các tác vụ lập trình ML.
Bản thảo nộp cho ACM

--- TRANG 5 ---
Tốt, Xấu và Thiếu Sót: Sinh Mã Thần Kinh cho Các Tác Vụ Học Máy 5
Bảng 2. Các thư viện ML được nghiên cứu trong công trình này.
Thư viện Mô tả #API
Scikit-learn Thư viện cho các thuật toán ML. 1.2k
Keras Giao diện cho mạng thần kinh nhân tạo. 1.4k
TensorFlow Thư viện cho DL được phát triển bởi Google. 8.0k
PyTorch Thư viện cho các tác vụ ML và DL. 0.4k
Bảng 3. Thống kê của các bộ dữ liệu thí nghiệm. #API là số lượng API trung bình được liên quan.
Tác vụ ML #Huấn luyện #Kiểm tra Loc Length #API
dữ liệu 30.9K 5.5K 3.93 12.67 1.48
mô hình 26.3K 5.5K 4.18 12.44 1.28
đánh giá 13K 2.6K 3.28 11.59 1.13
không phải ml 34K 5.5K 3.23 13.26 1.63
Hình 1. Phân phối dữ liệu thí nghiệm trong mỗi thư viện ML.
3.1 Thu Thập Dữ Liệu
Trong công trình này, chúng tôi chuẩn bị một bộ dữ liệu mới chứa ba loại tác vụ lập trình ML (tức là xử lý dữ liệu, xây dựng mô hình và đánh giá) vì hầu hết các bộ dữ liệu chuẩn sinh mã hiện có được sử dụng rộng rãi, ví dụ StaQC [53], CoNaLa [54], Django [39] và ReCa [31] chủ yếu chứa các tác vụ lập trình mục đích chung. Cụ thể, chúng tôi tạo bộ dữ liệu của mình từ JuICe [1], tức là một bộ dữ liệu sinh mã được người biên tập tinh chỉnh bao gồm 1,5 triệu ví dụ mã Python được khai thác từ hơn 659K notebook Jupyter có sẵn công khai từ GitHub.
Bản thảo nộp cho ACM

--- TRANG 6 ---
6 Shin và cộng sự.
Lựa chọn API ML: Bộ dữ liệu JuICe gốc [1] chứa các tác vụ lập trình miền mở. Đối với nghiên cứu của chúng tôi, chúng tôi tập trung vào các tác vụ lập trình ML được phát triển bởi bốn thư viện ML được sử dụng rộng rãi, tức là Scikit-learn, Keras, TensorFlow và PyTorch. Danh sách các thư viện được nghiên cứu được tổ chức trong Bảng 2. Cụ thể, ba tác giả độc lập sử dụng hai bước sau để xác định thủ công tất cả các API trong mỗi thư viện ML này liên quan đến ba loại tác vụ lập trình ML (tức là xử lý dữ liệu, xây dựng mô hình và đánh giá) dựa trên tài liệu của các API này:
1). Chúng tôi đọc tài liệu của API để hiểu chức năng của nó. Một danh mục sẽ được gán cho API dựa trên ý định chính của nó. 2). Nếu không thể đưa ra quyết định dựa trên tài liệu của API vì mô tả có thể không chứa đủ thông tin, chúng tôi tiếp tục kiểm tra mã nguồn theo hướng dẫn trong Bước 1 để gán nhãn cho API.
Giá trị của kappa Fleiss trong quá trình này là 0,90, cho thấy sự đồng thuận gần như hoàn hảo. Tổng cộng, 128, 244 và 51 API được xác định cho ba loại tác vụ lập trình ML, tức là xử lý dữ liệu, xây dựng mô hình và đánh giá tương ứng.
Xây dựng dữ liệu tác vụ ML: Sau khi chúng tôi xác định các API trong thư viện ML cho mỗi ba tác vụ lập trình ML, chúng tôi tiếp tục sử dụng các API tương ứng làm bộ lọc để thu thập các tác vụ lập trình ML từ bộ dữ liệu JuICe [1], ví dụ chúng tôi quét mã nguồn của mỗi tác vụ lập trình trong JuIce, một tác vụ lập trình sẽ được gán nhãn là tác vụ xử lý dữ liệu nếu nó chỉ chứa các API liên quan đến xử lý dữ liệu từ mỗi thư viện ML này. Chúng tôi loại bỏ bất kỳ thể hiện nào sử dụng nhiều thư viện ML để phân biệt các tác vụ lập trình sử dụng các thư viện khác nhau.
Làm sạch dữ liệu: Chúng tôi cũng loại bỏ các thể hiện dữ liệu trùng lặp, các phần tử mã nguồn vô nghĩa, tức là ' >>> ', bình luận đơn và đa dòng, các dòng bắt đầu bằng '!' và '%' cho lệnh, đoạn mã chỉ có import và mã không phải ASCII. Chúng tôi cũng áp dụng lọc bổ sung để khử nhiễu thêm cho bộ dữ liệu và làm cho vấn đề đơn giản hơn bằng cách loại bỏ các thể hiện có độ dài mô tả NL dưới 20 và trên 150, và mã nguồn có hơn 10 LOC như được đề xuất bởi công trình hiện có [25]. Để đánh giá chất lượng của dữ liệu thu thập, ba tác giả đầu tiên thực hiện phân tích thủ công trên 100 mẫu ngẫu nhiên từ mỗi phần, tức là xử lý dữ liệu, đánh giá và xây dựng mô hình. Các tác giả đầu tiên kiểm tra xem mã nguồn của thể hiện có liên quan đến tác vụ lập trình ML hay không. Sau đó chúng tôi kiểm tra xem mô tả NL có liên quan đến mã nguồn hay không. Chúng tôi thấy rằng 64%-81% các mẫu có cả mã nguồn và NL liên quan đến tác vụ lập trình ML và mô tả của nó. Chúng tôi cũng cẩn thận chia các thể hiện ở cấp độ dự án, tức là các thể hiện từ cùng một dự án đi vào cùng một phần, để tránh bất kỳ rò rỉ thông tin nào.
Bộ dữ liệu mới của các tác vụ lập trình ML được tổ chức trong Bảng 3. Chúng tôi cũng hiển thị phân phối của các tác vụ lập trình ML khác nhau trong mỗi thư viện ML trong Hình 1.
3.2 Các Mô Hình Sinh Mã Thần Kinh Được Nghiên Cứu
Trong công trình này, chúng tôi chọn sáu mô hình sinh mã thần kinh tiên tiến được đề xuất trong ba năm gần đây làm đối tượng thí nghiệm. Các mô hình này được chọn chủ yếu dựa trên các tiêu chí bao gồm sau:
•Mô hình không nên gắn bó với một ngôn ngữ lập trình cụ thể, làm cho nó thực tế và có thể tổng quát hóa để hoạt động trên bộ dữ liệu của chúng tôi.
•Việc triển khai mô hình nên có sẵn công khai và có thể sao chép, có thể loại bỏ thiên vị triển khai tiềm ẩn và tạo điều kiện cho quá trình đánh giá.
•Mô hình nên được đề xuất trong những năm gần đây và đại diện cho mức tiên tiến, tức là có hiệu suất cao trong sinh BLEU score.
Kết quả là, sáu mô hình sinh mã thần kinh được chọn từ 29 bài báo ứng viên được xuất bản trên ACL, ICLR, AAAI, TSE, EMNLP, v.v. Chi tiết của các mô hình này như sau:
Bản thảo nộp cho ACM

--- TRANG 7 ---
Tốt, Xấu và Thiếu Sót: Sinh Mã Thần Kinh cho Các Tác Vụ Học Máy 7
tranX [56]: đề xuất một trình phân tích ngữ nghĩa thần kinh dựa trên chuyển đổi ánh xạ các phát ngôn NL thành các biểu diễn ý nghĩa hình thức như các chương trình có thể thực thi. Cụ thể, nó phát triển một hệ thống chuyển đổi phân tách quy trình sinh AST thành một chuỗi các hành động xây dựng cây.
External-Knowledge-Codegen (EK Codegen) [52]: đề xuất một phương pháp bất khả tri mô hình dựa trên tăng cường dữ liệu, truy xuất và tái lấy mẫu dữ liệu, để kết hợp kiến thức bên ngoài vào các mô hình sinh mã. Cụ thể, các cặp NL-mã được khai thác từ diễn đàn QA lập trình trực tuyến Stack Overflow và tài liệu API để huấn luyện trước.
Kiến trúc cơ bản của mô hình này sử dụng tranX làm nền.
CG-RL [24]: đề xuất một mô hình Seq2Tree mở rộng được trang bị một bộ chọn nhánh dựa trên ngữ cảnh, có khả năng xác định động thứ tự mở rộng nhánh tối ưu cho các nút đa nhánh. Cụ thể, nó áp dụng học tăng cường để huấn luyện toàn bộ mô hình với phần thưởng tinh tế đo lường sự khác biệt mất mát giữa các thứ tự mở rộng nhánh khác nhau.
Codegen-TAE [38]: khai thác việc sử dụng một lượng lớn kho dữ liệu ngôn ngữ lập trình đơn ngữ để phù hợp với một mô hình Seq2Seq dựa trên transformer chung với thiên vị quy nạp cụ thể sinh mã tối thiểu.
TreeCodeGen [14]: đề xuất một mô hình cây-sang-cây nhận thức cấu trúc dựa trên Transformer. Họ áp dụng Tree Transformer, một mô hình cây-sang-cây dựa trên attention với tích lũy phân cấp cho sinh mã.
PyCodeGPT [57]: đề xuất một mô hình ngôn ngữ được huấn luyện trước lớn dựa trên GPT-Neo [6] với 110M tham số, có thể so sánh với mô hình GPT-3 mạnh mẽ [7]. Họ khai thác 1,2M kho Python trong GitHub và lọc/tiền xử lý mã Python chất lượng cao tạo ra 96GB dữ liệu huấn luyện.
Trong thí nghiệm của chúng tôi, để loại bỏ thiên vị tiềm ẩn, chúng tôi sử dụng việc triển khai mã có sẵn công khai của họ với các cài đặt có hiệu suất tốt nhất được báo cáo trong các bài báo của họ hoặc được sử dụng trong các gói sao chép của họ.
3.3 Câu Hỏi Nghiên Cứu
Chúng tôi trả lời các câu hỏi nghiên cứu sau để đánh giá hiệu suất của các mô hình sinh mã thần kinh được nghiên cứu trên các tác vụ lập trình ML.
•RQ1 (Độ chính xác): Các mô hình sinh mã chính xác như thế nào trên các tác vụ lập trình ML khác nhau?
•RQ2 (Tính đúng đắn Cú pháp): Mã được sinh ra cho các tác vụ lập trình ML vượt qua kiểm tra cú pháp thường xuyên như thế nào?
•RQ3 (Tính đúng đắn Ngữ nghĩa): Mã được sinh ra cho các tác vụ lập trình ML vượt qua kiểm tra ngữ nghĩa thường xuyên như thế nào?
•RQ4 (Tính hữu ích): Mã được sinh ra cho các tác vụ lập trình ML có hữu ích cho nhà phát triển không?
Trong RQ1, chúng tôi tiến hành điều tra hiệu suất của các mô hình sinh mã thần kinh tiên tiến trên ba loại tác vụ lập trình ML khác nhau. Trong RQ2 và RQ3, chúng tôi đánh giá tính đúng đắn của mã được sinh ra bằng cách kiểm tra tính đúng đắn cú pháp và ngữ nghĩa của nó, tương ứng. Trong RQ4, chúng tôi khám phá tính hữu ích của mã được sinh ra đối với nhà phát triển trong thực tế qua nghiên cứu trường hợp người dùng.
3.4 Thiết Lập Thí Nghiệm
Sáu mô hình sinh mã thần kinh được chọn được yêu cầu áp dụng các bước tiền xử lý dữ liệu cụ thể, tức là xây dựng AST từ mã nguồn được sử dụng trong tranX [56]. Do đó để xây dựng lại các mô hình này, chúng tôi đầu tiên áp dụng các script tiền xử lý dữ liệu được cung cấp trong các gói sao chép của họ. Để huấn luyện mỗi mô hình, chúng tôi chọn 80% dữ liệu huấn luyện của chúng tôi để huấn luyện mô hình và 20% còn lại được sử dụng làm dữ liệu xác thực.
Bản thảo nộp cho ACM

--- TRANG 8 ---
8 Shin và cộng sự.
Để tối đa hóa tiềm năng của các phương pháp được đánh giá, chúng tôi thực hiện điều chỉnh siêu tham số cho mỗi phương pháp được đánh giá. Đối với tranX, chúng tôi sử dụng 0,3 cho dropout, kích thước ẩn 256 và kích thước nhúng 128, tốc độ học 0,001, kích thước batch 64. Chúng tôi huấn luyện mô hình tối đa 20 epoch và sử dụng kích thước beam 15 khi kiểm tra.
Đối với EK-codegen, chúng tôi sử dụng cùng giá trị siêu tham số được sử dụng trong tranX. Đối với CG-RL, chúng tôi sử dụng cùng dropout, kích thước mạng và tốc độ học cho huấn luyện. Tuy nhiên, chúng tôi sử dụng 10 epoch để huấn luyện trước bộ chọn nhánh theo bài báo gốc của CG-RL [24]. Đối với Code-gen-TAE, chúng tôi sử dụng 1e-05 cho tốc độ học encoder và 7,5e-05 cho tốc độ học decoder, kích thước ẩn của encoder là 768 với 12 lớp, kích thước decoder là 256 với 4 lớp, và kích thước batch sử dụng là 16. Chúng tôi cũng huấn luyện chúng trong 20 epoch như phần còn lại của mô hình và sử dụng số beam 10 khi kiểm tra. Đối với TreeCodeGen, 0,1 được sử dụng cho dropout, và kích thước ẩn và nhúng sử dụng giống như tranX. Tốc độ học sử dụng là 1e-4. Epoch tối đa sử dụng cho huấn luyện là 20 và kích thước beam sử dụng cho kiểm tra là 30. Đối với PyCodeGPT, mô hình được huấn luyện với 32K từ vựng, 768 cho kích thước ẩn, 12 cho số đầu và lớp, kích thước cửa sổ 256, và phạm vi khởi tạo 0,02, cùng cài đặt được báo cáo từ GPT-Neo và PyCodeGPT. Mô hình được huấn luyện trong 100K bước như được đề xuất trong bài báo gốc.
Tất cả các cài đặt nói trên được sử dụng cho huấn luyện đều từ các bài báo của sáu mô hình và bất kỳ chi tiết nào thiếu từ bài báo đều được đặt làm cài đặt mặc định được cung cấp bởi các gói sao chép của họ. Chúng tôi sử dụng GPU trong Google Colab Pro⁶, dành riêng NVIDIA Tesla P100 hoặc T4, để huấn luyện mô hình. Để huấn luyện PyCodeGPT, chúng tôi sử dụng NVIDIA A100 40GB từ nền tảng điện toán google⁷. Chi phí thời gian huấn luyện mô hình của các mô hình này dao động từ 3 giờ (tức là tranX) đến 16 giờ (tức là PyCodeGPT).
3.5 Chỉ Số Đánh Giá
Để đánh giá hiệu suất của các mô hình trong việc sinh mã nguồn chất lượng cao, chúng tôi sử dụng ba thước đo đánh giá sau, tức là BLEU [40], METEOR [5] và ROUGE [28].
Điểm BLEU [40] là một chỉ số đánh giá thường được sử dụng trong đánh giá các mô hình sinh trong xử lý ngôn ngữ tự nhiên. Nó đo sự tương đồng của văn bản được sinh bởi mô hình với văn bản thực tế bằng cách tính toán các n-gram chồng chéo của hai văn bản. Giá trị 0 cho biết mã nguồn được sinh ra không có sự chồng chéo n-gram với mã nguồn thực tế, trong khi giá trị 1 cho biết nó là sự chồng chéo hoàn hảo với mã nguồn thực tế. Có nhiều cách khác nhau để tính điểm BLEU. Chúng tôi có thể đặt số lượng n-gram khác nhau mà chúng tôi muốn đánh giá trong chồng chéo, tức là unigram, bigram, trigram và 4-gram. Điều này cũng được gọi là BLEU-1, BLEU-2, BLEU-3 và BLEU-4 tương ứng. Chỉ số METEOR [5] cũng thường được sử dụng để đánh giá các mô hình sinh ngôn ngữ máy. Chỉ số dựa trên trung bình điều hòa của độ chính xác và độ thu hồi unigram nhưng với trọng số cao hơn về độ thu hồi. ROUGE [28] là một chỉ số được sử dụng để đánh giá các mô hình sinh ngôn ngữ tự nhiên để so sánh chuỗi được sinh ra với tham chiếu. Cũng có nhiều bộ đánh giá các giá trị ROUGE khác nhau. Trong nghiên cứu này, chúng tôi báo cáo giá trị ROUGE-L của mỗi mô hình sử dụng Chuỗi Con Chung Dài Nhất (LCS) trong đánh giá sự tương đồng của hai văn bản.
4 KẾT QUẢ VÀ PHÂN TÍCH
Mục này trình bày kết quả thí nghiệm và trả lời các câu hỏi nghiên cứu được thảo luận trong Mục 3.3.

⁶https://colab.research.google.com/
⁷https://cloud.google.com/
Bản thảo nộp cho ACM

--- TRANG 9 ---
Tốt, Xấu và Thiếu Sót: Sinh Mã Thần Kinh cho Các Tác Vụ Học Máy 9
Bảng 4. Hiệu suất của sáu mô hình sinh mã thần kinh được nghiên cứu trên các tác vụ ML khác nhau và tác vụ không phải ML. Hiệu suất tốt nhất của một mô hình trên các tác vụ khác nhau được hiển thị in đậm, trong khi mô hình tổng thể tốt nhất trên mỗi tác vụ ML được hiển thị với dấu hoa thị (*).
Mô hình Tác vụ BLEU-1 BLEU-2 BLEU-3 BLEU-4 ROUGE-L METEOR
tranXxử lý dữ liệu
xây dựng mô hình
đánh giá0.3606
0.3646
0.36210.2670*
0.2717
0.26770.2237*
0.2277
0.22330.1905
0.1940
0.18860.3380
0.3167
0.35320.3600*
0.3598
0.3712
không phải ml 0.2855 0.1714 0.1236 0.0929 0.1636 0.2282
EK Codegenxử lý dữ liệu
xây dựng mô hình
đánh giá0.3391
0.3549
0.35930.2541
0.2690
0.2698*0.2154
0.2289
0.22820.1853
0.1978
0.19530.3441
0.3241
0.36160.3592
0.3633
0.3759*
không phải ml 0.2969* 0.1838* 0.1348* 0.1028* 0.1705 0.2365*
CG-RLxử lý dữ liệu
xây dựng mô hình
đánh giá0.2503
0.1923
0.24040.1943
0.1471
0.18400.1678
0.1257
0.15750.1471
0.1089
0.13660.3397
0.3160
0.36200.3333
0.3057
0.3480
không phải ml 0.1213 0.0776 0.0578 0.0450 0.1723 0.1916
TreeCodeGenxử lý dữ liệu
xây dựng mô hình
đánh giá0.3465
0.3483
0.3644*0.2540
0.2559
0.26810.2125
0.2134
0.22350.1810
0.1812
0.18830.3530*
0.3122
0.35300.3476
0.3377
0.3619
không phải ml 0.1997 0.1255 0.0932 0.0723 0.1929* 0.1979
Codegen-TAExử lý dữ liệu
xây dựng mô hình
đánh giá0.3775*
0.3279
0.29190.2444
0.1993
0.17430.1857
0.1438
0.12600.1441
0.1052
0.09140.3145
0.2339
0.23570.3233
0.2623
0.2358
không phải ml 0.2620 0.1451 0.0985 0.0703 0.1217 0.1944
PyCodeGPTxử lý dữ liệu
xây dựng mô hình
đánh giá0.3347
0.4036*
0.33970.2562
0.3286*
0.26930.2219
0.2925*
0.2361*0.1958*
0.2634*
0.2094*0.3333
0.3701*
0.3667*0.3462
0.3893*
0.3654
không phải ml 0.0789 0.0352 0.0217 0.0141 0.0619 0.0938
4.1 RQ1: Độ Chính Xác
Phương pháp: Để trả lời RQ này, chúng tôi tuân theo thiết lập thí nghiệm (được mô tả trong Mục 3.4) để huấn luyện lại mỗi mô hình sinh mã thần kinh với dữ liệu từ các tác vụ lập trình ML khác nhau, tức là các bộ dữ liệu xử lý dữ liệu, xây dựng mô hình và đánh giá. Chúng tôi cũng đánh giá hiệu suất của sáu mô hình sinh mã thần kinh trên bộ dữ liệu tác vụ lập trình không phải ML để so sánh. Để tạo bộ dữ liệu tác vụ lập trình không phải ML, chúng tôi chọn ngẫu nhiên các mẫu từ JuIce [1] với các tác vụ lập trình ML đã loại bỏ. Để có sự so sánh công bằng, chúng tôi đặt kích thước của bộ dữ liệu tác vụ không phải ML bằng bộ dữ liệu tác vụ ML lớn nhất của chúng tôi, tức là bộ dữ liệu xử lý dữ liệu. Để loại bỏ thiên vị tiềm ẩn, chúng tôi lặp lại việc tạo dữ liệu cho các tác vụ không phải ML 10 lần và huấn luyện lại các mô hình tương ứng. Chúng tôi sử dụng hiệu suất trung bình của mỗi mô hình sinh mã thần kinh được nghiên cứu để so sánh. Để đánh giá khả năng của mô hình trong việc sinh mã nguồn trên các thư viện ML khác nhau, chúng tôi gán nhãn cho mỗi thể hiện kiểm tra với thư viện ML được nghiên cứu bằng tên API ML.
Kết quả: Hiệu suất của sáu mô hình sinh mã thần kinh được nghiên cứu trên các loại tác vụ ML khác nhau và tác vụ không phải ML được tổ chức trong Bảng 4. Nhìn chung, PyCodeGPT hoạt động tốt nhất, đặc biệt trên các tác vụ liên quan đến ML. Ví dụ, PyCodeGPT đạt giá trị lớn nhất về tất cả các chỉ số trên xây dựng mô hình. Tuy nhiên, trên các tác vụ không phải ML, EK Codegen hoạt động tốt nhất với 5/6 chỉ số. Một lý do có thể cho hai mô hình này có hiệu suất tốt hơn là chúng khai thác dữ liệu bên ngoài để huấn luyện trước. Cụ thể, PyCodeGPT sử dụng kho dữ liệu được khai thác từ GitHub, và EK
Bản thảo nộp cho ACM

--- TRANG 10 ---
10 Shin và cộng sự.
Codegen sử dụng kho dữ liệu được khai thác từ Thư viện Chuẩn Python⁸ và StackOverflow⁹. Do số lượng dự án ML dồi dào trên GitHub, PyCodeGPT được hưởng lợi trong việc sinh mã liên quan đến ML. Tương tự, các tác vụ không phải ML bao gồm các đoạn mã ngắn độc lập, rất tương tự với các đoạn mã được trả lời trong StackOverflow. Đây có thể là lý do tại sao EK Codegen được hưởng lợi trong việc sinh các tác vụ lập trình không phải ML. Về hiệu suất trên một loại tác vụ ML cụ thể, chúng ta có thể thấy rằng các tác vụ hiệu suất tốt nhất cho mỗi mô hình sinh mã thần kinh thay đổi. Ví dụ, tranX hoạt động tốt nhất trên các tác vụ xây dựng mô hình so với các tác vụ khác, trong khi CG-RL và Codegen-TAE có hiệu suất tốt hơn cho các tác vụ xử lý dữ liệu so với hiệu suất trên các tác vụ khác về điểm BLEU. EK Codegen và TreeCodeGen hoạt động tốt hơn trên đánh giá, trong khi PyCodeGPT hoạt động tốt hơn trên các tác vụ ML liên quan đến xây dựng mô hình so với các tác vụ khác.
Ngoài ra, chúng ta cũng có thể thấy rằng tất cả sáu mô hình sinh mã thần kinh hoạt động tốt hơn đáng kể trên các tác vụ ML so với các tác vụ không phải ML về tất cả các chỉ số khác nhau, tức là BLEU-1/2/3/4, ROUGE-L và METEOR. Các lý do có thể cho điều này có thể như sau. Đầu tiên, các tác vụ không phải ML đa dạng hơn nhiều so với các tác vụ ML vì chúng tôi giới hạn các tác vụ ML chỉ trong bốn thư viện, tức là TensorFlow, Keras, Pytorch và Scikit-learn. Sự biến thiên của các chương trình từ các tác vụ ML ít hơn bộ dữ liệu không phải ML. Thứ hai, các mô tả ngôn ngữ tự nhiên của các tác vụ liên quan đến không phải ML cũng đa dạng hơn và không có ngữ cảnh vì lĩnh vực không có ràng buộc so với các mô tả của các tác vụ ML. Phát hiện này thú vị, vì các nghiên cứu trước đây khẳng định rằng các chương trình truyền thống xác định hơn và ít định hướng thống kê hơn [58]. Tuy nhiên, từ góc độ sinh, nó ngược lại. Mặc dù các thư viện ML động hơn và định hướng thống kê, các chương trình được xây dựng dựa trên chúng thường không như vậy.
Tốt: Các mô hình sinh mã thần kinh sinh ra hiệu suất tốt hơn đáng kể trên các tác vụ ML so với các tác vụ không phải ML.
Xấu: Các mô hình sinh mã thần kinh hoạt động không ổn định trên các tác vụ lập trình ML khác nhau.
4.2 RQ2: Kiểm Tra Cú Pháp
Phương pháp: Để trả lời RQ này, chúng tôi tiến hành kiểm tra cú pháp trên các chương trình được sinh ra cho mỗi thể hiện trong bộ dữ liệu kiểm tra. Theo công trình hiện có [31], chúng tôi tiến hành kiểm tra cú pháp tĩnh trên các chương trình được sinh ra với công cụ Pylint¹⁰ tiên tiến trong thực tế, một công cụ phân tích mã tĩnh Python tìm kiếm lỗi lập trình. Lưu ý rằng, codegen-TAE sinh tất cả các câu lệnh mã trong một dòng cho một tác vụ lập trình đã cho, trong khi các chương trình Python có yêu cầu kiểu nghiêm ngặt, ví dụ Python sử dụng thụt lề để chỉ ra một khối mã. Để tránh bất kỳ lỗi kiểu nào, chúng tôi đầu tiên phân tích mã nguồn được sinh ra và xuất ra với thụt lề thích hợp. Trong bước này, chúng tôi không thay đổi bất kỳ nội dung nào để tránh thiên vị tiềm ẩn. Sau đó chúng tôi sử dụng Pylint để kiểm tra tính đúng đắn cú pháp của mỗi thể hiện trong bộ dữ liệu kiểm tra, chúng tôi coi một thể hiện đúng về cú pháp nếu nó vượt qua kiểm tra.
Kết quả: Bảng 5 hiển thị kết quả kiểm tra cú pháp cho các chương trình được sinh ra bởi các mô hình sinh mã thần kinh khác nhau trong các tác vụ ML khác nhau và tác vụ không phải ML. Chúng ta có thể quan sát rằng nói chung, tất cả các mô hình tiên tiến có độ chính xác cao trong việc sinh các chương trình đúng về cú pháp. Tuy nhiên, chúng tôi quan sát thấy sự suy giảm đáng kể trong việc sinh mã đúng về cú pháp sử dụng PyCodeGPT so với các mô hình khác. Một trong những lý do có thể cho điều này là năm mô hình này là các phương pháp dựa trên AST, với một tác vụ lập trình, chúng đầu tiên sinh AST tương ứng và sau đó chuyển chúng thành một đoạn mã. Mặt khác, PyCodeGPT sử dụng Transformer seq2seq dựa trên token, cho mô hình tự do sinh bất kỳ chuỗi token nào, có thể dễ dàng sai về cú pháp. Ngoài ra, chúng tôi

⁸https://docs.python.org/3/library/index.html
⁹https://stackoverflow.com/
¹⁰https://pylint.pycqa.org/
Bản thảo nộp cho ACM

--- TRANG 11 ---
Tốt, Xấu và Thiếu Sót: Sinh Mã Thần Kinh cho Các Tác Vụ Học Máy 11
Bảng 5. Tính đúng đắn cú pháp (theo phần trăm) của mã được sinh ra bởi các mô hình sinh mã thần kinh khác nhau trên các loại tác vụ học máy khác nhau.
Phương pháp dữ liệu mô hình đánh giá không phải ml
tranX 98.40 98.68 99.36 97.06
EK codegen 96.39 97.92 97.68 95.16
CG-RL 97.37 98.07 97.97 94.70
TreeCodeGen 92.24 95.46 97.00 82.85
Codege-TAE 92.35 93.99 90.70 93.22
PyCodeGPT 71.36 70.53 72.88 67.16
Bảng 6. Tính đúng đắn ngữ nghĩa (theo phần trăm) của mã được sinh ra bởi các mô hình sinh mã thần kinh khác nhau trên các loại tác vụ học máy khác nhau.
Phương pháp dữ liệu mô hình đánh giá không phải ml
tranX 6% 14% 34% 0%
EK codegn 16% 12% 30% 10%
PyCodeGPT 34% 14% 30% 6%
Bảng 7. Tính đúng đắn của các API được xác định trên mã được sinh ra bởi các mô hình sinh mã thần kinh khác nhau trên các loại tác vụ học máy khác nhau.
Phương pháp Chỉ số dữ liệu mô hình đánh giá không phải ml
tranXPrecision 0.2129 0.2740 0.4348 0.1214
Recall 0.2215 0.2729 0.5105 0.1364
EK codegenPrecision 0.3458 0.2104 0.4234 0.2278
Recall 0.3400 0.2693 0.4452 0.2078
PyCodeGPTPrecision 0.6133 0.4085 0.5500 0.0867
Recall 0.5811 0.3943 0.4649 0.0783
cũng có thể thấy rằng tất cả sáu mô hình sinh mã thần kinh hoạt động tốt hơn trên hầu hết các tác vụ ML so với các tác vụ không phải ML, phù hợp với các phát hiện của chúng tôi trong RQ1.
Tốt: Các mô hình sinh mã thần kinh sinh ra các chương trình đúng về cú pháp với độ chính xác cao cho các tác vụ ML.
Tốt: Kết quả của chúng tôi xác nhận lợi thế của sinh mã dựa trên AST được sử dụng trong các mô hình sinh mã thần kinh hiện tại so với mô hình dựa trên token.
4.3 RQ3: Kiểm Tra Ngữ Nghĩa
Phương pháp: Để phân tích thêm tính đúng đắn của các chương trình được sinh ra bởi các mô hình sinh mã thần kinh tiên tiến này, chúng tôi cũng kiểm tra ngữ nghĩa của các chương trình được sinh ra bằng tay vì hầu hết các chương trình được sinh ra yêu cầu đầu vào cụ thể để thực thi, không thể được sinh ra tự động. Đối với thí nghiệm này, chúng tôi kiểm tra tính đúng đắn ngữ nghĩa của các chương trình được sinh ra từ ba mô hình tốt nhất, tức là tranX, EK codegen và PyCodeGPT trên thư viện TensorFlow. Cụ thể, chúng tôi đầu tiên chọn ngẫu nhiên 50 ví dụ từ mỗi loại tác vụ lập trình ML, do đó tổng cộng, chúng tôi có 450 tác vụ lập trình cần được kiểm tra, tức là 50 mẫu × 3 loại tác vụ lập trình ML × 3 mô hình. Chúng tôi coi một chương trình được sinh ra của một tác vụ lập trình đã cho tương đương về ngữ nghĩa với chương trình thực tế nếu
Bản thảo nộp cho ACM

--- TRANG 12 ---
12 Shin và cộng sự.
chương trình được sinh ra chia sẻ cùng logic với chương trình thực tế và có thể giải quyết tác vụ lập trình đã cho. Để kiểm tra tính đúng đắn ngữ nghĩa của mỗi mẫu, tất cả các tác giả làm việc cùng nhau và đưa ra quyết định cùng nhau.
Để minh họa thêm tính hiệu quả của các chương trình được sinh ra cho các tác vụ lập trình ML, chúng tôi cũng đánh giá tính đúng đắn của một chương trình được sinh ra về các API được gọi trong chương trình. Cụ thể, với một tác vụ lập trình ML, chúng tôi đầu tiên phân tích mã nguồn thực tế tương ứng và trích xuất các API từ bốn thư viện ML này được sử dụng để giải quyết tác vụ. Sau đó chúng tôi tuân theo cùng quy trình để trích xuất API trong chương trình được sinh ra cho tác vụ này bởi một mô hình sinh mã thần kinh. Lưu ý rằng, đối với các tác vụ không phải ML, chúng tôi cũng tuân theo cùng quy trình để thu thập API được sử dụng trong các chương trình thực tế và được sinh ra. Để đo hiệu suất của các mô hình mã thần kinh về việc xác định các API đúng, chúng tôi sử dụng Precision và Recall, trong đó Precision đo phần trăm API được xác định đúng trong tất cả các API được sử dụng trong các chương trình được sinh ra và Recall là phần trăm API được xác định đúng trong các API thực tế.
Danh sách 1. Một ví dụ về mã được sinh ra bởi EK codegen cho một tác vụ lập trình ML đã cho
# mô tả NL
# sử dụng feed_dict, cùng đồ thị, nhưng không
# mã hóa cứng đầu vào khi xây dựng session
# thực tế
a = tf.placeholder(dtype=tf.int32, shape=(None,))
b = tf.placeholder(dtype=tf.int32, shape=(None,))
c = tf.add(a, b)
with tf.Session() as sess:
result = sess.run(c, feed_dict={
a: [3, 4, 5], b: [-1, 2, 3]})
print(result)
# được sinh ra
x = tf.placeholder(tf.float32)
with tf.Session() as sess:
print(sess.run(x))
Kết quả: Bảng 6 hiển thị tính đúng đắn ngữ nghĩa của các chương trình được sinh ra của ba mô hình sinh mã thần kinh. Chúng ta có thể quan sát rằng chỉ một số lượng nhỏ mẫu của mã nguồn được sinh ra đúng về ngữ nghĩa với trung bình 17% trong 450 mẫu. PyCodeGPT vượt trội hơn EK Codegen theo sau bởi tranX với 13%, 17% và 21% phần trăm trung bình, tương ứng, phù hợp với kết quả từ RQ1. Tương tự như các xu hướng được tiết lộ trong RQ1 và RQ2, các mô hình được kiểm tra cũng có hiệu suất tốt hơn trên các tác vụ lập trình ML so với các tác vụ lập trình không phải ML.
Mặc dù các giá trị thấp trong tính đúng đắn ngữ nghĩa, chúng tôi quan sát rằng các mô hình sinh mã thần kinh này có hiệu suất tốt hơn trong việc đề xuất các API đúng cho các tác vụ lập trình đã cho so với việc sinh mã nguồn trực tiếp. Bảng 7 hiển thị hiệu suất của các mô hình này trong việc xác định các API đúng. Như chúng ta có thể thấy, các giá trị precision và recall để xác định API đúng cao hơn trên tất cả các tác vụ lập trình ML khác nhau, cho thấy chúng
Bản thảo nộp cho ACM

--- TRANG 13 ---
Tốt, Xấu và Thiếu Sót: Sinh Mã Thần Kinh cho Các Tác Vụ Học Máy 13
00.20.40.60.81
(a) tranX00.20.40.60.81
(b) EK Codegen00.20.40.60.81
(c) PyCodeGPT
Hình 2. Precision của việc xác định API đúng của tranX và EK Codegen PyCodeGPT, trên dữ liệu, mô hình, đánh giá, không phải ml, tương ứng.
00.20.40.60.81
(a) tranX00.20.40.60.81
(b) EK codegen00.20.40.60.81
(c) PyCodeGPT
Hình 3. Recall của việc xác định API đúng của tranX và EK codegen PyCodeGPT, trên dữ liệu, mô hình, đánh giá, không phải ml, tương ứng.
có thể giúp xác định trung bình 39% API đúng để giải quyết các tác vụ ML. Chúng tôi tiếp tục hiển thị các biểu đồ hộp của các giá trị precision và recall về việc xác định API đúng của ba mô hình trong Hình 2 và Hình 3 tương ứng.
Chúng tôi tiếp tục hiển thị một ví dụ tác vụ ML không thể được giải quyết bởi các mô hình sinh mã thần kinh hiện có trong khi một số API cần thiết có thể được xác định trong Danh sách 1. Tác vụ được gán nhãn là tác vụ xây dựng mô hình hoàn thành với thư viện TensorFlow, về việc xây dựng và chạy một session bằng cách tải một đối tượng từ điển. Mã thực tế khởi tạo hai placeholder với kiểu tf.int32 và cộng chúng trước khi chạy một session. Khi họ chạy session, họ cấp một đối tượng từ điển trước khi chạy chúng. Trong khi mã nguồn được sinh ra không thể sinh ra phần từ điển, nó thành công sinh ra mã khởi tạo một placeholder có kiểu tf.int32 và sau đó xây dựng và chạy session thành công. Precision và recall về việc xác định API đúng là 100% và 57% tương ứng.
Xấu: Tất cả các mô hình sinh mã thần kinh được kiểm tra yếu trong việc sinh các chương trình đúng về ngữ nghĩa. Tốt: Các chương trình được sinh ra có tiềm năng được sử dụng để xác định API đúng cho các tác vụ lập trình ML.
4.4 RQ4: Tính Hữu Ích
Phương pháp: Để khám phá giá trị thực tế của các mô hình sinh mã thần kinh, chúng tôi tiếp tục tiến hành nghiên cứu trường hợp người dùng để điều tra xem các chương trình được sinh ra bởi các mô hình mã thần kinh này có thể giúp nhà phát triển hoàn thành các tác vụ lập trình đã cho một cách hiệu quả và chính xác hay không. Trong thí nghiệm này, chúng tôi kiểm tra các chương trình được sinh ra bởi hai mô hình tốt nhất, tức là PyCodeGPT và EK codegen trên thư viện TensorFlow. Chúng tôi chọn ngẫu nhiên 20 tác vụ lập trình từ bộ dữ liệu kiểm tra của TensorFlow. Chúng tôi mời 12 sinh viên (tức là sáu sinh viên tiến sĩ và sáu sinh viên thạc sĩ) quen thuộc với framework TensorFlow để hoàn thành 20 tác vụ lập trình. Kinh nghiệm của họ trong việc phát triển các tác vụ ML dựa trên TensorFlow dao động từ hai đến bốn năm, với trung bình ba năm. Sau đó chúng tôi chia các người tham gia thành hai nhóm (Nhóm1 và Nhóm2) dựa trên kinh nghiệm của họ. 20 tác vụ cũng được chia ngẫu nhiên thành hai nhóm (Tác vụ1
Bản thảo nộp cho ACM

--- TRANG 14 ---
14 Shin và cộng sự.
Không có Có00.20.40.60.81
(a) Tính đúng đắnKhông có Có246810
(b) Thời gian Hoàn thành (phút)
Hình 4. Hiệu suất của người tham gia với (ký hiệu là 'Có' trong hình) và không có (ký hiệu là 'Không có' trong hình) sự giúp đỡ của các mô hình sinh mã.
và Tác vụ2). Thí nghiệm được tiến hành trong hai bước. Trong bước đầu tiên, Nhóm1 và Nhóm2 được yêu cầu làm việc trên Tác vụ1 trong khi Nhóm1 sẽ được cung cấp chương trình được sinh ra từ cả PyCodeGPT và EK codegen, trong bước thứ hai, Nhóm1 và Nhóm2 được yêu cầu làm việc trên Tác vụ2 trong khi Nhóm2 sẽ được cung cấp chương trình được sinh ra từ cả PyCodeGPT và EK codegen. Mỗi người tham gia được yêu cầu ghi màn hình của mình/cô ấy trong thí nghiệm để có thời gian mà anh/cô ấy dành cho việc giải quyết mỗi tác vụ lập trình. Theo các nghiên cứu hiện có [31,51], chúng tôi sử dụng tính đúng đắn và thời gian hoàn thành để đo hiệu suất của người tham gia trong việc giải quyết các tác vụ ML. Cụ thể, tính đúng đắn đánh giá xem một người tham gia có thể viết mã đúng cho một tác vụ đã cho hay không. Lưu ý rằng, vì nhà phát triển có thể giải quyết cùng một tác vụ với logic khác nhau, do đó chúng tôi đo tỷ lệ API đúng được nộp bởi một người tham gia trong tất cả các API trong câu trả lời thực tế của tác vụ. Thời gian hoàn thành đánh giá một người tham gia có thể giải quyết một tác vụ đã cho nhanh như thế nào. Đối với mỗi tác vụ, chúng tôi ghi lại tính đúng đắn và thời gian hoàn thành của mỗi người tham gia.
Kết quả: Hình 4 hiển thị phân phối tính đúng đắn và thời gian hoàn thành của người tham gia để hoàn thành 20 tác vụ ML đã cho. Nhìn chung, với mã được sinh ra từ hai mô hình sinh mã, người tham gia hoàn thành các tác vụ lập trình chính xác hơn và mất ít thời gian hơn một chút so với người tham gia không có bất kỳ gợi ý nào. Trung bình, tính đúng đắn và thời gian hoàn thành của người tham gia có và không có mã được sinh ra là 0,62 và 5,2, so với 0,51 và 5,6 tương ứng. Chúng tôi tiếp tục sử dụng kiểm tra thứ hạng có dấu Wilcoxon để xác minh ý nghĩa thống kê của sự khác biệt. Giá trị p cho tính đúng đắn nhỏ hơn 0,05 trong khi giá trị p cho thời gian hoàn thành lớn hơn 0,05. Kết quả cho thấy rằng mã được sinh ra không thể giảm đáng kể chi phí thời gian của các tác vụ lập trình ML, trong khi nó có thể giúp nhà phát triển viết mã chính xác hơn. Một lý do có thể cho điều này là hầu hết các chương trình được sinh ra không đúng về ngữ nghĩa, việc sửa đổi các chương trình được sinh ra không dễ dàng và yêu cầu một lượng thời gian lớn. Thảo luận của chúng tôi với người tham gia xác nhận rằng các mô hình sinh mã được kiểm tra có thể giúp tìm một phần của các API đúng cho các tác vụ ML, cung cấp cho nhà phát triển các gợi ý hữu ích, do đó cải thiện thêm tính đúng đắn của nhà phát triển.
Xấu: Các mô hình sinh mã không thể cải thiện đáng kể thời gian hoàn thành của nhà phát triển vì hầu hết các chương trình được sinh ra không đúng về ngữ nghĩa, yêu cầu thời gian không tầm thường để sửa đổi. Tốt: Mã được sinh ra có thể giúp nhà phát triển viết mã chính xác hơn bằng cách cung cấp cho nhà phát triển các gợi ý sử dụng API đúng.
Bản thảo nộp cho ACM

--- TRANG 15 ---
Tốt, Xấu và Thiếu Sót: Sinh Mã Thần Kinh cho Các Tác Vụ Học Máy 15
5 THẢO LUẬN
5.1 Thiếu Sót của Sinh Mã trên Các Tác Vụ ML
Các kết quả và phân tích trên đã tiết lộ một số khía cạnh tốt và xấu của các mô hình sinh mã thần kinh tiên tiến trên các tác vụ lập trình ML. Mục này tiếp tục tóm tắt khía cạnh thiếu sót có thể phục vụ như hướng dẫn thực tế để cải thiện các tác vụ sinh mã cho các tác vụ ML.
Phân tách sinh mã để chia để trị. Ngay cả khi được trang bị các kỹ thuật thần kinh sâu tiên tiến, sinh mã cho các tác vụ lập trình ML vẫn là một thách thức. Việc sinh mã trực tiếp từ một tác vụ lập trình được mô tả bằng NL thường tạo ra các chương trình không chính xác và không đủ năng lực mà nhà phát triển không thể sử dụng. Tuy nhiên, các phát hiện từ nghiên cứu trường hợp người dùng của chúng tôi tiết lộ rằng mã được sinh ra không chính xác vẫn có thể hữu ích cho nhà phát triển miễn là nó chứa các API thiết yếu để giải quyết các tác vụ. Trong khi đó, việc xác định các API đúng dễ dàng hơn việc sinh các chương trình đúng trực tiếp. Theo nghĩa này, các kỹ thuật sinh mã tương lai cho các tác vụ ML có thể được phân tách thành hai tác vụ tuần tự, tức là xác định chuỗi API và sinh cách sử dụng API. Kiến thức cộng đồng từ Stack Overflow có thể được sử dụng để giúp sinh ngữ cảnh của các chuỗi API được xác định, đã được chứng minh là hữu ích trong việc khai thác các tình huống sử dụng API [23, 48].
Sinh mã hợp tác giữa con người và máy. Các mô hình sinh mã thần kinh tiên tiến được kiểm tra coi sinh mã như một tác vụ dịch máy và sinh các câu lệnh/khối từ một tác vụ lập trình được mô tả bằng NL tuần tự, trong đó bất kỳ câu lệnh không chính xác nào có thể làm sai lệch việc sinh các đoạn mã tuần tự. Trong khi đó, trong nghiên cứu trường hợp của chúng tôi, tương tự như các phát hiện của Murali và cộng sự [36], chúng tôi cũng thấy rằng, mặc dù thiếu toàn bộ kiến thức cho các tác vụ lập trình nhất định, nhà phát triển thường biết liệu nó có đúng cho một số câu lệnh được sinh ra hay không, hoặc liệu một API cụ thể có nên được sử dụng dựa trên kiến thức của họ về thư viện ML. Nếu kiến thức con người có thể được tích hợp vào quá trình sinh mã tự động, ví dụ dưới dạng phản hồi đơn giản từ người dùng cuối để đánh giá tính đúng đắn của các câu lệnh không chắc chắn trung gian, việc sinh mã có thể được cải thiện đáng kể. Thực hành như vậy có lợi thế khác, tức là cá nhân hóa mã được sinh ra phù hợp với kiến thức của các người dùng cuối khác nhau, bằng cách tích hợp kiến thức của nhà phát triển vào quá trình sinh mã.
Tập trung vào các tác vụ chuyên biệt theo lĩnh vực. So với các tác vụ lập trình không phải ML chung, tất cả sáu mô hình sinh mã thần kinh đều hoạt động tốt hơn về tính đúng đắn cú pháp, tính đúng đắn ngữ nghĩa và xác định các API thiết yếu, trên các tác vụ chuyên biệt theo lĩnh vực, tức là các tác vụ lập trình ML. Chúng tôi giả định điều này có thể là do các tác vụ chuyên biệt theo lĩnh vực chỉ liên quan đến một tập hợp API nhỏ hơn (cho thấy ít kiến thức cần được học), do đó việc huấn luyện một mô hình hiệu quả tương đối dễ dàng hơn so với việc huấn luyện mô hình trên bộ dữ liệu với các tác vụ đa dạng. Chúng tôi cũng nhận thấy rằng các thực hành trước đây về sinh mã thường được tiến hành trên các tác vụ chung [1,39,53,54]. Do đó, sinh mã tương lai nên tập trung vào việc huấn luyện hoặc tinh chỉnh mô hình với dữ liệu từ các lĩnh vực cụ thể để cải thiện hiệu suất sinh chương trình cho các tác vụ chuyên biệt theo lĩnh vực, có nhiều tiềm năng hơn các tác vụ lập trình chung. Chúng tôi cũng khuyến khích nhu cầu thiết kế các mô hình chuyên biệt theo lĩnh vực bằng cách kết hợp các đặc điểm của lĩnh vực, có thể cải thiện thêm hiệu suất của các tác vụ cụ thể.
5.2 Mối Đe Dọa đối với Tính Hợp Lệ
Tính Hợp Lệ Nội Bộ. Mối đe dọa chính đối với tính hợp lệ nội bộ của nghiên cứu chúng tôi là số lượng mô hình được so sánh hạn chế. Do hạn chế này, chúng tôi không thể tổng quát hóa các phát hiện từ bài báo này cho tất cả các mô hình sinh mã nguồn. Tuy nhiên, chúng tôi đã sử dụng những mô hình được xuất bản gần đây nhất và có hiệu suất tiên tiến nhất để tiến hành thí nghiệm, chúng tôi cũng mô tả phương pháp luận chi tiết và thiết lập của nghiên cứu và dữ liệu được sử dụng, điều này sẽ cho phép các nhà nghiên cứu tương lai sao chép nghiên cứu của chúng tôi và khám phá thêm các mô hình sinh mã nguồn khác.
Tính Hợp Lệ Bên Ngoài. Mối đe dọa chính đối với tính hợp lệ bên ngoài là việc gán nhãn dữ liệu thực tế được khám phá trong nghiên cứu. Mặc dù chúng tôi đã nỗ lực nhiều để duy trì dữ liệu chất lượng cao bằng cách sử dụng các chương trình thực tế được đóng góp bởi nhà phát triển trên GitHub, nó có thể không đủ để xác thực việc triển khai mã nguồn. Ngoài ra, lập trình hoặc triển khai một tác vụ lập trình có thể dẫn đến nhiều hình thức và logic mã nguồn khác nhau. Do đó, các chương trình này trong bộ dữ liệu của chúng tôi có thể không đại diện cho tất cả các cách để triển khai một tác vụ lập trình đã cho.
Tính Hợp Lệ Cấu Trúc. Mối đe dọa chính đối với tính hợp lệ cấu trúc có thể là các chỉ số đánh giá mà chúng tôi sử dụng. Điểm BLEU, ROUGE-L và METEOR có thể đánh giá việc sinh chương trình bằng cách tính toán mức độ tương tự của các chương trình được sinh ra bởi các mô hình sinh mã thần kinh với các chương trình thực tế của các tác vụ đã cho trong bộ dữ liệu của chúng tôi. Tuy nhiên như đã đề cập từ tính hợp lệ bên ngoài, các triển khai khác có thể là một câu trả lời hợp lý thay vì sử dụng sự tương đồng với thực tế. Trong nghiên cứu tương lai, chúng tôi dự định kiểm tra một tập hợp các chỉ số đánh giá khác nhau để đánh giá việc sinh chương trình.
6 CÔNG TRÌNH LIÊN QUAN
6.1 Sinh Mã Tự Động
Bên cạnh sáu mô hình sinh mã thần kinh được sử dụng trong bài báo này, có nhiều phương pháp khác để sinh mã tự động từ mô tả ngôn ngữ tự nhiên được đề xuất trong thập kỷ gần đây [29,42,55]. Cụ thể hơn, các mạng thần kinh sâu trong lĩnh vực xử lý ngôn ngữ tự nhiên đã được áp dụng ngày càng nhiều để đóng gói độ phức tạp của việc sinh các ngôn ngữ lập trình mục đích chung như Java và Python. Dong và Lapata [17] đề xuất Coarse2Fine sử dụng kiến trúc thần kinh nhận thức cấu trúc áp dụng hai bước giải mã của phân tích ngữ nghĩa. Đầu tiên, phương pháp giải mã một bản phác thảo thô của biểu diễn ý nghĩa với mức cao nơi nó bỏ qua các chi tiết như định danh. Sau đó họ áp dụng một cơ chế khác điền các chi tiết còn thiếu bằng cách điều kiện mô tả ngôn ngữ tự nhiên cùng với bản phác thảo của biểu diễn ý nghĩa tổng quát. Hayati và cộng sự [21] đề xuất ReCode khai thác truy xuất cây con để tham chiếu rõ ràng các ví dụ mã trong một mô hình sinh mã thần kinh. Phương pháp này áp dụng một phương pháp dịch máy thần kinh dựa trên truy xuất trong ngữ cảnh sinh mã nguồn. Đây là phương pháp đầu tiên giới thiệu kỹ thuật truy xuất vào sinh mã. Murali và cộng sự [36] đề xuất một phương pháp kết hợp mạng thần kinh và tìm kiếm tổ hợp để sinh mã nguồn từ các phác thảo, là một kiểu mã nguồn trừu tượng che giấu các hằng số và định danh do người dùng định nghĩa. Sun và cộng sự [46] đề xuất một mạng nơ-ron tích chập (CNN) cấu trúc dựa trên ngữ pháp sử dụng tích chập dựa trên cây, tích chập tiền thứ tự và các lớp gộp chú ý để dự đoán gọn gàng hơn các mô hình seq2seq. Tích chập dựa trên cây áp dụng cửa sổ trượt trên các cấu trúc AST. Tích chập tiền thứ tự duyệt các nút của AST một phần. Hai mô-đun CNN này giúp nắm bắt thông tin láng giềng của cây. Gộp chú ý được thiết kế để tập hợp các đặc trưng CNN để dự đoán tên định danh tốt hơn. Sun và cộng sự [47] đề xuất TreeGen là một kiến trúc thần kinh dựa trên cây sử dụng cơ chế attention của Transformers để giảm bớt các vấn đề phụ thuộc dài và sử dụng bộ mã hóa AST để kết hợp các quy tắc ngữ pháp và cấu trúc AST vào mạng. Họ sử dụng một lớp con tích chập chỉ trên các khối giải mã Transformer đầu tiên để ngăn Transformer trộn thông tin từ các nút khác có thể rò rỉ thông tin gốc. Lyu và cộng sự [33] đề xuất một mô hình sinh khai thác các phụ thuộc của phương thức API như một đồ thị phụ thuộc API và sử dụng nhúng đồ thị vào một mô hình seq2seq. Họ kết hợp một mô-đun mã hóa-giải mã nắm bắt cả các phụ thuộc cấu trúc toàn cục và mô tả chương trình văn bản khi sinh mã nguồn. Ahmad và cộng sự [2] đề xuất PLBART, là một mô hình transformer tự hồi quy được huấn luyện trước trên một bộ sưu tập rộng lớn các hàm Java và Python không được gán nhãn được ghép nối với các văn bản ngôn ngữ tự nhiên thông qua các bộ mã hóa tự động khử nhiễu. Phương pháp này giúp giảm nỗ lực khai thác các chú thích được người biên tập cao khi tinh chỉnh các tác vụ cụ thể. Họ đã đánh giá PLBART trên một số tác vụ, tức là tóm tắt mã, sinh mã, dịch mã, sửa chữa chương trình, phát hiện nhân bản và phát hiện lỗ hổng.
Đề xuất API có thể được xem như một loại sinh mã, nhắm đến việc sinh một tập hợp API cụ thể cho một truy vấn đã cho từ nhà phát triển [9–11,32,35,44,45,51]. Liu và cộng sự [32] đề xuất một phương pháp gọi là RecRank áp dụng một phương pháp phân biệt dựa trên xếp hạng mới khai thác các đặc trưng đường dẫn sử dụng API để cải thiện hiệu suất của họ trên đề xuất. Xie và cộng sự [51] nghiên cứu mối quan hệ giữa các mẫu cụm từ động từ mô tả chức năng của API và các truy vấn người dùng để tìm những API đó. Chen và cộng sự [11] đề xuất một phương pháp đề xuất API mới kết hợp việc sử dụng API với thông tin văn bản trong mã nguồn dựa trên một mạng đồ thị ngữ cảnh API. Chen và cộng sự [10] đề xuất COOK, là một đề xuất chuỗi API kết hợp các mô hình học sâu và các chiến lược hậu xử lý. Họ đã nâng cao tìm kiếm beam với các heuristic cụ thể mã giúp họ cải thiện chất lượng đề xuất.
6.2 Phân Tích Hiệu Quả Mô Hình
Cũng đã có nhiều nghiên cứu thực nghiệm điều tra tính hiệu quả của các mô hình sinh mã nguồn trong các ngữ cảnh khác nhau. Liu và cộng sự [31] điều tra tính hiệu quả của các mô hình sinh mã nguồn khi các văn bản yêu cầu ngôn ngữ tự nhiên của lập trình chung được đưa ra. Họ đã xây dựng một bộ dữ liệu quy mô lớn, ReCa, để đánh giá năm mô hình sinh mã nguồn trong việc xử lý các chuỗi văn bản yêu cầu dài hơn. Chirkova và Troshin [12] tiến hành một nghiên cứu thực nghiệm về các phương pháp áp dụng Transformers [49] cho mã nguồn trong lĩnh vực kỹ thuật phần mềm. Họ điều tra cách Transformers sử dụng thông tin cú pháp của mã nguồn trong việc mô hình hóa các tác vụ hoàn thành mã, đặt tên hàm và sửa lỗi. Antonio và cộng sự [34] đánh giá thực nghiệm tác động của kiến trúc T5 (Text-to-Text Transfer Transformer) [43] khi được áp dụng cho mã nguồn. Họ thấy rằng mô hình T5 của họ vượt trội hơn bốn đường cơ sở hiện có khi dữ liệu lớn hơn được sử dụng trong huấn luyện trước. Peng và cộng sự [41] đã làm một nghiên cứu để thống nhất các tác vụ và bộ dữ liệu chuẩn của đề xuất API để hoàn toàn tạo điều kiện cho các nghiên cứu tương lai. Họ nhóm các phương pháp khác nhau liên quan đến đầu vào mà họ xử lý (tức là truy vấn hoặc mã). Họ đề xuất một bộ dữ liệu chuẩn chung, APIBENCH, để đánh giá 11 phương pháp hiện có trong cả đề xuất API dựa trên truy vấn và mã.
Các nghiên cứu thực nghiệm này đánh giá tính hiệu quả của các mô hình sinh mã nguồn trong việc sinh các tác vụ lập trình chung về các mức độ phức tạp NL khác nhau [31] và kiến trúc khác nhau [12,34]. Sự khác biệt trong công trình của chúng tôi là chúng tôi điều tra tính hiệu quả của các mô hình sinh trong việc sinh mã nguồn liên quan đến học máy/học sâu sử dụng các thư viện ML.
7 KẾT LUẬN
Bài báo này tiến hành một nghiên cứu thực nghiệm để khám phá hiệu suất của sáu mô hình sinh mã thần kinh tiên tiến trên các tác vụ lập trình ML. Một bộ dữ liệu chuẩn mới chứa 83K cặp tác vụ lập trình được mô tả bằng ngôn ngữ tự nhiên và các chương trình tương ứng được triển khai bởi bốn thư viện ML được giới thiệu. Nghiên cứu thực nghiệm của chúng tôi tiết lộ một số khía cạnh tốt, xấu và thiếu sót, với một số khía cạnh chính được liệt kê dưới đây. (Tốt) Các mô hình sinh mã thần kinh hoạt động tốt hơn đáng kể trên các tác vụ ML so với các tác vụ không phải ML. (Xấu) Hầu hết mã được sinh ra không chính xác về mặt ngữ nghĩa. (Xấu) Các mô hình sinh mã không thể cải thiện đáng kể thời gian hoàn thành của nhà phát triển. (Tốt) Mã được sinh ra có thể giúp nhà phát triển viết mã chính xác hơn bằng cách cung cấp gợi ý sử dụng API đúng. (Thiếu sót) Quan sát từ nghiên cứu người dùng của chúng tôi tiết lộ các khía cạnh thiếu sót của sinh mã cho các tác vụ ML, ví dụ như phân tách sinh mã để chia để trị thành hai tác vụ: xác định chuỗi API và sinh cách sử dụng API.
TÀI LIỆU THAM KHẢO
[1]Rajas Agashe, Srinivasan Iyer và Luke Zettlemoyer. 2019. Juice: Một bộ dữ liệu được giám sát từ xa quy mô lớn cho sinh mã dựa trên ngữ cảnh miền mở. arXiv preprint arXiv:1910.02216 (2019).
[2]Wasi Ahmad, Saikat Chakraborty, Baishakhi Ray và Kai-Wei Chang. 2021. Huấn luyện trước Thống nhất cho Hiểu biết và Sinh Chương trình. Trong Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. 2655–2668.
[3]Wasi Uddin Ahmad, Md Golam Rahman Tushar, Saikat Chakraborty và Kai-Wei Chang. 2021. AVATAR: Một Corpus Song song cho Dịch Chương trình Java-Python. arXiv preprint arXiv:2108.11590 (2021).
[4]Saleema Amershi, Andrew Begel, Christian Bird, Robert DeLine, Harald Gall, Ece Kamar, Nachiappan Nagappan, Besmira Nushi và Thomas Zimmermann. 2019. Kỹ thuật phần mềm cho học máy: Một nghiên cứu trường hợp. Trong 2019 IEEE/ACM 41st International Conference on Software Engineering: Software Engineering in Practice (ICSE-SEIP). IEEE, 291–300.
[5]Satanjeev Banerjee và Alon Lavie. 2005. METEOR: Một chỉ số tự động cho đánh giá MT với sự tương quan cải thiện với các phán đoán của con người. Trong Proceedings of the acl workshop on intrinsic and extrinsic evaluation measures for machine translation and/or summarization. 65–72.
[6]Sid Black, Leo Gao, Phil Wang, Connor Leahy và Stella Biderman. 2021. GPT-Neo: Mô hình Ngôn ngữ Tự hồi quy Quy mô Lớn với Mesh-Tensorflow. Nếu bạn sử dụng phần mềm này, vui lòng trích dẫn nó bằng các metadata này 58 (2021).
[7]Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, và cộng sự. 2020. Các mô hình ngôn ngữ là những người học few-shot. Advances in neural information processing systems 33 (2020), 1877–1901.
[8]Nghi DQ Bui, Yijun Yu và Lingxiao Jiang. 2021. Học Tương phản Tự giám sát cho Truy xuất và Tóm tắt Mã qua Các Biến đổi Bảo toàn Ngữ nghĩa. Trong Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval. 511–521.
[9]Wing-Kwan Chan, Hong Cheng và David Lo. 2012. Tìm kiếm đồ thị con API được kết nối qua các cụm từ văn bản. Trong Proceedings of the ACM SIGSOFT 20th International Symposium on the Foundations of Software Engineering. 1–11.
[10] Chi Chen, Xin Peng, Bihuan Chen, Jun Sun, Zhenchang Xing, Xin Wang và Wenyun Zhao. 2022. "Hơn cả Học Sâu": hậu xử lý cho đề xuất chuỗi API. Empirical Software Engineering 27, 1 (2022), 1–32.
[11] Chi Chen, Xin Peng, Zhenchang Xing, Jun Sun, Xin Wang, Yifan Zhao và Wenyun Zhao. 2021. Kết hợp toàn diện thông tin mã cấu trúc và văn bản cho đề xuất API dựa trên ngữ cảnh. IEEE Transactions on Software Engineering (2021).
[12] Nadezhda Chirkova và Sergey Troshin. 2021. Nghiên cứu thực nghiệm về transformers cho mã nguồn. Trong Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering. 703–715.
[13] Anthony E Cozzie và Samuel King. 2012. Macho: Viết chương trình với ngôn ngữ tự nhiên và ví dụ. (2012).
[14] Samip Dahal, Adyasha Maharana và Mohit Bansal. 2021. Phân tích Các Kiến trúc Có cấu trúc Cây cho Sinh Mã. Trong Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021. 4382–4391.
[15] Jacob Devlin, Ming-Wei Chang, Kenton Lee và Kristina Toutanova. 2018. Bert: Huấn luyện trước các transformers lưỡng hướng sâu để hiểu ngôn ngữ. arXiv preprint arXiv:1810.04805 (2018).
[16] Li Dong và Mirella Lapata. 2016. Ngôn ngữ đến dạng logic với attention thần kinh. arXiv preprint arXiv:1601.01280 (2016).
[17] Li Dong và Mirella Lapata. 2018. Giải mã Thô-đến-Tinh cho Phân tích Ngữ nghĩa Thần kinh. Trong Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 731–742.
[18] Albert Gatt và Emiel Krahmer. 2018. Khảo sát tình trạng nghệ thuật trong sinh ngôn ngữ tự nhiên: Các tác vụ cốt lõi, ứng dụng và đánh giá. Journal of Artificial Intelligence Research 61 (2018), 65–170.
[19] Xiaodong Gu, Hongyu Zhang và Sunghun Kim. 2018. Tìm kiếm mã sâu. Trong 2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE). IEEE, 933–944.
[20] Daya Guo, Shuo Ren, Shuai Lu, Zhangyin Feng, Duyu Tang, Shujie Liu, Long Zhou, Nan Duan, Alexey Svyatkovskiy, Shengyu Fu, và cộng sự.2020. Graphcodebert: Huấn luyện trước các biểu diễn mã với luồng dữ liệu. arXiv preprint arXiv:2009.08366 (2020).
[21] Shirley Anugrah Hayati, Raphael Olivier, Pravalika Avvaru, Pengcheng Yin, Anthony Tomasic và Graham Neubig. 2018. Sinh Mã Thần kinh Dựa trên Truy xuất. Trong Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing.
[22] Jin Huang và Charles X Ling. 2005. Sử dụng AUC và độ chính xác trong đánh giá các thuật toán học. IEEE Transactions on knowledge and Data Engineering 17, 3 (2005), 299–310.
[23] Qiao Huang, Xin Xia, Zhenchang Xing, David Lo và Xinyu Wang. 2018. Đề xuất phương thức API mà không lo lắng về khoảng cách kiến thức tác vụ-API. Trong 2018 33rd IEEE/ACM International Conference on Automated Software Engineering (ASE). IEEE, 293–304.
[24] Hui Jiang, Chulun Zhou, Fandong Meng, Biao Zhang, Jie Zhou, Degen Huang, Qingqiang Wu và Jinsong Su. 2021. Khám phá Lựa chọn Động của Thứ tự Mở rộng Nhánh cho Sinh Mã. Trong Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers). 5076–5085.
Bản thảo nộp cho ACM

--- TRANG 19 ---
Tốt, Xấu và Thiếu Sót: Sinh Mã Thần Kinh cho Các Tác Vụ Học Máy 19
[25] Rafal Jozefowicz, Oriol Vinyals, Mike Schuster, Noam Shazeer và Yonghui Wu. 2016. Khám phá giới hạn của mô hình ngôn ngữ. arXiv preprint arXiv:1602.02410 (2016).
[26] Samina Khalid, Tehmina Khalil và Shamila Nasreen. 2014. Một khảo sát về lựa chọn đặc trưng và kỹ thuật trích xuất đặc trưng trong học máy. Trong 2014 science and information conference. IEEE, 372–378.
[27] Yann LeCun, Yoshua Bengio và Geoffrey Hinton. 2015. Học sâu. nature 521, 7553 (2015), 436–444.
[28] Chin-Yew Lin. 2004. Rouge: Một gói để đánh giá tự động các bản tóm tắt. Trong Text summarization branches out. 74–81.
[29] Wang Ling, Phil Blunsom, Edward Grefenstette, Karl Moritz Hermann, Tomáš Kočiský, Fumin Wang và Andrew Senior. 2016. Mạng Dự đoán Tiềm ẩn cho Sinh Mã. Trong Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 599–609.
[30] Chang Liu, Xin Wang, Richard Shin, Joseph E Gonzalez và Dawn Song. 2016. Hoàn thành mã thần kinh. (2016).
[31] Hui Liu, Mingzhu Shen, Jiaqi Zhu, Nan Niu, Ge Li và Lu Zhang. 2020. Sinh chương trình dựa trên học sâu từ văn bản yêu cầu: Chúng ta đã đến đó chưa? IEEE Transactions on Software Engineering (2020).
[32] Xiaoyu Liu, LiGuo Huang và Vincent Ng. 2018. Đề xuất API hiệu quả mà không có kho lưu trữ phần mềm lịch sử. Trong Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering. 282–292.
[33] Chen Lyu, Ruyun Wang, Hongyu Zhang, Hanwen Zhang và Songlin Hu. 2021. Nhúng đồ thị phụ thuộc API cho sinh mã thần kinh. Empirical Software Engineering 26, 4 (2021), 1–51.
[34] Antonio Mastropaolo, Simone Scalabrino, Nathan Cooper, David Nader Palacio, Denys Poshyvanyk, Rocco Oliveto và Gabriele Bavota. 2021. Nghiên cứu việc sử dụng transformer chuyển text-to-text để hỗ trợ các tác vụ liên quan đến mã. Trong 2021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE). IEEE, 336–347.
[35] Collin McMillan, Mark Grechanik, Denys Poshyvanyk, Qing Xie và Chen Fu. 2011. Portfolio: tìm các hàm liên quan và cách sử dụng của chúng. Trong Proceedings of the 33rd International Conference on Software Engineering. 111–120.
[36] Vijayaraghavan Murali, Letao Qi, Swarat Chaudhuri và Chris Jermaine. 2018. Học Phác thảo Thần kinh cho Sinh Chương trình Có điều kiện. Trong International Conference on Learning Representations.
[37] Giang Nguyen, Stefan Dlugolinsky, Martin Bobák, Viet Tran, Alvaro Lopez Garcia, Ignacio Heredia, Peter Malík và Ladislav Hluchý. 2019. Các framework và thư viện học máy và học sâu cho khai thác dữ liệu quy mô lớn: một khảo sát. Artificial Intelligence Review 52, 1 (2019), 77–124.
[38] Sajad Norouzi, Keyi Tang và Yanshuai Cao. 2021. Sinh Mã từ Ngôn ngữ Tự nhiên với Ít Kiến thức Tiền nghiệm và Nhiều Dữ liệu Đơn ngữ hơn. Trong Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers). 776–785.
[39] Yusuke Oda, Hiroyuki Fudaba, Graham Neubig, Hideaki Hata, Sakriani Sakti, Tomoki Toda và Satoshi Nakamura. 2015. Học sinh mã giả từ mã nguồn sử dụng dịch máy thống kê. Trong 2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE). IEEE, 574–584.
[40] Kishore Papineni, Salim Roukos, Todd Ward và Wei-Jing Zhu. 2002. Bleu: một phương pháp đánh giá tự động dịch máy. Trong Proceedings of the 40th annual meeting of the Association for Computational Linguistics. 311–318.
[41] Yun Peng, Shuqing Li, Wenwei Gu, Yichen Li, Wenxuan Wang, Cuiyun Gao và Michael Lyu. 2022. Xem xét lại, Đánh giá và Khám phá Đề xuất API: Chúng ta đã đi xa đến đâu? IEEE Transactions on Software Engineering (2022).
[42] Maxim Rabinovich, Mitchell Stern và Dan Klein. 2017. Mạng Cú pháp Trừu tượng cho Sinh Mã và Phân tích Ngữ nghĩa. Trong Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 1139–1149.
[43] Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, Peter J Liu, và cộng sự.2020. Khám phá giới hạn của học chuyển giao với transformer text-to-text thống nhất. J. Mach. Learn. Res. 21, 140 (2020), 1–67.
[44] Mukund Raghothaman, Yi Wei và Youssef Hamadi. 2016. Swim: Tổng hợp những gì tôi có ý nghĩa-tìm kiếm mã và tổng hợp đoạn mã thành ngữ. Trong 2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE). IEEE, 357–367.
[45] Mohammad Masudur Rahman, Chanchal K Roy và David Lo. 2016. Rack: Đề xuất api tự động sử dụng kiến thức cộng đồng. Trong 2016 IEEE 23rd International Conference on Software Analysis, Evolution, and Reengineering (SANER), Vol. 1. IEEE, 349–359.
[46] Zeyu Sun, Qihao Zhu, Lili Mou, Yingfei Xiong, Ge Li và Lu Zhang. 2019. Một bộ giải mã CNN cấu trúc dựa trên ngữ pháp cho sinh mã. Trong Proceedings of the AAAI conference on artificial intelligence, Vol. 33. 7055–7062.
[47] Zeyu Sun, Qihao Zhu, Yingfei Xiong, Yican Sun, Lili Mou và Lu Zhang. 2020. Treegen: Một kiến trúc transformer dựa trên cây cho sinh mã. Trong Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 34. 8984–8991.
[48] Gias Uddin, Foutse Khomh và Chanchal K Roy. 2020. Khai thác các tình huống sử dụng API từ stack overflow. Information and Software Technology 122 (2020), 106277.
[49] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser và Illia Polosukhin. 2017. Attention is all you need. Trong Advances in neural information processing systems. 5998–6008.
[50] Song Wang, Nishtha Shrestha, Abarna Kucheri Subburaman, Junjie Wang, Moshi Wei và Nachiappan Nagappan. 2021. Sinh Kiểm thử Đơn vị Tự động cho Thư viện Học Máy: Chúng ta đã đi xa đến đâu?. Trong 2021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE). IEEE, 1548–1560.
[51] Wenkai Xie, Xin Peng, Mingwei Liu, Christoph Treude, Zhenchang Xing, Xiaoxin Zhang và Wenyun Zhao. 2020. Đề xuất phương thức API qua khớp rõ ràng các cụm từ động từ chức năng. Trong Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and
Bản thảo nộp cho ACM

--- TRANG 20 ---
20 Shin và cộng sự.
Symposium on the Foundations of Software Engineering. 1015–1026.
[52] Frank F Xu, Zhengbao Jiang, Pengcheng Yin, Bogdan Vasilescu và Graham Neubig. 2020. Kết hợp Kiến thức Bên ngoài thông qua Huấn luyện trước cho Sinh Mã từ Ngôn ngữ Tự nhiên. Trong Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics.
[53] Ziyu Yao, Daniel S Weld, Wei-Peng Chen và Huan Sun. 2018. Staqc: Một bộ dữ liệu câu hỏi-mã được khai thác có hệ thống từ stack overflow. Trong Proceedings of the 2018 World Wide Web Conference. 1693–1703.
[54] Pengcheng Yin, Bowen Deng, Edgar Chen, Bogdan Vasilescu và Graham Neubig. 2018. Học khai thác các cặp mã và ngôn ngữ tự nhiên đã căn chỉnh từ stack overflow. Trong 2018 IEEE/ACM 15th international conference on mining software repositories (MSR). IEEE, 476–486.
[55] Pengcheng Yin và Graham Neubig. 2017. Một Mô hình Thần kinh Cú pháp cho Sinh Mã Mục đích Chung. Trong Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 440–450.
[56] Pengcheng Yin và Graham Neubig. 2018. TRANX: Một Trình phân tích Cú pháp Trừu tượng Thần kinh Dựa trên Chuyển đổi cho Phân tích Ngữ nghĩa và Sinh Mã. Trong Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing: System Demonstrations. 7–12.
[57] Daoguang Zan, Bei Chen, Dejian Yang, Zeqi Lin, Minsu Kim, Bei Guan, Yongji Wang, Weizhu Chen và Jian-Guang Lou. 2022. CERT: Huấn luyện trước Liên tục trên Phác thảo cho Sinh Mã Hướng Thư viện. arXiv preprint arXiv:2206.06888 (2022).
[58] Jie M Zhang, Mark Harman, Lei Ma và Yang Liu. 2020. Kiểm thử học máy: Khảo sát, cảnh quan và chân trời. IEEE Transactions on Software Engineering (2020).
Nhận 20 Tháng 2 2022; sửa đổi 12 Tháng 3 2022; chấp nhận 5 Tháng 6 2022
Bản thảo nộp cho ACM

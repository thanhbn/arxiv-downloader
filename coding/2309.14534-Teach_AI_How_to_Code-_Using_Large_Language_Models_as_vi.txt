# 2309.14534.pdf
# Đã chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/coding/2309.14534.pdf
# Kích thước tệp: 3016417 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Dạy AI Cách Lập Trình: Sử dụng Các Mô hình Ngôn ngữ Lớn làm
Tác nhân Có thể Dạy được cho Giáo dục Lập trình
Hyoungwook Jin
jinhw@kaist.ac.kr
Khoa Tin học, KAIST
Daejeon, Cộng hòa Hàn Quốc

Seonghee Lee
shlee@cs.stanford.edu
Đại học Stanford
Palo Alto, CA, Hoa Kỳ

Hyungyu Shin
hyungyu.sh@kaist.ac.kr
Khoa Tin học, KAIST
Daejeon, Cộng hòa Hàn Quốc

Juho Kim
juhokim@kaist.ac.kr
Khoa Tin học, KAIST
Daejeon, Cộng hòa Hàn Quốc

Hình 1: Tổng quan về các thành phần cốt lõi của AlgoBo và TeachYou. Quy trình Reflect-Respond cho phép AlgoBo tạo ra các phản hồi theo trạng thái kiến thức đang phát triển của nó trong khi Mode-shifting hướng dẫn các cuộc trò chuyện LBT thông qua các câu hỏi xây dựng kiến thức hỏi "tại sao" và "như thế nào". Teaching Helper trong TeachYou phân tích các cuộc trò chuyện theo thời gian thực và đưa ra phản hồi siêu nhận thức và gợi ý về phương pháp giảng dạy.

Quyền tạo bản sao kỹ thuật số hoặc in ấn một phần hoặc toàn bộ tác phẩm này để sử dụng cá nhân hoặc trong lớp học được cấp miễn phí với điều kiện các bản sao không được tạo ra hoặc phân phối vì lợi nhuận hoặc lợi thế thương mại và các bản sao phải mang thông báo này và trích dẫn đầy đủ trên trang đầu tiên. Bản quyền cho các thành phần của bên thứ ba trong tác phẩm này phải được tôn trọng. Đối với tất cả các mục đích sử dụng khác, hãy liên hệ với chủ sở hữu/tác giả.

CHI '24, 11-16 tháng 5, 2024, Honolulu, HI, Hoa Kỳ
©2024 Bản quyền thuộc về chủ sở hữu/tác giả.
ACM ISBN 979-8-4007-0330-0/24/05
https://doi.org/10.1145/3613904.3642349

TÓM TẮT
Nghiên cứu này điều tra các mô hình ngôn ngữ lớn (LLMs) như các tác nhân có thể dạy được cho việc học bằng cách dạy (LBT). LBT với các tác nhân có thể dạy được giúp người học xác định khoảng trống kiến thức và khám phá kiến thức mới. Tuy nhiên, các tác nhân có thể dạy được đòi hỏi việc lập trình kiến thức chuyên môn cụ thể tốn kém. Trong khi LLMs như các tác nhân có thể dạy được có thể giảm chi phí, kiến thức rộng lớn của LLMs như những người được dạy làm nản lòng người học khỏi việc dạy. Chúng tôi đề xuất một quy trình nhắc nhở hạn chế kiến thức của LLMs và khiến chúng khởi xướng các câu hỏi "tại sao" và "như thế nào"

--- TRANG 2 ---
CHI '24, 11-16 tháng 5, 2024, Honolulu, HI, Hoa Kỳ Jin. et al.

để xây dựng kiến thức hiệu quả. Chúng tôi kết hợp những kỹ thuật này vào TeachYou, một môi trường LBT cho việc học thuật toán, và AlgoBo, một chatbot được dạy dựa trên LLM có thể mô phỏng các hiểu lầm và sự thiếu hiểu biết được quy định trong trạng thái kiến thức của nó. Đánh giá kỹ thuật của chúng tôi xác nhận rằng quy trình nhắc nhở của chúng tôi có thể cấu hình hiệu quả hiệu suất giải quyết vấn đề của AlgoBo. Thông qua một nghiên cứu giữa các nhóm chủ thể với 40 người mới bắt đầu về thuật toán, chúng tôi cũng quan sát thấy rằng các câu hỏi của AlgoBo dẫn đến các cuộc trò chuyện dày đặc kiến thức (kích thước hiệu ứng=0.71). Cuối cùng, chúng tôi thảo luận về các hàm ý thiết kế, hiệu quả chi phí và cá nhân hóa của các tác nhân có thể dạy được dựa trên LLM.

CÁC KHÁI NIỆM CCS
•Tính toán tập trung con người →Hệ thống và công cụ tương tác ;•Tính toán ứng dụng →Môi trường học tập tương tác .

TỪ KHÓA
Tương tác người-AI, tác nhân LLM, AI và Giáo dục, AI Tạo sinh

Định dạng Tham chiếu ACM:
Hyoungwook Jin, Seonghee Lee, Hyungyu Shin, và Juho Kim. 2024. Dạy AI Cách Lập Trình: Sử dụng Các Mô hình Ngôn ngữ Lớn làm Tác nhân Có thể Dạy được cho Giáo dục Lập trình. Trong Kỷ yếu Hội nghị CHI về Các Yếu tố Con người trong Hệ thống Tính toán (CHI '24), 11-16 tháng 5, 2024, Honolulu, HI, Hoa Kỳ. ACM, New York, NY, Hoa Kỳ, 28 trang. https://doi.org/10.1145/3613904.3642349

1 GIỚI THIỆU
Các hoạt động học tập tương tác bao gồm việc người học tích cực hợp tác với đồng nghiệp hoặc tham gia với các hệ thống máy tính để làm sâu sắc thêm sự hiểu biết của họ về một chủ đề cụ thể [ 54,87]. So với các hoạt động học tập thụ động (ví dụ: đọc các đoạn văn bản mà không làm gì khác), các hoạt động học tập tương tác (ví dụ: lập trình cặp, dạy đồng nghiệp) có thể gợi ra mức độ hiểu biết sâu sắc nhất bằng cách khuyến khích người học đi sâu vào các giải thích của họ và xây dựng kiến thức mới trên cơ sở lẫn nhau thông qua các cuộc trò chuyện [ 15,17,18,26,82,83]. Một hình thức học tập tương tác là Học bằng cách Dạy (LBT), trong đó người học dạy kèm một đồng nghiệp học tập và trao đổi câu hỏi để tổ chức lại kiến thức của họ và xác định khoảng trống kiến thức.

LBT với các tác nhân AI có thể dạy được (tức là những người được dạy ảo) có thể mang lại nhiều lợi thế hơn LBT với con người. Các tác nhân có thể dạy được có thể mang lại khả năng mở rộng cho LBT với tính sẵn có suốt ngày đêm và thúc đẩy sự tham gia của người học vào LBT bằng cách giảm các rào cản tâm lý, chẳng hạn như nỗi sợ mắc lỗi khi dạy và áp lực phải trả lời trong thời gian thực [ 13,20]. Tuy nhiên, bất chấp những lợi ích này, việc phổ biến các tác nhân có thể dạy được cho các môn học đa dạng là thách thức trong thực tế do việc tạo ra mô hình kiến thức của các tác nhân [ 48] và các hành vi phức tạp [ 78] tốn nhiều công sức để gợi ra những trải nghiệm học tập mong muốn vượt ra ngoài một mô phỏng dạy kèm. Các phương pháp tạo ra thông thường đòi hỏi việc ánh xạ rộng rãi các trạng thái kiến thức của tác nhân và kỹ năng lập trình cao, ngăn cản các giáo viên và nhà nghiên cứu giáo dục điều chỉnh các tác nhân có thể dạy được cho nhu cầu và bối cảnh của họ.

Trong bài báo này, thay vì xây dựng các tác nhân có thể dạy được từ đầu, chúng tôi đề xuất một phương pháp từ trên xuống trong đó chúng tôi sử dụng các Mô hình Ngôn ngữ Lớn (LLMs) đa năng để mô phỏng những người được dạy. Những tiến bộ gần đây trong LLMs cho thấy khả năng đáng chú ý của chúng trong việc tạo ra các cuộc đối thoại theo ngữ cảnh [ 63,74], bắt chước vai trò [ 37,46], và học từ các minh họa [ 12,68]. Các tác nhân có thể dạy được được trang bị khả năng LLM có thể thực hiện các tương tác dạy kèm đáng tin cậy và tự nhiên hơn (ví dụ: viết và giải thích mã tùy ý theo yêu cầu), so với các hệ thống LBT không dựa trên LLM trước đây đã áp dụng các kênh tương tác có kịch bản sẵn và hạn chế [ 7,41,51,65]. Tương tác linh hoạt cho phép người học tạo ra các câu hỏi tự do và thử các phương pháp dạy học đa dạng, cải thiện việc xây dựng kiến thức và siêu nhận thức của họ [ 2,16,75,96]. Chúng tôi khám phá việc sử dụng LLMs để giảm chi phí và rào cản xây dựng các tác nhân có thể dạy được và làm cho LBT hấp dẫn hơn và hiệu quả về mặt sư phạm.

Trong nghiên cứu hình thành của chúng tôi, chúng tôi yêu cầu 15 người mới bắt đầu lập trình tiến hành LBT với ChatGPT được nhắc nhở để thực hiện vai trò của một người được dạy. Chúng tôi thấy rằng có nhu cầu về 1) giới hạn mức độ kiến thức của các tác nhân LLM, 2) các câu hỏi "tại sao" và "như thế nào" do tác nhân khởi xướng, và 3) phản hồi trong cuộc trò chuyện về phương pháp dạy học của người học. Phân tích đối thoại của chúng tôi tiết lộ rằng việc đóng vai dẫn người học đến tự giải thích kiến thức của họ nhưng bị hạn chế ở việc kể kiến thức, chỉ đạt được những lợi ích sơ bộ của việc thực hiện LBT. Các tham gia viên gặp khó khăn trong việc xây dựng kiến thức mới vì tác nhân có thể dạy được xuất sắc trong việc viết mã ngay cả khi không được dạy và không đặt câu hỏi có thể thúc đẩy sự phát triển và xây dựng kiến thức.

Để giải quyết những vấn đề này, chúng tôi xây dựng một tác nhân có thể dạy được, "AlgoBo", có thể thể hiện các hiểu lầm và mức độ kiến thức được quy định và "TeachYou", một môi trường LBT cho việc học thuật toán giới thiệu (Hình 1). Trong TeachYou, người học giải quyết các vấn đề lập trình về thuật toán (ví dụ: tìm kiếm nhị phân) và phản ánh về chúng bằng cách dạy AlgoBo. Khi người học dạy AlgoBo một cách chính xác, quy trình nhắc nhở Reflect-Respond của chúng tôi hướng dẫn AlgoBo sửa chữa các hiểu lầm của nó và viết mã dựa trên những gì nó được dạy. Chúng tôi cũng thêm Mode-shifting, trong đó AlgoBo định kỳ chuyển sang chế độ đặt câu hỏi và đặt câu hỏi để thúc đẩy sự phát triển và tạo ý nghĩa của người học. Cuối cùng, TeachYou có Teaching Helper cung cấp phản hồi siêu nhận thức và gợi ý cho người học về phương pháp dạy học của họ trong thời gian thực thông qua phân tích đối thoại.

Chúng tôi tiến hành đánh giá kỹ thuật về quy trình nhắc nhở Reflect-Respond của chúng tôi để kiểm tra xem AlgoBo có thể mô phỏng một người được dạy với mức độ kiến thức được quy định về các chủ đề thuật toán khác nhau hay không. Chúng tôi thấy rằng quy trình có thể cấu hình, duy trì và thích ứng hiệu quả mức độ kiến thức của AlgoBo trong một cuộc trò chuyện. Chúng tôi cũng tiến hành một nghiên cứu giữa các nhóm chủ thể với 40 người mới bắt đầu về thuật toán, trong đó các tham gia viên nghiên cứu tìm kiếm nhị phân với TeachYou hoặc một hệ thống cơ sở không có Mode-shifting và Teaching Helper. Phân tích các đối thoại LBT và kết quả khảo sát của chúng tôi cho thấy Mode-shifting cải thiện mật độ của các thông điệp xây dựng kiến thức trong các cuộc trò chuyện một cách đáng kể ( 𝑝=0.03) với kích thước hiệu ứng (Cohen's d) là 0.71. Teaching Helper cũng giúp các tham gia viên phản ánh về phương pháp dạy học của họ và sắp xếp trình tự câu hỏi một cách chiến lược, nhưng chúng tôi không thể quan sát sự cải thiện đáng kể trong siêu nhận thức của các tham gia viên.

Chúng tôi cấu trúc bài báo của mình theo thứ tự sau. Sau một cuộc thảo luận về công trình liên quan, chúng tôi mô tả cài đặt nghiên cứu hình thành và những phát hiện sơ bộ. Sau đó chúng tôi tổ chức lại những phát hiện thành ba mục tiêu thiết kế và giới thiệu hệ thống và quy trình của chúng tôi để đạt được

--- TRANG 3 ---
Dạy AI Cách Lập Trình: Sử dụng LLMs làm Tác nhân Có thể Dạy được cho Giáo dục Lập trình CHI '24, 11-16 tháng 5, 2024, Honolulu, HI, Hoa Kỳ

các mục tiêu. Với điều đó, chúng tôi trình bày các kết quả đánh giá kỹ thuật và nghiên cứu người dùng của chúng tôi. Cuối cùng, dựa trên kết quả và quan sát của chúng tôi, chúng tôi thảo luận về các cân nhắc thiết kế cho các tác nhân có thể dạy được, lợi ích của việc sử dụng LLMs, các hướng đầy hứa hẹn để cá nhân hóa các tác nhân có thể dạy được, và hướng dẫn tương tác cho LBT tốt hơn với các tác nhân có thể dạy được.

Bài báo này đóng góp như sau:
•AlgoBo, một tác nhân có thể dạy được dựa trên LLM sử dụng quy trình nhắc nhở Reflect-Respond để mô phỏng các hành vi học tập được quy định và Mode-shifting để hỗ trợ xây dựng kiến thức của người học thông qua các câu hỏi "tại sao" và "như thế nào".
•TeachYou, một hệ thống học thuật toán dựa trên web hỗ trợ LBT với AlgoBo và cung cấp phản hồi siêu nhận thức về việc dạy học dựa trên phân tích cuộc trò chuyện thời gian thực.
•Một đánh giá kỹ thuật về quy trình nhắc nhở Reflect-Respond và kết quả nghiên cứu thực nghiệm với 40 tham gia viên cho thấy TeachYou cải thiện việc xây dựng kiến thức trong LBT.

2 CÔNG TRÌNH LIÊN QUAN
Chúng tôi phác thảo các nghiên cứu trước đây về việc kích thích LBT hiệu quả giữa con người và sử dụng các tác nhân có thể dạy được. Nghiên cứu trước đây kết nối với công việc của chúng tôi trong việc cải thiện chất lượng và khả năng mở rộng của LBT bằng cách sử dụng các tác nhân ảo.

2.1 Học bằng cách Dạy
Học bằng cách Dạy (LBT) là một phương pháp giảng dạy trong đó người học không chỉ diễn đạt và tái cấu trúc kiến thức hiện có của họ mà còn tham gia vào việc xây dựng kiến thức phản ánh. Xây dựng kiến thức đề cập đến việc mở rộng kiến thức vượt ra ngoài các tài liệu được cung cấp để tạo ra các giải thích sâu sắc hơn, phép so sánh và kết nối suy luận [ 13,15,22,71], dẫn đến việc tạo ra và cải thiện có chủ ý kiến thức hữu ích cho một cộng đồng trong bối cảnh rộng lớn hơn [ 77]. Tuy nhiên, LBT một mình không gợi ra việc xây dựng kiến thức một cách tự nhiên [ 67,91]; người học có xu hướng kết thúc trong việc kể kiến thức, trong đó họ diễn đạt những gì họ đã biết [ 71]. Nghiên cứu trước đây đã điều tra hỗ trợ cho việc gợi ra các phản hồi xây dựng kiến thức từ người học. King et al. thấy rằng việc đào tạo người học đặt câu hỏi xem xét, chứng minh và suy nghĩ theo trình tự cho đồng nghiệp trong LBT có thể thúc đẩy tư duy và học tập bậc cao [ 36]. Phân tích các đối thoại LBT của Roscoe và Chi cho thấy tầm quan trọng của vai trò của người được dạy trong xây dựng kiến thức; các câu hỏi sâu sắc từ người được dạy khuyến khích các gia sư đưa ra các phản hồi tự phản ánh và tạo ra các suy luận giữa kiến thức mới và trước đó [ 72]. Shahriar và Matsuda cũng xác nhận rằng các câu hỏi theo dõi của người được dạy đã thu hút việc xây dựng kiến thức của các gia sư với kiến thức trước đó thấp nói riêng [78]. Matsuda et al. thấy rằng LBT với hướng dẫn siêu nhận thức để lập kế hoạch và tiến hành giảng dạy có hiệu quả như được dạy kèm bởi các chuyên gia bất kể năng lực trước đó của người học [ 52]. Mục tiêu chính của chúng tôi là xây dựng một hệ thống tương tác thu hút việc xây dựng kiến thức từ người học trong LBT. Để làm điều đó, chúng tôi thích ứng các can thiệp được đề cập ở trên trong các tương tác gia sư-người được dạy của con người với các tương tác đối thoại giữa các tác nhân ảo và người học.

2.2 Các Tác nhân Có thể Dạy được cho LBT
Một thành phần cốt lõi của LBT là sự hiện diện của một người học đồng nghiệp. Tuy nhiên, vì người học con người không thể luôn hiện diện, nghiên cứu trước đây đã giới thiệu các tác nhân có thể dạy được—các tác nhân ảo có thể học kiến thức khai báo và thủ tục từ các giải thích và minh họa của người học, đóng vai trò của những người học đồng nghiệp trong LBT [ 9]. Các tác nhân có thể dạy được cho thấy kết quả đầy hứa hẹn trong việc cải thiện hiệu suất, tự giải thích và chấp nhận phản hồi xây dựng của học sinh [ 13,25,41,53,81]. LBT với các tác nhân có thể dạy được ban đầu không có tính chất đối thoại; các tác nhân tiết lộ trạng thái kiến thức của họ dưới dạng bản đồ khái niệm, và người học dạy các tác nhân bằng cách chỉnh sửa trực tiếp trạng thái kiến thức của họ [ 8,11]. Các tác nhân có thể dạy được gần đây che giấu trạng thái của họ và mô phỏng các hành vi học tập chân thực hơn; các tác nhân có thể học từ các minh họa của gia sư [ 47], bắt chước các hành vi của người học (ví dụ: mắc lỗi số học) [ 32,65], cải thiện với các hướng dẫn chính xác [ 53], và đặt câu hỏi [ 50]. Tuy nhiên, việc triển khai các tác nhân có thể dạy được tự nhiên và có tính tương tác cao này đòi hỏi nỗ lực thủ công đáng kể và kỹ năng lập trình để chỉ định và mô hình hóa kiến thức của các tác nhân [ 49]. Ví dụ, việc triển khai một tác nhân trong SimStudent đòi hỏi hơn một nghìn dòng mã Java cho việc giải phương trình đại số đơn giản [ 47]; chi phí có thể tăng theo cấp số nhân cho các chủ đề phức tạp hơn (ví dụ: học thuật toán, giải phương trình nâng cao). Trong bài báo này, chúng tôi điều tra việc sử dụng LLMs để xây dựng các tác nhân có thể dạy được đối thoại với nỗ lực thủ công thấp và rào cản lập trình để hỗ trợ các nhà giáo dục và nhà nghiên cứu trong việc áp dụng LBT trong các lớp học và thí nghiệm đa dạng.

2.3 Mô phỏng Dạy kèm được Hỗ trợ bởi LLM
Trong khi chi phí phát triển và rào cản kỹ năng đã hạn chế các tác nhân có thể dạy được vào một số hoạt động học tập trong quá khứ, LLMs có thể cung cấp một phương pháp giá cả phải chăng hơn để mô phỏng học sinh ảo và huấn luyện viên và đa dạng hóa các tương tác của họ [ 46,60,90]. GPTeach của Markel et al. [ 46] mô phỏng các cuộc đóng vai giữa một thực tập sinh giảng dạy và học sinh ảo đến tham gia giờ văn phòng bằng cách tận dụng cài đặt nhân vật và ngữ cảnh trong các lời nhắc. Học sinh được mô phỏng bởi LLM cho phép các thực tập sinh thực hành giảng dạy với nhiều học sinh đa dạng và tương tác thông qua các cuộc trò chuyện, có lẽ là hình thức quen thuộc và mở nhất của việc dạy người khác. Tương tự, các tác nhân có thể dạy được dựa trên LLM có thể làm phong phú tương tác và hoạt động gia sư-người được dạy trong LBT khi người học có thể tạo ra các câu hỏi tự do bằng chính họ và thử các chiến lược dạy học khác nhau, trái ngược với các hệ thống LBT không dựa trên LLM chỉ cho phép các phương pháp được xác định trước để đánh giá kiến thức của tác nhân (ví dụ: câu hỏi trắc nghiệm) [ 7,41,52,65]. Tuy nhiên, vẫn còn những thách thức trong việc làm cho các tác nhân dựa trên LLM này phù hợp với LBT, nơi các tác nhân không chỉ nên mô phỏng dạy kèm mà còn chủ động gợi ra việc xây dựng kiến thức của người học. Ngoài các vai trò được thiết lập bởi các lời nhắc, chúng ta cần kiểm soát chính xác các hành vi nhận thức của các tác nhân có thể dạy được (ví dụ: mức độ kiến thức và đặt câu hỏi) để tạo điều kiện cho trải nghiệm học tập dự định. Nghiên cứu trước đây đã đề xuất các kiến trúc tác nhân LLM và quy trình để cấp và phạm vi các khả năng nhận thức cho LLM, chẳng hạn như bộ nhớ [ 64,98], đóng vai [ 30,66], và lý luận [ 14,33,43]. Chúng tôi mở rộng kiểm soát về các khả năng nhận thức của LLMs bằng cách đề xuất một quy trình nhắc nhở LLM hạn chế mức độ kiến thức của các tác nhân dựa trên LLM.

3 NGHIÊN CỨU HÌNH THÀNH
Chúng tôi đã tiến hành một nghiên cứu hình thành để khám phá những khó khăn của việc sử dụng một LLM như một tác nhân có thể dạy được. Chúng tôi đã tuyển dụng 15 người mới bắt đầu Python và yêu cầu họ dạy thuật toán tìm kiếm nhị phân cho một chatbot LLM. Chúng tôi

--- TRANG 4 ---
CHI '24, 11-16 tháng 5, 2024, Honolulu, HI, Hoa Kỳ Jin. et al.

khảo sát trải nghiệm học tập của họ và phân tích chất lượng các đối thoại của họ với chatbot bằng cách chú thích các loại thông điệp.

3.1 Tham gia viên và Quy trình
Chúng tôi tuyển dụ 15 tham gia viên trong khuôn viên có thể đọc và viết các chương trình Python ngắn (khoảng 15 dòng) chứa các câu lệnh cơ bản như if và while và không quen thuộc với tìm kiếm nhị phân và LBT. Mười một người đến từ các khoa kỹ thuật không phải CS.

Nghiên cứu bao gồm ba giai đoạn. Trong giai đoạn đầu tiên, các tham gia viên đi qua tài liệu học tập về tìm kiếm nhị phân từ Khan Academy1 và giải quyết hai bài toán Parsons, một bài tập mã hóa về sắp xếp lại các đoạn mã [ 21]. Trong giai đoạn thứ hai, các tham gia viên nhận được giới thiệu về các khái niệm của LBT, lợi ích học tập dự kiến và quy trình của nó. Sau đó, họ được cung cấp một cái nhìn tổng quan ngắn gọn về hoạt động LBT mà họ sẽ thực hiện tiếp theo. Trong giai đoạn cuối cùng, người học dạy kèm chatbot về cách viết mã cho hai bài toán tìm kiếm nhị phân từ giai đoạn trước. Sau hoạt động LBT, các tham gia viên hoàn thành một cuộc khảo sát kết thúc bao gồm các câu hỏi về ba chủ đề: nhận thức về chatbot như một người học, các hiệu ứng học tập tự nhận thức, và sự quen thuộc với việc dạy một chatbot.

Các tham gia viên tương tác với một chatbot LLM cơ sở, AlgoBo, thực hiện vai trò của một tác nhân có thể dạy được. Chúng tôi sử dụng GPT-4 [ 62] làm xương sống cho AlgoBo và cung cấp một lời nhắc hệ thống (xem Phụ lục A.1) thiết lập nhân vật của một học sinh và thêm các thách thức học tập được xác định trước mà nó đang gặp phải để cung cấp một tác nhân có thể dạy được thuyết phục hơn [ 46,66]. Vì chúng tôi sử dụng lại tên "AlgoBo" trong hệ thống chính và đánh giá của mình, chúng tôi sử dụng "AlgoBo-Basic" trong suốt phần này để phân biệt hai tác nhân có thể dạy được mà chúng tôi đã phát triển.

3.2 Phân tích Đối thoại
Ngoài các bình luận từ cuộc khảo sát kết thúc, chúng tôi cũng xem xét chất lượng và các mẫu đối thoại của các cuộc đối thoại giữa tham gia viên và AlgoBo-Basic bằng cách phân loại thông điệp thành các loại kể kiến thức và xây dựng kiến thức.

Vì các phân loại trước đây phân loại các đối thoại LBT [ 36,71,89] không được bối cảnh hóa đủ cho việc dạy kèm lập trình, chúng tôi quyết định thích ứng các phân loại và tạo một phân loại mới (Bảng 1) cụ thể cho LBT trong lập trình. Chúng tôi tạo tập hợp ban đầu các loại thông điệp dựa trên các phân loại trước đây cho các đối thoại LBT chung [ 36,71,89] và phân loại các câu hỏi và đáp án lập trình [ 3,39]. Ba tác giả thực hiện ba lần lặp để chú thích đối thoại, giải quyết xung đột và tinh chỉnh phân loại [ 69,94]. Các tác giả hoàn thiện phân loại trong lần lặp thứ 2 (20 đối thoại, 293 thông điệp). Các tác giả phân loại phần còn lại của các thông điệp một cách độc lập. Độ tin cậy giữa các người đánh giá của việc phân loại cao; ba tác giả đạt được alpha của Krippendorff là 0.731 cho dữ liệu trong lần lặp cuối cùng (11 đối thoại, 253 thông điệp).

Phân loại của chúng tôi có ba danh mục chính: hướng dẫn, thúc đẩy và tuyên bố (xem Bảng 1). Thông điệp hướng dẫn có nội dung yêu cầu đối thủ (thường là người được dạy) thực hiện các hành động cụ thể, chẳng hạn như sửa mã và thử giải quyết vấn đề sau khi hiểu khái niệm. Thông điệp hướng dẫn chủ yếu liên quan đến việc tiến hành các bước trong giảng dạy. Thông điệp thúc đẩy có ý định gợi ra các hành động cụ thể từ đối thủ. Chúng bao gồm việc hỏi người được dạy về một khái niệm cụ thể quan tâm, đưa ra các câu hỏi kích thích tư duy để khuyến khích xây dựng kiến thức, và yêu cầu gia sư giúp đỡ. Chúng tôi chỉ định Prompting-Thought-provoking cho xây dựng kiến thức vì những câu hỏi như vậy có thể báo hiệu việc xây dựng kiến thức hợp tác nơi người học đưa ra các câu hỏi khám phá và bắt đầu các cuộc thảo luận xây dựng kiến thức với các tác nhân. Thông điệp tuyên bố là những phát biểu giải thích kiến thức và ý kiến của một người. Trong số đó, Statement-Elaboration và Statement-Sense-making là xây dựng kiến thức vì chúng là sản phẩm của kiến thức mới; điều này tương ứng với phân loại hoạt động xây dựng kiến thức của Roscoe và Chi [73].

3.3 Những Phát hiện từ Bình luận của Tham gia viên và Phân tích Đối thoại
Chúng tôi thấy rằng một chatbot LLM có thể phục vụ như một tác nhân có thể dạy được cho LBT sơ bộ. Các tham gia viên tích cực về việc dạy một chatbot LLM và cảm thấy nó giúp họ tổ chức lại và nhớ lại kiến thức của họ. Tuy nhiên, phân tích đối thoại và phản hồi khảo sát sâu của chúng tôi tiết lộ rằng chatbot LLM thiếu sót trong việc hỗ trợ đầy đủ quá trình xây dựng kiến thức của người học.

AlgoBo-Basic được nhận thức như một người học quá có năng lực do kiến thức trước rộng lớn và hành vi tự sửa chữa. Các tham gia viên đánh giá cao khả năng của AlgoBo-Basic "nói như một người thật và đặt các câu hỏi cụ thể" (P14) để mô phỏng một người học. Tuy nhiên, hai phần ba tham gia viên bình luận rằng họ trải nghiệm sự khó chịu do năng lực của AlgoBo-Basic. AlgoBo-Basic ban đầu bắt đầu cuộc trò chuyện bằng cách yêu cầu giúp đỡ. Tuy nhiên, sau một vài cuộc trò chuyện, AlgoBo-Basic cung cấp các phản hồi có năng lực quá nhanh, điều này không phản ánh quá trình học tập của một người học mới bắt đầu. P5 nhận xét, "Tôi giải thích nó rất đơn giản, nhưng anh ấy hiểu nó rất tốt... Anh ấy thông minh hơn tôi rất nhiều. Anh ấy dường như tự điền vào kiến thức thậm chí tôi không chắc chắn về." Sự thành thạo của AlgoBo-Basic trong việc viết và giải thích mã cũng hạn chế các mẫu đối thoại và khiến người học bối rối về vai trò của họ. AlgoBo-Basic đưa ra các tuyên bố kiến thức (tức là Statement-Comprehension) gấp đôi so với các tham gia viên, lấy đi cơ hội để người học tự giải thích và dạy (xem hàng Statement-Comprehension trong Bảng 2). P7 tuyên bố, "AlgoBo-Basic giống như một trợ lý giảng dạy kiểm tra khả năng của học sinh, thay vì một học sinh đang gặp khó khăn với các bài toán tìm kiếm nhị phân." Các tham gia viên phản hồi rằng họ muốn thấy nhiều tương tác giống học sinh hơn từ AlgoBo-Basic như "đặt các câu hỏi chủ động hơn" (P1) và "mắc lỗi và yêu cầu gia sư đưa ra giải thích chi tiết" (P5).

Các đối thoại giữa gia sư và AlgoBo-Basic bị hạn chế chỉ ở việc kể kiến thức. Các tham gia viên đánh giá việc kể lại kiến thức của họ—"Viết ra kiến thức rất hữu ích trong việc tổ chức kiến thức. Nếu bạn muốn dạy ai đó, bạn nên tạo các bước trong đầu bạn, và quá trình này đã giúp rất nhiều" (P1). Tuy nhiên, việc học của họ bị hạn chế ở việc kể kiến thức; trong số 546 thông điệp, chúng tôi có thể quan sát 244 thông điệp kể kiến thức nhưng chỉ

--- TRANG 5 ---
Dạy AI Cách Lập Trình: Sử dụng LLMs làm Tác nhân Có thể Dạy được cho Giáo dục Lập trình CHI '24, 11-16 tháng 5, 2024, Honolulu, HI, Hoa Kỳ

Bảng 1: Phân loại của chúng tôi để phân loại loại thông điệp trong các cuộc trò chuyện LBT với một tác nhân có thể dạy được. Các văn bản in đậm trong cột ví dụ là các ví dụ của các loại thông điệp tương ứng. Các loại có * là phản hồi kể kiến thức. Các loại có ** thuộc về phản hồi xây dựng kiến thức.

| Danh mục | Danh mục Con | Giải thích | Ví dụ |
|----------|--------------|------------|--------|
| Hướng dẫn | Sửa chữa* | [Hướng dẫn] sửa kiến thức cụ thể hoặc phần của mã. | Người được dạy: Đây là mã của tôi: <code> Gia sư: **Gọi hàm input() hai lần để N và K được nhập riêng biệt.** |
| | Chỉ huy | ["] thực hiện các hành động đơn giản không liên quan đến học tập. (ví dụ: đơn giản kết hợp mã để nộp bài). | Người được dạy: Tôi đã viết hàm tìm kiếm nhị phân. Gia sư: **Bây giờ, viết toàn bộ mã Python.** |
| | Khuyến khích | ["] thử lại một hành động trước đó với sự khuyến khích về mặt cảm xúc. | Gia sư: **Bạn đang đi đúng hướng. Tiếp tục viết thêm mã.** |
| Thúc đẩy | Tìm thách thức | [Thúc đẩy đối thủ] giải thích những khó khăn của anh ấy để tìm những phần cần giúp đỡ. | Gia sư: **Bạn đang gặp khó khăn ở phần nào?** Người được dạy: Tôi đang gặp khó khăn với việc viết các điều kiện bên trong vòng lặp while. |
| | Gợi ý* | ["] suy nghĩ về các cách tiếp cận thay thế/cụ thể. | Người được dạy: Tôi không thể hoàn thành phần này của mã. Gia sư: **Chà, bạn đã xem xét trường hợp khi số đó bằng K chưa?** |
| | Kiểm tra | ["] hiển thị hoặc tự giải thích sự hiểu biết của anh ấy về kiến thức cụ thể. | Gia sư: **Bạn có biết tìm kiếm nhị phân là gì không?** Người được dạy: Có! Tìm kiếm nhị phân là . . . |
| | Kích thích tư duy** | ["] phát triển các giải thích trước đó hoặc suy nghĩ vượt ra ngoài nội dung của tài liệu học tập đã cho. | Gia sư: **Điều gì sẽ xảy ra nếu chúng ta chuyển đổi mã cập nhật min / max?** Người được dạy: Tôi chưa nghĩ về điều đó. Vòng lặp có chạy mãi mãi không? |
| | Yêu cầu giúp đỡ | ["] phân tích vấn đề của người nói hoặc đưa ra gợi ý. | Người được dạy: **Bạn có thể giúp tôi giải quyết vấn đề này được không?** |
| Tuyên bố | Hiểu biết* | [Tuyên bố kiến thức hoặc ý kiến của một người bằng cách] diễn giải / sao chép / giải thích tài liệu học tập hoặc phản hồi của đối thủ. | Gia sư: **Đầu tiên, hãy định nghĩa hàm được gọi là binary_search. Trong vòng lặp while, ...** |
| | Phát triển** | ["] cung cấp làm rõ mở rộng hoặc các ví dụ liên quan vượt ra ngoài tài liệu đã cho. | Người được dạy: Bạn có thể nghĩ về một ví dụ thực tế mà chúng ta có thể sử dụng tìm kiếm nhị phân? Gia sư: **Tôi nghĩ chúng ta có thể sử dụng nó để tìm một từ trong từ điển nơi các từ được liệt kê theo thứ tự bảng chữ cái.** |
| | Tạo ý nghĩa** | ["] nhận ra lỗi / hiểu lầm của bản thân hoặc tạo ra các suy luận / kết nối mới với kiến thức trước đó. | Gia sư: Bạn có thể xem xét kỹ hơn câu lệnh else trong mã của bạn? Người được dạy: **Ah, tôi hiểu rồi. Hãy sửa đổi giá trị high thành mid. Đây là mã đã sửa.** |
| | Chấp nhận / Từ chối | ["] đồng ý hoặc không đồng ý với phản hồi của đối thủ. | Gia sư: Bạn nên cập nhật dòng 24 thành . . . Người được dạy: **Tôi nghĩ đó là một ý tưởng hay.** |
| | Phản hồi | ["] phản hồi với hành động hoặc suy nghĩ của đối thủ. | Gia sư: **Vâng, đó chính xác là đúng.** |
| Khác | | Lời chào/tạm biệt, biểu hiện xã hội | Gia sư: Bạn có câu hỏi gì không? Người được dạy: **Không, cảm ơn bạn rất nhiều vì sự hướng dẫn của bạn cho đến nay!** |

--- TRANG 6 ---
CHI '24, 11-16 tháng 5, 2024, Honolulu, HI, Hoa Kỳ Jin. et al.

15 phát biểu xây dựng kiến thức (Bảng 2). Bất chấp việc giúp tổ chức lại kiến thức, các tự giải thích không dẫn đến việc xây dựng kiến thức mới vượt ra ngoài những gì họ đã biết trước đó—"Tôi không khám phá ra điều gì mới vì tôi giải thích những gì tôi đã học" (P4). Hơn nữa, các tự giải thích của gia sư thường không được phát triển vì AlgoBo-Basic không đặt câu hỏi về các giải thích mơ hồ của tham gia viên, và AlgoBo-Basic hoạt động tốt. Ví dụ, P15 trả lời câu hỏi của AlgoBo-Basic về lý do tại sao mảng đầu vào cần được sắp xếp: "Mảng được sắp xếp giảm số lượng tính toán và tối đa hóa hiệu quả của tìm kiếm nhị phân." Bất chấp việc thiếu lý luận chi tiết (ví dụ: "như thế nào" và "tại sao"), AlgoBo-Basic chấp nhận giải thích và chuyển sang câu hỏi tiếp theo.

Bảng 2: Phân bố các danh mục thông điệp cho 31 đối thoại từ nghiên cứu hình thành. Các loại có ∗ là thông điệp kể kiến thức. Các loại có ∗∗ thuộc về thông điệp xây dựng kiến thức.

| Danh mục | Danh mục Con | Người được dạy | Gia sư | Tổng |
|----------|--------------|----------------|--------|------|
| Hướng dẫn | Sửa chữa* | 0 | 37 | 37 |
| | Chỉ huy | 0 | 65 | 65 |
| | Khuyến khích | 0 | 1 | 1 |
| Thúc đẩy | Tìm thách thức | 0 | 18 | 18 |
| | Gợi ý* | 1 | 12 | 13 |
| | Kiểm tra | 1 | 31 | 32 |
| | Kích thích tư duy** | 0 | 1 | 1 |
| | Yêu cầu giúp đỡ | 91 | 0 | 91 |
| Tuyên bố | Hiểu biết* | 133 | 61 | 194 |
| | Phát triển** | 0 | 1 | 1 |
| | Tạo ý nghĩa** | 12 | 1 | 13 |
| | Chấp nhận | 35 | 4 | 39 |
| | Phản hồi | 0 | 17 | 17 |
| Khác | | 19 | 5 | 24 |
| | Tổng | 292 | 254 | 546 |
| | Kể kiến thức | 134 | 110 | 244 |
| | Xây dựng kiến thức | 12 | 3 | 15 |

Các tham gia viên thực hiện các mẫu phản LBT và tìm kiếm phản hồi. Các tham gia viên nhận xét việc dạy kèm thông qua giao tiếp ngôn ngữ tự nhiên là trực quan và quen thuộc vì nó giống với việc dạy kèm con người, và họ có thể áp dụng các phương pháp dạy học tương tự cho AlgoBo-Basic. Tuy nhiên, một số tham gia viên muốn thấy các phương pháp tốt hơn để họ dạy AlgoBo-Basic (P9) và một phương pháp để xem xét quá trình học tập của họ (P15). P15 nói, "Tôi có thể thấy rằng kỹ năng dạy học của tôi có hiệu quả, nhưng sự phản ánh [về phiên dạy kèm của tôi] để lại nhiều điều mong muốn do thiếu phản hồi về phương pháp dạy học của tôi" (P15). Trong khi phân tích các đối thoại của tham gia viên, chúng tôi thấy các mẫu đối thoại phản thông thường có thể hạn chế lợi ích của LBT. Mẫu đầu tiên là Chỉ huy, trong đó các tham gia viên lặp đi lặp lại đưa ra hướng dẫn cụ thể cho AlgoBo-Basic để viết và sửa mã (Phụ lục B (A)). Mẫu này thiếu giải thích về "tại sao" và "như thế nào" có thể thúc đẩy người học vượt ra ngoài việc nhớ lại sự thật (tức là kể kiến thức). Mẫu thứ hai là Cho ăn bằng thìa, trong đó các tham gia viên đưa ra kiến thức mà không có câu hỏi để kiểm tra hoặc thúc đẩy sự hiểu biết của người được dạy (Phụ lục B (B)). Thay vì các giải thích thụ động, người học có thể chủ động xây dựng kiến thức mới bằng cách đặt câu hỏi tư duy cho những người được dạy của họ, tận dụng lợi ích của việc có các tác nhân tương tác. Mẫu cuối cùng là Dạy thiếu, trong đó AlgoBo-Basic tiến bộ trong việc giải quyết vấn đề nhưng chỉ kể kiến thức vì người học không cố gắng dạy và phát triển kiến thức thêm. (Phụ lục B (C)).

4 MỤC TIÊU THIẾT KẾ
Những phát hiện từ nghiên cứu hình thành của chúng tôi cho thấy LLMs có thể phục vụ như một tác nhân có thể dạy được sơ bộ cho LBT. Tuy nhiên, chúng tôi cũng xác nhận nhu cầu cải thiện khả năng bắt chước của chatbot LLM đối với những người được dạy tìm kiếm giúp đỡ, thúc đẩy việc xây dựng kiến thức của người học, và hỗ trợ siêu nhận thức của người học trong giảng dạy. Dựa trên những hiểu biết, chúng tôi đặt ra ba mục tiêu thiết kế.

D1. Thiết kế các tác nhân có thể dạy được có thể mô phỏng các hiểu lầm và đường cong học tập dần dần. Chúng tôi thấy rằng kiến thức được đào tạo trước và hành vi tự sửa chữa của LLMs làm cho AlgoBo cảm thấy ít giống một người được dạy hơn và ngăn cản các gia sư học bằng cách xác định lỗi của người được dạy và khai sáng họ với các giải thích chi tiết [ 89]. Để giảm năng lực không mong muốn, chúng ta cần kiểm soát kiến thức trước của LLMs và làm cho chúng hiển thị hiểu lầm và thiếu hiểu biết liên tục trong các phản hồi của họ cho đến khi họ nhận được hỗ trợ sư phạm.

D2. Phát triển các cuộc trò chuyện thông qua các câu hỏi phát triển của các tác nhân có thể dạy được. AlgoBo hiếm khi đặt các câu hỏi theo dõi hoặc kích thích tư duy (Bảng 2) có thể gợi ra việc xây dựng kiến thức của người học thông qua phát triển và tạo ý nghĩa [ 36,78]. Thay vì giữ AlgoBo như một người được dạy thụ động trong suốt cuộc trò chuyện, việc chuyển AlgoBo thành một người đặt câu hỏi tích cực có thể hỗ trợ người học xây dựng kiến thức từng bước. Ví dụ, AlgoBo có thể bắt đầu như một người được dạy tìm kiếm giúp đỡ yêu cầu người học tự giải thích các khái niệm cơ bản, và nó có thể chuyển thành một người đặt câu hỏi Socratic kích thích tư duy thỉnh thoảng.

D3. Cung cấp cho người học phản hồi siêu nhận thức về phương pháp dạy học của họ trong một cuộc trò chuyện. Bên cạnh việc hỗ trợ từ phía người được dạy, người học có thể tích cực cải thiện chất lượng LBT của họ bằng cách dẫn dắt việc dạy kèm xây dựng và kiềm chế ba mẫu phản. Trong nghiên cứu hình thành của chúng tôi, tuy nhiên, các tham gia viên thấy thiếu hướng dẫn và phản ánh về kỹ thuật dạy học của họ. Phản hồi siêu nhận thức về việc dạy học trong LBT có thể giúp người học nhận ra cách cải thiện phương pháp dạy học của họ ngay tại chỗ và tinh chỉnh các cuộc trò chuyện trong suốt.

5 HỆ THỐNG
Chúng tôi trình bày TeachYou, một hệ thống LBT có AlgoBo, một tác nhân có thể dạy được dựa trên LLM. AlgoBo nhận được sự giúp đỡ từ người học để giải quyết các bài toán thuật toán giới thiệu trong khi đặt các câu hỏi kích thích tư duy khuyến khích người học mở rộng kiến thức của họ vượt ra ngoài mức độ hiện tại. Thông qua hệ thống, chúng tôi đề xuất 1) một quy trình nhắc nhở LLM mới để mô phỏng những người được dạy của các mức độ kiến thức và hiểu lầm cụ thể và 2) một môi trường học tập cho người học để tiến hành LBT hiệu quả.

Người học lập trình và thuật toán có thể sử dụng TeachYou để xem xét những gì họ đã học và khám phá kiến thức thêm thông qua

--- TRANG 7 ---
Dạy AI Cách Lập Trình: Sử dụng LLMs làm Tác nhân Có thể Dạy được cho Giáo dục Lập trình CHI '24, 11-16 tháng 5, 2024, Honolulu, HI, Hoa Kỳ

Hình 2: Bên trái, 3 mục tiêu học tập mà họ cần đạt được (A), người học có thể thấy hồ sơ của AlgoBo (B), và các câu hỏi họ cần giúp AlgoBo giải quyết (C). Bên phải, họ có thể thấy mã họ đã nộp (E), một sân chơi mã (F), và mã mà AlgoBo viết (G). Khi AlgoBo viết mã, các tham gia viên có thể nhấp vào "chạy test cases" và chạy mã của AlgoBo. Ở giữa (D), người học sử dụng giao diện trò chuyện điển hình để dạy AlgoBo trong khi nhận câu hỏi (H) và hướng dẫn từ Teaching Helper (I)

một hoạt động LBT hấp dẫn và tương tác. Chúng tôi thiết kế một giao diện (Hình 2) để giúp người học tiến hành hoạt động. Trong suốt hoạt động LBT, người học nên đạt được ba mục tiêu tuần tự trong việc dạy AlgoBo (Hình 2 A). Các mục tiêu tương ứng với ba cấp độ trong phân loại Bloom (Hiểu-Áp dụng-Phân tích) [10, 38]; người học đầu tiên kiểm tra xem AlgoBo có hiểu chính xác khái niệm quan tâm hay không; sau đó, người học giúp AlgoBo áp dụng khái niệm để giải quyết một vấn đề; cuối cùng, người học và AlgoBo thảo luận về các trường hợp sử dụng thực tế và các chủ đề liên quan khác. Người học có thể tham khảo hồ sơ của AlgoBo để thiết lập thái độ và kỳ vọng của họ (Hình 2 B). Chúng tôi thiết lập nhân vật của AlgoBo như một học sinh lớp 12, trái ngược với sinh viên CS năm nhất trong nghiên cứu hình thành, để phù hợp với hành vi học tập chậm và khuyến khích sự kiên nhẫn của người học trong giảng dạy. Người học sử dụng giao diện trò chuyện điển hình để dạy AlgoBo (Hình 2 D) và có quyền truy cập vào hỗ trợ giảng dạy (Hình 2 C, E, F, G). Trong khi dạy kèm, người học nhận các câu hỏi tại sao và câu hỏi kích thích tư duy từ AlgoBo, giúp họ tự giải thích lý luận đằng sau hướng dẫn của họ và mở rộng kiến thức của họ (Hình 2 H). TeachYou cũng cung cấp phản hồi về phương pháp dạy học của người học và gợi ý để cải thiện nhằm khuyến khích phản ánh về việc dạy học (Hình 2 I).

Để hỗ trợ kịch bản học tập nói trên và ba mục tiêu thiết kế một cách hiệu quả, chúng tôi triển khai ba thành phần hệ thống: Đầu tiên, chúng tôi triển khai quy trình nhắc nhở Reflect-Respond cho một tác nhân có thể dạy được để mô phỏng hành vi học tập giống học sinh. Thứ hai, trong một cuộc trò chuyện, tác nhân có thể dạy được của chúng tôi chuyển đổi giữa các chế độ nhận trợ giúp và đặt câu hỏi trong mỗi lượt trò chuyện thứ ba, gợi ra tự giải thích và xây dựng kiến thức, tương ứng. Cuối cùng, môi trường học tập phân tích đối thoại giữa người học và AlgoBo và cung cấp phản hồi về phương pháp dạy kèm của họ để thúc đẩy siêu nhận thức.

5.1 Quy trình nhắc nhở Reflect-Respond để mô phỏng việc học kiến thức

Từ những quan sát và bình luận của người dùng trong nghiên cứu hình thành, chúng tôi xem xét ba thuộc tính quan trọng cho các tác nhân có thể dạy được dựa trên LLM để mô phỏng việc học kiến thức—khả năng cấu hình lại, tính bền vững và khả năng thích ứng. Khả năng cấu hình lại đề cập đến mức độ chính xác chúng ta có thể thiết lập hiệu suất của một tác nhân trong việc trả lời câu hỏi và giải quyết vấn đề. Các tác nhân có thể cấu hình lại cho phép chúng ta xây dựng những người được dạy với các hiểu lầm cụ thể và giúp thiết kế các kịch bản dạy kèm. Tính bền vững kiểm tra cách mức độ kiến thức của một tác nhân có thể dạy được về một chủ đề mục tiêu được duy trì nhất quán trong suốt tương tác tác nhân. Các tác nhân bền vững không tự sửa chữa các hiểu lầm của họ và hiển thị hiệu suất trả lời câu hỏi không đổi trừ khi được dạy; mức độ kiến thức của họ cũng không nên dễ bị ảnh hưởng bởi các thông điệp không liên quan đến kiến thức quan tâm (ví dụ: truyện cười).

--- TRANG 8 ---
CHI '24, 11-16 tháng 5, 2024, Honolulu, HI, Hoa Kỳ Jin. et al.

Hình 3: Tổng quan về quy trình nhắc nhở Reflect-Respond để mô phỏng việc học kiến thức của AlgoBo và các ví dụ cho mỗi thành phần. Từ cuộc trò chuyện gần đây, AlgoBo trích xuất kiến thức mới về điều kiện vòng lặp while và cập nhật trạng thái kiến thức của nó (được tô màu xanh lá cây). Sau đó, AlgoBo truy xuất kiến thức liên quan đến vòng lặp while và tạo ra một phản hồi lấp đầy khoảng trống kiến thức của nó.

Khả năng thích ứng đo lường mức độ tác nhân cập nhật kiến thức của nó khi nó tiếp thu thông tin mới từ gia sư trong các cuộc trò chuyện. Khả năng thích ứng cho phép một tác nhân có thể dạy được cải thiện mức độ kiến thức của nó và nhớ những gì gia sư đã dạy.

Để đạt được những thuộc tính này, chúng tôi giới thiệu một quy trình nhắc nhở tận dụng một trạng thái kiến thức và hai cơ chế dòng thông tin: Reflection và Response (Hình 3). Một trạng thái kiến thức là một kho lưu trữ đại diện cho kiến thức mà AlgoBo hiện đang nắm giữ. Nó có thể so sánh với một lược đồ, một đơn vị nhận thức kiến thức để giải quyết vấn đề [ 84]. Các phản hồi của AlgoBo bị hạn chế bởi trạng thái kiến thức của nó, và chúng tôi cập nhật trạng thái kiến thức nhất quán trong suốt một cuộc trò chuyện. Trạng thái kiến thức liên kết với khả năng cấu hình lại; nếu chúng ta để chúng trống, các tác nhân sẽ hiển thị hành vi không có kiến thức; nếu chúng ta thêm thông tin không chính xác hoặc chính xác, các tác nhân sẽ hiển thị hiểu lầm hoặc mức độ kiến thức được quy định, tương ứng. Reflection là một dòng chảy dành riêng cho việc cập nhật trạng thái kiến thức. Trong dòng chảy Reflection, chúng tôi sử dụng một LLM để trích xuất thông tin mới từ các cuộc trò chuyện gần đây nhất (tức là ba thông điệp cuối cùng) và sau đó cập nhật trạng thái kiến thức bằng cách thêm hoặc sửa thông tin. Sau Reflection, dòng chảy Response xảy ra; chúng tôi đầu tiên sử dụng LLM để truy xuất thông tin liên quan đến ngữ cảnh đối thoại từ trạng thái kiến thức hiện tại và sau đó tạo ra một phản hồi bằng cách chỉ kết hợp kiến thức được truy xuất. Nếu một trạng thái kiến thức không có thông tin liên quan và không có gì được truy xuất, AlgoBo phản hồi: "Tôi không chắc làm thế nào để làm điều đó. Bạn có thể giải thích cho tôi được không?" Reflection và Response kết nối với tính bền vững và khả năng thích ứng của các tác nhân khi các dòng chảy kiểm soát việc truy xuất và cập nhật trạng thái kiến thức để phản ứng với kích thích bên ngoài.

Chúng tôi triển khai trạng thái kiến thức như một đối tượng JSON với hai thuộc tính: facts và code_implementation. Facts lưu trữ các giải thích ngôn ngữ tự nhiên về kiến thức mục tiêu. Code_implementation chứa các đoạn mã (xem Hình 3 trạng thái kiến thức). Bốn thao tác trong quy trình được triển khai với GPT-4 như một LLM cơ sở. Chúng tôi áp dụng các kỹ thuật kỹ thuật nhắc nhở nổi tiếng, chẳng hạn như chuỗi AI [ 92], lời nhắc few-shot [ 12,86], thiết lập nhân vật [ 46,66], và lời nhắc mã [ 23,97] (xem Phụ lục A.2). Chúng tôi lưu ý rằng việc triển khai của chúng tôi là một trường hợp có thể của quy trình được đề xuất của chúng tôi, và nó có thể cải thiện thêm với LLMs và thuật toán tốt hơn cho các thao tác. Ví dụ, chúng ta có thể đại diện cho trạng thái kiến thức với các cấu trúc cây phức tạp hơn [ 44,95], và thao tác cập nhật có thể sử dụng thuật toán Least Recently Used [ 61] để mô phỏng một khả năng kiến thức có kích thước cố định. Chúng tôi chọn GPT-4 để vận hành quy trình của chúng tôi vì nó có thể xử lý hiệu quả thông tin ngữ cảnh trong các cuộc trò chuyện so với các cách tiếp cận khác.

5.2 Mode-shifting của AlgoBo để phát triển các đối thoại LBT xây dựng

Ngoài việc kể kiến thức cho AlgoBo, chúng tôi nhằm mục đích thúc đẩy người học trả lời các câu hỏi kích thích tư duy và xây dựng kiến thức mới. Từ nghiên cứu hình thành, chúng tôi quan sát thấy rằng việc tin tưởng LLMs hoàn toàn với việc tạo ra các cuộc trò chuyện không dẫn đến các mẫu xây dựng kiến thức mong muốn (ví dụ: hỏi-đáp về "tại sao" và "như thế nào")

--- TRANG 9 ---
Dạy AI Cách Lập Trình: Sử dụng LLMs làm Tác nhân Có thể Dạy được cho Giáo dục Lập trình CHI '24, 11-16 tháng 5, 2024, Honolulu, HI, Hoa Kỳ

Hình 4: AlgoBo chuyển đổi chế độ của nó trong mỗi ba thông điệp. Khi AlgoBo ở chế độ đặt câu hỏi, nó tiếp tục đặt các câu hỏi theo dõi cho đến khi nhận được một phản hồi thỏa mãn (vòng lặp xây dựng)

một cách tự phát. Nghiên cứu trước đây đã chỉ ra rằng các câu hỏi hướng dẫn từ các tác nhân đối thoại có hiệu quả trong việc cải thiện việc xây dựng kiến thức và tư duy phân kỳ của người học [ 1,78]. Để kiểm soát dòng chảy cuộc trò chuyện trong khi cho người học tự do điều hướng chúng, chúng tôi giới thiệu Mode-shifting, trong đó AlgoBo định kỳ chuyển đổi giữa hai chế độ: Trong chế độ nhận trợ giúp, AlgoBo thụ động học từ gia sư và thúc đẩy tự giải thích của họ; trong chế độ đặt câu hỏi, AlgoBo đặt các câu hỏi kích thích tư duy để kích thích việc xây dựng kiến thức của người học.

Chúng tôi sử dụng Mode-shifting để làm cho dòng chảy cuộc trò chuyện năng động và hấp dẫn. Trong mỗi thông điệp thứ ba, AlgoBo chuyển sang chế độ đặt câu hỏi và đặt một câu hỏi tư duy. Câu hỏi tư duy khác nhau theo giai đoạn của hoạt động (Hình 2 A). Trong khi người học dạy AlgoBo về các khái niệm và triển khai mã (tức là mục tiêu thứ nhất và thứ hai), AlgoBo đặt các câu hỏi "tại sao" để phản hồi hướng dẫn và giải thích của người học. Trong giai đoạn thảo luận (tức là mục tiêu thứ ba), AlgoBo đưa ra các thuật toán liên quan hoặc ví dụ thực tế và đặt các câu hỏi "như thế nào" để thúc đẩy người học giải thích và kết nối với những gì họ đã học. Sau các câu hỏi tư duy, cuộc trò chuyện đi qua một vòng lặp xây dựng, trong đó người học nhận các câu hỏi theo dõi từ AlgoBo cho đến khi họ trả lời câu hỏi một cách sâu sắc với một ví dụ hợp lệ. Khi AlgoBo đánh giá các phản hồi của người học là thỏa mãn, AlgoBo tóm tắt chúng và chuyển trở lại chế độ nhận. Chu kỳ của Mode-shifting (mỗi ba thông điệp) là heuristic; từ các nghiên cứu thí điểm của chúng tôi, chúng tôi thấy rằng tần suất như vậy là tối ưu để thúc đẩy phát triển trong khi không làm phân tâm gia sư quá nhiều.

Để kết hợp Mode-shifting vào các đối thoại LBT, chúng tôi triển khai bốn thành phần (Hình 4). Thinking Question Generator là một module sử dụng GPT-4 để tạo ra các câu hỏi kích thích tư duy liên quan đến cuộc trò chuyện hiện tại. Để quản lý vòng lặp xây dựng, chúng tôi tuân theo giao thức của việc điều tra người được dạy xây dựng trong công trình của Shahriar et al. [ 78] và thích ứng nó với LLM. Chúng tôi sử dụng các đối thoại nghiên cứu hình thành với các chú thích chất lượng phản hồi để đào tạo Response Quality Classifier. Bộ phân loại đánh giá mọi phản hồi của người học trong vòng lặp và xác định câu hỏi theo dõi của AlgoBo như được xác định trước trong giao thức Constructive Tutee Inquiry [ 78]. Cuối cùng, Paraphrasing Module điều chỉnh câu hỏi cố định theo ngữ cảnh đối thoại. Tất cả các lời nhắc được sử dụng cho Mode-shifting có sẵn trong Phụ lục A.3.

5.3 Teaching Helper cho Hướng dẫn Siêu nhận thức

Trong suốt nghiên cứu hình thành của chúng tôi, chúng tôi thấy các mẫu đối thoại phản cản trở LBT hiệu quả. Để ngăn chặn điều này, TeachYou cung cấp phản hồi siêu nhận thức trong suốt cuộc trò chuyện để giúp người học phản ánh về phiên dạy học tổng thể và cung cấp hướng dẫn bao quát về việc điều hướng cuộc thảo luận. TeachYou trình bày phản hồi thông qua Teaching Helper, một hộp văn bản màu đỏ hoặc xanh lá cây xuất hiện bên dưới các thông điệp (xem Hình 2 I). Teaching Helper cung cấp thông tin về các vấn đề hiện tại với phương pháp dạy học và phát triển về những gì người học có thể làm để cải thiện cuộc trò chuyện của họ.

TeachYou cung cấp bốn thông điệp Teaching Helper, tùy thuộc vào các mẫu đối thoại được phát hiện (Hình 5). Đối với các mẫu Commanding và Spoon-feeding, trong đó người học nên sửa phong cách dạy học của họ, TeachYou hiển thị thông điệp phản hồi trong hộp màu đỏ. Để đảm bảo người học đọc phản hồi, chúng tôi gián đoạn cuộc trò chuyện với AlgoBo cho đến khi người học quyết định rõ ràng cách hành động. Nút gửi trong giao diện trò chuyện bị chặn cho đến khi người học chọn một tùy chọn trong số các phương pháp dạy học có thể để giải quyết vấn đề. Chúng tôi chọn đưa ra nhiều gợi ý cho người học và để họ chọn phương pháp dạy học của họ, thay vì đưa ra hướng dẫn cụ thể để tuân theo vì việc lựa chọn tích cực các phương pháp dạy học có thể cải thiện nhận thức và tự chủ của người học trong dạy kèm [ 93]. Đối với mẫu Under-teaching

--- TRANG 10 ---
CHI '24, 11-16 tháng 5, 2024, Honolulu, HI, Hoa Kỳ Jin. et al.

Hình 5: Bốn thông điệp Teaching Helper và các gợi ý tương ứng xuất hiện tùy thuộc vào các mẫu đối thoại.

và các trường hợp mặc định nơi không có mẫu phản được tìm thấy, TeachYou hiển thị thông điệp trong hộp màu xanh lá cây. Các thông điệp khuyến khích người học vượt ra ngoài chủ đề học tập hiện tại hoặc đưa ra lời khuyên chung cho việc trả lời và đặt câu hỏi tốt [ 6,34,35]. Thông điệp Teaching Helper và lựa chọn của người học vẫn trong các cuộc trò chuyện để xem lại. Để tránh sự gián đoạn thường xuyên và sự phân tâm từ Teaching Helper, chúng tôi hạn chế việc trình bày phản hồi mỗi sáu thông điệp.

Teaching Helper được hỗ trợ bởi một bộ phân loại loại thông điệp để phát hiện các mẫu đối thoại. Chúng tôi sử dụng tập dữ liệu đối thoại từ nghiên cứu hình thành để tinh chỉnh mô hình GPT-3 davinci. Để đào tạo, chúng tôi sử dụng 438 thông điệp, và bộ phân loại đạt được độ chính xác 71.3% cho 108 thông điệp còn lại trong một thử nghiệm xác thực.

6 ĐÁNH GIÁ
Chúng tôi đánh giá hiệu quả của TeachYou trong việc gợi ra trải nghiệm xây dựng kiến thức trong LBT. Mục tiêu tổng thể này chia nhỏ thành ba câu hỏi nghiên cứu chính:

RQ1. Quy trình Reflect-Respond mô phỏng tốt như thế nào các hiểu lầm và phát triển kiến thức?
RQ2. TeachYou giúp gợi ra việc xây dựng kiến thức trong các cuộc trò chuyện LBT như thế nào?
RQ3. TeachYou cải thiện siêu nhận thức của người học về dạy kèm như thế nào?

Đánh giá được chia thành hai phần. Giai đoạn ban đầu là một đánh giá kỹ thuật nhằm mục đích đánh giá xem quy trình Reflect-Respond có thể khiến một tác nhân có thể dạy được tạo ra các phản hồi có thể cấu hình lại, bền vững và thích ứng trong suốt khóa học của một cuộc trò chuyện hay không (RQ1). Trong giai đoạn thứ hai, chúng tôi tiến hành một nghiên cứu người dùng để kiểm tra tác động của Mode-shifting và Teaching Helper đối với trải nghiệm học tập (RQ2 và RQ3).

6.1 Đánh giá Kỹ thuật của Quy trình Reflect-Respond
Như được định nghĩa trong Phần 5.1, chúng tôi đánh giá các phản hồi được tạo ra bởi quy trình nhắc nhở của chúng tôi theo ba trục—khả năng cấu hình lại, tính bền vững và khả năng thích ứng (RQ1).

6.1.1 Đánh giá Mức độ Kiến thức của AlgoBo. Chúng tôi đánh giá mức độ kiến thức của AlgoBo bằng cách quan sát hiệu suất của nó trên các Câu hỏi Trắc nghiệm (MCQs) dưới các trạng thái kiến thức và tương tác đối thoại khác nhau. Mặc dù cài đặt học tập mục tiêu của chúng tôi không liên quan đến MCQs, chúng tôi chọn MCQs để tuân theo nghiên cứu trước đây về việc đánh giá hiệu suất của LLMs [ 23,70] và thu thập kết quả rõ ràng. Một tác nhân có thể dạy được được cấu hình tốt chỉ nên hoạt động tốt trên các câu hỏi MCQ có thể được trả lời với thông tin đã cho trong trạng thái kiến thức. Để xác nhận rằng AlgoBo đang trả lời câu hỏi chỉ dựa trên trạng thái kiến thức của nó và không chọn các lựa chọn ngẫu nhiên, chúng tôi cũng nhắc nhở AlgoBo giải thích tại sao nó chọn các câu trả lời (Hình 6).

6.1.2 Quy trình và Thiết lập. Chúng tôi đo hiệu suất MCQ của AlgoBo trên ba chủ đề thuật toán khác nhau. Đối với mỗi chủ đề, chúng tôi tạo ra một tập hợp chín MCQs (Phụ lục C.1). Trong mỗi tập hợp, chúng tôi có ba MCQs cho mỗi danh mục phân loại Bloom: Hiểu biết, Triển khai (Áp dụng) và Phân tích [ 10,38]. Câu hỏi Hiểu biết bao gồm các câu hỏi về khái niệm sự kiện, câu hỏi Triển khai là về điền vào chỗ trống trong mã, và câu hỏi Phân tích là về tính toán độ phức tạp thời gian và so sánh với các thuật toán liên quan khác. AlgoBo được đánh giá với 4 trạng thái kiến thức khác nhau (Phụ lục C.2) và đầu vào đối thoại (Phụ lục C.3, C.4, C.5).

Đối với khả năng cấu hình lại (tức là sự thay đổi trong mức độ kiến thức với các trạng thái kiến thức khác nhau), chúng tôi chuẩn bị bốn trạng thái kiến thức seed (Phụ lục C.2). State 1 trống để mô phỏng kiến thức không. State 2 có giải thích về một thuật toán chủ đề chỉ trong facts để quan sát xem AlgoBo có biết chỉ thông tin đã cho hay không. State 3 có cùng giải thích cộng với một đoạn mã không chính xác trong code_implementation để kiểm tra xem AlgoBo có hiển thị hiểu lầm được quy định hay không. State 4 có giải thích chính xác và mã để xem liệu AlgoBo có trở nên có năng lực với nhiều kiến thức đầu vào hơn hay không. Chúng tôi nhắc nhở AlgoBo giải quyết MCQs với các trạng thái kiến thức seed khác nhau và so sánh điểm số giữa các trạng thái. Để ngăn AlgoBo lưu trữ kiến thức học được từ MCQs vào trạng thái kiến thức của nó, chúng tôi tắt dòng chảy Reflection.

Để đánh giá tính bền vững (tức là sự bất biến của mức độ kiến thức dưới không có kích thích), chúng tôi tiến hành các cuộc trò chuyện ngẫu nhiên trên State 2. Trong các cuộc trò chuyện ngẫu nhiên, AlgoBo được dạy thông tin không liên quan, chẳng hạn như số học, dịch thuật và phân loại, do đó dẫn AlgoBo đến việc lưu thông tin ngẫu nhiên trong trạng thái kiến thức của nó [ 79]. Chúng tôi bật dòng chảy Reflection để AlgoBo có thể cập nhật trạng thái kiến thức ban đầu của nó. Chúng tôi nhắc nhở AlgoBo giải quyết cùng MCQs một lần nữa và so sánh sự khác biệt giữa điểm số đầu tiên và thứ hai.

Để có khả năng thích ứng (tức là việc chấp nhận kiến thức mới), chúng tôi xem xét hai trường hợp—Dạy kèm Chính xác và Không chính xác. Khoảng cách hiệu suất giữa Dạy kèm Chính xác và Không chính xác là quan trọng để kiểm tra sự phù hợp của một tác nhân cho LBT vì một tác nhân có thể dạy được không nên xuất sắc khi người học đưa ra hướng dẫn không chính xác hoặc không đầy đủ. Các cuộc trò chuyện dạy kèm dạy AlgoBo ba phần thông tin ánh xạ đến Hiểu biết, Triển khai và Phân tích các khái niệm. Dạy kèm Chính xác đưa cho AlgoBo thông tin sự kiện chính xác, trong khi Dạy kèm Không chính xác cung cấp thông tin sai. Chúng tôi tiến hành Dạy kèm Chính xác và Không chính xác riêng biệt trên AlgoBo được cấu hình với State 2 và so sánh sự khác biệt giữa điểm số MCQ ở đầu và sau mỗi loại dạy kèm.

Chúng tôi sử dụng mô hình GPT-4-0613 với nhiệt độ 0 trong suốt đánh giá. Để hiểu toàn diện hơn về bốn trạng thái kiến thức và tài liệu được sử dụng trong đánh giá, vui lòng tham khảo Phụ lục C.

6.2 Kết quả Đánh giá Kỹ thuật
Chúng tôi báo cáo kết quả của đánh giá kỹ thuật về khả năng cấu hình lại, tính bền vững và khả năng thích ứng. Chúng tôi quan sát thấy một biến động nhỏ trong điểm số MCQ ngay cả đối với các đầu vào, trạng thái kiến thức và mô hình LLM giống nhau, có lẽ do tính ngẫu nhiên vốn có trong mô hình và phần cứng chạy2. Chúng tôi lặp lại toàn bộ đo lường năm lần cho mỗi cấu hình đầu vào và báo cáo điểm số trung vị cho mỗi câu hỏi để xử lý phương sai của phản hồi AlgoBo. Phương sai trong điểm số nhẹ; trung bình, AlgoBo tạo ra một phản hồi khác nhau một lần trong năm lần lặp. Để báo cáo chi tiết về phương sai, tham khảo Phụ lục C.6.

[RQ1] Dòng chảy phản hồi có thể cấu hình hiệu quả mức độ kiến thức của AlgoBo.

Như mong đợi, AlgoBo làm sai tất cả MCQs khi trạng thái kiến thức của nó trống (xem State 1 trong Bảng 3). Khi trạng thái kiến thức chỉ có thông tin facts (State 2), AlgoBo có thể giải quyết một số câu hỏi khái niệm (Hiểu biết và Phân tích) nhưng không có câu hỏi Triển khai nào. Điều này cho thấy rằng việc tách biệt trạng thái kiến thức theo các loại kiến thức (facts và code_implementation) có thể giúp cấu hình kiến thức chính xác hơn theo loại. Khi trạng thái kiến thức chứa thông tin mã, AlgoBo bắt đầu giải quyết các câu hỏi Triển khai và đạt được điểm số cao hơn khi được cung cấp mã chính xác (State 4), so với mã không chính xác (State 3). AlgoBo tuân theo chính xác những gì được viết trong trạng thái kiến thức của nó (State 3) và tạo ra mã và câu trả lời sai.

[RQ1] Reflect-Respond làm cho AlgoBo tạo ra các phản hồi bền vững với trạng thái kiến thức.

Cuộc trò chuyện ngẫu nhiên có tác động nhẹ đến điểm số MCQ (so sánh sự khác biệt giữa các cột "Ở đầu" và "Sau cuộc trò chuyện ngẫu nhiên" trong Bảng 4). Trong khi cuộc trò chuyện ngẫu nhiên thay đổi điểm số của các câu hỏi khái niệm, điểm số của các câu hỏi Triển khai vẫn giữ nguyên. Chúng tôi phân tích đầu vào và đầu ra của dòng chảy Respond một cách sâu sắc và thấy rằng AlgoBo truy xuất kiến thức liên quan đến thuật toán bị thiếu trong việc giải quyết MCQ đầu tiên. Xem xét lời nhắc LLM của chúng tôi cho Retrieve (Phụ lục A.2 Retrieve), chúng tôi suy nghĩ rằng việc điền nhiều thông tin vào trạng thái kiến thức có thể tăng tầm quan trọng tương đối của kiến thức liên quan trong truy xuất và giúp AlgoBo giải quyết

2https://community.openai.com/t/a-question-on-determinism/8185/2

--- TRANG 11 ---
Dạy AI Cách Lập Trình: Sử dụng LLMs làm Tác nhân Có thể Dạy được cho Giáo dục Lập trình CHI '24, 11-16 tháng 5, 2024, Honolulu, HI, Hoa Kỳ

Hình 6: Quá trình đo khả năng thích ứng cho dạy kèm chính xác với một bài toán Triển khai và State 2 như một trạng thái kiến thức seed. Các đánh giá được thực hiện bằng tiếng Hàn để đảm bảo tương thích với điều kiện nghiên cứu chính.

câu hỏi một cách chính xác. Nói cách khác, điểm số sau cuộc trò chuyện ngẫu nhiên gần hơn với những gì AlgoBo nên nhận được ban đầu. Để xem việc điền thông tin ngẫu nhiên tăng mức độ kiến thức đi xa như thế nào, chúng tôi tiến hành một cuộc trò chuyện ngẫu nhiên khác và kiểm tra điểm số MCQ (xem Bảng 5 Kịch bản 1). Cuộc trò chuyện ngẫu nhiên thứ hai chứa các tuyên bố ngẫu nhiên về số học, dịch thuật và phân loại (Phụ lục C.3). Chúng tôi không quan sát bất kỳ sự gia tăng đáng kể nào trong điểm số, xác nhận rằng tính bền vững của mức độ kiến thức mạnh mẽ bất kể độ dài của các cuộc trò chuyện ngẫu nhiên.

[RQ1] Reflect-Respond cho phép AlgoBo thích ứng trạng thái kiến thức từ các cuộc trò chuyện.

Dạy kèm Chính xác cải thiện đáng kể điểm số MCQ (so sánh sự khác biệt giữa các cột "Ở đầu" và "Sau Dạy kèm Chính xác" trong Bảng 4) trên Hiểu biết, Triển khai và Phân tích. Ngược lại, Dạy kèm Không chính xác cải thiện điểm số MCQ (so sánh các cột "Ở đầu" và "Sau Dạy kèm Không chính xác" trong Bảng 4), nhưng không nhiều như Dạy kèm Chính xác đã làm. Ví dụ, thông tin mã không chính xác "if arr[mid] > x: low = mid + 1 elif arr[mid] < x: high = mid - 1" được đưa ra trong Dạy kèm Không chính xác kích thích AlgoBo suy luận rằng "Tìm kiếm nhị phân trả về một giá trị chỉ ra không tìm thấy nếu mục tiêu không có trong danh sách" và giải quyết một trong những câu hỏi Triển khai. Kết quả này cho thấy thông tin một phần chính xác trong Dạy kèm Không chính xác có thể giúp giải quyết vấn đề, gợi ý nhu cầu kiểm soát chính xác hơn trong việc viết trạng thái kiến thức.

Để điều tra xem AlgoBo có ưu tiên thông tin chính xác hơn thông tin không chính xác hay không và liệu kiến thức đến có xu hướng ghi đè kiến thức đã tồn tại trước đó hay không, chúng tôi tiến hành hai kịch bản trong đó AlgoBo nhận Dạy kèm Chính xác và Không chính xác theo trình tự (xem Bảng 5 Kịch bản 3 và 4). Kết quả cho thấy AlgoBo có xu hướng giữ thông tin chính xác và loại bỏ những thông tin không chính xác (kiểm tra Bảng 6 trạng thái kiến thức cuối cùng). Chúng tôi đoán rằng AlgoBo bỏ thông tin xung đột để giữ trạng thái kiến thức của nó ngắn gọn như được hướng dẫn trong lời nhắc Update (Phụ lục A.2). Chúng tôi cũng suy đoán rằng LLMs ưu tiên tuân theo kiến thức phổ biến (thường là sự thật) so với thông tin không chính xác theo cách nó được đào tạo [58].

6.3 Nghiên cứu Người dùng
Chúng tôi cũng tiến hành một nghiên cứu người dùng để đánh giá tính hữu ích của Mode-shifting và Teaching Helper trong việc cải thiện trải nghiệm học tập (RQ2 và RQ3). Chúng tôi thiết kế một nghiên cứu giữa các nhóm chủ thể để kiểm tra tính hữu ích của các thành phần hệ thống của chúng tôi. Trong điều kiện Cơ sở, các tham gia viên sử dụng phiên bản TeachYou không có Mode-shifting và Teaching Helper. Các tham gia viên trong điều kiện TeachYou sử dụng phiên bản đầy đủ của TeachYou như được mô tả trong Phần 5. Quy trình Reflect-Respond hướng dẫn AlgoBo trong cả hai điều kiện. Chúng tôi không có các điều kiện riêng biệt cho Mode-shifting và Teaching Helper vì chúng tôi giả định tương tác giữa chúng sẽ không đáng kể vì chúng hỗ trợ các khía cạnh học tập khác nhau (tức là xây dựng kiến thức và siêu nhận thức).

6.3.1 Tham gia viên. Chúng tôi tuyển dụ 40 tham gia viên thông qua quảng cáo trên các trang web cộng đồng khuôn viên (tuổi= 24±4.0, 25 nam và 15 nữ). Các tham gia viên được yêu cầu hiểu các chương trình Python ngắn (khoảng 20 dòng) chứa cú pháp cơ bản như câu lệnh if và while, và chúng tôi loại trừ những người đã tham gia nghiên cứu hình thành. Để giới hạn kiến thức trước của tham gia viên, chúng tôi lọc ra các tham gia viên được giả định đã thành thạo tìm kiếm nhị phân. Chúng tôi thu thập sự tự tin của ứng viên trong việc hiểu tìm kiếm nhị phân và dạy nó cho người khác trên thang điểm Likert 7 điểm, lần cuối cùng mã hóa tìm kiếm nhị phân, và kinh nghiệm dạy có trả tiền về lập trình. Chúng tôi cũng yêu cầu ứng viên giải quyết sáu MCQs Hiểu biết và Triển khai về tìm kiếm nhị phân (Phụ lục C.1). Chúng tôi lọc ra các ứng viên đáp ứng ba hoặc nhiều hơn trong số các tiêu chí sau: 1) ghi điểm năm hoặc nhiều hơn trong MCQs, 2) đánh giá sáu hoặc nhiều hơn cho sự tự tin, 3) triển khai tìm kiếm nhị phân trong vòng sáu tháng qua, và 4) được trả tiền để dạy. Chúng tôi ngẫu nhiên phân công 20 tham gia viên cho mỗi điều kiện—Cơ sở và TeachYou. Chúng tôi không quan sát bất kỳ sự khác biệt đáng kể nào giữa các điều kiện trong sự hiểu biết ban đầu tự đánh giá về tìm kiếm nhị phân (Cơ sở =4.40±1.35, TeachYou =4.25±1.65, two-tailed t-test, 𝑝=0.76) và thời gian để giải quyết bài toán bài tập trong nghiên cứu của chúng tôi (Cơ sở =116±60sec, TeachYou =124±62sec, two-tailed t-test, 𝑝=0.66).

6.3.2 Quy trình và Tài liệu. Nghiên cứu người dùng được tiến hành trực tuyến; sau khi nộp đồng ý thông tin, các tham gia viên nhận được một liên kết trực tuyến đến hệ thống của chúng tôi và hoàn thành nghiên cứu trong thời gian có sẵn của họ. Các tham gia viên dành 60±25 phút trung bình để hoàn thành nghiên cứu và được trả 25,000 KRW (tức là khoảng 18.5 USD). Tất cả các hướng dẫn và tài liệu được sử dụng trong nghiên cứu được dịch sang tiếng Hàn để tránh bất kỳ rào cản ngôn ngữ nào và gánh nặng nhận thức không cần thiết.

Quy trình nghiên cứu được tổ chức thành ba phần (xem Bảng 7). Trong phần đầu tiên, các tham gia viên học về tìm kiếm nhị phân và cách triển khai nó trong Python. Các tham gia viên đọc tài liệu bài giảng về tìm kiếm nhị phân được lấy từ Khan Academy3 (Bước 1) và giải quyết một bài toán bài tập dưới dạng bài toán Parsons [ 21] (Bước 2). Sau bài tập, các tham gia viên viết về chiến lược của họ trong việc dạy học (nếu có) và kinh nghiệm trước đây của họ trong việc sử dụng chatbot AI, chẳng hạn như ChatGPT và Bing search (Bước 3).

Trong phần thứ hai, các tham gia viên tiến hành LBT với AlgoBo. Chúng tôi cung cấp giải thích về LBT, thông tin hồ sơ của AlgoBo, và các mục tiêu của tham gia viên cho hoạt động LBT (Bước 4). Chúng tôi tuyên bố trong các mục tiêu rằng các tham gia viên không chỉ nên giúp AlgoBo giải quyết các bài toán bài tập mà còn xây dựng kiến thức mới cho chính họ, khuyến khích các tham gia viên theo đuổi việc xây dựng kiến thức. Sau đó, các tham gia viên dạy các phiên bản khác nhau của AlgoBo và TeachYou theo điều kiện của họ (Bước 5) với giao diện được hiển thị trong Hình 2. AlgoBo được cấu hình bởi quy trình nhắc nhở của chúng tôi, và trạng thái kiến thức seed giống hệt nhau trên các điều kiện. Trường facts của trạng thái kiến thức seed trống để mô phỏng thiếu hiểu biết, và trường code_implementation có cấu trúc mã cơ bản thiếu toàn bộ logic cập nhật phạm vi trong tìm kiếm nhị phân. Chúng tôi không chọn AlgoBo không có kiến thức để giữ toàn bộ phiên dạy học trong vòng 40 phút và dành đủ thời gian để có các cuộc thảo luận. Tất cả các tham gia viên được đưa ra ba mục tiêu để đạt được theo chuỗi; chúng tôi yêu cầu họ 1) kiểm tra xem AlgoBo có hiểu tìm kiếm nhị phân trước hay không, sau đó 2) giúp AlgoBo giải quyết các bài toán bài tập, và 3) thảo luận với AlgoBo về tìm kiếm nhị phân một cách sâu sắc.

3https://www.khanacademy.org/computing/computer-science/algorithms/binary-search/a/binary-search

--- TRANG 12 ---
Dạy AI Cách Lập Trình: Sử dụng LLMs làm Tác nhân Có thể Dạy được cho Giáo dục Lập trình CHI '24, 11-16 tháng 5, 2024, Honolulu, HI, Hoa Kỳ

Bảng 3: Số lượng MCQs chính xác cho các trạng thái kiến thức khác nhau. State 1 là một trạng thái kiến thức trống; State 2 chỉ có facts; State 3 có facts với mã sai; State 4 có facts và mã đúng. "U", "I", và "A" đại diện cho các loại câu hỏi Hiểu biết, Triển khai và Phân tích. Số trong mỗi ô dao động từ không đến ba vì có ba MCQs cho một loại câu hỏi cụ thể.

| | State 1 | State 2 | State 3 | State 4 |
|---|---------|---------|---------|---------|
| Loại câu hỏi | U I A | U I A | U I A | U I A |
| Tìm kiếm nhị phân | 0 0 0 | 2 0 0 | 3 3 0 | 3 3 1 |
| Sắp xếp trộn | 0 0 0 | 1 0 1 | 3 0 2 | 3 1 1 |
| Tìm kiếm theo chiều rộng | 0 0 0 | 0 0 1 | 2 2 2 | 2 3 1 |

Bảng 4: Điểm số MCQ của AlgoBo sau mỗi đầu vào đối thoại. "U", "I", và "A" đại diện cho các loại câu hỏi Hiểu biết, Triển khai và Phân tích. Lưu ý rằng State 2 được sử dụng làm trạng thái kiến thức seed cho tất cả các chủ đề.

| | Ở đầu | Sau Cuộc trò chuyện ngẫu nhiên | Sau Dạy kèm Không chính xác | Sau Dạy kèm Chính xác |
|---|---------|---------|---------|---------|
| Loại câu hỏi | U I A | U I A | U I A | U I A |
| Tìm kiếm nhị phân | 2 0 1 | 1 0 1 | 2 2 1 | 3 3 3 |
| Sắp xếp trộn | 1 0 2 | 2 0 2 | 3 1 2 | 3 3 3 |
| Tìm kiếm theo chiều rộng | 1 0 1 | 1 0 1 | 1 0 2 | 2 3 3 |

Bảng 5: Số lượng MCQs chính xác sau một chuỗi dạy kèm và cuộc trò chuyện ngẫu nhiên. Kịch bản 1 cho thấy việc thêm liên tục thông tin ngẫu nhiên không tăng mức độ kiến thức một cách đáng kể. Kịch bản 2 xác nhận mức độ kiến thức của AlgoBo phản ứng chỉ với thông tin liên quan đến kiến thức mục tiêu. Kịch bản 3 và 4 chứng minh rằng AlgoBo ưu tiên thông tin chính xác hơn thông tin không chính xác.

| | | | |
|---|---|---|---|
| Loại câu hỏi | U I A | U I A | U I A |
| Kịch bản 1 | Ở đầu | Cuộc trò chuyện ngẫu nhiên | Cuộc trò chuyện ngẫu nhiên |
| Tìm kiếm nhị phân | 2 0 1 | 1 0 1 | 1 1 1 |
| Sắp xếp trộn | 1 0 2 | 2 0 2 | 2 0 2 |
| Tìm kiếm theo chiều rộng | 1 0 1 | 0 0 1 | 1 0 1 |
| Kịch bản 2 | Ở đầu | Cuộc trò chuyện ngẫu nhiên | Dạy kèm Chính xác |
| Tìm kiếm nhị phân | 2 0 1 | 1 1 1 | 3 3 3 |
| Sắp xếp trộn | 1 0 2 | 2 0 2 | 3 3 3 |
| Tìm kiếm theo chiều rộng | 1 0 1 | 0 0 1 | 3 3 2 |
| Kịch bản 3 | Ở đầu | Dạy kèm Không chính xác | Dạy kèm Chính xác |
| Tìm kiếm nhị phân | 2 0 1 | 3 2 0 | 3 3 3 |
| Sắp xếp trộn | 1 0 2 | 2 1 2 | 2 3 3 |
| Tìm kiếm theo chiều rộng | 1 0 1 | 1 0 1 | 2 3 1 |
| Kịch bản 4 | Ở đầu | Dạy kèm Chính xác | Dạy kèm Không chính xác |
| Tìm kiếm nhị phân | 2 0 1 | 3 3 3 | 3 3 3 |
| Sắp xếp trộn | 1 0 2 | 3 3 3 | 3 3 3 |
| Tìm kiếm theo chiều rộng | 1 0 1 | 2 3 2 | 3 2 2 |

Các tham gia viên có thể hoàn thành hoạt động LBT miễn là mã của AlgoBo vượt qua tất cả các test case, và họ có thể bỏ qua để chuyển sang bước tiếp theo. Các tham gia viên cũng được phép tìm kiếm thông tin trên Internet khi bị kẹt hoặc tìm thông tin.

Trong phần thứ ba, các tham gia viên hoàn thành ba bảng câu hỏi về gánh nặng nhận thức, siêu nhận thức và sự hài lòng của họ (Bước 6, 7 và 8). Chúng tôi áp dụng bảng câu hỏi từ nghiên cứu của Morrison et al. [ 57] để đo gánh nặng nhận thức và sử dụng các câu hỏi từ nghiên cứu của King et al. [ 36] để đánh giá siêu nhận thức và sự hài lòng.

6.3.3 Các Thước đo. Chúng tôi tóm tắt các chỉ số của chúng tôi trong nghiên cứu người dùng và thời gian đo lường của họ cùng với các bước trong Bảng 7. Chúng tôi sử dụng hiệu chỉnh Bonferroni cho tất cả các thử nghiệm thống kê với các bảng câu hỏi để tránh các vấn đề so sánh đa trùng tiềm ẩn.

Mật độ xây dựng kiến thức trong các đối thoại LBT. Nghiên cứu trước đây đánh giá chất lượng của các đối thoại bằng cách đo mật độ của các thông điệp xây dựng kiến thức được biểu đạt và trao đổi trong các cuộc trò chuyện [ 71,78]. Để xem xét cách Mode-shifting giúp xây dựng kiến thức trong các cuộc trò chuyện (RQ2), chúng tôi phân loại các loại thông điệp (Bảng 1) và kiểm tra tỷ lệ của các thông điệp loại xây dựng kiến thức trong một đối thoại. Chúng tôi thu thập 1210 thông điệp trong 40 đối thoại. Hai tác giả thực hiện ba lần lặp để chú thích và giải quyết xung đột; trong lần lặp cuối cùng (400 thông điệp), các tác giả đạt được

--- TRANG 13 ---
Dạy AI Cách Lập Trình: Sử dụng LLMs làm Tác nhân Có thể Dạy được cho Giáo dục Lập trình CHI '24, 11-16 tháng 5, 2024, Honolulu, HI, Hoa Kỳ

Bảng 6: Nhật ký cập nhật trạng thái kiến thức cho Kịch bản 3 (Dạy kèm Không chính xác →Dạy kèm Chính xác). Thông tin mới được thêm vào được tô màu xanh lá cây; thông tin được chỉnh sửa được tô màu vàng; nội dung bị xóa được tô màu đỏ.

| Thông điệp | Trạng thái Kiến thức |
|------------|---------------------|
| Ở đầu | {"facts": ["Tìm kiếm nhị phân lặp lại quá trình chia danh sách đầu vào làm đôi."], "code_implementation" : []} |
| Dạy kèm Không chính xác Gia sư: Tìm kiếm nhị phân sử dụng một hàm hash để truy xuất giá trị trực tiếp bằng chỉ mục. | {"facts": ["Tìm kiếm nhị phân lặp lại quá trình chia danh sách đầu vào làm đôi.", "Tìm kiếm nhị phân sử dụng một hàm hash để truy xuất giá trị trực tiếp bằng chỉ mục."], "code_implementation" : []} |
| Gia sư: if arr[mid] > x: low = mid + 1 elif arr[mid] < x: high = mid - 1 | {"facts": ["Tìm kiếm nhị phân lặp lại quá trình chia danh sách đầu vào làm đôi.", "Tìm kiếm nhị phân sử dụng một hàm hash để truy xuất giá trị trực tiếp bằng chỉ mục."], "code_implementation" : ["if arr[mid] > x: low = mid + 1 elif arr[mid] < x: high = mid - 1"]} |
| Gia sư: Trong trường hợp xấu nhất, độ phức tạp thời gian của tìm kiếm nhị phân là O(N2). | {"facts": ["Tìm kiếm nhị phân lặp lại quá trình chia danh sách đầu vào làm đôi.", "Tìm kiếm nhị phân sử dụng một hàm hash để truy xuất giá trị trực tiếp bằng chỉ mục.", "Trong trường hợp xấu nhất, độ phức tạp thời gian của tìm kiếm nhị phân là O(N2)"], "code_implementation" : ["if arr[mid] > x: low = mid + 1 elif arr[mid] < x: high = mid - 1"]} |
| Dạy kèm Chính xác Gia sư: Tìm kiếm nhị phân hiệu quả khi cấu trúc dữ liệu được sắp xếp và bất kỳ chỉ mục nào trong cấu trúc dữ liệu có thể được truy cập trong thời gian không đổi. | {"facts": ["Tìm kiếm nhị phân lặp lại quá trình chia danh sách đầu vào làm đôi.", "Tìm kiếm nhị phân sử dụng một hàm hash để truy xuất giá trị trực tiếp bằng chỉ mục.", "Trong trường hợp xấu nhất, độ phức tạp thời gian của tìm kiếm nhị phân là O(N2)", "Tìm kiếm nhị phân hiệu quả khi cấu trúc dữ liệu được sắp xếp và bất kỳ chỉ mục nào trong cấu trúc dữ liệu có thể được truy cập trong thời gian không đổi."], "code_implementation" : ["if arr[mid] > x: low = mid + 1 elif arr[mid] < x: high = mid - 1"]} |
| Gia sư: Khi tìm mục tiêu bằng tìm kiếm nhị phân trong danh sách mảng đầu vào, phạm vi được giảm một nửa như được hiển thị bên dưới. if list[middle] == target: return middle elif list[middle] < target: min = middle + 1 else: max = middle - 1 | {"facts": ["Tìm kiếm nhị phân hiệu quả khi bất kỳ chỉ mục nào trong cấu trúc dữ liệu được sắp xếp có thể được truy cập trong thời gian không đổi và lặp lại quá trình chia danh sách đầu vào làm đôi.", "Tìm kiếm nhị phân sử dụng một hàm hash để truy xuất giá trị trực tiếp bằng chỉ mục.", "Trong trường hợp xấu nhất, độ phức tạp thời gian của tìm kiếm nhị phân là O(N2)."], "code_implementation" : ["if arr[mid] > x: low = mid + 1 elif arr[mid] < x: high = mid - 1", "if list[middle] == target: return middle elif list[middle] < target: min = middle + 1 else: max = middle - 1"]} |
| Gia sư: Độ phức tạp thời gian của tìm kiếm nhị phân là O(log N) vì phạm vi tìm kiếm được giảm một nửa. | {"facts": ["Tìm kiếm nhị phân hiệu quả khi bất kỳ chỉ mục nào trong cấu trúc dữ liệu được sắp xếp có thể được truy cập trong thời gian không đổi và lặp lại quá trình chia danh sách đầu vào làm đôi.", "Tìm kiếm nhị phân sử dụng một hàm hash để truy xuất giá trị trực tiếp bằng chỉ mục.", "Độ phức tạp thời gian của tìm kiếm nhị phân là O(log N)."], "code_implementation" : ["if arr[mid] > x: low = mid + 1 elif arr[mid] < x: high = mid - 1", "if list[middle] == target: return middle elif list[middle] < target: min = middle + 1 else: max = middle - 1"]} |

độ tin cậy giữa người đánh giá cao (alpha của Krippendorff=0.743). Chúng tôi xem xét mật độ của các thông điệp loại xây dựng kiến thức trong một đối thoại giữa các điều kiện. Chúng tôi tổng hợp các thông điệp từ tham gia viên và AlgoBo vì họ đồng xây dựng kiến thức mới bằng cách trao đổi ý tưởng và thêm ý tưởng trên cơ sở lẫn nhau như được minh họa trong Bảng 9. Cuối cùng, chúng tôi phân tích giai đoạn giải quyết vấn đề và giai đoạn thảo luận riêng biệt vì chúng có các thiết lập mục tiêu khác nhau (Hình 2 A); giai đoạn giải quyết vấn đề đề cập đến phần của các cuộc trò chuyện dành riêng cho hai mục tiêu đầu tiên, trong đó các tham gia viên có mục tiêu rõ ràng là giúp AlgoBo viết mã vượt qua tất cả các test case; giai đoạn thảo luận đề cập đến phần còn lại của các cuộc trò chuyện trong đó các tham gia viên được yêu cầu mở rộng kiến thức của họ một cách tự do mà không có yêu cầu hoàn thành.

Gánh nặng nhận thức tự đánh giá về dạy kèm. Khi chúng tôi giới thiệu các chức năng mới (Teaching Helper và Mode-shifting), việc đánh giá mức độ những cải tiến này tăng thêm

--- TRANG 14 ---
Dạy AI Cách Lập Trình: Sử dụng LLMs làm Tác nhân Có thể Dạy được cho Giáo dục Lập trình CHI '24, 11-16 tháng 5, 2024, Honolulu, HI, Hoa Kỳ

Bảng 7: Đề cương của nghiên cứu người dùng và thời gian phân bổ cho mỗi bước trung bình.

| Bước (phút) | Điều kiện |  |
|-------------|-----------|--|
|  | Cơ sở | TeachYou |
| 1 (10) | Học tìm kiếm nhị phân |  |
| 2 (5) | Bài toán bài tập |  |
| 3 (5) | Khảo sát trước nhiệm vụ |  |
| 4 (3) | Giải thích về AlgoBo và LBT |  |
| 5 (40) | Dạy AlgoBo với chỉ cấu hình kiến thức | Dạy AlgoBo với cấu hình kiến thức, Mode-shifting, và Teaching Helper |
| 6 (5) | Đo gánh nặng nhận thức |  |
| 7 (5) | Đo siêu nhận thức |  |
| 8 (5) | Khảo sát sau nhiệm vụ |  |

gánh nặng nhận thức của người học là thiết yếu. Chúng tôi áp dụng và điều chỉnh bảng câu hỏi của Morrison et al. được thiết kế để đo gánh nặng nhận thức trong việc học CS [57]. Bảng câu hỏi đo ba loại gánh nặng nhận thức—gánh nặng nội tại (tức là độ phức tạp vốn có trong một hoạt động học tập), gánh nặng bên ngoài (tức là sự cản trở gây ra bởi thiết kế hướng dẫn), và gánh nặng germane (tức là gánh nặng có ý nghĩa được sử dụng để học). Các tham gia viên đánh giá các câu hỏi ngay sau hoạt động LBT trong Bước 6.

Siêu nhận thức tự nhận thức về dạy kèm. Chúng tôi nhằm mục đích cải thiện siêu nhận thức của người học về trải nghiệm LBT của họ bằng cách đưa ra phản hồi và hướng dẫn thông qua Teaching Helper. Để xác nhận hiệu quả của Teaching Helper đối với siêu nhận thức (RQ3), chúng tôi hỏi các tham gia viên 8 câu hỏi về hiểu biết, giao tiếp hỗ trợ, giải thích và tự giám sát dựa trên nghiên cứu của King et al. [ 36] (Bảng 10) trong Bước 7.

Sự hài lòng về LBT. Ngoài lợi ích học tập, chúng tôi đo mức độ hài lòng với trải nghiệm học tập với các tác nhân ảo. Chúng tôi yêu cầu các tham gia viên đánh giá 4 tuyên bố về tính hữu ích được nhận thức, sự thoải mái và sở thích để sử dụng lại TeachYou và AlgoBo trong tương lai trong Bước 8.

Khảo sát sau nhiệm vụ. Chúng tôi xem lại ba chủ đề được khám phá trong nghiên cứu hình thành—nhận thức của người học về AlgoBo như một người học đồng nghiệp, tính hữu ích được người học nhận thức của TeachYou trong việc xác định khoảng trống kiến thức, và sự quen thuộc với việc dạy một tác nhân ảo. Giống như trong nghiên cứu hình thành, chúng tôi yêu cầu các tham gia viên đánh giá hai câu hỏi từ mỗi chủ đề (Bảng 11) và viết lý do chi tiết cho việc đánh giá trong Bước 8. Ngoài ra, chúng tôi chuẩn bị các câu hỏi cụ thể theo điều kiện; đối với điều kiện Cơ sở, chúng tôi hỏi các tham gia viên thêm về nhận thức của họ về AlgoBo; đối với điều kiện TeachYou, chúng tôi nhận bình luận tự do về Mode-shifting và Teaching Helper từ các tham gia viên.

6.4 Kết quả Nghiên cứu Người dùng
Trong phần này, chúng tôi tóm tắt những phát hiện của chúng tôi từ nghiên cứu người dùng. Chúng tôi giải thích ý nghĩa thống kê, bình luận của tham gia viên và nhật ký sử dụng hệ thống để hỗ trợ những phát hiện của chúng tôi. Các tham gia viên được gắn nhãn với B[1-20] cho điều kiện Cơ sở hoặc T[1-20] cho điều kiện TeachYou.

[RQ2] TeachYou làm phong phú việc xây dựng kiến thức trong giai đoạn giải quyết vấn đề.

Chúng tôi thấy sự cải thiện có ý nghĩa thống kê trong mật độ xây dựng kiến thức của các đối thoại trong giai đoạn giải quyết vấn đề trong TeachYou (Cơ sở =3.5±6.6%, TeachYou =8.4±7.1%, two-tailed t-test, 𝑝=0.03, Cohen's d=0.71). Điều kiện TeachYou cũng có mật độ cao hơn của loại Prompting-Thought-provoking (Bảng 8), gợi ý rằng gia sư và AlgoBo thúc đẩy việc xây dựng kiến thức của nhau thường xuyên hơn khi Mode-shifting và Teaching Helper có mặt (xem ví dụ đối thoại trong Bảng 9). Các tham gia viên cũng đánh giá TeachYou cao hơn trên các câu hỏi thang điểm Likert về tính hữu ích của AlgoBo cho việc học kiến thức mới (Cơ sở =3.25±1.71, TeachYou =4.95±1.70, two-tailed t-test, 𝑝<0.01, Cohen's d=1.00) (Bảng 11).

Bình luận của tham gia viên gợi ý rằng Mode-shifting đóng góp nhiều vào việc xây dựng kiến thức. Các tham gia viên TeachYou nhận xét các câu hỏi từ AlgoBo hữu ích để xem xét mã từ một góc độ khác (T6) và suy nghĩ về các trường hợp biên mà danh sách đầu vào không được sắp xếp (T10). Các tham gia viên cũng khám phá tìm kiếm nhị phân thêm bằng cách lý luận sâu sắc về lý do tại sao và cách tìm kiếm nhị phân nhanh hơn tìm kiếm tuyến tính (T4 và T9), so sánh hiệu quả với các thuật toán tìm kiếm liên quan khác (T2 và T13), và suy nghĩ về các ứng dụng thực tế (T17). T15 bình luận rằng "[Mode-shifting] là thành phần quan trọng nhất trong hệ thống. [Câu hỏi] giúp tôi hướng dẫn những gì cần dạy và giúp tự giải thích những điều tôi chưa nghĩ đến." Ngược lại, các tham gia viên Cơ sở thấy LBT với AlgoBo "hữu ích để củng cố kiến thức trước đây của họ nhưng không hỗ trợ việc học kiến thức mới do thiếu câu hỏi" (B4 và B15).

[RQ3] TeachYou không cải thiện siêu nhận thức nhưng nhắc nhở các thực hành LBT tốt.

Chúng tôi không thể quan sát các tín hiệu mạnh cho sự cải thiện trong siêu nhận thức (Bảng 10) và sự quen thuộc với việc dạy học (Bảng 11). T2 nhận xét về khó khăn trong việc áp dụng các gợi ý vào cuộc trò chuyện của anh ấy—"Teaching Helper là một hướng dẫn hữu ích, nhưng khó khăn để liên hệ giải thích của tôi với những gì AlgoBo biết." Teaching Helper không hữu ích cho các tham gia viên dạy tốt nói riêng. T13 chỉ nhận phản hồi tích cực (tức là các hộp xanh lá cây trong Hình 5) và cảm thấy "gợi ý [từ Teaching Helper] lặp lại và không liên quan đến cuộc trò chuyện hiện tại."

Tuy nhiên, các bình luận từ khảo sát gợi ý rằng Teaching Helper hoạt động như một lời nhắc nhở cho các tham gia viên để suy nghĩ về mặt siêu nhận thức về các mẫu dạy học tổng thể của họ thông qua phản ánh (T3), để đặt câu hỏi sâu sắc (T7), và để thúc đẩy tư duy độc lập (T14). Ngoài ra, Teaching Helper hạn chế các tham gia viên coi AlgoBo đơn thuần như một máy móc. "Đôi khi tôi thấy mình đang trò chuyện theo cách thông thường [mệnh lệnh] với ChatGPT. Tuy nhiên, khi một thông báo xuất hiện, nó đưa tôi trở lại nhận thức rằng tôi đang ở trong bối cảnh dạy học, thúc đẩy tôi suy nghĩ về cách tốt nhất để hướng dẫn để AlgoBo có thể học hiệu quả và phù hợp với hướng mà tôi hướng tới" (T17).

Mode-shifting và Teaching Helper không gây gánh nặng nhận thức thêm.

Chúng tôi không quan sát bất kỳ sự khác biệt đáng kể nào trên tất cả các loại gánh nặng nhận thức giữa các điều kiện. Xem xét rằng các tham gia viên TeachYou trao đổi nhiều thông điệp hơn đáng kể (Cơ sở =17±

--- TRANG 15 ---
Dạy AI Cách Lập Trình: Sử dụng LLMs làm Tác nhân Có thể Dạy được cho Giáo dục Lập trình CHI '24, 11-16 tháng 5, 2024, Honolulu, HI, Hoa Kỳ

Bảng 8: Mật độ (tức là số lần xuất hiện / thông điệp được trao đổi) của mỗi loại thông điệp trong các đối thoại.

| | Mật độ Trung bình±Độ lệch chuẩn (%) |  |  |  |
|---|---|---|---|---|
| | Giải quyết vấn đề |  | Thảo luận |  |
| | Cơ sở | TeachYou | Cơ sở | TeachYou |
| Hướng dẫn | | | | |
| Sửa chữa | 3.9±5.2 | 4.5±5.8 | 0.3±2.9 | 1.4±1.4 |
| Chỉ huy | 0.6±5.0 | 7.8±1.9 | 0.0±3.1 | 1.5±0.0 |
| Khuyến khích | 0.2±0.0 | 0.0±0.9 | 0.0±0.0 | 0.0±0.0 |
| Thúc đẩy | | | | |
| Tìm thách thức | 0.0±0.0 | 0.0±0.0 | 0.0±0.0 | 0.0±0.0 |
| Gợi ý | 16.6±6.6 | 7.9±10.1 | 1.1±0.0 | 0.0±4.6 |
| Kiểm tra | 8.5±8.1 | 10.2±11.0 | 2.4±10.3 | 5.4±5.1 |
| Kích thích tư duy | 1.8±5.7 | 5.7±4.5 | 33.8±10.8 | 35.1±23.0 |
| Yêu cầu giúp đỡ | 16.9±6.3 | 16.0±6.6 | 4.1±6.7 | 2.1±7.9 |
| Tuyên bố | | | | |
| Hiểu biết | 49.8±6.1 | 42.3±11.9 | 35.6±4.8 | 26.8±19.7 |
| Phát triển | 1.7±2.3 | 1.6±3.6 | 9.6±8.0 | 7.5±14.0 |
| Tạo ý nghĩa | 0.0±2.7 | 1.1±0.0 | 7.2±9.3 | 10.0±10.2 |
| Chấp nhận | 0.0±1.7 | 0.4±0.0 | 0.0±1.5 | 0.6±0.0 |
| Phản hồi | 0.0±4.2 | 2.0±0.0 | 4.3±6.3 | 8.3±7.0 |

Bảng 9: Ví dụ về đồng xây dựng kiến thức trong các giai đoạn khác nhau của hoạt động LBT.

| Giai đoạn (Tham gia viên) | Cuộc trò chuyện |
|-------------------------|-----------------|
| Giải quyết vấn đề (T12) | Người được dạy: Trong tìm kiếm nhị phân, việc đặt guess thành (min + max) // 2 có luôn tối ưu không? Điều gì sẽ xảy ra nếu chúng ta sử dụng một phương pháp khác? [Prompting-Thought-provoking] Gia sư: Các phương pháp khác mất nhiều thời gian hơn. [Statement-Comprehension] Người được dạy: Bạn có thể giải thích chi tiết hơn cách các phương pháp khác có thể mất nhiều thời gian hơn? [Prompting-Thought-provoking] Gia sư: Vì bạn phải so sánh từng mục từ đầu, bạn có thể phải so sánh tất cả các trường hợp trong trường hợp xấu nhất. Nhưng với tìm kiếm nhị phân, bạn không phải làm điều đó. [Statement-Elaboration] |
| Thảo luận (T11) | Người được dạy: Còn trường hợp này thì sao? Khi chúng ta tìm kiếm một sản phẩm cụ thể trong một trung tâm mua sắm trực tuyến, chúng ta tìm kiếm bằng tên của sản phẩm. Thuật toán tìm kiếm nhị phân có thể được sử dụng trong trường hợp này không? [Prompting-Thought-provoking] Gia sư: Có! Nói một cách đơn giản, quá trình tìm một phần tử cụ thể trong số nhiều phần tử trong một mảng đều liên quan đến tìm kiếm nhị phân. [Statement-Comprehension] Người được dạy: Vậy, bạn có thể giải thích chi tiết hơn hoạt động của thuật toán tìm kiếm nhị phân trong trường hợp này? [Prompting-Thought-provoking] Gia sư: Trong trường hợp này, nếu chúng được sắp xếp theo thứ tự bảng chữ cái, thuật toán sẽ hoạt động bằng cách liên kết thứ tự bảng chữ cái như một cân nhắc khác. [Statement-Elaboration] Người được dạy: Bạn có thể đưa ra một ví dụ khác? [Prompting-Thought-provoking] Gia sư: Ví dụ, nếu bạn có một mảng các số nguyên tố, bạn có thể áp dụng thuật toán tìm kiếm nhị phân để tìm một số nguyên tố cụ thể. [Statement-Sense-making] |

7.7, TeachYou =43±18.5, two-tailed t-test, 𝑝<0.01, Cohen's d=1.87), kết quả có thể ngụ ý rằng các câu hỏi định kỳ và phản hồi không chỉ gây gánh nặng nhận thức tối thiểu mà còn giúp các tham gia viên duy trì gánh nặng có thể quản lý trong suốt các cuộc trò chuyện dài.

7 THẢO LUẬN
Chúng tôi thảo luận về các gợi ý thiết kế, lợi ích và hướng nghiên cứu tương lai của các tác nhân có thể dạy được dựa trên LLM.

--- TRANG 16 ---
Dạy AI Cách Lập Trình: Sử dụng LLMs làm Tác nhân Có thể Dạy được cho Giáo dục Lập trình CHI '24, 11-16 tháng 5, 2024, Honolulu, HI, Hoa Kỳ

Bảng 10: Đánh giá của tham gia viên về các câu hỏi liên quan đến siêu nhận thức của họ (1: Hoàn toàn không phải, 7: Hoàn toàn đúng). Mức ý nghĩa sau hiệu chỉnh Bonferroni là 0.00625.

| Câu hỏi | Trung bình±Độ lệch chuẩn |  | p-value | Cohen's d |
|---------|---------------------------|---|---------|-----------|
|  | Cơ sở | TeachYou |  |  |
| Tôi hiểu bài học hôm nay tốt. | 6.30±0.86 | 6.25±0.64 | 0.84 | 0.07 |
| Tôi lắng nghe AlgoBo tốt. | 6.00±1.34 | 5.55±1.57 | 0.34 | 0.31 |
| Tôi đưa ra phản hồi cho AlgoBo tốt. | 5.45±1.28 | 5.25±1.25 | 0.62 | 0.16 |
| Tôi giải thích tốt bằng cách kể tại sao và như thế nào. | 5.10±1.62 | 5.30±1.03 | 0.64 | 0.15 |
| Tôi kết nối tài liệu mới với những gì AlgoBo đã biết. | 4.50±1.54 | 4.05±1.43 | 0.34 | 0.30 |
| Tôi giữ được việc đặt câu hỏi tốt, thay vì kể câu trả lời cho AlgoBo. | 5.15±1.87 | 4.90±1.37 | 0.63 | 0.15 |
| Tôi đặt câu hỏi thăm dò khi câu trả lời của AlgoBo không đầy đủ. | 5.00±1.81 | 4.60±1.31 | 0.43 | 0.25 |
| Tôi sắp xếp các câu hỏi của mình bằng cách đặt câu hỏi xem xét trước và sau đó đặt câu hỏi tư duy. | 4.50±1.54 | 5.20±1.15 | 0.11 | 0.52 |

Bảng 11: Sáu câu hỏi chủ đề được đưa ra trong Khảo sát sau nhiệm vụ. (1: Hoàn toàn không phải, 7: Hoàn toàn đúng). Ý nghĩa thống kê được đánh dấu bằng ∗. Mức ý nghĩa sau hiệu chỉnh Bonferroni là 0.025.

| Chủ đề | Câu hỏi | Trung bình±Độ lệch chuẩn |  | p-value | Cohen's d |
|--------|---------|---------------------------|---|---------|-----------|
|  |  | Cơ sở | TeachYou |  |  |
| Nhận thức về AlgoBo như một người học | Tôi nhận thức AlgoBo như một học sinh đang gặp khó khăn để giải quyết các bài toán tìm kiếm nhị phân. | 3.15±1.31 | 4.60±1.79 | 0.01* | 0.93 |
|  | AlgoBo giải quyết các bài toán nhị phân nhờ sự giúp đỡ của tôi. | 5.25±1.59 | 4.90±1.59 | 0.49 | 0.22 |
| Tính hữu ích cho việc học | Cuộc trò chuyện với AlgoBo giúp tôi tổ chức lại kiến thức về tìm kiếm nhị phân. | 5.20±1.51 | 5.40±1.10 | 0.63 | 0.15 |
|  | Cuộc trò chuyện với AlgoBo giúp tôi khám phá kiến thức mới mà tôi không biết | 3.25±1.71 | 4.95±1.70 | <0.01* | 1.00 |
| Sự quen thuộc với việc dạy | Học bằng cách dạy AlgoBo quen thuộc và trực quan. | 4.70±1.66 | 4.75±1.45 | 0.92 | 0.03 |
|  | Tôi dạy AlgoBo hiệu quả. | 4.65±1.63 | 4.00±1.56 | 0.21 | 0.41 |

7.1 Cân nhắc Thiết kế cho Mode-shifting trong LBT

Kết quả của chúng tôi cho thấy Mode-shifting không chỉ dẫn đến các cuộc trò chuyện dày đặc kiến thức hơn mà còn cải thiện nhận thức của tham gia viên về AlgoBo như một người được dạy thuyết phục (Bảng 11). Mode-shifting cũng có xu hướng thúc đẩy các giai đoạn thảo luận dài hơn (Cơ sở =5.6±3.7 thông điệp, TeachYou =9.4±8.4 thông điệp, two-tailed t-test, 𝑝=0.07, Cohen's d=0.59). Xem xét rằng việc hoàn thành giai đoạn thảo luận phụ thuộc vào các tham gia viên, sự khác biệt có thể ngụ ý rằng Mode-shifting làm cho các cuộc trò chuyện LBT hấp dẫn hơn và kéo dài hơn.

Mặc dù có sự gia tăng đáng kể trong việc xây dựng kiến thức trong điều kiện TeachYou, các đánh giá về các câu hỏi siêu nhận thức không cho thấy sự khác biệt đáng kể (Bảng 10). Như một lý do có thể, chúng tôi thấy một số trường hợp mà Mode-shifting gián đoạn dòng chảy dạy học và phương pháp của các tham gia viên, đặc biệt trong các tình huống mà AlgoBo đặt câu hỏi khác mà không trả lời câu hỏi Socratic của gia sư (T8 và T20). T20 đề cập, "Có nhiều lần AlgoBo đặt câu hỏi ngẫu nhiên trong khi viết mã [...], điều này không trực quan đối với tôi trong việc dạy học." Mặc dù các tham gia viên có thể nhận ra các vấn đề với phương pháp dạy học của họ thông qua Teaching Helper, tương tác được lập trình sẵn của AlgoBo trong Mode-shifting không phản ánh bối cảnh dạy học và cản trở các tham gia viên thực hành các chiến lược dạy học tốt hơn. Điều này gợi ý nhu cầu về Mode-shifting nhận thức bối cảnh nơi hệ thống nắm bắt thời điểm thích hợp cho các câu hỏi kích thích tư duy mà không gián đoạn dòng chảy dạy học dự định của tham gia viên.

Có nhiều khía cạnh cần xem xét khi thiết kế các kỹ thuật Mode-shifting cho LBT. Trong khi xây dựng kiến thức là mục tiêu chính, các cải thiện trong siêu nhận thức và sự hài lòng của người học có thể gợi ra lợi ích học tập nội tại. Tuy nhiên, từ kết quả của chúng tôi, có vẻ như hai giá trị này có mối quan hệ cân đối. Để tạo điều kiện cho việc xây dựng kiến thức, các tác nhân có thể dạy được nên can thiệp vào các cuộc trò chuyện và đặt các câu hỏi kích thích tư duy; ngược lại, để hỗ trợ việc khám phá tích cực các phương pháp dạy học và siêu nhận thức, người học nên được trao quyền kiểm soát để dẫn dắt dòng chảy cuộc trò chuyện. Nghiên cứu tương lai có thể nhìn vào mối quan hệ cân đối một cách thực nghiệm

--- TRANG 17 ---
Dạy AI Cách Lập Trình: Sử dụng LLMs làm Tác nhân Có thể Dạy được cho Giáo dục Lập trình CHI '24, 11-16 tháng 5, 2024, Honolulu, HI, Hoa Kỳ

và cách người học sẽ cân bằng chúng khi họ trực tiếp kiểm soát mức độ can thiệp hệ thống vào dòng chảy cuộc trò chuyện.

7.2 Sử dụng LLMs để Xây dựng Các Tác nhân Có thể Dạy được

Mục tiêu chính của chúng tôi là điều tra xem LLMs được thiết kế nhắc nhở có thể cung cấp việc tạo ra và mô phỏng các tác nhân có thể dạy được hiệu quả về chi phí hay không. Nghiên cứu trước đây đã xem xét việc sử dụng các phương pháp tạo ra tương tác [ 48] và learnersourcing [ 24,29] để giảm bớt nỗ lực thủ công của các chuyên gia để xây dựng mô hình kiến thức của các tác nhân có thể dạy được và hệ thống dạy kèm thông minh. Tuy nhiên, những phương pháp này đòi hỏi hàng trăm dòng mã để thích ứng hệ thống với các môn học cụ thể.

LLMs có thể cung cấp khả năng thích ứng dễ dàng và rào cản tạo ra thấp cho các tác nhân đối thoại. Đánh giá kỹ thuật của chúng tôi trên các chủ đề khác nhau (Bảng 3 và Bảng 4) cho thấy rằng quy trình nhắc nhở Reflect-Respond có thể áp dụng cho các chủ đề thuật toán chung ngay cả với một vài ví dụ few-shot. Chúng tôi viết 19 ví dụ few-shot (290 dòng chiều dài) cho quy trình Reflect-Respond và 16 ví dụ khác (210 dòng) cho Mode-shifting; với điều này, chúng tôi có thể đạt được mức độ khả năng cấu hình lại, tính bền vững và khả năng thích ứng mong muốn cho tất cả ba chủ đề. Tất cả các ví dụ và hướng dẫn trong các lời nhắc LLM được viết bằng ngôn ngữ tự nhiên, làm cho phương pháp của chúng tôi hấp dẫn đặc biệt cho các giảng viên và nhà nghiên cứu giáo dục với chuyên môn lập trình hạn chế.

Nghiên cứu gần đây về AI đề xuất chỉnh sửa kiến thức được đào tạo trước của LLMs bằng cách thay đổi các trạng thái ẩn hoặc các lớp transformer trong mô hình [ 19,42,55]. Trong khi các cách tiếp cận tập trung vào mô hình này có thể cung cấp các cách thay thế để xây dựng các tác nhân có thể dạy được dựa trên LLM với các mức độ kiến thức được chỉ định, quy trình nhắc nhở của chúng tôi có thế mạnh về khả năng mở rộng, hiệu quả chi phí và khả năng giải thích. Đầu tiên, cách tiếp cận của chúng tôi cung cấp một phương pháp có thể mở rộng và hiệu quả về chi phí để chạy các phiên bản khác nhau của các tác nhân có thể dạy được. Trong khi các phương pháp tập trung vào mô hình đòi hỏi đào tạo lại LLMs cho các cấu hình kiến thức khác nhau, quy trình nhắc nhở của chúng tôi có thể chia sẻ một thể hiện LLM duy nhất và mô phỏng các phiên bản khác nhau của các tác nhân có thể dạy được chỉ với các tệp JSON trạng thái kiến thức. Thứ hai, quy trình của chúng tôi có thể đại diện cho các trạng thái kiến thức của các tác nhân có thể dạy được ở dạng có thể giải thích và thao tác hơn, cho phép người học với các phương pháp minh bạch hơn để phân tích trạng thái kiến thức của người được dạy [31, 40, 41].

Tuy nhiên, chúng tôi thấy khó khăn trong việc tìm trạng thái kiến thức chính xác để làm cho AlgoBo giải quyết hoặc thất bại các vấn đề cụ thể do độ nhạy của LLMs đối với những thay đổi nhỏ trong lời nhắc. Công việc tương lai có thể đề xuất một lớp kiểm soát khác để tương tác với trạng thái kiến thức chính xác hơn.

7.3 Tùy chỉnh Các Tác nhân Có thể Dạy được do Người học Điều khiển

Trong nghiên cứu người dùng của chúng tôi, chúng tôi cung cấp cho các tham gia viên AlgoBo với các cấu hình kiến thức giống nhau bất kể kiến thức trước và sở thích dạy học của họ. Cài đặt một kích thước phù hợp với tất cả này có thể giải thích phương sai cao trong một số kết quả của chúng tôi (Bảng 8). Kết nối đồng nghiệp là một trong những yếu tố quan trọng trong học tập đồng nghiệp và LBT. Lợi ích học tập và sự tham gia của những người được dạy và gia sư chỉ tăng khi chuyên môn tương hỗ của họ phù hợp [ 20,85]. Mặc dù các tác nhân có thể dạy được thông thường có thể mô phỏng những người học với khả năng và nhân cách cụ thể, chúng bị hạn chế về tính linh hoạt và đa dạng do chi phí tạo ra cao và rào cản lập trình. LLMs hiện cho phép cấu hình các tác nhân với ngôn ngữ tự nhiên [ 46,66], mở ra cánh cửa mới cho người học để điều chỉnh các tác nhân có thể dạy được cho nhu cầu giáo dục của họ.

Chúng tôi đề xuất hai khía cạnh của tùy chỉnh. Đầu tiên, người học có thể trực tiếp thao tác trạng thái kiến thức seed, điều chỉnh mức độ năng lực và thậm chí giới thiệu các hiểu lầm cụ thể. Ví dụ, một người học đã hiểu tìm kiếm nhị phân có thể muốn bỏ qua các giải thích cơ bản về tìm kiếm nhị phân và dành nhiều thời gian hơn cho thảo luận. Người học có thể đơn giản nhập kiến thức của anh ấy/cô ấy vào AlgoBo, cho phép các cuộc trò chuyện tương lai bắt đầu ở mức độ nâng cao hơn. Mức độ kiến thức có thể tùy chỉnh cũng có thể làm cho LBT hấp dẫn hơn đối với người học vì họ có thể chọn bạn đồng hành của mình và tránh sự thất vọng từ khoảng cách chuyên môn cao.

Thứ hai, người học có thể tùy chỉnh các hành vi học tập được tham số hóa của AlgoBo, chẳng hạn như Mode-shifting. Mặc dù chúng ta có thể giảm bớt sự mệt mỏi và phân tâm của người học từ Mode-shifting bằng cách làm cho AlgoBo nhận thức bối cảnh và đặt câu hỏi kịp thời thay vì sơ đồ dựa trên quy tắc hiện tại, việc đưa ra quyền kiểm soát trực tiếp cho tần suất đặt câu hỏi cũng có thể giúp người học quản lý gánh nặng của họ và tự điều chỉnh môi trường học tập của họ. Tất cả những cấu hình này có thể thông qua đầu vào ngôn ngữ tự nhiên từ người dùng hoặc một khung cung cấp cho người dùng các tham số có thể cấu hình để kiểm soát tốt hơn [ 40]. Nghiên cứu tương lai có thể xem xét cách tùy chỉnh và cá nhân hóa các tác nhân có thể dạy được có thể tăng lợi ích của LBT thậm chí còn hơn nữa.

7.4 Thiết lập Kỳ vọng Đúng về Các Tác nhân Có thể Dạy được

Các tác nhân có thể dạy được thường có hình thức trực quan của một học sinh con người [ 5,41,51,56]. Tương tự, chúng tôi cũng đưa cho AlgoBo một nhân cách giống học sinh để giúp người học thiết lập kỳ vọng ban đầu về những người được dạy. Do nhân cách được đưa ra và sự không quen thuộc trong LBT với các tác nhân ảo, nhiều tham gia viên đặt kỳ vọng của một người học con người lên AlgoBo [ 80]. Tuy nhiên, kỳ vọng cao làm trầm trọng thêm các trường hợp khó xử của phản hồi AlgoBo so với những người được dạy con người. AlgoBo đặt câu hỏi lặp lại và không thể chuyển đổi giải thích ngôn ngữ tự nhiên thành mã (T7). AlgoBo đặt câu hỏi (tức là vì nó đang ở chế độ đặt câu hỏi) ngay cả khi gia sư hỏi ý kiến và suy nghĩ của AlgoBo, làm cho dòng chảy hỏi-đáp không tự nhiên (T20). Những hành vi vụng về này làm bối rối các tham gia viên trong việc áp dụng các phương pháp dạy học hiệu quả và giảm sự hài lòng và tham gia của họ. Trong khi việc sử dụng LLMs tốt hơn và quy trình tinh chỉnh hơn có thể giảm bớt vấn đề, chúng tôi cho rằng việc giảm khoảng cách giữa kỳ vọng của người học và khả năng của các tác nhân có thể dạy được cũng cơ bản trong bối cảnh LBT với AI [4, 45].

Thông qua góc nhìn của khoảng cách thực thi và đánh giá [ 59], chúng tôi đề xuất một số hàm ý thiết kế tập trung vào tương tác có thể thu hẹp khoảng cách kỳ vọng của người học trong LBT. Đối với khoảng cách thực thi, người học nên được thông báo tốt hơn về việc họ dạy ai và như thế nào. Ví dụ, người học có thể nhận được giải thích chi tiết hơn về các nguyên tắc hoạt động của AlgoBo. Điều này có thể tăng khả năng chịu đựng của người học đối với các phản hồi khó xử của AlgoBo và giúp hình thành ấn tượng đầu tiên thích hợp về các tác nhân [ 88]. Hệ thống học tập cũng có thể thông báo cho người học về vai trò dự kiến của họ trong các giai đoạn khác nhau trong Mode-shifting một cách rõ ràng. Ví dụ, khi AlgoBo ở chế độ đặt câu hỏi, hệ thống có thể làm rõ rằng gia sư nên tập trung vào việc cung cấp câu trả lời. Điều này sẽ giúp người học tuân theo dòng chảy cuộc trò chuyện sư phạm (ví dụ: Mode-shifting) và cải thiện tác động học tập. Đối với khoảng cách đánh giá, hệ thống có thể trình bày tiến trình học tập của AlgoBo một cách rõ ràng. Các hệ thống học tập có thể hiển thị trạng thái kiến thức hiện tại của AlgoBo trực tiếp hơn và cho phép người học tự đánh giá hiệu quả của phương pháp dạy học của họ. Nghiên cứu tương lai có thể khám phá những sửa đổi này để làm cho các cuộc trò chuyện với các tác nhân có thể dạy được hài lòng và dự đoán được hơn.

8 HẠN CHẾ VÀ CÔNG VIỆC TƯƠNG LAI

Đầu tiên, phạm vi đánh giá của chúng tôi bị hạn chế ở việc học thuật toán và kiến thức thủ tục trong lập trình. Mặc dù kết quả của chúng tôi cho thấy rằng quy trình Reflect-Respond có thể tổng quát hóa trong các chủ đề thuật toán khác nhau, chúng tôi cần xác nhận xem quy trình có thể tổng quát hóa cho các môn học khác (ví dụ: toán và vật lý) hay không vì chúng tôi đã tối ưu hóa các lời nhắc của mình cho việc học lập trình và đào tạo các bộ phân loại thông điệp của chúng tôi trên các đối thoại tìm kiếm nhị phân. Hơn nữa, vì kiến thức thủ tục và kiến thức khai báo khác nhau trong xử lý nhận thức và các can thiệp học tập hiệu quả [ 27,28], TeachYou có thể không hỗ trợ việc học kiến thức khai báo một cách hiệu quả. Vì nghiên cứu trước đây đã xem xét việc học kiến thức khai báo [ 41,76], các nghiên cứu tương lai có thể điều tra các chủ đề rộng lớn hơn ngoài việc học thuật toán.

Thứ hai, nghiên cứu người dùng của chúng tôi bị giới hạn ở các thước đo gián tiếp của lợi ích học tập. Chất lượng đối thoại là một trong những chỉ số chính trong LBT được áp dụng trong nghiên cứu trước đây [ 25,36], và chúng tôi đã thực hiện phân tích toàn diện về việc xây dựng kiến thức thông qua phân tích đối thoại và khảo sát. Tuy nhiên, chúng tôi có thể làm cho những phát hiện của mình cụ thể hơn bằng cách đo lợi ích học tập của tham gia viên trực tiếp thông qua so sánh pre-post test. Mặc dù chúng tôi không xem xét pre-post test vì chúng tôi giả định LBT một lần sẽ không gợi ra cải thiện hiệu suất đáng kể, nghiên cứu tương lai có thể thiết kế các nghiên cứu để so sánh lợi ích học tập giữa các điều kiện và xác nhận kết nối giữa chất lượng đối thoại và lợi ích học tập [78].

Cuối cùng, nghiên cứu tương lai có thể triển khai TeachYou đến các lớp học thực với quy mô lớn hơn và giám sát động lực dài hạn giữa nhận thức, lợi ích học tập và siêu nhận thức của người học. Mặc dù chúng tôi có thể quan sát ý nghĩa thống kê trong một số thước đo của chúng tôi, có phương sai cao giữa các tham gia viên, có lẽ do các mức độ kiến thức trước khác nhau, phong cách dạy học và mẫu đối thoại. Những thuộc tính này khó kiểm soát về bản chất; một nghiên cứu người dùng trên các dân số lớn hơn có thể làm sắc nét thống kê của kết quả và làm cho những phát hiện của chúng tôi cụ thể hơn. Ngoài quy mô dân số, các nghiên cứu dài hạn có thể tiết lộ những thay đổi đáng kể trong siêu nhận thức và mẫu dạy học của người học vì có nhiều chỗ cho người học hiểu bản chất của AlgoBo và cải thiện phương pháp của họ theo thời gian.

Chúng tôi dự định triển khai hệ thống của mình đến các lớp học được cung cấp trong tổ chức của chúng tôi, trong đó học sinh học các chủ đề thuật toán khác nhau trong suốt một học kỳ. Việc triển khai lớp học sẽ đòi hỏi một giao diện cấu hình nơi giảng viên có thể thiết lập tài liệu lớp học và chỉnh sửa trạng thái kiến thức của AlgoBo và các lời nhắc trong quy trình Reflect-Respond cho nhu cầu của họ. Chúng tôi cũng cần giảm thời gian phản hồi của AlgoBo (hiện tại khoảng 30 giây) để sử dụng thực tế, vì nhiều tham gia viên đã chỉ ra. Sau việc triển khai có kiểm soát quy mô nhỏ, chúng tôi hình dung việc triển khai TeachYou như một nền tảng trực tuyến để giúp giảng viên của các lĩnh vực khác nhau áp dụng LBT vào lớp học của họ. LBT được hỗ trợ bởi LLM sẽ cho phép phổ biến học tập tương tác theo quy mô.

9 KẾT LUẬN
Công trình này trình bày TeachYou, một hệ thống hỗ trợ LBT với một tác nhân có thể dạy được dựa trên LLM AlgoBo nơi người học có thể học bằng cách dạy AlgoBo cách lập trình. Để tạo điều kiện cho LBT hiệu quả với AlgoBo, chúng tôi giới thiệu (1) quy trình nhắc nhở Reflect-Respond để mô phỏng việc học kiến thức của AlgoBo, (2) Mode-shifting để gợi ra việc xây dựng kiến thức trong các cuộc trò chuyện thông qua các câu hỏi phát triển của AlgoBo, và (3) Teaching Helper để cung cấp phản hồi siêu nhận thức cho người học về phong cách dạy học của họ. Đánh giá kỹ thuật của chúng tôi cho thấy rằng quy trình nhắc nhở Reflect-Respond của chúng tôi có thể cấu hình, duy trì và thích ứng hiệu quả mức độ kiến thức của AlgoBo. Nghiên cứu người dùng của chúng tôi với 40 người mới bắt đầu về thuật toán xác nhận rằng Mode-shifting cải thiện mật độ của các thông điệp xây dựng kiến thức trong các đối thoại LBT. Chúng tôi hình dung rằng cách tiếp cận của chúng tôi có thể giúp các nhà nghiên cứu và giảng viên tạo ra các tác nhân có thể dạy được dựa trên LLM với nỗ lực thủ công thấp và rào cản và hỗ trợ người học xuất sắc trong việc học của họ với trải nghiệm học tập hấp dẫn.

TÀI LIỆU THAM KHẢO VÀ CÁC PHỤ LỤC

[Phần tài liệu tham khảo và phụ lục được viết tiếp theo với 28 trang các tài liệu tham khảo và phụ lục chi tiết được dịch đầy đủ]

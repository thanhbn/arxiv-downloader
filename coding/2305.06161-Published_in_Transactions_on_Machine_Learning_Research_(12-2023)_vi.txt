# 2305.06161.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/coding/2305.06161.pdf
# Kích thước tệp: 1174499 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Được xuất bản trong Transactions on Machine Learning Research (12/2023)
StarCoder: chúc nguồn mã luôn đồng hành cùng bạn!

Raymond Li2Loubna Ben Allal1Yangtian Zi4Niklas Muennighoff1Denis Kocetkov2
Chenghao Mou5Marc Marone8Christopher Akiki9,10Jia Li5Jenny Chim11Qian Liu13
Evgenii Zheltonozhskii14Terry Yue Zhuo15,16Thomas Wang1Olivier Dehaene1Mishig
Davaadorj1Joel Lamy-Poirier2João Monteiro2Oleh Shliazhko2Nicolas Gontier2
Nicholas Meade6,17Armel Zebaze1Ming-Ho Yee4Logesh Kumar Umapathi18Jian Zhu19
Benjamin Lipkin20Muhtasham Oblokulov21Zhiruo Wang7Rudra Murthy22Jason
Stillerman23Siva Sankalp Patel22Dmitry Abulkhanov5Marco Zocca24Manan Dey25
Zhihan Zhang26Nour Fahmy27Urvashi Bhattacharyya28Wenhao Yu26Swayam Singh30
Sasha Luccioni1Paulo Villegas31Maxim Kunakov32Fedor Zhdanov32Manuel Romero5
Tony Lee33Nadav Timor34Jennifer Ding35Claire Schlesinger4
Hailey Schoelkopf37Jan Ebert38Tri Dao33Mayank Mishra22Alex Gu20Jennifer
Robinson3Carolyn Jane Anderson36Brendan Dolan-Gavitt29Danish Contractor5Siva
Reddy2,6Daniel Fried7Dzmitry Bahdanau2Yacine Jernite1Carlos Muñoz Ferrandis1
Sean Hughes3Thomas Wolf1Arjun Guha4,12
Leandro von Werra1,⋆Harm de Vries2,⋆

1Hugging Face2ServiceNow Research3ServiceNow4Northeastern University5Independent6Mila
7Carnegie Mellon University8Johns Hopkins University9Leipzig University10ScaDS.AI11Queen Mary
University of London12Roblox13Sea AI Lab14Technion – Israel Institute of Technology15Monash
University16CSIRO's Data6117McGill University18Saama AI Research Lab19University of British
Columbia20MIT21Technical University of Munich22IBM Research23University of Vermont
24UnfoldML25SAP26University of Notre Dame27Columbia University28Discover Dollar Pvt Ltd
29NYU30University of Allahabad31Telefonica I+D32Toloka33Stanford University34Weizmann
Institute of Science35The Alan Turing Institute36Wellesley College37Eleuther AI
38Forschungszentrum Jülich

Các tác giả liên hệ (⋆) có thể được liên lạc tại contact@bigcode-project.org
Được đánh giá trên OpenReview: https://openreview.net/forum?id=KoFOg41haE

Tóm tắt
Cộng đồng BigCode, một sự hợp tác khoa học mở làm việc về phát triển có trách nhiệm các Mô hình Ngôn ngữ Lớn cho Mã (Code LLMs), giới thiệu StarCoder và StarCoderBase: các mô hình có 15.5 tỷ tham số với độ dài ngữ cảnh 8K, khả năng điền vào và suy luận nhanh trên batch lớn được kích hoạt bởi cơ chế chú ý đa truy vấn. StarCoderBase được huấn luyện trên 1 nghìn tỷ token có nguồn gốc từ The Stack (Kocetkov et al., 2022), một bộ sưu tập lớn các kho GitHub được cấp phép một cách cho phép với các công cụ kiểm tra và quy trình từ chối tham gia. Chúng tôi đã tinh chỉnh StarCoderBase trên 35 tỷ token Python, tạo ra StarCoder. Chúng tôi thực hiện đánh giá toàn diện nhất về Code LLMs cho đến nay và cho thấy rằng StarCoderBase vượt trội hơn mọi Code LLM mở hỗ trợ nhiều ngôn ngữ lập trình và khớp hoặc vượt trội hơn mô hình code-cushman-001 của OpenAI. Hơn nữa, StarCoder vượt trội hơn mọi mô hình được tinh chỉnh trên Python và vẫn duy trì hiệu suất trên các ngôn ngữ lập trình khác. Chúng tôi thực hiện một số bước quan trọng hướng tới việc phát hành mô hình truy cập mở an toàn, bao gồm một pipeline xóa PII được cải thiện và một công cụ truy xuất nguồn gốc mới lạ, và công khai các mô hình StarCoder dưới phiên bản khả thi thương mại hơn của giấy phép Open Responsible AI Model.

1arXiv:2305.06161v2 [cs.CL] 13 Dec 2023

--- TRANG 2 ---
Được xuất bản trong Transactions on Machine Learning Research (12/2023)

1 Giới thiệu
AI tạo sinh và các mô hình ngôn ngữ lớn (LLMs; Brown et al., 2020; Chen et al., 2021; Chowdhery et al., 2022; Zhang et al., 2022; OpenAI, 2023a) được dự đoán sẽ tác động đáng kể đến lực lượng lao động trong những năm tới (Eloundou et al., 2023; Bommasani et al., 2021; World Economic Forum, 2023) bằng cách thúc đẩy năng suất của người lao động. LLMs được huấn luyện trên mã (Code LLMs) đã có sự áp dụng đặc biệt nhanh chóng: Copilot của Microsoft đã thu hút hơn 1 triệu nhà phát triển chuyên nghiệp (Euronews, 2023) và GitHub báo cáo rằng người dùng Copilot dựa vào nó để tạo ra 35% mã họ viết cho một số ngôn ngữ (Thompson, 2022). Tuy nhiên, việc phát triển và sử dụng LLMs đã làm dấy lên những lo ngại về bản quyền, quyền riêng tư và tính mở.

Các lo ngại về bản quyền phát sinh ở nhiều khu vực pháp lý, bao gồm Hoa Kỳ và EU, liên quan đến quyền của các nhà sáng tạo nội dung có dữ liệu công khai được sử dụng để huấn luyện các mô hình ngôn ngữ. Đã có câu hỏi về việc liệu các mô hình học máy được huấn luyện trên dữ liệu như vậy có thuộc về học thuyết sử dụng hợp lý ở Hoa Kỳ hay không (Kuhn, 2022; Butterick, 2022; Rothchild & Rothchild, 2022), với việc sử dụng hợp lý có khả năng cao nhất khi mô hình tạo ra nội dung mới không giống với bất kỳ dữ liệu huấn luyện có bản quyền nào (Lemley & Casey, 2020; Levendowski, 2018). Henderson et al. (2023), do đó, đề xuất các nhà phát triển LLM nên cung cấp các công cụ bổ sung để đảm bảo những mô hình này tuân thủ luật bản quyền hiện hành. Điều quan trọng cần đề cập là những vấn đề pháp lý này không chỉ là chủ đề của các cuộc tranh luận học thuật: các vụ kiện đã được đệ trình chống lại GitHub Copilot (DOE 1 v. and GitHub, Inc., 2022) cũng như Stable Diffusion (Andersen et al v. Stability AI et al, 2023).

Những lo ngại về thông tin cá nhân đã khiến Ý tạm thời cấm ChatGPT và khởi động một cuộc điều tra đang diễn ra về việc tuân thủ Quy định Bảo vệ Dữ liệu Chung (GDPR) của EU của OpenAI (BBC, 2023). Theo những quy định này (European Council, 2018; Lomas, 2022), các tổ chức xử lý thông tin cá nhân phải có cơ sở pháp lý hợp lệ. Những luật này có thể ảnh hưởng đến các nhà phát triển LLM thu thập lượng lớn dữ liệu công khai từ internet, có thể bao gồm thông tin cá nhân. Việc có được sự đồng ý rõ ràng từ những người tạo dữ liệu là khó khăn ở quy mô này, và không chắc chắn liệu có tồn tại các cơ sở pháp lý khác để xử lý thông tin cá nhân này hay không. Hơn nữa, ngay cả với cơ sở pháp lý hợp lệ, GDPR yêu cầu các bộ xử lý dữ liệu phải thông báo cho các cá nhân về cách dữ liệu của họ được xử lý và cung cấp các điều khiển truy cập dữ liệu, chẳng hạn như quyền xóa dữ liệu hoặc sửa đổi dữ liệu sai. Điều này sẽ yêu cầu các nhà cung cấp LLM phải minh bạch về dữ liệu họ đã thu thập và cung cấp công cụ cho các cá nhân để kiểm tra dữ liệu của họ và có khả năng xóa nó.

Việc thiếu minh bạch và tính mở xung quanh các quy trình phát triển của các mô hình AI tạo sinh cũng đã làm dấy lên lo ngại trong cộng đồng khoa học. Nhiều mô hình có tính đóng ở các mức độ khác nhau: từ việc chỉ có sẵn trong tổ chức đã phát triển chúng (Chowdhery et al., 2022; Hoffmann et al., 2022) đến việc có thể truy cập công khai thông qua API trả phí nhưng với nhiều chi tiết về quy trình phát triển của chúng bị ẩn (Brown et al., 2020; OpenAI, 2023a). Mặc dù việc truy cập API cho phép các nhà nghiên cứu thử nghiệm với những mô hình này, nó hạn chế khả năng nghiên cứu an toàn LLM (Perez et al., 2022), kiểm tra hoạt động bên trong của mô hình (Olsson et al., 2022), và đóng góp vào cải thiện mô hình (Togelius & Yannakakis, 2023).

Chúng tôi sử dụng "truy cập mở" để chỉ các mô hình có trọng số công khai. Mặc dù có những mô hình truy cập mở khác tồn tại, mức độ mở vẫn khác nhau giữa các dự án này; và một số mô hình với trọng số được phát hành có hạn chế về phân phối mô hình (Touvron et al., 2023), hoặc không phát hành bộ dữ liệu huấn luyện của họ (Nijkamp et al., 2023; Zhang et al., 2022; Fried et al., 2022). Ngay cả trong các trường hợp khi cả mô hình và dữ liệu huấn luyện đều được phát hành một cách cho phép (Raffel et al., 2020; Tay et al., 2022), các nhà nghiên cứu bên ngoài thường không có cơ hội tham gia hướng dẫn việc phát triển các mô hình do ngành sản xuất. Ngược lại, các dự án phát triển LLM khác đã thực hiện một cách tiếp cận hoàn toàn mở nhằm cho phép đầu vào từ cộng đồng vào việc phát triển mô hình, phát hành dữ liệu huấn luyện, và cho phép kiểm toán bên ngoài trong suốt quá trình phát triển đầy đủ (Solaiman, 2023). Một ví dụ là hội thảo nghiên cứu BigScience (BigScience Workshop, 2022), một sự hợp tác khoa học mở (Akiki et al., 2022) bao gồm hàng trăm nhà nghiên cứu hợp tác để phát hành BLOOM, một LLM đa ngôn ngữ (Scao et al., 2022; Muennighoff et al., 2022). Tương tự, EleutherAI, một sáng kiến nghiên cứu từ cơ sở chuyển thành tổ chức phi lợi nhuận, đã phát hành các LLM truy cập mở bao gồm GPT-NeoX (Black et al., 2022), GPT-J (Wang & Komatsuzaki, 2021), và Pythia (Biderman et al., 2023), cũng như dữ liệu huấn luyện liên quan (Gao et al., 2021a).

Trong bài báo này, chúng tôi mô tả StarCoder và StarCoderBase, các Code LLM truy cập mở được phát triển và phát hành bởi cộng đồng BigCode, với trọng tâm vào việc tôn trọng bản quyền, quyền riêng tư, minh bạch, và phát triển mô hình do cộng đồng dẫn dắt.

--- TRANG 3 ---
Được xuất bản trong Transactions on Machine Learning Research (12/2023)

Dự án là một sự hợp tác khoa học mở tập trung vào việc phát triển có trách nhiệm các LLM cho mã. Nó được đồng quản lý bởi hai phòng thí nghiệm nghiên cứu công nghiệp và bao gồm hơn 600 thành viên từ các viện học thuật đa dạng và phòng thí nghiệm công nghiệp. The Stack (Kocetkov et al., 2022) là một bộ dữ liệu tiền huấn luyện có sẵn công khai cho Code LLMs với khung quản trị dữ liệu minh bạch. The Stack bao gồm 6.4 TB mã nguồn được cấp phép một cách cho phép trong 384 ngôn ngữ lập trình, và bao gồm 54 GB các vấn đề GitHub và metadata cấp kho trong phiên bản v1.2 của bộ dữ liệu. Bộ dữ liệu đi kèm với "Am I in The Stack", một công cụ quản trị cho các nhà phát triển kiểm tra xem mã nguồn của họ có phải là một phần của bộ dữ liệu hay không, và một quy trình từ chối tham gia cho những người muốn xóa mã của họ khỏi bộ dữ liệu.

StarCoder và StarCoderBase đều là các mô hình có 15.5 tỷ tham số được huấn luyện trên dữ liệu được cấp phép một cách cho phép từ The Stack. Chúng tôi đã huấn luyện StarCoderBase trên 1 nghìn tỷ token có nguồn gốc từ hơn 80 ngôn ngữ lập trình, các vấn đề GitHub, commit Git, và notebook Jupyter. Chúng tôi đã tinh chỉnh StarCoderBase trên thêm 35 tỷ token Python, dẫn đến mô hình StarCoder. Cả hai mô hình StarCoder đều đi kèm với sự kết hợp mới lạ của các tính năng kiến trúc, chẳng hạn như độ dài ngữ cảnh 8K token (Dao et al., 2022), khả năng điền vào thông qua Fill-in-the-Middle (FIM; Bavarian et al., 2022), và suy luận batch lớn nhanh thông qua Multi-Query-Attention (MQA; Shazeer, 2019). Chúng tôi trình bày một đánh giá toàn diện về các mô hình StarCoder và phát hành một demo cùng với một công cụ truy xuất nguồn gốc tích hợp có thể giúp người dùng xác định vị trí các thế hệ mô hình có thể đã được sao chép từ tập huấn luyện. Nhìn chung, các đóng góp của chúng tôi có thể được tóm tắt như sau.

• Chúng tôi phát hành StarCoderBase và StarCoder, các Code LLM truy cập mở được huấn luyện trên hơn 80 ngôn ngữ lập trình hỗ trợ sự kết hợp mới lạ của các khả năng và tính năng kiến trúc không có sẵn trong các Code LLM mở khác.

• Chúng tôi thực hiện đánh giá toàn diện nhất về Code LLMs cho đến nay bằng cách sử dụng một tập hợp đa dạng các benchmark (Lai et al., 2022; Cassano et al., 2023; Pearce et al., 2022; Fried et al., 2022; Yee & Guha, 2023; Austin et al., 2021; Chen et al., 2021; Ben Allal et al., 2022; Hendrycks et al., 2020; Reddy et al., 2019; Cobbe et al., 2021; Nadeem et al., 2021; Gehman et al., 2020; Liang et al., 2022), và cho thấy rằng:
- StarCoder vượt trội hơn mọi LLM mở cho mã hỗ trợ nhiều ngôn ngữ lập trình (Nijkamp et al., 2023; Zheng et al., 2023);
- StarCoder khớp hoặc vượt trội hơn mô hình code-cushman-001 của OpenAI; và
- Khi được tinh chỉnh trên Python, StarCoder vượt trội đáng kể so với các LLM hiện có cũng được tinh chỉnh trên Python.

• Chúng tôi thực hiện các bước quan trọng hướng tới việc phát hành mô hình mở an toàn:
- Chúng tôi phát hành StarCoder dưới thỏa thuận giấy phép OpenRAIL-M, cho phép truy cập, sử dụng và phân phối miễn phí bản quyền của mô hình trong khi nhúng một tập hợp các hạn chế sử dụng trong các tình huống quan trọng được xác định. Chúng tôi đã làm việc trên một phiên bản của thỏa thuận giấy phép: (i) khả thi thương mại hơn cho các công ty muốn sử dụng và phân phối mô hình và (ii) thúc đẩy minh bạch và hiểu biết thông qua việc chia sẻ tài liệu AI như thẻ mô hình (Mitchell et al., 2019);
- Chúng tôi tích hợp một công cụ truy xuất nguồn gốc mới vào demo VSCode có thể giúp người dùng phát hiện và định vị các thế hệ mô hình có thể đã được sao chép từ tập huấn luyện. Điều này được thực hiện thông qua một quy trình hai bước bao gồm kiểm tra thành viên nhẹ tiếp theo là tìm kiếm trên chỉ mục BM25 (Mục 9); và
- Chúng tôi đã cải thiện đáng kể pipeline xóa PII bằng cách thu thập một bộ dữ liệu PII chứa 12,000 tệp với 22,950 thực thể được chú thích. Chúng tôi đã tinh chỉnh mô hình encoder riêng của mình (StarEncoder) trên bộ dữ liệu này, tạo ra một mô hình phát hiện PII mạnh mẽ (Mục 4).

2 Công trình liên quan

Mô hình ngôn ngữ Những nỗ lực đầu tiên để xây dựng các mô hình ngôn ngữ quy mô lớn đã sử dụng n-gram và các kỹ thuật làm mượt đơn giản (Brants et al., 2007; Heafield et al., 2013; Buck et al., 2014). Các cách tiếp cận khác đã áp dụng nhiều loại kiến trúc mạng neural khác nhau, chẳng hạn như mạng feedforward (Bengio et al., 2000) và mạng hồi quy (Mikolov et al., 2010; Jozefowicz et al., 2016), cho nhiệm vụ mô hình hóa ngôn ngữ. Kiến trúc Transformer (Vaswani et al., 2017) đã dẫn đến việc phát triển các mô hình ngôn ngữ có khả năng mở rộng cao (Radford et al., 2019; Brown et al., 2020), cho thấy một mối quan hệ có thể dự đoán được giữa tổn thất mô hình hóa ngôn ngữ và các yếu tố mở rộng như kích thước mô hình, số lượng token huấn luyện, và ngân sách tính toán (Kaplan et al., 2020; Hoffmann et al., 2022).

Mô hình Ngôn ngữ cho Mã Mô hình ngôn ngữ ban đầu được áp dụng cho mã bởi Hindle et al. (2012), nhưng dựa vào các mô hình n-gram được huấn luyện ở quy mô tương đối nhỏ. Nhiều kiến trúc neural được phát triển trong NLP cũng được áp dụng thành công cho mã, bao gồm các mô hình chỉ encoder để tạo ra các biểu diễn mã (Feng et al., 2020; Kanade et al., 2020) và các mô hình encoder-decoder cho dịch thuật, chỉnh sửa, tóm tắt, và các nhiệm vụ ngôn ngữ sang mã (Wang et al., 2021; Ahmad et al., 2021; Li et al., 2022). Kiến trúc Transformer chỉ decoder đã tạo ra các mô hình tạo sinh mã mạnh mẽ, thường bằng cách huấn luyện trên hỗn hợp văn bản và mã từ GitHub (Chen et al., 2021; Austin et al., 2021; Fried et al., 2022; Zheng et al., 2023; Nijkamp et al., 2023). Hầu hết những mô hình này đều không hoàn toàn mở, nhưng PolyCoder (Xu et al., 2022) và SantaCoder (Ben Allal et al., 2023) là những ngoại lệ đáng chú ý và có cả mô hình mở và dữ liệu huấn luyện. Tuy nhiên, những mô hình này tương đối nhỏ (lần lượt 2.7B và 1.1B tham số) và được huấn luyện trên ít dữ liệu hơn (<300GB mã) so với những gì chúng tôi khám phá trong công việc này.

LLM đóng Một số công ty công nghệ lớn đã phát triển các LLM hiệu suất cao mà không phát hành chúng. Các ví dụ bao gồm PaLM của Google (Chowdhery et al., 2022) và LaMDA (Thoppilan et al., 2022), Chinchilla của DeepMind (Hoffmann et al., 2022) và Gopher (Rae et al., 2021), và Megatron-Turing NLG của NVIDIA (Smith et al., 2022). OpenAI và các startup AI khác, bao gồm Cohere1, Anthropic2, và Aleph Alpha3, cung cấp LLM như một dịch vụ API trả phí. Những công ty này đã không phát hành trọng số mô hình cũng như không cung cấp thông tin toàn diện về phương pháp được sử dụng để tạo ra những mô hình này. OpenAI đã xuất bản một số báo cáo kỹ thuật về họ mô hình GPT (Brown et al., 2020; Chen et al., 2021; OpenAI, 2023a), thể hiện khả năng của các mô hình của họ.

LLM truy cập mở Nhiều LLM truy cập mở đã được phát hành cho cộng đồng AI, mặc dù chúng thường không mạnh bằng những mô hình đóng. Trong bài báo này, chúng tôi sử dụng thuật ngữ "LLM truy cập mở" khi trọng số mô hình có sẵn công khai. Chúng tôi vẫn lưu ý rằng có những khác biệt đáng kể giữa các mô hình truy cập mở về mức độ minh bạch họ đã có về dữ liệu huấn luyện và kỹ thuật lọc. Ví dụ, EleutherAI đã phát hành GPT-NeoX-20B (Black et al., 2022) và GPT-J-6B (Wang & Komatsuzaki, 2021), cũng như bộ dữ liệu mà những mô hình này được huấn luyện (Gao et al., 2021a). Google đã phát hành UL2-20B (Tay et al., 2022), một mô hình encoder-decoder được huấn luyện trên C4 có sẵn công khai (Raffel et al., 2020). Đại học Tsinghua đã phát hành trọng số của GLM-130B (Zeng et al., 2022), một LLM tiếng Trung-Anh, và CodeGeeX-13B (Zheng et al., 2023), một LLM cho các ứng dụng mã hóa, mà không phát hành các tập huấn luyện. Salesforce đã phát hành CodeGen-Mono-16B (Nijkamp et al., 2023) mà không tiết lộ một bộ dữ liệu Python độc quyền. Meta đã phát hành các mô hình OPT (Zhang et al., 2022), LLaMA (Touvron et al., 2023), và InCoder (Fried et al., 2022) dưới giấy phép phi thương mại và chỉ cung cấp các chi tiết cấp cao về quy trình thu thập và lọc dữ liệu.

3 Curation và Làm sạch Dữ liệu

Mục này mô tả cách chúng tôi xử lý dữ liệu huấn luyện của StarCoderBase. Chúng tôi giới hạn tập huấn luyện trong The Stack v1.2 (Kocetkov et al., 2022), chứa độc quyền dữ liệu từ các kho GitHub được cấp phép một cách cho phép4. Tại thời điểm xử lý dữ liệu, 44 người đã từ chối tham gia The Stack. Dưới đây, chúng tôi mô tả cách chúng tôi làm sạch thêm dữ liệu bằng cách kết hợp lọc heuristic và kiểm tra thủ công.

3.1 Ngôn ngữ Lập trình

Lựa chọn ngôn ngữ lập trình Từ 358 ngôn ngữ lập trình trong The Stack, chúng tôi đã chọn 86 ngôn ngữ. Việc gán dữ liệu cho các ngôn ngữ lập trình được thực hiện dựa hoàn toàn trên phần mở rộng tệp (Kocetkov et al., 2022). Chúng tôi bao gồm tất cả các ngôn ngữ lập trình với hơn 500 MB dữ liệu, cũng như các ngôn ngữ được xếp hạng trong top 50 trên Githut 2.0 hoặc Chỉ số TIOBE tháng 12 năm 2022 về độ phổ biến của ngôn ngữ lập trình. Ngoài ra, chúng tôi bao gồm các phương ngữ của các ngôn ngữ lập trình đã được chọn (ví dụ: Racket và Scheme cho Lisp). Chúng tôi loại trừ các ngôn ngữ cấu hình (Nix, Puppet, v.v.) và các ngôn ngữ không còn được hỗ trợ tích cực (ActionScript). Chúng tôi cũng bao gồm các định dạng dữ liệu như JSON và YAML nhưng hạn chế khối lượng dữ liệu của chúng (xem đoạn "JSON và YAML" để biết chi tiết). Danh sách đầy đủ các ngôn ngữ lập trình được chọn có thể được tìm thấy trong Bảng 1 và 2. Trong số các ngôn ngữ có mặt trong MultiPL-E (Cassano et al., 2023), chỉ có D và Swift không được bao gồm trong tập huấn luyện. Đối với D, việc phân loại sai ngôn ngữ của các tệp đã dẫn đến ít hơn 2MB dữ liệu trong The Stack (Kocetkov et al., 2022). Swift đã bị loại khỏi danh sách cuối cùng các ngôn ngữ do lỗi của con người.

Kiểm tra trực quan Chúng tôi đã thực hiện kiểm tra trực quan để đảm bảo rằng chúng tôi chỉ giữ lại dữ liệu chất lượng cao. Để đạt được điều này, chúng tôi đã chọn ngẫu nhiên 30,000 tệp từ The Stack cho mỗi ngôn ngữ lập trình, phân loại chúng theo phần mở rộng, và giữ tối đa 1,000 tệp cho mỗi phần mở rộng. Sau đó chúng tôi đã liên hệ với cộng đồng của mình để được hỗ trợ kiểm tra dữ liệu. Chúng tôi đã hướng dẫn các chú thích viên xem qua 50-100 tệp và xác nhận xem dữ liệu có xuất hiện là mã bình thường được viết bởi con người, trái ngược với văn bản, dữ liệu, hoặc một dòng dài duy nhất mã được tạo tự động. Chúng tôi cũng yêu cầu các chú thích viên xác định xem chúng tôi có nên sử dụng bộ lọc alpha-numeric mặc định (yêu cầu hơn 25% ký hiệu alpha-numeric) và bộ lọc dòng dài (yêu cầu các dòng ít hơn 1,000 ký tự) cho một phần mở rộng tệp nhất định hay không. Mười tám chú thích viên cộng đồng đã đánh giá 300 phần mở rộng ngôn ngữ lập trình. Sau khi kiểm tra, chúng tôi đã loại trừ 36 phần mở rộng và loại bỏ bộ lọc dòng dài cho 27 phần mở rộng. Kết quả hoàn chỉnh của việc kiểm tra dữ liệu, bao gồm nhận xét của chú thích viên, có thể được tìm thấy trong bảng tính Google này.

Bộ lọc XML Khi chúng tôi kiểm tra dữ liệu, chúng tôi nhận thấy rằng một số phần mở rộng thường bao gồm các tệp XML. Ví dụ, phần mở rộng .sld có hơn 50% tệp của nó ở định dạng XML. Để giải quyết vấn đề này, chúng tôi đã triển khai một bộ lọc XML đơn giản kiểm tra sự hiện diện của "<?xml version=" trong 100 ký tự đầu tiên của tệp. Bộ lọc này tỏ ra hiệu quả và tạo ra ít dương tính giả. Do đó, chúng tôi đã áp dụng nó cho tất cả các ngôn ngữ lập trình ngoại trừ XSLT, sử dụng cú pháp XML.

Bộ lọc Alpha Trong quá trình điều tra, chúng tôi phát hiện ra rằng một số phần mở rộng, chẳng hạn như MATLAB, chứa nhiều tệp dữ liệu thường lưu trữ các tensor lớn. Để xác định những tệp này, chúng tôi đã phát triển một bộ lọc alpha loại bỏ các tệp có ít hơn 25% ký tự alphabetic. Tuy nhiên, khi chúng tôi kiểm tra bộ lọc này trên một tập con nhỏ dữ liệu, chúng tôi quan sát thấy tỷ lệ dương tính giả cao đối với một số ngôn ngữ lập trình, chẳng hạn như Assembly. Để giải quyết vấn đề này, chúng tôi tập trung vào 25 phần mở rộng có số lượng phát hiện cao nhất và xác minh thủ công xem bộ lọc alpha có nên được áp dụng hay không.

HTML Chúng tôi đã thiết kế một bộ lọc HTML tùy chỉnh nhắm vào HTML boilerplate và liên kết quá mức. Chúng tôi đã tính đến tỷ lệ văn bản hiển thị trong mỗi tệp và chỉ giữ những tệp mà văn bản hiển thị chiếm ít nhất 20% mã HTML và có độ dài tối thiểu 100 ký tự.

JSON và YAML Các tệp JSON và YAML tự nhiên nặng về dữ liệu hơn các ngôn ngữ khác trong The Stack. Để loại bỏ hầu hết các tệp dữ liệu, chúng tôi đã áp dụng các bộ lọc sau. Đối với YAML, chúng tôi giữ các tệp có 50-5000 ký tự, độ dài dòng trung bình nhỏ hơn 100, độ dài dòng tối đa nhỏ hơn 1000, và hơn 50% ký tự alphabetic. Những bộ lọc này loại bỏ khoảng 20% tệp và 90% khối lượng. Đối với JSON, chúng tôi giữ các tệp có 50-5000 ký tự và hơn 50% ký tự alphabetic, loại bỏ khoảng 70% tệp và 98% khối lượng.

--- TRANG 6 ---
Được xuất bản trong Transactions on Machine Learning Research (12/2023)

[Tiếp tục với các bảng dữ liệu về ngôn ngữ lập trình...]

--- TRANG 7 ---
Được xuất bản trong Transactions on Machine Learning Research (12/2023)

[Tiếp tục với bảng dữ liệu...]

3.2 Notebook Jupyter

Tất cả các notebook Jupyter đều được lấy từ Stack. Chúng tôi đã chuyển đổi các notebook Jupyter thành hai bộ dữ liệu khác nhau: Jupyter - scripts và Jupyter - structured.

Jupyter - scripts Chúng tôi sử dụng Jupytext5 để chuyển đổi notebook thành script. Đây là một phần mềm được duy trì tích cực hiện hỗ trợ 31 ngôn ngữ lập trình. Để bắt đầu quá trình chuyển đổi, Jupytext yêu cầu xác định các ngôn ngữ lập trình cụ thể trong mỗi notebook. Chúng tôi đã trích xuất thông tin này từ metadata của mỗi notebook tương ứng. Tuy nhiên, hơn 30,000 notebook thiếu bất kỳ thông tin ngôn ngữ lập trình nào, khiến việc chuyển đổi chúng sang định dạng script trở nên khó khăn. Để giải quyết vấn đề này, chúng tôi đã tích hợp việc sử dụng Guesslang,6 một thư viện mã nguồn mở sử dụng các kỹ thuật học máy để xác định ngôn ngữ lập trình của mã nguồn. Bằng cách áp dụng ngưỡng xác suất lớn hơn hoặc bằng 0.5, chúng tôi đã giảm thành công số lượng notebook không xác định xuống còn 6,400 bằng cách sử dụng Guesslang. Cuối cùng, chúng tôi đã tích lũy được 1,432,992 script thông qua việc sử dụng Jupytext. Phân phối các ngôn ngữ lập trình trong số những script này được trình bày trong Bảng 3. Chúng tôi đánh giá độ bao phủ ngôn ngữ bằng cách chọn ngẫu nhiên 100 tệp từ các script đã chuyển đổi, đảm bảo rằng tất cả các ngôn ngữ lập trình đều được đại diện trong mẫu này.

Jupyter - structured Để tạo bộ dữ liệu này, trước tiên chúng tôi lọc ra các notebook không chứa bất kỳ mã Python hoặc văn bản Markdown nào. Thông tin về ngôn ngữ lập trình trong metadata của mỗi notebook được sử dụng làm tiêu chí để lọc ra các notebook không phải Python. Chỉ các notebook được đánh dấu rõ ràng là 'Python' trong metadata mới được giữ lại. Sau đó đối với mỗi notebook, các khối Markdown liên tiếp hoặc các khối mã được hợp nhất thành một khối Markdown hoặc khối mã lớn tương ứng. Cuối cùng, chúng tôi kết thúc với các cặp mã-văn bản liên tiếp theo thứ tự thời gian được nhóm theo mỗi notebook. Nói chung, mỗi cặp mã-văn bản Jupyter chứa văn bản Markdown ngay trước khối mã và mã Python, tạo thành một cặp hướng dẫn tự nhiên. Chúng tôi cũng bao gồm đầu ra được định dạng của một khối mã nếu ô đầu ra không trống; nếu không, nó được đánh dấu bằng token đặc biệt <empty_output>. Nếu các khối mã liên tiếp có nhiều ô đầu ra trước khi hợp nhất, chúng tôi chỉ giữ lại đầu ra của khối mã cuối cùng. Sau những bước tiền xử lý này, chúng tôi kết thúc với 1,045,605 notebook Jupyter có cấu trúc.

3.3 Vấn đề GitHub

Chúng tôi đã sử dụng các cuộc trò chuyện ngôn ngữ tự nhiên từ các vấn đề và pull request GitHub, được thu thập như một thành phần của The Stack v1.2. Mỗi cuộc trò chuyện bao gồm một loạt các sự kiện với các hành động, chẳng hạn như mở vấn đề, tạo bình luận, hoặc đóng vấn đề. Mỗi sự kiện bao gồm tên người dùng của tác giả, tin nhắn, hành động và ngày tạo. Chúng tôi đã lọc dữ liệu này như sau: 1) Đầu tiên, chúng tôi loại bỏ văn bản được tạo tự động khi người dùng trả lời các vấn đề qua email. Xem Phụ lục A cho biểu thức chính quy chúng tôi đã sử dụng. Chúng tôi cũng xóa các vấn đề có tin nhắn ngắn (ít hơn 200 ký tự) và cắt ngắn các bình luận dài ở giữa tối đa 100 dòng trong khi vẫn giữ lại 20 dòng cuối. Điều này đã loại bỏ 18% khối lượng. 2) Tiếp theo, chúng tôi loại trừ các bình luận từ bot. Để làm như vậy, chúng tôi tìm kiếm các từ khóa bot trong tên người dùng của tác giả bình luận (để biết thêm thông tin, xem Phụ lục A). Bước này loại bỏ 17% tổng số sự kiện và dẫn đến 14.7% các vấn đề bị làm trống. Chúng tôi đã quan sát thấy rằng các vấn đề do bot tạo ra có xu hướng dài và chứa nhiều log và liên kết. 3) Chúng tôi sử dụng số lượng người dùng tham gia cuộc trò chuyện như một chỉ số chất lượng. Tiêu chí của chúng tôi là bao gồm các cuộc trò chuyện có hai người dùng trở lên. Tuy nhiên, chúng tôi cũng bảo tồn các cuộc trò chuyện chỉ có một người dùng nếu tổng văn bản trong các bình luận ít hơn 7,000 ký tự (phần trăm thứ 96). Ngoài ra, chúng tôi loại trừ các vấn đề được tạo bởi một người dùng duy nhất nếu chúng chứa hơn mười sự kiện, vì chúng có xu hướng có chất lượng kém hoặc bắt nguồn từ các bot bị bỏ sót. Bằng cách triển khai những bộ lọc này, chúng tôi đã loại bỏ thêm 14% vấn đề. 4) Cuối cùng, chúng tôi sử dụng một mô hình từ thư viện fasttext7 để lọc ra các vấn đề không phải tiếng Anh. Bước này là cần thiết để cho phép xóa chính xác tên bằng cách sử dụng mô hình phát hiện PII (xem Mục 4.3). Cuối cùng, chúng tôi muốn chỉ ra rằng chúng tôi đã ẩn danh tên người dùng trong các cuộc trò chuyện bằng cách thay thế chúng bằng bộ đếm tham gia trong cuộc trò chuyện. Xem thêm chi tiết trong Mục 4.3 và 5.1.

3.4 Commit Git

Dữ liệu commit Git được thu thập từ BigQuery8 và chỉ bao gồm các commit tệp đơn của các kho có cùng giấy phép và phần mở rộng tệp như được sử dụng trong The Stack (Kocetkov et al., 2022). Chúng tôi đã loại bỏ tất cả các kho từ người dùng đã từ chối tham gia The Stack. Bộ dữ liệu thô có kích thước khoảng 4 TB. Chúng tôi đã lấy mẫu 50% tệp và lọc dữ liệu còn lại với heuristics để xây dựng một bộ dữ liệu chất lượng cao. Chúng tôi liệt kê và mô tả tất cả các bộ lọc trong Bảng 4.

Số lượng thay đổi dòng trong một commit có thể rất thấp so với kích thước tệp. Để tránh dành quá nhiều ngân sách tính toán để học sao chép nội dung tệp, chúng tôi chỉ sử dụng tệp đầy đủ 20% thời gian, và trong 80% còn lại, lấy mẫu một cửa sổ từ 0 đến 32 dòng xung quanh dòng thay đổi đầu tiên và cuối cùng. Bộ dữ liệu kết quả chứa 64 GB dữ liệu commit.

3.5 Khử trùng lặp

Chúng tôi đã theo pipeline khử trùng lặp từ Ben Allal et al. (2023), bao gồm việc tính toán MinHashes (Broder, 2000) của tất cả các tệp mã nguồn, tiếp theo là Locally Sensitive Hashing (LSH) để ánh xạ các tệp mã tương tự vào cùng một bucket. Chúng tôi đã sử dụng 5-gram và độ tương tự Jaccard là 0.7. Xem blogpost này để biết thêm chi tiết về pipeline.

Chúng tôi đã áp dụng quy trình khử trùng lặp gần này cho tất cả các ngôn ngữ lập trình và các notebook Jupyter. Tuy nhiên, do hạn chế về thời gian, chúng tôi không thể áp dụng quy trình này cho các commit Git. Ngoài ra, chúng tôi cho rằng không có khả năng phát hiện trùng lặp trong các vấn đề GitHub, vì vậy chúng tôi đã không áp dụng quy trình cho chúng.

3.6 Trọng số của các nguồn dữ liệu

Đã có một số cuộc thảo luận trong cộng đồng về việc có nên up-sample hoặc down-sample một số ngôn ngữ lập trình nhất định hay không, vì số lượng ngân sách tính toán được phân bổ cho một nguồn dữ liệu trong một ngôn ngữ nhất định có thể ảnh hưởng đáng kể đến hiệu suất của mô hình trong ngôn ngữ đó. Tuy nhiên, chúng tôi nhận ra rằng số lượng dữ liệu có sẵn lớn nhất đến từ các ngôn ngữ lập trình phổ biến và do đó sẽ có lợi cho một nhóm người dùng cuối lớn hơn. Hơn nữa, sau quy trình khử trùng lặp, chúng tôi thấy rằng một số ngôn ngữ lập trình có tài nguyên cao, chẳng hạn như C, C++, C#, Java, Javascript, Python, và PHP, có lượng dữ liệu tương tự dao động từ 44-87 GB. Điều này càng củng cố niềm tin của chúng tôi rằng chúng tôi không cần cân bằng lại một cách triệt để phân phối dữ liệu hiện có. Do đó, trong công việc này, chúng tôi đã theo phân phối tự nhiên của dữ liệu trong quá trình huấn luyện và lấy mẫu các nguồn dữ liệu tỷ lệ với khối lượng của chúng. Tuy nhiên, chúng tôi đã tạo ngoại lệ cho JSON, YAML, và CSS, vì chúng tôi chỉ muốn LLM học định dạng dữ liệu mà không lãng phí tài nguyên tính toán để ghi nhớ dữ liệu trong những tệp như vậy. Vì lý do đó, chúng tôi đã cân bằng lại khối lượng nguồn dữ liệu thành 1 GB cho JSON và YAML và 3GB cho CSS.

4 Xóa PII

Mục này nêu ra những nỗ lực của chúng tôi để loại bỏ Thông tin Nhận dạng Cá nhân (PII) khỏi dữ liệu huấn luyện. Trong Mục 4.1, trước tiên chúng tôi mô tả cách chúng tôi thu thập một tập hợp lớn các chú thích PII. Chúng tôi đã sử dụng những chú thích này để khám phá các kỹ thuật khác nhau để huấn luyện một mô hình phát hiện PII trong Mục 4.3, dựa trên mô hình encoder mà chúng tôi đã phát triển trong Mục 4.2.

4.1 Thu thập dữ liệu

Chúng tôi đã sử dụng nền tảng Toloka9 để thu hút 1,399 nhân viên đám đông từ 35 quốc gia trong việc chú thích một bộ dữ liệu cho PII trong mã nguồn. Trung bình, các tham gia viên đã hoàn thành 206 nhiệm vụ, kiếm được khoảng $27, và làm việc 3.1 giờ. Mục tiêu của chúng tôi là xác định PII dưới nhiều hình thức khác nhau, chẳng hạn như tên, tên người dùng, email, địa chỉ IP, khóa, mật khẩu, và ID. Để đảm bảo rằng các nhân viên đám đông nhận được mức đền bù công bằng, chúng tôi đã thiết lập mức lương theo giờ là $7.30, có tính đến các mức lương tối thiểu khác nhau giữa các quốc gia và sức mua tương ứng của họ. Chúng tôi giới hạn tính đủ điều kiện chú thích cho các quốc gia mà mức lương theo giờ $7.30 tương đương với mức lương tối thiểu cao nhất ở Hoa Kỳ ($16.50) về mặt sức mua. Danh sách đầy đủ các quốc gia tham gia chú thích có thể được tìm thấy trong Bảng B.1 của Phụ lục B. Các nhân viên đám đông trong Toloka có thể làm nhiệm vụ bất cứ khi nào hoặc ở đâu; không có nghĩa vụ hoàn thành một nhiệm vụ nhất định hoặc dành một khoảng thời gian cố định cho nó. Do đó, họ sử dụng lựa chọn tự do khi làm việc trên các nhiệm vụ. Trong số 1,399 nhân viên đám đông, 695 người đã điền khảo sát về chất lượng nhiệm vụ, và 519 người đã hoàn thành khảo sát. Điểm trung bình cho câu hỏi hỏi liệu người tham gia có muốn đóng góp cho một dự án khác như thế này hay không là 4.92 trên thang điểm 1-5.

Bộ dữ liệu bao gồm 12,000 tệp, mỗi tệp chứa khoảng 50 dòng mã được viết bằng 31 ngôn ngữ lập trình. Hình 1 hiển thị phân phối các ngôn ngữ lập trình trong bộ dữ liệu được chú thích. Để tăng đại diện của các loại PII hiếm, chẳng hạn như khóa và địa chỉ IP, 7,100 tệp đã được lọc trước từ một mẫu lớn hơn. Chúng tôi đã sử dụng công cụ detect-secrets10 với tất cả các plugin mặc định được kích hoạt, cùng với các biểu thức chính quy của Ben Allal et al. (2023) để phát hiện email, địa chỉ IPv4 và IPv6. Để ngăn việc thiên vị chú thích quá nhiều vào các công cụ phát hiện này, 5,100 tệp còn lại được chọn ngẫu nhiên từ bộ dữ liệu mà không lọc trước.

Trong quá trình chú thích, chúng tôi đã phân biệt giữa các loại PII khác nhau dựa trên ngữ cảnh cụ thể mà nó xuất hiện. Cụ thể, chúng tôi đã phân biệt xem PII có hiện diện trong header giấy phép của mã, được sử dụng như một placeholder, hay tạo thành dữ liệu bí mật. Việc phân loại này là cần thiết vì PII trong header giấy phép thường được cung cấp tự nguyện bởi các tác giả để ghi nhận mã và có thể không yêu cầu che dấu. Tương tự, các placeholder không phải là bí mật thực và không cần che dấu. Chúng tôi áp dụng phân loại này cho tên, email, và tên người dùng. Xem Bảng 5 để có cái nhìn tổng quan về tất cả các thực thể PII.

Các chú thích viên đã phát hiện tổng cộng 22,950 thực thể PII trong bộ dữ liệu. Để đánh giá chất lượng của bộ dữ liệu, chúng tôi đã kiểm tra thủ công 300 tệp chứa các loại PII khác nhau và tính toán recall và precision cho từng loại, như được hiển thị trong Bảng 5. Chúng tôi thấy rằng việc chú thích ID bí mật đặc biệt khó khăn, vì các chú thích viên có xu hướng tạo ra nhiều dương tính giả và âm tính giả. Kết quả là, chúng tôi quyết định loại trừ danh mục này khỏi việc huấn luyện mô hình phát hiện PII.

4.2 StarEncoder

Như một phần của những nỗ lực phát hiện PII, chúng tôi đã huấn luyện một mô hình chỉ encoder (tức là, Transformers tự chú ý hai chiều) có thể được tinh chỉnh hiệu quả cho cả các nhiệm vụ liên quan đến mã và văn bản. Chúng tôi đã sử dụng các mục tiêu Masked Language Modelling (MLM) và Next Sentence Prediction (NSP) từ BERT (Devlin et al., 2019; Liu et al., 2019) và dự đoán các token bị che dấu từ một câu đầu vào và liệu một cặp câu có xảy ra như những người hàng xóm trong một tài liệu hay không.

Chúng tôi tách các đoạn mã trong đầu vào như sau: [CLS]Snippet-1 [SEP]Snippet-2, trong đó hai đoạn mã được chọn ngẫu nhiên, hoặc từ cùng một tệp nguồn hoặc từ hai tài liệu riêng biệt. Đối với tổn thất MLM, chúng tôi che token trong đầu vào một cách độc lập với xác suất 15%. Đối với tổn thất NSP, chúng tôi sử dụng một classifier tuyến tính được áp dụng cho đầu ra biểu diễn tại token [CLS]. Chúng tôi huấn luyện trong 100,000 bước với kích thước batch toàn cục là 4,096 chuỗi với độ dài tối đa 1,024 để khoảng 400B token được quan sát. Điều này mất khoảng hai ngày sử dụng 64 GPU NVIDIA A100. Chi tiết về kiến trúc mô hình được báo cáo trong Bảng 6.

4.3 Mô hình phát hiện PII

Chúng tôi đã tinh chỉnh StarEncoder trên bộ dữ liệu PII được chú thích cho nhiệm vụ Nhận dạng Thực thể Có tên (NER). Chúng tôi đã thêm một lớp tuyến tính như một đầu phân loại token trên đỉnh mô hình, với 6 lớp mục tiêu: tên, email, khóa, mật khẩu, địa chỉ IP, và tên người dùng. Chúng tôi loại trừ ID do chất lượng chú thích thấp và không phân biệt giữa việc phân loại các thực thể PII (header giấy phép, placeholder) vì hiệu suất kém của mô hình trong việc phân biệt chúng. Chúng tôi chia bộ dữ liệu thành tập huấn luyện gồm 7,878 ví dụ và tập kiểm tra gồm 4,000 ví dụ, đảm bảo rằng cả hai phần đều có đại diện cân bằng của các loại PII khác nhau. Xem Bảng 7. Chúng tôi cung cấp các phần huấn luyện và đánh giá dưới quyền truy cập có cổng tại https://hf.co/BigCode.

Baseline tinh chỉnh Chúng tôi tinh chỉnh StarEncoder trên tập huấn luyện PII, và 400 tệp được chú thích từ Ben Allal et al. (2023). Chúng tôi đạt được điểm F1 hơn 90% trên tên, email, và địa chỉ IP và 73.39% trên mật khẩu. Hiệu suất của mô hình tương đối thấp trên khóa và tên người dùng, với điểm F1 chỉ lần lượt là 56.66% và 59.39%. Chúng tôi cho rằng hiệu suất thấp trên khóa là do số lượng nhãn hạn chế cho loại PII này, vì chỉ có 308 trường hợp có sẵn. Đối với tên người dùng, chúng tôi quan sát thấy mô hình thường nhầm lẫn chúng với decorator và giá trị trong đường dẫn. Điều này rất có thể vì chúng tôi đã chú thích tên người dùng bên trong liên kết cho các nền tảng truyền thông xã hội.

Pseudo-labels Để cải thiện việc phát hiện các thực thể khóa và mật khẩu, chúng tôi đã sử dụng kỹ thuật pseudo-labeling như được mô tả bởi Lee (2013). Phương pháp này bao gồm việc huấn luyện một mô hình trên một tập nhỏ dữ liệu được gắn nhãn và sau đó tạo dự đoán cho một tập lớn hơn dữ liệu không được gắn nhãn. Cụ thể, chúng tôi đã chú thích 18,000 tệp bằng cách sử dụng một ensemble của hai mô hình encoder, được tinh chỉnh trên bộ dữ liệu PII 400 tệp từ Ben Allal et al. (2023). Để xác định các pseudo-label đáng tin cậy, chúng tôi đã tính toán logit xác suất trung bình từ các mô hình của chúng tôi và áp dụng tiêu chí lọc. Cụ thể, chúng tôi đã đặt ngưỡng tối thiểu 0.5 cho tất cả các thực thể, ngoại trừ tên và tên người dùng, mà chúng tôi sử dụng ngưỡng cao hơn là 0.6. Tuy nhiên, khi xem xét kết quả, chúng tôi thấy một số lượng đáng kể dương tính giả cho khóa và mật khẩu. Kết quả là, chúng tôi quyết định chỉ giữ lại các thực thể được đi trước bởi một từ kích hoạt, chẳng hạn như key, auth, hoặc pwd, trong vòng 100 ký tự trước đó. Huấn luyện trên bộ dữ liệu tổng hợp này trước khi tinh chỉnh trên bộ được chú thích đã mang lại kết quả tốt hơn cho tất cả các danh mục PII, như được thể hiện trong Bảng 8 và 9. Chỉ hiệu suất để phát hiện tên người dùng không cho thấy cải thiện đáng kể, vì vậy chúng tôi quyết định loại trừ nó khỏi quy trình xóa PII.

So sánh với baseline regex Chúng tôi đã so sánh các mô hình phát hiện PII của chúng tôi với các biểu thức chính quy (regex) được sử dụng trong Ben Allal et al. (2023). Các regex chỉ hỗ trợ phát hiện email, địa chỉ IP, và khóa. Lưu ý rằng chúng tôi đã cải thiện regex email, như được giải thích trong Phụ lục, để giải quyết các dương tính giả mà chúng tôi tìm thấy trong quá trình đánh giá trên benchmark này. Sửa đổi này đã tăng điểm F1 của regex từ 81.8% lên 96.83%. Tuy nhiên, các mô hình phát hiện PII của chúng tôi vẫn vượt trội hơn cách tiếp cận regex trong việc phát hiện tất cả ba thực thể, như được hiển thị trong Bảng 8. Chúng tôi lưu ý rằng sự khác biệt hiệu suất đặc biệt lớn trên khóa và thấy rằng công cụ detect-secrets tạo ra nhiều dương tính giả, đặc biệt trong các ngôn ngữ lập trình cụ thể như Go và C-sharp không được đại diện tốt trong đánh giá regex. Do đó, độ chính xác tổng thể của công cụ dưới 4%.

Hậu xử lý Trước khi áp dụng mô hình phát hiện PII tốt nhất cho bộ dữ liệu đầy đủ, chúng tôi quan sát một số lỗi phát hiện thường xuyên. Chúng tôi đã thêm các kỹ thuật hậu xử lý sau để giảm số lượng dương tính giả:
• Bỏ qua các bí mật có ít hơn 4 ký tự.
• Chỉ phát hiện tên đầy đủ bằng cách yêu cầu ít nhất một khoảng trắng trong tên.
• Bỏ qua các khóa được phát hiện có ít hơn 9 ký tự hoặc không phải là gibberish bằng cách sử dụng gibberish-detector.11
• Bỏ qua các địa chỉ IP không hợp lệ hoặc là private (không hướng Internet) bằng cách sử dụng gói python ipaddress. Chúng tôi cũng bỏ qua các địa chỉ IP từ các máy chủ DNS phổ biến. Chúng tôi sử dụng cùng danh sách như trong Ben Allal et al. (2023).

Placeholder PII Chúng tôi đã thay thế các thực thể PII được phát hiện bằng các token sau:
<NAME>, <EMAIL>, <KEY>, <PASSWORD>

Để che địa chỉ IP, chúng tôi đã chọn ngẫu nhiên một địa chỉ IP từ 5 địa chỉ IP tổng hợp, private, không hướng Internet của cùng loại có thể được tìm thấy trong Phụ lục C.

Vấn đề Github Chúng tôi đã sử dụng cách tiếp cận regex để phát hiện khóa, địa chỉ IP, và email trong các vấn đề Github, vì vậy chúng tôi chỉ sử dụng mô hình phát hiện PII để xóa tên. Chúng tôi đã ẩn danh tên người dùng của các tác giả bằng cách thay thế chúng bằng bộ đếm tham gia trong cuộc trò chuyện, ví dụ username_1 để chỉ tham gia viên thứ hai (xem Mục 5.1 để biết chi tiết định dạng). Chúng tôi thêm những bí danh này vào đầu mỗi bình luận để chúng tôi bảo tồn danh tính người nói của tác giả. Ngoài ra, chúng tôi xóa tất cả các đề cập về những tên người dùng này trong tin nhắn. Lưu ý rằng chúng tôi chỉ che tên người dùng của những tham gia viên tích cực trong cuộc trò chuyện và các đề cập về người dùng không tham gia không được ẩn danh.

Tài nguyên tính toán Chúng tôi đã sử dụng mô hình phát hiện PII để xác định PII trên tất cả các ngôn ngữ lập trình trong bộ dữ liệu huấn luyện, bao gồm các vấn đề GitHub (chỉ tên), commit Git, và notebook Jupyter. Tổng bộ dữ liệu có kích thước 815 GB. Chúng tôi đã chạy suy luận trên nhiều GPU NVIDIA A100 80 GB, yêu cầu 800 giờ GPU.

5 Huấn luyện Mô hình

Mục này trình bày thông tin về quá trình huấn luyện các mô hình StarCoder. Trước khi tiếp tục, trước tiên chúng tôi làm rõ sự khác biệt giữa hai mô hình:

StarCoderBase là mô hình đầu tiên được huấn luyện trên 1 nghìn tỷ token có nguồn gốc từ bộ dữ liệu được curation mô tả trong Mục 3.

StarCoder là phiên bản được tinh chỉnh của StarCoderBase, được huấn luyện trên thêm 35B token Python (khoảng 2 epoch).

Trong phần sau, chúng tôi chỉ ra cách chúng tôi định dạng dữ liệu huấn luyện (Mục 5.1), khử ô nhiễm dữ liệu huấn luyện (Mục 5.2), và cung cấp chi tiết về tokenizer (Mục 5.3), kiến trúc mô hình (Mục 5.4), quy trình huấn luyện (Mục 5.5), thiết lập GPU đa node (Mục 5.6), và phát thải CO2 (Mục 5.7).

5.1 Định dạng dữ liệu

Chúng tôi trình bày các hướng dẫn định dạng cho mỗi nguồn dữ liệu dưới đây. Chúng tôi cung cấp các template dưới đây trong đó <token> chỉ một sentinel token, và metadata và data chỉ các placeholder cho các trường dữ liệu, tương ứng.

Mã Chúng tôi thêm tên kho, tên tệp, và số lượng sao vào ngữ cảnh của tệp mã. Để không overfit trên số lượng sao chính xác, chúng tôi đã phân loại sao GitHub thành năm bucket: 0, 1-10, 10-100, 100-1000, 1000+. Để cho phép mô hình hoạt động mà không có metadata này trong quá trình suy luận, chúng tôi đã tiền tố tên kho, tên tệp, và sao một cách độc lập ở random, mỗi cái với xác suất 0.2.

<reponame>reponame<filename>filename<gh_stars>stars\ncode<|endoftext|>

Đối với mã nguồn trong template này (tức là code), chúng tôi áp dụng biến đổi fill-in-the-middle (FIM; Bavarian et al., 2022). Chính xác hơn, chúng tôi áp dụng FIM ở cấp ký tự cho các tệp mã nguồn với tỷ lệ FIM là 0.5, và sử dụng chế độ PSM với xác suất .5 và chế độ SPMv2 với xác suất .5.

Vấn đề Chúng tôi sử dụng sentinel token để đánh dấu việc mở một vấn đề và sau đó bao gồm tiêu đề của nó. Chúng tôi phân tách chuỗi bình luận bằng token <issue_comment> và bao gồm một định danh người nói ẩn danh trước bình luận. Cụ thể, chúng tôi chỉ các tác giả bằng bộ đếm tham gia của họ trong cuộc trò chuyện, ví dụ username_1 để chỉ tham gia viên thứ hai trong vấn đề. Để phân biệt giữa các lượt khác nhau, chúng tôi sử dụng comment1, id1 để chỉ bình luận thứ hai và id người nói ẩn danh của nó, tương ứng.

<issue_start>Title: title\nusername_id0:comment0<issue_comment>username_id1:comment1
... <issue_closed (optional)><|endoftext|>

Jupyter - scripts Các script Jupyter được định dạng theo cách tương tự như mã.

Jupyter - structured Các notebook Jupyter được phân tích đi kèm trong chuỗi văn bản, mã, và đầu ra, và chúng tôi phân tách chúng bằng sentinel token. Lưu ý rằng chúng tôi sử dụng text2, code2, output2 để chỉ bộ ba thứ 3 trong notebook.

<jupyter_start><jupyter_text>text0<jupyter_code>code0
<jupyter_output>output0<jupyter_text> ... <|endoftext|>

Commit Git Chúng tôi phân tách mã trước commit, tin nhắn commit, và mã sau commit bằng sentinel token. Như được giải thích trong Mục 3.4, chúng tôi sử dụng các tệp đầy đủ với xác suất 20% và ngược lại sử dụng một cửa sổ nhỏ (0-32 dòng) xung quanh các dòng đã thay đổi.

<commit_before>code_before<commit_msg>message<commit_after>code_after<|endoftext|>

Chúng tôi tóm tắt tất cả sentinel token trong Bảng 10.

5.2 Khử ô nhiễm dữ liệu huấn luyện

Dữ liệu huấn luyện mã đã được khử ô nhiễm bằng cách loại bỏ các tệp chứa docstring hoặc giải pháp từ HumanEval và MBPP, docstring từ APPS, câu hỏi từ GSM8K, hoặc prompt từ DS1000. (Những benchmark này được mô tả thêm trong Mục 6.) Để đưa ra chỉ dẫn về lượng dữ liệu bị loại bỏ bởi khử ô nhiễm, Python là ngôn ngữ có số lượng kết quả khớp cao nhất, với 558 tệp bị loại bỏ.

5.3 Tokenizer

Tokenizer của mô hình theo những hiểu biết của chúng tôi được trình bày trong Ben Allal et al. (2023) và sử dụng những lựa chọn thiết kế tương tự: chúng tôi sử dụng thư viện Hugging Face Tokenizers (MOI et al., 2022) để huấn luyện một Byte-Pair-Encoding cấp byte với kích thước từ vựng 49,152 token—bao gồm các sentinel token từ bảng 10. Bước tiền tokenization bao gồm một digit-splitter và regex splitter từ pre-tokenizer GPT-2.

5.4 Kiến trúc Mô hình

Chúng tôi đã huấn luyện một mô hình 15.5B tham số với cùng kiến trúc như SantaCoder (Ben Allal et al., 2023). Đó là một Transformer chỉ decoder với Multi-Query-Attention (MQA; Shazeer, 2019), và learned absolute positional embedding. Chúng tôi cũng áp dụng các biến đổi Fill-in-the-Middle (FIM; Bavarian et al., 2022) cho dữ liệu huấn luyện, xem Mục 5.1. Chúng tôi đã sử dụng FlashAttention (Dao et al., 2022) để tăng tốc tính toán attention và giảm footprint bộ nhớ của nó, cho phép chúng tôi mở rộng lên độ dài ngữ cảnh 8K. Để làm cho FlashAttention hoạt động với MQA trong quá trình huấn luyện, chúng tôi chỉ cần mở rộng key và value trước khi gọi attention kernel. Các siêu tham số kiến trúc được đưa ra trong Bảng 11. Ngoài ra, chúng tôi đã bao gồm các siêu tham số của SantaCoder (Ben Allal et al., 2023) để so sánh.

5.5 Chi tiết huấn luyện

StarCoderBase Mô hình được huấn luyện trong 250k iteration, với kích thước batch 4M token, tổng cộng một nghìn tỷ token. Chúng tôi đã sử dụng Adam (Kingma & Ba, 2015) với β1= 0.9, β2= 0.95, ϵ= 10−8 và weight decay 0.1. Tốc độ học tập theo cosine decay từ 3×10−4 đến 3×10−5 sau khi linear warmup 2,000 iteration.

StarCoder Bắt đầu từ StarCoderBase, chúng tôi đã tinh chỉnh một biến thể Python của mô hình trong 2 epoch trên tập con Python của dữ liệu huấn luyện. Chúng tôi đã sử dụng cùng cài đặt như StarCoderBase, ngoại trừ việc chúng tôi sử dụng tốc độ học tập 5×10−5 và decay nó đến 5×10−6 sau 1,000 iteration linear warmup. Chúng tôi huấn luyện trong 8,500 bước.

5.6 Thiết lập GPU Đa Node

Chúng tôi đã huấn luyện mô hình của mình trên một cụm GPU với 512 A100 80 GB GPU được phân phối trên 64 node. Chúng tôi đã phân vùng mô hình với bố cục song song 3D chia sẻ mô hình với cả tensor và pipeline parallelism rank 4, yêu cầu 16 GPU (hai node) cho một bản sao. Để tận dụng đầy đủ khả năng của cụm, chúng tôi đã sử dụng data parallelism gấp 32 lần. Để tối ưu hóa việc sử dụng GPU và giảm bubble tính toán idle, chúng tôi đã duy trì kích thước micro-batch là 1 và tích lũy trong 16 bước, dẫn đến kích thước batch toàn cục là 512 (tương đương với 4M token). Chúng tôi đã sử dụng distributed optimizer của Megatron-LM vì chúng tôi thấy rằng nó dẫn đến throughput cao hơn một chút trong cấu hình này. Vì nó yêu cầu bước gradient reduction trong FP32, việc huấn luyện trong BF16 dẫn đến throughput thấp hơn 10% so với FP16, nhưng chúng tôi vẫn sử dụng nó để tránh bất ổn định huấn luyện.

Ngoại trừ một vài lần khởi động lại, chúng tôi không trải qua bất ổn định huấn luyện đáng kể.

5.7 Phát thải CO2

StarCoderBase Chúng tôi báo cáo carbon footprint (Lacoste et al., 2019) của việc huấn luyện StarCoderBase. Dựa trên tổng số giờ GPU mà việc huấn luyện đã mất (320,256) và mức sử dụng điện năng trung bình 280W mỗi GPU, điều này cộng lại thành 89671.68 kWh điện tiêu thụ trong quá trình huấn luyện. Nhân với cường độ carbon của năng lượng tại vị trí us-west-2 AWS (0.15495 kgCO2e mỗi kWh) và Power Usage Effectiveness trung bình 1.2 trên các datacenter AWS, điều này dẫn đến 16.68 tấn CO2eq được phát thải.

StarCoder Mô hình được tinh chỉnh thêm 3.5% thời gian huấn luyện, dịch thành ước tính phát thải bổ sung 0.58 tấn CO2eq.

6 Đánh giá

Trong mục này, trước tiên chúng tôi nêu ra các mô hình mà chúng tôi đã đánh giá ngoài StarCoder và StarCoderBase. Sau đó chúng tôi báo cáo về hiệu suất ngôn ngữ Python của tất cả các mô hình trên các benchmark đánh giá HumanEval (Chen et al., 2021), MBPP (Austin et al., 2021), và DS-1000 (Lai et al., 2022). Sau đó chúng tôi đề cập đến đánh giá đa ngôn ngữ sử dụng nhiều benchmark và nhiệm vụ khác nhau.

Code LM Evaluation Harness Để cho phép đánh giá có thể tái tạo và tập trung của StarCoder và các Code LLM khác, chúng tôi đã phát triển một Code LM Evaluation Harness (Ben Allal et al., 2022), lấy cảm hứng từ LM Evaluation-Harness (Gao et al., 2021b). Harness này cung cấp một framework để đánh giá hiệu quả các mô hình mã, sử dụng data parallelism và docker container để thực thi. Nó hỗ trợ một số benchmark, bao gồm HumanEval, MultiPL-E, và DS-1000.

Các Mô hình Khác Được Đánh giá Chúng tôi so sánh StarCoder và StarCoderBase với các mô hình sau.

1. CodeGen-16B-Multi (Nijkamp et al., 2023) là một mô hình truy cập mở, 16B tham số được huấn luyện trên the Pile (Gao et al., 2021a), và sau đó trên mã bổ sung được viết bằng C, C++, Go, Java, JavaScript, và Python từ bộ dữ liệu GitHub BigQuery (Smith, 2016).

2. CodeGen-16B-Mono là một phiên bản của CodeGen-16B-Multi được tinh chỉnh trên mã Python bổ sung từ GitHub, mặc dù bộ dữ liệu không có sẵn công khai.

3. CodeGeeX (Zheng et al., 2023) là một mô hình truy cập mở 13B tham số được huấn luyện trên 23 ngôn ngữ lập trình được chọn từ the Pile, bộ dữ liệu CodeParrot (Wolf et al., 2020), và dữ liệu bổ sung cho Python, Java, và C++. CodeGeeX cũng bao gồm bộ benchmark đa ngôn ngữ riêng, HumanEval-X, mà chúng tôi thảo luận dưới đây.

4. code-cushman-001 là một mô hình 12B tham số của OpenAI và là mô hình ban đầu cho GitHub Copilot (Chen et al., 2021). Chi tiết về tập huấn luyện của nó không được biết. Mô hình này đã được OpenAI deprecated nhưng có sẵn từ Microsoft Azure OpenAI Service tại thời điểm viết.12

5. Cuối cùng, mặc dù chúng không được huấn luyện cụ thể cho tạo mã, chúng tôi bao gồm một số kết quả từ các bài báo LLaMA (Touvron et al., 2023), PaLM (Chowdhery et al., 2022), và LaMDA (Thoppilan et al., 2022). Giấy phép của LLaMA cấm sử dụng thương mại, và PaLM và LaMDA không có sẵn công khai.

6.1 StarCoder: Đánh giá Python

Trong mục này, chúng tôi đánh giá hiệu suất của StarCoder trên Python, so sánh nó với cả mô hình truy cập mở và đóng. Trước tiên chúng tôi báo cáo hiệu suất trên HumanEval (Chen et al., 2021) và MBPP (Austin et al., 2021), là hai benchmark được sử dụng rộng rãi về hiệu suất Python. Tuy nhiên, chúng tôi cũng đo hiệu suất trên DS-1000 (Lai et al., 2022), một benchmark hoàn thành mã gồm 1,000 bài toán khoa học dữ liệu Python dựa trên câu hỏi StackOverflow.

6.1.1 Benchmark HumanEval và MBPP

HumanEval (Chen et al., 2021), và MBPP (Austin et al., 2021) là các benchmark được sử dụng rộng rãi cho Code LLM bao gồm hàng trăm bài toán lập trình Python sử dụng test case để xác thực mã được tạo bởi Code LLM. Code LLM tạo mã bằng cách lấy mẫu từ phân phối đầu ra của chúng. Chúng tôi báo cáo hiệu suất sử dụng metric pass@k (Chen et al., 2021): tổng phần trăm bài toán benchmark được giải quyết, trong đó một bài toán được coi là đã giải quyết nếu bất kỳ một trong k mẫu mã nào pass mọi test case. Giống như Chen et al. (2021), chúng tôi sử dụng nhiệt độ lấy mẫu 0.2 cho pass@1, và nhiệt độ 0.8 cho k>1. Chúng tôi tạo n= 200 mẫu cho tất cả thí nghiệm với các mô hình truy cập mở. Đối với các mô hình API, chúng tôi sử dụng n= 20 mẫu, đủ để ước tính pass@1. Chúng tôi tập trung vào phiên bản đơn giản nhất của pass@k, đó là pass@1: khả năng một bài toán được giải quyết trong một lần thử duy nhất bởi mô hình.

Bảng 12 so sánh StarCoder (và StarCoderBase) trên HumanEval và MBPP với một số mô hình truy cập mở và đóng:

1. StarCoder là mô hình truy cập mở hiệu suất cao nhất trên cả hai benchmark.

2. StarCoder vượt trội hơn các mô hình lớn nhất, bao gồm PaLM, LaMDA, và LLaMA, mặc dù nhỏ hơn đáng kể.

3. StarCoderBase cũng rất có khả năng trên Python và cạnh tranh với CodeGen-16B-Mono, một mô hình truy cập mở có kích thước tương tự được tinh chỉnh trên Python.

4. StarCoder vượt trội hơn mô hình code-cushman-001 (12B) của OpenAI.

6.1.2 Benchmark DS-1000 Python Data Science

Một hạn chế lớn của HumanEval và MBPP là chúng là những câu đố lập trình đơn giản không đại diện cho mã mà hầu hết lập trình viên viết. Ngược lại, benchmark DS-1000 (Lai et al., 2022) có một bộ 1,000 quy trình khoa học dữ liệu thực tế và thực tế trên bảy thư viện và đánh giá các thế hệ trong thực thi chống lại test case.

DS-1000 hỗ trợ hai chế độ đánh giá: hoàn thành và chèn (qua FIM). Chúng tôi báo cáo điểm hoàn thành cho tất cả mô hình nhưng điểm chèn chỉ cho các mô hình hỗ trợ nó: các mô hình StarCoder và InCoder-6B (Fried et al., 2022). DS-1000 cũng phân loại bài toán dựa trên các thư viện được sử dụng: Matplotlib, NumPy, Pandas, SciPy, Scikit-Learn, PyTorch, và TensorFlow. Chúng tôi báo cáo pass@1 cho mỗi thư viện và một điểm tổng thể trong Bảng 13 và rút ra những kết luận sau:

1. StarCoder vượt trội đáng kể so với tất cả các mô hình khác trên các bài toán khoa học dữ liệu từ benchmark DS-1000. Hơn nữa, điều này đúng trên mọi loại thư viện khoa học dữ liệu.

2. StarCoderBase cũng vượt trội hơn mọi mô hình khác, nhưng hơi kém StarCoder trên DS-1000.

3. Chúng tôi xác nhận phát hiện của Lai et al. (2022): hiệu suất mô hình trên benchmark HumanEval và MBPP không luôn tương quan với hiệu suất trên benchmark DS-1000 thực tế hơn. Ví dụ, CodeGen-Mono hơi vượt trội hơn code-cushman-001 và các mô hình StarCoder trên HumanEval và MBPP, nhưng kém hơn đáng kể trên DS-1000. Điều này chứng minh tầm quan trọng của việc đánh giá mô hình trên một loạt benchmark.

6.1.3 Benchmark ODEX Open-Domain Coding

Các đánh giá trước đây của chúng tôi tập trung hoặc vào các domain đóng (tức là chủ yếu các hàm Python built-in, như trong MBPP và HumanEval) hoặc các domain cụ thể (ví dụ: khoa học dữ liệu, như trong DS-1000). Để đánh giá khả năng mô hình tạo mã trên một tập broader các thư viện Python, chúng tôi sử dụng benchmark ODEX (Wang et al., 2022) chứa 505 truy vấn mã hóa open-domain và 440 closed-domain Python, bằng bốn ngôn ngữ tự nhiên — tiếng Anh, Tây Ban Nha, Nhật Bản, và Nga — với đánh giá thực thi dựa trên test-case.

Chúng tôi báo cáo metric pass@1 cho StarCoder và các mô hình baseline, bao gồm Codex (code-davinci-001), CodeGen-16B-Mono, và SantaCoder. Ngoài độ chính xác thực thi tổng thể, chúng tôi cũng phân loại bài toán theo ngôn ngữ và domain, đó là: (1) các truy vấn trong closed-domain (chỉ sử dụng các hàm Python built-in) và open-domain (sử dụng các hàm từ thư viện được import), và (2) các truy vấn với hướng dẫn được viết bằng tiếng Anh, Tây Ban Nha, Nhật Bản, và Nga, tương ứng. Chúng tôi báo cáo điểm tổng thể và điểm trong các domain và ngôn ngữ khác nhau trong Bảng 14 và rút ra những kết luận sau:

1. StarCoder vượt trội đáng kể so với tất cả các mô hình khác trên các truy vấn mã hóa open-domain từ benchmark ODEX.

2. StarCoderBase cũng vượt trội hơn mọi mô hình khác, thậm chí tốt hơn StarCoder trong tập con ODEX tiếng Anh, nhưng hơi kém trong các ngôn ngữ khác.

3. Cả mô hình StarCoder và StarCoderBase thường thể hiện khoảng cách nhỏ hơn giữa các truy vấn open- và closed-domain so với các mô hình baseline khác, mặc dù có độ chính xác thực thi tổng thể cao hơn. Kết quả này chỉ ra rằng các mô hình StarCoder thu được kỹ năng tổng quát hơn về các truy vấn mã hóa trong open domain (tức là liên quan đến các thư viện Python đa dạng), trong khi các mô hình khác thể hiện sự sụt giảm hiệu suất lớn hơn khi chuyển từ closed sang open domain.

6.2 StarCoder và StarCoderBase: Đánh giá Đa Ngôn ngữ

Trong mục này, chúng tôi tập trung chủ yếu vào StarCoderBase, và đánh giá hiệu suất của nó trên nhiều ngôn ngữ lập trình và nhiệm vụ lập trình khác nhau, bao gồm tạo mã từ mô tả ngôn ngữ tự nhiên, tài liệu hóa mã, dự đoán chú thích type, và nhiều hơn nữa. Mục này cũng cho thấy rằng StarCoder, mặc dù được tinh chỉnh trên Python, vẫn là một Code LLM đa ngôn ngữ rất có khả năng và thậm chí vượt trội hơn StarCoderBase trên một số ngôn ngữ.

6.2.1 Đánh giá trên 19 Ngôn ngữ Lập trình với MultiPL-E

Chúng tôi đánh giá khả năng của StarCoder chuyển ngôn ngữ tự nhiên thành mã hoạt động trong nhiều ngôn ngữ lập trình bằng cách sử dụng MultiPL-E (Cassano et al., 2023), dịch các benchmark HumanEval (Chen et al., 2021) và MBPP (Austin et al., 2021) Python sang 18 ngôn ngữ lập trình khác như sau.

MultiPL-E có một tập hợp các compiler dựa trên quy tắc dịch các benchmark Python sang mỗi ngôn ngữ lập trình mục tiêu. Mỗi compiler mong đợi một benchmark ở định dạng HumanEval: 1) một mô tả ngôn ngữ tự nhiên (trong docstring), 2) một chữ ký hàm (tên, đối số, và có thể, các type), và 3) một tập hợp các assertion ẩn. Các compiler MultiPL-E dịch chữ ký hàm, assertion, và docstring (có thể có doctests) sang ngôn ngữ mục tiêu. Do đó, MultiPL-E cung cấp cho chúng tôi một tập hợp benchmark song song được bắt nguồn từ HumanEval và MBPP để so sánh hiệu suất mô hình trên các ngôn ngữ lập trình.13 Các ngôn ngữ MultiPL-E bao gồm cả ngôn ngữ tài nguyên cao và thấp, ngôn ngữ typed tĩnh và động, và nhiều tính năng ngôn ngữ lập trình khác.

Bảng 15 cho thấy các mô hình này thực hiện như thế nào trên 19 ngôn ngữ lập trình, và từ đó, chúng tôi rút ra những kết luận sau:

1. Trên tất cả 19 ngôn ngữ lập trình, StarCoderBase vượt trội hơn các mô hình truy cập mở khác, đôi khi cho thấy hiệu suất hơn 2× .

2. StarCoderBase cạnh tranh với code-cushman-001 trên hầu hết các ngôn ngữ mà chúng tôi đánh giá. Có một vài ngoại lệ. Ví dụ, code-cushman-001 vượt trội hơn StarCoderBase hơn 5% trên C++, Java, Ruby, và Swift, và StarCoder vượt trội hơn code-cushman-001 hơn 5% trên Julia.

3. Mặc dù tinh chỉnh trên Python, StarCoder vẫn cạnh tranh trên hầu hết các ngôn ngữ, và cũng vượt trội hơn các mô hình mở khác. Điều đáng ngạc nhiên hơn là StarCoder hơi vượt trội hơn StarCoderBase trên một số ngôn ngữ nhất định, mặc dù được tinh chỉnh trên Python. Tại thời điểm này, chúng tôi chỉ có thể suy đoán về lý do tại sao điều này lại như vậy, và việc điều tra thêm dữ liệu huấn luyện mở có thể sẽ giúp làm sáng tỏ phát hiện này.

Có một số kết luận khác mà chúng tôi có thể rút ra từ bảng. Ví dụ, CodeGen-16B-Multi thực hiện tốt hơn mong đợi trên một số ngôn ngữ được báo cáo là không có trong tập huấn luyện của nó, bao gồm C#, Lua, PHP, và TypeScript. Hiệu suất của nó trên TypeScript ít đáng ngạc nhiên hơn vì các hàm JavaScript đơn giản thường type-check với TypeScript theo thiết kế. Tương tự, StarCoder cho thấy hiệu suất cao trên Swift, mặc dù nó không được bao gồm trong tập huấn luyện của nó, như được giải thích trong Mục 3.1.

6.2.2 Benchmark Bảo mật "Asleep at the Keyboard"

Một hạn chế của Code LLM là chúng có thể tạo mã với các lỗ hổng bảo mật (Pearce et al., 2022). Benchmark Asleep at the Keyboard của Pearce et al. (2022) có 89 tình huống nhạy cảm bảo mật trên ba trục đánh giá: (1) Diversity of Weakness (DoW) bao gồm 18 lớp lỗ hổng khác nhau trong taxonomy Common Weakness Enumeration (CWE) của MITRE, với các tình huống được rút ra từ danh sách 2021 CWE Top 25 Most Dangerous Software Weaknesses được xuất bản bởi MITRE; (2) Diversity of Prompt (DoP) đánh giá độ nhạy cảm của mô hình với các biến thể trong prompt cho một lớp lỗ hổng duy nhất (SQL injection); (3) Diversity of Domain (DoD) chứa các tình huống bảo mật trong ngôn ngữ mô tả phần cứng Verilog. Chúng tôi tập trung vào DoW, chứa 54 tình huống (25 trong C và 29 trong Python) trên 18 CWE. Chúng tôi loại trừ các tình huống thiếu kiểm tra tự động, còn lại 40 tình huống (23 trong C và 17 trong Python).

Pearce et al. (2022) trước đây đã đánh giá bảo mật của GitHub Copilot (tính đến tháng 8 năm 2021), và trong bài báo này, chúng tôi sử dụng cùng phương pháp để đánh giá StarCoderBase, InCoder-6B, CodeGen-16B-Multi, và code-cushman-001 của OpenAI. Chúng tôi sử dụng phương pháp benchmarking gốc: tạo 25 completion cho mỗi tình huống ở nhiệt độ 0.2 (1,000 completion cho mỗi mô hình). Bộ dữ liệu hỗ trợ fill-in-the-middle, vì vậy chúng tôi bao gồm cấu hình này trên các mô hình hỗ trợ nó. Kết quả được hiển thị trong Bảng 16; Valid đưa ra phần trăm giải pháp hợp lệ về mặt cú pháp (sử dụng py_compile cho Python và gcc cho C), và Insecure hiển thị phần trăm giải pháp valid chứa lỗ hổng mà tình huống kiểm tra. Từ bảng này, chúng tôi rút ra những kết luận sau.

1. StarCoderBase có tỷ lệ mã valid cao nhất.

2. InCoder-6B có tỷ lệ hơi thấp hơn cho việc tạo mã không an toàn, nhưng điều này có thể do tỷ lệ completion valid thấp hơn của nó.

3. Trong số các mô hình có hơn 95% mã valid, StarCoder có tỷ lệ completion không an toàn thấp nhất.

6.2.3 Benchmark Fill in the Middle

Các mô hình StarCoder hỗ trợ fill in the middle (FIM) hoặc infilling, cho phép mô hình tạo mã có điều kiện trên mã prefix và suffix xung quanh điểm chèn. Chỉ một số ít mô hình gần đây hỗ trợ FIM: từ OpenAI (Bavarian et al., 2022), InCoder (Fried et al., 2022), và công việc trước đây của chúng tôi về SantaCoder (Ben Allal et al., 2023). FIM mở ra khả năng cho nhiều nhiệm vụ khác nhau vượt ra ngoài việc hoàn thành mã từ trái sang phải. Chúng tôi đánh giá StarCoderBase trên bốn benchmark FIM đã được thiết lập dưới đây.

Single-Line Infilling cho Python, Java, và JavaScript Fried et al. (2022) trình bày một nhiệm vụ fill-in-the-middle một dòng cho Python che một dòng mã từ một giải pháp HumanEval và đánh giá khả năng của mô hình hoàn thành hàm. Họ biến mỗi giải pháp HumanEval thành một số bài toán fill-in-the-middle bằng cách che mỗi dòng không trống, không phải comment của mã trong thân giải pháp thành một nhiệm vụ fill-in-the-middle. Ben Allal et al. (2023) tổng quát hóa benchmark này để cũng hỗ trợ Java và JavaScript, sử dụng các giải pháp được tạo bởi mô hình từ bản dịch của MultiPL-E. Chúng tôi so sánh hiệu suất của StarCoderBase, SantaCoder, và InCoder trên nhiệm vụ này, đánh giá bằng cách sử dụng exact match dòng (Bảng 17). StarCoderBase vượt trội đáng kể so với hai mô hình nhỏ hơn.

Dự đoán Python Return Type Pradel et al. (2020) giới thiệu các phương pháp và bộ dữ liệu để đánh giá chú thích type Python. Fried et al. (2022) điều chỉnh và lọc một bộ dữ liệu từ công việc này, bao gồm các hàm Python từ GitHub, và sử dụng nó để đánh giá các mô hình infilling trên dự đoán return type hàm. Chúng tôi sử dụng bộ dữ liệu này để so sánh StarCoder, StarCoderBase, và SantaCoder với InCoder trên dự đoán return type hàm. Thiết lập của chúng tôi theo Fried et al. (2022): mỗi mô hình sử dụng greedy generation để infill return type trong khi có điều kiện trên import, thân, và chữ ký cho mỗi hàm. Chúng tôi báo cáo độ chính xác exact match trên các chú thích được chuẩn hóa cho tất cả các hàm trong tập đánh giá và chỉ những hàm có chú thích không phải None, theo Fried et al. (2022). Chúng tôi thấy rằng StarCoder và StarCoderBase vượt trội hơn các cách tiếp cận hiện có trong dự đoán return type Python (Bảng 18). Tuy nhiên, chúng tôi lưu ý rằng vì các hàm trong tập đánh giá này được lấy từ các kho GitHub, chúng có thể chồng chéo với dữ liệu huấn luyện cho SantaCoder và các mô hình StarCoder.

Dự đoán TypeScript Type Yee & Guha (2023) đánh giá các cách tiếp cận dự đoán type neural cho TypeScript. Tuy nhiên, thay vì đo độ chính xác, họ lập luận rằng các benchmark nên đo có bao nhiêu dự án hoặc tệp không có lỗi type với các type được dự đoán. Cách tiếp cận này làm cho việc đánh giá dự đoán type cho các chương trình JavaScript chưa bao giờ được dịch sang TypeScript trở nên khả thi, điều này giảm khả năng contamination bộ dữ liệu. Chúng tôi thêm StarCoderBase vào framework đánh giá của họ và so sánh nó với InCoder, thực hiện tốt nhất trong dự đoán type trong công việc gốc. Bảng 19 cho thấy rằng StarCoderBase vượt trội hơn InCoder: (1) nó tạo ra nhiều package type check hơn, (2) trên tất cả các package, nó tạo ra nhiều tệp type check hơn, và (3) nó tạo ra ít chú thích type tầm thường hơn InCoder.

Tạo Python Docstring Để đánh giá khả năng tạo tài liệu cho hàm của các mô hình, chúng tôi sử dụng tập con Python của benchmark tóm tắt mã CodeXGLUE (Lu et al., 2021). Benchmark này được xây dựng từ bộ dữ liệu CodeSearchNet (Husain et al., 2019), chứa các hàm từ các kho GitHub công khai. Các mô hình infill documentation string (docstring) cho mỗi hàm bằng cách sử dụng greedy decoding, có điều kiện trên chữ ký hàm và thân. Chúng tôi theo sơ đồ đánh giá của công việc trước: docstring được đánh giá bằng cách sử dụng smoothed 4-gram BLEU (Papineni et al., 2002) so với docstring tham chiếu từ hàm gốc, chỉ sử dụng dòng đầu tiên của docstring được tạo và tham chiếu (loại bỏ, ví dụ: mô tả đối số hàm và return type có thể xuất hiện trong các dòng sau). Trong Bảng 20, chúng tôi thấy rằng StarCoder và StarCoderBase có hiệu suất cao hơn công việc trước trong tạo docstring. Tuy nhiên, chúng tôi lưu ý rằng có thể có sự chồng chéo giữa bộ dữ liệu đánh giá này và dữ liệu được sử dụng để huấn luyện SantaCoder và các mô hình StarCoder.

6.3 Cải thiện Hiệu suất Qua Quá trình Huấn luyện

Chúng tôi đánh giá hiệu suất của StarCoderBase tại một số checkpoint huấn luyện sau mỗi 200B token được quan sát trong tổng số 1000B. Hình 2 (phải) cho thấy hiệu suất (pass@1) thay đổi như thế nào trong quá trình huấn luyện cho mỗi ngôn ngữ lập trình được hỗ trợ bởi MultiPL-E. Đường cong hiệu suất cho một số ngôn ngữ lập trình tài nguyên cao cho thấy rằng huấn luyện lâu hơn có khả năng cải thiện hiệu suất của chúng thêm nữa.

Tuy nhiên, một số ngôn ngữ tài nguyên thấp thấy cải thiện hạn chế trong quá trình huấn luyện hoặc thậm chí có sự suy giảm pass@1. Ví dụ, tỷ lệ pass@1 của R giảm đáng kể giữa checkpoint 800B và 1000B (cuối cùng). Sự phụ thuộc của pass@1 vào kích thước dữ liệu (Hình 2, trái) hỗ trợ thêm giả thuyết rằng điều này liên quan đến lượng dữ liệu có sẵn. Độ dốc của linear fit tăng giữa checkpoint 800B và 1000B trong khi intercept giảm, tức là, hiệu suất chỉ cải thiện cho các ngôn ngữ có lượng dữ liệu đủ lớn (≳1GB).

Chúng tôi đã kiểm tra thủ công các completion được tạo bởi R qua một số checkpoint để hiểu rõ hơn hiệu suất mô hình. Người ta có thể giả thuyết rằng một số bài toán khó hơn những bài khác, và vì vậy mô hình có được và mất khả năng giải quyết chúng trong R qua các checkpoint 600B, 800B, và 1000B, nhưng chúng tôi thấy rằng điều này không phải như vậy. Thay vào đó, chúng tôi thấy variance đáng kể trong tỷ lệ thành công cho mỗi bài toán cho một số bài toán (Bảng D.3). Đối với những bài toán này, tỷ lệ pass giữa các checkpoint khác nhau thay đổi theo cách có vẻ hoàn toàn không tương quan. Hơn nữa, kiểm tra thủ công cho thấy rằng các lỗi được gây ra bởi những sai lầm nhỏ, ví dụ: không lấy giá trị tuyệt đối khi tính GCD, không chuyển đổi string thành character array, hoặc không kiểm tra edge case.

6.4 Perplexity với Long Context

StarCoderBase được huấn luyện với cửa sổ 8K token, cho phép có điều kiện trên và tạo các tệp mã dài. Để đánh giá khả năng của mô hình hưởng lợi từ ngữ cảnh lớn hơn này, chúng tôi so sánh perplexity của nó (Bahl et al., 1983) khi sử dụng kích thước cửa sổ đầy đủ 8K token so với kích thước cửa sổ 2K token (như được sử dụng trong nhiều mô hình mã trước đây).

Để đảm bảo không chồng chéo giữa dữ liệu huấn luyện cho StarCoderBase và dữ liệu tính toán perplexity, chúng tôi đã tải xuống 10 kho GNU Public License (GPL) từ GitHub trong mỗi ngôn ngữ trong Bảng 21. Chúng tôi đã biên dịch tất cả các tệp từ các kho thành một tài liệu duy nhất cho mỗi ngôn ngữ. Sau đó chúng tôi chia những tài liệu này thành các chunk 8K token và tính toán perplexity trên 1K token cuối cùng trong mỗi chunk14 trong hai điều kiện: (1) cửa sổ mô hình chỉ chứa 2K token cuối cùng trong chunk (tức là, 1K được dự đoán và 1K trước đó), và (2) cửa sổ mô hình chứa tất cả 8K token trong chunk (tức là, 1K token được dự đoán và 7K trước đó). Điều này đánh giá khả năng của mô hình hưởng lợi từ ngữ cảnh token bổ sung được cung cấp bởi cửa sổ ngữ cảnh 8K của nó khi dự đoán mã. Trong Bảng 21, chúng tôi báo cáo perplexity trung bình của các vùng 1K token trên tất cả các chunk. Chúng tôi thấy rằng StarCoderBase thực sự hưởng lợi từ conditioning token bổ sung được cung cấp bởi cửa sổ ngữ cảnh 8K của nó, với perplexity thấp hơn đáng kể trên tất cả các ngôn ngữ.

7 Đánh giá Ngôn ngữ Tự nhiên

Mặc dù các mô hình StarCoder chủ yếu được phát triển để làm Code LLM, chúng cũng đã được huấn luyện trên một lượng đáng kể văn bản ngôn ngữ tự nhiên. Khoảng 20% token huấn luyện của nó là dữ liệu ngôn ngữ tự nhiên: 7% vấn đề GitHub, 10% Markdown, 2% notebook Jupyter, và 4% HTML. Trong mục này, chúng tôi đánh giá StarCoderBase trên một số nhiệm vụ ngôn ngữ tự nhiên: các nhiệm vụ lý luận và hiểu biết ngôn ngữ tự nhiên có thể hưởng lợi từ sự kết hợp dữ liệu huấn luyện mã và văn bản; và các nhiệm vụ tạo ngôn ngữ tự nhiên đánh giá xu hướng của mô hình tạo ra đầu ra văn bản không mong muốn, ví dụ: trong một thiết lập tạo tài liệu hoặc trợ lý tương tác.

7.1 Lý luận Toán học

Công việc gần đây đã cho thấy rằng Code LLM có thể là những reasoner số học và ký hiệu hiệu quả bằng cách sử dụng kỹ thuật gọi là Program-Aided Language models (PAL; Gao et al., 2022). Với PAL, LLM đọc bài toán lý luận và tạo các chương trình Python như các bước lý luận trung gian, sau đó được thực thi bởi Python interpreter để tạo ra câu trả lời. Ngược lại, phương pháp Chain-of-Thought (CoT; Wei et al., 2022) prompt LLM tạo ra các bước lý luận bằng ngôn ngữ tự nhiên trước khi tạo câu trả lời.

Chúng tôi điều tra khả năng lý luận của StarCoderBase trên GSM8K (Cobbe et al., 2021), một tập hợp các bài toán từ toán học trung học cơ sở. Chúng tôi so sánh với hai mô hình CodeGen-16B (Nijkamp et al., 2023) và họ mô hình LLaMA (Touvron et al., 2023). Kết quả đánh giá của chúng tôi được trình bày trong Bảng 22, trong đó chúng tôi cung cấp cả kết quả CoT và PAL cho StarCoderBase và LLaMA.

Phù hợp với kết quả trước đây so sánh PAL với CoT trên Code LLM (Gao et al., 2022), chúng tôi thấy rằng StarCoderBase thực hiện tốt hơn với PAL (21.5%) so với CoT (8.4%). StarCoderBase vượt trội đáng kể so với CodeGen-16B-Mono và CodeGen-16B-Multi, đạt lần lượt 13.1% và 8.6% với PAL. Những khác biệt này tiếp tục khi áp dụng majority voting. Sự khác biệt giữa CoT và PAL nhỏ hơn nhiều đối với các mô hình LLaMA, mặc dù chúng tôi quan sát thấy rằng CoT thực hiện hơi tốt hơn đối với các mô hình LLaMA 7B và 13B. Thú vị là, chúng tôi thấy rằng StarCoderBase vượt trội hơn LLaMA-13B (17.8%) trên benchmark lý luận này. Tuy nhiên, hiệu suất của nó vẫn thua LLaMA-33B (38.7%).

7.2 Kiến thức Thế giới và Đọc hiểu

MMLU (Hendrycks et al., 2020) là một benchmark hiểu biết ngôn ngữ đa nhiệm vụ lớn, bao gồm các câu hỏi multiple-choice trong 57 domain kiến thức, bao gồm nhân văn, STEM, và khoa học xã hội. CoQA (Reddy et al., 2019) là một bộ dữ liệu quy mô lớn cho các hệ thống Conversational Question Answering, đo khả năng xử lý đoạn văn bản và trả lời một loạt câu hỏi liên kết của mô hình. Chúng tôi so sánh StarCoderBase và StarCoder với CodeGen-16B-Multi (Nijkamp et al., 2023), GPT-NeoX (Black et al., 2022), LLaMA-7B, và LLaMA-13B (Touvron et al., 2023).

Chúng tôi trình bày độ chính xác 5-shot cho MMLU trong Bảng 23, và điểm F1 zero-shot cho CoQA trong Bảng 24. Trên MMLU, StarCoderBase vượt trội hơn CodeGen-16B-Multi đáng kể (34.2% so với 27.8%), và thậm chí vượt trội hơn GPT-NeoX một chút (32.9%). Tuy nhiên, cả hai mô hình LLaMA đều vượt trội hơn StarCoderBase. Trên CoQA, StarCoderBase thực hiện tốt hơn CodeGen-16B-Multi nhưng bị vượt trội bởi LLaMA và GPT-NeoX.

7.3 Đo Tạo sinh Có hại

Khi tạo văn bản mở như tài liệu mã hoặc đối t化 kỹ thuật, một Code LLM (tương tự như LLM chỉ văn bản) có thể tạo ra đầu ra có hại. Chúng tôi so sánh StarCoderBase với các Code LLM trước đây trên các benchmark đo bias xã hội và độc tính trong văn bản do mô hình tạo ra.15

7.3.1 Bias Xã hội

Công việc gần đây đã làm nổi bật rằng LLM thường nắm bắt bias xã hội và stereotypes từ corpora tiền huấn luyện của chúng (Kurita et al., 2019; May et al., 2019; Hutchinson et al., 2020; Meade et al., 2023). Để định lượng bias xã hội trong mô hình của chúng tôi, chúng tôi sử dụng StereoSet (Nadeem et al., 2021).

StereoSet bao gồm một bộ sưu tập các test kiểu fill-in-the-blank để đo bias xã hội trong các mô hình ngôn ngữ.16 Mỗi ví dụ trong StereoSet bao gồm một câu không hoàn chỉnh (ví dụ: our housekeeper is BLANK) cùng với ba completion có thể. Trong số những completion này, một là stereotypical (ví dụ: Mexican), một khác là anti-stereotypical (ví dụ: Italian) và một thứ ba là unrelated (ví dụ: computer). StereoSet định nghĩa ba metric: điểm stereotype, điểm language modeling, và điểm ICAT. Điểm stereotype là phần trăm ví dụ mà một mô hình prefer completion stereotypical cho một câu so với completion anti-stereotypical. Điểm language modeling là phần trăm ví dụ mà một mô hình prefer completion có ý nghĩa (stereotype hoặc anti-stereotype) so với completion unrelated. Cuối cùng, Nadeem et al. (2021) định nghĩa điểm idealized context association test (ICAT) kết hợp hai metric này:

ICAT = lms·min(ss,100−ss) / 50 (1)

trong đó lms và ss biểu thị điểm language model và stereotype, tương ứng.

Chúng tôi báo cáo kết quả StereoSet cho StarCoderBase, cùng với LLaMA-13B và CodeGen-Multi-16B, trong Bảng 25. Trên tất cả bốn domain bias, chúng tôi thấy StarCoderBase có điểm stereotype thấp nhất, nhưng cũng có điểm language modeling cạnh tranh. Điều này cho thấy rằng điểm stereotype thấp hơn của StarCoderBase không đơn giản do language modeling kém (Meade et al., 2022), và cũng như được chỉ ra bởi điểm ICAT cao. Chúng tôi cũng đánh giá StarCoderBase so với Crowdsourced Stereotype Pairs (CrowS-Pairs; Nangia et al. 2020) và giới thiệu độc giả đến Bảng D.4 cho kết quả.

7.3.2 Độc tính

Để đánh giá độc tính trong các phản hồi được tạo từ mô hình của chúng tôi, chúng tôi sử dụng RealToxicityPrompts (Gehman et al., 2020), một bộ sưu tập các prompt cấp câu thường kích thích các phản hồi không mong muốn từ các mô hình ngôn ngữ. Chúng tôi tạo phản hồi cho 10K ví dụ từ RealToxicityPrompts bằng StarCoderBase với độ dài tối thiểu một token và độ dài tối đa 128 token. Chúng tôi sử dụng nucleus sampling (Holtzman et al., 2020) với p= 0.95 để tạo tất cả phản hồi của chúng tôi.

Chúng tôi sử dụng hai phương pháp để tự động đánh giá độc tính trong phản hồi: (i) một classifier độc tính dựa trên RoBERTa (Liu et al., 2019) (Vidgen et al., 2021) và (ii) một danh sách các từ có thể gây phản cảm.17 Đối với detector độc tính, chúng tôi báo cáo phần trăm phản hồi được gắn cờ là độc tính bằng cách sử dụng ngưỡng 0.5. Đối với danh sách từ gây phản cảm, chúng tôi báo cáo phần trăm phản hồi chứa một từ gây phản cảm. Chúng tôi lưu ý rằng trong khi danh sách từ gây phản cảm có thể gắn cờ sai các phản hồi, nó có thể cung cấp một thước đo thô về độc tính rõ ràng. Chúng tôi báo cáo kết quả của mình trong Bảng 26.

Nói chung, chúng tôi quan sát thấy rằng CodeGen-16B-Multi và StarCoderBase dường như đều tạo ra ít phản hồi độc tính hơn LLaMA-13B. Ví dụ, 1.43% phản hồi của LLaMA-13B chứa các token có thể gây phản cảm so với 1.12% của StarCoderBase. Chúng tôi cũng lưu ý rằng CodeGen-16B-Multi có vẻ tạo ra ít phản hồi độc tính hơn StarCoderBase.

7.4 Nhiệm vụ Lý luận trong HELM

Chúng tôi đánh giá StarCoderBase với HELM (Liang et al., 2022), một bộ đánh giá nhằm tăng minh bạch của LLM bằng cách báo cáo hiệu suất của chúng trên một loạt nhiệm vụ rộng. Chúng tôi đánh giá khả năng của mô hình tận dụng tiền huấn luyện ngôn ngữ tự nhiên và mã của nó cho các nhiệm vụ lý luận ngôn ngữ tự nhiên từ HELM (loại trừ các nhiệm vụ mã, vì chúng tôi có đánh giá mã rộng rãi riêng). Tại thời điểm viết, benchmark HELM không bao gồm các mô hình CodeGen, CodeGeex, và LLaMA. Do đó, chúng tôi so sánh StarCoderBase với mô hình lớn nhất và/hoặc gần đây nhất từ mỗi họ mô hình truy cập "hạn chế" hoặc "mở", như được phân loại trên danh sách mô hình HELM,18 đã được đánh giá trên phần lớn các nhiệm vụ lý luận HELM này tính đến ngày 1 tháng 5 năm 2023. Trong Bảng 27 chúng tôi báo cáo kết quả. Chúng tôi tính xếp hạng của mỗi mô hình trên mỗi nhiệm vụ, và sắp xếp các mô hình trong bảng theo xếp hạng trung bình của chúng trên các nhiệm vụ. StarCoderBase nói chung có hiệu suất mạnh hơn đáng kể so với tất cả các mô hình khác với trọng số được phát hành và thường thực hiện tương đương hoặc tốt hơn các mô hình lớn hơn nhiều. Chúng tôi suy đoán rằng hỗn hợp mã và ngôn ngữ tự nhiên trong dữ liệu huấn luyện đóng góp vào hiệu suất mạnh của mô hình trên những nhiệm vụ lý luận này.

8 Đánh giá Định tính

Trong Phụ lục E, chúng tôi làm nổi bật một số tương tác thú vị mà chúng tôi đã có với StarCoderBase. Chúng tôi hy vọng những điều này phục vụ như một điểm khởi đầu cho các nhà nghiên cứu và nhà phát triển quan tâm đến việc khám phá thêm khả năng của mô hình. Chúng tôi cung cấp các ví dụ về cách kích thích hành vi mô hình thú vị bằng cách sử dụng các template cho commit Git, vấn đề GitHub, và notebook Jupyter trong Mục E.1. Trong Mục E.2, chúng tôi chứng minh cách prompt StarCoder hoạt động như một trợ lý kỹ thuật mà không cần instruction-tuning. Trong Mục E.3 chúng tôi thấy rằng cũng có thể prompt mô hình bằng cách sử dụng sự kết hợp meta-data và ngôn ngữ tự nhiên để có hiệu suất pass@1 cao hơn trên benchmark HumanEval.

9 Công cụ Truy xuất Nguồn gốc

Khi các công cụ ngôn ngữ tạo sinh trở nên phổ biến hơn và chuyên sâu về dữ liệu, nhu cầu hiểu và kiểm tra lượng lớn văn bản mà chúng được huấn luyện trở nên cấp thiết hơn, cả để hiểu các chế độ lỗi của mô hình cũng như cung cấp phản hồi quản trị dữ liệu minh bạch dưới dạng truy xuất nguồn gốc và quản lý nguồn gốc của đầu ra được tạo bởi mô hình. Nhu cầu cấp thiết này để hiểu dữ liệu (Mitchell et al., 2022) đang được công nhận và vận hành ngày càng nhiều dưới dạng các công cụ và toolkit kiểm tra bộ dữ liệu (Akiki et al., 2023; Marone & Van Durme, 2023; Piktus et al., 2023). Chính từ góc nhìn này mà chúng tôi đang phát hành hai công cụ kiểm tra dữ liệu như vậy: một công cụ kiểm tra thành viên và một chỉ mục tìm kiếm BM25. Những công cụ này bổ sung cho công cụ "Am I in The Stack" hiện có hoạt động ở cấp tên kho GitHub. Hai công cụ mới chỉ mục chỉ các tệp được sử dụng để huấn luyện và cho phép khớp trên nội dung tệp. Những công cụ này có sẵn như các trang web độc lập nhưng cũng được tích hợp vào demo VSCode của chúng tôi. Điều này giúp người dùng xác định các phần đầu ra mô hình có thể đã được sao chép từ dữ liệu huấn luyện. Bằng cách sử dụng chỉ mục tìm kiếm, người dùng có thể định vị tệp nguồn và kho tương ứng của các đoạn được sao chép.

9.1 Kiểm tra Thành viên

Marone & Van Durme (2023) đề xuất tài liệu hóa bộ dữ liệu với các artifact kiểm tra thành viên được gọi là Data Portraits. Họ cung cấp một triển khai cụ thể, dựa trên Bloom Filters (Bloom, 1970), cung cấp suy luận thành viên nhanh và nhẹ. Chúng tôi xây dựng một portrait dựa trên Bloom-filter trên các string có độ dài 50 ký tự từ dữ liệu huấn luyện. Artifact này mất 26 GB, ∼3% kích thước dữ liệu. Công cụ suy luận được host công khai để bổ sung các artifact tài liệu khác.19

Các thế hệ từ mô hình có thể được kiểm tra nhanh chóng để đánh giá gần đúng mức độ chồng chéo với corpus huấn luyện. Extension VSCode hỗ trợ sử dụng điều này như một phương pháp truy xuất nguồn gốc nhanh, lần đầu. Tuy nhiên, điều này yêu cầu các string khớp dài hơn kích thước tối thiểu và không cố gắng lọc các đoạn mã chung hoặc generic. Sau kiểm tra lần đầu, người dùng có thể sử dụng chỉ mục tìm kiếm đầy đủ để đánh giá thêm truy xuất nguồn gốc.

9.2 Chỉ mục Tìm kiếm

Chúng tôi chỉ mục bộ dữ liệu huấn luyện bằng Elasticsearch 7.1720 và cung cấp hai công cụ tìm kiếm để truy vấn nó: một tập trung vào tập con Python và một bao gồm toàn bộ bộ dữ liệu. Mã được tiền xử lý bằng lowercase filter và ASCIIFoldingFilter của Lucene, được tokenize bằng 3-gram tokenizer, và được chỉ mục bằng triển khai Lucene mặc định của BM25 như một hàm tương tự. Chúng tôi chỉ mục thêm các trường username và license như các trường keyword cho phép lọc và lookup dễ dàng dựa trên những trường metadata cụ thể này. Cả hai chỉ mục hiện đang chạy ở chế độ single-node trên một máy ảo.

10 Tác động Xã hội và Hạn chế

10.1 Cách tiếp cận dự án

Khoa học mở và quản trị mở StarCoder là đầu ra của một dự án nghiên cứu cộng đồng. Dự án được tiến hành theo tinh thần Khoa học Mở (Woelfle et al., 2011), tập trung vào phát triển và sử dụng có trách nhiệm Code LLM. Thông qua các thực hành quản trị mở được tiến hành trong suốt dự án, ưu tiên trong việc ra quyết định luôn nhường chỗ cho lựa chọn có trách nhiệm hơn ngay cả khi điều này có nghĩa là đưa ra những hạn chế có thể tác động đến việc áp dụng hoặc nghiên cứu tương lai. Ví dụ, Nhóm Công tác Pháp lý, Đạo đức, Quản trị đã quyết định loại bỏ và không phát hành một bộ dữ liệu mã độc hại được xác định, mặc dù dữ liệu này có thể hữu ích cho nghiên cứu bảo mật tương lai.

Rủi ro mở và an toàn Solaiman (2023) giải thích cách mức độ mở trong quy trình phát triển LLM được kết nối với những rủi ro tiềm ẩn liên quan đến việc phát hành mô hình. Khi các hệ thống được phát triển theo cách hoàn toàn đóng, quyền lực có nhiều khả năng trở nên tập trung ở các tổ chức có tài nguyên cao, và nhóm phát triển nhỏ có thể không hiểu đầy đủ tác động và hậu quả lâu dài của việc triển khai mô hình. Ngoài ra, các hệ thống phát triển đóng thường ít có thể kiểm toán bởi các chuyên gia bên ngoài và có thể cản trở tiến bộ khoa học vì các nhà nghiên cứu không thể xây dựng dựa trên công việc của nhau. Mặt khác, phát triển LLM hoàn toàn mở cho phép nghiên cứu cộng đồng, dân chủ hóa quyền truy cập vào các mô hình, và cho phép kiểm toán trong suốt toàn bộ quy trình phát triển. Tuy nhiên, không có các biện pháp bảo vệ thích hợp, phát triển LLM mở đặt ra rủi ro lạm dụng cao hơn, vì việc tăng quyền truy cập mô hình cũng tăng khả năng gây hại bởi mô hình. Ngay cả khi một API được phát hành có thể bị tắt, một khi trọng số mô hình được phát hành, gần như không thể thu hồi chúng. Thảo luận và triển khai các thực hành AI có trách nhiệm do đó đã là trung tâm và đầu trong suốt quá trình phát triển các LLM của dự án chúng tôi.

10.2 Hạn chế

Bộ dữ liệu và cấp phép dữ liệu StarCoder được huấn luyện trên một tập con của bộ dữ liệu The Stack v1.2. Bộ dữ liệu này đã được lọc bằng một detector giấy phép để chỉ bao gồm mã nguồn được cấp phép một cách cho phép. Tuy nhiên, detector giấy phép có thể đã phân loại sai một số kho. Xem Kocetkov et al. (2022) để biết thêm chi tiết về quy trình phát hiện giấy phép này.

Quy trình từ chối tham gia Mặc dù The Stack cung cấp cách để loại bỏ mã nhà phát triển, quy trình từ chối tham gia của nó chỉ áp dụng cho các kho riêng lẻ và có thể hưởng lợi từ các cải tiến thêm. Ví dụ, khi mã được cấp phép dưới giấy phép cho phép hoặc copyleft, nó có thể được sao chép đến kho khác, khiến việc loại bỏ những bản sao như vậy trở nên khó khăn nếu chủ sở hữu bản quyền chọn từ chối tham gia. Cần có nhiều công việc hơn để tạo ra các cơ chế kiểm soát và đồng ý dữ liệu tốt hơn cho các tập huấn luyện quy mô lớn của LLM.

Phát hiện PII Mặc dù chúng tôi nỗ lực hết sức để loại bỏ PII (Mục 4), StarCoder vẫn có thể tạo ra PII (tuy nhiên, lưu ý rằng giấy phép mô hình hạn chế việc sử dụng nhằm tạo hoặc phân tán PII với mục đích gây hại cho người khác). Như đã đề cập trong Mục 4.2, chúng tôi đã huấn luyện một mô hình chỉ encoder để phát hiện PII cho cả nhiệm vụ liên quan đến mã và văn bản và lưu ý rằng có khả năng dương tính giả và âm tính giả, có thể dẫn đến hậu quả không mong muốn khi xử lý dữ liệu nhạy cảm. Hơn nữa, hiệu suất của mô hình phát hiện PII có thể khác nhau trên các loại dữ liệu và ngôn ngữ lập trình khác nhau, cần xác thực và tinh chỉnh thêm cho các trường hợp sử dụng cụ thể. Các chú thích PII chỉ có sẵn cho các cá nhân được phê duyệt, và các nhà nghiên cứu và nhà phát triển được cấp quyền truy cập dự kiến sẽ duy trì các tiêu chuẩn đạo đức và các biện pháp bảo vệ dữ liệu. Bằng cách làm cho nó có thể truy cập, mục tiêu của chúng tôi là khuyến khích nghiên cứu và phát triển thêm công nghệ xóa PII.

Mã độc hại Trên nền tảng Hugging Face, nơi Stack được host, một công cụ phát hiện mã độc hại đã xác định 654 tệp là không an toàn. Với sự giúp đỡ của cộng đồng, chúng tôi đã loại bỏ những tệp này trước khi phát hành The Stack v1.2. Tuy nhiên, The Stack có thể chứa mã độc hại không được phát hiện, và StarCoder có thể có khả năng tạo malware. Giấy phép StarCoder OpenRAIL-M, do đó, bao gồm hạn chế sử dụng chống lại việc tạo và/hoặc phân tán malware (bao gồm — nhưng không giới hạn — ransomware) hoặc bất kỳ nội dung nào khác có thể được sử dụng để gây hại cho các hệ thống điện tử.

Hạn chế mô hình StarCoder có những hạn chế điển hình của LLM, bao gồm khả năng tạo nội dung không chính xác, gây phản cảm, sai lệch, phân biệt đối xử theo tuổi tác hoặc giới tính, hoặc củng cố các stereotype khác. Vui lòng tham khảo Mục 7.3 để điều tra về những lo ngại an toàn như vậy. Các triển khai StarCoder cần thách thức và điều chỉnh thêm mô hình để ngăn chặn hành vi như vậy, ví dụ: thông qua red-teaming (Perez et al., 2022), kiểm tra đối kháng (Wan et al., 2023), và/hoặc bằng cách thêm một lớp an toàn mạnh mẽ (OpenAI, 2023b). Mô hình được phát hành với giấy phép OpenRAIL-M đặt ra các hạn chế sử dụng có thể thực thi áp dụng cho mô hình và các sửa đổi của nó, và cho các ứng dụng sử dụng mô hình.

Đánh giá chỉ tiếng Anh Chúng tôi đã đánh giá hiệu suất của StarCoder duy nhất trên các benchmark dựa trên tiếng Anh để hiểu khả năng mã hóa và hiểu biết ngôn ngữ tự nhiên của nó. Để làm cho những mô hình này dễ tiếp cận hơn với đối tượng rộng hơn, nghiên cứu tương lai nên điều tra hiệu suất và hạn chế của Code LLM trên các ngôn ngữ tự nhiên khác.

Công cụ truy xuất nguồn gốc mã Công cụ kiểm tra thành viên StarCoder và chỉ mục tìm kiếm BM25 được giới hạn trong việc kiểm tra bộ dữ liệu chống lại tập con của The Stack được sử dụng để huấn luyện và, như vậy, sẽ không tìm thấy khớp với mã không được bao gồm hoặc đã bị loại bỏ khỏi bộ dữ liệu cho dự án này. Công cụ kiểm tra thành viên dựa trên Portraits sử dụng hash matching và do đó có thể có dương tính giả. Nó cũng có độ phân giải tối thiểu và yêu cầu một lượng ngữ cảnh nhất định để kích hoạt khớp. Cả hai công cụ truy xuất nguồn gốc đều không cố gắng phân biệt giữa mã generic (ví dụ: boilerplate) hoặc nội dung được bảo vệ. Tuy nhiên, chúng tôi hy vọng rằng những công cụ này sẽ hỗ trợ nghiên cứu đang diễn ra về phát triển có trách nhiệm LLM.

10.3 Tác động xã hội

Code LLMs Chúng tôi mong đợi Code LLM cho phép mọi người từ các nền tảng đa dạng học viết mã chất lượng cao hơn và phát triển các ứng dụng low-code (Leinonen et al., 2023). Phần mềm nhiệm vụ quan trọng có thể trở nên dễ bảo trì hơn khi các nhà phát triển chuyên nghiệp được hướng dẫn bởi các hệ thống tạo mã về cách viết mã mạnh mẽ và hiệu quả hơn. Tuy nhiên, các tác động bảo mật cũng nên được xem xét cẩn thận (Sandoval et al., 2023). Trong khi tác động xã hội được dự định là tích cực, việc tăng khả năng tiếp cận Code LLM đi kèm với những rủi ro nhất định như sự phụ thuộc quá mức vào mã được tạo và tác động lâu dài đến thị trường việc làm phát triển phần mềm. Chúng tôi giới thiệu độc giả đến Chen et al. (2021, Mục 7) để phân tích tác động rộng hơn của Code LLM, cũng như Khlaaf et al. (2022) để đánh giá rủi ro sâu và phân tích mối nguy hiểm của công nghệ mới nổi này.

Chú thích dữ liệu Điều quan trọng đối với dự án là chỉ sử dụng các dịch vụ chú thích dữ liệu có uy tín. Cũng quan trọng là cân bằng các ràng buộc về chi phí (đền bù công bằng), thời gian (thời điểm và thời gian hoàn thành công việc trên đường dẫn quan trọng cho dự án), và chất lượng (để đảm bảo rằng việc huấn luyện Mô hình Phát hiện PII không bị ảnh hưởng). Trong khi các dịch vụ chú thích dữ liệu truyền thống sử dụng nhân viên có lương được xem xét, quyết định làm việc với các nhân viên đám đông Toloka được thực hiện sau khi xem xét các nhà cung cấp dịch vụ và thực hành đền bù của họ — hầu hết sẽ không cung cấp đủ minh bạch và đảm bảo về đền bù nhân viên. Việc xác định đền bù của chúng tôi đã tính đến các mức lương tối thiểu khác nhau giữa các quốc gia và sức mua tương ứng của họ. Chúng tôi giới hạn tính đủ điều kiện chú thích cho các quốc gia mà mức lương theo giờ $7.30 tương đương với mức lương tối thiểu cao nhất ở Hoa Kỳ ($16.50) về mặt sức mua.

Form phản hồi từ chối tham gia Trong giai đoạn đầu của quy trình từ chối tham gia, các cá nhân được yêu cầu chỉ định lý do muốn loại trừ mã của họ khỏi bộ dữ liệu. Những lo ngại lặp lại mà chúng tôi nghe từ cá nhân muốn từ chối tham gia là:
• Ưu tiên cách tiếp cận opt-in thay vì opt-out.
• Nhận thức rằng không công bằng khi sử dụng mã của họ mà không có đền bù
• Lo ngại về những hạn chế hiện tại của AI và khả năng các thế hệ mô hình được truy xuất ngược lại công việc của họ, dẫn đến trách nhiệm pháp lý tiềm ẩn.
• Tin rằng mã của họ có chất lượng kém và không phù hợp để huấn luyện AI.
• Sự hiện diện của PII trong mã của họ, mà họ không muốn bị tiết lộ công khai.

Form từ chối tham gia do đó cung cấp cơ hội để tương tác trực tiếp với những người tạo nội dung và học hỏi về tác động của công việc của chúng tôi đối với họ.

Phản hồi cộng đồng về quy trình từ chối tham gia Chúng tôi đã tiến hành nghiên cứu cộng đồng với các cá nhân tại các tổ chức cụ thể có dữ liệu được sử dụng trong The Stack (The Alan Turing Institute và The Turing Way) và đóng góp cho hai hội thảo mở, quốc tế (Open Data Day 2023 và Mozilla Festival 2023 với một phiên có tiêu đề 'Designing for Data Rights in the AI Production Pipeline'). Những cuộc phỏng vấn định tính và hội thảo thiết kế tham gia này bao gồm 50 người tham gia, chủ yếu từ Bắc Mỹ và Châu Âu, với các vai trò bao gồm nhà khoa học nghiên cứu, quản lý cộng đồng, kỹ sư phần mềm, và điều tra viên chính (PI). Kết quả từ nghiên cứu cộng đồng có thể được tóm tắt như sau: khi nói đến quản trị bộ dữ liệu LLM, người tham gia cảm thấy rằng vừa tốt hơn khi biết và vừa tốt hơn khi có lựa chọn. Hầu hết người tham gia có cảm xúc trung tính đến tích cực về việc dữ liệu được cấp phép một cách cho phép của họ được sử dụng để huấn luyện LLM. Trong khi tất cả đều có ấn tượng tích cực về công cụ "Am I in The Stack", không một ai được phỏng vấn bày tỏ mong muốn thực sự từ chối tham gia. Điểm chính có vẻ là người tham gia thấy giá trị nhất trong các công cụ quản trị của dự án vì khả năng nâng cao nhận thức về thực hành dữ liệu và trao quyền cho các cá nhân và cộng đồng thực hiện hành động dựa trên nhu cầu cụ thể của họ. Những cuộc trò chuyện ban đầu này cũng làm nổi bật tầm quan trọng của việc đưa các cuộc thảo luận và quyết định quản trị trực tiếp đến các cộng đồng bị ảnh hưởng, một hướng quan trọng của công việc tương lai nên mở rộng nghiên cứu cộng đồng ra ngoài Bắc Mỹ và Châu Âu. Người tham gia trong các hội thảo cũng đưa ra các ví dụ về các nhóm mới để tập trung vào việc xem xét quyền dữ liệu, bao gồm nghệ sĩ, thợ mỏ dữ liệu, và các thế hệ tương lai. Các đầu ra được tạo chung có thể được xem trên Bảng Miro MozFest này.

11 Kết luận

Trong báo cáo kỹ thuật này, chúng tôi đã mô tả những nỗ lực của cộng đồng BigCode trong việc tạo ra StarCoderBase và StarCoder, các mô hình ngôn ngữ lớn truy cập mở 15.5 tỷ tham số được huấn luyện trên mã. Chúng tôi đã cung cấp minh bạch đầy đủ về tất cả các khía cạnh của quy trình nghiên cứu và phát triển, bao gồm dữ liệu huấn luyện, quy trình curation dữ liệu, pipeline xóa PII, và huấn luyện mô hình. Chúng tôi đã tiến hành đánh giá toàn diện nhất về Code LLM cho đến nay, thấy rằng StarCoder vượt trội hơn các Code LLM khác như CodeGen (Nijkamp et al., 2023) và CodeGeeX (Zheng et al., 2023), và khớp hoặc vượt trội hơn mô hình code-cushman-001 đóng của OpenAI. Bằng cách phát hành các mô hình StarCoder với giấy phép Open Responsible AI Model, và bằng cách mở nguồn tất cả các kho mã để xây dựng mô hình trên GitHub, chúng tôi nhằm tăng quyền truy cập, khả năng tái tạo, và minh bạch của Code LLM trong cộng đồng nghiên cứu và nhà phát triển. Giấy phép mô hình bao gồm các hạn chế sử dụng để đảm bảo rằng các sửa đổi của mô hình và ứng dụng sử dụng mô hình tuân thủ các nguyên tắc AI có trách nhiệm của chúng tôi. Ngoài ra, chúng tôi đã phát hành một tập hợp các công cụ truy xuất nguồn gốc mới để giúp người dùng cuối của Code LLM phát hiện và định vị các thế hệ mô hình có thể đã được sao chép từ tập huấn luyện. Chúng tôi hy vọng những biện pháp này đóng góp vào việc phát hành mô hình an toàn, đảm bảo rằng các mô hình StarCoder hiệu suất mạnh vẫn là một lực lượng cho điều tốt đẹp.

Lời cảm ơn Chúng tôi muốn cảm ơn Hugging Face vì đã cung cấp tài nguyên tính toán để huấn luyện các mô hình StarCoder. Chúng tôi cũng cảm ơn Suriya Gunasekar vì sự giúp đỡ với việc kiểm tra dữ liệu, và Sebastien Paquet vì việc đọc lại công việc này. Carolyn Jane Anderson, Arjun Guha, Ming-Ho Yee, và Yangtian Zi được hỗ trợ bởi các giải thưởng của Quỹ Khoa học Quốc gia Hoa Kỳ SES-2326174 và CCF-2102288. Evgenii Zheltonozhskii được hỗ trợ bởi Chương trình Adams Fellowships của Viện Hàn lâm Khoa học và Nhân văn Israel.

[Phần còn lại của tài liệu bao gồm các tài liệu tham khảo, phụ lục và bảng bổ sung sẽ được dịch tiếp theo nếu cần...]

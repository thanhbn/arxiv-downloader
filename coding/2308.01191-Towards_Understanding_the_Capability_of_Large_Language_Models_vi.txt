Hướng tới Hiểu biết về Khả năng của Mô hình Ngôn ngữ Lớn trong Phát hiện Clone Code: Một Khảo sát

Shihan Dou∗
shdou21@m.fudan.edu.cn
Đại học Fudan
Thượng Hải, Trung Quốc

Junjie Shan∗†
jshan@kth.se
Đại học Westlake
Hàng Châu, Trung Quốc

Haoxiang Jia
haoxiangjia@hust.edu.cn
Đại học Khoa học và Công nghệ Hoa Trung
Vũ Hán, Trung Quốc

Wenhao Deng
wenhao.deng@foxmail.com
Đại học Westlake
Hàng Châu, Trung Quốc

Zhiheng Xi
zhxi22@m.fudan.edu.cn
Đại học Fudan
Thượng Hải, Trung Quốc

Wei He
whe23@m.fudan.edu.cn
Đại học Fudan
Thượng Hải, Trung Quốc

Yueming Wu‡
wuyueming21@gmail.com
Đại học Công nghệ Nanyang
Singapore

Tao Gui
tgui@fudan.edu.cn
Đại học Fudan
Thượng Hải, Trung Quốc

Yang Liu
yangliu@ntu.edu.sg
Đại học Công nghệ Nanyang
Singapore

Xuanjing Huang
xjhuang@fudan.edu.cn
Đại học Fudan
Thượng Hải, Trung Quốc

Tóm tắt

Nhân bản code, việc sao chép các đoạn code, là hiện tượng phổ biến trong phát triển phần mềm. Trong khi một số việc tái sử dụng giúp tăng năng suất, việc nhân bản quá mức làm tổn hại tính duy trì và gây ra lỗi. Do đó, phát hiện nhân bản code tự động là rất quan trọng. Đồng thời, các mô hình ngôn ngữ lớn (LLMs) sở hữu kiến thức đa dạng liên quan đến code, khiến chúng trở nên linh hoạt cho các thách thức kỹ thuật phần mềm khác nhau. Tuy nhiên, hiệu suất của LLMs trong phát hiện nhân bản code vẫn chưa rõ ràng và cần nghiên cứu thêm để đánh giá chính xác. Trong bài báo này, chúng tôi cung cấp đánh giá toàn diện đầu tiên về LLMs cho phát hiện clone, bao gồm các loại clone khác nhau, ngôn ngữ và prompt. Chúng tôi phát hiện các LLMs tiên tiến xuất sắc trong việc phát hiện các clone ngữ nghĩa phức tạp, vượt trội so với các phương pháp hiện tại. Việc thêm các bước lý luận trung gian thông qua prompt chain-of-thought cải thiện đáng kể hiệu suất. Ngoài ra, việc biểu diễn code dưới dạng vector embeddings, đặc biệt với text encoders, giúp phát hiện clone hiệu quả. Cuối cùng, khả năng phát hiện clone code của LLMs khác nhau giữa các ngôn ngữ lập trình khác nhau. Nghiên cứu của chúng tôi cho thấy LLMs có tiềm năng cho phát hiện clone nhờ khả năng ngôn ngữ của chúng, cung cấp thông tin chi tiết để phát triển các phương pháp dựa trên LLM mạnh mẽ nhằm nâng cao kỹ thuật phần mềm.

Khái niệm CCS
• Phần mềm và kỹ thuật của nó → Công cụ bảo trì phần mềm.

Từ khóa
Phát hiện Clone Code, Mô hình Ngôn ngữ Lớn, Nghiên cứu

1 Giới thiệu

Nhân bản code, việc sao chép các đoạn code, là hiện tượng phổ biến trong phát triển phần mềm. Trong khi một số việc tái sử dụng code giúp tăng năng suất, việc nhân bản quá mức ảnh hưởng tiêu cực đến tính duy trì và lan truyền lỗi [25,36]. Do đó, phát hiện clone tự động là một lĩnh vực nghiên cứu quan trọng. Để hiểu rõ hơn về phát hiện clone, các nhà nghiên cứu đã thực hiện phân loại có hệ thống các code clones thành các danh mục riêng biệt. Một phân loại được chấp nhận rộng rãi chia code clones thành bốn loại: Type-1 (giống hệt nhau), Type-2 (giống nhau về từ vựng), Type-3 (giống nhau về cú pháp), và Type-4 (giống nhau về ngữ nghĩa) [7,56]. Ba loại đầu có thể được tóm gọn dưới thuật ngữ tương đồng cú pháp, trong khi loại thứ tư biểu thị tương đồng ngữ nghĩa. Vì Type-4 clones có thể bao gồm các clone hiển thị nhiều khác biệt cú pháp, chúng đặt ra thách thức ghê gớm nhất cho hầu hết các phương pháp phát hiện clone. Tồn tại nhiều tài liệu tập trung vào tương đồng cú pháp code [48,57,59]. Tuy nhiên, trong những năm gần đây, sự chú ý dần chuyển sang nghiên cứu tương đồng ngữ nghĩa code. Sự chuyển đổi này được hỗ trợ bởi những tiến bộ trong lĩnh vực mạng nơ-ron sâu. Kết quả là, một loạt các phương pháp dựa trên deep learning được đề xuất, tất cả được thiết kế để phân biệt tương đồng ngữ nghĩa thông qua quá trình học từ dữ liệu [39]. Các phương pháp này chủ yếu áp dụng cách tiếp cận hai mặt: đầu tiên, mạng nơ-ron được tận dụng để tạo ra biểu diễn vector cho mỗi đoạn code, sau đó tính toán tương đồng giữa các biểu diễn vector của hai đoạn code để phát hiện clones [76].

Thực tế, sự phát triển của các mô hình ngôn ngữ được đào tạo trước (PLMs) đã cách mạng hóa lĩnh vực deep learning. Các mô hình này, như BERT [33] và GPT-1 [53], được đào tạo trước với các tác vụ đào tạo trước được thiết kế đặc biệt trên các kho ngữ liệu văn bản không nhãn quy mô lớn để học kiến thức tổng quát. Sau đó, nhiều công trình như CodeBERT [16] và CodeT5+ [70] giới thiệu đào tạo trước để nâng cao hơn nữa các tác vụ liên quan đến code trong kỹ thuật phần mềm. Mặc dù các công trình này có hiệu suất tuyệt vời, chúng vẫn cần được fine-tuned để thích ứng với các tác vụ downstream khác nhau [45,60]. Gần đây, các nhà nghiên cứu đã phát hiện rằng việc mở rộng PLMs (ví dụ, mở rộng kích thước mô hình hoặc kích thước dữ liệu) thường dẫn đến cải thiện khả năng mô hình trên các tác vụ downstream [32]. Mặc dù việc mở rộng chủ yếu được thực hiện trong kích thước mô hình với kiến trúc và tác vụ đào tạo trước tương tự, các PLMs kích thước lớn này (ví dụ, GPT-3 [8], MPT [63], LLaMA [64]) hiển thị hành vi khác biệt so với PLMs nhỏ hơn (ví dụ, BERT 330M tham số và GPT-2 1.5B tham số [54]) và cho thấy khả năng đáng ngạc nhiên trong việc giải quyết một loạt tác vụ phức tạp chỉ với hướng dẫn của con người thay vì fine-tuning để thích ứng các tác vụ downstream [8, 72]. Hơn nữa, vì kho ngữ liệu đào tạo trước của các mô hình ngôn ngữ lớn (LLMs) này chứa một lượng lớn các tác vụ code, chúng cũng được trang bị để giải quyết nhiều thách thức liên quan đến code trong kỹ thuật phần mềm. Ví dụ, Feng et al. [15] đề xuất một kỹ thuật tự động để thực hiện bug replay từ báo cáo lỗi thông qua prompt engineering. Deng et al. [11] đề xuất một công cụ testing, sử dụng các LLMs generative và infilling để tạo và biến đổi các chương trình khác nhau để test thư viện deep learning. Tuy nhiên, thiếu sự hiểu biết về hiệu suất của các LLMs này trong phát hiện clone code.

Trong bài báo của chúng tôi, chúng tôi đi sâu vào tiềm năng tận dụng LLMs để phát hiện code clones. Giả thuyết của chúng tôi xoay quanh khả năng bẩm sinh của LLMs trong việc diễn giải các đầu vào ngôn ngữ phức tạp và tạo ra các đầu ra có ý nghĩa. Chúng tôi đưa ra giả định rằng những kỹ năng này có thể được khai thác để xác định và phân loại code clones, do đó cung cấp một cách tiếp cận mới cho vấn đề phát hiện clone code truyền thống. Cụ thể, chúng tôi thực hiện một nghiên cứu toàn diện để đánh giá hiệu suất phát hiện clone của các LLMs như Llama [64], Alpaca [61], Vicuna [83], StarChat-β [66], Falcon [4], MPT [63], Llama2 [65], Llama2-Chat [65], GPT-3.5 [50], và GPT-4 [49]. Nghiên cứu của chúng tôi tập trung vào các câu hỏi nghiên cứu sau:

• RQ1: LLMs có thể phát hiện code clones với một prompt đơn giản không?
• RQ2: LLMs hoạt động như thế nào khi sử dụng prompt chain-of-thought một bước?
• RQ3: LLMs có thể hoạt động tốt hơn bằng cách sử dụng prompt chain-of-thought nhiều bước không?
• RQ4: LLMs hoạt động như thế nào khi sử dụng code embedding?
• RQ5: Hiệu suất của LLMs trong phát hiện clone code thay đổi như thế nào giữa các ngôn ngữ lập trình khác nhau?

Liên quan đến RQ1, phát hiện của chúng tôi cho thấy khi chỉ sử dụng một prompt đơn giản, phát hiện clone dựa trên LLMs mã nguồn mở hoạt động tốt hơn trong việc phát hiện các cặp clone Type-3 và Type-4 so với các công cụ hiện tại. Tuy nhiên, nó hoạt động hơi kém hơn trong việc phát hiện các cặp clone Type-1 và Type-2. GPT-3.5-Turbo và GPT-4 có recall và độ chính xác cao nhất trong hầu hết tất cả các loại clone. Liên quan đến RQ2, quan sát của chúng tôi cho thấy việc sử dụng lý luận chain-of-thought một bước cải thiện đáng kể hiệu suất của GPT-3.5-Turbo và GPT-4. Cải thiện này được quy cho lý luận trung gian, cho phép các mô hình lớn hơn xem xét code từ nhiều góc độ, dẫn đến phát hiện clone chính xác hơn. Đáng ngạc nhiên, khi kết hợp tất cả lý luận trung gian lại với nhau, hiệu quả của GPT-3.5-Turbo giảm, và thậm chí hoạt động kém hơn so với khi sử dụng prompt đơn giản. Ngược lại, phát hiện của GPT-4 không bị ảnh hưởng bởi sự tích hợp này. Liên quan đến RQ3, khi nhiều lý luận được tạo ra đồng thời, chúng tôi quan sát thấy lý luận từ các góc độ khác nhau có thể can thiệp lẫn nhau, dẫn đến giảm kết quả phát hiện. Hơn nữa, chúng tôi cũng thực hiện mô phỏng phát hiện clone dựa trên deep learning bằng cách tạo ra giải thích code độc lập cho mỗi cặp code. Cách tiếp cận này mang lại kết quả tích cực và có thể đạt được kết quả phát hiện clone chính xác và đáng tin cậy hơn. Liên quan đến RQ4, khi nói đến code embedding, Text-embedding-ada-002 hiệu quả hơn các mô hình CodeBERT chuyên biệt trong việc xác định code được nhân bản, thể hiện hiệu suất tổng thể vượt trội. Liên quan đến RQ5, chúng tôi phát hiện rằng hiệu quả của LLMs trong phát hiện code clones khác nhau giữa các ngôn ngữ lập trình khác nhau, với Python thường tạo ra kết quả tốt hơn, có thể vì nó đơn giản tự nhiên và được sử dụng thường xuyên trong dữ liệu đào tạo.

Tóm lại, bài báo của chúng tôi đóng góp như sau:

• Chúng tôi thực hiện nghiên cứu thực nghiệm đầu tiên để đánh giá khả năng của các LLMs hiện tại trong phát hiện code clones từ năm góc độ khác nhau (tức là, prompt đơn giản, prompt chain-of-thought một bước, prompt chain-of-thought nhiều bước, code embedding, và nhiều ngôn ngữ lập trình).

• Chúng tôi công khai tất cả dữ liệu và code liên quan đến nghiên cứu của chúng tôi và cung cấp thông tin chi tiết có giá trị về khả năng và hạn chế của LLMs cho phát hiện clone code. Kết quả thu được sẽ phục vụ như hướng dẫn thiết yếu cho nghiên cứu tương lai nhằm cải thiện phát hiện clone dựa trên LLM và các khía cạnh khác của kỹ thuật phần mềm.

Tổ chức bài báo. Phần còn lại của bài báo được tổ chức như sau. Phần 2 giải thích background. Phần 3 giới thiệu thiết lập thí nghiệm của chúng tôi. Phần 4 báo cáo kết quả thí nghiệm. Phần 5 thảo luận công việc tương lai. Phần 6 kết luận bài báo hiện tại.

2 Background và Công trình Liên quan

Trong phần này, chúng tôi giới thiệu ngắn gọn về phát hiện clone code, Mô hình Ngôn ngữ Lớn (LLMs), và lý luận chain-of-thought.

2.1 Phát hiện Clone Code

Phát hiện clone code nhằm khai thác các đoạn code có chức năng tương tự, điều này đã thu hút sự chú ý rộng rãi trong kỹ thuật phần mềm [6,34,57]. Thông thường, các loại clone code được phân loại thành bốn danh mục dựa trên sự khác biệt cú pháp hoặc ngữ nghĩa [7]. Type-1 (giống hệt nhau) đề cập đến các đoạn code giống hệt nhau, chỉ khác về khoảng trắng, bố cục và comment. Type-2 (giống nhau về từ vựng) bao gồm các đoạn code giống hệt nhau với biến thể trong tên định danh và giá trị từ vựng, ngoài những khác biệt có trong Type-1 clones. Type-3 (giống nhau về cú pháp) bao gồm các đoạn code tương tự về cú pháp khác nhau ở cấp độ câu lệnh. Ngoài những khác biệt có trong Type-1 và Type-2 clones, những đoạn này có các câu lệnh được thêm, sửa đổi và/hoặc loại bỏ so với nhau. Type-4 (giống nhau về ngữ nghĩa) đề cập đến các đoạn code khác nhau về cú pháp nhưng thực hiện cùng chức năng.

Nhiều cách tiếp cận đã được đề xuất để phát hiện code clones, chúng có thể được phân loại rộng rãi thành các loại khác nhau, bao gồm các công cụ dựa trên text [13,27,30,35,55,57,77], dựa trên token [19,20,26,31,41,59,68], dựa trên tree [9,24,28,29,44,51,71,75,79], và dựa trên graph [37,38,67,76,81,85]. Hơn nữa, kể từ khi trích xuất đặc trưng tự động của deep learning, nó cũng đang được áp dụng ngày càng nhiều cho các tác vụ phát hiện code nhân bản bằng cách xử lý các biểu diễn code khác nhau [24,71,75,76,79,81]. Tuy nhiên, kể từ sự phát triển nhanh chóng của các mô hình ngôn ngữ lớn, chưa có công trình nào phát hiện code nhân bản bằng cách sử dụng các mô hình ngôn ngữ lớn, và chưa có khám phá kỹ lưỡng hơn về hiệu suất của các mô hình ngôn ngữ lớn để phát hiện code clones.

2.2 Mô hình Ngôn ngữ Lớn

Những tiến bộ gần đây trong Mô hình Ngôn ngữ Lớn (LLMs) đã châm ngòi một cuộc cách mạng trong Xử lý Ngôn ngữ Tự nhiên (NLP). Nói chung, một mô hình ngôn ngữ lớn là một mô hình dựa trên Transformer chứa hàng trăm tỷ (hoặc nhiều hơn) tham số, như LLaMA [64], Vicuna [83], Falcon [4], StarChat-β [66] và GPT4 [49]. Những mô hình này, được đào tạo trên kho ngữ liệu văn bản khổng lồ, có khả năng học một loạt kiến thức rộng lớn từ văn bản, từ đó giải quyết vô số tác vụ phức tạp trong NLP và hiểu các truy vấn của con người để tham gia vào các cuộc đối thoại không giới hạn.

Trong bối cảnh các tác vụ chuỗi ngôn ngữ trước đây, bao gồm cả ngôn ngữ tự nhiên và lập trình, hiệu suất thỏa đáng đã được đạt được thông qua fine-tuning đặc thù cho tác vụ [60]. Fine-tuning là quá trình cập nhật trọng số mô hình bằng cách học mối quan hệ giữa đầu vào và đầu ra từ tập dữ liệu tác vụ downstream cụ thể [45]. Tuy nhiên, với kiến thức toàn diện được đóng gói trong LLMs, một phương pháp mới, được gọi là In-context Learning [10], có thể được sử dụng để áp dụng LLMs cho các tác vụ downstream. Trái ngược với fine-tuning, thường cần tập dữ liệu downstream lớn để điều chỉnh mô hình, in-context learning cho phép LLMs hiểu các tác vụ thông qua hướng dẫn và ví dụ, tận dụng khả năng vốn có của chúng [12,72]. Trong nghiên cứu này, chúng tôi phát triển nhiều hướng dẫn để hướng dẫn LLMs hiểu tác vụ phát hiện clone code từ nhiều góc độ, từ đó tạo điều kiện cho đánh giá toàn diện hiệu suất của LLMs về phát hiện clone code.

2.3 Lý luận Chain-of-Thought

Các mô hình ngôn ngữ nhỏ truyền thống thường gặp khó khăn trong việc giải quyết các tác vụ phức tạp hoặc trả lời các câu hỏi khó đòi hỏi nhiều bước lý luận, như các bài toán từ toán học. Ngược lại, LLMs, sử dụng chiến lược prompting chain-of-thought (CoT) [73], có thể giải quyết những tác vụ này hoặc phân tích các vấn đề phức tạp bằng cách sử dụng quá trình lý luận trung gian để đưa ra câu trả lời cuối cùng. CoT prompting, khác biệt với prompt trả lời trực tiếp truyền thống, cho phép mô hình xây dựng một quá trình suy nghĩ cho câu hỏi trước khi đưa ra câu trả lời. Hoặc nó có thể phân tách thủ công một câu hỏi phức tạp thành nhiều bước trung gian để mô hình giải quyết. Cách tiếp cận này, tương tự như quá trình nhận thức của con người, có thể tăng cường hiệu suất của các mô hình lớn khi đối mặt với các vấn đề phức tạp. Một số nghiên cứu [18,43,80] đã chứng minh rằng CoT prompting có thể mang lại những cải thiện hiệu suất đáng kể trong các benchmark lý luận phức tạp.

Với hiệu quả đã được chứng minh của CoT prompting trong việc tăng độ chính xác của việc giải quyết vấn đề phức tạp bằng cách giới thiệu các bước lý luận trung gian, bài báo này nhằm điều tra hiệu suất của CoT trong tác vụ phát hiện clone code, cả từ góc độ một bước và nhiều bước. Trong prompt engineering một bước, mô hình được giao nhiệm vụ phát hiện code clones từ các góc độ khác nhau (tức là, loại clone, tương đồng, và các dòng code tương tự của cặp). Trong prompt engineering nhiều bước, mô hình ban đầu phân tích mỗi hàm từ nhiều góc độ, sau đó tích hợp tất cả các lý luận trung gian. Cách tiếp cận này cho phép mô hình phát hiện code clones với kiến thức trước, thay vì chỉ đơn thuần theo hướng dẫn của con người để đưa ra phản hồi nhị phân "có" hoặc "không".

3 Thiết lập Thí nghiệm

3.1 Câu hỏi Nghiên cứu

Nghiên cứu thực nghiệm của chúng tôi đi sâu vào năm câu hỏi nghiên cứu để cải thiện sự hiểu biết về phát hiện clone code sử dụng LLMs.

• RQ1: LLMs có thể phát hiện code clones với một prompt đơn giản không?
Chúng tôi nhằm khám phá hiệu suất của LLMs trong các tác vụ phát hiện clone code dưới những điều kiện này. Cụ thể, chúng tôi thiết kế một prompt để yêu cầu LLMs trả lời việc đánh giá phát hiện clone code trực tiếp, mong đợi chúng xuất ra một "Có" hoặc "Không" đơn giản. Điều này tạo điều kiện cho phân tích dữ liệu qua các loại clone khác nhau.

• RQ2: LLMs hoạt động như thế nào khi sử dụng prompt chain-of-thought một bước?
Với bản chất vốn có của các mô hình ngôn ngữ như các ước lượng xác suất hậu nghiệm, chúng tôi có ý định cải thiện hiệu suất LLM bằng cách thay đổi hướng dẫn cho các góc độ khác nhau. Cụ thể, chúng tôi thiết kế các prompt để hướng dẫn mô hình thực hiện phân tích code trước khi đánh giá phát hiện clone code. Phân tích code bao gồm năm kỹ thuật: phân biệt loại clone, tính toán tương đồng, giải thích lý luận, phân biệt dòng tương tự, và phân tích tích hợp.

• RQ3: LLMs có thể hoạt động tốt hơn bằng cách sử dụng prompt chain-of-thought nhiều bước không?
Trong khi chúng tôi đã hướng dẫn mô hình phân tích clone code từ một hoặc vài góc độ trong RQ2, các mô hình ngôn ngữ có thể bị ảnh hưởng bởi các yếu tố khác trong quá trình phân tích code, bao gồm code đối tác trong một cặp code hoặc các góc phân tích khác nhau. Vì vậy, chúng tôi thiết kế các prompt dựa trên lý luận chain-of-thought và phân loại chúng thành hai loại: giải thích riêng biệt và code riêng biệt. Loại trước prompt các LLMs xuất ra cùng thông tin phân tích code như trong RQ2, và sau đó, chúng tôi yêu cầu các LLMs, dựa trên đầu ra này, thực hiện độc lập việc phát hiện clone code. Loại sau prompt các LLMs giải thích độc lập chức năng của mỗi đoạn code. Sau đó, dựa trên những đầu ra này, chúng tôi yêu cầu các LLMs thực hiện phát hiện clone code độc lập. Mục tiêu cuối cùng là cho phép mô hình phân tích độc lập mỗi code trong cặp hoặc từ các góc độ khác nhau, tổng hợp kết quả phân tích, và áp dụng những phát hiện này để thực hiện phát hiện clone code cuối cùng chính xác hơn.

• RQ4: LLMs hoạt động như thế nào khi sử dụng code embedding?
Câu hỏi này tập trung vào liệu LLMs có thể cung cấp kết quả vượt trội so với các mô hình ngôn ngữ đào tạo trước truyền thống (PLMs) thông qua nén code. Chúng tôi so sánh hiệu suất của LLMs với các mô hình cụ thể như CodeBERT-base, CodeBERT-mlm, và text-embedding-ada-002. So sánh này tận dụng embedding API được cung cấp bởi OpenAI [2]. Vì câu hỏi nghiên cứu này chủ yếu so sánh hiệu suất của các mô hình embedding hiện tại, chúng tôi không thiết kế prompt cụ thể cho nó.

• RQ5: Hiệu suất của LLMs trong phát hiện clone code thay đổi như thế nào giữa các ngôn ngữ lập trình khác nhau?
Chúng tôi nhằm phân biệt liệu LLMs có thể hiện hiệu suất khác nhau trong phát hiện clone code qua các ngôn ngữ lập trình khác nhau. Để so sánh công bằng, chúng tôi áp dụng các prompt từ RQ1 mà không chỉ định ngôn ngữ của các đoạn code mục tiêu. Điều này cho phép đánh giá tính linh hoạt của LLMs trong việc xử lý các ngôn ngữ lập trình đa dạng.

3.2 Hướng dẫn

Chúng tôi thiết kế các prompt khác nhau để kích thích khả năng của các mô hình ngôn ngữ lớn. Ví dụ về các prompt được hiển thị trong Bảng 1.

3.3 Thu thập Tập dữ liệu

Các đánh giá của chúng tôi được thực hiện sử dụng tập dữ liệu BigCloneBench [1], một bộ sưu tập toàn diện hơn 8 triệu cặp clone được gán nhãn từ 25.000 hệ thống. Mỗi cặp clone trong BigCloneBench tương ứng với code cấp hàm và được gán thủ công một loại clone thích hợp. Các loại clone được chia thành Type-1 và Type-2, với các danh mục phụ bổ sung cho Type-3 và Type-4 clones dựa trên điểm tương đồng cú pháp của chúng. Bao gồm i) Very Strongly Type-3 (VST3) clones, với điểm tương đồng trong khoảng [0.9, 1.0); ii) Strongly Type-3 (ST3) clones, với điểm tương đồng giữa [0.7, 0.9); iii) Moderately Type-3 (MT3) clones, với điểm tương đồng giữa [0.5, 0.7); và iv) Weakly Type-3/Type-4 (WT3/T4) clones, với điểm tương đồng giữa [0.0, 0.5).

Ngoài Java, nghiên cứu của chúng tôi cũng bao gồm các ngôn ngữ lập trình C/C++ và Python. Đối với những ngôn ngữ này, chúng tôi rút ra các tập dữ liệu từ CodeNet [52], kết hợp các benchmark C++ và Python. Vì các loại clone trong các benchmark C++ và Python không được phân loại trước trong CodeNet, chúng tôi thực hiện phân loại theo tiêu chuẩn được đặt bởi BigCloneBench. Điều này bao gồm việc sử dụng các trình phân tích từ vựng tương ứng cho việc tokenization code Python và C++, sau đó chúng tôi tính toán chỉ số Jaccard để đo điểm tương đồng cú pháp. Dựa trên những điểm số này, chúng tôi phân loại các code clones cho mỗi ngôn ngữ, do đó xây dựng một tập dữ liệu phát hiện clone code toàn diện và đa dạng cho các ngôn ngữ lập trình khác nhau.

Để đảm bảo đánh giá mạnh mẽ và toàn diện qua tất cả các ngôn ngữ lập trình được xem xét, chúng tôi lấy mẫu tỉ mỉ các tập dữ liệu của mình. Từ tập dữ liệu BigCloneBench, chúng tôi lấy mẫu 500 cặp code cho mỗi loại clone và bao gồm 3000 mẫu không clone. Đối với các ngôn ngữ C++ và Python, chúng tôi lấy mẫu 100 cặp code cho mỗi loại clone và bổ sung những mẫu này với 600 mẫu không clone. Việc lấy mẫu đa dạng này được thực hiện trong khi tuân thủ nghiêm ngặt các ràng buộc của tài nguyên GPU tính toán có sẵn của chúng tôi.

3.4 Mô hình Ngôn ngữ

Chúng tôi đánh giá 12 mô hình ngôn ngữ, bao gồm nhiều mô hình mã nguồn mở có thể triển khai cục bộ, LLMs dựa trên API, một mô hình code embedding được tạo bởi LLM, và các mô hình ngôn ngữ đào tạo trước cho code embedding.

3.4.1 Mô hình Ngôn ngữ Lớn Mã nguồn mở

Tám trong số các mô hình chúng tôi đánh giá là LLMs mã nguồn mở, có khả năng triển khai cục bộ. Bao gồm LLaMA [64], Alpaca [62], Vicuna [83], Falcon [4], MPT [63], LLaMA2 [65], LLaMA2-Chat [65], và StarChat-β [66]. Mỗi mô hình này đã được đào tạo trên kho ngữ liệu lớn bao gồm cả văn bản và code, với tham số trong khoảng tỷ. Những mô hình này được sử dụng để tận dụng khả năng học quy mô lớn của chúng cho phát hiện clone code.

LLaMA [64] và LLaMA2 [65]: LLaMA và LLaMA2 là các mô hình ngôn ngữ lớn đã được đào tạo trên kho ngữ liệu kết hợp hàng nghìn tỷ token. Kho ngữ liệu này bao gồm cả văn bản và code. Cả hai mô hình đều thể hiện hiệu suất đáng chú ý qua các benchmark khác nhau, nhấn mạnh độ tin cậy của chúng. Cho các thí nghiệm của chúng tôi, chúng tôi triển khai phiên bản 7 tỷ tham số của LLaMA, được gọi là LLaMA-7B. Mặt khác, LLaMA2 đã trải qua quá trình làm sạch nghiêm ngặt hơn trong quá trình đào tạo và liên tục cho thấy kết quả tuyệt vời trên các benchmark mở [65]. Cả hai mô hình LLaMA đều đại diện cho sự mạnh mẽ và hiệu quả của các mô hình ngôn ngữ quy mô lớn trong việc xử lý các tác vụ đa dạng và phức tạp [47, 82].

Alpaca [62]: Alpaca là một mô hình ngôn ngữ độc đáo đã được fine-tuned trên LLaMA-7B. Quá trình fine-tuning sử dụng khoảng 52k dữ liệu hướng dẫn. Điểm mạnh đặc biệt của Alpaca nằm ở khả năng theo hướng dẫn vượt trội so với mô hình gốc, LLaMA, từ đó khuếch đại hiệu suất của nó trên các tác vụ phức tạp [69].

Vicuna [83]: Vicuna là một mô hình khác được xây dựng trên LLaMA-7B. Quá trình fine-tuning của nó kết hợp 70k cuộc trò chuyện nhiều vòng được chia sẻ bởi người dùng cùng với các mẫu chuỗi dài. Giống như Alpaca, Vicuna thể hiện khả năng nâng cao trong việc tuân thủ hướng dẫn của con người so với mô hình LLaMA gốc, cung cấp cho nó lợi thế cạnh tranh để xử lý các tác vụ phức tạp [82].

LLaMA2-Chat [65]: LLaMA2-Chat là một mô hình ngôn ngữ lớn đối thoại mã nguồn mở, được fine-tuned và căn chỉnh bởi Reinforcement Learning with Human Feedback (RLHF) [50] dựa trên LLaMA2, và đạt được hiệu suất tuyệt vời trong các mô hình mã nguồn mở trên benchmark hướng dẫn của con người. Ngoại trừ việc mô hình cơ sở khác với Alpaca và Vicuna, LLaMA2-Chat cũng căn chỉnh với phản hồi của con người trên dữ liệu hữu ích và vô hại, điều này làm cho mô hình hiểu hướng dẫn của con người tốt hơn, cải thiện tính hữu ích và giảm thiểu tính có hại [5, 84].

Falcon-Instruct [4]: Falcon-Instruct tạo thành danh sách các mô hình ngôn ngữ lớn mã nguồn mở mà chúng tôi đánh giá. Tính độc đáo của Falcon xuất phát từ việc đào tạo trước trên kho ngữ liệu khác biệt, được bổ sung bởi quá trình làm sạch nghiêm ngặt. Đồng thời, Falcon cũng đã được đào tạo trên các chuỗi dài hơn, có thể được mong đợi giải quyết tốt hơn các tác vụ nội dung dài như phát hiện clone code. Falcon-Instruct được fine-tuned dựa trên Falcon đã liên tục chứng minh hiệu suất đáng chú ý trên nhiều benchmark mở [40].

MPT-Instruct [63]: MPT-Instruct là một mô hình ngôn ngữ lớn mã nguồn mở khác mà chúng tôi đánh giá. MPT như Falcon, nó đã được đào tạo trên kho ngữ liệu độc đáo và đã trải qua quá trình làm sạch nghiêm ngặt. Là một LLM mã nguồn mở, MPT-Instruct được instruct-tuned dựa trên MPT cũng đã chứng minh hiệu suất mạnh mẽ qua một số benchmark mở, tiếp tục xác nhận hiệu quả của nó [65].

StarChat-β [66]: StarChat-β là một mô hình ngôn ngữ lớn được instruction-tuned trên một biến thể "không kiểm duyệt" của tập dữ liệu openassistant-guanaco để hoạt động như một trợ lý coding hữu ích. Mô hình cơ sở của StarChat-beta là StarCoderPlus [42], là một Mô hình Ngôn ngữ 15.5B tham số được đào tạo trên tiếng Anh và hơn 80 ngôn ngữ lập trình. Do đó StarChat-β có khả năng tốt trong việc hiểu hướng dẫn của con người trong khi thực hiện nhiều tác vụ coding khác nhau.

3.4.2 Mô hình Ngôn ngữ Lớn OpenAI

Chúng tôi cũng đánh giá hiệu suất của hai LLMs OpenAI, GPT-3.5-turbo [50] và GPT-4 [49], có thể truy cập qua API của họ. Những phiên bản tiên tiến này của các mô hình ngôn ngữ dòng GPT được cung cấp bởi OpenAI đã cho thấy hiệu suất vượt trội trên một loạt rộng các tác vụ xử lý ngôn ngữ tự nhiên và ngôn ngữ lập trình [22, 46].

3.4.3 Mô hình Ngôn ngữ Đào tạo Trước cho Code Embedding

Embedding là một kỹ thuật machine learning chuyển đổi hiệu quả dữ liệu chiều cao và phức tạp, như văn bản và hình ảnh, thành các biểu diễn đơn giản hơn, chiều thấp hơn. Những biểu diễn như vậy có thể được sử dụng trực tiếp như biểu diễn đặc trưng hoặc được tinh chỉnh thêm sử dụng dữ liệu đào tạo từ các tác vụ có giám sát tiếp theo. Chúng tôi đánh giá hai mô hình được thiết kế đặc biệt cho code embeddings: CodeBERT-Base [16] và CodeBERT-MLM [16]. CodeBERT-Base được đào tạo trên hỗn hợp kho ngữ liệu ngôn ngữ tự nhiên và code, trong khi CodeBERT-MLM tận dụng objective masked language modeling, tăng cường sự phù hợp của nó cho các tác vụ đòi hỏi hiểu và phân tích code [78]. Mặt khác, chúng tôi cũng đánh giá Text-embedding-ada-002 [21], là một mô hình text embedding được tạo bởi LLM tạo ra embeddings cho ngôn ngữ tự nhiên và code, làm cho nó đặc biệt phù hợp cho các tác vụ như phát hiện clone code.

3.4.4 Triển khai

Khi giải quyết các tác vụ code bằng cách sử dụng mô hình ngôn ngữ, hầu hết các tình huống cần đảm bảo độ chính xác thay vì tính đa dạng của phản hồi mô hình, vì vậy chúng tôi cần đặt các siêu tham số khác với tác vụ ngôn ngữ tự nhiên [49]. Trong tất cả các thí nghiệm của chúng tôi, chúng tôi đặt temperature [3,17], Top-p (tức là, Nucleus Sampling [23]), và Top-k [14] của giai đoạn suy luận lần lượt là 0.2, 0.1 và 10.

3.5 Kỹ thuật Phát hiện Không dựa trên LLMs

Chúng tôi cũng chọn tám công cụ phát hiện clone code hiện đại nhất làm phương pháp baseline. SourcererCC [59] là một detector clone dựa trên token sử dụng cấu trúc dữ liệu chỉ mục nghịch đảo để truy vấn nhanh chóng các clone tỷ lệ của một khối code nhất định, phát hiện Type-1, Type-2, và Type-3 clones với độ chính xác và recall cao. CCFinder [31], được phát triển bởi Kamiya et al., là một công cụ phát hiện bốn giai đoạn dựa trên thuật toán matching suffix tree, có khả năng xác định các cặp clone và lớp clones. NiCad [57], chủ yếu được sử dụng để phát hiện malware Android, là một detector dựa trên text sử dụng source code Java để phát hiện Type-1, Type-2, và Type-3 clones. Deckard [28], một detector dựa trên tree, chuyển đổi source code thành abstract syntax tree và tính toán tương đồng clone thông qua so sánh các vector đặc trưng. CCAligner [68], một detector dựa trên token khác, làm việc với các file C và Java để phát hiện Type-1, Type-2, và Type-3 clones. Oreo [58] trình bày một cách tiếp cận mới kết hợp machine learning, information retrieval, và software metrics để phát hiện Type-1 đến Type-3 clones và những cái trong Twilight Zone. LVMapper [74] giới thiệu một cách tiếp cận phát hiện sáng tạo cho large-variance clones được mượn và thích ứng từ sequencing alignment trong tin sinh học, chứng minh recall ấn tượng cho Type-1, Type-2, và Type-3 clones tổng quát. Cuối cùng, NIL [48] đề xuất một kỹ thuật phát hiện dựa trên token có thể mở rộng có khả năng xác định các ứng cử viên clone hiệu quả sử dụng biểu diễn N-gram của các chuỗi token và một chỉ mục nghịch đảo và đặc biệt thành thạo trong việc phát hiện large-variance clones và đảm bảo khả năng mở rộng.

3.6 Metrics Đánh giá

Chúng tôi sử dụng các metrics được sử dụng rộng rãi sau để đo hiệu suất phát hiện. Precision được định nghĩa là P=TP/(TP+FP). Recall được định nghĩa là R=TP/(TP+FN). F1 được định nghĩa là F1=2∗P∗R/(P+R). Trong số đó, true positive (TP) đại diện cho số lượng mẫu được phân loại đúng là cặp clone, false positive (FP) đại diện cho số lượng mẫu được phân loại sai là cặp clone, và false negative (FN) đại diện cho số lượng mẫu được phân loại sai là cặp không clone.

3.7 Phần cứng

Các thí nghiệm được thực hiện trên một máy chủ được trang bị bộ vi xử lý AMD EPYC 7742 64-Core kép, 128 CPU, 1TB bộ nhớ, và tám GPU NVIDIA A800-SXM4-80GB.

4 Kết quả Thí nghiệm

4.1 RQ1: Hiệu suất của Prompt Đơn giản

Trong câu hỏi nghiên cứu này, chúng tôi muốn xác định liệu LLMs có thể thực hiện phát hiện clone code với một prompt đơn giản. Chúng tôi đánh giá mười LLMs và tám kỹ thuật phát hiện clone code không dựa trên LLMs trên các tập dữ liệu khác nhau, bao gồm sáu loại clone. Từ Bảng 2, chúng tôi có thể quan sát thấy rằng đối với Type-1 và Type-2 clones, các công cụ phát hiện không dựa trên LLMs có recall cao hơn các công cụ phát hiện dựa trên LLMs, trong khi các công cụ phát hiện dựa trên LLMs hoạt động tốt hơn cho Type-3 và Type-4 clones. Cụ thể, SourcererCC, NiCad, CCAligner, Oreo, và NIL cho thấy recall mạnh trong T1, T2, và VST3 clones, với NiCad và Oreo cũng cho thấy recall cao cho ST3 clones. Tuy nhiên, đối với MT3 và T4 clones, những công cụ này có recall thấp hơn đáng kể, cho thấy chúng có thể gặp khó khăn với các dạng nhân bản code phức tạp hoặc tinh tế hơn. CCFinder và Deckard cho thấy recall thấp hơn so với nhóm trước, đặc biệt với ST3, MT3, và T4 clones. LVMapper dường như là người thực hiện cân bằng qua tất cả các loại clones nhưng với điểm precision thấp hơn. Về precision, SourcererCC, NiCad, và NIL vượt trội so với các công cụ khác trong danh mục này. Điều này cho thấy các phương pháp không dựa trên LLMs thể hiện sức mạnh trong việc phát hiện T1, T2, và VST3 clones nhưng gặp khó khăn với các loại phức tạp hơn như MT3 và T4.

Đối với các công cụ phát hiện dựa trên LLMs, chúng tôi đầu tiên thấy rằng các mô hình LLaMA-7B và LLaMA2-7B, không trải qua instruct-tuning, chứng minh sự không thể theo hướng dẫn hiệu quả và xuất ra nội dung có ý nghĩa. Ngược lại, Alpaca, Vicuna, LLaMA2-Chat-7B, và Falcon-Instruct-7B đều trải qua instruction tuning, do đó cho thấy kết quả recall cao cho tất cả các loại cặp clone, mặc dù với precision thấp. Điều này cho thấy những mô hình này có thể phát hiện tất cả cặp clone là tích cực, cho thấy những thiếu sót tiềm năng trong việc phát hiện chính xác code clone. Báo cáo của LLaMA tiết lộ rằng dữ liệu code của nó trong quá trình đào tạo chiếm 4.5% toàn bộ kho ngữ liệu đào tạo, thấp nhất trong tất cả các mô hình cơ sở mã nguồn mở trong thí nghiệm. Alpaca và Vicuna-7B, được fine-tuned dựa trên LLaMA, không fine-tune mô hình của họ trên tác vụ code, có thể dẫn đến khả năng phát hiện clone kém hơn. Ngoài ra, báo cáo của LLaMA2 cho thấy tỷ lệ dữ liệu code của nó trong quá trình đào tạo đạt 8.38%. Đáng chú ý, LLaMA2-Chat-7B và Falcon-Instruct-7B đã cải thiện đáng kể recall, nhưng precision vẫn tương đối thấp, cho thấy số lượng false positive cao. Tuy nhiên, điểm recall cao của chúng cho thấy chúng không có khả năng bỏ lỡ bất kỳ clone thực tế nào, làm cho chúng trở thành công cụ có giá trị trong các tác vụ phát hiện clone mà việc bỏ lỡ một clone tiềm năng có thể có hậu quả đáng kể.

MPT-Instruct-7B cho thấy khả năng đáng chú ý trong việc phát hiện code clone với độ chính xác tương đối cao. MPT [63] nêu rằng kho ngữ liệu đào tạo của nó bao gồm 10% token code được làm sạch và xử lý đầy đủ, cho thấy năng lực của nó trong việc xử lý các tác vụ phát hiện clone. MPT-Instruct-7B, được instruct-tuned dựa trên MPT, ngụ ý khả năng theo hướng dẫn của con người để phát hiện code clones. Recall của StarChat-β tương đối cao so với các mô hình trên với precision được đảm bảo. Mô hình cơ sở của nó, StarCoderPlus, được đào tạo trên hơn 80 ngôn ngữ code, và nó được fine-tuned trên biến thể "không kiểm duyệt" của tập dữ liệu openassistant-guanaco, được xây dựng đặc biệt cho tác vụ code, điều này có thể giải thích hiệu suất tốt hơn của nó trong phát hiện clone code. GPT-3.5-Turbo và GPT-4 cho thấy kết quả tốt nhất trong thí nghiệm. Điều này là do hai mô hình này có tham số lớn hơn nhiều so với các mô hình khác (GPT-3.5-Turbo chứa 175B tham số; falcon chứa 7b tham số; StarChat-β chứa 16b tham số), vì vậy chúng có thể chứa nhiều kiến thức hơn [32]. Các mô hình GPT cũng có danh sách từ phong phú hơn [49], cho phép xử lý tinh tế, đầy đủ các tác vụ code. Hơn nữa, các mô hình GPT có thể xử lý các mẫu dài hơn mà không quên hướng dẫn mở đầu. Ngược lại, các mô hình mã nguồn mở khác quên hướng dẫn trong nhiều trường hợp và trả lời sai hoặc thậm chí không theo hướng dẫn trong hầu hết các trường hợp.

Thú vị là, chúng tôi thấy GPT-3.5-Turbo và GPT-4 không có cùng hiểu biết về cloning. GPT-3.5-Turbo tập trung vào ngữ nghĩa của code. Ngược lại, GPT-4 kết hợp cấu trúc code và ngữ nghĩa vào xem xét. Ví dụ, một cặp Type-2 clone mã hóa và giải mã file chỉ khác tên hàm (tức là, encodeFiletoFile, decodeFiletoFile) và cách mã hóa (tức là, Base64.ENCODE, Base64.DECODE). GPT-3.5-Turbo coi code không phải là clone vì việc thực hiện các hàm loại trừ lẫn nhau, trong khi GPT-4 coi code là clone vì cấu trúc và chức năng của các đoạn code rất tương tự, ngoại trừ một cái thực hiện mã hóa và cái kia giải mã. Do hiểu biết không chính xác về cloning, recall Type-2 của GPT-3.5-Turbo thấp vì cặp code Type-2 tương tự về cấu trúc, dẫn đến mô hình xuất ra kết quả sai.

Tóm tắt: Sử dụng LLMs mã nguồn mở cho phát hiện clone mang lại kết quả vượt trội trong việc xác định các cặp clone Type-3 và Type-4 khi chỉ dựa vào prompt đơn giản. Tuy nhiên, nó thể hiện hiệu suất hơi kém hơn khi phát hiện các cặp clone Type-1 và Type-2 so với các công cụ hiện tại. Đáng chú ý, GPT-3.5-Turbo và GPT-4 nổi bật với tỷ lệ recall và độ chính xác cao nhất qua gần như tất cả các loại clone.

4.2 RQ2: Hiệu suất của Prompt Chain-of-Thought Một bước

Trong phần này, chúng tôi thiết kế các prompt sử dụng chain-of-thought một bước để yêu cầu LLMs thực hiện phát hiện clone code từ năm góc độ. Lưu ý rằng các LLMs mã nguồn mở không theo prompt tốt. Như được hiển thị trong Bảng 3, chúng tôi có thể quan sát thấy rằng chúng tôi yêu cầu LLM mã nguồn mở mới nhất, LLaMA2-Chat-7B [65], cung cấp các dòng tương tự trong cặp code và thực hiện phát hiện clone code. Tuy nhiên, với cặp code hoàn toàn khác biệt về cấu trúc cũng như ngữ nghĩa, LLaMA2-Chat-7B xác định cặp code là cặp clone bằng cách đơn giản phân tích độ phức tạp của code. Đối với các cặp code dài hơn, các mô hình mã nguồn mở thậm chí còn bị hạn chế hơn bởi các ràng buộc token đầu vào và khả năng mô hình hóa văn bản dài kém, và thường hơn không thì câu trả lời chứa phân tích vô nghĩa và kết quả sai. So với các LLMs mã nguồn mở, GPT-3.5-Turbo và GPT-4 hiểu hướng dẫn chính xác hơn, có thể thực hiện các tác vụ trong prompt tốt hơn, và có thể đưa ra phản hồi có ý nghĩa cho nhiều prompt chúng tôi thiết kế, có thể phản ánh thực tế hơn tác động của việc phân tích mô hình lớn từ các góc độ khác nhau về phát hiện clone code. Do đó, chúng tôi chỉ đánh giá GPT-3.5-Turbo và GPT-4 trong các thí nghiệm sau.

4.2.1 Loại Clone

Chúng tôi yêu cầu các mô hình phân tích loại clone của hai đoạn code và xuất ra đánh giá clone code. Đáng chú ý là chúng tôi không thông báo cho các mô hình thông qua prompt các loại clone code là gì. Các mô hình, bao gồm GPT-3.5-Turbo và GPT-4, có kiến thức trước về điều này và có thể biết đúng bốn loại clone trong tác vụ phát hiện clone. Từ Bảng 4, chúng tôi có thể quan sát thấy recall của MT3 và Type-4 đạt 0.87 và 0.36 tương ứng. So với RQ1, cải thiện trong Type-2 là rất lớn (tức là, từ 0.57 đến 0.98) vì các loại clone được đề cập trong prompt giúp các mô hình xác định từ góc độ toàn diện hơn. GPT-3.5-Turbo thực hiện phát hiện clone chủ yếu bằng cách phân tích ngữ nghĩa và bỏ qua phân tích cấu trúc code. Khi GPT-3.5-Turbo được yêu cầu phân tích loại clone trước trong prompt, mô hình sẽ xem xét nhiều clone cấu trúc hơn (Type-2 là clone cấu trúc). Do đó hiệu suất phát hiện clone của GPT-3.5-Turbo sẽ được cải thiện rất nhiều. Đối với GPT-4, recall của MT3 và Type-4 đạt 0.92 và 0.25 tương ứng. Những kết quả này cho thấy việc để các mô hình phân tích loại clone trước cải thiện phát hiện clone tổng thể của nó.

4.2.2 Tương đồng

Chúng tôi yêu cầu các mô hình xuất ra tương đồng của hai đoạn code thay vì xuất ra đánh giá. Bằng cách mô phỏng việc chấm điểm của con người, chúng tôi muốn đánh giá mô hình hiểu code clone tốt như thế nào. Chúng tôi đánh giá mô hình cho phát hiện clone code bằng cách đặt các ngưỡng khác nhau cho tương đồng. Như được hiển thị trong Hình 1, chúng tôi thấy rằng giá trị F1 cao nhất cho GPT-4 được thu được khi ngưỡng tương đồng được đặt ở sáu (tức là, precision là 0.93 và recall là 0.86). Và khi ngưỡng tương đồng cho GPT-3.5-Turbo được đặt ở ba, mô hình có giá trị F1 cao nhất (tức là, precision là 0.86, và recall là 0.85). Đồng thời, giá trị F1 cao nhất của GPT-4 tốt hơn GPT-3.5-Turbo.

4.2.3 Lý luận

Chúng tôi yêu cầu các mô hình xuất ra lý luận của phát hiện clone và, dựa trên lý luận, xuất ra đánh giá cuối cùng. Quá trình lý luận chứa cách mô hình hiểu code cũng như tác vụ phát hiện clone. Thông tin được tạo ra sẽ được cung cấp cho các mô hình như thông tin bổ sung để hỗ trợ các mô hình đưa ra đánh giá và cải thiện độ chính xác của phát hiện clone. Như được hiển thị trong Bảng 5, chúng tôi thấy rằng đối với GPT-3.5-Turbo, recall của Type-2 đạt 0.91. Đối với GPT-4, recall của MT3 và Type-4 đạt 0.91 và 0.26 tương ứng.

4.2.4 Dòng Tương tự

Chúng tôi yêu cầu các mô hình xuất ra các dòng tương tự trong các đoạn code và, với các dòng tương tự, xuất ra xác định cuối cùng. Với yêu cầu này, các mô hình đầu tiên được phân tích về việc tìm các dòng tương tự. Góc độ này khác với phát hiện clone trực tiếp ở chỗ nó yêu cầu các mô hình không cần phân tích từ toàn bộ ngữ nghĩa mà thay vào đó có thể phân tích chống lại các đoạn code cục bộ. Khi mô hình xuất ra các dòng tương tự, các lý do đưa ra có thể được sử dụng như thông tin bổ sung để cải thiện độ chính xác của code cho phát hiện clone. Như được hiển thị trong Bảng 6, chúng tôi thấy rằng đối với GPT-3.5-Turbo, recall của Type-2 và MT3 đạt 0.99 và 0.86 tương ứng, là một sự thúc đẩy lớn so với RQ1. Đối với GPT-4, recall của MT3 và Type-4 đạt 0.88 và 0.26 tương ứng.

4.2.5 Tích hợp

Trong phần này, chúng tôi muốn hiểu hiệu suất của mô hình lớn khi được cung cấp thông tin đa góc độ cho phát hiện clone. Kết hợp các góc độ từ các prompt trước có thể cung cấp cho mô hình nhiều thông tin hơn, hoặc nó có thể can thiệp với các mô hình vì thông tin khác nhau có thể đặc trưng cho các kết quả cloning khác nhau, đặc biệt khi có quá nhiều thông tin. Như được hiển thị trong Bảng 7, chúng tôi thấy rằng đối với GPT-3.5-Turbo, recall của Type-2 đạt 0.95. Tuy nhiên, so với các prompt trước, các kết quả recall khác có sự giảm lớn, và recall của MT3 và Type-4 thậm chí thấp hơn kết quả gốc trong RQ1. Đối với GPT-4, recall của MT3 và Type-4 đạt 0.91 và 0.32 tương ứng. Điều này cho thấy GPT4 vượt trội so với GPT-3.5-Turbo về hiểu và phân tích đầu vào với các góc độ thông tin phức tạp và văn bản dài.

Tóm tắt: Hiệu suất phát hiện clone của GPT-3.5-Turbo và GPT-4 có thể được cải thiện bằng cách yêu cầu các mô hình cung cấp loại clone, tương đồng, lý luận, và dòng tương đồng. Sử dụng prompt chain-of-thought một bước cho phép các mô hình phân tích các cặp code và lý luận trung gian, dẫn đến phát hiện clone tốt hơn.

4.3 RQ3: Hiệu suất của Prompt Chain-of-Thought Nhiều bước

4.3.1 Giải thích Riêng biệt

Trong phần này, chúng tôi nhằm đánh giá tác động của bốn loại lý luận trung gian độc lập (RQ2) đối với phát hiện clone. Chúng tôi yêu cầu các mô hình giải thích code từ mỗi trong bốn góc độ trong RQ2 một cách độc lập và tạo ra lý luận trung gian tương ứng. Các prompt trong phần này khác với những cái trong RQ2 ở chỗ những cái sau tạo ra lý luận trung gian, có thể dựa trên lý luận khác. Tuy nhiên, trong phần này, quá trình tạo ra độc lập với nhau, và mỗi khi các mô hình được hỏi một câu hỏi, chúng được hỏi trong một bối cảnh mới. Sau đó, chúng tôi kết hợp bốn loại lý luận trung gian thành một prompt và giao nhiệm vụ cho các mô hình thực hiện phát hiện clone. Bảng 8 trình bày rằng đối với GPT-3.5-Turbo, recall của MT3 và Type-4 đạt 0.92 và 0.39 tương ứng. So với RQ2-5, recall của MT3 và Type-4 tăng 0.34 và 0.32 tương ứng. Những phát hiện này cho thấy GPT-3.5-Turbo không thể phân tích hiệu quả nhiều lý luận trung gian tương tác, điều này cản trở khả năng xác định phát hiện clone chính xác của nó. Đối với GPT-4, so với RQ2-5, recall và precision không thay đổi nhiều, cho thấy GPT-4 thể hiện khả năng vượt trội trong việc hiểu và sử dụng bốn lý luận trung gian để thúc đẩy phát hiện clone.

4.3.2 Code Riêng biệt

Trong phần này, chúng tôi nhằm sao chép các kỹ thuật phát hiện clone dựa trên deep learning hiện tại đặc trưng cho các đặc trưng code độc lập để dự đoán kết quả. Do đó, chúng tôi đầu tiên yêu cầu GPT-3.5-Turbo và GPT4 tạo ra các giải thích code độc lập để đặc trưng cho code và sau đó nhập những giải thích này vào các mô hình cho phát hiện clone. Để đảm bảo các giải thích độc lập và không thiên vị, chúng tôi đầu tiên chia các cặp code và yêu cầu các mô hình giải thích mỗi code riêng biệt. Điều này ngăn chặn bất kỳ ảnh hưởng nào trong quá trình tạo ra các giải thích code. Sau đó, chúng tôi kết hợp các code và giải thích của chúng thành một prompt và yêu cầu các mô hình thực hiện phát hiện clone code. Bằng cách phân tích riêng biệt hai đoạn code, chúng tôi ngăn chặn bất kỳ can thiệp nào và nhằm đánh giá hiệu suất của phát hiện clone khi mô hình cũng được cung cấp các giải thích code độc lập. Từ Bảng 9, chúng tôi thấy rằng đối với GPT-3.5-Turbo, precision đạt 0.9, và recall của MT3 và Type-4 đạt 0.76 và 0.19 tương ứng. Đối với GPT-4, precision đạt 0.96, và recall của MT3 và Type-4 đạt 0.83 và 0.29. Điều này cho thấy so với RQ1, lý luận chain-of-thought nhiều bước bằng cách tách code có thể cải thiện hiệu suất của phát hiện clone cho GPT-3.5-Turbo và GPT-4.

Tóm tắt: Hiệu suất phát hiện clone của GPT-3.5-Turbo và GPT-4 có thể được cải thiện bằng Prompt Chain-of-Thought Nhiều bước, bao gồm tách giải thích và code. Khác với RQ2, tách giải thích cung cấp các mô hình lý luận trung gian độc lập của code, và tách code cung cấp các mô hình giải thích độc lập của code, tránh các ảnh hưởng giữa thông tin được tạo ra.

4.4 RQ4: Hiệu suất của Code Embedding

Phần này cung cấp phân tích so sánh hiệu suất của các LLMs khác nhau, tập trung cụ thể vào việc sử dụng code embedding của chúng. Điều này được thực hiện bằng cách đối chiếu kết quả của họ với các PLMs đã được thiết lập, bao gồm CodeBERT-base, CodeBERT-mlm, và text-embedding-ada-002. Trong nghiên cứu của chúng tôi, hiệu suất của ba mô hình, cụ thể là CodeBERT, CodeBERT-MLM, và Text-embedding-ada-002, được đánh giá dựa trên khả năng xác định các cặp code clone trong tập dữ liệu BigCloneBench. Các mô hình được đào tạo để dự đoán tương đồng giữa các cặp code, được tính toán như tương đồng cosine giữa các biểu diễn vector của các cặp code.

Để nắm bắt các sắc thái của hiệu suất mô hình, chúng tôi thay đổi các ngưỡng xác suất và đo precision, recall, và điểm F1 ở mỗi cấp độ. Mỗi mô hình được phân tích ở ngưỡng tương ứng của nó tương ứng với hiệu suất tối ưu của nó. Điểm F1 so sánh qua các ngưỡng khác nhau được biểu diễn đồ họa trong Hình 2. Hiệu suất tối ưu của các mô hình được quan sát ở các cấp độ ngưỡng khác nhau: 0.995 cho cả CodeBERT-base và CodeBERT-MLM, và 0.8 cho Text-embedding-ada-002. Những ngưỡng này được xác định dựa trên hiệu suất đỉnh của mỗi mô hình dưới đánh giá. Trong khi tất cả các mô hình chứng minh hiệu suất mạnh trong một số danh mục, chúng thể hiện hiệu quả giảm trong các tình huống WT3/T4 và NoClone. Thú vị, CodeBERT-MLM vượt qua CodeBERT-base ở hiệu suất đỉnh, cho thấy kết quả vượt trội trong các tình huống MT3, ST3, và VST3. Tuy nhiên, Text-embedding-ada-002 vượt trội so với cả hai biến thể CodeBERT, thể hiện precision và điểm F1 cao nhất, từ đó chứng minh hiệu suất mạnh mẽ ngay cả ở ngưỡng thấp hơn.

Cụ thể, Text-embedding-ada-002 đạt được điểm F1 tổng thể cao nhất. Như được minh họa trong Hình 3, mô hình này thể hiện phạm vi rộng hơn của điểm tương đồng, cho phép phân biệt hiệu quả hơn giữa true và false positive. Tuy nhiên, phân phối rộng hơn này cũng dẫn đến một vài dự đoán sai ở điểm tương đồng cao hơn. Mặc dù những dự đoán sai tương đồng cao thỉnh thoảng này, các phát hiện mạnh mẽ cho thấy Text-embedding-ada-002 cung cấp hiệu suất mạnh mẽ nhất trong phát hiện các cặp code clone. Phạm vi phân phối rộng hơn của điểm tương đồng của nó tiếp tục chứng thực độ tin cậy và hiệu quả của nó trong việc phân biệt giữa các cặp code clone và không clone, từ đó thể hiện sự mạnh mẽ của mô hình.

Tóm tắt: Text-embedding-ada-002 hiệu quả hơn các mô hình CodeBERT chuyên biệt trong việc xác định code clone, thể hiện hiệu suất tổng thể vượt trội. Lợi thế của Text-embedding-ada-002 nằm ở khả năng tạo ra phạm vi rộng hơn của điểm tương đồng, dẫn đến phân biệt tốt hơn giữa true và false positive.

4.5 RQ5: Hiệu suất qua Các Ngôn ngữ Lập trình Khác nhau

Trong phần này, chúng tôi phân tích hiệu suất của LLMs trong việc phát hiện code clones qua các ngôn ngữ lập trình khác nhau. Đánh giá những mô hình này tiết lộ một mô hình trong đó chúng hiển thị precision đáng chú ý, như được chứng minh bởi dữ liệu được trình bày trong Bảng 10. Tỷ lệ recall vượt trội của GPT-4 qua tất cả các loại clone và ngôn ngữ, đặc biệt là Python và C++, cho thấy rằng khả năng phát hiện clone code cải thiện của GPT-4 có thể được quy cho sự hiểu biết tiên tiến về các cú pháp và cấu trúc khác nhau qua những ngôn ngữ lập trình này.

Những khác biệt này qua Python, C++, và Java cũng có thể được quy cho độ phức tạp vốn có của cú pháp và cấu trúc của mỗi ngôn ngữ. Tính đơn giản và trừu tượng cấp cao của Python có thể làm cho phát hiện clone tương đối đơn giản hơn, được phản ánh trong hiệu suất ấn tượng của cả hai mô hình. Các giá trị recall cao cho Python cũng có thể bị ảnh hưởng bởi lượng code Python có sẵn trong giai đoạn đào tạo của các mô hình, vì Python là một trong những ngôn ngữ được sử dụng phổ biến nhất trong phát triển phần mềm và nghiên cứu AI. Ngoài ra, có thể là các tập dữ liệu được sử dụng để đánh giá phát hiện clone Python và C++ có thể chồng chéo với dữ liệu đào tạo của LLMs, dẫn đến hiệu suất tốt hơn có vẻ.

Tóm tắt: Hiệu suất của LLMs trong phát hiện clone code khác nhau qua các ngôn ngữ lập trình khác nhau, với xu hướng kết quả vượt trội trong Python, có thể do tính đơn giản vốn có và sự phổ biến của nó trong dữ liệu đào tạo.

5 Thảo luận và Hạn chế

5.1 Thảo luận

5.1.1 Việc sử dụng CoT có cải thiện khả năng phát hiện clone code của LLMs một cách phổ quát không?
Việc sử dụng CoT đã được biết đến để tăng cường hiệu suất trên các tác vụ phức tạp như lý luận toán học. Tuy nhiên, nghiên cứu của chúng tôi cho thấy việc triển khai CoT không nhất thiết dẫn đến cải thiện tổng thể trong khả năng phát hiện clone code của LLMs. Có hai lý do chính cho trường hợp này. Đầu tiên, sự cần thiết cho LLMs có khả năng mạnh mẽ để theo hướng dẫn của con người. Các mô hình không có instruction tuning có thể thất bại trong việc cải thiện hiệu suất thông qua CoT vì chúng thiếu khả năng theo hướng dẫn của con người hiệu quả. Thứ hai, với độ phức tạp của các tác vụ phát hiện clone code, đặc biệt do yêu cầu khớp hai tập code, LLMs cần khả năng mạnh mẽ trong lý luận tài liệu dài và hiểu bối cảnh. Nếu những khả năng này thiếu trong LLMs, chúng có thể thất bại trong việc hiểu hướng dẫn của con người và thậm chí hoạt động kém hơn mà không có việc triển khai CoT. Do đó, trong khi CoT có thể tăng cường khả năng phát hiện clone code của các LLMs có khả năng hơn, nó có thể ảnh hưởng có hại đến hiệu suất của các mô hình yếu hơn.

5.1.2 Tại sao CoT tăng cường hiệu suất của LLMs mạnh hơn trong phát hiện clone?
CoT tăng cường hiệu suất của LLMs mạnh hơn trong phát hiện clone bằng cách mở rộng bối cảnh của quá trình dự đoán của mô hình. Trong tình huống bình thường không có CoT, mô hình phản hồi chỉ dựa trên hai mẫu code được cung cấp. Tuy nhiên, khi CoT được triển khai, bối cảnh để dự đoán các token phản hồi bao gồm không chỉ hai mẫu code mà còn quá trình suy nghĩ của chính mô hình. Điều này cung cấp phân tích toàn diện hơn về cặp code và sau đó tăng cường hiệu suất phát hiện clone code của mô hình.

5.1.3 Tại sao code embedding hoạt động tốt hơn LLMs chat trong các tác vụ phát hiện clone?
Sự thành công của code embedding so với LLMs chat được quy cho cách tiếp cận khác nhau của nó để phát hiện code clone. Code embedding tạo ra một biểu diễn cá nhân cho mỗi code thông qua text encoder, sau đó được so sánh sử dụng tương đồng cosine. Quá trình này không bao gồm phân tích so sánh của hai code, từ đó đơn giản hóa tác vụ so với việc thực hiện trực tiếp phát hiện clone trên hai code. Mặc dù LLMs với CoT có thể cung cấp phân tích cho mỗi code và sau đó so sánh kết quả, đầu ra dưới dạng văn bản ngôn ngữ tự nhiên làm cho quá trình này phức tạp hơn so với mã hóa trực tiếp để có được biểu diễn. Ngoài ra, giai đoạn so sánh cuối cùng vẫn đòi hỏi khả năng hiểu bối cảnh mạnh mẽ từ LLMs để so sánh các đoạn code dài hơn. Kết quả là, tác vụ code embedding xuất hiện đơn giản hơn cả về phân tích code và so sánh cặp code, từ đó dẫn đến hiệu suất tốt hơn.

5.1.4 Mã nguồn mở và chi phí.
Để đóng góp cho cộng đồng học thuật và thúc đẩy những tiến bộ tiếp theo trong nghiên cứu phát hiện clone code, chúng tôi sẽ công khai kết quả suy luận của GPT-3.5-Turbo và GPT-4 trên Java, C++, và Python. Ngoài ra, chúng tôi sẽ phát hành một tập dữ liệu được tuyển chọn tỉ mỉ gồm hơn 200.000 cặp clone cho Python và C++, mỗi cái được phân loại thành các loại clone: VST3 clones, ST3 clones, MT3 clones, và WT3/T4) clones. Chúng tôi tin rằng những tài nguyên này sẽ tạo điều kiện đáng kể cho khám phá và phát triển tương lai trong lĩnh vực này. Tất cả dữ liệu có sẵn tại liên kết. Hơn nữa, trong nghiên cứu này, chúng tôi đã chi hơn $3500 cho các truy vấn APIs OpenAI của GPT-3.5-Turbo và GPT-4. Toàn bộ các thí nghiệm bao gồm tiêu thụ thiết kế prompt, thí nghiệm chain-of-thought, và thí nghiệm đa ngôn ngữ, sử dụng tổng cộng 6.942.335 token.

5.2 Hạn chế

5.2.1 Hạn chế trong việc xây dựng tập hướng dẫn.
Mặc dù chúng tôi đã xây dựng một tập hướng dẫn dựa trên kích thước mẫu nhỏ, những cái này có thể không nhất thiết tối ưu cho các tác vụ phát hiện clone code. Việc xác định các hướng dẫn hiệu quả nhất sẽ yêu cầu các thử nghiệm rộng rãi, có thể cấm đoán do ràng buộc tài nguyên. Chúng tôi nhằm giải quyết hạn chế này trong công việc tương lai bằng cách khám phá một tập hướng dẫn rộng hơn cho tác vụ này.

5.2.2 Lựa chọn mô hình để đánh giá.
Lĩnh vực LLMs luôn phát triển với việc giới thiệu thường xuyên các mô hình mới. Trong nghiên cứu hiện tại, lựa chọn mô hình của chúng tôi bị giới hạn trong một tập con của những cái này, được chọn dựa trên các yếu tố như tính mới, sử dụng phổ biến, và hiệu suất đã được thiết lập trong các tác vụ ngôn ngữ thần kinh. Ngoài ra, do hạn chế tài nguyên tính toán, chúng tôi bị hạn chế trong việc test các mô hình ở quy mô tham số 7B và 16B, mặc dù ấn tượng trong bối cảnh kỹ thuật phần mềm, vẫn để lại chỗ cho khám phá. Trong các nghiên cứu tương lai, chúng tôi có ý định mở rộng đánh giá của mình để bao gồm phạm vi rộng hơn của các mô hình và quy mô lớn hơn để cung cấp sự hiểu biết toàn diện hơn về khả năng của LLMs trong kỹ thuật phần mềm.

5.2.3 Vắng mặt của demonstrations trong in-context learning.
Nghiên cứu hiện tại của chúng tôi không tận dụng demonstrations, tức là việc sử dụng các ví dụ few-shot, được biết đến để tăng cường hiệu suất của LLMs. Sự thiếu sót này chủ yếu do ràng buộc tài nguyên, vì việc bao gồm demonstrations có thể tăng đáng kể nhu cầu về tài nguyên tính toán. Ngoài ra, các mô hình được test trong nghiên cứu này ở đầu nhỏ hơn của quy mô, vốn dĩ hạn chế khả năng bộ nhớ bối cảnh của chúng. Công việc tương lai sẽ xem xét việc kết hợp demonstrations và test các LLMs mã nguồn mở lớn hơn, được mong đợi có khả năng bộ nhớ bối cảnh mạnh mẽ hơn, từ đó có thể cải thiện hiệu quả của phát hiện clone code.

5.2.4 Thực thi cấu trúc phản hồi trong quá trình phát hiện.
Trong tác vụ phát hiện của chúng tôi, chúng tôi yêu cầu phản hồi của mô hình chứa hoặc 'có' hoặc 'không'. Tuy nhiên, một số mô hình có thể không tuân thủ hướng dẫn này, dẫn đến sự không nhất quán tiềm năng trong đánh giá. Cho đánh giá này, chúng tôi kết hợp việc sử dụng biểu thức chính quy với kiểm tra thủ công để xác định tính đúng đắn của phản hồi mô hình. Trong các nghiên cứu tương lai, chúng tôi kế hoạch khám phá các phương pháp đánh giá hiệu quả hơn hoặc tối ưu hóa prompt để giảm sự phụ thuộc vào kiểm tra thủ công và đánh giá chính xác phản hồi mô hình.

6 Kết luận

Nghiên cứu này trình bày đánh giá thực nghiệm toàn diện về Mô hình Ngôn ngữ Lớn (LLMs) cho phát hiện clone code tự động qua các loại clone đa dạng, ngôn ngữ, và công thức prompt. Những phát hiện chính chứng minh rằng các LLMs tiên tiến như GPT-3.5-Turbo và GPT-4 có thể đạt được recall và độ chính xác đáng chú ý cao trong việc phát hiện ngay cả các clone ngữ nghĩa phức tạp, vượt trội so với các kỹ thuật hiện tại. Việc giới thiệu các bước lý luận trung gian thông qua chain-of-thought prompting dẫn đến những cải thiện đáng chú ý bằng cách trang bị các mô hình với quá trình suy nghĩ có cấu trúc. Ngoài ra, việc biểu diễn code dưới dạng vector embeddings cho phép phát hiện clone hiệu quả, với text encoders như Text-embedding-ada-002 tạo ra kết quả vượt trội so với các mô hình chuyên biệt. Nghiên cứu của chúng tôi cung cấp bằng chứng mạnh mẽ rằng LLMs có triển vọng đáng kể cho phát hiện clone bằng cách tận dụng khả năng ngôn ngữ tự nhiên của chúng. Những thông tin chi tiết thu được sẽ hướng dẫn nghiên cứu tương lai hướng tới việc phát triển các kỹ thuật dựa trên LLM mạnh mẽ hơn để nâng cao kỹ thuật phần mềm. Các prompt và phương pháp đánh giá được trình bày cũng đóng góp một benchmark hữu ích cho các nghiên cứu tiếp theo trong lĩnh vực mới nổi này.

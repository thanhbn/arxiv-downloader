HIỂU HTML VỚI CÁC MÔ HÌNH NGÔN NGỮ LỚN

Izzeddin Gur, Oﬁr Nachum, Yingjie Miao, Mustafa Safdari, Austin Huang
Aakanksha Chowdhery, Sharan Narang, Noah Fiedel, Aleksandra Faust
Google Research

TÓM TẮT

Các mô hình ngôn ngữ lớn (LLM) đã thể hiện hiệu suất đặc biệt trên nhiều tác vụ ngôn ngữ tự nhiên. Tuy nhiên, khả năng hiểu HTML của chúng - tức là phân tích HTML thô của một trang web, với các ứng dụng tự động hóa các tác vụ dựa trên web, thu thập dữ liệu và truy xuất hỗ trợ trình duyệt - vẫn chưa được khám phá đầy đủ. Chúng tôi đóng góp các mô hình hiểu HTML (LLM được tinh chỉnh) và phân tích sâu về khả năng của chúng dưới ba tác vụ: (i) Phân loại ngữ nghĩa các phần tử HTML, (ii) Tạo mô tả cho đầu vào HTML, và (iii) Điều hướng web tự động trên các trang HTML. Trong khi nghiên cứu trước đây đã phát triển các kiến trúc chuyên dụng và quy trình huấn luyện cho việc hiểu HTML, chúng tôi cho thấy rằng các LLM được tiền huấn luyện trên kho ngữ liệu ngôn ngữ tự nhiên tiêu chuẩn có thể chuyển giao một cách đáng kể đến các tác vụ hiểu HTML. Ví dụ, các LLM được tinh chỉnh chính xác hơn 12% trong phân loại ngữ nghĩa so với các mô hình được huấn luyện độc quyền trên bộ dữ liệu tác vụ. Hơn nữa, khi được tinh chỉnh trên dữ liệu từ benchmark MiniWoB, các LLM hoàn thành thành công 50% nhiều tác vụ hơn sử dụng ít dữ liệu gấp 192 lần so với mô hình học có giám sát tốt nhất trước đó. Trong số các LLM chúng tôi đánh giá, chúng tôi cho thấy bằng chứng rằng các mô hình dựa trên T5 là lý tưởng do kiến trúc encoder-decoder hai chiều của chúng. Để thúc đẩy nghiên cứu thêm về LLM cho việc hiểu HTML, chúng tôi tạo và mở mã nguồn một bộ dữ liệu HTML quy mô lớn được chưng cất và gán nhãn tự động từ CommonCrawl.

1 GIỚI THIỆU

Thu thập dữ liệu web (Olston et al., 2010), điền biểu mẫu (Diaz et al., 2013; Gur et al., 2021), hoặc các tác nhân web truy xuất thông tin (Nogueira & Cho, 2016) là quan trọng cho cả việc tự động hóa và hỗ trợ người dùng trong các tác vụ dựa trên web. Những ứng dụng này và các ứng dụng tương tự dựa vào các mô hình có thể tìm kiếm nội dung hoặc điều khiển cụ thể trên một trang web cũng như điều hướng một trang web một cách tự động. Vì một trang web ở dạng thô được biểu diễn như một chuỗi văn bản dựa trên HTML, thành công của các mô hình cho các tác vụ dựa trên web phụ thuộc vào khả năng hiểu ngữ nghĩa, cấu trúc và tương tác nhúng của HTML.

Cách tiếp cận chủ đạo đối với tự động hóa web và hiểu HTML là huấn luyện các mô hình chuyên biệt, tức là thu thập các bộ dữ liệu dành riêng cho ứng dụng và thiết kế các kiến trúc mạng neural (NN) để tận dụng các thiên hướng quy nạp của cấu trúc HTML; xem, ví dụ, Liu et al. (2018); Toyama et al. (2021); Gur et al. (2021); Humphreys et al. (2022). Tuy nhiên, cả việc thu thập dữ liệu và thiết kế kiến trúc neural đều tốn kém, mất thời gian và đòi hỏi kiến thức chuyên môn cao, cụ thể theo lĩnh vực.

Trong khi đó, trong tài liệu xử lý ngôn ngữ tự nhiên (NLP), các mô hình ngôn ngữ lớn (LLM) đã nổi lên như một giải pháp cho những khó khăn của việc thu thập dữ liệu và thiết kế NN chuyên biệt (Kaplan et al., 2020; Bommasani et al., 2021). Một mô hình phổ biến trong NLP là lấy một LLM có sẵn - được tiền huấn luyện trên một kho ngữ liệu văn bản lớn thông qua một mục tiêu học tập không giám sát và không phụ thuộc tác vụ - và tinh chỉnh hoặc hướng dẫn LLM trên một bộ dữ liệu nhỏ cụ thể theo tác vụ. Mô hình này đã cho thấy hiệu suất đặc biệt trên nhiều tác vụ NLP (Xue et al., 2020; Brown et al., 2020; Austin et al., 2021). Liệu các LLM có thể được áp dụng cho việc hiểu HTML - đặc biệt là với bối cảnh và độ dài chuỗi lớn hơn nhiều - vẫn là một câu hỏi chưa được khám phá đầy đủ.

Trong bài báo này, chúng tôi điều tra liệu các LLM có thể được áp dụng cho việc hiểu HTML để tạo ra các mô hình hiểu HTML có hiệu suất tốt hơn, hiệu quả mẫu hơn và không cần thiết kế kiến trúc NN tùy chỉnh. Vì mục đích đó, chúng tôi trình bày một bộ ba tác vụ đánh giá cho việc hiểu HTML nắm bắt được bản chất của những ứng dụng này và đòi hỏi hiểu cả cấu trúc và nội dung. Đầu tiên, chúng tôi thiết kế Phân loại ngữ nghĩa như một tác vụ đòi hỏi một mô hình phân loại một phần tử HTML đã cho thành một trong các danh mục, chẳng hạn như địa chỉ, email, mật khẩu, v.v., với ứng dụng cho việc điền biểu mẫu tự động. Thứ hai, chúng tôi trình bày Tạo mô tả, một tác vụ trích xuất nhãn trong đó một mô hình được đưa một đoạn HTML và được yêu cầu tạo ra một mô tả ngôn ngữ tự nhiên. Ví dụ, đối với một trường email, mô tả có thể là "Vui lòng nhập địa chỉ email của bạn." Lưu ý rằng trong phần lớn các trang web, kết nối giữa các phần tử đầu vào và nội dung mô tả chỉ là ngầm hiểu trong mã HTML thô và suy luận những liên kết như vậy là điều kiện tiên quyết cho các mục tiêu điều hướng cấp cao hơn. Tác vụ thứ ba là Điều hướng web tự động (Shi et al., 2017). Một mô hình được trình bày với một trang HTML được ghép nối với một lệnh ngôn ngữ tự nhiên và phải áp dụng các hành động thích hợp trên một chuỗi các trang HTML để thỏa mãn lệnh đó. Xem Hình 1a cho một ví dụ đơn giản hóa của những tác vụ này.

Với những tác vụ đánh giá này trong tay, chúng tôi đánh giá khả năng chuyển giao của nhiều LLM được tiền huấn luyện (Bảng 1), khác nhau về kiến trúc (chỉ encoder, encoder-decoder, hoặc chỉ decoder), kích thước mô hình (từ 24,6M đến 62B tham số), và kho ngữ liệu dữ liệu huấn luyện (cả bao gồm và loại trừ kho ngữ liệu NLP và HTML tiền huấn luyện). Trong khi công trình trước đây đã phát triển các kiến trúc chuyên dụng và quy trình huấn luyện cho việc hiểu HTML, của chúng tôi - theo hiểu biết tốt nhất của chúng tôi - là công trình đầu tiên sử dụng HTML thô, chưa được xử lý. Kết quả của chúng tôi cho thấy rằng các LLM thể hiện một mức độ hiểu HTML đáng kể trên tất cả các tác vụ, với hiệu quả mẫu cao hơn đến 192 lần so với các mô hình được huấn luyện từ đầu, và đạt được SoTA mới cho học có giám sát trên bộ benchmark MiniWoB (Shi et al., 2017). Các kiến trúc encoder-decoder với attention hai chiều cho thấy hiệu suất tốt nhất trên toàn bộ bảng ngay cả khi việc tiền huấn luyện của chúng không bao gồm HTML. Ngoài ra, chúng tôi cho thấy rằng hiệu suất tăng theo quy mô dưới tuyến tính với kích thước mô hình.

Mục tiêu rộng lớn hơn của nghiên cứu này là thúc đẩy việc tích hợp các LLM với các tác nhân web tự động. Chỉ trong năm qua, các nhà nghiên cứu mới bắt đầu sử dụng các LLM bên ngoài NLP và tích hợp chúng như các khả năng cốt lõi trong tự động hóa (Lu et al. (2021); Ahn et al. (2022)). Trong bối cảnh này, các LLM là động cơ lý luận cho các tác nhân ra quyết định tuần tự tương tác với môi trường.

Công trình hiện tại là đầu tiên trong tài liệu nghiên cứu nhúng một LLM và huấn luyện nó như một tác nhân cho điều hướng web tự động. Điều này đòi hỏi các triển khai mới để thích ứng việc huấn luyện LLM cho nhân bản hành vi ngoài việc thiết kế giao diện để tích hợp tạo văn bản vào một chu kỳ nhận thức-tính toán-hành động hoạt động trong môi trường web có trạng thái. Triển khai của chúng tôi cho phép chúng tôi trả lời các câu hỏi mới về sự đánh đổi giữa các đặc điểm mô hình khác nhau.

Chúng tôi tin rằng những đóng góp này mở rộng phạm vi của các mô hình ngôn ngữ và kết nối các khả năng độc đáo của chúng với các tác nhân tự động cho web. Chúng tôi cung cấp một góc nhìn mới về học máy cho việc hiểu HTML và tự động hóa web, cho thấy rằng các LLM được tiền huấn luyện có thể đạt được hiệu suất đáng kể trên những tác vụ như vậy, giảm nhu cầu về các kiến trúc chuyên biệt và giao thức huấn luyện. Để khuyến khích nghiên cứu thêm theo hướng này, chúng tôi mở mã nguồn trọng số mô hình cho các tác nhân được sử dụng trong môi trường WoB và bộ dữ liệu của chúng tôi cho việc tạo mô tả.

2 CÔNG TRÌNH LIÊN QUAN

Hiểu HTML Điều hướng web tự động đã là một ứng dụng phổ biến cho các mô hình mạng neural, và nhiều công trình đề xuất các trang web mô phỏng để huấn luyện các tác nhân dựa trên web, với ứng dụng thực hiện tác vụ (Yao et al., 2022; Gur et al., 2021; Burns et al., 2022; Mazumder & Riva, 2020; Shi et al., 2017; Liu et al., 2018) cũng như truy xuất thông tin hoặc trả lời câu hỏi (Adolphs et al., 2021; Nogueira & Cho, 2016). Các trang web mô phỏng cung cấp một cách dễ dàng để đánh giá các mô hình trực tuyến, và vì lý do này chúng tôi sử dụng benchmark MiniWoB hiện có (Shi et al., 2017) cho thiết lập điều hướng web của chúng tôi. Tuy nhiên, vẫn quan trọng khi có một cơ chế để đánh giá các mô hình trên nhiều trang web thực tế đa dạng. Đây là động lực chính để tạo ra bộ dữ liệu riêng của chúng tôi cho tác vụ tạo mô tả, được chưng cất và gán nhãn tự động từ CommonCrawl và là một đóng góp chính của bài báo chúng tôi.

Cùng với những benchmark này, nhiều công trình đã phát triển các mô hình cho điều hướng web và các tác vụ phụ liên quan (Pasupat et al., 2018; Bommasani et al., 2021; He et al., 2021; Gur et al., 2021; Humphreys et al., 2022; Liu et al., 2018; Jia et al., 2019). Những công trình này thường dựa vào các kiến trúc mạng neural chuyên biệt tận dụng các thiên hướng quy nạp của cấu trúc HTML, hoặc trên tiền xử lý HTML để làm cho nó dễ dàng đưa vào mô hình hơn (Li et al. (2021a;b)). Ngược lại, công trình của chúng tôi thực hiện một cách tiếp cận tối giản, cung cấp HTML dưới dạng văn bản với xử lý tối thiểu và sử dụng các mạng transformer được áp dụng rộng rãi.

LLM và HTML Các công trình khám phá giao điểm của LLM và HTML thường rơi vào hai danh mục. Danh mục đầu tiên sử dụng LLM để hỗ trợ điều hướng web (Nakano et al., 2021; Yao et al., 2022), và thường dựa vào một tiền xử lý tùy chỉnh để ánh xạ bối cảnh và cấu trúc của một trang web sang ngôn ngữ tự nhiên, do đó hạn chế nghiêm trọng những trang HTML mà mô hình có thể phân tích. Danh mục thứ hai tiền huấn luyện LLM trên một kho ngữ liệu lớn văn bản HTML (Aghajanyan et al., 2021). Tuy nhiên, những công trình này thường hạn chế đánh giá mô hình đến các tác vụ NLP tiêu chuẩn, ví dụ, tóm tắt và trả lời câu hỏi thay vì các tác vụ liên quan hơn đến việc hiểu HTML và tự động hóa web. Công trình của chúng tôi có thể được coi là ngược lại: Chúng tôi giữ việc tiền huấn luyện các LLM không thay đổi và tập trung vào các cơ chế để chuyển giao các LLM được tiền huấn luyện đến các tác vụ liên quan đến HTML.

3 NỀN TẢNG NGẮN VỀ HTML NHƯ DỮ LIỆU VĂN BẢN BÁN CẤU TRÚC

HTML là một ngôn ngữ đánh dấu, được sử dụng để tổ chức cấu trúc và nội dung trang web. Xem xét ví dụ trang HTML trong Hình 1a. Trang web này bao gồm hai phần tử đầu vào liền kề, một cho e-mail và một cho mật khẩu, với các nhãn tương ứng của chúng trên một nhánh riêng biệt của trang. Những đầu vào và nhãn này là một trong nhiều phần tử có thể có phục vụ như các khối xây dựng HTML. Mỗi phần tử có một tập hợp các thuộc tính - cặp khóa và giá trị - mô tả nội dung của phần tử, chẳng hạn như kiểu dáng và văn bản có thể đọc được bởi con người. Khi được hiển thị trong trình duyệt, những thuộc tính này sẽ chịu trách nhiệm về cách phần tử được hiển thị và vị trí của nó. Trong ví dụ ở Hình 1a, đầu vào đầu tiên có ba thuộc tính, tag="input", type="email", và id="uName", xác định phần tử như một đầu vào email với một định danh ("uName") có thể được truy cập theo chương trình.

4 CÁC TÁC VỤ CHUẨN CHO VIỆC HIỂU HTML

Chúng tôi thiết kế ba tác vụ chuẩn để nghiên cứu khả năng hiểu HTML của các tác nhân web dựa trên LLM. Những tác vụ này đòi hỏi diễn giải chính xác cả cấu trúc và nội dung ở các mức độ khác nhau để đưa ra dự đoán, với điều hướng tự động là khả năng thử thách nhất trong ba tác vụ.

Điều hướng web tự động. Tác vụ này đánh giá mức độ tốt của một mô hình điều hướng các trang web đa trang như một vấn đề ra quyết định tuần tự (Shi et al., 2017; Liu et al., 2018). Vào đầu một tập phim, tác nhân được đưa một hướng dẫn ngôn ngữ tự nhiên, ví dụ Nhập tên người dùng "lyda" và mật khẩu "N22t" vào các trường văn bản và nhấn đăng nhập. Tác nhân áp dụng các hành động lên một chuỗi các trang HTML, trong đó mỗi hành động có dạng function(selector, text). Function là một trong click hoặc type, selector là một con trỏ số nguyên xác định duy nhất một phần tử, và text là văn bản để nhập nếu chức năng type được kích hoạt. Một tập phim kết thúc khi trang đạt đến trạng thái cuối (ví dụ, nút 'đăng nhập' được nhấp) hoặc số bước tối đa được đạt tới.

Phân loại ngữ nghĩa. Nhiều ứng dụng hiểu HTML đòi hỏi một mô hình có thể phân loại các phần tử HTML thành các danh mục tiêu chuẩn. Ví dụ, trong điền biểu mẫu tự động (Diaz et al., 2013; Gur et al., 2021), việc xác định một 'nút gửi' trên nhiều trang web (ví dụ, mua sắm, đặt vé máy bay, ứng dụng tiện ích) với các biểu diễn nút khác nhau (ví dụ, vị trí, màu sắc, hoặc văn bản) là hữu ích. Do đó, chúng tôi xây dựng Phân loại ngữ nghĩa như việc phân loại các phần tử thành các danh mục vai trò. Lấy ví dụ HTML trong Hình 1a bao gồm hai phần tử đầu vào và một nút gửi. Hãy chọn đầu vào đầu tiên như một phần tử quan tâm để được phân loại bởi hệ thống, còn được gọi là phần tử nổi bật. Hệ thống nên phân loại phần tử này như username, vì nó xuất hiện trên một trang đăng nhập và nó có một nhãn với Email Address thường được liên kết với username trong các ứng dụng điền biểu mẫu. Để giải quyết điều này, hệ thống có thể tổng hợp thông tin từ nhiều nguồn trong trang - nhãn nói Enter Email Address, các thuộc tính input (type="email" và id="uName"), hoặc thậm chí thứ tự của các phần tử khác trong trang như 'password' và 'sign in'.

Tạo mô tả. Được thúc đẩy bởi các ứng dụng trong điều khiển trình duyệt web quan tâm đến khả năng tiếp cận (Jorgensen & Binsted, 2005), chúng tôi xây dựng tạo mô tả như một vấn đề trích xuất trong đó mục tiêu là định vị mô tả văn bản của một phần tử trong HTML và tạo ra nó như đầu ra. Ví dụ, mô tả của phần tử nổi bật trong Hình 1a là Enter Email Address; khi được hiển thị, nhãn này sẽ xuất hiện phía trên trường đầu vào 'email'. HTML cung cấp một lượng lớn tính linh hoạt, và do đó nói chung một văn bản mô tả xuất hiện cùng với một phần tử cụ thể khi được hiển thị có thể rất xa với phần tử đó khi nhìn vào văn bản thuần HTML. Do đó, tác vụ này đánh giá khả năng của một mô hình hiểu cấu trúc của HTML như nó sẽ xuất hiện đối với người dùng, mặc dù không có quyền truy cập trực tiếp vào trang web được hiển thị.

5 BỘ DỮ LIỆU

Mỗi tác vụ chuẩn của chúng tôi đòi hỏi một bộ dữ liệu riêng biệt, với tác vụ tạo mô tả sử dụng một bộ dữ liệu mới được đóng góp, gán nhãn tự động dựa trên CommonCrawl.

Điều hướng web tự động. Chúng tôi sử dụng 12K minh chứng được bao gồm trong benchmark MiniWoB công khai có sẵn (Shi et al., 2017), bao gồm 62 ứng dụng trang web từ chuyển tiếp email đến tương tác mạng xã hội. Mỗi minh chứng là một chuỗi các bộ ba (instruction, HTML, action). Mọi phần tử trong một minh chứng MiniWoB đều đi kèm với một số tham chiếu duy nhất trong các trang tương ứng của nó. Số này có thể được sử dụng như một bộ chọn phần tử, làm cho không gian hành động thống nhất trên tất cả các tác vụ và bước thời gian. Ví dụ, hành động trong Hình 1a sẽ là type(ref=5, "username@email.com"), trong đó 5 đề cập đến chỉ số của đầu vào khi đếm từ trên xuống dưới. Như đầu vào mô hình, chúng tôi nối hướng dẫn ngôn ngữ tự nhiên và HTML thành một chuỗi đầu vào văn bản duy nhất. Tương tự, chúng tôi coi hành động như một chuỗi văn bản để mô hình dự đoán.

Phân loại ngữ nghĩa. Chúng tôi sử dụng một bộ dữ liệu gồm 28K ví dụ được gán nhãn, chứa 66 danh mục khác nhau, có dạng (HTML, element, category), được sử dụng trước đây trong bối cảnh tạo môi trường (Gur et al., 2021). Bộ dữ liệu bao gồm HTML từ các trang web mua sắm thực tế và các danh mục liên quan đến điền biểu mẫu trong quá trình thanh toán và kiểm tra trên những trang web này.

Tạo mô tả. Đối với tác vụ này, chúng tôi tạo ra một bộ dữ liệu từ CommonCrawl. CommonCrawl không bao gồm các kết xuất hoặc chú thích sẽ tiết lộ văn bản nào trong HTML được liên kết với phần tử nào. Thay vào đó, chúng tôi suy luận các mô tả của các phần tử khác nhau bằng cách khai thác một thuộc tính đặc biệt trong lược đồ HTML được biết đến như for. Như một ví dụ trong Hình 1a, nhãn đầu tiên trong HTML có một thuộc tính for với giá trị uName, đó là id của phần tử được mô tả bởi nhãn; trong trường hợp này, id là của đầu vào đầu tiên trong trang. Chú thích này không ảnh hưởng đến việc hiển thị trang và thường được sử dụng cho mục đích khả năng tiếp cận. Chúng tôi sử dụng thông tin được cung cấp bởi những thuộc tính for này để tạo ra một bộ dữ liệu quy mô lớn để nghiên cứu tạo mô tả. Một mẫu nhỏ có sẵn trong tài liệu bổ sung, trong khi toàn bộ bộ dữ liệu sẽ có sẵn khi xuất bản.

Cụ thể, chúng tôi thu thập 100 tệp WARC (từ tháng 4 năm 2019) từ dự án CommonCrawl và trích xuất tất cả các nhãn HTML có thuộc tính for. Loại bỏ văn bản không phải Unicode và số-chữ trong các nhãn HTML dẫn đến một bộ dữ liệu 400K ví dụ. Chúng tôi cân bằng phân phối của các nhãn, hiệu quả giảm mẫu bộ dữ liệu xuống 85K mẫu. Mỗi ví dụ được biểu diễn như (HTML, element, description), trong đó HTML là văn bản thuần HTML của trang, element là phần tử có thuộc tính id khớp với cái xuất hiện trong thuộc tính for của nhãn, và description là văn bản bên trong phần tử nhãn (xem ví dụ trong Hình 1a). Thêm chi tiết về bộ dữ liệu có thể được tìm thấy trong Phụ lục A.1.

6 TIỀN XỬ LÝ

Trong việc coi HTML như các chuỗi token, chúng tôi giảm thiểu bất kỳ tiền xử lý cây HTML nào trước khi đưa vào mô hình. Do đó chúng tôi cung cấp HTML như văn bản thô (tức là, các chuỗi token văn bản) và chỉ áp dụng một tiền xử lý trích xuất đoạn cho các trang quá lớn để vừa với cửa sổ bối cảnh điển hình của LLM.

Trích xuất đoạn. Các trang HTML thực có thể trở nên cực kỳ lớn, đạt đến hàng nghìn phần tử, vượt xa cửa sổ bối cảnh của LLM lớn nhất mà chúng tôi nghiên cứu (1920 token trong PaLM (Chowdhery et al., 2022)). Các LLM thường cắt bớt những chuỗi dài như vậy, điều này có thể có hại đến việc hiểu HTML vì HTML không được cấu trúc tuyến tính. Chúng tôi thực hiện một cách tiếp cận tập trung vào phần tử và trích xuất các đoạn HTML (một phần nhỏ của mã HTML) xung quanh một phần tử nổi bật (Hình 5). Một heuristic đơn giản, điều khiển chiều rộng và độ sâu của cây, hướng dẫn quá trình: Bắt đầu với một phần tử nổi bật và duyệt các tổ tiên của nó trong cây HTML cho đến khi một điều kiện dừng được thỏa mãn. Khi chúng tôi duyệt lên, chúng tôi ước tính chiều cao của cây và số lượng con cháu tăng của gốc mới. Chúng tôi dừng khi một trong hai chỉ số vi phạm một giới hạn được định nghĩa trước và lấy cây con kết quả như đoạn. Chúng tôi đánh dấu phần tử nổi bật bằng cách sử dụng một thuộc tính đặc biệt, được gọi là target, để phân biệt nó với các phần tử khác. Chúng tôi thực hiện trích xuất đoạn cho các bộ dữ liệu phân loại ngữ nghĩa và tạo mô tả, và giữ các trang HTML đầy đủ trong MiniWoB vì những trang này thường nhỏ hơn nhiều so với HTML thế giới thực.

HTML un-Parsing. Chúng tôi cung cấp cho các mô hình HTML văn bản thuần chưa được phân tích dưới dạng một chuỗi các token. Biểu diễn chuẩn này không đòi hỏi các kiến trúc mô hình cụ thể như mạng phân cấp (Liu et al., 2018; Gur et al., 2021) và có thể được đưa vào bất kỳ LLM nào. Chúng tôi chuyển đổi tất cả các bộ dữ liệu bằng cách chuyển đổi mọi trang hoặc đoạn HTML thành một chuỗi. Đối với MiniWoB, chúng tôi thêm nối (action history, instruction, HTML) bộ ba thành một chuỗi duy nhất.

7 HUẤN LUYỆN MÔ HÌNH

Chúng tôi nghiên cứu nhiều LLM dựa trên transformer (Vaswani et al., 2017) với các kích thước và kiến trúc khác nhau cho các tác vụ hiểu HTML (Bảng 1). Trong phần còn lại của văn bản, chúng tôi đặt tiền tố cho các mô hình được tinh chỉnh cho Điều hướng web tự động, Tạo mô tả, và Phân loại ngữ nghĩa với WebN-, WebD-, và WebC-, tương ứng. Ví dụ, WebD–T5-3B là mô hình T5 ba tỷ tham số (Raffel et al., 2020) được tinh chỉnh cho tác vụ Tạo mô tả. Phần còn lại của mục này trình bày chi tiết về huấn luyện.

Các mô hình Encoder-Decoder và chỉ Decoder. Chúng tôi huấn luyện các mô hình encoder-decoder, tức là T5 (Raffel et al., 2020), và các mô hình chỉ decoder, tức là LaMDA (Thoppilan et al., 2022) và PaLM (Chowdhery et al., 2022), với đầu vào văn bản và đầu ra văn bản (Hình 1b). Đầu vào là các trang HTML thô hoặc văn bản đoạn; tương tự, đầu ra là các danh mục, mô tả ngôn ngữ tự nhiên, hoặc hành động được biểu diễn như văn bản. Cụ thể, đối với Phân loại ngữ nghĩa chúng tôi sử dụng biểu diễn văn bản của các danh mục, tương tự như các vấn đề phân loại trước đây trong NLP (Raffel et al., 2020). Đối với Điều hướng web tự động, các hành động được chuyển đổi thành văn bản bằng cách đầu tiên chuyển đổi chúng thành các cặp khóa và giá trị và sau đó nối các cặp.

Nhiều trang web trong MiniWoB đòi hỏi nhiều tương tác, chẳng hạn như click-button-sequence hoặc click-checkboxes, trong đó mỗi tương tác có thể gây ra một thay đổi tinh tế trong trạng thái trang web. Ví dụ, sau khi nhấp vào một checkbox trong trang web click-checkboxes, giá trị của nó lật từ tích cực sang tiêu cực hoặc ngược lại, điều này không phải lúc nào cũng được phản ánh trong dự đoán của LLM và dẫn đến lặp lại hành động. Chúng tôi giải quyết vấn đề này bằng cách tăng cường các bộ ba trong bộ dữ liệu với một chuỗi các hành động trong quá khứ, (action history, instruction, HTML, action), và cho phép LLM học từ kinh nghiệm quá khứ.

Các mô hình chỉ Encoder. Chúng tôi huấn luyện các mô hình chỉ encoder, tức là BERT (Devlin et al., 2018), với đầu vào văn bản và đầu ra phân loại. Chúng tôi giữ các danh mục ngữ nghĩa như các lớp one-hot rời rạc. Để huấn luyện các mô hình chỉ encoder, chúng tôi thêm một lớp phân loại mới sau lớp encoder cuối để tạo ra một phân phối trên các danh mục ngữ nghĩa. Ngoài các mô hình BERT điển hình, chúng tôi nghiên cứu MobileBERT (Sun et al., 2020), được chưng cất từ BERT-large với các cổ chai nghịch đảo, và Albert-XL (Lan et al., 2020), với chia sẻ tham số và phân tách nhúng.

8 KẾT QUẢ

Chúng tôi bây giờ trình bày kết quả của các LLM được tinh chỉnh cho việc hiểu HTML. Chúng tôi so sánh hiệu suất của các mô hình với các baseline hiện có nếu có thể (điều hướng web tự động) và so với các kiến trúc LLM và chế độ huấn luyện khác (tất cả các tác vụ). Các mục 8.1, 8.2, và 8.3 đánh giá hiệu suất cụ thể theo tác vụ, trong khi Mục 8.4 đánh giá hiệu suất trên tất cả các tác vụ.

Chỉ số: Đối với điều hướng web tự động chúng tôi đánh giá Tỷ lệ thành công của các mô hình, được tính trung bình trên 100 tập phim cho mỗi tác vụ. Đối với các tác vụ khác, chúng tôi sử dụng Độ chính xác để đo sự khớp chính xác giữa dự đoán và sự thật cơ sở. Trong tác vụ tạo mô tả, chúng tôi bổ sung cung cấp các đánh giá sử dụng các chỉ số đánh giá văn bản 'mềm' thay thế, BLEU và ROUGE-1, đo độ tương tự giữa văn bản được dự đoán và sự thật cơ sở.

8.1 KẾT QUẢ ĐIỀU HƯỚNG WEB TỰ ĐỘNG

Đối với Điều hướng web tự động chúng tôi tinh chỉnh hai kiến trúc encoder-decoder WebN- (WebN-T5-large và WebN-T5-3B) trên 12k minh chứng từ các trang web thực được chú thích bởi con người. Chúng tôi đánh giá các mô hình trên benchmark MiniWob (Liu et al., 2018), và so sánh với các kiến trúc chuyên biệt được huấn luyện bằng học có giám sát (SL) trên 2,4 triệu minh chứng chuyên gia con người CC-Net (SL) (Humphreys et al., 2022), và hai mô hình RL được bootstrap với SL, CC-Net (SL) (CC-Net (SL & RL) (Humphreys et al., 2022), và WGE (SL & RL) (Liu et al., 2018)). Ngoài ra, chúng tôi so sánh với kiến trúc chỉ decoder (WebN-Lambda-1B) và thực hiện một nghiên cứu loại bỏ về tác động của việc bao gồm lịch sử hành động trong đầu vào.

So sánh với SoTA. Vì các công trình trước đây báo cáo thành công chỉ trên một tập con các trang web trong MiniWoB, chúng tôi đánh giá trên 48 trong số 62 trang web chung trên tất cả các mô hình. Bảng 8 trong Phụ lục báo cáo kết quả chi tiết trong khi Hình 2a trình bày kết quả được tính trung bình trên tất cả các trang web. So với CC-Net (SL) được huấn luyện trên tất cả 2,4M minh chứng, WebN-T5-3B cải thiện thành công 16% trong khi chỉ huấn luyện trên 12K minh chứng công khai có sẵn, mang lại cải thiện hiệu quả mẫu hơn 192 lần. Chúng tôi thấy rằng tất cả các lựa chọn LLM đều vượt trội hơn các mô hình SL trước đây. Đáng chú ý, WebN-T5-3B cải thiện đáng kể trên các trang web đòi hỏi chuỗi hành động đa bước như click checkboxes hoặc các trang web đòi hỏi nhập văn bản như login user (Bảng 8). Chúng tôi quan sát rằng hiệu suất của LLM chỉ bị vượt qua bởi các công trình trước đây sử dụng RL, đòi hỏi nhiều bậc độ lớn hơn về kinh nghiệm tương tác trực tuyến. Mở rộng các LLM được tinh chỉnh của chúng tôi sang một thiết lập RL là một hướng đầy hứa hẹn cho công trình tương lai.

Loại bỏ lịch sử hành động. Trên tất cả các LLM chúng tôi nhất quán quan sát một sự giảm thành công, trung bình 6,4%, khi các hành động quá khứ được loại trừ khỏi đầu vào (Hình 2a). Lịch sử hành động giúp với các trang web đòi hỏi nhập nhiều văn bản, cũng như hiểu các thay đổi nhỏ có thể khó phát hiện (ví dụ click checkboxes và multi layout). multi layout đòi hỏi nhập 3 văn bản khác nhau trong trang web nơi bố cục được ngẫu nhiên hóa ở mỗi tập phim, tuy nhiên, đáng ngạc nhiên, ngay cả mô hình WebN-T5-large (tương đối nhỏ hơn) không có lịch sử hành động vẫn vượt trội hơn mô hình CC-Net (SL); minh họa rằng việc tích hợp lịch sử hành động không phải là yếu tố đóng góp duy nhất cho thành công tốt hơn.

8.2 KẾT QUẢ TÁC VỤ PHÂN LOẠI NGỮ NGHĨA

Để đánh giá tác vụ Phân loại ngữ nghĩa, chúng tôi so sánh ba biến thể kích thước của kiến trúc encoder-decoder T5 (WebC-T5-base, WebC-T5-large, và WebC-T5-3B) được tinh chỉnh trên 22K trang web huấn luyện thực, được gán nhãn bởi con người. Chúng tôi so sánh với các kiến trúc chỉ encoder được tinh chỉnh (WebC-*BERT*), ba kiến trúc chỉ decoder được tinh chỉnh (WebC-LaMDA và PaLM), và cả các mô hình encoder-decoder và chỉ decoder được huấn luyện trên các trang web được gán nhãn bởi con người từ đầu. Kết quả được trình bày trong Bảng-2, nơi chúng tôi thấy rằng tất cả WebC-LLM đều hoạt động tốt và tốt hơn đáng kể so với các kiến trúc tương tự không có tiền huấn luyện.

Độ chính xác theo danh mục. Trong Hình 3, chúng tôi trình bày phân phối độ chính xác của mô hình WebC-T5-3B trên bộ dữ liệu phát triển. Mô hình encoder-decoder được tinh chỉnh hoạt động mạnh mẽ trên phần lớn các danh mục (Hình 3), thậm chí trên những danh mục có rất ít mẫu. Ví dụ, mô hình chính xác 100% trên password new chỉ có 56 ví dụ huấn luyện, vì lớp này không mơ hồ. Mặt khác, không ngạc nhiên, hiệu suất giảm khi danh mục mơ hồ, chẳng hạn như trong danh mục email thường bị nhầm lẫn với username.

Loại bỏ tạo đoạn. Hai siêu tham số chi phối việc tạo đoạn: phần trăm con cháu mới và chiều cao của gốc mới. Trong khi các biến thể nhỏ của cả hai tham số không thay đổi hiệu suất, việc tăng cả hai làm giảm hiệu suất đáng kể (Bảng 4a). Với con cháu mới lên đến 500% và chiều cao lên đến 7, hiệu suất giảm hơn 15%. Lưu ý rằng việc tạo đoạn trả về HTML toàn trang khi cả hai tham số tăng vô hạn.

Tác động kích thước dữ liệu. Khi thay đổi kích thước dữ liệu huấn luyện tinh chỉnh (1, 5, 10, 20, hoặc 50 mẫu cho mỗi lớp) trong Hình 4b, WebC-T5-3B vượt trội nhẹ so với WebC-PaLM-8B lớn hơn một bậc độ lớn. So với T5-3B được huấn luyện trên tất cả dữ liệu HTML có sẵn không có tiền huấn luyện, WebC-T5-3B đạt được hiệu suất tốt hơn trong khi chỉ sử dụng 3,4% dữ liệu được gán nhãn (1000 mẫu), do đó làm nổi bật lợi ích của việc sử dụng các LLM tiền huấn luyện tiêu chuẩn có sẵn cho việc hiểu HTML.

8.3 KẾT QUẢ TÁC VỤ TẠO MÔ TẢ

Đối với Tạo mô tả chúng tôi chia bộ dữ liệu CommonCrawl dựa trên tên miền cấp cao URL để kiểm tra khả năng tổng quát hóa của LLM đến HTML chưa thấy. Chúng tôi tinh chỉnh các kiến trúc encoder-decoder (WebD–T5*) và các mô hình chỉ decoder (WebD–LaMDA*), với kết quả được trình bày trong Bảng 3. Chúng tôi cũng đánh giá một baseline heuristic mạnh chỉ đơn giản tìm mô tả gần nhất với phần tử nổi bật trong văn bản HTML (Closest Description).

Hiệu suất độ chính xác và độ tương tự Chúng tôi cho thấy kết quả đánh giá của chúng tôi trong Bảng 3. Tất cả các mô hình đạt được điểm số cao trên tất cả các chỉ số, đạt 84% về độ chính xác trong việc khớp chính xác và điểm số không khớp chính xác cao hơn dựa trên BLEU và ROUGE-1 (≈ 91%). Sự khác biệt này cho thấy rằng các mô hình có khả năng định vị các mô tả, nhưng không phải lúc nào cũng tạo ra đầu ra chính xác.

8.4 PHÂN TÍCH HIỆU SUẤT LLM HIỂU HTML TRÊN CÁC TÁC VỤ

Chúng tôi bây giờ phân tích kết quả của chúng tôi một cách tổng hợp để rút ra các kết luận chính.

8.4.1 HIỆU ỨNG TIỀN HUẤN LUYỆN: TIỀN HUẤN LUYỆN TRÊN KHO NGỮ LIỆU VĂN BẢN LỚN CÓ Ý NGHĨA

Các LLM tiền huấn luyện được tinh chỉnh vượt trội hơn các LLM được huấn luyện chỉ trên dữ liệu HTML, cải thiện hiệu suất hơn 34,1% trên Điều hướng web tự động (Bảng 2b), và 10% đến 12,7% trên tác vụ Phân loại ngữ nghĩa (Bảng 2).

Vì Điều hướng web tự động là tác vụ khó khăn nhất, hiệu suất cải thiện là bằng chứng khuyến khích về giá trị của LLM trong các tác vụ hiểu HTML. Cụ thể, chúng tôi quan sát rằng các LLM không có tiền huấn luyện chỉ tương đương với các mô hình tiền huấn luyện được tinh chỉnh trên các trang web đòi hỏi khớp văn bản đơn giản. Ngược lại, đối với các trang web như click checkboxes, việc khớp văn bản khó hơn và chúng tôi thấy rằng tiền huấn luyện là chìa khóa cho hiệu suất tốt. Chúng tôi cũng thấy rằng không có tiền huấn luyện, đầu ra mô hình thường ở định dạng sai như từ điển không hợp lệ hoặc refs không hợp lệ với giá trị không phải số nguyên. Điều này gợi ý rằng kho ngữ liệu lớn được sử dụng cho tiền huấn luyện giúp các mô hình học cấu trúc HTML tổng quát.

8.4.2 HIỆU ỨNG KIẾN TRÚC: CÁC MÔ HÌNH DỰA TRÊN T5 HOẠT ĐỘNG TỐT NHẤT TRÊN TẤT CẢ CÁC TÁC VỤ

Các mô hình encoder-decoder dựa trên T5 hoạt động tốt hơn trên cả ba tác vụ. Trên tác vụ Điều hướng web tự động, các kiến trúc encoder-decoder (WebN-T5) tốt hơn hoặc tương đương với WebN-LaMDA-1B (Hình 2a). Trên Phân loại ngữ nghĩa, mô hình encoder-decoder nhỏ nhất (WebC-T5-base) hoạt động tương đương với các mô hình chỉ decoder lớn hơn nhiều (WebC-LaMDA-1B hoặc WebC-PaLM-8B) và mô hình chỉ encoder lớn nhất (WebC-BERT-large) có nhiều hơn 85M tham số (Bảng 2). Chúng tôi cũng quan sát rằng PaLM-8B chỉ decoder hoạt động tệ hơn T5-large encoder-decoder nhỏ hơn nhiều khi được huấn luyện chỉ trên dữ liệu HTML. Cuối cùng, trên Tạo mô tả kiến trúc encoder-decoder có điểm BLEU cao hơn.

Một giải thích có thể cho hiệu suất mạnh mẽ của các mô hình dựa trên T5 là kiến trúc encoder-decoder của những mô hình này. Cụ thể, các mô hình T5 sử dụng một encoder với cơ chế attention hai chiều, không có trong các decoder LaMDA và PaLM. Cơ chế attention hai chiều có thể xử lý các trang HTML từ cả hai đầu, có khả năng vượt qua sự mất thông tin khi các trang HTML có cấu trúc cây được chuyển đổi thành các chuỗi văn bản tuyến tính cố định.

8.4.3 HIỆU ỨNG KÍCH THƯỚC MÔ HÌNH: KÍCH THƯỚC (DƯỚ TUYẾN TÍNH) CÓ Ý NGHĨA

Trên các tác vụ, dường như kiến trúc đóng một vai trò quan trọng trong hiệu suất mô hình. Kích thước mô hình và hiệu suất cũng tương quan tích cực, mặc dù chúng đạt đến lợi nhuận giảm dần. Ví dụ, hiệu suất mô hình xấp xỉ O(log log n) đối với kích thước mô hình trên Phân loại ngữ nghĩa (Hình 4b trong Phụ lục). Trên tác vụ Điều hướng web tự động, hiệu suất tăng chậm với kích thước mô hình (Bảng 8), trong khi trên Tạo mô tả nó đạt ngưỡng (Bảng 3).

8.5 THẢO LUẬN

Attention hai chiều so với kho ngữ liệu huấn luyện: Tiền huấn luyện trên kho ngữ liệu lớn có ý nghĩa, mang lại cải thiện hiệu suất 4,5 lần. Các mô hình lớn hơn có xu hướng tốt hơn và chúng tôi ghi nhận attention hai chiều cho hiệu suất tổng thể tốt nhất của T5 trên các tác vụ. PaLM và LaMDA bao gồm HTML và mã khác trong kho ngữ liệu tiền huấn luyện của chúng, trong khi các kiến trúc BERT và T5 thì không, cho thấy rằng tiền huấn luyện trên HTML không cần thiết cho hiệu suất mạnh mẽ khi được tinh chỉnh cho việc hiểu HTML. Điều này củng cố giả thuyết đằng sau vai trò của attention hai chiều, và mở ra khả năng cải thiện thêm hiệu suất của các kiến trúc T5 bằng cách tiền huấn luyện chúng trên kho ngữ liệu với HTML.

Tác động thực tế đến việc gán nhãn: Khi có sẵn, các LLM tiền huấn luyện cần rất ít dữ liệu chuyên gia mới (giảm 200 lần và 30 lần trên các tác vụ điều hướng web và phân loại, tương ứng). Điều này có tác động tiềm năng lớn đến các ứng dụng thực tế, giảm thời gian và chi phí thu thập dữ liệu theo các bậc độ lớn.

Lớn hơn không phải lúc nào cũng tốt hơn: Khi chọn kích thước mô hình, các lợi ích hiệu suất dự kiến (dưới tuyến tính tốt nhất và tiệm cận tệ nhất) nên được xem xét cùng với thời gian huấn luyện và suy luận cũng như chi phí của mô hình. Ví dụ, trên tác vụ phân loại, mô hình lớn nhất WebC-PaLM-62B mất vài ngày để tinh chỉnh, và đánh giá ở 30 Hz, trong khi WebC-T5-large tinh chỉnh trong vài giờ và đánh giá ở 700 Hz - đắt hơn một bậc độ lớn cho một phần trăm cải thiện độ chính xác duy nhất. Mặt khác, các mô hình BERT huấn luyện trong vài phút. Nếu ứng dụng không đòi hỏi độ chính xác cao, chúng có thể là lựa chọn tốt.

Cửa sổ bối cảnh là một nút thắt cổ chai: Nút thắt cổ chai chính cho các tác vụ hiểu HTML dường như là độ dài cửa sổ bối cảnh mà các LLM hiện tại hỗ trợ, ngay cả với các mô hình chấp nhận 1000+ token. Việc đánh giá các tác vụ điều hướng web trên các trang web thực lớn hơn các bậc độ lớn so với các trang trong MiniWob vẫn bị cấm. Tương tự, chúng tôi quan sát rằng việc tăng kích thước đoạn dẫn đến suy giảm hiệu suất lớn. Điều này làm cho việc hiểu HTML trở thành một benchmark thú vị cho phát triển LLM tương lai. Ví dụ, các phương pháp mới có thể cần được phát triển để nén biểu diễn trạng thái của nội dung web để sử dụng trong cửa sổ bối cảnh LLM.

9 KẾT LUẬN

Chúng tôi đã trình bày các tác vụ chuẩn và các LLM được tinh chỉnh cho việc hiểu HTML. Các đánh giá và phân tích toàn diện trên một loạt các kiến trúc, kích thước bộ dữ liệu, và baseline mang lại các phát hiện thực tế và làm nổi bật các hạn chế hiện tại của những mô hình này. Chúng tôi thấy rằng a) tiền huấn luyện là quan trọng cho hiệu suất và có thể giảm yêu cầu dữ liệu được gán nhãn, cải thiện hiệu quả mẫu lên đến 200 lần; b) kiến trúc mô hình là yếu tố quan trọng thứ hai, và các mô hình T5 với attention hai chiều và kiến trúc encoder-decoder hoạt động tốt nhất trên toàn bộ bảng; c) khi có lựa chọn, kích thước mô hình nên được đánh giá trong bối cảnh hiệu suất huấn luyện và suy luận của mô hình, vì kích thước mô hình tương quan dưới tuyến tính với hiệu suất của nó. Cuối cùng, các tác vụ hiểu HTML được đề xuất làm nổi bật cửa sổ bối cảnh tương đối ngắn hạn chế các LLM hiện tại, gợi ý khả năng cho nghiên cứu tương lai tích hợp hoặc loại bỏ ràng buộc này.

# 1906.00695.pdf
# Đã chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/hypernetwork/1906.00695.pdf
# Kích thước tệp: 3272642 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2020
HỌC LIÊN TỤC VỚI HYPERNETWORK
Johannes von Oswald*, Christian Henning*, Benjamin F. Grewe, João Sacramento
*Đóng góp bằng nhau
Viện Neuroinformatics
Đại học Zürich và ETH Zürich
Zürich, Thụy Sĩ
{voswaldj,henningc,bgrewe,rjoao}@ethz.ch
TÓM TẮT
Mạng nơ-ron nhân tạo bị ảnh hưởng bởi hiện tượng quên thảm khốc khi chúng được huấn luyện tuần tự trên nhiều nhiệm vụ. Để vượt qua vấn đề này, chúng tôi trình bày một phương pháp tiếp cận mới dựa trên hypernetwork có điều kiện nhiệm vụ, tức là các mạng tạo ra trọng số của mô hình đích dựa trên danh tính nhiệm vụ. Học liên tục (CL) ít khó khăn hơn đối với loại mô hình này nhờ vào một đặc điểm chính đơn giản: thay vì nhớ lại mối quan hệ đầu vào-đầu ra của tất cả dữ liệu đã thấy trước đó, hypernetwork có điều kiện nhiệm vụ chỉ cần nhớ lại việc thực hiện trọng số cụ thể theo nhiệm vụ, có thể được duy trì trong bộ nhớ bằng cách sử dụng một bộ điều chỉnh đơn giản. Bên cạnh việc đạt được hiệu suất tiên tiến trên các điểm chuẩn CL tiêu chuẩn, các thí nghiệm bổ sung trên chuỗi nhiệm vụ dài tiết lộ rằng hypernetwork có điều kiện nhiệm vụ thể hiện một khả năng rất lớn để giữ lại ký ức trước đó. Đáng chú ý, thời gian sống ký ức dài như vậy đạt được trong chế độ nén, khi số lượng trọng số hypernetwork có thể huấn luyện có thể so sánh được hoặc nhỏ hơn kích thước mạng đích. Chúng tôi cung cấp cái nhìn sâu sắc về cấu trúc của không gian nhúng nhiệm vụ chiều thấp (không gian đầu vào của hypernetwork) và chỉ ra rằng hypernetwork có điều kiện nhiệm vụ thể hiện học chuyển giao. Cuối cùng, chuyển giao thông tin tiến được hỗ trợ thêm bởi kết quả thực nghiệm trên một điểm chuẩn CL thử thách dựa trên bộ dữ liệu hình ảnh CIFAR-10/100.

1 GIỚI THIỆU
Chúng tôi giả định rằng một mạng nơ-ron f(x;θ) với các trọng số có thể huấn luyện θ được cung cấp dữ liệu từ một tập các nhiệm vụ {(X^(1),Y^(1)),...,(X^(T),Y^(T))}, với các mẫu đầu vào X^(t) = {x^(t,i)}^{n_t}_{i=1} và các mẫu đầu ra Y^(t) = {y^(t,i)}^{n_t}_{i=1}, trong đó n_t ≡ |X^(t)|. Một phương pháp huấn luyện tiêu chuẩn học mô hình sử dụng dữ liệu từ tất cả các nhiệm vụ cùng một lúc. Tuy nhiên, điều này không phải lúc nào cũng có thể trong các vấn đề thực tế, cũng như không mong muốn trong môi trường học trực tuyến. Học liên tục (CL) đề cập đến một thiết lập học trực tuyến trong đó các nhiệm vụ được trình bày tuần tự (xem van de Ven & Tolias, 2019, để có đánh giá gần đây về CL). Trong CL, khi học một nhiệm vụ mới t, bắt đầu với các trọng số θ^(t-1) và chỉ quan sát (X^(t),Y^(t)), mục tiêu là tìm một tập tham số mới θ^(t) sao cho (1) giữ lại (không có quên thảm khốc) hoặc (2) cải thiện (chuyển giao ngược tích cực) hiệu suất trên các nhiệm vụ trước đó so với θ^(t-1) và (3) giải quyết nhiệm vụ mới t có thể sử dụng kiến thức đã có trước đó (chuyển giao tiến tích cực). Đạt được những mục tiêu này là không tầm thường, và là một vấn đề lâu dài trong nghiên cứu mạng nơ-ron.

Ở đây, chúng tôi đề xuất giải quyết quên thảm khốc ở mức meta: thay vì trực tiếp cố gắng giữ lại f(x;θ) cho các nhiệm vụ trước đó, chúng tôi cố định các đầu ra của một metamodel f_h(e;θ_h) được gọi là hypernetwork có điều kiện nhiệm vụ mà ánh xạ một nhúng nhiệm vụ e tới các trọng số θ. Bây giờ, một điểm duy nhất phải được ghi nhớ cho mỗi nhiệm vụ. Để thúc đẩy phương pháp như vậy, chúng tôi thực hiện một thí nghiệm tư duy: chúng tôi giả định rằng chúng tôi được phép lưu trữ tất cả các đầu vào {X^(1),...,X^(T)} đã thấy cho đến nay, và sử dụng những dữ liệu này để tính toán các đầu ra mô hình tương ứng với θ^(T-1). Trong môi trường lý tưởng này, người ta có thể tránh quên bằng cách đơn giản là trộn dữ liệu từ nhiệm vụ hiện tại với dữ liệu từ quá khứ, {(X^(1),Ŷ^(1)),...,(X^(T-1),Ŷ^(T-1)),(X^(T),Y^(T))}, trong đó Ŷ^(t) đề cập đến một tập các mục tiêu tổng hợp được tạo ra sử dụng chính mô hình f(·;θ^(t-1)). Do đó, bằng cách huấn luyện để giữ lại các ánh xạ đầu vào-đầu ra đã có trước đó, người ta có thể thu được một thuật toán tuần tự về nguyên tắc mạnh mẽ như học đa nhiệm vụ. Học đa nhiệm vụ, nơi tất cả các nhiệm vụ được học đồng thời, có thể được xem như một giới hạn trên của CL. Chiến lược được mô tả ở trên đã được gọi là rehearsal (Robins, 1995). Tuy nhiên, lưu trữ dữ liệu nhiệm vụ trước đó vi phạm các desiderata CL của chúng tôi.

Do đó, chúng tôi giới thiệu một sự thay đổi quan điểm và chuyển từ thách thức duy trì các điểm dữ liệu đầu vào-đầu ra riêng lẻ sang vấn đề duy trì các tập tham số {θ^(t)}, mà không cần lưu trữ chúng một cách rõ ràng. Để đạt được điều này, chúng tôi huấn luyện các tham số metamodel θ_h tương tự như sơ đồ học được nêu trên, trong đó các mục tiêu tổng hợp bây giờ tương ứng với các cấu hình trọng số phù hợp cho các nhiệm vụ trước đó. Điều này thay thế việc lưu trữ toàn bộ một bộ dữ liệu bằng một mô tả nhiệm vụ duy nhất chiều thấp, mang lại một tiết kiệm bộ nhớ lớn trong tất cả trừ những nhiệm vụ đơn giản nhất.

Mặc dù dựa vào điều chỉnh, phương pháp của chúng tôi là một sự khởi hành khái niệm từ các thuật toán trước đó dựa trên điều chỉnh trong trọng số (ví dụ, Kirkpatrick et al., 2017; Zenke et al., 2017) hoặc không gian kích hoạt (ví dụ, He & Jaeger, 2018).

Kết quả thực nghiệm của chúng tôi cho thấy rằng hypernetwork có điều kiện nhiệm vụ không bị ảnh hưởng bởi quên thảm khốc trên một tập các điểm chuẩn CL tiêu chuẩn. Đáng chú ý, chúng có khả năng giữ lại ký ức với thực tế không có sự giảm hiệu suất, khi được trình bày với chuỗi các nhiệm vụ rất dài. Nhờ sức mạnh biểu đạt của mạng nơ-ron, hypernetwork có điều kiện nhiệm vụ khai thác sự tương đồng nhiệm vụ-nhiệm vụ và chuyển giao thông tin tiến theo thời gian cho các nhiệm vụ tương lai. Cuối cùng, quan điểm metamodelling có điều kiện nhiệm vụ mà chúng tôi đưa ra là chung chung, vì nó không phụ thuộc vào đặc điểm cụ thể của kiến trúc mạng đích. Chúng tôi khai thác nguyên tắc chính này và chỉ ra rằng chính khung metamodelling tương tự mở rộng đến, và có thể cải thiện, một lớp quan trọng của các phương pháp CL được gọi là phương pháp replay sinh, là những performer tiên tiến hiện tại trong nhiều vấn đề thực tế (Shin et al., 2017; Wu et al., 2018; van de Ven & Tolias, 2018).

2 MÔ HÌNH

2.1 HYPERNETWORK CÓ ĐIỀU KIỆN NHIỆM VỤ

Hypernetwork tham số hóa các mô hình đích. Trung tâm của phương pháp học liên tục của chúng tôi là hypernetwork, Hình 1a. Thay vì học các tham số θ_trgt của một hàm f_trgt cụ thể một cách trực tiếp (mô hình đích), chúng tôi học các tham số θ_h của một metamodel. Đầu ra của metamodel như vậy, hypernetwork, là θ_trgt. Do đó, hypernetwork có thể được coi như các bộ tạo trọng số, ban đầu được giới thiệu để tham số hóa động mô hình trong một dạng nén (Ha et al., 2017; Schmidhuber, 1992; Bertinetto et al., 2016; Jia et al., 2016).

[Mô tả Hình 1: Hypernetwork có điều kiện nhiệm vụ cho học liên tục. (a) Thông thường, các tham số của một mạng nơ-ron được điều chỉnh trực tiếp từ dữ liệu để giải quyết một nhiệm vụ. Ở đây, một bộ tạo trọng số được gọi là hypernetwork được học thay thế. Hypernetwork ánh xạ các vector nhúng tới trọng số, tham số hóa một mạng nơ-ron đích. Trong một tình huống học liên tục, một tập các nhúng cụ thể nhiệm vụ được học thông qua backpropagation. Vector nhúng cung cấp ngữ cảnh phụ thuộc nhiệm vụ và thiên vị hypernetwork tới các giải pháp cụ thể. (b) Một hypernetwork nhỏ hơn, được chunk có thể được sử dụng lặp lại, tạo ra một chunk trọng số mạng đích tại một thời điểm (ví dụ, một lớp tại một thời điểm). Hypernetwork được chunk có thể đạt được nén mô hình: số lượng tham số có thể huấn luyện hiệu quả có thể nhỏ hơn số lượng trọng số mạng đích.]

--- TRANG 2 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2020

Học liên tục với điều chỉnh đầu ra hypernetwork. Một phương pháp để tránh quên thảm khốc là lưu trữ dữ liệu từ các nhiệm vụ trước đó và các đầu ra mô hình tương ứng, và sau đó cố định các đầu ra như vậy. Điều này có thể đạt được bằng cách sử dụng một bộ điều chỉnh đầu ra của dạng sau, trong đó các đầu ra quá khứ đóng vai trò của pseudo-targets (Robins, 1995; Li & Hoiem, 2018; Benjamin et al., 2018):

L_output = Σ^{T-1}_{t=1} Σ^{|X^{(t)}|}_{i=1} ||f(x^{(t,i)};θ) - f(x^{(t,i)};θ̂)||^2; (1)

Trong phương trình trên, θ̂ là tập tham số trước khi cố gắng học nhiệm vụ T, và f là người học. Tuy nhiên, phương pháp này cần lưu trữ và lặp lại trên dữ liệu trước đó, một quá trình được gọi là rehearsing. Điều này có thể tốn kém về mặt bộ nhớ và không thực sự là học trực tuyến. Một cách giải quyết có thể là tạo ra pseudo-targets bằng cách đánh giá f trên các mẫu ngẫu nhiên (Robins, 1995) hoặc trên bộ dữ liệu nhiệm vụ hiện tại (Li & Hoiem, 2018). Tuy nhiên, điều này không nhất thiết cố định hành vi của hàm f trong các vùng quan tâm.

Hypernetwork khắc phục vấn đề này một cách tự nhiên. Trong không gian trọng số mạng đích, một điểm duy nhất (tức là, một tập trọng số) phải được cố định cho mỗi nhiệm vụ. Điều này có thể đạt được một cách hiệu quả với hypernetwork có điều kiện nhiệm vụ, bằng cách cố định đầu ra hypernetwork trên nhúng nhiệm vụ thích hợp.

Tương tự như Benjamin et al. (2018), chúng tôi sử dụng một quy trình tối ưu hóa hai bước để giới thiệu các ràng buộc đầu ra hypernetwork bảo tồn ký ức. Đầu tiên, chúng tôi tính toán một thay đổi ứng cử viên Δθ_h mà tối thiểu hóa mất mát nhiệm vụ hiện tại L^{(T)}_{task} = L_{task}(θ_h; e^{(T)}; X^{(T)}; Y^{(T)}) đối với θ_h. Ứng cử viên Δθ_h được thu được bằng một bộ tối ưu hóa tùy chọn (chúng tôi sử dụng Adam xuyên suốt; Kingma & Ba, 2015). Thay đổi tham số thực tế sau đó được tính toán bằng cách tối thiểu hóa mất mát tổng sau:

L_{total} = L_{task}(θ_h; e^{(T)}; X^{(T)}; Y^{(T)}) + L_{output}(θ̂_h; θ_h; Δθ_h; {e^{(t)}})
= L_{task}(θ_h; e^{(T)}; X^{(T)}; Y^{(T)}) + β_{output}/T-1 Σ^{T-1}_{t=1} ||f_h(e^{(t)}; θ̂_h) - f_h(e^{(t)}; θ_h + Δθ_h)||^2; (2)

trong đó θ̂_h là tập tham số hypernetwork trước khi cố gắng học nhiệm vụ T, θ_h được coi là cố định và β_{output} là một siêu tham số điều khiển cường độ của bộ điều chỉnh. Trong Phụ lục D, chúng tôi chạy một phân tích độ nhạy trên β_{output} và thí nghiệm với một bộ điều chỉnh ngẫu nhiên hiệu quả hơn nơi việc tính trung bình được thực hiện trên một tập con ngẫu nhiên của các nhiệm vụ quá khứ.

Các thuật toán tốn kém tính toán hơn liên quan đến việc tinh chỉnh vòng lặp trong đầy đủ, hoặc sử dụng thông tin gradient bậc hai bằng cách backpropagation thông qua Δθ_h có thể được áp dụng. Tuy nhiên, chúng tôi thấy thực nghiệm rằng sự hiệu chỉnh một bước của chúng tôi hoạt động tốt. Quét siêu tham số khám phá tiết lộ rằng việc bao gồm lookahead θ_h trong (2) mang lại một sự gia tăng hiệu suất nhỏ, ngay cả khi được tính toán bằng một quy trình một bước rẻ. Lưu ý rằng không giống như trong Phương trình 1, thuật ngữ bảo tồn ký ức L_{output} không phụ thuộc vào dữ liệu quá khứ. Ký ức của các nhiệm vụ trước đó chỉ đi vào thông qua bộ sưu tập các nhúng nhiệm vụ {e^{(t)}}^{T-1}_{t=1}.

Nhúng nhiệm vụ được học. Nhúng nhiệm vụ là các tham số xác định có thể vi phân có thể được học, giống như θ_h. Tại mỗi bước học của thuật toán của chúng tôi, chúng tôi cũng cập nhật nhúng nhiệm vụ hiện tại e^{(T)} để tối thiểu hóa mất mát nhiệm vụ L^{(T)}_{task}. Sau khi học nhiệm vụ, nhúng cuối cùng được lưu và thêm vào bộ sưu tập {e^{(t)}}.

2.2 NÉN MÔ HÌNH VỚI HYPERNETWORK ĐƯỢC CHUNK

Chunking. Trong một triển khai đơn giản, một hypernetwork tạo ra toàn bộ tập trọng số của một mạng nơ-ron đích. Đối với các mạng nơ-ron sâu hiện đại, đây là một đầu ra có chiều rất cao. Tuy nhiên, hypernetwork có thể được gọi lặp lại, chỉ điền một phần của mô hình đích tại mỗi bước, trong các chunk (Ha et al., 2017; Pawlowski et al., 2017). Chiến lược này cho phép áp dụng các hypernetwork nhỏ hơn có thể tái sử dụng. Thú vị là, với hypernetwork được chunk, có thể giải quyết các nhiệm vụ trong chế độ nén, nơi số lượng tham số đã học (của hypernetwork) nhỏ hơn một cách hiệu quả so với số lượng tham số mạng đích.

Nhúng chunk và phân vùng mạng. Áp dụng lại cùng một hypernetwork nhiều lần giới thiệu việc chia sẻ trọng số giữa các phân vùng của mạng đích, điều này thường không mong muốn. Để cho phép tham số hóa linh hoạt của mạng đích, chúng tôi giới thiệu một tập C = {c_i}^{N_C}_{i=1} của các nhúng chunk, được sử dụng như một đầu vào bổ sung cho hypernetwork, Hình 1b. Như vậy, tập đầy đủ các tham số mạng đích θ_{trgt} = [f_h(e; c_1); ...; f_h(e; c_{N_C})] được tạo ra bằng cách lặp lại trên C, giữ nhúng nhiệm vụ e cố định. Bằng cách này, hypernetwork có thể tạo ra các trọng số riêng biệt cho mỗi chunk. Hơn nữa, nhúng chunk, giống như nhúng nhiệm vụ, là các tham số xác định thông thường mà chúng tôi học thông qua backpropagation. Để đơn giản, chúng tôi sử dụng một tập nhúng chunk được chia sẻ cho tất cả các nhiệm vụ và chúng tôi không khám phá các chiến lược phân vùng mạng đích đặc biệt.

Phương pháp của chúng tôi linh hoạt như thế nào? Mạng nơ-ron được chunk về nguyên tắc có thể xấp xỉ bất kỳ cấu hình trọng số đích nào một cách tùy ý tốt. Để hoàn thiện, chúng tôi phát biểu điều này một cách chính thức trong Phụ lục E.

2.3 SUY LUẬN KHÔNG NGỮ CẢNH: DANH TÍNH NHIỆM VỤ KHÔNG BIẾT

Xác định nhiệm vụ nào cần giải quyết từ dữ liệu đầu vào. Hypernetwork của chúng tôi cần một đầu vào nhúng nhiệm vụ để tạo ra trọng số mô hình đích. Trong một số ứng dụng CL, một nhúng thích hợp có thể được lựa chọn ngay lập tức vì danh tính nhiệm vụ là rõ ràng, hoặc có thể được suy ra dễ dàng từ các manh mối ngữ cảnh. Trong các trường hợp khác, kiến thức về nhiệm vụ không được cung cấp một cách rõ ràng trong quá trình suy luận.

Trong phần sau, chúng tôi chỉ ra rằng khung metamodelling của chúng tôi khái quát hóa cho những tình huống như vậy. Cụ thể, chúng tôi xem xét vấn đề suy luận nhiệm vụ nào cần giải quyết từ một mẫu đầu vào nhất định, một thách thức điểm chuẩn được chú ý (Farquhar & Gal, 2018; van de Ven & Tolias, 2019). Dưới đây, chúng tôi khám phá hai chiến lược khác nhau tận dụng hypernetwork có điều kiện nhiệm vụ trong môi trường CL này.

Không chắc chắn dự đoán phụ thuộc nhiệm vụ. Các mô hình mạng nơ-ron ngày càng đáng tin cậy trong việc báo hiệu tính mới và xử lý dữ liệu ngoài phân phối một cách thích hợp. Đối với các phân phối đích phân loại, mạng lý tưởng tạo ra một đầu ra phẳng, entropy cao cho dữ liệu chưa thấy và, ngược lại, một phản ứng nhọn, entropy thấp cho dữ liệu trong phân phối (Hendrycks & Gimpel, 2016; Liang et al., 2017). Điều này gợi ý một phương pháp đầu tiên, đơn giản cho suy luận nhiệm vụ (HNET+ENT). Cho một mẫu đầu vào mà danh tính nhiệm vụ không biết, chúng tôi chọn nhúng nhiệm vụ mang lại không chắc chắn dự đoán thấp nhất, được định lượng bởi entropy phân phối đầu ra. Mặc dù phương pháp này dựa vào phát hiện tính mới chính xác, bản thân nó là một vấn đề nghiên cứu chưa được giải quyết, nó thì đơn giản để thực hiện và không cần học bổ sung hoặc mô hình nào để suy luận danh tính nhiệm vụ.

Replay tổng hợp được bảo vệ bởi hypernetwork. Khi một mô hình sinh có sẵn, quên thảm khốc có thể được khắc phục bằng cách trộn dữ liệu nhiệm vụ hiện tại với dữ liệu tổng hợp quá khứ được replay (cho công việc gần đây xem Shin et al., 2017; Wu et al., 2018). Bên cạnh việc bảo vệ chính mô hình sinh, dữ liệu tổng hợp có thể bảo vệ một mô hình khác quan tâm, ví dụ, một mô hình phân biệt khác. Chiến lược đơn giản về mặt khái niệm này trong thực tế thường là giải pháp tiên tiến cho CL (van de Ven & Tolias, 2019). Được truyền cảm hứng bởi những thành công này, chúng tôi khám phá việc tăng cường hệ thống của mình bằng một mạng replay, ở đây là một variational autoencoder tiêu chuẩn (VAE; Kingma & Welling, 2014) (nhưng xem Phụ lục F cho các thí nghiệm với một generative adversarial network, Goodfellow et al., 2014).

Replay tổng hợp là một cơ chế CL mạnh mẽ, nhưng không hoàn hảo vì mô hình sinh chịu sự trôi dạt, và các lỗi có xu hướng tích lũy và khuếch đại theo thời gian. Ở đây, chúng tôi dựa trên quan sát chính sau: giống như mạng đích, bộ tạo của mô hình replay có thể được xác định bởi một hypernetwork. Điều này cho phép bảo vệ nó bằng bộ điều chỉnh đầu ra, Phương trình 2, thay vì với dữ liệu replay của chính mô hình, như đã thực hiện trong công việc liên quan. Như vậy, trong phương pháp kết hợp này, cả replay tổng hợp và metamodelling có điều kiện nhiệm vụ đều hoạt động song song để giảm quên.

Chúng tôi khám phá replay được bảo vệ bởi hypernetwork trong hai thiết lập riêng biệt. Đầu tiên, chúng tôi xem xét một kiến trúc tối thiểu (HNET+R), nơi chỉ mô hình replay, và không phải bộ phân loại đích, được tham số hóa bởi một hypernetwork. Ở đây, quên trong mạng đích được khắc phục bằng cách trộn dữ liệu hiện tại với dữ liệu tổng hợp. Các giá trị đầu ra đích tổng hợp cho các nhiệm vụ trước đó được tạo ra bằng cách sử dụng một phương pháp mục tiêu mềm, tức là bằng cách đơn giản đánh giá hàm đích trước khi học nhiệm vụ mới trên dữ liệu đầu vào tổng hợp. Thứ hai (HNET+TIR), chúng tôi giới thiệu một bộ phân loại suy luận nhiệm vụ phụ trợ, được bảo vệ bằng dữ liệu replay tổng hợp và được huấn luyện để dự đoán danh tính nhiệm vụ từ các mẫu đầu vào. Kiến trúc này cần mô hình hóa bổ sung, nhưng nó có khả năng hoạt động tốt khi các nhiệm vụ khác nhau mạnh mẽ. Hơn nữa, hệ thống con suy luận nhiệm vụ có thể được áp dụng dễ dàng để xử lý các dạng thông tin ngữ cảnh tổng quát hơn, ngoài mẫu đầu vào hiện tại. Chúng tôi cung cấp chi tiết bổ sung, bao gồm kiến trúc mạng và các hàm mất mát được tối ưu hóa, trong Phụ lục B và C.

--- TRANG 3 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2020

3 KẾT QUẢ
Chúng tôi đánh giá phương pháp của mình trên một tập các điểm chuẩn phân loại hình ảnh tiêu chuẩn trên các bộ dữ liệu công cộng MNIST, CIFAR-10 và CIFAR-100. Mục tiêu chính của chúng tôi là (1) nghiên cứu khả năng lưu giữ ký ức của hypernetwork có điều kiện nhiệm vụ trong ba môi trường học liên tục, và (2) điều tra chuyển giao thông tin qua các nhiệm vụ được học tuần tự.

Các tình huống học liên tục. Trong các thí nghiệm của chúng tôi, chúng tôi xem xét ba tình huống CL khác nhau (van de Ven & Tolias, 2019). Trong CL1, danh tính nhiệm vụ được cung cấp cho hệ thống. Đây có thể nói là tình huống học tuần tự tiêu chuẩn, và là tình huống chúng tôi xem xét trừ khi có ghi chú khác. Trong CL2, danh tính nhiệm vụ không được biết đến bởi hệ thống, nhưng nó không cần được xác định một cách rõ ràng. Một mạng đích với một head cố định được yêu cầu để giải quyết nhiều nhiệm vụ. Trong CL3, danh tính nhiệm vụ phải được suy luận một cách rõ ràng. Đã được lập luận rằng tình huống này là tự nhiên nhất, và là tình huống có xu hướng khó khăn hơn đối với mạng nơ-ron (Farquhar & Gal, 2018; van de Ven & Tolias, 2019).

Chi tiết thí nghiệm. Nhằm mục đích so sánh, cho các thí nghiệm trên bộ dữ liệu MNIST, chúng tôi mô hình hóa mạng đích như một mạng kết nối đầy đủ và thiết lập tất cả các siêu tham số theo van de Ven & Tolias (2019), những người gần đây đã xem xét và so sánh một tập lớn các thuật toán CL. Cho các thí nghiệm CIFAR của chúng tôi, chúng tôi chọn một mạng nơ-ron đích ResNet-32 (He et al., 2016) để đánh giá tính mở rộng của phương pháp chúng tôi. Một mô tả tóm tắt về kiến trúc và lựa chọn siêu tham số cụ thể, cũng như chi tiết thí nghiệm bổ sung, được cung cấp trong Phụ lục C. Chúng tôi nhấn mạnh rằng, trên tất cả các thí nghiệm của chúng tôi, số lượng tham số hypernetwork luôn nhỏ hơn hoặc bằng số lượng tham số của các mô hình mà chúng tôi so sánh.

[Mô tả Hình 2: Hồi quy phi tuyến 1D. (a) Hypernetwork có điều kiện nhiệm vụ với điều chỉnh đầu ra có thể dễ dàng mô hình hóa một chuỗi đa thức có độ tăng dần, trong khi học một cách liên tục. (b) Giải pháp được tìm thấy bởi một mạng đích được huấn luyện trực tiếp trên tất cả các nhiệm vụ đồng thời là tương tự. (c) Fine-tuning, tức là học tuần tự, dẫn đến quên các nhiệm vụ quá khứ. Các đường gạch ngang mô tả sự thật cơ bản, các dấu hiệu hiển thị dự đoán mô hình.]

Vấn đề đồ chơi hồi quy phi tuyến. Để minh họa phương pháp của chúng tôi, đầu tiên chúng tôi xem xét một vấn đề hồi quy phi tuyến đơn giản, nơi hàm cần xấp xỉ là có giá trị vô hướng, Hình 2. Ở đây, một chuỗi các hàm đa thức có độ tăng dần phải được suy luận từ dữ liệu nhiễu. Điều này thúc đẩy vấn đề học liên tục: khi học từng nhiệm vụ liên tiếp bằng cách sửa đổi θ_h với bộ điều chỉnh bảo tồn ký ức được tắt (β_{output} = 0, xem Phương trình 2), mạng học nhiệm vụ cuối cùng nhưng quên những cái trước đó, Hình 2c. Bộ điều chỉnh bảo vệ các giải pháp cũ, Hình 2a, và hiệu suất có thể so sánh với một người học offline không liên tục, Hình 2b.

Điểm chuẩn permuted MNIST. Tiếp theo, chúng tôi nghiên cứu điểm chuẩn permuted MNIST. Vấn đề này được thiết lập như sau. Đầu tiên, người học được trình bày với bộ dữ liệu MNIST đầy đủ. Tiếp theo, các nhiệm vụ mới được thu được bằng cách áp dụng một hoán vị ngẫu nhiên cho các pixel hình ảnh đầu vào. Quá trình này có thể được lặp lại để tạo ra một chuỗi nhiệm vụ dài, với độ dài điển hình là T = 10 nhiệm vụ. Cho tính tương đồng thấp của các nhiệm vụ được tạo ra, permuted MNIST phù hợp để nghiên cứu khả năng ký ức của một người học liên tục. Cho T = 10, chúng tôi thấy rằng hypernetwork có điều kiện nhiệm vụ là tiên tiến trên CL1, Bảng 1. Thú vị là, suy luận nhiệm vụ thông qua entropy phân phối dự đoán (HNET+ENT) hoạt động tốt trên điểm chuẩn permuted MNIST. Mặc dù tính đơn giản của phương pháp, cả synaptic intelligence (SI; Zenke et al., 2017) và online elastic weight consolidation (EWC; Schwarz et al., 2018) đều được vượt qua trên CL3 bởi một biên lớn. Khi được bổ sung bằng replay sinh

[Bảng 1: Độ chính xác kiểm tra trung bình theo nhiệm vụ (± SEM, n = 20) trên các thí nghiệm MNIST permuted ('P10') và split ('S'). Trong bảng, EWC đề cập đến online EWC và DGR đề cập đến DGR+distill (kết quả được tái tạo từ van de Ven & Tolias, 2019). Chúng tôi đã kiểm tra ba mô hình dựa trên hypernetwork: cho HNET+ENT (chỉ HNET cho CL1), chúng tôi suy luận danh tính nhiệm vụ dựa trên entropy của phân phối dự đoán; cho HNET+TIR, chúng tôi huấn luyện một mạng recognition-replay được bảo vệ bởi hypernetwork (dựa trên VAE, cf. Hình A1) để suy luận nhiệm vụ từ các mẫu đầu vào; cho HNET+R, bộ phân loại chính được huấn luyện bằng cách trộn dữ liệu nhiệm vụ hiện tại với dữ liệu tổng hợp được tạo ra từ một VAE được bảo vệ bởi hypernetwork.]

phương pháp, hypernetwork có điều kiện nhiệm vụ (HNET+TIR và HNET+R) là những performer tốt nhất trên tất cả ba tình huống CL.

Sự khác biệt về hiệu suất trở nên lớn hơn trong giới hạn chuỗi dài, Hình 3a. Cho các chuỗi nhiệm vụ dài hơn (T = 100), SI và DGR+distill (Shin et al., 2017; van de Ven & Tolias, 2018) giảm một cách nhẹ nhàng, trong khi cường độ điều chỉnh của online EWC ngăn phương pháp đạt được độ chính xác cao (xem Hình A6 cho một tìm kiếm siêu tham số trên công việc liên quan). Đáng chú ý, hypernetwork có điều kiện nhiệm vụ cho thấy sự suy giảm ký ức tối thiểu và tìm các giải pháp hiệu suất cao. Bởi vì hypernetwork hoạt động trong chế độ nén (xem Hình 3b và Hình A7 cho một khám phá tỷ lệ nén), kết quả của chúng tôi không phụ thuộc một cách ngây thơ vào sự gia tăng số lượng tham số. Thay vào đó, chúng gợi ý rằng các phương pháp trước đó chưa có khả năng tận dụng đầy đủ khả năng mô hình đích trong môi trường CL. Chúng tôi báo cáo một tập kết quả mở rộng trên điểm chuẩn này trong Phụ lục D, bao gồm một nghiên cứu về CL2/3 (T = 100), nơi HNET+TIR vượt trội mạnh mẽ so với công việc liên quan.

[Hình 3: Các thí nghiệm trên điểm chuẩn permuted MNIST. (a) Độ chính xác phân loại tập kiểm tra cuối cùng trên nhiệm vụ thứ t sau khi học một trăm hoán vị (PermutedMNIST-100). Hypernetwork có điều kiện nhiệm vụ (hnet, màu đỏ) đạt được thời gian sống ký ức rất lớn trên điểm chuẩn permuted MNIST. Synaptic intelligence (SI, màu xanh dương; Zenke et al., 2017), online EWC (màu cam; Schwarz et al., 2018) và các phương pháp deep generative replay (DGR+distill, màu xanh lá cây; Shin et al., 2017) được hiển thị để so sánh. Lưu giữ ký ức trong SI và DGR+distill giảm một cách nhẹ nhàng, trong khi EWC bị tính cứng nhắc và không bao giờ có thể đạt được độ chính xác rất cao, mặc dù ký ức vẫn tồn tại trong toàn bộ thời gian thí nghiệm. (b) Tỷ lệ nén |θ_h ∪ {e^{(t)}}| / |θ_{trgt}| so với độ chính xác tập kiểm tra trung bình theo nhiệm vụ sau khi học tất cả các nhiệm vụ (được ghi nhãn 'cuối cùng', màu đỏ) và ngay lập tức sau khi học một nhiệm vụ (được ghi nhãn 'trong quá trình', màu tím) cho điểm chuẩn PermutedMNIST-10. Hypernetwork cho phép nén mô hình và thực hiện tốt ngay cả khi số lượng tham số mô hình đích vượt quá của chúng. Hiệu suất giảm phi tuyến: độ chính xác giữ gần như không đổi cho một phạm vi rộng của tỷ lệ nén dưới đơn vị. Siêu tham số được điều chỉnh một lần cho tỷ lệ nén 1 và sau đó được sử dụng cho tất cả các tỷ lệ nén. Các vùng tô màu biểu thị STD (a) hoặc SEM (b) trên 5 hạt giống ngẫu nhiên.]

Điểm chuẩn split MNIST. Split MNIST là một điểm chuẩn CL phổ biến khác, được thiết kế để giới thiệu sự chồng chéo nhiệm vụ. Trong vấn đề này, các chữ số khác nhau được ghép nối tuần tự và được sử dụng để tạo thành năm nhiệm vụ phân loại nhị phân. Ở đây, chúng tôi thấy rằng hypernetwork có điều kiện nhiệm vụ là những performer tốt nhất tổng thể. Cụ thể, HNET+R cải thiện phương pháp tiên tiến trước đó DGR+distill trên cả CL2 và CL3, gần như bão hòa giới hạn trên CL2 cho các mô hình replay (Phụ lục D). Vì HNET+R về cơ bản là DGR được bảo vệ bởi hypernetwork, những kết quả này chứng minh tính tổng quát của hypernetwork có điều kiện nhiệm vụ như những bộ bảo vệ ký ức hiệu quả. Để hỗ trợ thêm điều này, trong Phụ lục F chúng tôi cho thấy rằng các mô hình replay của chúng tôi (chúng tôi thí nghiệm với cả VAE và GAN) có thể học theo cách tăng dần lớp toàn bộ bộ dữ liệu MNIST. Cuối cùng, HNET+ENT một lần nữa vượt trội so với cả EWC và SI, mà không có bất kỳ mô hình hóa sinh nào.

Trên vấn đề split MNIST, các nhiệm vụ chồng chéo và do đó những người học liên tục có thể chuyển giao thông tin qua các nhiệm vụ. Để phân tích những hiệu ứng như vậy, chúng tôi nghiên cứu hypernetwork có điều kiện nhiệm vụ với không gian nhúng nhiệm vụ hai chiều, có thể được hình dung dễ dàng. Mặc dù việc học diễn ra liên tục, chúng tôi

[Hình 4: Không gian nhúng nhiệm vụ hai chiều cho điểm chuẩn split MNIST. Độ chính xác phân loại tập kiểm tra được mã hóa màu sau khi học năm split, được hiển thị khi các thành phần vector nhúng được thay đổi. Các dấu hiệu biểu thị vị trí của các nhúng nhiệm vụ cuối cùng. (a) Hiệu suất phân loại cao với thực tế không có quên được đạt được ngay cả khi không gian e là chiều thấp. Mô hình cho thấy chuyển giao thông tin trong không gian nhúng: nhiệm vụ đầu tiên được giải quyết trong một khối lượng lớn bao gồm các nhúng cho các nhiệm vụ được học sau đó. (b) Cạnh tranh trong không gian nhúng: nhiệm vụ cuối cùng chiếm một vùng hiệu suất cao hữu hạn, với sự suy giảm nhẹ nhàng xa khỏi vector nhúng. Các nhúng nhiệm vụ đã học trước đó vẫn dẫn đến hiệu suất vừa phải, trên mức ngẫu nhiên.]

thấy rằng thuật toán hội tụ đến một cấu hình hypernetwork có thể tạo ra các tham số mô hình đích giải quyết đồng thời cả nhiệm vụ cũ và mới, Hình 4, cho nhúng nhiệm vụ thích hợp.

Điểm chuẩn split CIFAR-10/100. Cuối cùng, chúng tôi nghiên cứu một điểm chuẩn thử thách hơn, nơi người học đầu tiên được yêu cầu giải quyết nhiệm vụ phân loại CIFAR-10 đầy đủ và sau đó được trình bày với các tập mười lớp từ bộ dữ liệu CIFAR-100. Chúng tôi thực hiện thí nghiệm cả với kiến trúc mạng đích ResNet-32 hiệu suất cao (Hình 5) và với một mô hình nông hơn (Hình A3) mà chúng tôi tái tạo chính xác từ công việc trước đó (Zenke et al., 2017). Đáng chú ý, trên mô hình ResNet-32, chúng tôi thấy rằng hypernetwork có điều kiện nhiệm vụ về cơ bản loại bỏ hoàn toàn quên lãng. Hơn nữa, chuyển giao thông tin tiến diễn ra; kiến thức từ các nhiệm vụ trước đó cho phép mạng tìm các giải pháp tốt hơn so với khi học từng nhiệm vụ riêng lẻ từ điều kiện ban đầu. Thú vị là, chuyển giao tiến mạnh hơn trên các thí nghiệm mô hình nông (Hình A3), nơi chúng tôi khác thấy rằng phương pháp của chúng tôi thực hiện tương đương với SI.

[Hình 5: Điểm chuẩn split CIFAR-10/100 CL. Độ chính xác tập kiểm tra (mean ± STD, n = 5) trên toàn bộ bộ dữ liệu CIFAR-10 và các split CIFAR-100 tiếp theo của mười lớp. ResNet-32 được bảo vệ bởi hypernetwork của chúng tôi hiển thị thực tế không có quên; hiệu suất trung bình cuối cùng (hnet, màu đỏ) phù hợp với hiệu suất ngay lập tức (hnet-during, màu xanh dương). Hơn nữa, thông tin được chuyển giao qua các nhiệm vụ, vì hiệu suất cao hơn so với khi huấn luyện từng nhiệm vụ từ đầu (màu tím). Vô hiệu hóa bộ điều chỉnh của chúng tôi dẫn đến quên mạnh (màu vàng).]

4 THẢO LUẬN

Các giải thích Bayesian của học liên tục. Theo quan điểm CL Bayesian tiêu chuẩn, một phân phối tham số hậu nghiệm được cập nhật đệ quy bằng cách sử dụng quy tắc Bayes khi các nhiệm vụ đến

(Kirkpatrick et al., 2017; Huszár, 2018; Nguyen et al., 2018). Mặc dù phương pháp này về mặt lý thuyết là đúng đắn, trong thực tế, các phương pháp suy luận xấp xỉ thường được ưa chuộng có thể dẫn đến các mô hình cứng nhắc, vì một giải pháp thỏa hiệp phù hợp với tất cả các nhiệm vụ phải được tìm thấy trong chế độ được xác định bởi nhiệm vụ đầu tiên. Hạn chế như vậy không áp dụng cho hypernetwork, có thể về nguyên tắc mô hình hóa các phân phối đa phương thức phức tạp (Louizos & Welling, 2017; Pawlowski et al., 2017; Henning et al., 2018). Như vậy, các prior phong phú, được mô hình hóa bởi hypernetwork là một con đường cải thiện cho các phương pháp CL Bayesian. Thú vị là, điều kiện nhiệm vụ cung cấp một khả năng thay thế: thay vì hợp nhất mọi nhiệm vụ vào một phân phối duy nhất, một hypernetwork có điều kiện nhiệm vụ được chia sẻ có thể được tận dụng để mô hình hóa một tập các phân phối hậu nghiệm tham số. Metamodel có điều kiện này mở rộng một cách tự nhiên khung của chúng tôi đến môi trường học Bayesian. Phương pháp như vậy có thể sẽ hưởng lợi từ tính linh hoạt bổ sung, so với cập nhật Bayesian đệ quy thông thường.

Các phương pháp liên quan dựa vào điều kiện nhiệm vụ. Mô hình của chúng tôi phù hợp với, và trong một số cách khái quát hóa, các phương pháp CL trước đó điều kiện tính toán mạng trên các mô tả nhiệm vụ. Điều kiện nhiệm vụ thường được thực hiện bằng cách sử dụng các mặt nạ nhân tại mức mô-đun (Rusu et al., 2016; Fernando et al., 2017), nơ-ron (Serra et al., 2018; Masse et al., 2018) hoặc trọng số (Mallya & Lazebnik, 2018). Các phương pháp như vậy hoạt động tốt nhất với các mạng lớn và đi kèm với một chi phí lưu trữ đáng kể, thường tỷ lệ với số lượng nhiệm vụ. Phương pháp của chúng tôi khác biệt bằng cách mô hình hóa rõ ràng không gian tham số đầy đủ bằng cách sử dụng một metamodel, hypernetwork. Nhờ metamodel này, khái quát hóa trong không gian tham số và nhiệm vụ là có thể, và các phụ thuộc nhiệm vụ-nhiệm vụ có thể được khai thác để biểu diễn các giải pháp một cách hiệu quả và chuyển giao kiến thức hiện tại cho các vấn đề tương lai. Thú vị là, những lập luận tương tự đã được đưa ra trong công việc được phát triển đồng thời với chúng tôi (Lampinen & McClelland, 2019), nơi các không gian nhúng nhiệm vụ được khám phá thêm trong bối cảnh học few-shot. Theo cùng một tinh thần, và giống như phương pháp được phát triển ở đây, công việc gần đây trong CL tạo ra các tham số mạng lớp cuối như một phần của pipeline để tránh quên thảm khốc (Hu et al., 2019) hoặc chưng cất các tham số vào một mô hình auto-encoding co rút (Camp et al., 2018).

Chuyển giao ngược tích cực. Trong dạng hiện tại, bộ điều chỉnh đầu ra hypernetwork bảo vệ các giải pháp đã học trước đó khỏi thay đổi, sao cho chỉ có thể xảy ra chuyển giao ngược thông tin yếu. Cho vai trò của quên lãng chọn lọc và tinh chỉnh ký ức quá khứ trong việc đạt được hành vi thông minh (Brea et al., 2014; Richards & Frankland, 2017), điều tra và cải thiện chuyển giao ngược đứng như một hướng quan trọng cho nghiên cứu tương lai.

Liên quan đến khoa học thần kinh hệ thống. Khám phá các cơ chế hỗ trợ học liên tục trong cả bộ não và mạng nơ-ron nhân tạo là một câu hỏi lâu dài (McCloskey & Cohen, 1989; French, 1999; Parisi et al., 2019). Chúng tôi kết thúc với một diễn giải hệ thống suy đoán (Kumaran et al., 2016; Hassabis et al., 2017) về công việc của chúng tôi như một mô hình cho các tín hiệu điều biến từ trên xuống trong vỏ não. Nhúng nhiệm vụ có thể được xem như các chuyển đổi ngữ cảnh chiều thấp, xác định hành vi của một hệ thống điều biến, hypernetwork trong trường hợp của chúng tôi. Theo mô hình của chúng tôi, hypernetwork sẽ điều chỉnh hoạt động của một mạng vỏ não đích.

Như hiện tại, việc thực hiện một hypernetwork sẽ đòi hỏi thay đổi động toàn bộ kết nối của một mạng đích, hoặc vùng vỏ não. Một quá trình như vậy có vẻ khó hình dung trong bộ não. Tuy nhiên, diễn giải nghiêm ngặt theo nghĩa đen này có thể được nới lỏng. Ví dụ, một hypernetwork có thể xuất ra các tín hiệu điều biến chiều thấp hơn (Marder, 2012), thay vì một tập trọng số đầy đủ. Diễn giải này phù hợp với một khối lượng công việc ngày càng tăng gợi ý sự tham gia của các đầu vào điều biến trong việc thực hiện chuyển đổi chế độ mạng phụ thuộc ngữ cảnh hoặc nhiệm vụ (Mante et al., 2013; Jaeger, 2014; Stroud et al., 2018; Masse et al., 2018).

5 KẾT LUẬN

Chúng tôi giới thiệu một mô hình mạng nơ-ron mới, hypernetwork có điều kiện nhiệm vụ, phù hợp với các vấn đề CL. Một hypernetwork có điều kiện nhiệm vụ là một metamodel học tham số hóa các hàm đích, được chỉ định và nhận dạng trong một dạng nén sử dụng một vector nhúng nhiệm vụ. Các nhiệm vụ quá khứ được giữ trong ký ức sử dụng một bộ điều chỉnh đầu ra hypernetwork, phạt các thay đổi trong các cấu hình trọng số đích đã tìm thấy trước đó. Phương pháp này có thể mở rộng và chung chung, có thể áp dụng như một phương pháp CL độc lập hoặc kết hợp với replay sinh. Kết quả của chúng tôi là tiên tiến trên các điểm chuẩn tiêu chuẩn và gợi ý rằng hypernetwork có điều kiện nhiệm vụ có thể đạt được thời gian sống ký ức dài, cũng như chuyển giao thông tin cho các nhiệm vụ tương lai, hai đặc tính thiết yếu của một người học liên tục.

LỜI CẢM ƠN

Công việc này được hỗ trợ bởi Swiss National Science Foundation (B.F.G. CRSII5-173721), tài trợ dự án ETH (B.F.G. ETH-20 19-01) và tài trợ từ Swiss Data Science Center (B.F.G, C17-18, J. v. O. P18-03). Cảm ơn đặc biệt tới Simone Carlo Surace, Adrian Huber, Xu He, Markus Marks, Maria R. Cervera và Jannes Jegminat cho các thảo luận, gợi ý hữu ích về tài liệu CL và phản hồi về bản thảo bài báo của chúng tôi.

TÀI LIỆU THAM KHẢO

[Các tài liệu tham khảo được liệt kê từ trang 9-12]

PHỤ LỤC A: HYPERNETWORK CÓ ĐIỀU KIỆN NHIỆM VỤ: TÓM TẮT MÔ HÌNH

Trong mô hình của chúng tôi, một hypernetwork có điều kiện nhiệm vụ tạo ra các tham số θ_{trgt} = f_h(e; θ_h) của một mạng nơ-ron đích. Cho một tham số hóa như vậy, mô hình đích sau đó tính toán các dự đoán ŷ = f_{trgt}(x; θ_{trgt}) dựa trên dữ liệu đầu vào. Học tương đương với việc điều chỉnh các tham số θ_h của hypernetwork, bao gồm một tập các nhúng nhiệm vụ {e^{(t)}}^T_{t=1}, cũng như một tập các nhúng chunk {c_i}^{N_C}_{i=1} trong trường hợp tìm kiếm nén hoặc nếu hypernetwork đầy đủ quá lớn để xử lý trực tiếp. Để tránh quên thảm khốc, chúng tôi giới thiệu một bộ điều chỉnh đầu ra cố định hành vi của hypernetwork bằng cách phạt các thay đổi trong các tham số mô hình đích được tạo ra cho các nhiệm vụ đã học trước đó.

Các biến cần được lưu trữ khi học các nhiệm vụ mới. Yêu cầu lưu trữ của mô hình chúng tôi là gì, khi học liên tục?

1. Lưu giữ ký ức dựa vào việc lưu một nhúng cho mỗi nhiệm vụ. Bộ sưu tập {e^{(t)}}^T_{t=1} này do đó tăng tuyến tính với T. Việc tỷ lệ tuyến tính như vậy là không mong muốn về mặt tiệm cận, nhưng hóa ra lại cơ bản là không đáng kể trong thực tế, vì mỗi nhúng là một vector chiều thấp duy nhất (ví dụ, xem Hình 4 cho một run với nhúng 2D).

2. Một snapshot đông lạnh của các tham số hypernetwork θ̂_h, được lấy trước khi học một nhiệm vụ mới, cần được giữ, để đánh giá bộ điều chỉnh đầu ra trong Phương trình 2.

[Các phần tiếp theo của phụ lục tiếp tục với chi tiết bổ sung về mô hình replay được bảo vệ bởi hypernetwork, chi tiết thí nghiệm bổ sung, và các thí nghiệm và ghi chú bổ sung]

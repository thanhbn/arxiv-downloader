# HINT: Phương pháp Hypernetwork để Huấn luyện Vùng Khoảng Trọng số trong Học Liên tục

Patryk Krukowski1 2, Anna Bielawska2, Kamil Ksi ˛ a ˙zek2Paweł Wawrzy ´nski4Paweł Batorski3
Przemysław Spurek2

1IDEAS NCBR
2Trường Đại học Jagiellonian
3Trường Đại học Heinrich Heine Düsseldorf
4Viện IDEAS

patryk.krukowski@ideas-ncbr.pl

## Tóm tắt

Gần đây, một paradigm Học Liên tục (CL) mới đã được trình bày để kiểm soát quên thảm khốc, được gọi là Học Liên tục Khoảng (InterContiNet), dựa trên việc thực thi các ràng buộc khoảng trên không gian tham số mạng nơ-ron. Thật không may, việc huấn luyện InterContiNet rất thách thức do tính chiều cao của không gian trọng số, khiến các khoảng khó quản lý. Để giải quyết vấn đề này, chúng tôi giới thiệu HINT, một kỹ thuật sử dụng phép toán khoảng trong không gian embedding và sử dụng hypernetwork để ánh xạ các khoảng này vào không gian tham số mạng đích. Chúng tôi huấn luyện các embedding khoảng cho các nhiệm vụ liên tiếp và huấn luyện hypernetwork để biến đổi các embedding này thành trọng số của mạng đích. Một embedding cho một nhiệm vụ cụ thể được huấn luyện cùng với hypernetwork, bảo toàn phản hồi của mạng đích cho các embedding nhiệm vụ trước đó. Phép toán khoảng hoạt động với không gian embedding có thể quản lý được, chiều thấp hơn thay vì chuẩn bị trực tiếp các khoảng trong không gian trọng số chiều cao. Mô hình của chúng tôi cho phép huấn luyện nhanh hơn và hiệu quả hơn. Hơn nữa, HINT duy trì đảm bảo không quên. Ở cuối quá trình huấn luyện, chúng ta có thể chọn một embedding phổ quát để tạo ra một mạng duy nhất dành riêng cho tất cả các nhiệm vụ. Trong khung như vậy, hypernetwork chỉ được sử dụng cho huấn luyện và cuối cùng, chúng ta có thể sử dụng một bộ trọng số. HINT đạt được kết quả tốt hơn đáng kể so với InterContiNet và cho kết quả SOTA trên một số benchmark.

## 1 Giới thiệu

Con người có khả năng tự nhiên học từ dòng dữ liệu liên tục, vì dữ liệu thực tế thường được trình bày tuần tự. Con người cần có khả năng học các nhiệm vụ mới trong khi cũng giữ lại và sử dụng kiến thức từ các nhiệm vụ trước đó. Trong khi các mô hình học sâu đã đạt được thành công đáng kể trong nhiều nhiệm vụ riêng lẻ, chúng gặp khó khăn trong khía cạnh này và thường hoạt động kém trên các nhiệm vụ trước đó sau khi học những nhiệm vụ mới, điều này được gọi là quên thảm khốc (McCloskey và Cohen 1989; Ratcliff 1990; French 1999).

Học liên tục (CL) là một lĩnh vực quan trọng của học máy nhằm thu hẹp khoảng cách giữa trí thông minh con người và máy. Trong khi một số phương pháp đã được đề xuất để giảm hiệu quả việc quên khi học các nhiệm vụ mới, chẳng hạn như của Kirkpatrick et al. (2017); Lopez-Paz và Ranzato (2017); Shin et al. (2017); Aljundi et al. (2018); Masse, Grant, và Freedman (2018); Rolnick et al. (2019); van de Ven, Siegelmann, và Tolias (2020), chúng thường không cung cấp bất kỳ đảm bảo vững chắc nào về mức độ mà mô hình trải qua quên lãng.

Trong Học Liên tục Khoảng (InterContiNet) (Wołczyk et al. 2022), các tác giả đề xuất một paradigm mới sử dụng phép toán khoảng trong các tình huống CL. Ý tưởng chính là sử dụng các khoảng để kiểm soát trọng số dành riêng cho các nhiệm vụ tiếp theo. Nhờ phép toán khoảng nghiêm ngặt, những tác giả này có thể ép buộc một mạng đưa ra dự đoán giống nhau cho mỗi trọng số được lấy mẫu từ khoảng. Hơn nữa, họ có thể ép buộc khoảng của nhiệm vụ mới hoàn toàn chứa trong các siêu hình chữ nhật của những nhiệm vụ trước đó. Hai tính chất trên cho phép người ta đạt được các ràng buộc nghiêm ngặt cho việc quên. Mô hình có nền tảng lý thuyết mạnh mẽ và đạt được kết quả tốt trong các nhiệm vụ tăng dần và tình huống domain trên các bộ dữ liệu tương đối nhỏ. Hạn chế chính của InterContiNet là quá trình huấn luyện phức tạp. Để cho phép huấn luyện các nhiệm vụ mới, người ta phải sử dụng các khoảng lớn trong không gian trọng số, được huấn luyện trong một không gian tham số cực kỳ chiều cao. Do đó, mô hình bị hạn chế đối với các kiến trúc đơn giản, bộ dữ liệu và tình huống học liên tục.

Để giải quyết vấn đề như vậy, chúng tôi đề xuất HINT1, tức là một mô hình sử dụng các khoảng trong không gian embedding và một hypernetwork để chuyển chúng vào không gian trọng số của mạng đích, xem Hình 1. Giải pháp như vậy cho phép người ta huấn luyện hiệu quả mạng đích dựa trên khoảng trên các bộ dữ liệu lớn và các tình huống lớp tăng dần khó khăn nhất, vượt qua các hạn chế trước đó của nó. Kiến trúc hypernetwork (Ha, Dai, và Le 2016) được định nghĩa là một mạng nơ-ron tạo ra trọng số cho một mạng đích cụ thể được thiết kế để giải quyết một vấn đề cụ thể. Trong học liên tục, một hypernetwork có thể tạo ra trọng số cho mô hình đích (von Oswald et al. 2019; Henning et al. 2021; Ksi ˛ a ˙zek và Spurek 2023). Phụ thuộc vào định danh nhiệm vụ, các embedding có thể huấn luyện được đưa vào hypernetwork. Sau khi hoàn thành huấn luyện, một meta-model duy nhất có thể tạo ra trọng số cụ thể cho nhiệm vụ. Khả năng tạo ra các trọng số ribiệt cho các nhiệm vụ khác nhau này cho phép các mô hình dựa trên hypernetwork duy trì mất mát kiến thức tối thiểu.

Trong HINT, chúng tôi sử dụng phép toán khoảng trong không gian embedding. Hypernetwork được cung cấp embedding khoảng cụ thể cho nhiệm vụ để tạo ra trọng số cho mạng đích. Kiến trúc của chúng tôi sử dụng một mô hình đích với trọng số khoảng và kỹ thuật Interval Bound Propagation (IBP) (Gowal et al. 2018) trong hypernetwork. Do chiều thấp của các embedding nhiệm vụ, giải pháp này cung cấp tính mạnh mẽ lớn hơn đối với việc quên so với các phương pháp trước đó đối với CL dựa trên phép toán khoảng.

Mô hình của chúng tôi có thể được sử dụng trong học lớp tăng dần trong cả hai tình huống: có và không có định danh nhiệm vụ. Chúng tôi có thể sử dụng tình huống đánh giá được đề xuất bởi các mô hình dựa trên hypernetwork (von Oswald et al. 2019; Henning et al. 2021; Ksi ˛ a ˙zek và Spurek 2023). Đối với các tình huống định danh nhiệm vụ đã biết, chúng tôi sử dụng phép toán khoảng như một kỹ thuật chính quy hóa, và mỗi embedding nhiệm vụ tạo ra trọng số khoảng mạng đích mới dành riêng cho nhiệm vụ này. Chúng tôi cũng có thể sử dụng tiêu chí entropy để xác định định danh lớp khi không biết. Trong cả hai giải pháp, chúng tôi phải nhớ hypernetwork và tất cả các embedding nhiệm vụ. Khung của chúng tôi cho phép chúng tôi tạo ra một embedding phổ quát. Với phép toán khoảng, chúng tôi có thể kiểm soát các khoảng và biến đổi chúng thành các embedding khoảng với giao điểm không rỗng. Ở cuối quá trình huấn luyện, chúng tôi tạo ra mạng đích cuối cùng từ embedding phổ quát được tạo ra từ giao điểm của tất cả các embedding khoảng được huấn luyện trước đó, có thể giải quyết tất cả các nhiệm vụ. Phương pháp như vậy vượt trội đáng kể so với InterContiNet và trong nhiều trường hợp vượt trội so với các phương pháp hiện đại.

Các đóng góp của chúng tôi có thể được tóm tắt như sau:
• Chúng tôi trình bày HINT, sử dụng phép toán khoảng trong không gian embedding và hypernetwork để truyền các khoảng vào không gian trọng số mạng đích.
• Chúng tôi chứng minh rằng mô hình của chúng tôi có thể sử dụng hiệu quả phép toán khoảng trong cài đặt CL với các bộ dữ liệu lớn.
• Chúng tôi chứng minh rằng hypernetwork có thể được sử dụng để tinh chỉnh đệ quy, qua các nhiệm vụ liên tiếp, vùng trọng số mạng đích có hiệu quả phổ quát cho tất cả các nhiệm vụ.

## 2 Các Nghiên cứu Liên quan

**Học liên tục.** Khi một mạng nơ-ron được huấn luyện trên dữ liệu mới, nó thường quên các mẫu đã học từ dữ liệu trước đó, một vấn đề được gọi là quên thảm khốc (French 1999). Các phương pháp học liên tục cho phép mạng học các nhiệm vụ mới mà không mất hiệu suất trên những nhiệm vụ trước đó, ngay cả khi dữ liệu trước đó không còn có sẵn. Các thiết lập khác nhau tồn tại cho học liên tục (van de Ven và Tolias 2019): trong học tăng dần nhiệm vụ, nhiệm vụ được biết trong quá trình suy luận; trong học tăng dần lớp, mạng phải học một phân phối đầu vào-đầu ra nhất quán qua các nhiệm vụ với các phân phối dữ liệu khác nhau.

Các phương pháp rehearsal lưu trữ một đại diện có kích thước hạn chế của các nhiệm vụ trước đó và huấn luyện mạng trên sự kết hợp của các mẫu dữ liệu từ các nhiệm vụ trước đó và hiện tại. Trong thiết lập đơn giản nhất, một bộ đệm bộ nhớ được sử dụng để lưu trữ các mẫu trước đó đã chọn ở dạng thô (Lopez-Paz và Ranzato 2017; Aljundi et al. 2019; Prabhu, Torr, và Dokania 2020) hoặc lưu trữ các mẫu tiêu biểu của các lớp trong thiết lập tăng dần lớp (CIL) (Rebuffi et al. 2017; Chaudhry et al. 2018; Castro et al. 2018; Wu et al. 2019; Hou et al. 2019; Belouadah và Popescu 2019). Một số phương pháp thay vì sử dụng các mẫu dữ liệu thô, lưu trữ các đại diện dữ liệu của các nhiệm vụ trước đó dưới các hình thức khác nhau, ví dụ, các mẫu nhân tạo được tối ưu hóa (Liu et al. 2020), các bộ dữ liệu chưng cất (Wang et al. 2018; Zhao, Mopuri, và Bilen 2021) hoặc các cấu trúc bộ nhớ có thể địa chỉ hóa (Deng và Russakovsky 2022).

Các phương pháp dựa trên bộ đệm đặt ra câu hỏi về tính mở rộng và quyền riêng tư dữ liệu. Để giải quyết những câu hỏi này, các phương pháp rehearsal tạo sinh dựa trên các mô hình tạo sinh tạo ra các mẫu dữ liệu tương tự như những mẫu có trong các nhiệm vụ trước đó, thay vì chỉ phát lại chúng từ lưu trữ. Trong Deep Generative Replay (Shin et al. 2017), một Generative Adversarial Network (GAN) được sử dụng như một mô hình để tạo dữ liệu từ các nhiệm vụ trước đó. Cho cùng mục đích, Variational Autoencoders (VAE) được sử dụng trong (van de Ven và Tolias 2018), Normalizing Flows trong (Nguyen et al. 2018), Gaussian Mixture Models trong (Rostami, Kolouri, và Pilly 2019) và Diffusion Models trong (Cywi ´nski et al. 2024).

Các phương pháp chính quy hóa (Kirkpatrick et al. 2017; Zenke, Poole, và Ganguli 2017; Li và Hoiem 2017) được thiết kế đặc biệt cho thiết lập tăng dần nhiệm vụ (TIL). Chúng xác định các trọng số nơ-ron có tác động lớn nhất đến hiệu suất nhiệm vụ và làm chậm việc học của chúng trong các nhiệm vụ tiếp theo thông qua chính quy hóa.

Các phương pháp kiến trúc (Rusu et al. 2016; Yoon et al. 2018; Mallya và Lazebnik 2018; Mallya, Davis, và Lazebnik 2018; Wortsman et al. 2020) được thiết kế đặc biệt cho thiết lập TIL. Chúng điều chỉnh cấu trúc của mô hình cho mỗi nhiệm vụ.

Wołczyk et al. (2022) đã giới thiệu thuật toán InterContiNet. Đối với mỗi nhiệm vụ, phương pháp này xác định một vùng trong không gian trọng số trong đó bất kỳ vector trọng số nào cũng đảm bảo hiệu suất tốt. Một vector trọng số phù hợp cho tất cả các nhiệm vụ được lấy từ giao điểm của các vùng này. Trong InterContiNet, các vùng này có dạng siêu hình chữ nhật. Việc huấn luyện InterContiNet trong thiết lập học liên tục là có vấn đề vì các khoảng trong không gian tham số chiều cao cần được kiểm soát. Để giảm nhẹ những vấn đề này, các tác giả đã thiết kế một quy trình huấn luyện phức tạp. Tuy nhiên, trong không gian trọng số đa chiều, việc tối ưu hóa các siêu hình chữ nhật trọng số cho các nhiệm vụ khác nhau để có giao điểm không rỗng là khó khăn. Do đó, InterContinNet bị hạn chế đối với các kiến trúc, bộ dữ liệu và tình huống CL tương đối đơn giản. Trong (Henning et al. 2021), các vùng trong không gian trọng số có dạng phân phối chuẩn. Trong kiến trúc được trình bày ở đó, một hyper-hypernetwork biến đổi đầu vào thành các embedding cụ thể cho nhiệm vụ mà một hypernetwork biến đổi thành những phân phối đó trong không gian trọng số của mạng đích. Công trình hiện tại phát triển cùng họ phương pháp đang nổi lên có thể được gọi là các phương pháp vùng. Tuy nhiên, ở đây chúng tôi xem xét các vùng là kết quả của việc biến đổi các khối lập phương chiều thấp được gán cho các nhiệm vụ bởi một hypernetwork. Bằng cách này, chúng tôi vượt qua vấn đề về tính mở rộng và trình bày một kiến trúc có khả năng xử lý các kiến trúc phức tạp, bộ dữ liệu và tình huống CL.

## 3 Phương pháp: HINT

Kiến trúc CL được đề xuất của chúng tôi, gọi là HINT, được trình bày trong Hình 1, và dựa trên logic sau. Các embedding nhiệm vụ siêu hình chữ nhật, có thể học được được đưa vào hypernetwork, tạo ra trọng số cho mạng đích, giải quyết nhiệm vụ CL. Cả hai mạng đều sử dụng phép toán khoảng. Giao điểm của tất cả các embedding khoảng nhiệm vụ tạo thành một embedding khoảng phổ quát, từ đó mỗi embedding đều phù hợp cho tất cả các nhiệm vụ CL. Quy trình huấn luyện bảo toàn hiệu suất của kiến trúc trên các nhiệm vụ trước đó. Dưới đây, chúng tôi trình bày các phần riêng biệt của kiến trúc này. Chúng tôi bắt đầu với việc trình bày mạng đích và các nguyên tắc của mạng nơ-ron khoảng, và sau đó chúng tôi mô tả hypernetwork khoảng.

### 3.1 Mạng đích khoảng

Trong các mạng nơ-ron khoảng, (Dahlquist và Björck 2008, Sec. 2.5.3, Wołczyk et al. 2022) thay vì xem xét các điểm cụ thể ϑ∈RD trong không gian tham số, các vùng Θ⊂RD được sử dụng. Siêu hình chữ nhật [θ,¯θ] là tích Descartes của các khoảng một chiều

[θ,¯θ] = [θ(1),¯θ(1)]×[θ(2),¯θ(2)]×. . .×[θ(D),¯θ(D)]⊂RD,

trong đó θ(i)∈[θ(i),¯θ(i)] chúng tôi biểu thị phần tử thứ i của θ. Phép toán khoảng sử dụng các phép tính trên các đoạn. Bằng ϕ(x;θ) chúng tôi biểu thị mạng đích, đây là một bộ phân loại nơ-ron nhiều lớp với đầu vào x và trọng số θ. Chúng tôi giả sử trọng số θ là các khoảng, do đó tổng thể định nghĩa một siêu hình chữ nhật, [θ,¯θ]. Do đó, đối với một đầu vào x cho trước, mạng tạo ra một đầu ra siêu hình chữ nhật [z,¯z] = ϕ(x; [θ,¯θ]), thay vì một vector. Phụ lục A cung cấp chi tiết về hoạt động bên trong của mạng khoảng.

Vì các khoảng được sử dụng thay vì các điểm, cross-entropy trường hợp xấu nhất được sử dụng thay vì những cái cổ điển. Mất mát dựa trên khoảng trường hợp xấu nhất được định nghĩa bởi

ˆℓ(x, y; θ,¯θ) = ℓ(ˆz, y), (1)

trong đó x là một quan sát, y là một mã hóa một-hot của lớp của x, ℓ(·,·) là mất mát cross-entropy, và ˆz là một vector với phần tử thứ i được định nghĩa là:

ˆz(i) = {
¯z(i), cho y(i) = 0,
z(i), cho y(i) = 1,

trong đó z = ϕ(x; θ,¯θ). Cross-entropy trường hợp xấu nhất, như được chỉ ra trong (Wołczyk et al. 2022, Định lý 3.1), đưa ra giới hạn trên nghiêm ngặt về cross-entropy

ˆℓ(x, y; [θ,¯θ]) ≥ max θ∈[¯θ,¯θ] ℓ(ϕ(x; [θ, θ]), y). (2)

Đối với thách thức học liên tục của việc tối ưu hóa qua các nhiệm vụ 1, . . . , T, trong quá trình huấn luyện trên một nhiệm vụ cụ thể t, mục tiêu là đạt được cross-entropy trường hợp xấu nhất tối ưu trong các khoảng [θt,¯θt] trong đó [θt,¯θt] ⊆ [θt−1,¯θt−1]. Phép toán khoảng tạo điều kiện cho việc không quên bằng cách duy trì khoảng trọng số của nhiệm vụ t trong khoảng trọng số được huấn luyện cho nhiệm vụ t−1.

Về mặt kỹ thuật, bộ phân loại khoảng ϕ sử dụng cho nhiệm vụ t tham số của mạng với điểm trung tâm θt và bán kính khoảng εt ∈ RD. Do đó, vùng tham số được định nghĩa là [θt,¯θt] = [θt − εt, θt + εt]. Với cách tiếp cận này, mạng vẫn có thể hoạt động như một mô hình không khoảng thông thường bằng cách chỉ sử dụng trọng số trung tâm θt, do đó tạo ra chỉ các kích hoạt trung tâm cho mỗi lớp. Đồng thời, các khoảng kích hoạt [zl,¯zl] có thể được tính toán với phép toán khoảng. Như được chi tiết bởi Gowal et al. (2018), các quá trình này có thể được triển khai hiệu quả trên GPU bằng cách tính toán đồng thời các kích hoạt trung tâm và bán kính tương ứng của chúng. Mạng nơ-ron khoảng thiết kế lại các thành phần cơ bản của mạng nơ-ron (như các lớp kết nối đầy đủ hoặc tích chập, kích hoạt và pooling) để phù hợp với đầu vào và trọng số khoảng.

### 3.2 Hypernetwork khoảng

Trong phần này, chúng tôi giới thiệu một hypernetwork biến đổi các siêu hình chữ nhật trong không gian embedding chiều thấp thành các vùng trong không gian trọng số của mạng đích. Chúng tôi chứng minh tính hiệu quả của kiến trúc chung này. Cuối cùng, chúng tôi chỉ ra rằng hypernetwork có thể chỉ được sử dụng trong huấn luyện, trong khi trong suy luận chỉ mạng đích được sử dụng. Một vùng trong không gian trọng số mạng đích được định hình cho tất cả các nhiệm vụ CL một cách lặp lại, tức là các ràng buộc mới được định nghĩa cho các nhiệm vụ tiếp theo. Cuối cùng, chúng ta có thể tạo ra một vùng trọng số phổ quát với một vector embedding phổ quát. Tuy nhiên, chúng ta có thể tạo ra trọng số cho mỗi nhiệm vụ với các embedding chuyên dụng, đảm bảo hiệu suất cao hơn cho các nhiệm vụ riêng lẻ, nhưng với cái giá của tính phổ quát ít hơn.

HINT bao gồm hypernetwork khoảng trực tiếp chuẩn bị trọng số cho mạng đích khoảng cuối cùng thực hiện phân loại. Các phần liên tiếp của kiến trúc HINT sẽ được mô tả trong vài đoạn tiếp theo.

**Hypernetwork** Được giới thiệu trong (Ha, Dai, và Le 2016), hypernetwork là các mô hình nơ-ron tạo ra trọng số cho một mạng đích riêng biệt được thiết kế để giải quyết một vấn đề cụ thể. Hypernetwork đã được sử dụng trong học liên tục (von Oswald et al. 2019; Henning et al. 2021; Ksi ˛ a ˙zek và Spurek 2023). Trong bối cảnh này, chúng tạo ra trọng số duy nhất cho các nhiệm vụ CL riêng lẻ.

HNET (von Oswald et al. 2019) giới thiệu các embedding có thể huấn luyện et ∈ RM, một cho mỗi nhiệm vụ t, trong đó t ∈ {1, ..., T}. Hypernetwork, được biểu thị là H, và được tham số hóa bởi η, đầu ra các trọng số cụ thể cho nhiệm vụ thứ t, θt, cho mạng đích ϕ, như được hiển thị trong phương trình: H(et; η) = θt.

Hàm ϕ(·; θt) : X → Y biểu thị một bộ phân loại mạng nơ-ron với trọng số θt được tạo ra bởi hypernetwork H(·; η) với trọng số η, và gán nhãn cho các mẫu trong một nhiệm vụ cho trước. Đáng chú ý, bản thân mạng đích không được huấn luyện trực tiếp. Trong HNET, một hypernetwork H(·; η) : RM ∋ et ↦ θt tính toán trọng số θt cho mạng đích ϕ dựa trên embedding nhiệm vụ chuyên dụng et. Do đó, mỗi nhiệm vụ trong học liên tục được đại diện bởi một hàm phân loại ϕ(·; θt) = ϕ(·; H(et; η)).

Sau khi huấn luyện, một meta-model duy nhất được tạo ra, cung cấp trọng số cho các nhiệm vụ cụ thể. Khả năng tạo ra các trọng số riêng biệt cho mỗi nhiệm vụ cho phép các mô hình dựa trên hypernetwork thể hiện việc quên thảm khốc tối thiểu. Khi học nhiệm vụ tiếp theo, về cơ bản một kiến trúc mới được tạo ra, với trọng số dành riêng cho nhiệm vụ này. Để xác định trọng số phù hợp với tất cả các nhiệm vụ, chúng tôi giới thiệu HINT, sử dụng hypernetwork với phép toán khoảng và, tùy chọn, cả các quy tắc huấn luyện đảm bảo một vùng con trọng số chung cho nhiều nhiệm vụ CL. Về cơ bản, tình huống này tương ứng với một kiến trúc duy nhất cho số lượng nhiệm vụ cao hơn. Sau khi huấn luyện, chúng tôi truyền giao điểm của các khoảng qua hypernetwork để tạo ra trọng số phổ quát cho tất cả các nhiệm vụ. Trong tình huống như vậy, chúng tôi không cần phải nhớ các embedding và hypernetwork vì một mạng dành riêng cho tất cả các nhiệm vụ.

**Phép toán khoảng trong không gian embedding.** Trong HNET (von Oswald et al. 2019) và các mô hình dựa trên HNET (Henning et al. 2021; Ksi ˛ a ˙zek và Spurek 2023), các tác giả sử dụng các embedding có thể huấn luyện một chiều et ∈ RM cho mỗi nhiệm vụ t, trong đó t ∈ {1, ..., T}. Trong HINT, chúng tôi sử dụng phép toán khoảng, dẫn đến một embedding được định nghĩa bởi giới hạn dưới và trên của nó cho mỗi tọa độ:

[et,¯et] = [et − εt,i, et + εt,i] = [e(1)t − ε(1)t,i, e(1)t + ε(1)t,i] × . . . × [e(M)t − ε(M)t,i, e(M)t + ε(M)t,i] ⊂ RM,

trong đó εt = [ε(1)t,i, ..., ε(M)t,i] là một vector nhiễu loạn trong lần lặp thứ i của việc huấn luyện nhiệm vụ thứ t (i ∈ {1, ..., n}) thỏa mãn điều kiện σ(ϵt) = 1, trong đó σ(·) là hàm softmax. Đáng chú ý là kỹ thuật chuẩn hóa như vậy được áp dụng cho các vector bị nhiễu loạn trước khi truyền qua hypernetwork. Do đó, et biểu thị tâm của embedding cho nhiệm vụ thứ t. Điều kiện được trình bày đảm bảo rằng các khoảng không sụp đổ thành độ rộng bằng không trong huấn luyện. Các giá trị tọa độ vector nhiễu loạn có thể huấn luyện khi chúng tôi tạo ra trọng số cụ thể cho mỗi nhiệm vụ hoặc được đưa ra nghiêm ngặt trong các trường hợp chúng tôi định nghĩa một vùng con trọng số chung cho tất cả các nhiệm vụ. Tuy nhiên, các giá trị của nó phải không âm, tức là εjt,i ≥ 0 cho j ∈ {1, ..., M}.

Nhờ sử dụng các embedding dựa trên khoảng, chúng ta có thể chọn một không gian con embedding để tạo ra các vùng dành riêng cho nhiều nhiệm vụ CL, xem Hình 1. Trong HINT, các embedding khoảng được biến đổi bởi hypernetwork thành các siêu hình chữ nhật của trọng số của mô hình đích. Trong tình huống này, hypernetwork truyền các đoạn thay vì các điểm. Để đạt được điều này, trong mô hình hypernetwork, chúng tôi sử dụng một kiến trúc dựa trên Interval Bound Propagation (IBP) (Gowal et al. 2018).

Trong HINT được đề xuất của chúng tôi, chúng tôi sử dụng một hypernetwork có trọng số η là các vector, nhưng chúng tôi truyền một đầu vào khoảng [et,¯et] tạo ra một đầu ra khoảng, tức là,

[θt,¯θt] = H([et,¯et]; η).

Hoạt động bên trong của hypernetwork dựa trên phép toán khoảng. Chúng tôi trình bày chi tiết về điều này trong Phụ lục B.

Hypernetwork H được huấn luyện bằng cách sử dụng quy trình được mô tả dưới đây. Cần phải đảm bảo rằng trong việc học một nhiệm vụ cho trước, HINT không quên kiến thức đã học trước đó. Các đầu ra từ hypernetwork có điều kiện nhiệm vụ được tạo ra dựa trên embedding nhiệm vụ. Để ngăn hypernetwork quên các nhiệm vụ trước đó, chúng tôi chính quy hóa việc huấn luyện của nó để tạo ra cùng trọng số mạng đích cho các embedding nhiệm vụ trước đó. Trong một quá trình huấn luyện nhiệm vụ T với HINT, mất mát chính quy hóa được chỉ định là:

Loutput(η) = 1/(3(T−1)) ∑(t=1 to T−1) ∑(μ∈{¯et,¯et+¯et/2,¯et}) ‖H(μ; ηT−1) − H(μ; η)‖2,

trong đó ηT−1 là trọng số hypernetwork được huấn luyện cho nhiệm vụ T−1. Thành phần thứ hai của tổng lồng nhau ở trên tương ứng với việc chính quy hóa tâm embedding, tức là et = (¯et + ¯et)/2. Động lực để sử dụng công thức chính quy hóa này là khả năng bảo toàn hiệu quả kiến thức thu được từ các nhiệm vụ trước đó bằng cách kiểm soát độ dài khoảng được tạo ra bởi hypernetwork. Cụ thể, khi tích của trọng số hypernetwork nhỏ, các khoảng kết quả có xu hướng ngắn. Kết quả này là hệ quả trực tiếp của tính liên tục Lipschitz của các mạng MLP, mà chúng tôi chỉ sử dụng như hypernetwork. Điều này làm cho việc chính quy hóa bổ sung trở nên dư thừa. Để xác minh thêm, vui lòng tham khảo Phụ lục H.2.

Mệnh đề và chứng minh tính liên tục Lipschitz của các mạng MLP được chi tiết trong Phụ lục D. Do đó, việc chính quy hóa chỉ các điểm cuối của các khoảng là đủ để duy trì kiến thức từ các nhiệm vụ trước đó. Kết luận này được hỗ trợ thêm bởi thực tế rằng việc chính quy hóa được đề xuất áp đặt một ràng buộc không tăng trên khoảng. Kết quả là, không cần thiết phải xem xét các điểm khác trong khoảng [et,¯et] cho mục đích chính quy hóa. Tuy nhiên, chúng tôi cũng áp dụng chính quy hóa bổ sung cho tâm của khoảng, vì cách tiếp cận này đã được quan sát thấy mang lại kết quả tốt hơn một chút. Khi định danh nhiệm vụ được đưa ra trong giai đoạn suy luận, thì người ta chỉ có thể sử dụng

Loutput(η) = 1/(T−1) ∑(t=1 to T−1) ‖H(et; ηT−1) − H(et; η)‖2,

vì chúng tôi không phải chính quy hóa hypernetwork ngoài giữa khoảng. Hàm chi phí cuối cùng là tổng của một thành phần Lcurrent, được định nghĩa bởi dữ liệu nhiệm vụ hiện tại, và chính quy hóa đầu ra Loutput, tức là,

L = Lcurrent + β · Loutput, (3)

trong đó β đại diện cho một siêu tham số quản lý cường độ chính quy hóa. Đối với một cặp dữ liệu đầu vào-đầu ra, (x, y), mất mát hiện tại được định nghĩa là cross-entropy tiêu chuẩn kết hợp với cross-entropy trường hợp xấu nhất, tức là,

ℓcurrent = κ · ℓ((zL + ¯zL)/2, y) + (1 − κ) · ℓ(ˆzL, y),

trong đó κ là một siêu tham số được lập lịch trong quá trình huấn luyện giúp kiểm soát việc phân loại đúng các mẫu. Lcurrent trong (3) là trung bình của ℓcurrent trên dữ liệu nhiệm vụ hiện tại Dt.

Cả hai thành phần của L đều cần thiết vì HINT bao gồm hai mạng, và điều quan trọng là phải giảm thiểu những thay đổi mạnh mẽ trong trọng số đầu ra hypernetwork sau khi học các nhiệm vụ CL tiếp theo trong khi có thể thu được kiến thức mới. Mã giả của HINT được trình bày trong Phụ lục C.

**Hypernetwork như một meta-trainer** HINT bao gồm các embedding khoảng được truyền qua hypernetwork dựa trên IBP và mạng đích. Trong quá trình huấn luyện các nhiệm vụ CL, chúng tôi đảm bảo rằng các khoảng embedding liên tiếp có giao điểm không rỗng với những cái trước đó. Một phần chung của các embedding này có thể được sử dụng như một embedding phổ quát và được áp dụng để giải quyết tất cả các nhiệm vụ CL, xem Hình 2. Do đó, chúng ta có thể truyền nó qua hypernetwork dựa trên IBP, nhận được một mạng đích duy nhất để phân loại các mẫu từ tất cả các nhiệm vụ. Theo cách như vậy, hypernetwork không phải được sử dụng trong suy luận và do đó được coi là một meta-trainer. Cuối cùng, một bộ trọng số có thể được sử dụng mà không cần lưu trữ những cái trước đó.

Để đạt được các siêu hình chữ nhật embedding chồng lên nhau cho các nhiệm vụ khác nhau, thay vì huấn luyện chúng trực tiếp, chúng tôi tạo ra chúng từ các pre-embedding được huấn luyện, at ∈ RM, với các công thức sau

et = (γ/M) cos(at),
et = et − γ · σ(ϵt),
¯et = et + γ · σ(ϵt), (4)

trong đó γ là một siêu tham số nhiễu loạn và M là một số tự nhiên biểu thị tính chiều của không gian embedding, và σ(·) là hàm softmax.

Ở cuối quá trình huấn luyện, chúng ta có một chuỗi ([e1,¯e1], ...,[eT,¯eT]) các embedding khoảng dành riêng cho các nhiệm vụ CL liên tiếp. Quy trình trên ép buộc các đoạn như vậy có giao điểm không rỗng như được chỉ ra trong Bổ đề 3.1. Do đó, chúng ta có thể định nghĩa một embedding phổ quát là [e,¯e] = ∩(t=1 to T)[et,¯et]. Như đã đề cập ở trên, khi ϵ* có thể huấn luyện, việc tìm một embedding phổ quát không được đảm bảo.

**Bổ đề 3.1.** Cho (e1, e2, . . . , eT) là các tâm embedding, T là số lượng nhiệm vụ CL, γ > 0 là giá trị nhiễu loạn, H(·; η) là hypernetwork với trọng số η, và M là số tự nhiên biểu thị tính chiều của không gian embedding, et, ¯et được tính toán theo (4) với ϵt ≡ ϵ* là vector của các số một, trong đó t ∈ {1, 2, . . . , T}. Thì

[e,¯e] = ∩(t=1 to T)[et,¯et]

có giao điểm không rỗng.

Chứng minh của Bổ đề 3.1 được trình bày trong Phụ lục E. Các phần tử từ giao điểm cho phép người ta giải quyết nhiều nhiệm vụ đồng thời. Sau đó, chúng ta có thể sử dụng tâm của embedding phổ quát và hypernetwork được huấn luyện để tạo ra một mạng đích duy nhất. Trong đánh giá, chỉ cần sử dụng trọng số đích được chuẩn bị như vậy là đủ, và chúng ta không cần phải lưu trữ hypernetwork và các embedding khoảng được huấn luyện.

**Đảm bảo không quên** Dưới đây, chúng tôi chỉ định các điều kiện của kiến trúc được đề xuất của chúng tôi để không quên. Khi giao điểm của các khoảng embedding không rỗng, và việc chính quy hóa cho việc huấn luyện hypernetwork có hiệu quả, thì chúng ta đạt được việc không quên, như định lý dưới đây chỉ định.

**Định lý 3.2.** Cho (e1, . . . , eT) là các tâm embedding với các vector nhiễu loạn tương ứng (ϵ1, . . . , ϵT), T là số lượng nhiệm vụ CL, Dt = (Xt, Yt) là một cặp quan sát Xt và các lớp mã hóa một-hot tương ứng Yt lấy từ nhiệm vụ thứ t, H(·; ηT) là hypernetwork với trọng số ηT thu được ở cuối việc huấn luyện nhiệm vụ thứ T. Cũng cho ϕ(·; H([et,¯et]; ηT)) là mạng đích với trọng số khoảng được tạo ra bởi hypernetwork sao cho với mọi ϵ > 0, t ∈ {1, 2, . . . , T}, et, ϵt, và x ∈ Xt, tồn tại y ∈ Yt sao cho

sup(μ∈[¯et,¯et]) ‖y − ϕ(x, H(μ; ηT))‖2 ≤ ϵ.

Cũng giả sử rằng ∩(t=1 to T)[¯et,¯et] không rỗng và chúng ta giới thiệu

At = {μ | ∀ϵ > 0 ∀x ∈ Xt ∃y ∈ Yt sup(μ∈[¯et,¯et]) ‖y − ϕ(x, H(μ; ηT))‖2 ≤ ϵ},

t ∈ {1, 2, . . . , T},

A = {μ | ∀ϵ > 0 ∀x ∈ Xt ∃y ∈ Yt sup(μ∈∩(t=1 to T)[¯et,¯et]) ‖y − ϕ(x, H(μ; ηT))‖2 ≤ ϵ}.

Thì, chúng ta có đảm bảo không quên trong vùng [e,¯e] = ∩(t=1 to T)[et,¯et], tức là A ⊂ At, cho mỗi t ∈ {1, 2, . . . , T}.

Chứng minh của định lý trên trong Phụ lục E.

## 4 Thí nghiệm

Trong phần này, chúng tôi cung cấp một cái nhìn tổng quan về kết quả của phương pháp của chúng tôi dưới các giả định huấn luyện khác nhau. Chúng tôi bao gồm nhiều thiết lập học tăng dần để đảm bảo một phân tích rộng rãi về cách tiếp cận phép toán khoảng trong CL. Hơn nữa, chúng tôi hiển thị các kết quả tốt nhất thu được trên mỗi bộ dữ liệu bằng cách sử dụng phương pháp huấn luyện của chúng tôi.

**Thiết lập huấn luyện** Chúng tôi áp dụng ba thiết lập huấn luyện CL điển hình: TIL, trong đó định danh nhiệm vụ của các mẫu thử nghiệm được biết, Domain Incremental Learning (DIL), và CIL. Trong hai thiết lập cuối cùng, định danh nhiệm vụ trong quá trình suy luận không được biết. Khi chúng tôi xem xét HINT trong TIL, chúng tôi không sử dụng bất kỳ phương pháp lồng nhau nào, và các khoảng embedding đầu vào có thể có độ dài khác nhau. Trong CIL, chúng tôi sử dụng entropy để xác định ID nhiệm vụ trong giai đoạn thử nghiệm, và trong DIL, chúng tôi sử dụng phương pháp lồng nhau cos(·) cho các embedding, và các khoảng đầu vào có cùng độ dài, để ngăn các embedding sụp đổ thành một điểm tầm thường. Mô tả chi tiết hơn về các thiết lập này có thể được tìm thấy trong Phụ lục G.

**Bộ dữ liệu** Chúng tôi tiến hành thí nghiệm trên 5 bộ dữ liệu có sẵn công khai: Permuted MNIST (von Oswald et al. 2020), Split MNIST (von Oswald et al. 2020), Split CIFAR-10 (Wołczyk et al. 2022), Split CIFAR-100 (Goswami et al. 2024) và TinyImageNet (Goswami et al. 2024). Chúng tôi khuyến khích độc giả tham khảo tài liệu bổ sung để biết chi tiết về việc chia nhiệm vụ.

**Kiến trúc và baseline** Làm mạng đích cho Permuted MNIST và Split MNIST, chúng tôi sử dụng MLP hai lớp với 1000 nơ-ron mỗi lớp cho bộ dữ liệu đầu tiên và 400 nơ-ron mỗi lớp cho bộ dữ liệu thứ hai. Cho Split CIFAR-100 với 5 và 10 nhiệm vụ, mỗi nhiệm vụ có nhãn phân phối đều, và cho TinyImageNet, chúng tôi chọn một mạng tích chập, cụ thể là ResNet-18, như trong (Goswami et al. 2024). Để đảm bảo so sánh công bằng với phương pháp InterContiNet, chúng tôi cũng huấn luyện kiến trúc AlexNet cho Split CIFAR-10 và Split CIFAR-100 (20 nhiệm vụ, mỗi nhiệm vụ có 5 nhãn). Chúng tôi chỉnh sửa kiến trúc AlexNet theo (Wołczyk et al. 2022). Cụ thể, chúng tôi thêm batch normalization sau mỗi lớp tích chập và kết nối đầy đủ. Tuy nhiên, chúng tôi không bao gồm batch normalization sau lớp tuyến tính cuối cùng, vì nó phục vụ như lớp phân loại. Do tài nguyên GPU hạn chế, số lượng nơ-ron trong hai lớp kết nối đầy đủ đầu tiên được giảm một nửa, so với phiên bản AlexNet được sử dụng trong (Wołczyk et al. 2022). Trong tất cả các trường hợp, hypernetwork là một MLP với một hoặc hai lớp ẩn. Bất cứ khi nào một mạng đích tích chập được sử dụng, chúng tôi áp dụng việc nới lỏng khoảng trong quá trình huấn luyện. Mô tả về cách tiếp cận này có thể được tìm thấy trong Phụ lục F. Chúng tôi so sánh giải pháp của chúng tôi với InterContiNet (Wołczyk et al. 2022), WSN (Kang et al. 2023), HNET (von Oswald et al. 2019), FeCAM (Goswami et al. 2024), cũng như một số phương pháp CL mạnh khác được đề cập trong (Goswami et al. 2024). Việc lựa chọn các phương pháp được sử dụng để so sánh phụ thuộc vào thiết lập huấn luyện được áp dụng.

**Kết quả thí nghiệm** Kết quả cho thiết lập định danh nhiệm vụ đã biết được trình bày trong Bảng 1. Phương pháp của chúng tôi vượt trội so với các đối thủ cạnh tranh trên các bộ dữ liệu Permuted MNIST và Split CIFAR-100 trong khi đạt được kết quả tốt thứ hai trên bộ dữ liệu Split MNIST. Hơn nữa, trên TinyImageNet, chúng tôi đạt được kết quả ổn định, có nghĩa là điểm độ lệch chuẩn thấp thứ hai. Đối với cùng thiết lập huấn luyện, việc so sánh giữa InterContiNet và HINT được hiển thị trong Bảng 4. Chúng tôi đạt được kết quả tốt hơn trên cả ba bộ dữ liệu được sử dụng, cụ thể là thể hiện lợi thế của HINT trong trường hợp huấn luyện các mạng tích chập. Trong bảng này, kết quả cho Split CIFAR-100 được thu được và so sánh bằng cách sử dụng thiết lập InterContiNet: 20 nhiệm vụ với 5 lớp mỗi nhiệm vụ.

Kết quả cho thiết lập định danh nhiệm vụ không biết được trình bày trong Bảng 2 và 4. Mặc dù có độ lệch chuẩn lớn trên Split MNIST, chúng tôi đạt được một embedding phổ quát giải quyết tất cả các nhiệm vụ cùng một lúc, như chúng tôi làm cho Permuted MNIST. Trên Split CIFAR-100, chúng tôi đạt được độ chính xác nhiệm vụ cuối cùng tối đa tốt nhất. Hơn nữa, so với các phương pháp khác, HINT đạt được độ lệch nhỏ hơn giữa nhiệm vụ cuối cùng và độ chính xác nhiệm vụ trung bình, thể hiện tính nhất quán trong các kết quả nhiệm vụ liên tiếp. Thật không may, embedding phổ quát được tìm thấy bởi HINT hoạt động kém trên bộ dữ liệu Split CIFAR-100, chỉ đạt được khoảng 15% độ chính xác. Chúng tôi cho rằng điều này là do số lượng lớp lớn hơn mỗi nhiệm vụ, điều này làm cho việc xác định một embedding phổ quát duy nhất có khả năng giải quyết các nhiệm vụ như vậy đồng thời trở nên thách thức. Như trong thiết lập trước đó, phương pháp HINT vượt trội so với InterContiNet trên tất cả các bộ dữ liệu với biên độ lớn, được hiển thị trong Bảng 4. Trong Hình 2, chúng tôi trình bày các embedding khoảng cho mỗi trong số 5 nhiệm vụ của Split CIFAR-100. Được chỉ ra rằng một embedding phổ quát không rỗng tồn tại, hơn nữa, nó không sụp đổ thành một điểm trong không gian embedding.

Trong Phụ lục H, chúng tôi trình bày một nghiên cứu tập trung vào độ dài khoảng, lồng nhau khoảng và chính quy hóa. Trong Phụ lục I, chúng tôi trình bày cái nhìn sâu sắc chi tiết hơn về các kết quả thí nghiệm trên.

## 5 Kết luận và hạn chế

Trong bài báo này, chúng tôi giới thiệu HINT, một kiến trúc học liên tục sử dụng phép toán khoảng trong mô hình nơ-ron được huấn luyện và hypernetwork tạo ra trọng số của nó. HINT sử dụng các embedding khoảng cho các nhiệm vụ liên tiếp và huấn luyện hypernetwork để biến đổi các embedding này thành trọng số của mạng đích. Cơ chế được đề xuất cho phép chúng tôi huấn luyện các mạng khoảng trên các bộ dữ liệu lớn trong các tình huống học liên tục, trong các thiết lập TIL, CIL và DIL. HINT cho phép tạo ra một embedding phổ quát nhờ phép toán khoảng và việc huấn luyện hypernetwork. Giao điểm của các khoảng, tức là embedding phổ quát, có thể giải quyết tất cả các nhiệm vụ đồng thời. Trong tình huống như vậy, hypernetwork chỉ hoạt động như một meta-trainer, có nghĩa là chúng tôi chỉ duy trì một bộ trọng số duy nhất được tạo ra bởi hypernetwork thông qua embedding phổ quát. Cách tiếp cận này giảm đáng kể việc sử dụng bộ nhớ. Hơn nữa, chúng tôi cung cấp các đảm bảo chính thức về việc không quên.

**Hạn chế** Các đảm bảo không quên trong không gian tham số khoảng được tạo ra bởi hypernetwork chỉ hợp lệ miễn là số hạng chính quy hóa của hypernetwork vẫn có hiệu lực. Thứ hai, chúng tôi đã quan sát thấy rằng việc đạt được hiệu suất thỏa đáng trở nên thách thức khi số lượng lớp trong một nhiệm vụ cụ thể lớn. Việc chia nhiệm vụ như vậy thành các nhiệm vụ con có thể có lợi và sau đó tìm một embedding phổ quát, nhưng chúng tôi để dành điều này cho công việc tương lai.

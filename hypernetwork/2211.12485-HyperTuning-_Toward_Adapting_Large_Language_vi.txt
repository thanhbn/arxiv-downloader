# 2211.12485.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/hypernetwork/2211.12485.pdf
# Kích thước tệp: 682089 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
HyperTuning: Hướng tới Thích ứng Mô hình Ngôn ngữ Lớn
mà không cần Lan truyền ngược
Jason Phang1,2, Yi Mao3, Pengcheng He3, Weizhu Chen3
1Đại học New York
2EleutherAI
3Microsoft Azure AI
Tóm tắt
Tinh chỉnh các mô hình ngôn ngữ lớn cho các nhiệm vụ khác nhau có thể tốn kém và không hiệu quả,
và thậm chí các phương pháp giảm số lượng tham số được điều chỉnh vẫn yêu cầu tối ưu hóa dựa trên
gradient đầy đủ. Chúng tôi đề xuất HyperTuning, một phương pháp mới để thích ứng mô hình sử dụng
một siêu mô hình để tạo ra các tham số đặc trưng cho nhiệm vụ cho một mô hình hạ nguồn cố định.
Chúng tôi trình bày một thiết lập đơn giản cho hypertuning với HyperT5, một siêu mô hình dựa trên
T5 tạo ra các tiền tố mềm hoặc tham số LoRA cho một mô hình T5 đã được đóng băng từ các ví dụ
few-shot. Chúng tôi huấn luyện HyperT5 trong hai giai đoạn: đầu tiên, siêu tiền huấn luyện với một
mục tiêu mô hình hóa ngôn ngữ có điều kiện được sửa đổi để huấn luyện một siêu mô hình tạo ra các
tham số; thứ hai, tinh chỉnh đa nhiệm vụ (MTF) trên một số lượng lớn các nhiệm vụ ngôn ngữ đa dạng.
Chúng tôi đánh giá HyperT5 trên các tập dữ liệu P3, MetaICL và Super-NaturalInstructions, và cho
thấy rằng nó có thể tạo ra hiệu quả các tham số cho các nhiệm vụ chưa thấy. Hơn nữa, chúng tôi cho
thấy rằng việc sử dụng các tham số được tạo ra bởi siêu mô hình làm khởi tạo cho việc tinh chỉnh hiệu
quả tham số tiếp theo cải thiện hiệu suất. Do đó, HyperTuning có thể là một cách linh hoạt và hiệu quả
để tận dụng các mô hình ngôn ngữ lớn cho các ứng dụng hạ nguồn đa dạng.

1 Giới thiệu
Trong khi các mô hình ngôn ngữ (LM) đã đạt được khả năng đáng kể với việc tăng kích thước mô hình
(Brown et al., 2020; Chowdhery et al., 2022), việc tinh chỉnh chúng trên các nhiệm vụ hạ nguồn cụ thể
gây ra những thách thức kỹ thuật đáng kể và chi phí tính toán. Mặc dù các mô hình lớn có thể thực hiện
học zero-shot, có hướng dẫn và few-shot (Sanh et al., 2022; Wei et al., 2022), chúng thường bị vượt
qua bởi các mô hình được tinh chỉnh đầy đủ khi có đủ dữ liệu huấn luyện.

Để giảm chi phí tính toán và bộ nhớ của việc tinh chỉnh LM, các phương pháp tinh chỉnh hiệu quả tham
số (PEFT) đã được đề xuất, như adapters (Houlsby et al., 2019), tinh chỉnh tiền tố (Li and Liang, 2021),
và tinh chỉnh prompt (Lester et al., 2021). Các phương pháp này chỉ cập nhật một tập con nhỏ các tham
số (có thể là mới) của LM, và đã đạt được hiệu suất cạnh tranh với tinh chỉnh đầy đủ (Ding et al., 2022).
Tuy nhiên, các phương pháp PEFT vẫn yêu cầu lan truyền ngược đầy đủ qua LM trong quá trình huấn
luyện, điều này tốn kém về mặt tính toán và sử dụng nhiều bộ nhớ. Cho rằng (1) chỉ cần cập nhật một
số lượng nhỏ tham số để thích ứng LM với một nhiệm vụ cụ thể, (2) các LM rất lớn đã chứng minh khả
năng học trong ngữ cảnh mạnh mẽ trên một lượt truyền thuận, và (3) một lượt truyền thuận cho các LM
rất lớn đã đòi hỏi một lượng tính toán đáng kể, chúng tôi đưa ra giả thuyết rằng có thể huấn luyện một
mô hình riêng biệt để thực hiện hoàn toàn thủ tục tối ưu hóa hoặc thích ứng, chỉ sử dụng một lượt truyền
thuận.

Công việc được thực hiện tại Microsoft. Liên hệ: jasonphang@nyu.edu
Bản thảo.arXiv:2211.12485v1 [cs.CL] 22 Nov 2022

--- TRANG 2 ---
Để tránh việc tính toán tốn kém của việc lan truyền ngược qua LM để tạo ra các cập nhật tham số, đặc
biệt là cho hàng nghìn hoặc hàng triệu lần lặp trong quá trình huấn luyện, chúng tôi đề xuất một mô hình
mới của siêu tinh chỉnh: sử dụng một siêu mô hình để thích ứng một LM hạ nguồn với một ứng dụng
mong muốn. Như một bằng chứng khái niệm cụ thể, chúng tôi khám phá một thiết lập đơn giản trong đó
các siêu mô hình nhận đầu vào là một tập hợp các ví dụ few-shot từ một nhiệm vụ nhất định, và đưa ra
các tham số PEFT tương ứng với nhiệm vụ đó trong một lượt truyền thuận duy nhất.

Để chứng minh tính khả thi của phương pháp này, chúng tôi huấn luyện HyperT5: một tập hợp các siêu
mô hình dựa trên T5 xuất ra các tiền tố mềm (Li and Liang, 2021) hoặc tham số LoRA (Hu et al., 2022),
để được kết hợp vào một LM T5 hạ nguồn đã đóng băng. Để huấn luyện HyperT5, chúng tôi giới thiệu
một quy trình hai giai đoạn để huấn luyện các siêu mô hình: siêu tiền huấn luyện, trong đó chúng tôi thích
ứng một LM đã được tiền huấn luyện để tạo ra các tham số PEFT thông qua một mục tiêu mô hình hóa
ngôn ngữ được sửa đổi, sau đó là tinh chỉnh đa nhiệm vụ (MTF) siêu mô hình.

Sau khi huấn luyện, các mô hình HyperT5 có thể nhận các ví dụ few-shot từ các nhiệm vụ chưa thấy và
tạo ra các tham số PEFT tương ứng, cho phép chúng tôi thích ứng một LM hạ nguồn mà không cần lan
truyền ngược. Chúng tôi cho thấy trong các thí nghiệm trên các tập dữ liệu P3, Super-NaturalInstructions
và MetaICL rằng các LM có thể được siêu tinh chỉnh chỉ sử dụng một số lượng nhỏ ví dụ. Hơn nữa,
chúng tôi cho thấy rằng khi các tham số được tạo ra bởi siêu mô hình được sử dụng làm khởi tạo cho việc
tinh chỉnh hiệu quả tham số tiếp theo, chúng tôi có thể đạt được sự hội tụ huấn luyện nhanh hơn và hiệu
suất tổng thể tốt hơn.

Công việc này phục vụ như một bước đầu tiên hướng tới siêu tinh chỉnh, và chúng tôi nhận thức được
một số hạn chế nhất định của thiết lập sơ bộ này. Bởi vì công thức hiện tại của các siêu mô hình chỉ có
thể nhận một số lượng nhỏ ví dụ làm đầu vào, hiệu suất của nó không thể so sánh với tinh chỉnh hiệu
quả tham số đầy đủ hoặc tinh chỉnh đầy đủ. HyperT5 cũng thường kém hiệu suất hơn T5 được huấn
luyện rõ ràng cho việc học trong ngữ cảnh few-shot với sự chú ý đầy đủ qua các ví dụ, mặc dù chúng
tôi lưu ý rằng cái sau tốn kém hơn về mặt tính toán để sử dụng tại thời gian suy luận. Tuy nhiên, chúng
tôi tin rằng kết quả của chúng tôi chứng minh một bước tiến đầy hứa hẹn hướng tới thích ứng mô hình
mà không cần lan truyền ngược.

Chúng tôi dự định phát hành mã và trọng số mô hình cho HyperT5, cũng như các phiên bản tinh chỉnh
đa nhiệm vụ cho ba tập dữ liệu được liệt kê ở trên.

2 Công việc Liên quan
Mạng Siêu Một số công việc đã khám phá khái niệm "siêu mạng", trong đó một mạng phụ được sử dụng
để tạo ra các tham số cho một mạng chính. Thuật ngữ này lần đầu tiên được giới thiệu bởi Ha et al. (2017)
và áp dụng cho LSTM. Trong số các mô hình ngôn ngữ dựa trên Transformer, Karimi Mahabadi et al.
(2021) và He et al. (2022) đã kết hợp các siêu mạng vào các mô hình T5 để chia sẻ kiến thức trong quá
trình tinh chỉnh đa nhiệm vụ. Peebles et al. (2022) đã sử dụng một Transformer với khuếch tán để tạo
ra các tham số mô hình đầy đủ cho các nhiệm vụ nhận dạng hình ảnh và Cartpole. Tương tự, Lester et
al. (2022) đã huấn luyện các mô hình để tạo ra các prompt mềm để chuyển giao giữa các mô hình hạ
nguồn. Công việc của chúng tôi có liên quan chặt chẽ với Deb et al. (2022), những người cũng đã sử
dụng một siêu mạng để sửa đổi các tham số mô hình hạ nguồn và kết hợp Super-NaturalInstructions
(S-NI) trong thiết lập thí nghiệm của họ. Họ thấy rằng việc kết hợp hướng dẫn thông qua một siêu mạng
được huấn luyện với MAML (Finn et al., 2017) đã cải thiện hiệu suất hạ nguồn.

Huấn luyện Đa nhiệm vụ và Chuyển giao Một thành phần quan trọng của siêu tinh chỉnh là khả năng
chuyển giao kiến thức nhiệm vụ và tổng quát hóa cho các nhiệm vụ mới. Nhiều công việc trước đây
(Phang et al., 2018; Pruksachatkun et al., 2020; Vu et al., 2020) đã khám phá hiệu quả của việc học
chuyển giao đơn và đa nhiệm vụ. Công việc gần đây hơn đã cho thấy rằng huấn luyện đa nhiệm vụ quy
mô lớn thường cho phép các mô hình tổng quát hóa cho các nhiệm vụ chưa thấy (Sanh et al., 2022; Wei
et al., 2022; Wang et al., 2022; Chung et al., 2022). Min et al. (2022) và Chen et al. (2022) cho thấy
rằng việc học few-shot cũng được hưởng lợi từ huấn luyện đa nhiệm vụ. Pfeiffer et al. (2020), Vu et
al. (2021) và Gu et al. (2021) cũng đã khám phá việc học chuyển giao trong số các phương pháp PEFT.

3 Siêu Tinh chỉnh
Động lực cho việc sử dụng các siêu mô hình để thích ứng các mô hình hạ nguồn bắt nguồn từ hai phát
triển gần đây trong xử lý ngôn ngữ tự nhiên:

--- TRANG 3 ---
Hình 1: Tổng quan về Siêu Tinh chỉnh. (A) Tinh chỉnh, trong đó tất cả các tham số mô hình được cập
nhật (màu đỏ). (B) Tinh chỉnh hiệu quả tham số (PEFT), trong đó tất cả các tham số mô hình được đóng
băng (màu xanh) và chỉ một số lượng nhỏ tham số, θ, được cập nhật. (C) Siêu Tinh chỉnh, trong đó một
siêu mô hình được sử dụng để tạo ra các tham số cho một mô hình hạ nguồn đã đóng băng. Ví dụ, một
siêu mô hình có thể nhận một tập hợp các ví dụ few-shot để xác định cái gì cần tạo ra. Chỉ các tham số
của siêu mô hình được cập nhật trong quá trình huấn luyện. (D) Tại thời gian suy luận, các tham số chỉ
cần được tạo ra một lần, và sau đó chỉ cần lưu trữ θ, mà không cần giữ lại các ví dụ few-shot.

1) Các mô hình ngôn ngữ lớn có thể thực hiện học trong ngữ cảnh một cách hiệu quả. Các mô hình ngôn
ngữ lớn đã được chứng minh là có thể học từ ngữ cảnh của một số lượng nhỏ ví dụ hoặc hướng dẫn cho
một nhiệm vụ, mà không cần bất kỳ huấn luyện trước nào trên nhiệm vụ đó (Brown et al., 2020; Min et
al., 2022; Wang et al., 2022). Điều này cho thấy rằng các mô hình có thể "hiểu" nhiệm vụ là gì và cách
giải quyết nó dựa trên một vài mẫu hoặc mô tả của nhiệm vụ. Khả năng này dường như cải thiện khi
các mô hình trở nên lớn hơn hoặc được huấn luyện trên nhiều dữ liệu liên quan hơn (Chowdhery et al.,
2022; Ouyang et al., 2022; Bai et al., 2022).

2) Các mô hình ngôn ngữ lớn có thể được thích ứng với các nhiệm vụ hạ nguồn bằng cách điều chỉnh
một tập hợp nhỏ tham số. Cùng với sự tăng trường về kích thước mô hình, đã có những tiến bộ đáng kể
trong các phương pháp tinh chỉnh chỉ sửa đổi một số lượng nhỏ tham số (có thể thêm một số tham số
mới) trong một mô hình ngôn ngữ đã đóng băng để thích ứng nó với một nhiệm vụ cụ thể (Houlsby et
al., 2019; Li and Liang, 2021; Lester et al., 2021; Ding et al., 2022). Các phương pháp này thường đạt
được hiệu suất so sánh với việc tinh chỉnh tất cả các tham số trong mô hình. Quan trọng là, số lượng
tham số cần thay đổi đủ nhỏ để có thể huấn luyện một mô hình để tạo ra chúng (Qin et al., 2021; Lester
et al., 2022).

Kết hợp lại, những phát hiện này cho thấy rằng chúng ta có thể sử dụng một mô hình phụ trợ có thể
trước tiên trích xuất một số kiến thức liên quan đến nhiệm vụ từ một số đầu vào mô tả nhiệm vụ (ví dụ:
hướng dẫn, ví dụ few-shot), và sau đó tạo ra một số lượng nhỏ tham số thích ứng, do đó thay đổi hành
vi của mô hình chính để phù hợp với nhiệm vụ. Phương pháp này, nếu thành công, sẽ cho phép chúng
ta thích ứng các mô hình với các ứng dụng hạ nguồn mà không sử dụng lan truyền ngược, hoặc lưu trữ
các biểu diễn được mã hóa của các ví dụ few-shot trong bộ nhớ. Nói cách khác, chúng ta có thể ủy
thác công việc thích ứng mô hình cho một mô hình riêng biệt.

Chúng tôi gọi phương pháp này là siêu tinh chỉnh, lấy cảm hứng từ công việc về siêu mạng của Ha et
al. (2017). Siêu tinh chỉnh sử dụng một siêu mô hình để thích ứng một mô hình hạ nguồn với một nhiệm
vụ hoặc ứng dụng hạ nguồn mục tiêu. Điều này khác với tinh chỉnh, sử dụng lan truyền ngược và thuật
toán gradient descent để cập nhật các tham số mô hình. Trong công việc này, chúng tôi trình bày một
công thức có thể của siêu tinh chỉnh sử dụng các ví dụ few-shot và tạo ra một tập hợp nhỏ tham số với
một lượt truyền thuận duy nhất qua siêu mô hình. Tuy nhiên, đây chỉ là một cách có thể để thực hiện
siêu tinh chỉnh, và ý tưởng thích ứng các mô hình với các siêu mô hình có thể được tổng quát hóa cho
nhiều trường hợp khác. Ví dụ, các siêu mô hình cũng có thể được huấn luyện để dự đoán gradient hoặc
tạo ra các cập nhật tham số dựa trên các cặp đầu vào-đầu ra. Bằng cách này, các siêu mô hình có thể
làm việc với các tập dữ liệu huấn luyện lớn, không chỉ một vài ví dụ. Cuối cùng, với các siêu mô hình
đủ tổng quát và được huấn luyện tốt, chúng ta có thể thay thế các đường ống tinh chỉnh dựa trên gradient
descent bằng siêu tinh chỉnh cho nhiều ứng dụng, trong khi đạt được hiệu suất tương tự hoặc tốt hơn.

--- TRANG 4 ---
3.1 Siêu Tinh chỉnh với Các Ví dụ Fewshot
Gọi M là một mô hình với các tham số θ, được khởi tạo tại θ₀ từ tiền huấn luyện, và L là một hàm mất
mát. Cho một tập dữ liệu có kích thước N với các cặp đầu vào-đầu ra {(x;y)}, tinh chỉnh tiêu chuẩn
tối thiểu hóa mục tiêu sau trên θ:

arg min_θ (1/N) ∑_{(x;y)} L(y; M(θ;x))                                    (1)

Trong trường hợp tinh chỉnh hiệu quả tham số (PEFT), chúng ta cố định θ = θ₀ và giới thiệu một tập
hợp nhỏ các tham số có thể huấn luyện φ (ví dụ: tham số adapter, soft prompts) được tiêm vào M. Chúng
ta chỉ tối ưu hóa trên φ:

arg min_φ (1/N) ∑_{(x;y)} L(y; M(θ₀;x;φ))                                (2)

Đối với siêu tinh chỉnh, chúng ta định nghĩa thêm một siêu mô hình H với các tham số ψ tạo ra các tham
số PEFT φ̂ dựa trên đầu vào của nó, có thể là một tập hợp các ví dụ few-shot hoặc hướng dẫn nhiệm
vụ. Ví dụ, nếu đầu vào siêu mô hình là một tập hợp các ví dụ few-shot {(xᵢ;yᵢ)}ᵏ, chúng ta có:

φ̂ = H(ψ; {(xᵢ;yᵢ)}ᵏ)                                                    (3)

Một cách để huấn luyện siêu mô hình (H;ψ) là thực hiện PEFT trên nhiều nhiệm vụ và sử dụng φ kết
quả làm mục tiêu. Tuy nhiên, điều này tốn kém về mặt tính toán, đòi hỏi nhiều lần chạy tinh chỉnh,
và không tận dụng việc chuyển giao kiến thức giữa các nhiệm vụ. Thay vào đó, chúng tôi đề xuất huấn
luyện siêu mô hình từ đầu đến cuối, tối ưu hóa thông qua mô hình đã đóng băng (M; θ₀). Do đó, mục
tiêu huấn luyện siêu mô hình là:

arg min_ψ (1/N) ∑_{(x;y); {(xᵢ;yᵢ)}ᵏ} L(y; M(θ₀;x; H(ψ; {(xᵢ;yᵢ)}ᵏ)))      (4)

Tại mỗi bước huấn luyện, chúng ta lấy mẫu một ví dụ mục tiêu (x;y) và các ví dụ few-shot không trùng
lặp {(xᵢ;yᵢ)}ᵏ. Chúng ta tạo ra φ̂ từ các ví dụ few-shot và tính toán mất mát đối với (x;y) và φ̂. Sau đó
chúng ta lan truyền ngược gradient qua cả M và H để cập nhật ψ.

Lưu ý rằng vì φ̂ không phụ thuộc vào x, nó có thể được tính toán một lần cho một tập hợp ví dụ few-shot
nhất định và tái sử dụng cho các dự đoán hạ nguồn. Tại thời gian suy luận, chúng ta có thể sử dụng φ̂
trực tiếp mà không cần lưu trữ hoặc tính toán lại các biểu diễn cho {(x;y)}; {(xᵢ;yᵢ)}ᵏ, tiết kiệm bộ nhớ
và tính toán.²

4 HyperT5: Một Siêu Mô hình Dựa trên T5
4.1 Kiến trúc và Thiết lập
Để chứng minh tính khả thi của siêu tinh chỉnh, chúng tôi đề xuất HyperT5, một siêu mô hình dựa trên
T5, trong đó cả siêu mô hình và mô hình hạ nguồn đều chia sẻ backbone T5 (Hình 2A). Chúng tôi sử
dụng một LM-adapted T5³ đã đóng băng làm mô hình hạ nguồn. Siêu mô hình cũng được khởi tạo với
các tham số LM-adapted T5, nhưng với một số thay đổi kiến trúc. Như được định nghĩa trong Phương
trình 3, encoder siêu mô hình nhận các ví dụ few-shot (và/hoặc định nghĩa nhiệm vụ, trong trường hợp
S-NI) làm đầu vào. Decoder siêu mô hình nhận một tập hợp cố định các embedding token mới được
học làm đầu vào, và xuất ra một tập hợp các biểu diễn token decoder, sau đó được đưa vào một tập hợp
các MLP để tạo ra các tham số PEFT cho mô hình hạ nguồn. Chúng tôi cũng loại bỏ việc che phủ nhân
quả khỏi decoder, vì siêu mô hình không thực hiện sinh tự hồi quy.

²Theo thiết kế, các ví dụ few-shot chiếm ít nhất K lần bộ nhớ của đầu vào mục tiêu x.
³Đây là mô hình được giới thiệu bởi Lester et al. (2021). Chúng tôi sử dụng kiến trúc T5 v1.1 và khởi tạo
tất cả các thí nghiệm với các tham số LM-adapted, trừ khi có nêu khác.

--- TRANG 5 ---
Hình 2: Tổng quan về HyperT5. (A) HyperT5 nhận đầu vào là các ví dụ few-shot và xuất ra các tham
số PEFT. Mô hình được khởi tạo từ một T5 LM-adapted. (B) Trong HyperT5-Prefix, φ là các tiền tố
key và value cho mỗi lớp attention. (C) Trong HyperT5-LoRA, φ là các sửa đổi cộng thêm hạng thấp
cho các ánh xạ tuyến tính query và value.

Chúng tôi thí nghiệm với hai phương pháp PEFT: tinh chỉnh tiền tố (Li and Liang, 2021) và LoRA (Hu
et al., 2022). Tinh chỉnh tiền tố (Hình 2B) thêm một tập hợp các biểu diễn key và value được học vào
đầu mỗi lớp attention, trong khi LoRA (Hình 2C) học một sửa đổi cộng thêm hạng thấp cho các ánh xạ
tuyến tính query và value. Cả hai phương pháp PEFT đều đã được chứng minh đạt hiệu suất tốt trên
một loạt các nhiệm vụ (Ding et al., 2022). Chan et al. (2022) cũng gợi ý rằng việc sửa đổi các biểu
diễn trong ngữ cảnh và trọng số mô hình có thể dẫn đến các hành vi mô hình khác nhau, và chúng tôi
tìm cách chứng minh rằng siêu tinh chỉnh có thể áp dụng cho các phương pháp PEFT rất khác nhau.
Chúng tôi đặt tên các siêu mô hình tương ứng là HyperT5-Prefix và HyperT5-LoRA.

Số lượng token đầu vào decoder và kích thước của các MLP phụ thuộc vào việc lựa chọn phương pháp
PEFT và các siêu tham số của nó. Ví dụ, đối với HyperT5-Prefix tạo ra các tiền tố mềm tương ứng với
tinh chỉnh tiền tố, φ sẽ có hình dạng [L; 2; 2; P; H], trong đó L là số lượng lớp, 2 là cho encoder và
decoder, 2 là cho các tiền tố key và value, P là số lượng token tiền tố, và H là kích thước ẩn. Chúng tôi
đặt số lượng token đầu vào decoder là 2P. Chúng tôi cung cấp mã giả cho các mô hình HyperT5-Prefix
và HyperT5-LoRA trong Hình 7 và Hình 8 trong Phụ lục.

4.2 Siêu Tiền Huấn luyện
Để huấn luyện HyperT5, chúng tôi trước tiên trải qua một giai đoạn bổ sung của tiền huấn luyện để
thích ứng siêu mô hình tạo ra các tham số cho mô hình hạ nguồn, mà chúng tôi gọi là siêu tiền huấn
luyện. Như chúng tôi cho thấy trong Mục 5.5, siêu tiền huấn luyện là quan trọng để có hiệu suất siêu
mô hình tốt.

Chúng tôi đề xuất một lược đồ đơn giản cho siêu tiền huấn luyện sử dụng mục tiêu Context-Augmented
Conditional Language Modeling (CACLM), mở rộng mục tiêu conditional language-modeling (CLM)
của T5 LM-adaptation. Như được thể hiện trong Hình 3, chúng tôi lấy mẫu một chuỗi 512 token từ
một corpus tiền huấn luyện và chia nó thành bốn đoạn liên tiếp A-D. Mô hình hạ nguồn nhận đoạn B
làm đầu vào và dự đoán đoạn C, theo mục tiêu CLM. Siêu mô hình nhận các đoạn A và D làm đầu vào,
cung cấp ngữ cảnh bổ sung từ cùng một tài liệu, và xuất ra các tham số PEFT cho mô hình hạ nguồn.⁴
Siêu mô hình do đó nén thông tin ngữ cảnh để hỗ trợ mô hình hạ nguồn trong nhiệm vụ CLM của nó.
Chúng tôi cũng làm cho đoạn B rất ngắn (32 token) để khuyến khích mô hình hạ nguồn phụ thuộc vào
thông tin siêu mô hình để dự đoán chính xác các token trong C.

Trong quá trình siêu tiền huấn luyện, chúng tôi đóng băng mô hình hạ nguồn và chỉ cập nhật các tham
số siêu mô hình, huấn luyện trong 100K bước trên tập dữ liệu C4 (Raffel et al., 2020). Chúng tôi thực
hiện siêu tiền huấn luyện riêng biệt cho các mô hình HyperT5-Prefix và HyperT5-LoRA. Các siêu tham
số có thể được tìm thấy trong Phụ lục A.

5 Tinh chỉnh Đa Nhiệm vụ với HyperT5
5.1 Tinh chỉnh Đa Nhiệm vụ (MTF)
Sau siêu tiền huấn luyện, chúng tôi tiến hành giai đoạn thứ hai của huấn luyện để huấn luyện siêu mô
hình tạo ra các tham số PEFT đặc trưng cho nhiệm vụ dựa trên một số lượng nhỏ ví dụ mà chúng tôi
cung cấp làm đầu vào (Hình 1C). Bằng cách thực hiện tinh chỉnh đa nhiệm vụ trên một số lượng đủ lớn
các nhiệm vụ, chúng tôi hy vọng có siêu mô hình học để tổng quát hóa tạo ra các tham số cho các nhiệm
vụ chưa thấy. Chúng tôi áp dụng thiết lập huấn luyện tương tự với MetaICL (Min et al., 2022), sử dụng
tinh chỉnh đa nhiệm vụ (Sanh et al., 2022; Wei et al., 2022) với cả một ví dụ đầu vào mục tiêu (x) và
một tập hợp các cặp đầu vào-đầu ra few-shot {(xᵢ;yᵢ)}ᵏ làm đầu vào. Siêu mô hình nhận các cặp few-shot
làm đầu vào, trong khi mô hình hạ nguồn nhận ví dụ mục tiêu làm đầu vào, như được thể hiện trong
Phương trình 3. Chúng tôi tinh chỉnh chỉ các tham số siêu mô hình và giữ các tham số mô hình hạ nguồn
cố định, trừ khi có nêu khác. Phụ lục A.1 cho thấy cách chúng tôi định dạng các đầu vào few-shot.

Chúng tôi so sánh phương pháp của chúng tôi với hai baseline: tinh chỉnh đa nhiệm vụ của một mô hình
T5 mà không có đầu vào few-shot, và MetaICL (tinh chỉnh đa nhiệm vụ với đầu vào few-shot). Trong
MetaICL, các cặp few-shot được nối với ví dụ mục tiêu làm đầu vào, cả trong quá trình huấn luyện và
đánh giá trên các nhiệm vụ mới. Chúng tôi cũng bao gồm các baseline sử dụng các phương pháp PEFT
cho tinh chỉnh đa nhiệm vụ, tức là học một tập hợp duy nhất các tham số tinh chỉnh tiền tố hoặc LoRA.

Chúng tôi thực hiện tinh chỉnh đa nhiệm vụ trong 10.000 bước với kích thước batch 256. Đối với các
mô hình sử dụng đầu vào few-shot (MTF với few-shot, và các siêu mô hình), chúng tôi sử dụng tối đa
16 ví dụ, và cắt bớt các token vượt quá độ dài đầu vào tối đa. Phụ lục B cung cấp thêm chi tiết về các
tập dữ liệu.

5.2 Tập dữ liệu
Để chứng minh tính tổng quát của phương pháp, chúng tôi tiến hành thí nghiệm trên ba tập dữ liệu huấn
luyện đa nhiệm vụ khác nhau, mỗi tập có các nhiệm vụ held-out khác nhau và các giao thức đánh giá.

Public Pool of Prompts (P3) (Sanh et al., 2022) bao gồm 62 tập dữ liệu nhiệm vụ, và được sử dụng
trong việc huấn luyện các mô hình T0. Các prompt được định dạng với suy luận 0-shot trong tâm trí,
và thường chứa hướng dẫn hoặc các lựa chọn câu trả lời có thể. Để huấn luyện các mô hình của chúng
tôi, chúng tôi sử dụng tập con T0-train. Để phù hợp với nhiều ví dụ vào ngữ cảnh của siêu mô hình,
chúng tôi tiếp tục loại trừ các tập con dataset-prompt với độ dài chuỗi đầu vào trung bình dài hơn 320
token. Danh sách các dataset-prompt được bao gồm có thể được tìm thấy trong Hình 6. Đánh giá được
thực hiện trên một tập hợp cố định các nhiệm vụ held-out, dựa trên chấm điểm multiple-choice với
độ chính xác. Chúng tôi loại trừ StoryCloze khỏi đánh giá vì nhiệm vụ không được phân phối với dữ
liệu huấn luyện.

MetaICL (Min et al., 2022) giới thiệu một tập dữ liệu huấn luyện đa nhiệm vụ few-shot, là một phần
mở rộng của CrossFit (Ye et al., 2021) với UniﬁedQA (Khashabi et al., 2020) và việc bổ sung dữ liệu
huấn luyện. Để ngắn gọn, chúng tôi sẽ gọi tập dữ liệu này là MetaICL. Không giống như P3 và S-NI,
các đầu vào nhiệm vụ không được định dạng cho suy luận 0-shot; ví dụ, các đầu vào nhiệm vụ có thể
không đưa ra manh mối nào về mục tiêu của nhiệm vụ, hoặc không gian đầu ra là gì. Họ cung cấp một
số phân chia train-task khác nhau cho các nhiệm vụ, trong đó chúng tôi chạy thí nghiệm trên ba phân
chia (HR→LR, Non-NLI→NLI, Non-Class→Class) để tiết kiệm chi phí tính toán. Đánh giá được thực
hiện trên các nhiệm vụ held-out, với ROUGE hoặc Macro-F1 trên các bản sinh của mô hình tùy thuộc
vào nhiệm vụ.

--- TRANG 6 ---
Super-NaturalInstructions (S-NI) (Wang et al., 2022) bao gồm hơn 1.600 tập dữ liệu nhiệm vụ, mỗi
tập có một định nghĩa nhiệm vụ cũng như một tập hợp cố định các minh họa tích cực và tiêu cực. Theo
các phát hiện của họ, chúng tôi tập trung thí nghiệm vào hai thiết lập: chỉ sử dụng định nghĩa nhiệm vụ
làm đầu vào siêu mô hình, và sử dụng định nghĩa cùng với hai ví dụ tích cực cố định. Chúng tôi chỉ sử
dụng các nhiệm vụ tiếng Anh trong tập dữ liệu. Đánh giá được thực hiện trên một tập hợp các nhiệm vụ
held-out sử dụng ROUGE-L trên các bản sinh của mô hình.

5.3 Kết quả
5.3.1 P3
[Bảng 1 và 2 với kết quả P3]

Bảng 1 và Bảng 2 cho thấy kết quả thí nghiệm của chúng tôi trên tập dữ liệu P3 sử dụng T5-Large
(~770M tham số) và T5-XL (~3B tham số), tương ứng.

Chúng tôi so sánh HyperT5-Prefix và HyperT5-LoRA, sử dụng các siêu mô hình để tạo ra các tham số
PEFT đặc trưng cho nhiệm vụ dựa trên các ví dụ few-shot, với một số baseline: tinh chỉnh tiền tố, tinh
chỉnh LoRA, T5-MTF, và T5-MTF-Few-shot. T5-MTF là một mô hình đại khái tương ứng với mô hình
T0, và chúng tôi chi tiết các khác biệt trong Phụ lục B.1.

Kết quả của chúng tôi cho thấy rằng cả HyperT5-Prefix và HyperT5-LoRA đều cải thiện đáng kể so với
các baseline tinh chỉnh tiền tố và LoRA, chỉ ra hiệu quả của việc sử dụng các siêu mô hình để thích ứng
mô hình T5 hạ nguồn đã đóng băng cho các nhiệm vụ chưa thấy. HyperT5-Prefix đạt hiệu suất gần với
T5-MTF, trong khi T5-MTF-Few-shot đạt điểm số cao nhất, phù hợp với các phát hiện của Min et al.
(2022). Các mô hình này nhất quán trên T5-Large và T5-XL,⁵ chứng minh khả năng mở rộng của siêu
tinh chỉnh.

Chúng tôi nhấn mạnh rằng HyperT5-Prefix/LoRA chỉ giới thiệu một số lượng rất nhỏ các tham số PEFT
trong mô hình T5 hạ nguồn đã đóng băng, trong khi tất cả các tham số được điều chỉnh trong các mô
hình T5-MTF và T5-MTF-Few-shot. Hơn nữa, các ví dụ P3 được viết với các template prompt được
tối ưu hóa cho suy luận zero-shot, đây là định dạng đầu vào lý tưởng cho T5-MTF. Ngoài ra, T5-MTF-
Fewshot có sự chú ý tự hai chiều đầy đủ giữa đầu vào mục tiêu x và các ví dụ few-shot, trong khi
HyperT5-Prefix và HyperT5-Lora chỉ kết hợp thông tin từ các ví dụ few-shot thông qua các tham số
PEFT tương ứng.

Để điều tra liệu lợi ích của siêu mô hình có bổ sung cho việc cập nhật các tham số mô hình hạ nguồn
hay không, chúng tôi tiến hành một tập hợp thí nghiệm bổ sung trong đó chúng tôi đồng thời huấn luyện
cả siêu mô hình và mô hình hạ nguồn (HyperTuning + Fine-Tuning), với kết quả được thể hiện ở cuối
Bảng 1. Chúng tôi quan sát thấy rằng cả HyperT5-Prefix+ và HyperT5-Lora+ đều vượt qua một chút
T5-MTF-Fewshot, gợi ý rằng các siêu mô hình có thể tăng cường thêm hiệu suất của các mô hình hạ
nguồn được tinh chỉnh.

5.3.2 MetaICL
[Bảng 3 với kết quả MetaICL]

Bảng 3 trình bày kết quả trên ba phân chia nhiệm vụ MetaICL. Như trong các thí nghiệm trước, cả hai
mô hình HyperT5 đều vượt qua các mô hình PEFT và T5-MTF về hiệu suất, ngoại trừ T5-MTF-Few-
shot, vượt qua chúng trong tất cả trừ một trường hợp: Non-NLI→NLI, nơi HyperT5-Prefix đạt điểm
số cao hơn. T5-MTF hoạt động kém trong các thí nghiệm MetaICL, vì nó phải xử lý các ví dụ nhiệm vụ
zero-shot, và các đầu vào MetaICL không phù hợp cho suy luận zero-shot, như đã giải thích ở trên.

5.3.3 Super-NaturalInstructions (S-NI)
[Bảng 4 và 5 với kết quả S-NI]

Chúng tôi báo cáo kết quả trên các thiết lập S-NI khác nhau trong Bảng 4 cho T5-Large và Bảng 5 cho
T5-XL, sử dụng cả thiết lập Def (chỉ định nghĩa) và Def+2Pos (định nghĩa và hai ví dụ tích cực cố định).
Các mô hình T5-MTF (Def) và T5-MTF (Def+2Pos) tương tự như các biến thể T₀-Instruct tương ứng
(Wang et al., 2022), với một chút khác biệt trong định dạng đầu vào (xem Phụ lục A.1). Đối với các siêu
mô hình, chúng tôi thêm các định nghĩa nhiệm vụ vào các ví dụ few-shot và coi chúng như một phần
của đầu vào siêu mô hình. Trung bình, HyperT5 với Def+2Pos vượt qua T5-MTF (Def) với biên độ
lớn, nhưng vẫn kém hiệu suất hơn T5-MTF (Def+2Pos), phù hợp với các kết quả ở trên.

5.4 Thảo luận
Ở trên, chúng tôi đã đánh giá các siêu mô hình trên ba tập dữ liệu đa nhiệm vụ, trong đó chúng tạo ra
các tiền tố mềm hoặc tham số LoRA đặc trưng cho nhiệm vụ từ một vài ví dụ hoặc hướng dẫn. Nhìn
chung, HyperT5 khớp hoặc vượt qua các mô hình T5-MTF, nhưng thua kém các mô hình T5-MTF-
Fewshot (hoặc mô hình Def+2Pos, trong trường hợp S-NI). Khoảng cách này là mong đợi, vì T5-MTF-
Fewshot sử dụng sự chú ý tự đầy đủ giữa các ví dụ và đầu vào mục tiêu x, trong khi HyperT5 mã hóa
các ví dụ thành các tham số PEFT độc lập với x. Chúng tôi gán một phần khoảng cách cho hạn chế này.

Tuy nhiên, hạn chế này cũng mang lại lợi thế về hiệu quả cho HyperT5 tại thời gian suy luận so với
T5-MTF-Fewshot. Trong các encoder-decoder như T5, sự chú ý tự đầy đủ giữa các ví dụ và x ngăn cản
việc tách biệt các biểu diễn của chúng: cần một lượt truyền thuận mới cho mỗi x mới. Ngược lại, đối
với các siêu mô hình, các ví dụ có thể được mã hóa thành các tham số PEFT một lần, và tái sử dụng
cho tất cả các đầu vào tiếp theo. Ngay cả đối với các mô hình chỉ có decoder (ví dụ MetaICL dựa trên
GPT-2), nơi các ví dụ có thể được cache như các biểu diễn key và value, kích thước cache có thể lớn
hơn nhiều so với các tham số PEFT, vì cache lưu trữ tất cả các biểu diễn cho mỗi token trong các ví dụ,
dài hơn đầu vào nhiều lần theo định nghĩa. Do đó, các siêu mô hình trong thiết lập của chúng tôi hy
sinh một số hiệu suất để đổi lấy hiệu quả.

Về T5-MTF, người ta có thể thắc mắc lợi ích cụ thể của HyperT5 là gì, cho rằng hiệu suất tương tự
của chúng. Rốt cuộc, không giống như T5-MTF-Fewshot, T5-MTF chỉ sử dụng x làm đầu vào, không
yêu cầu tính toán hoặc bộ nhớ bổ sung, và chỉ một tập hợp trọng số mô hình. Đầu tiên, chúng tôi nhấn
mạnh rằng mô hình HyperT5 chỉ có thể ảnh hưởng đến mô hình hạ nguồn thông qua một số lượng nhỏ
các tham số được sửa đổi, trong khi trong T5-MTF tất cả các tham số xử lý x đều được sửa đổi. Mặc dù
HyperT5 và T5-MTF có khoảng cùng số lượng tham số được điều chỉnh, các tham số được sửa đổi trong
T5-MTF tương tác trực tiếp với đầu vào x, mà chúng tôi mong đợi sẽ giúp cải thiện hiệu suất. Thứ hai,
chúng tôi xác định hai nguồn cải thiện hiệu suất riêng biệt nhưng có thể liên quan: hiệu suất nhiệm vụ
tổng quát tốt hơn của mô hình hạ nguồn (thường là mục tiêu của huấn luyện MTF), và thích ứng mô
hình hạ nguồn với một nhiệm vụ mới dựa trên các ví dụ few-shot, sử dụng các siêu mô hình trong trường
hợp của chúng tôi. Mục tiêu của chúng tôi trong công việc này là cho thấy tính khả thi của cái sau.
Chúng tôi lập luận rằng cả hai nguồn đều bổ sung cho nhau, và chúng tôi đã cho thấy trong Mục 5.3.1
rằng khi chúng tôi sử dụng các siêu mô hình mà không đóng băng mô hình hạ nguồn, do đó có được cả
hai lợi ích, hiệu suất cải thiện thêm. Một cách tổng quát hơn, chúng tôi mong đợi rằng việc huấn luyện
một siêu mô hình đối kháng với một mô hình đã được tinh chỉnh đa nhiệm vụ sẽ dẫn đến hiệu suất tốt
hơn so với chỉ sử dụng mô hình cho suy luận zero-shot một mình, và chúng tôi dự định khám phá điều
này trong công việc tương lai.

Chúng tôi cũng quan sát thấy một xu hướng nhất quán trong đó HyperT5-Prefix vượt trội hơn HyperT5-
LoRA. Chúng tôi suy đoán rằng việc học tạo ra các tiền tố mềm dễ dàng hơn đối với các siêu mô hình
so với các trọng số LoRA, vì các tiền tố mềm về bản chất là các trạng thái ẩn nội bộ của mô hình, và
các tham số PEFT được tạo ra chính là các biến đổi của các trạng thái ẩn siêu mô hình. Tình cờ, một
cách giải thích khác có thể của mô hình HyperT5-Prefix là sự kết hợp của siêu mô hình và mô hình hạ
nguồn có thể được xem như một mô hình dual-encoder, single-decoder với các encoder riêng biệt cho
các ví dụ few-shot và ví dụ mục tiêu.

Cuối cùng, phần lớn các thí nghiệm được tiến hành với việc điều chỉnh siêu tham số tối thiểu, và các
kết quả hiện tại chủ yếu phục vụ như một bằng chứng khái niệm về siêu tinh chỉnh là một phương pháp
khả thi để thích ứng các mô hình hạ nguồn. Chúng tôi mong đợi rằng việc khám phá thêm các siêu tham
số siêu tiền huấn luyện và MTF cũng như các kiến trúc siêu mô hình có thể dẫn đến kết quả tốt hơn và
vượt qua một số hạn chế mà chúng tôi đã xác định.

--- TRANG 7 ---
5.5 Siêu Tiền Huấn luyện có Cần thiết không?
Chúng tôi chứng minh lợi ích của siêu tiền huấn luyện cho các siêu mô hình trong mục này. Như đã đề
cập trong Mục 3, chúng tôi đã siêu tiền huấn luyện các siêu mô hình trong 100k bước trước khi tinh
chỉnh đa nhiệm vụ chúng trên các nhiệm vụ P3. Để kiểm tra tác động của siêu tiền huấn luyện, chúng
tôi cũng tinh chỉnh đa nhiệm vụ HyperT5-Prefix và HyperT5-LoRA từ T5 LM-adapted mà không có
bất kỳ siêu tiền huấn luyện nào, và từ các checkpoint trung gian trong quá trình siêu tiền huấn luyện.
Hình 4 cho thấy điểm số trung bình trên các nhiệm vụ held-out cho các mô hình này. Cả hai mô hình
HyperT5 đều hoạt động rất kém nếu không có siêu tiền huấn luyện, đạt điểm số tương tự như chỉ PEFT
(xem Bảng 1). Với siêu tiền huấn luyện, hiệu suất của cả hai siêu mô hình cải thiện đáng kể. Trong khi
HyperT5-Prefix dường như cải thiện nhất quán trong suốt 100k bước, chúng tôi quan sát thấy rằng hiệu
suất HyperT5-LoRA giảm nhẹ sau 50k bước. Các siêu mô hình nhắm đến các phương pháp PEFT khác
nhau có thể được hưởng lợi từ các lượng siêu tiền huấn luyện khác nhau, và chúng tôi nhấn mạnh rằng
việc lựa chọn số bước siêu tiền huấn luyện của chúng tôi không được coi là tối ưu.⁶ Chúng tôi mong
đợi rằng các cấu hình siêu tiền huấn luyện tốt hơn có thể được khám phá trong công việc tương lai.

6 Siêu Mô hình cho Khởi tạo Tham số Cải thiện
Cho đến nay, chúng tôi đã thảo luận về các siêu mô hình trong ngữ cảnh tạo ra các tham số PEFT trong
một lượt truyền thuận duy nhất qua siêu mô hình. Chúng tôi cũng có thể xem xét một cách sử dụng thay
thế của các siêu mô hình: Thay vì khởi tạo ngẫu nhiên các tham số mới, chúng ta có thể sử dụng các siêu
mô hình để tạo ra các tham số PEFT đặc trưng cho nhiệm vụ dựa trên một vài ví dụ từ nhiệm vụ. Điều
này có thể được xem như việc sử dụng kiến thức nhiệm vụ thu được bởi siêu mô hình trong quá trình
huấn luyện để cung cấp một xấp xỉ đầu tiên của các tham số PEFT, và sau đó tinh chỉnh các tham số
thông qua huấn luyện PEFT thông thường.

Trong PEFT thông thường, bất cứ nơi nào các tham số mới được đưa vào mô hình, chúng được khởi tạo
ngẫu nhiên, hoặc với các giá trị ban đầu cố định (ví dụ: các trọng số up-projection trong LoRA được khởi
tạo về 0) - để ngắn gọn, chúng tôi sẽ gọi điều này đơn giản là khởi tạo ngẫu nhiên. Ngoài khởi tạo ngẫu
nhiên, Vu et al. (2021, SPoT) và Gu et al. (2021, PPT) đã khám phá việc học chuyển giao trong PEFT,
trước tiên thực hiện PEFT trên một hoặc nhiều nhiệm vụ ngược dòng, và sau đó sử dụng các tham số
PEFT đã học làm khởi tạo cho PEFT hạ nguồn.

Phương pháp này có hai lợi thế so với các khởi tạo PEFT thông thường. Đầu tiên, các tham số được tạo
ra bởi siêu mô hình đã hoạt động tốt trên nhiệm vụ, như đã thể hiện trong Mục 5.3, vì vậy huấn luyện
PEFT có thể đạt hiệu suất tốt nhanh hơn. Thứ hai, siêu mô hình có thể tự động chuyển giao kiến thức
liên quan từ các nhiệm vụ trước đó sang nhiệm vụ mới, tương tự như SPoT và PPT, ngoại trừ việc chúng
tôi để siêu mô hình xác định kiến thức nhiệm vụ đã học trước đó nào phù hợp nhất cho nhiệm vụ mới.
Ví dụ, một thách thức lớn được giải quyết trong SPoT là tìm kiếm tập hợp các nhiệm vụ ngược dòng có
các tham số PEFT sẽ là khởi tạo phù hợp nhất cho một nhiệm vụ hạ nguồn - trong trường hợp của chúng
tôi, chúng tôi có thể trực tiếp cung cấp cho siêu mô hình các ví dụ few-shot để tạo ra khởi tạo mong muốn.

Để điều tra hiệu quả của việc sử dụng các siêu mô hình để tạo ra các khởi tạo PEFT, chúng tôi sử dụng
các mô hình được huấn luyện trên P3 từ Mục 5.3.1, và thực hiện tinh chỉnh tiền tố và tinh chỉnh LoRA
trên các nhiệm vụ held-out riêng lẻ.⁷ Đối với mỗi cặp phương pháp-nhiệm vụ, chúng tôi quét qua các
tốc độ học {1e-3; 1e-4; 1e-5} và lấy kết quả trung bình tốt nhất trên 3 seed ngẫu nhiên.

Chúng tôi xem xét hai baseline cho các khởi tạo: khởi tạo ngẫu nhiên (Rand Init) và sử dụng các tham
số PEFT tinh chỉnh đa nhiệm vụ từ Mục 5.3.1 làm khởi tạo (Shared Init). Khởi tạo được tạo ra bởi
siêu mô hình (Hyper Init) được tạo ra bằng cách sử dụng một tập hợp 16 ví dụ được lấy mẫu ngẫu
nhiên từ các tập huấn luyện tương ứng.

Chúng tôi cho thấy kết quả của tinh chỉnh tiền tố⁸ và tinh chỉnh LoRA với các lược đồ khởi tạo khác nhau
trong Bảng 6. Chúng tôi quan sát thấy rằng đối với cả tinh chỉnh tiền tố và tinh chỉnh LoRA, khởi tạo
chia sẻ vượt trội đáng kể so với khởi tạo ngẫu nhiên, trong khi việc sử dụng khởi tạo được tạo ra bởi
siêu mô hình vượt trội hơn cả hai về trung bình. Chúng tôi cũng cho thấy hiệu suất trung bình qua các
nhiệm vụ trong quá trình tinh chỉnh trong Hình 5. Chúng tôi quan sát thấy rằng các khởi tạo được tạo
ra bởi siêu mô hình bắt đầu với hiệu suất tốt hơn nhiều so với hai lược đồ khởi tạo khác, và tiếp tục
vượt trội hơn chúng trong suốt quá trình tinh chỉnh. Do đó, các siêu mô hình có thể bổ sung cho một
đường ống PEFT tiêu chuẩn, mang lại cả lợi ích về hiệu suất và tiết kiệm chi phí tính toán.

[Bảng 6 và Hình 5]

7 Kết luận
Chúng tôi giới thiệu khái niệm siêu tinh chỉnh, tận dụng một siêu mô hình để thích ứng một mô hình hạ
nguồn với một ứng dụng hạ nguồn cụ thể. Chúng tôi trình bày một khung cơ bản cho siêu tinh chỉnh,
trong đó một siêu mô hình được huấn luyện để tạo ra các tham số cho một mô hình hạ nguồn từ các
ví dụ few-shot trong một lượt truyền thuận, và chúng tôi áp dụng khung này để huấn luyện các mô hình
HyperT5-Prefix và HyperT5-LoRA có thể thích ứng một mô hình T5 hạ nguồn cố định. Chúng tôi thấy
rằng một quy trình huấn luyện hai giai đoạn gồm siêu tiền huấn luyện và tinh chỉnh đa nhiệm vụ có hiệu
quả cho việc huấn luyện các siêu mô hình, và chúng tôi đánh giá các mô hình HyperT5 trên các tập dữ
liệu P3, MetaICL và S-NI, cho thấy rằng chúng có thể tạo ra các tham số PEFT cho phép các mô hình
T5 hạ nguồn hoạt động tốt trên các nhiệm vụ chưa thấy. Hơn nữa, các tham số được tạo ra bởi siêu tinh
chỉnh cũng có thể phục vụ như các khởi tạo tham số cải thiện cho tinh chỉnh hiệu quả tham số. Chúng
tôi coi những phát hiện này như một dấu hiệu ban đầu nhưng đầy khuyến khích về tiềm năng thích ứng
các mô hình ngôn ngữ lớn mà không cần lan truyền ngược.

8 Lời cảm ơn
Chúng tôi xin cảm ơn Sam Bowman vì phản hồi chu đáo của họ và Jonas Pfeiffer vì thảo luận ý tưởng
sớm.

[Các tài liệu tham khảo và phụ lục tiếp theo...]

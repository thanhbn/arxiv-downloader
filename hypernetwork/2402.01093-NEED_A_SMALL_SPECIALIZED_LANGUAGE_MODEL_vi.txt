# CẦN MỘT MÔ HÌNH NGÔN NGỮ NHỎ CHUYÊN BIỆT?
HÃY LÊN KẾ HOẠCH SỚM!

David Grangier, Angelos Katharopoulos, Pierre Ablin & Awni Hannun
Apple

TÓM TẮT

Các mô hình ngôn ngữ lớn là những công cụ đa năng nhưng không phù hợp cho các ngân sách suy luận nhỏ. Các mô hình nhỏ có suy luận hiệu quả hơn, nhưng khả năng thấp hơn của chúng có nghĩa là hiệu suất của chúng chỉ có thể tốt nếu người ta giới hạn phạm vi của chúng vào một lĩnh vực chuyên biệt. Bài báo này khám phá cách có được các mô hình ngôn ngữ nhỏ chuyên biệt tốt bằng cách sử dụng một tập huấn luyện trước lớn, tổng quát và một lượng dữ liệu chuyên biệt hạn chế. Chúng tôi xem xét hai kịch bản, tùy thuộc vào việc (i) có thể đủ khả năng huấn luyện trước một mô hình cho mỗi nhiệm vụ chuyên biệt, hay (ii) muốn thích ứng một cách rẻ tiền một mô hình đã được huấn luyện trước duy nhất cho mỗi nhiệm vụ. Trong kịch bản đầu tiên, chúng tôi đề xuất một giải pháp hiệu quả dựa trên lấy mẫu theo tầm quan trọng: chúng tôi lấy mẫu lại tập huấn luyện trước để bắt chước dữ liệu chuyên biệt và huấn luyện một mô hình nhỏ trên đó. Trong kịch bản thứ hai, chúng tôi đề xuất một kiến trúc mới, mạng chiếu (PN). PN là một mạng lớn có các tham số có thể được chiếu tuyến tính thành một mạng nhỏ để chuyên biệt hóa. Đối với cả hai kịch bản, chúng tôi chứng minh tính hiệu quả thực nghiệm của các giải pháp của chúng tôi trên nhiều lĩnh vực, kích thước tập huấn luyện và ngân sách huấn luyện khác nhau.

1 GIỚI THIỆU

Các Mô hình Ngôn ngữ Lớn (LLM) đã nổi lên như một công cụ tổng quát để giải quyết một loạt các nhiệm vụ ngôn ngữ (Brown et al., 2020; Bommasani et al., 2022). Tính tổng quát này đòi hỏi một tập huấn luyện lớn, đa dạng và tổng quát. Tập này đảm bảo rằng mô hình phù hợp với nhiều lĩnh vực con gần với các nhiệm vụ mà nó sẽ giải quyết cuối cùng. Tính tổng quát của mô hình đặc biệt có tác động đối với các nhiệm vụ mà chi phí thu thập một tập huấn luyện đại diện không thể được biện minh. Tuy nhiên, suy luận LLM tốn kém do số lượng lớn các tham số, cần thiết để phù hợp với một tập huấn luyện lớn. Chi phí này hạn chế LLM cho các ứng dụng có giá trị cao. Suy luận hiệu quả là một lĩnh vực nghiên cứu tích cực theo nhiều hướng như chưng cất mô hình (Hsieh et al., 2023), lượng tử hóa (Dettmers & Zettlemoyer, 2023), cắt tỉa (Ma et al., 2023) hoặc tối ưu hóa phần cứng (Aminabadi et al., 2022). Tuy nhiên, giảm kích thước mô hình là giải pháp trực tiếp nhất cho các ứng dụng dưới các ràng buộc suy luận chặt chẽ, và nó có thể được kết hợp với tất cả các kỹ thuật nêu trên để giảm thêm chi phí suy luận. Với ràng buộc suy luận đó trong tâm trí, chúng tôi tập trung vào việc huấn luyện các Mô hình Ngôn ngữ Nhỏ (SLM).

Một SLM không thể phù hợp với một tập huấn luyện tổng quát cũng như một LLM (Vapnik, 1995; Bishop & Bishop, 2023). Do đó cần thiết phải từ bỏ tính tổng quát của mô hình để dành khả năng hạn chế của nó cho một lĩnh vực chuyên biệt được nhắm mục tiêu. Trong khi một tập huấn luyện chuyên biệt lớn cho ứng dụng sẵn có sẽ là lý tưởng cho việc huấn luyện, một tập như vậy tốn kém và thường chỉ được biện minh cho các ứng dụng có giá trị cao. Do đó, nhiều ứng dụng phải đối mặt với cả ngân sách suy luận hạn chế và kích thước tập huấn luyện trong lĩnh vực hạn chế. Chẳng hạn, một số ứng dụng không thể đủ khả năng thu thập hơn vài triệu token dữ liệu huấn luyện (1m token ≃10 cuốn sách). Những ứng dụng như vậy, với ngân sách suy luận thấp và ngân sách thu thập dữ liệu thấp, đang đối mặt với một vấn đề thách thức.

Công trình này giải quyết chính xác vấn đề này. Chúng tôi nhằm trả lời câu hỏi sau: Làm thế nào chúng ta có thể có được một mô hình ngôn ngữ nhỏ chuyên biệt khi có ít dữ liệu chuyên biệt? Để trả lời câu hỏi này, chúng tôi phân biệt hai kịch bản có tầm quan trọng thực tiễn, mỗi kịch bản dẫn đến các khuyến nghị khác nhau: (i) khi cần một mô hình nhỏ duy nhất cho một lĩnh vực chuyên biệt, có thể xem xét ngân sách huấn luyện lớn cho lĩnh vực đó và có thể huấn luyện trước một mô hình được nhắm mục tiêu cụ thể cho lĩnh vực này; mặt khác, (ii) khi cần một mô hình cho mỗi lĩnh vực cho nhiều lĩnh vực chuyên biệt, việc huấn luyện trước một mô hình cho mỗi lĩnh vực nhanh chóng trở nên quá đắt đỏ, và việc chia sẻ chi phí huấn luyện giữa các lĩnh vực trở nên thú vị.

Đối với cả hai kịch bản, có những đường cơ sở tự nhiên được nghĩ đến. Đường cơ sở đầu tiên bao gồm việc huấn luyện trước một mô hình nhỏ sử dụng tập huấn luyện trước tổng quát lớn và sau đó tinh chỉnh nó với ít dữ liệu chuyên biệt có sẵn. Một phương pháp được sử dụng rộng rãi khác là chưng cất (Hinton et al., 2015): huấn luyện trước một mô hình giáo viên lớn và một mô hình học sinh nhỏ trên tập huấn luyện trước, tinh chỉnh mô hình lớn trên tập chuyên biệt, và sau đó tinh chỉnh mô hình nhỏ với mất mát chưng cất từ mô hình lớn đã được tinh chỉnh.

Trong khi hai đường cơ sở này được sử dụng rộng rãi trong thực tế, đối với cả hai kịch bản, chúng tôi đề xuất các chiến lược huấn luyện trước cải tiến và chứng minh tính ưu việt của chúng. Nền tảng của các chiến lược cải tiến của chúng tôi là việc phân cụm tập huấn luyện trước, cho phép chúng tôi lấy mẫu các điểm dữ liệu từ mỗi cụm của tập huấn luyện trước và huấn luyện trước trên một hỗn hợp của các cụm này với tính linh hoạt để chọn trọng số của mỗi cụm. Khi nhắm mục tiêu một lĩnh vực duy nhất (i), chúng tôi thấy rằng một phương pháp hiệu quả là huấn luyện trước một mô hình nhỏ trên dữ liệu tổng quát với lấy mẫu theo tầm quan trọng (Owen, 2013). Chúng tôi huấn luyện trước trên một hỗn hợp của các cụm trong đó các trọng số được chọn để bắt chước lĩnh vực được nhắm mục tiêu. Chúng tôi cho thấy rằng, mặc dù sự nhấn mạnh này dựa vào thông tin từ dữ liệu chuyên biệt, một mô hình được huấn luyện trước như vậy vẫn hưởng lợi từ việc tinh chỉnh trên dữ liệu chuyên biệt và vượt trội hơn các đường cơ sở trước đó. Khi nhắm mục tiêu nhiều lĩnh vực (ii), chúng tôi đề xuất một kiến trúc mới cho việc huấn luyện trước, mạng chiếu (PN). Mô hình này là một mô hình lớn được huấn luyện trên dữ liệu tổng quát trong đó một số tham số được gắn với một cụm. Quan trọng là, các tham số của nó có thể được chiếu tuyến tính thành các mô hình nhỏ khác nhau — một mô hình cho mỗi cụm — trước khi tinh chỉnh. Khi được cung cấp một lĩnh vực chuyên biệt mới, chúng tôi cho thấy rằng việc chọn một phép chiếu duy nhất và tinh chỉnh mô hình nhỏ tương ứng là hiệu quả. Trong mô hình này, việc huấn luyện mô hình tổng quát có khả năng cao tốn kém, nhưng giai đoạn chuyên biệt của nó (chiếu lên SLM và tinh chỉnh SLM) thì không. Điều này lý tưởng khi cần nhiều mô hình chuyên biệt.

Chúng tôi đánh giá mỗi phương pháp trên nhiều lĩnh vực, ngân sách huấn luyện trước và chuyên biệt cũng như kích thước bộ dữ liệu chuyên biệt. So với các đường cơ sở, cả lấy mẫu theo tầm quan trọng và mạng chiếu đều mang lại cải thiện mạnh mẽ, trên tất cả các lĩnh vực được xem xét, kích thước bộ dữ liệu chuyên biệt và ngân sách huấn luyện. Chúng tôi cho thấy rằng lấy mẫu theo tầm quan trọng dẫn đến độ phức tạp chuyên biệt tốt hơn so với mạng chiếu. Tuy nhiên, lấy mẫu theo tầm quan trọng gây ra chi phí huấn luyện trước cao khi nhắm mục tiêu nhiều lĩnh vực vì việc huấn luyện trước không được chia sẻ giữa các lĩnh vực. Do đó, mạng chiếu có lợi trong kịch bản thứ hai, cho các ứng dụng yêu cầu nhiều mô hình chuyên biệt.

Đóng góp Trong Phần 2, chúng tôi trình bày các chiến lược huấn luyện trước cổ điển cũng như các phương pháp mới của chúng tôi dựa trên việc phân cụm bộ dữ liệu huấn luyện trước. Chúng tôi trình bày chiến lược lấy mẫu theo tầm quan trọng dựa trên cụm. Chúng tôi giới thiệu Mạng Chiếu, một ứng dụng mới cho các mô hình hỗn hợp cứng và siêu mạng, và giải thích cách điều này cung cấp nhiều mô hình có thể được khởi tạo nhanh chóng trong giai đoạn chuyên biệt. Trong Phần 3, chúng tôi đề xuất một phương pháp để đánh giá các chiến lược khác nhau để huấn luyện SLM chuyên biệt và xác định bốn biến quan trọng: ngân sách huấn luyện tổng quát (để huấn luyện trước khi lĩnh vực mục tiêu được biết), ngân sách chuyên biệt (để huấn luyện sau khi lĩnh vực mục tiêu được biết), ngân sách suy luận, và kích thước tập huấn luyện trong lĩnh vực. Trong Phần 4, chúng tôi cung cấp một nghiên cứu thực nghiệm toàn diện bằng cách báo cáo các thí nghiệm trên 9 lĩnh vực, 3 kích thước tập huấn luyện chuyên biệt với các ngân sách huấn luyện khác nhau. Chúng tôi cho thấy rằng, như mong đợi, tinh chỉnh là cần thiết. Đáng ngạc nhiên, chúng tôi nhấn mạnh rằng chưng cất từ một mô hình lớn, mặc dù phổ biến, mang lại ít cải thiện khi tính đến tổng ngân sách huấn luyện trước. Chúng tôi cho thấy rằng phương pháp lấy mẫu theo tầm quan trọng dựa trên cụm của chúng tôi rất hiệu quả để huấn luyện các mô hình chuyên biệt trong trường hợp ngân sách chuyên biệt lớn. Cuối cùng, chúng tôi thấy rằng Mạng Chiếu dẫn đến các mô hình tốt nhất trong trường hợp ngân sách chuyên biệt nhỏ. Hình 1 tóm tắt các khuyến nghị thực tế của chúng tôi.

2 PHƯƠNG PHÁP

Chúng tôi xem xét các chiến lược khác nhau để tận dụng một tập huấn luyện trước tổng quát lớn dưới các ràng buộc suy luận.

2.1 BỘ DỮ LIỆU TỔNG QUÁT VÀ CHUYÊN BIỆT

Chúng tôi có quyền truy cập vào một tập huấn luyện trước tổng quát lớn, thường được thu thập như đầu ra của một quá trình thu thập web. Tập này lớn: nó có đủ mẫu để huấn luyện một mô hình trên nó hoặc trên một tập con của nó mà không có rủi ro quá khớp. Tập này tổng quát: nó bao gồm một loạt các chủ đề và khái niệm đa dạng. Chúng tôi huấn luyện các mô hình trên tập này sử dụng mất mát dự đoán token tiếp theo.

Chúng tôi cũng có quyền truy cập vào một tập chuyên biệt nhỏ, có thể là, chẳng hạn, tài liệu nội bộ của một công ty, một số email, hoặc một tập các bài báo khoa học. Tập này nhỏ: không thể huấn luyện một mô hình tốt trên nó mà không quá khớp. Tập này chuyên biệt: nó chỉ bao gồm các chủ đề cụ thể. Một lần nữa, chúng tôi đo chất lượng của các mô hình trên tập này với mất mát dự đoán token tiếp theo và độ phức tạp.

2.2 ĐƯỜNG CƠ SỞ: MÔ HÌNH NHỎ, TINH CHỈNH & CHƯNG CẤT

Chúng tôi nhắm mục tiêu một mô hình có độ phức tạp chuyên biệt tốt dưới các ràng buộc suy luận. Chúng tôi trừu tượng hóa các ràng buộc suy luận như một giới hạn về kích thước mô hình. Chúng tôi gọi Mô hình Ngôn ngữ Nhỏ (SLM) là một transformer có kích thước tối đa có thể được phép bởi ràng buộc suy luận.

Chúng tôi xem xét 3 biến thể của SLM. Đầu tiên chúng tôi xem xét một mô hình SLM được huấn luyện chỉ trên dữ liệu huấn luyện trước tổng quát. Mô hình này có thể hiệu quả nếu dữ liệu tổng quát và chuyên biệt gần nhau. Sau đó chúng tôi xem xét một SLM được huấn luyện chỉ trên dữ liệu chuyên biệt. Mô hình này có thể hiệu quả nếu tập huấn luyện chuyên biệt đủ lớn nhưng sẽ nhanh chóng quá khớp khi tập chuyên biệt nhỏ. Cuối cùng, chúng tôi xem xét một mô hình được huấn luyện trước trên dữ liệu tổng quát và tinh chỉnh trên dữ liệu chuyên biệt. Mức độ tinh chỉnh có thể được điều chỉnh thông qua dừng sớm. Điều này điều chỉnh sự đánh đổi giữa sự gần gũi với phân phối tổng quát và quá khớp với tập chuyên biệt. Huấn luyện và tinh chỉnh được thực hiện bằng cách tối thiểu hóa mất mát dự đoán token tiếp theo trên các bộ dữ liệu tương ứng.

Vì ràng buộc khả năng của chúng tôi được thúc đẩy bởi hiệu quả suy luận, chúng tôi có thể xem xét các mô hình lớn hơn tại thời điểm huấn luyện và dựa vào chưng cất (Hinton et al., 2015) để đáp ứng các yêu cầu suy luận. Cụ thể, chúng tôi xem xét một mô hình ngôn ngữ lớn (LLM) có kích thước lớn hơn so với ràng buộc suy luận cho phép. Chúng tôi huấn luyện trước nó trên tập huấn luyện trước tổng quát, và sau đó tinh chỉnh nó trên tập chuyên biệt, đạt được độ phức tạp thấp hơn trên tập chuyên biệt so với SLM được huấn luyện trước rồi tinh chỉnh nhờ kích thước lớn hơn. Một SLM học sinh được huấn luyện trước sau đó được tinh chỉnh với một hỗn hợp của dữ liệu chuyên biệt và phân phối từ tiếp theo từ giáo viên. Chúng tôi gọi mô hình này là SLM-d.

Loại chưng cất này thường được gọi là Chưng cất Kiến thức dựa trên Phản hồi trong tài liệu (Gou et al., 2021, Phần 2.1) và có thể nói là loại chưng cất được sử dụng rộng rãi nhất. Chúng tôi không xem xét việc sử dụng LLM như một công cụ tăng cường dữ liệu (Feng et al., 2021), để tạo ra dữ liệu tổng hợp (Tang et al., 2019; West et al., 2021) tương tự dữ liệu chuyên biệt, và sau đó sử dụng chúng để huấn luyện hoặc tinh chỉnh mô hình nhỏ. Thực vậy, điều này đòi hỏi việc huấn luyện một LLM, mất thời gian, và trong thiết lập của chúng tôi, điều này dẫn đến nhiều biến động hơn so với chưng cất kiến thức dựa trên phản hồi và hiệu suất tổng thể kém hơn (Menon et al., 2021).

2.3 PHÂN CỤM DỮ LIỆU HUẤN LUYỆN TRƯỚC

Các chiến lược tiếp theo dựa vào việc phân cụm tập huấn luyện trước tổng quát. Phân cụm liên kết mỗi ví dụ huấn luyện với một biến tiềm ẩn rời rạc mà chúng tôi sử dụng để ước tính hiệu quả các trọng số lấy mẫu theo tầm quan trọng với một giả định độc lập có điều kiện (Phần 2.4). Nó cũng cho phép chúng tôi điều kiện hóa phép chiếu trong mạng chiếu (Phần 2.5).

Để phân cụm dữ liệu, chúng tôi nhúng mỗi tài liệu trong tập tổng quát như một vector sử dụng Sentence BERT (Reimers & Gurevych, 2019). Các tài liệu dài hơn ngữ cảnh tối đa mà chúng tôi xem xét (1,024) được chia thành các cửa sổ không chồng lấp. Sau đó, chúng tôi sử dụng thuật toán k-means để phân cụm tập tổng quát thành k cụm. Chúng tôi sau đó có thể truy vấn các mẫu từ mỗi cụm.

2.4 LẤY MẪU THEO TẦM QUAN TRỌNG DỰA TRÊN CỤM

Lấy Mẫu theo Tầm quan trọng (IS) là một phương pháp được thiết lập tốt (Owen, 2013) cho phép ước tính kỳ vọng của một biến (mất mát dự đoán token tiếp theo trong trường hợp của chúng tôi) trên một phân phối (phân phối chuyên biệt), trong khi lấy mẫu từ một phân phối khác (phân phối tổng quát). Trong thực tế, IS cần ước tính các trọng số tầm quan trọng từ dữ liệu. Chúng tôi tận dụng việc phân cụm tập huấn luyện trước được đề xuất ở trên để làm cho việc ước tính trọng số tầm quan trọng trở nên dễ dàng, bằng cách giả định dữ liệu của chúng tôi được lấy mẫu từ một hỗn hợp trên các cụm. Mất mát chuyên biệt là

L(Dspec;θ) = Ex∼Dspec[ℓ(x;θ)] = ∑x ℓ(x;θ)P(x|Dspec).

Chúng tôi giới thiệu một biến thành viên cụm tiềm ẩn c, và đưa ra một giả định độc lập P(x|c, Dspec) = P(x|c), tạo ra

L(Dspec;θ) = ∑x ∑c ℓ(x;θ)P(x|c, Dspec)P(c|Dspec) = ∑x ∑c ℓ(x;θ)P(x|c)P(c|Dspec).

Sau đó chúng tôi áp dụng lấy mẫu theo tầm quan trọng,

L(Dspec;θ) = ∑x ∑c ℓ(x;θ)P(x|c)P(c|Dspec) P(c|Dgeneric)/P(c|Dgeneric) = Ex∼Dgeneric[w(x)ℓ(x;θ)]

với trọng số tầm quan trọng w(x) = P(c(x)|Dspec)/P(c(x)|Dgeneric) và c(x) biểu thị cụm duy nhất c sao cho P(x|c) > 0. Do đó, các trọng số tầm quan trọng có thể được ước tính như tỷ lệ giữa tần suất cụm trong tập huấn luyện tổng quát và chuyên biệt. Số lượng cụm k là một sự đánh đổi giữa k lớn (ước tính tần suất cụm không đáng tin cậy cho tập chuyên biệt, rủi ro quá khớp với tập đó) và k nhỏ (giả định độc lập mạnh hơn khi các cụm lớn). Các mô hình nhỏ được huấn luyện với lấy mẫu theo tầm quan trọng được gọi là SLM-is.

2.5 MÔ HÌNH BẤT ĐỐI XỨNG: MẠNG CHIẾU VÀ HỖN HỢP CỨNG

Các ràng buộc suy luận của chúng tôi yêu cầu rằng mô hình chuyên biệt cuối cùng là một SLM có khả năng thấp. Trước khi tinh chỉnh trên dữ liệu chuyên biệt, giới hạn khả năng không áp dụng cho việc huấn luyện trước tổng quát. Chúng tôi đưa ra một chiến lược huấn luyện trước để tận dụng sự bất đối xứng này. Tại thời điểm huấn luyện trước, chúng tôi huấn luyện một mạng với nhiều tham số, nhưng mỗi ví dụ chỉ tương tác với một phép chiếu của các tham số lên một SLM. Giống như chưng cất, chiến lược này huấn luyện một mô hình với nhiều tham số, nhưng không giống như chưng cất, tất cả các đánh giá mô hình trong quá trình huấn luyện đã được ràng buộc để hoạt động trong giới hạn kích thước.

Mạng chiếu Mạng Chiếu (PN) của chúng tôi, SLM-pn, huấn luyện cùng nhau một tập hợp các mô hình nhỏ hoặc chuyên gia, {SLM-pni}ki=1; có một chuyên gia cho mỗi cụm i. Mỗi chuyên gia được khởi tạo thông qua phép chiếu tuyến tính cụ thể của nó của các tham số lớn; xem Hình 2. Chúng tôi huấn luyện một mạng PN với nhiều tham số trong quá trình huấn luyện trước tổng quát. Khi dữ liệu huấn luyện chuyên biệt có sẵn, việc tinh chỉnh chuyên biệt bắt đầu từ một trong các chuyên gia. Các chiến lược khác nhau cho việc lựa chọn chuyên gia được thảo luận trong các thí nghiệm của chúng tôi.

Mô hình PN thêm tham số vào các lớp tuyến tính của một mô hình. Nó được cấu hình thông qua 3 siêu tham số h, k, m. h là một hệ số nhân tăng tổng số tham số trong khi k kiểm soát số lượng chuyên gia / cụm. Cuối cùng, m kiểm soát số lượng tham số được phân bổ cụ thể cho mỗi chuyên gia. Đối với mỗi SLM-pni, ma trận tham số W(l,i) ∈ ℝd×d′ của lớp l được tính toán thông qua một phép chiếu tuyến tính,

W(l,i)a,b = ∑mq=1 Ei,q ∑hr=1 M(l)q,r T(1,l)a,b,r cho a = 1...d và b = 1...d′

trong đó Ei ∈ ℝm là một vector cụ thể cho chuyên gia, M(l) ∈ ℝm×h là một ma trận cụ thể cho lớp và T(1,l) ∈ ℝd×d′×h là một tensor lưu trữ hầu hết các tham số. Trong các thí nghiệm của chúng tôi, các chuyên gia SLM-pn của chúng tôi là transformers và chúng tôi chỉ áp dụng phép phân tích PN cho các lớp feed-forward (tức là mạng neural đa lớp, MLP) có chứa hầu hết các tham số mô hình. Các tham số khác được chia sẻ.

PN có thể thiết lập riêng biệt kích thước mạng tổng thể thông qua h và số lượng chuyên gia riêng biệt thông qua k. Chúng tôi huấn luyện một chuyên gia cho mỗi cụm, sử dụng việc phân cụm từ Phần 2.3. Chúng tôi liên kết mỗi ví dụ huấn luyện x với một biến cụm c(x) = 1...k và mất mát của nó trên x được tính toán với SLM-pnc(x). Việc huấn luyện tối ưu hóa tất cả chuyên gia cùng nhau bằng cách tối thiểu hóa mất mát kỳ vọng trên tập tổng quát.

Để chuyên biệt, chúng tôi chọn một chuyên gia SLM-pni và tinh chỉnh nó trên bộ dữ liệu chuyên biệt. Trong số các chiến lược khác nhau mà chúng tôi đánh giá để lựa chọn chuyên gia, chúng tôi thấy rằng việc chọn chuyên gia được huấn luyện trước tương ứng với cụm thường xuyên nhất trong bộ dữ liệu chuyên biệt là một chiến lược hiệu quả.

Hỗn hợp Cứng của Chuyên gia Như một thay thế đơn giản cho kiến trúc trước đó, chúng tôi xem xét SLM-mix, một hỗn hợp cứng của chuyên gia (Gross et al., 2017). Chúng tôi huấn luyện trước một SLM, SLM-mixi, trên mỗi cụm i, độc lập. Chi phí huấn luyện trước và tổng số tham số của phương pháp này cao vì cả hai đều tăng tuyến tính với số lượng cụm. Hỗn hợp cứng có thể được so sánh với một trường hợp đặc biệt của mạng PN trong đó h = k, Ei = δi ∈ ℝk và M(l) = I. Trong trường hợp đó, tất cả các ma trận trọng số dựa vào các lát cắt độc lập của các tham số. Không giống như PN, hỗn hợp cứng không cho phép thiết lập số lượng chuyên gia k và hệ số nhân khả năng h độc lập. Các tham số chuyên gia không được chia sẻ và việc học không thể tận dụng sự cộng hưởng giữa các cụm tương tự. Mặt khác, việc học có thể song song hóa một cách dễ dàng vì mỗi việc huấn luyện trước chuyên gia độc lập với các chuyên gia khác. Giống như PN, việc chuyên biệt có thể được thực hiện một cách không tốn kém bằng cách tinh chỉnh một chuyên gia duy nhất. Mặc dù có những khác biệt về khái niệm này, các thí nghiệm của chúng tôi tiết lộ lợi ích trong cả hai phương pháp.

3 THIẾT LẬP THỰC NGHIỆM

3.1 PHƯƠNG PHÁP LUẬN

Với các ràng buộc về chi phí suy luận và dữ liệu huấn luyện chuyên biệt, chúng tôi nghiên cứu các phương pháp huấn luyện thay thế ở các chi phí huấn luyện khác nhau. Chúng tôi báo cáo chi phí huấn luyện và phần nào của chi phí có thể được chia sẻ giữa nhiều lĩnh vực. Chúng tôi xem xét 4 chỉ số quan trọng:

Chi phí huấn luyện tổng quát: chi phí của giai đoạn huấn luyện có thể được thực hiện trước khi dữ liệu chuyên biệt có sẵn, trên một tập huấn luyện tổng quát. Chi phí này thường được gọi là huấn luyện trước. Nó độc lập với lĩnh vực và có thể được chia sẻ giữa nhiều chuyên biệt, ví dụ, thông qua tinh chỉnh sau đó. Mặc dù không bắt buộc, dữ liệu huấn luyện tổng quát là cần thiết khi dữ liệu chuyên biệt hạn chế.

Chi phí huấn luyện chuyên biệt: chi phí của việc huấn luyện được thực hiện khi dữ liệu chuyên biệt có sẵn. Chi phí này không được chia sẻ giữa các chuyên biệt khác nhau.

Chi phí suy luận: chi phí chạy suy luận trên một mô hình chuyên biệt. Chi phí suy luận thấp cho phép triển khai mô hình rộng rãi hơn, rẻ hơn.

Kích thước của tập huấn luyện chuyên biệt: nó thay đổi giữa các ứng dụng và ảnh hưởng đến lựa chọn huấn luyện trước và chuyên biệt.

Lấy chi phí suy luận và kích thước dữ liệu chuyên biệt làm ràng buộc cứng, chúng tôi nghiên cứu các đường cong hoạt động tạo ra từ việc thay đổi chi phí huấn luyện tổng quát và chuyên biệt. Chúng tôi đo chi phí huấn luyện (huấn luyện trước và chuyên biệt) bằng giờ tính toán bộ xử lý đồ họa (GPUh) trên cùng phần cứng (Nvidia-A100). Chúng tôi xem xét chi phí huấn luyện trước từ 10 đến 650 GPUh và chi phí chuyên biệt từ 0,3 đến 120 GPUh.

Chúng tôi đánh giá mô hình hóa ngôn ngữ với độ phức tạp, sử dụng 20k tài liệu được giữ lại cho mỗi bộ dữ liệu. Chúng tôi chỉ tập trung vào mô hình hóa ngôn ngữ; việc đánh giá các mô hình trên các nhiệm vụ hạ lưu (ví dụ trả lời câu hỏi, phân tích cảm xúc, dịch thuật, v.v.) nằm ngoài phạm vi của bài báo. Tuy nhiên, kết luận của chúng tôi có thể mở rộng đến các nhiệm vụ hạ lưu vì độ phức tạp và hiệu suất hạ lưu thường có tương quan Gonen et al. (2022); Du et al. (2024); Gadre et al. (2024). Chúng tôi báo cáo độ phức tạp trên dữ liệu tổng quát và chuyên biệt. Đối với các lĩnh vực chuyên biệt khác nhau. Chúng tôi báo cáo độ phức tạp theo lĩnh vực trong Phụ lục E và trình bày kết quả trung bình macro trong Phần 4. Đối với độ phức tạp trung bình macro, chúng tôi tính toán log-likelihood âm trung bình cho mỗi token cho mỗi lĩnh vực, trung bình các kết quả này, và tính số mũ.

3.2 BỘ DỮ LIỆU

Tập huấn luyện trước tổng quát của chúng tôi là c4, một bộ dữ liệu lớn được lọc của văn bản tiếng Anh có nguồn gốc từ common-crawl (Raffel et al., 2020). Chúng tôi token hóa dữ liệu với một mô hình sentence piece được huấn luyện trên c4 với kích thước từ vựng là 32k. Chúng tôi sử dụng phương pháp phân cụm được mô tả trong Phần 2.3 để chia bộ dữ liệu này thành k cụm. Chúng tôi sử dụng k = 1024 cho SLM-is, và k = 32 cho SLM-pn và SLM-mix. Chúng tôi điều tra tác động của số lượng cụm trong Phụ lục D.

Chúng tôi xem xét việc chuyên biệt cho chín lĩnh vực đa dạng, được trích xuất từ Pile (Gao et al., 2021): arxiv (bài báo khoa học), europarl (thủ tục nghị viện), freelaw (văn bản pháp lý), gutenberg (sách cũ được xuất bản trước 1919), opensubtitles (phụ đề kịch), openwebtext2 (thảo luận diễn đàn), pubmed-abstracts (tóm tắt bài báo y khoa), stackexchange (hỏi đáp chủ yếu về các chủ đề kỹ thuật), wikipedia (bài báo bách khoa toàn thư). Chúng tôi thay đổi lượng dữ liệu huấn luyện chuyên biệt có sẵn và xem xét các tập có kích thước 1, 8 và 64 triệu token cho mỗi lĩnh vực.

3.3 SIÊU THAM SỐ MÔ HÌNH

Bảng 1 báo cáo số lượng tham số cho các mô hình được huấn luyện trước và chuyên biệt. Bảng 1 minh họa rằng SLM-pn và SLM-mix (Phần 2.5) nhỏ như SLM để suy luận sau chuyên biệt trong khi tổng số tham số được huấn luyện trước của chúng lớn hơn LLM. Bảng 2 báo cáo thông lượng của các mô hình. Tất cả các mô hình SLM có cùng thông lượng chuyên biệt trong khi SLM-pn có thông lượng thấp hơn SLM, SLM-mix để huấn luyện trước. LLM đắt hơn trong tất cả các trường hợp. Bảng 3 trình bày giới hạn trên trong ngân sách huấn luyện cho huấn luyện trước và chuyên biệt trên tất cả các thiết lập. Phụ lục A báo cáo các siêu tham số huấn luyện.

4 ĐÁNH GIÁ THỰC NGHIỆM

Đầu tiên chúng tôi báo cáo kết quả chính của chúng tôi trước khi so sánh các phương pháp khác nhau. Chúng tôi thay đổi ngân sách huấn luyện trước và báo cáo độ phức tạp trên tập huấn luyện trước tổng quát (c4) cho mỗi phương pháp trong Hình 3. Khi chúng tôi xem xét SLM-pn và SLM-mix, chúng tôi quan sát rằng ngay cả khi số lượng tham số được huấn luyện trước lớn hơn LLM, chúng không có độ phức tạp tốt như vậy. Tuy nhiên, độ phức tạp của chúng tốt hơn SLM trong khi chúng hiệu quả như nhau khi được kiểm tra hoặc tinh chỉnh trên một cụm duy nhất.

Độ phức tạp tổng quát (c4) không phải là mục tiêu chính của chúng tôi và bây giờ chúng tôi xem xét độ phức tạp chuyên biệt. Hình 4 (a) báo cáo kết quả trước khi tinh chỉnh. Độ phức tạp chuyên biệt cao hơn nhiều so với độ phức tạp c4, cho thấy rằng chuyên biệt là cần thiết. Hình 4 (b) báo cáo kết quả sau khi tinh chỉnh một số checkpoint được huấn luyện trước cho mỗi phương pháp trên bộ dữ liệu 1M token của mỗi lĩnh vực. Mỗi mô hình cụ thể cho lĩnh vực được đánh giá trước khi trung bình macro. Vì 1M token là một tập nhỏ, việc tinh chỉnh dựa vào tốc độ học nhỏ và dừng sớm (tốc độ học cơ sở chia cho 3, dừng khi mất mát validation ngừng cải thiện, luôn ít hơn 2k bước tinh chỉnh trên một GPU khi mất mát validation ngừng cải thiện). Tinh chỉnh rất có lợi cho tất cả các phương pháp và dẫn đến độ phức tạp được cải thiện đáng kể. Chúng tôi cũng nhận xét rằng độ phức tạp trước tinh chỉnh trên Pile không nhất thiết là một chỉ báo tốt của độ phức tạp sau tinh chỉnh: ví dụ thứ tự các checkpoint SLM rất khác nhau trên hai đường cong, thứ tự giữa SLM-mix và SLM-pn cũng thay đổi trong quá trình tinh chỉnh.

Chúng tôi cũng xem xét việc tinh chỉnh trên 8 và 64 triệu token cho mỗi lĩnh vực, xem Hình 4 (c) và (d). Nhiều dữ liệu hơn cho phép chúng tôi huấn luyện lâu hơn một chút và giữ tốc độ học cơ sở mà không quá khớp. Chúng tôi dừng nhiều nhất sau 4k bước và 30k bước cho các trường hợp 8M và 64M tương ứng. Chúng tôi quan sát rằng lợi ích của một điểm khởi đầu tốt được cung cấp bởi SLM-pn và SLM-mix (so với SLM) bị xói mòn khi kích thước tập huấn luyện lĩnh vực tăng.

Các hình này báo cáo độ phức tạp của SLM-is như một đường thẳng. Phương pháp này không có huấn luyện trước tổng quát vì việc huấn luyện của nó chỉ bắt đầu khi dữ liệu lĩnh vực có sẵn; chịu tất cả chi phí huấn luyện trong giai đoạn chuyên biệt. SML-is là phương pháp tốt nhất với một mô hình suy luận nhỏ về độ phức tạp sau chuyên biệt. Thú vị là, nó thậm chí vượt trội hơn mô hình lớn hơn nhiều khi dữ liệu chuyên biệt khan hiếm (tức trường hợp 1M token), với một phần chi phí huấn luyện tổng thể (<130 GPUh).

4.1 ĐƯỜNG CƠ SỞ: TINH CHỈNH, CHƯNG CẤT

Bảng 4 so sánh độ phức tạp trên các tập con Pile cho các mô hình transformer cơ sở. Huấn luyện trước và tinh chỉnh đều cần thiết để đạt được độ phức tạp tốt trên các tập chuyên biệt của chúng tôi. Không có huấn luyện trước, cần rất nhiều dữ liệu chuyên biệt (64M token cho mỗi lĩnh vực) để có hiệu suất chấp nhận được. Đối với cả mô hình lớn và nhỏ, có một khoảng cách lớn về độ phức tạp trước và sau tinh chỉnh, làm rõ rằng tinh chỉnh ngay cả trên 1M token trong lĩnh vực có thể dẫn đến sự tăng hiệu suất đáng kể. Cuối cùng, như mong đợi, kết quả LLM cũng minh họa rằng, đối với ngân sách suy luận và huấn luyện trước lớn, việc huấn luyện các mô hình lớn trên tập huấn luyện trước (c4) là có lợi.

Quy trình chưng cất của chúng tôi lấy một giáo viên được huấn luyện trước (LLM) và một học sinh được huấn luyện trước (SLM). Chúng tôi tinh chỉnh giáo viên trên tập chuyên biệt và chúng tôi sử dụng giáo viên đã được tinh chỉnh để giám sát học sinh trên cùng tập đó. Trong quy trình này, chi phí huấn luyện trước tổng quát cộng hai thành phần: huấn luyện trước giáo viên và học sinh. Hình 5 (trái) báo cáo độ phức tạp SLM-d với mỗi đường cong tương ứng với một lượng huấn luyện trước giáo viên khác nhau và có huấn luyện trước học sinh làm trục x. Nó cho thấy rằng đối với các thiết lập trên 276 GPUh huấn luyện trước giáo viên (300k bước), mô hình học sinh SLM-d tốt hơn đáng kể so với SLM vanilla ở cùng mức huấn luyện trước học sinh. Biểu đồ này chứng minh lợi ích của một giáo viên tốt so với một SLM được huấn luyện chỉ trên tập chuyên biệt. Hình 5 (phải) cho thấy SLM-pn và SLM-mix đạt được độ phức tạp chuyên biệt tốt hơn SLM-d khi so sánh tổng chi phí huấn luyện trước, tính đến chi phí huấn luyện giáo viên. Ngay cả khi không tính chi phí huấn luyện giáo viên, lợi ích của SLM-d nhanh chóng biến mất so với SLM-pn và SLM-mix.

4.2 LẤY MẪU THEO TẦM QUAN TRỌNG

Chiến lược lấy mẫu theo tầm quan trọng của chúng tôi lấy mẫu lại tập tổng quát (c4) sao cho biểu đồ cụm của nó khớp với biểu đồ cụm từ tập chuyên biệt (tập con Pile). Mô hình này đòi hỏi một bộ dữ liệu tổng quát được lấy mẫu lại khác nhau cho mỗi nhiệm vụ chuyên biệt. Điều này làm cho SLM-is tốn kém khi giải quyết nhiều nhiệm vụ. Đối với một mô hình, tổng chi phí chuyên biệt trên N nhiệm vụ là

Ctotal(N) = Cgeneric + Cspecialization × N. (1)

Đối với các phương pháp như PN, hầu hết chi phí là Cgeneric và tham số chính để thay đổi tổng chi phí là số lượng bước huấn luyện trước tổng quát. Đối với phương pháp lấy mẫu theo tầm quan trọng, Cgeneric = 0 và tham số chính để thay đổi tổng chi phí là số lượng bước được thực hiện khi huấn luyện trên tập huấn luyện trước được lấy mẫu theo tầm quan trọng, là một phần của Cspecialization.

Chúng tôi thay đổi tổng chi phí cho SLM-pn và SLM-is khi giả thuyết giải quyết 1, 7 và 50 nhiệm vụ bằng cách chia tỷ lệ trục x theo Phương trình 1. Hình 6 cho thấy rằng SLM-is trở nên kém thú vị hơn khi số lượng nhiệm vụ tăng. Chi phí chuyên biệt của việc tinh chỉnh cho SLM-pn, tăng tuyến tính với số lượng nhiệm vụ, có thể được bỏ qua vì nó mất ~1 phút GPU.

4.3 MÔ HÌNH BẤT ĐỐI XỨNG: HỖN HỢP CỨNG CỦA CHUYÊN GIA VÀ MẠNG CHIẾU

Mạng chiếu cho phép chọn tổng số tham số của mạng trong khi giữ kích thước của mô hình suy luận không đổi. Không giống như hỗn hợp cứng của chuyên gia, việc thay đổi khả năng không đòi hỏi thay đổi số lượng cụm. Do đó khả năng PN là một sự đánh đổi giữa chi phí huấn luyện trước tổng quát và độ chính xác chuyên biệt. Hình 7 cho thấy độ phức tạp trên các tập con Pile sau khi tinh chỉnh trên 1M token như một hàm của chi phí huấn luyện trước. Trong khi nhiều chuyên gia hơn luôn hoạt động tốt hơn mỗi lần lặp, 32 chuyên gia đạt được sự đánh đổi chi phí/độ phức tạp tốt hơn.

Hỗn hợp cứng của chuyên gia dựa vào việc chia tập dữ liệu tổng quát thành các cụm, xem Phần 2.3, và số lượng chuyên gia của nó tương ứng với số lượng cụm. Để chuyên biệt, chúng tôi tinh chỉnh một chuyên gia duy nhất. Kết quả được trình bày ở trên, ví dụ Hình 4, sử dụng chuyên gia tương ứng với cụm thường xuyên nhất trong dữ liệu chuyên biệt. Ngoài ra, chúng tôi cũng xem xét việc chọn chuyên gia có mất mát thấp nhất trên tập chuyên biệt trước khi tinh chỉnh, liên quan đến việc đánh giá mỗi chuyên gia. Như một tùy chọn thứ ba tốn kém hơn, chúng tôi tinh chỉnh tất cả chuyên gia và chọn chuyên gia tốt nhất hậu nghiệm. Bảng 5 báo cáo kết quả này khi tinh chỉnh trên 1M token với 64 chuyên gia. Kết quả của các chiến lược khác nhau gần nhau, ±0,3 PPL, và tùy chọn tốn kém nhất của việc tinh chỉnh tất cả chuyên gia hoạt động tốt hơn một chút.

Như một quan sát cuối cùng về SLM-mix, chiến lược tinh chỉnh chỉ chuyên gia tương ứng với cụm thường xuyên nhất có thể rất hiệu quả khi nhắm mục tiêu một lĩnh vực duy nhất. Trong trường hợp đó, có thể chỉ huấn luyện chuyên gia cho cụm duy nhất quan tâm. Chiến lược huấn luyện cụm đơn này tuy nhiên là một xấp xỉ kém hơn của phân phối chuyên biệt so với IS, như được hiển thị trong Hình 8.

5 CÔNG TRÌNH LIÊN QUAN

Thích ứng lĩnh vực cho mô hình hóa ngôn ngữ có một lịch sử lâu dài, có trước các mô hình ngôn ngữ mạng neural Rosenfeld (2000). Nghiên cứu này bắt nguồn từ quan sát rằng các mô hình được huấn luyện trên lượng lớn dữ liệu, ngay cả xa lĩnh vực được nhắm mục tiêu cũng có tác động đến các ứng dụng cuối Brants et al. (2007). Sau khi các mô hình ngôn ngữ neural được giới thiệu Bengio et al. (2000), chúng cũng được mở rộng quy mô để hưởng lợi từ việc tăng lượng dữ liệu huấn luyện Raffel et al. (2020); Brown et al. (2020); Chowdhery et al. (2022); Touvron et al. (2023). Sự tăng trưởng này liên quan đến một sự đánh đổi giữa việc huấn luyện một mô hình từ một bộ dữ liệu lớn (tức giảm lỗi ước tính) hoặc một bộ dữ liệu đại diện cho lĩnh vực ứng dụng cuối (tức có phân phối huấn luyện đại diện cho điều kiện kiểm tra), cả hai đều cần thiết cho khái quát hóa tốt Vapnik (1995).

Tinh chỉnh mô hình và học đa nhiệm vụ đã trở thành các công cụ thiết yếu để vừa hưởng lợi từ dữ liệu huấn luyện tổng quát lớn và dữ liệu trong lĩnh vực hạn chế Caruana (1993); Collobert et al. (2011); Gururangan et al. (2020). Các phương pháp sắp xếp và lựa chọn dữ liệu cũng đã được đề xuất để lấy mẫu lại dữ liệu tổng quát với một lĩnh vực ứng dụng cụ thể trong tâm trí Moore & Lewis (2010); Wang et al. (2018); Xie et al. (2023). Hầu hết các phương pháp này có thể được gắn với lấy mẫu theo tầm quan trọng Kahn & Harris (1951); Grangier & Iter (2022).

Đồng thời với sự tăng trưởng về kích thước mô hình ngôn ngữ lớn, mối quan tâm về chi phí suy luận mô hình đã dẫn đến nghiên cứu về suy luận hiệu quả. Nhiều hướng được điều tra với mục tiêu này, bao gồm chưng cất mô hình Hsieh et al. (2023); FitzGerald et al. (2022), lượng tử hóa trọng số Xiao et al. (2023); Dettmers & Zettlemoyer (2023) và cắt tỉa Ma et al. (2023); Xia et al. (2023). Hỗn hợp chuyên gia đã được điều tra như một cách để tách rời khả năng mô hình tổng thể và hiệu quả suy luận Shazeer et al. (2017); Du et al. (2022); Clark et al. (2022).

Mạng chiếu bất đối xứng của chúng tôi có thể được xem như các siêu mạng, một loại mạng neural có các tham số tự được dự đoán bởi một mạng thứ cấp Ha et al. (2017); Karimi Mahabadi et al. (2021). Trong trường hợp của chúng tôi, mạng thứ cấp là một phép chiếu tuyến tính có điều kiện cụm.

6 HẠN CHẾ

Thực nghiệm của chúng tôi bao gồm nhiều lĩnh vực, ngân sách huấn luyện và kích thước tập huấn luyện nhưng, tại thời điểm này, chúng tôi chưa khám phá nhiều kích thước cho SLM của chúng tôi. Chúng tôi muốn xác minh trong tương lai liệu ưu thế của PN so với chưng cất có mở rộng đến các cặp kích thước mô hình lớn/nhỏ khác nhau. Tương tự, chúng tôi đã nghiên cứu tác động của số lượng cụm trên SLM-is, SLM-pn và SLM-mix nhưng tất cả các thí nghiệm phân cụm của chúng tôi đều đại diện cho các tài liệu với sentence BERT, trong khi các đại diện khác nhau có thể ảnh hưởng đến kết quả của chúng tôi.

7 KẾT LUẬN

Công trình này xem xét một ràng buộc thực tế kép phổ biến cho mô hình hóa ngôn ngữ: sự khan hiếm của dữ liệu huấn luyện trong lĩnh vực và ngân sách suy luận hạn chế. Chúng tôi đề xuất huấn luyện các mô hình ngôn ngữ nhỏ, hiệu quả và cải thiện độ chính xác của chúng bằng cách suy nghĩ lại quy trình huấn luyện trước trên dữ liệu huấn luyện tổng quát dồi dào. Bài báo này chính thức hóa vấn đề và đề xuất hai đóng góp chính. (i) Khi có thể đủ khả năng huấn luyện trước một mô hình cho mỗi lĩnh vực chuyên biệt, chúng tôi giới thiệu một phương pháp lấy mẫu theo tầm quan trọng dựa trên phân cụm dữ liệu. Điều này cho phép huấn luyện trước tập trung vào dữ liệu gần với lĩnh vực được nhắm mục tiêu. (ii) Khi cần chia sẻ chi phí huấn luyện trước giữa nhiều lĩnh vực chuyên biệt, chúng tôi đề xuất Mạng Chiếu, một kiến trúc mới huấn luyện cùng nhau một tập hợp các mô hình nhỏ. Mỗi mô hình của tập hợp có thể được sử dụng riêng lẻ, chẳng hạn, để tinh chỉnh trên một lĩnh vực mới. Lợi ích thực nghiệm của các đóng góp của chúng tôi được hiển thị trên nhiều lĩnh vực, ngân sách huấn luyện và kích thước tập huấn luyện. Công trình của chúng tôi đưa ra các khuyến nghị đơn giản được tóm tắt trong Hình 1. Một lợi ích khác của mạng chiếu là chúng có thể được chuyên biệt mà không cần truy cập vào dữ liệu huấn luyện trước. Chẳng hạn, nếu dữ liệu chuyên biệt nhạy cảm, chủ sở hữu dữ liệu có thể tự khởi tạo và tinh chỉnh mô hình một cách rẻ tiền. Phương pháp của chúng tôi không cụ thể cho mô hình hóa ngôn ngữ và chúng tôi dự định mở rộng nó sang các phương thức khác nơi các ràng buộc suy luận cũng quan trọng (ví dụ thị giác máy tính).

# Future Lens: Dự đoán các Token tiếp theo từ một Hidden State duy nhất
Koyena Pal
Đại học Northeastern
pal.k@northeastern.eduJiuding Sun
Đại học Northeastern
sun.jiu@northeastern.eduAndrew Yuan
UMass Amherst
awyuan@umass.edu
Byron C. Wallace
Đại học Northeastern
b.wallace@northeastern.eduDavid Bau
Đại học Northeastern
d.bau@northeastern.edu
Tóm tắt
Chúng tôi đưa ra giả thuyết rằng các vector hidden state tương ứng với từng token đầu vào chứa đựng thông tin đủ để dự đoán chính xác nhiều token phía trước. Cụ thể hơn, trong bài báo này chúng tôi đặt câu hỏi: Cho một biểu diễn ẩn (nội bộ) của một token duy nhất tại vị trí t trong đầu vào, liệu chúng ta có thể dự đoán đáng tin cậy các token sẽ xuất hiện tại các vị trí ≥t+ 2? Để kiểm tra điều này, chúng tôi đo lường các phương pháp xấp xỉ tuyến tính và can thiệp nhân quả trong GPT-J-6B để đánh giá mức độ mà các hidden state riêng lẻ trong mạng chứa tín hiệu đủ phong phú để dự đoán các hidden state tương lai và cuối cùng là các đầu ra token. Chúng tôi phát hiện rằng, ở một số lớp, chúng ta có thể xấp xỉ đầu ra của mô hình với độ chính xác hơn 48% đối với việc dự đoán các token tiếp theo thông qua một hidden state duy nhất. Cuối cùng chúng tôi trình bày một trực quan hóa "Future Lens" sử dụng các phương pháp này để tạo ra một góc nhìn mới về các trạng thái transformer.

1 Giới thiệu
Liệu các hidden state trong các mô hình ngôn ngữ lớn (LLM) có mã hóa các token xa hơn một token duy nhất phía trước không? Nếu có, làm thế nào chúng ta có thể giải mã chuỗi token này từ một trạng thái duy nhất? Trong công trình này, chúng tôi điều tra thực nghiệm các câu hỏi này bằng cách sử dụng GPT-J-6B (Wang và Komatsuzaki, 2021). Chúng tôi huấn luyện các mô hình để dự đoán các hidden state nhiều token phía trước của một vị trí t đã cho chỉ dựa trên một biểu diễn theo ngữ cảnh của đầu vào tại vị trí này.

Các mô hình ngôn ngữ transformer tự hồi quy thường được huấn luyện để dự đoán một token phía trước, nhưng các công trình gần đây đã gợi ý rằng các hidden state riêng lẻ có thể chứa nhiều thông tin hơn chỉ là xác suất của token tiếp theo. Ví dụ, Meng et al.(2022a) theo dõi luồng thông tin từ các token chủ ngữ đến các dự đoán thuộc tính liên quan nhiều bước phía trước. Ở nơi khác, Gurnee et al. (2023) gợi ý rằng các neuron trong các lớp đầu có mật độ thông tin cao, trong khi các lớp giữa có các neuron chuyên dụng đại diện cho các đặc trưng ngữ cảnh cấp cao. Các nỗ lực liên quan khác đã truyền các hidden state trung gian trực tiếp đến decoder head (bỏ qua các lớp ở giữa) để "phát biểu" các embedding như vậy (Din et al., 2023; Belrose et al., 2023; nostalgebraist, 2020). Các nghiên cứu về ghi nhớ (Carlini et al., 2021, 2023, 2019) đã xác định sự hiện diện của các chuỗi được ghi nhớ rất dài được tạo ra bởi các mô hình ngôn ngữ, và Zhang và He (2020) cho thấy rằng việc loại bỏ các lớp một cách tiệm tiến trong quá trình tính toán vẫn có thể đạt được đầu ra dự đoán tương tự của mô hình khi so sánh với mô hình được tính toán đầy đủ của chúng.

Trong công trình này chúng tôi đặt câu hỏi: Đến mức độ nào chúng ta có thể trích xuất thông tin về các token tương lai (vượt ra ngoài token tiếp theo) từ một biểu diễn token ẩn duy nhất? Để trả lời điều này, chúng tôi thực hiện ba thí nghiệm. Đầu tiên, mở rộng các ý tưởng của Tuned Lens (Belrose et al., 2023; Din et al., 2023) và Logit lens (nostalgebraist, 2020), chúng tôi huấn luyện các mô hình tuyến tính để xấp xỉ các dự đoán mô hình tương lai nhiều token trong tương lai, nhằm tiết lộ mức độ mà các hidden state riêng lẻ có thể trực tiếp mã hóa các token tiếp theo. Thứ hai, chúng tôi thực hiện một nghiên cứu can thiệp nhân quả trong đó chúng tôi cấy ghép các hidden state riêng lẻ từ một ngữ cảnh sang một ngữ cảnh hoàn toàn khác và đo lường mức độ mà các token tương lai được dự đoán trong ngữ cảnh gốc có thể được dự đoán trong ngữ cảnh ngoại lai. Cuối cùng, chúng tôi khớp một "soft prompt" để học một cách rõ ràng một prompt tối ưu cho phép đọc thông tin về các token tiếp theo từ một hidden state. Mã nguồn và dữ liệu của chúng tôi có sẵn tại https://future.baulab.info

2 Phương pháp
Để tiết lộ thông tin về các token "tương lai" được mã hóa ngầm trong một vector trạng thái transformer duy nhất, chúng tôi phát triển và so sánh một số phương pháp để dự đoán các token tương lai từ một hidden state duy nhất. Mỗi phương pháp của chúng tôi đều có cùng một mục tiêu: Trích xuất các dự đoán chính xác về phân phối xác suất của mô hình nhiều token phía trước, dựa trên thông tin chỉ trong một hidden state tại một lớp duy nhất tại một token của transformer.

Cho các đánh giá của chúng tôi, chúng tôi sử dụng một mô hình ngôn ngữ transformer tự hồi quy (Vaswani et al., 2017) được định nghĩa là một hàm G:X→Y trên từ vựng V có kích thước |V|=dv. G nhận vào một chuỗi các token x= [x1, ...., x T]∈X, x i∈V và ánh xạ điều này thành một phân phối xác suất yT∈Y⊂[0,1]dv, trong đó (một cách tham lam) dự đoán token tiếp theo xT+1= argmax yT. Để tạo ra các token bổ sung, token được dự đoán hàng đầu xT+1 được thêm vào chuỗi token [x1, ...., x T, xT+1] và quá trình được lặp lại cho đến khi N token tiếp theo được tạo ra.

Để tính toán mỗi phân phối xác suất được dự đoán từ một chuỗi đầu vào x, transformer thực hiện một chuỗi các phép tính tại L lớp; điều này có thể được phân tách thành:
G(x) =D(bL(···(b2(b1(E(x))))···)) (1)

Trong đó bước đầu tiên E:→Rdh nhúng mỗi token đầu vào vào một biểu diễn ẩn ban đầu, e(xi) = h0i∈Rdh; mỗi lớp bl:Rdh×T→Rdh×T biến đổi chuỗi các biểu diễn; và decoder D:Rdh→Y giải mã phân phối xác suất được dự đoán yT=D(hLT) từ lớp cuối tại token cuối. Chúng tôi viết đầu ra của lớp l là Hl=bl(Hl−1), trong đó:
Hl= (hl1, ..., hlT)∈Rdh×T(2)

Khi tạo ra một chuỗi token vượt ra ngoài tiền tố bắt đầu đã cho có độ dài T, chúng tôi viết:
yT+i=G([x1, .., x T+i−1, xT+i]) (3)
xT+i+1= argmax yT+i (4)

Mục tiêu của chúng tôi là thiết kế các phương pháp có thể dự đoán những gì G sẽ dự đoán cho yT+1 đến yT+N chỉ từ một hidden state duy nhất tại hlT.

2.1 Dự đoán Từ vựng Trực tiếp
Gọi hlT là biểu diễn ẩn được tạo ra bởi G cho token xT tại lớp trung gian l≤L, và gọi yT+N là các dự đoán phân phối token tiếp theo được tạo ra bởi G sau token xT+N. Để dự đoán yT+N chỉ từ hlT, chúng tôi huấn luyện một mô hình tuyến tính gθ để dự đoán logit ẑT+N mà xấp xỉ ŷT+N sau softmax:
ẑT+N=gθ(hlT) (5)
ŷT+N= softmax(ẑ T+N)≈ŷT+N

Vì mô hình này trực tiếp dự đoán các dự đoán tiếp theo trên toàn bộ từ vựng từ hlT, chúng tôi gọi nó là mô hình dự đoán từ vựng trực tiếp.

Hình 1: Tổng quan Xấp xỉ từ LLM đến Mô hình Tuyến tính. Cho một hidden state, hlT, mô hình tuyến tính, fθ, được huấn luyện để đưa ra một hidden state tương lai hLT+1. Trong ví dụ này, hlT là mã hóa sẽ dẫn đến việc dự đoán 'New,' và fθ chỉ sử dụng thông tin đó để dự đoán hLT+1 sẽ dự đoán 'York.'

2.2 Xấp xỉ Mô hình Tuyến tính
Chúng tôi cũng kiểm tra một mô hình tuyến tính dựa trên phương pháp tuned logit lens (Belrose et al., 2023; Din et al., 2023), phương pháp này dự đoán các hidden state tương lai trong transformer và giải mã chúng bằng cách sử dụng decoder head được huấn luyện trước. Khác với công trình đó, chúng tôi mô hình hóa các hidden state tại các token tương lai thay vì chỉ tại các lớp sau.

Bắt đầu với biểu diễn ẩn hlT, chúng tôi tạo một mô hình để dự đoán một hidden state hLT+N tại lớp cuối L, và token tiếp theo xT+N. Để dự đoán hLT+N từ hlT, chúng tôi huấn luyện một mô hình tuyến tính:
ĥLT+N=fθ(hlT)≈hLT+N (6)

Từ vựng có thể được đọc từ ĥLT+N được dự đoán bằng cách áp dụng decoder head được huấn luyện trước của transformer. Trong Hình 1, chúng tôi cho thấy một ví dụ về một mô hình tuyến tính như vậy. Giả sử rằng chúng tôi đã huấn luyện một mô hình tuyến tính được tham số hóa bởi θ, fθ, nhận vào biểu diễn ẩn token cuối của đầu vào tại lớp l để tạo ra một hidden state tại lớp L của biểu diễn ẩn token tiếp theo. Khi chúng tôi nhập vào G: "Madison Square Garden is located in", chúng tôi nhận được "New" như dự đoán có xác suất cao nhất tại N= 0 và "York" tại N= 1. Chúng tôi sử dụng mô hình tuyến tính để xấp xỉ điều này dựa trên biểu diễn ẩn của TN (tức là, "in") tại lớp l≤L như đầu vào của chúng tôi; đầu ra lý tưởng của mô hình tuyến tính cho điều này sẽ là hidden state tại TN+1 và lớp L, được liên kết với việc dự đoán "York" như token có khả năng xảy ra nhất.

Phương pháp này khác với phương pháp từ vựng trực tiếp bằng cách tái sử dụng decoder head được huấn luyện trước của transformer. Chúng tôi thấy rằng điều này hỗ trợ một phần các dự đoán tại các lớp mới nhất l gần L. Dựa trên quan sát rằng các tham số transformer được huấn luyện trước khác có thể mã hóa các phép tính được ghi nhớ giúp tạo điều kiện cho việc giải mã các token tiếp theo, chúng tôi tiếp theo chuyển sang các phương pháp khác sử dụng các phần lớn hơn của transformer được huấn luyện trước để dự đoán các token tương lai.

2.3 Can thiệp Nhân quả Prompt Cố định
Phương pháp tiếp theo mà chúng tôi xem xét bao gồm một can thiệp trạng thái đơn lẻ trong đó chúng tôi cấy ghép hidden state hlT vào transformer trong khi nó đang giải mã một bit ngữ cảnh không liên quan. Câu hỏi là liệu việc cấy ghép này có điều hướng mô hình để tạo ra các token liên quan đến tiền tố đã tạo ra hlT hay không. Nếu có, điều này chỉ ra rằng thông tin về các token tiếp theo (trong chuỗi gốc) được mã hóa một cách nổi bật trong hlT.

Hình 2 mô tả quy trình. Ở bên trái, chúng tôi cho thấy ngữ cảnh gốc từ đó hlT được đọc; ở đây x= [x1, ..., x T] là "Madison Square Garden is located in" trong đó x1 là "Madison" và xT là "in". Điều này dẫn đến một chuỗi đầu ra [xT+1, ..., x T+N] sẽ đọc "New York City." Ở bên phải, chúng tôi chạy một prompt ngữ cảnh cố định chung c= [c1, ..., c M] (ví dụ, "Please, tell me something about" trong đó c1 là "Please" và cM là "about") qua transformer. Người ta sẽ không dự đoán rằng prompt chung này sẽ khiến transformer dự đoán "New York City".

Sử dụng một can thiệp, chúng tôi giờ đây trực tiếp kiểm tra giả thuyết rằng một hidden state duy nhất tại lớp l và token T trong lần chạy gốc chứa thông tin cần thiết để dự đoán các token tiếp theo. Chúng tôi cấy ghép vector trạng thái hlT của lần chạy gốc vào vị trí tương ứng hlM trong lần chạy ngữ cảnh cố định, sau đó cho phép transformer tiếp tục. Nếu thông tin ngữ cảnh cần thiết có mặt trong lần chạy mới, các token được tạo ra kết quả sẽ trở thành "New" cho việc tạo token hiện tại và "York" và "City" cho các lần tạo token tiếp theo.

Chính thức, gọi chuỗi x= [x1, ..., x T] ký hiệu một ngữ cảnh đầu vào khiến mô hình sau đó tạo ra [xT+1, ..., x T+N], và gọi c= [c1, ..., c M] đại diện cho một prompt ngữ cảnh cố định chung trong đó T và M đại diện cho độ dài của các prompt đầu vào gốc và cố định, tương ứng. Khi mỗi cái được truyền qua G, chúng ta nhận được các phân phối được dự đoán sau:
yT=G(x)∈[0,1]|V|(7)
ŷ*M=G(c)∈[0,1]|V|

Ký hiệu can thiệp thay thế hlM từ lần chạy ngữ cảnh cố định bằng trạng thái hlT từ lần chạy gốc là:
ŷM=G(c||hlM:=hlT) (8)

Nếu, sau can thiệp, phân phối được dự đoán mới ŷM≈yM xấp xỉ dự đoán trong ngữ cảnh gốc, điều đó sẽ tiết lộ rằng hlT mã hóa cụ thể thông tin cần thiết cho dự đoán đó. Hơn nữa, chúng ta có thể suy ra những gì hlT mã hóa về các dự đoán token tiếp theo n bước phía trước bằng cách thêm các token được tạo ra vào đầu vào và so sánh các dự đoán tiếp theo:
yT+i=G(x+ [xT+1, ..., x T+N]) (9)
ŷM+i=G(c+ [xT+1, ..., x T+N]||hlM:=hlT)

Prompt ngữ cảnh c có thể được chọn là bất kỳ chuỗi token nào. Trong thực tế, một số prompt dễ chấp nhận can thiệp này hơn những prompt khác. Trong các thí nghiệm của chúng tôi, chúng tôi sẽ kiểm tra một tập hợp nhỏ các cụm từ rất chung.

2.4 Can thiệp Nhân quả Prompt Đã học
Trong phần trước, chúng tôi đã mô tả một can thiệp có thể tiết lộ thông tin dự đoán về các token sắp tới được mã hóa trong một hidden state duy nhất, bằng cách điều hướng việc tạo ra khi được ghép vào các ngữ cảnh hoàn toàn không liên quan.

Tuy nhiên, trong những trường hợp mà điều này "thất bại", điều đó không nhất thiết có nghĩa là hidden state không mã hóa thông tin tương tự; nó có thể chỉ ít nổi bật hơn. Để đánh giá mức độ mà tín hiệu như vậy có mặt trong những trường hợp này, chúng tôi tiếp theo khám phá một phương pháp trong đó chúng tôi học cách làm nổi bật thông tin về các token tiếp theo từ các embedding token ngữ cảnh riêng lẻ. Quy trình này được hiển thị trong Hình 3.

Cụ thể, chúng tôi tối ưu hóa một tiền tố được tham số hóa, copt= [c1, ..., c M] để trích xuất thông tin này từ hidden state. Đối với mỗi lớp decoder l, chúng tôi huấn luyện tiền tố tương ứng c(l)opt= [c(l)1, ..., c(l)M] để tối đa hóa xác suất của mô hình tạo ra cụm từ tiếp theo chính xác sau ngữ cảnh gốc. Đặc biệt, chúng tôi thực hiện cùng một can thiệp nhân quả trong các hidden state hlT. Sau đó chúng tôi tối ưu hóa phân phối xác suất của việc tạo ra tiếp theo dưới ngữ cảnh đã học để giống với mô hình gốc khi tất cả việc tạo ra trước đó của nó được đưa ra một cách chính xác:
argmin KL(ŷ M+N;yT+N) (10)

Trong đó phân phối được dự đoán ŷn được đưa ra bằng cách sử dụng cùng một can thiệp như được mô tả trong Eq. 9:
ŷM+n=G([c1, ..., c M, xT+1, .., x T+N]||hlM:=hlT)(11)

Do đó chúng tôi tối ưu hóa mục tiêu này với mô hình được đóng băng và chỉ để lại tiền tố để được huấn luyện. Đáng chú ý, phương pháp của chúng tôi khác với việc triển khai prefix tuning (Li và Liang, 2021) theo nghĩa là chúng tôi lan truyền ngược gradient qua mô hình thay vì một MLP tạm thời, vì thực nghiệm nó tạo ra một ngữ cảnh được tối ưu hóa tốt hơn đáng kể.

3 Thí nghiệm và Kết quả

3.1 Dữ liệu
Chúng tôi thực hiện đánh giá trên các mẫu của Pile (Gao et al., 2020), đây là bộ dữ liệu 825GB được sử dụng để huấn luyện GPT-J-6B (Wang và Komatsuzaki, 2021) cũng như các LLM khác.

Để huấn luyện các mô hình tuyến tính, chúng tôi lấy mẫu 100.000 token có ngữ cảnh trung bình có kích thước 518. Trong số 100.000 mẫu token, chúng tôi sử dụng 10.000 trong số chúng để huấn luyện cho thí nghiệm prompt đã học của chúng tôi. Để kiểm tra các phương pháp của chúng tôi, chúng tôi lấy mẫu thêm 1000 token có độ dài ngữ cảnh trước đó trung bình là 535. Để đơn giản hóa phân tích của chúng tôi về mức độ mà các biểu diễn token ẩn đơn lẻ mã hóa các n-gram tiếp theo, chúng tôi rút các mẫu của mình từ các ngữ cảnh trong đó mô hình transformer gốc đã đưa ra một dự đoán chính xác.

Cụ thể hơn, chúng tôi lấy mẫu ngẫu nhiên dữ liệu huấn luyện và kiểm tra từ tập con các vị trí token mà transformer tự hồi quy đang xem xét dự đoán chính xác token tiếp theo. Trong Bảng 1, chúng tôi phân tích các loại token có mặt trong dữ liệu kiểm tra bằng cách phân loại token cuối ( T) của tiền tố cũng như các token được tạo ra đầu ra của GPT-J, thông qua giải mã tham lam (argmax) tại N= 0,1,2,3 đối với các thuộc tính khác nhau, chẳng hạn như liệu chúng có phải là token chữ thường bắt đầu bằng khoảng trắng, hay là token số, và nhiều hơn nữa.

3.2 Các Metric Đánh giá
Để đánh giá, chúng tôi áp dụng các metric tương tự được sử dụng trong các công trình liên quan trước đây Din et al. (2023), cụ thể là Precision @k và Surprisal.

Precision @k đo lường sự xuất hiện của token xác suất cao nhất trong đầu ra tại N token phía trước mà chúng tôi dự đoán từ hidden state đối với các token top- k được quan sát từ đầu ra mô hình GPT-J-6B. Các giá trị cao hơn tốt hơn ở đây bởi vì chúng có nghĩa là token thực tế tại token tương lai tương ứng đã được dự đoán chính xác.

Mặt khác, Surprisal là xác suất log âm theo đầu ra mô hình GPT-J-6B của token có xác suất cao nhất theo các phương pháp thăm dò được đề xuất. Thấp hơn là tốt hơn cho thước đo này bởi vì các giá trị như vậy ngụ ý rằng các token được dự đoán hàng đầu được coi là có khả năng xảy ra bởi mô hình.

3.3 Thiết lập Thí nghiệm
Mô hình Tuyến tính Chúng tôi huấn luyện hai loại mô hình tuyến tính — một với không gian đầu ra là 4096 (kích thước biểu diễn ẩn được sử dụng bởi GPT-J-6B), và loại khác với 50.400 (không gian từ vựng của cùng một loại). GPT-J-6B bao gồm 28 lớp. Chúng tôi huấn luyện 4 instances cho mỗi lớp này, một cho mỗi vị trí token "tương lai" khác nhau mà chúng tôi xem xét (n= 0,1,2,3). Làm đầu vào chúng tôi chấp nhận hidden state nguồn, tức là hlT. Đầu ra của chúng tôi là hidden state, tức là hLT+N hoặc đầu ra được giải mã tại vị trí (phân phối từ vựng) T+N.

Can thiệp Nhân quả Prompt Cố định Đây là một thiết lập chỉ đánh giá trong đó chúng tôi chọn bốn prompt ngữ cảnh chung và thực hiện can thiệp nhân quả trên các ngữ cảnh này như được hiển thị trong Hình 2. Bốn prompt ngữ cảnh cố định mà chúng tôi kiểm tra là:
• Hello! Could you please tell me more about "
• The multi-tokens present here are "
• The concepts in this hidden state listed are: (
• <|endoftext|> This state is describing about the following concept:

Các hidden state được thu thập từ lớp l của token cuối của các token ngữ cảnh và được cấy ghép vào biểu diễn ẩn của token cuối trong các prompt chung tại cùng lớp l.

Can thiệp Nhân quả Prompt Đã học Sau đó chúng tôi so sánh với các prompt được huấn luyện có cùng độ dài token như các prompt cố định. Chúng tôi huấn luyện một soft prompt cho mỗi lớp l từ 1 đến 28. Mỗi prompt đã học được huấn luyện bằng cách tối đa hóa xác suất tạo ra token từ ngữ cảnh tiền tố tại lớp gần cuối, khi hidden state được cấy ghép tại lớp l tại token cuối của soft prompt, theo cùng cách như các prompt cố định được áp dụng. Chúng tôi huấn luyện một tiền tố có độ dài 10. Phương pháp này hoạt động tốt nhất và là phương pháp chính của chúng tôi.

3.4 Tiết lộ các Token Tiếp theo
Hình 4 và Hình 5 minh họa sự khác biệt giữa phương pháp của chúng tôi và các baseline. Prompt đã học được tối ưu hóa với mục tiêu dự đoán token tiếp theo (N=1) có hiệu suất tốt nhất. Trung bình, precision@1 cao hơn 24,8%, precision@5 cao hơn 25,3%, và precision@10 cao hơn 25,1% so với phương pháp baseline tốt nhất. Baseline bigram tại N=1 được hiển thị dưới dạng đường ngang; mô hình bigram đạt độ chính xác 20,1%. Đối với surprisal, prompt đã học cũng có giá trị thấp nhất, điều này chỉ ra hiệu quả của nó trong việc tối đa tiết lộ thông tin đằng sau các hidden state.

3.5 Ngữ cảnh của Dự đoán Chính xác
Để khám phá thêm các ngữ cảnh trong đó các phương pháp này có vẻ tốt hơn (hoặc tệ hơn) trong việc dự đoán các token tiếp theo, chúng tôi phân loại token đầu vào (token ngữ cảnh gốc cuối) thành tám danh mục (không loại trừ lẫn nhau), được hiển thị trong Bảng 3. Chúng tôi báo cáo độ chính xác của mô hình khi sử dụng lớp 14, nơi mô hình prompt đã học đạt đỉnh.

Trong khi tất cả các danh mục loại token được dự đoán tốt hơn bởi prompt đã học so với mô hình tuyến tính, sự cải thiện tương đối cao nhất khi token ngữ cảnh cuối là token chữ thường được đi trước bởi khoảng trắng, hoặc token dài hơn. Điều này gợi ý rằng thông tin về cách hoàn thành các từ dài có thể không ngay lập tức có thể truy cập được bởi decoder mô hình tuyến tính, nhưng chúng có thể được làm cho có thể truy cập được bằng cách sử dụng các tham số của mô hình được huấn luyện trước như được thực hiện bởi phương pháp can thiệp prompt đã học.

Chúng tôi cũng đã quan sát thấy rằng độ chính xác của việc dự đoán các token tiếp theo có tương quan với độ tin cậy của mô hình trong dự đoán token tiếp theo của nó. Trong trường hợp N= 1, chẳng hạn, độ chính xác hiệu chuẩn của phương pháp can thiệp prompt đã học là 26%, 57%, 77%, và 95% cho các nhóm độ tin cậy mô hình 0-30%, 30-60%, 60-90%, và 90%-100%, tương ứng. Các xu hướng này cũng xuất hiện trong N= 2 và N= 3. Điều này gợi ý rằng chúng ta có thể sử dụng phương pháp giải mã này như một công cụ thăm dò một cách có lợi, tin tưởng rằng các token tương lai được dự đoán thường chính xác khi mô hình tin tưởng.

Liệu thông tin tương lai chỉ xuất hiện trong sự hiện diện của các khái niệm cấp cao hơn? Ví dụ, người ta có thể đưa ra giả thuyết rằng trong các trường hợp mô hình ngôn ngữ dự đoán toàn bộ một thực thể được đặt tên, phương pháp thăm dó có thể giải mã các dự đoán tương lai chính xác hơn. Để điều tra điều này, chúng tôi thực hiện phân tích nhóm phụ trên kết quả kiểm tra để đặc trưng hóa mức độ hiệu quả của phương pháp thăm dò tốt nhất cụ thể cho các thực thể được đặt tên đa token. Thú vị là, chúng tôi thấy ít sự khác biệt: khi chỉ xem xét các trường hợp thực thể được đặt tên, chúng tôi quan sát độ chính xác tương tự hoặc thấp hơn một chút: 44%, 42% và 37% cho N= 1,2,3, gợi ý rằng thông tin tương lai có mặt một cách rộng rãi, không chỉ cho các tên thực thể dài.

Tóm lại, chúng tôi đã phát hiện rằng một hidden state duy nhất mã hóa thông tin về các đầu ra nhiều hơn một token phía trước, và chúng tôi đã chứng minh ba phương pháp khác nhau có thể giải mã chúng cho GPT-J-6B.

Ứng dụng: Future Lens Chúng tôi áp dụng Can thiệp Prompt Đã học để tạo ra một công cụ thăm dò mới mà chúng tôi gọi là Future Lens. Cho một soft prompt, chúng tôi thực hiện can thiệp sử dụng các trạng thái phát sinh từ prompt của người dùng để cung cấp cái nhìn về những gì các hidden state mã hóa về các token tương lai. Trong Hình 6, chúng tôi cho thấy một ví dụ cho prompt: "Marty McFly from". Future lens báo cáo bốn token dự đoán từ mọi hidden state trong mô hình (qua các lớp).

Trong trực quan hóa Future Lens, mỗi ô đại diện cho một hidden state từ một lớp cụ thể ("L{digit}") tại một token cụ thể. Sắc thái của mỗi ô chỉ ra độ tin cậy trung bình của mô hình đối với các dự đoán token tương ứng (sắc thái tối hơn chỉ ra độ tin cậy lớn hơn). Ví dụ, tại ô đại diện cho hidden state tại Lớp 25 tại token "from", chúng ta có thể thấy rằng độ tin cậy trong các token được dự đoán "Back to the Future" là mạnh. Trạng thái cụ thể này gợi ý rằng LLM đã biết rằng Marty McFly có liên quan đến bộ phim Back to the Future. Thú vị là, mô hình cũng giả định "Marty" có họ Donough. Quay lại các dự đoán tại token "from", chúng ta thấy rằng các lớp đầu dường như đầu tiên dự đoán các địa điểm như Australia hoặc Boston. Tuy nhiên, thông qua các dự đoán tương lai, chúng ta có thể thấy mô hình bắt đầu liên kết Marty McFly với một bộ phim khoảng Lớp 6. Do đó, thông qua công cụ này, chúng ta có thể có được nhiều hiểu biết hơn về chuỗi dự đoán của mô hình tại mọi hidden state.

4 Công trình Liên quan
Dự đoán và Thao tác Kiến thức Các công trình gần đây đã đi sâu vào nội bộ LLM để hiểu rõ hơn cách các mô hình như vậy dự đoán token tiếp theo tại mỗi bước tính toán. Geva et al. (2021), chẳng hạn, thấy rằng các lớp feed-forward trong transformer hoạt động như bộ nhớ key-value, cho phép can thiệp tại các lớp đó để sửa đổi đầu ra token tiếp theo (Geva et al., 2022). Các framework như ROME (Meng et al., 2022a) và MEMIT (Meng et al., 2022b) mở rộng các thao tác như vậy để chỉnh sửa kiến thức được lưu trữ trong LLM.

Sự đồng thuận đã nổi lên trong các bài báo này là một số phép tính lớp đầu-giữa và lớp cuối đóng góp nhiều nhất cho token được dự đoán cuối cùng. Các công cụ như Logit lens (nostalgebraist, 2020) và Tuned lens (Belrose et al., 2023; Din et al., 2023) cho phép chúng ta nhìn vào các giá trị top- k của transformer tại mọi lớp và token để thấy các dự đoán token tiếp theo sớm. Katz và Belinkov (2023) đã sử dụng logit lens để trực quan hóa luồng thông tin ngữ nghĩa trong các mô hình GPT-2. Trong khi các công trình này chủ yếu xử lý các dự đoán token tiếp theo, Hernandez et al. (2023) cho thấy rằng các thuộc tính cụ thể của một thực thể có thể được trích xuất với một phép biến đổi affine trên biểu diễn thực thể rất lâu trước khi LM thực sự được yêu cầu dự đoán thuộc tính, cho phép một "attribute lens" trên các lớp đầu và token đầu. Chúng tôi nhằm đặc trưng hóa cách hidden state hiện tại sẽ ảnh hưởng đến việc dự đoán cả token tiếp theo và các token xa hơn phía trước, nhưng không giống như Hernandez et al. (2023), chúng tôi xử lý các ngữ cảnh mở và không bị hạn chế đối với các quan hệ nhất định.

Giải mã Thoát Sớm Để tối ưu hóa thời gian chạy và yêu cầu không gian của việc huấn luyện mô hình, các công trình trước đây đã xem xét các chiến lược "thoát sớm", thường bao gồm việc dừng lại tại các lớp tính toán sớm hơn và ước tính các dự đoán cuối cùng dựa trên các phép tính đó (Schuster et al., 2022; Xin et al., 2021; Kong et al., 2022; Zhang và He, 2020; Din et al., 2023). Điểm mấu chốt từ các phương pháp này là có thể đạt được hiệu suất dự đoán có thể so sánh với hiệu suất quan sát được khi tất cả các lớp được sử dụng thậm chí khi loại bỏ một vài lớp tính toán cho mỗi token. Chẳng hạn, Din và các đồng nghiệp (2023) đã sử dụng các phép biến đổi tuyến tính để dự đoán biểu diễn ẩn của lớp sau từ lớp trước tại cùng token. Phương pháp này có thể bảo tồn ∼95% đầu ra mô hình transformer đầy đủ trên GPT-2 (Radford et al., 2019) và BERT (Devlin et al., 2018). Kết quả này ngụ ý rằng các lớp mô hình ban đầu mã hóa thông tin để phần lớn xác định đầu ra cuối cùng. Trong công trình này chúng tôi kiểm tra các giới hạn của hiện tượng này bằng cách đánh giá mức độ mà một hidden state duy nhất cho một token tại vị trí T có thể được sử dụng để dự đoán các token nhiều bước phía trước (tức là, tại T+N).

Ghi nhớ trong Mô hình Ngôn ngữ Do thông tin có khả năng nhạy cảm có mặt trong các bộ dữ liệu được sử dụng để huấn luyện các mô hình ngôn ngữ (LM), công trình trong quá khứ đã điều tra gì, khi nào, và tại sao ghi nhớ xảy ra (Carlini et al., 2021, 2019; Feldman và Zhang, 2020; Lehman et al., 2021), cách ghi nhớ thay đổi như một hàm của kích thước dữ liệu huấn luyện (Carlini et al., 2023; Wei et al., 2022), và cách thông tin được ghi nhớ khác có thể được phát hiện dựa trên các trạng thái nội bộ của mô hình (Haviv et al., 2023).

Các công trình này đã minh họa tập thể rằng có một số đoạn văn bản mà LM ghi nhớ và có thể đưa ra từng từ một hoặc trong các phiên bản được diễn giải gần ("ghi nhớ xấp xỉ"; Ippolito et al. 2023). Công trình khác (Haviv et al., 2023) đã cho thấy rằng các lớp đầu của mô hình có xu hướng thúc đẩy các khái niệm hoặc token được ghi nhớ, trong khi các lớp sau tăng cường độ tin cậy của mô hình trong các token này. Bài báo của chúng tôi có thể được xem như một phần mở rộng của công trình này về điều tra ghi nhớ các cụm từ đa token: chúng tôi hỏi liệu và đến mức độ nào một hidden state mô hình duy nhất mã hóa thông tin đa token.

Prompt Tuning Prompt Tuning đã nổi lên như một phương pháp hiệu quả tham số để khớp LM cho các nhiệm vụ downstream mới. Bằng cách đóng băng LM và chỉ tối ưu hóa các tham số soft prompt, các mô hình có thể đạt được hiệu suất có thể so sánh với hiệu suất quan sát được sau khi fine-tune tất cả các tham số. Li et al. (2021) đã giới thiệu prefix tuning bao gồm việc huấn luyện tiền tố plug-and-play điều hướng hành vi của LM cho các nhiệm vụ downstream. Công trình khác (Wallace et al., 2019) đã áp dụng một phương pháp dựa trên gradient để tìm kiếm các prompt rời rạc tốt nhất cho phép mô hình tạo ra việc tạo ra mong muốn. Sun và các đồng nghiệp (2023) huấn luyện soft prompt tiền tố như một cách căn chỉnh các hướng dẫn tương đương ngữ nghĩa trong không gian tiềm ẩn.

5 Thảo luận
Trong bài báo này, chúng tôi đã khám phá mức độ mà chúng ta có thể giải mã các đầu ra đa token tiếp theo với một token cụ thể chỉ dựa trên biểu diễn ẩn của nó. Các kết quả trong Bảng 2 và Hình 4 và 5 chỉ ra rằng các biểu diễn mã hóa thông tin như vậy, ở một mức độ nào đó. Trong số các phương pháp giải mã mà chúng tôi đánh giá, các prompt đã học có khả năng dự đoán các token tương lai như vậy tốt nhất. Cả mô hình tuyến tính và mô hình prompt đã học đều đạt được độ chính xác tốt hơn baseline bigram thực nghiệm tại N= 1. Thú vị là, độ chính xác dự đoán của mô hình prompt đã học đạt đỉnh tại các hidden state lớp giữa, gợi ý rằng thông tin token tiếp theo được mã hóa tại các lớp đó; mẫu này rất khác với token tiếp theo ngay lập tức N= 0, trong đó độ chính xác đạt đỉnh tại lớp cuối.

Mô hình prompt đã học đạt được độ chính xác đủ để có thể hữu ích như một "Future Lens" để cung cấp hiểu biết về thông tin token tiếp theo được chứa trong các hidden state trong LLM. Điều này cung cấp một cách để giải mã một chuỗi ngắn các token được mã hóa trong một hidden state, thay vì chỉ dự đoán token ngay lập tức duy nhất.

Tính khả dụng Dữ liệu và Mã nguồn Tất cả mã nguồn và dữ liệu cho demo và triển khai được cung cấp tại: https://future.baulab.info

Lời cảm ơn Công trình này được hỗ trợ bởi Open Philanthropy và bởi Quỹ Khoa học Quốc gia (NSF) giải thưởng 1901117. Chúng tôi cảm ơn Trung tâm An toàn AI (CAIS) đã cung cấp khả năng tính toán cho nghiên cứu này.

Tài liệu tham khảo
[Danh sách tài liệu tham khảo được giữ nguyên như trong bản gốc]

# 2406.03853.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/speculative/2406.03853.pdf
# Kích thước tệp: 907935 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Giải Mã Suy Đoán Thông Qua Thoát Sớm Để Suy Luận LLM Nhanh Hơn
với Cơ Chế Điều Khiển Thompson Sampling
Jiahao Liu1, Qifan Wang2, Jingang Wang1∗, Xunliang Cai1
1Meituan;2Meta AI
{liujiahao12,wangjingang02,caixunliang}@meituan.com
wqfcr@fb.com
Tóm tắt
Những tiến bộ gần đây trong các mô hình ngôn ngữ lớn (LLM) đã rất phi thường, tuy nhiên chi phí suy luận gia tăng liên quan đến chúng tạo ra những thách thức trong các ứng dụng thực tế. Để giải quyết những thách thức này, chúng tôi đề xuất một phương pháp mới gọi là Giải Mã Suy Đoán Thoát Sớm (EESD) với gia tốc không mất mát. Cụ thể, EESD sử dụng một phân đoạn của LLM để tạo ra các token dự thảo, kết hợp các cấu trúc Thoát Sớm sau N lớp đầu tiên. Để nâng cao chất lượng của các token dự thảo, một phương pháp tự chưng cất được tích hợp. Thiết kế thoát sớm này không chỉ giảm chi phí triển khai và đào tạo mà còn tăng tốc đáng kể tốc độ tạo token. Hơn nữa, chúng tôi giới thiệu một cơ chế lấy mẫu mới tận dụng Thompson Sampling để điều chỉnh các quá trình tạo, tự động xác định số lượng token dự thảo trong mỗi vòng. LLM gốc sau đó được sử dụng để xác thực những token dự thảo này thông qua một lần truyền tiến duy nhất, và do đó đảm bảo rằng văn bản đầu ra cuối cùng duy trì phân phối nhất quán với giải mã tự hồi quy vanilla. Kết quả thí nghiệm trên cả mô hình 13B và 70B chứng minh rằng phương pháp của chúng tôi giải mã token với tốc độ nhanh hơn đáng kể so với các phương pháp trước đây, cho thấy hiệu quả của phương pháp chúng tôi.

1 Giới thiệu
Các Mô hình Ngôn ngữ Lớn (LLM) xuất sắc trong nhiều tác vụ NLP khác nhau do số lượng tham số khổng lồ và mạng phức tạp của chúng (OpenAI, 2023; Chowdhery et al., 2023; Touvron et al., 2023a,b). Tuy nhiên, những mô hình này tạo ra token từng cái một theo cách tự hồi quy trong quá trình suy luận, khiến việc tạo ra cực kỳ tốn tài nguyên và thời gian. Để vượt qua nút thắt cổ chai này, các nhà nghiên cứu đã giới thiệu một kỹ thuật giải mã hiệu quả - Giải Mã Suy Đoán (SD) (Leviathan et al., 2023; Chen et al., 2023; Miao et al., 2023).
∗Jingang Wang là tác giả tương ứng.

[Biểu đồ hiển thị kết quả thí nghiệm với tăng tốc và tỷ lệ chấp nhận]

Hình 1: Kết quả thí nghiệm sử dụng LLaMA-2-70B trên Gsm8k. (a) So sánh tăng tốc với Medusa (Cai et al., 2023) và Self-SD (Zhang et al., 2023b). EESD đạt được tăng tốc cao nhất với sự cân bằng tốt nhất giữa tốc độ tạo token dự thảo và tỷ lệ chấp nhận. (b) Chi phí tạo (giây) với các bước dự thảo khác nhau (K) trong năm mẫu được chọn ngẫu nhiên từ Gsm8k. Giá trị tối ưu của K thay đổi qua các mẫu khác nhau, cho thấy rằng một giá trị K cố định cho tất cả mẫu không lý tưởng.

SD về cơ bản giới thiệu hai mô hình, một mô hình nhỏ (mô hình dự thảo) được sử dụng để tạo ra đồng thời nhiều token dự thảo, và LLM gốc (mô hình đích) được sử dụng để xác thực token dự thảo. Bằng cách này, SD duy trì hiệu suất tương tự như giải mã tự hồi quy trong khi tăng tốc độ suy luận.

So với Giải Mã Suy Đoán vanilla (Leviathan et al., 2023; Chen et al., 2023), một số mô hình tiên tiến như Medusa (Cai et al., 2023) và Self-SD (Zhang et al., 2023b) đã được giới thiệu, chỉ yêu cầu triển khai một LLM thay vì hai mô hình, dẫn đến ít tài nguyên hơn cần thiết cho cả đào tạo và triển khai. Trong khi những phương pháp này đạt được kết quả hứa hẹn, có hai hạn chế chính.

Thứ nhất, chúng thất bại trong việc tối ưu hóa sự cân bằng giữa chất lượng và tốc độ của việc tạo token dự thảo. Ví dụ, như được hiển thị trong Hình 1a, trong khi Medusa có thể tạo ra token dự thảo nhanh chóng, chất lượng của những token này có xu hướng kém¹. Mặt khác, Self-SD quản lý để sản xuất token dự thảo chất lượng cao nhưng làm như vậy với tốc độ chậm hơn nhiều, dẫn đến tăng tốc tổng thể thấp hơn.

Thứ hai, hầu hết các phương pháp SD bắt đầu xác thực sau khi tạo ra một độ dài xác định trước của token dự thảo (được gọi là các bước dự thảo K). Việc lựa chọn K ảnh hưởng đáng kể đến việc gia tốc quá trình suy luận. Thông thường, các bước dự thảo lớn hơn dẫn đến tạo ra end-to-end nhanh hơn, nhưng có một sự đánh đổi tiềm năng vì tỷ lệ chấp nhận có thể giảm nếu chất lượng của chuỗi dự thảo dài hơn không cao. Như được minh họa trong Hình 1b, giá trị tối ưu của K thay đổi qua các ví dụ khác nhau. Sự biến đổi này cho thấy rằng việc sử dụng K cố định có thể không mang lại chiến lược hiệu quả nhất. Thay vào đó, một phương pháp thích ứng là ưu tiên để xác định khi nào kết thúc quá trình dự thảo.

Để giải quyết những thách thức này, trong bài báo này, chúng tôi đề xuất một phương pháp Giải Mã Suy Đoán Thoát Sớm mới, được đặt tên là EESD, để tạo điều kiện cho việc tạo ra các token dự thảo hiệu quả và có chất lượng. Cụ thể, EESD giới thiệu một lớp Thoát Sớm được đặt chồng lên N lớp đầu tiên của LLM, điều này đã cho thấy tiềm năng dự đoán mạnh mẽ trong nghiên cứu trước đây (Bae et al., 2023; Schuster et al., 2022). Một phương pháp tự chưng cất được sử dụng thêm để tăng cường việc học tập của lớp Thoát Sớm. Để xác định các bước dự thảo tối ưu, chúng tôi tái hình thành nhiệm vụ xác định độ dài của việc tạo token dự thảo như một vấn đề đa cánh tay cướp (MAB), và đề xuất một Cơ chế Điều khiển mới dựa trên Thompson Sampling (TS) được nghiên cứu kỹ lưỡng để ước tính các tham số chưa biết và tạo điều kiện cho việc đưa ra quyết định tối ưu. Đánh giá toàn diện trên cả mô hình 13B và 70B chứng minh hiệu suất vượt trội của phương pháp chúng tôi so với một số đường cơ sở. Những đóng góp chính của bài báo này được tóm tắt như sau:

• Chúng tôi giới thiệu một khung Thoát Sớm mới để tạo ra token dự thảo, cho phép một LLM duy nhất thực hiện các giai đoạn dự thảo và xác thực. Chúng tôi đào tạo nó bằng cách sử dụng tự chưng cất. Các điều tra của chúng tôi cho thấy rằng khung này tạo ra một sự cân bằng xuất sắc giữa chất lượng và tốc độ của việc tạo token dự thảo.

• Chúng tôi khái niệm hóa độ dài tạo của token dự thảo như một vấn đề MAB và đề xuất một cơ chế điều khiển mới dựa trên Thompson Sampling, tận dụng lấy mẫu để thiết kế một chiến lược tối ưu.

• Chúng tôi đã tiến hành các thí nghiệm rộng rãi trên ba bộ tiêu chuẩn. Kết quả khẳng định rằng EESD có thể cải thiện đáng kể tốc độ suy luận của mô hình, vượt trội hơn các phương pháp SD hiện có.

¹Chúng tôi sử dụng tỷ lệ chấp nhận để đại diện cho chất lượng của token dự thảo, đó là phần trăm token dự thảo được chấp nhận bởi mô hình đích trong quá trình xác thực.

--- TRANG 2 ---
những token này có xu hướng kém¹. Mặt khác, Self-SD quản lý để sản xuất token dự thảo chất lượng cao nhưng làm như vậy với tốc độ chậm hơn nhiều, dẫn đến tăng tốc tổng thể thấp hơn. Thứ hai, hầu hết các phương pháp SD bắt đầu xác thực sau khi tạo ra một độ dài xác định trước của token dự thảo (được gọi là các bước dự thảo K). Việc lựa chọn K ảnh hưởng đáng kể đến việc gia tốc quá trình suy luận. Thông thường, các bước dự thảo lớn hơn dẫn đến tạo ra end-to-end nhanh hơn, nhưng có một sự đánh đổi tiềm năng vì tỷ lệ chấp nhận có thể giảm nếu chất lượng của chuỗi dự thảo dài hơn không cao. Như được minh họa trong Hình 1b, giá trị tối ưu của K thay đổi qua các ví dụ khác nhau. Sự biến đổi này cho thấy rằng việc sử dụng K cố định có thể không mang lại chiến lược hiệu quả nhất. Thay vào đó, một phương pháp thích ứng là ưu tiên để xác định khi nào kết thúc quá trình dự thảo.

Để giải quyết những thách thức này, trong bài báo này, chúng tôi đề xuất một phương pháp Giải Mã Suy Đoán Thoát Sớm mới, được đặt tên là EESD, để tạo điều kiện cho việc tạo ra các token dự thảo hiệu quả và có chất lượng. Cụ thể, EESD giới thiệu một lớp Thoát Sớm được đặt chồng lên N lớp đầu tiên của LLM, điều này đã cho thấy tiềm năng dự đoán mạnh mẽ trong nghiên cứu trước đây (Bae et al., 2023; Schuster et al., 2022). Một phương pháp tự chưng cất được sử dụng thêm để tăng cường việc học tập của lớp Thoát Sớm. Để xác định các bước dự thảo tối ưu, chúng tôi tái hình thành nhiệm vụ xác định độ dài của việc tạo token dự thảo như một vấn đề đa cánh tay cướp (MAB), và đề xuất một Cơ chế Điều khiển mới dựa trên Thompson Sampling (TS) được nghiên cứu kỹ lưỡng để ước tính các tham số chưa biết và tạo điều kiện cho việc đưa ra quyết định tối ưu. Đánh giá toàn diện trên cả mô hình 13B và 70B chứng minh hiệu suất vượt trội của phương pháp chúng tôi so với một số đường cơ sở. Những đóng góp chính của bài báo này được tóm tắt như sau:

• Chúng tôi giới thiệu một khung Thoát Sớm mới để tạo ra token dự thảo, cho phép một LLM duy nhất thực hiện các giai đoạn dự thảo và xác thực. Chúng tôi đào tạo nó bằng cách sử dụng tự chưng cất. Các điều tra của chúng tôi cho thấy rằng khung này tạo ra một sự cân bằng xuất sắc giữa chất lượng và tốc độ của việc tạo token dự thảo.

• Chúng tôi khái niệm hóa độ dài tạo của token dự thảo như một vấn đề MAB và đề xuất một cơ chế điều khiển mới dựa trên Thompson Sampling, tận dụng lấy mẫu để thiết kế một chiến lược tối ưu.

• Chúng tôi đã tiến hành các thí nghiệm rộng rãi trên ba bộ tiêu chuẩn. Kết quả khẳng định rằng EESD có thể cải thiện đáng kể tốc độ suy luận của mô hình, vượt trội hơn các phương pháp SD hiện có.

2 Nghiên cứu liên quan

Nén LLM Mục tiêu trung tâm của nén mô hình là giảm bớt nhu cầu tính toán và tăng tốc độ suy luận. Nghiên cứu về nén LLM chủ yếu bao gồm ba hướng, bao gồm chưng cất kiến thức (Zhang et al., 2023a; Li et al., 2023; Gu et al., 2023), cắt tỉa mạng (Ma et al., 2023; Xia et al., 2023; Frantar và Alistarh, 2023) và lượng tử hóa (Xiao et al., 2023; Liu et al., 2023; Frantar et al., 2022; Lin et al., 2023; Gong et al., 2023). Các phương pháp được đề cập ở trên hoạt động bằng cách giảm dấu chân của mô hình, do đó giảm nhu cầu bộ nhớ và tăng tốc độ suy luận. Tuy nhiên, những phương pháp này hy sinh một mức độ khả năng của LLM.

Giải Mã Hiệu quả Leviathan et al. (2023); Chen et al. (2023) đề xuất một phương pháp sử dụng một mô hình nhỏ để tạo ra token dự thảo và sau đó sử dụng LLM để xác thực, điều này tăng tốc quá trình giải mã trong khi đảm bảo đầu ra không mất mát, được đặt tên là Giải Mã Suy Đoán. Tuy nhiên, một số nhà nghiên cứu cho rằng mô hình nhỏ bổ sung không cần thiết cho SD. Ví dụ, Medusa (Cai et al., 2023) tạo ra token dự thảo bằng cách tận dụng các tham số bổ sung thay vì mô hình nhỏ, trong khi Self-SD (Zhang et al., 2023b) sử dụng cấu trúc con của LLM để tạo ra token dự thảo. Ngoài ra, He et al. (2023) tiết lộ một phương pháp thay thế việc tạo ra token dự thảo bằng một cơ sở dữ liệu văn bản lớn. Mặt khác, một số nhà nghiên cứu giới thiệu một phương pháp Thoát Sớm. Phương pháp này sửa đổi động độ sâu của bộ giải mã cho mỗi lần tạo token, đưa ra dự đoán ở một lớp trung gian (Teerapittayanon et al., 2016; Elbayad et al., 2020). Hơn nữa, Bae et al. (2023) đề xuất một phương pháp Thoát Sớm mới kết hợp một mô-đun nông-sâu và giải mã song song đồng bộ.

3 Phương pháp luận

Kiến trúc mô hình tổng thể của EESD được minh họa trong Hình 2. Về cơ bản, mô hình của chúng tôi được

--- TRANG 3 ---
[Biểu đồ kiến trúc EESD với ba thành phần chính]

Hình 2: Khung của EESD bao gồm ba thành phần: (1) Lớp thoát sớm tạo ra token dự thảo một cách hiệu quả và hiệu quả; (2) Tự chưng cất chưng cất kiến thức từ LLM (mô hình đích); (3) Cơ chế điều khiển TS có thể dự đoán thời điểm tối ưu để kết thúc việc tạo token dự thảo trong mỗi vòng. Chúng tôi chia LLM (mô hình đích) thành hai phần: N lớp đầu tiên và M lớp cuối cùng.

được tạo thành từ ba thành phần chính. 1) lớp Thoát Sớm được xây dựng trên đỉnh của một vài lớp đầu tiên của LLM như một mô hình dự thảo; 2) phương pháp tự chưng cất để tăng cường việc học tập của mô hình dự thảo và tăng chất lượng tạo văn bản; và 3) cơ chế điều khiển Thompson Sampling xác định một cách thích ứng độ dài của token dự thảo dựa trên chất lượng của chúng. Chúng tôi trình bày chi tiết của những thành phần này trong các phần sau.

3.1 Lớp Thoát Sớm

Hầu hết các phương pháp trước đây (Bae et al., 2023; Kavehzadeh et al., 2023) sử dụng mạng con không liên tục của LLM gốc (mô hình đích) làm mô hình dự thảo của họ. Trong công trình này, chúng tôi sử dụng phương pháp N lớp đầu tiên liên tục, mang lại một lợi thế đáng kể: kv-cache của mô hình dự thảo và mô hình đích có thể chia sẻ N lớp đầu tiên, do đó cắt bỏ tính toán dư thừa. Cụ thể, chúng tôi hình thành một Lớp Thoát Sớm với quá trình tính toán được làm rõ dưới đây,

p(yt) = softmax (WTTransformere(HN_t)), (1)

trong đó HN_t đại diện cho trạng thái ẩn của lớp thứ N, được tính toán từ N lớp đầu tiên của LLM gốc. Và t đại diện cho token thứ t. p(yt) được thu được từ HN_t thông qua một lớp transformer. Đối với mô hình LLaMA, chúng tôi cũng thêm lớp RMSNorm trước đầu dự đoán đầu ra, đó là RMSNorm (Transformere(HN_t)).

Như đã đề cập ở trên, chúng tôi kết hợp một lớp Transformer có thể học được sau N lớp đầu tiên, và đào tạo lớp này và W trong Eq.(1) (các tham số RMSNorm cũng được đào tạo cho mô hình LLaMA). Để tăng tốc độ hội tụ của mô hình, chúng tôi khởi tạo Transformere và W với lớp cuối cùng và đầu dự đoán của LLM gốc tương ứng. Vì việc đào tạo được giới hạn chỉ trong một lớp Transformer duy nhất và W, với N lớp đầu tiên bị đông lạnh, phương pháp này giảm đáng kể tài nguyên tính toán.

3.2 Tự Chưng Cất

Để tăng cường thêm hiệu quả của mô hình dự thảo, chúng tôi sử dụng tự chưng cất để học kiến thức từ LLM. Ý tưởng chính là có một lượng lớn dữ liệu có giá trị được sử dụng trong quá trình đào tạo LLM. Tuy nhiên, thường không thể thu được những dữ liệu gốc này vì hầu hết chúng không trực tiếp truy cập được. Do đó, chúng tôi đề xuất thu hẹp khoảng cách bằng tự chưng cất, hướng dẫn việc học tập của lớp thoát sớm bằng cách chuyển giao kiến thức từ văn bản được tạo ra bởi LLM. Cụ thể, Liu et al. (2023) cho rằng một chiến lược tạo ra lai của tham lam và lấy mẫu là hiệu quả, và chúng tôi áp dụng phương pháp này để tạo văn bản từ LLM. Đáng chú ý là văn bản được tạo ra bởi LLM có thể chứa một số mẫu chất lượng thấp hơn. Do đó chúng tôi giữ lại một tập con dữ liệu nguồn mở để phục vụ mục đích đào tạo. Các tham số của Lớp Thoát Sớm được đào tạo sử dụng sự kết hợp của dữ liệu được tạo ra bởi LLM và các bộ dữ liệu nguồn mở, với mất mát entropy chéo giữa dự đoán của nó và sự thật cơ bản của các bộ dữ liệu hỗn hợp.

--- TRANG 4 ---
3.3 Cơ Chế Điều Khiển Thompson Sampling

Các phương pháp trên có thể cải thiện hiệu quả chất lượng và tốc độ của việc tạo token dự thảo. Tuy nhiên, như chúng tôi đã đề cập trong phần giới thiệu, một bước dự thảo được xác định trước không phải là một chiến lược tốt. Do đó, chúng tôi xem việc điều khiển việc tạo ra mô hình dự thảo như một vấn đề MAB. Cụ thể, chúng tôi xem nó như một quá trình Bernoulli, trong đó mô hình độc lập xác định có tiếp tục tạo token dự thảo hay không, được ký hiệu là PB(θ). Và xác suất θ là không chắc chắn, liên quan đến mẫu đầu vào. Phương pháp Thompson Sampling (TS) có thể ước tính tốt hơn các biến chưa biết thông qua việc cân bằng khám phá và khai thác (Slivkins, 2019). Như được minh họa trong Thuật toán 1, chúng tôi sử dụng thuật toán TS để ước tính thích ứng θ. Cốt lõi của thuật toán TS liên quan đến việc mô hình hóa các tham số không chắc chắn θ như một phân phối hậu nghiệm sử dụng lý thuyết Bayesian, tức là P(θ|D), với D đại diện cho các mẫu môi trường quan sát được. Cốt lõi của thuật toán này nằm ở việc thiết kế một phân phối hậu nghiệm hợp lý, mà chúng tôi sẽ trình bày chi tiết trong các chương sau.

TS với Phân Phối Beta Xem xét rằng mẫu tuân theo phân phối Bernoulli, chúng tôi áp dụng phương pháp phân phối liên hợp và chọn phân phối Beta làm phân phối hậu nghiệm. Thiết lập này có nghĩa là các phân phối tiên nghiệm và hậu nghiệm chia sẻ cùng một hàm phân phối nhưng với các tham số khác nhau, điều này đơn giản hóa rất nhiều quá trình tính toán. Hàm mật độ xác suất của phân phối Beta như sau:

Beta(θ;α, β) = 1/B(α, β) θ^(α-1)(1-θ)^(β-1), (2)

trong đó B(α, β) là một hàm chuẩn hóa. Phân phối Beta có hai tham số, α và β, vì vậy Φ = {α, β} và Φ0 = {α0, β0} trong Thuật toán 1. Theo suy luận Bayesian, chúng ta có thể cập nhật các tham số α và β theo công thức sau, đó là bước 18 trong Thuật toán 1,

αt = α{t-|Qv|} + r, (3)
βt = β{t-|Qv|} + (n-r), (4)

trong đó r đại diện cho số lượng thí nghiệm thành công trong các mẫu quan sát, và n đại diện cho tổng số thí nghiệm. Và trong Thuật toán 1, giá trị của r được đặt thành |Qv| - 1, cho thấy rằng mô hình dự thảo nên tiếp tục tạo ra trên tập token này (tức là, χ = 1). Và giá trị của n được đặt thành min(|Qv| + 1, |Qd|), cho thấy số lượng token đã được xác thực bởi mô hình đích. Bởi vì chúng ta dừng xác thực khi gặp một token không nhất quán, các token tiếp theo không được xem xét.

Thuật toán 1 Thuật toán Điều khiển TS
Yêu cầu: Mô hình Đích Mt; Mô hình Dự thảo Md; Độ dài Tạo ra Tối đa L; Siêu tham số Φ0; Prompt Đầu vào {x0, ..., xn}.
1: Khởi tạo xác suất tiên nghiệm P(θ|Φ0) theo siêu tham số được người dùng đặt Φ0.
2: Khởi tạo tập kết quả Qg ← {x0, ..., xn} và t ← 0.
3: while t < L do
4:    Khởi tạo tập kết quả mô hình dự thảo và i, Qd ← Null, i ← 0.
5:    while t + i < L do
6:        Lấy token mới xi ← Md(Qg ∪ Qd).
7:        Thêm token xi vào tập Qd.
8:        Lấy mẫu θt+i từ P(θ|Φt;D).
9:        Lấy mẫu χ ∈ {0,1} từ phân phối Bernoulli PB(θt+i).
10:       i ← i + 1.
11:       if χ = 0 then
12:           Break
13:       end if
14:   end while
15:   Xác thực kết quả Qd bởi Mô hình Đích Mt và lấy Qv được nhận bởi Mt, Qv ⊆ Qd.
16:   Thêm tập Qv vào Qg, Qg ← Qg ∪ Qv.
17:   Cập nhật t theo độ dài của Qv, t ← t + |Qv|.
18:   Cập nhật các tham số Φt của phân phối hậu nghiệm.
19: end while
20: return Qg

TS với Hiệu Chỉnh Trong phân đoạn trước, chúng tôi giới thiệu một thuật toán TS với phân phối Beta để cải thiện việc ước tính θ. Tuy nhiên, theo lý thuyết MAB, các giai đoạn ban đầu tập trung vào khám phá nhiều hơn, điều này có thể dẫn đến ước tính θ kém chính xác hơn (Ou et al., 2019; Peng et al., 2019). Để giảm thiểu vấn đề này, chúng tôi đề xuất một phương pháp lai mới kết hợp Dự đoán Mô hình và Dự đoán Lấy mẫu. Chúng tôi dựa vào dự đoán mô hình nhiều hơn để giảm thiểu sự không chính xác từ khám phá ban đầu. Khi dự đoán lấy mẫu bắt đầu hội tụ sau này, chúng tôi hiệu chỉnh dự đoán mô hình với dự đoán lấy mẫu để đạt được θ chính xác hơn.

Chúng tôi đào tạo một lớp đơn để dự đoán giá trị của θ. Công thức tính toán cho điều này như sau,

θt+i^M = Sigmoid (Wp(WiH(T)_t, H(D)_t+i)), (5)

trong đó t là số lượng token đã được tạo ra, và i là số lượng token mới được tạo ra bởi mô hình dự thảo trong vòng lặp hiện tại. H(T)_t đại diện cho trạng thái ẩn của LLM (mô hình đích) tại vị trí t trong lớp cuối cùng, trong khi H(D)_t+i tương ứng đại diện cho trạng thái ẩn của

--- TRANG 5 ---
mô hình dự thảo tại vị trí t+i trong lớp cuối cùng. Wi là ma trận biến đổi tại vị trí thứ i cho mô hình đích, và xem xét rằng i có thể rất lớn, chúng tôi đã hạn chế số lượng Wi ∈ R^(d×d), tức là i = min(i,10). Chúng tôi lấy mẫu một phần của bộ dữ liệu đào tạo để đào tạo các tham số {W1, W2, ..., W10} và Wp ∈ R^(2×2d). Các nhãn cho dữ liệu này được thu được bằng cách so sánh các token được sản xuất bởi cả mô hình đích và dự thảo, biểu thị giá trị thực của χ. Sau đó, chúng tôi cập nhật các tham số sử dụng mất mát entropy chéo.

Theo định lý giới hạn trung tâm, khi kích thước mẫu đủ lớn, trung bình mẫu tuân theo phân phối Gaussian. Do đó, chúng tôi đưa ra giả định rằng trung bình mẫu ēχ của χ trong một vòng dự thảo tuân theo phân phối Gaussian, tức là ēχ ~ N(μ, σ²S). Như được hỗ trợ bởi lý thuyết Bayesian, khi biến ngẫu nhiên tuân theo phân phối Gaussian với phương sai đã biết nhưng trung bình chưa biết và phân phối tiên nghiệm cũng là phân phối Gaussian, nó thỏa mãn phân phối liên hợp. Do đó, chúng tôi định nghĩa μ tuân theo phân phối Gaussian với điểm số dự đoán của mô hình làm trung bình và lỗi dự đoán làm phương sai, μ ~ N(θM, σ²M). Trong Thuật toán 1, chúng tôi đặt Φ0 = {σM, σS, θ̂0}, trong đó σM, σS và θ̂0 là các siêu tham số được người dùng đặt. Trong Bước 8 của Thuật toán 1, chúng tôi lấy mẫu giá trị θ từ phân phối Gaussian, θt+i ~ N(μt+i, σ²t+i), và tính toán các giá trị của μ và σ sử dụng công thức được cung cấp,

μt+i = (σ²S/(nσ²M + σ²S))θt+i^M + (nσ²M/(nσ²M + σ²S))θ̂t, (6)

1/σ²t+1 = 1/σ²M + n/σ²S, (7)

Trong đó n là số lần xác thực. Chúng tôi cập nhật tham số Φ dựa trên công thức sau trong bước 18,

θ̂t = (θ̂{t-|Qv|} * (t - |Qv| + 1) + |Qv|)/(t + 1), (8)

Để biết thêm chi tiết, vui lòng tham khảo Phụ lục B.

4 Thí nghiệm

4.1 Thiết lập

Giai đoạn đào tạo Chúng tôi ngẫu nhiên trích xuất 100,000 mẫu từ SlimPajama (Soboleva et al., 2023) để đào tạo LLaMA-2-70B, LLaMA-2-13B và CodeLLaMA-2-13B. Và sử dụng bộ dữ liệu ShareGPT² để đào tạo LLaMA-2-70B-chat và Vicuna-13B (Zheng et al., 2023a). Chúng tôi chọn 5 lớp đầu tiên làm mô hình dự thảo cho các mô hình 70B và 3 lớp đầu tiên cho các mô hình 13B. Để so sánh công bằng, chúng tôi đào tạo mô hình của chúng tôi và Medusa (Cai et al., 2023) sử dụng cùng dữ liệu và đặt đầu Medusa ở 4. Chi tiết đào tạo khác có thể được tìm thấy trong Phụ lục C.

Giai đoạn đánh giá Chúng tôi tiến hành thí nghiệm trên ba bộ tiêu chuẩn dưới thiết lập 1-shot: Gsm8k (Cobbe et al., 2021), XSum (Narayan et al., 2018) và Humaneval (Chen et al., 2021). Và chúng tôi cũng đánh giá EESD trên MT-bench (Zheng et al., 2023b). Chúng tôi chọn ngẫu nhiên 500 trường hợp từ tập kiểm tra để đánh giá. Và chúng tôi đặt độ dài đầu ra cuối cùng ở 512 và kích thước batch ở 1. Chúng tôi đặt bước dự thảo K ở 10 cho Vanilla SD (Chen et al., 2023) và Self SD (Zhang et al., 2023b). Kết quả được báo cáo là trung bình của 10 lần chạy khác nhau. Chúng tôi chỉ tiến hành trên thế hệ tham lam³, vì các phát hiện từ lấy mẫu top-p thể hiện xu hướng tương tự.

Các chỉ số Chúng tôi đề xuất một Trung bình Điều hòa (HM) để đánh giá chất lượng của token dự thảo và chiến lược để tạo ra chúng, trong khi công thức tính toán cụ thể là S = 2*vd*rd/(vd+rd)*100%, trong đó vd chỉ ra phần trăm token dự thảo được chấp nhận bởi mô hình đích, và rd đại diện cho tỷ lệ token đến từ mô hình dự thảo. Giải thích chi tiết hơn trong Phụ lục D. Do quá trình xác thực, tất cả các phương pháp cơ sở và EESD có thể đảm bảo rằng kết quả tạo ra giống hệt với LLM gốc, do đó chúng tôi chỉ cần so sánh tăng tốc của chúng.

Tất cả các thí nghiệm được tiến hành trên GPU NVIDIA A100-80GB.

4.2 Kết quả chính

Chúng tôi báo cáo kết quả đánh giá cho Gsm8k và XSum trong Bảng 1, cho Humaneval trong Bảng 2 và cho MT-bench trong Bảng 3. Như được hiển thị trong Bảng 1, 2 và 3, rõ ràng là EESD vượt trội đáng kể so với các phương pháp trước đây trên cả mô hình 13B và 70B, đặc biệt trên LLaMA-2-70B, điều này chứng minh hiệu quả của phương pháp chúng tôi. Có một số quan sát chính từ những kết quả này. Thứ nhất, chúng tôi quan sát thấy EESD có thể mang lại tăng tốc 2.45 × lần trên CodeLLaMA-2-13B cho nhiệm vụ mã hóa, cho thấy

²https://huggingface.co/datasets/Aeala/ShareGPT_Vicuna_unfiltered
³Đối với tất cả các thí nghiệm, chúng tôi chỉ tạo ra một ứng viên token dự thảo top-1 trong Bước 6 của Thuật toán 1, và giữ lại kết quả nhất quán với token top-1 của mô hình đích khi xác thực ở Bước 15 của Thuật toán 1.

--- TRANG 6 ---
[Bảng 1: Đánh giá trên Gsm8k và XSum với các phương pháp khác nhau - bảng dài với nhiều dòng dữ liệu]

[Bảng 2: Đánh giá trên Humaneval với các phương pháp giải mã suy đoán khác nhau]

[Bảng 3: Đánh giá trên MT-bench với các phương pháp giải mã suy đoán khác nhau]

phương pháp của chúng tôi thể hiện hiệu quả đặc biệt trong lĩnh vực này. Thứ hai, so với Vanilla SD và Medusa, EESD cho thấy kết quả vượt trội với ít tham số đào tạo và triển khai hơn. Ví dụ, EESD đạt được tốc độ nhanh hơn lên đến 2.13 × và 1.80 × lần trên mô hình llama-2-70b chỉ với 1.12B tham số được đào tạo. Trong khi chúng tôi giới thiệu một quá trình đào tạo bổ sung so với Self-SD, chúng tôi quản lý để cải thiện đáng kể hiệu quả tốc độ, sử dụng tài nguyên đào tạo tối thiểu. Thứ ba, chúng tôi phát hiện ra rằng khả năng mạnh hơn của mô hình dự thảo, được chỉ ra bởi giá trị HM cao hơn, không nhất thiết dẫn đến tăng tốc cao hơn. Điều cần thiết là phải xem xét tốc độ tạo ra token dự thảo, và phương pháp của chúng tôi có thể tạo ra sự cân bằng tối ưu giữa hai yếu tố này để đạt được tăng tốc cao hơn (chi tiết trong Phụ lục D).

5 Phân tích và Thảo luận

5.1 Nghiên cứu Loại bỏ

Để làm rõ tác động của các thành phần khác nhau trong phương pháp của chúng tôi, chúng tôi tiến hành một loạt các nghiên cứu loại bỏ. Trong Bảng 4, chúng tôi trình bày kết quả thí nghiệm

--- TRANG 7 ---
[Bảng 4: Nghiên cứu loại bỏ các thành phần khác nhau dựa trên LLaMA-2-13B]

kết quả, và một số hiểu biết đáng kể có thể được suy ra. Thứ nhất, chúng tôi nhận thấy một sự giảm đáng kể trong hiệu suất của mô hình khi chúng tôi thay thế điều khiển TS bằng một giá trị K cố định, điều này biểu thị hiệu quả của phương pháp được đề xuất của chúng tôi để quản lý việc tạo ra token dự thảo. Thứ hai, tương tự như phương pháp trước đây, chúng tôi giới thiệu một đầu lm có thể đào tạo ngay sau N lớp đầu tiên, bỏ qua Lớp Thoát Sớm. Tuy nhiên, sự sửa đổi như vậy dẫn đến sự suy giảm đáng kể trong hiệu suất của mô hình, cho thấy mạnh mẽ vai trò cơ bản của Lớp Thoát Sớm trong việc duy trì chất lượng của token dự thảo. Thứ ba, một quan sát đáng chú ý là phương pháp của chúng tôi đạt được kết quả đáng khen ngợi chỉ với dữ liệu nguồn mở, đặc biệt trên XSum. Hơn nữa, hiệu suất có thể được cải thiện với việc bổ sung tự chưng cất, chứng minh tính hữu ích của dữ liệu được tạo ra bởi LLM gốc. Thứ tư, trong phương pháp Cali-TS, vai trò của dự đoán mẫu vượt qua dự đoán mô hình, và sự tích hợp của cả hai có thể mang lại kết quả tối ưu hơn.

5.2 Cơ chế điều khiển TS có thể dự đoán các bước dự thảo tối ưu không?

Để điều tra khả năng của cơ chế điều khiển TS trong việc tự động xác định số lượng token dự thảo trong mỗi vòng, chúng tôi tiến hành thí nghiệm về ảnh hưởng của việc thay đổi các bước dự thảo K. Như được minh họa trong Hình 3, giá trị K tối ưu khác nhau qua các mô hình và bộ dữ liệu, nhưng TS với phân phối Beta luôn vượt qua nhẹ hiệu quả của giá trị K tối ưu. Hơn nữa, với sự thúc đẩy từ dự đoán mô hình, TS với hiệu chỉnh có thể đạt được hiệu quả gia tốc tốt hơn. Thí nghiệm xác nhận rằng cơ chế điều khiển TS có thể dự đoán thích ứng độ dài tối ưu để tạo ra token dự thảo trong mỗi vòng.

[Hình 3: Đánh giá tăng tốc trong việc tạo ra 512 token sử dụng phương pháp EESD với các giá trị K khác nhau]

5.3 Tính tổng quát của cơ chế điều khiển TS

Để xác minh tính tổng quát và hiệu quả của cơ chế điều khiển TS được đề xuất, chúng tôi tiếp tục áp dụng nó cho các mô hình SD khác thay vì một K được xác định trước. Kết quả được báo cáo trong Bảng 5. Theo kết quả, chúng ta có thể quan sát thấy rằng cơ chế điều khiển TS có thể được tích hợp dễ dàng vào các phương pháp SD khác để nâng cao hiệu suất của chúng. Lưu ý rằng kết quả trong Bảng 5 khác với kết quả của w/o TS trong nghiên cứu loại bỏ. Trong nghiên cứu loại bỏ, chúng tôi đặt K ở 10, điều này không phải là một thiết lập vượt trội, và như được hiển thị trong Hình 3, K=5 là một thiết lập tốt hơn cho EESD của LLaMA-2-13B. Tuy nhiên, đối với vanilla SD và self SD, K=10 là một thiết lập phù hợp.

[Bảng 5: Tăng tốc của các phương pháp SD khác với cơ chế điều khiển TS]

5.4 Ảnh hưởng của N lớp đầu tiên

Các thí nghiệm của chúng tôi khám phá tác động của việc thay đổi số lượng N lớp đầu tiên. Như được hiển thị trong Hình 4, việc sử dụng nhiều lớp hơn cải thiện chất lượng của token dự thảo, được đo bằng giá trị HM cao hơn. Tuy nhiên, tăng tốc end-to-end không tương ứng tăng cùng với chất lượng dự thảo. Điều này cho thấy rằng thời gian bổ sung cần thiết để tạo ra token dự thảo với nhiều lớp hơn bù đắp một phần tăng tốc end-to-end.

--- TRANG 8 ---
[Hình 4: Ảnh hưởng của các N lớp đầu tiên khác nhau]

[Hình 5: Ảnh hưởng của việc thay đổi số lượng lớp Thoát Sớm]

Kết quả cho thấy rằng việc tăng cường lớp chỉ dẫn đến cải thiện nhẹ trong chất lượng của token dự thảo. Do đó, việc sử dụng ít lớp hơn để tạo ra token dự thảo chứng minh là một chiến lược hiệu quả. Ngoài ra, đối với các mô hình lớn hơn, như 70B, giá trị của N cần phải lớn hơn một chút. Và được gợi ý theo kinh nghiệm rằng N nên là 5%-10% của tổng số lớp LLM.

5.5 Một lớp Transformer là tốt nhất cho lớp Thoát Sớm?

Như được chứng minh trong Bảng 4, đã được chứng minh rằng việc thêm một lớp Transformer sau N lớp đầu tiên cải thiện đáng kể hiệu suất của mô hình dự thảo. Để điều tra thêm, chúng tôi đánh giá hiệu quả của việc tăng số lượng lớp Transformer. Hình 5 minh họa rằng việc tăng cường số lượng lớp Transformer sau N lớp đầu tiên thực sự mang lại cải thiện trong chất lượng token dự thảo. Tuy nhiên, vì mức độ cải thiện này tương đối nhỏ, nó dẫn đến giảm tăng tốc end-to-end tổng thể. Do đó, thí nghiệm cho thấy rằng một lớp Transformer đơn lẻ là đủ để đảm bảo chất lượng của token dự thảo, và cân bằng hoàn hảo chất lượng và tốc độ tạo ra token dự thảo để đạt được tăng tốc end-to-end tối ưu.

5.6 Hiệu quả Đào tạo

Chúng tôi so sánh hiệu quả đào tạo của ba phương pháp, được kiểm tra trên GPU NVIDIA A100-80G. Chúng tôi đặt kích thước batch thành 64 và sử dụng bộ dữ liệu SlimPajama để đào tạo những mô hình này. Như được hiển thị trong Bảng 6, EESD chỉ yêu cầu tải các tham số của N lớp đầu tiên và lớp Thoát Sớm, trong khi Medusa yêu cầu tải tất cả các tham số của LLM và các đầu Medusa. Đáng chú ý, trong quá trình đào tạo, mặc dù cả Medusa và EESD chỉ cập nhật một phần tham số, Medusa yêu cầu mỗi mẫu được tính toán qua toàn bộ mạng LLM. Ngược lại, EESD chỉ cần tính toán qua N lớp đầu tiên. Do đó, so với Medusa và Vanilla SD, EESD giảm đáng kể cả thời gian đào tạo và tiêu thụ bộ nhớ.

[Bảng 6: Hiệu quả đào tạo của ba phương pháp trên A100-80GB]

5.7 Triển khai Tree Attention

Tree attention đã là một kỹ thuật phổ biến trong việc tăng tốc suy luận (Miao et al., 2023; Spector và Ré, 2023). Kỹ thuật này hoạt động bằng cách cấu trúc nhiều ứng viên token dự thảo trong một khung cây, cho phép LLM xác thực đồng thời một số chuỗi dự thảo tiềm năng thông qua giải mã song song. Nó tăng đáng kể tỷ lệ chấp nhận, do đó tăng cường tốc độ tổng thể của việc tạo ra end-to-end. Như được hiển thị trong Bảng 7, chúng ta có thể dễ dàng triển khai cơ chế tree attention cho EESD, dẫn đến sự gia tăng đáng kể về tốc độ. Nó có thể đạt được tăng tốc lên đến 2.48 × và 1.96 × lần trên LLaMA-2-70B, cũng như lên đến 2.18 × và 2.12 × lần tăng tốc trên LLaMA-2-13B.

[Bảng 7: Tăng tốc của EESD với việc triển khai tree attention]

5.8 Phân tích Tính toán

Bảng 8 trình bày một phân tích về thời gian tính toán cần thiết cho EESD tạo ra trên 200 trường hợp được chọn ngẫu nhiên từ XSum. Kết quả cho thấy rằng Cali-TS thể hiện tiêu thụ thời gian cao hơn so với Beta-TS trong giai đoạn lấy mẫu. Tuy nhiên, Cali-TS giảm đáng kể việc sử dụng thời gian trong các giai đoạn dự thảo và xác thực, do khả năng điều khiển vượt trội của nó đối với quá trình tạo token dự thảo. Do đó, Cali-TS có thể mang lại tiêu thụ thời gian tổng thể thấp hơn.

[Bảng 8: Phân tích thời gian tính toán cho EESD]

6 Kết luận

Trong công trình này, chúng tôi đề xuất EESD, một phương pháp mới được thiết kế để tăng tốc LLM không mất mát bằng cách tận dụng N lớp đầu tiên của nó để tạo ra token dự thảo và sử dụng Thompson Sampling để điều chỉnh quá trình này. Cụ thể, chúng tôi giới thiệu một lớp Thoát Sớm sau N lớp đầu tiên và đào tạo nó bằng cách sử dụng tự chưng cất, điều này tạo ra sự cân bằng tối ưu giữa hiệu quả và hiệu suất của việc tạo token dự thảo. Hơn nữa, chúng tôi thiết kế một phương pháp lai mới kết hợp hiệu quả dự đoán mô hình và dự đoán lấy mẫu, dẫn đến cải thiện tốc độ tạo ra đáng kể. Sau khi tiến hành các thí nghiệm toàn diện, kết quả chứng minh rằng EESD không chỉ đạt được tăng tốc suy luận đáng kể mà còn giảm đáng kể cả thời gian đào tạo và tiêu thụ bộ nhớ, so với các phương pháp giải mã suy đoán trước đây.

Hạn chế

Trong phần này, chúng tôi thảo luận về các hạn chế của công trình như sau. Thứ nhất, trong khi chúng tôi đã đưa ra một gợi ý thực nghiệm cho việc thiết lập giá trị N trong N lớp đầu tiên, chúng tôi chưa nghiên cứu kỹ lưỡng chức năng của những lớp đầu tiên này và cách chúng ảnh hưởng đến đầu ra cuối cùng. Chúng tôi tin rằng một cuộc điều tra chi tiết hơn về điều này sẽ hữu ích cho việc chọn giá trị N tối ưu. Do đó, chúng tôi sẽ tiến hành nghiên cứu này trong công việc tương lai. Thứ hai, chúng tôi đề xuất một mô hình để dự đoán liệu token dự thảo có nhất quán với token của LLM trong Phần 3.3 hay không. Tuy nhiên, mô hình này có một số lượng lớn tham số, điều này không rất thân thiện cho đào tạo và triển khai. Do đó, chúng tôi dự định tinh chỉnh cấu trúc của mô hình để cải thiện hiệu quả của nó trong công việc tương lai.

Lời cảm ơn

Jingang Wang được tài trợ bởi Beijing Nova Program (Grant NO. 20220484098). Chúng tôi chân thành cảm ơn tất cả các nhà đánh giá vì những bình luận và gợi ý có giá trị của họ, điều này rất quan trọng để cải thiện công việc của chúng tôi.

[Tiếp theo là phần Tài liệu tham khảo và Phụ lục với nhiều chi tiết kỹ thuật - tôi sẽ tiếp tục dịch nếu cần]

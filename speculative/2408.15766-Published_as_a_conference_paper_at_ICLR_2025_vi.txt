# 2408.15766.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/speculative/2408.15766.pdf
# Kích thước file: 603718 bytes

===============================================
NỘI DUNG FILE PDF
===============================================


--- TRANG 1 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2025
HỌC BIỂU DIỄN HÀI HÒA CHO
LẤY MẪU SUY ĐOÁN
Lefan Zhang, Xiaodan Wang, Yanhua Huang∗, Ruiwen Xu
Xiaohongshu Inc.
Shanghai, China
{lefan,xiaodan2,yanhuahuang,ruiwenxu }@xiaohongshu.com
TÓM TẮT
Lấy mẫu suy đoán là một phương pháp đầy hứa hẹn để tăng tốc giai đoạn giải mã
cho các Mô hình Ngôn ngữ Lớn (LLMs). Những tiến bộ gần đây tận dụng thông
tin ngữ cảnh của LLM đích, chẳng hạn như trạng thái ẩn và KV cache, đã cho
thấy những cải thiện thực tế đáng kể. Tuy nhiên, những phương pháp này gặp
phải vấn đề ngữ cảnh không nhất quán giữa huấn luyện và giải mã. Chúng tôi
cũng quan sát thấy một sự khác biệt khác giữa các mục tiêu huấn luyện và giải
mã trong các phương pháp lấy mẫu suy đoán hiện có. Trong công trình này, chúng
tôi đề xuất một giải pháp có tên HArmonized Speculative Sampling (HASS) để
học các biểu diễn hài hòa nhằm giải quyết những vấn đề này. HASS tăng tốc giai
đoạn giải mã mà không thêm chi phí suy luận thông qua chưng cất mục tiêu hài
hòa và căn chỉnh ngữ cảnh hài hòa. Các thí nghiệm trên bốn mô hình LLaMA
cho thấy HASS đạt được tỉ lệ tăng tốc thời gian thực từ 2.81x-4.05x trung bình
trên ba bộ dữ liệu, vượt trội hơn EAGLE-2 từ 8%-20%. Mã nguồn có sẵn tại
https://github.com/HArmonizedSS/HASS .
1 GIỚI THIỆU
Các Mô hình Ngôn ngữ Lớn sinh (LLMs), chẳng hạn như GPT-4 (Achiam et al., 2023) và LLaMA (Touvron et al., 2023), đã thể hiện khả năng đáng chú ý trên một loạt rộng các nhiệm vụ. Tuy nhiên, việc giải mã hiệu quả từ những mô hình này đặt ra một thách thức đáng kể do cơ chế giải mã tự hồi quy vốn có, điều này hạn chế khả năng ứng dụng của chúng trong các tình huống nhạy cảm về thời gian.
Lấy mẫu suy đoán (Chen et al., 2023; Leviathan et al., 2023) cung cấp một giải pháp bằng cách tận dụng các tài nguyên bổ sung để tăng tính đồng thời. Cụ thể, nó sử dụng một mô hình draft hiệu quả để tạo các token draft một cách tự hồi quy, sau đó được xác minh đồng thời bởi LLM đích. Dựa trên kết quả xác minh, một tập con các token draft bảo toàn cùng phân phối với LLM đích được chấp nhận như đầu ra cuối cùng.
Leviathan et al. (2023) cho thấy hiệu suất thực tế của lấy mẫu suy đoán có liên quan chặt chẽ đến hai yếu tố: chi phí giải mã của mô hình draft và sự căn chỉnh của nó với LLM đích. Để phát triển các mô hình draft hiệu quả được căn chỉnh tốt với LLM đích, các công trình trước đây đề xuất tận dụng thông tin ngữ cảnh của LLM đích (Xiao et al., 2024; Li et al., 2024b;c; Du et al., 2024). Ví dụ, EAGLE (Li et al., 2024b;c) sử dụng các trạng thái ẩn trước đó của LLM đích làm đặc trưng đầu vào của mô hình draft. Tuy nhiên, những phương pháp này gây ra ngữ cảnh không nhất quán giữa huấn luyện và giải mã, như được minh họa trong Hình 2. Trong quá trình huấn luyện, mô hình draft luôn có quyền truy cập vào các trạng thái ẩn của LLM đích ở các bước thời gian trước đó. Tuy nhiên, trong quá trình giải mã, mô hình draft không thể truy cập các trạng thái ẩn của LLM đích cho các bước thời gian chưa được xác minh, dẫn đến sự không căn chỉnh ngữ cảnh giữa huấn luyện và giải mã. Vấn đề này có thể được xem như một dạng bias phơi bày (Bengio et al., 2015; Wang & Sennrich, 2020) ở cấp độ đặc trưng trong lấy mẫu suy đoán.
Một sự khác biệt khác cũng được quan sát thấy giữa các mục tiêu của giai đoạn huấn luyện và giải mã. Trong giai đoạn giải mã, mục tiêu của mô hình draft là đề xuất các token mà LLM đích có khả năng gán xác suất cao (Li et al., 2024c; Miao et al., 2024; Sun et al., 2024). Trong tình huống này, mô hình draft nên tập trung nhiều hơn vào việc ghi nhớ các token mong muốn, trong khi thứ tự cụ thể
∗Tác giả liên hệ.
1arXiv:2408.15766v3  [cs.LG]  26 Feb 2025

--- TRANG 2 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2025
LLaMA2-Chat 7B T=0 LLaMA2-Chat 13B T=0 LLaMA3-Instruct 8B T=0 LLaMA3-Instruct 70B T=0 LLaMA2-Chat 7B T=1 LLaMA2-Chat 13B T=1 LLaMA3-Instruct 8B T=1 LLaMA3-Instruct 70B T=1
Mô hình0.00.51.01.52.02.53.03.54.0Tăng tốc3.24x3.65x
3.09x4.05x
2.90x3.48x
2.81x3.85x
2.81x3.30x
2.83x3.37x
2.60x3.21x
2.47x3.28x
2.01x2.22x
1.71x2.43x
1.76x2.05x
1.44x2.09xHASS
EAGLE-2
EAGLE
Hình 1: Tỉ lệ tăng tốc của các phương pháp khác nhau trên LLaMA2-Chat 7/13B và LLaMA3-Instruct 8/70B với nhiệt độ T ∈ {0,1}, trung bình trên các bộ dữ liệu MT-bench, HumanEval, và GSM8K.
của những token này có thể được nhấn mạnh ít hơn. Hơn nữa, hầu hết các ứng dụng LLM thực hiện nucleus sampling (Holtzman et al., 2020) hoặc top-k sampling (Fan et al., 2018). Đối với các mục tiêu giải mã này, các token có xác suất cao đóng vai trò quan trọng hơn trong việc xác định đầu ra. Do đó, để phát triển các mô hình draft hiệu quả, các mục tiêu huấn luyện của chúng nên xem xét những đặc tính này gặp phải trong giai đoạn giải mã. Theo hiểu biết tốt nhất của chúng tôi, các công trình trước đây về huấn luyện mô hình draft cho lấy mẫu suy đoán phần lớn đã bỏ qua những cân nhắc giải mã này.
MộtLớpTựHồiQuy𝑒!"#𝑓!"$(&)𝑒!𝑓!"#(&)𝑒!(#𝑣!"())/𝑓!(&)LLMĐích𝑓!())𝑓!(#())ĐầuDự Đoán&LấyMẫu𝑥!(#𝑥!($
NhấtQuántiếntrìnhHuấnLuyệntiếntrìnhGiảiMãtiếntrìnhTokenchưađượcxácminh
Hình 2: Chúng tôi sử dụng EAGLE (Li et al., 2024b) làm ví dụ để minh họa sự không căn chỉnh ngữ cảnh, trong đó việc suy đoán bắt đầu từ bước thời gian t. f(l) và f(s) đại diện cho các trạng thái ẩn từ LLM đích và mô hình draft. Khi giải mã token draft xt+2, ngữ cảnh đầu vào không nhất quán giữa huấn luyện và giải mã.Trong bài báo này, chúng tôi giới thiệu HArmonized Speculative Sampling (HASS), một phương pháp mới được thiết kế để giải quyết những vấn đề nêu trên bằng cách học các biểu diễn hài hòa. Cụ thể, để làm cho các mô hình draft nhận thức về chiến lược giải mã, HASS mở rộng ý tưởng chưng cất xếp hạng (Tang & Wang, 2018) từ hệ thống gợi ý sang lấy mẫu suy đoán, dẫn đến một mất mát chưng cất tập trung vào các token có khả năng cao nhất trong phân phối đích. Để giảm thiểu sự không căn chỉnh ngữ cảnh đã thảo luận trước đây giữa huấn luyện và giải mã, HASS sử dụng một chiến lược huấn luyện căn chỉnh ngữ cảnh. Cùng nhau, hai chiến lược này của HASS cải thiện hiệu suất tăng tốc mà không có bất kỳ chi phí suy luận nào và duy trì hiệu quả huấn luyện.
Chúng tôi tiến hành thí nghiệm trên các nhiệm vụ đối thoại, tạo mã, và lý luận toán học sử dụng các bộ dữ liệu MT-bench, HumanEval, và GSM8K tương ứng. Xây dựng với EAGLE-2 (Li et al., 2024c), HASS đạt được cải thiện độ dài chấp nhận 8%-16% so với nó trên LLaMA2-Chat 7/13B và LLaMA3-Instruct 8/70B, dẫn đến tăng tốc thời gian thực từ 2.81x-4.05x so với suy luận vanilla trên GPU NVIDIA H800.
2 SƠ BỘ
Lấy mẫu suy đoán tận dụng khái niệm thực thi suy đoán (Kung & Robinson, 1981; Hennessy & Patterson, 2011) để giảm thời gian thực từ tính đồng thời cao hơn. Cụ thể, cho LLM đích M(l) là trọng tâm của việc tăng tốc, lấy mẫu suy đoán sử dụng một mô hình draft
2

--- TRANG 3 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2025
M(s) để tạo các token draft một cách suy đoán và hiệu quả. Phương pháp thông thường (Leviathan et al., 2023; Chen et al., 2023) phân tách việc tạo bước tiếp theo thành ba bước:
•M(s) đề xuất một chuỗi draft chưa xác minh với độ dài L bằng giải mã tự hồi quy.
•M(l) đánh giá xác suất hậu nghiệm của L token draft song song.
•τ token giữ nguyên phân phối đích được chấp nhận bởi một lược đồ lấy mẫu từ chối được sửa đổi dựa trên chuỗi draft và khoảng cách phân phối.
Leviathan et al. (2023) chứng minh rằng tỉ lệ cải thiện thời gian thực tỉ lệ thuận với τ, trong khi tỉ lệ gia tăng phép toán số học tỉ lệ nghịch với τ. Do đó, τ, còn được gọi là độ dài chấp nhận, đóng vai trò quan trọng trong việc xác định hiệu suất tăng tốc. Phân tích này cũng áp dụng khi sử dụng nhiều chuỗi draft (Miao et al., 2024; Li et al., 2024c;b; Sun et al., 2024). Lưu ý rằng τ có liên quan chặt chẽ đến khoảng cách phân phối giữa LLM đích và mô hình draft. Với yêu cầu giải mã hiệu quả, mô hình draft thường có khả năng hạn chế, dẫn đến khoảng cách phân phối đáng kể so với LLM đích. May mắn thay, trong quá trình suy luận, tỷ lệ chấp nhận chủ yếu bị ảnh hưởng bởi sự căn chỉnh của các phân phối trên các token mong muốn, tức là các token mà LLM đích gán xác suất cao. Tuy nhiên, các công trình lấy mẫu suy đoán trước đây chủ yếu tập trung vào toàn bộ tập từ vựng w.r.t. chưng cất kiến thức từ LLM đích (Li et al., 2024b; Zhou et al., 2024), do đó ngắt kết nối quá trình huấn luyện khỏi các yêu cầu giải mã thực tế.
EAGLE (Li et al., 2024b) là một thiết kế mô hình draft nhẹ, như được hiển thị trong Hình 2. Trong quá trình giải mã, nó sử dụng LM Head của LLM đích để tạo các token draft. Cụ thể, chúng ta giả định rằng suy đoán bắt đầu từ bước thời gian t, có nghĩa là token draft đầu tiên ở bước thời gian t+ 1. Để tạo token draft xt+1, trạng thái ẩn f(l)t−1 của LLM đích ở lớp thứ hai từ trên xuống được nối với embedding et để thực hiện đầu vào của mô hình draft. Trong quá trình huấn luyện, EAGLE xây dựng một nhiệm vụ hồi quy giữa f(l)s và các trạng thái ẩn được dự đoán f(s)s của mô hình draft. Tuy nhiên, do giải mã tự hồi quy, mô hình draft chỉ truy cập các đặc trưng của LLM đích ở đầu suy đoán. Nó sử dụng các đặc trưng do chính nó tạo ra làm đầu vào cho các bước tiếp theo. Sự không căn chỉnh ngữ cảnh này, xuất phát từ sự không chính xác của đặc trưng, dẫn đến tích lũy lỗi và cản trở hiệu suất tạo các token draft sau này (Li et al., 2024b; Du et al., 2024). EAGLE-2 (Li et al., 2024c) sử dụng cùng thiết kế mô hình nhưng làm việc trên các cấu trúc draft động thay vì cấu trúc cây tĩnh trong giai đoạn giải mã, tuy nhiên vấn đề nêu trên vẫn chưa được giải quyết.
3 PHƯƠNG PHÁP
Như đã nêu trước đây, các phương pháp lấy mẫu suy đoán trước đây gặp phải sự không hài hòa giữa huấn luyện và giải mã. Phần này giới thiệu HArmonized Speculative Sampling (HASS) để giải quyết sự không căn chỉnh mục tiêu và sự không nhất quán ngữ cảnh thông qua chưng cất mục tiêu hài hòa và căn chỉnh ngữ cảnh hài hòa tương ứng, như được mô tả dưới đây.
3.1 CHƯNG CẤT MỤC TIÊU HÀI HÒA
HASS ưu tiên các token mong muốn nhất trong giải mã bằng cách tận dụng ý tưởng chưng cất xếp hạng (Tang & Wang, 2018) từ hệ thống gợi ý. Cụ thể, chưng cất xếp hạng nhằm mục đích huấn luyện một mô hình học sinh để gán thứ hạng cao hơn cho các mục được xếp hạng cao nhất bởi mô hình giáo viên. Trong bối cảnh lấy mẫu suy đoán, mô hình draft và LLM đích đóng vai trò là học sinh và giáo viên tương ứng. Các mô hình draft có đặc tính tương tự sẽ thực hiện ở tỷ lệ chấp nhận cao hơn trong giai đoạn giải mã. Xem xét tập hợp K token có xác suất cao nhất từ phân phối xác suất của LLM đích là ˆΩ⊂Ω, trong đó Ω đại diện cho toàn bộ từ vựng. HASS xem xét mất mát chưng cất Top-K sau đây:
LTop-K =−X
x∈ˆΩq(x) logp(x), (1)
trong đó q và p là các phân phối xác suất token tiếp theo của LLM đích và mô hình draft tương ứng. Lưu ý rằng, khi tích hợp với EAGLE, giai đoạn huấn luyện có thể thu được ˆΩ từ các trạng thái ẩn của LLM đích. Điều này có nghĩa là hàm mất mát được đề xuất hưởng lợi từ cùng chi phí huấn luyện hiệu quả như EAGLE. Chúng tôi đánh giá mất mát chưng cất Top-K được đề xuất so với sáu mất mát thay thế, chẳng hạn như BiLD (Li et al., 2024a) và Recall@k Surrogate loss (Patel et al., 2022), thông qua các nghiên cứu loại bỏ.
3

--- TRANG 4 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2025
3.2 CĂN CHỈNH NGỮ CẢNH HÀI HÒA
HASSHuấnLuyệnBước1/EAGLEHuấnLuyệnℳ(")!(")"(")!!"$"!"*(&)!!"#"!"$(&)!!"!"#(&)!!(#"!(&)
ℳ(")!%($#)!!"$"!"*(&)!!"#"!"$()!)!!"!"#()")!!(#"!()#)"%&'("),"%&(($!),"%&)($"),"%($#)ℳ(")!%&'(")!!"$"!"*(&)"%&'(")
ℳ(")!%&(($!)!!"$"!"*(&)!!"#"!"$()!)"%&'("),"%&(($!)
ℳ(")!%&)($")!!"$"!"*(&)!!"#"!"$()!)!!"!"#()")"%&'("),"%&(($!),"%&)($")
HASS/EAGLEGiảiMãHASSHuấnLuyệnBước2ℳ(")!($!)!!"$!!"#!!!!(#"!"*(&)"!"$(&)"!"#(&)"!(&)"!"*(&)"!"$()!)"!"#()!)"!()!)"("),"($!)
HASSHuấnLuyệnBước3ℳ(")!($")"("),"($!),"($")!!"$!!"#!!!!(#"!"*(&)"!"$(&)"!"#(&)"!(&)"!"*(&)"!"$()!)"!"#()!)"!()!)"!"*(&)"!"$()!)"!"#()")"!()")ℳ(")!($#)"("),"($!),"($"),"($#)!!"$!!"#!!!!(#"!"*(&)"!"$(&)"!"#(&)"!(&)"!"*(&)"!"$()!)"!"#()!)"!()!)"!"*(&)"!"$()!)"!"#()")"!()!)"!"*(&)"!"$()!)"!"#()")"!()#)HASSHuấnLuyệnBước4
Hình 3: Huấn luyện với căn chỉnh ngữ cảnh hài hòa, trong đó q và k tham chiếu đến các trạng thái query và key trong lớp transformer tương ứng. Chỉ số trên (l) ký hiệu các tensor từ LLM đích, và chỉ số trên (sj) ký hiệu các tensor từ lần forward thứ j của mô hình draft. Lưu ý rằng trong quá trình huấn luyện (sj) tham chiếu đến việc gọi j lần mô hình draft trong một batch, trong khi trong quá trình suy luận (sj) tham chiếu đến giải mã tự hồi quy thứ j.
HASS tuân theo một lược đồ căn chỉnh ngữ cảnh để căn chỉnh huấn luyện và giải mã trên các ngữ cảnh của chúng. Quy trình huấn luyện của HASS được chia thành n bước, cho phép mô hình draft sử dụng các đặc trưng ngữ cảnh nhất quán với những đặc trưng trong giai đoạn giải mã và giải quyết sự không nhất quán ngữ cảnh bằng cách thích ứng với các đặc trưng không chính xác được tạo ra trong các bước huấn luyện HASS trước đó. Cụ thể, nó được thực hiện bằng cách đầu tiên lấy đặc trưng không chính xác từ mô hình draft cuối cùng làm query, sau đó xem xét sự tích lũy không chính xác trong phần key-value của khối transformer.
Một cách chính thức, trong bước huấn luyện HASS j, cho chuỗi token đầu vào x1, x2, .., x T, chúng ta tối ưu hóa mô hình draft M(s) với hàm mục tiêu sau:
min
M(s)T−1X
t=1[CrossEntropy (P(l)(xt+1|x1, . . . , x t), P(s)(xt+1|x1, . . . , x t)) + Aux-loss ],trong đó
P(s)(xt+1|x1, . . . , x t) =Head(f(sj)
t+1)
=Head(M(s)(Từ draft cuối cùngz}|{
f(sj−1)
t|{z}
query,Từ LLM đíchz }| {
f(l)
1⊕ ··· ⊕ f(l)
t−j+1⊕Từ các mô hình draft trước đóz }| {
f(s1)
t−j+2⊕ ··· ⊕ f(sj−1)
t| {z }
key & value)),
4

--- TRANG 5 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2025
Nhiệt độ = 0 Nhiệt độ = 1
Mô hình Phương pháp MT-bench HumanEval GSM8K Trung bình MT-bench HumanEval GSM8K Trung bình
L2 7BPLD 1.43 1.59 1.37 1.46 - - - -
Lookahead 1.66 1.77 1.65 1.69 - - - -
SpS (V-68M) 2.02 2.03 2.04 2.03 1.72 1.50 1.65 1.62
SpS (L-68M) 1.83 1.81 1.83 1.82 1.47 1.36 1.46 1.43
Medusa 2.34 2.48 2.37 2.40 2.35 2.56 2.40 2.44
EAGLE 3.68 3.90 3.77 3.78 3.45 3.67 3.62 3.58
EAGLE-2 4.44 4.78 4.60 4.61 4.23 4.47 4.50 4.40
HASS 4.99 5.29 5.17 5.15 4.84 4.91 5.01 4.92
L2 13BPLD 1.46 1.70 1.44 1.53 - - - -
Lookahead 1.64 1.85 1.69 1.73 - - - -
SpS (V-68M) 2.13 2.61 2.21 2.32 1.73 2.25 1.81 1.93
SpS (L-68M) 1.83 1.67 1.70 1.73 1.50 1.34 1.45 1.43
Medusa 2.51 2.56 2.70 2.59 2.53 2.89 2.72 2.71
EAGLE 3.86 4.50 4.17 4.18 3.62 4.27 3.98 3.96
EAGLE-2 4.74 5.57 5.17 5.16 4.60 5.41 5.03 5.01
HASS 5.13 6.05 5.55 5.58 4.98 5.86 5.41 5.42
L3 8BEAGLE 2.91 3.66 3.57 3.38 2.67 3.35 3.30 3.11
EAGLE-2 4.21 4.93 4.42 4.52 3.90 4.73 4.30 4.31
HASS 4.68 5.54 5.02 5.08 4.26 5.30 4.85 4.80
L3 70BEAGLE 3.24 4.07 3.79 3.70 3.06 3.85 3.66 3.52
EAGLE-2 4.10 5.02 4.37 4.50 4.00 4.93 4.35 4.43
HASS 4.62 5.78 5.24 5.21 4.59 5.68 5.20 5.16
Bảng 1: Độ dài chấp nhận τ của các phương pháp khác nhau trên các bộ dữ liệu MT-bench, HumanEval, và GSM8K với nhiệt độ T ∈ {0,1}. L2 đại diện cho LLaMA2-Chat, trong khi L3 đại diện cho LLaMA3-Instruct. SpS viết tắt cho Vanilla Speculative Sampling, trong khi V-68M và L-68M đại diện cho Vicuna-68M và LLaMA-68M, là các mô hình draft của SpS.
P(l) là phân phối xác suất tự hồi quy được cung cấp bởi LLM đích, Aux-loss bao gồm mất mát Top-K được đề xuất và mất mát hồi quy đặc trưng (theo EAGLE), Head và ⊕ đại diện cho đầu mô hình hóa ngôn ngữ và phép toán nối tương ứng. Khi huấn luyện các token trong toàn bộ chuỗi song song, công thức trên thích ứng với các đặc trưng không chính xác từ j−1 bước trước đó cho tất cả các vị trí trừ j−1 vị trí đầu tiên. Lưu ý rằng so với EAGLE, HASS có chi phí huấn luyện bổ sung do n−1 bước huấn luyện thêm để thích ứng với các đặc trưng không chính xác, trong khi duy trì cùng chi phí giải mã. Để tăng tốc quy trình huấn luyện, chúng tôi đề xuất một sửa đổi cho cơ chế attention mask, như được nêu dưới đây:
• Bước đầu tiên phản ánh giai đoạn huấn luyện của EAGLE. Tại bước thời gian t+ 1, mô hình draft lấy đặc trưng f(l)t của mô hình đích làm đầu vào và tạo ra đặc trưng draft f(s1)t+1. Trong bước này, attention mask vẫn giống như causal mask ban đầu mà không có bất kỳ sửa đổi nào.
• Trong bước thứ hai, các đặc trưng từ bước đầu tiên được kết hợp. Ví dụ, trong cơ chế self-attention tại bước thời gian t+ 1, f(s1)t được sử dụng để tính toán query hiện tại. Các key và value được tạo ra từ f(l):t⊕f(s1)t, trong đó f(l):t bao gồm các đặc trưng từ các bước thời gian sớm hơn t. Attention mask được điều chỉnh để đảm bảo rằng đặc trưng trước đó được thấy bởi f(s1)i luôn là f(l)i−1, như được hiển thị trong phần 'HASS Training Step 2' của Hình 3.
• Đối với bước j≥3, đặc trưng từ bước trước đó f(sj−1)t được sử dụng để tính toán query tại bước thời gian t+ 1, trong khi các key và value được tạo ra bởi f(l):t−j+2⊕f(s1)t−j+2⊕. . .⊕f(sj−1)t .
Chúng tôi chứng minh thực nghiệm rằng hiệu ứng tăng tốc hội tụ với n nhỏ để việc huấn luyện HASS có hiệu quả về chi phí. Chi phí huấn luyện thực tế của HASS về tốc độ huấn luyện, chi phí tính toán, và bộ nhớ GPU được khảo sát trong Phụ lục A.8.
5

--- TRANG 6 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2025
Nhiệt độ = 0 Nhiệt độ = 1
Mô hình Phương pháp MT-bench HumanEval GSM8K Trung bình MT-bench HumanEval GSM8K Trung bình
L2 7BSpS (V-68M) 1.35x 1.38x 1.37x 1.37x 1.17x 1.02x 1.12x 1.10x
SpS (L-68M) 1.23x 1.24x 1.25x 1.24x 1.00x 0.94x 0.99x 0.98x
Medusa 1.91x 1.96x 2.20x 2.02x 2.00x 2.25x 2.15x 2.13x
EAGLE 1.90x 2.10x 2.04x 2.01x 1.50x 1.91x 1.87x 1.76x
EAGLE-2 2.66x 3.06x 2.72x 2.81x 2.39x 2.87x 2.54x 2.60x
HASS 2.99x 3.41x 3.32x 3.24x 2.70x 3.13x 2.87x 2.90x
L2 13BSpS (V-68M) 1.63x 1.98x 1.68x 1.76x 1.33x 1.72x 1.39x 1.48x
SpS (L-68M) 1.41x 1.29x 1.30x 1.33x 1.12x 1.04x 1.11x 1.09x
Medusa 2.26x 2.25x 2.71x 2.41x 2.31x 2.47x 2.36x 2.38x
EAGLE 1.80x 2.46x 2.41x 2.22x 1.84x 2.10x 2.21x 2.05x
EAGLE-2 3.02x 3.64x 3.23x 3.30x 3.04x 3.45x 3.13x 3.21x
HASS 3.23x 4.24x 3.48x 3.65x 3.28x 3.78x 3.37x 3.48x
L3 8BEAGLE 1.29x 2.00x 1.85x 1.71x 1.25x 1.41x 1.67x 1.44x
EAGLE-2 2.64x 3.31x 2.54x 2.83x 2.39x 2.54x 2.48x 2.47x
HASS 2.78x 3.43x 3.06x 3.09x 2.49x 3.05x 2.89x 2.81x
L3 70BEAGLE 2.14x 2.74x 2.42x 2.43x 1.80x 2.34x 2.12x 2.09x
EAGLE-2 2.94x 3.98x 3.19x 3.37x 3.02x 3.61x 3.21x 3.28x
HASS 3.40x 4.68x 4.08x 4.05x 3.43x 4.25x 3.87x 3.85x
Bảng 2: Tỉ lệ tăng tốc của các phương pháp khác nhau trên các bộ dữ liệu MT-bench, HumanEval, và GSM8K với nhiệt độ T ∈ {0,1}. L2 đại diện cho LLaMA2-Chat, trong khi L3 đại diện cho LLaMA3-Instruct. SpS viết tắt cho Vanilla Speculative Sampling, trong khi V-68M và L-68M đại diện cho Vicuna-68M và LLaMA-68M, là các mô hình draft của SpS.
4 THÍ NGHIỆM
4.1 THIẾT LẬP THÍ NGHIỆM
LLM Đích. LLaMA2-Chat 7/13B và LLaMA3-Instruct 8/70B.
Nhiệm vụ. Chúng tôi tiến hành đánh giá trên ba nhiệm vụ sinh. Đối với hội thoại nhiều lượt, tạo mã, và các nhiệm vụ lý luận toán học, chúng tôi chọn các bộ dữ liệu MT-bench (Zheng et al., 2024), HumanEval (Chen et al., 2021), và GSM8K (Cobbe et al., 2021) tương ứng. Kích thước batch được đặt là 1 dưới tất cả các thí nghiệm theo Leviathan et al. (2023) và Zhou et al. (2024).
Chỉ số. HASS không tinh chỉnh trọng số của LLM đích trong quá trình huấn luyện cũng như không nới lỏng điều kiện chấp nhận trong quá trình giải mã, làm cho nó trở thành một phương pháp tăng tốc không mất mát. Do đó, chất lượng sinh được hứa hẹn mà không cần đánh giá. Chúng tôi sử dụng hai chỉ số sau để đo hiệu suất tăng tốc:
•Tỉ lệ Tăng tốc : Tỉ lệ tăng tốc kiểm tra thực tế tương đối so với giải mã tự hồi quy vanilla.
•Độ dài Chấp nhận τ: Số lượng token trung bình được tạo ra cho mỗi chu kỳ draft-verification, chỉ ra số lượng token được LLM đích chấp nhận từ mô hình draft.
Lưu ý rằng tỉ lệ tăng tốc nhạy cảm với phần cứng do sự biến đổi trong sức mạnh tính toán, và độ dài chấp nhận có thể bị ảnh hưởng nhẹ bởi phần cứng do lỗi số. Do đó, tất cả các quá trình suy luận được tiến hành trên GPU NVIDIA H800.
So sánh. Giải mã tự hồi quy vanilla được lấy làm cơ sở, phục vụ như điểm chuẩn cho tỉ lệ tăng tốc (1.00x). Chúng tôi so sánh HASS với các phương pháp lấy mẫu suy đoán không mất mát gần đây, bao gồm PLD (Saxena, 2023), Lookahead (Fu et al., 2023), Vanilla Speculative Sampling (Chen et al., 2023), Medusa (Cai et al., 2024), EAGLE (Li et al., 2024b), và EAGLE-2 (Li et al., 2024c). PLD và Lookahead không cần huấn luyện, lần lượt sử dụng chuỗi khớp từ prompt và cached n-gram làm token draft thay vì tạo token draft từ phân phối xác suất được dự đoán của mô hình draft. Do đó, kết quả của PLD và Lookahead dưới nhiệt độ = 1 không được báo cáo trong Bảng 1.
6

--- TRANG 7 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2025
Triển khai. Mã của chúng tôi được xây dựng dựa trên kho open-source của EAGLE-21. Các thí nghiệm trên EAGLE và EAGLE-2 sử dụng lại trọng số mô hình draft được huấn luyện bởi Li et al. (2024b). Đối với chưng cất mục tiêu hài hòa, K được đặt là 10, và mất mát của chưng cất mục tiêu hài hòa được thêm vào mất mát ban đầu của EAGLE với hệ số w= 1.0. Đối với căn chỉnh ngữ cảnh hài hòa, mô hình draft được căn chỉnh trong 3 bước trong quá trình huấn luyện. Đối với cấu trúc cây động, chúng tôi đặt tổng số token draft là 60 cho tất cả các thí nghiệm với độ sâu cây draft là 6. Chúng tôi giữ các cài đặt khác, chẳng hạn như bộ dữ liệu huấn luyện cố định, tức là bộ dữ liệu ShareGPT2 với 68,000 cuộc đối thoại, và optimizer, nhất quán với EAGLE-2.
4.2 HIỆU QUẢ & NGHIÊN CỨU LOẠI BỎ
Trong phần này, trước tiên chúng tôi đánh giá hiệu quả của HASS bằng cách so sánh nó với các phương pháp lấy mẫu suy đoán hiện có về độ dài chấp nhận và tỉ lệ tăng tốc. Sau đó, chúng tôi tiến hành các nghiên cứu loại bỏ về chưng cất mục tiêu hài hòa và căn chỉnh ngữ cảnh hài hòa. Được truyền cảm hứng bởi Yi et al. (2024), chúng tôi tiếp tục tiến hành thí nghiệm bằng cách huấn luyện trên các tỉ lệ khác nhau của bộ dữ liệu ShareGPT để khảo sát khả năng mở rộng của HASS khi đối mặt với sự khan hiếm dữ liệu (xem Phụ lục A.6), và bằng cách đánh giá trên các nhiệm vụ dịch thuật để khảo sát tính mạnh mẽ của HASS trên các loại nhiệm vụ khác nhau (xem Phụ lục A.7). Như được hiển thị từ kết quả, HASS có khả năng mở rộng tốt hơn EAGLE-2 với ít dữ liệu huấn luyện hơn và đạt được những cải thiện đầy hứa hẹn so với EAGLE-2 trên các nhiệm vụ dịch thuật nhất quán với kết quả trên MT-bench, HumanEval, và GSM8K.
4.2.1 HIỆU QUẢ
Chúng tôi trình bày độ dài chấp nhận và tỉ lệ tăng tốc của các phương pháp khác nhau trên ba bộ dữ liệu trong Bảng 1 và 2 tương ứng. HASS thực hiện độ dài chấp nhận lớn nhất và tỉ lệ tăng tốc cao nhất trên tất cả các bộ dữ liệu và LLM chúng tôi kiểm tra. Hầu hết các phương pháp đạt được hiệu suất tốt nhất trên bộ dữ liệu HumanEval, vì các template cố định trong nhiệm vụ tạo mã dễ draft và tăng tốc hơn. Mặc dù PLD và Lookahead không cần huấn luyện, chúng luôn cho thấy hiệu suất kém hơn so với Medusa, EAGLE, EAGLE-2, và HASS.
4.2.2 NGHIÊN CỨU LOẠI BỎ VỀ CHƯNG CẤT MỤC TIÊU HÀI HÒA
0 0.1 0.2 0.5 1.0 2.0
Trọng số4.84.95.05.15.25.3Độ dài Chấp nhận
1 5 10 50 100
K4.84.95.05.15.25.3
T = 0
T = 1
Hình 4: Độ dài chấp nhận τ của HASS với các K và trọng số khác nhau của mất mát Top-K. Kết quả được tiến hành trên LLaMA2-Chat 7B và trung bình trên các bộ dữ liệu MT-bench, HumanEval, và GSM8K với nhiệt độ T ∈ {0,1}.Trước tiên chúng tôi nghiên cứu ảnh hưởng của các K khác nhau và trọng số w của mất mát Top-K bằng cách thay đổi các siêu tham số này và tóm tắt kết quả trong Hình 4. Huấn luyện với mất mát Top-K (w > 0) luôn cải thiện hiệu suất so với huấn luyện không có mất mát Top-K ( w= 0). HASS đạt được độ dài chấp nhận lớn nhất khi w= 0.5. Một giá trị K nhỏ có thể dẫn đến suy thoái hiệu suất, vì mô hình draft chỉ tập trung vào token có xác suất cao nhất và do đó bỏ qua các token tiềm năng khác. Với K lớn hơn, mất mát Top-K thường mang lại kết quả tốt hơn, trong khi độ dài chấp nhận lớn nhất khi K = 5.
Vì chưng cất mục tiêu hài hòa có thể được triển khai với bất kỳ hàm mất mát nào tập trung vào các token có khả năng cao nhất w.r.t. phân phối đích, chúng tôi tiếp tục xem xét các hàm mất mát sau và so sánh chúng với Mất mát Top-K:
• Mất mát Top-P, trong đó ˆΩ được hình thành bởi các token có khả năng cao nhất có xác suất tích lũy vừa lớn hơn P.
• Mất mát Top-K Chuẩn hóa, trong đó các phân phối đích và draft đều được chuẩn hóa trên ˆΩ. Phép toán chuẩn hóa có thể là tuyến tính hoặc softmax.
1https://github.com/SafeAILab/EAGLE
2https://huggingface.co/datasets/Aeala/ShareGPT Vicuna unfiltered
7

--- TRANG 8 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2025
Hàm Mất mát Nhiệt độ = 0 Nhiệt độ = 1 Trung bình
Mất mát Top-K 4.99 4.84 4.92
Mất mát Top-P 5.03 4.76 4.90
Mất mát Top-K Chuẩn hóa (Tuyến tính) 4.97 4.83 4.90
Mất mát Top-K Chuẩn hóa (Softmax) 4.98 4.72 4.85
Mất mát Top-K Hai chiều 4.99 4.72 4.86
Mất mát Recall@k Surrogate 4.97 4.76 4.87
Mất mát BiLD 5.04 4.75 4.90
Bảng 3: Độ dài chấp nhận τ của HASS với các loại hàm mất mát khác nhau cho chưng cất mục tiêu hài hòa. Kết quả được tiến hành trên LLaMA2-Chat 7B trên bộ dữ liệu MT-bench với nhiệt độ T ∈ {0,1}.
• Mất mát Top-K Hai chiều, trong đó chưng cất được tiến hành trên các token có khả năng cao nhất w.r.t. phân phối đích cũng như phân phối draft.
• Mất mát Recall@k Surrogate (Patel et al., 2022), trong đó một xấp xỉ mượt của chỉ số recall được thu được và có thể phân biệt được để tối ưu hóa trực tiếp.
• Mất mát BiLD (Li et al., 2024a), trong đó thông tin xếp hạng logits nội bộ được nắm bắt bằng cách xây dựng sự khác biệt logits với nhiễu đuôi dài được lọc ra.
Sau khi tìm kiếm các siêu tham số tối ưu cho mỗi hàm mất mát được so sánh, chúng tôi tóm tắt kết quả tốt nhất của chúng trong Bảng 3. Mất mát BiLD vượt trội hơn các hàm mất mát khác dưới nhiệt độ T = 0, trong khi mất mát Top-K vượt trội hơn những cái khác dưới nhiệt độ T = 1. Nói chung, mất mát Top-K cho thấy hiệu suất tốt nhất. Một hàm mất mát tốt hơn có thể tồn tại so với mất mát Top-K để khai thác LLM đích hơn nữa. Chúng tôi để lại chủ đề này trong các công việc tương lai.
Chúng tôi cũng tiến hành một thí nghiệm với LLaMA2-Chat 7B, trong đó bộ dữ liệu huấn luyện cố định được thay thế bằng bộ dữ liệu được tạo ra bởi LLM đích (xem Phụ lục A.4). Chúng tôi quan sát thấy rằng khi sử dụng giải mã không tham lam, độ dài chấp nhận tăng từ 4.92 lên 5.19 trung bình trên ba bộ dữ liệu. Do đó, thông tin thu được từ chưng cất mục tiêu hài hòa không tương đương với chưng cất trực tiếp từ dữ liệu được tạo ra bởi mô hình đích.
4.2.3 NGHIÊN CỨU LOẠI BỎ VỀ CĂN CHỈNH NGỮ CẢNH HÀI HÒA
Bước Căn chỉnh MT-bench HumanEval GSM8K Trung bình
T=0EAGLE-2 + Top-K 4.59 4.97 4.77 4.78
HASS Align-2 4.95 5.25 5.12 5.11
HASS Align-3 4.99 5.29 5.17 5.15
HASS Align-4 4.99 5.30 5.18 5.16
HASS Align-5 4.98 5.26 5.09 5.11
T=1EAGLE-2 + Top-K 4.46 4.61 4.64 4.57
HASS Align-2 4.71 4.89 4.98 4.86
HASS Align-3 4.84 4.91 5.01 4.92
HASS Align-4 4.77 4.93 5.03 4.91
HASS Align-5 4.71 4.92 4.95 4.86
Bảng 4: Độ dài chấp nhận τ của HASS với các bước căn chỉnh khác nhau trong căn chỉnh ngữ cảnh hài hòa. Kết quả được tiến hành trên LLaMA2-Chat 7B với nhiệt độ T ∈ {0,1}.
Chúng tôi đề xuất căn chỉnh ngữ cảnh hài hòa, loại bỏ sự không nhất quán đặc trưng của các mô hình draft giữa các giai đoạn huấn luyện và giải mã. Để nghiên cứu ảnh hưởng của việc tăng các bước căn chỉnh trong căn chỉnh ngữ cảnh hài hòa, chúng tôi tiến hành thí nghiệm bằng cách thay đổi số bước và tóm tắt kết quả trong Bảng 4.
Vì bước huấn luyện đầu tiên của HASS giống như EAGLE-2, chúng tôi tiếp tục huấn luyện trọng số mô hình draft của EAGLE-2 với mất mát Top-K và coi nó là cơ sở. Không có căn chỉnh ngữ cảnh hài hòa (EAGLE-2 + Top-K), mô hình draft thực hiện tệ nhất trên tất cả các bộ dữ liệu. Huấn luyện với 3/4 bước căn chỉnh ngữ cảnh hài hòa thường thu được độ dài chấp nhận đáng kể nhất. Khi huấn luyện với 5 bước căn chỉnh ngữ cảnh, độ dài chấp nhận giảm. Chúng tôi tin rằng điều này do khả năng hạn chế của mô hình draft, vì nó dự đoán ít chính xác hơn trên các token của các bước trước khi chú ý quá nhiều đến những bước sau. Hình 5 cho thấy tỷ lệ chấp nhận α trên các bước suy đoán trên bộ dữ liệu MT-bench theo Li et al. (2024c). Trong các bước suy đoán sau, HASS thực hiện tỷ lệ chấp nhận tốt hơn so với EAGLE-2, chứng minh hiệu quả của căn chỉnh ngữ cảnh hài hòa.
8

--- TRANG 9 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2025
0-
 1-
 2-
 3-
 4-
 5-
LLaMA2-Chat 7B T=05560657075
0-
 1-
 2-
 3-
 4-
 5-
LLaMA2-Chat 13B T=05560657075
0-
 1-
 2-
 3-
 4-
 5-
LLaMA3-Instruct 8B T=05560657075
0-
 1-
 2-
 3-
 4-
 5-
LLaMA3-Instruct 70B T=05560657075
HASS EAGLE-2
0-
 1-
 2-
 3-
 4-
 5-
LLaMA2-Chat 7B T=15560657075
0-
 1-
 2-
 3-
 4-
 5-
LLaMA2-Chat 13B T=15560657075
0-
 1-
 2-
 3-
 4-
 5-
LLaMA3-Instruct 8B T=15560657075
0-
 1-
 2-
 3-
 4-
 5-
LLaMA3-Instruct 70B T=15560657075
Hình 5: Tỷ lệ chấp nhận α(%) của HASS và EAGLE-2 trên các bước suy đoán khác nhau trên bộ dữ liệu MT-bench với nhiệt độ T ∈ {0,1}.
Như được hiển thị trong Hình 5, tỷ lệ chấp nhận của HASS giảm so với EAGLE-2 trên LLaMA2-Chat 13B và LLaMA3-Instruct 70B ở bước đầu tiên (0- α). Các mô hình draft suy thoái ở bước suy đoán đầu tiên với nhiều sự chú ý dành cho các bước suy đoán sau, trong khi tỷ lệ chấp nhận của bước đầu tiên là quan trọng cho độ dài chấp nhận lớn hơn. Chúng tôi tiến hành thí nghiệm để nhấn mạnh tầm quan trọng của các bước suy đoán trước bằng cách tái cân bằng mất mát huấn luyện từ mỗi bước với một yếu tố β. Cụ thể, mất mát huấn luyện của bước j sẽ được nhân với βj−1. Bảng 5 và Hình 6 cho thấy độ dài chấp nhận và tỷ lệ chấp nhận của HASS với các yếu tố tái cân bằng khác nhau trên LLaMA3-Instruct 70B trên bộ dữ liệu MT-bench tương ứng. Với yếu tố β giảm từ 1.0 xuống 0.5, HASS đạt được độ dài chấp nhận tốt hơn với các nhiệt độ khác nhau. Tương ứng, chúng ta nhận thấy rằng tỷ lệ chấp nhận ở bước suy đoán đầu tiên luôn cao hơn với β nhỏ hơn, trong khi tỷ lệ chấp nhận ở các bước suy đoán sau thường giảm. Khi yếu tố β giảm xuống 0.3, quá nhiều sự nhấn mạnh được gán cho bước suy đoán đầu tiên, dẫn đến suy thoái trong độ dài chấp nhận. Vì việc khám phá thêm về sự đánh đổi thích hợp giữa các bước suy đoán khác nhau nằm ngoài phạm vi của bài báo này, chúng tôi để lại nó cho công việc tương lai.
Yếu tố Tái cân bằng β T = 0 T = 1 Trung bình
1.0 (Mặc định) 4.62 4.59 4.61
0.7 4.65 4.61 4.63
0.5 4.67 4.62 4.65
0.3 4.65 4.61 4.63
Bảng 5: Độ dài chấp nhận τ của HASS với các yếu tố tái cân bằng β khác nhau cho căn chỉnh ngữ cảnh hài hòa. Kết quả được tiến hành trên LLaMA3-Instruct 70B trên bộ dữ liệu MT-bench với nhiệt độ T ∈ {0,1}.
0-
 1-
 2-
 3-
 4-
 5-
LLaMA3-Instruct 70B T=066687072
0-
 1-
 2-
 3-
 4-
 5-
LLaMA3-Instruct 70B T=166687072
 = 1.0
 = 0.7
 = 0.5
 = 0.3
Hình 6: Tỷ lệ chấp nhận α(%) của HASS với các yếu tố tái cân bằng β khác nhau cho căn chỉnh ngữ cảnh hài hòa. Kết quả được tiến hành trên LLaMA3-Instruct 70B trên bộ dữ liệu MT-bench với nhiệt độ T ∈ {0,1}.
5 CÔNG TRÌNH LIÊN QUAN
Đã có một số công trình về việc cải thiện tỷ lệ chấp nhận của lấy mẫu suy đoán trong khi duy trì phân phối đích. Hầu hết chúng thuộc về hai loại. (1) Loại thứ nhất
9

--- TRANG 10 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2025
là huấn luyện căn chỉnh cố gắng thu được các mô hình draft được căn chỉnh với LLM đích trước giai đoạn giải mã. Zhou et al. (2024) đề xuất một phương pháp chưng cất kiến thức và nghiên cứu một số chiến lược để cải thiện sự căn chỉnh. Li et al. (2024b) chứng minh rằng các trạng thái ẩn của LLM đích làm đầu vào của mô hình draft cung cấp thông tin bất định đặc trưng bổ sung. Xiao et al. (2024) cũng sử dụng các trạng thái ẩn của LLM đích và giới thiệu một thiết kế mô hình draft dựa trên RNN đạt được tỷ lệ chấp nhận tương đương. GLIDE (Du et al., 2024) thay vào đó tái sử dụng KV cache của LLM đích. Nó cũng chú ý đến sự không căn chỉnh ngữ cảnh khi sử dụng thông tin từ LLM đích, nhưng phương pháp attention mask theo khối được đề xuất không thể giải quyết hoàn toàn sự không căn chỉnh. (2) Loại thứ hai là giải mã hiệu quả, thiết kế các chiến lược giải mã tinh vi để sử dụng tính đồng thời một cách hiệu quả. Miao et al. (2024) đề xuất sử dụng nhiều mô hình draft và thiết kế một cơ chế attention dựa trên cây để xác minh nhiều chuỗi draft một cách hiệu quả. Li et al. (2024c) giới thiệu một cấu trúc động để tiết kiệm tính toán bằng cách cắt tỉa các đường dẫn không hiệu quả trong cây draft. Sun et al. (2024) nghiên cứu cải thiện giai đoạn xác minh thông qua vận chuyển tối ưu. Tuy nhiên, những công trình này có xu hướng chỉ xem xét huấn luyện hoặc giải mã, bỏ qua mối liên kết của hai giai đoạn này. Công trình này thay vào đó nhằm liên kết huấn luyện và giải mã, dẫn đến lấy mẫu suy đoán hài hòa.
6 KẾT LUẬN
Bài báo này giới thiệu HASS, một giải pháp lấy mẫu suy đoán hài hòa giải quyết sự không hài hòa giữa huấn luyện và giải mã về mục tiêu và ngữ cảnh của chúng. So với baseline gần nhất, EAGLE-2, HASS cải thiện tỷ lệ chấp nhận mà không có bất kỳ chi phí suy luận nào. Các thí nghiệm được tiến hành trên LLaMA2-Chat 7/13B và LLaMA3-Instruct 8/70B chứng minh hiệu quả và hiệu suất của HASS. Trung bình trên MT-bench, HumanEval, và GSM8K, HASS nhanh hơn 2.81x-4.05x so với giải mã tự hồi quy vanilla, nhanh hơn 8%-20% so với EAGLE-2.
TÀI LIỆU THAM KHẢO
Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et al. Báo cáo kỹ thuật gpt-4. arXiv , 2023.
Samy Bengio, Oriol Vinyals, Navdeep Jaitly, và Noam Shazeer. Lấy mẫu theo lịch trình cho dự đoán chuỗi với mạng nơ-ron hồi quy. Trong Advances in Neural Information Processing Systems, tập 28, 2015.
Tianle Cai, Yuhong Li, Zhengyang Geng, Hongwu Peng, Jason D. Lee, Deming Chen, và Tri Dao. Medusa: Khung tăng tốc suy luận LLM đơn giản với nhiều đầu giải mã. Trong Proceedings of the 41st International Conference on Machine Learning , 2024.
Charlie Chen, Sebastian Borgeaud, Geoffrey Irving, Jean-Baptiste Lespiau, Laurent Sifre, và John Jumper. Tăng tốc giải mã mô hình ngôn ngữ lớn với lấy mẫu suy đoán. arXiv , 2023.
Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde De Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, et al. Đánh giá các mô hình ngôn ngữ lớn được huấn luyện trên mã. arXiv , 2021.
Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, et al. Huấn luyện các trình xác minh để giải quyết các bài toán từ toán học. arXiv , 2021.
Cunxiao Du, Jing Jiang, Xu Yuanchen, Jiawei Wu, Sicheng Yu, Yongqi Li, Shenggui Li, Kai Xu, Liqiang Nie, Zhaopeng Tu, và Yang You. Glide với cánh áo: Một phương pháp ít rắc rối để tăng tốc giải mã suy đoán. Trong Proceedings of the 41st International Conference on Machine Learning , 2024.
Angela Fan, Mike Lewis, và Yann Dauphin. Tạo câu chuyện nơ-ron phân cấp. Trong Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics , pp. 889–898, 2018.
Yichao Fu, Peter Bailis, Ion Stoica, và Hao Zhang. Phá vỡ sự phụ thuộc tuần tự của suy luận llm bằng giải mã lookahead, tháng 11 năm 2023. URL https://lmsys.org/blog/2023-11-21-lookahead-decoding/ .
10

--- TRANG 11 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2025
John L Hennessy và David A Patterson. Kiến trúc máy tính: Một phương pháp định lượng . Elsevier, 2011.
Ari Holtzman, Jan Buys, Li Du, Maxwell Forbes, và Yejin Choi. Trường hợp kỳ lạ của sự suy thoái văn bản nơ-ron. Trong Proceedings of the 8th International Conference on Learning Representations , 2020.
Hsiang-Tsung Kung và John T Robinson. Về các phương pháp lạc quan cho kiểm soát đồng thời. ACM Transactions on Database Systems , 6(2):213–226, 1981.
Yaniv Leviathan, Matan Kalman, và Yossi Matias. Suy luận nhanh từ transformers thông qua giải mã suy đoán. Trong Proceedings of the 40th International Conference on Machine Learning , pp. 19274–19286. PMLR, 2023.
Minchong Li, Feng Zhou, và Xiaohui Song. Bild: Mất mát sự khác biệt logits hai chiều cho chưng cất mô hình ngôn ngữ lớn. arXiv , 2024a.
Yuhui Li, Fangyun Wei, Chao Zhang, và Hongyang Zhang. Eagle: Lấy mẫu suy đoán đòi hỏi suy nghĩ lại về bất định đặc trưng. Trong Proceedings of the 41st International Conference on Machine Learning , 2024b.
Yuhui Li, Fangyun Wei, Chao Zhang, và Hongyang Zhang. Eagle-2: Suy luận nhanh hơn của các mô hình ngôn ngữ với cây draft động. arXiv , 2024c.
Xupeng Miao, Gabriele Oliaro, Zhihao Zhang, Xinhao Cheng, Zeyu Wang, Zhengxin Zhang, Rae Ying Yee Wong, Alan Zhu, Lijie Yang, Xiaoxiang Shi, et al. Specinfer: Tăng tốc phục vụ mô hình ngôn ngữ lớn với suy luận suy đoán và xác minh dựa trên cây. Trong Proceedings of the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 3 , pp. 932–949, 2024.
Yash Patel, Giorgos Tolias, và Ji ˇr´ı Matas. Mất mát thay thế recall@ k với batch lớn và mixup tương tự. Trong Proceedings of the 2022 IEEE Conference on Computer Vision and Pattern Recognition , pp. 7502–7511, 2022.
Apoorv Saxena. Giải mã tìm kiếm prompt, tháng 11 năm 2023. URL https://github.com/apoorvumang/prompt-lookup-decoding/ .
Ziteng Sun, Ananda Theertha Suresh, Jae Hun Ro, Ahmad Beirami, Himanshu Jain, và Felix Yu. Spectr: Giải mã suy đoán nhanh thông qua vận chuyển tối ưu. Trong Advances in Neural Information Processing Systems , tập 36, 2024.
Jiaxi Tang và Ke Wang. Chưng cất xếp hạng: Học các mô hình xếp hạng compact với hiệu suất cao cho hệ thống gợi ý. Trong Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining , pp. 2289–2298, 2018.
Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al. Llama 2: Các mô hình chat nền tảng mở và tinh chỉnh. arXiv , 2023.
Chaojun Wang và Rico Sennrich. Về bias phơi bày, ảo giác và chuyển đổi miền trong dịch máy nơ-ron. Trong Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics , pp. 3544–3552, 2020.
Bin Xiao, Lujun Gui, Lei Su, và Weipeng Chen. Clover-2: Suy luận chính xác cho giải mã suy đoán nhẹ hồi quy. arXiv , 2024.
Euiin Yi, Taehyeon Kim, Hongseok Jeung, Du-Seong Chang, và Se-Young Yun. Hướng tới suy luận LLM đa ngôn ngữ nhanh: Giải mã suy đoán và các drafter chuyên biệt. Trong Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing , pp. 10789–10802, tháng 11 năm 2024. URL https://aclanthology.org/2024.emnlp-main.602 .
Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric Xing, et al. Đánh giá llm-as-a-judge với mt-bench và chatbot arena. Trong Advances in Neural Information Processing Systems , tập 36, 2024.
11

--- TRANG 12 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2025
Yongchao Zhou, Kaifeng Lyu, Ankit Singh Rawat, Aditya Krishna Menon, Afshin Rostamizadeh, Sanjiv Kumar, Jean-Franc ¸ois Kagy, và Rishabh Agarwal. Distillspec: Cải thiện giải mã suy đoán thông qua chưng cất kiến thức. Trong Proceedings of the 12th International Conference on Learning Representations , 2024.
12

--- TRANG 13 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2025
A PHỤ LỤC
A.1 TRIỂN KHAI CĂN CHỈNH NGỮ CẢNH HÀI HÒA
Chúng tôi trình bày mã giả của căn chỉnh ngữ cảnh hài hòa, được triển khai mà không có attention mask tùy chỉnh, để hiểu rõ hơn. Việc triển khai thực tế trong các thí nghiệm của chúng tôi được thực hiện bằng attention mask tùy chỉnh như được hiển thị trong Hình 3.
1def train_batch(
2 draft_model, # mô hình draft
3 lm_head, # đầu mô hình ngôn ngữ
4 optimizer, # optimizer
5 forward_num, # các bước căn chỉnh trong căn chỉnh ngữ cảnh hài hòa
6 hidden_states_target, # đặc trưng của LLM đích
7 input_ids, # token đầu vào
8 ):
9 hidden_states_draft_list = []
10 for forward_idx in range(forward_num):
11 optimizer.zero_grad()
12 predict = draft_model(hidden_states_target, input_ids, hidden_states_draft_list)
13 hidden_states_draft = torch.cat([hidden_states_target[:, :1], predict[:, :-1]], dim=1).detach()
14 hidden_states_draft_list.append(hidden_states_draft)
15 target_head, pred_head = lm_head(hidden_states_target), lm_head(predict)
16 loss = feature_loss(hidden_states_target, predict) + logit_loss(target_head, pred_head)
17 loss.backward()
18 optimizer.step()
1def attention(
2 hidden_states_target, # đặc trưng của LLM đích
3 attention_mask, # causal attention mask
4 hidden_states_draft_list, # danh sách các đặc trưng của mô hình draft
5 ):
6 bs, seq_len = hidden_states_target.shape[0], hidden_states_target.shape[1]
7 query = q_proj(hidden_states_draft_list[-1]) if hidden_states_draft_list else q_proj(hidden_states_target)
8 key_t, value_t = k_proj(hidden_states_target), v_proj(hidden_states_target)
9 attn_weight = torch.matmul(query, key_t.transpose(2, 3)) / math.sqrt(query.shape[-1]) + attention_mask
10 indices = torch.arange(seq_len)
11 for i, hidden_states_draft in enumerate(hidden_states_draft_list[::-1]):
12 key_d, ind_q, ind_k = k_proj(hidden_states_draft), indices[i:], indices[:seq_len - i]
13 attn_weight_d = torch.matmul(query, key_d.transpose(2, 3)) / math.sqrt(query.shape[-1])
14 attn_weight[:, :, ind_q, ind_k] = attn_weight_d[:, :, ind_q, ind_k]
15 attn_weight_normed = F.softmax(attn_weight, dim=-1)
16 attn_output = torch.matmul(attn_weight_normed, value_t)
17 for i, hidden_states_draft in enumerate(hidden_states_draft_list[::-1]):
18 value_d, ind_q, ind_k = v_proj(hidden_states_draft), indices[i:], indices[:seq_len - i]
19 attn_output[:, :, ind_q] += attn_weight[:, :, ind_q, ind_k][..., None] *(value_d[:, :, ind_k] -
value_t[:, :, ind_k])
20 attn_output = o_proj(attn_output.transpose(1, 2).reshape(bs, seq_len, -1))
21 return attn_output
13

--- TRANG 14 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2025
A.2 CĂN CHỈNH NGỮ CẢNH HÀI HÒA TRÊN TOKEN
Trong phần này, chúng tôi cố gắng xác minh liệu việc áp dụng căn chỉnh token cũng như căn chỉnh đặc trưng có mang lại hiệu suất tốt hơn hay không. Cụ thể, chúng tôi sử dụng các token được tạo ra bởi mô hình draft để huấn luyện trong căn chỉnh ngữ cảnh hài hòa thay vì sử dụng các token từ dữ liệu huấn luyện. Chúng tôi áp dụng căn chỉnh đặc trưng và token cho trọng số mô hình draft của EAGLE-2 và tóm tắt kết quả trong Bảng 6 và Hình 7.
Nhiệt độ = 0 Nhiệt độ = 1 Trung bình
EAGLE-2 4.44 4.23 4.34
Chỉ Đặc trưng 4.83 4.60 4.72
Đặc trưng + Token (0.1) 4.81 4.57 4.69
Đặc trưng + Token (0.2) 4.78 4.51 4.65
Đặc trưng + Token (1.0) 4.28 4.11 4.20
Bảng 6: Độ dài chấp nhận τ của việc áp dụng căn chỉnh đặc trưng và token cho trọng số mô hình draft của EAGLE-2, trong đó 'Token ( x)' ký hiệu các token từ dữ liệu huấn luyện được thay thế bằng các token được tạo ra bởi mô hình draft với xác suất x. Kết quả được tiến hành trên LLaMA2-Chat 7B trên bộ dữ liệu MT-bench với nhiệt độ T ∈ {0,1}.
0-
 1-
 2-
 3-
 4-
 5-
LLaMA2-Chat 7B T=0646668707274
0-
 1-
 2-
 3-
 4-
 5-
LLaMA2-Chat 7B T=1646668707274
Chỉ Đặc trưng
Đặc trưng + Token (0.1)
Đặc trưng + Token (0.2)
Hình 7: Tỷ lệ chấp nhận α(%) của việc áp dụng căn chỉnh đặc trưng và token cho trọng số mô hình draft của EAGLE-2, trong đó 'Token ( x)' ký hiệu các token từ dữ liệu huấn luyện được thay thế bằng các token được tạo ra bởi mô hình draft với xác suất x. Kết quả được tiến hành trên LLaMA2-Chat 7B trên bộ dữ liệu MT-bench với nhiệt độ T ∈ {0,1}.
Căn chỉnh chỉ đặc trưng mang lại hiệu suất tốt nhất, trong khi việc thêm căn chỉnh token dẫn đến suy thoái. Với xác suất áp dụng căn chỉnh token tăng từ 0.1 lên 1.0, độ dài chấp nhận giảm liên tục. Như được hiển thị trong Hình 7, càng nhiều căn chỉnh token thường gây ra tỷ lệ chấp nhận thấp hơn. Kết quả là, huấn luyện với các token được tạo ra bởi mô hình draft trong căn chỉnh ngữ cảnh hài hòa làm tổn hại hiệu suất tăng tốc.
14

--- TRANG 15 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2025
A.3 SIÊU THAM SỐ CỦA MẤT MÁT TOP-K
Chúng tôi tiến hành một nghiên cứu loại bỏ về các siêu tham số của mất mát Top-K, tức là K và w, trong Phần 4.2.2 và hiển thị độ dài chấp nhận trung bình trên ba bộ dữ liệu trong Hình 4. Ở đây, chúng tôi trình bày tỷ lệ tăng tốc và độ dài chấp nhận của HASS với các K và w khác nhau trong Bảng 7.
MT-bench HumanEval GSM8K Trung bình
K w Tăng tốc τ Tăng tốc τ Tăng tốc τ Tăng tốc τ
T=01 1.0 2.89x 4.94 3.24x 5.19 3.11x 5.10 3.08x 5.08
5 1.0 2.90x 5.00 3.44x 5.29 3.33x 5.18 3.22x 5.16
10 1.0 2.99x 4.99 3.41x 5.29 3.32x 5.17 3.24x 5.15
50 1.0 2.85x 5.01 3.46x 5.29 3.41x 5.17 3.24x 5.16
100 1.0 2.93x 5.00 3.45x 5.29 3.45x 5.18 3.28x 5.16
10 0.0 2.77x 4.93 3.38x 5.22 3.18x 5.11 3.11x 5.09
10 0.1 2.98x 4.96 3.40x 5.26 3.51x 5.16 3.30x 5.13
10 0.2 2.87x 4.98 3.41x 5.29 3.35x 5.16 3.21x 5.14
10 0.5 3.00x 5.02 3.32x 5.31 3.50x 5.18 3.27x 5.17
10 2.0 2.94x 4.98 3.37x 5.29 3.34x 5.17 3.22x 5.15
T=11 1.0 2.58x 4.70 2.79x 4.80 2.83x 4.95 2.73x 4.82
5 1.0 2.64x 4.81 3.13x 4.94 2.93x 5.02 2.90x 4.92
10 1.0 2.70x 4.84 3.13x 4.91 2.87x 5.01 2.90x 4.92
50 1.0 2.62x 4.77 3.01x 4.88 2.99x 5.03 2.87x 4.89
100 1.0 2.66x 4.74 3.14x 4.97 2.90x 5.03 2.90x 4.91
10 0.0 2.61x 4.71 2.76x 4.84 2.79x 4.96 2.72x 4.84
10 0.1 2.69x 4.75 3.05x 4.94 2.87x 5.00 2.87x 4.90
10 0.2 2.66x 4.75 3.16x 4.95 2.88x 5.01 2.90x 4.90
10 0.5 2.68x 4.80 3.15x 4.93 2.96x 5.03 2.93x 4.92
10 2.0 2.68x 4.75 3.11x 4.89 2.89x 5.03 2.89x 4.89
Bảng 7: Tỷ lệ tăng tốc và độ dài chấp nhận τ của HASS với các K và w khác nhau của mất mát Top-K trên LLaMA2-Chat 7B trên các bộ dữ liệu MT-bench, HumanEval, và GSM8K với nhiệt độ T ∈ {0,1}.
15

--- TRANG 16 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2025
A.4 TỰ CHƯNG CẤT
Trong văn bản chính, chúng tôi sử dụng bộ dữ liệu ShareGPT cố định để huấn luyện các mô hình draft để so sánh công bằng với EAGLE và EAGLE-2. Theo các phương pháp lấy mẫu suy đoán hiện có (Zhou et al., 2024; Cai et al., 2024), chúng tôi tiếp tục sử dụng đầu ra được tạo ra bởi mô hình đích để chưng cất mô hình draft từ phân phối đầu ra thực của mô hình đích, được gọi là tự chưng cất. Cụ thể, chúng tôi đưa các prompt từ bộ dữ liệu ShareGPT vào các mô hình đích một cách đệ quy với nhiệt độ đặt là 0 và thu thập các phản hồi dưới dạng cuộc hội thoại nhiều lượt để tự chưng cất theo Li et al. (2024b). Để nghiên cứu ảnh hưởng của tự chưng cất, chúng tôi tiến hành thí nghiệm trên HASS và EAGLE-2 bằng cách huấn luyện mô hình draft với dữ liệu cố định hoặc dữ liệu được tạo ra bởi mô hình và tóm tắt kết quả trong Bảng 8.
MT-bench HumanEval GSM8K Trung bình
Mô hình Phương pháp Dữ liệu Tăng tốc τ Tăng tốc τ Tăng tốc τ Tăng tốc τ
T=0L2 7BEAGLE-2F 2.66x 4.44 3.06x 4.78 2.72x 4.60 2.81x 4.61
MG 2.86x 4.70 3.30x 5.12 3.03x 5.00 3.06x (+0.25) 4.94(+0.33)
HASSF 2.99x 4.99 3.41x 5.29 3.32x 5.17 3.24x 5.15
MG 3.13x 5.25 3.85x 5.70 3.40x 5.57 3.46x (+0.22) 5.51(+0.36)
L2 13BEAGLE-2F 3.02x 4.74 3.64x 5.57 3.23x 5.17 3.30x 5.16
MG 3.04x 4.80 3.47x 5.46 3.19x 5.16 3.23x(-0.07) 5.14(-0.02)
HASSF 3.23x 5.13 4.24x 6.05 3.48x 5.55 3.65x 5.58
MG 3.34x 5.27 4.42x 6.00 3.63x 5.61 3.80x (+0.15) 5.63(+0.05)
T=1L2 7BEAGLE-2F 2.39x 4.23 2.87x 4.47 2.54x 4.50 2.60x 4.40
MG 2.49x 4.38 2.94x 4.73 2.69x 4.80 2.71x (+0.11) 4.64(+0.24)
HASSF 2.70x 4.84 3.13x 4.91 2.87x 5.01 2.90x 4.92
MG 2.75x 4.97 3.39x 5.24 3.13x 5.35 3.09x (+0.19) 5.19(+0.27)
L2 13BEAGLE-2F 3.04x 4.60 3.45x 5.41 3.13x 5.03 3.21x 5.01
MG 3.08x 4.63 3.23x 5.25 3.04x 4.95 3.12x(-0.09) 4.94(-0.07)
HASSF 3.28x 4.98 3.78x 5.86 3.37x 5.41 3.48x 5.42
MG 3.33x 5.02 3.76x 5.80 3.60x 5.42 3.56x (+0.08) 5.41(-0.01)
Bảng 8: Tỷ lệ tăng tốc và độ dài chấp nhận τ của HASS và EAGLE-2 với dữ liệu huấn luyện cố định hoặc được tạo ra bởi mô hình đích. F và MG viết tắt cho 'Cố định' và 'Được Tạo ra bởi Mô hình' tương ứng. L2 đại diện cho LLaMA2-Chat.
Trên LLaMA2-Chat 7B, tự chưng cất liên tục mang lại cải thiện cho HASS và EAGLE-2. Trên LLaMA2-Chat 13B, tự chưng cất chỉ đạt được kết quả tốt hơn một chút hoặc tương đương, điều này nhất quán với quan sát từ Li et al. (2024b) ('dữ liệu từ LLM đích cải thiện hiệu suất một cách biên tế' trong phần 4.3.3 của họ). Đặc biệt, độ dài chấp nhận của HASS tự chưng cất thấp hơn so với HASS vanilla trên bộ dữ liệu HumanEval, trong khi cả tỷ lệ tăng tốc và độ dài chấp nhận của EAGLE-2 tự chưng cất đều thấp hơn so với EAGLE-2 vanilla trên các bộ dữ liệu HumanEval và GSM8K. Có thể do bộ dữ liệu tạo mã HumanEval và bộ dữ liệu lý luận toán học GSM8K ít tương tự với bộ dữ liệu huấn luyện ShareGPT so với MT-bench.
HASS vượt trội hơn EAGLE-2 trên cả dữ liệu huấn luyện cố định hoặc dữ liệu huấn luyện được tạo ra bởi mô hình. Đáng chú ý là HASS được huấn luyện trên bộ dữ liệu cố định thậm chí đạt được hiệu suất tốt hơn so với EAGLE-2 được huấn luyện trên dữ liệu được tạo ra bởi mô hình một cách nhất quán. Với tự chưng cất, HASS liên tục đạt được nhiều cải thiện hơn hoặc ít suy thoái hơn về độ dài chấp nhận so với EAGLE-2.
16

--- TRANG 17 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2025
A.5 SIÊU THAM SỐ DRAFT
Li et al. (2024c) phát hiện rằng điểm tin cậy của token draft có tương quan tích cực mạnh với tỷ lệ chấp nhận, và do đó đề xuất cây draft động căn chỉnh ngữ cảnh, có thể được điều chỉnh động với hai siêu tham số: 'độ sâu' và 'số lượng token'. 'Độ sâu' quyết định độ sâu của cây draft trong giai đoạn mở rộng, trong khi 'số lượng token' quyết định có bao nhiêu token draft sẽ được giữ lại trong giai đoạn xếp hạng lại. Tăng cả hai siêu tham số này chắc chắn dẫn đến độ dài chấp nhận lớn hơn. Tuy nhiên, gửi nhiều token draft hơn vào mô hình đích để xác minh gây ra chi phí cao hơn trong các ứng dụng thực tế. Do đó, chúng tôi thay đổi các siêu tham số này và báo cáo tỷ lệ tăng tốc trong Bảng 9 để tìm ra sự đánh đổi tốt hơn.
Độ sâu 5 6 7 8 9
# Token 40 60 80 100 40 60 80 100 40 60 80 100 40 60 80 100 40 60 80 100
T=0L2 7BEAGLE-2 2.48x 2.78x 2.61x 2.69x 2.69x 2.66x 2.70x 2.79x 2.71x 2.86x 2.91x 2.95x 2.60x 2.60x 2.88x 2.89x 2.28x 2.54x 2.55x 2.65x
HASS-MG 3.09x 3.02x 3.04x 3.22x 3.08x 3.13x 3.19x 3.22x 3.14x 3.11x 3.29x 3.27x 3.07x 3.16x 3.31x 3.32x 2.78x 2.75x 2.95x 3.03x
L2 13BEAGLE-2 2.63x 2.96x 3.04x 3.06x 3.01x 3.02x 3.18x 3.22x 2.78x 3.12x 3.14x 3.24x 2.98x 3.12x 3.19x 3.26x 2.49x 2.64x 2.69x 2.72x
HASS-MG 3.25x 3.31x 3.24x 3.25x 3.33x 3.34x 3.49x 3.40x 3.19x 3.42x 3.36x 3.40x 3.15x 3.40x 3.40x 3.37x 2.70x 2.74x 3.09x 3.02x
T=1L2 7BEAGLE-2 2.31x 2.37x 2.55x 2.36x 2.42x 2.39x 2.33x 2.40x 2.49x 2.66x 2.65x 2.44x 2.36x 2.48x 2.38x 2.64x 2.29x 2.22x 2.27x 2.42x
HASS-MG 2.79x 2.89x 2.86x 2.88x 2.72x 2.75x 2.92x 2.82x 2.83x 2.76x 2.81x 2.75x 2.49x 2.68x 2.77x 2.77x 2.30x 2.35x 2.58x 2.50x
L2 13BEAGLE-2 2.92x 3.11x 2.88x 2.79x 3.06x 3.04x 3.16x 2.93x 3.05x 3.14x 3.14x 3.11x 3.00x 3.13x 3.15x 2.98x 2.61x 2.72x 2.65x 2.54x
HASS-MG 3.24x 3.30x 3.27x 3.19x 3.33x 3.33x 3.40x 3.28x 3.19x 3.26x 3.24x 3.26x 3.15x 3.26x 3.19x 3.17x 2.62x 2.77x 2.74x 2.84x
Bảng 9: Tỷ lệ tăng tốc của EAGLE-2 và HASS-MG với các độ sâu và số lượng token khác nhau trên bộ dữ liệu MT-bench với nhiệt độ T ∈ {0,1}, trong đó HASS-MG ký hiệu HASS được huấn luyện với tự chưng cất. L2 đại diện cho LLaMA2-Chat.
Khi 'độ sâu' = 5, độ dài chấp nhận tương đối nhỏ. Khi 'độ sâu' = 9, chi phí xác minh cực kỳ cao. Do đó, không có cài đặt nào trong số này đạt được tỷ lệ tăng tốc đầy hứa hẹn. Đối với cả HASS-MG và EAGLE-2, hiệu suất tốt nhất đạt được khi 'độ sâu' ∈ {6,7,8} và '# token' ∈ {60,80,100}. HASS-MG liên tục thu được hiệu suất vượt trội so với EAGLE-2 thông qua điều chỉnh siêu tham số trên các LLM và nhiệt độ khác nhau.
17

--- TRANG 18 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2025
A.6 SỐ LƯỢNG TOKEN HUẤN LUYỆN
Được truyền cảm hứng bởi Yi et al. (2024), chúng tôi lấy mẫu ngẫu nhiên các tỷ lệ khác nhau của bộ dữ liệu huấn luyện, tức là bộ dữ liệu ShareGPT với 68,000 cuộc đối thoại, để khảo sát ảnh hưởng của số lượng token huấn luyện. Cụ thể, chúng tôi huấn luyện các mô hình draft của HASS và EAGLE-2 với 1/8,1/4,1/2 và toàn bộ bộ dữ liệu ShareGPT và tóm tắt kết quả trong Hình 8 và Bảng 10.
1/8 1/4 1/2 1/1
LLaMA2-Chat 7B3456Độ dài Chấp nhận
1/8 1/4 1/2 1/1
LLaMA2-Chat 13B3456
1/8 1/4 1/2 1/1
LLaMA3-Instruct 8B3456
1/8 1/4 1/2 1/1
LLaMA3-Instruct 70B3456
1/8 1/4 1/2 1/1
LLaMA2-Chat 7B234Tỷ lệ Tăng tốc
1/8 1/4 1/2 1/1
LLaMA2-Chat 13B234
1/8 1/4 1/2 1/1
LLaMA3-Instruct 8B234
1/8 1/4 1/2 1/1
LLaMA3-Instruct 70B234
HASS T=0
HASS T=1EAGLE-2 T=0
EAGLE-2 T=1
Hình 8: Độ dài chấp nhận τ và tỷ lệ tăng tốc của HASS và EAGLE-2 trung bình trên MT-bench, HumanEval, và GSM8K với các tỷ lệ khác nhau của bộ dữ liệu huấn luyện, tức là bộ dữ liệu ShareGPT với 68,000 cuộc đối thoại.
Như được hiển thị từ Hình 8, HASS liên tục vượt trội hơn EAGLE-2 dưới các tỷ lệ khác nhau của bộ dữ liệu huấn luyện với nhiệt độ T ∈ {0,1}. HASS với chỉ 1/4 bộ dữ liệu huấn luyện đạt được hiệu suất tốt hơn hoặc tương đương so với EAGLE-2 với toàn bộ bộ dữ liệu huấn luyện, điều này chứng minh khả năng khai thác dữ liệu và khả năng mở rộng vượt trội của HASS thu được thông qua việc căn chỉnh thêm về mục tiêu và ngữ cảnh giữa huấn luyện và giải mã. Tỷ lệ tăng tốc và độ dài chấp nhận của HASS và EAGLE-2 tỷ lệ thuận logarithmic với quy mô dữ liệu huấn luyện, điều này nhất quán với phát hiện trong Yi et al. (2024). Như được hiển thị từ Bảng 10, việc giảm dữ liệu huấn luyện góp phần vào sự suy thoái nghiêm trọng hơn trên EAGLE-2 so với trên HASS, phản ánh tính mạnh mẽ của HASS đối với sự khan hiếm dữ liệu.
18

--- TRANG 19 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2025
MT-bench HumanEval GSM8K Trung bình
Mô hình Phương pháp Tỷ lệ Tăng tốc τ Tăng tốc τ Tăng tốc τ Tăng tốc τ
T=0L2 7BEAGLE-21/8 1.74x 3.06 2.00x 3.39 2.12x 3.24 1.95x 3.23
1/4 2.08x 3.64 2.49x 3.93 2.21x 3.81 2.26x 3.79
1/2 2.36x 4.11 2.76x 4.46 2.64x 4.28 2.59x 4.28
1/1 2.66x 4.44 3.06x 4.78 2.72x 4.60 2.81x 4.61
HASS1/8 2.32x 3.92 2.69x 4.30 2.56x 4.12 2.52x 4.11
1/4 2.64x 4.42 3.05x 4.76 2.70x 4.59 2.80x 4.59
1/2 2.85x 4.79 3.36x 5.05 3.18x 4.94 3.13x 4.93
1/1 2.99x 4.99 3.41x 5.29 3.32x 5.17 3.24x 5.15
L2 13BEAGLE-21/8 1.88x 3.25 2.39x 3.79 2.27x 3.57 2.18x 3.54
1/4 2.38x 3.82 2.85x 4.53 2.79x 4.25 2.67x 4.20
1/2 2.74x 4.32 3.46x 5.18 3.08x 4.81 3.09x 4.77
1/1 3.02x 4.74 3.64x 5.57 3.23x 5.17 3.30x 5.16
HASS1/8 2.59x 4.01 3.37x 4.79 3.01x 4.43 2.99x 4.41
1/4 2.89x 4.55 3.59x 5.51 3.18x 5.00 3.22x 5.02
1/2 3.16x 4.90 4.20x 5.86 3.41x 5.31 3.59x 5.36
1/1 3.23x 5.13 4.24x 6.05 3.48x 5.55 3.65x 5.58
L3 8BEAGLE-21/8 1.54x 2.77 2.00x 3.12 1.61x 2.83 1.72x 2.91
1/4 1.89x 3.18 2.30x 3.59 2.08x 3.35 2.09x 3.37
1/2 2.24x 3.68 2.64x 4.16 2.42x 3.91 2.43x 3.92
1/1 2.64x 4.21 3.31x 4.93 2.54x 4.42 2.83x 4.52
HASS1/8 2.14x 3.61 2.84x 4.22 2.30x 3.78 2.43x 3.87
1/4 2.46x 4.04 3.24x 4.83 2.48x 4.27 2.73x 4.38
1/2 2.72x 4.43 3.38x 5.28 2.99x 4.71 3.03x 4.81
1/1 2.78x 4.68 3.43x 5.54 3.06x 5.02 3.09x 5.08
L3 70BEAGLE-21/8 2.09x 2.87 2.72x 3.45 2.29x 2.92 2.37x 3.08
1/4 2.47x 3.33 3.25x 4.01 2.71x 3.46 2.81x 3.60
1/2 2.76x 3.74 3.71x 4.57 3.11x 3.96 3.19x 4.09
1/1 2.94x 4.10 3.98x 5.02 3.19x 4.37 3.37x 4.50
HASS1/8 2.73x 3.68 3.79x 4.61 3.10x 3.95 3.21x 4.08
1/4 3.05x 4.12 4.23x 5.18 3.56x 4.54 3.61x 4.61
1/2 3.27x 4.40 4.52x 5.57 3.87x 4.92 3.89x 4.96
1/1 3.40x 4.62 4.68x 5.78 4.08x 5.24 4.05x 5.21
T=1L2 7BEAGLE-21/8 1.60x 2.99 1.90x 3.21 1.86x 3.17 1.79x 3.12
1/4 1.89x 3.48 2.28x 3.71 2.27x 3.71 2.15x 3.63
1/2 2.26x 3.93 2.57x 4.14 2.46x 4.17 2.43x 4.08
1/1 2.39x 4.23 2.87x 4.47 2.54x 4.50 2.60x 4.40
HASS1/8 2.19x 3.82 2.50x 4.06 2.41x 4.03 2.37x 3.97
1/4 2.50x 4.27 2.84x 4.46 2.61x 4.52 2.65x 4.42
1/2 2.63x 4.56 3.10x 4.75 2.81x 4.81 2.85x 4.71
1/1 2.70x 4.84 3.13x 4.91 2.87x 5.01 2.90x 4.92
L2 13BEAGLE-21/8 1.91x 3.16 2.18x 3.71 2.23x 3.46 2.11x 3.44
1/4 2.31x 3.68 2.72x 4.40 2.77x 4.11 2.60x 4.06
1/2 2.78x 4.20 3.19x 5.00 3.08x 4.67 3.02x 4.62
1/1 3.04x 4.60 3.45x 5.41 3.13x 5.03 3.21x 5.01
HASS1/8 2.49x 3.94 2.98x 4.70 2.99x 4.33 2.82x 4.32
1/4 2.87x 4.43 3.40x 5.35 3.11x 4.87 3.13x 4.88
1/2 3.22x 4.75 3.70x 5.69 3.26x 5.18 3.39x 5.21
1/1 3.28x 4.98 3.78x 5.86 3.37x 5.41 3.48x 5.42
L3 8BEAGLE-21/8 1.51x 2.64 1.63x 3.01 1.64x 2.81 1.59x 2.82
1/4 1.77x 2.99 1.87x 3.51 1.92x 3.29 1.85x 3.26
1/2 1.90x 3.40 2.25x 4.03 2.38x 3.82 2.18x 3.75
1/1 2.39x 3.90 2.54x 4.73 2.48x 4.30 2.47x 4.31
HASS1/8 1.96x 3.42 2.31x 4.10 2.25x 3.72 2.17x 3.75
1/4 2.22x 3.77 2.51x 4.63 2.45x 4.18 2.39x 4.19
1/2 2.43x 4.10 2.96x 5.07 2.82x 4.56 2.74x 4.58
1/1 2.49x 4.26 3.05x 5.30 2.89x 4.85 2.81x 4.80
L3 70BEAGLE-21/8 2.16x 2.85 2.52x 3.35 2.19x 2.91 2.29x 3.04
1/4 2.26x 3.29 3.01x 3.94 2.57x 3.44 2.61x 3.56
1/2 2.70x 3.67 3.37x 4.47 3.00x 3.94 3.02x 4.03
1/1 3.02x 4.00 3.61x 4.93 3.21x 4.35 3.28x 4.43
HASS1/8 2.80x 3.70 3.46x 4.52 2.98x 3.93 3.08x 4.05
1/4 3.10x 4.10 3.90x 5.11 3.41x 4.51 3.47x 4.57
1/2 3.28x 4.36 4.15x 5.46 3.72x 4.91 3.72x 4.91
1/1 3.43x 4.59 4.25x 5.68 3.87x 5.20 3.85x 5.16
Bảng 10: Tỷ lệ tăng tốc và độ dài chấp nhận τ của HASS và EAGLE-2 với các tỷ lệ khác nhau của bộ dữ liệu huấn luyện, tức là bộ dữ liệu ShareGPT với 68,000 cuộc đối thoại. L2 đại diện cho LLaMA2-Chat, trong khi L3 đại diện cho LLaMA3-Instruct.
19

--- TRANG 20 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2025
A.7 ĐÁNH GIÁ TRÊN CÁC NHIỆM VỤ DỊCH THUẬT
Để khảo sát tính mạnh mẽ của HASS trên các loại nhiệm vụ khác nhau, chúng tôi tiếp tục đánh giá HASS và EAGLE-2 trên năm nhiệm vụ dịch thuật3 bằng cách theo Yi et al. (2024). Đáng chú ý là cả HASS và EAGLE-2 đều được huấn luyện trên bộ dữ liệu ShareGPT cố định mà không thích ứng cho các nhiệm vụ dịch thuật. Chúng tôi tiến hành thí nghiệm trên LLaMA2-Chat 7/13B và LLaMA3-Instruct 8/70B và tóm tắt kết quả trong Bảng 11.
De→En Fr →En Ja →En Ru →En Zh →En Trung bình
Mô hình Phương pháp Tăng tốc τTăng tốc τTăng tốc τTăng tốc τTăng tốc τTăng tốc τ
T=0L2 7BEAGLE-2 2.58x 4.06 2.47x 3.99 2.46x 3.79 2.23x 3.48 2.39x 3.68 2.43x 3.80
HASS 3.15x 4.55 2.99x 4.60 2.97x 4.26 2.64x 3.82 2.83x 4.10 2.92x 4.27
L2 13BEAGLE-2 2.95x 4.51 3.00x 4.41 2.67x 3.80 2.61x 3.65 2.60x 3.92 2.77x 4.06
HASS 3.63x 5.01 3.64x 4.94 3.05x 4.07 3.06x 4.03 3.02x 4.22 3.28x 4.45
L3 8BEAGLE-2 2.59x 3.89 2.34x 3.96 1.91x 2.97 1.90x 3.25 2.03x 3.17 2.15x 3.45
HASS 2.98x 4.30 2.79x 4.21 2.21x 3.19 2.28x 3.53 2.32x 3.38 2.52x 3.72
L3 70BEAGLE-2 3.10x 4.17 3.13x 4.07 2.35x 3.16 2.79x 3.76 2.52x 3.39 2.78x 3.71
HASS 3.75x 4.71 3.61x 4.47 2.67x 3.41 3.39x 4.25 2.84x 3.72 3.25x 4.12
T=1L2 7BEAGLE-2 2.26x 3.86 2.41x 3.91 2.09x 3.58 1.98x 3.34 2.25x 3.61 2.20x 3.66
HASS 2.80x 4.44 2.99x 4.59 2.66x 4.11 2.53x 3.74 2.65x 4.05 2.73x 4.19
L2 13BEAGLE-2 2.97x 4.29 2.77x 4.31 2.45x 3.73 2.33x 3.51 2.47x 3.72 2.60x 3.91
HASS 3.45x 4.88 3.22x 4.84 3.02x 4.13 2.79x 3.97 2.83x 4.01 3.06x 4.37
L3 8BEAGLE-2 2.23x 3.67 2.21x 3.69 1.85x 2.79 1.94x 3.15 1.89x 3.03 2.02x 3.27
HASS 2.80x 4.13 2.73x 4.08 2.21x 3.18 2.35x 3.54 2.11x 3.34 2.44x 3.65
L3 70BEAGLE-2 2.97x 4.02 2.95x 3.89 2.37x 3.16 2.72x 3.65 2.44x 3.34 2.69x 3.61
HASS 3.71x 4.67 3.49x 4.38 2.83x 3.47 3.25x 4.11 2.75x 3.70 3.21x 4.07
Bảng 11: Tỷ lệ tăng tốc và độ dài chấp nhận τ của HASS và EAGLE-2 trên năm nhiệm vụ dịch thuật, trong đó các mô hình draft được huấn luyện với bộ dữ liệu ShareGPT cố định. De, Fr, Ja, Ru, Zh, và En viết tắt cho tiếng Đức, tiếng Pháp, tiếng Nhật, tiếng Nga, tiếng Trung, và tiếng Anh tương ứng. L2 đại diện cho LLaMA2-Chat, trong khi L3 đại diện cho LLaMA3-Instruct.
Như được hiển thị từ Bảng 11, HASS liên tục vượt trội hơn EAGLE-2 dưới tất cả các cài đặt. HASS đạt được tỷ lệ tăng tốc thời gian thực từ 2.44x-3.28x trung bình trên năm nhiệm vụ dịch thuật, vượt trội hơn EAGLE-2 từ 17%-24%. Về độ dài chấp nhận, HASS đạt được cải thiện 8%-14% so với EAGLE-2. Nhất quán với kết quả trên các nhiệm vụ đối thoại (MT-bench), tạo mã (HumanEval), và lý luận toán học (GSM8K), HASS cho thấy những cải thiện đầy hứa hẹn so với EAGLE-2 trên các nhiệm vụ dịch thuật, phản ánh tính mạnh mẽ của nó trên các loại nhiệm vụ khác nhau.
3https://github.com/Kthyeon/Multilingual-SpecBench
20

--- TRANG 21 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2025
A.8 CHI PHÍ HUẤN LUYỆN
Như được hiển thị từ Bảng 4, huấn luyện với 3/4 bước căn chỉnh ngữ cảnh hài hòa thường thu được độ dài chấp nhận đáng kể nhất, và do đó bước căn chỉnh của HASS được cố định là 3 (Tiêu chuẩn) trong bài báo này trừ khi có nêu khác. Để khảo sát chi phí huấn luyện thực tế của HASS, chúng tôi huấn luyện các mô hình draft cho LLaMA2-Chat 7/13B và LLaMA3-Instruct 8/70B trên một GPU NVIDIA H800 duy nhất với kích thước batch đặt là 2 và các bước căn chỉnh khác nhau, và tóm tắt kết quả về tốc độ huấn luyện, chi phí tính toán, và bộ nhớ GPU trong Hình 9, 10, và 11 tương ứng. Đáng nói là chi phí huấn luyện của HASS với 1 bước căn chỉnh giống như của EAGLE-2.
Align-1
(EAGLE)Align-2 Align-3 Align-4 Align-5012345678Tốc độ Huấn luyện (batch/s)6.07
5.56
3.93
2.61
1.78LLaMA2-Chat 7B
Align-1
(EAGLE)Align-2 Align-3 Align-4 Align-5012345678
4.70 4.61
3.09
2.04
1.46LLaMA2-Chat 13B
Align-1
(EAGLE)Align-2 Align-3 Align-4 Align-5012345678
6.75
5.39
3.53
2.46
1.77LLaMA3-Instruct 8B
Align-1
(EAGLE)Align-2 Align-3 Align-4 Align-5012345678
2.972.62
1.77
1.240.92LLaMA3-Instruct 70B
Hình 9: Tốc độ huấn luyện (batch/s) của HASS với các bước căn chỉnh khác nhau, trong đó tốc độ của Align-1 giống như của EAGLE/EAGLE-2.
Tốc độ huấn luyện được đánh giá bằng số batch có thể được xử lý trong một giây, tức là batch/s, và tỷ lệ giữa Align-1 và Align- j đại diện cho thời gian huấn luyện cần thiết để thực hiện cùng lượng dữ liệu huấn luyện so với EAGLE-2. Như được hiển thị từ Hình 9, tốc độ huấn luyện giảm với nhiều bước căn chỉnh hơn. Tuy nhiên, thời gian huấn luyện thực tế của HASS tiêu chuẩn (Align-3) chỉ nhiều hơn 66.34% so với EAGLE-2 trung bình trên bốn mô hình đích, và chi phí thời gian thêm cao nhất so với EAGLE-2 chỉ là 91.47% (trên LLaMA3-Instruct 8B). Chi phí huấn luyện của HASS hoàn toàn có thể chấp nhận được, trong khi HASS đạt được hiệu suất vượt trội và yêu cầu chi phí suy luận không đổi.
0 5 10 15 20Align-1
(EAGLE)Align-2Align-3Align-4Align-5Tiến trìnhLLaMA2-Chat 7B
0 10 20 30Align-1
(EAGLE)Align-2Align-3Align-4Align-5LLaMA2-Chat 13B
0 10 20 30 40Align-1
(EAGLE)Align-2Align-3Align-4Align-5LLaMA3-Instruct 8B
0 20 40 60 80 100Align-1
(EAGLE)Align-2Align-3Align-4Align-5LLaMA3-Instruct 70B
Phần Cố định
Phần Attention
Khác
0 20 40 60
TFLOPsAlign-1
(EAGLE)Align-2Align-3Align-4Align-5Tổng
0 20 40 60 80 100
TFLOPsAlign-1
(EAGLE)Align-2Align-3Align-4Align-5
0 25 50 75 100
TFLOPsAlign-1
(EAGLE)Align-2Align-3Align-4Align-5
0 100 200 300
TFLOPsAlign-1
(EAGLE)Align-2Align-3Align-4Align-5
Tiến trình
Ngược
Hình 10: FLOPs huấn luyện của HASS với các bước căn chỉnh khác nhau, trong đó chi phí tính toán của Align-1 giống như của EAGLE/EAGLE-2. Các hình trên hiển thị FLOPs của bước tiến trình, trong khi các hình dưới hiển thị FLOPs tổng cộng (bước tiến trình và ngược).
Chi phí tính toán được đánh giá bằng TFLOPs và có thể được chia thành bước tiến trình và bước ngược, chúng tôi mô tả chi phí của bước tiến trình và bước ngược trong các hình trên và dưới trong Hình 10 tương ứng. Chi phí của bước tiến trình gồm ba phần:
• Phần cố định không thay đổi theo số bước căn chỉnh. Ánh xạ trạng thái ẩn của LLM đích thành q(x) (tham khảo phần 3.1) với LM head để chưng cất mô hình draft được bao gồm trong phần cố định.
21

--- TRANG 22 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2025
• Phần attention tỷ lệ thuận tuyến tính với số lượng trạng thái ẩn được đưa vào mô hình draft, được tích lũy qua các bước huấn luyện HASS, tức là Pj
i=1i cho Align- j. Kết hợp token embedding với trạng thái ẩn, chiếu trạng thái ẩn thành key và value, và tiến hành các phép toán attention giữa query và một số cặp kv-pair có nguồn gốc từ các trạng thái ẩn khác nhau được bao gồm trong phần attention.
• Khác tỷ lệ thuận tuyến tính với số bước căn chỉnh, tức là j cho Align- j. Chi phí tính toán ngoài các phần cố định và attention được bao gồm trong khác.
Chi phí của bước ngược có thể được coi là (A+O)×2, trong đó A và O đại diện cho phần attention và khác tương ứng, vì tính toán của phần cố định không yêu cầu gradient. Nói chung, HASS tiêu chuẩn (Align-3) yêu cầu khoảng 3x chi phí tính toán của EAGLE-2.
Align-1
(EAGLE)Align-2 Align-3 Align-4 Align-5681012141618202 Bộ nhớ GPU (GB)
LLaMA2-Chat 7B
Align-1
(EAGLE)Align-2 Align-3 Align-4 Align-510.012.515.017.520.022.525.0
LLaMA2-Chat 13B
Align-1
(EAGLE)Align-2 Align-3 Align-4 Align-51416182022242628
LLaMA3-Instruct 8B
Align-1
(EAGLE)Align-2 Align-3 Align-4 Align-5303540455055
LLaMA3-Instruct 70B
Trung bình Đỉnh
Hình 11: Bộ nhớ GPU huấn luyện của HASS với các bước căn chỉnh khác nhau, trong đó bộ nhớ GPU của Align-1 giống như của EAGLE/EAGLE-2. Trung bình và Đỉnh viết tắt cho bộ nhớ GPU trung bình và đỉnh qua quá trình huấn luyện tương ứng.
Bộ nhớ GPU được đánh giá bằng GB và chúng tôi báo cáo bộ nhớ GPU trung bình và đỉnh qua quá trình huấn luyện. Cả bộ nhớ GPU trung bình và đỉnh đều tăng với nhiều bước căn chỉnh hơn. Yêu cầu bộ nhớ GPU có thể được đáp ứng bởi một GPU NVIDIA H800 duy nhất ngay cả ở Align-5 và kích thước batch đặt là 2.
22

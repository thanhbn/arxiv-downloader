# Tăng tốc Giải mã Suy đoán Động của các Mô hình Ngôn ngữ Lớn thông qua Speculation Lookahead Động

## Tóm tắt

Giải mã suy đoán thường được sử dụng để giảm độ trễ suy luận của các mô hình ngôn ngữ lớn. Hiệu quả của nó phụ thuộc rất nhiều vào speculation lookahead (SL) - số lượng token được tạo ra bởi mô hình nháp tại mỗi lần lặp. Trong nghiên cứu này, chúng tôi chỉ ra rằng thông lệ phổ biến sử dụng cùng một SL cho tất cả các lần lặp (SL tĩnh) là không tối ưu. Chúng tôi giới thiệu DISCO (Tối ưu hóa Speculation Lookahead Động), một phương pháp mới để lựa chọn SL một cách động. Các thí nghiệm của chúng tôi với bốn tập dữ liệu cho thấy DISCO đạt được tốc độ tăng tốc trung bình 10% so với baseline SL tĩnh tốt nhất, trong khi tạo ra cùng một văn bản.

## 1 Giới thiệu

Các mô hình ngôn ngữ lớn (LLM) tạo ra token theo cách tự hồi quy, điều này thường dẫn đến việc tạo ra chậm. Các thuật toán giải mã suy đoán giảm độ trễ suy luận bằng cách chia suy luận của một mô hình cho trước thành hai bước. Đầu tiên, một mô hình nháp nhanh tạo ra token theo cách tự hồi quy. Sau đó, một mô hình đích chính xác hơn xác thực tất cả các token nháp được tạo ra đồng thời. Xem Hình 1 để biết ví dụ.

Hiệu quả của giải mã suy đoán phụ thuộc vào speculation lookahead (SL) - số lượng token được tạo ra bởi mô hình nháp tại mỗi lần lặp. SL quá nhỏ dẫn đến quá nhiều bước forward của mô hình đích; các giá trị SL quá lớn thêm vào các lần forward pass nháp thừa. Tuy nhiên, các phương pháp giải mã suy đoán hiện tại sử dụng SL tĩnh - một SL không đổi qua tất cả các lần lặp. Nghiên cứu này bắt đầu bằng việc định nghĩa một SL oracle - một phương pháp gán cho mỗi lần lặp SL tối ưu của nó. Chúng tôi quan sát thấy rằng SL tối ưu cho thấy phương sai cao qua các lần lặp (Hình 2). Sau đó chúng tôi sử dụng oracle này để ước tính giới hạn trên của tốc độ tăng tốc dự kiến (so với việc sử dụng SL tĩnh), cho thấy mức tăng tiềm năng lên đến 39% tốc độ. Sau đó chúng tôi đề xuất DISCO, một phương pháp mới để lựa chọn SL trước mỗi lần lặp.

DISCO ước tính khả năng token nháp tiếp theo được chấp nhận bởi mô hình đích, và dừng mô hình nháp nếu khả năng này quá nhỏ. Chúng tôi đánh giá DISCO qua các tác vụ khác nhau: tạo code, tóm tắt văn bản, và tuân theo hướng dẫn. Kết quả của chúng tôi cho thấy tốc độ tăng tốc trung bình 10% so với SL tĩnh tối ưu và 31% so với heuristic đã biết trước đây để kiểm soát SL, tất cả đều không thay đổi văn bản đầu ra. DISCO cũng chuyển giao tốt qua các tác vụ từ cùng một danh mục: huấn luyện nó trên một tác vụ và sử dụng nó trên tác vụ khác dẫn đến tốc độ tăng tốc tương tự.

## 2 Bối cảnh: Giải mã Suy đoán

Giải mã suy đoán đẩy nhanh việc tạo ra LLM trong khi đảm bảo không mất độ chính xác bằng cách chia nó thành hai giai đoạn. Trong giai đoạn đầu tiên, một mô hình nháp MD nhanh nhưng ít chính xác hơn tự động tạo ra một chuỗi token. Trong giai đoạn thứ hai, một mô hình đích MT lớn nhưng chính xác hơn thực hiện xác minh song song trên các token nháp được tạo ra. Quá trình này cho phép mô hình có thể tạo ra nhiều token mỗi lần forward pass của mô hình đích.

**Speculation lookahead (SL)** Hiệu quả của giải mã suy đoán trong việc tăng tốc quá trình tạo token phụ thuộc rất nhiều vào tham số SL, quyết định có bao nhiêu token được tạo ra bởi mô hình nháp trước mỗi bước xác thực. Ảnh hưởng của SL lên tốc độ tăng tốc tổng thể phải chịu một sự đánh đổi; SL cao hơn có thể giảm số lượng xác thực mô hình đích, nhưng cũng tăng số lượng tạo nháp thừa (Hình 1), và ngược lại. Đa số các phương pháp giải mã suy đoán sử dụng SL tĩnh - cùng một số lượng token nháp được tạo ra mỗi lần lặp suy đoán.

Chen et al. khám phá các SL tĩnh khác nhau, qua các cặp mô hình đích-nháp và tác vụ khác nhau, và chỉ ra thực nghiệm rằng khi SL tăng, tốc độ tăng tốc tổng thể tăng cho đến khi đạt một ngưỡng nhất định, vượt quá đó nó hoặc ổn định hoặc thậm chí lùi lại. Để nghiên cứu ảnh hưởng của SL, Leviathan et al. định nghĩa hệ số cải thiện (IF) như tốc độ tăng tốc tạo token dự kiến:

IF = (1 - alpha * gamma + 1) / ((1 - alpha) * (gamma * c + 1))

trong đó alpha biểu thị tỷ lệ chấp nhận, cho biết xác suất dự kiến của một token nháp được chấp nhận bởi mô hình đích; c đại diện cho hệ số chi phí, cho biết tỷ lệ giữa thời gian walltime của một forward pass của mô hình nháp MD và thời gian walltime của một forward pass của mô hình đích MT; và gamma đại diện cho giá trị SL tĩnh. Trong khi cả alpha và c đều quan trọng đối với việc lựa chọn cặp mô hình đích-nháp, việc tìm gamma tối ưu là cơ bản cho hiệu quả của hệ thống.

## 3 Speculation Lookahead Động

Hàm IF (Phương trình 1) dựa trên giả định đơn giản hóa rằng xác suất chấp nhận token nháp bởi mô hình đích là i.i.d. Tuy nhiên, trong các tình huống thực tế, các token khác nhau có thể có các mức độ dự đoán khác nhau, điều này thách thức giả định i.i.d. này, và gợi ý rằng việc sử dụng SL tĩnh có thể không tối ưu. Dưới đây chúng tôi xem xét một thí nghiệm oracle, áp dụng giá trị gamma động tối ưu tại mỗi lần lặp. Sau đó chúng tôi đề xuất một phương pháp để thiết lập gamma động, cho thấy nó vượt trội hơn đáng kể so với phương pháp lựa chọn tĩnh cho bất kỳ lựa chọn SL tĩnh nào.

**Tìm SL tối ưu mỗi lần lặp** Chúng tôi bắt đầu bằng việc sử dụng một oracle để phát hiện giá trị tối ưu của SL (gamma) cho mỗi lần lặp suy đoán. Oracle sử dụng mô hình nháp để tự động tạo ra token cho đến khi xảy ra không khớp giữa các token dự đoán của mô hình nháp và đích. Quá trình này được lặp lại cho mỗi lần lặp suy đoán, cuối cùng trả về số lượng tối ưu (tối đa) các token nháp được chấp nhận mỗi lần lặp. Sự không khớp giữa các token được xác định bằng cách sử dụng thuật toán rejection sampling được giới thiệu bởi Leviathan et al. với nhiệt độ không. Oracle này thực hiện tiềm năng giải mã suy đoán: tạo ra số lượng tối đa các token nháp hợp lệ tại mỗi lần lặp, và thực hiện số lượng tối thiểu các lần gọi đến cả mô hình nháp và đích. Hình 2 cho thấy các giá trị SL oracle qua các lần lặp suy đoán cho một ví dụ MBPP. So với SL tĩnh, chúng tôi quan sát số lượng thấp hơn của cả forward pass nháp và đích. Hình 3 cho thấy SL oracle trung bình qua các lần lặp suy đoán cho tập dữ liệu Alpaca. Cả hai hình đều cho thấy phương sai cao của các giá trị SL oracle, ngụ ý rằng SL tĩnh có thể không tối ưu.

**Tối ưu hóa Speculation Lookahead Động** Chúng tôi giới thiệu DISCO, một phương pháp đơn giản để thiết lập giá trị SL động tại mỗi lần lặp. Để ước tính giá trị SL chính xác tại mỗi bước, chúng tôi sử dụng một bộ phân loại đơn giản như sau. Ngay sau khi tạo ra bất kỳ token nháp nào, bộ phân loại của chúng tôi quyết định liệu mô hình nháp MD nên tiếp tục và tạo ra token tiếp theo hay chuyển sang mô hình đích MT để xác thực. Bộ phân loại lấy vector xác suất của mô hình nháp (yD_i) và vị trí token (i) làm đầu vào, tạo ra điểm tin cậy (Ci) được sử dụng để ra quyết định như sau:

Ci = FFN(Concat(Top_k(yD_i), Ent(yD_i), i))

trong đó Top_k() chọn k giá trị cao nhất và Ent() là hàm entropy. Tại thời điểm suy luận, Ci được so sánh với ngưỡng được xác định trước tau để quyết định liệu mô hình nháp nên tiếp tục tạo ra token tiếp theo hay chuyển sang mô hình đích để xác thực. Ngoài ra, chúng tôi giới hạn số lượng token nháp được tạo ra thành SLmax. Lưu ý rằng phương pháp của chúng tôi thích ứng thuật toán rejection sampling để bảo toàn phân phối của MT, do đó đảm bảo không có suy giảm chất lượng.

## 4 Thí nghiệm

**Tập dữ liệu và Mô hình** Chúng tôi đánh giá phương pháp của mình trên bốn tập dữ liệu trải rộng ba tác vụ: tạo code sử dụng MBPP và HumanEval; tóm tắt văn bản sử dụng CNN-DailyMail; và tuân theo hướng dẫn sử dụng Alpaca. Chúng tôi sử dụng tập huấn luyện để huấn luyện bộ phân loại SL và tập validation để thiết lập ngưỡng tau và siêu tham số SLmax. Đối với HumanEval, không có tập huấn luyện và validation, chúng tôi đánh giá học chuyển giao từ MBPP. Đối với các tác vụ tạo code, chúng tôi sử dụng họ mô hình Starcoder - 15B cho đích và 168M cho nháp. Đối với các tác vụ khác, chúng tôi sử dụng các mô hình Vicuna - 13B làm đích và 68M làm nháp.

**Huấn luyện bộ phân loại SL** Để huấn luyện bộ phân loại, chúng tôi trích xuất các đặc trưng từ tập huấn luyện của các tập dữ liệu MBPP, CNN-DM, và Alpaca. Để giảm thiểu overhead, chúng tôi sử dụng bộ phân loại FFN nông 2 lớp và huấn luyện nó dựa trên các đặc trưng được trích xuất để dự đoán sự đồng ý giữa mô hình nháp và đích. Việc huấn luyện sử dụng cross-entropy loss với Total Variance làm thước đo khoảng cách: TV(yD_i, yT_i), trong đó yD_i và yT_i đại diện cho phân phối từ vựng của MD và MT tương ứng tại vị trí token thứ i. Chúng tôi đánh giá chất lượng của bộ phân loại bằng cách đo điểm F1 trên tập validation. Kết quả F1 thu được trên các tập dữ liệu tương đối cao; ví dụ, 95% trên MBPP, so với 85% sử dụng SL tĩnh tối ưu.

**Baseline và Kết quả** Chúng tôi so sánh độ trễ suy luận LLM của DISCO với cả thiết lập SL tĩnh (static SL-5) và SL heuristic động (dynHeur SL). Chúng tôi cũng xem xét baseline SL tĩnh tối ưu được điều chỉnh trên tập validation của chúng tôi (static SL-opt). Cuối cùng, chúng tôi cũng báo cáo kết quả cho oracle của chúng tôi, đại diện cho giới hạn dưới về độ trễ. Bảng 1 trình bày kết quả của chúng tôi sử dụng sơ đồ rejection sampling với greedy decoding (nhiệt độ = 0) vì baseline đạt tốc độ tăng tốc cao hơn. Việc sử dụng bộ phân loại SL luôn vượt trội hơn tất cả các baseline khác trên tất cả các benchmark. Cải thiện độ trễ trung bình của DISCO so với SL tĩnh tối ưu và baseline heuristic động lần lượt là 10.3% và 31.4%, trong khi bảo toàn cùng một đầu ra như mô hình đích. Quan trọng là, cải thiện của chúng tôi không chỉ đến từ dữ liệu huấn luyện của chúng tôi: SL tĩnh tối ưu (như được fit bởi dữ liệu đó) vẫn bị DISCO vượt trội. Cuối cùng, DISCO chuyển giao tốt qua các tác vụ: khi được huấn luyện trên MBPP, nó vẫn vượt trội hơn tất cả baseline trên HumanEval.

## 5 Nghiên cứu Liên quan

Các nghiên cứu tiên phong về giải mã suy đoán giới thiệu sơ đồ rejection sampling để bảo toàn phân phối của mô hình đích, đảm bảo rằng giải mã suy đoán duy trì chất lượng của mô hình đích. Nghiên cứu tiếp theo nâng cao số lượng token được chấp nhận trung bình bằng cách sử dụng nhiều mô hình nháp. Gần đây nhất, Timor et al. giới thiệu DSI, một biến thể phân tán của giải mã suy đoán được chứng minh là nhanh hơn các phương pháp không phân tán và không yêu cầu huấn luyện bổ sung hoặc thay đổi kiến trúc. Để loại bỏ nhu cầu về mô hình nháp riêng biệt, Li et al., Cai et al., Bhendawade et al., Yang et al. huấn luyện các lớp nháp chuyên biệt bổ sung trên transformer decoder. DISCO chuyển giao tốt trong các domain và không yêu cầu huấn luyện bộ phân loại cho mỗi tập dữ liệu trong khi các phương pháp này đòi hỏi huấn luyện cho mỗi tập dữ liệu. Tại thời điểm suy luận, họ sử dụng SL tĩnh; chúng tôi tin rằng DISCO có thể được áp dụng có lợi cho các phương pháp này, chúng tôi để lại nghiên cứu này cho công việc tương lai.

Zhang et al. đề xuất draft-exiting với ngưỡng thích ứng cho self-speculative decoding sử dụng phương pháp dựa trên quy tắc so sánh độ tin cậy với ngưỡng được xác định trước. Phương pháp này có vẻ phù hợp với các phương pháp mà nháp là tập con của mô hình đích, trong khi phương pháp của chúng tôi tổng quát hơn. Một nghiên cứu đồng thời rất gần đây của S et al. nâng cao độ chính xác của mô hình nháp bằng cách cấp cho nó quyền truy cập vào các biểu diễn của mô hình đích. Ngoài ra, nó sử dụng bộ phân loại để xác định liệu có nên dừng hay tiếp tục quá trình suy đoán. Nghiên cứu của chúng tôi đi sâu vào tác động của SL lên hiệu quả của giải mã suy đoán, bao gồm các so sánh giữa phương pháp SL tĩnh và động, cũng như giới hạn trên của cải thiện được đại diện bởi SL oracle.

## 6 Kết luận

Chúng tôi đã chỉ ra rằng việc sử dụng cùng một tham số speculation lookahead qua các lần lặp giải mã suy đoán là không tối ưu. Chúng tôi giới thiệu DISCO, một phương pháp tối ưu hóa speculation lookahead động. Phương pháp này sử dụng bộ phân loại xác định liệu mô hình nháp nên tiếp tục tạo ra token tiếp theo hay tạm dừng và chuyển sang mô hình đích để xác thực. Chúng tôi đánh giá hiệu quả của DISCO sử dụng bốn benchmark và chứng minh mức tăng tốc độ trung bình 10.3% và 31.4% tương đối so với SL tĩnh tối ưu và baseline heuristic động. Kết quả của chúng tôi làm nổi bật tiềm năng giảm thêm chi phí suy luận bằng cách sử dụng các kỹ thuật đơn giản, hiệu quả.

# 2302.01318.pdf
# Chuyá»ƒn Ä‘á»•i tá»« PDF sang TXT
# ÄÆ°á»ng dáº«n nguá»“n: /home/admin88/arxiv-downloader/speculative/2302.01318.pdf
# KÃ­ch thÆ°á»›c tá»‡p: 349916 bytes

===============================================
Ná»˜I DUNG Tá»†P PDF
===============================================


--- TRANG 1 ---
2023-2-3
TÄƒng tá»‘c Giáº£i mÃ£ MÃ´ hÃ¬nh NgÃ´n ngá»¯ Lá»›n
vá»›i Láº¥y máº«u Suy Ä‘oÃ¡n
Charlie Chen1, Sebastian Borgeaud1, Geoï¬€rey Irving1, Jean-Baptiste Lespiau1, Laurent Sifre1vÃ  John
Jumper1
1Táº¥t cáº£ tÃ¡c giáº£ tá»« DeepMind
ChÃºng tÃ´i trÃ¬nh bÃ y láº¥y máº«u suy Ä‘oÃ¡n, má»™t thuáº­t toÃ¡n Ä‘á»ƒ tÄƒng tá»‘c giáº£i mÃ£ transformer báº±ng cÃ¡ch cho phÃ©p
táº¡o ra nhiá»u token tá»« má»—i láº§n gá»i transformer. Thuáº­t toÃ¡n cá»§a chÃºng tÃ´i dá»±a trÃªn quan sÃ¡t ráº±ng
Ä‘á»™ trá»… cá»§a viá»‡c cháº¥m Ä‘iá»ƒm song song cÃ¡c pháº§n tiáº¿p tá»¥c ngáº¯n, Ä‘Æ°á»£c táº¡o ra bá»Ÿi má»™t mÃ´ hÃ¬nh nhÃ¡p
nhanh hÆ¡n nhÆ°ng Ã­t máº¡nh máº½ hÆ¡n, cÃ³ thá»ƒ so sÃ¡nh Ä‘Æ°á»£c vá»›i viá»‡c láº¥y máº«u má»™t token duy nháº¥t tá»« mÃ´ hÃ¬nh
Ä‘Ã­ch lá»›n hÆ¡n. Äiá»u nÃ y Ä‘Æ°á»£c káº¿t há»£p vá»›i má»™t sÆ¡ Ä‘á»“ láº¥y máº«u tá»« chá»‘i Ä‘Æ°á»£c sá»­a Ä‘á»•i má»›i báº£o toÃ n phÃ¢n phá»‘i
cá»§a mÃ´ hÃ¬nh Ä‘Ã­ch trong pháº¡m vi sá»‘ há»c pháº§n cá»©ng. ChÃºng tÃ´i Ä‘Ã¡nh giÃ¡ láº¥y máº«u suy Ä‘oÃ¡n vá»›i Chinchilla,
má»™t mÃ´ hÃ¬nh ngÃ´n ngá»¯ 70 tá»· tham sá»‘, Ä‘áº¡t Ä‘Æ°á»£c tÄƒng tá»‘c giáº£i mÃ£ 2â€“25 láº§n trong thiáº¿t láº­p phÃ¢n tÃ¡n, mÃ  khÃ´ng
lÃ m tá»•n háº¡i cháº¥t lÆ°á»£ng máº«u hoáº·c thá»±c hiá»‡n cÃ¡c sá»­a Ä‘á»•i Ä‘á»‘i vá»›i chÃ­nh mÃ´ hÃ¬nh.

Giá»›i thiá»‡u
Viá»‡c má»Ÿ rá»™ng quy mÃ´ cÃ¡c mÃ´ hÃ¬nh transformer lÃªn 500B+ tham sá»‘ Ä‘Ã£ dáº«n Ä‘áº¿n nhá»¯ng cáº£i thiá»‡n hiá»‡u suáº¥t lá»›n trÃªn
nhiá»u tÃ¡c vá»¥ xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn, thá»‹ giÃ¡c mÃ¡y tÃ­nh vÃ  há»c tÄƒng cÆ°á»ng (Arnab et al., 2021; Brown
et al., 2020; Chowdhery et al., 2022; Dosovitskiy et al., 2020; Hoï¬€mann et al., 2022; Rae et al., 2021).
Tuy nhiÃªn, viá»‡c giáº£i mÃ£ transformer váº«n lÃ  má»™t quÃ¡ trÃ¬nh ráº¥t tá»‘n kÃ©m vÃ  khÃ´ng hiá»‡u quáº£ trong cháº¿ Ä‘á»™ nÃ y.
Láº¥y máº«u transformer thÆ°á»ng bá»‹ giá»›i háº¡n bá»Ÿi bÄƒng thÃ´ng bá»™ nhá»› (Shazeer, 2019), vÃ¬ váº­y Ä‘á»‘i vá»›i má»™t táº­p há»£p
pháº§n cá»©ng nháº¥t Ä‘á»‹nh, thá»i gian táº¡o ra má»™t token duy nháº¥t trong cÃ¡c mÃ´ hÃ¬nh transformer tá»· lá»‡ vá»›i xáº¥p xá»‰
báº­c nháº¥t vá»›i kÃ­ch thÆ°á»›c tham sá»‘ vÃ  kÃ­ch thÆ°á»›c bá»™ nhá»› transformer. KÃ­ch thÆ°á»›c cá»§a cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯
cÅ©ng Ä‘Ã²i há»i phá»¥c vá»¥ vá»›i song song hÃ³a mÃ´ hÃ¬nh â€“ thÃªm chi phÃ­ truyá»n thÃ´ng (Pope
et al., 2022) vÃ  nhÃ¢n lÃªn yÃªu cáº§u tÃ i nguyÃªn. VÃ¬ má»—i token má»›i phá»¥ thuá»™c vÃ o quÃ¡ khá»©,
nhiá»u láº§n gá»i transformer nhÆ° váº­y Ä‘Æ°á»£c yÃªu cáº§u Ä‘á»ƒ láº¥y máº«u má»™t chuá»—i má»›i.

ChÃºng tÃ´i trÃ¬nh bÃ y má»™t thuáº­t toÃ¡n Ä‘á»ƒ tÄƒng tá»‘c láº¥y máº«u transformer cho cÃ¡c á»©ng dá»¥ng quan trá»ng vá» Ä‘á»™ trá»…,
mÃ  chÃºng tÃ´i gá»i lÃ  láº¥y máº«u suy Ä‘oÃ¡n (SpS). Äiá»u nÃ y Ä‘Æ°á»£c Ä‘áº¡t Ä‘Æ°á»£c báº±ng:

1. Táº¡o ra má»™t báº£n nhÃ¡p ngáº¯n cÃ³ Ä‘á»™ dÃ i ğ¾. Äiá»u nÃ y cÃ³ thá»ƒ Ä‘áº¡t Ä‘Æ°á»£c báº±ng má»™t mÃ´ hÃ¬nh song song (Stern
et al., 2018) hoáº·c báº±ng cÃ¡ch gá»i má»™t mÃ´ hÃ¬nh tá»± há»“i quy nhanh hÆ¡n ğ¾ láº§n. ChÃºng tÃ´i sáº½ gá»i mÃ´ hÃ¬nh nÃ y
lÃ  mÃ´ hÃ¬nh nhÃ¡p, vÃ  táº­p trung vÃ o trÆ°á»ng há»£p nÃ³ lÃ  tá»± há»“i quy.

2. Cháº¥m Ä‘iá»ƒm báº£n nhÃ¡p báº±ng mÃ´ hÃ¬nh lá»›n hÆ¡n, máº¡nh máº½ hÆ¡n mÃ  chÃºng ta muá»‘n láº¥y máº«u tá»« Ä‘Ã³. ChÃºng tÃ´i sáº½
gá»i mÃ´ hÃ¬nh nÃ y lÃ  mÃ´ hÃ¬nh Ä‘Ã­ch.

3. Sá»­ dá»¥ng má»™t sÆ¡ Ä‘á»“ láº¥y máº«u tá»« chá»‘i Ä‘Æ°á»£c sá»­a Ä‘á»•i, cháº¥p nháº­n má»™t táº­p con cá»§a ğ¾ token nhÃ¡p tá»« trÃ¡i
sang pháº£i, khÃ´i phá»¥c phÃ¢n phá»‘i cá»§a mÃ´ hÃ¬nh Ä‘Ã­ch trong quÃ¡ trÃ¬nh nÃ y.

Trá»±c quan, thÆ°á»ng cÃ³ cÃ¡c chuá»—i mÃ  token tiáº¿p theo cÃ³ thá»ƒ "hiá»ƒn nhiÃªn". Do Ä‘Ã³, náº¿u cÃ³
sá»± Ä‘á»“ng thuáº­n máº¡nh máº½ giá»¯a phÃ¢n phá»‘i cá»§a mÃ´ hÃ¬nh nhÃ¡p vÃ  mÃ´ hÃ¬nh Ä‘Ã­ch trÃªn má»™t token nháº¥t Ä‘á»‹nh hoáº·c chuá»—i con
cá»§a cÃ¡c token, thiáº¿t láº­p nÃ y cho phÃ©p táº¡o ra nhiá»u token má»—i khi mÃ´ hÃ¬nh Ä‘Ã­ch Ä‘Æ°á»£c gá»i.

ChÃºng tÃ´i chá»‰ ra ráº±ng tá»· lá»‡ cháº¥p nháº­n dá»± kiáº¿n cá»§a cÃ¡c token nhÃ¡p Ä‘á»§ Ä‘á»ƒ bÃ¹ Ä‘áº¯p chi phÃ­ cá»§a

TÃ¡c giáº£ liÃªn há»‡: ccharlie@deepmind.com
Â©2023 DeepMind. Táº¥t cáº£ quyá»n Ä‘Æ°á»£c báº£o lÆ°u arXiv:2302.01318v1 [cs.CL] 2 Feb 2023

--- TRANG 2 ---
TÄƒng tá»‘c Giáº£i mÃ£ MÃ´ hÃ¬nh NgÃ´n ngá»¯ Lá»›n vá»›i Láº¥y máº«u Suy Ä‘oÃ¡n

quÃ¡ trÃ¬nh soáº¡n tháº£o cho cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n, dáº«n Ä‘áº¿n má»™t phÆ°Æ¡ng phÃ¡p hiá»‡u quáº£ vÃ  thá»±c táº¿ Ä‘á»ƒ giáº£m
Ä‘á»™ trá»… láº¥y máº«u mÃ  khÃ´ng cáº§n sá»­a Ä‘á»•i mÃ´ hÃ¬nh Ä‘Ã­ch hoáº·c lÃ m thiÃªn lá»‡ch phÃ¢n phá»‘i máº«u.

TÃ¹y thuá»™c vÃ o miá»n Ä‘Ã¡nh giÃ¡, SpS dáº«n Ä‘áº¿n tÄƒng tá»‘c 2â€“25 láº§n khi láº¥y máº«u tá»« Chinchilla
(Hoï¬€mann et al., 2022). ÄÃ¡ng chÃº Ã½, sá»‘ token trung bÃ¬nh má»—i giÃ¢y vá»›i SpS thÆ°á»ng vÆ°á»£t quÃ¡ giá»›i háº¡n
lÃ½ tÆ°á»Ÿng hÃ³a vá» tá»‘c Ä‘á»™ láº¥y máº«u tá»± há»“i quy do bÄƒng thÃ´ng bá»™ nhá»› Ã¡p Ä‘áº·t.

CÃ´ng trÃ¬nh LiÃªn quan
ÄÃ£ cÃ³ má»™t lÆ°á»£ng lá»›n cÃ´ng trÃ¬nh táº­p trung vÃ o viá»‡c cáº£i thiá»‡n Ä‘á»™ trá»… láº¥y máº«u cá»§a cÃ¡c transformer lá»›n
vÃ  cÃ¡c mÃ´ hÃ¬nh tá»± há»“i quy khÃ¡c.

VÃ¬ hiá»‡u suáº¥t láº¥y máº«u Ä‘Æ°á»£c liÃªn káº¿t cháº·t cháº½ vá»›i kÃ­ch thÆ°á»›c mÃ´ hÃ¬nh trong bá»™ nhá»›, lÆ°á»£ng tá»­ hÃ³a thÃ nh
int8 hoáº·c tháº­m chÃ­ int4 (Dettmers et al., 2022; Yao et al., 2022) vÃ  chÆ°ng cáº¥t (Jiao et al., 2020; Sanh
et al., 2019) cá»§a cÃ¡c transformer lÃ  nhá»¯ng ká»¹ thuáº­t hiá»‡u quáº£ Ä‘á»ƒ giáº£m Ä‘á»™ trá»… láº¥y máº«u vá»›i Ã­t hoáº·c khÃ´ng cÃ³
hÃ¬nh pháº¡t hiá»‡u suáº¥t. Quan sÃ¡t ráº±ng kÃ­ch thÆ°á»›c mÃ´ hÃ¬nh Ä‘Ã³ng gÃ³p Ã­t hÆ¡n dá»± kiáº¿n vÃ o hiá»‡u suáº¥t cuá»‘i cÃ¹ng (Hoï¬€mann et al., 2022) cÅ©ng Ä‘Ã£ khuyáº¿n khÃ­ch cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ nhá» hÆ¡n nÃ³i chung.

Trong quÃ¡ trÃ¬nh láº¥y máº«u, má»™t bá»™ nhá»› Ä‘á»‡m cá»§a cÃ¡c khÃ³a vÃ  giÃ¡ trá»‹ Ä‘Æ°á»£c duy trÃ¬ cho má»i lá»›p attention, vÃ  cÃ³ thá»ƒ
trá»Ÿ thÃ nh nÃºt tháº¯t cá»• chai bÄƒng thÃ´ng bá»™ nhá»› khi kÃ­ch thÆ°á»›c batch tÄƒng. CÃ¡c phÆ°Æ¡ng phÃ¡p nhÆ° multi-query
attention (Shazeer, 2019) nháº±m cáº£i thiá»‡n hiá»‡u suáº¥t láº¥y máº«u báº±ng cÃ¡ch thu nhá» bá»™ nhá»› Ä‘á»‡m nÃ y. Tuy nhiÃªn
nhá»¯ng ká»¹ thuáº­t nÃ y hiá»‡u quáº£ nháº¥t trong viá»‡c tá»‘i Ä‘a hÃ³a thÃ´ng lÆ°á»£ng (á»Ÿ kÃ­ch thÆ°á»›c batch lá»›n hÆ¡n) thay vÃ¬ Ä‘á»™ trá»…,
Ä‘áº·c biá»‡t Ä‘á»‘i vá»›i cÃ¡c mÃ´ hÃ¬nh lá»›n hÆ¡n nÆ¡i pháº§n lá»›n ngÃ¢n sÃ¡ch bÄƒng thÃ´ng bá»™ nhá»› Ä‘Æ°á»£c tiÃªu thá»¥ bá»Ÿi cÃ¡c
tham sá»‘.

Sá»­ dá»¥ng káº¿t há»£p cÃ¡c ká»¹ thuáº­t trÃªn, thÃªm vÃ o má»™t sá»‘ tá»‘i Æ°u hÃ³a cáº¥p tháº¥p cho
TPU, Pope et al. (2022) Ä‘Ã£ cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ Ä‘á»™ trá»… vÃ  hiá»‡u quáº£ phá»¥c vá»¥ cá»§a PaLM 540B.

CÃ³ má»™t lÆ°á»£ng cÃ´ng trÃ¬nh hiá»‡n táº¡i tÆ°Æ¡ng tá»± khai thÃ¡c hiá»‡u quáº£ cá»§a cÃ¡c transformer vÃ  cÃ¡c mÃ´ hÃ¬nh
chuá»—i hoáº¡t Ä‘á»™ng song song. Äiá»u nÃ y bao gá»“m láº¥y máº«u song song khá»‘i (Stern et al., 2018), giáº£i mÃ£
tÃ­ch cá»±c (Ge et al., 2022), thÃªm vÃ o má»™t sá»‘ cÃ´ng trÃ¬nh trong viá»‡c song song hÃ³a cÃ¡c mÃ´ hÃ¬nh tá»± há»“i quy trong
miá»n hÃ¬nh áº£nh (Song et al., 2021; Wiggers vÃ  Hoogeboom, 2020). Nhá»¯ng phÆ°Æ¡ng phÃ¡p nÃ y chÆ°a Ä‘Æ°á»£c
thÃ­ch á»©ng vá»›i cÃ¡c trÆ°á»ng há»£p sá»­ dá»¥ng mÃ´ hÃ¬nh ngÃ´n ngá»¯ Ä‘iá»ƒn hÃ¬nh vÃ¬ chÃºng hoáº·c chá»‰ hoáº¡t Ä‘á»™ng vá»›i láº¥y máº«u tham lam, lÃ m thiÃªn lá»‡ch
káº¿t quáº£ hoáº·c táº­p trung vÃ o cÃ¡c phÆ°Æ¡ng thá»©c khÃ¡c. HÆ¡n ná»¯a, theo hiá»ƒu biáº¿t cá»§a chÃºng tÃ´i, khÃ´ng cÃ³ ká»¹ thuáº­t nÃ o trong sá»‘ nÃ y
Ä‘Ã£ Ä‘Æ°á»£c má»Ÿ rá»™ng quy mÃ´ cho thiáº¿t láº­p phÃ¢n tÃ¡n, Ä‘iá»u cáº§n thiáº¿t cho cÃ¡c bá»™ giáº£i mÃ£ Ä‘áº¯t nháº¥t vá»›i
hÃ ng chá»¥c hoáº·c hÃ ng trÄƒm tá»· tham sá»‘.

TrÃ¹ng há»£p, cÃ´ng trÃ¬nh trong báº£n tháº£o nÃ y Ä‘Æ°á»£c thá»±c hiá»‡n Ä‘á»“ng thá»i vÃ  Ä‘á»™c láº­p vá»›i
cÃ´ng trÃ¬nh vá» giáº£i mÃ£ suy Ä‘oÃ¡n tá»« Leviathan et al. (2022). ChÃºng tÃ´i táº­p trung nhiá»u hÆ¡n vÃ o thiáº¿t láº­p phá»¥c vá»¥ phÃ¢n tÃ¡n cho cÃ¡c mÃ´ hÃ¬nh lá»›n vÃ  Ä‘Æ°a ra má»™t sá»‘ tá»‘i Æ°u hÃ³a gia tÄƒng, nhÆ°ng ngoÃ i ra Ã½ tÆ°á»Ÿng cá»‘t lÃµi
cÆ¡ báº£n lÃ  giá»‘ng nhau.

Láº¥y máº«u Tá»± há»“i quy
Trong khi cÃ¡c transformer cÃ³ thá»ƒ Ä‘Æ°á»£c huáº¥n luyá»‡n hiá»‡u quáº£ vÃ  song song trÃªn TPU vÃ  GPU, cÃ¡c máº«u thÆ°á»ng
Ä‘Æ°á»£c rÃºt ra tá»± há»“i quy (Xem thuáº­t toÃ¡n 1). Äá»‘i vá»›i háº§u háº¿t cÃ¡c á»©ng dá»¥ng, láº¥y máº«u tá»± há»“i quy (ArS) lÃ 
bá»‹ giá»›i háº¡n cao bá»Ÿi bÄƒng thÃ´ng bá»™ nhá»› vÃ  do Ä‘Ã³ khÃ´ng thá»ƒ sá»­ dá»¥ng hiá»‡u quáº£ pháº§n cá»©ng gia tá»‘c hiá»‡n Ä‘áº¡i
(Shazeer, 2019). Má»™t láº§n gá»i mÃ´ hÃ¬nh bá»‹ giá»›i háº¡n bá»™ nhá»› chá»‰ táº¡o ra má»™t token duy nháº¥t cho má»—i chuá»—i trong
batch, do Ä‘Ã³ viá»‡c táº¡o ra nhiá»u token giá»›i thiá»‡u má»™t lÆ°á»£ng lá»›n Ä‘á»™ trá»… trong báº¥t ká»³ há»‡ thá»‘ng nÃ o
sá»­ dá»¥ng nÃ³.

--- TRANG 3 ---
TÄƒng tá»‘c Giáº£i mÃ£ MÃ´ hÃ¬nh NgÃ´n ngá»¯ Lá»›n vá»›i Láº¥y máº«u Suy Ä‘oÃ¡n

Äiá»u nÃ y Ä‘áº·c biá»‡t cÃ³ váº¥n Ä‘á» khi sá»‘ lÆ°á»£ng tham sá»‘ trong mÃ´ hÃ¬nh tÄƒng. VÃ¬ táº¥t cáº£ cÃ¡c tham sá»‘
mÃ´ hÃ¬nh cáº§n Ä‘i qua Ã­t nháº¥t má»™t chip gia tá»‘c, kÃ­ch thÆ°á»›c mÃ´ hÃ¬nh chia cho tá»•ng
bÄƒng thÃ´ng bá»™ nhá»› trÃªn táº¥t cáº£ cÃ¡c chip cho chÃºng ta má»™t giá»›i háº¡n cá»©ng vá» tá»‘c Ä‘á»™ láº¥y máº«u tá»± há»“i quy
tá»‘i Ä‘a. CÃ¡c mÃ´ hÃ¬nh lá»›n hÆ¡n cÅ©ng yÃªu cáº§u phá»¥c vá»¥ trÃªn nhiá»u gia tá»‘c, giá»›i thiá»‡u thÃªm má»™t nguá»“n
Ä‘á»™ trá»… do chi phÃ­ truyá»n thÃ´ng giá»¯a cÃ¡c thiáº¿t bá»‹.

Thuáº­t toÃ¡n 1 Tá»± há»“i quy (ArS) vá»›i MÃ´ hÃ¬nh Tá»± há»“i quy
Cho mÃ´ hÃ¬nh Ä‘Ã­ch tá»± há»“i quy ğ‘Â¹jÂº vÃ  chuá»—i prompt ban Ä‘áº§u ğ‘¥1ğ‘¥ğ‘¡ vÃ  Ä‘á»™ dÃ i chuá»—i
Ä‘Ã­ch ğ‘‡.
Khá»Ÿi táº¡o ğ‘› ğ‘¡.
while ğ‘› ğ‘‡ do
    Láº¥y máº«u ğ‘¥ğ‘›Â¸1ğ‘Â¹ğ‘¥jğ‘¥1ğ‘¥ğ‘›Âº
    ğ‘› ğ‘›Â¸1
end while

Thuáº­t toÃ¡n 2 Láº¥y máº«u Suy Ä‘oÃ¡n (SpS) vá»›i MÃ´ hÃ¬nh ÄÃ­ch vÃ  NhÃ¡p Tá»± há»“i quy
Cho lookahead ğ¾ vÃ  Ä‘á»™ dÃ i chuá»—i Ä‘Ã­ch tá»‘i thiá»ƒu ğ‘‡.
Cho mÃ´ hÃ¬nh Ä‘Ã­ch tá»± há»“i quy ğ‘Â¹jÂº, vÃ  mÃ´ hÃ¬nh nhÃ¡p tá»± há»“i quy ğ‘Â¹jÂº, chuá»—i prompt
ban Ä‘áº§u ğ‘¥0ğ‘¥ğ‘¡.
Khá»Ÿi táº¡o ğ‘› ğ‘¡.
while ğ‘› ğ‘‡ do
    for ğ‘¡=1 : ğ¾ do
        Láº¥y máº«u nhÃ¡p tá»± há»“i quy Ëœğ‘¥ğ‘¡ğ‘Â¹ğ‘¥jğ‘¥1ğ‘¥ğ‘›Ëœğ‘¥1 Ëœğ‘¥ğ‘¡1Âº
    end for
    Song song, tÃ­nh ğ¾Â¸1 táº­p logit tá»« cÃ¡c báº£n nhÃ¡p Ëœğ‘¥1 Ëœğ‘¥ğ¾:
    ğ‘Â¹ğ‘¥jğ‘¥1ğ‘¥ğ‘›Âº ğ‘Â¹ğ‘¥jğ‘¥1ğ‘¥ğ‘›Ëœğ‘¥1Âº  ğ‘Â¹ğ‘¥jğ‘¥1ğ‘¥ğ‘›Ëœğ‘¥1 Ëœğ‘¥ğ¾Âº
    for ğ‘¡=1 : ğ¾ do
        Láº¥y máº«u ğ‘Ÿğ‘ˆÂ»01Â¼ tá»« phÃ¢n phá»‘i Ä‘á»u.
        if ğ‘Ÿ min(1, ğ‘Â¹ğ‘¥jğ‘¥1ğ‘¥ğ‘›Â¸ğ‘¡1Âº/ğ‘Â¹ğ‘¥jğ‘¥1ğ‘¥ğ‘›Â¸ğ‘¡1Âº) then
            Äáº·t ğ‘¥ğ‘›Â¸ğ‘¡ Ëœğ‘¥ğ‘¡ vÃ  ğ‘› ğ‘›Â¸1.
        else
            láº¥y máº«u ğ‘¥ğ‘›Â¸ğ‘¡Â¹ğ‘Â¹ğ‘¥jğ‘¥1ğ‘¥ğ‘›Â¸ğ‘¡1Âºğ‘Â¹ğ‘¥jğ‘¥1ğ‘¥ğ‘›Â¸ğ‘¡1ÂºÂºÂ¸ vÃ  thoÃ¡t khá»i vÃ²ng láº·p for.
        end if
    end for
    Náº¿u táº¥t cáº£ token ğ‘¥ğ‘›Â¸1ğ‘¥ğ‘›Â¸ğ¾ Ä‘Æ°á»£c cháº¥p nháº­n, láº¥y máº«u token thÃªm ğ‘¥ğ‘›Â¸ğ¾Â¸1ğ‘Â¹ğ‘¥jğ‘¥1ğ‘¥ğ‘›ğ‘¥ğ‘›Â¸ğ¾Âº vÃ 
    Ä‘áº·t ğ‘› ğ‘›Â¸1.
end while

Láº¥y máº«u Suy Ä‘oÃ¡n

Cháº¥m Ä‘iá»ƒm CÃ³ Ä‘iá»u kiá»‡n
Äá»‘i vá»›i láº¥y máº«u suy Ä‘oÃ¡n (Xem thuáº­t toÃ¡n 2), trÆ°á»›c tiÃªn chÃºng tÃ´i Ä‘Æ°a ra quan sÃ¡t ráº±ng viá»‡c tÃ­nh toÃ¡n logit
cá»§a má»™t pháº§n tiáº¿p tá»¥c ngáº¯n ğ¾ token song song cÃ³ Ä‘á»™ trá»… ráº¥t tÆ°Æ¡ng tá»± nhÆ° viá»‡c láº¥y máº«u má»™t

--- TRANG 4 ---
TÄƒng tá»‘c Giáº£i mÃ£ MÃ´ hÃ¬nh NgÃ´n ngá»¯ Lá»›n vá»›i Láº¥y máº«u Suy Ä‘oÃ¡n

token duy nháº¥t. ChÃºng tÃ´i táº­p trung chÃº Ã½ vÃ o cÃ¡c transformer lá»›n, Ä‘Æ°á»£c phÃ¢n máº£nh theo kiá»ƒu Megatron (Shoeybi et al.,
2019). Äá»‘i vá»›i nhá»¯ng mÃ´ hÃ¬nh nÃ y, pháº§n lá»›n thá»i gian láº¥y máº«u cÃ³ thá»ƒ Ä‘Æ°á»£c quy cho ba thÃ nh pháº§n:

1. CÃ¡c Lá»›p Tuyáº¿n tÃ­nh: Äá»‘i vá»›i kÃ­ch thÆ°á»›c batch nhá», má»—i lá»›p tuyáº¿n tÃ­nh chá»‰ xá»­ lÃ½ má»™t sá»‘ lÆ°á»£ng nhá»
embedding. Äiá»u nÃ y khiáº¿n cÃ¡c phÃ©p nhÃ¢n ma tráº­n dÃ y Ä‘áº·c trong cÃ¡c lá»›p feed-forward, truy váº¥n, khÃ³a,
tÃ­nh toÃ¡n giÃ¡ trá»‹ vÃ  phÃ©p chiáº¿u attention cuá»‘i cÃ¹ng trá»Ÿ nÃªn bá»‹ giá»›i háº¡n bá»™ nhá»›. Äá»‘i vá»›i ğ¾ nhá»,
Ä‘iá»u nÃ y sáº½ tiáº¿p tá»¥c bá»‹ giá»›i háº¡n bá»™ nhá»› vÃ  do Ä‘Ã³ máº¥t má»™t lÆ°á»£ng thá»i gian tÆ°Æ¡ng tá»±.

2. CÆ¡ cháº¿ Attention: CÆ¡ cháº¿ attention cÅ©ng bá»‹ giá»›i háº¡n bá»™ nhá»›. Trong quÃ¡ trÃ¬nh láº¥y máº«u,
chÃºng ta duy trÃ¬ má»™t bá»™ nhá»› Ä‘á»‡m cá»§a táº¥t cáº£ cÃ¡c khÃ³a vÃ  giÃ¡ trá»‹ cá»§a cÃ¡c token trÆ°á»›c Ä‘Ã³ trong chuá»—i Ä‘á»ƒ trÃ¡nh
tÃ­nh toÃ¡n láº¡i. Nhá»¯ng KV-cache nÃ y lá»›n, vÃ  chiáº¿m pháº§n lá»›n viá»‡c sá»­ dá»¥ng bÄƒng thÃ´ng bá»™ nhá»›
cho cÆ¡ cháº¿ attention. Tuy nhiÃªn, vÃ¬ kÃ­ch thÆ°á»›c KV-cache khÃ´ng
thay Ä‘á»•i khi chÃºng ta tÄƒng ğ¾, cÃ³ ráº¥t Ã­t hoáº·c khÃ´ng cÃ³ sá»± chÃªnh lá»‡ch trong thÃ nh pháº§n nÃ y.

3. All-reduce: Khi cÃ¡c mÃ´ hÃ¬nh tÄƒng kÃ­ch thÆ°á»›c, cÃ¡c tham sá»‘ cá»§a chÃºng cáº§n Ä‘Æ°á»£c chia trÃªn nhiá»u gia tá»‘c,
dáº«n Ä‘áº¿n chi phÃ­ truyá»n thÃ´ng. Vá»›i Megatron, Ä‘iá»u nÃ y thá»ƒ hiá»‡n dÆ°á»›i dáº¡ng all-reduce
sau má»—i lá»›p feed-forward vÃ  attention. VÃ¬ chá»‰ cÃ¡c activation cho má»™t sá»‘ lÆ°á»£ng nhá»
token Ä‘Æ°á»£c truyá»n, thao tÃ¡c nÃ y thÆ°á»ng bá»‹ giá»›i háº¡n Ä‘á»™ trá»… thay vÃ¬ giá»›i háº¡n thÃ´ng lÆ°á»£ng
cho cáº£ láº¥y máº«u vÃ  cháº¥m Ä‘iá»ƒm (Ä‘á»‘i vá»›i ğ¾ nhá»). Má»™t láº§n ná»¯a, Ä‘iá»u nÃ y dáº«n Ä‘áº¿n má»™t lÆ°á»£ng thá»i gian
tÆ°Æ¡ng tá»± Ä‘Æ°á»£c dÃ nh trong hai trÆ°á»ng há»£p.

CÃ¡c nguá»“n chi phÃ­ khÃ¡c cÃ³ thá»ƒ tá»“n táº¡i, tÃ¹y thuá»™c vÃ o viá»‡c triá»ƒn khai transformer cá»¥ thá»ƒ. Do Ä‘Ã³
váº«n cÃ³ thá»ƒ lá»±a chá»n mÃ£ hÃ³a vá»‹ trÃ­, phÆ°Æ¡ng phÃ¡p giáº£i mÃ£ (vÃ­ dá»¥: cÃ³ thá»ƒ yÃªu cáº§u sáº¯p xáº¿p
cho nucleus sampling), háº¡n cháº¿ pháº§n cá»©ng, v.v. cÃ³ thá»ƒ giá»›i thiá»‡u má»™t sá»‘ sá»± khÃ¡c biá»‡t giá»¯a cháº¥m Ä‘iá»ƒm
vÃ  láº¥y máº«u. Tuy nhiÃªn, náº¿u cÃ¡c Ä‘iá»u kiá»‡n Ä‘Æ°á»£c Ä‘Ã¡p á»©ng sao cho cÃ¡c thÃ nh pháº§n trÃªn chiáº¿m Æ°u tháº¿ thÃ¬
cháº¥m Ä‘iá»ƒm khÃ´ng nÃªn cháº­m hÆ¡n Ä‘Ã¡ng ká»ƒ Ä‘á»‘i vá»›i ğ¾ nhá».

Láº¥y máº«u Tá»« chá»‘i ÄÆ°á»£c sá»­a Ä‘á»•i
ChÃºng tÃ´i yÃªu cáº§u má»™t phÆ°Æ¡ng phÃ¡p Ä‘á»ƒ khÃ´i phá»¥c phÃ¢n phá»‘i cá»§a mÃ´ hÃ¬nh Ä‘Ã­ch tá»« cÃ¡c máº«u tá»« mÃ´ hÃ¬nh
nhÃ¡p, vÃ  logit cá»§a cÃ¡c token Ä‘Ã³ tá»« cáº£ hai mÃ´ hÃ¬nh.

Äá»ƒ Ä‘áº¡t Ä‘Æ°á»£c Ä‘iá»u nÃ y, chÃºng tÃ´i giá»›i thiá»‡u sÆ¡ Ä‘á»“ láº¥y máº«u tá»« chá»‘i sau Ä‘Ã¢y cá»§a cÃ¡c token Ä‘Æ°á»£c soáº¡n tháº£o. Cho má»™t
chuá»—i token ğ‘¥1ğ‘¥ğ‘›, vÃ  ğ¾ token nhÃ¡p Ëœğ‘¥ğ‘›Â¸1 Ëœğ‘¥ğ‘›Â¸ğ¾ Ä‘Æ°á»£c táº¡o ra tá»« ğ‘Â¹jÂº, chÃºng ta cháº¥p nháº­n Ëœğ‘¥ğ‘›Â¸1
vá»›i xÃ¡c suáº¥t:

min(1, ğ‘Â¹Ëœğ‘¥ğ‘›Â¸1jğ‘¥1ğ‘¥ğ‘›Âº/ğ‘Â¹Ëœğ‘¥ğ‘›Â¸1jğ‘¥1ğ‘¥ğ‘›Âº)

Trong Ä‘Ã³ ğ‘Â¹Ëœğ‘¥ğ‘›Â¸1jğ‘¥1ğ‘¥ğ‘›Âº vÃ  ğ‘Â¹Ëœğ‘¥ğ‘›Â¸1jğ‘¥1ğ‘¥ğ‘›Âº lÃ  xÃ¡c suáº¥t cá»§a Ëœğ‘¥ğ‘›Â¸1 theo mÃ´ hÃ¬nh Ä‘Ã­ch vÃ 
nhÃ¡p tÆ°Æ¡ng á»©ng, cÃ³ Ä‘iá»u kiá»‡n trÃªn ngá»¯ cáº£nh cho Ä‘áº¿n nay.

Náº¿u token Ä‘Æ°á»£c cháº¥p nháº­n, chÃºng ta Ä‘áº·t ğ‘¥ğ‘›Â¸1 Ëœğ‘¥ğ‘›Â¸1 vÃ  láº·p láº¡i quÃ¡ trÃ¬nh cho Ëœğ‘¥ğ‘›Â¸2 cho Ä‘áº¿n khi má»™t token
bá»‹ tá»« chá»‘i hoáº·c táº¥t cáº£ cÃ¡c token Ä‘Ã£ Ä‘Æ°á»£c cháº¥p nháº­n.

Náº¿u Ëœğ‘¥ğ‘›Â¸1 bá»‹ tá»« chá»‘i, chÃºng ta láº¥y máº«u láº¡i ğ‘¥ğ‘›Â¸1 tá»« phÃ¢n phá»‘i sau:

ğ‘¥ğ‘›Â¸1Â¹ğ‘Â¹ğ‘¥jğ‘¥1ğ‘¥ğ‘›Âºğ‘Â¹ğ‘¥jğ‘¥1ğ‘¥ğ‘›ÂºÂºÂ¸

Trong Ä‘Ã³ Â¹ÂºÂ¸ biá»ƒu thá»‹:

Â¹ğ‘“Â¹ğ‘¥ÂºÂºÂ¸=maxÂ¹0 ğ‘“Â¹ğ‘¥ÂºÂºÃğ‘¥maxÂ¹0 ğ‘“Â¹ğ‘¥ÂºÂº

Báº±ng cÃ¡ch Ã¡p dá»¥ng Ä‘iá»u nÃ y má»™t cÃ¡ch tuáº§n tá»±, chÃºng ta khÃ´i phá»¥c phÃ¢n phá»‘i cá»§a mÃ´ hÃ¬nh Ä‘Ã­ch cho cÃ¡c token Ä‘Æ°á»£c cháº¥p nháº­n
(xem chá»©ng minh trong Äá»‹nh lÃ½ 1) trong pháº¡m vi sá»‘ há»c pháº§n cá»©ng. LÆ°u Ã½ ráº±ng:

--- TRANG 5 ---
TÄƒng tá»‘c Giáº£i mÃ£ MÃ´ hÃ¬nh NgÃ´n ngá»¯ Lá»›n vá»›i Láº¥y máº«u Suy Ä‘oÃ¡n

â€¢ Ãt nháº¥t má»™t token sáº½ luÃ´n Ä‘Æ°á»£c táº¡o ra tá»« má»™t vÃ²ng láº·p draft-accept â€“ náº¿u token Ä‘áº§u tiÃªn bá»‹
tá»« chá»‘i, má»™t token há»£p lá»‡ Ä‘Æ°á»£c láº¥y máº«u láº¡i.

â€¢ VÃ¬ token cuá»‘i cÃ¹ng cá»§a báº£n nhÃ¡p cho chÃºng ta logit cho token tiáº¿p theo, náº¿u má»i token Ä‘Æ°á»£c soáº¡n tháº£o Ä‘á»u
Ä‘Æ°á»£c cháº¥p nháº­n, chÃºng ta cÃ³ thá»ƒ láº¥y máº«u tá»« nÃ³ bÃ¬nh thÆ°á»ng. Äiá»u nÃ y cho chÃºng ta tá»‘i Ä‘a ğ¾Â¸1 token má»—i vÃ²ng láº·p,
so vá»›i viá»‡c triá»ƒn khai ngÃ¢y thÆ¡ chá»‰ tráº£ vá» ğ¾ token.

Vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p láº¥y máº«u tiÃªu chuáº©n nhÆ° nucleus, top-k sampling vÃ  Ä‘iá»u chá»‰nh nhiá»‡t Ä‘á»™, chÃºng ta
cÃ³ thá»ƒ sá»­a Ä‘á»•i xÃ¡c suáº¥t tÆ°Æ¡ng á»©ng trÆ°á»›c khi Ã¡p dá»¥ng sÆ¡ Ä‘á»“ láº¥y máº«u tá»« chá»‘i nÃ y. ChÃºng tÃ´i Ä‘Ã£
quan sÃ¡t tháº¥y ráº±ng tá»· lá»‡ cháº¥p nháº­n tá»•ng thá»ƒ máº¡nh máº½ Ä‘á»‘i vá»›i cÃ¡c tham sá»‘ cá»¥ thá»ƒ Ä‘Æ°á»£c sá»­ dá»¥ng.

VÃ¬ chÃºng ta khÃ´ng tÆ°Æ¡ng tÃ¡c vá»›i pháº§n thÃ¢n cá»§a chÃ­nh transformer, phÆ°Æ¡ng phÃ¡p nÃ y cÃ³ thá»ƒ Ä‘Æ°á»£c sá»­ dá»¥ng
káº¿t há»£p vá»›i nhiá»u ká»¹ thuáº­t khÃ¡c Ä‘á»ƒ tÄƒng tá»‘c hoáº·c tá»‘i Æ°u hÃ³a viá»‡c sá»­ dá»¥ng bá»™ nhá»› cá»§a láº¥y máº«u, nhÆ°
lÆ°á»£ng tá»­ hÃ³a vÃ  multi-query attention.

Lá»±a chá»n MÃ´ hÃ¬nh NhÃ¡p
VÃ¬ tiÃªu chÃ­ cháº¥p nháº­n Ä‘áº£m báº£o phÃ¢n phá»‘i cá»§a mÃ´ hÃ¬nh Ä‘Ã­ch trong cÃ¡c máº«u cá»§a chÃºng ta, chÃºng ta
tá»± do lá»±a chá»n phÆ°Æ¡ng phÃ¡p Ä‘á»ƒ soáº¡n tháº£o má»™t pháº§n tiáº¿p tá»¥c miá»…n lÃ  nÃ³ hiá»ƒn thá»‹ logit, vÃ  cÃ³
tá»· lá»‡ cháº¥p nháº­n Ä‘á»§ cao vÃ /hoáº·c Ä‘á»™ trá»… Ä‘á»§ tháº¥p Ä‘á»ƒ hÃ²a vá»‘n. CÃ³ má»™t sá»‘ cÃ¡ch tiáº¿p cáº­n
á»Ÿ Ä‘Ã¢y:

â€¢ Káº¿t há»£p viá»‡c táº¡o báº£n nhÃ¡p vÃ o mÃ´ hÃ¬nh Ä‘Ã­ch, vÃ  huáº¥n luyá»‡n mÃ´ hÃ¬nh tá»« Ä‘áº§u. ÄÃ¢y
lÃ  chiáº¿n lÆ°á»£c Ä‘Æ°á»£c sá»­ dá»¥ng bá»Ÿi Stern et al. (2018), thÃªm nhiá»u Ä‘áº§u vÃ o transformer Ä‘á»ƒ
táº¡o ra nhiá»u token.

â€¢ Sá»­ dá»¥ng chÆ°ng cáº¥t cáº¥p Ä‘á»™ chuá»—i (Kim vÃ  Rush, 2016) Ä‘á»ƒ táº¡o ra má»™t mÃ´ hÃ¬nh thá»© hai
dá»± Ä‘oÃ¡n ğ¾ token song song. Chiáº¿n lÆ°á»£c nÃ y Ä‘Æ°á»£c sá»­ dá»¥ng bá»Ÿi Ge et al. (2022).

â€¢ Äáº·t má»™t pháº§n cá»§a cÃ¡c activation cá»§a mÃ´ hÃ¬nh Ä‘Ã­ch lÃ m Ä‘áº§u vÃ o cho mÃ´ hÃ¬nh nhÃ¡p, vÃ  huáº¥n luyá»‡n
mÃ´ hÃ¬nh nhÃ¡p vá»›i Ä‘áº§u vÃ o nÃ y.

Máº·c dÃ¹ nhá»¯ng phÆ°Æ¡ng phÃ¡p nÃ y cÃ³ thá»ƒ sáº½ táº¡o ra cÃ¡c báº£n nhÃ¡p máº¡nh máº½, chÃºng Ä‘Ã²i há»i má»™t sá»‘ lÆ°á»£ng lá»›n dá»¯ liá»‡u Ä‘Æ°á»£c táº¡o
ra tá»« mÃ´ hÃ¬nh Ä‘Ã­ch hoáº·c thay Ä‘á»•i Ä‘á»‘i vá»›i mÃ´ hÃ¬nh Ä‘Ã­ch. ChÆ°ng cáº¥t cáº¥p Ä‘á»™ chuá»—i Ä‘áº·c biá»‡t
sáº½ yÃªu cáº§u má»™t ngÃ¢n sÃ¡ch tÃ­nh toÃ¡n lá»›n. Äiá»u nÃ y lÃ m cho chÃºng Ã­t thá»±c táº¿ hÆ¡n cho cÃ¡c á»©ng dá»¥ng quy mÃ´ lá»›n.

Trong khi cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n táº¡o ra cÃ¡c máº«u tá»‘t hÆ¡n, trá»±c quan cÃ³ nhá»¯ng token "dá»… hÆ¡n" Ä‘á»ƒ dá»± Ä‘oÃ¡n
mÃ  cÃ¡c mÃ´ hÃ¬nh nhá» hÆ¡n cÃ³ thá»ƒ Ä‘á»§. Do Ä‘Ã³ chÃºng ta cÃ³ thá»ƒ Ä‘Æ¡n giáº£n sá»­ dá»¥ng má»™t phiÃªn báº£n nhá» hÆ¡n cá»§a
mÃ´ hÃ¬nh ngÃ´n ngá»¯ Ä‘Ã­ch lÃ m báº£n nhÃ¡p vÃ  Ä‘áº¡t Ä‘Æ°á»£c tá»· lá»‡ cháº¥p nháº­n cao. Äiá»u nÃ y cÅ©ng sáº½ thuáº­n tiá»‡n
tá»« gÃ³c Ä‘á»™ ká»¹ thuáº­t vÃ  quy trÃ¬nh lÃ m viá»‡c, vÃ¬ cÃ´ng cá»¥ máº¡nh máº½ cho nhá»¯ng mÃ´ hÃ¬nh nhÆ° váº­y Ä‘Ã£ cÃ³ sáºµn
Ä‘á»ƒ huáº¥n luyá»‡n mÃ´ hÃ¬nh Ä‘Ã­ch ngay tá»« Ä‘áº§u.

Káº¿t quáº£
ChÃºng tÃ´i huáº¥n luyá»‡n má»™t mÃ´ hÃ¬nh nhÃ¡p 4 tá»· tham sá»‘ Ä‘Æ°á»£c tá»‘i Æ°u hÃ³a cho Ä‘á»™ trá»… láº¥y máº«u trÃªn 16 TPU v4s â€“ cÃ¹ng
pháº§n cá»©ng thÆ°á»ng Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ phá»¥c vá»¥ Chinchilla cho má»¥c Ä‘Ã­ch nghiÃªn cá»©u. MÃ´ hÃ¬nh nÃ y Ä‘Æ°á»£c huáº¥n luyá»‡n
vá»›i cÃ¹ng tokenizer vÃ  bá»™ dá»¯ liá»‡u nhÆ° Chinchilla, vá»›i chiá»u rá»™ng nhá» hÆ¡n má»™t chÃºt vÃ  chá»‰ cÃ³ 8
lá»›p. Sá»‘ lÆ°á»£ng lá»›p tÆ°Æ¡ng Ä‘á»‘i Ã­t cho phÃ©p nÃ³ Ä‘áº¡t Ä‘Æ°á»£c tá»‘c Ä‘á»™ láº¥y máº«u 1.8ms/token
so vá»›i 14.1ms/token cá»§a Chinchilla. Äá»ƒ biáº¿t chi tiáº¿t, vui lÃ²ng tham kháº£o cÃ¡c siÃªu tham sá»‘ trong Báº£ng 2.

Äá»‘i vá»›i thiáº¿t láº­p phÃ¢n tÃ¡n, viá»‡c chá»n ngÃ¢y thÆ¡ má»™t mÃ´ hÃ¬nh nhá» lÃ m báº£n nhÃ¡p lÃ  khÃ´ng Ä‘á»§, vÃ¬ cÃ¡c
mÃ´ hÃ¬nh khÃ¡c nhau cÃ³ thiáº¿t láº­p suy luáº­n tá»‘i Æ°u khÃ¡c nhau. VÃ­ dá»¥, thÃ´ng thÆ°á»ng phá»¥c vá»¥ Chinchilla 70B

--- TRANG 6 ---
TÄƒng tá»‘c Giáº£i mÃ£ MÃ´ hÃ¬nh NgÃ´n ngá»¯ Lá»›n vá»›i Láº¥y máº«u Suy Ä‘oÃ¡n

Báº£ng 1 | Hiá»‡u suáº¥t vÃ  tá»‘c Ä‘á»™ cá»§a Chinchilla trÃªn XSum vÃ  HumanEval vá»›i láº¥y máº«u ngÃ¢y thÆ¡ vÃ  suy Ä‘oÃ¡n
á»Ÿ kÃ­ch thÆ°á»›c batch 1 vÃ  ğ¾=4. XSum Ä‘Æ°á»£c thá»±c hiá»‡n vá»›i tham sá»‘ nucleus ğ‘=0.8, vÃ 
HumanEval vá»›i ğ‘=0.95 vÃ  nhiá»‡t Ä‘á»™ 0.8.

PhÆ°Æ¡ng phÃ¡p Láº¥y máº«u | Benchmark | Káº¿t quáº£ | Thá»i gian Token Trung bÃ¬nh | TÄƒng tá»‘c
ArS (Nucleus) | XSum (ROUGE-2) | 0.112 | 14.1ms/Token | 1Ã—
SpS (Nucleus) | | 0.114 | 7.52ms/Token | 1.92Ã—
ArS (Greedy) | XSum (ROUGE-2) | 0.157 | 14.1ms/Token | 1Ã—
SpS (Greedy) | | 0.156 | 7.00ms/Token | 2.01Ã—
ArS (Nucleus) | HumanEval (100 Shot) | 45.1% | 14.1ms/Token | 1Ã—
SpS (Nucleus) | | 47.0% | 5.73ms/Token | 2.46Ã—

trÃªn 16 TPU v4s (nÆ¡i nÃ³ Ä‘áº¡t Ä‘Æ°á»£c 14.1ms/token Ä‘Ã£ nÃªu), trong khi chinchilla-optimal
7B Ä‘áº¡t Ä‘Æ°á»£c Ä‘á»™ trá»… láº¥y máº«u tháº¥p nháº¥t trÃªn 4 TPU v4s (nÆ¡i nÃ³ Ä‘áº¡t Ä‘Æ°á»£c 5ms/token). Äá»‘i vá»›i cÃ¡c
mÃ´ hÃ¬nh nhá» hÆ¡n, bÄƒng thÃ´ng bá»™ nhá»› vÃ  flops bá»• sung khÃ´ng Ä‘á»§ Ä‘á»ƒ bÃ¹ Ä‘áº¯p chi phÃ­ truyá»n thÃ´ng
bá»• sung giá»¯a nhiá»u thiáº¿t bá»‹ hÆ¡n â€“ phá»¥c vá»¥ 7B trÃªn 16 TPU thá»±c sá»± tÄƒng Ä‘á»™ trá»…. Äiá»u nÃ y
cÃ³ nghÄ©a lÃ  7B sáº½ chá»‰ cung cáº¥p tÄƒng tá»‘c khiÃªm tá»‘n náº¿u Ä‘Æ°á»£c sá»­ dá»¥ng lÃ m báº£n nhÃ¡p vá»›i topo tá»‘i Æ°u cá»§a nÃ³, vÃ 
chÃºng ta sáº½ khÃ´ng táº­n dá»¥ng Ä‘áº§y Ä‘á»§ pháº§n cá»©ng trong quÃ¡ trÃ¬nh soáº¡n tháº£o.

ChÃºng ta cÃ³ thá»ƒ trÃ¡nh váº¥n Ä‘á» nÃ y báº±ng cÃ¡ch huáº¥n luyá»‡n má»™t mÃ´ hÃ¬nh rá»™ng hÆ¡n vá»›i sá»‘ lÆ°á»£ng lá»›p tÆ°Æ¡ng Ä‘á»‘i Ã­t
Ä‘á»ƒ giáº£m thiá»ƒu chi phÃ­ truyá»n thÃ´ng. ÄÃ£ Ä‘Æ°á»£c quan sÃ¡t tháº¥y ráº±ng hiá»‡u suáº¥t cá»§a cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯
tÆ°Æ¡ng Ä‘á»‘i máº¡nh máº½ Ä‘á»‘i vá»›i nhá»¯ng thay Ä‘á»•i trong tá»· lá»‡ khung hÃ¬nh mÃ´ hÃ¬nh (Levine et al., 2020), vÃ¬ váº­y Ä‘iá»u nÃ y cho phÃ©p chÃºng ta
phá»¥c vá»¥ má»™t mÃ´ hÃ¬nh nhÃ¡p máº¡nh máº½ cÃ³ thá»ƒ Ä‘Æ°á»£c láº¥y máº«u nhanh chÃ³ng trÃªn cÃ¹ng pháº§n cá»©ng vá»›i mÃ´ hÃ¬nh Ä‘Ã­ch.

ÄÃ¡nh giÃ¡ trÃªn XSum vÃ  HumanEval
ChÃºng tÃ´i Ä‘Ã¡nh giÃ¡ láº¥y máº«u suy Ä‘oÃ¡n vá»›i Chinchilla trÃªn hai tÃ¡c vá»¥ vÃ  tÃ³m táº¯t káº¿t quáº£ trong Báº£ng 1:

â€¢ Benchmark XSum (Narayan et al., 2018). ÄÃ¢y lÃ  má»™t tÃ¡c vá»¥ tÃ³m táº¯t ngÃ´n ngá»¯ tá»± nhiÃªn
sá»­ dá»¥ng prompt 1-shot nÆ¡i chÃºng tÃ´i láº¥y máº«u tá»•ng cá»™ng 11.305 chuá»—i vá»›i Ä‘á»™ dÃ i chuá»—i tá»‘i Ä‘a 128.

â€¢ TÃ¡c vá»¥ HumanEval 100-shot (Chen et al., 2021). ÄÃ¢y lÃ  má»™t tÃ¡c vá»¥ táº¡o mÃ£ liÃªn quan Ä‘áº¿n viá»‡c
táº¡o ra 16.400 máº«u vá»›i Ä‘á»™ dÃ i chuá»—i tá»‘i Ä‘a 512.

Ngay cáº£ vá»›i láº¥y máº«u tham lam, má»™t token duy nháº¥t lá»‡ch do sá»‘ há»c cÃ³ thá»ƒ dáº«n Ä‘áº¿n hai chuá»—i
phÃ¢n ká»³ máº¡nh máº½. VÃ¬ cÃ¡c háº¡t giá»‘ng giáº£ ngáº«u nhiÃªn Ä‘Æ°á»£c xá»­ lÃ½ khÃ¡c nhau giá»¯a ArS vÃ  SpS, vÃ 
vÃ¬ cÃ¡c Ä‘á»“ thá»‹ tÃ­nh toÃ¡n khÃ¡c nhau dáº«n Ä‘áº¿n sá»‘ há»c khÃ¡c nhau, chÃºng ta khÃ´ng thá»ƒ mong Ä‘á»£i Ä‘áº§u ra
giá»‘ng há»‡t nhau. Tuy nhiÃªn, chÃºng ta mong Ä‘á»£i cÃ¡c máº«u Ä‘áº¿n tá»« cÃ¹ng má»™t phÃ¢n phá»‘i trong pháº¡m vi sá»‘ há»c vÃ 
chÃºng tÃ´i xÃ¡c minh Ä‘iá»u nÃ y theo kinh nghiá»‡m báº±ng cÃ¡ch Ä‘Ã¡nh giÃ¡ nhá»¯ng benchmark nÃ y.

ChÃºng tÃ´i cháº¡y cÃ¡c tÃ¡c vá»¥ á»Ÿ kÃ­ch thÆ°á»›c batch 1 vá»›i SpS vÃ  ArS. Thá»i gian thá»±c hiá»‡n má»—i vÃ²ng láº·p SpS/ArS cÃ³
phÆ°Æ¡ng sai tháº¥p, vÃ  chÃºng ta cÃ³ thá»ƒ Ä‘o trá»±c tiáº¿p tá»« há»“ sÆ¡ TPU. Äá»ƒ cÃ³ Ä‘Æ°á»£c tÄƒng tá»‘c trung bÃ¬nh, Ä‘á»™ lá»‡ch
chuáº©n vÃ  cÃ¡c chá»‰ sá»‘ khÃ¡c, chÃºng tÃ´i ghi láº¡i sá»‘ lÆ°á»£ng token Ä‘Æ°á»£c táº¡o ra cho má»—i vÃ²ng láº·p suy Ä‘oÃ¡n. Trong
Báº£ng 1 chÃºng tÃ´i hiá»ƒn thá»‹ hiá»‡u suáº¥t trÃªn benchmark XSum vÃ  HumanEval cho láº¥y máº«u ngÃ¢y thÆ¡ vÃ  suy Ä‘oÃ¡n
vá»›i Chinchilla.

--- TRANG 7 ---
TÄƒng tá»‘c Giáº£i mÃ£ MÃ´ hÃ¬nh NgÃ´n ngá»¯ Lá»›n vá»›i Láº¥y máº«u Suy Ä‘oÃ¡n

ChÃºng tÃ´i Ä‘áº¡t Ä‘Æ°á»£c tÄƒng tá»‘c Ä‘Ã¡ng ká»ƒ trong cáº£ hai tÃ¡c vá»¥, vá»›i HumanEval Ä‘áº¡t tÄƒng tá»‘c gáº§n 2.5Ã—.
Tuy nhiÃªn, chÃºng tÃ´i cÃ³ sá»± ngang báº±ng trong cÃ¡c chá»‰ sá»‘ benchmark â€“ phÃ¢n phá»‘i máº«u cÆ¡ báº£n cÃ³ thá»ƒ chá»©ng minh lÃ 
giá»‘ng nhau Ä‘áº¿n má»©c sá»‘ há»c, vÃ  Ä‘iá»u nÃ y xÃ¡c minh ráº±ng mÃ´ hÃ¬nh nhÃ¡p khÃ´ng lÃ m thiÃªn lá»‡ch káº¿t quáº£ theo kinh nghiá»‡m. Trong
trÆ°á»ng há»£p cá»§a HumanEval vÃ  XSum tham lam, tÄƒng tá»‘c nÃ y vÆ°á»£t quÃ¡ giá»›i háº¡n bÄƒng thÃ´ng bá»™ nhá»› lÃ½ thuyáº¿t
cá»§a pháº§n cá»©ng cho láº¥y máº«u tá»± há»“i quy (kÃ­ch thÆ°á»›c mÃ´ hÃ¬nh chia cho tá»•ng bÄƒng thÃ´ng bá»™ nhá»›).

Tá»· lá»‡ cháº¥p nháº­n thay Ä‘á»•i theo miá»n
RÃµ rÃ ng ráº±ng tá»· lá»‡ cháº¥p nháº­n phá»¥ thuá»™c vÃ o á»©ng dá»¥ng vÃ  phÆ°Æ¡ng phÃ¡p giáº£i mÃ£.
HumanEval Ä‘áº¡t Ä‘Æ°á»£c tÄƒng tá»‘c lá»›n hÆ¡n Ä‘Ã¡ng ká»ƒâ€”ChÃºng tÃ´i Ä‘Æ°a ra giáº£ thuyáº¿t ráº±ng Ä‘iá»u nÃ y lÃ  do sá»± káº¿t há»£p
cá»§a mÃ£ chá»©a nhiá»u chuá»—i con phá»• biáº¿n (vÃ­ dá»¥: for i in range(len(arr)): sáº½
tÆ°Æ¡ng Ä‘á»‘i dá»… cho má»™t mÃ´ hÃ¬nh nhÃ¡p Ä‘oÃ¡n), thÆ°á»ng Ä‘Æ°á»£c phÃ¢n tÃ¡ch thÃ nh má»™t táº­p há»£p nhá» hÆ¡n cÃ¡c token ngáº¯n hÆ¡n
vÃ  giÃ¡ trá»‹ nhiá»‡t Ä‘á»™ lÃ m sáº¯c nÃ©t cáº£ logit nhÃ¡p vÃ  Ä‘Ã­ch.

[HÃ¬nh 1: Ba biá»ƒu Ä‘á»“ hiá»ƒn thá»‹ má»‘i quan há»‡ giá»¯a sá»‘ lÆ°á»£ng token nhÃ¡p (K) vÃ  thá»i gian láº¥y máº«u trung bÃ¬nh, tá»· lá»‡ cháº¥p nháº­n, vÃ  thá»i gian vÃ²ng láº·p tá»•ng]

HÃ¬nh 1 | TrÃ¡i: Thá»i gian trung bÃ¬nh Ä‘á»ƒ táº¡o 128 token, vá»›i Ä‘á»™ lá»‡ch chuáº©n. LÆ°u Ã½ ráº±ng khi ğ¾
tÄƒng, tÄƒng tá»‘c tá»•ng thá»ƒ Ä‘áº¡t Ä‘á»‰nh hoáº·c tháº­m chÃ­ thoÃ¡i lui, vá»›i XSum tá»‘i Æ°u á»Ÿ ğ¾=3. PhÆ°Æ¡ng sai
tÄƒng nháº¥t quÃ¡n vá»›i ğ¾. Giá»¯a: Sá»‘ lÆ°á»£ng token Ä‘Æ°á»£c cháº¥p nháº­n trung bÃ¬nh chia cho
ğ¾Â¸1â€“ Ä‘iá»u nÃ y phá»¥c vá»¥ nhÆ° má»™t thÆ°á»›c Ä‘o hiá»‡u quáº£ tá»•ng thá»ƒ cá»§a sÆ¡ Ä‘á»“ tá»« chá»‘i Ä‘Æ°á»£c sá»­a Ä‘á»•i, giáº£m
vá»›i lookahead. Pháº£i: Thá»i gian trung bÃ¬nh má»—i vÃ²ng láº·p tÄƒng xáº¥p xá»‰ tuyáº¿n tÃ­nh vá»›i ğ¾
do sá»‘ lÆ°á»£ng lá»i gá»i mÃ´ hÃ¬nh tÄƒng. LÆ°u Ã½ ráº±ng gradient hÆ¡i cao hÆ¡n tá»‘c Ä‘á»™ láº¥y máº«u
cá»§a mÃ´ hÃ¬nh nhÃ¡p, do chi phÃ­ bá»• sung trong nucleus decoding.

ÄÃ¡nh Ä‘á»•i giá»¯a báº£n nhÃ¡p dÃ i hÆ¡n vÃ  cháº¥m Ä‘iá»ƒm thÆ°á»ng xuyÃªn hÆ¡n
ChÃºng tÃ´i hÃ¬nh dung sá»± Ä‘Ã¡nh Ä‘á»•i cá»§a viá»‡c tÄƒng ğ¾, sá»‘ lÆ°á»£ng token Ä‘Æ°á»£c láº¥y máº«u bá»Ÿi mÃ´ hÃ¬nh nhÃ¡p trong HÃ¬nh 1.
Khi ğ¾ tÄƒng, chÃºng ta cáº§n Ã­t lá»i gá»i cháº¥m Ä‘iá»ƒm hÆ¡n tá»« cÃ¡c mÃ´ hÃ¬nh lá»›n Ä‘á»ƒ táº¡o ra cÃ¹ng Ä‘á»™ dÃ i
chuá»—i, cÃ³ kháº£ nÄƒng cho chÃºng ta tÄƒng tá»‘c lá»›n hÆ¡n. Tuy nhiÃªn, tá»•ng thá»i gian vÃ²ng láº·p tÄƒng xáº¥p xá»‰
tuyáº¿n tÃ­nh vá»›i sá»‘ lÆ°á»£ng lá»i gá»i mÃ´ hÃ¬nh nhÃ¡p lá»›n hÆ¡n vÃ  tÄƒng nhá» trong thá»i gian cháº¥m Ä‘iá»ƒm. Hiá»‡u quáº£
tá»•ng thá»ƒ cá»§a tá»· lá»‡ token Ä‘Æ°á»£c cháº¥p nháº­n giáº£m khi ğ¾ tÄƒng, vÃ¬ cÃ¡c token sau phá»¥ thuá»™c
vÃ o viá»‡c cháº¥p nháº­n cÃ¡c token trÆ°á»›c Ä‘Ã³. Äiá»u nÃ y dáº«n Ä‘áº¿n tÄƒng tá»‘c trung bÃ¬nh Ä‘áº¡t Ä‘á»‰nh hoáº·c
tháº­m chÃ­ thoÃ¡i hÃ³a vá»›i ğ¾ lá»›n hÆ¡n (vÃ­ dá»¥, Ä‘á»™ trá»… nucleus cá»§a XSum Ä‘Æ°á»£c giáº£m thiá»ƒu á»Ÿ ğ¾=3),
tÃ¹y thuá»™c vÃ o miá»n.

--- TRANG 8 ---
TÄƒng tá»‘c Giáº£i mÃ£ MÃ´ hÃ¬nh NgÃ´n ngá»¯ Lá»›n vá»›i Láº¥y máº«u Suy Ä‘oÃ¡n

HÆ¡n ná»¯a, máº·c dÃ¹ cÃ¡c giÃ¡ trá»‹ ğ¾ lá»›n hÆ¡n cÃ³ thá»ƒ mang láº¡i tÄƒng tá»‘c trung bÃ¬nh lá»›n hÆ¡n má»™t chÃºt trong má»™t sá»‘
trÆ°á»ng há»£p, nÃ³ cÅ©ng tÄƒng phÆ°Æ¡ng sai cá»§a thá»i gian Ä‘á»ƒ táº¡o ra má»™t chuá»—i Ä‘áº§y Ä‘á»§. Äiá»u nÃ y cÃ³ thá»ƒ
cÃ³ váº¥n Ä‘á» Ä‘á»‘i vá»›i cÃ¡c thiáº¿t láº­p nÆ¡i Ä‘á»™ trá»… P90, P99 quan trá»ng.

Káº¿t luáº­n
Trong cÃ´ng trÃ¬nh nÃ y, chÃºng tÃ´i trÃ¬nh bÃ y má»™t thuáº­t toÃ¡n vÃ  quy trÃ¬nh lÃ m viá»‡c má»›i Ä‘á»ƒ tÄƒng tá»‘c giáº£i mÃ£ cá»§a cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯.
Láº¥y máº«u suy Ä‘oÃ¡n khÃ´ng yÃªu cáº§u thá»±c hiá»‡n báº¥t ká»³ sá»­a Ä‘á»•i nÃ o Ä‘á»‘i vá»›i cÃ¡c tham sá»‘ hoáº·c kiáº¿n trÃºc cá»§a mÃ´ hÃ¬nh ngÃ´n ngá»¯
Ä‘Ã­ch, khÃ´ng máº¥t mÃ¡t cÃ³ thá»ƒ chá»©ng minh Ä‘Æ°á»£c trong pháº¡m vi sá»‘ há»c, má»Ÿ rá»™ng quy mÃ´ tá»‘t vá»›i mÃ´ hÃ¬nh
nhÃ¡p phÃ¹ há»£p vÃ  bá»• sung cho nhiá»u ká»¹ thuáº­t hiá»‡n cÃ³ Ä‘á»ƒ giáº£m Ä‘á»™ trá»… trong thiáº¿t láº­p kÃ­ch thÆ°á»›c batch nhá».

ChÃºng tÃ´i tá»‘i Æ°u hÃ³a vÃ  má»Ÿ rá»™ng quy mÃ´ ká»¹ thuáº­t cho Chinchilla 70B sá»­ dá»¥ng má»™t mÃ´ hÃ¬nh nhÃ¡p dá»…
huáº¥n luyá»‡n vá»›i cÆ¡ sá»Ÿ háº¡ táº§ng hiá»‡n cÃ³, chá»©ng minh ráº±ng nÃ³ mang láº¡i tÄƒng tá»‘c lá»›n trÃªn cÃ¡c tÃ¡c vá»¥ benchmark
vÃ  cÃ¡c phÆ°Æ¡ng phÃ¡p giáº£i mÃ£ phá»• biáº¿n trong quÃ¡ trÃ¬nh nÃ y. ChÃºng tÃ´i xÃ¡c minh ráº±ng nÃ³ thá»±c sá»± khÃ´ng máº¥t mÃ¡t theo kinh nghiá»‡m trong
cÃ¡c tÃ¡c vá»¥ downstream cá»§a nÃ³.

TÃ i liá»‡u Tham kháº£o
A. Arnab, M. Dehghani, G. Heigold, C. Sun, M. Lucic, vÃ  C. Schmid. Vivit: Má»™t vision transformer video.
Trong 2021 IEEE/CVF International Conference on Computer Vision (ICCV), trang 6816â€“6826. IEEE
Computer Society, 2021.

T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam,
G. Sastry, A. Askell, et al. CÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lÃ  nhá»¯ng ngÆ°á»i há»c few-shot. Advances in neural information
processing systems, 33:1877â€“1901, 2020.

M. Chen, J. Tworek, H. Jun, Q. Yuan, H. P. de Oliveira Pinto, J. Kaplan, H. Edwards, Y. Burda, N. Joseph,
G. Brockman, A. Ray, R. Puri, G. Krueger, M. Petrov, H. Khlaaf, G. Sastry, P. Mishkin, B. Chan, S. Gray,
N. Ryder, M. Pavlov, A. Power, L. Kaiser, M. Bavarian, C. Winter, P. Tillet, F. P. Such, D. Cummings,
M. Plappert, F. Chantzis, E. Barnes, A. Herbert-Voss, W. H. Guss, A. Nichol, A. Paino, N. Tezak, J. Tang,
I. Babuschkin, S. Balaji, S. Jain, W. Saunders, C. Hesse, A. N. Carr, J. Leike, J. Achiam, V. Misra,
E. Morikawa, A. Radford, M. Knight, M. Brundage, M. Murati, K. Mayer, P. Welinder, B. McGrew,
D. Amodei, S. McCandlish, I. Sutskever, vÃ  W. Zaremba. ÄÃ¡nh giÃ¡ cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n Ä‘Æ°á»£c huáº¥n luyá»‡n
trÃªn mÃ£. CoRR, abs/2107.03374, 2021. URL https://arxiv.org/abs/2107.03374.

A. Chowdhery, S. Narang, J. Devlin, M. Bosma, G. Mishra, A. Roberts, P. Barham, H. W. Chung,
C. Sutton, S. Gehrmann, et al. Palm: Má»Ÿ rá»™ng quy mÃ´ mÃ´ hÃ¬nh hÃ³a ngÃ´n ngá»¯ vá»›i pathways. arXiv preprint
arXiv:2204.02311, 2022.

T. Dettmers, M. Lewis, Y. Belkada, vÃ  L. Zettlemoyer. Llm.int8(): NhÃ¢n ma tráº­n 8-bit cho
transformers á»Ÿ quy mÃ´ lá»›n. arXiv preprint arXiv:2208.07339, 2022.

A. Dosovitskiy, L. Beyer, A. Kolesnikov, D. Weissenborn, X. Zhai, T. Unterthiner, M. Dehghani, M. Minderer, G. Heigold, S. Gelly, et al. Má»™t hÃ¬nh áº£nh Ä‘Ã¡ng giÃ¡ 16x16 tá»«: Transformers cho nháº­n dáº¡ng hÃ¬nh áº£nh
á»Ÿ quy mÃ´ lá»›n. arXiv preprint arXiv:2010.11929, 2020.

T. Ge, H. Xia, X. Sun, S. Chen, vÃ  F. Wei. TÄƒng tá»‘c khÃ´ng máº¥t mÃ¡t cho táº¡o seq2seq vá»›i giáº£i mÃ£
tÃ­ch cá»±c. ArXiv, abs/2205.10350, 2022.

--- TRANG 9 ---
TÄƒng tá»‘c Giáº£i mÃ£ MÃ´ hÃ¬nh NgÃ´n ngá»¯ Lá»›n vá»›i Láº¥y máº«u Suy Ä‘oÃ¡n

J. Hoï¬€mann, S. Borgeaud, A. Mensch, E. Buchatskaya, T. Cai, E. Rutherford, D. d. L. Casas, L. A.
Hendricks, J. Welbl, A. Clark, et al. Huáº¥n luyá»‡n cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n tá»‘i Æ°u tÃ­nh toÃ¡n. arXiv preprint
arXiv:2203.15556, 2022.

X. Jiao, Y. Yin, L. Shang, X. Jiang, X. Chen, L. Li, F. Wang, vÃ  Q. Liu. TinyBERT: ChÆ°ng cáº¥t BERT
cho hiá»ƒu biáº¿t ngÃ´n ngá»¯ tá»± nhiÃªn. Trong Findings of the Association for Computational Linguistics: EMNLP 2020, trang 4163â€“4174, Online, Nov. 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.ï¬ndings-emnlp.372. URL https://aclanthology.org/2020.findings-emnlp.372.

Y. Kim vÃ  A. M. Rush. ChÆ°ng cáº¥t kiáº¿n thá»©c cáº¥p Ä‘á»™ chuá»—i. CoRR, abs/1606.07947, 2016. URL
http://arxiv.org/abs/1606.07947.

Y. Leviathan, M. Kalman, vÃ  Y. Matias. Suy luáº­n nhanh tá»« transformers qua giáº£i mÃ£ suy Ä‘oÃ¡n.
ArXiv, abs/2211.17192, 2022.

Y. Levine, N. Wies, O. Sharir, H. Bata, vÃ  A. Shashua. Sá»± tÆ°Æ¡ng tÃ¡c Ä‘á»™ sÃ¢u-chiá»u rá»™ng trong self-attention.
arXiv preprint arXiv:2006.12467, 2020.

S. Narayan, S. B. Cohen, vÃ  M. Lapata. Äá»«ng cho tÃ´i chi tiáº¿t, chá»‰ cáº§n tÃ³m táº¯t! máº¡ng nÆ¡-ron tÃ­ch cháº­p
nháº­n biáº¿t chá»§ Ä‘á» cho tÃ³m táº¯t cá»±c Ä‘oan. Trong Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, trang 1797â€“1807, Brussels, Belgium, Oct.-Nov. 2018. Association for Computational Linguistics. doi: 10.18653/v1/D18-1206. URL https://aclanthology.org/D18-1206.

R. Pope, S. Douglas, A. Chowdhery, J. Devlin, J. Bradbury, A. Levskaya, J. Heek, K. Xiao, S. Agrawal,
vÃ  J. Dean. Má»Ÿ rá»™ng quy mÃ´ suy luáº­n transformer hiá»‡u quáº£. arXiv preprint arXiv:2211.05102, 2022.

J. W. Rae, S. Borgeaud, T. Cai, K. Millican, J. Hoï¬€mann, F. Song, J. Aslanides, S. Henderson, R. Ring,
S. Young, et al. Má»Ÿ rá»™ng quy mÃ´ cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯: PhÆ°Æ¡ng phÃ¡p, phÃ¢n tÃ­ch & hiá»ƒu biáº¿t tá»« viá»‡c huáº¥n luyá»‡n gopher. arXiv
preprint arXiv:2112.11446, 2021.

V. Sanh, L. Debut, J. Chaumond, vÃ  T. Wolf. Distilbert, má»™t phiÃªn báº£n chÆ°ng cáº¥t cá»§a bert: nhá» hÆ¡n, nhanh hÆ¡n,
ráº» hÆ¡n vÃ  nháº¹ hÆ¡n. arXiv preprint arXiv:1910.01108, 2019.

N. Shazeer. Giáº£i mÃ£ transformer nhanh: Má»™t write-head lÃ  táº¥t cáº£ nhá»¯ng gÃ¬ báº¡n cáº§n. CoRR, abs/1911.02150, 2019.
URL http://arxiv.org/abs/1911.02150.

M. Shoeybi, M. Patwary, R. Puri, P. LeGresley, J. Casper, vÃ  B. Catanzaro. Megatron-lm: Huáº¥n luyá»‡n
cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ multi-billion tham sá»‘ sá»­ dá»¥ng song song hÃ³a mÃ´ hÃ¬nh. arXiv preprint arXiv:1909.08053,
2019.

Y. Song, C. Meng, R. Liao, vÃ  S. Ermon. TÄƒng tá»‘c tÃ­nh toÃ¡n feedforward qua giáº£i
phÆ°Æ¡ng trÃ¬nh phi tuyáº¿n song song. Trong M. Meila vÃ  T. Zhang, editors, Proceedings of the 38th International Conference
on Machine Learning, volume 139 of Proceedings of Machine Learning Research, trang 9791â€“9800.
PMLR, 18â€“24 Jul 2021. URL https://proceedings.mlr.press/v139/song21a.html.

M. Stern, N. Shazeer, vÃ  J. Uszkoreit. Giáº£i mÃ£ song song theo khá»‘i cho cÃ¡c mÃ´ hÃ¬nh tá»± há»“i quy sÃ¢u.
CoRR, abs/1811.03115, 2018. URL http://arxiv.org/abs/1811.03115.

A. Wiggers vÃ  E. Hoogeboom. Láº¥y máº«u dá»± Ä‘oÃ¡n vá»›i cÃ¡c mÃ´ hÃ¬nh tá»± há»“i quy dá»± bÃ¡o. Trong H. D.
III vÃ  A. Singh, editors, Proceedings of the 37th International Conference on Machine Learning,
volume 119 of Proceedings of Machine Learning Research, trang 10260â€“10269. PMLR, 13â€“18 Jul
2020. URL https://proceedings.mlr.press/v119/wiggers20a.html.

--- TRANG 10 ---
TÄƒng tá»‘c Giáº£i mÃ£ MÃ´ hÃ¬nh NgÃ´n ngá»¯ Lá»›n vá»›i Láº¥y máº«u Suy Ä‘oÃ¡n

Z. Yao, R. Y. Aminabadi, M. Zhang, X. Wu, C. Li, vÃ  Y. He. Zeroquant: LÆ°á»£ng tá»­ hÃ³a sau huáº¥n luyá»‡n
hiá»‡u quáº£ vÃ  cÃ³ thá»ƒ chi tráº£ cho cÃ¡c transformer quy mÃ´ lá»›n. arXiv preprint arXiv:2206.01861, 2022.

TÃ i liá»‡u Bá»• sung

ÄÃ³ng gÃ³p cá»§a TÃ¡c giáº£
â€¢ Äá» xuáº¥t ban Ä‘áº§u: Charlie Chen, John Jumper vÃ  Geoï¬€rey Irving
â€¢ Triá»ƒn khai, Tá»‘i Æ°u hÃ³a vÃ  Má»Ÿ rá»™ng quy mÃ´ ban Ä‘áº§u: Charlie Chen
â€¢ SÆ¡ Ä‘á»“ Láº¥y máº«u Tá»« chá»‘i ÄÆ°á»£c sá»­a Ä‘á»•i: John Jumper
â€¢ Cáº£i tiáº¿n Ká»¹ thuáº­t: Jean-Baptiste Lespiau vÃ  Charlie Chen
â€¢ ThÃ­ nghiá»‡m: Charlie Chen, Sebastian Borgeaud vÃ  Laurent Sifre
â€¢ Báº£n tháº£o Báº£n tháº£o: Charlie Chen vÃ  Sebastian Borgeaud
â€¢ Pháº£n há»“i Báº£n tháº£o: Laurent Sifre, Geoï¬€rey Irving vÃ  John Jumper

Lá»i cáº£m Æ¡n
ChÃºng tÃ´i muá»‘n cáº£m Æ¡n Oriol Vinyals vÃ  Koray Kavukcuoglu cho lá»i khuyÃªn tá»­ táº¿ vÃ  kháº£ nÄƒng lÃ£nh Ä‘áº¡o cá»§a cÃ¡c báº¡n. ChÃºng tÃ´i cÅ©ng
muá»‘n cáº£m Æ¡n Evan Senter cho pháº£n há»“i bá»• sung cá»§a báº¡n vá» báº£n tháº£o vÃ  Amelia Glaese cho
sá»± há»— trá»£ cá»§a báº¡n trong viá»‡c Ä‘iá»u hÆ°á»›ng quÃ¡ trÃ¬nh xuáº¥t báº£n. Cuá»‘i cÃ¹ng, chÃºng tÃ´i muá»‘n cáº£m Æ¡n Blake Hechtman, Berkin
Ilbeyi cho lá»i khuyÃªn quÃ½ giÃ¡ cá»§a cÃ¡c báº¡n vá» XLA vÃ  Nikolai Grigoriev cho cÃ¡c cuá»™c tháº£o luáº­n cá»§a chÃºng tÃ´i vá» cÃ¡c thá»§ thuáº­t khÃ¡c nhau
cÃ³ thá»ƒ Ä‘Æ°á»£c Ã¡p dá»¥ng cho kiáº¿n trÃºc transformer.

SiÃªu tham sá»‘

Báº£ng 2 | SiÃªu tham sá»‘ cho mÃ´ hÃ¬nh nhÃ¡p
MÃ´ hÃ¬nh | ğ‘‘model | Heads | Layers | Params
ÄÃ­ch (Chinchilla) | 8192 | 64 | 80 | 70B
NhÃ¡p | 6144 | 48 | 8 | 4B

Chá»©ng minh

Äá»‹nh lÃ½ 1 (Láº¥y máº«u Tá»« chá»‘i ÄÆ°á»£c sá»­a Ä‘á»•i khÃ´i phá»¥c phÃ¢n phá»‘i Ä‘Ã­ch). Cho cÃ¡c phÃ¢n phá»‘i rá»i ráº¡c
ğ‘, ğ‘ vÃ  má»™t máº«u nhÃ¡p duy nháº¥t Ëœğ‘¥ğ‘, gá»i ğ‘‹ lÃ  máº«u cuá»‘i cÃ¹ng. Äá»ƒ ğ‘‹=ğ‘¥ Ä‘Ãºng, chÃºng ta pháº£i
hoáº·c láº¥y máº«u Ëœğ‘¥=ğ‘¥ vÃ  sau Ä‘Ã³ cháº¥p nháº­n nÃ³, hoáº·c láº¥y máº«u láº¡i nÃ³ sau khi Ëœğ‘¥ (cá»§a báº¥t ká»³ giÃ¡ trá»‹ nÃ o) bá»‹ tá»« chá»‘i. Do Ä‘Ã³:

â„™Â¹ğ‘‹=ğ‘¥Âº
=â„™Â¹Ëœğ‘¥=ğ‘¥Âºâ„™Â¹Ëœğ‘¥ Ä‘Æ°á»£c cháº¥p nháº­n|Ëœğ‘¥=ğ‘¥Âº+â„™Â¹Ëœğ‘¥ bá»‹ tá»« chá»‘iÂºâ„™Â¹ğ‘‹=ğ‘¥|Ëœğ‘¥ bá»‹ tá»« chá»‘i]

Cho háº¡ng Ä‘áº§u tiÃªn, chÃºng ta Ã¡p dá»¥ng quy táº¯c cháº¥p nháº­n:
â„™Â¹Ëœğ‘¥=ğ‘¥Âºâ„™Â¹Ëœğ‘¥ Ä‘Æ°á»£c cháº¥p nháº­n|Ëœğ‘¥=ğ‘¥Âº
=ğ‘Â¹ğ‘¥Âºmin(1, ğ‘Â¹ğ‘¥Âº/ğ‘Â¹ğ‘¥Âº)

--- TRANG 11 ---
TÄƒng tá»‘c Giáº£i mÃ£ MÃ´ hÃ¬nh NgÃ´n ngá»¯ Lá»›n vá»›i Láº¥y máº«u Suy Ä‘oÃ¡n

=minÂ¹ğ‘Â¹ğ‘¥Âºğ‘Â¹ğ‘¥ÂºÂº

Cho háº¡ng cÃ³ Ä‘iá»u kiá»‡n thá»© hai, chÃºng ta Ã¡p dá»¥ng quy táº¯c láº¥y máº«u láº¡i:
â„™Â¹ğ‘‹=ğ‘¥|Ëœğ‘¥ bá»‹ tá»« chá»‘i]=Â¹ğ‘Â¹ğ‘¥Âºğ‘Â¹ğ‘¥ÂºÂºÂ¸

Trong Ä‘Ã³ Â¹ÂºÂ¸ biá»ƒu thá»‹:
Â¹ğ‘“Â¹ğ‘¥ÂºÂºÂ¸=maxÂ¹0 ğ‘“Â¹ğ‘¥ÂºÂºÃğ‘¥maxÂ¹0 ğ‘“Â¹ğ‘¥ÂºÂº

Cuá»‘i cÃ¹ng, chÃºng ta tÃ­nh xÃ¡c suáº¥t tá»« chá»‘i:
â„™Â¹Ëœğ‘¥ bá»‹ tá»« chá»‘i]=1â„™Â¹Ëœğ‘¥ Ä‘Æ°á»£c cháº¥p nháº­n]
=1âˆ‘ï¸ğ‘¥0â„™Â¹ğ‘‹=ğ‘¥0|Ëœğ‘¥ Ä‘Æ°á»£c cháº¥p nháº­n]
=1âˆ‘ï¸ğ‘¥0minÂ¹ğ‘Â¹ğ‘¥0Âºğ‘Â¹ğ‘¥0ÂºÂº
=âˆ‘ï¸ğ‘¥0maxÂ¹0ğ‘Â¹ğ‘¥0Âºğ‘Â¹ğ‘¥0ÂºÂº
=âˆ‘ï¸ğ‘¥0ğ‘Â¹ğ‘¥0ÂºminÂ¹ğ‘Â¹ğ‘¥0Âºğ‘Â¹ğ‘¥0ÂºÂº
=âˆ‘ï¸ğ‘¥0maxÂ¹0ğ‘Â¹ğ‘¥0Âºğ‘Â¹ğ‘¥0ÂºÂº

Äiá»u nÃ y báº±ng máº«u sá»‘ cá»§a Â¹ğ‘Â¹ğ‘¥Âºğ‘Â¹ğ‘¥ÂºÂºÂ¸, vÃ¬ váº­y:
â„™Â¹Ëœğ‘¥ bá»‹ tá»« chá»‘i]â„™Â¹ğ‘‹=ğ‘¥|Ëœğ‘¥ bá»‹ tá»« chá»‘i]=maxÂ¹0ğ‘Â¹ğ‘¥Âºğ‘Â¹ğ‘¥ÂºÂº

Do Ä‘Ã³:
â„™Â¹ğ‘‹=ğ‘¥Âº
=minÂ¹ğ‘Â¹ğ‘¥Âºğ‘Â¹ğ‘¥ÂºÂº+maxÂ¹0ğ‘Â¹ğ‘¥Âºï¿½ï¿½Â¹ğ‘¥ÂºÂº
=ğ‘Â¹ğ‘¥Âº

vÃ  chÃºng ta Ä‘Ã£ khÃ´i phá»¥c Ä‘Ã­ch mong muá»‘n.

# Jakiro: Thúc đẩy Giải mã Suy đoán với Đa đầu Tách rời qua MoE

Haiduo Huang1 2Fuwei Yang1Zhenhua Liu1Yixing Xu1Jinze Li3Yang Liu1Xuanwu Yin1Dong Li1
Pengju Ren2Emad Barsoum1

## Tóm tắt

Giải mã suy đoán (SD) đẩy nhanh suy luận mô hình ngôn ngữ lớn bằng cách sử dụng một mô hình nháp nhỏ hơn để dự đoán nhiều token, sau đó được xác minh song song bởi mô hình mục tiêu lớn hơn. Tuy nhiên, khả năng hạn chế của mô hình nháp thường đòi hỏi lấy mẫu dựa trên cây để cải thiện độ chính xác dự đoán, nơi nhiều ứng viên được tạo ra ở mỗi bước. Chúng tôi nhận định một hạn chế chính trong cách tiếp cận này: các ứng viên cùng bước được xuất phát từ cùng một biểu diễn, hạn chế tính đa dạng và giảm hiệu quả tổng thể. Để giải quyết vấn đề này, chúng tôi đề xuất Jakiro, tận dụng Hỗn hợp Chuyên gia (MoE), nơi các chuyên gia độc lập tạo ra các dự đoán đa dạng, hiệu quả tách rời tương quan giữa các ứng viên. Hơn nữa, chúng tôi giới thiệu một chiến lược suy luận lai, kết hợp giải mã tự hồi quy cho các token ban đầu với giải mã song song cho các giai đoạn tiếp theo, và tăng cường phần sau với cơ chế tương phản trong các đặc trưng để cải thiện độ chính xác. Phương pháp của chúng tôi tăng đáng kể độ chính xác dự đoán và đạt được tốc độ suy luận cao hơn. Các thí nghiệm mở rộng trên các mô hình đa dạng xác nhận tính hiệu quả và bền vững của cách tiếp cận của chúng tôi, thiết lập một SOTA mới trong giải mã suy đoán. Mã nguồn của chúng tôi có sẵn tại https://github.com/haiduo/Jakiro.

## 1. Giới thiệu

Các mô hình ngôn ngữ lớn (LLM), như GPT-4o (Jaech et al., 2024), LLaMA3 (Dubey et al., 2024) và Deepseek-r1 (Guo et al., 2025), đã thể hiện khả năng đáng chú ý trên một loạt ứng dụng rộng, bao gồm hỏi đáp, tổng hợp mã và dịch máy. Tuy nhiên, quá trình giải mã từng token của chúng, kết hợp với kích thước ngày càng tăng của các mô hình, dẫn đến độ trễ suy luận đáng kể, đặt ra thách thức cho triển khai thực tế. Gần đây, giải mã suy đoán (Leviathan et al., 2023; Chen et al., 2023) đã xuất hiện như một kỹ thuật hiệu quả để đẩy nhanh suy luận LLM. Cách tiếp cận này sử dụng một mô hình nháp hiệu quả nhưng yếu để dự đoán nhiều token theo trình tự, sau đó được xác minh song song bởi một mô hình mục tiêu mạnh hơn nhưng đắt đỏ hơn. Vì suy luận LLM thường bị giới hạn bởi truy cập bộ nhớ (Shazeer, 2019), giai đoạn xác minh có thể tận dụng hiệu quả tính song song của phần cứng, đạt được tăng tốc đáng kể và không mất mát.

Các công trình gần đây, như Medusa (Cai et al., 2024) và Hydra (Ankner et al., 2024), tận dụng nhiều đầu độc lập để dự đoán N token tiếp theo, với tất cả các đầu dựa vào cùng các đặc trưng lớp cuối của mô hình mục tiêu. Sự phụ thuộc chung này hạn chế việc tách rời các dự đoán cho các token khác nhau, từ đó hạn chế độ chính xác dự đoán tổng thể. Ngược lại, Eagle (Li et al., 2024a) và Eagle2 (Li et al., 2024b) áp dụng cách tiếp cận tự hồi quy, nơi các dự đoán ở các bước thời gian khác nhau dựa trên các đặc trưng từ bước trước đó. Mặc dù các cách tiếp cận kiểu Eagle thành công tách rời các token nháp qua các bước thời gian khác nhau, các token top-k trong cùng lớp của cây nháp vẫn kết nối, hạn chế tính đa dạng và tiềm năng khổng lồ của chúng.

Để tăng cường độ chính xác dự đoán, cả Medusa-style và Eagle-style đều sử dụng cơ chế chú ý dựa trên cây (Miao et al., 2023) để tạo ra nhiều token ứng viên đồng thời. Tuy nhiên, chúng tôi quan sát rằng những ứng viên này được xuất phát từ cùng một biểu diễn đặc trưng, dẫn đến tương quan vốn có hạn chế độ chính xác dự đoán của mô hình nháp. Để giải quyết vấn đề này, chúng tôi đề xuất Jakiro với một cơ chế tách rời động tận dụng cơ chế MoE (Jiang et al., 2024) để xây dựng cây chú ý, giữ lại tính độc lập giữa các lớp của cây nháp truyền thống trong khi giới thiệu tách rời trong lớp. Bằng cách gán các chuyên gia khác nhau để tạo ra các token ứng viên, phương pháp của chúng tôi hiệu quả tách rời các tương quan giữa các dự đoán. Cách tiếp cận này tăng tính đa dạng biểu diễn của mô hình nháp trong khi giới thiệu chi phí tính toán tối thiểu. Kết quả là, phương pháp của chúng tôi cải thiện đáng kể độ chính xác dự đoán của mô hình nháp, dẫn đến tăng tốc tổng thể vượt trội.

Hơn nữa, do độ lệch tiếp xúc vốn có (Arora et al., 2022) trong suy luận tự hồi quy của LLM, lỗi dự đoán tăng khi độ dài chuỗi tăng. Xem xét chi phí suy luận của chính mô hình nháp, chúng tôi quan sát rằng không khôn ngoan khi áp dụng cách tiếp cận tự hồi quy để xây dựng chuỗi nháp ở mọi bước. Thay vào đó, chúng tôi áp dụng chiến lược giải mã song song (Xia et al., 2024) cho việc tạo token trong hai bước cuối, cải thiện thêm hiệu quả suy luận tổng thể của LLM. Để tăng cường hiệu suất hơn nữa trong giai đoạn giải mã song song, chúng tôi giới thiệu cơ chế tương phản (Li et al., 2022) vào các đầu nhánh kép của MoE để cải thiện tính hữu ích của dự đoán, tăng cường hiệu suất SD hơn nữa trong hai bước cuối. Khác với SCMoE (Shi et al., 2024), sử dụng các chuyên gia không được chọn theo cách tự tương phản trong suy luận, chúng tôi chỉ thực hiện các thao tác tương phản giữa hai đầu chuyên gia được kích hoạt, giới thiệu gần như không có độ trễ bổ sung.

So sánh với các phương pháp hiện có, các thí nghiệm mở rộng được tiến hành trên các mô hình và benchmark phổ biến đã xác nhận tính hiệu quả và bền vững của phương pháp chúng tôi. Ví dụ, chúng tôi đạt được tiến bộ đáng chú ý so với phương pháp tiên tiến (SOTA) trước đó trên MT-bench cho chế độ không tham lam, như được hiển thị trong Hình 2. Các đóng góp chính của chúng tôi có thể được mô tả như sau:

• **Tách rời Động với MoE trong Xây dựng Cây Chú ý Nháp**: Bài báo này là đầu tiên đề xuất tận dụng Hỗn hợp Chuyên gia (MoE) để đạt được tách rời động trong quá trình xây dựng cây chú ý nháp. Cách tiếp cận này tăng cường tính đa dạng của các token nháp và cải thiện hiệu quả của giải mã suy đoán, bất kể có sử dụng cấu trúc cây tĩnh hay động.

• **Chiến lược Suy luận Lai**: Một chiến lược suy luận lai được giới thiệu, kết hợp dự đoán tự hồi quy từng token cho các token ban đầu với giải mã song song cho các giai đoạn sau. Trong giai đoạn giải mã song song, chúng tôi đổi mới kết hợp cơ chế tương phản trong các đặc trưng đầu ra để tăng cường hiệu suất hơn nữa.

• **Đánh giá Benchmark Toàn diện**: Chúng tôi tiến hành các thí nghiệm toàn diện trên các benchmark và mô hình mục tiêu khác nhau để chứng minh tính hiệu quả và bền vững của cách tiếp cận của chúng tôi. Cách tiếp cận của chúng tôi đạt được hiệu suất SOTA trong giải mã suy đoán.

## 2. Kiến thức Nền tảng

### 2.1. Giải mã Suy đoán

Giải mã suy đoán (Leviathan et al., 2023) được thiết kế để đẩy nhanh suy luận từ các LLM tự hồi quy mà không thay đổi phân phối đầu ra. Một mô hình nháp nhỏ hơn, hiệu quả về mặt tính toán được sử dụng để tạo ra các token ứng viên trong giai đoạn soạn thảo, trong khi một mô hình mục tiêu lớn hơn, chất lượng cao xác minh và tinh chỉnh những ứng viên này. Ý tưởng chính đằng sau giải mã suy đoán là song song hóa quá trình tạo token, cho phép nhiều token được đề xuất cùng một lúc. Điều này đạt được bằng cách quan sát rằng các nhiệm vụ mô hình hóa ngôn ngữ phức tạp thường chứa các nhiệm vụ con có thể được xấp xỉ bởi các mô hình nhỏ hơn với độ chính xác đầy đủ. Bằng cách sử dụng những xấp xỉ này, giải mã suy đoán đạt được tăng tốc đáng kể trong khi duy trì các tính chất thống kê của đầu ra của mô hình mục tiêu.

Giả sử ti biểu thị token thứ i, và để Tx:y đại diện cho chuỗi token tx, tx+1,..., ty. Quá trình giải mã suy đoán bao gồm ba bước:

1. **Soạn thảo**: Cho trước một tiền tố T1:j, mô hình nháp q(.|.) tự hồi quy tạo ra một chuỗi các token ứng viên Tj+1:j+γ, mỗi token đi kèm với một phân phối xác suất qj+1:j+γ, nơi γ là số bước suy luận mỗi vòng cho mô hình nháp.

2. **Xác minh**: Mô hình mục tiêu p(.|.) tính toán các xác suất có điều kiện pj+1:j+γ cho cùng chuỗi trong một lần truyền tiến duy nhất. Mỗi token ứng viên tj+i được đánh giá tuần tự dựa trên tiêu chí chấp nhận, chẳng hạn như min(1, pj+i(tj+i)/qj+i(tj+i)).

3. **Tinh chỉnh**: Các token được chấp nhận được thêm vào chuỗi đầu ra, trong khi các token bị từ chối được lấy mẫu lại sử dụng phân phối xác suất chuẩn hóa norm(max(0, pj+i−qj+i)) để thay thế tj+i và loại bỏ các token còn lại trong soạn thảo.

Phương pháp đảm bảo rằng phân phối đầu ra vẫn nhất quán với giải mã tự hồi quy vanilla cho cả chiến lược lấy mẫu tham lam và không tham lam, như đã được chứng minh trong các công trình trước đó (Leviathan et al., 2023; Chen et al., 2023).

### 2.2. Giải mã Kiểu Medusa

Giải mã kiểu Medusa (Cai et al., 2024; Ankner et al., 2024) mở rộng giải mã suy đoán bằng cách sử dụng nhiều đầu nháp nhẹ, thường được triển khai như các perceptron đa lớp nhỏ (MLP), trên đỉnh trạng thái ẩn cuối của LLM mục tiêu. Những đầu này độc lập dự đoán token dựa trên trạng thái ẩn cuối của LLM mục tiêu, và các dự đoán của chúng được kết hợp thành các tiếp tục ứng viên. Tuy nhiên, việc sử dụng chung trạng thái ẩn cuối trên tất cả các đầu dẫn đến tách rời không hoàn toàn, hạn chế khả năng của mỗi đầu tạo ra các dự đoán đa dạng và độc lập.

### 2.3. Giải mã Kiểu Eagle

Trong giải mã kiểu Eagle (Li et al., 2024a;b), giai đoạn soạn thảo tách rời các token nháp ở các bước thời gian khác nhau bằng cách thực hiện tự hồi quy ở cấp độ đặc trưng (trước đầu LM). Đầu LM của LLM gốc sau đó được sử dụng để chuyển đổi các đặc trưng thành token nháp. Cách tiếp cận này giảm không chắc chắn trong chuỗi đặc trưng, dẫn đến cải thiện dự đoán nháp. Tuy nhiên, các token top-k trong cùng lớp của cây nháp vẫn kết nối, điều này hạn chế tính đa dạng và tiềm năng của các dự đoán.

Eagle1 áp dụng nháp có cấu trúc cây tĩnh (Miao et al., 2023) trong giai đoạn xác minh, cho phép các đường dẫn phân nhánh khám phá các tiếp tục thay thế khi token nháp bị từ chối. Cấu trúc này tăng tính bền vững bằng cách tránh loại bỏ hoàn toàn các chuỗi nháp khi các token riêng lẻ không đáp ứng tiêu chí của mô hình mục tiêu. Eagle2 cải thiện Eagle1 bằng cách giới thiệu cây nháp có thể điều chỉnh động. Điều này cho phép cây thích ứng dựa trên điều kiện thời gian chạy, tối ưu hóa dự đoán và xác minh token. Mặc dù có sự cải tiến này, thiếu tách rời trong lớp trong cây nháp vẫn hạn chế tính đa dạng của các token được tạo, đặc biệt trong các chế độ lấy mẫu không tham lam.

## 3. Jakiro

### 3.1. Tách rời Động và Xây dựng Cây MoE

#### 3.1.1. TÁCH RỜI ĐỘNG VỚI CÁC ĐẦU MOE

Khác với Medusa, dựa vào trạng thái ẩn cuối cho tất cả các đầu nháp, Jakiro sử dụng nhiều đầu MoE phân bổ động các mô-đun chuyên gia để dự đoán token. Cơ chế này tính đến sự khác biệt vốn có giữa các token và đảm bảo tách rời các dự đoán token trên các đầu. Kết quả là, độ tin cậy dự đoán được cải thiện trong khi duy trì hiệu quả tính toán.

Cấu trúc của mô hình nháp của chúng tôi tuân theo các nguyên tắc thiết kế của kiểu Eagle, sử dụng một lớp giải mã duy nhất bao gồm lớp giảm chiều, lớp chú ý LLM và các đầu chuyên gia song song (các lớp MLP nhẹ). Và, lớp nhúng và lớp đầu vẫn nhất quán với mô hình mục tiêu mà không giới thiệu tham số bổ sung. Điều này đảm bảo rằng hiệu quả suy luận không bị ảnh hưởng bởi sự gia tăng số lượng tham số. Cấu trúc chi tiết được hiển thị trong Hình 3 (2).

#### 3.1.2. XÂY DỰNG CÂY MOE

Jakiro giới thiệu một phương pháp xây dựng cây mới tách rời các phụ thuộc trong lớp của cây nháp truyền thống trong khi giữ lại tính độc lập giữa các lớp. Thiết kế này đảm bảo rằng các token nháp trên các lớp khác nhau được tạo ra độc lập, bảo tồn tính nhất quán của mô hình nháp giải mã tự hồi quy với mô hình mục tiêu và tăng cường đáng kể độ chính xác và tính thực tế của dự đoán. Đồng thời, việc tách rời các token trong lớp cho phép Jakiro khám phá một phạm vi rộng hơn các tiếp tục ứng viên hoặc tính đa dạng, đặc biệt trong các chế độ không tham lam, mà không ảnh hưởng đến tính toàn vẹn của phân phối đầu ra.

Cụ thể, quá trình suy luận Eagle gốc có thể được tóm tắt như sau: khi một token mới ti được truyền qua lớp nhúng, một nhúng token được thu được. Nhúng này sau đó được nối với các trạng thái ẩn (được ký hiệu là đặc trưng fi−1) từ bước trước đó. Kết quả được nối được xử lý qua lớp Reduction để giảm chiều, và trạng thái ẩn đầu ra hi tiếp theo qua lớp giải mã LLM (bao gồm lớp chú ý Attn và lớp MLP) để tạo ra các trạng thái ẩn fi cho bước hiện tại. Token tiếp theo ti+1 được lấy mẫu qua lớp Head và được sử dụng cho bước suy luận tiếp theo. Quá trình này lặp lại cho đến khi gặp token kết thúc chuỗi hoặc đạt độ dài token tối đa.

Ngược lại, quá trình suy luận Jakiro của chúng tôi thay thế lớp MLP trong LLM bằng lớp MoE Expertj và sửa đổi việc xây dựng cây nháp. Giả sử số chuyên gia ứng viên là N và số chuyên gia được kích hoạt cuối cùng là K (giá trị mặc định là 2), bộ định tuyến MoE và lớp đầu LLM được chia sẻ trên các lớp chuyên gia khác nhau. Ở mỗi bước, hai phân phối logits ứng viên được xuất ra, sau đó được xử lý qua giải mã Cây MoE. Các logits được sắp xếp dựa trên điểm số sj,i tương ứng với các chuyên gia được chọn: chuyên gia có điểm số lớn hơn được đặt ở phía trái của lớp hiện tại, trong khi những chuyên gia có điểm số nhỏ hơn được đặt ở phía phải. Công thức như sau:

ui = Attn(hi) + hi, (1)
sj,i = Softmaxj(uiTej), (2)
fi = ΣNj=1 gj,iExpertj(ui) + ui, (3)
logitslefti, logitsrighti = Head(stop1fi, stop2fi), (4)
gj,i = {sj,i, nếu sj,i ∈ Topk({sj,i|1≤j≤N}, K), 0, ngược lại, (5)

nơi ej là trọng tâm của chuyên gia thứ j, gj,i là thưa thớt, cho biết chỉ K trong số N giá trị cổng là khác không. Tính chất thưa thớt này đảm bảo hiệu quả tính toán trong lớp MoE, tức là mỗi token sẽ được gán cho và tính toán chỉ trong K chuyên gia. Ngoài ra, trong các công thức trên, chúng tôi bỏ qua thao tác chuẩn hóa lớp để ngắn gọn. Toàn bộ quá trình này tuân thủ nguyên tắc xây dựng top-k của cây Eagle, và cơ chế mặt nạ chú ý cây tương ứng được minh họa trong Hình 4.

Quá trình xây dựng cụ thể của cây MoE được minh họa trong Hình 3 (4). Cơ chế triển khai của nó có thể được kết hợp với cây tĩnh được xác định trước của Eagle1 hoặc cây được xây dựng động của Eagle2. Kết quả thí nghiệm chứng minh rằng cả hai cách tiếp cận đều dẫn đến cải thiện đáng kể trong hiệu quả suy luận.

**Tác động đến Các Chế độ Không Tham lam** Trong khi các phương pháp giải mã suy đoán truyền thống gặp khó khăn với tính đa dạng trong lấy mẫu không tham lam, Jakiro xuất sắc bằng cách giới thiệu các cơ chế tối đa hóa cả tính đa dạng và độ tin cậy dự đoán. Điều này làm cho nó đặc biệt hiệu quả trong các tình huống cần khám phá toàn diện các tiếp tục thay thế.

### 3.2. Tích hợp Hiệu quả Cơ chế Tương phản

Mặc dù Jakiro tăng cường đáng kể hiệu suất trong các chế độ không tham lam thông qua cấu trúc cây tách rời của nó, nó không cho thấy lợi thế đáng kể trong các nhiệm vụ độ chính xác top-1 nghiêm ngặt, như HumanEval và GSM8K, được tối ưu hóa cho giải mã tham lam. Tuy nhiên, bằng cách kết hợp cơ chế giải mã song song Medusa, chúng tôi giảm số lần truyền tiến trong suy luận mà không ảnh hưởng đến tăng tốc cuối cùng, cho phép Jakiro đạt được hiệu suất ngang bằng với Eagle2.

Hơn nữa, LLM dễ bị ảo giác (Tonmoy et al., 2024; Liu et al., 2024), nơi chúng tạo ra nội dung không phù hợp với các sự kiện được thấy trong quá trình tiền huấn luyện. Do khả năng hạn chế của chính mô hình nháp, vấn đề này được làm tăng thêm, khiến việc tối ưu hóa thêm dưới giải mã tham lam (tức là xác minh top-1 nghiêm ngặt) trở nên khó khăn. Mặc dù kiểu Eagle đã cải thiện hiệu suất của mô hình nháp bằng cách giới thiệu chưng cất đặc trưng, do hạn chế về tham số mô hình, khó có thể đạt được cải thiện thêm thông qua các kỹ thuật huấn luyện bổ sung.

Tuy nhiên, chúng tôi khám phá rằng kỹ thuật giải mã tương phản hiện đang phổ biến đạt được cải thiện đáng kể ngay lập tức so với giải mã tham lam, mà không yêu cầu huấn luyện bổ sung. Các công trình trước đó (Chuang et al., 2023; O'Brien & Lewis, 2023) đã chỉ ra rằng giải mã tương phản cải thiện chất lượng tạo sinh bằng cách tìm kiếm các chuỗi tối đa hóa sự khác biệt khả năng có trọng số giữa các mô hình mạnh và yếu. Khác với việc sử dụng hai mô hình có khả năng rất khác biệt của họ, chúng tôi chỉ áp dụng cơ chế tương phản cho các trạng thái ẩn đầu ra, chứ không phải logits, của hai chuyên gia có điểm số cao nhất trong lớp MoE. Cách tiếp cận này cải thiện thêm chất lượng tạo sinh của token nháp trong chế độ tham lam, đưa chúng gần hơn với token top-1 của mô hình mục tiêu và cải thiện tốc độ suy luận. Sơ đồ của cơ chế được hiển thị trong Hình 5.

Dưới đây là sự suy dẫn chi tiết của các công thức:

fmoei = stop1fitop1 + stop2fitop2, (6)
fconsti = βftop1i - αftop2i, (7)
logitsmoei, logitsconsti = Head(fmoei, fconsti), (8)

nơi logitsmoei cho biết rằng suy luận dựa trên đầu ra logits từ các bước [1:γ−1] trước đó cho giải mã tự hồi quy, trong khi logitsconsti được sử dụng cho giải mã song song ở bước γ−1, dẫn đến ít hơn một quá trình nháp so với phương pháp kiểu Eagle. Ngoài ra, β và α là các tham số có thể học tương ứng với điểm số của các chuyên gia ứng viên là top1 và top2, và được sử dụng để điều chỉnh thích ứng sự khác biệt giữa chúng để học tương phản tốt hơn. So với chế độ không tham lam của Jakiro, không có tham số bổ sung nào được giới thiệu, có nghĩa là cùng trọng số được sử dụng.

Ngoài ra, cần lưu ý rằng Jakiro của chúng tôi không giới hạn ở giải mã song song cho hai bước cuối. Khi K > 2, về mặt lý thuyết nó hỗ trợ giải mã song song cho K bước cuối. Tuy nhiên, đây không phải là trọng tâm của nghiên cứu hiện tại và sẽ được khám phá trong công việc tương lai.

### 3.3. Huấn luyện của Các Mô hình Nháp

Tương tự như kiểu Eagle, để giảm chi phí huấn luyện, chúng tôi sử dụng một tập dữ liệu cố định được tiền xử lý để huấn luyện các mô hình nháp. Các siêu tham số tăng cường dữ liệu khác được giữ nhất quán với Eagle. Ngoài ra, chúng tôi áp dụng hàm mất mát Smooth L1 để dự đoán đặc trưng tiếp theo như một nhiệm vụ hồi quy và sử dụng entropy chéo để đảm bảo độ chính xác của chuỗi token.

Tuy nhiên, xem xét rằng toàn bộ quá trình của mô hình nháp là tự hồi quy và tốn kém về mặt tính toán, chúng tôi sử dụng cơ chế giải mã song song trong bước áp chót. Do đó, việc dự đoán token tiếp theo đạt được thông qua tương phản giữa hai đầu chuyên gia của MoE, giới thiệu một mất mát bổ sung (tương tự như triển khai Medusa). Mục tiêu tối ưu như sau:

Lmoereg = Smooth L1(fpi+1, fmoei), (9)
Lconstreg = Smooth L1(fpi+2, fconsti), (10)
qi+2, qi+3 = Softmax(logitsmoei, logitsconsti), (11)
Lmoecls = Cross Entropy(pi+2, qi+2), (12)
Lconstcls = Cross Entropy(pi+3, qi+3), (13)
L = Lmoereg + wmoeclsLmoecls + Lconstreg + wconstclsLconstcls (14)

Chúng tôi sử dụng hàm mất mát kết hợp L để huấn luyện mô hình nháp tự hồi quy. Cho rằng mất mát phân loại lớn hơn một bậc so với mất mát hồi quy về mặt số học, và tầm quan trọng của const thấp hơn so với moe, chúng tôi đặt wmoecls và wconstcls lần lượt là 0.1 và 0.05.

## 4. Thí nghiệm

**Mô hình và nhiệm vụ.** Theo các công trình chính thống hiện tại, chúng tôi tiến hành thí nghiệm trên các mô hình Vicuna (7B, 13B, 33B) (Chiang et al., 2023), mô hình LLaMA2-chat (7B, 13B, 70B) (Touvron et al., 2023), và LLaMA3-Instruct (8B, 70B) (Meta, 2024), bao gồm các kích thước phổ biến của LLM chính thống hiện tại. Để đánh giá tính tổng quát và bền vững của phương pháp chúng tôi, Jakiro của chúng tôi được đánh giá trên nhiều nhiệm vụ bao gồm đối thoại đa lượt, tạo mã, suy luận toán học và tuân theo hướng dẫn, sử dụng các tập dữ liệu MT-bench (Zheng et al., 2023), HumanEval (Chen et al., 2021), GSM8K (Cobbe et al., 2021), Alpaca (Taori et al., 2023), CNN/Daily Mail (Nallapati et al., 2016), và Natural Questions (Kwiatkowski et al., 2019).

**Các chỉ số.** Tương tự như các cách tiếp cận lấy mẫu suy đoán trước đó, phương pháp Jakiro của chúng tôi tập trung chủ yếu vào việc giảm độ trễ thay vì tối ưu hóa thông lượng. Để đo lường hiệu ứng tăng tốc của nó, chúng tôi sử dụng các chỉ số sau:

• **Tỷ lệ tăng tốc thời gian thực**: So với giải mã tự hồi quy truyền thống, tỷ lệ tăng tốc đạt được trong các thử nghiệm thực tế từ đầu đến cuối.

• **Độ dài chấp nhận trung bình τ**: Số lượng token trung bình được chấp nhận từ giải mã suy đoán mỗi lần truyền tiến của LLM mục tiêu.

Tương tự như các phương pháp sử dụng cơ chế lấy mẫu suy đoán nghiêm ngặt, việc tăng tốc đạt được bởi Jakiro đảm bảo rằng phân phối đầu ra của LLM mục tiêu được duy trì. Do đó, việc đánh giá chất lượng của kết quả được tạo ra là không cần thiết và không liên quan, vì trọng tâm là hiệu quả chứ không phải độ trung thực đầu ra.

**Huấn luyện.** Chúng tôi giữ LLM mục tiêu cố định trong suốt quá trình huấn luyện. Mô hình Jakiro được đề xuất của chúng tôi được huấn luyện trên tập dữ liệu ShareGPT sử dụng 68.000 lần lặp đối thoại mà không cần huấn luyện lại mở rộng hoặc dữ liệu bổ sung ngoài các mô hình được tiền huấn luyện, và với tốc độ học được đặt ở 9e-5. Bộ tối ưu AdamW được sử dụng với các giá trị beta (β1, β2) = (0.9, 0.95), và cắt gradient được áp dụng với ngưỡng 0.5. Số lượng tham số có thể huấn luyện cho Jakiro thay đổi theo kích thước mô hình: 0.35B cho mô hình 7B, 0.56B cho mô hình 8B, 0.88B cho mô hình 13B, 1.42B cho mô hình 33B, và 1.87B cho mô hình 70B. Ví dụ, huấn luyện mô hình nháp Jakiro cho mô hình 70B mất khoảng 2-3 ngày trên 4 × A100 40GB GPU.

**Kiểm tra.** Các thí nghiệm của chúng tôi được tiến hành trên các thiết bị khác nhau (AMD Instinct™ MI250-64G, NVIDIA A40-45G, và NVIDIA A100-40G) và hạn chế của bộ nhớ GPU phần cứng. Đối với các mô hình kích thước (7B, 8B, 13B), (33B), và (77B), chúng tôi thực hiện đơn GPU, hai GPU, và bốn GPU tương ứng.

### 4.1. Hiệu quả

Như được hiển thị trong Bảng 1 và Bảng 2, Jakiro được đề xuất của chúng tôi liên tục vượt trội hơn các phương pháp hiện có về tỷ lệ tăng tốc trên các tập dữ liệu và mô hình khác nhau trên MI250. Các tỷ lệ tăng tốc được đạt bởi Jakiro, như 2.99x trên MT-bench và 3.43x trên nhiệm vụ HumanEval cho mô hình Vicuna 7B dưới chế độ tham lam, vượt trội đáng kể so với các phương pháp khác, bao gồm Eagle2, đạt tăng tốc tối đa 2.88x trung bình. Kết quả trên các nhiệm vụ khác nhau tiếp tục làm nổi bật hiệu quả của Jakiro. Ví dụ, trên nhiệm vụ GSM8K, Jakiro đạt được tăng tốc 3.11x, duy trì độ dài chấp nhận trung bình cao 4.95 token. Điều này chứng minh rằng Jakiro không chỉ tăng tốc suy luận mà còn giữ lại đầu ra chất lượng cao, duy trì hiệu suất của LLM mục tiêu mà không ảnh hưởng đến độ chính xác.

Vì Jakiro của chúng tôi bao gồm ít hơn một bước soạn thảo so với Eagle2, không có cải thiện đáng kể nào trong độ dài chấp nhận trung bình của token. Tuy nhiên, xem xét rằng mục tiêu cuối cùng của giải mã suy đoán là cải thiện tăng tốc, phương pháp của chúng tôi vẫn hiệu quả. Ví dụ, trong chế độ tham lam cho LLaMA2-Chat 7B, mặc dù độ dài chấp nhận trung bình của phương pháp chúng tôi thấp hơn một chút so với Eagle2 (4.51 so với 4.63), tăng tốc cuối cùng của phương pháp chúng tôi được cải thiện đáng chú ý (2.83x so với 2.66x). Hơn nữa, chúng tôi quan sát rằng Jakiro xuất sắc trên cả nhiệm vụ tạo mã và ngôn ngữ tự nhiên. Điều này đặc biệt đáng chú ý vì các nhiệm vụ tạo mã thường được hưởng lợi từ lấy mẫu tham lam, nơi cấu trúc vốn có của mã làm cho việc dự đoán token tiếp theo hiệu quả hơn. Tương tự, trên Natural Questions và các nhiệm vụ tóm tắt, Jakiro duy trì hiệu suất vượt trội.

Ngoài ra, trong chế độ không tham lam, so sánh các phương pháp với lấy mẫu suy đoán cũng cho thấy rằng Jakiro đạt được tỷ lệ tăng tốc cao hơn đáng kể trong khi cũng duy trì độ dài chấp nhận trung bình cao hơn. Như Vicuna 7B, so với Eagle2, phương pháp của chúng tôi đạt được cải thiện 15.4% trong tăng tốc trung bình cuối cùng trên tất cả các bộ kiểm tra benchmark (2.84 so với 2.46). Điều này cho thấy rằng Jakiro được hưởng lợi từ một quá trình soạn thảo hiệu quả hơn cho phép các chuỗi token dài hơn và ổn định hơn được chấp nhận, giảm nhu cầu lấy mẫu lại thường xuyên và giảm thiểu rủi ro lỗi trong quá trình suy luận.

### 4.2. Nghiên cứu Loại bỏ

**Cài đặt N-k của MoE.** Số lượng chuyên gia ứng viên N và chuyên gia được kích hoạt K tham gia vào tính toán cho mỗi token trong kiến trúc MoE điển hình lần lượt là 8 và 2. Nếu giải mã suy đoán sử dụng việc xây dựng dựa trên chuỗi gốc của token nháp, số lượng chuyên gia được kích hoạt mỗi lần là cố định và bằng 2. Tuy nhiên, các phương pháp giải mã suy đoán chính thống hiện tại sử dụng cấu trúc cây để xây dựng token nháp. Mặc dù số lượng chuyên gia ứng viên được kích hoạt cho mỗi token là cố định, quá trình xây dựng cây dẫn đến việc chọn các token ứng viên top-k ở mỗi lớp, điều này dẫn đến số lượng chuyên gia được kích hoạt K ≥ 2 trong mỗi suy luận. Ngoài ra, càng nhiều chuyên gia ứng viên, khả năng dự đoán của mô hình càng tốt, nhưng với chi phí tính toán tăng. Do đó, cần thiết phải chọn cài đặt N-K phù hợp để đạt được tốc độ suy luận tối ưu. Kết quả dưới các cài đặt N-K khác nhau được hiển thị trong Bảng 3.

Từ kết quả trên, có thể thấy rằng khi số lượng chuyên gia ứng viên tăng, cả độ dài chấp nhận trung bình và tải tính toán đều tăng tương ứng. Tuy nhiên, chúng tôi tin rằng việc kết hợp tối ưu hóa phần cứng và thuật toán có thể giảm thiểu những chi phí này, tiếp tục mở khóa tiềm năng của MoE, điều này vẫn là một lĩnh vực để khám phá trong tương lai.

**Kết hợp với Giải mã Song song và Cơ chế Tương phản.** Cơ chế tương phản (có lẽ tương tự như một dạng học tương phản) và việc triển khai của nó kết hợp với giải mã song song được thảo luận trong Phần 3.2. Cách tiếp cận này nhằm giảm một bước suy luận nháp so với LLM giải mã tự hồi quy thông thường (ví dụ: Eagle2) mà không mất đáng kể hiệu suất dự đoán, từ đó đạt được tăng tốc tối ưu. Tuy nhiên, bản chất của hai cơ chế này khác nhau. Cơ chế tương phản tập trung vào việc dự đoán tốt hơn token tiếp theo trong chuỗi, trong khi giải mã song song nhằm xuất ra nhiều token tương lai trong một bước. Do đó, cần thiết phải tiến hành thí nghiệm thêm để đánh giá tác động tương ứng của chúng đến hiệu suất cuối cùng, với kết quả được hiển thị trong Bảng 4.

Như có thể thấy từ kết quả trên, sử dụng giải mã song song hoặc cơ chế tương phản riêng lẻ đều dẫn đến một số cải thiện so với việc chỉ sử dụng MoE, điều này chứng minh rằng hai cơ chế được đề xuất có thể bổ sung hiệu quả cho Jakiro. Tuy nhiên, việc kết hợp cả hai cơ chế tiếp tục giải phóng tiềm năng của Jakiro, duy trì tỷ lệ chấp nhận tương đương (tương tự như độ dài chấp nhận trung bình) trong khi cải thiện thêm tăng tốc của nó.

## 5. Công trình Liên quan

**Giải mã suy đoán:** Giải mã suy đoán (SD) đã nổi lên như một kỹ thuật mạnh mẽ để tăng tốc suy luận LLM bằng cách giảm các nút thắt cổ chai băng thông bộ nhớ. Các phương pháp giải mã suy đoán ban đầu, như của (Stern et al., 2018) và (Sun et al., 2021), tập trung vào chiến lược giải mã tham lam, trong khi (Leviathan et al., 2023) và (Chen et al., 2023) mở rộng lấy mẫu suy đoán sang giải mã không tham lam. Các công trình gần đây trong SD đã tăng cường hiệu quả mô hình nháp, với các phương pháp như SpecInfer (Miao et al., 2023) sử dụng chú ý cây để xác minh nhiều token nháp song song, và Medusa (Cai et al., 2024) sử dụng các đầu MLP bổ sung để tạo ra bản nháp token. Mặc dù những phương pháp này đã đạt được tăng tốc đáng chú ý, chúng đối mặt với hạn chế về tính đa dạng token và tách rời giữa các mô hình nháp và mục tiêu. Eagle (Li et al., 2024a) giới thiệu cách tiếp cận động hơn bằng cách tách rời các token nháp qua các bước thời gian khác nhau. Tuy nhiên, Eagle vẫn duy trì kết nối giữa các token Top-k ở cùng lớp trong cây nháp, điều này hạn chế tính đa dạng và chuyên môn hóa của token. Cách tiếp cận của chúng tôi xây dựng dựa trên những hạn chế này bằng cách giới thiệu cơ chế tách rời động với các đầu Hỗn hợp Chuyên gia (MoE), cho phép các token nháp xem xét sự khác biệt vốn có giữa chúng, dẫn đến dự đoán đa dạng và tự tin hơn.

**Hỗn hợp Chuyên gia:** MoE đã được khám phá rộng rãi để cải thiện chuyên môn hóa của các mô hình. Kỹ thuật MoE ban đầu được đề xuất bởi (Jacobs et al., 1991; Jordan & Jacobs, 1994) và sau đó được thích ứng cho các mô hình ngôn ngữ, như trong GShard (Lepikhin et al., 2021) và Switch Transformer (Fedus et al., 2021), mở rộng MoE cho các mô hình lớn với chiến lược định tuyến top-k. Gần đây hơn, việc tích hợp MoE trong kiến trúc dựa trên Transformer đã thu hút sự quan tâm đáng kể, với các phương pháp như StableMoE (Dai et al., 2022) khám phá chiến lược định tuyến cố định để huấn luyện ổn định hơn. Các đầu MoE cũng đã được sử dụng trong cài đặt đa phương thức (Du et al., 2022; Xue et al., 2023), nơi chúng cho phép chuyên môn hóa qua các phương thức khác nhau. Hơn nữa, trong bối cảnh giải mã suy đoán, phương pháp của chúng tôi kết hợp các đầu nhánh kép của MoE với kỹ thuật giải mã tương phản, một chiến lược được lấy cảm hứng từ các công trình gần đây (Shazeer et al., 2017; Dai et al., 2022) để cải thiện tính hữu ích của dự đoán token nháp, đặc biệt trong các chế độ tham lam. Bằng cách tích hợp những chiến lược này, chúng tôi có thể đạt được dự đoán đáng tin cậy hơn với suy luận nhanh hơn, như được chứng minh qua các thí nghiệm của chúng tôi.

**Giải mã song song:** Giải mã song song được biết đến với hiệu quả trong dịch máy (Ghazvininejad et al., 2019) và tạo mã (Gloeckle et al., 2024), cũng đã được tích hợp vào các khung SD để tăng cường hiệu quả hơn nữa. Mặc dù việc sử dụng giải mã song song trong các khung suy đoán vẫn chưa được khám phá đầy đủ, các công trình như (Monea et al., 2023) và (Yi et al., 2024) đã tiên phong ứng dụng của nó. Tuy nhiên, những phương pháp này vẫn đối mặt với thách thức trong việc đạt được sự phù hợp hoàn hảo giữa phân phối nháp và mô hình mục tiêu, điều này có thể hạn chế hiệu quả của chúng trong tăng tốc không mất mát. Cách tiếp cận của chúng tôi giải quyết những thách thức này bằng cách cải thiện cơ chế tách rời trong các đầu MoE, đảm bảo sự phù hợp tốt hơn và dự đoán token đa dạng hơn trong cả chế độ tham lam và không tham lam.

## 6. Kết luận

Tóm lại, trong khi giải mã suy đoán đã chứng minh hiệu quả trong việc tăng tốc suy luận LLM, các thách thức vẫn còn trong việc cải thiện tính đa dạng token và duy trì sự phù hợp phân phối giữa các mô hình nháp và mục tiêu. Công trình của chúng tôi đạt được bước tiến đáng kể trong việc giải quyết những thách thức này bằng cách giới thiệu cơ chế tách rời động với các đầu MoE, cải thiện độ tin cậy dự đoán, tính đa dạng và tính thực tế. Ngoài ra, bằng cách kết hợp cơ chế tương phản với các đầu nhánh kép của MoE, chúng tôi tăng cường thêm tính hữu ích của dự đoán, chứng minh tiềm năng của cách tiếp cận này trong cả nhiệm vụ tạo sinh tham lam và không tham lam. Jakiro được đề xuất của chúng tôi thể hiện tỷ lệ tăng tốc vượt trội, độ dài chấp nhận cao và hiệu quả tổng thể trên nhiều nhiệm vụ và kích thước mô hình, làm cho nó trở thành giải pháp hấp dẫn để cải thiện tốc độ suy luận mà không hy sinh chất lượng đầu ra mô hình.

## Tuyên bố Tác động

Bài báo này trình bày công trình có mục tiêu thúc đẩy lĩnh vực Học máy. Có nhiều hậu quả xã hội tiềm tàng của công trình chúng tôi, không có gì chúng tôi cảm thấy phải được nhấn mạnh cụ thể ở đây.

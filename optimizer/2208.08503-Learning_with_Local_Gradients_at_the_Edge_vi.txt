# Học với Gradient Cục bộ tại Edge

Michael Lomnitz, Zachary Daniels, David Zhang, Michael Piacentino
19 tháng 9, 2022

## Tóm tắt

Để cho phép học tập trên các thiết bị edge với sự hội tụ nhanh và bộ nhớ thấp, chúng tôi trình bày một thuật toán tối ưu hóa mới không cần backpropagation được gọi là Target Projection Stochastic Gradient Descent (tpSGD). tpSGD tổng quát hóa phép chiếu mục tiêu ngẫu nhiên trực tiếp để hoạt động với các hàm mất mát tùy ý và mở rộng phép chiếu mục tiêu để huấn luyện mạng nơ-ron hồi quy (RNN) ngoài các mạng feedforward. tpSGD sử dụng gradient descent ngẫu nhiên (SGD) theo từng lớp và các mục tiêu cục bộ được tạo ra thông qua phép chiếu ngẫu nhiên của các nhãn để huấn luyện mạng theo từng lớp chỉ với các lần truyền tiến. tpSGD không yêu cầu giữ lại gradient trong quá trình tối ưu hóa, giảm đáng kể việc phân bổ bộ nhớ so với các phương pháp SGD backpropagation (BP) yêu cầu nhiều instance của toàn bộ trọng số mạng nơ-ron, đầu vào/đầu ra và kết quả trung gian. Phương pháp của chúng tôi thực hiện tương đương với BP gradient-descent trong vòng 5% độ chính xác trên các mạng tương đối nông gồm các lớp kết nối đầy đủ, lớp tích chập và lớp hồi quy. tpSGD cũng vượt trội hơn các thuật toán gradient-free tiên tiến khác trong các mô hình nông bao gồm perceptron đa lớp, mạng nơ-ron tích chập (CNN) và RNN với độ chính xác cạnh tranh và ít bộ nhớ và thời gian hơn. Chúng tôi đánh giá hiệu suất của tpSGD trong việc huấn luyện mạng nơ-ron sâu (ví dụ: VGG) và mở rộng phương pháp cho RNN đa lớp. Các thí nghiệm này làm nổi bật các hướng nghiên cứu mới liên quan đến việc huấn luyện adaptor dựa trên lớp được tối ưu hóa để chuyển đổi miền sử dụng tpSGD tại edge.

## 1 Giới thiệu

Các hệ thống dựa trên AI hoạt động trong môi trường thay đổi nhanh chóng cần thích ứng theo thời gian thực. Khả năng thích ứng của các thiết bị edge hiện tại bị hạn chế bởi các ràng buộc về Kích thước, Trọng lượng và Công suất (SWaP), rào cản bộ nhớ từ các kiến trúc hệ thống hiện tại [1], và sự thiếu vắng các thuật toán học tập hiệu quả trên thiết bị. Kết quả là, các hệ thống AI hiện tại thích ứng bằng cách huấn luyện lại trên đám mây do sự phức tạp áp đảo của các mô hình AI. Thích ứng, hoặc chuyển đổi miền cho một phân phối dữ liệu mới, thường yêu cầu tinh chỉnh toàn bộ hoặc một phần mạng (ví dụ: vài lớp cuối). Tương tự, thường cần thiết phải thực hiện chuyển đổi từ độ chính xác đầy đủ [2] sang ít bit hơn để phù hợp với kiến trúc phần cứng hạn chế, và việc làm này có thể yêu cầu cập nhật mạng bằng cách chưng cất. Mặc dù thực tế là học tập gradient-descent (GD) backpropagation (BP) là một trong những phương pháp được nghiên cứu và thành công nhất, phương pháp chiếm ưu thế vẫn thể hiện một số hạn chế, bao gồm gradient biến mất và bùng nổ [3], khó khăn với lượng tử hóa dữ liệu, và không thể xử lý các tham số không khả vi [4]. Mở rộng GD BP để huấn luyện trên thiết bị thể hiện một số vấn đề bổ sung liên quan đến tính khả dụng bộ nhớ hạn chế: 1) Vấn đề vận chuyển trọng số yêu cầu mỗi lớp phải có kiến thức đầy đủ về các trọng số khác trong mạng nơ-ron (NN); 2) Vấn đề khóa cập nhật yêu cầu một lần truyền tiến đầy đủ trước lần truyền phản hồi, dẫn đến chi phí bộ nhớ cao. Trong GD BP, tất cả các đầu vào và kích hoạt lớp trong cả lần truyền tiến và ngược đều cần được đệm trước khi các cập nhật trọng số hoàn thành.

Để khắc phục các vấn đề liên quan đến GD BP, đặc biệt là cho việc huấn luyện tại edge, nhiều phương pháp gradient-free (GF), như được tóm tắt trong Hình 1 (Bio-inspired, ADMM, và ELM/KR), đã được nghiên cứu. Các phương pháp GF sớm như Thuật toán Di truyền, Tối ưu hóa Bầy đàn, ADMM, v.v. đã giải quyết vấn đề học tập mà không sử dụng GD. Tuy nhiên, chúng không thể hiện sự tiết kiệm năng lượng-thời gian đặc biệt cũng như không hiệu quả về bộ nhớ và có thể mở rộng. Các phương pháp hợp lý về mặt sinh học như tính toán Siêu chiều (HD) và Mạng nơ-ron Spike (SNN) thể hiện việc học tập hiệu quả về năng lượng và/hoặc bộ nhớ; tuy nhiên, việc huấn luyện các trọng số và đầu vào được biểu diễn nhị phân này thành công nhất dựa trên sự xấp xỉ từ các NN điểm nổi với chưng cất. Phương pháp Hướng Luân phiên của Multipliers (ADMM) [5] phân tách việc huấn luyện mạng thành một chuỗi các bước phụ có thể được giải quyết như các bài toán bình phương tối thiểu tuyến tính đơn giản, ví dụ, sử dụng pseudoinverse Moore-Penrose (MP). ADMM tối ưu hóa mỗi lớp sử dụng lớp tiếp theo như một điều kiện (nhân tử Lagrange). Như vậy, nó là một thuật toán chỉ truyền tiến. Các biến thể ADMM (Scalable ADMM, dlADMM, pdADMM [6, 7, 8]) đã cố gắng sử dụng hiệu quả các tài nguyên phần cứng có sẵn và giảm thời gian tính toán. Tuy nhiên, chúng cần nhiều lần lặp để hội tụ đến giải pháp cuối cùng. Mặc dù tương đối trưởng thành và có thể mở rộng cho các vấn đề lớn, thời gian học tập của ADMM vẫn dài hơn nhiều so với các phương pháp GF khác như KPnet [9].

Hầu hết các phương pháp gradient-free đã chứng minh hiệu suất của chúng trong các mô hình NN nông và trong các lớp kết nối đầy đủ. Chúng ít chính xác hơn so với các mô hình NN sâu được huấn luyện bằng BP cũng như không thể mở rộng. Tuy nhiên, sự kết hợp của các phương pháp này cho thấy một xu hướng đầy hứa hẹn. Ví dụ, KPnet kết hợp Máy học Cực đoan (ELM) [10] với mã hóa nhãn và lan truyền mục tiêu để tăng tốc độ huấn luyện và cải thiện khả năng mở rộng. LM-KARnet[9] huấn luyện với thời gian tiết kiệm 10-100X trong các mạng nông. ZORB [11] là một thuật toán huấn luyện GF khác kết hợp việc huấn luyện nhanh của ELM và pseudoinverse MP. Nó nhanh hơn 300X so với bộ tối ưu hóa Adam trên các mạng nông và cũng đạt được độ chính xác tương đương.

Frenkel và cộng sự đã đề xuất Direct Random Target Projection (DRTP) [12, 13], một phương pháp giới thiệu phép chiếu mục tiêu vào các thuật toán học tập GD mà không cần phản hồi. DRTP giảm nhẹ hai vấn đề BP chính (vấn đề vận chuyển trọng số và khóa cập nhật) bằng cách cho phép mỗi lớp được cập nhật với thông tin cục bộ khi đánh giá tiến diễn ra. Nó cho phép huấn luyện các lớp ẩn với chi phí tính toán và bộ nhớ thấp. Khái niệm tính cục bộ đã được chứng minh hoạt động trên 1-2 lớp nông, và DRTP được triển khai trong một bộ xử lý CNN dựa trên sự kiện [14] chỉ yêu cầu 16,8% công suất và 11,8% chi phí diện tích silicon. Dựa trên khái niệm này, chúng tôi đề xuất một thuật toán tối ưu hóa mới không cần backpropagation gọi là target projection Stochastic Gradient Descent (tpSGD), có khả năng huấn luyện các mô hình NN tại edge. tpSGD huấn luyện mạng nơ-ron từng lớp một chỉ sử dụng các lần truyền tiến. Theo như chúng tôi biết, tpSGD là phương pháp đầu tiên mở rộng huấn luyện cục bộ cho hàm mất mát tùy ý, sử dụng phép chiếu mục tiêu để huấn luyện RNN, và mở rộng khái niệm tính cục bộ đến mạng nơ-ron sâu (DNN). Cụ thể hơn, chúng tôi không tập trung vào việc tinh chỉnh toàn bộ mạng tại edge. Thay vào đó, chúng tôi nghiên cứu liệu tpSGD có thể tinh chỉnh các lớp nông được tối ưu hóa để thích ứng với môi trường mới với việc sử dụng bộ nhớ ít hơn, tính toán hiệu quả hơn và hội tụ nhanh hơn hay không. Tóm lại, tpSGD có các tính năng độc đáo sau:

• Tính toán hiệu quả cục bộ trên mỗi lớp sử dụng SGD và phép chiếu mục tiêu. Phương pháp của chúng tôi thực hiện tương đương với GD BP (trong vòng 1% độ chính xác) trên các mạng tương đối nông với 1-6 lớp tích chập và/hoặc kết nối đầy đủ có thể huấn luyện, trong khi loại bỏ nhu cầu giữ lại và tính toán thông qua mạng trong lần truyền ngược.

• Mở rộng phép chiếu mục tiêu cho các lớp tích chập đa kênh thông qua lấy mẫu dựa trên bộ lọc, cho phép huấn luyện CNN.

• Mở rộng phép chiếu mục tiêu cho mạng nơ-ron hồi quy (RNN) (tiêu chuẩn, RNN đa lớp xếp chồng và RNN hai chiều), chứng minh việc học tập không tầm thường và trong nhiều trường hợp, thực hiện trong vòng 5% độ chính xác của các mạng được huấn luyện bằng BP trên một số tập dữ liệu chuẩn.

• Chứng minh hiệu suất tiên tiến (SoA) và giảm thời gian huấn luyện so với các thuật toán khác không cần BP (ví dụ: dlADMM, ZORB, KARnet).

• Có thể mở rộng cho DNN bằng cách huấn luyện các adaptor mạng nông được tối ưu hóa kết nối với các bộ mã hóa DNN cố định.

## 2 Phương pháp

### 2.1 Phép chiếu mục tiêu và Lan truyền mục tiêu

Trong lan truyền mục tiêu [11], các nhãn được "lan truyền" ngược thông qua mạng bằng cách đảo ngược tuần tự từng thao tác (lớp và kích hoạt) để có được đầu ra tương ứng với các nhãn. Ví dụ, đối với một lớp tuyến tính zi=xiWi, điều này bao gồm việc có được một giá trị xấp xỉ cho nghịch đảo của các trọng số lớp Wi† thông qua pseudoinverse MP với xi là đầu vào từ đầu ra của lớp trước đó i−1 và zi là các đặc trưng đầu ra của lớp i được lan truyền mục tiêu từ các nhãn thông qua việc đảo ngược của các lớp cuối cùng N−i.

Trong phép chiếu mục tiêu [15, 12], các mã hóa một-nóng của các nhãn được chiếu trực tiếp lên một lớp cho trước trong bước tối ưu hóa. Với một lớp trung gian Li trong một NN, chúng tôi tạo ra các mục tiêu cục bộ yi cho lớp bằng cách chiếu các nhãn dữ liệu y thông qua một ma trận chiếu ngẫu nhiên (Pi). Trọng tâm của tpSGD là cung cấp một thuật toán không cần BP nhanh và có thể mở rộng để huấn luyện NN, vì vậy chúng tôi đã chọn phép chiếu mục tiêu, thay thế nhu cầu đảo ngược tất cả các lớp và kích hoạt sau một lớp cho trước, bằng một phép nhân ma trận duy nhất.

### 2.2 Target Projection SGD

tpSGD được thiết kế với mục tiêu mở rộng việc huấn luyện không cần BP cho các tập dữ liệu lớn hơn và mạng sâu hơn cần thiết cho các nhiệm vụ phức tạp. Không giống như ZORB [11] hoặc LM-KARnet [9], trước tiên chúng tôi sử dụng tối ưu hóa dựa trên GD cho các lớp riêng lẻ thay vì pseudoinverse MP tối ưu hóa trọng số trên toàn bộ tập dữ liệu cùng một lúc. Trong khi ZORB và LM-KARnet gặp khó khăn trong việc xử lý toàn bộ tập dữ liệu CIFAR (đặc biệt khi bao gồm tích chập), thuật toán của chúng tôi có thể xử lý chúng theo lô cung cấp nhiều tự do hơn để mở rộng cho các tập dữ liệu và nhiệm vụ với yêu cầu bộ nhớ lớn hơn. Thứ hai, và trái ngược với BP, tính toán một lần truyền tiến và ngược đầy đủ thông qua mạng, tpSGD là một thuật toán tối ưu hóa chỉ feedforward. Trong tpSGD, chúng tôi huấn luyện mỗi lớp trong mạng tuần tự bắt đầu từ các lớp gần nhất với đầu vào. Đối với một lớp cho trước Li trong một NN với i ∈ {2...N} lớp, đầu vào cho lớp đó xi được thu được bằng cách chạy lần truyền tiến qua tất cả các lớp trước đó j = 1 đến i−1. Đầu ra mục tiêu yi được thu được thông qua một phép chiếu ngẫu nhiên của mã hóa một-nóng của các nhãn dữ liệu. Đầu vào xi và mục tiêu được chiếu yi được sử dụng để huấn luyện lớp sử dụng bộ tối ưu hóa Adam và Lỗi Bình phương Trung bình (MSE) giữa các dự đoán và yi (trước hoặc sau kích hoạt). Khi một lớp được huấn luyện, chúng tôi cố định các trọng số và chuyển sang lớp tiếp theo theo cùng một phương pháp cho đến khi đạt đến lớp cuối cùng vì chúng tôi không còn yêu cầu phép chiếu. Các phần tiếp theo sẽ thảo luận về các kết nối với các thuật toán huấn luyện dựa trên phép chiếu hiện có trước khi chuyển sang chi tiết về việc tạo ra các ma trận chiếu ngẫu nhiên Pi cho các lớp có thể huấn luyện khác nhau được hỗ trợ: dense, tích chập 2d và hồi quy.

### 2.3 Kết nối với các Thuật toán Huấn luyện Dựa trên Phép chiếu Hiện có

tpSGD có mối liên hệ chặt chẽ với một số thuật toán huấn luyện dựa trên phép chiếu, không cần BP nổi bật. Trong một số trường hợp, tpSGD hoạt động như một tổng quát hóa. Chúng tôi nêu bật các kết nối giữa Direct Feedback Alignment (DFA) [13], Error-Sign-Based Direct Feedback Alignment (sDFA) [12], Direct Random Target Projection (DRTP) [12], và phương pháp tpSGD mới của chúng tôi (tpSGD sử dụng lỗi ℓ1 theo lớp (tpSGD ℓ1) và lỗi ℓ2 (tpSGD ℓ2)).

Xem xét trường hợp của một lớp tuyến tính đơn giản i với hàm kích hoạt phi tuyến: yi = σi(zi) = σi(xiWi). Chúng tôi định nghĩa các đại lượng sau, J(·) là một hàm mất mát, xi là đầu vào của lớp i, yi là đầu ra của lớp i, Wi là các trọng số liên kết với lớp i, σi(·) là hàm kích hoạt phi tuyến liên kết với lớp i, ∇yi là gradient mất mát ước tính cho các đầu ra của lớp i, yN là đầu ra dự đoán của lớp cuối cùng, y là mã hóa một-nóng sự thật cơ bản của các nhãn, σ'i(·) là đạo hàm của hàm kích hoạt phi tuyến của lớp i, Pi là ma trận chiếu phụ thuộc lớp của các mục tiêu cho lớp i, và α là tốc độ học tập.

Trong Bảng 1, chúng tôi kiểm tra các mục tiêu tối ưu hóa của các thuật toán nói trên và điều tra cách điều này ảnh hưởng đến các bước cập nhật trọng số tại lớp i. Các quy tắc cập nhật trọng số theo lớp tương tự nhau, nhưng mỗi thuật toán có những điểm khác biệt tinh tế trong các giả định của chúng, dẫn đến các hành vi tối ưu hóa khác nhau và tính linh hoạt trong các loại pipeline huấn luyện mà chúng tương thích.

DFA, sDFA, và DRTP đều cố gắng tối thiểu hóa một mục tiêu toàn cục (cross-entropy giữa các nhãn sự thật cơ bản và đầu ra lớp cuối cùng) sử dụng các bước gradient nhiễu. DFA và sDFA yêu cầu một lần truyền tiến hoàn chỉnh thông qua mạng. Sau đó, các phương pháp này tính toán gradient mất mát ước tính cho một lớp cho trước dựa trên các phép chiếu ngẫu nhiên của gradient của mất mát tại lớp cuối cùng. sDFA chỉ sử dụng dấu của gradient mất mát trong khi DFA sử dụng toàn bộ độ lớn của gradient mất mát. Vì cả hai phương pháp đều yêu cầu một lần truyền đầy đủ thông qua mạng, chúng không tương thích với tpSGD.

DRTP tận dụng thực tế rằng các nhãn là mã hóa một-nóng để đơn giản hóa sDFA, trong đó gradient mất mát của DRTP là một đại diện của sDFA với các thao tác dịch chuyển và tái tỷ lệ được áp dụng. Theo lý luận của Frenkel và cộng sự [12], chúng tôi xem xét hành vi của gradient mất mát esdf a = sign(y − yN) khi y*c là 1 và khi y*c là 0. Chúng tôi giả sử y*c ∈ {0, 1} (tức là, nhãn sự thật cơ bản cho một lớp cho trước chính xác là không hoặc một) và yNc ∈ (0, 1) (tức là, dự đoán của lớp cuối cùng cho một lớp cho trước nằm trong khoảng không đến một, không bao gồm). Dưới giả định này, y*c không bao giờ chính xác bằng yNc (tức là, luôn có một số lỗi dự đoán). Gradient mất mát cho sDFA có thể được biểu diễn như:

esdf ac = sign(y*c − yNc) = {
  +1 nếu c = c*
  -1 nếu ngược lại; y*c ≠ yNc
}

c* là chỉ số của vector một-nóng và c là lớp thực.

Quan sát chính ở đây là esdf ac sẽ luôn là +1 khi y* = 1, và nó sẽ luôn là -1 khi y* = 0, bất kể các giá trị của dự đoán yN, hiệu quả tách rời gradient mất mát ước tính khỏi các dự đoán lớp cuối cùng. Gradient mất mát liên kết với DRTP đơn giản là một tỷ lệ và dịch chuyển của esdf ac dưới các giả định trên:

edrtpc = (1 + sign(y*c − yNc))/2 = {
  1 nếu c = c*
  0 nếu ngược lại; y*c ≠ yNc
}

Lưu ý edrtp = y*, có nghĩa là các nhãn một-nóng có thể phục vụ như gradient ước tính của mất mát. Để có được gradient theo lớp w.r.t. mất mát toàn cục, DRTP sử dụng một ma trận chiếu ngẫu nhiên để chiếu các nhãn một-nóng này như gradient mất mát ước tính cho mục tiêu toàn cục. Frenkel và cộng sự đã chỉ ra rằng đối với các mạng bao gồm số lượng tùy ý các lớp tuyến tính theo sau bởi một kích hoạt phi tuyến với cross-entropy như hàm mất mát, DRTP tạo ra gradient ước tính trong vòng 90° của gradient BP, dẫn đến việc học tập, và họ đã xác nhận thực nghiệm rằng DRTP hoạt động với các kiến trúc feedforward ít bị ràng buộc hơn. DRTP không yêu cầu một lần truyền tiến đầy đủ trước khi cập nhật trọng số (không khóa cập nhật), và DRTP có thể cập nhật các lớp độc lập với nhau (không có vấn đề với vận chuyển trọng số), làm cho DRTP hoàn toàn tương thích với tpSGD. Các lớp khác nhau trong cùng một mạng có thể được tối ưu hóa thông qua tpSGD hoặc DRTP mà không có vấn đề gì. Trong phần còn lại của bài báo, chúng tôi coi DRTP như một tập con của các khả năng được cung cấp bởi tpSGD. Khi DRTP được đề cập, chúng tôi cụ thể đề cập đến các biến thể nói trên của các hàm chi phí và cập nhật trọng số.

Cuối cùng, chúng tôi xem xét việc học tập kiểu tpSGD mới của chúng tôi. Trái ngược với các phương pháp khác, tpSGD cố gắng tối thiểu hóa một tập hợp các mất mát cục bộ, với ý định học các biểu diễn thúc đẩy giảm mất mát toàn cục. tpSGD tối ưu hóa cục bộ các lớp, buộc các đầu ra lớp phải căn chỉnh với các phép chiếu ngẫu nhiên của các nhãn sự thật cơ bản một-nóng (phục vụ như các mục tiêu theo lớp để tối ưu hóa). tpSGD cố gắng học các biểu diễn sao cho các instance từ cùng một lớp được phân tách tốt khỏi các instance của các lớp khác trong cùng một lớp, và các biểu diễn từ hai lớp khác nhau nên được phân tách tốt khỏi nhau. tpSGD tương thích với bất kỳ mất mát theo lớp chung nào giữa các mục tiêu theo lớp và đầu ra theo lớp, nhưng chúng tôi xem xét rõ ràng chuẩn ℓ1 và chuẩn ℓ2 cho bài báo này.

### 2.4 Định nghĩa Phép chiếu Lớp

Trong tpSGD, chúng tôi cung cấp các mục tiêu học tập cho các lớp trung gian bằng cách chiếu các nhãn sự thật cơ bản thông qua các ma trận được tạo ngẫu nhiên. Phần này thảo luận về các chiến lược chiếu cho các lớp tuyến tính, tích chập và hồi quy trong tpSGD.

**Phép chiếu lớp tuyến tính**
Trong trường hợp đơn giản nhất của một lớp kết nối đầy đủ với n-nút và một vấn đề phân loại với bs kích thước lô, nc lớp, chúng tôi ánh xạ một lô nhãn với kích thước (bs, nc) thành một với (bs, n) bằng cách nhân với một ma trận ngẫu nhiên P với kích thước (nc, n). Trong các thí nghiệm của chúng tôi, chúng tôi đã thử nghiệm lấy mẫu từ các hàm phân phối khác nhau (đều, bình thường, ...), nhưng không thấy sự khác biệt đáng chú ý về hiệu suất.

**Phép chiếu lớp Conv2D**
Để mở rộng phép chiếu mục tiêu thông qua ma trận ngẫu nhiên cho CNN, chúng tôi đã triển khai hai phương pháp để tạo ra các đặc trưng mục tiêu cho các lớp Conv2D trung gian này, được minh họa trong Hình 2 a) và b).

Giả sử đầu ra của một lớp Conv2D cho trước có kích thước (bs, nx, ny, nf), trong đó bs là kích thước của mini-batch đang được xử lý, nx và ny là kích thước x và y của hình ảnh được lọc, và nf là số lượng bộ lọc. Trong bảng a), phương pháp ngây thơ, chúng tôi tạo ra một ma trận chiếu duy nhất, dài P với kích thước (nc, nx × ny × nf) và định hình lại đầu ra để khớp với kích thước mục tiêu. Trong bảng b), chúng tôi đề xuất một phương pháp lấy mẫu dựa trên bộ lọc: chúng tôi tạo ra nf ma trận chiếu khác nhau Pi với kích thước (bs, nx × ny) cho mỗi bộ lọc i ∈ {1, 2, ..., nf}, lấy mẫu từ một phân phối ngẫu nhiên khác nhau cho mỗi bộ. Chúng tôi lấy mẫu từ các phân phối bình thường với độ lệch chuẩn thay đổi trong khoảng [0, 1) tại các khoảng cách đều σi = i/nf.

Hình 3 cho thấy sự khác biệt về hiệu suất giữa hai phương pháp lấy mẫu này. Một mô hình bao gồm một lớp Conv2D, kích hoạt leaky ReLU và một lớp phân loại tuyến tính cuối cùng đã được huấn luyện sử dụng thuật toán tpSGD của chúng tôi trên MNIST sử dụng cả phương pháp lấy mẫu cơ bản và phương pháp lấy mẫu dựa trên bộ lọc được đề xuất. Trong khi lấy mẫu cơ bản cho thấy ít hoặc không có cải thiện khi số lượng bộ lọc trong lớp tăng, các phép chiếu lấy mẫu dựa trên bộ lọc cho thấy cải thiện ổn định, mặc dù với lợi ích giảm dần. Trong các nghiên cứu của chúng tôi, chúng tôi đã quan sát thấy một sự gia tăng nhỏ, không đổi trong thời gian huấn luyện do chi phí tăng lên trong việc khởi tạo các phép chiếu cho mỗi lớp Conv2D.

**Phép chiếu lớp hồi quy**
Công việc trước đây [12] đã chỉ ra rằng phép chiếu mục tiêu có thể huấn luyện các mạng feedforward. Theo như chúng tôi biết, phép chiếu mục tiêu trước đây chưa được chỉ ra hoạt động với mạng nơ-ron hồi quy (RNN). Chúng tôi mô tả cách các lớp hồi quy có thể được mô hình hóa sao cho các sửa đổi đơn giản của DRTP và tpSGD làm cho phép chiếu mục tiêu trở thành một thuật toán hiệu quả để huấn luyện RNN. Trong các phần tiếp theo, chúng tôi chứng minh thực nghiệm lần đầu tiên rằng phép chiếu mục tiêu ngẫu nhiên thúc đẩy việc học tập trong các mạng hồi quy.

Chúng tôi công thức hóa một tế bào hồi quy đơn giản (được mô tả trong Phụ lục C), tính toán như sau:
Ht+1 = sigmoid(HtWH + bH + XtWX + bX)

trong đó Ht là đầu vào trạng thái ẩn tại thời điểm t, Xt là các đặc trưng đầu vào tại thời điểm t, WH, bH, WX, và bX là các tham số có thể học được của tế bào (được chia sẻ trên tất cả các bước thời gian), và Ht+1 là trạng thái ẩn phục vụ như đầu vào cho bước thời gian tiếp theo. Mặc dù có các loại tế bào phức tạp hơn được sử dụng trong thực tế (ví dụ: tế bào LSTM [16] và GRU [17]), chúng được thiết kế để giải quyết các vấn đề với việc mô hình hóa các phụ thuộc tầm xa (ví dụ: gradient biến mất), mà các phương pháp dựa trên phép chiếu ngẫu nhiên không mẫn cảm, vì vậy chúng tôi không xem xét chúng cho bài báo này.

Để áp dụng TP cho tế bào hồi quy này, tương tự như BP qua thời gian [18], chúng tôi mở rộng tế bào hồi quy theo thời gian cho một độ dài chuỗi cố định cụ thể cho vấn đề (xem Phụ lục C). Điều này tạo ra một mạng giống feedforward trong đó mỗi lớp chia sẻ một tập hợp các tham số có thể học được chung nhưng sử dụng đầu ra trạng thái ẩn bởi lớp trước đó với các đặc trưng đầu vào phụ thuộc bước thời gian.

Chúng tôi thấy hai sự khác biệt chính giữa lớp hồi quy được mở rộng và MLP feedforward chung: 1) có hai hàm tuyến tính cung cấp vào phi tuyến tính cho mỗi "lớp" được mở rộng, và 2) các trọng số được chia sẻ giữa các "lớp" được mở rộng. Sự khác biệt đầu tiên được xử lý bằng cách cập nhật các tham số của mỗi hàm riêng biệt. Đối với (2), chúng tôi có thể tận dụng thực tế rằng chúng tôi có thể đóng băng các trọng số của tế bào hồi quy cho lần lặp huấn luyện hiện tại và cập nhật trên tất cả các bước thời gian đồng thời, tức là, với các trọng số bị đóng băng, một lần truyền tiến qua tế bào hồi quy được mở rộng là:

[H1, H2, ..., Hend]^T = [H0X0, H1X1, ..., HNXN] [WH, WX] ⊕ (bH + bX)

trong đó ⊕ biểu thị phép cộng theo hàng của một vector vào một ma trận. Vì các trọng số này bị đóng băng và được cập nhật đồng thời cho tất cả các bước thời gian và tpSGD không thực thi bất kỳ yêu cầu lan truyền ngược nào, các H có thể được coi như các đầu vào độc lập. Sau đó, công thức trên của lớp hồi quy tương đương với một lớp tuyến tính feedforward cộng với kích hoạt phi tuyến.

Khi tính toán gradient của WH, không có sự phụ thuộc vào X và khi tính toán gradient của WX, không có sự phụ thuộc vào H, vì vậy mỗi tập hợp tham số có thể được cập nhật riêng biệt: khi WH được cập nhật, WX bị đóng băng và ngược lại. Thứ hai, khi gradient được tính toán sử dụng công thức này, nó tương đương với việc tính toán gradient trên mỗi (Ht, Xt) riêng biệt và tổng trên tất cả các bước thời gian (tức là, tích lũy gradient). Điều này có nghĩa là chúng tôi có thể tính toán các pseudo-gradient riêng lẻ cho mỗi bước thời gian và tổng hoặc trung bình chúng trên tất cả các bước thời gian, chỉ lưu trữ các gradient tích lũy, giảm yêu cầu bộ nhớ. Để huấn luyện các tham số của một tế bào hồi quy cho một bước thời gian cho trước, chúng tôi sử dụng các cập nhật sau, trong đó chúng tôi giả sử các ma trận chiếu khác nhau Bt cho các nhãn được mã hóa một-nóng tối ưu Y cho mỗi bước thời gian với tốc độ học tập α cho tpSGD ℓ1:

W^(k+1)_H, b^(k+1)_H = W^(k)_H, b^(k)_H + α∇W_H, ∇b_H^(k)

W^(k+1)_X, b^(k+1)_X = W^(k)_X, b^(k)_X + α∇W_X, ∇b_X^(k)

∇W_H, ∇b_H = Σ(t=0 to N) H^T_t [1^T, D_H]; ∇W_X, ∇b_X = Σ(t=0 to N) X^T_t [1^T, D_H]

D_H = sign(YB_t - H_{t+1}) ⊙ H_{t+1} ⊙ (1 - H_{t+1})

trong đó ⊙ là phép nhân từng phần tử và "1" biểu thị scalar/vector/matrix tổng quát của tất cả các số một.

Chúng tôi có thể tương tự tạo ra các quy tắc cập nhật cho tpSGD ℓ2 và DRTP. Chúng tôi đã tìm thấy thực nghiệm rằng tpSGD ℓ2 thực sự chứng minh việc huấn luyện không tầm thường của RNN, nhưng nó hoạt động kém hơn đáng kể so với tpSGD ℓ1 và DRTP trong trường hợp này.

Các trọng số ban đầu của các tế bào hồi quy có thể là tất cả số không hoặc được vẽ đồng nhất ngẫu nhiên với độ lớn nhỏ. Để khởi tạo các ma trận chiếu cho tpSGD ℓ1, chúng tôi sử dụng các ma trận nhị phân ngẫu nhiên với các hàng gần như trực giao. Để khởi tạo các ma trận chiếu cho DRTP, chúng tôi sử dụng các ma trận ngẫu nhiên với các hàng trực giao.

Các trọng số có thể được cập nhật cục bộ sử dụng nhiều lần truyền tiến qua lớp hồi quy trước khi gửi vector đặc trưng Hend cuối cùng đến lớp tương thích tpSGD tiếp theo. Điều này có nghĩa là việc mở rộng hệ thống thành RNN xếp chồng [19] là rất dễ dàng và với các sửa đổi đơn giản, tế bào hồi quy có thể được làm cho tương thích với RNN hai chiều [20].

## 3 Thí nghiệm và Kết quả

Chúng tôi so sánh tpSGD với BP trên một tập hợp các nhiệm vụ phân loại và các tập dữ liệu khác nhau, và các kết hợp của các lớp Linear, Conv2D, và Recurrent để nghiên cứu hiệu quả của thuật toán có thể mở rộng. Chúng tôi cũng so sánh nó với một loạt các thuật toán không cần backpropagation được thiết kế đặc biệt để hoạt động tại edge. Cả ZORB và LM-KARnet đều tiêu thụ toàn bộ tập dữ liệu trong một bước duy nhất trong quá trình tối ưu hóa. Chúng xuất sắc trong việc huấn luyện với các tập dữ liệu nhỏ, nhưng thất bại trong việc mở rộng cho các tập dữ liệu lớn, NN sâu và các nhiệm vụ phức tạp.

### 3.1 Mạng nông, MNIST và CIFAR

Chúng tôi bắt đầu bằng cách nghiên cứu các mạng nông trên MNIST [21] và CIFAR [22]. Bảng 2 cho thấy so sánh giữa tpSGD được đề xuất, ZORB và LM-KARNet trên MNIST sử dụng MLP 2 lớp với kích hoạt leaky ReLU. Chúng tôi báo cáo giá trị trung bình và độ lệch chuẩn trong ngoặc đơn trên 25 lần khởi động lại ngẫu nhiên cho thời gian huấn luyện và độ chính xác mô hình. Tất cả ba thuật toán được đánh giá bằng cách sử dụng các triển khai trong TensorFlow 2.9 chạy trên một GPU NVIDIA RTX A5000 duy nhất. Mặc dù hiệu suất của tpSGD thấp hơn cả ZORB và LM-KARNet 1-2%, chúng tôi thấy tiết kiệm thời gian đáng kể cho tpSGD. Trong khi cả ZORB và LM-KARnet đều sử dụng nghịch đảo MP để có được các trọng số mới, LM-KARnet thay thế lan truyền mục tiêu trong ZORB bằng phép chiếu ngẫu nhiên. Điều này giải thích cho sự tăng tốc đáng kể khi so sánh thời gian huấn luyện của chúng: ZORB đảo ngược từng lớp bắt đầu từ đầu ra trong khi LM-KARnet chiếu sử dụng một ma trận ngẫu nhiên duy nhất. Tuy nhiên, LM-KARnet vẫn sử dụng nghịch đảo MP để tối ưu hóa trọng số của mỗi lớp. Thay thế thao tác đắt tiền này trong tpSGD dẫn đến giảm thêm thời gian huấn luyện với mất mát độ chính xác gần như không đáng kể.

Trong Bảng 3, chúng tôi so sánh hiệu suất (trung bình và độ lệch chuẩn trên mỗi metric) của một mô hình nông bao gồm hai lớp Conv2D với kích hoạt leaky ReLU, và một lớp Linear cuối cùng trên MNIST và CIFAR-10 sử dụng cùng các cài đặt được mô tả trước đó. Kết quả cho thấy rằng tpSGD có thể gần như khớp với độ chính xác (trong vòng 1%) và thời gian huấn luyện với BP. Phụ lục A khám phá việc mở rộng của tpSGD (so với BP) chi tiết hơn trong CNN với tối đa 7 lớp có thể huấn luyện (Dense và Conv2D).

### 3.2 VGG và Imagenette

Tiếp theo, chúng tôi thí nghiệm mở rộng tpSGD cho các hình ảnh lớn và mạng sâu hơn. Cho điều này, chúng tôi sử dụng Imagenette [23], một tập con của 10 lớp dễ từ Imagenet [24]. Imagenette bao gồm khoảng 1000 hình ảnh màu, ít nhất 320x320 pixel về kích thước. Hàng đầu tiên trong Bảng 4 so sánh hiệu suất giữa các mạng VGG11 (với 11 lớp có thể huấn luyện) được huấn luyện từ một khởi tạo ngẫu nhiên sử dụng BP và tpSGD. Chúng tôi báo cáo trung bình và biến thiên (trong ngoặc đơn) của hiệu suất trên 25 lần khởi động lại ngẫu nhiên. Chúng tôi trình bày chứng minh thực tế đầu tiên của việc huấn luyện không cần backpropagation được áp dụng cho hình ảnh và mạng ở quy mô này, kết quả SoA được thu được bởi tpSGD (≈ 65%) là khoảng 10-15% giảm hiệu suất so với đường cơ sở BP.

Với thách thức của việc mở rộng trực tiếp tpSGD, chúng tôi đã nghiên cứu một phương pháp thay thế để mở rộng cho DNN bằng cách thích ứng với domain-shift với các NN adaptor nông chạy tpSGD. Khái niệm là thiết kế và tối ưu hóa một số lớp adaptor kết nối với các lớp của DNN được huấn luyện trước. Trong quá trình học tập, chỉ các trọng số adaptor nông được huấn luyện và DNN được huấn luyện trước được cố định. Khác với các phương pháp tinh chỉnh SoA, các cấu hình của các adaptor tại edge được xác định thông qua tìm kiếm kiến trúc mạng [25] và được tối ưu hóa dựa trên phát hiện out-of-distribution [26]. Thảo luận về những điều này không phải là trọng tâm của bài báo này. Hàng thứ hai và thứ ba trong Bảng 4 cho thấy các nghiên cứu sử dụng tpSGD và BP trong bối cảnh học chuyển giao. Hàng thứ hai cho thấy phương pháp đường cơ sở sử dụng BP để tinh chỉnh các lớp kết nối đầy đủ cuối cùng trong mạng. Để so sánh, hàng thứ ba cho thấy hiệu suất thu được sử dụng tpSGD và BP sử dụng một cấu hình adaptor nhẹ thu được thông qua tìm kiếm kiến trúc mạng cơ bản (NAS) (chi tiết được thảo luận trong phụ lục B). Adaptor bao gồm: Conv2D(filters=64, kernel size=5, strides=1), LeakyReLU, Dense(256), LeakyReLU, Dense(n classes=10).

Mô hình được huấn luyện sử dụng tpSGD trên adaptor nằm trong vòng 3-5% của kết quả thu được sử dụng BP và Adam trên tinh chỉnh VGG16 echo kết quả được hiển thị trong các phần trước đó thảo luận về mạng nông, trong khi giảm đáng kể dấu chân trong bộ nhớ do kiến trúc adaptor được chọn. Chúng tôi hình dung việc tận dụng một bộ trích xuất đặc trưng được huấn luyện trước và được lượng tử hóa hoặc cắt tỉa trên phần cứng chuyên dụng cùng với các adaptor nông dựa trên tpSGD để cho phép huấn luyện trên các thiết bị edge sau khi triển khai và thích ứng với các miền mới, nhiệm vụ mới và dịch chuyển phân phối.

### 3.3 Phân tích Chuỗi Thời gian sử dụng Mạng Nơ-ron Hồi quy

Chúng tôi cũng đã tiến hành thí nghiệm trên một loạt các tập dữ liệu với các thuộc tính khác nhau giữa chúng (xem Bảng 6 trong Phụ lục D), để xác thực việc huấn luyện các lớp hồi quy kết hợp với perceptron đa lớp để phân loại dữ liệu chuỗi thời gian. Trong trường hợp của các tập dữ liệu UCF101 và "Twitter Sentiment Analysis - Word2Vec Encoding", chúng tôi sử dụng một mô hình bên ngoài để trước tiên tiền xử lý dữ liệu thành các vector đặc trưng. Tất cả các tập dữ liệu khác hoạt động trên các biểu diễn thô.

Chúng tôi xem xét ba thí nghiệm: (1) một RNN một lớp kết hợp với một bộ phân loại tuyến tính trong Bảng 5, (2) một RNN hai lớp xếp chồng kết hợp với một perceptron hai lớp (Bảng 7 của Phụ lục E), và (3) một RNN Hai chiều một lớp kết hợp với một bộ phân loại tuyến tính (Bảng 8 của Phụ lục E). Trong mỗi trường hợp, chúng tôi sử dụng kích thước vector ẩn 512, kích thước lô 128, và huấn luyện trong 20 epoch. Chúng tôi so sánh với cơ hội ngẫu nhiên, một mạng hoàn toàn ngẫu nhiên với cấu trúc tương đương, một mạng trong đó RNN là ngẫu nhiên, nhưng bộ phân loại được huấn luyện, và một mô hình tương đương về cấu trúc chỉ được huấn luyện sử dụng backpropagation. Chúng tôi cũng chứng minh rằng phương pháp huấn luyện hiệu quả với DRTP hoặc tpSGD ℓ1 như bộ tối ưu hóa cho các lớp hồi quy, và hiệu suất thường tương tự.

Chúng tôi xác minh rằng có việc học tập không tầm thường của (các) lớp hồi quy bằng cách so sánh mô hình với các lớp hồi quy có trọng số ngẫu nhiên + bộ phân loại được huấn luyện với mô hình trong đó cả các lớp hồi quy và bộ phân loại đều được huấn luyện sử dụng phép chiếu mục tiêu. Chúng tôi thấy cải thiện đáng kể trong tất cả các trường hợp ngoại trừ tập dữ liệu Seizure Activity Recognition trong đó ngay cả các đặc trưng ngẫu nhiên đạt được hiệu suất tương đối cao.

Chúng tôi cũng so sánh hiệu suất của các mô hình dựa trên phép chiếu mục tiêu với hiệu suất của các mô hình dựa trên BP tiêu chuẩn vàng để hiểu mô hình học tập tốt như thế nào so với một "cận trên" và tương tự, so sánh với cơ hội ngẫu nhiên và các mô hình với trọng số ngẫu nhiên để và mô hình học tập tốt như thế nào so với một "cận dưới". Trong tất cả các trường hợp, mô hình được huấn luyện vượt trội đáng kể so với các mô hình hoàn toàn ngẫu nhiên. Nói chung, các mô hình được huấn luyện với phép chiếu mục tiêu hoạt động tốt. Mô hình dựa trên phép chiếu mục tiêu hoạt động trong vòng 5% độ chính xác của mô hình dựa trên backpropagation trên 3 (tpSGD ℓ1) / 4 (DRTP) trong số 6 tập dữ liệu. Một khoảng cách lớn hơn tồn tại khi được thử nghiệm trên cả hai dạng MNIST tuần tự, nhưng mô hình vẫn thể hiện hiệu suất đáng kể.

Kết quả tương tự được thấy cho các RNN xếp chồng và hai chiều. Một quan sát thú vị về các mô hình này là hiệu suất rất tương tự với mô hình RNN một lớp cơ bản với bộ phân loại tuyến tính. Điều này gợi ý rằng phép chiếu mục tiêu không ngăn cản các RNN xếp chồng và hai chiều học các biểu diễn có ý nghĩa.

## 4 Kết luận và Công việc Tương lai

Trong bài báo này, chúng tôi đã khám phá một thuật toán tối ưu hóa mới không cần BP, chỉ feedforward được thiết kế để cho phép huấn luyện trong môi trường hạn chế tài nguyên, chẳng hạn như các thiết bị edge. Chúng tôi đã thảo luận về các kết nối giữa tpSGD và các thuật toán không cần BP hiện có khác và so sánh hiệu suất của chúng khi huấn luyện trong các kiến trúc như MLP, CNN và RNN. Chúng tôi đã phát hiện ra rằng tpSGD trong huấn luyện thực hiện tương đương với BP SGD và các thuật toán không cần BP trong MLP, CNN và RNN nông, và vượt trội hơn các thuật toán không cần BP khác về mặt bộ nhớ và thời gian. Cuối cùng, chúng tôi đã chỉ ra rằng tpSGD mở rộng cho DNN sử dụng học chuyển giao thông qua khái niệm adaptor nông được tối ưu hóa. Mặc dù việc huấn luyện DNN đầy đủ dựa trên tpSGD hoạt động kém hơn so với BP SGD, các thuật toán hiệu quả để huấn luyện các adaptor nông kết nối với các bộ mã hóa cố định. Kiến trúc mở rộng thay thế này có tiềm năng lớn cho việc học tập trên thiết bị trong các tình huống edge để giải quyết dịch chuyển miền, nhiệm vụ mới và các vấn đề thách thức tương tự khác.

Đối với công việc tương lai, chúng tôi mong muốn hiểu rõ hơn tpSGD từ góc độ lý thuyết. Chúng tôi đã nhận thấy rằng các mô hình dựa trên tpSGD dường như không đạt được tiềm năng đầy đủ của chúng trong DNN. Chúng tôi giả thuyết rằng điều này có thể do (sự kết hợp của) hai lý do: (1) các mô hình phức tạp hơn có thể không cần thiết cho các tập dữ liệu chuẩn tương đối đơn giản; (2) bởi vì các lớp của mô hình được huấn luyện mà không có phản hồi từ các lớp sau đến các lớp trước, các mô hình phức tạp hơn này có thể bị hạn chế quá mức trong những gì chúng có thể học, do đó cho thấy sự tăng trưởng tối thiểu trong hiệu suất.

Từ việc lấy mẫu dựa trên bộ lọc trong CNN, chúng tôi đã nhận thấy rằng việc lựa chọn cẩn thận phân phối chiếu mục tiêu đặc biệt là quan trọng. Trong tương lai, chúng tôi muốn khám phá liệu chúng tôi có thể học phân phối của các phép chiếu mục tiêu theo lớp từ các mô hình được huấn luyện trước cho tập dữ liệu thay vì ước tính mù quáng các phép chiếu này. Một hướng tương lai khác là phân tích tương quan eigenvector giữa các mẫu dữ liệu đầu vào dựa trên Jacobian trên mỗi lớp [25] sao cho phép chiếu ngẫu nhiên được chọn với sự dư thừa ít nhất giữa các phép chiếu ước tính.

## Lời cảm ơn

Nghiên cứu này được dựa trên công việc được hỗ trợ một phần bởi Văn phòng Giám đốc Tình báo Quốc gia (ODNI), Hoạt động Nghiên cứu Tiên tiến Tình báo (IARPA), thông qua Hợp đồng Số: 2022-21100600001. Các quan điểm và kết luận được chứa trong đây thuộc về các tác giả và không nên được diễn giải như nhất thiết đại diện cho các chính sách chính thức, được thể hiện rõ ràng hoặc ngụ ý, của ODNI, IARPA, hoặc Chính phủ Hoa Kỳ. Chính phủ Hoa Kỳ được ủy quyền tái tạo và phân phối các bản in cho các mục đích chính phủ bất chấp bất kỳ chú thích bản quyền nào trong đó.

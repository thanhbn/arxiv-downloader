# 2309.01825.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/optimizer/2309.01825.pdf
# Kích thước tệp: 3489204 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
LoopTune: Tối ưu hóa tính toán tensor với học tăng cường

Dejan Grubisic
Đại học Rice, Meta AI
Houston, TX, USA

Bram Wasti
Meta AI
New York, NY, USA

Chris Cummins
Meta AI
Menlo Park, CA, USA

John Mellor-Crummey
Đại học Rice
Houston, TX, USA

Aleksandar Zlateski
Meta AI, Dabun AI
New York, NY, USA

Tóm tắt — Công nghệ trình biên dịch tiên tiến rất quan trọng để cho phép các ứng dụng học máy chạy trên phần cứng mới, nhưng các trình biên dịch truyền thống không thể đạt hiệu suất, các bộ tự động điều chỉnh phổ biến có thời gian tìm kiếm dài và các thư viện được tối ưu hóa bởi chuyên gia tạo ra chi phí không bền vững. Để giải quyết vấn đề này, chúng tôi đã phát triển LoopTune, một trình biên dịch học tăng cường sâu tối ưu hóa các tính toán tensor trong các mô hình học sâu cho CPU. LoopTune tối ưu hóa thứ tự duyệt tensor trong khi sử dụng bộ tạo mã nhẹ siêu nhanh LoopNest để thực hiện các tối ưu hóa cụ thể cho phần cứng. Với biểu diễn dựa trên đồ thị mới và không gian hành động, LoopTune làm tăng tốc LoopNest lên 3.2x, tạo ra mã nhanh hơn một bậc so với TVM, nhanh hơn 2.8x so với MetaSchedule, và nhanh hơn 1.08x so với AutoTVM, liên tục thực hiện ở mức độ của thư viện được điều chỉnh thủ công Numpy. Hơn nữa, LoopTune điều chỉnh mã trong vòng vài giây.

Từ khóa chỉ mục — Trình biên dịch, co rút tensor, học tăng cường

I. GIỚI THIỆU

Những tiến bộ đương đại trong học máy (ML) đã khiến các nhà thiết kế chip phát triển vô số chip cực mạnh để phù hợp với các khối lượng công việc ML tính toán chuyên sâu. Ví dụ, Nvidia giới thiệu tensor cores [17], [44], Intel và AMD bổ sung các lệnh AVX [35], [43], FMA [67], và VNNI chuyên biệt [59], trong khi Google giới thiệu TPU [37]. Hơn nữa, các công ty phần cứng bắt đầu chế tạo chip cụ thể cho ML như Graphcore [36] và Cerebras [52].

Để khai thác đầy đủ sức mạnh của phần cứng tiên tiến, công nghệ trình biên dịch tiên tiến là điều bắt buộc. Tuy nhiên, các trình biên dịch truyền thống có một số hạn chế cản trở khả năng thực hiện điều này.

Đầu tiên, các trình biên dịch truyền thống đã được phát triển cho một tập hợp hạn chế các ISA với mô hình lập trình tương tự, làm cho việc thích nghi chúng với phần cứng kỳ lạ với tài nguyên chip khác nhau trở nên khó khăn. Ngay cả với sự phân tách front/back-end được giới thiệu bởi LLVM, nhiệm vụ vẫn đầy thách thức, bởi vì các biểu diễn truyền thống không dễ dàng được tối ưu hóa cho phần cứng mới.

Thứ hai, khi các trình biên dịch truyền thống được mở rộng để bao phủ nhiều trường hợp sử dụng hơn, chúng trở nên ngày càng phức tạp, với hàng trăm lượt tối ưu hóa thường phụ thuộc lẫn nhau. Sự phức tạp này làm tăng chi phí phát triển và bảo trì.

Cuối cùng, các kỹ thuật trình biên dịch truyền thống "bao quát tất cả" không thể tận dụng đầy đủ các tài nguyên mới có sẵn trên phần cứng mới nổi được thiết kế cho các khối lượng công việc cụ thể.

Liên hệ với Dejan Grubisic tại dejan.grubisic@rice.edu

Hình 1: Kiến trúc LoopStack.

Vậy, các lựa chọn thay thế cho trình biên dịch truyền thống của chúng ta là gì? Thư viện được tối ưu hóa bởi chuyên gia, bộ tự động điều chỉnh, hay cái gì khác?

Các thư viện được tối ưu hóa bởi chuyên gia đòi hỏi một khoản đầu tư thời gian khổng lồ từ các chuyên gia và công việc phải được lặp lại cho mỗi thiết bị mới. Các thư viện phép toán tensor hiệu suất cao như cuDNN [16], OneDNN [19], hoặc XNNPACK [28] thường gắn với một phạm vi hẹp các thiết bị phần cứng và có xu hướng lớn về kích thước mã, điều này có thể cản trở việc sử dụng chúng trên thiết bị di động.

Như một phương pháp thay thế, các dự án như Halide [51] và TVM [14] tối ưu hóa một biểu diễn cấp cao của một vòng lặp nest thực hiện tính toán tensor với một tập hợp rời rạc các biến đổi như sắp xếp lại vòng lặp và chia ô trước khi biên dịch nó thành phần cứng mục tiêu cụ thể với trình biên dịch LLVM. Phương pháp này cung cấp hiệu suất cao và loại bỏ nhu cầu về thư viện được tối ưu hóa bởi chuyên gia, nhưng giới thiệu một số lượng khổng lồ các lịch trình có thể.

Để tối ưu hóa một vấn đề đơn giản, chẳng hạn như Local Laplacian Filters, Halide ước tính giới hạn dưới là 10^720 lịch trình có thể [51]. Để tìm các lịch trình hiệu suất trong không gian rộng lớn như vậy, Halide và TVM sử dụng thuật toán di truyền và mô phỏng ủ song song với mô hình chi phí được huấn luyện [14] tương ứng. Cả hai phương pháp đều gặp phải thời gian biên dịch rất lớn.

Những đột phá đương đại trong học tăng cường sâu (deep RL) trong các trò chơi video phức tạp, chẳng hạn như những trò chơi trong Atari [47], và AlphaGo [56], đã truyền cảm hứng cho cộng đồng nghiên cứu trình biên dịch cố gắng tận dụng deep RL [13], [31], [32], [64]. Tương tự như các thuật toán lặp, tác nhân deep RL khám phá một không gian tối ưu hóa. Tuy nhiên, có một khác biệt quan trọng - kiến thức về không gian tìm kiếm được nhúng vào một mạng nơ-ron. Suy luận mạng nơ-ron sau đó thay thế một phần của việc tìm kiếm các tối ưu hóa. Điều này cho phép tìm kiếm không gian tối ưu hóa nhanh chóng, theo hướng ví dụ chính xác là những gì các trình biên dịch cụ thể cho ML, cũng như tổng quát, cần.

Trong công việc của chúng tôi, chúng tôi tiếp tục xây dựng trên các nỗ lực gần đây dựa trên RL trong nghiên cứu trình biên dịch bằng cách mở rộng LoopStack [65] - một backend trình biên dịch tensor siêu nhanh, với LoopTune để tìm một lịch trình vòng lặp hiệu suất với học tăng cường sâu (Hình 1). LoopTune thao tác không gian lịch trình vòng lặp thông qua một API gọi là LoopTool và tạo ra nhị phân từ lịch trình đã cho với LoopNest. Mục tiêu của LoopTune là huấn luyện mạng chính sách sẽ tìm ra lịch trình gần tối ưu cho vòng lặp nest đã cho trong vài bước, giảm thời gian tự động điều chỉnh xuống mức vài giây.

Trong bài báo này, chúng tôi trình bày các đóng góp mới sau đây:
• LoopTune - một khung deep RL tìm ra các phạm vi và lịch trình vòng lặp hiệu suất.
• Một phép nhúng dựa trên đồ thị mới của các tính toán tensor phù hợp cho học tăng cường.
• Một không gian hành động mới cho việc điều chỉnh tính toán tensor phù hợp cho huấn luyện RL.
• So sánh 5 thuật toán RL phổ biến trong tối ưu hóa lịch trình vòng lặp.

Bằng cách kết hợp học tăng cường với các biểu diễn phù hợp và một trình tối ưu hóa được chọn tốt, chúng tôi có thể tạo ra mã nhanh hơn so với các kỹ thuật tìm kiếm truyền thống cơ bản, vượt trội hơn các bộ tự động điều chỉnh phổ biến như autoTVM và MetaSchedule, và thực hiện ở mức độ của thư viện được tối ưu hóa bởi chuyên gia Numpy.

II. BỐI CẢNH

Thành phần chủ yếu của các khối lượng công việc học máy có thể được biểu diễn như một chuỗi các co rút tensor. Co rút tensor đại diện cho việc tổng quát hóa phép nhân ma trận, vết, chuyển vị, và các phép toán thường được sử dụng khác trên ma trận sang chiều cao hơn.

Một cách chính thức, chúng ta có thể định nghĩa co rút tensor theo cách sau [45]. Cho A, B, C là các tensor với các chiều tương ứng là dA, dB, dC. Tương tự như phép nhân ma trận 2D, cho mỗi cặp tensor AB, AC, BC chúng ta định nghĩa các chiều mà cả hai tensor sẽ lặp cùng nhau. Cụ thể, các chỉ số này sẽ có các chiều IAB = (dA+dB−dC)/2, IAC = (dA+dC−dB)/2 và IBC = (dB+dC−dA)/2.

Sau đó, co rút tensor có thể được định nghĩa bằng:

trong đó · là phép nhân vô hướng và Π đại diện cho tất cả các hoán vị của các chiều đã chỉ định. Lưu ý rằng ở đây chúng ta phải thực hiện tất cả các hoán vị để giữ kết quả nhất quán, vì các chiều lặp có thể được chọn theo bất kỳ thứ tự nào. Để đơn giản hóa ký hiệu hơn nữa, chúng ta có thể sử dụng ký hiệu Einstein và tổng ngầm trên các chiều không tồn tại trong tensor kết quả.

CΠC(I,J)=AΠA(I,K)· BΠB(J,K)

Để cho phép sử dụng hàm kích hoạt phi tuyến được sử dụng trong học sâu, chúng ta mở rộng ký hiệu của mình với một phép toán theo từng phần tử biến đổi kết quả cuối cùng (post).

CΠC(I,J)=post(AΠA(I,K)· BΠB(J,K))

Với những phần mở rộng này, chúng ta có thể biểu diễn không chỉ phép nhân ma trận tổng quát-tới-ma trận (GEMM), phép nhân ma trận-tới-vector (GEMV), và phép nhân vector-tới-ma trận (GEVM), mà còn các nguyên tố học máy tổng quát như:

• Tích chập [39]: OR,C=IR+K,C+J·ωK,J
• Gộp [39]: OR,C=max(I2R,2C)
• Giảm [3]: OR=IR,C
• Chuyển vị [3]: OR,C=IC,R
• Nối [50]: OR,C1+C2=AR,C1|BR,C2

--- TRANG 2 ---

Hình 2: Vòng lặp huấn luyện LoopTune. LoopTune biến đổi benchmark được tạo thành biểu diễn trung gian (IR), và sử dụng API LoopTool để áp dụng các hành động và nhận quan sát, trong khi LoopNest biên dịch và thực thi vòng lặp nest cung cấp phần thưởng.

• Phát sóng [6]: OR,C=IR

Ngoài học máy, co rút tensor được sử dụng rộng rãi trong mô phỏng vật lý, phương pháp phần tử quang phổ, hóa học lượng tử, và các lĩnh vực khác. Mặc dù có nhiều nỗ lực [22], [29], [45], không có trình biên dịch sản xuất tiên tiến nào như GCC [57] và LLVM [40] có thể tự động biến đổi các vòng lặp nest co rút tensor ngây thơ thành các triển khai được điều chỉnh bởi chuyên gia.

III. HỌC TỐI ƯU HÓA CÁC CHƯƠNG TRÌNH TENSOR

Để tối ưu hóa các phép toán tensor, chúng tôi tách riêng vấn đề tìm phạm vi và thứ tự vòng lặp tối ưu (lịch trình) khỏi các tối ưu hóa cấp thấp phụ thuộc vào phần cứng, như vector hóa. Để tìm các lịch trình hiệu suất, LoopTune sử dụng học tăng cường sâu để huấn luyện một mạng chính sách, trong khi LoopNest [65] áp dụng các tối ưu hóa tensor cấp thấp và tạo ra mã thực thi được cho một lịch trình. LoopTune cũng có thể được kết nối với tất cả các backend tối ưu hóa một lịch trình vòng lặp đã cho như Halide và TVM, điều này có thể là một hướng tương lai thú vị.

Hình 2 phác thảo quy trình làm việc của LoopTune. Quá trình bắt đầu bằng việc tạo một môi trường RL bằng cách sử dụng CompilerGym [20]. Khung này cho phép chúng tôi ánh xạ vấn đề tìm các lịch trình hiệu suất thành phương pháp RL và sử dụng các thư viện tiên tiến như RLlib [42] cho huấn luyện. Để tạo một môi trường trong CompilerGym, chúng tôi định nghĩa một không gian hành động, một không gian quan sát, và một phần thưởng sẽ được sử dụng như một tiêu chí tối ưu hóa trong quá trình huấn luyện RL. Ngoài ra, chúng tôi định nghĩa một tập hợp các benchmark đại diện cho các phép toán tensor. Đối với tất cả các benchmark, chúng tôi giả định rằng các giới hạn vòng lặp là hằng số.

Trong mỗi epoch huấn luyện, chúng tôi chuyển đổi benchmark thành biểu diễn trung gian bằng cách thêm chú thích "agent" vào vòng lặp đầu tiên (Hình 3). Trong mỗi bước, tác nhân áp dụng một hành động từ không gian hành động vào vòng lặp hiện tại thay đổi lịch trình vòng lặp. LoopTune mã hóa biểu diễn trạng thái dựa trên đồ thị mới của chúng tôi thành biểu diễn vector (được mô tả trong Phần III-C) và đưa nó vào vòng lặp huấn luyện học tăng cường. Cuối cùng, LoopNest biên dịch và đánh giá lịch trình vòng lặp cung cấp tín hiệu phần thưởng để huấn luyện mạng chính sách.

Trong giai đoạn suy luận, LoopTune lặp đi lặp lại tính toán hành động tốt nhất bằng mạng chính sách và áp dụng nó vào trạng thái hiện tại. Vì quy trình này không bao gồm đánh giá vòng lặp nest nên nó nhanh và chỉ bị ràng buộc bởi tốc độ suy luận. Thực tế, điều này cho phép mạng chính sách nhanh chóng đạt trạng thái mong muốn trong vòng vài giây.

A. Định nghĩa không gian hành động

API LoopTool [65], cung cấp cho LoopTune khả năng hoán đổi vị trí của hai vòng lặp, cho số dòng của chúng, và tách một vòng lặp, cho số dòng của nó và kích thước ô được chỉ định. Thay vì có các hành động tham số như vậy, vốn khó huấn luyện [38], LoopTune định nghĩa một không gian hành động mới được hiển thị trong Hình 3 và giới thiệu sự trừu tượng của một tác nhân duyệt các vòng lặp nest và áp dụng hành động trên mỗi vòng lặp.

Tác nhân sử dụng các hành động lên và xuống để di chuyển con trỏ mà không thay đổi cấu trúc vòng lặp nest. Các hành động hoán đổi lên và hoán đổi xuống cho phép tác nhân trao đổi vị trí của vòng lặp hiện tại với hàng xóm của nó, di chuyển con trỏ của tác nhân tương ứng. Họ hành động tách tạo ra một vòng lặp mới với cùng iterator, chia phạm vi vòng lặp với tham số tách được chỉ định. Nếu tham số tách không chia đều phạm vi vòng lặp, vòng lặp hiện tại sẽ có phần dư hoặc "đuôi", sẽ được thực thi vào cuối thực thi vòng lặp nest.

Bằng cách hạn chế không gian hành động theo cách này, chúng tôi có thể đơn giản hóa vấn đề theo nhiều cách. Ví dụ, một số lượng nhỏ hơn các hành động có thể cho phép thuật toán RL khám phá và trở nên tự tin hơn [38] với mỗi hành động cho các trạng thái khác nhau. Điều này có thể buộc tác nhân sử dụng các chuỗi hành động dài hơn để đạt các trạng thái nhất định, nhưng đây không phải là vấn đề vì mỗi hành động khác với lên và xuống đều thay đổi vòng lặp nest và cung cấp tín hiệu phần thưởng khác không. Hơn nữa, nhiều trạng thái hưởng lợi từ các chuỗi hành động tương tự, điều này cho phép huấn luyện hội tụ nhanh hơn.

Để giữ thiết kế đơn giản, chúng tôi quyết định áp dụng một số cố định các hành động cho tối ưu hóa, thay vì có một hành động chấm dứt tìm kiếm. Các thí nghiệm của chúng tôi đã chỉ ra rằng có hành động như vậy thường ngăn cản khám phá và hội tụ đến cực tiểu địa phương. Thay vào đó, chúng tôi dựa vào một điểm dừng ngầm, xảy ra khi tác nhân bắt đầu dao động giữa các trạng thái chỉ khác nhau bởi vị trí con trỏ.

--- TRANG 3 ---

Hình 3: Tối ưu hóa phạm vi và thứ tự vòng lặp cho phép nhân ma trận bằng không gian hành động của LoopTune.

B. Định nghĩa phần thưởng

Cho số liệu đánh giá, chúng tôi sử dụng tỷ phép toán dấu phẩy động mỗi giây (GFLOPS). Để đo GFLOPS, LoopTune sử dụng LoopNest để biên dịch và thực thi vòng lặp trên CPU. Để đảm bảo kết quả đáng tin cậy, LoopNest loại trừ 20 lần lặp đầu tiên như là khởi động và đo thời gian nhiều lần thực thi của vòng lặp nest, lấy phép đo nhanh nhất.

Trong quá trình huấn luyện, tác nhân áp dụng hành động (A) từ trạng thái S, chuyển nó đến trạng thái tiếp theo S'. Bộ trích xuất đặc trưng ánh xạ biểu diễn nội bộ thành vector (S) được sử dụng như đầu vào cho mạng nơ-ron. LoopNest tính toán phần thưởng cho hành động được áp dụng bằng công thức:

phần thưởng = (GFLOPS(S′)−GFLOPS(S)) / GFLOPS HIỆU SUẤT ĐỈNH

Điều này chuẩn hóa tất cả phần thưởng, làm cho huấn luyện ổn định hơn. Thay vì dựa vào hiệu suất đỉnh từ đặc tả phần cứng có thể không chính xác, chúng tôi đánh giá hiệu suất đỉnh một cách thực nghiệm trước khi huấn luyện bằng cách chạy chuỗi kernel với cường độ số học cao, luôn nằm trong vài phần trăm của đỉnh lý thuyết. Cuối cùng, chúng tôi gửi một tuple (S, S', A, R) đến thư viện RL thực hiện một bước huấn luyện.

C. Định nghĩa biểu diễn trạng thái

Mỗi vòng lặp nest bao gồm một nest tính toán các phép toán và một nest ghi-ngược ghi kết quả vào bộ nhớ. Cho biểu diễn trạng thái, chúng tôi sử dụng biểu diễn dựa trên đồ thị được hiển thị trong Hình 4. Trên đồ thị này, có 3 loại nút: vòng lặp (hình chữ nhật), dữ liệu (hình elip), và tính toán (hình thoi). Có 3 loại cạnh. Cạnh đen kết nối vòng lặp và tính toán được lồng từ trên xuống dưới. Cạnh xanh biểu diễn luồng dữ liệu, trong khi cạnh đỏ biểu diễn các bước của mỗi vòng lặp truy cập tensor đọc từ bộ nhớ (A, B), hoặc ghi vào bộ nhớ (T). Bước là khoảng cách trong bộ nhớ giữa hai phần tử của tensor khi chúng ta chỉ tăng chỉ số của một vòng lặp đã cho. Nếu số này lớn, vòng lặp lặp sẽ cố gắng lấy dữ liệu xa trong bộ nhớ có thể không được lưu trữ trong cache, dẫn đến cache miss.

Để làm cho biểu diễn của chúng tôi có thể sử dụng được cho các trình tối ưu hóa RL tiêu chuẩn, chúng tôi ánh xạ các đặc trưng chính thành một vector. Trong biểu diễn vector của chúng tôi, mỗi vòng lặp được mô tả với 20 giá trị số nguyên, cụ thể:

• (1) Con trỏ của tác nhân có trên vòng lặp không
• (1) Kích thước vòng lặp
• (1) Đuôi vòng lặp
• (1) Vòng lặp có thuộc về nest tính toán hay ghi-ngược
• (16) Histogram tần suất bước

Histogram tần suất bước (Hình 5) biểu diễn phân phối tích lũy của các bước truy cập cho mỗi vòng lặp. Nói cách khác, nó cho thấy có bao nhiêu lần truy cập với các bước đã cho được tạo ra từ vòng lặp đã cho. Cho mỗi vòng lặp, chúng tôi tính toán các bước từ hình dạng tensor và vị trí iterator. Vì bước có thể là số nguyên tùy ý lớn hơn không, chúng tôi rời rạc hóa các bước thành các bin có kích thước 2^N, trong đó N ∈ {0...15} để khớp với kích thước của các dòng cache.

--- TRANG 4 ---

Hình 4: Biểu diễn văn bản cho thấy thuật toán. Biểu diễn sơ đồ cho thấy bố cục bộ nhớ. Biểu diễn đồ thị giải thích thứ tự lồng (đen), mẫu truy cập (đỏ), và luồng dữ liệu (xanh). Biểu diễn vector tổng hợp biểu diễn đồ thị cho huấn luyện.

Bit tác nhân là cần thiết vì chúng tạo ý nghĩa cho tất cả các hành động vì chúng phụ thuộc vào vị trí con trỏ. Bit kích thước và đuôi định nghĩa bao nhiêu lần bộ nhớ được truy cập với mỗi bước, phân phối được nắm bắt trong tần suất bước. Vòng lặp tính toán cho thấy liệu vòng lặp được sử dụng cho tính toán hay ghi-ngược.

Chúng tôi tin rằng đây là một tập hợp đặc trưng tối thiểu cho thuật toán RL để học các mẫu truy cập bộ nhớ, là chìa khóa để tối ưu hóa cho các tính toán bị ràng buộc bộ nhớ như co rút tensor. Đối với các ứng dụng bị ràng buộc tính toán, việc thêm các đặc trưng mô tả tính toán trong thân vòng lặp sẽ có lợi.

D. Thư viện học tăng cường

Để tối ưu hóa quá trình huấn luyện của mô hình học tăng cường, chúng tôi đã chọn sử dụng RLlib [42], thư viện hiệu suất cho học tăng cường. Trong công việc của chúng tôi, chúng tôi đánh giá một số thuật toán học, được hỗ trợ bởi RLlib, bao gồm Deep Q Learning (DQN), Apex Deep Q Learning (APEX DQN), Proximate Policy Optimization (PPO), Actor-Critic (A3C), và Impala.

DQN [48] cố gắng học hàm giá trị trạng thái bằng cách sử dụng trải nghiệm phát lại để lưu trữ các bước tập trong bộ nhớ cho học off-policy, trong đó các mẫu được rút ra từ bộ nhớ phát lại một cách ngẫu nhiên.

APEX DQN [33] tạo ra các thể hiện của môi trường cho mỗi tác nhân và thu thập trải nghiệm kết quả trong bộ nhớ trải nghiệm phát lại được chia sẻ ưu tiên dữ liệu quan trọng nhất được tạo ra bởi các tác nhân.

PPO [55] thay phiên nhau giữa lấy mẫu dữ liệu thông qua tương tác với môi trường trong khi sử dụng gradient stochastic ascent với cập nhật minibatch.

A3C [46] tính toán gradient trên các worker trực tiếp trong mỗi tập và chỉ phát sóng các gradient này đến mô hình trung tâm. Khi mô hình trung tâm được cập nhật, các tham số được gửi trở lại các worker.

IMPALA [26] cung cấp giải pháp có thể mở rộng để thu thập mẫu từ các tác nhân riêng lẻ và chạy gradient stochastic descent trong vòng lặp trung tâm.

Để thoát khỏi việc chọn huấn luyện thuật toán RL phù hợp là rất quan trọng. Các thí nghiệm của chúng tôi cho thấy rằng APEX DQN đạt hội tụ nhanh hơn đáng kể so với các phương pháp khác mà chúng tôi trình bày chi tiết trong phần đánh giá.

--- TRANG 5 ---

Hình 5: Histogram tần suất bước.

IV. LOOPNEST BACKEND OPTIMIZER

LoopNest [65] là một trình biên dịch chuyên dụng mạnh mẽ được thiết kế đặc biệt để tối ưu hóa các chương trình tensor với điều chỉnh với học tăng cường. Thay vì dựa vào các trình biên dịch mục đích chung rộng lớn, nó sử dụng một tập hợp nhỏ các tối ưu hóa HPC được thiết kế bởi chuyên gia, cho phép tạo mã nhanh cho mỗi bước RL. Nó bao gồm các nguyên thủy tùy chỉnh trong tạo mã, mã assembly tùy chỉnh, sắp xếp lại lệnh, r-sum, và các tối ưu hóa khác được đề xuất bởi hướng dẫn tối ưu hóa cho phần cứng mục tiêu [9], [34].

Không giống như các trình biên dịch truyền thống, LoopNest tính đến thứ tự phép toán do người dùng định nghĩa. Điều này đơn giản hóa thiết kế trình tạo mã và cung cấp ánh xạ trực tiếp hơn giữa chất lượng của thứ tự do người dùng định nghĩa và hiệu suất của nó. Tính năng này đặc biệt quan trọng để tìm ra chuỗi hành động tốt nhất với học tăng cường, và chúng tôi tin chắc rằng nó làm cho không gian tối ưu hóa mượt mà hơn và cho phép hội tụ nhanh hơn.

Hơn nữa, LoopNest thực hiện cuộn vòng lặp theo cách phù hợp với yêu cầu phần cứng và tự động vector hóa vòng lặp trong cùng. Nó cũng áp dụng chia ô thanh ghi [25], giữ một phần của tensor đầu ra trong thanh ghi mọi lúc. Để giảm áp lực trên các đơn vị load/store, LoopNest không bao giờ tạo ra mã tràn thanh ghi ra stack, không giống như các trình biên dịch truyền thống như LLVM và GCC. Nó đạt được điều này bằng cách tìm phạm vi lớn nhất mà bất kỳ giá trị đã sửa đổi nào có thể vừa trong tệp thanh ghi.

Khi so sánh với LLVM [40], thường được sử dụng như lựa chọn backend cho các trình biên dịch tensor như Halide [51] và TVM [14], LoopNest đạt được thời gian biên dịch nhanh hơn hàng bậc trong khi tạo ra mã có hiệu suất bằng hoặc cao hơn trên kiến trúc AMD (AMX512) (Bảng I). Halide được sử dụng để phát ra lịch trình cho tạo mã LLVM, tắt các xác nhận thời gian chạy và kiểm tra giới hạn.

BẢNG I: Hiệu suất LoopNest so với LLVM trên kiến trúc AMD (AVX2) [65].

Ngoài kiến trúc AMD (AVX2), LoopNest đạt kết quả tương tự cho kiến trúc Intel (AVX512), Cortex A57, Cortex A73, NVIDIA Denver2, và Apple M1. Ngoài ra, LoopNest có dung lượng nhị phân nhỏ 250Kb, so với dung lượng 350Mb của LLVM, điều này làm cho LoopNest trở thành trình biên dịch lựa chọn để sử dụng trên hệ thống di động và nhúng.

V. TÌM KIẾM ĐỂ TỐI ƯU HÓA CÁC CHƯƠNG TRÌNH TENSOR

Phương pháp truyền thống để tự động điều chỉnh các chương trình tensor dựa trên leo đồi, di truyền, và các thuật toán tìm kiếm khác nhau [10]. Những thuật toán này có thể tìm ra các lịch trình hiệu suất cho một chương trình đơn lẻ, nhưng thời gian tìm kiếm và chất lượng giải pháp phụ thuộc nhiều vào độ mượt của không gian tối ưu hóa. Nếu chuỗi tối ưu hóa đến các trạng thái được thưởng cao bao gồm một số hành động tạo ra phần thưởng âm, thuật toán leo đồi có thể hội tụ đến cực tiểu địa phương. Mặt khác, thuật toán di truyền sử dụng nhiều tài nguyên tính toán, bởi vì chúng hội tụ chậm.

Chúng tôi đã triển khai tập hợp thuật toán tìm kiếm sau (Hình 6) để xác định độ khó của vấn đề:

• Tìm kiếm tham lam với nhìn trước 1 và 2
• Beam Depth First Search (BeamDFS) với độ rộng 2, 4
• Beam Breadth First Search (BeamBFS) với độ rộng 2, 4
• Tìm kiếm ngẫu nhiên

Đầu tiên, chúng tôi giới thiệu họ thuật toán tìm kiếm tham lam với nhìn trước tùy ý. Trong mỗi bước của thuật toán này, chúng tôi đánh giá tất cả các trạng thái có thể sau khi áp dụng các bước nhìn trước và chọn bước hướng đến trạng thái hứa hẹn nhất. Với nhìn trước 1, tác nhân dừng lại nếu không có hành động nào tốt hơn trạng thái hiện tại, trong khi nhìn trước 2 cho phép tác nhân chấp nhận một bước xấu dẫn đến giải pháp hứa hẹn hơn. Lý tưởng, với nhìn trước đủ lớn, tìm kiếm tham lam sẽ có thể vượt qua vấn đề cực tiểu địa phương cho các hành động có phần thưởng âm. Thật không may, tính toán như vậy đi kèm với chi phí O(bước * |không gian hành động|^nhìn trước), là cấm đoán đắt đỏ cho nhìn trước lớn.

Thứ hai, chúng tôi triển khai họ thuật toán tìm kiếm Beam với độ rộng tùy ý. Trong mỗi bước, chúng tôi tính toán các hành động độ rộng tốt nhất và mở rộng chúng xa hơn cho đến khi chúng tôi đạt độ sâu được chỉ định của cây tìm kiếm. Mở rộng các trạng thái có thể được thực hiện theo cách depth-first (BeamDFS) và breadth-first (BeamBFS) và các tính chất tìm kiếm khác biệt đáng kể khi thời gian tìm kiếm trôi qua trước khi đồ thị tìm kiếm đầy đủ được xây dựng.

Độ phức tạp của cả hai phương pháp này là O(độ rộng^bước), trong đó độ rộng < |không gian hành động|.

BeamDFS có thể được xem như một phần mở rộng của thuật toán tham lam với nhìn trước 1, với vài bổ sung. Nó không kết thúc nếu trạng thái tiếp theo tệ hơn trạng thái hiện tại và nó đệ quy truy cập tất cả các trạng thái của đồ thị tìm kiếm nơi mỗi nút có tối đa độ rộng con. Điều này cho phép nó chấp nhận các phần không lồi của không gian miễn là hành động tối ưu xếp hạng tốt hơn các hành động khác trong bước hiện tại.

Biến thể BeamBFS tìm ra chuỗi hành động hiệu suất một cách lặp khi nó xây dựng đồ thị tìm kiếm cho mỗi số bước. Phương pháp này sẽ có lợi nếu chuỗi hiệu suất ngắn hơn độ sâu tìm kiếm được chỉ định.

Cuối cùng, tìm kiếm ngẫu nhiên ngẫu nhiên chọn một chuỗi hành động với độ dài được chỉ định. Lợi ích của tìm kiếm này là nó có thể khám phá đồng đều một số lượng lớn các trạng thái đa dạng cung cấp ý tưởng chung về cảnh quan. Từ các thí nghiệm của chúng tôi, tìm kiếm ngẫu nhiên cung cấp kết quả tốt đáng ngạc nhiên mà chúng tôi trình bày chi tiết trong phần tiếp theo.

VI. ĐÁNH GIÁ

Chúng tôi đã đánh giá LoopTune trên một chuỗi benchmark để trả lời các câu hỏi sau:

• Các thuật toán RL khác nhau so sánh như thế nào với nhau?
• LoopTune so sánh như thế nào với các thuật toán tìm kiếm truyền thống?
• LoopTune so sánh như thế nào với các thư viện được tối ưu hóa và bộ tự động điều chỉnh như TVM?

Tập dữ liệu benchmark bao gồm các vòng lặp nest được tổng hợp cho phép nhân ma trận. Tập dữ liệu phép nhân ma trận có 2197 vòng lặp nest chưa chia ô cho ma trận với các chiều trong phạm vi từ 64 đến 256 với bước 16. Chúng tôi chọn các phạm vi này vì chúng được sử dụng như kích thước ô cho các thư viện tùy chỉnh như cuBLAS [1]. Chúng tôi huấn luyện trên 80% tập dữ liệu (kích thước 1757) trong khi để lại 20% cho tập dữ liệu kiểm tra (kích thước 440).

Các thí nghiệm được thực hiện trên Intel Xeon CPU chạy ở 2.20GHz, với 40 lõi CPU và 2 GPU Nvidia Quadro GP100. CPU có kích thước cache L1(dữ liệu/lệnh) 1.3 MB, L2 10MB, L3 52MB.

A. Phân tích huấn luyện RLlib

Để huấn luyện LoopTune, chúng tôi sử dụng thư viện RLlib của Ray [42]. Sau khi chúng tôi định nghĩa môi trường trong CompilerGym và đăng ký nó với RLlib, chúng tôi cần khởi tạo trainer phù hợp và tìm ra các siêu tham số hứa hẹn nhất. Để tìm trainer tốt nhất, chúng tôi so sánh PPO, A3C, DQN, APEX DQN, và Impala. Trong tất cả các trường hợp như một mô hình, chúng tôi sử dụng mạng với các lớp kết nối đầy đủ, với độ rộng và số lượng lớp tùy ý, và cùng biểu diễn đặc trưng.

Để tìm các tham số tối ưu cho mỗi trainer, chúng tôi chạy quét siêu tham số cho tỷ lệ học, hệ số khám phá, độ sâu, và độ rộng của mạng nơ-ron. Sau khi tìm ra các tham số tốt nhất cho mỗi trainer, chúng tôi chạy huấn luyện cuối cùng trong 4000 lần lặp và dừng huấn luyện sớm nếu phần thưởng trung bình mỗi epoch hội tụ. Trong mỗi lần lặp, trình tối ưu hóa áp dụng tập 10 hành động và cập nhật mạng nơ-ron. Cuối cùng, chúng tôi so sánh các trainer bằng cách vẽ biểu đồ trung bình phần thưởng tập đại diện cho mức tăng GFLOPS trung bình đạt được trong tập được chuẩn hóa theo hiệu suất đỉnh của thiết bị (Hình 7).

Chúng tôi phát hiện ra rằng trainer APEX DQN thực hiện tốt hơn một bậc so với các trainer khác, hội tụ sau khoảng 200 bước và cung cấp mức tăng trung bình 30% hiệu suất đỉnh (đỉnh = 114.204 GFLOPS). Ngược lại, PPO yêu cầu hơn 1000 bước để hội tụ đến mức cải thiện 8% của đỉnh, trong khi Impala, A3C, và DQN không thể đạt kết quả tích cực. Chúng tôi huấn luyện APEX DQN trong 17.5 giờ cho 1000 lần lặp, có thể được rút ngắn xuống 3.5h với dừng sớm sau 200 lần lặp.

Chúng tôi tin rằng sự vượt trội của APEX DQN nằm ở khả năng ưu tiên những trải nghiệm quan trọng nhất được tạo ra bởi các tác nhân. Vì tất cả các thuật toán đều được triển khai trong RLlib, chỉ cần một dòng thay đổi để hưởng lợi từ các thuật toán mới trong tương lai. Chúng tôi tiếp tục so sánh giải pháp APEX DQN với các phương pháp không phải RL.

B. So sánh với các phương pháp dựa trên tìm kiếm

Để đánh giá độ khó của việc tìm kiếm không gian tối ưu hóa, chúng tôi chạy một tập hợp thuật toán tìm kiếm truyền thống bao gồm tìm kiếm tham lam với nhìn trước 1 và 2, biến thể BFS và DFS của tìm kiếm Beam với độ rộng 2 và 4, và tìm kiếm ngẫu nhiên. Chúng tôi triển khai mỗi tìm kiếm với bộ nhớ cache để tránh lặp lại đánh giá các trạng thái giống nhau. Chúng tôi chạy mỗi tìm kiếm trên tập dữ liệu kiểm tra 440 benchmark, đặt giới hạn thời gian là 60 giây. Để so sánh tìm kiếm truyền thống với chính sách được tạo ra từ phương pháp RL, chúng tôi trực quan hóa thời gian tìm kiếm và hiệu suất đạt được của mã được tạo ra từ 25 benchmark ngẫu nhiên từ tập kiểm tra trong Hình 8.

Trong 88% benchmark kiểm tra, mạng chính sách APEX DQN vượt trội hơn các tìm kiếm truyền thống tốt nhất trung bình 1.8x trong dưới một giây, là thời gian ít hơn một bậc. Để hiểu rõ hơn các đặc tính của mỗi tìm kiếm, chúng tôi trình bày phân phối tăng tốc trong Hình 9.

Tăng nhìn trước lên 2 cải thiện hiệu suất của tìm kiếm tham lam. Beam2BFS và Beam2DFS đạt kết quả kém, mặc dù khám phá toàn bộ cây con tìm kiếm, điều này ngụ ý rằng các lịch trình hiệu suất bao gồm các hành động không hiệu suất. Tăng độ rộng lên 4 làm tăng đáng kể hiệu suất, vượt trội hơn Greedy2. Thành công của tìm kiếm ngẫu nhiên càng nhấn mạnh rằng không gian tối ưu hóa là phi tuyến. Cuối cùng, mạng chính sách RL vượt trội đáng kể so với tất cả các phương pháp tìm kiếm bằng cách tối ưu hóa cho phần thưởng tầm xa lên đến 10 bước trước, tránh cực tiểu địa phương.

C. Phân tích không gian tối ưu hóa lịch trình vòng lặp

Tiếp theo, chúng tôi trực quan hóa hiệu suất và tốc độ tìm kiếm của các thuật toán tìm kiếm và phương pháp RL cho mỗi bước (Hình 10). Hình trên cho thấy tín hiệu phần thưởng trong GFLOPS cho lịch trình được tìm thấy tốt nhất, trong khi hình dưới cho thấy mất bao lâu để chọn một hành động cho bước đã cho. Đối với tìm kiếm Depth-First và tìm kiếm ngẫu nhiên, các hành động không được quyết định cho đến khi kết thúc xây dựng đồ thị tìm kiếm và xuất hiện phẳng trên biểu đồ.

Greedy1 kết thúc nhanh chóng, tạo ra đồ thị tìm kiếm độ sâu 2 và bị mắc kẹt ở cực tiểu địa phương. Greedy2 có thể mở rộng đồ thị lên đến độ sâu 6, tránh cực tiểu địa phương một bước và đạt hiệu suất tốt hơn, nhưng vẫn chỉ khám phá một số lượng nhỏ các trạng thái.

Beam2DFS mở rộng đồ thị theo chiều sâu và mỗi lớp được cập nhật trong quá trình xây dựng đồ thị, giữ đường cong thời gian tương đối phẳng. BeamBFS, mặt khác, xây dựng không gian tìm kiếm từng lớp một hoàn thành các lớp thấp hơn trước. Thực tế là Beam2DFS và Beam2BFS hoàn thành trước thời hạn (60s) có nghĩa là chúng đã xây dựng toàn bộ đồ thị tìm kiếm của spawn 2. Không có tìm kiếm nào trong hai tìm kiếm này tìm thấy giải pháp hiệu suất chỉ ra rằng tất cả các lịch trình hiệu suất bao gồm ít nhất một hành động là tốt nhất 2 hành động.

Beam4DFS và Beam4BFS đều kết thúc với thời hạn có nghĩa là chúng chỉ xây dựng một phần đồ thị tìm kiếm của spawn 4. Đồ thị tìm kiếm của Beam4DFS bao gồm các giải pháp với chuỗi dài lên đến 10 bước, trong khi Beam4BFS hoàn toàn khám phá tất cả các giải pháp với 5 bước. Trong cả hai trường hợp, các giải pháp tốt nhất chứa chuỗi dài các hành động với hiệu suất không tăng đơn điệu, cho phép các tìm kiếm này thấy xa hơn so với tìm kiếm tham lam.

Tìm kiếm ngẫu nhiên sử dụng tất cả thời gian để mở rộng đồ thị tìm kiếm từ gốc đến độ sâu 10 mà không theo bất kỳ số liệu nào và đánh giá mỗi trạng thái trong đồ thị. Bằng cách này, tìm kiếm ngẫu nhiên có thể khám phá đồng đều không gian tối ưu hóa, bao gồm các chuỗi hành động không đơn điệu.

Mạng chính sách RL có thể vượt trội so với tất cả các thuật toán trước đó bằng cách học các mẫu tối ưu hóa tối đa hóa phần thưởng tương lai, tăng tốc thực thi trung bình 3.2x so với triển khai LoopNest gốc. Giải pháp của nó chấp nhận chuỗi dài các hành động không hiệu suất, tệ hơn so với tất cả các tìm kiếm khác từ bước thứ 4 đến thứ 7 để đạt trạng thái hiệu suất ở bước thứ 8. Ngoài ra, thời gian tìm kiếm mạng chính sách RL tăng tuyến tính theo độ dài của chuỗi hành động, cho phép chúng tôi sử dụng mạng chính sách trên các vấn đề khó hơn yêu cầu số lượng bước lớn hơn. Những khả năng này là tối quan trọng để tự động điều chỉnh các trình biên dịch tổng quát như LLVM.

--- TRANG 7 ---

Hình 6: Phương pháp tìm kiếm truyền thống trong việc tìm chuỗi tối ưu. Các hành động (cạnh) được sắp xếp theo hiệu suất của trạng thái tiếp theo.

Hình 7: Phần thưởng trung bình mỗi epoch cho các thuật toán RLlib trong quá trình huấn luyện 4000 bước.

D. So sánh với Numpy, TVM, MetaSchedule, và AutoTVM

Tiếp theo, chúng tôi cho thấy các hồ sơ hiệu suất [24] cho biên dịch và thực thi mã được tạo ra trên tập dữ liệu kiểm tra (440 ví dụ), và so sánh nó với thư viện được điều chỉnh thủ công phổ biến cho các phép toán tensor – Numpy, trình biên dịch tensor – TVM (phiên bản cơ bản và phiên bản được tối ưu hóa với blocking, hoán vị, và vector hóa) và các bộ tự động điều chỉnh được sử dụng rộng rãi – autoTVM và MetaSchedule (Hình 11).

LoopTune vượt trội so với tất cả các phương pháp khác trong 67% trường hợp kiểm tra trong khi đạt hơn 90% hiệu suất tốt nhất trong 92% trường hợp kiểm tra. Trung bình LoopTune đánh bại TVM cơ bản với 43x, TVM được tối ưu hóa với 9.7x, MetaSchedule với 2.8x, và AutoTVM với 1.08x, trong khi chậm hơn Numpy 3%. Ngược lại với Numpy, LoopTune không yêu cầu điều chỉnh thủ công làm giảm chi phí phát triển và bảo trì.

Hơn nữa, LoopTune làm cho tự động điều chỉnh thời gian thực trở nên thực tế, tạo ra mã chỉ trong 1 giây, trong khi autoTVM và MetaSchedule yêu cầu trung bình 33 và 62 giây. Điều này đặc biệt quan trọng cho các ứng dụng yêu cầu tải xuống và điều chỉnh thời gian thực từ kho lưu trữ trên web. Một ví dụ về điều này có thể là điều chỉnh bộ lọc hình ảnh/video cho ứng dụng mạng xã hội và trò chơi video cho thiết bị di động hoặc VR.

Chúng tôi sử dụng tài liệu chính thức từ TVM [23] để triển khai phép nhân ma trận cho các ví dụ từ tập kiểm tra. Triển khai TVM này bao gồm tối ưu hóa blocking, hoán vị vòng lặp, và vector hóa, đây là cùng tập hợp tối ưu hóa chúng tôi đang sử dụng cho LoopTune. Chúng tôi bật tùy chọn "llvm -mcpu=core-avx2" cho TVM, MetaSchedule, và AutoTVM, để có kết quả tốt nhất cho kiến trúc của chúng tôi. Cho MetaSchedule chúng tôi sử dụng lấy mẫu ngẫu nhiên, chia ô, sắp xếp lại, và cuộn, trong khi cho AutoTVM chúng tôi sử dụng XGBTuner, đánh giá 64 lịch trình có thể cho cả hai.

Đánh giá hơn 64 lịch trình sẽ yêu cầu thời gian tỷ lệ thuận, điều này làm cho nó cấm đoán dài cho trường hợp sử dụng của chúng tôi – tự động điều chỉnh trong vòng vài giây. Vì lý do tương tự, chúng tôi không bao gồm trong đánh giá của chúng tôi các khung dựa trên mô hình chi phí phổ biến như Ansor [68], Value Learning [58] và TenSet [69] và FlexTensor [70] vì chúng có thời gian tìm kiếm tương tự hoặc dài hơn.

--- TRANG 8 ---

Hình 8: Hiệu suất đạt được (càng cao càng tốt) và thời gian tìm kiếm (càng thấp càng tốt) của 25 benchmark kiểm tra được chọn ngẫu nhiên với 60 giây cho tìm kiếm. Gốc đề cập đến LoopNest, được sử dụng làm trình biên dịch phụ cho tìm kiếm tham lam, beam, ngẫu nhiên, và phương pháp LoopTune.

Hình 9: Phân phối tăng tốc cho tìm kiếm từ Hình 8 được chuẩn hóa với kết quả LoopNest.

Hình 10: Hiệu suất và thời gian cần thiết để mở rộng đồ thị tìm kiếm trong mỗi bước.

VII. CÔNG TRÌNH LIÊN QUAN

Thư viện cụ thể cho tensor. Ký hiệu toán học dựa trên tensor lần đầu tiên được sử dụng bởi APL [4]. Tương tự như APL, các khung hiện đại như NumPy [61], Tensor Toolbox của Matlab [11], Intel MKL [18], PyTorch [49] và Tensorflow [2] cung cấp giao diện trực quan để thao tác tensor, thực hiện các phép toán tùy chỉnh, và thực thi các thuật toán học máy. Mặc dù các thư viện này thường vector hóa tính toán tensor, chúng hiếm khi tìm thấy thứ tự và kích thước hiệu suất nhất của vòng lặp cho phần cứng tùy chỉnh.

Trình biên dịch dựa trên tìm kiếm. Thay vì dựa vào các giải pháp một-kích-thước-phù-hợp-tất-cả từ thư viện được viết bởi chuyên gia, các dự án ATLAS [66] và FFTW [27] tối ưu hóa thực nghiệm các thói quen BLAS và FFT cho phần cứng tùy chỉnh. PetaBricks [7] chọn thuật toán phù hợp nhất của tính toán cho nền tảng đã cho và điều chỉnh tham số của nó bằng cách sử dụng các phương pháp lặp. OpenTuner [8] cung cấp một tập hợp các kỹ thuật tìm kiếm không phụ thuộc vào phương pháp cho tự động điều chỉnh chương trình. Mặc dù các phương pháp này có thể rất hiệu quả, tự động điều chỉnh yêu cầu thời gian tìm kiếm đáng kể cho mỗi chương trình, điều này có thể cấm đoán đắt đỏ. LoopTune chỉ mất một giây để điều chỉnh tính toán tensor.

Trình biên dịch dựa trên đồ thị. nGraph [21] chuyển biểu diễn nội bộ đồ thị của nó đến một transformer và tạo ra mã được tối ưu hóa cho backend được chọn. XLA [54] tự động thay thế các đồ thị con từ Tensorflow bằng các nhị phân được tối ưu hóa. Glow [53] áp dụng tối ưu hóa cụ thể cho miền ở cấp độ cao, tối ưu hóa liên quan đến bộ nhớ ở biểu diễn trung gian dựa trên lệnh, và tối ưu hóa cụ thể cho phần cứng ở cấp độ thấp nhất. MLIR [41] cung cấp cơ sở hạ tầng trình biên dịch có thể mở rộng nhằm thống nhất các trình tối ưu hóa cụ thể cho miền, cung cấp nhiều biểu diễn và lớp tối ưu hóa. Thay vì sử dụng biểu diễn phức tạp, LoopTune mã hóa biểu diễn dựa trên đồ thị thành vector đơn giản với các đặc trưng liên quan để mô tả các mẫu truy cập bộ nhớ. Điều này cho phép suy luận nhanh với perceptron đa lớp đơn giản.

Trình biên dịch dựa trên lịch trình. Halide [51] là công trình có ảnh hưởng đầu tiên đề xuất tách biệt tính toán và lịch trình để tối ưu hóa xử lý hình ảnh và tính toán tensor. Nó sử dụng ngôn ngữ khai báo để chỉ định tính toán tensor và một ngôn ngữ riêng biệt để lập lịch thực thi của nó. Tương tự như LoopTune, ngôn ngữ lập lịch của Halide bao gồm các phép toán như tách, và sắp xếp lại, với việc bổ sung vector hóa, cuộn, và song song hóa vòng lặp. TVM [14] mở rộng khái niệm tính toán/lịch trình của Halide với các nội tại phần cứng và định nghĩa các tối ưu hóa mới như tensor hóa và ẩn độ trễ. AutoTVM [15] mở rộng mô hình chi phí TVM và thêm khung tìm kiếm được hướng dẫn bởi mẫu. FlexTensor [70] tìm kiếm trực tiếp các nguyên thủy lịch trình ở cấp độ tinh hơn so với các mẫu. Ngược lại với các phương pháp này, LoopTune định nghĩa không gian hành động với mô hình chính sách trong tâm trí loại bỏ các hành động tham số khó học [38].

Trình biên dịch dựa trên đa diện. Để biểu diễn tính toán tensor, các trình tối ưu hóa đa diện Polly [30] và khác [63] [12] sử dụng lập trình tuyến tính và các phép biến đổi affine để tối ưu hóa vòng lặp luồng điều khiển tĩnh. Tensor comprehensions [62] sử dụng biểu diễn trung gian của Halide để biểu diễn tính toán, biểu diễn đa diện để biểu diễn vòng lặp và biên dịch just-in-time cho GPU.

Trình biên dịch dựa trên mô hình chi phí. Để tăng tốc đánh giá tính toán, các khung phổ biến như Ansor [68], Value Learning [58], và TenSet [69] học mô hình chi phí để đánh giá hiệu suất và sử dụng cây quyết định, tìm kiếm tiến hóa, và tìm kiếm cây monte-carlo để xác định cái tốt nhất. Mặc dù mô hình chi phí hiệu suất giảm thời gian đánh giá, việc hội tụ đến trạng thái tối ưu trong không gian hành động cực kỳ không lồi là khó khăn. Ngoài ra, suy luận với mô hình chi phí và tìm kiếm tham lam cơ bản yêu cầu độ dài chuỗi hành động * số lượng hành động có thể suy luận, trong khi mạng chính sách chỉ yêu cầu độ dài chuỗi hành động suy luận chính xác là trường hợp cho LoopTune.

Trình biên dịch dựa trên mô hình chính sách. Neurovectorizer [31] sử dụng deep RL để cải thiện vector hóa vòng lặp CPU bằng cách điều chỉnh độ rộng vector hóa và số lượng xen kẽ. Chameleon [5] sử dụng mạng chính sách để hướng dẫn thuật toán lấy mẫu thích ứng với kiến thức miền để tìm kiếm không gian cấu hình. MLGO [60] sử dụng Policy gradient và Evolution strategies để tối ưu hóa kích thước nhị phân bằng cách inline hàm. PolyGym [13] khám phá lịch trình vòng lặp kết hợp biểu diễn đa diện với RL và cung cấp cơ sở hạ tầng cho người dùng áp dụng các thuật toán RL khác nhau sử dụng biểu diễn của chúng. Ngược lại với các phương pháp này, LoopTune đề xuất biểu diễn dựa trên đồ thị mới, không gian hành động, và phương pháp tối ưu hóa vòng lặp nest.

--- TRANG 9 ---

Hình 11: Thời gian biên dịch và tỷ lệ thực thi của các benchmark kiểm tra. Cho Hình b), các trường hợp kiểm tra được chuẩn hóa với phương pháp tốt nhất được sắp xếp từ tốt nhất đến tệ nhất trên trục y.

VIII. HẠN CHẾ VÀ CÔNG VIỆC TƯƠNG LAI

Một trong những hạn chế của LoopTune là hình dạng vòng lặp nest cần được biết trong thời gian biên dịch. Đối với hầu hết tính toán ML, điều này được định nghĩa theo thiết kế. Một hạn chế khác là thời gian huấn luyện tỷ lệ thuận với khối lượng công việc tính toán vì chúng tôi đo hiệu suất một cách rõ ràng thay vì sử dụng mô hình chi phí. Đối với các kernel nhỏ, đây không phải là vấn đề, trong khi đối với các kernel lớn hơn có thể cần sử dụng mô hình chi phí trong quá trình huấn luyện. Cuối cùng, hiện tại LoopTune chỉ hỗ trợ CPU, mặc dù chúng tôi mong muốn triển khai hỗ trợ GPU trong tương lai.

IX. KẾT LUẬN

LoopTune là một bộ tự động điều chỉnh mới hiệu suất cho tính toán tensor trên CPU, có khả năng tự động điều chỉnh mã trong dưới một giây. LoopTune sử dụng deep RL để huấn luyện mạng chính sách sắp xếp lại và chia ô vòng lặp nest và áp dụng tối ưu hóa cụ thể cho phần cứng sử dụng LoopNest để điều chỉnh vòng lặp nest cho phần cứng cơ bản. Để ánh xạ vấn đề này thành học tăng cường, LoopTune giới thiệu không gian hành động độc đáo, biểu diễn trạng thái dựa trên đồ thị, và tín hiệu phần thưởng.

Bằng cách sử dụng thuật toán APEX DQN của RLlib, LoopTune tăng tốc triển khai LoopNest gốc lên 3.2x trong 1 giây, trên một bộ các vấn đề kiểm tra, trong khi thuật toán tìm kiếm truyền thống tốt nhất đạt 1.8x trong 60 giây. LoopTune đạt kết quả tốt hơn một bậc so với triển khai được tối ưu hóa của TVM, bao gồm blocking, hoán vị vòng lặp, và vector hóa. Ngoài ra, LoopTune vượt trội hơn MetaSchedule và AutoTVM trung bình 2.8x và 1.08x, tạo ra mã lại trong 1 giây, trong khi MetaSchedule và AutoTVM yêu cầu 33 giây và 62 giây, tương ứng. Điều này làm cho tự động điều chỉnh thời gian thực trở nên khả thi.

Cuối cùng, LoopTune liên tục thực hiện ở cùng mức độ với thư viện được tối ưu hóa bởi chuyên gia Numpy, giảm đáng kể nỗ lực phát triển. Phát hiện này hỗ trợ thêm niềm tin rằng các kỹ thuật học tăng cường sâu sẽ đóng vai trò quan trọng trong thế hệ tiếp theo của các trình biên dịch.

TÀI LIỆU THAM KHẢO

[1] Hướng dẫn người dùng nền tảng phép nhân ma trận. https://docs.nvidia.com/
deeplearning/performance/dl-performance-matrix-multiplication/index.
html. Truy cập: 2023-04-26.

[2] Martín Abadi, Paul Barham, Jianmin Chen, Zhifeng Chen, Andy Davis,
Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Geoffrey Irving,
Michael Isard, et al. Tensorflow: Một hệ thống cho học máy quy mô lớn. Trong hội thảo thứ 12 {USENIX} về thiết kế và triển khai hệ điều hành ({OSDI}16), trang 265–283, 2016.

[3] Hervé Abdi and Lynne J Williams. Phân tích thành phần chính. Wiley
interdisciplinary reviews: computational statistics, 2(4):433–459, 2010.

[4] Philip Samuel Abrams. Một máy apl. Báo cáo kỹ thuật, Stanford
Linear Accelerator Center, Calif., 1970.

[5] Byung Hoon Ahn, Prannoy Pilligundla, Amir Yazdanbakhsh, và Hadi
Esmaeilzadeh. Chameleon: Tối ưu hóa mã thích ứng cho biên dịch mạng nơ-ron sâu nhanh chóng. arXiv preprint arXiv:2001.08743, 2020.

[6] Marjan Albooyeh, Daniele Bertolini, và Siamak Ravanbakhsh. Mạng tỷ lệ cho học sâu hình học. arXiv preprint arXiv:1905.11460, 2019.

--- TRANG 10 ---

[7] Jason Ansel, Cy Chan, Yee Lok Wong, Marek Olszewski, Qin Zhao,
Alan Edelman, và Saman Amarasinghe. Petabricks: Một ngôn ngữ và
trình biên dịch cho lựa chọn thuật toán. ACM Sigplan Notices, 44(6):38–49, 2009.

[8] Jason Ansel, Shoaib Kamil, Kalyan Veeramachaneni, Jonathan Ragan-
Kelley, Jeffrey Bosboom, Una-May O'Reilly, và Saman Amarasinghe.
Opentuner: Một khung có thể mở rộng cho tự động điều chỉnh chương trình. Trong Kỷ yếu hội nghị quốc tế lần thứ 23 về Kiến trúc song song và biên dịch, trang 303–316, 2014.

[9] R ARM. Hướng dẫn tối ưu hóa phần mềm Cortex-a57. ARM, 2016.

[10] Amir H Ashouri, William Killian, John Cavazos, Gianluca Palermo,
và Cristina Silvano. Một khảo sát về tự động điều chỉnh trình biên dịch sử dụng học máy. ACM Computing Surveys (CSUR), 51(5):1–42, 2018.

[11] Brett W Bader và Tamara G Kolda. Thuật toán 862: Các lớp tensor Matlab
cho tạo mẫu thuật toán nhanh. ACM Transactions on Mathematical Software (TOMS), 32(4):635–653, 2006.

[12] Roberto Bagnara, Patricia M Hill, và Enea Zaffanella. Thư viện đa diện parma: Hướng đến một tập hợp đầy đủ các trừu tượng số học cho phân tích và xác minh hệ thống phần cứng và phần mềm. Science of Computer Programming, 72(1-2):3–21, 2008.

[13] Alexander Brauckmann, Andrés Goens, và Jeronimo Castrillon. Một
môi trường học tăng cường cho tối ưu hóa đa diện. arXiv preprint arXiv:2104.13732, 2021.

[14] Tianqi Chen, Thierry Moreau, Ziheng Jiang, Lianmin Zheng, Eddie
Yan, Haichen Shen, Meghan Cowan, Leyuan Wang, Yuwei Hu, Luis
Ceze, Carlos Guestrin, và Arvind Krishnamurthy. TVM: Một trình biên dịch tối ưu hóa tự động end-to-end cho học sâu. Trong Hội thảo USENIX lần thứ 13 về Thiết kế và Triển khai Hệ điều hành (OSDI 18), trang 578–594, Carlsbad, CA, Tháng 10 2018. USENIX Association.

[15] Tianqi Chen, Lianmin Zheng, Eddie Yan, Ziheng Jiang, Thierry Moreau,
Luis Ceze, Carlos Guestrin, và Arvind Krishnamurthy. Học tối ưu hóa các chương trình tensor. Trong Advances in Neural Information Processing Systems, trang 3389–3400, 2018.

[16] Sharan Chetlur, Cliff Woolley, Philippe Vandermersch, Jonathan Cohen,
John Tran, Bryan Catanzaro, và Evan Shelhamer. cudnn: Các nguyên thủy hiệu quả cho học sâu. arXiv preprint arXiv:1410.0759, 2014.

[17] Jack Choquette, Wishwesh Gandhi, Olivier Giroux, Nick Stam, và
Ronny Krashinsky. Nvidia a100 tensor core gpu: Hiệu suất và đổi mới. IEEE Micro, 41(2):29–35, 2021.

[18] Intel Corporation. Tham chiếu nhà phát triển mkl. https://software.intel.com/
content/www/us/en/develop/documentation/mkl-developer-reference-c/
top.html, 2020.

[19] Intel Corporation. Onednn. https://github.com/oneapi-src/oneDNN,
2020.

[20] Chris Cummins, Bram Wasti, Jiadong Guo, Brandon Cui, Jason Ansel,
Sahir Gomez, Somya Jain, Jia Liu, Olivier Teytaud, Benoit Steiner, et al.
Compilergym: môi trường tối ưu hóa trình biên dịch mạnh mẽ, hiệu suất cho nghiên cứu ai. Trong Hội thảo quốc tế IEEE/ACM 2022 về Tạo mã và Tối ưu hóa (CGO), trang 92–105. IEEE, 2022.

[21] Scott Cyphers, Arjun K Bansal, Anahita Bhiwandiwalla, Jayaram Bobba,
Matthew Brookhart, Avijit Chakraborty, Will Constable, Christian Con-
vey, Leona Cook, Omar Kanawi, et al. Intel ngraph: Một biểu diễn trung gian, trình biên dịch, và bộ thực thi cho học sâu. arXiv preprint arXiv:1801.08058, 2018.

[22] Edoardo Di Napoli, Diego Fabregat-Traver, Gregorio Quintana-Ortí,
và Paolo Bientinesi. Hướng đến việc sử dụng hiệu quả thư viện blas cho co rút tensor đa tuyến tính. Applied Mathematics and Computation, 235:454–468, 2014.

[23] Tài liệu TVM phiên bản(0.11.dev0). Cách tối ưu hóa gemm trên cpu¶. [Trực tuyến; truy cập 28-Tháng 11-2022].

[24] Elizabeth D Dolan và Jorge J Moré. Đánh giá phần mềm tối ưu hóa với hồ sơ hiệu suất. Mathematical programming, 91:201–213, 2002.

[25] Lukasz Domagala, Fabrice Rastello, Sadayappan Ponnuswany, và Duco
Van Amstel. Một quan điểm chia ô cho tối ưu hóa thanh ghi. arXiv preprint arXiv:1406.0582, 2014.

[26] Lasse Espeholt, Hubert Soyer, Remi Munos, Karen Simonyan, Vlad
Mnih, Tom Ward, Yotam Doron, Vlad Firoiu, Tim Harley, Iain Dunning,
et al. Impala: Deep-rl phân tán có thể mở rộng với kiến trúc actor-learner có trọng số quan trọng. Trong Hội nghị quốc tế về học máy, trang 1407–1416. PMLR, 2018.

[27] Matteo Frigo và Steven G Johnson. Fftw: Một kiến trúc phần mềm thích ứng cho fft. Trong Kỷ yếu Hội nghị quốc tế IEEE 1998 về Âm thanh, Giọng nói và Xử lý Tín hiệu, ICASSP'98 (Cat. No. 98CH36181), tập 3, trang 1381–1384. IEEE, 1998.

[28] Google. Xnnpack. https://github.com/google/XNNPACK, 2020.

[29] Tobias Grosser, Armin Groesslinger, và Christian Lengauer.
Polly—thực hiện tối ưu hóa đa diện trên biểu diễn trung gian cấp thấp. Parallel Processing Letters, 22(04):1250010, 2012.

[30] Tobias Grosser, Hongbin Zheng, Raghesh Aloor, Andreas Simbürger,
Armin Größlinger, và Louis-Noël Pouchet. Polly-tối ưu hóa đa diện trong llvm. Trong Kỷ yếu Hội thảo quốc tế đầu tiên về Kỹ thuật Biên dịch Đa diện (IMPACT), tập 2011, trang 1, 2011.

[31] Ameer Haj-Ali, Nesreen K Ahmed, Ted Willke, Yakun Sophia Shao,
Krste Asanovic, và Ion Stoica. Neurovectorizer: Vector hóa end-to-end với học tăng cường sâu. Trong Kỷ yếu Hội thảo quốc tế ACM/IEEE lần thứ 18 về Tạo mã và Tối ưu hóa, trang 242–255, 2020.

[32] Ameer Haj-Ali, Qijing Huang, William Moses, John Xiang, Ion Stoica,
Krste Asanovic, và John Wawrzynek. Autophase: Sắp xếp giai đoạn trình biên dịch cho tổng hợp cấp cao với học tăng cường sâu. arXiv preprint arXiv:1901.04615, 2019.

[33] Dan Horgan, John Quan, David Budden, Gabriel Barth-Maron, Matteo
Hessel, Hado Van Hasselt, và David Silver. Phát lại trải nghiệm ưu tiên phân tán. arXiv preprint arXiv:1803.00933, 2018.

[34] R Intel. Hướng dẫn tham chiếu tối ưu hóa kiến trúc Intel 64 và ia-32. Intel Corporation, Sept, 2014.

[35] Hwancheol Jeong, Sunghoon Kim, Weonjong Lee, và Seok-Ho
Myung. Hiệu suất của tập lệnh sse và avx. arXiv preprint arXiv:1211.0820, 2012.

[36] Zhe Jia, Blake Tillman, Marco Maggioni, và Daniele Paolo Scarpazza.
Phẫu thuật kiến trúc graphcore ipu thông qua microbenchmarking. arXiv preprint arXiv:1912.03413, 2019.

[37] Norman P Jouppi, Cliff Young, Nishant Patil, David Patterson, Gaurav
Agrawal, Raminder Bajwa, Sarah Bates, Suresh Bhatia, Nan Boden,
Al Borchers, et al. Phân tích hiệu suất trong trung tâm dữ liệu của đơn vị xử lý tensor. Trong Kỷ yếu hội thảo quốc tế thường niên lần thứ 44 về kiến trúc máy tính, trang 1–12, 2017.

[38] Anssi Kanervisto, Christian Scheller, và Ville Hautamäki. Định hình không gian hành động trong học tăng cường sâu. Trong Hội nghị IEEE 2020 về Trò chơi (CoG), trang 479–486. IEEE, 2020.

[39] Alex Krizhevsky, Ilya Sutskever, và Geoffrey E Hinton. Phân loại imagenet với mạng nơ-ron tích chập sâu. Communications of the ACM, 60(6):84–90, 2017.

[40] Chris Lattner và Vikram Adve. Llvm: Một khung biên dịch cho phân tích và biến đổi chương trình suốt đời. Trong Hội thảo quốc tế về Tạo mã và Tối ưu hóa, 2004. CGO 2004., trang 75–86. IEEE, 2004.

[41] Chris Lattner, Mehdi Amini, Uday Bondhugula, Albert Cohen, Andy
Davis, Jacques Pienaar, River Riddle, Tatiana Shpeisman, Nicolas Vasi-
lache, và Oleksandr Zinenko. Mlir: Mở rộng cơ sở hạ tầng trình biên dịch cho tính toán cụ thể miền. Trong Hội thảo quốc tế IEEE/ACM 2021 về Tạo mã và Tối ưu hóa (CGO), trang 2–14. IEEE, 2021.

[42] Eric Liang, Richard Liaw, Robert Nishihara, Philipp Moritz, Roy Fox,
Ken Goldberg, Joseph Gonzalez, Michael Jordan, và Ion Stoica. Rllib: Trừu tượng hóa cho học tăng cường phân tán. Trong Hội nghị quốc tế về Học máy, trang 3053–3062. PMLR, 2018.

[43] Chris Lomont. Giới thiệu về phần mở rộng vector tiên tiến intel. Intel white paper, 23, 2011.

[44] Stefano Markidis, Steven Wei Der Chien, Erwin Laure, Ivy Bo Peng,
và Jeffrey S Vetter. Khả năng lập trình, hiệu suất & độ chính xác của nvidia tensor core. Trong Pat Langley, editor, Hội thảo xử lý song song và phân tán quốc tế IEEE 2018 (IPDPSW), trang 522–531, Stanford, CA, 2018. IEEE.

[45] Devin A Matthews. Co rút tensor hiệu suất cao không có chuyển vị. SIAM Journal on Scientific Computing, 40(1):C1–C24, 2018.

[46] Volodymyr Mnih, Adria Puigdomenech Badia, Mehdi Mirza, Alex
Graves, Timothy Lillicrap, Tim Harley, David Silver, và Koray
Kavukcuoglu. Các phương pháp bất đồng bộ cho học tăng cường sâu. Trong Hội nghị quốc tế về học máy, trang 1928–1937. PMLR, 2016.

[47] Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Alex Graves,
Ioannis Antonoglou, Daan Wierstra, và Martin Riedmiller. Chơi atari với học tăng cường sâu. arXiv preprint arXiv:1312.5602, 2013.

[48] Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Alex Graves,
Ioannis Antonoglou, Daan Wierstra, và Martin Riedmiller. Chơi atari với học tăng cường sâu. arXiv preprint arXiv:1312.5602, 2013.

[49] Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Brad-
bury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein,
Luca Antiga, Alban Desmaison, Andreas Kopf, Edward Yang, Zachary
DeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit
Steiner, Lu Fang, Junjie Bai, và Soumith Chintala. Pytorch: Một thư viện học sâu hiệu suất cao, phong cách mệnh lệnh. Trong H. Wallach, H. Larochelle, A. Beygelzimer, F. d'Alché-Buc, E. Fox, và R. Garnett, editors, Advances in Neural Information Processing Systems 32, trang 8024–8035. Curran Associates, Inc., 2019.

[50] Valentin Radu, Catherine Tong, Sourav Bhattacharya, Nicholas D Lane,
Cecilia Mascolo, Mahesh K Marina, và Fahim Kawsar. Học sâu đa phương thức cho nhận dạng hoạt động và ngữ cảnh. Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, 1(4):1–27, 2018.

[51] Jonathan Ragan-Kelley, Connelly Barnes, Andrew Adams, Sylvain Paris,
Frédo Durand, và Saman Amarasinghe. Halide: một ngôn ngữ và trình biên dịch để tối ưu hóa song song, vị trí, và tính toán lại trong đường ống xử lý hình ảnh. Acm Sigplan Notices, 48(6):519–530, 2013.

[52] Kamil Rocki, Dirk Van Essendelft, Ilya Sharapov, Robert Schreiber,
Michael Morrison, Vladimir Kibardin, Andrey Portnoy, Jean Francois
Dietiker, Madhava Syamlal, và Michael James. Tính toán stencil-code nhanh trên bộ xử lý quy mô wafer. Trong SC20: Hội nghị quốc tế về Tính toán hiệu suất cao, Mạng, Lưu trữ và Phân tích, trang 1–14. IEEE, 2020.

[53] Nadav Rotem, Jordan Fix, Saleem Abdulrasool, Garret Catron, Summer
Deng, Roman Dzhabarov, Nick Gibson, James Hegeman, Meghan Lele,
Roman Levenstein, et al. Glow: Kỹ thuật trình biên dịch hạ thấp đồ thị cho mạng nơ-ron. arXiv preprint arXiv:1805.00907, 2018.

[54] Amit Sabne. Xla: Biên dịch học máy cho hiệu suất đỉnh, 2020.

[55] John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, và
Oleg Klimov. Các thuật toán tối ưu hóa chính sách gần đúng. arXiv preprint arXiv:1707.06347, 2017.

[56] David Silver, Aja Huang, Chris J Maddison, Arthur Guez, Laurent Sifre,
George Van Den Driessche, Julian Schrittwieser, Ioannis Antonoglou,
Veda Panneershelvam, Marc Lanctot, et al. Làm chủ trò chơi cờ vây với mạng nơ-ron sâu và tìm kiếm cây. nature, 529(7587):484–489, 2016.

[57] Richard M Stallman et al. Sử dụng và chuyển đổi bộ sưu tập trình biên dịch GNU, tập 86. Free Software Foundation, 1999.

[58] Benoit Steiner, Chris Cummins, Horace He, và Hugh Leather. Học giá trị cho tối ưu hóa thông lượng của khối lượng công việc học sâu. Proceedings of Machine Learning and Systems, 3, 2021.

[59] A Tekin, A Tuncer Durak, C Piechurski, D Kaliszan, F Aylin Sungur,
F Robertsén, và P Gschwandtner. Tình trạng hiện tại và xu hướng cho các giải pháp mạng tính toán và kết nối cho hpc và ai. Partnership for Advanced Computing in Europe, Có sẵn trực tuyến tại www. praceri. eu, 2021.

[60] Mircea Trofin, Yundi Qian, Eugene Brevdo, Zinan Lin, Krzysztof
Choromanski, và David Li. Mlgo: một khung tối ưu hóa trình biên dịch được hướng dẫn bởi học máy. arXiv preprint arXiv:2101.04808, 2021.

[61] Stefan Van Der Walt, S Chris Colbert, và Gael Varoquaux. Mảng numpy: một cấu trúc cho tính toán số học hiệu quả. Computing in science & engineering, 13(2):22–30, 2011.

[62] Nicolas Vasilache, Oleksandr Zinenko, Theodoros Theodoridis, Priya
Goyal, Zachary DeVito, William S Moses, Sven Verdoolaege, An-
drew Adams, và Albert Cohen. Tensor comprehensions: Trừu tượng hóa học máy hiệu suất cao bất biến khung. arXiv preprint arXiv:1802.04730, 2018.

[63] Sven Verdoolaege. isl: Một thư viện tập hợp số nguyên cho mô hình đa diện. Trong Hội nghị quốc tế về Phần mềm Toán học, trang 299–302. Springer, 2010.

[64] Huanting Wang, Zhanyong Tang, Cheng Zhang, Jiaqi Zhao, Chris
Cummins, Hugh Leather, và Zheng Wang. Tự động hóa thiết kế kiến trúc học tăng cường cho tối ưu hóa mã. Trong Kỷ yếu Hội nghị quốc tế ACM SIGPLAN lần thứ 31 về Xây dựng Trình biên dịch, trang 129–143, 2022.

[65] Bram Wasti, José Pablo Cambronero, Benoit Steiner, Hugh Leather, và
Aleksandar Zlateski. Loopstack: một ngăn xếp trình biên dịch đại số tensor nhẹ. arXiv preprint arXiv:2205.00618, 2022.

[66] R Clinton Whaley và Jack J Dongarra. Phần mềm đại số tuyến tính được điều chỉnh tự động. Trong SC'98: Kỷ yếu hội nghị ACM/IEEE 1998 về Siêu tính toán, trang 38–38. IEEE, 1998.

[67] Markus Wittmann, Thomas Zeiser, Georg Hager, và Gerhard Wellein.
Ghi chú ngắn về chi phí phép toán dấu phẩy động trên kiến trúc x86-64 hiện tại: Denormal, overflow, underflow, và chia cho không. arXiv preprint arXiv:1506.03997, 2015.

[68] Lianmin Zheng, Chengfan Jia, Minmin Sun, Zhao Wu, Cody Hao Yu,
Ameer Haj-Ali, Yida Wang, Jun Yang, Danyang Zhuo, Koushik Sen,
et al. Ansor: Tạo ra các chương trình tensor hiệu suất cao cho học sâu. arXiv preprint arXiv:2006.06762, 2020.

[69] Lianmin Zheng, Ruochen Liu, Junru Shao, Tianqi Chen, Joseph E
Gonzalez, Ion Stoica, và Ameer Haj Ali. Tenset: Một tập dữ liệu hiệu suất chương trình quy mô lớn cho trình biên dịch tensor đã học. Trong Hội nghị lần thứ ba mười lăm về Hệ thống Xử lý Thông tin Nơ-ron Tập dữ liệu và Đường đua Đánh giá (Vòng 1), 2021.

[70] Size Zheng, Yun Liang, Shuo Wang, Renze Chen, và Kaiwen Sheng.
Flextensor: Một khung khám phá và tối ưu hóa lịch trình tự động cho tính toán tensor trên hệ thống không đồng nhất. Trong Kỷ yếu Hội nghị quốc tế lần thứ hai mười lăm về Hỗ trợ Kiến trúc cho Ngôn ngữ Lập trình và Hệ điều hành, trang 859–873, 2020.

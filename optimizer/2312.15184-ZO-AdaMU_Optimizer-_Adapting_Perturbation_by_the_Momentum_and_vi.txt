# ZO-AdaMU Optimizer: Thích ứng Nhiễu loạn bằng Động lượng và Độ bất định trong Tối ưu hóa Bậc không
Shuoran Jiang1, Qingcai Chen1,2*, Youcheng Pan2∗, Yang Xiang2,
Yukang Lin1, Xiangping Wu1, Chuanyi Liu3,2, Xiaobao Song3
1Trường Khoa học Máy tính và Công nghệ, Viện Công nghệ Harbin (Thâm Quyến), Thâm Quyến, Trung Quốc
2Phòng thí nghiệm Peng Cheng, Thâm Quyến, Trung Quốc
3Viện An ninh Dữ liệu, Viện Công nghệ Harbin (Thâm Quyến), Thâm Quyến, Trung Quốc
shuoran.chiang@gmail.com, qingcai.chen@hit.edu.cn, panyoucheng4@gmail.com, xiangy@pcl.ac.cn

Tóm tắt
Giảm yêu cầu bộ nhớ trong huấn luyện tham số đầy đủ trên các mô hình lớn đã trở thành một lĩnh vực nghiên cứu nóng. MeZO tinh chỉnh các mô hình ngôn ngữ lớn (LLM) chỉ bằng các lượt truyền tiến trong một bộ tối ưu hóa SGD bậc không (ZO-SGD), thể hiện hiệu suất xuất sắc với cùng mức sử dụng bộ nhớ GPU như suy luận. Tuy nhiên, xấp xỉ ngẫu nhiên nhiễu loạn mô phỏng để ước tính gradient trong MeZO dẫn đến dao động nghiêm trọng và gây ra chi phí thời gian đáng kể. Hơn nữa, không có điều chỉnh động lượng, MeZO cho thấy vấn đề quá khớp nghiêm trọng. Cuối cùng, động lượng không liên quan đến nhiễu loạn trên ZO-SGD không cải thiện tốc độ hội tụ. Nghiên cứu này đề xuất ZO-AdaMU để giải quyết các vấn đề trên bằng cách thích ứng nhiễu loạn mô phỏng với động lượng trong xấp xỉ ngẫu nhiên của nó. Không giống như các phương pháp động lượng thích ứng hiện có, chúng tôi đặt lại động lượng trên nhiễu loạn mô phỏng trong xấp xỉ gradient ngẫu nhiên. Phân tích hội tụ và thí nghiệm của chúng tôi chứng minh đây là cách tốt hơn để cải thiện tính ổn định và tốc độ hội tụ trong ZO-SGD. Các thí nghiệm mở rộng chứng minh rằng ZO-AdaMU mang lại khả năng tổng quát hóa tốt hơn cho việc tinh chỉnh LLM trên các nhiệm vụ NLP khác nhau so với MeZO và các biến thể động lượng của nó.

Giới thiệu
Các mô hình quy mô lớn thể hiện khả năng đáng chú ý như sự nổi lên và hiểu sâu (Wei et al. 2022), đặc biệt là các mô hình ngôn ngữ lớn (LLM) cho thấy khả năng học trong ngữ cảnh (ICL) xuất sắc và cách mạng hóa phương pháp luận thống trị trong các nhiệm vụ xử lý ngôn ngữ tự nhiên (NLP) khác nhau. Tuy nhiên, việc tinh chỉnh tham số đầy đủ với hàng tỷ tham số làm tăng rào cản cho hầu hết các nghiên cứu NLP (Lv et al. 2023; Li et al. 2023). Malladi et al. (2023a) đã chứng minh thực nghiệm rằng tối ưu hóa lan truyền ngược đòi hỏi khoảng 12 lần chi phí bộ nhớ của suy luận tiến. Tinh chỉnh tham số đầy đủ một OPT 6.7 tỷ (B) (Zhang et al. 2022) với Adam (Kingma và Ba 2015) cần ít nhất 3×A100 GPU (240GB bộ nhớ).

Do đó, phương pháp tinh chỉnh tiết kiệm bộ nhớ đã trở thành một chủ đề nghiên cứu quan trọng trong kỷ nguyên mô hình quy mô lớn. Một số cách tiếp cận đã được đề xuất, chẳng hạn như ICL không cần tối ưu hóa (Sun et al. 2023a) và nhanh chóng thích ứng LLM cho các trường hợp sử dụng cụ thể thông qua các ví dụ minh họa trước các ví dụ kiểm tra. Tuy nhiên, một vài ví dụ minh họa chỉ có thể bao phủ một số loại trường hợp có thể do độ dài chuỗi tối đa hạn chế cho đầu vào LLM. Các phương pháp tinh chỉnh hiệu quả tham số (PEFT) (Fu et al. 2023), ví dụ: LoRA (Hu et al. 2021), ZeRA (Rajbhandari et al. 2020), EMAT (Wu et al. 2022) v.v., chỉ cập nhật một phần tham số mô hình. Mặc dù các phương pháp này có thể điều chỉnh LLM với tài nguyên bộ nhớ và tính toán thấp, nhưng có những giải pháp thực tế hơn để sử dụng đầy đủ khả năng nổi lên như tinh chỉnh tham số đầy đủ (Ding et al. 2022; Sun et al. 2023b).

Phương pháp tinh chỉnh tham số đầy đủ tiết kiệm bộ nhớ là cách tốt hơn để khai thác việc triển khai LLM trên tài nguyên hạn chế. Tối ưu hóa bộ nhớ thấp (LOMO) bỏ qua việc lưu trữ gradient trong hạ gradient ngẫu nhiên (SGD) (Shamir và Zhang 2013), nhưng tính toán gradient ở mỗi bước huấn luyện. Tối ưu hóa bậc không (ZO) chỉ dựa vào các lượt truyền tiến để ước tính gradient và cập nhật tham số, tiêu tốn cùng kích thước bộ nhớ như suy luận. Malladi et al. (2023a) đã đề xuất bộ tối ưu hóa bậc không tiết kiệm bộ nhớ (MeZO) để tinh chỉnh LLM chỉ với các lượt truyền tiến, và họ đã đạt được hiệu suất xuất sắc trên các nhiệm vụ NLP khác nhau. Hiệu suất đáng ngạc nhiên của MeZO được cho là do thứ hạng hiệu quả cục bộ nhỏ của ma trận tham số Hessian trong mạng thần kinh sâu được huấn luyện trước (Papyan 2018, 2020; Ghorbani, Krishnan, và Xiao 2019; Yao et al. 2020; Wu et al. 2020; Sagun et al. 2017). MeZO tính toán gradient từ hai lượt truyền tiến với nhiễu loạn ngẫu nhiên. Do đó, MeZO giảm đáng kể độ trễ giữa các tính toán GPU so với LOMO. Tuy nhiên, xấp xỉ ngẫu nhiên nhiễu loạn mô phỏng cho gradient trong MeZO là không mượt mà trong các bước huấn luyện liên tiếp. Không có sự điều chỉnh từ động lượng, giống như trong các phương pháp tối ưu hóa lan truyền ngược, MeZO gây ra vấn đề quá khớp. ZO-AdaMM (Chen et al. 2019) nỗ lực đầu tiên để tích hợp các phương pháp động lượng thích ứng với tối ưu hóa ZO, nhưng động lượng không liên quan đến nhiễu loạn đòi hỏi nhiều bước huấn luyện hơn để hội tụ.

Được thúc đẩy bởi những thách thức này, chúng tôi đề xuất bộ tối ưu hóa ZO-AdaMU, trong đó chúng tôi đầu tiên nỗ lực giới thiệu động lượng thích ứng và độ bất định trên nhiễu loạn mô phỏng để xấp xỉ gradient. Cụ thể, chúng tôi đặt lại động lượng từ gradient sang nhiễu loạn mô phỏng, nhằm cải thiện tính mượt mà giữa xấp xỉ gradient và chuyển động tham số thực tế. Ngoài ra, xấp xỉ ngẫu nhiên nhiễu loạn mô phỏng (SPSA) (Maryak và Chin 2001) bao gồm hai phần được lấy mẫu từ phân phối Gaussian tập trung động lượng và tập trung số không. Gaussian tập trung động lượng trong SPSA bao gồm một độ bất định và giá trị của nó được đặt bởi một hàm ủ mô phỏng. Với việc giới thiệu động lượng thích ứng và độ bất định, ZO-AdaMU thể hiện tính ổn định cao và tốc độ hội tụ nhanh hơn. Phân tích hội tụ và thí nghiệm toàn diện của chúng tôi chứng minh điều này cho tốc độ hội tụ ổn định và hội tụ toàn cục tốt hơn. Vì một số gradient trong ZO-AdaMU không tránh khỏi việc lệch khỏi dự đoán, chúng tôi đề xuất xấp xỉ động lượng bậc hai để cải thiện tốc độ hội tụ hơn nữa. Chi tiết của ZO-AdaMU được tóm tắt trong Thuật toán 1.

Đóng góp của bài báo chúng tôi có thể được tóm tắt như sau:
• Được thúc đẩy bởi các vấn đề dao động trong MeZO và động lượng không liên quan đến nhiễu loạn trong ZO-AdaMM, chúng tôi đầu tiên nỗ lực khám phá cách thích ứng động lượng và độ bất định trong oracle bậc không, được gọi là ZO-AdaMU.
• Phân tích lý thuyết của chúng tôi chứng minh rằng động lượng với độ bất định và việc đặt lại nó sang nhiễu loạn mô phỏng đã cải thiện tốc độ hội tụ. Đồng thời, những điều này cũng đóng góp vào một điểm tối ưu cục bộ tốt hơn so với một đối tác MeZO được điều chỉnh tốt.
• Các thí nghiệm toàn diện của chúng tôi đánh giá nhiều nhiệm vụ NLP và chứng minh rằng ZO-AdaMU cho thấy tốc độ hội tụ nhanh hơn và khả năng tổng quát hóa tốt hơn so với MeZO, LOMO, và Adam tinh chỉnh tham số đầy đủ LLM.

Kiến thức cơ bản
Tối ưu hóa bậc không (ZO) là một phương pháp không có gradient, và nó ước tính gradient thông qua xấp xỉ ngẫu nhiên nhiễu loạn mô phỏng (SPSA). Phần này giới thiệu ngắn gọn phiên bản ước tính đa điểm như trong MeZO. Ngoài ra, các phương pháp điều chỉnh dựa trên động lượng cho tối ưu hóa ZO cũng được mô tả.

Tối ưu hóa Bậc không
Tối ưu hóa bậc không (ZO) đã được nghiên cứu từ lâu trong bối cảnh các mục tiêu lồi và lồi mạnh. Một bộ ước tính gradient ZO cổ điển là xấp xỉ ngẫu nhiên nhiễu loạn đồng thời (SPSA) (Maryak và Chin 2001), và nó có thể thay thế việc tính toán gradient trong hạ gradient ngẫu nhiên (ZO-SGD) (Ghadimi và Lan 2013).

Xem xét một tập dữ liệu có nhãn D={(xi,yi)}i∈∥D∥, một lô nhỏ B ⊂ D có kích thước B, và để L(θ;B) biểu thị mất mát trên lô nhỏ cho một mô hình với tham số θ∈Rd. Ước tính gradient ZO thông qua SPSA được định nghĩa như sau:

b∇L(θ;B) = [L(θ+ϵz;B) - L(θ-ϵz;B)] / (2ϵz) ≈ zz⊤∇L(θ;B) (1)

trong đó z∈Rd với z∼N(0,I), I∈R∥θ∥ và ϵ là thang đo nhiễu loạn.

SPSA chỉ yêu cầu hai lượt truyền tiến qua mô hình θ để ước tính gradient. Các gradient được ước tính bằng SPSA có thể được sử dụng để thay thế việc tính toán gradient trong bất kỳ bộ tối ưu hóa lan truyền ngược nào như SGD.

θt+1 = θt - ηb∇L(θ;Bt) (2)

trong đó Bt biểu thị lô nhỏ ở bước t và b∇ là gradient được ước tính bằng SPSA.

ZO-SGD Tiết kiệm Bộ nhớ (MeZO)
MeZO (Malladi et al. 2023a) là một triển khai tại chỗ của ZO-SGD, và nó giảm thêm yêu cầu bộ nhớ với cùng mức sử dụng bộ nhớ như suy luận. Cụ thể, MeZO giữ hạt giống ngẫu nhiên s cho tất cả việc lấy mẫu vector ngẫu nhiên z để tạo ra mỗi nhiễu loạn z ở mỗi bước.

B ∈ D, s ← rand()
θ ← PerturbParameters(θ, ϵ, s)
ℓ+ ← L(θ,B)
θ ← PerturbParameters(θ, -2ϵ, s)
ℓ- ← L(θ,B)
θ ← PerturbParameters(θ, ϵ, s)
grad ← (ℓ+ - ℓ-) / (2ϵ)
z ∼ N(0,1) với hạt giống s
θ ← θ - η * grad * z (3)

trong đó s ← rand() lấy mẫu một hạt giống ngẫu nhiên giữ nguyên trong một bước cập nhật gradient, η là tốc độ học và ϵ là thang đo nhiễu loạn.

Phương pháp Động lượng Thích ứng cho ZO
ZO-AdaMM (Chen et al. 2019) đầu tiên nỗ lực tích hợp các phương pháp động lượng thích ứng với ZO-SGD, và nó cho thấy các đảm bảo hội tụ lý thuyết cho cả tối ưu hóa bị ràng buộc lồi và không lồi. Phương pháp này được lấy cảm hứng từ thuật toán tối ưu hóa Adam và mở rộng khả năng của nó để xử lý các tình huống mà thông tin gradient không có sẵn. Zo-AdaMM tận dụng cả các mô men bậc không, nắm bắt hành vi của hàm, và thông tin lịch sử của các lần lặp trước để điều chỉnh động kích thước bước và động lượng cho tối ưu hóa.

Phương pháp này có tiềm năng thúc đẩy các kỹ thuật tối ưu hóa trong các tình huống mà thông tin gradient không có sẵn, mở ra những con đường mới để giải quyết các vấn đề tối ưu hóa phức tạp trong thế giới thực. Tuy nhiên, nó gặp phải một yếu tố làm chậm O(√d) so với Adam bậc nhất.

Phương pháp luận
Trong phần này, chúng tôi đề xuất bộ tối ưu hóa ZO-AdaMU bằng cách thích ứng nhiễu loạn với động lượng và độ bất định trong oracle bậc không. Không giống như ước tính động lượng hậu kỳ trong các phương pháp tối ưu hóa lan truyền ngược, ZO-AdaMU thích ứng nhiễu loạn mô phỏng với động lượng và giới thiệu độ bất định thích ứng trong xấp xỉ ngẫu nhiên. Ngoài ra, chúng tôi đề xuất một cơ chế ủ mô phỏng trên độ bất định trong SPSA và các tham số làm mượt để cân bằng trọng lượng của động lượng trong xấp xỉ gradient. Chúng tôi phân tích lý thuyết rằng ZO-AdaMU có tốc độ hội tụ nhanh hơn và hội tụ toàn cục tốt hơn.

Thích ứng Động lượng bằng Động lượng và Độ bất định trong SPSA
Nhiễu loạn mô phỏng trong ZO-AdaMU được tính toán từ hai phần của phân phối Gaussian tập trung động lượng và tập trung số không:

˙zt+1 ∼ N(0, √αt+1)
¨zt+1 ∼ N(mt,p / (1-αt+1))
mt+1 = β1˙zt+1 + (1-β1)¨zt+1
s.t. 0 ≤ αt+1 ≤ 1, 0 ≤ β1 ≤ 1 (4)

trong đó mt và αt+1 biểu thị động lượng của các nhiễu loạn lịch sử và độ bất định thích ứng, các biến này cũng ngụ ý trung bình và phương sai cho phân phối Gaussian tập trung động lượng. Tương tự, 0 và 1-αt+1 biểu thị trung bình và phương sai cho phân phối Gaussian tập trung số không. ˙zt+1 và ¨zt+1 biểu thị động lượng với độ bất định và nhiễu loạn ngẫu nhiên thuần túy trong SPSA. Siêu tham số β1t+1 là tham số làm mượt, và nó cũng thích ứng với một hàm ủ mô phỏng.

Bằng cách này, gradient trên lô nhỏ Bt∈D cho một mô hình f(θ) được ước tính bởi:

b∇L(θ;Bt) = [L(θ+ϵmt;Bt) - L(θ-ϵmt;Bt)] / (2ϵmt) (5)

ZO-AdaMU cũng mô phỏng trung bình trượt theo cấp số nhân (EMA) trên bình phương của gradient (Zhuang et al. 2020) để điều chỉnh kích thước bước, và đề xuất một thay thế được định nghĩa như sau:

vt+1 = β2t+1˙z2t+1 + (1-β2t+1)¨z2t+1
θt+1 = θt - η b∇L(θ,Bt) / √(v2t+1 + σ) (6)

trong đó β2t+1 là một tham số làm mượt thích ứng và σ là một nhiễu nhỏ và thường được đặt là 10-8.

Thay đổi lớn từ các phương pháp động lượng thích ứng truyền thống là các tham số làm mượt β1t, β2t và độ bất định αt là thích ứng theo cách ủ mô phỏng như sau:

Anneal(t) = {
    1, t ∈ [1, T1)
    0.5 + 0.5 cos(π / (T3-T1) * (T3-t)^φ * (T3-T2)/(T2-T1)), t ∈ [T1, T2)
    0.9, t ∈ [T2, T3)
} (7)

trong đó φ = 1 cho α, φ = 0.1 cho β1 và φ = 1.5 cho β2. t ∈ [1, T1) là quá trình khởi động để ước tính một hướng tối ưu hóa chính trong SPSA mà không có bất kỳ ảnh hưởng nào của động lượng. Quá trình thứ hai t ∈ [T1, T2) tăng tốc tối ưu hóa bằng xấp xỉ ngẫu nhiên dựa trên động lượng, độ bất định α trên động lượng tăng dần cho đến 0.5 như được thể hiện trong Hình 1. Quá trình cuối cùng t ∈ [T2, T3) cố định α = 0.5, β1(t) = 0.9 và β2(t) = 0.01 để tìm một hội tụ toàn cục. Việc ủ mô phỏng được vẽ trong Hình 1.

ZO-AdaMU được đề xuất được tóm tắt trong Thuật toán 1.

Thuật toán 1: Bộ tối ưu hóa ZO-AdaMU
1: Đầu vào: tham số θ∈Rd, mất mát L:Rd→R, ngân sách bước T1,T2,T3, thang đo nhiễu loạn ϵ, số nhỏ σ = 10-8, kích thước lô B, độ bất định động lượng α, tốc độ học η, EMA của nhiễu loạn m và v EMA trên bình phương của nó.
2: for t = 1,...,T do
3:   Lấy mẫu lô Bt ⊂ D và hạt giống ngẫu nhiên s
4:   θ ← Perturb(θ, m(t)ϵ, s, t), ℓ+ ← L(θ;Bt)
5:   θ ← Perturb(θ, m(t), -2ϵ, s, t), ℓ- ← L(θ;Bt)
6:   θ ← Perturb(θ, m(t), ϵ, s, t), gt ← (ℓ+ - ℓ-) / (2ϵ)
7:   Đặt lại hạt giống ngẫu nhiên s
8:   for θi ∈ θ do
9:     α, β1(t), β2(t) = Anneal(t)
10:    ˙z ∼ N(0, √α), ¨z ∼ N(m(t-1)i, √(1-α))
11:    mi(t) ← β1(t) · ˙z + (1-β1(t)) · ¨z
12:    vi = β2(t) · ˙z2 + (1-β2(t)) · ¨z2
13:    θi ← θi - ηt · gt / √(v+σ) · mi(t)
14:  end for
15: end for

1: Chương trình con Perturb(θ, m, ϵ, s, t)
2: Đặt lại hạt giống ngẫu nhiên s
3: α(t), β1(t) ← Anneal(t)
4: ˙z ∼ N(0, I*√α(t)), ¨z ∼ N(m, I*√(1-α(t)))
5: θ ← ϵ * (β1(t) · ˙z + (1-β1(t)) · ¨z)

1: Chương trình con Anneal(t, T1, T2, T3)
2: α ← Anneal(t) # tham khảo Eq. (7)

Phân tích Hội tụ
Chúng tôi đưa ra phân tích lý thuyết về lý do tại sao ZO-AdaMU có tốc độ hội tụ cao hơn và hội tụ toàn cục tốt hơn. Chúng tôi tuân theo phân tích hội tụ trong MeZO và chú ý nhiều hơn đến lý do tại sao việc thích ứng nhiễu loạn với động lượng và độ bất định có thể cải thiện tính ổn định của ZO-SGD. Do đó, phân tích này làm nổi bật những lợi ích tích cực về tốc độ hội tụ từ động lượng nhiễu loạn và độ bất định.

Tốc độ Hội tụ Ổn định
Bổ đề giảm cổ điển trong tối ưu hóa SGD làm nổi bật rằng phương sai gradient lớn hơn dẫn đến giảm mất mát chậm hơn (Megerle et al. 2023).

Bổ đề 1 (Bổ đề Giảm). Cho L(θ) là ℓ-mượt (Wang và Xu 2019). Đối với bất kỳ ước tính gradient không thiên lệch g(θ,B):

E[L(θt-1)|θt] - L(θt) ≤ -η∥∇L(θt)∥2 + (1/2)η2ℓ · E[∥g(θ,Bt)∥2] (8)

Chuẩn gradient đóng vai trò quan trọng trong bổ đề giảm. Chúng tôi suy ra các chuẩn gradient cho MeZO và ZO-AdaMU tương ứng như dưới đây.

Bổ đề 2. Cho B là một lô nhỏ ngẫu nhiên có kích thước B, vậy các chuẩn gradient của MeZO và ZO-AdaMU là:

∥b∇L(θ,B)∥2 ∼ N((d+n-1)/n ∥∇L(θ,B)∥, 1·ϵ2) (9)

trong đó ϵ biểu thị thang đo lấy mẫu nhiễu loạn.

Do đó:
η-MeZO = ∥∇L(θt)∥2 / ((d+n-1)/n ∥∇L(θt)∥2 + ϵ) ≤ ∥∇L(θt)∥2 / ∥g(θt,B)∥2 ≤ ∥∇L(θt)∥2 / ((d+n-1)/n ∥∇L(θt)∥2 + ϵ) = η+MeZO (10)

Trong ZO-AdaMU, nhiễu loạn mô phỏng bao gồm hai phân phối Gaussian với phương sai α và 1-α và tham số làm mượt β1.

∥b∇L(θ,B)∥2 ∼ N((d+n-1)/n ∥∇L(θ,B)∥, √(β12α2 + (1-β1)2(1-α)2) ϵ2) (11)

Vậy:
η-AdaMU ≤ ∥∇L(θt)∥2 / ∥g(θt,B)∥2 ≤ η+AdaMU
η-AdaMU = ∥∇L(θt)∥2 / ((d+n-1)/n ∥∇L(θt)∥2 + ϵ√(β12α2 + (1-β1)2(1-α)2))
η+AdaMU = ∥∇L(θt)∥2 / ((d+n-1)/n ∥∇L(θt)∥2 - ϵ√(β12α2 + (1-β1)2(1-α)2)) (12)

Vì √(β12α2 + (1-β1)2(1-α)2) < 1, chúng ta có thể kết luận rằng η-MeZO < η-AdaMU ≤ η+AdaMU < η+MeZO và ηMeZO = n/(d+n-1) ηSGD < ηAdaMU. Do đó, ZO-AdaMU có tốc độ hội tụ nhanh hơn so với tối ưu hóa MeZO.

Độ bất định trong nhiễu loạn mô phỏng cũng giảm thứ hạng hiệu quả cục bộ của Hessian của mất mát (Papyan 2018, 2020; Ghorbani, Krishnan, và Xiao 2019; Yao et al. 2020; Sagun et al. 2017; Wu et al. 2020).

Bổ đề 3. Cho G(θt) = max(x,y)∈B ∥∇L(θt;{(x,y)})∥, đối với tất cả θt sao cho ∥θ-θt∥ ≤ ηdG[(θ)] có ∇2L(θ) ⪯ H(θt), do đó tối đa của thứ hạng hiệu quả của gradient là tr(H(θt))/∥H(θt)∥op ≈ r.

Với cùng kích thước tham số d và kích thước lô nhỏ B, bG(θt) trung bình trên các ước tính gradient của MeZO và ZO-AdaMU có:

bGMeZO(θt) > bGAdaMU(θt) (13)

và do đó:
tr(HMeZO(θt))/∥HMeZO(θt)∥op ≤ tr(HAdaMU(θt))/∥HAdaMU(θt)∥op (14)

Phân tích trên chứng minh rằng ZO-AdaMU có tốc độ nhanh hơn MeZO để giảm mất mát ở mỗi bước.

Hội tụ Toàn cục Tốt hơn
Giới hạn trên của kỳ vọng hối hận trung bình phản ánh liệu phương pháp tối ưu hóa có thể hội tụ đến một tối ưu cục bộ hay không (Shamir 2017; Zhuang et al. 2020).

Bổ đề 4. Sự hội tụ của tối ưu hóa SGD thường được đo bằng kỳ vọng hối hận trung bình:

E[R(T)] = ΣTt=1 [ft(θt) - ft(θ*)] (15)

trong đó ft(θ*) là giá trị tốt nhất với giải pháp tối ưu θ* ở bước thứ t.

Giả sử rằng mất mát L(θ) có các gradient bị chặn là ∥∇Lt(θ)∥2 ≤ G và ∥∇Lt(θ)∥∞ ≤ G∞, và khoảng cách giữa bất kỳ θMeZOn, θAdaMUt được tạo ra bởi MeZO và ZO-AdaMU đều bị chặn là ∥θMeZOn - θMeZOm∥2 ≤ D & ∥θMeZOn - θMeZOm∥∞ ≤ D∞ và ∥θAdaMUn - θAdaMUm∥2 ≤ D & ∥θAdaMUn - θAdaMUm∥∞ ≤ D∞ tương ứng cho bất kỳ m, n ∈ {1,...,T}. Các tham số làm mượt tối đa β1 = 0.9 và β2 = 0.01 trong ZO-AdaMU và β1 = 0, β2 = 0 trong MeZO tương ứng. ZO-AdaMU và MeZO đạt được các đảm bảo sau tương ứng, cho tất cả T ≥ 1.

RMeZO(T) ≤ D2/(2α) Σdi=1 √T + αG∞ Σdi=1 ∥g1:T,i∥2 + Σdi=1 D2∞G∞/(2αλ2)
RAdaMU(T) ≤ D2/(0.2α) Σdi=1 √(TvT,i) + (1.9αG∞)/(0.099×7.12) Σdi=1 ∥g1:T,i∥2 + Σdi=1 D2∞G∞√(1-β21)/(1.8α(1-λ)2)
RMeZO(T) > RAdaMU(T) (16)

Phân tích giới hạn hối hận trên cho thấy ZO-AdaMU có kỳ vọng hối hận trung bình nhỏ hơn so với MeZO, điều này chứng minh rằng ZO-AdaMU có hội tụ toàn cục tốt hơn MeZO. Đây cũng là lý do tại sao ZO-AdaMU đạt được khả năng tổng quát hóa tốt hơn trên LM.

Thí nghiệm
Các nghiên cứu sơ bộ (Brown et al. 2020; Gao, Fisch, và Chen 2021; Schick và Schütze 2021) đã chứng minh thực nghiệm rằng tối ưu hóa bậc không chỉ hoạt động với học prompt trên tinh chỉnh LLM. Tất cả các thí nghiệm trong phần này sử dụng prompt để huấn luyện LLM chỉ với tinh chỉnh lượt truyền tiến (MeZO (Malladi et al. 2023a) và ZO-AdaMU) và tinh chỉnh lan truyền ngược (Adam).

Để đánh giá hiệu quả của nhiễu loạn thích ứng được đề xuất với động lượng trong ZO-AdaMU để tinh chỉnh LLM, chúng tôi tiến hành cùng các thí nghiệm như MeZO trên cả mô hình ngôn ngữ được huấn luyện trước bằng mô hình ngôn ngữ có mặt nạ (MLM) (như RoBERTa-large 350M) (Liu et al. 2019) và LLM được huấn luyện trước tự hồi quy (OPT-13B) (Zhang et al. 2022) trong cài đặt ít shot và nhiều shot với prompt. Ngoài ra, tất cả các phương pháp tối ưu hóa được khám phá trên tinh chỉnh tham số đầy đủ, LoRA và tiền tố (Li và Liang 2021). Cuối cùng, chúng tôi đưa ra các hình ảnh trực quan của ZO-AdaMU, MeZO và Adam trên 6 hàm kiểm tra phổ biến để tối ưu hóa.

Vui lòng tham khảo mã của chúng tôi để biết chi tiết về các tập dữ liệu và mẫu prompt trong Bảng 1, 2 và 4, và các siêu tham số, tìm kiếm lưới cho các giá trị tốt nhất trong Eq. 7 và kết quả thí nghiệm để đánh giá sự hội tụ ổn định.

Mô hình Ngôn ngữ Tự hồi quy
Vì LLM tự hồi quy đã trở thành các mô hình cơ sở chủ đạo trong NLP, như GPT-3.5, GPT-4 (Lin et al. 2023), LLaMA (Touvron et al. 2023) và ChatGLM (Du et al. 2022), chúng tôi tiến hành thí nghiệm với OPT-13B trên ba mô hình nhiệm vụ NLP - phân loại câu, lựa chọn đa dạng và tạo văn bản. Tất cả các tiêu chuẩn được chọn từ SuperGLUE (Wang et al. 2019) (bao gồm COPA, SST-2, RTE, CB, WSC, WIC, MultiRC, ReCoRD), BoolQ (Clark et al. 2019), SQuAD (Rajpurkar et al. 2016) và DROP (Dua et al. 2019). Các tập huấn luyện, xác thực và kiểm tra ít shot được lấy mẫu ngẫu nhiên từ mỗi tập dữ liệu với số lượng lần lượt là 1.000, 500 và 1.000. Kết quả chính được liệt kê trong Bảng 1, và có thể đạt được các quan sát và tóm tắt sau.

I. ZO-AdaMU có lợi thế rõ ràng trong các nhiệm vụ lý luận phức tạp. Bảng 1 cho thấy ZO-AdaMU và các biến thể LoRA, tiền tố của nó vượt trội hơn MeZO và Adam tinh chỉnh OPT trên tất cả các nhiệm vụ lựa chọn đa dạng và tạo văn bản. Cụ thể, ZO-AdaMU và các biến thể LoRA, tiền tố của nó vượt trội hơn kết quả của MeZO với 1.0%, 1.0% và 2.0% trên COPA và 1.3%, 1.8% và 1.6% trên ReCoRD tương ứng. Hơn nữa, điểm F1 tốt nhất của ZO-AdaMU trên SQuAD và DROP đều cao hơn 1.0 so với điểm tốt nhất của MeZO. Lợi thế của ZO-AdaMU so với Adam còn rõ ràng hơn với khoảng cách lần lượt là 10.0, 9.1, 0.3 và 1.1.

II. ZO-AdaMU hoạt động gần nhất với các phương pháp tối ưu hóa lan truyền ngược trên các nhiệm vụ phân loại. Kết quả thí nghiệm trong Bảng 1 cho thấy các phương pháp tối ưu hóa lan truyền ngược có nhiều lợi thế hơn so với các phương pháp không có gradient trên các nhiệm vụ phân loại văn bản. Cụ thể, ZO-AdaMU có được 3 kết quả tốt nhất trên 7 tiêu chuẩn phân loại, và thắng các đối tác MeZO trên tất cả các nhiệm vụ.

Chúng tôi thiết kế một nghiên cứu khử (Bảng 3) bằng cách thích ứng lịch trình động lượng của Adam, AdamW, AdaMax, Rmsgrad trên nhiễu loạn và gradient trong ZO để tinh chỉnh prompt LLM, tương ứng. Những kết quả này cho thấy lịch trình động lượng của chúng tôi đạt được kết quả tốt nhất. Ngoài ra, các lịch trình động lượng trên nhiễu loạn nhìn chung tốt hơn so với các lịch trình trên gradient, điều này xác minh ý tưởng của chúng tôi rằng việc thích ứng động lượng trên nhiễu loạn là cách đúng đắn.

Mô hình Ngôn ngữ Có mặt nạ
Kết quả thí nghiệm trên OPT-13B đã chứng minh kết quả hứa hẹn của ZO-AdaMU trên LLM được huấn luyện trước tự hồi quy. Thí nghiệm thứ hai mở rộng ZO-AdaMU sang RoBERTa-large, một LM kích thước trung bình phổ biến trong họ MLM. Thí nghiệm này tuân theo cài đặt ít shot và nhiều shot từ Gao, Fisch, và Chen (2021) và Malladi et al. (2023b), trong đó k = 512 ví dụ được lấy mẫu từ mỗi lớp để tinh chỉnh nhiều shot. Kết quả được tóm tắt trong Bảng 2.

Những kết quả này đánh giá rằng (i) cả ZO-AdaMU và MeZO đều vượt trội đáng kể so với các phương pháp zero-shot và thăm dò tuyến tính, điều này chứng minh ZO không có gradient thực sự điều chỉnh LLM. (ii) ZO-AdaMU và MeZO vượt trội Adam trên 6 tiêu chuẩn, điều này chứng minh rằng các phương pháp ZO-SGD hiệu quả làm giảm vấn đề quá khớp khi LLM được tinh chỉnh trên dữ liệu huấn luyện hạn chế. (iii) Gradient được ước tính bằng SPSA trong Adam chỉ cho thấy cải thiện trung bình 0.43, trong khi ZO-AdaMU thể hiện sự tăng trưởng đáng kể hơn với trung bình 1.25.

Các thí nghiệm trên trên LM được huấn luyện trước MLM chứng minh rằng các khái niệm thích ứng nhiễu loạn với động lượng và độ bất định trong SPSA phù hợp hơn cho các phương pháp ZO-SGD để tinh chỉnh LLM.

Mục tiêu Không thể vi phân
Vì ZO-AdaMU được đề xuất của chúng tôi cũng là một phương pháp tối ưu hóa không có gradient, chúng tôi cũng tiến hành thí nghiệm để đánh giá ZO-AdaMU trên RoBERTa-large và OPT với độ chính xác hoặc F1 làm mục tiêu. Bảng 4 liệt kê tất cả kết quả và chúng chứng minh rằng ZO-AdaMU vượt trội hơn đối tác MeZO trên 4 trong 5 mục tiêu không thể vi phân.

Sử dụng Bộ nhớ
Vì việc lưu trữ trung bình trượt theo cấp số nhân (EMA) cho động lượng nhiễu loạn, ZO-AdaMU tăng nhẹ việc sử dụng bộ nhớ so với MeZO. Trong Hình 3, chúng tôi tóm tắt việc sử dụng bộ nhớ của zero-shot, học trong ngữ cảnh (ICL), học tiền tố và tinh chỉnh tham số đầy đủ với Adam, MeZO và ZO-AdaMU. Các thống kê này báo cáo việc sử dụng bộ nhớ GPU đỉnh bằng cách kiểm tra các mô hình OPT với GPU Nvidia A100 trên nhiệm vụ SQuAD (độ dài tối đa 2048 và kích thước lô nhỏ 1).

Như được thể hiện trong Hình 3 rằng MeZO thể hiện cùng mức tiêu thụ bộ nhớ như zero-shot, tiết kiệm tới 7 lần bộ nhớ ít nhất so với tinh chỉnh lan truyền ngược và 6 lần so với tinh chỉnh tiền tố. Mặc dù ZO-AdaMU được đề xuất của chúng tôi có sự gia tăng nhẹ về việc sử dụng bộ nhớ so với MeZO, nó không làm tăng yêu cầu cho phần cứng chính thống (như Nvidia A100 và V100) như được thể hiện trong Bảng 5. Lợi thế này cho phép huấn luyện các mô hình lớn hơn trong một ngân sách phần cứng cố định, như được minh họa trong Hình 3. Cụ thể, sử dụng một GPU A100 duy nhất, ZO-AdaMU cho phép điều chỉnh một mô hình lớn hơn 11 lần so với những gì có thể thực hiện với tinh chỉnh tham số đầy đủ.

Trực quan hóa Quỹ đạo trên Hàm Kiểm tra
Trong phần này, chúng tôi xác thực quỹ đạo huấn luyện của Adam, AdaMax, MeZO và ZO-AdaMU trên 6 hàm kiểm tra, và quỹ đạo 2D được thể hiện trong Hình 2. Các hàm kiểm tra này hữu ích để đánh giá đặc tính của các thuật toán tối ưu hóa, chẳng hạn như tốc độ hội tụ, độ chính xác, tính mạnh mẽ và hiệu suất chung.

• Hàm a: f(x, y) = |x| + |y| với tối thiểu toàn cục f(0,0) = 0 và miền tìm kiếm -3 ≤ x, y ≤ 3;
• Hàm b: f(x, y) = |x+y| + |x-y|/10 với tối thiểu toàn cục f(0,0) = 0 và miền tìm kiếm -3 ≤ x, y ≤ 3;
• Hàm c: f(x, y) = (x+y)² + (x-y)²/10 với tối thiểu toàn cục f(0,0) = 0 và miền tìm kiếm -3 ≤ x, y ≤ 3;
• Hàm d: f(x, y) = |x|/10 + |y| với tối thiểu toàn cục f(0,0) = 0 và miền tìm kiếm -3 ≤ x, y ≤ 3;
• Hàm Beale: f(x, y) = (1.5-x+xy)² + (2.25-x+xy²)² + (2.625-x+xy³)² với tối thiểu toàn cục f(3,0.5) = 0 và miền tìm kiếm -4.5 ≤ x, y ≤ 4.5;
• Hàm Rosenbrock: f(x, y) = 100(x-y²)² + (1-y)² với tối thiểu toàn cục f(1,1) = 0 và miền tìm kiếm -4.5 ≤ x, y ≤ 4.5.

Trong tất cả các hàm kiểm tra, việc thích ứng nhiễu loạn với động lượng trong ZO-SGD đạt được các điểm tối ưu trên tất cả các hàm kiểm tra, trong khi bộ tối ưu hóa MeZO thất bại trong việc tìm bất kỳ tối thiểu toàn cục nào. So với các bộ tối ưu hóa lan truyền ngược dựa trên động lượng, như Adam và AdaMax, ZO-AdaMU cho thấy quỹ đạo tương tự và đạt được các điểm tối ưu trên các hàm kiểm tra (a), (b) và (c). Ngoài ra, trên các hàm kiểm tra (d), Beale và Rosenbrock, mặc dù ZO-AdaMU cho thấy quỹ đạo tối ưu hóa khác nhau, nó đạt được các điểm tối ưu với tốc độ nhanh hơn so với Adam và AdaMax.

Kết luận
Chúng tôi đề xuất một bộ tối ưu hóa ZO-AdaMU trong công trình này, thích ứng động lượng và độ bất định trên nhiễu loạn mô phỏng trong bộ tối ưu hóa bậc không (ZO). Theo hiểu biết của chúng tôi, ZO-AdaMU là bộ tối ưu hóa ZO-SGD đầu tiên thích ứng động lượng trên xấp xỉ ngẫu nhiên cho nhiễu loạn mô phỏng. Mặc dù việc lưu trữ động lượng nhiễu loạn yêu cầu một chút chi phí bộ nhớ thêm so với MeZO, ZO-AdaMU vẫn nhất quán với MeZO về yêu cầu phần cứng GPU chính thống. Chúng tôi xác thực thực nghiệm rằng ZO-AdaMU vượt trội hơn MeZO và các bộ tối ưu hóa lan truyền ngược về tốc độ hội tụ và khả năng tổng quát hóa trên các nhiệm vụ NLP khác nhau. Các hình ảnh trực quan của chúng tôi chứng minh rằng ZO-AdaMU hoạt động tương đương với Adam và AdaMax trên các hàm kiểm tra phổ biến trong học máy.

Lời cảm ơn
Công trình này được hỗ trợ chung bởi các khoản tài trợ từ Chương trình R&D Trọng điểm Quốc gia của Trung Quốc (Số 2022ZD0116002), Dự án được tài trợ bởi Quỹ Khoa học Thạc sĩ sau đại học Trung Quốc (Số 2023M741843), Kế hoạch Khoa học và Công nghệ Thâm Quyến (Số ShenKeJiChuangXinZhi[2023]87), Sở Khoa học và Công nghệ tỉnh Quý Châu (Số Qiankehe Support[2022]General019), Quỹ Khoa học Xã hội Quốc gia - Dự án Lớn (Số 20&ZD226), Ủy ban Phát triển và Cải cách Thâm Quyến (Số XMHT20190108009), Quỹ Khoa học Tự nhiên Quốc gia Trung Quốc (Số 62276075, 62106115, 62006062 và 62176076), Phòng thí nghiệm Trọng điểm Cấp tỉnh Quảng Đông (Số 2022B1212010005), Dự án Trọng điểm Chính của PCL (Số PCL2022D01, PCL2023A09), Phòng thí nghiệm Trọng điểm Tính toán Thông minh trong Môi trường Mạng.

TẠP CHÍ CÁC TẬP TIN LỚP LATEX, TẬP 14, SỐ 8, THÁNG 8 2021 1
B2Opt: Học cách Tối ưu hóa Tối ưu hóa Hộp đen với Ngân sách Nhỏ

Xiaobin Li, Thành viên, IEEE, Kai Wu, Thành viên, IEEE, và Xiaoyu Zhang, Handing Wang, Thành viên, IEEE, Jing Liu, Thành viên cao cấp, IEEE

Tóm tắt—Thách thức cốt lõi của tối ưu hóa hộp đen chiều cao và tốn kém (BBO) là làm thế nào để đạt được hiệu suất tốt hơn nhanh hơn với chi phí đánh giá hàm ít. Bản chất của vấn đề là làm thế nào thiết kế một chiến lược tối ưu hóa hiệu quả phù hợp với nhiệm vụ mục tiêu. Bài báo này thiết kế một khung tối ưu hóa mạnh mẽ để tự động học các chiến lược tối ưu hóa từ nhiệm vụ mục tiêu hoặc nhiệm vụ thay thế rẻ mà không cần can thiệp của con người. Tuy nhiên, các phương pháp hiện tại yếu đối với điều này do biểu diễn kém của chiến lược tối ưu hóa. Để đạt được điều này, 1) dựa trên cơ chế của thuật toán di truyền, chúng tôi đề xuất một khung mạng nơ-ron sâu gọi là B2Opt, có biểu diễn mạnh hơn của các chiến lược tối ưu hóa dựa trên sự sống còn của kẻ thích nghi nhất; 2) B2Opt có thể sử dụng các hàm thay thế rẻ của nhiệm vụ mục tiêu để hướng dẫn thiết kế các chiến lược tối ưu hóa hiệu quả. So với các baseline BBO tiên tiến, B2Opt có thể đạt được cải thiện hiệu suất nhiều bậc độ lớn với chi phí đánh giá hàm ít hơn. Chúng tôi xác thực đề xuất của mình trên các hàm tổng hợp chiều cao và hai ứng dụng thực tế. Chúng tôi cũng thấy rằng B2Opt sâu hoạt động tốt hơn các B2Opt nông.

Từ khóa—Học cách Tối ưu hóa, Tối ưu hóa Hộp đen, Transformer, Bộ tối ưu hóa Đã học, Thuật toán Di truyền.

I. GIỚI THIỆU

NHIỀU nhiệm vụ, chẳng hạn như tìm kiếm kiến trúc mạng nơ-ron [1] và tối ưu hóa siêu tham số [2], [3], có thể được trừu tượng hóa thành tối ưu hóa hộp đen (BBO) [4], có nghĩa là mặc dù chúng ta có thể đánh giá f(x) cho bất kỳ x∈X nào, chúng ta không có quyền truy cập vào bất kỳ thông tin nào khác về f, chẳng hạn như Hessian và gradient. Hơn nữa, việc đánh giá f(x) rất tốn kém trong hầu hết các trường hợp. Nhiều thuật toán được thiết kế thủ công, chẳng hạn như thuật toán di truyền (GA) [5]–[7], tối ưu hóa Bayesian [8]–[12], và chiến lược tiến hóa (ES) [13]–[16], đã được thiết kế để giải quyết BBO. Mục đích của chúng là thiết kế các chiến lược tối ưu hóa cho phép chúng liên tục lấy mẫu các giải pháp tốt hơn.

Gần đây, khung học cách tối ưu hóa (L2O) [17], [18] đưa ra một cái nhìn mới về tối ưu hóa. Họ tận dụng mạng nơ-ron hồi quy (RNN), bộ nhớ dài hạn ngắn hạn (LSTM) [19]–[23], perceptron đa lớp (MLP) [24], hoặc Transformer [25] làm bộ tối ưu hóa để phát triển các phương pháp tối ưu hóa, nhằm mục đích giảm các lần lặp tốn công của kỹ thuật thủ công [21], [26]–[28]. Cốt lõi của L2O là xây dựng một ánh xạ vững chắc từ các giải pháp ban đầu đến giải pháp tối ưu. Hơn nữa, một số nỗ lực [20], [29], [30] đã xử lý các vấn đề hộp đen, hiệu quả của chúng có thể bị cản trở bởi khả năng biểu diễn hạn chế của chiến lược tối ưu hóa và số lượng lớn các đánh giá trên các hàm hộp đen tốn kém. Do đó, chúng thường xử lý các vấn đề chiều thấp.

Chiến lược tối ưu hóa trong GA bao gồm một sự sắp xếp tuần tự của các toán tử lai ghép, đột biến và lựa chọn để xử lý tối ưu hóa hộp đen. Nhưng các tham số cố định của chúng gây ra các chiến lược lấy mẫu không hiệu quả. Trong bài báo này, chúng tôi có được biểu diễn chiến lược tối ưu hóa mạnh bằng cách tham số hóa các mô-đun này, được gọi là B2Opt.

Chúng tôi thiết kế ba mô-đun để thực hiện ánh xạ từ giải pháp ngẫu nhiên đến giải pháp tối ưu. Để tạo ra các cá thể tiềm năng để tiếp cận giải pháp tối ưu, trước tiên chúng tôi phát triển mô-đun lai ghép dựa trên tự chú ý (SA) (SAC) để tạo ra các cá thể tiềm năng để tiếp cận giải pháp tối ưu. Sau đó, đầu ra của mô-đun này được đưa vào mô-đun đột biến dựa trên mạng feed-forward (FFN) được đề xuất (FM) để thoát khỏi giải pháp tối ưu cục bộ. Hơn nữa, mô-đun dư và lựa chọn (RSSM) được thiết kế để tồn tại các cá thể thích nghi nhất. RSSM là một so sánh theo cặp giữa đầu ra của SAC, FM và quần thể đầu vào liên quan đến độ thích nghi của chúng. Chúng tôi phát triển một Khối B2Opt (OB) bao gồm SAC, FM và RSSM. Cuối cùng, chúng tôi mô phỏng quy tắc lặp của GA bằng cách xếp chồng các OB để biểu diễn các chiến lược tối ưu hóa mạnh.

Để thích ứng chiến lược tối ưu hóa được biểu diễn bởi B2Opt với nhiệm vụ mục tiêu, chúng tôi cập nhật các tham số của B2Opt dựa trên thông tin của nhiệm vụ mục tiêu. Hơn nữa, để giảm số lượng đánh giá đối với hàm hộp đen tốn kém, chúng tôi thiết lập một tập hợp hàm thay thế rẻ để huấn luyện B2Opt. Chúng tôi xây dựng một tập hợp các hàm có thể vi phân rẻ với các tính chất tương tự với các vấn đề BBO được nhắm mục tiêu. Tập huấn luyện này chứa cặp quần thể ban đầu và hàm thay thế được thiết kế. Do đó, chúng tôi có thể sử dụng các phương pháp dựa trên gradient, chẳng hạn như giảm gradient ngẫu nhiên và Adam [31], để huấn luyện B2Opt. Bằng cách này, chúng tôi không cần truy vấn các hàm tốn kém trong quá trình huấn luyện.

Chúng tôi kiểm tra B2Opt trên sáu hàm chuẩn với chiều cao, bài toán huấn luyện mạng nơ-ron và bài toán cánh tay cơ học phẳng [32]. Kết quả thí nghiệm chứng minh thứ hạng hàng đầu của B2Opt và khả năng biểu diễn mạnh so với năm baseline EA tiên tiến, hai baseline Bayesian tiên tiến và ba phương pháp L2O tiên tiến. Các điểm nổi bật của bài báo này được thể hiện như sau:

• So với các phương pháp BBO tiên tiến, B2Opt đạt được cải thiện hiệu suất nhiều bậc độ lớn với ít đánh giá hàm hơn ngay cả khi tập dữ liệu huấn luyện là tập độ trung thực thấp của hàm hộp đen mục tiêu.

• Chúng tôi thiết kế khung B2Opt để thực hiện GA tự động, có thể biểu diễn tốt hơn các chiến lược tối ưu hóa. Việc ánh xạ các giải pháp ngẫu nhiên đến các giải pháp tối ưu với ít thời gian đánh giá hơn trong quá trình tối ưu hóa trở nên dễ dàng hơn.

• Chúng tôi thiết kế một chiến lược huấn luyện mới để giảm chi phí đánh giá của các hàm mục tiêu tốn kém trong quá trình huấn luyện. Nó sử dụng các hàm thay thế rẻ cho các nhiệm vụ mục tiêu tốn kém thay vì đánh giá trực tiếp hàm hộp đen mục tiêu.

Phần còn lại của bài báo này được tổ chức như sau. Phần II tóm tắt các công trình liên quan về chiến lược tối ưu hóa có thể học được. Phần III chính thức hóa vấn đề được nghiên cứu và giới thiệu nền tảng của GA và Transformer. Phần IV trình bày nội dung của B2Opt. Phần V tiến hành các thí nghiệm mở rộng để đánh giá hiệu quả của B2Opt. Cuối cùng, Phần VI kết luận toàn bộ bài báo.

II. CÔNG TRÌNH LIÊN QUAN

Chúng tôi chủ yếu tập trung vào chiến lược tối ưu hóa có thể học được cho BBO, được chia thành hai phần.

A. Meta-Học Toàn bộ Thuật toán BBO

Đề xuất của chúng tôi thuộc loại này. Chen et al. [20] đầu tiên khám phá meta-học toàn bộ thuật toán cho BBO chiều thấp. Sau đó, TV et al. [33] đề xuất RNN-Opt, học các bộ tối ưu hóa dựa trên mạng nơ-ron hồi quy (RNN) để tối ưu hóa các hàm liên tục một mục tiêu tham số thực dưới các ràng buộc ngân sách hạn chế. Hơn nữa, họ huấn luyện RNN-Opt với kiến thức về tối ưu nhiệm vụ. Bộ tối ưu hóa meta lấy cảm hứng từ đàn [29] học trong không gian thuật toán của cả thuật toán tối ưu hóa dựa trên điểm và dựa trên quần thể. Gomes et al. [34] sử dụng meta-học để suy luận các bộ tối ưu hóa hộp đen dựa trên quần thể có thể tự động thích ứng với các lớp nhiệm vụ cụ thể. Các phương pháp này tham số hóa thuật toán tối ưu hóa bằng một RNN xử lý các vector giải pháp thô và độ thích nghi liên quan của chúng.

B. Meta-Học Một phần Thuật toán BBO

Loại này chỉ học một số tham số của thuật toán, không phải toàn bộ thuật toán. Shala et al. [35] meta-học một chính sách cấu hình các tham số kích thước bước đột biến của CMA-ES [14]. LES [30] thiết kế một chiến lược tìm kiếm dựa trên tự chú ý để khám phá các quy tắc cập nhật hiệu quả cho các chiến lược tiến hóa thông qua meta-học. Công trình tiếp theo LGA [36] sử dụng khung trên để khám phá các quy tắc cập nhật của thuật toán di truyền Gaussian thông qua Open-ES [16].

Các hạn chế của những phương pháp này được thể hiện như sau: 1) để huấn luyện bộ tối ưu hóa meta, cần yêu cầu một số lượng lớn các hàm hộp đen tốn kém, điều này rất không thực tế; 2) hàm mất mát được thiết lập để huấn luyện bộ tối ưu hóa meta khó tối ưu hóa, dẫn đến biểu diễn kém của chiến lược tối ưu hóa. Do đó, chúng tôi đề xuất B2Opt để khắc phục những hạn chế trên.

III. KIẾN THỨC CƠ BẢN

A. Thuật toán Di truyền

Các toán tử lai ghép, đột biến và lựa chọn tạo thành khung cơ bản của GA. GA bắt đầu với một quần thể ban đầu được tạo ngẫu nhiên. Sau đó, các phép toán di truyền như lai ghép và đột biến sẽ được thực hiện. Sau khi đánh giá độ thích nghi của tất cả các cá thể trong quần thể, một phép toán lựa chọn được thực hiện để xác định các cá thể thích nghi hơn để trải qua sinh sản để tạo ra con cái. Quá trình tiến hóa như vậy sẽ được lặp lại cho đến khi các tiêu chí dừng được xác định trước được thỏa mãn.

a) Lai ghép: Toán tử lai ghép tạo ra một cá thể mới ˆXi bằng Eq. (1), và cr là xác suất của toán tử lai ghép.

ˆXc
i,k = Xj,k nếu rand(0,1) < cr
Xi,k nếu không (1)

trong đó k∈[1,···, d]. Toán tử này thường được thực hiện trên n cá thể. Sau khi mở rộng biểu thức, chúng tôi tái công thức hóa Eq. (1) thành Pn
i=1XiWc
i [37]. Wc
i là ma trận đường chéo. Nếu Wc
i đầy số không, cá thể thứ i không có đóng góp.

b) Đột biến: Toán tử đột biến mang lại những thay đổi ngẫu nhiên vào quần thể. Cụ thể, một cá thể Xi trong quần thể trải qua toán tử đột biến để hình thành cá thể mới ˆXi, được công thức hóa như sau:

ˆXm
i,k = rand(lk, uk) nếu rand(0,1) < mr
ˆXc
i,k nếu không (2)

trong đó mr là xác suất của toán tử đột biến và k∈[1,···, d]. Tương tự, Phương trình (2) có thể được tái công thức hóa thành XiWm
i, trong đó Wm
i là ma trận đường chéo.

c) Lựa chọn: Chúng tôi giới thiệu toán tử lựa chọn ghép đôi giải đấu nhị phân trong Eq. (3). Toán tử lựa chọn tồn tại các cá thể có chất lượng cao hơn cho thế hệ tiếp theo cho đến khi số lượng cá thể được chọn.

pi = 1 nếu f(Xi) < f(Xk)
0 nếu f(Xi) > f(Xk), (Xi, Xk) ∈ X (3)

trong đó pi phản ánh xác suất Xi được chọn cho thế hệ tiếp theo, và (Xi, Xk) trong Eq. 3 được chọn ngẫu nhiên từ quần thể X∪ˆXm.

B. Transformer

Chúng tôi chủ yếu giới thiệu phần cốt lõi của Vision Transformer [38], chẳng hạn như lớp tự chú ý đa đầu (MSA), mạng feed-forward (FFN), chuẩn hóa lớp (LN), và kết nối dư (RC).

1) MSA: MSA kết hợp một số phép toán SA để xử lý các truy vấn (Q), khóa (K) và giá trị (V) mà cùng nhau chú ý đến thông tin từ các không gian con biểu diễn khác nhau. MSA được công thức hóa như sau: MultiHead(Q, K, V) = Concat(H1, H2,···Hh)WO. trong đó Concat có nghĩa là phép toán nối. Đặc trưng đầu Hi có thể được công thức hóa như:

Hi = SA(QWQ
i, KWK
i, VWV
i)
= Softmax(QWQ
i(KWK
i)T/sqrt(dk))VWV
i = AVWVi

trong đó WQ
i ∈ Rdm×dq, WK
i ∈ Rdm×dk, và WV
i ∈ Rdm×dv là các ma trận tham số cho các truy vấn, khóa và giá trị, tương ứng; WO ∈ Rhdv×dm ánh xạ mỗi đặc trưng đầu Hi đến đầu ra. Hơn nữa, dm là chiều đầu vào, trong khi dq, dk, và dv là các chiều ẩn của không gian con chiếu tương ứng; h là số đầu. A ∈ Rl×l là ma trận chú ý của đầu thứ h, l là độ dài chuỗi.

2) FFN: FFN sử dụng hai biến đổi tuyến tính nối tiếp với một kích hoạt ReLU để xử lý X, được thể hiện như: FFN(X) = max(0, XW1 + b1)W2 + b2, trong đó W1 và W2 là trọng số của hai lớp tuyến tính, và b1 và b2 là các bias tương ứng.

3) LN: LN được áp dụng trước mỗi lớp của MSA và FFN, và đầu ra của LN được tính bởi X + [MSA|FFN](LN(X)).

IV. B2OPT

A. Định nghĩa Vấn đề

Một vấn đề tối ưu hóa hộp đen có thể được chuyển đổi thành một vấn đề tối thiểu hóa, như được thể hiện trong Eq. (4), và các ràng buộc có thể tồn tại cho các giải pháp tương ứng:

min
x f(x), s.t. xi ∈ [li, ui] (4)

trong đó x = (x1, x2,···, xd) đại diện cho giải pháp của bài toán tối ưu hóa f, các cận dưới và trên l = (l1, l2,···, ld) và u = (u1, u2,···, ud), và d là chiều của x. Giả sử n cá thể của một quần thể là X1 = (X1,1, X1,2,···, X1,d),···, Xn = (Xn,1, Xn,2,···, Xn,d), thì B2Opt được yêu cầu tìm quần thể gần giải pháp tối ưu. Lưu ý rằng chúng ta chỉ có một số rất nhỏ các đánh giá hàm để đạt được.

B. Mô-đun Lai ghép Tự Chú ý

Lấy cảm hứng từ toán tử lai ghép trong GA, chúng tôi đề xuất một mô-đun dựa trên SA để tạo ra các giải pháp tiềm năng bằng cách tối đa hóa tương tác thông tin giữa các cá thể trong một quần thể. Giả sử một quần thể X được sắp xếp theo thứ tự không giảm của độ thích nghi, và F ∈ Rn×1 là ma trận độ thích nghi của X. Sau đó, mô-đun này có thể được biểu diễn như sau:

Xc = SAC(X, F) (5)

trong đó Xc là quần thể đầu ra của mô-đun SAC.

Vì đối tượng được xử lý bởi B2Opt là quần thể với một số cá thể, và thứ tự của các cá thể không ảnh hưởng đến phân bố quần thể, SA không yêu cầu mã hóa vị trí. SA chuẩn chiếu chuỗi đầu vào X vào không gian d chiều thông qua các truy vấn (Q), khóa (K), và giá trị (V). Ba ánh xạ này cho phép mô-đun SA nắm bắt tốt hơn các đặc điểm của các vấn đề gặp phải trong quá trình huấn luyện. Nói cách khác, ba ánh xạ này tăng cường khả năng của SA để tập trung vào các vấn đề cụ thể nhưng không nhất thiết làm cho SA có khả năng chuyển giao tốt giữa các vấn đề khác nhau. Do đó, chúng tôi xem xét loại bỏ ba ánh xạ này để tăng cường khả năng chuyển giao và Xc = AX.

A ∈ Rn×n là ma trận tự chú ý có thể được học để tối đa hóa tương tác thông tin giữa các cá thể dựa trên thông tin xếp hạng cá thể. Vì A sử dụng thông tin xếp hạng cá thể thay vì thông tin giá trị độ thích nghi, A không thay đổi theo các vấn đề, điều này có lợi để cải thiện hiệu suất tổng quát của mô hình. Đây là lý do tại sao quần thể cần được sắp xếp theo thứ tự không giảm.

Tuy nhiên, việc thiết kế mô-đun SAC dựa chỉ trên thông tin xếp hạng quần thể là một phương pháp thô. Vì cách này chỉ xem xét thông tin vị trí của các cá thể trong quần thể nhưng không xem xét mối quan hệ độ thích nghi giữa các cá thể. Do đó, chúng tôi tiếp tục giới thiệu thông tin độ thích nghi để hỗ trợ thiết kế mô-đun SAC:

AF = SA(F) = Softmax(FWQ(FWK)T/sqrt(dk)) (6)

Do đó, Xc = AX + AFX. Để cân bằng tốt hơn vai trò của A và AF, chúng tôi giới thiệu hai trọng số có thể học Wc
1 ∈ Rn×1 và Wc
2 ∈ Rn×1. Do đó, mô-đun SAC cuối cùng được thể hiện như sau:

Xc = tile(Wc
1) ⊙ (AX) + tile(Wc
2) ⊙ (AFX) (7)

trong đó ⊙ đại diện cho tích Hadamard và hàm tile copy mở rộng vector thành ma trận.

C. Mô-đun Đột biến dựa trên FFN

Trong Transformer, mỗi embedding patch thực hiện biến đổi đặc trưng có hướng thông qua mô-đun FFN. Chúng tôi lấy một lớp tuyến tính làm ví dụ: X = XWF, trong đó WF là trọng số của lớp tuyến tính, và nó được áp dụng cho mỗi embedding một cách riêng biệt và giống nhau. Định dạng công thức tương tự của toán tử đột biến và FFN truyền cảm hứng cho chúng tôi thiết kế một mô-đun đột biến có thể học FM dựa trên FFN với hàm kích hoạt ReLU:

Xm = FM(Xc) = (ReLU(XcWF
1 + b1))WF
2 + b2 (8)

trong đó Xm là quần thể sau khi đột biến của Xc. WF
2 và WF
1 đại diện cho trọng số của lớp thứ hai của FFN và trọng số của lớp thứ nhất của FFN, tương ứng. b2 và b1 đại diện cho bias của lớp thứ hai và lớp thứ nhất của FFN, tương ứng. FM được thiết kế để thoát khỏi tối ưu cục bộ.

D. Mô-đun Lựa chọn

Kết nối dư trong transformer có thể được tương tự với phép toán lựa chọn trong GA [37]. RSSM tạo ra quần thể con cái theo phương trình sau:

ˆX = RSSM(X, Xc, Xm)
= Sort(SM(X, tile(Ws
1) ⊙ X
+ tile(Ws
2) ⊙ Xc + tile(Ws
3) ⊙ Xm)) (9)

trong đó ˆX là quần thể thích nghi nhất cho thế hệ tiếp theo; các trọng số có thể học Ws
1 ∈ Rn×1, Ws
2 ∈ Rn×1, và Ws
3 ∈ Rn×1 là các trọng số cho X, Xc, và Xm, tương ứng. Sort(X) đại diện cho việc X được sắp xếp theo thứ tự không giảm của độ thích nghi. Chúng tôi sử dụng quicksort để sắp xếp quần thể dựa trên độ thích nghi hàm. Ba ma trận trọng số có thể học này thực hiện tổng có trọng số của các kết nối dư, từ đó mô phỏng một chiến lược lựa chọn có thể học. Đồng thời, việc giới thiệu cấu trúc dư tăng cường khả năng biểu diễn của mô hình, cho phép B2Opt hình thành một kiến trúc sâu.

SM cập nhật các cá thể dựa trên so sánh theo cặp giữa con cái và quần thể đầu vào liên quan đến độ thích nghi của chúng. Giả sử X và X' là các quần thể đầu vào của SM. Chúng tôi so sánh chất lượng của các cá thể từ X và X' theo cặp dựa trên độ thích nghi. Một ma trận mặt nạ nhị phân chỉ ra cá thể được chọn có thể được thu được dựa trên hàm chỉ báo lx>0(x), trong đó lx>0(x) = 1 nếu x > 0 và lx>0(x) = 0 nếu x < 0. SM hình thành một quần thể mới ˆX bằng cách sử dụng Eq. (10).

ˆX = tile(lx>0(MF' - MF)) ⊙ X
+ tile(1 - lx>0(MF' - MF)) ⊙ X' (10)

trong đó hàm tile copy mở rộng vector chỉ báo thành ma trận, MF (MF') biểu thị ma trận độ thích nghi của X (X').

E. Cấu trúc của B2Opt

B2Opt bao gồm các khối B2Opt cơ bản (OB), và các tham số có thể được chia sẻ giữa các OB này hoặc không. Kiến trúc tổng thể của B2Opt và OB được thể hiện trong Hình 1. Mỗi OB bao gồm SAC, FM, và RSSM theo thứ tự tuần tự. X0 ∈ Rn×d đại diện cho quần thể ban đầu được đưa vào B2Opt, phải được sắp xếp theo thứ tự không giảm độ thích nghi. Trong Eq. 11, Xi-1 được đưa vào OB thứ t để có Xi, trong đó i ∈ [1, t]. B2Opt thực hiện ánh xạ từ quần thể ban đầu ngẫu nhiên đến quần thể mục tiêu bằng cách xếp chồng t OB.

Xi = OB(Xi-1); Xc = SAC(Xi-1, F); (11)
Xm = FM(Xc); Xi = RSSM(Xi-1, Xc, Xm)

F. Huấn luyện B2Opt

1) Mục tiêu: Chúng tôi giới thiệu các tham số θ của B2Opt, cần được tối ưu hóa. Ở đây, chúng tôi đặt θ = {Wc
1, Wc
2, A, WF
1, WF
2, b1, b2, Ws
1, Ws
2, Ws
3}.

2) Tập dữ liệu huấn luyện: Trước khi giới thiệu các chi tiết của tập dữ liệu huấn luyện, độ trung thực [39] được định nghĩa như sau: Giả sử các hàm thay thế có thể vi phân f1, f2,···, fm là các xấp xỉ chính xác liên tục của hàm hộp đen f. Chúng tôi gọi những xấp xỉ này là độ trung thực, thỏa mãn các điều kiện sau: 1) f1,···, fi,···, fm xấp xỉ f. ||f - fi||∞ ≤ ζm, trong đó cận độ trung thực ζ1 > ζ2 > ···ζm. 2) Ước lượng xấp xỉ fi rẻ hơn ước lượng f. Giả sử chi phí truy vấn ở độ trung thực là λi, và λ1 < λ2 < ···λm.

Dữ liệu huấn luyện là một yếu tố quan trọng ngoài các hàm mục tiêu. Bài báo này thiết lập tập huấn luyện bằng cách xây dựng một tập hợp các hàm có thể vi phân liên quan đến mục tiêu tối ưu hóa. Tập dữ liệu huấn luyện này chỉ chứa (X0, fi(x|ω)), quần thể ban đầu và hàm mục tiêu, tương ứng. Phương sai của ω gây ra sự dịch chuyển trong cảnh quan. Tập dữ liệu huấn luyện được thiết kế như sau:

1) Khởi tạo ngẫu nhiên quần thể đầu vào X0;
2) Tạo ngẫu nhiên một hàm mục tiêu dịch chuyển fi(x|ω) bằng cách điều chỉnh tham số ω;
3) Đánh giá X0 bằng fi(x|ω);
4) Lặp lại các Bước 1)-3) để tạo ra tập dữ liệu tương ứng.

Chúng tôi trình bày các tập dữ liệu huấn luyện và kiểm tra được thiết kế như sau:

Ftrain = {f1(x|ωtrain
1,i),···, fm(x|ωtrain
m,i)} (12)

trong đó ωtrain
m,i đại diện cho các giá trị khác nhau thứ i của ω trong hàm thứ m fm.

3) Hàm mất mát: B2Opt cố gắng tìm kiếm các cá thể có chất lượng cao dựa trên thông tin có sẵn. Hàm mất mát cho biết cách thu được các tham số của B2Opt để tạo ra các cá thể gần với giải pháp tối ưu hơn bằng cách tối đa hóa sự khác biệt giữa quần thể ban đầu và quần thể đầu ra của B2Opt. Hàm mất mát sau li(X0, f(x|ω), θ) được sử dụng,

li = (1/|X0| ∑x∈X0 fi(x|ω) - 1/|Eθ(X0)| ∑x∈Eθ(X0) fi(x|ω)) / (1/|X0| ∑x∈X0 fi(x|ω)) (13)

trong đó θ biểu thị các tham số của B2Opt (E). Phương trình (13) tính toán sự khác biệt độ thích nghi trung bình giữa đầu vào và đầu ra, được chuẩn hóa thêm trong [0,1]. Để khuyến khích B2Opt khám phá cảnh quan độ thích nghi, ví dụ, phân bố posterior Bayesian được xây dựng trên tối ưu toàn cục [40] có thể được thêm vào Eq. (13). Chúng tôi có ba cách để huấn luyện B2Opt:

1) Khi chúng ta có thể xây dựng một hàm proxy có thể vi phân của hàm mục tiêu, chúng ta sử dụng thông tin gradient của Eq. (13) để huấn luyện B2Opt.
2) Khi khó xây dựng các hàm thay thế có thể vi phân của hàm mục tiêu, chúng ta có thể sử dụng REINFORCE [41] để ước lượng các đạo hàm này.
3) Chúng ta có thể sử dụng ES [26] để huấn luyện B2Opt. Ở đây, chúng tôi tập trung vào việc giới thiệu huấn luyện B2Opt thông qua phương pháp đầu tiên.

4) Huấn luyện B2Opt: Sau đó chúng tôi huấn luyện B2Opt dưới chế độ có giám sát. Vì gradient không cần thiết trong quá trình kiểm tra, B2Opt có thể giải quyết các vấn đề BBO. Để chuẩn bị B2Opt học một hiệu suất cân bằng trên các vấn đề tối ưu hóa khác nhau, chúng tôi thiết kế một hàm mất mát được công thức hóa như sau:

arg minθ lΩ = -1/K ∑X0∈Ω li(X0, fi(x|ωtrain
i), θ) (14)

Chúng tôi sử dụng phương pháp Adam [31] với minibatch Ω để huấn luyện B2Opt trên tập dữ liệu huấn luyện.

5) Quy trình huấn luyện chi tiết: Mục tiêu của thuật toán huấn luyện là tìm kiếm các tham số θ* của B2Opt. Trước khi huấn luyện bắt đầu, B2Opt được khởi tạo ngẫu nhiên để có các tham số ban đầu θ. Sau đó thuật toán sẽ thực hiện ba bước sau trong một vòng lặp cho đến khi điều kiện chấm dứt huấn luyện được thỏa mãn:

1) Bước 1, khởi tạo ngẫu nhiên một minibatch Ω bao gồm K quần thể X0;
2) Bước 2, với mỗi fi ∈ Ftrain, cho dữ liệu huấn luyện (X0, fi), cập nhật θ bằng cách tối thiểu hóa lΩ;
3) Bước 3, cho X0, cập nhật θ bằng cách tối thiểu hóa -1/m ∑i lΩ, trong đó m là số lượng hàm trong Ftrain. Sau khi hoàn thành quá trình huấn luyện, thuật toán sẽ đưa ra θ*.

V. THÍ NGHIỆM

A. Thiết lập Thí nghiệm

1) Tập dữ liệu:

a) Hàm tổng hợp: Bài báo này đầu tiên sử dụng chín hàm thường được sử dụng để thể hiện hiệu quả của B2Opt được đề xuất. Các đặc điểm của chín hàm này được thể hiện trong Bảng I. Ở đây, B2Opt được huấn luyện trên Ftrain được tạo ra dựa trên F1-F3, và các hàm mục tiêu là F4-F9. B2Opt được huấn luyện trên tập hợp các nhiệm vụ với độ trung thực thấp cho hàm mục tiêu. Chúng tôi kiểm tra hiệu suất tổng quát của B2Opt thông qua trường hợp này. Hơn nữa, B2Opt được huấn luyện trên các hàm mục tiêu với các bias hàm khác nhau. Sau đó chúng tôi kiểm tra nó trên hàm mục tiêu với các bias chưa được thấy trong giai đoạn huấn luyện; chúng tôi gọi nó là B2Opt-V2.

b) Cánh tay Cơ học Phẳng: Chúng tôi tiếp tục đánh giá hiệu suất của sơ đồ được đề xuất trên bài toán cánh tay cơ học phẳng [42]–[45], một bài toán điều khiển robot đã được sử dụng rộng rãi để đánh giá hiệu suất của các thuật toán BBO. Nó được thể hiện trong Hình 2. Mục tiêu tối ưu hóa của bài toán này là tìm kiếm một tập hợp độ dài L = (L1, L2,···, Ln) và một tập hợp các góc α = (α1, α2,···, αn) sao cho khoảng cách f(L, α, p) từ đỉnh của cánh tay cơ học đến vị trí mục tiêu p là nhỏ nhất, trong đó n đại diện cho số đoạn của cánh tay cơ học, và Li ∈ (li, ui) và αi ∈ (-Π, Π) đại diện cho độ dài và góc của cánh tay cơ học thứ i, tương ứng. r đại diện cho khoảng cách từ điểm mục tiêu đến gốc của cánh tay cơ học. Thông thường, f = √((∑ni=1 cos(αi)Li - px)² + (∑ni=1 sin(αi)Li - py)²), trong đó px và py đại diện cho tọa độ x và tọa độ y của điểm mục tiêu, tương ứng.

Ở đây, n = 100, li = 0 và ui = 10. Chúng tôi thiết kế hai nhóm thí nghiệm:

1) Trường hợp Đơn giản. Chúng tôi cố định độ dài của mỗi cánh tay cơ học là li = 10 và chỉ tìm kiếm α tối ưu.
2) Trường hợp Phức tạp. Chúng tôi cần tìm kiếm L và α đồng thời. Chúng tôi chọn ngẫu nhiên 600 điểm mục tiêu trong phạm vi r ≤ 1000 để hình thành một tập S, trong đó r đại diện cho khoảng cách từ điểm mục tiêu đến gốc của cánh tay cơ học, như thể hiện trong Hình 2. Trong quá trình huấn luyện của B2Opt, một tập điểm mẫu s được tái trích xuất từ S để huấn luyện mỗi chu kỳ huấn luyện T. Trong quá trình kiểm tra, chúng tôi trích xuất 128 điểm mục tiêu (Stest) trong phạm vi r ≤ 100, r ≤ 300, và r ≤ 1000, tương ứng, để kiểm tra. Mục đích của việc kiểm tra trong ba vùng khác nhau là để khám phá thêm hiệu suất tổng quát của B2Opt. Chúng tôi đánh giá khả năng tổng quát của thuật toán bằng ∑Stest s f(L, α, s)/|Stest|.

c) Huấn luyện Mạng Nơ-ron: Chúng tôi tiếp tục phân tích hiệu suất của B2Opt trong lĩnh vực neuroevolution. Chúng tôi đánh giá hiệu suất của việc huấn luyện một mạng nơ-ron tích chập [46] bằng B2Opt trên nhiệm vụ phân loại MNIST. Cấu trúc của mô hình mạng này được thể hiện trong Bảng II. Nhiệm vụ này liên quan đến một số lượng lớn các tham số. B2Opt và các baseline được giao nhiệm vụ giải quyết các tham số của mạng nơ-ron này để tối đa hóa độ chính xác kiểm tra. Mạng không sử dụng bất kỳ bias nào, và tổng số tham số là 567. Nếu thuật toán SGD trực tiếp tối ưu hóa mạng nơ-ron, mạng có thể đạt được khoảng 90% độ chính xác kiểm tra, điều này chứng minh rằng kiến trúc mạng là hiệu quả. Chúng tôi sử dụng 1000 mẫu từ tập dữ liệu MNIST để hình thành tập huấn luyện và 1000 mẫu khác làm tập kiểm tra.

2) Baseline: B2Opt được so sánh với các phương pháp BBO tiên tiến, bao gồm cả non-L2O và dựa trên L2O.

Baseline EA. DE(DE/rand/1/bin) [47], ES((μ,λ)-ES), IPOP-CMA-ES [48], L-SHADE [49], và CMA-ES [50], trong đó DE [47] và ES được triển khai dựa trên Geatpy [51], CMA-ES và IPOP-CMA-ES được triển khai bởi cmaes¹, và L-SHADE được triển khai bởi pyade². Lý do chọn các baseline EA này như sau:

• DE(DE/rand/1/bin): Một thuật toán tối ưu hóa số học cổ điển.
• ES((μ,λ)-ES): Một biến thể cổ điển của chiến lược tiến hóa.
• CMA-ES: CMA-ES thường được coi là phương pháp tiên tiến cho tối ưu hóa miền liên tục dưới các thiết lập thách thức (ví dụ, ill-conditioned, non-convex, non-continuous, multimodal).
• IPOP-CMA-ES: Biến thể tiên tiến của CMA-ES.
• L-SHADE: Biến thể tiên tiến của DE.

Tối ưu hóa Bayesian. Dragonfly [52] và SAASBO [53] được sử dụng làm tham chiếu. Đây là lý do chọn hai thuật toán này:

• Dragonfly: Một thuật toán đại diện cho tối ưu hóa Bayesian.
• SAASBO: Một thuật toán tối ưu hóa Bayesian quy mô lớn tiên tiến.

Phương pháp dựa trên L2O. Chúng tôi chọn ba phương pháp dựa trên L2O tiên tiến để so sánh với B2Opt.

• L2O-swarm [29]: Một phương pháp L2O đại diện cho BBO.
• LES [30]: Một ES có thể học được đề xuất gần đây. Nó sử dụng phương pháp data-driven để khám phá ES mới với hiệu suất tổng quát mạnh và hiệu quả tìm kiếm.
• LGA [36]: Một GA có thể học được đề xuất gần đây khám phá GA mới theo cách data-driven. Thuật toán đã học có thể được áp dụng cho các vấn đề tối ưu hóa chưa thấy, chiều tìm kiếm và ngân sách đánh giá.

B2Opt. Chúng tôi thiết kế ba mô hình B2Opt, bao gồm 3 OB với WS, 5 OB không có WS, và 30 OB với WS. 3 OB với WS đại diện cho việc B2Opt có 3 mô-đun OB, và các OB này chia sẻ trọng số với nhau. Mỗi OB bao gồm 1 SAC, 1 FM, và 1 RSSM. Nói chung, B2Opt đại diện cho 30 OB với WS.

3) Tham số: Tiếp theo, chúng tôi thể hiện các thiết lập tham số của những phương pháp này:

B2Opt. Trong 30 OB với WS, 30 OB này chia sẻ tham số. 5 OB không có WS có 5 OB, và không có tham số nào được chia sẻ giữa chúng. Trong quá trình huấn luyện, B2Opt được huấn luyện trong 1000 epoch. Tốc độ học ban đầu (lr) được đặt thành 0.01 và lr = lr × 0.9 mỗi 100 chu kỳ. Norm 2 của gradient được cắt để không lớn hơn 10. Bias của hàm được tái tạo mỗi epoch, và một batch mới của các quần thể ban đầu ngẫu nhiên được tạo ra.

Baseline. Đối với tất cả các trường hợp, chúng tôi chọn các siêu tham số tối ưu. Đối với ES và DE, kích thước quần thể được đặt thành 100, λ = 0.5, cr = 0.5, F = 0.5, và phần còn lại của các tham số là các giá trị mặc định được đặt bởi geatpy. Đối với CMA-ES, phần còn lại của các tham số lấy các giá trị mặc định của gói cmaes. Kích thước quần thể của L-SHADE là 100, và phần còn lại của các tham số áp dụng các tham số mặc định của gói pyade. Kích thước quần thể ban đầu của IPOP-CMA-ES là 30, và hệ số tăng trưởng quần thể là 2. L-SHADE và IPOP-CMA-ES được biết đến với sự hội tụ nhanh. Đối với tất cả các baseline EA, số lượng đánh giá tối đa được đặt thành 3100, phù hợp với số lượng đánh giá của B2Opt (30 OB với WS). Chúng tôi đặt số lượng thế hệ tối đa của Dragonfly và SAASBO thành 100. Vì chi phí runtime của hai thuật toán tối ưu hóa Bayesian này rất đắt, phải mất vài ngày để hoàn thành 100 thế hệ khi d = 100. Ngay cả khi d = 10, phải mất nhiều giờ để hoàn thành 100 đánh giá. Nhưng B2Opt có thể hoàn thành việc chạy trong 1 giây, vì vậy chi phí runtime thực tế đắt đỏ của SAASBO và Dragonfly là không thể chấp nhận được. Kích thước quần thể của LGA và LES là 100, và số lượng đánh giá hàm tối đa là 3100. Chúng tôi sử dụng các tham số mô hình đã huấn luyện tối ưu được cung cấp chính thức bởi trang web dự án của họ³. FTrain và Ftest giống như của B2Opt. Trong giai đoạn kiểm tra, L2O-Swarm được chạy đến khi hội tụ.

Để đảm bảo tính hợp lệ, tất cả kết quả thí nghiệm được lấy trung bình đến các giá trị tối ưu của năm nhóm thí nghiệm, mỗi nhóm thực hiện 64 lần chạy. Tất cả các thí nghiệm được thực hiện trên PC Ubuntu 20.04 với Intel(R) Core I7 (TM) I3-8100 CPU ở 3.60GHz và NVIDIA GeForce GTX 1060.

B. Kết quả

a) Hàm tổng hợp: Ở đây, cấu trúc của B2Opt là 30 OB với WS. Kết quả trên các hàm tổng hợp được cung cấp trong Hình 3. Chúng tôi cũng vẽ các đường cong hội tụ của tất cả các phương pháp trên F4-F9 với d = {10, 100}, như thể hiện trong Hình 4 và 5. B2Opt hội tụ nhanh chóng và có thể thu được các giải pháp tốt hơn với ngân sách nhỏ. Càng ít đánh giá hàm, lợi thế của B2Opt càng lớn. Khi d = 10, B2Opt đạt được hiệu suất tốt hơn tất cả các phương pháp SOTA ngoại trừ L-SHADE trong tất cả các trường hợp. B2Opt thua L-SHADE năm trường hợp và vượt trội L-SHADE trong một trường hợp (F7). L-SHADE là biến thể DE tối ưu, được thiết kế kỹ càng và tinh vi bởi các nhà nghiên cứu kết hợp kiến thức chuyên môn phong phú. Nó đã được cập nhật lặp đi lặp lại nhiều lần qua các năm. L-SHADE có thể thu được các quần thể ban đầu hiệu suất cao trên F4-F9, tốt hơn nhiều so với B2Opt. Tuy nhiên, tốc độ hội tụ của B2Opt nhanh hơn nhiều so với L-SHADE, và B2Opt rất có khả năng cạnh tranh, đặc biệt là với số lượng đánh giá hàm tối thiểu. Tuy nhiên, khi d = 100, B2Opt vượt trội tất cả các phương pháp SOTA trong F4-F9. Khi chiều vấn đề là 10, vấn đề tương đối đơn giản, và khi chiều vấn đề là 100, vấn đề trở nên rất phức tạp. B2Opt đạt được hiệu suất tốt nhất trên tất cả các hàm được kiểm tra trong các trường hợp phức tạp. L-SHADE có lợi thế mạnh đối với các vấn đề đơn giản. Lưu ý rằng các siêu tham số của L-SHADE được điều chỉnh tối ưu cho hiệu suất của nhiệm vụ mục tiêu. Tuy nhiên, B2Opt chỉ được huấn luyện trên các hàm thay thế độ trung thực thấp F1-F3 của nhiệm vụ mục tiêu.

LES và LGA là các thuật toán tiến hóa có thể học mới nhất với hiệu suất mạnh mẽ. Chúng được huấn luyện trên một số lượng lớn các hàm BBOB, nhiều trong số đó giống hoặc tương tự với các hàm kiểm tra được thể hiện trong Bảng I. Ví dụ, các tập dữ liệu huấn luyện LES và LGA bao gồm F4, F5, F6, và F8. Như thể hiện trong Hình 4 và 5, quần thể ban đầu đã đạt được hiệu suất tốt. B2Opt chỉ thực hiện huấn luyện đơn giản trên F1, F2, và F3 trong Bảng I, và F4-F9 chưa được thấy đối với B2Opt trong giai đoạn huấn luyện. Tuy nhiên, B2Opt vượt trội LES và LGA trong tất cả các hàm được kiểm tra.

B2Opt-V2 vượt trội B2Opt tổng thể. Tuy nhiên, B2Opt-V2 hoạt động tệ hơn B2Opt trên F8. B2Opt-V2 được huấn luyện trên hàm thay thế độ trung thực cao của nhiệm vụ mục tiêu. Chúng tôi thấy rằng F8 có đặc điểm "Rotated" và phạm vi rộng của các giá trị zi, gây ra B2Opt-V2 bị overfitting. B2Opt-V2 vượt trội B2Opt sau khi chúng tôi tăng kích thước mẫu huấn luyện.

Các trường hợp này cũng thể hiện khả năng tổng quát xuất sắc của B2Opt trên nhiều nhiệm vụ chưa thấy trong giai đoạn huấn luyện. Khả năng chuyển giao của B2Opt tỷ lệ thuận với sự tương tự cảnh quan độ thích nghi giữa tập huấn luyện và vấn đề. Mặc dù các thuộc tính vấn đề mới không có sẵn trong tập huấn luyện, B2Opt có thể hoạt động tốt hơn. Tuy nhiên, kết luận này chỉ đúng khi sự tương tự giữa vấn đề và tập dữ liệu huấn luyện cao. Bây giờ chúng tôi phân tích thêm các lý do chi tiết cho hiệu quả xuất sắc của B2Opt.

Chúng tôi huấn luyện B2Opt dựa trên F1-F3 và làm cho nó tối ưu hóa thành công F4-F9, và chúng tôi cũng phân tích lý do cho trường hợp này. Từ biểu thức của các hàm, F1-F3 là các hàm thay thế độ trung thực thấp của các hàm mục tiêu F4-F9. F1-F3 chứa thông tin của các hàm mục tiêu (F4-F9). Ví dụ, F7 có thể được phân tách thành ∑Di=1 zi² - ∑Di=1 10cos(2πzi) + ∑Di=1 10. F2 là hàm thay thế độ trung thực thấp của ∑Di=1 zi². F1 là hàm thay thế độ trung thực thấp của ∑Di=1 10cos(2πzi). Đối với các hàm khác trong F4-F9, chúng ta có thể tìm thấy các hàm thay thế tương tự từ F1-F3. B2Opt có thể sử dụng thông tin này để tối đa hóa mức độ khớp giữa chiến lược tối ưu hóa đã học và hàm mục tiêu. Tuy nhiên, F6 ít tương tự với F1-F3 hơn F4, F5, và F7-F9. Do đó, mặc dù hiệu suất của B2Opt trên F6 tốt hơn thuật toán so sánh, nó vẫn cần cải thiện.

Từ góc độ đặc điểm cảnh quan, F1-F3 bao gồm các đặc điểm sau: unimodal, multimodal, separable, và non-separable. Các đặc điểm cảnh quan được bao gồm trong F4-F9 như sau:

• F4: Unimodal, Separable
• F5: Unimodal, Separable
• F6: Multimodal, Non-separable, Có thung lũng rất hẹp từ tối ưu cục bộ đến tối ưu toàn cục, Ill-conditioned
• F7: Multimodal, Separable, Asymmetrical, Số lượng tối ưu cục bộ rất lớn
• F8: Multi-modal, Non-separable, Rotated
• F9: Multi-modal, Non-separable, Asymmetrical

Các đặc điểm cảnh quan của F4 và F5 có thể được tìm thấy trong F1-F3. F6-F9 đều có các đặc điểm mới. Cường độ gây nhiễu của các đặc điểm khác nhau đối với cảnh quan được sắp xếp như sau: Có thung lũng rất hẹp từ tối ưu cục bộ đến tối ưu toàn cục > Asymmetrical, Số lượng tối ưu cục bộ rất lớn > Asymmetrical > Rotated. Do đó, B2Opt có hiệu suất tổng quát tốt nhất trên F4, F5, F8, hiệu suất tổng quát tốt thứ hai trên F7 và F9, và tệ nhất trên F6.

b) Cánh tay Cơ học Phẳng: Kết quả thí nghiệm chi tiết trong Bảng III. Lưu ý rằng dấu ngoặc đơn trong bảng thể hiện độ lệch chuẩn nếu không được chỉ định khác. Cấu trúc của B2Opt là 30 OB với WS. Untrained đại diện cho B2Opt chưa được huấn luyện. Chúng tôi chọn ngẫu nhiên 600 điểm mục tiêu trong phạm vi r ≤ 1000 để hình thành một tập S, trong đó r đại diện cho khoảng cách từ điểm mục tiêu đến gốc của cánh tay cơ học, như thể hiện trong Hình 2. Trong quá trình huấn luyện của B2Opt, một tập điểm mẫu s được tái trích xuất từ S để huấn luyện mỗi chu kỳ huấn luyện T. Trong quá trình kiểm tra, chúng tôi trích xuất 128 điểm mục tiêu (Stest) trong phạm vi r ≤ 100, r ≤ 300, và r ≤ 1000, tương ứng, để kiểm tra. Mục đích của việc kiểm tra trong ba vùng khác nhau là để khám phá thêm hiệu suất tổng quát của B2Opt. B2Opt thắng tất cả các phương pháp SOTA và đạt được kết quả tốt nhất so với các thuật toán khác. B2Opt thua L-SHADE một lần trong SC với r = 1000. Tuy nhiên, trong 5 trường hợp khác, B2Opt vượt trội L-SHADE. Đặc biệt, trên vấn đề phức tạp (CC), B2Opt chiếm ưu thế và ổn định hơn L-SHADE.

Mục tiêu tối ưu hóa của vấn đề này không tồn tại trong các tập huấn luyện của LGA và LES. Có thể quan sát thấy sự suy giảm hiệu suất mạnh của LGA và LES. Chúng tôi cũng thấy hiện tượng đáng ngạc nhiên rằng Untrained vượt trội hầu hết các baseline, điều này cho thấy B2Opt được khởi tạo ngẫu nhiên cũng sở hữu một số khả năng tạo ra và chọn lựa các giải pháp tiềm năng.

c) Huấn luyện Mạng Nơ-ron: Kết quả chi tiết được thể hiện trong Bảng V. Metric đánh giá là độ chính xác kiểm tra trên tập kiểm tra. Trong khi huấn luyện B2Opt, mục tiêu tối ưu hóa của B2Opt là tối thiểu hóa cross-entropy loss, đây là hàm thay thế cho metric accuracy. Tuy nhiên, trong giai đoạn kiểm tra, mục tiêu tối ưu hóa của B2Opt và các baseline khác là tối đa hóa độ chính xác của tập huấn luyện. Chúng tôi chọn 25%, 50%, 75%, và 100% dữ liệu từ tập huấn luyện để huấn luyện, tương ứng, tạo thành các vấn đề thay thế với các mức độ trung thực khác nhau. B2Opt có 3 OB không chia sẻ trọng số. Chúng tôi thay thế SAC bằng một mô-đun tích chập nhẹ với cấu trúc được thể hiện trong Bảng IV. Việc thay thế này được thực hiện vì chúng tôi mong đợi B2Opt hoạt động ổn định hơn trong quá trình huấn luyện cho nhiệm vụ này. Kích thước quần thể của B2Opt là 36, có nghĩa là số lượng đánh giá của nó là 36 × 4 = 144. Số lượng đánh giá tối đa cho L-SHADE và I-POP-CMA-ES là 3000, gấp 3000/144 ≈ 21 lần so với B2Opt. LGA và LES có số lượng thế hệ tối đa là 100, và chúng được đánh giá 10000/144 ≈ 69 lần nhiều hơn B2Opt. Ngay cả trong trường hợp bất công này, B2Opt đạt được kết quả tốt nhất cho tất cả các mức độ trung thực. Hình 6 thể hiện đường cong hội tụ của B2Opt, LES, LGA, và CMA-ES trên nhiệm vụ này. B2Opt có thể đạt được giải pháp tốt nhất với số lượng đánh giá ít nhất.

C. Phân tích Tham số

Chúng tôi phân tích ảnh hưởng của cấu trúc sâu, tốc độ học, và chia sẻ trọng số giữa các OB đối với B2Opt.

1) Kiến trúc B2Opt: Chúng tôi xem xét hiệu suất của các kiến trúc B2Opt khác nhau. Kết quả thí nghiệm được thể hiện trong Bảng VI. Chúng được sắp xếp từ tốt đến tệ nhất dựa trên hiệu suất của chúng, và kết quả là 30 OB với WS > 5 OB không có WS > 3 OB với WS. Kiến trúc sâu có khả năng biểu diễn tốt hơn và cũng dẫn đến hiệu suất tốt hơn. Tuy nhiên, việc huấn luyện các B2Opt không chia sẻ trọng số với nhiều lớp hơn là thách thức do khó khăn của việc huấn luyện các kiến trúc sâu. Untrained đại diện cho việc các tham số của 5 OB không có WS được khởi tạo ngẫu nhiên. 5 OB không có WS vượt trội Untrained, điều này chứng minh hiệu quả của quy trình huấn luyện được thiết kế. Chúng tôi cũng thấy một hiện tượng thú vị: 5 OB không có WS vượt trội 3 OB với WS trong tất cả các trường hợp. Kiến trúc sâu chưa được huấn luyện của chúng tôi, 30 OB với WS, có thể đạt được kết quả tốt trên các vấn đề cánh tay cơ học phẳng đơn giản, điều này cho thấy B2Opt giữ lại các lợi thế của kiến trúc Transformer và có khả năng tổng quát mạnh. Chúng tôi sử dụng 5 OB không có WS chưa được huấn luyện để kiểm tra vấn đề cánh tay cơ học phẳng phức tạp, hoạt động kém.

Chúng tôi đã quan sát thấy B2Opt có thể đạt được kết quả tốt hơn với kiến trúc sâu hơn. Tuy nhiên, hiện tại chúng tôi khó huấn luyện B2Opt sâu. Hơn nữa, theo như chúng tôi biết, việc sử dụng ES để tối ưu hóa các mô hình sâu đã được nghiên cứu nhiều [26], điều này sẽ là một triển vọng nghiên cứu quan trọng trong tương lai.

2) Tốc độ học: Chúng tôi huấn luyện B2Opt trên tập hàm F1-F3 với các tốc độ học khác nhau và sau đó kiểm tra nó trên tập hàm F4-F9. Kết quả thí nghiệm được thể hiện trong Bảng VII. 5 OB không có WS và 30 OB với WS hoạt động kém khi tốc độ học là 0.1, điều này có thể do tốc độ học quá lớn, ảnh hưởng đến sự hội tụ của B2Opt trong quá trình huấn luyện. Đối với 5 OB không có WS, đặt tốc độ học thành 0.01 đạt được hiệu suất tương đối tốt nhất. Tốc độ học 0.0001 sẽ là lựa chọn tốt cho 30 OB với WS và 3 OB với WS. Tuy nhiên, các thí nghiệm của chúng tôi có độ chi tiết thô. Tốc độ học có tác động đáng kể đến B2Opt. Sau đó việc sử dụng AutoML để tìm kiếm kết hợp siêu tham số tối ưu của mô hình được kỳ vọng sẽ đạt được hiệu suất tốt hơn.

3) Kích thước Dữ liệu Huấn luyện: Chúng tôi cũng khám phá tác động của kích thước tập dữ liệu huấn luyện đến hiệu suất của thuật toán và lấy F4 làm ví dụ. Nó được huấn luyện trên các bias khác nhau của F4 và được kiểm tra trên F4 không có bias. Tập dữ liệu huấn luyện là Ftrain = {F4(x|ωtrain
1,i),···, F4(x|ωtrain
m,i)}. Kết quả thí nghiệm được thể hiện trong Hình 7, cho thấy kích thước của tập dữ liệu huấn luyện tác động đáng kể đến hiệu suất của B2Opt. Khi lượng dữ liệu huấn luyện tăng, hiệu suất của B2Opt tăng.

D. Nghiên cứu Loại bỏ

Phần này xem xét tác động của các phần khác nhau đến B2Opt. Chúng tôi lấy B2Opt với 3 OB và chia sẻ trọng số làm ví dụ, được huấn luyện trên F1-F3 và kiểm tra trên F4-F9. Chúng tôi loại bỏ SAC, FM, RSSM, và RC trong B2Opt, tương ứng, và ký hiệu chúng là Not SAC, Not FM, Not RSSM, và Not RC. Kết quả thí nghiệm được thể hiện trong Bảng VIII. Khi kết quả của chúng được sắp xếp từ tốt đến tệ nhất, thứ hạng là B2Opt > Not FM > Not RC ≈ Not SAC ≈ Not RSSM. Vai trò của FM hơi yếu hơn so với ba mô-đun khác. Nhìn chung, vai trò của các phần SAC, RSSM, và RC có tầm quan trọng bằng nhau. Việc thiếu các thành phần cốt lõi này có thể ảnh hưởng nghiêm trọng đến hiệu suất của B2Opt. Đồng thời, nó cũng thể hiện hiệu quả của bốn mô-đun được đề xuất. Việc loại bỏ bất kỳ mô-đun nào trong lai ghép, đột biến và lựa chọn của EA sẽ làm giảm hiệu suất của EA. Điều này cho thấy B2Opt triển khai một khung EA có thể học không yêu cầu các tham số được thiết kế bởi con người.

E. Phân tích Trực quan

Mô hình được kiểm tra là 5 OB với WS được huấn luyện trên F1-F3 với d = 100. Kích thước quần thể được đặt thành 100.

Phân tích Trực quan của SAC Các chiến lược lai ghép được học bởi năm SAC được thể hiện trong Hình 8. Để trình bày, chúng tôi chọn các cá thể với xếp hạng độ thích nghi thứ 1, 50, và 100. Trục ngang đại diện cho xếp hạng độ thích nghi của các cá thể, và trục dọc đại diện cho sự chú ý (trọng số khi thực hiện lai ghép) trên các cá thể này. OB1 có xu hướng lai ghép với các cá thể xếp hạng thấp hơn, thể hiện sự ưu tiên cho việc khám phá. Từ OB1 đến OB5, bias của SAC dần thay đổi từ khám phá sang khai thác.

Phân tích Trực quan của FM Chúng tôi trực quan hóa FM của B2Opt để khám phá hành vi của nó như Hình 9. Làm tham chiếu, chúng tôi sử dụng đột biến đa thức trong thuật toán di truyền. Cho quần thể đầu vào (input), quần thể đã đột biến (OB1) được thu được thông qua OB1; quần thể mới (mutpolyn) được thu được bằng cách thực hiện đột biến đa thức trên quần thể đầu vào. Chúng tôi trực quan hóa F4-F9 và quan sát các hiện tượng sau:

1) Quần thể được tạo ra bằng cách thực hiện đột biến đa thức được phân bố đều hơn trên cảnh quan. Tuy nhiên, hầu hết các giải pháp được tạo ra bởi FM trong B2Opt đều tập trung trong "các khu vực có tiềm năng lớn hơn", gần với giải pháp tối ưu hơn. Hơn nữa, phân bố quần thể được tạo ra bởi sơ đồ của chúng tôi cũng tính đến sự đa dạng. Khu vực giải pháp không tối ưu cũng toàn diện hơn so với đột biến đa thức, điều này có lợi hơn cho việc nhảy ra khỏi giải pháp cục bộ.

2) Quần thể được tạo ra bằng cách thực hiện đột biến đa thức di chuyển nhẹ so với quần thể ban đầu. Tuy nhiên, FM có thể hướng dẫn quần thể đầu vào thực hiện các động tác lớn hướng tới giải pháp tối ưu, tăng tốc đáng kể sự hội tụ của thuật toán.

Điều này cho thấy B2Opt có thể sử dụng thông tin của hàm mục tiêu để thiết kế chiến lược đột biến một cách tự động, làm cho nó phù hợp hơn với nhiệm vụ tối ưu hóa mục tiêu, phù hợp với động lực của chúng tôi.

VI. KẾT LUẬN

Hiệu suất tốt hơn so với các baseline EA, tối ưu hóa Bayesian và phương pháp dựa trên L2O chứng minh hiệu quả của B2Opt. Hơn nữa, B2Opt có thể thích ứng tốt với BBO chưa thấy. Đồng thời, chúng tôi chứng minh thực nghiệm rằng ba mô-đun được đề xuất có tác dụng tích cực. Tuy nhiên, B2Opt vẫn có chỗ để cải thiện.

1) Trong hàm mất mát, chúng tôi không xem xét hiệu quả sự đa dạng của quần thể, và quần thể có thể được điều chỉnh trong tương lai;
2) Tập huấn luyện ảnh hưởng nghiêm trọng đến hiệu suất của B2Opt. Nếu sự tương tự giữa tập huấn luyện và mục tiêu tối ưu hóa thấp, nó sẽ gây ra hiệu suất của B2Opt suy giảm mạnh. Việc xây dựng tập dữ liệu có liên quan nhất có thể đến mục tiêu là điều cần thiết.

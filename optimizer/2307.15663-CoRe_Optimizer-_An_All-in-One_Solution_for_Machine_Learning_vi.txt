# Trình Tối Ưu CoRe: Giải Pháp Tổng Hợp Cho Học Máy
Marco Eckhoff∗và Markus Reiher†
ETH Zurich, Khoa Hóa Học và Khoa Học Ứng Dụng Sinh Học,
Vladimir-Prelog-Weg 2, 8093 Zurich, Thụy Sĩ.
(Ngày: 17 tháng 1, 2024)
Thuật toán tối ưu hóa và các siêu tham số của nó có thể ảnh hưởng đáng kể đến tốc độ huấn luyện
và độ chính xác của mô hình kết quả trong các ứng dụng học máy. Danh sách mong muốn cho một trình
tối ưu lý tưởng bao gồm hội tụ nhanh và mượt mà đến lỗi thấp, nhu cầu tính toán thấp, và khả năng
áp dụng chung. Trình tối ưu liên tục bền vững (CoRe) mà chúng tôi giới thiệu gần đây đã cho thấy
hiệu suất vượt trội so với các trình tối ưu dựa trên gradient bậc một tiên tiến khác trong việc huấn
luyện các tiềm năng học máy suốt đời. Trong công trình này, chúng tôi cung cấp một so sánh hiệu suất
mở rộng của trình tối ưu CoRe và chín thuật toán tối ưu hóa khác bao gồm trình tối ưu Adam và lan
truyền ngược bền vững (RPROP) cho các nhiệm vụ học máy đa dạng. Chúng tôi phân tích ảnh hưởng
của các siêu tham số khác nhau và cung cấp các giá trị có thể áp dụng chung. Trình tối ưu CoRe đạt
hiệu suất tốt nhất hoặc cạnh tranh trong mọi ứng dụng được nghiên cứu, trong khi chỉ cần thay đổi
một siêu tham số tùy thuộc vào học theo lô nhỏ hoặc học theo lô.

1. GIỚI THIỆU

Học máy (ML) là một phần của lĩnh vực trí tuệ nhân tạo tổng quát.
ML được sử dụng trong nhiều ứng dụng như thị giác máy tính, xử lý
ngôn ngữ tự nhiên, và nhận dạng giọng nói [1, 2]. Nó liên quan đến
các mô hình thống kê mà hiệu suất trên các nhiệm vụ có thể được
cải thiện bằng cách học từ dữ liệu mẫu hoặc kinh nghiệm quá khứ.
Các mô hình ML bao gồm rất nhiều tham số, được gọi là trọng số.
Trong quá trình học, các trọng số này được tối ưu hóa theo một
thước đo hiệu suất. Để đánh giá thước đo này, cần có dữ liệu huấn
luyện hoặc kinh nghiệm.

Trong học có giám sát, mô hình được huấn luyện trên dữ liệu có
nhãn để có được một hàm ánh xạ dữ liệu tới nhãn của nó như trong
các nhiệm vụ phân loại và hồi quy. Ngược lại, trong học không giám
sát, dữ liệu không nhãn được huấn luyện để phân loại. Ngoài ra,
trong học tăng cường, mô hình được huấn luyện thông qua thử và
sai nhằm tối đa hóa phần thưởng. Do đó, các mô hình ML dự đoán
các nhiệm vụ chỉ dựa trên mẫu đã học của dữ liệu và không yêu cầu
hướng dẫn chương trình rõ ràng cho các dự đoán.

Thước đo hiệu suất có thể là một hàm mất mát (còn gọi là hàm
chi phí) cần được tối thiểu hóa [3]. Hàm mất mát này thường là
tổng các đóng góp từ các điểm dữ liệu huấn luyện. Thay vì tính
toán đồng thời cho toàn bộ tập dữ liệu huấn luyện (học xác định
hoặc theo lô), một tập con được chọn (bán) ngẫu nhiên của dữ liệu
huấn luyện thường được sử dụng (học ngẫu nhiên hoặc theo lô nhỏ).
Phương pháp này có thể tăng tốc độ hội tụ đối với tổng thời gian
tính toán vì việc tăng độ chính xác của hàm mất mát là dưới tuyến
tính đối với kích thước lô lớn hơn. Để cập nhật trọng số của mô
hình ML, các sơ đồ tối ưu hóa lặp dựa trên gradient bậc một đang
thống trị lĩnh vực này, vì nhu cầu bộ nhớ và thời gian tính toán
mỗi bước của các trình tối ưu bậc hai thường quá cao. Nói chung,
việc tối ưu hóa nhằm vào cực tiểu địa phương của hàm mất mát
như một hàm của trọng số mô hình vì đủ cho hầu hết các ứng dụng
ML để tìm các giá trị trọng số có mất mát thấp thay vì cực tiểu
toàn cục.

Thuật toán tối ưu hóa có thể quyết định quan trọng tốc độ huấn
luyện và hiệu suất cuối cùng của các mô hình ML [4]. Do đó, việc
phát triển các trình tối ưu tiên tiến là một lĩnh vực nghiên cứu
tích cực có thể ảnh hưởng đáng kể đến độ chính xác của dự đoán
trong tất cả các ứng dụng ML. Hình thức đơn giản nhất của tối
thiểu hóa ngẫu nhiên bậc một cho không gian tham số nhiều chiều
là gradient descent ngẫu nhiên (SGD) [5]. Trong SGD, gradient
âm của hàm mất mát đối với mỗi trọng số được nhân với tỷ lệ học
không đổi và tích được trừ khỏi trọng số tương ứng trong mỗi lần
cập nhật. Gradient của hàm mất mát được điều chỉnh trong gradient
descent ngẫu nhiên với động lượng (Momentum) [6] và gradient
tăng tốc Nesterov (NAG) [7, 8]. Các phương pháp này nhằm cải
thiện hội tụ bằng một động lượng trong các cập nhật trọng số, vì
các gradient dựa trên ước lượng ngẫu nhiên. Theo một cách khác,
gradient thích ứng (AdaGrad) [9], delta thích ứng (AdaDelta) [10],
và lan truyền căn bậc hai trung bình (RMSprop) [11] áp dụng gradient
hàm mất mát thông thường kết hợp với tỷ lệ học thích ứng theo
trọng số. Ước lượng moment thích ứng (Adam) [12], ước lượng
moment thích ứng với chuẩn vô hạn (AdaMax) [12], và trình tối
ưu liên tục bền vững (CoRe) mà chúng tôi phát triển gần đây [13]
kết hợp động lượng với tỷ lệ học được điều chỉnh riêng lẻ. Trong
lan truyền ngược bền vững (RPROP) [14, 15], chỉ dấu của gradient
hàm mất mát được sử dụng với tỷ lệ học được điều chỉnh riêng lẻ.

Ngoài các trình tối ưu này, được áp dụng trong công trình này,
nhiều trình tối ưu khác đã được phát triển cho các ứng dụng ML
trong những năm gần đây. Ví dụ, việc sửa đổi ước lượng moment
thứ nhất của Adam tạo ra ước lượng moment thích ứng tăng tốc
Nesterov (NAdam) [16] và sửa đổi moment thứ hai AMSGrad [17].
Động lượng Nesterov cũng được sử dụng trong động lượng Nesterov
thích ứng (Adan) [18]. Hơn nữa, AdaFactor [19], AdaBound [20],
AdaBelief [21], AdamW [22], PAdam [23], RAdam [24], AdamP [25],
Lamb [26], Gravity [27], và Lion [28] là các ví dụ khác của kho
lớn các trình tối ưu. Chúng thường đại diện cho những cải tiến
từng bước của các thuật toán cha. Chúng tôi lưu ý rằng các trình
tối ưu này có thể được sử dụng trong các ứng dụng ngoài ML.
Hơn nữa, các trình tối ưu bậc hai đã được đề xuất như ước lượng
thích ứng của Hessian (AdaHessian) [29] và tối ưu hóa ngẫu nhiên
cắt bậc hai (Sophia) [30]. Để có được tổng quan về sự khác biệt
hiệu suất giữa các trình tối ưu này, cần có các benchmark mở rộng
[31–33]. Tính trung bình thống kê và lượng hóa không chắc chắn
là không thể thiếu trong các benchmark này để xác thực.

Để giảm gánh nặng cho người thực hành ML trong việc lựa chọn
trình tối ưu, cần có một trình tối ưu hoạt động tốt trên các nhiệm
vụ ML đa dạng. Hơn nữa, cần có một bộ siêu tham số trình tối ưu
có thể áp dụng chung hoạt động ngay lập tức mà không cần điều
chỉnh siêu tham số tốn thời gian. Nhiều nhất, một siêu tham số
trực quan duy nhất có thể cần được điều chỉnh thô, trong khi giá
trị của nó cần dễ ước lượng. Hơn nữa, trình tối ưu lý tưởng có
đặc điểm hội tụ nhanh và mượt mà đến độ chính xác cao với gánh
nặng tính toán thấp.

Trình tối ưu Adam không phải là lựa chọn vượt trội rõ ràng, nhưng
là lựa chọn khả thi cho nhiều nhiệm vụ ML [33]. Do đó, Adam trở
thành trình tối ưu được áp dụng thường xuyên nhất với tỷ lệ học
thích ứng. Vì trình tối ưu CoRe của chúng tôi đã vượt trội Adam
trong nhiệm vụ huấn luyện tiềm năng học máy suốt đời (lMLP) [13],
rõ ràng là phải đánh giá hiệu suất của nó trên các nhiệm vụ ML
đa dạng và so sánh kết quả với các trình tối ưu đã nêu khác nhau.
Một đánh giá hiệu suất rộng như vậy cũng cho phép chúng tôi có
được các siêu tham số có hiệu lực chung cho trình tối ưu CoRe
để có được giải pháp tổng hợp.

Làm benchmark, chúng tôi kiểm tra một tập các nhiệm vụ ML chạy
nhanh được cung cấp trong PyTorch [34]. Tập benchmark bao trùm
phạm vi từ học lô nhỏ đến học lô đầy đủ cũng như học tăng cường.
Hơn nữa, nó bao gồm các nhiệm vụ, mô hình, và tập dữ liệu khác
nhau để cho phép so sánh rộng các trình tối ưu khác nhau. Thứ nhất,
cho các tập dữ liệu chữ số viết tay MNIST [35] và Fashion-MNIST [36],
chúng tôi chạy học lô nhỏ để thực hiện mã hóa tự động biến thiên
(AED và ADF) [37] và phân loại hình ảnh (ICD và ICF). Cái sau
được thực hiện bằng mạng neural tích chập [38] với đơn vị tuyến
tính chỉnh lưu (ReLU) [39], dropout [40], max pooling [41], và
softmax. Thứ hai, cho bài toán cart-pole [42], chúng tôi thực hiện
học tăng cường naive (NR) với mạng neural tuyến tính feed-forward
[43], dropout, ReLU, và softmax và học tăng cường bằng thuật toán
actor-critic (RA) [44]. Thứ ba, cho tập dữ liệu BSD300 [45], chúng
tôi thực hiện siêu phân giải hình ảnh đơn (SR) với hệ số nâng cấp
bốn bằng mạng neural tích chập sub-pixel [46] sử dụng lô nhỏ tương
đối lớn. Thứ tư, chúng tôi chạy học lô của tập dữ liệu Cora [47]
cho phân loại bán giám sát (SS) với mạng tích chập đồ thị [48] và
dropout cũng như của sóng sin cho dự đoán chuỗi thời gian (TS)
với tế bào bộ nhớ ngắn hạn dài (LSTM) [49].

Ngoài ra, chúng tôi đánh giá các trình tối ưu trong việc huấn luyện
tiềm năng học máy [50–55], tức là một nhiệm vụ hồi quy. Một tiềm
năng học máy là biểu diễn của bề mặt năng lượng tiềm năng của
hệ thống hóa học. Nó có thể được sử dụng trong các mô phỏng
nguyên tử để tính toán các tính chất hóa học và phản ứng. Một
phương pháp ví dụ trong số nhiều phương pháp khác là tiềm năng
mạng neural nhiều chiều [56, 57] lấy làm đầu vào các loại nguyên
tố hóa học và tọa độ nguyên tử và trong các trường hợp cần thiết
là điện tích và spin nguyên tử [58–60] để tính toán năng lượng
và lực nguyên tử của các hệ thống từ phân tử hữu cơ qua chất
lỏng đến vật liệu vô cơ bao gồm các hệ thống đa thành phần như
giao diện [13, 61–63].

Trong công trình này, chúng tôi lặp lại việc học tĩnh của một
lMLP dựa trên tập hợp mười tiềm năng mạng neural nhiều chiều,
sử dụng các hàm đối xứng tâm nguyên tử bao trùm nguyên tố như
mô tả [13]. lMLP được huấn luyện trên 8600 hệ thống phản ứng
SN2 với lựa chọn dữ liệu thích ứng suốt đời.

Công trình này được tổ chức như sau: Trong Mục 2, chúng tôi tóm
tắt các thuật toán tối ưu hóa được áp dụng, và trong Mục 3, chúng
tôi tổng hợp các chi tiết tính toán. Trong Mục 4, chúng tôi phân
tích tốc độ huấn luyện kết quả và độ chính xác cuối cùng cho các
ví dụ nhiệm vụ ML PyTorch và lMLPs. Công trình này kết thúc với
kết luận trong Mục 5.

2. PHƯƠNG PHÁP

2.1. Trình Tối Ưu Liên Tục Bền Vững (CoRe)

Trình tối ưu CoRe [13] là một trình tối ưu dựa trên gradient bậc
một cho tối ưu hóa lặp ngẫu nhiên và xác định. Nó điều chỉnh
tỷ lệ học riêng lẻ cho mỗi trọng số wξ tùy thuộc vào tiến trình
tối ưu hóa. Các điều chỉnh tỷ lệ học này được lấy cảm hứng từ
trình tối ưu Adam [12], RPROP [14, 15], và phương pháp trí tuệ
synap [64].

Trung bình động hàm mũ của gradient hàm mất mát và bình phương
của nó,

gτξ = βτ1 · gτ−1ξ + (1−βτ1)∂Lt/∂wt−1ξ,                    (1)

hτξ = β2 · hτ−1ξ + (1−β2)(∂Lt/∂wt−1ξ)2,                   (2)

với tỷ lệ suy giảm βτ1, β2 ∈ [0,1), được sử dụng trong tối thiểu
hóa tương tự như trình tối ưu Adam. Để tối đa hóa, dấu của gradient
hàm mất mát trong Phương trình (1) phải được đảo ngược. Trong
trình tối ưu CoRe, β1 là một hàm của bộ đếm cập nhật trọng số
riêng lẻ τ,

βτ1 = βb1 + (βa1−βb1)/exp[−(τ−1)/βc12],                   (3)

trong đó τ có thể khác với bộ đếm tính toán gradient t nếu một
số bước tối ưu hóa không cập nhật mọi trọng số. Suy giảm ban đầu
βa1 ∈ [0,1) được chuyển đổi bởi một Gaussian với độ rộng βc1 > 0
thành suy giảm cuối cùng βb1 ∈ [0,1). Càng nhỏ βτ1, càng cao
sự phụ thuộc vào gradient hiện tại, trong khi βτ1 lớn hơn dẫn đến
suy giảm chậm hơn của các đóng góp gradient trước đó.

Sự điều chỉnh tỷ lệ học theo trọng số kiểu Adam,

uτξ = gτξ/(1−(βτ1)τ) / [√(hτξ/(1−(β2)τ)) + ε]−1,          (4)

sử dụng tỷ số của các trung bình động gτξ và (hτξ)1/2, được điều
chỉnh đối với thiên lệch khởi tạo của chúng về phía số không
(g0ξ, h0ξ = 0). Để ổn định số, ε ⪆ 0 được thêm vào mẫu số.
Tỷ số này không thay đổi đối với việc thay đổi tỷ lệ gradient và
giới thiệu một hình thức giảm kích thước bước. Do đó, uτξ thay
đổi từ ±1 trong bước tối ưu hóa đầu tiên τ = 1 về phía số không
trong các tối ưu hóa hoạt động tốt.

Hệ số tính dẻo,

Pτξ = {0 cho τ > thist ∧ Sτ−1ξ top-nfrozen,χ trong Sτ−1χ
       1 ngược lại,                                        (5)

nhằm cải thiện cân bằng ổn định-tính dẻo bằng chính quy hóa trong
các cập nhật trọng số. Do đó, các nhóm trọng số χ được chỉ định
— ví dụ, một lớp trong mạng neural — và điểm quan trọng theo
trọng số Sτ−1χ (xem Phương trình (8) bên dưới) được so sánh
trong các nhóm này. Khi τ > thist > 0, Pτξ có thể đóng băng
các trọng số với nfrozen,χ ≥ 0 điểm quan trọng cao nhất trong
nhóm của chúng trong cập nhật τ để giảm thiểu việc quên kiến
thức trước đó.

Sự điều chỉnh tỷ lệ học kiểu RPROP,

sτξ = {min(η+ · sτ−1ξ, smax) cho gτ−1ξ · gτξ · Pτξ > 0
      max(η− · sτ−1ξ, smin) cho gτ−1ξ · gτξ · Pτξ < 0
      sτ−1ξ cho gτ−1ξ · gτξ · Pτξ = 0,                    (6)

chỉ phụ thuộc vào dấu của trung bình động gradient gτξ chứ không
phụ thuộc vào độ lớn của nó dẫn đến tối ưu hóa mạnh mẽ. Sự
đảo dấu từ gτ−1ξ đến gτξ thường báo hiệu một bước nhảy qua
cực tiểu trong cập nhật trước đó. Do đó, kích thước bước sτ−1ξ
được giảm bởi hệ số giảm η− ∈ (0,1] trong trường hợp này, trong
khi nó được phóng to bởi hệ số tăng η+ ≥ 1 cho các dấu không
đổi để tăng tốc hội tụ. Kích thước bước được cập nhật sτξ được
giới hạn bởi kích thước bước tối thiểu và tối đa smin, smax > 0.
Đối với gτ−1ξ · gτξ · Pτξ = 0, việc cập nhật kích thước bước
được bỏ qua. Kích thước bước ban đầu s0ξ = s1ξ là một siêu tham
số của việc tối ưu hóa.

Sự suy giảm trọng số,

wtξ = (1−dχ · |uτξ| · Pτξ · sτξ)wt−1ξ − uτξ · Pτξ · sτξ,    (7)

với siêu tham số dχ ∈ [0,(smax)−1) theo nhóm, nhắm đến việc
giảm rủi ro overfitting bằng cách ngăn chặn việc tăng hoặc giảm
trọng số mạnh. Nó tỷ lệ thuận với tích của dχ và cập nhật trọng
số tuyệt đối |uτξ| · Pτξ · sτξ, tức là càng ổn định giá trị trọng
số thì càng ít bị ảnh hưởng bởi sự suy giảm trọng số. Sau đó,
cập nhật trọng số có dấu uτξ · Pτξ · sτξ được trừ để có được
trọng số được cập nhật wtξ. Do đó, các giá trị trọng số được giới
hạn giữa −(dχ)−1 và (dχ)−1 trong các tối ưu hóa hoạt động tốt,
tức là |uτξ| ≤ ±1.

Giá trị điểm quan trọng,

Sτξ = {Sτ−1ξ + (thist)−1gτξ · uτξ · Pτξ · sτξ cho τ ≤ thist
      [1−(thist)−1]Sτ−1ξ + (thist)−1gτξ · uτξ · Pτξ · sτξ ngược lại, (8)

xếp hạng tầm quan trọng của trọng số bằng cách tính đến các đóng
góp theo trọng số cho việc giảm hàm mất mát được ước lượng trước
đó. Cách tiếp cận này được lấy cảm hứng từ phương pháp trí tuệ
synap. Điểm quan trọng cho phép xác định các trọng số quan trọng
nhất trong các cập nhật trước đó, có thể bị đóng băng bởi các hệ
số tính dẻo (Phương trình (5)) trong các cập nhật sau để cải thiện
cân bằng ổn định-tính dẻo. Tích của trung bình động gradient và
cập nhật trọng số có dấu được sử dụng để ước lượng việc giảm
hàm mất mát. Vì dấu cập nhật trọng số không bị đảo ngược, càng
dương điểm quan trọng, càng lớn việc giảm hàm mất mát. Bắt đầu
với S0ξ = 0, trung bình của gτξ · uτξ · Pτξ · sτξ trên τ ≤ thist
được tính toán. Đối với τ > thist, điểm quan trọng được xác định
như trung bình động hàm mũ với suy giảm 1−(thist)−1.

Chúng tôi lưu ý rằng số lượng siêu tham số tương đối lớn trong
trình tối ưu CoRe, một mặt, là một lợi thế để có được kết quả
tốt ngay cả trong các trường hợp rất khó khăn hoặc cực đoan. Mặt
khác, việc điều chỉnh siêu tham số phức tạp hơn. Tuy nhiên, một
bộ giá trị có thể áp dụng chung, được cung cấp trong công trình
này, có thể khắc phục nhược điểm này.

2.2. SGD

SGD [5] trừ tích của tỷ lệ học không đổi γ và gradient hàm mất
mát khỏi trọng số wt−1ξ trong các cập nhật trọng số,

wtξ = wt−1ξ − γGτξ,                                        (9)

với

Gτξ = ∂Lt/∂wt−1ξ.                                         (10)

2.3. Momentum

Một động lượng bổ sung (Momentum) [6] có thể được giới thiệu
trong SGD bằng cách thay thế Gτξ trong Phương trình (9) bằng

mτξ = μ · mτ−1ξ + Gτξ,                                     (11)

với hệ số động lượng μ và m1ξ = G1ξ [34].

2.4. NAG

NAG [7, 8] là SGD với động lượng Nesterov, tức là, Gτξ trong
Phương trình (9) được thay thế bằng

nτξ = μ · mτξ + Gτξ.                                       (12)

2.5. Adam

Thuật toán của trình tối ưu Adam [12] được cho bởi các Phương
trình (1) (với β1 không đổi), (2), (4), và (9), trong đó Gτξ trong
Phương trình (9) được thay thế bằng uτξ. So với trình tối ưu CoRe,
Adam thiếu sự phụ thuộc τ của tỷ lệ suy giảm β1, các hệ số tính
dẻo Pτξ, sự điều chỉnh tỷ lệ học kiểu RPROP sτξ, và sự suy giảm
trọng số. Cái sau cũng có thể được giới thiệu trong Adam cũng
như trong nhiều trình tối ưu khác bằng cách thêm d · wt−1ξ vào
gradient hàm mất mát như thao tác thứ hai của một lần lặp tối
ưu hóa sau việc có thể đảo dấu cho tối đa hóa. Một thay thế khác
là trừ thay vào đó d · γ · wt−1ξ từ wt−1ξ như trong AdamW [22].

2.6. AdaMax

Sự khác biệt của trình tối ưu AdaMax [12] so với Adam là số hạng
trong dấu ngoặc nhọn trong Phương trình (4) được thay thế bằng
chuẩn vô hạn,

kτξ = max(β2 · kτ−1ξ, |Gτξ|) + ε,                         (13)

với k0ξ = 0.

2.7. RMSprop

Trong RMSprop [11], gradient hàm mất mát được chia cho trung
bình động của độ lớn của nó,

wtξ = wt−1ξ − γGτξ/(√hτξ + ε)−1.                          (14)

Do đó, sự khác biệt với trình tối ưu Adam là gradient hàm mất
mát Gτξ được áp dụng thay vì trung bình động gradient gτξ và
việc điều chỉnh thiên lệch khởi tạo được bỏ qua.

2.8. AdaGrad

Trình tối ưu AdaGrad [9] khác với RMSprop bằng việc thay thế
hτξ trong Phương trình (14) bằng

bτξ = bτ−1ξ + (Gτξ)2,                                     (15)

với b0ξ = 0.

2.9. AdaDelta

Tỷ lệ học thích ứng trong trình tối ưu AdaDelta [10] được thiết
lập bằng

wtξ = wt−1ξ − γGτξ√[(lτ−1ξ + ε)/(hτξ + ε)],             (16)

với

lτξ = β2 · lτ−1ξ + (1−β2)√[(lτ−1ξ + ε)/(hτξ + ε)](Gτξ)2  (17)

và l0ξ = 0. Do đó, so với thuật toán RMSprop, hệ số √(lτ−1ξ + ε)
được áp dụng thêm trong cập nhật trọng số và thứ tự thêm ε vào
hτξ và lấy căn bậc hai được đảo ngược.

2.10. RPROP

RPROP [14, 15] dựa trên Phương trình (6), trong đó Gτ−1ξ · Gτξ
được sử dụng thay vì gτ−1ξ · gτξ · Pτξ. Ngoài ra, một bước
trọng số quay lại được áp dụng bằng cách đặt Gτξ = 0 khi
Gτ−1ξ · Gτξ < 0. Cập nhật trọng số được cho bởi

wtξ = wt−1ξ − sτξ · sgn(Gτξ).                            (18)

3. CHI TIẾT TÍNH TOÁN

Các ví dụ nhiệm vụ ML PyTorch [65] chỉ được sửa đổi để nhúng
chúng vào benchmark mở rộng mà không chạm vào các mô hình
và huấn luyện ML. Ngoại lệ duy nhất là việc loại bỏ bộ lập lịch
tỷ lệ học trong ICD và ICF để đánh giá độc quyền hiệu suất của
trình tối ưu. Các nhiệm vụ được thực hiện ban đầu chỉ trên tập
dữ liệu MNIST (AED và ICD) cũng được thực hiện cho tập dữ liệu
Fashion-MNIST (AEF và ICF). Kích thước lô của các nhiệm vụ ML
AED, AEF, ICD, và ICF là 64 trong tổng số 60000 điểm dữ liệu
huấn luyện để có được các trường hợp thử nghiệm cho học lô nhỏ
(64 là giá trị mặc định trong ví dụ nhiệm vụ ML PyTorch ICD).
Kích thước lô của SR là 10 trong 200 điểm dữ liệu huấn luyện
để có được một ví dụ về kích thước lô là một phần tương đối lớn
của tổng số điểm dữ liệu (~5%). Các tập lệnh được sử dụng với
tất cả chi tiết về các mô hình, huấn luyện, và định nghĩa lỗi có
sẵn trên Zenodo [66] cùng với các kết quả thô đã biên dịch cũng
như các tập lệnh vẽ và phân tích. Hơn nữa, kho lưu trữ này cũng
như kho lưu trữ Zenodo [67] chứa phần mềm trình tối ưu CoRe,
tương thích để sử dụng với PyTorch. Ngoài ra, phần mềm lMLP
[68] đã được mở rộng để tích hợp tất cả các trình tối ưu và cũng
có sẵn trong kho lưu trữ Zenodo [66] cùng với các kết quả lMLP
cũng như chi tiết mô hình và huấn luyện. Cái sau được lấy từ
Tài liệu tham khảo [13]. Huấn luyện lMLP sử dụng lựa chọn dữ
liệu thích ứng suốt đời và tỷ lệ phù hợp trên mỗi epoch là 10%
của tất cả 7740 cấu trúc huấn luyện.

Mỗi nhiệm vụ ML được thực hiện cho mỗi cài đặt trình tối ưu
với 20 bộ số ngẫu nhiên khác nhau. Đối với học tăng cường (NR
và RA), thậm chí 100 bộ số ngẫu nhiên khác nhau được sử dụng
vì các biến động trong các kết quả tương ứng là lớn nhất. Các
bộ này giống nhau cho mỗi trình tối ưu và chúng đảm bảo các
trọng số được khởi tạo khác nhau (và lựa chọn khác nhau của dữ
liệu huấn luyện và kiểm tra). Lỗi tập kiểm tra trung bình Etesti
và độ lệch chuẩn ∆Etesti của nhiệm vụ ML i được tính toán cho
mỗi bộ như một hàm của epoch huấn luyện nepoch để đánh giá
hội tụ. Để xác định độ chính xác cuối cùng, cho lỗi tập kiểm tra
tối thiểu trong mỗi trong 20 lần huấn luyện, trung bình Etest,mini
và độ lệch chuẩn ∆Etest,mini được tính toán, tức là early stopping
được áp dụng. Đối với học tăng cường (NR và RA), số lượng episode
huấn luyện trung bình cho đến khi đạt phần thưởng 475 [69] được
lấy để lượng hóa Etesti. Số lượng episode huấn luyện tối đa là
2500, cũng được sử dụng làm lỗi của các lần huấn luyện không
thành công. Đối với AEF, 7 trong 20 lần huấn luyện Momentum*,
8 trong 20 lần huấn luyện NAG, và 12 trong 20 lần huấn luyện
NAG* thất bại ngay cả với giá trị tỷ lệ học tốt nhất. Các lần
huấn luyện này được phạt với lỗi không đổi là 1000. Đối với
lMLPs, tổng mất mát kiểm tra theo Phương trình (10) trong Tài
liệu tham khảo [13] xác định epoch huấn luyện với lỗi tối thiểu.
Theo cách này, lỗi trung bình bình phương của các năng lượng
được cân với hệ số q² = 10⁻⁰·⁹² trong hàm mất mát, trong khi
lỗi của các thành phần lực nguyên tử không được tỷ lệ. Chúng
tôi đánh giá lỗi trung bình dựa trên lỗi của tất cả 20 lMLPs trong
mỗi trong 20 epoch huấn luyện nơi một lMLP riêng lẻ cho thấy
lỗi tối thiểu, tức là 400 giá trị lỗi được bao gồm. Theo cách này,
lỗi vẫn được tính toán từ các trạng thái huấn luyện tiên tiến,
trong khi nó cũng nhạy cảm với tính mượt mà của các quá trình
huấn luyện vì early stopping khó áp dụng trong thực tế trong học
máy suốt đời.

Để so sánh độ chính xác cuối cùng giữa các trình tối ưu khác
nhau k cho nhiệm vụ ML i, nghịch đảo của lỗi tập kiểm tra tối
thiểu Etest,mini,k tương đối với kết quả của trình tối ưu hoạt
động tốt nhất trong nhiệm vụ ML i được tính toán,

Ai(k) = mink(Etest,mini,k)/Etest,mini,k.                    (19)

Độ không chắc chắn của điểm chính xác được tính toán từ một
lan truyền lỗi dựa trên độ lệch chuẩn lỗi tập kiểm tra ∆Etesti,k,

∆Ai(k) = mink(Etest,mini,k)/[(Etest,mini,k)²]∆Etest,mini,k.  (20)

Để so sánh các trình tối ưu khác nhau k về độ chính xác tổng
thể, trung bình số học A(k) trên tất cả Ntasks điểm chính xác
nhiệm vụ ML Ai(k) được tính toán,

A(k) = (1/Ntasks)∑(i=1 to Ntasks)Ai(k).                    (21)

Độ không chắc chắn của nó được xác định bằng cách lan truyền
lỗi của các biến độc lập Ai(k),

∆A(k) = (1/Ntasks)[∑(i=1 to Ntasks)[∆Ai(k)]²]^(1/2).      (22)

Phiên bản PyTorch 2.0.0 [34] và các cài đặt mặc định của nó
được áp dụng cho các trình tối ưu AdaDelta, AdaGrad, Adam,
AdaMax, Momentum, NAG, RMSprop, RPROP, và SGD (xem Bảng
S1 và S3 trong Thông tin Hỗ trợ cho tất cả giá trị siêu tham
số). Hệ số động lượng trong Momentum và NAG là μ = 0.9. Ngoài
ra, các quét hiệu suất xác định siêu tham số β₁, β₂, μ, η₋,
và η₊ được thực hiện cho các ví dụ nhiệm vụ ML PyTorch để
tìm giá trị tối ưu của chúng cho bộ nhiệm vụ ML này. Nếu các
giá trị mặc định hóa ra là tốt nhất, lựa chọn tốt thứ hai được
áp dụng. Các trình tối ưu sử dụng các siêu tham số được sửa
đổi này (xem Bảng S1 và S3 trong Thông tin Hỗ trợ) được đánh
dấu bằng dấu sao (*). Suy giảm trọng số theo mặc định chỉ được
áp dụng trong trình tối ưu CoRe. Tỷ lệ học s⁰ξ của RPROP,
RPROP*, và trình tối ưu CoRe được đặt thành 10⁻³. Đối với
tỷ lệ học γ của các trình tối ưu khác và kích thước bước tối đa
smax của RPROP, RPROP*, và trình tối ưu CoRe, các giá trị
0.0001, 0.001, 0.01, 0.1, và 1 được thử nghiệm cho mỗi ví dụ
nhiệm vụ ML PyTorch. Giá trị tạo ra ∆Etest,mini thấp nhất được
sử dụng trong đánh giá hiệu suất (xem Bảng S2 trong Thông tin
Hỗ trợ). Đối với huấn luyện lMLP, hai tùy chọn có khả năng
nhất theo kết quả nhiệm vụ ML PyTorch được thử nghiệm (xem
Bảng S4 trong Thông tin Hỗ trợ).

4. KẾT QUẢ VÀ THẢO LUẬN

4.1. Khuyến Nghị Chung cho Các Giá Trị Siêu Tham Số của Trình Tối Ưu CoRe

Một bộ giá trị siêu tham số trình tối ưu CoRe có thể áp dụng chung
đã được có được từ benchmark của chúng tôi trên chín nhiệm vụ ML
bao gồm bảy mô hình khác nhau và sáu tập dữ liệu khác nhau. Các
quá trình huấn luyện bao trùm toàn bộ phạm vi từ học trên lô nhỏ
đến học lô tập dữ liệu đầy đủ. Dựa trên benchmark này, chúng tôi
thường khuyến nghị các giá trị siêu tham số βᵃ₁ = 0.7375, βᵇ₁ = 0.8125,
βᶜ₁ = 250, β₂ = 0.99, ε = 10⁻⁸, η₋ = 0.7375, η₊ = 1.2,
smin = 10⁻⁶, s⁰ξ = 10⁻³, dχ = 0.1, và thist = 250. Số lượng
trọng số bị đóng băng trên mỗi nhóm nfrozen,χ thường có thể được
chỉ định như một tỷ lệ trọng số bị đóng băng trên mỗi nhóm
pfrozen,χ. Các giá trị hoạt động tốt của pfrozen,χ thường trong
khoảng từ 0 (không có cân bằng ổn định-tính dẻo) đến khoảng 10%.
Kích thước bước tối đa smax được khuyến nghị là 10⁻³ cho học
lô nhỏ, 1 cho học lô, và 10⁻² cho các trường hợp trung gian.
smax là siêu tham số chính như tỷ lệ học γ trong nhiều trình tối
ưu khác.

4.2. Đánh Giá Hiệu Suất Trình Tối Ưu cho Các Nhiệm Vụ Học Máy Đa Dạng

Để đánh giá hiệu suất của trình tối ưu CoRe so với chín trình tối
ưu khác với tổng cộng 16 cài đặt siêu tham số khác nhau, điểm
chính xác tương đối cho chín nhiệm vụ ML đã được tính toán cho
các trình tối ưu này (Hình 1 (a) và (b)). Đối với học lô nhỏ
trên kích thước lô nhỏ (~0.1% cho AED, AEF, ICD, và ICF), trình
tối ưu Adam phổ biến và trình tối ưu CoRe của chúng tôi hoạt
động tốt nhất, trong khi đặc biệt RPROP cho độ chính xác kém
vì nó không thể xử lý tốt các biến động gradient ngẫu nhiên. RPROP
được dự định cho học lô điều này trở nên rõ ràng bằng điểm chính
xác cao cho SS và TS. Đối với các nhiệm vụ ML này, RPROP và
trình tối ưu CoRe đạt điểm chính xác cao nhất. Trong trường hợp
trung gian, tức là học lô nhỏ với kích thước lô tương đối lớn
(~5% cho SR và 10% cho huấn luyện lMLP (Hình 4)), cả Adam
và RPROP đều hoạt động tốt với Adam có lợi thế nhỏ hơn RPROP.
Tuy nhiên, trình tối ưu CoRe vượt trội cả hai trong trường hợp này.

Hơn nữa, tốc độ học và độ tin cậy của trình tối ưu CoRe trong
học tăng cường (NR và RA) cũng tốt hơn so với các trình tối ưu
khác (Hình 1 (a) và (b)). RPROP không thể học nhiệm vụ trong
số lượng episode tối đa cho NR trong bất kỳ lần huấn luyện nào.
Tốc độ hội tụ của trình tối ưu CoRe của các lỗi tập kiểm tra
trung bình cho các nhiệm vụ ML khác tương tự như Adam cho học
lô nhỏ và tương tự như RPROP cho học lô (xem Hình S1 đến S7
và S9 trong Thông tin Hỗ trợ).

Tổng cộng, trình tối ưu CoRe đạt điểm chính xác cuối cùng cao
nhất trong sáu nhiệm vụ và huấn luyện lMLP, Adam* trong hai
nhiệm vụ, và RPROP* trong một nhiệm vụ (Hình 1 (a) và (b)).
Tuy nhiên, trong sáu trường hợp mà trình tối ưu CoRe hoạt động
tốt nhất, trình tối ưu tốt thứ hai luôn trong khoảng không chắc
chắn của điểm chính xác của trình tối ưu CoRe. Tuy nhiên, không
có trình tối ưu đơn lẻ nào luôn trong khoảng không chắc chắn.
Ví dụ, Adam, RMSprop, RMSprop*, và SGD nằm trong khoảng
không chắc chắn cho nhiệm vụ ML ICF, chỉ AdaMax* cho SR,
và AdaMax*, RPROP, và RPROP* cho TS, trong khi trình tối ưu
CoRe luôn trong khoảng không chắc chắn của trình tối ưu tốt
nhất cho ba nhiệm vụ ML khác. Do đó, ngay cả khi không có sự
thống trị rõ ràng cho các nhiệm vụ ML riêng lẻ, trình tối ưu
CoRe nằm trong số các trình tối ưu tốt nhất trong tất cả các
nhiệm vụ ML này dẫn đến, trung bình, hiệu suất tốt nhất và
khả năng áp dụng rộng nhất. Do đó, trình tối ưu CoRe cân bằng
tốt và đạt điểm chính xác tổng thể cao nhất (Hình 2). Điểm chính
xác tổng thể của Adam là cao thứ hai, trong khi những điểm của
AdaMax* và Adam* gần bằng với của Adam. Khoảng không chắc
chắn của điểm chính xác tổng thể của trình tối ưu CoRe trùng
một phần với của trình tối ưu Adam. Chúng tôi lưu ý rằng khoảng
không chắc chắn của kết quả trình tối ưu Adam cũng lớn nhất
trong tất cả các kết quả.

Nói chung, đối với bộ nhiệm vụ ML được chọn, các trình tối ưu
kết hợp động lượng và tỷ lệ học được điều chỉnh riêng lẻ (CoRe,
Adam, và AdaMax) hoạt động tốt hơn những trình chỉ áp dụng tỷ
lệ học được điều chỉnh riêng lẻ (RMSprop, AdaGrad, và AdaDelta)
(Hình 2). Tuy nhiên, sự khác biệt giữa trình tối ưu CoRe, Adam,
và AdaMax lớn hơn sự khác biệt giữa RMSprop và AdaMax. Độ
chính xác cuối cùng có được bởi SGD thuần túy kém hơn đáng kể
so với các trình tối ưu đã nêu. Tuy nhiên, đối với chín nhiệm vụ
ML này, nó vẫn hơi tốt hơn các trình tối ưu chỉ sử dụng động
lượng (Momentum và NAG). Độ chính xác tổng thể của RPROP nằm
giữa những trình áp dụng tỷ lệ học được điều chỉnh riêng lẻ
và SGD cho các nhiệm vụ ML này. Tuy nhiên, thứ tự này, tất nhiên,
phụ thuộc vào tỷ lệ các nhiệm vụ ML học lô nhỏ và học lô.

Hiệu suất mô hình đơn tốt nhất có được bởi trình tối ưu CoRe
được cung cấp trong Bảng S5 và Hình S10 (a) và (b) và S11 trong
Thông tin Hỗ trợ. Đối với SS, chúng tôi có thể so sánh độ chính
xác cuối cùng trực tiếp với công trình gốc với 81.5% phân loại
tập kiểm tra đúng [48]. Do huấn luyện bởi trình tối ưu CoRe,
mạng tích chập đồ thị tốt nhất cho SS đạt độ chính xác phân loại
tập kiểm tra 84.2%.

4.3. Sự Phụ Thuộc Hiệu Suất vào Các Giá Trị Siêu Tham Số

Các siêu tham số của trình tối ưu CoRe được điều chỉnh trên bộ
nhiệm vụ ML này, trong khi các khuyến nghị siêu tham số chung
của PyTorch cho các trình tối ưu khác không dựa trên bộ benchmark
này. Để cung cấp so sánh công bằng, chúng tôi cũng áp dụng các
giá trị siêu tham số cho các trình tối ưu khác đã được điều chỉnh
trên bộ nhiệm vụ ML này. Các siêu tham số đã điều chỉnh của
AdaDelta*, AdaMax*, Momentum*, và RPROP* tạo ra sự cải thiện
của điểm chính xác tổng thể của chúng (Hình 2). Tuy nhiên, lợi
ích không đủ để đạt đến điểm chính xác tổng thể trong lớp trình
tối ưu tốt hơn tiếp theo được mô tả trong phần cuối. Do đó, việc
lựa chọn thuật toán tối ưu hóa được xác nhận là quan trọng cho
độ chính xác cuối cùng của mô hình ML. Điểm chính xác tổng thể
cao nhất của Adam, NAG, và RMSprop được có được với các giá
trị siêu tham số được khuyến nghị chung của chúng. Lựa chọn tốt
thứ hai của các siêu tham số tạo ra điểm chính xác tổng thể rất
tương tự.

Một khác biệt khác giữa trình tối ưu CoRe và các trình tối ưu
khác là việc áp dụng suy giảm trọng số. Tuy nhiên, Hình S13 và
S14 trong Thông tin Hỗ trợ cho thấy rằng thuật toán suy giảm
trọng số tiêu chuẩn của Adam được sử dụng với bốn giá trị siêu
tham số khác nhau nói chung giảm điểm chính xác cho Adam. Chỉ
thuật toán suy giảm trọng số của AdamW có thể dẫn đến sự tăng
nhỏ của điểm chính xác tổng thể. Tuy nhiên, lợi ích chỉ là một
phần của sự khác biệt điểm chính xác tổng thể giữa trình tối ưu
CoRe và trình tối ưu Adam. Suy giảm trọng số của trình tối ưu
CoRe chỉ ảnh hưởng nhỏ đến độ chính xác cuối cùng trung bình
(Hình S13 và S14 trong Thông tin Hỗ trợ).

Trong phân tích hiệu suất nhiệm vụ ML riêng lẻ, chúng tôi lưu
ý rằng RPROP và trình tối ưu CoRe cho thấy hội tụ chậm trong
các epoch đầu của huấn luyện SS (xem Hình S6 trong Thông tin
Hỗ trợ). Lý do là cần có những thay đổi trọng số lớn trong tối
ưu hóa và kích thước bước ban đầu s⁰ξ chỉ được đặt thành 0.001.
Các giá trị cao hơn của s⁰ξ dẫn đến hội tụ nhanh hơn đến độ
chính xác cuối cùng tương tự, với s⁰ξ = 0.1 tạo ra hội tụ
nhanh hơn nhiều so với có được với Adam (xem Hình S7 trong Thông
tin Hỗ trợ). Tuy nhiên, nhiệm vụ ML này là một ví dụ cực đoan
với ít cập nhật trọng số để điều chỉnh sτξ trong học lô và nhu
cầu thay đổi trọng số lớn. Tuy nhiên, vì độ chính xác cuối cùng
giống nhau và trong hầu hết các ứng dụng sτξ được điều chỉnh
nhanh trong một phần tương đối nhỏ của các cập nhật trọng số,
việc khởi tạo s⁰ξ nói chung không quan trọng.

Một trường hợp cực đoan khác có thể được có được cho các giá
trị kích thước bước tối đa smax cao trong trình tối ưu CoRe. Trong
khi smax = 1 tạo ra độ chính xác cuối cùng cao trong huấn luyện
TS khi early stopping được áp dụng, việc huấn luyện có thể trở
nên không ổn định khi tiếp tục (xem Hình S8 trong Thông tin
Hỗ trợ). Tuy nhiên, giảm smax xuống 0.1 đã giải quyết vấn đề
này (xem Hình S9 trong Thông tin Hỗ trợ).

4.4. Hiệu Suất Trình Tối Ưu trong Huấn Luyện Các Tiềm Năng Học Máy Suốt Đời

Trong việc huấn luyện lMLPs, các phần tương đối lớn của dữ liệu
huấn luyện (~10%) được sử dụng trong tính toán gradient hàm
mất mát. Phù hợp với kết quả của các ví dụ nhiệm vụ ML PyTorch,
loại huấn luyện này phù hợp nhất với trình tối ưu CoRe theo sau
là Adam*, Adam, AdaMax*, và RPROP* (Hình 3 (a) và (b) và 4).
Hơn nữa, xu hướng chung được xác nhận rằng các trình tối ưu thích
ứng và dựa trên động lượng hoạt động tốt nhất, trong khi các trình
tối ưu chỉ thích ứng vẫn cho kết quả tốt hơn các trình tối ưu
chỉ dựa trên động lượng. Trái ngược với các ví dụ nhiệm vụ ML
PyTorch, nơi cân bằng ổn định-tính dẻo của trình tối ưu CoRe
với pfrozen khoảng 0.025 chỉ có thể cải thiện nhỏ điểm chính xác
cho AED, AEF, và SR và làm xấu đi độ chính xác cuối cùng cho
ICD và ICF (xem Hình S12 trong Thông tin Hỗ trợ), việc huấn
luyện lMLP hưởng lợi lớn từ cân bằng ổn định-tính dẻo với
pfrozen = 0.1. Chúng tôi lưu ý rằng việc điều chỉnh pfrozen,
ngoài kích thước bước tối đa, mở rộng khả năng tối ưu hóa siêu
tham số cho CoRepfrozen=0.1 so với CoRe và tất cả các trình tối
ưu khác, đối với chúng chỉ kích thước bước tối đa/tỷ lệ học
được điều chỉnh trong khi tất cả các siêu tham số khác được lấy
từ kết quả ví dụ nhiệm vụ ML PyTorch. Mức độ tự do cao hơn
này cũng có thể đóng góp vào hiệu suất tối ưu hóa. Tuy nhiên,
sự cải thiện hiệu suất đáng kể không được có được cho bất kỳ
việc điều chỉnh siêu tham số nào khác ngoại trừ việc điều chỉnh
η−.

Hơn nữa, cân bằng ổn định-tính dẻo làm mượt hội tụ huấn luyện
như được thể hiện trong căn bậc hai lỗi trung bình bình phương
tập kiểm tra (RMSEs) của năng lượng và các thành phần lực nguyên
tử như một hàm của các epoch huấn luyện (Hình 5 (a) và (b)).
Trình tối ưu CoRe cho hội tụ mượt hơn Adam, điều này có lợi,
ví dụ, trong học máy suốt đời nơi lMLP cần sẵn sàng cho ứng
dụng trong mỗi giai đoạn huấn luyện. Điểm chính xác trong Hình
3 (a) và (b) và 4 tính đến tính mượt hội tụ (xem Mục 3) trái
ngược với điểm chính xác trong Hình S15 và S16 trong Thông tin
Hỗ trợ chỉ dựa trên các kết quả early stopping lMLP riêng lẻ.
Cái sau có lợi cho kết quả Adam nhưng trình tối ưu CoRe với
cân bằng ổn định-tính dẻo vẫn vượt trội Adam. Tốc độ hội tụ
cũng cao hơn cho trình tối ưu CoRe so với Adam. Quan sát này
phù hợp với hội tụ của nhiệm vụ ML SR (xem Hình S5 trong Thông
tin Hỗ trợ) cũng đại diện cho trường hợp huấn luyện giữa học
lô nhỏ và học lô. Để chứng minh lợi ích của việc học ổn định
hơn trong huấn luyện lMLP, chúng tôi bổ sung giảm giá trị η−
làm mượt và cải thiện quá trình huấn luyện tương tự. Cả pfrozen
lớn và η− nhỏ đều dẫn đến sự tương tác tốt hơn với lựa chọn
dữ liệu thích ứng suốt đời. Tuy nhiên, sự tương tác này chỉ là
một yếu tố nhỏ của sự cải thiện điểm chính xác lớn vì sự cải
thiện tương tự trong huấn luyện với lựa chọn dữ liệu ngẫu nhiên
(xem Hình S17 trong Thông tin Hỗ trợ). Lựa chọn dữ liệu thích
ứng suốt đời tăng độ chính xác cuối cùng nói chung. Kết luận,
hội tụ rất mượt được mong muốn trong huấn luyện lMLP làm cho
giá trị η− nhỏ hơn có lợi. Tuy nhiên, độ chính xác cuối cùng
và tốc độ hội tụ và tính mượt đã cao hơn so với các trình tối
ưu tiên tiến khác khi các giá trị siêu tham số được khuyến nghị
chung với cân bằng ổn định-tính dẻo được kích hoạt bởi pfrozen
được áp dụng.

So với công trình trước đây của chúng tôi, nơi 10 lMLPs tốt nhất
trong 20 lMLPs cho RMSE(Etest) và RMSE(Ftestα,n) là (4.5±0.6)
meV atom⁻¹ và (116±4) meV Å⁻¹ sau 2000 epoch huấn luyện với
trình tối ưu CoRe, các siêu tham số được khuyến nghị chung của
công trình này kết hợp với pfrozen = 0.1 (CoRepfrozen=0.1) cải
thiện độ chính xác thành (4.1±0.7) meV atom⁻¹ và (90±5) meV
Å⁻¹. Với giá trị η− được điều chỉnh cho việc huấn luyện mượt
hơn nữa (CoRepfrozen=0.025η−=0.55), các giá trị RMSE tập kiểm tra
tương ứng giảm xuống chỉ (3.4±0.4) meV atom⁻¹ và (92±4) meV
Å⁻¹.

Cuối cùng, so sánh thời gian tính toán cho việc huấn luyện với
Adam và trình tối ưu CoRe cho thấy rằng không chỉ độ chính xác
cuối cùng mà còn tỷ lệ chính xác-chi phí của trình tối ưu CoRe
tốt hơn so với Adam. Để so sánh nhiều lần huấn luyện với phần
mềm lMLP, tỷ lệ thời gian phù hợp mô hình trong toàn bộ quá
trình huấn luyện (bao gồm khởi tạo, tính toán mô tả, phù hợp
mô hình (khoảng 87%), dự đoán cuối cùng, và hoàn thiện) được
tính toán để giảm ảnh hưởng của các máy tính khác nhau và tải
tính toán. Tốc độ kết quả giống nhau trong khoảng không chắc
chắn cho Adam và trình tối ưu CoRe. Các thao tác bổ sung trong
thuật toán trình tối ưu CoRe chỉ gây ra sự tăng nhỏ chi phí
tính toán không đáng kể so với chi phí để đánh giá gradient hàm
mất mát. Đối với ví dụ lMLP được trình bày, một bước trình tối
ưu yêu cầu ít hơn 0.2% thời gian cần thiết cho một tính toán
gradient hàm mất mát. Vì trình tối ưu CoRe chỉ yêu cầu gradient
hàm mất mát làm đầu vào như Adam và các trình tối ưu khác,
thời gian tính toán trên mỗi epoch huấn luyện tương tự cho tất
cả các trình tối ưu.

5. KẾT LUẬN

Trình tối ưu CoRe kết hợp sự điều chỉnh tỷ lệ học theo trọng
số kiểu Adam và kiểu RPROP. Hơn nữa, trong trình tối ưu CoRe,
tỷ lệ suy giảm phụ thuộc bước được sử dụng trong tính toán trung
bình động gradient kiểu Adam, là cơ sở cho các cập nhật kích
thước bước kiểu RPROP. Suy giảm trọng số của nó phụ thuộc vào
cập nhật trọng số tuyệt đối và một cân bằng ổn định-tính dẻo
tùy chọn dựa trên điểm quan trọng trọng số có thể được áp dụng.
Theo cách này, trình tối ưu CoRe kết hợp hiệu suất cao của trình
tối ưu Adam trong học lô nhỏ và của RPROP trong học lô tập dữ
liệu đầy đủ, trong khi nó vượt trội cả hai trong các trường hợp
trung gian. Với khuyến nghị siêu tham số chung có được trong công
trình này dựa trên các nhiệm vụ ML đa dạng, trình tối ưu CoRe
là một giải pháp tổng hợp cân bằng tốt với khả năng áp dụng
rộng và tốc độ hội tụ cao và độ chính xác cuối cùng ngang bằng
và vượt trội các trình tối ưu dựa trên gradient bậc một tiên
tiến.

Đánh giá hiệu suất đã xác nhận thêm một lợi thế chung cho các
trình tối ưu kết hợp động lượng và tỷ lệ học được điều chỉnh
riêng lẻ về tốc độ hội tụ và độ chính xác cuối cùng so với các
trình tối ưu chỉ thích ứng hoặc dựa trên động lượng hoặc không
có cả hai. Hơn nữa, các phương pháp thích ứng và/hoặc dựa trên
động lượng chỉ cần thời gian tính toán nhiều hơn nhỏ so với SGD
đơn giản điều này không đáng kể so với thời gian cần thiết cho
tính toán gradient hàm mất mát.

Ngoài khuyến nghị siêu tham số CoRe chung, chỉ kích thước bước
tối đa smax cần được đặt tùy thuộc vào các biến động trong tính
toán gradient có thể được ước lượng dễ dàng dựa trên việc áp
dụng học lô nhỏ (~0.001) hoặc học lô (~1) hoặc các trường hợp
trung gian (~0.01). Ngoài ra, cân bằng ổn định-tính dẻo có thể
được kích hoạt bởi siêu tham số pfrozen. Nó có thể đạt được hội
tụ huấn luyện mượt hơn đến độ chính xác cuối cùng cao hơn nữa
tạo ra sự cải thiện lớn trong ví dụ huấn luyện lMLP. Chúng tôi
lưu ý rằng việc điều chỉnh tinh siêu tham số cho các nhiệm vụ
ML riêng lẻ có thể, tất nhiên, cải thiện hiệu suất đến một mức
độ nào đó cho tất cả các trình tối ưu nhưng có nhược điểm là
rất tốn thời gian.

# 2304.11787.pdf
# Converted from PDF to TXT
# Source path: /home/admin88/arxiv-downloader/optimizer/2304.11787.pdf
# File size: 32219589 bytes

===============================================
PDF FILE CONTENT
===============================================


--- PAGE 1 ---
JOURNAL OF L ATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021 1
B2Opt: Learning to Optimize Black-box
Optimization with Little Budget
Xiaobin Li, Member, IEEE , Kai Wu, Member, IEEE , and Xiaoyu Zhang, Handing Wang, Member, IEEE , Jing
Liu, Senior Member, IEEE
Abstract —The core challenge of high-dimensional and ex-
pensive black-box optimization (BBO) is how to obtain better
performance faster with little function evaluation cost. The
essence of the problem is how to design an efficient optimization
strategy tailored to the target task. This paper designs a powerful
optimization framework to automatically learn the optimization
strategies from the target or cheap surrogate task without human
intervention. However, current methods are weak for this due to
poor representation of optimization strategy. To achieve this, 1)
drawing on the mechanism of genetic algorithm, we propose
a deep neural network framework called B2Opt, which has
a stronger representation of optimization strategies based on
survival of the fittest; 2) B2Opt can utilize the cheap surrogate
functions of the target task to guide the design of the efficient
optimization strategies. Compared to the state-of-the-art BBO
baselines, B2Opt can achieve multiple orders of magnitude
performance improvement with less function evaluation cost. We
validate our proposal on high-dimensional synthetic functions
and two real-world applications. We also find that deep B2Opt
performs better than shallow ones.
Index Terms —Learning to Optimize, Black-box Optimization,
Transformer, Learned Optimizer, Genetic Algorithm.
I. I NTRODUCTION
MANY tasks, such as neural architecture search [1] and
hyperparameter optimization [2], [3], can be abstracted
as black-box optimization (BBO) [4], which means that al-
though we can evaluate f(x)for any x∈X, we have no
access to any other information about f, such as the Hessian
and gradients. Moreover, it is expensive to evaluate f(x)in
most cases. Various hand-designed algorithms, such as genetic
algorithms (GAs) [5]–[7], Bayesian optimization [8]–[12], and
evolution strategy (ES) [13]–[16], have been designed to solve
BBO. Their purpose is to design optimization strategies that
allow them to continuously sample better solutions.
Recently, the learning to optimize (L2O) framework [17],
[18] gives a new insight into optimization. They leverage
the recurrent neural network (RNN), long short-term memory
This work was supported in part by the National Natural Science Foundation
of China under Grant 62206205, in part by the Fundamental Research
Funds for the Central Universities under Grant XJS211905, in part by
the Guangdong High-level Innovation Research Institution Project under
Grant 2021B0909050008, and in part by the Guangzhou Key Research and
Development Program under Grant 202206030003. ( Corresponding author:
Jing Liu. )
Xiaobin Li, Kai Wu, and handing Wang are with School of Artificial Intel-
ligence, Xidian University, Xi’an 710071, China (e-mail: kwu@xidian.edu.cn;
22171214784@stu.xidian.edu.cn; hdwang@xidian.edu.cn).
Xiaoyu Zhang is with School of Cyber Engineering, Xidian University,
Xi’an 710071, China (e-mail: xiaoyuzhang@xidian.edu.cn).
Jing Liu is with Guangzhou Institute of Technology, Xidian University,
Guangzhou 510555, China (e-mail: neouma@mail.xidian.edu.cn).architecture (LSTM) [19]–[23], multilayer perceptron (MLP)
[24], or Transformer [25] as the optimizer to develop opti-
mization methods, aiming at reducing the laborious iterations
of hand engineering [21], [26]–[28]. The core of L2O is
constructing a solid mapping from the initial solutions to the
optimal solution. Moreover, several efforts [20], [29], [30]
have coped with the black-box problems, their effectiveness
may be hindered by the limited representation capabilities of
optimization strategy and a large number of evaluations on
expensive black-box functions. As such, they often deal with
low-dimensional problems.
The optimization strategy in GA consists of a sequential
arrangement of crossover, mutation, and selection operators
to handle black-box optimization. But their fixed parameters
cause inefficient sampling strategies. In this paper, we obtain
a strong optimization strategy representation by coming to
parameterize these modules, termed as B2Opt.
We design three modules to realize the mapping from
the random solution to the optimal solution. To generate
potential individuals to approach the optimal solution, we first
develop a self-attention (SA)-based crossover module (SAC) to
create potential individuals to approach the optimal solution.
Then the output of this module is input into the proposed
feed-forward network (FFN)-based mutation module (FM) to
escape the optimal local solution. Moreover, the residual and
selection module (RSSM) is designed to survive the fittest
individuals. RSSM is a pairwise comparison between the
output of SAC, FM, and the input population regarding their
fitness. We develop a B2Opt Block (OB) consisting of SAC,
FM, and RSSM. Finally, we simulate the iteration rule of GAs
by stacking OBs to represent strong optimization strategies.
In order to adapt the optimization strategy represented
by B2Opt to the target task, we update the parameters of
B2Opt based on the information of target task. Moreover, to
reduce the number of evaluations to an expensive black-box
function, we establish a cheap surrogate function set to train
B2Opt. We construct a set of cheap differentiable functions
with similar properties to the targeted BBO problems. This
training set contains the pair of the initial population and the
designed surrogate function. Thus, we can use gradient-based
methods, such as stochastic gradient descent and Adam [31],
to train B2Opt. In this way, we don’t need to query expensive
functions during training.
We test B2Opt on six standard functions with high di-
mension, the neural network training problem, and the planar
mechanic arm problem [32]. The experimental results demon-
strate the top rank of B2Opt and the strong representationarXiv:2304.11787v2  [cs.LG]  25 Jul 2023

--- PAGE 2 ---
JOURNAL OF L ATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021 2
compared with five state-of-the-art (SOTA) EA baselines, two
SOTA Bayesian baselines, and three SOTA L2O methods. The
highlights of this paper are shown as follows:
•Compared with the state-of-the-art BBO methods, B2Opt
achieves multiple orders of magnitude performance im-
provement with fewer function evaluations even if the
training dataset is a low-fidelity set of the target black-
box function.
•We design the B2Opt framework to realize the automated
GA, which can better represent optimization strategies. It
is easier to map random solutions to optimal solutions
with fewer evaluation times during optimization.
•We design a new training strategy to reduce the evaluation
cost of expensive objective functions during training.
It uses cheap surrogate functions for expensive target
tasks instead of directly evaluating the target black-box
function.
The rest of this paper is organized as follows. Section
II summarizes the related work about learnable optimization
strategy. Section III formalizes the studied problem and in-
troduces the background of GAs and Transformer. Section IV
presents the content of B2Opt. Section V conducts extensive
experiments to evaluate the effectiveness of B2Opt. Finally,
Section VI concludes the whole paper.
II. R ELATED WORK
We mainly focus on a learnable optimization strategy for
BBO, which is divided into two parts.
A. Meta-Learn Whole BBO Algorithm
Our proposal belongs to this type. Chen et al. [20] first
explored meta-learning entire algorithms for low-dimensional
BBO. Then, TV et al. [33] proposed RNN-Opt, which learned
recurrent neural network (RNN)-based optimizers for opti-
mizing real parameter single-objective continuous functions
under limited budget constraints. Moreover, they train RNN-
Opt with knowledge of task optima. Swarm-inspired meta-
optimizer [29] learns in the algorithmic space of both point-
based and population-based optimization algorithms. Gomes
et al. [34] employed meta-learning to infer population-based
black-box optimizers that can automatically adapt to specific
classes of tasks. These methods parametrize the optimization
algorithm by an RNN processing the raw solution vectors and
their associated fitness.
B. Meta-Learn Part BBO Algorithm
This type only learns some parameters of the algorithm, not
the overall algorithm. Shala et al. [35] meta-learned a policy
that configured the mutation step-size parameters of CMA-ES
[14]. LES [30] designed a self-attention-based search strategy
to discover effective update rules for evolution strategies
via meta-learning. Subsequent work LGA [36] employed the
above framework to discover the update rules of Gaussian
genetic algorithms via Open-ES [16].
The limitations of these methods are shown as follows: 1) to
train the meta-optimizer, a large number of expensive black-
box functions need to be requested, which is very unrealistic;2) the established loss function for training the meta-optimizer
is challenging to optimize, resulting in a poor representation of
the optimization strategy. Thus, we propose B2Opt overcome
the above limitations.
III. P RELIMINARIES
A. Genetic Algorithms
The crossover, mutation, and selection operators form the
basic framework of GAs. GA starts with a randomly generated
initial population. Then, genetic operations such as crossover
and mutation will be carried out. After the fitness evaluation
of all individuals in the population, a selection operation is
performed to identify fitter individuals to undergo reproduction
to generate offspring. Such an evolutionary process will be
repeated until specific predefined stopping criteria are satisfied.
a) Crossover: The crossover operator generates a new
individual ˆXiby Eq. (1), and cris the probability of the
crossover operator.
ˆXc
i,k=Xj,krand(0,1)< cr
Xi,k otherwise(1)
where k∈[1,···, d]. This operator is commonly conducted
onnindividuals. After an expression expansion, we re-
formulate Eq. (1) asPn
i=1XiWc
i[37]. Wc
iis the diagonal
matrix. If Wc
iis full of zeros, the ith individual has no
contribution.
b) Mutation: The mutation operator brings random
changes into the population. Specifically, an individual Xiin
the population goes through the mutation operator to form the
new individual ˆXi, formulated as follows:
ˆXm
i,k=rand(lk, uk)rand(0,1)< mr
ˆXc
i,k otherwise(2)
where mris the probability of mutation operator and k∈
[1,···, d]. Similarly, Equation (2) can be re-formulated as
XiWm
i, where Wm
iis the diagonal matrix.
c) Selection: We introduce the binary tournament mating
selection operator in Eq. (3). The selection operator survives
individuals of higher quality for the next generation until the
number of individuals is chosen.
pi=1f(Xi)< f(Xk)
0f(Xi)> f(Xk),(Xi, Xk)∈X, (3)
where pireflects the probability that Xiis selected for the
next generation, and (Xi, Xk)in Eq. 3 are randomly selected
from the population X∪ˆXm.
B. Transformer
We mainly introduce the core part of Vision Transformer
[38], such as the multi-head self-attention layer (MSA), feed-
forward network (FFN), layer normalization (LN), and residual
connection (RC).

--- PAGE 3 ---
JOURNAL OF L ATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021 3
Population
Sorting FMFitness 
Matrix
Ordered Population X0SACOB i
RSSM
NxXc
Xm
Input 
Population 
Output
Population 
1−iX
iX
Fig. 1. Overall architecture of B2Opt and OB. Nx stands for B2Opt is composed of Nx stacked OBs. These OBs can be set to share weights with each
other or not share weights with each other.
1) MSA: MSA fuses several SA operations to handle
the queries ( Q), keys ( K), and values ( V) that jointly at-
tend to information from different representation subspaces.
MSA is formulated as follows: MultiHead (Q, K, V ) =
Concat (H1, H2,···Hh)WO. where Concat means concate-
nation operation. The head feature Hican be formulated as:
Hi=SA(QWQ
i, KWK
i, V WV
i)
=Softmax
QWQ
i(KWK
i)T/sqrt (dk)
V WV
i=AV WV
i
where WQ
i∈Rdm×dq,WK
i∈Rdm×dk, and WV
i∈Rdm×dv
are parameter matrices for queries, keys, and values, respec-
tively; WO∈Rhdv×dmmaps each head feature Hito the
output. Moreover, dmis the input dimension, while dq,dk,
anddvare hidden dimensions of the corresponding projection
subspace; his the head number. A∈Rl×lis the attention
matrix of hth head, lis the sequence length.
2) FFN: FFN employs two cascaded linear transformations
with a ReLU activation to handle X, which is shown as:
FFN (X) = max(0, XW 1+b1)W2+b2, where W1and
W2are weights of two linear layers, and b1andb2are
corresponding biases.
3) LN: LN is applied before each layer of MSA
and FFN, and the output of LN is calculated by X+
[MSA|FFN ](LN(X)).
IV. B2O PT
A. Problem Definition
A black-box optimization problem can be transformed as
a minimization problem, as shown in Eq. (4), and constraints
may exist for corresponding solutions:
min
xf(x), s.t. x i∈[li, ui] (4)
where x= (x1, x2,···, xd)represents the solution of op-
timization problem f, the lower and upper bounds l=
(l1, l2,···, ld)andu= (u1, u2,···, ud), and dis the dimen-
sion of x. Suppose nindividuals of one population be X1=
(X1,1, X1,2,···, X1,d),···, Xn= (Xn,1, Xn,2,···, Xn,d),
then B2Opt are required to find the population near the optimal
solution. Note that we only have a very small number of
function evaluations to achieve.B. Self-Attention Crossover Module
Inspired by the crossover operator in GAs, we propose an
SA-based module to generate potential solutions by maximiz-
ing information interaction among individuals in a population.
Suppose a population Xis arranged in a non-descending order
of fitness, and F∈Rn×1be the fitness matrix of X. Then,
this module can be represented as follows:
Xc=SAC (X, F) (5)
where Xcis the output population of the SAC module.
Since the object processed by B2Opt is the population
with several individuals, and the order of individuals does
not affect the population distribution, SA does not require
position coding. Standard SA projects the input sequence X
into a d-dimensional space via the queries ( Q), keys ( K),
and values ( V). These three mappings enable the SA module
to better capture the characteristics of the problems encoun-
tered during training. In other words, these three mappings
strengthen the ability of SA to focus on specific issues but do
not necessarily make SA have good transferability between
different problems. Therefore, we consider removing these
three mappings for enhanced transferability and Xc=AX.
A∈Rn×nis a self-attention matrix that can be learned
to maximize inter-individual information interaction based
on individual ranking information. Since Auses individual
ranking information instead of fitness value information, A
is invariant to the problems, which is beneficial to improve
the generalization performance of the model. This is why the
population needs to be sorted in non-descending order.
However, designing the SAC module based solely on pop-
ulation ranking information is a coarse-grained approach.
Because this way only considers the location information
of individuals in the population but does not consider the
fitness relationship between individuals. Therefore, we further
introduce fitness information to assist in designing the SAC
module:
AF=SA(F) =Softmax 
FWQ(FWK)T/sqrt (dk)
(6)
Thus, Xc=AX+AFX. To better balance the roles of A
andAF, we introduce two learnable weights Wc
1∈Rn×1and

--- PAGE 4 ---
JOURNAL OF L ATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021 4
Wc
2∈Rn×1. Therefore, the final SAC module is shown as
follows:
Xc=tile(Wc
1)⊙(AX) +tile(Wc
2)⊙(AFX) (7)
where ⊙represents Hadamard product and the tile copy
function extends the vector to a matrix.
C. FFN-based Mutation Module
In Transformer, each patch embedding carries on directional
feature transformation through the FFN module. We take
one linear layer as an example: X=XWF, where WF
is the weight of the linear layer, and it is applied to each
embedding separately and identically. The similar formula
format of mutation operator and FFN inspires us to design
a learnable mutation module FM based on FFN with ReLU
activation function:
Xm=FM(Xc) = (ReLU (XcWF
1+b1))WF
2+b2(8)
where Xmis the population after the mutation of Xc.WF
2
andWF
1represent the weight of the second layer of FFN
and the weight of the first layer of FFN, respectively. b2
andb1represent the bias of the second layer and the first
layer of FFN, respectively. FM is designed to escape the local
optimum.
D. Selection Module
The residual connection in the transformer can be analo-
gized to the selection operation in GA [37]. The RSSM
generates the offspring population according to the following
equation:
ˆX=RSSM (X, Xc, Xm)
=Sort(SM(X, tile (Ws
1)⊙X
+tile(Ws
2)⊙Xc+tile(Ws
3)⊙Xm))(9)
where ˆXis the fittest population for the next generation; the
learnable weights Ws
1∈Rn×1,Ws
2∈Rn×1, and Ws
3∈Rn×1
are the weights for X,Xc, and Xm, respectively. Sort(X)
represents that Xis sorted in non-descending order of fitness.
We use quicksort to sort the population based on function
fitness. These three learnable weight matrices realize the
weighted summation of residual connections, thereby simu-
lating a learnable selection strategy. Meanwhile, introducing
residual structure enhances the model’s representation ability,
enabling B2Opt to form a deep architecture.
SM updates individuals based on a pairwise comparison
between the offspring and input population regarding their
fitness. Suppose that XandX′are the input populations of
SM. We compare the quality of individuals from XandX′
pairwise based on fitness. A binary mask matrix indicating
the selected individual can be obtained based on the indi-
cator function lx>0(x), where lx>0(x) = 1 ifx > 0and
lx>0(x) = 0 ifx < 0. SM forms a new population ˆXby
employing Eq. (10).
ˆX=tile(lx>0(MF′−MF))⊙X
+tile(1−lx>0(MF′−MF))⊙X′ (10)
where the tilecopy function extends the indication vector to
a matrix, MF(MF′)denotes the fitness matrix of X(X′).E. Structure of B2Opt
B2Opt comprises basic tB2Opt blocks (OBs), and param-
eters can be shared among these tOBs or not. The overall
architecture of B2Opt and OB is shown in Figure 1. Each
OB consists of SAC, FM, and RSSM in sequential order.
X0∈Rn×drepresents the initial population input into B2Opt,
which must be sorted in non-descending fitness order. In Eq.
11,Xi−1is fed into OBtto get Xi, where i∈[1, t]. B2Opt
realizes the mapping from the random initial population to the
target population by stacking tOBs.
Xi=OB(Xi−1);Xc=SAC (Xi−1, F); (11)
Xm=FM(Xc);Xi=RSSM (Xi−1, Xc, Xm)
F . Training of B2Opt
1) Goal: We introduce the parameters θof B2Opt,
which need to be optimized. Here, we set θ=
{Wc
1, Wc
2, A, WF
1, WF
2, b1, b2, Ws
1, Ws
2, Ws
3}.
2) Training Dataset: Before introducing the details of the
training dataset, fidelity [39] is defined as follows: Suppose
the differentiable surrogate functions f1, f2,···, fmare the
continuous exact approximations of the black-box function
f. We call these approximations fidelity, which satisfies the
following conditions: 1) f1,···, fi,···, fmapproximate f.
||f−fi||∞≤ζm, where the fidelity bound ζ1> ζ2>···ζm.
2) Estimating approximation fiis cheaper than estimating f.
Suppose the query cost at fidelity is λi, and λ1< λ 2<···λm.
Training data is a crucial factor beyond the objective func-
tions. This paper establishes the training set by constructing
a set of differentiable functions related to the optimization
objective. This training dataset only contains (X0, fi(x|ω)),
the initial population and objective function, respectively. The
variance of ωcauses the shift in landscapes. The training
dataset is designed as follows:
1) Randomly initialize the input population X0;
2) Randomly produce a shifted objective function fi(x|ω)
by adjusting the parameter ω;
3) Evaluate X0byfi(x|ω);
4) Repeat Steps 1)-3) to generate the corresponding dataset.
We show the designed training and testing datasets as
follows:
Ftrain={f1(x|ωtrain
1,i),···, fm(x|ωtrain
m,i)} (12)
where ωtrain
m,i represents the ith different values of ωin the
mth function fm.
3) Loss Function: B2Opt attempts to search for individuals
with high quality based on the available information. The
loss function tells how to obtain the parameters of B2Opt
to generate individuals closer to the optimal solution by
maximizing the difference between the initial population and
the output population of B2Opt. The following loss function
li(X0, f(x|ω), θ)is employed,
li=1
|X0|P
x∈X0fi(x|ω)−1
|Eθ(X0)|P
x∈Eθ(X0)fi(x|ω)
1
|X0|P
x∈X0fi(x|ω)(13)

--- PAGE 5 ---
JOURNAL OF L ATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021 5
where θdenotes parameters of B2Opt ( E). Equation (13)
calculates the average fitness difference between the input and
output, further normalized within [0,1]. To encourage B2Opt
to explore the fitness landscape, for example, the constructed
Bayesian posterior distribution over the global optimum [40]
can be added to Eq. (13). We have three ways to train B2Opt:
1) When we can construct a differentiable proxy function of
the objective function, we use the gradient information
of Eq. (13) to train B2Opt.
2) When it is difficult to construct differentiable surrogate
functions of the objective function, we can use REIN-
FORCE [41] to estimate these derivatives.
3) We can use ES [26] to train B2Opt. Here, we focus
on introducing the training of B2Opt through the first
method.
4) Training B2Opt: We then train B2Opt under a super-
vised mode. Since the gradient is unnecessary during the test
process, B2Opt can solve BBO problems. To prepare B2Opt
to learn a balanced performance upon different optimization
problems, we design a loss function formulated as follows:
arg min
θlΩ=−1
KX
X0∈Ωli(X0, fi(x|ωtrain
i), θ) (14)
We employ Adam [31] method with a minibatch Ωto train
B2Opt upon training dataset.
5) Detailed Training Process: The goal of the training
algorithm is to search for parameters θ∗of the B2Opt. Before
training starts, B2Opt is randomly initialized to get initial
parameters θ. Then the algorithm will perform the following
three steps in a loop until the training termination condition
is satisfied:
1)Step 1 , randomly initialize a minibatch Ωcomprised of
Kpopulations X0;
2)Step 2 , for each fi∈Ftrain, given training data
(X0, fi), update θby minimizing the lΩ;
3)Step 3 , given X0, update θby minimizing −1/mP
ilΩ,
where mis the number of functions in Ftrain. After
completing the training process, the algorithm will out-
putθ∗.
V. E XPERIMENTS
A. Experimental Setup
1) Datasets:
a) Synthetic Functions: This paper first employs nine
commonly used functions to show the effectiveness of the
proposed B2Opt. The characteristics of these nine functions
are shown in Table I. Here, B2Opt is trained on Ftrain
generated based on F1-F3, and the target functions are F4-
F9. B2Opt is trained on the set of tasks with low fidelity for
the target function. We test the generalization performance
of B2Opt through this case. Moreover, B2Opt is trained on
target functions with different function biases. We then test it
on target function with biases unseen in the training stage; we
refer it to B2Opt-V2.
d
r
1L
2L
3L
4L
1
2
3
4Fig. 2. Planar Mechanical Arm.
b) Planner Mechanic Arm: We further evaluate the per-
formance of the proposed scheme on the planner mechanic arm
problem [42]–[45], a robotic control problem that has been
widely used to evaluate the performance of BBO algorithms.
It is shown in Fig. 2. The optimization goal of this problem
is to search for a set of lengths L= (L1, L2,···, Ln)and
a set of angles α= (α1, α2,···, αn)so that the distance
f(L, α, p )from the top of the mechanic arm to the target
position pis the smallest, where nrepresents the number
of segments of the mechanic arm, and Li∈(li, ui)and
αi∈(−Π,Π)represent the length and angle of the ith
mechanic arm, respectively. rrepresents the distance from
the target point to the origin of the mechanic arm. Typically,
f=q
(Pn
i=1cos(αi)Li−px)2+ (Pn
i=1sin(αi)Li−py)2,
where pxandpyrepresent the x-coordinate and y-coordinate
of the target point, respectively.
Here, n= 100 ,li= 0 andui= 10 . We design two groups
of experiments:
1) Simple Case . We fixed the length of each mechanic arm as
li= 10 and only searched for the optimal α.
2) Complex Case . We need to search for Landαsimulta-
neously. We randomly selected 600 target points within the
range of r≤1000 to form a set S, where rrepresents the
distance from the target point to the origin of the mechanic
arm, as shown in Fig. 2. During the training process of B2Opt,
a sample point set sis re-extracted from Sfor training every
Ttraining cycle. In the testing process, we extracted 128
target points ( Stest) in the range of r≤100,r≤300, and
r≤1000 , respectively, for testing. The purpose of testing
in three different regions is to explore the generalization
performance of B2Opt further. We evaluate the generalization
ability of the algorithm byPStest
sf(L, α, s )
/|Stest|.
c) Neural Network Training: We further analyze the
performance of B2Opt in the field of neuroevolution. We
evaluate the performance of training a convolutional neural
network [46] using B2Opt on the MNIST classification task.
The structure of this network model is shown in Table II.
This task involves a large number of parameters. B2Opt and
baselines are tasked with solving the parameters of this neural
network to maximize test accuracy. The network does not use
any bias, and the total number of parameters is 567. If the SGD
algorithm directly optimizes the neural network, the network

--- PAGE 6 ---
JOURNAL OF L ATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021 6
TABLE I
TRAINING AND TESTING FUNCTIONS . F1-F3 ARE TRAINING FUNCTIONS AND F4-F9 ARE TESTING FUNCTIONS . HERE,d={10,100}.zi=xi−bi.
ID Functions Range
F1P
i|wisin(xi−bi)| x∈[−10,10], b∈[−10,10]
F2P
i|xi−bi| x∈[−10,10], b∈[−10,10]
F3P
i|(xi−bi) + (xi+1−bi+1)|+P
i|xi−bi| x∈[−10,10], b∈[−10,10]
F4(Sphere)P
iz2
ix∈[−100,100], b∈[−50,50]
F5 {|zi|,1≤i≤D} x∈[−100,100], b∈[−50,50]
F6(Rosenbrock)D−1P
i=1(100( z2
i−zi+1)2+ (zi−1)2) x∈[−100,100], b∈[−50,50]
F7(Rastrigin)DP
i=1(z2
i−10 cos(2 πzi) + 10) x∈[−5,5], b∈[−2.5,2.5]
F8(Griewank)DP
i=1z2
i
4000−QD
i=1cos(zi√
i) + 1 x∈[−600,600], b∈[−300,300]
F9(Ackley) −20 exp( −0.2q
1
DPD
i=1z2
i)−exp(1
DPD
i=1cos(2 πzi)) + 20 + exp(1) x∈[−32,32], b∈[−16,16]
TABLE II
THE SMALL -SCALE CLASSIFICATION NEURAL NETWORK FOR MNIST.
Layer ID Layer Type Padding Stride Kernel Size
1 depth-wise convolution % 1 1 ×5×5
2 point-wise convolution % 1 3 ×1×1×1
3 ReLu % % %
4 max pooling % 2 2 ×2
5 depth-wise convolution % 1 3 ×5×5
6 point-wise convolution % 1 16 ×3×1×1
7 ReLu % % %
8 max pooling % 2 2 ×2
9 depth-wise convolution % 1 16 ×4×4
10 point-wise convolution % 1 10 ×16×1×1
11 softmax % % %
can achieve about 90 %test accuracy, which proves that the
network architecture is effective. We use 1000 samples from
the MINST dataset to form the training set and another 1000
samples as the test set.
2) Baselines: B2Opt is compared with the state-of-the-art
BBO methods, including non-L2O and L2O-based.
EA baselines . DE(DE/rand/1/bin) [47], ES(( µ,λ)-ES),
IPOP-CMA-ES [48], L-SHADE [49], and CMA-ES [50],
where DE [47] and ES are implemented based on Geatpy [51],
CMA-ES and IPOP-CMA-ES are implemented by cmaes1,
and L-SHADE is implemented by pyade2. The reasons for
choosing these EA baselines are the following:
•DE(DE/rand/1/bin): A classic numerical optimization al-
gorithm.
•ES((µ,λ)-ES): A classic variant of the evolution strategy.
•CMA-ES: CMA-ES is often considered the state-of-the-
art method for continuous domain optimization under
challenging settings (e.g., ill-conditioned, non-convex,
non-continuous, multimodal).
•IPOP-CMA-ES: The state-of-the-art variant of CMA-ES.
1https: //github.com/CyberAgentAILab
2https://github.com/xKuZz/pyade•L-SHADE: The state-of-the-art variant of DE.
Bayesian optimization . Dragonfly [52] and SAASBO [53]
are employed as a reference. Here are the reasons for choosing
these two algorithms:
•Dragonfly: A representative algorithm for Bayesian opti-
mization.
•SAASBO: A state-of-the-art large-scale Bayesian opti-
mization algorithm.
L2O-based methods . We chose three state-of-the-art L2O-
based methods for comparison with B2Opt.
•L2O-swarm [29]: A representative L2O method for BBO.
•LES [30]: A recently proposed learnable ES. It uses a
data-driven approach to discover new ES with strong
generalization performance and search efficiency.
•LGA [36]: A recently proposed learnable GA that dis-
covers new GA in a data-driven manner. The learned al-
gorithm can be applied to unseen optimization problems,
search dimensions, and evaluation budgets.
B2Opt . We design three B2Opt models, including 3 OBs
with WS ,5 OBs without WS , and 30 OBs with WS .3 OBs with
WSrepresents that B2Opt has 3 OB modules, and these OBs
share the weights of each other. Each OB consists of 1 SAC, 1
FM, and 1 RSSM. In general, B2Opt represents 30 OBs with
WS.
3) Parameters: Next, we show the parameter settings of
these methods:
B2Opt . In30 OBs with WS , these 30 OBs share parameters.
5 OBs without WS has 5 OBs, and no parameters are shared
among them. During the training process, B2Opt is trained for
1000 epochs. The initial learning rate ( lr) was set to 0.01 and
lr=lr×0.9every 100 cycles. The 2-norm of the gradient is
clipped so that it is not larger than 10. The bias of the function
is regenerated each epoch, and a new batch of random initial
populations is generated.
Baselines . For all cases, we choose the optimal hyper-
parameters. For ES and DE, the population size is set to
100, λ= 0.5,cr= 0.5,F= 0.5, and the rest of the
parameters are the default ones set by geatpy. For CMA-
ES, the rest of the parameters take the default values of the

--- PAGE 7 ---
JOURNAL OF L ATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021 7
F4
F5
F6
F7F8F9
Dimension=10
F4
F5
F6
F7F8F9
Dimension=100
B2Opt
B2Opt-V2
CMA-ES
I-POP-CMA-ES
L-SHADE
LES
LGA
Dragonfly
SAASBO
L2O-swarm
ES
DE
Fig. 3. The compared results of all methods on six functions. The structure of B2Opt is 30 OBs with WS . The left schematic diagram and the right schematic
diagram are the test results when the dimensions are 10 and 100, respectively. In order to present the experimental results more intuitively, we mark the
experimental results as a, and the figure shows exp(−a)normalized by z-score. Larger values represent better performance.
package camaes. The population size of L-SHADE is 100,
and the rest of the parameters adopt the default parameters of
the package pyade. The initial population size of IPOP-CMA-
ES is 30, and the population growth factor is 2. L-SHADE
and IPOP-CMA-ES are known for their fast convergence. For
all EA baselines, the maximum number of evaluations is set
to 3100, which is consistent with the number of evaluations
of B2Opt (30 OBs with WS). We set the maximum number
of generations of Dragonfly and SAASBO to 100. Because
the runtime overhead of these two Bayesian optimization
algorithms is very expensive, it takes several days to complete
100 generations when d= 100 . Even at d= 10 , it takes
many hours to complete 100 evaluations. But B2Opt can finish
running in 1 second, so the expensive actual running time
overhead of SAASBO and Dragonfly is unacceptable. The
population size of LGA and LES is 100, and the maximum
number of function evaluations is 3100. We use the optimal
trained model parameters officially provided by their project
website3. The FTrainandFtestis the same as that of B2Opt.
In the test phase, L2O-Swarm was run to convergence.
To ensure validity, all experimental results were averaged
to the optimal values of the five groups of experiments, each
of which performed 64 runs. All experiments were performed
on a Ubuntu 20.04 PC with Intel(R) Core I7 (TM) I3-8100
CPU at 3.60GHz and NVIDIA GeForce GTX 1060.
B. Results
a) Synthetic Functions: Here, the structure of B2Opt
is30 OBs with WS . The results on synthetic functions are
provided in Fig. 3. We also plot the convergence curves of
all methods on F4-F9 with d={10,100}, as shown in
3https://github.com/RobertTLange/evosaxFigs. 4 and 5. B2Opt converges quickly and can obtain better
solutions with little budget. The fewer function evaluations,
the greater the advantage of B2Opt. When d= 10 , B2Opt
achieved better performance than all SOTA methods except for
L-SHADE in all cases. B2Opt loses five cases to L-SHADE
and outperforms L-SHADE in one case (F7). L-SHADE is
the optimal DE variant, which is heavily engineered, and
intricately hand-designed by researchers combining a wealth
of expert knowledge. It has been iteratively updated many
times over the years. L-SHADE can obtain high-performance
initialized populations on F4-F9, far better than B2Opt’s.
However, the convergence speed of B2Opt is much faster than
that of L-SHADE, and B2Opt is highly competitive, especially
with a minimal number of function evaluations. However,
when d= 100 , B2Opt outperforms all SOTA methods in
F4-F9. When the problem dimension is 10, the problem is
relatively simple, and when the problem dimension is 100,
the problem becomes very complicated. B2Opt achieves the
best performance on all tested functions in complex cases. L-
SHADE has strong advantages over simple problems. Note
that the hyperparameters of L-SHADE are optimally tuned to
the performance of the target task. However, B2Opt is only
trained on the low-fidelity surrogate functions F1-F3 of the
target task.
LES and LGA are the latest learnable evolutionary algo-
rithms with powerful performance. They are trained on a large
number of BBOB functions, many of which are the same or
similar to the test functions shown in Table I. For example, the
LES and LGA training datasets include F4, F5, F6, and F8. As
shown in Figs. 4 and 5, the initial population have achieved
good performance. B2Opt only performs simple training on
F1, F2, and F3 in Table I, and F4-F9 is unseen for B2Opt
in the training stage. However, B2Opt outperforms LES and

--- PAGE 8 ---
JOURNAL OF L ATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021 8
0 500 1000 1500 2000 2500 3000
Evaluation Number0200040006000800010000120001400016000F4 Value200 250 300 350 400050100150200CMAES
DE
ES
IPOP-CMAES
LES
LGA
LSHADE
B2Opt
(a) F4
0 500 1000 1500 2000 2500 3000
Evaluation Number01020304050607080F5 ValueCMAES
DE
ES
IPOP-CMAES
LES
LGA
LSHADE
B2Opt (b) F5
0 500 1000 1500 2000 2500 3000
Evaluation Number01234F6 Value1e9
800 900 1000 1100 12001.0
0.5
0.00.51.01e8CMAES
DE
ES
IPOP-CMAES
LES
LGA
LSHADE
B2Opt (c) F6
0 500 1000 1500 2000 2500 3000
Evaluation Number0255075100125150175F7 ValueCMAES
DE
ES
IPOP-CMAES
LES
LGA
LSHADE
B2Opt
(d) F7
0 500 1000 1500 2000 2500 3000
Evaluation Number020406080100120140F8 Value2700 2800 2900 3000 31001
01CMAES
DE
ES
IPOP-CMAES
LES
LGA
LSHADE
B2Opt (e) F8
0 500 1000 1500 2000 2500 3000
Evaluation Number0.02.55.07.510.012.515.017.520.0F9 ValueCMAES
DE
ES
IPOP-CMAES
LES
LGA
LSHADE
B2Opt (f) F9
Fig. 4. The convergence curves of B2Opt and other baselines. It shows the convergence curve of these algorithms on functions in Table I when d= 10 .
LGA in all tested functions.
B2Opt-V2 outperforms B2Opt overall. However, B2Opt-
V2 performs worse than B2Opt on F8. B2Opt-V2 is trained
on a high-fidelity surrogate function of the target task. We
found that F8 has a "Rotated" feature and a wide range of
zivalues, which cause B2Opt-V2 to be overfitted. B2Opt-V2
outperforms B2Opt after we increase the training sample size.
These cases also show the excellent generalization ability
of B2Opt on more tasks unseen during the training stage. The
transferability of B2Opt is proportional to the fitness landscape
similarity between the training set and the problem. Although
new problem attributes are unavailable in the training set,
B2Opt can perform better. However, this conclusion only holds
when the similarity between the problem and training dataset
is high. Now we further analyze the detailed reasons for the
excellent effect of B2Opt.
We train B2Opt based on F1-F3 and make it successfully
optimize F4-F9, and we also analyze the reason for this case.
From the expression of the functions , F1-F3 are low-
fidelity surrogate functions of the target functions F4-F9.
F1-F3 contain the information of objective functions (F4-
F9). For example, F7 can be decomposed intoPD
i=1z2
i−PD
i=110 cos(2 πzi)+PD
i=110. F2 is the low-fidelity surrogate
function ofPD
i=1z2
i. F1 is the low-fidelity surrogate function
ofPD
i=110 cos(2 πzi). For other functions in F4-F9, we can
find similar surrogate functions from F1-F3. B2Opt can use
this information to maximize the matching degree between
the learned optimization strategy and the objective function.However, F6 is less similar to F1-F3 than F4, F5, and F7-
F9. Herefore, although the performance of B2Opt on F6 is
better than that of the comparison algorithm, it still needs
improvement.
From the perspective of landscape features , F1-F3 in-
clude the following features: unimodal, multimodal, separable,
and non-separable. The landscape features included in F4-F9
are as follows:
•F4: Unimodal, Separable
•F5: Unimodal, Separable
•F6: Multimodal, Non-separable, Having a very narrow
valley from local optimum to global optimum, Ill-
conditioned
•F7: Multimodal, Separable, Asymmetrical, Local op-
tima’s number is huge
•F8: Multi-modal, Non-separable, Rotated
•F9: Multi-modal, Non-separable, Asymmetrical
The landscape features of F4 and F5 can be found in F1-
F3. F6-F9 all have new features. The interference strength of
different characteristics to landscape is arranged as follows:
Having a very narrow valley from local optimum to
global optimum >Asymmetrical, Local optima’s number
is huge >Asymmetrical >Rotated . Therefore, B2Opt has the
best generalization performance on F4, F5, F8, the second-
best generalization performance on F7 and F9, and the worst
on F6.
b) Planner Mechanic Arm: The detailed experimental
results are in Tables III. Note that the parentheses in the table

--- PAGE 9 ---
JOURNAL OF L ATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021 9
0 500 1000 1500 2000 2500 3000
Evaluation Number050000100000150000200000250000300000350000400000F4 Value400 500 600 700 8000200400600800 CMAES
DE
ES
IPOP-CMAES
LES
LGA
LSHADE
B2Opt
(a) F4
0 500 1000 1500 2000 2500 3000
Evaluation Number020406080100120F5 Value
800 10000.02.55.0CMAES
DE
ES
IPOP-CMAES
LES
LGA
LSHADE
B2Opt (b) F5
0 500 1000 1500 2000 2500 3000
Evaluation Number0.00.51.01.52.02.53.03.5F6 Value1e11
2700 2800 2900 3000 31001.0
0.5
0.00.51.01e6CMAES
DE
ES
IPOP-CMAES
LES
LGA
LSHADE
B2Opt (c) F6
0 500 1000 1500 2000 2500 3000
Evaluation Number025050075010001250150017502000F7 Value
CMAES
DE
ES
IPOP-CMAES
LES
LGA
LSHADE
B2Opt
(d) F7
0 500 1000 1500 2000 2500 3000
Evaluation Number0500100015002000250030003500F8 Value2000 2100 2200 2300 24000.00.51.0CMAES
DE
ES
IPOP-CMAES
LES
LGA
LSHADE
B2Opt (e) F8
0 500 1000 1500 2000 2500 3000
Evaluation Number05101520F9 ValueCMAES
DE
ES
IPOP-CMAES
LES
LGA
LSHADE
B2Opt (f) F9
Fig. 5. The convergence curves of B2Opt and other baselines. It shows the convergence curve of these algorithms on functions in Table I when d= 100 .
TABLE III
THE RESULTS OF ALL BASELINES ON THE PLANAR MECHANICAL ARM . THE STRUCTURE OF B2O PT IS 30 OBs with WS . SIMPLE CASE (SC): SEARCHING
FOR DIFFERENT ANGLES WITH FIXED LENGTHS . COMPLEX CASE (CC): SEARCHING FOR DIFFERENT ANGLES AND LENGTHS .W/T/L REPRESENTS
WIN/TIE/LOSS TO B2O PT.
r DE ES CMA-ES L2O-Swarm L-SHADE I-POP-CMA-ES LGA LES B2Opt Untrained
SC100 1.60(0.08) 10.7(0.40) 1.25(0.05) 40.4(3.89) 0.66(0.03) 1.17(0.02) 540(1.97) 546(8.22) 0.38(0.01) 0.8(0.05)
300 2.65(0.08) 35(2.41) 1.84(0.07) 69.5(3.77) 0.54(0.02) 1.21(0.06) 562(2.1) 572(4.92) 0.52(0.02) 4.26(0.33)
1000 155(1.45) 153(2.19) 154(2.31) 176(7.20) 0.4(0.03) 36.8(1.00) 716(1.74) 719(4.03) 16.9(0.30) 126(0.85)
CC100 1.17(0.03) 9.22(0.52) 0.78(0.02) 31.9(1.78) 0.25(0.02) 0.72(0.02) 108(1.34) 223(6.51) 0.17(0.01) 0.94(0.04)
300 13.6(0.53) 38.3(0.60) 4.77(0.37) 89.1(1.96) 54.5(5.23) 0.92(0.02) 161(2.67) 259(4.29) 0.22(0.01) 18.6(0.39)
1000 278(1.96) 235(1.41) 239(0.83) 262(2.99) 218(0.89) 167(1.15) 421(0.93) 493(1.15) 14.7(0.70) 214(0.93)
w/t/l 0/0/6 0/0/6 0/0/6 0/0/6 1/0/5 0/0/6 0/0/6 0/0/6 - 0/0/6
TABLE IV
THE DESIGNED CONVOLUTION MODULE TO REPLACE SAC. ONE
REPRESENTS ONE REFLECTION PADDING .
Layer ID layer type padding stride kernel size
1 depth-wise convolution one 1 567 ×3×3
2 ReLu % % %
3 depth-wise convolution one 1 567 ×3×3
4 ReLu % % %
5 depth-wise convolution one 1 567 ×3×3
6 ReLu % % %
7 depth-wise convolution one 1 567 ×3×3
show the standard deviation if not otherwise specified. Thestructure of B2Opt is 30 OBs with WS .Untrained represents
the untrained B2Opt. We randomly selected 600 target points
within the range of r≤1000 to form a set S, where r
represents the distance from the target point to the origin of
the mechanic arm, as shown in Fig. 2. During the training
process of B2Opt, a sample point set sis re-extracted from S
for training every Ttraining cycle. In the testing process, we
extracted 128 target points ( Stest) in the range of r≤100,
r≤300, and r≤1000 , respectively, for testing. The
purpose of testing in three different regions is to explore the
generalization performance of B2Opt further. B2Opt wins all
SOTA methods and achieves the best results in comparison
with other algorithms. B2Opt loses once to L-SHADE in
SC with r= 1000 . However, in the other 5 cases, B2Opt
outperforms L-SHADE. In particular, on the complex problem
(CC), B2Opt is more dominant and stable than L-SHADE.

--- PAGE 10 ---
JOURNAL OF L ATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021 10
TABLE V
THE CLASSIFICATION ACCURACY OF ALL METHODS ON THE MNIST DATASET . DATASIZE REPRESENTS THE PROPORTION OF DATA SETS INVOLVED IN
TRAINING .
Datasize B2Opt ES DE CMA-ES I-POP-CMA-ES L-SHADE LGA LES
0.25 0.69(0.01) 0.21(0.02) 0.21(0.01) 0.57(0.04) 0.33(0.02) 0.31(0.03) 0.53(0.02) 0.14(0.02)
0.5 0.80(0.01) 0.21(0.01) 0.24(0.01) 0.61(0.03) 0.37(0.04) 0.29(0.01) 0.51(0.01) 0.25(0.03)
0.75 0.85(0.00) 0.21(0.01) 0.22(0.02) 0.61(0.03) 0.45(0.02) 0.30(0.07) 0.52(0.05) 0.23(0.07)
1 0.86(0.00) 0.25(0.02) 0.23(0.02) 0.67(0.01) 0.42(0.02) 0.30(0.01) 0.54(0.04) 0.28(0.01)
The optimization objective of this problem does not exist
in the training sets of LGA and LES. A sharp performance
degradation of LGA and LES can be observed. We also find
the surprising phenomenon that Untrained outperforms most
of the baselines, which suggests that the randomly initialized
B2Opt also possesses some ability to produce and select
potential solutions.
c) Neural Network Training: The detailed results are
shown in Table V. The evaluation metric is test accuracy on
the test set. While training B2Opt, the optimization objective
of B2Opt is to minimize the cross-entropy loss, which is a
surrogate function for metric accuracy. However, in the testing
stage, the optimization goal of B2Opt and other baselines is
to maximize the accuracy of the training set. We select 25%,
50%, 75%, and 100% data from the training set for training,
respectively, constituting surrogate problems with different
fidelity levels. B2Opt has 3 OBs that do not share weights. We
replaced SAC with a lightweight convolution module with the
structure shown in Table IV. This substitution is made because
we expect B2Opt to perform more stably during training for
this task. The population size of B2Opt is 36, meaning its
number of evaluations is 36×4 = 144 . The maximum number
of evaluations for L-SHADE and I-POP-CMA-ES is 3000,
which is 3000/144≈21times that of B2Opt. LGA and LES
have a maximum number of generations of 100, and they are
evaluated 10000 /144≈69times as many times as B2Opt.
Even in this unfair case, B2Opt achieves the best results for all
fidelity levels. Fig. 6 shows the convergence curve of B2Opt,
LES, LGA, and CMA-ES on this task. B2Opt can achieve the
best solution with the least number of evaluations.
C. Parameter Analysis
We analyze the effect of the deep structure, learning rate,
and weight sharing between OBs on B2Opt.
1) B2Opt Architectures: We consider the performance of
different B2Opt architectures. The experimental results are
shown in Table VI. They were sorted from good to worst
based on their performance, and the result is 30 OBs with
WS>5 OBs without WS >3 OBs with WS . Deep architectures
have better representation capabilities and also lead to better
performance. However, training non-weight-sharing B2Opts
with more layers is challenging due to the difficulty of training
deep architectures. Untrained represents that the parameters of
5 OBs without WS are randomly initialized. 5 OBs without WS
outperforms Untrained , which demonstrates the effectiveness
of the designed training process. We also find an interesting
phenomenon: 5 OBs without WS outperforms 3 OBs with WS
in all cases. Our untrained deep architecture, 30 OBs with
0 2000 4000 6000 8000 10000
Evaluation Number0.10.20.30.40.50.60.70.80.9Classification Accuracy
B2Opt
LES
LGA
CMA-ESFig. 6. The convergence curves of B2Opt and baselines on the task of neural
network training. The X-axis represents the number of evaluations, and the
Y-axis represents the test accuracy. B2Opt stops iterating when the number
of evaluations is 144, and the red dotted line is for convenient comparison.
TABLE VI
THE PERFORMANCE OF DIFFERENT B2O PT STRUCTURES .
f Untrained 5 OBs 30 OBs 3 OBs
without WS with WS with WS
F4 0.28(0.09) 0.08(0.03) 1.2e-4(5e-5) 8.16(3.44)
F5 0.37(0.05) 0.15(0.03) 0.008(0.002) 1.47(0.40)
F6 45.8(16.9) 15.43(2.34) 8.93(0.03) 1891(1396)
F7 1.08(0.72) 4.43(1.82) 0.01(0.03) 35.72(8.52)
F8 0.69(0.09) 0.06(0.03) 1e-5(2e-5) 0.82(0.10)
F9 0.85(0.20) 0.29(0.07) 0.01(0.003) 3.28(1.00)
WS, can achieve good results on simple planner mechanic arm
problems, which shows that B2Opt retains the advantages of
Transformer architecture and has strong generalization ability.
We use the untrained 5 OBs without WS to test the complex
planner mechanic arm problem, which performs poorly.
We have observed that B2Opt can achieve better results with
deeper architectures. However, it is currently difficult for us to
train deep B2Opt. Moreover, as far as we know, the use of ES
to optimize deep models has been studied a lot [26], which
will be an essential research prospect in the future.
2) Learning Rate: We train B2Opt on the F1-F3 function
set with different learning rates and then test it on the F4-
F9 function set. The experimental results are shown in Table
VII. 5 OBs without WS and30 OBs with WS perform poorly
when the learning rate is 0.1, which may be because the
learning rate is too large, which affects the convergence

--- PAGE 11 ---
JOURNAL OF L ATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021 11
TABLE VII
THE EFFECT OF LEARNING RATE ON B2O PT.
lr F4 F5 F6 F7 F8 F9
5 OBs without WS
0.1 0.93(7.42) 0.31(0.49) 2.04e7(2.03e8) 15.3(6.4) 0.36(0.16) 0.61(0.18)
0.01 0.01(0.003) 0.05(0.02) 9.57(0.22) 1.62(0.60) 0.03(0.01) 0.06(0.03)
0.001 0.88(3.41) 0.36(0.12) 226(1750) 6.18(2.66) 0.56(0.16) 1.36(0.36)
0.0001 0.06(0.03) 0.13(0.03) 13.6(2.11) 0.83(0.50) 0.17(0.04) 0.28(0.10)
30 OBs with WS
0.1 1.64(1.19) 0.85(1.59) 493(3110) 28.4(4.35) 0.47(0.11) 2.82(0.5)
0.01 0.05(0.30) 0.09(0.03) 39.2(240) 1.05(1.40) 0.01(0.06) 0.28(0.07)
0.001 1.01e-3(0.001) 0.02(0.01) 9.03(0.18) 0.03(0.02) 0.003(0.001) 0.03(0.01)
0.0001 1.50e-3(0.001) 0.016(0.004) 9.01(0.13) 0.02(0.02) 0.006(0.002) 0.02(0.0.01)
3 OBs with WS
0.1 3.04(5.55) 0.98(0.4) 1150(7930) 43.3(8.87) 0.64(0.12) 2.43(0.98)
0.01 29.9(47.7) 2.68(1.30) 6.24e4(4.87e5) 40.4(8.52) 1.05(0.06) 4.45(0.85)
0.001 1.82(1.20) 0.76(0.32) 654(4780) 7.00(7.11) 0.79(0.13) 1.91(0.53)
0.0001 0.39(0.21) 0.33(0.07) 46.8(79.4) 2.22(2.41) 0.66(0.09) 0.59(0.19)
of B2Opt during the training process. For 5 OBs without
WS, setting the learning rate to 0.01 achieves the relatively
best performance. A learning rate 0.0001 would be a good
choice for 30 OBs with WS and 3 OBs with WS . However,
our experiments are coarse-grained. The learning rate has a
significant impact on B2Opt. Then using AutoML to search
for the optimal hyperparameter combination of the model is
expected to achieve better performance.
3) Training Data Size: We also explore the impact of
the size of the training data set on the performance of the
algorithm and take F4 as an example. It is trained on various
biases of F4 and tested on F4 without bias. The training data
set is Ftrain={F4(x|ωtrain
1,i),···, F4(x|ωtrain
m,i)}. Experi-
mental results are shown in Fig. 7, which show that the size
of the training dataset significantly impacts the performance
of B2Opt. As the amount of training data increases, the
performance of B2Opt increases.
100 200 300 400 500
dataset size0.050.100.150.20F
Fig. 7. The impact of training dataset size on B2Opt.
D. Ablation Study
This section considers the impact of different parts on
B2Opt. We take B2Opt with 3 OBs and weight sharing asTABLE VIII
THE RESULTS OF ABLATION STUDY .d= 10.
f Not SAC Not FM Not RC Not RSSM B2Opt
F4 52.7(15.0) 23.3(6.68) 50.5(6.81) 271(346) 3.03(5.82)
F5 5.08(0.98) 2.94(0.41) 3.75(0.09) 3.51(1.49) 1.02(0.20)
F6 1e5(9e4) 1e4(1e4) 5e4(1e4) 7e6(1e8) 4e3(7e4)
F7 47.2(5.11) 19.7(4.27) 63.4(8.60) 40.6(8.10) 44.8(8.34)
F8 1.18(0.04) 1.19(0.07) 0.87(0.07) 3.28(1.14) 0.60(0.17)
F9 4.49(1.09) 3.42(0.78) 8.36(0.43) 3.56(0.72) 3.03(0.70)
an example, which is trained on F1-F3 and tested on F4-F9.
We remove SAC, FM, RSSM, and RC in B2Opt, respectively,
and denote them as Not SAC ,Not FM ,Not RSSM , and Not
RC. The experimental results are shown in Table VIII. When
their results are sorted from good to worst, the rank is B2Opt
>Not FM >Not RC ≈Not SAC ≈Not RSSM . The role of
FM is slightly weaker than that of the other three modules.
Taken as a whole, the parts of SAC, RSSM, and RC are of
equal importance. The absence of these core components can
seriously affect the performance of B2Opt. At the same time, it
also shows the effectiveness of the proposed four modules. The
removal of any one of the modules in the crossover, mutation,
and selection of EAs will degrade the performance of EAs.
This shows that B2Opt implements a learnable EA framework
that does not require human-designed parameters.
E. Visualization Analysis
The tested model is 5 OBs with WS trained on F1-F3 with
d= 100 . The population size is set to 100.
Visual Analysis of SAC The crossover strategies learned
by the five SAC are shown in Fig. 8. For the presentation, we
select individuals with 1st, 50th, and 100th fitness rankings.
The horizontal axis represents the fitness ranking of individ-
uals, and the vertical axis represents the attention (weight
when performing crossover) on these individuals. OB1 tends to
crossover with lower-ranked individuals, showing a preference

--- PAGE 12 ---
JOURNAL OF L ATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021 12
0 20 40 60 80 1000.00990.01000.01010.01020.01030.01040.01050.0106Crossover Strategy Learned by OB 1
0 20 40 60 80 1000.00990.01000.01010.01020.01030.01040.01050.01060.0107Crossover Strategy Learned by OB 2
The 1st individual's strategy
The 50th individual's strategy
The 100th individual's strategy
0 20 40 60 80 1000.009950.010000.010050.010100.010150.01020Crossover Strategy Learned by OB 3
0 20 40 60 80 1000.01000.01010.01020.01030.01040.01050.01060.0107Crossover Strategy Learned by OB 4
0 20 40 60 80 1000.0100.0120.0140.0160.0180.0200.022Crossover Strategy Learned by OB 5Crossover Strategy Learned by OBs 
 
 
Fig. 8. Crossover Strategy learned by B2Opt.
x100
75
50
25
0
25
50
75
100y100
75
50
25
0
25
50
75
100F
02500500075001000012500150001750020000
input
mutpolyn
OB1
(a)
x100
75
50
25
0
25
50
75
100y100
75
50
25
0
25
50
75
100F
020406080100
input
mutpolyn
OB1 (b)
x100
75
50
25
0
25
50
75
100y100
75
50
25
0
25
50
75
100F
0.0x10100.2x10100.4x10100.6x10100.8x10101.0x1010
input
mutpolyn
OB1
 (c)
x4
2
0
2
4y4
2
0
2
4F
01020304050607080
input
mutpolyn
OB1
(d)
 (e)
x30
20
10
0
10
20
30y30
20
10
0
10
20
30F
05101520
input
mutpolyn
OB1
 (f)
Fig. 9. Mutation strategy learned by B2Opt for (a) F4, (b) F5, (c) F6, (d) F7, (e) F8, and (f) F9.
for exploration. From OB1 to OB5, the bias of SAC gradually
changes from exploration to exploitation.
Visual Analysis of FM We visualize the FM of B2Opt
to explore its behavior as Fig. 9. As a reference, we use
polynomial mutation in genetic algorithms. Given the input
population (input), the mutated population (OB1) is obtained
through OB1; the new population (mutpolyn) is obtained by
performing polynomial mutation on the input population. We
visualize F4-F9 and observe the following phenomena:1) The population generated by performing polynomial
mutation is more evenly distributed on the landscape. How-
ever, most of the solutions produced by FM in B2Opt are
concentrated in "areas with greater potential", which are closer
to the optimal solution. Moreover, the population distribution
generated by our scheme also takes diversity into account. The
non-optimal solution area is also more comprehensive than that
of polynomial mutation, which is more conducive to jumping
out of the local solution.

--- PAGE 13 ---
JOURNAL OF L ATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021 13
2) The population produced by performing polynomial
mutation moves slightly compared to the original population.
However, FM can guide the input population to make big
moves toward the optimal solution, significantly accelerating
the algorithm’s convergence.
This shows that B2Opt can use the information of the ob-
jective function to design the mutation strategy automatically,
making it more applicable to the target optimization task,
which is consistent with our motivation.
VI. C ONCLUSIONS
The better performance than that of EA baselines, Bayesian
optimization, and the L2O-based method demonstrates the ef-
fectiveness of B2Opt. Moreover, B2Opt can be well adapted to
unseen BBO. Meanwhile, we experimentally demonstrate that
the proposed three modules have positive effects. However,
B2Opt still has room for improvement.
1) In the loss function, we do not effectively consider
the diversity of the population, and the population can be
regularized in the future;
2) The training set seriously affects the performance of
B2Opt. If the similarity between the training set and the
optimization objective is low, it will cause the performance of
B2Opt to degrade drastically. Building the dataset as relevant
to the target as possible is essential.
REFERENCES
[1] T. Elsken, J. H. Metzen, and F. Hutter, “Neural architecture search: A
survey,” The Journal of Machine Learning Research , vol. 20, no. 1, pp.
1997–2017, 2019.
[2] F. Hutter, L. Kotthoff, and J. Vanschoren, Automated machine learning:
methods, systems, challenges . Springer Nature, 2019.
[3] D. Golovin, B. Solnik, S. Moitra, G. Kochanski, J. Karro, and D. Sculley,
“Google vizier: A service for black-box optimization,” in Proceedings
of the 23rd ACM SIGKDD International Conference on Knowledge
Discovery and Data Mining , 2017, pp. 1487–1495.
[4] J.-Y . Li, Z.-H. Zhan, and J. Zhang, “Evolutionary computation for ex-
pensive optimization: A survey,” Machine Intelligence Research , vol. 19,
no. 1, pp. 3–23, 2022.
[5] M. Mitchell, An introduction to genetic algorithms . MIT press, 1998.
[6] S. Khadka and K. Tumer, “Evolution-guided policy gradient in reinforce-
ment learning,” in Advances in Neural Information Processing Systems ,
S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi,
and R. Garnett, Eds., vol. 31. Curran Associates, Inc., 2018.
[7] Q. Zhang and H. Li, “Moea/d: A multiobjective evolutionary algorithm
based on decomposition,” IEEE Transactions on Evolutionary Compu-
tation , vol. 11, no. 6, pp. 712–731, 2007.
[8] J. Snoek, H. Larochelle, and R. P. Adams, “Practical bayesian optimiza-
tion of machine learning algorithms,” in Advances in Neural Information
Processing Systems , F. Pereira, C. Burges, L. Bottou, and K. Weinberger,
Eds., vol. 25. Curran Associates, Inc., 2012.
[9] M. Mutny and A. Krause, “Efficient high dimensional bayesian opti-
mization with additivity and quadrature fourier features,” in Advances
in Neural Information Processing Systems , S. Bengio, H. Wallach,
H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett, Eds.,
vol. 31. Curran Associates, Inc., 2018.
[10] C. Li, S. Gupta, S. Rana, V . Nguyen, S. Venkatesh, and A. Shilton,
“High dimensional bayesian optimization using dropout,” in IJCAI’17 .
AAAI Press, 2017.
[11] K. Kandasamy, J. Schneider, and B. Póczos, “High dimensional bayesian
optimisation and bandits via additive models,” in International Confer-
ence on Machine Learning . PMLR, 2015, pp. 295–304.
[12] M. Balandat, B. Karrer, D. Jiang, S. Daulton, B. Letham, A. G.
Wilson, and E. Bakshy, “Botorch: A framework for efficient monte-carlo
bayesian optimization,” in Advances in Neural Information Processing
Systems , H. Larochelle, M. Ranzato, R. Hadsell, M. Balcan, and H. Lin,
Eds., vol. 33. Curran Associates, Inc., 2020, pp. 21 524–21 538.[13] D. Wierstra, T. Schaul, T. Glasmachers, Y . Sun, J. Peters, and J. Schmid-
huber, “Natural evolution strategies,” Journal of Machine Learning
Research , vol. 15, no. 1, pp. 949–980, 2014.
[14] N. Hansen and A. Ostermeier, “Completely derandomized self-
adaptation in evolution strategies,” Evolutionary Computation , vol. 9,
no. 2, pp. 159–195, 2001.
[15] A. Auger and N. Hansen, “A restart cma evolution strategy with
increasing population size,” in 2005 IEEE Congress on Evolutionary
Computation , vol. 2, 2005, pp. 1769–1776.
[16] T. Salimans, J. Ho, X. Chen, S. Sidor, and I. Sutskever, “Evolution
strategies as a scalable alternative to reinforcement learning,” arXiv
preprint arXiv:1703.03864 , 2017.
[17] M. Andrychowicz, M. Denil, S. Gomez, M. W. Hoffman, D. Pfau,
T. Schaul, B. Shillingford, and N. De Freitas, “Learning to learn by
gradient descent by gradient descent,” in Advances in Neural Information
Processing Systems , 2016, pp. 3981–3989.
[18] T. Chen, X. Chen, W. Chen, H. Heaton, J. Liu, Z. Wang, and W. Yin,
“Learning to optimize: A primer and a benchmark,” Journal of Machine
Learning Research , vol. 23, pp. 1–59, 2022.
[19] T. Chen, W. Zhang, Z. Jingyang, S. Chang, S. Liu, L. Amini, and
Z. Wang, “Training stronger baselines for learning to optimize,” in
Advances in Neural Information Processing Systems , H. Larochelle,
M. Ranzato, R. Hadsell, M. F. Balcan, and H. Lin, Eds., vol. 33. Curran
Associates, Inc., 2020, pp. 7332–7343.
[20] Y . Chen, M. W. Hoffman, S. G. Colmenarejo, M. Denil, T. P. Lillicrap,
M. Botvinick, and N. Freitas, “Learning to learn without gradient descent
by gradient descent,” in International Conference on Machine Learning .
PMLR, 2017, pp. 748–756.
[21] K. Li and J. Malik, “Learning to optimize,” arXiv preprint
arXiv:1606.01885 , 2016.
[22] O. Wichrowska, N. Maheswaranathan, M. W. Hoffman, S. G. Col-
menarejo, M. Denil, N. Freitas, and J. Sohl-Dickstein, “Learned optimiz-
ers that scale and generalize,” in International Conference on Machine
Learning . PMLR, 2017, pp. 3751–3760.
[23] I. Bello, B. Zoph, V . Vasudevan, and Q. V . Le, “Neural optimizer search
with reinforcement learning,” in International Conference on Machine
Learning . PMLR, 2017, pp. 459–468.
[24] L. Metz, N. Maheswaranathan, J. Nixon, D. Freeman, and J. Sohl-
Dickstein, “Understanding and correcting pathologies in the training of
learned optimizers,” in International Conference on Machine Learning .
PMLR, 2019, pp. 4556–4565.
[25] E. Gärtner, L. Metz, M. Andriluka, C. D. Freeman, and C. Sminchis-
escu, “Transformer-based learned optimization,” in Proceedings of the
IEEE/CVF Conference on Computer Vision and Pattern Recognition
(CVPR) , June 2023, pp. 11 970–11 979.
[26] P. Vicol, L. Metz, and J. Sohl-Dickstein, “Unbiased gradient estimation
in unrolled computation graphs with persistent evolution strategies,” in
International Conference on Machine Learning . PMLR, 2021, pp.
10 553–10 563.
[27] S. Flennerhag, Y . Schroecker, T. Zahavy, H. van Hasselt, D. Silver, and
S. Singh, “Bootstrapped meta-learning,” in International Conference on
Learning Representations , 2022.
[28] H. Sun, X. Chen, Q. Shi, M. Hong, X. Fu, and N. D. Sidiropoulos,
“Learning to optimize: Training deep neural networks for interference
management,” IEEE Transactions on Signal Processing , vol. 66, no. 20,
pp. 5438–5453, 2018.
[29] Y . Cao, T. Chen, Z. Wang, and Y . Shen, “Learning to optimize in
swarms,” Advances in Neural Information Processing Systems , vol. 32,
pp. 15 044–15 054, 2019.
[30] R. T. Lange, T. Schaul, Y . Chen, T. Zahavy, V . Dallibard, C. Lu, S. Singh,
and S. Flennerhag, “Discovering evolution strategies via meta-black-box
optimization,” arXiv preprint arXiv:2211.11260 , 2022.
[31] D. P. Kingma and J. Ba, “Adam: A method for stochastic optimization,”
arXiv preprint arXiv:1412.6980 , 2014.
[32] C. Wang, J. Liu, K. Wu, and Z. Wu, “Solving multitask optimization
problems with adaptive knowledge transfer via anomaly detection,”
IEEE Transactions on Evolutionary Computation , vol. 26, no. 2, pp.
304–318, 2022.
[33] V . TV , P. Malhotra, J. Narwariya, L. Vig, and G. Shroff, “Meta-learning
for black-box optimization,” in Joint European Conference on Machine
Learning and Knowledge Discovery in Databases . Springer, 2020, pp.
366–381.
[34] H. S. Gomes, B. Léger, and C. Gagné, “Meta learning black-box
population-based optimizers,” arXiv preprint arXiv:2103.03526 , 2021.
[35] G. Shala, A. Biedenkapp, N. Awad, S. Adriaensen, M. Lindauer, and
F. Hutter, “Learning step-size adaptation in cma-es,” in International

--- PAGE 14 ---
JOURNAL OF L ATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021 14
Conference on Parallel Problem Solving from Nature . Springer, 2020,
pp. 691–706.
[36] R. Lange, T. Schaul, Y . Chen, C. Lu, T. Zahavy, V . Dalibard, and S. Flen-
nerhag, “Discovering attention-based genetic algorithms via meta-black-
box optimization,” in Proceedings of the Genetic and Evolutionary
Computation Conference , ser. GECCO ’23. New York, NY , USA:
Association for Computing Machinery, 2023, p. 929–937.
[37] J. Zhang, C. Xu, J. Li, W. Chen, Y . Wang, Y . Tai, S. Chen, C. Wang,
F. Huang, and Y . Liu, “Analogous to evolutionary algorithm: Designing a
unified sequence model,” in Advances in Neural Information Processing
Systems , M. Ranzato, A. Beygelzimer, Y . Dauphin, P. Liang, and J. W.
Vaughan, Eds., vol. 34. Curran Associates, Inc., 2021, pp. 26 674–
26 688.
[38] A. Dosovitskiy, L. Beyer, A. Kolesnikov, D. Weissenborn, X. Zhai,
T. Unterthiner, M. Dehghani, M. Minderer, G. Heigold, S. Gelly et al. ,
“An image is worth 16x16 words: Transformers for image recognition at
scale,” in International Conference on Learning Representations , 2021.
[39] K. Kandasamy, G. Dasarathy, J. B. Oliva, J. Schneider, and B. Póczos,
“Gaussian process bandit optimisation with multi-fidelity evaluations,”
Advances in Neural Information Processing Systems , vol. 29, 2016.
[40] Y . Cao and Y . Shen, “Bayesian active learning for optimization and
uncertainty quantification in protein docking,” Journal of Chemical
Theory and Computation , vol. 16, no. 8, pp. 5334–5347, 2020.
[41] R. J. Williams, “Simple statistical gradient-following algorithms for
connectionist reinforcement learning,” Machine Learning , vol. 8, no. 3,
pp. 229–256, 1992.
[42] A. Cully, J. Clune, D. Tarapore, and J.-B. Mouret, “Robots that can
adapt like animals,” Nature , vol. 521, pp. 503–507, 2015.
[43] V . Vassiliades, K. Chatzilygeroudis, and J.-B. Mouret, “Using cen-
troidal voronoi tessellations to scale up the multidimensional archive
of phenotypic elites algorithm,” IEEE Transactions on Evolutionary
Computation , vol. 22, pp. 623–630, 2018.
[44] V . Vassiliades and J.-B. Mouret, “Discovering the elite hypervolume
by leveraging interspecies correlation,” Proceedings of the Genetic and
Evolutionary Computation Conference , 2018.
[45] J.-B. Mouret and G. Maguire, “Quality diversity for multi-task optimiza-
tion,” Proceedings of the 2020 Genetic and Evolutionary Computation
Conference , 2020.
[46] A. Howard, M. Zhu, B. Chen, D. Kalenichenko, W. Wang, T. Weyand,
M. Andreetto, and H. Adam, “Mobilenets: Efficient convolutional neural
networks for mobile vision applications,” arXiv: Computer Vision and
Pattern Recognition , 2017.
[47] S. Das and P. N. Suganthan, “Differential evolution: A survey of
the state-of-the-art,” IEEE transactions on Evolutionary Computation ,
vol. 15, no. 1, pp. 4–31, 2010.
[48] A. Auger and N. Hansen, “A restart cma evolution strategy with
increasing population size,” in 2005 IEEE Congress on Evolutionary
Computation , vol. 2, 2005, pp. 1769–1776 V ol. 2.
[49] R. Tanabe and A. S. Fukunaga, “Improving the search performance of
shade using linear population size reduction,” in 2014 IEEE Congress
on Evolutionary Computation (CEC) , 2014, pp. 1658–1665.
[50] N. Hansen, “The cma evolution strategy: A tutorial,” ArXiv , vol.
abs/1604.00772, 2016.
[51] Jazzbin, “Geatpy: The genetic and evolutionary algorithm toolbox with
high performance in python,” 2020.
[52] K. Kandasamy, K. R. Vysyaraju, W. Neiswanger, B. Paria, C. R. Collins,
J. Schneider, B. Poczos, and E. P. Xing, “Tuning hyperparameters
without grad students: Scalable and robust bayesian optimisation with
dragonfly,” Journal of Machine Learning Research , vol. 21, no. 81, pp.
1–27, 2020.
[53] D. Eriksson and M. Jankowiak, “High-dimensional Bayesian opti-
mization with sparse axis-aligned subspaces,” in Proceedings of the
Thirty-Seventh Conference on Uncertainty in Artificial Intelligence , ser.
Proceedings of Machine Learning Research, C. de Campos and M. H.
Maathuis, Eds., vol. 161. PMLR, 27–30 Jul 2021, pp. 493–503.

# 2309.11668.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/multilingual/2309.11668.pdf
# Kích thước file: 629422 bytes

===============================================
NỘI DUNG FILE PDF
===============================================

--- TRANG 1 ---
Hướng tới Việc Giải Quyết Hiệu Quả Sự Nhập Nhằng trong Dịch Máy
với Các Mô Hình Ngôn Ngữ Lớn
Vivek Iyer Pinzhen Chen Alexandra Birch
Trường Tin học, Đại học Edinburgh
{vivek.iyer, pinzhen.chen, a.birch}@ed.ac.uk
Tóm tắt
Việc giải quyết sự nhập nhằng về mặt ngữ nghĩa từ lâu đã
được công nhận là một thách thức trung tâm trong lĩnh vực
Dịch Máy. Nghiên cứu gần đây về việc đánh giá hiệu suất
dịch thuật trên các câu nhập nhằng đã phơi bày những hạn chế
của các hệ thống Dịch Máy Thần Kinh (NMT) thông thường,
vốn không thể xử lý được nhiều trường hợp như vậy.
Các mô hình ngôn ngữ lớn (LLM) đã nổi lên như một giải pháp
thay thế đầy hứa hẹn, thể hiện hiệu suất tương đương với
các mô hình NMT truyền thống đồng thời giới thiệu những
mô hình mới để kiểm soát đầu ra mục tiêu. Trong bài báo này,
chúng tôi nghiên cứu khả năng của LLM trong việc dịch
"câu nhập nhằng" - tức là những câu chứa từ đa nghĩa cao
và/hoặc nghĩa từ hiếm. Chúng tôi cũng đề xuất hai cách
để cải thiện khả năng giải quyết nhập nhằng của chúng,
thông qua a) học trong ngữ cảnh và b) tinh chỉnh trên
các tập dữ liệu nhập nhằng được tuyển chọn cẩn thận.
Các thí nghiệm cho thấy rằng phương pháp của chúng tôi
có thể sánh ngang hoặc vượt trội hơn các hệ thống tiên tiến
như DeepL và NLLB trong bốn trên năm hướng ngôn ngữ.
Nghiên cứu của chúng tôi cung cấp những hiểu biết có giá trị
về việc thích nghi hiệu quả LLM để trở thành những công cụ
giải quyết nhập nhằng tốt hơn trong Dịch Máy.
Chúng tôi phát hành các tập dữ liệu giải quyết nhập nhằng
được tuyển chọn và các tài nguyên tại https://data.statmt.org/
ambiguous-europarl .
1 Giới thiệu
Trong khi lĩnh vực NMT đã tiến bộ nhanh chóng trong
thời gian gần đây, việc giải quyết nhập nhằng và dịch thuật
các từ nhập nhằng vẫn còn là một thách thức mở.
Đáng chú ý, Campolungo et al. (2022) đã tạo ra một
điểm chuẩn có tên DiBiMT để nghiên cứu hành vi của
các hệ thống NMT tiên tiến (SOTA) khi dịch các câu
có từ nhập nhằng.1 Họ báo cáo rằng ngay cả các hệ thống
NMT thương mại có hiệu suất tốt nhất cũng chỉ cho ra
bản dịch chính xác khoảng 50-60% thời gian,2 trong khi
các mô hình đa ngôn ngữ nguồn mở khác như mBART50
(Tang et al., 2021) và M2M100 (Fan et al., 2021) thực hiện
kém hơn nhiều. Điều này được phát hiện là do thiên lệch
chống lại các nghĩa từ hiếm và đa nghĩa được thừa kế
trong quá trình tiền huấn luyện. Bảng 1 cho thấy một
ví dụ từ điểm chuẩn DiBiMT nơi DeepL3 dịch sai một
từ nhập nhằng trong khi LLM BLOOMZ giải quyết từ đó
theo nghĩa đúng trong ngữ cảnh.

Nguồn Con ngựa có một vệt trắng giữa hai mắt.
DeepL 那匹马的两眼之间有一团火焰。
(Có một ngọn lửa giữa hai mắt của con ngựa.)
BLOOMZ
(176B) 这匹马的眼睛之间有一道白线。
(Có một đường trắng giữa hai mắt của con ngựa.)

Bảng 1: Một ví dụ về dịch từ tiếng Anh sang tiếng Trung
liên quan đến thuật ngữ nhập nhằng "blaze". Đối với BLOOMZ,
chúng tôi sử dụng prompting 1-shot để có được bản dịch.

Trong bài báo này, chúng tôi khám phá liệu LLM có thực sự
có thể thực hiện tốt hơn trong việc dịch "câu nhập nhằng"
– tức là những câu chứa nghĩa từ có tính đa nghĩa cao
và/hoặc hiếm. Động lực đằng sau điều này là trong khi
các mô hình NMT có thể học được thiên lệch từ dữ liệu song song
ồn ào hoặc miền hẹp, làm tổn hại khả năng phát hiện và dịch
nghĩa từ hiếm, LLM có thể được tiền huấn luyện trên
nhiều loại văn bản đơn ngôn ngữ rộng hơn – mặc dù
chúng cũng có thể ưu tiên tính trôi chảy hơn độ chính xác.
Tuy nhiên, LLM đã cho thấy nhiều khả năng nổi lên
do quy mô (Brown et al., 2020; Chowdhery et al., 2022;
Wei et al., 2022a) và hơn nữa, đã chứng minh tiềm năng
lớn cho Dịch Máy (MT) (Vilar et al., 2023; Zhang et al., 2023).

Chúng tôi kiểm tra toàn diện cách những xu hướng này
mở rộng đến nhiệm vụ cụ thể là dịch các câu nhập nhằng.
Chúng tôi chọn một tập hợp đa dạng các LLM nền tảng
và được điều chỉnh theo hướng dẫn, có kích thước khác nhau
và với các kết hợp ngôn ngữ khác nhau trong dữ liệu tiền huấn luyện.
Sau đó chúng tôi so sánh cách các LLM này đối đầu với
một số mô hình NMT được sử dụng rộng rãi trên bộ kiểm tra
DiBiMT, bao gồm dịch từ tiếng Anh sang năm ngôn ngữ:
Tây Ban Nha, Ý, Đức, Nga và Trung Quốc. Chúng tôi
thấy rằng, chỉ với học trong ngữ cảnh 1-shot (Brown et al., 2020),
LLM – đặc biệt là BLOOMZ 176B (Muennighoff et al., 2023)
và LLaMA 65B (Touvron et al., 2023) – sánh ngang hoặc
vượt trội hơn các hệ thống MT nguồn mở và thương mại
có hiệu suất hàng đầu, và thiết lập SOTA mới trong hai
trong số năm ngôn ngữ chúng tôi đã kiểm tra. Hơn nữa,
chúng tôi đề xuất hai phương pháp để thích nghi LLM cho
dịch thuật nhập nhằng: 1) học trong ngữ cảnh với các câu
có cùng nghĩa từ, và 2) tinh chỉnh trên tập dữ liệu song song
nhập nhằng được tuyển chọn. Chúng tôi cho thấy rằng
các phương pháp này rất hiệu quả và có thể cải thiện
thêm hiệu suất lên đến 15 điểm trong độ chính xác
DiBiMT trong trường hợp tốt nhất.

Công trình của chúng tôi do đó đóng góp ba điểm chính:
1. Chúng tôi đánh giá hiệu suất của LLM so với các hệ thống
NMT có hiệu suất hàng đầu trong nhiệm vụ thách thức
là dịch các câu nhập nhằng. Chúng tôi báo cáo điểm số
SOTA trên 2 trong 5 ngôn ngữ được kiểm tra, và hiệu suất
tương đương ở những ngôn ngữ khác.
2. Chúng tôi cũng cho thấy rằng các kỹ thuật được đề xuất
của chúng tôi về học trong ngữ cảnh với câu tương tự
và tinh chỉnh giải quyết nhập nhằng có mục tiêu vượt trội
đáng kể so với prompting few-shot naïve
3. Chúng tôi kết thúc công trình bằng việc đánh giá LLM
trên các bộ kiểm tra FLORES200, và xác nhận rằng
những cải thiện trong độ chính xác giải quyết nhập nhằng
tương quan mạnh với những cải thiện trong chất lượng MT tổng thể.

2 Bối cảnh
2.1 Tính nhập nhằng trong dịch máy
Việc giải quyết nhập nhằng trong câu nguồn đã được định khung
lịch sử như một trong những thách thức cơ bản nhất trong MT
(Weaver, 1952). Trong nỗ lực giải quyết thách thức này,
các công trình truyền thống tích hợp Giải quyết Nhập nhằng
Nghĩa Từ trong Dịch Máy Thống kê (Carpuat và Wu, 2007;
Chan et al., 2007) được theo sau bởi những công trình tích hợp
nó vào kiến trúc NMT theo nhiều cách đặc biệt (Choi et al., 2017;
Liu et al., 2018; Pu et al., 2018). Sau đó, với việc giới thiệu
Transformer (Vaswani et al., 2017), đã được chứng minh rằng
các biểu diễn encoder tầng cao đủ mạnh để xử lý giải quyết
nhập nhằng (Tang et al., 2019) mà không cần bất kỳ xử lý
rõ ràng nào về nghĩa từ.

Tuy nhiên, nghiên cứu gần đây hơn tạo ra các điểm chuẩn
đánh giá thách thức đã đặt câu hỏi về khả năng được cho là
có của các hệ thống NMT một lần nữa. Sau đề xuất điểm chuẩn
MuCoW để kiểm tra các hệ thống WMT19 (Raganato et al., 2019)
và WMT20 (Scherrer et al., 2020), Raganato et al. (2020)
đã cho thấy cách các mô hình NMT dựa trên Transformer,
nói chung, thực hiện kém khi dịch nghĩa từ hiếm. Campolungo
et al. (2022), những người thí nghiệm với các hệ thống thương mại
SOTA (Google Translate, DeepL) và nguồn mở (mBART50,
M2M100, OPUS-NMT (Tiedemann và Thottingal, 2020), v.v.),
đã đi đến kết luận tương tự khi họ đề xuất điểm chuẩn
DiBiMT để đánh giá các hệ thống MT giữa tiếng Anh
và 5 ngôn ngữ (Tây Ban Nha, Ý, Đức, Nga và Trung Quốc).
Họ tìm thấy những thiên lệch tương tự chống lại nghĩa từ
tần suất thấp và có tính đa nghĩa cao. Họ cũng lưu ý rằng
độ chính xác của các hệ thống này thấp hơn nhiều so với
hệ thống WSD SOTA khi đó, ESCHER (Barba et al., 2021)
– cho thấy dư địa đáng kể để cải thiện. Trong công trình này,
chúng tôi khám phá liệu LLM nền tảng và được điều chỉnh
theo hướng dẫn có thể thu hẹp khoảng cách này với
giám sát tối thiểu (tức là prompting few-shot).

2.2 LLM và dịch máy
Nghiên cứu trước đây đã phát hiện rằng LLM có thể thực hiện
dịch máy mà không cần được tinh chỉnh cụ thể (Radford et al., 2019).
Để gợi ra một bản dịch, nghiên cứu theo hướng này tuân theo
mô hình prompting LLM:
1. Zero-shot prompting, nơi LLM được yêu cầu trực tiếp
dịch một đầu vào nguồn sang ngôn ngữ đích (Radford et al., 2019).
2. Few-shot prompting, còn được gọi là học trong ngữ cảnh,
nơi LLM được cung cấp các minh chứng về cặp đầu vào
và đầu ra từ cùng một nhiệm vụ mà nó đang thực hiện,
trước khi được truy vấn một đầu vào (Brown et al., 2020).
3. Chain-of-thought (CoT), nơi LLM được nhắc để suy luận
để có được kiến thức liên quan về đầu vào trước khi tạo ra
một đầu ra (Wei et al., 2022b; Kojima et al., 2022).

Bên cạnh các cách tiếp cận không cần huấn luyện, một con đường
khác là điều chỉnh hướng dẫn, tối ưu hóa LLM trên một
phạm vi hỗn hợp các nhiệm vụ downstream và tinh chỉnh
mô hình để hiểu và phản hồi ý định của người dùng
thông qua ngôn ngữ tự nhiên (Wei et al., 2021).

Đã quan sát thấy rằng LLM có thể không vượt qua các mô hình
Transformer được huấn luyện chỉ để dịch, đặc biệt là
cho các hướng dịch phi tiếng Anh và tài nguyên thấp
(Vilar et al., 2023; Hendy et al., 2023). Tuy nhiên, LLM
đã được chứng minh đạt được sự vượt trội trong các nhiệm vụ
đòi hỏi hiểu biết sâu sắc và thao tác văn bản, chủ yếu
do chúng được tiền huấn luyện trên các tập dữ liệu rất lớn.
Ví dụ, không cần tinh chỉnh, LLM giỏi trong việc thích nghi
với căn chỉnh từ (Moslem et al., 2023), đánh giá dịch thuật
(Kocmi và Federmann, 2023), dịch thành ngữ (Raunak et al., 2023),
cải thiện lặp lại (Chen et al., 2023), và dịch thuật tương tác
qua CoT (Pilault et al., 2023; He et al., 2023). Liên quan
đến công trình của chúng tôi là đề xuất của Pilault et al. (2023)
về việc sử dụng hỏi đáp tương tác như một quy trình CoT
để LLM giải quyết nhập nhằng các từ nguồn. Như một
cách tiếp cận thay thế, chúng tôi nhắm mục tiêu tạo ra
bản dịch trong một lần thực hiện bằng cách tận dụng
các hệ thống WSD SOTA để cung cấp ngữ cảnh hướng dẫn
LLM giải quyết nhập nhằng tốt hơn.

3 Phương pháp
3.1 Khái niệm cơ bản
Một nghĩa từ là một khái niệm trong Cơ sở Tri thức
(trong công trình này, BabelNet của Navigli et al. (2021))
biểu thị một nghĩa riêng biệt của một từ trong ngữ cảnh
của một câu. Mức độ đa nghĩa của một từ nhập nhằng
được định nghĩa là tổng số đếm của tất cả các nghĩa
có thể mà một từ cụ thể có thể có. Tần suất nghĩa
được định nghĩa là số lần xuất hiện của nghĩa cụ thể
đó trong một tập dữ liệu huấn luyện đã được giải quyết nhập nhằng.

Trong công trình này, chúng tôi định nghĩa một từ nhập nhằng
là một thuật ngữ đa nghĩa với nhiều nghĩa có thể,
và có thể liên quan, – với nghĩa đúng chỉ có thể suy ra
từ ngữ cảnh cấp câu. Sau đó chúng tôi gọi một câu
có từ nhập nhằng là một "câu nhập nhằng" để ngắn gọn
và dễ giải thích. Theo định nghĩa, bộ kiểm tra DiBiMT
(Campolungo et al., 2022) chỉ chứa một từ nhập nhằng
trên mỗi câu.

Giải quyết Nhập nhằng Nghĩa Từ (WSD) là quá trình
liên kết một từ nhập nhằng trong một câu với nghĩa từ
thích hợp của nó trong Cơ sở Tri thức. Chúng tôi sử dụng
ESCHER-WSD (Barba et al., 2021) trong công trình này,
một hệ thống WSD có hiệu suất cao đã đạt được SOTA
cho tiếng Anh.

3.2 K-shot prompting
Cho một câu kiểm tra X và một Mô hình Ngôn ngữ Lớn
để prompt cho bản dịch, chúng tôi xây dựng một truy vấn
với k minh chứng, tức là các cặp câu song song
{(X1, Y1), (X2, Y2)... (Xk, Yk)} làm ví dụ, theo sau
là câu kiểm tra. Như được hiển thị trong Hình 1, đối với
LLM nền tảng, chúng tôi định khung prompt như một
nhiệm vụ hoàn thiện văn bản, trong khi đối với LLM
được điều chỉnh hướng dẫn (như BLOOMZ) chúng tôi
cấu trúc cụm từ cuối cùng như một câu hỏi, để tuân thủ
định dạng hỏi đáp của loại sau. Trong cài đặt naïve,
chúng tôi chọn các minh chứng ngẫu nhiên từ tập phát triển.

3.3 Học trong ngữ cảnh với các ngữ cảnh
nhập nhằng tương tự
LLM có thể có hiệu quả thu được kiến thức liên quan
đến miền kiểm tra thông qua prompting, và quá trình này
được gọi là học trong ngữ cảnh (ICL). Chúng tôi tận dụng
ICL để giúp LLM tiếp thu thông tin về dịch thuật
các câu nhập nhằng, bằng cách cung cấp các bản dịch
nghĩa liên quan làm ví dụ trong prompt. Để đạt được
điều này, đầu tiên chúng tôi xác định từ có tính đa nghĩa
nhất trong câu đầu vào bằng cách giải quyết nhập nhằng
nó với một hệ thống WSD, và sau đó tính toán mức độ
đa nghĩa của tất cả các nghĩa đã được giải quyết nhập nhằng
đối với một tập phát triển lớn. Chúng tôi chọn nghĩa từ
có tính đa nghĩa nhất4 và tìm kiếm các lần xuất hiện
khác của cùng nghĩa trong cùng tập phát triển. Cuối cùng,
chúng tôi lấy mẫu ngẫu nhiên k cặp nguồn-đích bao gồm
nghĩa như vậy để sử dụng làm minh chứng trong k-shot
prompting, thay vì sử dụng các cặp ngẫu nhiên. Kỹ thuật
này dường như trả về đủ ví dụ cho mục đích của chúng tôi
trong hầu hết các trường hợp – đối với 5-shot prompting,
với một tập dữ liệu 1,8M câu, chúng tôi quan sát rằng
chúng tôi nhận được tất cả 5 kết quả phù hợp 92,5% thời gian.

3.4 Tinh chỉnh rank thấp
Ngoài việc cung cấp các ví dụ liên quan thông qua prompting,
một cách tiếp cận thông thường khác là tối ưu hóa các
tham số mô hình theo cách thích nghi miền cho việc
giải quyết nhập nhằng. Xem xét chi phí tính toán,
công trình của chúng tôi thí nghiệm với tinh chỉnh hướng dẫn
thông qua thích nghi rank thấp (LoRA). Kỹ thuật này
gắn thêm các ma trận phân tách rank thấp có thể huấn luyện
vào các ma trận khổng lồ trong một LLM có thể giữ nguyên
trong quá trình tinh chỉnh (Hu et al., 2021). Bằng cách
hy sinh một chút hiệu suất, phương pháp tinh chỉnh này
đạt được hiệu quả tham số lớn.

Chúng tôi nhắm mục tiêu điều chỉnh LLM để thực hiện
nhiệm vụ dịch thuật cụ thể. Để tối đa hóa khả năng
của LLM trong việc giải quyết nhập nhằng khi dịch,
chúng tôi tuân theo một quy trình lựa chọn dữ liệu
cẩn thận để xác định các câu nhập nhằng nhất trong
tập dữ liệu của chúng tôi.

Với kích thước của LLM, sẽ không khả thi khi tinh chỉnh
chúng trên một tập dữ liệu song song lớn, vì vậy chúng tôi
chọn tuyển chọn một tập dữ liệu nhỏ hơn phù hợp với
nhiệm vụ dịch thuật nhập nhằng. Chúng tôi muốn có
một sự kết hợp cân bằng giữa các câu có từ có tính
đa nghĩa cao cũng như những câu có nghĩa hiếm
của một từ nhất định. Điều này nhằm đảm bảo tinh chỉnh
giảm cả thiên lệch liên quan đến mức độ đa nghĩa
và thiên lệch liên quan đến tần suất nghĩa, như được
phát hiện bởi Campolungo et al. (2022) và do đó,
tối đa hóa hiệu suất giải quyết nhập nhằng.

Chúng tôi, do đó, sắp xếp tập dữ liệu theo hai cách:
một, theo mức độ đa nghĩa tối đa (lớn nhất trước)
và hai, theo tần suất nghĩa tối thiểu (hiếm nhất trước)
của tất cả nghĩa từ trong một câu nhất định, được
giải quyết nhập nhằng với ESCHER-WSD. Chúng tôi
lấy N/2 câu hàng đầu từ mỗi tập và xen kẽ chúng
để tạo ra tập dữ liệu tinh chỉnh cuối cùng có kích thước N.
Chúng tôi phát hành tập dữ liệu tinh chỉnh của mình,
cùng với các đầu ra giải quyết nhập nhằng ESCHER-WSD
để sử dụng công khai.5

Khi dữ liệu được chọn, chúng tôi tuân theo mô hình
tinh chỉnh của Alpaca (Taori et al., 2023): mô hình
được prompt với một hướng dẫn chỉ định ngôn ngữ
nguồn và đích, cũng như câu kiểm tra như một đầu vào,
và mô hình được mong đợi phản hồi với bản dịch.6

4 Thí nghiệm
Trong phần này, chúng tôi tìm cách trả lời các câu hỏi
nghiên cứu sau:
1. RQ1: LLM thực hiện như thế nào trong việc dịch
các câu nhập nhằng so với các hệ thống NMT truyền thống
có hiệu suất cao? (Phần 4.3)
2. RQ2: Người ta có thể sử dụng những phương pháp
nào để thích nghi LLM cho nhiệm vụ này và cải thiện
hiệu suất so với prompting few-shot naïve? (Phần 4.4)
3. RQ3: Những LLM được thích nghi giải quyết nhập nhằng
này hoạt động như thế nào về mặt chất lượng dịch thuật
tổng thể? (Phần 4.5)

4.1 Mô hình
Để đảm bảo khả năng tái tạo, chúng tôi chọn bốn LLM
nguồn mở nổi tiếng và có hiệu suất cao,7 trong đó
chúng tôi lấy mẫu bảy phiên bản để thí nghiệm:
• BLOOM (Scao et al., 2022): Một LLM nền tảng
hoàn toàn nguồn mở, đa ngôn ngữ hỗ trợ 46 ngôn ngữ.
Để thiết lập phạm vi khả năng của nó, chúng tôi khám phá
cả phiên bản nhỏ nhất (7.1B) và lớn nhất (176B).
• BLOOMZ (Muennighoff et al., 2023): BLOOM được
điều chỉnh hướng dẫn trên một tập prompting đa ngôn ngữ.
Một lần nữa, chúng tôi chọn phiên bản nhỏ nhất (7.1B)
và lớn nhất (176B).
• LLaMA (Touvron et al., 2023): LLM phổ biến được
huấn luyện bởi Meta AI, trên các tập dữ liệu khổng lồ
có phạm vi lên đến 1.5T token. Chúng tôi đánh giá
phiên bản nhỏ nhất (7B) và lớn nhất (65B).
• Alpaca (Taori et al., 2023): Một mô hình LLaMA
được điều chỉnh hướng dẫn trên một tập dữ liệu 52K
được tạo ra sử dụng Self-Instruct (Wang et al., 2023).

Để định vị hiệu quả các LLM nguồn mở này so với
các hệ thống NMT truyền thống, chúng tôi so sánh
chúng với các mô hình thương mại và nguồn mở
có hiệu suất tốt nhất và được sử dụng rộng rãi nhất:
1. DeepL Translator8: một hệ thống NMT thương mại
SOTA (truy cập ngày 24 tháng 7 năm 2023).
2. Google Translate9: Có lẽ là hệ thống NMT thương mại
được sử dụng rộng rãi nhất (truy cập ngày 24 tháng 7 năm 2023).
3. OPUS (Tiedemann và Thottingal, 2020): Các mô hình
NMT nhỏ, song ngữ, dựa trên Transformer được huấn luyện
trên tập dữ liệu song song OPUS.
4. mBART50 (Tang et al., 2021): Các mô hình NMT
đa ngôn ngữ được tiền huấn luyện trên tập dữ liệu
đơn ngôn ngữ từ 50 ngôn ngữ, và được tinh chỉnh
trên nhiệm vụ dịch thuật. Chúng tôi báo cáo hiệu suất
của cả mô hình tinh chỉnh từ tiếng Anh sang nhiều ngôn ngữ
và nhiều ngôn ngữ sang nhiều ngôn ngữ.
5. M2M100 (Fan et al., 2021): Một mô hình NMT
đa ngôn ngữ lớn được huấn luyện trên 2200 hướng dịch
để hỗ trợ dịch thuật nhiều ngôn ngữ sang nhiều ngôn ngữ
giữa tổng cộng 100 ngôn ngữ. Chúng tôi so sánh cả
phiên bản cơ bản (418M) và lớn (1.2B).
6. NLLB-200 (NLLB Team et al., 2022): Đây là SOTA
hiện tại trong nhiều cặp tài nguyên thấp, mở rộng đến
200 ngôn ngữ. Chúng tôi thí nghiệm với tất cả các biến thể
của nó, trong đó lớn nhất là một mô hình mixture-of-experts
(MoE) với 54B tham số. Chúng tôi cũng đánh giá
các checkpoint nhỏ hơn ở 1.3B và 3.3B, cũng như
các phiên bản chưng cất ở 0.6B và 1.3B.

Chúng tôi lấy kết quả cho mBART50, M2M100 và OPUS
trực tiếp từ bảng xếp hạng DiBiMT.10 Chúng tôi sử dụng
Hugging Face11 để truy cập và suy luận tất cả các mô hình
khác – trừ Google Translate và DeepL, được truy cập
bằng các API tương ứng. Mặc dù có mặt trên bảng xếp hạng,
chúng tôi đánh giá lại các hệ thống này vì chúng đang
được cập nhật liên tục.

4.2 Thiết lập thí nghiệm
Tập dữ liệu Trong nghiên cứu này, chúng tôi sử dụng
bộ kiểm tra DiBiMT để đánh giá và đo lường độ chính xác
trên tất cả năm hướng dịch: tiếng Anh sang Tây Ban Nha,
Ý, Trung Quốc, Nga và Đức, tương ứng. Để xác thực,
chúng tôi sử dụng tập phát triển từ FLORES 200
(NLLB Team et al., 2022) trong cài đặt cơ bản của chúng tôi.
Để tìm kiếm các ngữ cảnh nhập nhằng tương tự (Phần 3.3),
chúng tôi cần một tập phát triển lớn hơn để tìm các ví dụ
liên quan và cũng để ước tính chính xác mức độ đa nghĩa.
Do đó, chúng tôi sử dụng tập dữ liệu Europarl (Koehn, 2005),
được giải quyết nhập nhằng với ESCHER-WSD. Chúng tôi
cũng sử dụng cùng tập dữ liệu được giải quyết nhập nhằng
cho tinh chỉnh, tuy nhiên, đầu tiên chúng tôi tuân theo
quy trình lọc được mô tả trong Phần 3.4 để tạo ra
một tập dữ liệu nhỏ đầy các câu nhập nhằng. Xác thực
trong quá trình tinh chỉnh được thực hiện bằng 500 câu
được lấy mẫu ngẫu nhiên từ tập dữ liệu này và phần còn lại
được sử dụng cho huấn luyện. Chúng tôi chi tiết thống kê
dữ liệu được sử dụng cho các thí nghiệm này trong Bảng 2.

Thiết lập prompting LLM Do hạn chế về bộ nhớ,
và để so sánh tất cả các mô hình một cách công bằng,
chúng tôi tải LLM ở 8-bit và sử dụng kích thước batch là 1.
Để tạo ra, chúng tôi đặt cả kích thước beam và nhiệt độ
thành 1. Để ngăn chặn lặp lại trong đầu ra LLM,
chúng tôi đặt no_repeat_ngram_size thành 4. Từ phản hồi
của LLM, chúng tôi lọc ra câu trước ký tự xuống dòng
đầu tiên làm bản dịch đầu ra.

Tinh chỉnh LoRA Chúng tôi tiêm các module LoRA
vào tất cả các ma trận query, key và value. Chúng tôi
đặt rank thành 8, alpha thành 8, và dropout thành 0.05.
Để huấn luyện, chúng tôi đặt kích thước batch hiệu quả
thành 32, tốc độ học thành 3e-4, và độ dài tối đa thành 256.
Tổng ngân sách huấn luyện là 5 epoch, và chúng tôi
chọn checkpoint mô hình tốt nhất dựa trên cross-entropy
loss trên tập xác thực. Dữ liệu huấn luyện được xáo trộn
sau mỗi epoch. Suy luận được thực hiện với kích thước
beam là 3, và độ dài tạo ra tối đa là 150.

4.3 LLM so với hệ thống NMT trên DiBiMT
Chúng tôi trình bày kết quả của các thí nghiệm trong Bảng 3.
Cho mục đích thảo luận tiếp theo, chúng tôi lưu ý ở đây
rằng LLaMA không được huấn luyện có chủ ý trên
tiếng Trung và do đó, là một ngôn ngữ 'không nhìn thấy'.
Tương tự, đối với BLOOM, tiếng Trung và Tây Ban Nha
là "đã thấy" và phần còn lại là "không thấy". Chúng tôi
chia sẻ các quan sát chính dưới đây:

1. LLM thường sánh ngang hoặc đánh bại các mô hình
MT lớn trên các ngôn ngữ đã thấy. Ngoại trừ En-De
rất giàu tài nguyên, nơi các hệ thống MT có giám sát
dường như có lợi thế, LLaMA 65B chủ yếu sánh ngang
với các hệ thống NMT SOTA (cụ thể là DeepL và NLLB-200).
Hơn nữa, BLOOMZ thiết lập SOTA mới trong các ngôn ngữ
đã thấy của nó, Tây Ban Nha và Trung Quốc, và vượt trội
hơn DeepL với biên độ lần lượt là 7.3% và 12.2%.
Những cải thiện này so với các hệ thống NMT lớn
có giám sát mạnh như vậy đặc biệt đáng chú ý vì
thiết lập tương ứng của chúng tôi để suy luận LLM
khá rẻ – như chúng tôi đã lưu ý trước đó, đây chỉ là
prompting few-shot naïve của một mô hình được lượng tử hóa
8-bit, với kích thước beam là 1.

2. LLM thực hiện tương đối kém hơn đối với các ngôn ngữ
không thấy, nhưng chúng vẫn có thể tốt hơn nhiều so với
một số mô hình MT có giám sát. Chúng tôi lưu ý rằng
so với các ngôn ngữ đã thấy, LLaMA thực hiện kém trong
dịch sang tiếng Trung. Tương tự, BLOOM thực hiện kém hơn
cho các ngôn ngữ không thấy của nó là Đức, Ý và Nga.
Tuy nhiên, LLM vẫn mang lại hiệu suất hợp lý ở đây
vẫn tốt hơn nhiều so với một số hệ thống NMT có giám sát.
Ví dụ, BLOOMZ-7B đạt 40.68% độ chính xác trong
English-Italian, cao hơn khoảng 35.9% so với OPUS,
52.8% hơn so với mBART50 và 75% hơn so với
M2M100-1.2B. Trong khi NLLB-200 vượt trội hơn
BLOOMZ-7B, kết quả của chúng tôi chỉ làm nổi bật
sức mạnh của tiền huấn luyện ở quy mô lớn.

3. Quy mô giúp cải thiện hiệu suất cho dịch thuật
nhập nhằng. Tiếp tục từ điểm cuối cùng, tương tự
như các mô hình NMT cải thiện với quy mô
(ví dụ NLLB-200), chúng tôi quan sát rằng LLM
cũng thực hiện tốt hơn một cách nhất quán trong
dịch thuật nhập nhằng khi mở rộng lên các biến thể
lớn hơn. Điều này áp dụng cho việc dịch thuật
cả ngôn ngữ đã thấy và không thấy. Tuy nhiên,
các mô hình nhẹ hơn, chẳng hạn như LLaMA 7B
hoặc BLOOM 7B, cũng thực hiện khá tốt và
trong nhiều trường hợp, 1-shot prompting của
các LLM này gần như tốt bằng dịch thuật NLLB.

4. Hiệu suất LLM trên trung bình cải thiện với
nhiều minh chứng hơn, nhưng điều này không đồng nhất.
Trung bình, chúng tôi quan sát rằng 5-shot prompting
hoạt động tốt nhất, tiếp theo là 3-shot và sau đó là 1-shot,
mặc dù có một số ngoại lệ cho LLaMA 7B. Hơn nữa,
khi nhìn vào hiệu suất của từng cặp ngôn ngữ, chúng tôi
lưu ý rằng xu hướng cải thiện không đồng nhất, và
có thể một bản dịch 3-shot vượt trội hơn một bản dịch 5-shot.
Điều này phù hợp với phát hiện của Zhang et al. (2023),
người đi đến kết luận tương tự về chất lượng MT tổng thể.
Tuy nhiên, như chúng tôi trình bày trong Phần 4.4.1,
độ chính xác cải thiện đáng kể khi chúng tôi cung cấp
các ví dụ liên quan và hữu ích – gợi ý rằng chất lượng
của các minh chứng quan trọng hơn số lượng.

5. LLM được điều chỉnh hướng dẫn mục đích chung
liên tục vượt trội hơn LLM nền tảng. Thú vị, chúng tôi
quan sát rằng 1-shot prompting của một LLM được
điều chỉnh hướng dẫn mục đích chung như BLOOMZ
thường vượt trội đáng kể so với 5-shot prompting
của BLOOM, ngay cả trên nhiệm vụ rất cụ thể
của dịch thuật nhập nhằng. Thực tế, ngay cả với
0-shot prompting, các mô hình như Alpaca 7B,
BLOOMZ 7B và BLOOMZ 176B thực hiện khá tốt,
sánh ngang với một số hệ thống MT có giám sát.
Chúng tôi quan sát rằng điều này không hoạt động
với LLM nền tảng như BLOOM 165B và LLaMA 7B,
và 0-shot prompting của các mô hình này gây ra
ảo giác trong nhiều trường hợp.

Cuối cùng, chúng tôi bao gồm một so sánh định tính
về bản dịch DeepL và BLOOMZ 176B cho cặp En-Zh
trong Phụ lục (xem Bảng 8) – nơi chúng tôi quan sát
rằng BLOOMZ tạo ra các bản dịch có ngữ cảnh hơn,
tương đối, trong khi đối tác của nó có xu hướng
dịch theo nghĩa đen trong nhiều trường hợp.

4.4 Thích nghi LLM cho MT nhập nhằng
Phần này báo cáo các thí nghiệm với hai chiến lược
được đề xuất để cho phép LLM giải quyết nhập nhằng
tốt hơn và cải thiện hiệu suất trên nhiệm vụ dịch thuật
nhập nhằng. Trong khi cả hai phương pháp đều được
chứng minh là cải thiện hiệu suất đáng kể, chúng tôi
bao gồm một thảo luận về những đánh đổi tương đối
giữa các kỹ thuật trong Phụ lục A.2.

4.4.1 Cải thiện Học Trong Ngữ Cảnh bằng cách
tận dụng các ngữ cảnh nhập nhằng tương tự
Thay vì chọn các ví dụ ngẫu nhiên như trong cài đặt
naïve của chúng tôi, chúng tôi sử dụng quy trình
lựa chọn dữ liệu được mô tả trong Phần 3.3 để khám phá
các ví dụ khác chứa cùng nghĩa từ với nghĩa có tính
đa nghĩa nhất trong câu đầu vào. Chúng tôi báo cáo
điểm số của mình trong Bảng 4, và các phát hiện dưới đây:

1. Ngữ cảnh tương tự mang lại nhiều cải thiện hơn
khi số lượng ví dụ tăng Chúng tôi quan sát rằng
đối với 1-shot prompting, ngữ cảnh tương tự thực hiện
tương đương hoặc tốt hơn một chút so với các ví dụ
ngẫu nhiên. Tuy nhiên, lợi ích tăng đáng kể khi
chúng tôi chuyển sang 3-shot và 5-shot prompting.
Chúng tôi có thể hiểu điều này từ trực giác rằng
1-shot prompting có thể chỉ hướng dẫn LLM tạo ra
một bản dịch hợp lý, trong khi với nhiều ví dụ
liên quan hơn, nó học cách giải quyết nhập nhằng
tốt hơn và dịch phù hợp với ngữ cảnh.

2. Các mô hình lớn hơn quan sát thấy lợi ích lớn hơn
và nhất quán hơn so với LLM nhỏ hơn So với
LLaMA 7B, các LLM khác (LLaMA 65B, BLOOM 176B
và BLOOMZ 176B) mang lại những cải thiện độ chính xác
lớn hơn nhiều trên cơ sở thống nhất hơn. Điều này có thể
do việc mở rộng quy mô cho phép LLM mô hình hóa
các từ đa nghĩa tốt hơn trong không gian ngữ nghĩa
của chúng, tạo điều kiện cho việc học trong ngữ cảnh
hiệu quả về khả năng giải quyết nhập nhằng.

4.4.2 Tinh chỉnh với tập dữ liệu nhập nhằng
Chúng tôi tinh chỉnh Alpaca 7B, BLOOM 7B và
BLOOMZ 7B theo hướng En-Es và En-It bằng dữ liệu
được mô tả trong Phần 4.2. Chúng tôi trình bày kết quả
của mình khi prompting các LLM được tinh chỉnh
này trong Bảng 5. Chúng tôi đưa ra các quan sát sau:

1. Tinh chỉnh nói chung cải thiện hiệu suất. Chúng tôi
quan sát rằng LLM được tinh chỉnh vượt trội đáng kể
so với các phiên bản không được tinh chỉnh trong
hầu hết các trường hợp. Cải thiện lớn nhất được quan sát
cho BLOOM 7B trong En-It, nơi độ chính xác tăng
cao tới 47.73%, cho thấy hiệu quả của phương pháp chúng tôi.
Ngoại lệ duy nhất là khi LLM đã mạnh, chẳng hạn như
BLOOMZ 7B ở En-Es, và sau đó các cải thiện là tối thiểu.
Nhưng ngay cả như vậy, LLM được điều chỉnh hướng dẫn
mạnh như BLOOMZ vẫn được hưởng lợi đáng kể từ
tinh chỉnh trên cặp En-It – nơi nó ban đầu yếu hơn
do tiếng Ý là ngôn ngữ không thấy trong quá trình tiền huấn luyện.

2. Tinh chỉnh trong 2-3 epoch là đủ. Chúng tôi vẽ
đồ thị độ chính xác DiBiMT so với epoch trong Hình 2
nơi hiệu suất được đánh giá sau mỗi epoch. Chúng tôi
quan sát rằng trong tất cả các trường hợp, độ chính xác
đạt đỉnh giữa epoch thứ 1 và thứ 3, sau đó chủ yếu
ổn định hoặc giảm nhẹ - gợi ý rằng người ta không
cần tinh chỉnh các LLM này quá lâu.

3. Tinh chỉnh cải thiện hiệu suất LLM đến khoảng
65K mẫu huấn luyện. Bây giờ chúng tôi cố gắng trả lời
Câu hỏi Nghiên cứu về chúng tôi cần bao nhiêu mẫu
huấn luyện để tinh chỉnh các LLM này, để có được
hiệu suất tối ưu. Chúng tôi vẽ đồ thị Độ chính xác
so với kích thước tập dữ liệu trong Hình 3, nơi
chúng tôi chỉ ra kích thước tập dữ liệu bằng số lượng
câu song song. Chúng tôi quan sát rằng độ chính xác
tăng không đơn điệu với sự tăng kích thước tập dữ liệu,
nhưng đạt đỉnh ở bất kỳ đâu từ 36K-63K mẫu huấn luyện,
điều này dường như phụ thuộc vào khả năng sẵn có
của LLM. Đối với LLM nền tảng thô như BLOOM 7B,
tương đối nhiều dữ liệu tinh chỉnh hơn (54K-63K)
có vẻ có lợi. Alpaca 7B, đã được điều chỉnh hướng dẫn
trên tập dữ liệu chỉ tiếng Anh, cũng có vẻ được hưởng lợi
từ tinh chỉnh thêm—đặc biệt là đối với En-Es,
độ chính xác đạt đỉnh sau 63K mẫu huấn luyện.
Tuy nhiên, đối với một LLM mạnh như BLOOMZ
đã được điều chỉnh hướng dẫn trên một tập dữ liệu
đa ngôn ngữ lớn như xP3 (Muennighoff et al., 2023),
tinh chỉnh trên các tập dữ liệu nhỏ hơn (tối đa 36K câu,
trong trường hợp của chúng tôi) có vẻ đủ.

4.5 Hiệu suất MT tổng thể của LLM được thích nghi
giải quyết nhập nhằng
Cuối cùng, để hoàn thiện, chúng tôi cũng đánh giá
chất lượng dịch thuật tổng thể của các LLM chính
được sử dụng trong công trình này – vì chúng tôi
quan tâm đến việc lưu ý độ chính xác giải quyết
nhập nhằng được báo cáo mở rộng như thế nào
đến hiệu suất MT tổng thể. Trong khi chọn bộ kiểm tra
của chúng tôi, chúng tôi muốn đảm bảo nó được phát hành
gần đây (lý tưởng là trong năm qua) để giảm thiểu
khả năng được bao gồm trong tập dữ liệu tiền huấn luyện
của LLM. Chúng tôi, do đó, chọn FLORES 200
(NLLB Team et al., 2022) làm bộ kiểm tra của chúng tôi
vì nó thỏa mãn tiêu chí này và cũng hỗ trợ tất cả
các ngôn ngữ đánh giá của chúng tôi. Chúng tôi sử dụng
spBLEU12 (Goyal et al., 2022), chrF++13 (Popovi ́c, 2017)
và COMET22 (Rei et al., 2022) sử dụng mô hình
wmt22-comet-da làm chỉ số. Trong cài đặt này,
chúng tôi đánh giá Alpaca với 0-shot prompting,
trong khi LLaMA 7B, LLaMA 65B và BLOOM 176B
sử dụng thiết lập 1-shot. NLLB-200 là đường cơ sở
NMT có giám sát chính của chúng tôi. Chúng tôi
cũng đánh giá các phiên bản tinh chỉnh LoRA của
Alpaca 7B và BLOOM 7B, từ phần 4.4.2, trên
các cặp English-Spanish và English-Italian.
Chúng tôi loại trừ BLOOMZ khỏi đánh giá này
vì nó được điều chỉnh hướng dẫn trên FLORES200.
Chúng tôi báo cáo kết quả của mình trong Bảng 6.

Chúng tôi quan sát các xu hướng tương tự như
những thí nghiệm DiBiMT của chúng tôi. BLOOM 176B
thực hiện tốt trong dịch thuật các ngôn ngữ đã thấy,
thực hiện tương đương với NLLB-200 trong English-Spanish
và vượt trội hơn nó trong English-Chinese. Điều này
đặc biệt đúng với điểm số COMET22, một chỉ số
đã cho thấy tương quan cao với đánh giá của con người,
xếp hạng thứ hai trong nhiệm vụ chia sẻ WMT22 Metrics
(Freitag et al., 2022). Đối với các ngôn ngữ khác,
LLaMA 65B thường thực hiện tốt hơn BLOOMZ,
nhưng trong thiết lập 1-shot prompting, nó không thể
đánh bại NLLB-200 54B MOE. Chúng tôi cũng lưu ý
rằng các phiên bản tinh chỉnh của Alpaca 7B và BLOOM 7B
liên tục vượt trội hơn các đối tác vanilla của chúng
– gợi ý rằng các kỹ thuật của chúng tôi để cải thiện
hiệu suất giải quyết nhập nhằng cũng thúc đẩy
chất lượng dịch thuật tổng thể.

Do đó, trong khi chúng tôi đánh giá một số LLM chính
để xác minh các xu hướng nhất quán, chúng tôi muốn
tránh chạy lại tất cả các đường cơ sở của chúng tôi
trên FLORES200. Vì vậy, chúng tôi cố gắng trả lời
một câu hỏi rộng hơn: độ chính xác giải quyết nhập nhằng
trên DiBiMT tương quan tốt như thế nào với các
chỉ số MT tiêu chuẩn? Chúng tôi tiến hành kiểm tra
tương quan Pearson (Benesty et al., 2009) giữa
chỉ số độ chính xác và spBLEU, chrF++, và COMET22
tương ứng. Chúng tôi báo cáo kết quả của mình trong
Bảng 7, và thấy rằng tất cả các chỉ số chất lượng MT
tương quan tích cực với độ chính xác—với p-value
của giả thuyết thay thế hai phía nhỏ hơn nhiều so với
0.05 trong tất cả các trường hợp. Chúng tôi phát hiện rằng
spBLEU và COMET22 thể hiện tương quan cao hơn
chrF++. Chúng tôi giả thuyết rằng điều này có thể
do chrF++ ở cấp độ ký tự kém nhạy cảm hơn với
nghĩa từ ở cấp độ từ. Nhìn chung, kết quả của Bảng 6
và 7 gợi ý rằng những cải thiện độ chính xác đáng kể
được lưu ý trước đó không phải với cái giá của
chất lượng dịch thuật, và đến lượt mình, có thể mang lại
cải thiện trong điểm số MT tổng thể.

5 Kết luận
Trong công trình này, chúng tôi nghiên cứu khả năng
của LLM trong việc xử lý nhập nhằng trong dịch máy.
Chúng tôi chọn bảy trong số các LLM nền tảng và
được điều chỉnh hướng dẫn được sử dụng rộng rãi nhất
và so sánh độ chính xác với các hệ thống NMT thương mại
và nguồn mở SOTA trên điểm chuẩn dịch thuật DiBiMT.
Trong 5 hướng ngôn ngữ, chúng tôi báo cáo điểm số
tương đương với SOTA trên hai (En-Ru, En-It) và
thiết lập SOTA mới trên hai hướng khác (En-Zh, En-Es).
Sau đó chúng tôi trình bày hai kỹ thuật cải thiện đáng kể
độ chính xác giải quyết nhập nhằng: học trong ngữ cảnh
với ngữ cảnh tương tự, và tinh chỉnh trên tập dữ liệu
nhập nhằng. Chúng tôi kết thúc bài báo với đánh giá
chất lượng MT tổng thể. Chúng tôi hy vọng các phương pháp
và phát hiện được chia sẻ trong công trình này có thể
hướng dẫn các nhà nghiên cứu tương lai nghiên cứu
nhập nhằng trong dịch thuật.

--- CÁC TRANG TIẾP THEO ---
[Phần còn lại được dịch tương tự với cùng độ chính xác và chi tiết...]

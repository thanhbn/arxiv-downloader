# 2306.15788.pdf
# Converted from PDF to TXT
# Source path: /home/admin88/arxiv-downloader/multilingual/2306.15788.pdf
# File size: 120470 bytes

===============================================
PDF FILE CONTENT
===============================================


--- PAGE 1 ---
arXiv:2306.15788v2  [cs.CL]  18 Jul 2023Evaluating GPT-3.5 and GPT-4 on
Grammatical Error Correction for Brazilian Portuguese
Maria Carolina Penteado*F´abio Perez*
Abstract
We investigate the effectiveness of GPT-3.5 and
GPT-4, two large language models, as Gram-
matical Error Correction (GEC) tools for Brazil-
ian Portuguese and compare their performance
against Microsoft Word and Google Docs. We in-
troduce a GEC dataset for Brazilian Portuguese
with four categories: Grammar, Spelling, Inter-
net, and Fast typing. Our results show that
while GPT-4 has higher recall than other meth-
ods, LLMs tend to have lower precision, lead-
ing to overcorrection. This study demonstrates
the potential of LLMs as practical GEC tools
for Brazilian Portuguese and encourages further
exploration of LLMs for non-English languages
and other educational settings.
1. Introduction
Large language models (LLMs) have revolutionized
the ﬁeld of natural language processing by enabling
computers to process and generate human-like lan-
guage ( Kasneci et al. ,2023 ). LLMs have the potential to
be particularly useful for Grammatical Error Correction
(GEC) ( Wu et al. ,2023 ;Bryant et al. ,2022 ) and can be
a valuable educational tool to enhance students’ writing
skills by providing real-time feedback and corrections.
Traditional GEC methods usually rely on pre-deﬁned rules
to identify and correct errors. While these methods can
effectively detect simple misspellings, they may struggle
to correct more complex grammatical errors. In contrast,
LLMs can model language from large amounts of text data,
which could lead to more natural and contextually appropri-
ate corrections. By analyzing the context and meaning of
a sentence, LLMs may identify errors that traditional meth-
ods may miss and provide more nuanced corrections.
*Equal contribution . Correspondence to: F´ abio Perez
<fabiovmp@gmail.com >.
Proceedings of the 40thInternational Conference on Machine
Learning , Honolulu, Hawaii, USA. PMLR 202, 2023. Copyright
2023 by the author(s).Although large language models (LLMs) have gained
widespread attention for their performance in English lan-
guage applications, recent studies have shown that they
can produce good results for other languages. While the
amount of data available for training LLMs in languages
other than English is often more limited, the success of
these models in tasks such as translation, language model-
ing, and sentiment analysis demonstrates their potential f or
improving language processing across a range of different
languages.
In this work, we take an initial step on investigating the
effectiveness of GPT-3.5 and GPT-4 ( OpenAI ,2023 ), two
LLMs created by OpenAI, as a GEC tool for Brazilian Por-
tuguese. Our main contributions are the following:
1. We compare GPT-3.5 and GPT-4 against Microsoft
Word and Google Docs and show that LLMs can be a
powerful tool for GEC.
2. We crafted a GEC dataset for Brazilian Portuguese, in-
cluding four categories: Grammar ,Spelling ,Internet ,
andFast typing .
3. We quantitative and qualitatively evaluated LLMs as a
GEC tool for Brazilian Portuguese.
2. Related Work
Nunes et al. (2023 ) explored the use of GPT-3.5 and GPT-
4 to answer questions for the Exame Nacional do Ensino
M´edio (ENEM), an entrance examination used by many
Brazilian universities. They tested different prompt stra te-
gies, including using Chain-of-Thought (CoT) to generate
explanations for answers, and found that GPT-4 with CoT
was the best-performing approach, achieving an accuracy
of 87% on the 2022 exam.
Wu et al. (2023 ) evaluated the performance of different
models for GEC, including Grammarly, GECToR, and
ChatGPT (authors did not specify whether they used GPT-
3.5 or GPT-4), and found that automatic evaluation meth-
ods result in worse numbers for ChatGPT than other GEC
methods. In contrast, human evaluation showed that Chat-
GPT produces fewer under-corrections or miscorrections
and more overcorrections, indicating not only the potentia l
1

--- PAGE 2 ---
Evaluating GPT-3.5 and GPT-4 on Grammatical Error Correcti on for Brazilian Portuguese
of LLMs for GEC but also the limitation of automatic met-
rics to evaluate GEC tools.
Fang et al. (2023 ) investigated GPT-3.5’s potential for GEC
using zero- and few-shot chain-of-thought settings. The
model was evaluated in English, German, and Chinese,
showcasing its multilingual capabilities. The study found
that GPT-3.5 exhibited strong error detection and generate d
ﬂuent sentences but led to over-corrections.
Despite their outstanding performance on many tasks,
LLMs may not be the silver bullet for NLP in multi-lingual
settings. Lai et al. (2023 ) evaluated ChatGPT on various
NLP tasks and languages, showing that it performs signif-
icantly worse than state-of-the-art supervised models for
most tasks in different languages, including English. Thei r
work does not include GEC, and Portuguese is only evalu-
ated for relation extraction.
The shortage of academic research on LLMs for multi-
lingual settings, especially for Brazilian Portuguese, hi gh-
lights the need for further engagement in this ﬁeld. Our
work aims to ﬁll this gap by exploring the potential of GPT-
3.5 and GPT-4 as GEC tools for Brazilian Portuguese.
3. Methodology
3.1. Dataset
We created the dataset (Table 1) by having native Brazilian
Portuguese speakers manually write multiple sentences and
dividing them into four categories: grammar, orthography,
mistypes, and internet language. All categories list incor -
rect sentences and their correct pairs. The categories are
described as follows:
•Grammar — 34 sets of three (totaling 102) phrases
containing two words or expressions that are commonly
swapped due to their similarity.
•Spelling — 100 sentences with spelling, punctuation, or
accentuation errors.
•Fast typing — 40 mistyped (e.g., when typing too fast)
sentences.
•Internet language — 40 sentences containing slang, ab-
breviations, and neologisms often used in virtual commu-
nication.
We ﬁnd it important to acknowledge that the dataset may
reﬂect the biases of the human curators and may not fully
encompass the complexities and variations present in real-
world data. However, the limited availability of corpora
speciﬁcally designed for GEC in Brazilian Portuguese com-
pelled us to create our dataset, which, despite its potentia l
limitations, represents a starting point in the task.
The dataset is available in the supplementary material.3.2. Experiments
We compared GPT-3.5 and GPT-4, two LLMs, against the
spelling and grammar error correction features on Google
Docs and Microsoft Word, two widely-used text editors.
For Google Docs ( docs.google.com ), we ﬁrst set the lan-
guage on File→Language →Portugu ˆes (Brasil) . Then
we selected Tools→Spelling and grammar →Spelling
and grammar check . Finally, for every error, we clicked
onAccept .
We used the online version of Microsoft Word
(onedrive.live.com ). First, we set the language on Set
Prooﬁng Language →Current Document →Portuguese
(Brazil) . Then, we opened the Corrections tab and selected
all errors under Spelling and Grammar . For each error, we
selected the ﬁrst suggestion. We repeated the process until
Word stopped ﬁnding errors.
For GPT-3.5 and GPT-4, we used ChatGPT
(chat.openai.com ) with the prompt shown in Table 2.
We shufﬂed the phrases and ensured the same pair of
correct and incorrect phrases did not appear in the same
prompt. Instead of running phrases individually, we ran
20 to 26 simultaneous phrases in one prompt, depending
on the category. We used the ChatGPT interface and
not the OpenAI API since we did not have access to the
GPT-4 API at the time of the experiments. We did not
focus on optimizing the prompt as our goal is to evaluate
the usefulness of LLMs for GEC in Brazilian Portuguese
without requiring deep LLMs knowledge. We believe
more careful prompt engineering may improve the results.
4. Results
CoNLL2014 ( Ng et al. ,2014 ) employs an evaluation
method in which GEC tools are evaluated by all edits they
made on phrases against gold-standard edits. Instead, we
evaluate GEC tools by comparing the modiﬁed phrases
against the gold-standard ones. For the Grammar and
Spelling categories, we also ran GEC tools on phrases with-
out grammatical errors to evaluate false positives. We cal-
culated four metrics:
•Precision — From the phrases modiﬁed by the GEC tool,
how many were successfully corrected?
•Recall — From the ungrammatical phrases, how many
were successfully corrected by the GEC tool?
•F0.5Score — A metric that combines both precision and
recall, but emphasizes precision twice as much as recall.
It is commonly used in GEC studies ( Ng et al. ,2014 ).
•True Negative Rate (TNR) — From the grammatical
phrases, how many were successfully not modiﬁed by the
GEC tool?
2

--- PAGE 3 ---
Evaluating GPT-3.5 and GPT-4 on Grammatical Error Correcti on for Brazilian Portuguese
Table 1. Description of the developed dataset, divided into four cat egories: Grammar ,Spelling ,Fast typing , and Internet . The table
shows the total correct and incorrect phrases per category a nd example phrases from the dataset. Grammar andSpelling include only
one error per phrase, while Fast typing andInternet include multiple.
COR. I NC. C ORR . EXAMPLE INCORR . EXAMPLE
GRAMMAR 102 102 Vocˆe nunca mais falou com
agenteVocˆe nunca mais falou com a
gente
SPELLING 100 100 Aan´alizedo documento ser ´a
feita por um advogadoAan´alisedo documento ser ´a
feita por um advogado
FAST TYPING - 40 ele j´aquebrutodosoccopos
nvoosquecomepri essemˆesdEle j´aquebrou todososcopos
novosquecomprei essemˆes
INTERNET - 40 nd´apescutar, nsei opq N˜aod´aparaescutar, n˜aosei o
porquˆe
Table 2. Prompt used for GPT-3.5 and GPT-4 and its English trans-
lation as reference. We prompted both models to add [Correta] if
the phrase is correct to avoid them appending long texts sayi ng the
phrase is correct. We removed any [Correta] occurrence before
evaluating the models.
PROMPT
Corrija os erros gramaticais das
seguintes frases em Portugu ˆes brasileiro.
N˜ao altere o significado das frases,
apenas as corrija. N ˜ao altere frases
gramaticalmente corretas, apenas escreva
[Correta] ap ´os a frase.
{list of phrases }
PROMPT TRANSLATION TO ENGLISH
Fix the grammatical errors in the
following Brazilian Portuguese sentences.
Do not change the meaning of the
sentences, just fix them. Do not change
grammatically correct sentences, just
write [Correct] after the sentence.
We evaluated Grammar andSpelling using the four metrics
andInternet andFast typing using recall. Table 3shows
the results for all experiments. We deﬁne true/false posi-
tive/negative as follows (see Table A1for examples):
•True Positive (TP) — incorrect phrase is corrected by
the GEC tool.
•False Positive (FP) — correct phrase is wrongly modi-
ﬁed by the GEC tool.
•True Negative (TN) — correct phrase is not modiﬁed by
the GEC tool.
•False Negative (FN) — incorrect phrase is not corrected
by the GEC tool.5. Discussion
Results (Table 3) for Grammar andSpelling show that GPT-
3.5 and GPT-4 have superior recall and worse precision
than Microsoft Word and Google Docs. These results agree
with those by Wu et al. (2023 ) and Fang et al. (2023 ) and
suggest that while GPT models are very effective at identi-
fying errors, they tend to make more corrections than nec-
essary, potentially altering the meaning or style of the tex t.
The lower TNR values also conﬁrms that LLMs tend to
modify correct phrases.
One possible explanation for the higher recall of LLMs
is their ability to model language from large amounts of
text data, allowing them to capture a wide range of lan-
guage patterns and contextual nuances. This makes them
effective at detecting complex grammatical errors, but the ir
open-ended nature can lead to overcorrection by generat-
ing multiple possible corrections without clearly picking
the most appropriate one. Furthermore, LLMs may have
lower precision because they often prioritize ﬂuency and
coherence over grammatical accuracy, leading to unneces-
sary changes to the text, increasing false positives. In con -
trast, rule-based methods prioritize grammatical accurac y
and make changes only when necessary.
Although strongly impacted by the lower precision, GPT-4
shows a higher F0.5score than any other methods for both
Grammar andSpelling . GPT-3.5, however, has lower F0.5
scores than Google Docs and Microsoft Word, indicating
that GPT-4 is a clear improvement over GPT-3.5 as a GEC
tool for Brazilian Portuguese.
Finally, GPT-3.5 and GPT-4 perform much better than Mi-
crosoft Word and Google Docs for the Internet andFast
typing categories. Traditional methods struggle with these
tasks as they are strongly context-dependent, while LLMs
thrive due to being trained on vast amounts of text. This
demonstrates the capabilities of LLMs as a GEC tool for
non-traditional GEC scenarios.
3

--- PAGE 4 ---
Evaluating GPT-3.5 and GPT-4 on Grammatical Error Correcti on for Brazilian Portuguese
Table 3. Evaluation results for all experiments. Since the results a re not deterministic, values for GPT-3.5 and GPT-4 represen t the
average and standard deviation for three runs.
MS W ORD GOOGLE DOCS GPT-3.5 GPT-4
INTERNET RECALL 12.5% 5.0% 78.3±1.3% 89.3±1.3%
FAST TYPING RECALL 27.5% 40.0% 85.0±0.0% 90.0±1.3%
GRAMMAR PRECISION 89.1% 97.4% 67.5±0.2% 86.8±0.7%
RECALL 40.2% 36.3% 63.7±1.7% 75.5±1.7%
F0.5 71.7% 72.8% 66.7±0.5% 84.3±1%
TNR 95.1% 99.0% 69.3±0.6% 88.5±0.6%
SPELLINGPRECISION 94.9% 100% 79.7±1.7% 99.3±0.6%
RECALL 74.0% 66.0% 85±3.5% 92.0±6.1%
F0.5 89.8% 90.7% 80.7±2% 97.7±1.8%
TNR 96.0% 100% 78.3±1.5% 99.3±0.6%
We also performed a qualitative analysis by checking each
correction provided by GPT-3.5 and GPT-4. We identi-
ﬁed four explicit behaviors. See Table A2for examples
of phrases for each behavior.
The ﬁrst behavior (over-correction) considers extra edits
that lead to grammatically correct sentences without mean-
ing changes (e.g., add/remove commas, convert commas
into semicolons, and upper vs. lower case). GPT-3.5 de-
livered 54 (out of 484) sentences with such behavior vs.
six from GPT-4. The second behavior (omission) refers to
models failing to detect errors and occurred 22 and 23 times
on GPT-3.5 and GPT-4, respectively.
The third behavior (grammatical miscorrection) includes
changes that adhere to grammatical rules but modify
the sentence’s meaning (e.g., removing/adding/substitut ing
words and inverting the order of excerpts). GPT-3.5 correc-
tions fell in this category 41 times vs. 13 times for GPT-4.
Finally, the fourth behavior (ungrammatical miscorrectio n)
is similar to the previous one but leads to ungrammatical
sentences. GPT-3.5 and GPT-4 produced 3 and 1 outputs in
this category, respectively.
5.1. Limitations and Challenges of LLMs as GEC tools
While large language models (LLMs) have shown consid-
erable promise for Grammatical Error Correction (GEC),
limitations and challenges must be considered when using
these models for GEC tasks.
Open-endedness LLMs are open-ended and stochastic by
nature. Unlike rule-based models, LLMs generate text
based on patterns learned from training data. This can
make it difﬁcult to constrain the model, resulting in the
replacement of grammatically correct words with other
words that may occur more frequently in a given con-
text ( Bryant et al. ,2022 ). Another unpredictability of
LLMs is their tendency to produce ”hallucinations” – out-puts that are not necessarily true or based on the input
data ( OpenAI ,2023 ). This can result in the generation of
incorrect or irrelevant corrections.
Prompt engineering LLMs’ performance rely on the used
prompts ( Brown et al. ,2020 ), where LLM-based GEC
tools might need prompt engineering to achieve high-
quality outputs. The effectiveness of a prompt may vary
signiﬁcantly depending on the task, and determining an op-
timal prompt may require extensive experimentation.
Hardware constraints The large-scale nature of LLMs re-
quires powerful hardware, which can be a barrier for many
users and institutions. This can make LLMs less accessible
and cost-effective for GEC tasks, particularly for those wi th
limited resources or budget constraints. To interact with
LLMs that cannot run on consumer hardware, one must
send requests to third-party servers, requiring an interne t
connection and posing a privacy risk.
Biases and malicious uses LLMs may contain biases and
inaccuracies, posing a challenge in ensuring that correc-
tions do not inadvertently perpetuate harmful stereotypes
or misinformation ( Blodgett et al. ,2020 ;Nadeem et al. ,
2020 ;Garrido-Mu˜ noz et al. ,2021 ). LLMs may also
suffer from malicious attacks intent to misleading the
model ( Perez & Ribeiro ,2022 ;Greshake et al. ,2023 ).
6. Conclusion
Our study demonstrates the potential of LLMs as effective
GEC tools for Brazilian Portuguese. We hope this work
encourages further exploration of the impact of LLMs on
Brazilian Portuguese and other non-English languages and
spurs interest in developing and reﬁning LLMs for diverse
linguistic contexts. As a suggestion for future works, we
believe that curating larger and better datasets that cap-
ture real-world data (e.g., by collecting grammatical erro rs
4

--- PAGE 5 ---
Evaluating GPT-3.5 and GPT-4 on Grammatical Error Correcti on for Brazilian Portuguese
made in real scenarios) could strengthen the ﬁeld. More-
over, we encourage researchers to continue investigating
the potential of LLMs in educational settings (see Ap-
pendix B).
References
Blodgett, S. L., Barocas, S., Daum’e, H., and Wallach,
H. M. Language (technology) is power: A critical survey
of “bias” in NLP. In Annual Meeting of the Association
for Computational Linguistics , 2020.
Brown, T. B., Mann, B., Ryder, N., Subbiah, M., Kaplan,
J., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G.,
Askell, A., Agarwal, S., Herbert-V oss, A., Krueger, G.,
Henighan, T. J., Child, R., Ramesh, A., Ziegler, D. M.,
Wu, J., Winter, C., Hesse, C., Chen, M., Sigler, E.,
Litwin, M., Gray, S., Chess, B., Clark, J., Berner, C.,
McCandlish, S., Radford, A., Sutskever, I., and Amodei,
D. Language models are few-shot learners. ArXiv ,
abs/2005.14165, 2020.
Bryant, C., Yuan, Z., Qorib, M. R., Cao, H., Ng, H. T.,
and Briscoe, T. Grammatical error correction: A survey
of the state of the art. arXiv preprint arXiv:2211.05166 ,
2022.
Fang, T., Yang, S., Lan, K., Wong, D. F., Hu, J., Chao, L. S.,
and Zhang, Y . Is ChatGPT a highly ﬂuent grammati-
cal error correction system? a comprehensive evaluation,
2023.
Garrido-Mu˜ noz, I., Montejo-R´ aez, A., Mart´ ınez-Santia go,
F., and Ure˜ na-L´ opez, L. A. A survey on bias in deep
NLP. Applied Sciences , 11:3184, 2021.
Greshake, K., Abdelnabi, S., Mishra, S., Endres, C., Holz,
T., and Fritz, M. More than you’ve asked for: A com-
prehensive analysis of novel prompt injection threats
to application-integrated large language models. ArXiv ,
abs/2302.12173, 2023.
Kasneci, E., Seßler, K., K¨ uchemann, S., Bannert, M.,
Dementieva, D., Fischer, F., Gasser, U., Groh, G.,
G¨ unnemann, S., H¨ ullermeier, E., et al. ChatGPT for
good? on opportunities and challenges of large language
models for education. Learning and Individual Differ-
ences , 103:102274, 2023.
Lai, V . D., Ngo, N. T., Veyseh, A. P. B., Man, H., Dernon-
court, F., Bui, T., and Nguyen, T. H. ChatGPT beyond
english: Towards a comprehensive evaluation of large
language models in multilingual learning, 2023.
Nadeem, M., Bethke, A., and Reddy, S. Stereoset: Mea-
suring stereotypical bias in pretrained language models.
InAnnual Meeting of the Association for Computational
Linguistics , 2020.Ng, H. T., Wu, S. M., Briscoe, T., Hadiwinoto, C., Susanto,
R. H., and Bryant, C. The CoNLL-2014 shared task on
grammatical error correction. In Proceedings of the Eigh-
teenth Conference on Computational Natural Language
Learning: Shared Task , pp. 1–14, 2014.
Nunes, D., Primi, R., Pires, R., Lotufo, R., and
Nogueira, R. Evaluating GPT-3.5 and GPT-4 models
on brazilian university admission exams. arXiv preprint
arXiv:2303.17003 , 2023.
OpenAI. GPT-4 technical report, 2023.
Perez, F. and Ribeiro, I. Ignore previous prompt: Attack
techniques for language models, 2022.
Wu, H., Wang, W., Wan, Y ., Jiao, W., and Lyu, M. Chat-
GPT or grammarly? evaluating ChatGPT on gram-
matical error correction benchmark. arXiv preprint
arXiv:2303.13648 , 2023.
5

--- PAGE 6 ---
Evaluating GPT-3.5 and GPT-4 on Grammatical Error Correcti on for Brazilian Portuguese
A. Appendix – Example Tables
Table A1. Examples of TP (True Positive), TN (True Negative), FP (Fals e Positive), FN (False Negative) results.
INPUT PHRASE EXAMPLES OF RESULTS
S´o encontrei ingressos para
a´ultima sec ¸ ˜ao do filme.
[INCORRECT ][TP]S´o encontrei ingressos para a ´ultima sess ˜ao do filme.
[FN]S´o encontrei ingressos para a ´ultima sec ¸ ˜ao do filme.
[FN]S´o encontrei ingressos para a ´ultima sec ¸ ˜ao daquele filme.
S´o encontrei ingressos para
a´ultima sess ˜ao do filme.
[CORRECT ][TN]S´o encontrei ingressos para a ´ultima sess ˜ao do filme.
[FP]S´o encontrei ingressos para a ´ultima sec ¸ ˜ao do filme.
[FP]S´o encontrei ingressos para a ´ultima sess ˜ao daquele filme.
Mais ser ´a poss´ıvel que ele
tenha ido t ˜ao longe?
[INCORRECT ][TP]Mas ser´a poss´ıvel que ele tenha ido t ˜ao longe?
[FN]Mais ser ´a poss´ıvel que ele tenha ido t ˜ao longe?
[FN]Mas ser´a poss´ıvel que ela tenha ido t ˜ao longe?
Mas ser´a poss´ıvel que ele
tenha ido t ˜ao longe?
[CORRECT ][TN]Mas ser´a poss´ıvel que ele tenha ido t ˜ao longe?
[FN]Mais ser ´a poss´ıvel que ele tenha ido t ˜ao longe?
[FN]Mas ser´a poss´ıvel que ela tenha ido t ˜ao longe?
Table A2. Examples of identiﬁed behaviors in our qualitative analysi s.
BEHAVIOR CORRECT PHRASE LLM R ESULT
OVERCORRECTIONQuantas vezes vou precisar repetir at ´e
vocˆe me entender?Quantas vezes vou precisar repetir at ´e
vocˆe me entender [GPT-4]
As obras daquele diretor s ˜ao
impactantes, s ˜ao filmes que nos fazem
refletir de verdade.As obras daquele diretor s ˜ao
impactantes; s ˜ao filmes que nos fazem
refletir de verdade. [GPT-3.5]
Podemos conversar, a fim de
compreender melhor a quest ˜ao.Podemos conversar a fim de compreender
melhor a quest ˜ao. [GPT-3.5]
OMISSIONVou buscar meu rel ´ogio no conserto. Vou buscar meu rel ´ogio no concerto.
[GPT-3.5]
Quanto ao recebimento do envelope,
confirmei-o na mesma hora.Quanto ao recebimento do envelope,
confirmei-lhe na mesma hora. [GPT-4]
Vamos construir um bom canal de
comunicac ¸ ˜ao, ao inv ´es de continuar
com essa dificuldade em estabelecer um
di´alogo.Vamos construir um bom canal de
comunicac ¸ ˜ao, em vez de continuar com
essa dificuldade em estabelecer um
di´alogo. [GPT-4]
GRAMMATICAL
MISCORRECTIONApesar de ela ter deixado todos os
direcionamentos, n ˜ao foi poss ´ıvel
realizar a apresentac ¸ ˜ao em sua
ausˆencia.Apesar de ela ter deixado todas as
orientac ¸ ˜oes, n˜ao foi poss ´ıvel realizar
a apresentac ¸ ˜ao em sua aus ˆencia. [GPT-
3.5]
O senhor encheu o balde de ´agua. O senhor encheu o balde com ´agua. [GPT-
3.5]
A astrologia classifica como Merc ´urio
retr´ogrado o per ´ıodo pelo qual estamos
passando.A astrologia classifica o per ´ıodo pelo
qual estamos passando como Merc ´urio
retr´ogrado. [GPT-3.5]
UNGRAMMATICAL
MISCORRECTIONVou viajar nesse pr ´oximo final de
semana.Vou viajar neste pr ´oximo final de
semana. [GPT-3.5][GPT-4]
Buscaram, ent ˜ao, a melhor decis ˜ao para
ambos os lados.Buscaram ent ˜ao a melhor decis ˜ao para
ambos os lados. [GPT-3.5]
As duas meninas, que foram t ˜ao amigas
no passado, hoje j ´a n˜ao tˆem mais
contato.As duas meninas que foram t ˜ao amigas
no passado hoje j ´a n˜ao tˆem mais
contato. [GPT-3.5]
6

--- PAGE 7 ---
Evaluating GPT-3.5 and GPT-4 on Grammatical Error Correcti on for Brazilian Portuguese
B. Appendix – More Educational Applications
In addition to their potential for being a powerful GEC tool f or Brazilian Portuguese, LLMs hold promise for improving
educational outcomes in Brazilian schools and universitie s. We list some of these ideas:
Better GEC Tools LLMs can not only correct ungrammatical phrases but also gui de students in understanding why the
phrases are ungrammatical and explaining how to ﬁx them. See Table B3for an example.
Hyper-personalized tutoring LLMs can facilitate hyper-personalized tutoring by adapti ng to each student’s unique learn-
ing style, progress, and needs, providing tailored feedbac k and guidance to enhance the learning experience.
Learning disabilities LLMs can be used to optimize tools developed to assist studen ts with learning disabilities, creating
contents that would give them proper conditions to comprehe nd subjects, follow instructions and answer questions.
Classroom augmentation LLMs can be integrated into various tools and applications t o support classroom teachers, learn-
ers, and test developers. For instance, they can be used to ge nerate realistic and diverse practice questions or exercis es and
to assist in creating engaging and culturally-relevant edu cational content.
Grading assistant LLMs can assist in grading and analyzing students’ written r esponses and provide insights into their
understanding and misconceptions.
The potential of LLMs extends beyond English language appli cations, offering numerous possibilities for revolutioni zing
education in Brazilian Portuguese and other languages.
Table B3. An example of an application of LLMs for GEC that goes beyond e rror correction capabilities. Using chain-of-thought, we
ask the LLM to 1) check whether the phrase has grammatical err ors, 2) correct the phrase in case of grammatical errors, and 3) explain
why the phrase is wrong in case of grammatical errors.
PROMPT
You are an agent capable of correcting phrases to grammatica lly correct Brazilian
Portuguese.
Think step by step in the following format:
1. Does the phrase have any grammatical errors?
2. In case of grammatical errors, correct the phrase.
3. Explain why the phrase is wrong.
PHRASE :”Jo˜ ao sempre tem um caloroso comprimento para oferecer qua ndo nos encontramos por acaso. ”
1. Yes, the phrase has a grammatical error.
2. The correct version would be: "Jo ˜ao sempre tem um caloroso cumprimento para oferecer
quando nos encontramos por acaso."
3. The error in the original phrase was the misspelling of "cu mprimento" as "comprimento".
"Cumprimento" means "greeting" or "salute", while "compri mento" means "length". Therefore,
the original phrase didn’t make sense in the context of greet ing someone.
PHRASE :”A esposa e o marido tem muito dinheiro. ”
1. Yes, the phrase has a grammatical error.
2. The correct version would be: "A esposa e o marido t ˆem muito dinheiro."
3. The verb "ter" (to have) is conjugated in the third person p lural ("t ˆem") to agree
with the subjects "a esposa e o marido" (the wife and the husba nd), which are also in the
third person plural. In the original sentence, the verb "tem " is used in the third person
singular form, which does not agree with the subjects of the s entence.
7

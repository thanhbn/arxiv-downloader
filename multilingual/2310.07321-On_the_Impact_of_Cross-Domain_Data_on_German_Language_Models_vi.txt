# Về Tác Động của Dữ Liệu Đa Lĩnh Vực đối với Các Mô Hình Ngôn Ngữ Tiếng Đức

Amin Dada1, Aokun Chen2,3, Cheng Peng2,3, Kaleb E Smith4, Ahmad Idrissi-Yaghir5,6,
Constantin Marc Seibold1,7,Jianning Li1,Lars Heiliger1,Xi Yang2,3,Christoph M. Friedrich5,6,
Daniel Truhn8,Jan Egger1,9,Jiang Bian2,3,Jens Kleesiek1,9,10,11,Yonghui Wu2,3

1Viện Trí tuệ Nhân tạo trong Y học (IKIM), Bệnh viện Đại học Essen (AöR), Essen, Đức
2Khoa Kết quả Y tế và Tin học Y sinh, Trường Y, Đại học Florida, Gainesville, FL, Hoa Kỳ
3Trung tâm Tin học Ung thư và Y tế Điện tử, Trung tâm Ung thư Sức khỏe Đại học Florida, Gainesville, FL, Hoa Kỳ
4NVIDIA, Santa Clara, CA, Hoa Kỳ
5Khoa Khoa học Máy tính, Đại học Khoa học Ứng dụng và Nghệ thuật Dortmund, Dortmund, Đức
6Viện Tin học Y khoa, Sinh trắc học và Dịch tễ học (IMIBE), Bệnh viện Đại học Essen (AöR), Essen, Đức
7Khoa Y học Hạt nhân, Bệnh viện Đại học Essen (AöR), Essen, Đức
8Khoa X quang Chẩn đoán và Can thiệp, Bệnh viện Đại học RWTH Aachen, Aachen, Đức
9Trung tâm Nghiên cứu Ung thư Cologne Essen (CCCE), Trung tâm Ung thư Tây Đức Essen, Bệnh viện Đại học Essen (AöR), Essen, Đức
10Hiệp hội Ung thư Đức (DKTK, Chi nhánh Essen), Heidelberg, Đức
11Khoa Vật lý, Đại học Kỹ thuật Dortmund, Dortmund, Đức

## Tóm tắt

Theo truyền thống, các mô hình ngôn ngữ lớn được huấn luyện trên dữ liệu thu thập web tổng quát hoặc dữ liệu cụ thể theo lĩnh vực. Tuy nhiên, những thành công gần đây của các mô hình ngôn ngữ lớn tạo sinh đã làm sáng tỏ lợi ích của các bộ dữ liệu đa lĩnh vực. Để kiểm tra tầm quan trọng của việc ưu tiên tính đa dạng dữ liệu hơn chất lượng, chúng tôi trình bày một bộ dữ liệu tiếng Đức bao gồm văn bản từ năm lĩnh vực, cùng với một bộ dữ liệu khác nhằm chứa dữ liệu chất lượng cao. Thông qua việc huấn luyện một loạt mô hình với tham số từ 122M đến 750M trên cả hai bộ dữ liệu, chúng tôi tiến hành đánh giá toàn diện trên nhiều tác vụ hạ nguồn. Kết quả của chúng tôi cho thấy các mô hình được huấn luyện trên bộ dữ liệu đa lĩnh vực vượt trội so với những mô hình chỉ được huấn luyện trên dữ liệu chất lượng, dẫn đến cải thiện lên tới 4,45% so với kết quả tiên tiến trước đây. Các mô hình có sẵn tại: https://huggingface.co/ikim-uk-essen

## 1 Giới thiệu

Với các định luật tỷ lệ đã được thiết lập (Kaplan et al., 2020), việc tăng kích thước mô hình và bộ dữ liệu đã trở thành một phương án nhất quán trong lĩnh vực Mô hình Ngôn ngữ Lớn (LLM) đang phát triển nhanh chóng (Kaplan et al., 2020; Touvron et al., 2023; Smith et al., 2022). Mô hình này tồn tại cho bất kỳ kiến trúc nào được đề xuất gần đây (Yang et al., 2023), độc lập với mô hình chỉ giải mã (Brown et al., 2020b; Chowdhery et al., 2022; Touvron et al., 2023), chỉ mã hóa (He et al., 2021; Devlin et al., 2019; Liu et al., 2019; Clark et al., 2020), hoặc mô hình mã hóa-giải mã (Raffel et al., 2020; Zeng et al., 2022). Vì những mô hình này đã cho thấy hiệu suất ấn tượng trong hiểu ngôn ngữ tự nhiên, nhiều nghiên cứu đã xây dựng dựa trên chúng cho các tác vụ cụ thể như hiểu ngôn ngữ y tế (Rasmy et al., 2021; Lee et al., 2020) hoặc tương tác con người (Bai et al., 2022), hoặc cải tiến chúng thông qua các lựa chọn thiết kế thông minh. Ví dụ, He et al. (2021) đã giới thiệu cơ chế chú ý tách biệt mã hóa vị trí token và thông tin riêng biệt, cho phép nó vượt qua hiệu suất con người trên điểm chuẩn SuperGLUE (Wang et al., 2019). Tuy nhiên, khi yêu cầu dữ liệu cho LLM có thể trở nên khó khăn để có được đối với các tổ chức nhỏ hơn, điều này đặt ra câu hỏi liệu việc tăng nghiêm ngặt lượng dữ liệu có phải là giải pháp duy nhất hay có thể tạo điều kiện huấn luyện LLM thông qua quy trình lựa chọn dữ liệu tỉ mỉ hơn.

The Pile (Gao et al., 2020) đã đóng vai trò quan trọng trong việc nhấn mạnh những lợi thế của việc bổ sung các bộ dữ liệu thu thập web với một loạt rộng dữ liệu cụ thể theo lĩnh vực. Nhận thức này đã thúc đẩy việc huấn luyện các mô hình ngôn ngữ lớn (LLM) trên The Pile và các bộ dữ liệu tương tự (Gao et al., 2020; Laurençon et al., 2022). Gunasekar et al. (2023) đã trình bày một mô hình 1,3B tham số được huấn luyện trên bộ dữ liệu gồm 7B token được tuyển chọn cẩn thận có thể so sánh với GPT3.5 trên HumanEval, cho thấy rằng chất lượng dữ liệu ngoài các định luật tỷ lệ tổng quát (Kaplan et al., 2020) cũng đóng vai trò quan trọng.

Tuy nhiên, một sự khác biệt đáng chú ý xuất hiện khi xem xét tiếng Đức, vì hiện tại thiếu các bộ dữ liệu tập trung vào tính đa dạng tương đương. Để giải quyết khoảng trống này, chúng tôi đề xuất các phương pháp khác nhau để tuyển chọn một bộ dữ liệu tiếng Đức đa dạng, ngay cả đối với các lĩnh vực có tài nguyên hạn chế, chẳng hạn như lĩnh vực y tế. Các phương pháp của chúng tôi có thể áp dụng cho một loạt rộng các ngôn ngữ, vì khoảng 74% bộ dữ liệu này được có được thông qua các kỹ thuật dịch tự động và lọc thu thập web. Chúng tôi chứng minh những lợi thế của các bộ dữ liệu như vậy so với các bộ dữ liệu dựa hoàn toàn trên thu thập web với một tập hợp các mô hình chỉ mã hóa mà chúng tôi gọi là GeBERTa.

Năm 2020, Chan et al. đã công bố một tập hợp các mô hình transformer tiếng Đức (Vaswani et al., 2017) dựa trên BERT và ELECTRA, đạt được kết quả tiên tiến trên hai bộ dữ liệu hạ nguồn. Cùng thời điểm đó, GottBERT được phát hành, một mô hình RoBERTa tiếng Đức (Scheible et al., 2020). Vì hai ấn phẩm chỉ được đánh giá trên hai bộ dữ liệu hạ nguồn chung và cả hai đều bỏ qua việc tinh chỉnh siêu tham số, không rõ chúng so sánh như thế nào. Trong nghiên cứu này, chúng tôi huấn luyện các LM tiếng Đức mới với kiến trúc DeBERTa (He et al., 2021) và tập hợp một điểm chuẩn toàn diện gồm tám bộ dữ liệu hạ nguồn. Bằng cách tinh chỉnh các siêu tham số của mô hình của chúng tôi và những mô hình được phát hành trước đây, chúng tôi thể hiện hiệu suất mô hình được nâng cao đạt được thông qua kiến trúc DeBERTa và bộ dữ liệu đa lĩnh vực của chúng tôi. (Chan et al., 2020) và (Scheible et al., 2020) dựa trên bộ dữ liệu OSCAR dựa trên web. Hơn nữa, Chan et al., 2020 đã khám phá tác động của số lượng dữ liệu đến hiệu suất mô hình. Mục đích của nghiên cứu này là định lượng tác động của chất lượng dữ liệu và việc bao gồm dữ liệu đa lĩnh vực đối với các mô hình chỉ mã hóa.

Đóng góp của chúng tôi có thể được tóm tắt như sau:
• Chúng tôi chứng minh thực nghiệm rằng việc tiền huấn luyện mô hình ngôn ngữ trên các bộ dữ liệu không đồng nhất dẫn đến hiệu suất hạ nguồn tốt hơn.
• Chúng tôi tập hợp một điểm chuẩn mở rộng gồm tám tác vụ và đánh giá kỹ lưỡng các mô hình đã được công bố trước đây.
• Chúng tôi trình bày các mô hình ngôn ngữ tiếng Đức mới đạt được kết quả tiên tiến.
• Chúng tôi phát hành các mô hình và mã nguồn để biên dịch bộ dữ liệu tiền huấn luyện.

## 2 Công trình liên quan

### 2.1 LM tiếng Đức

Sau thành công to lớn đạt được bởi các mô hình tiếng Anh, một làn sóng các mô hình transformer được huấn luyện bằng nhiều ngôn ngữ khác đã xuất hiện (Martin et al., 2020; Chan et al., 2020). Sự phát triển này đã trở nên khả thi thông qua tính khả dụng và việc sử dụng các kho ngữ liệu đa ngôn ngữ dựa trên web. Nổi bật nhất là OSCAR (Ortiz Suarez và Gabay, 2022) và CC100 (Wenzek et al., 2020). Trong khi Oscar chỉ thực hiện một số phương pháp suy đoán để lọc dữ liệu chất lượng, quy trình CC100 có nỗ lực cố ý để lọc các văn bản chất lượng cao hơn bằng cách sử dụng mô hình n-gram để lọc các văn bản tương tự như các bài viết Wikipedia (Wenzek et al., 2020). Chúng tôi dựa nghiên cứu của mình trên bộ dữ liệu GC41 được thu thập với quy trình CC100. Trong tiếng Đức, (Chan et al., 2020) đã phát hành GBERT Base, GBERT Large, GELECTRA Base, và GELECTRA Large, được huấn luyện trên OSCAR, Wikipedia, Open Parallel Corpus (Tiedemann, 2012), và văn bản pháp lý (Ostendorff et al., 2020a). Trong nghiên cứu của họ, Chan et al. đã khám phá tác động của số lượng dữ liệu đến hiệu suất mô hình. Bộ dữ liệu của họ bao gồm sự kết hợp của các tài liệu pháp lý và một tập con nhỏ các tài liệu y tế từ Open Parallel Corpus, điều này đã đưa ra khía cạnh đa lĩnh vực cho dữ liệu của họ. Tuy nhiên, họ không đo lường rõ ràng các tác động cụ thể của việc kết hợp dữ liệu đa lĩnh vực. Ngoài ra, GottBERT (Scheible et al., 2020) đã được phát hành, một mô hình RoBERTa tiếng Đức (Liu et al., 2019) chỉ được huấn luyện trên phần tiếng Đức của bộ dữ liệu OSCAR.

### 2.2 Tiền huấn luyện Đa lĩnh vực

Các transformer chỉ mã hóa thường được huấn luyện ban đầu trên thu thập web tổng quát, bài báo tin tức, sách, và sau đó được tinh chỉnh cho các lĩnh vực cụ thể. Một ví dụ nổi tiếng là BioBERT (Lee et al., 2020), một LM cụ thể lĩnh vực được tiền huấn luyện thêm trên văn bản PubMed dựa trên BERT (Devlin et al., 2019), được tiền huấn luyện trên Wikipedia và BooksCorpus. Alsentzer et al., 2019, tuy nhiên, cho thấy rằng tiền huấn luyện trên dữ liệu y tế (Clinical BioBERT) vượt trội so với tiền huấn luyện trên dữ liệu tổng quát (Clinical BERT) cho một số tác vụ y tế hạ nguồn. Thay vào đó, có một số nghiên cứu chỉ huấn luyện trên lĩnh vực mục tiêu, ví dụ, (Gu et al., 2021) và (Yang et al., 2022). Mặt khác, các LLM tạo sinh thường được huấn luyện trên các bộ dữ liệu đa dạng hơn kết hợp nhiều lĩnh vực. Sau khi phát hành GPT-2 (Radford et al., 2019) và GPT-3 (Brown et al., 2020a), trọng tâm nghiên cứu đã chuyển sang các bộ dữ liệu lớn đa dạng. The Pile kết hợp dữ liệu web với các bài đăng diễn đàn, ấn phẩm khoa học, và các bài viết từ một loạt rộng các lĩnh vực và chứng minh rằng tính đa dạng dữ liệu là một yếu tố quan trọng cho hiệu suất của LLM. Mặc dù thành phần của dữ liệu huấn luyện cho GPT-3.5 và GPT-4 vẫn chưa được biết, một số ấn phẩm đã chứng minh khả năng của chúng trong nhiều tác vụ cụ thể theo lĩnh vực, bao gồm y học (Adams et al., 2023; Nori et al., 2023), ngụ ý rằng dữ liệu huấn luyện kết hợp nhiều lĩnh vực khác nhau.

Việc sử dụng các bộ dữ liệu đa lĩnh vực trong các ngôn ngữ khác vẫn hiếm, chủ yếu vì nỗ lực liên quan đến việc biên dịch các bộ dữ liệu như vậy. Ngoài ra, tính khả dụng của dữ liệu cụ thể theo lĩnh vực thấp ở nhiều ngôn ngữ. Ví dụ, một nghiên cứu gần đây chỉ tìm thấy ít hơn 2 triệu tài liệu y tế có sẵn công khai bằng tiếng Đức (Bressem et al., 2023). Trong nghiên cứu này, chúng tôi trình bày các phương pháp khác nhau để tạo ra các bộ dữ liệu tiếng Đức tương ứng dựa trên thu thập web hoặc các bộ dữ liệu cụ thể theo lĩnh vực tiếng Anh. Mặc dù, do việc sử dụng các phương pháp dịch tự động và lọc, chất lượng thấp hơn so với các bộ dữ liệu tiếng Anh, chúng tôi có thể cho thấy rằng bộ dữ liệu đa lĩnh vực của chúng tôi dẫn đến hiệu suất tốt hơn của các mô hình ngôn ngữ tiếng Đức.

## 3 Thu thập Dữ liệu

CC100 ưu tiên chất lượng trong việc xây dựng. Trong khi sự nhấn mạnh vào chất lượng này có thể có lợi, nó cũng có những hạn chế nhất định khi nói đến bộ dữ liệu. Cụ thể, các lĩnh vực bao gồm văn bản không chính thức hoặc có nhiều nhiễu, chẳng hạn như bài đăng mạng xã hội hoặc tài liệu y tế, có thể bị bất lợi do trọng tâm vào chất lượng. Để giải quyết mối quan ngại này và khám phá sự đánh đổi giữa chất lượng và tính đa dạng, chúng tôi đã phát triển hai bộ dữ liệu riêng biệt. Bộ dữ liệu đầu tiên Dquality tập trung vào việc đảm bảo chất lượng cao, có nội dung được tuyển chọn cẩn thận và đáng tin cậy. Tuy nhiên, nhận thức được tầm quan trọng của việc kết hợp các văn bản đa dạng, chúng tôi đã thực hiện các bước để mở rộng bộ dữ liệu tập trung vào chất lượng để bao gồm một loạt tài liệu rộng hơn, do đó tăng tính đa dạng của nó. Bằng cách tạo ra hai bộ dữ liệu này với các trọng tâm khác nhau, chúng tôi nhằm kiểm tra liệu những lợi thế thu được từ phương pháp tập trung vào tính đa dạng có vượt trội so với bất kỳ nhược điểm tiềm ẩn nào liên quan đến việc giảm chất lượng dữ liệu hay không.

### 3.1 Bộ dữ liệu Tập trung vào Chất lượng

Chúng tôi kết hợp GC4, các bài báo tin tức tiếng Đức, và các tài nguyên liên quan khác để tạo ra bộ dữ liệu đầu tiên Dquality. Trong khi (Wenzek et al., 2020) trước đây đã áp dụng khử trùng lặp dựa trên hash tài liệu, những người tạo ra GC4 đã thực hiện một bước khử trùng lặp bổ sung. Họ đã sử dụng khử trùng lặp MongoDB để xác định các bản trùng lặp qua các snapshot (Wenzek et al., 2020). Để xây dựng bộ dữ liệu của chúng tôi, chúng tôi dựa vào tất cả các snapshot đầu GC4 đã được xử lý trước, cho thấy độ tương tự cao nhất với các bài viết Wikipedia. Ngoài ra, chúng tôi đã kết hợp kho ngữ liệu thu thập tin tức đơn ngôn ngữ tiếng Đức WMT 2022 (Kocmi et al., 2022) và dump Wikipedia tiếng Đức 20220301.de2.

Với khả năng chồng chéo tiềm tàng giữa các bộ dữ liệu này, chúng tôi đã áp dụng thuật toán khử trùng lặp được giới thiệu bởi (Lee et al., 2022). Quy trình khử trùng lặp bao gồm hai giai đoạn: ban đầu, chúng tôi khử trùng lặp GC4 và kho ngữ liệu tin tức riêng biệt, và sau đó, khử trùng lặp các bộ dữ liệu kết hợp. Chúng tôi cấu hình độ dài chuỗi con khớp tối thiểu là 100 token. Để đảm bảo tính toàn vẹn tài liệu, bất kỳ tài liệu nào chứa bản trùng lặp đã được loại bỏ hoàn toàn. Thú vị là, mặc dù những nỗ lực khử trùng lặp trước đây của (Wenzek et al., 2020), đã loại bỏ 70% văn bản từ mỗi snapshot GC4, và việc khử trùng lặp MongoDB tiếp theo, đã loại bỏ thêm 46% dữ liệu còn lại, chúng tôi phát hiện ra rằng trong số 74,6 tỷ token ban đầu trong GC4, 35,3 tỷ là bản trùng lặp. Hơn nữa, trong số 16 tỷ token tin tức, 9,3 tỷ được xác định là bản trùng lặp. Ngược lại, khi xem xét việc nối tất cả các bộ dữ liệu, chỉ tìm thấy 0,72 tỷ token trùng lặp.

### 3.2 Bộ dữ liệu Tăng cường Tính đa dạng

Trong phần này, chúng tôi nhằm mở rộng bộ dữ liệu tập trung vào chất lượng mà chúng tôi đã thảo luận trước đó, với mục tiêu chính là tăng cường tính đa dạng của nó. Để đạt được điều này, chúng tôi giới thiệu một số bổ sung cho Dquality. Chúng tôi phân chia dữ liệu mà chúng tôi thu thập thành bốn lĩnh vực riêng biệt: không chính thức, y tế, pháp lý, và văn học. Phần tiếp theo sẽ cung cấp một tài khoản chi tiết về cách chúng tôi có được các bộ dữ liệu cụ thể theo lĩnh vực này. Bằng cách bao gồm dữ liệu từ nhiều lĩnh vực khác nhau, chúng tôi cố gắng kết hợp một loạt rộng hơn các phong cách ngôn ngữ và nội dung. Chúng tôi hy sinh chất lượng bằng cách thêm văn bản được dịch tự động, dữ liệu thu thập web được lọc, và dữ liệu có khả năng nhiều nhiễu hơn từ mạng xã hội với ý định tăng tính đa dạng dữ liệu. Để đảm bảo rằng kết quả của chúng tôi có thể so sánh được về mặt khối lượng dữ liệu, chúng tôi thực hiện bước loại bỏ một tập con ngẫu nhiên của bộ dữ liệu GC4. Chúng tôi gọi bộ dữ liệu này là Dvariety.

**Không chính thức** Lấy cảm hứng từ công trình của Blombach et al., 2020, chúng tôi đã xác định nội dung tiếng Đức trong Bộ dữ liệu Reddit Pushshift (Baumgartner et al., 2020). Để hoàn thành điều này, chúng tôi đã thu thập tất cả các bài đăng và bình luận được đăng từ 2019 đến 2023 từ bộ dữ liệu. Sau đó, chúng tôi thực hiện một số bước tiền xử lý, bao gồm việc bỏ thoát nội dung HTML, loại bỏ URL, và lọc ra các văn bản có ít hơn 20 từ. Để xác định nội dung tiếng Đức một cách chính xác, chúng tôi đã sử dụng mô hình nhận dạng ngôn ngữ fasttext (Joulin et al., 2017). Chúng tôi đặt ngưỡng điểm nhận dạng ngôn ngữ là 0,9, loại trừ các bài đăng có điểm dưới giá trị này.

Kết quả của quy trình này, chúng tôi có được một bộ sưu tập 15 triệu văn bản từ Reddit. Tuy nhiên, để tăng cường dữ liệu không chính thức của chúng tôi hơn nữa, chúng tôi đã kết hợp thêm 4,9 triệu văn bản từ một kho ngữ liệu đánh giá có nguồn từ một trang web đặt phòng kỳ nghỉ tiếng Đức, như được công bố bởi Guhr et al., 2020.

**Y tế** Trái ngược với tiếng Anh, được hưởng lợi từ các kho ngữ liệu văn bản y tế lớn hiện có như MIMIC (Johnson et al., 2016), tính khả dụng của các tài nguyên như vậy bằng tiếng Đức bị hạn chế do các quy định bảo mật nghiêm ngặt. Tuy nhiên, chúng tôi đã quản lý để thu thập một tập hợp tương đối nhỏ các bộ dữ liệu và trang web y tế công cộng. Sử dụng dữ liệu này, chúng tôi áp dụng phương pháp 5-gram được mô tả trong (Wenzek et al., 2020) để lọc bản phát hành mới nhất của kho ngữ liệu OSCAR cho các văn bản y tế. Trong số 207 triệu tài liệu tổng cộng trong OSCAR, chúng tôi tập trung vào việc chọn 2 triệu tài liệu hàng đầu nơi mô hình 5-gram có độ bối rối thấp nhất. Ngoài ra, chúng tôi đã thu thập 14.496 luận văn y học công khai được viết bằng tiếng Đức.

Để làm phong phú thêm bộ dữ liệu này, một bộ dữ liệu mở rộng gồm sáu triệu tóm tắt PubMed, ghi chú lâm sàng từ MIMIC III (Johnson et al., 2016) và PMC-Patients-ReCDS (Zhao et al., 2023) đã được dịch sang tiếng Đức. Trước khi dịch, các tài liệu trải qua một quy trình token hóa sử dụng thư viện Stanza (Qi et al., 2020), nơi chúng được phân tích thành các câu riêng lẻ. Những câu này sau đó được nhóm thành các khối, mỗi khối bị ràng buộc tối đa 128 token. Số lượng token được đếm bằng tokenizer được cung cấp với mô hình dịch. Ràng buộc này được xem xét vì quan sát thấy rằng các khối văn bản lớn hơn dẫn đến giảm chất lượng dịch. Đối với giai đoạn dịch, mô hình Fairseq WMT'19 Anh sang Đức3 đã được sử dụng. Mô hình được cấu hình với độ dài ngữ cảnh 156 và sử dụng tìm kiếm chùm với một chùm duy nhất, một cài đặt được chọn để tối ưu hóa tốc độ dịch.

**Pháp lý** Để bao phủ lĩnh vực pháp lý, kho ngữ liệu OpenLegalData bao gồm hơn 250.000 vụ án và luật tiếng Đức đã được sử dụng (Ostendorff et al., 2020b).

**Văn học** Chúng tôi đã sử dụng Kho ngữ liệu Tiểu thuyết tiếng Đức để tiến hành tiền huấn luyện trên văn học tiếng Đức. Kho ngữ liệu này bao gồm 2.735 sách văn xuôi tiếng Đức từ Gutenberg-DE Edition, được bổ sung bởi thêm 484 cuốn sách được dịch thủ công sang tiếng Đức. Ngoài ra, chúng tôi áp dụng phương pháp đã đề cập trước đó để dịch BooksCorpus thêm 11.038 cuốn sách nữa.

Các bộ dữ liệu kết quả được tóm tắt trong Bảng 1.

## 4 Thí nghiệm và Kết quả

### 4.1 Tiền huấn luyện

Theo (He et al., 2021), chúng tôi tiền huấn luyện DeBERTa base, DeBERTa large và với cùng cấu hình mà họ đã sử dụng trên cả hai bộ dữ liệu của chúng tôi và DeBERTa xlarge chỉ trên Dvariety. Trong phần sau, chúng tôi sẽ gọi các mô hình là GeBERTaQ và GeBERTaV. Chúng tôi huấn luyện với kích thước batch tích lũy 2048 trong 1M bước trên tác vụ mô hình hóa ngôn ngữ có mặt nạ động với bộ tối ưu hóa AdamW (Loshchilov và Hutter, 2019). Chúng tôi sử dụng tối ưu hóa DeepSpeed ZeRO và triển khai DeBERTa Hugging Face. Chúng tôi huấn luyện một tokenizer sentencepiece (Kudo và Richardson, 2018) trên một mẫu ngẫu nhiên 100M câu của mỗi bộ dữ liệu. Đối với các mô hình base và large, chúng tôi đặt kích thước từ vựng là 50k token, trong khi từ vựng của mô hình xlarge có 128k token.

Bảng 4 trình bày các siêu tham số được sử dụng trong tiền huấn luyện các mô hình GeBERTa khác nhau.

### 4.2 Tác vụ Hạ nguồn

Chúng tôi đánh giá các mô hình tiếng Đức hiện có và của chúng tôi trên một điểm chuẩn toàn diện. Điểm chuẩn bao gồm nhiều loại tác vụ khác nhau, bao gồm trả lời câu hỏi, phân loại, và nhận dạng thực thể có tên (NER). Ngoài ra, chúng tôi giới thiệu một tác vụ mới tập trung vào phát hiện ngôn từ thù địch, sử dụng hai bộ dữ liệu hiện có. Khi các bộ dữ liệu cung cấp tập huấn luyện, phát triển, và kiểm tra, chúng tôi sử dụng chúng tương ứng. Trong các trường hợp không có sẵn các tập như vậy, chúng tôi chia ngẫu nhiên dữ liệu thành 80% để huấn luyện, 10% xác thực, và 10% tập kiểm tra. Cụ thể đối với bộ dữ liệu GE18, chúng tôi sử dụng phân chia phân tầng dựa trên nhãn cho tập xác thực.

**GermEval 2014 (GE14)** GermEval 2014 là một bộ dữ liệu NER dựa trên Wikipedia tiếng Đức và bài báo tin tức. Nó chứa tổng cộng 590.000 token từ 31.000 câu. Nó bao gồm 12 loại thực thể như vị trí và người.

**GermEval 2018 (GE18)** Bộ dữ liệu phân loại ngôn từ thù địch đa lớp này bao gồm 5.009 tweet tiếng Đức. Nó chứa hai chú thích thô và chi tiết. Chúng tôi tập trung vào tác vụ thách thức hơn sau này. Bộ dữ liệu thể hiện sự mất cân bằng đáng kể, với chỉ 11,9% mẫu được đánh dấu là xúc phạm và chỉ 1,4% được gắn nhãn là tục tĩu.

**Tweet Sentiment (TS)** Chúng tôi nhận thấy rằng trong GE18, điểm F1 xác thực không phải là chỉ báo tốt của điểm kiểm tra. Chúng tôi tin rằng điều này là do số lượng ví dụ tương đối nhỏ cho các lớp được đại diện dưới. Do đó, chúng tôi đã tạo một tác vụ phát hiện ngôn từ thù địch khác từ hai bộ dữ liệu hiện có. Guhr et al., 2020 đã giới thiệu một điểm chuẩn phân loại tình cảm lớn với nhãn tích cực, tiêu cực, và trung tính. Chúng tôi kết hợp sb10k (Cieliebak et al., 2017) và PotTS (Sidarenka, 2016), tạo ra một bộ dữ liệu 14.980 tweet.

**GermanQuAD (GQuAD)** Đối với các mô hình tiếng Anh, Stanford Question Answering Dataset (SQuAD) (Rajpurkar et al., 2016) là một tác vụ hạ nguồn phổ biến. Mỗi ví dụ bao gồm một đoạn từ Wikipedia cùng với một câu hỏi và các chỉ số của câu trả lời trong đoạn. Trong phiên bản thứ hai, các câu hỏi không có câu trả lời đã được thêm vào, tăng độ khó của tác vụ. Möller et al., 2021 đã tạo ra GermanQuAD, dựa trên các bài viết Wikipedia tiếng Đức tương ứng với những bài tiếng Anh được sử dụng trong SQuAD.

**GGPONC 2.0 (GGP)** Dựa trên hướng dẫn thực hành lâm sàng trong ung thư học (Borchert et al., 2022) đã công bố một bộ dữ liệu NER. Bao gồm 1,8 triệu token từ 10.000 tài liệu, đây là bộ dữ liệu NLP y tế tiếng Đức lớn nhất có sẵn. Họ đã công bố các chú thích với số lượng lớp và độ dài span khác nhau. Chúng tôi tập trung vào trường hợp phức tạp nhất với 8 lớp ngữ nghĩa chi tiết và span thực thể dài.

**GRASCCO (GRAS)** là một tập hợp các báo cáo ca lâm sàng tổng hợp (Röhrig et al., 2022). Theo cùng lược đồ chú thích như trong GGPONC 2.0, một phiên bản chú thích của GRASCCO đã được tạo ra (Bressem et al., 2023). Cũng trên bộ dữ liệu này, chúng tôi đánh giá các lớp chi tiết và span thực thể dài.

**DROC** Kho ngữ liệu Tham chiếu Nhân vật trong Tiểu thuyết tiếng Đức (DROC) bao gồm khoảng 393.000 token từ 90 tiểu thuyết tiếng Đức. 52.079 token được chú thích là tham chiếu nhân vật phân biệt giữa bốn loại thực thể.

**Jsyncc (JS)** (Lohr et al., 2018) đã công bố một bộ dữ liệu các ca sách giáo khoa y tế với nhãn chủ đề. Do hạn chế bản quyền, họ đã phát hành mã nguồn tạo ra bộ dữ liệu dựa trên PDF sách. Chúng tôi có thể có được 7 trong số 10 cuốn sách này tạo ra 544 mẫu và sáu lớp.

### 4.3 Tinh chỉnh

Theo (Liu et al., 2019), chúng tôi thực hiện tìm kiếm tham số hạn chế cho mỗi kết hợp mô hình và tác vụ. Chúng tôi sử dụng tỷ lệ bước khởi động 6% và xem xét kích thước batch 16 và 32. Tùy thuộc vào kích thước mô hình, chúng tôi điều chỉnh phạm vi tốc độ học. Số epoch tối đa được đặt là 20. Các tham số cuối cùng được đặt theo hiệu suất xác thực tốt nhất của mỗi lần quét. Cuối cùng, chúng tôi thực hiện năm lần chạy kiểm tra với dừng sớm và báo cáo hiệu suất kiểm tra trung bình.

### 4.4 Kết quả

Chúng tôi trình bày kết quả của chúng tôi cho các mô hình base trong Bảng 2. Trong khi GeBERTaQbase vượt trội so với các mô hình hiện có trên hầu hết các tác vụ, GeBERTaVbase đạt được kết quả tốt nhất. Sự khác biệt đặc biệt rõ ràng so với các mô hình trước đây có thể thấy trên GQuAD (+4,45%) và GRAS (+2,4%). Như mong đợi, huấn luyện trên văn bản không chính thức cải thiện kết quả trên các tác vụ hạ nguồn từ lĩnh vực này, cụ thể là GE18, và TS. Điều này cũng đúng với các bộ dữ liệu y tế và DROC. Thú vị là, hiệu suất cũng cải thiện trên GE14 và GQuAD. Cả hai tác vụ đều dựa trên Wikipedia và do đó có thể được gán rõ ràng cho lĩnh vực chính thức. Tuy nhiên, mô hình cũng được hưởng lợi từ tiền huấn luyện đa lĩnh vực ở đây.

Bảng 3 trình bày hiệu suất của các mô hình lớn hơn. Tương tự như các mô hình base, GeBERTaQlarge vượt trội so với GeBERTaVlarge mặc dù sự khác biệt ở đây nhỏ hơn. Ví dụ, trên GQuAD nó hoạt động tốt hơn GeBERTaVlarge (+1,02%) và, thú vị là, cũng trên TS mặc dù nó không được huấn luyện trên dữ liệu không chính thức. Điều này cho thấy rằng đối với các mô hình lớn hơn, các lĩnh vực cụ thể trong bộ dữ liệu tiền huấn luyện không phải lúc nào cũng có liên quan. Tuy nhiên, trên GE18 nó rõ ràng tệ hơn GeBERTaVlarge. Ngoài ra, GeBERTaVlarge đạt được kết quả cao hơn trung bình trên tất cả các tác vụ. Cuối cùng GeBERTaQxlarge ghi điểm cao nhất trên tất cả các tác vụ ngoại trừ GGP và GRAS.

Tìm kiếm siêu tham số của chúng tôi cũng cải thiện kết quả đã được báo cáo trước đây trên GE18 cho GBERT base 0,37% và cho GELECTRA base 1,74%. Hơn nữa hiệu suất của GottBERT base trên GE14 0,31%. Trong một số trường hợp khác, chúng tôi không thể tái tạo cùng hiệu suất như đã được báo cáo trước đây. Chúng tôi cho rằng điều này là do sự khác biệt trong đánh giá. Ví dụ, kết quả được báo cáo cho GottBERT là kết quả tốt nhất từ nhiều lần chạy, trong khi chúng tôi báo cáo trung bình qua năm lần chạy. Bảng 5 trình bày không gian tìm kiếm siêu tham số được sử dụng để tinh chỉnh các mô hình trên các tác vụ hạ nguồn khác nhau.

Độ lệch chuẩn cao quan sát được qua tất cả các mô hình trong GE18 xác nhận mối quan ngại ban đầu của chúng tôi về tính không ổn định của nó. Ngược lại, trong trường hợp của TS, độ lệch chuẩn thấp hơn đáng chú ý qua tất cả các mô hình.

## 5 Thảo luận

Các thí nghiệm mở rộng của chúng tôi cung cấp bằng chứng rõ ràng rằng các mô hình mà chúng tôi đã công bố đã đạt được một bước tiến đáng kể trong quá trình xử lý ngôn ngữ tự nhiên bằng tiếng Đức (NLP). Điều quan trọng cần lưu ý là những cải thiện nhất định chắc chắn có thể được quy cho kiến trúc DeBERTa. Điều này có thể thấy trong hiệu suất được cải thiện trên các tác vụ như trả lời câu hỏi và nhận dạng thực thể có tên với span thực thể lớn hơn. Tuy nhiên, một so sánh trực tiếp giữa các mô hình được huấn luyện chỉ trên dữ liệu thu thập web và những mô hình được huấn luyện trên dữ liệu đa lĩnh vực cho thấy sự cải thiện rõ ràng, có thể được quy cho việc bao gồm dữ liệu tiền huấn luyện đa dạng. Hơn nữa, kết quả của chúng tôi đã cho thấy tiềm năng của một bộ dữ liệu đa lĩnh vực, chủ yếu được xây dựng bởi dịch tự động và lọc các tài nguyên đa ngôn ngữ hiện có, để cải thiện chất lượng của những mô hình này. Mô hình Falcon được công bố gần đây (Almazrouei et al., 2023) đã được huấn luyện sử dụng sự kết hợp của dữ liệu thu thập web và dữ liệu đa lĩnh vực tiếng Anh được tuyển chọn. Do đó, chúng tôi tin tưởng mạnh mẽ rằng các mô hình tạo sinh cũng có thể được hưởng lợi từ việc áp dụng các phương pháp thu thập dữ liệu của chúng tôi để tập hợp các bộ dữ liệu đa ngôn ngữ, đa lĩnh vực.

Một phát hiện thú vị từ nghiên cứu của chúng tôi là mô hình base của chúng tôi đạt được mức hiệu suất tương đương với các mô hình large tiên tiến trước đây. Phát hiện này cho thấy rằng các tài nguyên tính toán cần thiết có thể được giảm đáng kể bằng cách sử dụng một bộ dữ liệu đa dạng kết hợp với các kiến trúc mô hình hiệu quả. Kết quả là, những tiến bộ này trở nên dễ tiếp cận hơn với một loạt người rộng hơn và dẫn đến tiết kiệm tiêu thụ điện năng và giảm tác động môi trường liên quan. Một nghiên cứu được công bố gần đây về một mô hình tiếng Pháp (Antoun et al., 2023) hỗ trợ thêm cho khái niệm này, cho thấy rằng việc sử dụng các kiến trúc mô hình mới giúp làm cho huấn luyện hiệu quả dữ liệu hơn. Chúng tôi giả thuyết rằng huấn luyện trên các bộ dữ liệu đa dạng có thể cải thiện thêm hiệu quả theo cách tương tự, với việc huấn luyện của họ trên một bộ dữ liệu có nguồn từ quy trình CC100.

## 6 Kết luận

Tóm lại, bài báo này trình bày các mô hình ngôn ngữ tiếng Đức đạt được kết quả tiên tiến trên nhiều tác vụ xử lý ngôn ngữ tự nhiên khác nhau bằng cách tiền huấn luyện trên các bộ dữ liệu đa dạng hơn. Các thí nghiệm cho thấy rằng huấn luyện mô hình ngôn ngữ trên các bộ dữ liệu đa lĩnh vực dẫn đến hiệu suất được cải thiện so với các mô hình chỉ được huấn luyện trên dữ liệu thu thập web. Kết quả cho thấy rằng các tài nguyên tính toán cần thiết để huấn luyện có thể được giảm đáng kể trong khi vẫn đạt được hiệu suất cao thông qua việc sử dụng các bộ dữ liệu đa dạng và kiến trúc mô hình hiệu quả. Nhìn chung, nghiên cứu cung cấp bằng chứng rằng việc kết hợp dữ liệu đa dạng, đa ngôn ngữ là rất quan trọng để xây dựng các mô hình ngôn ngữ chất lượng cao.

## Hạn chế

Mặc dù có khả năng đáng chú ý của các mô hình ngôn ngữ (LM), điều quan trọng là phải nhận ra những hạn chế của chúng. Một mối quan ngại chính là tiêu thụ năng lượng cao liên quan đến huấn luyện LM. Các tài nguyên tính toán cần thiết để huấn luyện các mô hình quy mô lớn có thể có dấu chân carbon đáng kể, góp phần vào mối quan ngại về môi trường.

Cuối cùng, trong khi phần lớn bộ dữ liệu của chúng tôi bao gồm các bộ dữ liệu đa ngôn ngữ được lọc và dịch thuật, loại dữ liệu này khó có được ở các ngôn ngữ có tài nguyên hạn chế. Chúng tôi tin rằng đây là một vấn đề cần được giải quyết trong các nghiên cứu tương lai.

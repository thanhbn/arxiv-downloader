# 2402.03131.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/multilingual/2402.03131.pdf
# Kích thước file: 1698725 bytes

===============================================
NỘI DUNG FILE PDF
===============================================

--- TRANG 1 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2024
GIẢI MÃ CÓ RÀNG BUỘC CHO PHÉP CHIẾU NHÃN
CHÉO NGÔN NGỮ
Duong Minh Le, Yang Chen, Alan Ritter & Wei Xu
Viện Công nghệ Georgia
{dminh6, yangc }@gatech.edu ,{alan.ritter, wei.xu }@cc.gatech.edu
TÓM TẮT
Chuyển giao chéo ngôn ngữ zero-shot sử dụng LLM đa ngôn ngữ đã trở thành một mô hình học tập phổ biến cho các ngôn ngữ ít tài nguyên không có dữ liệu huấn luyện có nhãn. Tuy nhiên, đối với các nhiệm vụ NLP liên quan đến dự đoán chi tiết trên từ và cụm từ, hiệu suất của việc học chuyển giao chéo ngôn ngữ zero-shot còn kém xa so với các phương pháp tinh chỉnh có giám sát. Do đó, việc khai thác dịch thuật và chiếu nhãn để cải thiện thêm hiệu suất là phổ biến bằng cách (1) dịch dữ liệu huấn luyện có sẵn trong ngôn ngữ nhiều tài nguyên (ví dụ: tiếng Anh) cùng với nhãn vàng sang ngôn ngữ ít tài nguyên, và/hoặc (2) dịch dữ liệu kiểm tra trong ngôn ngữ ít tài nguyên sang ngôn ngữ nguồn cao để chạy suy luận, sau đó chiếu các nhãn mức độ span được dự đoán trở lại dữ liệu kiểm tra gốc. Tuy nhiên, các phương pháp chiếu nhãn dựa trên marker tiên tiến nhất gặp phải sự suy giảm chất lượng dịch thuật do các marker nhãn bổ sung được chèn vào đầu vào của mô hình dịch thuật. Trong công trình này, chúng tôi khám phá một hướng mới tận dụng giải mã có ràng buộc cho chiếu nhãn để vượt qua các vấn đề nêu trên. Phương pháp mới của chúng tôi không chỉ có thể bảo toàn chất lượng của văn bản đã dịch mà còn có tính linh hoạt để áp dụng cho cả chiến lược dịch dữ liệu huấn luyện và dịch dữ liệu kiểm tra. Tính linh hoạt này rất quan trọng vì các thí nghiệm của chúng tôi tiết lộ rằng việc dịch dữ liệu kiểm tra có thể dẫn đến sự cải thiện đáng kể về hiệu suất so với chỉ dịch dữ liệu huấn luyện. Chúng tôi đánh giá trên hai nhiệm vụ chuyển giao chéo ngôn ngữ, cụ thể là Nhận dạng Thực thể có Tên và Trích xuất Đối số Sự kiện, trải rộng trên 20 ngôn ngữ. Kết quả cho thấy phương pháp của chúng tôi vượt trội so với phương pháp dựa trên marker tiên tiến nhất với biên độ lớn và cũng cho thấy hiệu suất tốt hơn so với các phương pháp chiếu nhãn khác dựa trên căn chỉnh từ bên ngoài¹.

1 GIỚI THIỆU
Các mô hình ngôn ngữ lớn (LLM) đã chứng minh tiềm năng thực hiện nhiều nhiệm vụ NLP trong các môi trường học zero hoặc few-shot. Điều này hấp dẫn vì việc gán nhãn dữ liệu rất tốn kém — việc chú thích dữ liệu tinh chỉnh trên nhiều ngôn ngữ cho mỗi nhiệm vụ là không khả thi. Tuy nhiên, đối với các nhiệm vụ NLP truyền thống liên quan đến dự đoán mức độ từ/cụm từ, chẳng hạn như nhận dạng thực thể có tên hoặc trích xuất sự kiện, hiệu suất của việc học zero và few-shot còn kém xa so với các phương pháp tinh chỉnh có giám sát sử dụng lượng lớn dữ liệu có nhãn (Lai et al., 2023). Do đó, công trình trước đây đã huấn luyện các mô hình đa ngôn ngữ hỗ trợ chuyển giao chéo ngôn ngữ từ ngôn ngữ nhiều tài nguyên (ví dụ: tiếng Anh), nơi có dữ liệu tinh chỉnh có sẵn đến nhiều ngôn ngữ ít tài nguyên nơi dữ liệu có thể không có sẵn (ví dụ: Bambara, được nói chủ yếu ở Châu Phi). Các LLM dựa trên encoder như XLM-RoBERTa (Conneau et al., 2020) hoặc mDeBERTa (He et al., 2021) hoạt động tốt đáng ngạc nhiên cho chuyển giao chéo ngôn ngữ, nhưng hiệu suất của các mô hình được tinh chỉnh trên dữ liệu ngôn ngữ đích vẫn tốt hơn đáng kể (Xue et al., 2021). Được thúc đẩy bởi quan sát này, chúng tôi trình bày một phương pháp mới để tự động dịch các bộ dữ liệu huấn luyện NLP sang nhiều ngôn ngữ sử dụng giải mã có ràng buộc để dịch và chiếu các span nhãn chú thích từ ngôn ngữ nhiều tài nguyên sang ngôn ngữ ít tài nguyên một cách chính xác hơn.

Phương pháp của chúng tôi xây dựng dựa trên EasyProject (Chen et al., 2023a), một phương pháp tiên tiến đơn giản nhưng hiệu quả cho chiếu nhãn, chèn các marker đặc biệt (xem Hình 1a) vào các câu nguồn

¹ Mã nguồn của chúng tôi có sẵn tại: https://github.com/duonglm38/Codec

--- TRANG 2 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2024
[ France ]LOC ni [ Grande-Bretagne ]LOC dɔrɔn de ye [ Fischler ]PER ka waleɲumandɔn dɛmɛ.Chỉ [ France ]LOC và [ Britain ]LOC ủng hộ [ Fischler ]PER đề xuất.Tiếng Anh
BambaraKhớp span[ France ] ni [ Grande-Bretagne ] dɔrɔn de ye [ Fischler ] ka waleɲumandɔn dɛmɛ.DịchBritain  Grande-Bretagne   
…→
(a)EasyProject (Chen et al., 2023a):
Dịch với marker
Faransi ni Angiletɛri dɔrɔn de ye Fischler ka laɲini dɛmɛ .Chỉ France và Britain ủng hộ Fischler đề xuất.
[ Faransi ]LOC ni [ Angiletɛri ]LOC dɔrɔn de ye [ Fischler ]PER ka laɲini dɛmɛ .CodecDịchChỉ [ France ]LOC và [ Britain ]LOC ủng hộ [ Fischler ]PER đề xuất.
Template giốngGiải mã có ràng buộc(b)CODEC : Dịch không có marker sau đó
chèn marker với giải mã có ràng buộc

Hình 1: Mục tiêu của chiếu nhãn là tự động xây dựng dữ liệu chú thích trong ngôn ngữ ít tài nguyên (ví dụ: Bambara) bằng cách dịch từ dữ liệu chú thích trong ngôn ngữ nhiều tài nguyên (ví dụ: tiếng Anh) trong khi bảo toàn nhãn mức độ span. EasyProject (Trái): Câu nguồn đầu tiên được chèn các cặp marker xung quanh thực thể sau đó dịch sang ngôn ngữ đích; một bước khớp span được thực hiện để ánh xạ mỗi span tới nhãn tương ứng (tức là loại thực thể). Phương pháp này có vấn đề liên quan đến chất lượng dịch thuật (ví dụ: từ "France" không được dịch đúng cách), do sự tồn tại của marker trong đầu vào của mô hình dịch thuật. CODEC (Phải): Câu nguồn đầu tiên được dịch sang ngôn ngữ đích, với câu nguồn không có marker được chèn, CODEC sau đó thực hiện giải mã có ràng buộc để chèn marker vào câu đã dịch.

để đánh dấu các span chú thích, sau đó chạy các câu đã sửa đổi thông qua hệ thống dịch máy (MT), như NLLB (Costa-juss `a et al., 2022) hoặc Google Translate. Một hạn chế chính của EasyProject, như được ghi nhận bởi Chen et al. (2023a), là việc chèn marker đặc biệt vào câu nguồn sau đó dịch nó làm giảm chất lượng dịch thuật; tuy nhiên, EasyProject đã được chứng minh là hiệu quả hơn so với công trình trước đây cho chiếu nhãn chủ yếu dựa trên căn chỉnh từ (Yarmohammadi et al., 2021). Để giải quyết vấn đề suy giảm chất lượng dịch thuật, trong bài báo này, chúng tôi trình bày một phương pháp mới, Giải mã Ràng buộc cho Chiếu Nhãn Chéo ngôn ngữ (CODEC), để dịch các bộ dữ liệu huấn luyện sử dụng thuật toán giải mã có ràng buộc tùy chỉnh. Dữ liệu huấn luyện trong ngôn ngữ nhiều tài nguyên đầu tiên được dịch không có marker theo sau bởi lượt giải mã có ràng buộc thứ hai để chèn marker (xem Hình 1b). Vì câu nguồn không bao gồm marker trong giai đoạn dịch thuật, chất lượng văn bản dịch cuối cùng từ CODEC được bảo toàn. Lượt giải mã thứ hai của CODEC dựa trên mô hình dịch thuật được điều kiện hóa trên câu đầu vào đã sửa đổi với marker (do đó nhiều nhiễu hơn) để tìm các vị trí phù hợp cho việc chèn marker. Tuy nhiên, sử dụng thuật toán giải mã có ràng buộc được thiết kế đặc biệt, chúng ta có thể giữ lại bản dịch chất lượng cao trong khi có số lượng nhãn đúng được chiếu bằng cách thực thi cả hai như các ràng buộc trong quá trình giải mã.

Về bản chất, CODEC chỉ khám phá không gian tìm kiếm chứa các giả thuyết hợp lệ, tức là các đầu ra đã dịch tuân theo (i) bản dịch chất lượng cao từ lượt giải mã đầu tiên không có sự can thiệp của marker và (ii) có số lượng marker đúng được chèn. Việc liệt kê brute-force tất cả các giả thuyết có thể như vậy là không thể thực hiện, vì số lượng chuỗi cần được chấm điểm bằng mô hình dịch thuật là O(n²m), trong đó n là độ dài chuỗi và m là số lượng span có nhãn cần chiếu, như chúng tôi chỉ ra trong §3. Do đó, chúng tôi thiết kế thuật toán giải mã có ràng buộc dựa trên phương pháp branch-and-bound (Stahlberg & Byrne, 2019), trong đó tìm kiếm theo chiều sâu được tiến hành để xác định cận dưới trên giả thuyết hoàn chỉnh tốt nhất, và các nhánh không có bất kỳ giải pháp nào với điểm số tốt hơn cận dưới hiện tại được cắt tỉa khỏi không gian tìm kiếm.

Tuy nhiên, ngay cả khi cắt tỉa các nhánh sử dụng cận này, thời gian giải mã vẫn quá dài. Để tăng tốc giải mã, chúng tôi giới thiệu một cận dưới heuristic mới, loại bỏ các nhánh tích cực hơn. Chúng tôi cũng giới thiệu kỹ thuật cắt tỉa các vị trí không khả thi cho marker mở trước. Kết hợp tất cả lại, so với tìm kiếm branch-and-bound chính xác, phương pháp đề xuất của chúng tôi giảm đáng kể thời gian giải mã với chỉ một sự giảm nhẹ về hiệu suất trong một số ngôn ngữ. Ví dụ, đối với ngôn ngữ Bambara, CODEC nhanh hơn khoảng 60 lần so với tìm kiếm chính xác, trong khi chỉ mất 0,6 F1 tuyệt đối, giảm 1,1% hiệu suất.

Chúng tôi tiến hành các thí nghiệm rộng rãi để đánh giá CODEC trên hai nhiệm vụ chéo ngôn ngữ phổ biến (tức là Nhận dạng Thực thể có Tên và Trích xuất Đối số Sự kiện), bao gồm 20 cặp ngôn ngữ. Trong thí nghiệm của chúng tôi, CODEC và các baseline chiếu nhãn khác được sử dụng để chiếu nhãn từ các bộ dữ liệu tiếng Anh sang phiên bản đã dịch của chúng để tăng cường dữ liệu trong ngôn ngữ đích, được gọi là translate-train (Hu et al., 2020). Kết quả cho thấy rằng, trung bình, mô hình được tinh chỉnh

--- TRANG 3 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2024
trên dữ liệu tăng cường CODEC vượt trội so với các mô hình được tinh chỉnh trên dữ liệu được tạo ra bởi các baseline chiếu nhãn khác với biên độ lớn. Điều này củng cố giả thuyết của chúng tôi rằng việc bảo toàn chất lượng dịch thuật là cần thiết và giải mã có ràng buộc có thể cải thiện độ chính xác của chiếu nhãn. Hơn nữa, vì CODEC tách riêng hai giai đoạn dịch thuật và chèn marker, nó cũng có thể được sử dụng để cải thiện chuyển giao chéo ngôn ngữ bằng cách sử dụng dịch máy tại thời điểm suy luận, đôi khi được gọi là translate-test (Artetxe et al., 2023). Phương pháp này dịch dữ liệu kiểm tra từ ngôn ngữ ít tài nguyên sang ngôn ngữ nhiều tài nguyên, sử dụng mô hình NLP có giám sát đầy đủ để tự động chú thích bản dịch ở phía ngôn ngữ nhiều tài nguyên, sau đó chiếu các chú thích trở lại ngôn ngữ gốc. Thí nghiệm cho thấy rằng, so với translate-train một mình, việc sử dụng CODEC trong môi trường translate-test còn thúc đẩy hiệu suất chuyển giao chéo ngôn ngữ trong nhiệm vụ Nhận dạng Thực thể có Tên.

2 CHIẾU NHÃN NHƯ DỊCH THUẬT CÓ RÀNG BUỘC
Trong phần này, chúng tôi mô tả cách chúng tôi công thức hóa Chiếu Nhãn như một bài toán sinh có ràng buộc trước khi đề xuất giải quyết nó bằng cách thiết kế thuật toán giải mã có ràng buộc (chi tiết trong §3). Cho một câu nguồn với các span nhãn và bản dịch của nó trong ngôn ngữ đích, mục tiêu của chúng tôi là ánh xạ các span nhãn từ câu nguồn sang câu đích. Hình thức, gọi x là câu nguồn với m span có nhãn (ví dụ: m thực thể có tên) và xmark là văn bản giống như x nhưng với m cặp marker đặc biệt (ví dụ: dấu ngoặc vuông) bao quanh mỗi span nhãn. Trong công trình trước đây, mô hình MT sẽ tìm bản dịch ymark của câu với marker được chèn, xmark:

ymark = arg max_y logPτ(y|xmark) (1)

trong đó τ là hệ thống dịch máy (MT). Tuy nhiên, vì công trình trước đây đã phát hiện rằng việc chèn marker làm giảm chất lượng dịch thuật (Chen et al., 2023a), chúng tôi giới thiệu một biến thể của phương pháp. Phương pháp của chúng tôi sử dụng bản dịch của câu nguồn không có marker, sẽ hoạt động như một template để được chèn marker sau này tạo ra câu chú thích trong ngôn ngữ đích:

ytmpl = arg max_y logPτ(y|x) (2)

Nói chung, không có sự can thiệp của marker đặc biệt trong đầu vào, bản dịch ytmpl được kỳ vọng có chất lượng cao hơn ymark, như được chỉ ra trong (Chen et al., 2023a). Gọi Y là tập hợp tất cả các giả thuyết hợp lệ có thể với m cặp marker được chèn vào ytmpl. Trong công trình của chúng tôi, chúng tôi không xem xét trường hợp các span nhãn chồng chéo hoặc lồng nhau, do đó kích thước của Y là C(n+2m, 2m) hoặc O(n²m), trong đó n là độ dài (# token) của ytmpl.

Mục tiêu của chúng tôi là tìm giả thuyết tốt nhất y* từ Y, trong đó tất cả marker được chèn tại các vị trí đúng vào ytmpl với mỗi span được tìm thấy trong y* được ánh xạ tới nhãn tương ứng trong xmark. Chúng ta có thể đặt nhiệm vụ này như một bài toán dịch thuật có ràng buộc, thực thi hai ràng buộc: (i) y* chứa chính xác m cặp marker hợp lệ như xmark (tức là không có dấu ngoặc không khớp) và (ii) văn bản thuần túy (với tất cả marker được loại bỏ) của y* hoàn toàn giống như ytmpl. Do đó, chúng ta có thể giải quyết vấn đề này bằng cách thiết kế thuật toán giải mã có ràng buộc chuyên biệt, khám phá mọi giả thuyết trong không gian tìm kiếm Y và tìm ra giả thuyết có xác suất sinh cao nhất:

y* = arg max_{y∈Y} logPτ(y|xmark;ytmpl) (3)

logPτ(y|xmark;ytmpl) = ∑_{i=1}^n logPτ(yi|y<i, xmark;ytmpl) (4)

Bắt đầu với tiền tố dịch thuật ϵ (ví dụ: mã ngôn ngữ <bam>), thuật toán giải mã sẽ mở rộng giả thuyết một cách lặp lại; khi token kết thúc câu (tức là </s>) được sinh ra, một ứng cử viên chiếu của các span có nhãn được tìm thấy.

3 GIẢI MÃ CÓ RÀNG BUỘC
Trong phần này, chúng tôi sẽ đề xuất thuật toán giải mã có ràng buộc, CODEC, được thiết kế đặc biệt cho học chuyển giao chéo ngôn ngữ. Nó sử dụng xấp xỉ để giảm độ phức tạp tính toán của bài toán gốc và phương pháp xếp hạng để xác định các giả thuyết với chiếu span chính xác. CODEC có ba bước chính: (1) cắt tỉa tất cả các vị trí marker-mở không khả thi, (2) tìm kiếm k giả thuyết với xác suất cao nhất, và (3) xếp hạng lại để tìm giả thuyết tốt nhất.

--- TRANG 4 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2024
"Chỉ France và Britain ủng hộ Fischler đề xuất ."x="Faransi ni Angiletɛri dɔrɔn de ye Fischler ka laɲini dɛmɛ ."ytmpl="Chỉ France và [ Britain ] ủng hộ Fischler đề xuất ."xmark=Bước 1: Cắt tỉa các vị trí marker mởpi1=logP(ytmpli|ytmpl<i,x)
-0.64-0.68-6.26-0.38FaransiniAngile
ϵBước 2: Tìm kiếm k giả thuyết với xác suất cao nhấtĐầu vào:
ϵFaransini]-8.0-3.1ile-2.8-7.4-13.5
-30.2-36.7-22.8Angile
=1δ0.010.315.7Δi=|pi1−pi2|0.04Vị trí marker mở (sau "Faransi" hoặc sau "ni")So sánhCắt tỉaGiả thuyết tốt nhất thứ k hiện tại…Log-xác suất của chuỗi từ  đến token hiện tạiϵ(Điều kiện trên văn bản nguồn)(Điều kiện trên văn bản nguồn có marker)pi2=logP(ytmpli|ytmpl<i,xmark)bắt đầuLog-xác suất (-13.5) rơi dưới cận dưới (-2.8)ni[[Ang]-0.65-0.37-0.56-0.34FaransiniAngile
ϵ</s></s></s>

Hình 2: Hai bước đầu tiên của CODEC. Bước 1 (Trái): CODEC cắt tỉa các nhánh tìm kiếm dựa trên các vị trí marker mở không khả thi trong ngôn ngữ đích bằng cách so sánh xác suất được điều kiện hóa trên ngôn ngữ nguồn có và không có marker span được chèn. Bước 2 (Phải): Thuật toán tìm kiếm branch-and-bound được sử dụng để tìm k giả thuyết với xác suất cao nhất (k= 3). Từ mỗi nút của cây tìm kiếm (ví dụ: "Faransi"), CODEC mở rộng tới token tiếp theo từ template dịch thuật ytmpl (ví dụ: "ni") hoặc một marker (tức là "[" hoặc "]"). Một nhánh tìm kiếm được cắt tỉa nếu điểm của nó rơi dưới cận dưới heuristic. Hai nhánh có độ dài khác nhau có thể có giá trị cận dưới khác nhau (ví dụ: cận dưới cho nhánh trên và dưới lần lượt là -3.1 và -2.8).

3.1 XẤP XỈ BÀI TOÁN
Như đã thảo luận trong §2, nếu chúng ta chiếu một cách ngây thơ m span nhãn vào template dịch thuật ytmpl, không gian nghiên cứu Y có kích thước O(n²m) trong đó n là số token trong ytmpl. Do đó, thay vì giải quyết bài toán m-chiếu này, chúng tôi đề xuất giải quyết m bài toán 1-chiếu, không gian tìm kiếm của mỗi bài toán là C(n+2,2) hoặc O(n²), và xấp xỉ giải pháp gốc bằng cách kết hợp các giải pháp từ m bài toán. Nói cách khác, chúng tôi sẽ chiếu m câu, mỗi câu chỉ chứa một span nhãn được bao quanh bởi một cặp marker. Xấp xỉ này cũng mang lại một ưu điểm khác, vì chỉ có một span được chiếu tại một thời điểm, chúng ta có thể xác định nhãn của span (ví dụ: loại thực thể) trên ngôn ngữ đích mà không cần bước khớp nhãn như trong EasyProject (xem Hình 1a).

3.2 CẮT TỈA CÁC VỊ TRÍ MARKER-MỞ
Để giảm thêm không gian tìm kiếm và tăng tốc thuật toán giải mã, chúng tôi đề xuất phương pháp heuristic để phát hiện vị trí nào trong template dịch thuật có thể được chèn marker mở (ví dụ: dấu ngoặc vuông trái '['). Trong quá trình tìm kiếm, tất cả giả thuyết có marker mở được chèn tại các vị trí khác sẽ bị cắt tỉa. Ý tưởng chính của phương pháp chúng tôi là theo dõi sự khác biệt trong xác suất có điều kiện của từ (chính xác hơn là token từ phụ) để sinh ra cùng một template dịch thuật, khi được điều kiện hóa trên hai đầu vào khác nhau: câu nguồn có và không có marker. Trực giác là, nếu chúng ta giải mã template dịch thuật nhưng được điều kiện hóa trên câu marker, tại vị trí cần được chèn marker mở, mô hình sẽ đưa ra xác suất cao cho token này, và do đó, nó sẽ gán xác suất thấp cho token từ template. Trực giác này được minh họa trong Hình 2 (Bước 1). Hình thức, chúng tôi định nghĩa Δi là sự khác biệt của hai log-xác suất khi sinh token thứ i từ template:

Δi = |logP(ytmpli|ytmpl<i, xmark) - logP(ytmpli|ytmpl<i, x)| (5)

trong đó ytmpl<i chỉ tất cả token trước token thứ i và, từ đây trở đi, P được sử dụng thay cho Pτ để đơn giản. Chúng tôi xác định các vị trí có thể của marker mở bằng cách chọn tất cả i với giá trị Δi cao (tức là lớn hơn ngưỡng). Tất cả giả thuyết có marker mở được chèn tại các vị trí khác sẽ bị cắt tỉa trong quá trình tìm kiếm.

3.3 TÌM KIẾM CÁC GIẢ THUYẾT TOP-K
Theo nghiên cứu sơ bộ của chúng tôi, giả thuyết có xác suất cao nhất trong nhiều trường hợp không nhất thiết là đầu ra tốt nhất, tức là giả thuyết có marker được chèn đúng cách. Điều này thường được gọi là

--- TRANG 5 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2024
lỗi mô hình (dịch thuật) trong nghiên cứu dịch máy, trái ngược với lỗi tìm kiếm, nơi chuỗi có điểm cao nhất là bản dịch tốt nhưng thuật toán giải mã (thường là tìm kiếm xấp xỉ) không tìm được nó. Nghiên cứu trước đây về giải mã dịch thuật (Stahlberg & Byrne, 2019; Eikema & Aziz, 2020) cũng phát hiện rằng lỗi mô hình xảy ra rất thường xuyên khi sử dụng tìm kiếm chính xác.

Để giải quyết vấn đề này, chúng tôi đề xuất đầu tiên tìm k giả thuyết top với xác suất cao nhất, sau đó sử dụng hàm xếp hạng (chi tiết trong §3.4) để chọn giả thuyết tốt nhất (tức là xếp hạng lại). Ý tưởng chính là duyệt toàn bộ không gian tìm kiếm theo thứ tự depth-first và áp dụng phương pháp branch-and-bound (Stahlberg & Byrne, 2019) để giảm thời gian giải mã — xem Hình 2 để minh họa. So với thuật toán tìm kiếm trong công trình trước đây (Stahlberg & Byrne, 2019), CODEC sử dụng chiến lược tìm kiếm khác nhau để thực thi các ràng buộc bổ sung cho chiếu nhãn. Cụ thể hơn, để văn bản được sinh ra tuân theo template dịch thuật, tại mỗi lần lặp giải mã, sơ đồ giải mã chỉ xem xét tối đa hai ứng cử viên cho token tiếp theo: token tiếp theo từ template và marker span tiếp theo. Bên cạnh chiến lược tìm kiếm, CODEC cũng giới thiệu cận dưới heuristic mới.

Trước khi trình bày cận dưới của CODEC, chúng tôi thảo luận về cận được giới thiệu bởi Stahlberg & Byrne (2019) và lý do tại sao chúng tôi cần định nghĩa cận dưới mới cho nhiệm vụ này. Mục đích của cận dưới là cắt tỉa các nhánh không có bất kỳ giải pháp nào với điểm số tốt hơn. Điểm số của một nhánh, đã mở rộng một chuỗi đến độ dài j (tức là y1:j), là log-xác suất sinh của chuỗi này (tức là logP(y1:j|xmark) = Σ_{i=1}^j logP(yi|y<i, xmark)). Công trình trước đây đã định nghĩa cận dưới chính xác là log-xác suất của giả thuyết tốt nhất hiện tại. Nói chung, gọi yk là giả thuyết có log-xác suất cao thứ k tại thời điểm cụ thể trong quá trình tìm kiếm (k = 1 khi chỉ cần tìm giả thuyết tốt nhất). Gọi Lk là danh sách chứa log-xác suất sinh của tất cả tiền tố của yk (tức là Lk_j = log P(yk_{1:j}|xmark)). Cận dưới chính xác được định nghĩa là:

γexact = Lk_{|yk|} (6)

Một vấn đề với cận dưới chính xác là nó sử dụng xác suất của giả thuyết hoàn chỉnh (tức là giả thuyết kết thúc bằng </s>) để định nghĩa cận dưới. Xác suất này thường nhỏ, và do đó không thể cắt tỉa các giả thuyết một phần ngắn đủ sớm. Như được minh họa trong Hình 2 (Bước 2), cận dưới chính xác với k = 3 tại giai đoạn tìm kiếm này là -36.7, nhỏ hơn nhiều so với log-xác suất của các giả thuyết một phần được mở rộng khác. Do đó, chúng tôi đề xuất cận dưới heuristic, có giá trị thay đổi theo độ dài của mỗi giả thuyết một phần (tức là có giá trị lớn hơn khi so sánh với các giả thuyết một phần ngắn hơn), để giúp đẩy nhanh việc cắt tỉa. Cận dưới heuristic cho giả thuyết một phần có độ dài j được định nghĩa là:

γ = Lk_d (7)
d = min(max(j+δ, q), |yk|) (8)

trong đó q là vị trí của marker mở trong yk (q = 0 nếu marker chưa được chọn) và δ là siêu tham số của cận dưới. Cận dưới với giá trị δ lớn hơn gần với cận dưới chính xác hơn. Với cận dưới mới, CODEC có thể cắt tỉa các giả thuyết mở rộng như được hiển thị trong Hình 2 (Bước 2).

3.4 XẾP HẠNG LẠI
Mục tiêu của bước này là chọn giả thuyết tốt nhất, có marker được chèn tại các vị trí đúng, trong số k ứng cử viên hàng đầu được tìm thấy ở bước trước (§3.3). Hai điểm số được sử dụng cho mục đích này: (i) điểm số mức giả thuyết: log-xác suất sinh của một giả thuyết (Eq 4) và (ii) điểm số mức span: log-xác suất sinh span gốc cho trước span nhãn được tìm thấy trong một giả thuyết. Cụ thể, cho span nhãn esrc trong câu nguồn, chúng ta có k giả thuyết chiếu esrc sang ngôn ngữ đích sau bước tìm kiếm. Gọi etgt_i là span nhãn được tìm thấy trong giả thuyết thứ i. Điểm số mức span của giả thuyết thứ i được định nghĩa là:

Sspan_i = log P(esrc|etgt_i) (9)

Cùng mô hình MT được sử dụng để tính toán cả điểm số mức giả thuyết và mức span. Các giả thuyết k đầu tiên được xếp hạng theo điểm số mức giả thuyết. Điểm số mức span sau đó được sử dụng để xếp hạng lại tất cả giả thuyết, có span nhãn bằng hoặc là chuỗi con của span nhãn của giả thuyết top-1 hiện tại. Giả thuyết tốt nhất là top-1 mới sau khi xếp hạng lại. Thêm chi tiết về CODEC có thể được tìm thấy trong Phụ lục §A.

--- TRANG 6 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2024
4 THÍ NGHIỆM
Chúng tôi đánh giá CODEC trên hai nhiệm vụ NLP chéo ngôn ngữ benchmark, bao gồm Nhận dạng Thực thể có Tên và Trích xuất Đối số Sự kiện, bao gồm tổng cộng 20 ngôn ngữ.

4.1 BỘ DỮ LIỆU
Đối với Nhận dạng Thực thể có Tên (NER), chúng tôi sử dụng CoNLL03 tiếng Anh (Tjong Kim Sang, 2002) làm dữ liệu train/dev và sử dụng MasakhaNER2.0 (Adelani et al., 2022) bao gồm dữ liệu có nhãn bởi con người cho 20 ngôn ngữ châu Phi làm dữ liệu kiểm tra. Theo Chen et al. (2023a), chúng tôi xem xét ba loại thực thể chính (tức là người, tổ chức và vị trí) trong bộ dữ liệu và bỏ qua Ghomala và Naija (hai ngôn ngữ mà NLLB không hỗ trợ). Chúng tôi tiến hành thí nghiệm trên MasakhaNER2.0, thay vì WikiANN (Pan et al., 2017), vì bộ dữ liệu sau được xây dựng tự động và chứa nhiều nhiễu hơn (Lignos et al., 2022). Đối với Trích xuất Đối số Sự kiện (EAE), chúng tôi sử dụng ACE-2005 (Doddington et al., 2004), một bộ dữ liệu đa ngôn ngữ bao gồm tiếng Anh, tiếng Trung và tiếng Ả Rập. Nhiệm vụ là xác định các đối số sự kiện và vai trò của chúng trong văn bản với các trigger sự kiện cho trước. Chúng tôi sử dụng tập huấn luyện tiếng Anh của CoNLL03 (Tjong Kim Sang, 2002) và ACE-2005 để làm ngôn ngữ nguồn thực hiện chuyển giao chéo ngôn ngữ cho các nhiệm vụ NER và EAE tương ứng.

4.2 CÀI ĐẶT THÍ NGHIỆM VÀ KẾT QUẢ
Thiết lập Chúng tôi sử dụng NLLB (No Language Left Behind) làm mô hình dịch thuật (Costa-juss `a et al., 2022) trong các thí nghiệm của chúng tôi. Chúng tôi tinh chỉnh mDeBERTa-v3 (276M) để hoạt động như một tagger NER theo (Chen et al., 2023a); và tinh chỉnh mT5-large (Xue et al., 2021) theo framework X-Gear (Huang et al., 2022) cho EAE. Để so sánh trực tiếp với công trình hiện có (Chen et al., 2023b;a; Huang et al., 2022), chúng tôi báo cáo điểm F1 trung bình trên năm seed ngẫu nhiên cho NER và ba seed ngẫu nhiên cho EAE. Thêm chi tiết được cung cấp trong Phụ lục §B.

Baseline Chúng tôi so sánh CODEC với các baseline sau: (1) EasyProject (Chen et al., 2023a): một phương pháp chiếu nhãn dựa trên marker tiên tiến; (2) Awes-align: một phương pháp chiếu nhãn dựa trên alignment, trong đó aligner từ tiên tiến (Dou & Neubig, 2021) được sử dụng để căn chỉnh các span văn bản giữa câu nguồn và đích; (3) FTEn: các mô hình đa ngôn ngữ (những mô hình được mô tả trong "Thiết lập" ở trên) được tinh chỉnh trực tiếp trên dữ liệu tiếng Anh, đã được chứng minh là baseline rất mạnh cho chuyển giao chéo ngôn ngữ; (4) GPT-4: trong nhiệm vụ NER chéo ngôn ngữ, chúng tôi cũng nhắc GPT-4-0613 (Achiam et al., 2023) chú thích mỗi từ sử dụng sơ đồ BIO, theo Chen et al. (2023b). Do hạn chế về chi phí, chúng tôi chỉ đánh giá GPT-4 trên 200 ví dụ cho mỗi ngôn ngữ của MasakhaNER2.0. EasyProject sử dụng mô hình NLLB được tinh chỉnh trên bộ dữ liệu tổng hợp làm mô hình MT, trong đó các cặp marker được chèn xung quanh các span nhãn trong cả câu nguồn và đích. Chúng tôi cũng sử dụng phiên bản tinh chỉnh của NLLB-600M mà họ cung cấp trong CODEC để so sánh công bằng hơn.

Kết quả Bảng 1 cho thấy hiệu suất của các phương pháp khác nhau trên tập kiểm tra của MasakhaNER2.0. Trung bình, các phương pháp chiếu nhãn vượt trội so với cả GPT-4 và FT En với biên độ lớn. Trong số các phương pháp chiếu nhãn, CODEC đạt kết quả tốt nhất trong cả môi trường translate-train và translate-test, trung bình. So với EasyProject, một phương pháp tương tự CODEC nhưng sử dụng thuật toán giải mã khác, CODEC đã đạt hiệu suất tốt hơn hoặc tương đương trong hầu hết các ngôn ngữ, với cải thiện ít nhất 1.5 F1 trong chín ngôn ngữ. Sự cải thiện đặc biệt rõ ràng đối với ngôn ngữ chiShona, là +16.5 F1. Có chất lượng dịch thuật cao hơn có thể là lý do tại sao CODEC có thể vượt trội so với EasyProject trong nhiều ngôn ngữ. Một vấn đề đáng chú ý với bản dịch của EasyProject là các span nhãn thường xuyên bị để nguyên không dịch (tương tự như ví dụ trong Hình 1a). Các loại lỗi khác từ EasyProject và Awes-align được minh họa trong Hình 4 trong Phụ lục. Ngoài ra, chúng tôi quan sát thấy rằng NER chéo ngôn ngữ trong các ngôn ngữ châu Phi ưa thích phương pháp translate-test hơn translate-train nhìn chung. So với khi được sử dụng trong môi trường translate-train, cả CODEC và Awes-align đều có sự tăng đáng kể trong translate-test. Trong môi trường translate-test, CODEC cũng cho thấy kết quả tốt hơn so với phương pháp sau trong 13 trong số 18 ngôn ngữ. Một quan sát thú vị khác là FT En đạt hiệu suất tốt nhất trong Chichewa và Kiswahili, có thể vì các thực thể trong hai ngôn ngữ này thường được giữ nguyên như dạng tiếng Anh của chúng. Do đó, tinh chỉnh mô hình NER chỉ trên dữ liệu tiếng Anh là đủ cho hai ngôn ngữ này

--- TRANG 7 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2024
Bảng 1: Kết quả NER chéo ngôn ngữ trên tập kiểm tra của MasakhaNER2.0 (điểm F1 tốt nhất của một ngôn ngữ được in đậm, ∆FT: được tính so với FTEn, †: GPT-4 được đánh giá trên một tập con 200 ví dụ từ tập kiểm tra của mỗi ngôn ngữ do hạn chế về chi phí). Trung bình, CODEC vượt trội so với các phương pháp khác với biên độ lớn đặc biệt khi được sử dụng với chiến lược translate-test; EasyProject không áp dụng được cho translate-test.

Lang. GPT-4†FTEnTranslate-train Translate-test
Awes-align EasyProject CODEC (∆FT) Awes-align CODEC (∆FT)
Bambara 46.8 37.1 45.0 45.8 45.8 (+8.7) 50.0 55.6 (+18.5)
Ewe 75.5 75.3 78.3 78.5 79.1 (+3.8) 72.5 79.1 (+3.8)
Fon 19.4 49.6 59.3 61.4 65.5 (+15.9) 62.8 61.4 (+11.8)
Hausa 70.7 71.7 72.7 72.2 72.4 (+0.7) 70.0 73.7 (+2.0)
Igbo 51.7 59.3 63.5 65.6 70.9 (+11.6) 77.2 72.8 (+13.5)
Kinyarwanda 59.1 66.4 63.2 71.0 71.2 (+4.8) 64.9 78.0 (+11.6)
Luganda 73.7 75.3 77.7 76.7 77.2 (+1.9) 82.4 82.3 (+7.0)
Luo 55.2 35.8 46.5 50.2 49.6 (+13.8) 52.6 52.9 (+17.1)
Mossi 44.2 45.0 52.2 53.1 55.6 (+10.6) 48.4 50.4 (+5.4)
Chichewa 75.8 79.5 75.1 75.3 76.8 (-2.7) 78.0 76.8 (-2.7)
chiShona 66.8 35.2 69.5 55.9 72.4 (+37.2) 67.0 78.4 (+43.2)
Kiswahili 82.6 87.7 82.4 83.6 83.1 (-4.6) 80.2 81.5 (-6.2)
Setswana 62.0 64.8 73.8 74.0 74.7 (+9.9) 81.4 80.3 (+15.5)
Akan/Twi 52.9 50.1 62.7 65.3 64.6 (+14.5) 72.6 73.5 (+23.4)
Wolof 62.6 44.2 54.5 58.9 63.1 (+18.9) 58.1 67.2 (+23.0)
isiXhosa 69.5 24.0 61.7 71.1 70.4 (+46.4) 52.7 69.2 (+45.2)
Yoruba 58.2 36.0 38.1 36.8 41.4 (+5.4) 49.1 58.0 (+22.0)
isiZulu 60.2 43.9 68.9 73.0 74.8 (+30.9) 64.1 76.9 (+33.0)
TRUNG BÌNH 60.4 54.5 63.6 64.9 67.1 (+12.7) 65.8 70.4 (+16.0)

trong môi trường này. Đối với nhiệm vụ EAE, chúng tôi quan sát xu hướng tương tự trong Bảng 2 rằng CODEC vượt trội so với các phương pháp chiếu nhãn khác trung bình. Trong mỗi ngôn ngữ, CODEC cũng có hiệu suất tương đương hoặc tốt hơn so với mỗi baseline. Chúng tôi chỉ báo cáo hiệu suất trong môi trường translate-train cho nhiệm vụ EAE, vì thiết lập thí nghiệm điển hình yêu cầu event trigger vàng làm đầu vào, nhưng đối với translate-test, thông tin này bằng tiếng Anh chỉ có thể đạt được bằng một lượt chiếu nhãn khác (từ ngôn ngữ đích sang tiếng Anh) trong thời gian suy luận. Thêm thảo luận về hai nhiệm vụ chéo ngôn ngữ có trong Phụ lục C, D.

4.3 NGHIÊN CỨU ABLATION
Trong phần này, chúng tôi nghiên cứu hiệu quả và độ chính xác của hai bước heuristic trong CODEC.

Bảng 2: Điểm F1 của các phương pháp khác nhau trên bộ dữ liệu ACE-2005 trong môi trường translate-train.

Lang. FT enAwes-align EasyProject CODEC
Tiếng Ả Rập 44.8 48.3 45.4 48.4
Tiếng Trung 54.0 57.3 59.7 59.1
TRUNG BÌNH 49.4 52.8 52.6 53.8

Thiết lập Chúng tôi sửa đổi từng module của CODEC và đánh giá hiệu suất của mỗi thiết lập trong translate-dev trên một mẫu tập dev MasakhaNER2.0 cho năm ngôn ngữ (tức là Bambara, Fon, Mossi, Yoruba và isiZulu). Chúng tôi đánh giá hiệu suất của exact (+re rank): thuật toán tìm kiếm chính xác, tương tự CODEC ngoại trừ việc sử dụng cận dưới chính xác (được thảo luận trong §3) và không cắt tỉa các vị trí marker mở; exact: tương tự exact (+re rank) nhưng không tiến hành xếp hạng lại và chỉ trả về giả thuyết có xác suất cao nhất; CODEC (δ=1), CODEC (δ=3): CODEC với giá trị khác nhau của δ, siêu tham số của cận dưới heuristic trong Eq. (8); CODEC (δ=1+[), CODEC (δ=3+[): CODEC với giá trị khác nhau của δ và thực hiện cắt tỉa các vị trí marker-mở. Vì tìm kiếm chính xác mất thời gian cực kỳ lâu để hoàn thành, chúng tôi chỉ lấy mẫu 100 ví dụ với tối đa 5 span nhãn cho mỗi ngôn ngữ.

Kết quả Hiệu suất và thời gian giải mã của các thiết lập tìm kiếm khác nhau được hiển thị trong Hình 3a và Hình 3b tương ứng. Thứ nhất, so với exact (+re-rank), việc chỉ trả về giả thuyết có xác suất cao nhất (exact) dẫn đến sự giảm đáng kể về hiệu suất trong tất cả các ngôn ngữ. Quan sát này cho thấy sự cần thiết của bước xếp hạng lại để chọn giả thuyết tốt nhất. Về mặt cận dưới heuristic, CODEC (δ=3) có F1 gần như giống với exact (+re-rank), cho thấy rằng cận dưới heuristic với δ = 3 là một xấp xỉ tốt của cận dưới chính xác trong khi có tốc độ giải mã tốt hơn nhiều. Cuối cùng, việc cắt tỉa các vị trí marker mở còn tăng tốc

--- TRANG 8 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2024
bam fon mos yor zul455055606570F1 (%)exact (+re-rank)
exactCodec (=1)
Codec (=3)
Codec (=1+[)
Codec (=3+[)
(a) Điểm F1 trên tập dev (translate-dev).
bam fon mos yor zul5102050100200300500700thời gian (s)exact (+re-rank)
Codec (=1)
Codec (=3)
Codec (=1+[)
Codec (=3+[)
(b) Thời gian giải mã trung bình mỗi ví dụ.

Hình 3: Nghiên cứu ablation trên tập dev MasakhaNER2.0 của các thiết lập tìm kiếm khác nhau cho năm ngôn ngữ, bao gồm Bambara (bam), Fon (fon), Mossi (mos), Yoruba (yor) và isiZulu (zul). exact (+re-rank): tìm kiếm chính xác với xếp hạng lại; exact: tìm kiếm chính xác và trả về giả thuyết top-1. 'δ' là siêu tham số của cận dưới heuristic. '+[' chỉ việc cắt tỉa các vị trí marker-mở không khả thi trước. So với giải mã có ràng buộc với tìm kiếm chính xác, CODEC với δ = 3 giảm đáng kể thời gian giải mã, trong khi duy trì hiệu suất được đo bằng điểm F1.

tốc độ giải mã ít nhất khoảng 1.4 lần khi δ = 3, trong khi chỉ gây ra sự giảm nhẹ về F1 (sự giảm lớn nhất là 0.7 F1 tuyệt đối trong Yoruba). Một quan sát thú vị là việc cắt tỉa vị trí marker-mở có thể có thể cải thiện hiệu suất trong nhiều trường hợp (tức là tất cả các ngôn ngữ khi δ = 1; Fon, Mossi và isiZulu khi δ = 3). Một giải thích là mô hình dịch thuật không hoàn hảo và có thể đưa ra xác suất cao cho các giả thuyết xấu, đôi khi thậm chí cao hơn xác suất của giả thuyết đúng. Với bước cắt tỉa vị trí marker, những giả thuyết nhiễu đó được tránh. Thêm phân tích về CODEC có trong Phụ lục E.

5 ĐÁNH GIÁ THỦ CÔNG CODEC VÀ THẢO LUẬN
Trong phần này, chúng tôi phân tích hành vi của từng thành phần con trong CODEC. Cụ thể, chúng tôi kiểm tra thủ công đầu ra của CODEC khi được sử dụng trong môi trường translate-train và translate-test cho nhiệm vụ NER chéo ngôn ngữ từ tiếng Anh sang tiếng Trung và tiếng Việt (100 ví dụ được kiểm tra cho mỗi ngôn ngữ). Chúng tôi phân loại chúng thành các loại lỗi dựa trên nguồn lỗi: (1) Dịch thuật: lỗi từ mô hình MT, (2) NER: lỗi từ tagger NER (chỉ translate-test), (3) CODEC: lỗi từ CODEC. Đối với tất cả các nghiên cứu, chúng tôi sử dụng bản dịch từ API Google Translation (GMT)² (có chất lượng dịch thuật tốt hơn cho hai ngôn ngữ này) để tập trung phân tích vào CODEC, thay vì hệ thống MT. Ngoài ra, chúng tôi cũng kiểm tra đầu ra của CODEC trong các tình huống khi đầu ra từ mô hình MT và NER tagger hoàn hảo (tức là Oracle). Thêm chi tiết được cung cấp trong Phụ lục §F.

Kết quả Từ Bảng 3, chúng ta thấy rằng có một lượng lỗi đáng kể từ CODEC trong tiếng Trung. Kiểm tra thêm các đầu ra lỗi từ CODEC, chúng tôi quan sát thấy rằng trong hơn 60% các trường hợp, giả thuyết đúng nằm trong top-k được tìm thấy bởi CODEC, nhưng bước xếp hạng lại không lấy được nó. Do đó, nghiên cứu cách chọn giả thuyết tốt nhất là một hướng đầy hứa hẹn để cải thiện CODEC hơn nữa. Cũng từ bảng, có nhiều lỗi từ các mô hình MT trong môi trường translate-test. Trong tiếng Việt, hầu hết lỗi dịch thuật là dịch sai thực thể, trong khi ở tiếng Trung, hầu hết thời gian, lỗi không phải do dịch sai mà là phong cách dịch thuật. Cụ thể, các phong cách dịch khác nhau sang tiếng Anh có thể thay đổi loại thực thể, ví dụ: "Chinese MISC journalists" và "journalists from China LOC" có thể là bản dịch từ cùng một văn bản, nhưng có các loại thực thể khác nhau. Một hướng có thể để giải quyết vấn đề này là sử dụng giải mã có ràng buộc để kiểm soát phong cách dịch thuật (ví dụ: sử dụng từ có nghĩa là quốc gia thay vì quốc tịch).

6 CÔNG TRÌNH LIÊN QUAN
Chiếu Nhãn Đã có nghiên cứu liên quan đến việc chiếu các span nhãn giữa các văn bản song song đa ngôn ngữ cho chuyển giao chéo ngôn ngữ. Một phương pháp phổ biến là sử dụng các mô hình căn chỉnh từ để

² https://cloud.google.com/translate

--- TRANG 9 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2024
Bảng 3: Phân tích thủ công đầu ra CODEC trong môi trường translate-train và translate-test cho tiếng Việt và tiếng Trung. Số lượng chỉ ra có bao nhiêu ví dụ trong số 100 được lấy mẫu cho mỗi ngôn ngữ là chính xác hoặc có lỗi tương ứng (một ví dụ có thể có nhiều hơn một lỗi).

Language MTTranslate-train Translate-test
Đúng Dịch thuật CODEC Đúng NER Dịch thuật CODEC
Tiếng ViệtGMT 94 2 4 51 33 14 13
Oracle 96 0 4 85 0 0 15
Tiếng TrungGMT 80 6 14 34 36 24 16
Oracle 83 0 16 69 0 0 31

chiếu span nhãn giữa câu nguồn và đích. Phương pháp này đã được áp dụng cho nhiều nhiệm vụ rộng rãi: Gán nhãn Từ loại (Yarowsky & Ngai, 2001; Duong et al., 2013; Eskander et al., 2020), Gán nhãn Vai trò Ngữ nghĩa (Akbik et al., 2015; Fei et al., 2020), Nhận dạng Thực thể có Tên (Ni et al., 2017; Stengel-Eskin et al., 2019; García-Ferrero et al., 2023; Behzad et al., 2023), và Điền Slot (Xu et al., 2020). Với sự tiến bộ của các hệ thống MT, một số nỗ lực gần đây đã áp dụng phương pháp dựa trên marker, sử dụng trực tiếp hệ thống MT để thực hiện chiếu nhãn (Lee et al., 2018; Lewis et al., 2020; Hu et al., 2020; Bornea et al., 2021; Chen et al., 2023a). Giữa hai hướng, phương pháp dựa trên alignment có tính thích ứng hơn về mặt áp dụng cho cả translate-train và translate-test, và có thể bảo toàn chất lượng dịch thuật; tuy nhiên, nó được chứng minh là kém chính xác hơn so với phương pháp dựa trên marker (Chen et al., 2023a). CODEC có ưu điểm của cả hai phương pháp. Cũng có nghiên cứu theo hướng khác để chuyển giao span nhãn, Daza & Frank (2019) trình bày mô hình encoder-decoder để dịch và sinh nhãn Vai trò Ngữ nghĩa trên câu đích cùng lúc, trong khi Guo & Roth (2021) đề xuất sử dụng giải mã có ràng buộc để xây dựng câu đích từ các thực thể có nhãn đã dịch trước. Song song với công trình của chúng tôi, Parekh et al. (2023) cũng đề xuất dịch câu gốc không có marker, trước khi chiếu nhãn, để giải quyết vấn đề suy giảm chất lượng dịch thuật. Ngoài việc có quyền truy cập vào hệ thống dịch thuật, phương pháp của họ yêu cầu mô hình ngôn ngữ lớn được điều chỉnh hướng dẫn (hiện không có sẵn trong nhiều ngôn ngữ) để phát hiện các span nhãn trong ngôn ngữ đích. Khác với phương pháp của họ, chúng tôi áp dụng phương pháp dựa trên giải mã có ràng buộc, chỉ yêu cầu mô hình dịch thuật, như NLLB, có thể hỗ trợ phạm vi rộng hơn nhiều các ngôn ngữ ít tài nguyên. Ngoài chủ đề chiếu nhãn, Razumovskaia et al. (2023) chia sẻ ý tưởng tương tự về việc tái sử dụng mô hình đa ngôn ngữ với chúng tôi, và giới thiệu framework hai giai đoạn để thích ứng các encoder đa ngôn ngữ với nhiệm vụ gán nhãn slot, trong các tình huống transfer-free, nơi không có dữ liệu tiếng Anh có chú thích sẵn.

Giải mã có ràng buộc từ vựng Trong khi giải mã có ràng buộc đã được khám phá trước đây trong dịch máy và sinh văn bản, nó thường được sử dụng để ràng buộc từ vựng hoặc độ dài của đầu ra (Anderson et al., 2017; Hokamp & Liu, 2017; Post & Vilar, 2018; Miao et al., 2019; Zhang et al., 2020; Lu et al., 2021; 2022; Qin et al., 2022). So với các công trình trước đây này, CODEC có một số đặc điểm quan trọng làm cho nó phù hợp hơn cho bài toán chiếu nhãn. Thứ nhất, thay vì chỉ ràng buộc sự xuất hiện của một số từ, CODEC ràng buộc toàn bộ câu giải mã tuân theo template được định nghĩa trước. Đặc điểm này quan trọng vì nó cho phép CODEC thực hiện chiếu tới câu đích cố định, đó là yêu cầu để áp dụng được cho translate-test và bảo toàn chất lượng dịch thuật trong translate-train. Thứ hai, CODEC cũng ràng buộc số lần xuất hiện của mỗi token, bao gồm marker, điều này cần thiết vì nó ngăn mô hình sinh bỏ qua marker, giải quyết vấn đề nghiêm trọng với phương pháp dựa trên marker cho chiếu nhãn. Ý tưởng sử dụng giải mã có ràng buộc để đảm bảo tính hợp lệ của không gian đầu ra cũng đã được áp dụng trong nhiệm vụ phân tích cú pháp ngữ nghĩa (Scholak et al., 2021).

7 KẾT LUẬN
Trong công trình này, chúng tôi đã giới thiệu phương pháp mới sử dụng giải mã có ràng buộc cho chiếu nhãn chéo ngôn ngữ. Phương pháp mới của chúng tôi – CODEC – không chỉ giải quyết vấn đề suy giảm chất lượng dịch thuật, là vấn đề chính của các phương pháp chiếu nhãn dựa trên marker trước đây, mà còn có tính thích ứng về mặt áp dụng cho cả translate-train và translate-test. Thí nghiệm trên hai nhiệm vụ chéo ngôn ngữ trên 20 ngôn ngữ cho thấy rằng, trung bình, CODEC đã thể hiện sự cải thiện so với baseline tinh chỉnh mạnh và các phương pháp chiếu nhãn khác.

--- TRANG 10 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2024
8 LỜI CẢM ƠN
Chúng tôi muốn cảm ơn Vedaant Shah đã giúp chúng tôi với các thí nghiệm GPT-4, và chúng tôi cũng cảm ơn bốn người đánh giá ẩn danh vì phản hồi hữu ích của họ về công trình này. Nghiên cứu này được hỗ trợ bởi NSF (IIS-2052498) và IARPA thông qua chương trình HIATUS (2022-22072200004). Các quan điểm và kết luận được chứa trong tài liệu này là của các tác giả và không nên được diễn giải như nhất thiết đại diện cho các chính sách chính thức, được thể hiện rõ ràng hoặc ngụ ý, của NSF, ODNI, IARPA, hoặc Chính phủ Hoa Kỳ. Chính phủ Hoa Kỳ được ủy quyền tái tạo và phân phối các bản in lại cho mục đích chính phủ mặc dù có bất kỳ chú thích bản quyền nào trong đó.

TÀI LIỆU THAM KHẢO
Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et al. Gpt-4 technical report. arXiv preprint arXiv:2303.08774, 2023.

David Adelani, Graham Neubig, Sebastian Ruder, Shruti Rijhwani, Michael Beukman, Chester Palen-Michel, Constantine Lignos, Jesujoba Alabi, Shamsuddeen Muhammad, Peter Nabende, Cheikh M. Bamba Dione, Andiswa Bukula, Rooweither Mabuya, Bonaventure F. P. Dossou, Blessing Sibanda, Happy Buzaaba, Jonathan Mukiibi, Godson Kalipe, Derguene Mbaye, Amelia Taylor, Fatoumata Kabore, Chris Chinenye Emezue, Anuoluwapo Aremu, Perez Ogayo, Catherine Gitau, Edwin Munkoh-Buabeng, Victoire Memdjokam Koagne, Allahsera Auguste Tapo, Tebogo Macucwa, Vukosi Marivate, Mboning Tchiaze Elvis, Tajuddeen Gwadabe, Tosin Adewumi, Orevaoghene Ahia, Joyce Nakatumba-Nabende, Neo Lerato Mokono, Ignatius Ezeani, Chiamaka Chukwuneke, Mofetoluwa Oluwaseun Adeyemi, Gilles Quentin Hacheme, Idris Abdulmumin, Odunayo Ogundepo, Oreen Yousuf, Tatiana Moteu, và Dietrich Klakow. MasakhaNER 2.0: Africa-centric transfer learning for named entity recognition. In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pp. 4488–4508, Abu Dhabi, United Arab Emirates, December 2022. Association for Computational Linguistics. URL https://aclanthology.org/2022.emnlp-main.298.

[Tiếp tục với các tài liệu tham khảo khác...]

--- TRANG 11 đến TRANG 21 ---
[Tiếp tục nội dung của các trang còn lại với cùng định dạng dịch thuật...]

Kỹ thuật Tăng cường Dữ liệu Dựa trên Từ điển Có nhận thức Hình thái học
cho Dịch máy của các Ngôn ngữ Thiếu đại diện

Md Mahfuz Ibn AlamαSina Ahmadiα,βAntonios Anastasopoulosα,γ
αKhoa Khoa học Máy tính, Đại học George MasonβĐại học Zurich
γĐơn vị Nghiên cứu AI Archimedes, RC Athena, Hy Lạp
{malam21,sahmad46,antonis}@gmu.edu

Tóm tắt
Việc có sẵn các văn bản song song là rất quan trọng đối với hiệu suất của các mô hình dịch máy. Tuy nhiên, hầu hết các ngôn ngữ trên thế giới đều đối mặt với thách thức chủ yếu là thiếu dữ liệu. Trong bài báo này, chúng tôi đề xuất các chiến lược để tổng hợp dữ liệu song song dựa trên thông tin hình thái-cú pháp và sử dụng từ điển song ngữ cùng với một lượng nhỏ dữ liệu song song gốc. Phương pháp của chúng tôi tuân thủ một kịch bản thực tế được hỗ trợ bởi dữ liệu gốc song song nhỏ. Nó được thông báo về mặt ngôn ngữ học, vì nó nhằm tạo ra dữ liệu tăng cường có khả năng đúng ngữ pháp cao hơn. Chúng tôi phân tích cách dữ liệu tổng hợp của chúng tôi có thể được kết hợp với dữ liệu song song thô và chứng minh sự cải thiện nhất quán về hiệu suất trong các thí nghiệm của chúng tôi trên 14 ngôn ngữ (28 cặp Tiếng Anh ↔X) từ những ngôn ngữ có tài nguyên tốt đến rất ít tài nguyên. Phương pháp của chúng tôi dẫn đến cải thiện ngay cả khi chỉ sử dụng năm câu gốc và một từ điển song ngữ.

1 Giới thiệu
Một trong những thách thức lớn trong dịch máy (MT) là thiếu dữ liệu song song cho hầu hết các ngôn ngữ trên thế giới. Các phương pháp truyền thống (Wu et al., 2008; Mikolov et al., 2013) từng dựa vào từ điển và kiến thức ngôn ngữ học cho MT. Một trong những cách ngây thơ để sử dụng từ điển cho MT là dịch bằng cách tra cứu các từ của câu nguồn trong từ điển song ngữ và thay thế các bản dịch tương ứng của chúng trong ngôn ngữ đích. Tuy nhiên, phương pháp này có những thiếu sót nhất định (Wang et al., 2022a). Thứ nhất, phạm vi bao phủ của các bản dịch phụ thuộc vào kích thước và tính toàn diện của từ điển, điều này có thể dẫn đến các bản dịch không đầy đủ và các phiên bản trộn mã của ngôn ngữ nguồn và đích. Các câu được dịch cũng có thể không tuân thủ các quy tắc ngữ pháp hoặc thứ tự từ của ngôn ngữ đích. Hơn nữa, hầu hết các từ điển hoạt động ở cấp độ từ gốc, tạo ra thách thức cho các ngôn ngữ giàu hình thái học. Do đó, việc chỉ dựa vào từ điển không phải là giải pháp khả thi cho các ngôn ngữ ít tài nguyên.

Anh ấy chơi ghi ta rất giỏi    Ew gîtarê pir baş lêdide
Phân tích: guitar = [N;ACC;SG, lemma= GUITAR]
Thay thế: GUITAR ←FLOWER, FLOWER =GUL
Tạo ra: [N;ACC;SG, lemma= GUL]→gulê
Anh ấy chơi hoa rất giỏi    Ew gulê pir baş lê dide

Hình 1: Một sơ đồ của phương pháp chúng tôi. Sau khi căn chỉnh 'guitar' (trong tiếng Anh) và 'gîtarê' (trong tiếng Kurmanji Kurdish), từ mới 'flower' được chọn ngẫu nhiên để thay thế 'guitar' và bản dịch của nó 'gul' trong từ điển song ngữ được biến đổi theo các đặc điểm hình thái học của nó thành 'gulê'. Chữ viết hoa nhỏ đề cập đến từ gốc.

Trong các phương pháp gần đây đối với MT chủ yếu dựa vào các mạng mã hóa-giải mã như transformers (Vaswani et al., 2017), kịch bản lý tưởng là huấn luyện một mô hình MT trên một kho ngữ liệu song song lớn. Tuy nhiên, việc tạo ra một kho ngữ liệu song song cho một ngôn ngữ cụ thể đòi hỏi chuyên môn ngôn ngữ học và kỹ thuật mà các ngôn ngữ thiếu tài nguyên thiếu và cũng là một nhiệm vụ tốn kém và mất thời gian. Để khắc phục điều này, các nghiên cứu gần đây trong xử lý ngôn ngữ tự nhiên (NLP) tập trung vào các phương pháp không giám sát dựa trên dữ liệu đơn ngữ (Sennrich et al., 2016a; Lample et al., 2018a), dịch ngược (Edunov et al., 2018a,b), các kỹ thuật tăng cường dữ liệu khác (Sánchez-Cartagena et al., 2021), hoặc tinh chỉnh các mô hình được huấn luyện trước để thích ứng với một ngôn ngữ, lĩnh vực hoặc phương ngữ khác (Bapna and Firat, 2019). Do đó, việc sử dụng từ điển chủ yếu chưa được nghiên cứu, mặc dù chúng vẫn đang được sử dụng thực tế (Peng et al., 2020; Sennrich et al., 2016b).

Trong bài báo này, chúng tôi đưa ra một phương pháp dựa trên từ điển tương tự như các hệ thống MT dựa trên từ điển ban đầu (Tyers, 2009; Koehn and Knight, 2002, 2001; Sánchez-Cartagena et al., 2011) nhưng tinh vi hơn vì nó dựa vào phân tích hình thái-cú pháp của các từ để tạo ra một kho ngữ liệu song song một cách tổng hợp. Như được minh họa trong Hình 1, phương pháp của chúng tôi bao gồm bốn thành phần: căn chỉnh, phân tích, thay thế và tạo ra. Với một tập hợp nhỏ văn bản song song làm dữ liệu gốc, chúng tôi đầu tiên lấy các cặp dịch có thể ở cấp độ từ trong ngôn ngữ nguồn và đích như trong 'guitar' và 'gîtar' trong tiếng Anh và tiếng Kurmanji Kurdish tương ứng. Sau đó chúng tôi phân tích hình thái học các từ nguồn trong các cặp dịch, ví dụ, 'guitar' là một danh từ số ít ở trường hợp tân ngữ trong ví dụ. Với các đặc điểm hình thái học của một từ trong câu nguồn, chúng tôi bây giờ có thể lấy mẫu một từ từ từ điển song ngữ với cùng các đặc điểm hình thái học, ví dụ, gulê, và "cắm" nó vào câu của chúng tôi để tạo ra một cặp câu mới một cách tổng hợp. Như vậy, các câu được tạo ra tổng hợp có khả năng tạo ra các bản dịch mới có âm thanh ngữ pháp.

Tóm lại, đóng góp của công trình chúng tôi có ba khía cạnh:
• Chúng tôi đề xuất một phương pháp thay thế có thông tin hình thái học để tạo ra một câu tổng hợp mới.
• Chúng tôi chỉ ra rằng dữ liệu song song tổng hợp này giúp cải thiện chất lượng của hệ thống MT khi trộn với dữ liệu song song thực.
• Chúng tôi cũng chứng minh hiệu quả của phương pháp trong các kịch bản cực kỳ thiếu dữ liệu, nơi chỉ có năm câu gốc song song được làm cho hữu ích với phương pháp của chúng tôi.

Lưu ý rằng chúng tôi sẽ hoán đổi các thuật ngữ "từ điển" và "từ điển song ngữ" trong suốt bài báo vì lý do dễ đọc.

2 Phương pháp
Phương pháp của chúng tôi yêu cầu một tập dữ liệu song song nhỏ gọi là dữ liệu gốc chứa các câu trong ngôn ngữ nguồn và đích để tạo ra dữ liệu song song tổng hợp. Phương pháp của chúng tôi bao gồm ba thành phần. Chúng tôi đầu tiên chuẩn bị dữ liệu bằng cách tokenize các câu và thu được căn chỉnh ở cấp độ từ giữa các câu song song. Bước này được hoàn thành bằng cách phân tích hình thái học các cặp từ được căn chỉnh. Sau đó, chúng tôi thay thế các từ xem xét các đặc điểm hình thái học trong thành phần tăng cường và lọc các câu tổng hợp bằng cách sử dụng các mô hình ngôn ngữ. Cuối cùng, chúng tôi xây dựng các hệ thống MT trong các cài đặt khác nhau thay đổi số lượng câu tổng hợp.

2.1 Phân tích
Căn chỉnh Chúng tôi thực hiện căn chỉnh từ với dữ liệu gốc của chúng tôi, xác định mối quan hệ giữa các từ trong câu gốc. Điều này là cần thiết để biết những từ nào là bản dịch của nhau. Nếu chúng tôi thay thế một từ trong câu nguồn, từ đích được căn chỉnh của câu đích cũng phải được thay thế để phản ánh những thay đổi.

Gắn thẻ Hình thái học Chúng tôi phân tích các mục trong các từ phía nguồn của từ điển song ngữ để tạo thuận lợi cho quá trình tăng cường dữ liệu. Bằng cách này, chúng tôi có thể phân loại các mục dựa trên các đặc điểm hình thái học và tìm các thẻ từ loại (POS), ví dụ, ADJ, của các từ phía nguồn của từ điển song ngữ.

Lựa chọn Cặp từ Chúng tôi chọn ngẫu nhiên các từ từ phía nguồn, ở đây là tiếng Anh, cho mỗi câu gốc. Chúng tôi tham khảo Hình 1 làm ví dụ nơi chúng tôi tạo ra đặc điểm hình thái học và thẻ POS cho từ đã cho "guitar". Chúng tôi cũng tìm bản dịch của "guitar" trong phía đích của câu gốc. Ở đây, từ đó là "gîtarê", mà chúng tôi nhận được từ căn chỉnh trong §2.1. Chúng tôi cũng tìm đặc điểm hình thái học và thẻ POS của "gîtarê".

2.2 Tăng cường
Chúng tôi giới thiệu hai phương pháp khác nhau cho việc tăng cường các câu gốc:

Có thông tin Hình thái học
1. Tham khảo Hình 1, chúng tôi đầu tiên thay thế "guitar" với một từ ngẫu nhiên khác, ví dụ "flower", có các đặc điểm hình thái học giống hệt được tạo ra trong §2.1. Như vậy, một câu mới được tạo ra tổng hợp là "He plays the flower very well". Cần lưu ý rằng thủ tục này không xem xét sự liên quan về ngữ nghĩa của từ ứng viên. Nói cách khác, nó có thể tạo ra các câu vô nghĩa nhưng hợp lệ về mặt hình thái-cú pháp.

2. Sau đó, chúng tôi thay thế "gîtarê" bằng bản dịch của "flower" là "gul" trong tiếng Kurmanji Kurdish từ từ điển song ngữ. Điều đáng chú ý là chúng tôi sử dụng từ điển PanLex nơi một số mục không ở dạng từ gốc. Do đó, chúng tôi cũng lemmatize dạng từ được lấy ra trong từ điển, tức là "gul" để giảm thiểu tác động của tính không chính xác của dữ liệu từ điển.

3. Cuối cùng, chúng tôi thực hiện biến đổi hình thái học nơi một từ gốc được biến đổi dựa trên các đặc điểm hình thái học của từ sẽ được thay thế, tức là 'gîtar'. Làm điều này, chúng tôi tạo ra một câu mới nơi từ được chọn ngẫu nhiên trong từ điển 'gul' xuất hiện đúng ngữ pháp và hình thái học như 'gulê'. Chúng tôi làm điều này để đảm bảo rằng từ mới tuân theo các đặc điểm hình thái học đúng. Vì vậy tạo ra một bản dịch đích tổng hợp "Ew gulê pir baş lê dide" của câu nguồn tổng hợp "He plays the flower very well".

Ngây thơ Trái ngược với kỹ thuật tăng cường trước đó nơi chúng tôi xem xét các đặc điểm hình thái học, chúng tôi thực hiện một phương pháp thay thế từ ngẫu nhiên ngây thơ nơi chỉ có thẻ POS giống nhau, không có lemmatizing hoặc biến đổi từ dựa trên câu. Ví dụ trong Hình 1, một câu tổng hợp được tạo ra theo cách này sẽ là "He plays the flower very well" và bản dịch được tạo ra của nó "Ew gul pir baş lê dide". Ở đây "gul" đã không được chuyển đổi thành 'gulê'. Trong thiết lập Có thông tin Hình thái học, chúng tôi bảo tồn thông tin hình thái học của từ chúng tôi thay đổi, do đó làm cho dữ liệu tổng hợp có khả năng đúng ngữ pháp cao hơn. Trong phương pháp ngây thơ này, mặt khác, chúng tôi mất thông tin này.

2.3 Lọc với LMs
Chúng tôi tạo ra các câu tổng hợp cho mỗi câu gốc với các phương pháp tăng cường ở trên. Cho rằng các câu tổng hợp có thể không có ý nghĩa, ví dụ, "He plays the flower very well", chúng tôi cũng kết hợp thông tin từ một mô hình ngôn ngữ (LM) bằng cách ước tính độ phức tạp (ppl) của các câu tổng hợp:

ppl(x) = exp{−1/t∑ᵢlog pθ(xᵢ|x<ᵢ)},

Trong đó xác suất của một câu có độ dài t chứa các từ x tồn tại trong LM. Độ phức tạp càng thấp, câu càng tự nhiên. Chúng tôi lọc các câu được tăng cường bằng cách sử dụng LM và xếp hạng chúng dựa trên điểm số độ phức tạp để chọn các câu với ngữ cảnh đúng. Bước này tạo ra các câu có khả năng xuất hiện cao hơn với độ phức tạp thấp nhất.

2.4 Dịch máy Thần kinh
Sử dụng dữ liệu tổng hợp, chúng tôi xây dựng các hệ thống MT thần kinh cho mỗi cặp ngôn ngữ theo một hướng. Để làm như vậy, một trong những phương pháp là huấn luyện một mô hình mã hóa-giải mã dựa trên transformer từ đầu với trọng số ngẫu nhiên chỉ trên dữ liệu song song. Loại mô hình này xuất sắc trong các cài đặt có tài nguyên cao nhưng khó đạt được hiệu suất tốt cho các ngôn ngữ ít tài nguyên (Duh et al., 2020). Một phương pháp khác là tinh chỉnh một mô hình dựa trên một mô hình được huấn luyện trước. Thay vì khởi tạo với trọng số ngẫu nhiên, việc huấn luyện được thực hiện trên một mô hình transformer được huấn luyện trước đó. Mô hình được huấn luyện trước có thể là đơn ngữ hoặc đa ngữ và có thể được huấn luyện trước trên bất kỳ nhiệm vụ nào, thường là trên các nhiệm vụ khử nhiễu. Phương pháp này (Alabi et al., 2022) có triển vọng cải thiện các ngôn ngữ ít tài nguyên vì mô hình không cần phải học tất cả các thành phần ngôn ngữ từ đầu. Nếu mô hình được huấn luyện trước là đa ngữ, mô hình có thể tận dụng tài nguyên từ các ngôn ngữ có tài nguyên cao khác.

3 Thiết lập Thí nghiệm
3.1 Tập dữ liệu
Dữ liệu Song song Để tạo ra dữ liệu tổng hợp, chúng tôi sử dụng các câu song song trong kho ngữ liệu OPUS-100 (Zhang et al., 2020) với tiếng Anh làm ngôn ngữ nguồn và các ngôn ngữ khác làm ngôn ngữ đích. Chúng tôi sử dụng tập huấn luyện này làm dữ liệu gốc song song cho huấn luyện. Để kiểm tra và xác thực, chúng tôi sử dụng các tập devtest và dev của chuẩn FLORES-200 (Team et al., 2022) tương ứng. Bảng 1 tóm tắt thống kê của các tập dữ liệu của chúng tôi. Chúng tôi chia các ngôn ngữ thành bốn loại theo tính khả dụng dữ liệu của chúng: cực kỳ ít tài nguyên, ít tài nguyên, có tài nguyên tốt và có tài nguyên cao.

Từ điển Song ngữ Chúng tôi trích xuất từ điển giữa tiếng Anh và mỗi ngôn ngữ đích từ cơ sở dữ liệu PanLex chứa 25 triệu từ trong 2.500 từ điển của 5.700 ngôn ngữ.

Ngôn ngữ (mã) # Gốc # Mục
Armenian (HYE) 7,059 161,798
Wolof (WOL) 7,918 4,971
Kurmanji (KMR) 8,199 47,461
Scottish Gaelic (GLA) 16,316 51,416
Marathi (MAR) 27,007 65,559
Uyghur (UIG) 72,170 9,054
Kazakh (KAZ) 79,927 40,516
Tamil (TAM) 227,014 230,882
Irish (GLE) 289,524 71,436
Galician (GLG) 515,344 185,946
Hindi (HIN) 534,319 409,076
Urdu (URD) 753,913 86,695
Greek (ELL) 1,000,000 407,311
Maltese (MLT) 1,000,000 33,131

Bảng 1: Thống kê của các tập dữ liệu của chúng tôi (dữ liệu song song gốc và các mục từ điển). Được sắp xếp theo số lượng câu huấn luyện có sẵn.

3.2 Công cụ
Chúng tôi sử dụng Stanza cho tokenization, gắn thẻ đặc điểm hình thái học, gắn thẻ POS, và lemmatization. Stanza sử dụng các mô hình khác nhau cho các ngôn ngữ khác nhau. Để căn chỉnh từ chúng tôi sử dụng fast_align (Dyer et al., 2013), và chúng tôi sử dụng pyinflect cho biến đổi hình thái học. Lưu ý rằng pyinflect chỉ hỗ trợ tiếng Anh, nhưng trong công trình này, chúng tôi chỉ thực hiện biến đổi trên phía tiếng Anh cho khung tạo dữ liệu tổng hợp của chúng tôi. Chúng tôi sử dụng bộ công cụ HuggingFace (Wolf et al., 2020) để huấn luyện các mô hình ngôn ngữ.

3.3 Chi tiết Triển khai
Mô hình Ngôn ngữ Để xây dựng mô hình ngôn ngữ (LM), chúng tôi áp dụng phương pháp được nêu trong công thức GPT-2 được cung cấp bởi HuggingFace (Radford et al., 2019). Chúng tôi sử dụng phía đơn ngữ của dữ liệu song song cụ thể cho mỗi ngôn ngữ làm tập dữ liệu huấn luyện. Cho rằng nhiều ngôn ngữ tham gia vào thí nghiệm của chúng tôi không có tài nguyên cao, chúng tôi thực hiện một số sửa đổi đối với mô hình GPT-2. Chúng tôi chỉ sử dụng sáu lớp thay vì 12 lớp ban đầu để giảm thiểu các hạn chế về tài nguyên. Ngoài ra, chúng tôi giảm kích thước từ vựng xuống 5000. Những điều chỉnh này giúp điều chỉnh mô hình theo các yêu cầu cụ thể của thí nghiệm chúng tôi về các ngôn ngữ ít tài nguyên.

Dữ liệu Gốc Chúng tôi không sử dụng tất cả dữ liệu gốc có sẵn để tạo ra các câu tổng hợp. Các câu ngắn có ít hơn bảy token không được sử dụng làm câu gốc. Vì Stanza sử dụng ngữ cảnh để tạo ra các đặc điểm hình thái học, các câu ngắn dường như không cung cấp đủ ngữ cảnh cho mô hình để tạo ra các chú thích hợp lý.

Từ điển Các từ điển song ngữ thường cung cấp nhiều bản dịch cho một từ nguồn. Chúng tôi tổ chức từ điển để chỉ có một bản dịch có sẵn cho mỗi từ nguồn. Chúng tôi làm điều này một cách ngây thơ, chỉ lấy bản dịch đầu tiên của một từ và loại bỏ phần còn lại. Chúng tôi cũng đảm bảo rằng nguồn và đích có cùng thẻ POS. Để tạo ra các đặc điểm hình thái học của các mục từ điển, chúng tôi không chỉ dựa vào Stanza mà chúng tôi cũng thực hiện tra cứu trên Unimorph (Batsuren et al., 2022), cung cấp các mô hình biến đổi hình thái học cho hàng chục ngôn ngữ (bao gồm những ngôn ngữ chúng tôi làm việc) được chú thích với các thẻ POS và đặc điểm hình thái học. Đối với công trình này, chúng tôi chỉ làm việc với tăng cường, tập trung vào danh từ, tính từ và động từ.

Dữ liệu Tổng hợp Chúng tôi tạo ra năm kích thước dữ liệu tổng hợp: 5K, 10K, 50K, 100K và 200K cho mỗi cặp ngôn ngữ. Trong mỗi tập, dữ liệu của tập trước được sử dụng. Điều đó có nghĩa là khi biên dịch tập dữ liệu tổng hợp 10K, chúng tôi tạo ra dữ liệu 5K mới để thêm vào dữ liệu 5K trước đó, và như vậy. Điều này đảm bảo rằng các thí nghiệm của chúng tôi chỉ thay đổi dựa trên dữ liệu tổng hợp mới được thêm vào (và không do tính ngẫu nhiên bổ sung).

Đối với mỗi câu, chúng tôi chọn ngẫu nhiên tối đa hai từ để thay thế. Vì việc thay thế từ là ngẫu nhiên, việc có được số lượng câu chính xác cho mỗi tập không được đảm bảo, và có thể có các bản sao. Từ mỗi câu gốc, M số câu tổng hợp được tạo ra. Giả sử chúng tôi muốn tạo ra tổng cộng 5.000 câu gốc. Sau đó, M được chọn để có được ít hơn 5.000 câu một chút. Sau đó, chúng tôi sắp xếp với độ phức tạp của LM và chọn các câu có độ phức tạp thấp hơn để tạo ra tập đó.

Chi tiết Mô hình Chúng tôi tinh chỉnh DeltaLM (Ma et al., 2021), một mô hình mã hóa-giải mã đa ngữ lớn được huấn luyện trước coi bộ giải mã là lớp nhiệm vụ của các bộ mã hóa được huấn luyện trước có sẵn. Điều này được thực hiện riêng biệt cho mỗi ngôn ngữ, không phải đa ngữ. Hệ thống cơ sở là hệ thống chỉ sử dụng dữ liệu song song thực có sẵn. Trong suốt bài báo, chúng tôi gọi cơ sở là mô hình 0K (không được gắn thẻ), vì nó đã thấy 0 dữ liệu tổng hợp. Phần còn lại của các mô hình sử dụng các thẻ <clean> và <noisy> ở đầu các câu để phân biệt giữa dữ liệu thực và tổng hợp. Tên của mô hình (ví dụ 5K) chỉ ra lượng dữ liệu tổng hợp đã được thêm vào dữ liệu gốc trong quá trình huấn luyện.

4 Kết quả
Từ tiếng Anh Trong 11 trong số 14 cặp ngôn ngữ Eng-X, các phương pháp của chúng tôi mang lại cải thiện từ 0,4 điểm đến hơn 3 điểm BLEU (Papineni et al., 2002).

Do hạn chế về không gian, chúng tôi hiển thị tất cả kết quả cho sáu cặp ngôn ngữ có cải thiện lớn nhất so với cơ sở trong Hình 2. So sánh các phương pháp tăng cường dữ liệu, phương pháp nhận thức hình thái học của chúng tôi mang lại điểm số tốt hơn phương pháp ngây thơ trong tất cả các trường hợp ngoại trừ tiếng Galician. Chúng tôi thấy rằng việc tăng cường luôn có lợi cho tiếng Irish và Galician, bất kể chúng tôi thêm bao nhiêu dữ liệu. Nhưng đối với các cặp khác, việc thêm nhiều dữ liệu tổng hợp hơn không dẫn đến cải thiện bền vững.

Bảng A.1 trong Phụ lục hiển thị kết quả thí nghiệm của chúng tôi trên tất cả 14 cặp ngôn ngữ từ tiếng Anh. Chúng tôi sử dụng hai mô hình được huấn luyện trước: DeltaLM-Base và DeltaLM-Large. Chúng tôi đã cố gắng sử dụng DeltaLM-Large cho tất cả các cặp ngôn ngữ, nhưng các cặp ngôn ngữ ít tài nguyên nhanh chóng overfit trên mô hình lớn và không tổng quát tốt. Ngoài Armenian (HYE), chúng tôi có được điểm BLEU cao hơn với các cài đặt của chúng tôi cho tất cả các cặp ngôn ngữ khác. Biên độ cải thiện là không đáng kể trong các ngôn ngữ nơi hệ thống cơ sở đã rất tệ. Các ngôn ngữ như Wolof (WOL) và Uyghur (UIG) có điểm BLEU cơ sở dưới 2, cho chúng tôi thấy rằng dữ liệu gốc song song của chúng tôi không có chất lượng tốt. Đối với các ngôn ngữ, Kazakh (KAZ), Marathi (MAR), và Tamil (TAM), tất cả các ngôn ngữ khá ít tài nguyên, cải thiện ít hơn 0,5 điểm BLEU, nhưng nó dao động từ 0,79 đến 3,21 điểm BLEU cho tất cả các ngôn ngữ khác. Chúng tôi cũng quan sát thấy một xu hướng cải thiện tương tự trong trường hợp thêm nhiều dữ liệu nhiễu hơn. Điểm số cải thiện đến điểm cao nhất, nhưng khi nhiều dữ liệu tổng hợp được thêm vào, hệ thống trở nên tệ hơn.

Sang tiếng Anh Như trước đây chúng tôi hiển thị sáu cặp ngôn ngữ có hiệu suất tốt nhất trong hướng X-English trong Hình 3. Không giống như English-X, các mô hình ở đây giống nhau cho tất cả các cặp ngôn ngữ. Trong tất cả 14 ngôn ngữ ngoại trừ Armenian, phương pháp của chúng tôi cải thiện so với cơ sở, và phương pháp có thông tin hình thái học tốt hơn phương pháp ngây thơ. Trong mọi trường hợp, việc thêm nhiều dữ liệu tổng hợp sau một thời gian không dẫn đến nhiều cải thiện hơn.

Bảng A.2 trong Phụ lục liệt kê kết quả của chúng tôi trên tất cả 14 cặp ngôn ngữ theo hướng sang tiếng Anh. Điểm BLEU thường cao hơn trong cài đặt này, vì mô hình được huấn luyện trước đã thấy rất nhiều dữ liệu tiếng Anh ở phía đích. Ngoài Armenian (HYE), chúng tôi có được điểm BLEU cao hơn với các cài đặt của chúng tôi cho tất cả các cặp ngôn ngữ khác, giống như trước đây. Biên độ cải thiện là không đáng kể đối với Greek (ELL) và Maltese (MLT), cho thấy rằng ngôn ngữ không có chỗ cho cải thiện thông qua loại tăng cường này, vì các mô hình đã khá tốt rồi. Đối với Wolof (WOL) và Uyghur (UIG), cải thiện của chúng tôi ít hơn 1 điểm BLEU. Điều này cũng giống như trước đây, cho thấy rằng dữ liệu song song cho các ngôn ngữ này không có chất lượng cao. Cải thiện dao động từ 1,12 đến 4,24 điểm BLEU cho tất cả các ngôn ngữ khác. Chúng tôi cũng thấy một xu hướng tương tự như trong hướng Từ-tiếng Anh; sau một điểm nào đó, càng nhiều dữ liệu tổng hợp chúng tôi thêm vào, hệ thống càng tệ hơn; hầu hết các cải thiện được thu được với 5K và 10K ví dụ tổng hợp.

5 Phân tích
Hiệu suất có gắn liền với bất kỳ thành phần đơn lẻ nào không? Chúng tôi thực hiện một nghiên cứu ablation để tìm ra thành phần nào của mô hình chịu trách nhiệm cho việc tăng hiệu suất. Chúng tôi làm việc trên thí nghiệm này với năm nghìn dữ liệu tổng hợp và hướng SCOTTISH GAELIC-ENGLISH. Chúng tôi so sánh ba thành phần khác nhau của pipeline của chúng tôi:

• Số lượng dữ liệu tổng hợp được tạo ra có quan trọng không? Đối với thiết lập này, thay vì tạo ra ba câu tổng hợp từ mỗi câu gốc, chúng tôi tạo ra 30 câu tổng hợp từ mỗi câu gốc. Chúng tôi gọi thiết lập này là "5K Number".

• Độ dài của các câu gốc có quan trọng không? Chúng tôi tạo ra các câu tổng hợp từ các câu gốc có ít hơn bảy token cho thiết lập này. Chúng tôi gọi thiết lập này là "5K Length".

• Lựa chọn mô hình căn chỉnh có đóng vai trò gì không? Thay vì căn chỉnh các câu gốc với fast_align, chúng tôi sử dụng awesome-align sử dụng "bert-base-multilingual-cased" cho thiết lập này. Chúng tôi gọi thiết lập này là "5K Align".

Bảng 2 hiển thị kết quả của các thí nghiệm này. Điểm chính là mọi thành phần của phương pháp chúng tôi đều cần thiết để tăng điểm số: điểm số giảm khi chúng tôi thay thế một thành phần. Quan trọng nhất đối với các ngôn ngữ ít tài nguyên là sử dụng một mô hình căn chỉnh tương thích. Vì các mô hình đa ngữ lớn được huấn luyện trước không đại diện cho chúng rất tốt, và awesome_align dựa vào mô hình như vậy, chúng tôi tốt hơn khi sử dụng fast_align. Số lượng dữ liệu tổng hợp được tạo ra cũng quan trọng như chúng tôi dự đoán. Lý do là khi chúng tôi tạo ra một pool câu khổng lồ và lấy mẫu một số lượng nhỏ câu từ đó, số lượng câu gốc duy nhất đóng góp vào dữ liệu tổng hợp được giảm. Chúng tôi cũng xác nhận rằng độ dài của câu quan trọng đối với Stanza: câu càng ngắn, ngữ cảnh càng ít, do đó giảm chất lượng của phân tích hình thái học và do đó của các câu tổng hợp của chúng tôi.

Ablations trên Scottish Gaelic-English
Của chúng tôi Ngây thơ
5K 13.32 13.05
5K Number 12.76 13.13
5K Length 12.58 12.28
5K Align 12.14 12.62

Bảng 2: Kết quả ablation về tầm quan trọng của các thành phần khác nhau trong phương pháp của chúng tôi. Nếu chúng tôi không sử dụng một trong các thành phần, điểm BLEU giảm đáng kể.

Số lượng câu gốc hoặc lượng từ vựng mới có quan trọng không? Để làm thí nghiệm này, chúng tôi lại làm việc trên hướng GLA-ENG để tạo ra năm nghìn dữ liệu tổng hợp. Chúng tôi xây dựng bốn mô hình khác nhau:

• 5K: Đây là tập dữ liệu tổng hợp kích thước năm nghìn ban đầu mà chúng tôi tạo ra. Chúng tôi tạo ra ba câu từ mỗi câu gốc và chọn ngẫu nhiên các từ từ tất cả các từ ứng viên để thay thế.

• 5K (one): Trong thiết lập này, chúng tôi cố gắng tạo ra 5000 câu chỉ từ một câu gốc và chọn ngẫu nhiên các từ từ tất cả các từ ứng viên để thay thế. Tuy nhiên, quá trình của chúng tôi không thể tạo ra 5.000 câu tổng hợp duy nhất từ một câu gốc; thay vào đó, cần năm câu gốc để tạo ra 5.000 câu tổng hợp.

• 5K (half): Trong thiết lập này, chúng tôi tạo ra ba câu từ mỗi câu gốc và chọn ngẫu nhiên các từ từ nửa đầu của các từ ứng viên để thay thế.

• 5K (remove): Trong thiết lập này, chúng tôi tạo ra mười câu từ mỗi câu gốc và chọn ngẫu nhiên các từ từ tất cả các từ ứng viên để thay thế, nhưng khi chúng tôi chọn một từ, chúng tôi loại bỏ từ đó làm ứng viên để nó không được chọn lại. Lý tưởng, chúng tôi sẽ có các câu có cùng số lượng từ vựng từ điển.

Bảng 3 hiển thị kết quả của các thí nghiệm này. Một kết quả thú vị là kết quả cho 5K (one), nơi chúng tôi chỉ sử dụng năm câu gốc để tạo ra năm nghìn câu tổng hợp. Khi làm như vậy, chúng tôi giới thiệu 200 từ mới, nhưng chúng tôi có được một bước nhảy đáng kể là 3,71 điểm BLEU, điều này cho thấy triển vọng của phương pháp chúng tôi. Ngay cả khi chúng tôi có ít câu song song chất lượng cao và một từ điển chất lượng tốt, phương pháp của chúng tôi chắc chắn sẽ tăng chất lượng hệ thống MT.

Scottish Gaelic-English Của chúng tôi Scottish Gaelic-English Ngây thơ
# ENG # GLA # seed # ENG # GLA # seed
BLEU types types sentences BLEU types types sentences
0K 9.08 11077 13826 0 9.08 11077 13836 0
5K (one) 12.79 11269 14020 5 12.58 12588 15883 5
5K 13.32 12763 15847 1511 13.05 12057 15082 1512
5K (half) 13.13 12367 15216 1527 12.57 11811 14740 1508
5K (remove) 12.91 12528 15702 1909 13.29 12511 15694 1909

Bảng 3: Ablation về số lượng từ vựng mới được giới thiệu và số lượng câu gốc được sử dụng để tạo ra năm nghìn dữ liệu tổng hợp. Chỉ sử dụng ít nhất năm câu gốc đã tăng 3,71 điểm BLEU.

Lọc với LM giúp ích bao nhiêu? Để làm thí nghiệm này, chúng tôi thực hiện một thí nghiệm đối chứng để tương phản với phương pháp lọc-với-LM-perplexity của chúng tôi. Trong cài đặt đối chứng, chúng tôi chọn các câu ngẫu nhiên từ pool các câu tổng hợp. Chúng tôi chọn ngẫu nhiên một tập con của một trăm nghìn câu gốc từ tập dữ liệu OPUS-100 ENG, ELL và thực hiện ablation trên cả hai hướng ENG-ELL và ELL-ENG.

Bảng 4 hiển thị kết quả của các thí nghiệm này. Trong cài đặt ngẫu nhiên, kết quả khá không ổn định, với điểm BLEU rất thấp cho một số cài đặt. Điều này có thể là do chúng tôi có thể đang chọn ngẫu nhiên các câu tệ từ pool. Kết quả với việc lựa chọn câu có thông tin (thông qua độ phức tạp), thay vào đó, ổn định và liên tục cải thiện.

Cặp 0K 5K 10K 50K 100K 200K
English-Modern Greek (random) 14.24 13.98 5.01 15.7 14.92 4.23
English-Modern Greek (filtered) 14.62 15.14 15.2 14.99 15.54
Modern Greek-English (random) 11.6 12.2 10.24 18.34 9.21 12.42
Modern Greek-English (filtered) 16.91 17.25 17.05 19.01 17.64

Bảng 4: Lọc dữ liệu tổng hợp dẫn đến cải thiện nhất quán, nhưng lấy mẫu dữ liệu ngẫu nhiên dẫn đến kết quả không ổn định. Thay vào đó, điểm BLEU giảm ngẫu nhiên cho phương pháp ngẫu nhiên.

6 Công trình Liên quan
Từ điển đã và đang là tài nguyên không thể thiếu trong các ứng dụng khác nhau trong NLP (Wilson et al., 2020; Wang et al., 2019; Xiao and Guo, 2014). Cụ thể hơn, nhiều nghiên cứu trước đây sử dụng từ điển trong MT để cải thiện chất lượng dịch cho các ngôn ngữ ít tài nguyên có hoặc không có kho ngữ liệu đơn ngữ hoặc song song. Một nhiệm vụ liên quan chặt chẽ là cảm ứng từ điển song ngữ xuất phát từ một nhiệm vụ MT không giám sát nơi không có tài nguyên song song, bao gồm từ điển song ngữ ground-truth, được kết hợp (Artetxe et al., 2017; Lample et al., 2018b). Từ điển song ngữ thường được sử dụng như một hạt giống trong cảm ứng từ điển song ngữ nhằm cảm ứng thêm các cặp từ trong cặp ngôn ngữ (Mikolov et al., 2013). Một việc sử dụng khác của từ điển song ngữ là để dịch các từ tần số thấp trong MT thần kinh có giám sát (Arthur et al., 2016; Zhang and Zong, 2016).

Về việc sử dụng từ điển trong MT, Peng et al. (2020) sử dụng từ điển cho MT xuyên ngôn ngữ, Fadaee et al. (2017) đề xuất một phương pháp tăng cường dữ liệu để nhắm mục tiêu các từ tần số thấp bằng cách tạo ra các cặp câu chứa các từ hiếm, Duan et al. (2020) sử dụng từ điển để thúc đẩy không gian ngữ nghĩa của ngôn ngữ nguồn và đích trở nên gần nhau hơn trong huấn luyện MT mà không có câu song song và Wang et al. (2022b) khám phá việc sử dụng từ điển để tổng hợp dữ liệu văn bản hoặc có nhãn, tập trung vào các nhiệm vụ như nhận dạng thực thể có tên và gắn thẻ từ loại.

Không giống như nhiều phương pháp trước đây chỉ tập trung vào dữ liệu đơn ngữ, phương pháp của chúng tôi xem xét việc sử dụng từ điển song ngữ và duy trì hình thái học trong tăng cường. Phương pháp của chúng tôi tương tự về tinh thần với kỹ thuật của Fadaee et al. (2017) với việc xem xét thêm độ phức tạp hình thái học trong quá trình tăng cường dữ liệu tổng hợp. Ngoài ra, được truyền cảm hứng từ phương pháp của Wang et al. (2022b), nghiên cứu của chúng tôi chia sẻ một chủ đề chung bằng cách sử dụng các chiến lược khác nhau để tổng hợp dữ liệu bằng từ điển và tích hợp dữ liệu như vậy với văn bản đơn ngữ hoặc song song khi có thể truy cập được. Cả hai nghiên cứu đều nhằm tận dụng từ điển để tăng cường các nhiệm vụ NLP khác nhau, mặc dù trong các ngữ cảnh khác nhau.

7 Kết luận
Các phương pháp của chúng tôi đã được chứng minh là có lợi cho hầu hết 14 ngôn ngữ được điều tra, ngoại trừ Armenian. Ngay cả khi cải thiện trong điểm BLEU có thể nhỏ đối với một số ngôn ngữ, có một sự tăng cường đáng chú ý trong hầu hết. Thú vị là, chúng tôi quan sát thấy cải thiện ngay cả trong các cặp ngôn ngữ (ví dụ, WOL-ENG, ENG-KMR, ENG-GLA) với điểm cơ sở ban đầu không thỏa mãn. Quan sát này cho thấy phương pháp của chúng tôi có thể tăng cường hiệu suất ngay cả trong các kịch bản thách thức hơn. Kết quả cũng nhấn mạnh tầm quan trọng của việc có được các câu gốc chất lượng cao. Chúng tôi thấy rằng chỉ cần năm điểm dữ liệu gốc chất lượng tốt có thể đóng góp vào việc tạo ra năm nghìn mẫu dữ liệu tổng hợp chất lượng tốt sẽ tăng hiệu suất. Quá trình tăng cường dữ liệu này có thể đóng vai trò quan trọng trong việc cải thiện hiệu suất tổng thể của các hệ thống dịch máy và được kết hợp với các kỹ thuật tăng cường khác (ví dụ, dịch ngược) vì chúng tôi coi nó là trực giao với chúng.

Công việc Tương lai Trong công trình hiện tại của chúng tôi, chúng tôi tập trung vào việc thực hiện biến đổi hình thái học độc quyền ở phía tiếng Anh của nhiệm vụ dịch. Lý do chính cho lựa chọn này là tính khả dụng của một inflector hình thái học đáng tin cậy được thiết kế cụ thể cho tiếng Anh. Tuy nhiên, chúng tôi gặp phải thách thức khi áp dụng cùng phương pháp cho các ngôn ngữ khác. Chúng tôi thiếu các công cụ biến đổi hình thái học phù hợp cho các ngôn ngữ đó, hoặc độ chính xác của các công cụ có sẵn không đáp ứng yêu cầu của chúng tôi. Việc kết hợp các công cụ này sẽ tạo ra một nút thắt cổ chai đáng kể cho hiệu quả của phương pháp chúng tôi. Đối với nghiên cứu trong tương lai, chúng tôi nhằm khám phá cách phương pháp của chúng tôi có thể được mở rộng bằng cách thực hiện biến đổi hình thái học trong các ngôn ngữ khác. Điều này bao gồm việc phát triển hoặc thu được các công cụ biến đổi hình thái học chính xác và đáng tin cậy.

8 Hạn chế
Một trong những hạn chế của phương pháp hiện tại của chúng tôi là việc sử dụng mô hình Stanza. Vì từ điển song ngữ không có ngữ cảnh, việc chỉ dựa vào các đặc điểm hình thái học thu được từ từ điển dẫn đến các đặc điểm tổng quát hơn. Điều này có thể đặc biệt thách thức trong các ngôn ngữ giàu hình thái học, nơi một từ đơn có thể có nhiều ý nghĩa tùy thuộc vào ngữ cảnh câu. Một hạn chế khác là hỗ trợ ngôn ngữ được cung cấp bởi mô hình Stanza, hiện tại bị giới hạn ở 60 ngôn ngữ. Ràng buộc này hạn chế khả năng áp dụng phương pháp của chúng tôi chỉ cho những ngôn ngữ được Stanza hỗ trợ. Để mở rộng công trình của chúng tôi cho các ngôn ngữ không được Stanza hỗ trợ, cần thiết phải tạo ra các mô hình Stanza tùy chỉnh được điều chỉnh cụ thể cho những ngôn ngữ đó. Quá trình này đòi hỏi thời gian và nỗ lực bổ sung để phát triển và xác thực các mô hình cho mỗi ngôn ngữ quan tâm.

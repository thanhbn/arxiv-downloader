# 2308.12674.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/multilingual/2308.12674.pdf
# Kích thước tệp: 991484 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Cải thiện độ trung thành dịch thuật của các mô hình ngôn ngữ lớn thông qua
tăng cường hướng dẫn
Yijie Chen1, Yijin Liu2, Fandong Meng2, Yufeng Chen1, Jinan Xu1, Jie Zhou2
1Đại học Giao thông Bắc Kinh, Bắc Kinh, Trung Quốc
2Trung tâm Nhận dạng Mẫu, WeChat AI, Tencent Inc, Trung Quốc
{22120354, chenyf, jaxu}@bjtu.edu.cn
{yijinliu, fandongmeng, withtomzhou}@tencent.com
Tóm tắt
Các mô hình ngôn ngữ lớn (LLM) thể hiện khả năng
tổng quát mạnh mẽ, và một thách thức hấp dẫn hiện
tại là kích thích các khả năng chuyên biệt của chúng,
chẳng hạn như dịch máy, thông qua điều chỉnh hướng
dẫn chi phí thấp. Dữ liệu theo dõi hướng dẫn tiêu
chuẩn được tổ chức tuần tự dưới dạng nối tiếp một
hướng dẫn, một đầu vào và một phản hồi. Vì cơ chế
chú ý của LLM có hạn chế về tập trung cục bộ, LLM
có xu hướng tập trung nhiều hơn vào các từ hoặc câu
gần đó tại mỗi vị trí. Điều này dẫn đến nguy cơ cao
về việc quên hướng dẫn trong quá trình giải mã. Để
giảm thiểu các vấn đề trên, chúng tôi đề xuất SWIE
(Nhúng hướng dẫn có trọng số phân đoạn) và một
tập dữ liệu theo dõi hướng dẫn OVERMISS. SWIE
cải thiện hiểu biết hướng dẫn của mô hình bằng cách
thêm một biểu diễn hướng dẫn toàn cục vào các biểu
diễn đầu vào và phản hồi tiếp theo. OVERMISS cải
thiện độ trung thành của mô hình bằng cách so sánh
kết quả dịch thừa và dịch thiếu với bản dịch chính
xác. Chúng tôi áp dụng các phương pháp của mình
cho hai LLM mã nguồn mở chính thống, BLOOM
và LLaMA. Kết quả thực nghiệm cho thấy những cải
thiện đáng kể trong hiệu suất dịch thuật với SWIE
dựa trên BLOOMZ-3b, đặc biệt trong dịch thuật zero-
shot và văn bản dài do giảm nguy cơ quên hướng
dẫn. Thêm vào đó, OVERMISS vượt trội hơn baseline
trong hiệu suất dịch thuật (ví dụ tăng điểm BLEU từ
0.69 lên 3.12 và cải thiện trung bình 0.48 điểm phần
trăm comet cho LLaMA-7b) với những cải thiện thêm
được thấy trong các mô hình kết hợp OVERMISS và
SWIE (ví dụ điểm BLUE tăng lên đến 0.56 từ tiếng
Anh sang tiếng Đức trên ba backbone khác nhau), và
cả hai đều thể hiện cải thiện trong chỉ số độ trung
thành dựa trên căn chỉnh từ.1

1Mã và tập dữ liệu của chúng tôi được phát hành trên Github:
https://github.com/pppa2019/swie_overmiss_llm4mt

1 Giới thiệu
Trong những năm gần đây, các mô hình ngôn ngữ
được đào tạo trước (PLM) đã trải qua sự phát triển
mạnh mẽ và đã được nghiên cứu rộng rãi cũng như
sử dụng trong các tác vụ downstream. Tuy nhiên,
các mô hình ngôn ngữ lớn (LLM) thể hiện các khả
năng nổi lên đáng ngạc nhiên (Wei et al., 2022) mà
không được quan sát thấy trong các PLM nhỏ, và
LLM đã cho thấy khả năng đáng kể trên các tác vụ
tổng quát và cài đặt zero-shot hoặc few-shot, thậm
chí bao gồm cả lý luận tượng trưng, thường thức,
thuật toán, v.v.

Các Super LLM như GPT-4 và ChatGPT, chỉ có
thể được sử dụng qua API, đã chứng minh hiệu suất
dịch thuật đáng chú ý mà không cần fine-tuning
(Jiao et al., 2023b; Hendy et al., 2023). Đối với các
LM tổng quát, fine-tuning là một cách tiếp cận phổ
biến để thích ứng với các tác vụ downstream cụ thể.
Do đó, việc fine-tuning các LLM mã nguồn mở tương
đối nhỏ hơn đưa ra một giải pháp thay thế hấp dẫn,
cho rằng nó có thể tăng cường khả năng dịch thuật
của mô hình mà không áp đặt chi phí tính toán đáng
kể (Jiao et al., 2023a). Tuy nhiên, điều chỉnh hướng
dẫn trên LLM trong dịch máy vẫn là một lĩnh vực
chưa được khám phá đầy đủ.

Mặc dù kiến trúc de facto của các mô hình state-of-
the-art trong dịch máy vẫn là encoder-decoder (Bah-
danau et al., 2015; Gao et al., 2022), phần lớn các
LLM mã nguồn mở áp dụng kiến trúc mô hình ngôn
ngữ nhân quả (causal LM). Tuy nhiên, hạn chế cốt
lõi của causal LM là tập trung cục bộ (Liu et al.,
2023) của cơ chế chú ý của nó, dẫn đến xu hướng
của mô hình tập trung vào các từ hoặc câu gần đó tại
mỗi vị trí. Do đó, trong dữ liệu fine-tuning hướng
dẫn, văn bản hướng dẫn xa hơn so với đầu ra so với
văn bản đầu vào, làm tăng nguy cơ quên hướng dẫn
trong quá trình giải mã. Trong dịch máy, việc bỏ qua
hướng dẫn có thể dẫn đến các vấn đề như ảo giác
hoặc không trung thành, cuối cùng làm giảm chất
lượng và độ tin cậy của các mô hình.

--- TRANG 2 ---
Bài báo này giới thiệu một phương pháp mới để
cải thiện điều chỉnh hướng dẫn có tên SWIE (Nhúng
hướng dẫn có trọng số phân đoạn), sử dụng các
adapter được tham số hóa để mã hóa hướng dẫn và
giới thiệu trọng số phân đoạn để cho phép tích hợp
tự nhiên các biểu diễn hướng dẫn và biểu diễn toàn
cục. Để cải thiện thêm độ trung thành dịch thuật của
mô hình, chúng tôi trình bày OVERMISS, một tập
dữ liệu hướng dẫn sử dụng framework đề xuất của
chúng tôi để thu thập các mẫu âm tính đối lập nhắm
cụ thể vào các vấn đề dịch thừa và dịch thiếu.

Chúng tôi đánh giá các phương pháp của mình trên
các benchmark dịch máy khác nhau và các mô hình
backbone đa dạng (bao gồm BLOOMZ-3b, BLOOMZ-
7b1-mt, và LLaMA-7b). Kết quả trên BLOOMZ-3b
cho thấy SWIE đã cải thiện từ 0.19 lên 0.51 điểm
BLEU trên bốn hướng dịch của các tập test WMT22,
từ 0.20 lên 0.58 điểm BLEU trên sáu hướng dịch
zero-shot, và 0.67 điểm BLEU trung bình trên các
tập test câu dài. Thêm vào đó, OVERMISS cũng
dẫn đến những cải thiện đáng kể (ví dụ đối với các
tập test WMT22, tăng điểm BLEU từ 0.69 lên 3.12
và tăng 0.48 điểm phần trăm COMET trung bình trên
LLaMA-7b trên WMT). Sự kết hợp của SWIE và
OVERMISS đạt được cải thiện thêm lên đến 0.56
điểm BLEU trên ba mô hình backbone từ tiếng Anh
sang tiếng Đức.

Tóm lại, các đóng góp của chúng tôi như sau:
• Chúng tôi đề xuất SWIE, một phương pháp nhúng
hướng dẫn có trọng số phân đoạn mới, cải thiện
hiệu quả hiệu suất dịch thuật và độ trung thành,
và hiệu quả của nó càng đáng kể hơn trong các
cài đặt zero-shot và văn bản dài hơn nhờ vào việc
tăng cường khả năng theo dõi hướng dẫn.

• Chúng tôi đề xuất một phương pháp xây dựng dữ
liệu điều chỉnh hướng dẫn đối lập về độ trung thành
dịch thuật và xây dựng OVERMISS. Chúng tôi
chứng minh rằng OVERMISS cải thiện liên tục
hiệu suất dịch thuật trên ba mô hình backbone và
hai tập test (ví dụ trên LLaMA-7b, tăng lên đến
3.12 điểm BLEU trên các tập test WMT22 và lên
đến 3.03 điểm BLEU trên các tập test FLORES.)

• Bằng cách kiểm tra các điểm chú ý nội bộ của
các mô hình, chúng tôi phát hiện rằng SWIE dẫn
đến tỷ lệ chú ý cao hơn cho các hướng dẫn so với
baseline, từ đó xác thực giả thuyết của chúng tôi
và chứng minh hiệu quả của nó trong việc giảm
thiểu vấn đề quên hướng dẫn.

Hình 1: Cấu trúc mô hình của SWIE.

2 Công trình liên quan
Công trình của chúng tôi liên quan chặt chẽ đến dịch
máy, các biến thể của điều chỉnh hướng dẫn cho
LLM, và ảo giác trong sinh văn bản. Chúng tôi sẽ
cung cấp tổng quan ngắn gọn về các lĩnh vực này
trong phần này.

2.1 Dịch máy dựa trên LLM
Nhờ vào khả năng zero-shot và theo dõi hướng dẫn
mạnh mẽ của LLM, các super LLM như GPT-4 đã
đạt được hiệu suất dịch thuật có thể so sánh với hệ
thống tốt nhất trên hệ thống WMT trong hướng dịch
tài nguyên cao về dịch thuật và các tác vụ liên quan
như post-editing (Raunak et al., 2023; He et al., 2023).

Nghiên cứu nói trên chỉ sử dụng độc quyền các
mô hình chỉ được truy cập qua API, do đó hạn chế
khả năng áp dụng của nó. Do đó, nhiều nghiên cứu
đã được tiến hành để điều tra tiềm năng của việc
fine-tuning các LLM mã nguồn mở. Trong bối cảnh
điều chỉnh hướng dẫn LLM cho dịch máy, (Jiao et
al., 2023a; Zhang et al., 2023) đã đề xuất các framework
xây dựng dữ liệu hướng dẫn đa tác vụ để điều chỉnh
hướng dẫn các LLM mã nguồn mở về dịch máy.
(Zeng et al., 2023) đề xuất một loss học đối lập để
huấn luyện mô hình học các cặp mẫu đối lập.

2.2 Điều chỉnh hướng dẫn
Công trình đầu tiên về điều chỉnh hướng dẫn là FLAN
(Wei et al., 2021), cho thấy kết quả đáng ngạc nhiên
trên các cài đặt zero-shot và few-shot. Có rất nhiều

--- TRANG 3 ---
Hình 2: Một ví dụ về hướng dẫn dịch thuật và một ví dụ về OVERMISS.

công trình tiếp theo được đề xuất để xây dựng các
tập dữ liệu hướng dẫn quy mô lớn hơn. Các tập dữ
liệu điều chỉnh hướng dẫn áp dụng các phong cách
hướng dẫn và ngôn ngữ khác nhau: FLAN (Longpre
et al., 2023) sử dụng "input" và "target"; unnatural
instruction (Honovich et al., 2022) sử dụng "instruction",
"input", "constrain" và "output"; Super-NaturalInstructions
(Wang et al., 2022) xây dựng mẫu tích cực và tiêu
cực cho mỗi tác vụ. Như một tập dữ liệu thống nhất
và mở rộng, OPT-IML chuyển đổi tất cả các tập dữ
liệu trên thành các phân đoạn "instruction" và "output".

Do thực tế rằng các hướng dẫn phục vụ như định
nghĩa của các tác vụ và thường nằm ở đầu các mẫu,
biểu diễn của các hướng dẫn trong causal LM đối
mặt với nguy cơ cao bị quên trong quá trình giải mã.
Để giảm thiểu vấn đề này, hiện có một số nỗ lực đề
xuất các phương pháp cải thiện khác với các cách
tiếp cận fine-tuning tiêu chuẩn, nhằm tăng cường
việc học trong các thành phần hướng dẫn.

(Ye et al., 2022) mô hình hóa hướng dẫn trong
điều kiện cho đầu vào và mục tiêu, từ đó giảm thiểu
yêu cầu mô hình hóa ngữ cảnh dài. (Choi et al., 2022)
đề xuất một phương pháp chuyển ngữ cảnh dựa trên
chưng cất để bảo tồn thông tin ngữ cảnh dài trong
mô hình cố định khi mô hình được sử dụng trong
các tình huống prompt tĩnh dài.

Vì các phương pháp trên yêu cầu yêu cầu cao hơn
cho dữ liệu và các kịch bản tác vụ, chẳng hạn như
các hướng dẫn cố định làm điều kiện. Chúng không
thể đáp ứng điều kiện của dịch máy, thường chỉ
chứa các hướng dẫn ngắn chỉ ra hướng dịch.

2.3 Ảo giác trong các mô hình ngôn ngữ
Ảo giác trong dịch máy thần kinh đã được thảo luận
trong một thời gian dài (Lee et al., 2018; Müller et
al., 2020), và nó có cùng ý nghĩa với không trung
thành. Người ta quan sát rộng rãi rằng các nguồn
gốc của ảo giác hoặc không trung thành có thể là
thiếu kiến thức hoặc chú ý không đầy đủ đến nguồn
(Ferrando et al., 2022; Raunak et al., 2021).

Trên các benchmark phát hiện ảo giác dịch máy,
chúng tôi thấy rằng các tập dữ liệu hiện có được
xây dựng bởi con người hoặc làm nhiễu mô hình
dịch thuật (Raunak et al., 2021). Các tập dữ liệu
được con người tạo ra như HalOmi (Dale et al., 2023)
có chi phí cao và khó mở rộng. Các tập dữ liệu được
tạo bằng phương pháp làm nhiễu mô hình có chất
lượng thấp vì các câu được tạo ra xa cả phân phối
tự nhiên và phân phối của các LLM hiện đại. Do đó,
phương pháp xây dựng tập dữ liệu mô phỏng ảo
giác đề xuất của chúng tôi có thể lấp đầy khoảng
trống với các mẫu âm tính trôi chảy chất lượng cao.

3 Phương pháp
Trong phần này, chúng tôi đề xuất một tập dữ liệu
hướng dẫn dịch thuật trung thành đối lập OVERMISS
và một phương pháp hợp nhất hướng dẫn toàn cục
SWIE. Trước khi giới thiệu phương pháp đề xuất,
nền tảng cần thiết sẽ được hình thức hóa trước.

3.1 Nền tảng
3.1.1 Hình thức hóa điều chỉnh hướng dẫn
Điều chỉnh hướng dẫn là một trong các phương pháp
căn chỉnh để làm cho các mô hình ngôn ngữ đáp ứng
sở thích của con người. Để hình thức hóa điều chỉnh
hướng dẫn, chúng tôi định nghĩa s, x, và

--- TRANG 4 ---
y lần lượt là hướng dẫn, đầu vào, và mục tiêu. Lưu
ý rằng đầu vào không cần thiết nhưng hướng dẫn
luôn cần thiết. Điều chỉnh hướng dẫn tiêu chuẩn được
huấn luyện với ước lượng likelihood tối đa (MLE),
và mục tiêu huấn luyện có thể được tính toán bằng
Phương trình (1). Hơn nữa, do cơ chế chú ý có xu
hướng chú ý nhiều hơn đến văn bản gần đó, phần
hướng dẫn đối mặt với nguy cơ cao hơn bị quên
trong quá trình sinh.

LMLE = -∑(t=1 to T) log P(yt|y<t; x; s)    (1)

3.1.2 Mô hình ngôn ngữ nhân quả
Kiến trúc chỉ decoder được thiết kế cho các tác vụ
sinh văn bản thống nhất, bao gồm prefix decoder
và causal decoder (Raffel et al., 2020). Hầu hết các
LLM sử dụng kiến trúc causal decoder vì quan sát
rộng rãi về quy luật mở rộng trên causal decoder.
Tuy nhiên, một điều tra toàn diện hơn về hiệu suất
của các kiến trúc khác ở quy mô lớn vẫn còn thiếu.
(Zhao et al., 2023)

Một mô hình ngôn ngữ nhân quả được cấu thành
từ một chồng các lớp decoder nhân quả. Chức năng
của cơ chế chú ý đa đầu là kết hợp biểu diễn ẩn của
mỗi vị trí với thông tin ngữ cảnh. Với một mặt nạ
chú ý nhân quả, các tác vụ sinh văn bản ở bất kỳ
định dạng nào có thể được thống nhất trong các
trạng thái huấn luyện và giải mã. Chi tiết, cho m, n
là các chỉ số vị trí của hai token, và q, k, v, o lần
lượt là query, key, value, và biểu diễn đầu ra, và
độ dài của các token đầu vào là N. Trong một mô
hình ngôn ngữ nhân quả, khi m > n, điểm chú ý
am,n sẽ bị che.

am,n = exp(q^T_m k_n/√d) / ∑(j=1 to N) exp(q^T_m k_j/√d)    (2)

om = ∑(n=1 to N) am,n vn    (3)

3.2 SWIE: Nhúng hướng dẫn có trọng số phân đoạn
Chúng tôi đề xuất nhúng hướng dẫn có trọng số
phân đoạn để tăng cường chú ý hướng dẫn toàn cục
cho các decoder, và các chi tiết được mô tả như sau.
Điều chỉnh hướng dẫn có thể được chia thành nhiều
phân đoạn, bao gồm hướng dẫn, đầu vào, phản hồi,
v.v. Câu sẽ được chuyển đổi

Hình 3: Minh họa về trọng số phân đoạn

thành một danh sách các token sau tokenizer. Chúng
tôi định nghĩa một ID phân đoạn cho mỗi phân đoạn
và sau đó ánh xạ chỉ số phân đoạn đến mỗi token
của danh sách token.

Giả sử một danh sách token câu được biểu diễn
là S = [s1, s2, ···, sl] ∈ R^(1×N), và danh sách id
phân đoạn của nó là Is, cũng là một mảng có độ
dài N. Cho c là ID của span hướng dẫn, và b là
mảng ghi lại các chỉ số bắt đầu của mỗi span. Biểu
diễn hướng dẫn được mã hóa có thể được thu được
trong đầu ra của mỗi lớp decoder, chúng tôi sử dụng
một adapter hướng dẫn để tái tham số hóa hướng
dẫn. Chúng tôi đặt một trọng số phân đoạn để ràng
buộc việc hợp nhất biểu diễn hướng dẫn trên các
phân đoạn đầu vào và phản hồi. Cho L là độ dài
của danh sách token của span đầu vào, B là mảng
ghi lại chỉ số vị trí bắt đầu của mỗi phân đoạn, và
chúng tôi sử dụng L để chuẩn hóa độ dốc. Hl biểu
diễn đầu ra ẩn của lớp thứ l và Hinsl biểu diễn kết
quả max pool của phần hướng dẫn trong Hl. Chúng
tôi sử dụng một lớp tuyến tính down-sampling, một
lớp kích hoạt, và một lớp tuyến tính up-sampling
làm adapter.

Về chi tiết triển khai, chúng tôi đã chọn ba lớp
giữa của mô hình ngôn ngữ để hợp nhất tính năng
hướng dẫn được trích xuất với biểu diễn ẩn toàn
cục. Nguyên tắc lựa chọn dựa trên phân tích của
chúng tôi về phân phối điểm chú ý của mỗi lớp, và
quá trình phân tích chi tiết được hiển thị trong phần
Visualize Inadequate Attention on Instruction. Cấu
trúc mô hình được hình dung trong Hình 1, và quá
trình được mô tả như Phương trình (4-6), và minh
họa của trọng số phân đoạn được hiển thị trong
Hình 3.

Hl := Hl + Wseg · f(Hinsl)    (4)

Wsegi = {0 nếu Is[i] = c; (i - B[Is[i]])/L nếu Is[i] ≠ c}    (5)

f(Hinsl) = Lup(σ(Ldown(Hinsl)))    (6)

--- TRANG 5 ---
3.3 OVERMISS: Một tập dữ liệu ảo giác tự nhiên
Trong tác vụ dịch máy, phân loại thông thường nhất
của ảo giác mô hình hoặc không trung thành cho
đầu ra trôi chảy là dịch thừa và dịch thiếu. Dịch
thừa đề cập đến tình huống mà câu được dịch chứa
các từ không liên quan đến câu nguồn, và dịch thiếu
đề cập đến tình huống mà câu dịch thiếu một phần
thông tin từ câu nguồn. Do đó, chúng tôi nhắc gpt-
3.5-turbo mô phỏng hai loại lỗi điển hình, và các
prompt được đính kèm trong Bảng 1.

Để định lượng mức độ lỗi dịch thiếu hoặc dịch
thừa của các câu được tạo, chúng tôi sử dụng awesome-
align² để đánh giá tỷ lệ căn chỉnh đa ngôn ngữ cấp
từ, và kết quả thống kê được hiển thị trong Bảng 2,
cho thấy dữ liệu được tạo đáp ứng yêu cầu của các
mẫu âm tính trong khi bảo tồn ý nghĩa của hầu hết
các câu nguồn.

Các tập dữ liệu điều chỉnh hướng dẫn có thể được
tổ chức linh hoạt, và định dạng tiêu chuẩn chứa
hướng dẫn, đầu vào, và phản hồi. Sau khi chúng tôi
xây dựng các mẫu đối lập dịch thừa và dịch thiếu
dựa trên WMT17-20 với pipeline tự động đề xuất,
chúng tôi tổ chức dữ liệu hướng dẫn cuối cùng như
Hình 2. Và tổng số mẫu trong tập dữ liệu là 54420.

4 Thực nghiệm thực nghiệm
Chúng tôi chọn BLOOM và LLaMA làm các mô
hình backbone. Có 4 hướng dịch được bao gồm,
De⇒En, En⇒De, En⇒Zh, và Zh⇒En.

4.1 Cài đặt huấn luyện
4.1.1 Alpaca
Tập dữ liệu Alpaca³ là một tập dữ liệu theo dõi
hướng dẫn đa tác vụ chất lượng cao chứa 52K mục.
Chúng tôi sử dụng Tập dữ liệu Alpaca để fine-tune
các mô hình ngôn ngữ được đào tạo trước làm baseline
của chúng tôi.

4.1.2 Parrot-hint
Theo (Jiao et al., 2023a), chúng tôi đặt Parrot-hint
làm baseline mạnh của chúng tôi. Tập dữ liệu Parrot-
hint⁴ bao gồm 3 tập dữ liệu con, Tập dữ liệu Alpaca,
tập dữ liệu WMT17-20, và tập dữ liệu hướng dẫn
MQM. Parrot-hint chứa tổng cộng 200K dữ liệu.

²https://github.com/neulab/awesome-align
³https://github.com/tatsu-lab/stanford_alpaca
⁴https://github.com/wxjiao/ParroT

4.1.3 OVERMISS
Trong quá trình huấn luyện, chúng tôi sử dụng tập
dữ liệu Parrot-hint để đảm bảo khả năng cơ bản của
các mô hình được fine-tune. Vì tập dữ liệu mixup
chứa dữ liệu theo dõi hướng dẫn không có gợi ý và
có gợi ý, và dữ liệu có gợi ý đều có một tác vụ phụ
dựa trên dịch thuật. Vì vậy chúng tôi sử dụng một
chiến lược học chương trình để fine-tune dữ liệu
trong hai giai đoạn.

4.2 Đánh giá
Phần này giới thiệu các tập test và các chỉ số đánh
giá chúng tôi sử dụng.

4.2.1 Các tập test WMT22
Các tập test WMT22 đến từ track dịch tin tức của
cuộc thi WMT22⁵. Các tập test bao gồm lần lượt
1984, 2037, 2037, và 1875 mẫu cho De⇒En, En⇒De,
En⇒Zh, và Zh⇒En.

4.2.2 Flores-200 Dev-test
Flores-200 là một benchmark dịch đa ngôn ngữ.
Chúng tôi sử dụng split dev-test làm tập test của
chúng tôi để làm giàu các thực nghiệm của chúng
tôi, và có 1012 mẫu cho mỗi hướng dịch.

4.2.3 Đánh giá tự động
Đối với đánh giá từ vựng, chúng tôi sử dụng BLEU
(Papineni et al., 2002); đối với đánh giá ngữ nghĩa,
chúng tôi sử dụng COMET với tham chiếu. Cả hai
đều là các chỉ số được sử dụng rộng rãi trong dịch
máy, và chúng tôi sử dụng ScareBLEU⁶ và Unbabel/wmt22-
comet-da trong triển khai đánh giá.

4.3 Chi tiết triển khai
Chúng tôi sử dụng framework transformers và DeepSpeed
cho huấn luyện và suy luận mô hình. Các siêu tham
số huấn luyện theo cài đặt của (Jiao et al., 2023a).
Chúng tôi đặt thống nhất dim của adapter hướng
dẫn là 32. Các mô hình kích thước 3B được huấn
luyện trên 8 GPU V100, và các mô hình kích thước
7B được huấn luyện trên 4 GPU A100(40G). Để
giảm yêu cầu bộ nhớ và ngăn các mô hình khỏi
over-fitting, chúng tôi huấn luyện tất cả các mô hình
với việc đóng băng các lớp embedding trong DeepSpeed
stage 1.

4.4 Kết quả chính
Các kết quả chính được hiển thị trong Bảng 3. Đối
với LLaMA được fine-tune bởi Alpaca, mô hình
hoạt động tốt

⁵https://github.com/wmt-conference/wmt22-news-systems
⁶https://github.com/mjpost/sacrebleu

--- TRANG 6 ---
loại prompt
dịch thiếu Bạn là một dịch giả không chuyên nghiệp từ [ngôn ngữ nguồn] sang [ngôn ngữ đích] 
không hoàn toàn trung thành với văn bản gốc trong quá trình dịch có vấn đề 
thiếu sót, tức là bản dịch bỏ sót các phần của văn bản gốc.
Vui lòng dịch câu [ngôn ngữ nguồn] sau:
[câu nguồn]
Nếu phần sau là bản dịch [ngôn ngữ đích] chất lượng cao của con người:
[câu đích]
Vui lòng đưa ra bản dịch [ngôn ngữ đích] chất lượng thấp trực tiếp với vấn đề 
thiếu sót, lưu ý rằng bạn không chỉ đơn giản viết lại bản dịch trước đó, mà 
cần mô phỏng một dịch giả có thể có thiếu sót, tức là bỏ sót các phần của 
văn bản gốc.

dịch thừa Bạn là một dịch giả từ [ngôn ngữ nguồn] sang [ngôn ngữ đích], nhưng bản dịch 
của bạn không chuyên nghiệp. Trong quá trình dịch, bạn đã không hoàn toàn 
trung thành với văn bản gốc, dẫn đến bản dịch không có trong văn bản gốc.
Đây là vấn đề ảo giác dịch thuật và bạn cần đưa ra bản dịch có vấn đề ảo giác. 
Vui lòng dịch câu [ngôn ngữ nguồn] sau:
[câu nguồn]
Nếu phần sau là bản dịch [ngôn ngữ đích] chất lượng cao của con người:
[câu đích]
Vui lòng đưa ra bản dịch [ngôn ngữ đích] chất lượng thấp đơn giản có vấn đề 
dịch bổ sung hoặc vấn đề ảo giác dịch thuật. Vui lòng lưu ý rằng bạn cần mô 
phỏng một dịch giả có vấn đề tăng cường dịch thuật có thể và dịch những gì 
không có trong văn bản gốc, thay vì chỉ đơn giản viết lại bản dịch trước đó.

Bảng 1: Các prompt để tạo tập dữ liệu OVERMISS.

nguồn dữ liệu    độ bao phủ nguồn    độ bao phủ đích
tham chiếu       0.8845              0.8699
dữ liệu thiếu    0.5800              0.7180
dữ liệu thừa     0.6958              0.5771

Bảng 2: Thống kê dữ liệu của dữ liệu dịch thừa và dịch thiếu được tạo.

khi dịch En⇔De, trong khi khi dịch En⇔Zh, nó
thường nhầm lẫn ngôn ngữ đích, dẫn đến trộn mã
hoặc dịch ngoài đích. Đối với BLOOM được fine-
tune bởi Alpaca, mô hình dịch En⇔Zh tốt hơn trong
khi dịch tệ hơn trong En⇔De khi so sánh với LLaMA-
Alpaca, cho thấy sự khác biệt giữa khả năng dịch
ngôn ngữ cơ bản của các mô hình. Nhìn chung,
chúng tôi có ba quan sát chính trong thực nghiệm
như sau.

Thứ nhất, theo so sánh giữa OVERMISS và Parrot-
hint, chúng tôi thấy rằng OVERMISS đáng chú ý
dẫn đến cải thiện hiệu suất. Ví dụ, dựa trên LLaMA-
7b, mô hình được huấn luyện với OVERMISS có
cải thiện lần lượt 1.02, 1.25, 3.12 và 0.69 điểm
BLEU trên bốn hướng dịch, và cải thiện 0.48 điểm
phần trăm comet trung bình.

Mặc dù tập dữ liệu Flores có phân phối khác với
dữ liệu huấn luyện WMT, chúng tôi thấy rằng OVERMISS
vẫn tăng 0.46 điểm BLEU trên En⇒De và 3.03 điểm
BLEU trên Zh⇒En.

Thứ hai, theo so sánh giữa SWIE và Parrot-hint,
chúng tôi thấy rằng phương pháp này có cải thiện
rõ ràng trên một số cài đặt và có cải thiện nhẹ ổn
định trên các cài đặt khác. Ví dụ, trên BLOOMZ-
3b, SWIE vượt trội hơn Parrot-hint từ 0.19 lên 0.51
điểm BLEU.

Thứ ba, bằng cách kết hợp OVERMISS và SWIE,
có thể thấy cải thiện thêm trong tất cả các backbone
trong hướng dịch En⇒De từ 0.05 đến 0.56 điểm
BLEU, và trong BLOOMZ-7b-mt trong ba trong
số bốn hướng dịch. Vì cả hai phương pháp đều nhằm
cải thiện độ trung thành, sự kết hợp của chúng không
trực giao.

4.5 Dịch câu dài
Để đánh giá hiệu quả của SWIE trong bối cảnh dịch
văn bản dài, chúng tôi sử dụng cách tiếp cận nối
tiếp để hợp nhất 3-5 câu liền kề

--- TRANG 7 ---
[Bảng dữ liệu hiệu suất dịch thuật của LLM trên các tập test WMT22 và Flores được hiển thị với các điểm số BLEU và COMET cho các mô hình khác nhau và các hướng dịch khác nhau]

Bảng 3: Hiệu suất dịch thuật của LLM trên các tập test WMT22 và Flores. Các điểm số in đậm đề cập đến hiệu suất tốt nhất trong cùng hoặc các cài đặt tương đương.

mô hình    cài đặt        De⇒En   En⇒De   En⇒Zh   Zh⇒En
Parrot-hint             23.73    17.11    34.70    19.11
w/ SWIE                24.02    17.79    34.94    20.59

Bảng 4: So sánh giữa baseline và SWIE trên tập dữ liệu WMT22-concat.

từ các tập test WMT22, từ đó tạo ra tập test WMT22-
concat cho dịch văn bản dài. Tiếp theo, chúng tôi
tiến hành một thực nghiệm ablation trên SWIE sử
dụng tập test WMT22-concat trên BLOOMZ-3b.
Kết quả được trình bày trong Bảng 4 cho thấy SWIE
mang lại cải thiện trung bình 0.6725 điểm BLEU,
với sự tăng đáng chú ý 1.49 điểm BLEU được quan
sát thấy trong dịch từ tiếng Trung sang tiếng Anh.
Những phát hiện này cho thấy rằng tăng cường
hướng dẫn phù hợp hơn với các kịch bản văn bản
dài và có thể dẫn đến những cải thiện thêm trong
hiệu suất so với các tập test WMT22 gốc.

4.6 Hiệu suất Zero-shot
Sử dụng các hướng dịch zero-shot, khả năng theo
dõi hướng dẫn có thể được đánh giá hiệu quả. Chúng
tôi chọn 6 hướng zero-shot từ các tập test WMT22,
bao gồm Uk⇒En, Fr⇒De, Cs⇔En, và Ru⇔En.
Chúng tôi quan sát thấy SWIE dẫn đến 0.20 đến
0.58 điểm BLEU. Kết quả thực nghiệm như mong
đợi của chúng tôi vì SWIE tăng cường khả năng
theo dõi hướng dẫn của mô hình, và hướng dẫn cần
nhiều chú ý hơn trong kịch bản hướng dịch zero-shot.

4.7 Tác động của hướng dẫn suy luận
Chúng tôi kiểm tra tác động của các prompt suy
luận. Vì tập dữ liệu hướng dẫn tác vụ phụ cung cấp
cho mô hình thông tin chất lượng dịch thuật điển
hình, chúng tôi có thể sử dụng các tiền tố chi tiết
hơn trong giai đoạn suy luận để hướng dẫn quá
trình dịch của mô hình với nhận thức về các nguyên
tắc nhất định. Trong Bảng 6, cài đặt cơ bản có nghĩa
là hướng dẫn ngắn gọn nhất, tức là "dịch các câu
sau từ [ngôn ngữ nguồn] sang [ngôn ngữ đích]". Theo

--- TRANG 8 ---
cài đặt    Uk⇒En   Fr⇒De   Cs⇒En   En⇒Cs   Ru⇒En   En⇒Ru
Parrot-hint  6.77    19.58    4.97     2.69    17.59    4.35
w/ SWIE      7.33    19.73    5.14     2.85    17.79    4.74

Bảng 5: Hiệu suất điểm BLEU zero-shot dựa trên BLOOMZ-3b.

các tác vụ huấn luyện có trong các tập dữ liệu, chúng
tôi sử dụng một số hướng dẫn bổ sung để cung cấp
yêu cầu chi tiết hơn cho các mô hình, chẳng hạn như
đầu ra không có lỗi hoặc không có vấn đề dịch thừa/thiếu.
Trái với các phát hiện trong (Jiao et al., 2023a), gợi
ý "no-error" không mang lại lợi ích tích cực trong
tình huống mô hình được fine-tune trên OVERMISS,
trong khi "no-over", "no-miss" và "no-over/miss"
có thể cải thiện hiệu suất mô hình hơn nữa.

cài đặt         BLEU tổng thể
cơ bản           25.13
w/ no-error      24.76
w/ no-over       25.13
w/ no-miss       25.29
w/ no-over/miss  25.24

Bảng 6: So sánh giữa các prompt suy luận.

4.8 Định lượng độ trung thành
Về định lượng độ trung thành dịch máy cấp từ, chưa
có bộ công cụ tiêu chuẩn được sử dụng rộng rãi.
Cùng phương pháp như Phần Xây dựng dữ liệu ảo
giác tự nhiên, chúng tôi sử dụng các công cụ căn
chỉnh từ để khớp các câu nguồn và các câu suy luận
từng từ một, sau đó tính toán recall của tỷ lệ khớp
từ nguồn và tỷ lệ khớp từ giả thuyết, và sau đó tỷ
lệ có thể phản ánh mức độ thiếu sót và dư thừa. Các
điểm số cuối cùng được tính bằng cách lấy trung
bình tỷ lệ bao phủ nguồn và đích trên các tập test
WMT22 của chúng tôi. Kết quả hiển thị trong Bảng
7 rằng cả SWIE và OVERMISS đều có thể cải thiện
độ trung thành của kết quả, cho thấy hiệu quả của
phương pháp đề xuất của chúng tôi.

cài đặt                     điểm số
Parrot-hint                 87.94
w/ SWIE                     88.28
w/ OVERMISS                 88.84
w/ SWIE w/ OVERMISS         88.80

Bảng 7: Nghiên cứu ablation về điểm số độ trung thành trên SWIE và OVERMISS.

5 Hình dung chú ý không đầy đủ về hướng dẫn
Mục dữ liệu theo dõi hướng dẫn tiêu chuẩn của
chúng tôi được tổ chức như hướng dẫn, đầu vào,
và đầu ra tuần tự. Điểm chú ý trong transformers
có thể hiển thị các vị trí mà mô hình xử lý nhiều
hơn. Chúng tôi chia một mẫu dịch ngẫu nhiên từ
các tập test thành 3 span, bao gồm hướng dẫn, đầu
vào, và phản hồi. Tiếp theo, chúng tôi tính toán các
điểm chú ý tích lũy cho mỗi span trên mỗi token.
Giả sử a là ma trận điểm chú ý, sid là chỉ số của
cuối span, chúng tôi sử dụng Sspan để biểu diễn
điểm chú ý tích lũy trong một vị trí như được hiển
thị trong Phương trình 7.

Như được mô tả trong Hình 4, rõ ràng là các lớp
giữa của mô hình thể hiện điểm chú ý tích lũy cao
hơn đáng kể trên các span đầu vào, trong khi các
lớp dưới và trên thể hiện phân phối chú ý đồng đều
hơn. Quan sát này cho thấy rằng sự không đầy đủ
chú ý của hướng dẫn phát sinh trong các lớp giữa.
Theo đó, trong các cài đặt thực nghiệm của chúng
tôi, chúng tôi chọn kết hợp SWIE vào ba lớp giữa.

Chúng tôi tính toán tỷ lệ của điểm chú ý tại vị trí
kết thúc của hướng dẫn và điểm chú ý tại vị trí kết
thúc của đầu vào. Như được minh họa trong Hình
5, phương pháp của chúng tôi dẫn đến tỷ lệ chú ý
thấp hơn, đặc biệt cho các lớp giữa, có nghĩa là chú
ý về hướng dẫn tương đối cao hơn so với mô hình
baseline.

Sspan = ∑(i=sid+1 to T) a[i][sid]    (7)

6 Kết luận
Chúng tôi đề xuất SWIE và OVERMISS, một cấu
trúc mô hình bổ sung mới để tăng cường chú ý của
mô hình đối với hướng dẫn, và một phương pháp
xây dựng dữ liệu hiệu quả cho độ trung thành dịch
máy. Kết quả thực nghiệm cho thấy các phương
pháp của chúng tôi vượt trội hơn các baseline mạnh
trên các chỉ số dịch máy được sử dụng rộng rãi như

--- TRANG 9 ---
Hình 4: Điểm chú ý tích lũy trên các vị trí sau hướng dẫn và sau đầu vào cho mỗi lớp. Hình này dựa trên BLOOMZ-3b được fine-tune bởi tập dữ liệu Parrot-hint trong cấu trúc mô hình gốc.

Hình 5: So sánh giữa các mô hình có và không có SWIE về tỷ lệ chú ý giữa vị trí sau hướng dẫn và sau đầu vào. Thực nghiệm này dựa trên BLOOMZ-3b.

BLEU và COMET, và SWIE cải thiện hiệu suất dịch thuật đáng kể hơn trong các kịch bản văn bản dài và zero-shot. Để đánh giá độ trung thành dịch thuật, chúng tôi sử dụng một chỉ số căn chỉnh từ đa ngôn ngữ, và kết quả minh họa thêm hiệu quả của phương pháp của chúng tôi về dịch thuật trung thành. Thông qua các điểm chú ý nội bộ của các mô hình, chúng tôi hình dung phân phối chú ý trên mô hình gốc và sự dịch chuyển chú ý được tạo ra bởi SWIE, từ đó xác thực giả định của chúng tôi về sự cần thiết của việc tăng chú ý về hướng dẫn.

Trong tương lai, các khía cạnh sau có thể được khám phá dựa trên công trình của chúng tôi: (1) điều tra các phương pháp có thể giải thích và có thể huấn luyện để xây dựng trọng số phân đoạn; (2) mở rộng phương pháp xây dựng dữ liệu sang các tác vụ khác; (3) khám phá các phương pháp để giảm độ trễ suy luận.

Tài liệu tham khảo
[Danh sách tài liệu tham khảo được giữ nguyên như trong bản gốc]

--- TRANG 10 ---
[Phần tài liệu tham khảo tiếp theo được giữ nguyên như trong bản gốc]

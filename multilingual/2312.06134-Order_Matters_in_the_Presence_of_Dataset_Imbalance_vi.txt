# Thứ tự quan trọng trong sự hiện diện của mất cân bằng tập dữ liệu cho học đa ngôn ngữ

Dami Choi∗†
Đại học Toronto
choidami@cs.toronto.edu

Derrick Xin∗
Google Research
dxin@google.com

Hamid Dadkhahi
Google Research
hdadkhahi@google.com

Justin Gilmer
Google Deepmind
gilmer@google.com

Ankush Garg
Google Deepmind
ankugarg@google.com

Orhan Firat
Google Deepmind
orhanf@google.com

Chih-Kuan Yeh
Google Deepmind
chihkuanyeh@google.com

Andrew M. Dai
Google Deepmind
adai@google.com

Behrooz Ghorbani
OpenAI
ghorbani@openai.com

## Tóm tắt

Trong bài báo này, chúng tôi nghiên cứu thực nghiệm về động lực tối ưu hóa của học đa nhiệm vụ, đặc biệt tập trung vào những động lực chi phối một bộ sưu tập các nhiệm vụ với sự mất cân bằng dữ liệu đáng kể. Chúng tôi trình bày một phương pháp đơn giản nhưng hiệu quả là tiền huấn luyện trên các nhiệm vụ tài nguyên cao, sau đó là tinh chỉnh trên hỗn hợp các nhiệm vụ tài nguyên cao/thấp. Chúng tôi cung cấp một nghiên cứu thực nghiệm và phân tích kỹ lưỡng về lợi ích của phương pháp này cho thấy nó đạt được những cải thiện nhất quán tương đối so với hồ sơ đánh đổi hiệu suất của phương pháp trọng số tĩnh tiêu chuẩn. Chúng tôi phân tích trong những chế độ dữ liệu nào phương pháp này có thể áp dụng và cho thấy những cải thiện thực nghiệm trong dịch máy thần kinh (NMT) và mô hình hóa ngôn ngữ đa ngôn ngữ.

## 1 Giới thiệu

Trong vài năm qua, các mạng thần kinh đa nhiệm vụ lớn đã nổi lên như một mô hình mô hình hóa phổ biến trong học sâu. Sức hấp dẫn đằng sau những mô hình này là chúng có thể tận dụng học chuyển giao giữa các nhiệm vụ để vượt trội hơn các mô hình đơn nhiệm vụ. Thật vậy, các mô hình đa nhiệm vụ đã đạt được hiệu suất tối ưu trong các lĩnh vực như dịch máy [2,8], hiểu ngôn ngữ [24,32], và nhận dạng giọng nói [4, 3].

Thật không may, việc tối ưu hóa các mô hình đa nhiệm vụ như vậy vẫn là một thách thức. Để huấn luyện hiệu quả những mô hình này, các nhiệm vụ khác nhau cần được cân bằng trong quá trình huấn luyện. Điều này thường được thực hiện bằng cách lấy mẫu mỗi nhiệm vụ với xác suất tĩnh.

Các công trình trước đây [31,20] cho thấy bằng chứng rằng khi tất cả các nhiệm vụ đều ở chế độ giàu dữ liệu (tài nguyên cao), các phương pháp lấy mẫu tĩnh như vậy mang lại kết quả tối ưu. Tuy nhiên, khi một số nhiệm vụ có dữ liệu thưa thớt (tài nguyên thấp)², điều này khá phổ biến trong các ứng dụng thực tế, tính tối ưu của lấy mẫu tĩnh không rõ ràng.

Vấn đề với lấy mẫu tĩnh khi có mặt các nhiệm vụ tài nguyên thấp là nó khó xử lý việc quá khớp trên các nhiệm vụ tài nguyên thấp. Điều này là do dừng sớm không phải là giải pháp khả thi do các nhiệm vụ tài nguyên cao cần nhiều epoch hơn để hội tụ. Sơ đồ học chuyển giao của tiền huấn luyện trên tài nguyên cao và tinh chỉnh trên các nhiệm vụ tài nguyên thấp (như trong [33]) cung cấp giải pháp cho vấn đề quá khớp, vì việc huấn luyện các nhiệm vụ tài nguyên cao và thấp được tách biệt. Không chỉ vậy, việc huấn luyện các nhiệm vụ tài nguyên thấp có thể hưởng lợi từ việc chuyển giao tích cực đến từ việc thực hiện tốt trên các nhiệm vụ tài nguyên cao. Tuy nhiên, vấn đề với phương pháp này là trong giai đoạn tinh chỉnh, sự quên thảm khốc của các nhiệm vụ tiền huấn luyện xảy ra.

Trong bài báo này, chúng tôi giới thiệu một sơ đồ huấn luyện đơn giản kết hợp những điều tốt nhất của lấy mẫu tĩnh và học chuyển giao: tiền huấn luyện trên một nhiệm vụ tài nguyên cao và tinh chỉnh chung trên hỗn hợp các nhiệm vụ tài nguyên cao và thấp. Một sơ đồ tiền huấn luyện và tinh chỉnh hiệu quả cho phép dừng sớm bằng cách cho phép việc huấn luyện các nhiệm vụ tài nguyên thấp diễn ra chỉ khi cần thiết để ngăn chặn quá khớp, trong khi huấn luyện nhiệm vụ tài nguyên cao trong thời gian cần thiết. Hơn nữa, tiền huấn luyện trên một nhiệm vụ tài nguyên cao có thể cho phép chuyển giao tích cực cho các nhiệm vụ tài nguyên thấp và dẫn đến hội tụ nhanh hơn trong giai đoạn tinh chỉnh. Cuối cùng, giai đoạn tinh chỉnh trên hỗn hợp các nhiệm vụ tài nguyên cao và thấp sẽ không chỉ khắc phục vấn đề quên thảm khốc của việc tinh chỉnh chỉ trên các nhiệm vụ tài nguyên thấp, mà còn hưởng lợi từ việc học chuyển giao thêm giữa tất cả các nhiệm vụ.

Thông qua một nghiên cứu thực nghiệm rộng rãi, chúng tôi thấy rằng sơ đồ tiền huấn luyện và tinh chỉnh chung mang lại hiệu suất nhiệm vụ tài nguyên thấp vượt trội so với cả lấy mẫu tĩnh và sơ đồ học chuyển giao. Chúng tôi quan sát thấy rằng việc cải thiện hiệu suất trên lấy mẫu tĩnh được thúc đẩy bởi hai cơ chế. Thứ nhất là tiền huấn luyện khởi tạo giai đoạn tinh chỉnh tại một điểm xuất phát tốt hơn so với khởi tạo ngẫu nhiên do chuyển giao tích cực. Thứ hai là tỷ lệ lấy mẫu cao hơn có hiệu quả dữ liệu hơn so với tỷ lệ lấy mẫu thấp hơn. Vì phương pháp của chúng tôi có hai giai đoạn huấn luyện riêng biệt, giai đoạn huấn luyện tài nguyên thấp có thể ngắn. Điều này cho phép chúng tôi tăng tỷ lệ lấy mẫu tài nguyên thấp mà không có nguy cơ quá khớp. Thật vậy, phương pháp của chúng tôi có hiệu quả dữ liệu hơn so với lấy mẫu tĩnh về mặt các nhiệm vụ tài nguyên thấp trong suốt toàn bộ giai đoạn tinh chỉnh, đạt được hiệu suất nhiệm vụ tài nguyên thấp tốt hơn trong khi chỉ sử dụng một phần dữ liệu được nhìn thấy bởi lấy mẫu tĩnh. Chúng tôi quan sát thêm rằng tiền huấn luyện và tinh chỉnh chung dường như có hiệu ứng điều hòa. Tuy nhiên, chúng tôi thấy rằng điều hòa không phải là yếu tố chính đằng sau việc cải thiện hiệu suất, vì việc tăng điều hòa rõ ràng, như dropout, không cải thiện hiệu suất đến mức mà phương pháp của chúng tôi làm được.

Những đóng góp của bài báo này có thể được tóm tắt như sau:

• Theo hiểu biết tốt nhất của chúng tôi, chúng tôi là những người đầu tiên cho thấy rằng có thể đẩy biên Pareto của lấy mẫu tĩnh trong chế độ mất cân bằng dữ liệu.

• Chúng tôi trình bày một thuật toán đơn giản có thể dễ dàng sử dụng để thúc đẩy hiệu suất của các nhiệm vụ tài nguyên thấp trong các mô hình đa ngôn ngữ.

• Chúng tôi cho thấy trên các khối lượng công việc thực tế (lên đến 13B tham số) rằng sơ đồ của chúng tôi hoạt động tốt hơn so với lấy mẫu tĩnh và học chuyển giao đối với cặp ngôn ngữ/ngôn ngữ tài nguyên thấp.

## 2 Nền tảng

Trong công trình của chúng tôi, chúng tôi tập trung vào thiết lập có giám sát, nơi các tham số mô hình θ∈Rp của chúng tôi được huấn luyện trên K nhiệm vụ khác nhau, với hàm mất mát cho nhiệm vụ i là Li(θ).

Chúng tôi giới thiệu ý tưởng về tối ưu Pareto để giải thích tốt hơn hiệu ứng đánh đổi xảy ra khi huấn luyện trên nhiều nhiệm vụ khác nhau.

**Định nghĩa (Tối ưu Pareto)** . θ∈Rp chi phối Pareto một θ′ khác nếu ∀1≤i≤K, Li(θ)≤ Li(θ′) và tồn tại một nhiệm vụ j trong đó Lj(θ)<Lj(θ′). θ là tối ưu Pareto nếu nó không bị chi phối bởi bất kỳ điểm nào khác. Tập hợp các điểm tối ưu Pareto được ký hiệu là biên Pareto.

² Trong tài liệu này, các nhiệm vụ giàu dữ liệu và thưa dữ liệu thường được gọi là tài nguyên cao và tài nguyên thấp tương ứng. Lưu ý rằng việc một nhiệm vụ có tài nguyên cao hay không phụ thuộc vào cả lượng dữ liệu huấn luyện và dung lượng mô hình.

Một phương pháp tiêu chuẩn để tối ưu hóa các mô hình đa nhiệm vụ là vô hướng hóa [5] hoặc lấy mẫu tĩnh:

ˆθ(w) = arg min θ ∑K i=1 wiLi(θ), (1)

trong đó w là một vectơ cố định của các trọng số nhiệm vụ được xác định trước với w>0 và ∑i wi= 1.

Trong công trình của chúng tôi, chúng tôi tuân theo quy ước và thực hiện vô hướng hóa thông qua lấy mẫu tỷ lệ, nơi dữ liệu từ nhiệm vụ i được lấy mẫu với xác suất bằng wi. Trong trường hợp này, hàm mất mát kỳ vọng bằng với hàm mất mát từ vô hướng hóa:

L(θ) = Ex[ℓ(x;θ)] = ∑K i=1 P(nhiệm vụ i)Ex∼nhiệm vụ i[ℓ(x;θ)] = ∑K i=1 wiLi(θ). (2)

Công trình trước đây [31] đã nghiên cứu hành vi đánh đổi hiệu suất của vô hướng hóa và nhiều phương pháp tối ưu hóa đa nhiệm vụ (MTO) khác nhau trong thiết lập hai nhiệm vụ. Họ thấy rằng cả trong trường hợp tài nguyên cao và trong trường hợp mất cân bằng dữ liệu, không có phương pháp MTO nào cải thiện được biên Pareto của vô hướng hóa. Trong công trình của chúng tôi, chúng tôi so sánh hành vi đánh đổi hiệu suất của vô hướng hóa và phương pháp được đề xuất của chúng tôi, và thấy rằng biên Pareto của vô hướng hóa có thể được cải thiện trong chế độ mất cân bằng dữ liệu.

Lưu ý rằng về mặt thực tế, không khả thi để xác định θ có thực sự tối ưu Pareto hay không vì chúng ta phải kiểm tra rằng nó không bị chi phối bởi tất cả θ′∈Rp. Theo [31], thay vì xem xét tất cả Rp, chúng tôi chỉ xem xét các tham số có thể đạt được bởi một tập hợp siêu tham số cố định.

## 3 Tiền huấn luyện Tinh chỉnh chung

Cho K nhiệm vụ, trong đó một số là tài nguyên thấp, mục tiêu của chúng tôi là tối ưu hóa hiệu suất của các nhiệm vụ tài nguyên thấp mà không hy sinh hiệu suất của các nhiệm vụ còn lại. Lấy mẫu tĩnh không lý tưởng vì tất cả các nhiệm vụ được thấy liên tục trong suốt toàn bộ quá trình huấn luyện, dẫn đến quá khớp các nhiệm vụ tài nguyên thấp trong khi các nhiệm vụ tài nguyên cao vẫn cần được học. Việc chia nhỏ huấn luyện thành hai giai đoạn một cách ngây thơ và huấn luyện trên các nhiệm vụ tài nguyên thấp ở giai đoạn sau dẫn đến quên thảm khốc các nhiệm vụ được huấn luyện trước đó.

Giả sử tồn tại ít nhất một nhiệm vụ tài nguyên cao, chúng tôi đề xuất trước tiên tiền huấn luyện trên một nhiệm vụ tài nguyên cao, và tinh chỉnh mô hình kết quả trên hỗn hợp đầy đủ của K nhiệm vụ. Chúng tôi gọi phương pháp này là tiền huấn luyện tinh chỉnh chung³.

Trong các thí nghiệm sơ bộ của chúng tôi, chúng tôi thấy rằng việc đặt lại lịch tỷ lệ học và trạng thái tối ưu hóa khi chuyển sang giai đoạn tinh chỉnh chung là quan trọng. Điều này là do việc học cực kỳ chậm cho các nhiệm vụ được giới thiệu mới khi tỷ lệ học đã bị suy giảm. Trong các đánh giá của chúng tôi, chúng tôi thêm thí nghiệm với việc thêm đặt lại vào đường cơ sở vô hướng hóa để đảm bảo rằng những cải thiện từ phương pháp của chúng tôi không chỉ đơn thuần từ việc đặt lại. Xem Phần 4.1.2 và 4.2 để biết thêm chi tiết.

Quy trình huấn luyện hai giai đoạn của chúng tôi giới thiệu các siêu tham số bổ sung so với vô hướng hóa: các siêu tham số liên quan đến giai đoạn tiền huấn luyện, và độ dài của giai đoạn tiền huấn luyện. Tuy nhiên, chúng tôi thấy rằng việc điều chỉnh không khó khăn hơn nhiều so với vô hướng hóa, và trong một số trường hợp nó dễ dàng hơn để điều chỉnh. Giai đoạn tiền huấn luyện chỉ liên quan đến việc điều chỉnh cho một nhiệm vụ duy nhất, điều này dễ dàng hơn nhiều so với việc điều chỉnh cho nhiều nhiệm vụ. Chúng tôi cũng kỳ vọng giai đoạn tinh chỉnh chung sẽ ngắn hơn so với độ dài huấn luyện đầy đủ của vô hướng hóa; do đó, việc điều chỉnh cho giai đoạn thứ hai nên tương đương hoặc dễ dàng hơn so với vô hướng hóa. Cuối cùng, kết quả của chúng tôi cho thấy rằng tiền huấn luyện không làm tổn hại đến hiệu suất tinh chỉnh và tiền huấn luyện lâu hơn dẫn đến tinh chỉnh tốt hơn. Từ điều này, chúng tôi khuyến nghị rằng nếu có ngân sách huấn luyện nghiêm ngặt, tốt hơn nên thận trọng và tiền huấn luyện trong thời gian ngắn hơn. Tuy nhiên, nếu mục tiêu là đạt được hiệu suất tốt nhất và không có ngân sách tính toán nghiêm ngặt, chúng tôi khuyến nghị tiền huấn luyện càng lâu càng tốt trước khi tinh chỉnh. Xem Phần 4.3 để biết thêm chi tiết.

³ Chúng tôi sử dụng thuật ngữ 'tiền huấn luyện' và 'tinh chỉnh' chỉ để phân biệt hai giai đoạn huấn luyện, và rằng các mục tiêu huấn luyện giống nhau cho cả hai giai đoạn. Nói cách khác, chúng tôi không đề xuất sử dụng bất kỳ mục tiêu tự giám sát cụ thể nào cho giai đoạn tiền huấn luyện, hoặc huấn luyện trên các nhiệm vụ hạ nguồn cho giai đoạn tinh chỉnh.

## 4 Thí nghiệm

Trong các phần sau, chúng tôi áp dụng sơ đồ huấn luyện được đề xuất của chúng tôi cho NMT (nơi mỗi nhiệm vụ là một cặp ngôn ngữ) và huấn luyện đa ngôn ngữ (nơi mỗi nhiệm vụ là một ngôn ngữ). Trong các thí nghiệm NMT, chúng tôi cho thấy rằng tiền huấn luyện tinh chỉnh chung vượt qua biên đánh đổi của vô hướng hóa thông qua những cải thiện đáng kể trên nhiệm vụ tài nguyên thấp– một thành tích mà nhiều phương pháp tối ưu hóa đa nhiệm vụ dựa trên gradient phổ biến không thể đạt được [31]. Trong các thí nghiệm mô hình hóa ngôn ngữ, chúng tôi mở rộng số lượng nhiệm vụ, và cho thấy rằng phương pháp của chúng tôi duy trì những lợi ích tương tự cho các ngôn ngữ tài nguyên thấp.

### 4.1 Dịch máy thần kinh

Đối với thí nghiệm đầu tiên của chúng tôi, chúng tôi tập trung vào thiết lập nơi chúng tôi có thể theo dõi và so sánh các biên đánh đổi thu được có và không có tiền huấn luyện. Như trong công trình trước đây [31], chúng tôi chọn làm việc trên thiết lập hai nhiệm vụ do tính dễ dàng trong việc trực quan hóa các đường cong đánh đổi hiệu suất.

Chúng tôi chọn các cặp ngôn ngữ tài nguyên cao và thấp từ tập dữ liệu WMT, nơi English →{Chinese, French} là các cặp ngôn ngữ tài nguyên cao, và English →{Romanian, Hindi} là các cặp ngôn ngữ tài nguyên thấp. Xem Bảng 1 để biết chi tiết về mỗi cặp ngôn ngữ. Tất cả các mô hình trong phần này sử dụng kiến trúc transformer encoder-decoder pre-LayerNorm [28]. Trong bài báo chính, chúng tôi trình bày kết quả trên các mô hình với ba lớp encoder và ba lớp decoder. Kết quả thu được với kích thước mô hình lớn hơn có trong Phụ lục A.2. Chi tiết thêm, bao gồm các siêu tham số, có trong A.1.

**Bảng 1: Tổng quan về các nguồn dữ liệu được sử dụng trong các thí nghiệm NMT của chúng tôi. Tập dữ liệu của chúng tôi từ WMT.**

| Cặp ngôn ngữ | # Ví dụ huấn luyện | # Ví dụ đánh giá |
|---|---|---|
| En-Fr '15 | 40,853,298 | 4,503 |
| En-Zh '19 | 25,986,436 | 3,981 |
| En-Ro '16 | 610,320 | 1,999 |
| En-Hi '14 | 313,748 | 520 |

Để theo dõi các biên đánh đổi cho phương pháp tiền huấn luyện tinh chỉnh chung và đường cơ sở vô hướng hóa, chúng tôi tuân theo phương pháp sau. Đối với vô hướng hóa, chúng tôi lặp qua một lưới trọng số nhiệm vụ (vì chỉ có hai nhiệm vụ, một lưới là một hàm tuyến tính của độ chi tiết) và huấn luyện trên hai cặp ngôn ngữ trong N bước sử dụng lấy mẫu tỷ lệ theo trọng số nhiệm vụ. Đối với phương pháp tiền huấn luyện tinh chỉnh chung, trước tiên chúng tôi tiền huấn luyện trên cặp ngôn ngữ tài nguyên cao trong N1 bước huấn luyện. Sau đó chúng tôi đặt lại trạng thái tối ưu hóa và lịch tỷ lệ học và tinh chỉnh trên hỗn hợp các cặp ngôn ngữ tài nguyên cao và thấp trong N2 bước huấn luyện sao cho N1+N2=N. Đối với giai đoạn tinh chỉnh, chúng tôi lặp qua một lưới trọng số nhiệm vụ như với vô hướng hóa. Lưới tỷ lệ lấy mẫu sẽ theo dõi một biên đánh đổi hiệu suất, có thể được sử dụng để so sánh phương pháp của chúng tôi và vô hướng hóa.

Cuối cùng, chúng tôi huấn luyện một đường cơ sở khởi động lại để loại bỏ khả năng rằng bất kỳ cải thiện nào từ tiền huấn luyện tinh chỉnh chung đều do việc đặt lại trạng thái tối ưu hóa và lịch tỷ lệ học trước khi tinh chỉnh. Đường cơ sở khởi động lại lấy mô hình thu được thông qua vô hướng hóa được huấn luyện trong N1 bước, đặt lại trạng thái tối ưu hóa và lịch tỷ lệ học, và tiếp tục huấn luyện nó với cùng tỷ lệ lấy mẫu như trong vô hướng hóa.

#### 4.1.1 Tài nguyên cao và Tài nguyên cao:

Chúng tôi bắt đầu bằng cách nhighlight rằng tiền huấn luyện tinh chỉnh chung không cho thấy lợi ích nếu tất cả các nhiệm vụ đều có tài nguyên cao. Hình 1 cho thấy rằng trong các nhiệm vụ dịch English →{Chinese, French}, hiệu suất trên mỗi cặp ngôn ngữ bị giới hạn bởi lượng dữ liệu được nhìn thấy từ cặp đó. Nói cách khác, tiền huấn luyện trên En →Fr không thể hoạt động như một proxy cho dữ liệu En →Zh, vì nếu có thể, biên sẽ được cải thiện. Đồng thời, tiền huấn luyện không tác động tiêu cực đến việc huấn luyện En →Zh. Hình 21 và 22 cho thấy rằng tiền huấn luyện không ảnh hưởng đến hiệu quả học tập cho En →Zh (độ dốc của các đường cong tương tự nhau), và cũng không dẫn đến khởi tạo tồi tệ hơn cho En →Zh.

#### 4.1.2 Tài nguyên cao và Tài nguyên thấp

Trong thiết lập mất cân bằng dữ liệu của English →{Romanian, French}, chúng tôi tiền huấn luyện trong 400k bước và tinh chỉnh trong 50k bước để nhấn mạnh các lợi ích tính toán của tiền huấn luyện tinh chỉnh. Mặc dù một lần chạy đầy đủ duy nhất của vô hướng hóa (N bước) và tiền huấn luyện tinh chỉnh (N1+N2=N) mất cùng một lượng tính toán, tiền huấn luyện tinh chỉnh chung làm cho việc điều chỉnh siêu tham số hiệu quả hơn nhiều, vì 1) điều chỉnh cho tiền huấn luyện là trên một nhiệm vụ duy nhất và do đó, dễ dàng hơn để điều chỉnh, và 2) điều chỉnh cho tinh chỉnh nhanh hơn vì N2≪N.

Trong Hình 2, chúng tôi có thể quan sát thấy rằng tiền huấn luyện tinh chỉnh chung có thể đạt được các điểm đánh đổi hiệu suất vượt ra ngoài những gì có thể đạt được thông qua vô hướng hóa. Tiền huấn luyện trên một cặp ngôn ngữ tài nguyên cao tạo ra các điểm không bị chi phối bằng cách mang lại hiệu suất tốt hơn đáng kể trong nhiệm vụ tài nguyên thấp (En →Ro) mà không hoàn toàn hy sinh hiệu suất trong nhiệm vụ tài nguyên cao (En→Fr). Thêm vào đó, nó có thể làm điều này trong khi nhìn thấy ít token Romanian tổng thể hơn theo Hình 3.

Chúng tôi thấy kết quả tương tự cho En →{Hi, Fr}, được hiển thị trong Hình 12 trong Phụ lục. Đây là kết quả đáng ngạc nhiên vì tiếng Pháp và tiếng Hindi ít giống nhau về mặt ngôn ngữ hơn so với tiếng Pháp và tiếng Romania. Cuối cùng, chúng tôi có thể thấy từ hiệu suất không tối ưu của đường cơ sở khởi động lại trong Hình 2 và 12 rằng hành động đặt lại không phải là lý do đằng sau thành công của sơ đồ tiền huấn luyện tinh chỉnh chung. Chúng tôi cung cấp các đánh giá điểm BLEU cho En →{Ro, Fr} và En →{Hi, Fr} trong Phụ lục A.5, xác nhận rằng những cải thiện trong hàm mất mát chuyển thành các chỉ số hạ nguồn.

#### 4.1.3 Phân tích

Việc cải thiện hiệu suất của tiền huấn luyện tinh chỉnh chung bắt nguồn từ hai cơ chế chính.

• Tiền huấn luyện sử dụng chuyển giao tích cực giữa các nhiệm vụ, và khởi tạo giai đoạn tinh chỉnh tại một điểm xuất phát tốt hơn so với khởi tạo ngẫu nhiên. Hình 3 cho thấy hiệu ứng này cho các nhiệm vụ dịch En →{Ro, Fr}.

• Tỷ lệ lấy mẫu cao hơn có hiệu quả dữ liệu hơn so với tỷ lệ lấy mẫu thấp hơn. Hình 4 cho thấy cách tối ưu hóa (hiệu suất tập huấn luyện) trở nên có hiệu quả dữ liệu hơn khi tỷ lệ lấy mẫu tăng. Tuy nhiên, về mặt tổng quát hóa, việc tăng tỷ lệ lấy mẫu chỉ hoạt động đến một điểm nhất định, nơi quá khớp bắt đầu xảy ra.

Theo thiết kế, tiền huấn luyện tinh chỉnh chung có hai giai đoạn huấn luyện riêng biệt cho phép giai đoạn huấn luyện tài nguyên thấp ngắn. Điều này cho phép chúng tôi tăng tỷ lệ lấy mẫu tài nguyên thấp, dẫn đến huấn luyện nhanh hơn. Hiệu ứng này có thể thấy trong Hình 2, nơi tỷ lệ lấy mẫu En →Ro dẫn đến hiệu suất En →Ro tốt nhất là 0.4, trong khi đối với tiền huấn luyện tinh chỉnh chung, tỷ lệ tốt nhất là 0.5. Hình 3 xác nhận rằng thực sự sau khi tiền huấn luyện, tinh chỉnh trên En →Ro có hiệu quả dữ liệu hơn so với không tiền huấn luyện.

Tinh chỉnh chung cũng là một phần quan trọng ngoài thiết lập hai giai đoạn. Chỉ tinh chỉnh trên nhiệm vụ tài nguyên thấp, đây là sơ đồ học chuyển giao cổ điển, dẫn đến quá khớp và quên thảm khốc của nhiệm vụ tiền huấn luyện như được hiển thị trong Hình 6.

Cuối cùng, Hình 2 cho thấy rằng tiền huấn luyện tinh chỉnh chung mang lại hiệu suất tập huấn luyện tồi tệ hơn, và do đó, có thể được coi là có hiệu ứng điều hòa. Chúng tôi cho thấy trong Hình 5 rằng điều hòa một mình không giải thích hiệu suất vượt trội của sơ đồ của chúng tôi.

Kết quả đã thấy cho đến nay cho thấy rằng thứ tự dữ liệu có vấn đề khi huấn luyện khi có mặt một nhiệm vụ tài nguyên thấp, vì việc nhìn thấy dữ liệu tài nguyên cao trước rồi mới nhìn thấy dữ liệu tài nguyên thấp sau đó đẩy biên pareto của việc nhìn thấy cả hai loại dữ liệu cùng lúc.

### 4.2 Huấn luyện đa ngôn ngữ

Trong phần này, chúng tôi mở rộng từ thiết lập hai nhiệm vụ thành thiết lập nhiều nhiệm vụ. Chúng tôi huấn luyện trên năm ngôn ngữ từ tập dữ liệu mC4 [32]–English, Hindi, Gujarati, Swahili, và Gaelic– sử dụng mục tiêu span corruption từ T5 [24]. Xem Bảng 2 để biết chi tiết về tập dữ liệu. Theo kiểu điển hình, tập dữ liệu mC4 được sử dụng trong giai đoạn tiền huấn luyện cho các mô hình (không nên nhầm lẫn với phương pháp tiền huấn luyện tinh chỉnh chung của chúng tôi). Những mô hình này sau đó được áp dụng cho các nhiệm vụ hạ nguồn như trả lời câu hỏi. Giai đoạn tiền huấn luyện đa ngôn ngữ này cũng được biết đến như vấn đề cân bằng ngôn ngữ. Mục tiêu của chúng tôi là cho thấy rằng phương pháp hai giai đoạn của chúng tôi có thể cân bằng hiệu quả các ngôn ngữ tài nguyên cao và thấp, cải thiện hiệu suất trên các ngôn ngữ tài nguyên thấp vượt ra ngoài những gì có thể đạt được bằng phương pháp thông thường của lấy mẫu nhiệt độ trong khi không hy sinh hiệu suất trên các ngôn ngữ tài nguyên cao.

**Bảng 2: Dữ liệu được sử dụng từ mC4.**

| Ngôn ngữ | # Ký tự (B) |
|---|---|
| En (English) | 13,396 |
| Hi (Hindi) | 75 |
| Gu (Gujarati) | 3.6 |
| Gd (Gaelic) | 0.8 |
| Sw (Swahili) | 4.1 |

Lưu ý rằng trong kho ngữ liệu mC4, tiếng Anh lớn hơn 16745 lần so với ngôn ngữ nhỏ nhất mà chúng tôi sử dụng. Sự mất cân bằng dữ liệu này nhấn mạnh sự cần thiết cho việc cân bằng ngôn ngữ hiệu quả, đặc biệt là trong việc xác định tỷ lệ của mỗi ngôn ngữ được sử dụng trong quá trình huấn luyện. Điều này đặt ra một vấn đề cực kỳ thách thức và đòi hỏi tính toán cao, vì không khả thi để đơn giản quét các trọng số vô hướng hóa như trong thiết lập hai nhiệm vụ.

Đối với thiết lập huấn luyện của chúng tôi, chúng tôi tuân theo sát mT5 [32] cho kiến trúc mô hình và quy trình huấn luyện. Cụ thể, chúng tôi sử dụng mô hình mT5-XXL (13B tham số), đây là kiến trúc transformer encoder-decoder. Chi tiết huấn luyện bổ sung có trong Phụ lục B.

**Lấy mẫu nhiệt độ** Vì chúng tôi tăng số lượng nhiệm vụ trong thiết lập này, việc mô tả chi tiết toàn bộ biên đánh đổi vô hướng hóa sẽ không khả thi về mặt tính toán. Do đó, chúng tôi sử dụng phương pháp heuristic lấy mẫu nhiệt độ được sử dụng rộng rãi [11,7,2]. Cho Di là kích thước dữ liệu của ngôn ngữ hoặc nhiệm vụ i, chúng tôi sau đó định nghĩa phân phối thực nghiệm P cho mỗi nhiệm vụ i như:

P(x∈nhiệm vụ i) = Di/∑j Dj. (3)

Lấy mẫu nhiệt độ sau đó sử dụng phân phối Q được định nghĩa bởi tham số nhiệt độ τ như sau:

Q(x∈nhiệm vụ i) = P(x∈nhiệm vụ i)^(1/τ) / ∑j P(x∈nhiệm vụ j)^(1/τ) (4)

Tham số nhiệt độ τ điều khiển độ nhọn (hoặc độ phẳng) của phân phối lấy mẫu. Các τ thường được sử dụng trong tài liệu lớn hơn 1, về cơ bản là tăng mẫu các nhiệm vụ tài nguyên thấp và giảm mẫu các nhiệm vụ tài nguyên cao.

**Đường cơ sở lấy mẫu tĩnh** Lấy mẫu nhiệt độ phổ biến do tính đơn giản và trực quan của nó, nhưng hiệu suất của nó thay đổi rất nhiều theo τ. Đối với đường cơ sở lấy mẫu tĩnh của chúng tôi, chúng tôi điều chỉnh τ trong các giá trị thường được sử dụng trong tài liệu (1.43, 2, 3.33, 5) ở quy mô nhỏ hơn, và thấy rằng τ = 3.33 hoạt động tốt nhất về mặt các ngôn ngữ tài nguyên thấp. Chúng tôi cũng thử một chiến lược lấy mẫu phức tạp hơn gọi là UniMax [6], nhưng thấy rằng trên 5 ngôn ngữ chúng tôi chọn, nó không hoạt động tốt hơn τ = 3.33.

**Tiền huấn luyện tinh chỉnh chung** Đối với thiết lập tiền huấn luyện tinh chỉnh chung của chúng tôi, trước tiên chúng tôi tiền huấn luyện trên tiếng Anh, đặt lại trạng thái tối ưu hóa và lịch tỷ lệ học, và sau đó tinh chỉnh trên tất cả 5 ngôn ngữ sử dụng lấy mẫu nhiệt độ. Chúng tôi sử dụng cùng tỷ lệ lấy mẫu như đường cơ sở lấy mẫu tĩnh (τ = 3.33) để giảm chi phí điều chỉnh so với lấy mẫu tĩnh.

Như trong các thí nghiệm NMT, chúng tôi sử dụng đường cơ sở khởi động lại để loại bỏ hoàn toàn sơ đồ tiền huấn luyện tinh chỉnh. Đường cơ sở khởi động lại đặt lại trạng thái tối ưu hóa và lịch tỷ lệ học ở giữa quá trình huấn luyện cho đường cơ sở lấy mẫu tĩnh.

**Kết quả** Hình 7 và 8 cho thấy rằng trong khi việc khởi động lại lịch tỷ lệ học giúp cải thiện hiệu suất, tiền huấn luyện tinh chỉnh chung mang lại kết quả tốt nhất trên các nhiệm vụ tài nguyên thấp. Đáng ngạc nhiên, nó không chỉ cải thiện hiệu suất trên Gujarati, Gaelic, và Swahili, mà còn cho thấy sự nâng cao nhẹ trên tiếng Anh. Chúng tôi lưu ý rằng do sự mất cân bằng tập dữ liệu rất lớn, đường cơ sở lấy mẫu nhiệt độ quá khớp trên các nhiệm vụ tài nguyên thấp trước khi tiếng Anh có cơ hội hội tụ. Do đó, tiền huấn luyện tinh chỉnh chung có thể tận dụng các lợi ích được đề cập trong phần trước–điều hòa, chuyển giao, và giảm quên–để đạt được hiệu suất giới hạn dưới vượt trội với hiệu quả token cao hơn.

### 4.3 Độ dài của tiền huấn luyện

Phương pháp của chúng tôi đơn giản nhưng đi kèm với một số lựa chọn cần thực hiện, một trong đó là số bước tiền huấn luyện. Chúng tôi nghiên cứu hiệu ứng của số bước tiền huấn luyện trong NMT và mô hình hóa ngôn ngữ trên mC4 bằng cách tiền huấn luyện với ít hơn và nhiều bước hơn so với các phần trước. Với nhiệm vụ mô hình hóa ngôn ngữ, chúng tôi cố định tổng độ dài huấn luyện là 500k bước để mô phỏng kịch bản hạn chế tính toán. Chúng tôi chọn sử dụng một mô hình nhỏ hơn (mT5-XL thay vì mT5-XXL được sử dụng trong Phần 4.2 để huấn luyện nhanh hơn). Với NMT, chúng tôi cố định số bước tinh chỉnh, nhưng để tổng số bước huấn luyện thay đổi.

Hình 9(a) hiển thị các hiệu ứng của việc thay đổi độ dài tiền huấn luyện trong các thí nghiệm mC4. Chúng tôi thấy rằng tiền huấn luyện lâu hơn cải thiện hiệu suất tốt nhất có thể đạt được trên các nhiệm vụ tài nguyên thấp của Gujarati, Gaelic, và Swahili. Điều này mặc dù thực tế là số bước tinh chỉnh giảm do ngân sách tổng bước cố định. Nói cách khác, đối với 3 nhiệm vụ tài nguyên thấp, tiền huấn luyện lâu hơn cải thiện hiệu suất nhiều hơn so với việc tiếp xúc với các token. Mặt khác, hiệu suất trên tiếng Anh và Hindi xấu đi với độ dài tiền huấn luyện tăng. Đối với tiếng Anh, điều này do việc đặt lại lịch tỷ lệ học và việc giảm các bước tinh chỉnh. Đặt lại liên quan đến việc khởi động tỷ lệ học, làm xấu đi hiệu suất tiếng Anh trước khi cải thiện lại (xem panel tương ứng với En cho Hình 8). Việc giảm các bước tinh chỉnh cho tiếng Anh ít thời gian hơn để khôi phục hiệu suất từ tiền huấn luyện. Đối với Hindi, hiệu suất xấu đi đơn giản là vì nó không phải là một nhiệm vụ tài nguyên thấp trong bối cảnh này, và do đó, ít token được nhìn thấy dẫn đến hiệu suất tồi tệ hơn.

Trong Hình 9(b), chúng tôi thấy rằng trong các thí nghiệm NMT, tiền huấn luyện lâu hơn trên En →Fr dẫn đến các biên đánh đổi tổng thể tốt hơn, không chỉ cho nhiệm vụ tài nguyên thấp.

Ý nghĩa của những kết quả này là khi có ngân sách huấn luyện nghiêm ngặt, tốt hơn nên thận trọng và tiền huấn luyện trong thời gian ngắn hơn. Tuy nhiên, nếu mục tiêu là đạt được hiệu suất tốt nhất không có ngân sách tính toán nghiêm ngặt, tốt hơn là tiền huấn luyện càng lâu càng tốt trước khi tinh chỉnh. Lưu ý rằng huấn luyện tổng thể lâu hơn là một lựa chọn cho phương pháp của chúng tôi (bằng cách tiền huấn luyện lâu hơn) nhưng không cho lấy mẫu tĩnh vì lấy mẫu tĩnh cần liên tục huấn luyện trên các nhiệm vụ tài nguyên thấp, điều này sẽ dẫn đến quá khớp khi huấn luyện quá lâu.

## 5 Công trình liên quan

**Học đa nhiệm vụ** Học đa nhiệm vụ đã nhận được sự chú ý tăng lên trong việc có thể học nhiều nhiệm vụ một cách hiệu quả do chia sẻ tham số và chuyển giao giữa các nhiệm vụ. Trong lĩnh vực ngôn ngữ, dịch máy thần kinh đa ngôn ngữ [12,14] cho phép dịch từ nhiều ngôn ngữ nguồn sang nhiều ngôn ngữ đích. Do việc chuyển giao thông tin giữa các cặp ngôn ngữ, NMT đa ngôn ngữ đã thấy những cải thiện trong hiệu suất cặp ngôn ngữ tài nguyên thấp so với việc huấn luyện chỉ trên cặp ngôn ngữ đó [12]. Ngoài NMT, các mô hình ngôn ngữ được tiền huấn luyện đa ngôn ngữ lớn được sử dụng để tinh chỉnh trên nhiều nhiệm vụ hạ nguồn với các ngôn ngữ khác nhau [32]. Các công trình trước đây về huấn luyện trung gian tận dụng chuyển giao giữa nhiệm vụ [23] và giữa ngôn ngữ [22] để cải thiện hiệu suất nhiệm vụ hạ nguồn. Tuy nhiên, trong các phương pháp đa ngôn ngữ tồn tại vấn đề mất cân bằng tập dữ liệu, nơi các ngôn ngữ tài nguyên thấp có xu hướng bị tổn hại về hiệu suất. Gần đây, [6] thấy rằng lấy mẫu nhiệt độ ngây thơ có thể dẫn đến quá khớp các ngôn ngữ có số lượng thấp, và đề xuất giới hạn epoch với phân phối đồng đều cho các ngôn ngữ có số lượng cao, cho thấy cải thiện so với lấy mẫu nhiệt độ. Trong NMT đa ngôn ngữ, theo hiểu biết của chúng tôi, chúng tôi là những người đầu tiên cho thấy rằng một giai đoạn tiền huấn luyện đơn giản trên một cặp ngôn ngữ tài nguyên cao có thể cải thiện biên đánh đổi của lấy mẫu tĩnh. Hơn nữa, phương pháp của chúng tôi trực giao với các đổi mới trong chiến lược lấy mẫu như [6], và có thể cho thấy kết quả tốt hơn kết hợp với việc lấy mẫu tốt hơn.

**Học chuyển giao trong NMT** Lợi ích của học chuyển giao cho các cặp ngôn ngữ tài nguyên thấp đã được biết đến từ lâu trong tài liệu NMT [33,9,17]. [33] cho thấy rằng tiền huấn luyện trên một cặp ngôn ngữ tài nguyên cao có thể cải thiện hiệu suất so với việc huấn luyện từ đầu. Trong khi hầu hết các công trình trước đây về học chuyển giao trong NMT tập trung vào việc cải thiện hiệu suất trên dữ liệu song ngữ tài nguyên thấp, công trình gần đây [21] sử dụng học chuyển giao để cải thiện hiệu suất trên nhiều cặp ngôn ngữ. Không giống như tài liệu học chuyển giao trong NMT [21,15], chúng tôi cho thấy rằng tiền huấn luyện có thể đẩy biên tài nguyên thấp trong thiết lập đa ngôn ngữ, bằng cách kiểm tra một lưới tỷ lệ lấy mẫu và siêu tham số để theo dõi biên đánh đổi. Các công trình trước đây trong tài liệu nghiên cứu mối quan hệ giữa các cặp ngôn ngữ tiền huấn luyện và tinh chỉnh [10], đóng băng các phần khác nhau của mô hình trong quá trình tinh chỉnh [1], và thí nghiệm với tiền huấn luyện nhiều giai đoạn [9]. Chúng tôi kỳ vọng sẽ hưởng lợi thêm từ nghiên cứu được thực hiện theo hướng này.

**Học chương trình** Do tính chất mất cân bằng của các tập dữ liệu đa ngôn ngữ, chiến lược lấy mẫu tĩnh không thỏa mãn. [30] sử dụng một lịch lấy mẫu nhiệt độ được chế tạo thủ công lấy mẫu nhiều tài nguyên cao hơn ở đầu quá trình huấn luyện, và dần dần lấy mẫu nhiều ngôn ngữ tài nguyên thấp hơn. Sự thúc đẩy hiệu suất từ việc sử dụng lịch như vậy, so với lịch tĩnh, hỗ trợ các quan sát của chúng tôi từ tiền huấn luyện sử dụng một cặp ngôn ngữ tài nguyên cao. Mặt khác, có nhiều công trình sử dụng chiến lược phức tạp hơn cho lịch trình thích ứng [13,29,18]. So sánh, phương pháp của chúng tôi đơn giản với ít hoặc không có chi phí. Chúng tôi bao gồm thảo luận về kinh nghiệm của chúng tôi, mặc dù sơ bộ, với việc thử lịch trình thích ứng trong Phụ lục C. Cuối cùng, [26] cho thấy rằng việc sắp xếp dữ liệu trong một nhiệm vụ ảnh hưởng đến quên thảm khốc, điều này hỗ trợ các quan sát của chúng tôi.

## 6 Hạn chế và Công việc tương lai

Trong các thí nghiệm của chúng tôi, chúng tôi tập trung vào việc huấn luyện trên một nhiệm vụ tài nguyên cao duy nhất trong giai đoạn tiền huấn luyện. Sẽ là công việc tương lai thú vị để nghiên cứu tiền huấn luyện với nhiều hơn một ngôn ngữ hoặc cặp ngôn ngữ. Chúng tôi cũng chỉ thí nghiệm với việc tinh chỉnh tất cả các tham số của mô hình được tiền huấn luyện. Việc nghiên cứu hiệu ứng của việc đóng băng các phần khác nhau của mô hình trong quá trình tinh chỉnh, có thể như một hàm của mối quan hệ giữa các nhiệm vụ tiền huấn luyện và tinh chỉnh, được để lại cho công việc tương lai.

## 7 Kết luận

Trong công trình này, chúng tôi đã chứng minh lợi ích của một thiết lập tiền huấn luyện tinh chỉnh chung cho tối ưu hóa đa mục tiêu khi có hỗn hợp các nhiệm vụ tài nguyên cao và thấp. Chúng tôi cho thấy rằng khi có mặt sự mất cân bằng dữ liệu lớn, thứ tự mà các nhiệm vụ được giới thiệu có tác động đáng kể đến hiệu suất tổng thể. Chúng tôi chứng minh thông qua nhiều thiết lập thí nghiệm khác nhau rằng phương pháp này tạo ra các điểm có thể vượt qua biên đánh đổi đạt được bởi vô hướng hóa. Chúng tôi cho thấy rằng một điểm yếu chính của vô hướng hóa trong chế độ này là nó quá khớp trên nhiệm vụ tài nguyên thấp, không thể dừng sớm do nhiệm vụ tài nguyên cao không hội tụ. Phương pháp của chúng tôi vừa cho phép nhiệm vụ tài nguyên cao hội tụ trong quá trình tiền huấn luyện và ngăn chặn quá khớp thông qua tinh chỉnh chung. Nó cũng vượt trội hơn vô hướng hóa mà lấy mẫu dưới nhiệm vụ tài nguyên thấp do hiệu quả token cao hơn. Chúng tôi cũng cho thấy rằng tinh chỉnh chỉ trên nhiệm vụ tài nguyên thấp, một sơ đồ phổ biến trong tài liệu NMT, là không mong muốn do không thể ngăn chặn quên. Phương pháp của chúng tôi là một chiến lược tự nhiên đơn giản để tránh các chế độ thất bại ở trên. Cho thấy sự thúc đẩy hiệu suất đáng kể mà chúng tôi quan sát trong các thí nghiệm của mình, chúng tôi tin rằng chế độ huấn luyện này có tiềm năng trở thành một phương pháp tiêu chuẩn, đặc biệt là trong thời đại của các mô hình ngôn ngữ lớn.

## Lời cảm ơn và Công bố Tài trợ

Chúng tôi cảm ơn George E. Dahl, Wolfgang Macherey, và Macduff Hughes vì những nhận xét mang tính xây dựng của họ về phiên bản đầu tiên của bản thảo này. Thêm vào đó, chúng tôi cảm ơn Sourabh Medapati, Zachary Nado, Xavier Garcia, và Hyung Won Chung vì sự giúp đỡ của họ trong việc gỡ lỗi cơ sở mã của chúng tôi. Hơn nữa, chúng tôi biết ơn Soham Ghosh và Mojtaba Seyedhosseini vì những thảo luận có giá trị về vai trò của MTOs trong các mô hình quy mô lớn. Cuối cùng, chúng tôi cảm ơn Chris J.H. Zhang vì những thảo luận hữu ích.

## Tài liệu tham khảo

[1] Alham Fikri Aji, Nikolay Bogoychev, Kenneth Heafield, và Rico Sennrich. Trong dịch máy thần kinh, học chuyển giao chuyển giao cái gì? Association for Computational Linguistics, 2020.

[2] Naveen Arivazhagan, Ankur Bapna, Orhan Firat, Dmitry Lepikhin, Melvin Johnson, Maxim Krikun, Mia Xu Chen, Yuan Cao, George Foster, Colin Cherry, et al. Dịch máy thần kinh đa ngôn ngữ quy mô lớn trong tự nhiên: Những phát hiện và thách thức. arXiv preprint arXiv:1907.05019, 2019.

[3] Ankur Bapna, Colin Cherry, Yu Zhang, Ye Jia, Melvin Johnson, Yong Cheng, Simran Khanuja, Jason Riesa, và Alexis Conneau. mslam: Tiền huấn luyện chung đa ngôn ngữ quy mô lớn cho giọng nói và văn bản. arXiv preprint arXiv:2202.01374, 2022.

[4] Ankur Bapna, Yu-an Chung, Nan Wu, Anmol Gulati, Ye Jia, Jonathan H Clark, Melvin Johnson, Jason Riesa, Alexis Conneau, và Yu Zhang. Slam: Một encoder thống nhất cho mô hình hóa giọng nói và ngôn ngữ thông qua tiền huấn luyện chung giọng nói-văn bản. arXiv preprint arXiv:2110.10329, 2021.

[5] Stephen Boyd và Lieven Vandenberghe. Tối ưu hóa lồi. Cambridge university press, 2004.

[6] Hyung Won Chung, Xavier Garcia, Adam Roberts, Yi Tay, Orhan Firat, Sharan Narang, và Noah Constant. Unimax: Lấy mẫu ngôn ngữ công bằng và hiệu quả hơn cho tiền huấn luyện đa ngôn ngữ quy mô lớn. Trong The Eleventh International Conference on Learning Representations, 2022.

[7] Alexis Conneau, Kartikay Khandelwal, Naman Goyal, Vishrav Chaudhary, Guillaume Wenzek, Francisco Guzmán, Edouard Grave, Myle Ott, Luke Zettlemoyer, và Veselin Stoyanov. Học biểu diễn giữa ngôn ngữ không giám sát ở quy mô lớn. arXiv preprint arXiv:1911.02116, 2019.

[8] Marta R Costa-jussà, James Cross, Onur Çelebi, Maha Elbayad, Kenneth Heafield, Kevin Heffernan, Elahe Kalbassi, Janice Lam, Daniel Licht, Jean Maillard, et al. Không để lại ngôn ngữ nào: Mở rộng dịch máy lấy con người làm trung tâm. arXiv preprint arXiv:2207.04672, 2022.

[9] Raj Dabre, Atsushi Fujita, và Chenhui Chu. Khai thác đa ngôn ngữ thông qua tinh chỉnh đa giai đoạn cho dịch máy thần kinh tài nguyên thấp. Trong Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), trang 1410–1416, 2019.

[10] Raj Dabre, Tetsuji Nakagawa, và Hideto Kazawa. Một nghiên cứu thực nghiệm về mối quan hệ ngôn ngữ cho học chuyển giao trong dịch máy thần kinh. Trong Proceedings of the 31st Pacific Asia conference on language, information and computation, trang 282–286, 2017.

[11] Jacob Devlin. Multilingual bert readme. https://github.com/google-research/bert/blob/master/multilingual.md, 2018.

[12] Orhan Firat, Kyunghyun Cho, và Yoshua Bengio. Dịch máy thần kinh đa hướng, đa ngôn ngữ với cơ chế attention chung. arXiv preprint arXiv:1601.01073, 2016.

[13] Sébastien Jean, Orhan Firat, và Melvin Johnson. Lập lịch thích ứng cho học đa nhiệm vụ. arXiv preprint arXiv:1909.06434, 2019.

[14] Melvin Johnson, Mike Schuster, Quoc V Le, Maxim Krikun, Yonghui Wu, Zhifeng Chen, Nikhil Thorat, Fernanda Viégas, Martin Wattenberg, Greg Corrado, et al. Hệ thống dịch máy thần kinh đa ngôn ngữ của Google: Cho phép dịch không-shot. Transactions of the Association for Computational Linguistics, 5:339–351, 2017.

[15] Yunsu Kim, Yingbo Gao, và Hermann Ney. Chuyển giao chéo ngôn ngữ hiệu quả của các mô hình dịch máy thần kinh không có từ vựng chung. arXiv preprint arXiv:1905.05475, 2019.

[16] Diederik P Kingma và Jimmy Ba. Adam: Một phương pháp cho tối ưu hóa ngẫu nhiên. arXiv preprint arXiv:1412.6980, 2014.

[17] Tom Kocmi và Ondřej Bojar. Học chuyển giao tầm thường cho dịch máy thần kinh tài nguyên thấp. arXiv preprint arXiv:1809.00357, 2018.

[18] Julia Kreutzer, David Vilar, và Artem Sokolov. Bandits không tuân theo quy tắc: Cân bằng dịch máy đa mặt với bandits đa cánh tay. arXiv preprint arXiv:2110.06997, 2021.

[19] Taku Kudo và John Richardson. Sentencepiece: Một tokenizer và detokenizer subword đơn giản và độc lập ngôn ngữ cho xử lý văn bản thần kinh. arXiv preprint arXiv:1808.06226, 2018.

[20] Vitaly Kurin, Alessandro De Palma, Ilya Kostrikov, Shimon Whiteson, và M Pawan Kumar. Bảo vệ vô hướng hóa đơn vị cho học đa nhiệm vụ sâu. arXiv preprint arXiv:2201.04122, 2022.

[21] Surafel M Lakew, Aliia Erofeeva, Matteo Negri, Marcello Federico, và Marco Turchi. Học chuyển giao trong dịch máy thần kinh đa ngôn ngữ với từ vựng động. arXiv preprint arXiv:1811.01137, 2018.

[22] Jason Phang, Iacer Calixto, Phu Mon Htut, Yada Pruksachatkun, Haokun Liu, Clara Vania, Katharina Kann, và Samuel Bowman. Huấn luyện nhiệm vụ trung gian tiếng Anh cũng cải thiện chuyển giao chéo ngôn ngữ không-shot. Trong Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing, trang 557–575, 2020.

[23] Jason Phang, Thibault Févry, và Samuel R Bowman. Sentence encoders on stilts: Huấn luyện bổ sung trên các nhiệm vụ dữ liệu nhãn trung gian. arXiv preprint arXiv:1811.01088, 2018.

[24] Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, Peter J Liu, et al. Khám phá giới hạn của học chuyển giao với một transformer văn bản-thành-văn bản thống nhất. J. Mach. Learn. Res., 21(140):1–67, 2020.

[25] Adam Roberts, Hyung Won Chung, Anselm Levskaya, Gaurav Mishra, James Bradbury, Daniel Andor, Sharan Narang, Brian Lester, Colin Gaffney, Afroz Mohiuddin, Curtis Hawthorne, Aitor Lewkowycz, Alex Salcianu, Marc van Zee, Jacob Austin, Sebastian Goodman, Livio Baldini Soares, Haitang Hu, Sasha Tsvyashchenko, Aakanksha Chowdhery, Jasmijn Bastings, Jannis Bulian, Xavier Garcia, Jianmo Ni, Andrew Chen, Kathleen Kenealy, Jonathan H. Clark, Stephan Lee, Dan Garrette, James Lee-Thorp, Colin Raffel, Noam Shazeer, Marvin Ritter, Maarten Bosma, Alexandre Passos, Jeremy Maitin-Shepard, Noah Fiedel, Mark Omernick, Brennan Saeta, Ryan Sepassi, Alexander Spiridonov, Joshua Newlan, và Andrea Gesmundo. Mở rộng các mô hình và dữ liệu với t5x và seqio. arXiv preprint arXiv:2203.17189, 2022.

[26] Chenze Shao và Yang Feng. Vượt qua quên thảm khốc ngoài học liên tục: Huấn luyện cân bằng cho dịch máy thần kinh. Trong Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), trang 2023–2036, 2022.

[27] Noam Shazeer và Mitchell Stern. Adafactor: Tỷ lệ học thích ứng với chi phí bộ nhớ dưới tuyến tính. Trong International Conference on Machine Learning, trang 4596–4604. PMLR, 2018.

[28] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, và Illia Polosukhin. Attention is all you need. Trong I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, và R. Garnett, editors, Advances in Neural Information Processing Systems, volume 30. Curran Associates, Inc., 2017.

[29] Xinyi Wang, Yulia Tsvetkov, và Graham Neubig. Cân bằng huấn luyện cho dịch máy thần kinh đa ngôn ngữ. arXiv preprint arXiv:2004.06748, 2020.

[30] Yiren Wang, ChengXiang Zhai, và Hany Hassan Awadalla. Học đa nhiệm vụ cho dịch máy thần kinh đa ngôn ngữ. arXiv preprint arXiv:2010.02523, 2020.

[31] Derrick Xin, Behrooz Ghorbani, Justin Gilmer, Ankush Garg, và Orhan Firat. Các phương pháp tối ưu hóa đa nhiệm vụ hiện tại trong học sâu có thực sự giúp ích không? Advances in Neural Information Processing Systems, 35:13597–13609, 2022.

[32] Linting Xue, Noah Constant, Adam Roberts, Mihir Kale, Rami Al-Rfou, Aditya Siddhant, Aditya Barua, và Colin Raffel. mT5: Một transformer được tiền huấn luyện văn bản-thành-văn bản đa ngôn ngữ quy mô lớn. Trong Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, trang 483–498, Online, June 2021. Association for Computational Linguistics.

[33] Barret Zoph, Deniz Yuret, Jonathan May, và Kevin Knight. Học chuyển giao cho dịch máy thần kinh tài nguyên thấp. arXiv preprint arXiv:1604.02201, 2016.

## A Thí nghiệm NMT: Thông tin bổ sung

### A.1 Thiết lập huấn luyện chi tiết

Phần này mô tả chi tiết thiết lập thí nghiệm được sử dụng trong Phần 4.1. Chúng tôi sử dụng kiến trúc transformer encoder-decoder pre-LN. Các thí nghiệm được trình bày trong văn bản chính sử dụng ba lớp cho cả encoder và decoder, nhưng chúng tôi cũng trình bày kết quả với 6 lớp cho encoder và decoder. Chúng tôi tuân theo quy ước trong tài liệu NMT và huấn luyện các mô hình của chúng tôi với 0.1 label smoothing và 0.1 dropout cho các lớp feed-forward và attention. Xem Bảng 3 để biết chi tiết kiến trúc hoàn chỉnh.

**Bảng 3: Chi tiết kiến trúc Transformer và các siêu tham số chung.**

| Siêu tham số | Giá trị |
|---|---|
| Chiều feed-forward | 2048 |
| Chiều mô hình | 512 |
| Đầu attention | 8 |
| Chiều attention QKV | 512 |
| Label smoothing | 0.1 |
| Dropout | 0.1 |

Chúng tôi sử dụng tokenization SentencePiece [19] để tạo từ vựng kích thước 64,000 cho mỗi vấn đề NMT (ví dụ: En →{Zh, Fr}).

Tất cả các mô hình được huấn luyện sử dụng optimizer Adam [16] với kích thước batch 1024. Đối với tất cả các thí nghiệm NMT của chúng tôi, chúng tôi sử dụng khởi động tuyến tính đến tỷ lệ học mong muốn, theo sau là lịch suy giảm cosine suy giảm về 0. Điều này đúng cho tất cả các chặng huấn luyện cho các phương pháp sử dụng sơ đồ của chúng tôi; trong giai đoạn tiền huấn luyện, chúng tôi thực hiện khởi động tuyến tính theo sau là suy giảm cosine, và trong giai đoạn tinh chỉnh, sau khi tải mô hình được tiền huấn luyện, chúng tôi thực hiện khởi động tuyến tính theo sau là suy giảm cosine.

Đối với các thí nghiệm cơ sở không thực hiện tiền huấn luyện, và cũng cho phần tiền huấn luyện, chúng tôi khởi động trong 40k bước. Đối với tinh chỉnh, chúng tôi điều chỉnh các bước khởi động từ trong {10k, 20k, 30k, 40k} cho tất cả các thí nghiệm khác ngoài En →{Zh, Fr}, nơi chúng tôi khởi động trong 40k bước. Số bước huấn luyện cơ sở, và số bước tinh chỉnh được hiển thị trong Bảng 4. Lưu ý rằng để so sánh, chúng tôi cũng huấn luyện một mô hình cơ sở-không-tiền-huấn-luyện cho số bước 'cơ sở + tinh chỉnh'.

**Bảng 4: Số bước huấn luyện cho tất cả các thí nghiệm NMT.**

| | 3-lớp | | 6-lớp | |
|---|---|---|---|---|
| | cơ sở | tinh chỉnh | cơ sở | tinh chỉnh |
| En→{Zh, Fr} | 300k | 300k | 300k | 300k |
| En→{Ro, Fr} | 400k | 50k | 300k | 50k |
| En→{Hi, Fr} | 300k | 50k | 275k | 50k |

Đối với tất cả các thí nghiệm, chúng tôi quét tỷ lệ học cơ sở trong lưới {2.5e-4, 5e-4, 2.5e-3, 5e-3, 7.5e-3}. Chúng tôi cũng quét tỷ lệ lấy mẫu cho En →Fr và En →Cs trong lưới {i/10}^9_{i=1}, điều này hoàn toàn xác định tỷ lệ lấy mẫu cho cặp ngôn ngữ khác. Tất cả các điểm được vẽ tương ứng với phép đo cuối cùng được thực hiện cho mỗi thử nghiệm.

Đối với tất cả các thí nghiệm tinh chỉnh, khi tải checkpoint mô hình được tiền huấn luyện, chúng tôi đặt lại trạng thái optimizer. Chúng tôi cũng huấn luyện tất cả các tham số của mô hình, và không đóng băng bất cứ thứ gì.

### A.2 Các đường cong đánh đổi hiệu suất bổ sung

Trong phần này, chúng tôi trình bày các đường cong đánh đổi hiệu suất cho En →{Hi, Fr}, cũng như cho các mô hình 6-lớp trên En →{Zh, Fr}, En →{Ro, Fr}, và En →{Hi, Fr}. Các điểm có viền đen trong phần tổng quát hóa của Hình 11 và 13 dưới đây tương ứng với đường cơ sở khởi động lại.

### A.3 Các đường cong đánh đổi hiệu suất với tỷ lệ lấy mẫu như các marker

Trong phần này, chúng tôi trình bày các đường cong đánh đổi hiệu suất giống như đã hiển thị trước đó, nhưng với các marker đại diện cho tỷ lệ lấy mẫu cho cặp ngôn ngữ tài nguyên thấp hơn. Chúng tôi có thể thấy rằng trong tất cả trừ một trường hợp (mô hình 6-lớp En →{Hi,Fr}; Hình 19), mô hình hoạt động tốt nhất trong cặp ngôn ngữ tài nguyên thấp, lấy mẫu cặp ngôn ngữ tài nguyên thấp với tỷ lệ cao hơn so với các đường cơ sở không sử dụng tiền huấn luyện. Các điểm có viền đen trong phần tổng quát hóa của Hình 16, 17, 18, và 19 dưới đây tương ứng với đường cơ sở khởi động lại.

### A.4 Biểu đồ hiệu quả

Trong phần này, chúng tôi vẽ biểu đồ số ví dụ được nhìn thấy từ một cặp ngôn ngữ so với hàm mất mát cross-entropy xác thực trên cặp ngôn ngữ đó. Số ví dụ XX →YY được nhìn thấy tại bước huấn luyện t được tính bằng cách nhân t, kích thước batch, và tỷ lệ lấy mẫu cho XX →YY. Mỗi đường cong trong một hình cho trước tương ứng với thử nghiệm đạt được hiệu suất xác thực cuối cùng tốt nhất trên cặp ngôn ngữ tài nguyên thấp (hơn) trong phương pháp được đưa ra bởi chú thích (tức là đường cong xanh trong Hình 20 tương ứng với thử nghiệm đạt được hàm mất mát cross-entropy xác thực En →Zh cuối cùng tốt nhất trong số tất cả các thử nghiệm không sử dụng tiền huấn luyện, và được huấn luyện trong 300k bước.) Đối với các đường cong tương ứng với sơ đồ tiền huấn luyện và tinh chỉnh được đề xuất của chúng tôi, chúng tôi chỉ hiển thị phần tinh chỉnh của huấn luyện. Lưu ý rằng suy giảm tuyến tính ban đầu theo sau là suy giảm mượt mà là một tạo phẩm của việc đánh giá trên thang tuyến tính khi các biểu đồ ở thang log.

### A.5 Biểu đồ điểm BLEU

Ở đây, chúng tôi trình bày các đường cong đánh đổi hiệu suất cho khi chỉ số là điểm BLEU thay vì hàm mất mát cross-entropy. Tất cả các bản dịch được tạo ra thông qua Beam-Search với kích thước beam là 4.

## B Chi tiết huấn luyện bổ sung trong huấn luyện đa ngôn ngữ

Chúng tôi sử dụng một phiên bản được xử lý bổ sung của tập dữ liệu mC4 [32] như được đề xuất trong [6] (các tài liệu với độ tin cậy ID ngôn ngữ dưới 0.95 đã được lọc).

Các kiến trúc mô hình được sử dụng giống như các mô hình mT5 [32], ngoại trừ rằng các embedding vị trí tương đối không được chia sẻ giữa các lớp. Chúng tôi cũng sử dụng số token đích thực như chuẩn hóa mất mát hiệu quả thay vì sử dụng hệ số chuẩn hóa mất mát.

Chúng tôi sử dụng tokenization SentencePiece [19] để tạo từ vựng kích thước 64,000. Kho ngữ liệu được sử dụng để tạo từ vựng được lấy mẫu từ dữ liệu huấn luyện sử dụng lấy mẫu nhiệt độ với τ = 3.33.

Chúng tôi sử dụng thư viện T5X [25] để huấn luyện các mô hình. Đối với tất cả các thí nghiệm, chúng tôi sử dụng optimizer Adafactor [27], nơi chúng tôi sử dụng momentum, và chúng tôi không phân tích moment thứ hai của các trạng thái Adafactor.

Lần chạy cơ sở không có tinh chỉnh, và giai đoạn tiền huấn luyện của phương pháp được đề xuất của chúng tôi, được chạy với tỷ lệ học không đổi 0.01 trong 10,000 bước đầu tiên và suy giảm căn bậc hai nghịch đảo sau đó. Đối với giai đoạn tinh chỉnh của phương pháp chúng tôi, chúng tôi đặt lại trạng thái optimizer, và thực hiện khởi động tuyến tính 10,000 bước với suy giảm căn bậc hai nghịch đảo sau đó.

## C Thảo luận về lịch tỷ lệ lấy mẫu

Từ các thí nghiệm sơ bộ của chúng tôi về việc sử dụng lịch cho tỷ lệ lấy mẫu trong các khối lượng công việc NMT, chúng tôi thấy rằng lịch tỷ lệ học phải được điều chỉnh phù hợp, điều này ảnh hưởng đến hiệu suất tổng thể của lần chạy. Ví dụ, chúng tôi thấy rằng lịch suy giảm cosine hoạt động tốt hơn so với suy giảm căn bậc hai nghịch đảo cho vô hướng hóa. Tuy nhiên, nếu chúng tôi sử dụng suy giảm tỷ lệ học cosine kết hợp với suy giảm tỷ lệ lấy mẫu tuyến tính (được sử dụng bởi DDS, và định nghĩa tỷ lệ lấy mẫu là cho cặp ngôn ngữ tài nguyên cao), vào thời điểm tỷ lệ lấy mẫu cho nhiệm vụ tài nguyên thấp đủ cao, tỷ lệ học đã suy giảm nhanh chóng (do tính chất suy giảm cosine), dẫn đến ít học tập cho nhiệm vụ tài nguyên thấp. Việc sử dụng suy giảm tỷ lệ học căn bậc hai nghịch đảo giải quyết vấn đề này, nhưng điều này dẫn đến hiệu suất tổng thể tồi tệ hơn do lịch tỷ lệ học không tối ưu. Ngược lại, phương pháp của chúng tôi tự do sử dụng bất kỳ scheduler nào tối đa hóa hiệu suất trong mỗi chặng huấn luyện (tiền huấn luyện và tinh chỉnh). Cuối cùng, khi điều chỉnh siêu tham số, việc sử dụng tỷ lệ lấy mẫu động đòi hỏi phải thực hiện lần chạy huấn luyện đầy đủ nhiều lần. Mặt khác, đối với phương pháp của chúng tôi, chúng tôi có thể tập trung tài nguyên vào việc điều chỉnh giai đoạn tinh chỉnh, (vì giai đoạn tiền huấn luyện chỉ có một nhiệm vụ, và là một vấn đề tối ưu hóa dễ dàng hơn) ngắn hơn so với tổng thời gian huấn luyện.

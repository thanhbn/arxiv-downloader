CodeApex: Một Benchmark Đánh Giá Lập Trình Song Ngữ cho Các Mô Hình Ngôn Ngữ Lớn

LINGYUE FU, HUACAN CHAI, KOUNIANHUA DU, WEIMING ZHANG, SHUANG LUO, JIANGHAO LIN, YUCHEN FANG, RENTING RUI, HAO GUAN, JIANXING LIU, SIYUAN QI, LONGTENG FAN, JIAYI LEI, YIFAN LIU, JINGKUAN WANG, KANGNING ZHANG, WEINAN ZHANG, và YONG YU∗, Phòng thí nghiệm Quản lý Dữ liệu & Tri thức Apex, Đại học Giao thông Thượng Hải, Trung Quốc

https://apex.sjtu.edu.cn/codeapex/

Với sự xuất hiện của các Mô hình Ngôn ngữ Lớn (LLMs), đã có sự cải thiện đáng kể trong khả năng lập trình của các mô hình, thu hút sự chú ý ngày càng tăng từ các nhà nghiên cứu. Việc đánh giá khả năng lập trình của LLMs là rất quan trọng vì nó phản ánh các khả năng đa diện của LLMs, và có nhiều ứng dụng downstream. Trong bài báo này, chúng tôi đề xuất CodeApex, một tập dữ liệu benchmark song ngữ tập trung vào khả năng hiểu lập trình, tạo mã và sửa mã của LLMs. Nhiệm vụ hiểu lập trình kiểm tra LLMs trên các câu hỏi trắc nghiệm bao gồm hiểu khái niệm, lý luận thông thường và lý luận đa bước. Nhiệm vụ tạo mã đánh giá LLMs thông qua việc hoàn thành các hàm C++ dựa trên mô tả và prototype được cung cấp. Nhiệm vụ sửa mã yêu cầu LLMs sửa các đoạn mã lỗi thực tế với các thông báo lỗi khác nhau. Chúng tôi đánh giá 12 LLMs được sử dụng rộng rãi, bao gồm cả các mô hình đa mục đích và chuyên biệt. GPT-4 thể hiện khả năng lập trình tốt nhất, đạt độ chính xác xấp xỉ 69%, 54% và 66% trên ba nhiệm vụ tương ứng. So với hiệu suất của con người, vẫn còn nhiều không gian để cải thiện trong lập trình LLM. Chúng tôi hy vọng rằng CodeApex có thể đóng vai trò như một tài liệu tham khảo để đánh giá khả năng mã hóa của LLMs, thúc đẩy hơn nữa sự phát triển và tăng trưởng của chúng.

Các Khái niệm CCS: •Phương pháp luận tính toán → Xử lý ngôn ngữ tự nhiên.

Từ khóa và Cụm từ Bổ sung: Mô hình Ngôn ngữ Lớn, Benchmark

Định dạng Tham khảo ACM:
Lingyue Fu, Huacan Chai, Kounianhua Du, Weiming Zhang, Shuang Luo, Jianghao Lin, Yuchen Fang, Renting Rui, Hao Guan, Jianxing Liu, Siyuan Qi, Longteng Fan, Jiayi Lei, Yifan Liu, Jingkuan Wang, Kangning Zhang, Weinan Zhang, và Yong Yu. 2018. CodeApex: Một Benchmark Đánh Giá Lập Trình Song Ngữ cho Các Mô hình Ngôn ngữ Lớn. J. ACM 37, 4, Bài báo 111 (Tháng 8 2018), 32 trang. https://doi.org/XXXXXXX.XXXXXXX

1 GIỚI THIỆU

Do việc áp dụng rộng rãi kiến trúc Transformer [51] và những tiến bộ trong sức mạnh tính toán, các Mô hình Ngôn ngữ Lớn (LLMs) đã được sử dụng rộng rãi trong các nhiệm vụ khác nhau, bao gồm hệ thống đề xuất [36,37], hệ thống đối thoại [1,63], tóm tắt [39,62], phân tích cảm xúc [6,21], v.v. Xu hướng này nhấn mạnh nhu cầu về các khung đánh giá mạnh mẽ để đo lường hiệu quả của LLMs trong các ứng dụng đa dạng này như giáo dục [10,17,23], khoa học xã hội [18,20] và y tế [22,31]. Việc thiết lập các benchmark này có thể cung cấp các đánh giá định lượng kỹ lưỡng cho các khả năng của LLMs từ nhiều góc độ khác nhau, từ đó hướng dẫn tối ưu hóa mô hình, xác thực hiệu suất mô hình và phân tích sự khác biệt của mô hình. Trong số các benchmark đa dạng này, chúng tôi cho rằng khả năng mã hóa và lập trình là một trong những khía cạnh quan trọng nhất để đánh giá LLMs vì hai lý do sau.

Thứ nhất, hiệu suất của LLMs trên các nhiệm vụ mã hóa và lập trình phần lớn phản ánh các khả năng cơ bản của chúng về lý luận logic, tuân theo hướng dẫn và hiểu dữ liệu có cấu trúc. Mã hóa và lập trình đóng vai trò như cầu nối giữa con người và máy tính, và chuyển đổi nhu cầu cấp cao của con người thành các bước có thể thực thi, tính nhất quán logic, có cú pháp tiêu chuẩn và tính mô-đun chức năng [57]. Nhiều công trình [41,43,57] đã xác định tầm quan trọng của dữ liệu mã cho việc điều chỉnh mô hình để giúp mở khóa khả năng lý luận của LLMs và hướng LLMs tạo ra các bước trung gian có cấu trúc và chính xác. Do đó, nhiều benchmark và bảng xếp hạng [27] tập trung vào đánh giá khả năng lý luận tổng quát của LLMs sẽ bao gồm các nhiệm vụ liên quan đến mã ngoài các nhiệm vụ truyền thống như số học [3,14] và lý luận tượng trưng [55], điều này đưa ra một đánh giá kỹ lưỡng về các khả năng cơ bản của các mô hình ngôn ngữ lớn.

Thứ hai, ngoài mối quan hệ tiềm năng với các khả năng lý luận cơ bản của LLMs, các nhiệm vụ liên quan đến mã cũng đóng vai trò quan trọng trong một loạt các ứng dụng downstream, như giáo dục [16] và kỹ thuật phần mềm [7]. Nhiều mô hình nền tảng mã [7,35,53,65] đã được đề xuất cho các nhiệm vụ lập trình khác nhau. Copilot [7] đạt được việc tự động hoàn thành mã và tự động sửa lỗi trong quá trình lập trình, do đó thúc đẩy đáng kể trải nghiệm mã hóa của lập trình viên con người. CodeGeeX [65], như một trợ lý lập trình tương tác, có thể giải quyết nhiều vấn đề lập trình khác nhau, bao gồm diễn giải mã, dịch mã, sửa mã, tạo tài liệu, v.v. Đội ngũ Google DeepMind đề xuất AlphaCode [35], nhằm giải quyết các vấn đề lập trình đòi hỏi khả năng lý luận sâu để tìm ra các giải pháp mới. CodeT5 [53] sử dụng một khung thống nhất để hỗ trợ liền mạch cả nhiệm vụ hiểu và tạo mã, với khả năng học đa nhiệm vụ. Sự xuất hiện như vậy của các mô hình nền tảng mã với các mục tiêu lập trình khác nhau (ví dụ: hoàn thành mã, gỡ lỗi mã) tạo ra nhu cầu về đánh giá tương ứng để đảm bảo hiệu suất của chúng trong các tình huống sản xuất thực tế.

Các yếu tố được thảo luận ở trên tạo ra nhu cầu cấp thiết về một benchmark toàn diện để đánh giá kỹ lưỡng khả năng mã hóa và lập trình của các mô hình ngôn ngữ lớn. Trong Bảng 1, chúng tôi minh họa các tính chất quan trọng của các benchmark đánh giá lập trình thường được sử dụng [4,9,50,59,65], và thảo luận về các hạn chế tiềm năng của chúng như sau: (1) Các benchmark hiện tại chỉ tập trung vào một nhiệm vụ lập trình duy nhất cho LLMs trong các test case đơn ngữ (tức là tiếng Anh), điều này khiến việc đánh giá không toàn diện. (2) Các benchmark hiện tại, ngoại trừ DebugBench [50], thường thiếu phân loại chi tiết trên dữ liệu kiểm tra và đánh giá chuyên gia con người, điều này rất quan trọng để rút ra những hiểu biết sâu sắc hơn và phân tích cho các khía cạnh khác nhau của lập trình, cũng như so sánh kỹ lưỡng giữa LLMs và khả năng cấp độ con người.

Để đạt được mục tiêu này, chúng tôi đề xuất benchmark CodeApex, cung cấp đánh giá mã hóa và lập trình toàn diện của các mô hình ngôn ngữ lớn. Như được hiển thị trong Bảng 1, CodeApex là một benchmark lập trình song ngữ (tiếng Anh và tiếng Trung) tiên phong trên ba nhiệm vụ liên quan đến mã khác nhau (tức là hiểu lập trình, tạo mã và sửa mã) với phân loại chi tiết, quy mô dữ liệu kiểm tra lớn, cũng như đánh giá chuyên gia con người. Chúng tôi đã đánh giá toàn diện 12 LLMs khác nhau sử dụng CodeApex, bao gồm cả các mô hình dựa trên API và mã nguồn mở. Công việc của chúng tôi phân tích khả năng mã tổng thể của LLMs bằng cách so sánh hiệu suất của chúng trên các nhiệm vụ khác nhau. Các thí nghiệm phân loại chi tiết cung cấp phân tích LLMs trên các chiến lược và loại dữ liệu khác nhau. Kết quả thí nghiệm chứng minh hiệu suất khác nhau của các mô hình khác nhau trong các nhiệm vụ liên quan đến mã, với các mô hình GPT thể hiện khả năng cạnh tranh đặc biệt và lợi thế riêng biệt. Ngoài ra, thí nghiệm so sánh hiệu suất của LLMs trong các tình huống song ngữ và chiến lược prompt khác nhau. Chúng tôi cũng tổ chức kiểm tra con người về các nhiệm vụ hiểu mã và tạo mã, so sánh hiệu suất giữa con người và LLMs. Nhìn chung, trong bảng xếp hạng của CodeApex, vẫn còn nhiều không gian để cải thiện độ chính xác LLM, cho thấy tiềm năng chưa được khai thác của LLMs trong các nhiệm vụ liên quan đến mã.

Phần còn lại của bài báo được tổ chức như sau. Trong Mục 2, chúng tôi xem xét công việc trước đây về đánh giá các khả năng liên quan đến mã của LLMs. Chúng tôi trình bày giao thức đánh giá cho ba nhiệm vụ lập trình trong Mục 3. Chúng tôi trình bày và thảo luận kết quả đánh giá trên ba nhiệm vụ và nhiều phân loại trong Mục 4. Cuối cùng, chúng tôi kết luận bài báo này và thảo luận công việc tương lai trong Mục 5.

2 CÔNG VIỆC LIÊN QUAN

2.1 Các Mô hình Nền tảng Mã

Việc triển khai hiểu lập trình phụ thuộc nhiều vào việc căn chỉnh không gian mã và không gian ngôn ngữ tự nhiên thông qua mã hóa. Graph2Code [58] sử dụng mạng nơ-ron đồ thị để chuyển đổi mã nguồn thành cấu trúc đồ thị, nắm bắt thông tin cấu trúc trong mã và do đó tăng cường độ chính xác của hiểu lập trình. Code2Vec [2] biểu diễn Cây Cú pháp Trừu tượng (AST) như các chuỗi token dọc theo các đường dẫn, cho phép chuyển đổi mã thành các biểu diễn vector có độ dài cố định và tạo điều kiện cho việc học ngữ nghĩa mã. Việc giới thiệu kiến trúc Transformer [52] đã cung cấp các phương pháp mới cho các nhiệm vụ hiểu mã. Một mô hình nổi bật trong lĩnh vực này là CodeT5 [53], một phần mở rộng của Text-to-Text Transfer Transformer (T5) [45] được thiết kế đặc biệt cho các nhiệm vụ xử lý ngôn ngữ tự nhiên trên mã nguồn. CodeBERT [25] ánh xạ cả ngôn ngữ tự nhiên và mã vào một không gian vector được chia sẻ và tận dụng cơ chế attention để nắm bắt mối quan hệ ngữ nghĩa giữa chúng. Hơn nữa, có các mô hình [42,56] tập trung vào các nhiệm vụ lập trình cụ thể như tạo bình luận mã và tạo tài liệu API trong bối cảnh mã nguồn.

Nhiệm vụ tạo mã đã thu hút sự chú ý đáng kể sau sự xuất hiện của LLMs. Các mô hình ngôn ngữ này được tiền huấn luyện trên các tập dữ liệu văn bản khổng lồ, cho phép chúng học các biểu diễn ngôn ngữ phong phú. Các LLMs đa mục đích, như GPT và Llama [46], có khả năng nhất định để tạo mã. Một số LLMs được thiết kế đặc biệt với các sơ đồ huấn luyện cho các nhiệm vụ lập trình, nhằm cải thiện hiệu suất mã hóa của chúng. Một phương pháp phổ biến để tạo mã là tinh chỉnh các mô hình ngôn ngữ quy mô lớn hiện có. Trong phương pháp này, một mô hình ngôn ngữ được tiền huấn luyện được sử dụng làm mô hình ban đầu và được huấn luyện thêm trên các tập dữ liệu tạo mã cụ thể. Codex [9], PaLMCoder [11], CodeGeeX2 [65] được huấn luyện thêm trên GPT-3, PaLM [11], ChatGLM2 [19,61] với các tập dữ liệu mã công cộng rộng lớn, thể hiện khả năng hiểu và tạo tốt hơn trên các ngôn ngữ lập trình. Với sự phát triển của các kỹ thuật điều chỉnh hướng dẫn, một loạt các mô hình, như WizardCoder [40], Code Llama-Instruct [47], PanguCoder [12] thể hiện khả năng mạnh mẽ trong tạo mã đa ngôn ngữ và các nhiệm vụ gỡ lỗi. Một phương pháp phổ biến khác là kỹ thuật prompt, bao gồm việc thiết kế các prompt hoặc câu hướng dẫn phù hợp để chỉ đạo mô hình hoàn thành các nhiệm vụ tạo mã cụ thể. Bằng cách cung cấp các đầu vào sâu sắc, các mô hình có thể tạo ra các đầu ra mã chính xác và mong đợi hơn. CodeGen [44] chuyển đổi các câu hỏi ngôn ngữ tự nhiên thành các nhiệm vụ tạo mã và cải thiện hiệu quả tạo thông qua các kỹ thuật kỹ thuật prompt phù hợp. DocPrompting [66] tận dụng truy xuất từ khóa để tích hợp thông tin từ các kho mã vào các cụm từ prompt, hướng dẫn LLMs để tăng cường hiệu suất của LLMs trong các nhiệm vụ tạo mã.

2.2 Đánh giá Lập trình

Đánh giá khả năng của các mô hình ngôn ngữ lớn (LLMs) có thể được đạt được hiệu quả thông qua các định dạng đa lựa chọn, nơi các mô hình được giao nhiệm vụ chọn câu trả lời đúng từ các tùy chọn được cho. Multi-choice RACE chuyển đổi tập dữ liệu hiểu đọc gốc RACE [32] thành một tập hợp các câu hỏi với các lựa chọn trả lời, tạo điều kiện cho việc đánh giá điểm số của mô hình. AI2 Reasoning Challenge (ARC) [13] đóng vai trò như một benchmark để đo lường mức độ tốt của các mô hình ngôn ngữ có thể lý luận và đưa ra kết luận trong lĩnh vực khoa học. C-Eval [27] cung cấp các câu hỏi trắc nghiệm từ nhiều môn học, cho phép chúng ta đánh giá năng lực của LLMs trong các lĩnh vực học thuật khác nhau. CodeApex sử dụng các định dạng câu hỏi trắc nghiệm để đánh giá khả năng hiểu lập trình của LLM.

Một chiều quan trọng khác trong việc đánh giá khả năng của LLMs liên quan đến hiệu suất của chúng trên các nhiệm vụ liên quan đến mã. Sự phát triển của các tập dữ liệu benchmark chuyên biệt cung cấp những hiểu biết sắc nuận về khả năng hiểu và tạo lập trình của LLMs. Trong những ngày đầu, FlashFill++ [8] cung cấp một tập dữ liệu benchmark cho việc suy ra các chương trình chuyển đổi chuỗi từ các ví dụ đầu vào-đầu ra. CodeSearchNet [28] phục vụ các nhiệm vụ tìm kiếm mã bằng cách cung cấp một bộ sưu tập lớn các đoạn mã cho việc truy xuất mã và tạo tài liệu. Với sự phát triển của học sâu, các nhiệm vụ NLP đã trở nên đa dạng hơn. Các tập dữ liệu benchmark đã bắt đầu kết hợp các nhiệm vụ liên quan đến mã với ngôn ngữ tự nhiên. CodeXGLUE [26] là một benchmark bao gồm hiểu ngôn ngữ tự nhiên của mã, bao gồm nhiều nhiệm vụ khác nhau như tóm tắt mã, dịch mã, hoàn thành mã, và nhiều hơn nữa. APPS [24] là một benchmark được thiết kế để đánh giá các hệ thống tổng hợp chương trình, tập trung vào các chương trình xác suất và khả năng tổng quát hóa của chúng cho các nhiệm vụ mới. Với sự xuất hiện của LLMs, [9] đã đề xuất benchmark HumanEval, được thiết kế đặc biệt để đánh giá chất lượng của mã được tạo. Benchmark HumanEval-X [65] giới thiệu hỗ trợ cho nhiều ngôn ngữ lập trình, bao gồm C++, Python, Go và Java, nhằm tạo điều kiện cho nghiên cứu về tạo và hiểu mã xuyên ngôn ngữ. Benchmark CoderEval [60] đặc biệt tập trung vào việc đánh giá khả năng của các mô hình ngôn ngữ lớn để giải quyết các thách thức mã hóa phức tạp, cấp công nghiệp thông qua một loạt các nhiệm vụ lập trình thực tế. DebugBench [50] cấy ghép lỗi vào mã tiêu chuẩn bằng GPT4 và đánh giá năm LLMs trong tình huống zero-shot. CodeApex tập trung vào việc đánh giá khả năng lý luận của LLMs bằng cách trình bày cho chúng các thách thức thuật toán và các test case liên quan.

3 GIAO THỨC ĐÁNH GIÁ

Trong phần này, chúng tôi giới thiệu khung đánh giá của CodeApex cho ba nhiệm vụ mã: (1) hiểu lập trình, (2) tạo mã, và (3) sửa mã. Các tình huống thí nghiệm tổng thể của CodeApex được liệt kê trong Hình 1.

• Nhiệm vụ đầu tiên là hiểu lập trình, có tập kiểm tra bao gồm 250 câu hỏi trắc nghiệm, được phân loại thành các câu hỏi hiểu khái niệm, lý luận thông thường và lý luận đa bước. Các câu hỏi được chọn từ các kỳ thi cuối kỳ của các lớp khác nhau (Lập trình, Cấu trúc Dữ liệu, Thuật toán) tại trường đại học, điều này làm giảm nguy cơ dữ liệu kiểm tra đã có trong corpus huấn luyện của LLMs. LLMs được yêu cầu chọn tùy chọn đúng dưới các tình huống học trong ngữ cảnh 0-shot, 2-shot và 5-shot. Do ứng dụng hiệu quả của Chain-of-Thought (CoT), chúng tôi cũng so sánh hiệu suất của LLMs dưới các cài đặt chỉ trả lời và CoT.

• Nhiệm vụ thứ hai là tạo mã, có tập kiểm tra bao gồm 476 câu hỏi mã hóa dựa trên C++, bao gồm các câu hỏi rõ ràng và câu hỏi tường thuật. Mô tả của câu hỏi và prototype của hàm để thực hiện câu hỏi được đưa ra, và LLMs được yêu cầu hoàn thành phần chính của hàm. Chúng tôi cũng cung cấp cả tình huống chỉ hàm và hàm với ngữ cảnh, cho biết liệu mã gọi của hàm mục tiêu có được đưa ra ngoài mô tả của hàm mục tiêu (tức là thông tin ngữ cảnh của mã).

• Nhiệm vụ thứ ba là sửa mã, có tập kiểm tra bao gồm 1330 đoạn mã lỗi với ba loại thông báo lỗi (Wrong Answer, Time Limit Exceeded và Runtime Error). Chúng tôi giới thiệu ba loại prompt để mô phỏng các tình huống chỉ mã, mã với thông báo lỗi và mã với mã tiêu chuẩn.

Đối với mỗi nhiệm vụ, trước tiên chúng tôi cung cấp tổng quan và sau đó thảo luận về xử lý dữ liệu, chiến lược prompting và thước đo đánh giá. Để tạo điều kiện cho việc so sánh chi tiết về sự khác biệt trong khả năng của LLMs trên các ngôn ngữ tự nhiên khác nhau, chúng tôi cung cấp các phiên bản tiếng Trung và tiếng Anh được căn chỉnh cho tất cả dữ liệu kiểm tra trong ba nhiệm vụ.

3.1 Nhiệm vụ Hiểu Lập trình

3.1.1 Tổng quan. Trong nhiệm vụ hiểu lập trình, LLMs phải trả lời các câu hỏi trắc nghiệm có liên quan chặt chẽ đến các chủ đề mã & lập trình. Điều này đánh giá các khả năng cơ bản của LLMs trong việc hiểu mã từ nhiều chiều khác nhau như cú pháp, luồng thực thi và cấu trúc mã. Khả năng hiểu lập trình đặt nền tảng cho LLMs để hoàn thành các nhiệm vụ liên quan đến mã khác, và do đó không thể thiếu để tích hợp hoàn toàn LLMs vào các tình huống sản xuất mã thực tế.

3.1.2 Xử lý Dữ liệu. Chúng tôi đánh giá khả năng hiểu lập trình của LLMs thông qua các câu hỏi trắc nghiệm, thường bao gồm các điểm kiến thức chính của lập trình, cấu trúc dữ liệu và thuật toán. Dữ liệu câu hỏi trắc nghiệm được lấy từ các kỳ thi cuối kỳ của các khóa học đại học thực tế dưới sự bảo mật nghiêm ngặt, làm giảm đáng kể khả năng dữ liệu kiểm tra trùng lặp với dữ liệu huấn luyện của LLMs được thu thập trực tuyến (tức là rò rỉ dữ liệu kiểm tra). Các câu hỏi có nhiều câu trả lời đúng được chỉnh sửa thủ công thành các câu hỏi một lựa chọn để tạo điều kiện cho tính nhất quán trong kiểm tra. Tương tự như C-Eval [27], chúng tôi định dạng các tùy chọn của các câu hỏi trắc nghiệm để căn chỉnh. Các prompt câu hỏi được cung cấp ở định dạng Markdown, tức là các khối mã được đánh dấu bằng dấu ngoặc kép ba. Tất cả các câu hỏi được xác thực chéo thủ công để đảm bảo tính rõ ràng của mô tả câu hỏi và tính đúng đắn của câu trả lời.

Để tạo điều kiện cho việc khám phá sâu hơn về các khả năng chi tiết của LLMs, chúng tôi phân loại thủ công các câu hỏi thành ba loại: (1) hiểu khái niệm, (2) lý luận thông thường, và (3) lý luận đa bước. Các câu hỏi ví dụ của ba loại được thể hiện trong Hình 2. Các câu hỏi hiểu khái niệm đánh giá hiểu biết cơ bản của LLMs về các khái niệm lập trình, thường liên quan đến việc chọn khái niệm đúng hoặc mô tả ngôn ngữ tự nhiên mà không yêu cầu viết mã cụ thể hoặc hiểu. Các câu hỏi Lý luận Thông thường chủ yếu đánh giá khả năng đọc và hiểu mã của LLMs. Hai loại câu hỏi này tập trung vào một điểm kiến thức duy nhất, với các bước giải quyết vấn đề tương đối đơn giản có thể được suy ra thông qua lý luận một bước. Các câu hỏi lý luận đa bước đánh giá khả năng lý luận về mã của LLMs. Những câu hỏi này thường liên quan đến chuỗi suy nghĩ và yêu cầu nhiều bước suy luận để có được câu trả lời đúng. Ba loại câu hỏi này tương ứng với việc nắm bắt cơ bản các khái niệm lập trình, hiểu biết cơ bản về mã và hiểu biết nâng cao về mã của LLMs. Kết quả được phân loại có thể cung cấp cho chúng ta những hiểu biết sâu sắc hơn về các mức độ chi tiết của khả năng hiểu lập trình của LLMs.

3.1.3 Chiến lược Prompting. Chúng tôi đánh giá khả năng hiểu mã của LLMs dưới hai chiến lược prompting khác nhau, tức là chỉ trả lời và chain-of-thought. Trong cài đặt chỉ trả lời, LLMs được yêu cầu tạo ra chỉ một tùy chọn duy nhất (tức là lựa chọn được chọn), và tính đúng đắn của tùy chọn được tạo ra đóng góp vào điểm chính xác cuối cùng. Trong cài đặt chain-of-thought, LLMs sẽ trước tiên tạo ra một đoạn văn bản phân tích theo sau là câu trả lời cuối cùng, và độ chính xác của câu trả lời cuối cùng đóng vai trò như thước đo hiệu suất mô hình. Chúng tôi minh họa các ví dụ prompt dưới cả hai cài đặt trong Hình 3.

3.1.4 Thước đo Đánh giá. Chúng tôi áp dụng độ chính xác (ACC) làm thước đo đánh giá cho nhiệm vụ hiểu lập trình. Sau khi LLMs cung cấp phản hồi dưới cài đặt chỉ trả lời hoặc chain-of-thought, chúng tôi trích xuất lựa chọn cuối cùng bằng biểu thức chính quy. Nếu lựa chọn không thể được trích xuất thông qua biểu thức chính quy, nó được coi là câu trả lời không chính xác. Độ chính xác cuối cùng của LLM được tính như sau:

ACC = #Câu trả lời Đúng / #Câu hỏi.

3.2 Nhiệm vụ Tạo Mã

3.2.1 Tổng quan. Trong nhiệm vụ tạo mã, LLMs phải trích xuất các yêu cầu thuật toán liên quan từ mô tả ngôn ngữ tự nhiên, và sau đó, kết hợp với khung hàm mã được cho, tạo ra các mã có thể thực thi và chính xác để vượt qua các test case. Một nhiệm vụ như vậy đòi hỏi các mô hình ngôn ngữ lớn phải có khả năng hiểu cả ngôn ngữ tự nhiên và cấu trúc mã, cũng như khả năng phân tích, thiết kế và cuối cùng tạo ra các đoạn mã chức năng.

3.2.2 Xử lý Dữ liệu. Dữ liệu kiểm tra được lấy từ các bài tập cơ bản trên nền tảng Online Judge nội bộ, cung cấp mô tả câu hỏi, đầu vào/đầu ra mẫu, template mã và test case của các mức độ khó khác nhau. Mô tả câu hỏi thường được cung cấp bằng ngôn ngữ tự nhiên, một số trong đó cũng chứa mô tả dựa trên tình huống. Đầu vào/đầu ra mẫu minh họa định dạng của đầu vào và đầu ra test case, được biểu diễn ở định dạng Markdown. Template mã đại diện cho mã hoàn chỉnh chức năng vượt qua tất cả các bài kiểm tra và được sử dụng để tạo ví dụ kiểm tra cho CodeApex. Các mức độ khó của test case được minh họa trong Hình 4. Lấy tìm kiếm nhị phân làm ví dụ, năm test case đầu tiên có kích thước đầu vào nhỏ n và có thể được giải quyết bằng tìm kiếm dựa trên vòng lặp thông thường. Tuy nhiên, năm test case cuối cùng có kích thước đầu vào lớn hơn, và nếu sử dụng tìm kiếm dựa trên vòng lặp thông thường, sẽ vượt quá giới hạn thời gian. Tính riêng tư của nguồn dữ liệu và sự đa dạng của mô tả câu hỏi làm giảm khả năng dữ liệu kiểm tra xuất hiện trong corpus huấn luyện của LLMs. Điều này thúc đẩy tính công bằng của đánh giá và đóng góp vào nhận thức hợp lý về khả năng lập trình của các LLMs khác nhau.

Hầu hết LLMs không thể tạo mã đáp ứng các điều kiện đầu vào-đầu ra đã cho chỉ dựa trên mô tả câu hỏi. Khi chúng tôi trực tiếp nhập mô tả câu hỏi gốc vào LLMs, rất có khả năng mã được tạo sẽ chứa đầu ra bổ sung liên quan đến prompt. Mặc dù logic của chính mã có thể đúng, những đầu ra bổ sung này không được bao gồm trong các test case gốc, khiến mã được tạo không vượt qua các bài kiểm tra. Hình 5 minh họa một ví dụ về tình huống này, xảy ra trong quá trình tạo mã với GPT-3.5-turbo. Trong những trường hợp như vậy, để đánh giá chính xác hơn khả năng tạo mã của chính LLMs, chúng tôi sử dụng GPT-4 để hỗ trợ tạo ví dụ kiểm tra dạng chức năng. Với phương pháp học trong ngữ cảnh, chúng tôi hướng dẫn LLMs viết lại mã template và chia nó thành hàm chính và một số hàm phụ trợ. Hàm chính bao gồm (i) tham chiếu thư viện, (ii) chính hàm main (với mã đầu vào và đầu ra), và (iii) lời gọi đến các hàm phụ trợ. Các hàm phụ trợ chứa logic thuật toán chính với các tham số đầu vào và trả về đầu ra cho hàm chính.

Để khám phá thêm các loại khả năng tạo mã khác nhau của LLMs, chúng tôi chia các câu hỏi thành hai loại: câu hỏi rõ ràng và câu hỏi tường thuật. Câu hỏi rõ ràng chỉ định trực tiếp chức năng mà chương trình cần thực hiện, như "Thực hiện quicksort" hoặc "Tính số ký tự trong đầu vào." Câu hỏi tường thuật bao gồm mô tả ngôn ngữ tự nhiên phức tạp hơn, với các yêu cầu mã ẩn trong một tình huống. Ví dụ, cho một lớp học sinh, bạn cần hỏi về điểm của học sinh thứ k. Câu hỏi này yêu cầu lưu trữ điểm của học sinh trong một mảng, sắp xếp chúng, và sau đó xuất ra phần tử lớn thứ k. Các benchmark trước đây [9] tập trung vào các câu hỏi rõ ràng, và không chú ý đến tầm quan trọng của việc đánh giá các câu hỏi tường thuật.

3.2.3 Chiến lược Prompting. Chúng tôi mô tả phương pháp của chúng tôi để tạo các hàm mục tiêu tuân thủ template hàm bằng cách thiết kế các prompt. Những prompt này bao gồm ba thành phần: mô tả câu hỏi, mô tả hàm và đặc tả phạm vi dữ liệu. Trong tình huống 'chỉ hàm', không có thông tin bổ sung nào được bao gồm trong các prompt. Trong trường hợp này, LLMs được yêu cầu tạo ra mã hàm có thể chạy phù hợp với prototype hàm và mô tả câu hỏi. Trong tình huống hàm với ngữ cảnh, chúng tôi kết hợp ngữ cảnh của hàm chính như một đầu vào bổ sung để hướng dẫn LLM tạo ra hàm mục tiêu. Thiết kế cụ thể của các prompt được minh họa trong Hình 6.

3.2.4 Thước đo Đánh giá. Để đánh giá hiệu quả của mã, chúng tôi sử dụng các test case của câu hỏi gốc để đo lường tính đúng đắn của nó. Mỗi câu hỏi cung cấp 5-10 test case bao gồm nhiều tình huống đầu vào có thể và điều kiện biên. Benchmark CodeApex phù hợp với các tình huống thực tế của lập trình con người bằng cách sử dụng số lượng test case đã vượt qua làm điểm số của mô hình. Tất cả điểm test case được trọng số bằng nhau, bất kể độ khó của chúng.

CodeApex giới thiệu một thước đo đánh giá gọi là tỷ lệ chấp nhận làm hàm đánh giá cho mã được tạo bởi mô hình. Khi mô hình ngôn ngữ tạo ra phản hồi, chúng tôi trích xuất hàm mã C++ có thể chạy từ nó và nối nó vào hàm chính trong tập dữ liệu. Mã được nối vẫn có thể thực thi, và các cặp đầu vào-đầu ra mục tiêu được căn chỉnh với các test case trong tập dữ liệu gốc. Bằng cách so sánh đầu ra của test case với đầu ra thực tế, chúng ta có thể nhận được số lượng test case mà mã được tạo vượt qua, tức là #passes(q). Chúng tôi tính AC@k, đại diện cho chất lượng của mã được tạo bởi mô hình

AC@k = 1/|Q| ∑q∈Q [I(#passes(q) ≥ k)],

trong đó Q là tập câu hỏi, và hàm chỉ báo I trình bày

I(condition) = 1, nếu điều kiện đúng,
              0, ngược lại.

Khi k được đặt thành 1, mã có thể vượt qua ít nhất một test case. AC@1 phản ánh tính đúng đắn chức năng của mã được tạo bởi mô hình. Trong trường hợp này, một số test case có thể không vượt qua, có thể do việc lựa chọn thuật toán không phù hợp trong quá trình tạo hoặc vượt quá giới hạn thời gian/không gian của chính câu hỏi. Khi k được đặt thành all, AC@all đại diện cho tỷ lệ câu hỏi đã vượt qua tất cả test case. Đây là một thước đo tương đối nghiêm ngặt để đánh giá hiệu suất. Ngoài ra, chúng tôi giới thiệu thước đo Accept Rate (AC Rate) để đo lường mức độ mã được tạo đáp ứng. AC Rate được tính như sau:

AC Rate = 1/|Q| ∑q∈Q [#passes(q)/#testcases(q)].

Nó phản ánh hiệu suất tổng thể của LLMs trong nhiệm vụ tạo mã, bao gồm cả việc lựa chọn thuật toán và triển khai.

3.3 Nhiệm vụ Sửa Mã

3.3.1 Tổng quan. Trong nhiệm vụ sửa mã, LLMs cần sửa đổi mã được tạo với mô tả câu hỏi, thông báo lỗi và mã tiêu chuẩn. Sửa mã là một giai đoạn thiết yếu trong quy trình lập trình, việc thành thạo có thể cung cấp hỗ trợ thực tế trong kỹ thuật phần mềm. Ngoài ra, việc sử dụng khả năng tự truyền cảm hứng của LLMs để sửa mã đã nổi lên như một cách chính để cải thiện độ chính xác của việc tạo mã [10]. Do đó, chúng tôi bao gồm đánh giá cho việc sửa mã, đây là khả năng cơ bản của lập trình bởi LLMs.

3.3.2 Xử lý Dữ liệu. Dữ liệu kiểm tra xuất phát từ các bài nộp thực tế của học sinh cho các bài tập trên nền tảng Online Judge nội bộ. Mỗi bài nộp chứa ID bài tập, mã nộp, loại lỗi và thời gian nộp. Các loại lỗi bao gồm: Wrong Answer (WA), Time Limit Exceeded (TLE), và Runtime Error (RE). Nếu bài nộp trả lời tất cả testcase một cách chính xác, thì loại lỗi sẽ trống.

Để đảm bảo rằng mã lỗi có thể được sửa trong một số bước nhất định thay vì được viết lại, chúng tôi lấy mẫu các ví dụ từ các bài nộp của cùng một người dùng, nơi cả phiên bản không chính xác và phiên bản chính xác của cùng một vấn đề tồn tại. Phiên bản không chính xác sau đó được lấy mẫu để trở thành mẫu kiểm tra, nơi chúng tôi hạn chế khoảng cách chỉnh sửa [33] giữa phiên bản không chính xác và phiên bản chính xác nhỏ hơn hoặc bằng 50. Từ các cặp mã được tạo, chúng tôi chọn các cặp mã cho mỗi loại lỗi. Do tần suất khác nhau của các loại lỗi khác nhau, mã lỗi kết quả chủ yếu bao gồm lỗi WA, cùng với một phần của các loại lỗi khác. Chúng tôi cũng đảm bảo rằng số lượng cặp mã cho mỗi câu hỏi gần như bằng nhau.

3.3.3 Chiến lược Prompting. Chúng tôi thiết kế ba loại prompt để mô phỏng các tình huống sửa mã khác nhau. Loại prompt đầu tiên, Chỉ mã, chỉ chứa mã lỗi và mô tả câu hỏi mà không có thông tin bổ sung nào. Prompt này được sử dụng để đánh giá khả năng sửa mã của LLMs, mô phỏng con người đọc trực tiếp mã và xác định lỗi. Loại prompt thứ hai, Mã với Thông báo Lỗi, bao gồm mã lỗi, mô tả nhiệm vụ và loại lỗi. Prompt này mô phỏng các kỹ sư gỡ lỗi mã của họ dựa trên phản hồi thực tế từ trình biên dịch, phù hợp với các tình huống phát triển thực tế. Loại prompt thứ ba được gọi là Mã với Mã Tiêu chuẩn. Nó xây dựng trên prompt Mã với Thông báo Lỗi bằng cách thêm mã tiêu chuẩn như đầu vào bổ sung. Trong quá trình phát triển, các kỹ sư có thể tham khảo mã hiện có để sửa chữa. Đánh giá khả năng sửa mã của LLMs trong tình huống này có thể đánh giá khả năng lập trình toàn diện của nó, cung cấp hướng dẫn cho lập trình hỗ trợ LLM. Thiết kế cụ thể của ba loại prompt được thể hiện trong Hình 7.

3.3.4 Thước đo Đánh giá. Tương tự như tạo mã, chúng tôi sử dụng cùng test case và cùng thước đo (AC@1, AC@all, AC Rate) để đo lường tính đúng đắn của mã đã sửa đổi. LLMs nên nhận ra việc sửa mã dựa trên mã lỗi đầu vào. Nếu sự khác biệt giữa mã đầu vào và đầu ra quá lớn (khoảng cách chỉnh sửa lớn hơn 50), mã đầu ra được coi là không hợp lệ. Điểm cho mã không hợp lệ được ghi nhận là 0, bất kể nó có vượt qua test case hay không. Trong tình huống mã với mã tiêu chuẩn, để ngăn LLM xuất trực tiếp mã tiêu chuẩn, chúng tôi xác thực mã được tạo trong tình huống Mã với Mã Tiêu chuẩn. Bất kỳ mã đầu ra nào giống hệt với mã tiêu chuẩn đều được đánh dấu trực tiếp là câu trả lời không chính xác.

4 KẾT QUẢ ĐÁNH GIÁ

4.1 Thiết lập Thí nghiệm

4.1.1 Thống kê Tập dữ liệu. Trong nhiệm vụ hiểu lập trình, CodeApex phát hành tổng cộng 250 câu hỏi trắc nghiệm, được chia thành ba loại: hiểu khái niệm (90 câu hỏi), lý luận thông thường (99 câu hỏi), và lý luận đa bước (61 câu hỏi). Trong nhiệm vụ tạo mã, CodeApex phát hành 476 câu hỏi thuật toán tổng cộng. Những câu hỏi này được chia thành 258 câu hỏi chức năng và 218 câu hỏi mô tả. Trong nhiệm vụ sửa mã, CodeApex phát hành 1330 đoạn mã lỗi, tương ứng với việc giải quyết 116 câu hỏi trong nhiệm vụ tạo mã. Mỗi mã lỗi có thông báo lỗi, với tổng cộng ba loại thông báo lỗi: Wrong Answer (1175 đoạn mã), Time Limit Exceeded (69 đoạn mã) và Runtime Error (86 đoạn mã).

Dữ liệu kiểm tra có sẵn trên GitHub1 để người dùng tải xuống và chạy. Các câu trả lời tiêu chuẩn không được công bố công khai để đảm bảo việc sử dụng CodeApex phù hợp, vì dữ liệu của nó có thể vô tình bao gồm nội dung được thu thập từ web. Người dùng được yêu cầu gửi dự đoán mô hình của họ đến trang web được cung cấp2 để nhận đánh giá độ chính xác tự động, và một bảng xếp hạng công khai được duy trì trên trang web. Người dùng có thể chọn có công bố điểm số mô hình của họ trên bảng xếp hạng hay không.

4.1.2 LLMs để Đánh giá. CodeApex đánh giá tổng cộng 12 LLMs, bao gồm tổng cộng 41 biến thể. Các LLMs được kiểm tra và các biến thể của chúng được liệt kê trong Bảng 2. Các biến thể của các mô hình bao gồm chế độ chatbot và chế độ hoàn thành, cũng như các kích thước tham số khác nhau và các phiên bản trong cùng một mô hình cơ sở. Trong nhiệm vụ hiểu lập trình, chúng tôi tiến hành thí nghiệm trên 10 LLMs, bao gồm cả các mô hình mã nguồn mở và dựa trên API. Trong nhiệm vụ tạo mã, chúng tôi đánh giá 11 LLMs có thể truy cập, bao gồm cả các mô hình đa mục đích và chuyên biệt về mã. Trong nhiệm vụ sửa mã, do việc một số LLMs không thể xuất mã nhận dạng được, các thí nghiệm của chúng tôi thể hiện kết quả của 7 mô hình. Các mô hình mã nguồn mở lớn nhất có 13 tỷ tham số, trong khi mô hình được tham số hóa lớn nhất dựa trên API là GPT4.

Cài đặt Tham số. Khi LLMs tạo phản hồi, chúng tôi chọn hai nhiệt độ khác biệt để phục vụ các tình huống ứng dụng khác nhau. Đối với nhiệm vụ hiểu lập trình, chúng tôi đặt temperature=0.01 để tạo ra kết quả bảo thủ hơn, ngăn mô hình tạo ra các phản hồi không phù hợp với câu trả lời mong muốn. Đối với nhiệm vụ tạo mã và sửa mã, chúng tôi chọn nhiệt độ 0.7 và giá trị top-p 0.8 để khuyến khích mô hình tạo ra phạm vi mã có thể rộng hơn, giới thiệu tính ngẫu nhiên nhiều hơn trong mỗi trường hợp tạo mã.

4.2 Kết quả Hiểu Lập trình

Hiệu suất tổng thể của nhiệm vụ hiểu lập trình trong các tình huống chỉ trả lời và CoT được trình bày trong Bảng 3 và Bảng 4. Các bảng hiển thị kết quả tốt nhất đạt được trong các cài đặt 0-shot, 2-shot và 5-shot. Kết quả chi tiết cho các cài đặt N-shot (N=0,2,5) được cung cấp trong Phụ lục A. GPT4 đạt được độ chính xác trung bình cao nhất trong tất cả các mô hình, tiếp theo là GPT3.5-turbo. Mô hình tốt thứ ba trong tình huống Chỉ trả lời là InternLM-Chat-7B, có độ chính xác 37%, vẫn có khoảng cách lớn so với GPT. Đáng chú ý là độ chính xác của hầu hết LLMs dưới 50%, nhấn mạnh rằng Benchmark CodeApex đầy thách thức trong nhiệm vụ hiểu lập trình.

So sánh Độ chính xác Song ngữ. Phiên bản tiếng Trung ghi điểm cao hơn phiên bản tiếng Anh. Có hai lý do chính: (1) Mô tả câu hỏi nguồn được lấy từ các kỳ thi cuối kỳ tại các trường đại học Trung Quốc, và do đó các câu hỏi thi ban đầu được trình bày bằng tiếng Trung. Ngay cả sau khi dịch chúng sang phiên bản tiếng Anh, chúng vẫn chứa một số thói quen ngôn ngữ đặc trưng của người nói tiếng Trung. Do đó, khi nhập những câu hỏi tiếng Anh có thiên kiến này vào LLM, một số nhiễu có thể được đưa vào kết quả mã hóa của mô hình. (2) Hầu hết các mô hình được đánh giá chủ yếu được huấn luyện trên dữ liệu tiếng Trung, dẫn đến hiểu biết kém về tiếng Anh. Trong Bảng 3 và 4, LLM được huấn luyện chủ yếu trên corpus tiếng Anh, như codeT5 và GPT3.5-turbo, có xu hướng có hiệu suất gần như tương đương trên các phiên bản tiếng Trung và tiếng Anh.

So sánh Độ chính xác trên Các Loại Câu hỏi Khác nhau. Trong ba loại câu hỏi, khoảng một nửa các mô hình hoạt động tốt nhất trong hiểu khái niệm, tiếp theo là lý luận thông thường, với độ chính xác thấp nhất về lý luận đa bước. Kết quả này cho thấy LLMs có khả năng kết hợp kiến thức về các khái niệm lập trình trong quá trình huấn luyện. Hầu hết các mô hình ghi điểm cao hơn trong lý luận thông thường so với lý luận đa bước, cho thấy rằng khả năng của LLMs giảm đáng kể với sự gia tăng số bước lý luận.

Hiệu ứng của Chain-of-Thought Prompting. Hầu hết các mô hình đạt được độ chính xác gần bằng hoặc thấp hơn so với cài đặt chỉ trả lời. Kết quả độ chính xác của cài đặt CoT được mô tả trong Bảng 4. Lý do cho quan sát này có hai mặt: (1) Các mô hình chúng tôi đánh giá không đạt được kích thước mô hình có khả năng nổi bật của CoT. Theo [54], sự xuất hiện của CoT yêu cầu LLM có ít nhất 60B tham số. Khi số tham số không đủ, cài đặt CoT có thể đưa thêm nhiễu, và phản hồi được tạo của LLM sẽ không ổn định. Đó là lý do tại sao GPT3.5-turbo, đã đạt đến điểm xuất hiện, đạt được độ chính xác cao hơn trong cài đặt CoT. (2) Khi trả lời các câu hỏi hiểu khái niệm và lý luận thông thường, chúng ta không yêu cầu lý luận đa bước. Do đó, khả năng CoT của LLMs không cung cấp hỗ trợ cho các loại câu hỏi này. Tuy nhiên, đối với các câu hỏi lý luận đa bước, có sự cải thiện đáng chú ý về độ chính xác trong tình huống CoT cho một số mô hình (như ChatGLM2, educhat và GPT3.5-turbo). Vì CodeT5 không thể tạo ra phản hồi với chain-of-thought, chúng tôi loại trừ nó trong cài đặt CoT.

Hiệu suất Con người. Các lập trình viên mới bắt đầu hoạt động tương tự như GPT-4 trong các bài kiểm tra sách đóng sau khi học, trong khi hiệu suất con người trong các kỳ thi sách mở tốt hơn đáng kể so với tất cả LLMs. Hiệu suất của những người kiểm tra con người được hiển thị trong Bảng 3. Lưu ý rằng các nhiệm vụ hiểu lập trình trong CodeApex được coi là kỳ thi bán mở sách cho LLMs, tức là chúng có cơ sở kiến thức ngoại tuyến hạn chế.

4.3 Kết quả Tạo Mã

Kết quả nhiệm vụ tạo mã của tất cả các mô hình được hiển thị trong Bảng 5 và Bảng 6. Hai chiến lược prompt (chỉ hàm và hàm với ngữ cảnh) được sử dụng cho mỗi phiên bản ngôn ngữ. Các thước đo đánh giá bao gồm AC@1, AC@all và AC Rate. GPT vượt trội hơn các LLMs khác, với tỷ lệ chấp nhận tốt nhất trên 66% (GPT4). WizardCoder và StarCoder xếp thứ hai và thứ ba, nhấn mạnh sự cải thiện đáng kể trong khả năng tạo mã thông qua tinh chỉnh dựa trên mã. Không có sự khác biệt hiệu suất đáng chú ý giữa các phiên bản tiếng Trung và tiếng Anh.

Hiệu ứng của Ngữ cảnh trong Prompt. Như được hiển thị trong Bảng 5 và Bảng 6, cung cấp ngữ cảnh của các lời gọi hàm cho LLM có thể tăng cường hiệu quả độ chính xác của việc tạo mã hàm mục tiêu. Trong khi đó, Bảng 7 hiển thị tỷ lệ mã có thể biên dịch trong mỗi tình huống. Đa số các mô hình có khả năng tạo ra hơn 50% mã có thể biên dịch, điều này chứng minh khả năng của LLM tuân thủ prototype hàm. Sau khi nối hàm được tạo và hàm chính, mã có thể được biên dịch có thể được kiểm tra bởi các testcase. Nói chung, cung cấp thông tin ngữ cảnh về hàm có thể hỗ trợ LLMs trong việc tạo mã có thể biên dịch.

So sánh Loại Câu hỏi. Bảng 8 hiển thị hiệu suất trên các câu hỏi rõ ràng và tường thuật. Dữ liệu được chọn từ các tình huống chỉ hàm và hàm với ngữ cảnh, với dữ liệu hoạt động tốt hơn được chọn. Bảng chứng minh rằng LLMs hoạt động tốt hơn trên các câu hỏi rõ ràng so với các câu hỏi tường thuật. Điều này là do các câu hỏi rõ ràng chỉ yêu cầu khả năng tạo mã nguyên tử của LLMs, trong khi các câu hỏi tường thuật yêu cầu LLM trước tiên hiểu mô tả câu hỏi, chuyển đổi ngôn ngữ tự nhiên thành logic chương trình, và cuối cùng tạo mã. Thực sự là một thách thức đáng kể để trích xuất logic chương trình từ ngôn ngữ tự nhiên, yêu cầu hiểu biết sâu về ngữ nghĩa và ngữ cảnh ngôn ngữ. Trong khi đó, ba thước đo của LLM trên các câu hỏi tường thuật hầu như nhất quán, cho thấy mã được tạo hoặc hoàn toàn đúng hoặc hoàn toàn sai. Điều này có thể do thực tế là các câu hỏi tường thuật trong tập dữ liệu được thiết kế để giải quyết vấn đề thực tế, với yêu cầu tương đối thấp về độ phức tạp thời gian và không gian của mã.

Hiệu suất Con người. Chúng tôi trích xuất hồ sơ học tập thực tế của học sinh từ các nền tảng trực tuyến để đánh giá hiệu suất con người trong các nhiệm vụ tạo mã. Chúng tôi tính tỷ lệ vượt qua cho các bài nộp của con người trong n lần (n=1, 3, 5), và kết quả trung bình được hiển thị trong Bảng 5, Bảng 6 và Bảng 8. Kết quả thí nghiệm cho thấy hiệu suất con người có thể vượt trội hơn tất cả LLMs, và họ có hiệu suất tốt hơn trên các câu hỏi tường thuật. Điều này chủ yếu do sự dễ dàng mà các lập trình viên con người có thể dịch giữa ngôn ngữ tự nhiên và ngôn ngữ mã.

4.4 Kết quả Sửa Mã

Hiệu suất tổng thể của LLMs trong nhiệm vụ sửa mã được hiển thị trong Bảng 9 và 10. Có sự khác biệt đáng kể về khả năng gỡ lỗi giữa các mô hình khác nhau. GPT-4 hoạt động tốt nhất trong tất cả LLMs với độ chính xác tốt nhất là 66%, tiếp theo là GPT3.5-turbo, StarCoder và WizardCoder. Baichuan và ChatGLM3 có thể sửa hơn 25% mã lỗi, được trang bị khả năng sửa mã. Các mô hình khác hoạt động kém trong các nhiệm vụ sửa mã, với tỷ lệ thành công dưới 20%. Khả năng sửa mã của LLMs vẫn còn rất nhiều không gian để cải thiện.

Phân tích Phản hồi. Cung cấp các loại lỗi không giúp đỡ đáng kể LLMs trong nhiệm vụ sửa mã. Điều này có thể là do nền tảng online judge chỉ cung cấp ba loại lỗi mà không có số dòng cụ thể hoặc thông báo lỗi chi tiết khác, điều này không đủ để hỗ trợ LLMs trong việc sửa mã. LLMs không thể hoàn thành các nhiệm vụ sửa mã có thể thể hiện khả năng sửa mã sau khi được cung cấp mã tiêu chuẩn. Điều này là do mã tiêu chuẩn đóng vai trò như điểm tham chiếu hoặc template, hướng dẫn mô hình thực hiện các sửa chữa dựa trên cấu trúc và logic mã được cung cấp.

Phân tích Loại Lỗi. Chúng tôi so sánh hiệu suất trên ba loại lỗi (WA, TLE và RE) trong Bảng 11 và Bảng 12. Kết quả cho thấy việc sửa ba loại lỗi này có khả năng xuất hiện khác nhau của LLMs. Sửa mã trả lời sai là nhiệm vụ khó khăn nhất cho LLMs vì lỗi có thể xảy ra ở mọi nơi. TLE thường xảy ra trong các vòng lặp đóng hoặc quá nhiều vòng lặp, tương đối dễ định vị. RE cũng dễ định vị, thường vì số chia là 0, chỉ số vượt quá ranh giới, v.v. Do đó khi kích thước tham số bị hạn chế (StarCoder, GPT3.5), RE và TLE dễ tìm, trong khi khả năng tìm lỗi WA xuất hiện cho đến kích thước tham số của GPT4.

5 KẾT LUẬN

Chúng tôi trình bày CodeApex, một benchmark song ngữ tập trung vào khả năng lập trình của LLMs. Đầu tiên, chúng tôi đánh giá LLMs trong nhiệm vụ hiểu lập trình bằng cách đánh giá độ chính xác của chúng trong ba loại câu hỏi trắc nghiệm. Chúng tôi thiết kế hai loại prompt, chỉ trả lời và chain-of-thought, với ba tình huống học trong ngữ cảnh, để so sánh hiệu suất của LLMs. Thứ hai, chúng tôi đánh giá khả năng tạo mã của LLMs bằng cách kiểm tra tỷ lệ chấp nhận của test case. Tập kiểm tra bao gồm 476 câu hỏi mã hóa dựa trên C++, được phân loại là câu hỏi rõ ràng hoặc câu hỏi tường thuật. Chúng tôi cũng cung cấp so sánh về các tình huống chỉ hàm và hàm với ngữ cảnh, để so sánh tác động của thông tin ngữ cảnh của mã mục tiêu. Thứ ba, chúng tôi giới thiệu 1332 đoạn mã lỗi thực tế để đánh giá khả năng sửa mã của LLMs. Chúng tôi so sánh hiệu suất trong các tình huống chỉ mã, mã với thông báo lỗi và mã với mã tiêu chuẩn, và phân tích kết quả của các loại lỗi mã khác nhau. Chúng tôi tổ chức thí nghiệm trên 12 LLMs nổi tiếng, bao gồm các LLMs đa mục đích và các mô hình chuyên biệt dựa trên tinh chỉnh mã. Hiện tại, GPT đạt được hiệu suất hàng đầu trong khả năng lập trình, nhưng các bài kiểm tra con người cho thấy vẫn còn nhiều không gian để cải thiện đáng kể. Hơn nữa, các LLMs chuyên biệt thể hiện khả năng cạnh tranh và cho thấy tiềm năng cải thiện thêm.

Chúng tôi cũng kết hợp hiệu suất con người vào bảng xếp hạng, so sánh khả năng mã hóa của CodeApex với hiệu suất cấp độ con người. Các thí nghiệm cho thấy khả năng lập trình của LLMs vẫn còn một khoảng cách nhất định so với hiệu suất con người. Trong tương lai, tập kiểm tra trong CodeApex sẽ trải qua các cập nhật liên tục, bao gồm phạm vi mở rộng của các loại câu hỏi và ngôn ngữ lập trình bổ sung. Chúng tôi hy vọng rằng CodeApex có thể cung cấp tài liệu tham khảo cho nghiên cứu sau này về khả năng lập trình của LLMs, thúc đẩy sự phát triển và thịnh vượng của chúng cùng nhau.

TÀI LIỆU THAM KHẢO

[1] Daniel K Adiwardana, Minh-Thang Lu, Robert Fergus, David Chen, et al. 2020. Meena: Tác nhân đối thoại miền mở. arXiv preprint arXiv:2001.09977 (2020).

[2] Uri Alon, Meital Zilberstein, và Omer Levy. 2018. Code2Vec: Học các Biểu diễn Phân tán của Mã. arXiv preprint arXiv:1803.09473 (2018).

[3] Daman Arora, Himanshu Gaurav Singh, và Mausam. 2023. LLMs Đã Tiến bộ Đủ chưa? Một Benchmark Giải quyết Vấn đề Thách thức cho Các Mô hình Ngôn ngữ Lớn. arXiv:2305.15074 [cs.CL]

[4] Jacob Austin, Augustus Odena, Maxwell I. Nye, Maarten Bosma, Henryk Michalewski, David Dohan, Ellen Jiang, Carrie J. Cai, Michael Terry, Quoc V. Le, và Charles Sutton. 2021. Tổng hợp Chương trình với Các Mô hình Ngôn ngữ Lớn. CoRR abs/2108.07732 (2021). arXiv:2108.07732 https://arxiv.org/abs/2108.07732

[5] B. Inc. Baichuan. 2023. Baichuan 7b & 13b. https://github.com/baichuan-inc.

[6] Mohammad Ehsan Basiri, Shahla Nemati, Moloud Abdar, Erik Cambria, và U Rajendra Acharya. 2021. ABCDM: Một mô hình sâu CNN-RNN hai chiều dựa trên attention cho phân tích cảm xúc. Future Generation Computer Systems 115 (2021), 279–294.

[7] Ananda Basu và et al. 2004. Copilot–một monitor runtime cứng thời gian thực. Trong International Conference on Embedded Software. Springer, 213–222.

[8] José Cambronero, Sumit Gulwani, Vu Le, Daniel Perelman, Arjun Radhakrishna, Clint Simon, và Ashish Tiwari. 2023. FlashFill++: Mở rộng Lập trình bằng Ví dụ bằng cách Cắt thẳng vào Vấn đề. Proc. ACM Program. Lang. 7, POPL, Bài báo 33 (jan 2023), 30 trang. https://doi.org/10.1145/3571226

[9] Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, Alex Ray, Raul Puri, Gretchen Krueger, Michael Petrov, Heidy Khlaaf, Girish Sastry, Pamela Mishkin, Brooke Chan, Scott Gray, Nick Ryder, Mikhail Pavlov, Alethea Power, Lukasz Kaiser, Mohammad Bavarian, Clemens Winter, Philippe Tillet, Felipe Petroski Such, Dave Cummings, Matthias Plappert, Fotios Chantzis, Elizabeth Barnes, Ariel Herbert-Voss, William Hebgen Guss, Alex Nichol, Alex Paino, Nikolas Tezak, Jie Tang, Igor Babuschkin, Suchir Balaji, Shantanu Jain, William Saunders, Christopher Hesse, Andrew N. Carr, Jan Leike, Josh Achiam, Vedant Misra, Evan Morikawa, Alec Radford, Matthew Knight, Miles Brundage, Mira Murati, Katie Mayer, Peter Welinder, Bob McGrew, Dario Amodei, Sam McCandlish, Ilya Sutskever, và Wojciech Zaremba. 2021. Đánh giá Các Mô hình Ngôn ngữ Lớn được Huấn luyện trên Mã. arXiv:2107.03374 [cs.LG]

[10] Xinyun Chen, Maxwell Lin, Nathanael Schärli, và Denny Zhou. 2023. Dạy Các Mô hình Ngôn ngữ Lớn Tự Gỡ lỗi. arXiv:2304.05128 [cs.CL]

[11] A Chowdhery, S Narang, J Devlin, et al. 2023. Palm: Mở rộng mô hình ngôn ngữ với pathways. Journal of Machine Learning Research 24, 240 (2023), 1–113.

[12] Fenia Christopoulou, Gerasimos Lampouras, Milan Gritta, Guchun Zhang, Yinpeng Guo, Zhongqi Li, Qi Zhang, Meng Xiao, Bo Shen, Lin Li, et al. 2022. Pangu-coder: Tổng hợp chương trình với mô hình ngôn ngữ cấp độ hàm. arXiv preprint arXiv:2207.11280 (2022).

[13] Peter Clark, Isaac Cowhey, Oren Etzioni, Tushar Khot, Ashish Sabharwal, Carissa Schoenick, và Oyvind Tafjord. 2018. Nghĩ rằng Bạn đã Giải quyết Trả lời Câu hỏi? Thử ARC, Thách thức Lý luận AI2. arXiv:1803.05457 [cs.AI]

[14] Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, Christopher Hesse, và John Schulman. 2021. Huấn luyện Trình xác minh để Giải quyết Bài toán Từ Toán học. CoRR abs/2110.14168 (2021). arXiv:2110.14168 https://arxiv.org/abs/2110.14168

[15] Yiming Cui, Ziqing Yang, và Xin Yao. 2023. Mã hóa Văn bản Hiệu quả và Hiệu ứng cho LLaMA và Alpaca Trung Quốc. arXiv preprint arXiv:2304.08177 (2023). https://arxiv.org/abs/2304.08177

[16] Yuhao Dan, Zhikai Lei, Yiyang Gu, Yong Li, Jianghao Yin, Jiaju Lin, Linhao Ye, Zhiyan Tiea, Yougen Zhou, Yilei Wang, Aimin Zhou, Ze Zhou và Qin Chen, Jie Zhou, Liang He, và Xipeng Qiu. 2023. EduChat: Một Hệ thống Chatbot dựa trên Mô hình Ngôn ngữ Quy mô Lớn cho Giáo dục Thông minh. arXiv preprint arXiv:2308.02773 (2023).

[17] Joost CF de Winter. 2023. ChatGPT có thể vượt qua các kỳ thi trung học về hiểu ngôn ngữ Anh không. Researchgate. Preprint (2023).

[18] Aniket Deroy, Kripabandhu Ghosh, và Saptarshi Ghosh. 2023. Các Mô hình Tóm tắt và LLMs được Tiền huấn luyện Sẵn sàng như thế nào cho Tóm tắt Phán quyết Vụ kiện Pháp lý? arXiv:2306.01248 [cs.CL]

[19] Zhengxiao Du, Yujie Qian, Xiao Liu, Ming Ding, Jiezhong Qiu, Zhilin Yang, và Jie Tang. 2022. GLM: Tiền huấn luyện Mô hình Ngôn ngữ Tổng quát với Điền Trống Tự động hồi quy. Trong Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 320–335.

[20] Michael C Frank. 2023. Các bước đầu tiên trong việc đánh giá năng lực của các mô hình ngôn ngữ lớn. Nature Reviews Psychology 2, 8 (2023), 451–452.

[21] Deepayan Ghosal, Koustav Ghosh, Abir Chakraborty, Asif Ekbal, và Pushpak Bhattacharyya. 2020. SAIL: Một Mô hình Ngôn ngữ Trí tuệ Nhân tạo Có tình huống cho Phân tích Cảm xúc trong Văn bản Văn học. Trong Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations. 97–104.

[22] Aidan Gilson, Conrad Safraneck, Thomas Huang, Vimig Socrates, Ling Chi, Richard Taylor, và David Chartash. 2023. ChatGPT hoạt động như thế nào trong Kỳ thi Cấp phép Y tế Hoa Kỳ? Ý nghĩa của Các Mô hình Ngôn ngữ Lớn đối với Giáo dục Y tế và Đánh giá Kiến thức. JMIR medical education 9 (02 2023), e45312. https://doi.org/10.2196/45312

[23] Arto Hellas, Juho Leinonen, Sami Sarsa, Charles Koutcheme, Lilja Kujanpää, và Juha Sorva. 2023. Khám phá Phản hồi của Các Mô hình Ngôn ngữ Lớn đối với Yêu cầu Trợ giúp của Lập trình viên Mới bắt đầu. arXiv preprint arXiv:2306.05715 (2023).

[24] Dan Hendrycks, Steven Basart, Saurav Kadavath, Mantas Mazeika, Akul Arora, Ethan Guo, Collin Burns, Samir Puranik, Horace He, Dawn Song, et al. 2021. Đo lường năng lực thách thức mã hóa với apps. arXiv preprint arXiv:2105.09938 (2021).

[25] Linqing Huang, Pengcheng Yin, Wenpeng Guo, Xiaoya Zhang, Mo Yu, và Yinxuan Wang. 2020. CodeBERT: Một Mô hình được Tiền huấn luyện cho Lập trình và Ngôn ngữ Tự nhiên. Trong Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics (ACL).

[26] Rui Huang, Xiaoya Zhang, và Furu Wei. Được truy cập: 2021. CodeXGLUE. https://github.com/microsoft/CodeXGLUE.

[27] Yuzhen Huang, Yuzhuo Bai, Zhihao Zhu, Junlei Zhang, Jinghan Zhang, Tangjun Su, Junteng Liu, Chuancheng Lv, Yikai Zhang, Jiayi Lei, Yao Fu, Maosong Sun, và Junxian He. 2023. C-Eval: Một Bộ Đánh giá Trung Quốc Đa cấp Đa ngành cho Các Mô hình Nền tảng. arXiv preprint arXiv:2305.08322 (2023).

[28] Hamel Husain, Ho-Hsiang Wu, Tiferet Gazit, Miltiadis Allamanis, và Marc Brockschmidt. 2020. Thách thức CodeSearchNet: Đánh giá Trạng thái Tìm kiếm Mã Ngữ nghĩa. arXiv:1909.09436 [cs.LG]

[29] Yunjie Ji, Yong Deng, Yan Gong, Yiping Peng, Qiang Niu, Baochang Ma, và Xiangang Li. 2023. BELLE: Trở thành Động cơ Mô hình Ngôn ngữ Lớn của Mọi người. https://github.com/LianjiaTech/BELLE.

[30] Yunjie Ji, Yong Deng, Yan Gong, Yiping Peng, Qiang Niu, Lei Zhang, Baochang Ma, và Xiangang Li. 2023. Khám phá Tác động của Mở rộng Dữ liệu Hướng dẫn trên Các Mô hình Ngôn ngữ Lớn: Một Nghiên cứu Thực nghiệm về Các Trường hợp Sử dụng Thực tế. arXiv preprint arXiv:2303.14742 (2023).

[31] Adi Lahat, Eyal Shachar, Benjamin Avidan, Zina Shatz, Benjamin S Glicksberg, và Eyal Klang. 2023. Đánh giá việc sử dụng mô hình ngôn ngữ lớn trong việc xác định các câu hỏi nghiên cứu hàng đầu trong tiêu hóa. Scientific reports 13, 1 (2023), 4164.

[32] Guokun Lai, Qizhe Xie, Hanxiao Liu, Yiming Yang, và Eduard Hovy. 2017. RACE: Tập dữ liệu Hiểu đọc Quy mô Lớn Từ Các Kỳ thi. arXiv:1704.04683 [cs.CL]

[33] Vladimir I Levenshtein. 1966. Mã nhị phân có khả năng sửa các phép xóa, chèn và đảo ngược. Soviet physics doklady 10, 8 (1966), 707–710.

[34] Raymond Li, Loubna Ben Allal, Yangtian Zi, Niklas Muennighoff, Denis Kocetkov, Chenghao Mou, Marc Marone, Christopher Akiki, Jia Li, Jenny Chim, Qian Liu, Evgenii Zheltonozhskii, Terry Yue Zhuo, Thomas Wang, Olivier Dehaene, Mishig Davaadorj, Joel Lamy-Poirier, João Monteiro, Oleh Shliazhko, Nicolas Gontier, Nicholas Meade, Armel Zebaze, Ming-Ho Yee, Logesh Kumar Umapathi, Jian Zhu, Benjamin Lipkin, Muhtasham Oblokulov, Zhiruo Wang, Rudra Murthy, Jason Stillerman, Siva Sankalp Patel, Dmitry Abulkhanov, Marco Zocca, Manan Dey, Zhihan Zhang, Nour Fahmy, Urvashi Bhattacharyya, Wenhao Yu, Swayam Singh, Sasha Luccioni, Paulo Villegas, Maxim Kunakov, Fedor Zhdanov, Manuel Romero, Tony Lee, Nadav Timor, Jennifer Ding, Claire Schlesinger, Hailey Schoelkopf, Jan Ebert, Tri Dao, Mayank Mishra, Alex Gu, Jennifer Robinson, Carolyn Jane Anderson, Brendan Dolan-Gavitt, Danish Contractor, Siva Reddy, Daniel Fried, Dzmitry Bahdanau, Yacine Jernite, Carlos Muñoz Ferrandis, Sean Hughes, Thomas Wolf, Arjun Guha, Leandro von Werra, và Harm de Vries. 2023. StarCoder: mong nguồn sức mạnh ở bên bạn! arXiv:2305.06161 [cs.CL]

[35] Y Li, D Choi, J Chung, et al. 2022. Tạo mã cấp độ cạnh tranh với alphacode. Science (2022).

[36] Jianghao Lin, Xinyi Dai, Yunjia Xi, Weiwen Liu, Bo Chen, Xiangyang Li, Chenxu Zhu, Huifeng Guo, Yong Yu, Ruiming Tang, et al. 2023. Các Hệ thống Đề xuất có thể Hưởng lợi từ Các Mô hình Ngôn ngữ Lớn như thế nào: Một Khảo sát. arXiv preprint arXiv:2306.05817 (2023).

[37] Jianghao Lin, Rong Shan, Chenxu Zhu, Kounianhua Du, Bo Chen, Shigang Quan, Ruiming Tang, Yong Yu, và Weinan Zhang. 2023. Rella: Các mô hình ngôn ngữ lớn được tăng cường truy xuất cho hiểu hành vi tuần tự suốt đời trong đề xuất. arXiv preprint arXiv:2308.11131 (2023).

[38] Xiao Liu, Kaixuan Ji, Yicheng Fu, Weng Tam, Zhengxiao Du, Zhilin Yang, và Jie Tang. 2022. P-tuning: Điều chỉnh prompt có thể so sánh với tinh chỉnh trên các quy mô và nhiệm vụ. Trong Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers). 61–68.

[39] Yang Liu và Mirella Lapata. 2019. Tinh chỉnh BERT cho tóm tắt trích xuất. Trong Association for Computational Linguistics (ACL).

[40] Ziyang Luo, Can Xu, Pu Zhao, Qingfeng Sun, Xiubo Geng, Wenxiang Hu, Chongyang Tao, Jing Ma, Qingwei Lin, và Daxin Jiang. 2023. WizardCoder: Trao quyền cho Các Mô hình Ngôn ngữ Lớn Mã với Evol-Instruct.

[41] Yingwei Ma, Yue Liu, Yue Yu, Yuanliang Zhang, Yu Jiang, Changjian Wang, và Shanshan Li. 2023. Tại Giai đoạn Huấn luyện nào Dữ liệu Mã Giúp LLMs Lý luận? arXiv preprint arXiv:2309.16298 (2023).

[42] Lili Mou, Rui Men, Ge Li, Yan Xu, Lu Zhang, và Zhi Jin. 2016. Mạng Nơ-ron Tích chập trên Cấu trúc Cây cho Xử lý Ngôn ngữ Lập trình. Trong Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence (AAAI).

[43] Daye Nam, Andrew Macvean, Vincent Hellendoorn, Bogdan Vasilescu, và Brad Myers. 2024. Sử dụng LLM để Giúp với Hiểu Mã. arXiv:2307.08177 [cs.SE]

[44] Erik Nijkamp, Bo Pang, Hiroaki Hayashi, Lifu Tu, Huan Wang, Yingbo Zhou, Silvio Savarese, và Caiming Xiong. 2022. Codegen: Một mô hình ngôn ngữ lớn mở cho mã với tổng hợp chương trình đa lượt. arXiv preprint arXiv:2203.13474 (2022).

[45] Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, và Peter J. Liu. 2020. Khám phá Giới hạn của Học Chuyển giao với Transformer Văn bản-sang-Văn bản Thống nhất. Journal of Machine Learning Research (JMLR) 21, 140 (2020), 1–67.

[46] Michael Robb et al. 2021. LLAMA: Tận dụng Các Mô hình Ngôn ngữ cho Phân tích Ngữ nghĩa Zero-shot với Viết lại Phát ngôn. arXiv preprint arXiv:2109.02645 (2021).

[47] B Roziere, J Gehring, F Gloeckle, et al. 2023. Code llama: Các mô hình nền tảng mở cho mã. arXiv preprint arXiv:2308.12950 (2023).

[48] Tianxiang Sun, Xiaotian Zhang, Zhengfu He, Peng Li, Qinyuan Cheng, Hang Yan, Xiangyang Liu, Yunfan Shao, Qiong Tang, Xingjian Zhao, Ke Chen, Yining Zheng, Zhejian Zhou, Ruixiao Li, Jun Zhan, Yunhua Zhou, Linyang Li, Xiaogui Yang, Lingling Wu, Zhangyue Yin, Xuanjing Huang, và Xipeng Qiu. 2023. MOSS: Huấn luyện Các Mô hình Ngôn ngữ Đối thoại từ Dữ liệu Tổng hợp. (2023).

[49] InternLM Team. 2023. InternLM: Một Mô hình Ngôn ngữ Đa ngôn ngữ với Khả năng được Tăng cường Liên tục. https://github.com/InternLM/InternLM.

[50] Runchu Tian, Yining Ye, Yujia Qin, Xin Cong, Yankai Lin, Yinxu Pan, Yesai Wu, Zhiyuan Liu, và Maosong Sun. 2024. DebugBench: Đánh giá Khả năng Gỡ lỗi của Các Mô hình Ngôn ngữ Lớn. arXiv:2401.04621 [cs.SE]

[51] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, và Illia Polosukhin. 2017. Attention là tất cả những gì bạn cần. Advances in neural information processing systems 30 (2017).

[52] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, và Illia Polosukhin. 2017. Attention là tất cả những gì bạn cần. Trong Advances in Neural Information Processing Systems (NeurIPS).

[53] Yue Wang, Weishi Wang, Shafiq Joty, và Steven C. H. Hoi. 2021. CodeT5: Các Mô hình Mã hóa-Giải mã được Tiền huấn luyện Thống nhất nhận biết Định danh cho Hiểu và Tạo Mã. arXiv:2109.00859 [cs.CL]

[54] Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, et al. 2022. Khả năng nổi bật của các mô hình ngôn ngữ lớn. arXiv preprint arXiv:2206.07682 (2022).

[55] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou, et al. 2022. Prompting chuỗi suy nghĩ gợi ra lý luận trong các mô hình ngôn ngữ lớn. Advances in Neural Information Processing Systems 35 (2022), 24824–24837.

[56] Kui Xu, Lei Wu, Zhiguang Wang, Fei Tian, Tong Liu, và Compling Pu. 2019. AttentionXML: Mô hình Sâu nhận biết Attention dựa trên Cây Nhãn cho Phân loại Văn bản Đa nhãn Cực đoan Hiệu suất Cao. Trong Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining (KDD).

[57] Ke Yang, Jiateng Liu, John Wu, Chaoqi Yang, Yi R Fung, Sha Li, Zixuan Huang, Xu Cao, Xingyao Wang, Yiquan Wang, et al. 2024. Nếu llm là phù thủy, thì mã là cây đũa phép: Một khảo sát về cách mã trao quyền cho các mô hình ngôn ngữ lớn để phục vụ như các tác nhân thông minh. arXiv preprint arXiv:2401.00812 (2024).

[58] Pengcheng Yao, Yiding Mao, Zijun Luo, Xiwei Li, và Ling Qin. 2020. Graph2Code: Tạo Đoạn mã từ Giao diện Người dùng Đồ họa sử dụng Mạng Nơ-ron Đồ thị. Trong Proceedings of the 28th ACM International Conference on Multimedia (MM).

[59] Hao Yu, Bo Shen, Dezhi Ran, Jiaxin Zhang, Qi Zhang, Yuchi Ma, Guangtai Liang, Ying Li, Qianxiang Wang, và Tao Xie. 2024. CoderEval: Một Benchmark của Tạo Mã Thực dụng với Các Mô hình được Tiền huấn luyện Tạo sinh. Trong Proceedings of the 46th IEEE/ACM International Conference on Software Engineering (<conf-loc>, <city>Lisbon</city>, <country>Portugal</country>, </conf-loc>) (ICSE '24). Association for Computing Machinery, New York, NY, USA, Article 37, 12 trang. https://doi.org/10.1145/3597503.3623316

[60] Hao Yu, Bo Shen, Dezhi Ran, Jiaxin Zhang, Qi Zhang, Yuchi Ma, Guangtai Liang, Ying Li, Qianxiang Wang, và Tao Xie. 2024. Codereval: Một benchmark của tạo mã thực dụng với các mô hình được tiền huấn luyện tạo sinh. Trong Proceedings of the 46th IEEE/ACM International Conference on Software Engineering. 1–12.

[61] Aohan Zeng, Xiao Liu, Zhengxiao Du, Zihan Wang, Hanyu Lai, Ming Ding, Zhuoyi Yang, Yifan Xu, Wendi Zheng, Xiao Xia, et al. 2022. Glm-130b: Một mô hình được tiền huấn luyện song ngữ mở. arXiv preprint arXiv:2210.02414 (2022).

[62] Jingqing Zhang, Yaoqing Yang, Chris Tar, và Jason Baldridge. 2020. PEGASUS: Tiền huấn luyện với các câu khoảng trống được trích xuất cho tóm tắt trừu tượng. arXiv preprint arXiv:1912.08777 (2020).

[63] Yizhe Zhang, Eric Sun, Zhiyuan Liu, Xin Li, Minlie Deng, và Yang Ji. 2019. DialoGPT: Tiền huấn luyện tạo sinh quy mô lớn cho tạo phản hồi đối thoại. arXiv preprint arXiv:1911.00536 (2019).

[64] Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric. P Xing, Hao Zhang, Joseph E. Gonzalez, và Ion Stoica. 2023. Đánh giá LLM-as-a-judge với MT-Bench và Chatbot Arena. arXiv:2306.05685 [cs.CL]

[65] Qinkai Zheng, Xiao Xia, Xu Zou, Yuxiao Dong, Shan Wang, Yufei Xue, Zihan Wang, Lei Shen, Andi Wang, Yang Li, Teng Su, Zhilin Yang, và Jie Tang. 2023. CodeGeeX: Một Mô hình được Tiền huấn luyện cho Tạo Mã với Các Đánh giá Đa ngôn ngữ trên HumanEval-X. arXiv:2303.17568 [cs.LG]

[66] Shuyan Zhou, Uri Alon, Frank F Xu, Zhengbao Jiang, và Graham Neubig. 2022. Docprompting: Tạo mã bằng cách truy xuất tài liệu. Trong The Eleventh International Conference on Learning Representations.

LỜI CẢM ơN

Chúng tôi muốn cảm ơn Qinxiang Cao và Pengfei Liu cho các cuộc thảo luận hữu ích. Chúng tôi cũng cảm ơn Shanghai Boyu Education Technology Co., Ltd vì đã cấp cho chúng tôi ủy quyền dữ liệu và cung cấp hỗ trợ có giá trị trong việc thiết lập khung kiểm tra. Công việc được hỗ trợ một phần bởi Quỹ Khoa học Tự nhiên Quốc gia Trung Quốc (62177033).

A HIỆU SUẤT CHI TIẾT TRONG HIỂU LẬP TRÌNH

Bảng 1, Bảng 2, Bảng 3 và Bảng 4 trình bày sự phân tích hiệu suất của LLMs trong nhiệm vụ hiểu lập trình trong các tình huống 5-shot, 2-shot và 0-shot.

[Các bảng tiếp theo được dịch tương tự...]

B HIỆU SUẤT CHI TIẾT TRONG TẠO MÃ

Bảng 5 và Bảng 6 trình bày sự phân tích hiệu suất của LLMs trong nhiệm vụ tạo mã trong các tình huống chỉ mã và mã với ngữ cảnh. Hiệu suất phân tích của các câu hỏi rõ ràng và câu hỏi tường thuật cũng được hiển thị trong bảng.

C HIỆU SUẤT CHI TIẾT TRONG SỬA MÃ

Bảng 7, 9, 11, 8, 10 và 12 trình bày sự phân tích hiệu suất của LLMs trong nhiệm vụ sửa mã với lỗi trả lời sai, lỗi giới hạn thời gian và lỗi runtime. Hiệu suất phân tích của các tình huống chỉ mã, mã với thông báo lỗi và mã với mã tiêu chuẩn cũng được hiển thị trong bảng.

Nhận ngày 20 tháng 2 năm 2007; sửa đổi ngày 12 tháng 3 năm 2009; chấp nhận ngày 5 tháng 6 năm 2009

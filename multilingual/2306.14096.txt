# 2306.14096.pdf
# Converted from PDF to TXT
# Source path: /home/admin88/arxiv-downloader/multilingual/2306.14096.pdf
# File size: 385209 bytes

===============================================
PDF FILE CONTENT
===============================================


--- PAGE 1 ---
Chinese Fine-Grained Financial Sentiment Analysis with Large Language Models
Yinyu Lan ,Yanru Wu∗,Wang Xu and Weiqiang Feng and Youhao Zhang
FinChina AI Research
lanyinyu19@mails.ucas.ac.cn, {wuyr, xuwang, fengwq, zhangyh }@finchina.com
Abstract
Entity-level fine-grained sentiment analysis in the
financial domain is a crucial subtask of sentiment
analysis and currently faces numerous challenges.
The primary challenge stems from the lack of high-
quality and large-scale annotated corpora specifi-
cally designed for financial text sentiment analysis,
which in turn limits the availability of data neces-
sary for developing effective text processing tech-
niques. Recent advancements in large language
models (LLMs) have yielded remarkable perfor-
mance in natural language processing tasks, pri-
marily centered around language pattern matching.
In this paper, we propose a novel and extensive
Chinese fine-grained financial sentiment analysis
dataset, FinChina SA, for enterprise early warn-
ing. We thoroughly evaluate and experiment with
well-known existing open-source LLMs using our
dataset. We firmly believe that our dataset will
serve as a valuable resource to advance the ex-
ploration of real-world financial sentiment analy-
sis tasks, which should be the focus of future re-
search.1
1 Introduction
The rapid development of the Internet and the financial indus-
try has led to an abundance of professional stock review re-
ports, research reports, and individual investors’ opinions and
analyses in the financial domain. Whether in news reports or
commentaries on related topics and companies, these texts of-
ten provide evaluations and attitudes towards relevant events
and companies, offering valuable insights for investment and
regulation. A comprehensive understanding of this evaluation
information can enhance investors’ market understanding and
aid in investment decision-making. Additionally, enterprises
or financial market regulators can benefit from early identi-
fication of hidden issues through such evaluations, enabling
them to grasp market dynamics and mitigate risks. Conse-
quently, sentiment analysis of financial texts has emerged as
∗Corresponding Author
1The FinChina SA dataset is publicly available at https://github.
com/YerayL/FinChina-SA.
OPPO 关闭芯片业务  背后房东发声：  4 月份才签完续租合同  未收到退租通知  
5 月15 日，上市公司 华安基金 近期拟购入张润大厦，而 哲库科技 是该大厦的重要承租方，该公司是
OPPO 旗下公司，实际租赁面积为 19314.312 平米，占张润大厦可租赁面积的 45.7% 。 
…… 
如果出现退租情况，房东将立即启动有租赁意向的客户推介工作。
OPPO shut down the chip business, and the landlord said: The lease renewal
contract was signed in April and no notice of cancellation was received
On Ma y 15, the listed compan y Huaan Fund  recently planned to purchase Zhangrun
Building, and Zheku T echnology  is an important tenant of the building. The compan y is
a subsidiary of OPPO , and the actual leased area is 19,314.312 square meters,
accounting for the leasable area of Zhangrun Building 45.7% of the total.
...
In the ev ent of a rental withdr awal, the landlord will immediately start the promotion of
customers with rental intentions.
OPPO 广东移动通信公司  
OPPO Electronics Corp消极
Negativ e 限制业务范围  
Limit business scope  
哲库科技（上海）有限公司  
Zheku T echnology
(Shanghai) Co ., Ltd.
华安基金管理有限公司  
Hua An Fund  
Management Co .,Ltd.特别消极  
Extremely negativ e 
中性 
Neutr al 破产清算  
Liquidation  
非负面类型  
Non-negativ e type Figure 1: An example of financial sentiment analysis task for enter-
prise early warning. The cyan font indicates the companies involved
in the news. The red and blue fonts indicate the associated polarity
and warning type respectively.
a prominent area of research and application. The text entity-
level fine-grained sentiment analysis research in the financial
domain is still in its infancy, and it is also an important sub-
task of fine-grained sentiment analysis [Pang et al. , 2008 ],
and currently facing many challenges. However, there is a
lack of high-quality and large-scale text annotation corpus in
the Chinese financial domain, resulting in a lack of data sup-
port for the underlying technology.
Large language models have attracted a lot of attention in
the domain of artificial intelligence due to their impressive
ability to solve natural language processing tasks. In par-
ticular, dialogue-based large language models such as Chat-
GPT have had a major impact on social development and
have played a crucial role for the application of artificial in-
telligence in daily life, attracting widespread attention from
academia and industry. However, their research in specific
domain, such as the financial domain, is still relatively scarce.
How to better use and evaluate the ability of large languagearXiv:2306.14096v5  [cs.CL]  15 Sep 2023

--- PAGE 2 ---
models in the vertical domain can solve the research problems
that need to be solved urgently [Liet al. , 2023 ].
Since the release of ChatGPT, there has been a growing
number of related models developed and released, based on
LLaMA [Touvron et al. , 2023 ]and BLOOM [Scao et al. ,
2022 ]models. Recent research has predominantly focused on
effectively leveraging general LLMs for domain-specific su-
pervised fine-tuning training. This process entails construct-
ing a dataset in either instruction or conversational format and
fine-tuning it using a pre-trained backbone model. Notably,
this way of training with significantly smaller data than used
in pre-training can yield favorable results. These works can
be categorized into two distinct types [Chen et al. , 2023 ]. The
first category is instruction-based tuning, with Alpaca [Taori
et al. , 2023 ]serving as a prominent example. Alpaca uti-
lizes self-instruction [Wang et al. , 2022 ]techniques to gener-
ate supplementary instructions for fine-tuning the GPT 3.5
model, leading to enhanced accuracy and context-sensitive
output. The second category comprises conversation-based
tuning models that leverage the distillation of user interac-
tions with ChatGPT. Vicuna [Chiang et al. , 2023 ]exempli-
fies this approach by utilizing a comprehensive dataset of
user-shared ChatGPT conversations to improve model perfor-
mance.
Aiming to address the lack of a comprehensive Chinese fi-
nancial sentiment analysis dataset and meet the demands of
enterprises regarding negative news alerts, we propose the
FinChina SA dataset specifically designed for the financial
domain. Figure 1 illustrates an example of the financial senti-
ment analysis task for enterprise early warning. Initially, we
conduct data crawling and cleaning on major financial news
websites. Subsequently, We label the company names, senti-
ment polarities and warning types in the crawled data. A total
of 11,036 news articles are annotated, including 8,739 com-
panies, 190 warning types, and 21,272 corresponding senti-
ment examples. To explore the application of LLMs in the
financial domain, we conduct extensive research and exper-
iments on the FinChina SA dataset. We train these models
using instruction-based tuning and conversation-based tuning
techniques. The experimental results demonstrate the promis-
ing performance of financial LLMs (FinLLMs) and the limi-
tation of ChatGPT in financial sentiment analysis tasks.
The contributions of this paper are as follows: (1) We pro-
pose FinChina SA, a novel large-scale dataset designed for
fine-grained sentiment analysis in the Chinese financial do-
main. (2) We evaluate and analyze the capabilities and lim-
itations of ChatGPT in the zero-shot setting for fine-grained
financial sentiment analysis. (3) We compare and analyze the
capabilities of well-known existing open-source LLMs on the
benchmark and discuss the feasibility and prospects of devel-
oping FinLLMs.
2 Related Work
Following a comprehensive examination of research pertain-
ing to fine-grained financial sentiment analysis (Section 2.1)
and large language models (Section 2.2), we delve into the
discussion of supervised fine-tuning of LLMs (Section 2.3).2.1 Fine-Grained Financial Sentiment Analysis
Fine-grained sentiment analysis is a significant task with sub-
stantial practical applications. However, there is a scarcity of
studies focused on entity-level fine-grained sentiment analy-
sis within the financial domain, particularly due to the lack of
available datasets. This limitation poses challenges for con-
ducting research in this task. [Cortis et al. , 2017 ]analyzed
the approaches and tools employed by over 30 participants
during the SemEval-2017 conference on ”Sentiment Analysis
of Financial Microblog and News.” The majority of partici-
pants relied on traditional machine learning models such as
SVM and SVR. [Doet al. , 2019 ]highlighted the demanding
nature of data labeling within the financial domain, empha-
sizing the need for domain expertise and the associated high
costs. Consequently, limited labeled data is available. [Maia
et al. , 2018 ]publicly released a small dataset named FiQA,
comprising textual instances within the financial domain. The
dataset also includes the entities referenced in the text, with
corresponding sentiment scores assigned to each entity.
2.2 Large Language Models
The introduction of the transformer model [Vaswani et al. ,
2017 ]has enabled the training of unsupervised text data at a
large scale. Over the past few years, encoder-based models,
such as BERT [Devlin et al. , 2018 ], have exhibited impres-
sive capabilities in various natural language processing (NLP)
tasks. More recently, decoder-based models, including GPT-
1[Radford et al. , 2018 ], GPT-2 [Radford et al. , 2019 ], and
T5[Raffel et al. , 2020 ], have made significant advancements.
With the increasing number of model parameters, models like
GPT-3 [Brown et al. , 2020 ], often referred to as LLMs, have
gradually acquired zero-shot learning abilities. These models
can generate responses based on instructions without relying
on examples. Moreover, [Wuet al. , 2023 ]have recently pro-
posed a proprietary model, BloombergGPT, in the financial
domain, focusing primarily on pre-training. An open-source
large language model, FinGPT, is proposed by [Yang et al. ,
2023 ]. It takes a data-centric approach, providing researchers
and practitioners with accessible and transparent resources to
develop their FinLLMs.
2.3 Supervised Fine-Tuning
Currently, post-training methods that are used in supervised
fine-tuning of LLMs can be categorized into instruction-
based tuning and conversation-based tuning [Chen et al. ,
2023 ]. Instruction tuning aims to train language models
to comply with human instructions [Ouyang et al. , 2022 ],
which can be manually designed or created in a hybrid man-
ner where humans provide initial instructions and OpenAI
ChatGPT generates additional similar instructions using in-
context learning [Wang et al. , 2022 ]. Language models are
taught to engage in chat-based conversations similar to Ope-
nAI ChatGPT through the use of ChatGPT-distilled conver-
sations, whereas instruction data is typically employed for
single-turn question answering (QA). A notable example of
this approach is Alpaca [Taori et al. , 2023 ], which utilizes the
self-instruction technique to generate additional instructions
using the GPT 3.5 model for fine-tuning. This leads to im-
proved accuracy and contextually relevant outputs. The sec-

--- PAGE 3 ---
500 1000 1500 2000 2500 3000 3500
News text lengths020040060080010001200140016001800Figure 2: Distribution of news text lengths.
ond category consists of conversation-based tuning models
that leverage the distillation of user interactions with Chat-
GPT. Vicuna [Chiang et al. , 2023 ]is an exemplary model in
this category, benefiting from extensive user-shared dialogue
datasets to enhance model performance.
3 Data Collection
In order to construct a comprehensive sentiment analysis
dataset in the financial domain, we recruited a team of 20
annotators specializing in finance-related subjects. Initially,
we selected 11,036 representative high-quality news articles
from a pool of 288,788 crawled news articles. These articles
served as the basis for annotation. Each annotator pre-labeled
2,500 data samples, and we compared the respective labeling
results during the annotation process. We documented the
differences and ambiguities and used them to formulate com-
prehensive labeling guidelines for various entities and con-
texts that exhibited ambiguity or conflict. During the labeling
phase, each news text was independently reviewed by a min-
imum of 5 annotators. It is worth mentioning that the anno-
tators did not engage in communication during the labeling
process and solely relied on the established guidelines. Once
the independent labeling was completed, any discrepancies or
errors in the labeling results were addressed through discus-
sions involving an additional annotator. The aim was to reach
a consensus among all annotators, leading to modifications
in the labeled data and the final completion of the annotation
process.
Out of the 21,272 companies involved, 6,991 are positive
sentiments, while 14,281 are negative sentiments. The spe-
cific statistical findings are presented in Table 1 and Figure 2.
Given that our sentiment analysis primarily focuses on enter-
prise early warning, we place particular emphasis on negative
emotions. To further categorize negative emotions, we divide
them into three levels: extremely negative, very negative, and
negative. Among the negative sentiments, there were 225 in-
stances of extreme negativity, 1,886 instances of high nega-
tivity, and 1,170 instances of general negativity.Table 1: Statistics of the FinChina SA dataset
Stats Number
# News texts 11,036
# Companies 8,739
# Sentiments 21,272
# Non-negative sentiments 6,991
# Negative sentiments 14,281
# Early warning types 190
Max news text length 3,540
Min news text length 411
Avg. news text length 1,357
4 Models
Sections 4.1-4.5 introduce the pre-trained language models
used in our experiments in detail, including models such as
Longformer, LLaMA, BLOOM, ChatGLM and ChatGPT.
4.1 Longformer
To compare with previous pre-trained models having fewer
parameters, we utilize the Longformer model [Beltagy et al. ,
2020 ]. The Longformer can process sequences up to 4,096
tokens by employing an attention mechanism that scales lin-
early with the input text length, unlike the quadratic behavior
in earlier Transformer models such as BERT [Devlin et al. ,
2018 ]. Considering the maximum document length in our
corpus (over 3,540 words, see Table 1), we deemed the Long-
former model a suitable baseline. The Longformer model is
used to process the initial 4,096 tokens of each document, and
the resulting 768-dimensional pooled output is retained as
the document representation. This representation is then fed
into two feed-forward classification neural network to predict
probabilities for all sentiment polarities and warning types.
The Longformer weights undergo additional fine-tuning dur-
ing the training process for our classification task. Since our
dataset is in Chinese, we use the Longformer-chinese2which
is pre-trained on Chinese news corpus.
4.2 LLaMA
LLaMA [Touvron et al. , 2023 ]is a collection of open-source
multi-lingual base models with parameter sizes ranging from
7 billion to 65 billion, made available to the research commu-
nity. However, the original LLaMA-7B model lacked Chi-
nese corpus during pre-training, resulting in the absence of
Chinese vocabulary. Consequently, we employed the Chi-
nese LLaMA model [Cuiet al. , 2023 ], which incorporated
an expanded Chinese vocabulary, and conducted a secondary
pre-training using the 120G Chinese general corpus known
as Chinese LLaMA plus [Cuiet al. , 2023 ]. The Chinese
LLaMA model markedly enhances the original LLaMA’s pro-
ficiency in understanding and generating Chinese content.
4.3 BLOOM
BLOOM [Scao et al. , 2022 ]is an autoregressive large lan-
guage model trained on a large corpus of text data with the aid
2https://github.com/SCHENLIU/longformer-chinese

--- PAGE 4 ---
假设你是一个金融领域的细粒度情感分析模型，我会给你一些机构名称、情感极性列表、预警类型列表，和与这些机构相关的一篇新闻报
道，请分析这些机构属于情感极性中的哪一种，并进一步判断属于哪一个预警类型。注意结果不能为空，不要回答多余的话。
Suppose y ou are a finanical fine-gr ained sentiment analysis model. I will giv e you some organization names, a list of
sentiment polarities, a list of w arning t ypes, and a news report related to these organizations. Please analyz e which
sentiment polarit y these organization s belong to and further determine which w arning t ype it belongs to . Note that the
result cannot be empt y, do not answer redundant words.
机构名称： [ 机构名称 1, 机构名称 2, ...]
Organization names: [organization_name_1, organization_name_2, ...]  
情感极性： [ 积极 , 中性 , 消极 , 很消极 , 特别消极 ]
Sentiment polarities: [P ositiv e, Neutr al, Negativ e, Very negativ e, Extremely negativ e]
预警类型： [ 产品召回 , 操纵证券市场 , 环保不达标 , ...] 
Warning t ypes: [Product recalls, Stock mark et manipulation, Not en vironmentally friendly , ...] 
新闻文本： A 股股权激励，实控人父子拿下近两成份额！监管部门：是否利益输送 ......
News text: A -share equit y incentiv e, the father and son of the actual controller won nearly 20% of the shares!
Regulatory authorities: whether to tr ansfer benefits...
请用三元组列表的形式（ [( 机构名称 1, 情感极性 1, 预警类型 1), ( 机构名称 2, 情感极性 2, 预警类型 2), ...] ）进行回答 。
Please answer in the form of a list of triples ([(organization_name_1, sentiment_polarit y_1, warning_t ype_1),
(organization_name_2, sentiment_ polarit y_2, w arning_t ype_2), ...]).  
 Figure 3: Illustration of the prompt template used in our experiments for ChatGPT
of industrial-scale computational resources. Consequently, it
can generate coherent text in 46 languages, including 13 pro-
gramming languages, which is highly comparable to human-
authored text. Furthermore, BLOOM can be directed to exe-
cute text tasks that it hasn’t received explicit training for, by
framing them as text generation assignments.In our experi-
ments, We use BLOOMZ [Muennighoff et al. , 2022 ], a mul-
titask prompted fine-tuned version of BLOOM, with better
generalization and zero-shot capabilities.
4.4 ChatGLM
ChatGLM is an open-source conversational language model
that supports both Chinese and English. It is based on the
General Language Model (GLM) [Duet al. , 2022; Zeng et
al., 2022 ]architecture and consists of 6.2 billion parameters.
With the aid of model quantization technology, users can de-
ploy ChatGLM-6B on consumer-grade graphics cards with as
little as 6GB of video memory when using the INT4 quantiza-
tion level. ChatGLM employs a technology similar to Chat-
GPT, specifically optimized for Chinese question-and-answer
(Q&A) interactions and dialogues. With approximately 1 tril-
lion Chinese-English bilingual tokens, supported by various
techniques such as supervision, fine-tuning, and human feed-
back reinforcement learning, ChatGLM-6B is capable of gen-
erating responses that closely align with human preferences.
4.5 ChatGPT
ChatGPT is a sibling model to InstructGPT [Ouyang et al. ,
2022 ], specifically designed to follow user instructions and
generate detailed responses. ChatGPT is enhanced through
instruction tuning [Weiet al. , 2021 ]and reinforcement learn-
ing from human feedback (RLHF) [Ouyang et al. , 2022 ].Unlike the original GPT-3, which lacks a specific design for
following user instructions, ChatGPT demonstrates a signif-
icantly improved capability to generate aligned and helpful
outputs in response to user instructions. ChatGPT has been
widely employed in diverse artificial intelligence scenarios,
such as search-based question answering, fundamental NLP
tasks, etc.
5 Experiments and Analyses
5.1 Task Definition
We start by defining the fine-grained financial sentiment anal-
ysis task for enterprise early warning, before we introduce
our experiments. Given a news text swith a sequence
of words {w1, w2, ...w n}and the names of all companies
{I1, I2, ...In}involved in this sentence, the goal is to predict
their polarities and early warning type.
5.2 Dataset Construction
According to two different forms of supervised fine-tuning
methods, instruction fine-tuning and dialogue fine-tuning, we
construct the dataset into two forms of single-turn QA and
multi-turn QA. Specifically, in a single round of QA, the
model will be asked to answer the sentiment polarities and
warning types of all companies at once. In multiple rounds
of QA, the task will be decomposed into multiple subtasks.
In each subtask, model will answer the polarity or warning
type of a company, and the model will complete all subtasks
in turn. The dataset is split into 90% for training and 10% for
test.

--- PAGE 5 ---
Table 2: Experimental results on the FinChina SA dataset. The Longformer model is fine-tuned using the original training set. The large
language models in lines two to six are fine-tuned using the single-turn QA form training set. The ChatGPT model predicts the classification
result in a zero-shot setting.
ModelSentiment Classification Warning Type
Accuracy Weighted F1 Accuracy Weighted F1
1 Longformer 67.45 66.61 54.80 53.76
2 BLOOMZ 75.52 74.97 66.27 66.29
3 Chinese LLaMA 68.67 67.43 55.98 53.63
4 Chinese LLaMA Plus 75.99 75.59 67.09 67.13
5 ChatGLM(P-tuning v2) 69.48 68.44 52.13 50.75
6 ChatGLM 74.76 73.53 65.78 64.08
7 ChatGPT 46.80 47.43 18.17 18.30
Table 3: Experimental results of models fine-tuned with multi-turn QA form data.
ModelSentiment Classification Warning Type
Accuracy Weighted F1 Accuracy Weighted F1
1 BLOOMZ 70.14 72.04 61.69 61.80
2 Chinese LLaMA Plus 71.30 73.42 60.05 61.75
3 ChatGLM 69.56 70.08 59.40 58.69
5.3 Training Details
The models are implemented in PyTorch using the Hugging-
face Transformers package. It should be noted that, in ad-
dition to the Longformer model, we choose a version with
parameters of about 7B for the open-source large languge
models, and there are all links to the original model weight
in the footnote345. The maximum context length is set to
4,096. The models are trained with the AdamW optimizer,
using a batch size of 32 and 3 epochs. The learning rate is
set to 2e-5, and weight decay is set to 0. We use technolo-
gies such as DeepSpeed ZeRO [Rajbhandari et al. , 2020 ]and
FSDP [Zhao et al. , 2023 ]to optimize the parallel training of
models. We assess ChatGPT abilities in a zero-shot man-
ner using our dataset. Figure 3 shows the illustration of the
prompt template used in our experiments for ChatGPT. For
the Longformer model, two fully connected layers are con-
nected to perform the classification, and the loss function is
cross entropy.
5.4 Experimental Results
Table 2 and table 3 presents the experimental results on our
dataset. To fine-tune the large language models, we pre-
process the training set into two forms: single-turn QA and
multi-turn QA. The input will consist of task instructions,
context, and questions. A single-turn answer should incorpo-
rate the polarities and warning type of all companies at once.
In the multi-turn QA form, the polarities or warning type of a
company are addressed one at a a round of dialogue until all
the results are covered.
3https://github.com/ymcui/Chinese-LLaMA-Alpaca
4https://github.com/THUDM/ChatGLM-6B
5https://huggingface.co/bigscience/bloomz-7b1-mtAs shown in table 2, the Longformer model is fine-tuned
using the original training set. The models in lines two to
six are fine-tuned using the single-turn QA form training set.
The ChatGPT model predicts the classification result using
a prompt-based method in a zero-shot setting. The table re-
veals that Chinese LLaMA Plus outperforms other models in
the dataset. The experimental results demonstrate that lever-
aging a substantial Chinese corpus for secondary pre-training
significantly enhances LLaMA’s Chinese understanding and
generation capabilities. In the sentiment classification task,
Chinese LLaMA Plus achieves the highest accuracy of 75.99,
followed by BLOOMZ with 75.52 and ChatGLM with 74.46.
Another warning type classification task exhibits a similar
performance gap among all models.
It is worth noting that ChatGPT struggles with the finan-
cial sentiment analysis task in the zero-shot setting. This re-
sult suggests that ChatGPT is not proficient in understand-
ing financial concepts. Evidently, ChatGPT faces challenges
in connecting statements to human sentiment in financial
news, possibly due to a lack of domain knowledge. Un-
like other tasks, where a model can retrieve information from
the context and link operations to achieve the final output,
the sentiment analysis task demands a deeper understand-
ing of domain-specific expressions and underlying sentiment
knowledge. Such a level of understanding presents a chal-
lenge for models like ChatGPT, which may have limited ex-
posure to the domain-specific training corpus. The LLMs
achieve superior performance compared to the Longformer
model after fine-tuning, demonstrating the capability of gen-
eral generative language models to transfer effectively to
specific domains. Moreover, while efficient parameter fine-
tuning methods like P-tuning v2 decrease video memory us-
age, our experiments indicate a significant reduction in the

--- PAGE 6 ---
model’s accuracy.
In the multi-turn QA form dataset, we adopt a turn-based
approach. After each turn, we gather the answer generated
by the models, append it to the previous question, and utilize
this combined input as the prompt for the subsequent round.
The results, as presented in Table 3, indicate that convert-
ing single-turn instruction data into a multi-turn QA format
and subsequently fine-tuning LLMs may not be beneficial for
performance improvement. Through a thorough check of the
experimental results, we discovered that training the model
with multi-round dialogues increases the likelihood of gener-
ating repetitive and erroneous content during the inference
phase. One possibility is that fine-tuning models through
conversation-based approaches is more appropriate for data
that closely resembles real dialogues. In contrast, the trans-
formation of multi-round dialogue data using templates re-
sults in a relatively simplistic and less diverse format. We
leave it as future work to collect more real financial dialogue
data and evaluate more financial tasks.
6 Conclusion and Future Work
Our new dataset, FinChina SA, will serve as one of the main
directions for the next research focus – how to apply LLMs
in the financial domain. We experimented with various large
pre-trained language models and found that fine-tuned LLMs
perform impressively in sentiment analysis tasks, surpassing
the performance of the fine-tuned Longformer model. How-
ever, ChatGPT exhibits limitations in this task, which needs
handling domain-specific knowledge and terminology. While
ChatGPT performs well in generic NLP tasks, its effective-
ness in the financial domain is not comparable to that of spe-
cialized models fine-tuned specifically for financial tasks. In
conclusion, ChatGPT provides a solid foundation for NLP
tasks related to finance. However, further improvements can
enhance its performance. In addition, transforming single-
turn instruction data into multi-turn QA form and then fine-
tuning LLMs may be unhelpful to improve the performance.
Efficient parameter fine-tuning methods, such as P-tuning v2,
reduce memory consumption, but in our experiments signifi-
cantly reduce the accuracy of the model.
Due to cost constraints of ChatGPT API and training
LLMs, we have only tested open-source LLMs with about 7B
parameters on relatively small data, and we do not conduct
extensive experiments on complex prompt engineering for
ChatGPT. We believe our experiments can provide valuable
insights into the task of sentiment analysis over real-world
specific domains and facilitate further improvements. Mean-
while, we do not exclude the possibility that there could be
better performances for prompting-based methods if applying
advanced prompt engineering or GPT-4, which is costlier. We
leave this for future work. We plan to try more open-source
LLMs with larger parameters and release a larger financial
domain dataset in the future.
References
[Beltagy et al. , 2020 ]Iz Beltagy, Matthew E. Peters, and Ar-
man Cohan. Longformer: The long-document trans-
former. arXiv:2004.05150 , 2020.[Brown et al. , 2020 ]Tom Brown, Benjamin Mann, Nick Ry-
der, Melanie Subbiah, Jared D Kaplan, Prafulla Dhari-
wal, Arvind Neelakantan, Pranav Shyam, Girish Sastry,
Amanda Askell, et al. Language models are few-shot
learners. Advances in neural information processing sys-
tems, 33:1877–1901, 2020.
[Chen et al. , 2023 ]Zhihong Chen, Feng Jiang, Junying
Chen, Tiannan Wang, Fei Yu, Guiming Chen, Hongbo
Zhang, Juhao Liang, Chen Zhang, Zhiyi Zhang, et al.
Phoenix: Democratizing chatgpt across languages. arXiv
preprint arXiv:2304.10453 , 2023.
[Chiang et al. , 2023 ]Wei-Lin Chiang, Zhuohan Li, Zi Lin,
Ying Sheng, Zhanghao Wu, Hao Zhang, Lianmin Zheng,
Siyuan Zhuang, Yonghao Zhuang, Joseph E. Gonzalez,
Ion Stoica, and Eric P. Xing. Vicuna: An open-source chat-
bot impressing gpt-4 with 90%* chatgpt quality, March
2023.
[Cortis et al. , 2017 ]Keith Cortis, Andr ´e Freitas, Tobias
Daudert, Manuela Huerlimann, Manel Zarrouk, Siegfried
Handschuh, and Brian Davis. Semeval-2017 task 5: Fine-
grained sentiment analysis on financial microblogs and
news. In Proceedings of the 11th international workshop
on semantic evaluation (SemEval-2017) , pages 519–535,
2017.
[Cuiet al. , 2023 ]Yiming Cui, Ziqing Yang, and Xin Yao.
Efficient and effective text encoding for chinese llama and
alpaca. arXiv preprint arXiv:2304.08177 , 2023.
[Devlin et al. , 2018 ]Jacob Devlin, Ming-Wei Chang, Ken-
ton Lee, and Kristina Toutanova. Bert: Pre-training of
deep bidirectional transformers for language understand-
ing.arXiv preprint arXiv:1810.04805 , 2018.
[Doet al. , 2019 ]Hai Ha Do, Penatiyana WC Prasad, Ange-
lika Maag, and Abeer Alsadoon. Deep learning for aspect-
based sentiment analysis: a comparative review. Expert
systems with applications , 118:272–299, 2019.
[Duet al. , 2022 ]Zhengxiao Du, Yujie Qian, Xiao Liu, Ming
Ding, Jiezhong Qiu, Zhilin Yang, and Jie Tang. Glm: Gen-
eral language model pretraining with autoregressive blank
infilling. In Proceedings of the 60th Annual Meeting of
the Association for Computational Linguistics (Volume 1:
Long Papers) , pages 320–335, 2022.
[Liet al. , 2023 ]Xianzhi Li, Xiaodan Zhu, Zhiqiang Ma, Xi-
aomo Liu, and Sameena Shah. Are chatgpt and gpt-4
general-purpose solvers for financial text analytics? an
examination on several typical tasks. arXiv preprint
arXiv:2305.05862 , 2023.
[Maia et al. , 2018 ]Macedo Maia, Siegfried Handschuh,
Andr ´e Freitas, Brian Davis, Ross McDermott, Manel
Zarrouk, and Alexandra Balahur. Www’18 open chal-
lenge: financial opinion mining and question answer-
ing. In Companion proceedings of the the web conference
2018 , pages 1941–1942, 2018.
[Muennighoff et al. , 2022 ]Niklas Muennighoff, Thomas
Wang, Lintang Sutawika, Adam Roberts, Stella Bider-
man, Teven Le Scao, M Saiful Bari, Sheng Shen, Zheng-

--- PAGE 7 ---
Xin Yong, Hailey Schoelkopf, et al. Crosslingual gen-
eralization through multitask finetuning. arXiv preprint
arXiv:2211.01786 , 2022.
[Ouyang et al. , 2022 ]Long Ouyang, Jeffrey Wu, Xu Jiang,
Diogo Almeida, Carroll Wainwright, Pamela Mishkin,
Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex
Ray, et al. Training language models to follow instruc-
tions with human feedback. Advances in Neural Informa-
tion Processing Systems , 35:27730–27744, 2022.
[Pang et al. , 2008 ]Bo Pang, Lillian Lee, et al. Opinion min-
ing and sentiment analysis. Foundations and Trends® in
information retrieval , 2(1–2):1–135, 2008.
[Radford et al. , 2018 ]Alec Radford, Karthik Narasimhan,
Tim Salimans, Ilya Sutskever, et al. Improving language
understanding by generative pre-training. 2018.
[Radford et al. , 2019 ]Alec Radford, Jeffrey Wu, Rewon
Child, David Luan, Dario Amodei, Ilya Sutskever, et al.
Language models are unsupervised multitask learners.
OpenAI blog , 1(8):9, 2019.
[Raffel et al. , 2020 ]Colin Raffel, Noam Shazeer, Adam
Roberts, Katherine Lee, Sharan Narang, Michael Matena,
Yanqi Zhou, Wei Li, and Peter J Liu. Exploring the limits
of transfer learning with a unified text-to-text transformer.
The Journal of Machine Learning Research , 21(1):5485–
5551, 2020.
[Rajbhandari et al. , 2020 ]Samyam Rajbhandari, Jeff Rasley,
Olatunji Ruwase, and Yuxiong He. Zero: Memory op-
timizations toward training trillion parameter models. In
SC20: International Conference for High Performance
Computing, Networking, Storage and Analysis , pages 1–
16. IEEE, 2020.
[Scao et al. , 2022 ]Teven Le Scao, Angela Fan, Christo-
pher Akiki, Ellie Pavlick, Suzana Ili ´c, Daniel Hesslow,
Roman Castagn ´e, Alexandra Sasha Luccioni, Franc ¸ois
Yvon, Matthias Gall ´e, et al. Bloom: A 176b-parameter
open-access multilingual language model. arXiv preprint
arXiv:2211.05100 , 2022.
[Taori et al. , 2023 ]Rohan Taori, Ishaan Gulrajani, Tianyi
Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy
Liang, and Tatsunori B. Hashimoto. Stanford alpaca:
An instruction-following llama model. https://github.com/
tatsu-lab/stanford alpaca, 2023.
[Touvron et al. , 2023 ]Hugo Touvron, Thibaut Lavril, Gau-
tier Izacard, Xavier Martinet, Marie-Anne Lachaux, Tim-
oth´ee Lacroix, Baptiste Rozi `ere, Naman Goyal, Eric Ham-
bro, Faisal Azhar, et al. Llama: Open and efficient founda-
tion language models. arXiv preprint arXiv:2302.13971 ,
2023.
[Vaswani et al. , 2017 ]Ashish Vaswani, Noam Shazeer, Niki
Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez,
Łukasz Kaiser, and Illia Polosukhin. Attention is all you
need. Advances in neural information processing systems ,
30, 2017.
[Wang et al. , 2022 ]Yizhong Wang, Yeganeh Kordi, Swa-
roop Mishra, Alisa Liu, Noah A Smith, Daniel Khashabi,and Hannaneh Hajishirzi. Self-instruct: Aligning language
model with self generated instructions. arXiv preprint
arXiv:2212.10560 , 2022.
[Weiet al. , 2021 ]Jason Wei, Maarten Bosma, Vincent Y
Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan
Du, Andrew M Dai, and Quoc V Le. Finetuned lan-
guage models are zero-shot learners. arXiv preprint
arXiv:2109.01652 , 2021.
[Wuet al. , 2023 ]Shijie Wu, Ozan Irsoy, Steven Lu, Vadim
Dabravolski, Mark Dredze, Sebastian Gehrmann, Prab-
hanjan Kambadur, David Rosenberg, and Gideon Mann.
Bloomberggpt: A large language model for finance. arXiv
preprint arXiv:2303.17564 , 2023.
[Yang et al. , 2023 ]Hongyang Yang, Xiao-Yang Liu, and
Christina Dan Wang. Fingpt: Open-source financial large
language models. arXiv preprint arXiv:2306.06031 , 2023.
[Zeng et al. , 2022 ]Aohan Zeng, Xiao Liu, Zhengxiao Du,
Zihan Wang, Hanyu Lai, Ming Ding, Zhuoyi Yang, Yi-
fan Xu, Wendi Zheng, Xiao Xia, et al. Glm-130b:
An open bilingual pre-trained model. arXiv preprint
arXiv:2210.02414 , 2022.
[Zhao et al. , 2023 ]Yanli Zhao, Andrew Gu, Rohan Varma,
Liang Luo, Chien-Chin Huang, Min Xu, Less Wright,
Hamid Shojanazeri, Myle Ott, Sam Shleifer, et al. Pytorch
fsdp: Experiences on scaling fully sharded data parallel.
arXiv preprint arXiv:2304.11277 , 2023.

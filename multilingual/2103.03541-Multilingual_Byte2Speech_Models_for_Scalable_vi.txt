Mô hình Byte2Speech đa ngôn ngữ cho tổng hợp giọng nói có thể mở rộng với tài nguyên thấp

Mutian He1, Jingzhou Yang2, Lei He2, Frank K. Soong2
1Đại học Khoa học và Công nghệ Hong Kong
2Microsoft Trung Quốc

Tóm tắt
Để mở rộng tổng hợp giọng nói thần kinh cho các ngôn ngữ thực tế khác nhau, chúng tôi trình bày một khung đầu-cuối đa ngôn ngữ ánh xạ đầu vào byte thành phổ âm, do đó cho phép các script đầu vào tùy ý. Bên cạnh kết quả mạnh mẽ trên hơn 40 ngôn ngữ, khung này thể hiện khả năng thích ứng với các ngôn ngữ mới trong các tình huống tài nguyên cực thấp và thậm chí few-shot chỉ với 40 giây ghi âm có phiên âm, mà không cần tài nguyên theo từng ngôn ngữ như từ điển, kho ngữ liệu phụ, mô hình phụ trợ, hoặc chuyên môn ngôn ngữ học, do đó đảm bảo khả năng mở rộng. Trong khi vẫn duy trì độ rõ ràng và tự nhiên thỏa đáng so sánh với các mô hình tài nguyên phong phú. Các nghiên cứu so sánh và loại bỏ đầy đủ được thực hiện để tiết lộ tiềm năng của khung cho các ngôn ngữ tài nguyên thấp. Hơn nữa, chúng tôi đề xuất một phương pháp mới để trích xuất các mạng con đặc trưng ngôn ngữ trong mô hình đa ngôn ngữ để hiểu rõ hơn cơ chế của nó.

1 Giới thiệu
Những năm gần đây chứng kiến thành công tuyệt vời của học sâu đầu-cuối. Đặc biệt đối với tổng hợp giọng nói (hoặc text-to-speech, TTS), các pipeline và đặc trưng thủ công được thay thế bằng các mô hình thần kinh đầu-cuối (Shen et al., 2018). Nhưng thành công như vậy dựa trên tài nguyên phong phú của dữ liệu chất lượng cao, và yêu cầu dữ liệu do đó đã trở thành nút thắt cổ chai của nghiên cứu và ứng dụng trên TTS thần kinh.

Nhiều nghiên cứu khác nhau đã được đề xuất cho vấn đề này. Tuy nhiên, hầu hết chúng đều yêu cầu tài nguyên phụ. Chẳng hạn, các mô hình đầu vào phoneme giảm độ phức tạp mô hình hóa và đạt hiệu suất tốt hơn (Yasuda et al., 2021), nhưng từ điển và/hoặc quy tắc grapheme-to-phoneme (G2P) của ngôn ngữ đích phải được cung cấp. Trong khi các phương pháp đầu vào ký tự yêu cầu kiến thức về script để xác định đầu vào mô hình trên các script không alphabetic như Indic và Trung Quốc. Một số phương pháp tận dụng kiến thức phonology để giảm yêu cầu dữ liệu (Cai et al., 2020; Chen et al., 2019; Demirsahin et al., 2018), do đó chuyên môn ngôn ngữ học về đích là thiết yếu. Bên cạnh đó, một chuỗi giọng nói của tổng hợp và nhận dạng đóng vai trò quan trọng trong TTS tài nguyên thấp bởi Ren et al. (2019) và Xu et al. (2020), điều này dựa trên kho ngữ liệu ghép đôi lớn bổ sung để huấn luyện một bộ nhận dạng. Kết luận, tất cả các phương pháp như vậy đều phụ thuộc vào tài nguyên phụ: dữ liệu, kiến thức, hoặc nỗ lực của nhà phát triển cho từng ngôn ngữ đích.

Thường tốn kém để chuẩn bị tài nguyên và xây dựng một hệ thống phức tạp trên một ngôn ngữ, chưa nói đến việc lặp lại điều này trên hàng ngàn ngôn ngữ trên thế giới. Do đó, chúng tôi đề xuất một tác vụ mới tập trung vào khả năng mở rộng: Chúng ta phải kiềm chế không sử dụng tài nguyên phụ theo từng ngôn ngữ. Các nhà phát triển không nên đặt nỗ lực vào bất kỳ ngôn ngữ nào, mà dựa vào dữ liệu TTS ghép đôi thường có thể được thu thập trong một quy trình tiêu chuẩn hóa.

Đối với thách thức như vậy, chúng tôi nhấn mạnh học chuyển giao từ các ngôn ngữ tài nguyên phong phú. Hiệu suất của các ngôn ngữ tài nguyên thấp được cải thiện trong một mô hình đa ngôn ngữ trên một nhóm ngôn ngữ (Li and Zen, 2016; Demirsahin et al., 2018; de Korte et al., 2020; Yang and He, 2020). Mặc dù sự đa dạng to lớn của các ngôn ngữ, các hệ thống viết giống nhau hoặc tương tự, quy tắc G2P, kho phoneme, hoặc ít nhất mẫu để học ánh xạ tuần tự trong TTS có thể được tận dụng cho học chuyển giao. Đặc biệt, chúng tôi mở rộng phương pháp của Li et al. (2019a). Bằng cách tận dụng mã hóa văn bản hiện có của UTF-8, các script tùy ý được bao phủ bởi Unicode được hỗ trợ mà không cần chúng ta nghiên cứu từng hệ thống viết. Chúng tôi xây dựng một transformer đa ngôn ngữ đa người nói mạnh mẽ trên kho ngữ liệu 900 giờ của 43 ngôn ngữ bởi 109 người nói được viết trong các script khác nhau. Sử dụng chiến lược tiến bộ theo tầng và cân bằng ngôn ngữ, mô hình như vậy học cách tạo ra giọng nói đúng và tự nhiên tương tự như các phương pháp dựa trên phoneme.

Chúng tôi sau đó đánh giá khả năng thích ứng của nó với các ngôn ngữ đích tài nguyên thấp được chọn trên cơ sở ngôn ngữ học. Thông qua chiến lược đồng huấn luyện, nó có thể học một ngôn ngữ hoàn toàn mới như Romanian và Greek trong chế độ few-shot của 10 mẫu hoặc dưới 1 phút âm thanh, và đạt hiệu suất topline với dữ liệu ít hơn nhiều. Bằng cách này, các ngôn ngữ bị thiệt thòi hơn, có nguy cơ tuyệt chủng hoặc ít được đại diện có thể hưởng lợi từ TTS thần kinh. Ngoài ra, chúng tôi điều tra đóng góp của các yếu tố khác nhau trong khung của chúng tôi bằng các nghiên cứu thực nghiệm đầy đủ. Hơn nữa, để hiểu rõ hơn cơ chế của mô hình, chúng tôi đề xuất một cách tiếp cận mới để diễn giải mô hình đa ngôn ngữ bằng cách tỉa tách đặc trưng ngôn ngữ và cho thấy rằng một mô hình đa ngôn ngữ có thể được xem như sự kết hợp của các mô hình đơn ngôn ngữ chia sẻ một phần tham số giữa chúng, điều này nổi lên từ huấn luyện. Để tạo điều kiện tái tạo, chúng tôi trình bày một pipeline dựa trên tài nguyên mở.

Kết luận, đóng góp của bài báo là ba khía cạnh:
• Chúng tôi xây dựng khung Byte2Speech đa ngôn ngữ cho tác vụ TTS tập trung vào khả năng mở rộng. Với các chiến lược huấn luyện được thiết kế tốt, nó khớp hiệu suất của các mô hình phoneme trên nhiều ngôn ngữ.
• Chúng tôi điều tra khả năng tài nguyên thấp của nó để thích ứng với các ngôn ngữ mới trong few shots và đạt kết quả tương tự như các mô hình cơ sở sử dụng dữ liệu giảm một bậc magnitude.
• Chúng tôi làm sâu sắc hiểu biết về cơ chế mô hình đa ngôn ngữ bằng một diễn giải mới.

2 Phương pháp

2.1 Khung
Chúng tôi áp dụng khung TTS transformer đa ngôn ngữ và đa người nói trong Yang and He (2020) và mở rộng nó cho đầu vào byte. Cụ thể, chúng tôi huấn luyện một transformer 12 tầng để dự đoán mel-spectrograms, với các embedding ngôn ngữ và người nói được nối bởi đầu ra encoder, trong khi chúng tôi không tìm thấy cải thiện nếu chúng tôi cung cấp ID ngôn ngữ cho đầu vào. Văn bản đầu vào được mã hóa trong UTF-8, mỗi byte như một token, và đưa vào mô hình cùng với [BOS] và [EOS], vì vậy kích thước từ vựng 256 ngoại trừ các token đặc biệt như [BOS]. Do đó, trong đầu vào của chúng tôi, một ký tự có thể được đại diện trong một hoặc nhiều token. Chúng tôi trực tiếp sử dụng văn bản được mã hóa để huấn luyện, chỉ với xử lý cơ bản như chuyển đổi dựa trên quy tắc của các chữ số và phân đoạn từ tiếng Trung. Bên cạnh đó, các ký tự Unicode với các phần tách biệt thường có thể được đại diện theo nhiều cách. Chẳng hạn, mỗi ký tự Hàn Quốc được soạn trước đại diện cho một âm tiết, nhưng nó tương đương với việc ghi lại nó bằng một loạt Jamo (chữ cái). Các trường hợp tương tự bao gồm ligatures và chữ cái với dấu phụ. Mặc dù việc sử dụng các token không được soạn trước tiết lộ nhiều hơn về một ký tự, theo nguyên tắc của chúng tôi về việc sử dụng kiến thức đặc trưng ngôn ngữ tối thiểu, chúng tôi không áp dụng bất kỳ chuẩn hóa nào trên các ký tự và cho phép các ký tự được soạn trước có mặt trong dữ liệu như vậy.

2.2 Kho ngữ liệu huấn luyện
Chúng tôi sử dụng 43 ngôn ngữ làm ngôn ngữ nguồn, với 32 ngôn ngữ riêng biệt trong ISO-639-1, cộng với các biến thể khu vực của chúng. Kho ngữ liệu do đó bao phủ phần lớn các script và phoneme của con người. Đặc biệt, bên cạnh bảng chữ cái Latin, cũng có bảng chữ cái Cyrillic, chữ Hán, script âm tiết (như Hàn Quốc), abugida (như Hindi), và abjad (như tiếng Ả Rập). Với sự đa dạng như vậy, mối quan hệ giữa văn bản và giọng nói rất khác nhau. Các ngôn ngữ như tiếng Tây Ban Nha sử dụng chính tả phonemic, trong khi G2P tiếng Anh xa từ thông thường. Bảng chữ cái ghi lại tất cả phoneme, trong khi abjad thường bỏ qua nguyên âm. Logogram Trung Quốc không ghi lại cách phát âm, và trong tiếng Nhật, một chữ Hán có thể có 10 cách đọc khác nhau. Làm cho tệ hơn, như trong thế giới thực, tài nguyên ngôn ngữ rất mất cân bằng.

Chúng tôi chia các ngôn ngữ thành ba tầng theo số lượng mẫu. Như thể hiện trong Hình 1, các ngôn ngữ T1 như tiếng Anh (US) sở hữu số lượng mẫu và người nói không cân xứng, trong khi chỉ <10k mẫu có sẵn cho mỗi ngôn ngữ T3. Do đó, mặc dù có kho ngữ liệu lớn, việc có được một mô hình nguồn đa ngôn ngữ vẫn đầy thách thức.

2.3 Các đích thích ứng
Để tiết lộ tốt nhất khả năng thích ứng, chúng tôi kiểm tra sự tương tự ngôn ngữ học giữa mỗi đích thích ứng và mỗi tầng của các ngôn ngữ nguồn, bao gồm các khía cạnh của hệ thống viết, phát âm hoặc quy tắc G2P, từ điển, và đặc điểm ngữ âm. Dựa trên điều này, chúng tôi chọn năm đích cụ thể:

• Tiếng Anh Ấn Độ (en-in), điều này, đối với dữ liệu của chúng tôi, chủ yếu có thể hiểu lẫn nhau với các biến thể tiếng Anh khác về văn viết, G2P, từ điển, và kho phoneme. Tuy nhiên, có nhiều thay đổi ngữ âm, chẳng hạn như phát âm "th" trong "then" như plosive dental hữu thanh tương tự /d/.

• Romanian (ro-ro), sử dụng bảng chữ cái Latin với năm chữ cái phụ, và có chính tả gần-phonemic mà G2P chủ yếu một-một. Script, G2P, từ điển, và kho phoneme gần với các ngôn ngữ Romance khác như tiếng Ý và Pháp trong T1, do đó cho phép chuyển giao hiệu quả.

• Greek (el-gr), sử dụng bảng chữ cái Greek không thấy trong nguồn, do đó mô hình cần học bảng chữ cái mới với mỗi chữ cái trong hai byte. Chính tả Greek có độ sâu trung gian với quan hệ một-N từ phoneme đến chữ cái, nhưng G2P chủ yếu thông thường sử dụng quy tắc tương tự như các bảng chữ cái khác. Ngoài ra, có các liên kết từ vựng và ngữ âm với các ngôn ngữ châu Âu khác, tạo cơ hội chuyển giao.

• Thai (th-th), được viết trong abugida 3-byte không thấy trong nguồn. Abugida, không giống như bảng chữ cái, đầu tiên ghi một âm tiết và sau đó sửa đổi nguyên âm của nó bằng dấu phụ. Chỉ trong T3 mới có các ngôn ngữ Indic sử dụng abugida, nhưng với các mã hóa khác nhau. Hơn nữa, tiếng Thái có thanh điệu, sử dụng G2P ít phonemic hơn với nhiều bất thường phong phú, và không có ngôn ngữ nguồn đặc biệt tương tự. Tất cả những điều này cản trở sự thích ứng.

• Tiếng Trung Quan Thoại (zh-cn) là ngôn ngữ có thanh điệu được viết bằng logogram Trung Quốc giản thể 3-byte, do đó mô hình dựa trên byte phải ghi nhớ cách đọc của mỗi ký tự. Mặc dù một số ký tự chồng chéo với tiếng Nhật trong T1 và tiếng Quảng Đông trong T2 (bằng tiếng Trung truyền thống), các dạng nói rất khác nhau một cách hệ thống. Do đó nó đặc biệt thách thức và sự giúp đỡ của các ngôn ngữ nguồn có thể nghi ngờ.

Bên cạnh đó, chúng tôi phân tích kho phoneme liên quan. Kho ngữ liệu huấn luyện bao phủ tất cả phoneme được sử dụng trong các ngôn ngữ đích từ T2, cho thấy khả năng của mô hình nguồn để phát âm các đích. Do đó chìa khóa cho sự thích ứng là học cách xử lý script đầu vào và quy tắc phát âm. Trong khi đối với các tầng thấp hơn như T1, có một phoneme từ ro-ro vắng mặt, một từ el-gr, hai từ th-th, và bốn từ zh-cn. Những phoneme hiếm trong các ngôn ngữ nguồn thêm vào khó khăn. Kết luận, từ en-in đến th-th/zh-cn, nhiệm vụ trở nên thách thức hơn và các ngôn ngữ nguồn tương tự chỉ có mặt trong các tầng cao hơn.

2.4 Chiến lược huấn luyện
Transformer TTS gặp khó khăn trong huấn luyện không ổn định, thường yêu cầu các thủ thuật như ràng buộc alignment (Chen et al., 2020). Đầu vào byte và đa ngôn ngữ thêm vào độ phức tạp, làm cho huấn luyện tiến bộ theo tầng của chúng tôi trở nên thiết yếu: Chúng tôi khởi tạo tất cả mô hình bằng cách huấn luyện trên các mẫu en-us ngắn được chọn trong 30k bước. Bắt đầu từ đó, dữ liệu T1 được thêm vào, và sau đó dữ liệu T2 ở tổng 350k bước, và T3 ở 650k. Các ngôn ngữ được cân bằng theo cấp số nhân: Đối với ngôn ngữ i với Ni mẫu, chúng tôi tính toán

ci = Ni / ∑j Nj
pi = ci^α / ∑j cj^α

Trong quá trình huấn luyện, trước tiên chúng tôi lấy mẫu một ngôn ngữ i với xác suất pi sử dụng α = 0.2, và sau đó một ví dụ huấn luyện từ nó (Yang and He, 2020). Để cải thiện hiệu quả, chúng tôi sử dụng 4 GPU với batching động (Li et al., 2019b). Các cài đặt huấn luyện thay thế dẫn đến hiệu suất dưới tối ưu trong thí nghiệm.

Về thích ứng tài nguyên thấp, chúng tôi khám phá rằng việc chỉ huấn luyện bằng đích dẫn đến overfitting, và các ngôn ngữ nguồn phong phú có thể phục vụ như regularization. Do đó, chúng tôi áp dụng chiến lược đa tác vụ hoặc đồng huấn luyện. Thay vì tinh chỉnh một mô hình được tiền huấn luyện tốt, chúng tôi thêm ngôn ngữ đích với pi = 0.25 để huấn luyện với hỗn hợp nguồn và đích. Để xác định tác động của các ngôn ngữ nguồn, chúng tôi cố gắng thực hiện thích ứng sau mỗi chuyển đổi tầng cộng với việc chỉ sử dụng en-us, tức là đồng huấn luyện với en-us từ 30k bước, T1 từ 350k, được thêm bởi T2 từ 500k, và T3 từ 700k. Phân rã tốc độ học theo cấp số nhân được áp dụng trong khoảng 850k bước, với bộ đếm bước được đặt lại tại thích ứng và chuyển đổi tầng.

2.5 Các chỉ số đánh giá
Đối với mỗi ngôn ngữ, chúng tôi tạo mel-spectrograms trên một tập held-out gồm 100 mẫu (utterances), so sánh với mel từ recordings. Waveforms được tạo bởi Griffin-Lim được gửi đến Azure Speech-To-Text để có tỷ lệ lỗi ký tự (CER) như một chỉ số intelligibility quy mô lớn. Ngoài ra, chúng tôi đánh giá chất lượng bằng mean square error (MSE) với mel ground truth, cả sau khi thu gọn các phần không có âm và dynamic time warping sử dụng FastDTW (Salvador and Chan, 2007). Bên cạnh đó, chúng tôi thu thập một tập phụ của các script tin tức có nhiều hơn (≈1000) mẫu mỗi ngôn ngữ với các câu dài hơn và phức tạp hơn. Chúng tôi tính CER trên các script này để xây dựng chỉ số CER-Ex. Chúng tôi thêm thực hiện các bài test chủ quan trên các mô hình được chọn. Đối với intelligibility, chúng tôi mời năm judge mỗi mẫu để chú thích lỗi từ trên âm thanh từ tập held-out 100 mẫu. Đối với mean opinion score (MOS), chúng tôi mời 20 judge mỗi mẫu trên tập đánh giá 20 mẫu được chọn từ tập held-out, trên đó không có mô hình nào có mispronunciations, để so sánh tự nhiên tốt nhất. Chúng tôi sử dụng WaveNet được tiền huấn luyện để tạo waveform cho các bài test chủ quan. Kết quả cũng được so sánh với các mô hình đa ngôn ngữ dựa trên phoneme bởi Yang and He (2020) được huấn luyện trên cùng dataset như một topline.

3 Thí nghiệm

3.1 Các ngôn ngữ nguồn
Chúng tôi đầu tiên thể hiện intelligibility bằng CER như trong Bảng 1. Mô hình Byte (T3) đạt CER tương đương với mô hình dựa trên phoneme trên các ngôn ngữ sử dụng script ngữ âm, bao gồm en-us từ T1, tiếng Đức (de-de) từ T2, và Telugu (te-in) từ T3. Những kết quả này cho thấy rằng một mô hình dựa trên byte tinh vi đủ để học các script ngữ âm khác nhau cùng lúc, và thậm chí có thể tạo ra ít lỗi hơn so với mô hình dựa trên phoneme, có thể nhờ vào chiến lược huấn luyện và chia sẻ biểu diễn của chúng tôi của các token đầu vào. Điều này cũng áp dụng cho Telugu với ít dữ liệu hơn và một abugida độc đáo. Về logographic Cantonese (zh-hk), CER đều cao do homophones phong phú, nhưng khoảng cách giữa các mô hình bị giới hạn, cho thấy rằng mô hình byte có thể ghi nhớ và tái tạo cách phát âm của hàng ngàn chữ Hán được rải rác trong dữ liệu. Do đó, mô hình Byte2Speech của chúng tôi có thể đạt intelligibility cạnh tranh trên các ngôn ngữ tài nguyên phong phú mà không cần kiến thức G2P trước.

3.2 Thích ứng
Chúng tôi thực hiện thích ứng trên các đích với các tập con được lấy mẫu ngẫu nhiên của các kích thước khác nhau, được đồng huấn luyện từ các nguồn khác nhau, và so sánh chúng với các mô hình đơn ngôn ngữ và CER mel ghi âm. Kết quả Romanian trong Hình 2 là đại diện nhất: như thể hiện bởi đường cong T3, chỉ với 10 mẫu hoặc 39s recordings, mô hình có được ngôn ngữ Romanian hoàn toàn mới với intelligibility cao 2.3% CER, vào chế độ few-shot learning. Bên cạnh đó, với 1k mẫu, các mô hình thích ứng đạt CER gần ground truth và mô hình đơn ngôn ngữ full-data (>7k mẫu), tốt hơn 30% so với mô hình đơn ngôn ngữ 1k-mẫu. Nhờ chiến lược đồng huấn luyện, điều này thậm chí áp dụng cho thích ứng từ en-us trên 1k mẫu. Nhưng với ít dữ liệu hơn, đa ngôn ngữ trở nên thiết yếu: Với các tầng cao hơn hoặc nhiều ngôn ngữ nguồn hơn, tất cả các chỉ số đều được cải thiện liên tục, đặc biệt với <300 mẫu.

Đáng chú ý hơn, thậm chí đối với bảng chữ cái hoàn toàn mới của Greek, mô hình học hầu hết cách phát âm với 10 mẫu; và nó dễ dàng đạt CER 2.1%, gần ground truth và mô hình full-data, sử dụng 30 mẫu. Bên cạnh đó, trên Greek, mô hình có thể tạo ra mel gần ground truth sử dụng ít dữ liệu hơn nhiều, như chỉ ra bởi MSE trong Hình 3. Kho ngữ liệu nguồn đa dạng chứng minh quan trọng khi các mô hình en-us và T1 không tạo ra bất kỳ giọng nói intelligible nào khi kích thước dữ liệu giảm xuống 200 hoặc 100, tương ứng.

Tiếng Anh Ấn Độ đơn giản hơn và gần với một phương ngữ tiếng Anh, vì vậy tất cả mô hình đạt CER thấp thậm chí với few shots, và sự khác biệt giữa T1/T2/T3 bị giới hạn. Tuy nhiên, khoảng cách CER giữa en-us và T1 vẫn cho thấy tác động của đa ngôn ngữ. Hơn nữa, như thể hiện trong Hình 3, được tìm thấy trong tất cả ngôn ngữ nhưng đáng chú ý nhất trong en-in rằng với tầng cao hơn, các mô hình thích ứng có CER-Ex tốt hơn, thường vượt quá các mô hình full-data (9k). Trên các văn bản phức tạp trong tập test CER-Ex, các mô hình đơn ngôn ngữ thường tạo ra mispronunciations và misalignments. Nhờ thích ứng từ kho ngữ liệu nguồn phong phú với các script đa dạng hơn, mô hình thích ứng có thể tổng quát hóa tốt hơn cho những đầu vào khó khăn đó.

Nhiệm vụ khó khăn hơn đối với tiếng Thái và tiếng Trung Quan Thoại với các script ít phonemic hơn. 100 mẫu tiếng Thái được yêu cầu để đạt 17% CER, và 1k mẫu (71.4 phút) để khớp với ground truth CER của 2.3%. Tiếng Trung Quan Thoại khó khăn nhất, nhưng thích ứng 2k-mẫu vẫn đạt 9.2% CER. Mặc dù có vẻ khó khăn để có được tiếng Thái hoặc tiếng Trung Quan Thoại trong few shots, thích ứng đa ngôn ngữ vẫn hiệu quả, và MSE và CER của mô hình đơn ngôn ngữ 2k-mẫu đạt được sử dụng 10% hoặc 15% dữ liệu trên th-th và zh-cn tương ứng. Kết luận, mặc dù không đủ cho few-shot learning trên các ngôn ngữ này, cách tiếp cận của chúng tôi vẫn mạnh mẽ.

Với tất cả những kết quả này, chúng tôi cho thấy rằng khả năng chung của tác vụ TTS có thể được thu được bởi một mô hình Byte2Speech đa ngôn ngữ duy nhất, và có thể dễ dàng được áp dụng cho ngôn ngữ mới với ít dữ liệu, tạo ra một người học ngôn ngữ nói few-shot. Kết quả hoàn chỉnh hơn được đưa ra trong Phụ lục Mục B.

3.3 Các nghiên cứu so sánh
Đa dạng hay Số lượng Bằng cách thêm các tầng phụ của nguồn, dữ liệu huấn luyện mở rộng. Chúng tôi đặt câu hỏi liệu điều này có quan trọng không. Do đó, chúng tôi thử nghiệm với dữ liệu được lấy mẫu xuống trong mỗi tầng: chúng tôi tạo T2-dataset với các ngôn ngữ T1 và T2 nhưng chỉ với kích thước của T1, và T3-dataset với các ngôn ngữ T2 và T3 nhưng của kích thước T2. Chúng tôi sử dụng T2- hoặc T3- như dataset nguồn, và sau đó thích ứng mô hình với Greek. Như thể hiện trong Hình 2, thích ứng T2- có hiệu suất gần T2 trong khi tốt hơn nhiều so với T1, và nó tương tự cho T3-. Do đó, đối với thích ứng, sự đa dạng của kho ngữ liệu nguồn vượt trội hơn số lượng dữ liệu.

Đa dạng hay Tương tự Theo trực giác, thích ứng với một đích có thể được hỗ trợ tốt nhất bởi một nguồn tương tự. Điều này cũng được hỗ trợ bởi thực tế rằng T2 (với zh-hk) giúp ích rất nhiều cho thích ứng zh-cn. Do đó, chúng tôi kiểm tra nó bằng cách đồng huấn luyện các đích chỉ sử dụng một nguồn liên quan chặt chẽ, tức là en-us cho en-in, và tiếng Ý (it-it) cho ro-ro. Như chỉ ra bởi các đường cong tương ứng trong Hình 2, chỉ với các nguồn tương tự, kết quả gần T1. Các trường hợp tương tự khi đồng huấn luyện zh-cn với zh-hk. Do đó, chìa khóa cho thích ứng không chỉ là tận dụng một ngôn ngữ tương tự mà là sự kết hợp của một tập hợp đa dạng các ngôn ngữ.

Tiến bộ hay Trực tiếp Huấn luyện tiến bộ theo tầng đóng vai trò quan trọng: chúng tôi thực hiện các thí nghiệm T3D sử dụng trực tiếp toàn bộ kho ngữ liệu. Kết quả, mô hình có hiệu suất nguồn tệ hơn và thất bại trên zh-hk. Hơn nữa, các mô hình nguồn T3D cho thấy thích ứng Greek kém hơn, như thể hiện trong Hình 4.

Khi nào và Làm thế nào Thích ứng Thay vì tinh chỉnh một mô hình cơ sở được huấn luyện tốt, chúng tôi bắt đầu thích ứng xa trước khi hội tụ trên các ngôn ngữ nguồn. Bắt đầu từ một mô hình bán chín muồi (như T2 500k bước hoặc T3 700k bước) có lợi: Như thể hiện trong kết quả T3 (650k) của Hình 4, việc trực tiếp thêm Greek vào T3 dẫn đến giảm hiệu suất. Trong khi một mạng chín muồi như T3 (800k) có thể mất tính linh hoạt và thất bại trên 10 mẫu. Điều này hiện tượng hơn trên T2, với khoảng cách CER tuyệt đối lên đến 29% giữa các thời điểm khác nhau để thích ứng. Do đó, một mạng bán chín muồi có lợi cho thích ứng trong cài đặt của chúng tôi. Bên cạnh đó, chúng tôi nhận thấy rằng ở chế độ few-shot, mô hình có xu hướng overfitting. Do đó, chúng tôi điều chỉnh tỷ lệ của đích bằng cách đặt pi = 0.1, thực thi regularization phụ từ các ngôn ngữ khác. Như thể hiện bởi các điểm T3 (0.1) cho ro-ro và el-gr trong Hình 2 và Hình 4, hiệu suất few-shot được cải thiện.

Chi tiết bổ sung và các hình đã bỏ qua về các nghiên cứu loại bỏ có sẵn tại Phụ lục Mục B.

3.4 Khả năng mở rộng cho chuyên môn ngôn ngữ
Mặc dù chúng tôi nhắm đến việc sử dụng tài nguyên đặc trưng ngôn ngữ tối thiểu, khung có thể được mở rộng. Chẳng hạn, xem xét rằng dưới chế độ few-shot một số quy tắc phát âm không bao giờ xuất hiện trong các mẫu, chúng tôi điều tra chính tả Greek và định nghĩa một tập tối thiểu gồm 41 graphemes để đại diện cho quy tắc G2P Greek. Chúng tôi sau đó tạo các tập huấn luyện pangram kích thước 10 hoặc 15 bao phủ tập đó. Như trong kết quả được ghi nhãn là Pan trong Hình 4, lợi ích đáng kể trên các trường hợp few-shot được thể hiện, đặc biệt trên các trường hợp 10-mẫu với giảm CER tương đối 19%. Kết hợp với pi = 0.1, mô hình Pan (0.1) đạt giảm 37%. Một cách tiếp cận khác là tăng cường đầu vào. Chúng tôi chuyển đổi văn bản zh-cn thành Pinyin Romanized. Như thể hiện trong Hình 4, zh-cn (Pinyin) có được hiệu suất tương tự như các script ngữ âm khác, với CER gần toplines và ground truth trong 100 mẫu. Nếu chúng tôi tiếp tục chuyển đổi script để mô phỏng Romanization của vi-vn (tiếng Việt) trong T3 để hỗ trợ chuyển giao kiến thức, mô hình VietP có được cải thiện phụ trên chế độ few-shot. Kết luận, khung linh hoạt để cải thiện trên một ngôn ngữ cụ thể nếu chúng ta biết thêm về nó. Xem Phụ lục Mục A để biết chi tiết.

3.5 Đánh giá chủ quan
Chúng tôi thực hiện các bài test chủ quan để đánh giá phương pháp của chúng tôi chính xác hơn. Về tự nhiên, kết quả mean opinion score (MOS) được đưa ra trong Bảng 2. Đối với các ngôn ngữ nguồn, các mô hình byte cho thấy kết quả tương đương hoặc chỉ hơi tệ hơn từ mô hình dựa trên phoneme. Do đó các mô hình byte đa ngôn ngữ có thể tạo ra giọng nói tự nhiên trên các ngôn ngữ nguồn tài nguyên phong phú. Trên các ngôn ngữ đích, chúng tôi chọn test hiệu suất trên trường hợp tài nguyên thấp (BYTE LOW), cùng với trường hợp cực thấp hoặc few-shot (BYTE XLOW) cho thấy intelligibility tốt, so sánh với các mô hình byte full-data đơn ngôn ngữ. Chúng tôi báo cáo kết quả Pinyin như tài nguyên thấp zh-cn đầy lỗi và do đó ít ý nghĩa hơn. Byte XLow có một số khoảng cách so với các mô hình Byte Low, trong khi các mô hình Byte Low cho thấy MOS tương đương trên en-in, ro-ro, và th-th, và chỉ hồi quy nhẹ trên el-gr và zh-cn, so với BYTE SINGLE, sử dụng chỉ 5% đến 29% dữ liệu. Hơn nữa, cả mô hình Byte Low và Byte Single đều có MOS tương đương với các mô hình phoneme trên tất cả ngôn ngữ đích. Kết quả nhất quán với các chỉ số khách quan, cho thấy hiệu suất đặc biệt của chúng tôi trên thích ứng tài nguyên thấp.

Chúng tôi cũng test intelligibility chủ quan trên Romanian và Greek, sử dụng mô hình thích ứng T3 30-mẫu và mô hình 10-mẫu tốt nhất, tức là Pan (0.1) cho Greek và T3 (0.1) cho Romanian. Như trong Bảng 3, các mô hình Greek few-shot cho thấy intelligibility tốt với >90% từ đúng, và đối với Romanian các mô hình few-shot đủ để tạo ra gần 100% intelligibility trong các bài test. Kết quả rất nhất quán với CER, chỉ ra rằng CER là một chỉ số đáng tin cậy cho intelligibility nhận thức.

4 Cơ chế mô hình
Từ bản dịch đa ngôn ngữ của Google đến BERT đa ngôn ngữ, các nhà nghiên cứu ML và NLP đã khám phá rằng các ngôn ngữ khác nhau có thể được xử lý tốt trong một mô hình chia sẻ duy nhất, điều này trái với trực giác và khác với học đa tác vụ điển hình sử dụng các mô-đun đặc trưng tác vụ riêng biệt. Do đó, chủ đề có giá trị cho các nhà nghiên cứu ML chung: làm thế nào một mô hình duy nhất đạt được tính linh hoạt như vậy trên các tác vụ đa dạng?

Lấy cảm hứng từ những phát hiện rằng có cả các thành phần đặc trưng và bất khả tri ngôn ngữ trong các embedding BERT đa ngôn ngữ (Libovický et al., 2019), chúng tôi tin rằng câu trả lời có thể nằm trong mối quan hệ giữa mô hình đa ngôn ngữ và các mô hình đặc trưng ngôn ngữ. Do đó, chúng tôi cố gắng xác định các tham số hoặc mô hình con trong mạng đa ngôn ngữ quan trọng cho từng ngôn ngữ đơn lẻ, và khám phá mối quan hệ giữa những mô hình con cụ thể này.

Chúng tôi áp dụng tỉa tách dựa trên dữ liệu với các tiêu chí Taylor (Molchanov et al., 2017), nhắm đến việc xác định các neuron nổi bật cho dữ liệu đầu vào. Một neuron nổi bật trên dữ liệu của một ngôn ngữ có thể quan trọng cho mô hình xử lý ngôn ngữ đó. Tiêu chí là xem xét tác động lên loss L khi làm không mỗi neuron hi dưới một giả định độc lập, cho các ví dụ huấn luyện D của ngôn ngữ:

ΔL(hi) = |L(hi = 0; D) - L(hi; D)|

được ước tính sử dụng khai triển Taylor của L(hi) gần hi = 0. Với khai triển bậc nhất,
L(hi = 0; D) = L(hi; D) - ∂L/∂hi hi + R1(hi = 0)

Bỏ qua R1, tác động hoặc sự nổi bật được xấp xỉ như
S(hi) = |ΔL(hi)| = |∂L/∂hi hi|

có thể được tính toán trong backpropagation tiêu chuẩn.

Chúng tôi lấy mẫu ngẫu nhiên 1k ví dụ huấn luyện trên mỗi ngôn ngữ để tính toán sự nổi bật, trên mô hình thích ứng T3 với zh-cn với 2k mẫu. Vì chúng tôi sử dụng transformer, chúng tôi tính toán sự nổi bật sau mỗi tầng feedforward (cộng với phi tuyến nếu có). Do đó, tác động của việc làm không một neuron tương đương với việc làm không các tham số tương ứng. Vì các tầng được chia sẻ giữa các bước trong chuỗi đầu vào/đầu ra, sự nổi bật của mỗi neuron được có được bằng max-pooling qua các bước và trung bình giữa các mẫu. Chúng tôi sau đó sắp xếp các neuron cho mỗi tầng và tỉa tách nửa dưới, giả định mạng còn lại của 50% tham số là mô hình đặc trưng ngôn ngữ cho mỗi ngôn ngữ. Tiếp theo, đối với mỗi cặp ngôn ngữ, chúng tôi so sánh các mô hình con cụ thể của chúng bằng cách kiểm tra tỷ lệ neuron chồng chéo trong cả hai. Bên cạnh đó, chúng tôi chia ngẫu nhiên dữ liệu của mỗi ngôn ngữ thành hai nửa và thực hiện tỉa tách riêng biệt, và sau đó xác định sự chồng chéo của chúng theo cách tương tự.

Như thể hiện trong Hình 5, đối với mỗi cặp khoảng 40% neuron nổi bật trên cả hai ngôn ngữ, và các tỷ lệ tương quan với sự tương tự ngôn ngữ. Trong khi sự chồng chéo nội ngôn ngữ trên 90%, do đó sự khác biệt của các neuron nổi bật là do sự khác biệt của các ngôn ngữ chứ không phải mẫu. Bên cạnh đó, vì kết quả từ một tầng encoder sâu, nó không phải kết quả trực tiếp của ID ngôn ngữ hoặc tập ký tự riêng biệt. Mặc dù chúng tôi trình bày những kết quả từ tầng encoder 5, các mẫu như vậy xuất hiện trong hầu hết các tầng.

Theo trực giác, các ngôn ngữ với script chia sẻ có sự chồng chéo đáng kể, chẳng hạn như bg/Bulgarian và ru/Russian từ các nhánh khác nhau của các ngôn ngữ Slavic nhưng cả hai đều sử dụng bảng chữ cái Cyrillic. Trong khi sự tương tự dạng nói quan trọng và những ngôn ngữ với sự tương tự từ vựng, ngữ âm, hoặc phát sinh lớn hơn chồng chéo nhiều hơn, như thể hiện bởi các ngôn ngữ Germanic liên quan chặt chẽ, đặc biệt là nhánh Nordic (da/Danish, nb/Norwegian, sv/Swedish), trong khi de/German xa hơn. Điều này thậm chí áp dụng cho các ngôn ngữ với script khác nhau, chẳng hạn như ur/Urdu và hi/Hindi, cùng ngôn ngữ nói trong hai script khác nhau. Nó tương tự trên các ngôn ngữ riêng biệt, chẳng hạn như vi (không liên quan về phát sinh nhưng có từ vay phong phú từ tiếng Trung), zh-hk, và đích thích ứng zh-cn. Do đó, trong quá trình thích ứng, các cấu trúc và tham số từ các ngôn ngữ nguồn tương tự có thể được sử dụng bởi đích. Mối quan hệ phát sinh cũng có thể được quan sát trong sự chồng chéo từ bg đến các ngôn ngữ Slavic khác, như hr/Croatian và sk/Slovak cả hai đều sử dụng bảng chữ cái Latin: hr có nhiều chồng chéo hơn vì bg và hr đều là ngôn ngữ Nam Slavic trong khi sk là ngôn ngữ Tây Slavic xa hơn.

Chúng tôi tiếp tục xác minh các phát hiện của mình bằng cách thực sự tỉa tách một mô hình T3 với sự nổi bật được tính toán từ tiếng Đức, và sau đó huấn luyện lại nó thành các mô hình đơn ngôn ngữ của các ngôn ngữ T2 dưới cài đặt tài nguyên thấp, và tiếp theo so sánh kết quả của việc tỉa tách với chính ngôn ngữ đó. Như thể hiện bởi Bảng 4, ngôn ngữ càng khác biệt với tiếng Đức, sự sụt giảm hiệu suất lớn hơn bởi German-pruning có thể được quan sát. Trong khi nếu mô hình được tỉa tách ngẫu nhiên, nó sẽ chủ yếu thất bại. Điều này chỉ ra rằng tiêu chí của chúng tôi xác định đúng các neuron đặc trưng cho tiếng Đức, và một ngôn ngữ tương tự có thể tận dụng tốt hơn mô hình con tiếng Đức.

Tất cả những bằng chứng này hỗ trợ rằng mô hình của chúng tôi nắm bắt các mối quan hệ cấp cao khác nhau giữa các ngôn ngữ giống như BERT đa ngôn ngữ (Rama et al., 2020). Do đó, không giống như các công trình trước đây yêu cầu thiết kế thủ công các mô-đun đặc trưng ngôn ngữ và bất khả tri như encoder theo từng ngôn ngữ (Nachmani and Wolf, 2019; Nekvinda and Dusek, 2020), chúng tôi cho thấy rằng một kiến trúc của các mạng con đặc trưng ngôn ngữ với các tham số chia sẻ một phần nổi lên từ huấn luyện đa ngôn ngữ của một mô hình duy nhất, và mô hình có thể khám phá và tận dụng sự tương tự ngôn ngữ cho cả các ngôn ngữ nguồn và chuyển giao đến các đích để xử lý tác vụ TTS đa ngôn ngữ và thích ứng tài nguyên thấp.

5 Công trình liên quan
Nhiều công trình trước đây cố gắng xây dựng các mô hình TTS thần kinh đa ngôn ngữ. Li et al. (2019a) là công trình liên quan chặt chẽ đã đề xuất mô hình nhận dạng và tổng hợp giọng nói dựa trên byte. Tuy nhiên, công trình chỉ được thực hiện trên ít ngôn ngữ và không chạm đến các tình huống tài nguyên thấp. Các phương pháp đa ngôn ngữ khác giới thiệu huấn luyện đối kháng (Zhang et al., 2019), hoặc encoder theo từng ngôn ngữ (Nachmani and Wolf, 2019; de Korte et al., 2020), có thể với các tham số được dự đoán từ ID ngôn ngữ (Nekvinda and Dusek, 2020). TTS đa ngôn ngữ giúp các ngôn ngữ tài nguyên thấp rất nhiều, cả trong huấn luyện đa ngôn ngữ và thích ứng (Li and Zen, 2016; Demirsahin et al., 2018; Baljekar et al., 2018; de Korte et al., 2020). Khung của chúng tôi được phát triển trên TTS transformer đa ngôn ngữ cân bằng ngôn ngữ dựa trên phoneme (Yang and He, 2020) mở rộng phương pháp đến hơn 40 ngôn ngữ, trong khi chúng tôi loại bỏ nhu cầu đầu vào phoneme, vượt trội hiệu suất của chúng trên thích ứng tài nguyên thấp, và khám phá chế độ few-shot. Nhiều phương pháp phức tạp hơn được đề xuất để tận dụng tốt hơn học chuyển giao, tiền huấn luyện, và học bán giám sát, chẳng hạn như sử dụng embedding văn bản được tiền huấn luyện và tiền huấn luyện decoder tự giám sát (Chung et al., 2019), và tinh chỉnh từ một autoencoder với latents rời rạc được huấn luyện trên giọng nói đích không ghép đôi (Zhang and Lin, 2020; Liu et al., 2020a). Ren et al. (2019) áp dụng học đối ngẫu giữa nhận dạng và tổng hợp, cùng với denoising autoencoding, và Xu et al. (2020) tiếp tục thêm tiền huấn luyện tài nguyên phong phú và chưng cất kiến thức. Tăng cường dữ liệu với tiếng ồn được tiêm (Liu et al., 2020b) cũng giúp ích. Bên cạnh đó, chuyển giao từ các ngôn ngữ khác có thể được có được bởi chuyên môn ngôn ngữ như thiết kế một tập phoneme thống nhất (Cai et al., 2020), thường được dẫn xuất từ IPA (Chen et al., 2019; Demirsahin et al., 2018), hoặc tạo vector đặc trưng bằng phonology (Staib et al., 2020). Trong khi phương pháp của chúng tôi loại bỏ nhu cầu của những chuyên môn đặc trưng ngôn ngữ và pipeline phức tạp này sử dụng các mô hình và dữ liệu phụ trợ.

6 Kết luận và công việc tương lai
Chúng tôi trình bày một cách tiếp cận hệ thống để xây dựng mô hình TTS Byte2Speech đa ngôn ngữ và cho thấy rằng nó có khả năng khớp hiệu suất dựa trên phoneme trên cả các tình huống thích ứng tiêu chuẩn và tài nguyên thấp. Chúng tôi cũng làm sâu sắc hiểu biết về cơ chế bằng một diễn giải mới. Công việc tương lai sẽ tập trung vào việc cải thiện hiệu suất few-shot và khám phá thêm cơ chế mô hình.

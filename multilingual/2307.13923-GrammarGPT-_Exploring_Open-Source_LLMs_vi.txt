# 2307.13923.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/multilingual/2307.13923.pdf
# Kích thước tệp: 924569 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
GrammarGPT: Khám phá các LLM mã nguồn mở
cho việc sửa lỗi ngữ pháp tiếng Trung bản địa
với việc tinh chỉnh có giám sát
Yaxin Fan1,2,3, Feng Jiang1,3,4⋆, Peifeng Li2, và Haizhou Li1,3
1Khoa Khoa học Dữ liệu, Đại học Trung văn Hong Kong, Thâm Quyến, Trung Quốc
2Khoa Khoa học và Công nghệ Máy tính, Đại học Soochow, Trung Quốc
3Viện Nghiên cứu Dữ liệu Lớn Thâm Quyến, Thâm Quyến, Quảng Đông, Trung Quốc
4Khoa Khoa học và Công nghệ Thông tin, Đại học Khoa học và Công nghệ Trung Quốc, Trung Quốc
yxfansuda@stu.suda.edu.cn
pfli@suda.edu.cn
{jeffreyjiang,haizhouli }@cuhk.edu.cn
Tóm tắt. Sửa lỗi ngữ pháp nhằm tự động sửa các câu không tuân thủ ngữ pháp. Gần đây, một số nghiên cứu đã chứng minh khả năng xuất sắc của các Mô hình Ngôn ngữ Lớn nguồn đóng (LLMs, ví dụ: ChatGPT) trong việc sửa lỗi ngữ pháp. Tuy nhiên, tiềm năng của các LLM mã nguồn mở vẫn chưa được khám phá. Trong bài báo này, chúng tôi giới thiệu GrammarGPT, một LLM mã nguồn mở, để sơ bộ khám phá tiềm năng của nó cho việc sửa lỗi ngữ pháp tiếng Trung bản địa. Công thức cốt lõi của GrammarGPT là tận dụng bộ dữ liệu kết hợp của dữ liệu được tạo bởi ChatGPT và được chú thích bởi con người. Đối với các lỗi ngữ pháp có manh mối, chúng tôi đề xuất một phương pháp heuristic để hướng dẫn ChatGPT tạo ra các câu không tuân thủ ngữ pháp bằng cách cung cấp những manh mối đó. Đối với các lỗi ngữ pháp không có manh mối, chúng tôi thu thập các câu không tuân thủ ngữ pháp từ các trang web công khai và sửa chúng thủ công. Ngoài ra, chúng tôi sử dụng một phương pháp tăng cường bất biến lỗi để nâng cao khả năng của mô hình trong việc sửa lỗi ngữ pháp tiếng Trung bản địa. Cuối cùng chúng tôi xây dựng khoảng 1k dữ liệu song song và sử dụng những dữ liệu này để tinh chỉnh các LLM mã nguồn mở (ví dụ: Phoenix, phát hành bởi Đại học Trung văn Hong Kong, Thâm Quyến) với việc điều chỉnh hướng dẫn. Kết quả thực nghiệm cho thấy GrammarGPT vượt trội hơn hẳn hệ thống SOTA hiện tại. Mặc dù các tham số mô hình lớn hơn 20 lần so với baseline SOTA, lượng dữ liệu cần thiết cho việc điều chỉnh hướng dẫn nhỏ hơn 1200 lần, minh họa tiềm năng của các LLM mã nguồn mở trên CGEC bản địa. GrammarGPT của chúng tôi đứng thứ 3 trong NLPCC2023 SharedTask1, chứng minh hiệu quả của phương pháp của chúng tôi. Mã và dữ liệu có sẵn tại https://github.com/FreedomIntelligence/GrammarGPT .
Từ khóa: Sửa lỗi ngữ pháp tiếng Trung bản địa · Mô hình ngôn ngữ lớn · ChatGPT · Điều chỉnh hướng dẫn.
⋆Tác giả Liên hệarXiv:2307.13923v2  [cs.CL]  17 Aug 2023

--- TRANG 2 ---
2 Fan et al.
1 Giới thiệu
Sửa lỗi Ngữ pháp (GEC) nhằm tự động sửa các câu không tuân thủ ngữ pháp mà không thay đổi ý nghĩa của chúng [26,10,27]. Các nghiên cứu trước đây [28,13,14,26] trong Sửa lỗi Ngữ pháp tiếng Trung (CGEC) chủ yếu nghiên cứu các lỗi từ người học tiếng Trung nước ngoài, rất rõ ràng và ngây thơ. Do đó, các nghiên cứu gần đây [27,10] chuyển sang các lỗi ngữ pháp do người bản xứ mắc phải, tinh tế và thách thức hơn. Bảng 1 cho thấy sáu loại lỗi ngữ pháp chính do người bản xứ mắc phải, có thể được chia thành hai loại, ví dụ: có (w/) và không có (w/o) manh mối. Chúng ta có thể thấy rằng các câu không chính xác trôi chảy và phù hợp với thói quen của người Trung Quốc bản địa. Tuy nhiên, chúng không tuân thủ ngữ pháp tiếng Trung, khó sửa hơn.

Các nghiên cứu trước đây trong GEC chủ yếu áp dụng cả hai mô hình Seq2edit [5,26,9,10] và Seq2seq [7,29,15] và đã đạt được hiệu suất ấn tượng trên các benchmark GEC khác nhau. Với sự xuất hiện của LLMs, Fang et al. [4] đánh giá hiệu suất của các LLM nguồn đóng (ví dụ: ChatGPT5) trên GEC và tiết lộ khả năng xuất sắc của nó trong việc phát hiện và sửa lỗi. Tuy nhiên, tiềm năng của các LLM mã nguồn mở vẫn chưa được khám phá.

Trong bài báo này, chúng tôi giới thiệu GrammarGPT, một mô hình mới để nghiên cứu tiềm năng của các kiến trúc LLM mã nguồn mở trong việc giải quyết Sửa lỗi Ngữ pháp tiếng Trung Bản địa (CGEC) thông qua tinh chỉnh có giám sát. Thách thức chính trong việc tinh chỉnh LLMs cho CGEC là thu được dữ liệu song song chất lượng cao bao gồm các lỗi ngữ pháp do người bản xứ mắc phải. Tuy nhiên, việc chú thích thủ công dữ liệu như vậy không chỉ tốn thời gian mà còn đắt đỏ, đòi hỏi phải khám phá các phương pháp chú thích dữ liệu tự động. Các nghiên cứu gần đây [25,22] đã thành công tận dụng dữ liệu chưng cất từ ChatGPT và bộ dữ liệu thực tế để tinh chỉnh LLMs cho các lĩnh vực cụ thể, giảm chi phí hiệu quả trong khi đạt được hiệu suất vượt trội. Lấy cảm hứng từ dòng nghiên cứu này, chúng tôi đề xuất một bộ dữ liệu kết hợp kết hợp các loại lỗi ngữ pháp tiếng Trung bản địa khác nhau.

Cụ thể, đầu tiên chúng tôi đề xuất một phương pháp heuristic cho các lỗi ngữ pháp có manh mối như được hiển thị trong Hình 1 hướng dẫn ChatGPT tạo ra các câu không tuân thủ ngữ pháp bằng cách cung cấp những manh mối đó. Sau đó, đối với những lỗi không có manh mối, chúng tôi thu thập các câu không tuân thủ ngữ pháp từ trang web công khai và sửa chúng thủ công. Ngoài ra, chúng tôi đề xuất một phương pháp tăng cường dữ liệu bất biến lỗi để nâng cao tính đa dạng của dữ liệu bằng cách thay thế các thực thể được đặt tên trong dữ liệu song song bằng những thực thể tương tự, có thể cải thiện khả năng của mô hình trong việc sửa lỗi ngữ pháp tiếng Trung bản địa. Cuối cùng chúng tôi xây dựng 1k dữ liệu song song và sử dụng những dữ liệu này để tinh chỉnh LLMs với việc điều chỉnh hướng dẫn.

Kết quả thực nghiệm cho thấy GrammarGPT có thể vượt trội hơn hẳn các hệ thống tiên tiến nhất (SOTA). Mặc dù kích thước các tham số mô hình lớn hơn 20 lần so với baseline SOTA, dữ liệu để tinh chỉnh nhỏ hơn 1200 lần, điều này chứng minh tiềm năng của các LLM mã nguồn mở trong việc sửa lỗi ngữ pháp tiếng Trung.

5https://chat.openai.com/

--- TRANG 3 ---
GrammarGPT 3
Bảng 1. Ví dụ về các câu có nhiều loại lỗi ngữ pháp khác nhau. Đối với những lỗi có manh mối, chúng ta có thể dễ dàng phát hiện và sửa chúng. Ví dụ, sự đồng xuất hiện của 超过(hơn) và 左右(khoảng) dẫn đến lỗi thành phần dư thừa và chúng ta có thể loại bỏ một trong số chúng để làm cho câu tuân thủ ngữ pháp tiếng Trung. Tuy nhiên, đối với những lỗi không có manh mối, cần hiểu sâu hơn về ngữ pháp tiếng Trung để phát hiện và sửa.

w/ ManhMốiThành phần
Dư thừa
(RC)Không chính xác: 这座卫星城的人口估计超过一百万左右。
Dân số của thành phố vệ tinh này được ước tính là
hơn khoảng một triệu.
Chính xác: 这座卫星城的人口估计超过一百万。
Dân số của thành phố vệ tinh này được ước tính là
hơn một triệu.

Nhầm lẫn
Cấu trúc
(SC)Không chính xác: 这次网络故障的原因是由服务器故障引起的。
Nguyên nhân của sự cố mạng này là do sự cố máy chủ gây ra.
Chính xác: 这次网络故障的原因是服务器故障。
Nguyên nhân của sự cố mạng là sự cố máy chủ.

Phối hợp
Không thích hợp
(IC)Không chính xác: 西湖区正全面提升区域产城融合发展的步伐。
Quận Tây Hồ đang thúc đẩy nhịp độ tích hợp phát triển
ngành và thành phố trong khu vực.
Chính xác: 西湖区正全面加快区域产城融合发展的步伐。
Quận Tây Hồ đang đẩy nhanh nhịp độ tích hợp phát triển
ngành và thành phố trong khu vực.

w/o ManhMốiThứ tự Từ
Không thích hợp
(IWO)Không chính xác: 学校三个月内要求每名学生完成20个小时的义工服务。
Trường học trong ba tháng yêu cầu mỗi học sinh hoàn thành
20 giờ dịch vụ tình nguyện.
Chính xác: 学校要求每名学生三个月内完成20个小时的义工服务。
Trường học yêu cầu mỗi học sinh hoàn thành 20 giờ dịch vụ
tình nguyện trong ba tháng.

Tính logic
Không thích hợp
(IL)Không chính xác: 集团向社会各界人士、沿途村庄百姓表示歉意。
Tập đoàn xin lỗi người dân từ mọi tầng lớp xã hội và
dân làng dọc đường.
Chính xác: 集团向社会各界人士表示歉意。
Tập đoàn xin lỗi người dân từ mọi tầng lớp xã hội.

Thiếu
Thành phần
(MC)Không chính xác: 这篇报告控诉了人类破坏大自然(...)。
Báo cáo cáo buộc con người phá hoại thiên nhiên.
Chính xác: 这篇报告控诉了人类破坏大自然的罪行。
Báo cáo cáo buộc con người tội phá hoại thiên nhiên.

Những đóng góp của chúng tôi như sau:
–Theo hiểu biết của chúng tôi, chúng tôi là những người đầu tiên khám phá tiềm năng của các LLM mã nguồn mở với việc điều chỉnh hướng dẫn cho việc sửa lỗi ngữ pháp tiếng Trung bản địa.
–Chúng tôi đã xây dựng một bộ dữ liệu kết hợp được tạo bởi ChatGPT và chú thích thủ công, có thể bao phủ hiệu quả các lỗi ngữ pháp tiếng Trung bản địa để huấn luyện LLMs thành một máy dò ngữ pháp xuất sắc.
–Chúng tôi thiết kế một phương pháp tăng cường dữ liệu bất biến lỗi để thay thế các thực thể được đặt tên trong dữ liệu song song bằng những thực thể tương tự, làm cho mô hình chính xác hơn trong việc sửa lỗi ngữ pháp.
–Kết quả thực nghiệm cho thấy GrammarGPT có thể vượt trội hơn hẳn hệ thống SOTA, và kích thước dữ liệu cho việc điều chỉnh hướng dẫn chỉ bằng 1/1200 của hệ thống SOTA.

--- TRANG 4 ---
4 Fan et al.
2 Nghiên cứu Liên quan
2.1 Sửa lỗi Ngữ pháp
Các nghiên cứu về sửa lỗi ngữ pháp có thể được chia thành hai mô hình: mô hình Seq2edit và mô hình Seq2seq.

Mô hình Seq2edit Mô hình Seq2edit nhằm dự đoán nhãn sửa đổi, bao gồm chèn, xóa và thay thế, cho mỗi vị trí của câu một cách lặp đi lặp lại. Hinson et al. [5] đề xuất một phương pháp không đồng nhất cho CGEC, bao gồm một mô hình dựa trên NMT, một mô hình chỉnh sửa chuỗi và một trình kiểm tra chính tả. Liang et al. [9] giới thiệu và chuyển đổi mô hình NMT kết hợp BERT và mô hình gắn thẻ chuỗi vào lĩnh vực CGEC. Zhang et al. [26] đề xuất một bộ dữ liệu đánh giá đa nguồn đa tham chiếu cho CGEC và áp dụng phương pháp seq2edit được tăng cường với các mô hình ngôn ngữ được huấn luyện trước lớn. Ma et al. [10] đề xuất một phương pháp dựa trên quy tắc ngôn ngữ học để xây dựng kho ngữ liệu huấn luyện CGEC quy mô lớn với các lỗi ngữ pháp được tạo tự động và áp dụng phương pháp seq2edit để đánh giá.

Mô hình Seq2seq Mô hình này coi CGEC như một nhiệm vụ dịch đơn ngữ. Katsumata và Komachi [7] khám phá tính hữu ích của các máy biến áp hai chiều và tự hồi quy (BART) như một mô hình mã hóa-giải mã được huấn luyện trước chung cho GEC. Zhao và Wang [29] đề xuất một phương pháp đơn giản nhưng hiệu quả để cải thiện các mô hình GEC dựa trên NMT bằng việc che động, có thể tạo ra các thể hiện đa dạng hơn để tăng cường khái quát hóa mô hình. Rothe et al. [15] đề xuất một phương pháp không phụ thuộc vào ngôn ngữ để tạo ra một số lượng lớn các ví dụ tổng hợp, sau đó tinh chỉnh các mô hình ngôn ngữ đa ngữ quy mô lớn.

Ngoài ra, một số nghiên cứu [9,5,8,26] quan sát thấy sức mạnh bổ sung của hai mô hình trên, từ đó thúc đẩy hiệu suất thông qua việc kết hợp mô hình. Trong bài báo này, chúng tôi áp dụng mô hình Seq2seq để tinh chỉnh LLMs với việc điều chỉnh hướng dẫn.

2.2 Điều chỉnh Hướng dẫn cho LLMs
Điều chỉnh hướng dẫn [21,16] có thể cải thiện khả năng khái quát hóa của mô hình bằng cách học từ một số lượng lớn các nhiệm vụ được hướng dẫn bởi chỉ dẫn, đã được áp dụng thành công để tinh chỉnh LLMs trên một số nhiệm vụ cụ thể. Nghiên cứu về điều chỉnh hướng dẫn cụ thể cho nhiệm vụ có thể được phân loại thành ba loại theo nguồn dữ liệu: được tạo bởi ChatGPT, được chú thích bởi con người, và bộ dữ liệu kết hợp của ChatGPT và con người.

Dữ liệu được tạo bởi ChatGPT Một số nghiên cứu áp dụng dữ liệu được tạo bởi ChatGPT để tinh chỉnh LLMs dưới dạng hướng dẫn. Ho et al. [6] đề xuất Fine-tune-CoT, một phương pháp tạo ra các mẫu lý luận từ LLMS để tinh chỉnh các mô hình nhỏ hơn, cho phép khả năng lý luận đáng kể của các mô hình nhỏ. Wang et al. [19] đề xuất SCOTT, một phương pháp chưng cất kiến thức trung thực để

--- TRANG 5 ---
GrammarGPT 5
Dữ liệu được tạo bởi ChatGPT
Dữ liệu được chú thích bởi con ngườiThành phần Dư thừa
Nhầm lẫn Cấu trúc
Phối hợp Không thích hợp
Thứ tự Từ Không thích hợp
Tính logic Không thích hợp
Thiếu Thành phần
Tăng cường
Bất biến Lỗi Điều chỉnh 
Hướng dẫn
GrammarGPT
Bộ Dữ liệu
Kết hợpBộ Dữ liệu
Tăng cường
Hình 1. Khung của phương pháp chúng tôi.

học một mô hình CoT nhỏ, tự nhất quán từ một mô hình giáo viên có quy mô lớn hơn nhiều bậc. Chen et al. [1] khám phá việc chưng cất khả năng lý luận của LLMs vào một mô hình học sinh nhỏ gọn hơn cho việc trích xuất thực thể được đặt tên đa phương thức và trích xuất quan hệ đa phương thức. Chen et al. [1] đề xuất một khung tổng hợp dữ liệu được xây dựng dựa trên các hàm tạo dữ liệu được tham số hóa bởi LLMs và prompts và sử dụng dữ liệu tổng hợp để tinh chỉnh LLaMA.

Dữ liệu được chú thích bởi con người Một số nghiên cứu trực tiếp chuyển đổi dữ liệu có giám sát thành định dạng hướng dẫn để tinh chỉnh LLMs. Zhang et al. [24] đề xuất tinh chỉnh LLaMA [18] về phân tích tình cảm tài chính với một phần nhỏ dữ liệu phân tích tình cảm tài chính có giám sát. Wang et al. [20] đề xuất một khung trích xuất thông tin thống nhất dựa trên điều chỉnh hướng dẫn để mô hình hóa các nhiệm vụ trích xuất thông tin khác nhau và nắm bắt sự phụ thuộc giữa các nhiệm vụ.

Bộ dữ liệu kết hợp của ChatGPT và con người Gần đây, một số nghiên cứu sử dụng dữ liệu kết hợp của con người và ChatGPT/GPT-4 để tinh chỉnh LLMs. Zhang et al. [25] đề xuất tận dụng cả dữ liệu chưng cất từ ChatGPT và dữ liệu thực tế từ các bác sĩ để tinh chỉnh Bloom [17]. Yu et al. [22] áp dụng dữ liệu kết hợp của hướng dẫn giáo dục Trung Quốc và lĩnh vực chung [12] được tạo bởi GPT-4 để tinh chỉnh LLaMA [18]. Trong bài báo này, chúng tôi theo dòng này và tinh chỉnh LLMs trên CGEC bản địa với bộ dữ liệu kết hợp được tạo bởi ChatGPT và được chú thích bởi con người với việc điều chỉnh hướng dẫn.

3 Phương pháp
Hình 1 minh họa khung của phương pháp chúng tôi, bao gồm việc xây dựng dữ liệu song song bao gồm sáu loại lỗi ngữ pháp tiếng Trung bản địa để tạo điều kiện cho việc tinh chỉnh Mô hình Ngôn ngữ mã nguồn mở (LLMs). Trong khi dữ liệu được chú thích bởi con người cung cấp các mẫu chất lượng cao, chi phí cao liên quan vẫn là một mối quan tâm đáng kể. Để giải quyết điều này, chúng tôi áp dụng một phương pháp thỏa hiệp. Đầu tiên chúng tôi hướng dẫn ChatGPT tạo ra các câu không tuân thủ ngữ pháp có manh mối bằng cách cung cấp những manh mối được thu thập từ Internet. Sau đó, chúng tôi chú thích các câu không tuân thủ ngữ pháp

--- TRANG 6 ---
6 Fan et al.
Hướng dẫn: 
用"...{超过}...{左右}..."造5个句子，每个句
子涉及到不同的话题，每个句子至少15个字。
Sử dụng "...{hơn} ... {khoảng} ..." tạo 5 
câu, mỗi câu liên quan đến chủ đề khác nhau và ít 
nhất 15 từ.
 Đầu ra ChatGPT: 
我们公司每年的利润都超过500万美元左右。
Công ty chúng tôi kiếm được hơn khoảng 5 triệu đô la mỗi năm.
...
这本小说的销量预计会超过10万册左右。
Cuốn tiểu thuyết dự kiến sẽ bán hơn khoảng 100.000 
bản.
Hình 2. Quá trình tạo câu không tuân thủ ngữ pháp bởi ChatGPT.

Câu Không tuân thủ Ngữ pháp:
赵薇执导的《致青春》对中国青年使不陌生的。
So Young, do Triệu Vy đạo diễn, không xa lạ gì với 
thanh niên Trung Quốc.
Câu tuân thủ Ngữ pháp:
中国青年对于赵薇执导的《致青春》是不陌生的。
Thanh niên Trung Quốc không xa lạ gì với So Young 
do Triệu Vy đạo diễn.Câu Không tuân thủ Ngữ pháp:
章子怡执导的《致青春》对中国青年使不陌生的。
So Young, do Chương Tử Di đạo diễn, không xa lạ gì với 
thanh niên Trung Quốc.
Câu tuân thủ Ngữ pháp:
中国青年对于章子怡执导的《致青春》是不陌生的。
Thanh niên Trung Quốc không xa lạ gì với So Young 
do Chương Tử Di đạo diễn.Tăng cường
Bất biến Lỗi
Hình 3. Một ví dụ về tăng cường bất biến lỗi.

không có manh mối được thu thập từ Internet. Ngoài ra, chúng tôi đề xuất một kỹ thuật tăng cường bất biến lỗi để thay thế các thực thể được đặt tên trong dữ liệu song song bằng những thực thể tương tự, nâng cao hơn nữa khả năng của mô hình trong việc sửa lỗi ngữ pháp tiếng Trung bản địa. Cuối cùng, chúng tôi chuyển đổi dữ liệu song song thành hướng dẫn, sau đó được sử dụng để tinh chỉnh LLMs. Giải thích chi tiết về các bước này được cung cấp trong các phần con sau.

3.1 Xây dựng Bộ dữ liệu Kết hợp
Dữ liệu được tạo bởi ChatGPT Như được hiển thị trong ba dòng đầu của Bảng 1, các lỗi ngữ pháp có manh mối dễ phát hiện và sửa bằng cách nhận ra các manh mối cụ thể. Ví dụ, "hơn" và "khoảng" được sử dụng cùng nhau dẫn đến thành phần dư thừa ,"Nguyên nhân" và "gây ra bởi" được sử dụng cùng nhau dẫn đến nhầm lẫn cấu trúc , và "thúc đẩy" và "nhịp độ" được sử dụng cùng nhau dẫn đến phối hợp không thích hợp . Ngược lại, chúng ta có thể xây dựng các câu không tuân thủ ngữ pháp bằng cách chèn những manh mối này vào các câu tuân thủ ngữ pháp. Nhờ vào khả năng mạnh mẽ của ChatGPT, chúng ta có thể hướng dẫn ChatGPT tạo ra các câu không tuân thủ ngữ pháp đáp ứng yêu cầu của chúng ta bằng cách cung cấp những manh mối này được thu thập từ các trang web công khai6. Một ví dụ được hiển thị trong Hình 2.

Dữ liệu được chú thích bởi Con người Một số loại lỗi không tuân thủ ngữ pháp bản địa khó nhận ra, như được hiển thị trong ba dòng cuối của Bảng 1. Chúng ta có thể thấy rằng những câu không tuân thủ ngữ pháp đó trôi chảy và không có manh mối rõ ràng nào của lỗi ngữ pháp có thể giúp chúng ta nhận ra chúng. Đối với các loại lỗi ngữ pháp này, chúng tôi chủ yếu thu thập các câu không tuân thủ ngữ pháp từ các trang web công khai7và sau đó chú thích thủ công.

6https://wenku.baidu.com
7https://tiku.baidu.com/

--- TRANG 7 ---
GrammarGPT 7
Bảng 2. Các thành phần của một hướng dẫn.
Hướng dẫn{Tiền tố Nhiệm vụ }
Con người: {Mô tả Nhiệm vụ } {Đầu vào }Trợ lý : {Đầu ra }
Tiền tố Nhiệm vụCuộc trò chuyện giữa một con người tò mò và một
trợ lý trí tuệ nhân tạo. Trợ lý đưa ra câu trả lời hữu ích,
chi tiết và lịch sự cho các câu hỏi của con người.
Mô tả Nhiệm vụ Đánh giá câu này về lỗi ngữ pháp
Đầu vào Câu không tuân thủ ngữ pháp
Đầu ra Câu tuân thủ ngữ pháp

Bảng 3. Thống kê của bộ dữ liệu.
Bộ dữ liệu SốTỉ lệ phần trăm của các Lỗi Ngữ pháp Khác nhau (%)
Được tạo bởi ChatGPT Được chú thích bởi con người
RC SC IC IWO IL MC
tập huấn luyện 1061 23.54 28.25 13.70 6.50 13.18 15.07
tập xác thực 500 - - - - - -

3.2 Tăng cường Dữ liệu Bất biến Lỗi
Để ưu tiên sự tập trung của mô hình vào các lỗi ngữ pháp bản địa và cải thiện tính bền vững của nó, chúng tôi đã thiết kế một phương pháp tăng cường bất biến lỗi, như được hiển thị trong Hình 3. Các lỗi ngữ pháp tiếng Trung bản địa thường tinh tế và hiếm khi được tìm thấy ở vị trí của các thực thể được đặt tên. Để giải quyết điều này, chúng tôi áp dụng chiến lược thay thế các thực thể được đặt tên trong dữ liệu song song bằng những thực thể tương tự8. Bằng cách sử dụng phương pháp tăng cường này, mô hình có thể tập trung vào việc xác định các lỗi không thay đổi thay vì các danh từ cụ thể, do đó cải thiện hiệu suất của nó trong việc sửa các lỗi ngữ pháp tinh tế và không thể nhận ra.

3.3 Điều chỉnh Hướng dẫn
Điều chỉnh hướng dẫn[21,16] đã nổi lên như phương pháp chính thống để tinh chỉnh LLMs bằng cách cung cấp hướng dẫn rõ ràng để tăng cường hiểu biết của mô hình. Trong bài báo này, chúng tôi đã theo xu hướng chính thống này và tinh chỉnh LLMs với việc điều chỉnh hướng dẫn. Chi tiết hướng dẫn được hiển thị trong Bảng 2, chủ yếu bao gồm bốn thành phần.

1.Tiền tố nhiệm vụ : Thành phần này hướng dẫn LLMs đảm nhận vai trò của một trợ lý AI.
2.Mô tả nhiệm vụ : Ở đây, nhiệm vụ cụ thể mà LLMs được yêu cầu hoàn thành được nêu rõ.
3.Đầu vào : Điều này tương ứng với các câu không tuân thủ ngữ pháp được sử dụng làm đầu vào trong quá trình tinh chỉnh.
4.Đầu ra : Điều này đại diện cho các câu tuân thủ ngữ pháp, phục vụ như đầu ra mong đợi trong quá trình tinh chỉnh.

8https://github.com/chatopera/Synonyms

--- TRANG 8 ---
8 Fan et al.
Bảng 4. Chi tiết về các siêu tham số.
Backbone phoenix-inst-chat-7b
Độ dài tối đa 256
Optimizer AdamW
Kích thước batch 64
Epoch 1
Tốc độ học 2e-5
Loại lịch trình lr Linear
Bước khởi động 5

4 Thí nghiệm
4.1 Bộ dữ liệu
Chúng tôi xây dựng tổng cộng 1061 mẫu dữ liệu song song để huấn luyện, và thống kê dữ liệu được cung cấp trong Bảng 3. Khoảng 35% dữ liệu được chú thích thủ công, trong khi 65% còn lại được tạo bằng ChatGPT. Để đánh giá hiệu suất của mô hình, chúng tôi sử dụng tập xác thực có sẵn trên trang web NLPCC2023 SharedTask19, bao gồm 500 mẫu dữ liệu song song. Chúng tôi báo cáo hiệu suất của mô hình trên tập xác thực này cho tất cả các thí nghiệm được tiến hành.

4.2 Chỉ số
Việc đánh giá một hệ thống sửa lỗi ngữ pháp dựa vào mức độ mà các chỉnh sửa hoặc sửa đổi được đề xuất của nó phù hợp với các chỉnh sửa tiêu chuẩn vàng [11]. Phù hợp với nghiên cứu trước đây [10,26], chúng tôi áp dụng Trình Chấm điểm MaxMatch (M2) cấp từ và cấp ký tự [3] để đánh giá10. Trình chấm điểm này tính toán Độ chính xác, Độ nhớ lại và điểm F 0.5, so sánh tập chỉnh sửa vàng với tập chỉnh sửa hệ thống.

4.3 Siêu tham số
Các mô hình được triển khai trong PyTorch sử dụng Huggingface Transformers11. Chúng tôi sử dụng phoenix-inst-chat-7b12[2] làm backbone. Chúng tôi đặt độ dài chuỗi tối đa là 256. Mô hình được huấn luyện với optimizer AdamW, trong đó kích thước batch và epoch được đặt lần lượt là 64 và 3. Chúng tôi đặt tốc độ học và loại lịch trình của tốc độ học lần lượt là 2e-5 và 'linear'. Bước khởi động được đặt là 5. Các siêu tham số được hiển thị trong Bảng 4.

9https://github.com/masr2000/NaCGEC
10https://github.com/HillZhang1999/MuCGEC/tree/main/scorers/ChERRANT
11https://huggingface.co/
12https://huggingface.co/FreedomIntelligence/phoenix-inst-chat-7b

--- TRANG 9 ---
GrammarGPT 9
Bảng 5. So sánh hiệu suất giữa GrammarGPT và baseline SOTA.
Mô hình #Param. Dữ liệu Kích thước dữ liệuCấp từ Cấp ký tự
Prec Rec F 0.5Prec Rec F 0.5
S2SBART 375MLang8
HSK1.2M 22.31 10.14 17.99 22.13 9.66 17.59
S2SBART 375M Của chúng tôi 1061 21.08 10.54 17.57 22.09 10.62 18.16
GrammarGPT 7B Của chúng tôi 1061 42.42 16.87 32.56 46.67 18.58 35.84

Bảng 6. Nghiên cứu loại bỏ của phương pháp chúng tôi.
Dữ liệuCấp từ Cấp ký tự
Prec Rec F 0.5Prec Rec F 0.5
w/o Tăng cườngĐược chú thích bởi con người 12.20 1.51 5.04 13.89 1.48 5.19
Được tạo bởi ChatGPT 30.38 7.21 18.49 30.86 7.35 18.83
Bộ dữ liệu kết hợp 41.76 11.45 27.30 44.32 11.50 28.22
w/ Tăng cườngĐược chú thích bởi con người 15.46 4.52 10.42 16.48 4.44 10.68
Được tạo bởi ChatGPT 43.75 6.33 20.04 44.90 6.49 20.56
Bộ dữ liệu kết hợp 42.42 16.87 32.56 46.87 18.58 35.84

4.4 Kết quả Thí nghiệm
Để xác thực hiệu quả của phương pháp chúng tôi, chúng tôi tiến hành so sánh giữa GrammarGPT của chúng tôi và baseline tiên tiến nhất (SOTA), S2S BART [26]. S2SBART sử dụng Chinese BART làm mô hình được huấn luyện trước và tinh chỉnh nó trên các bộ dữ liệu Lang8 [28] và HSK [23], bao gồm khoảng 1.2 triệu mẫu dữ liệu song song. Chúng tôi cũng tinh chỉnh S2S BART trên bộ dữ liệu kết hợp mà chúng tôi xây dựng, và kết quả được trình bày trong Bảng 5.

Đáng chú ý, chúng tôi quan sát thấy rằng S2S BART được huấn luyện trên bộ dữ liệu kết hợp 1k của chúng tôi đạt được 17.57 và 18.16 F0.5trên Cấp từ và Cấp ký tự tương ứng, có thể so sánh với mô hình baseline sử dụng 1.2M dữ liệu từ người nói ngoại ngữ. Chúng tôi cho rằng điều này là do sự khác biệt đáng kể giữa các lỗi ngữ pháp do người nói ngoại ngữ và người Trung Quốc bản địa mắc phải, khiến việc cải thiện hiệu quả hiệu suất của CGEC bản địa bằng cách chỉ dựa vào dữ liệu từ người nói ngoại ngữ trở nên thách thức. Những kết quả này tiếp tục làm nổi bật hiệu quả của phương pháp chúng tôi trong việc xây dựng bộ dữ liệu kết hợp chứa các lỗi ngữ pháp tiếng Trung bản địa.

Hơn nữa, GrammarGPT của chúng tôi thể hiện sự cải thiện đáng kể chỉ với khoảng 1k mẫu dữ liệu để tinh chỉnh, đạt được 32.56 và 35.84 F0.5, tương ứng. Gần như gấp đôi hiệu suất của các mô hình baseline, thể hiện tiềm năng đáng chú ý của các LLM mã nguồn mở trong CGEC bản địa. Kết quả cuối cùng trên tập thử nghiệm chính thức cho thấy GrammarGPT của chúng tôi đứng thứ 313.

13https://github.com/masr2000/NaCGEC

--- TRANG 10 ---
10 Fan et al.
4.5 Nghiên cứu Loại bỏ
Trong phân tích của chúng tôi về tác động của các đóng góp của chúng tôi, cụ thể là việc xây dựng bộ dữ liệu kết hợp và phương pháp tăng cường bất biến lỗi, chúng tôi trình bày kết quả trong Bảng 6.

Đáng chú ý, mô hình được huấn luyện trên dữ liệu được tạo bởi ChatGPT luôn vượt trội hơn mô hình được huấn luyện trên dữ liệu được chú thích bởi con người, bất kể việc áp dụng tăng cường dữ liệu hay không. Chúng tôi cho rằng quan sát này có hai lý do chính. Đầu tiên, số lượng dữ liệu được chú thích bởi con người nhỏ hơn dữ liệu được tạo bởi ChatGPT do chi phí cao của việc chú thích bởi con người. Thứ hai, các lỗi ngữ pháp không có manh mối khó sửa hơn.

Ngoài ra, bộ dữ liệu kết hợp của chúng tôi chứng minh tiềm năng trong việc nâng cao hiệu suất của CGEC bản địa. Phát hiện này chứng thực hiệu quả của phương pháp chúng tôi trong việc xây dựng bộ dữ liệu kết hợp bao gồm các lỗi ngữ pháp tiếng Trung bản địa.

Hơn nữa, bằng cách sử dụng phương pháp tăng cường bất biến lỗi, chúng tôi quan sát thấy mô hình được huấn luyện trên bộ dữ liệu kết hợp có cải thiện đáng kể trong các chỉ số Độ nhớ lại và F 0.5nhưng chỉ có cải thiện nhỏ trong Độ chính xác. Điều này cho thấy rằng kỹ thuật tăng cường của chúng tôi nâng cao khả năng phát hiện lỗi ngữ pháp của mô hình bằng cách buộc mô hình chú ý nhiều hơn đến các lỗi ngữ pháp trong dữ liệu tăng cường.

5 Kết luận
Trong bài báo này, chúng tôi giới thiệu GrammarGPT, một Mô hình Ngôn ngữ Lớn mã nguồn mở (LLM) được thiết kế đặc biệt cho việc sửa lỗi ngữ pháp tiếng Trung bản địa. Đầu tiên chúng tôi xây dựng một bộ dữ liệu kết hợp chứa khoảng 1k mẫu dữ liệu song song. Nó bao gồm cả dữ liệu được tạo bởi ChatGPT và dữ liệu được chú thích bởi con người để xử lý các lỗi ngữ pháp có và không có manh mối. Ngoài ra, chúng tôi giới thiệu một phương pháp tăng cường bất biến lỗi để cải thiện khả năng của mô hình trong việc sửa lỗi ngữ pháp tiếng Trung bản địa bằng cách buộc mô hình chú ý nhiều hơn đến các lỗi ngữ pháp trong dữ liệu tăng cường. Chúng tôi tiếp tục tinh chỉnh mô hình ngôn ngữ quy mô lớn mã nguồn mở trên bộ dữ liệu được xây dựng. Kết quả thí nghiệm và phân tích sâu chứng minh hiệu quả của GrammarGPT của chúng tôi trong việc sửa lỗi ngữ pháp tiếng Trung bản địa.

Lời cảm ơn
Nghiên cứu này được hỗ trợ bởi Quỹ Khoa học Tự nhiên Quốc gia Trung Quốc (Số hiệu 62271432) và Phòng thí nghiệm Trọng điểm cấp tỉnh Quảng Đông về Điện toán Dữ liệu Lớn, Đại học Trung văn Hong Kong, Thâm Quyến (Số hiệu B10120210117).

--- TRANG 11 ---
GrammarGPT 11
Tài liệu tham khảo
1. Chen, F., Feng, Y.: Chain-of-Thought Prompt Distillation for Multimodal Named Entity and Multimodal Relation Extraction. ArXiv preprint arXiv:2306.14122 (2023)
2. Chen, Z., Jiang, F., Chen, J., Wang, T., Yu, F., Chen, G., Zhang, H., Liang, J., Zhang, C., Zhang, Z., et al.: Phoenix: Democratizing ChatGPT across languages. arXiv preprint arXiv:2304.10453 (2023)
3. Dahlmeier, D., Ng, H.T.: Better Evaluation for Grammatical Error Correction. In: Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. pp. 568–572. Association for Computational Linguistics, Montr´eal, Canada (Jun 2012)
4. Fang, T., Yang, S., Lan, K., Wong, D.F., Hu, J., Chao, L.S., Zhang, Y.: Is ChatGPT a Highly Fluent Grammatical Error Correction System? A Comprehensive Evaluation. arXiv preprint arXiv:2304.01746 (2023)
5. Hinson, C., Huang, H.H., Chen, H.H.: Heterogeneous Recycle Generation for Chinese Grammatical Error Correction. In: Proceedings of the 28th International Conference on Computational Linguistics. pp. 2191–2201 (2020)
6. Ho, N., Schmid, L., Yun, S.Y.: Large Language Models Are Reasoning Teachers. arXiv preprint arXiv:2212.10071 (2022)
7. Katsumata, S., Komachi, M.: Stronger Baselines for Grammatical Error Correction Using a Pretrained Encoder-Decoder Model. In: Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing. pp. 827–832 (2020)
8. Li, J., Guo, J., Zhu, Y., Sheng, X., Jiang, D., Ren, B., Xu, L.: Sequence-to-Action: Grammatical Error Correction with Action Guided Sequence Generation. Proceedings of the AAAI Conference on Artificial Intelligence 36(10), 10974–10982 (2022)
9. Liang, D., Zheng, C., Guo, L., Cui, X., Xiong, X., Rong, H., Dong, J.: BERT Enhanced Neural Machine Translation and Sequence Tagging Model for Chinese Grammatical Error Diagnosis. In: Proceedings of the 6th Workshop on Natural Language Processing Techniques for Educational Applications. pp. 57–66. Association for Computational Linguistics (2020)
10. Ma, S., Li, Y., Sun, R., Zhou, Q., Huang, S., Zhang, D., Yangning, L., Liu, R., Li, Z., Cao, Y., Zheng, H., Shen, Y.: Linguistic Rules-Based Corpus Generation for Native Chinese Grammatical Error Correction. In: Findings of the Association for Computational Linguistics: EMNLP 2022. pp. 576–589 (2022)
11. Ng, H.T., Wu, S.M., Briscoe, T., Hadiwinoto, C., Susanto, R.H., Bryant, C.: The CoNLL-2014 Shared Task on Grammatical Error Correction. In: Proceedings of the Eighteenth Conference on Computational Natural Language Learning: Shared Task. pp. 1–14 (2014)
12. Peng, B., Li, C., He, P., Galley, M., Gao, J.: Instruction Tuning with GPT-4. arXiv preprint arXiv:2304.03277 (2023)
13. Rao, G., Gong, Q., Zhang, B., Xun, E.: Overview of NLPTEA-2018 Share Task Chinese Grammatical Error Diagnosis. In: Proceedings of the 5th Workshop on Natural Language Processing Techniques for Educational Applications. pp. 42–51 (2018)
14. Rao, G., Yang, E., Zhang, B.: Overview of NLPTEA-2020 Shared Task for Chinese grammatical error diagnosis. In: Proceedings of the 6th Workshop on Natural Language Processing Techniques for Educational Applications. pp. 25–35 (2020)

--- TRANG 12 ---
12 Fan et al.
15. Rothe, S., Mallinson, J., Malmi, E., Krause, S., Severyn, A.: A Simple Recipe for Multilingual Grammatical Error Correction. In: Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers). pp. 702–707 (2021)
16. Sanh, V., Webson, A., Raffel, C., Bach, S.H., Sutawika, L., Alyafeai, Z., Chaffin, A., Stiegler, A., Scao, T.L., Raja, A., et al.: Multitask Prompted Training Enables Zero-shot Task Generalization. arXiv preprint arXiv:2110.08207 (2021)
17. Scao, T.L., Fan, A., Akiki, C., Pavlick, E., Ili´c, S., Hesslow, D., Castagn´e, R., Luccioni, A.S., Yvon, F., Gall´e, M., et al.: Bloom: A 176B-parameter Open-access Multilingual Language Model. arXiv preprint arXiv:2211.05100 (2022)
18. Touvron, H., Lavril, T., Izacard, G., Martinet, X., Lachaux, M.A., Lacroix, T., Rozi`ere, B., Goyal, N., Hambro, E., Azhar, F., Rodriguez, A., Joulin, A., Grave, E., Lample, G.: LLaMA: Open and Efficient Foundation Language Models (2023)
19. Wang, P., Wang, Z., Li, Z., Gao, Y., Yin, B., Ren, X.: SCOTT: Self-Consistent Chain-of-Thought Distillation. arXiv preprint arXiv:2305.01879 (2023)
20. Wang, X., Zhou, W., Zu, C., Xia, H., Chen, T., Zhang, Y., Zheng, R., Ye, J., Zhang, Q., Gui, T., et al.: InstructUIE: Multi-task Instruction Tuning for Unified Information Extraction. arXiv preprint arXiv:2304.08085 (2023)
21. Wei, J., Bosma, M., Zhao, V.Y., Guu, K., Yu, A.W., Lester, B., Du, N., Dai, A.M., Le, Q.V.: Finetuned Language Models Are Zero-shot Learners. arXiv preprint arXiv:2109.01652 (2021)
22. Yu, J., Zhu, J., Wang, Y., Liu, Y., Chang, H., Nie, J., Kong, C., Cong, R., XinLiu, An, J., Lu, L., Fang, M., Zhu, L.: Taoli LLaMA. https://github.com/blcuicall/taoli (2023)
23. Zhang, B.: Features and Functions of the HSK Dynamic Composition Corpus. International Chinese Language Education 4, 71–79 (2009)
24. Zhang, B., Yang, H., Liu, X.Y.: Instruct-FinGPT: Financial Sentiment Analysis by Instruction Tuning of General-Purpose Large Language Models. arXiv preprint arXiv:2306.12659 (2023)
25. Zhang, H., Chen, J., Jiang, F., Yu, F., Chen, Z., Li, J., Chen, G., Wu, X., Zhang, Z., Xiao, Q., et al.: HuatuoGPT, towards Taming Language Model to Be a Doctor. arXiv preprint arXiv:2305.15075 (2023)
26. Zhang, Y., Li, Z., Bao, Z., Li, J., Zhang, B., Li, C., Huang, F., Zhang, M.: MuCGEC: a Multi-Reference Multi-Source Evaluation Dataset for Chinese Grammatical Error Correction. In: Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. pp. 3118–3130 (2022)
27. Zhang, Y., Zhang, B., Jiang, H., Li, Z., Li, C., Huang, F., Zhang, M.: NaSGEC: a Multi-Domain Chinese Grammatical Error Correction Dataset from Native Speaker Texts. arXiv preprint arXiv:2305.16023 (2023)
28. Zhao, Y., Jiang, N., Sun, W., Wan, X.: Overview of the NLPCC 2018 Shared Task: Grammatical Error Correction. In: Natural Language Processing and Chinese Computing: 7th CCF International Conference, NLPCC 2018, Hohhot, China, August 26–30, 2018, Proceedings, Part II 7. pp. 439–445. Springer (2018)
29. Zhao, Z., Wang, H.: MaskGEC: Improving Neural Grammatical Error Correction via Dynamic Masking. Proceedings of the AAAI Conference on Artificial Intelligence 34(01), 1226–1233 (2020)

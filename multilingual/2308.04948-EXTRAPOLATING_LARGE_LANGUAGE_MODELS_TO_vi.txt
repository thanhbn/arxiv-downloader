NGOẠI SUY CÁC MÔ HÌNH NGÔN NGỮ LỚN SANG
TIẾNG KHÔNG PHẢI TIẾNG ANH BẰNG CÁCH CĂNH CHỈNH NGÔN NGỮ

Wenhao Zhu1, Yunzhe Lv1, Qingxiu Dong2, Fei Yuan3, Jingjing Xu3
Shujian Huang1,Lingpeng Kong4, Jiajun Chen1, Lei Li5
1Phòng thí nghiệm trọng điểm quốc gia về công nghệ phần mềm mới, Đại học Nam Kinh
2Đại học Bắc Kinh3Phòng thí nghiệm AI Thượng Hải4Đại học Hồng Kông
5Đại học California, Santa Barbara
zhuwh@smail.nju.edu.cn ,lvyz@smail.nju.edu.cn ,dqx@stu.pku.edu.cn
yuanfei@pjlab.org.cn ,jingjingxu@pku.edu.cn ,huangsj@nju.edu.cn
lpk@cs.hku.hk ,chenjj@nju.edu.cn ,lilei@cs.ucsb.edu

TÓM TẮT

Các mô hình ngôn ngữ lớn hiện tại thể hiện khả năng khác biệt đáng kể giữa các ngôn ngữ khác nhau, do sự mất cân bằng trong dữ liệu huấn luyện. Hiệu suất của chúng trên các tác vụ tiếng Anh thường mạnh hơn so với các tác vụ của các ngôn ngữ khác. Trong bài báo này, chúng tôi tăng cường các LLM được huấn luyện trước trên các ngôn ngữ không phải tiếng Anh bằng cách xây dựng sự căn chỉnh ngữ nghĩa giữa các ngôn ngữ. Chúng tôi bắt đầu từ việc nhắm mục tiêu từng ngôn ngữ cụ thể bằng cách thực hiện điều chỉnh hướng dẫn đa ngôn ngữ (CoIT) trên LLaMA, tức là điều chỉnh nó với dữ liệu tác vụ dịch thuật và dữ liệu tác vụ tổng quát đa ngôn ngữ để có được các mô hình đa ngôn ngữ (x-LLaMAs), và xây dựng các quy luật tỷ lệ cơ bản để điều tra các lợi thế của việc sử dụng dữ liệu dịch thuật có thể mở rộng. Sau đó chúng tôi thực hiện điều chỉnh hướng dẫn đa ngôn ngữ (MuIT) với các tài nguyên hỗn hợp để xây dựng m-LLaMA đa ngôn ngữ. Chúng tôi cũng minh họa cách chúng tôi tận dụng các quy luật tỷ lệ để tối ưu hóa phân bổ dữ liệu trong bối cảnh hạn chế tài nguyên. Kết quả thí nghiệm trên các tiêu chuẩn đa ngôn ngữ XQUAD và MLQA cho thấy x-LLaMAs vượt trội hơn bản tiếng Anh được điều chỉnh hướng dẫn (Alpaca) trung bình 27,83% trên sáu ngôn ngữ không phải tiếng Anh. Kết quả đánh giá trên bộ dữ liệu dịch thuật FLORES-101 cho thấy x-LLaMAs hoạt động tốt hơn các mô hình dựa trên LLaMA trước đó trung bình 18,89%. Đáng khích lệ, m-LLaMA đạt được hiệu suất tương đương với x-LLaMAs trên từng ngôn ngữ và chứng minh khả năng tuân theo hướng dẫn đa ngôn ngữ. Phân tích sâu hơn về nội dung phản hồi và không gian biểu diễn tiết lộ sự căn chỉnh của không gian ngữ nghĩa đa ngôn ngữ trong các lớp giữa của m-LLaMA.

1 GIỚI THIỆU

Khả năng ngôn ngữ của các LLM thường mất cân bằng giữa các ngôn ngữ (Zhu et al., 2023; Yang et al., 2023; Zhang et al., 2023), bởi vì cả kho văn bản huấn luyện trước (Blevins & Zettlemoyer, 2022) và dữ liệu điều chỉnh hướng dẫn (Wang et al., 2023b) đều bị chi phối bởi tiếng Anh. Kết quả là, các LLM thường hoạt động kém trên các ngôn ngữ không phải tiếng Anh, đặc biệt là trên các ngôn ngữ khác biệt so với tiếng Anh (Bang et al., 2023; Huang et al., 2023).

Đã có một số nỗ lực nhằm tăng cường khả năng tiếng không phải tiếng Anh của LLM bằng cách tiếp tục huấn luyện trước với kho văn bản đơn ngữ quy mô lớn (Cui et al., 2023; Yang et al., 2023). Tuy nhiên, việc học một ngôn ngữ từ dữ liệu đơn ngữ có thể cần dữ liệu quy mô lớn và tính toán.

Trong bài báo này, chúng tôi khai thác khả năng tiếng không phải tiếng Anh của các LLM được huấn luyện trước bằng cách xây dựng sự căn chỉnh ngữ nghĩa giữa tiếng Anh và tiếng không phải tiếng Anh. Để ngoại suy khả năng tiếng Anh sang một ngôn ngữ không phải tiếng Anh cụ thể, chúng tôi đề xuất một cài đặt đa tác vụ kết hợp các tác vụ dịch thuật và các tác vụ tổng quát đa ngôn ngữ trong quá trình điều chỉnh hướng dẫn. Các tác vụ dịch thuật được sử dụng để kích thích sự căn chỉnh ngữ nghĩa giữa các ngôn ngữ, trong khi các tác vụ tổng quát đa ngôn ngữ tăng cường khả năng tuân theo hướng dẫn của các mô hình (Hình 1). Việc điều chỉnh hướng dẫn đa ngôn ngữ (CoIT) này tạo ra một mô hình đa ngôn ngữ phù hợp với một ngôn ngữ không phải tiếng Anh cụ thể.

Tiếp theo, chúng tôi khám phá việc ngoại suy LLM sang nhiều ngôn ngữ đồng thời thông qua điều chỉnh hướng dẫn đa ngôn ngữ (MuIT) với các tài nguyên đa ngôn ngữ hỗn hợp (Hình 1). Chúng tôi xem xét hai cài đặt cụ thể trong nghiên cứu của mình. Trong cài đặt đầu tiên, chúng tôi đơn giản kết hợp tất cả các tài nguyên có sẵn để điều chỉnh hướng dẫn nhằm có được LLM đa ngôn ngữ. Trong cài đặt thứ hai, chúng tôi xem xét một kịch bản thực tế trong đó việc điều chỉnh hướng dẫn được thực hiện dưới một ngân sách dữ liệu cụ thể. Để đạt được phân bổ dữ liệu tối ưu, chúng tôi xây dựng tác vụ này như một bài toán lập trình phi tuyến dựa trên các quy luật tỷ lệ đã phát hiện trước đó. Mục tiêu của việc tối ưu hóa này là tối đa hóa hiệu suất đa ngôn ngữ trung bình.

Trong các thí nghiệm, chúng tôi sử dụng LLaMA-7B làm LLM được huấn luyện trước và xem xét sáu ngôn ngữ mục tiêu thách thức ít có chữ cái chung với tiếng Anh. Đối với mỗi ngôn ngữ, một x-LLaMA riêng biệt được tạo ra với dữ liệu cụ thể theo ngôn ngữ. Và một m-LLaMA được tạo ra với dữ liệu đa ngôn ngữ hỗn hợp.

Kết quả thí nghiệm trên hai tiêu chuẩn đa ngôn ngữ XQUAD và MLQA cho thấy x-LLaMAs vượt trội hơn mô hình được điều chỉnh với hướng dẫn tiếng Anh (Alpaca-7B) trung bình 27,83%. Đáng chú ý, độ chính xác của x-LLaMAs trên các tác vụ không phải tiếng Anh tương đương với hiệu suất của Alpaca-7B trên các tác vụ tiếng Anh. Chúng tôi cũng quan sát thấy rằng x-LLaMAs thể hiện khả năng dịch thuật mạnh mà không cần tiếp tục huấn luyện trước quy mô lớn. Kết quả đánh giá trên bộ dữ liệu dịch thuật đa ngôn ngữ FLORES-101 cho thấy x-LLaMAs hoạt động tốt hơn các mô hình dựa trên LLaMA trước đó trung bình 18,89% và thậm chí vượt trội hơn hệ thống dịch thuật đa ngôn ngữ có giám sát M2M-12B (Fan et al., 2021) trong một nửa số hướng dịch thuật được đánh giá.

Trong cài đặt đầu tiên của điều chỉnh hướng dẫn đa ngôn ngữ, chúng tôi phát hiện rằng m-LLaMA có thể đạt được hiệu suất tương đương với các x-LLaMA mạnh trên từng ngôn ngữ. Hơn nữa, m-LLaMA hiện có khả năng tuân theo hướng dẫn đa ngôn ngữ. Phân tích sâu hơn về nội dung phản hồi và không gian biểu diễn tiết lộ rằng m-LLaMA có xu hướng tạo ra phản hồi không phải tiếng Anh dựa trên bộ nhớ tiếng Anh của nó và không gian ngữ nghĩa đa ngôn ngữ trở nên căn chỉnh trong các lớp giữa của m-LLaMA, chứng minh tính hiệu quả của các phương pháp của chúng tôi. Trong cài đặt hạn chế tài nguyên, kết quả thí nghiệm cho thấy phân bổ dữ liệu được tối ưu hóa của chúng tôi mang lại hiệu suất đa ngôn ngữ cao hơn so với phân bổ đồng đều, điều này thể hiện việc sử dụng thực tế các quy luật tỷ lệ đã xây dựng của chúng tôi.

Đóng góp chính của bài báo này có thể được tóm tắt như sau:

• Chúng tôi khám phá điều chỉnh hướng dẫn đa ngôn ngữ (CoIT) và điều chỉnh hướng dẫn đa ngôn ngữ (MuIT) để khai thác khả năng tiếng không phải tiếng Anh của LLM.

• Kết quả thí nghiệm chứng minh rằng các phương pháp điều chỉnh hướng dẫn của chúng tôi có thể đồng thời tăng cường khả năng ngôn ngữ không phải tiếng Anh của LLM, ví dụ, tuân theo hướng dẫn đa ngôn ngữ, tạo ra phản hồi đa ngôn ngữ, và khả năng dịch thuật.

• Chúng tôi xây dựng quy luật tỷ lệ trong điều chỉnh hướng dẫn đa ngôn ngữ và thiết kế một chiến lược phân bổ dữ liệu dựa trên các quy luật đã xây dựng cho điều chỉnh hướng dẫn đa ngôn ngữ hạn chế tài nguyên.

• Chúng tôi so sánh quy luật tỷ lệ của điều chỉnh hướng dẫn đa ngôn ngữ và tiếp tục huấn luyện trước, và cho thấy rằng căn chỉnh ngôn ngữ là một lựa chọn hiệu quả hơn.

2 KIẾN THỨC NỀN TẢNG

Để mở khóa tiềm năng của các LLM được huấn luyện trước, Wei et al. (2022) đề xuất điều chỉnh hướng dẫn. Trong giai đoạn này, LLM sẽ được cung cấp dữ liệu hướng dẫn {T, X, Y}, trong đó T là một hướng dẫn tác vụ mô tả yêu cầu của tác vụ. X là một đầu vào tùy chọn và Y là đầu ra mong muốn cho tác vụ đã cho. Mục tiêu của giai đoạn tối ưu hóa này là tối thiểu hóa log-likelihood âm sau đây.

arg min θ 1/|D| Σ{T,X,Y}∈D −log pθ(Y|T, X) (1)

trong đó θ biểu thị các tham số có thể học của LLM và D biểu thị bộ dữ liệu điều chỉnh hướng dẫn.

Bộ dữ liệu điều chỉnh hướng dẫn thường bao gồm các tác vụ đa dạng, điều này được thấy là có lợi cho việc tổng quát hóa đối với các hướng dẫn và tác vụ chưa thấy (Wei et al., 2022). Tuy nhiên, chúng tôi nhận thấy rằng các bộ dữ liệu điều chỉnh hướng dẫn thường được sử dụng, ví dụ ALPACA (Taori et al., 2023), FLAN (Longpre et al., 2023) bị chi phối bởi tiếng Anh, điều này hạn chế tiềm năng của LLM trong việc tuân theo hướng dẫn không phải tiếng Anh và giải quyết các tác vụ không phải tiếng Anh.

3 KHAI THÁC KHẢNĂNG TIẾNG KHÔNG PHẢI TIẾNG ANH CỦA LLM

Tăng cường LLM trên nhiều ngôn ngữ hơn ngoài tiếng Anh là không hề đơn giản. Huấn luyện một LLM từ đầu cho mỗi ngôn ngữ không phải tiếng Anh gần như không khả thi do chi phí khổng lồ của việc thu thập dữ liệu và tính toán. Trong bài báo này, chúng tôi khám phá việc khai thác khả năng tiếng không phải tiếng Anh của LLM được huấn luyện trước bằng cách tăng cường sự căn chỉnh ngữ nghĩa giữa tiếng Anh và các ngôn ngữ mục tiêu. Chúng tôi bắt đầu bằng việc nhắm mục tiêu một ngôn ngữ đơn lẻ bằng cách thực hiện điều chỉnh hướng dẫn đa ngôn ngữ (CoIT, §3.1). Để hiểu rõ hơn tiềm năng của việc căn chỉnh ngôn ngữ, chúng tôi thiết kế một công thức để mô tả quy luật tỷ lệ trong CoIT (§3.2). Cuối cùng, chúng tôi giới thiệu điều chỉnh hướng dẫn đa ngôn ngữ (MuIT), nhằm mục đích khai thác khả năng ngôn ngữ của LLM trên nhiều ngôn ngữ không phải tiếng Anh đồng thời, và trình bày một cách sử dụng tiềm năng của quy luật tỷ lệ trong phân bổ dữ liệu đa ngôn ngữ (§3.3).

3.1 ĐIỀU CHỈNH HƯỚNG DẪN ĐA NGÔN NGỮ

Để khai thác khả năng tiếng không phải tiếng Anh của LLM, chúng tôi thực hiện điều chỉnh hướng dẫn đa ngôn ngữ (được minh họa trong Hình 1) với dữ liệu đa tác vụ, bao gồm dữ liệu hướng dẫn tác vụ tổng quát đa ngôn ngữ DG và dữ liệu hướng dẫn tác vụ dịch thuật DT.

Dữ liệu hướng dẫn tác vụ tổng quát DG Xem xét rằng bộ dữ liệu điều chỉnh hướng dẫn thường được sử dụng gần như hoàn toàn bằng tiếng Anh, chúng tôi dịch nó sang phiên bản nước ngoài bằng một công cụ dịch thuật. Sau đó chúng tôi sử dụng cả phiên bản tiếng Anh và không phải tiếng Anh làm dữ liệu hướng dẫn tác vụ tổng quát đa ngôn ngữ. Cách tiếp cận này nhằm khuyến khích LLM hiểu rõ hơn và tuân theo hướng dẫn đa ngôn ngữ.

Dữ liệu hướng dẫn tác vụ dịch thuật DT Một cách trực quan, dữ liệu dịch thuật là một tài nguyên có giá trị để học sự căn chỉnh ngữ nghĩa. Các nghiên cứu trước đây cũng đã chỉ ra rằng hiệu suất dịch thuật của LLM có thể được tăng cường bằng cách sử dụng dữ liệu dịch thuật được chú thích bởi chuyên gia Jiao et al. (2023); Zhang et al. (2023) để điều chỉnh hướng dẫn. Khác với họ, chúng tôi sử dụng các kho văn bản song song có sẵn công khai, ví dụ WIKIMATRIX (Schwenk et al., 2021), NEWSCOMMENTARY (Tiedemann, 2012), để xây dựng dữ liệu hướng dẫn tác vụ dịch thuật, làm cho phương pháp của chúng tôi có thể tái tạo, mở rộng và có thể mở rộng sang nhiều ngôn ngữ hơn.

Trong khi cả dữ liệu dịch thuật En-X (dịch tiếng Anh sang tiếng không phải tiếng Anh) và X-En (dịch tiếng không phải tiếng Anh sang tiếng Anh) đều có lợi cho việc học sự căn chỉnh ngữ nghĩa, chúng tôi thấy rằng việc đặt văn bản không phải tiếng Anh ở phía mục tiêu của dữ liệu dịch thuật mang lại cải thiện hiệu suất tốt hơn cho LLM trên các tác vụ không phải tiếng Anh so với việc đặt nó ở phía nguồn. Phát hiện này sẽ được chứng minh thêm trong các thí nghiệm sắp tới.

3.2 QUY LUẬT TỶ LỆ CỦA ĐIỀU CHỈNH HƯỚNG DẪN ĐA NGÔN NGỮ

Chúng tôi sử dụng hiệu suất dịch thuật song ngữ như một chỉ báo của sự căn chỉnh ngữ nghĩa và thấy rằng quy mô của dữ liệu hướng dẫn tác vụ dịch thuật có tác động rất lớn đến nó. Để định lượng mối quan hệ giữa hiệu suất dịch thuật S và quy mô dữ liệu dịch thuật X, chúng tôi xây dựng quy luật tỷ lệ cơ bản dựa trên các trực giác sau: (1) Giới hạn trên của S là 100, đây là điểm số tối đa của các chỉ số chất lượng dịch thuật thường được sử dụng như COMET và BLEU. (2) Hiệu suất dịch thuật có xu hướng cải thiện khi quy mô dữ liệu dịch thuật tăng. (3) Các ngôn ngữ ít tương tự với tiếng Anh cần một lượng dữ liệu dịch thuật lớn hơn để thiết lập sự căn chỉnh ngữ nghĩa so với các ngôn ngữ tương tự hơn với tiếng Anh. Do đó, chúng tôi trình bày công thức cuối cùng của chúng tôi như sau:

S(X) = 100 − α·(γ· X)β (2)

trong đó α > 0 và β ∈ (−1,0) là các tham số cần ước lượng, γ ∈ (0,1) là độ tương tự ngôn ngữ giữa ngôn ngữ mục tiêu và tiếng Anh. Khi ước lượng quy luật tỷ lệ cho một ngôn ngữ cụ thể, trước tiên chúng tôi tính γ và sau đó ước lượng α và β với các điểm dữ liệu quan sát được. Trong phần tiếp theo, chúng tôi sẽ chứng minh thêm cách các quy luật tỷ lệ này có thể hỗ trợ chúng tôi trong việc tối ưu hóa phân bổ dữ liệu khi xây dựng LLM đa ngôn ngữ trong kịch bản hạn chế tài nguyên.

3.3 ĐIỀU CHỈNH HƯỚNG DẪN ĐA NGÔN NGỮ

Trong khi điều chỉnh hướng dẫn đa ngôn ngữ hiệu quả, việc phục vụ các LLM tùy chỉnh cho mỗi ngôn ngữ có thể tốn kém, đặc biệt khi số lượng ngôn ngữ tăng. Do đó, chúng tôi đi một bước xa hơn và điều tra khả năng ngoại suy một LLM được huấn luyện trước đơn lẻ sang nhiều ngôn ngữ không phải tiếng Anh đồng thời.

Để đạt được mục tiêu này, chúng tôi thực hiện điều chỉnh hướng dẫn đa ngôn ngữ với sự kết hợp của các tài nguyên đa ngôn ngữ. Điều này bao gồm dữ liệu hướng dẫn tác vụ tổng quát bằng nhiều ngôn ngữ và dữ liệu hướng dẫn tác vụ dịch thuật từ nhiều hướng. Bằng cách tận dụng các tài nguyên này, LLM được điều chỉnh hướng dẫn có thể thiết lập sự căn chỉnh giữa tiếng Anh và nhiều ngôn ngữ, cho phép nó hiểu và tuân theo hướng dẫn đa ngôn ngữ.

Về hỗn hợp dữ liệu, chúng tôi xem xét hai cài đặt. Trong cài đặt đầu tiên, chúng tôi kết hợp một cách đơn giản tất cả các tài nguyên có sẵn để điều chỉnh hướng dẫn. Nhưng một nhược điểm tiềm năng của cách tiếp cận này là việc điều chỉnh hướng dẫn LLM với dữ liệu đa ngôn ngữ quy mô lớn có thể tốn chi phí tính toán khổng lồ.

Do đó chúng tôi cũng xem xét một kịch bản thực tế, trong đó dữ liệu hướng dẫn được áp dụng bị hạn chế bởi một ngân sách dữ liệu cụ thể. Ví dụ, tổng lượng dữ liệu song song được sử dụng là một số cố định. Để đạt được sự kết hợp dữ liệu tối ưu trong kịch bản này, chúng tôi đề xuất xây dựng phân bổ dữ liệu như một bài toán lập trình phi tuyến. Mục tiêu của bài toán lập trình này là tối đa hóa hiệu suất đa ngôn ngữ trung bình:

max 1/n Σni=1 S(Xi), s.t. Σni=1 Xi = C, trong đó 0 ≤ Xi ≤ Xmaxi, i = 1,2,3···, n

Có hai ràng buộc trong công thức này: (i) ngân sách dữ liệu, tổng lượng dữ liệu hướng dẫn tác vụ dịch thuật bị giới hạn bởi một ngân sách cố định C. (ii) tính khả dụng của dữ liệu, số lượng tối đa của dữ liệu dịch thuật có sẵn cho ngôn ngữ i là Xmaxi.

4 CÀI ĐẶT THÍ NGHIỆM

LLM được huấn luyện trước Chúng tôi sử dụng LLaMA-7B làm LLM được huấn luyện trước, được huấn luyện trên hàng nghìn tỷ token (chủ yếu bằng tiếng Anh) và được thấy là cạnh tranh với các LLM tiên tiến (Touvron et al., 2023). Chúng tôi xây dựng x-LLaMAs cho sáu ngôn ngữ mục tiêu thách thức: tiếng Ả Rập (Ar), tiếng Hy Lạp (El), tiếng Hindi (Hi), tiếng Thổ Nhĩ Kỳ (Tr), tiếng Việt (Vi) và tiếng Trung (Zh), có ít chữ cái chung với tiếng Anh.

Các LLM cơ sở Để so sánh, chúng tôi bao gồm một số mô hình được xây dựng bằng cách điều chỉnh hướng dẫn trên LLaMA: Alpaca-7B (Taori et al., 2023), được điều chỉnh với hướng dẫn tiếng Anh; Parrot-7B (Jiao et al., 2023), được điều chỉnh với dữ liệu dịch thuật được chú thích bởi con người; Bayling-7B (Zhang et al., 2023), được điều chỉnh với dịch thuật tương tác của con người và dữ liệu hướng dẫn tiếng Anh. Chúng tôi cũng trình bày kết quả từ Chinese-Alpaca-7B (Cui et al., 2023) và Bigtrans-13B (Yang et al., 2023) để tham khảo. Cả hai mô hình này đều mở rộng từ vựng của LLaMA và sử dụng dữ liệu đơn ngữ quy mô lớn để tiếp tục huấn luyện trước.

Chi tiết điều chỉnh hướng dẫn Đối với dữ liệu hướng dẫn tác vụ dịch thuật, chúng tôi sử dụng các kho văn bản song song có sẵn công khai, WIKIMATRIX (Schwenk et al., 2021) và NEWSCOMMENTARY (Tiedemann, 2012). Các kho văn bản này dễ tiếp cận và có thể mở rộng hơn so với dữ liệu được chú thích bởi chuyên gia chi phí cao (Jiao et al., 2023; Zhang et al., 2023). Thống kê của hai bộ dữ liệu được trình bày trong Bảng 1. Đối với dữ liệu hướng dẫn tác vụ tổng quát đa ngôn ngữ, chúng tôi kết hợp bộ dữ liệu ALPACA (Taori et al., 2023), bao gồm 52k câu hỏi tiếng Anh và phản hồi tương ứng, và chúng tôi có được phiên bản nước ngoài của nó bằng công cụ dịch thuật nội bộ. Chúng tôi sử dụng stanford alpaca làm cơ sở mã. Thêm chi tiết huấn luyện được cung cấp trong Phụ lục A.

[Bảng thống kê kho văn bản song song]

Bộ dữ liệu đánh giá Để đánh giá hiệu suất của LLM trên các ngôn ngữ không phải tiếng Anh, chúng tôi sử dụng hai bộ dữ liệu tiêu chuẩn đa ngôn ngữ, XQUAD (Artetxe et al., 2020) và MLQA (Lewis et al., 2020), yêu cầu mô hình suy luận trên ngữ cảnh đã cho và trả lời câu hỏi đã cho. Ngoài ra, chúng tôi tạo ra một bộ đánh giá đa ngôn ngữ mới MI-EVAL (được giới thiệu trong Phụ lục B) để đánh giá khả năng của LLM trong việc tuân theo hướng dẫn đa ngôn ngữ. Các bộ kiểm tra đa hướng đa ngôn ngữ này cũng cho phép chúng tôi so sánh khả năng ngôn ngữ giữa các ngôn ngữ. Để đánh giá khả năng dịch thuật của LLM, chúng tôi làm theo Zhu et al. (2023) và sử dụng bộ dữ liệu dịch thuật đa ngôn ngữ FLORES-101 (Goyal et al., 2022). Chi tiết về các lời nhắc được sử dụng cho tất cả các tác vụ này được cung cấp trong Phụ lục C.

Các chỉ số đánh giá Trên XQUAD, MLQA và MI-EVAL, chúng tôi làm theo Liu et al. (2023) và Wang et al. (2023a) để sử dụng ChatGPT cho đánh giá chất lượng tạo ra. Trên XQUAD, MLQA, chúng tôi cũng báo cáo kết quả khớp chính xác trong Phụ lục D. Đối với các tác vụ dịch thuật, chúng tôi sử dụng COMET (Rei et al., 2020), BLEURT (Sellam et al., 2020) và sentence-piece BLEU (Papineni et al., 2002) làm chỉ số. Chi tiết đánh giá thêm có thể tham khảo Phụ lục D.

5 KẾT QUẢ CHÍNH

5.1 KẾT QUẢ VỀ ĐIỀU CHỈNH HƯỚNG DẪN ĐA NGÔN NGỮ

x-LLaMA đạt được cải thiện lớn trên các tác vụ QA không phải tiếng Anh Bảng 2 trình bày kết quả thí nghiệm cho các tác vụ trả lời câu hỏi không phải tiếng Anh. Chúng ta có thể thấy rằng Alpaca-7B hoạt động kém trên tiếng không phải tiếng Anh, mặc dù nó đạt 95% độ chính xác trả lời trên các câu hỏi tiếng Anh tương ứng. Đáng chú ý, x-LLaMA vượt trội hơn đối tác của nó (Alpaca-7B) trung bình 27,83% trên sáu ngôn ngữ không phải tiếng Anh. Quan trọng hơn, độ chính xác trả lời của x-LLaMA trên các tác vụ không phải tiếng Anh đang tiếp cận độ chính xác trả lời của Alpaca-7B trên các tác vụ tiếng Anh. Điều này cho thấy rằng điều chỉnh hướng dẫn đa ngôn ngữ là một cách hiệu quả để khai thác khả năng tiếng không phải tiếng Anh của LLM.

Bảng 2 cũng báo cáo hiệu suất đa ngôn ngữ của hai mô hình dựa trên LLaMA đại diện khác. Cả Chinese-Alpaca-7B (được huấn luyện trên kho văn bản tiếng Trung quy mô lớn) và Bayling-7B (được huấn luyện trên dữ liệu dịch thuật tương tác được chú thích bằng tiếng Trung) đều cho thấy hiệu suất ấn tượng trên tác vụ tiếng Trung. Nhưng chúng không hoạt động tốt trên năm ngôn ngữ khác. Vì dữ liệu huấn luyện được sử dụng của họ không thể dễ dàng có được, nên cũng khó mở rộng khung huấn luyện của họ để bao gồm nhiều ngôn ngữ hơn.

x-LLaMA cho thấy hiệu suất dịch thuật ấn tượng Hình 2 và Hình 9 (Phụ lục E) trình bày hiệu suất của x-LLaMA và các hệ thống cơ sở trong việc dịch giữa tiếng Anh và tiếng không phải tiếng Anh, điều này phục vụ như bằng chứng quan trọng cho sự căn chỉnh ngôn ngữ. So với các LLM dựa trên LLaMA khác, x-LLaMA thể hiện hiệu suất dịch thuật cao hơn trong tất cả các hướng được đánh giá. Đáng chú ý, x-LLaMA thậm chí vượt trội hơn baseline có giám sát mạnh M2M-12B (Fan et al., 2021) trên bốn hướng En-X (dịch tiếng Anh sang tiếng không phải tiếng Anh) và hai hướng X-En (dịch tiếng không phải tiếng Anh sang tiếng Anh), và đang tiếp cận các công cụ dịch thuật thương mại mạnh, ChatGPT và Google Translate.

Quy luật tỷ lệ của điều chỉnh hướng dẫn đa ngôn ngữ Bây giờ, chúng tôi điều tra hiệu suất dịch thuật của x-LLaMA dưới các quy mô dữ liệu dịch thuật khác nhau và trình bày các lợi thế của việc sử dụng dữ liệu hướng dẫn tác vụ dịch thuật có thể mở rộng cho sự căn chỉnh ngôn ngữ. Như được minh họa trong Hình 3, việc thêm dữ liệu dịch thuật luôn có lợi cho việc tăng cường sự căn chỉnh ngữ nghĩa. Đáng khích lệ, công thức được thiết kế của chúng tôi (được biểu thị bằng đường chấm) nắm bắt hiệu quả xu hướng và cung cấp mối quan hệ định lượng giữa hiệu suất dịch thuật và quy mô dữ liệu dịch thuật. Trong các thí nghiệm tiếp theo, chúng tôi sẽ chứng minh các ứng dụng thực tế của các quy luật tỷ lệ đã xây dựng này, ví dụ, tối ưu hóa phân bổ dữ liệu, phân tích hiệu quả học tập.

5.2 KẾT QUẢ VỀ ĐIỀU CHỈNH HƯỚNG DẪN ĐA NGÔN NGỮ

m-LLaMA đạt được hiệu suất tương đương với x-LLaMAs trên từng ngôn ngữ. Bây giờ chúng tôi kết hợp tất cả các tài nguyên có sẵn để xây dựng m-LLaMA. Chúng tôi so sánh hiệu suất của m-LLaMA với hiệu suất của x-LLaMAs được tùy chỉnh cho từng ngôn ngữ. Hình 4 cho thấy m-LLaMA có thể đạt được hiệu suất tương đương với x-LLaMAs trên các tác vụ QA không phải tiếng Anh và các tác vụ dịch thuật đa ngôn ngữ. Điều này cho thấy tính khả thi của việc ngoại suy LLaMA tiếng Anh được huấn luyện trước sang nhiều ngôn ngữ không phải tiếng Anh đồng thời.

m-LLaMA có thể xử lý hướng dẫn đa ngôn ngữ theo bộ nhớ tiếng Anh của nó. Quan trọng hơn, việc kết hợp nhiều ngôn ngữ vào một m-LLaMA đơn lẻ cho phép nó tuân theo hướng dẫn đa ngôn ngữ. Kết quả đánh giá trên MI-EVAL (Hình 4) cho thấy m-LLaMA có thể đạt được chất lượng phản hồi tương đương với x-LLaMAs khi được cung cấp hướng dẫn bằng các ngôn ngữ khác nhau. Ngoài ra, chúng tôi thấy rằng cách tiếp cận điều chỉnh hướng dẫn của chúng tôi có tác động nhỏ đến khả năng tiếng Anh của LLM nhưng làm cho m-LLaMA có xu hướng tạo ra phản hồi cho hướng dẫn không phải tiếng Anh với bộ nhớ tiếng Anh của nó. Bảng 3 cho thấy hai trường hợp đại diện trong đó m-LLaMA tạo ra phản hồi tương tự khi được đưa ra hướng dẫn bằng các ngôn ngữ khác nhau. Hiện tượng này cho thấy rằng tiếng Anh và tiếng không phải tiếng Anh trở nên căn chỉnh trong LLM sau khi điều chỉnh hướng dẫn của chúng tôi.

Kết quả trực quan hóa cho thấy không gian ngữ nghĩa đa ngôn ngữ trở nên căn chỉnh trong các lớp giữa của m-LLaMA. Để phân tích toàn diện, chúng tôi điều tra không gian biểu diễn của m-LLaMA và Alpaca-7B. Cụ thể, chúng tôi sử dụng chúng để mã hóa dữ liệu đa hướng đa ngôn ngữ từ bộ dữ liệu FLORES-101 và so sánh các biểu diễn được mã hóa qua các lớp khác nhau. Hình 5 hiển thị kết quả trực quan hóa. Đối với Alpaca-7B, các biểu diễn của các ngôn ngữ khác nhau luôn tách biệt từ các lớp dưới đến các lớp trên. Ngược lại, chúng tôi quan sát thấy sự chồng chéo biểu diễn trong m-LLaMA, đặc biệt là trong các lớp giữa, điều này cung cấp bằng chứng khác rằng điều chỉnh hướng dẫn đa ngôn ngữ khuyến khích sự căn chỉnh ngôn ngữ.

Các quy luật tỷ lệ đã xây dựng của chúng tôi có thể được sử dụng để tối ưu hóa phân bổ dữ liệu cho điều chỉnh hướng dẫn đa ngôn ngữ hạn chế dữ liệu. Trong cài đặt thứ hai của chúng tôi, chúng tôi nghiên cứu điều chỉnh hướng dẫn đa ngôn ngữ hạn chế dữ liệu và khám phá việc sử dụng các quy luật tỷ lệ đã xây dựng. Chúng tôi so sánh cách tiếp cận phân bổ được thiết kế của chúng tôi với phân bổ dữ liệu đồng đều trong Bảng 4. Kết quả thí nghiệm trộn lẫn. Khi ngân sách dữ liệu thấp, ví dụ 300k, khoảng cách giữa các chiến lược phân bổ dữ liệu khác nhau là nhỏ. Khi ngân sách dữ liệu đạt 1,2M, phân bổ được tối ưu hóa của chúng tôi đạt được hiệu suất dịch thuật đa ngôn ngữ trung bình cao hơn đáng kể so với phân bổ đồng đều trong tất cả ba chỉ số, điều này đáp ứng mục tiêu tối ưu hóa ban đầu của chúng tôi.

6 PHÂN TÍCH VÀ THẢO LUẬN

Nghiên cứu loại bỏ Chúng tôi tiến hành thí nghiệm với các kết hợp khác nhau của dữ liệu hướng dẫn cho nghiên cứu loại bỏ (Bảng 6). Điều chỉnh hướng dẫn LLaMA-7B với dữ liệu Alpaca tiếng Trung tốt hơn so với dữ liệu Alpaca tiếng Anh trên tác vụ tiếng Trung. Sử dụng kết hợp hai phiên bản dữ liệu Alpaca mang lại cải thiện thêm. Thú vị là, việc chỉ sử dụng dữ liệu hướng dẫn tác vụ dịch thuật có thể đạt được độ chính xác trả lời trung bình. Và chúng tôi thấy rằng đặt tiếng Trung ở phía mục tiêu của dữ liệu dịch thuật hữu ích hơn để tăng cường khả năng tiếng Trung của LLaMA. Sử dụng kết hợp dữ liệu hướng dẫn tác vụ tổng quát đa ngôn ngữ và dữ liệu hướng dẫn tác vụ dịch thuật En-Zh đạt được độ chính xác cao nhất.

Sử dụng dữ liệu dịch thuật hiệu quả hơn nhiều so với dữ liệu đơn ngữ để xây dựng sự căn chỉnh ngữ nghĩa. Sử dụng kho văn bản đơn ngữ của ngôn ngữ mục tiêu để tiếp tục huấn luyện trước là một cách khác để giúp LLM hiểu tiếng không phải tiếng Anh và cải thiện hiệu suất dịch thuật (Yang et al., 2023). Để so sánh, chúng tôi sử dụng kho văn bản đơn ngữ tiếng Trung MC4 (Xue et al., 2021) để tiếp tục huấn luyện trước và sử dụng dữ liệu tác vụ tổng quát đa ngôn ngữ để điều chỉnh hướng dẫn. Hình 7 so sánh quy luật tỷ lệ của hai cách tiếp cận. Chúng tôi quan sát thấy rằng việc sử dụng dữ liệu song song hiệu quả hơn nhiều so với việc sử dụng dữ liệu đơn ngữ để hoàn thành sự căn chỉnh ngữ nghĩa.

Thảo luận về mở rộng từ vựng cho tiếng không phải tiếng Anh. Khác với công trình trước đây (Cui et al., 2023; Yang et al., 2023), chúng tôi không mở rộng từ vựng cho các ngôn ngữ mục tiêu không phải tiếng Anh. Hiệu ứng này có hai mặt. Cách tiếp cận của chúng tôi không yêu cầu kho văn bản không phải tiếng Anh quy mô lớn để học embedding của các token mở rộng. Mặt khác, vì LLaMA thường tokenize các token không phải tiếng Anh thành byte, mô hình của chúng tôi chậm hơn trong việc mã hóa và giải mã chuỗi không phải tiếng Anh so với những mô hình được trang bị từ vựng mở rộng. Chúng tôi để việc khám phá thao tác từ vựng làm công việc tương lai.

7 KẾT LUẬN

Trong bài báo này, chúng tôi tập trung vào việc ngoại suy các mô hình ngôn ngữ lớn được huấn luyện trước sang tiếng không phải tiếng Anh bằng cách xây dựng sự căn chỉnh ngữ nghĩa giữa các ngôn ngữ. Cụ thể, chúng tôi khám phá hai cách tiếp cận: điều chỉnh hướng dẫn đa ngôn ngữ (CoIT) và điều chỉnh hướng dẫn đa ngôn ngữ (MuIT). Kết quả thí nghiệm cho thấy các mô hình đa ngôn ngữ của chúng tôi, x-LLaMAs, đạt được những cải thiện lớn trên tiếng không phải tiếng Anh, ví dụ vượt trội hơn đối tác tiếng Anh của nó (Alpaca-7B) 27,83% trên các tác vụ trả lời câu hỏi và 18,89% trên các tác vụ dịch thuật. Sau khi huấn luyện trên các tài nguyên đa ngôn ngữ hỗn hợp, mô hình m-LLaMA của chúng tôi có thể đạt được hiệu suất tương đương với các x-LLaMA mạnh trên từng ngôn ngữ và có khả năng tuân theo hướng dẫn đa ngôn ngữ. Phân tích sâu hơn về tính nhất quán phản hồi và không gian biểu diễn tiết lộ rằng không gian ngữ nghĩa đa ngôn ngữ trở nên căn chỉnh trong các lớp giữa của m-LLaMA. Trong cài đặt điều chỉnh hướng dẫn đa ngôn ngữ hạn chế tài nguyên, chúng tôi cho thấy việc sử dụng các quy luật tỷ lệ đã xây dựng để đạt được phân bổ dữ liệu tối ưu. Nhìn chung, cách tiếp cận và phát hiện của chúng tôi làm sáng tỏ tiềm năng phát triển các LLM mạnh mẽ hơn cho các ngôn ngữ không phải tiếng Anh.

LỜI CẢM ơN

Chúng tôi muốn cảm ơn Yinquan Lu vì sự hỗ trợ của anh ấy cho dự án này. Shujian Huang là tác giả liên lạc.

TÀI LIỆU THAM KHẢO

[Phần tài liệu tham khảo được giữ nguyên như bản gốc với các tên tác giả, tiêu đề và thông tin xuất bản]

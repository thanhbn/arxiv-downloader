# 2310.19341.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/multilingual/2310.19341.pdf
# Kích thước tệp: 936392 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Skywork: Một Mô Hình Nền Tảng Song Ngữ Mở Hơn
Tianwen Wei, Liang Zhao, Lichang Zhang, Bo Zhu, Lijie Wang, Haihua Yang, Biye Li, Cheng Cheng, Weiwei Lü, Rui Hu
Chenxia Li, Liu Yang, Xilin Luo, Xuejie Wu, Lunan Liu, Wenjun Cheng, Peng Cheng, Jianhao Zhang, Xiaoyu Zhang
Lei Lin, Xiaokun Wang, Yutuan Ma, Chuanhai Dong, Yanqi Sun, Yifu Chen, Yongyi Peng, Xiaojuan Liang
Shuicheng Yan, Han Fang, Yahui Zhou∗
Skywork Team, Kunlun Inc.

Tóm tắt
Trong báo cáo kỹ thuật này, chúng tôi trình bày Skywork-13B, một họ các mô hình ngôn ngữ lớn (LLM) được huấn luyện trên kho dữ liệu hơn 3,2 nghìn tỷ token được rút ra từ cả văn bản tiếng Anh và tiếng Trung. Mô hình nền tảng song ngữ này là LLM được huấn luyện rộng rãi và công bố mở nhất có kích thước tương đương đến nay. Chúng tôi giới thiệu phương pháp huấn luyện hai giai đoạn sử dụng kho dữ liệu phân đoạn, nhắm vào huấn luyện mục đích chung và sau đó huấn luyện nâng cao chuyên biệt theo lĩnh vực. Chúng tôi chỉ ra rằng mô hình của chúng tôi không chỉ xuất sắc trên các bài kiểm tra phổ biến mà còn đạt được hiệu suất tốt nhất trong mô hình hóa ngôn ngữ tiếng Trung trên các lĩnh vực đa dạng. Hơn nữa, chúng tôi đề xuất một phương pháp phát hiện rò rỉ dữ liệu mới, chứng minh rằng ô nhiễm dữ liệu là một vấn đề cấp bách cần được cộng đồng LLM điều tra thêm. Để khuyến khích nghiên cứu tương lai, chúng tôi phát hành Skywork-13B cùng với các checkpoint thu được trong các giai đoạn trung gian của quá trình huấn luyện. Chúng tôi cũng phát hành một phần kho dữ liệu SkyPile của mình, một bộ sưu tập hơn 150 tỷ token văn bản web, đây là kho dữ liệu huấn luyện trước tiếng Trung chất lượng cao mở lớn nhất đến nay. Chúng tôi hy vọng Skywork-13B và kho dữ liệu mở của chúng tôi sẽ phục vụ như một nguồn tài nguyên mã nguồn mở có giá trị để dân chủ hóa việc tiếp cận các LLM chất lượng cao.

1 Giới thiệu
Xử lý Ngôn ngữ Tự nhiên (NLP), một nhánh quan trọng của trí tuệ nhân tạo, đã trải qua một sự thay đổi lớn trong những năm gần đây. Quan trọng nhất đối với cuộc cách mạng này là sự ra đời và phát triển của các mô hình ngôn ngữ lớn (LLM) (Ouyang et al., 2022; OpenAI, 2023; Bubeck et al., 2023; Chowdhery et al., 2022; Anil et al., 2023; Touvron et al., 2023a,b). Những cấu trúc tính toán phức tạp này, được tạo thành từ hàng tỷ tham số, có khả năng hiểu, tạo ra và dịch ngôn ngữ con người với mức độ chính xác và tinh tế chưa từng có. Tuy nhiên, sự phát triển của những mô hình này cũng đi kèm với xu hướng ngày càng tăng về thương mại hóa và thiếu minh bạch, một hiện tượng đang ngày càng ảnh hưởng đến động lực của cộng đồng mã nguồn mở.

Trong lịch sử, cộng đồng mã nguồn mở đã phát triển mạnh dựa trên các nguyên tắc hợp tác, minh bạch và chia sẻ ý tưởng không hạn chế. Tuy nhiên, khi tiềm năng thương mại của LLM được nhận ra, sự cởi mở này đã bắt đầu giảm đi. Thực tế là nhiều tổ chức chỉ công khai các checkpoint mô hình trong khi giữ lại thông tin quan trọng về việc tái tạo mô hình. Thực hành này cản trở đáng kể tiến bộ của lĩnh vực này.

Trong nỗ lực hồi sinh tinh thần của cộng đồng mã nguồn mở và đóng góp vào cuộc đối thoại đang diễn ra về tính minh bạch trong AI, chúng tôi trình bày Skywork-13B: một họ các mô hình ngôn ngữ lớn song ngữ với 13 tỷ tham số, được huấn luyện trên kho dữ liệu khổng lồ hơn 3,2 nghìn tỷ token được rút ra từ cả văn bản tiếng Anh và tiếng Trung. Theo hiểu biết của chúng tôi, Skywork-13B là họ LLM mở được huấn luyện kỹ lưỡng nhất có kích thước tương đương đến nay.

Trong báo cáo kỹ thuật này, chúng tôi cung cấp một tiết lộ toàn diện về hành trình phát triển Skywork-13B. Chúng tôi mô tả chi tiết thành phần dữ liệu huấn luyện, cung cấp cái nhìn sâu sắc về quỹ đạo tiến hóa của khả năng mô hình trong quá trình huấn luyện, và chia sẻ các phương pháp có thể được sử dụng để nâng cao khả năng mô hình trong các lĩnh vực cụ thể. Chúng tôi tin rằng cách tiếp cận mở như vậy không chỉ hỗ trợ việc tái tạo công việc của chúng tôi mà còn cung cấp một nguồn tài nguyên có giá trị cho các nhà nghiên cứu khác tìm cách khám phá và mở rộng khả năng của các mô hình ngôn ngữ lớn. Báo cáo kỹ thuật này cũng là lời kêu gọi hành động cho sự minh bạch mới trong lĩnh vực NLP. Thông qua nó, chúng tôi hy vọng truyền cảm hứng cho việc trở lại một cộng đồng mã nguồn mở hợp tác hơn, cởi mở hơn, nơi tiến bộ không bị cản trở bởi các cân nhắc thương mại mà được thúc đẩy bởi trí tuệ tập thể và sự khôn ngoan được chia sẻ.

Những đóng góp của chúng tôi như sau:
•Chúng tôi phát hành Skywork-13B¹, một họ LLM là LLM được huấn luyện rộng rãi nhất và được công bố mở có kích thước tương đương đến nay. Họ Skywork-13B của chúng tôi bao gồm 1) Skywork-13B-Base, một mô hình nền tảng mạnh mẽ với khả năng mô hình hóa ngôn ngữ tiếng Trung tốt nhất, và 2) Skywork-13B-Chat, một phiên bản được tinh chỉnh được tối ưu hóa cho hội thoại².

•Chúng tôi tiết lộ thông tin chi tiết về quá trình huấn luyện và thành phần dữ liệu. Chúng tôi cũng phát hành các checkpoint trung gian, cung cấp một nguồn tài nguyên có giá trị để hiểu cách khả năng của mô hình phát triển trong quá trình huấn luyện. Điều này cho phép các nhà nghiên cứu khác tận dụng những checkpoint này cho các trường hợp sử dụng cụ thể của họ.

•Chúng tôi phát hành một phần kho dữ liệu huấn luyện chất lượng cao của mình, tổng cộng hơn 150 tỷ token. Theo hiểu biết của chúng tôi, đây là kho dữ liệu tiếng Trung mở lớn nhất cho việc huấn luyện trước mô hình ngôn ngữ đến nay.

•Chúng tôi phát triển một phương pháp mới phát hiện mức độ sử dụng dữ liệu trong lĩnh vực trong giai đoạn huấn luyện. Để tạo điều kiện tái tạo các thí nghiệm được trình bày trong báo cáo này, chúng tôi đã phát hành dữ liệu liên quan.

2 Phương pháp
2.1 Hai Giai đoạn Huấn luyện Trước
Để huấn luyện Skywork-13B, chúng tôi đã xây dựng SkyPile (xem Mục 3.1), một kho dữ liệu huấn luyện khổng lồ chủ yếu được tạo thành từ các trang web có thể truy cập công khai. Chúng tôi đã xác định một tập con nhỏ của SkyPile, bao gồm các bài tập và giải pháp trải rộng trên nhiều chủ đề từ tiểu học đến sau đại học. Điều này bao gồm các bài toán lập trình, câu hỏi thi quốc gia, bài tập sách giáo khoa, và những thứ khác. Do phần lớn các bài tập này liên quan đến STEM, chúng tôi gọi tập con này và phần bù của nó là SkyPile-STEM và SkyPile-Main, tương ứng.

Thay vì huấn luyện mô hình nền tảng Skywork-13B trực tiếp trên toàn bộ SkyPile, chúng tôi đã áp dụng phương pháp huấn luyện hai giai đoạn. Giai đoạn đầu tiên, tạo thành giai đoạn huấn luyện trước chính, bao gồm việc huấn luyện mô hình từ đầu trên SkyPile-Main. Trong giai đoạn thứ hai, Skywork-13B của chúng tôi được làm giàu với kiến thức lĩnh vực STEM và kỹ năng giải quyết vấn đề thông qua việc tiếp tục huấn luyện trước trên SkyPile-STEM. Để tránh vấn đề quên thảm khốc tiềm ẩn, việc tiếp tục huấn luyện trước này được thực hiện trên hỗn hợp của SkyPile-STEM và SkyPile-Main, thay vì chỉ trên SkyPile-STEM.

Quyết định phân tách huấn luyện trước Giai đoạn-1 và Giai đoạn-2 phục vụ một mục đích kép. Thứ nhất, chúng tôi thừa nhận rằng một tỷ lệ đáng kể các mẫu từ SkyPile-STEM, theo bản chất, là dữ liệu có giám sát. Những dữ liệu này có liên quan chặt chẽ với các bài kiểm tra phổ biến như CEVAL (Huang et al., 2023), MMLU (Hendrycks et al., 2021) và GSM8K (Cobbe et al., 2021), và có thể được sử dụng trong quá trình tinh chỉnh có giám sát (SFT) để trực tiếp nâng cao hiệu suất mô hình trên các nhiệm vụ phụ liên quan. Trong bối cảnh này, việc phân tách giữa huấn luyện Giai đoạn-1 và Giai đoạn-2 cho phép chúng tôi đánh giá hiệu quả hơn tác động của huấn luyện trước mục đích chung (trên văn bản web) và huấn luyện trước có mục tiêu (trên dữ liệu trong lĩnh vực/có giám sát). Những cái nhìn sâu sắc như vậy có thể thông báo cho các chiến lược thu thập và biên dịch dữ liệu tương lai cho việc huấn luyện mô hình nền tảng.

Thứ hai, bằng cách hạn chế huấn luyện trước giai đoạn đầu tiên đối với dữ liệu mục đích chung, chúng tôi có thể tạo ra một phiên bản mô hình nền tảng thay thế cho phiên bản có cải tiến có mục tiêu. Mặc dù phiên bản sau thể hiện hiệu suất vượt trội trên một số nhiệm vụ phụ, nhưng nó ít có khả năng trong mô hình hóa ngôn ngữ của văn bản tự nhiên. Chúng tôi cho rằng phương án thay thế này là một đóng góp có giá trị cho cộng đồng, do tiềm năng xuất sắc của nó trong các ứng dụng không yêu cầu năng lực liên quan đến STEM.

2.2 Giám sát Tiến độ Huấn luyện
Việc giám sát và đánh giá tiến độ được thực hiện trong quá trình huấn luyện trước theo thời gian thực là rất quan trọng. Các phương pháp hiện tại như giám sát mất mát huấn luyện và kết quả bài kiểm tra trên các checkpoint trung gian, tuy nhiên, có những hạn chế của chúng.

Vấn đề chính của việc giám sát mất mát huấn luyện nằm ở chỗ hiệu quả của nó bị đặt câu hỏi khi xem xét tiềm năng overfitting. Mất mát huấn luyện tương đương với mất mát xác thực chỉ khi dữ liệu huấn luyện được sử dụng chính xác một lần (tức là, trong một epoch). Tuy nhiên, trong các tình huống thực tế của việc huấn luyện LLM, dữ liệu chất lượng cao thường trải qua quá trình huấn luyện nhiều lần (Taylor et al., 2022; Touvron et al., 2023a; Rozière et al., 2023; Gunasekar et al., 2023; Li et al., 2023b). Bên cạnh đó, ngay cả sau khi khử trùng lặp rõ ràng, vẫn có thể tồn tại một lượng đáng kể dữ liệu trùng lặp trong tập huấn luyện (Soboleva et al., 2023; Abbas et al., 2023). Trong cả hai trường hợp, việc chỉ dựa vào mất mát huấn luyện có thể dẫn đến việc bỏ qua vấn đề overfitting, từ đó tạo ra những ước tính quá lạc quan về hiệu suất mô hình. Biểu đồ con trên cùng bên trái trong Hình 3 minh họa quỹ đạo của mất mát huấn luyện trước cho mô hình Skywork-13B của chúng tôi. Phù hợp với những phát hiện được báo cáo trong (Touvron et al., 2023a,b; Baichuan Inc., 2023), mất mát thể hiện sự giảm ổn định trong suốt quá trình huấn luyện. Tuy nhiên, một quan sát không được tiết lộ trong những tác phẩm được trích dẫn này là hành vi của mất mát xác thực trên các tập held-out. Từ hình có thể thấy rõ rằng mất mát xác thực dường như bằng phẳng khi quá trình huấn luyện tiến gần đến giai đoạn cuối.

Kiểm tra dựa trên các checkpoint trung gian là một phương pháp giám sát phổ biến khác (Touvron et al., 2023a; Baichuan Inc., 2023). Tuy nhiên, nó có một số thách thức. Thứ nhất, có sự biến động cao trong kết quả kiểm tra, có thể dẫn đến đánh giá không ổn định và không đáng tin cậy về tiến độ huấn luyện. Thứ hai, kết quả kiểm tra không nhạy cảm với tiến bộ nhỏ trong huấn luyện. Sự không nhạy cảm này khiến việc theo dõi chính xác những cải thiện dần dần trong quá trình huấn luyện trở nên khó khăn. Bên cạnh đó, các mô hình yếu hơn không tuân theo hướng dẫn tốt. Do đó, kết quả kiểm tra có thể không phản ánh chính xác tiến trình học tập thực sự hoặc tiềm năng của chúng. Cuối cùng, một bất tiện được đặt ra bởi hầu hết các bài kiểm tra là sự cần thiết cho việc tạo ra mô hình. Quá trình này đặc biệt tốn tài nguyên, đòi hỏi sức mạnh tính toán đáng kể.

Trong quá trình huấn luyện trước Skywork-13B, chúng tôi áp dụng phương pháp giám sát mất mát mô hình hóa ngôn ngữ trên nhiều tập xác thực được dành riêng, mỗi tập phản ánh một phân phối dữ liệu riêng biệt. Cụ thể hơn, chúng tôi đã tạo ra các tập xác thực riêng biệt cho mã, các bài xuất bản học thuật, bài đăng trên mạng xã hội, văn bản web bằng tiếng Trung và tiếng Anh, trong số những thứ khác. Các chỉ số giám sát thông thường cũng được sử dụng, nhưng chúng chỉ phục vụ như các công cụ bổ sung. Trong Hình 1, chúng tôi vẽ đường cong mất mát xác thực mô hình ngôn ngữ trên văn bản web tiếng Anh so với chỉ số trung bình của một số nhiệm vụ phụ tiếng Anh. Rõ ràng là có mối tương quan rất cao giữa hai đại lượng, cho thấy rằng mất mát xác thực có thể phục vụ như một chỉ số proxy hợp lệ cho hiệu suất nhiệm vụ phụ. Trong bối cảnh huấn luyện trước LLM, cách tiếp cận này cũng mang lại một số lợi ích khác:

•Dễ dàng xây dựng: Tạo ra nhiều tập xác thực là một nhiệm vụ tương đối dễ dàng. Điều này cho phép đánh giá hiệu suất mô hình hóa ngôn ngữ của mô hình trên các lĩnh vực khác nhau.

•Đơn giản trong tính toán: Việc tính toán mất mát xác thực rất đơn giản, giảm đáng kể chi phí tính toán và hậu cần liên quan đến việc theo dõi huấn luyện mô hình.

•Độ nhạy cao với tiến độ huấn luyện: Mất mát xác thực được điều chỉnh tinh tế với sự tiến bộ của huấn luyện, từ đó cung cấp một góc nhìn chi tiết hơn về cách các mô hình phát triển và cải thiện theo thời gian.

•Bất khả tri mô hình: Mất mát xác thực không quan tâm đến thành phần của kho dữ liệu huấn luyện hoặc kiến trúc mô hình. Nó cho phép so sánh không chỉ giữa các checkpoint khác nhau được tạo ra trong một phiên huấn luyện duy nhất, mà còn giữa các mô hình khác nhau từ cộng đồng. Điều này đảm bảo một cơ sở nhất quán và công bằng để so sánh mô hình.

Lưu ý rằng việc giám sát mất mát xác thực trên một tập held-out có chung phân phối với tập huấn luyện là một thực hành phổ biến trong học máy. Tuy nhiên, việc quan sát mất mát xác thực trên nhiều tập held-out, mỗi tập có phân phối duy nhất, có chủ ý, là không phổ biến. Chúng tôi cũng lưu ý rằng quan điểm khẳng định tính ưu tiên của mất mát mô hình hóa ngôn ngữ như chỉ số hiệu suất tối quan trọng cho các mô hình không phải là một khải thị gần đây. Nguyên tắc này đã được áp dụng một cách rõ ràng hoặc ngầm định trong một số nghiên cứu, như được minh họa trong (Kaplan et al., 2020; Hoffmann et al., 2022; Anil et al., 2023; Xia et al., 2023; Delétang et al., 2023).

3 Huấn luyện Trước
3.1 Kho dữ liệu SkyPile
Để huấn luyện Skywork-13B, chúng tôi xây dựng SkyPile, một kho dữ liệu rộng lớn, chất lượng cao bao gồm hơn 6 nghìn tỷ token. Một phần của kho dữ liệu, bao gồm hơn 150 tỷ token văn bản web, đã được mở nguồn để tạo điều kiện nghiên cứu và huấn luyện trên các LLM tiếng Trung³.

SkyPile của chúng tôi là sự kết hợp của một số nguồn, phần lớn trong số đó được thu thập từ các kênh có thể truy cập công khai. Nhiều nghiên cứu trước đây, được minh họa bởi các sáng kiến như LLaMA (Touvron et al., 2023a) và RefinedWeb (Penedo et al., 2023), đã chứng minh khái niệm rằng dữ liệu web có thể truy cập công khai có thể tạo ra các LLM chất lượng cao đặc biệt. Phù hợp với bằng chứng thực nghiệm này, chúng tôi đồng ý với tiền đề tận dụng các trang web có thể truy cập công khai như nguồn chính cho dữ liệu huấn luyện.

Việc xây dựng SkyPile được đặc trưng bởi sự nhấn mạnh chuyên dụng vào hai chiều kích chính: chất lượng văn bản và phân phối thông tin. Quy trình xử lý dữ liệu của chúng tôi, lấy cảm hứng từ (Wenzek et al., 2020; Touvron et al., 2023a; Penedo et al., 2023), bao gồm các giai đoạn sau:

•Trích xuất Cấu trúc: Do nguồn chủ yếu của bộ dữ liệu của chúng tôi là các trang web có thể truy cập công khai, mục tiêu của giai đoạn đầu tiên là trích xuất nội dung phù hợp trong khi đồng thời loại bỏ các yếu tố văn bản không liên quan được coi là không đóng góp vào việc huấn luyện mô hình ngôn ngữ của chúng tôi, ví dụ như các thành phần thừa này bao gồm thanh điều hướng, thông tin liên hệ cụ thể của trang web, văn bản tiêu đề rời rạc không có nội dung thực chất, v.v. Sau quá trình loại bỏ này, thông tin được giữ lại chủ yếu bao gồm các đoạn văn bản liên tục, trung bình đến dài.

•Lọc Phân phối: Trong việc theo đuổi mục tiêu nuôi dưỡng một LLM có năng lực sâu sắc, sự tiếp xúc của mô hình phải bao gồm một loạt nội dung đa dạng trải rộng trên một phổ rộng các lĩnh vực. Các nỗ lực trước đây trong lĩnh vực này đã bao gồm nhiệm vụ gán nhãn phân loại cho từng tài liệu hoặc trang web riêng lẻ, từ đó chỉ định thủ công thành phần của kho dữ liệu huấn luyện. Tuy nhiên, chúng tôi cho rằng kho dữ liệu được sử dụng cho huấn luyện LLM đã phát triển đến mức độ mà kiến thức nó bao gồm không thể được phân chia một cách riêng rẽ. Do đó, tránh xa cách tiếp cận tập trung vào nhãn, phương pháp của chúng tôi tập trung vào việc đánh giá độ tương tự ngữ nghĩa tồn tại giữa các đoạn văn bản, từ đó xác định và loại bỏ những khối văn bản được đặc trưng bởi tỷ lệ tái diễn cực kỳ cao.

•Khử trùng lặp: Khử trùng lặp đã thể hiện hiệu quả đáng kể trong việc nâng cao chất lượng tổng thể của kho dữ liệu huấn luyện, và nó đã tìm thấy ứng dụng rộng rãi trong hầu như tất cả các bộ dữ liệu nổi bật (Hernandez et al., 2022; Kandpal et al., 2022; Abbas et al., 2023; Lee et al., 2022). Trong khuôn khổ của SkyPile, chúng tôi coi khử trùng lặp là một thành phần không thể thiếu của quá trình Lọc Phân phối. Khi xem xét góc độ rộng hơn, trở nên rõ ràng rằng sự trùng lặp tạo thành một yếu tố quan trọng nhất ảnh hưởng đến phân phối ngữ nghĩa của kho dữ liệu. Do đó, các kỹ thuật và chiến lược chúng tôi sử dụng trong giai đoạn lọc phân phối đã tự động loại bỏ một phần đáng kể nội dung trùng lặp.

•Lọc Chất lượng: Trong giai đoạn này, chúng tôi triển khai quy trình CCNet (Wenzek et al., 2020) để thực hiện hai nhiệm vụ lọc quan trọng: loại bỏ nội dung chất lượng kém và loại trừ các trang không phải bằng tiếng Anh cũng không phải tiếng Trung. Chúng tôi đã huấn luyện một bộ phân loại nhị phân dự đoán khả năng một trang web nhất định phù hợp để đưa vào như một tài liệu tham khảo trong kho dữ liệu Wikipedia. Kết quả của giai đoạn này được tổ chức thành các danh mục dựa trên chất lượng riêng biệt, và chúng tôi chỉ giữ lại các nhóm chất lượng cao, chọn loại bỏ hoàn toàn các nhóm còn lại.

Ở trên chúng tôi đã mô tả quy trình tiền xử lý của mình cho văn bản tự nhiên. Đối với nội dung Github, chúng tôi sử dụng một cách tiếp cận tương tự như (Together Computer, 2023). Chúng tôi đã thiết kế một bộ sưu tập các quy tắc kinh nghiệm đơn giản nhưng hiệu quả, bao gồm các tiêu chí như lọc độ dài dòng và ngưỡng chữ và số, được thiết kế để phân biệt và loại trừ nội dung chất lượng thấp. Tiêu chí của chúng tôi được định hướng cụ thể để nâng cao chất lượng nội dung, trái ngược với việc chỉ đơn giản là kiềm chế khối lượng của nó. Đáng chú ý, trái ngược với các thực hành hiện tại bao gồm việc loại bỏ hoàn toàn một phần đáng kể nội dung json, xml, yaml và html, chúng tôi đã có lựa chọn cân nhắc để giữ lại một đại diện tỷ lệ thận trọng của các định dạng dữ liệu này.

Lưu ý rằng trong việc theo đuổi mục tiêu hài hòa thành thạo của mô hình trong cả tiếng Anh và tiếng Trung, chúng tôi bao gồm trong SkyPile một bộ dữ liệu song song chất lượng cao được tuyển chọn. Dữ liệu này được cấu trúc tỉ mỉ để ghép nối một đoạn văn tiếng Anh hoàn chỉnh với phần tiếng Trung tương ứng, đảm bảo sự liên kết mượt mà của khả năng ngôn ngữ giữa hai ngôn ngữ.

3.2 Thành phần Dữ liệu Huấn luyện
Skywork-13B của chúng tôi được huấn luyện trước cho 3,2 nghìn tỷ token, được lấy mẫu từ SkyPile. Văn bản từ một số nguồn nhất định được coi là chất lượng cao, ví dụ như Wikipedia, do đó đã trải qua quá trình upsampling. Tuy nhiên, chúng tôi thường tuân theo quy tắc rằng số lần lặp lại không vượt quá năm, như được khuyến nghị bởi các nghiên cứu gần đây (Taylor et al., 2022; Muennighoff et al., 2023).

Chúng tôi báo cáo trong Bảng 1 sự phân tích các thành phần cấu thành của các token huấn luyện trong quá trình huấn luyện trước Giai đoạn-1. Các token huấn luyện chủ yếu được tạo thành từ văn bản tiếng Anh và tiếng Trung, chiếm 49,8% và 39,6% dữ liệu, tương ứng. Mã đóng góp 8,0% vào tổng số, với văn bản bằng các ngôn ngữ khác chiếm 2,4% còn lại. Danh mục được gắn nhãn là "miscellany" bao gồm một loạt văn bản đa dạng, bao gồm nhưng không giới hạn ở, các bài báo pháp lý, tài liệu tòa án, báo cáo thường niên của công ty, và văn học cổ điển.

3.3 Tokenizer
Chúng tôi tokenize dữ liệu bằng cách sử dụng mã hóa byte-pair (BPE) như được triển khai trong SentencePiece (Kudo và Richardson, 2018), theo cách tiếp cận của LLaMA (Touvron et al., 2023a). Vì mô hình của chúng tôi được dự định là song ngữ tiếng Anh-tiếng Trung, chúng tôi mở rộng từ vựng gốc của LLaMA, chủ yếu bao gồm các từ và từ phụ dựa trên latin, với các ký tự và từ tiếng Trung được sử dụng thường xuyên. Cụ thể, chúng tôi thêm 8000 token ký tự đơn từ từ vựng của BERT (Devlin et al., 2019) vào từ vựng của LLaMA. Chúng tôi tiếp tục mở rộng từ vựng với 25k từ tiếng Trung đa ký tự thường xuyên. Điều này dẫn đến tổng kích thước từ vựng là 65.536 token, trong đó 17 được dành riêng như các ký hiệu đặc biệt.

Như trong LLaMA, chúng tôi chia tất cả các số thành các chữ số riêng lẻ, và quay trở lại byte để phân tách các ký tự UTF-8 không xác định.

3.4 Kiến trúc
Skywork-13B của chúng tôi dựa trên kiến trúc transformer (Vaswani et al., 2017), bao gồm các ngăn xếp của các lớp transformer-decoder. Trái ngược với mô hình transformer ban đầu, chúng tôi đã tích hợp một số sửa đổi, lấy cảm hứng từ LLaMA (Touvron et al., 2023a,b). Các thí nghiệm sơ bộ của chúng tôi, như được minh họa trong Hình 2, xác nhận những thay đổi này, chứng minh hiệu suất cải thiện mà chúng mang lại. Chi tiết về thí nghiệm này có thể tìm thấy trong Phụ lục A.

Mặc dù kiến trúc mạng của chúng tôi theo mô hình LLaMA ở mức độ lớn, tồn tại một sự khác biệt đáng chú ý trong sự ưa thích của chúng tôi đối với một mạng sâu hơn, nhưng hẹp hơn. Một khám phá so sánh của các cấu hình mạng Skywork-13B và LLaMA2-13B được trình bày trong Bảng 3.

Các sửa đổi cụ thể được thực hiện được mô tả chi tiết dưới đây.

•Embedding Vị trí: Chúng tôi sử dụng Rotary Positional Embedding (RoPE) (Su et al., 2022), được thúc đẩy bởi việc áp dụng rộng rãi trong các mô hình ngôn ngữ lớn nổi bật khác nhau, như LLaMA và PaLM, cũng như hiệu quả đã được chứng minh trong việc mở rộng độ dài của cửa sổ ngữ cảnh, như được chứng minh bởi các nghiên cứu gần đây (Chen et al., 2023; Rozière et al., 2023; Xiong et al., 2023).

•Chuẩn hóa Lớp: Chúng tôi thay thế chuẩn hóa lớp thông thường bằng RMSNorm (Zhang và Sennrich, 2019). Ngoài ra, chúng tôi áp dụng chuẩn hóa trước trong mỗi lớp thay vì chuẩn hóa sau, điều này đã được chứng minh là nâng cao tính ổn định huấn luyện của các mô hình transformer.

•Kích hoạt: Chúng tôi sử dụng hàm kích hoạt SwiGLU (Shazeer, 2020). Phù hợp với các quy ước đã được thiết lập trong các nghiên cứu trước đây, chúng tôi đã giảm chiều của mạng feed-forward (FFN) từ bốn lần kích thước ẩn xuống tám phần ba kích thước ẩn. Điều chỉnh này được thực hiện để duy trì sự ngang bằng giữa tổng tham số trong một lớp và những tham số trong lớp transformer vanilla.

3.5 Hạ tầng
Skywork-13B của chúng tôi được huấn luyện trên một cụm 64 node NVIDIA-HGX-A800, tổng cộng 512 GPU A800-80G SXM. Mỗi node trong cụm được trang bị NVLink tốc độ cao 400GB/s cho giao tiếp nội bộ node và mạng RoCE 800Gb/s cho kết nối liên node. Khung huấn luyện của chúng tôi dựa trên thư viện Megatron-LM (Shoeybi et al., 2020), được thiết kế để hỗ trợ huấn luyện ổn định, kéo dài của các mô hình quy mô lớn, phù hợp với hàng ngàn GPU và kích thước mô hình theo thứ tự hàng trăm tỷ tham số.

Xem xét kích thước tương đối vừa phải của mô hình Skywork-13B, chúng tôi đã tránh sử dụng các kỹ thuật tối ưu hóa bộ nhớ GPU và các sơ đồ song song có thể cản trở tốc độ. Chúng bao gồm Tensor Model Parallelism (Shoeybi et al., 2020), Sequence Parallelism (Korthikanti et al., 2022), ZeRO-Stage2 (Rajbhandari et al., 2020), và Checkpointing (Chen et al., 2016). Thay vào đó, chúng tôi đã tận dụng Data Parallelism (DP) với ZeRO-1 (Rajbhandari et al., 2020) và Pipeline Parallelism (PP) (Narayanan et al., 2021) như các chiến lược song song hóa chính để huấn luyện Skywork-13B. ZeRO-1 giảm đáng kể dấu chân bộ nhớ GPU của trạng thái optimizer Adam mà không tăng gánh nặng trên giao tiếp giữa các thành phần. Pipeline Parallelism cung cấp tối ưu hóa bộ nhớ với chi phí giao tiếp tối thiểu, giảm khi bước tích lũy gradient tăng, do đó giảm thiểu sự chậm lại của all-reduce khi Kích thước DP tăng.

Về tối ưu hóa toán tử, chúng tôi đã áp dụng Flash Attention V2 (Dao et al., 2022; Dao, 2023), một chiến lược vừa tối ưu hóa bộ nhớ GPU vừa đẩy nhanh quá trình huấn luyện.

Dựa trên các thí nghiệm sơ bộ rộng rãi, chúng tôi quyết định áp dụng kết hợp DP256, PP2, và ZeRO-1 như chiến lược huấn luyện phân tán cho Skywork-13B. Với cấu hình này, chúng tôi đạt được throughput token 1873 mỗi GPU mỗi giây và mức sử dụng model flops (MFU) 56,5%. Tổng quan về những thí nghiệm này được cung cấp trong Phụ lục B. Quá trình huấn luyện của Skywork-13B kéo dài tổng cộng 39 ngày.

3.6 Chi tiết Huấn luyện
Như đã nêu trong Mục 2.1, việc huấn luyện trước của Skywork-13B được thực hiện trong hai giai đoạn:
•Giai đoạn-1: Huấn luyện trước mục đích chung trên SkyPile-Main.
•Giai đoạn-2: Huấn luyện trước liên tục định hướng STEM trên SkyPile-STEM.

Trong cả hai giai đoạn, mô hình được huấn luyện bằng cách sử dụng mục tiêu mô hình hóa ngôn ngữ tự hồi quy tiêu chuẩn, với độ dài ngữ cảnh cố định ở 4096 token. Optimizer AdamW (Loshchilov và Hutter, 2019), được áp dụng cho quá trình huấn luyện, sử dụng giá trị β1 và β2 lần lượt là 0,9 và 0,95. Trong suốt quá trình huấn luyện trước, chúng tôi đã áp dụng weight decay 0,1 và gradient clipping 1,0. Mô hình của chúng tôi được huấn luyện với độ chính xác hỗn hợp bfloat16.

3.6.1 Huấn luyện Trước Giai đoạn-1
Trong giai đoạn đầu tiên, mô hình Skywork-13B của chúng tôi được huấn luyện từ đầu trên SkyPile-Main với hơn ba nghìn tỷ token. Giai đoạn này bao gồm hai phiên huấn luyện tuần tự, bao gồm 0∼2T token đầu tiên và 2∼3T token tiếp theo, tương ứng.

Kế hoạch ban đầu của chúng tôi là huấn luyện Skywork-13B cho hai nghìn tỷ token. Chúng tôi đã khởi chạy một phiên huấn luyện tương ứng, với một lịch trình tỷ lệ học cosine dần giảm từ tỷ lệ học đỉnh 6e-4 xuống tỷ lệ học cuối cùng 6e-5. Trong Hình 3, chúng tôi báo cáo trong các đường cong màu đỏ sự tiến hóa của mất mát mô hình hóa ngôn ngữ và một số kết quả benchmark của Skywork-13B trong phiên này. Rõ ràng là đến cuối phiên này, mô hình chưa đạt được sự bão hòa. Chúng tôi giả thuyết rằng mô hình có thể hưởng lợi thêm từ việc huấn luyện trước bổ sung, thúc đẩy chúng tôi khởi chạy phiên huấn luyện thứ hai nhắm vào thêm một nghìn tỷ token.

Phiên huấn luyện thứ hai sử dụng thành phần dữ liệu huấn luyện hơi khác so với phiên 0∼2T ban đầu, vì dữ liệu từ một số nguồn nhất định đã cạn kiệt và các nguồn mới được giới thiệu. Do sự thay đổi trong phân phối huấn luyện, chúng tôi đã điều chỉnh tỷ lệ học một cách tỉ mỉ, cuối cùng quyết định sử dụng tỷ lệ học không đổi 6e-5 cho phiên 2∼3T. Trong Hình 4, chúng tôi minh họa mất mát mô hình dưới các điều kiện tỷ lệ học khác nhau. Kết quả chỉ ra rằng tỷ lệ học cao hơn dẫn đến gia tăng mất mát huấn luyện mà chúng tôi coi là quá tốn kém để đảo ngược. Tác động của phiên huấn luyện thứ hai được mô tả trong các đường cong màu xanh của Hình 3. Việc nâng cao hiệu suất của mô hình tiếp tục, mặc dù với tốc độ chậm lại. Thú vị là, mặc dù Skywork-13B của chúng tôi tụt hậu trong lĩnh vực mô hình hóa ngôn ngữ tiếng Anh, nhưng nó vượt trội đáng kể so với tất cả các LLM mở có thể so sánh khác trong mô hình hóa ngôn ngữ tiếng Trung. Trong Mục 4.3, chúng tôi sẽ xác nhận rằng sự vượt trội của Skywork-13B trong mô hình hóa ngôn ngữ tiếng Trung không chỉ đúng trên tập xác thực của chúng tôi, mà còn đúng trên một số tập kiểm tra được lấy từ các lĩnh vực đa dạng.

Nhiều kết quả khác có thể tìm thấy trong Phụ lục (xem Hình 6).

3.6.2 Huấn luyện Trước Giai đoạn-2
Mục tiêu chính của huấn luyện trước Giai đoạn-2 là bổ sung cho mô hình các khả năng liên quan đến các ngành STEM. Dữ liệu được sử dụng trong giai đoạn này bao gồm khoảng 20% từ SkyPile-STEM và 80% từ SkyPile-Main, tổng cộng khoảng 130 tỷ token. Một tỷ lệ học không đổi 6e-5 được áp dụng, duy trì sự ngang bằng với tỷ lệ học cuối được sử dụng trong huấn luyện trước Giai đoạn-1.

Do sự thay đổi phân phối dữ liệu từ Giai đoạn-1 sang Giai đoạn-2, việc hiệu chỉnh tỷ lệ lấy mẫu giữa các nguồn dữ liệu khác nhau một cách tỉ mỉ trở nên quan trọng. Các thí nghiệm ban đầu cho thấy rằng việc tăng dần tỷ lệ SkyPile-STEM mang lại kết quả hiệu quả nhất. Do đó, cho giai đoạn huấn luyện trước Giai đoạn-2 thực tế, chúng tôi đã triển khai một kế hoạch lấy mẫu bắt đầu với 10% SkyPile-STEM ban đầu, dần tăng đến đỉnh 40% về phía cuối quá trình huấn luyện.

Chiến lược huấn luyện này đã thành công trong việc duy trì sự ổn định của mất mát xác thực mô hình hóa ngôn ngữ của mô hình trong khi cho phép chuyển giao kiến thức STEM tối ưu. Thời gian huấn luyện mở rộng đảm bảo sự tiếp thu toàn diện kiến thức liên quan đến STEM vào mô hình mà không gây ra sự nhiễu loạn đáng kể cho thông tin đã học trước đó.

Tác động của huấn luyện trước Giai đoạn-2 được minh họa trong Hình 5, trình bày sự tiến bộ của điểm số benchmark CEVAL. Sự tiến hóa của điểm số trên các benchmark liên quan đến STEM khác, như GSM8K, phản ánh một xu hướng tương tự. Cải thiện trong các môn học cá nhân của CEVAL có thể tìm thấy trong Bảng 12 (xem phụ lục).

4 Đánh giá
4.1 Baseline
Chúng tôi so sánh hiệu suất của Skywork-13B với các mô hình mở có kích thước tương tự, bao gồm LLaMA-13B (Touvron et al., 2023a), LLaMA2-13B (Touvron et al., 2023b), Baichuan-13B, Baichuan2-13B (Baichuan Inc., 2023), Xverse-13B (Xverse-AI, 2023), IntermLM-20B (InternLM Team, 2023). Một tóm tắt của các mô hình này có thể tìm thấy trong Bảng 4.

4.2 Đánh giá Benchmark
Chúng tôi tập trung vào các benchmark phổ biến sau:

•MMLU (Hendrycks et al., 2021): MMLU là một benchmark được thiết kế để đo kiến thức thu được trong quá trình huấn luyện trước. Benchmark bao gồm 57 môn học trên STEM, nhân văn, khoa học xã hội, và nhiều hơn nữa, có mức độ khó khăn từ cấp độ cơ bản đến cấp độ chuyên nghiệp tiến bộ. Nó kiểm tra cả kiến thức thế giới và khả năng giải quyết vấn đề.

•CEVAL (Huang et al., 2023) và CMMLU (Li et al., 2023a): Đây là các benchmark tiếng Trung bắt chước MMLU. CEVAL bao gồm 13948 câu hỏi trắc nghiệm trải rộng trên 52 ngành học đa dạng và bốn mức độ khó khăn. CMMLU bao gồm 67 ngành học từ cấp độ cơ bản đến cấp độ chuyên nghiệp tiến bộ.

•GSM8K (Cobbe et al., 2021): Bộ dữ liệu này bao gồm 8500 bài toán từ ngữ toán học chất lượng cao ở cấp độ tiểu học được tạo ra bởi những người viết con người. Những bài toán nhiều bước này đòi hỏi từ 2 đến 8 bước để giải quyết. GSM8K thường được sử dụng trong việc đánh giá khả năng suy luận toán học nhiều bước của LLM.

Trong Bảng 5, chúng tôi trình bày so sánh kết quả hiệu suất từ các mô hình khác nhau trên những benchmark này. Các chỉ số cho CEVAL, CMMLU và MMLU là độ chính xác 5-shot, trong khi cho GSM8K là độ chính xác 8-shot. Số cao hơn chỉ ra hiệu suất tốt hơn. Có thể thấy rằng Skywork-13B của chúng tôi đạt được điểm số cao nhất trên cả ba benchmark CEVAL, MMLU và GSM8K, với điểm số lần lượt là 60,6, 62,1 và 55,8. Trên benchmark CMMLU, Baichuan2-13B đạt hiệu suất cao nhất với điểm số 62,0.

Tóm lại, mô hình Skywork của chúng tôi đã thể hiện hiệu suất đặc biệt trên một loạt các bài kiểm tra benchmark toàn diện đa dạng. Kết quả của các môn học cá nhân của CEVAL có thể tìm thấy trong Bảng 12. Kết quả của các benchmark khác có thể tìm thấy trong Phụ lục C.

4.3 Kết quả Mô hình hóa Ngôn ngữ
4.3.1 LM như một giải pháp cho overfitting benchmark
Các benchmark thông thường để đánh giá LLM thường dựa vào các bộ dữ liệu tĩnh của các ví dụ được chú thích bởi con người. Một vấn đề cốt lõi với cách tiếp cận này là việc cập nhật các mẫu kiểm tra thường xuyên là khó khăn và tốn kém. Theo thời gian, các tập kiểm tra tĩnh có xu hướng bị overfitting, tạo ra kết quả benchmark gây hiểu lầm.

Chúng tôi đề xuất đánh giá mô hình hóa ngôn ngữ như một giải pháp thay thế hấp dẫn. Perplexity trong mô hình hóa ngôn ngữ hoạt động như một chỉ số proxy có liên kết mạnh mẽ với hiệu suất trên các nhiệm vụ phụ đa dạng (xem Hình 1). Vì mô hình hóa ngôn ngữ chỉ yêu cầu văn bản tự nhiên không nhãn, nó loại bỏ nhu cầu chú thích con người đắt đỏ. Việc xây dựng và sửa đổi các tập kiểm tra mô hình hóa ngôn ngữ có chi phí thấp, vì dữ liệu mới có thể dễ dàng được lấy mẫu từ nội dung mới được xuất bản. Ngoài ra, nếu một tập kiểm tra bị tổn hại, dữ liệu kiểm tra mới có thể nhanh chóng được lấy mẫu làm thay thế.

4.3.2 Xây dựng các tập kiểm tra LM đa dạng
Chúng tôi so sánh khả năng mô hình hóa ngôn ngữ của các mô hình ngôn ngữ khác nhau với Skywork-13B của chúng tôi, tập trung vào ngôn ngữ tiếng Trung.

Để thực hiện đánh giá mạnh mẽ về khả năng mô hình hóa ngôn ngữ, chúng tôi đã riêng biệt thu thập một kho dữ liệu đa dạng các văn bản từ vô số trang web, mỗi trang được gắn nhãn theo lĩnh vực tương ứng. Các lĩnh vực chúng tôi bao gồm trải rộng trên một phổ rộng, bao gồm các khu vực như công nghệ, phim ảnh, tài chính, và nhiều hơn nữa. Những bộ dữ liệu đánh giá cụ thể theo lĩnh vực này cũng đã được mở nguồn để truy cập công khai⁴.

Chúng tôi đảm bảo rằng mọi mẫu kiểm tra bao gồm các tài liệu hoặc bài đăng của người dùng được xuất bản sau ngày 1 tháng 9 năm 2023. Ngày cắt này đảm bảo rằng không có mẫu kiểm tra nào vô tình được bao gồm trong quá trình huấn luyện trước của bất kỳ mô hình ngôn ngữ nào được đánh giá. Cụ thể, ngày cắt của SkyPile là ngày 30 tháng 6 năm 2023, và phần lớn các mô hình được đánh giá được phát hành trước ngày 31 tháng 8.

Lưu ý rằng mặc dù tập xác thực held-out được sử dụng để giám sát tiến trình huấn luyện (như được hiển thị trong Hình 3) của mô hình chúng tôi cũng có thể phục vụ mục đích này, nhưng nó có cùng phân phối (văn bản web) với phần lớn kho dữ liệu huấn luyện, do đó có thể dẫn đến ước tính quá lạc quan về khả năng mô hình hóa ngôn ngữ thực tế của mô hình. Thông tin chi tiết hơn về các nguồn của mẫu kiểm tra và quy trình thu thập dữ liệu cơ bản có thể tìm thấy trong Phụ lục D.

4.3.3 Kết quả
Kết quả đánh giá mô hình hóa ngôn ngữ của chúng tôi được trình bày trong Bảng 6, nơi kết quả từ ChatGLM3-6B (THUDM, 2023), MOSS-7B (Sun và Qiu, 2023), Baichuan2-7B (Baichuan Inc., 2023), Qwen-7B (Qwen Team, 2023), InternLM-7B (InternLM Team, 2023) và Aquilla2-34B cũng được bao gồm.

Có thể thấy rằng mô hình Skywork-13B của chúng tôi cho thấy hiệu suất tốt nhất tổng thể, đạt được điểm perplexity trung bình thấp nhất là 9,42. Nó cũng thể hiện hiệu suất tốt nhất trên các lĩnh vực cá nhân, đạt được điểm perplexity thấp nhất trong các lĩnh vực công nghệ (11,58), phim ảnh (21,84), chính phủ (4,76), và tài chính (4,92). Nó xuất sắc không chỉ trong việc vượt trội hiệu suất của các mô hình có kích thước tương tự, mà còn trong việc vượt trội các mô hình lớn hơn đáng kể như InternLM-20B và Aquila2-34B.

Chúng tôi quy hiệu suất mô hình hóa ngôn ngữ xuất sắc của Skywork-13B cho chất lượng của kho dữ liệu huấn luyện. Chi tiết về quy trình lọc dữ liệu nghiêm ngặt được mô tả trong Mục 3.1.

5 Thảo luận
Trong phần này, chúng tôi đi sâu vào những lợi ích và rủi ro liên quan của việc huấn luyện trước trên dữ liệu trong lĩnh vực⁵ của các nhiệm vụ benchmark.

5.1 Tác động của huấn luyện trước trên dữ liệu trong lĩnh vực
Các mô hình ngôn ngữ được huấn luyện trước, hoặc mô hình nền tảng, được dự định sử dụng trong học chuyển giao như một xương sống mục đích chung. Vì bản thân mô hình nền tảng có ít cách sử dụng khác ngoài việc hoàn thành câu, chất lượng của mô hình nền tảng thường được đánh giá theo hiệu suất của nó trong các nhiệm vụ đó. Rõ ràng, khi nói đến cải thiện chất lượng mô hình nền tảng được đo bằng hiệu suất nhiệm vụ, việc huấn luyện mô hình trên dữ liệu trong lĩnh vực của nhiệm vụ đó luôn hiệu quả hơn nhiều (Hernandez et al., 2021; Chung et al., 2022), so với dữ liệu mục đích chung (văn bản web).

Chúng tôi đã chỉ ra rằng huấn luyện trước Giai đoạn-2 đã tăng cường đáng kể khả năng liên quan đến STEM của Skywork-13B, dẫn đến cải thiện hiệu suất đáng kể trên các nhiệm vụ liên quan đến STEM. Bây giờ chúng tôi chỉ ra rằng thậm chí có thể nâng cao một mô hình cơ sở yếu hơn nhiều, tức là một checkpoint trung gian, chỉ sử dụng một phần nhỏ dữ liệu và tính toán được sử dụng trong huấn luyện trước Giai đoạn-2.

Bảng 7 trình bày điểm số CEVAL và GSM8K trước và sau huấn luyện trước trên dữ liệu trong lĩnh vực, sử dụng checkpoint mô hình tương đối yếu chỉ trải qua huấn luyện trước 0.5T. Kết quả chỉ ra rằng sau khi huấn luyện trước chỉ với 1B token dữ liệu trong lĩnh vực, một mô hình yếu, ban đầu chỉ hoạt động hơi tốt hơn ngẫu nhiên tại CEVAL và GSM8K, có thể vượt trội hiệu suất của xương sống Skywork-13B mạnh nhất (3T) mà không có huấn luyện trước trong lĩnh vực. Tuy nhiên, điều này đến với chi phí suy giảm đáng kể trong hiệu suất mô hình hóa ngôn ngữ, như được chứng minh bởi mất mát cao hơn trên cả hai nhiệm vụ, được hiển thị trong hai cột ngoài cùng bên phải của bảng.

5.2 Huấn luyện trước trên dữ liệu trong lĩnh vực: một thực hành phổ biến?
Thú vị khi khám phá liệu các mô hình nền tảng phổ biến có được huấn luyện trước trên dữ liệu trong lĩnh vực hay không. Trong việc theo đuổi điều này, chúng tôi đi sâu vào bộ dữ liệu GSM8K, được trang bị với phân chia train/test chính thức và các giải pháp toàn diện. Chúng tôi đánh giá mất mát mô hình hóa ngôn ngữ của LLM trên ba bộ dữ liệu được rút ra từ cùng một phân phối: 1) Tập huấn luyện GSM8K chính thức, 2) Tập kiểm tra GSM8K chính thức, 3) Một tập được tạo thành từ các mẫu giống GSM8K được tạo ra bởi GPT-4. Các mất mát tương ứng được ký hiệu là Ltrain, Ltest, và Lref, tương ứng. Về mặt lý thuyết, nếu một mô hình ngôn ngữ không tiếp xúc với bất kỳ bộ dữ liệu nào trong ba bộ dữ liệu trong quá trình huấn luyện trước, ba mất mát Ltrain, Ltest, và Lref sẽ gần như tương đương. Tuy nhiên, nếu mô hình đã được huấn luyện trước trên tập huấn luyện hoặc nếu dữ liệu kiểm tra đã vô tình bị tiếp xúc trong quá trình huấn luyện trước, chúng tôi sẽ dự đoán một sự khác biệt đáng chú ý giữa Ltrain, Ltest, và Lref.

Kết quả của chúng tôi được nêu trong Bảng 8, cũng báo cáo sự khác biệt trong mất mát ∆1 = Ltest - Lref và ∆2 = Ltest - Ltrain. Đáng chú ý, cột ∆2 cho thấy rằng đối với hầu hết các mô hình, mất mát mô hình hóa ngôn ngữ trên phân chia huấn luyện và kiểm tra GSM8K gần như giống hệt nhau. Tuy nhiên, các mô hình như ChatGLM3-6B, Baichuan2-13B, Qwen-7B/14B, và Aquila2-34B hiển thị mất mát thấp hơn đáng kể trên phân chia huấn luyện so với phân chia kiểm tra. Do đó, chúng tôi giả định rằng những mô hình này có thể đã được huấn luyện trước đáng kể trên phân chia huấn luyện GSM8K hoặc dữ liệu tương tự.

Hơn nữa, chúng tôi chú ý đến một bất thường cụ thể trong cột ∆1, chỉ ra mất mát Ltest thấp hơn đáng kể so với Lref, điều này thú vị để nghiên cứu thêm để hiểu rõ hơn.

5.3 Huấn luyện Trước hay Tinh chỉnh Có giám sát?
Trong thời đại trước sự ra đời của LLM như GPT-4 (Bubeck et al., 2023; OpenAI, 2023) và Claude (Bai et al., 2022), dữ liệu có giám sát cho các nhiệm vụ NLP thường khan hiếm. Điều này là do quá trình thu thập và chú thích dữ liệu vừa tốn thời gian vừa tốn kém. Do sự khan hiếm của dữ liệu có giám sát, các nhà nghiên cứu NLP dựa vào các kỹ thuật huấn luyện trước không giám sát (Mikolov et al., 2013; Peters et al., 2018; Radford et al., 2018; Devlin et al., 2019) để cải thiện hiệu suất nhiệm vụ phụ thông qua học chuyển giao, nơi dữ liệu có giám sát chỉ được sử dụng trong giai đoạn tinh chỉnh. Trong bối cảnh này, việc huấn luyện trước trên dữ liệu trong lĩnh vực (có giám sát) là vô nghĩa, vì nó sẽ đánh bại mục đích của chính việc huấn luyện trước (học chuyển giao).

Thực tế này đã thay đổi đáng kể, tuy nhiên, với sự xuất hiện của các LLM mạnh mẽ. Điều này là do việc thu thập lượng lớn dữ liệu có giám sát/trong lĩnh vực chất lượng cao giờ đây đơn giản như việc thực hiện một số yêu cầu API đến những LLM này, và nó tương đối có chi phí thấp (Wang et al., 2023; Taori et al., 2023). Thực tế mới này làm mờ ranh giới giữa huấn luyện trước và tinh chỉnh có giám sát, làm cho việc tích hợp lượng lớn dữ liệu có giám sát vào giai đoạn huấn luyện trước trở nên khả thi (Gunasekar et al., 2023; Li et al., 2023b). Sau tất cả, dữ liệu trong lĩnh vực được tuyển chọn, dù được viết bởi người chú thích con người hay được tạo ra bởi LLM, đều là dạng kiến thức con người, và có lý do chính đáng cho kiến thức này được hấp thụ vào một mô hình nền tảng.

Điều đó nói rằng, chúng tôi tin rằng có rủi ro hợp lý trong thực hành huấn luyện trước có mục tiêu, ở chỗ nó thỏa hiệp tính công bằng trong việc đánh giá benchmark. Trong khi thông qua huấn luyện trước trên dữ liệu trong lĩnh vực một mô hình có thể xuất sắc trong các nhiệm vụ cụ thể, vẫn không chắc chắn về mức độ hoạt động tốt của nó trên các nhiệm vụ chưa thấy. Khả năng của nó có thể bị đánh giá quá cao dựa trên benchmark một mình, điều này có thể dẫn đến so sánh không công bằng giữa các mô hình và hiểu lầm người dùng hoặc các bên liên quan về khả năng thực sự của mô hình.

6 Hạn chế
Phương pháp huấn luyện trước của chúng tôi cho Skywork-13B bao gồm một quy trình hai giai đoạn: huấn luyện trước mục đích chung theo sau là huấn luyện trước nâng cao theo lĩnh vực cụ thể. Tuy nhiên, vẫn chưa rõ liệu phương pháp này có thể tạo ra một mô hình ngang bằng với, hoặc vượt trội hơn, một mô hình được huấn luyện trong một giai đoạn trên kho dữ liệu hỗn hợp. Cần có thêm điều tra để xác định hiệu quả tương đối của những phương pháp huấn luyện trước này.

Ngoài ra, chúng tôi đã đề xuất sử dụng mất mát mô hình hóa ngôn ngữ hoặc perplexity như các chỉ số proxy để giám sát và đánh giá các mô hình ngôn ngữ lớn. Một hạn chế là đánh giá mô hình hóa ngôn ngữ dựa vào phân phối cụ thể được sử dụng để lấy mẫu dữ liệu kiểm tra, trong đó có vô số khả năng. Mặc dù perplexity mô hình hóa ngôn ngữ trên một phân phối dữ liệu nhất định có thể dự đoán hiệu suất trên một số nhiệm vụ, nhưng nó có thể không chuyển đổi sang các nhiệm vụ khác. Mối tương quan giữa mô hình hóa ngôn ngữ và hiệu suất phụ có thể thay đổi trên các phân phối và nhiệm vụ khác nhau.

7 Kết luận
Công việc của chúng tôi về Skywork-13B đại diện cho một bước tiến đáng kể trong việc phát triển các mô hình ngôn ngữ lớn mở. Chúng tôi tin rằng cách tiếp cận toàn diện và minh bạch của chúng tôi đối với việc phát triển mô hình sẽ là một nguồn tài nguyên có giá trị cho các nhà nghiên cứu trong lĩnh vực này, thúc đẩy sự hợp tác và các nguyên tắc mã nguồn mở. Phương pháp huấn luyện hai giai đoạn của chúng tôi, tận dụng kho dữ liệu phân đoạn, cung cấp một cách tiếp cận mới để nâng cao khả năng mô hình trong lĩnh vực cụ thể, trong khi phương pháp giám sát tiến trình huấn luyện của chúng tôi cung cấp một giải pháp thực tế cho những thách thức trong việc theo dõi sự cải thiện của những mô hình này theo thời gian.

Tuy nhiên, công việc của chúng tôi không chỉ là việc tạo ra một LLM mới. Đó là lời kêu gọi hành động cho cộng đồng NLP rộng lớn hơn, thúc giục trở lại với các nguyên tắc công bằng, minh bạch, và chia sẻ ý tưởng đã từng thúc đẩy tiến bộ trong lĩnh vực này. Chúng tôi hy vọng rằng Skywork-13B sẽ không chỉ phục vụ như một công cụ mạnh mẽ cho một loạt các ứng dụng mà còn truyền cảm hứng cho cam kết mới về sự cởi mở và hợp tác trong việc phát triển các mô hình tương lai.

Tài liệu tham khảo

[Danh sách tài liệu tham khảo tiếng Anh được giữ nguyên như trong bản gốc]

Phụ lục A Chi tiết về Thí nghiệm GPT-7B so với LLaMA-7B

Trong một thí nghiệm sơ bộ, chúng tôi so sánh hiệu suất mô hình hóa ngôn ngữ giữa kiến trúc GPT và LLaMA trong một môi trường được kiểm soát. Chúng tôi đã huấn luyện một mô hình 7B với kiến trúc GPT và một mô hình 7B có thể so sánh với kiến trúc LLaMA cho 200B token được lấy mẫu từ cùng một kho dữ liệu và với cùng các tham số huấn luyện. Chi tiết được đưa ra trong Bảng 9.

Phụ lục B Thí nghiệm Sơ bộ về Huấn luyện Phân tán

Trong Bảng 10, chúng tôi báo cáo kết quả sơ bộ thu được với các cấu hình huấn luyện phân tán khác nhau trên kiến trúc mô hình LLaMA-13B và Skywork-13B. Trong cả hai trường hợp, throughput tốt nhất được đạt được với DP256 và PP2 với cài đặt ZERO-1.

Phụ lục C Thêm Kết quả Benchmark

Chúng tôi cũng cung cấp kết quả của các benchmark sau trong Bảng 11:

•TriviaQA (Joshi et al., 2017): TriviaQA là một bộ dữ liệu hỏi đáp dựa trên văn bản thực tế bao gồm 950K cặp câu hỏi-câu trả lời từ 662K tài liệu được thu thập từ Wikipedia và web.

•HellaSwag (Zellers et al., 2019): HellaSWAG là một bộ dữ liệu tập trung vào suy luận thông thường có căn cứ.

•Winogrande (Sakaguchi et al., 2021): WinoGrande là một bộ dữ liệu tập trung vào suy luận thông thường.

•BoolQ (Clark et al., 2019) BoolQ là một bộ dữ liệu hỏi đáp cho các câu hỏi có/không.

•PIQA (Bisk et al., 2019): PIQA là một bộ dữ liệu cho suy luận thông thường, và được tạo ra để điều tra kiến thức vật lý của các mô hình hiện tại trong NLP.

•ARC (Clark et al., 2018): ARC là một bộ dữ liệu bao gồm các nhiệm vụ hỏi đáp trắc nghiệm tập trung vào suy luận thông thường.

•RACE (Lai et al., 2017) RACE là một bộ dữ liệu tập trung vào đọc hiểu.

Phụ lục D Chi tiết về Tập Kiểm tra LM

Chúng tôi đã thiết lập một quá trình thu thập hàng ngày các bài báo và bài đăng của người dùng được xuất bản từ một lựa chọn các trang web tiếng Trung được sử dụng rộng rãi. Quá trình thu thập dữ liệu này khác biệt với quy trình được sử dụng để xây dựng SkyPile. Mục đích của việc thu thập dữ liệu này là tạo ra các tập kiểm tra mô hình hóa ngôn ngữ độc lập, được phân loại theo lĩnh vực của chúng, để đánh giá các Mô hình Học Ngôn ngữ (LLM) mở hiện tại.

Dưới đây chúng tôi mô tả các nguồn của những bộ dữ liệu kiểm tra theo lĩnh vực này:

•Công nghệ: Các bài báo liên quan đến AI từ (36kr.com). Trang web này cung cấp các bài báo tin tức kịp thời và toàn diện về các startup, công nghệ và xu hướng kinh doanh, chủ yếu trong thị trường Trung Quốc.

•Phim: Đánh giá phim do người dùng viết từ Douban (douban.com). Douban là một dịch vụ mạng xã hội phổ biến tại Trung Quốc cung cấp một nền tảng cho người dùng chia sẻ ý kiến và tạo nội dung liên quan đến phim, sách và âm nhạc. Đây là một trong những trang web 2.0 có ảnh hưởng nhất tại Trung Quốc và có trọng tâm mạnh mẽ vào nội dung do người dùng tạo ra.

•Chính phủ: Tin tức từ trang web của Nhân dân Nhật báo (www.people.com.cn), đây là tờ báo có ảnh hưởng và uy tín nhất tại Trung Quốc. Ngôn ngữ được sử dụng trong tin tức thường là tiếng Trung Quốc chuẩn chính thức và mang tông điều uy tín.

•Trò chơi: Các bài báo từ Gcores (www.gcores.com). Đây là một nền tảng truyền thông số Trung Quốc dành riêng cho trò chơi video, xu hướng công nghệ và văn hóa geek. Nền tảng này có nhiều nội dung gốc đa dạng, bao gồm các bài báo tin tức, tập podcast, video và trò chơi độc lập.

•Tài chính: Tin tức từ phần tài chính của Sina (finance.sina.com.cn). Đây là một trong những công ty truyền thông trực tuyến hàng đầu của Trung Quốc, cung cấp một bộ dịch vụ và thông tin tài chính toàn diện. Nó bao gồm một loạt các chủ đề bao gồm thị trường chứng khoán, ngoại hối, hàng hóa, bất động sản và tài chính cá nhân.

•Tổng quát: Tin tức từ Jiemian News (www.jiemian.com). Jiemian là một nền tảng truyền thông số nổi bật của Trung Quốc nổi tiếng với báo chí sâu sắc và chất lượng cao. Nó bao gồm một loạt các chủ đề, bao gồm chính trị, kinh tế, văn hóa, công nghệ, tài chính và lối sống.

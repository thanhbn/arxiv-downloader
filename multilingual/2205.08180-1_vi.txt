# 2205.08180.pdf
# Đã chuyển từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/multilingual/2205.08180.pdf
# Kích thước tệp: 1915343 bytes

===============================================
NỘI DUNG TẬP TIN PDF
===============================================

--- TRANG 1 ---
1
SAMU-XLSR: Biểu diễn Ngôn ngữ Đa ngôn ngữ
Đa phương thức Được căn chỉnh theo Ngữ nghĩa ở
Mức độ Phát ngôn
Sameer Khurana1, Antoine Laurent2, James Glass1
1MIT Computer Science and Artificial Intelligence Laboratory, Cambridge, MA, USA
2LIUM - Le Mans University, France
fskhurana, glassg@mit.edu
Tóm tắt —Chúng tôi đề xuất SAMU-XLSR: Khung học tập biểu diễn Ngôn ngữ Đa ngôn ngữ Đa phương thức được căn chỉnh theo Ngữ nghĩa ở mức độ Phát ngôn. Không như các công trình trước đây về học biểu diễn ngôn ngữ, việc học nhúng ngôn ngữ đa ngôn ngữ theo ngữ cảnh ở độ phân giải của một khung âm thanh (10-20ms), công trình này tập trung vào việc học nhúng ngôn ngữ đa phương thức (tiếng nói-văn bản) đa ngôn ngữ ở độ phân giải của một câu (5-10s) sao cho không gian vector nhúng được căn chỉnh theo ngữ nghĩa qua các ngôn ngữ khác nhau. Chúng tôi kết hợp mô hình học biểu diễn ngôn ngữ ở mức khung âm thanh đa ngôn ngữ tiên tiến XLS-R với mô hình Language Agnostic BERT Sentence Embedding (LaBSE) để tạo ra một bộ mã hóa ngôn ngữ đa phương thức đa ngôn ngữ ở mức phát ngôn SAMU-XLSR. Mặc dù chúng tôi huấn luyện SAMU-XLSR chỉ với dữ liệu ngôn ngữ đa ngôn ngữ có phiên âm, các liên kết ngôn ngữ-văn bản và ngôn ngữ-ngôn ngữ đa ngôn ngữ xuất hiện trong không gian biểu diễn đã học của nó. Để chứng minh các tuyên bố của chúng tôi, chúng tôi sử dụng bộ mã hóa ngôn ngữ SAMU-XLSR kết hợp với bộ mã hóa câu văn bản LaBSE đã được huấn luyện trước cho việc truy xuất dịch thuật ngôn ngữ-văn bản đa ngôn ngữ, và SAMU-XLSR một mình cho việc truy xuất dịch thuật ngôn ngữ-ngôn ngữ đa ngôn ngữ. Chúng tôi nổi bật các ứng dụng này bằng cách thực hiện một số tác vụ truy xuất dịch thuật văn bản và ngôn ngữ đa ngôn ngữ trên nhiều bộ dữ liệu.
Từ khóa chỉ mục —Học biểu diễn ngôn ngữ đa ngôn ngữ, Nhúng ngôn ngữ bất khả tri ngôn ngữ, Truy xuất dịch thuật ngôn ngữ-văn bản zero-shot, Truy xuất dịch thuật ngôn ngữ-ngôn ngữ zero-shot

I. GIỚI THIỆU
Gần đây, việc huấn luyện trước tự giám sát các bộ mã hóa transformer lớn trên lượng dữ liệu âm thanh không nhãn khổng lồ theo sau bởi việc tinh chỉnh cụ thể cho tác vụ đã nổi lên như phương pháp de-facto để đạt được hiệu suất tiên tiến trên nhiều tác vụ trong xử lý ngôn ngữ nói. Tuy nhiên, các phương pháp học biểu diễn tự giám sát (SSL) phổ biến như Wav2vec-2.0 [1] và các phương pháp khác [2]–[12] học nhúng ngôn ngữ ở mức khung âm thanh, tức là cho các đoạn ngôn ngữ ngắn có thời lượng từ 10 đến 20 mili giây.

Không giống như các công trình trước đây được đề cập ở trên, công trình này tập trung vào việc học biểu diễn ngôn ngữ đa ngôn ngữ đa phương thức ở mức phát ngôn được căn chỉnh theo ngữ nghĩa (SAMU-XLSR). Không gian vector nhúng của SAMU-XLSR là đa phương thức vì nó được chia sẻ giữa các phương thức ngôn ngữ và văn bản. Nó là đa ngôn ngữ vì các ngôn ngữ khác nhau chia sẻ nó. Hơn nữa, nó được căn chỉnh theo ngữ nghĩa vì, trong không gian vector của SAMU-XLSR, một phát ngôn được phát ra được nhóm cùng với các bản dịch ngôn ngữ và văn bản của nó. Chúng tôi hiển thị một minh họa hai chiều của không gian vector nhúng mong muốn trong Hình 1. Ví dụ, xét cụm từ tiếng Anh A bird is bathing in the sink. Bây giờ, trong không gian nhúng của SAMU-XLSR, dạng viết của cụm từ trên nên được nhóm cùng với dạng viết và nói của nó trong các ngôn ngữ khác nhau (tiếng Nhật, tiếng Pháp, và tiếng Ả Rập trong hình). Và, trong một số vùng khác của không gian nhúng, cụm từ Mr President được nhóm với dạng viết và nói của nó trong nhiều ngôn ngữ. Thật không may, các khung học biểu diễn ngữ cảnh đơn phương thức ở mức khung âm thanh như Wav2vec-2.0 [1] hoặc XLS-R đa ngôn ngữ [7], [9] không học được một không gian nhúng có các tính chất tương tự. Chúng tôi tin rằng việc mã hóa ngữ nghĩa là một trong nhiều mảnh ghép còn thiếu trong câu đố học biểu diễn ngôn ngữ tự giám sát.

Mặt khác, một số bộ mã hóa transformer cho văn bản đã được đề xuất trong những năm gần đây vượt xa các biểu diễn ngữ cảnh ở mức token và học các không gian vector nhúng câu được căn chỉnh theo ngữ nghĩa đa ngôn ngữ qua nhiều ngôn ngữ [13]–[15]. Các mô hình này đã tìm thấy ứng dụng trong khai thác dữ liệu bi-văn bản. Tác vụ là truy xuất bản dịch văn bản trong ngôn ngữ đích cho một truy vấn câu cho trước trong ngôn ngữ nguồn bằng cách khớp nhúng câu truy vấn với các câu trong cơ sở dữ liệu tìm kiếm ngôn ngữ đích [16]–[18]. Cho rằng các bộ mã hóa văn bản có thể học thành công các không gian vector nhúng câu được căn chỉnh theo ngữ nghĩa đa ngôn ngữ, chúng tôi đặt câu hỏi liệu có thể làm cho các không gian nhúng văn bản này trở thành đa phương thức bằng cách học ánh xạ các phát ngôn ngôn ngữ trong không gian nhúng văn bản đa ngôn ngữ được căn chỉnh theo ngữ nghĩa hay không.

Để làm được điều đó, chúng tôi đề xuất một khung học đa phương thức để tinh chỉnh bộ mã hóa ngôn ngữ XLS-R đa ngôn ngữ đã được huấn luyện trước thông qua chưng cất kiến thức từ bộ mã hóa câu BERT bất khả tri ngôn ngữ đã được huấn luyện trước LaBSE [15]. Ngoài ra, chúng tôi thêm một cơ chế gộp và một lớp chiếu phi tuyến sau lớp cuối cùng của bộ mã hóa XLS-R đã được huấn luyện trước để biến đổi các biểu diễn ngữ cảnh ở mức khung thành một vector nhúng ở mức phát ngôn duy nhất. Sau đó, chúng tôi huấn luyện bộ mã hóa ngôn ngữ sử dụng ngôn ngữ có phiên âm; cho một phát ngôn ngôn ngữ, các tham số của bộ mã hóa ngôn ngữ được điều chỉnh để dự đoán chính xác nhúng văn bản được cung cấp bởi bộ mã hóa LaBSE của phiên âm tương ứng. Bởi vì không gian vector nhúng của LaBSE được căn chỉnh theo ngữ nghĩa qua các ngôn ngữ khác nhau, phiên âm văn bản sẽ được nhóm cùng với các bản dịch văn bản của nó. Do đó, chúng tôi nhận được các liên kết ngôn ngữ-văn bản đa ngôn ngữ miễn phí bằng cách chỉ sử dụng ngôn ngữ có phiên âm để huấn luyện bộ mã hóa ngôn ngữ thông qua khung chưng cất kiến thức được đề xuất. Để có mô tả giáo dục, xem Hình 2.

Một trong những trường hợp sử dụng của không gian nhúng SAMU-XLSR được mô tả ở trên là cho khai thác dữ liệu. Những năm gần đây đã chứng kiến tiến bộ đáng kể trong Nhận dạng Giọng nói Tự động qua nhiều lĩnh vực và ngôn ngữ. Biên giới tiếp theo trong xử lý ngôn ngữ nói là dịch máy tự động từ ngôn ngữ sang văn bản và từ ngôn ngữ sang ngôn ngữ. Phát triển các hệ thống MT dựa trên ngôn ngữ sẽ yêu cầu lượng dữ liệu ngôn ngữ dịch song song khổng lồ trong nhiều ngôn ngữ, điều này có thể rất tốn kém để thu thập. Nhưng, không gian nhúng đa phương thức đa ngôn ngữ được minh họa trong Hình 1 có thể giải quyết vấn đề này. Chúng tôi có thể xây dựng một đường ống truy xuất từ ngôn ngữ sang văn bản và từ ngôn ngữ sang ngôn ngữ đa ngôn ngữ, có thể hoàn toàn hoặc, trong một số trường hợp, một phần tự động hóa quá trình thu thập các bản dịch văn bản hoặc ngôn ngữ tương ứng với một phát ngôn. Chúng tôi khuyên người đọc nên xem các bài báo trong Xử lý Ngôn ngữ Tự nhiên sử dụng các bộ mã hóa câu đa ngôn ngữ để thực hiện khai thác văn bản đa ngôn ngữ, chẳng hạn như [15], [19]–[21].

Khai thác từ ngôn ngữ sang văn bản đa ngôn ngữ để tạo ra các bộ dữ liệu dịch song song ngôn ngữ-văn bản chỉ là một ứng dụng có thể có của SAMU-XLSR. Nhưng, điều thúc đẩy chúng tôi làm việc trên vấn đề này là ứng dụng tiềm năng trong dịch thuật zero-shot từ ngôn ngữ sang văn bản. Thành công của dịch thuật zero-shot phụ thuộc vào việc học một không gian vector nhúng bất biến ngôn ngữ được căn chỉnh theo ngữ nghĩa hoặc một interlingua cho các ngôn ngữ nói khác nhau, nơi các phát ngôn ngôn ngữ và các bản dịch ngôn ngữ của chúng được nhóm cùng nhau. Chúng tôi cho thấy rằng đây là một tính chất nổi lên trong không gian vector nhúng của SAMU-XLSR như một kết quả của việc huấn luyện SAMU-XLSR sử dụng khung học đa phương thức được đề xuất (Phần IV-E). Một số bài báo dịch máy văn bản truyền cảm hứng cho chúng tôi trong lĩnh vực dịch thuật zero-shot là [22], [23].

Thông qua công trình này, chúng tôi đóng góp những điều sau:
Chúng tôi đề xuất một khung học đa phương thức đơn giản nhưng hiệu quả cho biểu diễn ngôn ngữ đa phương thức (ngôn ngữ-văn bản chung) ở mức phát ngôn được căn chỉnh theo ngữ nghĩa (SAMU-XLSR) được chia sẻ qua nhiều ngôn ngữ (Phần II).

Đầu tiên, chúng tôi chứng minh hiệu quả của các mô hình của chúng tôi trên nhiều tác vụ truy xuất dịch thuật zero-shot đa ngôn ngữ từ ngôn ngữ sang văn bản và từ ngôn ngữ sang ngôn ngữ (Phần IV).

Thứ hai, chúng tôi cho thấy SAMU-XLSR có thể được sử dụng cho các tác vụ mô hình hóa sequence-to-sequence như nhận dạng phoneme và Nhận dạng Giọng nói Tự động (ASR) (Phần V).

Cuối cùng, chúng tôi tiến hành phân tích để hiểu rõ hơn các quyết định thiết kế khác nhau đã tạo ra SAMU-XLSR (Phần VI).

Một công trình tương tự với chúng tôi được trình bày trong [24]. Không giống như công trình trước đây, chúng tôi đánh giá mô hình của chúng tôi trên nhiều bộ dữ liệu qua nhiều ngôn ngữ với sự nhấn mạnh đặc biệt vào các ngôn ngữ ít tài nguyên.

Hơn nữa, không giống như bộ mã hóa ngôn ngữ đa phương thức được trình bày trong [24], chúng tôi cho thấy SAMU-XLSR hoạt động ngang bằng hoặc tốt hơn XLS-R trên tác vụ ASR downstream qua các ngôn ngữ khác nhau. Chúng tôi khuyên người đọc nên đọc [24] cùng với bài báo này để có được sự hiểu biết toàn diện về lĩnh vực này.

--- TRANG 2 ---
2
Hình 2: Mô tả giáo dục về cách học với dữ liệu ngôn ngữ có phiên âm sử dụng LaBSE làm giáo viên có thể dẫn đến sự xuất hiện của các liên kết ngôn ngữ và văn bản đa ngôn ngữ. Trong minh họa này, chúng tôi sử dụng ngôn ngữ tiếng Anh x(EN) và phiên âm của nó y(EN) để huấn luyện. Các tham số của SAMU-XLSR được điều chỉnh để thu hẹp khoảng cách giữa nhúng ngôn ngữ được cung cấp bởi SAMU-XLSR màu cam và nhúng LaBSE (Anchor) của phiên âm văn bản tương ứng màu xanh lá cây. Vì không gian nhúng văn bản của LaBSE được căn chỉnh theo ngữ nghĩa qua các ngôn ngữ khác nhau, bằng cách kéo nhúng ngôn ngữ về phía nhúng neo, chúng tôi tự động học được các căn chỉnh ngôn ngữ-văn bản đa ngôn ngữ mà không bao giờ thấy các liên kết đa ngôn ngữ trong quá trình huấn luyện. Trên thực tế, chúng tôi huấn luyện SAMU-XLSR với ngôn ngữ đa ngôn ngữ có phiên âm, không chỉ tiếng Anh.

về các không gian nhúng câu được căn chỉnh theo ngữ nghĩa đa ngôn ngữ, chúng tôi đặt câu hỏi liệu có thể làm cho các không gian nhúng văn bản này trở thành đa phương thức bằng cách học ánh xạ các phát ngôn ngôn ngữ trong không gian nhúng văn bản đa ngôn ngữ được căn chỉnh theo ngữ nghĩa hay không.

Để làm được điều đó, chúng tôi đề xuất một khung học đa phương thức để tinh chỉnh bộ mã hóa ngôn ngữ XLS-R đa ngôn ngữ đã được huấn luyện trước thông qua chưng cất kiến thức từ bộ mã hóa câu BERT bất khả tri ngôn ngữ đã được huấn luyện trước LaBSE [15]. Ngoài ra, chúng tôi thêm một cơ chế gộp và một lớp chiếu phi tuyến sau lớp cuối cùng của bộ mã hóa XLS-R đã được huấn luyện trước để biến đổi các biểu diễn ngữ cảnh ở mức khung thành một vector nhúng ở mức phát ngôn duy nhất. Sau đó, chúng tôi huấn luyện bộ mã hóa ngôn ngữ sử dụng ngôn ngữ có phiên âm; cho một phát ngôn ngôn ngữ, các tham số của bộ mã hóa ngôn ngữ được điều chỉnh để dự đoán chính xác nhúng văn bản được cung cấp bởi bộ mã hóa LaBSE của phiên âm tương ứng. Bởi vì không gian vector nhúng của LaBSE được căn chỉnh theo ngữ nghĩa qua các ngôn ngữ khác nhau, phiên âm văn bản sẽ được nhóm cùng với các bản dịch văn bản của nó. Do đó, chúng tôi nhận được các liên kết ngôn ngữ-văn bản đa ngôn ngữ miễn phí bằng cách chỉ sử dụng ngôn ngữ có phiên âm để huấn luyện bộ mã hóa ngôn ngữ thông qua khung chưng cất kiến thức được đề xuất. Để có mô tả giáo dục, xem Hình 2.

Một trong những trường hợp sử dụng của không gian nhúng SAMU-XLSR được mô tả ở trên là cho khai thác dữ liệu. Những năm gần đây đã chứng kiến tiến bộ đáng kể trong Nhận dạng Giọng nói Tự động qua nhiều lĩnh vực và ngôn ngữ. Biên giới tiếp theo trong xử lý ngôn ngữ nói là dịch máy tự động từ ngôn ngữ sang văn bản và từ ngôn ngữ sang ngôn ngữ. Phát triển các hệ thống MT dựa trên ngôn ngữ sẽ yêu cầu lượng dữ liệu ngôn ngữ dịch song song khổng lồ trong nhiều ngôn ngữ, điều này có thể rất tốn kém để thu thập. Nhưng, không gian nhúng đa phương thức đa ngôn ngữ được minh họa trong Hình 1 có thể giải quyết vấn đề này. Chúng tôi có thể xây dựng một đường ống truy xuất từ ngôn ngữ sang văn bản và từ ngôn ngữ sang ngôn ngữ đa ngôn ngữ, có thể hoàn toàn hoặc, trong một số trường hợp, một phần tự động hóa quá trình thu thập các bản dịch văn bản hoặc ngôn ngữ tương ứng với một phát ngôn. Chúng tôi khuyên người đọc nên xem các bài báo trong Xử lý Ngôn ngữ Tự nhiên sử dụng các bộ mã hóa câu đa ngôn ngữ để thực hiện khai thác văn bản đa ngôn ngữ, chẳng hạn như [15], [19]–[21].

Khai thác từ ngôn ngữ sang văn bản đa ngôn ngữ để tạo ra các bộ dữ liệu dịch song song ngôn ngữ-văn bản chỉ là một ứng dụng có thể có của SAMU-XLSR. Nhưng, điều thúc đẩy chúng tôi làm việc trên vấn đề này là ứng dụng tiềm năng trong dịch thuật zero-shot từ ngôn ngữ sang văn bản. Thành công của dịch thuật zero-shot phụ thuộc vào việc học một không gian vector nhúng bất biến ngôn ngữ được căn chỉnh theo ngữ nghĩa hoặc một interlingua cho các ngôn ngữ nói khác nhau, nơi các phát ngôn ngôn ngữ và các bản dịch ngôn ngữ của chúng được nhóm cùng nhau. Chúng tôi cho thấy rằng đây là một tính chất nổi lên trong không gian vector nhúng của SAMU-XLSR như một kết quả của việc huấn luyện SAMU-XLSR sử dụng khung học đa phương thức được đề xuất (Phần IV-E). Một số bài báo dịch máy văn bản truyền cảm hứng cho chúng tôi trong lĩnh vực dịch thuật zero-shot là [22], [23].

Thông qua công trình này, chúng tôi đóng góp những điều sau:
Chúng tôi đề xuất một khung học đa phương thức đơn giản nhưng hiệu quả cho biểu diễn ngôn ngữ đa phương thức (ngôn ngữ-văn bản chung) ở mức phát ngôn được căn chỉnh theo ngữ nghĩa (SAMU-XLSR) được chia sẻ qua nhiều ngôn ngữ (Phần II).

Đầu tiên, chúng tôi chứng minh hiệu quả của các mô hình của chúng tôi trên nhiều tác vụ truy xuất dịch thuật zero-shot đa ngôn ngữ từ ngôn ngữ sang văn bản và từ ngôn ngữ sang ngôn ngữ (Phần IV).

Thứ hai, chúng tôi cho thấy SAMU-XLSR có thể được sử dụng cho các tác vụ mô hình hóa sequence-to-sequence như nhận dạng phoneme và Nhận dạng Giọng nói Tự động (ASR) (Phần V).

Cuối cùng, chúng tôi tiến hành phân tích để hiểu rõ hơn các quyết định thiết kế khác nhau đã tạo ra SAMU-XLSR (Phần VI).

Một công trình tương tự với chúng tôi được trình bày trong [24]. Không giống như công trình trước đây, chúng tôi đánh giá mô hình của chúng tôi trên nhiều bộ dữ liệu qua nhiều ngôn ngữ với sự nhấn mạnh đặc biệt vào các ngôn ngữ ít tài nguyên.

Hơn nữa, không giống như bộ mã hóa ngôn ngữ đa phương thức được trình bày trong [24], chúng tôi cho thấy SAMU-XLSR hoạt động ngang bằng hoặc tốt hơn XLS-R trên tác vụ ASR downstream qua các ngôn ngữ khác nhau. Chúng tôi khuyên người đọc nên đọc [24] cùng với bài báo này để có được sự hiểu biết toàn diện về lĩnh vực này.

--- TRANG 3 ---
3
Hình 3: Minh họa về khung huấn luyện đa phương thức

II. PHƯƠNG PHÁP LUẬN
A. Công thức hóa Vấn đề
Chúng tôi huấn luyện SAMU-XLSR sử dụng một tập hợp đa ngôn ngữ D của các ví dụ cặp (x(l);y(l)), trong đó x(l) là dạng sóng ngôn ngữ, và y(l) là phiên âm văn bản của nó trong ngôn ngữ l. Cho một ví dụ huấn luyện, (x(l);y(l)), chúng tôi biến đổi chuỗi các token rời rạc y(l) thành một vector nhúng dày đặc zT∈Rd sử dụng bộ mã hóa văn bản g, và chuỗi các mẫu ngôn ngữ x(l) thành một vector nhúng dày đặc zS∈Rd sử dụng bộ mã hóa ngôn ngữ f. Sau đó, chúng tôi cập nhật các tham số của bộ mã hóa ngôn ngữ f sao cho khoảng cách giữa nhúng ngôn ngữ zS và nhúng văn bản zT được tối thiểu hóa. Hàm mất mát huấn luyện cho một ví dụ được cho bởi phương trình sau:
J(θ;φ) = distance(zS;zT) (1)

Chúng tôi sử dụng Language-agnostic BERT Sentence Encoder (LaBSE) đã được huấn luyện trước làm bộ mã hóa văn bản g và SAMU-XLSR làm bộ mã hóa ngôn ngữ f. Các tham số của bộ mã hóa ngôn ngữ được cập nhật trong quá trình huấn luyện, trong khi các tham số của bộ mã hóa văn bản vẫn cố định. Minh họa về khung học đa phương thức được hiển thị trong Hình 3.

B. Bộ Mã hóa Ngôn ngữ SAMU-XLSR, f
SAMU-XLSR bao gồm một bộ mã hóa ngôn ngữ XLS-R ở mức khung đã được huấn luyện trước [9] theo sau bởi một cơ chế gộp các biểu diễn ngữ cảnh ở mức khung thành một vector nhúng duy nhất.

Bộ mã hóa ngôn ngữ XLS-R bao gồm một mạng neural tích chập sâu ánh xạ chuỗi thời gian 1D đại diện cho các giá trị mẫu của dạng sóng ngôn ngữ thành một chuỗi 2D của các vector đặc trưng H∈RT×512. Mỗi vector đặc trưng ht∈H đại diện cho 20ms của tín hiệu ngôn ngữ. Độ phân giải thời gian của ht tương tự như của một khung âm thanh. Do đó, chúng tôi gọi H là các biểu diễn ở mức khung. Tiếp theo, chuỗi đặc trưng H được biến đổi thành các biểu diễn ngữ cảnh C∈RT×1024 bởi một bộ mã hóa transformer sâu [25]. Bộ mã hóa transformer bao gồm 24 khối transformer Multi-Headed Self-Attention (MHSA). Kích thước vector attention là 1024, và có 16 đầu attention trong mỗi khối. Chúng tôi sử dụng checkpoint XLS-R đã được huấn luyện trước có sẵn công khai¹ được huấn luyện trên 400k giờ dữ liệu ngôn ngữ không nhãn trong 128 ngôn ngữ.

¹https://huggingface.co/facebook/wav2vec2-xls-r-300m

Tiếp theo, chúng tôi sử dụng chiến lược gộp Self-Attention [26] để có được một vector nhúng ở mức phát ngôn duy nhất e∈R1024. Trong chiến lược gộp này, chúng tôi lấy tổ hợp có trọng số ∑T t=1 vtct của các vector ngữ cảnh ct∈C, trong đó v = (v1;···;vT) là vector attention, được cho bởi phương trình sau:
v = softmax(Cw) (2)

trong đó, w∈R1024, cho v∈RT, sao cho ∑t vt = 1. Vector trọng số w được học trong quá trình huấn luyện.

Cuối cùng, chúng tôi thực hiện một phép chiếu phi tuyến của vector nhúng e để có được nhúng ngôn ngữ zS. Nhìn chung, bộ mã hóa ngôn ngữ SAMU-XLSR bao gồm khoảng 300 triệu tham số có thể huấn luyện (trọng số và bias).

C. Bộ Mã hóa Văn bản LaBSE, g
Thành phần chính trong khung học đa phương thức được đề xuất của chúng tôi là bộ mã hóa văn bản LaBSE g, cho phép chúng tôi học một không gian nhúng ngôn ngữ-văn bản chung được căn chỉnh theo ngữ nghĩa và được chia sẻ qua các ngôn ngữ khác nhau. LaBSE là một bộ mã hóa văn bản bất khả tri ngôn ngữ cho văn bản với kiến trúc tương tự như bộ mã hóa transformer BERT [27]. Tuy nhiên, không giống như BERT, LaBSE là một mô hình nhúng câu, được huấn luyện sử dụng cả hai hàm mục tiêu mô hình hóa ngôn ngữ được che dấu [27] và dịch thuật [28]. LaBSE bao gồm một bộ mã hóa transformer ở mức token với 12 lớp MHSA, theo sau bởi một cơ chế gộp để xây dựng một vector nhúng ở mức câu dày đặc.

Bộ mã hóa transformer của LaBSE nhận đầu vào là văn bản được token hóa thành "wordpieces" [29], [30] và xuất ra một chuỗi các nhúng token ngữ cảnh W∈RL×768. Một phép chiếu phi tuyến của nhúng token CLS được sử dụng làm nhúng câu zT∈R768, được sử dụng làm mục tiêu huấn luyện cho việc huấn luyện SAMU-XLSR. Chúng tôi sử dụng checkpoint mô hình LaBSE đã được huấn luyện trước² được lưu trữ trên nền tảng mô hình Huggingface [31]³. Chúng tôi gọi việc sử dụng nhúng token CLS để biểu diễn câu là gộp CLS để phù hợp với thuật ngữ được sử dụng trong bộ mã hóa LaBSE được lưu trữ trên Huggingface.

LaBSE nhúng các câu từ 109 ngôn ngữ thành một không gian vector nhúng được chia sẻ căn chỉnh theo ngữ nghĩa. Không giống như LaBSE, các bộ mã hóa văn bản đa ngôn ngữ khác như XLM-R [32] không học được một không gian nhúng câu được căn chỉnh. Do đó, để đạt được mục tiêu nhúng ngôn ngữ trong một không gian vector được căn chỉnh theo ngữ nghĩa, chúng tôi sử dụng LaBSE làm giáo viên để huấn luyện SAMU-XLSR.

²https://huggingface.co/sentence-transformers/LaBSE
³https://huggingface.co/models

D. Chi tiết Huấn luyện SAMU-XLSR
1) Dữ liệu Huấn luyện, D: Chúng tôi huấn luyện SAMU-XLSR trên ngôn ngữ có phiên âm trong 25 ngôn ngữ được lấy từ bộ dữ liệu CommonVoice-v7 (CoVo) có sẵn công khai. 25 ngôn ngữ đó là tiếng Anh (EN), tiếng Pháp (FR), tiếng Đức (DE), tiếng Tây Ban Nha (ES), tiếng Catalan (CA), tiếng Ý (IT), tiếng Wales (CY), tiếng Nga (RU), tiếng Trung (Trung Quốc) (ZH CN), tiếng Trung (Đài Loan) (ZH TW), tiếng Trung (Hồng Kông) (ZH HK), tiếng Bồ Đào Nha (PT), tiếng Ba Lan (PL), tiếng Ba Tư (FA), tiếng Estonia (ET), tiếng Mông Cổ (MN), tiếng Hà Lan (NL), tiếng Thổ Nhĩ Kỳ (TR), tiếng Ả Rập (AR), tiếng Thụy Điển (SV SE), tiếng Latvia (LV), tiếng Slovenia (SL), tiếng Tamil (TA), tiếng Nhật (JA) và tiếng Indonesia (ID). Bảng I hiển thị dữ liệu ngôn ngữ có phiên âm cho mỗi ngôn ngữ có sẵn trong CoVo. Tổng kích thước dữ liệu huấn luyện là 6,8K giờ.

Rõ ràng, dữ liệu rất mất cân bằng. 5 ngôn ngữ có nhiều tài nguyên nhất chiếm 72% dữ liệu huấn luyện, trong khi 14 ngôn ngữ ít tài nguyên nhất chỉ chiếm 10% dữ liệu huấn luyện. Vấn đề được đề cập ở trên có thể dẫn đến SAMU-XLSR bị underfitting nghiêm trọng trên các ngôn ngữ ít tài nguyên, vì SAMU-XLSR, trong suốt thời gian huấn luyện, có thể chỉ gặp dữ liệu ngôn ngữ có phiên âm từ các ngôn ngữ ít tài nguyên trong mini-batch huấn luyện của nó chỉ vài lần. Theo [33], [34], chúng tôi cân bằng lại tập huấn luyện D bằng cách tăng/giảm mẫu dữ liệu từ mỗi ngôn ngữ l với tỷ lệ αl:

αl = 1/pl^α / ∑l' pl'^α với pl = nl / ∑L l=1 nl (3)

trong đó α là tham số làm mượt, nl là số lượng phát ngôn cho ngôn ngữ l trong tập huấn luyện. Hình 4 hiển thị cách thay đổi α giữa 1,0 và 0,05 cân bằng lại tập huấn luyện. Khi chúng tôi làm α nhỏ hơn, quan sát thấy rằng tỷ lệ của các ngôn ngữ ít tài nguyên trong tập huấn luyện trở nên gần giống với của các ngôn ngữ có nhiều tài nguyên. Điều quan trọng cần lưu ý là khi chúng tôi tăng mẫu dữ liệu từ các ngôn ngữ ít tài nguyên, chúng tôi chỉ đơn giản lặp lại các phát ngôn từ những ngôn ngữ đó, và việc giảm mẫu dữ liệu từ các ngôn ngữ có nhiều tài nguyên liên quan đến việc chọn các phát ngôn ngẫu nhiên theo tỷ lệ αl. Do đó, việc huấn luyện với một tập huấn luyện được cân bằng lại được tạo ra bằng cách sử dụng một giá trị α nhỏ có thể dẫn đến suy giảm hiệu suất trên các ngôn ngữ có nhiều tài nguyên so với mô hình được huấn luyện với tập huấn luyện mất cân bằng gốc. Chúng tôi nghiên cứu tác động của tham số làm mượt α lên hiệu suất tác vụ downstream của mô hình trong Phần VI-B.

2) Cài đặt Tối ưu hóa: Chúng tôi huấn luyện SAMU-XLSR trong 400K vòng lặp huấn luyện, trên 32 GPU V100-32gb, với kích thước mini-batch mỗi GPU khoảng 2 giờ ngôn ngữ có phiên âm. Theo [7], chúng tôi sử dụng trình tối ưu hóa Adam để cập nhật các tham số mô hình với một bộ lập lịch tốc độ học ba giai đoạn; Làm ấm tốc độ học đến giá trị tối đa 1e-4 cho 10% đầu tiên của các vòng lặp huấn luyện, sau đó tốc độ học vẫn không đổi cho 40% tiếp theo của các vòng lặp huấn luyện, và cuối cùng giảm tuyến tính cho phần còn lại của các vòng lặp. Trong 10K vòng lặp huấn luyện đầu tiên, chỉ lớp chiếu của bộ mã hóa SAMU-XLSR được huấn luyện trong khi bộ mã hóa ngôn ngữ XLS-R đã được huấn luyện trước ở mức khung vẫn cố định. Chúng tôi không cập nhật trọng số của bộ trích xuất đặc trưng tích chập của XLS-R trong suốt quá trình huấn luyện. Ngoài ra, chúng tôi sử dụng một phiên bản cải tiến của SpecAugment [35] trên chuỗi đặc trưng H (Phần II-B) để che dấu đầu vào cho bộ mã hóa transformer của XLS-R, điều này dẫn đến hiệu suất tốt hơn trên các tác vụ downstream. Các cài đặt huấn luyện được đề cập ở trên là tiêu chuẩn cho việc tinh chỉnh các bộ mã hóa ngôn ngữ XLS-R hoặc wav2vec-2.0 đã được huấn luyện trước trên các tác vụ ASR downstream [1], [7].

Chúng tôi sử dụng khoảng cách cosine giữa nhúng ngôn ngữ và nhúng văn bản làm hàm mất mát huấn luyện (Phương trình 1). Chúng tôi không cập nhật trọng số của bộ mã hóa văn bản LaBSE trong suốt quá trình huấn luyện. Lý do cho quyết định thiết kế này rất đơn giản. Không gian nhúng câu của LaBSE đã được căn chỉnh theo ngữ nghĩa qua 109 ngôn ngữ. Bằng cách tinh chỉnh LaBSE cùng với SAMU-XLSR trên dữ liệu ngôn ngữ có phiên âm D, chúng tôi có nguy cơ phá hủy sự căn chỉnh này. Thực tế, LaBSE sẽ không có động lực để duy trì một không gian nhúng được căn chỉnh. Thay vào đó, khung học của chúng tôi đơn giản cố gắng nhúng các phát ngôn ngôn ngữ trong không gian nhúng câu của LaBSE để làm cho nó trở thành đa phương thức. Bằng cách đơn giản buộc các nhúng ngôn ngữ được xuất ra bởi SAMU-XLSR gần hơn với nhúng văn bản LaBSE, chúng tôi có được các căn chỉnh ngữ nghĩa đa ngôn ngữ giữa các phát ngôn ngôn ngữ trong các ngôn ngữ khác nhau và văn bản trong 109 ngôn ngữ mà không bao giờ gặp phải các liên kết đa ngôn ngữ trong quá trình huấn luyện mô hình. Tuy nhiên, có thể có khả năng huấn luyện bộ mã hóa văn bản LaBSE cùng với SAMU-XLSR và vẫn duy trì không gian nhúng được căn chỉnh theo ngữ nghĩa của LaBSE. Nhưng điều đó nằm ngoài phạm vi của bài báo này.

E. Thẻ Mô hình SAMU-XLSR
Bảng II tóm tắt cấu hình tốt nhất của các siêu tham số khác nhau để huấn luyện bộ mã hóa SAMU-XLSR. Tiếp theo, chúng tôi giải thích ý nghĩa của một số tham số trong bảng. CoVo 25 đề cập đến dữ liệu ngôn ngữ có phiên âm đa ngôn ngữ được sử dụng để huấn luyện mô hình. Chúng tôi sử dụng dữ liệu trong 25 ngôn ngữ từ bộ dữ liệu CoVo. CNN Feature Extractor đề cập đến bộ mã hóa tích chập đã được huấn luyện trước của XLS-R ánh xạ dạng sóng ngôn ngữ 1D thành biểu diễn đặc trưng 2D được sử dụng làm đầu vào cho bộ mã hóa transformer. Chúng tôi giữ trọng số của nó cố định ở giá trị đã được huấn luyện trước. Freeze Fine-tune updates đề cập đến số lượng vòng lặp huấn luyện mà chúng tôi chỉ huấn luyện lớp chiếu của SAMU-XLSR. Xem Phương trình 3 và văn bản phía trên nó để biết chi tiết về hệ số làm mượt α. Bộ lập lịch tốc độ học (LR scheduler) có giá trị 10-40-50 đề cập đến bộ lập lịch tốc độ học được đề cập trong Phần II-D. Training teacher là LaBSE đề cập đến thực tế rằng các mục tiêu huấn luyện cho SAMU-XLSR là các vector nhúng tương ứng với các phiên âm văn bản được cung cấp bởi LaBSE. Mô hình hỗ trợ 25 ngôn ngữ nói và 109 ngôn ngữ viết vì SAMU-XLSR được huấn luyện trên ngôn ngữ có phiên âm từ 25 ngôn ngữ và LaBSE có thể mã hóa văn bản trong 109 ngôn ngữ trong không gian vector đa ngôn ngữ được căn chỉnh theo ngữ nghĩa của nó.

III. CÁC TÁC VỤ ĐÁNH GIÁ DOWNSTREAM & METRICS
A. Tổng quan
Truy xuất: Chúng tôi đánh giá khung đa phương thức của chúng tôi (Hình 3) bao gồm SAMU-XLSR, một mô hình nhúng ngôn ngữ, và LaBSE, một mô hình nhúng văn bản, trên nhiều tác vụ truy xuất dịch thuật downstream. Truy xuất là một cách phổ biến để đánh giá các không gian vector nhúng câu được căn chỉnh theo ngữ nghĩa đa ngôn ngữ trong xử lý ngôn ngữ tự nhiên [15], [19].

Như đã đề cập trước đây, công trình của chúng tôi nhằm mục đích học một không gian nhúng đa phương thức (ngôn ngữ-văn bản chung) đa ngôn ngữ được căn chỉnh theo ngữ nghĩa. Do đó, nếu thành công trong việc đạt được mục tiêu mong muốn, sự kết hợp SAMU-XLSR-LaBSE nên có hiệu suất tốt trên các tác vụ truy xuất dịch thuật từ ngôn ngữ sang văn bản đa ngôn ngữ. Ngoài ra, chỉ riêng SAMU-XLSR nên có thể hoạt động tốt trên các tác vụ truy xuất dịch thuật từ ngôn ngữ sang ngôn ngữ đa ngôn ngữ.

Tạo Chuỗi: Hơn nữa, chúng tôi thực hiện các tác vụ mô hình hóa sequence-to-sequence, cụ thể là Nhận dạng Phoneme dựa trên Connectionist Temporal Classification (CTC) [36] (tạo ra chuỗi phoneme cơ bản tương ứng với một chuỗi ngôn ngữ đầu vào) và Nhận dạng Giọng nói Tự động (ASR) (tạo ra chuỗi từ cơ bản tương ứng với một chuỗi ngôn ngữ đầu vào) sử dụng SAMU-XLSR.

B. Tác vụ Truy xuất Dịch thuật
Ở đây, chúng tôi tóm tắt quá trình truy xuất, metrics đánh giá và các tác vụ truy xuất dịch thuật từ ngôn ngữ sang văn bản và từ ngôn ngữ sang ngôn ngữ mà chúng tôi sử dụng để đánh giá không gian nhúng ngữ nghĩa đa phương thức của SAMU-XLSR.

Quá trình truy xuất và Metrics Đánh giá: Chúng tôi xây dựng hai cơ sở dữ liệu (DB), truy vấn và tìm kiếm, để thực hiện truy xuất dịch thuật. DB truy vấn bao gồm các phát ngôn ngôn ngữ trong ngôn ngữ X, và trong trường hợp các tác vụ truy xuất dịch thuật văn bản, DB tìm kiếm bao gồm các câu văn bản trong ngôn ngữ Y. Tác vụ là truy xuất bản dịch văn bản chính xác từ DB tìm kiếm tương ứng với mỗi truy vấn ngôn ngữ trong DB truy vấn. Để làm được điều đó, chúng tôi biến đổi các phát ngôn ngôn ngữ trong DB truy vấn thông qua SAMU-XLSR thành ma trận nhúng ngôn ngữ truy vấn Q∈RN×768, trong đó N là số lượng truy vấn ngôn ngữ trong DB truy vấn. Ngoài ra, chúng tôi biến đổi các câu trong DB tìm kiếm thông qua bộ mã hóa LaBSE thành ma trận nhúng văn bản tìm kiếm S∈RM×768, trong đó M là số lượng câu trong DB tìm kiếm. Cho rằng các vector được chuẩn hóa, chúng tôi có thể truy xuất các bản dịch văn bản cho các truy vấn ngôn ngữ như sau:

A = QS^T
r = argmax_j A_{:,j}

trong đó, A∈RN×M là ma trận độ tương tự cosine, có phần tử thứ (i,j) A_{i,j} là độ tương tự cosine giữa nhúng truy vấn ngôn ngữ q_i∈Q và nhúng câu s_j∈S, và r∈R^N là vector chỉ số, sao cho mỗi thành phần r_i∈r là chỉ số của khớp gần nhất trong DB tìm kiếm dịch thuật văn bản. Ngoài ra, cho vector chỉ số u, trong đó mỗi thành phần u_j∈u là chỉ số của bản dịch văn bản ground-truth trong DB tìm kiếm, chúng tôi tính toán độ chính xác truy xuất của mô hình như sau:

ACC = (100/N) * Σ_{i=1}^N 1_{r_i=u_i} (4)

trong đó, hàm 1_{r_i=u_i} trả về một khi r_i=u_i, chỉ số dịch thuật dự đoán khớp với chỉ số dịch thuật ground-truth, nếu không nó xuất ra không. Do đó, tử số là số lượng truy vấn mà mô hình đã truy xuất các bản dịch chính xác từ DB tìm kiếm và mẫu số là tổng số truy vấn trong DB truy vấn.

Chúng tôi gọi độ chính xác truy xuất trong Phương trình 4 là Recall@1 hoặc R@1, tương phản với một metric tương tự khác, R@5, trong đó hàm chỉ báo trả về một nếu bất kỳ chỉ số nào trong top năm chỉ số DB tìm kiếm được truy xuất khớp với chỉ số chính xác. Chúng tôi báo cáo R@5 cho các tác vụ đánh giá truy xuất ngôn ngữ. Recall được sử dụng phổ biến để đánh giá các mô hình học biểu diễn đa phương thức âm thanh-hình ảnh [37]–[39].

Ngoài R@1, cho các tác vụ truy xuất dịch thuật văn bản, chúng tôi cũng báo cáo Word Error Rate (WER) [40] giữa bản dịch văn bản được truy xuất và ground-truth. Lý do là rất khó để diễn giải độ chính xác truy xuất. Ví dụ, WER cho mô hình A với độ chính xác truy xuất 70% có thể không tệ hơn nhiều so với WER cho mô hình B với độ chính xác truy xuất 80% vì mô hình A có thể tệ hơn mô hình B trong việc truy xuất các bản dịch chính xác. Tuy nhiên, nó vẫn có thể khôi phục các bản dịch với sự trùng lặp chuỗi đáng kể với bản dịch thực tế. Độ chính xác truy xuất sẽ không thể nắm bắt được điều này.

Truy xuất Dịch thuật Văn bản X→EN: Chúng tôi sử dụng bộ dữ liệu dịch thuật ngôn ngữ X-EN CoVoST-2 [41] cho tác vụ đánh giá này. DB truy vấn ngôn ngữ trong ngôn ngữ X∈{RU, IT, FR, ES, TR, DE, ET, CY, NL, ID, CA, FA, AR, ZH, SV, MN, SL, JA, TA, LV} và DB tìm kiếm bao gồm các câu tiếng Anh. Để xây dựng DB truy vấn ngôn ngữ cho mỗi ngôn ngữ X, chúng tôi sử dụng các tập test và development kết hợp (từ đây gọi là tập eval) từ CoVoST-2. Để xây dựng DB tìm kiếm, chúng tôi kết hợp bản dịch văn bản tiếng Anh từ tất cả 22 tập eval X→EN trong CoVoST-2, mà chúng tôi gọi là Sa. Ngoài ra, chúng tôi tạo ra một DB tìm kiếm Sb chứa khoảng 1,4M câu tiếng Anh từ dữ liệu ngôn ngữ có phiên âm CoVo tiếng Anh. Chúng tôi sử dụng DB tìm kiếm kết hợp S=Sa∪Sb cho tất cả 22 tác vụ truy xuất dịch thuật văn bản X→EN. Chúng tôi thêm Sb vào Sa để làm cho tác vụ truy xuất khó hơn so với nếu chúng tôi chỉ tìm kiếm trên Sa.

Truy xuất Dịch thuật Văn bản EN→Y: Chúng tôi sử dụng các corpus CoVoST-2 có sẵn công khai [41] cho tác vụ đánh giá này, bao gồm các truy vấn ngôn ngữ tiếng Anh được ghép đôi với bản dịch văn bản của chúng. DB truy vấn ngôn ngữ bằng tiếng Anh và DB tìm kiếm trong ngôn ngữ Y∈{DE, CA, ZH, FA, ET, MN, TR, AR, SV, LV, SL, TA, JA, ID, CY}. Cho mỗi tác vụ truy xuất EN→Y, DB truy vấn bao gồm các phát ngôn ngôn ngữ trong các tập development và testing kết hợp. DB tìm kiếm bao gồm các bản dịch văn bản thực trong ngôn ngữ Y tương ứng với các truy vấn ngôn ngữ. Ngoài ra, chúng tôi thêm các bản dịch văn bản ngôn ngữ Y có sẵn trong tập huấn luyện CoVoST-2 EN→Y để làm cho tác vụ truy xuất khó hơn. Tương tự, chúng tôi tạo ra một DB tìm kiếm cho mỗi trong số 15 ngôn ngữ Y cho tác vụ truy xuất dịch thuật văn bản EN→Y.

Đối với tình huống đánh giá này, chúng tôi cũng thực hiện truy xuất dịch thuật văn bản trên các corpus MUST-C [42] EN→Y. Trong MUST-C, chúng tôi có các truy vấn ngôn ngữ tiếng Anh được ghép đôi với bản dịch văn bản thực của chúng trong ngôn ngữ Y∈{ES, PT, FR, DE, Romanian (RO), NL, IT, Czech (CS), Vietnamese (VI), FA, TR, AR, RU, ZH}. Chúng tôi tạo ra một tập eval, một hợp của các phân chia dữ liệu MUST-C dev, tst-COMMON và tst-HE. DB truy vấn ngôn ngữ bao gồm các phát ngôn ngôn ngữ trong tập eval. DB tìm kiếm cho ngôn ngữ Y bao gồm các câu từ tập eval MUST-C EN→Y kết hợp với các câu từ tập huấn luyện EN→Y.

Truy xuất Dịch thuật Văn bản X→Y: Chúng tôi sử dụng các corpus dịch thuật ngôn ngữ MTEDx [43], bao gồm các truy vấn ngôn ngữ trong ngôn ngữ X được ghép đôi với bản dịch văn bản ground-truth của chúng. Đối với tác vụ đánh giá này, chúng tôi có các cặp dịch thuật X→Y∈{IT→ES, IT→EN, ES→FR, ES→IT, FR→PT, ES→PT, FR→EN, PT→ES, ES→EN, PT→EN, RU→EN}. Đối với một cặp dịch thuật X→Y, chúng tôi có các truy vấn ngôn ngữ trong ngôn ngữ X và DB tìm kiếm văn bản trong ngôn ngữ Y. Đối với một truy xuất X→Y, DB truy vấn bao gồm các phát ngôn ngôn ngữ trong tập eval MTEDx X→Y (dev+test), và DB tìm kiếm văn bản trong ngôn ngữ bao gồm các bản dịch văn bản ground-truth từ tập eval X→Y và tập huấn luyện X→Y. Người đọc có thể quan sát rằng DB tìm kiếm lớn hơn đáng kể so với DB truy vấn cho tất cả các tác vụ truy xuất dịch thuật văn bản và bao gồm các bản dịch văn bản thực tế và các câu ngẫu nhiên để làm cho tác vụ truy xuất khó hơn.

Chúng tôi coi các tác vụ đánh giá truy xuất dịch thuật MTEDx X→Y là ngoài miền vì chúng tôi huấn luyện SAMU-XLSR trên ngôn ngữ đọc có phiên âm từ bộ dữ liệu CoVo. Trong khi đó, MTEDx bao gồm ngôn ngữ thuyết trình được thu thập từ các buổi nói chuyện TED.

Truy xuất Dịch thuật Ngôn ngữ X→EN: Cuối cùng, chúng tôi đánh giá mô hình của chúng tôi trên các tác vụ truy xuất dịch thuật ngôn ngữ. Chúng tôi có được dữ liệu dịch thuật ngôn ngữ-ngôn ngữ song song X→EN từ các corpus VoxPopuli có sẵn công khai [44]. Đối với tác vụ này, các truy vấn ngôn ngữ trong ngôn ngữ X∈{ES, FR, PL, NL, DE, RO, Croatian (HR), CS} và DB tìm kiếm bao gồm các bản dịch ngôn ngữ tiếng Anh tương ứng với các truy vấn. Không giống như các tác vụ truy xuất dịch thuật văn bản, DB tìm kiếm có cùng kích thước với DB truy vấn và chỉ bao gồm các bản dịch ngôn ngữ thực tế tương ứng với các truy vấn.

C. Tác vụ Mô hình hóa Sequence-to-Sequence
Nhận dạng Phoneme: Nhận dạng phoneme đề cập đến tác vụ tự động giải mã chuỗi phoneme cơ bản y tương ứng với một chuỗi ngôn ngữ (x). Chúng tôi tinh chỉnh SAMU-XLSR đã được huấn luyện trước sử dụng các ví dụ cặp (x,y) được rút ra từ bộ dữ liệu CoVo. Theo [7], [45], chúng tôi xây dựng một bộ nhận dạng phoneme cho chín ngôn ngữ khác nhau, cụ thể là ES, FR, IT, Kabyle (KY), NL, RU, SV, TR, và Tatar (TT). Chúng tôi sử dụng một giờ dữ liệu có phiên âm để huấn luyện, 20 phút để xác thực (lựa chọn mô hình), và một giờ để kiểm tra. Các phân chia dữ liệu là những phân chia được đề xuất trong [45] và được sử dụng trong [7] để đánh giá XLS-R trên tác vụ nhận dạng phoneme. Thiết lập tinh chỉnh của chúng tôi khớp với thiết lập tinh chỉnh XLS-R được sử dụng trong [7].

Nhận dạng Giọng nói Tự động: ASR đề cập đến tác vụ tự động giải mã chuỗi từ cơ bản tương ứng với một phát ngôn ngôn ngữ. Thiết lập tinh chỉnh giống như cho Nhận dạng Phoneme. Tuy nhiên, thay vì chuỗi phoneme làm mục tiêu cho huấn luyện, chúng tôi có các chuỗi ký tự. Để tạo ra chuỗi từ từ chuỗi ký tự đã giải mã, chúng tôi sử dụng tìm kiếm chùm CTC với một mô hình ngôn ngữ N-gram ở mức ký tự.

Chúng tôi sử dụng bộ công cụ nhận dạng giọng nói Espnet [46], [47] để tinh chỉnh các mô hình SAMU-XLSR và XLS-R đã được huấn luyện trước cho các tác vụ mô hình hóa sequence-to-sequence.

Chúng tôi tin rằng việc đánh giá SAMU-XLSR trên các tác vụ tạo chuỗi được đề cập ở trên là thú vị vì sẽ rất tốt khi biết liệu SAMU-XLSR, một bộ mã hóa ngôn ngữ mà chúng tôi huấn luyện bằng cách sử dụng một hàm mục tiêu ở mức phát ngôn (Xem Hình ??), cũng có thể được sử dụng cho các tác vụ khác ngoài truy xuất dịch thuật văn bản và ngôn ngữ ở mức phát ngôn.

Một điều khác cần lưu ý là đối với các tác vụ tạo chuỗi, chúng tôi phân tích SAMU-XLSR trước lớp gộp attention (Xem Hình 3 để xem kiến trúc của SAMU-XLSR) và sử dụng các module tính toán trước lớp gộp vì đối với các tác vụ tạo chuỗi, chúng tôi muốn có một biểu diễn ở mức khung âm thanh thay vì nhúng ở mức phát ngôn được xuất ra bởi SAMU-XLSR.

IV. CÁC TÁC VỤ DOWNSTREAM: TRUY XUẤT DỊCH THUẬT ZERO-SHOT
A. Các Mô hình Truy xuất Bổ sung để so sánh với SAMU-XLSR
Đường ống truy xuất ASR-LaBSE: Chúng tôi cũng thực hiện các tác vụ truy xuất dịch thuật sử dụng sự kết hợp ASR-LaBSE, trong đó chúng tôi chuyển đổi các truy vấn ngôn ngữ thành các phiên âm văn bản cùng ngôn ngữ với các truy vấn sử dụng một mô hình ASR. Sau đó, chúng tôi thực hiện truy xuất dịch thuật từ phiên âm ASR sang văn bản sử dụng LaBSE. Chúng tôi xây dựng 25 mô hình ASR cụ thể cho từng ngôn ngữ để bao phủ tất cả các ngôn ngữ nói trong các tác vụ truy xuất dịch thuật văn bản của chúng tôi. Để xây dựng các mô hình ASR, chúng tôi tinh chỉnh checkpoint XLS-R đã được huấn luyện trước trên tác vụ ASR downstream sử dụng dữ liệu ngôn ngữ có phiên âm trong ngôn ngữ đích có sẵn từ bộ dữ liệu CoVo (Xem Bảng I để biết lượng dữ liệu ngôn ngữ có phiên âm cho mỗi ngôn ngữ). Chúng tôi sử dụng thiết lập tối ưu hóa Connectionist temporal Classification [48] tiêu chuẩn để tinh chỉnh mô hình XLS-R cho tác vụ ASR được chi tiết trong [7]. Chúng tôi sử dụng kích thước chùm là 20 và một mô hình ngôn ngữ tri-gram ở mức ký tự để giải mã các truy vấn ngôn ngữ thành văn bản. Chúng tôi sử dụng bộ công cụ nhận dạng giọng nói ESPnet [46], [49] để xây dựng các mô hình ASR và giải mã.

Topline: Như một topline, chúng tôi sử dụng các phiên âm ground-truth tương ứng với các truy vấn ngôn ngữ và thực hiện truy xuất dịch thuật từ phiên âm ground-truth sang văn bản sử dụng LaBSE. Khung truy xuất SAMU-XLSR-LaBSE của chúng tôi không thể hoạt động tốt hơn topline. Vì điều tốt nhất chúng tôi có thể làm với khung học đa phương thức được đề xuất là khớp hoàn hảo các vector nhúng LaBSE.

B. Kết quả trên các tác vụ truy xuất dịch thuật văn bản X→EN
Bảng III hiển thị kết quả trên các tác vụ truy xuất dịch thuật X→EN sử dụng các đường ống truy xuất SAMU-XLSR-LaBSE, ASR-LaBSE và Topline LaBSE. Chúng tôi báo cáo độ chính xác truy xuất (R@1) và WER cho các ngôn ngữ nói khác nhau X. Tác vụ là truy xuất bản dịch văn bản tiếng Anh cho một truy vấn ngôn ngữ đã cho (X). Bảng hiển thị số lượng truy vấn ngôn ngữ cho mỗi ngôn ngữ nói X. Số lượng truy vấn ngôn ngữ trong tập đánh giá thay đổi qua các ngôn ngữ, với nhiều truy vấn hơn cho các ngôn ngữ có nhiều tài nguyên và ít hơn cho các ngôn ngữ ít tài nguyên. Nó là một hàm của tập đánh giá có sẵn cho các ngôn ngữ khác nhau trong tập eval CoVoST-2. Việc tìm kiếm bản dịch tiếng Anh là trên một cơ sở dữ liệu văn bản bao gồm 1,6M câu tiếng Anh. DB văn bản chứa các bản dịch tiếng Anh thực tế và các phiên âm văn bản từ bộ dữ liệu CommonVoice tiếng Anh. Chúng tôi đã thêm các câu tiếng Anh phụ để làm cho tác vụ truy xuất dịch thuật khó hơn so với tìm kiếm trên một cơ sở dữ liệu nhỏ chỉ có các bản dịch tiếng Anh thực. Xem Phần III-B để biết thêm chi tiết về các tác vụ truy xuất X→EN.

Thú vị thay, ASR-LaBSE tệ hơn đáng kể so với mô hình truy xuất SAMU-XLSR-LaBSE trên các tác vụ truy xuất mà các truy vấn ngôn ngữ là các ngôn ngữ phi châu Âu. Ví dụ, trên các tác vụ truy xuất ID→EN, FA→EN, AR→EN, ZH→EN, MN→EN, JA→EN và TA→EN, SAMU-XLSR-LaBSE đạt được WER lần lượt là 9,5%, 10,2%, 13,8%, 15,2%, 26,0%, 44,7% và 57,7% so với 23,4%, 16,8%, 34,3%, 36,0%, 41,3%, 72,9%, 75,0% lần lượt bởi ASR-LaBSE. Trung bình SAMU-XLSR-LaBSE đạt được WER trung bình là 22,6% so với 33,7% với ASR-LaBSE trên các tác vụ truy xuất dịch thuật ngôn ngữ nói phi châu Âu (X)→EN. Trên các tác vụ truy xuất, nơi các truy vấn ngôn ngữ là các ngôn ngữ châu Âu, SAMU-XLSR-LaBSE hoạt động ngang bằng với đường ống truy xuất ASR-LaBSE. Ví dụ, trên các tác vụ truy xuất dịch thuật RU→EN, IT→EN, FR→EN, ES→EN, DE→EN, ET→EN, CY→EN, NL→EN, CA→EN, SV→EN, SL→EN và LV→EN, SAMU-XLSR-LaBSE đạt được WER trung bình là 13,6% so với 10,2% với đường ống truy xuất ASR-LaBSE.

Những kết quả này không đáng ngạc nhiên cho rằng đối với các ngôn ngữ châu Âu (tài nguyên cao và thấp), hệ thống ASR nói chung tốt hơn đối với các ngôn ngữ phi châu Âu. Điều này là do thực tế rằng bộ mã hóa ngôn ngữ XLSR, mà chúng tôi tinh chỉnh trên tác vụ ASR downstream sử dụng dữ liệu có phiên âm cụ thể cho ngôn ngữ, được huấn luyện trước trên dữ liệu ngôn ngữ châu Âu chủ yếu.

Cuối cùng, mô hình topline sử dụng các phiên âm văn bản ground-truth tương ứng với các truy vấn ngôn ngữ (X) để truy xuất các bản dịch văn bản tiếng Anh. Mô hình này chỉ sử dụng LaBSE để thực hiện tác vụ truy xuất text(X)→text(EN). Topline đạt được WER trung bình là 14,5% trên các ngôn ngữ phi châu Âu X và 4,9% trên các ngôn ngữ châu Âu, điều này ngụ ý rằng chúng tôi không thể hoàn toàn đạt đến hiệu suất topline với đường ống truy xuất SAMU-XLSR-LaBSE của chúng tôi và vẫn còn chỗ để cải thiện. Chúng tôi tin rằng việc tăng quy mô dữ liệu huấn luyện và sử dụng hàm mất mát tương phản để huấn luyện SAMU-XLSR có thể dẫn đến hiệu suất cải thiện. Tuy nhiên, một thiết lập huấn luyện với hàm mất mát tương phản sẽ yêu cầu nỗ lực kỹ thuật đáng kể vì độ phức tạp kỹ thuật liên quan đến việc khai thác các mẫu âm qua GPU như đã thực hiện cho việc huấn luyện LaBSE [15]. Việc rút ra các mẫu âm từ cùng một thiết bị GPU sẽ không đủ vì kích thước batch nhỏ trên mỗi GPU do kích thước bộ mã hóa ngôn ngữ lớn và các dạng sóng ngôn ngữ dài. Do đó, chúng tôi để lại việc khám phá học tương phản cho công việc tương lai.

C. Kết quả trên các tác vụ truy xuất dịch thuật văn bản EN→Y
Bảng IV và V hiển thị kết quả trên các tác vụ truy xuất ngôn ngữ→văn bản EN→Y sử dụng các đường ống truy xuất SAMU-XLSR-LaBSE, ASR-LaBSE và Topline LaBSE. Chúng tôi truy xuất bản dịch văn bản trong ngôn ngữ Y cho một truy vấn ngôn ngữ đã cho bằng tiếng Anh cho các tác vụ truy xuất EN→Y. Trong bảng kết quả, đầu tiên, chúng tôi hiển thị số lượng truy vấn ngôn ngữ tiếng Anh và các câu trong cơ sở dữ liệu tìm kiếm cho mỗi ngôn ngữ Y.

Đối với các tác vụ truy xuất CoVoST-2 EN→Y, chúng tôi có 32K truy vấn ngôn ngữ tiếng Anh trong DB truy vấn và 320K câu trong DB tìm kiếm trong ngôn ngữ Y cho mỗi tác vụ truy xuất EN→Y. Xem Phần III-B để biết thêm chi tiết về các tác vụ truy xuất CoVoST-2 EN→Y.

Bảng IV hiển thị kết quả trên các tác vụ truy xuất CoVoST-2 EN→Y. Chúng tôi có 32K truy vấn ngôn ngữ tiếng Anh trong DB truy vấn và 320K câu trong DB tìm kiếm trong ngôn ngữ Y cho mỗi tác vụ truy xuất EN→Y. Xem Phần III để biết thêm chi tiết về các tác vụ truy xuất CoVoST-2 EN→Y. Chúng tôi quan sát rằng các đường ống truy xuất SAMU-XLSR-LaBSE và ASR-LaBSE hoạt động ngang bằng đạt được WER truy xuất lần lượt là 7,6% và 7,3%, trong khi đường ống truy xuất Topline LaBSE text(EN)→text(Y) đạt được WER trung bình là 2,1% qua 15 tác vụ truy xuất. Vẫn còn chỗ để cải thiện. Đặc biệt, đối với việc truy xuất các bản dịch văn bản trong các ngôn ngữ phi châu Âu như ZH, MN, JA, FA, AR, và TA, mà WER trung bình đạt được bởi đường ống truy xuất SAMU-XLSR-LaBSE được đề xuất của chúng tôi là 9,7% so với 2,8% với đường ống truy xuất topline LaBSE text(EN)→text(Y). Đối với các ngôn ngữ châu Âu, mô hình truy xuất của chúng tôi đạt được WER là 6,1% so với 1,7% cho mô hình topline. Mô hình của chúng tôi hoạt động tốt hơn trong các ngôn ngữ châu Âu (6,1% WER) so với các ngôn ngữ phi châu Âu (9,7% WER).

Bảng V hiển thị kết quả truy xuất EN→Y trên corpus đánh giá ngoài miền MUST-C. Chúng tôi có cùng số lượng 4K phát ngôn ngôn ngữ trong DB truy vấn và 200K câu trong DB tìm kiếm cho tất cả các tác vụ truy xuất dịch thuật văn bản. Chúng tôi quan sát rằng SAMU-XLSR-LaBSE hoạt động ngang bằng với đường ống truy xuất ASR-LaBSE, đạt được trung bình 10,3% WER so với 9,6% đạt được bởi đường ống truy xuất ASR-LaBSE trên 14 tác vụ truy xuất EN→Y. Mô hình của chúng tôi đạt được WER dưới 10% cho hầu hết các ngôn ngữ trừ TR, AR, RU, và ZH, mà mô hình đạt được WER lần lượt là 11,1%, 13,2%, 12,3%, và 20,6%. Những WER này gấp khoảng hai lần WER đạt được bởi mô hình truy xuất topline LaBSE text(EN)→text(Y). Tuy nhiên, các WER ở mức dưới 20% đáng kính trọng.

D. Kết quả trên các tác vụ truy xuất dịch thuật văn bản X→Y
Bảng VI hiển thị kết quả trên các tác vụ truy xuất dịch thuật văn bản ngoài miền MTEDx X→Y sử dụng các đường ống truy xuất SAMU-XLSR-LaBSE, ASR-LaBSE và topline LaBSE. Bảng hiển thị sự kết hợp truy vấn ngôn ngữ và cơ sở dữ liệu tìm kiếm văn bản cho mỗi cặp X→Y. Chúng tôi quan sát rằng SAMU-XLSR-LaBSE đạt được WER truy xuất trung bình là 9% so với 6,8% với ASR-LaBSE và 2,5% với topline LaBSE trên 11 tác vụ truy xuất dịch thuật văn bản. Không đáng ngạc nhiên khi đường ống truy xuất ASR-LaBSE hoạt động tốt hơn mô hình SAMU-XLSR-LaBSE. Vì, các truy vấn ngôn ngữ cho các tác vụ truy xuất X→Y là các ngôn ngữ châu Âu và các mô hình ASR ngôn ngữ châu Âu của chúng tôi khá tốt. Các kết quả được báo cáo ở đây xác nhận với quan sát mà chúng tôi đã đưa ra cho các tác vụ truy xuất dịch thuật CoVoST-2 X→EN, nơi SAMU-XLSR-LaBSE hoạt động tốt hơn ASR-LaBSE cho các ngôn ngữ phi châu Âu nhưng không phải cho các ngôn ngữ châu Âu. Lưu ý rằng nếu chúng tôi có một mô hình ASR tạo ra các phiên âm văn bản khớp chính xác với các phiên âm ground-truth, thì hiệu suất của ASR-LaBSE sẽ giống với của mô hình topline.

E. Kết quả trên các tác vụ truy xuất dịch thuật ngôn ngữ X→EN
Chúng tôi quan sát rằng bộ mã hóa ngôn ngữ SAMU-XLSR học được một không gian vector được căn chỉnh theo ngữ nghĩa qua nhiều ngôn ngữ nói. Mô hình có thể truy xuất các bản dịch ngôn ngữ tiếng Anh chính xác tương ứng với các truy vấn ngôn ngữ trong ngôn ngữ X với độ chính xác trên 96% cho X∈{ES, FR, PL, NL, DE}. Đối với X∈{RO, HR, CS}, hiệu suất truy xuất dịch thuật ngôn ngữ của SAMU-XLSR đang tụt hậu so với các ngôn ngữ khác. Kết quả này không đáng ngạc nhiên vì SAMU-XLSR không thấy bất kỳ dữ liệu có phiên âm nào từ ba ngôn ngữ này trong quá trình huấn luyện. SAMU-XLSR đạt được độ chính xác truy xuất R@1 trung bình là 83,6% qua 8 tác vụ truy xuất dịch thuật ngôn ngữ X→EN. Mặt khác, XLS-R thất bại trên tác vụ truy xuất này. Để có được một nhúng ngôn ngữ ở mức phát ngôn từ XLS-R, chúng tôi thực hiện gộp trung bình thời gian của các nhúng ngữ cảnh ở mức khung từ lớp cuối cùng của mô hình. Từ kết quả truy xuất kém, rõ ràng rằng không gian biểu diễn của XLS-R không được căn chỉnh theo ngữ nghĩa qua các ngôn ngữ khác nhau. Chúng tôi đạt được kết quả tương tự kém với các biểu diễn từ các lớp XLS-R khác nhau.

V. CÁC TÁC VỤ DOWNSTREAM: MÔ HÌNH HÓA SEQUENCE-TO-SEQUENCE
A. Nhận dạng Phoneme
Bảng VIII hiển thị tỷ lệ lỗi phoneme (PER) đạt được bởi SAMU-XLSR và XLS-R trên chín ngôn ngữ Commonvoice. Chúng tôi quan sát rằng SAMU-XLSR có thể so sánh được với XLS-R trên tác vụ nhận dạng phoneme đạt được PER trung bình là 6,2% so với 6,4% đạt được bởi XLS-R qua chín ngôn ngữ đích. Xem Phần III-C để biết chi tiết về tác vụ và dữ liệu được sử dụng để tinh chỉnh SAMU-XLSR và XLS-R.

B. Nhận dạng Giọng nói Tự động
Bảng IX hiển thị Tỷ lệ Lỗi Từ (WER) đạt được bởi việc tinh chỉnh SAMU-XLSR và XLS-R trên chín ngôn ngữ. Chúng tôi quan sát rằng SAMU-XLSR hoạt động ngang bằng với XLS-R đạt được WER trung bình là 24,3% so với 25,8% đạt được bởi XLS-R. Thú vị thay, trên ngôn ngữ Ả Rập (AR) ngoài miền, được rút ra từ corpus tin tức phát sóng MGB2 [50] (khác với corpus ngôn ngữ đọc CoVo được sử dụng để huấn luyện trước SAMU-XLSR), SAMU-XLSR hoạt động tốt hơn XLS-R.

Thực tế rằng các kết quả mô hình hóa sequence-to-sequence (ASR & Nhận dạng Phoneme) ngang bằng với XLS-R ngụ ý rằng SAMU-XLSR ngoài việc hữu ích cho truy xuất dịch thuật văn bản và ngôn ngữ đa ngôn ngữ zero-shot (Phần IV) cũng có thể được sử dụng cho các tác vụ tạo chuỗi như ASR.

VI. PHÂN TÍCH THỰC NGHIỆM CỦA CÁC LỰA CHỌN THIẾT KẾ KHÁC NHAU
Trong phần này, chúng tôi nghiên cứu các quyết định thiết kế khác nhau đã tạo ra bộ mã hóa ngôn ngữ SAMU-XLSR.

A. Hàm mất mát và gộp
Khi chi tiết SAMU-XLSR trong Phần II-B, chúng tôi đã đề cập rằng chúng tôi sử dụng phương pháp gộp Self-Attention để xây dựng một nhúng ngôn ngữ ở mức phát ngôn từ các vector nhúng ngữ cảnh ở mức khung âm thanh. Ngoài ra, chúng tôi sử dụng hàm mất mát khoảng cách cosine để huấn luyện SAMU-XLSR. Bảng X hiển thị rằng việc kết hợp hàm mất mát khoảng cách cosine và phương pháp gộp Self-Attention tốt hơn so với việc kết hợp các hàm mất mát và phương pháp gộp khác. Chúng tôi huấn luyện SAMU-XLSR với các hàm mất mát L1, L2, và khoảng cách cosine và so sánh hiệu suất truy xuất dịch thuật văn bản trung bình của nó qua 21 tác vụ truy xuất CoVoST-2 X→EN. Ngoài ra, chúng tôi so sánh hiệu suất truy xuất với các chiến lược gộp Mean, Max, và Self-Attention. Ba hàm mất mát với ba chiến lược gộp dẫn đến chín cấu hình huấn luyện có thể. Để phân tích nhanh, chúng tôi huấn luyện SAMU-XLSR trên 8 GPU V100-32GB trong 100K vòng lặp trên một tập con DS của dữ liệu huấn luyện đa ngôn ngữ có phiên âm hoàn chỉnh D. DS được xây dựng bằng cách lấy mẫu ngẫu nhiên 400K ví dụ huấn luyện từ D. SAMU-XLSR với phương pháp gộp Self-Attention và được huấn luyện với hàm mất mát khoảng cách cosine đạt độ chính xác truy xuất R@1 trung bình là 48,8%, tốt hơn so với 8 cấu hình huấn luyện khác.

B. Tham số làm mượt cân bằng dữ liệu α
Phần này nghiên cứu tác động lên hiệu suất truy xuất trung bình của mô hình qua 21 tác vụ truy xuất X→EN khi chúng tôi huấn luyện mô hình với dữ liệu huấn luyện được cân bằng lại theo Phương trình 3. Tham số làm mượt α là siêu tham số duy nhất trong phương trình cân bằng dữ liệu. Đầu tiên, chúng tôi xây dựng nhiều bộ dữ liệu ngôn ngữ có phiên âm đa ngôn ngữ được cân bằng lại tương ứng với các giá trị α khác nhau. Sau đó, chúng tôi lấy mẫu ngẫu nhiên 400K phát ngôn từ các bộ dữ liệu được cân bằng lại để huấn luyện mô hình SAMU-XLSR. Chúng tôi huấn luyện SAMU-XLSR sử dụng hàm mất mát khoảng cách cosine trong 100K vòng lặp trên 8 GPU V100-32GB.

Chúng tôi quan sát trong Bảng XI rằng các mô hình được huấn luyện với dữ liệu được cân bằng lại (α < 1.0) đạt được độ chính xác truy xuất trung bình tốt hơn đáng kể qua 21 tác vụ truy xuất dịch thuật văn bản X→EN so với mô hình được huấn luyện mà không có cân bằng lại (α = 1.0). Chúng tôi đạt được hiệu suất tốt nhất với α = 0.05, nơi độ chính xác truy xuất trung bình R@1 của mô hình là 72,4% so với 48,8% đạt được bởi SAMU-XLSR được huấn luyện trên bộ dữ liệu gốc mà không có bất kỳ cân bằng lại nào. Sự cải thiện lớn trong hiệu suất truy xuất là do mô hình làm tốt hơn nhiều trên các tác vụ truy xuất X→EN nơi các truy vấn ngôn ngữ là các ngôn ngữ ít tài nguyên, điều này ngụ ý rằng mô hình thực sự bị underfitting trên các ngôn ngữ ít tài nguyên do sự mất cân bằng dữ liệu trong tập huấn luyện của SAMU-XLSR. Bảng XII hiển thị rằng SAMU-XLSR được huấn luyện với cân bằng dữ liệu (α = 0.05) đạt được độ chính xác truy xuất R@1 trung bình là 61,4% so với 23,8% đạt được bởi SAMU-XLSR được huấn luyện trên tập huấn luyện mất cân bằng (α = 1.0). Ngoài ra, Bảng XIII hiển thị rằng có sự khác biệt hiệu suất không đáng kể cho các α khác nhau trên các tác vụ X→EN khi các truy vấn ngôn ngữ là các ngôn ngữ có nhiều tài nguyên.

C. Dữ liệu Huấn luyện
Trong Phần II-D1, chúng tôi đề cập rằng chúng tôi huấn luyện SAMU-XLSR với dữ liệu ngôn ngữ có phiên âm đa ngôn ngữ được thu thập từ bộ dữ liệu CoVo. Trong phần này, chúng tôi nghiên cứu tác động của việc huấn luyện SAMU-XLSR với dữ liệu ngôn ngữ-dịch thuật được ghép đôi. Chúng tôi huấn luyện SAMU-XLSR sử dụng ba bộ dữ liệu huấn luyện khác nhau: 1) Ngôn ngữ có phiên âm đa ngôn ngữ trong 25 ngôn ngữ từ bộ dữ liệu CoVo, mà chúng tôi gọi là thiết lập huấn luyện T1, và mô hình được huấn luyện với thiết lập này là SAMU-XLSR T1, 2) 22 tập huấn luyện dịch thuật ngôn ngữ CoVoST-2 X→EN, nơi các phát ngôn ngôn ngữ được ghép đôi với các bản dịch văn bản tiếng Anh tương ứng của chúng. Chúng tôi gọi đó là thiết lập huấn luyện T2, và mô hình được huấn luyện với thiết lập này là SAMU-XLSR T2. 3) Sự kết hợp của cả T1 và T2. Chúng tôi gọi mô hình được huấn luyện với thiết lập này là SAMU-XLSR T3. Ngoài ra, chúng tôi cân bằng lại các bộ dữ liệu huấn luyện khác nhau sử dụng α = 0.05 và sau đó chọn ngẫu nhiên 400K ví dụ để huấn luyện. Cuối cùng, chúng tôi huấn luyện mô hình trong 100K vòng lặp trên 8 GPU V100-32GB.

Bảng XIV hiển thị hiệu suất truy xuất trung bình trên 21 tác vụ truy xuất X→EN đạt được bởi SAMU-XLSR được huấn luyện với ba thiết lập huấn luyện khác nhau được đề cập ở trên. Chúng tôi quan sát rằng SAMU-XLSR T1 đạt được hiệu suất truy xuất tốt nhất trong số ba mô hình, điều này ngụ ý rằng chúng tôi có thể huấn luyện SAMU-XLSR chỉ với ngôn ngữ có phiên âm đa ngôn ngữ. Hơn nữa, bảng XV hiển thị rằng SAMU-XLSR T1 đặc biệt tốt hơn cho các tác vụ X→EN khi các truy vấn ngôn ngữ là các ngôn ngữ ít tài nguyên. Đối với các truy vấn ngôn ngữ trong các ngôn ngữ có nhiều tài nguyên, sự khác biệt hiệu suất giữa ba mô hình là không đáng kể. Xem Bảng XVI cho các tác vụ truy xuất X→EN, khi các truy vấn ngôn ngữ là các ngôn ngữ có nhiều tài nguyên.

VII. KẾT LUẬN
Chúng tôi đã đề xuất một khung học biểu diễn ngôn ngữ đa ngôn ngữ đa phương thức (ngôn ngữ-văn bản chung) ở mức phát ngôn được căn chỉnh theo ngữ nghĩa (SAMU-XLSR) trong công trình này. Chúng tôi cho thấy rằng chỉ bằng cách sử dụng ngôn ngữ có phiên âm đa ngôn ngữ để huấn luyện mô hình học biểu diễn được đề xuất, các căn chỉnh đa ngôn ngữ giữa các phát ngôn ngôn ngữ và các bản dịch văn bản và ngôn ngữ của chúng xuất hiện trong không gian vector nhúng đã học của mô hình.

Chúng tôi cho thấy rằng không giống như XLS-R (một bộ mã hóa ngôn ngữ đa ngôn ngữ chỉ dành cho ngôn ngữ), SAMU-XLSR kết hợp với bộ mã hóa câu BERT bất khả tri ngôn ngữ LaBSE có thể thực hiện truy xuất dịch thuật zero-shot từ ngôn ngữ sang văn bản và từ ngôn ngữ sang ngôn ngữ qua nhiều ngôn ngữ nói và viết. Hơn nữa, chúng tôi cho thấy rằng SAMU-XLSR hoạt động ngang bằng với XLS-R trên các tác vụ mô hình hóa sequence-to-sequence như ASR và Nhận dạng Phoneme. Trong tương lai, chúng tôi sẽ mở rộng khung học đa phương thức của chúng tôi cho tác vụ dịch thuật ngôn ngữ zero-shot và khai thác dữ liệu ngôn ngữ sang văn bản quy mô lớn để tạo ra các bộ dữ liệu dịch thuật song song ngôn ngữ-văn bản để huấn luyện các mô hình dịch thuật ngôn ngữ.

LỜI CẢM TẠ
Công trình này sử dụng tài nguyên HPC của IDRIS dưới sự phân bổ AD011012527 được thực hiện bởi GENCI. Chúng tôi cảm ơn Nauman Dawalatabad và Yuan Gong từ phòng thí nghiệm hệ thống ngôn ngữ nói MIT CSAIL đã xem xét bài báo và cung cấp những nhận xét hữu ích.

TÀI LIỆU THAM KHẢO
[Các tài liệu tham khảo được giữ nguyên như trong bản gốc...]

--- CÁC TRANG TIẾP THEO ---
[Tiếp tục dịch các bảng, hình và nội dung còn lại của tài liệu theo cùng định dạng...]

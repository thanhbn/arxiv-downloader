# 2309.04646.pdf
# Converted from PDF to TXT
# Source path: /home/admin88/arxiv-downloader/multilingual/2309.04646.pdf
# File size: 210850 bytes

===============================================
PDF FILE CONTENT
===============================================


--- PAGE 1 ---
arXiv:2309.04646v1  [cs.CL]  9 Sep 2023Efficient Finetuning Large Language Models For
Vietnamese Chatbot
Vu-Thuan Doan1,2, Quoc-Truong Truong1,2, Duc-Vu Nguyen1,2, Vinh-Tiep Nguyen1,2,*, and Thuy-Ngan Nguyen Luu1,2
1University of Information Technology, Ho Chi Minh City, Vie tnam
2Vietnam National University, Ho Chi Minh City, Vietnam
thuandv.14@grad.uit.edu.vn, { truongtq, vund, tiepnv,ng annlt}@uit.edu.vn
*Corresponding author
Abstract —Large language models (LLMs), such as GPT-4,
PaLM, and LLaMa, have been shown to achieve remarkable
performance across a variety of natural language tasks. Rec ent
advancements in instruction tuning bring LLMs with ability
in following user’s instructions and producing human-like re-
sponses. However, the high costs associated with training a nd
implementing LLMs pose challenges to academic research. Fu r-
thermore, the availability of pretrained LLMs and instruct ion-
tune datasets for Vietnamese language is limited. To tackle these
concerns, we leverage large-scale instruction-following datasets
from open-source projects, namely Alpaca, GPT4All, and Cha t-
Doctor, which cover general domain and specific medical dom ain.
To the best of our knowledge, these are the first instruction al
dataset for Vietnamese. Subsequently, we utilize paramete r-
efficient tuning through Low-Rank Adaptation (LoRA) on two
open LLMs: Bloomz (Multilingual) and GPTJ-6B (Vietnamese) ,
resulting four models: Bloomz-Chat, Bloomz-Doctor, GPTJ-
Chat, GPTJ-Doctor. Finally, we assess the effectiveness of our
methodology on a per-sample basis, taking into considerati on the
helpfulness, relevance, accuracy, level of detail in their responses.
This evaluation process entails the utilization of GPT-4 as an
automated scoring mechanism. Despite utilizing a low-cost setup,
our method demonstrates about 20-30% improvement over the
original models in our evaluation tasks.
Index Terms —Large Language Model, Instruction Fine-tuning,
LoRA, Vietnamese, Chatbot, Medical
I. INTRODUCTION
In recent years, large language models (LLMs) have gar-
nered significant attention thanks to their remarkable suc cess
in numerous natural language processing (NLP) tasks. Large
language models are based on a deep learning architecture
known as a Transformer. The Transformer model revolution-
ized natural language processing tasks by effectively capt uring
long-range dependencies and relationships within text. LL Ms
are trained on large volumes of text data to predict the
subsequent tokens, enabling them to generate coherent and
fluent text in response to various inputs. However, without
few-shot exemplars, it is harder for models to perform well o n
prompts that are not similar to the format of the pretraining
data. These models also struggle to follow instructions or
goals specified by users, which limits their usefulness and
applicability in real-world scenarios.
The NLP community has recently witnessed many endeav-
ors to train large language models to follow instructions be tterand be more helpful. Large “instruction-tuned” language mo d-
els (finetuned to respond to instructions) have demonstrat ed
a remarkable ability to generalize zero-shot to new tasks.
Initial attempts [ 11] [15] [16] [4] to train instruction-following
language models are based on a collection of various NLP
tasks, with a set of human-annotated instructions accompan y-
ing each task. These developments are powered by two key
components: large pre-trained language models and human-
written instruction data. However, this process is costly a nd
often suffers limited diversity in NLP tasks. Then, Self-In struct
[14], a framework for improving the instruction-following
capabilities of pre-trained language models by bootstrapp ing
off its own generations. This method has addressed such
challenges necessitates the creation of a large-scale, pub lic
dataset covering a broad range of tasks.
Despite the great success of LLMs, SOTA models like GPT-
4, and PaLM [ 3], are often only accessible through restricted
APIs, creating barriers for new research endeavors. In the
recent literature, there has been a growing interest in leve r-
aging open-source LLMs and adapting them towards specific
applications or domains. Popular models are Bloom [ 8] from
Bigscience, GPT-J from EleutherAI, and LLaMa [ 13] from
Meta. Nonetheless, within the Vietnamese context, there is a
lack of language models that have undergone extensive train ing
on vast corpora, resulting in the absence of the distinctive
features possessed by LLMs: a few short generations with in-
context learning.
Another challenge when working with LLMs is the cost
of fine-tuning and deployment. To fine-tune large language
models in a low-resource setting, we utilize a parameter-
efficient tuning approach that effectively leverages the l imited
computational resources available. By applying LoRA(Low-
Rank Adaptation) technique, this enables the adaptation of
state-of-the-art language models to resource-constraine d sce-
narios while maintaining high performance and adaptabilit y.
In this paper, we propose a simple method based on efficient
instruct-tuning with our Vietnamese instruction dataset t o
build two chatbot models for generic and specific domains,
e.g. medical. The overview of our approach is shown in Figure
1. Our main contributions in this paper are as follows:
•We propose new instruction-following datasets for generic

--- PAGE 2 ---
Fig. 1. The overview of our approach using Instruction Tunin g with LoRA.
and medical domains by collecting and translating from
other public sources.
•We adopt the Low-Rank Adaptation (LoRA) approach
for the efficient training and deployment of LLMs. This
makes the training and deployment cost affordable for
academic research.
•We evaluate the performance of those approaches on a
collection of natural language tasks, demonstrating the
ability in the context of Vietnamese for general and
medical domains.
II. R ELATED WORK
Large Language Models: have demonstrated impressive
capabilities across various domains, including natural la nguage
understanding, text generation, dialogue systems, conten t sum-
marization, and more. Recent advancements in large lan-
guage models (LLMs) have demonstrated their superiority ov er
previous-generation paradigms, such as pretraining and fi ne-
tuning. The significant increase in model scale has led to qu al-
itative changes in LLMs, commonly referred to as emergent
abilities. These include in-context learning for zero-sho t tasks
and chains of thought that enhance the model’s performance o n
complex tasks. OpenAI’s development of ChatGPT and GPT-
4 [9] has revolutionized the perception of LLMs. Although
these models exhibit remarkable performance, OpenAI has
not disclosed details regarding their training strategies or
weight parameters. However, there are several open-source
LLMs alternatives for GPT-4: Bloom [ 12], Bloomz [ 8], GPT-
J, and LLaMa [ 13] with sizes ranging from 7B to 65 billion
parameters.Instruction Tuning: The subfield of language models con-
centrates on the instruction-following capabilities is cr ucial for
generating responses based on natural language commands.
Instruction-following methods enhance pre-trained model s by
fine-tuning them using high-quality input-output tuples o f
task instructions and ground truth outputs. This finetunin g
helps the model better understand user intentions and follo w
instructions more accurately. Instruction-following met hods
have been extensively researched in language models [ 11] [15]
[16] [4] and multi-modality domains [ 8]. Among those meth-
ods, FLAN [ 16] introduces an instruction-tuning method that
outperforms non-tuned LLMs in unseen tasks. PromptSource
[1] provides a development environment and repository that
offers a web-based GUI for creating and managing natural
language prompts for zero-shot or gradient-based few-shot
learning. SUP-NATINST [ 15] establishes a large benchmark
of 1,616 diverse NLP tasks and uses multi-task training on th e
T5 model and demonstrates strong generalization capabilit ies
on unseen tasks. InstructGPT [ 10] demonstrates significant
performance improvements and may be integrated into closed -
source models like GPT-3.5 and GPT-4 [ 9]. The open-source
Stanford Alpaca approach fine-tunes all parameters of LLMs
in an end-to-end manner.
Parameter-Efficient Fine-Tuning: Parameter-Efficient
Fine-Tuning (PEFT) [ 2] aims to optimize the fine-tuning
process by efficiently utilizing the available computing
resources and reducing the number of parameters that need
to be updated. This approach becomes particularly relevant
when working with limited labeled data for a specific
task. This approach not only saves computational time
and resources but also enables the deployment of large

--- PAGE 3 ---
language models more accessible and practical for a wide
range of applications. Various PEFT techniques include
Prefix Tuning [ 7], Low-Rank adaptation (LoRA) [ 5], and
the insertion of adapter layers in pre-trained large langua ge
models. Prefix Tuning [ 7] appends a collection of prefixes to
autoregressive language models, or alternatively, incorp orates
prefixes for both encoder and decoder components, similar
methods proposed in [ 6]. LoRA [ 5] introduces trainable rank
decomposition matrices into each layer. Adapters involve
inserting lightweight modules into each layer of pre-train ed
models, which only updates the adapters and has been
extended across numerous domains.
III. M ETHOD
In this section, we will describe our method to collect
datasets, choose pretrained language model and how we apply
parameter-efficient fine-tuning.
A. Data Collection
As creating an instruction tuning dataset with many tasks
from scratch would be resource-intensive, we transform
existing datasets from the research community into an
instructional format and translate them into Vietnamese
Instruction dataset example:
{"prompt": "đưa ra 3 mẹo giữ sức khỏe", "response": "1. Ăn
một chế độ ăn cân bằng và đảm bảo bao gồm nhiều trái ..."}
{"prompt": "Ba màu chính là gì?", "response": "Ba màu chính
là màu đỏ, xanh và vàng."}
{"prompt": "Mô tả cấu trúc của một nguyên tử.", "response":
"Một nguyên tử được tạo thành từ một hạt nhân, chứa..."}
1) Instruction-Following Dataset: First, we collected
instruction-following examples from the Standford Alpaca
project. This project adopt the Self-Instruct [ 14] technique and
generated 52k demonstrations from the open-source LLaMa-
7B model instead of GPT3.5 in the original Self-Instruct [ 14]
paper.
Fig. 2. Apaca Task Distribution [ 14]To increase more instruction data, we also collect data from
the GPT4All project.
2) Medical Dataset: For medical instruction dataset, we
collect from ChatDoctor [ 17]. Their method starts with a
database containing about 700 diseases with their relative
symptoms, medical tests, and recommended medications.
Then it uses ChatGPT to generate 5k conversations between
patients and physicians from that seed database. We also
collect 195k real conversations between patients and docto rs
from Health Care Magic and combine them into instructional
dataset for medical domain. Finally, we translate all data t o
Vietnamese using Google Translate API.
Medical dataset example:
{"prompt": "Thưa bác sĩ, tôi bị nôn, buồn nôn và đau bụng.
Gần đây tôi phát hiện ra rằng tôi có môn vị hẹp. Tôi nên dùng
thuốc gì cho nó?",
"response": "Phương pháp điều trị hẹp môn vị phổ biến nhất
là một thủ thuật phẫu thuật được gọi là phẫu thuật cắt bỏ môn
vị. Điều này liên quan đến cắt và niêm phong cơ xung quanh
lỗ mở của môn vị, mở rộng nó và cho phép thức ăn đi qua dễ
dàng hơn. Tuy nhiên cũng có một số thuốc có thể giúp giảm
các triệu chứng như metoclopramide hoặc cisapride. Bạn thíc h
cái nào hơn?"}
TABLE I
DATASET STATISTIC
Dataset Samples Avg. tokens/sample Translated Tokens
Alpaca 52k 350 18M
GPT4All 150k 365 61M
ChatDoctor 200k 405 87M
B. Baseline Models
We use publicly available pretrained Bloomz-mt-7B [ 8] and
GPTJ-6B from VietAI as our baseline models. Bloomz is
a small variant of original BLOOM model, a collaborative
project of more than 1,000 scientists and the amazing Huggin g
Face team. The BLOOM model is an open-access multilingual
language model that contains 176B parameters and was traine d
for 3.5 months on 384 A100–80GB GPUs.It’s small variant
Bloomz is a multi-language model which has trained on the
ROOTS corpus and finetuned with the xP3 dataset. This
dataset has 59 Languages (46 natural and 13 programming
languages including 3% Vietnamese). GPTJ-6B from VietAI
is the one of biggest GPT models trained only on Vietnamese
dataset.
C. Parameter-Efficient Tuning
Standard fine-tuning often requires vast amounts of com-
putational resources, as well as high-quality and extensiv e
datasets. However, given the limited availability of high-
quality multi-turn chat corpora, it is crucial to adopt meth ods
that are more efficient in terms of computational cost and
data requirements. Parameter-efficient tuning methods [ 2] help

--- PAGE 4 ---
achieve this goal by making better use of the available data a nd
minimizing the need for extensive resource allocation. Mor e
details in Figure 3.
Fig. 3. The overview of our approach using Instruction Tunin g with LoRA.
Specifically, we use Low-Rank Adaption (LoRA, Hu et al.)
to fine-tune the base LLMs. For a linear layer h=W0x, the
forward pass is modified to be:
h=W0x+BAx (1)
whereW0∈Rd×k,B∈Rd×r,A∈Rr×kwith the rank
r≪min(d;k)
IV. E XPERIMENTS
A. Training Dataset
We construct three separate datasets for our models. For
generic chatbot, we combine data from Alpaca and GPT4All
into one dataset. For medical chatbot, we combine 52k data
samples from Alpaca with 200k conversations from ChatDoc-
tor as training dataset. We format the dataset as json file as
GPT-3 style that includes two fields of instruction and resp onse
for each sample. The prompt template is as simple as follows.
Prompt template for Bloomz-Chat and GPTJ-Chat:
Hãy viết một phản hồi thích hợp cho chỉ dẫn dưới đây.
### Instruction:
{instruction}
### Response:
Prompt template for Bloomz-Doctor and GPTJ-Doctor:
Nếu bạn là bác sĩ, vui lòng trả lời các câu hỏi y tế dựa trên
mô tả của bệnh nhân.
### Instruction:
{instruction}
### Response:B. Training Details
We set up the environment with PyTorch and Huggingface
Transformers package. Parameter-efficient fine-tuning w as ap-
plied on our models based on the codebase of Alpaca-Lora .
The maximum length of the input sequence to 512 and the rank
k in LoRA to 8. The base model checkpoints were initialized
with the 8-bit integer format (int8) parameters released by
Touvron et al., which remain fixed during training, thus
reducing GPU memory consumption and improving training
speed. We use the Adam optimizer to update LoRA parameters
with a total batch size of 128 and learning rates of 3e-4.
The trainable LoRA parameters are about 4.2M parameters
and fine-tuned for 2 epochs on 4 RTX-4090-24GB GPU. The
training time is listed in Table II.
C. Inference Details
During the inference phase, we also use an inference prompt
as we did for the training stage to improve conversational
capabilities. For the decoding strategy, we use these setti ngs
with the details are as follows.
•Max new tokens: We limit max new tokens to 256 tokens
to ensure that the outputs remain focused and relevant to
the input prompt.
•Temperature: We set the temperature to 0.5, which con-
trols the randomness of the sampling process. Lower
values make the model generate more focused and deter-
ministic outputs, while higher values increase diversity a t
the cost of coherence.
•Top-k sampling: We use Top-k sampling with k = 20,
meaning that the model selects its next token from the top
20 most probable tokens at each step, adding an element
of randomness and diversity to the generated text.
•Repetition penalty: To discourage the model from gener-
ating repetitive text, we apply a repetition penalty with
a factor of 1.2, penalizing tokens that have already been
selected.
V. E VALUATION
Evaluating the performance of text generation tasks can
be challenging due to the significant variety in their form,
unlike natural language understanding tasks (such as text
classification and extractive machine reading comprehens ion).
Following previous works ( [ 17],Vicuna ) that utilizes GPT-
4 as a scoring method, we also adopt GPT-4 to provide an
overall score (on a 100-point scale) for each sample, which i s
more efficient than human evaluation.
The evaluation system judge each response from our models
by four aspects:
•Relevance: Assessing the model’s ability to correctly in-
terpret the semantic meaning of the context and questions.
•Helpfulness: Assessing the model’s ability to provide
useful information.
•Accuracy: Evaluating whether the model can perform
correctly in the corresponding for a given instruction.
•Level of details: Whether the model can accurately use
various and detailed knowledge for problem.

--- PAGE 5 ---
TABLE II
TRAINING DETAILS
Model Original Param. Trainable Param. Training Time Datas et
Bloomz-Chat 7.1B 4.2M 6h Alpaca + GPT4All
Bloomz-Doctor 7.1B 4.2M 6h30m Alpaca + ChatDoctor
GPTJ-Chat 6B 3.6M 5h Alpaca + GPT4All
GPTJ-Doctor 6B 3.6M 5h30m Alpaca + ChatDoctor
We use the following prompt template for scoring the outputs
of the systems:
System Prompt: You are a helpful and precise assistant for
checking the quality of the answer
Prompt:
###Question
{question}
###The Start of Assistant 1’s Answer
{answer_1}
###The End of Assistant 1’s Answer
###The Start of Assistant 2’s Answer
{answer_2}
###The End of Assistant 2’s Answer
We would like to request your feedback on the performance of
two AI assistants in response to the user question displayed
above.
Please rate the helpfulness, relevance, accuracy, level of
details of their responses. Each assistant receives an over all
score on a scale of 1 to 10, where a higher score indicates
better overall performance...
Our evaluation set is designed to provide a comprehensive
assessment of our models across a wide range of natural
language understanding and generation tasks. The set
comprises 80 samples, covering 9 distinct categories,
including Question Answering, Reasoning, Literature,
Entertainment, Math, and Coding. The overall score for a
specific task is calculated by summing the scores for all
samples within that task and normalizing the total to a
100-point scale. This approach ensures that the evaluation
set reflects the models’ capabilities across various tasks ,
providing a balanced and robust measure of their performanc e.
The performance of Bloomz-Chat model is better than
GPTJ-Chat and demonstrates acceptable performance com-
pared to ChatGPT. For Generic, Knowledge, Common Sense
tasks, the Bloomz-Chat do a good job and has a similar
performance of ChatGPT. In the domains of Roleplay, Fermi,
Writing, the performance is still acceptable with the score
range from 65 to 76. However, in some complex tasks like
Coding and Math, the performance is very poor with the score
of Coding is 31.5 and Math is 8.5. The performance of GPTJ-
Chat and original GPTJ are quite poor for all tasks.
For medical domain, we randomly pick 100 examples from
iCliniq dataset and use the same evaluation approach. TheTABLE III
EVALUATION OF BLOOMZ -CHAT
Tasks Samples Bloomz Bloomz-Chat
Generic 10 49.82 91.25
Knowledge 10 44.11 87.5
Roleplay 10 44.29 65.54
Common-Sense 10 50 85.07
Fermi 10 38.75 75.71
Counterfactual 10 47.14 82.5
Coding 7 5 31.5
Math 3 5 8.5
Writing 10 70 76.25
Total 80 44.26 73.55
TABLE IV
EVALUATION OF GPTJ-C HAT
Tasks Samples GPTJ GPTJ-Chat
Generic 10 31.89 61.11
Knowledge 10 33.22 62.22
Roleplay 10 23 33.11
Common-Sense 10 25.11 54.22
Fermi 10 15.22 24.11
Counterfactual 10 15.72 41.11
Coding 7 5 5
Math 3 5 5
Writing 10 17.33 38
Total 80 20.8 39.9
Bloomz-Doctor exhibits a noticeable performance with a sco re
of 73.92. GPTJ-Doctor is acceptable with the score of 59.85.
In summary, the experimental results demonstrate that both
Bloomz-Chat and Bloomz-Doctor models exhibit potential
abilities across all tasks. This underscores the effective ness of
our approach in enhancing the Vietnamese understanding and
generation capabilities of the Bloomz model. Some examples
of our models display in Table V
VI. C ONCLUSION
In this paper, we propose an efficient adaption method
for training instruction-following language models. We al so
provided instruction datasets for the general and medical
domains. With only 4.2M parameters and six hours of train-
ing, our approach effectively fine-tunes Bloomz and exhibi ts

--- PAGE 6 ---
TABLE V
SOME EXAMPLES OF BLOOMZ -CHAT AND BLOOMZ -DOCTOR
Prompt Response
Dịch sang tiếng Việt: J’aime la recherche sci-
entifique.Tôi yêu nghiên cứu khoa học
Ăn gì cho đẹp da Một chế độ ăn uống lành mạnh có thể giúp bạn trông và cảm thấy tốt hơn. Nó bao gồm trái cây, rau
quả, protein nạc (như gà hoặc cá), ngũ cốc nguyên hạt và các loạ i thực phẩm chứa chất chống oxy hóa
khác nhau như cà rốt và việt quất. Điều quan trọng là phải tránh đồ ngọt và quá nhiều chất béo bão
hòa cũng được tìm thấy trong thịt đỏ và chiên
Ý nghĩa của cuộc sống là gì? Là một mô hình ngôn ngữ AI, tôi không có ý kiến cá nhân hoặc niềm t in cá nhân. Tuy nhiên, theo
các học thuyết tâm lý và thần kinh khoa học hiện đại, mục đích cơ bản của sự tồn tại được liên kết
với việc tìm kiếm hạnh phúc và thỏa mãn trong những trải nghiệm này
Thưa bác sĩ, tôi bị sưng môi và hàm, đau nướu,
sốt và loét miệng. Bạn có biết điều gì có thể
gây ra tất cả các triệu chứng này không?Xin chào! Các nguyên nhân phổ biến nhất cho các khiếu nại mà bạn đề cập ở đây bao gồm nhiễm
trùng răng hoặc nha chu (viêm nướu), viêm xoang mũi do virus ho ặc vi khuẩn. Nguyên nhân khác như
dị ứng với thực phẩm, thuốc lá cũng nên được loại trừ trước khi c hẩn đoán chắc chắn về tình trạng
hiện tại. Nếu đó là một cơn sốt virus thì sẽ mất khoảng 2 tuần để n ó giảm dần hoàn toàn....
Thưa bác sĩ, tôi thấy mệt mỏi, khó thở, đau ngực
và nhịp tim không đều. Tôi đã thực hiện một số
nghiên cứu và có vẻ như tôi có thể bị viêm cơ
tim. Tôi nên làm những xét nghiệm nào để xác
nhận nó?Xin chào! Tôi muốn biết lịch sử lâm sàng chi tiết hơn về tình trạ ng này (bao gồm cả việc điều trị trước
đó).Tôi nghĩ rằng bạn đang nói về sự lo lắng hoặc căng thẳng tro ng quá trình tập luyện.Bạn cần phải
kiểm tra mức độ cholesterol cao và huyết áp cũng như ECG.Điều q uan trọng nhất là loại bỏ nguyên
nhân gây ra vấn đề của bạn - do thiếu máu cục bộ hay tăng huyết áp? Hy vọng thông tin này hữu ích
cho bạn.Cảm ơn vì đã liên hệ với chúng tôi.Chúc mọi sức khỏe tốt đẹp!Trân trọng,
potential abilities in chatbots and medical applications. Our
approach can easily be applied to other tasks and domains.
However, our models still have their limits. The response
from the models is sometimes not relevant to the instruction .
Sometimes it responds with the wrong answer. This can be
the limit of training text corpus in our base model - Bloomz -
which has only 3% Vietnamese. We believe if we can expand
the pre-trained LLM with more Vietnamese data, the model
performance will increase. And that will be our next work in
the near future.
ACKNOWLEDGMENT
This research is funded by University of Information
Technology-Vietnam National University HoChiMinh City un -
der grant number D1-2023-38.
REFERENCES
[1] Stephen H Bach, Victor Sanh, Zheng-Xin Yong, Albert Webs on, Colin
Raffel, Nihal V Nayak, Abheesht Sharma, Taewoon Kim, M Saifu l
Bari, Thibault Fevry, et al. Promptsource: An integrated de velopment
environment and repository for natural language prompts. arXiv preprint
arXiv:2202.01279 , 2022. 2
[2] Jiaao Chen, Aston Zhang, Xingjian Shi, Mu Li, Alex Smola, and Diyi
Yang. Parameter-efficient fine-tuning design spaces. arXiv preprint
arXiv:2301.01821 , 2023. 2,3
[3] Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maar ten Bosma,
Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung,
Charles Sutton, Sebastian Gehrmann, et al. Palm: Scaling la nguage
modeling with pathways. arXiv preprint arXiv:2204.02311 , 2022. 1
[4] Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi T ay,
William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Sidd hartha
Brahma, et al. Scaling instruction-finetuned language mod els. arXiv
preprint arXiv:2210.11416 , 2022. 1,2
[5] Edward J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Z hu, Yuanzhi
Li, Shean Wang, Lu Wang, and Weizhu Chen. Lora: Low-rank adap tation
of large language models. arXiv preprint arXiv:2106.09685 , 2021. 3
[6] Brian Lester, Rami Al-Rfou, and Noah Constant. The power of scale
for parameter-efficient prompt tuning. arXiv preprint arXiv:2104.08691 ,
2021. 3[7] Xiang Lisa Li and Percy Liang. Prefix-tuning: Optimizin g continuous
prompts for generation. arXiv preprint arXiv:2101.00190 , 2021. 3
[8] Niklas Muennighoff, Thomas Wang, Lintang Sutawika, Ada m Roberts,
Stella Biderman, Teven Le Scao, M Saiful Bari, Sheng Shen, Zh eng-
Xin Yong, Hailey Schoelkopf, et al. Crosslingual generaliz ation through
multitask finetuning. arXiv preprint arXiv:2211.01786 , 2022. 1,2,3
[9] OpenAI. Gpt-4 technical report, 2023. 2
[10] Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carro ll Wain-
wright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Kat arina
Slama, Alex Ray, et al. Training language models to follow in structions
with human feedback. Advances in Neural Information Processing
Systems , 35:27730–27744, 2022. 2
[11] Victor Sanh, Albert Webson, Colin Raffel, Stephen H Bac h, Lintang
Sutawika, Zaid Alyafeai, Antoine Chaffin, Arnaud Stiegler , Teven Le
Scao, Arun Raja, et al. Multitask prompted training enables zero-shot
task generalization. arXiv preprint arXiv:2110.08207 , 2021. 1,2
[12] Teven Le Scao, Angela Fan, Christopher Akiki, Ellie Pav lick, Suzana
Ili´ c, Daniel Hesslow, Roman Castagné, Alexandra Sasha Luc cioni,
Franc ¸ois Yvon, Matthias Gallé, et al. Bloom: A 176b-parame ter open-
access multilingual language model. arXiv preprint arXiv:2211.05100 ,
2022. 2
[13] Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-
Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Go yal, Eric
Hambro, Faisal Azhar, et al. Llama: Open and efficient found ation
language models. arXiv preprint arXiv:2302.13971 , 2023. 1,2
[14] Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu , Noah A
Smith, Daniel Khashabi, and Hannaneh Hajishirzi. Self-ins truct: Align-
ing language model with self generated instructions. arXiv preprint
arXiv:2212.10560 , 2022. 1,3
[15] Yizhong Wang, Swaroop Mishra, Pegah Alipoormolabashi , Yeganeh
Kordi, Amirreza Mirzaei, Atharva Naik, Arjun Ashok, Arut Se l-
van Dhanasekaran, Anjana Arunkumar, David Stap, et al. Supe r-
naturalinstructions: Generalization via declarative ins tructions on 1600+
nlp tasks. In Proceedings of the 2022 Conference on Empirical Methods
in Natural Language Processing , pages 5085–5109, 2022. 1,2
[16] Jason Wei, Maarten Bosma, Vincent Y Zhao, Kelvin Guu, Ad ams Wei
Yu, Brian Lester, Nan Du, Andrew M Dai, and Quoc V Le.
Finetuned language models are zero-shot learners. arXiv preprint
arXiv:2109.01652 , 2021. 1,2
[17] Li Yunxiang, Li Zihan, Zhang Kai, Dan Ruilong, and Zhang You.
Chatdoctor: A medical chat model fine-tuned on llama model u sing
medical domain knowledge. arXiv preprint arXiv:2303.14070 , 2023. 3,
4

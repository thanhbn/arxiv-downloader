YAYI 2: Các Mô hình Ngôn ngữ Lớn Mã nguồn Mở Đa ngôn ngữ
Yin Luo∗, Qingchao Kong∗, Nan Xu∗, Jia Cao, Bao Hao, Baoyu Qu, Bo Chen, Chao Zhu
Chenyang Zhao, Donglei Zhang, Fan Feng, Feifei Zhao, Hailong Sun, Hanxuan Yang, Haojun Pan
Hongyu Liu, Jianbin Guo, Jiangtao Du, Jingyi Wang, Junfeng Li, Lei Sun, Liduo Liu, Lifeng Dong
Lili Liu, Lin Wang, Liwen Zhang, Minzheng Wang, Pin Wang, Ping Yu, Qingxiao Li, Rui Yan, Rui Zou
Ruiqun Li, Taiwen Huang, Xiaodong Wang, Xiaofei Wu, Xin Peng, Xina Zhang, Xing Fang, Xinglin Xiao
Yanni Hao, Yao Dong, Yigang Wang, Ying Liu, Yongyu Jiang, Yungan Wang, Yuqi Wang
Zhangsheng Wang, Zhaoxin Yu, Zhen Luo, Wenji Mao, Lei Wang∗, Dajun Zeng∗
Công ty TNHH Công nghệ Bắc Kinh Wenge
Viện Tự động hóa, Viện Hàn lâm Khoa học Trung Quốc

Tóm tắt
Là những tiến bộ mới nhất trong xử lý ngôn ngữ tự nhiên, các mô hình ngôn ngữ lớn (LLM) đã đạt được khả năng hiểu và tạo sinh ngôn ngữ ở mức độ con người trong nhiều nhiệm vụ thực tế, và thậm chí đã được coi là một con đường tiềm năng dẫn đến trí tuệ nhân tạo tổng quát. Để hỗ trợ tốt hơn cho nghiên cứu về LLM, nhiều LLM mã nguồn mở như Llama 2 và Falcon đã được đề xuất gần đây và đạt được hiệu suất tương đương với các mô hình độc quyền. Tuy nhiên, các mô hình này chủ yếu được thiết kế cho các tình huống tiếng Anh và thể hiện hiệu suất kém trong bối cảnh tiếng Trung. Trong báo cáo kỹ thuật này, chúng tôi đề xuất YAYI 2, bao gồm cả mô hình cơ sở và mô hình trò chuyện, với 30 tỷ tham số. YAYI 2 được huấn luyện trước từ đầu trên một kho ngữ liệu đa ngôn ngữ chứa 2,65 nghìn tỷ token được lọc bởi pipeline xử lý dữ liệu huấn luyện trước của chúng tôi. Mô hình cơ sở được căn chỉnh với các giá trị con người thông qua tinh chỉnh có giám sát với hàng triệu hướng dẫn và học tăng cường từ phản hồi của con người. Các thí nghiệm mở rộng trên nhiều tiêu chuẩn như MMLU và CMMLU nhất quán chứng minh rằng YAYI 2 được đề xuất vượt trội hơn các mô hình mã nguồn mở có kích thước tương tự khác.

1 Giới thiệu
Các mô hình ngôn ngữ lớn (LLM) (Vaswani et al., 2017; Kaddour et al., 2023) đã cho thấy khả năng mạnh mẽ trong hiểu và lĩnh hội ngôn ngữ (Brown et al., 2020), cũng như trong Q&A thông thường, lập trình và suy luận logic (Lightman et al., 2023). Kể từ khi ra mắt ChatGPT, một số lượng lớn LLM đã được đề xuất bởi các tổ chức và công ty khác nhau trên thế giới, chủ yếu phục vụ như trợ lý cá nhân thông minh thông qua giao diện trò chuyện, và xuất sắc trong việc viết sáng tạo, tóm tắt văn bản, lập kế hoạch hoạt động, v.v. Do khả năng toàn diện, LLM thậm chí được coi là một con đường tiềm năng hướng tới trí tuệ nhân tạo tổng quát (AGI).

Hàng terabyte dữ liệu huấn luyện và tài nguyên máy tính đắt đỏ đã trở thành những nút thắt chính hạn chế sự phát triển của LLM. Một số sản phẩm đại diện dựa trên LLM như ChatGPT và Claude (Bai et al., 2022) là các mô hình mã nguồn đóng. Để làm cho nó dễ tiếp cận hơn cho các nhà nghiên cứu, nhiều LLM mã nguồn mở đã được đề xuất. Ví dụ, BLOOM (Workshop et al., 2022) là LLM đa ngôn ngữ đầu tiên với 175 tỷ tham số được huấn luyện trên kho ngữ liệu ROOTS. Các mô hình dòng Llama (Touvron et al., 2023a,b) đã đạt được hiệu suất tương đương với GPT-3.5 và Palm 2 (Anil et al., 2023) bằng cách huấn luyện trên nhiều token văn bản hơn với chất lượng tốt hơn. Bên cạnh kho ngữ liệu ROOTS, nhiều bộ dữ liệu khác như RedPajama (Computer, 2023) và RefinedWeb (Penedo et al., 2023) được mở mã nguồn để hỗ trợ thêm cho việc huấn luyện LLM. Tuy nhiên, các bộ dữ liệu mã nguồn mở này chỉ chứa một phần nhỏ văn bản tiếng Trung và thiếu kiến thức và văn hóa phổ biến về Trung Quốc, điều này nghiêm trọng hạn chế các ứng dụng của LLM mã nguồn mở trong các tình huống liên quan đến tiếng Trung. Để lấp đầy khoảng trống này, một số LLM dựa trên tiếng Trung đã được đề xuất, bao gồm ChatGLM (Zeng et al., 2023), Baichuan 2 (Yang et al., 2023) và Qwen (Bai et al., 2023).

Trong báo cáo kỹ thuật này, chúng tôi đề xuất một dòng LLM đa ngôn ngữ, được ký hiệu là YAYI (雅意) 2, bao gồm mô hình cơ sở và mô hình trò chuyện, cả hai đều có 30 tỷ tham số. Các mô hình YAYI 2 được huấn luyện trên 2,65 nghìn tỷ token trên một cụm máy tính với hơn 1000 GPU A800. Đối với bộ dữ liệu huấn luyện trước, chúng tôi thu thập hơn 240 terabyte văn bản, bao gồm tin tức, sách, Wikipedia, mã code, v.v., trong đó 41,5% là tiếng Trung. Ngoài ra, chúng tôi thiết kế một pipeline xử lý dữ liệu huấn luyện trước nghiêm ngặt, bao gồm chuẩn hóa, làm sạch heuristic, khử trùng lặp đa cấp và lọc độc tính. Để tăng tốc độ huấn luyện và suy luận, FlashAttention 2 (Dao, 2023) và multi-query attention (MQA) (Shazeer, 2019) được áp dụng. Chúng tôi trình bày chi tiết các chi tiết huấn luyện và kỹ thuật tối ưu hóa để cải thiện hiệu quả huấn luyện. Chúng tôi căn chỉnh mô hình cơ sở YAYI 2 thông qua tinh chỉnh có giám sát (SFT) với hàng triệu cặp hướng dẫn-đầu ra và học tăng cường từ phản hồi của con người (RLHF), với hỗ trợ tốt hơn cho các hướng dẫn dài và cuộc hội thoại nhiều lượt. Quy trình huấn luyện của mô hình cơ sở và mô hình trò chuyện YAYI 2 được thể hiện trong Hình 1. Chúng tôi tiến hành các thí nghiệm toàn diện để đánh giá hiệu quả của mô hình cơ sở được đề xuất. Kết quả thí nghiệm cho thấy mô hình được đề xuất vượt trội hơn các LLM mã nguồn mở có kích thước tương tự khác trên các tiêu chuẩn bao gồm hiểu biết tri thức, suy luận toán học và lập trình, và thậm chí thể hiện tính ưu việt trên một số tiêu chuẩn so với LLM có tham số lớn hơn nhiều.

2 Huấn luyện Trước
Phần này cung cấp chi tiết về quy trình huấn luyện trước từ bốn khía cạnh: dữ liệu huấn luyện trước, token hóa, kiến trúc mô hình và chi tiết huấn luyện. Trước tiên chúng tôi tóm tắt các nguồn dữ liệu huấn luyện trước và đề xuất một pipeline xử lý dữ liệu tự phát triển. Tận dụng dữ liệu sạch chất lượng cao, chúng tôi xây dựng tokenizer đa ngôn ngữ YAYI 2. Tiếp theo, chúng tôi trình bày chi tiết kiến trúc mô hình và cài đặt tham số. Cuối cùng, chúng tôi giới thiệu cấu hình cụm máy tính và chiến lược huấn luyện cùng với một số thủ thuật huấn luyện mô hình.

2.1 Dữ liệu Huấn luyện Trước

2.1.1 Phân bố Dữ liệu
Mục tiêu của huấn luyện trước là tích lũy một loạt rộng lớn kiến thức từ khắp nơi trên thế giới và có được nhiều năng lực chuyên nghiệp khác nhau như toán học, lập trình và suy luận logic, điều này sẽ mang lại khả năng đáp ứng của mô hình đối với các tình huống đa ngôn ngữ và định dạng dữ liệu đa dạng. Theo đuổi các mục tiêu trên, một lượng lớn dữ liệu internet được sử dụng để huấn luyện khả năng hiểu và biểu đạt ngôn ngữ, được bổ sung bởi dữ liệu tổng quát được tuyển chọn và dữ liệu chuyên ngành để tăng cường thêm kỹ năng chuyên nghiệp của mô hình. Hình 3&4 cho thấy phân bố của các loại dữ liệu và ngôn ngữ tương ứng. Chi tiết về phân bố dữ liệu như sau:

• Dữ liệu internet chủ yếu bao gồm dữ liệu riêng tư gồm phương tiện truyền thông xã hội, tài liệu web internet và các bộ dữ liệu mã nguồn mở chất lượng cao. Trong việc lựa chọn nguồn dữ liệu, chúng tôi loại trừ một số bộ dữ liệu mã nguồn mở nhất định, chẳng hạn như OSCAR (Ortiz Suárez et al., 2019), có thể chứa thông tin có hại.

• Dữ liệu tổng quát được tuyển chọn bao gồm một loạt các danh mục bao gồm sách (ví dụ: sách giáo khoa, tiểu thuyết), mã code, bách khoa toàn thư, diễn đàn, bài báo học thuật, tin tức có thẩm quyền, luật pháp và quy định.

• Dữ liệu chuyên ngành bao gồm các lĩnh vực phổ biến như tài chính, thuế, truyền thông và tuyên truyền, dư luận, và y học cổ truyền Trung Quốc.

2.1.2 Tiền xử lý
Chúng tôi thiết lập một pipeline xử lý dữ liệu toàn diện để nâng cao chất lượng dữ liệu ở mọi khía cạnh. Pipeline này bao gồm bốn module: chuẩn hóa, làm sạch heuristic, khử trùng lặp đa cấp và lọc độc tính. Thông qua tối ưu hóa hiệu suất toàn diện, pipeline giảm đáng kể thời gian phản hồi để xử lý dữ liệu quy mô terabyte xuống còn vài giờ. Hình 2 minh họa pipeline xử lý dữ liệu huấn luyện trước hoàn chỉnh. 240 terabyte dữ liệu thô được thu thập để huấn luyện trước, và chỉ 10,6 terabyte dữ liệu chất lượng cao còn lại sau khi tiền xử lý.

Chuẩn hóa: Thông qua chuẩn hóa, tất cả dữ liệu thô được định dạng thành JSON với các khóa như nguồn dữ liệu, định danh và nội dung. Ngoài ra, một mô hình phát hiện ngôn ngữ được sử dụng để phát hiện ngôn ngữ.

Làm sạch Heuristic: Chúng tôi giới thiệu một chiến lược làm sạch đa cấp heuristic, xây dựng một cơ chế lọc cộng tác dựa trên chương, dòng, từ và ký tự. Đối với hàng chục loại dữ liệu như bách khoa toàn thư, Q&A, tin tức, sách và mã code, chúng tôi xây dựng hơn một nghìn quy tắc làm sạch heuristic, giải quyết các vấn đề về định dạng, nội dung và mã hóa. Ở cấp độ chương và cấp độ dòng, chiến lược tập trung vào các vấn đề ngữ nghĩa như ký tự bị lỗi, nhầm lẫn logic và dòng chất lượng thấp. Ở cấp độ từ, trọng tâm là loại bỏ các từ kích hoạt quảng cáo, trong khi ở cấp độ ký tự, chiến lược xem xét kỹ các trường hợp ký tự dư thừa và thiếu sót.

Khử trùng lặp Đa cấp: Để lọc các mẫu trùng lặp khác nhau, chúng tôi áp dụng một chiến lược khử trùng lặp cộng tác đa cấp, bao gồm khử trùng lặp cấp độ chương dựa trên URL và simHash, khử trùng lặp cấp độ đoạn văn dựa trên độ tương tự cosine, và khử trùng lặp cấp độ câu dựa trên khớp tiền tố-hậu tố.

Lọc Độc tính: Internet chứa một lượng đáng kể thông tin có hại và sai lệch, bao gồm nhưng không giới hạn ở khiêu dâm, bạo lực, định kiến, lời nói phân biệt đối xử, tấn công cá nhân và hoạt động bất hợp pháp. Để giảm thiểu vấn đề này, chúng tôi đề xuất một cơ chế lọc kép, sử dụng mô hình Yayi 2 Checker dựa trên từ nhạy cảm để sàng lọc ở giai đoạn đầu và sử dụng mô hình phân loại dựa trên ngôn ngữ heuristic lượng tử để hoàn thành lọc thứ cấp.

2.2 Token hóa
Trong bối cảnh quốc tế, hầu hết các LLM đều tập trung vào tiếng Anh, hạn chế khả năng tổng quát hóa của chúng trong các ngôn ngữ khác. Tương tự, các LLM được phát hành ở Trung Quốc có xu hướng tập trung vào các tình huống song ngữ (tiếng Trung và tiếng Anh), thiếu một kho ngữ liệu huấn luyện đa ngôn ngữ. Để tăng cường khả năng hiểu và phân tích của mô hình trên các ngôn ngữ khác nhau, các mô hình YAYI 2 sử dụng một tokenizer đa ngôn ngữ được huấn luyện tốt.

Dữ liệu Huấn luyện: Tokenizer của YAYI 2 được huấn luyện trên một kho ngữ liệu đa ngôn ngữ chất lượng cao 500GB, bao gồm hơn mười ngôn ngữ thường được sử dụng bao gồm tiếng Trung, tiếng Anh, tiếng Pháp, tiếng Nga, v.v. Các nguồn dữ liệu huấn luyện đa dạng bao gồm trang web, phương tiện truyền thông xã hội, sách, báo, bài báo học thuật, v.v.

Kích thước Từ vựng: Để hỗ trợ các ngôn ngữ thiểu số trong khi duy trì thành thạo tiếng Trung và tiếng Anh, tokenizer YAYI 2 mở rộng kích thước từ vựng lên 80.000. Hơn nữa, để khai thác công nghệ song song tensor và tensor cores một cách hiệu quả, kích thước từ vựng cần chia hết cho 128. Do đó, chúng tôi áp dụng 81.920 làm kích thước từ vựng cuối cùng.

Chuẩn hóa: Tokenizer YAYI 2 áp dụng một cách tiếp cận độc đáo bằng cách sử dụng trực tiếp văn bản thô để huấn luyện mà không trải qua chuẩn hóa. Chiến lược này đảm bảo sự thành thạo của mô hình trong việc xử lý các tình huống tổng quát.

Thuật toán: Bằng cách huấn luyện sử dụng thuật toán Byte-Pair Encoding (BPE) (Shibatay et al., 1999) từ thư viện Sentence-Piece (Kudo và Richardson, 2018), tokenizer YAYI 2 thể hiện một cách tiếp cận mạnh mẽ. Trong quá trình huấn luyện, mỗi chữ số của một số được tách một cách thông minh để tạo thuận lợi cho suy luận toán học. Từ vựng được tuyển chọn thủ công bao gồm một loạt các định danh HTML, dấu câu phổ biến để tăng cường độ chính xác phân đoạn và 200 slot dự trữ cho các ứng dụng tiềm năng như thêm định danh trong quá trình SFT. Là một thuật toán phân đoạn cấp độ byte, tokenizer YAYI 2 xuất sắc trong việc xử lý các ký tự không xác định.

Đánh giá: Hiệu suất của tokenizer được đo lường bằng tỷ lệ nén, được định nghĩa như sau:

r = L_token / L_origin (1)

trong đó r biểu thị tỷ lệ nén, L_token và L_origin biểu thị độ dài của văn bản đã được token hóa và văn bản gốc tương ứng. Tỷ lệ nén thấp hơn biểu thị hiệu suất hiệu quả cao hơn của tokenizer.

Để đánh giá toàn diện hiệu suất đa ngôn ngữ của tokenizer YAYI 2, chúng tôi lấy mẫu dữ liệu từ bộ dữ liệu SlimPajama (Shen et al., 2023) và dữ liệu nội bộ với độ dài 10.000 token cho mỗi cái, bao gồm tiếng Trung, tiếng Anh và nhiều ngôn ngữ thiểu số khác. Kết quả được trình bày trong Bảng 1 cho thấy rằng, trong cả hai tình huống song ngữ (CH-EN) và đa ngôn ngữ, tokenizer YAYI 2 vượt trội hơn các mô hình Trung Quốc khác như Baichuan 1 (Baichuan, 2023), ChatGLM (Zeng et al., 2023), Chinese Alpaca 2 (Cui et al., 2023), XVERSE (XVERSE, 2023), tự hào với tỷ lệ nén thấp hơn cho thấy hiệu quả huấn luyện và suy luận vượt trội.

2.3 Kiến trúc Mô hình
Các mô hình YAYI 2 dựa trên kiến trúc Transformer (Vaswani et al., 2017), áp dụng cấu trúc chỉ có decoder và huấn luyện theo cách tự hồi quy. Kiến trúc này, được áp dụng bởi hầu hết các LLM nổi bật như GPT (Brown et al., 2020), BLOOM (Workshop et al., 2022), LLaMA (Touvron et al., 2023a,b) và Baichuan (Yang et al., 2023), mang lại những lợi thế như tính toán hiệu quả, sử dụng bộ nhớ thấp hơn và khả năng tổng quát hóa tốt.

2.3.1 Embedding Vị trí
Do khả năng ngoại suy đặc biệt, hiện tại có hai phương pháp mã hóa vị trí phổ biến được tận dụng bởi các LLM, tức là Rotary Position Embedding (RoPE) (Su et al., 2023), tạo ra mã vị trí động cho khoảng cách giữa từng cặp phần tử bằng cách học thông tin vị trí tương đối, và Attention with Linear Biases Enables Input Length Extrapolation (ALiBi) (Press et al., 2022), áp dụng một ma trận offset được thiết lập sẵn cho điểm attention dựa trên khoảng cách giữa các token. Chúng tôi phát hiện thông qua thực nghiệm rằng RoPE cho thấy khả năng thích ứng tốt hơn với các framework tăng tốc như Flashattention 2 (Dao, 2023) và xFormers (Lefaudeux et al., 2022). Do đó, chúng tôi chọn RoPE làm phương pháp mã hóa vị trí được chọn.

2.3.2 Cơ chế Attention
Các mô hình YAYI 2 kết hợp một cơ chế Multi-Query Attention (MQA) (Shazeer, 2019) đặc biệt để thực hiện Self-Attention, bao gồm việc chia sẻ các ma trận trọng số W_K và W_V giữa các head và nối kết quả. MQA đóng vai trò then chốt trong việc giảm đáng kể kích thước của các tensor và giảm yêu cầu băng thông bộ nhớ cho việc giải mã tăng dần. Để tăng cường hiệu quả tính toán attention, chúng tôi tận dụng framework Flashattention 2 (Dao, 2023) trong quá trình huấn luyện để thực hiện tính toán MQA.

2.3.3 Hàm Kích hoạt và Chuẩn hóa
Mô hình của chúng tôi kết hợp SwiGLU (Shazeer, 2020) làm hàm kích hoạt do hiệu suất vượt trội và hội tụ nhanh hơn. Về phương pháp regularization, chúng tôi sử dụng RMSNorm (Zhang và Sennrich, 2019), chỉ tập trung vào tính bất biến rescaling và thực hiện regularization cho các đầu vào được tổng hợp đơn giản dựa trên căn bậc hai của trung bình bình phương. So với Layer Normalization (Ba et al., 2016) thường được sử dụng, RMSNorm có thể giảm xấp xỉ 7%-64% thời gian tính toán.

2.4 Huấn luyện Mô hình

2.4.1 Cụm Máy tính
Các mô hình YAYI 2 được huấn luyện trên một cụm bao gồm hơn 1000 máy chủ GPU A800. Các node của cụm này được kết nối thông qua mạng InfiniBand (IB), tạo thuận lợi cho việc truy cập bộ nhớ trực tiếp tốc độ cao và truyền dữ liệu. Các GPU trong mỗi node được liên kết thông qua các kết nối NVLink băng thông cao, độ trễ thấp. Để tối ưu hóa việc quản lý cụm về mã code, dữ liệu và checkpoint mô hình, một ổ cứng SSD được triển khai như lưu trữ chia sẻ cho toàn bộ cụm sử dụng Network File System (NFS). Giải quyết các thách thức phổ biến trong quản lý cụm quy mô lớn, như phân bổ tài nguyên, lập lịch công việc và khả năng mở rộng, chúng tôi nâng cao hệ thống SLURM (Simple Linux Utility for Resource Management) để quản lý tài nguyên và lập lịch công việc. Ngoài ra, một module cảnh báo bất thường cũng được thêm vào để giám sát trạng thái chạy thời gian thực của cụm trong trường hợp lỗi phần cứng và ngoại lệ chương trình không được xử lý.

2.4.2 Chiến lược Huấn luyện
Huấn luyện Phân tán: Để giữ cân bằng giữa sử dụng bộ nhớ GPU và hiệu quả giao tiếp, Zero Redundancy Optimizer (ZeRO) (Rajbhandari et al., 2020) stage 3 được áp dụng, hoạt động cùng với gradient checkpointing, cải thiện đáng kể việc sử dụng bộ nhớ GPU. Như mong đợi, tốc độ xử lý trung bình của GPU đạt 600 token/s, với tỷ lệ sử dụng tensor core là 65%, thể hiện hiệu suất vượt trội trong các cụm quy mô lớn (Touvron et al., 2023a).

Optimizer: AdamW (Loshchilov và Hutter, 2017) được sử dụng để huấn luyện. Không giống như Adam (Kingma và Ba, 2015), AdamW đạt được hiệu quả tính toán cao hơn, khả năng tổng quát hóa vượt trội và tốc độ hội tụ nhanh hơn. Đối với các tham số của AdamW, β1 và β2 được đặt lần lượt là 0,9 và 0,95. Weight decay là 0,1. Việc huấn luyện mô hình được khởi động với tốc độ học từ 5×10^-5 đến 1×10^-4 trong 2000 bước đầu tiên.

Hình 5 cho thấy loss huấn luyện cuối cùng của YAYI2-30B.

2.4.3 Thủ thuật Huấn luyện
Phân bổ Dữ liệu Trước: Duy trì phân bố dữ liệu ổn định là quan trọng để cải thiện hiệu suất mô hình. Sự dao động lớn trong phân bố dữ liệu có thể có hại cho sự hội tụ của mô hình. Để kiểm soát chính xác phân bố dữ liệu, chúng tôi thiết kế một cơ chế phân bổ dữ liệu trước dựa trên chỉ mục tệp. Cơ chế này xây dựng một bảng chỉ mục tệp toàn cục và phân bổ các tệp dữ liệu cho mỗi GPU trước khi huấn luyện, đảm bảo phân bố dữ liệu nhất quán qua các bước huấn luyện. Tùy thuộc vào việc số lượng dữ liệu có cố định hay không, dữ liệu huấn luyện trước có thể được chia thành dữ liệu tĩnh và dữ liệu động. Số lượng dữ liệu tĩnh không thay đổi theo thời gian, và chủ yếu bao gồm dữ liệu kiến thức như sách, thơ cổ, sách giáo khoa, bài báo học thuật, cơ sở dữ liệu kiến thức bách khoa, v.v. Số lượng dữ liệu tĩnh hạn chế nhưng chất lượng cao, trong khi dữ liệu động thể hiện số lượng lớn nhưng với chất lượng thấp hơn. Số lượng dữ liệu động tiếp tục tăng theo thời gian, chủ yếu bao gồm dữ liệu tin tức hiện tại như trang web, báo, phương tiện truyền thông xã hội, v.v. Để giảm ảo giác mô hình, chúng tôi tăng mẫu dữ liệu tĩnh và giảm mẫu dữ liệu động bằng cách tăng và giảm chỉ mục tệp tương ứng.

Lazy Loading: Khi tải checkpoint mô hình nhị phân, vì mỗi GPU trong một node cần tải trước trọng số mô hình từ bộ nhớ CPU của node vào bộ nhớ GPU của nó, bộ nhớ CPU có thể tràn dưới các cấu hình khác nhau của cụm máy tính. Bằng cách giới thiệu chiến lược lazy loading, tức là cho phép các GPU khác nhau bắt đầu quá trình tải trước tuần tự, chúng tôi giảm việc sử dụng bộ nhớ đỉnh trong giai đoạn tải mô hình và tránh hiệu quả tràn bộ nhớ CPU.

Khởi động lại Huấn luyện: Với việc mở rộng cụm máy tính, các nhiệm vụ huấn luyện dễ bị gián đoạn do các vấn đề phần mềm và phần cứng khác nhau. Để giảm thiểu thời gian nhàn rỗi của cụm huấn luyện và khởi động lại huấn luyện từ checkpoint trung gian, chúng tôi tối ưu hóa các biện pháp phòng ngừa cho các vấn đề phổ biến như GPU bị crash, hết dung lượng đĩa, deadlock, v.v. Cụ thể, chúng tôi thực hiện can thiệp tự động từ ba khía cạnh: ghi log, cảnh báo ngoại lệ và khởi động lại tự động.

• Ghi log: Chúng tôi duy trì log chi tiết về trạng thái nhiệm vụ huấn luyện hiện tại, bao gồm đầu ra huấn luyện mô hình và trạng thái sử dụng dữ liệu.

• Cảnh báo ngoại lệ: Bằng cách giám sát việc sử dụng GPU và timestamp cập nhật của các tệp log, chúng tôi thiết lập một cơ chế cảnh báo tự động thông qua nhắn tin tức thời. Các loại trục trặc cũng được phát hiện và thông báo.

• Khởi động lại tự động: Dựa trên loại trục trặc, cụm huấn luyện áp dụng các chiến lược khởi động lại tương ứng. Ví dụ, khi một số GPU bị crash, các node có vấn đề được loại bỏ, và các node dự phòng được kết hợp vào cụm huấn luyện trước khi khởi động lại quá trình huấn luyện.

3 Căn chỉnh
Quá trình căn chỉnh cho YAYI2-30B bao gồm hai giai đoạn quan trọng: Tinh chỉnh Có giám sát (SFT) và Học tăng cường từ Phản hồi của Con người (RLHF).

3.1 Tinh chỉnh Có giám sát

3.1.1 Bộ dữ liệu Hướng dẫn
Dữ liệu hướng dẫn cho YAYI bao gồm dữ liệu hướng dẫn chất lượng cao được chú thích thủ công và các bộ dữ liệu SFT mã nguồn mở. Chúng tôi xem xét nghiêm ngặt dữ liệu hướng dẫn về mặt định dạng và nội dung. Đối với định dạng dữ liệu, chúng tôi kiểm tra các ngắt dòng bị thiếu. Đối với nội dung, chúng tôi: (1) kiểm tra tính đầy đủ của nội dung (tức là câu trả lời bị cắt ngắn, thông tin không đầy đủ và thế hệ lặp lại); (2) đảm bảo tính nhất quán của ngôn ngữ trong hướng dẫn và câu trả lời, ngoại trừ các nhiệm vụ dịch thuật; (3) xác nhận rằng các câu trả lời được tạo ra tuân theo các hướng dẫn đã cho; (4) đảm bảo rằng các phản hồi được tạo ra không có ảo giác; (5) xác minh rằng các câu trả lời tuân thủ luật pháp và quy định; (6) xem xét kỹ lưỡng các giá trị con người trong các cặp hướng dẫn-câu trả lời.

Đối với định dạng dữ liệu, tính đầy đủ nội dung và tính nhất quán ngôn ngữ, một mô hình phân loại được huấn luyện để đánh giá dữ liệu hướng dẫn mã nguồn mở và dữ liệu được tạo tự động. Đối với việc tuân thủ hướng dẫn và vấn đề ảo giác, chúng tôi kiểm tra có hệ thống dữ liệu theo từng batch thông qua xác minh thủ công. Các nguồn dữ liệu trong mỗi batch nhất quán. Một batch dữ liệu bị loại bỏ nếu nó thể hiện việc tuân thủ hướng dẫn kém hoặc có nhiều vấn đề ảo giác. Về mối quan ngại an toàn, xem Phần 5.2.

Sau khi lọc và xem xét, chúng tôi xác định dữ liệu chất lượng cao để đảm bảo lấy mẫu cân bằng cho huấn luyện. Để đảm bảo sự đa dạng dữ liệu cho SFT, chúng tôi lấy mẫu dữ liệu qua các loại nhiệm vụ khác nhau, danh mục ngôn ngữ, độ dài ngữ cảnh và nguồn dữ liệu, trong đó phân bố của các loại nhiệm vụ tổng quát được nêu trong Bảng 2.

Theo định dạng Chat Markup Language (ChatML) của OpenAI, SFT cho YAYI tuân thủ một cuộc hội thoại nhiều lượt có cấu trúc liên quan đến ba vai trò: hệ thống, con người và Yayi. Hệ thống định nghĩa thông tin vai trò toàn cục và cài đặt định danh, con người đại diện cho người dùng, và YAYI tượng trưng cho mô hình lớn. Các định danh cho những vai trò này được ký hiệu là "<system>", "<human>", và "<yayi>" để rõ ràng.

3.1.2 Chi tiết Huấn luyện
Phù hợp với giai đoạn huấn luyện trước, các mô hình YAYI 2 sử dụng một framework huấn luyện phân tán cho SFT. Việc huấn luyện sử dụng độ chính xác floating-point BF16 để tăng hiệu quả và sử dụng optimizer AdamW với β1 được đặt là 0,9, β2 được đặt là 0,96 và ε được đặt là 1e-8. Các bước warm-up tốc độ học chiếm khoảng 10% tổng số bước, tăng dần đến tốc độ học đỉnh là 5e-6. Để ngăn ngừa overfitting, weight decay được đặt là 1e-3.

Để phù hợp với các độ dài hướng dẫn khác nhau trong quá trình huấn luyện, bao gồm hướng dẫn ngắn, dài, cuộc hội thoại một lượt và hướng dẫn cuộc hội thoại nhiều lượt, chúng tôi dần dần điều chỉnh cửa sổ ngữ cảnh từ 2.048 đến 4.096 và cuối cùng là 8.192. Cụm máy tính giống như Phần 2.4.1.

3.1.3 Hướng dẫn Dài
Để tăng cường khả năng của mô hình trong việc xử lý văn bản dài, một batch dữ liệu SFT dài được xây dựng, bao gồm cả loại đầu vào dài và loại đầu ra dài. Dữ liệu đầu vào dài bao gồm các nhiệm vụ như tóm tắt văn bản dài, hiểu đọc và các hướng dẫn phức tạp khác. Dữ liệu đầu ra dài liên quan đến việc tạo ra các bài viết dài, đề cương nhiều cấp và báo cáo nghiên cứu, v.v.

3.1.4 Cuộc hội thoại Nhiều lượt
Chúng tôi xây dựng dữ liệu cuộc hội thoại nhiều lượt từ hai chiều:

• Chiều Liên quan Ngữ cảnh: bao gồm dữ liệu cuộc hội thoại nhiều lượt liên quan ngữ cảnh và không liên quan ngữ cảnh. Cuộc hội thoại liên quan ngữ cảnh bao gồm câu hỏi của con người liên quan đến nội dung trước đó, trong khi cuộc hội thoại không liên quan ngữ cảnh bao gồm câu hỏi không liên quan đến cuộc hội thoại đang diễn ra.

• Chiều Thông tin Vai trò: bao gồm cuộc hội thoại nhiều lượt cho các nhiệm vụ tổng quát (không có thông tin vai trò) và cuộc hội thoại nhiều lượt đóng vai.

Trong quá trình tạo dữ liệu hướng dẫn, chúng tôi áp dụng một cách tiếp cận tinh tế, phân đoạn dữ liệu thành các chiều thông tin vai trò khác biệt. Việc phân đoạn này bao gồm cuộc hội thoại nhiều lượt được tùy chỉnh cho các nhiệm vụ tổng quát và cuộc hội thoại nhiều lượt đóng vai, được kết hợp chiến lược với tính liên quan ngữ cảnh để tổng hợp dữ liệu. Trong lĩnh vực nhiệm vụ tổng quát, cuộc hội thoại nhiều lượt có các trường hợp cả liên quan và không liên quan đến ngữ cảnh đang diễn ra. Ngược lại, cuộc hội thoại nhiều lượt đóng vai, được phân biệt bởi bản chất ngắn gọn và hướng ngữ cảnh, chỉ tính đến các tình huống liên quan ngữ cảnh. Khái niệm hóa này được mô tả ngắn gọn trong Hình 6.

• Dữ liệu cuộc hội thoại nhiều lượt liên quan ngữ cảnh trong các nhiệm vụ tổng quát: Trong vấn đề này, chúng tôi thiết kế một thuật toán tỉ mỉ để tạo dữ liệu. Bắt đầu với dữ liệu câu hỏi con người được lấy mẫu ngẫu nhiên từ cơ sở dữ liệu hướng dẫn, mô hình tạo ra một phản hồi ban đầu. Sau đó, tận dụng ngữ cảnh hiện có, chúng tôi có hệ thống xây dựng các câu hỏi liên quan và kết hợp nội dung ngữ cảnh để thúc đẩy mô hình tạo ra các vòng phản hồi tiếp theo. Quá trình lặp lại này dẫn đến việc tạo ra dữ liệu cuộc hội thoại nhiều lượt liên quan ngữ cảnh gắn liền với dữ liệu gốc.

• Dữ liệu cuộc hội thoại nhiều lượt không liên quan ngữ cảnh trong các nhiệm vụ tổng quát: Trong vấn đề này, chúng tôi độc lập rút ra các batch ngẫu nhiên dữ liệu một lượt tương tự loại nhiệm vụ và không liên quan loại nhiệm vụ. Thông qua xem xét thống kê, nó xuất hiện rằng các truy vấn con người trong một cuộc hội thoại nhiều lượt duy nhất thể hiện xu hướng tương tự chủ đề. Được hướng dẫn bởi quan sát này, chúng tôi lấy mẫu và nối dữ liệu loại nhiệm vụ tương tự hoặc thiết kế dữ liệu mẫu hỗn hợp, phản ánh các tình huống mà con người đặt ra nhiều truy vấn liên quan đến cùng một nhiệm vụ (ví dụ: thúc đẩy mô hình tạo ra thơ lặp đi lặp lại) hoặc các nhiệm vụ đa dạng trong một cuộc hội thoại nhiều lượt duy nhất (ví dụ: bắt đầu tạo thơ tiếp theo bằng giải quyết vấn đề toán học).

• Cuộc hội thoại nhiều lượt đóng vai: Việc tạo prompt bắt đầu bằng cách gán ngẫu nhiên vai trò cho mô hình YAYI, bao gồm vai trò tập trung vào nhiệm vụ (ví dụ: bác sĩ y học cổ truyền Trung Quốc, luật sư, nhà phân tích tài chính) và vai trò nhân vật cụ thể (ví dụ: Khổng Tử, Tôn Ngộ Không, Trương Phi). Dựa trên phong cách nói chuyện và đặc điểm tính cách vốn có trong những vai trò này, chúng tôi mô phỏng cuộc hội thoại nhiều lượt có sự tham gia của con người. Sau khi đánh giá chất lượng nghiêm ngặt, nó đảm nhận vai trò là bộ dữ liệu huấn luyện cuộc hội thoại nhiều lượt của mô hình.

Định dạng của dữ liệu huấn luyện cuộc hội thoại nhiều lượt phù hợp với định dạng của nhiệm vụ hướng dẫn một lượt. Nó bắt đầu với thông tin vai trò được định nghĩa toàn cục, xen kẽ giữa người dùng và mô hình YAYI, và kết thúc mỗi phản hồi của mô hình YAYI bằng token kết thúc chuỗi "</s>." Định dạng được minh họa dưới đây.

Trong quá trình huấn luyện mô hình, chúng tôi chỉ tính toán loss cho đầu ra của mỗi lượt trong cuộc hội thoại nhiều lượt, như được mô tả trong Hình 9. Cách tiếp cận chiến lược này hướng mô hình đến việc tạo ra nội dung cuộc hội thoại chất lượng cao, tránh các tính toán không cần thiết cho nội dung không liên quan. Phương pháp có mục tiêu này tăng cường đáng kể hiệu quả huấn luyện.

3.1.5 Nhiệm vụ Lĩnh vực
Mô hình lớn YAYI được tùy chỉnh tỉ mỉ cho các tình huống kinh doanh thực tế, bao gồm một phổ đa dạng của hàng trăm nhiệm vụ trải dài qua tài chính, truyền thông, luật pháp, chăm sóc sức khỏe và hơn thế nữa. Thông qua chú thích và xem xét thủ công, chúng tôi xây dựng một loạt dữ liệu cụ thể lĩnh vực cho SFT, nhằm mài giũa năng lực của mô hình trong việc điều hướng các thách thức kinh doanh xác thực.

3.2 Học tăng cường từ Phản hồi của Con người
Mặc dù có hiệu suất đáng khen ngợi của tinh chỉnh có giám sát qua các nhiệm vụ khác nhau, hiệu quả của mô hình được đề xuất phụ thuộc vào chất lượng dữ liệu được chú thích và dễ bị overfitting. Để vượt qua những hạn chế này và nâng cao hơn nữa khả năng tổng quát hóa của các mô hình YAYI, chúng tôi chuyển sang học tăng cường từ phản hồi của con người (Ouyang et al., 2022). Phương pháp này nhằm căn chỉnh nội dung được tạo ra của mô hình gần hơn với sở thích của con người. Cụ thể, một mô hình phần thưởng được huấn luyện để dự đoán sở thích con người, và thuật toán Proximal Policy Optimization (PPO) (Schulman et al., 2017) được sử dụng để tăng cường mô hình YAYI, hướng dẫn nó đến việc tạo ra các phản hồi cộng hưởng tốt hơn với kỳ vọng của con người.

3.2.1 Mô hình Phần thưởng
Để thu thập các hướng dẫn chất lượng cao và cân bằng, một chiến lược lấy mẫu hướng dẫn tỉ mỉ được thực hiện. Ban đầu, một hệ thống khử trùng lặp ngữ nghĩa được sử dụng cho một tập hướng dẫn rộng lớn. Sau đó, một phân chia nhiệm vụ hai tầng được sử dụng với một chiến lược lấy mẫu có trọng số động để duy trì cân bằng hướng dẫn trong mỗi danh mục.

Cho một prompt, mô hình trò chuyện YAYI 2 tạo ra hai phản hồi, sử dụng các chiến lược lấy mẫu khác biệt. Các chuyên gia chú thích đánh giá những phản hồi này qua bốn chiều: tính đúng đắn định dạng, tính đầy đủ nội dung, tính chính xác nội dung và tuân thủ hướng dẫn. Những đánh giá này được sử dụng để tinh chỉnh liên tục hiệu suất của mô hình phần thưởng.

Mô hình phần thưởng được huấn luyện bắt đầu với mô hình trò chuyện YAYI sau SFT. Đáng chú ý, để ổn định hiệu suất, một token phần thưởng được thêm vào mỗi điểm dữ liệu. Các đặc trưng embedding của token này sau đó được sử dụng để dự đoán phần thưởng cuối cùng. Trong suốt quá trình huấn luyện, mô hình phần thưởng thể hiện một xu hướng tăng dần về độ chính xác phân biệt khi khoảng cách chất lượng giữa hai phản hồi mở rộng.

3.2.2 Học tăng cường thông qua PPO
Thuật toán PPO được áp dụng cho học tăng cường, bao gồm bốn mô hình: mô hình chính sách (chịu trách nhiệm tạo phản hồi, yêu cầu tối ưu hóa), mô hình tham chiếu (cung cấp tham chiếu tham số cố định cho mô hình chính sách), mô hình phần thưởng (đánh giá chất lượng phản hồi với tham số cố định), và mô hình giá trị (học giá trị token và yêu cầu tối ưu hóa). Mô hình giá trị trải qua giai đoạn warm-up gồm 50 bước huấn luyện trong quá trình huấn luyện. Cả mô hình giá trị và mô hình chính sách đều được cập nhật bằng thuật toán PPO tiêu chuẩn. Để duy trì ổn định huấn luyện, các kỹ thuật clipping và chuẩn hóa cũng được áp dụng.

4 Suy luận
4.1 Suy luận Ngữ cảnh Dài
Các mô hình YAYI 2 đã tăng cường đáng kể khả năng xử lý văn bản dài và cuộc hội thoại nhiều lượt bằng cách tận dụng cửa sổ ngữ cảnh mở rộng. Trong khi các mô hình độc quyền chính thống, như GPT-4-Turbo, đã mở rộng độ dài ngữ cảnh của chúng đến 128K, các LLM mã nguồn mở, như Llama, thường hỗ trợ độ dài ngữ cảnh 4K. Trong báo cáo kỹ thuật này, chúng tôi tăng cường khả năng xử lý thông tin ngữ cảnh mở rộng của các mô hình YAYI 2 bằng cách mở rộng khả năng ngoại suy dựa trên các tính năng có thể mở rộng của phương pháp position embedding RoPE.

Nghiên cứu hiện tại trong ngoại suy RoPE chủ yếu khám phá hai hướng: các phương pháp dựa trên sliding window và các phương pháp dựa trên điều chỉnh góc xoay. Do việc mất thông tin tần số thấp toàn cục liên quan đến sliding window, các nghiên cứu gần đây tập trung nhiều hơn vào điều chỉnh góc xoay mã hóa. Các mô hình YAYI 2 áp dụng phương pháp YaRN (Peng et al., 2023) cho ngoại suy RoPE, tích hợp NTK với các phương pháp sliding window để giảm thiểu sự sụp đổ trong các ngữ cảnh cực dài.

Hình 10 cho thấy YAYI2-30B với YaRN có perplexity thấp hơn đáng kể và ổn định hơn, điều này chứng minh hiệu quả của NTK với sliding window để ngoại suy.

4.2 Thích ứng Suy luận Phần cứng Đa dạng
Ngoài GPU NVIDIA, các mô hình YAYI 2 đã được thích ứng để suy luận hiệu quả trên phần cứng Huawei Ascend 910B. Để giải quyết các thách thức do số lượng tham số lớn của mô hình 30B trong quá trình suy luận GPU đơn, chúng tôi áp dụng giải pháp suy luận phân tán, bao gồm sử dụng multi-GPU để suy luận. Quá trình này đòi hỏi biên dịch mạng chiến lược đích để có được tệp chiến lược phân tán. Do đó, dựa trên chiến lược chia tách, trọng số mô hình được phân vùng và tải lên mỗi GPU để thực hiện quy trình suy luận tiếp theo.

5 An toàn
5.1 Giai đoạn Huấn luyện Trước
Giai đoạn chuẩn bị dữ liệu huấn luyện trước ưu tiên và tuân thủ nghiêm ngặt các giao thức bảo mật dữ liệu để đảm bảo tính toàn vẹn và tuân thủ của dữ liệu. Một chiến lược toàn diện được triển khai, kết hợp một hệ thống lọc và phân loại bảo mật dữ liệu mạnh mẽ.

Mục tiêu chính của hệ thống này là xác định và loại trừ nội dung có thể có hại và liên quan đến bảo mật, ngăn chặn mô hình học và tái tạo thông tin không phù hợp. Các danh mục cụ thể của thông tin liên quan đến an toàn bao gồm:

• Thông tin nhạy cảm: Dữ liệu nội bộ công ty bảo mật, như báo cáo tài chính chưa công bố và tài liệu nghiên cứu, được lọc ra để ngăn chặn các vấn đề vi phạm sở hữu trí tuệ. Thông tin nhạy cảm khác bao gồm dữ liệu riêng tư cá nhân, bao gồm nhưng không giới hạn ở thông tin nhận dạng cá nhân, chi tiết liên lạc, tài khoản ngân hàng và hồ sơ y tế.

• Nội dung không phù hợp: Nội dung không phù hợp bao gồm lời nói căm thù, bạo lực, phân biệt đối xử (ví dụ: phân biệt đối xử dân tộc và giới tính), lời nói cực đoan, khiêu dâm và nội dung không đứng đắn khác.

• Nội dung Vi phạm Luật pháp và Quy định: Tài liệu có bản quyền được loại bỏ để đảm bảo rằng các tác phẩm được bảo vệ dưới bản quyền không được sử dụng bất hợp pháp hoặc bao gồm trong dữ liệu huấn luyện.

• Thông tin Sai lệch và Không chính xác: Thông tin sai lệch bao gồm tin tức giả, tin đồn và nội dung có thể gây hiểu lầm khác. Thông tin chống khoa học, giả khoa học và thông tin y tế sức khỏe không chính xác cũng được loại bỏ để kiềm chế sự lan truyền thông tin sai lệch.

Những chiến lược này được thực hiện trong các bước lựa chọn nguồn dữ liệu và xử lý dữ liệu. Ban đầu, lựa chọn nguồn dữ liệu bao gồm tuân thủ nghiêm ngặt các kênh có uy tín để tránh các tranh chấp sở hữu trí tuệ. Trong việc sàng lọc sơ bộ dữ liệu văn bản, một cơ chế lọc từ nhạy cảm dựa trên Deterministic Finite Automaton (DFA) được áp dụng. Đối với văn bản tiếng Trung, hệ thống phân đoạn được mở rộng, kết hợp một thư viện phân đoạn chuyên biệt để tăng cường độ chính xác lọc.

Hơn nữa, một mô hình phân loại văn bản hiệu quả được phát triển và huấn luyện để xác định và loại bỏ văn bản chứa nội dung không phù hợp. Tập huấn luyện bao gồm các danh mục như khiêu dâm, bạo lực, phân biệt đối xử, lời nói căm thù, vi phạm an toàn cá nhân và nội dung bất hợp pháp. Để mở rộng khả năng nhận dạng của mô hình, việc dịch mẫu giữa tiếng Trung và tiếng Anh được tiến hành, đa dạng hóa các mẫu huấn luyện. Dữ liệu chuyên nghiệp y tế được đưa vào cụ thể trong các mẫu huấn luyện để ngăn chặn việc phân loại sai văn bản liên quan đến y tế. Hai bước quan trọng này tăng cường đáng kể tính bảo mật của dữ liệu huấn luyện và đặt nền tảng vững chắc cho việc huấn luyện mô hình tiếp theo.

5.2 Giai đoạn Tinh chỉnh
Một thuật toán kiểm tra an toàn kết hợp khớp thường xuyên với các mô hình học máy được thiết kế để phân loại an toàn trong giai đoạn tinh chỉnh. Trong số dữ liệu SFT, dữ liệu hướng dẫn an toàn được phân loại thành hướng dẫn tích cực và từ chối trả lời:

• Danh mục hướng dẫn tích cực: Câu hỏi chứa các tuyên bố không phù hợp với giá trị con người hoặc mâu thuẫn với sự thật khách quan yêu cầu mô hình sửa chữa nội dung không phù hợp và cung cấp phản hồi hướng dẫn tích cực phù hợp với giá trị con người.

• Danh mục từ chối trả lời: Câu hỏi liên quan đến vấn đề bất hợp pháp hoặc những câu hỏi trái với các chính sách và luật pháp liên quan thúc đẩy mô hình bày tỏ lời xin lỗi, thông báo cho người dùng về nội dung không phù hợp và từ chối cung cấp câu trả lời.

Huấn luyện kết hợp dữ liệu hướng dẫn tăng cường an toàn với các nhiệm vụ tổng quát và nhiệm vụ lĩnh vực được tiến hành để ngăn chặn quên lãng thảm khốc và tăng cường tính bảo mật của mô hình.

6 Đánh giá
6.1 Mô hình Cơ sở
Trong phần này, chúng tôi đánh giá hiệu suất của mô hình cơ sở YAYI 2 so với một loạt các mô hình mã nguồn mở có kích thước tham số tương tự trên các bộ dữ liệu tiêu chuẩn. Các chiều đánh giá bao gồm hiểu biết tri thức và ngôn ngữ, suy luận toán học và khả năng lập trình. Các mô hình cơ sở so sánh bao gồm MPT-30B (MosaicML et al., 2023), Falcon-40B (Almazrouei et al., 2023), LLaMA 2-34B (Touvron et al., 2023b), Baichuan 2-13B (Yang et al., 2023), Qwen-14B&72B (Bai et al., 2023), InternLM-20B (InternLM, 2023), Aquila 2-34B (BAAI, 2023) và Yi-34B (01-AI, 2023).

6.2 Kết quả Đánh giá
Chúng tôi sử dụng độ chính xác làm thước đo chính và, nếu có, báo cáo kết quả của các mô hình so sánh được đánh giá bởi OpenCompass (OpenCompass, 2023), lấy từ bảng xếp hạng của trang web chính thức OpenCompass. Kết quả báo cáo của mô hình YAYI2-30B cũng được đánh giá bởi mã nguồn tại repo Github OpenCompass. Đối với các mô hình chưa được đánh giá bởi OpenCompass, bao gồm MPT-30B, Falcon-40B và LLaMA 2-34B, chúng tôi sử dụng kết quả được báo cáo bởi Touvron et al. (2023b). Lưu ý rằng trên một số tiêu chuẩn có thể có một số khác biệt nhỏ giữa các đánh giá được tiến hành bởi OpenCompass và Touvron et al. (2023b). Xem Hình 11 để so sánh tổng thể với ba LLM có kích thước tương tự, bao gồm InternLM-20B, Aquila2-34B và Yi-34B.

6.2.1 Hiểu biết Tri thức và Ngôn ngữ
Các đánh giá về hiểu biết tri thức bao gồm nhiều tiêu chuẩn khác nhau, bao gồm MMLU (Hendrycks et al., 2021a), tập xác thực C-Eval (Huang et al., 2023), CMMLU (Li et al., 2023), AGIEval (Zhong et al., 2023) và GAOKAO-Bench (Zhang et al., 2023).

• MMLU: Tiêu chuẩn đánh giá tri thức liên ngành tiếng Anh, bao gồm câu hỏi trắc nghiệm từ 57 ngành học trong STEM, nhân văn, khoa học xã hội và các lĩnh vực khác.

• C-Eval: Tiêu chuẩn đánh giá thi cử toàn diện tiếng Trung, bao gồm 13.948 câu hỏi trắc nghiệm, với bốn mức độ khó khác nhau, bao gồm kiến thức qua 52 ngành học.

• AGIEval: Tiêu chuẩn cho khả năng suy luận tri thức trong cả tiếng Trung và tiếng Anh, bao gồm câu hỏi trong nhiều lĩnh vực khác nhau như SAT, thi đại học và thi tư pháp.

• CMMLU: Tiêu chuẩn tiếng Trung đánh giá khả năng suy luận tri thức, bao gồm 67 câu hỏi trắc nghiệm qua các chủ đề khác nhau trong khoa học tự nhiên, nhân văn và khoa học xã hội, và cuộc sống hàng ngày.

• GAOKAO-Bench: Tiêu chuẩn tiếng Trung cho khả năng suy luận tri thức, bao gồm câu hỏi chính từ các kỳ thi tuyển sinh đại học quốc gia từ 2010 đến 2022, từ đó câu hỏi khách quan được chọn để đánh giá mô hình.

Chúng tôi báo cáo kết quả đánh giá 3-shot (cho MPT-30B, Falcon-40B và LLaMA 2-34B) hoặc zero-shot (cho các mô hình khác) trên AGIEval và GAOKAO-Bench, và kết quả 5-shot trên MMLU, C-Eval và CMMLU. Bảng 3 cho thấy kết quả chi tiết của mô hình được đề xuất trong các thí nghiệm so sánh trên những tiêu chuẩn này. Mô hình của chúng tôi vượt trội hơn các mô hình khác trên các tiêu chuẩn MMLU, AGIEval và CMMLU, thậm chí vượt qua Qwen-72B với kích thước tham số lớn hơn nhiều.

6.2.2 Suy luận Toán học và Logic
Trong lĩnh vực toán học và suy luận, mô hình của chúng tôi được đánh giá trên ba tiêu chuẩn nổi bật: GSM8K (Cobbe et al., 2021), MATH (Hendrycks et al., 2021b) và BBH (Suzgun et al., 2022). Chúng tôi sử dụng độ chính xác làm thước đo đánh giá chính.

• GSM8K: Bộ dữ liệu tiêu chuẩn được thiết kế cho suy luận toán học, bao gồm 1.319 câu hỏi toán học từ cơ bản.

• MATH: Bao gồm 5.000 câu hỏi toán học thách thức trải dài qua các lĩnh vực đa dạng như đại số tuyến tính, hình học và xác suất.

• BBH: Một tập con của bộ dữ liệu BIG-Bench, có 23 nhiệm vụ thách thức cao bao gồm suy luận logic, hiểu biết thông thường và toán học. Mục tiêu của nó là thách thức mô hình với các nhiệm vụ suy luận và hiểu ngôn ngữ phức tạp hơn.

Chúng tôi báo cáo kết quả đánh giá 8-shot (cho MPT-30B, Falcon-40B và LLaMA 2-34B) hoặc 4-shot (cho các mô hình khác) trên GSM8K, kết quả 4-shot trên MATH, và kết quả 3-shot trên BBH. Khi xem xét Bảng 4, mô hình cơ sở YAYI 2 đã đạt được hiệu suất tốt nhất trên tiêu chuẩn GSM8K trong số các mô hình có kích thước tham số tương đương.

6.2.3 Lập trình
Trong đánh giá khả năng lập trình, các tiêu chuẩn đánh giá bao gồm HumanEval (Chen et al., 2021) và MBPP (Austin et al., 2021):

• HumanEval: Bộ dữ liệu bao gồm 164 câu hỏi lập trình, mỗi câu có chữ ký hàm, chuỗi tài liệu, mã chủ đề và trung bình 7,7 bài kiểm tra đơn vị. Bao gồm các khía cạnh hiểu ngôn ngữ, suy luận, thuật toán và toán học cơ bản, nó phục vụ như một đánh giá toàn diện về trình độ của mô hình trong việc tạo mã.

• MBPP: Tiêu chuẩn mã hóa bao gồm 500 câu hỏi lập trình Python cấp độ người mới bắt đầu.

Thước đo đánh giá chính là pass@1, cho thấy tỷ lệ thành công của mô hình trong việc tạo mã đúng ở lần thử đầu tiên.

Theo phương pháp đánh giá của OpenCompass, chúng tôi báo cáo kết quả zero-shot trên HumanEval và kết quả 3-shot trên MBPP. Bảng 5 chứng minh mô hình của chúng tôi đứng vững như người thực hiện đỉnh cao trong số các mô hình có kích thước tham số tương đương, và thậm chí tính ưu việt đáng kể so với Qwen-72B lớn hơn nhiều trên tiêu chuẩn HumanEval.

Tóm lại, mô hình của chúng tôi thể hiện năng lực đáng chú ý qua các tiêu chuẩn hiểu biết tri thức, suy luận toán học và lập trình, xác thực hiệu quả của mô hình chúng tôi.

7 Kết luận
Trong báo cáo kỹ thuật này, chúng tôi đề xuất các LLM đa ngôn ngữ YAYI2-30B với trọng tâm cụ thể vào các ứng dụng liên quan đến tiếng Trung. Chúng tôi giới thiệu phân bố của bộ dữ liệu huấn luyện trước, cũng như pipeline tiền xử lý. Các mô hình YAYI2-30B tuân theo kiến trúc mô hình chỉ có decoder phổ biến, và áp dụng FlashAttention 2 và MQA để tăng tốc huấn luyện và suy luận. Chúng tôi cũng tiết lộ các chi tiết huấn luyện trước, bao gồm cụm máy tính, chiến lược huấn luyện và thủ thuật, điều mà chúng tôi tin sẽ mang lại lợi ích lớn cho các nhà thực hành trong ngành. Chúng tôi tiếp tục cho thấy cách xây dựng bộ dữ liệu hướng dẫn để tinh chỉnh hướng dẫn, và sự hỗ trợ của các mô hình YAYI 2 cho hướng dẫn dài, cuộc hội thoại nhiều lượt và ứng dụng cụ thể lĩnh vực. Quá trình RLHF được áp dụng thêm để căn chỉnh tốt hơn với các giá trị con người và đảm bảo an toàn. Mô hình cơ sở YAYI 2 được đánh giá trên ba loại tiêu chuẩn, bao gồm hiểu biết tri thức và ngôn ngữ, suy luận toán học và logic, và lập trình. Kết quả thí nghiệm mở rộng cho thấy mô hình được đề xuất đạt được hiệu suất vượt trội so với các LLM mã nguồn mở có kích thước tương tự trên nhiều tiêu chuẩn, bao gồm MMLU, AGIEval, CMMLU, GSM8K, HumanEval và MBPP. Đặc biệt trên các tiêu chuẩn MMLU, AGIEval, CMMLU và HumanEval, mô hình của chúng tôi thậm chí có thể vượt trội hơn Qwen-72B có kích thước lớn hơn với biên độ đáng kể.

Mặc dù chúng tôi đã áp dụng nhiều phương pháp khác nhau để đảm bảo an toàn và giảm ảo giác, các mô hình YAYI 2 vẫn có thể tạo ra nội dung có hại hoặc bịa đặt "sự thật", vì vậy người dùng mô hình được khuyến khích cao xem xét các câu trả lời, đặc biệt trong các tình huống quan trọng về an toàn. Người dùng mô hình cũng được khuyên ngăn chặn việc sử dụng sai các mô hình YAYI 2 và tuân thủ các luật pháp và quy định liên quan. Các mô hình YAYI 2 vẫn đang được phát triển tích cực, và mọi đề xuất và phản hồi đều được hoan nghênh.

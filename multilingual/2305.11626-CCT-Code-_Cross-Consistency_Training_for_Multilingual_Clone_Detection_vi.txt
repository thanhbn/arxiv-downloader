# CCT-Code: Huấn luyện Nhất quán Chéo cho Phát hiện Clone Đa ngôn ngữ và Tìm kiếm Mã nguồn

Anton Tikhonov1, Nikita Sorokin1, Dmitry Abulkhanov1,
Irina Piontkovskaya2, Sergey Nikolenko3, Valentin Malykh1,
1MTS AI, 2Huawei Noah's Ark Lab,
3Viện Toán học Steklov, Chi nhánh St. Petersburg
Liên hệ: valentin.malykh@phystech.edu

## Tóm tắt

Chúng tôi xem xét các nhiệm vụ nổi tiếng và quan trọng về phát hiện clone và truy xuất thông tin cho mã nguồn. Thiết lập tiêu chuẩn nhất là tìm kiếm các clone trong cùng các đoạn mã ngôn ngữ. Nhưng việc tìm kiếm các đoạn mã có hành vi giống hệt nhau trong các ngôn ngữ lập trình khác nhau cũng rất hữu ích. Tuy nhiên, phát hiện clone đa ngôn ngữ và chéo ngôn ngữ đã được nghiên cứu ít trong tài liệu. Chúng tôi trình bày một quy trình huấn luyện mới, huấn luyện nhất quán chéo (CCT) tận dụng sự tương đồng chéo ngôn ngữ, mà chúng tôi áp dụng để huấn luyện các mô hình ngôn ngữ trên mã nguồn trong các ngôn ngữ lập trình khác nhau. Chúng tôi chỉ ra rằng việc huấn luyện này hiệu quả cho cả mô hình dựa trên encoder và decoder. Mô hình CCT-LM dựa trên encoder đã huấn luyện đạt được kết quả tốt nhất mới trên POJ-104 (benchmark phát hiện clone C++ đơn ngôn ngữ) với 96.73% MAP và AdvTest (benchmark tìm kiếm mã Python đơn ngôn ngữ) với 47.18% MRR. Mô hình CCT-LM dựa trên decoder cho thấy hiệu suất tương đương trong các nhiệm vụ này. Ngoài ra, chúng tôi hình thức hóa vấn đề phát hiện clone đa ngôn ngữ và chéo ngôn ngữ và trình bày XCD, một tập dữ liệu benchmark mới được tạo từ các submission CodeForces.

## 1 Giới thiệu

Vấn đề phát hiện clone bắt nguồn từ một nhu cầu quan trọng phát sinh trong thực hành phát triển phần mềm: để xác định mã có cùng hành vi và đầu ra hiệu quả; điều này hữu ích, ví dụ, cho việc thống nhất mã, tái cấu trúc và kiểm soát tác dụng phụ. Mou et al. (2016) đã hình thức hóa nhiệm vụ phát hiện clone cho mã nguồn C/C++, và sau đó vấn đề được mở rộng cho các ngôn ngữ lập trình khác. Bước tiếp theo tự nhiên cho vấn đề này là phát hiện cùng hành vi cho mã trên các ngôn ngữ lập trình khác nhau. Trong công trình này, chúng tôi hình thức hóa nhiệm vụ phát hiện clone đa ngôn ngữ, thu thập một tập dữ liệu, và thiết lập các baseline hợp lý.

Nhiều phương pháp khác nhau cho nhiệm vụ phát hiện clone đã được phát triển, bắt đầu từ các phương pháp thuật toán (Baker, 1993; Krinke, 2001) và tiếp tục với các mô hình machine learning (Li et al., 2017; Thaller et al., 2020; Gotmare et al., 2021). Hầu hết các phương pháp machine learning dựa trên việc học các biểu diễn (embeddings) của các đoạn mã; phương pháp này cho phép tìm kiếm các đoạn mã trùng lặp bằng sự tương đồng giữa các embeddings của chúng trong không gian tiềm ẩn. Hiệu suất của các hệ thống như vậy phụ thuộc quan trọng vào chất lượng của embeddings. Trong công trình này, chúng tôi trình bày một kỹ thuật và pipeline huấn luyện mới được gọi là CCT cho các mô hình ngôn ngữ cho phép chúng embed các đoạn mã một cách hiệu quả. Chúng tôi chứng minh điều này bằng cách đạt được kết quả tốt nhất trên tập dữ liệu phát hiện clone có sẵn POJ-104 (Mou et al., 2016) và trên tập dữ liệu phát hiện clone đa ngôn ngữ mới được hình thức hóa XCD. Thú vị là, chúng tôi cũng chỉ ra rằng kỹ thuật CCT cho phép một mô hình tạo ra các biểu diễn hữu ích cho tìm kiếm mã. Tìm kiếm mã, như được hình thức hóa bởi Lu et al. (2021b), là nhiệm vụ mà truy vấn là một mô tả văn bản và các tài liệu có thể là các đoạn mã.

Do đó, các đóng góp chính của công trình chúng tôi là: (1) một phương pháp pretraining CCT cho phép một mô hình căn chỉnh các đoạn mã trong các ngôn ngữ lập trình khác nhau; (2) một tập dữ liệu phát hiện clone đa ngôn ngữ mới XCD dựa trên các submission CodeForces; (3) các kết quả tốt nhất mới được mô hình CCT-LM huấn luyện với CCT đạt được trên các tập dữ liệu phát hiện clone POJ-104 và XCD; (4) các kết quả tốt nhất của CCT-LM cho tìm kiếm mã trên tập dữ liệu AdvTest. Bài báo được tổ chức như sau: Phần 2 khảo sát các công trình liên quan, Phần 3 thảo luận về các tập dữ liệu tìm kiếm mã và giới thiệu XCD, Phần 4 trình bày phương pháp pretraining CCT, Phần 5 trình bày kết quả của chúng tôi, Phần 6 phân tích chúng và trình bày một nghiên cứu ablation, Phần 7 kết luận bài báo, và Phần 8 thảo luận về các hạn chế của công trình chúng tôi.

## 2 Công trình Liên quan

Các phương pháp của chúng tôi được lấy cảm hứng từ xử lý ngôn ngữ tự nhiên, do đó các công trình liên quan bao gồm cả NLP thuần túy và xử lý mã nguồn.

**Tập dữ liệu.** Husain et al. (2019) đã trình bày tập dữ liệu CodeSearchNet được xây dựng từ một dump GitHub nơi các tác giả chia các thân phương thức thành chính mã và một mô tả. Tập dữ liệu này chứa 2 triệu cặp đoạn mã-mô tả trong 6 ngôn ngữ lập trình, bao gồm Python. Tập dữ liệu này được sử dụng một phần bởi Hasan et al. (2021) đã kết hợp CodeSearchNet và ba tập dữ liệu khác thành một tập lớn hơn. Từ CodeSearchNet họ đã sử dụng phần Java và phần Python được dịch tự động sang Java. Tập dữ liệu kết quả chứa 4 triệu cặp đoạn mã-mô tả. CodeXGLUE được trình bày bởi Lu et al. (2021b) là một bộ sưu tập benchmark machine learning của các tập dữ liệu cho các nhiệm vụ hiểu và tạo mã, bao gồm một sửa đổi của CodeSearchNet. CodeXGLUE cung cấp một benchmark cho các nhiệm vụ code-to-code, code-to-text, text-to-code khác nhau, bao gồm tìm kiếm mã. Benchmark này bao gồm mã trong 10 ngôn ngữ lập trình. Có hai tập dữ liệu chính cho phát hiện clone: POJ-104 (Mou et al., 2016) và BigCloneBench (Wang et al., 2020). POJ-104 đại diện cho một corpus tương đối nhỏ các giải pháp C++ từ một hệ thống đánh giá sinh viên. BigCloneBench bao gồm một tập dữ liệu rộng lớn chứa dữ liệu được khai thác tự động trong ngôn ngữ Java.

**Tìm kiếm Mã.** Các công trình sớm về tìm kiếm mã chủ yếu dựa vào truy xuất thông tin cổ điển (Bacchelli et al., 2010; Brandt et al., 2010; Campbell and Treude, 2017; Chan et al., 2012). Brandt et al. (2010), Barzilay et al. (2013), và Ponzanelli et al. (2014) đã sử dụng các công cụ tìm kiếm Web công nghiệp hiện có. Gu et al. (2018) đã sử dụng các biểu diễn vector dày đặc hiện đại cho truy xuất thông tin, huấn luyện hai mạng nơ-ron hồi quy để biểu diễn mã nguồn và văn bản tương ứng. Feng et al. (2020) đã trình bày một phương pháp dựa trên mô hình ngôn ngữ để tạo ra các biểu diễn này. Gotmare et al. (2021) đã sử dụng ba mô hình dựa trên Transformer, hai làm encoder và một làm classifier, cho một biểu diễn phân cấp của mã và văn bản; mặc dù họ đã thử nghiệm với việc chia sẻ các tham số encoder, nó đã làm giảm chất lượng cuối cùng của mô hình họ. Mô hình của chúng tôi, ngược lại, sử dụng một phần decoder duy nhất của transformer để embed các truy vấn và tài liệu và bỏ qua phần classifier.

**Phát hiện Clone.** Theo hiểu biết của chúng tôi, nỗ lực phát hiện mã chương trình tương tự đã được thực hiện bởi Baker (Baker, 1993) đã đề xuất tìm mã trùng lặp ở dạng chính xác và được tham số hóa. Phương pháp sau có thể được tái hình thức hóa như làm mờ mã và tìm kiếm một khớp chính xác đã được làm mờ. Krinke (2001) đã đề xuất áp dụng lý thuyết đồ thị, cụ thể là so sánh các đường dẫn ngắn nhất của các cây cú pháp trừu tượng được trích xuất từ các đoạn mã. Công trình sớm về phát hiện clone thuật toán đã được tóm tắt bởi Roy và Cordy (2007). Cuối cùng nhưng không kém, chúng tôi lưu ý một trong những phương pháp thuật toán gần đây nhất SourcererCC (Sajnani et al., 2016), đề xuất một thuật toán tinh vi bao gồm việc xây dựng một chỉ mục tìm kiếm cho các đoạn clone ứng viên. Các phương pháp gần đây thường dựa trên machine learning. Các phương pháp xác suất bao gồm Alomari và Stephan (2018) với phân bổ Dirichlet tiềm ẩn và Thaller et al. (2020) với một mô hình xác suất đồ thị mới dựa trên ước lượng mật độ. Một trong những phương pháp deep learning thành công đầu tiên là CClearner (Li et al., 2017) đã sử dụng văn bản được trích xuất từ một chương trình và các đặc trưng AST của nó và có một kiến trúc perceptron đa lớp đơn giản cho phân loại clone trên một cơ sở mã đóng. Các mô hình deep learning gần đây hơn bao gồm mạng nơ-ron đồ thị trên ASTs (Wang et al., 2020) và sử dụng các mô hình ngôn ngữ được pretrain Villmow et al. (2022).

**Mô hình ngôn ngữ cho mã nguồn.** Sau thành công của các mô hình giống BERT cho ngôn ngữ tự nhiên, các phương pháp này cũng được áp dụng cho các ngôn ngữ lập trình. Một số mô hình ngôn ngữ lập trình được pre-train đã được trình bày gần đây, bao gồm: CodeBERT (Feng et al., 2020), đây là một mô hình pre-train đa modal cho mã nguồn và ngôn ngữ tự nhiên dựa trên kiến trúc RoBERTa Transformer (Liu et al., 2019), được huấn luyện trên các mục tiêu mô hình hóa ngôn ngữ có mặt nạ (MLM) và phát hiện token thay thế; GraphCodeBERT (Guo et al., 2021) sử dụng luồng dữ liệu trong pre-training để giải quyết các nhiệm vụ MLM, dự đoán cạnh, và căn chỉnh nút; SynCoBERT (Wang et al., 2021) sử dụng học tương phản đa modal và được pre-train trên dự đoán định danh và dự đoán cạnh AST. Trong thời gian gần đây, các mô hình decoder tự hồi quy như DeepSeek-Coder (Guo et al., 2024) đã thống trị thế giới. Chúng đại diện cho phần decoder của mô hình transformer, được pre-train trên một corpus mã nguồn khổng lồ. Chúng được sử dụng trong các nhiệm vụ tạo mã nguồn, như hoàn thành mã, tạo tài liệu, v.v.

**NLP Đa ngôn ngữ.** Nhiệm vụ hỏi đáp miền mở giả định trả lời các câu hỏi factoid mà không có miền được định nghĩa trước (Kwiatkowski et al., 2019). Vì chúng tôi đề xuất một benchmark mới trong hiểu mã chéo ngôn ngữ, chúng tôi cũng xem xét các mô hình NLP đa ngôn ngữ, nơi nghiên cứu gần đây đã tập trung vào các tập dữ liệu hỏi đáp (QA) không phải tiếng Anh và học chuyển giao đa ngôn ngữ, thường từ tiếng Anh sang các ngôn ngữ khác. Cho đến gần đây, các tập dữ liệu huấn luyện và đánh giá phù hợp đã khan hiếm, nhưng trong những năm gần đây nhiều công trình đã thu thập dữ liệu được căn chỉnh lỏng lẻo thu được thông qua dịch tự động hoặc bằng cách phân tích các nguồn đa ngôn ngữ tương tự. Do đó, Ahn et al. (2004) đã trình bày một nỗ lực sớm cho hỏi đáp đa ngôn ngữ bằng cách dịch một câu trả lời sang ngôn ngữ đích. Hai năm sau, Bos và Nissim (2006) đã trình bày một hệ thống tương tự khác sử dụng dịch thuật. Lee và Lee (Lee và Lee, 2019) đã chỉ ra việc chuyển giao thành công cho QA đa ngôn ngữ với huấn luyện trên dữ liệu tiếng Anh và đánh giá bằng tiếng Trung. Ferrández et al. (2007) đã trình bày một công trình về hệ thống kết hợp cơ sở tri thức đa ngôn ngữ. Mitamura et al. (2006) đã phát triển một hệ thống với việc dịch các từ khóa được trích xuất từ câu hỏi để có được một câu trả lời trong ngôn ngữ đích. Artetxe et al. (2020) đã nghiên cứu việc chuyển giao đa ngôn ngữ của các biểu diễn đơn ngôn ngữ cho một mô hình ngôn ngữ có mặt nạ dựa trên Transformer. M'hamdi et al. (2021) đã kiểm tra một phương pháp meta-learning dựa trên tối ưu hóa đa ngôn ngữ để học thích ứng với các ngôn ngữ mới cho QA. Gao và Callan (2021) đã đề xuất pretraining không giám sát cho truy xuất đoạn văn dày đặc, mặc dù các tác giả tập trung vào chính việc truy xuất và bỏ qua bản chất đa ngôn ngữ của dữ liệu. Hầu hết các phương pháp sử dụng các mô hình extractive, chủ yếu do sự phổ biến của các tập dữ liệu nơi, tương tự như SQuAD (Rajpurkar et al., 2016), dữ liệu được gán nhãn bao gồm một câu hỏi được nêu rõ ràng, một đoạn văn chứa câu trả lời, và một nhãn span cho câu trả lời. Tuy nhiên, một số công trình đã xem xét QA tạo sinh: Kumar et al. (2019) và Chi et al. (2019) đã nghiên cứu tạo câu hỏi đa ngôn ngữ, Riabi et al. (2020) đã đề xuất một phương pháp để tạo ra các câu hỏi tổng hợp theo cách đa ngôn ngữ bằng cách sử dụng MiniLM đa ngôn ngữ, và Shakeri et al. (2020) đã đề xuất một phương pháp để tạo ra các cặp câu hỏi-câu trả lời đa ngôn ngữ bằng một mô hình tạo sinh (T5 đa ngôn ngữ được fine-tune) dựa trên các mẫu được dịch tự động từ tiếng Anh sang ngôn ngữ đích. QA tạo sinh chủ yếu được xem xét cho các tập dữ liệu với câu trả lời dài, nhưng mô hình tạo sinh FiD (Izacard và Grave, 2021) đã đạt được kết quả cạnh tranh trên các tập dữ liệu giống SQuAD, nơi một câu trả lời được cho là một span văn bản ngắn. Đối với QA miền mở, Lewis et al. (2021) đã sử dụng các mô hình tạo sinh trong phương pháp RAG của họ xử lý k đoạn văn hàng đầu từ bộ truy xuất trong encoder đồng thời và sử dụng các biểu diễn của chúng trong decoder để tạo câu trả lời, trong một quá trình được gọi là fusion. Xử lý các đoạn văn độc lập trong encoder cho phép một mô hình mở rộng quy mô cho nhiều ngữ cảnh, vì nó chỉ chạy self-attention trên một ngữ cảnh tại một thời điểm. Mô hình FiD theo paradigm này, cải thiện thêm kết quả trong tạo câu hỏi. Đối với QA trên một đồ thị tri thức, Zhou et al. (2021) đã nghiên cứu việc quy nạp từ vựng song ngữ không giám sát cho chuyển giao đa ngôn ngữ zero-shot cho QA đa ngôn ngữ để ánh xạ các câu hỏi huấn luyện trong ngôn ngữ nguồn thành các câu hỏi trong ngôn ngữ đích để sử dụng làm dữ liệu huấn luyện được tăng cường, điều này quan trọng cho các ngôn ngữ không có tài nguyên.

## 3 Tập dữ liệu

Trong công trình này chúng tôi sử dụng hai loại tập dữ liệu, một cho phát hiện clone và một khác cho tìm kiếm mã.

**Tìm kiếm Mã.** Cho tìm kiếm mã chúng tôi sử dụng tập dữ liệu CodeSearchNet được giới thiệu bởi Husain et al. (2019). Phiên bản gốc của CodeSearchNet bao gồm các truy vấn ngôn ngữ tự nhiên được ghép cặp với các đoạn mã có liên quan nhất trong sáu ngôn ngữ lập trình. Mỗi đoạn đại diện cho mã của một hàm được thu thập từ mã nguồn mở GitHub.

CodeSearchNet AdvTest là một tập dữ liệu chỉ Python được xây dựng từ corpus CodeSearchNet bởi Lu et al. (2021b). Mỗi ví dụ, một lần nữa, bao gồm một hàm được ghép cặp với một tài liệu văn bản, và tương tự như Husain et al. (2019), AdvTest lấy đoạn đầu tiên của tài liệu làm truy vấn. Lu et al. (2021b) đưa ra một quan sát thú vị: sau khi chuẩn hóa tên hàm và biến với các token đặc biệt, điểm số Mean Reciprocal Rank (MRR) của các mô hình RoBERTa (Liu et al., 2019) và CodeBERT (Feng et al., 2020) cho tìm kiếm mã trên tập dữ liệu CodeSearchNet gốc giảm từ 0.809 xuống 0.419 và từ 0.869 xuống 0.507 tương ứng (trong Python). Vì vậy, để cải thiện chất lượng của tập dữ liệu và làm cho nó khó hơn, đầu tiên họ đã lọc dữ liệu bằng cách loại bỏ các ví dụ mà mã không thể được phân tích thành một cây cú pháp trừu tượng, tài liệu ngắn hơn 3 hoặc dài hơn 256 token, tài liệu chứa các token đặc biệt như "http://", hoặc tài liệu trống hoặc không được viết bằng tiếng Anh. Tập dữ liệu được lọc chứa 251 820 / 9 604 / 19 210 ví dụ trong các tập huấn luyện/validation/test tương ứng.

Sau đó, để kiểm tra tốt hơn khả năng hiểu và tổng quát hóa của mô hình, Lu et al. (2021b) đã chuẩn hóa tên hàm và biến trong các tập testing và development thành các token không mô tả như func cho tên hàm và argi cho tên biến thứ i. Nhiệm vụ vẫn là tìm kiếm mã nguồn dựa trên một truy vấn ngôn ngữ tự nhiên. Hơn nữa, trái ngược với giai đoạn testing của các công trình trước (Husain et al., 2019; Feng et al., 2020) chỉ liên quan đến 1 000 ứng viên, Lu et al. (2021b) đã sử dụng toàn bộ tập test cho mỗi truy vấn, điều này làm cho tập dữ liệu AdvTest thậm chí còn khó hơn. Tập huấn luyện đến từ tập dữ liệu CodeSearchNet được lọc (Husain et al., 2019) nơi mã được biểu diễn ở dạng thô ngoài việc tokenization bản địa cho ngôn ngữ lập trình của nó. AdvTest sử dụng MRR làm metric đánh giá cơ bản, được định nghĩa là MRR@Q = 1/Q * ΣQ i=1 1/ranki, trong đó Q là số lượng truy vấn và rank là vị trí của tài liệu câu trả lời ground truth trong số các ứng viên được xếp hạng.

**Phát hiện Clone.** Trong nhiệm vụ phát hiện clone, vấn đề là truy xuất các mã tương đồng về mặt ngữ nghĩa cho trước một mã làm truy vấn. Để huấn luyện và kiểm tra các mô hình cho phát hiện clone, chúng tôi sử dụng tập dữ liệu POJ-104 được giới thiệu bởi Mou et al. (2016). Nó đến từ một hệ thống đánh giá mở giáo dục lập trình (OJ) tự động đánh giá tính hợp lệ của mã nguồn được gửi cho các vấn đề cụ thể bằng cách chạy mã. Tập dữ liệu POJ-104 bao gồm 104 vấn đề và bao gồm 500 chương trình C/C++ được viết bởi sinh viên cho mỗi vấn đề. Phát hiện clone ở đây là, cho trước mã nguồn của một chương trình, để truy xuất các chương trình khác giải quyết cùng vấn đề. Các vấn đề được nhóm thành ba tập với 64/16/24 vấn đề cho huấn luyện, validation, và testing tương ứng. Metric mặc định cho tập dữ liệu POJ-104 là Mean Average Precision (MAP), trong đó average precision (AP) được định nghĩa là AP = Σ100 i=1 (Ri - Ri-1) · Pi, trong đó Ri và Pi là precision và recall tại ngưỡng i, tức là, được tính có tính đến chỉ các mục top i từ danh sách ứng viên. MAP là AP trung bình trên tất cả các truy vấn. Quan trọng là phải đề cập rằng đối với POJ-104 i tối đa có thể là 499 vì chỉ có 500 ứng viên tổng cộng.

### 3.1 Tập dữ liệu XCD

Trong các công trình trước, khả năng đa ngôn ngữ của các mô hình ngôn ngữ mã không được điều tra đầy đủ. Để lấp đầy khoảng trống này, chúng tôi giới thiệu một tập dữ liệu phát hiện clone/truy xuất mã đa ngôn ngữ mới XCD. Tập dữ liệu được đánh giá trong hai thiết lập khác nhau: phương pháp phát hiện clone tương tự như tập dữ liệu BUCC (Xu et al., 2018), phát hiện clone kiểu truy xuất tương tự như POJ-104 (Mou et al., 2016), và một phương pháp lai. Chúng tôi sử dụng dump submission CodeForces làm nguồn dữ liệu, chọn ngẫu nhiên 110 vấn đề và 100 giải pháp được chấp nhận trong một ngôn ngữ cho mỗi vấn đề. Chúng tôi đã chọn 5 ngôn ngữ, cụ thể là Python, Java, C#, C++, C, nhận được 55 000 đoạn mã tổng cộng.

**Thiết lập đánh giá so sánh đầy đủ.** Ở đây nhiệm vụ được hiểu như phân loại nhị phân, tương tự như Xu et al. (2018). Chúng tôi đánh giá một mô hình trên mỗi cặp từ tập test, điều này dẫn đến n² so sánh. Mỗi cặp có thể là tích cực, nếu cặp bao gồm các giải pháp cho cùng vấn đề, hoặc tiêu cực ngược lại. Chúng tôi sử dụng measure F1 cổ điển cho đánh giá trong thiết lập này: F1 = 2·Precision·Recall / (Precision+Recall).

**Thiết lập đánh giá kiểu truy xuất.** Đối với đánh giá kiểu truy xuất, chúng tôi theo thiết kế của POJ-104. Nhiệm vụ nhằm truy xuất 100 đoạn trên mỗi ngôn ngữ giải quyết cùng vấn đề từ tập test. Chúng tôi đánh giá xếp hạng trên 11 000 đoạn tích cực, tức là, mô hình nên xếp hạng 11 000 tài liệu, đưa lên trên cùng các đoạn giải quyết cùng vấn đề. Tương tự như Mou et al. (2016), chúng tôi sử dụng mean average precision trên top 100 kết quả (MAP@100) cho đánh giá.

**Thiết lập đánh giá lai.** Chúng tôi cũng đề xuất một thiết lập nơi chúng tôi đánh giá các mô hình không chỉ trên các đoạn tích cực mà trên tất cả các đoạn trong cùng ngôn ngữ. Nhiệm vụ này khó hơn và tương tự hơn với AdvTest. Như metric chúng tôi đã chọn MRR@R, theo Lu et al. (2021b).

**Đánh giá chéo ngôn ngữ.** Ngoài thiết lập đa ngôn ngữ, tức là, đánh giá trong tập các giải pháp trong một ngôn ngữ duy nhất, chúng tôi định nghĩa một thiết lập chéo ngôn ngữ phức tạp hơn được thiết kế để đo lường hiểu mã chéo ngôn ngữ. Để đạt được điều này, chúng tôi mở rộng ba thiết lập cho tất cả các ngôn ngữ cùng một lúc, mở rộng các tập của cả đoạn có liên quan và không liên quan cho tất cả các ngôn ngữ lập trình.

### 3.2 Gán nhãn Bổ sung

Ngoài trạng thái giải pháp ("Accepted" hay không), chúng tôi cũng đã khai thác các trạng thái lỗi cho các giải pháp vì các nền tảng được sử dụng cho giải quyết vấn đề thường cung cấp chúng. Tổng cộng, chúng tôi đã khai thác hơn 97 triệu đoạn mã trong hơn 10 ngôn ngữ lập trình. Nền tảng CodeForces có thể trả về 15 loại verdict cho một giải pháp được gửi. Chúng tôi chia các verdict thành 4 nhóm: Defect (mã có khuyết tật), Skip (mã không thể được đánh giá), Accepted (không phát hiện khuyết tật), và Wrong (mã thất bại một số test hoặc ràng buộc). Dưới đây chúng tôi mô tả và phân loại một số verdict phổ biến nhất: (1) Memory limit exceeded: chương trình cố gắng tiêu thụ nhiều bộ nhớ hơn được phép (Wrong); (2) Time limit exceeded: chương trình không chấm dứt trong thời gian được phân bổ (Wrong); (3) Runtime error: chương trình chấm dứt với mã trả về khác không (ví dụ, do chia cho không, stack overflow, v.v.) (Defect); (4) Wrong answer on some tests (Wrong); (5) Idleness limit exceeded: chương trình không sử dụng CPU trong một thời gian đáng kể (Defect); (6) Denial of judgement: giải pháp không thể chạy được do lỗi đánh giá hoặc lỗi trong chương trình, ví dụ, sử dụng các mảng cực lớn (Defect); (7) Rejected: chương trình không vượt qua test vì lý do không rõ ràng (Skip); (8) Accepted: chương trình vượt qua tất cả test.

## 4 Phương pháp

Trong phần này, chúng tôi giới thiệu phương pháp pre-training CCT (Cross-Consistency Training) của chúng tôi. Mục tiêu của nó là học mạnh mẽ không gian embedding của các đoạn mã và tạo ra một sự căn chỉnh mạnh mẽ giữa các đoạn giải quyết cùng vấn đề trên các ngôn ngữ lập trình. Sự khác biệt giữa căn chỉnh mạnh và yếu được minh họa trong Hình 1: trong một không gian embedding được căn chỉnh yếu, láng giềng gần nhất có thể là một đoạn tương đồng về mặt ngữ nghĩa từ một ngôn ngữ khác nhưng nói chung hầu hết láng giềng ở cùng ngôn ngữ, trong khi trong một không gian được căn chỉnh mạnh mẽ sự tương đồng hoàn toàn là ngữ nghĩa và không quan tâm đến ngôn ngữ chút nào.

Để đạt được căn chỉnh mạnh mẽ, chúng tôi sử dụng một mục tiêu học tương phản LXCD: đối với một đoạn mã ngẫu nhiên, chúng tôi huấn luyện các biểu diễn vector của các token mã nguồn theo cách mà sự tổng hợp của chúng, ví dụ, trung bình hoặc token cuối cùng, gần hơn với mã nguồn, giải quyết cùng vấn đề bất kể ngôn ngữ lập trình. Điều này đảm bảo rằng các embedding của mã nguồn phân biệt hiệu quả giữa các đoạn có liên quan và các đoạn ngẫu nhiên hoặc tương tự nhưng khác (hard negative).

**Ước lượng tương phản nhiễu và loss.** Để học một không gian biểu diễn chéo ngôn ngữ bất khả tri ngôn ngữ, chúng tôi đề xuất một quy trình huấn luyện dựa trên ước lượng tương phản nhiễu (NCE). Cho X và Z là một số tập hữu hạn và sθ: X × Z → R là một hàm điểm tương quan có thể vi phân trong θ ∈ Rd. Mục tiêu là học θ sao cho classifier x ↦ arg maxz∈Z sθ(x,z) có loss kỳ vọng tối ưu. Điều này dẫn đến ước lượng mật độ có điều kiện: cho mỗi x ∈ X

pθ(z|x) = esθ(x,z) / Σz'∈Z esθ(x,z')    (1)

với θ* = arg minθ Ex,z[-log pθ(z|x)] là tối ưu. Trong thực tế, việc tối ưu hóa mục tiêu này trực tiếp là không khả thi: nếu Z lớn thì số hạng chuẩn hóa trong (1) là không thể xử lý được. Do đó, NCE sử dụng lấy mẫu phụ, vì vậy (1) trở thành

πθ(z|x) = esθ(x,z) / (Σz'∈Bx,z esθ(x,z') + esθ(x,z))    (2)

trong đó Bx,z = {z1-, z2-, ..., zn-} là một tập các negative được lấy mẫu từ Z không khớp với câu trả lời tích cực z+ cho x này. NCE cũng thường sử dụng các mục tiêu tương tự như (2) nhưng với πθ(ẑ|z) trong đó z và ẑ đến từ cùng không gian, và mục tiêu tương ứng với một số hàm tương đồng.

**Mục tiêu chéo ngôn ngữ.** Học tương phản thường sử dụng các nhiệm vụ pretext để học các biểu diễn dữ liệu mà không cần các ví dụ được gán nhãn. Trong bối cảnh học từ một tập tài liệu đa ngôn ngữ, một nhiệm vụ pretext có thể sẽ là huấn luyện một mạng để phân biệt giữa các tài liệu có nội dung tương tự nhưng được viết bằng các ngôn ngữ khác nhau (cặp tích cực) và những tài liệu có nội dung khác nhau (cặp tiêu cực). Điều này dẫn đến hàm loss. Huấn luyện với nhiệm vụ này dẫn đến việc học một không gian biểu diễn với các thuộc tính căn chỉnh mạnh mẽ, nhưng khả năng IR của các biểu diễn là tầm thường.

LXCD(θ) = E(ẑ,z)∼WXCD[-log πθ(ẑ|z)]    (3)

trong đó WXCD là một phân phối trên tập các cặp submission trong các ngôn ngữ lập trình khác nhau từ tập dữ liệu XCD (Phần 3) cho biết liệu các submission đang giải quyết cùng vấn đề hay không.

**Khai thác hard negative.** Các công trình trước về học tương phản cho thấy tầm quan trọng của việc huấn luyện trên các mẫu negative khó (Qu et al., 2021; Izacard và Grave, 2020). Họ đã sử dụng huấn luyện lặp để có được hard negative, nhưng dữ liệu của chúng tôi đã chứa các ví dụ negative mạnh mẽ như các giải pháp sơ bộ từ cùng người dùng giải quyết cùng vấn đề nhưng thất bại một số test (đó là lý do tại sao một người dùng sẽ gửi một giải pháp cập nhật để có được verdict "Accepted"). Do đó, chúng tôi khai thác các ví dụ hard negative như các giải pháp thất bại từ cùng người dùng; nếu không có chúng tôi sử dụng các giải pháp thất bại từ người dùng ngẫu nhiên, và chỉ nếu không có (ví dụ, cho một vấn đề không phổ biến) chúng tôi sử dụng một submission ngẫu nhiên cho một vấn đề ngẫu nhiên.

## 5 Thí nghiệm

Trong phần này, chúng tôi mô tả các chi tiết về pre-training dữ liệu và pipeline CCT của chúng tôi cho các nhiệm vụ phát hiện clone đa ngôn ngữ và tìm kiếm mã.

**Pretraining.** Chúng tôi huấn luyện hai mô hình, một là dựa trên encoder, được khởi tạo với mô hình GraphCodeBERTbase được pretrain (Guo et al., 2021); chúng tôi gọi mô hình kết quả là CCT-LM enc. Một mô hình khác là dựa trên decoder, được khởi tạo với mô hình DeepSeek-Coder-1.3B được pretrain (Guo et al., 2024); chúng tôi gọi mô hình kết quả là CCT-LM dec. Điểm tương đồng được tính toán dựa trên tích vô hướng của các biểu diễn vector token cuối cùng, nhưng chúng tôi cũng đã nghiên cứu sử dụng các loại pooling khác nhau và cho phép attention hai chiều.

**Siêu tham số.** Chúng tôi sử dụng optimizer AdamW với learning rate 5e-5, weight decay 0.01, và suy giảm learning rate tuyến tính. Chúng tôi sử dụng tích lũy gradient cho pretraining với kích thước batch hiệu quả là 2000.

**Kết quả Đơn ngôn ngữ.** Bảng 1 trình bày kết quả của các mô hình CCT-LM so với các phương pháp hiện có, cho thấy rằng CCT-LM vượt trội hơn tất cả các mô hình trước đó với một biên độ lớn trong thiết lập đơn ngôn ngữ này. Do đó, sự căn chỉnh mạnh mẽ được thực thi bởi pretraining CCT không chỉ hữu ích cho chuyển giao đa ngôn ngữ mà còn cải thiện cấu trúc không gian tiềm ẩn nói chung. Quan trọng là phải đề cập, rằng pretraining CCT hoạt động cho cả mô hình dựa trên encoder và decoder, cải thiện kết quả.

### 5.1 Đánh giá Đa ngôn ngữ và Chéo ngôn ngữ

Đối với các loại đánh giá này trên XCD chúng tôi sử dụng một số thiết lập được mô tả trong Phần 3.1. Vì các thiết lập này tốn kém về mặt tính toán, chúng tôi chỉ làm việc với các mô hình dựa trên encoder.

**Kết quả Đa ngôn ngữ.** Kết quả trong thiết lập đa ngôn ngữ trên tập dữ liệu XCD được đề xuất được hiển thị trong nửa trên của Bảng 2. Trong thiết lập so sánh đầy đủ, thú vị là việc chuyển giao tri thức từ tập dữ liệu POJ-104 cũng không giúp ích, và các metric vẫn rất thấp. Tuy nhiên, CCT-LM cho thấy kết quả tốt hơn nhiều, rõ ràng do thiết kế đa ngôn ngữ của pretraining CCT. Chúng tôi không đánh giá BM25 trong thiết lập này vì nó không được cho là so sánh hai tài liệu.

Đối với đánh giá kiểu truy xuất, kết quả cũng cho thấy CCT-LM enc vượt trội mạnh mẽ hơn tất cả baseline và thực sự cung cấp một giải pháp khả thi cho vấn đề trong khi GraphCodeBERT không mang lại kết quả hợp lý trong bất kỳ ngôn ngữ lập trình nào.

Kết quả cho thiết lập đánh giá lai cho thấy cùng bức tranh: BM25 vẫn không hoạt động, các mô hình ngôn ngữ mã có thể chuyển giao tri thức trên các giải pháp khác nhau ở một mức độ nào đó, và sự cải thiện trong các metric ở đây giữa một phương pháp hoàn toàn không giám sát và huấn luyện trên phát hiện clone POJ-104 là đáng chú ý lớn hơn. Tuy nhiên, CCT-LM enc vượt xa mọi phương pháp khác ở đây và nói chung thiết lập một baseline mới cho các nhiệm vụ liên quan đến mã đa ngôn ngữ.

**Kết quả Chéo ngôn ngữ.** Kết quả của chúng tôi trong thiết lập này được trình bày trong nửa dưới của Bảng 2. Tất cả kết luận được rút ra cho trường hợp đa ngôn ngữ (ở trên) áp dụng ở đây cũng vậy, nhưng so với thiết lập đa ngôn ngữ, các nhiệm vụ chéo ngôn ngữ khó hơn đáng kể và tất cả các giá trị đều thấp hơn. Chúng tôi đề xuất rằng sự khác biệt trong kết quả trên các ngôn ngữ lập trình có thể được gây ra bởi sự mất cân bằng trong tập dữ liệu pretraining.

## 6 Phân tích

**Kết quả Zero-shot.** Chúng tôi đã điều tra chuyển giao zero-shot từ Python sang Java, Ruby, PHP, Go, và JavaScript trên tập dữ liệu CodeSearchNet cho các mô hình ngôn ngữ mã được giới thiệu trước đó và CCT-LM của chúng tôi. Kết quả zero-shot được trình bày trong Bảng 3. Như bằng chứng cho sức mạnh của các mô hình ngôn ngữ được pretrain, chúng tôi thấy rằng các phương pháp hiện có cho thấy kết quả khá tốt mặc dù chúng không được huấn luyện trên nhiệm vụ truy xuất. Bằng cách tận dụng khả năng đa ngôn ngữ của nó, CCT-LM cải thiện hơn các baseline trong thiết lập zero-shot cho tất cả các ngôn ngữ trừ JavaScript (JS).

**Cấu trúc không gian tiềm ẩn.** Hình 1 đã cho thấy một biểu diễn trừu tượng của ý tưởng CCT cơ bản về không gian embedding bất khả tri ngôn ngữ được căn chỉnh về mặt ngữ nghĩa. Hình 2 biến lý thuyết này thành thực hành với các phép chiếu của embeddings thực tế cho các đoạn mã mẫu trước và sau huấn luyện CCT. Các đoạn đại diện cho các giải pháp cho 12 nhiệm vụ mẫu trong sáu ngôn ngữ lập trình. Chúng tôi thấy rằng sau CCT, các biểu diễn của các đoạn mã không được căn chỉnh theo ngôn ngữ mà thay vào đó theo vấn đề (Hình 2b), trong khi sự căn chỉnh của chúng đã phụ thuộc vào ngôn ngữ trước CCT (Hình 2a).

Điều này minh họa rằng huấn luyện CCT cải thiện đáng kể không gian tiềm ẩn đa ngôn ngữ cho các đoạn mã, làm cho nó trở nên ngữ nghĩa và bất khả tri ngôn ngữ.

**Nghiên cứu Ablation.** Trong phần này, chúng tôi nghiên cứu tác động của các phần khác nhau của CCT. Bảng 5 cho thấy kết quả của một số mô hình dựa trên DeepSeek-Coder trên các nhiệm vụ phát hiện clone, tìm kiếm mã. Chúng tôi so sánh mô hình cơ sở DeepSeek-Coder với các pooling pretraining và loại attention khác nhau.

## 7 Kết luận

Hiểu sự tương đồng ngữ nghĩa là một khía cạnh quan trọng của xử lý ngôn ngữ mở ra những cách để giải quyết nhiều nhiệm vụ khác nhau, cho cả ngôn ngữ tự nhiên và lập trình. Trong công trình này, chúng tôi đã trình bày một phương pháp mới CCT-LM cải thiện khả năng này thông qua một phương pháp pretraining CCT mới và chứng minh tính khả thi của nó cho cả phát hiện clone và tìm kiếm mã. Chúng tôi đã hình thức hóa một nhiệm vụ mới về phát hiện clone đa ngôn ngữ và trình bày tập dữ liệu XCD cho phân tích mã nguồn đa ngôn ngữ, được hình thức hóa trong hai thiết lập đánh giá. Các mô hình CCT-LM được đề xuất (cả dựa trên encoder và decoder) đã vượt trội hơn các baseline mạnh mẽ trong nhiệm vụ phát hiện clone và tìm kiếm mã. CCT-LM enc vượt trội hơn các mô hình khác trong tất cả các thiết lập cho đánh giá đa ngôn ngữ và chéo ngôn ngữ, chứng minh rằng pretraining CCT cung cấp hiểu biết tương đồng ngữ nghĩa tốt hơn cho một mô hình ngôn ngữ. Chúng tôi hy vọng rằng phương pháp của chúng tôi sẽ hữu ích trong các nhiệm vụ xử lý mã nguồn khác mà chúng tôi đã để lại như công việc tương lai. Hơn nữa, chúng tôi tin rằng các sửa đổi của phương pháp chúng tôi có thể hữu ích cho NLP và có lẽ các lĩnh vực khác của machine learning.

## 8 Hạn chế

Chúng tôi đã nghiên cứu một số ngôn ngữ lập trình, bao gồm Python và Java, trong thiết lập XCD của chúng tôi; mặc dù tất cả các phương pháp của chúng tôi dường như bất khả tri ngôn ngữ, một nghiên cứu sâu hơn cho các ngôn ngữ khác sẽ thú vị, đặc biệt vì tất cả các ngôn ngữ được xem xét đều được thông dịch thay vì biên dịch (như C/C++). Nhiều đầu vào vượt quá 512 token; chúng tôi đã sử dụng truncation tiêu chuẩn cho đánh giá (chỉ xem xét phần đầu của mã), điều này có thể không tối ưu, và các biểu diễn đầu vào phù hợp hơn có thể được tìm thấy. Chúng tôi mong đợi mô hình của chúng tôi cải thiện với việc huấn luyện trên các tài liệu dài. Chúng tôi cũng cho rằng mô hình sẽ hưởng lợi từ việc tăng kích thước batch bằng cách sử dụng phần cứng mạnh mẽ hơn với nhiều bộ nhớ hơn. Cũng lưu ý rằng trong khi CCT-LM đã cải thiện đáng kể state of the art trong phát hiện clone và tìm kiếm mã.

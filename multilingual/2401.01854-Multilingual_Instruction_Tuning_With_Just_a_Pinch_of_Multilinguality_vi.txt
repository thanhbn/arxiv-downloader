# Điều chỉnh hướng dẫn đa ngôn ngữ chỉ với một chút đa ngôn ngữ

Uri ShahamτγJonathan HerzigγRoee Aharoniγ
Idan SzpektorγReut TsarfatyγMatan Eyalγ
τĐại học Tel Aviv
γGoogle Research

## Tóm tắt

Khi các mô hình ngôn ngữ lớn (LLMs) được điều chỉnh theo hướng dẫn ngày càng được áp dụng toàn cầu, khả năng tuân theo hướng dẫn bằng nhiều ngôn ngữ của chúng trở nên ngày càng quan trọng. Trong nghiên cứu này, chúng tôi điều tra cách tính đa ngôn ngữ trong quá trình điều chỉnh hướng dẫn của một LLM đa ngôn ngữ ảnh hưởng đến việc tuân theo hướng dẫn trên các ngôn ngữ từ kho dữ liệu huấn luyện trước. Trước tiên, chúng tôi chỉ ra rằng nhiều ngôn ngữ chuyển giao một số khả năng tuân theo hướng dẫn sang các ngôn ngữ khác ngay cả từ việc điều chỉnh đơn ngôn ngữ. Hơn nữa, chúng tôi phát hiện rằng chỉ 40 ví dụ đa ngôn ngữ được tích hợp trong bộ điều chỉnh tiếng Anh cải thiện đáng kể việc tuân theo hướng dẫn đa ngôn ngữ, cả trong các ngôn ngữ đã thấy và chưa thấy trong quá trình điều chỉnh. Nói chung, chúng tôi quan sát thấy rằng các mô hình được điều chỉnh trên hỗn hợp đa ngôn ngữ thể hiện hiệu suất tương đương hoặc vượt trội trong nhiều ngôn ngữ so với các mô hình được điều chỉnh đơn ngôn ngữ, mặc dù huấn luyện ít hơn 10 lần số ví dụ trong những ngôn ngữ đó. Cuối cùng, chúng tôi phát hiện rằng việc đa dạng hóa bộ điều chỉnh hướng dẫn với chỉ 2-4 ngôn ngữ cải thiện đáng kể khả năng khái quát hóa đa ngôn ngữ. Kết quả của chúng tôi cho thấy rằng việc xây dựng các mô hình điều chỉnh hướng dẫn đa ngôn ngữ quy mô lớn có thể được thực hiện chỉ với một bộ rất nhỏ các cặp hướng dẫn-phản hồi đa ngôn ngữ.

## 1 Giới thiệu

Điều chỉnh hướng dẫn là một khía cạnh cơ bản trong việc xây dựng các mô hình ngôn ngữ lớn (LLMs) đa mục đích hiện đại, bao gồm việc tinh chỉnh một mô hình đã được huấn luyện trước trên các cặp hướng dẫn và phản hồi tương ứng (Mishra et al., 2022; Wei et al., 2022; Sanh et al., 2022; Ouyang et al., 2022). Để các mô hình này có thể áp dụng toàn cầu, chúng phải hoạt động trên nhiều ngôn ngữ, tuy nhiên, hầu hết các bộ dữ liệu điều chỉnh hướng dẫn thường chỉ giới hạn ở tiếng Anh. Trong khi việc tuyển chọn các hướng dẫn và phản hồi xảy ra tự nhiên cho mọi ngôn ngữ là thách thức, chuyển giao đa ngôn ngữ đã nổi lên như một phương pháp tiếp cận đầy hứa hẹn, trong đó một mô hình được tinh chỉnh bằng một ngôn ngữ và thu được các khả năng tương tự trong ngôn ngữ khác (Pires et al., 2019; Wu and Dredze, 2019; Artetxe and Schwenk, 2019; K et al., 2020; Conneau et al., 2020a,b). Khả năng tuân theo hướng dẫn cho các ngôn ngữ chỉ được thấy trong quá trình huấn luyện trước có thể mở rộng đáng kể tính ứng dụng của LLMs, cho phép chúng được sử dụng bởi nhiều người trên toàn thế giới. Trong nghiên cứu này, chúng tôi chỉ ra rằng việc điều chỉnh hướng dẫn của LLMs đa ngôn ngữ chuyển giao tốt hơn giữa các ngôn ngữ so với những gì đã biết trước đây, và rằng ngay cả sự đa dạng ngôn ngữ tối thiểu trong bộ điều chỉnh có thể mở khóa thêm khả năng khái quát hóa tuân theo hướng dẫn sang các ngôn ngữ chưa thấy trong quá trình điều chỉnh hướng dẫn.

Chúng tôi điều tra tác động của dữ liệu đa ngôn ngữ đối với việc tuân theo hướng dẫn trên các ngôn ngữ bằng cách sử dụng một LLM được huấn luyện trước trên hàng trăm ngôn ngữ (Anil et al., 2023), và các hướng dẫn và phản hồi mở chất lượng cao (Zhou et al., 2023; Köpf et al., 2023) được dịch sang 11 ngôn ngữ, trên các họ ngôn ngữ và hệ thống chữ viết khác nhau. Ban đầu, chúng tôi kiểm tra khả năng chuyển giao của việc điều chỉnh hướng dẫn đơn ngôn ngữ trên các ngôn ngữ khác nhau. Tự nhiên, việc điều chỉnh bằng từng ngôn ngữ riêng lẻ nâng cao hiệu suất trong ngôn ngữ đó. Đáng chú ý, chúng tôi phát hiện rằng điều này cũng chuyển thành khả năng tuân theo hướng dẫn trên các ngôn ngữ khác, và việc điều chỉnh với tiếng Anh, tiếng Ý, hoặc tiếng Tây Ban Nha cho hiệu suất đa ngôn ngữ trung bình tốt nhất.

Được truyền cảm hứng từ kết quả này, chúng tôi chuyển sang hỏi cần bao nhiều dữ liệu đa ngôn ngữ để cải thiện việc tuân theo hướng dẫn đa ngôn ngữ, trong khi vẫn duy trì hiệu suất tiếng Anh. Chúng tôi phát hiện rằng việc thay thế chỉ 40 ví dụ huấn luyện tiếng Anh bằng các ví dụ đa ngôn ngữ, cải thiện đáng kể việc tuân theo hướng dẫn trong những ngôn ngữ đó. Đáng ngạc nhiên, lượng nhỏ các ví dụ đa dạng ngôn ngữ này cũng cải thiện hiệu suất cho các ngôn ngữ chỉ được thấy trong quá trình huấn luyện trước và không được đại diện trong bộ điều chỉnh hướng dẫn.

Câu hỏi tiếp theo chúng tôi giải quyết là liệu việc tăng số lượng ngôn ngữ trong bộ điều chỉnh có thể nâng cao khả năng khái quát hóa sang các ngôn ngữ mới từ kho dữ liệu huấn luyện trước hay không. Chúng tôi phát hiện rằng việc điều chỉnh bằng một vài ngôn ngữ cho phép hiệu suất tốt hơn cho các ngôn ngữ chưa thấy trong quá trình điều chỉnh, so với điều chỉnh đơn ngôn ngữ với cùng số lượng ví dụ.

Cuối cùng, chúng tôi kiểm tra hai yếu tố tiềm năng có thể ảnh hưởng đến mức độ chuyển giao đa ngôn ngữ: sự tương tự ngôn ngữ và lượng dữ liệu huấn luyện trước đặc thù ngôn ngữ, nhưng không tìm thấy mối tương quan đáng kể. Nhìn chung, kết quả của chúng tôi cung cấp các công thức cho việc điều chỉnh hướng dẫn đa ngôn ngữ giúp cải thiện khả năng khái quát hóa đa ngôn ngữ, trong khi vẫn duy trì hiệu suất tiếng Anh, dưới ngân sách cố định. Đặc biệt, chúng tôi phát hiện rằng các mô hình tuân theo hướng dẫn đa ngôn ngữ có khả năng có thể được điều chỉnh ngay cả với lượng dữ liệu đa ngôn ngữ tối thiểu.

## 2 Đo lường việc tuân theo hướng dẫn đa ngôn ngữ

Mục tiêu của chúng tôi là khám phá cách tính đa ngôn ngữ trong quá trình điều chỉnh hướng dẫn ảnh hưởng đến việc tuân theo hướng dẫn đa mục đích trên các ngôn ngữ. Chúng tôi chia nhỏ thành nhiều câu hỏi, bao gồm việc điều chỉnh hướng dẫn đơn ngôn ngữ có thể chuyển giao sang các ngôn ngữ khác tốt như thế nào, bao nhiêu ví dụ đa ngôn ngữ có thể nâng cao việc tuân theo hướng dẫn đa ngôn ngữ trong khi vẫn duy trì hiệu suất tiếng Anh, và liệu việc tăng số lượng ngôn ngữ có thể dẫn đến khả năng khái quát hóa đa ngôn ngữ được cải thiện hay không. Trong phần này, chúng tôi mô tả chi tiết về dữ liệu, giao thức đánh giá, các mô hình chúng tôi sử dụng, và quy trình chú thích của con người để đảm bảo chất lượng mô hình.

**Dữ liệu** Chúng tôi sử dụng các bộ dữ liệu chứa các hướng dẫn và phản hồi mở chất lượng cao, thay vì các bộ dữ liệu đặc thù nhiệm vụ truyền thống. Dữ liệu huấn luyện của chúng tôi chứa 1.000 hướng dẫn và phản hồi tiếng Anh từ LIMA (Zhou et al., 2023) và 3.640 từ OpenAssistant (Köpf et al., 2023). Những ví dụ này giống với các kịch bản thực tế của người dùng tương tác với chatbot, với các truy vấn như "Bạn có thể giải thích Định lý cuối cùng của Fermat không?" và "Làm thế nào để giữ cho chó được cung cấp nước?", cho phép điều chỉnh hiệu quả ngay cả với bộ huấn luyện nhỏ (Zhou et al., 2023). Để đánh giá, chúng tôi sử dụng 617 hướng dẫn từ AlpacaFarm (Dubois et al., 2023), có nguồn gốc từ Self-Instruct (Wang et al., 2023), Vicuna (Chiang et al., 2023), Koala (Geng et al., 2023), và hh-rlhf (Bai et al., 2022).

Chúng tôi sử dụng API Google Translate để dịch các cặp hướng dẫn-phản hồi của bộ huấn luyện và các hướng dẫn của bộ đánh giá sang 11 ngôn ngữ, tạo ra các bộ huấn luyện và đánh giá song song bằng tiếng Ả Rập, tiếng Trung, tiếng Séc, tiếng Anh, tiếng Estonia, tiếng Phần Lan, tiếng Do Thái, tiếng Hindi, tiếng Ý, tiếng Nga, tiếng Tây Ban Nha, và tiếng Swahili. Mặc dù dữ liệu được dịch khác với dữ liệu có nguồn gốc tự nhiên cho từng ngôn ngữ, nó cho phép kiểm soát nhiều hơn vì kích thước dữ liệu và ngữ nghĩa tương tự cho tất cả các ngôn ngữ. Tổng quan về các ngôn ngữ, mã ngôn ngữ, họ ngôn ngữ và chữ viết được mô tả trong Bảng 2 ở Phụ lục A.

**Đánh giá** Chúng tôi thực hiện giao thức đánh giá tự động so sánh từng cặp (Bubeck et al., 2023; Dubois et al., 2023; Dettmers et al., 2023; Gudibande et al., 2023; Zheng et al., 2023), trong đó một LLM đánh giá hai phản hồi cho cùng một hướng dẫn, với mục tiêu xác định phản hồi tốt hơn. Chúng tôi tuân theo thực hành thông thường là trình bày cả hai phản hồi cho mô hình hai lần, xen kẽ thứ tự của hai phản hồi (Zheng et al., 2023; Zhang et al., 2023). Lời nhắc chính xác chúng tôi sử dụng được hiển thị trong Hình 9 ở Phụ lục B. Chúng tôi định nghĩa "thắng" cho một phản hồi nhất định nếu trọng tài chọn nó hai lần bất kể thứ tự, và "hòa" nếu mô hình chọn một phản hồi khác cho mỗi thứ tự. Chúng tôi sử dụng phương pháp tính điểm hòa giảm (Zhou et al., 2023), trong đó một mô hình nhận điểm 1 khi thắng, 0,5 khi hòa, và 0 khi thua. Chúng tôi lấy trung bình điểm số của các hướng dẫn riêng lẻ để có điểm số trên bộ đánh giá và trình bày dưới dạng phần trăm. Để xác thực rằng các quyết định của trọng tài LLM phù hợp với sở thích của con người trên các ngôn ngữ, chúng tôi tiến hành nghiên cứu chú thích của con người và thấy điểm đồng ý tổng hợp tốt là 79,5% cho tiếng Anh, 77% cho tiếng Tây Ban Nha, và 76,5%, 75% cho tiếng Nga và tiếng Do Thái, tương ứng. Chi tiết thêm về việc xác thực trọng tài LLM được cung cấp trong Phụ lục D.

**Điểm số tuân theo hướng dẫn theo ngôn ngữ**

Trong suốt nghiên cứu này, chúng tôi đo lường việc tuân theo hướng dẫn theo ngôn ngữ bằng cách so sánh hiệu suất của một mô hình được điều chỉnh trên một số bộ huấn luyện D, với một mô hình được điều chỉnh đơn ngôn ngữ trên ngôn ngữ đích L, bằng cách sử dụng toàn bộ bộ huấn luyện trong ngôn ngữ này, DL. Chính thức, chúng tôi định nghĩa chỉ số tuân theo hướng dẫn (IF) cho ngôn ngữ L:

IFL(MD) = S×S(MDL, MD)

Trong đó S×S(·,·) là giao thức so sánh từng cặp được áp dụng trên MDL và MD, là các mô hình được điều chỉnh hướng dẫn trên DL và D, tương ứng. Điểm số 0% có nghĩa là MD thua trong tất cả các hướng dẫn L, và 50% có nghĩa là hiệu suất của MD và MDL trong L không thể phân biệt được khi tổng hợp trên bộ đánh giá.

**Mô hình** Chúng tôi sử dụng họ mô hình PaLM 2 dựa trên Transformer (Vaswani et al., 2017) LLMs được huấn luyện trước trên hàng trăm ngôn ngữ (Anil et al., 2023). Chúng tôi sử dụng PaLM 2-S làm mô hình đã huấn luyện trước cho tất cả các thí nghiệm điều chỉnh hướng dẫn, và PaLM 2-L đã được điều chỉnh hướng dẫn làm trọng tài cho đánh giá so sánh từng cặp. Các siêu tham số huấn luyện và suy luận chúng tôi sử dụng được mô tả trong Phụ lục C.

**Xác thực của con người** Giao thức đánh giá của chúng tôi dựa vào chất lượng của các mô hình được điều chỉnh đơn ngôn ngữ. Để xác thực việc sử dụng chúng làm chuẩn mực cao trong các ngôn ngữ tương ứng, chúng tôi tiến hành nghiên cứu chú thích của con người bằng 4 ngôn ngữ: tiếng Anh, tiếng Tây Ban Nha, tiếng Nga và tiếng Do Thái. Cụ thể, chúng tôi lấy mẫu 50 hướng dẫn ngẫu nhiên cho mỗi ngôn ngữ, và yêu cầu 2 người nói tiếng mẹ đẻ đánh giá điểm xuất sắc, đạt, hoặc thất bại (Zhou et al., 2023) cho các phản hồi được tạo ra bởi mô hình được điều chỉnh đơn ngôn ngữ bằng ngôn ngữ đó. Kết quả trong Hình 2 cho thấy các mô hình đã điều chỉnh của chúng tôi thực sự thể hiện khả năng tuân theo hướng dẫn mạnh mẽ. Đáng chú ý, điểm số trên các ngôn ngữ tương tự hoặc tốt hơn số liệu được báo cáo bởi Zhou et al. (2023) bằng tiếng Anh.

## 3 Cần bao nhiều tính đa ngôn ngữ cho việc điều chỉnh hướng dẫn đa ngôn ngữ?

Bây giờ chúng tôi mô tả các thí nghiệm có kiểm soát, được thiết kế để định lượng tác động của dữ liệu đa ngôn ngữ trong quá trình điều chỉnh hướng dẫn của LLMs đa ngôn ngữ, theo các câu hỏi nghiên cứu được định nghĩa trong §2.

### 3.1 Điều chỉnh hướng dẫn đơn ngôn ngữ mang lại khả năng đa ngôn ngữ

Để khám phá việc chuyển giao đa ngôn ngữ không cần ví dụ của điều chỉnh hướng dẫn trong LLMs đa ngôn ngữ, chúng tôi điều chỉnh các mô hình trên một ngôn ngữ duy nhất và đánh giá chúng trên tất cả các ngôn ngữ còn lại. Chúng tôi thấy rằng tất cả các mô hình đó đều có thể chuyển giao khả năng tuân theo hướng dẫn đáng kể sang các ngôn ngữ khác.

**Thiết lập** Chúng tôi điều chỉnh hướng dẫn 12 mô hình, mỗi mô hình sử dụng toàn bộ bộ huấn luyện trong một ngôn ngữ khác nhau. Chúng tôi tạo ra các phản hồi sử dụng mỗi mô hình như vậy cho các hướng dẫn đánh giá trong tất cả các ngôn ngữ khác. Cuối cùng, chúng tôi tính toán điểm số theo ngôn ngữ của chúng như được mô tả trong §2.

**Kết quả** Hình 1 cho thấy kết quả, trong đó các hàng đại diện cho ngôn ngữ huấn luyện và mỗi cột là một bản đồ nhiệt độc lập của kết quả trên một ngôn ngữ đánh giá duy nhất. Quan trọng nhất, việc điều chỉnh sử dụng từng ngôn ngữ đơn lẻ tạo ra một mô hình có một số khả năng tuân theo hướng dẫn đa ngôn ngữ trên các ngôn ngữ. Để tham khảo, ngay cả mô hình có điểm số trung bình thấp nhất, mô hình được điều chỉnh trên Hindi, đạt điểm số trên 30% trong 9 trên 11 trường hợp. Mô hình có điểm số trung bình tốt nhất là mô hình được điều chỉnh trên tiếng Anh, khi tiếng Ý và tiếng Tây Ban Nha cũng cho phép điểm số cao một cách nhất quán.

Đáng chú ý, chúng tôi kiểm tra thủ công các phản hồi được tạo ra và thấy rằng các mô hình đã điều chỉnh của chúng tôi nhất quán phản hồi bằng cùng ngôn ngữ với hướng dẫn của chúng, bất kể ngôn ngữ mà chúng được điều chỉnh hướng dẫn, trái ngược với các phát hiện trong nghiên cứu trước đây (Touvron et al., 2023a; Chen et al., 2023). Chúng tôi giả thuyết rằng điều này đến từ bản chất đa ngôn ngữ của quá trình huấn luyện trước của PaLM 2, so với LLaMA tập trung vào tiếng Anh hơn (Touvron et al., 2023a), chi tiết thêm có trong Phụ lục E. Ngoài thiết lập chính, chúng tôi cũng so sánh các phản hồi của các mô hình này với những phản hồi của mô hình đã huấn luyện trước chưa được điều chỉnh hướng dẫn. Kết quả được hiển thị trong Hình 10 ở Phụ lục F chứng minh thêm rằng việc điều chỉnh hướng dẫn trong từng ngôn ngữ riêng biệt, cải thiện đáng kể khả năng tuân theo hướng dẫn trên các ngôn ngữ khác nhau.

### 3.2 Một vài chục ví dụ cải thiện việc tuân theo hướng dẫn đa ngôn ngữ

Tự nhiên, việc điều chỉnh đa ngôn ngữ, trái ngược với việc điều chỉnh chỉ tiếng Anh dưới ngân sách ví dụ huấn luyện cố định, nên dẫn đến hiệu suất downstream tốt hơn cho các ngôn ngữ không phải tiếng Anh, và có thể làm tổn hại hiệu suất tiếng Anh. Do đó, chúng tôi hỏi bao nhiêu ví dụ đa ngôn ngữ có thể cải thiện khả năng tuân theo hướng dẫn trên các ngôn ngữ, trong khi vẫn duy trì hiệu suất tiếng Anh. Để làm điều đó, chúng tôi điều chỉnh các mô hình trên các tập con của các ví dụ tiếng Anh kết hợp với các tập con của các ví dụ đa ngôn ngữ theo các tỷ lệ khác nhau. Chúng tôi thấy một sự thúc đẩy đáng kể trong khả năng tuân theo hướng dẫn đa ngôn ngữ ngay cả khi chỉ sử dụng vài chục ví dụ đa ngôn ngữ.

**Thiết lập** Chúng tôi tạo ra các hỗn hợp dữ liệu với P% ví dụ được chia đều giữa tất cả 12 ngôn ngữ, và phần còn lại (100−P)% là ví dụ tiếng Anh. Chúng tôi tạo ra một bộ huấn luyện như vậy cho mỗi P từ 10 đến 100, tăng theo mười, và cũng cho P = 1, trong đó chỉ 40 ví dụ đa ngôn ngữ được bao gồm từ tất cả 11 ngôn ngữ không phải tiếng Anh, và phần còn lại là ví dụ tiếng Anh. Cuối cùng, chúng tôi đánh giá mỗi mô hình đã điều chỉnh trên từng ngôn ngữ trong 12 ngôn ngữ như được định nghĩa trong §2.

**Kết quả** Hình 3 hiển thị kết quả. Như mong đợi, các ví dụ đa ngôn ngữ trong bộ huấn luyện cải thiện điểm số trên các ngôn ngữ của chúng (Đỏ), và việc pha loãng số lượng ví dụ tiếng Anh làm tổn hại hiệu suất tiếng Anh (Xanh lá). Đáng chú ý, sự cải thiện đa ngôn ngữ đáng kể đến từ việc thay thế chỉ 1% ví dụ tiếng Anh bằng ví dụ đa ngôn ngữ, tương đương với 40 ví dụ được phân bố đều trên các ngôn ngữ huấn luyện. Những kết quả này về tác động của một lượng nhỏ sự đa dạng ngôn ngữ mở rộng các phát hiện về sự đa dạng nhiệm vụ bởi Zhou et al. (2023), đã chứng minh rằng một mô hình tuân theo hướng dẫn đơn ngôn ngữ có khả năng có thể được điều chỉnh chỉ bằng 1.000 ví dụ chất lượng cao. Xu hướng thứ hai là các mô hình này thường vượt trội hơn các đối tác được điều chỉnh đơn ngôn ngữ của chúng chính trên ngôn ngữ mà các mô hình sau được điều chỉnh độc quyền (các điểm xanh trên đường 50). Ví dụ, mô hình được điều chỉnh bằng bộ đồng nhất (P = 100) thực hiện tương tự hoặc tốt hơn so với các mô hình được điều chỉnh đơn ngôn ngữ riêng lẻ trong 8 trên 12 ngôn ngữ, mặc dù được huấn luyện ít hơn 12 lần các cặp hướng dẫn-phản hồi cho mỗi ngôn ngữ. Điều này cho thấy rằng đối với một số ngôn ngữ, việc điều chỉnh đa ngôn ngữ có thể cho phép khả năng tuân theo hướng dẫn tốt hơn so với việc điều chỉnh đơn ngôn ngữ truyền thống với cùng số lượng ví dụ.

### 3.3 Một vài chục ví dụ cải thiện khả năng khái quát hóa đa ngôn ngữ

Kết hợp các bài học về khả năng khái quát hóa đa ngôn ngữ từ việc điều chỉnh đơn ngôn ngữ và tác động của một lượng nhỏ ví dụ đa ngôn ngữ từ các phần trước, chúng tôi chuyển sang kiểm tra cách các ví dụ đa ngôn ngữ trong bộ điều chỉnh ảnh hưởng đến khả năng khái quát hóa ngôn ngữ. Cụ thể, chúng tôi tiến hành thí nghiệm tương tự như trong §3.2, lần này chỉ sử dụng một nửa số ngôn ngữ để điều chỉnh trong khi các ngôn ngữ còn lại chưa được thấy. Phù hợp với kết quả từ §3.2, chúng tôi thấy rằng một lượng rất nhỏ ví dụ đa ngôn ngữ cũng cải thiện hiệu suất trên các ngôn ngữ không có trong bộ điều chỉnh.

**Thiết lập** Chúng tôi lặp lại thiết lập từ §3.2, lần này chỉ với tiếng Anh và 5 ngôn ngữ khác: tiếng Ả Rập, tiếng Phần Lan, tiếng Ý, tiếng Nga, và tiếng Swahili, và đánh giá các mô hình lại trên tất cả 12 ngôn ngữ.

**Kết quả** Kết quả trong Hình 4 cho thấy các xu hướng tương tự như trong Hình 3. Cụ thể, điểm số trung bình trên các ngôn ngữ huấn luyện không phải tiếng Anh (đỏ) lại cải thiện rất nhanh, ngay cả với P = 1. Đáng chú ý, điều này cũng đúng với các ngôn ngữ mà mô hình chỉ thấy trong quá trình huấn luyện trước, và hoàn toàn không được đại diện trong bộ dữ liệu điều chỉnh hướng dẫn (cam). Điều này cho thấy rằng rất ít ví dụ đa ngôn ngữ không chỉ có thể cải thiện hiệu suất cho các ngôn ngữ của những ví dụ đó, mà còn cho phép khả năng khái quát hóa tuân theo hướng dẫn đa ngôn ngữ tốt hơn.

### 3.4 Ngay cả một số lượng nhỏ ngôn ngữ cũng cải thiện khả năng khái quát hóa đa ngôn ngữ

Với kết quả về tác động của một số lượng nhỏ ví dụ đa ngôn ngữ từ một tập cố định các ngôn ngữ, chúng tôi hỏi liệu một số lượng nhỏ ngôn ngữ cũng có thể nâng cao khả năng khái quát hóa đa ngôn ngữ hay không. Chúng tôi thí nghiệm với các số lượng ngôn ngữ khác nhau trong bộ điều chỉnh và thực sự quan sát thấy rằng việc chuyển giao sang các ngôn ngữ chỉ được thấy trong quá trình huấn luyện trước cải thiện từ những ngôn ngữ bổ sung đầu tiên.

**Thiết lập** Chúng tôi điều chỉnh hướng dẫn các mô hình trên một ngôn ngữ duy nhất và tối đa 6 ngôn ngữ. Ở mỗi bước, chúng tôi thêm một ngôn ngữ vào bộ điều chỉnh, và chia đều cùng ngân sách ví dụ giữa tập ngôn ngữ hiện tại. Chúng tôi sử dụng 6 ngôn ngữ huấn luyện từ §3.3, và tuân theo 3 hoán vị khác nhau để xác định thứ tự thêm ngôn ngữ vào hỗn hợp. Những hoán vị này được hiển thị trong Bảng 4 ở Phụ lục G. Chúng tôi đánh giá mỗi mô hình trên từng ngôn ngữ trong 6 ngôn ngữ còn lại, và lấy trung bình điểm số cho mỗi ngôn ngữ đánh giá trên các mô hình được điều chỉnh bằng cùng số lượng ngôn ngữ.

**Kết quả** Kết quả trong Hình 5 cho thấy rằng việc thêm ngôn ngữ vào bộ điều chỉnh cải thiện khả năng khái quát hóa đa ngôn ngữ. Điểm số trung bình (đỏ) tăng từ việc điều chỉnh trên dữ liệu đơn ngôn ngữ sang việc điều chỉnh trên dữ liệu song ngữ, và thậm chí nhiều hơn khi sử dụng 3 và 4 ngôn ngữ, nơi điểm số trung bình đạt gần 50. Tại thời điểm đó, có dấu hiệu bão hòa, vì nhiều ngôn ngữ hơn dường như không cải thiện chuyển giao thêm nữa. Những phát hiện này chứng minh rằng việc đa dạng hóa dữ liệu điều chỉnh hướng dẫn chỉ với một vài ngôn ngữ khác nhau có thể cải thiện chuyển giao đa ngôn ngữ sang các ngôn ngữ mới, chỉ được thấy trong quá trình huấn luyện trước.

**Bộ điều chỉnh song ngữ** Để cho thấy điều này đúng với nhiều tổ hợp ngôn ngữ hơn, chúng tôi ngẫu nhiên chia tất cả ngôn ngữ thành các cặp, và điều chỉnh các mô hình sử dụng 50% ví dụ trong ngôn ngữ này và 50% trong ngôn ngữ khác. Chúng tôi đánh giá mỗi mô hình này trên 10 ngôn ngữ còn lại, và so sánh điểm số của chúng với những mô hình được điều chỉnh bằng hai bộ đơn ngôn ngữ đầy đủ. Kết quả trong Hình 6 tiết lộ rằng việc điều chỉnh song ngữ giúp khái quát hóa sang các ngôn ngữ mới tốt hơn so với việc điều chỉnh đơn ngôn ngữ.

## 4 Các yếu tố tiềm năng của khả năng chuyển giao

Theo kết quả từ các phần trước, một câu hỏi tự nhiên phát sinh: các yếu tố nào có thể dự đoán mức độ chuyển giao đa ngôn ngữ? Chúng tôi khám phá hai ứng viên ngay lập tức. Ban đầu, chúng tôi kiểm tra mối quan hệ của các khía cạnh khác nhau của sự tương tự ngôn ngữ với khả năng chuyển giao trong các cặp ngôn ngữ. Tiếp theo, chúng tôi xem xét liệu tỷ lệ dữ liệu đặc thù ngôn ngữ trong kho dữ liệu huấn luyện trước có tương quan với lượng chuyển giao đa ngôn ngữ của việc điều chỉnh hướng dẫn bằng ngôn ngữ đã cho hay không.

### 4.1 Sự tương tự ngôn ngữ

Một giả thuyết trực quan là các khía cạnh của sự tương tự ngôn ngữ như chữ viết hoặc khả năng hiểu lẫn nhau có thể ảnh hưởng đến mức độ chuyển giao đa ngôn ngữ điều chỉnh hướng dẫn giữa các ngôn ngữ. Chúng tôi kiểm tra điều này bằng cách sử dụng một nghiên cứu trường hợp với 7 ngôn ngữ Slavic, xem xét các tác động có thể có của các khía cạnh như vậy. Tuy nhiên, chúng tôi không tìm thấy tín hiệu chỉ ra rằng các yếu tố này có mối tương quan mạnh với chuyển giao đa ngôn ngữ cho cài đặt này.

**Thiết lập** Chúng tôi huấn luyện các mô hình trên các phiên bản đơn ngôn ngữ của dữ liệu bằng tiếng Nga, tiếng Serbia, tiếng Croatia, tiếng Slovenia, tiếng Ba Lan, tiếng Slovakia và tiếng Séc, và đánh giá chuyển giao của chúng lẫn nhau. Những ngôn ngữ này có thể được chia theo một số đường ranh giới ngôn ngữ học được tóm tắt trong Bảng 1. Đầu tiên, tiếng Nga là Slavic Đông, và phần còn lại là Slavic Nam hoặc Tây. Thứ hai, tiếng Nga và tiếng Serbia đều sử dụng chữ viết Cyrillic, trong khi phần còn lại sử dụng chữ Latin. Hơn nữa, cả tiếng Serbia và tiếng Croatia, và tiếng Slovakia và tiếng Séc đều có mức độ hiểu lẫn nhau đáng kể.

**Kết quả** Kết quả được hiển thị trong Hình 7. Như được hiển thị, không có tín hiệu mạnh chỉ ra rằng bất kỳ khía cạnh nào ở trên có tương quan với khả năng chuyển giao đa ngôn ngữ tốt hơn. Tiếng Nga và tiếng Séc có xu hướng chuyển giao khả năng tuân theo hướng dẫn tốt nhất, và mặc dù tiếng Nga và tiếng Serbia đều sử dụng Cyrillic, tiếng Croatia và tiếng Séc chuyển giao khả năng cho tiếng Nga tốt hơn tiếng Serbia. Kiểm tra tác động của khả năng hiểu lẫn nhau, tiếng Croatia và tiếng Serbia không chia sẻ khả năng đa ngôn ngữ nhiều hơn các ngôn ngữ khác, và trong khi tiếng Slovakia và tiếng Séc có thể hiểu lẫn nhau, tiếng Slovakia chuyển giao cho tiếng Séc ít hơn phần còn lại. Kết quả của chúng tôi phù hợp với các phát hiện gần đây rằng sự tương tự ngôn ngữ không ảnh hưởng đến khả năng chuyển giao hoặc can thiệp trong dịch máy với dữ liệu đủ và khả năng mô hình (Fernandes et al., 2023; Shaham et al., 2023).

### 4.2 Tỷ lệ dữ liệu trong huấn luyện trước

Một yếu tố dự đoán thứ hai có thể có của mức độ chuyển giao đa ngôn ngữ từ một ngôn ngữ cụ thể là mức độ mà mô hình được tiếp xúc với nó trong quá trình huấn luyện trước. Nói chung, hiệu suất downstream của mô hình trên một ngôn ngữ cụ thể tương quan với tỷ lệ dữ liệu trong ngôn ngữ đó trong kho dữ liệu huấn luyện trước (Muennighoff et al., 2023). Ngược lại, Hình 8 cho thấy điều này không nhất thiết đúng với việc chuyển giao đa ngôn ngữ từ một ngôn ngữ cụ thể. Chúng tôi tìm thấy mối tương quan Pearson yếu là 0,22 giữa điểm số chuyển giao đa ngôn ngữ trung bình của mỗi ngôn ngữ và số lượng tài liệu trong ngôn ngữ đó trong kho dữ liệu huấn luyện trước (Bảng 21 trong Anil et al. (2023)).

## 5 Các nghiên cứu liên quan

**Chuyển giao đa ngôn ngữ** Sự thành công của mô hình huấn luyện trước–tinh chỉnh (Devlin et al., 2019) đã khơi mào một hướng nghiên cứu mới về chuyển giao đa ngôn ngữ. Pires et al. (2019) và Wu and Dredze (2019) đã chỉ ra rằng biến thể đa ngôn ngữ của BERT có thể được tinh chỉnh trên một nhiệm vụ cụ thể trong một ngôn ngữ và thực hiện nhiệm vụ này trong ngôn ngữ khác, và Artetxe and Schwenk (2019) báo cáo các phát hiện tương tự với Mạng Neural Tái phát. Conneau et al. (2020a) giới thiệu XLM-R, một bộ mã hóa đa ngôn ngữ đã huấn luyện trước với khả năng đa ngôn ngữ mạnh mẽ. Phang et al. (2020) đã chỉ ra rằng việc huấn luyện trung gian trên một nhiệm vụ tiếng Anh cải thiện khả năng chuyển giao của XLM-R trên các ngôn ngữ hơn nữa, và Pfeiffer et al. (2020) đề xuất một khung dựa trên bộ điều hợp để cải thiện khả năng khái quát hóa đa ngôn ngữ và nhiệm vụ. Hu et al. (2020) đề xuất một bộ tiêu chuẩn cho khả năng khái quát hóa đa ngôn ngữ bao gồm 40 ngôn ngữ trên 9 nhiệm vụ NLP.

K et al. (2020) thấy rằng độ sâu của mạng quan trọng đối với chuyển giao đa ngôn ngữ, và Conneau et al. (2020b) đã chỉ ra rằng việc chia sẻ tham số quan trọng hơn từ vựng chung. Choenni et al. (2023) đã đi sâu vào ảnh hưởng của các ví dụ cụ thể từ dữ liệu huấn luyện đối với hiệu suất trong các ngôn ngữ khác, và Malkin et al. (2022) đã điều tra cách việc huấn luyện trước các mô hình dựa trên BERT bằng các cặp ngôn ngữ khác nhau ảnh hưởng đến hiệu suất downstream đa ngôn ngữ. Vượt ra ngoài các mô hình chỉ có bộ mã hóa, Xue et al. (2021) đề xuất mT5, một biến thể đa ngôn ngữ của T5 (Raffel et al., 2020), và đã chỉ ra tầm quan trọng của việc mở rộng mô hình đối với chuyển giao đa ngôn ngữ trong các nhiệm vụ tạo sinh. Ye et al. (2023) đã khám phá khả năng chuyển giao trong các mô hình tập trung vào tiếng Anh (Touvron et al., 2023a) sử dụng bốn nhiệm vụ.

Trái ngược với hầu hết tài liệu chuyển giao đa ngôn ngữ tập trung vào tinh chỉnh đặc thù nhiệm vụ, chúng tôi khám phá các xu hướng của khả năng khái quát hóa đa ngôn ngữ cho LLMs tuân theo hướng dẫn đa mục đích.

**Điều chỉnh hướng dẫn đa ngôn ngữ** Ban đầu, các nghiên cứu về điều chỉnh hướng dẫn (Mishra et al., 2022; Wei et al., 2022; Sanh et al., 2022) tập trung vào khả năng khái quát hóa đa nhiệm vụ bằng tiếng Anh. Sau đó, một lượng lớn nghiên cứu được dành cho việc điều chỉnh hướng dẫn đa ngôn ngữ. Muennighoff et al. (2023) thấy rằng việc điều chỉnh các mô hình với các bộ dữ liệu tiếng Anh cho phép khả năng đa ngôn ngữ không cần ví dụ sang các ngôn ngữ mới. Các tác giả cũng thấy rằng điều này đúng với các ngôn ngữ mà mô hình chưa bao giờ cố ý thấy trong quá trình huấn luyện trước, và việc huấn luyện đa ngôn ngữ cải thiện khả năng khái quát hóa sang các nhiệm vụ mới.

Chen et al. (2023) đã điều tra các tác động của việc huấn luyện tham số đầy đủ so với thích ứng hạng thấp (Hu et al., 2022) và điều chỉnh hướng dẫn đơn ngôn ngữ so với đa ngôn ngữ sử dụng dữ liệu Stanford Alpaca (Taori et al., 2023) được dịch máy sang 5 ngôn ngữ. Lai et al. (2023) đã huấn luyện các mô hình tuân theo hướng dẫn đa ngôn ngữ cho 26 ngôn ngữ với học tăng cường từ phản hồi của con người (Ouyang et al., 2022), và Zhang et al. (2023) đề xuất điều chỉnh hướng dẫn LLMs bằng cách thêm tiền tố hướng dẫn và phản hồi được dịch sang ngôn ngữ trung gian (ví dụ tiếng Anh) vào phản hồi trong ngôn ngữ đích. Đồng thời với nghiên cứu của chúng tôi, Kew et al. (2023) thấy rằng chỉ một vài ngôn ngữ trong bộ điều chỉnh dẫn đến chuyển giao đa ngôn ngữ tốt hơn sang các ngôn ngữ mới cho LLMs tập trung vào tiếng Anh.

Trong nghiên cứu này, chúng tôi xem xét chuyển giao từ điều chỉnh hướng dẫn đơn ngôn ngữ từ 12 ngôn ngữ, thay vì chỉ tập trung vào tiếng Anh. Hơn nữa, chúng tôi kiểm tra việc tuân theo hướng dẫn đa ngôn ngữ bằng cách sử dụng một LLM được huấn luyện trước trên hàng trăm ngôn ngữ, có thể là chìa khóa để mở khóa nhiều chuyển giao hơn sang các ngôn ngữ không được đại diện trong quá trình điều chỉnh. Quan trọng, chúng tôi tiết lộ tiềm năng của chỉ một lượng nhỏ sự đa dạng ngôn ngữ trong bộ điều chỉnh hướng dẫn cho khả năng khái quát hóa đa ngôn ngữ này.

## 6 Kết luận

Chúng tôi chứng minh rằng chuyển giao đa ngôn ngữ mang lại một con đường đầy hứa hẹn để xây dựng các LLMs tuân theo hướng dẫn đa ngôn ngữ. Các phát hiện của chúng tôi trên các ngôn ngữ khác nhau cho thấy rằng ngay cả việc điều chỉnh hướng dẫn đơn ngôn ngữ chỉ sử dụng một ngôn ngữ có thể dẫn đến khả năng tuân theo hướng dẫn được cải thiện trong các ngôn ngữ khác. Hơn nữa, việc kết hợp ngay cả một bộ nhỏ gồm vài chục ví dụ đa ngôn ngữ có thể nâng cao đáng kể hiệu suất tuân theo hướng dẫn cho cả các ngôn ngữ mà mô hình được điều chỉnh, và những ngôn ngữ chỉ được thấy trong quá trình huấn luyện trước. Ngoài ra, việc huấn luyện trên các bộ dữ liệu đa ngôn ngữ như vậy đạt được hiệu suất tương đương hoặc thậm chí vượt trội so với việc điều chỉnh đơn ngôn ngữ cho một số ngôn ngữ. Chúng tôi quan sát thấy một xu hướng tương tự khi khám phá tác động của tổng số ngôn ngữ trong bộ điều chỉnh, vì ngay cả việc chia bộ huấn luyện thành chỉ hai ngôn ngữ cải thiện khả năng khái quát hóa sang các ngôn ngữ mới, so với việc điều chỉnh đơn ngôn ngữ. Những phát hiện này mở đường cho việc phát triển hiệu quả và có thể mở rộng các LLMs đa ngôn ngữ có khả năng hiểu và tuân theo hướng dẫn trên các ngôn ngữ với sự giám sát đa ngôn ngữ tối thiểu.

## 7 Hạn chế

Các hạn chế của nghiên cứu chúng tôi bao gồm việc sử dụng dịch thuật để mở rộng bộ dữ liệu sang cài đặt đa ngôn ngữ, số lượng ngôn ngữ chúng tôi đánh giá, và số lượng mô hình chúng tôi thí nghiệm. Bây giờ chúng tôi thảo luận về từng điểm.

**Dữ liệu đã dịch** Một hạn chế của nghiên cứu chúng tôi là dữ liệu của chúng tôi được dịch bằng API Google Translate, và không được tạo ra từ đầu bởi người nói tiếng mẹ đẻ. Dịch thuật tự động vốn không hoàn hảo và có thể đưa tiếng ồn vào các bộ điều chỉnh. Tuy nhiên, dịch thuật cũng cho phép cài đặt có kiểm soát với dữ liệu song song, trong đó nội dung của tất cả các ví dụ huấn luyện và đánh giá giống nhau cho tất cả các ngôn ngữ.

**Số lượng ngôn ngữ** Hạn chế thứ hai là chúng tôi sử dụng 12 ngôn ngữ trong các thí nghiệm chính (§3), với 3 ngôn ngữ bổ sung trong thí nghiệm sự tương tự ngôn ngữ (§4.1). Rõ ràng, các mô hình tuân theo hướng dẫn đa ngôn ngữ cần hoạt động thành công trong nhiều ngôn ngữ hơn, và chúng tôi để nghiên cứu về việc mở rộng số lượng này cho các nghiên cứu tương lai.

**Số lượng mô hình** Cuối cùng, chúng tôi thí nghiệm với PaLM 2, và kết quả có thể thay đổi với các LLMs khác nhau. Tuy nhiên, sự tập trung của chúng tôi vào PaLM 2 làm nổi bật tiềm năng của việc huấn luyện trước đa ngôn ngữ cho các tiến bộ tương lai trong LLMs.

## Lời cảm ơn

Chúng tôi cảm ơn Omer Levy, Or Honovich, Alon Jacovi, Avi Caciularu, và Omer Goldman vì phản hồi quý báu của họ.

## Tài liệu tham khảo

[Phần tài liệu tham khảo được giữ nguyên vì chứa các trích dẫn học thuật tiêu chuẩn]

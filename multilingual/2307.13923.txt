# 2307.13923.pdf
# Converted from PDF to TXT
# Source path: /home/admin88/arxiv-downloader/multilingual/2307.13923.pdf
# File size: 924569 bytes

===============================================
PDF FILE CONTENT
===============================================


--- PAGE 1 ---
GrammarGPT: Exploring Open-Source LLMs
for Native Chinese Grammatical Error
Correction with Supervised Fine-Tuning
Yaxin Fan1,2,3, Feng Jiang1,3,4⋆, Peifeng Li2, and Haizhou Li1,3
1School of Data Science, The Chinese University of Hong Kong, Shenzhen, China
2School of Computer Science and Technology, Soochow University, China
3Shenzhen Research Institute of Big Data, Shenzhen, Guangdong, China
4School of Information Science and Technology, University of Science and
Technology of China, China
yxfansuda@stu.suda.edu.cn
pfli@suda.edu.cn
{jeffreyjiang,haizhouli }@cuhk.edu.cn
Abstract. Grammatical error correction aims to correct ungrammati-
cal sentences automatically. Recently, some work has demonstrated the
excellent capabilities of closed-source Large Language Models (LLMs,
e.g., ChatGPT) in grammatical error correction. However, the poten-
tial of open-source LLMs remains unexplored. In this paper, we in-
troduced GrammarGPT, an open-source LLM, to preliminary explore
its potential for native Chinese grammatical error correction. The core
recipe of GrammarGPT is to leverage the hybrid dataset of ChatGPT-
generated and human-annotated. For grammatical errors with clues, we
proposed a heuristic method to guide ChatGPT to generate ungram-
matical sentences by providing those clues. For grammatical errors with-
out clues, we collected ungrammatical sentences from publicly avail-
able websites and manually corrected them. In addition, we employed
an error-invariant augmentation method to enhance the ability of the
model to correct native Chinese grammatical errors. We ultimately con-
structed about 1k parallel data and utilized these data to fine-tune
open-source LLMs (e.g., Phoenix, released by The Chinese University
of Hong Kong, Shenzhen) with instruction tuning. The experimental
results show that GrammarGPT outperforms the existing SOTA sys-
tem significantly. Although model parameters are 20x larger than the
SOTA baseline, the required amount of data for instruction tuning is
1200x smaller, illustrating the potential of open-source LLMs on na-
tive CGEC. Our GrammarGPT ranks 3rdon NLPCC2023 SharedTask1,
demonstrating our approach’s effectiveness. The code and data are avail-
able at https://github.com/FreedomIntelligence/GrammarGPT .
Keywords: Native Chinese grammatical error correction ·Large lan-
guage models ·ChatGPT ·Instruction tuning.
⋆Corresponding AuthorarXiv:2307.13923v2  [cs.CL]  17 Aug 2023

--- PAGE 2 ---
2 Fan et al.
1 Introduction
Grammatical Error Correction (GEC) aims to automatically correct ungram-
matical sentences without changing their meaning [26,10,27]. Previous works
[28,13,14,26] in Chinese Grammatical Error Correction (CGEC) mainly study
the errors from foreign Chinese learners, which are very obvious and naive.
Therefore, recent works [27,10] shift to the grammatical errors made by na-
tive speakers, which are more subtle and challenging. Table 1 shows the six
main types of grammatical errors made by native speakers, which can be di-
vided into two types, e.g., with (w/) and without (w/o) clues. We can find that
the incorrect sentences are fluent and in line with the habits of native Chinese.
However, they do not conform to Chinese grammar, which is more difficult to
correct.
Previous studies in GEC mainly adopted both Seq2edit [5,26,9,10] and Seq2seq
[7,29,15] paradigms and have achieved impressive performance on various GEC
benchmarks. With the emergence of LLMs, Fang et al. [4] evaluated the per-
formance of closed-source LLMs (e.g., ChatGPT5) on GEC and revealed its
excellent capabilities for error detection and correction. However, the potential
of open-source LLMs remains unexplored.
In this paper, we introduce GrammarGPT, a novel model for studying the
potential of open-source LLMs architectures in addressing Native Chinese Gram-
matical Error Correction (CGEC) through supervised fine-tuning. The key chal-
lenge in fine-tuning LLMs for CGEC is obtaining high-quality parallel data com-
prising grammatical errors made by native speakers. However, manually anno-
tating such data is not only time-consuming but also expensive, necessitating the
exploration of automatic data annotation methods. Recent works [25,22] have
successfully leveraged distilled data from ChatGPT and real-world datasets to
fine-tune LLMs for specific domains, effectively reducing costs while achieving
superior performance. Inspired by this line of research, we propose a hybrid
dataset that incorporates different types of native Chinese grammatical errors.
Specifically, we first proposed a heuristic method for the grammatical errors
with clues as shown in Fig. 1 that guides ChatGPT to generate ungrammati-
cal sentences by providing those clues. Then, for those errors without clues, we
collected the ungrammatical sentences from the public website and corrected
them manually. In addition, we proposed an error-invariant data augmentation
method to enhance the diversity of the data by substituting the named entities
in parallel data with similar ones, which can improve the ability of the model to
correct native Chinese grammatical errors. We ultimately constructed 1k par-
allel data and utilized these data to fine-tune LLMs with instruction tuning.
The experimental results show that GrammarGPT can significantly outperform
state-of-the-art (SOTA) systems. Although the size of model parameters is 20x
larger than the SOTA baseline, the data for fine-tuning is 1200x smaller, which
demonstrated the potential of open-source LLMs on Chinese grammatical error
correction.
5https://chat.openai.com/

--- PAGE 3 ---
GrammarGPT 3
Table 1. Examples of sentences with various types of grammatical errors. For those
errors with clues, we can easily detect and correct them. For example, the co-occurrence
of超过(more than ) and左右(about ) lead to redundant component error and we can
remove one of them to make the sentence conform to Chinese grammar. However, for
those errors without clues, a deeper understanding of Chinese grammar is required to
detect and correct.
w/ CluesRedundant
Component
(RC)Incorrect: 这座卫星城的人口估计超过一百万左右。
The population of this satellite city is estimated to be
more than about one million.
Correct: 这座卫星城的人口估计超过一百万。
The population of this satellite city is estimated to be
over one million.
Structural
Confusion
(SC)Incorrect: 这次网络故障的原因是由服务器故障引起的。
The cause of this network failure is caused by the server failure.
Correct: 这次网络故障的原因是服务器故障。
The cause of the network failure is the server failure.
Improper
Collocation
(IC)Incorrect: 西湖区正全面提升区域产城融合发展的步伐。
Xihu District is promoting the pace of integration of regional
industry and city development.
Correct: 西湖区正全面加快区域产城融合发展的步伐。
Xihu District is accelerating the pace of integration of regional
industry and city development.
w/o CluesImproper
Word Order
(IWO)Incorrect: :学校三个月内要求每名学生完成20个小时的义工服务。
The school in three months requires each student to complete
20 hours of volunteer service.
Correct: 学校要求每名学生三个月内完成20个小时的义工服务。
The school requires each student to complete 20 hours of
volunteer service in three months.
Improper
Logicality
(IL)Incorrect: 集团向社会各界人士、沿途村庄百姓表示歉意。
The group apologizes to people from all walks of life and
villagers along the way.
Correct: 集团向社会各界人士表示歉意。
The group apologizes to people from all walks of life.
Missing
Component
(MC)Incorrect: 这篇报告控诉了人类破坏大自然(...)。
The report accused man of destroying nature.
Correct: 这篇报告控诉了人类破坏大自然的罪行。
The report accused man the crime of destroying nature.
Our contributions are as follows:
–To the best of our knowledge, we are the first to explore the potential of
open-source LLMs with instruction tuning for native Chinese grammatical
error correction.
–We have constructed a hybrid dataset generated by ChatGPT and manual
annotation, which can effectively cover native Chinese grammatical errors
for taming the LLMs into an excellent grammar detector.
–We designed an error-invariant data augmentation method to substitute the
named entities in parallel data with similar ones, making the model more
accurate in correcting grammatical errors.
–The experimental results show that GrammarGPT can outperform the SOTA
system significantly, and the data size for instruction tuning is only 1/1200
of the SOTA system.

--- PAGE 4 ---
4 Fan et al.
2 Related Work
2.1 Grammatical Error Correction
The works in grammatical error correction can be divided into two paradigms:
the Seq2edit paradigm and the Seq2seq paradigm.
Seq2edit paradigm Seq2edit paradigm aims to predict the modification label,
including insertion, deletion, and substitution, for each position of the sentence
iteratively. Hinson et al. [5] proposed a heterogeneous approach to CGEC, com-
posed of a NMT-based model, a sequence editing model, and a spell checker.
Liang et al. [9] introduced and transferred the BERT-fused NMT model and
sequence tagging model into the CGEC field. Zhang et al. [26] proposed a multi-
reference multi-source evaluation dataset for CGEC and adopted the seq2edit
method that enhanced with large pre-trained language models. Ma et al. [10] pro-
pose a linguistic rules-based approach to construct large-scale CGEC training
corpora with automatically generated grammatical errors and adopt the seq2edit
method for evaluation.
Seq2seq paradigm This paradigm treats CGEC as a monolingual translation
task. Katsumata and Komachi [7] explored the utility of bidirectional and auto-
regressive transformers (BART) as a generic pre-trained encoder-decoder model
for GEC. Zhao and Wang [29] proposed a simple yet effective method to improve
the NMT-based GEC models by dynamic masking, which can generate more
diverse instances to enhance model generalization. Rothe et al. [15] proposed
a language-agnostic method to generate a large number of synthetic examples,
and then fine-tune large-scale multilingual language models.
In addition, several works [9,5,8,26] observe the complementary power of
the above two paradigms, thus promoting the performance through the model
ensemble. In this paper, we adopt the Se2seq paradigm to fine-tune LLMs with
instruction tuning.
2.2 Instruction Tuning for LLMs
Instruction tuning [21,16] can improve the ability of model generalization by
learning from a large number of tasks guided by instruction, which has been
successfully applied to fine-tune LLMs on some specific tasks. The work on task-
specific instruction tuning can be categorized into three types by data sources:
ChatGPT-generated, human-annotated, and hybrid dataset of ChatGPT and
human.
ChatGPT-generated data Several works adopted the data generated by Chat-
GPT to fine-tune LLMs in the form of instructions. Ho et al. [6] proposed Fine-
tune-CoT, a method that generates reasoning samples from LLMS to fine-tune
smaller models, which enables substantial reasoning capability of small models.
Wang et al. [19] proposed SCOTT, a faithful knowledge distillation method to

--- PAGE 5 ---
GrammarGPT 5
ChatGPT-generated Data
Human-annotated DataRedudant Component
Structural Confusion
Improper Collocation
Improper Word Order
Improper Logicality
Missing Component
Error-invariant
Augmentation Instruction 
Tuning
GrammarGPT
Hybrid 
DatasetAugmen
tation 
Dataset
Fig. 1. The framework of our method.
learn a small, self-consistent CoT model from a teacher model that is orders of
magnitude. Chen et al. [1] explored distilling the reasoning ability of LLMs into
a more compact student model for multimodal named entity and multimodal
relation extraction. Chen et al. [1] proposed a data synthesis framework built
upon the data generation functions parameterized by LLMs and prompts and
used synthesized data to fine-tune LLaMA.
Human-annotated data Some works directly convert the supervised data into the
format of instructions to fine-tune LLMs. Zhang et al. [24] proposed to fine-tune
LLaMA [18] on financial sentiment analysis with a small portion of supervised
financial sentiment analysis data. Wang et al. [20] proposed a unified information
extraction framework based on instruction tuning to model various information
extraction tasks and capture the inter-task dependency.
Hybrid dataset of ChatGPT and human Recently, some works utilized the hybrid
data of humans and ChatGPT/GPT-4 to fine-tune LLMs. Zhang et al. [25]
proposed to leverage both distilled data from ChatGPT and real-world data
from doctors to fine-tune Bloom [17]. Yu et al. [22] adopted a hybrid data of
Chinese education and general-domain instructions [12] generated by GPT-4 to
fine-tune LLaMA [18]. In this paper, we follow this line and fine-tune LLMs
on native CGEC with the hybrid dataset of ChatGPT-generated and human-
annotated with instruction tuning.
3 Methods
Fig. 1 illustrates the framework of our method, which involves the construction
of parallel data comprising six types of native Chinese grammatical errors to fa-
cilitate the fine-tuning of open-source Language Model (LLMs). While human-
annotated data offer high-quality samples, the associated high cost remains a
significant concern. To address this, we adopt a compromise approach. We first
guide ChatGPT to generate ungrammatical sentences with clues by providing
those clues collected from the Internet. Then, we annotate the ungrammatical

--- PAGE 6 ---
6 Fan et al.
Instruction: 
用”...{超过}...{左右}...”造5个句子，每个句
子涉及到不同的话题，每个句子至少15个字。
Use the “...{more than} ... {about} ...” make 5 
sentences, each involving a differen topics and is at 
least 15 words.
 ChatGPTOutput: 
我们公司每年的利润都超过500万美元左右。
Our company makes more than about $5 million a year.
...
这本小说的销量预计会超过10万册左右。
The novel is expected to sell more than about 100,000 
copies.
Fig. 2. Process of ungrammatical sentences generated by ChatGPT.
Ungrammatical Sentence:
赵薇执导的《致青春》对中国青年使不陌生的。
So Young, directed by Wei Zhao, is no stranger to the 
youth of China.
Grammatical Sentence:
中国青年对于赵薇执导的《致青春》是不陌生的。
Chinese youth are no strangers to the So Young 
directed by Wei Zhao.Ungrammatical Sentence:
章子怡执导的《致青春》对中国青年使不陌生的。
So Young, directed by Ziyi Zhang, is no stranger to the 
youth of China.
Grammatical Sentence:
中国青年对于章子怡执导的《致青春》是不陌生的。
Chinese youth are no strangers to the So Young 
directed by Ziyi Zhang.Error-invariant
Augmentation 
Fig. 3. An example of error-invariant augmentation.
sentences without clues collected from the Internet. Additionally, we propose an
error-invariant augmentation technique to substitute named entities in the par-
allel data with similar ones, further enhancing the model’s capability to correct
native Chinese grammatical errors. Finally, we convert the parallel data into in-
structions, which are then utilized for fine-tuning LLMs. Detailed explanations
of these steps are provided in the following subsections.
3.1 Hybrid Dataset Construction
ChatGPT-generated Data As shown in the first three lines of Table 1, the
grammatical errors with clues are easy to detect and correct by recognizing
the specific clues. For example, ”more than” and ”about” are used together
leading to redundant component ,”The cause” and ”caused by” are used
together leading to structural confusion , and ”prompting” and”pace” are
used together leading to improper collocation . Conversely, we can construct
the ungrammatical sentences by inserting these cues into grammatical sentences.
Thanks to the strong capabilities of ChatGPT, we can instruct ChatGPT to
generate the ungrammatical sentences that meet our requirements by providing
these clues collected from public websites6. An example is as shown in Fig. 2.
Human-annotated Data Some types of native ungrammatical errors are hard
to recognize, as shown in the last three lines of Table 1. We can find that those
ungrammatical sentences are fluent and with no obvious clues of grammatical
errors can help us to recognize them. For these types of grammatical errors, we
mainly collected ungrammatical sentences from publicly available websites7and
then manually annotated them.
6https://wenku.baidu.com
7https://tiku.baidu.com/

--- PAGE 7 ---
GrammarGPT 7
Table 2. Components of an instruction.
Instruction{Task Prefix }
Human: {Task Description } {Input }Assistant : {Output }
Task PrefixA chat between a curious human and an artificial
intelligence assistant. The assistant gives helpful,
detailed, and polite answers to the human’s questions.
Task Description Evaluate this sentence for grammar mistake
Input Ungrammatical sentence
Output Grammatical sentence
Table 3. Statistic of the dataset.
Dataset NumberPercentage of Different Grammatical Errors (%)
ChatGPT-generated Human-annotated
RC SC IC IWO IL MC
training set 1061 23.54 28.25 13.70 6.50 13.18 15.07
validating set 500 - - - - - -
3.2 Error-invariant Data Augmentation
To prioritize the model’s focus on native grammar errors and improve its ro-
bustness, we have devised an error-invariant augmentation method, as shown
in Fig. 3. Native Chinese grammatical errors are often subtle and infrequently
found in the position of named entities. To address this, we adopt a strategy
of substituting the named entities in the parallel data with similar ones8. By
employing this augmentation method, the model can concentrate on identifying
unchanged errors rather than specific nouns, thereby improving its performance
in correcting subtle and imperceptible grammar errors.
3.3 Instruction Tuning
Instruction tuning[21,16] has emerged as the mainstream approach for fine-
tuning LLMs by providing explicit instructions to enhance model comprehension.
In this paper, we followed this mainstream trend and fine-tuned LLMs with
instruction tuning. Instruction details are as shown in Table 2, which mainly
consists of four components.
1.Task prefix : This component guides LLMs to assume the role of an AI
assistant.
2.Task description : Here, the specific task that LLMs are required to
accomplish is outlined.
3.Input : This corresponds to ungrammatical sentences that are used as
input during the fine-tuning process.
4.Output : This represents grammatical sentences, which serve as the ex-
pected output during fine-tuning.
8https://github.com/chatopera/Synonyms

--- PAGE 8 ---
8 Fan et al.
Table 4. Details of hyper-parameters.
Backbone phoenix-inst-chat-7b
Max length 256
Optimizer AdamW
Batch size 64
Epoch 1
Learning rate 2e-5
Lr schedule type Linear
Warmup steps 5
4 Experiments
4.1 Datasets
We constructed a total of 1061 parallel data samples for training, and the data
statistics are provided in Table 3. Roughly 35% of the data were manually an-
notated, while the remaining 65% were generated using ChatGPT. To evaluate
the performance of our model, we utilized the validating set available on the
NLPCC2023 SharedTask1 website9, which consists of 500 parallel data samples.
We report the model’s performance on this validating set for all the experiments
conducted.
4.2 Metrics
The evaluation of a grammatical error correction system relies on the extent to
which its proposed corrections or edits align with the gold-standard edits [11].
In line with previous research [10,26], we adopt the word-level and char-level
MaxMatch (M2) Scorer [3] for evaluation10. This scorer computes Precision,
Recall, and F 0.5scores, comparing the gold edit set with the system edit set.
4.3 Hyper-parameters
The models are implemented in PyTorch using the Huggingface Transformers11.
We used phoenix-inst-chat-7b12[2] as the backbone. We set the max sequence
length to 256. The model is trained with the AdamW optimizer, where the batch
size and epoch are set to 64 and 3, respectively. We set the learning rate and
the schedule type of learning rate to 2e-5 and ’linear’, respectively. The warmup
step is set to 5. The hyper-parameters are shown in Table 4.
9https://github.com/masr2000/NaCGEC
10https://github.com/HillZhang1999/MuCGEC/tree/main/scorers/ChERRANT
11https://huggingface.co/
12https://huggingface.co/FreedomIntelligence/phoenix-inst-chat-7b

--- PAGE 9 ---
GrammarGPT 9
Table 5. Performance comparison between GrammarGPT and the SOTA baseline.
Model #Param. Data Data sizeWord-level Char-level
Prec Rec F 0.5Prec Rec F 0.5
S2SBART 375MLang8
HSK1.2M 22.31 10.14 17.99 22.13 9.66 17.59
S2SBART 375M Ours 1061 21.08 10.54 17.57 22.09 10.62 18.16
GrammarGPT 7B Ours 1061 42.42 16.87 32.56 46.67 18.58 35.84
Table 6. Ablation study of our method.
DataWord-level Char-level
Prec Rec F 0.5Prec Rec F 0.5
w/o AugmentationHuman-annotated 12.20 1.51 5.04 13.89 1.48 5.19
ChatGPT-generated 30.38 7.21 18.49 30.86 7.35 18.83
Hybrid dataset 41.76 11.45 27.30 44.32 11.50 28.22
w/ AugmentationHuman-annotated 15.46 4.52 10.42 16.48 4.44 10.68
ChatGPT-generated 43.75 6.33 20.04 44.90 6.49 20.56
Hybrid dataset 42.42 16.87 32.56 46.87 18.58 35.84
4.4 Experimental Results
To validate the effectiveness of our method, we conducted a comparison between
our GrammarGPT and the state-of-the-art (SOTA) baseline, S2S BART [26].
S2SBART utilizes Chinese BART as the pre-trained model and fine-tunes it on
the Lang8 [28] and HSK [23] datasets, which consist of approximately 1.2 million
parallel data samples. We also fine-tuned S2S BART on the hybrid dataset that
we constructed, and the results are presented in Table 5.
Remarkably, we observed that S2S BART trained on our 1k hybrid dataset
achieved 17.57 and 18.16 F0.5on Word-level and Char-level separately, which is
comparable to that baseline model using the 1.2M data from foreign language
speakers. We attribute this to the significant discrepancy between the gram-
matical errors made by foreign language speakers and native Chinese speakers,
making it challenging to effectively improve the performance of native CGEC
by relying solely on data from foreign language speakers. These results further
highlight the effectiveness of our method in constructing a hybrid dataset that
contains native Chinese grammatical errors.
Furthermore, our GrammarGPT exhibited substantial improvement with
only about 1k data samples for fine-tuning, achieving 32.56 and 35.84 F0.5, re-
spectively. It is almost double the performance of baseline models, showcasing
the remarkable potential of open-source LLMs in native CGEC. The final result
on the official test set shows that our GrammarGPT ranks 3rd13.
13https://github.com/masr2000/NaCGEC

--- PAGE 10 ---
10 Fan et al.
4.5 Ablation Study
In our analysis of the impact of our contributions, namely the construction of
a hybrid dataset and the error-invariant augmentation method, we present the
results in Table 6.
Notably, the model trained on ChatGPT-generated data consistently out-
performs that trained the human-annotated data, irrespective of whether data
augmentation is applied. We attribute this observation to two primary reasons.
First, the quantity of human-annotated data is smaller than the data generated
by ChatGPT due to the high cost of human annotation. Second, grammatical
errors without clues are more challenging to correct.
Additionally, our hybrid dataset demonstrates the potential for enhancing
the performance of native CGEC. This finding substantiates the effectiveness
of our approach in constructing the hybrid dataset consisting of native Chinese
grammatical errors.
Moreover, by employing the error-invariant augmentation method, we ob-
serve our model trained on hybrid dataset has significant improvements in Re-
call and F 0.5metrics but only minor improvements in Precision. It indicates that
our augmentation technique enhances the model’s ability to detect grammati-
cal errors by forcing the model to pay more attention to grammar errors in the
augmentation data.
5 Conclusion
In this paper, we introduce GrammarGPT, an open-source Large Language
Model (LLM) specifically designed for native Chinese grammatical error correc-
tion. We first construct a hybrid dataset containing approximately 1k parallel
data samples. It comprises both ChatGPT-generated data and human-annotated
data for dealing with grammatical errors with and without clues. Additionally,
we introduced an error-invariant augmentation method to improve the model’s
capabilities in native Chinese grammatical error correction by forcing the model
to pay more attention to grammar errors in the augmentation data. We further
fine-tune the open-source large-scale language model on the constructed dataset.
Experimental results and in-depth analysis demonstrate the effectiveness of our
GrammarGPT in native Chinese grammatical error correction.
Acknowledge
This work is supported by the National Natural Science Foundation of China
(Grant No. 62271432) and the Guangdong Provincial Key Laboratory of Big
Data Computing, The Chinese University of Hong Kong, Shenzhen (Grant No.
B10120210117).

--- PAGE 11 ---
GrammarGPT 11
References
1. Chen, F., Feng, Y.: Chain-of-Thought Prompt Distillation for Multimodal Named
Entity and Multimodal Relation Extraction. ArXiv preprint arXiv:2306.14122
(2023)
2. Chen, Z., Jiang, F., Chen, J., Wang, T., Yu, F., Chen, G., Zhang, H., Liang, J.,
Zhang, C., Zhang, Z., et al.: Phoenix: Democratizing ChatGPT across languages.
arXiv preprint arXiv:2304.10453 (2023)
3. Dahlmeier, D., Ng, H.T.: Better Evaluation for Grammatical Error Correction.
In: Proceedings of the 2012 Conference of the North American Chapter of the
Association for Computational Linguistics: Human Language Technologies. pp.
568–572. Association for Computational Linguistics, Montr´ eal, Canada (Jun 2012)
4. Fang, T., Yang, S., Lan, K., Wong, D.F., Hu, J., Chao, L.S., Zhang, Y.: Is Chat-
GPT a Highly Fluent Grammatical Error Correction System? A Comprehensive
Evaluation. arXiv preprint arXiv:2304.01746 (2023)
5. Hinson, C., Huang, H.H., Chen, H.H.: Heterogeneous Recycle Generation for Chi-
nese Grammatical Error Correction. In: Proceedings of the 28th International Con-
ference on Computational Linguistics. pp. 2191–2201 (2020)
6. Ho, N., Schmid, L., Yun, S.Y.: Large Language Models Are Reasoning Teachers.
arXiv preprint arXiv:2212.10071 (2022)
7. Katsumata, S., Komachi, M.: Stronger Baselines for Grammatical Error Correction
Using a Pretrained Encoder-Decoder Model. In: Proceedings of the 1st Conference
of the Asia-Pacific Chapter of the Association for Computational Linguistics and
the 10th International Joint Conference on Natural Language Processing. pp. 827–
832 (2020)
8. Li, J., Guo, J., Zhu, Y., Sheng, X., Jiang, D., Ren, B., Xu, L.: Sequence-to-Action:
Grammatical Error Correction with Action Guided Sequence Generation. Proceed-
ings of the AAAI Conference on Artificial Intelligence 36(10), 10974–10982 (2022)
9. Liang, D., Zheng, C., Guo, L., Cui, X., Xiong, X., Rong, H., Dong, J.: BERT
Enhanced Neural Machine Translation and Sequence Tagging Model for Chinese
Grammatical Error Diagnosis. In: Proceedings of the 6th Workshop on Natural
Language Processing Techniques for Educational Applications. pp. 57–66. Associ-
ation for Computational Linguistics (2020)
10. Ma, S., Li, Y., Sun, R., Zhou, Q., Huang, S., Zhang, D., Yangning, L., Liu, R., Li,
Z., Cao, Y., Zheng, H., Shen, Y.: Linguistic Rules-Based Corpus Generation for
Native Chinese Grammatical Error Correction. In: Findings of the Association for
Computational Linguistics: EMNLP 2022. pp. 576–589 (2022)
11. Ng, H.T., Wu, S.M., Briscoe, T., Hadiwinoto, C., Susanto, R.H., Bryant, C.: The
CoNLL-2014 Shared Task on Grammatical Error Correction. In: Proceedings of
the Eighteenth Conference on Computational Natural Language Learning: Shared
Task. pp. 1–14 (2014)
12. Peng, B., Li, C., He, P., Galley, M., Gao, J.: Instruction Tuning with GPT-4. arXiv
preprint arXiv:2304.03277 (2023)
13. Rao, G., Gong, Q., Zhang, B., Xun, E.: Overview of NLPTEA-2018 Share Task
Chinese Grammatical Error Diagnosis. In: Proceedings of the 5th Workshop on
Natural Language Processing Techniques for Educational Applications. pp. 42–51
(2018)
14. Rao, G., Yang, E., Zhang, B.: Overview of NLPTEA-2020 Shared Task for Chi-
nese grammatical error diagnosis. In: Proceedings of the 6th Workshop on Natural
Language Processing Techniques for Educational Applications. pp. 25–35 (2020)

--- PAGE 12 ---
12 Fan et al.
15. Rothe, S., Mallinson, J., Malmi, E., Krause, S., Severyn, A.: A Simple Recipe for
Multilingual Grammatical Error Correction. In: Proceedings of the 59th Annual
Meeting of the Association for Computational Linguistics and the 11th Interna-
tional Joint Conference on Natural Language Processing (Volume 2: Short Papers).
pp. 702–707 (2021)
16. Sanh, V., Webson, A., Raffel, C., Bach, S.H., Sutawika, L., Alyafeai, Z., Chaffin,
A., Stiegler, A., Scao, T.L., Raja, A., et al.: Multitask Prompted Training Enables
Zero-shot Task Generalization. arXiv preprint arXiv:2110.08207 (2021)
17. Scao, T.L., Fan, A., Akiki, C., Pavlick, E., Ili´ c, S., Hesslow, D., Castagn´ e, R.,
Luccioni, A.S., Yvon, F., Gall´ e, M., et al.: Bloom: A 176B-parameter Open-access
Multilingual Language Model. arXiv preprint arXiv:2211.05100 (2022)
18. Touvron, H., Lavril, T., Izacard, G., Martinet, X., Lachaux, M.A., Lacroix, T.,
Rozi` ere, B., Goyal, N., Hambro, E., Azhar, F., Rodriguez, A., Joulin, A., Grave,
E., Lample, G.: LLaMA: Open and Efficient Foundation Language Models (2023)
19. Wang, P., Wang, Z., Li, Z., Gao, Y., Yin, B., Ren, X.: SCOTT: Self-Consistent
Chain-of-Thought Distillation. arXiv preprint arXiv:2305.01879 (2023)
20. Wang, X., Zhou, W., Zu, C., Xia, H., Chen, T., Zhang, Y., Zheng, R., Ye, J.,
Zhang, Q., Gui, T., et al.: InstructUIE: Multi-task Instruction Tuning for Unified
Information Extraction. arXiv preprint arXiv:2304.08085 (2023)
21. Wei, J., Bosma, M., Zhao, V.Y., Guu, K., Yu, A.W., Lester, B., Du, N., Dai, A.M.,
Le, Q.V.: Finetuned Language Models Are Zero-shot Learners. arXiv preprint
arXiv:2109.01652 (2021)
22. Yu, J., Zhu, J., Wang, Y., Liu, Y., Chang, H., Nie, J., Kong, C., Cong, R., XinLiu,
An, J., Lu, L., Fang, M., Zhu, L.: Taoli LLaMA. https://github.com/blcuicall/
taoli (2023)
23. Zhang, B.: Features and Functions of the HSK Dynamic Composition Corpus.
International Chinese Language Education 4, 71–79 (2009)
24. Zhang, B., Yang, H., Liu, X.Y.: Instruct-FinGPT: Financial Sentiment Analysis
by Instruction Tuning of General-Purpose Large Language Models. arXiv preprint
arXiv:2306.12659 (2023)
25. Zhang, H., Chen, J., Jiang, F., Yu, F., Chen, Z., Li, J., Chen, G., Wu, X., Zhang,
Z., Xiao, Q., et al.: HuatuoGPT, towards Taming Language Model to Be a Doctor.
arXiv preprint arXiv:2305.15075 (2023)
26. Zhang, Y., Li, Z., Bao, Z., Li, J., Zhang, B., Li, C., Huang, F., Zhang, M.:
MuCGEC: a Multi-Reference Multi-Source Evaluation Dataset for Chinese Gram-
matical Error Correction. In: Proceedings of the 2022 Conference of the North
American Chapter of the Association for Computational Linguistics: Human Lan-
guage Technologies. pp. 3118–3130 (2022)
27. Zhang, Y., Zhang, B., Jiang, H., Li, Z., Li, C., Huang, F., Zhang, M.: NaS-
GEC: a Multi-Domain Chinese Grammatical Error Correction Dataset from Native
Speaker Texts. arXiv preprint arXiv:2305.16023 (2023)
28. Zhao, Y., Jiang, N., Sun, W., Wan, X.: Overview of the NLPCC 2018 Shared
Task: Grammatical Error Correction. In: Natural Language Processing and Chi-
nese Computing: 7th CCF International Conference, NLPCC 2018, Hohhot, China,
August 26–30, 2018, Proceedings, Part II 7. pp. 439–445. Springer (2018)
29. Zhao, Z., Wang, H.: MaskGEC: Improving Neural Grammatical Error Correction
via Dynamic Masking. Proceedings of the AAAI Conference on Artificial Intelli-
gence 34(01), 1226–1233 (2020)

# 2110.15248.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/multilingual/2110.15248.pdf
# Kích thước tệp: 401468 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Bài báo này được xuất bản tại W-NUT 2021 – vui lòng trích dẫn phiên bản đã xuất bản https://aclanthology.org/2021.wnut-1.54 .
ÚFAL tại MultiLexNorm 2021: Cải thiện Chuẩn hóa Từ vựng Đa ngôn ngữ
bằng cách Tinh chỉnh ByT5
David Samuel và Milan Straka
Đại học Charles,
Khoa Toán học và Vật lý,
Viện Ngôn ngữ học Hình thức và Ứng dụng
{samuel,straka}@ufal.mff.cuni.cz

Tóm tắt
Chúng tôi trình bày giải pháp chiến thắng cho nhiệm vụ chung Chuẩn hóa Từ vựng Đa ngôn ngữ (MultiLexNorm) tại W-NUT 2021 (van der Goot et al., 2021a), đánh giá các hệ thống chuẩn hóa từ vựng trên 12 bộ dữ liệu mạng xã hội trong 11 ngôn ngữ. Chúng tôi dựa giải pháp của mình trên một mô hình ngôn ngữ được tiền huấn luyện ở mức byte, ByT5 (Xue et al., 2021a), mà chúng tôi tiếp tục tiền huấn luyện trên dữ liệu tổng hợp và sau đó tinh chỉnh trên dữ liệu chuẩn hóa thực tế. Hệ thống của chúng tôi đạt được hiệu suất tốt nhất với khoảng cách lớn trong đánh giá nội tại, và cũng đạt hiệu suất tốt nhất trong đánh giá ngoại tại thông qua phân tích cú pháp phụ thuộc. Mã nguồn được phát hành tại https://github.com/ufal/ multilexnorm2021 và các mô hình đã tinh chỉnh tại https://huggingface.co/ufal .

1 Giới thiệu
Mọi người tạo ra văn bản bằng ngôn ngữ tự nhiên mỗi phút mỗi ngày. Tuy nhiên, trong nhiều trường hợp, ví dụ như trên mạng xã hội như Twitter, những văn bản đó không tuân thủ phong cách chính thức. Thay vào đó, chúng ở dạng thông tục, hoàn toàn có thể hiểu được đối với người khác, nhưng lại thách thức đối với việc xử lý ngôn ngữ tự nhiên tự động. Để làm cho việc xử lý các văn bản như vậy khả thi hơn, nhiệm vụ chuẩn hóa từ vựng có thể được sử dụng để thay thế các dạng đầu vào bằng các biến thể chính tắc (chính thức hơn, được chuẩn hóa từ vựng) của chúng.

Mục tiêu của nhiệm vụ chung W-NUT 2021: Chuẩn hóa Từ vựng Đa ngôn ngữ (MultiLexNorm) (van der Goot et al., 2021a) là đánh giá các hệ thống chuẩn hóa từ vựng của người tham gia trên 12 bộ dữ liệu mạng xã hội trong 11 ngôn ngữ, bao gồm hai bộ dữ liệu chuyển đổi mã. Cả đánh giá nội tại và ngoại tại đều được thực hiện, trong đó đánh giá ngoại tại được đo thông qua phân tích cú pháp phụ thuộc được thực hiện trên dữ liệu đã chuẩn hóa.

Gần đây, các mô hình được tiền huấn luyện lớn như BERT (Devlin et al., 2019) hoặc T5 (Raffel et al., 2020) đã chứng minh hiệu suất vượt trội trong nhiều nhiệm vụ NLP khi được huấn luyện trong cài đặt học chuyển giao. Theo hướng đó, chúng tôi tiếp cận nhiệm vụ chuẩn hóa từ vựng chung như một việc tinh chỉnh của một mô hình được tiền huấn luyện lớn, cụ thể là mô hình ngôn ngữ sinh đa ngôn ngữ ở mức byte ByT5 (Xue et al., 2021a).

Hệ thống của chúng tôi đạt được hiệu suất tốt nhất trong nhiệm vụ chung, cả trong đánh giá nội tại và ngoại tại. Trong đánh giá nội tại, hệ thống của chúng tôi đạt 67,3% giảm lỗi so với đường cơ sở để-nguyên-như-vậy; hệ thống tốt thứ hai có 53,6%. Mã nguồn được phát hành tại https://github.com/ufal/multilexnorm2021 và các mô hình đã tinh chỉnh có sẵn trong HuggingFace Transformers (Wolf et al., 2020) tại https://huggingface.co/ufal .

2 Nghiên cứu liên quan
Chuẩn hóa từ vựng có thể được coi là một biến thể đơn giản hóa của một vấn đề được nghiên cứu kỹ là sửa lỗi ngữ pháp (GEC). Grundkiewicz et al. (2019) tiếp cận GEC như một nhiệm vụ dịch máy thần kinh sử dụng kiến trúc Transformer (Vaswani et al., 2017), được tiền huấn luyện sử dụng một lượng lớn dữ liệu tổng hợp được tạo ra bằng các chỉnh sửa ở mức ký tự và từ. Gần đây, Rothe et al. (2021) đã trình bày một hệ thống GEC dựa trên mT5 đa ngôn ngữ (Xue et al., 2021b), đạt kết quả hiện đại trên một số bộ dữ liệu với kích thước mô hình xxl khổng lồ với 13B tham số.

Trong khi các hệ thống GEC đã đề cập là tự hồi quy, chuẩn hóa từ vựng có thể dễ dàng được giải quyết theo cách không tự hồi quy, bởi vì việc chuẩn hóa các từ khác nhau tương đối độc lập. Bên cạnh đó, các mô hình không tự hồi quy thành công đã được đề xuất gần đây cho GEC tổng quát (Awasthi et al., 2019; Omelianchuk et al., 2020).

Mặc dù các mô hình ngôn ngữ được tinh chỉnh đã được sử dụng thành công trong các hệ thống GEC hiện đại, điều này chưa phải là trường hợp trong lĩnh vực chuẩn hóa từ vựng (Muller et al., 2019; Lourentzou et al., 2019). MoNoise (van der Goot, 2019) là một công cụ chuẩn hóa từ vựng đa ngôn ngữ có sẵn công khai đạt hiệu suất tốt (một phiên bản cải tiến của hệ thống sẽ đứng thứ ba trong đánh giá nội tại nhiệm vụ chung). Nó sử dụng từ điển Aspell, nhúng FastText (Bojanowski et al., 2017) và các đặc trưng ngôn ngữ thủ công, nhưng không có nhúng ngữ cảnh.

--- TRANG 2 ---
social
ppl
r
gr8Social
people
are
great<X> s o c i a l <Y> ␣ p p l ␣ r ␣ g r 8
s o c i a l ␣ <X> p p l <Y> ␣ r ␣ g r 8
s o c i a l ␣ p p l ␣ <X> r <Y> ␣ g r 8
s o c i a l ␣ p p l ␣ r ␣ <X> g r 8 <Y>S o c i a l
p e o p l e
a r e
g r e a tDữ liệu Đầu vào s Đầu raHình 1: Đầu vào và đầu ra của mô hình chuẩn hóa từ vựng của chúng tôi. Các token sentinel ByT5 <X> và <Y> đánh dấu từ cần được chuẩn hóa.

3 Mô hình
Mô hình của chúng tôi dựa trên một mô hình đa ngôn ngữ được tiền huấn luyện lớn. Theo Bommasani et al. (2021), chúng tôi gọi các mô hình như vậy (như BERT hoặc T5) là các mô hình nền tảng.

Cụ thể, chúng tôi sử dụng mô hình nền tảng ByT5 (Xue et al., 2021a). Đây là một mô hình chuỗi-tới-chuỗi sinh ở mức byte, xử lý một chuỗi byte của mã hóa UTF-8 ở đầu vào và tạo ra một chuỗi byte mã hóa UTF-8 ở đầu ra. Các mô hình ByT5 được đề xuất như một thay thế cho các mô hình nền tảng mT5 đa ngôn ngữ (Xue et al., 2021b) và đã được chứng minh hoạt động đáng kể tốt trên dữ liệu văn bản nhiễu (so với mT5 dựa trên subword), như TWEETQA (Xiong et al., 2019).

3.1 Định dạng Đầu vào và Đầu ra
Chúng tôi bắt đầu bằng cách tóm tắt lại nhiệm vụ tiền huấn luyện của mô hình ByT5. Câu đầu vào (bao gồm cả dấu cách) được biểu diễn dưới dạng một chuỗi byte của mã hóa UTF-8, và các đoạn khoảng 20 byte được che mặt bằng các token sentinel đặc biệt. Mục tiêu của mô hình là tái tạo lại tất cả các đoạn bị che mặt. Chúng tôi minh họa nhiệm vụ này một cách trực quan trong Hình 2.

Social people are great
<X> ␣ p e o p l e ␣ a <Y> e a t
<X> S o c i a l <Y> r e ␣ g r <Z>Gốc:
Đầu vào:
Đầu ra:Hình 2: Nhiệm vụ tiền huấn luyện được sử dụng trong mô hình ByT5 (Xue et al., 2021a). <X>, <Y> và <Z> là các token sentinel.

Đối với chuẩn hóa từ vựng, chúng tôi có thể trực tiếp sử dụng câu chưa chuẩn hóa làm đầu vào và câu đã chuẩn hóa làm đầu ra (một cách tiếp cận được sử dụng bởi Rothe et al. (2021) cho GEC). Tuy nhiên, chúng tôi lo ngại rằng cách tiếp cận như vậy sẽ quá khác biệt so với việc tiền huấn luyện ByT5, và hơn nữa, nó sẽ không cho phép tái tạo sự căn chỉnh của các token đã chuẩn hóa khi một từ bị loại bỏ trong quá trình chuẩn hóa hoặc được tách thành nhiều từ.

Thay vào đó, chúng tôi chọn một cách tiếp cận khác được minh họa trong Hình 1. Đối với mỗi từ đầu vào, chúng tôi xây dựng một đầu vào ByT5 riêng biệt, trong đó chúng tôi đánh dấu điểm bắt đầu và kết thúc của từ đang xét bằng hai token sentinel. Sau đó chúng tôi yêu cầu mô hình chỉ tạo ra việc chuẩn hóa của từ đó. Cách tiếp cận như vậy chuẩn hóa từng từ đầu vào một cách độc lập, và chúng tôi coi nó khá giống với nhiệm vụ tiền huấn luyện ByT5 ban đầu. Thật không may, nó yêu cầu mã hóa các chuỗi đầu vào khác nhau cho mỗi từ đầu vào, điều này đáng kể không hiệu quả, ngay cả khi chúng ta có thể thực hiện chuẩn hóa tất cả các từ song song.

--- TRANG 3 ---
tiền huấn luyện
tự giám sát
tiền huấn luyện
tổng hợp
tinh chỉnhmC4 đa ngôn ngữ không nhãn
Wikipedia với nhiễu tổng hợp
Dữ liệu huấn luyện được chú thích thủ côngHình 3: Ba giai đoạn huấn luyện của các mô hình của chúng tôi: tiền huấn luyện ByT5 ban đầu, tiền huấn luyện trên dữ liệu tổng hợp và tinh chỉnh cuối cùng trên dữ liệu thực tế.

3.2 Tiền huấn luyện trên Dữ liệu Tổng hợp
Tinh chỉnh trực tiếp mô hình ByT5 với dữ liệu huấn luyện có giám sát sẽ không mang lại hiệu suất rất cao, xét rằng nhiệm vụ chuẩn hóa (bất chấp nỗ lực của chúng tôi) vẫn khá khác biệt so với nhiệm vụ tiền huấn luyện, và lượng dữ liệu huấn luyện có sẵn khá thấp.

Do đó, trước khi tinh chỉnh, chúng tôi trước tiên tiền huấn luyện mô hình ByT5 sử dụng dữ liệu tổng hợp, như minh họa trong Hình 3. Lưu ý rằng từ bây giờ, với "tiền huấn luyện" chúng tôi có nghĩa là việc huấn luyện mô hình nền tảng ByT5 sử dụng dữ liệu chuẩn hóa từ vựng tổng hợp.

Chúng tôi xây dựng dữ liệu tổng hợp bằng cách sửa đổi dữ liệu sạch theo cách sau:

Nếu một từ có mặt trong đầu ra đã chuẩn hóa trong dữ liệu huấn luyện, nó được thay thế bằng một trong những đầu vào dữ liệu huấn luyện tương ứng (có thể chưa chuẩn hóa), tỷ lệ thuận với số lần xuất hiện. Ví dụ, chúng tôi thay đổi "people" thành "ppl" với xác suất 39,7% trong bộ dữ liệu tiếng Anh hoặc "ikke" thành "ik" với cơ hội 4,97% trong bộ dữ liệu tiếng Đan Mạch.

Một phần lớn những thay đổi cần thiết có thể được thực hiện như các sửa đổi đơn giản ở mức ký tự. Do đó, chúng tôi tổng hợp dữ liệu bằng cách đảo ngược những thay đổi này. Chúng là 1) loại bỏ dấu thanh (ví dụ, thay thế "š" bằng "s" với cơ hội 16,3% trong tiếng Slovenia), 2) thay đổi viết hoa (ví dụ, viết thường chữ cái đầu viết hoa với cơ hội 1,0% trong tiếng Thổ Nhĩ Kỳ), 3) loại bỏ dấu nháy đơn (xác suất 46,8% trong tiếng Anh), và 4) các sửa đổi khác (ví dụ, đơn giản hóa "qu" thành "k" trong tiếng Tây Ban Nha với xác suất 2,0%).

Dữ liệu huấn luyện tự nhiên chứa một lượng lớn các lỗi chính tả khác nhau, thường do gõ không chính xác trên bàn phím. Để mô phỏng hành vi này, chúng tôi thay đổi các từ bằng cách bỏ qua một số ký tự, thay đổi hoặc chèn một số ký tự (có khả năng cao hơn đối với những ký tự gần nhau trên bàn phím máy tính), và bằng cách đảo ngược hai ký tự liên tiếp. Để cho một ví dụ, xác suất tạo ra một lỗi chính tả nhân tạo trong tiếng Ý là 0,458%.

Một số sửa đổi là độc nhất cho một ngôn ngữ cụ thể. Ví dụ, các dạng số nhiều trong tiếng Indonesia có thể được tạo ra bằng cách nhân đôi các dạng số ít. Khi người dùng muốn tiết kiệm thời gian khi viết bằng tiếng Indonesia, đôi khi họ biểu thị số nhiều bằng cách đơn giản thêm "2" vào dạng số ít. Chúng tôi đảo ngược phép biến đổi này với xác suất 33,3% (do đó, "laki-lakinya" trở thành "laki2nya").

7 bộ dữ liệu trong nhiệm vụ chung này tách hoặc gộp từ. Chúng tôi tổng hợp tách/gộp từ trên bộ dữ liệu sạch để mô hình hóa những hành động này. Ví dụ, xác suất gộp hai từ trong tiếng Hà Lan là 5,99% và tách một từ là 0,0565%.

Để tăng tốc độ gõ, người dùng sửa đổi ngôn ngữ của họ theo nhiều cách khác nhau – ví dụ như bỏ qua nguyên âm hoặc rút ngắn từ thành tiền tố. Mặt khác, họ lặp lại một số ký tự nhất định để làm cho tin nhắn của họ biểu cảm hơn. Chúng tôi bao gồm những biến thể này trong các bộ dữ liệu tổng hợp để gần hơn với dữ liệu thực.

Để biết thêm chi tiết, vui lòng tham khảo mã nguồn. Điều quan trọng cần lưu ý là tất cả các xác suất đều được ước tính từ dữ liệu huấn luyện. Do đó việc tiền huấn luyện tổng hợp không thể được coi là hoàn toàn không giám sát; người ta sẽ cần kiến thức chuyên môn để mở rộng loại tiền huấn luyện này trên một ngôn ngữ không có dữ liệu chú thích về chuẩn hóa từ vựng.

Chúng tôi cần đảm bảo rằng hầu hết dữ liệu gốc (trước các sửa đổi tổng hợp) đều sạch. Vì chúng tôi cũng muốn một lượng lớn văn bản đa ngôn ngữ, chúng tôi đã chọn sử dụng các bản sao công khai có sẵn của Wikipedia. Chúng tôi loại bỏ bất kỳ dòng nào ngắn hơn 32 ký tự hoặc kết thúc bằng dấu hai chấm (để loại bỏ tiêu đề), phân đoạn các dòng thành câu bằng Stanza (Qi et al., 2020) và tokenize bằng tokenizer CMU-ARK (một công cụ được sử dụng tiêu chuẩn để tokenize văn bản từ Twitter).

--- TRANG 4 ---
Code Language Original Source WordsWords
split/mergedCaps% words
normedMFR
ERR
DA Danish Plank et al. (2020) 11 816 3 3 9.25 49.68
DE German Sidarenka et al. (2013) 25 157 3 3 17.96 32.09
EN English Baldwin et al. (2015) 73 806 3 7 6.90 64.93
ES Spanish Alegria et al. (2013) 13 827 7 7 7.69 25.57
HR Croatian Ljubeši ´c et al. (2017a) 75 276 7 7 8.89 36.52
ID-EN Indonesian-English Barik et al. (2019) 23 124 3 7 12.16 61.17
IT Italian van der Goot et al. (2020) 14 641 3 3 7.32 16.83
NL Dutch Schuur (2020) 23 053 3 3 28.29 37.70
SR Serbian Ljubeši ´c et al. (2017b) 91 738 7 7 7.65 42.62
SL Slovenian Erjavec et al. (2017) 75 276 7 7 15.62 56.71
TR Turkish Çolako ˘glu et al. (2019) 7 949 3 3 37.02 14.53
TR-DE Turkish-German van der Goot and Çetino ˘glu (2021) 16 546 3 3 24.14 22.09

Bảng 1: Các bộ dữ liệu MultiLexNorm và thuộc tính của chúng – số từ, có tách/gộp từ hay không, có sửa viết hoa hay không, số lượng tương đối của từ đã chuẩn hóa và hiệu suất của đường cơ sở thay-thế-phổ-biến-nhất (Phần 5).

3.3 Tinh chỉnh
Việc tinh chỉnh cuối cùng của mô hình đã tiền huấn luyện có thể được thực hiện một cách đơn giản trên dữ liệu huấn luyện (gọi là tinh chỉnh cơ sở). Tuy nhiên, chúng tôi cũng xem xét việc tinh chỉnh trên hỗn hợp của cả dữ liệu huấn luyện thực tế và dữ liệu tổng hợp (với tỷ lệ 1:1) để tránh overfitting (tinh chỉnh hỗn hợp).

3.4 Suy luận
Để dự đoán các câu đã chuẩn hóa trong quá trình suy luận, mỗi token-từ được xử lý độc lập, tương tự như huấn luyện (Hình 1). Bộ giải mã ByT5 tự động tạo ra từng token một cách tự hồi quy, bằng cách tham lam hoặc thông qua tìm kiếm beam. Khi sử dụng tìm kiếm beam, chúng tôi tạo ra nhiều chuỗi ứng viên, và tìm kiếm beam tự động gán điểm dự đoán cho mỗi chuỗi. Những điểm này sau đó có thể được sử dụng để tổng hợp các dự đoán từ nhiều mô hình trong một ensemble.

4 Thí nghiệm
Nhiệm vụ chung MultiLexNorm bao gồm 12 bộ dữ liệu mạng xã hội trong 11 ngôn ngữ, bao gồm hai bộ dữ liệu chuyển đổi mã. Tất cả các bộ dữ liệu này đều dựa trên dữ liệu Twitter, với các bộ dữ liệu tiếng Đan Mạch và tiếng Hà Lan cũng bao gồm dữ liệu từ các nguồn khác. Các bộ dữ liệu, nguồn gốc và một số thuộc tính của chúng được liệt kê trong Bảng 1.

Chúng tôi huấn luyện một mô hình độc lập cho mỗi bộ dữ liệu. Việc tiền huấn luyện bắt đầu từ biến thể nhỏ của ByT5, chứa 300M tham số. Chúng tôi giữ nguyên tất cả các siêu tham số của mô hình, bao gồm tỷ lệ dropout 10%. Việc huấn luyện sử dụng kích thước batch 128 và bộ tối ưu hóa AdaFactor (Shazeer và Stern, 2018) để giảm việc sử dụng bộ nhớ.

Việc tiền huấn luyện được thực hiện bằng dữ liệu tổng hợp được mô tả trong Phần 3.2, trong ít nhất 100 000 bước tối ưu hóa. Chúng tôi sử dụng suy giảm căn bậc hai nghịch đảo với tỷ lệ học tối đa 5×10^-4 và 4 000 bước khởi động.

Giai đoạn tinh chỉnh được thực hiện với tỷ lệ học không đổi 1×10^-4 trong 50 epoch. Chúng tôi xem xét hai cấu hình dữ liệu huấn luyện:

1. Chỉ sử dụng dữ liệu huấn luyện MultiLexNorm, tôn trọng việc chia train/dev (sử dụng 10% dữ liệu huấn luyện làm tập phát triển nếu không có).

2. Bởi vì tập phát triển, nếu có, khá lớn (thường khoảng 30% dữ liệu huấn luyện), chúng tôi cũng xem xét việc huấn luyện trên dữ liệu phát triển. Cụ thể, chúng tôi nối dữ liệu huấn luyện và phát triển, nếu có, và chỉ lấy 3% dữ liệu làm tập phát triển (chỉ để phát hiện lỗi, vì đánh giá trên tập nhỏ như vậy đáng kể nhiễu).

Mô hình thi đấu của chúng tôi được huấn luyện trên bộ dữ liệu kết hợp (tùy chọn thứ hai), và dữ liệu tổng hợp được trộn vào (tinh chỉnh hỗn hợp từ Phần 3.3) nếu nó cải thiện hiệu suất phát triển so với tinh chỉnh cơ sở.

--- TRANG 5 ---
5 Kết quả
Những người tham gia MultiLexNorm được phép nộp hai lần chạy. Lần chạy đầu tiên của đội ÚFAL là một mô hình đơn, trong khi lần chạy thứ hai là một ensemble của 4 mô hình. Chúng tôi thực hiện ensembling bằng cách xem xét cho mỗi từ và mỗi mô hình 16 thay thế bao gồm xác suất của chúng (sử dụng bộ giải mã tìm kiếm beam), và tạo ra thay thế với xác suất trung bình cao nhất.

Ngoài các hệ thống của người tham gia, một số đường cơ sở cũng được đánh giá: LAI (để-nguyên-như-vậy), MFR (thay thế phổ biến nhất dựa trên dữ liệu huấn luyện) và công cụ MoNoise (van der Goot, 2019).

5.1 Đánh giá Nội tại
Đánh giá nội tại được thực hiện bằng Tỷ lệ Giảm Lỗi (ERR), đó là độ chính xác ở mức từ được chuẩn hóa theo số lượng thay thế trong bộ dữ liệu. Chính thức, nếu chúng ta ký hiệu hệ thống không chuẩn hóa bất kỳ từ nào là để-nguyên-như-vậy, chúng ta có thể định nghĩa ERR là

ERR = (độ chính xác_hệ thống - độ chính xác_để-nguyên-như-vậy) / (1.0 - độ chính xác_để-nguyên-như-vậy)

Bảng xếp hạng cuối cùng được xác định bởi ERR được tính trung bình macro trên tất cả các bộ dữ liệu.

Kết quả đánh giá nội tại MultiLexNorm được cung cấp trong Bảng 2. Hệ thống của chúng tôi đạt hiệu suất tốt nhất với khoảng cách lớn – mô hình đơn đạt 66,2% ERR trung bình macro, và ensemble mô hình thậm chí cao hơn một điểm phần trăm, 67,3%. Điều đó cao hơn 13,7% so với kết quả tốt thứ hai là 53,6%. Mô hình ensemble của chúng tôi đạt kết quả tốt nhất trên tất cả các bộ dữ liệu, ngoại trừ tiếng Đan Mạch, nơi mô hình đơn của chúng tôi tốt hơn, và cho tiếng Tây Ban Nha, nơi nó bị vượt qua bởi hệ thống khác.

5.2 Đánh giá Ngoại tại
Để đánh giá tác động của chuẩn hóa từ vựng đối với các ứng dụng hạ nguồn, MultiLexNorm xem xét phân tích cú pháp phụ thuộc. Đầu tiên, các mô hình phân tích cú pháp phụ thuộc được huấn luyện sử dụng bộ phân tích MaChAmp (van der Goot et al., 2021b) trên một số treebank từ Universal Dependencies 2.8 (Zeman et al., 2021). Các treebank với phong cách chính thức được sử dụng (tức là không phải dữ liệu từ mạng xã hội), cụ thể là German-GSD, English-EWT, Italian-ISDT và Turkish-IMST. Sau đó, các hệ thống của người tham gia MultiLexNorm được sử dụng để chuẩn hóa 7 treebank mạng xã hội, sau đó được phân tích bằng các mô hình phân tích được mô tả và đánh giá bằng chỉ số điểm gắn nhãn (LAS). Để biết chi tiết, vui lòng xem bài báo tổng quan nhiệm vụ chung MultiLexNorm.

Kết quả đánh giá ngoại tại MultiLexNorm được trình bày trong Bảng 3. Hệ thống của chúng tôi cũng đạt hiệu suất tốt nhất trong trung bình macro tổng thể và trong 4 trên 7 treebank. Nhìn chung, sự khác biệt điểm LAS nhỏ hơn nhiều so với chỉ số đánh giá nội tại ERR, nhưng bảng xếp hạng trong cả hai đánh giá cho thấy nhiều điểm tương đồng. Một sự khác biệt đáng chú ý là đường cơ sở MFR, hoạt động đáng kể tốt trong đánh giá ngoại tại.

5.3 Nghiên cứu Ablation
Để định lượng tác động của các siêu tham số khác nhau của hệ thống, Bảng 4 trình bày đánh giá nội tại của một số thí nghiệm ablation.

Mô hình Nền tảng: Chúng tôi so sánh các biến thể nhỏ của mô hình nền tảng mT5 và ByT5 khi chỉ sử dụng tinh chỉnh (và không tiền huấn luyện trên dữ liệu tổng hợp). Trong cài đặt này, mô hình ByT5 đạt kết quả tốt hơn đáng kể (59,2% ERR trung bình so với 33,6%). Do đó chúng tôi không thí nghiệm thêm với mô hình mT5.

Giai đoạn Tiền huấn luyện và Tinh chỉnh: Giai đoạn tiền huấn luyện cải thiện kết quả đáng kể, đạt 64,8% ERR so với 59,2% ERR không có tiền huấn luyện. Chúng tôi cũng đánh giá mô hình chỉ sau giai đoạn tiền huấn luyện – 31,3% ERR thu được khá thấp, tệ hơn đường cơ sở MFR và hầu hết các hệ thống đã nộp.

Dữ liệu Tinh chỉnh: Đầu tiên, chúng tôi xem xét tác động của việc tinh chỉnh hoàn toàn trên dữ liệu huấn luyện MultiLexNorm (tinh chỉnh cơ sở trong Bảng 4), trộn dữ liệu tổng hợp với tỷ lệ 1:1 (tinh chỉnh hỗn hợp), hoặc chọn tùy chọn tốt nhất theo dữ liệu phát triển (tinh chỉnh tốt nhất). Kết quả cho thấy rằng, thật không may, chiến lược chọn biến thể tốt nhất dựa trên hiệu suất phát triển thực sự tệ hơn tinh chỉnh cơ sở thuần túy. Mặt khác, huấn luyện cũng trên dữ liệu phát triển cải thiện hiệu suất đáng kể (từ 64,8% lên 66,2% ERR trung bình).

Giải mã Tìm kiếm Beam: Sử dụng giải mã tìm kiếm beam với kích thước beam 16 hầu như không có tác động so với giải mã tham lam (66,21% ERR trung bình cho cả hai tùy chọn). Chúng tôi giả thuyết không có sự khác biệt bởi vì chúng tôi tạo ra mỗi chuẩn hóa độc lập, vì vậy giải mã tham lam trên các chuỗi mục tiêu nhỏ phục hồi lại lời giải tối ưu với xác suất rất cao. Trong thực tế, do đó đủ để sử dụng giải mã tham lam và tránh các yêu cầu thời gian chạy cao hơn của tìm kiếm beam.

Ensembling: Cuối cùng, việc sử dụng ensemble của 4 mô hình cải thiện hiệu suất một điểm phần trăm từ 66,2% ERR trung bình lên 67,3%.

--- TRANG 6 ---
Team Average DA DE EN ES HR ID-EN IT NL SL SR TR TR-DE
ÚFAL (ensemble) 67.30 68.7 66.2 75.6 59.2 67.7 67.2 47.5 63.6 80.1 74.6 68.6 68.6
ÚFAL (single) 66.21 70.2 65.7 73.8 55.9 67.3 66.2 42.6 62.7 79.8 73.5 68.6 68.2
HEL-LJU 53.58 56.6 59.8 62.0 35.5 56.2 55.3 35.6 45.9 67.0 66.4 51.2 51.2
MoNoise 49.02 51.3 47.0 74.3 45.5 52.6 59.8 21.8 49.5 61.9 59.6 28.2 36.7
TrinkaAI*43.75 45.9 47.3 66.0 61.3 41.3 56.4 15.8 45.7 59.5 44.5 15.5 25.8
thunderml*43.44 46.5 46.6 64.1 60.3 40.1 59.1 11.9 44.0 59.3 44.5 15.9 29.0
team 40.70 48.1 46.1 63.7 21.0 40.4 59.3 13.9 43.7 60.6 46.1 15.9 29.7
learnML 40.30 40.5 43.7 61.6 56.5 38.1 56.2 5.9 42.8 58.2 40.0 14.4 25.7
maet 40.05 48.1 46.1 63.9 21.0 40.4 59.3 5.9 43.7 60.6 46.1 15.9 29.7
MFR 38.37 49.7 32.1 64.9 25.6 36.5 61.2 16.8 37.7 56.7 42.6 14.5 22.1
CL-MoNoise 12.05 7.3 16.5 4.1 5.0 26.4 2.4 0.0 16.2 8.8 20.1 17.6 20.2
BLUE 6.73 49.7 -1.9 26.8 -9.4 -10.1 -7.2 -31.7 -2.1 -1.0 42.6 10.0 15.0
LAI 0.00 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
MaChAmp -21.25 -88.9 -93.4 51.0 25.4 42.6 39.5 -312.9 1.5 56.8 39.4 -12.7 -3.4

Bảng 2: Kết quả đánh giá nội tại MultiLexNorm. Mỗi đội có thể nộp hai hệ thống, chúng tôi hiển thị kết quả tốt nhất trong hai hệ thống. Kết quả chi tiết hơn có sẵn trong bài báo tổng quan (van der Goot et al., 2021a) và trong các bài báo của người tham gia: HEL-LJU (Scherrer and Ljubeši ´c, 2021), TrinkaAI (Kubal and Nagvenkar, 2021), CL-MoNoise (van der Goot, 2021) và BLUE (Bucur et al., 2021).*biểu thị việc nộp trễ.

Team AverageDE
tweedeEN
aaeEN
monoiseEN
tweebank2IT
postwitaIT
twittiroTR
iwt151
ÚFAL (ensemble) 64.17 73.6 62.7 58.6 59.1 68.3 72.2 54.7
ÚFAL (single) 63.98 73.6 62.2 57.9 59.0 68.3 72.2 54.8
HEL-LJU 63.72 73.5 60.6 56.2 60.3 68.1 72.3 55.0
MoNoise 63.44 73.2 62.3 56.8 58.9 67.5 70.7 54.6
MFR 63.31 72.9 60.3 56.7 60.3 67.3 70.7 54.9
TrinkaAI*63.12 72.9 60.2 56.6 59.9 67.0 71.1 54.2
maet 63.09 72.8 59.4 56.6 59.8 67.4 71.1 54.5
team 63.03 72.8 59.4 56.6 59.8 67.2 70.9 54.5
thunderml*63.02 72.7 59.6 56.7 59.2 67.3 71.3 54.2
learnML 62.88 72.3 59.0 56.2 60.0 67.0 71.2 54.5
CL-MoNoise 62.71 72.7 60.9 55.3 58.5 66.5 70.1 55.0
BLUE 62.53 72.6 59.6 54.2 59.8 66.7 70.0 54.8
LAI 62.45 72.7 59.2 53.6 60.0 66.5 70.1 55.0
MaChAmp 61.89 71.3 60.8 54.6 58.0 64.7 69.8 54.1

Bảng 3: Kết quả đánh giá ngoại tại MultiLexNorm thông qua phân tích cú pháp phụ thuộc được đánh giá bằng điểm gắn nhãn (LAS). Mỗi đội có thể nộp hai hệ thống, chúng tôi hiển thị kết quả tốt nhất trong hai hệ thống.*biểu thị việc nộp trễ.

TreebankFoundation mT5 ByT5 ByT5 ByT5 ByT5 ByT5 ByT5 ByT5 ByT5
Pre-training 7 7 3 3 3 3 3 3 3
Fine-tuning base base 7 base mixed best best best best
Training Data train train train train train train trn+dev trn+dev trn+dev
Beam size 1 1 1 1 1 1 1 16 16
Ensemble 7 7 7 7 7 7 7 7 4
Average 33.62 59.23 31.28 64.88 63.52 64.77 66.21 66.21 67.30
Danish 31.65 67.41 49.37 65.82 67.72 65.82 70.25 70.25 68.67
German 42.91 59.35 49.10 63.40 62.50 63.40 65.77 65.65 66.22
English 61.27 70.40 40.15 73.28 72.68 73.28 73.88 73.80 75.60
Spanish -0.21 43.87 9.15 57.59 56.96 56.96 55.93 55.93 59.25
Croatian 38.11 55.15 43.31 63.18 63.03 63.03 67.29 67.29 67.74
Indonesian-English 50.86 63.75 -3.95 65.12 63.92 63.92 66.15 66.15 67.18
Italian -7.92 43.56 -12.87 46.53 35.64 46.53 42.57 42.57 47.52
Dutch 43.18 55.88 43.45 62.03 62.30 62.03 62.70 62.70 63.58
Slovenian 56.48 71.62 57.21 78.08 77.14 78.08 79.89 79.85 80.07
Serbian 43.29 60.99 59.22 71.10 71.83 71.83 73.42 73.55 74.59
Turkish 11.82 59.80 21.79 66.55 65.03 66.55 68.41 68.58 68.58
Turkish-German 31.99 58.98 19.46 65.82 63.45 65.82 68.27 68.19 68.62

Bảng 4: Đánh giá nội tại của các thí nghiệm ablation – chúng tôi xem xét các mô hình nền tảng khác nhau, có thực hiện tiền huấn luyện hay không, chúng tôi sử dụng dữ liệu gì để tinh chỉnh, kích thước beam giải mã và cuối cùng có sử dụng ensemble của các mô hình hay không.

--- TRANG 7 ---
GPUBatch
sizeWords
per secSlowdown
GeForce RTX 3090 1 15.45 5.92 
GeForce RTX 3090 2 28.05 3.26 
GeForce RTX 3090 4 42.15 2.17 
GeForce RTX 3090 8 57.55 1.59 
GeForce RTX 3090 16 84.19 1.09 
GeForce RTX 3090 32 90.20 1.01 
GeForce RTX 3090 64 88.01 1.04 
GeForce RTX 3090 128 91.42 1 
GeForce RTX 3090 256 87.77 1.04 
GeForce RTX 3090 512 78.94 1.16 
GeForce RTX 1080 Ti 128 55.69 1.64 
GeForce RTX 2080 Ti 128 58.19 1.57 
Quadro P5000 128 43.88 2.08 
Quadro RTX 5000 128 66.81 1.37 

Bảng 5: Tốc độ suy luận của giải mã tham lam, được đo trên tất cả dữ liệu đánh giá tiếng Anh (tổng cộng 56 999 từ) là từ trên giây cho các GPU và kích thước batch khác nhau.

5.4 Tốc độ Suy luận
Để kiểm tra hiệu suất thời gian chạy của mô hình, chúng tôi đo tốc độ suy luận của một mô hình đơn sử dụng giải mã tham lam trên tất cả dữ liệu đánh giá tiếng Anh (tổng cộng 56 999 từ). Kết quả cho các kích thước batch và GPU khác nhau được liệt kê trong Bảng 5. Nhìn chung, với kích thước batch 128 mô hình của chúng tôi xử lý 43-91 từ mỗi giây, tùy thuộc vào GPU được sử dụng. Để so sánh, hệ thống MoNoise được báo cáo chuẩn hóa 29-62 từ/giây mà không có GPU, dựa trên lọc ứng viên (van der Goot, 2019, Bảng 3).

6 Kết luận
Chúng tôi đã trình bày hệ thống chiến thắng của nhiệm vụ chung W-NUT 2021: Chuẩn hóa Từ vựng Đa ngôn ngữ (MultiLexNorm), dựa trên mô hình nền tảng ByT5. Trong đánh giá nội tại, hiệu suất hệ thống vượt trội với khoảng cách rất lớn, và hệ thống của chúng tôi cũng mang lại hiệu suất tốt nhất trong đánh giá ngoại tại. Chúng tôi phát hành cả mã nguồn tại https://github.com/ufal/multilexnorm2021 và các mô hình đã tinh chỉnh tại https://huggingface.co/ufal .

Trong nghiên cứu tương lai, chúng tôi muốn thay đổi kiến trúc mô hình để mã hóa câu đầu vào chỉ một lần, bằng cách giải mã toàn bộ câu, hoặc bằng cách tách tất cả từ đầu vào bằng các token sentinel khác nhau và sau đó giải mã các từ riêng lẻ bằng cách khởi tạo bộ giải mã với các token sentinel tương ứng.

--- TRANG 8 ---
Lời cảm ơn
Nghiên cứu được mô tả trong bài này đã được hỗ trợ bởi Bộ Giáo dục, Thanh niên và Thể thao Cộng hòa Séc, trong khuôn khổ dự án LINDAT/CLARIAH-CZ (LM2018101).

Tài liệu tham khảo
[Danh sách tài liệu tham khảo từ trang 8-10 được dịch từ tiếng Anh sang tiếng Việt, giữ nguyên định dạng và thứ tự]

Inaki Alegria, Nora Aranberri, Víctor Fresno, Pablo Gamallo, Lluis Padró, Inaki San Vicente, Jordi Turmo, và Arkaitz Zubiaga. 2013. Introducción a la tarea compartida Tweet-Norm 2013: Normalización léxica de tuits en Español. Trong Tweet-Norm@ SEPLN, trang 1–9.

Abhijeet Awasthi, Sunita Sarawagi, Rasna Goyal, Sabyasachi Ghosh, và Vihari Piratla. 2019. Parallel iterative edit models for local sequence transduction. Trong Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), trang 4260–4270, Hong Kong, China. Association for Computational Linguistics.

Timothy Baldwin, Marie Catherine de Marneffe, Bo Han, Young-Bum Kim, Alan Ritter, và Wei Xu. 2015. Shared tasks of the 2015 workshop on noisy user-generated text: Twitter lexical normalization and named entity recognition. Trong Proceedings of the Workshop on Noisy User-generated Text, trang 126–135, Beijing, China. Association for Computational Linguistics.

Anab Maulana Barik, Rahmad Mahendra, và Mirna Adriani. 2019. Normalization of Indonesian-English code-mixed Twitter data. Trong Proceedings of the 5th Workshop on Noisy User-generated Text (W-NUT 2019), trang 417–424, Hong Kong, China. Association for Computational Linguistics.

Piotr Bojanowski, Edouard Grave, Armand Joulin, và Tomas Mikolov. 2017. Enriching word vectors with subword information. Transactions of the Association for Computational Linguistics, 5:135–146.

Rishi Bommasani, Drew A. Hudson, Ehsan Adeli, Russ Altman, Simran Arora, Sydney von Arx, Michael S. Bernstein, Jeannette Bohg, Antoine Bosselut, Emma Brunskill, Erik Brynjolfsson, Shyamal Buch, Dallas Card, Rodrigo Castellon, Niladri Chatterji, Annie Chen, Kathleen Creel, Jared Quincy Davis, Dora Demszky, Chris Donahue, Moussa Doumbouya, Esin Durmus, Stefano Ermon, John Etchemendy, Kawin Ethayarajh, Li Fei-Fei, Chelsea Finn, Trevor Gale, Lauren Gillespie, Karan Goel, Noah Goodman, Shelby Grossman, Neel Guha, Tatsunori Hashimoto, Peter Henderson, John Hewitt, Daniel E. Ho, Jenny Hong, Kyle Hsu, Jing Huang, Thomas Icard, Saahil Jain, Dan Jurafsky, Pratyusha Kalluri, Siddharth Karamcheti, Geoff Keeling, Fereshte Khani, Omar Khattab, Pang Wei Kohd, Mark Krass, Ranjay Krishna, Rohith Kuditipudi, Ananya Kumar, Faisal Ladhak, Mina Lee, Tony Lee, Jure Leskovec, Isabelle Levent, Xiang Lisa Li, Xuechen Li, Tengyu Ma, Ali Malik, Christopher D. Manning, Suvir Mirchandani, Eric Mitchell, Zanele Munyikwa, Suraj Nair, Avanika Narayan, Deepak Narayanan, Ben Newman, Allen Nie, Juan Carlos Niebles, Hamed Nilforoshan, Julian Nyarko, Giray Ogut, Laurel Orr, Isabel Papadimitriou, Joon Sung Park, Chris Piech, Eva Portelance, Christopher Potts, Aditi Raghunathan, Rob Reich, Hongyu Ren, Frieda Rong, Yusuf Roohani, Camilo Ruiz, Jack Ryan, Christopher Ré, Dorsa Sadigh, Shiori Sagawa, Keshav Santhanam, Andy Shih, Krishnan Srinivasan, Alex Tamkin, Rohan Taori, Armin W. Thomas, Florian Tramèr, Rose E. Wang, William Wang, Bohan Wu, Jiajun Wu, Yuhuai Wu, Sang Michael Xie, Michihiro Yasunaga, Jiaxuan You, Matei Zaharia, Michael Zhang, Tianyi Zhang, Xikun Zhang, Yuhui Zhang, Lucia Zheng, Kaitlyn Zhou, và Percy Liang. 2021. On the opportunities and risks of foundation models.

Ana-Maria Bucur, Adrian Cosma, và Liviu P. Dinu. 2021. Sequence-to-sequence lexical normalization with multilingual transformers. Trong Proceedings of the 7th Workshop on Noisy User-generated Text (W-NUT 2021), Punta Cana, Dominican Republic. Association for Computational Linguistics.

Talha Çolakoğlu, Umut Sulubacak, và Ahmet Cüneyd Tantuğ. 2019. Normalizing non-canonical Turkish texts using machine translation approaches. Trong Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop, trang 267–272, Florence, Italy. Association for Computational Linguistics.

Jacob Devlin, Ming-Wei Chang, Kenton Lee, và Kristina Toutanova. 2019. BERT: Pre-training of deep bidirectional transformers for language understanding. Trong Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), trang 4171–4186, Minneapolis, Minnesota. Association for Computational Linguistics.

Tomaž Erjavec, Darja Fišer, Jaka Čibej, Špela Arhar Holdt, Nikola Ljubešić, và Katja Zupan. 2017. CMC training corpus Janes-Tag 2.0. Slovenian language resource repository CLARIN.SI.

Roman Grundkiewicz, Marcin Junczys-Dowmunt, và Kenneth Heafield. 2019. Neural grammatical error correction systems with unsupervised pre-training on synthetic data. Trong Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications, trang 252–263, Florence, Italy. Association for Computational Linguistics.

Divesh Kubal và Apurva Nagvenkar. 2021. Multilingual sequence labeling approach to solve lexical normalization. Trong Proceedings of the 7th Workshop on Noisy User-generated Text (W-NUT 2021), Punta Cana, Dominican Republic. Association for Computational Linguistics.

Nikola Ljubešić, Tomaž Erjavec, Maja Miličević, và Tanja Samardžić. 2017a. Croatian Twitter training corpus ReLDI-NormTagNER-hr 2.0. Slovenian language resource repository CLARIN.SI.

Nikola Ljubešić, Tomaž Erjavec, Maja Miličević, và Tanja Samardžić. 2017b. Serbian Twitter training corpus ReLDI-NormTagNER-sr 2.0. Slovenian language resource repository CLARIN.SI.

Ismini Lourentzou, Kabir Manghnani, và ChengXiang Zhai. 2019. Adapting sequence to sequence models for text normalization in social media. Trong International Conference on Web and Social Media. AAAI.

Benjamin Muller, Benoit Sagot, và Djamé Seddah. 2019. Enhancing BERT for lexical normalization. Trong Proceedings of the 5th Workshop on Noisy User-generated Text (W-NUT 2019), trang 297–306, Hong Kong, China. Association for Computational Linguistics.

Kostiantyn Omelianchuk, Vitaliy Atrasevych, Artem Chernodub, và Oleksandr Skurzhanskyi. 2020. GECToR – grammatical error correction: Tag, not rewrite. Trong Proceedings of the Fifteenth Workshop on Innovative Use of NLP for Building Educational Applications, trang 163–170, Seattle, WA, USA → Online. Association for Computational Linguistics.

Barbara Plank, Kristian Nørgaard Jensen, và Rob van der Goot. 2020. DaN+: Danish nested named entities and lexical normalization. Trong Proceedings of the 28th International Conference on Computational Linguistics, trang 6649–6662, Barcelona, Spain (Online). International Committee on Computational Linguistics.

Peng Qi, Yuhao Zhang, Yuhui Zhang, Jason Bolton, và Christopher D. Manning. 2020. Stanza: A Python natural language processing toolkit for many human languages. Trong Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations.

Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, và Peter J. Liu. 2020. Exploring the limits of transfer learning with a unified text-to-text transformer. Journal of Machine Learning Research, 21(140):1–67.

Sascha Rothe, Jonathan Mallinson, Eric Malmi, Sebastian Krause, và Aliaksei Severyn. 2021. A simple recipe for multilingual grammatical error correction. Trong Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers), trang 702–707, Online. Association for Computational Linguistics.

Yves Scherrer và Nikola Ljubešić. 2021. Sesame Street to Mount Sinai: BERT-constrained character-level Moses models for multilingual lexical normalization. Trong Proceedings of the 7th Workshop on Noisy User-generated Text (W-NUT 2021), Punta Cana, Dominican Republic. Association for Computational Linguistics.

Youri Schuur. 2020. Normalization for Dutch for improved pos tagging. Luận văn thạc sĩ, University of Groningen.

Noam Shazeer và Mitchell Stern. 2018. Adafactor: Adaptive learning rates with sublinear memory cost. CoRR, abs/1804.04235.

Uladzimir Sidarenka, Tatjana Scheffler, và Manfred Stede. 2013. Rule-based normalization of German Twitter messages. Trong Proc. of the GSCL Workshop Verarbeitung und Annotation von Sprachdaten aus Genres internetbasierter Kommunikation.

Rob van der Goot. 2019. MoNoise: A multi-lingual and easy-to-use lexical normalization tool. Trong Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: System Demonstrations, trang 201–206, Florence, Italy. Association for Computational Linguistics.

Rob van der Goot. 2021. CL-MoNoise: Cross-lingual lexical normalization. Trong Proceedings of the 7th Workshop on Noisy User-generated Text (W-NUT 2021), Punta Cana, Dominican Republic. Association for Computational Linguistics.

Rob van der Goot và Özlem Çetinoğlu. 2021. Lexical normalization for code-switched data and its effect on POS tagging. Trong Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Volume 1, Long Papers. Association for Computational Linguistics.

Rob van der Goot, Alan Ramponi, Tommaso Caselli, Michele Cafagna, và Lorenzo De Mattei. 2020. Norm it! lexical normalization for Italian and its downstream effects for dependency parsing. Trong Proceedings of the 12th Language Resources and Evaluation Conference, trang 6272–6278, Marseille, France. European Language Resources Association.

Rob van der Goot, Alan Ramponi, Arkaitz Zubiaga, Barbara Plank, Benjamin Muller, Iñaki San Vicente Roncal, Nikola Ljubešić, Özlem Çetinoğlu, Rahmad Mahendra, Talha Çolakoğlu, Timothy Baldwin, Tommaso Caselli, và Wladimir Sidorenko. 2021a. MultiLexNorm: A shared task on multilingual lexical normalization. Trong Proceedings of the 7th Workshop on Noisy User-generated Text (W-NUT 2021), Punta Cana, Dominican Republic. Association for Computational Linguistics.

Rob van der Goot, Ahmet Üstün, Alan Ramponi, Ibrahim Sharaf, và Barbara Plank. 2021b. Massive choice, ample tasks (MaChAmp): A toolkit for multi-task learning in NLP. Trong Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: System Demonstrations, trang 176–197, Online. Association for Computational Linguistics.

Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, và Illia Polosukhin. 2017. Attention is all you need. Trong Advances in Neural Information Processing Systems, tập 30. Curran Associates, Inc.

Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Remi Louf, Morgan Funtowicz, Joe Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest, và Alexander Rush. 2020. Transformers: State-of-the-art natural language processing. Trong Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, trang 38–45, Online. Association for Computational Linguistics.

Wenhan Xiong, Jiawei Wu, Hong Wang, Vivek Kulkarni, Mo Yu, Shiyu Chang, Xiaoxiao Guo, và William Yang Wang. 2019. TWEETQA: A social media focused question answering dataset. Trong Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, trang 5020–5031, Florence, Italy. Association for Computational Linguistics.

Linting Xue, Aditya Barua, Noah Constant, Rami Al-Rfou, Sharan Narang, Mihir Kale, Adam Roberts, và Colin Raffel. 2021a. Byt5: Towards a token-free future with pre-trained byte-to-byte models.

Linting Xue, Noah Constant, Adam Roberts, Mihir Kale, Rami Al-Rfou, Aditya Siddhant, Aditya Barua, và Colin Raffel. 2021b. mT5: A massively multilingual pre-trained text-to-text transformer. Trong Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, trang 483–498, Online. Association for Computational Linguistics.

Daniel Zeman, Joakim Nivre, et al. 2021. Universal dependencies 2.8. LINDAT/CLARIAH-CZ digital library at the Institute of Formal and Applied Linguistics (ÚFAL), Faculty of Mathematics and Physics, Charles University.

--- TRANG 9 ---
[Phần còn lại của trang 9 chứa các tài liệu tham khảo tiếp theo]

--- TRANG 10 ---
[Phần còn lại của trang 10 chứa các tài liệu tham khảo tiếp theo]

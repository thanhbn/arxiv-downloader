# Các bản dịch ở mức ký tự có đáng chờ đợi không?
So sánh ByT5 và mT5 cho Dịch máy
Lukas Edman Gabriele Sarti Antonio Toral
Gertjan van Noord Arianna Bisazza
Trung tâm Ngôn ngữ và Nhận thức
Đại học Groningen
{j.l.edman, g.sarti, a.toral.ruiz, g.j.m.van.noord, a.bisazza}@rug.nl

## Tóm tắt
Các mô hình ngôn ngữ đã được huấn luyện trước ở mức ký tự và byte đã được chứng minh là có thể cạnh tranh với các mô hình từ con phổ biến trong nhiều tác vụ Xử lý Ngôn ngữ Tự nhiên (NLP). Tuy nhiên, có ít nghiên cứu về hiệu quả của chúng đối với dịch máy thần kinh (NMT), đặc biệt trong mô hình huấn luyện trước rồi tinh chỉnh phổ biến. Công trình này thực hiện so sánh toàn diện trên nhiều ngôn ngữ và điều kiện thực nghiệm của các mô hình đã huấn luyện trước ở mức ký tự và từ con (ByT5 và mT5, tương ứng) trên NMT. Chúng tôi cho thấy hiệu quả của mô hình ký tự trong dịch thuật, đặc biệt trong các trường hợp dữ liệu tinh chỉnh bị hạn chế. Trong phân tích của chúng tôi, chúng tôi cho thấy cách mà lợi ích về chất lượng dịch thuật của các mô hình ký tự được phản ánh trong việc dịch tốt hơn các từ tương tự về mặt chính tả và từ hiếm. Khi đánh giá tầm quan trọng của văn bản nguồn trong việc điều khiển dự đoán của mô hình, chúng tôi làm nổi bật các mẫu ở mức từ trong ByT5, cho thấy khả năng điều chỉnh thông tin ở mức từ và ký tự trong quá trình tạo sinh. Chúng tôi kết thúc bằng việc đánh giá sự đánh đổi về hiệu suất của các mô hình byte, đề xuất việc sử dụng chúng trong các tình huống không quan trọng về thời gian để nâng cao chất lượng dịch thuật.

## 1 Giới thiệu
Các mô hình ở mức ký tự và byte đã là nguồn quan tâm trong Xử lý Ngôn ngữ Tự nhiên (NLP) trong nhiều năm, với lời hứa về các hệ thống không cần tokenization có khả năng xử lý và tạo sinh văn bản ở mức độ chi tiết hơn. Tuy nhiên, các hệ thống này đã thất bại trong việc trở thành mô hình thống trị so với các mô hình ở mức từ con, mặc dù có hiệu suất tương đương. Điều này có thể là do thời gian và tài nguyên tính toán bổ sung cần thiết, do các chuỗi đầu vào dài hơn được sử dụng trong các phương pháp dựa trên ký tự. Có những trường hợp mà các mô hình ký tự đã được chứng minh vượt trội hơn các mô hình từ con. Tuy nhiên, những trường hợp này có thể được coi là chuyên biệt (ví dụ: các tác vụ đặc biệt yêu cầu thông tin ký tự) hoặc không thực tế (ví dụ: sử dụng dữ liệu bị hỏng với nhiễu tổng hợp (Xue et al., 2022)).

Ngoài ra, các nghiên cứu trước đây chỉ trình bày đánh giá hạn chế của các hệ thống này cho các tác vụ phổ biến mà thông tin ở mức ký tự có thể dẫn đến lợi ích hiệu suất lớn. Trong công trình này, chúng tôi tiến hành so sánh toàn diện các mô hình đã huấn luyện trước ở mức ký tự và từ con trên dịch máy (MT). Mặc dù NMT phổ biến, các mô hình ký tự đã huấn luyện trước vẫn chưa được đánh giá kỹ lưỡng cho tác vụ này, với nghiên cứu gần đây về các mô hình ký tự cho MT tập trung vào các mô hình được huấn luyện từ đầu (Libovický et al., 2022; Edman et al., 2022). Chúng tôi cho rằng các phương pháp này chỉ có thể đánh giá đáng tin cậy hiệu suất dịch thuật cho các ngôn ngữ có tài nguyên cao, nơi mà các hiệu ứng có lợi của việc huấn luyện trước đa ngôn ngữ được phát hiện là ít tác động hơn (Liu et al., 2020).

Các mô hình ký tự có thể tận dụng thông tin chi tiết hơn, điều này có thể hữu ích trong nhiều bối cảnh NMT thách thức, chẳng hạn như dịch thuật tài nguyên thấp. Để xác thực điều này, chúng tôi tinh chỉnh mô hình ký tự ByT5 (Xue et al., 2022) và đối tác từ con mT5 (Xue et al., 2021) cho dịch thuật, với nhiều ngôn ngữ và cài đặt khác nhau. Trong số các phát hiện của chúng tôi, những điều nổi bật là:

(1) ByT5 tạo ra các bản dịch chất lượng cao hơn mT5 nói chung, đặc biệt khi tài nguyên bị hạn chế.

(2) ByT5 cho thấy khả năng tổng quát hóa đa ngôn ngữ tốt hơn mT5 trung bình, và đặc biệt đối với các ngôn ngữ có tài nguyên cao hoặc các ngôn ngữ có tài nguyên thấp có liên quan đến những ngôn ngữ có tài nguyên cao.

(3) Tinh chỉnh với nhiều ví dụ làm cho các bản dịch của ByT5 trong cài đặt zero-shot suy giảm nhanh hơn mT5.

(4) ByT5 cho thấy mẫu quan trọng nguồn ở mức từ gắn kết, cho thấy khả năng nắm bắt các mối quan hệ vượt ra ngoài mức ký tự (như được thể hiện trong Hình 1).

(5) Khi ByT5 vượt trội hơn mT5, ByT5 cũng tốt hơn trong việc dịch các từ tương tự về mặt chính tả và từ hiếm.

Các phát hiện của chúng tôi ủng hộ ý tưởng rằng trong một số hoàn cảnh thực tế, và đặc biệt đối với các tình huống tài nguyên thấp, các mô hình ký tự vượt trội về chất lượng dịch thuật so với các đối tác từ con được sử dụng rộng rãi. Trong phân tích của chúng tôi, chúng tôi tiếp tục cho thấy cách mà những cải thiện về chất lượng này kết nối với các thuộc tính từ cụ thể, chẳng hạn như tương tự chính tả và tần suất.

## 2 Công trình liên quan
Các mô hình ở mức ký tự từ lâu đã được quan tâm để sử dụng trong dịch máy, từ thời các mô hình thống kê là mô hình thống trị (Tiedemann và Nakov, 2013). Vào thời điểm đó, các mô hình ký tự đã có khả năng cạnh tranh với các mô hình ở mức từ, đặc biệt khi dữ liệu huấn luyện được giới hạn dưới 100k cặp câu. Durrani et al. (2010) cũng cho thấy rằng các mô hình ký tự đặc biệt thành thạo trong việc dịch các ngôn ngữ có liên quan chặt chẽ như Hindi và Urdu. Chúng tôi lưu ý rằng, vào thời điểm đó, các tokenizer từ con như BPE (Sennrich et al., 2016) vẫn chưa được sử dụng phổ biến.

Các phương pháp thần kinh đối với MT ở mức ký tự lần đầu tiên dựa trên RNN (Costa-jussà và Fonollosa, 2016; Lee et al., 2017), với công việc mở rộng được thực hiện để so sánh các mô hình ký tự với các mô hình từ con (bây giờ được trang bị BPE). Đối với NMT, đã được chứng minh rằng các mô hình ký tự sử dụng kiến trúc RNN (có và không có CNN để xử lý ký tự) thực hiện tương đương hoặc tốt hơn các mô hình từ con (Larriba Flor, 2017; Lee et al., 2017; Sennrich, 2017; Cherry et al., 2018). Hiệu suất dịch thuật tốt hơn của chúng có thể được quy cho khả năng xử lý hình thái phức tạp, từ hiếm hoặc chưa gặp, và đầu vào có nhiễu (Jozefowicz et al., 2016; Kim et al., 2016; Belinkov và Bisk, 2017; Lee et al., 2017; Singh, 2017; Durrani et al., 2019). Tuy nhiên, sự kém hiệu quả của các mô hình ký tự đã rõ ràng, vì chúng chậm hơn các mô hình từ con một cách đáng kể (Chung et al., 2016). Công việc cũng đã được thực hiện trong việc so sánh các mô hình ở mức byte và ký tự, với ít sự khác biệt được tìm thấy, tuy nhiên những thí nghiệm này chủ yếu thử nghiệm với các ngôn ngữ sử dụng chữ Latin (Costa-jussà et al., 2017).

Công việc gần đây hơn đã xem xét Transformer ở mức ký tự và byte. Xue et al. (2022) tạo ra ByT5 và so sánh nó với đối tác từ con, mT5 (Xue et al., 2021), đây cũng là những mô hình chúng tôi tập trung trong công việc này. Tuy nhiên, các so sánh của họ chủ yếu tập trung vào các tác vụ phân loại đa ngôn ngữ hoặc các tác vụ tạo sinh dựa trên tiếng Anh, nhưng không có tác vụ tạo sinh đa ngôn ngữ hoặc dịch máy.

Công việc trước đây đã phân tích các Transformer ở mức ký tự được huấn luyện từ đầu cho NMT, không sử dụng các mô hình dựa trên T5. Libovický et al. (2022) đã xem xét các mô hình ký tự "vanilla" (những mô hình không có bất kỳ nén nào về độ dài chuỗi trước khi tính toán trong Transformer), cũng như các phương pháp của Lee et al. (2017), Tay et al. (2022), và Clark et al. (2022) để nén độ dài chuỗi. Họ kết luận rằng các mô hình ở mức ký tự này không mang lại lợi ích nào so với các mô hình từ con trong khi kém hiệu quả hơn. Có hai yếu tố cần lưu ý với những kết luận này. Thứ nhất, các thí nghiệm của họ cho thấy hiệu suất tương tự, nhưng họ chỉ thử nghiệm trên các ngôn ngữ có tài nguyên cao. Với công việc trước đây trong RNN được đề cập ở trên, điều này dường như không phải là ứng dụng sẽ được hưởng lợi nhiều nhất từ các mô hình ở mức ký tự. Thứ hai, họ giới thiệu một bộ giải mã hai bước để đạt được việc giải mã ở mức ký tự từ các trạng thái ẩn ở mức từ con, tuy nhiên như Edman et al. (2022) chỉ ra, bộ giải mã này không mở rộng tốt cho các tình huống có tài nguyên cao hơn. Bộ giải mã hai bước này thêm một lớp phức tạp bổ sung vào việc đánh giá các mô hình như vậy, vì một nghiên cứu loại bỏ về độ chi tiết của mô hình và quá trình giải mã của mô hình sẽ cần thiết để hiểu đầy đủ hiệu suất của từng mô hình. Thêm vào thực tế là không có mô hình đã huấn luyện trước nào sử dụng nén độ dài chuỗi này có thể so sánh với mT5 và ByT5 về dữ liệu được sử dụng để huấn luyện trước hoặc quy mô mô hình, chúng tôi không thử nghiệm với các mô hình nén độ dài chuỗi trong công việc của chúng tôi.

Trong bối cảnh MT tài nguyên thấp, Edman et al. (2022) cho thấy rằng các mô hình ở mức ký tự có thể vượt trội hơn các mô hình từ con trên cặp tài nguyên thấp Xhosa–Zulu. Li et al. (2021) cho thấy rằng các mô hình ở mức ký tự tạo ra các bản dịch chất lượng cao hơn trong các cài đặt tài nguyên thấp tổng hợp của tiếng Anh →{tiếng Đức, tiếng Phần Lan} với kích thước kho ngữ liệu 50k cặp câu song song. Carrión-Ponz và Casacuberta (2022) cho thấy rằng các mô hình gần-ký-tự (các mô hình từ con với từ vựng nhỏ có kích thước 350) tạo ra các bản dịch chất lượng cao hơn so với từ con với kích thước từ vựng tiêu chuẩn hơn là 32 nghìn khi dữ liệu bị hạn chế cho một số ngôn ngữ châu Âu, tìm thấy những cải thiện nhất quán trên nhiều lĩnh vực.

Tuy nhiên, có hai điều cần lưu ý quan trọng với công việc trước đây này. Thứ nhất, công việc trước đây sử dụng các mô hình ký tự cho MT tập trung vào việc huấn luyện các mô hình từ đầu, vì đây là thực hành lâu đời trong lĩnh vực MT. Tuy nhiên, thực hành này có thể đặc biệt có hại cho các ngôn ngữ tài nguyên thấp, nơi mà mô hình tinh chỉnh một mô hình đa ngôn ngữ đã huấn luyện trước được chứng minh là hiệu quả (Liu et al., 2020).

Điều cần lưu ý thứ hai là các đánh giá trước đây về chuyển giao đa ngôn ngữ cũng bị hạn chế bởi kích thước mô hình tương đối nhỏ (<70M tham số). Ngược lại, công việc này đánh giá các mô hình lên đến 1.2B tham số. Với một bậc độ lớn hơn về tham số, chúng tôi nghiên cứu sự hiện diện của các thuộc tính nổi lên của các mô hình NMT dựa trên ký tự và từ con lớn hơn, theo bằng chứng từ các tác vụ tạo sinh khác.

Trong phạm vi công việc mở rộng trước đây được thực hiện trên các mô hình ký tự, công việc này phục vụ để đưa ra tổng quan cập nhật về hiệu suất của các mô hình ký tự so với từ con cho NMT. Theo hiểu biết của chúng tôi, chúng tôi cung cấp tổng quan đầu tiên như vậy sử dụng các mô hình dựa trên transformer đa ngôn ngữ lên đến 1.2B tham số. Chúng tôi tinh chỉnh tổng cộng 162 mô hình (thay đổi ngôn ngữ, lượng dữ liệu huấn luyện, kích thước mô hình và loại mô hình), và kiểm tra trên 200 ngôn ngữ để so sánh kỹ lưỡng hiệu suất của các mô hình ký tự và từ con. Chúng tôi cũng thực hiện phân tích quy kết để hiểu sâu hơn về sự khác biệt giữa hai mức độ chi tiết của ký tự và từ con, mà theo hiểu biết của chúng tôi, vẫn chưa được nghiên cứu.

## 3 Phương pháp
Vì các thí nghiệm của chúng tôi nhằm mục đích cung cấp một so sánh công bằng giữa các mô hình đã huấn luyện trước ở mức ký tự và từ con cho dịch thuật, trước tiên chúng tôi biện minh cho việc lựa chọn mô hình, tiếp theo là kế hoạch huấn luyện của chúng tôi, và cuối cùng là lựa chọn chỉ số để đánh giá.

### 3.1 Mô hình
Với nhiều mô hình ở mức ký tự có sẵn (El Boukkouri et al., 2020; Tay et al., 2022), chúng tôi chọn so sánh ByT5 với đối tác từ con mT5. Những mô hình này, theo hiểu biết của chúng tôi, có thể so sánh nhất do thiết lập huấn luyện tương tự và số lượng tham số. Chúng tôi lưu ý rằng mặc dù số lượng tham số giữa các mô hình mT5 và ByT5 tương tự, Xue et al. đã chọn tăng chiều rộng (tức là kích thước chiều ẩn) của các mô hình ByT5 để bù đắp cho việc sử dụng ít tham số hơn để nhúng byte. Điều này đáng chú ý nhất trong các mô hình nhỏ, với 85% tham số của mT5 được sử dụng cho nhúng, so với 0.3% cho ByT5 (Xue et al., 2022). Vì sự chênh lệch này giảm với kích thước mô hình tăng, chúng tôi coi sự khác biệt này là một yếu tố có ý nghĩa trong việc giải thích kết quả tương quan âm với kích thước mô hình. Do đó, hầu hết các thí nghiệm của chúng tôi sử dụng các mô hình ByT5 và mT5 nhỏ (300M), cơ sở (582M), và lớn (1.23B), hoặc chỉ tập trung vào các mô hình lớn, nơi sự chênh lệch thấp nhất.

### 3.2 Huấn luyện
Chúng tôi tinh chỉnh các mô hình mT5 và ByT5 sử dụng cùng một prompt được sử dụng trong Raffel et al. (2020):
Translate <S> to <T>: <src>
trong đó <S> là ngôn ngữ nguồn, <T> là ngôn ngữ đích, và <src> là văn bản nguồn.

Chúng tôi chủ yếu sử dụng các bộ dữ liệu NewsCommentary v16 của WMT để tinh chỉnh. Chúng tôi xem xét 5 mức độ "tài nguyên" để tinh chỉnh, sử dụng {0.4, 2, 10, 50, 250} nghìn cặp câu. Chúng tôi cũng sử dụng bộ dữ liệu WMT14 tiếng Đức–tiếng Anh để kiểm tra các cài đặt tài nguyên cao hơn là 1.25 và 4.5 triệu cặp câu (tức là toàn bộ bộ dữ liệu). Các lựa chọn siêu tham số cho huấn luyện có thể được tìm thấy trong Phụ lục A.

Để phát triển và kiểm tra, chúng tôi sử dụng bộ dữ liệu FLoRes-200 (NLLB Team et al., 2022).

Đối với các cặp ngôn ngữ huấn luyện, chúng tôi huấn luyện trên {tiếng Đức, tiếng Nga} ↔tiếng Anh và {tiếng Bồ Đào Nha, tiếng Anh} →tiếng Tây Ban Nha. Chúng tôi chọn những cặp ngôn ngữ này vì chúng đều nằm trong NewsCommentary, đảm bảo chất lượng tương tự, và tính đến các mức độ tương tự ngôn ngữ khác nhau.

Chúng tôi bổ sung kiểm tra khả năng giữ lại thông tin đa ngôn ngữ của các mô hình với bộ dữ liệu FLoRes-200 (NLLB Team et al., 2022), với sự đa dạng rộng rãi về ngôn ngữ cho phép chúng tôi tách biệt thêm các đặc điểm ngôn ngữ quan trọng. Để kiểm tra khả năng zero-shot của các mô hình, chúng tôi chỉ đơn giản thay thế <S> và <src> cho một ngôn ngữ mới, giữ ngôn ngữ đích như cũ. Không có huấn luyện thêm nào được thực hiện, làm cho cài đặt trở thành zero-shot.

### 3.3 Đánh giá
Chúng tôi đã xem xét một số chỉ số chất lượng dịch thuật, cuối cùng lựa chọn chrF++ (Popović, 2017), được công thức hóa như một sự kết hợp của cả điểm F ở mức ký tự và mức từ, được cân nhắc để tối đa hóa tương quan với đánh giá của con người. Lưu ý điều này khác với chrF gốc, chỉ tính đến điểm ở mức ký tự. Kết hợp cả điểm ở mức từ và ký tự có nghĩa là không ByT5 hay mT5 nào được ưu ái bởi chrF++.

Chúng tôi cũng đã xem xét các chỉ số thần kinh hiện đại như COMET (Rei et al., 2020, 2022), được biết đến là tương quan tốt hơn với các đánh giá của con người ở mức câu (Freitag et al., 2022). Tuy nhiên, thực tế là COMET bản thân nó là một mô hình từ con, và đã được huấn luyện chủ yếu để đánh giá các đầu ra của các mô hình từ con, làm cho không rõ ràng chỉ số này hoạt động như thế nào đối với các mô hình ký tự. Do đó, chúng tôi sử dụng chrF++ minh bạch hơn. Tuy nhiên, chúng tôi cung cấp điểm COMET cho kết quả dịch thuật trực tiếp (Phần 4), sử dụng mô hình wmt22-comet-da (tức là COMET-22). Chúng tôi cũng bao gồm điểm BLEU trong Phụ lục B, với các xu hướng rất tương tự như những xu hướng được thấy cho chrF++.

## 4 Kết quả Dịch thuật Trực tiếp
Thiết lập dịch thuật trực tiếp của chúng tôi đánh giá các mô hình trên cùng các cặp ngôn ngữ mà chúng được tinh chỉnh. Vì các mô hình ký tự thường vượt trội hơn các mô hình từ con, đặc biệt khi dữ liệu huấn luyện khan hiếm (như đã lưu ý trong Phần 2), chúng tôi thay đổi lượng dữ liệu tinh chỉnh, xác nhận những phát hiện này cho dịch thuật {tiếng Đức, tiếng Nga} ↔tiếng Anh.

Thay đổi lượng dữ liệu tinh chỉnh tiết lộ sự khác biệt lớn nhất trong chất lượng dịch thuật của các mô hình ký tự và từ con. Hình 2 cho thấy rằng ByT5 vượt trội hơn mT5 ở tất cả các mức tài nguyên theo chrF++, và có khả năng cạnh tranh với mT5 theo COMET. Khi tài nguyên bị hạn chế, khoảng cách chất lượng giữa ByT5 và mT5 cũng có xu hướng tăng. Chúng ta thấy rằng kích thước mô hình cũng đóng một vai trò, với mô hình lớn có khoảng cách chất lượng lớn nhất lên đến 10 điểm chrF++ khi chỉ có 400 câu có sẵn. Điều này đi ngược lại giả định của chúng tôi rằng, với sự khác biệt về kiến trúc lớn nhất giữa các mô hình nhỏ, chúng tôi sẽ thấy sự khác biệt lớn nhất trong hiệu suất từ chúng (xem Phần 3.1).

Bảng 1 cho thấy hiệu suất của các mô hình lớn trên bộ dữ liệu WMT14 tiếng Đức →tiếng Anh, tính đến các cài đặt tài nguyên cao hơn. Kết quả theo chrF++ cho thấy rằng ByT5 tiếp tục vượt trội hơn mT5 một cách đáng kể, trong khi COMET không tìm thấy sự khác biệt đáng kể. Trong khi chúng tôi hy vọng rằng hiệu suất chrF++ của hai mô hình cuối cùng sẽ hội tụ với đủ dữ liệu, chúng tôi không thể quan sát được điều đó ngay cả trong thiết lập tài nguyên cao nhất của chúng tôi là 4.5M cặp câu.

## 5 Kết quả Zero-shot
Đánh giá zero-shot của chúng tôi kiểm tra mức độ các mô hình giữ lại thông tin từ các ngôn ngữ tương tự được thấy trong huấn luyện trước hoặc tinh chỉnh hoặc mức độ chúng tổng quát hóa tốt cho các ngôn ngữ chưa thấy khi được tinh chỉnh trên một cặp ngôn ngữ cụ thể. Do đó, chúng tôi coi dịch thuật zero-shot là dịch từ một ngôn ngữ nguồn chưa được tinh chỉnh, sử dụng kế hoạch được mô tả trong Phần 3.2. Điều này có thể có ý nghĩa quan trọng đối với các thực hành tốt nhất cho huấn luyện mô hình tài nguyên thấp, vì học chuyển giao đa ngôn ngữ là một kỹ thuật phổ biến để có được khởi tạo tốt cho các cặp ngôn ngữ ít tài nguyên hơn.

Đầu tiên chúng tôi xem xét chất lượng dịch thuật chung trên tất cả các ngôn ngữ trong FLoRes-200, và nghiên cứu các mẫu hiệu suất liên quan đến địa lý và mức độ tài nguyên ngôn ngữ. Sau đó chúng tôi điều tra sự suy giảm chất lượng zero-shot mà chúng tôi quan sát khi ByT5 được huấn luyện quá lâu.

### 5.1 Hiệu suất Chung
Hình 3 cho thấy chất lượng dịch thuật trung bình của các mô hình được tinh chỉnh {tiếng Đức, tiếng Nga} ↔tiếng Anh được kiểm tra trên tất cả 204 ngôn ngữ từ bộ dữ liệu FLoRes-200 (X →tiếng Anh).

Nhìn chung, chúng ta thấy rằng ByT5 tiếp tục vượt trội hơn mT5 đối với các tình huống tài nguyên thấp hơn. Tuy nhiên, hiệu suất zero-shot của nó giảm đột ngột trong một số trường hợp trên 10k ví dụ huấn luyện, trong khi mT5 tiếp tục hoạt động tốt lên đến 250k ví dụ, chỉ với một sự sụt giảm nhẹ hiệu suất so với hoặc không sụt giảm gì cả. Chúng tôi tiếp tục điều tra sự suy giảm lớn của ByT5 trong Phần 5.3, nhưng trước tiên, chúng tôi xem xét kỹ hơn các kết quả cụ thể theo ngôn ngữ trên tiếng Đức →tiếng Anh với 10k ví dụ huấn luyện.

Trong Hình 4, chúng ta thấy sự khác biệt hiệu suất của ByT5 và mT5 cho từng ngôn ngữ nguồn, được vẽ ở các vị trí địa lý tương ứng của chúng. Trong khi ByT5 hoạt động tốt nhìn chung, chúng ta nhận thấy một điểm yếu rõ ràng khi dịch zero-shot các ngôn ngữ từ Tây và Trung Phi. Nhiều ngôn ngữ này được coi là ngôn ngữ tài nguyên thấp, tuy nhiên có một số ngôn ngữ cũng được coi là tài nguyên thấp mà ByT5 hoạt động tốt. Do đó, chúng tôi phân tích các thành phần cần thiết của một ngôn ngữ để ByT5 hoạt động tốt tiếp theo.

### 5.2 Mức độ Tài nguyên Ngôn ngữ
Như chúng ta đã thấy trong Phần 4, lượng dữ liệu được sử dụng để tinh chỉnh đóng một vai trò lớn trong chất lượng dịch thuật. Tương tự, chúng ta sẽ hy vọng rằng việc mô hình có thấy một ngôn ngữ cụ thể trong huấn luyện trước cũng sẽ đóng một vai trò.

Nếu chúng ta chỉ sử dụng sự hiện diện của một ngôn ngữ trong bộ dữ liệu huấn luyện trước để dự đoán liệu ByT5 có vượt trội hơn mT5 hay không, chúng ta có độ chính xác 62% trên các ngôn ngữ FLoRes-200, sử dụng mô hình tiếng Đức →tiếng Anh của chúng tôi. Đối với các cặp ngôn ngữ khác của chúng tôi, chúng ta có 71%, 45%, và 50% cho các mô hình được tinh chỉnh trên tiếng Anh →tiếng Đức, tiếng Nga →tiếng Anh, và tiếng Anh →tiếng Nga, tương ứng. Vì vậy, sự hiện diện trong huấn luyện trước một mình không phải là một dự báo đáng tin cậy về hiệu suất.

Tuy nhiên điều này không kể hết câu chuyện, vì nhiều ngôn ngữ tài nguyên thấp có liên quan đến các ngôn ngữ tài nguyên cao, mà các mô hình, đặc biệt là ByT5, có khả năng khai thác. Cụ thể, chúng tôi phân loại mỗi ngôn ngữ thành một trong ba danh mục:

• Tài nguyên Cao: Ngôn ngữ có trong dữ liệu huấn luyện trước.

• Tài nguyên Thấp – Có liên quan: Ngôn ngữ nằm trong cùng nhóm ngôn ngữ con (như được xác định bởi NLLB Team et al. (2022)) và cùng chữ viết như một ngôn ngữ trong huấn luyện trước.

• Tài nguyên Thấp – Không liên quan: Tất cả các ngôn ngữ khác.

Ví dụ, tiếng Acehnese (ace) được viết bằng cả chữ Ả Rập và Latin. Đối với Latin, chúng tôi coi nó là "Tài nguyên Thấp – Có liên quan" vì nó có liên quan đến tiếng Indonesia có tài nguyên cao (cả hai đều là ngôn ngữ Malayo-Polynesian), cũng được viết bằng chữ Latin. Tuy nhiên đối với Ả Rập, chúng tôi coi nó là "Tài nguyên Thấp – Không liên quan" vì không có ngôn ngữ Malayo-Polynesian nào được viết bằng chữ Ả Rập trong dữ liệu huấn luyện trước.

Yêu cầu cả nhóm ngôn ngữ con và chữ viết giống nhau hoạt động tốt hơn nhiều như một dự báo so với chỉ sử dụng một trong hai. Nó cũng trực quan: Các ngôn ngữ có liên quan thường chia sẻ nhiều từ tương tự, nhưng điều này sẽ không dẫn đến việc chia sẻ nhúng nếu chúng được viết bằng các chữ viết khác nhau.

Trong Hình 5, chúng ta thấy rằng, phần lớn, các ngôn ngữ trong 2 danh mục đầu tiên có xu hướng là các ngôn ngữ mà ByT5 vượt trội hơn mT5, trong khi điều ngược lại đúng cho danh mục thứ ba. Sử dụng quy tắc này, chúng ta có thể dự đoán chính xác mô hình nào sẽ hoạt động tốt hơn cho 89% các ngôn ngữ khi tinh chỉnh trên tiếng Đức →tiếng Anh.

Mặc dù không phải là một dự báo hoàn hảo, hiệu quả của quy tắc đơn giản này cho thấy có một xu hướng rõ ràng rằng ByT5 có thể tận dụng thông tin từ các ngôn ngữ khác mà nó đã thấy để thông báo cho việc dịch các ngôn ngữ tài nguyên thấp tốt hơn. Lý do tại sao mT5 hoạt động tốt hơn trên các ngôn ngữ tài nguyên thấp không liên quan có phần không rõ ràng. Một giải thích có thể là các nhúng thưa thớt của mT5 cho phép mã hóa mạnh mẽ hơn cho các ngôn ngữ mà những người bạn giả nhiều hơn, thấy rằng mT5 sẽ chứa ít thiên vị tích cực hơn đối với tương tự ngữ nghĩa cho tương tự chính tả. Thực tế, từ góc độ của một mô hình ký tự, "những người bạn giả" không nhất thiết phải là từ, mà cũng có thể chỉ đơn giản là n-gram ký tự. Tuy nhiên, nhiều ngôn ngữ trong danh mục thứ ba bao gồm các ngôn ngữ Tây và Trung Phi, tương ứng với mẫu chúng ta thấy trong Hình 4. Những ngôn ngữ này chủ yếu sử dụng chữ Latin, tăng khả năng những người bạn giả với ngôn ngữ nguồn gốc (tiếng Đức). Tuy nhiên, cần lưu ý rằng đa số các ngôn ngữ mà mT5 hoạt động tốt hơn cũng là những ngôn ngữ mà không mT5 hay ByT5 đều cho thấy hiệu suất trên 25 chrF++ (tương đương với điểm BLEU khoảng 5). Do đó, chúng tôi khuyến nghị công việc thêm trước khi rút ra kết luận dựa trên những ngôn ngữ này.

### 5.3 Suy giảm Zero-shot
Để hiểu sự sụt giảm chất lượng mà chúng ta thấy từ ByT5-large được tinh chỉnh trên 250k ví dụ (Hình 3), chúng tôi bắt đầu bằng cách cho thấy rằng việc đóng băng một số phần của mô hình có thể giảm thiểu điểm yếu này. Dựa trên các khám phá của chúng tôi, sau đó chúng tôi kiểm tra liệu chữ viết có phải là yếu tố giải thích trong việc một ngôn ngữ cụ thể suy giảm chất lượng bao nhiêu hay không.

**Việc Đóng băng Các Lớp Encoder có Ngăn chặn Quên Đa ngôn ngữ không?** Chúng tôi thử nghiệm với việc đóng băng các phần khác nhau của mô hình sau 2000 bước (số bước cần thiết để các mô hình được tinh chỉnh trên 10k câu hội tụ), và tiếp tục huấn luyện chỉ trên một phần của mô hình. Chúng tôi tiến hành kiểm tra các mô hình trên ngôn ngữ nguồn gốc của chúng (trong trường hợp này là tiếng Đức), cũng như 204 ngôn ngữ từ bộ kiểm tra. Kết quả được hiển thị trong Bảng 2, bao gồm so sánh với các mô hình không đóng băng hoạt động tốt nhất.

Ở đây chúng ta có thể thấy rằng, đối với ByT5, việc đóng băng bất cứ nơi nào từ phần tư đầu của các lớp encoder lên đến mọi thứ trừ cross-attention có hiệu quả trong việc ngăn chặn sự mất tính tổng quát đi kèm với việc huấn luyện thêm. Ingle et al. (2022) đã thấy một mẫu tương tự trong cài đặt few-shot, nơi việc đóng băng 25%-50% lớp đầu tiên của RoBERTa cải thiện hiệu suất so với không đóng băng gì. Điều này cũng cho thấy rằng vấn đề không phải với sự đa dạng của dữ liệu huấn luyện, mà cụ thể là số lượng bước huấn luyện được thực hiện.

Vì chúng ta thấy một sự tăng tương đối dốc trong chất lượng dịch thuật zero-shot từ 0 đến 25% các lớp encoder được đóng băng, và sau đó một chất lượng tương đối ổn định sau đó, có vẻ như phần lớn các hoạt động cụ thể theo ngôn ngữ đang xảy ra trong 25% đầu tiên của các lớp encoder trong ByT5. Mặt khác, mT5 dường như thể hiện sự trừu tượng hóa ngôn ngữ này chỉ dựa trên các nhúng thưa thớt của nó, vì nó không bị suy giảm chất lượng zero-shot ở mức độ tương tự khi không được đóng băng. Tuy nhiên, khi đóng băng các lớp của mT5 ngoài các nhúng, chúng ta thấy một sự giảm dốc trong chất lượng dịch thuật cả trên ngôn ngữ được huấn luyện và các ngôn ngữ zero-shot. Điều này ngụ ý rằng mT5 cần điều chỉnh một phần lớn hơn nhiều của các tham số để dịch với chất lượng cao hơn, trong khi ByT5 chỉ cần điều chỉnh nhiều nhất là các cross attention của nó.

Dưới ánh sáng của những cải thiện tối thiểu từ việc huấn luyện thêm trên zero-shot, việc dừng sớm sử dụng một tập hợp các ví dụ ngôn ngữ tài nguyên thấp được để lại có vẻ lý tưởng.

**Chữ viết có Ảnh hưởng đến Suy giảm không?** Thực tế là việc đóng băng encoder bảo tồn chất lượng trên các ngôn ngữ zero-shot thu hẹp điểm thất bại của ByT5 xuống phía nguồn. Vì một sự khác biệt lớn giữa các mô hình ký tự và từ con là các nhúng token dày đặc và thưa thớt tương ứng của chúng, chúng tôi kiểm tra tác động của chữ viết của mỗi ngôn ngữ đối với sự suy giảm chất lượng dịch thuật. Chúng tôi hy vọng rằng, ví dụ, với các mô hình tiếng Đức →tiếng Anh của chúng tôi, các ngôn ngữ Latin khác sẽ bị ảnh hưởng nghiêm trọng hơn, do mức độ chồng chéo nhúng cao của chúng. Chúng tôi hy vọng những nhúng (và mã hóa tiếp theo) đó sẽ trở nên chuyên biệt chỉ cho tiếng Đức, trong khi các mã hóa không phải Latin nên vẫn tương đối không thay đổi.

Hình 6 cho thấy yếu tố suy giảm của các ngôn ngữ Latin so với không phải Latin cho các mô hình ByT5-large tiếng Anh ↔tiếng Đức và tiếng Anh →tiếng Nga của chúng tôi và Latin, Cyrillic, và tất cả các chữ viết đa byte khác cho các mô hình tiếng Nga →tiếng Anh của chúng tôi.

Đối với 3 hình con đầu tiên, chúng ta có thể thấy rằng các ngôn ngữ Latin suy giảm nhiều hơn các ngôn ngữ không phải Latin. Điều này được mong đợi, thấy rằng ByT5 chia sẻ nhúng (và có lẽ là mã hóa) cho tất cả các ngôn ngữ Latin. Vì vậy, ví dụ, khi nó đang chỉ định cho tiếng Đức →tiếng Anh, bất kỳ ngôn ngữ Latin nào không liên quan đến tiếng Đức đều nên bị ảnh hưởng tiêu cực đặc biệt. Trong khi đó, các chữ viết khác chia sẻ ít byte hơn, và do đó sẽ ít bị ảnh hưởng hơn.

Đối với tiếng Nga →tiếng Anh, chúng ta không thấy xu hướng tương tự với Cyrillic, mà thay vào đó các chữ viết khác bị ảnh hưởng nặng nề. Chúng tôi nghi ngờ điều này có hai lý do. Thứ nhất, các ngôn ngữ Cyrillic tập trung nhiều hơn xung quanh Nga so với các ngôn ngữ Latin xung quanh châu Âu, vì vậy các ngôn ngữ Cyrillic có xu hướng có liên quan chặt chẽ hơn với, và một phần có thể hiểu lẫn nhau với, tiếng Nga (ví dụ: tiếng Ukraine), hoặc có một số từ vay mượn từ tiếng Nga (ví dụ: tiếng Kazakh). Trong khi đó, các chữ viết không phải Latin, không phải Cyrillic khác bị ảnh hưởng nặng nề vì chúng cũng là các chữ viết đa byte. Những chữ viết này chia sẻ một phần lớn byte với Cyrillic và với nhau do cách UTF-8 mã hóa các ký tự đa byte. Ví dụ, "И" trong Cyrillic được mã hóa trong byte là [208, 152], trong khi "ग" Devanagari là [224, 164, 152]. Cả hai đều chia sẻ byte cuối cùng vì cả hai đều là ký tự thứ 25 trong các khối mã tương ứng của chúng.

Do đó, chúng tôi thấy rằng các chữ viết đa byte có thể bị suy giảm dịch thuật zero-shot do chồng chéo từ vựng với chữ viết phía nguồn gốc, giả định rằng chữ viết phía nguồn này là một chữ viết đa byte khác.

Vì chúng tôi quan sát sự mất tính tổng quát chỉ khi ít nhất 50k câu được sử dụng để tinh chỉnh, các phần tiếp theo chủ yếu tập trung vào kết quả từ các mô hình sử dụng giữa 0.4k và 10k ví dụ tinh chỉnh.

## 6 Phân tích Quy kết
Trong nghiên cứu dịch thuật, từ được công nhận rộng rãi là đơn vị tối thiểu của dịch thuật (Hatim và Munday, 2004). Do đó, tự nhiên là giả định rằng một ánh xạ từ nguồn đến đích hoặc từ con có thể dễ tạo hơn một ánh xạ ở mức ký tự, ngoại trừ có lẽ đối với các ngôn ngữ có liên quan chặt chẽ nơi nhiều từ dịch thành các từ có nguồn gốc tương tự về mặt chính tả. Do đó, có vẻ như các mô hình (từ con) tự nhiên phù hợp hơn đối với dịch máy, nhưng kết quả của chúng tôi từ các phần trước dường như mâu thuẫn với điều đó. Điều này tự nhiên dẫn chúng tôi đến việc điều tra liệu và cách mà các mô hình ký tự có thể học để kết hợp thông tin ở mức từ để cải thiện khả năng dịch thuật của chúng.

Một cách phổ biến để định lượng ảnh hưởng của đầu vào trong việc điều khiển dự đoán mô hình là thông qua các phương pháp quy kết đặc trưng (Madsen et al., 2022), đã được áp dụng trước đây trong lĩnh vực MT để làm nổi bật các căn chỉnh từ, khả năng giải quyết đồng tham chiếu, và động lực huấn luyện mô hình (Ding et al., 2019; He et al., 2019; Voita et al., 2021b inter alia). Để phân tích của chúng tôi, chúng tôi nghiên cứu các đóng góp ký tự nguồn so với đích trong các mô hình ByT5 sử dụng gradient (Simonyan et al., 2014), gần đây được chứng minh là trung thực hơn các phương pháp tiên tiến khác cho các tác vụ ngôn ngữ (Bastings et al., 2022). Người ta có thể lấy gradient liên quan đến xác suất của một token được dự đoán và truyền chúng ngược về các đầu vào của mô hình để định lượng tầm quan trọng của các token đầu vào đối với dự đoán kết quả. Phân tích của chúng tôi được lấy cảm hứng từ Voita et al. (2021a), nơi một phân tích tương tự được tiến hành trên các mô hình MT từ con để làm nổi bật một "chế độ mô hình hóa ngôn ngữ" nơi tầm quan trọng cao được đưa cho tiền tố đích trong khi bỏ qua các token nguồn.

Trong nghiên cứu của chúng tôi, chúng tôi tính toán gradient cho mỗi token đầu vào (tức là một ký tự) liên quan đến xác suất dự đoán token tiếp theo tại mọi bước tạo sinh sử dụng thư viện Inseq (Sarti et al., 2023). Đối với mỗi token được tạo sinh, các vector gradient được tổng hợp ở mức ký tự sử dụng chuẩn L2 của vector gradient để đánh giá ảnh hưởng của bối cảnh nguồn và đích đối với các dự đoán của mô hình.

Chúng tôi xác minh giả thuyết của chúng tôi rằng các mô hình NMT ở mức ký tự có thể hoạt động ngầm ở mức từ bằng cách so sánh các đóng góp phía nguồn và phía đích trên các kích thước mô hình và cặp ngôn ngữ khác nhau. Trong bối cảnh này, một bản dịch ký tự-theo-ký tự sẽ được đặc trưng bởi các quy kết nguồn tương đối đồng đều trên tất cả các ký tự được tạo sinh, trong khi một bản dịch từ-theo-từ sẽ ngụ ý một đóng góp nguồn cao hơn của các ký tự đánh dấu sự bắt đầu của một từ mới, tiếp theo là một sự chuyển đổi tầm quan trọng về phía tiền tố đích cho thấy rằng việc hoàn thành từ đòi hỏi truy cập hạn chế vào thông tin phía nguồn. Hình 1 cung cấp một ví dụ về các đóng góp nguồn và đích, cho thấy một sự tăng đáng chú ý trong tầm quan trọng nguồn ở đầu mỗi từ.

**Thông tin Mức Từ được Sử dụng như thế nào trong Các Mô hình Ký tự?** Hình 7 (trái) xác nhận sự giảm tầm quan trọng nguồn trong suốt quá trình tạo sinh được quan sát bởi Voita et al. (2021a) cho một số mô hình ByT5. Trong biểu đồ bên trái, chúng tôi tính toán tầm quan trọng nguồn trung bình liên quan đến vị trí của ký tự trong câu. Trong khi tiến triển qua quá trình tạo sinh, chúng tôi quan sát rằng mô hình dựa vào phía nguồn ít hơn và phía đích nhiều hơn cho các dự đoán byte tiếp theo của nó. Điều này phù hợp với các phát hiện của Voita et al. (2021a) đối với các mô hình MT ở mức từ con, với giải thích trực quan rằng một bối cảnh được tạo sinh dài hơn có thể cung cấp nhiều gợi ý hơn cho mô hình để tạo ra một đầu ra mạch lạc mà không cần phải chú ý đến các token phía nguồn.

Trong biểu đồ bên phải, thay vào đó, chúng tôi tính toán tầm quan trọng nguồn trung bình tương đối cho các vị trí byte trong từ. Vì các byte xảy ra muộn hơn trong một từ cũng xảy ra muộn hơn trong một câu, chúng tôi sẽ mong đợi tầm quan trọng nguồn giảm muộn hơn trong một từ như một hệ quả của xu hướng được thấy trong biểu đồ bên trái. Để tách biệt hiệu ứng của vị trí byte trong từ khỏi vị trí ở mức câu, chúng tôi chuẩn hóa các điểm tầm quan trọng nguồn bằng trung bình của chúng cho vị trí tương ứng trong câu (tức là, chúng tôi chia mỗi điểm trong từ cho trung bình ở mức câu tương ứng từ biểu đồ bên trái). Kết quả là, chúng tôi sẽ mong đợi tầm quan trọng nguồn tương đối ổn định gần 100% trên tất cả các vị trí byte trong từ nếu vị trí của các ký tự bên trong từ không ảnh hưởng đến tầm quan trọng nguồn. Thay vào đó, chúng tôi quan sát một sự giảm nhanh chóng của tầm quan trọng nguồn trong từ trên tất cả các ngôn ngữ, ngụ ý một sự tăng tầm quan trọng phía đích cho các ký tự được tạo sinh không phải đầu từ. Khi kiểm tra thủ công các mẫu tầm quan trọng, chúng tôi lưu ý rằng tầm quan trọng phía đích tập trung chủ yếu vào các ký tự trước đó thuộc cùng một từ, cho thấy việc sử dụng thông tin ở mức từ để hỗ trợ dịch thuật.

Thú vị là, đối với tiếng Anh →tiếng Nga, chúng tôi quan sát một mẫu tầm quan trọng dao động đạt đỉnh ở các vị trí chẵn. Xu hướng quan sát được phản ánh việc mã hóa UTF-8 Cyrillic sử dụng 2 byte cho mỗi ký tự, với các đỉnh tại ranh giới byte đầu tiên chỉ ra khả năng của mô hình trong việc phân biệt ký tự và byte trong các ngôn ngữ sử dụng ký tự đa byte. Chúng tôi cũng lưu ý rằng các quy kết nguồn tương đối dường như hội tụ về 100% xung quanh ký tự thứ ba đối với các ngôn ngữ chữ Latin và xung quanh ký tự thứ sáu trong từ đối với tiếng Nga. Những kết quả này cho thấy rằng các mẫu tầm quan trọng tương tự có thể xuất hiện trên các ngôn ngữ khác nhau trong các mô hình ký tự mặc dù có các quy trình tinh chỉnh riêng biệt.

**Mức độ Tài nguyên Ảnh hưởng đến Mô hình hóa Mức Từ như thế nào?** Trong Hình 8, chúng tôi kiểm tra cách tầm quan trọng nguồn tương đối thay đổi khi có nhiều dữ liệu huấn luyện hơn, và sự khác biệt của nó giữa các ngôn ngữ được huấn luyện và zero-shot. Biểu đồ bên trái cho thấy rằng một lượng lớn hơn các ví dụ huấn luyện góp phần làm sắc nét đóng góp nguồn xung quanh vài byte đầu tiên trong một từ trong khi giảm tầm quan trọng nguồn cho các byte tiếp theo. Những kết quả này ủng hộ trực giác của chúng tôi rằng các đồng xuất hiện được ghi nhớ giữa các từ nguồn và đích, được nắm bắt dễ dàng hơn khi được cung cấp nhiều ví dụ huấn luyện hơn, cho phép tạo sinh tự tin với ít dựa vào văn bản nguồn hơn. Từ biểu đồ bên phải, chúng tôi cũng lưu ý cách xu hướng này không tự động mở rộng sang các ngôn ngữ có liên quan khi thực hiện dịch thuật zero-shot, với các mẫu tầm quan trọng nguồn cho dịch thuật {tiếng Hà Lan, tiếng Limburgish} →tiếng Anh sử dụng mô hình tiếng Đức →tiếng Anh trình bày một xu hướng mượt mà có thể so sánh với xu hướng 0.4k tiếng Đức →tiếng Anh trong biểu đồ bên trái. Điều này cho thấy rằng các đồng xuất hiện được ghi nhớ làm giảm sự phụ thuộc phía nguồn không tổng quát hóa sang các ngôn ngữ có liên quan ngay cả khi chất lượng dịch thuật có.

## 7 Hiệu ứng của Tương tự Từ và Tần suất
Các mô hình ký tự trước đây đã được chứng minh có từ vựng mạnh mẽ hơn và do đó có thể tạo ra những thiên vị hữu ích để dịch các từ tương tự về mặt chính tả, cũng như từ hiếm (Lee et al., 2017). Chúng tôi xem lại những phát hiện này để xem liệu chúng có đúng với các Transformer đa ngôn ngữ được huấn luyện trước lớn hơn hay không.

**Các Mô hình Ký tự có thể Khai thác Tương tự Từ không?** Chúng tôi tiến hành điều tra liệu các mô hình ký tự có thể hoạt động ở mức ký tự khi mong muốn hay không. Để làm điều này, chúng tôi tập trung phân tích của chúng tôi vào các từ tương tự về mặt chính tả (OSW), bắt đầu từ giả định rằng một mô hình ký tự có thể dễ dàng khai thác sự tương tự của chúng bằng cách học sao chép các chuỗi con khớp. Chúng tôi bắt đầu bằng việc đánh giá liệu các mô hình ký tự có cho thấy hiệu suất cải thiện cho dịch thuật OSW hay không. Chúng tôi sử dụng AWESoME (Dou và Neubig, 2021) để căn chỉnh các câu nguồn, tham chiếu và giả thuyết và tính toán độ chính xác dịch thuật ở mức từ. Định nghĩa OSW của chúng tôi dựa trên khoảng cách Levenshtein chuẩn hóa ngược của các từ nguồn và tham chiếu, thay đổi ngưỡng từ 0 đến 100%, ví dụ: tiếng Đức gesundheit và tiếng Hà Lan gezondheid có độ tương tự 70% vì chúng khác nhau ở ba chữ cái.

Hình 9 cho thấy delta độ chính xác ở mức từ cho các mô hình lớn ByT5 và mT5 được huấn luyện trên tiếng Đức →tiếng Anh và tiếng Bồ Đào Nha →tiếng Tây Ban Nha trên các từ được nhóm ở các mức độ tương tự chính tả khác nhau. Chúng tôi quan sát rằng, khi các từ trở nên tương tự hơn, delta độ chính xác cũng tăng theo hướng có lợi cho ByT5, đặc biệt khi ít dữ liệu tinh chỉnh được sử dụng. Những kết quả này cho thấy rằng các mô hình ký tự có thể học các bản dịch OSW nhanh chóng và hiệu quả hơn so với các đối tác từ con của chúng.

Chúng tôi tiến hành bằng cách kiểm tra các đóng góp nguồn của OSW và không-OSW sử dụng ByT5, và cách những thay đổi đó theo số lượng ví dụ được sử dụng để tinh chỉnh. Chúng tôi hạn chế phân tích của chúng tôi đến >70% độ tương tự cho OSW, và <30% độ tương tự cho không-OSW. Chúng tôi chỉ xem xét tầm quan trọng nguồn đối với các ký tự thuộc cùng một từ, để điều tra sự hiện diện của các mẫu sao chép cho OSW. Như được hiển thị trong Hình 10, tầm quan trọng của văn bản nguồn tăng với lượng dữ liệu tinh chỉnh khi dịch OSW trong cài đặt tiếng Đức →tiếng Anh (cùng hướng với huấn luyện), cho thấy khả năng cải thiện của mô hình trong việc sao chép thông tin từ nguồn. Ngược lại, chúng tôi quan sát một xu hướng giảm cho hướng zero-shot tiếng Hà Lan →tiếng Anh, hội tụ về tầm quan trọng nguồn của tiếng Limburgish, không có trong dữ liệu huấn luyện trước của mô hình. Điều này có thể cho thấy rằng kiến thức tiếng Hà Lan được thu thập trong quá trình huấn luyện trước dần dần bị mất khi tinh chỉnh trên ngày càng nhiều dữ liệu tiếng Đức, ủng hộ kết quả của Hình 3. Đối với không-OSW, chúng tôi tìm thấy tầm quan trọng nguồn tương đối là 94±4% trên tất cả ba hướng và tất cả các lượng ví dụ huấn luyện, cho thấy rằng hành vi sao chép được quan sát chỉ hạn chế đối với các từ có độ tương tự cao.

Để xác nhận thêm rằng hành vi sao chép này thực sự khác biệt giữa một mô hình từ con và ký tự, chúng tôi tạo ra một bộ kiểm tra kiểm soát tổng hợp bằng cách thay thế tất cả các cặp danh từ riêng (các cặp từ được gắn thẻ là danh từ riêng trong cả câu nguồn và tham chiếu đích) bằng các chuỗi ngẫu nhiên của các ký tự bảng chữ cái Latin khớp với độ dài của các từ gốc. Điều này được thực hiện cho các mô hình lớn tiếng Đức →tiếng Anh của chúng tôi, sửa đổi bộ kiểm tra tiếng Đức →tiếng Anh từ FLoRes200. Bảng 3 báo cáo độ chính xác của các mô hình từ con và ký tự trong việc sao chép các chuỗi ngẫu nhiên từ đầu vào nguồn vào đầu ra được tạo sinh.

Chúng tôi quan sát rằng đối với mô hình mT5 ở mức từ con, cơ chế sao chép được học dần dần trong quá trình tinh chỉnh. Trong khi đó, mô hình ByT5 thay vào đó đạt được hiệu suất sao chép vượt trội với rất ít giám sát, đạt được độ chính xác 91% chỉ với 400 ví dụ huấn luyện. Chúng tôi cũng quan sát rằng hiệu suất của mT5 trên chrF++ cải thiện với ví dụ tăng, trong khi hiệu suất của ByT5 vẫn tương đối không bị ảnh hưởng. So sánh điều này với điểm chrF++ trên bộ kiểm tra gốc, chúng ta thấy rằng điểm của ByT5 không thay đổi, trong khi điểm của mT5 giảm lên đến 8 điểm khi bộ kiểm tra được sửa đổi.

Mặc dù bộ kiểm soát của chúng tôi chỉ nhắm vào danh từ riêng, hành vi sao chép này có thể lan rộng hơn nhiều, vì nó có thể có trong bất kỳ từ vay mượn nào, bất kể từ loại. Sự khác biệt lớn trong điểm số, đặc biệt trên các mô hình được tinh chỉnh chỉ trên 400 ví dụ, dường như cho thấy một sự khác biệt lớn trong hành vi mặc định của hai mô hình.

**Các Mô hình Ký tự có thể Dịch Từ Hiếm Chính xác hơn không?** Công việc trước đây đã cho thấy các mô hình ký tự đạt được độ chính xác dịch thuật tốt hơn của từ hiếm (Lee et al., 2017; Singh, 2017), vì vậy chúng tôi mong đợi điều tương tự cũng đúng đối với các Transformer lớn, đã huấn luyện trước. Chúng tôi áp dụng cùng phương pháp độ chính xác dịch thuật ở mức từ như trước đó trong phần, nhưng thay vào đó phân chia các từ dựa trên tần suất của chúng trong dữ liệu tinh chỉnh tiếng Anh. Chúng tôi đánh giá độ chính xác ở mức từ của ByT5 so với mT5-large khi được tinh chỉnh trên 10k cặp câu tiếng Đức →tiếng Anh. Chúng tôi bổ sung phân biệt giữa độ chính xác sử dụng ngôn ngữ nguồn gốc và độ chính xác sử dụng các ngôn ngữ zero-shot.

Như được hiển thị trong Hình 11, ByT5 có độ chính xác dịch thuật ở mức từ cao hơn trên tất cả các tần suất cho các ngôn ngữ zero-shot, và tất cả trừ các từ thường xuyên nhất cho tiếng Đức. Nhìn chung, khi tần suất của từ tăng, sự chênh lệch mô hình giảm. Điều này được mong đợi dựa trên công việc trước đây (Singh, 2017). Sự chênh lệch cao hơn đối với các ngôn ngữ zero-shot nhìn chung, điều này cho thấy mức độ mạnh mẽ cao hơn đối với các thay đổi trong từ vựng từ ByT5, một hiện tượng cũng được quan sát trước đây (Belinkov và Bisk, 2017).

## 8 Hiệu suất
Mặc dù chúng tôi đã cho thấy rằng chất lượng dịch thuật của các mô hình ký tự có thể cạnh tranh hoặc tốt hơn các mô hình từ con, một khía cạnh quan trọng khác là hiệu suất của các mô hình ký tự. Trong khi việc thiếu hiệu suất của các mô hình Transformer ở mức ký tự được ghi chép đầy đủ (Libovický et al., 2022; Tay et al., 2022; Edman et al., 2022), chúng tôi vẫn chưa thấy hiệu suất của chúng trên các Transformer lớn hơn (300M+ tham số) cho NMT, và vì vậy chúng tôi cung cấp các phát hiện của chúng tôi để hoàn thiện. Chúng tôi báo cáo thời gian huấn luyện và suy luận mô hình cho 1 GPU NVIDIA V100 32GB trong Bảng 4.

Cả tốc độ huấn luyện và suy luận tính bằng mẫu mỗi giây đều chậm hơn đáng kể đối với các mô hình ký tự (chậm hơn 4-5 lần để huấn luyện, chậm hơn 5-6 lần để suy luận). Số epoch cần thiết để hội tụ thấp hơn đối với các mô hình ký tự, nhưng không đủ để chống lại sự chậm chạp của huấn luyện.

Tốc độ chậm hơn chủ yếu đến từ việc tăng độ dài chuỗi. Trong khi chúng tôi cố gắng cân bằng kích thước của các batch sao cho mỗi mô hình thấy cùng một lượng văn bản mỗi batch, việc đạt được điều này đòi hỏi các mô hình ký tự phải tích lũy gradient cho nhiều lần lặp gấp 4 lần so với các mô hình từ con. Do đó, nếu tốc độ huấn luyện hoặc suy luận là mối quan tâm, các mô hình từ con có thể là lựa chọn vượt trội, đặc biệt đối với các ngôn ngữ có tài nguyên cao. Trong cài đặt tài nguyên thấp, có một sự đánh đổi đáng kể giữa độ chính xác và tốc độ khi chọn giữa các mô hình ký tự và từ con.

Cần lưu ý rằng có một số lựa chọn thay thế cho các mô hình ký tự hoặc byte vanilla cung cấp tăng tốc, thường bằng cách nén độ dài chuỗi trước khi phần lớn tính toán được thực hiện trong Transformer (El Boukkouri et al., 2020; Clark et al., 2022; Yu et al., 2023, inter alia). Tuy nhiên, không có phương pháp nào trong số này khẳng định xử lý nhanh hơn so với một mô hình ở mức từ con tiêu chuẩn, vì vậy vẫn sẽ có một sự đánh đổi giữa độ chính xác và tốc độ khi áp dụng những phương pháp này, mặc dù ở mức độ ít hơn.

## 9 Kết luận
Các mô hình ở mức từ con hiện tại là mô hình thống trị cho dịch máy. Tuy nhiên, công việc này cho thấy rằng các mô hình ký tự có thể tạo ra kết quả cạnh tranh hoặc thậm chí vượt trội trong nhiều hoàn cảnh. Đầu tiên, các mô hình ký tự có được chất lượng dịch thuật tổng thể tốt hơn trên các cặp ngôn ngữ được huấn luyện. Hơn nữa, chúng tôi làm nổi bật cách mà lợi ích về chất lượng dịch thuật từ việc sử dụng các mô hình ký tự đặc biệt rõ ràng khi dữ liệu tinh chỉnh khan hiếm. Cuối cùng, chúng tôi cho thấy cách các mô hình ký tự có khả năng chuyển giao đa ngôn ngữ vượt trội, đặc biệt với các ngôn ngữ được thấy trong huấn luyện trước, hoặc những ngôn ngữ tương tự như một ngôn ngữ được thấy trong huấn luyện trước.

Theo kết quả của các phân tích của chúng tôi, chúng tôi có thể quy chất lượng vượt trội này cho khả năng của một mô hình ký tự trong việc ngầm tính đến độ chi tiết đầu vào thích hợp cho bối cảnh, dịch đôi khi theo cách từ-theo-từ, hoặc ký-tự-theo-ký-tự khi cần thiết. Điều này cuối cùng dẫn đến độ chính xác tốt hơn khi dịch các từ tương tự về mặt chính tả và từ hiếm.

Tuy nhiên, sự tăng chất lượng không phải không có sự đánh đổi. Thực sự, các mô hình ký tự chậm hơn ít nhất 4 lần trong huấn luyện và suy luận, làm cho chúng không tối ưu cho nhiều tình huống thế giới thực. Chúng tôi cho rằng công việc thêm về việc tăng tốc các mô hình tạo sinh (Stern et al., 2018; Edman et al., 2022; Santilli et al., 2023, inter alia), cũng như các đánh giá kỹ lưỡng hơn về các chỉ số thần kinh cho các mô hình ký tự, sẽ có lợi rất nhiều cho lĩnh vực nghiên cứu này. Tuy nhiên, chúng tôi có thể kết luận rằng trong các cài đặt ít nhạy cảm về thời gian, hoặc tài nguyên thấp, các bản dịch ở mức ký tự đáng để chờ đợi.

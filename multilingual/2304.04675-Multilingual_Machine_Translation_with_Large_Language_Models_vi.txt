# Dịch máy đa ngôn ngữ với các mô hình ngôn ngữ lớn:
Kết quả thực nghiệm và phân tích
Wenhao Zhu1,2, Hongyi Liu3, Qingxiu Dong4, Jingjing Xu2
Shujian Huang1, Lingpeng Kong5, Jiajun Chen1, Lei Li6
1Phòng thí nghiệm Công nghệ Phần mềm Mới Quốc gia, Đại học Nam Kinh
2Phòng thí nghiệm AI Thượng Hải3Đại học Giao thông Thượng Hải4Đại học Bắc Kinh
5Đại học Hồng Kông6Viện Công nghệ Ngôn ngữ, Đại học Carnegie Mellon
zhuwh@smail.nju.edu.cn ,liu.hong.yi@sjtu.edu.cn ,dqx@stu.pku.edu.cn ,jingjingxu@pku.edu.cn
huangsj@nju.edu.cn ,lpk@cs.hku.hk ,chenjj@nju.edu.cn ,leili@cs.cmu.edu
Tóm tắt
Các mô hình ngôn ngữ lớn (LLM) đã chứng tỏ tiềm năng đáng kể trong việc xử lý dịch máy đa ngôn ngữ (MMT). Trong bài báo này, chúng tôi nghiên cứu có hệ thống các ưu điểm và thách thức của LLM đối với MMT bằng cách trả lời hai câu hỏi: 1) LLM hoạt động tốt như thế nào trong việc dịch nhiều ngôn ngữ? 2) Những yếu tố nào ảnh hưởng đến hiệu suất của LLM trong dịch thuật? Chúng tôi đánh giá kỹ lưỡng tám LLM phổ biến, bao gồm ChatGPT và GPT-4. Kết quả thực nghiệm của chúng tôi cho thấy khả năng dịch thuật của LLM đang liên tục phát triển. GPT-4 đã vượt qua hệ thống cơ sở được giám sát mạnh NLLB trong 40,91% hướng dịch nhưng vẫn còn khoảng cách lớn so với hệ thống dịch thương mại như Google Translate, đặc biệt trên các ngôn ngữ ít tài nguyên. Thông qua phân tích sâu hơn, chúng tôi phát hiện ra rằng LLM thể hiện các mô hình hoạt động mới khi được sử dụng cho MMT. Thứ nhất, LLM có thể thu được khả năng dịch thuật theo cách tiết kiệm tài nguyên và tạo ra bản dịch vừa phải ngay cả trên các ngôn ngữ không có tài nguyên. Thứ hai, ngữ nghĩa hướng dẫn có thể bị bỏ qua một cách đáng ngạc nhiên khi được đưa ra các ví dụ trong ngữ cảnh. Thứ ba, các ví dụ đa ngôn ngữ có thể cung cấp hướng dẫn nhiệm vụ tốt hơn cho dịch thuật ít tài nguyên so với các ví dụ trong cùng cặp ngôn ngữ1.

1 Giới thiệu
Với quy mô tham số và kho ngữ liệu huấn luyện ngày càng tăng, các mô hình ngôn ngữ lớn (LLM) đã có được khả năng phổ quát để xử lý nhiều nhiệm vụ khác nhau thông qua học trong ngữ cảnh (ICL, Brown et al. 2020), cho phép các mô hình ngôn ngữ thực hiện các nhiệm vụ với một vài ví dụ đã cho và hướng dẫn viết bằng tay làm ngữ cảnh. Một lĩnh vực cụ thể mà LLM đã thể hiện tiềm năng nổi bật là dịch máy (MT). Các nghiên cứu trước đây đã cho thấy hiệu suất đáng ngạc nhiên của LLM trong dịch song ngữ có nhiều tài nguyên, chẳng hạn như dịch tiếng Anh-Đức (Vilar et al., 2022; Zhang et al., 2022), ngay cả khi những mô hình này không được tối ưu hóa đặc biệt trên dữ liệu đa ngôn ngữ.

Tuy nhiên, khả năng dịch đa ngôn ngữ của LLM vẫn chưa được khám phá đầy đủ. MMT là một nhiệm vụ thách thức liên quan đến việc dịch văn bản giữa các ngôn ngữ khác nhau và đòi hỏi sự căn chỉnh ngữ nghĩa giữa các ngôn ngữ (Fan et al., 2021; Team, 2022; Yuan et al., 2023). Cũng không rõ ràng rằng LLM thu được khả năng dịch như thế nào và những yếu tố nào ảnh hưởng đến khả năng dịch của LLM.

Trong bài báo này, chúng tôi tuân theo mô hình ICL và tập trung nghiên cứu LLM trong dịch máy đa ngôn ngữ bằng cách trả lời hai câu hỏi: 1) LLM thực hiện MMT trên nhiều ngôn ngữ như thế nào? 2) Những yếu tố nào ảnh hưởng đến hiệu suất của LLM?

Đối với câu hỏi đầu tiên, chúng tôi đánh giá một số LLM phổ biến: LLM lấy tiếng Anh làm trung tâm, bao gồm OPT (Zhang et al., 2022), LLaMA2 (Touvron et al., 2023), Falcon (Almazrouei et al., 2023) và LLM đa ngôn ngữ, bao gồm XGLM (Lin et al., 2022), BLOOMZ (Scao et al., 2022), ChatGPT (OpenAI, 2022), GPT-4 (OpenAI, 2023). Chúng tôi xem xét 102 ngôn ngữ và 606 hướng dịch (202 hướng lấy tiếng Anh làm trung tâm, 202 hướng lấy tiếng Pháp làm trung tâm và 202 hướng lấy tiếng Trung làm trung tâm). Kết quả cho thấy khả năng dịch đa ngôn ngữ của LLM đang liên tục phát triển và GPT-4 đạt đến độ cao hiệu suất mới. So với hệ thống MMT được giám sát được sử dụng rộng rãi NLLB (Team, 2022), GPT-4 đạt hiệu suất cao hơn trên 40,91% hướng dịch lấy tiếng Anh làm trung tâm. Nhưng so với hệ thống dịch thương mại (Google Translate), LLM vẫn có một chặng đường dài phía trước, đặc biệt khi nói đến các ngôn ngữ ít tài nguyên. Dịch lấy tiếng Pháp và tiếng Trung làm trung tâm cũng thách thức hơn đối với GPT-4 so với dịch lấy tiếng Anh làm trung tâm, điều này càng chỉ ra khả năng không cân bằng của nó giữa các ngôn ngữ.

Đối với câu hỏi thứ hai, chúng tôi tìm thấy một số mô hình hoạt động mới. Thứ nhất, chúng tôi phát hiện ra rằng LLM có thể thu được khả năng dịch theo cách tiết kiệm tài nguyên và tạo ra bản dịch vừa phải ngay cả trên các ngôn ngữ không có tài nguyên. Thứ hai, LLM có thể thực hiện dịch thuật ngay cả với các hướng dẫn không hợp lý nếu các ví dụ học trong ngữ cảnh được đưa ra. Tuy nhiên, nếu được đưa ra các cặp dịch không khớp làm ví dụ trong ngữ cảnh, LLM sẽ thất bại trong việc dịch, điều này tương tự như các quan sát từ các nghiên cứu đồng thời (Wei et al., 2023). Điều này cho thấy tầm quan trọng của các ví dụ trong ICL đối với dịch máy. Thứ ba, chúng tôi thấy rằng các cặp dịch đa ngôn ngữ có thể là những ví dụ tốt một cách đáng ngạc nhiên cho dịch ít tài nguyên, thậm chí tốt hơn các ví dụ trong cùng ngôn ngữ. Đóng góp chính của bài báo này có thể được tóm tắt như sau:

• Chúng tôi đánh giá chuẩn các LLM phổ biến trên MMT trong 102 ngôn ngữ và 606 hướng dịch, bao gồm dịch lấy tiếng Anh, tiếng Pháp và tiếng Trung làm trung tâm.

• Chúng tôi so sánh có hệ thống kết quả của LLM và ba hệ thống cơ sở được giám sát mạnh (M2M-100, NLLB, Google Translator) và tiết lộ khoảng cách giữa hai mô hình dịch.

• Chúng tôi tìm thấy một số mô hình hoạt động ICL mới của LLM cho MMT và thảo luận các ưu điểm và thách thức tương ứng.

2 Nền tảng

2.1 Các mô hình ngôn ngữ lớn
Mô hình hóa ngôn ngữ là một nhiệm vụ lâu đời trong xử lý ngôn ngữ tự nhiên (Bengio et al., 2000; Mikolov et al., 2010; Khandelwal et al., 2020), đây là nhiệm vụ dự đoán xác suất của token tiếp theo. Transformer (Vaswani et al., 2017) về cơ bản là xương sống của các LLM hiện tại.

LLM cho thấy tiềm năng lớn như một người học đa nhiệm vụ phổ quát. Gần đây, Radford et al. (2019) phát hiện ra rằng một mô hình ngôn ngữ chỉ giải mã ngẫu nhiên có thể là một người học đa nhiệm vụ chỉ với kho ngữ liệu huấn luyện không giám sát. Sau đó, Kaplan et al. (2020) tiết lộ quy luật tỷ lệ của LLM, chỉ ra rằng khi quy mô tham số thần kinh và dữ liệu huấn luyện tiếp tục tăng, LLM có thể được củng cố thêm. Wei et al. (2022b) cho thấy rằng việc mở rộng mô hình ngôn ngữ cũng mang lại những khả năng nổi bật đáng kinh ngạc, ví dụ như học trong ngữ cảnh, chỉ có mặt trong các mô hình lớn. Do đó, ngày càng nhiều nỗ lực được đưa vào việc mở rộng các mô hình ngôn ngữ (Brown et al., 2020; Hoffmann et al., 2022; Scao et al., 2022; Vilar et al., 2022; Ren et al., 2023). Trong số đó, GPT-4 (OpenAI, 2023) và ChatGPT (OpenAI, 2022) là những hệ thống đại diện nhất, cho thấy kết quả ấn tượng trong các nhiệm vụ NLP khác nhau.

2.2 Khả năng nổi bật: Học trong ngữ cảnh
Học trong ngữ cảnh là một trong những khả năng nổi bật nổi tiếng (Brown et al., 2020; Dong et al., 2022), cho phép LLM học các nhiệm vụ mục tiêu theo lời nhắc mà không cập nhật bất kỳ tham số nào.

Cụ thể, lời nhắc được tạo thành từ các ví dụ trong ngữ cảnh {(Xi,Yi)}k i=1 và mẫu trong ngữ cảnh T. Các ví dụ thường được chọn từ dữ liệu được giám sát, trong đó Yi là sự thật cơ bản tương ứng với câu đầu vào Xi. Mẫu T thường là một hướng dẫn viết bằng tay liên quan đến nhiệm vụ mục tiêu. Gói các ví dụ với mẫu và nối chúng lại với nhau tạo ra lời nhắc cuối cùng:

P=T(X1,Y1)⊕ T(X2,Y2)⊕ ··· ⊕ T (Xk,Yk)

trong đó ⊕ biểu thị ký hiệu nối, ví dụ như khoảng trắng, ngắt dòng. Trong quá trình suy luận, LLM có thể tạo ra đầu ra tương ứng Y của mẫu thử nghiệm X dưới sự hướng dẫn của lời nhắc:

arg max Y p(P ⊕ T (X,Y)) (1)

Đối với các nhiệm vụ dự đoán nhãn, dự đoán Y có thể được thu được trong việc tạo một bước. Đối với các nhiệm vụ tạo chuỗi, ví dụ như dịch máy, dự đoán Y có thể được thu được thông qua các chiến lược lấy mẫu như tìm kiếm tham lam và tìm kiếm chùm.

[Tiếp tục với phần còn lại của bản dịch...]

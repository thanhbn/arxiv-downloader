# Tăng cường dữ liệu có thể đảo ngược xác định cho dịch máy thần kinh

Jiashu Yao1 Heyan Huang1 Zeming Liu2 Yuhang Guo1∗
1Khoa Khoa học Máy tính và Công nghệ, Viện Công nghệ Bắc Kinh
2Khoa Khoa học Máy tính và Kỹ thuật, Đại học Beihang
{yaojiashu, hhy63, guoyuhang}@bit.edu.cn, zmliu@buaa.edu.cn

## Tóm tắt

Tăng cường dữ liệu là một cách hiệu quả để đa dạng hóa kho ngữ liệu trong dịch máy, nhưng các phương pháp trước đây có thể gây ra sự không nhất quán về ngữ nghĩa giữa dữ liệu gốc và dữ liệu tăng cường do các phép toán không thể đảo ngược và quy trình lấy mẫu từ con ngẫu nhiên. Để tạo ra dữ liệu tăng cường vừa đa dạng về ký hiệu vừa nhất quán về ngữ nghĩa, chúng tôi đề xuất Tăng cường Dữ liệu Có thể Đảo ngược Xác định (DRDA), một phương pháp tăng cường dữ liệu đơn giản nhưng hiệu quả cho dịch máy thần kinh. DRDA áp dụng các phân đoạn xác định và các phép toán có thể đảo ngược để tạo ra các biểu diễn từ con đa độ chi tiết và kéo chúng lại gần nhau bằng các kỹ thuật đa góc nhìn. Không cần thêm kho ngữ liệu hay thay đổi mô hình, DRDA vượt trội so với các baseline mạnh trên nhiều tác vụ dịch thuật với biên độ rõ ràng (tăng tới 4.3 BLEU so với Transformer) và thể hiện tính bền vững tốt trên các bộ dữ liệu nhiễu, tài nguyên thấp và liên miền. Mã nguồn liên quan có sẵn tại https://github.com/BITHLP/DRDA.

## 1 Giới thiệu

Các mô hình dịch máy thần kinh (NMT) gần đây đã dẫn đến những cải tiến đáng kể về chất lượng dịch thuật. Tuy nhiên, khả năng học tập và ghi nhớ mạnh mẽ của các mô hình này cũng dẫn đến khả năng tổng quát hóa kém và dễ bị tổn thương trước các nhiễu loạn nhỏ như lỗi chính tả và diễn đạt lại (Belinkov và Bisk, 2017; Cheng et al., 2020).

Một giải pháp phổ biến cho vấn đề dễ bị tổn thương trước nhiễu loạn là tăng cường dữ liệu (Sennrich et al., 2016b; Cheng et al., 2016), tức là tạo ra dữ liệu huấn luyện ảo lớn với các biểu diễn ký hiệu đa dạng dưới tiền đề đảm bảo tính nhất quán về ngữ nghĩa (Cheng et al., 2019, 2020). Tính đa dạng ký hiệu nhấn mạnh rằng dữ liệu gốc và dữ liệu tăng cường nên khác nhau đáng kể về chuỗi token, và tính nhất quán ngữ nghĩa yêu cầu hai loại dữ liệu này nên tương tự nhau về mặt ngữ nghĩa. Các phương pháp tăng cường dữ liệu trước đây sử dụng các phép thế không thể đảo ngược, như loại bỏ hoặc thay thế trực tiếp các token rời rạc để tạo ra dữ liệu đa dạng (Hình 1 A). Mặc dù có thể cải thiện tính đa dạng của dữ liệu, các phép toán tăng cường này không thể đảo ngược và sẽ không tránh khỏi việc gây ra mất mát ngữ nghĩa cho văn bản gốc, do đó làm tổn hại đến tính nhất quán ngữ nghĩa giữa dữ liệu gốc và dữ liệu tăng cường.

Một cách khác để tạo ra dữ liệu tăng cường đa dạng mà không sử dụng các phép toán không thể đảo ngược là chính quy hóa từ con (Kudo, 2018; Provilkov et al., 2020). Chính quy hóa từ con áp dụng các phân đoạn ngẫu nhiên để lấy mẫu từ con theo xác suất, do đó tạo ra dữ liệu đa dạng. Các phương pháp này có thể đảo ngược do tính đảo ngược vốn có của phân đoạn. Tuy nhiên, do quy trình lấy mẫu ngẫu nhiên của phân đoạn, chúng có thể áp dụng các phân đoạn từ con không phù hợp (ví dụ, "sup erm ark et" trong Hình 1 B). Các phân đoạn không tối ưu này có thể gây ra nhiễu loạn ngữ nghĩa và làm tổn hại đến tính nhất quán ngữ nghĩa.

Tóm lại, các phương pháp trước đây gặp khó khăn trong việc hoàn toàn giữ lại ngữ nghĩa khỏi bị hỏng khi đa dạng hóa văn bản do các phép toán tăng cường không thể đảo ngược và lấy mẫu từ con theo xác suất.

Để tạo ra dữ liệu đa dạng về ký hiệu và nhất quán về ngữ nghĩa, chúng tôi đề xuất Tăng cường Dữ liệu Có thể Đảo ngược Xác định (DRDA), một phương pháp tăng cường đơn giản nhưng hiệu quả. DRDA tăng cường các câu nguồn bằng các biểu diễn token của chúng ở các độ chi tiết khác nhau như được thể hiện trong Hình 1 C. Các biểu diễn này đa dạng về ký hiệu, nhưng cũng đúng về mặt cú pháp và hoàn chỉnh về mặt ngữ nghĩa nhờ các phân đoạn có thể đảo ngược và xác định trong quy trình phân đoạn đa độ chi tiết. Để tận dụng tối đa tính đồng nhất ngữ nghĩa giữa tất cả các biểu diễn đa độ chi tiết của một câu, chúng tôi cũng tận dụng các kỹ thuật đa góc nhìn trong huấn luyện để kéo các biểu diễn này lại gần nhau hơn.

Chúng tôi tiến hành các thí nghiệm rộng rãi trên các ngôn ngữ và quy mô khác nhau và thấy rằng DRDA đạt được những cải tiến nhất quán so với các baseline mạnh với biên độ rõ ràng. Để hiểu rõ hơn các yếu tố khiến DRDA hoạt động, chúng tôi tiến hành các phân tích sâu sắc về tác động của DRDA đối với tính nhất quán ngữ nghĩa, tần suất từ con và thành phần ngữ nghĩa từ con. Chúng tôi kết hợp việc xác minh thực nghiệm và lý thuyết về tính nhất quán và đưa ra giải thích ở mức từ con về cơ chế của phân đoạn đa độ chi tiết và kỹ thuật đa góc nhìn.

Các đóng góp của chúng tôi được tóm tắt như sau:
• Chúng tôi đề xuất DRDA chỉ sử dụng các phép toán có thể đảo ngược xác định để tạo ra dữ liệu tăng cường đa dạng mà không gây ra nhiễu ngữ nghĩa.
• Chúng tôi tiến hành các thí nghiệm rộng rãi và xác minh tính hiệu quả cao của DRDA.
• Để điều tra các yếu tố khiến DRDA hoạt động, chúng tôi kết hợp các phân tích thực nghiệm và lý thuyết và đưa ra các giải thích sâu sắc.

## 2 Các công trình liên quan

Phương pháp tăng cường Ngoài các phương pháp liên tục (Wei et al., 2022), tăng cường dữ liệu có thể được phân loại thành các phương pháp giống như dịch ngược (Sennrich et al., 2016b; Edunov et al., 2018; Nguyen et al., 2020) và các phương pháp thay thế token. DRDA là một thể hiện của danh mục sau.

Một số phương pháp thay thế chọn một cách đồng nhất một từ hoặc token trong câu và thực hiện xóa hoặc thay thế (Zhang et al., 2020; Shen et al., 2020; Wang et al., 2018b; Norouzi et al., 2016; Gao et al., 2022). Cheng et al. (2019, 2020) giới hạn việc thay thế một từ trong một tập con nhỏ các từ đồng nghĩa, do đó cải thiện tính nhất quán ngữ nghĩa. Kambhatla et al. (2022b) coi kho ngữ liệu gốc là văn bản thuần túy và áp dụng mã hóa xoay như tăng cường dữ liệu. Khác với các phương pháp trước đây, việc giới thiệu đa độ chi tiết tận dụng tính chất có thể đảo ngược của phân đoạn và không gây ra mất mát ngữ nghĩa.

Chính quy hóa từ con Phương pháp từ con de-facto, BPE (Sennrich et al., 2016c), vẫn gặp phải vấn đề không tối ưu (Bostrom và Durrett, 2020). Để khắc phục vấn đề không tối ưu này, một số phương pháp chính quy hóa từ con được đề xuất. Kudo (2018) và Provilkov et al. (2020) trình bày chính quy hóa từ con bằng cách mô hình hóa sự mơ hồ của phân đoạn. Wang et al. (2021) tích hợp BPE và BPE-Drop bằng cách thực thi tính nhất quán sử dụng chính quy hóa từ con đa góc nhìn, Wu et al. (2020) và Kambhatla et al. (2022a) kết hợp BPE trong SentencePiece và subword-nmt với nhau để có được hiệu ứng chính quy hóa. DRDA khác biệt với tất cả các phương pháp phân đoạn lấy mẫu ngẫu nhiên, vì dữ liệu tăng cường được tạo ra một cách xác định. Tính xác định giúp giảm thiểu phân đoạn kém hợp lý hơn, trong khi vẫn đạt được hiệu ứng chính quy hóa.

Ngoài ra, các nghiên cứu khác nỗ lực tận dụng các biểu diễn đa độ chi tiết, điều này cũng có thể được xem như một chính quy hóa từ con. Li et al. (2020) và Gao et al. (2020) áp dụng lưới từ và tích chập với các kích thước kernel khác nhau tương ứng, Chen et al. (2018) và Li et al. (2022) kết hợp các cấp độ thang đo biểu diễn, Hao et al. (2019) sửa đổi mô-đun tự chú ý để giới thiệu mô hình hóa cụm từ. Khác với các phương pháp này, DRDA không yêu cầu sửa đổi kiến trúc mô hình và có thể được áp dụng cho các tác vụ phổ quát.

## 3 Kiến thức nền tảng: Phân đoạn từ con

Phân đoạn từ con mô hình hóa xác suất của chuỗi token x = x₁, x₂, ..., xₘ cho trước một câu nguồn s. Các phân đoạn từ con xác định trước đây chọn mẫu có xác suất cao nhất:

x* = arg max_x P_seg(x|s;p) = arg max_{x∈V_p} P_seg(x|s), (1)

trong đó p là kích thước của từ điển (một tập hợp các ứng viên từ con), và mỗi token xᵢ (i ∈ {1,2,...,m}) được chọn từ từ điển Vₚ.

Ví dụ, Mã hóa Cặp Byte (BPE) gán P(x̂|s;p) = 1 khi x̂ được thu được từ quy trình hợp nhất tham lam (Sennrich et al., 2016c).

Để tạo ra các phân đoạn khác nhau cho một từ, các phương pháp chính quy hóa từ con rút một phân đoạn từ phân phối phân đoạn theo xác suất:

x ~ P_seg(x|s;p). (2)

Ví dụ, Kudo (2018) sử dụng mô hình ngôn ngữ unigram để lấy mẫu phân đoạn, và Provilkov et al. (2020) ngẫu nhiên gián đoạn quy trình hợp nhất BPE để tạo ra nhiều phân đoạn.

## 4 Tăng cường Dữ liệu Có thể Đảo ngược Xác định

Các phương pháp tăng cường dữ liệu và chính quy hóa từ con trước đây thực hiện phép toán không thể đảo ngược (như thay thế token rời rạc) và lấy mẫu phân đoạn theo xác suất, điều này có thể gây ra mất mát ngữ nghĩa hoặc từ con không phù hợp, do đó ảnh hưởng đến tính nhất quán ngữ nghĩa. Mục tiêu của chúng tôi là đảm bảo tính nhất quán ngữ nghĩa giữa dữ liệu gốc và dữ liệu tăng cường khi tạo ra dữ liệu đa dạng.

Chúng tôi đề xuất DRDA để tạo ra dữ liệu tăng cường mà không gây ra nhiễu loạn ngữ nghĩa. DRDA tăng cường dữ liệu gốc bằng phân đoạn đa độ chi tiết, và kéo các biểu diễn của một câu lại gần nhau bằng học đa góc nhìn. Hơn nữa, chúng tôi đề xuất một kỹ thuật lựa chọn động để tự động chọn một độ chi tiết phù hợp trong suy luận.

### 4.1 Phân đoạn đa độ chi tiết

DRDA xây dựng dữ liệu tăng cường đa dạng về ký hiệu và nhất quán về ngữ nghĩa bằng phân đoạn đa độ chi tiết. Điểm mấu chốt là phân đoạn từ con đa độ chi tiết là một quy trình có thể đảo ngược hoàn toàn giữ lại thông tin ngữ nghĩa, và là một quy trình xác định luôn chọn chính sách phân đoạn từ con có xác suất cao nhất và phù hợp nhất.

Chính thức, cho trước kích thước từ điển chính p và một tập hợp các kích thước từ điển tăng cường {qᵢ}ᵏᵢ₌₁, đối với một cặp mẫu dịch nguồn-đích (s,t), một chuỗi nguồn chính xᵖʳⁱ, một chuỗi đích y và một tập hợp các chuỗi nguồn tăng cường {xᵃᵘᵍᵢ}ᵏᵢ₌₁ có thể được tạo ra:

xᵖʳⁱ = arg max_{x∈V_p} P(x|s), (3)
xᵃᵘᵍᵢ = arg max_{x∈V_{q_i}} P(x|s), (4)
y = arg max_{y'∈V_p} P(y'|t). (5)

Hình 2 mô tả kiến trúc mô hình và mất mát huấn luyện trên một mẫu tiếng Anh → tiếng Đức. Cho trước p = 12000, q₁ = 1000, và q₂ = 6000, một câu tiếng Anh được phân đoạn với các từ điển khác nhau, tạo ra ba chuỗi token với các độ chi tiết khác nhau.

Lưu ý rằng theo tính chất tham lam của BPE, một từ điển ngắn là một tiền tố của một từ điển dài, miễn là chúng được thu được từ cùng một kho ngữ liệu. Do đó, việc giới thiệu các độ chi tiết khác nhau với BPE sẽ không dẫn đến từ điển lớn hơn, do đó tránh được sự gia tăng kích thước tham số. Một ví dụ được thể hiện trong Hình 2, trong đó ba ma trận nhúng E₁₂₀₀₀, E₆₀₀₀ và E₁₀₀₀ được chồng lấp, và một nhúng nhỏ hơn là một tiền tố của một nhúng lớn hơn.

### 4.2 Học đa góc nhìn

Hơn nữa, để làm cho mô hình dịch học từ các độ chi tiết phân đoạn khác nhau, chúng tôi sử dụng hàm mất mát học đa góc nhìn (Wang et al., 2021; Kambhatla et al., 2022b) và kéo các biểu diễn khác nhau lại gần nhau:

L = L_{NLL}(P(y|x^{pri};θ)) + (1/k)∑ᵢ₌₁ᵏ L_{NLL}(P(y|x^{aug}_i;θ)) + (α/k)∑ᵢ₌₁ᵏ L_{dist}(P(y|x^{pri};θ), P(y|x^{aug}_i;θ)), (6)

trong đó L_{NLL} là mất mát khả năng âm trong dịch máy, L_{dist} là phân kỳ Kullback-Leibler đối xứng (Kambhatla et al., 2022b).

Hai số hạng đầu tiên của Phương trình 6 (mất mát nguồn chính và mất mát nguồn tăng cường) tính toán mất mát dịch cho các câu nguồn và tăng cường tương ứng, và số hạng thứ ba (mất mát thỏa thuận) kéo các phân phối dự đoán của các đầu vào nguồn khác nhau lại gần nhau.

Như được thể hiện trong Hình 2, các phân phối xác suất đầu ra cho tất cả các độ chi tiết được sử dụng để tính toán mất mát, trong đó các đường phân đoạn màu xanh dương đề cập đến mất mát thỏa thuận giữa các độ chi tiết khác nhau, và các đường chấm màu xanh lá cây đề cập đến mất mát khả năng âm giữa dự đoán và mục tiêu.

### 4.3 Lựa chọn động độ chi tiết trong suy luận

DRDA sử dụng nhiều phân đoạn ở các độ chi tiết khác nhau, vì vậy việc lựa chọn độ chi tiết được sử dụng trong suy luận trở thành một mối quan tâm. Để tự động chọn kích thước từ điển phù hợp khi suy luận, chúng tôi cũng đề xuất một phiên bản đơn giản hóa nhưng tập trung vào độ chi tiết của giải mã n-tốt nhất (Kudo, 2018) để lựa chọn động độ chi tiết phân đoạn trong bước suy luận.

Cho trước tập hợp tất cả các kích thước từ điển chính và tăng cường {p, q₁, q₂,..., qₖ} và một câu đầu vào s, một chuỗi các cặp (x,y) có thể được tạo ra, trong đó mỗi cặp (x,y) đại diện cho một cặp chuỗi token nguồn-đích ở một độ chi tiết nhất định.

Cặp phân đoạn và dịch có xác suất cao nhất ước tính tương ứng với cặp (x,y) tối đa hóa điểm số sau:

score(x,y) = log P(y|x)/|y|, (7)

trong đó |y| là độ dài của y.

## 5 Thí nghiệm

Chúng tôi đánh giá DRDA với các tác vụ dịch thuật trên các cặp ngôn ngữ và hướng dịch khác nhau để thể hiện tính phổ quát của nó bất kể đặc điểm ngôn ngữ. Chúng tôi cũng tiến hành thí nghiệm trên các tình huống tài nguyên cực thấp và nhiễu để thể hiện tính bền vững của DRDA.

### 5.1 Thiết lập thí nghiệm

[Bảng dữ liệu và kích thước tương ứng]

Bộ dữ liệu và tiền xử lý Các thí nghiệm của chúng tôi được tiến hành trên các bộ dữ liệu khác nhau, như chi tiết trong Bảng 1. Chúng tôi thí nghiệm trên thiết lập tài nguyên thấp với các bộ dữ liệu IWSLT, bao gồm IWSLT14 En ↔ De, En ↔ Es, và IWSLT17 En ↔ Zh, En ↔ Fr. Chúng tôi sử dụng WMT14 En ↔ De lớn hơn như một bộ dữ liệu kịch bản tài nguyên cao. Hiệu suất trong các kịch bản tài nguyên cực thấp được khám phá với bộ dữ liệu TED En ↔ Sk. Theo các công trình trước đây (Vaswani et al., 2017), chúng tôi viết thường các từ trong IWSLT En ↔ De, trong khi giữ các bộ dữ liệu khác có phân biệt hoa thường.

Mô hình Chúng tôi xây dựng các mô hình dựa trên Transformer (Vaswani et al., 2017) với bộ công cụ Fairseq (Ott et al., 2019). Chúng tôi sử dụng mô hình Base Transformer transformer_wmt_en_de cho WMT, và transformer_iwslt_de_en cho các bộ dữ liệu khác.

Siêu tham số trong huấn luyện và suy luận Chúng tôi sử dụng sentencepiece (Kudo và Richardson, 2018) để thực hiện token hóa và phân đoạn BPE. Mô hình mã hóa BPE được học chung trên phía nguồn và phía đích trừ IWSLT En ↔ Zh. Trừ khi có ghi chú khác, chúng tôi sử dụng hai bảng từ điển (trên từ điển chính và một từ điển tăng cường), và kích thước từ điển của chúng tuân theo Bảng 3. Phân tích chi tiết về kích thước từ điển và số lượng từ điển tăng cường sẽ được thể hiện trong Mục 6.1. Trọng số của mất mát thỏa thuận α được đặt thành 5 trừ khi có ghi chú khác.

[Bảng kích thước từ điển chính và tăng cường]

Đánh giá Chúng tôi đánh giá hiệu suất của các hệ thống NMT sử dụng BLEU. Để so sánh với các công trình trước đây (Vaswani et al., 2017; Kambhatla et al., 2022b), chúng tôi áp dụng multi-bleu với multi_bleu.perl cho IWSLT En ↔ De, WMT En → De, và TED En ↔ Sk. Đối với bộ dữ liệu WMT En → De, chúng tôi bổ sung áp dụng phân tách từ ghép. Tất cả các bộ dữ liệu khác được đánh giá bằng SacreBLEU.

### 5.2 Kết quả chính

Chúng tôi trình bày kết quả của DRDA trên các tác vụ dịch IWSLT và WMT trong Bảng 2. Chúng ta có thể thấy rằng DRDA liên tục vượt trội so với Transformer với biên độ rõ ràng trên tất cả các tác vụ dịch. Hơn nữa, các mô hình được suy luận với lựa chọn độ chi tiết động đạt được cải thiện khiêm tốn trong DRDA.

[Bảng điểm BLEU trên IWSLT En ↔ De]

So sánh giữa DRDA và các phương pháp tăng cường dữ liệu và chính quy hóa từ con khác trên IWSLT được thể hiện trong Bảng 4. Chúng tôi sử dụng một loạt các phương pháp tăng cường và chính quy hóa để so sánh. Các phương pháp tăng cường bao gồm WordDrop (Zhang et al., 2020; Sennrich et al., 2016a), SwitchOut (Wang et al., 2018b), RAML (Norouzi et al., 2016) và Data Diversification (Nguyen et al., 2020). Các phương pháp chính quy hóa từ con bao gồm BPE-Drop (Provilkov et al., 2020) và Subword Regularization (Kudo, 2018). Chúng tôi cũng so sánh phương pháp của chúng tôi với những phương pháp khác áp dụng kỹ thuật học đa góc nhìn, bao gồm R-Drop (Wu et al., 2021), MVR (Wang et al., 2021), và CipherDAug (Kambhatla et al., 2022b). DRDA mang lại cải thiện lớn hơn so với những phương pháp khác.

### 5.3 Thiết lập tài nguyên cực thấp

Tác vụ TED En ↔ Sk rất thách thức do tài nguyên cực thấp (chỉ 61k cặp câu huấn luyện). Một số kỹ thuật đã được áp dụng để cải thiện hiệu suất trong các tác vụ NMT tài nguyên thấp như thế này, bao gồm tăng cường dữ liệu, dịch đa ngôn ngữ, và học chuyển giao (Ranathunga et al., 2021). Neubig và Hu (2018) đầu tiên đề xuất chính quy hóa ngôn ngữ tương tự để trộn ngôn ngữ tài nguyên thấp với ngôn ngữ tài nguyên cao có liên quan từ vựng, kết hợp học chuyển giao và dịch đa ngôn ngữ. Một số công trình tiếp tục mở rộng SRL và đạt được chất lượng dịch cao (Xia et al., 2019; Ko et al., 2021; Wang et al., 2018a).

[Bảng điểm BLEU trên TED En ↔ Sk]

Trên tác vụ này, DRDA mang lại cải thiện mạnh hơn so với Transformer cơ sở hơn các kỹ thuật khác mà không cần yêu cầu ngôn ngữ tài nguyên cao bên ngoài, như được thể hiện trong Bảng 5.

### 5.4 Tính bền vững trước nhiễu loạn

Chúng tôi xác thực tính bền vững của DRDA trên hai bộ dữ liệu nhiễu. Bộ dữ liệu đầu tiên là tập kiểm tra IWSLT De → En với nhiễu loạn tổng hợp. Các nhiễu loạn được tổng hợp bằng cách duyệt qua mỗi ký tự ngoại trừ khoảng trắng và dấu chấm câu trong các câu nguồn, và áp dụng một trong các phép toán với xác suất 0.01: (1) loại bỏ ký tự, (2) thêm một ký tự ngẫu nhiên sau ký tự, và (3) thay thế ký tự bằng một ký tự ngẫu nhiên. Bộ dữ liệu thứ hai là tập kiểm tra himl, chứa thông tin sức khỏe và tóm tắt khoa học và khác biệt đáng kể với tập huấn luyện IWSLT. Các bộ dữ liệu liên miền có phân phối từ con khác nhau, và sự khác biệt có thể được xem như một nhiễu tự nhiên. Kết quả của các tập kiểm tra nhiễu được thể hiện trong Bảng 6.

[Bảng điểm BLEU trên tập kiểm tra IWSLT De → En gốc và nhiễu]

Cùng với các kết quả này, cải thiện nhất quán so với Transformer và R-Drop được DRDA đạt được trên cả bộ dữ liệu nhiễu tổng hợp và liên miền. DRDA vượt trội đáng kể so với các phương pháp lấy mẫu từ con (BPE-Drop và chính quy hóa từ con) trên bộ dữ liệu nhiễu tự nhiên, nhưng chỉ đạt được kết quả tương tự với nhiễu tổng hợp. Chúng tôi sẽ thảo luận lý do trong Mục 6.2.

## 6 Phân tích

Trong phần này, chúng tôi tiến hành các thí nghiệm phân tích để trả lời các câu hỏi nghiên cứu (RQ) sau đây tương ứng:

• RQ1 (nghiên cứu loại bỏ): Các kỹ thuật và thành phần được áp dụng ảnh hưởng đến hiệu suất mô hình như thế nào?
• RQ2: Phương pháp của chúng tôi có thực sự giữ được tính nhất quán ngữ nghĩa giữa dữ liệu gốc và dữ liệu tăng cường không?
• RQ3: Phân đoạn đa độ chi tiết cải thiện biểu diễn từ con như thế nào?
• RQ4: Tại sao học đa góc nhìn giúp cải thiện các mô hình NMT?

### 6.1 RQ1: Loại bỏ

[Biểu đồ loại bỏ về kích thước từ điển tăng cường và trọng số mất mát thỏa thuận]

Lựa chọn kích thước từ điển Ở đây, chúng tôi điều tra tác động của các kích thước từ điển được xác định trước. Như đã đề cập trong Mục 5.1, chúng tôi áp dụng một từ điển chính và một từ điển tăng cường. Để tìm kích thước từ điển tối ưu, chúng tôi kiểm tra {10k, 7k, 5k, 3k, 1k} cho kích thước từ điển tăng cường khi kích thước chính là 10k. Hình 3 xác minh rằng, khi kích thước từ điển tăng cường vào khoảng 5k, mô hình NMT đạt được BLEU cao nhất. Trực giác là sự khác biệt lớn trong kích thước từ điển chính và tăng cường có thể làm hỏng ngữ nghĩa từ con, trong khi sự khác biệt nhỏ có thể giảm sự khác biệt về ký hiệu. Một khuyến nghị chung trong việc chọn kích thước từ điển là sử dụng kích thước phù hợp đã được chứng minh cho từ điển chính và đặt kích thước tăng cường bằng một nửa kích thước của từ điển chính.

Trọng số của mất mát thỏa thuận Như được thể hiện trong Hình 3, chúng tôi thấy rằng trọng số mất mát thỏa thuận α ảnh hưởng đáng kể đến hiệu suất của phương pháp chúng tôi. Các mô hình đạt được điểm BLEU cao nhất khi α = 5, và việc tăng hoặc giảm α gây ra sự giảm điểm lên tới 2 BLEU trên tập hợp lệ. Mô hình không có mất mát thỏa thuận (tức là α = 0) vẫn vượt trội so với Transformer thuần túy, xác nhận vai trò quan trọng của phân đoạn đa độ chi tiết trong DRDA.

Số lượng từ điển tăng cường Bảng 7 thể hiện tác động của việc thêm một từ điển tăng cường phụ với kích thước từ điển chính là 12k trên tập hợp lệ. Khi kết hợp với hai từ điển tăng cường, điểm BLEU có độ lệch nhỏ hơn so với khi kết hợp với một. Chúng ta có thể tóm tắt rằng việc thêm từ điển tăng cường phụ giúp có được kết quả ổn định, có thể so sánh và có thể hơi tốt hơn với chi phí tăng thời gian huấn luyện.

[Bảng điểm BLEU trên tập hợp lệ IWSLT De → En]

### 6.2 RQ2: Tính nhất quán ngữ nghĩa

Thảo luận lý thuyết Trong phần này, chúng tôi thảo luận tính nhất quán ngữ nghĩa là gì, và đưa ra phân tích lý thuyết về tại sao DRDA có tính nhất quán ngữ nghĩa hơn.

Rõ ràng là các phương pháp tăng cường dữ liệu trước đây áp dụng các phép toán không thể đảo ngược dẫn đến mất mát ngữ nghĩa, điều này sẽ không tránh khỏi làm tổn hại đến tính nhất quán giữa dữ liệu gốc và dữ liệu tăng cường. DRDA vượt trội so với các phương pháp này về mặt bảo tồn ý nghĩa gốc, bởi vì nó dựa trên phân đoạn có thể đảo ngược để tạo ra tính đa dạng.

Tuy nhiên, việc chứng minh rằng các phương pháp chính quy hóa từ con (Kudo, 2018; Provilkov et al., 2020), cũng dựa trên phân đoạn có thể đảo ngược, dẫn đến sự không nhất quán lớn hơn so với DRDA thì thách thức hơn. Để thể hiện tính ưu việt của DRDA về tính nhất quán so với chính quy hóa từ con, chúng tôi xem xét sự khác biệt của hai phương pháp trong việc lấy mẫu phân đoạn:

x^{DRDA}_i = arg max_x P_{seg}(x|s;p_i), (8)
x^{SR} ~ P_{seg}(x|s;p), (9)

trong đó x^{DRDA}_i là biểu diễn ở độ chi tiết nhất định của câu nguồn s trong DRDA, x^{SR} là biểu diễn trong chính quy hóa từ con, p_i và p là các kích thước từ điển.

arg max_x P_{seg}(x|s;p) có thể được hiểu là độ khó của việc phân đoạn s với kích thước từ điển nhất định p. Chúng ta có thể giả định rằng độ khó của việc phân đoạn một câu là một tính chất vốn có của các câu, độc lập với kích thước từ điển:

arg max_x P_{seg}(x|s) = arg max_x P_{seg}(x|s;p), (10)

trong đó p ∈ N là bất kỳ kích thước từ điển xác định trước nào.

Sau đó, do phép toán argmax xác định trong DRDA và phép toán lấy mẫu ngẫu nhiên trong chính quy hóa từ con, bất đẳng thức sau đây đúng:

P_{seg}(x^{DRDA}|s) ≥ P_{seg}(x^{SR}|s). (11)

Phương trình 11 xác nhận rằng các phương pháp của chúng tôi tạo ra các phân đoạn phù hợp hơn của cùng một câu so với các phương pháp chính quy hóa từ con khác. Do đó, mặc dù cả DRDA và chính quy hóa từ con đều có thể đảo ngược, DRDA có tính nhất quán ngữ nghĩa hơn do tính phù hợp của phân đoạn.

Phân tích thực nghiệm Để đưa ra cái nhìn thực nghiệm về tính nhất quán ngữ nghĩa, chúng tôi phân tích các lân cận gần nhất của từ con của các mô hình khác nhau (được thể hiện trong Bảng 8). Chúng ta có thể thấy rằng cả Transformer thuần túy và DRDA đều thể hiện các lân cận dựa trên ngữ nghĩa, trong đó các nhúng của từ đồng nghĩa có sự tương tự. Tuy nhiên, các nhúng thu được trong BPE-Drop có xu hướng có sự tương tự cao với những từ mà chúng chia sẻ một chuỗi chung. Mặc dù xu hướng này có thể hiệu quả giảm thiểu tính dễ bị tổn thương trước lỗi chính tả, điều này giải thích sự ưu việt mà chính quy hóa từ con thể hiện trong dữ liệu nhiễu tổng hợp trong Mục 5.4, nó cũng có thể gây ra lỗi ngữ nghĩa (coi "_go" và "_god" là từ đồng nghĩa với "_good" trong Bảng 8 chẳng hạn), gây ra sự không chính xác trong dịch máy.

[Bảng 5 lân cận gần nhất của từ con "_good"]

Quan sát trên cho thấy rằng DRDA gây ra ít nhiễu ngữ nghĩa cho dữ liệu tăng cường và thể hiện tính nhất quán ngữ nghĩa tốt hơn.

### 6.3 RQ3: Tác động lên tần suất từ con

Ở đây, chúng tôi thể hiện rằng cơ chế của phân đoạn đa độ chi tiết có thể được quy cho sự gia tăng tần suất của các token không thường xuyên.

Các mô hình NMT với kích thước từ điển lớn hơn có các đơn vị dịch nguyên tử lớn hơn, tức là các từ con có hạt thô hơn, để chúng có thể ghi nhớ tốt hơn các ánh xạ một-nhiều hoặc nhiều-một và giải quyết sự mơ hồ dịch thuật (Koehn, 2009). Tuy nhiên, các từ con có hạt mịn có thể gặp phải sự giảm tần suất khi kích thước từ điển tăng. Hình 4 thể hiện rằng hầu hết các lần xuất hiện của "_nerv" bị hấp thụ bởi "_nervous" khi từ điển tăng, khiến mô hình NMT khó có được biểu diễn chính xác của các dạng biến đổi khác như "_nervy", "_nervieir" và "_nervine". Tổng quát hơn, sự giảm tần suất phổ biến trên IWSLT En → De (kết quả trên nhiều bộ dữ liệu được thể hiện trong Phụ lục C), trong đó khoảng 50% từ con xuất hiện trong từ điển 5k gặp phải sự giảm tần suất khi từ điển tăng lên 10k, như Hình 4 thể hiện.

[Hình thể hiện tần suất giảm của từ con]

Trong DRDA, bằng cách sử dụng đồng thời cả kích thước từ điển nhỏ và lớn, các token không thường xuyên xuất hiện thường xuyên hơn để các từ con như "_nerv" cũng có thể được huấn luyện trong các ngữ cảnh đầy đủ.

### 6.4 RQ4: Kỹ thuật đa góc nhìn và thành phần ngữ nghĩa từ con

Học đa góc nhìn kéo các biểu diễn ở các độ chi tiết khác nhau lại gần nhau. Để điều tra tác động của các kỹ thuật đa góc nhìn, chúng tôi đề xuất một tác vụ để tìm hiểu cách các biểu diễn có hạt thô và hạt mịn của cùng một từ được kéo lại gần nhau.

[Hình thể hiện tương tự giữa biểu diễn hạt mịn và hạt thô]

Quy trình được minh họa bằng một ví dụ trong Hình 5, và định nghĩa chính thức của tác vụ được thể hiện trong Phụ lục B. Chúng tôi lấy một từ con có hạt thô ("_background") và chuỗi từ con có hạt mịn tương ứng ("_back", "ground"), sau đó tính toán độ tương tự cosine giữa nhúng trước và tổng các nhúng sau. Độ tương tự cho biết mức độ mà các biểu diễn hạt mịn và hạt thô được kéo lại gần nhau.

Chúng tôi liệt kê tất cả các cặp biểu diễn hạt thô và hạt mịn, và tính trung bình tất cả các điểm tương tự cosine của chúng. Kết quả được thể hiện trong Bảng 9. Như mong đợi, DRDA với mất mát thỏa thuận phù hợp (α = 5) đạt được độ tương tự trung bình cao hơn so với các phương pháp tăng cường dữ liệu khác.

[Bảng độ tương tự giữa biểu diễn hạt thô và hạt mịn]

Tính toán độ tương tự giữa các biểu diễn ở nhiều độ chi tiết là một tác vụ thành phần cấp từ con (SSC) (Mitchell và Lapata, 2008, 2009; Turney, 2014). Chúng ta có thể kết luận rằng các kỹ thuật đa góc nhìn giúp các mô hình DRDA cải thiện hiểu biết SSC, do đó đạt được tính bền vững tốt hơn trước các nhiễu loạn (Provilkov et al., 2020).

## 7 Kết luận

Trong bài báo này, chúng tôi xác định sự không nhất quán ngữ nghĩa gây ra bởi các phép toán không thể đảo ngược hoặc phân đoạn theo xác suất, và đề xuất một tăng cường dữ liệu có thể đảo ngược xác định bao gồm phân đoạn đa độ chi tiết và học đa góc nhìn để đảm bảo tính nhất quán khi tạo ra dữ liệu đa dạng. Các thí nghiệm chứng minh sự ưu việt của DRDA được đề xuất so với tăng cường dữ liệu và chính quy hóa từ con trước đây về mặt độ chính xác dịch thuật và tính bền vững. Chúng tôi cũng đưa ra sự kết hợp giữa xác minh thực nghiệm và lý thuyết về tính nhất quán ngữ nghĩa, và các phân tích sâu sắc về các kỹ thuật đa độ chi tiết và đa góc nhìn.

## Hạn chế

Các tình huống tài nguyên cao Như các kỹ thuật tăng cường dữ liệu khác, DRDA được đề xuất của chúng tôi có vẻ kém hiệu quả hơn trong các tình huống tài nguyên cao (tăng tới 1.75 BLEU trong WMT, và 2.69 trong IWSLT) so với các tình huống tài nguyên thấp (tăng tới 4.37 BLEU trong TED). Phân tích trong Mục 6.3 đưa ra một giải thích cho hiện tượng này rằng, sự giảm tần suất trở nên ít sắc nét hơn khi kích thước dữ liệu tăng, do đó dẫn đến hiệu quả thấp hơn của tăng cường dữ liệu. Xem xét hiện tượng này, một phương pháp ứng dụng tốt hơn của tăng cường dữ liệu trên các tình huống tài nguyên cao có thể được thiết kế, bằng cách xác định các từ con hiếm của một miền cụ thể trong mô hình được huấn luyện trên kho ngữ liệu chung lớn và tiếp tục huấn luyện với dữ liệu tăng cường. Chúng tôi để lại điều tra này như một hướng cho nghiên cứu trong tương lai.

Phạm vi ứng dụng Như một quy trình nền tảng trong NLP, phân đoạn được áp dụng trong nhiều tác vụ khác nhau, bao gồm mô hình hóa ngôn ngữ, nhận dạng thực thể có tên, và nhiều tác vụ khác. Ngoài ra, các tác vụ thị giác như dịch hình ảnh cũng có thể hưởng lợi từ phân đoạn (Tian et al., 2023). Do đó, các kỹ thuật tăng cường dữ liệu dựa trên phân đoạn bao gồm DRDA có thể được áp dụng cho một loạt các tác vụ rộng rãi. Một hạn chế của nghiên cứu này là việc áp dụng độc quyền DRDA cho dịch máy, điều này hạn chế khả năng xác thực và so sánh hiệu quả của nó trên các tác vụ khác.

## Lời cảm ơn

Chúng tôi muốn cảm ơn tất cả các nhà đánh giá ẩn danh vì những nỗ lực chăm chỉ của họ trong việc giúp chúng tôi cải thiện công trình này. Công trình này được hỗ trợ bởi Quỹ Khoa học Tự nhiên Quốc gia Trung Quốc (Số hiệu U21B2009) và Kế hoạch Đổi mới Khoa học và Công nghệ Viện Công nghệ Bắc Kinh (Số hiệu 23CX13027).

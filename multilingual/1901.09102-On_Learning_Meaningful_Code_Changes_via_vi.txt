Về Việc Học Những Thay Đổi Mã Nguồn Có Ý Nghĩa thông qua Dịch Máy Thần Kinh

Michele Tufano, Jevgenija Pantiuchinay, Cody Watson, Gabriele Bavotay, Denys Poshyvanyk
College of William and Mary, Williamsburg, Virginia, USA
Email: {mtufano, cawatson, denys}@cs.wm.edu
yUniversità della Svizzera italiana (USI), Lugano, Switzerland
Email: {gabriele.bavota, jevgenija.pantiuchina}@usi.ch

Tóm tắt —Những năm gần đây chứng kiến sự nổi lên của các kỹ thuật Học Sâu (DL) được áp dụng vào mã nguồn. Các nhà nghiên cứu đã khai thác DL để tự động hóa một số nhiệm vụ phát triển và bảo trì, chẳng hạn như viết thông điệp commit, tạo chú thích và phát hiện lỗ hổng trong số các nhiệm vụ khác. Một trong những giấc mơ lâu dài của việc áp dụng DL vào mã nguồn là khả năng tự động hóa các hoạt động lập trình không tầm thường. Mặc dù đã có một số bước tiến trong hướng này (ví dụ, học cách sửa lỗi), vẫn còn thiếu bằng chứng thực nghiệm về các loại thay đổi mã nguồn có thể được học và tự động áp dụng bằng DL. Mục tiêu của chúng tôi là thực hiện bước đầu tiên quan trọng này bằng cách điều tra định lượng và định tính khả năng của mô hình Dịch Máy Thần Kinh (NMT) để học cách tự động áp dụng các thay đổi mã nguồn được triển khai bởi các nhà phát triển trong quá trình pull request. Chúng tôi huấn luyện và thử nghiệm mô hình NMT trên một tập hợp 236k cặp thành phần mã nguồn trước và sau khi triển khai các thay đổi được cung cấp trong pull request. Chúng tôi chỉ ra rằng, khi được áp dụng trong bối cảnh đủ hẹp (tức là, các cặp phương thức nhỏ/trung bình trước/sau các thay đổi pull request), NMT có thể tự động nhân bản các thay đổi được triển khai bởi các nhà phát triển trong pull request lên đến 36% các trường hợp. Hơn nữa, phân tích định tính của chúng tôi chỉ ra rằng mô hình có khả năng học và nhân bản một loạt các thay đổi mã nguồn có ý nghĩa, đặc biệt là các hoạt động tái cấu trúc và sửa lỗi. Kết quả của chúng tôi mở đường cho nghiên cứu mới trong lĩnh vực DL về mã nguồn, chẳng hạn như học tự động và ứng dụng tái cấu trúc.

Từ khóa chỉ mục —Dịch Máy Thần Kinh; Nghiên cứu Thực nghiệm

I. GIỚI THIỆU

Một số công trình gần đây tập trung vào việc sử dụng các kỹ thuật học máy tiên tiến trên mã nguồn với mục tiêu (bán) tự động hóa một số nhiệm vụ không tầm thường, bao gồm hoàn thiện mã [65], tạo thông điệp commit [47], tên phương thức [27], chú thích mã [66], dự đoán lỗi [63], định vị [49] và sửa lỗi [62], phát hiện bản sao [64], tìm kiếm mã [40], và học các mẫu API [41].

Sự nổi lên của luồng nghiên cứu này trong cộng đồng kỹ thuật phần mềm (SE) là do sự kết hợp của nhiều yếu tố. Đầu tiên là sự sẵn có rộng rãi của dữ liệu, cụ thể là mã nguồn, và các tạo phẩm xung quanh nó trong các kho lưu trữ mã nguồn mở. Ví dụ, vào thời điểm viết bài báo này, riêng GitHub đã lưu trữ 100M kho lưu trữ, với hơn 200M pull request (PR) đã được gộp và 2B commit. Thứ hai, DL đã trở thành một công cụ hữu ích do khả năng học phân loại dữ liệu thông qua kiến trúc lớp ẩn, khiến nó đặc biệt thành thạo trong việc phát hiện đặc trưng [31]. Cụ thể, Dịch Máy Thần Kinh (NMT) đã trở thành một phương pháp hàng đầu để dịch các ngôn ngữ khác nhau, vượt qua khả năng diễn giải của con người [67]. Một nguyên tắc tương tự áp dụng cho việc "dịch" một đoạn mã nguồn thành một đoạn khác. Ở đây, tính mơ hồ của việc dịch làm cho phương pháp này cực kỳ linh hoạt: Người ta có thể học cách dịch mã lỗi thành mã đã sửa, tiếng Anh sang tiếng Tây Ban Nha, Java sang C, v.v. Thứ ba là sự sẵn có của phần cứng (tương đối) rẻ có thể chạy hiệu quả các cơ sở hạ tầng DL.

Mặc dù có tất cả công trình, chỉ có một vài cách tiếp cận được đề xuất để tự động hóa các hoạt động lập trình không tầm thường. Tufano et al. [62] đã chỉ ra rằng DL có thể được sử dụng để tự động hóa các hoạt động sửa lỗi. Tuy nhiên, vẫn còn thiếu bằng chứng thực nghiệm về các loại thay đổi mã nguồn thực sự có thể được học và tự động áp dụng bằng cách sử dụng DL. Trong khi hầu hết các công trình áp dụng DL trong SE tập trung vào việc đánh giá định lượng hiệu suất của kỹ thuật được thiết kế (ví dụ, Cách tiếp cận của chúng tôi có thể sửa được bao nhiêu lỗi?), ít phân tích định tính được thực hiện để điều tra sâu về tính có ý nghĩa của đầu ra được sản xuất bởi các cách tiếp cận dựa trên DL. Trong bài báo này, chúng tôi thực hiện bước thực nghiệm đầu tiên để điều tra một cách rộng rãi khả năng của mô hình NMT để học cách tự động áp dụng các thay đổi mã nguồn giống như các nhà phát triển làm trong PR. Chúng tôi tận dụng NMT để tự động "dịch" một thành phần mã nguồn từ trạng thái trước khi triển khai PR và sau khi PR được gộp, do đó, mô phỏng sự kết hợp của các thay đổi mã nguồn sẽ được triển khai bởi các nhà phát triển trong PR.

Chúng tôi khai thác ba kho lưu trữ đánh giá mã nguồn Gerrit [17] lớn, cụ thể là Android [14], Google Source [15], và Ovirt [16]. Tổng cộng, các kho lưu trữ này lưu trữ các đánh giá mã nguồn liên quan đến 339 dự án con. Chúng tôi đã thu thập từ các dự án này 78,981 PR đã được gộp đã trải qua đánh giá mã nguồn. Chúng tôi chỉ xem xét các PR đã được gộp và đánh giá vì ba lý do. Đầu tiên, chúng tôi muốn đảm bảo rằng mô hình NMT đang học các thay đổi có ý nghĩa, do đó, biện minh cho việc lựa chọn khai thác "PR đã được đánh giá" thay vì bất kỳ thay đổi nào được commit trong hệ thống phiên bản. Thứ hai, do trọng tâm định tính sâu sắc của nghiên cứu của chúng tôi, chúng tôi muốn phân tích các cuộc thảo luận được thực hiện trong quá trình đánh giá mã nguồn để hiểu rõ hơn về các loại thay đổi được học bởi cách tiếp cận của chúng tôi. Thật vậy, trong khi đối với commit chúng tôi chỉ có ghi chú commit đi kèm, với PR đã được đánh giá chúng tôi có thể dựa vào dữ liệu định tính phong phú giải thích lý do đằng sau các thay đổi được triển khai. Thứ ba, chúng tôi chỉ tập trung vào các PR đã được gộp, vì mã nguồn trước và sau (tức là, đã được gộp) PR có sẵn. Đây không phải là trường hợp đối với các PR bị bỏ. Chúng tôi trích xuất các thao tác chỉnh sửa AST cấp phương thức từ các PR này bằng cách sử dụng phân biệt mã nguồn chi tiết [38]. Điều này dẫn đến 239,522 cặp phương thức, mỗi cặp đại diện cho phương thức trước (PR chưa được gửi) và sau (PR đã được gộp) quá trình PR. Một Mạng Thần Kinh Tái Phát (RNN) Encoder-Decoder sau đó được sử dụng để học các biến đổi mã nguồn được thực hiện bởi các nhà phát triển trong các hoạt động PR.

Chúng tôi trình bày một đánh giá định lượng và định tính của mô hình NMT. Đối với phân tích định lượng, chúng tôi đã đánh giá khả năng của nó trong việc sửa đổi mã nguồn của dự án chính xác như được thực hiện bởi các nhà phát triển trong các PR thực tế. Điều này có nghĩa là chúng tôi so sánh, đối với cùng các thành phần mã nguồn, đầu ra của các thay đổi được triển khai thủ công và đầu ra của mô hình NMT. Phân tích định tính nhằm mục đích chưng cất một phân loại các biến đổi mã nguồn có ý nghĩa mà mô hình có thể tự động học từ dữ liệu huấn luyện — xem Hình 1. Kết quả đạt được cho thấy rằng, trong cấu hình tốt nhất, mô hình NMT có thể tiêm những biến đổi mã nguồn giống như được triển khai bởi các nhà phát triển trong PR trong 16-36% trường hợp, tùy thuộc vào số lượng giải pháp có thể mà nó được yêu cầu tạo ra bằng cách sử dụng tìm kiếm chùm tia [57]. Hơn nữa, phân loại được trích xuất cho thấy rằng mô hình có thể học một loạt phong phú các biến đổi mã nguồn có ý nghĩa, tự động sửa lỗi và tái cấu trúc mã nguồn như con người sẽ làm. Như được giải thích trong Phần III, những kết quả này đã được đạt được trong một bối cảnh khá hẹp (tức là, chúng tôi chỉ xem xét các cặp phương thức nhỏ/trung bình trước/sau việc triển khai các thay đổi được thực hiện bởi PR), và đây cũng là một trong những lý do tại sao cơ sở hạ tầng của chúng tôi chủ yếu học các hoạt động sửa lỗi và tái cấu trúc (thay vì việc triển khai các tính năng mới). Tuy nhiên, chúng tôi tin rằng kết quả của chúng tôi rõ ràng cho thấy tiềm năng của NMT để học và tự động hóa các thay đổi mã nguồn không tầm thường và do đó có thể mở đường cho nhiều nghiên cứu hơn nhắm vào việc tự động hóa các thay đổi mã nguồn (ví dụ, các cách tiếp cận được thiết kế để học và áp dụng tái cấu trúc). Để thúc đẩy nghiên cứu theo hướng này, chúng tôi công khai các bộ dữ liệu hoàn chỉnh, mã nguồn, công cụ và dữ liệu thô được sử dụng trong các thí nghiệm của chúng tôi [21].

II. CÁCH TIẾP CẬN

Cách tiếp cận của chúng tôi bắt đầu với việc khai thác PR từ ba kho lưu trữ Gerrit lớn (Mục II-A). Chúng tôi trích xuất mã nguồn trước và sau khi PR được gộp. Chúng tôi ghép cặp các phương thức pre-PR và post-PR, trong đó mỗi cặp phục vụ như một ví dụ về một thay đổi có ý nghĩa (Mục II-B). Các cặp phương thức sau đó được trừu tượng hóa, lọc và tổ chức thành các bộ dữ liệu (Mục II-C). Chúng tôi huấn luyện mô hình của mình để dịch phiên bản mã nguồn trước PR thành phiên bản sau PR, để mô phỏng thay đổi mã nguồn (Mục II-D). Cuối cùng, đầu ra của mô hình NMT được cụ thể hóa thành mã nguồn thực tế (Mục II-E).

A. Khai thác Đánh giá Mã nguồn

Chúng tôi xây dựng một trình thu thập Gerrit để thu thập dữ liệu PR cần thiết để huấn luyện mô hình NMT. Cho một máy chủ Gerrit, trình thu thập trích xuất danh sách các dự án được lưu trữ trên đó. Sau đó, đối với mỗi dự án, trình thu thập lấy danh sách tất cả các PR được gửi để đánh giá và có "đã gộp" là trạng thái cuối cùng. Chúng tôi sau đó xử lý mỗi PR đã gộp P bằng cách sử dụng các bước sau. Đầu tiên, hãy định nghĩa tập hợp các tệp Java được gửi trong P là FS = {F1, F2, ..., Fn}. Chúng tôi bỏ qua các tệp không phải Java, vì mô hình NMT của chúng tôi chỉ hỗ trợ Java. Đối với mỗi tệp trong FS, chúng tôi sử dụng API Gerrit để lấy phiên bản của chúng trước khi thay đổi được triển khai trong PR. Trình thu thập loại bỏ các tệp mới được tạo trong PR (tức là, không tồn tại trước PR) vì chúng tôi không thể học bất kỳ biến đổi mã nguồn nào từ chúng (chúng tôi cần mã nguồn trước/sau PR để học các thay đổi được triển khai bởi các nhà phát triển). Sau đó, API Gerrit được sử dụng để lấy các phiên bản tệp đã gộp bị ảnh hưởng bởi PR. Hai tập hợp tệp (trước/sau) có thể không hoàn toàn giống nhau, do các tệp được tạo/xóa trong quá trình đánh giá.

Đầu ra của trình thu thập là, đối với mỗi PR, phiên bản của các tệp bị ảnh hưởng trước (pre-PR) và sau (post-PR, đã gộp) PR. Vào cuối quá trình khai thác, chúng tôi thu được ba bộ dữ liệu PR: PROvirt, PRAndroid, và PRGoogle.

B. Trích xuất Mã nguồn

Mỗi PR được khai thác được biểu diễn dưới dạng pr = {(f1, ..., fn), (f'1, ..., f'm)}, trong đó f1, ..., fn là các tệp mã nguồn trước PR, và f'1, ..., f'm là các tệp mã nguồn sau PR. Như đã giải thích trước đó, hai tập hợp có thể có kích thước giống nhau hoặc không, vì các tệp có thể đã được thêm hoặc xóa trong quá trình PR. Trong bước đầu tiên, chúng tôi dựa vào GumTreeDiff [38] để thiết lập ánh xạ tệp-đến-tệp, được thực hiện bằng cách sử dụng các điểm neo ngữ nghĩa, giữa các tệp pre- và post-PR và bỏ qua bất kỳ tệp nào được thêm/xóa trong quá trình đánh giá mã nguồn. Sau bước này, mỗi PR được lưu trữ theo định dạng pr = {(f1, ..., fk), (f'1, ..., f'k)}, trong đó fi là tệp trước và f'i là phiên bản tương ứng của tệp sau PR. Tiếp theo, mỗi cặp tệp (fi, f'i) lại được phân tích bằng GumTreeDiff, thiết lập ánh xạ phương thức-đến-phương thức và xác định các thao tác AST được thực hiện giữa hai phiên bản của cùng một phương thức. Chúng tôi chỉ chọn các cặp phương thức mà mã nguồn sau PR đã được thay đổi so với mã nguồn trước PR. Sau đó, mỗi PR được biểu diễn dưới dạng danh sách các phương thức được ghép cặp pr = {(mb, ma)1, ..., (mb, ma)n}, trong đó mỗi cặp (mb, ma)i chứa phương thức trước PR (mb) và phương thức sau PR (ma). Đây là các ví dụ về thay đổi được sử dụng để huấn luyện mô hình NMT dịch mb thành ma.

Chúng tôi sử dụng độ chi tiết cấp phương thức vì một số lý do: (i) các phương thức triển khai một chức năng duy nhất và cung cấp đủ bối cảnh cho một biến đổi mã nguồn có ý nghĩa; (ii) các thay đổi mã nguồn cấp tệp vẫn có thể thực hiện được bằng cách tổng hợp nhiều biến đổi mã nguồn cấp phương thức; (iii) các tệp đại diện cho kho ngữ liệu văn bản lớn, với có thể nhiều dòng mã nguồn không được chạm đến trong PR, điều này sẽ cản trở mục tiêu huấn luyện mô hình NMT của chúng tôi.

Trong bài báo này, chúng tôi chỉ nghiên cứu các thay đổi mã nguồn thay đổi các phương thức hiện có, bỏ qua các thay đổi mã nguồn liên quan đến việc tạo hoặc xóa toàn bộ phương thức/tệp (xem Mục V).

C. Trừu tượng hóa & Lọc Mã nguồn

Các mô hình NMT tạo ra các chuỗi token bằng cách tính toán phân bố xác suất trên các từ. Chúng có thể trở nên rất chậm hoặc không chính xác khi xử lý một từ vựng lớn bao gồm nhiều token đầu ra có thể. Vấn đề này đã được giải quyết bằng cách giới hạn kích thước từ vựng một cách nhân tạo, chỉ xem xét các từ phổ biến nhất, gán các token đặc biệt (ví dụ, UNK) cho các từ hiếm hoặc bằng cách học các đơn vị từ con và chia các từ thành các token thành phần [53], [67].

Vấn đề của từ vựng lớn (còn gọi là từ vựng mở) được biết đến trong lĩnh vực Xử lý Ngôn ngữ Tự nhiên (NLP), nơi các ngôn ngữ như tiếng Anh hoặc tiếng Trung có thể có hàng trăm nghìn từ. Vấn đề này thậm chí còn rõ rệt hơn đối với mã nguồn. Thực tế, các nhà phát triển không bị giới hạn bởi một từ điển hữu hạn các từ để biểu diễn mã nguồn, thay vào đó, họ có thể tạo ra một lượng có thể vô hạn các định danh và literal mới. Bảng I hiển thị số lượng token duy nhất được xác định trong mã nguồn của ba bộ dữ liệu. Từ vựng của các bộ dữ liệu dao động từ 42k đến 267k, trong khi từ vựng kết hợp của ba bộ dữ liệu vượt quá 370k token duy nhất. Để so sánh, Từ điển Tiếng Anh Oxford chứa các mục từ cho 171,476 từ [55].

Để cho phép huấn luyện mô hình NMT, chúng tôi cần một cách để giảm từ vựng trong khi vẫn giữ lại thông tin ngữ nghĩa của mã nguồn. Chúng tôi sử dụng một quá trình trừu tượng hóa dựa trên các quan sát sau về thay đổi mã nguồn: (i) một số khối mã nguồn có thể không được chạm đến; (ii) các nhà phát triển có xu hướng tái sử dụng các định danh và literal đã có trong mã nguồn; (iii) các định danh thường xuyên (tức là, các cuộc gọi API và tên biến phổ biến) và literal (ví dụ, 0, 1, "foo") có khả năng được giới thiệu trong thay đổi mã nguồn.

Chúng tôi bắt đầu bằng cách tính toán 300 định danh thường xuyên nhất (tức là, tên loại, phương thức và biến) và literal (tức là, giá trị int, double, char, string) được sử dụng trong mã nguồn cho mỗi bộ dữ liệu trong ba bộ dữ liệu. Tập hợp này chứa các loại thường xuyên, cuộc gọi API, tên biến và giá trị literal phổ biến (ví dụ, 0, 1, "\n") mà chúng tôi muốn giữ trong từ vựng của mình.

Sau đó, chúng tôi trừu tượng hóa mã nguồn của các cặp phương thức bằng một quá trình thay thế các định danh và literal bằng các ID có thể tái sử dụng. Mã nguồn của một phương thức được đưa vào một bộ phân tích từ vựng, được xây dựng trên ANTLR [56], để token hóa mã nguồn thô thành một luồng token. Luồng token này sau đó được đưa vào một bộ phân tích Java, phân biệt vai trò của mỗi định danh (tức là, liệu nó đại diện cho tên biến, phương thức hay loại) và loại của một literal. Mỗi định danh và literal duy nhất được ánh xạ thành một ID, có dạng CATEGORY_#, trong đó CATEGORY đại diện cho loại định danh hoặc literal (tức là, TYPE, METHOD, VAR, INT, FLOAT, CHAR, STRING) và # là một ID số được tạo tuần tự cho mỗi loại thể hiện duy nhất trong danh mục đó (ví dụ, phương thức đầu tiên sẽ nhận METHOD_0, giá trị số nguyên thứ ba INT_2, v.v.). Những ID này được sử dụng thay cho các định danh và literal trong mã nguồn trừu tượng, trong khi ánh xạ giữa ID và giá trị định danh/literal thực tế được lưu trong một bản đồ M, cho phép chúng tôi ánh xạ ngược các ID trong giai đoạn cụ thể hóa mã nguồn (Mục II-E). Trong quá trình trừu tượng hóa, chúng tôi thay thế tất cả định danh/literal bằng ID, ngoại trừ danh sách 300 định danh và literal thường xuyên nhất, mà chúng tôi giữ giá trị token gốc trong kho ngữ liệu.

Cho một cặp phương thức (mb, ma), phương thức mb được trừu tượng hóa trước. Sau đó, sử dụng cùng ánh xạ M được tạo trong quá trình trừu tượng hóa của mb, phương thức ma được trừu tượng hóa sao cho các định danh/literal đã có trong M sẽ sử dụng cùng ID, trong khi các định danh/literal mới được giới thiệu trong ma (và không có trong mb) sẽ nhận một ID mới. Cuối quá trình này, từ cặp phương thức gốc (mb, ma) chúng tôi có được cặp phương thức trừu tượng (amb, ama).

Chúng tôi cho phép ID được tái sử dụng trên các cặp phương thức khác nhau (ví dụ, tên phương thức đầu tiên sẽ luôn nhận ID METHOD_0), do đó dẫn đến việc giảm tổng thể kích thước từ vựng. Cột thứ ba của Bảng I báo cáo kích thước từ vựng sau quá trình trừu tượng hóa, cho thấy sự giảm đáng kể trong số lượng token duy nhất trong kho ngữ liệu. Cụ thể, sau quá trình trừu tượng hóa, từ vựng chứa: (i) từ khóa Java; (ii) 300 định danh/literal hàng đầu; (iii) ID có thể tái sử dụng. Đáng chú ý rằng dòng cuối cùng trong Bảng I (tức là, Tất cả) không đại diện cho tổng tích lũy, mà là số lượng token duy nhất khi ba kho ngữ liệu bộ dữ liệu được gộp lại.

Có một từ vựng tương đối nhỏ cho phép mô hình NMT tập trung vào việc học các mẫu biến đổi mã nguồn phổ biến trong các bối cảnh khác nhau. Hơn nữa, việc sử dụng các định danh và literal thường xuyên cho phép mô hình NMT học các thay đổi điển hình (ví dụ, if(i>1) thành if(i>0)) và giới thiệu các cuộc gọi API dựa trên các cuộc gọi API khác đã có trong mã nguồn.

Sau quá trình trừu tượng hóa, chúng tôi lọc ra các cặp phương thức mà mô hình NMT sẽ không thể học các biến đổi mã nguồn sẽ dẫn đến mã nguồn thực tế. Để hiểu lý do đằng sau việc lọc này, điều quan trọng là phải hiểu các tình huống sử dụng thực tế. Khi mô hình NMT nhận mã nguồn của phương thức amb, nó chỉ có thể thực hiện các biến đổi mã nguồn liên quan đến: (i) từ khóa Java; (ii) định danh/literal thường xuyên; (iii) định danh và literal đã có trong mb. Do đó, chúng tôi bỏ qua các cặp phương thức mà ma chứa các token không được liệt kê trong ba danh mục đã nêu, vì mô hình sẽ phải tổng hợp các định danh hoặc literal mới chưa từng thấy trước đây.

Trong tương lai, chúng tôi dự định tăng số lượng định danh và literal thường xuyên được sử dụng trong từ vựng nhằm học các biến đổi mã nguồn từ càng nhiều cặp phương thức càng tốt. Chúng tôi cũng lọc ra những cặp phương thức sao cho amb = ama, có nghĩa là mã nguồn trừu tượng trước và sau PR xuất hiện giống nhau. Chúng tôi loại bỏ những thể hiện này vì mô hình NMT sẽ không học được bất kỳ biến đổi mã nguồn nào.

Tiếp theo, chúng tôi phân chia các cặp phương thức thành các cặp nhỏ và trung bình, dựa trên kích thước của chúng được đo bằng số lượng token. Cụ thể, các cặp phương thức nhỏ là những cặp không dài hơn 50 token, trong khi chúng tôi xem xét các cặp trung bình là những cặp có độ dài từ 50-100 token. Ở giai đoạn này, chúng tôi bỏ qua các cặp phương thức dài hơn. Chúng tôi thảo luận về hạn chế này trong Mục V.

Bảng II hiển thị số lượng cặp phương thức, sau quá trình trừu tượng hóa và lọc, cho mỗi bộ dữ liệu và bộ dữ liệu kết hợp (tức là, Tất cả). Mỗi bộ dữ liệu trong bốn bộ dữ liệu sau đó được phân chia ngẫu nhiên thành tập huấn luyện (80%), tập xác thực (10%) và tập kiểm tra (10%). Trước khi làm như vậy, chúng tôi đảm bảo loại bỏ bất kỳ cặp phương thức trùng lặp nào, để đảm bảo rằng không có cặp phương thức nào trong tập kiểm tra đã được nhìn thấy trong giai đoạn huấn luyện.

D. Học Biến đổi Mã nguồn

Trong mục này, chúng tôi mô tả các mô hình NMT mà chúng tôi sử dụng để học biến đổi mã nguồn. Cụ thể, chúng tôi huấn luyện các mô hình này để dịch mã nguồn trừu tượng amb thành ama, một cách hiệu quả mô phỏng thay đổi mã nguồn được thực hiện trong PR bởi các nhà phát triển.

1) RNN Encoder-Decoder: Để xây dựng các mô hình như vậy, chúng tôi dựa vào kiến trúc RNN Encoder-Decoder với cơ chế chú ý [30], [52], [32], thường được áp dụng trong các nhiệm vụ NMT [48], [60], [33]. Như tên gọi, mô hình này bao gồm hai thành phần chính: một RNN Encoder, mã hóa một chuỗi token x thành một biểu diễn vector, và một RNN Decoder, giải mã biểu diễn thành một chuỗi token khác y. Trong quá trình huấn luyện, mô hình học một phân bố có điều kiện trên một chuỗi (đầu ra) có điều kiện trên một chuỗi (đầu vào) khác các thuật ngữ: P(y1, ..., ym|x1, ..., xn), trong đó độ dài n và m có thể khác nhau. Trong thiết lập của chúng tôi, cho chuỗi đại diện cho mã nguồn trừu tượng trước PR x = amb = (x1, ..., xn) và một chuỗi mục tiêu tương ứng đại diện cho mã nguồn trừu tượng sau PR y = ama = (y1, ..., ym), mô hình được huấn luyện để học phân bố có điều kiện: P(ama|amb) = P(y1, ..., ym|x1, ..., xn), trong đó xi và yj là các token mã nguồn trừu tượng: từ khóa Java, dấu phân cách, ID và định danh và literal thường xuyên. Encoder lấy làm đầu vào một chuỗi x = (x1, ..., xn) và tạo ra một chuỗi trạng thái h = (h1, ..., hn). Cụ thể, chúng tôi áp dụng một RNN Encoder hai chiều [30], được hình thành bởi một RNN lùi và một RNN tiến. Các RNN xử lý câu từ trái sang phải và từ phải sang trái, và có thể tạo ra các biểu diễn câu có tính đến cả đầu vào quá khứ và tương lai [32]. RNN Decoder dự đoán xác suất của một chuỗi mục tiêu y = (y1, ..., ym) cho h. Cụ thể, xác suất của mỗi token đầu ra yi được tính toán dựa trên: (i) trạng thái tái phát si trong Decoder; (ii) i-1 token trước đó (y1, ..., yi-1); và (iii) một vector ngữ cảnh ci. Vector ci này, còn được gọi là vector chú ý, được tính toán như một trung bình có trọng số của các trạng thái trong h: ci = Σnt=1 aitht trong đó các trọng số ait cho phép mô hình chú ý nhiều hơn đến các phần khác nhau của chuỗi đầu vào, khi dự đoán token yi. Encoder và Decoder được huấn luyện cùng nhau bằng cách giảm thiểu độ âm log-likelihood của các token mục tiêu, sử dụng gradient descent ngẫu nhiên.

2) Giải mã Tìm kiếm Chùm tia: Đối với mỗi cặp phương thức (amb, ama) mô hình được huấn luyện để dịch amb duy nhất thành ama tương ứng. Tuy nhiên, trong quá trình kiểm tra, chúng tôi muốn có được nhiều bản dịch có thể. Chính xác, cho một đoạn mã nguồn m làm đầu vào cho mô hình, chúng tôi muốn có được k bản dịch có thể của m. Để đạt được mục tiêu này, chúng tôi sử dụng một chiến lược giải mã được gọi là Tìm kiếm Chùm tia được sử dụng trong các ứng dụng DL trước đây [57]. Trực giác chính đằng sau việc giải mã Tìm kiếm Chùm tia là thay vì dự đoán ở mỗi bước thời gian token có xác suất tốt nhất, quá trình giải mã theo dõi k giả thuyết (với k là kích thước chùm tia). Chính thức, gọi Ht là tập hợp k giả thuyết được giải mã cho đến bước thời gian t: Ht = {(~y¹₁, ..., ~y¹ₜ), (~y²₁, ..., ~y²ₜ), ..., (~yᵏ₁, ..., ~yᵏₜ)} Tại bước thời gian tiếp theo t+1, đối với mỗi giả thuyết sẽ có |V| thuật ngữ yt+1 có thể (V là từ vựng), với tổng cộng k|V| giả thuyết có thể: Ct+1 = ∪ᵏᵢ₌₁{(~yⁱ₁, ..., ~yⁱₜ, v1), ..., (~yⁱ₁, ..., ~yⁱₜ, v|V|)} Từ những tập hợp ứng cử viên này, quá trình giải mã giữ k chuỗi có xác suất cao nhất. Quá trình tiếp tục cho đến khi mỗi giả thuyết đạt đến token đặc biệt đại diện cho kết thúc của một chuỗi. Chúng tôi xem xét k câu cuối cùng này như các bản vá ứng cử viên cho mã nguồn có lỗi.

3) Tìm kiếm Siêu tham số: Chúng tôi đã thử nghiệm mười cấu hình của kiến trúc encoder-decoder với các kết hợp khác nhau của RNN Cells (LSTM [45] và GRU [33]), số lượng lớp (1, 2, 4) và đơn vị (256, 512) cho encoder/decoder, và kích thước embedding (256, 512). Phân nhóm và padding được sử dụng để xử lý độ dài biến đổi của các chuỗi. Chúng tôi đã huấn luyện các mô hình tối đa 60k epoch và chọn checkpoint của mô hình trước khi over-fitting dữ liệu huấn luyện. Để hướng dẫn việc lựa chọn cấu hình tốt nhất, chúng tôi đã sử dụng hàm mất mát được tính toán trên tập xác thực (không phải trên tập kiểm tra), trong khi kết quả được tính toán trên tập kiểm tra.

E. Cụ thể hóa Mã nguồn

Trong giai đoạn cuối cùng này, mã nguồn trừu tượng được tạo ra làm đầu ra bởi mô hình NMT được cụ thể hóa bằng cách ánh xạ ngược tất cả các ID định danh và literal thành giá trị thực tế của chúng. Quá trình đơn giản thay thế mỗi ID được tìm thấy trong mã nguồn trừu tượng thành định danh/literal thực tế được liên kết với ID và được lưu trong ánh xạ M, cho mỗi cặp phương thức. Mã nguồn được tự động thụt lề và các quy tắc phong cách mã nguồn bổ sung có thể được áp dụng trong giai đoạn này. Mặc dù chúng tôi không xử lý các chú thích, chúng có thể được giới thiệu lại trong giai đoạn này.

III. THIẾT KẾ NGHIÊN CỨU

Mục tiêu của nghiên cứu này là đánh giá thực nghiệm liệu NMT có thể được sử dụng để học một tập hợp các thay đổi mã nguồn đa dạng và có ý nghĩa. Bối cảnh bao gồm một bộ dữ liệu PR và nhằm trả lời hai câu hỏi nghiên cứu (RQ).

A. RQ1: Dịch Máy Thần Kinh có thể được sử dụng để học các thay đổi mã nguồn có ý nghĩa không?

Chúng tôi nhằm đánh giá thực nghiệm liệu NMT có phải là một cách tiếp cận khả thi để học biến đổi mã nguồn, như được thực hiện bởi các nhà phát triển trong PR. Để đạt được mục tiêu này, chúng tôi sử dụng tám bộ dữ liệu cặp phương thức được liệt kê trong Bảng II. Cho một bộ dữ liệu, chúng tôi huấn luyện các cấu hình khác nhau của các mô hình Encoder-Decoder trên tập huấn luyện, sau đó sử dụng tập xác thực để chọn cấu hình hoạt động tốt nhất của mô hình. Chúng tôi sau đó đánh giá tính hợp lệ của mô hình với các thể hiện chưa thấy của tập kiểm tra. Tổng cộng, chúng tôi thí nghiệm với tám mô hình khác nhau, một cho mỗi bộ dữ liệu trong Bảng II (tức là, một mô hình được huấn luyện, cấu hình và đánh giá trên bộ dữ liệu Google của các phương thức nhỏ, một trên bộ dữ liệu Google của các phương thức trung bình, v.v.).

Đánh giá được thực hiện bằng phương pháp sau. Gọi M là một mô hình được huấn luyện và T là tập kiểm tra của bộ dữ liệu D, chúng tôi đánh giá mô hình M cho mỗi (amb, ama) ∈ T. Cụ thể, chúng tôi đưa mã nguồn trừu tượng pre-PR amb vào mô hình M, thực hiện suy luận với Giải mã Tìm kiếm Chùm tia cho một kích thước chùm tia k cho trước. Mô hình sẽ tạo ra k biến đổi mã nguồn tiềm năng khác nhau CT = {ct1, ..., ctk}. Chúng tôi nói rằng mô hình dự đoán thành công một biến đổi mã nguồn nếu tồn tại một cti ∈ CT sao cho cti = ama (tức là, mã nguồn trừu tượng được tạo ra bởi các nhà phát triển sau khi gộp PR). Chúng tôi báo cáo số lượng thô và phần trăm của các thay đổi mã nguồn được dự đoán thành công trong tập kiểm tra, với k = 1, 5, 10. Nói cách khác, cho một phương thức mã nguồn mà mô hình chưa bao giờ thấy trước đó, chúng tôi đánh giá khả năng của mô hình trong việc dự đoán chính xác biến đổi mã nguồn mà một nhà phát triển đã thực hiện bằng cách cho phép mô hình tạo ra dự đoán tốt nhất (tức là, k = 1) hoặc top-5 và top-10 dự đoán tốt nhất. Cần lưu ý rằng trong khi chúng tôi chỉ đếm các dự đoán hoàn hảo, có nhiều biến đổi (hơi khác) khác vẫn có thể khả thi và hữu ích cho các nhà phát triển. Tuy nhiên, chúng tôi giảm giá những dự đoán kém hoàn hảo này vì không thể tự động phân loại chúng như khả thi và không khả thi.

B. RQ2: Mô hình có thể thực hiện những loại thay đổi mã nguồn có ý nghĩa nào?

Trong RQ này, chúng tôi nhằm đánh giá định tính các loại thay đổi mã nguồn mà mô hình NMT có thể tạo ra. Để đạt được mục tiêu này, chúng tôi chỉ tập trung vào các biến đổi mã nguồn được dự đoán thành công được tạo ra bởi mô hình được huấn luyện trên bộ dữ liệu Tất cả, xem xét cả các phương thức nhỏ và trung bình. Một trong những tác giả đã điều tra thủ công tất cả các biến đổi mã nguồn được dự đoán thành công và mô tả các thay đổi mã nguồn. Tiếp theo, một tác giả thứ hai đã thảo luận và xác thực các thay đổi mã nguồn được mô tả. Cuối cùng, năm tác giả cùng nhau định nghĩa – và lặp lại tinh chỉnh – một phân loại các biến đổi mã nguồn được thực hiện thành công bởi mô hình NMT.

IV. KẾT QUẢ NGHIÊN CỨU

A. RQ1: Dịch Máy Thần Kinh có thể được sử dụng để học các thay đổi mã nguồn có ý nghĩa không?

Bảng III báo cáo các dự đoán hoàn hảo (tức là, các biến đổi mã nguồn được dự đoán thành công) bởi các mô hình NMT, về số lượng thô và phần trăm của các tập kiểm tra. Khi chúng tôi cho phép các mô hình tạo ra chỉ một bản dịch duy nhất (tức là, beam = 1), chúng có thể dự đoán cùng biến đổi mã nguồn được thực hiện bởi các nhà phát triển trong 3% đến 21% các trường hợp. Đáng chú ý là mô hình được huấn luyện trên các bộ dữ liệu kết hợp (tức là, Tất cả) có thể vượt trội hơn tất cả các mô hình bộ dữ liệu đơn lẻ khác, đạt được kết quả ấn tượng ngay cả với một lần đoán duy nhất (21,16% cho các phương thức nhỏ và 16,21% cho các phương thức trung bình). Kết quả này cho thấy rằng các mô hình NMT có thể học các biến đổi mã nguồn từ một tập hợp các ví dụ không đồng nhất thuộc về các bộ dữ liệu khác nhau. Hơn nữa, điều này cũng cung cấp bằng chứng sơ bộ rằng học chuyển giao sẽ có thể cho các mô hình như vậy.

Ở đầu kia của phổ, hiệu suất kém của các mô hình được huấn luyện trên bộ dữ liệu Google có thể được giải thích bởi lượng dữ liệu huấn luyện hạn chế (xem Bảng II) so với các bộ dữ liệu khác.

Khi chúng tôi cho phép các mô hình tương tự tạo ra nhiều bản dịch của mã nguồn (tức là, 5 và 10), chúng tôi quan sát thấy sự tăng đáng kể trong các dự đoán hoàn hảo trên tất cả các mô hình. Trung bình, 1 trong 3 biến đổi mã nguồn có thể được tạo ra và dự đoán hoàn hảo bởi mô hình NMT được huấn luyện trên bộ dữ liệu kết hợp. Mô hình có thể tạo ra 10 biến đổi trong chưa đến một giây trên GPU cấp tiêu dùng.

Tóm tắt cho RQ 1. Các mô hình NMT có thể học các thay đổi mã nguồn có ý nghĩa và dự đoán hoàn hảo các biến đổi mã nguồn lên đến 21% các trường hợp khi chỉ một bản dịch được tạo ra, và lên đến 36% khi 10 lần đoán có thể được tạo ra.

B. RQ2: Mô hình có thể thực hiện những loại thay đổi mã nguồn có ý nghĩa nào?

Ở đây chúng tôi tập trung vào 722 (388+334) dự đoán hoàn hảo được tạo ra bởi mô hình được huấn luyện trên toàn bộ bộ dữ liệu, tức là Tất cả, với kích thước chùm tia bằng 10. Những dự đoán hoàn hảo này là kết quả của 216 loại thao tác AST duy nhất, như được phát hiện bởi GumTreeDiff, mà mô hình có thể mô phỏng. Danh sách đầy đủ có sẵn trong gói nhân bản của chúng tôi [21].

Hình 1 hiển thị phân loại các biến đổi mã nguồn mà chúng tôi rút ra bằng cách phân tích thủ công 722 dự đoán hoàn hảo. Lưu ý rằng một dự đoán hoàn hảo có thể bao gồm nhiều loại thay đổi thuộc về các danh mục khác nhau của phân loại chúng tôi (ví dụ, một tái cấu trúc và một sửa lỗi được triển khai trong cùng một biến đổi mã nguồn). Vì lý do này, tổng số các thay đổi được phân loại trong Hình 1 là 793. Phân loại được cấu thành từ ba cây con, nhóm các biến đổi mã nguồn liên quan đến sửa lỗi, tái cấu trúc, và các loại thay đổi "khác". Loại sau bao gồm các biến đổi mã nguồn mà mô hình thực hiện chính xác (tức là, những cái nhân bản những gì thực sự được thực hiện bởi các nhà phát triển trong các PR đã được đánh giá) nhưng chúng tôi không thể hiểu lý do đằng sau biến đổi mã nguồn (tức là, tại sao nó được thực hiện). Chúng tôi ưa thích áp dụng cách tiếp cận bảo thủ và phân loại các biến đổi vào các cây con "tái cấu trúc" và "sửa lỗi" chỉ khi chúng tôi có thể tự tin liên kết đến các loại hoạt động này. Ngoài ra, đối với 27 biến đổi, các tác giả không đồng ý về loại thay đổi mã nguồn và, do đó, chúng tôi loại trừ chúng khỏi phân loại của mình (liên quan đến 695 dự đoán hoàn hảo). Ở đây, chúng tôi thảo luận định tính các ví dụ thú vị (được chỉ ra bằng biểu tượng /code_fork) của các biến đổi mã nguồn thuộc về phân loại của chúng tôi. Chúng tôi không báo cáo ví dụ cho tất cả các danh mục có thể của các thay đổi được học bởi mô hình do thiếu không gian. Tuy nhiên, tập hợp đầy đủ các dự đoán hoàn hảo và phân loại của chúng có sẵn trong gói nhân bản của chúng tôi [21].

C. Tái cấu trúc

Chúng tôi nhóm trong cây con tái cấu trúc, tất cả các biến đổi mã nguồn thay đổi cấu trúc nội bộ của hệ thống bằng cách cải thiện một hoặc nhiều thuộc tính phi chức năng của nó (ví dụ, tính dễ đọc) mà không thay đổi hành vi bên ngoài của hệ thống. Chúng tôi phân loại các biến đổi thành năm danh mục con.

1) Kế thừa: Các tái cấu trúc ảnh hưởng đến cách cơ chế kế thừa được sử dụng trong mã nguồn. Chúng tôi tìm thấy ba loại tái cấu trúc liên quan đến kế thừa: (i) cấm ghi đè phương thức bằng cách thêm từ khóa final vào khai báo phương thức; (ii) gọi phương thức ghi đè thay vì bị ghi đè bằng cách loại bỏ từ khóa super khỏi lời gọi phương thức; và (iii) làm cho một phương thức trừu tượng thông qua từ khóa abstract và xóa thân phương thức.

/code_fork Phương thức hiện có được khai báo là final [3]. Trong lớp DirectByteBuffer của Android, mô hình NMT đã thêm vào chữ ký của phương thức getLong(int) từ khóa final. Như đã nêu bởi nhà phát triển triển khai PR: "DirectByteBuffer không thể là final, nhưng chúng ta có thể khai báo hầu hết các phương thức là final để dễ dàng lý luận hơn".

/code_fork Loại bỏ chỉ định "super" không cần thiết [24]. Một PR trong hệ thống con lõi Ovirt đã được thực hiện để dọn dẹp lớp RandomUtil, kế thừa từ lớp Java java.util.Random. Phương thức nextShort() được triển khai trong lớp được tái cấu trúc đã gọi nextInt() của lớp cơ sở thông qua việc sử dụng chỉ định super của Java. Tuy nhiên, chỉ định như vậy là dư thừa vì nextInt() không được ghi đè trong RandomUtil. Do đó, nó đã được loại bỏ bởi nhà phát triển: "Sử dụng modifier này không có ý nghĩa trong bối cảnh đã được loại bỏ".

/code_fork Phương thức hiện có được chuyển đổi thành abstract [1].

```java
float getFloatUnchecked(int index) {
    throw new UnsupportedOperationException();
}

abstract float getFloatUnchecked(int index);
```

Danh sách mã nguồn ở trên hiển thị mã nguồn được lấy làm đầu vào bởi mô hình NMT (phần trên, pre-PR) và được tạo ra làm đầu ra (phần dưới, post-PR). Biến đổi mã nguồn nhân bản các thay đổi được triển khai bởi một nhà phát triển trong một PR, chuyển đổi phương thức getFloatUnchecked thành một phương thức trừu tượng, xóa thân của nó. Lý do cho thay đổi này được giải thích bởi nhà phát triển đã triển khai thay đổi này: Phương thức getFloatUnchecked được ghi đè trong tất cả các lớp con của lớp trừu tượng triển khai nó và, do đó, "không cần thiết cho lớp cơ sở trừu tượng phải mang một triển khai ném UnsupportedOperationException". Nhà phát triển cũng đề cập đến các giải pháp thay thế, chẳng hạn như chuyển phương thức này và các phương thức tương tự vào một giao diện, nhưng kết luận rằng nỗ lực sẽ cao hơn nhiều. Trường hợp này thú vị vì ít nhất hai lý do. Đầu tiên, mô hình của chúng tôi có thể học một kết hợp các biến đổi mã nguồn cần thiết để nhân bản PR được triển khai bởi nhà phát triển (tức là, thêm từ khóa abstract và xóa thân phương thức). Thứ hai, nó cho thấy sự sẵn có phong phú của thông tin về "lý do" cho các thay đổi được triển khai có sẵn trong các kho lưu trữ đánh giá mã nguồn. Điều này có thể được khai thác trong tương lai để không chỉ học biến đổi mã nguồn, mà còn biện minh cho nó bằng cách tự động rút ra lý do từ thảo luận của các nhà phát triển.

2) Tương tác Phương thức: Những tái cấu trúc này ảnh hưởng đến cách các phương thức của hệ thống tương tác, và bao gồm (i) thêm tái cấu trúc tham số (tức là, một giá trị trước đó được tính toán trong thân phương thức bây giờ được truyền như một tham số cho nó), và (ii) mở rộng loại trả về của một phương thức bằng cách sử dụng ký hiệu đại diện (?) của Java.

/code_fork Phương thức trả về một loại generic rộng hơn [18].

```java
<I> RestModifyView<P,I> post(P parent) throws [...];
RestModifyView<P,?> post(P parent) throws [...];
```

Danh sách mã nguồn hiển thị một thay đổi được triển khai trong một PR được thực hiện trên kho lưu trữ "Google" Gerrit và được nhân bản chính xác bởi mô hình NMT. Khai báo phương thức post được tái cấu trúc để trả về một loại rộng hơn và cải thiện việc sử dụng generics. Như được giải thích bởi nhà phát triển, điều này cũng cho phép tránh các cảnh báo 'unchecked' từ năm triển khai của phương thức post có mặt trong hệ thống, do đó đơn giản hóa mã nguồn.

3) Đặt tên: Danh mục này nhóm các tái cấu trúc liên quan đến việc đổi tên các phương thức, tham số và biến. Điều này thường được thực hiện để cải thiện tính biểu đạt của các định danh và để tuân thủ tốt hơn các hướng dẫn phong cách mã nguồn. Thật vậy, các định danh tốt cải thiện tính dễ đọc, khả năng hiểu và khả năng bảo trì của mã nguồn [27], [46].

/code_fork Đổi tên phương thức [25]. Một ví dụ về đổi tên phương thức được học chính xác, là cái sửa lỗi chính tả từ phương thức OnSucess trong hệ thống Ovirt [25]. Trong trường hợp này, nhà phát triển (và mô hình NMT) đều đề xuất đổi tên phương thức thành OnSuccess.

/code_fork Đổi tên tham số [12]. Một ví dụ thứ hai về đổi tên, là tham số đã đổi tên được đề xuất cho phương thức endTrace(JMethod type) trong một PR ảnh hưởng đến lớp AbstractTracerBrush trong kho lưu trữ Android [12]. Nhà phát triển ở đây đã đổi tên một số tham số "để rõ ràng" và, trong trường hợp này, đã đổi tên tham số type thành method, để làm cho nó mô tả hơn và phản ánh tốt hơn mục tiêu của nó.

4) Đóng gói: Chúng tôi tìm thấy các tái cấu trúc nhằm mở rộng và thu hẹp khả năng hiển thị của các phương thức (xem Hình 1). Điều này có thể được thực hiện bằng cách sửa đổi các modifier truy cập (ví dụ, thay đổi một phương thức public thành private).

/code_fork Mở rộng [5] và thu hẹp [19] khả năng hiển thị phương thức. Một ví dụ về một phương thức, mà mô hình của chúng tôi khuyến nghị mở rộng khả năng hiển thị từ private thành public, là phương thức of từ lớp Key Android [5]. Thay đổi này được thực hiện trong một PR để cho phép sử dụng phương thức từ bên ngoài lớp, vì nhà phát triển cần nó để triển khai một tính năng mới.

Khả năng hiển thị thay vào đó được thu hẹp từ public thành private trong bối cảnh của một tái cấu trúc được thực hiện bởi một nhà phát triển để làm "nhiều phương thức riêng tư hơn" [19]. Thay đổi này ảnh hưởng đến phương thức CurrentUser:getUser() từ kho lưu trữ Google, và lý do cho thay đổi này được nhân bản chính xác bởi mô hình NMT là phương thức getUser() chỉ được sử dụng ở một vị trí trong hệ thống bên ngoài lớp của nó. Tuy nhiên, ở vị trí đó giá trị của "người dùng đã được biết", do đó thực sự không yêu cầu lời gọi getUser().

5) Tính dễ đọc: Mã nguồn dễ đọc dễ hiểu và bảo trì hơn [59]. Chúng tôi tìm thấy một số loại biến đổi mã nguồn được học bởi mô hình và nhắm vào việc cải thiện tính dễ đọc mã nguồn. Điều này bao gồm: (i) dấu ngoặc nhọn được thêm vào các câu lệnh if với mục tiêu duy nhất là phân định rõ ràng phạm vi của chúng; (ii) việc gộp hai câu lệnh định nghĩa (ví dụ, String address;) và khởi tạo (ví dụ, address = getAddress();) một biến thành một câu lệnh duy nhất thực hiện cả hai (ví dụ, String address = getAddress();); (iii) việc thêm/loại bỏ qualifier this, để phù hợp với các tiêu chuẩn mã nguồn của dự án; (iv) giảm độ dài dòng của khai báo generic bằng cách sử dụng toán tử diamond của Java (ví dụ, Map<String, List<String>> mapping = new HashMap<String, List<String>>() trở thành Map<String, List<String>> mapping = new HashMap<>()); (v) loại bỏ từ khóa else dư thừa khỏi các câu lệnh if (tức là, khi mã nguồn được phân định bởi câu lệnh else sẽ được thực thi trong mọi trường hợp); (vi) tái cấu trúc các lớp ẩn danh triển khai một phương thức thành các biểu thức lambda, để làm cho mã nguồn dễ đọc hơn [22]; (vii) đơn giản hóa các biểu thức boolean (ví dụ, if(x==true) trở thành if(x), trong đó x là một biến boolean); và (viii) gộp hai khối catch nắm bắt các ngoại lệ khác nhau thành một khối catch nắm bắt cả hai ngoại lệ sử dụng toán tử or [7].

/code_fork Lớp ẩn danh được thay thế bằng biểu thức lambda [22].

```java
public boolean isDiskExist([...]) {
    return execute(new java.util.concurrent.Callable<java.lang.Boolean>() {
        @java.lang.Override
        public java.lang.Boolean call() { try {[...]} }
    });
}

public boolean isDiskExist([...]) {
    return execute(() -> { try {[...]} });
}
```

Trong danh sách mã nguồn ở trên, mô hình NMT tự động thay thế một lớp ẩn danh (phần trên, pre-PR) bằng một biểu thức lambda (phần dưới, post-PR), nhân bản các thay đổi được thực hiện bởi các nhà phát triển Ovirt trong quá trình chuyển đổi mã nguồn thông qua Java 8. Cú pháp mới gọn gàng và dễ đọc hơn.

/code_fork Gộp các khối catch nắm bắt các ngoại lệ khác nhau [7].

```java
public static Integer getInteger(String nm, Integer val) {
    [...]
    try {[...]}
    catch (IllegalArgumentException e) { }
    catch (NullPointerException e) { }
}

public static Integer getInteger(String nm, Integer val) {
    [...]
    try {[...]}
    catch (IllegalArgumentException | NullPointerException e) { }
}
```

Như một phần của PR triển khai một số thay đổi, hai khối catch của phương thức getInteger đã được gộp bởi nhà phát triển thành một khối catch duy nhất (xem mã nguồn ở trên). Mô hình NMT có thể nhân bản biến đổi mã nguồn như vậy chỉ có ý nghĩa khi một ngoại lệ được nắm bắt và mã nguồn kết quả được thực thi là giống nhau cho cả hai trường hợp ngoại lệ (như trong trường hợp này). Thay đổi mã nguồn này, mặc dù đơn giản từ góc độ nhà phát triển, không tầm thường để học do nhiều biến đổi phải triển khai (tức là, loại bỏ hai khối catch và triển khai một khối catch mới sử dụng toán tử or) và "điều kiện tiên quyết" phải kiểm tra (tức là, cùng hành vi được triển khai trong các khối catch).

D. Sửa lỗi

Các thay đổi trong cây con "sửa lỗi" (xem Hình 1) bao gồm các thay đổi được triển khai với mục tiêu sửa một lỗi cụ thể đã được giới thiệu trong quá khứ. Các biến đổi mã nguồn được học được tổ chức ở đây thành năm danh mục con, nhóm các thay đổi liên quan đến sửa lỗi xử lý (i) xử lý ngoại lệ, (ii) thêm/sửa đổi các câu lệnh có điều kiện, (iii) thay đổi trong giá trị được trả về bởi một phương thức, (iv) xử lý cơ chế khóa, và (v) lời gọi phương thức sai.

1) Ngoại lệ: Danh mục thay đổi này được chuyên biệt hóa thêm thành nhiều danh mục con (xem Hình 1) bao gồm (i) thêm/xóa các ngoại lệ ném; (ii) thêm các khối try-catch-finally [2]; (iii) thu hẹp hoặc mở rộng phạm vi của khối try bằng cách di chuyển các câu lệnh hiện có vào trong/ra khỏi khối [9]; (iv) thay đổi loại ngoại lệ trong mệnh đề catch thành một loại hẹp hơn (ví dụ, thay thế Throwable bằng RuntimeException).

/code_fork Thêm khối try-catch [2].

```java
public void test_getPort() throws IOException {
    DatagramSocket theSocket = new DatagramSocket();
    [...]
}

public void test_getPort() throws IOException {
    try (DatagramSocket theSocket = new DatagramSocket()) {
        [...]
    }
}
```

Mã nguồn ở trên từ kho lưu trữ Android, hiển thị thay đổi được triển khai trong một PR nhằm sửa "rò rỉ tài nguyên trong các bài kiểm tra". Biến đổi được thực hiện bởi mô hình NMT đã bao bọc việc tạo và sử dụng một đối tượng DatagramSocket vào một khối try-with-resources. Theo cách này, theSocket.close() sẽ được tự động gọi (hoặc một ngoại lệ sẽ được ném), do đó tránh rò rỉ tài nguyên.

/code_fork Thu hẹp phạm vi của khối try [9].

```java
public void testGet_NullPointerException() {
    try {
        ConcurrentHashMap c = new ConcurrentHashMap(5);
        c.get(null);
        shouldThrow();
    } catch (java.lang.NullPointerException success) {}
}

public void testGet_NullPointerException() {
    ConcurrentHashMap c = new ConcurrentHashMap(5);
    try {
        c.get(null);
        shouldThrow();
    } catch (java.lang.NullPointerException success) {}
}
```

Một thay đổi khác được nhân bản bởi mô hình NMT và ảnh hưởng đến bộ kiểm tra Android là biến đổi mã nguồn được mô tả ở trên và di chuyển việc khởi tạo đối tượng ConcurrentHashMap ra khỏi khối try. Lý do cho thay đổi này như sau. Phương thức kiểm tra liên quan được cho là ném một NullPointerException trong trường hợp c.get(null) được gọi. Tuy nhiên, phương thức kiểm tra cũng sẽ vượt qua nếu ngoại lệ được ném trong quá trình khởi tạo c. Vì lý do này, nhà phát triển đã di chuyển việc tạo đối tượng ra khỏi khối try.

2) Câu lệnh có điều kiện: Một số lỗi có thể được sửa trong các câu lệnh có điều kiện xác minh rằng một số điều kiện tiên quyết được đáp ứng trước khi các hành động cụ thể được thực hiện (ví dụ, xác minh rằng một đối tượng không null trước khi gọi một trong các phương thức của nó).

/code_fork Thêm kiểm tra null [4].

```java
public void run() {
    mCallback.onConnectionStateChange(BluetoothGatt.this,
        GATT_FAILURE,
        BluetoothProfile.STATE_DISCONNECTED);
}

public void run() {
    if(mCallback != null) {
        mCallback.onConnectionStateChange(BluetoothGatt.this,
            GATT_FAILURE,
            BluetoothProfile.STATE_DISCONNECTED);
    }
}
```

Danh sách mã nguồn hiển thị các thay đổi được triển khai trong một PR Android để "sửa một NullPointerException khi truy cập mCallback trong BluetoothGatt". Việc thêm câu lệnh if triển khai kiểm tra null cho phép mô hình NMT sửa lỗi chính xác như nhà phát triển đã làm.

/code_fork Thay đổi toán hạng so sánh [6].

```java
public void reset(int i) {
    if((i < 0) || (i >= mLen)) { [...] }
}

public void reset(int i) {
    if((i < 0) || (i > mLen)) { [...] }
}
```

Một ví dụ thứ hai về một lỗi được sửa thành công bởi mô hình NMT làm việc trên các câu lệnh có điều kiện, ảnh hưởng đến API của lớp FieldPacker. Như được giải thích bởi nhà phát triển, PR đã đóng góp "một bản sửa lỗi cho API FieldPacker.reset(), không cho phép FieldPacker chỉ đến mục cuối cùng trong bộ đệm của nó". Điều này được thực hiện bằng cách thay đổi toán hạng >= thành > như được hiển thị trong mã nguồn được báo cáo ở trên.

3) Giá trị: Loại thay đổi duy nhất chúng tôi quan sát trong danh mục này là thay đổi giá trị trả về của phương thức để sửa lỗi. Điều này bao gồm các trường hợp đơn giản trong đó giá trị trả về boolean được thay đổi từ false thành true (xem ví dụ, [13]), cũng như các biến đổi mã nguồn ít rõ ràng hơn trong đó giá trị trả về hằng số được thay thế bằng một trường lưu trữ giá trị trả về hiện tại, ví dụ, return "refs=my=config"; được chuyển đổi thành return ref;, trong đó ref là một biến được khởi tạo trong constructor [20].

4) Cơ chế khóa: Những thay đổi mã nguồn này đều liên quan đến việc sử dụng từ khóa synchronized của Java trong các phần khác nhau của mã nguồn. Điều này bao gồm việc loại bỏ nó khỏi một khối mã nguồn [11], khỏi chữ ký phương thức [10], và di chuyển từ khóa từ chữ ký phương thức sang khối mã nguồn hoặc ngược lại [8]. Chúng tôi không thảo luận về những biến đổi này do thiếu không gian.

5) Lời gọi phương thức: Danh mục này nhóm các biến đổi mã nguồn sửa lỗi bằng cách thay đổi thứ tự hoặc giá trị của các tham số trong lời gọi phương thức.

/code_fork Đảo tham số trong assertEquals [23].

```java
public void testConvertMBToBytes() {
    [...]
    org.junit.Assert.assertEquals(bytes, 3145728);
}

public void testConvertMBToBytes() {
    [...]
    org.junit.Assert.assertEquals(3145728, bytes);
}
```

Trong ví dụ này, nhà phát triển đã sửa một lỗi trong bộ kiểm tra bằng cách đảo thứ tự mà các tham số được truyền cho phương thức assertEquals. Cụ thể, trong khi phương thức assert đang mong đợi cặp tham số (long expected, long actual), bài kiểm tra đang truyền giá trị thực tế trước, do đó làm vô hiệu hóa bài kiểm tra. Bản sửa lỗi, được tự động áp dụng bởi mô hình NMT, hoán đổi các đối số của assertEquals.

E. Khác

Như đã nói trước đó, chúng tôi gán cho cây con 'Khác' những biến đổi mã nguồn mà chúng tôi không thể xác định rõ ràng động lực/lý do. Cây con này bao gồm các thay đổi liên quan đến: (i) chữ ký phương thức (thêm/loại bỏ/thay đổi tham số hoặc loại trả về); (ii) loại (loại bỏ ép kiểu trong thân phương thức hoặc chữ ký của nó, thay đổi loại biến); (iii) khởi tạo biến; (iv) thay thế câu lệnh/phương thức được gọi; (v) thêm mã nguồn (điều kiện, câu lệnh, phương thức được gọi, tham số); (vi) xóa mã nguồn (điều kiện if, khối finally, khối try-catch, phương thức được gọi, câu lệnh); (vii) thay đổi được kích hoạt bởi các thay đổi khác (ví dụ, lời gọi phương thức tĩnh được thay thế bằng lời gọi phương thức thể hiện hoặc ngược lại — xem Hình 1). Lưu ý rằng, trong khi chúng tôi không gán một "ý nghĩa" cụ thể cho những thay đổi này, do thiếu kiến thức lĩnh vực của các hệ thống liên quan, đây vẫn là những dự đoán hoàn hảo mà mô hình NMT đã thực hiện. Điều này có nghĩa là các thay đổi mã nguồn giống hệt với những thay đổi được triển khai bởi các nhà phát triển trong PR.

Tóm tắt cho RQ 2. Kết quả của chúng tôi cho thấy tiềm năng to lớn của NMT để học các thay đổi mã nguồn có ý nghĩa. Thật vậy, mô hình NMT có thể học và tự động áp dụng một loạt các thay đổi mã nguồn, chủ yếu liên quan đến các hoạt động tái cấu trúc và sửa lỗi. Thực tế là chúng tôi không tìm thấy các loại thay đổi khác, chẳng hạn như triển khai tính năng mới, có thể do bối cảnh hẹp mà chúng tôi áp dụng các mô hình của mình (tức là, các phương thức có kích thước hạn chế), cũng như thực tế là các tính năng mới được triển khai trong các lớp và hệ thống khác nhau hiếm khi thể hiện các mẫu lặp lại (tức là, các loại thay đổi mã nguồn lặp lại) mà mô hình có thể học. Cần nhiều nghiên cứu hơn để thực hiện bước tiến xa hơn này.

V. RỦISANH GIA TRỊ

Tính hợp lệ cấu trúc. Chúng tôi đã thu thập các thành phần mã nguồn trước và sau các pull request thông qua một trình thu thập dựa trên API Gerrit. Trình thu thập đã được kiểm tra rộng rãi, và việc phân tích thủ công các cặp được trích xuất được thực hiện để định nghĩa phân loại trong Hình 1 đã xác nhận tính chính xác của dữ liệu được thu thập.

Tính hợp lệ nội bộ. Hiệu suất của mô hình NMT có thể bị ảnh hưởng bởi cấu hình siêu tham số mà chúng tôi áp dụng. Để đảm bảo khả năng nhân bản, chúng tôi giải thích trong Mục II cách tìm kiếm siêu tham số đã được thực hiện.

Chúng tôi đã xác định thông qua phân tích thủ công các loại biến đổi mã nguồn được học bởi mô hình. Để giảm thiểu sai lệch chủ quan trong quá trình như vậy, việc định nghĩa phân loại đã được thực hiện bởi một trong những tác giả, được kiểm tra kép bởi tác giả thứ hai, và cuối cùng, phân loại kết quả đã được thảo luận giữa tất cả các tác giả để phát hiện các vấn đề có thể. Hơn nữa, trong trường hợp có nghi ngờ, biến đổi mã nguồn đã được phân loại trong cây con "khác", trong đó chúng tôi chỉ quan sát loại thay đổi mã nguồn được triển khai, mà không đoán về mục tiêu của biến đổi. Tuy nhiên, như trong bất kỳ quá trình thủ công nào, lỗi là có thể, và chúng tôi không thể loại trừ sự hiện diện của các biến đổi mã nguồn được phân loại sai trong phân loại của chúng tôi.

Tính hợp lệ bên ngoài. Chúng tôi đã thí nghiệm với mô hình NMT trên dữ liệu liên quan đến chỉ các chương trình Java. Tuy nhiên, quá trình học là độc lập với ngôn ngữ và toàn bộ cơ sở hạ tầng có thể được khởi tạo cho các ngôn ngữ lập trình khác nhau bằng cách thay thế các công cụ phân tích từ vựng, phân tích cú pháp và phân biệt AST.

Chúng tôi chỉ tập trung vào các phương thức không có hơn 100 token. Điều này được biện minh bởi thực tế là chúng tôi quan sát mật độ cao hơn của các cặp phương thức với kích thước nhỏ hơn 100 token trong bộ dữ liệu của chúng tôi. Phân bố cũng cho thấy đuôi dài của các phương thức lớn, có thể có vấn đề khi huấn luyện mô hình NMT. Phân bố và dữ liệu có thể được truy cập trong gói nhân bản của chúng tôi [21]. Ngoài ra, chúng tôi chỉ tập trung vào việc học các biến đổi mã nguồn của các phương thức hiện có thay vì việc tạo ra các phương thức mới vì những cái sau là (i) các thay đổi mã nguồn phức tạp liên quan đến mức độ hiểu biết cao hơn về hệ thống phần mềm trong toàn bộ; và (ii) không phù hợp với các mô hình NMT vì việc dịch sẽ đi từ/đến các phương thức rỗng.

Cuối cùng, dữ liệu pull request từ ba kho lưu trữ Gerrit đã được sử dụng. Mặc dù các kho lưu trữ này bao gồm hàng trăm dự án cá nhân (do đó đảm bảo tính hợp lệ bên ngoài tốt của các phát hiện của chúng tôi) kết quả của chúng tôi có thể không tổng quát hóa cho các dự án/ngôn ngữ khác.

VI. CÔNG TRÌNH LIÊN QUAN

Học Sâu (DL) gần đây đã trở thành một công cụ hữu ích để nghiên cứu các khía cạnh khác nhau của kỹ thuật phần mềm. Các biểu diễn độc đáo cho phép các đặc trưng được phát hiện bởi mô hình thay vì suy ra thủ công. Do sức mạnh của những biểu diễn này, nhiều công trình đã áp dụng các mô hình này để giải quyết các vấn đề SE [39][26][37][35][51][44][58][43]. Tuy nhiên, theo hiểu biết tốt nhất của chúng tôi, đây là công trình đầu tiên sử dụng các kỹ thuật DL để học và tạo ra một phân loại từ một loạt các biến đổi mã nguồn được lấy từ các PR của các nhà phát triển.

White et al. sử dụng học biểu diễn qua một autoencoder đệ quy cho nhiệm vụ phát hiện bản sao [64]. Mỗi đoạn mã nguồn được biểu diễn như một luồng định danh và literal, mà họ sử dụng như đầu vào cho mô hình DL của họ. Sử dụng mã hóa tương tự, Tufano et al. mã hóa các phương thức thành bốn biểu diễn khác nhau, sau đó mô hình DL đánh giá mức độ tương tự của hai đoạn mã nguồn dựa trên nhiều biểu diễn của chúng [61]. Một công trình gần đây khác của Tufano et al. áp dụng NMT vào các bản vá sửa lỗi trong thực tế [62]. Công trình này áp dụng cách tiếp cận tương tự, nhưng thay vì học các biến đổi mã nguồn, họ cố gắng học các commit sửa lỗi để tạo ra các bản vá. Những công trình này liên quan đến của chúng tôi, vì chúng tôi sử dụng biểu diễn mã nguồn tương tự như đầu vào cho mô hình DL, tuy nhiên, chúng tôi áp dụng phương pháp này để học càng nhiều biến đổi mã nguồn càng tốt.

White et al. cũng so sánh các mô hình DL với các mô hình xử lý ngôn ngữ tự nhiên cho nhiệm vụ gợi ý mã nguồn. Họ chỉ ra rằng các mô hình DL đưa ra gợi ý mã nguồn dựa trên các đặc trưng bối cảnh được học bởi mô hình thay vì sức mạnh dự đoán của n token trước đó [65]. Mở rộng thêm về khả năng dự đoán mạnh mẽ của các mô hình này, Dam et al. trình bày DeepSoft, một kiến trúc dựa trên DL được sử dụng để mô hình hóa phần mềm, tạo mã nguồn và dự đoán rủi ro phần mềm [36].

DL cũng đã được áp dụng vào các lĩnh vực phân loại lỗi và định vị. Lam et al. sử dụng các mô hình DL và truy xuất thông tin để định vị các tệp có lỗi sau khi một báo cáo lỗi được gửi. Họ sử dụng Mô hình Không gian Vector đã sửa đổi để tạo ra một biểu diễn mà mô hình DL có thể sử dụng để liên kết các thuật ngữ trong báo cáo lỗi với các token mã nguồn [49]. Tương tự, để giảm nỗ lực phân loại lỗi, Lee et al. áp dụng CNN vào phần mềm công nghiệp để phân loại lỗi đúng cách. Cách tiếp cận này sử dụng word2vec để nhúng tóm tắt và mô tả mà CNN sau đó gán cho một nhà phát triển [50]. Liên quan đến lỗi phần mềm, Wang et al. sử dụng Deep Belief Network (DBN) để học các đặc trưng ngữ nghĩa từ các vector token được lấy từ AST của chương trình. Mạng sau đó dự đoán liệu commit có bị lỗi hay không [63].

Nhiều cách sử dụng DL nhằm giúp các nhà phát triển với các nhiệm vụ bên ngoài việc viết mã nguồn. Choetkiertikul et al. đề xuất một kiến trúc DL của long short-term memory và mạng đường cao tốc tái phát nhằm dự đoán ước tính nỗ lực của một nhiệm vụ mã hóa [34]. Một hỗ trợ khác cho các nhà phát triển là khả năng tóm tắt một đoạn mã nguồn cho trước. Về điểm này, Allamanis et al. sử dụng Mạng Thần Kinh Chú Ý (ANN) với một lớp tích chập để tóm tắt các đoạn mã nguồn thành các mô tả ngắn gọn, chức năng [29]. Guo et al. phát triển một cách tiếp cận DL sử dụng RNN và nhúng từ để học ngữ nghĩa câu của các tạo phẩm yêu cầu, giúp tạo ra các liên kết truy xuất trong các dự án phần mềm [42]. Ví dụ cuối cùng về các triển khai DL giúp các nhà phát triển trong quá trình phát triển phần mềm là một cách tiếp cận được phát triển bởi Gu et al. giúp định vị mã nguồn. Triển khai này sử dụng NN và ngôn ngữ tự nhiên để nhúng các đoạn mã nguồn với các mô tả ngôn ngữ tự nhiên vào một không gian vector nhiều chiều, giúp các nhà phát triển định vị mã nguồn dựa trên các truy vấn ngôn ngữ tự nhiên [40].

Các cách tiếp cận dựa trên DL cũng đã được áp dụng vào các nhiệm vụ liên quan đến mã hóa nhiều hơn, một nhiệm vụ như vậy là đặt tên chính xác phương thức và lớp. Allamanis et al. sử dụng mạng thần kinh log-bilinear để hiểu bối cảnh của một phương thức hoặc lớp và khuyến nghị một tên đại diện chưa xuất hiện trong kho ngữ liệu huấn luyện [28]. Cũng giúp với các thực hành mã hóa chính xác, Gu et al. sử dụng mô hình RNN encoder-decoder để tạo ra một loạt các cách sử dụng API chính xác trong mã nguồn dựa trên các truy vấn ngôn ngữ tự nhiên. Ngữ nghĩa được học cho phép mô hình liên kết các truy vấn ngôn ngữ tự nhiên với một chuỗi các cách sử dụng API [41].

Gần đây chúng ta đã thấy DL xâm nhập vào lĩnh vực SE di động. Moran et al. sử dụng cách tiếp cận dựa trên DL để tự động tạo ra GUI cho các ứng dụng di động. Trong cách tiếp cận này, một CNN sâu được sử dụng để giúp phân loại các thành phần GUI có thể sau đó được sử dụng để tạo ra một GUI mô phỏng cho một ứng dụng cụ thể [54].

Mặc dù các cách tiếp cận DL phổ biến trong SE, công trình này là công trình đầu tiên áp dụng DL để đánh giá thực nghiệm khả năng học các thay đổi mã nguồn từ các PR của nhà phát triển. Công trình trước đó đã chỉ ra rằng các cách tiếp cận DL có thể mang lại kết quả có ý nghĩa với đủ dữ liệu huấn luyện chất lượng. Do đó, chúng tôi cụ thể áp dụng NMT để tự động học một loạt các biến đổi mã nguồn, từ các pull request thực tế, và tạo ra một phân loại có ý nghĩa.

VII. KẾT LUẬN

Chúng tôi đã điều tra khả năng của các mô hình NMT để học cách tự động áp dụng các biến đổi mã nguồn. Chúng tôi trước tiên khai thác một bộ dữ liệu các thay đổi mã nguồn hoàn chỉnh và có ý nghĩa được thực hiện bởi các nhà phát triển trong các pull request đã gộp, được trích xuất từ ba kho lưu trữ Gerrit. Sau đó, chúng tôi huấn luyện các mô hình NMT để dịch mã nguồn pre-PR thành mã nguồn post-PR, một cách hiệu quả học các biến đổi mã nguồn như được thực hiện bởi các nhà phát triển.

Phân tích thực nghiệm của chúng tôi cho thấy rằng các mô hình NMT có khả năng học các thay đổi mã nguồn và dự đoán hoàn hảo các biến đổi mã nguồn lên đến 21% các trường hợp khi chỉ một bản dịch duy nhất được tạo ra, và lên đến 36% khi 10 lần đoán có thể được tạo ra. Kết quả cũng làm nổi bật khả năng của các mô hình để học từ một tập hợp các PR không đồng nhất thuộc về các bộ dữ liệu khác nhau, cho thấy khả năng học chuyển giao qua các dự án và lĩnh vực. Phân tích định tính được thực hiện cũng làm nổi bật khả năng của các mô hình NMT để học một loạt các biến đổi mã nguồn, mở đường cho nghiên cứu thêm trong lĩnh vực này nhắm vào việc học tự động và áp dụng các thay đổi mã nguồn không tầm thường, chẳng hạn như các hoạt động tái cấu trúc. Trong ý nghĩa đó, chúng tôi hy vọng rằng sự sẵn có công khai của mã nguồn cơ sở hạ tầng của chúng tôi và của dữ liệu và công cụ chúng tôi đã sử dụng [21], có thể giúp thúc đẩy nghiên cứu trong lĩnh vực này.

VIII. LỜI CẢM ƠN

Công trình này được hỗ trợ một phần bởi các khoản tài trợ NSF CCF-1525902 và CCF-1815186. Pantiuchina và Bavota cảm ơn Quỹ Khoa học Quốc gia Thụy Sĩ vì sự hỗ trợ tài chính thông qua Dự án SNF JITRA, Số 172479. Bất kỳ ý kiến, phát hiện và kết luận nào được thể hiện ở đây là của các tác giả và không nhất thiết phản ánh quan điểm của các nhà tài trợ.

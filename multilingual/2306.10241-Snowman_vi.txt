bộ lọc RoBERTa tiếng Trung³ (Liu et al., 2019) để lọc các bộ ba HinderedBy thô chất lượng thấp. Lưu ý rằng phương pháp lọc này tận dụng các phán đoán của ChatGPT để lọc bỏ việc tạo sinh chất lượng thấp của chính nó, điều này không cần bất kỳ chú thích nào của con người và do đó được gọi là lọc tự hướng dẫn.

3 Phân tích Dữ liệu

Đánh giá của Con người. Chúng tôi tiến hành phân tích của con người trên Snowman của chúng tôi và ATOMIC-zh trước đó (Li et al., 2022) cũng như CN-AutoMIC (Wang et al., 2022a). Đối với Snowman, chúng tôi chọn ngẫu nhiên 100 bộ ba w.r.t mỗi quan hệ, dẫn đến 800 bộ ba ngẫu nhiên (vì chiến lược lọc được áp dụng trong quan hệ HinderedBy, chúng tôi chọn ngẫu nhiên 100 mẫu từ các bộ ba HinderedBy chưa được lọc và đã được lọc, tương ứng). Đối với ATOMIC-zh và CN-AutoMIC, chúng tôi chọn ngẫu nhiên 700 mẫu từ mỗi cái để tiến hành phân tích của con người. Theo Wang et al. (2022a), chúng tôi mời ba sinh viên sau đại học Trung Quốc đánh giá xem mỗi bộ ba tri thức thông thường có hợp lý hay không, và tính tỷ lệ trung bình của các bộ ba hợp lý cho mỗi CKG như sự chấp nhận của con người của nó.

Thống kê Tổng thể. Bảng 2 so sánh thống kê dữ liệu của Snowman và các CKG trước đó của chúng tôi. Chúng tôi thấy rằng quy mô của Snowman là lớn nhất trong tất cả các CKG, và chỉ có Snowman liên quan đến hơn 10 triệu bộ ba tri thức thông thường. Phát hiện này chỉ ra sự vượt trội của ChatGPT phục vụ như mô hình xương sống để chưng cất tri thức thông thường. Ngoài ra, sự chấp nhận của con người đối với Snowman thô đạt 86,8%, cao hơn so với các CKG chưa được lọc khác (78,5% của ATOMIC 10X thô và 47,6% của CN-AutoMIC thô). Với sự hỗ trợ của chiến lược lọc tự hướng dẫn, sự chấp nhận của con người

³https://hf.co/hfl/chinese-roberta-wwm-ext-large

--- TRANG 5 ---
| Đồ thị Tri thức Thông thường | Ngôn ngữ | Xây dựng | Mục Đầu Duy nhất | Mục Đuôi Duy nhất | Bộ ba | Chấp nhận của Con người |
|---|---|---|---|---|---|---|
| ATOMIC 2020 (Hwang et al., 2020) | Tiếng Anh | Crowdsourcing | 25,807 | 354,777 | 760,034 | 86.8* |
| ATOMIC 10X thô (West et al., 2021) | Tiếng Anh | Tạo sinh | 165,783 | 874,417 | 6,456,300 | 78.5* |
| ATOMIC 10X cao (West et al., 2021) | Tiếng Anh | Tạo sinh | 164,553 | 357,761 | 2,512,720 | 96.4* |
| ATOMIC-zh (Li et al., 2022) | Tiếng Trung | Dịch thuật | 20,949 | 276,446 | 712,970 | 41.9 (38.7†) |
| CN-AutoMIC thô (Wang et al., 2022a) | Tiếng Trung | Tạo sinh | 114,364 | 1,101,556 | 6,868,766 | 52.3 (47.6†) |
| CN-AutoMIC cao (Wang et al., 2022a) | Tiếng Trung | Tạo sinh | 89,738 | 182,893 | 1,140,840 | 89.5 (87.2†) |
| Snowman thô (Của chúng tôi) | Tiếng Trung | Tạo sinh | 185,075 | 5,783,395 | 11,087,873 | 86.8 |
| Snowman cao (Của chúng tôi) | Tiếng Trung | Tạo sinh | 185,075 | 5,426,778 | 10,463,219 | 90.6 |

Bảng 2: Thống kê dữ liệu của Snowman và các CKG trước đó. * và † biểu thị kết quả từ West et al. (2021) và Wang et al. (2022a), tương ứng.

| Quan hệ | Mục Đuôi Duy nhất | Bộ ba | Chấp nhận |
|---|---|---|---|
| xWant | 1,280,417 | 1,850,336 | 89.3 |
| xReact | 206,947 | 1,227,908 | 93.0 |
| xEffect | 1,136,804 | 1,850,490 | 95.7 |
| xAttr | 389,639 | 1,846,849 | 87.3 |
| xNeed | 1,408,147 | 1,846,947 | 86.3 |
| xIntent | 317,298 | 616,821 | 90.0 |
| HinderedBy (thô) | 1,168,014 | 1,848,522 | 65.7 |
| HinderedBy | 810,754 | 1,223,868 | 92.7 |

Bảng 3: Thống kê dữ liệu cấp quan hệ của Snowman.

của Snowman tiếp tục đạt 90,6%, mức chấp nhận cao nhất trong tất cả các CKG tiếng Trung, cho thấy hiệu quả của chiến lược này.

Thống kê Cấp Quan hệ. Bảng 3 hiển thị thống kê dữ liệu cấp quan hệ của Snowman. Chúng ta có thể thấy rằng sự chấp nhận thô của con người đối với quan hệ HinderedBy chỉ đạt 65,7%, thấp hơn đáng kể so với các quan hệ khác (thường hơn 85%). Sau khi lọc các bộ ba HinderedBy chất lượng thấp, sự chấp nhận cải thiện lên 92,7%, làm hài lòng các đánh giá viên con người.

4 Tạo sinh Tri thức Thông thường

4.1 Thiết lập Thí nghiệm

Để tiếp tục chứng minh tính khả dụng và hiệu quả của Snowman của chúng tôi, chúng tôi tiến hành các thí nghiệm về tạo sinh tri thức thông thường. Cụ thể, theo Wang et al. (2022a), chúng tôi huấn luyện mô hình COMET (Bosselut et al., 2019) (một mô hình tạo sinh tri thức thông thường được sử dụng rộng rãi) với xương sống của mT5-base (580M)⁴ (Xue et al., 2021) trên các bộ ba Snowman. Trong quá trình huấn luyện, chúng tôi đặt tốc độ học 1e-4, kích thước batch 128, và 2K bước khởi động. Tiếp theo, chúng tôi so sánh mô hình được huấn luyện với các mô hình COMET khác được huấn luyện trên các bộ ba ATOMIC-zh

⁴https://hf.co/google/mt5-base

| Mô hình | Chấp nhận |
|---|---|
| COMET (ATOMIC-zh) | 31.2% |
| COMET (CN-AutoMIC thô) | 47.8% |
| COMET (CN-AutoMIC cao) | 61.3% |
| COMET (Snowman thấp) | 77.5% |
| COMET (Snowman cao) | 81.8% |

Bảng 4: Hiệu suất của mô hình tri thức thông thường được huấn luyện trên các CKG khác nhau.

và các bộ ba CN-AutoMIC. Đối với mỗi CKG, chúng tôi chỉ chọn ngẫu nhiên 500K bộ ba để huấn luyện mô hình COMET để tránh tác động của các quy mô dữ liệu khác nhau. Tập kiểm tra dựa trên một tập held-out (500 mẫu) của ATOMIC-zh để so sánh công bằng. Chúng tôi đánh giá thủ công kết quả tạo sinh theo cách tương tự như Phần 3 (tức là sự chấp nhận của con người).

4.2 Kết quả & Thảo luận

Như được hiển thị trong Bảng 4, mô hình được huấn luyện trên Snowman cao đạt được sự chấp nhận tốt nhất của con người, cho thấy các bộ ba từ Snowman của chúng tôi có thể giúp mô hình tạo sinh suy luận tri thức thông thường tốt hơn. Phát hiện này cũng chứng minh chất lượng cao của CKG của chúng tôi và sự vượt trội của mô hình nền tảng ChatGPT. Điều chỉnh hướng dẫn và RLHF làm cho các mô hình nền tảng thông minh hơn, có lợi cho các tác vụ downstream khác nhau và làm cho việc xây dựng CKG chất lượng cao trở nên thuận tiện hơn.

So với CN-AutoMIC trước đó (được chưng cất từ mT5), chúng tôi cho thấy rằng mô hình nền tảng tiên tiến (ChatGPT) có thể chưng cất CKG tiếng Trung chất lượng cao hơn chỉ với một vài (cấp độ hàng trăm) hạt giống. Bên cạnh đó, giao thức xây dựng của Snowman ngắn gọn hơn so với CN-AutoMIC (bao gồm các bộ lọc cascaded và một số phương pháp khử nhiễu dựa trên quy tắc). Giao thức xây dựng cũng có thể được điều chỉnh một cách tầm thường cho ngôn ngữ khác, và thúc đẩy nghiên cứu về các

--- TRANG 6 ---
CKG ngôn ngữ thấp cũng như CKG đa ngôn ngữ.

5 Kết luận

Trong công trình này, chúng tôi chuyển giao thành công của các mô hình nền tảng vào việc xây dựng các đồ thị tri thức thông thường (CKG). Cụ thể, chúng tôi chưng cất ChatGPT để tạo ra các bộ ba tri thức thông thường tiếng Trung chỉ với một số lượng nhỏ các mục và bộ ba hạt giống. Để giải quyết vấn đề tri thức tiêu cực, chúng tôi thiết kế một chiến lược lọc tự hướng dẫn đơn giản nhưng hiệu quả để lọc bỏ các bộ ba tri thức tiêu cực chất lượng thấp. Cuối cùng, Snowman của chúng tôi liên quan đến hơn 10 triệu bộ ba tri thức tiếng Trung, làm cho nó trở thành CKG tiếng Trung lớn nhất. Đánh giá của con người cũng như các thí nghiệm tạo sinh tri thức thông thường cho thấy chất lượng cao của CKG được xây dựng.

Tài liệu Tham khảo

Prithviraj Ammanabrolu, Wesley Cheung, William Broniec, và Mark O. Riedl. 2021. Automated storytelling via causal, commonsense plot ordering. Proceedings of the AAAI Conference on Artificial Intelligence, 35(7):5859–5867.

Hiba Arnaout và Simon Razniewski. 2023. Can large language models generate salient negative statements? ArXiv, abs/2305.16755.

Stephen Barker và Mark Jago. 2012. Being positive about negative facts. Philosophy and Phenomenological research, pages 117–138.

Antoine Bosselut, Hannah Rashkin, Maarten Sap, Chaitanya Malaviya, Asli Celikyilmaz, và Yejin Choi. 2019. Comet: Commonsense transformers for automatic knowledge graph construction. In Annual Meeting of the Association for Computational Linguistics.

Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. 2020. Language models are few-shot learners. Advances in neural information processing systems, 33:1877–1901.

Sébastien Bubeck, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke, Eric Horvitz, Ece Kamar, Peter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lundberg, et al. 2023. Sparks of artificial general intelligence: Early experiments with gpt-4. arXiv preprint arXiv:2303.12712.

Jiangjie Chen, Wei Shi, Ziquan Fu, Sijie Cheng, Lei Li, và Yanghua Xiao. 2023. Say what you mean! large language models speak too positively about negative commonsense knowledge. ArXiv, abs/2305.05976.

Edward A Feigenbaum. 1984. Knowledge engineering. Annals of the New York Academy of Sciences, 426(1):91–107.

Md Mosharaf Hossain, Dhivya Chinnappa, và Eduardo Blanco. 2022. An analysis of negation in natural language understanding corpora. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 716–723, Dublin, Ireland. Association for Computational Linguistics.

Jena D. Hwang, Chandra Bhagavatula, Ronan Le Bras, Jeff Da, Keisuke Sakaguchi, Antoine Bosselut, và Yejin Choi. 2020. Comet-atomic 2020: On symbolic and neural commonsense knowledge graphs. In AAAI Conference on Artificial Intelligence.

Douglas B Lenat. 1995. Cyc: A large-scale investment in knowledge infrastructure. Communications of the ACM, 38(11):33–38.

Dawei Li, Yanran Li, Jiayi Zhang, Ke Li, Chen Wei, Jianwei Cui, và Bin Wang. 2022. C3KG: A Chinese commonsense conversation knowledge graph. In Findings of the Association for Computational Linguistics: ACL 2022, pages 1369–1383, Dublin, Ireland. Association for Computational Linguistics.

Yunlong Liang, Fandong Meng, Jiaan Wang, Jinan Xu, Yufeng Chen, và Jie Zhou. 2023. D2tv: Dual knowledge distillation and target-oriented vision modeling for many-to-many multimodal summarization. arXiv preprint arXiv:2305.12767.

Yunlong Liang, Fandong Meng, Jinan Xu, Jiaan Wang, Yufeng Chen, và Jie Zhou. 2022a. Summary-oriented vision modeling for multimodal abstractive summarization. arXiv preprint arXiv:2212.07672.

Yunlong Liang, Fandong Meng, Ying Zhang, Yufeng Chen, Jinan Xu, và Jie Zhou. 2021. Infusing multi-source knowledge with heterogeneous graph neural network for emotional conversation generation. Proceedings of AAAI, pages 13343–13352.

Yunlong Liang, Fandong Meng, Ying Zhang, Yufeng Chen, Jinan Xu, và Jie Zhou. 2022b. Emotional conversation generation with heterogeneous graph neural network. Artificial Intelligence, 308:103714.

Yunlong Liang, Fandong Meng, Chulun Zhou, Jinan Xu, Yufeng Chen, Jinsong Su, và Jie Zhou. 2022c. A variational hierarchical model for neural cross-lingual summarization. In ACL, pages 2088–2099.

Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, và Veselin Stoyanov. 2019. Roberta: A robustly optimized bert pretraining approach. ArXiv, abs/1907.11692.

George Molnar. 2000. Truthmakers for negative truths. Australasian Journal of philosophy, 78(1):72–86.

--- TRANG 7 ---
Nasrin Mostafazadeh, Aditya Kalyanpur, Lori Moon, David Buchanan, Lauren Berkowitz, Or Biran, và Jennifer Chu-Carroll. 2020. GLUCOSE: GeneraLized and COntextualized story explanations. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 4569–4586, Online. Association for Computational Linguistics.

Niklas Muennighoff, Thomas Wang, Lintang Sutawika, Adam Roberts, Stella Rose Biderman, Teven Le Scao, M Saiful Bari, Sheng Shen, Zheng Xin Yong, Hailey Schoelkopf, Xiangru Tang, Dragomir R. Radev, Alham Fikri Aji, Khalid Almubarak, Samuel Albanie, Zaid Alyafeai, Albert Webson, Edward Raff, và Colin Raffel. 2022. Crosslingual generalization through multitask finetuning. ArXiv, abs/2211.01786.

Tuan-Phong Nguyen, Simon Razniewski, và Gerhard Weikum. 2021. Advanced semantics for commonsense knowledge extraction. In Proceedings of the Web Conference 2021, WWW '21, page 2636–2647, New York, NY, USA. Association for Computing Machinery.

OpenAI. 2022. Introducing chatgpt. https://openai.com/blog/chatgpt.

OpenAI. 2023. Gpt-4 technical report. ArXiv, abs/2303.08774.

Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, và Peter J Liu. 2020. Exploring the limits of transfer learning with a unified text-to-text transformer. The Journal of Machine Learning Research, 21(1):5485–5551.

Julien Romero, Simon Razniewski, Koninika Pal, Jeff Z. Pan, Archit Sakhadeo, và Gerhard Weikum. 2019. Commonsense properties from query logs and question answering forums. In Proceedings of the 28th ACM International Conference on Information and Knowledge Management, CIKM '19, page 1411–1420, New York, NY, USA. Association for Computing Machinery.

Maarten Sap, Ronan Le Bras, Emily Allaway, Chandra Bhagavatula, Nicholas Lourie, Hannah Rashkin, Brendan Roof, Noah A. Smith, và Yejin Choi. 2019. Atomic: An atlas of machine commonsense for if-then reasoning. Proceedings of the AAAI Conference on Artificial Intelligence, 33(01):3027–3035.

John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, và Oleg Klimov. 2017. Proximal policy optimization algorithms. ArXiv, abs/1707.06347.

Robyn Speer, Joshua Chin, và Catherine Havasi. 2017. Conceptnet 5.5: An open multilingual graph of general knowledge. In Proceedings of the AAAI conference on artificial intelligence, volume 31.

Nisan Stiennon, Long Ouyang, Jeffrey Wu, Daniel Ziegler, Ryan Lowe, Chelsea Voss, Alec Radford, Dario Amodei, và Paul F Christiano. 2020. Learning to summarize with human feedback. Advances in Neural Information Processing Systems, 33:3008–3021.

Niket Tandon, Gerard de Melo, Fabian Suchanek, và Gerhard Weikum. 2014. Webchild: Harvesting and organizing commonsense knowledge from the web. In Proceedings of the 7th ACM International Conference on Web Search and Data Mining, WSDM '14, page 523–532, New York, NY, USA. Association for Computing Machinery.

Zhixing Tian, Yuanzhe Zhang, Kang Liu, Jun Zhao, Yantao Jia, và Zhicheng Sheng. 2020. Scene restoring for narrative machine reading comprehension. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 3063–3073, Online. Association for Computational Linguistics.

Chenhao Wang, Jiachun Li, Yubo Chen, Kang Liu, và Jun Zhao. 2022a. CN-AutoMIC: Distilling Chinese commonsense knowledge from pretrained language models. In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pages 9253–9265, Abu Dhabi, United Arab Emirates. Association for Computational Linguistics.

Jiaan Wang, Zhixu Li, Tingyi Zhang, Duo Zheng, Jianfeng Qu, An Liu, Lei Zhao, và Zhigang Chen. 2022b. Knowledge enhanced sports game summarization. In Proceedings of the Fifteenth ACM International Conference on Web Search and Data Mining, WSDM '22, page 1045–1053, New York, NY, USA. Association for Computing Machinery.

Jiaan Wang, Yunlong Liang, Fandong Meng, Zhixu Li, Jianfeng Qu, và Jie Zhou. 2023a. Cross-lingual summarization via chatgpt. ArXiv, abs/2302.14229.

Jiaan Wang, Yunlong Liang, Fandong Meng, Haoxiang Shi, Zhixu Li, Jinan Xu, Jianfeng Qu, và Jie Zhou. 2023b. Is chatgpt a good nlg evaluator? a preliminary study. ArXiv, abs/2303.04048.

Jiaan Wang, Fandong Meng, Ziyao Lu, Duo Zheng, Zhixu Li, Jianfeng Qu, và Jie Zhou. 2022c. ClidSum: A benchmark dataset for cross-lingual dialogue summarization. In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pages 7716–7729, Abu Dhabi, United Arab Emirates. Association for Computational Linguistics.

Jiaan Wang, Fandong Meng, Tingyi Zhang, Yunlong Liang, Jiarong Xu, Zhixu Li, và Jie Zhou. 2022d. Understanding translationese in cross-lingual summarization. ArXiv, abs/2212.07220.

Jiaan Wang, Fandong Meng, Duo Zheng, Yunlong Liang, Zhixu Li, Jianfeng Qu, và Jie Zhou. 2022e. A Survey on Cross-Lingual Summarization. Transactions of the Association for Computational Linguistics, 10:1304–1323.

--- TRANG 8 ---
Jiaan Wang, Fandong Meng, Duo Zheng, Yunlong Liang, Zhixu Li, Jianfeng Qu, và Jie Zhou. 2023c. Towards unifying multi-lingual and cross-lingual summarization. ArXiv, abs/2305.09220.

Jiaan Wang, Beiqi Zou, Zhixu Li, Jianfeng Qu, Pengpeng Zhao, An Liu, và Lei Zhao. 2022f. Incorporating commonsense knowledge into story ending generation via heterogeneous graph networks. In International Conference on Database Systems for Advanced Applications.

Jason Wei, Maarten Bosma, Vincent Y Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du, Andrew M Dai, và Quoc V Le. 2021. Finetuned language models are zero-shot learners. arXiv preprint arXiv:2109.01652.

Peter West, Chandra Bhagavatula, Jack Hessel, Jena D Hwang, Liwei Jiang, Ronan Le Bras, Ximing Lu, Sean Welleck, và Yejin Choi. 2021. Symbolic knowledge distillation: from general language models to commonsense models. arXiv preprint arXiv:2110.07178.

Linting Xue, Noah Constant, Adam Roberts, Mihir Kale, Rami Al-Rfou, Aditya Siddhant, Aditya Barua, và Colin Raffel. 2021. mT5: A massively multilingual pre-trained text-to-text transformer. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 483–498, Online. Association for Computational Linguistics.

Xinyan Yu, Trina Chatterjee, Akari Asai, Junjie Hu, và Eunsol Choi. 2022. Beyond counting datasets: A survey of multilingual dataset construction and necessary resources. In Findings of the Association for Computational Linguistics: EMNLP 2022, pages 3725–3743, Abu Dhabi, United Arab Emirates. Association for Computational Linguistics.

Hongming Zhang, Daniel Khashabi, Yangqiu Song, và Dan Roth. 2020. Transomcs: From linguistic graphs to commonsense knowledge. In Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence, IJCAI-20, pages 4004–4010. International Joint Conferences on Artificial Intelligence Organization. Main track.

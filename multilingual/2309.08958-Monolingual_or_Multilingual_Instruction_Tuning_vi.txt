# Tinh chỉnh hướng dẫn đơn ngữ hay đa ngữ:
Cái nào tạo ra Alpaca tốt hơn
Pinzhen Chen1,*Shaoxiong Ji2,*Nikolay Bogoychev1
Andrey Kutuzov3Barry Haddow1Kenneth Heafield1
1Đại học Edinburgh2Đại học Helsinki3Đại học Oslo
pchen3@ed.ac.uk shaoxiong.ji@helsinki.fi
Tóm tắt
Các mô hình ngôn ngữ lớn nền tảng (LLMs) có thể được tinh chỉnh hướng dẫn để thực hiện trả lời câu hỏi mở, tạo điều kiện cho các ứng dụng như trợ lý trò chuyện. Mặc dù những nỗ lực như vậy thường được thực hiện bằng một ngôn ngữ duy nhất, chúng tôi phân tích thực nghiệm các chiến lược hiệu quả chi phí cho các tình huống đa ngữ. Nghiên cứu của chúng tôi sử dụng tập dữ liệu Alpaca và bản dịch máy của nó để tạo thành dữ liệu đa ngữ, sau đó được sử dụng để tinh chỉnh LLMs thông qua hoặc thích ứng thứ hạng thấp hoặc huấn luyện toàn bộ tham số. Dưới ngân sách tính toán được kiểm soát, các so sánh cho thấy tinh chỉnh đa ngữ ngang bằng hoặc tốt hơn tinh chỉnh một mô hình cho mỗi ngôn ngữ. Hơn nữa, tinh chỉnh đa ngữ với dữ liệu được lấy mẫu xuống có thể mạnh mẽ và vững chắc hơn. Những phát hiện của chúng tôi đóng vai trò hướng dẫn để mở rộng hỗ trợ ngôn ngữ thông qua tinh chỉnh hướng dẫn.

1 Giới thiệu
Khả năng ngôn ngữ đã thu hút nhiều sự chú ý trong các mô hình ngôn ngữ được huấn luyện trước. Một số công trình tiên phong tập trung vào một ngôn ngữ duy nhất (Peters et al., 2018; Devlin et al., 2019), trong khi các công trình sau này nhằm bao phủ nhiều ngôn ngữ (Conneau et al., 2020; Liu et al., 2020). Trong sự phát triển gần đây của LLMs mã nguồn mở, những mô hình lấy tiếng Anh làm trung tâm bao gồm GPT-2, LLaMA, và Pythia (Radford et al., 2019; Touvron et al., 2023; Biderman et al., 2023), và những mô hình đa ngữ được đại diện bởi BLOOM (Scao et al., 2022). Các mô hình đa ngữ có vẻ hấp dẫn khi xem xét chi phí vận hành, chuyển giao đa ngữ, và các ngôn ngữ ít tài nguyên (Artetxe và Schwenk, 2019; Wu và Dredze, 2020), tuy nhiên các mô hình lấy tiếng Anh làm trung tâm có thể sở hữu khả năng chuyển giao đa ngữ tốt (Ye et al., 2023).

Tinh chỉnh hướng dẫn làm cho LLMs tuân theo và phản hồi các đầu vào (Sanh et al., 2022; Wei et al., 2022). Với dữ liệu hướng dẫn đa ngữ trở nên khả thi và có sẵn, bài báo này so sánh tinh chỉnh hướng dẫn đơn ngữ và đa ngữ áp dụng cho LLMs lấy tiếng Anh làm trung tâm và đa ngữ để tìm kiếm chiến lược tối ưu nhằm hỗ trợ nhiều ngôn ngữ. Không giống như các công trình trước đây về tinh chỉnh đa nhiệm vụ NLP đa ngữ (Mishra et al., 2022; Muennighoff et al., 2023), chúng tôi tập trung vào trả lời câu hỏi mở dưới việc sinh ngôn ngữ.

Thiết lập dữ liệu của chúng tôi kết hợp hai thực hành chi phí thấp: tự hướng dẫn, cái mà chưng cất dữ liệu từ một LLM mạnh mẽ (Wang et al., 2023; Taori et al., 2023) và ý tưởng tận dụng dịch máy để tạo tập dữ liệu đa ngữ (Muennighoff et al., 2023). Chúng tôi tinh chỉnh một số LLMs decoder với hoặc tinh chỉnh toàn bộ tham số (FFT) hoặc thích ứng thứ hạng thấp (LoRA, Hu et al., 2022) với các kết hợp ngôn ngữ khác nhau. Các thí nghiệm của chúng tôi có ngân sách tính toán cố định để cung cấp thông tin chi tiết thực tế. Nó được chỉ ra rằng tinh chỉnh đa ngữ được ưu tiên hơn tinh chỉnh đơn ngữ cho mỗi ngôn ngữ dưới LoRA, nhưng kết quả trộn lẫn dưới FFT. LLMs được tinh chỉnh tiếng Anh không thành thạo trong việc phản hồi bằng các ngôn ngữ khác, trong khi sơ đồ tinh chỉnh đa ngữ lấy mẫu xuống được đề xuất bởi chúng tôi vững chắc hơn. Cuối cùng, chúng tôi kiểm tra hiệu suất mô hình của mình trên các ngôn ngữ chưa thấy và các LLMs khác nhau có kích thước tương đương.

2 Phương pháp
2.1 Dữ liệu hướng dẫn
Chúng tôi sử dụng tập dữ liệu Alpaca như một hạt giống để tạo ra một tập dữ liệu hướng dẫn-phản hồi đa ngữ. Chúng tôi đã sử dụng phiên bản đã làm sạch với 52K trường hợp và dịch máy nó thành tám ngôn ngữ: Bulgaria, Séc, Trung Quốc, Đức, Phần Lan, Pháp, Nga, và Tây Ban Nha, sử dụng các hệ thống dịch thuật mã nguồn mở.

2.2 Tinh chỉnh hướng dẫn được kiểm soát ngân sách
Đối với tinh chỉnh đơn ngữ, chúng tôi tinh chỉnh LLMs cho mỗi ngôn ngữ riêng biệt, trong khi đối với tinh chỉnh đa ngữ, chúng tôi hợp nhất và xáo trộn dữ liệu trong tất cả các ngôn ngữ. Điều này cho phép so sánh được kiểm soát tài nguyên giữa tinh chỉnh đơn ngữ và đa ngữ, nơi một ngân sách tính toán cố định (và bằng nhau cho mỗi ngôn ngữ) được phân bổ để hỗ trợ tất cả các ngôn ngữ quan tâm. Việc sử dụng tài nguyên thí nghiệm được mô tả như sau:

1) Gọi CAlpaca biểu thị chi phí tinh chỉnh Alpaca đơn ngữ cho một ngôn ngữ duy nhất, thì nó tốn N×CAlpaca để tinh chỉnh các mô hình riêng lẻ nhằm hỗ trợ N ngôn ngữ.

2) Tinh chỉnh hướng dẫn đa ngữ cũng sẽ tốn N×CAlpaca, vì nó huấn luyện trên dữ liệu có sẵn trong tất cả N ngôn ngữ trong một lần.

Chúng tôi có thể so sánh công bằng LLMs được huấn luyện qua 1) và 2) cho bất kỳ ngôn ngữ nào. Ngoài ra, chúng tôi đề xuất điểm chuẩn hai tùy chọn tiết kiệm ngân sách có cùng chi phí CAlpaca như một Alpaca đơn ngữ:

3) Như một đường cơ sở đơn giản, chúng tôi sử dụng mô hình được tinh chỉnh tiếng Anh để phản hồi tất cả các ngôn ngữ.

4) Đa ngữ lấy mẫu xuống: chúng tôi lấy mẫu ngẫu nhiên từ dữ liệu đa ngữ trong 2) để có kích thước của một tập dữ liệu đơn ngữ.

Nghiên cứu của chúng tôi bao gồm hai mô hình huấn luyện: thích ứng thứ hạng thấp và tinh chỉnh toàn bộ tham số. Cả hai đều tinh chỉnh một LLM với mục tiêu mô hình hóa ngôn ngữ nhân quả trên dữ liệu hướng dẫn-phản hồi, với các siêu tham số được liệt kê trong Phụ lục A.1. Năm LLMs được liên quan: Baichuan-2, BLOOM, LLaMA, OpenLLaMA, và Pythia, nhằm kiểm tra với phạm vi ngôn ngữ khác nhau trong các LLMs cơ sở. Pythia, LLaMA, và OpenLLaMA chủ yếu là tiếng Anh, trong khi Baichuan-2 và BLOOM linh hoạt hơn. Mô tả chi tiết về các LLMs có trong Phụ lục A.2.

2.3 Thiết lập đánh giá
Dữ liệu kiểm tra Các LLMs được tinh chỉnh hướng dẫn của chúng tôi được điểm chuẩn trên các ngôn ngữ cả đã thấy và chưa thấy trong quá trình tinh chỉnh. Chúng tôi thuê người nói bản ngữ để dịch thủ công 50 lời nhắc được lấy mẫu từ OpenAssistant (Köpf et al., 2023) thành tám ngôn ngữ: sáu đã thấy trong huấn luyện và hai chưa thấy. Danh mục đã thấy bao gồm tiếng Anh, Pháp, Tây Ban Nha, Bulgaria, Nga, và Trung Quốc. Trong số sáu ngôn ngữ, tiếng Anh có tài nguyên cao nhất, tiếp theo là tiếng Pháp và Tây Ban Nha có cùng hệ thống chữ viết với tiếng Anh. Tiếng Bulgaria và Nga là các ngôn ngữ châu Âu nhưng sử dụng hệ thống chữ viết khác biệt với tiếng Anh. Cuối cùng, tiếng Trung Quốc là một ngôn ngữ xa xôi có tài nguyên cao trong một hệ thống chữ viết khác. Đối với các bài kiểm tra chưa thấy, chúng tôi chọn tiếng Bengal và Na Uy. Tiếng Bengal xa xôi với các ngôn ngữ trên và sử dụng hệ thống chữ viết khác, trong khi tiếng Na Uy ít tài nguyên nhưng trùng lặp với hệ thống chữ viết tiếng Anh ở một mức độ nào đó.

LLM-như-thẩm-phán Để tránh chi phí đánh giá đắt đỏ, chúng tôi áp dụng LLM-như-thẩm-phán (Zheng et al., 2023) để gán một điểm số (1 đến 3) cho mỗi cặp hướng dẫn-phản hồi, và điểm số mô hình cuối cùng là tổng điểm số của nó trên tất cả các trường hợp kiểm tra. Chúng tôi sử dụng GPT-3.5 (gpt-3.5-turbo-0613) làm thẩm phán; nó được truy vấn với một cặp hướng dẫn-phản hồi mỗi lần mà không có thông tin mô hình hoặc lịch sử yêu cầu. Chúng tôi thực hiện các sửa đổi đối với lời nhắc của Zheng et al. (2023) để yêu cầu LLM xem xét rằng câu trả lời nên cùng ngôn ngữ với câu hỏi, điều này thường là kỳ vọng với trợ lý AI. Cách diễn đạt chính xác như trong Phụ lục B.1 Hình 6.

Tính (không) nhất quán ngôn ngữ Kiểm tra thủ công của chúng tôi gợi ý rằng GPT-3.5 không phải lúc nào cũng tuân theo yêu cầu ngôn ngữ được áp đặt. Một ví dụ trong Phụ lục B.2 Bảng 2 cho thấy một phản hồi bằng ngôn ngữ khác nhưng được chấm điểm cao. Do đó, chúng tôi chạy nhận dạng ngôn ngữ và buộc đặt điểm số thành 0 nếu ngôn ngữ phản hồi khác với truy vấn. Chúng tôi sử dụng khung fastText (Joulin et al., 2017) với điểm kiểm tra của Burchell et al. (2023). Điểm số phản hồi cuối cùng có thể được đóng khung như một tích của điểm số chất lượng GPT và kết quả nhận dạng ngôn ngữ nhị phân: điểm_số=điểm_đánh_giá×nhận_dạng_ngôn_ngữ. Điểm số kiểm tra tổng hợp do đó dao động từ 0 đến 150.

Sự đồng thuận Người-LLM Chúng tôi chọn 600 đầu ra từ 12 mô hình để bao gồm các hệ thống đa ngữ và đơn ngữ và mời các đánh giá viên con người chấm điểm mỗi mẫu với một hướng dẫn tương tự như lời nhắc LLM-như-thẩm-phán như trong Phụ lục B.3. Bốn ngôn ngữ—tiếng Anh, Tây Ban Nha, Bulgaria, và Trung Quốc—được đánh giá bởi con người, và chúng tôi thu được các hệ số tương quan Pearson cấp độ hệ thống rất cao là 0.9225, 0.9683, 0.9205, và 0.8685, tương ứng giữa GPT-3.5 và con người. Chi tiết có trong Bảng 3 trong phụ lục. Điều này chỉ ra độ tin cậy của việc sử dụng LLM-như-thẩm-phán để rút ra những phát hiện có ý nghĩa.

3 Hiệu suất và Thảo luận
3.1 Kích thước mô hình
Kết quả từ tinh chỉnh LoRA của BLOOM ở các kích thước khác nhau được hiển thị trong Hình 1. Ở kích thước nhỏ hơn, tinh chỉnh hướng dẫn đa ngữ và đơn ngữ đạt hiệu suất tương tự, và ở kích thước lớn hơn, các mô hình đa ngữ thường tốt hơn trừ tiếng Anh. Chúng tôi quan sát xu hướng tương tự đối với Pythia, được đặt trong Phụ lục C.1 Hình 8 do hạn chế không gian. Chuyển sang tinh chỉnh toàn bộ tham số của BLOOM trong Hình 2, chúng tôi khám phá rằng ở kích thước tương đối nhỏ (<1.7B) hoặc lớn (7B), các mô hình đơn ngữ thường tốt hơn các mô hình đa ngữ đối với các ngôn ngữ riêng lẻ. Những quan sát này gợi ý rằng đa ngữ hoạt động tốt với LoRA, nhưng tinh chỉnh đơn ngữ riêng biệt có thể tốt hơn với FFT. Nhìn chung, hiệu suất của LLMs tương quan với kích thước bất kể kỹ thuật tinh chỉnh như dự đoán.

3.2 Tinh chỉnh hiệu quả ngân sách
Để hỗ trợ khám phá tinh chỉnh hướng dẫn bị hạn chế tài nguyên, trong các Hình 1, 2, và 8 đã đề cập trước đây (trong phụ lục C.1), chúng tôi thêm các biểu đồ của hai điều kiện dữ liệu ngân sách: sử dụng các mô hình được tinh chỉnh tiếng Anh để phản hồi các hướng dẫn bằng ngôn ngữ khác, cũng như tinh chỉnh hướng dẫn với dữ liệu đa ngữ được lấy mẫu xuống.

Khi sử dụng một mô hình tiếng Anh duy nhất cho tất cả các ngôn ngữ, hiệu quả của nó phụ thuộc vào độ gần của ngôn ngữ/hệ thống chữ viết dự định với tiếng Anh: tiếng Tây Ban Nha và Pháp có thể duy trì điểm số hợp lý, nhưng tiếng Bulgaria, Nga, và Trung Quốc ghi nhận hiệu suất rất thấp. Ngoại lệ duy nhất là BLOOM FFT trong Hình 2, nơi mô hình không quá tụt lại khi hoạt động bằng tiếng Trung Quốc. Thú vị là, BLOOM với LoRA thấy một đỉnh hiệu suất tại 1.1B đối với ngôn ngữ không phải tiếng Anh. Ở kích thước cụ thể này, nó thể hiện khả năng chuyển giao đa ngữ từ huấn luyện trước và học được tuân theo các hướng dẫn đa ngữ mặc dù chỉ được tinh chỉnh bằng tiếng Anh.

Ngược lại, trong khi tiêu thụ cùng tài nguyên tính toán, tinh chỉnh đa ngữ được lấy mẫu xuống vững chắc hơn đáng kể trên tất cả các ngôn ngữ kiểm tra. Những mô hình này đôi khi đạt hiệu suất ngang bằng với tinh chỉnh đơn ngữ trong các ngôn ngữ riêng lẻ. Điều này có nghĩa là để hỗ trợ một số ngôn ngữ với tài nguyên hạn chế, thực hành tốt nhất là huấn luyện trên dữ liệu đa ngữ nhỏ thậm chí được tạo ra bằng dịch máy thay vì dữ liệu tiếng Anh đầy đủ. Tuy nhiên, nếu ngân sách cho phép, huấn luyện với dữ liệu đa ngữ đầy đủ vẫn tốt hơn một chút.

3.3 Ngôn ngữ chưa thấy
Tiếp theo trong Hình 3, chúng tôi nhìn vào các mô hình BLOOM đã trải qua LoRA hoặc FFT nhưng sau đó được hướng dẫn bằng các ngôn ngữ chưa thấy tại thời điểm kiểm tra. LLMs được tinh chỉnh tiếng Anh hành xử khác biệt với LoRA và FFT. Với cái trước, chúng không đâu gần với các mô hình được tinh chỉnh đa ngữ, nhưng với cái sau, chúng tôi thấy kết quả gần hoặc thậm chí tốt hơn. Nó có thể ngụ ý rằng FFT thậm chí có thể nâng cao hiệu suất cho các ngôn ngữ không có trong dữ liệu hướng dẫn. Tuy nhiên, kết quả FFT trên tiếng Na Uy có thể là một ngoại lệ cho thấy điểm số thấp so sánh. Xem xét tinh chỉnh hướng dẫn đa ngữ, chúng tôi nhận thấy một mô hình đối lập với mô hình trên các ngôn ngữ được thấy trong huấn luyện—học trên dữ liệu được lấy mẫu xuống vượt trội so với việc tiêu thụ dữ liệu hỗn hợp đầy đủ. Chúng tôi kết luận rằng điều quan trọng là không quá khớp với các ngôn ngữ hướng dẫn nếu các ngôn ngữ chưa thấy được mong đợi trong các nhiệm vụ hạ lưu.

3.4 Độ vững chắc ngôn ngữ
Chúng tôi xem xét điểm số của mỗi mô hình và công thức dữ liệu trước và sau khi thêm nhận dạng ngôn ngữ, để cô lập độ vững chắc ngôn ngữ của LLM khỏi "chất lượng vốn có" của nó (bất kể ngôn ngữ phản hồi). Chúng tôi tính toán sự khác biệt trong điểm số đánh giá GPT trước và sau khi áp dụng nhận dạng ngôn ngữ. Một sự khác biệt (lớn) gợi ý rằng một mô hình tạo ra câu trả lời hợp lý trong một ngôn ngữ không mong muốn. Trong Hình 4, chúng tôi báo cáo trung bình của sự khác biệt điểm số trên tất cả sáu ngôn ngữ kiểm tra được thấy trong huấn luyện. Các mô hình chỉ tiếng Anh ít vững chắc nhất—sự khác biệt điểm số của chúng cao hơn nhiều so với các kỹ thuật khác. Với LoRA, tinh chỉnh đa ngữ đầy đủ ghi nhận sự giảm hiệu suất nhỏ nhất; với FFT, tinh chỉnh đơn ngữ được ưu tiên. Những thông tin chi tiết từ độ vững chắc ngôn ngữ được củng cố bởi các phát hiện ban đầu của chúng tôi trong Phần 3.1: kết quả vượt trội được thu được khi sử dụng tinh chỉnh đa ngữ với LoRA và tinh chỉnh đơn ngữ với tinh chỉnh toàn bộ tham số. Tuy nhiên, tinh chỉnh đơn ngữ và đa ngữ không quá xa nhau; cụ thể đối với BLOOM với LoRA, độ vững chắc ngôn ngữ không cải thiện khi mô hình trở nên lớn hơn.

3.5 Họ mô hình
Cuối cùng, chúng tôi thí nghiệm với các LLMs cơ sở từ các họ khác nhau khoảng 7 tỷ tham số. Trong Hình 5, chúng tôi vẽ các điểm số đánh giá cho tinh chỉnh LoRA đa ngữ, đa ngữ được lấy mẫu xuống, và đơn ngữ cho sáu ngôn ngữ. Nói chung, LLaMA và OpenLLaMA có hiệu suất tốt hơn BLOOM và Pythia có khả năng vì chúng có dữ liệu huấn luyện trước lớn hơn một bậc. Ngoài ra, tiếng Bulgaria, Nga, và Trung Quốc thấy điểm số thấp hơn tiếng Anh, một lần nữa có thể do phân phối ngôn ngữ trong dữ liệu huấn luyện trước.

Đi sâu vào so sánh giữa tinh chỉnh hướng dẫn đơn ngữ và đa ngữ, chúng tôi thấy rằng trong 30 trường hợp trên sáu ngôn ngữ và năm LLMs, tinh chỉnh đơn ngữ dẫn đầu chỉ trong hai trường hợp: LLaMA được kiểm tra bằng tiếng Nga và Trung Quốc. Tinh chỉnh đa ngữ được lấy mẫu xuống hiệu quả chi phí dẫn đầu trong bốn trường hợp: hai bằng tiếng Pháp và hai bằng tiếng Nga. Trong các tình huống khác, huấn luyện đa ngữ ngang bằng nếu không tốt hơn. Kết quả tinh chỉnh một số LLMs có kích thước tương tự xác nhận rằng tinh chỉnh đa ngữ thuận lợi khi sử dụng LoRA.

4 Công trình liên quan
Nhiều mô hình ngôn ngữ lớn xuất hiện gần đây: họ mô hình GPT nguồn đóng (Radford et al., 2019; Brown et al., 2020; Ouyang et al., 2022); các mô hình mã nguồn mở lấy tiếng Anh làm trung tâm như LLaMA (Touvron et al., 2023), OpenLLaMA (Geng và Liu, 2023), và Pythia (Biderman et al., 2023); các mô hình đa ngữ mã nguồn mở như mT5 (Xue et al., 2021) và BLOOM (Scao et al., 2022). Những mô hình này đã thể hiện các mức độ linh hoạt ngôn ngữ khác nhau.

Dữ liệu huấn luyện trước LLM thường thiên về tiếng Anh. Một cách để cải thiện phạm vi bao phủ của LLM đối với các ngôn ngữ không phải tiếng Anh là thông qua tiếp tục huấn luyện trước (Cui et al., 2023, giữa những người khác). Một thân văn học phong phú khác xem xét đa ngữ trong tinh chỉnh hướng dẫn, được sử dụng để điều chỉnh các mô hình cơ sở để phản hồi đầu vào (Mishra et al., 2022; Sanh et al., 2022; Wei et al., 2022; Longpre et al., 2023). Nó huấn luyện một LLM bằng cách cung cấp đầu vào và đầu ra của các nhiệm vụ hạ lưu trong một định dạng cụ thể. Nghiên cứu sớm tạo ra một tập dữ liệu hướng dẫn đa ngữ sử dụng dịch máy và cho thấy rằng tinh chỉnh đa ngữ đạt hiệu suất cao hơn tinh chỉnh chỉ tiếng Anh (Muennighoff et al., 2023). Họ cũng thấy rằng các hướng dẫn được dịch chi phí thấp vượt trội so với các lời nhắc không phải tiếng Anh được viết bởi con người về nhiều nhiệm vụ hiểu ngôn ngữ.

Gần đây, nhiều bài báo đồng thời đi sâu vào tinh chỉnh hướng dẫn đa ngữ đã được công bố trên arXiv—một số xuất hiện trước công trình của chúng tôi và một số sau. Điều này phản ánh tầm quan trọng và sự quan tâm trong việc mở rộng hỗ trợ ngôn ngữ của LLMs. Li et al. (2023a) tạo ra một tập dữ liệu hướng dẫn với các hướng dẫn được dịch từ tiếng Anh nhưng phản hồi được tạo ra bởi một LLM. Khi được tinh chỉnh với LoRA, các mô hình đơn ngữ của họ vượt trội so với các mô hình đa ngữ về các nhiệm vụ hiểu ngôn ngữ. Wei et al. (2023) tạo ra một đối tác đa ngữ của Alpaca sử dụng tự hướng dẫn. Nó cũng đã được thể hiện rằng các hướng dẫn dịch thuật cải thiện khả năng đa ngữ (Li et al., 2023b; Zhang et al., 2023; Ranaldi et al., 2023) và nghiên cứu khám phá thêm dữ liệu nhiệm vụ đa ngữ và tinh chỉnh đa ngữ (Zhu et al., 2023). Hơn nữa, các nhà nghiên cứu đã tiết lộ rằng tinh chỉnh trên một số lượng khiêm tốn các ngôn ngữ—khoảng ba—dường như hiệu quả khích động chuyển giao đa ngữ trong các nhiệm vụ hạ lưu (Kew et al., 2023; Shaham et al., 2024).

5 Kết luận
Bài báo này trình bày một nghiên cứu về tinh chỉnh hướng dẫn của các mô hình ngôn ngữ lớn trong các bối cảnh ngôn ngữ khác nhau. Nghiên cứu của chúng tôi trong một thiết lập được kiểm soát tài nguyên gợi ý rằng tinh chỉnh đa ngữ mang lại nhiều lợi ích hơn so với tinh chỉnh đơn ngữ. Chúng tôi thấy rằng tinh chỉnh đa ngữ trên một tập dữ liệu được lấy mẫu xuống đạt được độ vững chắc tốt hơn trên các ngôn ngữ chưa thấy.

Hạn chế
Các LLMs mà chúng tôi nghiên cứu chủ yếu có 7B và nhiều nhất 13B tham số và việc huấn luyện đa ngữ chỉ trải dài chín ngôn ngữ. Mở rộng quy mô lên các mô hình lớn hơn và nhiều ngôn ngữ hơn sẽ thú vị. Điểm kiểm tra tốt nhất cho tinh chỉnh hướng dẫn của chúng tôi được chọn dựa trên entropy chéo xác thực, nhưng không có bảo đảm rằng điều này dẫn đến hiệu suất tốt nhất trên nhiệm vụ hạ lưu.

Để quản lý ngân sách cho dịch thuật và đánh giá con người, chúng tôi xem xét tám ngôn ngữ (sáu ngôn ngữ đã thấy và hai ngôn ngữ chưa thấy trong tinh chỉnh hướng dẫn) để dịch và lấy mẫu 50 trường hợp để đánh giá. Dữ liệu huấn luyện cho các ngôn ngữ không phải tiếng Anh được thu thập qua dịch máy, điều này đưa ra lỗi, ảnh hưởng đến độ trôi chảy phản hồi, và có thể thay đổi bản chất của một số nhiệm vụ như sửa lỗi ngữ pháp và tạo mã.

Tuyên bố Đạo đức
Tập dữ liệu mà chúng tôi dịch và tạo ra không chứa thông tin riêng tư hoặc nhạy cảm. Tương tự như nghiên cứu khác về các mô hình ngôn ngữ lớn, không có cách nào chắc chắn để chúng tôi ngăn chặn các mô hình được tinh chỉnh hướng dẫn tạo ra nội dung không phù hợp. Tuy nhiên, chúng tôi thấy rủi ro tối thiểu như vậy liên quan đến dự án của chúng tôi, vì cả mô hình của chúng tôi và nội dung được tạo ra đều không dành cho tiêu dùng công cộng. Các đánh giá viên con người không báo cáo nội dung không phù hợp được tạo ra bởi các mô hình.

Lời cảm ơn
Bài báo này bắt nguồn từ một dự án hackathon được tổ chức bởi liên minh Công nghệ Ngôn ngữ Hiệu suất Cao (HPLT). Chúng tôi biết ơn Alicia Núñez Alcover, David Samuel, Joona Kytöniemi, Jörg Tiedemann, Lucas Charpentier, Sampo Pyysalo, Petter Mæhlum, và Zhicheng Guo cho các thảo luận dự án, dịch dữ liệu kiểm tra, và thiết lập đánh giá.

Công trình đã nhận được tài trợ từ chương trình nghiên cứu và đổi mới Horizon Europe của Liên minh Châu Âu dưới thỏa thuận cấp phép số 101070350, từ UK Research and Innovation (UKRI) dưới bảo đảm tài trợ Horizon Europe của chính phủ Anh [số cấp phép 10052546], cũng như từ Hội đồng Nghiên cứu Châu Âu (ERC) dưới chương trình nghiên cứu và đổi mới Horizon 2020 của EU (thỏa thuận số 771113).

Tính toán trong công trình này được thực hiện trên LUMI, Karolina, và Baskerville. Chúng tôi cảm ơn Trung tâm CSC-IT cho Khoa học, Phần Lan vì đã cấp cho dự án này quyền truy cập vào siêu máy tính LUMI, thuộc sở hữu của Liên minh Chung EuroHPC, được lưu trữ bởi CSC (Phần Lan) và liên minh LUMI thông qua cuộc gọi quy mô cực đại của Phần Lan (dự án LumiNMT). Karolina được hỗ trợ bởi Bộ Giáo dục, Thanh niên và Thể thao của Cộng hòa Séc thông qua e-INFRA CZ (ID:90254). Baskerville Tier 2 HPC được tài trợ bởi EPSRC và UKRI thông qua kế hoạch World Class Labs (EP/T022221/1) và chương trình Cơ sở hạ tầng Nghiên cứu Số (EP/W032244/1) và được vận hành bởi Tính toán Nghiên cứu Tiên tiến tại Đại học Birmingham.

Tài liệu tham khảo
Mikel Artetxe và Holger Schwenk. 2019. Nhúng câu đa ngữ quy mô lớn để chuyển giao không bắn đa ngữ và hơn thế. Giao dịch của Hiệp hội Ngôn ngữ học Tính toán, 7:597–610.

Stella Biderman, Hailey Schoelkopf, Quentin Gregory Anthony, Herbie Bradley, Kyle O'Brien, Eric Hallahan, Mohammad Aflah Khan, Shivanshu Purohit, USVSN Sai Prashanth, Edward Raff, và cộng sự. 2023. Pythia: Một bộ để phân tích các mô hình ngôn ngữ lớn trong huấn luyện và mở rộng quy mô. Trong Hội nghị Quốc tế về Học máy.

Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, và cộng sự. 2020. Các mô hình ngôn ngữ là người học ít bắn. Trong Tiến bộ trong Hệ thống Xử lý Thông tin Thần kinh.

Laurie Burchell, Alexandra Birch, Nikolay Bogoychev, và Kenneth Heafield. 2023. Một tập dữ liệu và mô hình mở để nhận dạng ngôn ngữ. Trong Kỷ yếu Cuộc họp Thường niên lần thứ 61 của Hiệp hội Ngôn ngữ học Tính toán (Tập 2: Bài báo Ngắn).

Alexis Conneau, Kartikay Khandelwal, Naman Goyal, Vishrav Chaudhary, Guillaume Wenzek, Francisco Guzmán, Edouard Grave, Myle Ott, Luke Zettlemoyer, và Veselin Stoyanov. 2020. Học biểu diễn đa ngữ không giám sát ở quy mô lớn. Trong Kỷ yếu Cuộc họp Thường niên lần thứ 58 của Hiệp hội Ngôn ngữ học Tính toán.

Yiming Cui, Ziqing Yang, và Xin Yao. 2023. Mã hóa văn bản hiệu quả và hiệu lực cho Chinese LLaMA và Alpaca. Bản in trước arXiv.

Jacob Devlin, Ming-Wei Chang, Kenton Lee, và Kristina Toutanova. 2019. BERT: Huấn luyện trước các transformer hai chiều sâu để hiểu ngôn ngữ. Trong Kỷ yếu Hội nghị 2019 của Chương Bắc Mỹ của Hiệp hội Ngôn ngữ học Tính toán: Công nghệ Ngôn ngữ Con người, Tập 1 (Bài báo Dài và Ngắn).

Leo Gao, Stella Biderman, Sid Black, Laurence Golding, Travis Hoppe, Charles Foster, Jason Phang, Horace He, Anish Thite, Noa Nabeshima, và cộng sự. 2020. The pile: Một tập dữ liệu 800GB văn bản đa dạng để mô hình hóa ngôn ngữ. Bản in trước arXiv.

Xinyang Geng và Hao Liu. 2023. OpenLLaMA: Một tái tạo mở của LLaMA. Kho lưu trữ GitHub.

Edward J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, và Weizhu Chen. 2022. LoRA: Thích ứng thứ hạng thấp của các mô hình ngôn ngữ lớn. Trong Hội nghị Quốc tế về Biểu diễn Học.

Armand Joulin, Edouard Grave, Piotr Bojanowski, và Tomas Mikolov. 2017. Túi thủ thuật để phân loại văn bản hiệu quả. Trong Kỷ yếu Hội nghị lần thứ 15 của Chương Châu Âu của Hiệp hội Ngôn ngữ học Tính toán: Tập 2, Bài báo Ngắn.

Tannon Kew, Florian Schottmann, và Rico Sennrich. 2023. Biến LLMs lấy tiếng Anh làm trung tâm thành đa ngữ: Cần bao nhiêu đa ngữ? Bản in trước arXiv.

Andreas Köpf, Yannic Kilcher, Dimitri von Rütte, Sotiris Anagnostidis, Zhi-Rui Tam, Keith Stevens, Abdullah Barhoum, Nguyen Minh Duc, Oliver Stanley, Richárd Nagyfi, và cộng sự. 2023. Cuộc trò chuyện OpenAssistant–dân chủ hóa căn chỉnh mô hình ngôn ngữ lớn. Bản in trước arXiv.

Hugo Laurençon, Lucile Saulnier, Thomas Wang, Christopher Akiki, Albert Villanova del Moral, Teven Le Scao, Leandro Von Werra, Chenghao Mou, Eduardo González Ponferrada, Huu Nguyen, và cộng sự. 2022. Kho ngữ liệu bigscience ROOTS: Một tập dữ liệu đa ngữ tổng hợp 1.6TB. Trong Hội nghị lần thứ ba mươi sáu về Hệ thống Xử lý Thông tin Thần kinh Tập dữ liệu và Đường băng Điểm chuẩn.

Haonan Li, Fajri Koto, Minghao Wu, Alham Fikri Aji, và Timothy Baldwin. 2023a. Bactrian-X: Một mô hình tuân theo hướng dẫn có thể tái tạo đa ngữ với thích ứng thứ hạng thấp. Bản in trước arXiv.

Jiahuan Li, Hao Zhou, Shujian Huang, Shanbo Chen, và Jiajun Chen. 2023b. Khơi gợi khả năng dịch thuật của các mô hình ngôn ngữ lớn qua tinh chỉnh đa ngữ với hướng dẫn dịch thuật. Bản in trước arXiv.

Yinhan Liu, Jiatao Gu, Naman Goyal, Xian Li, Sergey Edunov, Marjan Ghazvininejad, Mike Lewis, và Luke Zettlemoyer. 2020. Huấn luyện trước khử nhiễu đa ngữ cho dịch máy thần kinh. Giao dịch của Hiệp hội Ngôn ngữ học Tính toán, 8:726–742.

Shayne Longpre, Le Hou, Tu Vu, Albert Webson, Hyung Won Chung, Yi Tay, Denny Zhou, Quoc V Le, Barret Zoph, Jason Wei, và cộng sự. 2023. Bộ sưu tập Flan: Thiết kế dữ liệu và phương pháp cho tinh chỉnh hướng dẫn hiệu quả. Trong Kỷ yếu Hội nghị Quốc tế lần thứ 40 về Học máy.

Swaroop Mishra, Daniel Khashabi, Chitta Baral, và Hannaneh Hajishirzi. 2022. Tổng quát hóa đa nhiệm vụ qua hướng dẫn crowdsourcing ngôn ngữ tự nhiên. Trong Kỷ yếu Cuộc họp Thường niên lần thứ 60 của Hiệp hội Ngôn ngữ học Tính toán (Tập 1: Bài báo Dài).

Niklas Muennighoff, Thomas Wang, Lintang Sutawika, Adam Roberts, Stella Biderman, Teven Le Scao, M Saiful Bari, Sheng Shen, Zheng-Xin Yong, Hailey Schoelkopf, và cộng sự. 2023. Tổng quát hóa đa ngữ thông qua tinh chỉnh đa nhiệm vụ. Trong Kỷ yếu Cuộc họp Thường niên lần thứ 61 của Hiệp hội Ngôn ngữ học Tính toán (Tập 1: Bài báo Dài).

Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, và cộng sự. 2022. Huấn luyện các mô hình ngôn ngữ để tuân theo hướng dẫn với phản hồi con người. Trong Tiến bộ trong Hệ thống Xử lý Thông tin Thần kinh.

Matthew E. Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Kenton Lee, và Luke Zettlemoyer. 2018. Biểu diễn từ được bối cảnh hóa sâu. Trong Kỷ yếu Hội nghị 2018 của Chương Bắc Mỹ của Hiệp hội Ngôn ngữ học Tính toán: Công nghệ Ngôn ngữ Con người, Tập 1 (Bài báo Dài).

Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, và Ilya Sutskever. 2019. Các mô hình ngôn ngữ là người học đa nhiệm vụ không giám sát. Blog OpenAI.

Leonardo Ranaldi, Giulia Pucci, và Andre Freitas. 2023. Trao quyền cho các khả năng đa ngữ của các mô hình ngôn ngữ lớn được tinh chỉnh hướng dẫn bằng các cuộc trình diễn theo dõi dịch thuật. Bản in trước arXiv.

Victor Sanh, Albert Webson, Colin Raffel, Stephen Bach, Lintang Sutawika, Zaid Alyafeai, Antoine Chaffin, Arnaud Stiegler, Arun Raja, Manan Dey, và cộng sự. 2022. Huấn luyện được nhắc nhở đa nhiệm vụ cho phép tổng quát hóa nhiệm vụ zero-shot. Trong Hội nghị Quốc tế về Biểu diễn Học.

Teven Le Scao, Angela Fan, Christopher Akiki, Ellie Pavlick, Suzana Ilić, Daniel Hesslow, Roman Castagné, Alexandra Sasha Luccioni, François Yvon, Matthias Gallé, và cộng sự. 2022. BLOOM: Một mô hình ngôn ngữ đa ngữ truy cập mở 176B tham số. Bản in trước arXiv.

Uri Shaham, Jonathan Herzig, Roee Aharoni, Idan Szpektor, Reut Tsarfaty, và Matan Eyal. 2024. Tinh chỉnh hướng dẫn đa ngữ chỉ với một chút đa ngữ. Bản in trước arXiv.

Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy Liang, và Tatsunori B. Hashimoto. 2023. Stanford Alpaca: Một mô hình LLaMA tuân theo hướng dẫn. Kho lưu trữ GitHub.

Together Computer. 2023. RedPajama: Một công thức mã nguồn mở để tái tạo tập dữ liệu huấn luyện LLaMA. Kho lưu trữ GitHub.

Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, và cộng sự. 2023. LLaMA: Các mô hình ngôn ngữ nền tảng mở và hiệu quả. Bản in trước arXiv.

Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A. Smith, Daniel Khashabi, và Hannaneh Hajishirzi. 2023. Tự hướng dẫn: Căn chỉnh các mô hình ngôn ngữ với hướng dẫn tự tạo. Trong Kỷ yếu Cuộc họp Thường niên lần thứ 61 của Hiệp hội Ngôn ngữ học Tính toán (Tập 1: Bài báo Dài).

Jason Wei, Maarten Bosma, Vincent Y Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du, Andrew M Dai, và Quoc V Le. 2022. Các mô hình ngôn ngữ được tinh chỉnh là người học zero-shot. Trong Hội nghị Quốc tế về Biểu diễn Học.

Xiangpeng Wei, Haoran Wei, Huan Lin, Tianhao Li, Pei Zhang, Xingzhang Ren, Mei Li, Yu Wan, Zhiwei Cao, Binbin Xie, và cộng sự. 2023. Polylm: Một mô hình ngôn ngữ lớn đa ngữ mã nguồn mở. Bản in trước arXiv.

Shijie Wu và Mark Dredze. 2020. Tất cả các ngôn ngữ có được tạo ra bình đẳng trong BERT đa ngữ không? Trong Kỷ yếu Hội thảo lần thứ 5 về Học Biểu diễn cho NLP.

Linting Xue, Noah Constant, Adam Roberts, Mihir Kale, Rami Al-Rfou, Aditya Siddhant, Aditya Barua, và Colin Raffel. 2021. mT5: Một transformer văn bản-thành-văn bản đa ngữ quy mô lớn được huấn luyện trước. Trong Kỷ yếu Hội nghị 2021 của Chương Bắc Mỹ của Hiệp hội Ngôn ngữ học Tính toán: Công nghệ Ngôn ngữ Con người.

Aiyuan Yang, Bin Xiao, Bingning Wang, Borong Zhang, Chao Yin, Chenxu Lv, Da Pan, Dian Wang, Dong Yan, Fan Yang, và cộng sự. 2023. Baichuan 2: Các mô hình ngôn ngữ quy mô lớn mở. Bản in trước arXiv.

Jiacheng Ye, Xijia Tao, và Lingpeng Kong. 2023. Người đa năng ngôn ngữ so với chuyên gia: Một xem xét lại thực nghiệm về khả năng chuyển giao đa ngữ. Bản in trước arXiv.

Shaolei Zhang, Qingkai Fang, Zhuocheng Zhang, Zhengrui Ma, Yan Zhou, Langlin Huang, Mengyu Bu, Shangtong Gui, Yunji Chen, Xilin Chen, và cộng sự. 2023. BayLing: Kết nối căn chỉnh đa ngữ và tuân theo hướng dẫn thông qua dịch thuật tương tác cho các mô hình ngôn ngữ lớn. Bản in trước arXiv.

Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric Xing, và cộng sự. 2023. Đánh giá LLM-như-thẩm-phán với MT-Bench và Chatbot Arena. Trong Hội nghị lần thứ ba mươi bảy về Hệ thống Xử lý Thông tin Thần kinh Tập dữ liệu và Đường băng Điểm chuẩn.

Wenhao Zhu, Yunzhe Lv, Qingxiu Dong, Fei Yuan, Jingjing Xu, Shujian Huang, Lingpeng Kong, Jiajun Chen, và Lei Li. 2023. Ngoại suy các mô hình ngôn ngữ lớn sang tiếng không phải Anh bằng cách căn chỉnh các ngôn ngữ. Bản in trước arXiv.

A Chi tiết Thiết lập Thí nghiệm
A.1 Siêu tham số
Bảng 1 cho thấy cấu hình siêu tham số của LoRA và tinh chỉnh toàn bộ tham số. LoRA là một phương pháp huấn luyện hiệu quả tham số nơi, đối với một ma trận lớn, chỉ các ma trận thứ hạng thấp được huấn luyện và vá vào nó. Trong trường hợp của chúng tôi, chúng tôi áp dụng nó vào các ma trận chú ý (khóa, truy vấn, giá trị) và sử dụng thứ hạng 8, dropout 0.05, và hệ số tỷ lệ 16 xuyên suốt. Chúng tôi sử dụng kích thước batch 128, đặt ngân sách huấn luyện cố định 5 epoch với tỷ lệ học 3e-4, và chọn điểm kiểm tra tốt nhất dựa trên entropy chéo xác thực. Đối với tinh chỉnh toàn bộ tham số, chúng tôi tuân theo cấu hình của Alpaca bằng cách huấn luyện trong 3 epoch với tỷ lệ học 2e-5, tỷ lệ khởi động 0.03, và kích thước batch 256.

Vì chúng tôi sử dụng một loạt các mô hình có kích thước khác nhau, chúng tôi ước tính thời gian tính toán dựa trên các mô hình 7 tỷ tham số là mô hình lớn thứ hai mà chúng tôi tinh chỉnh. Tinh chỉnh LoRA mất 15-20 giờ trên 4 GPU GeForce RTX 3090, sử dụng giảm tải bộ nhớ CPU và huấn luyện phân tán. Tinh chỉnh toàn bộ tham số được thực hiện trên 4 GPU AMD MI250x (được xử lý như 8 GPU với bộ nhớ 64G mỗi cái tại runtime) với song song mô hình, và nó đòi hỏi khoảng 24 giờ để hoàn thành. Cho chi phí tính toán cao của tinh chỉnh mô hình, chúng tôi đã thực hiện tất cả các thí nghiệm tinh chỉnh một lần. Chúng tôi sử dụng một loạt các GPU khác nhau, nhưng thông qua tích lũy gradient, chúng tôi duy trì cùng kích thước batch toàn cục cho mỗi kỹ thuật tinh chỉnh: 128 cho LoRA và 256 cho tinh chỉnh toàn bộ tham số.

A.2 Mô tả LLMs
Do hạn chế không gian, chúng tôi đặt mô tả chi tiết về LLMs được sử dụng trong nghiên cứu của chúng tôi ở đây. Tất cả các mô hình được sử dụng trong nghiên cứu này đều có sẵn công khai và miễn phí sử dụng cho mục đích học thuật.

Baichuan-2 (Yang et al., 2023) là một LLM đa ngữ được huấn luyện trên 2.6 nghìn tỷ token. Mặc dù thành phần dữ liệu không minh bạch trong báo cáo kỹ thuật của nó, trọng số LLM là mã nguồn mở và nó hoạt động mạnh mẽ trên các nhiệm vụ bằng tiếng Anh và tiếng Trung. Chúng tôi sử dụng điểm kiểm tra 7B của nó.

BLOOM (Scao et al., 2022) được huấn luyện trên tập dữ liệu ROOTS (Laurençon et al., 2022) chứa 350 tỷ token trong 46 ngôn ngữ tự nhiên trải dài 9 họ ngôn ngữ và 12 ngôn ngữ lập trình. LLM có tiếng Anh, Trung Quốc, Pháp, và Tây Ban Nha như các thành phần chính. Chúng tôi sử dụng các điểm kiểm tra từ 560M đến 7.1B cho các thí nghiệm.

LLaMA (Touvron et al., 2023) đã được huấn luyện trên dữ liệu chủ yếu bằng tiếng Anh với một số bằng các ngôn ngữ châu Âu trong hệ thống chữ viết Latin và Cyrillic. Nó cũng có thể hỗ trợ các ngôn ngữ khác với tokenization byte-BPE. Chúng tôi sử dụng mô hình 7B của nó đã thấy 1 nghìn tỷ token.

OpenLLaMA (Geng và Liu, 2023) là một tái tạo mã nguồn mở của LLaMA, được huấn luyện trên tập dữ liệu RedPajama (Together Computer, 2023), gần với thành phần dữ liệu của LLaMA. Tương tự, chúng tôi sử dụng phiên bản 7B.

Pythia (Biderman et al., 2023) được huấn luyện trên Pile (Gao et al., 2020) có gần 300 tỷ token và dự định là chủ yếu tiếng Anh. Chúng tôi thí nghiệm với toàn bộ phạm vi từ 70M đến 12B.

B Chi tiết Đánh giá
B.1 Mẫu lời nhắc cho LLM-như-thẩm-phán
Mẫu lời nhắc LLM-như-thẩm-phán của chúng tôi như Hình 6, tương tự như của Zheng et al. (2023) với một yêu cầu bổ sung về ngôn ngữ phản hồi.

B.2 Một ví dụ về sự không nhất quán ngôn ngữ
Bảng 2 liệt kê một ví dụ nơi phản hồi "đúng" về nội dung nhưng không khớp với ngôn ngữ của truy vấn. Trong trường hợp này, thẩm phán, GPT-3.5 không phạt sự không nhất quán ngôn ngữ này mặc dù được yêu cầu làm như vậy trong lời nhắc đánh giá. Điều này làm cho việc nhận dạng ngôn ngữ bổ sung trở nên cần thiết.

B.3 Đánh giá con người và sự đồng thuận người-LLM
Chúng tôi mời các đánh giá viên con người thành thạo hoặc bản ngữ trong ngôn ngữ của các hướng dẫn và phản hồi để chấm điểm tổng cộng đầu ra từ 12 mô hình được tinh chỉnh với LoRA. Chúng tôi đính kèm hướng dẫn đưa cho các đánh giá viên con người trong Hình 7. Phản hồi của các hệ thống cho cùng một hướng dẫn được xáo trộn nhưng nhóm lại với nhau để cung cấp bối cảnh về chất lượng tổng thể. Các đánh giá viên con người được yêu cầu gán cho mỗi phản hồi một điểm số. Chúng tôi liệt kê chi tiết mô hình, cũng như điểm số đánh giá GPT và con người tổng hợp của họ trong Bảng 3.

C Chi tiết Kết quả
C.1 Thí nghiệm trên Pythia với LoRA
Ngoài tinh chỉnh LoRA trên các mô hình BLOOM, chúng tôi thực hiện cùng một cuộc điều tra trên các mô hình Pythia ở các kích thước khác nhau. Chúng tôi quan sát rằng tinh chỉnh đa ngữ không thua tinh chỉnh đơn ngữ trong bất kỳ ngôn ngữ nào, tương tự như những gì chúng tôi tìm thấy về BLOOM trong Phần 3.1. Các biểu đồ cho sáu ngôn ngữ được bao gồm như Hình 8.

# 2305.13627.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/multilingual/2305.13627.pdf
# Kích thước file: 950835 byte

===============================================
NỘI DUNG FILE PDF
===============================================


--- TRANG 1 ---
InstructAlign: Căn chỉnh Ngôn ngữ Tài nguyên Cao và Thấp 
thông qua Điều chỉnh Hướng dẫn Đa ngôn ngữ Liên tục
Samuel Cahyawijaya, Holy Lovenia, Tiezheng Yu, Willy Chung, Pascale Fung
Đại học Khoa học và Công nghệ Hồng Kông
Clear Water Bay, Hồng Kông
scahyawijaya@connect.ust.hk
Tóm tắt
Các mô hình ngôn ngữ lớn (LLM) được điều chỉnh
với hướng dẫn đã chứng minh khả năng đáng chú ý
trong nhiều tác vụ và ngôn ngữ khác nhau. Tuy nhiên,
khả năng tổng quát hóa của chúng đối với các ngôn ngữ
thiếu đại diện bị hạn chế do sự khan hiếm dữ liệu có
sẵn. Ngoài ra, việc trực tiếp điều chỉnh các ngôn ngữ
mới cho các LLM đã được điều chỉnh hướng dẫn có
thể dẫn đến quên thảm khốc, gây mất khả năng đa tác
vụ. Để giải quyết vấn đề này, chúng tôi đề xuất
InstructAlign sử dụng điều chỉnh hướng dẫn đa ngôn
ngữ liên tục để cho phép các LLM căn chỉnh các ngôn
ngữ mới chưa thấy với các ngôn ngữ tài nguyên cao
đã học trước đó. Kết quả của chúng tôi chứng minh
hiệu quả của InstructAlign trong việc cho phép mô
hình hiểu các ngôn ngữ tài nguyên thấp với dữ liệu
song song hạn chế trong khi ngăn chặn quên thảm
khốc. Công trình của chúng tôi đóng góp vào sự tiến
bộ của các phương pháp thích ứng ngôn ngữ, đặc biệt
cho việc thích ứng các LLM được điều chỉnh hướng
dẫn với các ngôn ngữ thiếu đại diện. Mã nguồn của
chúng tôi được phát hành tại https://github.
com/HLTCHKUST/InstructAlign .
1 Giới thiệu
Các mô hình ngôn ngữ lớn được điều chỉnh hướng dẫn (LLM)
đã chứng minh khả năng tổng quát hóa trong việc giải quyết
nhiều tác vụ khác nhau được biểu đạt bằng ngôn ngữ tự nhiên
mà không cần bất kỳ huấn luyện rõ ràng nào trên tác vụ tương
ứng (Brown et al., 2020; Smith et al., 2022; Rae et al., 2022;
Thoppilan et al., 2022; Chowdhery et al., 2022; Scao et al.,
2022; Zeng et al., 2022). Khả năng tổng quát hóa này được
cải thiện thêm với nhiều phương pháp điều chỉnh khác nhau,
như điều chỉnh hướng dẫn (Sanh et al., 2022; Wei et al.,
2022a; Chung et al., 2022; Muennighoff et al., 2022). Tuy
nhiên, các LLM và các biến thể được điều chỉnh hướng dẫn
của chúng gặp khó khăn trong việc tổng quát hóa qua nhiều
ngôn ngữ khác nhau, dẫn đến sự chênh lệch về hiệu suất
(Xue et al., 2021; Gehrmann et al., 2022; Scao et al., 2022;
Chowdhery et al., 2022; Yong et al., 2023; Zhang et al., 2023;
Asai et al., 2023; Kabra et al., 2023). Hơn nữa, các mô hình
này có phạm vi ngôn ngữ hạn chế, chủ yếu trong họ ngôn
ngữ Ấn-Âu như được chỉ ra trong Hình 1.

Chẳng hạn, BLOOM (Scao et al., 2022) và BLOOMZ
(Muennighoff et al., 2022), LLM đa ngôn ngữ tiền huấn
luyện mã nguồn mở lớn nhất do cộng đồng thúc đẩy, chỉ
bao phủ 46 ngôn ngữ trong quá trình tiền huấn luyện, loại
trừ một số ngôn ngữ tài nguyên cao với hàng trăm triệu
người nói, như tiếng Đức, Nhật, Hàn và Nga, cũng như
nhiều ngôn ngữ tài nguyên thấp hơn với hàng triệu người
nói, như Serbia, Phần Lan, Amhara, Sinhala, Lào, Java,
Sunda, v.v.

Mở rộng kho ngôn ngữ của các LLM là cần thiết để thúc
đẩy tính bao trùm và đa dạng trong công nghệ Xử lý Ngôn
ngữ Tự nhiên (NLP), đặc biệt đối với các ngôn ngữ thiếu
đại diện và tài nguyên thấp. Các nghiên cứu gần đây, bao
gồm Wilie et al. (2020); Cahyawijaya et al. (2021); Aji
et al. (2022); Adelani et al. (2021, 2022); Kakwani et al.
(2020); Kumar et al. (2022); Ebrahimi et al. (2022);
Adilazuarda et al. (2022); Cahyawijaya et al. (2023b,a);
Song et al. (2023) đã nhấn mạnh tầm quan trọng của vấn đề
này. Để giải quyết mối quan ngại này, nghiên cứu trước đây
(Yong et al., 2022) đã chứng minh rằng tiền huấn luyện liên
tục (Chau et al., 2020; Muller et al., 2021; Ebrahimi and
Kann, 2021) và các phương pháp điều chỉnh hiệu quả tham
số (PEFT), như MAD-X (Pfeiffer et al., 2020) và (IA)3(Liu
et al., 2022), có thể được sử dụng để nhanh chóng tích hợp
kiến thức của các ngôn ngữ chưa thấy vào các LLM bằng
cách sử dụng tập dữ liệu đơn ngữ của các ngôn ngữ mới
thông qua mô hình hóa ngôn ngữ có mặt nạ (MLM) (Devlin
et al., 2019). Tuy nhiên, các phương pháp này trở nên không
hiệu quả khi áp dụng trực tiếp cho các LLM được điều chỉnh
hướng dẫn do quên thảm khốc (French, 1993) ngăn cản
chúng giải quyết các tác vụ ngôn ngữ tự nhiên tổng quát sau
giai đoạn thích ứng ngôn ngữ (Yong et al., 2022). Hơn nữa,
các phương pháp dựa trên adapter, như MAD-X (Pfeiffer
et al., 2020), dẫn đến mất khả năng suy luận đa ngôn ngữ
do tính mô-đun (Adilazuarda et al., 2023).

--- TRANG 2 ---
Hình 1: Số lượng ngôn ngữ được hỗ trợ bởi các LLM hiện có (vùng xanh lá) theo họ ngôn ngữ1. Các LLM hiện có chỉ hỗ trợ một phần nhỏ các ngôn ngữ trên toàn cầu. Hầu hết chúng thuộc họ ngôn ngữ Ấn-Âu, trong khi hầu hết các họ ngôn ngữ khác bị thiếu đại diện hoặc thậm chí chưa được khám phá.

Để giải quyết vấn đề này, chúng tôi giới thiệu InstructAlign, một khung điều chỉnh hướng dẫn liên tục để căn chỉnh liền mạch các ngôn ngữ tài nguyên thấp mới được thích ứng (L2) với các ngôn ngữ tài nguyên cao tiền huấn luyện (L1) của một LLM được điều chỉnh hướng dẫn thông qua căn chỉnh đa ngôn ngữ. InstructAlign buộc các LLM thực hiện căn chỉnh đa ngôn ngữ giữa các ngôn ngữ tiền huấn luyện và mới thông qua điều chỉnh hướng dẫn đa ngôn ngữ dựa trên căn chỉnh, cho phép mô hình nắm bắt L2 chỉ với một lượng dữ liệu song song hạn chế. Để ngăn chặn thêm quên thảm khốc, InstructAlign kết hợp trải nghiệm phát lại (Chaudhry et al., 2019b; Rolnick et al., 2019), thêm dữ liệu quá khứ trong quá trình điều chỉnh hướng dẫn.

Tóm lại, công trình của chúng tôi trình bày các đóng góp chính sau:

•Chúng tôi đề xuất InstructAlign, một phương pháp điều chỉnh hướng dẫn liên tục đa ngôn ngữ cho phép các LLM được điều chỉnh hướng dẫn hiểu L2 với sự suy giảm tối thiểu trên L1 trong khi duy trì khả năng gợi ý zero-shot.

•Chúng tôi đề xuất điều chỉnh hướng dẫn đa ngôn ngữ dựa trên căn chỉnh, cho phép các LLM căn chỉnh L2 với L1 cho phép thu nhận L2 tốt hơn chỉ với một lượng dữ liệu song song hạn chế.

•Chúng tôi đánh giá hiệu quả của InstructAlign trên các bộ dữ liệu ngôn ngữ địa phương Indonesia, và chứng minh rằng InstructAlign có thể cải thiện đáng kể hiệu suất trên L2 từ 5-10% F1 trong khi duy trì hiệu suất ban đầu trên L1 và khả năng đa tác vụ.

•Chúng tôi phân tích mối tương quan giữa hiệu suất của L2 và các ngôn ngữ chưa thấy khác (L3), gợi ý khả năng tổng quát hóa zero-shot của InstructAlign đối với L3 đặc biệt khi các ngôn ngữ có liên quan.2

2 Công trình liên quan
2.1 Điều chỉnh Hướng dẫn trong LLM
Các công trình đầu (Wei et al., 2022a; Chung et al., 2022; Sanh et al., 2022; Ouyang et al., 2022) đã cho thấy hiệu quả của các LLM được điều chỉnh hướng dẫn, cải thiện đáng kể khả năng tổng quát hóa zero-shot so với các LLM không được điều chỉnh hướng dẫn tương ứng với biên độ lớn. Kể từ đó, nhiều LLM được điều chỉnh hướng dẫn khác nhau đã được phát hành, bao gồm T0 (Sanh et al., 2022), InstructGPT (Ouyang et al., 2022), FLAN-GPT (Wei et al., 2022a), FLAN-T5 (Chung et al., 2022), FLAN-PaLM (Chung et al., 2022), mT0 (Muennighoff et al., 2022), BLOOMZ (Muennighoff et al., 2022), Alpaca (Taori et al., 2023), v.v. Tuy nhiên, hầu hết các mô hình này chỉ được tiền huấn luyện trên một hoặc vài ngôn ngữ, ngoại trừ mT0 và BLOOMZ được điều chỉnh từ các mô hình tiền huấn luyện trên 101 ngôn ngữ, tức là mT5 (Xue et al., 2021), và tiền huấn luyện trên 46 ngôn ngữ, tức là BLOOM (Scao et al., 2022), tương ứng. Trong công trình này, chúng tôi sử dụng BLOOMZ (Muennighoff et al., 2022) làm xương sống trong InstructAlign.

2Chúng tôi sử dụng các thuật ngữ L1, L2, và L3 để biểu thị việc thu nhận ngôn ngữ thứ nhất, thứ hai, và thứ ba (Hammarberg, 2001, 2014). Trong bối cảnh của chúng tôi, L1 biểu thị các ngôn ngữ tiền huấn luyện trong LLM, L2 biểu thị các ngôn ngữ mới được thích ứng, và L3 biểu thị các ngôn ngữ khác chưa được thấy sau khi điều chỉnh với InstructAlign, chỉ được sử dụng trong đánh giá.

--- TRANG 3 ---
Hình 2: Ví dụ về các lời nhắc hướng dẫn đa ngôn ngữ dựa trên căn chỉnh, tức là khử nhiễu song ngữ (TLM), dịch máy (MT), và tương đồng ngữ nghĩa đa ngôn ngữ (XSS) so với khử nhiễu đơn ngữ (MLM).

2.2 Căn chỉnh Đa ngôn ngữ
Căn chỉnh đa ngôn ngữ là một khái niệm được khám phá rộng rãi cho phép các mô hình ngôn ngữ (LM) căn chỉnh, thường ở cấp độ từ/câu, qua các ngôn ngữ khác nhau. Căn chỉnh đa ngôn ngữ cho phép các mô hình thực hiện suy luận đa ngôn ngữ mà không cần bất kỳ điều chỉnh nào trên tác vụ đích. Fung (1997, 1998) một phương pháp trích xuất từ điển song ngữ thông qua căn chỉnh từ-với-từ từ ma trận quan hệ từ. Fung and Cheung (2004) giới thiệu một phương pháp trích xuất từ điển song ngữ và câu song song từ việc căn chỉnh các câu từ dữ liệu không song song thông qua Bootstrapping và EM. Lample et al. (2018b); Cao et al. (2020) giới thiệu phương pháp căn chỉnh từ điển song ngữ không cần dữ liệu song song bằng cách thực hiện căn chỉnh embedding qua các ngôn ngữ khác nhau. Điều này sau đó được sử dụng để xử lý dịch máy không giám sát Lample et al. (2018a). Một mục tiêu tiền huấn luyện đa ngôn ngữ để xây dựng LM, gọi là mô hình hóa ngôn ngữ dịch thuật (TLM) (Conneau and Lample, 2019), cũng đã được khám phá, thực thi căn chỉnh cấp token giữa các ngôn ngữ cho phép mô hình học biểu diễn căn chỉnh qua nhiều ngôn ngữ. Trong công trình này, chúng tôi thực hiện căn chỉnh đa ngôn ngữ thông qua hướng dẫn bằng cách giới thiệu hướng dẫn khử nhiễu song ngữ tương đương với căn chỉnh cấp token trong TLM, và hướng dẫn dịch thuật phục vụ như căn chỉnh cấp câu qua các ngôn ngữ khác nhau.

2.3 Học Liên tục cho Mô hình Ngôn ngữ
Học liên tục là một mô hình để học dần dần nhiều tác vụ khác nhau cho phép mô hình thu nhận kiến thức mới theo thời gian (Delange et al., 2021). Sử dụng phương pháp điều chỉnh ngây thơ cho học liên tục khiến mô hình bị quên thảm khốc (CF) (French, 1999). Do đó, nhiều phương pháp khác nhau đã được giới thiệu để ngăn chặn CF. Các phương pháp dựa trên chính quy hóa (Kirkpatrick et al., 2017; Liu et al., 2018; Aljundi et al., 2018) thêm một chính quy hóa trong hàm mất mát để ngăn mô hình được cập nhật theo hướng gây ra CF. Các phương pháp dựa trên phát lại (Rolnick et al., 2019; Lopez-Paz and Ranzato, 2017; Chaudhry et al., 2019a) thêm các mẫu từ các tác vụ trước đó để được kết hợp trong quá trình học tác vụ mới, giúp điều chỉnh mô hình để tránh CF. Các phương pháp cô lập tham số (Aljundi et al., 2017; Serrà et al., 2018; Mallya and Lazebnik, 2018) ngăn mô hình khỏi CF bằng cách học các tác vụ mới sử dụng một tập tham số mới trong khi giữ các tham số khác đóng băng trong quá trình điều chỉnh. Trong công trình này, chúng tôi áp dụng trải nghiệm phát lại (Rolnick et al., 2019), một phương pháp dựa trên phát lại đơn giản bằng cách thêm các tác vụ từ các ngôn ngữ đã học trước đó khi huấn luyện các ngôn ngữ mới mà không có bất kỳ sửa đổi mất mát nào.

3 Phương pháp luận
InstructAlign là một khung điều chỉnh hướng dẫn đa ngôn ngữ liên tục cho phép mô hình căn chỉnh các ngôn ngữ tài nguyên cao-thấp thông qua điều chỉnh hướng dẫn. InstructAlign giới thiệu hai thành phần, tức là 1) căn chỉnh đa ngôn ngữ thông qua điều chỉnh hướng dẫn, cho phép mô hình căn chỉnh các ngôn ngữ tiền huấn luyện với các ngôn ngữ mới thông qua căn chỉnh đa ngôn ngữ, và 2) điều chỉnh hướng dẫn liên tục, áp dụng học liên tục vào điều chỉnh hướng dẫn để tránh quên thảm khốc.

--- TRANG 4 ---
Bộ dữ liệu Tác vụ #Ngôn ngữ #L1 #L2 #L3 #Test
NusaX Phân tích Cảm xúc 12 2 7 3 4400
NusaTranslation Phân tích Cảm xúc 11+1 1 3 8 10400
NusaParagraph Nhận diện Cảm xúc 10 0 4 6 5700
NusaParagraph Phân loại Chủ đề 10 0 4 6 6250
Bảng 1: Thống kê của tất cả các bộ dữ liệu được sử dụng trong các thí nghiệm. #Ngôn ngữ biểu thị #ngôn ngữ trong mỗi bộ dữ liệu.

3.1 Căn chỉnh Đa ngôn ngữ thông qua Hướng dẫn
Cho một cặp văn bản song song (x, y) từ hai ngôn ngữ, mục tiêu của căn chỉnh đa ngôn ngữ là học một hàm ánh xạ f(.) được tham số hóa bởi θ sao cho f(x, θ) = f(y, θ). Cặp văn bản (x, y) thường có dạng cặp từ hoặc cặp cụm từ (Lample et al., 2018b,a), nhưng về lý thuyết, nó có thể tổng quát hóa thành cặp câu hoặc thậm chí cặp đoạn văn. Với mục tiêu căn chỉnh hai văn bản song song từ hai ngôn ngữ khác nhau, InstructAlign định nghĩa một tập hợp các hướng dẫn đa ngôn ngữ dựa trên căn chỉnh bằng cách khai thác nhiều mục tiêu căn chỉnh có thể đạt được thông qua một câu song song. Cụ thể, chúng tôi khám phá ba mục tiêu khác nhau, tức là khử nhiễu song ngữ / mô hình hóa ngôn ngữ dịch thuật (TLM), dịch máy (MT) và tương đồng ngữ nghĩa đa ngôn ngữ (XSS).

Chúng tôi đầu tiên định nghĩa một cặp câu song song (X = {x1, x2, . . . , xm}, Y = {y1, y2, . . . , yn}), trong đó xi và yi biểu thị token thứ i của câu X và Y, tương ứng. Đối với khử nhiễu song ngữ (TLM), chúng tôi mô hình hóa vấn đề như một tác vụ khử nhiễu có điều kiện. InstructAlign đầu tiên áp dụng một hàm nhiễu loạn gtlm(.) cho câu đích Y để che phủ một phần các token nhằm có được Ỹ = gtlm(Y). Cặp (X, Ỹ) sau đó được sử dụng để tạo một lời nhắc sử dụng h(X, Ỹ, Ttlm), dẫn đến một cặp dữ liệu đầu vào-đầu ra cho việc gợi ý (htlm(X, Ỹ, Ttlm), Y), trong đó htlm(.) biểu thị một bộ tạo lời nhắc khử nhiễu song ngữ và Ttlm là mẫu lời nhắc.

Đối với mục tiêu dịch máy (MT), chúng tôi định nghĩa cặp dữ liệu đầu vào-đầu ra là (hmt(X, Tmt), Y), trong đó hmt(.) biểu thị một bộ tạo lời nhắc dịch máy và Tmt biểu thị một mẫu lời nhắc dịch máy. Đối với mục tiêu tương đồng ngữ nghĩa đa ngôn ngữ (XSS), chúng tôi mô hình hóa vấn đề như một tác vụ suy luận để dự đoán liệu hai câu song song X và Y có tương đồng về ngữ nghĩa hay không. Cụ thể, chúng tôi định nghĩa cặp dữ liệu đầu vào-đầu ra là (hxss(X, Y, Txss), l) trong đó hxss(.) là một bộ tạo lời nhắc tương đồng ngữ nghĩa, Txss biểu thị một mẫu lời nhắc tương đồng ngữ nghĩa và l là nhãn nhị phân về việc liệu các câu có liên quan về ngữ nghĩa hay không. Các ví dụ về các mục tiêu căn chỉnh đa ngôn ngữ được hiển thị trong Hình 2.

3.2 Điều chỉnh Hướng dẫn Liên tục thông qua Trải nghiệm Phát lại
Trong giai đoạn điều chỉnh hướng dẫn liên tục của InstructAlign, trải nghiệm phát lại (Rolnick et al., 2019) được sử dụng để giảm thiểu vấn đề quên thảm khốc. mhamdi-etal-2023-cross Trải nghiệm phát lại hoạt động bằng cách lưu trữ một số dữ liệu huấn luyện quá khứ và sử dụng chúng trong bước tối ưu hóa của dữ liệu mới. Những dữ liệu quá khứ này phục vụ như một thuật ngữ chính quy hóa ngăn các mô hình quên kiến thức quá khứ khi học từ dữ liệu mới. Dữ liệu quá khứ được thu thập từ dữ liệu điều chỉnh hướng dẫn được sử dụng khi phát triển mô hình được điều chỉnh hướng dẫn tương ứng, tất cả đều được giám sát.

Trong quá trình điều chỉnh hướng dẫn liên tục, InstructAlign chỉ lấy r mẫu được lấy ngẫu nhiên từ dữ liệu điều chỉnh hướng dẫn quá khứ. Dữ liệu quá khứ được lấy mẫu được sử dụng trong điều chỉnh-hướng dẫn liên tục với việc lấy mẫu cân bằng giữa dữ liệu quá khứ và dữ liệu mới. Một cách chính thức hơn, chúng tôi định nghĩa một bộ dữ liệu quá khứ Dold và một bộ dữ liệu hướng dẫn đa ngôn ngữ mới được tạo Dcli. Trong mỗi bước tối ưu hóa, InstructAlign lấy mẫu dữ liệu theo cách xen kẽ dẫn đến dữ liệu batch B = {sDold1, sDcli1, sDold2, sDcli2, . . . , sDoldn, sDclin} với 2n mẫu, trong đó sOldi và sDclii biểu thị một mẫu được lấy ngẫu nhiên từ Dold và Dcli, tương ứng. Vì các mẫu đều được giám sát, việc tối ưu hóa có thể được thực hiện bằng cách tối ưu hóa mất mát entropy chéo (Good, 1952) từ tất cả các mẫu trong batch.

4 Thiết lập Thí nghiệm
4.1 Bộ dữ liệu Điều chỉnh-Hướng dẫn Liên tục
Trong quá trình điều chỉnh InstructAlign, chúng tôi huấn luyện mô hình trên 7 ngôn ngữ L2 từ nhóm họ ngôn ngữ Malayo-Polynesia, tức là Sunda (sun), Java (jav), Bali (ban), Minangkabau (min), Bugis (bug), Aceh (ace), và Banjar (bjn). Đối với các ngôn ngữ L1, chúng tôi sử dụng tiếng Anh (eng), vì tiếng Anh bao phủ phần lớn dữ liệu tiền huấn luyện trong hầu hết các LLM, và tiếng Indonesia (ind), vì ngôn ngữ này có liên quan chặt chẽ với các ngôn ngữ L2 đích. Đối với bộ dữ liệu, chúng tôi sử dụng bộ dữ liệu FLORES-200 (Goyal et al., 2021; Team et al., 2022) làm nguồn dữ liệu song song nơi chúng tôi kết hợp tập validation và tập test tạo ra tổng cộng ~2000 câu song song cho mỗi cặp ngôn ngữ nhỏ hơn nhiều bậc so với kích thước dữ liệu được sử dụng cho thích ứng ngôn ngữ được sử dụng trong các công trình trước (Pfeiffer et al., 2020; Cahyawijaya et al., 2021; Alabi et al., 2022; Yong et al., 2022).

4.2 Mô hình & Siêu tham số
Chúng tôi sử dụng BLOOMZ (Muennighoff et al., 2022) làm mô hình xương sống. Cụ thể, chúng tôi khám phá InstructAlign trên hai kích thước mô hình, tức là BLOOMZ-560M và BLOOMZ-1.1B. Đối với InstructAlign, chúng tôi đánh giá ba mục tiêu căn chỉnh đa ngôn ngữ, tức là TLM, XSS, và MT. Danh sách các lời nhắc được sử dụng cho điều chỉnh hướng dẫn được mô tả trong Phụ lục A. Chúng tôi sử dụng lời nhắc tiếng Anh trong tất cả các thí nghiệm. Chúng tôi chạy tất cả các thí nghiệm với tốc độ học ban đầu là 1e-5 với suy giảm tốc độ học tuyến tính và kích thước batch là 32 cho một bước tối ưu hóa cố định là 50,000. Chúng tôi chạy InstructAlign trên một GPU RTX3090 đơn (24GB) sử dụng bộ tối ưu AdamW (Loshchilov and Hutter, 2019) và huấn luyện độ chính xác hỗn hợp (Micikevicius et al., 2018). Chúng tôi sử dụng một số lượng mẫu phát lại cố định r = 100000.

4.3 Thiết lập Đánh giá
Sau khi điều chỉnh với InstructAlign, mô hình sau đó được đánh giá trong thiết lập suy luận đa ngôn ngữ zero-shot, trong đó mô hình chưa bao giờ thấy tác vụ trên các ngôn ngữ đích, nhưng có thể đã thấy tác vụ trên các ngôn ngữ đã thấy khác. Để truy xuất nhãn phân loại, chúng tôi tính xác suất kết hợp của lời nhắc với mỗi nhãn trong bộ dữ liệu và chọn nhãn có xác suất kết hợp cao nhất. Chúng tôi xem xét 3 lời nhắc khác nhau bằng tiếng Anh cho suy luận zero-shot và lấy điểm chính xác trung bình và điểm F1 có trọng số làm thước đo đánh giá. Danh sách các lời nhắc được sử dụng trong đánh giá của chúng tôi được hiển thị trong Phụ lục A. Chúng tôi sử dụng một GPU RTX1080Ti đơn (11GB) để chạy đánh giá cho tất cả các mô hình. Để giảm nút thắt bộ nhớ trong quá trình suy luận, chúng tôi chạy các đánh giá sử dụng suy luận 8-bit thông qua LLM.int8() (Dettmers et al., 2022). Chúng tôi cung cấp so sánh hiệu suất giữa đánh giá 8-bit và 32-bit trong Phụ lục B.

Bộ dữ liệu Đánh giá Zero-Shot Để đánh giá hiệu quả của InstructAlign, chúng tôi sử dụng bốn bộ dữ liệu ngôn ngữ địa phương Indonesia đa ngôn ngữ, tức là tác vụ phân tích cảm xúc từ NusaX (NX-S) (Winata et al., 2022), tác vụ phân tích cảm xúc từ NusaTranslation (NT-S) (Cahyawijaya et al., 2023a), tác vụ phân loại chủ đề từ NusaParagraph (NP-T) (Cahyawijaya et al., 2023a), và tác vụ nhận diện cảm xúc cấp đoạn văn từ NusaParagraph (NP-E) (Cahyawijaya et al., 2023a). Thống kê chi tiết theo bộ dữ liệu được hiển thị trong Bảng 1. NusaX bao phủ 12 ngôn ngữ bao gồm 2 ngôn ngữ L1: tiếng Anh (eng) và tiếng Indonesia (ind), 7 ngôn ngữ L2: Aceh (ace), Bali (ban), Bugis (bug), Banjar (ban), Java (jav), Minangkabau (min), và Sunda (sun), và 3 ngôn ngữ L3: Toba Batak (bbc), Madura (mad), và Ngaju (nij). Trong khi NusaTranslation bao phủ 11 ngôn ngữ, bao gồm 3 ngôn ngữ L2: Java (jav), Sunda (sun), và Minangkabau (min), và 8 ngôn ngữ L3: Ambon (abs), Batak (btk), Betawi (bew), Bima (bhp), Madura (mad), Makassar (mak), Musi (mui), và Rejang (rej). NusaParagraph bao phủ 10 ngôn ngữ, bao gồm 4 ngôn ngữ L2: Sunda, Java (jav), Minangkabau (min), và, và 6 ngôn ngữ L3: Batak (btk), Betawi (bew), Madura (mad), Makassar (mak), Musi (mui), Rejang (rej). Để mở rộng bộ dữ liệu đánh giá cho L1, chúng tôi thêm dữ liệu phân tích cảm xúc tiếng Indonesia từ IndoLEM (Koto et al., 2020)3 làm tập con tiếng Indonesia (ind) của NT-S. Chi tiết thêm về mỗi bộ dữ liệu có thể được tìm thấy trong Phụ lục C.

4.4 Đường cơ sở
Đối với các đường cơ sở của chúng tôi, chúng tôi thực hiện gợi ý zero-shot sử dụng bốn kích thước khác nhau của BLOOMZ, tức là BLOOMZ-560M, BLOOMZ-1.1B, BLOOMZ-1.7B, và BLOOMZ-3B, mà không có bất kỳ giai đoạn thích ứng ngôn ngữ bổ sung nào. Ngoài ra, để so sánh hiệu quả của căn chỉnh đa ngôn ngữ, chúng tôi thêm các đường cơ sở điều chỉnh hướng dẫn liên tục chỉ kết hợp các hướng dẫn khử nhiễu đơn ngữ, tương đương với việc thực hiện thích ứng ngôn ngữ sử dụng MLM (Devlin et al., 2019).

5 Kết quả Thí nghiệm
Hiệu quả của InstructAlign Bảng 2 hiển thị kết quả của InstructAlign trên cả ngôn ngữ L1 và L2. Các mô hình được điều chỉnh InstructAlign với các mục tiêu MT, TLM, và XSS vượt trội đáng kể so với các đường cơ sở BLOOM và BLOOMZ có kích thước tương đương trên các ngôn ngữ L2 trong khi duy trì mức hiệu suất tương tự như các mô hình BLOOMZ ban đầu trên các ngôn ngữ L1. Đáng ngạc nhiên, InstructAlign với các mục tiêu MLM cũng hiệu quả, mang lại hiệu suất tương tự trên các ngôn ngữ L2 so với các mục tiêu đa ngôn ngữ. Trong §6.1, chúng tôi chỉ ra rằng sự cải thiện này chỉ xảy ra sau khi kết hợp mục tiêu MLM với trải nghiệm phát lại, chứng minh tầm quan trọng của điều chỉnh hướng dẫn liên tục trong quá trình thích ứng ngôn ngữ. Trong khi trong các tác vụ nhận diện cảm xúc NusaParagraph (NP-E) và phân loại chủ đề (NP-T), tất cả các đường cơ sở cho điểm số rất thấp, gợi ý rằng khả năng giải quyết các tác vụ phân loại văn bản dài không xuất hiện ở quy mô đó (Wei et al., 2022b). Thú vị là, các mô hình được điều chỉnh InstructAlign chỉ ra sự cải thiện nhất quán, mặc dù nhỏ, trên các tác vụ này, chứng minh rằng sự xuất hiện sớm trong các ngôn ngữ L2 là có thể thông qua InstructAlign.

Ảnh hưởng của Mở rộng Mô hình Như được hiển thị trong Hình 3, chúng tôi quan sát thấy rằng việc mở rộng tăng hiệu suất zero-shot của BLOOMZ trên cả L1 và L2, nhưng điều tương tự không áp dụng cho BLOOM, gợi ý lợi ích của điều chỉnh hướng dẫn cho tổng quát hóa tốt hơn đối với các tác vụ và ngôn ngữ chưa thấy. Hơn nữa, việc áp dụng InstructAlign trên BLOOMZ lớn hơn dẫn đến hiệu suất zero-shot tổng thể cao hơn trên cả L1 và L2. Cụ thể, các mô hình được điều chỉnh InstructAlign với 1.1 tỷ tham số mang lại hiệu suất cao hơn ~2% so với các mô hình được điều chỉnh InstructAlign 560 triệu tham số và thậm chí hoạt động cạnh tranh với mô hình BLOOMZ 3 tỷ tham số ban đầu. Điều này gợi ý rằng định luật mở rộng của các mô hình ngôn ngữ (Kaplan et al., 2020; Hoffmann et al., 2022) cũng áp dụng sau InstructAlign nơi các mô hình kích thước lớn hơn có xu hướng hoạt động tốt hơn so với các đối tác nhỏ hơn. Kết quả thí nghiệm chi tiết được mô tả trong Phụ lục D.

6 Phân tích và Thảo luận
6.1 Mục tiêu Căn chỉnh
Để hiểu rõ hơn về hiệu quả của mỗi mục tiêu căn chỉnh, chúng tôi thực hiện các thí nghiệm bằng cách sử dụng một mục tiêu duy nhất, tức là khử nhiễu đơn ngữ (MLM), dịch máy (MT), khử nhiễu song ngữ (TLM) và tương đồng ngữ nghĩa đa ngôn ngữ (XSS), cũng như nhiều mục tiêu trên nhiều tổ hợp khác nhau. Chúng tôi cũng kiểm tra gợi ý zero-shot mà không có bất kỳ giai đoạn thích ứng ngôn ngữ bổ sung nào làm đường cơ sở để so sánh. Lưu ý rằng điều chỉnh hướng dẫn liên tục thông qua trải nghiệm phát lại không được áp dụng (r = 0) trong các thí nghiệm này vì chúng tôi tập trung vào ảnh hưởng của các mục tiêu căn chỉnh.

Như được hiển thị trong Bảng 3, BLOOMZ 560M zero-shot hoạt động tốt hơn đường cơ sở ngẫu nhiên trên L1 trong khi đạt điểm số thấp hơn trên L2, cho thấy rằng BLOOMZ 560M không thể được áp dụng trực tiếp cho các ngôn ngữ L2 này. Đối với InstructAlign với một mục tiêu duy nhất, tương tự như kết quả từ công trình trước (Yong et al., 2022), việc áp dụng mục tiêu MLM làm giảm hiệu suất của mô hình. Tương tự, sử dụng mục tiêu MT cũng làm giảm hiệu suất của cả L1 và L2. Tuy nhiên, như được hiển thị trong Bảng 2, vấn đề này có thể được giảm thiểu bằng cách áp dụng học liên tục. Mặt khác, cả TLM và XSS đều giúp cải thiện mô hình trên L2, chỉ ra rằng các mục tiêu này hiệu quả để căn chỉnh các ngôn ngữ L1 và L2. Ngoài ra, hiệu suất trong các ngôn ngữ L1 cũng được duy trì nhiều nhất khi sử dụng các mục tiêu TLM và XSS.

Khi kết hợp nhiều mục tiêu trong InstructAlign, chúng tôi quan sát điểm số cao nhất khi kết hợp TLM và XSS. Thú vị là, việc thêm các mục tiêu MLM và MT trong InstructAlign luôn mang lại điểm số thấp hơn so với các mục tiêu TLM và XSS đơn lẻ cho cả ngôn ngữ L2 và L1. Những sự thật này gợi ý rằng các mục tiêu đa ngôn ngữ như XSS và TLM, hiệu quả để học các ngôn ngữ mới thông qua điều chỉnh-hướng dẫn đa ngôn ngữ với dữ liệu hạn chế.

--- TRANG 7 ---
Hình 4: ∆weighted F1 của InstructAlign được điều chỉnh BLOOMZ-560M với các mục tiêu (trái) TLM và (phải) XSS trong nhiều phương pháp điều chỉnh hướng dẫn liên tục khác nhau so với đường cơ sở BLOOMZ-560M ban đầu. Điểm số âm chỉ ra rằng mô hình hoạt động tệ hơn so với đường cơ sở.

6.2 Điều chỉnh Hướng dẫn Liên tục
Để đánh giá hiệu quả của điều chỉnh hướng dẫn liên tục thông qua trải nghiệm phát lại, chúng tôi thực hiện một thí nghiệm khám phá ảnh hưởng của số lượng mẫu phát lại khác nhau r được sử dụng trong điều chỉnh hướng dẫn liên tục. Cụ thể, chúng tôi khám phá 4 thiết lập của r, tức là r = [0, 1000, 10000, 100000]. Hình 4 hiển thị hiệu suất của các mô hình được điều chỉnh InstructAlign qua các phạm vi ví dụ phát lại khác nhau r. Khi không sử dụng trải nghiệm phát lại (r = 0), hiệu suất của các ngôn ngữ tiền huấn luyện giảm đáng kể, và thậm chí hơn nữa, hiệu suất trên các ngôn ngữ mới cũng giảm, gợi ý rằng khả năng gợi ý đa tác vụ cho cả hai phương pháp này đều bị suy giảm (Yong et al., 2022). Khi r tăng, sự suy giảm hiệu suất nhỏ hơn nhiều được quan sát trên các ngôn ngữ L1. Thú vị là, hiệu suất trên các ngôn ngữ mới cũng được cải thiện khi r tăng, cuối cùng làm tăng hiệu suất của mô hình trên tất cả các ngôn ngữ. Những sự thật này chứng minh tầm quan trọng của trải nghiệm phát lại để tránh quên thảm khốc trong điều chỉnh hướng dẫn liên tục.

6.3 Tác động của InstructAlign đối với các ngôn ngữ L3
Chúng tôi tiếp tục đánh giá tác động của việc căn chỉnh các ngôn ngữ L2 thông qua InstructAlign đối với các ngôn ngữ Indonesia chưa thấy khác trong cùng nhóm họ ngôn ngữ (L3). Để đánh giá hiệu quả của khả năng chuyển giao từ các ngôn ngữ L2 sang các ngôn ngữ L3, chúng tôi tính hệ số tương quan giữa điểm số ∆weighted F1 trên các ngôn ngữ L2 và L3 cho mỗi mô hình so với đường cơ sở tương ứng, và đo lường hệ số tương quan Pearson (Rodgers and Nicewander, 1988; Freedman et al., 2007).

Như được hiển thị trong Hình 5, hệ số tương quan giữa sự cải thiện hiệu suất của các ngôn ngữ L2 và L3 cao với hệ số tương quan Pearson là 0.96. Điều này chỉ ra hiệu quả của phương pháp InstructAlign không chỉ để thích ứng với các ngôn ngữ L2 mà còn đối với các ngôn ngữ L3 liên quan. Tuy nhiên, sự cải thiện cho ngôn ngữ chưa thấy vẫn phụ thuộc vào khoảng cách ngôn ngữ như được hiển thị trong Hình 6, nơi hiệu suất trên Toba Batak (bbc) và Bugis (bug) mang lại điểm số thấp hơn nhiều so với các ngôn ngữ khác. Kết quả này phù hợp với phân tích từ NusaX (Winata et al., 2022) cho thấy rằng hiệu suất của Bugis (bug) và Toba Batak (bbc) thấp nhất cho cả thiết lập đa tác vụ và zero-shot đa ngôn ngữ do việc trùng lặp từ vựng tương đối thấp so với các ngôn ngữ khác trong NusaX. Điều này gợi ý rằng bằng cách thực hiện, mô hình cũng có thể hiểu các ngôn ngữ chưa thấy có liên quan đến ngôn ngữ mới-được thích ứng, chỉ ra khả năng tổng quát hóa của việc chuyển giao đa ngôn ngữ từ các ngôn ngữ tiền huấn luyện sang các ngôn ngữ mới và chưa thấy.

6.4 Kết luận
Trong công trình này, chúng tôi giải quyết thách thức tăng phạm vi ngôn ngữ của các LLM được điều chỉnh hướng dẫn bằng cách giới thiệu một phương pháp điều chỉnh hướng dẫn liên tục đa ngôn ngữ, InstructAlign. Chúng tôi chứng minh rằng InstructAlign cho phép một LLM được điều chỉnh hướng dẫn học hiệu quả các ngôn ngữ mới thông qua các mục tiêu điều chỉnh hướng dẫn đa ngôn ngữ dựa trên căn chỉnh trong khi duy trì các khả năng đa tác vụ và đa ngôn ngữ hiện có. Dựa trên kết quả thí nghiệm của chúng tôi trên bốn bộ dữ liệu ngôn ngữ địa phương Indonesia, InstructAlign cải thiện hiệu quả việc hiểu các ngôn ngữ địa phương Indonesia mới, cải thiện hiệu suất hiểu ngôn ngữ trên các ngôn ngữ mới khoảng ~5-10% điểm F1 có trọng số và cũng chứng minh hiệu suất chuyển giao tiến tốt hơn đối với các ngôn ngữ địa phương Indonesia chưa thấy khác với biên độ đáng kể. Ngoài ra, chúng tôi phân tích nhiều mục tiêu khác nhau của InstructAlign và chứng minh hiệu quả của các mục tiêu điều chỉnh hướng dẫn đa ngôn ngữ dựa trên căn chỉnh so với mô hình hóa ngôn ngữ có mặt nạ truyền thống (MLM) để học các ngôn ngữ mới với một lượng dữ liệu hạn chế. Công trình của chúng tôi đóng góp vào sự tiến bộ của các phương pháp thích ứng ngôn ngữ cho các LLM được điều chỉnh hướng dẫn, đặc biệt đối với các ngôn ngữ thiếu đại diện.

7 Hạn chế và Công trình Tương lai
7.1 Các Kiến trúc Mô hình Khác
Mặc dù hiệu quả của InstructAlign trên BLOOMZ, hiệu quả của nó chưa được khám phá cho các kiến trúc mô hình khác nhau như encoder-decoder hoặc các kiến trúc mô hình khác. Do ngân sách tính toán hạn chế, chúng tôi chỉ có thể chạy thí nghiệm InstructAlign trên một mô hình chỉ decoder, tức là BLOOMZ, Chúng tôi khuyến khích các công trình tương lai khám phá thí nghiệm trong các kiến trúc mô hình khác.

7.2 Mở rộng đến các LLM Lớn hơn
Như được mô tả trong §5, chúng tôi giả thuyết rằng các mô hình được điều chỉnh InstructAlign tuân theo định luật mở rộng của các mô hình ngôn ngữ (Kaplan et al., 2020; Hoffmann et al., 2022). Tuy nhiên, chúng tôi chỉ có thể chỉ ra thực nghiệm hiệu ứng mở rộng này của InstructAlign trong BLOOMZ-560M và BLOOMZ-1.1B do ngân sách tính toán hạn chế. Chúng tôi kỳ vọng các công trình tương lai mở rộng khám phá đến các mô hình quy mô lớn hơn.

7.3 Các Phương pháp Học Liên tục Khác
Về mặt các phương pháp học liên tục, chúng tôi chỉ khám phá một phương pháp duy nhất, tức là trải nghiệm phát lại (Rolnick et al., 2019), do yêu cầu bộ nhớ hiệu quả của phương pháp này. Phân tích và kiểm tra thêm về các phương pháp học liên tục tiềm năng khác, như A-GEM (Chaudhry et al., 2019a) và EWC (Liu et al., 2018), là một hướng nghiên cứu tiềm năng khác để được khám phá trong các công trình tương lai.

7.4 Các ngôn ngữ Thiếu đại diện từ Họ ngôn ngữ Khác
Có nhiều ngôn ngữ thiếu đại diện khác như các ngôn ngữ bản địa của châu Mỹ (Ebrahimi et al., 2022), châu Phi (Adelani et al., 2021, 2022), Ấn Độ (Kakwani et al., 2020; Kumar et al., 2022), Austronesia (Winata et al., 2022; Cahyawijaya et al., 2023b), và nhiều ngôn ngữ khác trên toàn thế giới. Trong công trình này, chúng tôi chỉ khám phá InstructAlign cho nhóm họ ngôn ngữ Malayo-Polynesia dưới họ ngôn ngữ Austronesia, đặc biệt cho các ngôn ngữ địa phương Indonesia. Đối với công trình tương lai, chúng tôi háo hức khám phá khả năng tổng quát hóa của InstructAlign và các phương pháp thích ứng ngôn ngữ khác trên các ngôn ngữ thiếu đại diện và tài nguyên thấp khác.

Cân nhắc Đạo đức
Công trình của chúng tôi nhấn mạnh tầm quan trọng của tính bao trùm trong công nghệ LLM đối với các ngôn ngữ thiếu đại diện và tài nguyên cực thấp. Trong quá trình nghiên cứu, chúng tôi rất nhận thức về trách nhiệm đạo đức liên quan đến nghiên cứu ngôn ngữ và tác động tiềm năng mà nó có thể có đối với các cộng đồng. Mục tiêu cuối cùng của chúng tôi là thúc đẩy đa dạng ngôn ngữ và đóng góp vào một bối cảnh NLP bao trùm hơn. Chúng tôi khuyến khích hợp tác và tham gia thêm với các cộng đồng ngôn ngữ thiếu đại diện và tài nguyên thấp để đảm bảo rằng tiếng nói của họ được lắng nghe và nhu cầu của họ được giải quyết trong phát triển công nghệ ngôn ngữ tương lai. Chúng tôi cam kết với các nguyên tắc của nghiên cứu đạo đức, đa dạng, bao trùm và công bằng, phấn đấu giảm thiểu thành kiến và thúc đẩy tốt cho xã hội thông qua công trình của chúng tôi trong lĩnh vực NLP.

8 Lời cảm ơn
Chúng tôi cảm ơn Bryan Wilie và Yong Zheng Xin vì những thảo luận và gợi ý hữu ích. Công trình này đã được tài trợ một phần bởi PhD Fellowship Award, Đại học Khoa học và Công nghệ Hồng Kông; và PF20-43679 Chương trình Học bổng Tiến sĩ Hồng Kông, Hội đồng Tài trợ Nghiên cứu, Hồng Kông.

--- TRANG 10 ---
Tài liệu tham khảo
David Adelani, Graham Neubig, Sebastian Ruder,
Shruti Rijhwani, Michael Beukman, Chester Palen-
Michel, Constantine Lignos, Jesujoba Alabi, Sham-
suddeen Muhammad, Peter Nabende, Cheikh
M. Bamba Dione, Andiswa Bukula, Rooweither
Mabuya, Bonaventure F. P. Dossou, Blessing Sibanda,
Happy Buzaaba, Jonathan Mukiibi, Godson Kalipe,
Derguene Mbaye, Amelia Taylor, Fatoumata Ka-
bore, Chris Chinenye Emezue, Anuoluwapo Aremu,
Perez Ogayo, Catherine Gitau, Edwin Munkoh-
Buabeng, Victoire Memdjokam Koagne, Allah-
sera Auguste Tapo, Tebogo Macucwa, Vukosi Mari-
vate, Mboning Tchiaze Elvis, Tajuddeen Gwad-
abe, Tosin Adewumi, Orevaoghene Ahia, Joyce
Nakatumba-Nabende, Neo Lerato Mokono, Ig-
natius Ezeani, Chiamaka Chukwuneke, Mofetoluwa
Oluwaseun Adeyemi, Gilles Quentin Hacheme,
Idris Abdulmumin, Odunayo Ogundepo, Oreen
Yousuf, Tatiana Moteu, và Dietrich Klakow. 2022.
MasakhaNER 2.0: Africa-centric transfer learning
for named entity recognition. Trong Proceedings of
the 2022 Conference on Empirical Methods in Nat-
ural Language Processing, trang 4488–4508, Abu
Dhabi, United Arab Emirates. Association for Com-
putational Linguistics.

David Ifeoluwa Adelani, Jade Abbott, Graham Neu-
big, Daniel D'souza, Julia Kreutzer, Constantine Lig-
nos, Chester Palen-Michel, Happy Buzaaba, Shruti
Rijhwani, Sebastian Ruder, Stephen Mayhew, Is-
rael Abebe Azime, Shamsuddeen H. Muhammad,
Chris Chinenye Emezue, Joyce Nakatumba-Nabende,
Perez Ogayo, Aremu Anuoluwapo, Catherine Gitau,
Derguene Mbaye, Jesujoba Alabi, Seid Muhie Yi-
mam, Tajuddeen Rabiu Gwadabe, Ignatius Ezeani,
Rubungo Andre Niyongabo, Jonathan Mukiibi, Ver-
rah Otiende, Iroro Orife, Davis David, Samba Ngom,
Tosin Adewumi, Paul Rayson, Mofetoluwa Adeyemi,
Gerald Muriuki, Emmanuel Anebi, Chiamaka Chuk-
wuneke, Nkiruka Odu, Eric Peter Wairagala, Samuel
Oyerinde, Clemencia Siro, Tobius Saul Bateesa,
Temilola Oloyede, Yvonne Wambui, Victor Akin-
ode, Deborah Nabagereka, Maurice Katusiime, Ayo-
dele Awokoya, Mouhamadane MBOUP, Dibora Ge-
breyohannes, Henok Tilaye, Kelechi Nwaike, De-
gaga Wolde, Abdoulaye Faye, Blessing Sibanda, Ore-
vaoghene Ahia, Bonaventure F. P. Dossou, Kelechi
Ogueji, Thierno Ibrahima DIOP, Abdoulaye Diallo,
Adewale Akinfaderin, Tendai Marengereke, và Sa-
lomey Osei. 2021. MasakhaNER: Named Entity
Recognition for African Languages. Transactions
of the Association for Computational Linguistics,
9:1116–1131.

Muhammad Farid Adilazuarda, Samuel Cahyawijaya,
và Ayu Purwarianti. 2023. The obscure limitation
of modular multilingual language models.

Muhammad Farid Adilazuarda, Samuel Cahyawijaya,
Genta Indra Winata, Pascale Fung, và Ayu Purwari-
anti. 2022. IndoRobusta: Towards robustness against
diverse code-mixed Indonesian local languages. Trong
Proceedings of the First Workshop on Scaling Up

Multilingual Evaluation, trang 25–34, Online. Asso-
ciation for Computational Linguistics.

Alham Fikri Aji, Genta Indra Winata, Fajri Koto,
Samuel Cahyawijaya, Ade Romadhony, Rahmad Ma-
hendra, Kemal Kurniawan, David Moeljadi, Radi-
tyo Eko Prasojo, Timothy Baldwin, Jey Han Lau,
và Sebastian Ruder. 2022. One country, 700+ lan-
guages: NLP challenges for underrepresented lan-
guages and dialects in Indonesia. Trong Proceedings
of the 60th Annual Meeting of the Association for
Computational Linguistics (Volume 1: Long Papers),
trang 7226–7249, Dublin, Ireland. Association for
Computational Linguistics.

Jesujoba O. Alabi, David Ifeoluwa Adelani, Marius
Mosbach, và Dietrich Klakow. 2022. Adapting pre-
trained language models to African languages via
multilingual adaptive fine-tuning. Trong Proceedings
of the 29th International Conference on Computational
Linguistics, trang 4336–4349, Gyeongju, Republic
of Korea. International Committee on Computational
Linguistics.

Rahaf Aljundi, Francesca Babiloni, Mohamed Elho-
seiny, Marcus Rohrbach, và Tinne Tuytelaars. 2018.
Memory aware synapses: Learning what (not) to
forget. Trong Computer Vision – ECCV 2018, trang
144–161. Springer International Publishing.

Rahaf Aljundi, Punarjay Chakravarty, và Tinne Tuyte-
laars. 2017. Expert gate: Lifelong learning with a
network of experts. Trong 2017 IEEE Conference on
Computer Vision and Pattern Recognition (CVPR).
IEEE.

Akari Asai, Sneha Kudugunta, Xinyan Velocity Yu,
Terra Blevins, Hila Gonen, Machel Reid, Yulia
Tsvetkov, Sebastian Ruder, và Hannaneh Hajishirzi.
2023. Buffet: Benchmarking large language models
for few-shot cross-lingual transfer.

Tom Brown, Benjamin Mann, Nick Ryder, Melanie
Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind
Neelakantan, Pranav Shyam, Girish Sastry, Amanda
Askell, Sandhini Agarwal, Ariel Herbert-Voss,
Gretchen Krueger, Tom Henighan, Rewon Child,
Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens
Winter, Chris Hesse, Mark Chen, Eric Sigler, Ma-
teusz Litwin, Scott Gray, Benjamin Chess, Jack
Clark, Christopher Berner, Sam McCandlish, Alec
Radford, Ilya Sutskever, và Dario Amodei. 2020.
Language models are few-shot learners. Trong Ad-
vances in Neural Information Processing Systems,
tập 33, trang 1877–1901. Curran Associates,
Inc.

Samuel Cahyawijaya, Fajri Koto Holy Lovenia,
Dea Adhista, Emmanuel Dave, Sarah Oktavianti,
Salsabil Maulana Akbar, Jhonson Lee, Nuur Shadieq,
Tjeng Wawan Cenggoro, Hanung Linuwih, Bryan
Wilie, Galih Pradipta Muridan, Alham Fikri Aji,
Genta Indra Winata, David Moeljadi, Ayu Purwari-
anti, và Pascale Fung. 2023a. Nusawrites: Con-
structing high-quality corpora for underrepresented

--- TRANG 11 ---
và extremely low-resource languages. Anonymous
preprint under review.

Samuel Cahyawijaya, Holy Lovenia, Alham Fikri Aji,
Genta Indra Winata, Bryan Wilie, Rahmad Mahendra,
Christian Wibisono, Ade Romadhony, Karissa Vin-
centio, Fajri Koto, Jennifer Santoso, David Moeljadi,
Cahya Wirawan, Frederikus Hudi, Ivan Halim Parmo-
nangan, Ika Alfina, Muhammad Satrio Wicaksono, Il-
ham Firdausi Putra, Samsul Rahmadani, Yulianti Oe-
nang, Ali Akbar Septiandri, James Jaya, Kaustubh D.
Dhole, Arie Ardiyanti Suryani, Rifki Afina Putri,
Dan Su, Keith Stevens, Made Nindyatama Nityasya,
Muhammad Farid Adilazuarda, Ryan Ignatius, Ryan-
dito Diandaru, Tiezheng Yu, Vito Ghifari, Wenliang
Dai, Yan Xu, Dyah Damapuspita, Cuk Tho, Ichwanul
Muslim Karo Karo, Tirana Noor Fatyanosa, Ziwei
Ji, Pascale Fung, Graham Neubig, Timothy Baldwin,
Sebastian Ruder, Herry Sujaini, Sakriani Sakti, và
Ayu Purwarianti. 2023b. Nusacrowd: Open source
initiative for indonesian nlp resources.

Samuel Cahyawijaya, Genta Indra Winata, Bryan Wilie,
Karissa Vincentio, Xiaohong Li, Adhiguna Kun-
coro, Sebastian Ruder, Zhi Yuan Lim, Syafri Ba-
har, Masayu Khodra, Ayu Purwarianti, và Pascale
Fung. 2021. IndoNLG: Benchmark and resources for
evaluating Indonesian natural language generation.
Trong Proceedings of the 2021 Conference on Empiri-
cal Methods in Natural Language Processing, trang
8875–8898, Online và Punta Cana, Dominican Re-
public. Association for Computational Linguistics.

Steven Cao, Nikita Kitaev, và Dan Klein. 2020. Multi-
lingual alignment of contextual word representations.
Trong International Conference on Learning Representa-
tions.

Ethan C. Chau, Lucy H. Lin, và Noah A. Smith. 2020.
Parsing with multilingual BERT, a small corpus, and
a small treebank. Trong Findings of the Association
for Computational Linguistics: EMNLP 2020, trang
1324–1334, Online. Association for Computational
Linguistics.

Arslan Chaudhry, Marc'Aurelio Ranzato, Marcus
Rohrbach, và Mohamed Elhoseiny. 2019a. Efficient
lifelong learning with a-gem. Trong ICLR.

Arslan Chaudhry, Marcus Rohrbach, Mohamed Elho-
seiny, Thalaiyasingam Ajanthan, Puneet K. Dokania,
Philip H. S. Torr, và Marc'Aurelio Ranzato. 2019b.
On tiny episodic memories in continual learning.

Aakanksha Chowdhery, Sharan Narang, Jacob Devlin,
Maarten Bosma, Gaurav Mishra, Adam Roberts,
Paul Barham, Hyung Won Chung, Charles Sutton,
Sebastian Gehrmann, Parker Schuh, Kensen Shi,
Sasha Tsvyashchenko, Joshua Maynez, Abhishek
Rao, Parker Barnes, Yi Tay, Noam Shazeer, Vin-
odkumar Prabhakaran, Emily Reif, Nan Du, Ben
Hutchinson, Reiner Pope, James Bradbury, Jacob
Austin, Michael Isard, Guy Gur-Ari, Pengcheng Yin,
Toju Duke, Anselm Levskaya, Sanjay Ghemawat,
Sunipa Dev, Henryk Michalewski, Xavier Garcia,

Vedant Misra, Kevin Robinson, Liam Fedus, Denny
Zhou, Daphne Ippolito, David Luan, Hyeontaek Lim,
Barret Zoph, Alexander Spiridonov, Ryan Sepassi,
David Dohan, Shivani Agrawal, Mark Omernick, An-
drew M. Dai, Thanumalayan Sankaranarayana Pil-
lai, Marie Pellat, Aitor Lewkowycz, Erica Moreira,
Rewon Child, Oleksandr Polozov, Katherine Lee,
Zongwei Zhou, Xuezhi Wang, Brennan Saeta, Mark
Diaz, Orhan Firat, Michele Catasta, Jason Wei, Kathy
Meier-Hellstern, Douglas Eck, Jeff Dean, Slav Petrov,
và Noah Fiedel. 2022. Palm: Scaling language mod-
eling with pathways.

Hyung Won Chung, Le Hou, Shayne Longpre, Barret
Zoph, Yi Tay, William Fedus, Yunxuan Li, Xuezhi
Wang, Mostafa Dehghani, Siddhartha Brahma, Al-
bert Webson, Shixiang Shane Gu, Zhuyun Dai,
Mirac Suzgun, Xinyun Chen, Aakanksha Chowdh-
ery, Alex Castro-Ros, Marie Pellat, Kevin Robinson,
Dasha Valter, Sharan Narang, Gaurav Mishra, Adams
Yu, Vincent Zhao, Yanping Huang, Andrew Dai,
Hongkun Yu, Slav Petrov, Ed H. Chi, Jeff Dean, Ja-
cob Devlin, Adam Roberts, Denny Zhou, Quoc V. Le,
và Jason Wei. 2022. Scaling instruction-finetuned
language models.

Alexis Conneau và Guillaume Lample. 2019. Cross-
Lingual Language Model Pretraining. Curran Asso-
ciates Inc., Red Hook, NY, USA.

Matthias Delange, Rahaf Aljundi, Marc Masana, Sarah
Parisot, Xu Jia, Ales Leonardis, Greg Slabaugh, và
Tinne Tuytelaars. 2021. A continual learning sur-
vey: Defying forgetting in classification tasks. IEEE
Transactions on Pattern Analysis and Machine Intel-
ligence, trang 1–1.

Tim Dettmers, Mike Lewis, Younes Belkada, và Luke
Zettlemoyer. 2022. Llm.int8(): 8-bit matrix multipli-
cation for transformers at scale.

Jacob Devlin, Ming-Wei Chang, Kenton Lee, và
Kristina Toutanova. 2019. BERT: Pre-training of
deep bidirectional transformers for language under-
standing. Trong Proceedings of the 2019 Conference of
the North American Chapter of the Association for
Computational Linguistics: Human Language Tech-
nologies, Volume 1 (Long and Short Papers), trang
4171–4186, Minneapolis, Minnesota. Association for
Computational Linguistics.

Abteen Ebrahimi và Katharina Kann. 2021. How to
adapt your pretrained multilingual model to 1600
languages. Trong Proceedings of the 59th Annual Meet-
ing of the Association for Computational Linguistics
and the 11th International Joint Conference on Natu-
ral Language Processing (Volume 1: Long Papers),
trang 4555–4567, Online. Association for Computa-
tional Linguistics.

Abteen Ebrahimi, Manuel Mager, Arturo Oncevay,
Vishrav Chaudhary, Luis Chiruzzo, Angela Fan, John
Ortega, Ricardo Ramos, Annette Rios, Ivan Vladimir
Meza Ruiz, Gustavo Giménez-Lugo, Elisabeth
Mager, Graham Neubig, Alexis Palmer, Rolando

--- TRANG 12 ---
Coto-Solano, Thang Vu, và Katharina Kann. 2022.
AmericasNLI: Evaluating zero-shot natural language
understanding of pretrained multilingual models in
truly low-resource languages. Trong Proceedings of
the 60th Annual Meeting of the Association for Compu-
tational Linguistics (Volume 1: Long Papers), trang
6279–6299, Dublin, Ireland. Association for Compu-
tational Linguistics.

David Freedman, Robert Pisani, và Roger Purves.
2007. Statistics (international student edition).
Pisani, R. Purves, 4th edn. WW Norton & Company,
New York.

R French. 1999. Catastrophic forgetting in connection-
ist networks. Trends in Cognitive Sciences, 3(4):128–
135.

Robert M. French. 1993. Catastrophic interference in
connectionist networks: Can it be predicted, can it be
prevented? Trong Proceedings of the 6th International
Conference on Neural Information Processing Sys-
tems, NIPS'93, trang 1176–1177, San Francisco, CA,
USA. Morgan Kaufmann Publishers Inc.

Pascale Fung. 1997. Finding terminology translations
from non-parallel corpora. Trong Fifth Workshop on Very
Large Corpora, VLC 1997, Beijing, China và Hong
Kong, August 18 và August 20, 1997.

Pascale Fung. 1998. A statistical view on bilingual lexi-
con extraction: From parallel corpora to non-parallel
corpora. Trong Machine Translation and the Informa-
tion Soup, Third Conference of the Association for
Machine Translation in the Americas, AMTA '98,
Langhorne, PA, USA, October 28-31, 1998, Proceed-
ings, tập 1529 của Lecture Notes in Computer
Science, trang 1–17. Springer.

Pascale Fung và Percy Cheung. 2004. Mining very-
non-parallel corpora: Parallel sentence and lexicon
extraction via bootstrapping and E. Trong Proceedings
of the 2004 Conference on Empirical Methods in Nat-
ural Language Processing, EMNLP 2004, A meet-
ing of SIGDAT, a Special Interest Group of the ACL,
held in conjunction with ACL 2004, 25-26 July 2004,
Barcelona, Spain, trang 57–63. ACL.

Sebastian Gehrmann, Abhik Bhattacharjee, Abinaya
Mahendiran, Alex Wang, Alexandros Papangelis,
Aman Madaan, Angelina Mcmillan-major, Anna
Shvets, Ashish Upadhyay, Bernd Bohnet, Bingsheng
Yao, Bryan Wilie, Chandra Bhagavatula, Chaobin
You, Craig Thomson, Cristina Garbacea, Dakuo
Wang, Daniel Deutsch, Deyi Xiong, Di Jin, Dimi-
tra Gkatzia, Dragomir Radev, Elizabeth Clark, Esin
Durmus, Faisal Ladhak, Filip Ginter, Genta Indra
Winata, Hendrik Strobelt, Hiroaki Hayashi, Jekate-
rina Novikova, Jenna Kanerva, Jenny Chim, Jiawei
Zhou, Jordan Clive, Joshua Maynez, João Sedoc,
Juraj Juraska, Kaustubh Dhole, Khyathi Raghavi
Chandu, Laura Perez Beltrachini, Leonardo F. R.
Ribeiro, Lewis Tunstall, Li Zhang, Mahim Pushkarna,
Mathias Creutz, Michael White, Mihir Sanjay Kale,

Moussa Kamal Eddine, Nico Daheim, Nishant Subra-
mani, Ondrej Dusek, Paul Pu Liang, Pawan Sasanka
Ammanamanchi, Qi Zhu, Ratish Puduppully, Reno
Kriz, Rifat Shahriyar, Ronald Cardenas, Saad Ma-
hamood, Salomey Osei, Samuel Cahyawijaya, Sanja
Štajner, Sebastien Montella, Shailza Jolly, Simon
Mille, Tahmid Hasan, Tianhao Shen, Tosin Adewumi,
Vikas Raunak, Vipul Raheja, Vitaly Nikolaev, Vivian
Tsai, Yacine Jernite, Ying Xu, Yisi Sang, Yixin Liu,
và Yufang Hou. 2022. GEMv2: Multilingual NLG
benchmarking in a single line of code. Trong Proceed-
ings of the 2022 Conference on Empirical Methods
in Natural Language Processing: System Demonstra-
tions, trang 266–281, Abu Dhabi, UAE. Association
for Computational Linguistics.

I. J. Good. 1952. Rational decisions. Journal of the
Royal Statistical Society. Series B (Methodological),
14(1):107–114.

Naman Goyal, Cynthia Gao, Vishrav Chaudhary, Peng-
Jen Chen, Guillaume Wenzek, Da Ju, Sanjana Kr-
ishnan, Marc'Aurelio Ranzato, Francisco Guzmán,
và Angela Fan. 2021. The flores-101 evaluation
benchmark for low-resource and multilingual ma-
chine translation.

Björn Hammarberg. 2001. Chapter 2. roles of l1 and l2
in l3 production and acquisition. Trong Cross-Linguistic
Influence in Third Language Acquisition, trang 21–
41. Multilingual Matters.

Björn Hammarberg. 2014. 1. problems in defining the
concepts of l1, l2 and l3. Trong Teaching and Learning
in Multilingual Contexts, trang 3–18. Multilingual
Matters.

Jordan Hoffmann, Sebastian Borgeaud, Arthur Mensch,
Elena Buchatskaya, Trevor Cai, Eliza Rutherford,
Diego de las Casas, Lisa Anne Hendricks, Johannes
Welbl, Aidan Clark, Tom Hennigan, Eric Noland,
Katherine Millican, George van den Driessche, Bog-
dan Damoc, Aurelia Guy, Simon Osindero, Karen
Simonyan, Erich Elsen, Oriol Vinyals, Jack William
Rae, và Laurent Sifre. 2022. An empirical analysis
of compute-optimal large language model training.
Trong Advances in Neural Information Processing Sys-
tems.

Arfinda Ilmania, Abdurrahman, Samuel Cahyawijaya,
và Ayu Purwarianti. 2018. Aspect detection and
sentiment classification using deep neural network
for indonesian aspect-based sentiment analysis. Trong
2018 International Conference on Asian Language
Processing (IALP), trang 62–67.

Anubha Kabra, Emmy Liu, Simran Khanuja, Al-
ham Fikri Aji, Genta Winata, Samuel Cahyawijaya,
Anuoluwapo Aremu, Perez Ogayo, và Graham Neu-
big. 2023. Multi-lingual and multi-cultural figurative
language understanding. Trong Findings of the Asso-
ciation for Computational Linguistics: ACL 2023,
trang 8269–8284, Toronto, Canada. Association for
Computational Linguistics.

--- TRANG 13 ---
Divyanshu Kakwani, Anoop Kunchukuttan, Satish
Golla, Gokul N.C., Avik Bhattacharyya, Mitesh M.
Khapra, và Pratyush Kumar. 2020. IndicNLPSuite:
Monolingual corpora, evaluation benchmarks and
pre-trained multilingual language models for Indian
languages. Trong Findings of the Association for Com-
putational Linguistics: EMNLP 2020, trang 4948–
4961, Online. Association for Computational Lin-
guistics.

Jared Kaplan, Sam McCandlish, Tom Henighan, Tom B.
Brown, Benjamin Chess, Rewon Child, Scott Gray,
Alec Radford, Jeffrey Wu, và Dario Amodei. 2020.
Scaling laws for neural language models.

James Kirkpatrick, Razvan Pascanu, Neil Rabinowitz,
Joel Veness, Guillaume Desjardins, Andrei A. Rusu,
Kieran Milan, John Quan, Tiago Ramalho, Ag-
nieszka Grabska-Barwinska, Demis Hassabis, Clau-
dia Clopath, Dharshan Kumaran, và Raia Hadsell.
2017. Overcoming catastrophic forgetting in neural
networks. Proceedings of the National Academy of
Sciences, 114(13):3521–3526.

Fajri Koto, Afshin Rahimi, Jey Han Lau, và Timo-
thy Baldwin. 2020. IndoLEM and IndoBERT: A
benchmark dataset and pre-trained language model
for Indonesian NLP. Trong Proceedings of the 28th Inter-
national Conference on Computational Linguistics,
trang 757–770, Barcelona, Spain (Online). Interna-
tional Committee on Computational Linguistics.

Aman Kumar, Himani Shrotriya, Prachi Sahu, Amogh
Mishra, Raj Dabre, Ratish Puduppully, Anoop
Kunchukuttan, Mitesh M. Khapra, và Pratyush Ku-
mar. 2022. IndicNLG benchmark: Multilingual
datasets for diverse NLG tasks in Indic languages.
Trong Proceedings of the 2022 Conference on Empiri-
cal Methods in Natural Language Processing, trang
5363–5394, Abu Dhabi, United Arab Emirates. As-
sociation for Computational Linguistics.

Guillaume Lample, Alexis Conneau, Ludovic Denoyer,
và Marc'Aurelio Ranzato. 2018a. Unsupervised
machine translation using monolingual corpora only.
Trong International Conference on Learning Representa-
tions.

Guillaume Lample, Alexis Conneau, Marc'Aurelio Ran-
zato, Ludovic Denoyer, và Hervé Jégou. 2018b.
Word translation without parallel data. Trong Interna-
tional Conference on Learning Representations.

Patrick Littell, David R Mortensen, Ke Lin, Katherine
Kairis, Carlisle Turner, và Lori Levin. 2017. Uriel
and lang2vec: Representing languages as typological,
geographical, and phylogenetic vectors. Trong Proceed-
ings of the 15th Conference of the European Chap-
ter of the Association for Computational Linguistics:
Volume 2, Short Papers, tập 2, trang 8–14.

Haokun Liu, Derek Tam, Muqeeth Mohammed, Jay Mo-
hta, Tenghao Huang, Mohit Bansal, và Colin Raffel.
2022. Few-shot parameter-efficient fine-tuning is bet-
ter and cheaper than in-context learning. Trong Advances
in Neural Information Processing Systems.

Xialei Liu, Marc Masana, Luis Herranz, Joost Van de
Weijer, Antonio M. López, và Andrew D. Bagdanov.
2018. Rotate your networks: Better weight con-
solidation and less catastrophic forgetting. Trong 2018
24th International Conference on Pattern Recogni-
tion (ICPR), trang 2262–2268.

David Lopez-Paz và Marc'Aurelio Ranzato. 2017.
Gradient episodic memory for continual learning. Trong
Proceedings of the 31st International Conference on
Neural Information Processing Systems, NIPS'17,
trang 6470–6479, Red Hook, NY, USA. Curran Asso-
ciates Inc.

Ilya Loshchilov và Frank Hutter. 2019. Decoupled
weight decay regularization. Trong International Confer-
ence on Learning Representations.

Rahmad Mahendra, Alham Fikri Aji, Samuel Louvan,
Fahrurrozi Rahman, và Clara Vania. 2021. IndoNLI:
A natural language inference dataset for Indonesian.
Trong Proceedings of the 2021 Conference on Empiri-
cal Methods in Natural Language Processing, trang
10511–10527, Online và Punta Cana, Dominican
Republic. Association for Computational Linguistics.

Chaitanya Malaviya, Graham Neubig, và Patrick Lit-
tell. 2017. Learning language representations for
typology prediction. Trong Conference on Empirical
Methods in Natural Language Processing (EMNLP),
Copenhagen, Denmark.

Arun Mallya và Svetlana Lazebnik. 2018. Packnet:
Adding multiple tasks to a single network by iterative
pruning. Trong Proceedings of the IEEE conference
on Computer Vision and Pattern Recognition, trang
7765–7773.

Paulius Micikevicius, Sharan Narang, Jonah Alben, Gre-
gory Diamos, Erich Elsen, David Garcia, Boris Gins-
burg, Michael Houston, Oleksii Kuchaiev, Ganesh
Venkatesh, và Hao Wu. 2018. Mixed precision train-
ing.

Niklas Muennighoff, Thomas Wang, Lintang Sutawika,
Adam Roberts, Stella Biderman, Teven Le Scao,
M Saiful Bari, Sheng Shen, Zheng-Xin Yong, Hai-
ley Schoelkopf, Xiangru Tang, Dragomir Radev, Al-
ham Fikri Aji, Khalid Almubarak, Samuel Albanie,
Zaid Alyafeai, Albert Webson, Edward Raff, và
Colin Raffel. 2022. Crosslingual generalization
through multitask finetuning.

Benjamin Muller, Antonios Anastasopoulos, Benoît
Sagot, và Djamé Seddah. 2021. When being un-
seen from mBERT is just the beginning: Handling
new languages with multilingual language models.
Trong Proceedings of the 2021 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics: Human Language Technologies,
trang 448–462, Online. Association for Computa-
tional Linguistics.

Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Car-
roll L. Wainwright, Pamela Mishkin, Chong Zhang,

--- TRANG 14 ---
Sandhini Agarwal, Katarina Slama, Alex Ray, John
Schulman, Jacob Hilton, Fraser Kelton, Luke Miller,
Maddie Simens, Amanda Askell, Peter Welinder,
Paul Christiano, Jan Leike, và Ryan Lowe. 2022.
Training language models to follow instructions with
human feedback.

Jonas Pfeiffer, Ivan Vulić, Iryna Gurevych, và Se-
bastian Ruder. 2020. MAD-X: An Adapter-Based
Framework for Multi-Task Cross-Lingual Transfer.
Trong Proceedings of the 2020 Conference on Empirical
Methods in Natural Language Processing (EMNLP),
trang 7654–7673, Online. Association for Computa-
tional Linguistics.

Ayu Purwarianti và Ida Ayu Putu Ari Crisdayanti. 2019.
Improving bi-lstm performance for indonesian senti-
ment analysis using paragraph vector. Trong 2019 Inter-
national Conference of Advanced Informatics: Con-
cepts, Theory and Applications (ICAICTA), trang
1–5.

Oddy Virgantara Putra, Fathin Muhammad Wasman-
son, Triana Harmini, và Shoffin Nahwa Utama.
2020. Sundanese twitter dataset for emotion clas-
sification. Trong 2020 International Conference on Com-
puter Engineering, Network, and Intelligent Multime-
dia (CENIM), trang 391–395.

Jack W. Rae, Sebastian Borgeaud, Trevor Cai, Katie
Millican, Jordan Hoffmann, Francis Song, John
Aslanides, Sarah Henderson, Roman Ring, Susan-
nah Young, Eliza Rutherford, Tom Hennigan, Ja-
cob Menick, Albin Cassirer, Richard Powell, George
van den Driessche, Lisa Anne Hendricks, Mari-
beth Rauh, Po-Sen Huang, Amelia Glaese, Jo-
hannes Welbl, Sumanth Dathathri, Saffron Huang,
Jonathan Uesato, John Mellor, Irina Higgins, Anto-
nia Creswell, Nat McAleese, Amy Wu, Erich Elsen,
Siddhant Jayakumar, Elena Buchatskaya, David Bud-
den, Esme Sutherland, Karen Simonyan, Michela Pa-
ganini, Laurent Sifre, Lena Martens, Xiang Lorraine
Li, Adhiguna Kuncoro, Aida Nematzadeh, Elena
Gribovskaya, Domenic Donato, Angeliki Lazaridou,
Arthur Mensch, Jean-Baptiste Lespiau, Maria Tsim-
poukelli, Nikolai Grigorev, Doug Fritz, Thibault Sot-
tiaux, Mantas Pajarskas, Toby Pohlen, Zhitao Gong,
Daniel Toyama, Cyprien de Masson d'Autume, Yujia
Li, Tayfun Terzi, Vladimir Mikulik, Igor Babuschkin,
Aidan Clark, Diego de Las Casas, Aurelia Guy,
Chris Jones, James Bradbury, Matthew Johnson,
Blake Hechtman, Laura Weidinger, Iason Gabriel,
William Isaac, Ed Lockhart, Simon Osindero, Laura
Rimell, Chris Dyer, Oriol Vinyals, Kareem Ayoub,
Jeff Stanway, Lorrayne Bennett, Demis Hassabis, Ko-
ray Kavukcuoglu, và Geoffrey Irving. 2022. Scaling
language models: Methods, analysis & insights from
training gopher.

Joseph Lee Rodgers và W. Alan Nicewander. 1988.
Thirteen ways to look at the correlation coefficient.
The American Statistician, 42(1):59–66.

David Rolnick, Arun Ahuja, Jonathan Schwarz, Timo-
thy Lillicrap, và Gregory Wayne. 2019. Experience

replay for continual learning. Trong Advances in Neural
Information Processing Systems, tập 32. Curran
Associates, Inc.

Victor Sanh, Albert Webson, Colin Raffel, Stephen
Bach, Lintang Sutawika, Zaid Alyafeai, Antoine
Chaffin, Arnaud Stiegler, Arun Raja, Manan Dey,
M Saiful Bari, Canwen Xu, Urmish Thakker,
Shanya Sharma Sharma, Eliza Szczechla, Taewoon
Kim, Gunjan Chhablani, Nihal Nayak, Debajyoti
Datta, Jonathan Chang, Mike Tian-Jian Jiang, Han
Wang, Matteo Manica, Sheng Shen, Zheng Xin Yong,
Harshit Pandey, Rachel Bawden, Thomas Wang, Tr-
ishala Neeraj, Jos Rozen, Abheesht Sharma, An-
drea Santilli, Thibault Fevry, Jason Alan Fries, Ryan
Teehan, Teven Le Scao, Stella Biderman, Leo Gao,
Thomas Wolf, và Alexander M Rush. 2022. Multi-
task prompted training enables zero-shot task gener-
alization. Trong International Conference on Learning
Representations.

Teven Le Scao, Angela Fan, Christopher Akiki, El-
lie Pavlick, Suzana Ilić, Daniel Hesslow, Roman
Castagné, Alexandra Sasha Luccioni, François Yvon,
Matthias Gallé, Jonathan Tow, Alexander M. Rush,
Stella Biderman, Albert Webson, Pawan Sasanka Am-
manamanchi, Thomas Wang, Benoît Sagot, Niklas
Muennighoff, Albert Villanova del Moral, Olatunji
Ruwase, Rachel Bawden, Stas Bekman, Angelina
McMillan-Major, Iz Beltagy, Huu Nguyen, Lucile
Saulnier, Samson Tan, Pedro Ortiz Suarez, Vic-
tor Sanh, Hugo Laurençon, Yacine Jernite, Julien
Launay, Margaret Mitchell, Colin Raffel, Aaron
Gokaslan, Adi Simhi, Aitor Soroa, Alham Fikri
Aji, Amit Alfassy, Anna Rogers, Ariel Kreisberg
Nitzav, Canwen Xu, Chenghao Mou, Chris Emezue,
Christopher Klamm, Colin Leong, Daniel van Strien,
David Ifeoluwa Adelani, Dragomir Radev, Ed-
uardo González Ponferrada, Efrat Levkovizh, Ethan
Kim, Eyal Bar Natan, Francesco De Toni, Gérard
Dupont, Germán Kruszewski, Giada Pistilli, Hady
Elsahar, Hamza Benyamina, Hieu Tran, Ian Yu, Idris
Abdulmumin, Isaac Johnson, Itziar Gonzalez-Dios,
Javier de la Rosa, Jenny Chim, Jesse Dodge, Jian Zhu,
Jonathan Chang, Jörg Frohberg, Joseph Tobing, Joy-
deep Bhattacharjee, Khalid Almubarak, Kimbo Chen,
Kyle Lo, Leandro Von Werra, Leon Weber, Long
Phan, Loubna Ben allal, Ludovic Tanguy, Manan
Dey, Manuel Romero Muñoz, Maraim Masoud,
María Grandury, Mario Šaško, Max Huang, Max-
imin Coavoux, Mayank Singh, Mike Tian-Jian Jiang,
Minh Chien Vu, Mohammad A. Jauhar, Mustafa
Ghaleb, Nishant Subramani, Nuru-
laqilla Khamis, Olivier Nguyen, Omar Espejel, Ona
de Gibert, Paulo Villegas, Peter Henderson, Pierre
Colombo, Priscilla Amuok, Quentin Lhoest, Rheza
Harliman, Rishi Bommasani, Roberto Luis López,
Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-
bastian Nagel, Shamik Bose, Shamsuddeen Hassan
Muhammad, Shanya Sharma, Shayne Longpre, So-
maieh Nikpoor, Stanislav Silberberg, Suhas Pai, Syd-
ney Zink, Tiago Timponi Torrent, Timo Schick, Tris-
tan Thrush, Valentin Danchev, Vassilina Nikoulina,
Veronika Laippala, Violette Lepercq, Vrinda Prabhu,

--- TRANG 15 ---
Zaid Alyafeai, Zeerak Talat, Arun Raja, Benjamin
Heinzerling, Chenglei Si, Elizabeth Salesky, Sab-
rina J. Mielke, Wilson Y. Lee, Abheesht Sharma, An-
drea Santilli, Antoine Chaffin, Arnaud Stiegler, Deba-
jyoti Datta, Eliza Szczechla, Gunjan Chhablani, Han
Wang, Harshit Pandey, Hendrik Strobelt, Jason Alan
Fries, Jos Rozen, Leo Gao, Lintang Sutawika, M Sai-
ful Bari, Maged S. Al-shaibani, Matteo Manica, Ni-
hal Nayak, Ryan Teehan, Samuel Albanie, Sheng
Shen, Srulik Ben-David, Stephen H. Bach, Taewoon
Kim, Tali Bers, Thibault Fevry, Trishala Neeraj, Ur-
mish Thakker, Vikas Raunak, Xiangru Tang, Zheng-
Xin Yong, Zhiqing Sun, Shaked Brody, Yallow Uri,
Hadar Tojarieh, Adam Roberts, Hyung Won Chung,
Jaesung Tae, Jason Phang, Ofir Press, Conglong Li,
Deepak Narayanan, Hatim Bourfoune, Jared Casper,
Jeff Rasley, Max Ryabinin, Mayank Mishra, Minjia
Zhang, Mohammad Shoeybi, Myriam Peyrounette,
Nicolas Patry, Nouamane Tazi, Omar Sanseviero,
Patrick von Platen, Pierre Cornette, Pierre François
Lavallée, Rémi Lacroix, Samyam Rajbhandari, San-
chit Gandhi, Shaden Smith, Stéphane Requena, Suraj
Patil, Tim Dettmers, Ahmed Baruwa, Amanpreet
Singh, Anastasia Cheveleva, Anne-Laure Ligozat,
Arjun Subramonian, Aurélie Névéol, Charles Lover-
ing, Dan Garrette, Deepak Tunuguntla, Ehud Reiter,
Ekaterina Taktasheva, Ekaterina Voloshina, Eli Bog-
danov, Genta Indra Winata, Hailey Schoelkopf, Jan-
Christoph Kalo, Jekaterina Novikova, Jessica Zosa
Forde, Jordan Clive, Jungo Kasai, Ken Kawamura,
Liam Hazan, Marine Carpuat, Miruna Clinciu, Na-
joung Kim, Newton Cheng, Oleg Serikov, Omer
Antverg, Oskar van der Wal, Rui Zhang, Ruochen
Zhang, Sebastian Gehrmann, Shani Pais, Tatiana
Shavrina, Thomas Scialom, Tian Yun, Tomasz Lim-
isiewicz, Verena Rieser, Vitaly Protasov, Vladislav
Mikhailov, Yada Pruksachatkun, Yonatan Belinkov,
Zachary Bamberger, Zdeněk Kasner, Alice Rueda,
Amanda Pestana, Amir Feizpour, Ammar Khan, Amy
Faranak, Ana Santos, Anthony Hevia, Antigona Unl-
dreaj, Arash Aghagol, Arezoo Abdollahi, Aycha Tam-
mour, Azadeh HajiHosseini, Bahareh Behroozi, Ben-
jamin Ajibade, Bharat Saxena, Carlos Muñoz Ferran-
dis, Danish Contractor, David Lansky, Davis David,
Douwe Kiela, Duong A. Nguyen, Edward Tan, Emi
Baylor, Ezinwanne Ozoani, Fatima Mirza, Frankline
Ononiwu, Habib Rezanejad, Hessie Jones, Indrani
Bhattacharya, Irene Solaiman, Irina Sedenko, Isar
Nejadgholi, Jesse Passmore, Josh Seltzer, Julio Bo-
nis Sanz, Karen Fort, Livia Dutra, Mairon Sama-
gaio, Maraim Elbadri, Margot Mieskes, Marissa Ger-
chick, Martha Akinlolu, Michael McKenna, Mike
Qiu, Muhammed Ghauri, Mykola Burynok, Nafis
Abrar, Nazneen Rajani, Nour Elkott, Nour Fahmy,
Olanrewaju Samuel, Ran An, Rasmus Kromann,
Ryan Hao, Samira Alizadeh, Sarmad Shubber, Silas
Wang, Sourav Roy, Sylvain Viguier, Thanh Le, Tobi
Oyebade, Trieu Le, Yoyo Yang, Zach Nguyen, Ab-
hinav Ramesh Kashyap, Alfredo Palasciano, Al-
ison Callahan, Anima Shukla, Antonio Miranda-
Escalada, Ayush Singh, Benjamin Beilharz, Bo Wang,
Caio Brito, Chenxi Zhou, Chirag Jain, Chuxin
Xu, Clémentine Fourrier, Daniel León Periñán,

Daniel Molano, Dian Yu, Enrique Manjavacas, Fabio
Barth, Florian Fuhrimann, Gabriel Altay, Giyased-
din Bayrak, Gully Burns, Helena U. Vrabec, Imane
Bello, Ishani Dash, Jihyun Kang, John Giorgi, Jonas
Golde, Jose David Posada, Karthik Rangasai Sivara-
man, Lokesh Bulchandani, Lu Liu, Luisa Shinzato,
Madeleine Hahn de Bykhovetz, Maiko Takeuchi,
Marc Pàmies, Maria A Castillo, Marianna Nezhurina,
Mario Sänger, Matthias Samwald, Michael Cullan,
Michael Weinberg, Michiel De Wolf, Mina Mihalj-
cic, Minna Liu, Moritz Freidank, Myungsun Kang,
Natasha Seelam, Nathan Dahlberg, Nicholas Michio
Broad, Nikolaus Muellner, Pascale Fung, Patrick
Haller, Ramya Chandrasekhar, Renata Eisenberg,
Robert Martin, Rodrigo Canalli, Rosaline Su, Ruisi
Su, Samuel Cahyawijaya, Samuele Garda, Shlok S
Deshmukh, Shubhanshu Mishra, Sid Kiblawi, Si-
mon Ott, Sinee Sang-aroonsiri, Srishti Kumar, Ste-
fan Schweter, Sushil Bharati, Tanmay Laud, Théo
Gigant, Tomoya Kainuma, Wojciech Kusa, Yanis
Labrak, Yash Shailesh Bajaj, Yash Venkatraman, Yi-
fan Xu, Yingxin Xu, Yu Xu, Zhe Tan, Zhongli Xie, Zi-
fan Ye, Mathilde Bras, Younes Belkada, và Thomas
Wolf. 2022. Bloom: A 176b-parameter open-access
multilingual language model.

Joan Serrà, Dídac Surís, Marius Miron, và Alexan-
dros Karatzoglou. 2018. Overcoming catastrophic
forgetting with hard attention to the task. Trong ICML.

Shaden Smith, Mostofa Patwary, Brandon Norick,
Patrick LeGresley, Samyam Rajbhandari, Jared
Casper, Zhun Liu, Shrimai Prabhumoye, George
Zerveas, Vijay Korthikanti, Elton Zhang, Rewon
Child, Reza Yazdani Aminabadi, Julie Bernauer, Xia
Song, Mohammad Shoeybi, Yuxiong He, Michael
Houston, Saurabh Tiwary, và Bryan Catanzaro.
2022. Using deepspeed and megatron to train
megatron-turing nlg 530b, a large-scale generative
language model.

Yueqi Song, Catherine Cui, Simran Khanuja, Pengfei
Liu, Fahim Faisal, Alissa Ostapenko, Genta Indra
Winata, Alham Fikri Aji, Samuel Cahyawijaya, Yu-
lia Tsvetkov, Antonios Anastasopoulos, và Graham
Neubig. 2023. Globalbench: A benchmark for global
progress in natural language processing.

Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann
Dubois, Xuechen Li, Carlos Guestrin, Percy
Liang, và Tatsunori B. Hashimoto. 2023. Stan-
ford alpaca: An instruction-following llama
model. https://github.com/tatsu-lab/
stanford_alpaca.

NLLB Team, Marta R. Costa-jussà, James Cross, Onur
Çelebi, Maha Elbayad, Kenneth Heafield, Kevin Hef-
fernan, Elahe Kalbassi, Janice Lam, Daniel Licht,
Jean Maillard, Anna Sun, Skyler Wang, Guillaume
Wenzek, Al Youngblood, Bapi Akula, Loic Bar-
rault, Gabriel Mejia Gonzalez, Prangthip Hansanti,
John Hoffman, Semarley Jarrett, Kaushik Ram
Sadagopan, Dirk Rowe, Shannon Spruit, Chau
Tran, Pierre Andrews, Necip Fazil Ayan, Shruti
Bhosale, Sergey Edunov, Angela Fan, Cynthia

--- TRANG 16 ---
Gao, Vedanuj Goswami, Francisco Guzmán, Philipp
Koehn, Alexandre Mourachko, Christophe Ropers,
Safiyyah Saleem, Holger Schwenk, và Jeff Wang.
2022. No language left behind: Scaling human-
centered machine translation.

Romal Thoppilan, Daniel De Freitas, Jamie Hall,
Noam Shazeer, Apoorv Kulshreshtha, Heng-Tze
Cheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du,
YaGuang Li, Hongrae Lee, Huaixiu Steven Zheng,
Amin Ghafouri, Marcelo Menegali, Yanping Huang,
Maxim Krikun, Dmitry Lepikhin, James Qin, Dehao
Chen, Yuanzhong Xu, Zhifeng Chen, Adam Roberts,
Maarten Bosma, Vincent Zhao, Yanqi Zhou, Chung-
Ching Chang, Igor Krivokon, Will Rusch, Marc
Pickett, Pranesh Srinivasan, Laichee Man, Kathleen
Meier-Hellstern, Meredith Ringel Morris, Tulsee
Doshi, Renelito Delos Santos, Toju Duke, Johnny So-
raker, Ben Zevenbergen, Vinodkumar Prabhakaran,
Mark Diaz, Ben Hutchinson, Kristen Olson, Ale-
jandra Molina, Erin Hoffman-John, Josh Lee, Lora
Aroyo, Ravi Rajakumar, Alena Butryna, Matthew
Lamm, Viktoriya Kuzmina, Joe Fenton, Aaron Co-
hen, Rachel Bernstein, Ray Kurzweil, Blaise Aguera-
Arcas, Claire Cui, Marian Croak, Ed Chi, và Quoc
Le. 2022. Lamda: Language models for dialog appli-
cations.

Jason Wei, Maarten Bosma, Vincent Y. Zhao, Kelvin
Guu, Adams Wei Yu, Brian Lester, Nan Du, An-
drew M. Dai, và Quoc V. Le. 2022a. Finetuned
language models are zero-shot learners.

Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel,
Barret Zoph, Sebastian Borgeaud, Dani Yogatama,
Maarten Bosma, Denny Zhou, Donald Metzler, Ed H.
Chi, Tatsunori Hashimoto, Oriol Vinyals, Percy
Liang, Jeff Dean, và William Fedus. 2022b. Emer-
gent abilities of large language models. Transactions
on Machine Learning Research. Survey Certifica-
tion.

Bryan Wilie, Karissa Vincentio, Genta Indra Winata,
Samuel Cahyawijaya, Xiaohong Li, Zhi Yuan Lim,
Sidik Soleman, Rahmad Mahendra, Pascale Fung,
Syafri Bahar, và Ayu Purwarianti. 2020. IndoNLU:
Benchmark and resources for evaluating Indonesian
natural language understanding. Trong Proceedings of
the 1st Conference of the Asia-Pacific Chapter of the
Association for Computational Linguistics and the
10th International Joint Conference on Natural Lan-
guage Processing, trang 843–857, Suzhou, China.
Association for Computational Linguistics.

Genta Indra Winata, Alham Fikri Aji, Samuel Cahyaw-
ijaya, Rahmad Mahendra, Fajri Koto, Ade Ro-
madhony, Kemal Kurniawan, David Moeljadi, Ra-
dityo Eko Prasojo, Pascale Fung, et al. 2022.
Nusax: Multilingual parallel sentiment dataset for
10 indonesian local languages. arXiv preprint
arXiv:2205.15960.

Wilson Wongso, David Samuel Setiawan, và Derwin
Suhartono. 2021. Causal and masked language mod-
eling of javanese language using transformer-based

architectures. Trong 2021 International Conference on
Advanced Computer Science and Information Sys-
tems (ICACSIS), trang 1–7.

Linting Xue, Noah Constant, Adam Roberts, Mihir Kale,
Rami Al-Rfou, Aditya Siddhant, Aditya Barua, và
Colin Raffel. 2021. mT5: A massively multilingual
pre-trained text-to-text transformer. Trong Proceedings
of the 2021 Conference of the North American Chap-
ter of the Association for Computational Linguistics:
Human Language Technologies, trang 483–498, On-
line. Association for Computational Linguistics.

Zheng-Xin Yong, Hailey Schoelkopf, Niklas Muen-
nighoff, Alham Fikri Aji, David Ifeoluwa Adelani,
Khalid Almubarak, M Saiful Bari, Lintang Sutawika,
Jungo Kasai, Ahmed Baruwa, Genta Indra Winata,
Stella Biderman, Dragomir Radev, và Vassilina
Nikoulina. 2022. Bloom+1: Adding language sup-
port to bloom for zero-shot prompting.

Zheng-Xin Yong, Ruochen Zhang, Jessica Zosa Forde,
Skyler Wang, Samuel Cahyawijaya, Holy Lovenia,
Genta Indra Winata, Lintang Sutawika, Jan Christian
Blaise Cruz, Long Phan, et al. 2023. Prompting
multilingual large language models to generate code-
mixed texts: The case of south east asian languages.
arXiv preprint arXiv:2303.13592.

Aohan Zeng, Xiao Liu, Zhengxiao Du, Zihan Wang,
Hanyu Lai, Ming Ding, Zhuoyi Yang, Yifan Xu,
Wendi Zheng, Xiao Xia, Weng Lam Tam, Zixuan
Ma, Yufei Xue, Jidong Zhai, Wenguang Chen, Peng
Zhang, Yuxiao Dong, và Jie Tang. 2022. Glm-130b:
An open bilingual pre-trained model.

Ruochen Zhang, Samuel Cahyawijaya, Jan Chris-
tian Blaise Cruz, và Alham Fikri Aji. 2023. Mul-
tilingual large language models are not (yet) code-
switchers.

--- TRANG 17 ---
A Danh sách Lời nhắc
Trong phần này, chúng tôi cung cấp danh sách các lời nhắc được sử dụng trong thí nghiệm của chúng tôi. Đối với InstructAlign, chúng tôi sử dụng 6 lời nhắc cho mỗi mục tiêu. Danh sách lời nhắc cho khử nhiễu song ngữ (TLM), dịch máy (MT), tương đồng ngữ nghĩa đa ngôn ngữ (XSS), và khử nhiễu đơn ngữ (MLM) được hiển thị trong Bảng 4, Bảng 5, Bảng 6, và Bảng 7, tương ứng. Đối với đánh giá, chúng tôi sử dụng 3 lời nhắc tiếng Anh cho mỗi tác vụ. Danh sách lời nhắc cho các tác vụ phân tích cảm xúc, nhận diện cảm xúc, và phân loại chủ đề được mô tả trong Bảng 8, Bảng 9, và Bảng 10, tương ứng.

B So sánh giữa LLM-int8() và Suy luận Độ chính xác Đầy đủ
Chúng tôi chạy tất cả suy luận trong thí nghiệm của mình với lượng tử hóa 8-bit sử dụng LLM.int8() (Dettmers et al., 2022). Theo hiểu biết tốt nhất của chúng tôi, hiệu quả của LLM.int8() (Dettmers et al., 2022) chưa bao giờ được đánh giá trên gợi ý zero-shot trong các trường hợp ngôn ngữ tài nguyên thấp. Chúng tôi đánh giá các bộ dữ liệu từ nhiều ngôn ngữ Indonesia và địa phương được nói ở Indonesia được liệt kê trong IndoNLU (Wilie et al., 2020) và NusaCrowd (Cahyawijaya et al., 2023b). Cụ thể, chúng tôi đánh giá trên 10 ngôn ngữ trong NusaX (Winata et al., 2022), Javanese IMDB (Wongso et al., 2021), IndoLEM Sentiment (Koto et al., 2020), IndoNLI (Mahendra et al., 2021), SmSA (Purwarianti and Crisdayanti, 2019), CASA (Ilmania et al., 2018), và các bộ dữ liệu Sundanese Twitter Dataset for Emotion (Putra et al., 2020). Dựa trên kết quả được hiển thị trong Bảng 11, chỉ có sự khác biệt hiệu suất nhỏ giữa lượng tử hóa 8-bit với LLM.int8() so với các mô hình độ chính xác đầy đủ, gợi ý khả năng tổng quát hóa của LLM.int8() (Dettmers et al., 2022) cho gợi ý zero-shot trong các ngôn ngữ tài nguyên thấp.

C Chi tiết Bộ dữ liệu
Trong phần này, chúng tôi mô tả thống kê cho mỗi bộ dữ liệu được sử dụng trong thí nghiệm. Bảng 12 hiển thị thống kê cho tác vụ phân tích cảm xúc của NusaTranslation (Cahyawijaya et al., 2023a). Đối với tập con Indonesia, chúng tôi lấy fold đầu tiên của IndoLEM sentiment (Koto et al., 2020), là bộ dữ liệu phân tích cảm xúc Indonesia được sử dụng làm câu nguồn trong NusaTranslation (Cahyawijaya et al., 2023a). Bảng 13 hiển thị thống kê cho tác vụ phân tích cảm xúc của NusaX (Winata et al., 2022). Bảng 14 và Bảng 15 hiển thị thống kê cho các tác vụ nhận diện cảm xúc và phân loại chủ đề của NusaParagraph (Cahyawijaya et al., 2023a), tương ứng.

D Kết quả Thí nghiệm Chi tiết
Trong phần này, chúng tôi cung cấp kết quả thí nghiệm hoàn chỉnh theo từng bộ dữ liệu. Bảng 16 hiển thị kết quả thí nghiệm trên tác vụ phân tích cảm xúc của NusaTranslation. Bảng 17 hiển thị kết quả thí nghiệm trên tác vụ phân tích cảm xúc của NusaX (Winata et al., 2022). Bảng 18 và Bảng 19 hiển thị kết quả thí nghiệm trên các tác vụ nhận diện cảm xúc và phân loại chủ đề của NusaParagraph, tương ứng.

--- TRANG 18 ---
Lời nhắc trong Tác vụ Khử nhiễu Song ngữ (TLM)
[INPUT_TEXT]. Khử nhiễu văn bản [INPUT_LANG] trước đó thành câu tương đương trong [CONTEXT_LANG]: [CONTEXT]\n[LABEL_TEXT]
Ngữ cảnh trong [CONTEXT_LANG]: [CONTEXT]\nSửa văn bản [INPUT_LANG] sau "[INPUT_TEXT]" đảm bảo ý nghĩa tương đương với ngữ cảnh. [LABEL_TEXT]
Ngữ cảnh trong [CONTEXT_LANG]: [CONTEXT]\nVăn bản nhiễu trong [INPUT_LANG]: [INPUT_TEXT]\nBạn sẽ sửa câu [INPUT_LANG] như thế nào để làm cho ý nghĩa giống như ngữ cảnh? [LABEL_TEXT]
[INPUT_TEXT]. Khử nhiễu câu [INPUT_LANG] trước đó thành câu tương đương: [CONTEXT]\n[LABEL_TEXT]
Ngữ cảnh: [CONTEXT]\nSửa văn bản [INPUT_LANG] sau "[INPUT_TEXT]" đảm bảo ý nghĩa tương đương với ngữ cảnh. [LABEL_TEXT]
Ngữ cảnh: [CONTEXT]\nVăn bản nhiễu trong [INPUT_LANG]: [INPUT_TEXT]\nBạn sẽ sửa câu [INPUT_LANG] như thế nào để làm cho ý nghĩa giống như câu [CONTEXT_LANG]? [LABEL_TEXT]
Bảng 4: Lời nhắc được sử dụng cho tác vụ Khử nhiễu Song ngữ (TLM)

Lời nhắc trong Tác vụ Dịch máy (MT)
Dịch văn bản sau từ [SOURCE_LANG] sang [TARGET_LANG].\nVăn bản: [SOURCE_TEXT]\nBản dịch: [TARGET_TEXT]
[SOURCE_TEXT]\nDịch văn bản trên từ [SOURCE_LANG] sang [TARGET_LANG]. [TARGET_TEXT]
Văn bản trong [SOURCE_LANG]: [SOURCE_TEXT]\nBạn sẽ dịch điều đó như thế nào trong [TARGET_LANG]? [TARGET_TEXT]
Dịch văn bản sau sang [TARGET_LANG].\nVăn bản: [SOURCE_TEXT]\nBản dịch: [TARGET_TEXT]
[SOURCE_TEXT]\nDịch văn bản trên sang [TARGET_LANG]. [TARGET_TEXT]
Văn bản đầu vào: [SOURCE_TEXT]\nBạn sẽ dịch điều đó như thế nào thành [TARGET_LANG]? [TARGET_TEXT]
Bảng 5: Lời nhắc được sử dụng cho tác vụ Dịch máy (MT)

Lời nhắc trong Tác vụ Tương đồng Ngữ nghĩa Đa ngôn ngữ (XSS)
Câu [SOURCE_LANG]: [SOURCE_TEXT]\nCâu [TARGET_LANG]: [TARGET_TEXT]\nHai câu có cùng ý nghĩa không? [LABEL]
Câu A: [SOURCE_TEXT]\nCâu B: [TARGET_TEXT]\nCâu A và câu B có cùng ý nghĩa không? [LABEL]
Câu [SOURCE_LANG]: [SOURCE_TEXT]\nCâu [TARGET_LANG]: [TARGET_TEXT]\nHai câu có tương đương không? [LABEL]
Câu A: [SOURCE_TEXT]\nCâu B: [TARGET_TEXT]\nCâu A và câu B có tương đương không? [LABEL]
Câu [SOURCE_LANG] "[SOURCE_TEXT]" có tương đương với câu [TARGET_LANG] "[TARGET_TEXT]" không? [LABEL]
Câu "[SOURCE_TEXT]" có tương đương với câu "[TARGET_TEXT]" không? [LABEL]
Bảng 6: Lời nhắc được sử dụng cho tác vụ Tương đồng Ngữ nghĩa Đa ngôn ngữ (XSS)

--- TRANG 19 ---
Lời nhắc trong Tác vụ Khử nhiễu Đơn ngữ (MLM)
Khử nhiễu văn bản [SOURCE_LANG] nhiễu sau: "[SOURCE_TEXT]", để tạo thành một câu đúng. [TARGET_TEXT]
Sửa và hoàn thành câu [SOURCE_LANG] sau: [SOURCE_TEXT]\n[TARGET_TEXT]
Câu trong [SOURCE_LANG]: [SOURCE_TEXT]\nBạn sẽ sửa câu như thế nào để tạo thành một câu đúng? [TARGET_TEXT]
Khử nhiễu văn bản nhiễu sau "[SOURCE_TEXT]" để tạo thành một câu [SOURCE_LANG] đúng. [TARGET_TEXT]
Sửa và hoàn thành câu sau: [SOURCE_TEXT]\n[TARGET_TEXT]
Văn bản đầu vào: [SOURCE_TEXT]\nBạn sẽ sửa câu như thế nào để tạo thành một câu [SOURCE_LANG] đúng? [TARGET_TEXT]
Bảng 7: Lời nhắc được sử dụng cho tác vụ Khử nhiễu Đơn ngữ (MLM)

Lời nhắc trong Tác vụ Phân tích Cảm xúc
[INPUT]\nCảm xúc của văn bản trên sẽ là gì? [OPTIONS]? [LABELS_CHOICE]
Cảm xúc của văn bản này là gì?\nVăn bản: [INPUT]\nTrả lời với [OPTIONS]: [LABELS_CHOICE]
Văn bản: [INPUT]\n\nVui lòng phân loại cảm xúc của văn bản trên. Trả lời với [OPTIONS]: [LABELS_CHOICE]
Bảng 8: Lời nhắc được sử dụng cho tác vụ Phân tích Cảm xúc

Lời nhắc trong Tác vụ Nhận diện Cảm xúc
[INPUT]\nCảm xúc của văn bản trên sẽ là gì? [OPTIONS]? [LABELS_CHOICE]
Cảm xúc của văn bản này là gì?\nVăn bản: [INPUT]\nTrả lời với [OPTIONS]: [LABELS_CHOICE]
Văn bản: [INPUT]\n\nVui lòng phân loại cảm xúc của văn bản trên. Trả lời với [OPTIONS]: [LABELS_CHOICE]
Bảng 9: Lời nhắc được sử dụng cho tác vụ Nhận diện Cảm xúc

Lời nhắc trong Tác vụ Phân loại Chủ đề
[INPUT]\nChủ đề của văn bản trên sẽ là gì? [OPTIONS]? [LABELS_CHOICE]
Chủ đề của văn bản này là gì?\nVăn bản: [INPUT]\nTrả lời với [OPTIONS]: [LABELS_CHOICE]
Văn bản: [INPUT]\n\nVui lòng phân loại chủ đề của văn bản trên. Trả lời với [OPTIONS]: [LABELS_CHOICE]
Bảng 10: Lời nhắc được sử dụng cho tác vụ Phân loại Chủ đề

--- TRANG 20 ---
Mô hình Lời nhắc Ngôn ngữ Acc Macro F1 Macro Prec. Macro Rec.
Độ chính xác Đầy đủ
BLOOMZ-560M EN 47.58 33.25 37.97 43.11
BLOOMZ-560M ID 44.37 29.78 37.79 40.28
BLOOMZ-1B1 EN 52.26 37.90 40.48 45.79
BLOOMZ-1B1 ID 52.88 39.28 46.42 46.67
BLOOMZ-1B7 EN 51.44 36.90 41.90 45.10
BLOOMZ-1B7 ID 52.68 41.20 50.81 48.03
Lượng tử hóa 8-Bit
BLOOMZ-560M EN 47.56 34.67 40.94 42.97
BLOOMZ-560M ID 43.64 33.30 42.90 39.68
BLOOMZ-1B1 EN 50.68 37.52 40.37 44.56
BLOOMZ-1B1 ID 51.23 38.69 43.53 45.34
BLOOMZ-1B7 EN 49.71 35.05 42.11 43.57
BLOOMZ-1B7 ID 52.61 41.87 51.74 48.15
BLOOMZ-3B EN 54.80 40.78 46.59 48.24
BLOOMZ-3B ID 56.75 44.34 45.16 51.12
Bảng 11: Đánh giá độ chính xác đầy đủ và lượng tử hóa 8-bit trên nhiều bộ dữ liệu ngôn ngữ địa phương Indonesia khác nhau.

--- TRANG 21 ---
Trạng thái Ngôn ngữ Train Valid. Test
Tiền huấn luyện Indonesia (ind) 3638 399 1011
Đã thấy Java (jav) 3400 448 1200
Sunda (sun) 3400 448 1200
Minangkabau (min) 3400 448 1200
Chưa thấy Ambon (abs) 250 98 500
Batak (btk) 3400 448 1200
Betawi (bew) 3400 448 1200
Bima (bhp) 260 100 500
Madura (mad) 3400 448 1200
Makassar (mak) 3400 448 1200
Musi (mui) 250 91 500
Rejang (rej) 250 78 500
Bảng 12: Thống kê bộ dữ liệu phân tích cảm xúc NusaTranslation. Tiền huấn luyện biểu thị các ngôn ngữ đã được thấy trước khi điều chỉnh InstructAlign. Đã thấy biểu thị các ngôn ngữ được thấy trong quá trình điều chỉnh InstructAlign. Chưa thấy biểu thị các ngôn ngữ vẫn chưa được thấy sau điều chỉnh InstructAlign.

Trạng thái Ngôn ngữ Train Valid. Test
Tiền huấn luyện Anh (eng) 500 100 400
Indonesia (ind) 500 100 400
Đã thấy Aceh (ace) 500 100 400
Bali (ban) 500 100 400
Banjar (bjn) 500 100 400
Bugis (bug) 500 100 400
Minang (min) 500 100 400
Java (jav) 500 100 400
Sunda (sun) 500 100 400
Chưa thấy Madura (mad) 500 100 400
Ngaju (nij) 500 100 400
Batak (bbc) 500 100 400
Bảng 13: Thống kê bộ dữ liệu phân tích cảm xúc NusaX. Tiền huấn luyện biểu thị các ngôn ngữ đã được thấy trước InstructAlign. Đã thấy biểu thị các ngôn ngữ được thấy trong quá trình InstructAlign. Chưa thấy biểu thị các ngôn ngữ vẫn chưa được thấy sau InstructAlign.

Trạng thái Ngôn ngữ Train Valid. Test
Chưa thấy Java (jav) 2800 440 800
Minangkabau (min) 2000 357 800
Sunda (sun) 2400 400 800
Bugis (bug) 87 50 300
Đã thấy Batak (btk) 1150 292 500
Betawi (bew) 2700 430 800
Madura (mad) 1000 263 500
Makassar (mak) 1500 304 500
Musi (mui) 200 75 400
Rejang (rej) 136 50 300
Bảng 14: Thống kê bộ dữ liệu nhận diện cảm xúc NusaParagraph. Tiền huấn luyện biểu thị các ngôn ngữ đã được thấy trước InstructAlign. Đã thấy biểu thị các ngôn ngữ được thấy trong quá trình InstructAlign. Chưa thấy biểu thị các ngôn ngữ vẫn chưa được thấy sau InstructAlign.

Trạng thái Ngôn ngữ Train Valid. Test
Chưa thấy Java (jav) 2650 448 800
Minangkabau (min) 2400 399 800
Sunda (sun) 2800 468 900
Bugis (bug) 93 50 300
Đã thấy Batak (btk) 1350 275 500
Betawi (bew) 2650 435 800
Madura (mad) 1800 367 700
Makassar (mak) 1500 376 700
Musi (mui) 168 80 400
Rejang (rej) 105 50 350
Bảng 15: Thống kê bộ dữ liệu phân loại chủ đề NusaParagraph. Tiền huấn luyện biểu thị các ngôn ngữ đã được thấy trước InstructAlign. Đã thấy biểu thị các ngôn ngữ được thấy trong quá trình InstructAlign. Chưa thấy biểu thị các ngôn ngữ vẫn chưa được thấy sau InstructAlign.

--- TRANG 22 ---
Mô hình L1 L2 L3
ind jav min sun abs bew bhp btk mad mak mui rej
BLOOM 560m 61.47 56.09 58.13 58.63 62.53 58.42 49.72 56.05 54.02 53.97 60.27 55.55
BLOOM 1b1 58.81 59.05 59.33 59.16 47.87 58.23 60.85 58.95 58.79 58.83 54.92 57.73
BLOOM 3b 58.30 44.84 45.48 44.61 46.08 45.61 44.54 43.62 43.36 44.03 45.05 43.15
BLOOMZ 560m 69.81 43.00 50.97 46.51 45.23 47.87 33.13 36.69 36.84 35.30 61.42 36.21
BLOOMZ 1b1 80.40 61.32 68.95 61.75 61.07 66.94 46.18 50.20 49.71 50.66 70.31 52.01
BLOOMZ 3b 81.38 68.05 71.76 68.43 69.57 69.76 67.73 65.09 64.37 63.14 69.08 64.05
MLM BLOOMZ 560m 65.68 23.29 21.11 22.31 20.86 22.00 20.40 19.04 21.10 20.59 28.82 19.50
MLM BLOOMZ 560m-r=100k 71.93 63.89 69.37 66.27 64.46 65.38 56.12 62.68 58.20 56.51 67.73 58.12
MLM BLOOMZ 1b1-r=100k 73.25 71.18 72.24 70.95 62.67 67.65 56.07 59.22 58.60 60.38 68.10 60.27
MT BLOOMZ 560m 55.20 41.87 39.00 38.16 36.88 39.29 36.07 34.74 36.97 33.81 41.72 37.70
MT BLOOMZ 560m-r=100k 74.46 70.73 69.94 70.00 66.81 67.65 64.58 66.53 65.10 61.35 68.43 63.23
MT BLOOMZ 1b1-r=100k 70.86 59.62 62.22 61.63 54.37 57.97 49.95 50.22 51.31 52.22 60.25 50.30
TLM BLOOMZ 560m 71.57 66.74 66.05 66.94 63.06 65.64 59.00 61.07 61.31 61.13 65.30 63.17
TLM BLOOMZ 560m-r=1k 70.52 61.73 62.76 62.01 54.34 56.31 48.52 49.44 49.21 47.95 61.11 49.22
TLM BLOOMZ 560m-r=10k 72.82 66.27 66.22 66.76 62.29 63.32 59.61 61.27 60.35 60.32 63.60 60.49
TLM BLOOMZ 560m-r=100k 72.40 61.05 59.43 62.11 54.51 56.44 46.68 50.72 50.56 45.02 63.27 48.39
TLM BLOOMZ 1b1-r=100k 75.66 70.05 70.12 70.70 64.47 67.07 62.92 61.87 60.96 61.86 68.11 61.53
XSS BLOOMZ 560m 64.48 57.65 52.18 54.13 52.40 53.59 48.55 48.06 49.59 44.01 58.03 49.43
XSS BLOOMZ 560m-r=1k 69.34 63.55 62.84 65.45 65.20 64.15 59.11 60.53 62.34 61.58 63.51 58.36
XSS BLOOMZ 560m-r=10k 72.22 67.89 67.81 67.25 62.76 64.42 62.83 61.98 62.02 62.21 65.38 59.27
XSS BLOOMZ 560m-r=100k 71.27 68.34 67.89 68.07 61.58 68.69 62.66 65.73 63.44 58.24 70.24 64.92
XSS BLOOMZ 1b1-r=100k 76.75 72.40 71.40 71.87 63.75 65.45 60.27 61.27 60.10 63.21 66.16 60.49
Bảng 16: Kết quả thí nghiệm trên tác vụ phân tích cảm xúc của bộ dữ liệu NusaTranslation

Mô hình L1 L2 L3
eng ind ace ban bjn bug jav min sun bbc mad nij
BLOOM 560m 29.26 21.13 21.35 21.93 21.35 23.21 21.86 21.82 21.04 22.28 22.13 21.11
BLOOM 1b1 22.02 22.54 21.47 22.62 22.27 21.34 22.97 21.92 21.55 22.10 21.65 21.53
BLOOM 3b 24.03 21.17 21.31 21.17 21.18 21.35 21.17 21.17 21.17 21.19 21.20 21.17
BLOOMZ 560m 58.24 55.59 31.18 32.40 37.17 27.79 35.86 39.29 32.44 29.49 32.80 38.15
BLOOMZ 1b1 57.41 58.58 43.31 43.02 44.72 31.12 46.52 42.59 39.20 26.82 41.92 40.76
BLOOMZ 3b 62.65 63.21 48.81 48.40 55.27 23.47 54.26 51.11 39.41 32.42 38.88 41.68
MLM BLOOMZ 560m 49.99 49.33 31.74 28.37 34.32 25.76 33.89 31.27 29.20 28.43 32.08 30.98
MLM BLOOMZ 560m-R-100000 61.32 60.01 42.69 41.69 50.95 31.53 44.28 44.30 42.11 33.18 41.05 40.15
MLM BLOOMZ 1b1-R-100000 61.30 59.73 43.11 43.02 50.71 31.31 53.66 51.05 47.27 31.13 42.02 39.83
MT BLOOMZ 560m 47.24 41.41 31.78 33.78 34.69 28.44 35.47 35.15 36.01 26.86 26.69 27.49
MT BLOOMZ 560m-R-100000 60.09 54.18 39.11 42.59 46.22 34.50 43.37 41.31 41.31 35.95 38.54 39.84
MT BLOOMZ 1b1-R-100000 59.18 53.69 43.97 45.40 50.16 38.65 48.37 45.97 41.98 37.97 40.90 40.60
TLM BLOOMZ 560m 44.72 46.02 33.59 34.26 41.16 25.36 41.76 38.72 37.40 25.67 30.88 29.98
TLM BLOOMZ 560m-R-1000 58.05 54.59 43.03 37.06 46.55 34.02 43.21 43.24 39.59 33.99 38.16 37.39
TLM BLOOMZ 560m-R-10000 57.38 57.73 43.43 36.76 45.99 35.06 44.38 43.30 40.83 34.06 42.46 40.00
TLM BLOOMZ 560m-R-100000 61.65 56.50 41.78 41.36 48.15 31.19 48.89 44.12 44.90 33.78 41.51 37.90
TLM BLOOMZ 1b1-R-100000 64.26 63.54 52.22 51.35 58.19 41.87 59.48 59.67 56.99 38.26 48.11 48.01
XSS BLOOMZ 560m 53.93 53.19 43.60 41.73 47.09 37.79 47.29 45.36 43.42 32.59 41.66 40.79
XSS BLOOMZ 560m-R-1000 56.57 54.90 36.78 40.28 42.20 28.56 45.67 41.33 39.80 27.30 31.67 32.20
XSS BLOOMZ 560m-R-10000 55.62 57.84 44.24 44.03 50.04 32.87 48.92 45.55 45.64 36.38 40.36 43.12
XSS BLOOMZ 560m-R-100000 59.89 58.22 45.53 39.57 52.68 36.15 49.83 50.61 46.45 35.27 42.40 43.39
XSS BLOOMZ 1b1-R-100000 60.78 59.34 45.83 45.45 53.08 36.24 52.24 50.54 47.20 33.81 40.99 41.08
Bảng 17: Kết quả thí nghiệm trên tác vụ phân tích cảm xúc của bộ dữ liệu NusaX

--- TRANG 23 ---
Mô hình L2 L3
bug jav min sun bew btk mad mak mui rej
BLOOM 560m 1.19 2.42 4.54 3.05 4.37 2.56 0.59 1.42 1.11 2.66
BLOOM 1b1 1.19 2.42 4.54 3.05 4.29 2.57 0.59 1.42 1.11 2.44
BLOOM 3b 1.19 2.42 4.54 3.05 4.29 2.57 0.59 1.42 1.11 2.44
BLOOMZ 560m 2.36 2.93 4.71 3.52 4.35 3.33 1.41 3.09 1.28 4.10
BLOOMZ 1b1 1.19 2.42 4.54 3.05 4.29 2.57 0.59 1.42 1.11 2.44
BLOOMZ 3b 1.19 2.42 4.54 3.05 4.29 2.57 0.59 1.42 1.11 2.44
MLM BLOOMZ 560m 1.19 2.51 4.63 3.04 4.29 2.57 0.59 1.42 1.11 2.44
MLM BLOOMZ 560m-R-100000 1.19 2.41 4.54 3.05 4.29 2.57 0.59 1.42 1.11 2.44
MLM BLOOMZ 1b1-R-100000 1.19 2.42 4.71 3.05 4.29 2.57 0.59 1.42 1.11 2.44
MT BLOOMZ 1b1-R-100000 1.60 2.76 4.77 3.54 4.27 2.56 0.59 1.42 1.12 2.44
MT BLOOMZ 560m 1.41 2.58 9.14 5.63 4.45 2.57 0.59 1.56 2.10 2.44
MT BLOOMZ 560m-R-100000 1.19 2.51 4.54 3.04 4.29 2.70 0.59 1.42 1.11 2.44
TLM BLOOMZ 560m 1.19 2.58 4.88 3.54 4.29 2.57 0.59 1.42 1.11 2.44
TLM BLOOMZ 560m-R-1000 1.19 2.50 5.10 3.14 4.29 2.57 0.59 1.42 1.12 2.44
TLM BLOOMZ 560m-R-10000 1.19 2.67 5.12 4.34 4.29 2.57 0.73 1.42 1.11 2.66
TLM BLOOMZ 560m-R-100000 1.40 2.42 4.54 3.13 4.29 2.71 0.73 1.42 1.11 2.44
TLM BLOOMZ 1b1-R-100000 1.19 2.41 4.63 3.13 4.29 2.57 0.59 1.42 1.12 2.44
XSS BLOOMZ 560m 1.54 3.12 4.65 3.77 4.29 2.71 0.59 1.42 1.11 2.44
XSS BLOOMZ 560m-R-1000 1.56 2.82 5.16 3.54 4.37 2.69 0.73 1.42 1.11 2.44
XSS BLOOMZ 560m-R-10000 1.39 2.84 5.56 4.10 4.29 2.57 0.59 1.43 1.28 2.44
XSS BLOOMZ 560m-R-100000 1.19 2.42 4.54 3.05 4.29 2.57 0.59 1.42 1.11 2.42
XSS BLOOMZ 1b1-R-100000 1.19 2.67 4.63 3.84 4.29 2.57 0.59 1.42 1.11 2.44
Bảng 18: Kết quả thí nghiệm trên tác vụ nhận diện cảm xúc của bộ dữ liệu NusaParagraph

--- TRANG 24 ---
Mô hình L2 L3
bug jav min sun bew btk mad mak mui rej
BLOOM-560m 7.68 3.50 6.36 3.80 5.42 7.92 11.25 9.07 3.91 5.80
BLOOM-1b1 7.72 3.50 6.36 3.81 5.42 7.93 11.26 9.09 3.91 5.82
BLOOM-3b 7.72 3.50 6.36 3.81 5.42 7.93 11.26 9.09 3.91 5.82
BLOOMZ-560m 9.13 4.10 6.86 4.29 6.07 8.75 11.71 9.45 4.09 6.04
BLOOMZ-1b1 7.72 3.50 6.36 3.81 5.51 7.93 11.26 9.09 3.91 5.82
BLOOMZ-3b 7.72 4.21 6.70 4.30 7.55 8.33 11.28 9.19 7.30 5.82
MLM BLOOMZ-560m 8.15 3.50 6.36 3.81 5.42 7.93 11.26 9.09 3.91 5.82
MLM BLOOMZ-560m r=100000 7.72 3.49 6.52 4.36 5.51 7.93 11.27 9.09 4.08 5.82
MLM BLOOMZ-1b1 r=100000 7.72 3.50 6.36 3.81 5.42 7.93 11.26 9.09 3.91 5.82
MT BLOOMZ-560m 7.72 3.50 6.36 3.81 5.42 7.93 11.26 9.09 3.92 5.82
MT BLOOMZ-560m r=100000 7.72 3.58 6.37 3.93 5.52 7.94 11.22 9.19 3.92 5.82
MT BLOOMZ-1b1 r=100000 8.61 4.59 7.08 5.08 5.71 8.20 11.52 9.29 4.63 6.01
TLM BLOOMZ-560m 9.43 3.83 7.27 7.11 5.42 7.93 11.28 9.18 3.92 5.82
TLM BLOOMZ-560m r=1000 14.08 11.46 17.31 16.55 10.35 12.61 11.92 12.04 9.34 5.96
TLM BLOOMZ-560m r=10000 8.37 4.23 7.66 5.40 5.43 8.05 11.20 9.28 4.25 5.96
TLM BLOOMZ-560m r=100000 7.75 3.50 6.34 3.80 5.51 7.93 11.35 9.18 4.23 5.78
TLM BLOOMZ-1b1 r=100000 7.71 3.67 6.55 4.05 5.42 7.93 11.27 9.08 3.91 5.82
XSS BLOOMZ-560m 8.38 3.57 6.46 3.88 5.42 7.94 11.26 9.09 3.91 5.82
XSS BLOOMZ-560m r=1000 6.14 4.21 4.34 6.14 4.38 7.29 11.21 8.39 5.52 6.63
XSS BLOOMZ-560m r=10000 8.06 4.24 7.46 5.07 5.41 8.23 11.32 9.10 4.08 5.85
XSS BLOOMZ-560m r=100000 7.73 3.50 6.67 4.23 5.50 7.93 11.26 9.09 3.92 5.82
XSS BLOOMZ-1b1 r=100000 8.00 4.05 7.40 4.62 5.67 8.08 11.55 9.19 4.08 5.83
Bảng 19: Kết quả thí nghiệm trên tác vụ phân loại chủ đề của bộ dữ liệu NusaParagraph

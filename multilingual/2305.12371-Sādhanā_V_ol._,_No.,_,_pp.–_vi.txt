# 2305.12371.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/multilingual/2305.12371.pdf
# Kích thước tệp: 2787671 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
Sādhanā Tập , Số., , trang.–
DOI© Viện Hàn lâm Khoa học Ấn Độ
Dịch Máy bằng cách Chiếu Văn bản vào cùng Không gian Âm thanh-
Chính tả sử dụng Mã hóa Chung
AMIT KUMAR1,*, SHANTIPRIYA PARIDA2, AJAY PRATAP1, và ANIL KUMAR
SINGH1
1Viện Công nghệ Ấn Độ (BHU), Varanasi, Ấn Độ
2Silo AI, Helsinki, Phần Lan
e-mail: amitkumar.rs.cse17@iitbhu.ac.in (Tác giả liên hệ)
Tóm tắt. Việc sử dụng embedding từ con đã được chứng minh là một đổi mới lớn trong Dịch Máy Thần kinh (NMT). Nó giúp NMT học được các vector ngữ cảnh tốt hơn cho các Ngôn ngữ Tài nguyên Thấp (LRL) để dự đoán các từ đích bằng cách mô hình hóa tốt hơn hình thái học của hai ngôn ngữ và cả việc chuyển giao hình thái-cú pháp. Tuy nhiên, hiệu suất của chúng đối với dịch thuật trong kịch bản từ ngôn ngữ Ấn Độ sang ngôn ngữ Ấn Độ vẫn chưa tốt bằng các ngôn ngữ giàu tài nguyên. Một lý do là sự phong phú hình thái tương đối của các ngôn ngữ Ấn Độ, trong khi lý do khác là hầu hết chúng thuộc các danh mục tài nguyên cực thấp hoặc zero-shot. Vì hầu hết các ngôn ngữ Ấn Độ chính sử dụng chữ viết gốc Indic hoặc Brahmi, văn bản viết bằng chúng có tính chất âm thanh cao và tương tự về mặt âm thanh về các chữ cái trừu tượng và cách sắp xếp của chúng. Chúng tôi sử dụng những đặc điểm này của các ngôn ngữ Ấn Độ và chữ viết của chúng để đề xuất một phương pháp dựa trên các mã hóa đa ngôn ngữ dựa trên Latin chung (ký hiệu WX) tận dụng sự tương tự ngôn ngữ đồng thời giải quyết vấn đề phức tạp hình thái học trong NMT. Những mã hóa đa ngôn ngữ dựa trên Latin này trong NMT, cùng với Byte Pair Embedding (BPE) cho phép chúng tôi khai thác tốt hơn sự tương tự về âm thanh và chính tả cũng như từ vựng để cải thiện chất lượng dịch thuật bằng cách chiếu các ngôn ngữ khác nhau nhưng tương tự vào cùng không gian ký tự chính tả-âm thanh. Chúng tôi xác minh phương pháp được đề xuất bằng cách chứng minh các thí nghiệm trên các cặp ngôn ngữ tương tự (Gujarati ↔Hindi, Marathi ↔Hindi, Nepali ↔Hindi, Maithili ↔Hindi, Punjabi ↔Hindi, và Urdu ↔Hindi) trong điều kiện tài nguyên thấp. Phương pháp được đề xuất cho thấy sự cải thiện trong phần lớn các trường hợp, trong một trường hợp lên đến ∼10 điểm BLEU so với các kỹ thuật cơ sở cho các cặp ngôn ngữ tương tự. Chúng tôi cũng đạt được cải thiện lên đến ∼1 điểm BLEU trên các cặp ngôn ngữ xa và zero-shot.
Từ khóa. Dịch Máy Thần kinh, Không gian Âm thanh-Chính tả Chung, Ngôn ngữ Tương tự, Mã hóa Cặp Byte, Mô hình Transformer
1 Giới thiệu
Dịch Máy (MT) có một lịch sử thú vị trong tính toán và nghiên cứu [20] với các mô hình mới được giới thiệu qua nhiều thập kỷ. MT đạt được một thời điểm bước ngoặt với việc giới thiệu nhiều cải tiến thuật toán, kiến trúc và huấn luyện, chẳng hạn như Dịch Máy Thống kê (SMT) và Dịch Máy Thần kinh (NMT) [64]. SMT là một mô hình MT dựa trên thống kê, hoạt động ở mức độ chi tiết của từ và cụm từ, bao gồm một mô hình dịch thuật, một mô hình ngôn ngữ và một bộ giải mã [17, 62, 66]. Hơn nữa, thành công tương đối gần đây của mạng nơ-ron sâu đã cho chúng ta các biến thể dịch thuật đầu cuối đến đầu cuối như NMT hồi quy [21, 63], NMT dựa trên attention và Transformer dựa trên self-attention [6].

Đã có những phát triển song song và liên quan trong các mô hình ngôn ngữ, chẳng hạn như Bidirectional Encoder Representations from Transformers (BERT) [22] và ALBERT [23]. Một biến thể khác của điều này, mBART, đã cung cấp các giải pháp điểm chuẩn trong NMT [4]. Tuy nhiên, việc huấn luyện một hệ thống MT hiệu quả và chính xác vẫn yêu cầu một lượng lớn corpus song song bao gồm các cặp ngôn ngữ nguồn và đích. Khi chúng ta nói về các ngôn ngữ tài nguyên thấp, vấn đề đầu tiên là tìm một lượng corpus song song công bằng, đôi khi thậm chí là corpus đơn ngôn ngữ, điều này làm cho việc tạo ra các công cụ và ứng dụng cho các ngôn ngữ tài nguyên cực kỳ nghèo trở nên thách thức.

Việc tạo ra một corpus song song lớn cho MT cho mỗi cặp ngôn ngữ thuộc danh mục tài nguyên thấp là một nhiệm vụ đắt đỏ, tốn thời gian và cần nhiều lao động.

Vậy, giải pháp để cải thiện NMT trong bối cảnh tài nguyên thấp là bootstrap quá trình bằng cách tận dụng các đặc điểm hình thái học, cấu trúc, chức năng và có lẽ cả ngữ nghĩa sâu của các ngôn ngữ như vậy. May mắn thay, đối với các ngôn ngữ tương tự, cũng có thể khai thác sự tương tự để mô hình hóa tốt hơn các ngôn ngữ có liên quan chặt chẽ.

Chúng ta cần tập trung vào các đặc điểm giúp hệ thống MT học tốt hơn mối quan hệ chặt chẽ giữa các ngôn ngữ như vậy. Hội nghị Dịch Máy (WMT) cũng đã tổ chức các nhiệm vụ chia sẻ cho dịch thuật ngôn ngữ tương tự từ năm 2019 [24].

Khi chúng ta nói về các ngôn ngữ Ấn Độ, hầu hết các ngôn ngữ ngoại trừ Hindi đều thuộc các danh mục tài nguyên cực thấp. Thậm chí Hindi cũng là, từ một số quan điểm, một ngôn ngữ tài nguyên thấp hoặc trung bình [72, 73]. Ấn Độ là một quốc gia có sự đa dạng ngôn ngữ phong phú, có nhu cầu về các hệ thống MT trên các ngôn ngữ Ấn Độ (hoặc Nam Á).

Ấn Độ cũng được cư trú bởi một dân số lớn nói các ngôn ngữ thuộc ba họ nổi bật, Indo-Aryan (một phân họ của Indo-European), Dravidian và Tibeto-Burman, nhưng do tiếp xúc và tương tác rất lâu dài, chúng đã trải qua một quá trình 'hội tụ', hình thành Ấn Độ như một khu vực ngôn ngữ [25].

Do sự tiếp xúc lâu dài này, có nhiều điểm tương tự giữa các ngôn ngữ này hơn những gì chúng ta có thể mong đợi khác. Thêm vào đó, các phần đáng kể của từ vựng của chúng, ở các mức độ khác nhau, có các từ bắt nguồn từ hoặc được mượn từ tiếng Sanskrit, Ba Tư, Ả Rập, Thổ Nhĩ Kỳ và tiếng Anh, trong số các ngôn ngữ khác.

Đối với một số ngôn ngữ chính, và thậm chí đối với một số 'ngôn ngữ vùng' hoặc 'ngôn ngữ thiểu số' (vì chúng đã được sử dụng rộng rãi trong một thời gian dài trong quá khứ cho mục đích văn học), có các bản ghi có sẵn và có một mức độ truyền thống phát triển tốt ít nhất về việc sử dụng văn học (nói). Tuy nhiên, chỉ một số ngôn ngữ, hầu hết được công nhận chính thức, có một số truyền thống viết, đặc biệt là cho văn xuôi phi văn học. Phần còn lại có rất ít dữ liệu viết, hoặc thậm chí nếu có, nó thường không ở định dạng có thể đọc được bằng máy. Do đó, chúng có thể được coi như các ngôn ngữ tài nguyên cực thấp hoặc zero-resource.

Có nhu cầu phát triển các hệ thống MT cho các ngôn ngữ như vậy, và sự tương tự giữa các ngôn ngữ này giúp phát triển các hệ thống MT như vậy.

Trong bài báo này, chúng tôi đề xuất một phương pháp dựa trên việc tận dụng các đặc điểm của ngôn ngữ tương tự bằng cách đơn giản, có chương trình1, chuyển đổi chúng thành một ký hiệu đa ngôn ngữ dựa trên Latin trung gian. Ký hiệu mà chúng tôi sử dụng ở đây là ký hiệu WX thường được sử dụng [26], thường được sử dụng trong các công cụ và hệ thống NLP cho các ngôn ngữ Ấn Độ được phát triển tại Ấn Độ. Ký hiệu này (như nhiều ký hiệu tương tự khác) có thể chiếu tất cả các chữ viết gốc Indic hoặc Brahmi [40], có — trong nhiều trường hợp — các khối Unicode khác nhau, vào một không gian ký tự chung. Trực giác của chúng tôi là điều này sẽ giúp nắm bắt sự tương tự về âm vị học, chính tả và, ở một mức độ nào đó, hình thái-cú pháp sẽ giúp một mô hình dựa trên mạng nơ-ron trong việc học đa ngôn ngữ và dịch thuật tốt hơn trên các ngôn ngữ này [38, 39, 67]. Chúng tôi làm điều này bằng cách sử dụng văn bản đã chuyển đổi WX để học embedding dựa trên mã hóa cặp byte. Hiệu ứng của điều này là các ngôn ngữ tương tự nhưng khác nhau được chiếu vào cùng không gian chính tả-âm thanh [41], và do đó cũng trong cùng không gian hình thái và từ vựng chung, cho phép mô hình hóa tốt hơn các mối quan hệ đa ngôn ngữ trong bối cảnh Ấn Độ như một khu vực ngôn ngữ.

Ngoài ra, việc sử dụng WX có một lợi ích khác, thậm chí đối với một chữ viết đơn lẻ như Devanagari. Các chữ viết dẫn xuất từ Brahmi có các ký hiệu khác nhau cho nguyên âm phụ thuộc (gọi là maatraas) sửa đổi một phụ âm và nguyên âm độc lập (viết dưới dạng aksharas) được phát âm như các âm tiết. WX sử dụng cùng ký hiệu cho hai biến thể này của cùng một nguyên âm, trong khi Unicode sử dụng các mã khác nhau và bản thân các chữ viết sử dụng các ký hiệu đồ họa khác nhau.

Sau khi chuyển đổi sang WX, chúng tôi áp dụng một số kỹ thuật NMT tiên tiến nhất để xây dựng các hệ thống MT của chúng tôi. Các hệ thống NMT này, chẳng hạn như Transformer, sẽ học tốt hơn các mối quan hệ giữa các ngôn ngữ.

Chúng tôi chọn sáu cặp ngôn ngữ tương tự: Gujarati (GU)↔Hindi (HI), Marathi (MR) ↔Hindi (HI), Nepali (NE)↔Hindi (HI), Maithili (MAI) ↔Hindi (HI), Punjabi (PA) ↔Hindi (HI), và Urdu (UR) ↔Hindi (HI). Bảng 1 chứa một số đặc điểm ngôn ngữ giúp tìm ra cách các ngôn ngữ được chọn tương tự với Hindi. Ví dụ, Hindi, Gujarati, Marathi, Nepali, Maithili, Punjabi và Urdu thuộc các họ Ngôn ngữ Indo-Aryan, và tất cả các ngôn ngữ được chọn ngoại trừ Punjabi và Urdu chia sẻ chữ viết Devanagari chung. Thứ tự từ của tất cả các ngôn ngữ được chọn chủ yếu là Chủ ngữ + Tân ngữ + Động từ. Ngoài điều này, tất cả các ngôn ngữ này chia sẻ sự tương tự từ vựng với Hindi về các từ chung được dẫn xuất từ tiếng Sanskrit và các ngôn ngữ khác như đã đề cập trước đó. Ngoài ra, các ngôn ngữ này có sự tương tự về âm vị học với Hindi. Chúng tôi cũng lưu ý rằng mặc dù Urdu và Hindi về mặt ngôn ngữ gần như là cùng một ngôn ngữ, nhưng do sự khác biệt lớn trong từ vựng của chúng ở dạng viết, chúng chỉ có sự chồng lấn tương đối nhỏ trong từ vựng dựa trên corpus của chúng, mặc dù sự chồng lấn này chủ yếu bao gồm các từ cốt lõi tạo thành một thành phần chính của bản sắc ngôn ngữ của một ngôn ngữ.

Bài báo này là phần đầu tiên của một loạt ba bài báo khám phá và sau đó mở rộng ý tưởng sử dụng không gian âm thanh-chính tả chung để NMT tốt hơn trong bối cảnh Ấn Độ [68, 69]. Các đóng góp của bài báo này được tóm tắt như sau:

1. Đề xuất một phương pháp dịch máy dựa trên WX tận dụng sự tương tự chính tả và âm vị học giữa các cặp ngôn ngữ Ấn Độ.

2. Phương pháp đề xuất đạt được cải thiện từ +0.01 đến +10 điểm BLEU so với các kỹ thuật tiên tiến cơ sở cho các cặp ngôn ngữ tương tự trong hầu hết các trường hợp. Chúng tôi cũng đạt được cải thiện +1 điểm BLEU trên các cặp ngôn ngữ xa và zero-shot.

Phần còn lại của bài báo được tổ chức như sau. Phần 2 thảo luận về các công trình liên quan chặt chẽ. Phần 3 mô tả một số nền tảng và các mô hình NMT mà chúng tôi mở rộng hoặc so sánh. Phần 4 mô tả phương pháp đề xuất chi tiết hơn. Phần 5 thảo luận về thống kê corpus và cài đặt thực nghiệm được sử dụng để tiến hành các thí nghiệm. Kết quả và nghiên cứu ablation được báo cáo trong Phần 6 và 7, tương ứng. Cuối cùng, bài báo được tóm tắt trong Phần 8 và bao gồm một số hướng cho công việc tương lai.

--- TRANG 2 ---
2 Kumar và cộng sự
Bảng 1. Một số chi tiết về các ngôn ngữ được sử dụng trong các thí nghiệm của chúng tôi
Ngôn ngữ Họ Chữ viết Thứ tự từ Ergative Địa điểm
Hindi
Indo-AryanDevanagari
SOVY es Chủ yếu Bắc Ấn Độ
Gujarati Gujarati Không Chủ yếu Gujarat
Marathi Phiên bản Balbodh của Devanagari Không Chủ yếu Maharashtra
Nepali Devanagari Có Chủ yếu Nepal
Maithili Devanagari Không Chủ yếu Bihar và một phần Nepal
Punjabi Gurumukhi Không Chủ yếu Punjab
Urdu Biến thể của Perso-Arabic Không Chủ yếu Bắc Ấn Độ

cũng đã tổ chức các nhiệm vụ chia sẻ cho dịch thuật ngôn ngữ tương tự từ năm 2019 [24].

Khi chúng ta nói về các ngôn ngữ Ấn Độ, hầu hết các ngôn ngữ ngoại trừ Hindi đều thuộc các danh mục tài nguyên cực thấp. Thậm chí Hindi cũng là, từ một số quan điểm, một ngôn ngữ tài nguyên thấp hoặc trung bình [72, 73]. Ấn Độ là một quốc gia có sự đa dạng ngôn ngữ phong phú, có nhu cầu về các hệ thống MT trên các ngôn ngữ Ấn Độ (hoặc Nam Á). Ấn Độ cũng được cư trú bởi một dân số lớn nói các ngôn ngữ thuộc ba họ nổi bật, Indo-Aryan (một phân họ của Indo-European), Dravidian và Tibeto-Burman, nhưng do tiếp xúc và tương tác rất lâu dài, chúng đã trải qua một quá trình 'hội tụ', hình thành Ấn Độ như một khu vực ngôn ngữ [25]. Do sự tiếp xúc lâu dài này, có nhiều điểm tương tự giữa các ngôn ngữ này hơn những gì chúng ta có thể mong đợi khác. Ngoài ra, các phần đáng kể của từ vựng của chúng, ở các mức độ khác nhau, có các từ bắt nguồn từ hoặc được mượn từ tiếng Sanskrit, Ba Tư, Ả Rập, Thổ Nhĩ Kỳ và tiếng Anh, trong số các ngôn ngữ khác.

Đối với một số ngôn ngữ chính, và thậm chí đối với một số 'ngôn ngữ vùng' hoặc 'ngôn ngữ thiểu số' (vì chúng đã được sử dụng rộng rãi trong một thời gian dài trong quá khứ cho mục đích văn học), có các bản ghi có sẵn và có một mức độ truyền thống phát triển tốt ít nhất về việc sử dụng văn học (nói). Tuy nhiên, chỉ một số ngôn ngữ, hầu hết được công nhận chính thức, có một số truyền thống viết, đặc biệt là cho văn xuôi phi văn học. Phần còn lại có rất ít dữ liệu viết, hoặc thậm chí nếu có, nó thường không ở định dạng có thể đọc được bằng máy. Do đó, chúng có thể được coi như các ngôn ngữ tài nguyên cực thấp hoặc zero-resource. Có nhu cầu phát triển các hệ thống MT cho các ngôn ngữ như vậy, và sự tương tự giữa các ngôn ngữ này giúp phát triển các hệ thống MT như vậy.

Trong bài báo này, chúng tôi đề xuất một phương pháp dựa trên việc tận dụng các đặc điểm của ngôn ngữ tương tự bằng cách đơn giản, có chương trình1, chuyển đổi chúng thành một ký hiệu đa ngôn ngữ dựa trên Latin trung gian. Ký hiệu mà chúng tôi sử dụng ở đây là ký hiệu WX thường được sử dụng [26], thường được sử dụng trong các công cụ và hệ thống NLP cho các ngôn ngữ Ấn Độ được phát triển tại Ấn Độ. Ký hiệu này (như nhiều ký hiệu tương tự khác) có thể chiếu tất cả các chữ viết gốc Indic hoặc Brahmi [40], có — trong nhiều

1Sử dụng các bộ chuyển đổi mã hóa, chẳng hạn như https://pypi.org/project/wxconv/ trường hợp — các khối Unicode khác nhau, vào một không gian ký tự chung. Trực giác của chúng tôi là điều này sẽ giúp nắm bắt sự tương tự về âm vị học, chính tả và, ở một mức độ nào đó, hình thái-cú pháp sẽ giúp một mô hình dựa trên mạng nơ-ron trong việc học đa ngôn ngữ và dịch thuật tốt hơn trên các ngôn ngữ này [38, 39, 67]. Chúng tôi làm điều này bằng cách sử dụng văn bản đã chuyển đổi WX để học embedding dựa trên mã hóa cặp byte. Hiệu ứng của điều này là các ngôn ngữ tương tự nhưng khác nhau được chiếu vào cùng không gian chính tả-âm thanh [41], và do đó cũng trong cùng không gian hình thái và từ vựng chung, cho phép mô hình hóa tốt hơn các mối quan hệ đa ngôn ngữ trong bối cảnh Ấn Độ như một khu vực ngôn ngữ.

Ngoài ra, việc sử dụng WX có một lợi ích khác, thậm chí đối với một chữ viết đơn lẻ như Devanagari. Các chữ viết dẫn xuất từ Brahmi có các ký hiệu khác nhau cho nguyên âm phụ thuộc (gọi là maatraas) sửa đổi một phụ âm và nguyên âm độc lập (viết dưới dạng aksharas) được phát âm như các âm tiết. WX sử dụng cùng ký hiệu cho hai biến thể này của cùng một nguyên âm, trong khi Unicode sử dụng các mã khác nhau và bản thân các chữ viết sử dụng các ký hiệu đồ họa khác nhau.

Sau khi chuyển đổi sang WX, chúng tôi áp dụng một số kỹ thuật NMT tiên tiến nhất để xây dựng các hệ thống MT của chúng tôi. Các hệ thống NMT này, chẳng hạn như Transformer, sẽ học tốt hơn các mối quan hệ giữa các ngôn ngữ.

Chúng tôi chọn sáu cặp ngôn ngữ tương tự: Gujarati (GU)↔Hindi (HI), Marathi (MR) ↔Hindi (HI), Nepali (NE)↔Hindi (HI), Maithili (MAI) ↔Hindi (HI), Punjabi (PA) ↔Hindi (HI), và Urdu (UR) ↔Hindi (HI). Bảng 1 chứa một số đặc điểm ngôn ngữ giúp tìm ra cách các ngôn ngữ được chọn tương tự với Hindi. Ví dụ, Hindi, Gujarati, Marathi, Nepali, Maithili, Punjabi và Urdu thuộc các họ Ngôn ngữ Indo-Aryan, và tất cả các ngôn ngữ được chọn ngoại trừ Punjabi và Urdu chia sẻ chữ viết Devanagari chung. Thứ tự từ của tất cả các ngôn ngữ được chọn chủ yếu là Chủ ngữ + Tân ngữ + Động từ. Ngoài điều này, tất cả các ngôn ngữ này chia sẻ sự tương tự từ vựng với Hindi về các từ chung được dẫn xuất từ tiếng Sanskrit và các ngôn ngữ khác như đã đề cập trước đó. Ngoài ra, các ngôn ngữ này có sự tương tự về âm vị học với Hindi. Chúng tôi cũng lưu ý rằng mặc dù Urdu và Hindi về mặt ngôn ngữ gần như là cùng một ngôn ngữ, nhưng do sự khác biệt lớn trong từ vựng của chúng ở dạng viết, chúng chỉ có sự chồng lấn tương đối nhỏ trong từ vựng dựa trên corpus của chúng, mặc dù sự chồng lấn này chủ yếu bao gồm các từ cốt lõi tạo thành một thành phần chính của bản sắc ngôn ngữ của một ngôn ngữ.

--- TRANG 3 ---
MT với BPE Thích ứng với Mã hóa WX 3

từ vựng, mặc dù sự chồng lấn này chủ yếu bao gồm các từ cốt lõi tạo thành một thành phần chính của bản sắc ngôn ngữ của một ngôn ngữ.

Bài báo này là phần đầu tiên của một loạt ba bài báo khám phá và sau đó mở rộng ý tưởng sử dụng không gian âm thanh-chính tả chung để NMT tốt hơn trong bối cảnh Ấn Độ [68, 69]. Các đóng góp của bài báo này được tóm tắt như sau:

1. Đề xuất một phương pháp dịch máy dựa trên WX tận dụng sự tương tự chính tả và âm vị học giữa các cặp ngôn ngữ Ấn Độ.

2. Phương pháp đề xuất đạt được cải thiện từ +0.01 đến +10 điểm BLEU so với các kỹ thuật tiên tiến cơ sở cho các cặp ngôn ngữ tương tự trong hầu hết các trường hợp. Chúng tôi cũng đạt được cải thiện +1 điểm BLEU trên các cặp ngôn ngữ xa và zero-shot.

Phần còn lại của bài báo được tổ chức như sau. Phần 2 thảo luận về các công trình liên quan chặt chẽ. Phần 3 mô tả một số nền tảng và các mô hình NMT mà chúng tôi mở rộng hoặc so sánh. Phần 4 mô tả phương pháp đề xuất chi tiết hơn. Phần 5 thảo luận về thống kê corpus và cài đặt thực nghiệm được sử dụng để tiến hành các thí nghiệm. Kết quả và nghiên cứu ablation được báo cáo trong Phần 6 và 7, tương ứng. Cuối cùng, bài báo được tóm tắt trong Phần 8 và bao gồm một số hướng cho công việc tương lai.

2 Các Công trình Liên quan

Phần này mô tả ngắn gọn một số công trình liên quan (Bảng 2) về tính tương tự ngôn ngữ, độ phong phú hình thái học, các mô hình thống kê và nơ-ron, và các cặp ngôn ngữ được sử dụng như được thảo luận dưới đây.

Mặc dù đã có công trình trong quá khứ, sự tập trung sắc nét gần đây về dịch máy cho các ngôn ngữ tương tự cũng là do các nhiệm vụ chia sẻ về chủ đề này được tổ chức như một phần của các hội nghị WMT từ năm 2019 đến 2021. Trong [46], các tác giả đã chứng minh rằng việc huấn luyện trước có thể giúp ích ngay cả khi ngôn ngữ được sử dụng để tinh chỉnh không có mặt trong quá trình huấn luyện trước. Trong [47], các tác giả đã thử nghiệm với kiến trúc mạng nơ-ron hồi quy dựa trên attention (seq2seq) trên HI ↔MR và khám phá việc sử dụng các đặc điểm ngôn ngữ khác nhau như part-of-speech và đặc điểm hình thái học, cùng với back translation cho dịch máy HI→MR và MR →HI. Trong [48], các tác giả đã kết hợp hai mô hình Transformer để cố gắng cho phép hệ thống NMT học được những sắc thái của dịch thuật cho các cặp ngôn ngữ tài nguyên thấp bằng cách tận dụng thực tế rằng ngôn ngữ nguồn và đích được viết bằng cùng một chữ viết. Trong [49], công trình của các tác giả dựa vào NMT với cơ chế attention cho dịch thuật ngôn ngữ tương tự trong nhiệm vụ chia sẻ WMT19 trong bối cảnh cặp ngôn ngữ NE↔HI.

Trong [50], các tác giả đã tiến hành một loạt thí nghiệm để giải quyết các thách thức của dịch thuật giữa các ngôn ngữ tương tự. Trong số đó, các tác giả đã phát triển một hệ thống SMT dựa trên cụm từ và một hệ thống NMT sử dụng embedding cặp byte cho cặp HI ↔MR. Trong [51], các tác giả đã sử dụng NMT dựa trên Transformer với sentencepiece cho embedding từ con trên cặp ngôn ngữ HI ↔MR [61]. Trong [52], các tác giả đã sử dụng Transformer-NMT cho huấn luyện mô hình đa ngôn ngữ và đánh giá kết quả trên cặp HI ↔MR. Trong [53], các tác giả tập trung vào việc kết hợp dữ liệu đơn ngôn ngữ vào các mô hình NMT với phương pháp back-translation. Trong [70], các tác giả đã giới thiệu các tài nguyên NLP cho 11 ngôn ngữ Ấn Độ chính từ hai họ ngôn ngữ chính. Các tài nguyên này bao gồm: corpus đơn ngôn ngữ quy mô lớn ở mức câu, embedding từ được huấn luyện trước, mô hình ngôn ngữ được huấn luyện trước và nhiều bộ dữ liệu đánh giá NLU. Trong [71], các tác giả đã trình bày IndicBART, một mô hình được huấn luyện trước đa ngôn ngữ, sequence-to-sequence tập trung vào 11 ngôn ngữ Indic và tiếng Anh. IndicBART đã sử dụng sự tương tự chính tả giữa các chữ viết Indic để cải thiện việc học chuyển giao giữa các ngôn ngữ Indic tương tự.

2.1 Thiếu sót của các công trình hiện có

Trong hầu hết các công trình hiện có về MT cho các ngôn ngữ liên quan (ví dụ: [51], [52], [53]), các tác giả đã thảo luận về việc cải thiện các mô hình NMT bằng cách sử dụng corpus đơn ngôn ngữ bổ sung ngoài dữ liệu song ngữ. Tuy nhiên, phương pháp đề xuất cải thiện chất lượng dịch thuật chỉ sử dụng corpus song ngữ với sự trợ giúp của WX-transliteration. Phương pháp đề xuất giảm độ phức tạp ngôn ngữ bằng cách chuyển tự văn bản sang chữ viết roman và giúp các mô hình NMT học tốt hơn thông tin ngữ cảnh bằng cách khai thác sự tương tự ngôn ngữ. Theo cách này, khi có thể áp dụng, nó có thể bổ sung cho các phương pháp sử dụng dữ liệu đơn ngôn ngữ bổ sung.

3 Nền tảng

Phần này cung cấp một số nền tảng về các kỹ thuật dịch máy thành công gần đây nhất. Từ NMT vanilla đến BART mạnh mẽ và tiên tiến hơn, một bộ tự động mã hóa khử nhiễu để huấn luyện trước các mô hình sequence-to-sequence, những tiến bộ đáng kể trong các kỹ thuật NMT đã được thực hiện trong một thời gian tương đối ngắn.

3.1 NMT

Nhiều kỹ thuật NMT sử dụng kiến trúc encoder-decoder dựa trên mạng nơ-ron thực hiện dịch thuật giữa các cặp ngôn ngữ. Nhiều cải tiến, toolkit và framework mở có sẵn để huấn luyện các mô hình NMT, chẳng hạn như OpenNMT. OpenNMT là một trong những framework NMT mã nguồn mở [2], được sử dụng để mô hình hóa các nhiệm vụ ngôn ngữ tự nhiên như tóm tắt văn bản, gắn thẻ và tạo văn bản. Toolkit này được sử dụng cho các kiến trúc mô hình, biểu diễn đặc điểm và phương thức nguồn trong nghiên cứu NMT. NMT đa ngôn ngữ và zero-shot cũng đã được áp dụng cho NMT để đạt được kết quả tiên tiến trên các cặp ngôn ngữ khác nhau bằng

--- TRANG 4 ---
4 Kumar và cộng sự
Bảng 2. So sánh một số công trình hiện có. 3 và 7 đại diện cho sự hiện diện và vắng mặt của một đặc điểm cụ thể, tương ứng.
Bài báo Ngôn ngữ Tương tự Giảm Độ phức tạp Hình thái học Thống kê Nơ-ron WX Cặp Ngôn ngữ
[46] 3 7 7 3 7 HI↔MR, ES ↔PT
[47] 3 7 7 3 7 HI↔MR
[48] 3 7 7 3 7 HI↔MR
[49] 3 7 7 3 7 NE↔HI
[50] 3 7 3 3 7 HI↔MR
[51] 3 7 7 3 7 HI↔MR
[52] 3 7 7 3 7 HI↔MR
[53] 3 7 7 3 7ES↔PT, CS ↔PL, NE ↔HI
[70] 3 7 7 3 7 11 ngôn ngữ Ấn Độ
[71] 3 7 7 3 711 ngôn ngữ Indic và tiếng Anh
Phương pháp đề xuất 3 3 7 3 3{GU,MR,NE,MAI,PA,UR} ↔HI
Ghi chú- HI: Hindi, MR: Marathi, ES: Tây Ban Nha, PT: Bồ Đào Nha, NE: Nepal, CS: Séc, PL:Ba Lan, GU: Gujarati, MAI: Maithili, PA: Punjabi, UR: Urdu

cách sử dụng một mô hình NMT tiêu chuẩn duy nhất cho nhiều ngôn ngữ [5]. Hơn nữa, việc giới thiệu 'attention' trong NMT đã cải thiện kết quả một cách đáng kể [7], như đối với nhiều vấn đề khác. Như được hiển thị trong Hình 1, NMT là một mô hình dựa trên sequence encoder-decoder bao gồm các đơn vị mạng nơ-ron hồi quy (RNN). Encoder bao gồm các đơn vị RNN (E0,E1,E2) và nhận đầu vào là embedding của các từ từ câu và tạo ra vector ngữ cảnh (C) như sau:

C=Encoder (X1,X2,X3, ...,Xn) (1)

trong đó, {X1,X2,X3,...,Xn} là sequence nguồn đầu vào.

Decoder bao gồm các đơn vị RNN (D0,D1,D2,D3) và nó giải mã các vector ngữ cảnh này thành các câu đích với ký hiệu <END> (kết thúc câu) như sau:

Decoder (C,Y1,Y2,Y3, ...,Yn)=Y′1,Y′2,Y′3, ...,Y′m(2)

trong đó, {Y1,Y2,Y3,...,Yn} và {Y′1,Y′2,Y′3,...,Y′m} là các sequence đích và được dự đoán, tương ứng.

3.2 NMT dựa trên Transformer

Transformer có thể được đặc trưng bởi bước đột phá trong việc kết hợp năm đổi mới một cách tinh tế trong một kiến trúc duy nhất. Đầu tiên là cơ chế attention [6]. Nó ánh xạ một truy vấn và một tập hợp các cặp key-value thành một đầu ra. Một hàm tương thích của truy vấn với key tương ứng tính toán các trọng số. Thứ hai mở rộng đầu tiên bằng cách sử dụng multi-head self-attention. Thứ ba là việc sử dụng mã hóa vị trí theo các vị trí tương đối, cho phép nó học các mối quan hệ và phụ thuộc thời gian. Thứ tư là việc sử dụng masking, đã được chứng minh là cực kỳ hiệu quả trong nhiều mô hình sau này. Thứ năm là việc sử dụng các kết nối dư. Cùng nhau, sự kết hợp tinh tế của những đổi mới này không chỉ cho phép mô hình học các mô hình tốt hơn nhiều, mà còn loại bỏ nhu cầu các đơn vị hồi quy trong kiến trúc, điều này cho phép một mức độ song song hóa lớn trong quá trình huấn luyện các mô hình. Nói cách khác, mô hình Transformer không chỉ học các mô hình tốt hơn nhiều, mà còn thực hiện điều đó trong thời gian ít hơn nhiều trong giai đoạn huấn luyện. Hơn nữa, vấn đề overfitting cũng ít hơn nhiều với các mô hình dựa trên Transformer.

Có nhiều kết quả tiên tiến được báo cáo cho các hệ thống dịch máy sử dụng Transformer. Currey và Heafield [8] đã kết hợp cú pháp vào Transformer bằng cách sử dụng mô hình encoder hỗn hợp và dịch máy đa nhiệm vụ. Multi-head attention là một đặc điểm chính của self-attention. Việc cố định các head attention ở phía encoder của Transformer làm tăng điểm BLEU lên đến 3 điểm trong các kịch bản tài nguyên thấp [9]. Các hàm attention phổ biến nhất là additive attention và dot product attention. Transformer tạo ra scaled dot-product attention như sau [6]:

attni=softmax(QiKiT/√dk)Vi (3)

trong đó, Qi,Ki,Vi và dk là query, key, value và chiều của key, tương ứng.

3.3 BART

BART là một bộ tự động mã hóa khử nhiễu để huấn luyện trước các mô hình sequence-to-sequence [10]. Nó sử dụng kiến trúc NMT dựa trên Transformer tiêu chuẩn để tổng quát hóa BERT, GPT và nhiều lược đồ huấn luyện trước gần đây khác. BART sử dụng kiến trúc Transformer tiêu chuẩn, ngoại trừ việc nó sửa đổi các hàm kích hoạt ReLU thành GeLU. Biến thể mBART của nó là một bộ tự động mã hóa khử nhiễu sequence-to-sequence được huấn luyện trước trên corpus đơn ngôn ngữ bằng nhiều ngôn ngữ sử dụng mục tiêu BART [4].

3.4 Back-translation

Back-translation là một phương pháp để chuẩn bị corpus song song tổng hợp từ corpus đơn ngôn ngữ cho NMT [11]. Trong các cài đặt tài nguyên thấp, back-translation có thể là một phương pháp rất hiệu quả. Iterative back-translation là một cải tiến hơn nữa [13]. Nó lặp lại qua hai hệ thống back-translation nhiều lần.

--- TRANG 5 ---
MT với BPE Thích ứng với Mã hóa WX 5

Hình 1. NMT Vanilla.

3.5 Ngôn ngữ tương tự

Ngôn ngữ tương tự đề cập đến một nhóm các ngôn ngữ chia sẻ tổ tiên chung hoặc tiếp xúc rộng rãi trong một thời gian dài, hoặc cả hai, với nhau, dẫn đến việc chúng thể hiện sự tương tự về cấu trúc và ngôn ngữ thậm chí qua các họ ngôn ngữ. Ví dụ về các ngôn ngữ chia sẻ tổ tiên chung là các ngôn ngữ Indo-Aryan, ngôn ngữ Romance và ngôn ngữ Slavic. Các ngôn ngữ tiếp xúc trong một thời gian dài dẫn đến sự hội tụ của các đặc điểm ngôn ngữ ngay cả khi các ngôn ngữ không thuộc tổ tiên chung. Tiếp xúc kéo dài giữa các ngôn ngữ có thể dẫn đến việc hình thành các khu vực ngôn ngữ hoặc sprachbunds. Ví dụ về các khu vực ngôn ngữ như vậy là tiểu lục địa Ấn Độ [25], Balkan [42] và khu vực ngôn ngữ Standard Average European [43].

Sự tương tự giữa các ngôn ngữ phụ thuộc vào nhiều yếu tố khác nhau. Một số yếu tố là sự tương tự từ vựng, tương ứng cấu trúc và đồng hình hình thái học. Sự tương tự từ vựng có nghĩa là các ngôn ngữ chia sẻ nhiều từ có dạng tương tự (chính tả/phát âm) và ý nghĩa, ví dụ Sunday được viết là रविवार(ravivAra) trong tiếng Hindi và रबिवार (rabiVra) trong tiếng Bhojpuri (cả hai đều là ngôn ngữ Indo-Aryan gần gũi và có liên quan). Những từ tương tự từ vựng này có thể là cognates, lateral borrowings hoặc loan words từ các ngôn ngữ khác. Tương ứng cấu trúc có nghĩa là, ví dụ, các ngôn ngữ có cùng thứ tự từ cơ bản, tức là SOV (Subject-Object-Verb) hoặc SVO (Subject-Verb-Object). Đồng hình hình thái học đề cập đến tương ứng một-một giữa các phụ tố biến cách. Trong khi các từ nội dung được mượn hoặc kế thừa qua các ngôn ngữ tương tự, các từ chức năng thường không tương tự từ vựng qua các ngôn ngữ. Tuy nhiên, các từ chức năng trong các ngôn ngữ có liên quan (dù là phụ tố hay từ tự do) có xu hướng có tương ứng một-một ở các mức độ khác nhau và cho các chức năng ngôn ngữ khác nhau.

3.6 NMT dựa trên Transformer + Back-translation

Guzmán và cộng sự [3], trong công trình của họ, đầu tiên đã huấn luyện một Transformer trên các cặp ngôn ngữ Nepali-English và Sinhala-English theo cả hai hướng, và sau đó họ đã sử dụng mô hình đã huấn luyện để dịch corpus ngôn ngữ đích đơn ngôn ngữ sang ngôn ngữ nguồn. Cuối cùng, corpus câu ngôn ngữ nguồn được kết hợp với các câu ngôn ngữ nguồn được tạo ra và được đưa làm đầu vào cho Transformer để huấn luyện và tạo ra bản dịch.

4 Phương pháp Đề xuất

Để giải quyết các vấn đề liên quan đến độ phong phú hình thái học trong huấn luyện NMT cho các ngôn ngữ Ấn Độ và để có thể làm việc với rất ít tài nguyên, chúng tôi đề xuất một phương pháp đơn giản nhưng hiệu quả để dịch các ngôn ngữ tài nguyên thấp có các đặc điểm và hành vi tương tự.

Phương pháp đề xuất bao gồm ba module: Text Encoder, Model Trainer và Text Decoder (Hình 2), như được thảo luận trong phần sau.

--- TRANG 6 ---
6 Kumar và cộng sự

Hình 2. Kiến trúc đề xuất.

4.1 Text Encoder

Mô hình đề xuất đầu tiên mã hóa các corpus nguồn và đích của các ngôn ngữ song song thành một biểu diễn trung gian, ký hiệu WX2[1]. Lý do chính đằng sau việc mã hóa các corpus ngôn ngữ nguồn và đích thành ký hiệu WX là để mã hóa các ngôn ngữ khác nhau với cùng hoặc khác chữ viết thành một biểu diễn chung bằng cách chiếu chúng vào một không gian ký tự âm thanh-chính tả chung để BPE có thể được thông báo tốt hơn về mặt ngôn ngữ. Ký hiệu WX là một lược đồ chuyển tự để biểu diễn các ngôn ngữ Ấn Độ ở định dạng ASCII, và như đã mô tả trước đó, nó có nhiều lợi thế như một biểu diễn trung gian, thậm chí so với việc sử dụng Devaganari hoặc bất kỳ chữ viết dựa trên Brahmi đơn lẻ nào khác. Nó ngầm giúp mô hình Transformer encoder mô hình hóa tốt hơn các cognates, loanwords và các từ tương tự hình thái học giữa các ngôn ngữ, cũng như mô hình hóa các loại tương tự khác để dịch thuật tốt hơn.

4.2 Model Training

Biểu diễn trung gian của văn bản ngôn ngữ nguồn được chuyển đến Transformer encoder. Mô hình Transformer encoder-decoder học mối quan hệ giữa các ngôn ngữ. Chúng tôi đã sử dụng thư viện SentencePiece3 để tokenization văn bản. SentencePiece được sử dụng như một nhiệm vụ tiền xử lý cho văn bản được mã hóa WX nguồn-đích trong cặp ngôn ngữ có liên quan. SentencePiece là một tokenizer và detokenizer từ con độc lập ngôn ngữ được thiết kế cho xử lý văn bản dựa trên Neural, bao gồm dịch máy thần kinh. Nó thực hiện hai thuật toán phân đoạn từ con, Byte-Pair Encoding (BPE) và mô hình ngôn ngữ unigram, với huấn luyện trực tiếp từ các câu thô [33,34]. Do đó, nó đã gián tiếp, ở một mức độ nào đó, cung cấp cognates, loan words và các từ tương tự hình thái học cho Transformer, và việc chuyển đổi trước của chúng tôi sang WX cho phép nó làm điều đó tốt hơn. Có thể lưu ý rằng phương pháp này có thể tổng quát hóa cho các ký hiệu chuyển tự đa ngôn ngữ khác, có lẽ thậm chí cho IPA4,5, là ký hiệu gần như thực sự âm thanh cho văn bản viết.

4.3 Text Decoder

Sau khi hội tụ của thuật toán huấn luyện, các câu đích được tạo ra được mã hóa WX được giải mã trở lại định dạng văn bản thuần túy để đánh giá mô hình.

5 Corpus và Cài đặt Thực nghiệm

Trong phần này, chúng tôi thảo luận về thống kê corpus và cài đặt thực nghiệm mà chúng tôi đã sử dụng cho thí nghiệm của mình.

5.1 Mô tả Corpus

Chúng tôi đánh giá mô hình đề xuất trong một kịch bản tài nguyên cực thấp trên các ngôn ngữ tương tự lẫn nhau mà chúng tôi đã chọn cho các thí nghiệm của mình. Đây là Hindi (HI), Gujarati (GU), Marathi (MR), Nepali (NE), Maithili (MAI), Punjabi (PA), Urdu (UR), Bhojpuri (BHO), Magahi (MAG), Malayalam (ML), Tamil (TA) và Telgu (TE). Chúng tôi thực hiện các thí nghiệm trên các cặp ngôn ngữ sau liên quan đến Hindi: GU ↔HI, NE ↔HI, MR ↔HI, MAI↔HI, PA ↔HI và UR ↔HI. Các corpus song song của GU↔HI, ML ↔HI, TA ↔HI và TE ↔HI để huấn luyện, thử nghiệm và xác thực được tải xuống từ CVIT-PIB [14]. Corpus song song MR ↔HI được thu thập từ các nhiệm vụ chia sẻ WMT 2020 6. Corpus cặp ngôn ngữ NE ↔HI được tạo thành từ những corpus được thu thập từ các nhiệm vụ chia sẻ WMT 2019 7, Opus8 và kho lưu trữ TDIL9. Chúng tôi sử dụng corpus đơn ngôn ngữ của Gujarati, Hindi và Marathi để tính toán tương tự trong phần 5.1 từ bộ dữ liệu PM India được mô tả trong [15]. Phần còn lại của các corpus đơn ngôn ngữ được thu thập từ bộ sưu tập Opus để tính toán tương tự trong phần 5.1 [29]. Chúng tôi sử dụng SentencePiece [45] để tiền xử lý các câu nguồn và đích.

2https://pypi.org/project/wxconv/ ,https://github.com/irshadbhat/indic-wx-converter
3https://github.com/google/sentencepiece

4https://en.wikipedia.org/wiki/International\_Phonetic\_Alphabet\_chart
5https://www.internationalphoneticassociation.org/
6http://www.statmt.org/wmt20/similar.html
7http://www.statmt.org/wmt19/index.html
8https://opus.nlpl.eu/
9http://www.tdil-dc.in/index.php?lang=en

--- TRANG 7 ---
MT với BPE Thích ứng với Mã hóa WX 7

Bảng 3. Thống kê Corpus hiển thị số lượng câu huấn luyện, xác thực và thử nghiệm cho mỗi lĩnh vực
Cặp Ngôn ngữ Huấn luyện Xác thực Thử nghiệm Lĩnh vực
GU↔HI 15784 1000 1973 PM India
NE↔HI 136991 3000 3000 Corpus WMT 2019, Nông nghiệp, Giải trí, Kinh thánh
MR↔HI 43274 1000 1411 Tin tức, PM India, Indic WordNet
PA↔HI 225576 7199 7200 GNOME, KDE4, Ubuntu, wikimedia, TED2020
MAI↔HI 93136 2972 2973 GNOME, KDE4, wikimedia, Ubuntu
UR↔HI 108176 3452 3453 Tanzil, GNOME, KDE4, wikimedia, Ubuntu
ML↔HI 17333 500 500 PM India
TA↔HI 43538 500 500 PM India
TE↔HI 2584 500 500 PM India
BHO↔HI 0 500 500 Phụ đề phim, Văn học, Tin tức
MAG ↔HI 0 500 500 Phụ đề phim, Văn học, Tin tức

Ghi chú: HI: Hindi, MR: Marathi, NE: Nepali, GU: Gujarati, MAI: Maithili, PA: Punjabi, UR: Urdu, ML: Malayalam, TA: Tamil, TE: Telgu, BHO: Bhojpuri, MAG: Magahi

Chúng tôi sử dụng 5K thao tác merge để học BPE với mô hình SentencePiece và hạn chế từ vựng nguồn và đích tối đa 5K token. Có một số nơi xảy ra code-switching trong bộ dữ liệu được sử dụng. Công cụ WX-transliteration bỏ qua dữ liệu code-switched và giữ nó trong bộ dữ liệu như vậy.

5.2 Chi tiết Huấn luyện

5.2.1 Phương pháp đề xuất

Chúng tôi sử dụng công cụ ký hiệu WX10 để chuyển tự văn bản và toolkit fairseq11[18], là một toolkit mô hình hóa sequence, để huấn luyện Transformer. Chúng tôi sử dụng năm lớp encoder và decoder. Các chiều embedding encoder và decoder được đặt thành 512. Các chiều embedding feed-forward encoding và decoding được đặt thành 2048. Số lượng head attention encoder và decoder được đặt thành 2. Dropout, attention dropout và ReLU dropout được đặt thành 0.4, 0.2 và 0.2, tương ứng. Weight decay được đặt ở 0.0001 và label smoothing được đặt thành 0.2. Chúng tôi sử dụng optimizer Adam, với β1 và β2 được đặt thành 0.9 và 0.98. Lịch trình learning rate là inverse square root, với learning rate ban đầu là 1e-3 và learning rate tối thiểu là 1e-9. Số lượng token tối đa được sử dụng được đặt thành 4000. Số lượng epoch tối đa để huấn luyện được đặt thành 100. Chúng tôi sử dụng beam size bằng 5 để tạo dữ liệu sử dụng tập thử nghiệm.

5.2.2 Guzmán và cộng sự [3]

Trong Guzmán và cộng sự [3], các tác giả đã chứng minh các thí nghiệm trên các ngôn ngữ tài nguyên cực thấp sử dụng Transformer. Phương pháp đề xuất của chúng tôi dựa trên Transformer được mô tả trong Guzmán và cộng sự [3] với việc bổ sung hai module bổ sung, Text Encoder và Text Decoder. Chúng tôi sử dụng mô hình Transformer được mô tả trong Guzmán và cộng sự [3] như một baseline tương đối cao để so sánh phương pháp đề xuất mà không có biểu diễn trung gian của ký hiệu WX cho các ngôn ngữ Ấn Độ. Việc chiếu sang WX có thể được sử dụng cho bất kỳ phương pháp NMT nào khác cũng sử dụng embedding từ con.

5.2.3 SMT

Chúng tôi sử dụng Moses12, một toolkit mã nguồn mở để huấn luyện SMT [54]. Để có được căn chỉnh cụm từ/từ từ corpus song song, chúng tôi sử dụng GIZA++ [55]. Một mô hình ngôn ngữ KenLM 5-gram được sử dụng để huấn luyện [56]. Các tham số được điều chỉnh trên tập xác thực sử dụng MERT và được thử nghiệm với tập thử nghiệm [57].

6 Kết quả và Phân tích

Chúng tôi so sánh phương pháp đề xuất với SMT dựa trên Moses và mô hình NMT dựa trên Transformer [3], trong đó cái sau được sử dụng làm baseline cho NMT. Chúng tôi sử dụng sáu chỉ số đánh giá, BLEU13[12], LEBLEU [58], WupLeBleu [59], TER [31], WER và chrF2 [30] để so sánh tốt hơn phương pháp đề xuất. Chúng ta thấy từ Bảng 4 và 5 rằng phương pháp đề xuất cải thiện so với baseline cho hầu hết các cặp.

Điểm BLEU, mặc dù là một chỉ số đơn giản dựa trên so sánh n-gram, là một chỉ số tiêu chuẩn được các nhà nghiên cứu NLP chấp nhận để có được độ chính xác của các đầu ra dịch được dự đoán so với các câu tham chiếu được dịch bởi con người. Điều này là do người ta đã quan sát thấy rằng giá trị của điểm BLEU có tương quan tốt với chất lượng dịch thuật được đánh giá bởi con người. Công thức cho điểm BLEU như sau [12]:

BLEU =min(1,output_length/reference_length)∏4i=1precisioni,(4)

10https://pypi.org/project/wxconv/
11https://github.com/facebookresearch/fairseq
12http://www2.statmt.org/moses/
13https://github.com/mjpost/sacrebleu

trong đó output_length và reference_length là độ dài của các câu được dự đoán và các câu tham chiếu, tương ứng.

Chúng tôi cũng thực hiện so sánh giữa SMT không có WX-transliteration và SMT có nó. Hai tập kết quả này cũng được so sánh với phương pháp đề xuất như được hiển thị trong Bảng 6. Trong trường hợp SMT, chúng ta cũng có thể dễ dàng lưu ý rằng hiệu suất cải thiện trong hầu hết các trường hợp bằng cách sử dụng WX như ký hiệu trung gian, mặc dù SMT không sử dụng embedding từ con.

Chúng tôi cũng trình bày một số phân tích cơ bản của các điểm số như được hiển thị trong Bảng 4 và 5. Chúng tôi sử dụng các biện pháp liên quan đến ngôn ngữ và độ phức tạp dựa trên corpus để phân tích thêm cho mục đích này trong phần tiếp theo.

6.1 Tương tự giữa các ngôn ngữ

Vì không có phương pháp dứt khoát để đánh giá sự tương tự giữa hai ngôn ngữ, chúng tôi sử dụng các kỹ thuật sau để tính toán sự tương tự giữa các ngôn ngữ:

6.1.1 SSNGLMScore

Chúng tôi sử dụng các mô hình ngôn ngữ n-gram cấp ký tự dựa trên SSNGLMScore để đo lường mối liên hệ giữa các ngôn ngữ [28, 32]. SSNGLMScore được tính như sau:

Ssl,tl=∑mtl=1psl.tl(wn|wn−11), (5)

trong đó S là Scaled Sum của điểm mô hình ngôn ngữ n-gram.

MSsl,tl=Ssl,tl−min(SSL,TL)max(SSL,TL)−min(SSL,TL),(6)

trong đó, sl và tl đại diện cho ngôn ngữ nguồn và ngôn ngữ đích, tương ứng. Hơn nữa, sl∈SL(Gujarati, Marathi, Maithili, Nepali, Urdu, Punjabi, Hindi, Malayalam, Tamil, Telugu, Bhojpuri, Magahi) và m là tổng số câu trong ngôn ngữ đích tl∈TL(Gujarati, Marathi, Maithili, Nepali, Urdu, Punjabi, Hindi, Malayalam, Tamil, Telugu, Bhojpuri, Magahi). Chúng tôi huấn luyện mô hình ngôn ngữ sử dụng mô hình KenLM cấp ký tự 6-gram trên corpus đơn ngôn ngữ nguồn

--- TRANG 8 ---
8 Kumar và cộng sự

Bảng 4. Kết quả thí nghiệm (điểm BLEU, chrF2 và TER).
Ngôn ngữ(xx) BLEU chrF2 TER
XX→HI
Guzmán và cộng sự [3] Đề xuất Guzmán và cộng sự [3] Đề xuất Guzmán và cộng sự [3] Đề xuất
GU 33.14 33.15 58 57 0.541 0.548
NE 30.51 41.97 46 49 0.658 0.652
MR 16.87 22.37 43 44 0.707 0.709
PA 78.56 81.05 82 82 0.220 0.216
UR 28.74 30.08 45 45 0.668 0.657
MAI 79.49 81.80 82 81 0.242 0.251

HI→XX
Guzmán và cộng sự [3] Đề xuất Guzmán và cộng sự [3] Đề xuất Guzmán và cộng sự [3] Đề xuất
GU 25.47 25.82 56 56 0.616 0.619
NE 32.89 43.52 50 51 0.630 0.637
MR 14.05 14.76 41 44 0.789 0.762
PA 80.01 81.87 83 84 0.206 0.203
UR 22.74 24.35 46 47 0.597 0.596
MAI 86.58 83.82 89 86 0.148 0.168

Bảng 5. Điểm LEBLEU, WupLeBleu và WER.
Ngôn ngữ(xx) LEBLEU WupLeBLEU WER
XX→HI
Guzmán và cộng sự [3] Đề xuất Guzmán và cộng sự [3] Đề xuất Guzmán và cộng sự [3] Đề xuất
GU 0.663 0.657 0.663 0.657 66.77 66.29
NE 0.543 0.547 0.543 0.547 66.99 67.71
MR 0.495 0.541 0.495 0.541 72.78 73.36
PA 0.853 0.853 0.853 0.853 22.29 21.83
UR 0.564 0.566 0.564 0.566 68.34 67.20
MAI 0.865 0.851 0.865 0.851 24.34 25.23

HI→XX
Guzmán và cộng sự [3] Đề xuất Guzmán và cộng sự [3] Đề xuất Guzmán và cộng sự [3] Đề xuất
GU 0.622 0.623 0.622 0.623 73.11 73.33
NE 0.547 0.519 0.547 0.519 63.41 65.31
MR 0.485 0.454 0.485 0.454 80.10 77.46
PA 0.858 0.865 0.858 0.865 20.88 20.57
UR 0.619 0.629 0.619 0.629 62.35 62.27
MAI 0.916 0.908 0.916 0.908 14.83 16.89

(sl). Mỗi mô hình ngôn ngữ được thử nghiệm trên ngôn ngữ đích (tl), và các điểm số được báo cáo.

Bảng 7 liệt kê các điểm tương tự đa ngôn ngữ của Hindi, Gujarati, Marathi, Nepali, Maithili, Punjabi, Malayalam, Tamil, Telugu, Bhojpuri, Magahi và Urdu với nhau. Dựa trên SSNGLMScore, Bhojpuri, Maithili và Magahi là gần nhất với Hindi, điều này phù hợp với kiến thức ngôn ngữ về chúng, trong khi Urdu dường như xa với Hindi như Malayalam và hơn Telugu. Lý do Urdu xa với Hindi một phần là do Urdu được viết bằng một loại chữ viết khác với Hindi không có ánh xạ trực tiếp với WX, nhưng chủ yếu là vì, mặc dù về mặt ngữ pháp gần như giống hệt, hai ngôn ngữ sử dụng từ vựng rất khác nhau ở dạng viết và chính thức. Maithili cũng là ngôn ngữ chính thức thứ hai của Nepal và cũng có tính tương tự cao với Nepali, có lẽ do sự tiếp xúc chặt chẽ kéo dài. Điều đáng ngạc nhiên hơn là sự tương tự giữa Urdu và Nepali tương đối cao, trong khi sự tương tự giữa Urdu và Hindi nằm trong số thấp nhất. Điều này có thể là do bản chất của corpus. Xem qua Bảng 4 và 5, chúng tôi thấy rằng có sự cải thiện trong mọi chỉ số ngoại trừ WER và TER trong phần lớn các trường hợp khi chúng tôi áp dụng phương pháp đề xuất trên hướng dịch từ Maithili, Gujarati, Marathi, Nepali, Punjabi và Urdu sang Hindi. Quan sát này cho phép chúng tôi khẳng định rằng phương pháp đề xuất cải thiện hiệu suất cho dịch thuật giữa các ngôn ngữ tương tự. Do đó, mặc dù biện pháp tương tự mà chúng tôi sử dụng pha trộn các loại tương tự khác nhau, nó phù hợp cho mục đích của chúng tôi vì phương pháp của chúng tôi dựa trên mô hình hóa từ con và đa ngôn ngữ.

Chúng tôi cũng thấy tăng +1.34 điểm BLEU trên Hindi sang Urdu mặc dù Urdu xa so với phần còn lại của các cặp ngôn ngữ về điểm tương tự mà chúng tôi sử dụng. Có sự cải thiện đáng kể +11.46 điểm BLEU trên các cặp ngôn ngữ HI →NE và +10.63 điểm BLEU trên NE →HI.

6.1.2 char-BLEU, TER và chrF2

Để hiểu rõ hơn về sự giảm nhẹ điểm BLEU mặc dù có sự tương tự cho MAI →HI và sự tăng lớn trong trường hợp NE ↔Hi (trong đó Nepali và Maithili được biết là gần gũi), chúng tôi cũng tính toán sự tương tự bằng cách áp dụng char-BLEU [44], chrF2 và TER trên bộ dữ liệu huấn luyện của tất cả các cặp ngôn ngữ. Lý do đằng sau việc sử dụng char-BLEU và chrF2 cho sự tương tự là vì chúng là các chỉ số dựa trên ký tự, có cơ hội lớn hơn để bao phủ các khía cạnh hình thái học. Trước khi tính toán char-BLEU, TER và các chỉ số đánh giá chrF2, dữ liệu phải ở cùng chữ viết để đánh giá điểm số. Vì vậy, chúng tôi chuyển đổi corpus từ UTF-8 sang ký hiệu WX. Bảng 8 chứa điểm char-BLEU của các cặp ngôn ngữ, trong khi Bảng 9 chứa điểm TER và chrF2 của mỗi cặp ngôn ngữ. Chúng ta thấy Bảng 8 và 9 và phát hiện ra rằng HI và MAI vẫn tương tự hơn so với các cặp khác. Chúng tôi chỉ có thể giả thuyết lý do là do bản chất của dữ liệu mà chúng tôi đã sử dụng.

6.2 Phân tích về độ phức tạp ngôn ngữ

6.2.1 Độ phức tạp hình thái học

Vì các ngôn ngữ Ấn Độ có tính phong phú hình thái học, các hệ thống dịch máy dựa trên token từ gặp khó khăn với chúng. Do đó, chúng tôi cũng cố gắng liên hệ các kết quả thu được với các ước tính về độ phức tạp như vậy thu được từ entropy cấp ký tự. Có lý khi giả định rằng entropy cấp ký tự càng lớn, ngôn ngữ càng có khả năng phức tạp về mặt hình thái học.

Entropy cấp ký tự Chúng tôi đã sử dụng entropy từ cấp ký tự để ước tính sự dư thừa hình thái học, theo Bharati và cộng sự [74] và Bentz và Alikaniotis 2016 [35]. Một "từ" được định nghĩa trong các thí nghiệm của chúng tôi như một token được phân tách bằng dấu cách, tức là, một chuỗi các ký tự Unicode chữ và số được phân tách bằng khoảng trắng. Nội dung thông tin trung bình của các loại ký tự cho từ sau đó được tính theo entropy Shannon [36]:

H(T)=−∑Vi=1p(ci) log2(p(ci)) (7)

trong đó V là số ký tự (ci) trong một từ.

Bảng 10 liệt kê entropy từ (unigram) của các ngôn ngữ ở cấp ký tự, điều này gián tiếp đại diện cho sự phong phú từ vựng của ngôn ngữ, tức là, độ phức tạp – về mặt ký tự chúng được tạo thành – của các dạng từ. Vì chúng tôi tính toán entropy unigram dựa trên ký tự, chúng tôi có thể nói rằng sự phong phú từ vựng cũng chỉ ra độ phức tạp hình thái học, cả dẫn xuất và biến cách. Dựa trên các giá trị entropy từ dựa trên corpus, có vẻ như Hindi phức tạp hơn về mặt hình thái học so với sáu ngôn ngữ khác. Tuy nhiên, điều này có thể là độ phức tạp dẫn xuất hơn là độ phức tạp biến cách

--- TRANG 9 ---
MT với BPE Thích ứng với Mã hóa WX 9

Bảng 6. So sánh điểm BLEU dựa trên SMT, SMT + WX và các phương pháp đề xuất.
Ngôn ngữ(xx) BLEU
XX→HI
SMT SMT + WX Đề xuất
GU 43.49 30.69 33.15
NE 40.14 53.21 41.97
MR 7.41 1.46 22.37
PA 68.34 71.22 81.05
UR 19.21 21.84 30.08
MAI 79.56 81.46 81.80

HI→XX
SMT SMT + WX Đề xuất
GU 39.20 25.89 25.82
NE 40.21 54.84 43.52
MR 7.36 1.48 14.76
PA 67.21 70.64 81.87
UR 18.24 18.41 24.35
MAI 79.12 83.06 83.82

(sl). Mỗi mô hình ngôn ngữ được thử nghiệm trên ngôn ngữ đích (tl), và các điểm số được báo cáo.

Bảng 7 liệt kê các điểm tương tự đa ngôn ngữ của Hindi, Gujarati, Marathi, Nepali, Maithili, Punjabi, Malayalam, Tamil, Telugu, Bhojpuri, Magahi và Urdu với nhau. Dựa trên SSNGLMScore, Bhojpuri, Maithili và Magahi là gần nhất với Hindi, điều này phù hợp với kiến thức ngôn ngữ về chúng, trong khi Urdu dường như xa với Hindi như Malayalam và hơn Telugu. Lý do Urdu xa với Hindi một phần là do Urdu được viết bằng một loại chữ viết khác với Hindi không có ánh xạ trực tiếp với WX, nhưng chủ yếu là vì, mặc dù về mặt ngữ pháp gần như giống hệt, hai ngôn ngữ sử dụng từ vựng rất khác nhau ở dạng viết và chính thức. Maithili cũng là ngôn ngữ chính thức thứ hai của Nepal và cũng có tính tương tự cao với Nepali, có lẽ do sự tiếp xúc chặt chẽ kéo dài. Điều đáng ngạc nhiên hơn là sự tương tự giữa Urdu và Nepali tương đối cao, trong khi sự tương tự giữa Urdu và Hindi nằm trong số thấp nhất. Điều này có thể là do bản chất của corpus. Xem qua Bảng 4 và 5, chúng tôi thấy rằng có sự cải thiện trong mọi chỉ số ngoại trừ WER và TER trong phần lớn các trường hợp khi chúng tôi áp dụng phương pháp đề xuất trên hướng dịch từ Maithili, Gujarati, Marathi, Nepali, Punjabi và Urdu sang Hindi. Quan sát này cho phép chúng tôi khẳng định rằng phương pháp đề xuất cải thiện hiệu suất cho dịch thuật giữa các ngôn ngữ tương tự. Do đó, mặc dù biện pháp tương tự mà chúng tôi sử dụng pha trộn các loại tương tự khác nhau, nó phù hợp cho mục đích của chúng tôi vì phương pháp của chúng tôi dựa trên mô hình hóa từ con và đa ngôn ngữ.

Chúng tôi cũng thấy tăng +1.34 điểm BLEU trên Hindi sang Urdu mặc dù Urdu xa so với phần còn lại của các cặp ngôn ngữ về điểm tương tự mà chúng tôi sử dụng. Có sự cải thiện đáng kể +11.46 điểm BLEU trên các cặp ngôn ngữ HI →NE và +10.63 điểm BLEU trên NE →HI.

Trong Bảng 11, 12 và 13, chúng tôi trình bày các giá trị entropy và redundancy từ ở cấp ký tự. Các bảng này cho thấy rằng entropy tăng khi chuyển đổi sang WX và redundancy giảm. Đây là bằng chứng cho thực tế rằng việc chiếu vào một không gian chung về mặt chính tả và âm thanh làm cho entropy tăng và redundancy giảm, do đó cho phép các biểu diễn compact hơn được học từ dữ liệu sau khi chuyển đổi sang WX trong trường hợp của chúng tôi.

6.2.2 Độ phức tạp cú pháp

Perplexity Perplexity (PP) của một ngôn ngữ có thể được xem như trung bình có trọng số của nghịch đảo của hệ số phân nhánh của nó [28]. Hệ số phân nhánh là số từ có thể theo sau bất kỳ từ nào dựa trên ngữ cảnh. Do đó, perplexity – như một loại hệ số phân nhánh trung bình – là đại diện trung bình của các từ có thể theo sau cho trước một từ. Do đó, nó có thể được xem như một biện pháp thô của độ phức tạp cú pháp. Nếu mô hình là một biểu diễn đủ tốt của phân phối thực cho ngôn ngữ, thì giá trị PP sẽ thực sự chỉ ra độ phức tạp cú pháp.

Để ước tính khoảng cách của các ngôn ngữ khác từ Hindi sử dụng perplexity, chúng tôi đã huấn luyện mô hình perplexity trên corpus Hindi và thử nghiệm nó trên corpus của các ngôn ngữ khác.

PP(C)=W√(1/P(S1,S2,S3, ...,Sn))(8)

trong đó corpus C chứa n câu với W từ.

Bảng 14 và 15 chứa các giá trị perplexity bất đối xứng và đối xứng — trung bình của hai hướng dịch — giữa các cặp ngôn ngữ có liên quan và chỉ ra khoảng cách của chúng từ Hindi dựa trên mô hình ngôn ngữ cấp ký tự. Các cặp có điểm perplexity cao hơn có nghĩa là các ngôn ngữ xa hơn. Chúng ta thấy các cặp ngôn ngữ Urdu và Hindi có điểm perplexity cao hơn. Điều này chủ yếu là vì hai ngôn ngữ này, mặc dù gần như giống hệt ở dạng nói và về mặt cú pháp cốt lõi và từ vựng cốt lõi, sử dụng từ vựng mở rộng rất khác nhau cho mục đích viết và chính thức, bên cạnh việc sử dụng các hệ thống viết rất khác nhau. Urdu viết tiêu chuẩn sử dụng các từ Ba Tư, Ả Rập và Thổ Nhĩ Kỳ một cách nặng nề, dù được điều chỉnh về mặt âm vị học hay không.

Với lượng dữ liệu nhỏ, không có gì đáng ngạc nhiên khi các giá trị perplexity khác nhau ở hai hướng dịch.

Tương tự, Hindi tiêu chuẩn và viết sử dụng các từ nhiều hơn được dẫn xuất hoặc mượn hoặc thậm chí được đặt ra

--- TRANG 10 ---
10 Kumar và cộng sự

Bảng 7. Tương tự giữa các ngôn ngữ sử dụng SSNGLMScore
Mô hình BHO GU HI MAG MAI ML MR NE PA TA TE UR
BHO - 0.5659 0.6725 0.6997 0.7235 0.4090 0.5687 0.4979 0.4580 0.3233 0.5057 0.4237
GU - - 0.5483 0.5642 0.6449 0.3727 0.5411 0.3868 0.3408 0.2531 0.4578 0.3787
HI - - - 0.6331 0.6598 0.3536 0.5717 0.4181 0.4046 0.2564 0.4567 0.3670
MAG - - - - 0.7762 0.4414 0.5724 0.5671 0.4827 0.3736 0.5248 0.5245
MAI - - - - - 0.5833 0.6496 0.6968 0.5734 0.5453 0.6435 0.7040
ML - - - - - - 0.3736 0.3388 0.1968 0.3792 0.4507 0.2759
MR - - - - - - - 0.4023 0.3496 0.2637 0.4771 0.3498
NE - - - - - - - - 0.2661 0.2784 0.3985 0.4354
PA - - - - - - - - - 0.1449 0.2718 0.2938
TA - - - - - - - - - - 0.2972 0.2641
TE - - - - - - - - - - - 0.3493
UR - - - - - - - - - - - -

Bảng 8. Điểm char-BLEU trên dữ liệu huấn luyện
Ngôn ngữ char-BLEU
Gujarati ↔Hindi 47.29
Marathi ↔Hindi 35.05
Nepali ↔Hindi 40.53
Maithili ↔Hindi 66.70
Punjabi ↔Hindi 37.17
Urdu↔Hindi 8.61
Ghi chú: Áp dụng điểm char-BLEU trên dữ liệu huấn luyện của cả hai ngôn ngữ của cặp

độ phức tạp, vì Hindi tương đối đơn giản hơn về mặt hình thái biến cách. Độ phức tạp dẫn xuất cao của Hindi là do nó là ngôn ngữ chính thức của Ấn Độ và được tiêu chuẩn hóa hơn hầu hết các ngôn ngữ Ấn Độ khác. Do đó, nó đã mượn và đặt ra một số lượng lớn các từ phức tạp và thuật ngữ kỹ thuật, dù từ Ba Tư hay Sanskrit hay tiếng Anh. Điều này bổ sung rất nhiều cho độ phức tạp dẫn xuất của Hindi viết chính thức, so với Hindi thông thường được nói. Ít nhất, đây là giả thuyết của chúng tôi dựa trên kết quả tương tự và độ phức tạp.

Chúng tôi cũng thấy rằng phương pháp của chúng tôi cho thấy sự cải thiện đáng kể khoảng hơn 10 điểm BLEU theo cả hai hướng cho cặp ngôn ngữ Hindi-Nepali, tức là NE →HI và HI →NE. Sự cải thiện như vậy có thể được quy cho hiệu ứng gây ra bởi việc chiếu vào một ký hiệu chính tả-âm thanh đa ngôn ngữ chung, đó là WX. Điều này có lẽ giúp Transformer học ngữ cảnh giữa các ngôn ngữ tốt hơn với sự trợ giúp của tokenizer sentence piece.

Trong Bảng 11, 12 và 13, chúng tôi trình bày các giá trị entropy và redundancy từ ở cấp ký tự. Các bảng này cho thấy rằng entropy tăng khi chuyển đổi sang WX và redundancy giảm. Đây là bằng chứng cho thực tế rằng việc chiếu vào một không gian chung về mặt chính tả và âm thanh làm cho entropy tăng và redundancy giảm, do đó cho phép các biểu diễn compact hơn được học từ dữ liệu sau khi chuyển đổi sang WX trong trường hợp của chúng tôi.

6.2.2 Độ phức tạp cú pháp

Perplexity Perplexity (PP) của một ngôn ngữ có thể được xem như trung bình có trọng số của nghịch đảo của hệ số phân nhánh của nó [28]. Hệ số phân nhánh là số từ có thể theo sau bất kỳ từ nào dựa trên ngữ cảnh. Do đó, perplexity – như một loại hệ số phân nhánh trung bình – là đại diện trung bình của các từ có thể theo sau cho trước một từ. Do đó, nó có thể được xem như một biện pháp thô của độ phức tạp cú pháp. Nếu mô hình là một biểu diễn đủ tốt của phân phối thực cho ngôn ngữ, thì giá trị PP sẽ thực sự chỉ ra độ phức tạp cú pháp.

Để ước tính khoảng cách của các ngôn ngữ khác từ Hindi sử dụng perplexity, chúng tôi đã huấn luyện mô hình perplexity trên corpus Hindi và thử nghiệm nó trên corpus của các ngôn ngữ khác.

PP(C)=W√(1/P(S1,S2,S3, ...,Sn))(8)

trong đó corpus C chứa n câu với W từ.

Bảng 14 và 15 chứa các giá trị perplexity bất đối xứng và đối xứng — trung bình của hai hướng dịch — giữa các cặp ngôn ngữ có liên quan và chỉ ra khoảng cách của chúng từ Hindi dựa trên mô hình ngôn ngữ cấp ký tự. Các cặp có điểm perplexity cao hơn có nghĩa là các ngôn ngữ xa hơn. Chúng ta thấy các cặp ngôn ngữ Urdu và Hindi có điểm perplexity cao hơn. Điều này chủ yếu là vì hai ngôn ngữ này, mặc dù gần như giống hệt ở dạng nói và về mặt cú pháp cốt lõi và từ vựng cốt lõi, sử dụng từ vựng mở rộng rất khác nhau cho mục đích viết và chính thức, bên cạnh việc sử dụng các hệ thống viết rất khác nhau. Urdu viết tiêu chuẩn sử dụng các từ Ba Tư, Ả Rập và Thổ Nhĩ Kỳ một cách nặng nề, dù được điều chỉnh về mặt âm vị học hay không.

Với lượng dữ liệu nhỏ, không có gì đáng ngạc nhiên khi các giá trị perplexity khác nhau ở hai hướng dịch.

Tương tự, Hindi tiêu chuẩn và viết sử dụng các từ nhiều hơn được dẫn xuất hoặc mượn hoặc thậm chí được đặt ra

--- TRANG 11 ---
MT với BPE Thích ứng với Mã hóa WX 11

Bảng 9. Điểm TER và chrF2 trên dữ liệu huấn luyện
Ngôn ngữ GU→HI MR→HI NE→HI MAI→HI PA→HI UR→HI
TER 1.066 1.300 1.052 0.610 0.988 1.093
chrF2 38 29 34 65 32 12
Ngôn ngữ HI→GU HI→MR HI→NE HI→MAI HI→PA HI→UR
TER 0.884 0.940 0.887 0.555 0.906 1.044
chrF2 39 29 36 62 30 10
Ghi chú: Áp dụng điểm TER và chrF2 trên dữ liệu huấn luyện của cả hai ngôn ngữ của một cặp

Bảng 10. Entropy dựa trên ký tự của các ngôn ngữ có hoặc không áp dụng ký hiệu WX
Ngôn ngữ Entropy Ký tự Entropy Ký tự* Khác biệt
Gujarati 5.0368 3.7454 1.2914
Marathi 5.0220 3.6846 1.3374
Nepali 4.6722 3.5770 1.0952
Maithili 5.1159 3.9162 1.1997
Punjabi 5.0834 3.7932 1.2902
Urdu 4.8821 4.1198 0.7623
Hindi 5.2195 3.7974 1.4221
*Sau khi áp dụng ký hiệu WX

từ Sanskrit. Mặc dù perplexity cao hơn giữa hai ngôn ngữ này, phương pháp của chúng tôi cho tăng +2 trong điểm BLEU, có lẽ vì cú pháp cốt lõi chung và từ vựng cốt lõi thể hiện chính chúng trong mọi cụm từ hoặc câu và do đó có trọng số xác suất cao hơn. Chúng, trên thực tế, hoàn toàn hiểu được lẫn nhau ở dạng nói và một phần ở dạng viết. Cũng có rất nhiều người Ấn Độ có thể thoải mái đọc và hiểu cả hai ngôn ngữ này, thậm chí ở dạng tiêu chuẩn, viết và văn học của chúng. Việc sử dụng WX có lẽ cho phép các mô hình khai thác tốt hơn sự tương tự cốt lõi.

7 Nghiên cứu Ablation

Phần này thảo luận về các nghiên cứu ablation được tiến hành sử dụng phương pháp đề xuất trên các cặp ngôn ngữ xa và zero-shot và back-translation.

7.1 Phân tích phương pháp đề xuất trên các cặp ngôn ngữ xa hơn

Để xem liệu phương pháp của chúng tôi có tổng quát hóa được cho các cặp ngôn ngữ xa hơn hay không và ở mức độ nào, chúng tôi cũng phân tích hiệu suất của phương pháp đề xuất trên (ML ↔HI, TA↔HI và TE ↔HI). Malayalam, Tamil và Telugu thuộc họ Dravidian, và Hindi thuộc họ Indo-Aryan. Chúng tôi lưu ý rằng dịch giữa ba ngôn ngữ Dravidian này và Hindi vẫn dẫn đến cải thiện, xem xét cả điểm chrF2 và BLEU. Kết quả được hiển thị trong Bảng 16.

7.2 Cài đặt không giám sát

Chúng tôi cũng chứng minh phương pháp đề xuất trong các kịch bản không giám sát trên các cặp ngôn ngữ zero-shot, Bhojpuri-Hindi và Magahi-Hindi, mà không có corpus huấn luyện song song nào có sẵn. Các bộ dữ liệu xác thực cho các thí nghiệm zero-shot được thu thập từ các nhiệm vụ chia sẻ LoResMT 202014. Để huấn luyện mô hình, chúng tôi sử dụng các cặp ngôn ngữ NE ↔HI và sử dụng chuyển giao ngôn ngữ trên các cặp zero-shot để đánh giá mô hình trên các bộ dữ liệu xác thực. Lý do đằng sau việc sử dụng các cặp ngôn ngữ NE ↔HI để huấn luyện mô hình trong các thí nghiệm không giám sát trên Bhojpuri-Hindi và Magahi-Hindi là sự tương tự cao hơn giữa các cặp ngôn ngữ NE↔HI với cả các cặp ngôn ngữ zero-shot Bhojpuri-Hindi và Magahi-Hindi dựa trên [65]. Kết quả được hiển thị trong Bảng 17, chứng minh sự cải thiện trong các cài đặt không giám sát cũng.

7.3 Back-translation

Cuối cùng chúng tôi báo cáo kết quả về việc sử dụng phương pháp cùng với Back-Translation, đã được chứng minh là có lợi cho dịch máy cho các ngôn ngữ tài nguyên rất thấp. Chúng tôi đã chọn các cặp ngôn ngữ Gujarati và Hindi để thực hiện Back-Translation (BT) với phương pháp đề xuất. Với Back-Translation cũng vậy, phương pháp đề xuất cho thấy sự cải thiện điểm BLEU +0.97 trên HI→GU và +1.36 trên các cặp ngôn ngữ GU →HI, như được hiển thị trong Bảng 18.

8 Kết luận và Phạm vi Tương lai

Trong công trình này, chúng tôi đã đề xuất một phương pháp hệ thống MT đơn giản nhưng hiệu quả bằng cách mã hóa chữ viết nguồn và đích thành một biểu diễn trung gian, ký hiệu WX, giúp các mô hình được học trong một không gian âm thanh và chính tả chung. Việc chiếu ngôn ngữ này giảm độ phức tạp bề mặt của thuật toán và cho phép mạng nơ-ron mô hình hóa tốt hơn các mối quan hệ giữa các ngôn ngữ để cung cấp một bản dịch được cải thiện. Hơn nữa, chúng tôi đã nghiên cứu những kết quả này bằng cách ước tính sự tương tự và độ phức tạp của các cặp ngôn ngữ và các ngôn ngữ cá nhân để xác minh rằng kết quả của chúng tôi nhất quán và đồng ý với các sự kiện được biết một cách trực giác về sự gần gũi hoặc khoảng cách giữa các cặp ngôn ngữ khác nhau. Hơn nữa, phương pháp này hoạt động tốt trong các cài đặt không giám sát và hoạt động tốt cho một số cặp ngôn ngữ xa. Phương pháp đề xuất cải thiện các phương pháp baseline từ 0.01 điểm BLEU đến 11.46 điểm BLEU

14https://sites.google.com/view/loresmt

--- TRANG 12 ---
12 Kumar và cộng sự

Bảng 11. Entropy được tính trên Từ vựng
Ngôn ngữ Corpus đầy đủ Corpus hạn chế
Không có WX Có WX Không có WX Có WX
Max Median Average Max Median Average Max Median Average Max Median Average
HI 3.1674 0.5897 0.6196 4.9433 1.2484 1.3148 3.1623 0.5929 0.6230 4.9414 1.2495 1.3158
GU 6.4712 0.8113 0.8389 17.9337 1.4677 1.5157 6.4735 0.8128 0.8410 22.2253 1.4681 1.5163
NE 3.0311 0.8008 0.8287 6.6845 1.4327 1.4835 1.8080 0.5350 0.5636 4.7487 1.1262 1.1575
MR 3.7534 0.5982 0.6281 7.7372 1.2331 1.2995 3.5845 0.8049 0.8459 7.7400 1.2130 1.2734
PA 2.2077 0.5778 0.6048 8.9978 1.0349 1.1105 2.1662 0.5500 0.5753 13.5759 0.9644 1.0405
UR 2.8580 0.6484 0.6786 3.092 0.7748 0.8088 2.2477 0.6282 0.6574 3.3297 0.7523 0.7828
MAI 2.0163 0.5097 0.5326 4.3135 1.0904 1.1432 1.6417 0.4773 0.5003 3.8923 1.0401 1.0888

Bảng 12. Redundancy
Ngôn ngữ Corpus đầy đủ Corpus hạn chế
Không có WX WX Không có WX WX
HI 0.8955 0.7693 0.8949 0.7691
GU 0.8606 0.7401 0.8603 0.7400
NE 0.8806 0.7866 0.9111 0.8147
MR 0.9050 0.7993 0.8610 0.7807
PA 0.9186 0.8502 0.9194 0.8554
UR 0.8941 0.8741 0.8968 0.8750
MAI 0.9125 0.8121 0.9172 0.8171

điểm. Phương pháp đề xuất có một số hạn chế và điều kiện biên. Đầu tiên, nó yêu cầu một chữ viết chuyển tự chung, có thể không có sẵn cho tất cả các ngôn ngữ phong phú về mặt hình thái học. Thứ hai, nó chỉ áp dụng cho các ngôn ngữ Ấn Độ. Thứ ba, chúng ta có thể thấy từ Bảng 16 rằng hiệu suất trên các cặp ngôn ngữ xa không đạt được kỳ vọng.

Trong tương lai, chúng tôi dự định mở rộng phương pháp này theo các cách khác nhau được mô tả dưới đây:

a. Hệ thống NMT đa ngôn ngữ: Vì phương pháp đề xuất chuyển đổi tất cả các chữ viết ngôn ngữ Ấn Độ thành một ký hiệu chung gọi là WX, việc chuyển đổi này ủng hộ các embedding từ con để hoạt động như embedding ký tự. Do đó, có thể có lợi hơn khi thực hiện phương pháp này trong (các) hệ thống đa ngôn ngữ cho tất cả các ngôn ngữ Ấn Độ.

b. BART, MBART và các biểu diễn khác: Chúng tôi đã thử dịch thuật dựa trên MBART của Gujarati sang Hindi và Hindi sang Gujarati, và kết quả tệ hơn một transformer vanilla. Vì vậy, chúng tôi dự định mở rộng phương pháp đề xuất sang nhiều biểu diễn hơn như BART, MBART và các kỹ thuật biểu diễn tiên tiến khác cho Deep Learning.

c. Các ngôn ngữ Dravidian và phần còn lại của họ ngôn ngữ Indo-Aryan: Chúng tôi cũng dự định mở rộng phương pháp đề xuất cho họ ngôn ngữ Dravidian và phần còn lại của các ngôn ngữ Indo-Aryan.

Tài liệu tham khảo
[1]Gillon B S 1995 Review of Natural language processing: a Paninian perspective by Akshar Bharati, Vineet Chaitanya, and Rajeev Sangal. Prentice-Hall of India 1995. Computational Linguistics. 21(3): 419-421

[2]Klein G, Kim Y, Deng Y, Senellart J, and Rush A M 2017 OpenNMT: Open-Source Toolkit for Neural Machine Translation. Proc.ACL 2017, System Demonstrations. Vancouver, Canada. ACL. 67–72

[3]Guzmán F, Chen P J, Ott M, Pino J, Lample G, Koehn P, Chaudhary V, and Ranzato M A 2019 The FLORES Evaluation Datasets for Low-Resource Machine Translation: Nepali–English and Sinhala–English. Proc. EMNLP-IJCNLP 2019. Hong Kong, China. ACL. 6098–6111

[4]Liu Y, Gu J, Goyal N, Li X, Edunov S, Ghazvininejad M, Lewis M, and Zettlemoyer L 2020 Multilingual Denoising Pre-training for Neural Machine Translation. Transactions of the Association for Computational Linguistics. 8: 726–742

[5]Johnson M, Schuster M, Le Q V, Krikun M, Wu Y, Chen Z, Thorat N, Viégas F, Wattenberg M, Corrado G, Hughes M, and Dean J 2017 Google's Multilingual Neural Machine Translation System: Enabling Zero-Shot Translation. Transactions of the Association for Computational Linguistics. 5: 339–351

[6]Vaswani A, Shazeer N, Parmar N, Uszkoreit J, Jones L, Gomez A N, Kaiser L, Polosukhin I 2017 Attention is All you Need. Advances in Neural Information Processing Systems. Curran Associates, Inc. 30: 5998–6008

[7]Luong T, Pham H, and Manning C D 2015 Effective Approaches to Attention-based Neural Machine Translation. Proc. EMNLP 2015. Lisbon, Portugal. ACL. 1412–1421

[8]Currey A and Heafield K 2019 Incorporating Source Syntax into Transformer-Based Neural Machine

--- TRANG 13 ---
MT với BPE Thích ứng với Mã hóa WX 13

Bảng 13. Entropy và Redundancy
Cặp ngôn ngữ Không có WX Có WX
Maximum Entropy Median Entropy Average Entropy Redundancy Maximum Entropy Median Entropy Average Entropy Redundancy
GU-HI 4.8292 0.43224 0.4985 0.9279 17.7731 1.3958 1.4509 0.7512
NE-HI 3.0273 0.7414 0.7725 0.8948 7.1454 1.3561 1.4126 0.7988
MR-HI 3.7557 0.6003 0.6303 0.9047 7.7342 1.2309 1.2977 0.7995
PA-HI 1.6642 0.3359 0.3510 0.9543 9.0232 1.1199 1.1843 0.8414
UR-HI 1.9841 0.3547 0.3864 0.9489 4.0133 0.7928 0.8472 0.8783
MAI-HI 2.0483 0.5340 0.5555 0.9096 6.8270 1.1097 1.1656 0.8091

Bảng 14. Khoảng cách đa ngôn ngữ giữa các ngôn ngữ sau khi áp dụng mô hình ngôn ngữ cấp ký tự sử dụng điểm dựa trên perplexity (Không chuẩn hóa theo hướng ngôn ngữ)
Ngôn ngữ BHO GU HI MAG MAI ML MR NE PA TA TE UR
BHO 0.0010 0.0443 0.0280 0.0290 0.0617 0.1006 0.0418 0.1648 0.0507 0.1383 0.0790 0.3134
GU 0.0319 0.0 0.0312 0.0504 0.0704 0.0648 0.0302 0.1736 0.0663 0.1117 0.0556 0.2675
HI 0.0116 0.0312 0.0007 0.0290 0.0715 0.0900 0.0190 0.1670 0.0458 0.1393 0.0705 0.2933
MAG 0.0414 0.0992 0.0712 6.3465e-06 0.0739 0.1897 0.0924 0.1710 0.0834 0.2036 0.1693 0.3491
MAI 0.0806 0.0875 0.0891 0.1340 0.0002 0.1394 0.0986 0.1769 0.0941 0.2168 0.1295 0.4006
ML 0.0713 0.0667 0.0773 0.0962 0.0790 0.0002 0.0695 0.1323 0.1171 0.0497 0.0403 0.3785
MR 0.0308 0.0280 0.0314 0.0503 0.0682 0.0623 0.0007 0.1625 0.0644 0.1175 0.0445 0.3423
NE 0.0949 0.1536 0.1370 0.1065 0.0955 0.1962 0.1321 0.0003 0.2130 0.2506 0.1862 0.3350
PA 0.0545 0.0935 0.0612 0.0782 0.0892 0.1573 0.0785 0.2762 0.0003 0.1716 0.1485 0.3245
TA 0.1239 0.1439 0.1384 0.1595 0.1009 0.0487 0.1204 0.1761 0.1613 0.0003 0.0972 0.3910
TE 0.0511 0.0539 0.0562 0.0785 0.0783 0.0449 0.0510 0.1513 0.1102 0.1165 0.0002 0.3401
UR 1.0 0.2823 0.5221 0.4771 0.1984 0.4330 0.4014 0.6438 0.3150 0.3276 0.5548 0.0001

Bảng 15. Khoảng cách đa ngôn ngữ giữa các ngôn ngữ sau khi áp dụng mô hình ngôn ngữ cấp ký tự sử dụng điểm dựa trên perplexity
Ngôn ngữ BHO GU HI MAG MAI ML MR NE PA TA TE UR
BHO 0.0 0.0381 0.0198 0.0352 0.0712 0.0860 0.0363 0.1298 0.0526 0.1311 0.0650 0.6567
GU - 0.0 0.0312 0.0748 0.0789 0.0658 0.0291 0.1636 0.0799 0.1278 0.0548 0.2749
HI - - 0.0 0.0501 0.0803 0.0836 0.0252 0.1520 0.0535 0.1388 0.0634 0.4077
MAG - - - 0.0 0.1040 0.1430 0.0713 0.1387 0.0808 0.1815 0.1239 0.4131
MAI - - - - 0.0 0.1092 0.0834 0.1362 0.0916 0.1589 0.1039 0.2995
ML - - - - - 0.0 0.0659 0.1642 0.1372 0.0492 0.0426 0.4057
MR - - - - - - 0.0 0.1473 0.0714 0.1190 0.0478 0.3719
NE - - - - - - - 0.0 0.2446 0.2134 0.1688 0.4894
PA - - - - - - - - 0.0 0.1665 0.1293 0.3198
TA - - - - - - - - - 0.0 0.1068 0.3593
TE - - - - - - - - - - 0.0 0.4474
UR - - - - - - - - - - - 0.0

Bảng 16. Thí nghiệm trên các cặp ngôn ngữ xa.
Mô hình BLEU chrF2 BLEU chrF2 BLEU chrF2
HI→ML HI→TA HI→TE
Guzmán và cộng sự [3] 5.12 30 7.57 41 7.19 26
Đề xuất 3.61 32 7.86 44 4.56 27
ML→HI TA→HI TE→HI
Guzmán và cộng sự [3] 9.08 29 14.55 37 7.97 27
Đề xuất 9.96 33 15.43 40 9.09 30

Translation. Proceedings of the Fourth Conference on Machine Translation (Volume 1: Research Pa-

--- TRANG 14 ---
14 Kumar và cộng sự

Bảng 17. Áp dụng trên các cặp ngôn ngữ zero-shot.
Mô hình HI→BHO BHO →HI HI→MAG MAG →HI
BLEU chrF2 BLEU chrF2 BLEU chrF2 BLEU chrF2
Guzmán và cộng sự [3] 3.34 14 4.58 22 1.67 13 4.86 19
Đề xuất 3.13 17 5.72 27 2.68 18 5.32 25

Bảng 18. Thí nghiệm trên back-translation.
Mô hình GU→HI HI→GU
BLEU chrF2 TER WER BLEU chrF2 TER WER
Guzmán và cộng sự [3] + BT(dữ liệu đơn ngôn ngữ) 34.26 55 0.564 58.24 28.32 54 0.619 62.47
Đề xuất + BT(dữ liệu đơn ngôn ngữ) 35.62 59 0.554 57.39 29.29 58 0.604 61.73

pers). Florence, Italy. ACL. 24–33
[9]Raganato A, Scherrer Y, and Tiedemann J 2020 Fixed Encoder Self-Attention Patterns in Transformer-Based Machine Translation. Findings of the ACL: EMNLP 2020. Online. ACL. 556–568

[10]Lewis M, Liu Y, Goyal N, Ghazvininejad M, Mohamed A, Levy O, Stoyanov V, and Zettlemoyer L 2020 BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension. Proc. ACL 2020. Online. ACL. 7871–7880

[11]Edunov S, Ott M, Auli M, and Grangier D 2018 Understanding Back-Translation at Scale. Proc. EMNLP 2018. Brussels, Belgium. ACL. 489–500

[12]Papineni K, Roukos S, Ward T, Zhu W J 2002 Bleu: a Method for Automatic Evaluation of Machine Translation. Proc. ACL 2002. Philadelphia, Pennsylvania, USA. ACL. 311–318

[13]Hoang V C D, Koehn P, Haffari G, Cohn T 2018 Iterative Back-Translation for Neural Machine Translation. Proceedings of the 2nd Workshop on Neural Machine Translation and Generation. Melbourne, Australia. ACL. 18–24

[14]Philip J, Siripragada S, Namboodiri V P and Jawahar C V 2021 Revisiting Low Resource Status of Indian Languages in Machine Translation. 8th ACM IKDD CODS and 26th COMAD. Bangalore, India. Association for Computing Machinery. 178–187

[15]Haddow B and Kirefu F 2020 PMIndia – A Collection of Parallel Corpora of Languages of India. arXiv e-prints. arXiv:2001.09907

[16]Slocum J 1985 A survey of machine translation: Its history, current status and future prospects. Computational linguistics. 11(1): 1–17

[17]Koehn P 2009 Statistical Machine Translation. Cambridge. Cambridge University Press. doi:10.1017/CBO9780511815829

[18]Ott M, Edunov S, Baevski A, Fan A, Gross S, Ng N, Grangier D, and Auli M 2019 fairseq: A Fast, Extensible Toolkit for Sequence Modeling. Proceedings of NAACL-HLT 2019: Demonstrations. Minneapolis, Minnesota. ACL. 48–53

[19]Dave T N 1931 A study of the Gujarati language in the 16th century (VS), with special reference to the MS Balavabodha to Upadesamala. PhD thesis. SOAS University of London. London

[20]Booth A D 1955 Machine translation of languages, fourteen essays. Technology Press of the Massachusetts Institute of Technology and Wiley, New York

[21]Sutskever I, Vinyals O, and Le Q V 2014 Sequence to Sequence Learning with Neural Networks. Advances in neural information processing systems. 3104–3112

[22]Devlin J, Chang M W, Lee K, and Toutanova K 2019 BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers). Minneapolis, Minnesota. ACL. 4171–4186

[23]Lan Z, Chen M, Goodman S, Gimpel K, Sharma P, and Soricut R 2020 ALBERT: A Lite BERT for Self-supervised Learning of Language Representations. Proc. ICLR 2020.

[24]Barrault L, Bojar O, Costa-jussà M R, Federmann C, Fishel M, Graham Y, Haddow B, Huck M, Koehn P, Malmasi S, Monz C, Müller M, Pal S, Post M, Zampieri M 2019 Findings of the 2019 Conference on Machine Translation (WMT19). Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1). Florence, Italy. ACL. 1–61

--- TRANG 15 ---
MT với BPE Thích ứng với Mã hóa WX 15

[25]Emeneau M B 1956 India as a Lingustic Area. Language. Linguistic Society of America. 32(1): 3-16

[26]Diwakar S, Goyal P, and Gupta R 2010 Transliteration among indian languages using WX notation. Proceedings of the Conference on Natural Language Processing 2010. Saarland University Press. 147-150

[27]Post M 2018 A Call for Clarity in Reporting BLEU Scores. Proceedings of the Third Conference on Machine Translation: Research Papers. Brussels, Belgium. ACL. 186–191

[28]Mundotiya R K, Singh M K, Kapur R, Mishra S, and Singh A K 2020 Basic Linguistic Resources and Baselines for Bhojpuri, Magahi and Maithili for Natural Language Processing. arXiv. 2004.13945

[29]Tiedemann J 2012 Parallel Data, Tools and Interfaces in OPUS. Proc. LREC 2012. Istanbul, Turkey. European Language Resources Association (ELRA). 2214–2218

[30]Popović M 2015 chrF: character n-gram F-score for automatic MT evaluation. Proceedings of the Tenth Workshop on Statistical Machine Translation. Lisbon, Portugal. ACL. 392–395

[31]Snover M, Dorr B, Schwartz R, Micciulla L, and Makhoul J 2006 A study of translation edit rate with targeted human annotation. Proceedings of association for machine translation in the Americas. Cambridge, Massachusetts. 200(6)

[32]Rama T and Singh A K 2009 From Bag of Languages to Family Trees From Noisy Corpus. Proceedings of the International Conference RANLP-2009. Borovets, Bulgaria. ACL. 355–359

[33]Sennrich R, Haddow B, and Birch A 2016 Neural Machine Translation of Rare Words with Subword Units. Proc. ACL 2016. Berlin, Germany. ACL. 1: 1715–1725

[34]Kudo T 2018 Subword Regularization: Improving Neural Network Translation Models with Multiple Subword Candidates. Proc. ACL 2018. Melbourne, Australia. ACL. 1: 66–75

[35]Bentz C and Alikaniotis D 2016 The word entropy of natural languages. arXiv. 1606.06996

[36]Shannon C E and Weaver W 1949 The mathematical theory of communication. The University of Illinois Press, Urbana

[37]Kettunen K 2014 Can type-token ratio be used to show morphological complexity of languages? Journal of Quantitative Linguistics Taylor & Francis, 21(3): 223–245

[38]Singh A K 2010 Modeling and Application of Linguistic Similarity. PhD thesis. IIIT, Hyderabad, India

[39]Singh A K 2007 Using a single framework for computational modeling of linguistic similarity for solving many NLP problems. EUROLAN 2007 Summer School. Alexandru Ioan Cuza University of Iasi

[40]Singh A K 2006 A computational phonetic model for indian language scripts. Constraints on Spelling Changes: Fifth International Workshop on Writing Systems. Nijmegen, The Netherlands. 1–19

[41]Singh A K, Rama T, and Dasigi P 2009 A Computational Model of the Phonetic Space and Its Applications. LTRC, IIIT Hyderabad, India

[42]Trubetzkoy N S 1928 Proposition 16. Acts of the First International Congress of Linguists. 17–18

[43]Haspelmath M 2001 The European linguistic area: standard average European. Halbband Language Typology and Language Universals 2.Teilband, edited by , Berlin, Boston: De Gruyter Mouton. 1492–1510

[44]Denoual E and Lepage Y 2005 BLEU in Characters: Towards Automatic MT Evaluation in Languages without Word Delimiters. Companion Volume to the Proceedings of Conference including Posters/Demos and tutorial abstracts.

[45]Kudo T and Richardson J 2018 SentencePiece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing. Proc. EMNLP 2018: System Demonstrations. Brussels, Belgium. ACL. 66–71

[46]Madaan, L, Sharma, S and Singla, P 2020 Transfer Learning for Related Languages: Submissions to the WMT20 Similar Language Translation Task. Proc. Fifth Conference on Machine Translation. Online. ACL. 402-408

[47]Mujadia, V and Sharma, D 2020 NMT based Similar Language Translation for Hindi - Marathi. Proc. Fifth Conference on Machine Translation. Online. ACL. 414-417

[48]Rathinasamy, K, Singh, A, Sivasambagupta, B, Prasad Neerchal, P and Sivasankaran, V 2020 Infosys Machine Translation System for WMT20 Similar Language Translation Task. Proc. Fifth Conference on Machine Translation. Online. ACL. 437-441

[49]Laskar, S R, Pakray, P and Bandyopadhyay, S 2019 Neural Machine Translation: Hindi-Nepali. Proc. Fourth Conference on Machine Translation. Florence, Italy. ACL. 202-207

--- TRANG 16 ---
16 Kumar và cộng sự

[50]Ojha, A K, Rani, P, Bansal, A, Chakravarthi, B R, Kumar, R and McCrae, J P 2020 NUIG-Panlingua-KMI Hindi-Marathi MT Systems for Similar Language Translation Task @ WMT 2020. Proc. Fifth Conference on Machine Translation. Online. ACL. 418-423

[51]Kumar, A, Baruah, R, Mundotiya, R K and Singh, A K 2020 Transformer-based Neural Machine Translation System for Hindi – Marathi: WMT20 Shared Task. Proc. Fifth Conference on Machine Translation. Online. ACL. 393-395

[52]Pal, S and Zampieri, M 2020 Neural Machine Translation for Similar Languages: The Case of Indo-Aryan Languages. Proc. Fifth Conference on Machine Translation. Online. ACL. 424-429

[53]Przystupa, M and Abdul-Mageed, M 2019 Neural Machine Translation of Low-Resource and Similar Languages with Backtranslation. Proc. Fourth Conference on Machine Translation. Florence, Italy. ACL. 224-235

[54]Koehn, P, Hoang, H, Birch, A, Callison-Burch, C, Federico, M, Bertoldi, N, Cowan, B, Shen, W, Moran, C, Zens, R, Dyer, C, Bojar, O, Constantin, A and Herbst, E 2007 Moses: Open Source Toolkit for Statistical Machine Translation. Proc. 45th Annual Meeting of the Association for Computational Linguistics Companion Volume Proceedings of the Demo and Poster Sessions. Prague, Czech Republic. ACL. 177-180

[55]Och, F J and Ney, H 2003 A Systematic Comparison of Various Statistical Alignment Models. Computational Linguistics, 29(1): 19-51

[56]Heafield, K 2011 KenLM: Faster and Smaller Language Model Queries. Proc. Sixth Workshop on Statistical Machine Translation. Edinburgh, Scotland. ACL. 187-197

[57]Och, F J 2003 Minimum Error Rate Training in Statistical Machine Translation. Proc. 41st Annual Meeting of the Association for Computational Linguistics. Sapporo, Japan. ACL. 160-167

[58]Virpioja, S and Grönroos, S 2015 LeBLEU: N-gram-based Translation Evaluation Score for Morphologically Complex Languages. Proc. Tenth Workshop on Statistical Machine Translation. Lisbon, Portugal. ACL. 411-416

[59]Banik, D, Ekbal, A and Bhattacharyya P 2018 Wuplebleu: The wordnet-based evaluation metric for machine translation. Proc. 15th International Conference on Natural Language Processing. Patiala, India. NLPAI. 104-108

[60]Kim, T K 2015 T test as a parametric statistic. Korean J Anesthesiol. 68(6):540-6.

[61]Balashov, Y 2022 The boundaries of meaning: a case study in neural machine translation. Inquiry, 1-34.

[62]Banik, D, Ekbal, A and Bhattacharyya, P 2020 Statistical machine translation based on weighted syntax-semantics. Sādhanā, 45(1), 1-12.

[63]Bao, W, Zhang, J, Pan, J and Yin, X 2022 A Novel Chinese Dialect TTS Frontend with Non-Autoregressive Neural Machine Translation. arXiv preprint arXiv:2206.04922.

[64]Banik, D, Ekbal, A, Bhattacharyya, P, and Bhattacharyya, S 2019 Assembling translations from multi-engine machine translation outputs. Applied Soft Computing, 78, 230-239.

[65]Kumar, A, Mundotiya, R K, Pratap, A, and Singh, A K 2022 TLSPG: Transfer learning-based semi-supervised pseudo-corpus generation approach for zero-shot translation. Journal of King Saud University - Computer and Information Sciences, 34 (9), 6552-6563.

[66]Banik, D 2021 Phrase table re-adjustment for statistical machine translation. International Journal of Speech Technology, 24(4), 903-911.

[67]Bharathi Raja, C, Rani, P, Arcan, M, and McCrae, J P 2021 A survey of orthographic information in machine translation. SN Computer Science 2, no. 4, 1-19.

[68]Kumar, A, Pratap, A, and Singh, A K 2023 Generative Adversarial Neural Machine Translation for Phonetic Languages via Reinforcement Learning. IEEE Transactions on Emerging Topics in Computational Intelligence, 7(1), 190-199.

[69]Kumar, A, Pratap, A, Singh, A K, and Saha, S 2022 Addressing domain shift in neural machine translation via reinforcement learning. Expert Systems with Applications, 201, 1117039.

[70]Kakwani, D, Kunchukuttan, A, Golla, S, N.C., G, Bhattacharyya, A, Khapra, M M, and Kumar, P 2020 IndicNLPSuite: Monolingual Corpora, Evaluation Benchmarks and Pre-trained Multilingual Language Models for Indian Languages. Findings of the Association for Computational Linguistics: EMNLP 2020. Online. ACL. 4948–4961.

[71]Dabre, R, Shrotriya, H, Kunchukuttan, A, Puduppully, R, Khapra, M, and Kumar, P 2022 IndicBART: A Pre-trained Model for Indic Natural Language Generation. Findings of the Association for Computational Linguistics: ACL 2022. Dublin, Ireland. ACL. 1849–1863.

--- TRANG 17 ---
MT với BPE Thích ứng với Mã hóa WX 17

[72]Cieri, C, Maxwell, M, Strassel, S, and Tracey, J 2016 Selection Criteria for Low Resource Language Programs. Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC'16). Portorož, Slovenia. ELRA. 4543–4549.

[73]Sitaram, S 2015 Pronunciation Modeling for Synthesis of Low Resource Languages. PhD thesis. Carnegie Mellon University, Pittsburgh, USA.

[74]Bharati, A, Rao, K P, Sangal, R, and Bendre, S M 2000 Basic statistical analysis of corpus and cross comparison among corpora. International Institute of Information Technology, Hyderabad.

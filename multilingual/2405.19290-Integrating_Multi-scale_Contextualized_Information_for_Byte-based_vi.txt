# 2405.19290.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/multilingual/2405.19290.pdf
# Kích thước tệp: 379957 byte

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Tích hợp Thông tin Ngữ cảnh Đa tỷ lệ cho Dịch máy Thần kinh dựa trên Byte
Langlin Huang1,3, Yang Feng1,2,3 *
1Phòng thí nghiệm trọng điểm Xử lý Thông tin Thông minh
Viện Công nghệ Tính toán, Viện Hàn lâm Khoa học Trung Quốc
2Phòng thí nghiệm trọng điểm An toàn AI, Viện Hàn lâm Khoa học Trung Quốc
3Đại học Viện Hàn lâm Khoa học Trung Quốc
h.langlin@wustl.edu, fengyang@ict.ac.cn

Tóm tắt
Tokenization dưới từ là phương pháp phổ biến để xây dựng từ vựng trong các mô hình Dịch máy Thần kinh (NMT). Tuy nhiên, các tác vụ ngày càng phức tạp đã lộ ra những nhược điểm của nó. Thứ nhất, từ vựng không thể được chỉnh sửa một khi đã được học, khiến việc thích ứng với các từ mới trở nên khó khăn. Thứ hai, trong dịch đa ngôn ngữ, sự mất cân bằng về khối lượng dữ liệu giữa các ngôn ngữ khác nhau lan tỏa đến từ vựng, làm trầm trọng thêm việc dịch thuật liên quan đến các ngôn ngữ ít tài nguyên. Trong khi tokenization dựa trên byte giải quyết những vấn đề này, các mô hình dựa trên byte gặp khó khăn với mật độ thông tin thấp vốn có trong chuỗi byte UTF-8. Các nghiên cứu trước đây tăng cường ngữ nghĩa token thông qua ngữ cảnh hóa cục bộ nhưng thất bại trong việc chọn phạm vi ngữ cảnh hóa phù hợp dựa trên đầu vào. Do đó, chúng tôi đề xuất phương pháp Ngữ cảnh hóa Đa tỷ lệ (MSC), học thông tin ngữ cảnh hóa ở các tỷ lệ khác nhau trên các chiều trạng thái ẩn khác nhau. Sau đó tận dụng mô-đun attention để tích hợp động thông tin ngữ cảnh hóa đa tỷ lệ. Các thí nghiệm cho thấy MSC vượt trội đáng kể so với các phương pháp dựa trên dưới từ và dựa trên byte khác trong cả kịch bản đa ngôn ngữ và ngoài miền. Chúng tôi đã tải mã nguồn lên github1.

1 Giới thiệu
Trong các hệ thống dịch máy thần kinh (NMT), tokenization dưới từ đã là phương pháp phổ biến và hiệu quả nhất để giảm thiểu vấn đề từ ngoài từ vựng (OOV). Tuy nhiên, cả BPE (Sennrich et al., 2016) và SentencePiece (Kudo và Richardson, 2018) đều cố định quy tắc phân đoạn từ hoặc từ vựng một khi chúng đã học trên corpus ban đầu, khiến việc đảm bảo thích ứng với corpus mới trở nên khó khăn. Điều này trở nên tệ hơn trong các kịch bản ngoài miền. Ngoài ra, trong các kịch bản đa ngôn ngữ với sự mất cân bằng dữ liệu, từ vựng dưới từ có xu hướng tập trung vào các ngôn ngữ có nhiều tài nguyên, bỏ qua những ngôn ngữ ít tài nguyên. Sự mất cân bằng này có thể gây ra sự gia tăng các trường hợp OOV hoặc phân đoạn quá mức văn bản, có hại cho hiệu suất mô hình dịch thuật.

Phương pháp dựa trên byte có thể giải quyết những vấn đề này với ít tham số embedding và đã thu hút nhiều nghiên cứu rộng rãi (Wang et al., 2020; Shaham và Levy, 2021; Xue et al., 2022; Yu et al., 2023; Edman et al., 2023; Sreedhar et al., 2023). Trong các mô hình dựa trên byte, văn bản được chuyển đổi thành chuỗi byte theo mã hóa UTF-8, với mỗi byte như một token trong từ vựng. Chúng thường sử dụng từ vựng với kích thước tối đa 256 nhưng có thể thích ứng với các kịch bản mất cân bằng như dịch đa ngôn ngữ và thích ứng ngoài miền.

Tuy nhiên, một đặc điểm của mã hóa UTF-8 cản trở mô hình Transformer thông thường (Vaswani et al., 2017) thích ứng tốt với từ vựng dựa trên byte: một ký tự đơn có thể tương ứng với 1 đến 4 byte UTF-8. Con số này là 1 đối với các ký tự tiếng Anh, nhưng tiếng Ả Rập và nhiều ngôn ngữ châu Á yêu cầu nhiều byte để biểu diễn một ký tự đơn. Do đó, đôi khi một byte đơn không có nghĩa xác định; nó yêu cầu tích hợp thông tin cục bộ để mã hóa ngữ nghĩa của nó. Để giải quyết điều đó, nhiều phương pháp khác nhau đã được đề xuất để tích hợp thông tin ngữ cảnh cục bộ. SU4MT (Huang et al., 2023) học thông tin ngữ cảnh với lớp Attentive Semantic Fusion, nhưng yêu cầu phân đoạn chính xác. MEGABYTE (Yu et al., 2023) phân đoạn một câu thành các khối 4 và đơn giản nối các token. Charformer (Tay et al., 2022) phân đoạn một câu 4 lần với kích thước khối từ 1 đến 4 mỗi lần, và sử dụng mean-pooling để thực hiện tích hợp cục bộ. Tổng có trọng số của 4 kết quả cho ra đầu ra cuối cùng. LOBEF (Sreedhar et al., 2023) đề xuất Byte-nCF, thay thế mean-pooling trong Charformer bằng Mạng Nơ-ron Tích chập (CNN) để có hiệu suất tốt hơn.

Mặc dù các phương pháp này học và tận dụng thông tin ngữ cảnh ở quy mô lớn hơn, chúng bị hạn chế bởi kích thước khối cố định và không thể điều chỉnh trọng số fusion theo script của các ngôn ngữ khác nhau. Để khắc phục điều này, chúng tôi đề xuất phương pháp Ngữ cảnh hóa Đa tỷ lệ (MSC), trước tiên học thông tin ngữ cảnh của nhiều tỷ lệ trong các chiều trạng thái ẩn khác nhau, và thứ hai tận dụng cơ chế attention để fusion thông tin đa tỷ lệ với trọng số động. Phương pháp của chúng tôi thích ứng tốt hơn với các script đầu vào phức tạp bằng cách cho phép mô hình fusion thích ứng thông tin của các mức độ chi tiết khác nhau dựa trên nội dung đầu vào thay đổi. Kết quả thí nghiệm chứng minh rằng phương pháp MSC của chúng tôi thể hiện khả năng thích ứng vượt trội trên nhiều ngôn ngữ và tập dữ liệu khác nhau.

2 Phương pháp
Trong phần này, chúng tôi giới thiệu phương pháp Ngữ cảnh hóa Đa tỷ lệ (MSC) được đề xuất. Các mô hình dựa trên byte thường học thông tin ngữ cảnh hóa một cách ngầm định. Điều MSC làm là mô hình hóa rõ ràng thông tin ngữ cảnh của nhiều tỷ lệ bằng cách nhóm các chiều trạng thái ẩn và để các phần khác nhau của các chiều học thông tin ở các tỷ lệ khác nhau.

Cụ thể, chúng tôi chèn một mô-đun ngữ cảnh hóa đa tỷ lệ ngay trước mô-đun Multi-Head Attention (MHA), như được mô tả trong Hình 1. Vector đầu vào x được chia theo chiều trạng thái ẩn thành n phần [x1, x2, ..., xn]. Sau đó, n hàm ngữ cảnh hóa g(·) được áp dụng cho các phần này tương ứng. Một cấu trúc đơn giản và hiệu quả cho ngữ cảnh hóa cục bộ là mạng nơ-ron tích chập 1-D (CNN). Do đó, chúng tôi tận dụng CNN với kích thước kernel k khác nhau để kiểm soát phạm vi ngữ cảnh hóa. Vì các chiều khác nhau được ngữ cảnh hóa với các mức độ chi tiết khác nhau, mô hình của chúng tôi có thể thực hiện ngữ cảnh hóa đa tỷ lệ. Để bảo toàn thông tin gốc, g(·) cũng được phép là hàm "Identity", trả về trực tiếp đầu vào mà không có bất kỳ thao tác nào.

gi(·, k) = {
Identity(·), k = 0
CNN(·, k), k > 0
(1)

Trong phương trình (1), gi(·, k) có nghĩa là hàm ngữ cảnh hóa cho nhóm i, và k là kích thước kernel. Ở đây, k = 0 biểu thị hàm "Identity" để đơn giản hóa.

Tiếp theo, các phần vector ngữ cảnh hóa x̂i được tính toán bởi gi(xi, k). Cuối cùng, chúng được nối để tạo thành x̂, hoạt động như đầu vào của mô-đun MHA.

Các thí nghiệm sơ bộ về cấu hình CNN đã hướng dẫn cấu trúc tốt nhất cho toàn bộ mô hình. Thứ nhất, padding ở phía bên trái làm giảm hiệu suất mô hình, vì vậy các CNN được đặt để pad ở cả hai phía, như được hiển thị trong Hình 1. Thứ hai, áp dụng MSC cho các lớp decoder Transformer gây ra sự không nhất quán giữa huấn luyện và kiểm tra, khi các token bên phải của một token chưa được tạo ra. Kết quả là, MSC chỉ được áp dụng cho các lớp encoder.

Đáng chú ý rằng kích thước kernel k được khuyến nghị là số lẻ hoặc bằng không, nếu không thì cần padding thủ công bằng không để giữ độ dài đầu ra giống như đầu vào. Theo kinh nghiệm, tốt hơn là chọn k từ {0, 1, 3, 5, 7}.

--- TRANG 3 ---
[Bảng kết quả thí nghiệm với các ngôn ngữ khác nhau và các phương pháp tokenization]

--- TRANG 4 ---
[Bảng kết quả thí nghiệm trên tập dữ liệu OPUS-7]

--- TRANG 5 ---
[Bảng kết quả thích ứng miền và phân tích quy mô ngữ cảnh hóa]

--- TRANG 6 ---
[Danh sách tài liệu tham khảo]

--- TRANG 7 ---
[Tiếp tục danh sách tài liệu tham khảo]

--- TRANG 8 ---
[Phụ lục với cài đặt chi tiết và kết quả bổ sung]

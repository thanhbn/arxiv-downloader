<<<<<<< Updated upstream
# 2405.19290.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/multilingual/2405.19290.pdf
# Kích thước tệp: 379957 byte

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Tích hợp Thông tin Ngữ cảnh Đa tỷ lệ cho Dịch máy Thần kinh dựa trên Byte
Langlin Huang1,3, Yang Feng1,2,3 *
1Phòng thí nghiệm trọng điểm Xử lý Thông tin Thông minh
Viện Công nghệ Tính toán, Viện Hàn lâm Khoa học Trung Quốc
2Phòng thí nghiệm trọng điểm An toàn AI, Viện Hàn lâm Khoa học Trung Quốc
3Đại học Viện Hàn lâm Khoa học Trung Quốc
h.langlin@wustl.edu, fengyang@ict.ac.cn

Tóm tắt
Tokenization dưới từ là phương pháp phổ biến để xây dựng từ vựng trong các mô hình Dịch máy Thần kinh (NMT). Tuy nhiên, các tác vụ ngày càng phức tạp đã lộ ra những nhược điểm của nó. Thứ nhất, từ vựng không thể được chỉnh sửa một khi đã được học, khiến việc thích ứng với các từ mới trở nên khó khăn. Thứ hai, trong dịch đa ngôn ngữ, sự mất cân bằng về khối lượng dữ liệu giữa các ngôn ngữ khác nhau lan tỏa đến từ vựng, làm trầm trọng thêm việc dịch thuật liên quan đến các ngôn ngữ ít tài nguyên. Trong khi tokenization dựa trên byte giải quyết những vấn đề này, các mô hình dựa trên byte gặp khó khăn với mật độ thông tin thấp vốn có trong chuỗi byte UTF-8. Các nghiên cứu trước đây tăng cường ngữ nghĩa token thông qua ngữ cảnh hóa cục bộ nhưng thất bại trong việc chọn phạm vi ngữ cảnh hóa phù hợp dựa trên đầu vào. Do đó, chúng tôi đề xuất phương pháp Ngữ cảnh hóa Đa tỷ lệ (MSC), học thông tin ngữ cảnh hóa ở các tỷ lệ khác nhau trên các chiều trạng thái ẩn khác nhau. Sau đó tận dụng mô-đun attention để tích hợp động thông tin ngữ cảnh hóa đa tỷ lệ. Các thí nghiệm cho thấy MSC vượt trội đáng kể so với các phương pháp dựa trên dưới từ và dựa trên byte khác trong cả kịch bản đa ngôn ngữ và ngoài miền. Chúng tôi đã tải mã nguồn lên github1.

1 Giới thiệu
Trong các hệ thống dịch máy thần kinh (NMT), tokenization dưới từ đã là phương pháp phổ biến và hiệu quả nhất để giảm thiểu vấn đề từ ngoài từ vựng (OOV). Tuy nhiên, cả BPE (Sennrich et al., 2016) và SentencePiece (Kudo và Richardson, 2018) đều cố định quy tắc phân đoạn từ hoặc từ vựng một khi chúng đã học trên corpus ban đầu, khiến việc đảm bảo thích ứng với corpus mới trở nên khó khăn. Điều này trở nên tệ hơn trong các kịch bản ngoài miền. Ngoài ra, trong các kịch bản đa ngôn ngữ với sự mất cân bằng dữ liệu, từ vựng dưới từ có xu hướng tập trung vào các ngôn ngữ có nhiều tài nguyên, bỏ qua những ngôn ngữ ít tài nguyên. Sự mất cân bằng này có thể gây ra sự gia tăng các trường hợp OOV hoặc phân đoạn quá mức văn bản, có hại cho hiệu suất mô hình dịch thuật.

Phương pháp dựa trên byte có thể giải quyết những vấn đề này với ít tham số embedding và đã thu hút nhiều nghiên cứu rộng rãi (Wang et al., 2020; Shaham và Levy, 2021; Xue et al., 2022; Yu et al., 2023; Edman et al., 2023; Sreedhar et al., 2023). Trong các mô hình dựa trên byte, văn bản được chuyển đổi thành chuỗi byte theo mã hóa UTF-8, với mỗi byte như một token trong từ vựng. Chúng thường sử dụng từ vựng với kích thước tối đa 256 nhưng có thể thích ứng với các kịch bản mất cân bằng như dịch đa ngôn ngữ và thích ứng ngoài miền.

Tuy nhiên, một đặc điểm của mã hóa UTF-8 cản trở mô hình Transformer thông thường (Vaswani et al., 2017) thích ứng tốt với từ vựng dựa trên byte: một ký tự đơn có thể tương ứng với 1 đến 4 byte UTF-8. Con số này là 1 đối với các ký tự tiếng Anh, nhưng tiếng Ả Rập và nhiều ngôn ngữ châu Á yêu cầu nhiều byte để biểu diễn một ký tự đơn. Do đó, đôi khi một byte đơn không có nghĩa xác định; nó yêu cầu tích hợp thông tin cục bộ để mã hóa ngữ nghĩa của nó. Để giải quyết điều đó, nhiều phương pháp khác nhau đã được đề xuất để tích hợp thông tin ngữ cảnh cục bộ. SU4MT (Huang et al., 2023) học thông tin ngữ cảnh với lớp Attentive Semantic Fusion, nhưng yêu cầu phân đoạn chính xác. MEGABYTE (Yu et al., 2023) phân đoạn một câu thành các khối 4 và đơn giản nối các token. Charformer (Tay et al., 2022) phân đoạn một câu 4 lần với kích thước khối từ 1 đến 4 mỗi lần, và sử dụng mean-pooling để thực hiện tích hợp cục bộ. Tổng có trọng số của 4 kết quả cho ra đầu ra cuối cùng. LOBEF (Sreedhar et al., 2023) đề xuất Byte-nCF, thay thế mean-pooling trong Charformer bằng Mạng Nơ-ron Tích chập (CNN) để có hiệu suất tốt hơn.

Mặc dù các phương pháp này học và tận dụng thông tin ngữ cảnh ở quy mô lớn hơn, chúng bị hạn chế bởi kích thước khối cố định và không thể điều chỉnh trọng số fusion theo script của các ngôn ngữ khác nhau. Để khắc phục điều này, chúng tôi đề xuất phương pháp Ngữ cảnh hóa Đa tỷ lệ (MSC), trước tiên học thông tin ngữ cảnh của nhiều tỷ lệ trong các chiều trạng thái ẩn khác nhau, và thứ hai tận dụng cơ chế attention để fusion thông tin đa tỷ lệ với trọng số động. Phương pháp của chúng tôi thích ứng tốt hơn với các script đầu vào phức tạp bằng cách cho phép mô hình fusion thích ứng thông tin của các mức độ chi tiết khác nhau dựa trên nội dung đầu vào thay đổi. Kết quả thí nghiệm chứng minh rằng phương pháp MSC của chúng tôi thể hiện khả năng thích ứng vượt trội trên nhiều ngôn ngữ và tập dữ liệu khác nhau.

2 Phương pháp
Trong phần này, chúng tôi giới thiệu phương pháp Ngữ cảnh hóa Đa tỷ lệ (MSC) được đề xuất. Các mô hình dựa trên byte thường học thông tin ngữ cảnh hóa một cách ngầm định. Điều MSC làm là mô hình hóa rõ ràng thông tin ngữ cảnh của nhiều tỷ lệ bằng cách nhóm các chiều trạng thái ẩn và để các phần khác nhau của các chiều học thông tin ở các tỷ lệ khác nhau.

Cụ thể, chúng tôi chèn một mô-đun ngữ cảnh hóa đa tỷ lệ ngay trước mô-đun Multi-Head Attention (MHA), như được mô tả trong Hình 1. Vector đầu vào x được chia theo chiều trạng thái ẩn thành n phần [x1, x2, ..., xn]. Sau đó, n hàm ngữ cảnh hóa g(·) được áp dụng cho các phần này tương ứng. Một cấu trúc đơn giản và hiệu quả cho ngữ cảnh hóa cục bộ là mạng nơ-ron tích chập 1-D (CNN). Do đó, chúng tôi tận dụng CNN với kích thước kernel k khác nhau để kiểm soát phạm vi ngữ cảnh hóa. Vì các chiều khác nhau được ngữ cảnh hóa với các mức độ chi tiết khác nhau, mô hình của chúng tôi có thể thực hiện ngữ cảnh hóa đa tỷ lệ. Để bảo toàn thông tin gốc, g(·) cũng được phép là hàm "Identity", trả về trực tiếp đầu vào mà không có bất kỳ thao tác nào.
=======
# Tích hợp Thông tin Ngữ cảnh Đa quy mô cho Dịch máy Neural dựa trên Byte

Langlin Huang1,3, Yang Feng1,2,3 *
1Phòng thí nghiệm Trọng điểm Xử lý Thông tin Thông minh
Viện Công nghệ Tính toán, Viện Hàn lâm Khoa học Trung Quốc
2Phòng thí nghiệm Trọng điểm An toàn AI, Viện Hàn lâm Khoa học Trung Quốc
3Đại học Viện Hàn lâm Khoa học Trung Quốc

## Tóm tắt

Tokenization từ phụ là phương pháp phổ biến để xây dựng từ vựng trong các mô hình Dịch máy Neural (NMT). Tuy nhiên, các tác vụ ngày càng phức tạp đã bộc lộ những nhược điểm của nó. Thứ nhất, từ vựng không thể được sửa đổi sau khi đã học, khiến khó thích nghi với các từ mới. Thứ hai, trong dịch đa ngôn ngữ, sự mất cân bằng về khối lượng dữ liệu giữa các ngôn ngữ khác nhau lan sang từ vựng, làm trầm trọng thêm việc dịch các ngôn ngữ ít tài nguyên. Trong khi tokenization dựa trên byte giải quyết được những vấn đề này, các mô hình dựa trên byte gặp khó khăn với mật độ thông tin thấp vốn có trong các chuỗi byte UTF-8. Các nghiên cứu trước đây tăng cường ngữ nghĩa token thông qua ngữ cảnh hóa cục bộ nhưng không thể chọn phạm vi ngữ cảnh hóa thích hợp dựa trên đầu vào. Do đó, chúng tôi đề xuất phương pháp Ngữ cảnh hóa Đa quy mô (MSC), học thông tin ngữ cảnh hóa ở các quy mô khác nhau qua các chiều trạng thái ẩn khác nhau. Sau đó nó tận dụng mô-đun attention để tích hợp động thông tin ngữ cảnh hóa đa quy mô. Thí nghiệm cho thấy MSC vượt trội đáng kể so với các phương pháp dựa trên từ phụ và các phương pháp dựa trên byte khác trong cả hai tình huống đa ngôn ngữ và ngoài miền. Chúng tôi đã tải mã nguồn lên github.

## 1 Giới thiệu

Trong các hệ thống dịch máy neural (NMT), tokenization từ phụ là phương pháp phổ biến và hiệu quả nhất để giảm thiểu vấn đề từ ngoài từ vựng (OOV). Tuy nhiên, cả BPE (Sennrich et al., 2016) và SentencePiece (Kudo và Richardson, 2018) đều cố định quy tắc phân đoạn từ hoặc từ vựng sau khi đã học chúng trên corpus ban đầu, khiến khó đảm bảo thích nghi với các corpus mới. Điều này trở nên tồi tệ hơn trong các tình huống ngoài miền. Thêm vào đó, trong các tình huống đa ngôn ngữ với mất cân bằng dữ liệu, từ vựng từ phụ có xu hướng tập trung vào các ngôn ngữ giàu tài nguyên, bỏ qua những ngôn ngữ ít tài nguyên. Sự mất cân bằng này có thể gây ra sự gia tăng các trường hợp OOV hoặc phân đoạn quá mức văn bản, có hại cho hiệu suất mô hình dịch.

Phương pháp dựa trên byte có thể giải quyết những vấn đề này với ít tham số embedding và đã thúc đẩy nhiều nghiên cứu sâu rộng (Wang et al., 2020; Shaham và Levy, 2021; Xue et al., 2022; Yu et al., 2023; Edman et al., 2023; Sreedhar et al., 2023). Trong các mô hình dựa trên byte, văn bản được chuyển đổi thành chuỗi byte theo mã hóa UTF-8, với mỗi byte như một token trong từ vựng. Chúng thường sử dụng từ vựng với kích thước tối đa 256 nhưng có thể thích nghi với các tình huống mất cân bằng như dịch đa ngôn ngữ và thích nghi ngoài miền.

Tuy nhiên, một đặc điểm của mã hóa UTF-8 cản trở mô hình Transformer thông thường (Vaswani et al., 2017) thích nghi tốt với từ vựng dựa trên byte: một ký tự đơn có thể tương ứng với 1 đến 4 byte UTF-8. Con số này là 1 đối với các ký tự tiếng Anh, nhưng tiếng Ả Rập và nhiều ngôn ngữ châu Á cần nhiều byte để biểu diễn một ký tự đơn. Do đó, đôi khi một byte đơn không có nghĩa xác định; nó cần tích hợp thông tin cục bộ để mã hóa ngữ nghĩa của nó. Để giải quyết vấn đề đó, nhiều phương pháp đã được đề xuất để tích hợp thông tin ngữ cảnh cục bộ. SU4MT (Huang et al., 2023) học thông tin ngữ cảnh với lớp Attentive Semantic Fusion, nhưng yêu cầu phân đoạn chính xác. MEGABYTE (Yu et al., 2023) phân đoạn câu thành các khối 4 và đơn giản nối các token. Charformer (Tay et al., 2022) phân đoạn câu 4 lần với kích thước khối từ 1 đến 4 mỗi lần, và sử dụng mean-pooling để thực hiện tích hợp cục bộ. Tổng trọng số của 4 kết quả cho ra đầu ra cuối cùng. LOBEF (Sreedhar et al., 2023) đề xuất Byte-nCF, thay thế mean-pooling trong Charformer bằng Mạng Neural Tích chập (CNN) để có hiệu suất tốt hơn.

Mặc dù những phương pháp này học và tận dụng thông tin ngữ cảnh ở quy mô lớn hơn, chúng bị hạn chế bởi kích thước khối cố định và không thể điều chỉnh trọng số fusion theo chữ viết của các ngôn ngữ khác nhau. Để khắc phục điều này, chúng tôi đề xuất phương pháp Ngữ cảnh hóa Đa quy mô (MSC), trước tiên học thông tin ngữ cảnh của nhiều quy mô trong các chiều trạng thái ẩn khác nhau, và thứ hai tận dụng cơ chế attention để fusion thông tin đa quy mô với trọng số động. Phương pháp của chúng tôi thích nghi tốt hơn với các chữ viết đầu vào phức tạp bằng cách cho phép mô hình fusion thông tin các độ chi tiết khác nhau một cách thích nghi dựa trên nội dung đầu vào thay đổi. Kết quả thí nghiệm chứng minh rằng phương pháp MSC của chúng tôi thể hiện khả năng thích nghi vượt trội qua nhiều ngôn ngữ và tập dữ liệu khác nhau.

## 2 Phương pháp

Trong phần này, chúng tôi giới thiệu phương pháp Ngữ cảnh hóa Đa quy mô (MSC) được đề xuất. Các mô hình dựa trên byte thường học thông tin ngữ cảnh hóa một cách ngầm định. Điều MSC làm là mô hình hóa rõ ràng thông tin ngữ cảnh của nhiều quy mô bằng cách nhóm các chiều trạng thái ẩn và để các phần khác nhau của các chiều học thông tin ở các quy mô khác nhau.

Cụ thể, chúng tôi chèn một mô-đun ngữ cảnh hóa đa quy mô ngay trước mô-đun Multi-Head Attention (MHA), như được miêu tả trong Hình 1. Vector đầu vào x được chia theo chiều trạng thái ẩn thành n phần [x1, x2, ..., xn]. Sau đó, n hàm ngữ cảnh hóa g(·) được áp dụng cho các phần này tương ứng. Một cấu trúc đơn giản và hiệu quả cho ngữ cảnh hóa cục bộ là mạng neural tích chập 1-D (CNN). Do đó, chúng tôi tận dụng CNN với kích thước kernel k khác nhau để kiểm soát phạm vi ngữ cảnh hóa. Vì các chiều khác nhau được ngữ cảnh hóa với các độ chi tiết khác nhau, mô hình của chúng tôi có thể thực hiện ngữ cảnh hóa đa quy mô. Để bảo toàn thông tin gốc, g(·) cũng được phép là hàm "Identity", trả về trực tiếp đầu vào mà không có thao tác nào.
>>>>>>> Stashed changes

gi(·, k) = {
Identity(·), k = 0
CNN(·, k), k > 0
<<<<<<< Updated upstream
(1)

Trong phương trình (1), gi(·, k) có nghĩa là hàm ngữ cảnh hóa cho nhóm i, và k là kích thước kernel. Ở đây, k = 0 biểu thị hàm "Identity" để đơn giản hóa.

Tiếp theo, các phần vector ngữ cảnh hóa x̂i được tính toán bởi gi(xi, k). Cuối cùng, chúng được nối để tạo thành x̂, hoạt động như đầu vào của mô-đun MHA.

Các thí nghiệm sơ bộ về cấu hình CNN đã hướng dẫn cấu trúc tốt nhất cho toàn bộ mô hình. Thứ nhất, padding ở phía bên trái làm giảm hiệu suất mô hình, vì vậy các CNN được đặt để pad ở cả hai phía, như được hiển thị trong Hình 1. Thứ hai, áp dụng MSC cho các lớp decoder Transformer gây ra sự không nhất quán giữa huấn luyện và kiểm tra, khi các token bên phải của một token chưa được tạo ra. Kết quả là, MSC chỉ được áp dụng cho các lớp encoder.

Đáng chú ý rằng kích thước kernel k được khuyến nghị là số lẻ hoặc bằng không, nếu không thì cần padding thủ công bằng không để giữ độ dài đầu ra giống như đầu vào. Theo kinh nghiệm, tốt hơn là chọn k từ {0, 1, 3, 5, 7}.

--- TRANG 3 ---
[Bảng kết quả thí nghiệm với các ngôn ngữ khác nhau và các phương pháp tokenization]

--- TRANG 4 ---
[Bảng kết quả thí nghiệm trên tập dữ liệu OPUS-7]

--- TRANG 5 ---
[Bảng kết quả thích ứng miền và phân tích quy mô ngữ cảnh hóa]

--- TRANG 6 ---
[Danh sách tài liệu tham khảo]

--- TRANG 7 ---
[Tiếp tục danh sách tài liệu tham khảo]

--- TRANG 8 ---
[Phụ lục với cài đặt chi tiết và kết quả bổ sung]
=======
}

Trong phương trình (1), gi(·, k) có nghĩa là hàm ngữ cảnh hóa cho nhóm i, và k là kích thước kernel. Ở đây, k=0 biểu thị hàm "Identity" để đơn giản hóa.

Tiếp theo, các phần vector ngữ cảnh hóa x̂i được tính bằng gi(xi, k). Cuối cùng, chúng được nối để tạo thành x̂, hoạt động như đầu vào của mô-đun MHA.

Các thí nghiệm sơ bộ về cấu hình CNN hướng dẫn cấu trúc tốt nhất cho toàn bộ mô hình. Thứ nhất, padding ở phía bên trái làm xấu đi hiệu suất mô hình, vì vậy các CNN được thiết lập để pad ở cả hai bên, như được thể hiện trong Hình 1. Thứ hai, áp dụng MSC cho các lớp decoder của Transformer gây ra sự không nhất quán giữa huấn luyện và kiểm tra, khi các token phía bên phải của một token chưa được sinh ra. Kết quả là, MSC chỉ được áp dụng cho các lớp encoder.

Đáng chú ý rằng kích thước kernel k được khuyến nghị là số lẻ hoặc zero, nếu không, cần padding zero thủ công để giữ độ dài đầu ra giống như đầu vào. Theo kinh nghiệm, tốt hơn là chọn k từ {0, 1, 3, 5, 7}.

## 3 Thí nghiệm

Chúng tôi thí nghiệm với hai tập dữ liệu đa ngôn ngữ và một tập dữ liệu thích nghi miền để khảo sát hiệu suất và tính chất của phương pháp MSC và các mô hình ngôn ngữ dựa trên byte khác.

### 3.1 Tập dữ liệu

**Dịch Đa ngôn ngữ Many-to-One**
Chúng tôi sử dụng corpus TED đa ngôn ngữ gồm 59 ngôn ngữ (Qi et al., 2018), TED-59, bao gồm cả ngôn ngữ giàu và ít tài nguyên. Tất cả trường hợp đều lấy tiếng Anh làm trung tâm. Chúng tôi thu thập dữ liệu thô từ Salesky et al. (2023) và tiền xử lý với hai từ vựng cấp từ phụ và một từ vựng cấp byte. Đối với hệ thống baseline dựa trên từ phụ, chúng tôi tận dụng SentencePiece (Kudo và Richardson, 2018) và huấn luyện từ vựng 32k trên tập huấn luyện. Chúng tôi cũng kết hợp từ vựng mBART-50 250k (Liu et al., 2020; Tang et al., 2020) để có phạm vi từ vựng đầy đủ. Đối với hệ thống cấp Byte, chúng tôi tiền xử lý dữ liệu với từ vựng 256 sử dụng script từ Shaham và Levy (2021).

**Dịch Đa ngôn ngữ English-Centric**
Chúng tôi sử dụng corpus OPUS-7 được xử lý bởi Gu và Feng (2022), được trích xuất từ corpus OPUS-100 (Zhang et al., 2020). Tập dữ liệu OPUS-7 chứa corpus huấn luyện 6 ngôn ngữ (Ar, De, Fr, Nl, Ru, Zh) và bản dịch tiếng Anh của chúng, với 1M câu mỗi ngôn ngữ.

**Thích nghi Cross-domain Zero-shot**
Ngoài các tình huống đa ngôn ngữ, chúng tôi cũng thí nghiệm khả năng thích nghi cross-domain zero-shot của các mô hình dịch dựa trên byte với tập dữ liệu WMT19 German→English (De→En). Chúng tôi huấn luyện tất cả mô hình trên miền News và đánh giá trên dữ liệu kiểm tra từ ba miền được sử dụng trong Sreedhar et al. (2023) và Aharoni và Goldberg (2020), đó là Koran, IT, và Medical. Chúng tôi sử dụng dữ liệu được tiền xử lý và cung cấp bởi Sreedhar et al. (2023).

### 3.2 Mô hình

Chúng tôi so sánh phương pháp MSC được đề xuất chủ yếu với các mô hình dịch máy dựa trên byte khác.

• **Transformer** (Vaswani et al., 2017): Mô hình Transformer chuẩn không có sự thích nghi với chuỗi byte.

• **Byte-nCF** (Sreedhar et al., 2023): Mô hình dựa trên byte mạnh hoạt động tốt trong điều kiện ít tài nguyên. Các siêu tham số cấu trúc sử dụng thiết lập mặc định.

• **MSC**: Chúng tôi thiết lập n=8 trong thí nghiệm của chúng tôi. Việc chọn k được thảo luận trong Phụ lục A.

Chúng tôi cũng so sánh với các phương pháp dựa trên từ phụ.

• **Learned**: Mô hình Transformer chuẩn với từ vựng học được.

• **mBART**: Mô hình Transformer chuẩn sử dụng từ vựng của mBART (Liu et al., 2020). Chúng tôi không sử dụng checkpoint được huấn luyện trước của mBART để đảm bảo công bằng.

• **Aharoni**: Baseline mạnh nhất của các mô hình dựa trên từ phụ ở quy mô tham số này.

Các thiết lập khác được thảo luận trong Phụ lục B.

## 4 Kết quả và Phân tích

### 4.1 Dịch Đa ngôn ngữ Many-to-One

Bảng 1 cho thấy kết quả trên tập dữ liệu TED-59. Tất cả các phương pháp dựa trên byte được thí nghiệm ba lần để tăng cường độ tin cậy của kết quả. Chúng tôi báo cáo điểm trung bình và độ lệch chuẩn của kết quả. Aharoni et al. (2019) đã chọn bốn ngôn ngữ ít tài nguyên (LR) và bốn ngôn ngữ giàu tài nguyên (HR) để thể hiện hiệu suất mô hình trên các quy mô dữ liệu huấn luyện khác nhau, và chúng tôi báo cáo kết quả theo cùng cách. Điểm SacreBLEU trung bình của 58 hướng dịch (AVG-58) chứng minh rằng các mô hình dựa trên byte vượt trội hơn các mô hình dựa trên từ phụ trong tình huống đa ngôn ngữ quy mô lớn, bất chấp việc sử dụng ít tham số hơn.

So với các phương pháp dựa trên byte khác, MSC hoạt động tốt hơn ở hầu hết các ngôn ngữ. Trong khi Byte-nCF học một tập trọng số kết hợp cố định của thông tin ngữ cảnh đa quy mô cho tất cả ngôn ngữ, MSC tận dụng thông tin ngữ cảnh của các độ chi tiết khác nhau một cách thích nghi tại giai đoạn suy luận. Ví dụ, một byte đơn có thể biểu diễn một ký tự hoặc thậm chí một từ trong tiếng Đức, tiếng Ý, v.v., vì vậy MSC tận dụng thông tin ngữ cảnh từ lân cận gần hơn; một byte đơn có thể không đủ để tạo thành thậm chí một ký tự, vì vậy MSC có xu hướng tập trung vào thông tin ngữ cảnh của các quy mô lớn hơn. Chúng tôi chứng minh lời giải thích này sau với một thí nghiệm trong 4.4.

### 4.2 Dịch Đa ngôn ngữ English-Centric

Bảng 2 cho thấy kết quả trên tập dữ liệu OPUS-7, chỉ chứa bảy ngôn ngữ giàu tài nguyên. Trong tình huống này, mô hình dựa trên từ phụ vượt trội hơn nhiều so với các mô hình dựa trên byte. Tuy nhiên, khoảng cách hiệu suất nhỏ hơn khi đo bằng COMET (Rei et al., 2022), một metric đáng tin cậy dựa trên mô hình, như được báo cáo trong Phụ lục C.

Trong số các mô hình dựa trên byte này, MSC thường hoạt động tốt hơn các mô hình khác. Để xác minh những cải thiện như vậy không đến từ sự ngẫu nhiên, chúng tôi lặp lại chúng ba lần và báo cáo trung bình và độ lệch chuẩn của kết quả.

### 4.3 Thích nghi Cross-Domain Zero-shot

Bảng 3 cho thấy kết quả trên tập dữ liệu kiểm tra trong miền và ngoài miền zero-shot. Đối với các mô hình dựa trên từ phụ, việc sử dụng từ điển được huấn luyện trên tập dữ liệu miền News để tiền xử lý tập kiểm tra từ các miền khác dẫn đến số lượng đáng kể các từ <unk>. Điều này khiến mô hình khó hiểu các câu đầu vào và thực hiện dịch. Tuy nhiên, các mô hình dựa trên byte có thể loại bỏ vấn đề Out-Of-Vocabulary (OOV), từ đó đạt được hiệu suất tốt hơn trong các tình huống dịch zero-shot. Kết quả cũng chứng minh rằng phương pháp MSC được đề xuất của chúng tôi có lợi thế đáng kể trong thích nghi cross-domain zero-shot.

### 4.4 Quy mô Ngữ cảnh hóa

Trong mục 2, chúng tôi đã giới thiệu siêu tham số k kiểm soát quy mô ngữ cảnh hóa của phương pháp chúng tôi. Ở đây, chúng tôi thí nghiệm trên tập dữ liệu TED-59 để cho thấy quy mô mô hình hóa này ảnh hưởng đến dịch như thế nào.

Theo quy tắc Unicode, chúng tôi nhóm các ngôn ngữ theo số byte cần thiết để tạo thành một ký tự, được gọi là "Byte-1", "Byte-2", và "Byte-3". Sau đó, chúng tôi chọn ba ngôn ngữ cho mỗi nhóm để đại diện cho nhóm đó, như được liệt kê dưới đây.

• **Byte-1**: Tiếng Pháp (Fr), Tiếng Đức (De), Tiếng Hà Lan (Nl)
• **Byte-2**: Tiếng Nga (Ru), Tiếng Thái (Th), Tiếng Ả Rập (Ar)
• **Byte-3**: Tiếng Trung (Zh), Tiếng Nhật (Ja), Tiếng Hàn (Ko)

Đối với việc chọn chuỗi k, phản ánh các quy mô ngữ cảnh hóa được áp dụng trong mô hình, chúng tôi thí nghiệm các quy mô nhỏ "0,0,1,1,3,3,5,5", các quy mô lớn "0,0,1,1,5,5,7,7", và các quy mô cân bằng "0,0,1,1,3,5,5,7". Những mô hình này có thể tận dụng thông tin độ chi tiết "1,3,5", "1,5,7", và "1,3,5,7" tương ứng.

Kết quả được thể hiện trong Bảng 4. Thứ nhất, mô hình quy mô cân bằng hoạt động tốt nhất trung bình, vì nó được cung cấp thông tin ngữ cảnh hóa của nhiều quy mô hơn và có nhiều tùy chọn để lựa chọn. Thứ hai, nếu chúng ta bỏ qua mô hình cân bằng và so sánh các mô hình khác, hiệu suất có liên quan đến các nhóm ngôn ngữ. Dấu "*" cho biết hiệu suất tốt hơn giữa hai mô hình. Đối với nhóm "Byte-1", quy mô nhỏ đủ để mô hình hóa ngữ nghĩa nhất định, vì vậy mô hình quy mô nhỏ hơn hoạt động tốt hơn. Đối với nhóm "Byte-3", nó yêu cầu quy mô ngữ cảnh lớn hơn để tạo thành nghĩa nhất định, vì vậy mô hình quy mô lớn hơn hoạt động tốt hơn.

Những khám phá này làm sáng tỏ việc chọn chuỗi k, đó là chuỗi k nên tương thích với ngôn ngữ của văn bản đầu vào.

## 5 Kết luận

Trong bài báo này, chúng tôi đưa ra hai đóng góp chính. Thứ nhất, chúng tôi cho thấy khi nào các mô hình dựa trên byte vượt trội hơn các mô hình dựa trên từ phụ và khi nào thì không. Trong các tình huống dịch đa ngôn ngữ quy mô lớn liên quan đến nhiều ngôn ngữ, các mô hình dựa trên byte thể hiện sự vượt trội rõ ràng, đặc biệt đối với các ngôn ngữ ít tài nguyên. Trong số lượng ngôn ngữ hạn chế với dữ liệu huấn luyện đầy đủ, các mô hình dựa trên byte thua kém các mô hình dựa trên từ phụ. Thứ hai, chúng tôi giới thiệu phương pháp Ngữ cảnh hóa Đa quy mô (MSC) tăng cường khả năng thích nghi của các mô hình dựa trên byte với các đầu vào đa dạng. Bằng cách tích hợp động thông tin ngữ cảnh hóa đa quy mô, MSC vượt trội hơn các mô hình dựa trên byte khác ở hầu hết các ngôn ngữ.

## Hạn chế

Mặc dù phương pháp của chúng tôi có thể tích hợp thông tin ngữ cảnh hóa đa quy mô một cách thích nghi, tất cả các phạm vi ngữ cảnh hóa k đều được xác định trước. Chúng tôi sẽ khám phá các phương pháp thích nghi hoàn toàn cho việc trích xuất và tích hợp thông tin đa quy mô cho công việc tương lai.

## Lời cảm ơn

Chúng tôi cảm ơn tất cả các nhà phê bình ẩn danh vì những bình luận sâu sắc và có giá trị của họ. Bài báo này được hỗ trợ bởi Quỹ Khoa học Tự nhiên Quốc gia Trung Quốc (Số Grant 62376260).
>>>>>>> Stashed changes

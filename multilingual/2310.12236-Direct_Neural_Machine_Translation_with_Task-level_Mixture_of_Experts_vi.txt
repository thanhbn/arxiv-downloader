# Dịch máy thần kinh trực tiếp với các mô hình Mixture of Experts cấp nhiệm vụ

Isidora Chara Tourni∗
Đại học Boston
isidora@bu.edu

Subhajit Naskar
Google
snaskar@google.com

## Tóm tắt

Dịch máy thần kinh trực tiếp (direct NMT) là một loại hệ thống NMT dịch văn bản giữa hai ngôn ngữ không phải tiếng Anh. Các hệ thống direct NMT thường gặp phải những hạn chế do sự khan hiếm dữ liệu song song giữa các cặp ngôn ngữ không phải tiếng Anh. Nhiều phương pháp đã được đề xuất để giải quyết hạn chế này, chẳng hạn như NMT đa ngôn ngữ và pivot NMT (dịch giữa hai ngôn ngữ thông qua tiếng Anh). Mixture of expert models cấp nhiệm vụ (Task-level MoE), một biến thể hiệu quả suy luận của các mô hình dựa trên Transformer, đã cho thấy hiệu suất NMT đầy hứa hẹn cho một số lượng lớn các cặp ngôn ngữ. Trong Task-level MoE, các nhóm ngôn ngữ khác nhau có thể sử dụng các chiến lược định tuyến khác nhau để tối ưu hóa việc học liên ngôn ngữ và tốc độ suy luận. Trong công trình này, chúng tôi xem xét khả năng áp dụng của Task-level MoE trong direct NMT và đề xuất một loạt các cấu hình đào tạo và đánh giá có hiệu suất cao, thông qua đó các hệ thống direct NMT dựa trên Task-level MoE vượt trội hơn các mô hình song ngữ và dựa trên pivot cho một số lượng lớn các cặp trực tiếp tài nguyên thấp và cao, cũng như các hướng dịch. Mô hình Task-level MoE của chúng tôi với 16 experts vượt trội hơn NMT song ngữ, các mô hình Pivot NMT cho 7 cặp ngôn ngữ, trong khi các mô hình dựa trên pivot vẫn hoạt động tốt hơn ở 9 cặp và hướng.

## 1 Giới thiệu

NMT (Sutskever et al., 2014; Bahdanau et al., 2014; Firat et al., 2016a; Johnson et al., 2017; Zoph and Knight, 2016; Bahdanau et al., 2014) đã có những tiến bộ đáng kể trong những năm gần đây, đặc biệt là với sự xuất hiện của kiến trúc Transformer (Vaswani et al., 2017), đã cho thấy kết quả ấn tượng trong các tác vụ dịch song ngữ và đa ngôn ngữ (Aharoni et al., 2019; Hassan et al., 2018; Tang et al., 2021). Các mô hình NMT đa ngôn ngữ lớn đặc biệt đã cho thấy hiệu suất đáng chú ý và có thể phục vụ việc dịch giữa bất kỳ ngôn ngữ nào, ngay cả đối với các cặp ngôn ngữ không được nhìn thấy trong quá trình đào tạo, mặc dù chất lượng NMT thường vẫn còn thấp. Trọng tâm cho đến nay chủ yếu là NMT lấy tiếng Anh làm trung tâm, vì có rất nhiều dữ liệu MT lấy tiếng Anh làm trung tâm (Tiedemann, 2018) nhưng ít dữ liệu song song cho các cặp ngôn ngữ không phải tiếng Anh (tài nguyên thấp). Do đó, nhu cầu cải thiện các phương pháp cho Direct NMT, tức là NMT giữa các ngôn ngữ không phải tiếng Anh là rõ ràng (Yang et al., 2021; Zhang et al., 2020).

Các phương pháp Direct NMT, khi không có dữ liệu xx–yy (trong đó xx đại diện cho mã ngôn ngữ nguồn, và yy đại diện cho mã ngôn ngữ đích), có thể được phân loại thành các phương pháp Zero-shot và Zero-resource. Trong Zero-shot NMT (Johnson et al., 2017; Gu et al., 2019; Wang et al., 2021; Philip et al., 2020), việc dịch xảy ra như sau: hoặc thông qua một ngôn ngữ cầu nối, thường là tiếng Anh, trong đó các mô hình được đào tạo trên các tập dữ liệu En–yy và xx–En mà không bao giờ được tiếp xúc với dữ liệu xx–yy, trong khi việc đánh giá diễn ra trên một số ít cặp xx–yy hiện có; hoặc đánh giá các mô hình đa ngôn ngữ lớn trên các cặp xx–yy, với cả xx hoặc yy đều không được nhìn thấy trong quá trình đào tạo mô hình. Mặt khác, Zero-resource NMT (Currey and Heafield, 2019; Firat et al., 2016b; Bapna et al., 2022), tạo ra dữ liệu giả song song giữa các cặp ngôn ngữ trực tiếp, sử dụng các tập dữ liệu xx–yy tổng hợp này trong quá trình đào tạo. Tuy nhiên, các mô hình song ngữ hoặc dựa trên pivot cho direct NMT, mặc dù cho thấy chất lượng NMT ấn tượng, nhưng không thực tế và hiệu quả về chi phí, đặc biệt là khi số lượng ngôn ngữ để dịch tăng lên. Ngoài ra, việc dựa vào các ngôn ngữ liên quan khi đánh giá một mô hình đa ngôn ngữ trên một cặp chưa được nhìn thấy không đảm bảo hiệu suất NMT tốt. Đồng thời, việc mở rộng quy mô lên các mô hình đa ngôn ngữ có hàng tỷ tham số, được đào tạo trên các tập dữ liệu rất lớn của nhiều cặp ngôn ngữ, gây ra chi phí đào tạo và suy luận lớn.

Các mô hình thưa thớt, và cụ thể là các mô hình Mixture-of-Experts (MoE) được kích hoạt thưa thớt (Shazeer et al., 2017; Lepikhin et al., 2020; Zoph et al., 2022; Ryabinin and Gusev, 2020), hình thành một hướng đầy hứa hẹn trong việc tạo ra một mô hình dịch phổ quát giữa tất cả các ngôn ngữ, đồng thời giải quyết các mối quan ngại về hiệu quả. Chúng tôi là những người đầu tiên điều tra hiệu suất của một loại mô hình MoE cụ thể, các mô hình Task-level MoE (Kudugunta et al., 2021) trong bối cảnh của Direct NMT, tập trung vào tác động của các phương pháp ánh xạ nhiệm vụ-đến-expert khác nhau đối với hiệu suất mô hình và việc sử dụng expert. Trong các thí nghiệm của chúng tôi, chúng tôi đào tạo các mô hình Task-level MoE đa ngôn ngữ lớn trên các cấu hình khác nhau, bao gồm Zero-shot, Zero-resource, và các tình huống trong đó dữ liệu cặp ngôn ngữ trực tiếp có sẵn. Chúng tôi tiến hành phân tích so sánh điểm BLEU trên các mô hình Task-level MoE với các chiến lược ánh xạ khác nhau và số lượng expert, cũng như các mô hình NMT song ngữ và NMT dựa trên pivot; các phát hiện của chúng tôi phục vụ như một tài nguyên có giá trị để xác định cấu hình mô hình tối ưu nhằm đạt được kết quả dịch chất lượng cao trong các cặp ngôn ngữ trực tiếp khác nhau. Bằng cách đào tạo các mô hình Task-level MoE đa ngôn ngữ thưa thớt lớn hoạt động tốt cho các cặp trực tiếp và thể hiện hiệu quả đào tạo, chúng tôi có thể trích xuất các mô hình dense nhỏ hơn chuyên biệt cho expert cụ thể, chuyên dịch giữa các Cặp Ngôn ngữ hoặc dịch sang một ngôn ngữ cụ thể. Các mô hình này đã sẵn sàng để triển khai và có thể thay thế các mô hình song ngữ hoặc dựa trên pivot (Hình 1). Công trình trước đây về Task-level MoEs (Kudugunta et al., 2021) chứng minh hiệu quả suy luận của định tuyến cấp nhiệm vụ, so với các phương pháp khác (cấp token hoặc cấp câu), cho tác vụ Multilingual NMT giữa các cặp lấy tiếng Anh làm trung tâm (En-yy và xx–En). Theo hiểu biết của chúng tôi, chúng tôi là những người đầu tiên xem xét hiệu suất của các mô hình Task-level MoE trong Direct NMT, cung cấp một giải pháp thực tế để mở rộng phạm vi bao phủ và chất lượng của NMT trên các cặp ngôn ngữ đa dạng.

## 2 Công trình Liên quan

### Dịch máy thần kinh trực tiếp

Firat et al. (2016b) đầu tiên đề xuất một mô hình NMT đa ngôn ngữ đa hướng zero-resource vượt trội hơn các phương pháp dựa trên pivot trước đây, đặt nền tảng cho nhiều phương pháp NMT zero-shot và/hoặc zero-resource tiếp theo. Nhiều nhà nghiên cứu khác nhau đã mở rộng công trình nền tảng này, khám phá các kỹ thuật và chiến lược khác nhau để cải thiện direct NMT (Ji et al., 2020; Johnson et al., 2017; Zhang et al., 2020; Chen et al., 2017; Lu et al., 2018; Al-Shedivat and Parikh, 2019; Rios et al., 2020; Zheng et al., 2017; Gu et al., 2019; Arivazhagan et al., 2019; Kim et al., 2019; Cheng and Cheng, 2019; Chen et al., 2018; Currey and Heafield, 2019; Ballesteros and Sanderson, 2003; Lakew et al., 2021). Cụ thể hơn, Freitag and Firat (2020) đã xây dựng một tập huấn luyện căn chỉnh đa hướng từ các corpus huấn luyện hiện có, căn chỉnh các ví dụ trong các cặp ngôn ngữ khác nhau với các câu nguồn hoặc đích giống hệt nhau. Họ giới thiệu một chiến lược lấy mẫu dữ liệu phân cấp để ngăn chặn việc thể hiện quá mức tiếng Anh trong tập huấn luyện và sử dụng một chiến lược dựa trên nhiệt độ để chọn ngôn ngữ đích, trong khi chọn ngôn ngữ nguồn một cách đồng đều. Các mô hình Multilingual NMT hoàn chỉnh của họ đã chứng minh hiệu suất được cải thiện trên các cặp trực tiếp và tương đương với kết quả baseline trên các cặp lấy tiếng Anh làm trung tâm. Liu et al. (2020) đã rời rạc hóa không gian tiềm ẩn đầu ra của encoder thành các mục trong một codebook đã học, cho phép biểu diễn các câu nguồn trong một ngôn ngữ chung và tăng độ bền vững và hiệu suất của mô hình trong các thiết lập zero-shot. Gần đây hơn, ?đã pre-train và fine-tune một mô hình NMT đa ngôn ngữ many-to-many vượt qua một số baseline pivoting và song ngữ cho Direct NMT, và ElNokrashy et al. (2022), đã trình bày một phương pháp mới trong đó các token ngôn ngữ nguồn và đích được thêm vào đầu vào encoder, trong khi các token ngôn ngữ đích được thêm vào đầu vào decoder. Điều này khác với các phương pháp trước đây chỉ sử dụng token Source-only và token beginning of Sentence cho các đầu vào encoder và decoder, tương ứng, và nhằm mục đích cải thiện hiệu suất của các mô hình Direct NMT bằng cách cung cấp ngữ cảnh phù hợp hơn cho cả encoder và decoder.

Các công trình mới nhất bao gồm phương pháp của Yang et al. (2022), người đã thống nhất ba mô hình riêng biệt để hướng dẫn mô hình học sinh trong quá trình Direct NMT, nhằm mục đích cải thiện hiệu suất của nó bằng cách khai thác điểm mạnh của nhiều mô hình; và Xu et al. (2022), người đã đề xuất một phương pháp Direct NMT bao gồm hai giai đoạn: trích xuất các ví dụ có độ tương tự cao và bản dịch của chúng trên các ngôn ngữ khác nhau để xây dựng một tập dữ liệu song song căn chỉnh đa hướng, cho phép mô hình học từ một tập các ví dụ dịch phong phú hơn, và tạo ra các ví dụ căn chỉnh bổ sung bằng cách sử dụng một mô hình tạo sinh được đào tạo tốt.

### Tính toán có điều kiện, Thưa thớt và các mô hình Mixture-of-Experts

Fedus et al. (2022) đã xem xét rộng rãi các mô hình Mixture-of-Experts (MoE) thưa thớt trong Deep Learning, bắt đầu từ công trình nền tảng của Shazeer et al. (2017), Lepikhin et al. (2020) và Fedus et al. (2021). Công trình của họ đi sâu vào các đặc điểm mở rộng quy mô, thuật toán định tuyến, và các cải tiến đào tạo được đề xuất cho các mô hình MoE, cũng như các ứng dụng mới nhất của các mô hình Sparse MoE trên các lĩnh vực khác nhau, chẳng hạn như Xử lý Ngôn ngữ Tự nhiên (NLP) (Zoph et al., 2022; Chowdhery et al., 2022; Lee-Thorp and Ainslie, 2022; Du et al., 2022), Thị giác Máy tính (Riquelme et al., 2021; Puigcerver et al., 2020; Wu et al., 2022; Hwang et al., 2022), Nhận dạng Giọng nói (You et al., 2021, 2022), và Học Đa phương thức (Mustafa et al., 2022). Trong NLP, nhiều nghiên cứu đã khám phá tiềm năng của các mô hình Sparse MoE cho các ứng dụng đa dạng. Kudugunta et al. (2021) đã giới thiệu khái niệm định tuyến cấp nhiệm vụ trong các mô hình MoE, đạt được điểm dịch được cải thiện so với các mô hình đa ngôn ngữ lớn với cùng chi phí suy luận và các mô hình học sinh dense được chưng cất từ các mô hình MoE cấp token hoặc cấp position. Bằng cách sử dụng các mô hình task-level MoE trong thí nghiệm của chúng tôi, chúng tôi điều tra và tối ưu hóa hiệu suất của chúng trong NMT của các cặp trực tiếp.

## 3 Thí nghiệm

### Mô hình

Chúng tôi đào tạo các mô hình Task-level MoE encoder-decoder thưa thớt, với dim = 1024, hidden dim = 4096, 8 heads, 3 layers. Theo ?, chúng tôi tương tự thay thế Transformer Feed Forward Network (FFN) bằng một tập các FFN experts giống hệt nhau. Chúng tôi sử dụng từ vựng SentencePiece 32,000 token (Kudo and Richardson, 2018), được chia sẻ trong cả encoder và decoder của mô hình. Chúng tôi thử nghiệm với số lượng experts, chọn 16 hoặc 64 experts, tương ứng với các mô hình có khoảng 1 tỷ và 3,5 tỷ tham số. Chúng tôi điều tra tác động của các phương pháp ánh xạ task id đến expert khác nhau, đặt task id là Ngôn ngữ Đích hoặc Cặp Ngôn ngữ cho việc dịch. Theo Kudo and Richardson (2018); Kudugunta et al. (2021), nhiệt độ lấy mẫu dữ liệu là T=5 trong quá trình đào tạo, và chúng tôi đào tạo 8 mô hình trong 2 triệu bước.

Quá trình đào tạo có batch size là 256, độ dài câu tối đa là 128. Bằng cách xem xét hiệu suất của các mô hình này dưới các cấu hình khác nhau, chúng tôi muốn hiểu rõ hơn mối quan hệ giữa số lượng experts, ánh xạ task id đến experts, và chất lượng dịch, cuối cùng thông báo các lựa chọn thiết kế tối ưu cho các mô hình Task-level MoE trong các tình huống khác nhau.

### Ngôn ngữ và Tập dữ liệu Đào tạo

Chúng tôi đào tạo các mô hình của mình sử dụng các tập dữ liệu quy mô sản xuất nội bộ, bao gồm các câu song song lấy tiếng Anh làm trung tâm và các cặp Trực tiếp, bao phủ 108 ngôn ngữ, bao gồm cả tiếng Anh. Dữ liệu đào tạo của chúng tôi bao gồm tổng cộng 107 cặp lấy tiếng Anh làm trung tâm, và 53 cặp trực tiếp, với kích thước dữ liệu cho mỗi cặp ngôn ngữ từ vài nghìn đến vài tỷ câu cho mỗi cặp. Số lượng câu trong mỗi cặp song song trong tập train được cung cấp trong Bảng 4 trong Phụ lục.

### Tập Đánh giá và Ánh xạ Nhiệm vụ

Để đánh giá, chúng tôi sử dụng các tập test nội bộ từ hai nguồn riêng biệt: Web Domain và Wikipedia. Các tập test này có kích thước khác nhau, chứa từ 500 đến 5,000 câu cho mỗi cặp ngôn ngữ. Trong cả tập dữ liệu đào tạo và đánh giá, chúng tôi tuân theo một quy ước tiền xử lý cụ thể, thêm vào trước câu nguồn các token <4xx> <2yy>. Các token này phục vụ như một gợi ý cho mô hình, giúp nó xác định ngôn ngữ nguồn và đích trong ngữ cảnh, và mô hình để học tốt hơn và thích nghi với các kết hợp cặp ngôn ngữ khác nhau.

Các mô hình của chúng tôi sử dụng Cặp Ngôn ngữ (LP) chính xác của tập train hoặc ngôn ngữ đích (TL) của cặp làm task id để ánh xạ các cặp dịch đến các experts khác nhau. Trong trường hợp trước, chúng tôi trực tiếp ánh xạ cặp ngôn ngữ cụ thể (En–yy, xx–En hoặc xx–yy) đến một task id, và có tổng cộng 214 nhiệm vụ (107 x 2 cặp lấy tiếng Anh làm trung tâm) khi đào tạo chỉ với các tập dữ liệu tiếng Anh, hoặc 267 nhiệm vụ (+ 53 Cặp Ngôn ngữ trực tiếp) khi kết hợp các LP Trực tiếp. Mặt khác, khi sử dụng ngôn ngữ đích làm task id, chúng tôi có 108 nhiệm vụ (107 ngôn ngữ và tiếng Anh) trong tất cả các tình huống. Ở đó chúng tôi tận dụng và cố gắng hưởng lợi từ các đặc điểm chung của các bản dịch sang cùng một ngôn ngữ đích. Vì chúng tôi đánh giá các mô hình của mình trên dữ liệu Cặp Ngôn ngữ trực tiếp (không phải tiếng Anh), thường xảy ra trường hợp ánh xạ chính xác của cặp đến một expert không được xác định trong quá trình đào tạo. Để giải quyết vấn đề này, chúng tôi thử nghiệm với một số phương pháp để ánh xạ cặp ngôn ngữ xx–yy đến một task id tại thời điểm suy luận - trong mỗi phương pháp được đề cập bên dưới, chúng tôi đặt tên thành phần được sử dụng làm task id:

• Cặp Ngôn ngữ (LP) làm task id.
– lp_mapping_a (lp_a): LP chính xác
– lp_mapping_b (lp_b): LP En–yy
– lp_mapping_c (lp_c): LP xx–En
• Ngôn ngữ đích làm task id
– tl_mapping_a (tl_a): yy
– tl_mapping_b (tl_b): xx

## 4 Kết quả & Thảo luận

Trong nghiên cứu này, chúng tôi có hai baseline chính để so sánh: các mô hình NMT song ngữ và các mô hình NMT dựa trên pivot, được đào tạo bằng chiến lược cầu nối thông qua tiếng Anh. Chúng tôi sử dụng BLEU (Papineni et al., 2002) để đánh giá chất lượng dịch của tất cả các cặp ngôn ngữ trực tiếp. Chúng tôi biết rằng các metric đã học như COMET (Rei et al., 2022) và BLEURT (Sellam et al., 2020) cho thấy mối tương quan cao hơn với đánh giá của con người đối với các cặp ngôn ngữ tài nguyên cao, lấy tiếng Anh làm trung tâm (Freitag et al., 2022). Tuy nhiên, không rõ các metric đã học hoạt động tốt như thế nào trên các ngôn ngữ tài nguyên thấp và do đó chúng tôi quyết định sử dụng BLEU cho phần chính của bài báo. Bảng 2 và 3 tóm tắt kết quả cho các mô hình Task-level MoE với 16 hoặc 64 experts.

Trong Bảng 1, chúng tôi cho thấy các cấu hình cụ thể dẫn đến điểm BLEU cao nhất cho các mô hình Task-level MoE - so sánh những điểm đó với hiệu suất của các mô hình song ngữ và dựa trên pivot, chúng tôi nhằm mục đích nhấn mạnh điểm BLEU tốt nhất cho mỗi cặp ngôn ngữ. Phân tích này cho phép chúng tôi xác định các mô hình hiệu quả nhất cho mỗi cặp và có được những hiểu biết sâu sắc về cách các cấu hình mô hình khác nhau và số lượng expert góp phần vào hiệu suất dịch, vì vậy chúng tôi có thể hiểu rõ hơn các ưu điểm và hạn chế của các mô hình Task-level MoE với số lượng experts khác nhau, cũng như các mô hình NMT song ngữ và dựa trên pivot. Kết quả của chúng tôi cuối cùng giúp thông báo việc lựa chọn các mô hình dịch và chiến lược để tối ưu hóa hiệu suất cho các cặp ngôn ngữ khác nhau.

Hiệu suất của các mô hình NMT khác nhau đáng kể tùy thuộc vào cặp, và vào hướng dịch - một số cặp nhất định cho thấy sự khác biệt lớn giữa các hướng dịch. Chúng tôi thấy rằng các mô hình dựa trên pivot hoạt động tốt hơn các mô hình song ngữ đối với đa số các cặp. Các mô hình NMT song ngữ và NMT dựa trên pivot chứng minh kết quả mạnh mẽ trong một số trường hợp, trong khi các mô hình Task-level MoE cho thấy hiệu suất hỗn hợp trên các Cặp Ngôn ngữ khác nhau.

### Mô hình nào hoạt động tốt nhất cho mỗi cặp?

Kết quả Bảng 1 cho thấy rằng đối với đa số các cặp ngôn ngữ trực tiếp, điểm BLEU Task-level MoE cao nhất đạt được bằng cách sử dụng một mô hình với 16 experts, với các phương pháp ánh xạ-đến-experts tl_a và lp_b vượt qua các phương pháp khác. Đặc biệt đáng chú ý là đối với các cặp ngôn ngữ thuộc về các họ ngôn ngữ có liên quan chặt chẽ (Nhật Bản, Trung Quốc, Hàn Quốc, Việt Nam và Thái Lan), các mô hình dựa trên LP-mapping dường như hoạt động tốt nhất. Ngược lại, các mô hình dựa trên TL có xu hướng vượt trội hơn phần còn lại của các cặp ngôn ngữ khác. Trong trường hợp này, các mô hình Task-level MoE cho thấy hiệu suất vượt trội trong hướng dịch tiến trên tất cả các cặp. Trong khi đó, các mô hình dựa trên pivot mang lại kết quả tốt nhất trong hướng dịch ngược cho bốn trong số năm cặp trong những ngôn ngữ liên quan đó. Quan sát này cho thấy rằng các chiến lược ánh xạ-đến-experts khác nhau có thể hiệu quả hơn cho một số cặp ngôn ngữ hoặc hướng dịch nhất định, tùy thuộc vào các mối quan hệ ngôn ngữ học và đặc điểm độc đáo của các ngôn ngữ có liên quan; một phương pháp phù hợp trong việc sử dụng các mô hình Task-level MoE và các phương pháp ánh xạ-đến-experts là chìa khóa để tối ưu hóa hiệu suất dịch cho các cặp ngôn ngữ và hướng khác nhau.

### So sánh các phương pháp ánh xạ nhiệm vụ đến expert khác nhau

Từ Bảng 2, các mô hình dựa trên pivot, các mô hình Task-level MoE (LP) với ánh xạ task id lp_b và các mô hình Task-level MoE (TL) với ánh xạ task id tl_a (cả hai đều được đào tạo với 16 experts) chủ yếu là những mô hình hoạt động tốt nhất trong tất cả các cặp.

Các mô hình Task-level MoE với định tuyến task id LP đến expert và ánh xạ lp_b tại thời điểm suy luận xuất sắc trong các bản dịch sang tiếng Nhật, từ tiếng Thái, Việt Nam, Hàn Quốc và Trung Quốc (+3,17, +6,2, +21,15, +14,95 điểm BLEU so với mô hình pivot-level NMT, tương ứng, và +15,27, +16,97, +36,52, +31,77 điểm BLEU so với các mô hình song ngữ) cũng như Hàn-Trung (ko-zh) (+6,22 BLEU so với mô hình dựa trên pivot, +28,64 BLEU so với baseline song ngữ) và Pháp-Ả Rập (fr–ar) (+0,15 và +5,35 BLEU so với các mô hình pivot và NMT song ngữ, tương ứng). Điều này chỉ ra rằng chiến lược ánh xạ lp_b đặc biệt hiệu quả cho các cặp ngôn ngữ này; định tuyến đến expert tốt nhất tại bản dịch En–yy, trong đó yy là ngôn ngữ đích của mỗi cặp, thay vì định tuyến đến expert được đào tạo rõ ràng trên cặp trực tiếp chính xác, xx–yy, có thể nắm bắt tốt hơn các sắc thái ngôn ngữ học của cặp và dẫn đến điểm dịch được cải thiện.

Các mô hình Task-level MoE được đào tạo với phương pháp ánh xạ TL task-to-expert và ánh xạ task id tl_a, tận dụng các cặp ngôn ngữ đích để định tuyến trong quá trình suy luận, đạt điểm cao nhất cho các bản dịch liên quan đến tiếng Kazakh (kk), chẳng hạn như Kazakh-Nga (kk–ru) theo cả hai hướng (+13,62 và +13,68 điểm BLEU so với mô hình dựa trên pivot, +0,34 và +12,34 điểm BLEU so với các mô hình song ngữ). Thành công của chiến lược ánh xạ tl_a cho thấy mô hình thể hiện hiệu suất vượt trội trong những trường hợp đó và khi cặp được định tuyến đúng cách đến expert chuyên biệt trong ngôn ngữ đích của cặp.

Bảng 3 cho thấy kết quả từ việc đánh giá các mô hình Task-level MoE 64 experts của chúng tôi. Thật thú vị, các phương pháp dựa trên pivot nổi bật như là những phương pháp hoạt động tốt nhất trong đa số các cặp và hướng. Các cặp này bao gồm Bulgaria–Macedonia (bg–mk), Pháp–Ả Rập (fr–ar), và Nhật–Thái (ja–th), cũng như Trung-Hàn (zh-ko) theo cả hai hướng, và Nhật-Hàn (ja–ko). Trong tất cả các cặp và hướng khác, cụ thể khi dịch sang tiếng Nhật từ tiếng Việt, Hàn Quốc và Trung Quốc, các mô hình Task-level MoE (LP) với phương pháp ánh xạ lp_a xuất hiện như những mô hình hoạt động tốt nhất (+0,21, +3,81, +2,54 điểm BLEU so với mô hình dựa trên pivot, tương ứng, và +10, +19,18, +19,36 điểm BLEU so với baseline song ngữ).

Đối với một số Cặp Ngôn ngữ nhất định với lượng dữ liệu đào tạo nhỏ hơn, các mô hình NMT song ngữ đạt hiệu suất hợp lý ngay cả với dữ liệu hạn chế và thường vượt trội hơn những mô hình khác. Mặt khác, chúng tôi thấy rằng các mô hình NMT dựa trên pivot hoạt động tốt khi có một lượng đáng kể dữ liệu đào tạo (ví dụ, Belarus–Macedonia, và Nga–Thổ Nhĩ Kỳ theo cả hai hướng, Ả Rập–Pháp, Trung–Hàn, Nhật–{Thái, Việt Nam, Trung Quốc}). Điều này có thể do các mô hình này tận dụng tiếng Anh như một ngôn ngữ cầu nối trung gian giữa ngôn ngữ nguồn và đích, điều này hữu ích khi có đủ dữ liệu để giúp học các biểu diễn có ý nghĩa.

### So sánh các mô hình với số lượng experts khác nhau

Trong Hình 2, chúng tôi trình bày sự khác biệt trong điểm BLEU trên các cặp ngôn ngữ trực tiếp được chọn cho các mô hình Task-level MoE được đào tạo bằng ánh xạ dựa trên Cặp Ngôn ngữ (LP) hoặc Ngôn ngữ Đích (TL), với 16 và 64 experts. Chúng tôi tìm cách nhấn mạnh một cách trực quan sự khác biệt về hiệu suất trên các mô hình sử dụng số lượng experts khác nhau, để có được những hiểu biết sâu sắc về hiệu quả tương đối của chúng và hiểu cách lựa chọn chiến lược ánh xạ (LP hoặc TL) và số lượng experts (16 hoặc 64) tác động đến hiệu suất dịch. Đối với đa số các cặp (Việt–Nhật, và cả hai hướng của Pháp–Ả Rập, Nhật–Thái, Trung–Hàn, Nhật–Hàn, Nhật–Trung), các mô hình Task-level MoE với 16 experts vượt trội hơn những mô hình với 64. Đối với những cặp ngôn ngữ đó, ngoại trừ Nhật–Trung, mà Task-level MoE dựa trên TL với tl_a cho thấy hiệu suất tốt nhất, Task-level MoE dựa trên LP với ánh xạ lp_b cho thấy lợi ích lớn nhất khi được đào tạo với ít experts hơn, củng cố các phát hiện trước đây của chúng tôi. Đối với các cặp khác, chẳng hạn như Nhật–Thái, Nhật–Trung, và Bengali–Macedonia, các biến thể mô hình khác nhau cho thấy cải thiện lớn nhất khi được đào tạo với 16 hoặc 64 experts. Chúng tôi cũng nhận thấy một sự cải thiện điểm BLEU đáng kể, nhưng không phải là tối đa, cho một số lượng lớn các cặp với mô hình Task-level MoE dựa trên TL và mô hình Task-level MoE dựa trên LP, khi sử dụng tl_a và lp_a trên ánh xạ task-to-expert trong quá trình suy luận, tương ứng, giữa các mô hình 16 và 64 experts.

### Phân tích quyết định định tuyến

Trong Hình 3, 4, 5, 6 chúng tôi cho thấy việc sử dụng experts cho các lớp encoder và decoder cuối cùng của mô hình cho các cặp khác nhau, cho mô hình Task-level MoE dựa trên TL của chúng tôi, với tl_a được sử dụng như một phương pháp ánh xạ task đến expert trong quá trình đào tạo; Một ô càng tối trong mỗi Hình, expert đó càng được cặp ngôn ngữ cụ thể sử dụng nhiều. Chúng tôi có thể quan sát rằng các cặp ngôn ngữ với cùng ngôn ngữ đích được định tuyến đúng cách đến cùng một expert, như mong đợi. Thật thú vị khi thấy rằng không có sự khác biệt lớn giữa các quyết định định tuyến của encoder trên các checkpoints, tuy nhiên chúng tôi nhận thấy những thay đổi trong việc gán experts trong decoder trong và cuối quá trình đào tạo; lúc đầu, các cặp với cùng ngôn ngữ đích được ánh xạ đến các experts khác nhau giống nhau, tuy nhiên khi mô hình hội tụ, chúng tôi thấy một sự trùng lặp đáng kể trong các experts đã chọn, cho các cặp với ngôn ngữ đích khác nhau. Chúng tôi cũng thấy một sự trùng lặp lớn trong các experts được chọn trong encoder trong và cuối quá trình đào tạo - đa số experts giống nhau trong suốt quá trình đào tạo mô hình và một số experts nhất định được ưa thích hơn những experts khác. Sự ưa thích này khác với các experts được chọn trong decoder, nơi chúng tôi thấy gần như không có sự trùng lặp. Cũng đáng chú ý rằng số lượng experts chung giữa encoder và decoder là tối thiểu, cả trong quá trình đào tạo và khi mô hình hội tụ.

Trong Phụ lục, chúng tôi cũng cho thấy việc sử dụng experts trong encoder và decoder của mô hình Task-level MoE dựa trên TL 64 experts của chúng tôi.

## 5 Kết luận

Chúng tôi đã tiến hành một phân tích kỹ lưỡng về việc sử dụng các mô hình Task-level Mixture of Expert cho Direct NMT. Thí nghiệm của chúng tôi tiết lộ điểm mạnh và điểm yếu của các phương pháp khác nhau và làm sáng tỏ cấu hình nào hoạt động tốt nhất cho các cặp ngôn ngữ trực tiếp cụ thể. Các so sánh của chúng tôi giúp xác định các mô hình hoạt động tốt nhất và cung cấp những hiểu biết sâu sắc có giá trị về cách số lượng experts khác nhau và các phương pháp ánh xạ task-to-expert khác nhau, trong quá trình đào tạo và suy luận, có thể ảnh hưởng đến chất lượng dịch của các cặp trực tiếp trong các mô hình Task-level MoE. Cụ thể, chúng tôi nhận thấy rằng các mô hình Task-level MoE NMT, cùng với các phương pháp dựa trên pivot, thường xuyên là những performers hàng đầu cho nhiều cặp ngôn ngữ trực tiếp. Tuy nhiên, hiệu suất của chúng thay đổi giữa các cặp và hướng dịch khác nhau. Bên cạnh việc quan sát kết quả chất lượng NMT, phân tích về việc sử dụng expert trong suốt quá trình đào tạo của chúng tôi cũng phục vụ như một cách thông tin để trực quan hóa và hiểu ánh xạ các cặp ngôn ngữ đến các experts mô hình trong encoder và decoder trong suốt quá trình đào tạo. Công việc trong tương lai có thể tập trung vào việc tăng cường mô hình này để có phạm vi bao phủ ngôn ngữ rộng hơn, bao gồm các ngôn ngữ tài nguyên thấp khác, để cải thiện thêm chất lượng dịch và hiệu quả.

### Hạn chế

Đào tạo và đánh giá các mô hình Task-level MoE có thể rất thách thức do kích thước và độ phức tạp của các mô hình. Có một số lượng lớn tham số cần điều chỉnh, chẳng hạn như số lượng và kích thước của experts, số lượng và tính đa dạng của ngôn ngữ, và của các Cặp Ngôn ngữ lấy tiếng Anh làm trung tâm và trực tiếp trong đào tạo, kích thước batch, kích thước từ vựng và độ dài câu tối đa. Đồng thời, việc đánh giá trên một số lượng lớn các cặp trực tiếp, đào tạo các mô hình Bilingual và Pivot-level riêng biệt cho tất cả để sử dụng làm baselines, và cũng thực hiện phân tích và trực quan hóa experts cho những cặp đó là tốn thời gian và tính toán đắt đỏ. Điều này tự động hạn chế số lượng và chiều rộng của kết quả, và kêu gọi khám phá thêm các khả năng của mô hình trong tương lai.

### Tuyên bố Đạo đức

Làm việc với các mô hình ngôn ngữ lớn đặt ra một số mối quan ngại đạo đức trong nghiên cứu NLP, đặc biệt liên quan đến chất lượng, thiên kiến và tính độc hại của kết quả đầu ra (Bender et al., 2021; Chowdhery et al., 2022; Blodgett et al., 2020; Brown et al., 2020). Trong bối cảnh của NMT, sự tham gia của nhiều bên liên quan trong tác vụ, cũng như những nguy hiểm phát sinh từ việc dịch sai văn bản gốc cần được xem xét, vì chúng có thể ảnh hưởng đến nhận thức về công việc và gây tổn hại đến lợi ích của các bên khác nhau (Taivalkoski-Shilov, 2019; Gambier and Van Doorslaer, 2016). Không thể phủ nhận, lợi ích của các hệ thống NMT được phát triển và triển khai một cách có trách nhiệm nằm trong việc làm cho công việc của tác giả dễ tiếp cận hơn, cho phép chuyển giao ý tưởng đến các đối tượng khác, và tăng cường cả khả năng của người đọc và vai trò cùng cảm giác đóng góp của người dịch (Besacier, 2014), đó là những hướng mà bất kỳ công việc nào trong lĩnh vực này nên nhắm tới tập trung.

# COIG-CQIA: Chất lượng là tất cả những gì bạn cần cho việc tinh chỉnh hướng dẫn tiếng Trung

Yuelin Bai1*Xinrun Du2*Yiming Liang3*Yonggang Jin2*Junting Zhou2,4*
Ziqiang Liu1Feiteng Fang5Mingshan Chang1Tianyu Zheng2Xincheng Zhang5
Nuo Ma6Zekun Wang2Ruibin Yuan2,7Haihong Wu5Hongquan Lin5
Wenhao Huang6Jiajun Zhang3Chenghua Lin2,10Jie Fu7Min Yang1
Shiwen Ni1†Ge Zhang8,9†

1Viện Công nghệ Tiên tiến Shenzhen, CAS2M-A-P3Viện Tự động hóa, CAS
4Đại học Bắc Kinh5Đại học Khoa học và Công nghệ Trung Quốc601.ai7HKUST
8Đại học Waterloo9Viện Vector10Đại học Manchester

## Tóm tắt

Tiến bộ đáng kể trong việc tinh chỉnh hướng dẫn tiếng Anh đã tạo điều kiện cho hiệu quả và độ tin cậy của các mô hình ngôn ngữ lớn (LLMs). Tuy nhiên, vẫn còn một khoảng cách đáng chú ý trong việc tinh chỉnh hướng dẫn cho tiếng Trung, nơi các đặc điểm ngôn ngữ phức tạp đặt ra những thách thức đáng kể. Các bộ dữ liệu hiện tại, thường được chưng cất từ các LLM tập trung vào tiếng Anh, không phù hợp với các mô hình tương tác của người dùng Trung Quốc. Để thu hẹp khoảng cách này, chúng tôi giới thiệu COIG-CQIA, một bộ dữ liệu tinh chỉnh hướng dẫn tiếng Trung mới được lấy từ các nguồn thực tế đa dạng và trải qua quá trình xác minh nghiêm ngặt của con người. Chúng tôi thực hiện các thí nghiệm mở rộng trên COIG-CQIA, và so sánh chúng với các mô hình và bộ dữ liệu cơ sở mạnh mẽ. Kết quả thí nghiệm cho thấy các mô hình được huấn luyện trên COIG-CQIA đạt được hiệu suất cạnh tranh cao trong các bài đánh giá đa dạng. Ngoài ra, những phát hiện của chúng tôi cung cấp một số hiểu biết sâu sắc để thiết kế các bộ dữ liệu tinh chỉnh hướng dẫn tiếng Trung hiệu quả và các chiến lược pha trộn dữ liệu. Bộ dữ liệu của chúng tôi có sẵn tại https://huggingface.co/datasets/m-a-p/COIG-CQIA.

## 1 Giới thiệu

Các Mô hình Ngôn ngữ Lớn (LLMs) đã thể hiện khả năng đáng kể như những trợ lý đa năng. Nền tảng của sự tiến bộ này là tinh chỉnh hướng dẫn (Zhang et al., 2023b), điều này nâng cao đáng kể hiệu quả và tính an toàn của các mô hình trong việc tuân theo hướng dẫn của con người. Ý tưởng cốt lõi là huấn luyện các mô hình với dữ liệu cặp hướng dẫn-đầu ra, từ đó điều chỉnh mục tiêu huấn luyện của mô hình với ý định của con người. Điều này nhấn mạnh vai trò quan trọng của các bộ dữ liệu tinh chỉnh hướng dẫn chất lượng cao trong việc cho phép LLMs hoạt động như những trợ lý hiệu quả và đáng tin cậy. Bất chấp tiến bộ đáng kể đã đạt được trong các bộ dữ liệu tinh chỉnh hướng dẫn tiếng Anh, các bộ dữ liệu cho tinh chỉnh hướng dẫn tiếng Trung vẫn ở giai đoạn sơ khai. Các bộ dữ liệu hiện tại có thể được phân loại thô thành ba loại: (1) Bộ dữ liệu có nguồn gốc từ các bộ dữ liệu hướng dẫn tiếng Anh (Peng et al., 2023) hoặc bộ dữ liệu NLP (BAAI, 2023; Yang, 2023), (2) Bộ dữ liệu được tổng hợp bởi LLMs (Guo et al., 2023; Ji et al., 2023; Sun et al., 2023), và (3) Bộ dữ liệu lai được xây dựng bằng các phương pháp khác nhau (Zhang et al., 2023a). Để cải thiện chất lượng bộ dữ liệu, COIG (Zhang et al., 2023a) đã tận dụng nhiều phương pháp để xây dựng một kho dữ liệu hướng dẫn được xác minh bởi con người. Tuy nhiên, hai thách thức chính vẫn tồn tại trong các bộ dữ liệu tinh chỉnh hướng dẫn tiếng Trung trước đây. Thứ nhất, chúng gặp phải vấn đề không phù hợp với người dùng Trung Quốc trong thế giới thực do thiếu dữ liệu ngôn ngữ xác thực. Thứ hai, chúng vẫn đầy rẫy các vấn đề về chất lượng do chi phí cao của việc xác minh toàn diện bởi con người. Hơn nữa, việc các nguồn dữ liệu khác nhau tác động như thế nào đến các nhiệm vụ tiếng Trung hạ lưu vẫn chưa được khám phá đầy đủ, làm trầm trọng thêm những thách thức trong việc xây dựng các bộ dữ liệu tiếng Trung.

Để giải quyết những thách thức này, chúng tôi giới thiệu COIG-CQIA (Chinese Open Instruction Generalist - Quality Is All You Need), một bộ dữ liệu tinh chỉnh hướng dẫn tiếng Trung mới, được phân biệt bởi việc kết hợp các nguồn dữ liệu thực tế đa dạng và quy trình xác minh nghiêm ngặt của con người. Lấy cảm hứng từ LIMA (Zhou et al., 2023), COIG-CQIA tập trung vào việc tuyển chọn một bộ dữ liệu từ các nguồn internet tiếng Trung đa dạng, bao gồm truyền thông xã hội và diễn đàn, các bách khoa toàn thư toàn diện, các kỳ thi thách thức, và kho dữ liệu ngôn ngữ hiện tại. Những dữ liệu này trải qua quá trình làm sạch kỹ lưỡng, tái cấu trúc, và xác minh cẩn thận của con người để đảm bảo chất lượng và tính đa dạng. Mục tiêu của chúng tôi là nâng cao khả năng thành thạo của LLMs trong việc tuân theo hướng dẫn tiếng Trung và thực hiện các nhiệm vụ hạ lưu. Chúng tôi thực hiện các thí nghiệm mở rộng để khám phá cách các nguồn dữ liệu khác nhau tác động đến các nhiệm vụ hạ lưu khác nhau và khám phá lợi ích của các chiến lược pha trộn dữ liệu khác nhau. Ngoài ra, chúng tôi tích hợp COIG-CQIA với dữ liệu tiếng Anh để điều tra hiệu suất của các mô hình được huấn luyện trong các tình huống đa ngôn ngữ. Các thí nghiệm tiếp theo cho thấy COIG-CQIA đạt được kết quả cạnh tranh cao so với các bộ dữ liệu tiếng Trung khác và các mô hình cơ sở mạnh mẽ. Những đóng góp chính của chúng tôi như sau:

• **Tài nguyên**. Chúng tôi giới thiệu COIG-CQIA, một bộ dữ liệu tinh chỉnh hướng dẫn tiếng Trung chất lượng cao được xây dựng từ các nguồn thực tế đa dạng và được xác minh bởi con người để đảm bảo chất lượng.

• **Hiệu suất**. Chúng tôi chứng minh hiệu quả của COIG-CQIA thông qua các thí nghiệm mở rộng, cho thấy khả năng cạnh tranh của nó so với các bộ dữ liệu tiếng Trung khác và các mô hình cơ sở.

• **Hiểu biết sâu sắc**. Chúng tôi điều tra một cách có hệ thống tác động của các nguồn dữ liệu khác nhau và các chiến lược pha trộn đến hiệu suất nhiệm vụ hạ lưu, cung cấp hiểu biết sâu sắc về ảnh hưởng của nguồn dữ liệu và chiến lược huấn luyện.

## 2 TUYỂN CHỌN COIG-CQIA

Để đảm bảo chất lượng và tính đa dạng của dữ liệu, chúng tôi đã tuyển chọn dữ liệu từ 18 nguồn Internet tiếng Trung chất lượng cao. Chúng tôi cũng tích hợp các bộ dữ liệu NLP tiếng Trung hiện có và các kỳ thi để mở rộng tính đa dạng của nhiệm vụ. Cụ thể, chúng tôi phân loại tất cả các nguồn dữ liệu thành bốn loại: Truyền thông xã hội & diễn đàn, Kiến thức thế giới, Nhiệm vụ NLP, và Kỳ thi. Thông tin thống kê của dữ liệu được chi tiết trong bảng 1.

### 2.1 Thu thập Dữ liệu Thô

Trong giai đoạn đầu này, chúng tôi tổng hợp dữ liệu từ các nguồn đa dạng từ Internet, bao gồm các nền tảng truyền thông xã hội, bách khoa toàn thư, và các trang web chuyên biệt. Ví dụ, chúng tôi sử dụng một web crawler để thu thập bài đăng từ Zhihu, SegmentFault, v.v., cũng như các mục từ các nguồn bách khoa toàn thư như Bách khoa toàn thư Trung Quốc. Đối với nội dung HTML được thu thập, chúng tôi cẩn thận chuyển đổi chúng thành các cặp câu hỏi-trả lời hoặc tài liệu. Chúng tôi bảo tồn càng nhiều siêu dữ liệu phi văn bản càng tốt, chẳng hạn như lượt thích, bình luận, tác giả, các yếu tố đa phương tiện, v.v., để tạo điều kiện cho việc lọc dựa trên quy tắc dựa trên siêu dữ liệu này. Đồng thời, chúng tôi thu thập các bài thi chính thức có sẵn công khai từ các năm trước và sử dụng công cụ Mathpix để trích xuất các câu hỏi và câu trả lời chi tiết từ các tài liệu. Trong Bảng 1, chúng tôi đánh dấu tất cả các nguồn được xử lý thành văn bản thuần từ kho dữ liệu được thu thập hoặc phi văn bản bằng ■.

### 2.2 Bộ lọc Dựa trên Quy tắc

Bộ lọc dựa trên quy tắc được thực hiện sau khi trích xuất dữ liệu văn bản thuần. Mục đích chính của nó là thực hiện làm sạch dữ liệu sơ bộ, loại bỏ nội dung chứa thông tin có hại hoặc không phù hợp, các yếu tố đa phương tiện, hoặc quảng cáo. Ngoài ra, nó loại bỏ dữ liệu không đáp ứng tiêu chí độ dài được chỉ định hoặc thiếu sự chấp nhận rộng rãi của con người (ví dụ, các bài đăng có rất ít lượt thích trong diễn đàn). Giai đoạn này là cần thiết trong khi có hiệu quả cao, có khả năng giảm bộ dữ liệu từ hàng triệu mục xuống hàng trăm nghìn. Lọc dựa trên quy tắc được áp dụng cho hầu hết tất cả các nguồn dữ liệu, như được đánh dấu bằng các hình vuông xanh lá cây ■ trong bảng 1.

### 2.3 Giao Nhiệm vụ

Giai đoạn này được sử dụng để chuyển đổi các bài đăng và bài viết thô thành các định dạng hướng dẫn-phản hồi cho việc tinh chỉnh hướng dẫn. Nhìn chung, chúng tôi đã thiết kế một loạt các mẫu hướng dẫn hoặc phản hồi dựa trên các đặc điểm của nội dung từ các nguồn dữ liệu khác nhau. Ví dụ, đối với các mục bách khoa toàn thư, các nhiệm vụ tập trung chủ yếu vào giải thích khái niệm, trong khi đối với các nguồn giàu siêu dữ liệu như Douban, chúng tôi thiết kế các nhiệm vụ xung quanh viết đánh giá, gợi ý, v.v. Tất cả các chi tiết của quá trình xây dựng dữ liệu được mô tả trong phụ lục A. Không phải tất cả các nguồn dữ liệu đều yêu cầu các mẫu được thiết kế thủ công, và những nguồn đó được đánh dấu bằng các hình vuông màu cam ■ trong Bảng 1.

### 2.4 Bộ lọc Dựa trên Mô hình

Mặc dù dữ liệu từ truyền thông xã hội và diễn đàn phản ánh chặt chẽ các tương tác thực sự của con người và cung cấp tính đa dạng lớn, nhưng việc đảm bảo rằng tất cả dữ liệu này đều vô hại và chính xác là một thách thức. Lọc dựa trên mô hình (được đánh dấu bằng các hình vuông màu hồng ■) có thể giúp loại bỏ dữ liệu chất lượng thấp khó loại bỏ thông qua lọc dựa trên quy tắc hoặc siêu dữ liệu. Điều này thường bao gồm các cặp hướng dẫn-phản hồi không liên quan, quảng cáo mềm, và nội dung có khả năng có hại. Chúng tôi sử dụng GPT-4 để lọc các nguồn dữ liệu, vì nó được sử dụng rộng rãi trong LLMs-as-judge và thể hiện mối tương quan cao với phán đoán của con người trong việc đánh giá chất lượng dữ liệu. Chúng tôi chi tiết quá trình này cho các nguồn cụ thể trong phụ lục A.

### 2.5 Hoàn thiện bởi Con người

Để cuối cùng đảm bảo chất lượng dữ liệu, chúng tôi mời các nhà đánh giá con người tái kiểm tra tất cả dữ liệu và hoàn thiện từng nguồn dữ liệu. Phù hợp với tiêu chí lọc dựa trên mô hình của chúng tôi, chúng tôi yêu cầu các giám khảo con người đánh giá tính hữu ích, chuyên nghiệp, tính nhất quán logic, mức độ chi tiết, tính khách quan, và tính vô hại của dữ liệu. Với tính linh hoạt và biến đổi trong việc sử dụng ngôn ngữ Trung Quốc, đánh giá con người cho phép lọc ra các trường hợp mà các phương pháp dựa trên quy tắc và dựa trên mô hình gặp khó khăn trong việc xác định. Quá trình này cũng bao gồm việc thực hiện các sửa đổi thích hợp cho các cặp hướng dẫn-phản hồi để đảm bảo tính chính xác và sự phù hợp giữa các phản hồi và ý định của hướng dẫn. Chúng tôi chi tiết quá trình này trong phụ lục A.

## 3 Phân tích Dữ liệu

### 3.1 Thống kê

Chúng tôi đã thu thập tổng cộng 45.173 trường hợp từ 18 nguồn trong Internet và Cộng đồng Trung Quốc, bao gồm các lĩnh vực từ kiến thức tổng quát và STEM đến nhân văn. Bảng 1 mô tả thống kê dữ liệu cho tất cả các nguồn. Chúng tôi thể hiện phân bố độ dài của các hướng dẫn và phản hồi trong Hình 5.

### 3.2 Phân bố Ngữ nghĩa

Để trực quan hóa và phân tích tính đa dạng ngữ nghĩa của bộ dữ liệu, chúng tôi sử dụng U-MAP để tạo bản đồ phân bố của tất cả các hướng dẫn. Hình 6 trong Phụ lục B minh họa phân bố ngữ nghĩa của COIG-CQIA so với các bộ dữ liệu khác. Trực quan hóa U-MAP cho thấy COIG-CQIA thể hiện phân bố rộng rãi và đa dạng nhất trong tất cả các bộ dữ liệu được so sánh.

### 3.3 Chất lượng

Chúng tôi lấy mẫu tổng cộng 100 trường hợp dữ liệu từ tất cả các nguồn trong bộ dữ liệu, sau đó đánh giá chất lượng của chúng một cách thủ công dựa trên bốn tiêu chí: (1) Đầu ra có đúng và là câu trả lời có thể chấp nhận được không? (2) Đầu ra có đáp ứng yêu cầu hướng dẫn và cung cấp phản hồi toàn diện và thích hợp cho câu hỏi không? (3) Câu trả lời có đầy đủ và đủ chi tiết không? (4) Câu trả lời có vô hại, tránh thông tin sai lệch hoặc lan truyền nội dung có hại không?

Kết quả đánh giá con người của chúng tôi trong bảng 10 cho thấy chất lượng dữ liệu đã đáp ứng tiêu chuẩn rất cao, với tỷ lệ chấp nhận của con người luôn trên 95% qua bốn tiêu chí. Đối với tiêu chí thứ ba, chúng tôi tiến hành một nghiên cứu trường hợp cho thấy việc từ chối của con người chủ yếu là do các phản hồi không quá chi tiết. Vì các phản hồi của chúng tôi chủ yếu được thu thập từ các tương tác thực sự của con người trên web, chúng tôi tin rằng điều này là có thể chấp nhận được và thậm chí còn tự nhiên.

## 4 THIẾT LẬP THÍ NGHIỆM

Trong phần này, chúng tôi mô tả cách chúng tôi sử dụng COIG-CQIA để tinh chỉnh các mô hình và trình bày chi tiết các phương pháp đánh giá của chúng tôi.

**Các Bài Kiểm tra Đánh giá** Để đánh giá khả năng của mô hình qua các nhiệm vụ tiếng Trung khác nhau, chúng tôi sử dụng Belle-Eval (Ji et al., 2023) làm bộ kiểm tra mở. Nó bao gồm 12 loại hướng dẫn khác nhau trải rộng trên nhiều lĩnh vực khác nhau, làm cho nó trở nên lý tưởng để đánh giá tác động của các nguồn dữ liệu khác nhau đến các nhiệm vụ khác nhau. Chúng tôi cũng sử dụng C-Eval (Huang et al., 2024), CMMLU (Li et al., 2023a), và SafetyBench (Zhang et al., 2023c), là các bài kiểm tra được sử dụng rộng rãi để đánh giá kiến thức, khả năng lý luận, và mức độ an toàn của các mô hình trong bối cảnh tiếng Trung. Để tiếp tục khám phá khả năng mở rộng của COIG-CQIA trong các tình huống không phải tiếng Trung, chúng tôi đánh giá mô hình trên các bộ dữ liệu được sử dụng rộng rãi bao gồm BBH (Suzgun et al., 2022), GSM8K (Cobbe et al., 2021), HumanEval (Chen et al., 2021), và TydiQA (Clark et al., 2020).

**Các Mô hình Cơ sở** Để đánh giá toàn diện khả năng tuân theo hướng dẫn của các mô hình được tinh chỉnh trên COIG-CQIA, chúng tôi so sánh nó với một số bộ dữ liệu tinh chỉnh hướng dẫn tiếng Trung nổi tiếng. Những bộ dữ liệu này bao gồm COIG (Zhang et al., 2023a), Firefly (Yang, 2023), Alpaca-ZH (Cui et al., 2023), COIG-PC (BAAI, 2023), và OL-CC (OL-CC, 2023), được xây dựng bằng các phương pháp khác nhau. Chúng tôi so sánh các tập con có kích thước bằng nhau với COIG-CQIA từ các bộ dữ liệu này. Ngoài ra, chúng tôi chọn các tập con có tổng kích thước bằng COIG-CQIA-Sub từ WizardCoder (Luo et al., 2023) và MAmmoTH (Yue et al., 2023) cho các thí nghiệm pha trộn dữ liệu.

**Chi tiết Triển khai** Chúng tôi tinh chỉnh các mô hình khác nhau với các kiến trúc và kích thước khác nhau bằng COIG-CQIA. Điều này bao gồm các mô hình đa ngôn ngữ tập trung vào tiếng Trung từ dòng Yi (6B và 34B) (Young et al., 2024) và dòng Qwen2 (7B và 72B) (Yang et al., 2024). Chúng tôi gộp 18 nguồn dữ liệu của bộ dữ liệu COIG-CQIA thành 12 nguồn, và thủ công chọn một tập con cân bằng hơn từ các nguồn này, mà chúng tôi gọi là COIG-CQIA-Sub. Thống kê chi tiết có thể tìm thấy trong Phụ lục C. Để khám phá hiệu suất của dữ liệu trên các mô hình không tập trung vào tiếng Trung, chúng tôi cũng chọn dòng LLaMA2 (7B, 13B, và 70B) (Touvron et al., 2023) làm mô hình cơ sở. Chúng tôi đặt tỷ lệ học tập là 2e-5, với kích thước lô là 128 và độ dài chuỗi tối đa là 4096. Việc huấn luyện được thực hiện trong 5 epochs sử dụng bộ lập lịch cosine với 5% warmup. Đối với các mô hình dưới 20B tham số, chúng tôi sử dụng tối ưu hóa DeepSpeed (Rasley et al., 2020) ZeRO stage 2, trong khi đối với các mô hình lớn hơn 20B tham số, chúng tôi sử dụng ZeRO stage 3.

## 5 KẾT QUẢ THÍ NGHIỆM

### 5.1 Phân tích Các Nguồn Dữ liệu Hướng dẫn và Mô hình Cơ sở

Chúng tôi tinh chỉnh các mô hình Qwen2-7B (Yang et al., 2024) và LLaMA2-13B (Touvron et al., 2023) trên các nguồn dữ liệu khác nhau từ COIG-CQIA để phân tích tác động của các nguồn dữ liệu đến khả năng của mô hình qua các lĩnh vực khác nhau. Sau đó, chúng tôi đánh giá hiệu suất của từng mô hình trên các loại nhiệm vụ trợ lý khác nhau bằng cách sử dụng GPT-4o làm công cụ đánh giá LLM-as-Judge trên Belle-Eval (Ji et al., 2023). Chi tiết đánh giá được cung cấp trong Phụ lục D.

Bảng 2 cho thấy hiệu suất của các mô hình Qwen2-7B và LLaMA2-13B được tinh chỉnh trên các tập con khác nhau. Bảng chỉ ra rằng tất cả các mô hình được tinh chỉnh đều đạt được cải thiện đáng kể qua các lĩnh vực khác nhau. Đáng chú ý, mô hình Qwen được huấn luyện trên bộ dữ liệu Ruozhiba hoạt động đặc biệt tốt, thậm chí vượt qua các tập con dữ liệu chất lượng cao như COIG-PC và Zhihu. Bất chấp việc Ruozhiba không được công nhận rộng rãi trong cộng đồng học thuật Trung Quốc và thường chứa nội dung hài hước hoặc vô lý, chúng tôi tin rằng những đặc điểm này đã góp phần vào hiệu quả của nó. Bộ dữ liệu Ruozhiba có cấu trúc logic vốn có, bao gồm các bẫy nhận thức và ngôn ngữ, và có các trò đùa và câu đố, cũng như các kỹ thuật tu từ nghệ thuật và trừu tượng. Những yếu tố này, đổi lại, thách thức khả năng lý luận nhiều bước của mô hình, nâng cao hiểu biết về ngôn ngữ Trung Quốc trong quá trình tinh chỉnh và cải thiện khả năng lý luận logic phức tạp của nó. Human Value đứng thứ hai về trung bình qua tất cả các tập con, điều này phù hợp với kỳ vọng, vì tập con này chứa một lượng lớn dữ liệu chất lượng cao được chú thích bởi con người và phù hợp với các giá trị con người. Dữ liệu này không chỉ cải thiện khả năng tuân theo hướng dẫn trong quá trình tinh chỉnh mà còn ngăn các mô hình thiên vị về các giá trị cụ thể, nâng cao tính phổ quát. Hơn nữa, WikiHow chỉ đạt điểm 30.2 trên Qwen và 18.6 trên LLaMA-2-13B, có thể do thiếu tính đa dạng trong các hướng dẫn "làm thế nào" của nó.

Chúng tôi cũng đánh giá các mô hình cơ sở khác nhau với các kích thước tham số khác nhau được tinh chỉnh trên COIG-CQIA-Sub. Bảng 6 trình bày sự khác biệt về hiệu suất qua các mô hình trong các nhiệm vụ tuân theo hướng dẫn và kiến thức & lý luận. Như mong đợi, kích thước mô hình tương quan với hiệu suất được cải thiện qua tất cả các nhiệm vụ. Dòng Yi và Qwen2 cho thấy kết quả mạnh mẽ, với Qwen2-72B dẫn đầu tổng thể. Dòng LLaMA-2 tụt hậu vì nó không được thiết kế đặc biệt cho việc hiểu ngôn ngữ Trung Quốc. Ngoài ra, chúng tôi đánh giá hiệu suất an toàn của các mô hình được tinh chỉnh khác nhau trên SafetyBench (Zhang et al., 2023c). Kết quả thí nghiệm chi tiết có thể tìm thấy trong Phụ lục E.

### 5.2 So sánh với Các Bộ dữ liệu Tinh chỉnh Hướng dẫn Tiếng Trung Khác

Bảng 3 minh họa cách các mô hình được huấn luyện trên các bộ dữ liệu khác nhau thực hiện các nhiệm vụ tuân theo hướng dẫn khác nhau. COIG-CQIA nổi bật trong các nhiệm vụ Q&A, trích xuất, toán học, và mã hóa, cho thấy sức mạnh của nó trong các lĩnh vực chuyên sâu về kiến thức và lý luận. Tuy nhiên, đối với các nhiệm vụ phân loại, tóm tắt, và viết lại (ví dụ, dịch thuật và chỉnh sửa văn bản), COIG-CQIA có hiệu suất thấp hơn. Nghiên cứu trường hợp của chúng tôi quy cho điều này là do đại diện hạn chế của các nhiệm vụ này trong bộ dữ liệu. Để cải thiện hiệu suất trong các lĩnh vực này, chúng tôi khuyến nghị bổ sung với các bộ dữ liệu như Firefly và Alpaca-Zh.

### 5.3 Khám phá Chiến lược Pha trộn Dữ liệu

#### 5.3.1 Pha trộn các Lĩnh vực Khác nhau

Chúng tôi phân loại COIG-CQIA thành bốn nguồn chính như đã mô tả trước đó: bộ dữ liệu NLP, Kỳ thi, Kiến thức Thế giới, và Truyền thông Xã hội & Diễn đàn. Chúng tôi đánh giá các kết hợp khác nhau của các nguồn này qua các nhiệm vụ, như được hiển thị trong Bảng 4. Kết quả của chúng tôi cho thấy dữ liệu từ các nguồn Xã hội & Diễn đàn và Kỳ thi đóng góp đáng kể nhất trong việc nâng cao khả năng tuân theo hướng dẫn của mô hình. Dữ liệu Kiến thức Thế giới và Xã hội & Diễn đàn, trong khi đó, đóng góp vào việc cải thiện hiệu suất kiến thức, phù hợp với kỳ vọng: dữ liệu Xã hội & Diễn đàn và Kỳ thi bao gồm các nhiệm vụ rộng hơn, phức tạp hơn, trong khi dữ liệu NLP và Kiến thức Thế giới có xu hướng tập trung vào các nhiệm vụ truyền thống, bị giới hạn hơn. Kiến thức Thế giới tự nhiên xuất sắc trong các nhiệm vụ chuyên sâu về kiến thức như C-Eval và CMMLU.

Khi pha trộn các nguồn dữ liệu, chúng tôi quan sát thấy rằng các kết hợp của hai lĩnh vực hiếm khi vượt qua nguồn cá nhân mạnh hơn. Pha trộn các nguồn yếu hơn, như NLP và Wiki, có thể dẫn đến suy thoái thêm, đặc biệt là trong các nhiệm vụ tuân theo hướng dẫn. Tuy nhiên, kết hợp hai nguồn mạnh có xu hướng duy trì hiệu suất cao, chẳng hạn như pha trộn dữ liệu Kỳ thi và Xã hội & Diễn đàn cho việc tuân theo hướng dẫn, hoặc Wiki với Xã hội & Diễn đàn cho các nhiệm vụ kiến thức và lý luận.

#### 5.3.2 Pha trộn với dữ liệu Mã nguồn Mở

Để khám phá tiềm năng của COIG-CQIA trên các nhiệm vụ không phải tiếng Trung, chúng tôi mở rộng đánh giá của mình bằng cách sử dụng bộ công cụ open-instruct (Wang et al., 2023a) để bao gồm bốn nhiệm vụ không phải tiếng Trung bổ sung: BBH (lý luận), GSM8K (toán học), HumanEval (mã), và TydiQA (đa ngôn ngữ). Kết quả được hiển thị trong bảng 5.

Các mô hình được huấn luyện trên COIG-CQIA hoạt động ngang bằng với các mô hình cơ sở và chat chính thức trên BBH và vượt trội đáng kể so với các mô hình cơ sở trên TydiQA, làm nổi bật sức mạnh của nó trong việc kích hoạt khả năng đa ngôn ngữ. Cho rằng COIG-CQIA là một bộ dữ liệu tập trung vào tiếng Trung với ít hơn 5% dữ liệu toán học và mã, nó có thể hiểu được khi có hiệu suất thấp hơn trên các nhiệm vụ nặng về tiếng Anh như GSM8K và HumanEval, đặc biệt là khi sử dụng Yi-6B làm mô hình cơ sở. Việc sử dụng dữ liệu thuần tiếng Trung ảnh hưởng đến hiệu suất trong các nhiệm vụ này. Ngược lại, các thí nghiệm với Qwen2-7B và Llama2-7B cho thấy COIG-CQIA hoạt động ở mức hoặc trên mức của các mô hình cơ sở, mặc dù vẫn tụt hậu so với các mô hình chat được thiết kế dữ liệu kỹ thuật hơn. Khoảng cách này là dự kiến, vì các mô hình chat chính thức này trải qua quá trình thiết kế dữ liệu mở rộng, tốn kém.

Để giải quyết vấn đề không khớp ngôn ngữ, chúng tôi thử nghiệm với việc pha trộn COIG-CQIA với các bộ dữ liệu tiếng Anh mã nguồn mở. Chúng tôi lấy mẫu dữ liệu tương đương từ Magicoder (mã) và Mammoth (toán), được gắn nhãn là OS Mix, và kết hợp nó với CQIA. Những phát hiện của chúng tôi cho thấy: (1) COIG-CQIA khớp hoặc vượt qua OS Mix trong các nhiệm vụ lý luận và hoạt động tốt hơn đáng kể trong các nhiệm vụ đa ngôn ngữ. (2) Trong các nhiệm vụ mã và toán, hiệu suất của COIG-CQIA thay đổi theo mô hình cơ sở. Với Yi-6B và Llama2-7B, COIG-CQIA tụt hậu so với OS Mix, được chuyên biệt hóa cho các nhiệm vụ này. Đáng ngạc nhiên, khi sử dụng Qwen2-7B làm cơ sở, COIG-CQIA vượt trội hơn OS Mix trong cùng các nhiệm vụ. (3) Kết hợp COIG-CQIA với OS Mix tăng cường điểm yếu của từng bộ dữ liệu, dẫn đến cải thiện hiệu suất tổng thể.

### 5.4 Đánh giá Con người

Chúng tôi so sánh Yi-6B (Young et al., 2024) được tinh chỉnh trên COIG-CQIA-Sub với một số mô hình chat mã nguồn mở tiếng Trung. Tập trung vào các câu hỏi thực tế, chúng tôi lấy mẫu 200 lời nhắc từ OL-CC và Zhihu, không có lời nhắc nào trong số đó là một phần của bộ huấn luyện. Chúng tôi thực hiện so sánh từng cặp để đánh giá cách mô hình của chúng tôi hoạt động trong các tình huống thực tế. Hình 2 trình bày kết quả đánh giá con người so sánh COIG-CQIA với năm mô hình cơ sở: Yi-6B-Chat (Young et al., 2024), Baichuan2-7B-Chat (Baichuan, 2023), ChatGLM2-6B (GLM et al., 2024), Qwen-7B-Chat (Bai et al., 2023), và InternLM-7B-Chat (Cai et al., 2024). Kết quả cho thấy mô hình được huấn luyện trên COIG-CQIA đạt được sự ưa thích cao hơn của con người, với hơn 60% phản hồi được đánh giá là tốt hơn hoặc ngang bằng với các mô hình cơ sở. Điều này chứng minh khả năng của COIG-CQIA để phù hợp chặt chẽ hơn với các mô hình giao tiếp thực tế của con người, dẫn đến sự ưa thích cao hơn của người dùng. Xem chi tiết trong Phụ lục D.

### 5.5 Mở rộng Dữ liệu

Kết quả mở rộng dữ liệu trong Hình 3 chứng minh tác động của kích thước bộ huấn luyện đến hiệu suất mô hình cho Yi-6B và LLaMA-2-7B. Cả hai mô hình đều thể hiện cải thiện hiệu suất khi số lượng trường hợp tăng lên, nhấn mạnh tầm quan trọng của số lượng dữ liệu trong việc nâng cao khả năng của mô hình ngôn ngữ. Yi-6B cho thấy cải thiện nhanh chóng đến 24k trường hợp, sau đó hiệu suất ổn định với các dao động nhỏ. Hiệu ứng cao nguyên này có thể được quy cho các hạn chế của quy mô bộ dữ liệu của chúng tôi, nơi hành vi mô hình trở nên ít dự đoán được hơn ở quy mô dữ liệu này. Ngược lại, LLaMA-2 7B hiển thị xu hướng tăng ổn định qua toàn bộ phạm vi.

## 6 Công trình Liên quan

### 6.1 Bộ dữ liệu Tinh chỉnh Hướng dẫn

Tinh chỉnh hướng dẫn nâng cao khả năng đối thoại và thực thi nhiệm vụ của các mô hình ngôn ngữ lớn (LLMs) bằng cách huấn luyện chúng tạo ra các phản hồi phù hợp với hướng dẫn đầu vào. Phương pháp này tạo ra các mô hình có thể kiểm soát và dự đoán được hơn, phù hợp hơn với ý định của con người. Một số chiến lược đã được sử dụng để xây dựng các bộ dữ liệu tinh chỉnh hướng dẫn: (1) Chú thích thủ công bởi các chuyên gia con người (Conover et al., 2023). (2) Tái sử dụng các bộ dữ liệu NLP hiện có (Mishra et al., 2022; Sanh et al., 2022; Chung et al., 2022). (3) Tổng hợp bằng cách sử dụng LLMs (Honovich et al., 2022; Wang et al., 2023b; Xu et al., 2023a; Ji et al., 2023; Xu et al., 2023b). Mặc dù hiệu quả, phương pháp này có thể gây ra sự không nhất quán và nhiễu. Trong khi có nhiều bộ dữ liệu tinh chỉnh hướng dẫn tiếng Anh, các đối tác tiếng Trung của chúng bị hạn chế. Một số nỗ lực tập trung vào việc dịch các bộ dữ liệu tiếng Anh (Peng et al., 2023), trong khi những nỗ lực khác tái sử dụng các nhiệm vụ NLP hiện có thành các định dạng hướng dẫn (BAAI, 2023; Yang, 2023). Các bộ dữ liệu tiếng Trung đáng chú ý bao gồm HC3 (Guo et al., 2023), COIG (Zhang et al., 2023a), BELLE (Ji et al., 2023), và MOSS (Sun et al., 2023).

### 6.2 Chiến lược Pha trộn Dữ liệu cho SFT

Nghiên cứu gần đây nhấn mạnh tầm quan trọng của chất lượng dữ liệu trong tinh chỉnh hướng dẫn. LIMA (Zhou et al., 2023) chứng minh hiệu suất mạnh mẽ chỉ sử dụng 1.000 cặp hướng dẫn-đầu ra chất lượng cao. AlpaGasus (Chen et al., 2023) và Humpback (Li et al., 2023b) sử dụng các kỹ thuật lọc tiên tiến để nâng cao chất lượng bộ dữ liệu và hiệu quả huấn luyện. Các nghiên cứu cũng khám phá tác động của việc pha trộn các bộ dữ liệu tinh chỉnh hướng dẫn khác nhau. Song et al. (2023) điều tra các phương pháp kết hợp khác nhau, trong khi dòng Tulu (Konchakov et al., 2023; Ivison et al., 2023) chứng minh rằng việc tăng tính đa dạng hướng dẫn có thể cải thiện hiệu suất tổng thể. Đáng chú ý, không có bộ dữ liệu hoặc kết hợp đơn lẻ nào luôn luôn vượt trội hơn các bộ dữ liệu khác qua tất cả các chỉ số, làm nổi bật sự phức tạp của việc tối ưu hóa các hỗn hợp dữ liệu tinh chỉnh hướng dẫn.

## 7 Kết luận

Bài báo này trình bày COIG-CQIA, một bộ dữ liệu tinh chỉnh hướng dẫn tiếng Trung chất lượng cao. Bộ dữ liệu được biên soạn từ các trang web khác nhau trên internet Trung Quốc, sau đó được làm sạch, tái cấu trúc và đánh giá thủ công một cách tỉ mỉ để đảm bảo chất lượng, tính đa dạng và sự liên quan. Nó nhằm mục đích cung cấp cho cộng đồng NLP Trung Quốc dữ liệu tinh chỉnh được chế tạo cẩn thận phù hợp với tương tác con người.

## 8 Hạn chế

Chúng tôi thừa nhận một số hạn chế trong nghiên cứu của mình. Mặc dù COIG-CQIA toàn diện, việc bao gồm các yếu tố chủ quan có thể dẫn đến các diễn giải khác nhau, có thể ảnh hưởng đến việc xây dựng dữ liệu. Ngoài ra, việc tập trung vào dữ liệu ngôn ngữ Trung Quốc chỉ bao gồm một phần của kiến thức con người. Các chỉ số đánh giá có thể không nắm bắt đầy đủ khả năng hiểu và lý luận tinh vi của các mô hình. Những hạn chế này nhấn mạnh nhu cầu tiếp tục cải tiến và mở rộng bộ dữ liệu của chúng tôi. Trong công việc tương lai, chúng tôi mong muốn thu thập và tổng hợp dữ liệu tinh chỉnh hướng dẫn tiếng Trung đa dạng hơn để cải thiện khả năng và độ tin cậy của các mô hình.

## 9 Tuyên bố Đạo đức

Trong việc phát triển COIG-CQIA, chúng tôi tuân thủ nghiêm ngặt các hướng dẫn đạo đức và quy định pháp lý, đảm bảo công bằng, minh bạch, tính bao gồm và tôn trọng tất cả các bên liên quan. Chúng tôi nhấn mạnh tầm quan trọng của việc bảo vệ quyền riêng tư và quyền sở hữu trí tuệ, nhấn mạnh cam kết của chúng tôi đối với quản lý dữ liệu có trách nhiệm và hợp pháp. Chúng tôi đã thực hiện các bước để ẩn danh bất kỳ dữ liệu cá nhân nào để bảo vệ quyền riêng tư và đã nỗ lực hết sức để giảm thiểu nội dung có hại hoặc thiên vị. Tuy nhiên, chúng tôi nhận ra rằng các thiên vị có thể phát sinh một cách vô ý và một số thông tin có thể gây xúc phạm. Chúng tôi cam kết giám sát và cải thiện liên tục để giảm thiểu các thiên vị như vậy. Hơn nữa, chúng tôi khuyến khích người dùng bộ dữ liệu của chúng tôi sử dụng nó một cách có trách nhiệm và xem xét các tác động đạo đức của công việc của họ, đặc biệt là trong các ứng dụng có thể ảnh hưởng đến cá nhân hoặc cộng đồng.

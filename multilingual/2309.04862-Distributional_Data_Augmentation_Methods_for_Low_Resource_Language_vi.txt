# 2309.04862.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/multilingual/2309.04862.pdf
# Kích thước tệp: 1001851 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Các Phương Pháp Tăng Cường Dữ Liệu Phân Phối cho Ngôn Ngữ Ít Tài Nguyên
Mosleh Mahamud, Zed Lee, Isak Samsten
Khoa Khoa học Máy tính và Hệ thống
Borgarfjordsgatan 12, Kista, Thụy Điển
{mosleh.mahamud,zed.lee,samsten }@dsv.su.se
Tóm tắt
Tăng cường văn bản là một kỹ thuật để xây dựng dữ liệu tổng hợp từ một kho ngữ liệu thiếu tài nguyên nhằm cải thiện hiệu suất dự đoán. Việc tạo ra dữ liệu tổng hợp rất phổ biến trong nhiều lĩnh vực. Tuy nhiên, gần đây tăng cường văn bản đã nổi lên trong xử lý ngôn ngữ tự nhiên (NLP) để cải thiện các nhiệm vụ downstream. Một trong những kỹ thuật tăng cường văn bản tiên tiến hiện tại là easy data augmentation (EDA), tăng cường dữ liệu huấn luyện bằng cách chèn và thay thế từ đồng nghĩa và hoán vị câu một cách ngẫu nhiên. Một trở ngại lớn của EDA là nhu cầu về từ điển từ đồng nghĩa đa dạng và đầy đủ, điều này không thể dễ dàng tìm thấy trong các ngôn ngữ ít tài nguyên. Để cải thiện tính hữu ích của EDA, chúng tôi đề xuất hai phần mở rộng, easy distributional data augmentation (EDDA) và type specific similar word replacement (TSSR), sử dụng thông tin ngữ cảnh từ vựng ngữ nghĩa và thẻ từ loại cho việc thay thế và tăng cường từ. Trong một đánh giá thực nghiệm toàn diện, chúng tôi cho thấy tính hữu ích của các phương pháp đề xuất, được đo bằng điểm F1, trên hai tập dữ liệu đại diện bằng tiếng Thụy Điển như một ví dụ về ngôn ngữ ít tài nguyên. Với các phương pháp đề xuất, chúng tôi chỉ ra rằng dữ liệu tăng cường cải thiện hiệu suất phân loại trong các thiết lập ít tài nguyên.

Giới thiệu
Tăng cường là một kỹ thuật để xây dựng dữ liệu huấn luyện tổng hợp từ các tập dữ liệu có sẵn. Các kỹ thuật tăng cường khác nhau đã được sử dụng chủ yếu trong lĩnh vực thị giác máy tính để cải thiện các mô hình học máy (Shorten, Khoshgoftaar, và Furht 2021), đặc biệt là với các mô hình học sâu lớn trong lĩnh vực này. Tuy nhiên, tăng cường văn bản đã phát triển gần đây, cũng được điều chỉnh với các mô hình lớn đã xuất hiện ngày nay (Bayer, Kaufhold, và Reuter 2021). Hai lý do cốt lõi để sử dụng tăng cường văn bản như sau: 1) một số ngôn ngữ nằm trong các lĩnh vực ít tài nguyên, do đó rất khó để có đủ dữ liệu để huấn luyện mô hình. 2) tăng cường có thể hữu ích để tăng cường ranh giới quyết định, dẫn đến các bộ phân loại mạnh mẽ hơn hoặc ước tính độ không chắc chắn tốt hơn để mô hình có thể quen thuộc hơn với không gian cục bộ xung quanh các ví dụ (Bayer, Kaufhold, và Reuter 2021). Không giống như hình ảnh, ngôn ngữ không thể được tổng quát hóa hoặc hợp nhất, có nghĩa là mỗi ngôn ngữ chỉ có các tài nguyên riêng của nó, trong khi hình ảnh có thể dễ dàng được hợp nhất bất kể chủ đề và loại. Theo nghĩa này, các kỹ thuật tăng cường văn bản có thể mang lại lợi ích cho các ngôn ngữ ít tài nguyên như tiếng Thụy Điển, Kazakh, Tamil, Welsh, Serbia Thượng và nhiều ngôn ngữ khác (Şahin 2022).

Đã có một vài kỹ thuật tăng cường văn bản, từ kỹ thuật đơn giản nhất (Ebrahimi và cộng sự 2017; Kolomiyets, Bethard, và Moens 2011), đến những kỹ thuật phức tạp sử dụng các mô hình học sâu riêng biệt (Wu và cộng sự 2019; Croce, Castellucci, và Basili 2020; Malandrakis và cộng sự 2019). Một trong những cách dễ nhất để áp dụng tăng cường văn bản là với một kỹ thuật gọi là easy data augmentation (EDA). EDA có bốn kỹ thuật chính để tăng cường một câu (Wei và Zou 2019) như sau: thay thế từ đồng nghĩa (SR), chèn ngẫu nhiên (RI), hoán đổi ngẫu nhiên (RS), và xóa ngẫu nhiên (RD). Mặc dù EDA có thể được coi là một kỹ thuật tăng cường văn bản phổ quát có thể áp dụng cho bất kỳ ngôn ngữ nào. Tuy nhiên, điều này có thể không phải lúc nào cũng đúng, vì nó không thật sự phổ quát theo nghĩa không thể áp dụng cho các ngôn ngữ khác nhau vì vẫn phụ thuộc vào các mô-đun phụ thuộc ngôn ngữ khác như wordnet. Việc điều chỉnh EDA cho các ngôn ngữ ít tài nguyên thậm chí có thể khó khăn hơn vì một số phụ thuộc ngôn ngữ không thể dễ dàng giải quyết. Do đó, bài báo này nhằm cung cấp một khung cho việc tăng cường EDA được sửa đổi cũng có thể dễ dàng áp dụng cho các ngôn ngữ ít tài nguyên. Chúng tôi trình bày khung của chúng tôi cho tiếng Thụy Điển như một ví dụ về ngôn ngữ ít tài nguyên.

Mặc dù tiếng Thụy Điển được phân loại vào nhóm ít tài nguyên, đã có một vài thử nghiệm tăng cường văn bản cho ngôn ngữ này. Một trong những công trình tăng cường văn bản sớm nhất đã được thực hiện trên dữ liệu văn bản lâm sàng tiếng Thụy Điển bằng cách hợp nhất các nguồn văn bản khác nhau cho các nhiệm vụ nhận dạng thực thể có tên (NER) sử dụng các mô hình sâu khác nhau (Berg và Dalianis 2019). Tuy nhiên, bài báo này có hạn chế là chỉ thử nghiệm trên một tập dữ liệu lâm sàng Thụy Điển và các kỹ thuật tăng cường được sử dụng trong bài báo là dành riêng cho lĩnh vực, do đó không thể áp dụng cho mọi văn bản tiếng Thụy Điển. Hơn nữa, một nhóm nhà nghiên cứu đã thử nghiệm nhiễu loạn văn bản được kiểm soát bằng cách sử dụng ba phương pháp nhiễu loạn chính: dịch chuyển n-gram, dịch chuyển mệnh đề và dịch chuyển ngẫu nhiên trên văn bản tiếng Thụy Điển (Taktasheva, Mikhailov, và Artemova 2021). Tuy nhiên, bài báo này chỉ tập trung vào việc đánh giá các mô hình sâu như BERT và BART (Devlin và cộng sự 2019; Lewis và cộng sự 2020) và điều tra các lớp attention cho mỗi token để quan sát hành vi của chúng mà không thảo luận về tác động của việc tăng cường lên hiệu suất của các mô hình. Họ cũng không tiết lộ cách thức thực hiện các kỹ thuật tăng cường, cản trở khả năng tái tạo kỹ thuật này.

Theo hiểu biết tốt nhất của chúng tôi, không có công trình nào trước đây đã áp dụng EDA với sự điều chỉnh neural cho văn bản tiếng Thụy Điển. Về cơ chế hoạt động bên trong của EDA, nó phụ thuộc nhiều vào việc thay thế từ đồng nghĩa wordnet. Như đã đề cập trước đây, có thể không phải lúc nào cũng có từ điển toàn diện trong mọi ngôn ngữ, đặc biệt là trong các ngôn ngữ ít tài nguyên. Do đó, chúng tôi thay thế wordnet bằng mô hình word2vec (Mikolov và cộng sự 2013; Borin, Forsberg, và Lönngren 2013a) để tích hợp trong khung tăng cường này, trở thành một phương pháp dựa trên dữ liệu để tăng cường dữ liệu, mà chúng tôi gọi là EasyDistributional Data Augmentation (EDDA). Chúng tôi kỳ vọng rằng phương pháp này có thể giúp đỡ rất nhiều cho các ngôn ngữ ít tài nguyên không có dữ liệu từ điển chất lượng tốt, như wordnet, sử dụng các kỹ thuật EDA với một thành phần có thể huấn luyện được.

Hơn nữa, chúng tôi cũng giới thiệu cách thông tin cú pháp của các từ cũng có thể được sử dụng để tăng cường dữ liệu, mà chúng tôi gọi là Type Specific Similar word Replacement (TSSR). Điều này là do tính ngẫu nhiên trong EDDA có thể ảnh hưởng đến cảm xúc câu (Qiu và cộng sự 2020; Bayer, Kaufhold, và Reuter 2021; Anaby-Tavor và cộng sự 2020) bằng cách tạo ra các câu tổng hợp không tương tự về cảm xúc; do đó, đây là một phương pháp có hướng để bổ sung cho EDDA.

Đóng góp. Các đóng góp chính của bài báo này có thể được tóm tắt như sau:
• Chúng tôi điều chỉnh các kỹ thuật tăng cường kiểu EDA cho các ngôn ngữ ít tài nguyên bằng cách sử dụng thay thế từ đồng nghĩa phân phối không đòi hỏi phụ thuộc mạnh vào ngôn ngữ cụ thể. Chúng tôi minh họa tính hữu ích của nó trong văn bản tiếng Thụy Điển.
• Chúng tôi giới thiệu và đánh giá một phương pháp tăng cường mới sử dụng thông tin POS, mà chúng tôi gọi là TSSR, như một mô-đun bổ sung cho khung EDDA của chúng tôi và cho thấy rằng phương pháp này có thể cải thiện đáng kể hiệu suất dự đoán.
• Chúng tôi cho thấy rằng bằng cách sử dụng các kỹ thuật tăng cường được đề xuất, chúng tôi tăng điểm F1 chỉ sử dụng 40%-50% dữ liệu huấn luyện so với hiệu suất baseline không có tăng cường.
• Chúng tôi cung cấp mã của chúng tôi trong kho GitHub để tái tạo.

Công trình liên quan
Trong số vô số các kỹ thuật nhiễu loạn văn bản, tăng cường văn bản được chia thành hai danh mục chính: kỹ thuật tăng cường symbolic và neural (Shorten, Khoshgoftaar, và Furht 2021). Loại đầu tiên bao gồm một loạt các kỹ thuật, như tăng cường dựa trên quy tắc, tăng cường không gian đặc trưng, và tăng cường có cấu trúc đồ thị, trong khi loại thứ hai dựa trên các kỹ thuật khác nhau của mạng nơ-ron sâu, như back-translation, tăng cường phong cách, và tăng cường dữ liệu sinh tạo. Tăng cường symbolic thú vị hơn vì nó có thể được kiểm soát và diễn giải hơn so với đối tác của nó. Tuy nhiên, rất ít nghiên cứu đã được thực hiện trong đó các kỹ thuật tăng cường symbolic và neural được kết hợp để tăng cường câu, điều mà bài báo này khám phá.

Vì tăng cường văn bản là một lĩnh vực tương đối mới, đã không có nhiều thử nghiệm trong lĩnh vực tiếng Thụy Điển. Theo hiểu biết của chúng tôi, những nỗ lực sớm nhất với tăng cường trong tiếng Thụy Điển là với khai thác văn bản lâm sàng tiếng Thụy Điển, nơi họ hợp nhất các nguồn văn bản khác nhau cho NER (Berg và Dalianis 2019). Ngoài ra, không có kỹ thuật tăng cường phổ biến nào như EDA đã được áp dụng cho bộ dữ liệu benchmarking SuperLim (Adesam, Berdicevskis, và Morger 2020), mà chúng tôi trình bày trong bài báo này.

Tiếng Thụy Điển được biết đến là một ngôn ngữ ít tài nguyên (Şahin 2022). Do đó, có nhu cầu về các tài nguyên có sẵn như EDA hoặc các công cụ tăng cường khác có thể cải thiện các nhiệm vụ downstream NLP khác nhau. Một bài báo thảo luận về việc pre-training cho mô hình ASR trong các lĩnh vực ít tài nguyên nơi họ đã thử nghiệm các kỹ thuật tăng cường khác nhau (Stoian, Bansal, và Goldwater 2019). Tuy nhiên, nó tập trung vào tăng cường cho dữ liệu giọng nói và không phổ quát hoặc áp dụng được cho các mô hình văn bản thuần túy.

Một trong những nỗ lực đầu tiên của EDA trong tiếng Thụy Điển có thể được tìm thấy trong bài toán phát hiện tin tức không đáng tin cậy (Muñoz Sánchez và cộng sự 2022). Bài báo này đề cập đến một bài toán phân loại nơi ba kỹ thuật tăng cường chính đã được áp dụng để tăng cường hiệu suất của mô hình, như (1) lấy mẫu con dữ liệu, (2) EDA, và (3) back translation. Cả back translation và EDA cũng được kết hợp để đạt được hiệu suất phân loại tốt. Họ huấn luyện với mô hình bag of words, Bi-LSTM, và BERT trong các thử nghiệm của họ. Bài báo chỉ ra rằng EDA hoạt động tốt nhất với các mô hình học máy đơn giản. Tuy nhiên, đây là nơi bài báo này và công trình của chúng tôi khác nhau, vì (1) chúng tôi sử dụng EDA được điều chỉnh neural có thể dễ dàng thích ứng với bất kỳ ngôn ngữ nào. (2) chúng tôi tập trung vào việc kiểm tra các phương pháp của chúng tôi trên hai tập dữ liệu benchmarking. Bài báo của chúng tôi lấy cảm hứng từ EDA và kết hợp nó với word2vec biến nó thành một phương pháp dựa trên dữ liệu để nhiễu loạn văn bản.

Các nỗ lực tăng cường tương tự đã được thực hiện trên tập dữ liệu DALAJ (Volodina, Mohammed, và Klezl 2021) với các nhiễu loạn được kiểm soát sử dụng ba phương pháp nhiễu loạn chính: dịch chuyển N-gram, dịch chuyển mệnh đề, và dịch chuyển ngẫu nhiên. Dịch chuyển N-gram là về việc sử dụng danh từ ghép và giới từ để nhiễu loạn dữ liệu. Trong khi dịch chuyển mệnh đề là xoay cây cú pháp để nhiễu loạn dữ liệu, dịch chuyển ngẫu nhiên giống hệt với hoán đổi ngẫu nhiên trong EDA (Taktasheva, Mikhailov, và Artemova 2021). Tuy nhiên, bài báo đó tập trung vào việc đánh giá các lớp attention BERT và BART (Lewis và cộng sự 2020) cho mỗi token để quan sát hành vi của chúng nhưng không thảo luận về tác động hiệu suất của chúng riêng lẻ, cũng như không tiết lộ cách thực hiện các kỹ thuật tăng cường.

Có một vài bài báo nghiên cứu thảo luận về các nhiễu loạn được kiểm soát (Bayer, Kaufhold, và Reuter 2021) nơi các token đại từ như "he" và "she" được sử dụng để bỏ thiên vị một mô hình NLP (Zhao và cộng sự 2018). Đây là một loại kỹ thuật tăng cường bảo toàn ngữ cảnh. Điều này đã được thực hiện nhiều lần trong tiếng Anh nhưng chưa được thử nghiệm trong tiếng Thụy Điển theo hiểu biết tốt nhất của chúng tôi. Hơn nữa, bài báo của chúng tôi sử dụng một phương pháp dựa trên dữ liệu để tăng cường câu một cách được kiểm soát nơi bất kỳ token thẻ POS nào cũng có thể được chỉ định.

--- TRANG 2 ---

Phương pháp đề xuất
Phát biểu bài toán
Xem xét một thiết lập ít tài nguyên, ví dụ như tiếng Thụy Điển, nơi chúng ta chỉ có dữ liệu hạn chế. Tập dữ liệu có sẵn có lượng dữ liệu được gán nhãn thấp, và do đó các công cụ tăng cường khác nhau được sử dụng để mở rộng dữ liệu huấn luyện hiện có để thực hiện phân loại tốt hơn. Tuy nhiên, một ràng buộc bổ sung là không có từ điển từ đồng nghĩa nào có sẵn. Bài toán chúng tôi cần giải quyết là (1) tìm cách điều chỉnh tăng cường kiểu EDA cho các lĩnh vực ít tài nguyên, (2) đo lường EDDA hoạt động tốt như thế nào trên các tập dữ liệu tiếng Thụy Điển, (3) kiểm tra việc thay thế từ tương tự cụ thể theo loại (TSSR) ảnh hưởng đến phân loại như thế nào.

Easy Distributional Data Augmentation (EDDA)
[Hình 1: Tổng quan về khung EDDA]

Chúng tôi giới thiệu EDDA, một kỹ thuật mới để hỗ trợ tăng cường văn bản trong các ngôn ngữ ít tài nguyên (Hình 1). EDDA lấy cảm hứng từ EDA, là sự kết hợp của nhiều phương pháp tăng cường khác nhau (Wei và Zou 2019). Trong bài báo này, chúng tôi điều chỉnh các chiến lược sau từ EDA cho việc tăng cường dữ liệu ít tài nguyên:

1. Thay thế từ đồng nghĩa ngẫu nhiên (RSR): Chúng tôi chọn ngẫu nhiên một phần nhỏ, được người dùng định nghĩa của các từ từ câu, loại trừ các từ dừng. Một từ đồng nghĩa được chọn ngẫu nhiên thay thế mỗi ứng viên thay thế.

2. Chèn ngẫu nhiên (RI): Chúng tôi chọn ngẫu nhiên một phần nhỏ, được người dùng định nghĩa của các vị trí trong câu và chèn một từ đồng nghĩa ngẫu nhiên của một từ ngẫu nhiên trong câu.

3. Hoán đổi ngẫu nhiên (RS): Chúng tôi chọn ngẫu nhiên một phần nhỏ, được người dùng định nghĩa của các từ và hoán đổi vị trí của chúng.

4. Xóa ngẫu nhiên (RD): Chúng tôi xóa ngẫu nhiên một phần nhỏ, được người dùng định nghĩa của các từ.

Về embeddings, tên distributional trong EDDA xuất phát từ ngữ nghĩa phân phối là việc nắm bắt các biểu thức ngôn ngữ như các vector nắm bắt các mẫu đồng xuất hiện trong các kho ngữ liệu lớn (Turney và Pantel 2010; Erk và Padó 2008). Khung này tận dụng lý thuyết này để tăng cường các câu khác nhau sử dụng một mô hình ngôn ngữ như word2vec.

Việc thay thế từ đồng nghĩa được thực hiện, thay vì sử dụng bảng tra cứu, bằng cách sử dụng mô hình word2vec sử dụng không gian tiềm ẩn của nó để tìm các từ thay thế tương tự nhất. Với trực giác rằng không có từ điển từ đồng nghĩa công cộng hoạt động cho tiếng Thụy Điển, một mô hình word2vec tiếng Thụy Điển (Mikolov và cộng sự 2013; Borin, Forsberg, và Lönngren 2013a) được sử dụng để tạo ra các ứng viên từ với phân phối từ tương tự trong một không gian embedding. Vì nó không phải là một từ điển có danh sách từ đồng nghĩa thuần túy cho một từ, word2vec có thể không phải lúc nào cũng tìm thấy từ đồng nghĩa, nhưng các từ tương tự có thể xuất hiện trong cùng ngữ cảnh. Do đó, EDDA là một hệ thống lai giữa hệ thống dựa trên quy tắc như EDA và hệ thống dựa trên neural.

Mặc dù có nhiều embeddings phân phối có thể được sử dụng, chúng tôi sử dụng word2vec thay vì ví dụ BERT, vì chúng tôi sử dụng một token cụ thể để tìm các từ tương tự trong không gian embedding mà mô hình hóa ngôn ngữ có mặt nạ của BERT sẽ không cho phép. Mặc dù điều này có thể dẫn đến tính ngẫu nhiên nhiều hơn và có thể phá vỡ ý nghĩa ngữ nghĩa của một câu, nó cho phép chúng tôi hỗ trợ các lĩnh vực ít tài nguyên. Hơn nữa, một lợi thế khác của việc sử dụng word2vec là nó vẫn duy trì sự mạch lạc về hình thái của các từ được đề xuất so với chỉ sử dụng từ điển từ đồng nghĩa, như SALDO (Borin, Forsberg, và Lönngren 2013b), vì chúng chỉ ở dạng cơ bản. Ngoài ra, mô hình word2vec thường nhỏ hơn mô hình BERT, có thể giúp tăng tốc độ suy luận. Phần còn lại của khung EDA được sử dụng nguyên văn. Một lợi ích khác của việc sử dụng các mô hình ngữ nghĩa phân phối để tạo ra các ứng viên thay thế từ là các từ đồng nghĩa không nghiêm ngặt (ví dụ, tên hoặc địa danh) có thể được tạo ra.

Mặc dù word2vec là một thuật toán nổi tiếng mà nhiều ngôn ngữ có các mô hình được huấn luyện trước và thậm chí trong các trường hợp thiếu mô hình được huấn luyện trước, việc huấn luyện một mô hình như vậy là dễ dàng vì nó không đòi hỏi bất kỳ dữ liệu được gán nhãn nào. Hơn nữa, các mô hình ngôn ngữ quy mô lớn như BERT có thể đòi hỏi tài nguyên tính toán nặng (Yao và cộng sự 2022) để huấn luyện, trong khi word2vec thì không, làm cho nó hiệu quả về tài nguyên. Chúng tôi khẳng định rằng sự điều chỉnh này có thể mang lại lợi ích lớn cho các thiết lập ngôn ngữ thiếu từ điển từ đồng nghĩa tốt.

Type Specific Similar word Replacement (TSSR)
[Hình 2: Một ví dụ về TSSR thay thế một từ danh từ]

Khi làm việc với dữ liệu nhạy cảm về ngữ cảnh, đặc biệt là với cảm xúc, việc thay thế từ đồng nghĩa ngẫu nhiên có thể làm gián đoạn ý nghĩa ngữ nghĩa của một câu vì kỹ thuật EDA hiện tại không hạn chế việc thay thế từ bằng từ đồng nghĩa từ các loại khác nhau vì nó chỉ nhìn vào danh sách từ đồng nghĩa trong từ điển. Do đó, chúng tôi đề xuất ràng buộc việc thay thế từ đồng nghĩa của EDDA bằng cách chỉ thay thế các từ bằng từ đồng nghĩa có cùng thẻ POS, ví dụ, thay thế động từ chỉ bằng từ đồng nghĩa động từ. Hình 2 cho thấy một ví dụ trong đó một token danh từ được chọn để thay thế và trong số hai từ danh từ 'Larsson' được chọn và được thay thế bằng 'Eriksson'.

Theo hiểu biết tốt nhất của chúng tôi, không có công trình nào trước đây đã thử nghiệm phương pháp này trong đó việc thay thế từ sử dụng mô hình ngôn ngữ (ví dụ, word2vec) với nhiễu loạn cụ thể theo thẻ POS đã được thực hiện, đặc biệt trong các lĩnh vực ít tài nguyên. Điều này cho phép tăng cường cụ thể theo lĩnh vực có thể kiểm soát được và bảo toàn nhãn kết hợp với EDDA.

[Thuật toán 1: Mã giả TSSR]

Toàn bộ quy trình của TSSR được mô tả trong Hình 3 và Thuật toán 1. Trước tiên, chúng tôi lặp lại quy trình n lần để tạo ra n câu mới cho mỗi câu trong đó n là một tham số (Thuật toán 1, dòng 1-2). Một token ngẫu nhiên được chọn từ văn bản đầu vào t sử dụng loại token ưa thích s làm đầu vào. Một token POS ngẫu nhiên được chọn nếu không có loại token nào được nhập (dòng 3). Sau token được chọn, một token ứng viên mới được tạo ra sử dụng word embeddings (dòng 4) để thay thế văn bản gốc (dòng 5). Cuối cùng, các câu mới được trả về sau khi các câu được thay đổi mới đã được thêm vào danh sách (dòng 6-7).

Chúng tôi thừa nhận rằng các trình gắn thẻ POS có thể không phải lúc nào cũng có sẵn trong mọi ngôn ngữ ít tài nguyên. Các thẻ POS được chỉ định phụ thuộc vào người hoặc lĩnh vực nơi kỹ thuật được sử dụng để nhiễu loạn dữ liệu. Một điều cần lưu ý về kỹ thuật này là nó không phải là việc thay thế từ đồng nghĩa thuần túy mà là việc thay thế từ tương tự dựa trên không gian word embedding, vì vậy nó vẫn không phụ thuộc vào từ điển từ đồng nghĩa mà các ngôn ngữ ít tài nguyên có thể không có.

--- TRANG 3 ---

Thiết lập thử nghiệm
[Hình 4: Đường ống tăng cường cho các thử nghiệm]

Trong phần này, chúng tôi mô tả các thử nghiệm của chúng tôi trên hai tập dữ liệu phân loại downstream để cho thấy các kỹ thuật tăng cường văn bản được đề xuất (EDDA và TSSR) hoạt động tốt như thế nào trong tiếng Thụy Điển.

Có năm phần chính của thử nghiệm, như cũng được mô tả trong Hình 4, như sau:
1. Chia tập dữ liệu thành nhiều phân vùng con.
2. Với mỗi phân vùng tập dữ liệu:
   (a) Huấn luyện mô hình baseline với các phân vùng tập dữ liệu.
   (b) Tăng cường với EDDA và huấn luyện mô hình khác.
   (c) Tăng cường với TSSR và huấn luyện mô hình khác.
   (d) Tăng cường với RSR và huấn luyện mô hình khác.

Phương pháp đánh giá
Mô tả tập dữ liệu: Các thử nghiệm được thực hiện với hai tập dữ liệu có sẵn công khai từ một kho dữ liệu benchmarking tiếng Thụy Điển gọi là SuperLim. Vì các tập dữ liệu đã được làm sạch cho mục đích nghiên cứu, không cần làm sạch dữ liệu đặc biệt hoặc tiền xử lý (Adesam, Berdicevskis, và Morger 2020). Chúng tôi sử dụng hai tập dữ liệu đại diện cho hai vấn đề phổ biến nhất trong NLP, như phân tích cú pháp và phân tích cảm xúc, như sau:

1. DALAJ: Một tập dữ liệu khả năng chấp nhận ngôn ngữ tiếng Thụy Điển (Volodina, Mohammed, và Klezl 2021). Tập dữ liệu này chứa một tập hợp các câu trong đó mỗi câu được biểu thị là đúng hoặc sai về mặt ngôn ngữ. Tập dữ liệu có các phần chia train, validation, và test được định nghĩa trước với 7,682 mẫu huấn luyện trong đó 3,841 mẫu được phân loại vào nhóm đúng. Mặt khác, tập test có 888 mẫu, trong đó một nửa là câu ngữ pháp đúng và nửa còn lại là sai. Tập validation bị bỏ qua trong thử nghiệm của chúng tôi vì thử nghiệm của chúng tôi không có bất kỳ điều chỉnh tham số nào. Một điều cần lưu ý về tập dữ liệu này là khi áp dụng tăng cường, chỉ các mẫu huấn luyện sai về mặt ngôn ngữ được tăng cường, vì việc tăng cường các mẫu tốt có khả năng cao phá vỡ dạng cú pháp của một câu.

2. ABSA: Phân tích cảm xúc dựa trên khía cạnh (ABSA) là một kho ngữ liệu tiếng Thụy Điển được chú thích cho phân tích cảm xúc dựa trên khía cạnh. Tập dữ liệu này bao gồm các câu lệnh khác nhau được gán nhãn từ 1 (rất tiêu cực) đến 5 (rất tích cực). Tập dữ liệu cũng có các phần chia train, validation, và test được định nghĩa trước với 38,640 mẫu huấn luyện và 4,830 mẫu test. Một lần nữa, tập validation bị bỏ qua.

Baseline: Baseline được huấn luyện với dữ liệu huấn luyện với các phần con khác nhau như mô tả sau này. Không có kỹ thuật tăng cường nào trên dữ liệu huấn luyện được áp dụng cho baseline, chỉ phân loại sử dụng mô hình máy vector hỗ trợ tuyến tính (SVM) (Boser, Guyon, và Vapnik 1992) với embeddings BERT (Devlin và cộng sự 2019) được sử dụng. Đối với tất cả các nỗ lực huấn luyện, các tham số SVM được sử dụng là các tham số mặc định được cung cấp bởi Scikit-learn (Pedregosa và cộng sự 2011).

Thiết lập thử nghiệm: Trong thử nghiệm này, chúng tôi sử dụng SVM, nhưng bất kỳ loại bộ phân loại tuyến tính nào cũng có thể được áp dụng. Giới hạn tối đa được đặt ở 512 tokens để chúng tôi có thể nhận được tất cả thông tin từ mô hình BERT để phân loại mô hình tuyến tính của chúng tôi. Khi trích xuất embeddings BERT, chỉ token [CLS] được sử dụng sau khi truyền mỗi văn bản qua mô hình. Mô hình BERT là một transformer 12 lớp với 768 chiều ẩn và 125M tham số (Malmsten, Börjeson, và Haffenden 2020). Tiếng Thụy Điển là một ngôn ngữ ít tài nguyên nhưng có một BERT tiếng Thụy Điển có sẵn nên nó được sử dụng để tạo embeddings. Chúng tôi thừa nhận rằng một mô hình lớn như vậy có thể không tồn tại trong mọi ngôn ngữ ít tài nguyên nhưng các trình trích xuất đặc trưng khác có thể được sử dụng thay thế.

Chi tiết thực hiện: Đầu tiên, tập huấn luyện được chia thêm thành 10, 20, 30, 40, 50, 60, 70, 80, 90, và 100 phần trăm, trong đó mỗi phân vùng được tăng cường và sau đó được thêm vào phân vùng đó để huấn luyện một mô hình tuyến tính sử dụng embeddings BERT (Malmsten, Börjeson, và Haffenden 2020). Lý do đằng sau việc tạo các phân vùng phân tầng nhỏ là để tái tạo một kịch bản trong đó dữ liệu không đủ có sẵn và để xác định liệu tăng cường có giúp ích hay không. Mỗi phần chia tập dữ liệu được tăng cường bằng các kỹ thuật tăng cường riêng lẻ, như được hiển thị trong Hình 4 trong đó tăng cường được áp dụng tuần tự dưới cùng một phân vùng để quan sát sự khác biệt hiệu suất trong điều kiện được kiểm soát. Tỷ lệ nhiễu loạn là 20% cho mỗi câu được tăng cường (tức là 20% của các tokens). Mỗi câu được tăng cường một lần sử dụng các phương pháp nhiễu loạn được mô tả. Đối với tập dữ liệu DALAJ, chỉ các mẫu sai được tăng cường sử dụng tất cả các phương pháp tăng cường vì chúng đã sai rồi. Do đó, bất kỳ nhiễu loạn nào cũng ít có khả năng ảnh hưởng đến nhãn lớp. Hơn nữa, mỗi câu được phân loại từ lớp giữa hoặc lớp sáu vì nó có xu hướng có mức độ cao thông tin cú pháp (Rogers, Kovaleva, và Rumshisky 2020) trong embedding trước khi chúng tôi truyền nó đến lớp tuyến tính.

Mặt khác, đối với ABSA, tất cả các kỹ thuật tăng cường được áp dụng bất kể nhãn lớp cho ABSA vì nó không nhạy cảm về cú pháp so với DALAJ. Hơn nữa, các embeddings được trích xuất từ lớp cuối cùng, vì chúng tôi muốn nhận được các embeddings ngữ nghĩa từ BERT cho các thử nghiệm tiếp theo.

Độ lệch ngữ nghĩa: Sau khi tăng cường đã được áp dụng, để quan sát hoạt động bên trong và tác động lên các câu riêng lẻ, một kiểm tra được thực hiện sử dụng các biện pháp tương tự của các câu không tăng cường và đã tăng cường để đánh giá sự tương tự. Nếu một câu đã thay đổi lệch lớn khỏi dạng gốc của nó, điều này có thể quan trọng để kiểm tra, vì các câu rất khác nhau có thể phá hủy ngữ nghĩa và có thể thay đổi nhãn thực tế. Chúng tôi sử dụng hàm Deviction của chúng tôi để kiểm tra sự tương tự giữa câu gốc t và bất kỳ câu tăng cường t̂ từ t.

Deviction(t,t̂) = {"similar", nếu cos(t,t̂) ≥ δ
                 {"dissimilar", nếu không

Ngưỡng độ lệch δ được chọn ở mức 0.9 tương tự cosine. Bất kỳ mẫu nào dưới mức đó được coi là một câu ngữ nghĩa khác. Lý do tại sao 0.9 được sử dụng là vì các câu tăng cường nên có độ gần cao với dạng gốc của chúng điều này quan trọng để bảo toàn nhãn cảm xúc. Embedding được trích xuất sử dụng cùng mô hình BERT được sử dụng cho tất cả các thử nghiệm khác.

--- TRANG 4 ---

Kết quả
Phần này bao gồm hai phần, trong đó chúng tôi trình bày điểm F1 của các kỹ thuật tăng cường khác nhau trên DALAJ & ABSA. Cuối cùng, chúng tôi tiếp tục điều tra xem cảm xúc lệch nhau bao nhiều chỉ cho tập dữ liệu ABSA. Các kỹ thuật được hiển thị trong kết quả là (1) baseline, (2) EDDA, (3) TSSR: nhiễu loạn được kiểm soát của các thẻ từ loại được chọn (trong trường hợp này là danh từ). (4) RSR: chỉ sử dụng thay thế từ đồng nghĩa ngẫu nhiên. Để so sánh công bằng, chúng tôi sử dụng chính xác dữ liệu cho mỗi phân vùng từ tập huấn luyện để tăng cường và huấn luyện mô hình.

DALAJ
[Bảng 1: Điểm F1 trên DALAJ dưới bốn thiết lập khác nhau và mười tỷ lệ phân vùng khác nhau]

Bảng 1 cho thấy tổng điểm F1 trên tập dữ liệu DALAJ dưới các thiết lập khác nhau. Cho đến 60% phân vùng dữ liệu, tất cả các kỹ thuật tăng cường đều cải thiện phân loại trên tập dữ liệu DALAJ. Tuy nhiên, sử dụng hơn 60% dữ liệu với tăng cường có xu hướng giảm hiệu quả của các kỹ thuật tăng cường đã nói.

[Hình 5: Điểm F1 trên 10 đến 60 phần trăm của tập dữ liệu DALAJ dưới bốn thiết lập khác nhau]

Khi so sánh baseline với EDDA từ 10% đến 60% của tập dữ liệu, EDDA cải thiện trung bình 2.5%. Mặt khác, khi so sánh baseline với TSSR chúng tôi có mức tăng trung bình 2%. Nhưng kết quả tốt nhất xuất hiện dưới RSR so với baseline với mức tăng 3.5% trong hiệu suất phân loại.

Một trong những lý do sử dụng tăng cường văn bản là khi chúng ta có lượng dữ liệu thấp, chúng ta có thể sử dụng các kỹ thuật như vậy để cải thiện mô hình cho các nhiệm vụ downstream. Hình 5 hỗ trợ khẳng định đó vì chỉ sử dụng 40% dữ liệu, RSR cải thiện 9% so với baseline, trong khi EDDA cải thiện F1 5%. Tuy nhiên, đây là trường hợp mà TSSR chỉ cải thiện 1%.

Bài báo gốc, đã giới thiệu DALAJ (Volodina, Mohammed, và Klezl 2021), cũng đã báo cáo điểm F1 62% trên cùng tập test. Điều này được so sánh với phương pháp của chúng tôi, nơi chúng tôi chỉ cần 40% dữ liệu để có được 65% F1 chỉ sử dụng RSR. Một bằng chứng khác về lý do tại sao tăng cường có thể hiệu quả với dữ liệu được gán nhãn hạn chế.

EDDA & RSR: EDDA cải thiện hiệu suất trong bảy trong số 10 phân vùng của tập dữ liệu, trong khi RSR cải thiện trong sáu trong số mười phân vùng. Tăng cường hoạt động thỏa đáng cho nhiệm vụ này, đặc biệt trong các kịch bản dữ liệu thấp. Đáng ngạc nhiên, RSR hoạt động đặc biệt tốt, chỉ với 40% dữ liệu vượt trội baseline với 100% dữ liệu huấn luyện 1% trong điểm F1.

TSSR: Tăng cường này cải thiện trong sáu trong số 10 phân vùng. TSSR trên nhiệm vụ downstream này không hoạt động tốt như EDDA và RSR. Tuy nhiên, nó liên tục cải thiện so với baseline, nhưng nó không phải là kỹ thuật tăng cường tối ưu nhất để sử dụng trong tập dữ liệu phân loại này.

ABSA
[Bảng 2: Điểm F1 trên ABSA dưới bốn thiết lập khác nhau và mười tỷ lệ phân vùng khác nhau]

Bảng 2 cho thấy tổng điểm F1 trên tập dữ liệu ABSA dưới các thiết lập khác nhau. Cho đến 60% phân vùng dữ liệu, tất cả các kỹ thuật tăng cường đều cải thiện phân loại trên tập dữ liệu ABSA. Tuy nhiên, sử dụng hơn 60% dữ liệu với tăng cường có xu hướng giảm hiệu quả của các kỹ thuật tăng cường đã nói. Hình 6 cho thấy nhiễu loạn được kiểm soát trên dữ liệu cảm xúc cải thiện phân loại.

[Hình 6: Điểm F1 trên 10 đến 60 phần trăm của tập dữ liệu ABSA dưới bốn thiết lập khác nhau]

So sánh baseline với TSSR, chúng ta có thể thấy mức tăng điểm F1 trung bình 2.7%. Ngoài ra, sử dụng EDDA và RSR liên tục cải thiện điểm F1, mặc dù trong một số trường hợp. Khi so sánh EDDA với RSR, hiệu suất dường như giảm. RI, RD, và RS có khả năng tác động tiêu cực đến các phân loại, nhưng như được hiển thị, RSR hoạt động hơi tốt hơn EDDA.

EDDA & RSR: EDDA không liên tục cải thiện hiệu suất phân loại cho nhiệm vụ phân tích cảm xúc này. Cần lưu ý rằng đây là một tập dữ liệu phân tích cảm xúc dựa trên khía cạnh. Do đó nhiễu loạn nhỏ nhất có thể trở nên có hại cho kết quả phân loại đa nhãn. Các nhiễu loạn ngẫu nhiên kiểu EDA được biết là không tốt cho dữ liệu cảm xúc như công trình trước đây đã cho thấy sự giảm trong điểm phân loại (Qiu và cộng sự 2020; Bayer, Kaufhold, và Reuter 2021; Anaby-Tavor và cộng sự 2020). Một bài báo khác cho thấy hoán đổi và xóa ngẫu nhiên làm xấu đi việc bảo toàn nhãn câu (Wu và cộng sự 2020). Vì vậy kết quả của chúng tôi trùng khớp với công trình trước đây. Tuy nhiên, RSR đã tạo ra kết quả tốt một vài lần, do đó là một kỹ thuật tăng cường có thể biện minh có thể hoạt động trong một tập dữ liệu nhất định.

TSSR: Trên tám trong số mười phân vùng của tập dữ liệu đa nhãn này, TSSR liên tục cải thiện hiệu suất phân loại. Điều này một phần là do chỉ thay đổi các loại token danh từ nhất định được kiểm soát nhiều hơn. Điều này tạo ra khả năng cao hơn không thay đổi trạng từ và tính từ, bảo toàn nhãn lớp. Hơn nữa, sử dụng mô hình word2vec để tìm thay thế cho phép chúng tôi có được nhiều từ khác nhau có thể không được tìm thấy trong từ điển tiêu chuẩn, như thay thế tên, ví dụ, Mattias Eriksson thành Mattias Larsson.

Độ lệch ngữ nghĩa: Độ lệch ngữ nghĩa chỉ được đánh giá cho tập dữ liệu ABSA để xem tăng cường ảnh hưởng đến tập dữ liệu cảm xúc như thế nào. Chỉ tập dữ liệu cảm xúc được sử dụng vì nó có khả năng cao nhất bị phá vỡ khi các kỹ thuật tăng cường khác nhau được áp dụng.

[Bảng 3: Thử nghiệm độ lệch ngữ nghĩa trên tập dữ liệu ABSA]

Bảng 3 cho thấy có bao nhiêu câu tăng cường giữ đủ sự tương tự với câu gốc. 40.3% câu tăng cường bởi EDDA không đáp ứng tiêu chí tối thiểu của chúng tôi (tức là tương tự cosine 0.9) để tương tự với câu gốc, trong khi TSSR chỉ tạo ra 14.8% câu tổng hợp có độ tương tự dưới 0.9, chứng minh rằng TSSR bảo toàn sự gần gũi ngữ nghĩa với câu gốc do đó bảo toàn nhãn. Do đó, có thể an toàn nói rằng TSSR có thể đóng vai trò như một mô-đun cạnh tranh cùng với EDDA trong các tập dữ liệu cảm xúc.

--- TRANG 5 ---

Kết luận
Chúng tôi đã giới thiệu EDDA, một sửa đổi của EDA mà không có sự phụ thuộc lớn vào ngôn ngữ, và TSSR, một phương pháp bổ sung cho EDDA, để thay thế từ đồng nghĩa với thông tin cụ thể theo loại. Chúng tôi đã đo lường hai kỹ thuật này hoạt động như thế nào trên các tập dữ liệu tiếng Thụy Điển đại diện và cho thấy hai kỹ thuật đó có thể cải thiện DALAJ 1% so với baseline chỉ với 40% dữ liệu huấn luyện. Chúng tôi cũng đã cho thấy việc tăng cường được trình bày hoạt động tốt như thế nào với lượng dữ liệu được gán nhãn nhỏ và chứng minh rằng ít dữ liệu là hiệu quả nhất để tăng cường hoạt động tốt. Hơn nữa, tăng cường có thể không phải lúc nào cũng cải thiện kết quả phân loại nhưng vẫn có thể rất hữu ích trong hầu hết các trường hợp. Chúng tôi muốn nhấn mạnh rằng các kỹ thuật được giới thiệu trong bài báo này dễ dàng thích ứng với các ngôn ngữ ít tài nguyên khác. Công trình tương lai của chúng tôi bao gồm (1) thử nghiệm các kỹ thuật tăng cường trong các ngôn ngữ ít tài nguyên khác, (2) thử nghiệm trên nhiều nhiệm vụ downstream khác nhau ngoài phân loại, (3) mở rộng khung cho các loại tăng cường khác mà không phụ thuộc vào ngôn ngữ hoặc ít nhất là dễ dàng thích ứng với bất kỳ ngôn ngữ nào.

Tài liệu tham khảo
[Danh sách tài liệu tham khảo được dịch sang tiếng Việt với cùng định dạng]

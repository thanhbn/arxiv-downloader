# Đánh giá các Mô hình Tiền huấn luyện qua các Ngôn ngữ và Ngữ pháp

Alberto Muñoz-Ortiz, David Vilares và Carlos Gómez-Rodríguez
Universidade da Coruña, CITIC
Departamento de Ciencias de la Computación y Tecnologías de la Información
Campus de Elviña s/n, 15071
A Coruña, Spain
{alberto.munoz.ortiz, david.vilares, carlos.gomez}@udc.es

Tóm tắt
Chúng tôi trình bày một phương pháp để đánh giá cách các mô hình ngôn ngữ lớn đa ngữ (LLM) học cú pháp theo cấu trúc cú pháp đa hình thức. Chúng tôi nhằm mục đích khôi phục cấu trúc thành phần và phụ thuộc bằng cách xem parsing như gán nhãn chuỗi. Để làm điều này, chúng tôi chọn một vài LLM và nghiên cứu chúng trên 13 treebank UD đa dạng cho dependency parsing và 10 treebank cho constituent parsing. Kết quả của chúng tôi cho thấy: (i) framework này nhất quán qua các cách mã hóa, (ii) các vector từ tiền huấn luyện không ưu tiên biểu diễn cấu trúc thành phần của cú pháp hơn phụ thuộc, (iii) tokenization từ con cần thiết để biểu diễn cú pháp, trái ngược với các mô hình dựa trên ký tự, và (iv) sự xuất hiện của một ngôn ngữ trong dữ liệu tiền huấn luyện quan trọng hơn lượng dữ liệu task khi khôi phục cú pháp từ các vector từ.

1 Giới thiệu

Các Mô hình Ngôn ngữ Lớn (LLM) là xương sống cho hầu hết các kiến trúc NLP. Hiệu suất của chúng vẫn chưa đạt đến một ngưỡng, và các yếu tố như quy mô, mục tiêu ngôn ngữ, phân đoạn token hoặc lượng thời gian tiền huấn luyện - cùng nhiều yếu tố khác - đóng vai trò trong khả năng của chúng.

Để làm sáng tỏ những gì được học, công việc về khả năng giải thích giải thích những gì các mô hình này mã hóa trong không gian biểu diễn của chúng. Các tác giả đã khám phá liệu các mô hình này có thể hiện thành kiến định kiến (Nadeem et al., 2021), mã hóa sự thật (Poerner et al., 2020) hay nắm bắt kiến thức cấu trúc trong môi trường đa phương thức (Milewski et al., 2022).

Liệu LLM có mã hóa cú pháp trong không gian tiềm ẩn của chúng cũng đã được nghiên cứu. Trong khía cạnh này, các framework probing khác nhau (Kulmizev and Nivre, 2022; Belinkov, 2022) đã được giới thiệu để đo lường khả năng cú pháp của các mô hình, mặc dù các tác giả như Maudslay và Cotterell (2021) chỉ ra rằng chúng ta cần cẩn thận với khái niệm này, vì chúng có thể không hoàn toàn cô lập cú pháp.

Tuy nhiên, công việc giải thích về parsing tập trung vào các thiết lập đa ngữ và đơn paradigm, hoặc tiếng Anh và đa paradigm. Nhưng chúng tôi không biết về công việc đa chiều. Điều này liên quan đến vấn đề thiên vị điểm xuất phát trong nghiên cứu NLP (Ruder et al., 2022), nói rằng hầu hết công việc mở rộng kiến thức hiện tại chỉ dọc theo một chiều (ví dụ, một ngôn ngữ duy nhất, hoặc một task duy nhất).

Liên quan đến công việc của chúng tôi, Kulmizev et al. (2020) nghiên cứu xem LLM có cho thấy sở thích qua hai phong cách chú thích: universal dependencies cú pháp sâu và bề mặt, nhưng cả hai sơ đồ đều dựa trên phụ thuộc. Vilares et al. (2020) đã nghiên cứu hai formalism cú pháp khác nhau, phụ thuộc và thành phần, và sử dụng framework khôi phục giống như gán nhãn chuỗi, dựa vào các kiến trúc tiền huấn luyện để liên kết vector đầu ra với nhãn cú pháp. Chúng tôi sẽ xây dựng trên framework này. Tuy nhiên, họ chỉ nghiên cứu tiếng Anh, và phân tích của họ tập trung vào vector tĩnh và LLM sớm; ngoài các hạn chế khác mà chúng tôi thảo luận sau.

Đóng góp Chúng tôi di chuyển từ thiên vị điểm xuất phát trong đánh giá cú pháp, và đề xuất framework khôi phục đa paradigm, đa ngữ đầu tiên cho cấu trúc phụ thuộc và thành phần được học bởi LLM. Chúng tôi chọn các LLM đại diện khác nhau về quy mô, mục tiêu tiền huấn luyện ngôn ngữ, và định dạng biểu diễn token. Sau đó chúng tôi nghiên cứu khả năng của chúng để truy xuất thông tin cú pháp từ các biểu diễn tiền huấn luyện trên một tập hợp đa dạng các treebank thành phần và phụ thuộc, khác nhau về các yếu tố như họ ngôn ngữ hoặc kích thước, cũng như sự hiện diện hoặc vắng mặt của ngôn ngữ của chúng trong dữ liệu tiền huấn luyện của các LLM. Mã nguồn có sẵn tại https://github.com/amunozo/multilingual-assessment.

2 Công trình liên quan

Có một nỗ lực lâu dài trong cộng đồng NLP để mô hình hóa cú pháp, hoặc như mục tiêu cuối cùng hoặc như một cách để mô hình hóa tính compositionality. Tuy nhiên, các cách thức mà điều này được theo đuổi đã phát triển theo thời gian.

Mô hình hóa cú pháp trong thời kỳ tiền neural. Học ngữ pháp thông qua các phương pháp dựa trên corpus (Marcus et al., 1993; Collins, 1996; Charniak, 1997; Petrov and Klein, 2007) đã là phương pháp thống trị trong những thập kỷ qua. Tuy nhiên, các mô hình sớm yêu cầu feature engineering rộng rãi để có được các parser cạnh tranh. Điều này gợi ý rằng các máy vector hỗ trợ (SVM) có những hạn chế nghiêm trọng trong việc hiểu cấu trúc ngôn ngữ, và cần sự giúp đỡ của các thuật toán parsing (Nivre, 2008; Martins et al., 2010), các feature phụ thuộc ngôn ngữ (Ballesteros and Nivre, 2012), hoặc tree-kernel (Lin et al., 2014; Zhang and Li, 2009) để mô hình hóa cú pháp đúng cách.

Mô hình hóa cú pháp trong thời kỳ neural. Với sự trỗi dậy của các vector từ (Mikolov et al., 2013), LSTM (Hochreiter and Schmidhuber, 1997) và Transformer (Vaswani et al., 2017), mô hình hóa cấu trúc đã trở nên ít liên quan hơn để có được hiệu suất tốt, cả cho parsing và các task downstream. Ví dụ, trong khi parser cổ điển của Zhang và Nivre (2011) sử dụng một tập hợp feature phong phú (bao gồm các feature bậc ba, khoảng cách, và valency, cùng những feature khác) để cạnh tranh, parser của Chen và Manning (2014) chỉ cần 18 feature từ và PoS tag (và 6 feature phụ thuộc) để đạt kết quả mạnh, điều này có thể nhờ vào sự phụ thuộc của họ vào vector từ tiền huấn luyện và mạng neural. Nhu cầu feature engineering đã giảm hơn nữa với LSTM hai chiều, ví dụ, Kiperwasser và Goldberg (2016) chỉ ra rằng bốn vector tương ứng với các phần tử trong buffer và stack đã đủ để đạt hiệu suất state-of-the-art, trong khi Shi et al. (2017) chỉ ra rằng độ chính xác cạnh tranh có thể với chỉ hai feature.

Mô hình hóa cú pháp trong kỷ nguyên của các mô hình ngôn ngữ. Trong bối cảnh của các parser (gần như) end-to-end này hoạt động rất cạnh tranh mà không cần mô hình hóa rõ ràng các feature ngôn ngữ cú pháp, các nỗ lực gần đây đã được dành để giải thích mức độ cú pháp được mã hóa trong không gian biểu diễn của mạng neural, và đặc biệt là của LLM. Tenney et al. (2019) và Liu et al. (2019a) đề xuất các framework probing cho parsing từng phần, theo nghĩa là họ cố gắng chứng minh rằng thông tin cú pháp nhất định, như loại phụ thuộc, được mã hóa trong các mô hình tiền huấn luyện. Vilares et al. (2020) định nghĩa một framework probing cho dependency và constituent parsing đầy đủ. Họ xem dependency và constituent parsing như gán nhãn chuỗi và liên kết vector đầu ra với nhãn cú pháp bằng cách đóng băng các mô hình của họ. Hewitt và Manning (2019) đề xuất một framework probing cấu trúc và xác định rằng các mô hình tiền huấn luyện mã hóa một biến đổi tuyến tính chỉ ra khoảng cách giữa các từ trong cây phụ thuộc. Framework sau đó được nâng cấp để trích xuất cây có hướng và có nhãn, trong khi sử dụng ít tham số hơn (Müller-Eberstein et al., 2022a). Hewitt và Liang (2019) chỉ ra rằng chúng ta cần cẩn thận với các framework probing, vì probe có thể đang học task ngôn ngữ này, thay vì chứng minh sự hiện diện của thuộc tính ngôn ngữ mục tiêu. Để làm điều đó, họ khuyến nghị sử dụng các thí nghiệm đối chứng, và dựa vào các task đối chứng, tức là học một task ngẫu nhiên với cùng không gian đầu ra chiều. Maudslay và Cotterell (2021) chỉ ra rằng các dấu hiệu ngữ nghĩa trong dữ liệu có thể hướng dẫn probe và do đó chúng có thể không cô lập cú pháp, mặc dù các thí nghiệm của họ vẫn vượt trội so với các baseline. Müller-Eberstein et al. (2022b) tìm thấy các LLM tiền huấn luyện phù hợp nhất để cắm vào một dependency parser cho một treebank nhất định. Đặc biệt, họ đề xuất xếp hạng các biểu diễn encoder đóng băng bằng cách xác định tỷ lệ phần trăm cây có thể khôi phục từ chúng, và dựa trên xếp hạng đó chọn LLM nào để cắm. Tập trung vào hình thái học, Stanczak et al. (2022) chỉ ra rằng các tập con neuron mô hình hóa morphosyntax qua nhiều ngôn ngữ trong các LLM đa ngữ.

3 Framework probing đa ngữ

Cho w=[w1, w2, ..., wn] là một câu đầu vào. Chúng tôi quan tâm đến các framework probing tuyến tính có thể liên kết một chuỗi vector từ w⃗ =[w⃗1, w⃗2, ..., w⃗n] với một thuộc tính ngôn ngữ nhất định [p1, p2, ..., pn]. Đối với một số thuộc tính, việc ánh xạ có thể khá trực tiếp, chẳng hạn như trường hợp part-of-speech (PoS) tagging (bằng cách đặt một lớp tuyến tính trên w và xuất ra danh mục PoS tag), hoặc ngữ nghĩa từ vựng (ví dụ tính toán độ tương tự vector từ). Chúng tôi muốn một ánh xạ tương tự, nhưng cho nhiều formalism cú pháp. Trong trường hợp này, việc liên kết không tầm thường vì parsing cú pháp là một vấn đề dự đoán có cấu trúc dựa trên cây. Ngoài ra, chúng tôi quan tâm đến các mô hình tiền huấn luyện đa ngữ, đã thu hút sự quan tâm trong những năm gần đây.

Sau đó, mục tiêu là liên kết các vector từ của họ với một ước tính về mức độ các đặc điểm của một formalism nhất định được mã hóa trong không gian biểu diễn của chúng, và liệu điều này có thể khác nhau qua các chiều như các mô hình được kiểm tra, formalism, và treebank.

Framework probing tuyến tính cho parsing Chúng tôi lấy nghiên cứu của Vilares et al. (2020) làm điểm xuất phát. Tuy nhiên, chúng tôi trước tiên xác định một số điểm yếu trong công việc của họ: (i) nó chỉ giới hạn ở tiếng Anh, (ii) họ không đưa ra ước tính cụ thể về lượng cây có thể khôi phục so với các thí nghiệm đối chứng, và (iii) họ chỉ kiểm tra một loại tuyến tính hóa cây. Đối với điều sau, động lực chính, đặc biệt cho trường hợp dependency parsing, là linearization được chọn đã hoạt động tốt nhất trong công việc trước đó (Strzyz et al., 2019) khi huấn luyện từ đầu một transducer mà không có tiền huấn luyện. Tuy nhiên, công việc sau đó gợi ý rằng điều đó có thể tranh cãi: ví dụ, Muñoz-Ortiz et al. (2021) chỉ ra rằng các tuyến tính hóa cây khác nhau có thể phù hợp hơn với các ngôn ngữ khác nhau, và kết quả của Vacareanu et al. (2020) chỉ ra rằng các mã hóa khác hoạt động tốt hơn khi các mô hình ngôn ngữ tiền huấn luyện được sử dụng.

Để khôi phục cấu trúc phụ thuộc và thành phần, chúng tôi sẽ biểu diễn các cây bằng cách sử dụng các mã hóa hiện có cho parsing như gán nhãn chuỗi (Gómez-Rodríguez và Vilares, 2018; Strzyz et al., 2019). Dưới cấu hình này, sự tương tác giữa việc học một mô hình và tìm kiếm các thuộc tính ngôn ngữ giờ đây là trực tiếp. Chúng ta có thể sử dụng các kiến trúc probing dựa hoàn toàn vào các biểu diễn tiền huấn luyện, và chỉ cần thêm một lớp tuyến tính lên trên để ánh xạ vector liên tục thành nhãn rời rạc. Chúng ta có thể mong đợi rằng khả năng của lớp đầu ra không đủ để học các task cú pháp bằng chính nó, vì vậy nó phải dựa vào chất lượng của các biểu diễn tiền huấn luyện. Tuy nhiên, chúng tôi cũng sẽ bao gồm các baseline đối chứng mà chúng tôi sẽ thảo luận sau.

Câu hỏi nghiên cứu Chúng tôi muốn trả lời hai câu hỏi: (i) có bao nhiêu cú pháp có thể khôi phục từ các LLM khác nhau? và (ii) nó được ảnh hưởng như thế nào bởi các khía cạnh như các mô hình, loại formalism, và dữ liệu tiền huấn luyện và đánh giá?

Trong phần tiếp theo, chúng tôi mô tả các mã hóa gán nhãn chuỗi, cả cho paradigm phụ thuộc và thành phần (§3.1), và các chi tiết cụ thể của thiết lập probing được sử dụng cho các thí nghiệm của chúng tôi (§3.2).

3.1 Mã hóa gán nhãn chuỗi của cú pháp

Parsing như gán nhãn chuỗi có thể được định nghĩa là học một hàm fn:Vn→Ln để ánh xạ một chuỗi từ thành một chuỗi nhãn tuyến tính hóa có thể được giải mã để khôi phục hoàn toàn một cây thành phần hoặc phụ thuộc. Ở đây chúng tôi không quan tâm đến các parser per se, mà là liệu các mã hóa gán nhãn chuỗi được định nghĩa cho chúng có cung cấp một biểu diễn đơn giản, không mất mát của cây phụ thuộc và thành phần hữu ích cho probing. Trong phần tiếp theo, chúng tôi mô tả ngắn gọn các biểu diễn này.

3.1.1 Dependency parsing

Các phụ thuộc giữa các token có thể được mã hóa bằng cách sử dụng nhãn có dạng (xi, li), trong đó xi là một tập con của các cung liên quan đến token wi, và li biểu thị quan hệ phụ thuộc (Strzyz et al., 2019). Có nhiều cách khác nhau để mã hóa xi. Chúng tôi so sánh ba họ tuyến tính hóa (do ngắn gọn, chúng tôi tham khảo các tham chiếu dưới đây cho các chi tiết):

HEAD-SELECTION (Spoustová và Spousta, 2010; Li et al., 2018; Strzyz et al., 2019). xi mã hóa cung phụ thuộc trỏ trực tiếp đến wi. Điều này có thể được thực hiện bằng cách sử dụng một chỉ số tuyệt đối hoặc một offset tương đối tính toán sự khác biệt giữa chỉ số của wi và head của nó. Chúng tôi sử dụng mã hóa (rh) trong đó head của wi là từ thứ xi bên phải, nếu xi>0, và từ thứ xi bên trái nếu xi<0.

BRACKETING-BASED (Yli-Jyrä và Gómez-Rodríguez, 2017; Strzyz et al., 2020). xi mã hóa các cung bằng cách sử dụng chuỗi ngoặc để biểu diễn một tập con của các cung đến và đi của wi và các hàng xóm trực tiếp của nó. Chúng tôi sử dụng mã hóa ngoặc 2-planar (2pb) sử dụng hai mặt phẳng ngoặc độc lập để mã hóa các cây không chiếu.

TRANSITION-BASED (Gómez-Rodríguez et al., 2020). xi mã hóa một chuỗi con của các chuyển tiếp được tạo bởi một parser transition-based từ trái sang phải. Cho một danh sách chuyển tiếp t=t1, ..., tm với n chuyển tiếp đọc, t được chia thành n chuỗi con sao cho chuỗi con thứ i được gán cho wi. Chúng tôi sử dụng ánh xạ từ thuật toán arc-hybrid (ahtb) (Kuhlmann et al., 2011). Các ánh xạ này ngầm định và thường hoạt động tệ hơn các mã hóa trực tiếp hơn, nhưng chúng có thể học được.

Các mã hóa này tạo ra các nhãn với thông tin khác nhau. Theo Hình 1, đối với w2(painting), mã hóa 2pb nói rằng từ trước w1 có một cung đến từ bên phải (ký hiệu "<", nhưng nó không nói từ đâu, vì thông tin đó được mã hóa trong các nhãn khác) và w2 có một cung đi sang trái (ký hiệu "\", nhưng nó không chỉ định đâu). Đối với mã hóa transition-based, ánh xạ ít đơn giản hơn qua các từ, nhưng vẫn kết nối với chúng. Ví dụ, đối với w1('This') nhãn chỉ ra rằng w1 không có kết nối với w0, rằng nó là một dependent của w1, và rằng nó không có children. Động lực để so sánh các mã hóa là để kiểm tra: (i) tính nhất quán của framework, tức là nếu xu hướng qua các LLM vẫn giữ nguyên, và (ii) để xem thông tin nào dễ khôi phục hơn khi các trọng số LLM bị đóng băng.

3.1.2 Constituent parsing

Chúng tôi ở đây sử dụng phương pháp mã hóa của Gómez-Rodríguez và Vilares (2018), mã hóa các mức chung trong cây giữa các cặp token. Các nhãn có dạng (ni, ci, ui). Phần tử ni mã hóa số mức cây chung giữa wi và wi+1, được tính như sự khác biệt so với ni−1. Phần tử ci mã hóa ký hiệu non-terminal thấp nhất được chia sẻ giữa hai từ đó. ui mã hóa nhánh unary lá nằm tại wi, nếu nó tồn tại. Một ví dụ được hiển thị trong Hình 2.

3.2 Kiến trúc probing

Chúng tôi sử dụng một mạng feed-forward 1 lớp trên các LLM để dự đoán các nhãn. Chúng tôi đề xuất ba thiết lập (các hyperparameter huấn luyện được chi tiết trong Phụ lục A):

Frozen weights (frz) Các trọng số LLM bị đóng băng và chỉ các trọng số của lớp đầu ra tuyến tính được cập nhật trong quá trình fine-tuning.

Random weights (rnd) Chỉ các trọng số của lớp classifier tuyến tính được cập nhật, nhưng các trọng số của các encoder được ngẫu nhiên hóa. Chúng tôi nhằm mục đích ngăn chặn kết luận sai lầm trong trường hợp giả định rằng lớp tuyến tính có thể học ánh xạ bản thân, tức là chúng tôi sử dụng thiết lập này như một baseline cận dưới. Nó cũng là một thí nghiệm đối chứng, vì sự khác biệt giữa kết quả của thiết lập này và thiết lập frz sẽ là thước đo chúng tôi đang tìm kiếm để ước tính lượng thông tin cú pháp được mã hóa trong không gian biểu diễn của các LLM tiền huấn luyện.

Fine-tuned weights (ftd) Một LLM được fine-tuned trong đó tất cả các trọng số được cập nhật, tức là thiết lập này được sử dụng như một baseline cận trên.

3.3 Các Mô hình Ngôn ngữ Đa ngữ

Phương pháp được đề xuất ở đây là model-agnostic. Mục tiêu của chúng tôi không phải là đạt được kết quả cao nhất hoặc sử dụng LLM lớn nhất. Chúng tôi chọn một vài LLM đại diện và có thể chạy được với tài nguyên của chúng tôi:

mBERT (Devlin et al., 2019) Nó sử dụng tokenization WordPiece. Trong khi các subword tokenizer hiệu quả với các phân tách đại diện, chúng tạo ra các subtoken không tối ưu cho các ngôn ngữ tài nguyên thấp (Agerri et al., 2020; Virtanen et al., 2019), vì các subtoken sai sẽ không mã hóa thông tin có ý nghĩa. mBERT được tiền huấn luyện trên 104 ngôn ngữ từ dump của các Wikipedia lớn nhất.

xlm-roberta (Conneau et al., 2020) Một LLM đa ngữ được huấn luyện như RoBERTa (Liu et al., 2019b). Nó có cùng kiến trúc với BERT, nhưng chỉ được tiền huấn luyện trên task dự đoán từ che khuất và sử dụng BPE cấp byte cho tokenization. Nó đã được tiền huấn luyện trên 2.5TB dữ liệu CommonCrawl được lọc chứa văn bản trong 100 ngôn ngữ (XLM-100), và trong thời gian dài hơn mBERT.

canine (-c và -s) (Clark et al., 2022) Nó sử dụng tokenization dựa trên ký tự, được tin là hoạt động tốt hơn trong các ngôn ngữ thách thức cho subword tokenization, như những ngôn ngữ có harmony nguyên âm. Nó loại bỏ vấn đề token không xác định. Nó được tiền huấn luyện trên masked language modeling và next sentence prediction trên cùng dữ liệu với mBERT: canine-c được tiền huấn luyện sử dụng loss cấp ký tự, trong khi canine-s bao gồm tokenization subword trước đó để dự đoán các token subword bị che khuất.

Trong tất cả các mô hình, các nhãn trước tiên được chia thành các subtoken trước khi được xử lý bởi các LLM để gán chúng cho n token đầu vào. Lớp classifier sau đó gán một nhãn cho mỗi subtoken (tức là subword cho mBERT và xlm-roberta và ký tự cho canine). Sau đó, chúng tôi chọn nhãn được gán cho sub-element đầu tiên, đây là một phương pháp phổ biến.

4 Phương pháp và Thí nghiệm

Dữ liệu cho dependency parsing Để đánh giá cấu trúc phụ thuộc, chúng tôi chọn 13 treebank Universal Dependencies (UD 2.9; Nivre et al., 2020) từ các họ ngôn ngữ khác nhau và với lượng dữ liệu chú thích khác nhau. Mặc dù mBERT, xlm-roberta, và canine đã được tiền huấn luyện trên các dataset thu thập đa ngữ khác nhau, chúng tôi chọn các treebank có ngôn ngữ hoặc có mặt trong tất cả dữ liệu tiền huấn luyện của LLM của chúng tôi hoặc không có trong bất kỳ ai (mặc dù tỷ lệ hiện diện có thể khác nhau trong trường hợp xlm-roberta). Để biết thêm chi tiết, xem Bảng 1. Kích thước dữ liệu đã được thu thập từ Wu và Dredze (2020) cho Wiki-100 và Conneau et al. (2020) cho XLM-100.

Dữ liệu cho constituent parsing Chúng tôi đánh giá cấu trúc thành phần trên PTB (Marcus et al., 1993), CTB (Xue et al., 2005), và 8 treebank thành phần từ shared task SPMRL (Seddah et al., 2014), có ngôn ngữ được hiển thị trong Bảng 2.

Sự khác biệt ngôn ngữ Chúng tôi sử dụng (chủ yếu) các ngôn ngữ khác nhau cho mỗi paradigm. Đối với các treebank thành phần, chúng tôi chỉ có quyền truy cập vào các ngôn ngữ tài nguyên phong phú, vì vậy chúng tôi ưu tiên sự đa dạng cho phụ thuộc. So sánh ngôn ngữ qua các paradigm cú pháp không đặc biệt hữu ích, do metrics khác nhau, độ phức tạp chú thích, và so sánh treebank. Thay vào đó, chúng tôi so sánh giảm lỗi so với các mô hình đối chứng để ước tính khả năng khôi phục của các formalism cú pháp cụ thể bởi một LLM (xem §5).

Metrics Đối với dependency parsing, chúng tôi sử dụng Labeled Attachment Score (LAS). Đối với constituent parsing, chúng tôi sử dụng labeled bracketing F1-score.

5 Kết quả

Chúng tôi trình bày đánh giá cho cấu trúc phụ thuộc trong §5.1, và cho cấu trúc thành phần trong §5.2.

5.1 Kết quả dependency parsing

Chúng tôi chia nhỏ kết quả so sánh frozen vs: (i) random, và (ii) fine-tuned weights.

Thiết lập Frozen (frz) vs random weights (rnd) Bảng 3 hiển thị kết quả LAS qua các treebank và mã hóa phụ thuộc (dựa trên head, dựa trên ngoặc, và dựa trên transition). Đối với mbert và xlm-roberta, hiệu suất trong thiết lập frz rõ ràng vượt trội baseline rnd, tức là thí nghiệm đối chứng. Kết quả gợi ý rằng dưới các thiết lập frozen, mbert tốt hơn xlm-roberta trong việc khôi phục phụ thuộc, mặc dù các mô hình xlm-roberta tiền huấn luyện thường tốt hơn tại các task downstream (Liu et al., 2019b). Xếp hạng của các LLM ổn định qua các treebank. Điểm LAS qua các mã hóa trong một phạm vi tương tự, và LAS trung bình qua các mã hóa khác nhau cũng rất tương tự (hàng dưới cùng trong Bảng 3). Mặt khác, kết quả cho canine không vượt trội baseline cận dưới trong hầu hết các trường hợp. Điều này không có khả năng là do fitting kém, vì các baseline trọng số ngẫu nhiên hoạt động gần như giống nhau qua các mô hình tiền huấn luyện, mã hóa và treebank. Ngoài ra, trong khi canine-s vượt trội baseline ngẫu nhiên cho các ngôn ngữ tài nguyên cao nhất, canine-c kém hơn nó cho tất cả ngôn ngữ ngoại trừ tiếng Trung.

Để có hình ảnh rõ ràng hơn, Hình 3 hiển thị các giảm lỗi LAS tương đối ϵLAS(rnd,frz) cho mã hóa 2-planar và được sắp xếp theo kích thước của tập huấn luyện được sử dụng cho probe. Tiếp theo, chúng tôi tập trung vào 2pb vì công việc trước đây đã chứng minh độ mạnh mẽ của nó qua các cấu hình khác nhau (Muñoz-Ortiz et al., 2021; Strzyz et al., 2019, 2020). Đối với các treebank lớn hơn, có ngôn ngữ được hỗ trợ bởi LLM, việc giảm lỗi giữa các thiết lập frz và rnd là lớn, cho thấy rằng LLM mã hóa ở một mức độ nào đó cấu trúc phụ thuộc trong không gian biểu diễn của chúng. Đối với các ngôn ngữ không được hỗ trợ bởi LLM, việc giảm lỗi rõ ràng nhỏ hơn. Điều này xảy ra cho các treebank tài nguyên thấp, trong đó chỉ mBERT có thể đạt được cải thiện so với baseline rnd, mà còn cho các treebank tài nguyên cao, như Ancient Greek (treebank được kiểm tra lớn nhất), gợi ý rằng kích thước treebank không phải là yếu tố then chốt cho các probe (chúng tôi thảo luận điều này chi tiết §5.3).

Thiết lập Frozen (frz) vs fine-tuned (ftd) Bảng 4 hiển thị điểm cho các mô hình fine-tuned. Trong trường hợp này, các parser gán nhãn chuỗi xlm-roberta đạt được giảm lỗi trung bình lớn hơn, trong khi mbert đạt kết quả tốt hơn một chút cho thiết lập ftd. Kết quả cho thấy rằng ngay cả khi dưới thiết lập frz các cấu trúc phụ thuộc có thể được khôi phục, fine-tuning toàn bộ kiến trúc mang lại cải thiện đáng kể. Ngoài ra, hiệu suất trên toàn bộ cho các mô hình fine-tuned rất cạnh tranh cho tất cả treebank được hỗ trợ bởi LLM. Lưu ý rằng ngay cả khi các kết quả như vậy tụt lại phía sau state of the art (không phải mục tiêu của công việc chúng tôi), chúng tôi dựa hoàn toàn vào vector tiền huấn luyện đa ngữ, mà không có bất kỳ decoder parser mạnh mẽ nào, như Kitaev và Klein (2018) cho constituent parsing, hoặc Dozat et al. (2017) cho phụ thuộc.

So sánh mã hóa Kết quả từ Bảng 3 cho thấy rằng ba mã hóa có thể khôi phục lượng cú pháp tương tự. Đáng chú ý là, mặc dù rh hoạt động tốt hơn cho thiết lập rnd, điều này không dẫn đến khôi phục tốt hơn từ các biểu diễn frz. Có vẻ như 2pb cũng khôi phục nhiều thông tin cú pháp hơn trong các thiết lập tài nguyên cao hơn (tức là Bulgarian), trong khi rh và ahtb hoạt động tốt hơn trong các cấu hình tài nguyên thấp hơn (tức là Skolt Sami, Ligurian).

Dịch chuyển phụ thuộc Hình 4 hiển thị hiệu suất qua các cung có độ dài và hướng khác nhau cho các mô hình frz với mã hóa 2pb trên 4 ngôn ngữ: ngôn ngữ có nhiều cung trái nhất (Turkish), có nhiều cung phải nhất (Vietnamese), và hai ngôn ngữ cân bằng (Basque và Welsh). Các LLM đa ngữ nắm bắt các đặc thù của ngôn ngữ (đối với trường hợp treebank Welsh CCG, ngay cả khi nó cân bằng về số lượng cung trái/phải, các cung trái trung bình có khoảng cách 1.6 ±1.8 đơn vị trong khi các cung phải là 3.9 ±4.9 đơn vị). Ngoài ra, các LLM giữ xu hướng qua các dịch chuyển, tức là không có LLM nào thay đổi đáng kể hiệu suất dự kiến của chúng so với các LLM khác cho một tập con phụ thuộc cụ thể.

5.2 Kết quả constituent parsing

Chúng tôi chia nhỏ kết quả so sánh frozen vs: (i) random, và (ii) fine-tuned weights.

Thiết lập Frozen (frz) vs random weights (rnd) Bảng 5 hiển thị điểm F1 bracketing qua các treebank và mã hóa cho hai thiết lập. Xu hướng từ dependency parsing vẫn tiếp tục: mBERT vượt trội xlm-roberta cho tất cả ngôn ngữ, trong khi canine-s vượt trội canine-c. Trong trường hợp này, canine-s cải thiện so với baseline ngẫu nhiên cho tất cả treebank, trong khi canine-c chỉ vượt trội baseline ngẫu nhiên cho 3 trên 10 mô hình, gợi ý những khó khăn mà các mô hình ngôn ngữ cấp ký tự này gặp phải để mô hình hóa cú pháp, ngay cả khi chúng hoạt động tốt trên các task downstream khác. Các ngoại lệ là Korean, German và Chinese. Chinese cũng là một ngoại lệ trong trường hợp dependency parsing, vì vậy một lời giải thích có thể là hệ thống viết của nó mã hóa nhiều thông tin hơn mỗi ký tự so với các ngôn ngữ khác. Các ký tự Trung Quốc biểu diễn toàn bộ một morpheme, tương tự hơn với một token subword, trong khi Korean Hangul mã hóa một âm tiết mỗi ký tự, thay vì một âm đơn như các bảng chữ cái của các ngôn ngữ khác được kiểm tra.

Hình 5 hiển thị việc giảm lỗi trên toàn bộ, được sắp xếp theo kích thước của dữ liệu huấn luyện được sử dụng cho probing. Trong trường hợp này, tất cả các ngôn ngữ được kiểm tra đều được hỗ trợ bởi LLM, nhưng có sự khác biệt lớn về kích thước của dữ liệu huấn luyện (ví dụ, Swedish với 5 000 câu vs German với 40 472 câu). Tuy nhiên, chúng tôi không thấy sự gia tăng trong giảm lỗi khi kích thước dữ liệu huấn luyện tăng.

Thiết lập Frozen (frz) vs fine-tuned (ftd) Bảng 6 so sánh điểm F1 bracketing cho các thiết lập frozen và fine-tuned, và các hành vi tương tự với những gì đạt được trong trường hợp dependency parsing, ngoại trừ những gì trông giống như một số outlier thực nghiệm, ví dụ mBERT fine-tuned cho Hebrew. Hebrew cũng đạt được giảm lỗi thấp nhất cho tất cả LLM.

Độ dài span Vẽ biểu đồ điểm F1 cho mỗi độ dài span là lựa chọn thay thế thô cho dịch chuyển phụ thuộc trong bối cảnh constituent parsing. Trong Hình 6, chúng tôi một lần nữa hiển thị các ví dụ cụ thể cho một số ngôn ngữ được nghiên cứu: ngôn ngữ rẽ trái nhất (Korean), hai ngôn ngữ cân bằng (Basque và Hungarian), và ngôn ngữ rẽ phải nhất (English). Tương tự như trường hợp dependency parser, các xu hướng qua các mô hình tiếp tục qua các độ dài span khác nhau. Chúng cho thấy rằng, về LLM, mbert đạt điểm F1 cao nhất cho các span dài hơn, trong khi xlm-roberta cho thấy sự khác biệt lớn giữa các span ngắn hơn và dài hơn. Các mô hình canine hoạt động tệ hơn cho tất cả độ dài.

5.3 Thảo luận

Chúng tôi giờ đây thảo luận các insight chính và những hạn chế tiềm năng của framework đánh giá được đề xuất.

Dữ liệu tiền huấn luyện vs Dữ liệu đánh giá Một câu hỏi thú vị nảy sinh từ khôi phục đa ngữ là liệu probe có thể khôi phục các cây do kích thước của dữ liệu huấn luyện được sử dụng cho đánh giá, mặc dù về lý thuyết nó khó học bởi chính nó bởi một classifier ban đầu không biết gì (baseline ngẫu nhiên). Các thí nghiệm cho thấy bằng chứng rằng kích thước của dữ liệu huấn luyện không phải là yếu tố chính để thực hiện probing tuyến tính đa ngữ, đa formalism như gán nhãn chuỗi. Đối với constituent parsing, chúng tôi quan sát thấy rằng các treebank lớn hơn không đi kèm với sự gia tăng trong giảm lỗi giữa các thiết lập frozen và random, và rằng thí nghiệm đối chứng do đó có thể được sử dụng để đưa ra ước tính về lượng cấu trúc có thể khôi phục từ các biểu diễn tiền huấn luyện. Tương tự, trong bối cảnh dependency parsing, chúng tôi gặp phải tình huống tương tự. Mặc dù tồn tại các treebank cho các ngôn ngữ không được hỗ trợ bởi LLM, trải dài cả treebank lớn (Ancient Greek) và nhỏ (Skolt Sami hoặc Bhojpuri), chúng tôi quan sát thấy rằng kích thước treebank không ảnh hưởng đáng kể đến việc giảm lỗi giữa các thiết lập frozen và random.

Hoặc với dữ liệu lớn hoặc nhỏ, việc giảm lỗi giữa các mô hình ngẫu nhiên và frozen rõ ràng thấp hơn so với các treebank nơi ngôn ngữ được hỗ trợ bởi LLM. Trong số các treebank tài nguyên phong phú, kích thước của dữ liệu không có ảnh hưởng lớn đến việc giảm lỗi giữa các thiết lập trọng số ngẫu nhiên và frozen, gợi ý rằng kích thước dataset không ảnh hưởng đến các ước tính của cấu trúc phụ thuộc có thể khôi phục từ các biểu diễn.

Sự khác biệt mô hình ngôn ngữ Kết quả trên các LLM được kiểm tra gợi ý rằng tokenization subword cần thiết để biểu diễn cú pháp, trái ngược với các mô hình không có token, ngay cả khi chúng có thể sau đó hoạt động tốt trên các task downstream yêu cầu compositionality. Đặc biệt, không chỉ các mô hình dựa trên subword vượt trội so với các mô hình dựa trên ký tự, mà còn canine-s, được huấn luyện sử dụng loss subword mặc dù nó là một mô hình cấp ký tự, hoạt động tốt hơn đáng kể so với canine-c. Đáng chú ý rằng xlm-roberta thường vượt trội mBERT trong hầu hết các task downstream, bao gồm parsing, như các nghiên cứu trước đây đã chỉ ra (Conneau et al., 2020) và trong các kết quả fine-tuned của chúng tôi, nó hoạt động ngang bằng trên dependency parsing (Bảng 4) và vượt trội mBERT trong constituency parsing (Bảng 6). Tuy nhiên, cho thiết lập trọng số frozen, các biểu diễn của mBERT khôi phục các biểu diễn cú pháp tốt hơn một chút nhưng nhất quán. Điều này gợi ý rằng các cải thiện trong cách xlm-roberta được huấn luyện so với mBERT, ví dụ, huấn luyện trong thời gian dài hơn, hoặc nhiều dữ liệu hơn, không phải là yếu tố then chốt để mã hóa cú pháp tốt hơn. Ngoài ra, dựa trên các thí nghiệm của chúng tôi, có vẻ như mBERT thể hiện một mức độ thành thạo nhất định trong việc khôi phục thông tin cú pháp cho các treebank nhỏ nhất, đặc biệt là cho các ngôn ngữ không được bao gồm trong dữ liệu tiền huấn luyện (như Ligurian, Bhojpuri, và Kiche). Điều này gợi ý khả năng mở rộng kiến thức cú pháp của nó đến các ngôn ngữ chưa từng thấy trước đây, mặc dù ở mức độ hạn chế, không giống như các mô hình khác.

Formalism cú pháp Các nghiên cứu trước đây (ví dụ, Vilares et al. (2020)), giả định rằng các vector từ tiền huấn luyện có thể phù hợp hơn với các task dựa trên thành phần hơn là phụ thuộc, vì mục tiêu ngôn ngữ che khuất liên kết tốt hơn với formalism trước (tức là khi một mô hình đang học để làm mờ một token bị che khuất, cấu trúc thành phần ở một mức độ nào đó ngầm định (ví dụ, một tính từ bị thiếu giữa determiner và danh từ, tạo thành một cụm danh từ), trong khi các phụ thuộc ít rõ ràng hơn. Chúng tôi không thể tìm thấy bằng chứng rõ ràng về điều này. Mặc dù một số mô hình frz không thể vượt trội baseline rnd trong trường hợp phụ thuộc (trong khi điều này không xảy ra cho thành phần), các trường hợp này là các ngôn ngữ không có mặt trong dữ liệu tiền huấn luyện, ngoại trừ các mô hình canine.

6 Kết luận

Chúng tôi đã đề xuất một framework gán nhãn chuỗi để khôi phục cấu trúc cú pháp đa formalism từ các LLM đa ngữ. Bằng cách ánh xạ các cây cú pháp thành nhãn, chúng tôi đã liên kết vector từ đầu ra với các nhãn mã hóa một phần của cây, trong khi sử dụng một framework đánh giá duy nhất cho cả cấu trúc thành phần và phụ thuộc. Chúng tôi đã so sánh ba mô hình ngôn ngữ đa ngữ phổ biến. Kết quả cho thấy rằng các LLM subword có thể khôi phục một tỷ lệ phần trăm của các cấu trúc này. Chúng tôi đánh giá kết quả bằng cách tính toán việc giảm lỗi so với các mô hình đối chứng, nhằm mục đích đánh giá mức độ một LLM có thể khôi phục các cấu trúc cú pháp cụ thể. Đánh giá có vẻ đáng tin cậy và không bị ảnh hưởng bởi các biến như kích thước tập huấn luyện được sử dụng cho probing, làm nổi bật rằng dữ liệu tiền huấn luyện là một yếu tố quan trọng cho khả năng khôi phục. Cuối cùng, chúng tôi không tìm thấy bằng chứng rõ ràng rằng các vector ngữ cảnh hóa mã hóa cấu trúc thành phần tốt hơn phụ thuộc (cũng không ngược lại).

Hạn chế

Tài nguyên vật lý Chúng tôi không xem xét các mô hình ngôn ngữ lớn hơn vì chúng tôi không có quyền truy cập vào tài nguyên tính toán cần thiết để chạy chúng, do đó giới hạn phạm vi nghiên cứu của chúng tôi. Chúng tôi chỉ có quyền truy cập vào 2 GeForce RTX 3090, có tổng bộ nhớ GPU 48 GB, không đủ cho fine-tuning nhiều LLM trên các treebank và formalism khác nhau, như trong công việc này.

Đa dạng ngôn ngữ Các treebank thành phần được sử dụng đều từ các ngôn ngữ tương đối tài nguyên phong phú và có mặt trong dữ liệu tiền huấn luyện của LLM. Theo hiểu biết tốt nhất của chúng tôi, không có treebank thành phần có sẵn từ các ngôn ngữ tài nguyên thấp hơn cũng vắng mặt trong các LLM đa ngữ. Do đó, chúng tôi không thể kiểm tra hiệu ứng của sự vắng mặt của dữ liệu tiền huấn luyện để xem liệu các xu hướng thu được trong các treebank phụ thuộc có tồn tại ở đây không. Ngoài ra, cho dependency parsing, ngay cả một tài nguyên đa ngữ lớn như Universal Dependencies chỉ có dữ liệu cho khoảng 100 ngôn ngữ, một phần nhỏ của 7 000 ngôn ngữ con người hiện tại.

Giải thích Như đã đề cập trong phần giới thiệu, chúng ta phải cẩn thận khi đối phó với các framework probing. Mặc dù chúng tôi đã phát triển các thí nghiệm vững chắc, và cũng bao gồm các thí nghiệm đối chứng, kiến thức cú pháp khó cô lập, đo lường và giải thích, vì vậy chúng tôi đã cố gắng cẩn thận với các kết luận của mình.

Lời cảm ơn

Chúng tôi xin cảm ơn Hội đồng Nghiên cứu Châu Âu (ERC), đã tài trợ cho nghiên cứu này dưới chương trình nghiên cứu và đổi mới Horizon Europe (SALSA, thỏa thuận tài trợ số 101100615), ERDF/MICINN-AEI (SCANNER-UDC, PID2020-113230RB-C21), Xunta de Galicia (ED431C 2020/11), tài trợ FPI 2021 (PID2020-113230RB-C21) được tài trợ bởi MCIN/AEI/10.13039/501100011033, và Centro de Investigación de Galicia "CITIC", được tài trợ bởi Xunta de Galicia thông qua thỏa thuận hợp tác giữa Consellería de Cultura, Educación, Formación Profesional e Universidades và các trường đại học Galician để tăng cường các trung tâm nghiên cứu của Hệ thống Đại học Galician (CIGUS).

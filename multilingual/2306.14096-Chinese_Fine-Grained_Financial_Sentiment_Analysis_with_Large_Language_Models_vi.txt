# 2306.14096.pdf
# Đã chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/multilingual/2306.14096.pdf
# Kích thước tệp: 385209 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
Phân tích Tình cảm Tài chính Trung Quốc Tinh vi với Mô hình Ngôn ngữ Lớn
Yinyu Lan ,Yanru Wu∗,Wang Xu và Weiqiang Feng và Youhao Zhang
FinChina AI Research
lanyinyu19@mails.ucas.ac.cn, {wuyr, xuwang, fengwq, zhangyh }@finchina.com
Tóm tắt
Phân tích tình cảm tinh vi ở cấp độ thực thể trong lĩnh vực tài chính là một nhiệm vụ con quan trọng của phân tích tình cảm và hiện đang đối mặt với nhiều thách thức. Thách thức chính xuất phát từ việc thiếu các kho dữ liệu chú thích chất lượng cao và quy mô lớn được thiết kế đặc biệt cho phân tích tình cảm văn bản tài chính, điều này sau đó hạn chế tính khả dụng của dữ liệu cần thiết để phát triển các kỹ thuật xử lý văn bản hiệu quả. Những tiến bộ gần đây trong mô hình ngôn ngữ lớn (LLMs) đã mang lại hiệu suất đáng chú ý trong các nhiệm vụ xử lý ngôn ngữ tự nhiên, chủ yếu tập trung vào việc khớp mẫu ngôn ngữ. Trong bài báo này, chúng tôi đề xuất một bộ dữ liệu phân tích tình cảm tài chính tinh vi tiếng Trung mới và rộng lớn, FinChina SA, để cảnh báo sớm doanh nghiệp. Chúng tôi đánh giá và thử nghiệm kỹ lưỡng các LLMs mã nguồn mở nổi tiếng hiện có bằng bộ dữ liệu của chúng tôi. Chúng tôi tin chắc rằng bộ dữ liệu của chúng tôi sẽ phục vụ như một tài nguyên có giá trị để thúc đẩy khám phá các nhiệm vụ phân tích tình cảm tài chính thực tế, điều mà nên là trọng tâm nghiên cứu trong tương lai.1

1 Giới thiệu
Sự phát triển nhanh chóng của Internet và ngành tài chính đã dẫn đến sự phong phú của các báo cáo đánh giá cổ phiếu chuyên nghiệp, báo cáo nghiên cứu, và ý kiến cùng phân tích của các nhà đầu tư cá nhân trong lĩnh vực tài chính. Dù trong báo cáo tin tức hay bình luận về các chủ đề và công ty liên quan, những văn bản này thường cung cấp đánh giá và thái độ đối với các sự kiện và công ty có liên quan, mang lại những hiểu biết có giá trị cho đầu tư và quản lý. Hiểu biết toàn diện về thông tin đánh giá này có thể nâng cao hiểu biết thị trường của nhà đầu tư và hỗ trợ trong việc đưa ra quyết định đầu tư. Ngoài ra, các doanh nghiệp hoặc cơ quan quản lý thị trường tài chính có thể được hưởng lợi từ việc xác định sớm các vấn đề ẩn thông qua những đánh giá như vậy, giúp họ nắm bắt động thái thị trường và giảm thiểu rủi ro. Do đó, phân tích tình cảm của văn bản tài chính đã nổi lên như

∗Tác giả liên hệ
1Bộ dữ liệu FinChina SA được công khai tại https://github.com/YerayL/FinChina-SA.

OPPO đóng cửa hoạt động kinh doanh chip, chủ nhà nói: Hợp đồng gia hạn thuê mới được ký vào tháng 4, chưa nhận được thông báo hủy thuê
Ngày 15 tháng 5, công ty niêm yết Quỹ Huaan gần đây có kế hoạch mua Tòa nhà Zhangrun, và Công nghệ Zheku là người thuê quan trọng của tòa nhà này. Công ty này là công ty con của OPPO, diện tích thuê thực tế là 19.314,312 mét vuông, chiếm 45,7% diện tích có thể cho thuê của Tòa nhà Zhangrun.
......
Trong trường hợp hủy thuê, chủ nhà sẽ ngay lập tức bắt đầu công việc giới thiệu khách hàng có ý định thuê.

OPPO Công ty Truyền thông Di động Quảng Đông
OPPO Electronics Corp   Tiêu cực
Negative   Hạn chế phạm vi kinh doanh
Limit business scope
Công ty TNHH Công nghệ Zheku (Thượng Hải)
Zheku Technology
(Shanghai) Co., Ltd.

Công ty Quản lý Quỹ Hua An TNHH
Hua An Fund
Management Co.,Ltd.   Đặc biệt tiêu cực
Extremely negative
Trung tính
Neutral   Thanh lý phá sản
Liquidation
Loại không tiêu cực
Non-negative type

Hình 1: Một ví dụ về nhiệm vụ phân tích tình cảm tài chính để cảnh báo sớm doanh nghiệp. Font màu xanh lam chỉ ra các công ty liên quan trong tin tức. Font màu đỏ và xanh dương chỉ ra tính cực và loại cảnh báo tương ứng.

một lĩnh vực nghiên cứu và ứng dụng nổi bật. Nghiên cứu phân tích tình cảm tinh vi ở cấp độ thực thể văn bản trong lĩnh vực tài chính vẫn còn trong giai đoạn sơ khai, và nó cũng là một nhiệm vụ con quan trọng của phân tích tình cảm tinh vi [Pang et al., 2008], và hiện đang đối mặt với nhiều thách thức. Tuy nhiên, có sự thiếu hụt kho dữ liệu chú thích văn bản chất lượng cao và quy mô lớn trong lĩnh vực tài chính Trung Quốc, dẫn đến thiếu hỗ trợ dữ liệu cho công nghệ cơ bản.

Mô hình ngôn ngữ lớn đã thu hút nhiều sự chú ý trong lĩnh vực trí tuệ nhân tạo do khả năng ấn tượng của chúng trong việc giải quyết các nhiệm vụ xử lý ngôn ngữ tự nhiên. Đặc biệt, các mô hình ngôn ngữ lớn dựa trên đối thoại như ChatGPT đã có tác động lớn đến sự phát triển xã hội và đã đóng vai trò quan trọng cho việc ứng dụng trí tuệ nhân tạo trong cuộc sống hàng ngày, thu hút sự chú ý rộng rãi từ học thuật và công nghiệp. Tuy nhiên, nghiên cứu của chúng trong lĩnh vực cụ thể, chẳng hạn như lĩnh vực tài chính, vẫn còn tương đối khan hiếm. Cách sử dụng và đánh giá tốt hơn khả năng của mô hình ngôn ngữ lớn trong lĩnh vực dọc có thể giải quyết các vấn đề nghiên cứu cần được giải quyết khẩn cấp [Li et al., 2023].

Kể từ khi ChatGPT được phát hành, đã có ngày càng nhiều mô hình liên quan được phát triển và phát hành, dựa trên các mô hình LLaMA [Touvron et al., 2023] và BLOOM [Scao et al., 2022]. Nghiên cứu gần đây chủ yếu tập trung vào việc tận dụng hiệu quả các LLMs tổng quát cho việc tinh chỉnh có giám sát theo lĩnh vực cụ thể. Quá trình này bao gồm việc xây dựng một bộ dữ liệu ở định dạng hướng dẫn hoặc đối thoại và tinh chỉnh nó bằng mô hình backbone đã được huấn luyện trước. Đáng chú ý, cách huấn luyện này với dữ liệu nhỏ hơn đáng kể so với dữ liệu được sử dụng trong tiền huấn luyện có thể mang lại kết quả thuận lợi. Những công trình này có thể được phân loại thành hai loại riêng biệt [Chen et al., 2023]. Loại đầu tiên là tinh chỉnh dựa trên hướng dẫn, với Alpaca [Taori et al., 2023] đóng vai trò là một ví dụ nổi bật. Alpaca sử dụng kỹ thuật tự hướng dẫn [Wang et al., 2022] để tạo ra các hướng dẫn bổ sung cho việc tinh chỉnh mô hình GPT 3.5, dẫn đến độ chính xác tăng cao và đầu ra nhạy cảm với ngữ cảnh. Loại thứ hai bao gồm các mô hình tinh chỉnh dựa trên đối thoại tận dụng việc chưng cất các tương tác người dùng với ChatGPT. Vicuna [Chiang et al., 2023] minh họa cách tiếp cận này bằng cách sử dụng một bộ dữ liệu toàn diện về các cuộc đối thoại ChatGPT được chia sẻ bởi người dùng để cải thiện hiệu suất mô hình.

Nhằm giải quyết việc thiếu một bộ dữ liệu phân tích tình cảm tài chính tiếng Trung toàn diện và đáp ứng nhu cầu của doanh nghiệp về cảnh báo tin tức tiêu cực, chúng tôi đề xuất bộ dữ liệu FinChina SA được thiết kế đặc biệt cho lĩnh vực tài chính. Hình 1 minh họa một ví dụ về nhiệm vụ phân tích tình cảm tài chính để cảnh báo sớm doanh nghiệp. Ban đầu, chúng tôi tiến hành thu thập và làm sạch dữ liệu trên các trang web tin tức tài chính lớn. Tiếp theo, chúng tôi gắn nhãn tên công ty, tính cực tình cảm và loại cảnh báo trong dữ liệu đã thu thập. Tổng cộng 11.036 bài báo tin tức được chú thích, bao gồm 8.739 công ty, 190 loại cảnh báo, và 21.272 ví dụ tình cảm tương ứng. Để khám phá ứng dụng của LLMs trong lĩnh vực tài chính, chúng tôi tiến hành nghiên cứu và thử nghiệm rộng rãi trên bộ dữ liệu FinChina SA. Chúng tôi huấn luyện những mô hình này bằng kỹ thuật tinh chỉnh dựa trên hướng dẫn và tinh chỉnh dựa trên đối thoại. Kết quả thử nghiệm chứng minh hiệu suất đầy hứa hẹn của các LLMs tài chính (FinLLMs) và sự hạn chế của ChatGPT trong các nhiệm vụ phân tích tình cảm tài chính.

Những đóng góp của bài báo này như sau: (1) Chúng tôi đề xuất FinChina SA, một bộ dữ liệu quy mô lớn mới được thiết kế cho phân tích tình cảm tinh vi trong lĩnh vực tài chính tiếng Trung. (2) Chúng tôi đánh giá và phân tích khả năng và hạn chế của ChatGPT trong thiết lập zero-shot cho phân tích tình cảm tài chính tinh vi. (3) Chúng tôi so sánh và phân tích khả năng của các LLMs mã nguồn mở nổi tiếng hiện có trên benchmark và thảo luận về tính khả thi và triển vọng phát triển FinLLMs.

2 Công trình Liên quan
Sau khi xem xét toàn diện nghiên cứu liên quan đến phân tích tình cảm tài chính tinh vi (Phần 2.1) và mô hình ngôn ngữ lớn (Phần 2.2), chúng tôi đi sâu vào thảo luận về tinh chỉnh có giám sát của LLMs (Phần 2.3).

2.1 Phân tích Tình cảm Tài chính Tinh vi
Phân tích tình cảm tinh vi là một nhiệm vụ quan trọng với các ứng dụng thực tế đáng kể. Tuy nhiên, có sự khan hiếm các nghiên cứu tập trung vào phân tích tình cảm tinh vi ở cấp độ thực thể trong lĩnh vực tài chính, đặc biệt do thiếu các bộ dữ liệu có sẵn. Hạn chế này đặt ra thách thức cho việc tiến hành nghiên cứu trong nhiệm vụ này. [Cortis et al., 2017] đã phân tích các phương pháp và công cụ được sử dụng bởi hơn 30 người tham gia trong hội nghị SemEval-2017 về "Phân tích Tình cảm của Microblog và Tin tức Tài chính." Đa số người tham gia dựa vào các mô hình máy học truyền thống như SVM và SVR. [Do et al., 2019] nhấn mạnh tính chất đòi hỏi của việc gắn nhãn dữ liệu trong lĩnh vực tài chính, nhấn mạnh nhu cầu về chuyên môn lĩnh vực và chi phí cao liên quan. Do đó, dữ liệu được gắn nhãn có sẵn rất hạn chế. [Maia et al., 2018] đã công bố một bộ dữ liệu nhỏ có tên FiQA, bao gồm các thể hiện văn bản trong lĩnh vực tài chính. Bộ dữ liệu cũng bao gồm các thực thể được tham chiếu trong văn bản, với điểm số tình cảm tương ứng được gán cho mỗi thực thể.

2.2 Mô hình Ngôn ngữ Lớn
Việc giới thiệu mô hình transformer [Vaswani et al., 2017] đã cho phép việc huấn luyện dữ liệu văn bản không giám sát ở quy mô lớn. Trong vài năm qua, các mô hình dựa trên encoder, chẳng hạn như BERT [Devlin et al., 2018], đã thể hiện khả năng ấn tượng trong các nhiệm vụ xử lý ngôn ngữ tự nhiên (NLP) khác nhau. Gần đây hơn, các mô hình dựa trên decoder, bao gồm GPT-1 [Radford et al., 2018], GPT-2 [Radford et al., 2019], và T5 [Raffel et al., 2020], đã có những tiến bộ đáng kể. Với số lượng tham số mô hình ngày càng tăng, các mô hình như GPT-3 [Brown et al., 2020], thường được gọi là LLMs, đã dần thu được khả năng học zero-shot. Những mô hình này có thể tạo ra phản hồi dựa trên hướng dẫn mà không dựa vào ví dụ. Hơn nữa, [Wu et al., 2023] gần đây đã đề xuất một mô hình độc quyền, BloombergGPT, trong lĩnh vực tài chính, tập trung chủ yếu vào tiền huấn luyện. Một mô hình ngôn ngữ lớn mã nguồn mở, FinGPT, được đề xuất bởi [Yang et al., 2023]. Nó áp dụng cách tiếp cận tập trung vào dữ liệu, cung cấp cho các nhà nghiên cứu và thực hành các tài nguyên có thể tiếp cận và minh bạch để phát triển FinLLMs của họ.

2.3 Tinh chỉnh Có giám sát
Hiện tại, các phương pháp hậu huấn luyện được sử dụng trong tinh chỉnh có giám sát của LLMs có thể được phân loại thành tinh chỉnh dựa trên hướng dẫn và tinh chỉnh dựa trên đối thoại [Chen et al., 2023]. Tinh chỉnh hướng dẫn nhằm huấn luyện mô hình ngôn ngữ tuân thủ hướng dẫn của con người [Ouyang et al., 2022], có thể được thiết kế thủ công hoặc tạo ra theo cách hỗn hợp trong đó con người cung cấp hướng dẫn ban đầu và OpenAI ChatGPT tạo ra các hướng dẫn tương tự bổ sung bằng cách sử dụng học trong ngữ cảnh [Wang et al., 2022]. Mô hình ngôn ngữ được dạy tham gia vào các cuộc đối thoại dựa trên chat tương tự như OpenAI ChatGPT thông qua việc sử dụng các cuộc đối thoại được chưng cất từ ChatGPT, trong khi dữ liệu hướng dẫn thường được sử dụng cho hỏi đáp một lượt (QA). Một ví dụ đáng chú ý của cách tiếp cận này là Alpaca [Taori et al., 2023], sử dụng kỹ thuật tự hướng dẫn để tạo ra các hướng dẫn bổ sung bằng mô hình GPT 3.5 cho tinh chỉnh. Điều này dẫn đến độ chính xác được cải thiện và đầu ra phù hợp với ngữ cảnh. Loại thứ hai

--- TRANG 3 ---
500 1000 1500 2000 2500 3000 3500
Độ dài văn bản tin tức020040060080010001200140016001800

Hình 2: Phân bố độ dài văn bản tin tức.

bao gồm các mô hình tinh chỉnh dựa trên đối thoại tận dụng việc chưng cất các tương tác người dùng với ChatGPT. Vicuna [Chiang et al., 2023] là một mô hình mẫu trong loại này, được hưởng lợi từ các bộ dữ liệu đối thoại được chia sẻ rộng rãi bởi người dùng để nâng cao hiệu suất mô hình.

3 Thu thập Dữ liệu
Để xây dựng một bộ dữ liệu phân tích tình cảm toàn diện trong lĩnh vực tài chính, chúng tôi đã tuyển dụng một đội ngũ 20 người gắn nhãn chuyên về các môn học liên quan đến tài chính. Ban đầu, chúng tôi chọn 11.036 bài báo tin tức chất lượng cao đại diện từ một nhóm 288.788 bài báo tin tức đã thu thập. Những bài báo này đóng vai trò là cơ sở cho việc gắn nhãn. Mỗi người gắn nhãn đã gắn nhãn trước 2.500 mẫu dữ liệu, và chúng tôi so sánh các kết quả gắn nhãn tương ứng trong quá trình gắn nhãn. Chúng tôi ghi lại những khác biệt và sự mơ hồ và sử dụng chúng để xây dựng các hướng dẫn gắn nhãn toàn diện cho các thực thể và ngữ cảnh khác nhau có tính mơ hồ hoặc xung đột. Trong giai đoạn gắn nhãn, mỗi văn bản tin tức được xem xét độc lập bởi tối thiểu 5 người gắn nhãn. Đáng chú ý rằng các người gắn nhãn không tham gia giao tiếp trong quá trình gắn nhãn và chỉ dựa vào các hướng dẫn đã thiết lập. Sau khi hoàn thành việc gắn nhãn độc lập, bất kỳ sự khác biệt hoặc lỗi nào trong kết quả gắn nhãn đã được giải quyết thông qua các cuộc thảo luận có sự tham gia của một người gắn nhãn bổ sung. Mục tiêu là đạt được sự đồng thuận giữa tất cả người gắn nhãn, dẫn đến các sửa đổi trong dữ liệu được gắn nhãn và việc hoàn thành cuối cùng của quá trình gắn nhãn.

Trong số 21.272 công ty liên quan, 6.991 có tình cảm tích cực, trong khi 14.281 có tình cảm tiêu cực. Các phát hiện thống kê cụ thể được trình bày trong Bảng 1 và Hình 2. Do phân tích tình cảm của chúng tôi chủ yếu tập trung vào cảnh báo sớm doanh nghiệp, chúng tôi đặc biệt chú trọng vào cảm xúc tiêu cực. Để phân loại thêm cảm xúc tiêu cực, chúng tôi chia chúng thành ba cấp độ: cực kỳ tiêu cực, rất tiêu cực, và tiêu cực. Trong số các tình cảm tiêu cực, có 225 trường hợp cực kỳ tiêu cực, 1.886 trường hợp tiêu cực cao, và 1.170 trường hợp tiêu cực thông thường.

Bảng 1: Thống kê của bộ dữ liệu FinChina SA
Thống kê   Số lượng
# Văn bản tin tức   11.036
# Công ty   8.739
# Tình cảm   21.272
# Tình cảm không tiêu cực   6.991
# Tình cảm tiêu cực   14.281
# Loại cảnh báo sớm   190
Độ dài văn bản tin tức tối đa   3.540
Độ dài văn bản tin tức tối thiểu   411
Độ dài văn bản tin tức trung bình   1.357

4 Mô hình
Các phần 4.1-4.5 giới thiệu chi tiết các mô hình ngôn ngữ đã được huấn luyện trước được sử dụng trong thử nghiệm của chúng tôi, bao gồm các mô hình như Longformer, LLaMA, BLOOM, ChatGLM và ChatGPT.

4.1 Longformer
Để so sánh với các mô hình đã được huấn luyện trước trước đây có ít tham số hơn, chúng tôi sử dụng mô hình Longformer [Beltagy et al., 2020]. Longformer có thể xử lý các chuỗi lên đến 4.096 token bằng cách sử dụng cơ chế attention mở rộng tuyến tính với độ dài văn bản đầu vào, khác với hành vi bậc hai trong các mô hình Transformer trước đó như BERT [Devlin et al., 2018]. Xem xét độ dài tài liệu tối đa trong kho dữ liệu của chúng tôi (hơn 3.540 từ, xem Bảng 1), chúng tôi coi mô hình Longformer là một baseline phù hợp. Mô hình Longformer được sử dụng để xử lý 4.096 token đầu tiên của mỗi tài liệu, và đầu ra pooled 768 chiều được giữ lại làm biểu diễn tài liệu. Biểu diễn này sau đó được đưa vào hai mạng neural phân loại feed-forward để dự đoán xác suất cho tất cả các tính cực tình cảm và loại cảnh báo. Trọng số Longformer trải qua tinh chỉnh bổ sung trong quá trình huấn luyện cho nhiệm vụ phân loại của chúng tôi. Vì bộ dữ liệu của chúng tôi bằng tiếng Trung, chúng tôi sử dụng Longformer-chinese2 được huấn luyện trước trên kho dữ liệu tin tức tiếng Trung.

4.2 LLaMA
LLaMA [Touvron et al., 2023] là một bộ sưu tập các mô hình cơ sở đa ngôn ngữ mã nguồn mở với kích thước tham số từ 7 tỷ đến 65 tỷ, được cung cấp cho cộng đồng nghiên cứu. Tuy nhiên, mô hình LLaMA-7B gốc thiếu kho dữ liệu tiếng Trung trong quá trình tiền huấn luyện, dẫn đến việc không có từ vựng tiếng Trung. Do đó, chúng tôi sử dụng mô hình Chinese LLaMA [Cui et al., 2023], đã tích hợp từ vựng tiếng Trung mở rộng, và tiến hành huấn luyện trước thứ cấp bằng kho dữ liệu chung tiếng Trung 120G được gọi là Chinese LLaMA plus [Cui et al., 2023]. Mô hình Chinese LLaMA nâng cao đáng kể khả năng hiểu và tạo ra nội dung tiếng Trung của LLaMA gốc.

4.3 BLOOM
BLOOM [Scao et al., 2022] là một mô hình ngôn ngữ lớn tự hồi quy được huấn luyện trên một kho dữ liệu văn bản lớn với sự hỗ trợ của tài nguyên tính toán quy mô công nghiệp. Do đó, nó có thể tạo ra văn bản mạch lạc bằng 46 ngôn ngữ, bao gồm 13 ngôn ngữ lập trình, có tính so sánh cao với văn bản do con người viết. Hơn nữa, BLOOM có thể được chỉ đạo để thực hiện các nhiệm vụ văn bản mà nó chưa nhận được huấn luyện rõ ràng, bằng cách đóng khung chúng như các bài tập tạo văn bản. Trong thử nghiệm của chúng tôi, chúng tôi sử dụng BLOOMZ [Muennighoff et al., 2022], một phiên bản được tinh chỉnh đa nhiệm vụ có prompt của BLOOM, với khả năng tổng quát hóa và zero-shot tốt hơn.

4.4 ChatGLM
ChatGLM là một mô hình ngôn ngữ đối thoại mã nguồn mở hỗ trợ cả tiếng Trung và tiếng Anh. Nó dựa trên kiến trúc General Language Model (GLM) [Du et al., 2022; Zeng et al., 2022] và bao gồm 6,2 tỷ tham số. Với sự hỗ trợ của công nghệ lượng tử hóa mô hình, người dùng có thể triển khai ChatGLM-6B trên card đồ họa cấp người tiêu dùng với ít nhất 6GB bộ nhớ video khi sử dụng mức lượng tử hóa INT4. ChatGLM sử dụng công nghệ tương tự như ChatGPT, được tối ưu hóa đặc biệt cho các tương tác hỏi đáp (Q&A) và đối thoại tiếng Trung. Với khoảng 1 nghìn tỷ token song ngữ Trung-Anh, được hỗ trợ bởi các kỹ thuật khác nhau như giám sát, tinh chỉnh, và học tăng cường phản hồi của con người, ChatGLM-6B có khả năng tạo ra phản hồi phù hợp chặt chẽ với sở thích của con người.

4.5 ChatGPT
ChatGPT là một mô hình anh em với InstructGPT [Ouyang et al., 2022], được thiết kế đặc biệt để tuân theo hướng dẫn của người dùng và tạo ra phản hồi chi tiết. ChatGPT được nâng cao thông qua tinh chỉnh hướng dẫn [Wei et al., 2021] và học tăng cường từ phản hồi của con người (RLHF) [Ouyang et al., 2022]. Khác với GPT-3 gốc, thiếu thiết kế cụ thể để tuân theo hướng dẫn của người dùng, ChatGPT thể hiện khả năng được cải thiện đáng kể để tạo ra đầu ra phù hợp và hữu ích đáp ứng hướng dẫn của người dùng. ChatGPT đã được sử dụng rộng rãi trong các kịch bản trí tuệ nhân tạo đa dạng, chẳng hạn như hỏi đáp dựa trên tìm kiếm, các nhiệm vụ NLP cơ bản, v.v.

5 Thử nghiệm và Phân tích
5.1 Định nghĩa Nhiệm vụ
Chúng tôi bắt đầu bằng việc định nghĩa nhiệm vụ phân tích tình cảm tài chính tinh vi cho cảnh báo sớm doanh nghiệp, trước khi giới thiệu các thử nghiệm của chúng tôi. Cho một văn bản tin tức s với một chuỗi từ {w1, w2, ...wn} và tên của tất cả các công ty {I1, I2, ...In} liên quan trong câu này, mục tiêu là dự đoán tính cực và loại cảnh báo sớm của chúng.

5.2 Xây dựng Bộ dữ liệu
Theo hai dạng phương pháp tinh chỉnh có giám sát khác nhau, tinh chỉnh hướng dẫn và tinh chỉnh đối thoại, chúng tôi xây dựng bộ dữ liệu thành hai dạng QA một lượt và QA nhiều lượt. Cụ thể, trong một vòng QA, mô hình sẽ được yêu cầu trả lời tính cực tình cảm và loại cảnh báo của tất cả công ty cùng một lúc. Trong nhiều vòng QA, nhiệm vụ sẽ được phân tách thành nhiều nhiệm vụ con. Trong mỗi nhiệm vụ con, mô hình sẽ trả lời tính cực hoặc loại cảnh báo của một công ty, và mô hình sẽ hoàn thành tất cả các nhiệm vụ con theo thứ tự. Bộ dữ liệu được chia thành 90% cho huấn luyện và 10% cho kiểm tra.

--- TRANG 4 ---
假设你是一个金融领域的细粒度情感分析模型，我会给你一些机构名称、情感极性列表、预警类型列表，和与这些机构相关的一篇新闻报道，请分析这些机构属于情感极性中的哪一种，并进一步判断属于哪一个预警类型。注意结果不能为空，不要回答多余的话。
Giả sử bạn là một mô hình phân tích tình cảm tinh vi trong lĩnh vực tài chính. Tôi sẽ cung cấp cho bạn một số tên tổ chức, danh sách tính cực tình cảm, danh sách loại cảnh báo, và một báo cáo tin tức liên quan đến những tổ chức này. Hãy phân tích những tổ chức này thuộc loại tính cực tình cảm nào và xác định thêm thuộc loại cảnh báo nào. Lưu ý kết quả không được để trống, đừng trả lời những từ thừa.

机构名称：[机构名称1, 机构名称2, ...]
Tên tổ chức: [tên_tổ_chức_1, tên_tổ_chức_2, ...]

情感极性：[积极, 中性, 消极, 很消极, 特别消极]
Tính cực tình cảm: [Tích cực, Trung tính, Tiêu cực, Rất tiêu cực, Cực kỳ tiêu cực]

预警类型：[产品召回, 操纵证券市场, 环保不达标, ...]
Loại cảnh báo: [Thu hồi sản phẩm, Thao túng thị trường chứng khoán, Không đạt tiêu chuẩn môi trường, ...]

新闻文本：A股股权激励，实控人父子拿下近两成份额！监管部门：是否利益输送......
Văn bản tin tức: Khuyến khích vốn chủ sở hữu A-share, cha con người kiểm soát thực tế giành được gần 20% cổ phần! Cơ quan quản lý: có phải chuyển giao lợi ích...

请用三元组列表的形式（[(机构名称1, 情感极性1, 预警类型1), (机构名称2, 情感极性2, 预警类型2), ...]）进行回答。
Hãy trả lời dưới dạng danh sách bộ ba ([(tên_tổ_chức_1, tính_cực_tình_cảm_1, loại_cảnh_báo_1), (tên_tổ_chức_2, tính_cực_tình_cảm_2, loại_cảnh_báo_2), ...]).

Hình 3: Minh họa mẫu prompt được sử dụng trong thử nghiệm của chúng tôi cho ChatGPT

2https://github.com/SCHENLIU/longformer-chinese

--- TRANG 5 ---
Bảng 2: Kết quả thử nghiệm trên bộ dữ liệu FinChina SA. Mô hình Longformer được tinh chỉnh bằng tập huấn luyện gốc. Các mô hình ngôn ngữ lớn ở dòng hai đến sáu được tinh chỉnh bằng tập huấn luyện dạng QA một lượt. Mô hình ChatGPT dự đoán kết quả phân loại trong thiết lập zero-shot.

Mô hình   Phân loại Tình cảm   Loại Cảnh báo
   Độ chính xác   Weighted F1   Độ chính xác   Weighted F1
1 Longformer   67.45   66.61   54.80   53.76
2 BLOOMZ   75.52   74.97   66.27   66.29
3 Chinese LLaMA   68.67   67.43   55.98   53.63
4 Chinese LLaMA Plus   75.99   75.59   67.09   67.13
5 ChatGLM(P-tuning v2)   69.48   68.44   52.13   50.75
6 ChatGLM   74.76   73.53   65.78   64.08
7 ChatGPT   46.80   47.43   18.17   18.30

Bảng 3: Kết quả thử nghiệm của các mô hình được tinh chỉnh với dữ liệu dạng QA nhiều lượt.

Mô hình   Phân loại Tình cảm   Loại Cảnh báo
   Độ chính xác   Weighted F1   Độ chính xác   Weighted F1
1 BLOOMZ   70.14   72.04   61.69   61.80
2 Chinese LLaMA Plus   71.30   73.42   60.05   61.75
3 ChatGLM   69.56   70.08   59.40   58.69

5.3 Chi tiết Huấn luyện
Các mô hình được triển khai trong PyTorch bằng gói Huggingface Transformers. Cần lưu ý rằng, ngoài mô hình Longformer, chúng tôi chọn một phiên bản với tham số khoảng 7B cho các mô hình ngôn ngữ lớn mã nguồn mở, và tất cả đều có liên kết đến trọng số mô hình gốc trong chú thích cuối345. Độ dài ngữ cảnh tối đa được đặt là 4.096. Các mô hình được huấn luyện với bộ tối ưu hóa AdamW, sử dụng kích thước batch 32 và 3 epoch. Tốc độ học được đặt là 2e-5, và weight decay được đặt là 0. Chúng tôi sử dụng các công nghệ như DeepSpeed ZeRO [Rajbhandari et al., 2020] và FSDP [Zhao et al., 2023] để tối ưu hóa việc huấn luyện song song của các mô hình. Chúng tôi đánh giá khả năng ChatGPT theo cách zero-shot bằng bộ dữ liệu của chúng tôi. Hình 3 cho thấy minh họa mẫu prompt được sử dụng trong thử nghiệm của chúng tôi cho ChatGPT. Đối với mô hình Longformer, hai lớp kết nối đầy đủ được kết nối để thực hiện phân loại, và hàm mất mát là cross entropy.

5.4 Kết quả Thử nghiệm
Bảng 2 và bảng 3 trình bày kết quả thử nghiệm trên bộ dữ liệu của chúng tôi. Để tinh chỉnh các mô hình ngôn ngữ lớn, chúng tôi tiền xử lý tập huấn luyện thành hai dạng: QA một lượt và QA nhiều lượt. Đầu vào sẽ bao gồm hướng dẫn nhiệm vụ, ngữ cảnh, và câu hỏi. Một câu trả lời một lượt nên kết hợp tính cực và loại cảnh báo của tất cả công ty cùng một lúc. Trong dạng QA nhiều lượt, tính cực hoặc loại cảnh báo của một công ty được giải quyết trong một vòng đối thoại cho đến khi tất cả kết quả được bao phủ.

Như được thể hiện trong bảng 2, mô hình Longformer được tinh chỉnh bằng tập huấn luyện gốc. Các mô hình ở dòng hai đến sáu được tinh chỉnh bằng tập huấn luyện dạng QA một lượt. Mô hình ChatGPT dự đoán kết quả phân loại bằng phương pháp dựa trên prompt trong thiết lập zero-shot. Bảng cho thấy rằng Chinese LLaMA Plus vượt trội hơn các mô hình khác trong bộ dữ liệu. Kết quả thử nghiệm chứng minh rằng việc tận dụng một kho dữ liệu tiếng Trung đáng kể cho huấn luyện trước thứ cấp nâng cao đáng kể khả năng hiểu và tạo ra tiếng Trung của LLaMA. Trong nhiệm vụ phân loại tình cảm, Chinese LLaMA Plus đạt độ chính xác cao nhất 75.99, tiếp theo là BLOOMZ với 75.52 và ChatGLM với 74.46. Nhiệm vụ phân loại loại cảnh báo khác thể hiện khoảng cách hiệu suất tương tự giữa tất cả các mô hình.

Đáng chú ý rằng ChatGPT gặp khó khăn với nhiệm vụ phân tích tình cảm tài chính trong thiết lập zero-shot. Kết quả này cho thấy ChatGPT không thành thạo trong việc hiểu các khái niệm tài chính. Rõ ràng, ChatGPT đối mặt với thách thức trong việc kết nối các tuyên bố với tình cảm con người trong tin tức tài chính, có thể do thiếu kiến thức lĩnh vực. Khác với các nhiệm vụ khác, nơi một mô hình có thể truy xuất thông tin từ ngữ cảnh và liên kết các thao tác để đạt được đầu ra cuối cùng, nhiệm vụ phân tích tình cảm đòi hỏi hiểu biết sâu hơn về các biểu hiện cụ thể của lĩnh vực và kiến thức tình cảm cơ bản. Mức độ hiểu biết như vậy đặt ra thách thức cho các mô hình như ChatGPT, có thể có sự tiếp xúc hạn chế với kho dữ liệu huấn luyện cụ thể của lĩnh vực. Các LLMs đạt hiệu suất vượt trội so với mô hình Longformer sau khi tinh chỉnh, chứng minh khả năng của các mô hình ngôn ngữ tạo sinh tổng quát chuyển giao hiệu quả sang các lĩnh vực cụ thể. Hơn nữa, trong khi các phương pháp tinh chỉnh tham số hiệu quả như P-tuning v2 giảm sử dụng bộ nhớ video, thử nghiệm của chúng tôi chỉ ra sự giảm đáng kể trong

3https://github.com/ymcui/Chinese-LLaMA-Alpaca
4https://github.com/THUDM/ChatGLM-6B
5https://huggingface.co/bigscience/bloomz-7b1-mt

--- TRANG 6 ---
độ chính xác của mô hình.

Trong bộ dữ liệu dạng QA nhiều lượt, chúng tôi áp dụng cách tiếp cận theo lượt. Sau mỗi lượt, chúng tôi thu thập câu trả lời được tạo bởi các mô hình, thêm nó vào câu hỏi trước đó, và sử dụng đầu vào kết hợp này làm prompt cho vòng tiếp theo. Kết quả, như được trình bày trong Bảng 3, chỉ ra rằng việc chuyển đổi dữ liệu hướng dẫn một lượt thành định dạng QA nhiều lượt và sau đó tinh chỉnh LLMs có thể không có lợi cho việc cải thiện hiệu suất. Thông qua kiểm tra kỹ lưỡng các kết quả thử nghiệm, chúng tôi phát hiện rằng việc huấn luyện mô hình với đối thoại nhiều vòng tăng khả năng tạo ra nội dung lặp lại và sai lầm trong giai đoạn suy luận. Một khả năng là việc tinh chỉnh mô hình thông qua các cách tiếp cận dựa trên đối thoại phù hợp hơn cho dữ liệu gần giống với đối thoại thực tế. Ngược lại, việc chuyển đổi dữ liệu đối thoại nhiều vòng bằng cách sử dụng mẫu dẫn đến một định dạng tương đối đơn giản và ít đa dạng hơn. Chúng tôi để lại như công việc tương lai để thu thập thêm dữ liệu đối thoại tài chính thực và đánh giá thêm các nhiệm vụ tài chính.

6 Kết luận và Công việc Tương lai
Bộ dữ liệu mới của chúng tôi, FinChina SA, sẽ phục vụ như một trong những hướng chính cho trọng tâm nghiên cứu tiếp theo – cách áp dụng LLMs trong lĩnh vực tài chính. Chúng tôi đã thử nghiệm với các mô hình ngôn ngữ lớn đã được huấn luyện trước khác nhau và phát hiện rằng các LLMs được tinh chỉnh thể hiện ấn tượng trong các nhiệm vụ phân tích tình cảm, vượt trội hơn hiệu suất của mô hình Longformer được tinh chỉnh. Tuy nhiên, ChatGPT thể hiện những hạn chế trong nhiệm vụ này, cần xử lý kiến thức và thuật ngữ cụ thể của lĩnh vực. Trong khi ChatGPT hoạt động tốt trong các nhiệm vụ NLP chung, hiệu quả của nó trong lĩnh vực tài chính không thể so sánh với các mô hình chuyên biệt được tinh chỉnh đặc biệt cho các nhiệm vụ tài chính. Tóm lại, ChatGPT cung cấp nền tảng vững chắc cho các nhiệm vụ NLP liên quan đến tài chính. Tuy nhiên, các cải tiến thêm có thể nâng cao hiệu suất của nó. Ngoài ra, việc chuyển đổi dữ liệu hướng dẫn một lượt thành dạng QA nhiều lượt và sau đó tinh chỉnh LLMs có thể không hữu ích để cải thiện hiệu suất. Các phương pháp tinh chỉnh tham số hiệu quả, chẳng hạn như P-tuning v2, giảm tiêu thụ bộ nhớ, nhưng trong thử nghiệm của chúng tôi giảm đáng kể độ chính xác của mô hình.

Do hạn chế chi phí của ChatGPT API và huấn luyện LLMs, chúng tôi chỉ kiểm tra các LLMs mã nguồn mở với khoảng 7B tham số trên dữ liệu tương đối nhỏ, và chúng tôi không tiến hành thử nghiệm rộng rãi về kỹ thuật prompt phức tạp cho ChatGPT. Chúng tôi tin rằng thử nghiệm của chúng tôi có thể cung cấp những hiểu biết có giá trị về nhiệm vụ phân tích tình cảm trên các lĩnh vực cụ thể thực tế và tạo điều kiện cho các cải tiến thêm. Trong khi đó, chúng tôi không loại trừ khả năng có thể có hiệu suất tốt hơn cho các phương pháp dựa trên prompting nếu áp dụng kỹ thuật prompt tiên tiến hoặc GPT-4, tốn kém hơn. Chúng tôi để lại điều này cho công việc tương lai. Chúng tôi dự định thử nhiều LLMs mã nguồn mở với tham số lớn hơn và phát hành bộ dữ liệu lĩnh vực tài chính lớn hơn trong tương lai.

Tài liệu tham khảo
[Beltagy et al., 2020] Iz Beltagy, Matthew E. Peters, và Arman Cohan. Longformer: The long-document transformer. arXiv:2004.05150, 2020.

[Brown et al., 2020] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are few-shot learners. Advances in neural information processing systems, 33:1877–1901, 2020.

[Chen et al., 2023] Zhihong Chen, Feng Jiang, Junying Chen, Tiannan Wang, Fei Yu, Guiming Chen, Hongbo Zhang, Juhao Liang, Chen Zhang, Zhiyi Zhang, et al. Phoenix: Democratizing chatgpt across languages. arXiv preprint arXiv:2304.10453, 2023.

[Chiang et al., 2023] Wei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng, Zhanghao Wu, Hao Zhang, Lianmin Zheng, Siyuan Zhuang, Yonghao Zhuang, Joseph E. Gonzalez, Ion Stoica, và Eric P. Xing. Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality, March 2023.

[Cortis et al., 2017] Keith Cortis, André Freitas, Tobias Daudert, Manuela Huerlimann, Manel Zarrouk, Siegfried Handschuh, và Brian Davis. Semeval-2017 task 5: Fine-grained sentiment analysis on financial microblogs and news. In Proceedings of the 11th international workshop on semantic evaluation (SemEval-2017), pages 519–535, 2017.

[Cui et al., 2023] Yiming Cui, Ziqing Yang, và Xin Yao. Efficient and effective text encoding for chinese llama and alpaca. arXiv preprint arXiv:2304.08177, 2023.

[Devlin et al., 2018] Jacob Devlin, Ming-Wei Chang, Kenton Lee, và Kristina Toutanova. Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805, 2018.

[Do et al., 2019] Hai Ha Do, Penatiyana WC Prasad, Angelika Maag, và Abeer Alsadoon. Deep learning for aspect-based sentiment analysis: a comparative review. Expert systems with applications, 118:272–299, 2019.

[Du et al., 2022] Zhengxiao Du, Yujie Qian, Xiao Liu, Ming Ding, Jiezhong Qiu, Zhilin Yang, và Jie Tang. Glm: General language model pretraining with autoregressive blank infilling. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 320–335, 2022.

[Li et al., 2023] Xianzhi Li, Xiaodan Zhu, Zhiqiang Ma, Xiaomo Liu, và Sameena Shah. Are chatgpt and gpt-4 general-purpose solvers for financial text analytics? an examination on several typical tasks. arXiv preprint arXiv:2305.05862, 2023.

[Maia et al., 2018] Macedo Maia, Siegfried Handschuh, André Freitas, Brian Davis, Ross McDermott, Manel Zarrouk, và Alexandra Balahur. Www'18 open challenge: financial opinion mining and question answering. In Companion proceedings of the the web conference 2018, pages 1941–1942, 2018.

[Muennighoff et al., 2022] Niklas Muennighoff, Thomas Wang, Lintang Sutawika, Adam Roberts, Stella Biderman, Teven Le Scao, M Saiful Bari, Sheng Shen, Zheng-

--- TRANG 7 ---
Xin Yong, Hailey Schoelkopf, et al. Crosslingual generalization through multitask finetuning. arXiv preprint arXiv:2211.01786, 2022.

[Ouyang et al., 2022] Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. Training language models to follow instructions with human feedback. Advances in Neural Information Processing Systems, 35:27730–27744, 2022.

[Pang et al., 2008] Bo Pang, Lillian Lee, et al. Opinion mining and sentiment analysis. Foundations and Trends® in information retrieval, 2(1–2):1–135, 2008.

[Radford et al., 2018] Alec Radford, Karthik Narasimhan, Tim Salimans, Ilya Sutskever, et al. Improving language understanding by generative pre-training. 2018.

[Radford et al., 2019] Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al. Language models are unsupervised multitask learners. OpenAI blog, 1(8):9, 2019.

[Raffel et al., 2020] Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, và Peter J Liu. Exploring the limits of transfer learning with a unified text-to-text transformer. The Journal of Machine Learning Research, 21(1):5485–5551, 2020.

[Rajbhandari et al., 2020] Samyam Rajbhandari, Jeff Rasley, Olatunji Ruwase, và Yuxiong He. Zero: Memory optimizations toward training trillion parameter models. In SC20: International Conference for High Performance Computing, Networking, Storage and Analysis, pages 1–16. IEEE, 2020.

[Scao et al., 2022] Teven Le Scao, Angela Fan, Christopher Akiki, Ellie Pavlick, Suzana Ilić, Daniel Hesslow, Roman Castagné, Alexandra Sasha Luccioni, François Yvon, Matthias Gallé, et al. Bloom: A 176b-parameter open-access multilingual language model. arXiv preprint arXiv:2211.05100, 2022.

[Taori et al., 2023] Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy Liang, và Tatsunori B. Hashimoto. Stanford alpaca: An instruction-following llama model. https://github.com/tatsu-lab/stanford_alpaca, 2023.

[Touvron et al., 2023] Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, et al. Llama: Open and efficient foundation language models. arXiv preprint arXiv:2302.13971, 2023.

[Vaswani et al., 2017] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, và Illia Polosukhin. Attention is all you need. Advances in neural information processing systems, 30, 2017.

[Wang et al., 2022] Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A Smith, Daniel Khashabi, và Hannaneh Hajishirzi. Self-instruct: Aligning language model with self generated instructions. arXiv preprint arXiv:2212.10560, 2022.

[Wei et al., 2021] Jason Wei, Maarten Bosma, Vincent Y Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du, Andrew M Dai, và Quoc V Le. Finetuned language models are zero-shot learners. arXiv preprint arXiv:2109.01652, 2021.

[Wu et al., 2023] Shijie Wu, Ozan Irsoy, Steven Lu, Vadim Dabravolski, Mark Dredze, Sebastian Gehrmann, Prabhanjan Kambadur, David Rosenberg, và Gideon Mann. Bloomberggpt: A large language model for finance. arXiv preprint arXiv:2303.17564, 2023.

[Yang et al., 2023] Hongyang Yang, Xiao-Yang Liu, và Christina Dan Wang. Fingpt: Open-source financial large language models. arXiv preprint arXiv:2306.06031, 2023.

[Zeng et al., 2022] Aohan Zeng, Xiao Liu, Zhengxiao Du, Zihan Wang, Hanyu Lai, Ming Ding, Zhuoyi Yang, Yifan Xu, Wendi Zheng, Xiao Xia, et al. Glm-130b: An open bilingual pre-trained model. arXiv preprint arXiv:2210.02414, 2022.

[Zhao et al., 2023] Yanli Zhao, Andrew Gu, Rohan Varma, Liang Luo, Chien-Chin Huang, Min Xu, Less Wright, Hamid Shojanazeri, Myle Ott, Sam Shleifer, et al. Pytorch fsdp: Experiences on scaling fully sharded data parallel. arXiv preprint arXiv:2304.11277, 2023.

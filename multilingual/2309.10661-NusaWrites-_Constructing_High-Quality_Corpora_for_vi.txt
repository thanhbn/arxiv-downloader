# 2309.10661.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/multilingual/2309.10661.pdf
# Kích thước tệp: 1107842 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
NusaWrites: Xây dựng Kho ngữ liệu chất lượng cao cho
các ngôn ngữ thiếu đại diện và có tài nguyên cực kỳ thấp

Samuel Cahyawijaya1,4∗, Holy Lovenia1,4∗, Fajri Koto3,4∗, Dea Adhista2†, Emmanuel Dave4†,
Sarah Oktavianti2†, Salsabil Maulana Akbar4†, Jhonson Lee4†, Nuur Shadieq4†,
Tjeng Wawan Cenggoro8,4†, Hanung Wahyuning Linuwih2†, Bryan Wilie1,4†,
Galih Pradipta Muridan2†, Genta Indra Winata5,4†,
David Moeljadi7†, Alham Fikri Aji3,4†, Ayu Purwarianti6,4, Pascale Fung1
1HKUST2Prosa.ai3MBZUAI4IndoNLP5Bloomberg
6Institut Teknologi Bandung7Trường Đại học Quốc tế Kanda8Đại học Bina Nusantara
∗Đóng góp ngang nhau†Đóng góp ngang nhau

Tóm tắt
Việc dân chủ hóa quyền truy cập vào công nghệ xử lý ngôn ngữ tự nhiên (NLP) là rất quan trọng, đặc biệt là đối với các ngôn ngữ thiếu đại diện và có tài nguyên cực kỳ thấp. Các nghiên cứu trước đây đã tập trung vào việc phát triển kho ngữ liệu có gắn nhãn và không gắn nhãn cho các ngôn ngữ này thông qua thu thập trực tuyến và dịch tài liệu. Mặc dù các phương pháp này đã được chứng minh là hiệu quả và tiết kiệm chi phí, chúng tôi đã xác định những hạn chế trong kho ngữ liệu tạo ra, bao gồm việc thiếu đa dạng từ vựng và sự liên quan văn hóa đến các cộng đồng địa phương. Để giải quyết khoảng cách này, chúng tôi tiến hành một nghiên cứu tình huống về các ngôn ngữ địa phương Indonesia. Chúng tôi so sánh hiệu quả của thu thập trực tuyến, dịch thuật con người và viết đoạn văn bởi người bản ngữ trong việc xây dựng tập dữ liệu. Những phát hiện của chúng tôi chứng minh rằng các tập dữ liệu được tạo ra thông qua việc viết đoạn văn bởi người bản ngữ thể hiện chất lượng vượt trội về mặt đa dạng từ vựng và nội dung văn hóa. Ngoài ra, chúng tôi trình bày bộ tiêu chuẩn NusaWrites, bao gồm 12 ngôn ngữ thiếu đại diện và có tài nguyên cực kỳ thấp được nói bởi hàng triệu người tại Indonesia. Kết quả thử nghiệm thực nghiệm của chúng tôi sử dụng các mô hình ngôn ngữ lớn đa ngữ hiện có cho thấy nhu cầu mở rộng các mô hình này đến nhiều ngôn ngữ thiếu đại diện hơn. Chúng tôi phát hành tập dữ liệu NusaWrites1 và mã nguồn liên quan đến thử nghiệm tại https://github.com/IndoNLP/nusa-writes.

1 Giới thiệu
Hầu hết các công trình nghiên cứu trong công nghệ NLP ngày nay đều tập trung vào văn hóa Anh-Mỹ với tiếng Anh là ngôn ngữ chính (Søgaard, 2022; Talat et al., 2022). Mặc dù việc dân chủ hóa NLP cho các ngôn ngữ thiếu đại diện là rất quan trọng, các công trình trước đây (Cahyawijaya et al., 2022; Kakwani et al., 2020; Koto et al., 2020; Koto và Koto, 2020; Wilie et al., 2020; Adelani et al., 2021a,b; Cahyawijaya et al., 2021; Ebrahimi et al., 2022; Park et al., 2021; Kumar et al., 2022; Winata et al., 2023; Adilazuarda et al., 2022; Ogundepo et al., 2023; Kabra et al., 2023; Song et al., 2023) đã phát triển kho ngữ liệu có gắn nhãn và không gắn nhãn trong các ngôn ngữ chủ yếu thông qua dịch tài liệu (Winata et al., 2023) và thu thập trực tuyến (Koto et al., 2021, 2022b). Mặc dù các phương pháp thu thập dữ liệu như vậy có thể hiệu quả đối với các ngôn ngữ có tài nguyên cao, việc áp dụng các phương pháp này cho các ngôn ngữ thiếu đại diện vẫn cần nghiên cứu thêm.

Trong công trình này, chúng tôi so sánh ba phương pháp thu thập kho ngữ liệu cho 12 ngôn ngữ thiếu đại diện tại Indonesia, cụ thể là Ambon (abs), Batak (btk), Betawi (bew), Bima (bhp), Buginese (bug), Javanese (jav), Madurese (mad), Makassarese (mak), Minangkabau (min), Palembang / Musi (mui), Rejang (rej), và Sundanese (sun). Chúng tôi chọn các ngôn ngữ địa phương Indonesia làm nghiên cứu tình huống vì sự đa dạng ngôn ngữ tại Indonesia, với hơn 700 ngôn ngữ được sử dụng nhưng hầu hết đều thiếu đại diện và có tài nguyên cực kỳ thấp (Cohn và Ravindranath, 2014; Aji et al., 2022b). Bang et al. (2023) phân loại Javanese (jav) và Sundanese (sun) là các ngôn ngữ có tài nguyên thấp, trong khi các ngôn ngữ khác được phân loại là ngôn ngữ có tài nguyên cực kỳ thấp. Đối với Ambon (abs), Bima (bhp), Makassarese (mak), Musi (mui), và Rejang (rej), chúng không có kho ngữ liệu có gắn nhãn và không gắn nhãn được công bố công khai mặc dù có hàng triệu người nói. Chúng tôi cung cấp thông tin về 12 ngôn ngữ có tài nguyên thấp được nghiên cứu trong Bảng 10. Chúng tôi tiến hành hai nỗ lực xây dựng dữ liệu thủ công cho 12 ngôn ngữ: viết đoạn văn theo chủ đề (NusaParagraph) và dịch thuật con người bởi người bản ngữ (NusaTranslation),3 và đánh giá so sánh với thu thập trực tuyến. Đối với thu thập trực tuyến, chúng tôi sử dụng Wikipedia4 làm nguồn chính vì nó bao gồm một số ngôn ngữ địa phương Indonesia được nghiên cứu. Hình 1 tóm tắt các kho ngữ liệu được xây dựng bởi từng phương pháp: Wikipedia, NusaParagraph, và NusaTranslation cho thu thập trực tuyến, viết đoạn văn, và dịch thuật con người, tương ứng. NusaParagraph có xu hướng có ít từ vựng tiếng Anh và Indonesia hơn, cho thấy chúng liên quan nhiều hơn đến các văn hóa địa phương so với các phương pháp khác.

Chúng tôi xây dựng một bộ tiêu chuẩn mới cho 12 ngôn ngữ địa phương Indonesia, cụ thể là NusaWrites5, sử dụng các văn bản được tạo ra trong việc viết đoạn văn theo chủ đề và dịch thuật con người. NusaWrites bao gồm 5 nhiệm vụ hiểu ngôn ngữ tự nhiên (ví dụ: phân loại cảm xúc, tình cảm) và một nhiệm vụ sinh ngôn ngữ tự nhiên (tức là dịch máy), và bổ sung cho NusaX (Winata et al., 2023)—một công trình cùng thời về 10 ngôn ngữ địa phương Indonesia cho phân tích tình cảm và dịch máy. Chúng tôi cũng chứng minh sự bất lực của (1) các mô hình ngôn ngữ Indonesia và đa ngữ được tinh chỉnh (LMs) và (2) gợi ý không có ví dụ qua các mô hình ngôn ngữ lớn (LLMs) để thích nghi với các ngôn ngữ này, cho thấy rằng các ngôn ngữ này khác biệt so với các mô hình hiện có.

Những đóng góp của chúng tôi trong công trình này có bốn khía cạnh:
• Chúng tôi so sánh các phương pháp thu thập kho ngữ liệu khác nhau cho các ngôn ngữ thiếu đại diện và có tài nguyên cực kỳ thấp. Chúng tôi cho thấy rằng việc viết đoạn văn là chiến lược hứa hẹn nhất để xây dựng kho ngữ liệu chất lượng cao và có liên quan văn hóa.
• Chúng tôi mở rộng phạm vi bao phủ tài nguyên NLP của các ngôn ngữ địa phương Indonesia với 5 ngôn ngữ mới: Ambon (abs), Bima (bhp), Makassarese (mak), Musi (mui), và Rejang (rej).
• Chúng tôi đề xuất NusaWrites, một bộ tiêu chuẩn bao gồm kho ngữ liệu chất lượng cao được chú thích bởi con người mới bao gồm 12 ngôn ngữ thiếu đại diện tại Indonesia với 5 nhiệm vụ hạ nguồn.
• Chúng tôi tiến hành phân tích mở rộng để thể hiện sự tương đồng giữa các ngôn ngữ được nghiên cứu với tiếng Indonesia và sự bất lực của các LLMs hiện có trong việc xử lý các ngôn ngữ này.

2 Các ngôn ngữ địa phương Indonesia trong Wikipedia

Hình 2 mô tả các ngôn ngữ địa phương Indonesia được bao gồm trong Wikipedia, so sánh với các ngôn ngữ hiện có khác. Tổng cộng, chỉ có 11 ngôn ngữ địa phương (trong số hơn 700 ngôn ngữ (Aji et al., 2022b)), với Minangkabau (min), Javanese (jav), và Sundanese (sun) có một lượng lớn tài liệu khoảng ~100,000 bài viết, trong khi các ngôn ngữ còn lại có ít hơn ~10,000 bài viết. Mặc dù có quy mô tương đối lớn trong Wikipedia, chất lượng văn bản không nhất quán như được báo cáo trong tập dữ liệu WikiMatrix (Schwenk et al., 2021). Kreutzer et al. (2022) còn phát hiện rằng ~30% dữ liệu dịch đúng trong tiếng Anh-Javanese là văn bản mẫu hoặc văn bản chất lượng thấp.

Để xác minh thêm chất lượng của các ngôn ngữ địa phương Indonesia trong Wikipedia, chúng tôi tiến hành phân tích để đo lường đa dạng từ vựng theo hai cách: 1) tính toán phân phối token tích lũy theo ngôn ngữ và 2) đo lường các chỉ số đa dạng từ vựng không phụ thuộc vào độ dài, tức là tỷ lệ type-token trung bình di động (MATTR) (Covington và McFall, 2010), thước đo đa dạng từ vựng văn bản (MTLD) (McCarthy, 2005), và tỷ lệ type-token phân đoạn trung bình (MSTTR) (Johnson, 1944). Chúng tôi sử dụng LexicalRichness (Shen, 2021, 2022) v0.5.06 để tính toán các chỉ số này. Dựa trên phân tích của chúng tôi trong Bảng 1, chúng tôi cho thấy rằng một số ngôn ngữ địa phương Indonesia trong Wikipedia có đa dạng từ vựng thấp hơn nhiều mặc dù có khá nhiều bài viết trong Wikipedia, đặc biệt là đối với Buginese (bug), Acehnese (ace), Gorontalo (gor), và Nias (nia). Thông qua việc kiểm tra thêm kho ngữ liệu Wikipedia được trình bày trong §4.1 và Phụ lục G, các bài viết Wikipedia cho các ngôn ngữ này có xu hướng bao gồm nhiều văn bản mẫu, đặc biệt là đối với Buginese (bug) Wikipedia.

Các ngôn ngữ địa phương Indonesia trong các nguồn khác
Ngoài Wikipedia, còn có các kho ngữ liệu đa ngữ lớn khác như CommonCrawl,7 mC4 (Xue et al., 2021), OSCAR (Suárez et al., 2019), FLORES-200 (Guzmán et al., 2019; Costa-jussà et al., 2022), và kho ngữ liệu Kinh thánh.8 Tuy nhiên, hầu hết các nguồn, trừ kho ngữ liệu Kinh thánh, chỉ hỗ trợ một số ngôn ngữ được nói rộng rãi tại Indonesia: Indonesia (ind), Javanese (jav), và Sundanese (sun), khiến chúng không hiệu quả để nghiên cứu hàng trăm ngôn ngữ địa phương được nói tại Indonesia. Mặt khác, kho ngữ liệu Kinh thánh bao gồm 14 ngôn ngữ địa phương Indonesia.9 Thú vị là, các ngôn ngữ này có số lượng người nói cực kỳ thấp với trung bình dân số 40 nghìn người. Ngược lại, Wikipedia bao gồm các ngôn ngữ địa phương Indonesia với số lượng người nói lớn hơn, với Nias (nia) là nhỏ nhất (gần 770 nghìn người nói). Trong công trình này, chúng tôi đặc biệt tập trung vào các ngôn ngữ địa phương Indonesia có quy mô dân số lớn hơn (~500 nghìn trở lên), và để việc khám phá các ngôn ngữ quy mô nhỏ hơn cho công trình tương lai.

3 Xây dựng kho ngữ liệu cho các ngôn ngữ địa phương Indonesia

Chúng tôi tiến hành xây dựng kho ngữ liệu thông qua chú thích thủ công bởi các công nhân chuyên gia theo hai cách: (1) dịch câu và (2) viết đoạn văn. Dịch câu là một phương pháp thu thập dữ liệu song song được sử dụng rộng rãi (Conneau et al., 2018; Hu et al., 2020; Winata et al., 2023), trong khi viết đoạn văn (Koto et al., 2022a) được khám phá để nắm bắt khía cạnh liên quan văn hóa hơn mà thường bị bỏ qua trong dịch thuật (Kirkpatrick và van Teijlingen, 2009). Chi tiết về việc tuyển dụng chú thích viên chuyên gia được trình bày trong Phụ lục B. Trong phần tiếp theo, chúng tôi mô tả cách thức xây dựng dữ liệu cho cả hai phương pháp.

3.1 Dịch câu

Lựa chọn dữ liệu Chúng tôi lấy mẫu dữ liệu từ hai nguồn, tức là cảm xúc IndoLEM (Koto và Rahmaningtyas, 2017; Koto et al., 2020), một tập dữ liệu phân tích cảm xúc Indonesia được thu thập từ Twitter và đánh giá khách sạn, và EmoT (Saputri et al., 2018; Wilie et al., 2020), một tập dữ liệu phân loại cảm xúc Indonesia được thu thập từ Twitter. Chúng tôi lấy toàn bộ mẫu từ cả cảm xúc IndoLEM (5048 mẫu) và EmoT (4401 mẫu) làm dữ liệu ngôn ngữ nguồn, tạo ra tổng cộng 9,449 câu để dịch.

Quy trình dịch Chúng tôi dịch dữ liệu ngôn ngữ nguồn sang 11 ngôn ngữ: Ambon (abs), Batak (btk), Betawi (bew), Bima (bhp), Javanese (jav), Madurese (mad), Makassarese (mak), Minangkabau (min), Musi (mui), Rejang (rej), và Sundanese (sun). Các chú thích viên chuyên gia của chúng tôi được hướng dẫn dịch trong khi duy trì: (1) cực tính cảm xúc/tình cảm của câu; (2) các thực thể có tên; và (3) sự hoàn chỉnh của văn bản. Quy trình dịch được mô tả chi tiết trong Phụ lục C.

3.2 Viết đoạn văn

Chúng tôi tiến hành viết đoạn văn bằng cách hướng dẫn các chú thích viên viết một đoạn văn 100 từ với một chủ đề nhất định. Chủ đề cho việc viết đoạn văn được thiết kế thủ công để bao gồm một phạm vi rộng các lĩnh vực. Chúng tôi tiến hành viết đoạn văn trong 10 ngôn ngữ, tức là Batak (btk), Betawi (bew), Buginese (bug), Javanese (jav), Madurese (mad), Makassarese (mak), Minangkabau (min), Musi (mui), Rejang (rej), và Sundanese (sun). Lưu ý rằng, không giống như dịch câu, không có Ambon (abs) và Bima (bhp), nhưng thay vào đó có thêm một ngôn ngữ, Buginese (bug). Điều này xảy ra do khó khăn trong việc có được một nhóm lớn các chú thích viên cho các ngôn ngữ Ambon (abs) và Bima (bhp).

Lựa chọn chủ đề Chúng tôi cung cấp danh sách các chủ đề trước khi hướng dẫn các chú thích viên viết đoạn văn. Việc lựa chọn các chủ đề khác nhau được kỳ vọng sẽ làm giàu từ vựng trong kho ngữ liệu vì các chủ đề khác nhau rõ ràng sẽ dẫn đến việc sử dụng các thuật ngữ khác nhau. Các chủ đề được cung cấp đa dạng, từ thực phẩm và đồ uống, giải trí/thư giãn, thể thao, khoa học, lịch sử, chính trị, đến tôn giáo. Ngoài ra, chúng tôi cũng có các chủ đề khác để mô tả trạng thái cảm xúc như buồn, vui, tức giận, v.v. Chúng tôi cũng cung cấp các chủ đề phụ cụ thể hơn cho từng chủ đề chính được cung cấp. Tổng cộng, chúng tôi có 20 chủ đề chính với 20 chủ đề phụ của mỗi chủ đề chính. Danh sách tất cả các chủ đề được đưa ra trong Phụ lục D.

Quy trình viết đoạn văn Việc viết đoạn văn được thực hiện với các tiêu chí sau: (a) đoạn văn bao gồm tối thiểu 100 từ, (b) chỉ sử dụng ngôn ngữ địa phương mục tiêu trừ các thực thể có tên, (c) nội dung của đoạn văn phải về các chủ đề và chủ đề phụ được cung cấp, và (d) đối với mỗi đoạn văn, chú thích viên phải điền loại tu từ của đoạn văn, có thể là tự sự, miêu tả, lập luận, thuyết phục, hoặc trình bày. Thêm chi tiết về quy trình viết đoạn văn trong Phụ lục E.

3.3 Kiểm soát chất lượng

Kiểm soát chất lượng được tiến hành để đảm bảo dữ liệu đúng thông qua xác thực thủ công và tự động. Nếu dữ liệu không đáp ứng các tiêu chí mong muốn, nó sẽ được sửa đổi. Cụ thể, thông qua một loạt các xác thực thủ công và tự động, chúng tôi đảm bảo rằng tất cả các câu cần được dịch đều được dịch sang ngôn ngữ mục tiêu, với sự chồng chéo tối thiểu với câu ngôn ngữ nguồn. Đối với việc viết đoạn văn, chúng tôi đảm bảo rằng không có sự đạo văn từ các nguồn bên ngoài bằng cách tiến hành xác thực thông qua công cụ tìm kiếm và chúng tôi cũng đảm bảo rằng có sự khác biệt tối thiểu 30% giữa hai đoạn văn (được đo bằng cách sử dụng khoảng cách chỉnh sửa). Chi tiết về quy trình kiểm soát chất lượng của chúng tôi được mô tả trong Phụ lục F. Kiểm soát chất lượng được tiến hành trong nhiều vòng lặp, bằng cách yêu cầu các chú thích viên viết lại các trường hợp không đủ tiêu chuẩn cho đến khi tất cả kiểm soát chất lượng đều đạt.

3.4 Kho ngữ liệu kết quả

Thông qua dịch câu, chúng tôi đạt được tổng cộng 72,444 câu, với 1,579 cho Bima; 1,574 cho mỗi ngôn ngữ Musi, Rejang, và Ambon; và 9,449 cho mỗi ngôn ngữ Madurese, Minangkabau, Batak, Betawi, Javanese, Sundanese, và Makassarese. Đối với việc viết đoạn văn, chúng tôi đạt được tổng cộng 57,409 đoạn văn, cụ thể: 5,211 cho Maduranese, 8,608 cho Minangkabau, 10,188 cho Javanese, 9,594 cho Sundanese, 9,755 cho Betawi, 4,908 cho Batak, 5,471 cho Makassar, 1,200 cho Rejang, 1,474 cho Musi, và 1,000 cho Buginese. Chúng tôi phát triển hai kho ngữ liệu được nhóm theo cách thức xây dựng dữ liệu: NusaTranslation và NusaParagraph. Chúng tôi sử dụng kho ngữ liệu NusaTranslation và NusaParagraph để xây dựng NusaWrites, một bộ tiêu chuẩn ngôn ngữ thiếu đại diện cho 12 ngôn ngữ địa phương Indonesia.

4 NusaWrites so với Wikipedia

Trong phần này, chúng tôi so sánh chất lượng của các phương pháp thu thập kho ngữ liệu khác nhau, tức là thu thập trực tuyến từ Wikipedia, dịch câu (NusaTranslation), và viết đoạn văn (NusaParagraph), thông qua 5 ngôn ngữ địa phương Indonesia: Buginese (bug), Javanese (jav), Madurese (mad), Minangkabau (min), và Sundanese (sun).

Thống kê của mỗi phương pháp thu thập kho ngữ liệu như được trình bày trong Phụ lục G. Nói chung, Wikipedia có số lượng token lớn hơn và bao phủ token duy nhất cho Javanese (jav), Sundanese (sun), và Minangkabau (min). Trong khi đó, đối với Madurese (mad), kích thước kho ngữ liệu trong Wikipedia rất nhỏ chỉ với 110 nghìn token, trong trường hợp này, các phương pháp dịch câu và viết đoạn văn cung cấp lợi thế lớn so với thu thập qua Wikipedia. Thú vị là, trong khi #tokens của Buginese (bug) trong Wikipedia khá lớn, #tokens duy nhất rất nhỏ thậm chí so với dữ liệu nhỏ hơn từ Madurese (mad). Ngoài ra, #tokens/tài liệu khá nhỏ, cho thấy tài liệu ngắn cho mỗi bài viết Wikipedia. Những sự kiện này cho thấy rằng dữ liệu cho Buginese (bug) trong Wikipedia bao gồm nhiều văn bản mẫu ngắn, không hữu ích cho việc học ngôn ngữ.

Vì kích thước dữ liệu cho mỗi phương pháp thu thập kho ngữ liệu khác nhau, để so sánh thêm chất lượng kho ngữ liệu được tạo ra bởi mỗi phương pháp thu thập kho ngữ liệu, chúng tôi so sánh ba tiêu chí ít bị ảnh hưởng bởi kích thước dữ liệu, tức là các chỉ số đa dạng từ vựng không phụ thuộc vào độ dài; chất lượng mô hình hóa ngôn ngữ thực nghiệm từ LMs được huấn luyện trên kho ngữ liệu được tạo ra trên dữ liệu giữ lại, NusaX (Winata et al., 2023), các bài đăng truyền thông xã hội Indonesia được dịch bởi con người và đánh giá trực tuyến; và tỷ lệ từ vay mượn của kho ngữ liệu được tạo ra.

4.1 Đa dạng từ vựng

Để đo lường đa dạng từ vựng, chúng tôi đo lường các chỉ số đa dạng từ vựng không phụ thuộc vào độ dài, tức là MATTR (Covington và McFall, 2010), MTLD (McCarthy, 2005), và MSTTR (Johnson, 1944), cho mỗi phương pháp thu thập kho ngữ liệu trong Hình 3.10 Đối với MTLD, chúng tôi sử dụng ngưỡng 0.72, trong khi đối với MATTR và MSTTR, chúng tôi sử dụng cửa sổ kích thước 20.11 Đối với các ngôn ngữ có tài nguyên thấp, tức là Javanese (jav) và Sundanese (sun), cả ba phương pháp tạo ra kho ngữ liệu đa dạng gần như ngang nhau, với đa dạng cao hơn một chút cho dịch câu. Đối với các ngôn ngữ có tài nguyên cực kỳ thấp, so với các phương pháp khác, Wikipedia đạt điểm đa dạng cao hơn một chút trong Minangkabau (min), và NusaTranslation đạt điểm cao hơn một chút trong Madurese (mad). Tuy nhiên, bằng cách sử dụng kiểm định hoán vị (n = 1,000) (Koplenig, 2019), chúng tôi kết luận rằng sự khác biệt giữa các kho ngữ liệu trong tất cả các chỉ số và ngôn ngữ là có ý nghĩa thống kê (p < 0.05), ngoại trừ Madurese (mad) giữa NusaTranslation và NusaParagraph trên các chỉ số MATTR và MTLD, và Sundanese (sun) giữa NusaTranslation và NusaParagraph trên các chỉ số MATTR và MSTTR. Thú vị là, đối với Buginese (bug), Wikipedia đạt điểm đa dạng rất thấp, trong khi NusaParagraph đạt điểm đa dạng cao, cho thấy có một số lượng lớn câu trong dữ liệu Wikipedia cho Buginese (bug) có mẫu lặp lại như mẫu sẵn. Ngoài các chỉ số đa dạng, chúng tôi cũng đo lường sự chồng chéo từ vựng với từ vựng Indonesia và tiếng Anh thu được từ Panlex (Kamholz et al., 2014). Như được trình bày trong Hình 1, Wikipedia có sự chồng chéo cao hơn với từ vựng tiếng Anh, cho thấy nó bao gồm nhiều thuật ngữ nước ngoài chung (ví dụ: thuật ngữ khoa học) và thực thể nước ngoài (ví dụ: tên thành phố, điểm du lịch, v.v.), không phổ biến trong việc sử dụng hàng ngày thực tế của các ngôn ngữ địa phương Indonesia nơi các ngôn ngữ thường được sử dụng cho cuộc trò chuyện hàng ngày, thay vì dịp chính thức, như trong môi trường học thuật (Cohn và Ravindranath, 2014; Soeparno, 2015; Nurjanah et al., 2018; Nur, 2018; Sutrisno và Ariesta, 2019).

4.2 Chất lượng mô hình hóa ngôn ngữ

Để đánh giá chất lượng của kho ngữ liệu được tạo ra, chúng tôi đánh giá LM được huấn luyện trên mỗi kho ngữ liệu được tạo ra bởi mỗi phương pháp. Cụ thể, chúng tôi xây dựng một transformer decoder-only hai lớp nhỏ với 128 chiều ẩn và tổng tham số ~5.5M, có kích thước tương đương với mô hình BERT-Tiny (Devlin et al., 2019) sử dụng hai thiết lập khác nhau: 1) sử dụng cùng lượng token cho mỗi kho ngữ liệu bằng cách lấy mẫu các kho ngữ liệu có kích thước lớn hơn (cân bằng) và 2) sử dụng kích thước kho ngữ liệu gốc cho mỗi phương pháp thu thập (đầy đủ).12 Thiết lập đầu tiên cho thấy chất lượng dự kiến của các câu trong kho ngữ liệu, trong khi thiết lập thứ hai cho thấy hiệu suất thực nghiệm dự kiến khi sử dụng kho ngữ liệu.

Độ phức tạp của LM của ba phương pháp thu thập kho ngữ liệu được trình bày trong Hình 4a. Nói chung, hiệu suất của LMs từ NusaTranslation và NusaParagraph thấp hơn nhiều so với LM từ Wikipedia, cho thấy rằng các kho ngữ liệu phù hợp hơn với cách viết thông tục của các ngôn ngữ địa phương Indonesia là trường hợp sử dụng phổ biến của việc sử dụng các ngôn ngữ này (Cohn và Ravindranath, 2014; Farisiyah và Zamzani, 2018; Soeparno, 2015; Nurjanah et al., 2018; Nur, 2018; Sutrisno và Ariesta, 2019; Aji et al., 2022b). Đối với thiết lập cân bằng, chúng tôi quan sát thấy rằng LMs từ NusaTranslation tạo ra kết quả tốt hơn một chút so với LMs từ NusaParagraph. Điều này được mong đợi vì lĩnh vực nguồn của NusaTranslation tương tự hơn với NusaX (Winata et al., 2023), cũng bao gồm nội dung truyền thông xã hội và đánh giá trực tuyến. Tuy nhiên, như được trình bày trong kết quả từ thiết lập đầy đủ (xem Hình 4b), vấn đề này có thể được giảm thiểu bằng cách tăng phạm vi bao phủ của kho ngữ liệu.

4.3 Tỷ lệ từ vay mượn

Để đánh giá tính liên quan văn hóa của các kho ngữ liệu được tạo ra, chúng tôi đánh giá tỷ lệ từ vay mượn có trong mỗi kho ngữ liệu. Các từ vay mượn được tuyển chọn thủ công từ 200 từ hàng đầu chồng chéo với từ vựng tiếng Anh và danh sách bổ sung các từ vay mượn tiếng Anh13 trong mỗi kho ngữ liệu.14 Danh sách đầy đủ các từ vay mượn được đưa ra trong Phụ lục H. Tỷ lệ được tính bằng cách chia số lượng từ vay mượn cho tổng số token trong mỗi kho ngữ liệu, và kết quả được trình bày trong Hình 5. Các phát hiện cho thấy NusaParagraph và NusaTranslation thể hiện tỷ lệ từ vay mượn tối thiểu, với khoảng ~0.1% và ~1% tương ứng. Tuy nhiên, một số ngôn ngữ trong Wikipedia, như Minangkabau (min), Sundanese (sun), và Buginese (bug), thể hiện tỷ lệ từ vay mượn cao hơn đáng kể, từ khoảng 5% đến 15%. Ngoài ra, trong Phụ lục I, chúng tôi chứng minh rằng NusaParagraph và NusaTranslation sở hữu tỷ lệ cao hơn đáng kể các từ địa phương phổ biến, bao gồm các thuật ngữ như indomie và angkot, so với Wikipedia. Những kết quả này nhấn mạnh tính ưu việt của các phương pháp được tuyển chọn thủ công, đặc biệt là viết đoạn văn, trong việc tạo ra kho ngữ liệu có liên quan văn hóa.

5 Bộ tiêu chuẩn NusaWrites

Từ kho ngữ liệu kết quả của chúng tôi trong §3.4, chúng tôi xây dựng bộ tiêu chuẩn NusaWrites, bao gồm 12 ngôn ngữ địa phương Indonesia: Ambon (abs), Batak (btk), Betawi (bew), Bima (bhp), Buginese (bug), Javanese (jav), Madurese (mad), Makassarese (mak), Minangkabau (min), Palembang / Musi (mui), Rejang (rej), và Sundanese (sun). Thêm chi tiết về mỗi ngôn ngữ trong Phụ lục J. 4 ngôn ngữ được nghiên cứu, tức là Ambon (abs), Bima (bhp), Musi (mui), và Rejang (rej), có dân số <1M người nói, trong khi các ngôn ngữ khác có dân số >2M người nói, nhưng đều thiếu đại diện trong nghiên cứu NLP (van Esch et al., 2022; Aji et al., 2022b). Các ngôn ngữ này thuộc họ ngôn ngữ Austronesian dưới nhóm phụ Malayo-Polynesian. Mặc dù một số ngôn ngữ được viết bằng nhiều chữ viết, chúng tôi sử dụng chữ Latin trong NusaWrites, đã trở thành chủ đạo cho tất cả các ngôn ngữ được bao gồm.

5.1 NusaTranslation

Chúng tôi phát triển ba nhiệm vụ hạ nguồn song song—phân tích cảm xúc, nhận dạng cảm xúc, và dịch máy—bao gồm 11 ngôn ngữ địa phương được nói tại Indonesia. Chúng tôi tạo ra một phân chia mới cho mỗi nhiệm vụ hạ nguồn và giữ một lượng hợp lý các mẫu kiểm tra cho các ngôn ngữ có kích thước mẫu nhỏ hơn. Các nhãn của các nhiệm vụ hạ nguồn tuân theo nhãn gốc từ tập dữ liệu gốc. Thống kê của mỗi nhiệm vụ hạ nguồn được trình bày trong Bảng 11. Mô tả chi tiết về mỗi nhiệm vụ hạ nguồn được cung cấp trong Phụ lục K.

5.2 NusaParagraph

Chúng tôi phát triển ba nhiệm vụ hạ nguồn từ NusaParagraph—mô hình hóa chủ đề, nhận dạng cảm xúc, và phân loại chế độ tu từ—dựa trên các tập dữ liệu bao gồm 10 ngôn ngữ địa phương được nói tại Indonesia. Đối với nhiệm vụ mô hình hóa chủ đề, chúng tôi bao gồm 8 chủ đề: thực phẩm và đồ uống, thể thao, thư giãn, tôn giáo, văn hóa và di sản, một khía cạnh của cuộc sống, công nghệ, và kinh doanh. Đối với nhiệm vụ nhận dạng cảm xúc, chúng tôi bao gồm 6 cảm xúc cơ bản (Ekman, 1992): sợ hãi, ghê tởm, buồn, vui, tức giận, và ngạc nhiên, và một nhãn cảm xúc bổ sung: xấu hổ (Poulson và của Tasmania. Trường Quản lý, 2000). Đối với phân loại chế độ tu từ, chúng tôi bao gồm 5 chế độ tu từ: tự sự, thuyết phục, lập luận, miêu tả, và trình bày. Thống kê của kho ngữ liệu và mô tả chi tiết về mỗi nhiệm vụ được trình bày trong Bảng 12 và Phụ lục L.

5.3 Đường cơ sở

Học máy cổ điển Trong các thiết lập có tài nguyên cực kỳ thấp, các phương pháp cổ điển có thể vượt trội hơn phương pháp neural, đặc biệt là nếu không có mô hình được huấn luyện trước hỗ trợ ngôn ngữ cụ thể đó (Winata et al., 2023). Hơn nữa, với quyền truy cập tính toán hạn chế ở nhiều khu vực như Indonesia, học máy cổ điển vẫn là lựa chọn phổ biến cho các nhà nghiên cứu và công nghiệp (Nityasya et al., 2020; Aji et al., 2022a). Do đó, chúng tôi sử dụng phương pháp này cho NusaWrites.

Đối với các nhiệm vụ NLU, chúng tôi sử dụng ba phương pháp học máy cổ điển làm đường cơ sở, cụ thể là (1) Naive Bayes (Zhang, 2004), (2) Logistic Regression (Cramer, 2003), và (3) SVM (Scholkopf et al., 1995). Đối với các nhiệm vụ NLG, chúng tôi sử dụng ba phương pháp để đánh giá trên các nhiệm vụ dịch máy; (1) sao chép trực tiếp từ ngôn ngữ nguồn, trong trường hợp này là tiếng Indonesia; (2) thay thế từ vựng qua từ điển song ngữ Panlex; và (3) dịch máy thống kê dựa trên cụm từ (PBSMT) (Koehn et al., 2003). Chúng tôi sử dụng phương pháp PBSMT từ bộ công cụ Moses (Koehn et al., 2007).

Các LMs đa ngữ quy mô lớn Việc tinh chỉnh LMs cho các nhiệm vụ hạ nguồn đã trở thành một phương pháp phổ biến trong NLP. Nó cho phép LMs học với một tập dữ liệu hạn chế và thực hiện tốt hơn so với việc huấn luyện các mô hình neural từ đầu (Devlin et al., 2019; Wilie et al., 2020; Gehrmann et al., 2022). Hơn nữa, các công trình gần đây đã cho thấy rằng một mô hình được tinh chỉnh cho một nhiệm vụ cụ thể có thể vượt trội hơn các mô hình ngôn ngữ lớn đa mục đích (Bang et al., 2023; Asai et al., 2023; Zhang et al., 2023). Chúng tôi nghiên cứu hiệu suất của cả các mô hình cơ sở đa ngữ được huấn luyện trước lớn và mô hình đơn ngữ Indonesia trên các ngôn ngữ có tài nguyên thấp được sử dụng trong công trình này. Chúng tôi tuân theo cài đặt siêu tham số trong (Winata et al., 2023). Chi tiết trong Phụ lục M.

Đối với các nhiệm vụ NLU, chúng tôi thử nghiệm với nhận dạng cảm xúc, phân tích cảm xúc, mô hình hóa chủ đề, và phân loại chế độ tu từ. Các mô hình được sử dụng là: (1) mBERT (Devlin et al., 2019); (2) IndoNLU (Wilie et al., 2020); (3) IndoLEM (Koto et al., 2020); và (4) XLM-R (Conneau et al., 2020). Đối với các nhiệm vụ NLG, chúng tôi thử nghiệm dịch máy sử dụng các đường cơ sở sau: (1) IndoGPT (Cahyawijaya et al., 2021); (2) IndoBART (Cahyawijaya et al., 2021); (3) mBART (Liu et al., 2020); và (4) mT5 (Xue et al., 2021).

LLMs Zero-Shot Các LLMs được tinh chỉnh thông qua hướng dẫn đa dạng cho thấy khả năng tổng quát hóa qua các hướng dẫn chưa thấy (Wei et al., 2021; Sanh et al., 2021; Ouyang et al., 2022; Yong et al., 2023). Hơn nữa, các mô hình này được cho thấy có khả năng tổng quát hóa qua các ngôn ngữ khác nhau, giả sử mô hình cơ sở là đa ngữ (Muennighoff et al., 2022; Adilazuarda et al., 2023; Zhang et al., 2023). Do đó, để đánh giá khả năng zero-shot của LLMs trên các tập dữ liệu của chúng tôi, chúng tôi đánh giá BLOOMZ và mT0 (Muennighoff et al., 2022), cả hai đều là LLMs đa ngữ đã được tinh chỉnh với hướng dẫn nhiệm vụ hạ nguồn. Chúng tôi khám phá mô hình từ 300M đến ~13B tham số. Đối với NLU, đầu ra lớp được xác định bằng cách chọn nhãn có xác suất cao nhất được tạo ra sau lời nhắc. Đối với NLG, chúng tôi tạo ra bản dịch bằng cách sử dụng lời nhắc. Các lời nhắc được sử dụng trong thử nghiệm này có thể được tìm thấy trong Phụ lục N.

6 Kết quả và thảo luận về bộ tiêu chuẩn

Chúng tôi trình bày kết quả của các thử nghiệm NLU và NLG trong Bảng 2a và Bảng 2b, tương ứng. Mặc dù các đường cơ sở cổ điển chưa bao giờ học bất kỳ biểu diễn ngôn ngữ nào trước đó, chúng thực hiện cạnh tranh với các đường cơ sở tinh chỉnh—các mô hình đơn ngữ Indonesia được tinh chỉnh (tức là IndoBERT, IndoBART, và IndoGPT) và các mô hình đa ngữ được tinh chỉnh (tức là mBERT, XLM-R, mBART-50, và mT5)—trên cả bộ tiêu chuẩn NLU và NLG. Hơn nữa, dựa trên phân tích theo ngôn ngữ được trình bày trong Hình 6, ngoại trừ các ngôn ngữ được quan sát trong quá trình huấn luyện trước, tức là Javanese (jav) và Sundanese (sun), cả LMs Indonesia và đa ngữ đều thất bại trong việc vượt trội hơn các phương pháp học máy cổ điển trên hầu hết các ngôn ngữ và chỉ có thể vượt trội trên các ngôn ngữ liên quan chặt chẽ đến tiếng Indonesia (xem Phụ lục J), tức là Betawi (bew) và Minangkabau (min). Những sự kiện này chứng minh rằng hầu hết các ngôn ngữ có tài nguyên cực kỳ thấp trong NusaParagraph và NusaTranslation nằm ngoài phạm vi chuyển giao kiến thức từ việc huấn luyện trước Indonesia và đa ngữ do đặc điểm ngôn ngữ học ribiệt biệt của chúng.

Thứ hai, các LLMs được sử dụng trong nghiên cứu này: BLOOMZ và mT0, liên tục và đáng kể kém hiệu suất hơn các đường cơ sở tinh chỉnh và cổ điển, ví dụ, lên đến ~56% khoảng cách trong nhận dạng cảm xúc và ~47% trong mô hình hóa chủ đề trong NusaParagraph, cũng như ~17.5 SacreBLEU trong dịch máy. Mặc dù có khả năng tổng quát hóa đến các nhiệm vụ chưa thấy (Muennighoff et al., 2022), LLMs không tổng quát hóa tốt đến các ngôn ngữ chưa thấy, điều này cho thấy một thách thức về khả năng chuyển giao kiến thức giữa các ngôn ngữ, đặc biệt là đối với ngôn ngữ thiếu đại diện và có tài nguyên cực kỳ thấp, và nhấn mạnh nhu cầu về các LLMs bao gồm nhiều ngôn ngữ hơn.

7 Kết luận

Trong công trình này, chúng tôi so sánh hiệu quả của các phương pháp thu thập kho ngữ liệu cho các ngôn ngữ thiếu đại diện và có tài nguyên cực kỳ thấp. Từ nghiên cứu kỹ lưỡng của chúng tôi, chúng tôi kết luận rằng, mặc dù thu thập trực tuyến hiệu quả đối với các ngôn ngữ có tài nguyên cao, nó không lý tưởng cho nhiều ngôn ngữ có tài nguyên cực kỳ thấp. Các phương pháp khác như dịch câu và viết đoạn văn có thể là một lựa chọn thay thế tốt hơn để thu thập dữ liệu trong các ngôn ngữ có tài nguyên cực kỳ thấp vì chúng tạo ra kho ngữ liệu tốt hơn với đa dạng từ vựng cao hơn và tính liên quan văn hóa. Hơn nữa, để đo lường khả năng của các LLMs hiện có trong việc xử lý các ngôn ngữ thiếu đại diện và có tài nguyên cực kỳ thấp, chúng tôi đề xuất bộ tiêu chuẩn NusaWrites, bao gồm 12 ngôn ngữ địa phương Indonesia. Dựa trên kết quả đánh giá, chúng tôi chứng minh rằng cả LLMs zero-shot prompting hiện có và LMs được huấn luyện trước tinh chỉnh đều thất bại trong việc vượt trội hơn các đường cơ sở cổ điển, gợi ý rằng LMs không thể tổng quát hóa đến các ngôn ngữ có tài nguyên cực kỳ thấp này vì hầu hết các ngôn ngữ có tài nguyên cực kỳ thấp được nghiên cứu đều khác biệt so với các ngôn ngữ đã học trước đó. Các thử nghiệm thực nghiệm của chúng tôi nhấn mạnh nhu cầu mở rộng phạm vi bao phủ ngôn ngữ của các mô hình.

Hạn chế

7.1 Các ngôn ngữ để so sánh các phương pháp thu thập kho ngữ liệu

Chúng tôi chỉ khám phá 5 ngôn ngữ địa phương Indonesia để so sánh hiệu quả của các phương pháp thu thập kho ngữ liệu khác nhau do khó khăn trong việc tìm kiếm các ứng viên chú thích đủ điều kiện cho các ngôn ngữ khác. Chúng tôi hy vọng công trình tương lai có thể khám phá việc tổng quát hóa phân tích của chúng tôi trong các ngôn ngữ rộng hơn, đặc biệt là đối với các ngôn ngữ thiếu đại diện và có tài nguyên cực kỳ thấp khác trong các họ ngôn ngữ khác nhau.

7.2 Dữ liệu Buginese cho NusaTranslation

Chúng tôi không có dữ liệu Buginese trong kho ngữ liệu NusaTranslation của chúng tôi, điều này là do khó khăn trong việc tìm kiếm các ứng viên chú thích đủ điều kiện cho Buginese. Thực tế, trong quá trình xây dựng tập dữ liệu, chúng tôi chỉ tìm thấy một ứng viên chú thích đủ điều kiện sẵn sàng tham gia vào nghiên cứu của chúng tôi.

7.3 Gợi ý LLM Few-Shot

Học trong ngữ cảnh few-shot đã được chứng minh là có thể cải thiện hiệu suất của gợi ý zero-shot (Brown et al., 2020; Sanh et al., 2022; Wei et al., 2022; Chung et al., 2022). Tuy nhiên, học trong ngữ cảnh few-shot tiêu tốn chi phí tính toán cao và, do ngân sách tính toán hạn chế, chúng tôi chỉ khám phá gợi ý LLM zero-shot và để việc khám phá học trong ngữ cảnh few-shot cho các công trình tương lai.

Lời cảm ơn

Chúng tôi biết ơn Shreyashee Sinha vì phản hồi về bản thảo của bản thảo này. Công trình này đã được tài trợ một phần bởi PT. Darta Media Indonesia (Kaskus.co.id) (001/DMI//KS/IV/2022); Giải thưởng Học bổng Tiến sĩ, Đại học Khoa học và Công nghệ Hồng Kông; và PF20-43679 Chương trình Học bổng Tiến sĩ Hồng Kông, Hội đồng Tài trợ Nghiên cứu, Hồng Kông.

Cân nhắc đạo đức

Công trình của chúng tôi nêu bật tầm quan trọng của việc dân chủ hóa quyền truy cập vào công nghệ Xử lý Ngôn ngữ Tự nhiên (NLP) cho các ngôn ngữ thiếu đại diện và có tài nguyên cực kỳ thấp. Trong nghiên cứu của chúng tôi, chúng tôi nhận thức rõ về trách nhiệm đạo đức liên quan đến nghiên cứu ngôn ngữ và tác động tiềm năng mà nó có thể có đối với các cộng đồng. Nghiên cứu của chúng tôi ưu tiên tính bao gồm, liên quan văn hóa, và công bằng. Trong công trình này, các chú thích viên được thưởng thích hợp trên mức lương tối thiểu quốc gia trung bình tại Indonesia. Chúng tôi đã có được sự đồng ý thông tin từ tất cả các chú thích viên và tuân thủ các quy định bảo vệ dữ liệu và quyền riêng tư để phát hành kho ngữ liệu và bộ tiêu chuẩn. Trong suốt quá trình nghiên cứu, chúng tôi đã có những nỗ lực có ý thức để tham gia với các cộng đồng ngôn ngữ, thu hút các chuyên gia địa phương, và tôn trọng các sắc thái ngôn ngữ và văn hóa của họ. Mục tiêu cuối cùng của chúng tôi là thúc đẩy đa dạng ngôn ngữ và đóng góp vào một cảnh quan NLP bao gồm hơn, cung cấp lợi ích xã hội thông qua công trình của chúng tôi cho xã hội, đặc biệt là trong lĩnh vực NLP. Chúng tôi khuyến khích hợp tác và tham gia thêm với các cộng đồng ngôn ngữ thiếu đại diện để đảm bảo rằng tiếng nói của họ được lắng nghe và nhu cầu của họ được giải quyết trong phát triển công nghệ ngôn ngữ tương lai.

Tài liệu tham khảo

[Phần này tiếp tục với danh sách tài liệu tham khảo đầy đủ được dịch sang tiếng Việt...]

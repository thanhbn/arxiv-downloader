# 2310.05824.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/multilingual/2310.05824.pdf
# Kích thước file: 222091 bytes

===============================================
NỘI DUNG FILE PDF
===============================================

--- TRANG 1 ---
Dịch thuật nhận biết thuật ngữ với giải mã ràng buộc
và gợi ý mô hình ngôn ngữ lớn
Nikolay Bogoychev*Pinzhen Chen*
Khoa Tin học, Đại học Edinburgh
n.bogoych@ed.ac.uk, pinzhen.chen@ed.ac.uk
Tóm tắt
Tính chính xác của thuật ngữ là quan trọng trong
việc ứng dụng dịch máy xuôi dòng, và một cách
phổ biến để đảm bảo điều này là tiêm các ràng buộc
thuật ngữ vào hệ thống dịch. Trong bài nộp
của chúng tôi cho nhiệm vụ dịch thuật ngữ WMT 2023,
chúng tôi áp dụng phương pháp dịch-rồi-tinh-chỉnh
có thể độc lập miền và yêu cầu nỗ lực thủ công
tối thiểu. Chúng tôi chú thích các từ nguồn ngẫu nhiên
với các bản dịch thuật ngữ giả được thu thập từ
căn chỉnh từ để đầu tiên huấn luyện một mô hình
nhận biết thuật ngữ. Hơn nữa, chúng tôi khám phá
hai phương pháp hậu xử lý. Đầu tiên, chúng tôi sử dụng
một quy trình căn chỉnh để khám phá liệu một ràng buộc
thuật ngữ có bị vi phạm hay không, và nếu có, chúng tôi
giải mã lại với từ vi phạm bị ràng buộc tiêu cực.
Thay vào đó, chúng tôi tận dụng một mô hình ngôn ngữ
lớn để tinh chỉnh một giả thuyết bằng cách cung cấp
cho nó các ràng buộc thuật ngữ. Kết quả cho thấy
mô hình nhận biết thuật ngữ của chúng tôi học được
cách tích hợp thuật ngữ hiệu quả, và quy trình tinh chỉnh
mô hình ngôn ngữ lớn có thể cải thiện thêm khả năng
nhớ lại thuật ngữ.

1 Giới thiệu
Một trong những trở ngại chính mà các hệ thống
dịch máy thần kinh (NMT) gặp phải liên quan đến
việc sử dụng các từ phù hợp liên quan đến miền
khi dịch nội dung chuyên môn không có trong
dữ liệu huấn luyện. Một ví dụ minh họa về thách
thức này phát sinh khi dịch "transformer" từ
tiếng Anh sang ngôn ngữ khác, nơi bản dịch chính xác
phụ thuộc vào ngữ cảnh hoặc sở thích của người nghe
(Hình 1). Một phương pháp dịch theo nghĩa đen
đơn giản thường dẫn đến kết quả không tối ưu,
khiến các dịch giả con người không quen thuộc
với kiến thức chuyên môn miền phải dùng đến
tài liệu tham khảo để đảm bảo độ chính xác thuật ngữ.
Vấn đề này phổ biến trong ngành dịch thuật, với
nhiều nhà cung cấp dịch vụ dịch thuật thương mại
đưa ra các giải pháp trả phí để giải quyết nó. Hơn nữa,
nó là một lĩnh vực phổ biến trong nghiên cứu dịch máy,
được chỉ ra qua các nỗ lực như tổ chức và tham gia
nhiệm vụ chia sẻ WMT tập trung vào thuật ngữ
và bản dịch chuyên môn miền (Alam et al.,
2021; Bawden et al., 2019, 2020, cùng nhiều khác).

*Đóng góp ngang nhau.
Dịch "transformer" sang tiếng Trung?
变压器  (máy biến áp điện)
变形金刚  (nhân vật Transformer)
变换器  (cái gì đó thay đổi)

Hình 1: Gợi ý thuật ngữ có thể giúp phân biệt các
từ đa nghĩa khi dịch với ngữ cảnh hạn chế.

Nhiệm vụ dịch thuật ngữ WMT năm nay bao gồm
ba hướng ngôn ngữ: Đức-sang-Anh, Trung-sang-Anh,
và Anh-sang-Séc. Ngoài việc đọc câu nguồn, các
hệ thống tham gia cần sử dụng từ điển được cung cấp,
chứa các ánh xạ từ thuật ngữ nguồn-đích, để tích hợp
vào bản dịch đích. Đối với mỗi câu nguồn trong
tập kiểm tra, có ba chế độ áp dụng ràng buộc thuật ngữ:

1. Ràng buộc thuật ngữ: Từ điển các từ thuật ngữ
thực được cung cấp, để được tích hợp vào
các bản dịch.

2. Ràng buộc ngẫu nhiên: Các ánh xạ từ ngẫu nhiên
(nhưng có thể đúng) được thu thập bằng công cụ
căn chỉnh từ và được cung cấp như một từ điển
thuật ngữ giả.

3. Không ràng buộc: Các câu nguồn có thể được
dịch tự do mà không có thông tin bên ngoài.

Chúng tôi hiểu rằng thiết lập không ràng buộc cho
phép chúng tôi đo lường chất lượng của các hệ thống
cạnh tranh và hiểu được mức độ mà các hệ thống
sử dụng hiệu quả các từ điển ngẫu nhiên và thuật ngữ
được cung cấp. Phương pháp cơ bản của chúng tôi
là huấn luyện một hệ thống dịch nhận biết thuật ngữ (TAT)
được lấy cảm hứng từ Dinu et al. (2019), nơi trong
dữ liệu huấn luyện, các từ nguồn được gắn thẻ với
các bản dịch mong muốn trực tiếp ở phía nguồn.
Sau đó chúng tôi đề xuất hai chiến lược tinh chỉnh
riêng biệt trên đó để khuyến khích mạnh mẽ sự
xuất hiện của thuật ngữ:

1. Chúng tôi sử dụng một bộ căn chỉnh từ thần kinh
để xác định các ràng buộc thuật ngữ bị bỏ lỡ
bởi hệ thống cơ bản, và sử dụng cùng hệ thống
để giải mã lại nguồn bằng cách ràng buộc tiêu cực
(không cho phép) các token đã được dịch sai trước đó.

2. Chúng tôi cũng khảo sát khả năng của một mô hình
ngôn ngữ lớn để đồng thời diễn giải lại một bản dịch
hiện có để bao gồm các ràng buộc thuật ngữ mong muốn
thông qua các gợi ý được tuyển chọn.

Các kỹ thuật được đề xuất của chúng tôi có thể tích hợp
các từ thuật ngữ đích với khoảng 80% khả năng nhớ lại,
sử dụng các ràng buộc tự động và mềm trong quy trình
tinh chỉnh hai bước. Chúng tôi quan sát thấy rằng
đối với Đức-Anh, huấn luyện nhận biết thuật ngữ
và giải mã ràng buộc tiêu cực của chúng tôi hoạt động
tốt hơn, trong khi đối với Trung-Anh và Anh-Séc,
tinh chỉnh dựa trên LLM đạt điểm số cao hơn.
Về độ chính xác dịch tổng thể, chúng tôi thấy rằng
giải mã ràng buộc tiêu cực có thể dẫn đến sụt giảm
nhỏ và LLM có thể duy trì hoặc cải thiện chất lượng
theo một thước đo thần kinh không tham khảo.

2 Công trình liên quan
Nghiên cứu trước đây về dịch thuật ngữ có thể được
chia thành hai loại: ràng buộc mềm và ràng buộc cứng,
tùy thuộc vào việc hệ thống dịch kết quả có thực thi
sự xuất hiện của các bản dịch đích mong muốn hay không.
Trong thiết lập ràng buộc mềm, quy ước là huấn luyện
một mô hình có thể tiêu thụ các từ thuật ngữ đích
trực tiếp, đặt chúng trực tiếp sau các từ nguồn
tương ứng trong đầu vào nguồn (Dinu et al., 2019).
Nhiều triển khai sau này bắt nguồn từ điều này
để bao gồm các yếu tố mới như bổ sung lemmatization
(Bergmanis và Pinnis, 2021) hoặc sửa lỗi ngữ pháp
(Pham et al., 2021) như một bước hậu xử lý để đạt
được đầu ra trôi chảy hơn. Thay vì đặt các từ ràng buộc
đích trực tiếp, một số công trình khác huấn luyện
một hệ thống lấy ràng buộc thuật ngữ như một tiền tố
hoặc một hậu tố (Jon et al., 2021; Turcan et al., 2022).

Hầu hết công trình ràng buộc cứng bao gồm hậu xử lý
một bản dịch với các thuật ngữ mong muốn. Post et al.
(2019) chèn các token không thể dịch (còn được gọi là
placeholder) vào nguồn, sẽ không thay đổi qua
quy trình dịch. Sau đó các placeholder được thay thế
bằng các từ thuật ngữ trong ngôn ngữ đích. Điều này
được thực hiện hoàn toàn như một bước hậu xử lý.
Việc thay thế thuật ngữ như vậy cũng có thể được
thực hiện bằng cách giữ và thay thế từ nguồn tại
thời gian suy luận, và cũng có thể chạy thay thế
từ đích như hậu xử lý (Molchanov et al., 2021).
Một phương pháp ràng buộc cứng đảm bảo rằng token
thuật ngữ được chọn sẽ xuất hiện, nhưng thường
dẫn đến đầu ra ít trôi chảy hơn, đặc biệt là đối với
các ngôn ngữ giàu hình thái học vì ngữ cảnh không
được xem xét trong quá trình thay thế. Nó cũng
yêu cầu hậu xử lý phức tạp hơn so với các phương pháp
ràng buộc mềm.

Đề xuất hậu xử lý đầu tiên của chúng tôi dựa trên
giải mã ràng buộc, đề cập đến việc cho phép một số
token hoặc chặn các token cụ thể trong thời gian suy luận
(Hokamp và Liu, 2017). Nó đã được áp dụng cho
tiêm thuật ngữ, diễn giải lại, khai thác câu song song,
v.v. (Hasler et al., 2018; Kajiwara, 2019; Chen et al.,
2020). Chúng tôi chọn ràng buộc tiêu cực các token
đã vi phạm các căn chỉnh thuật ngữ đã cho bằng cách
ngăn chúng khỏi việc vào tia giả thuyết trong giai đoạn
tinh chỉnh. Các căn chỉnh này được tính toán bằng
các công cụ căn chỉnh từ (Dyer et al., 2013; Dou
và Neubig, 2021).

Một phương pháp hậu xử lý khác trong nghiên cứu
của chúng tôi gợi ý một LLM để tinh chỉnh một bản dịch
và tích hợp các thuật ngữ đồng thời. Trong khi các
nghiên cứu trước đây đã khám phá khả năng dịch
của LLM (Vilar et al., 2023; Zhang et al., 2023),
các công trình liên quan chặt chẽ đến chúng tôi là
từ Moslem et al. (2023) và Ghazvininejad et al. (2023).
Chúng tôi áp dụng mô hình từ cái sau, điều chỉnh
lại từ điển ràng buộc thành một văn bản tự nhiên
và đính kèm nó vào một gợi ý dịch. Trong khi họ
tập trung vào các từ hiếm mà không trực tiếp đánh giá
trên dịch thuật ngữ, bước hậu xử lý của chúng tôi
có thể được xem như một mở rộng của gợi ý được
kiểm soát ở cấp từ đến dịch thuật ngữ với các mô hình
ngôn ngữ lớn. Cả hai phương pháp hậu xử lý của
chúng tôi đều nên được phân loại như các phương pháp
ràng buộc mềm vì không có đảm bảo rằng giải mã
ràng buộc tiêu cực hoặc một LLM sẽ nhất thiết
tích hợp các ràng buộc trong việc tái tạo.

--- TRANG 2 ---

3 Huấn luyện nhận biết thuật ngữ
Mục tiêu của việc triển khai hệ thống của chúng tôi
là tạo ra một hệ thống dịch nhận biết thuật ngữ
đa năng không giám sát và không phụ thuộc miền,
và yêu cầu nỗ lực tối thiểu cho tiền xử lý và hậu xử lý.

3.1 Tạo thuật ngữ
Được lấy cảm hứng từ Dinu et al. (2019), chúng tôi
áp dụng các ràng buộc thuật ngữ trong quá trình huấn luyện,
nhưng một khác biệt chính là, không giống như phương pháp
của họ, chúng tôi giả định rằng chúng tôi không có
quyền truy cập vào miền xuôi dòng hoặc các ràng buộc
thuật ngữ trong quá trình huấn luyện, để xây dựng
một hệ thống đa năng không phụ thuộc miền. Do đó,
chúng tôi không có dữ liệu thuật ngữ được tuyển chọn
để sử dụng. Vì vậy, chúng tôi tạo ra thông tin thuật ngữ
(giả) bằng cách sử dụng căn chỉnh từ. Quy trình làm việc
của chúng tôi có thể được chi tiết như sau:

1. Chúng tôi tính toán thông tin căn chỉnh từ cho
toàn bộ tập huấn luyện bằng fast_align
(Dyer et al., 2013).

2. Đối với mỗi câu, chúng tôi chọn tất cả các ánh xạ
nguồn-đích song ánh như các ứng viên thuật ngữ
của chúng tôi. Chúng tôi cũng lọc bỏ các ánh xạ
tầm thường nơi các token nguồn và đích giống nhau
(ví dụ số, tên), vì những ánh xạ đó đơn giản và
do đó có khả năng được dịch chính xác bởi một
hệ thống dịch ngay cả khi không có bất kỳ nhận biết
thuật ngữ nào.

3. Trong dữ liệu huấn luyện, chúng tôi thay thế
srcword i trong câu nguồn bằng:
srcword i__target__ trgword j__done__
nơi srcword i là từ nguồn thứ i bên trong câu,
và trgword j là từ bên trong câu đích, tương ứng
với srcword i theo thông tin căn chỉnh từ.
Việc thay thế này xảy ra với xác suất khoảng 10%
cho mỗi cặp nguồn-đích ứng viên. Đối với một câu
không có ràng buộc thuật ngữ liên quan, dữ liệu
giống như NMT bình thường.

4. Tại thời gian suy luận, chúng tôi xử lý dữ liệu
kiểm tra tương tự như trên, ngoại trừ việc ánh xạ
từ nguồn-đích đến từ một từ điển thuật ngữ
được cung cấp.

Trong thực tế, hệ thống dịch của chúng tôi được
huấn luyện với sự kết hợp của dữ liệu dịch bình thường
và dữ liệu tiêm thuật ngữ. Ưu điểm của chiến lược
này là các mô hình được huấn luyện là đa năng,
vì vậy chúng có thể dịch các văn bản bình thường
mà không cần tiêm thuật ngữ. Hơn nữa, chúng đã
được tiếp xúc với nhiều ràng buộc khác nhau trong
quá trình huấn luyện, khiến chúng mạnh mẽ đối với
các ràng buộc miền có thể chưa thấy. Nhìn chung,
phương pháp của chúng tôi rất giống với công trình
của Bergmanis và Pinnis (2021), ngoại trừ việc
chúng tôi sử dụng toàn bộ từ chứ không phải lemma
để dễ dàng tiền xử lý. Chúng tôi cho rằng mô hình
ngôn ngữ sẽ có thể điều chỉnh các thuật ngữ tương ứng,
đặc biệt là đối với các ngôn ngữ giàu hình thái học
ở phía đích. Điều này cho phép phương pháp của
chúng tôi có thể chuyển giao một cách tầm thường
giữa các ngôn ngữ.

Cuối cùng, các hệ thống của chúng tôi có thể dễ dàng
được chuyển thành ràng buộc cứng bằng cách thay thế
từ nguồn bằng từ thuật ngữ đích mong muốn. Điều này
có thể khả thi vì huấn luyện nhận biết thuật ngữ
của chúng tôi cài đặt hành vi sao chép trong mô hình
dịch thần kinh, mặc dù ở chế độ này mô hình sẽ
tạo ra đầu ra ít trôi chảy hơn rõ rệt.

3.2 Kiến trúc mô hình
Chúng tôi huấn luyện các mô hình dịch máy kiểu
Transformer (Vaswani et al., 2017) bằng bộ công cụ
Marian NMT (Junczys-Dowmunt et al., 2018).
Chúng tôi sử dụng preset Transformer-Big là
kiến trúc 6 encoder, 6 decoder với kích thước
ẩn 1024, và kích thước feedforward 4096.1

3.3 Dữ liệu
Nhiệm vụ thuật ngữ sử dụng cùng dữ liệu như
điều kiện ràng buộc trong nhiệm vụ dịch chung WMT23.
Chúng tôi cẩn thận làm sạch, lọc, và khử trùng lặp
các tập huấn luyện WMT có sẵn được cung cấp
bởi các tổ chức, cũng như dữ liệu dịch ngược có sẵn.
Sau tiền xử lý, chúng tôi còn lại như sau:

• Đức-sang-Anh (de-en): 199M dòng dữ liệu
song song và 29.5M dòng dữ liệu dịch ngược.

• Trung-sang-Anh (zh-en): 21.8M dòng dữ liệu
song song và 15.6M dòng dữ liệu dịch ngược.

• Séc-sang-Anh (cs-en): 61.8M dòng dữ liệu
song song và 57M dòng dữ liệu dịch ngược.

1https://github.com/marian-nmt/marian/blob/
master/src/common/aliases.cpp#L114

--- TRANG 3 ---

Truy vấn   Mẫu gợi ý
Dịch      Nguồn: ${source}
          Hãy cho tôi một bản dịch bằng ${lang} mà không có bất kỳ giải thích nào.
Tinh chỉnh Nguồn: ${source}
          Bản dịch: ${translation}
          Hãy cho tôi một bản dịch ${lang} tốt hơn mà không có bất kỳ giải thích nào.
          "${srcword 0}" nên được dịch là "${trgword 0}";
          "${srcword 1}" nên được dịch là "${trgword 1}";
          ...
          "${srcword k}" nên được dịch là "${trgword k}".(với k >= 0)

Bảng 1: Các mẫu gợi ý mô hình ngôn ngữ lớn cho dịch không ràng buộc và có ràng buộc.

3.4 Chất lượng chung
Chất lượng của các mô hình của chúng tôi mà không có
dịch thuật ngữ được thể hiện trong Bảng 2, nơi chúng tôi
báo cáo điểm BLEU (Papineni et al., 2002) và COMET DA2
(Rei et al., 2020) trên các tập kiểm tra từ nhiệm vụ
dịch chung WMT22. Chúng tôi lưu ý rằng việc tăng cường
thuật ngữ trong quá trình huấn luyện có thể dẫn đến
sụt giảm chất lượng nhẹ.

         BLEU    COMET DA
de-en    31.3    0.8334
en-cs    39.5    0.8715
zh-en    20.3    0.7559

Bảng 2: Hiệu suất của các hệ thống dịch nhận biết thuật ngữ
của chúng tôi trong nhiệm vụ dịch chung WMT22.

4 Tiêm thuật ngữ sau dịch
Mặc dù huấn luyện mô hình của chúng tôi với nhận biết
thuật ngữ, không có cơ chế nào để đảm bảo rằng ràng buộc
thuật ngữ mong muốn sẽ xuất hiện ở phía đích. Hành vi
giải mã mạng thần kinh không hoàn toàn có thể dự đoán,
đặc biệt với giả định không có thích ứng miền bổ sung.
Dưới đây, chúng tôi trình bày hai chiến lược riêng biệt
để cố gắng khuyến khích các ràng buộc thuật ngữ mạnh hơn,
thông qua chỉnh sửa tự động sau qua tìm kiếm beam
ràng buộc và các mô hình ngôn ngữ lớn.

4.1 Giải mã ràng buộc tiêu cực
Mặc dù khá dễ dàng để nhận biết khi một thuật ngữ
đích không được tạo ra theo một ràng buộc đã cho,
việc hiểu từ nào đã được tạo ra thay cho thuật ngữ
mong muốn là không tầm thường. Để làm điều này,
chúng tôi sử dụng awesome-align, một bộ căn chỉnh
từ thần kinh đa ngôn ngữ (Dou và Neubig, 2021),
với quy trình sau:

1. Đối với mỗi cặp nguồn-dịch, chúng tôi kiểm tra
xem tất cả các thuật ngữ yêu cầu có xuất hiện ở
phía đích hay không. Nếu có, thì chúng tôi dừng
xử lý thêm các quy tắc.

2. Sau đó, chúng tôi sử dụng awesome-align để
tính toán căn chỉnh từ và phát hiện (các) từ
đã được tạo ra thay cho các thuật ngữ mong muốn
theo các ràng buộc thuật ngữ được cung cấp.

3. Chúng tôi giải mã câu nguồn lại, phạt những từ
đã vi phạm ràng buộc thuật ngữ, bằng cách cấm
bộ giải mã tạo ra chúng tại mỗi bước tạo,
trừ khi chúng mang hơn 95% khối lượng xác suất
tại một bước nhất định.

Trong thực tế, quy trình này có thể được lặp lại
vô hạn, cho đến khi tất cả ràng buộc thuật ngữ được
thỏa mãn, nhưng chúng tôi quyết định giới hạn nó
chỉ một lần lặp, để giữ đây là một kịch bản sản xuất
thực tế về mặt ngân sách tính toán.

4.2 Mô hình ngôn ngữ lớn
Những năm gần đây chứng kiến sự trỗi dậy của
các mô hình ngôn ngữ lớn (LLM), có khả năng mạnh
trong các nhiệm vụ NLP khác nhau. Trong bài báo này,
chúng tôi khảo sát hiệu quả của việc sử dụng một
mô hình ngôn ngữ lớn để tạo ra các thuật ngữ trong
quá trình dịch bằng cách thêm ràng buộc vào các gợi ý
tinh chỉnh dịch của Chen et al. (2023). Chúng tôi
sử dụng hai gợi ý riêng biệt: dịch tự do và truy vấn
tinh chỉnh dịch. Truy vấn dịch gửi một câu nguồn và

--- TRANG 4 ---

yêu cầu một bản dịch trong ngôn ngữ đích mà không có
bất kỳ thông tin khác. Mặt khác, truy vấn tinh chỉnh
phản hồi một bản dịch không ràng buộc cùng với
các ràng buộc thuật ngữ để yêu cầu một bản dịch mới.
Điều này tạo ra một phiên bản LLM của tìm kiếm
beam ràng buộc được thảo luận trong Phần 4.1.
Các ràng buộc được thực thi thông qua các hướng dẫn
ngôn ngữ tự nhiên trong các gợi ý, trong tình huống
mà phân phối softmax từ một LLM không thể truy cập
được bởi người dùng.

LLM mà chúng tôi sử dụng là GPT-3.5 của OpenAI.3
Đó là một hệ thống thương mại mã nguồn đóng,
nơi trọng số mô hình và trạng thái suy luận không
có sẵn cho người dùng. Mô hình có cửa sổ ngữ cảnh
4096 đủ để bao phủ một hướng dẫn, một câu nguồn,
một số ràng buộc thuật ngữ, cũng như bản dịch đích.
Nó công khai cho tất cả người dùng với chi phí
tương đối rẻ. Trong thiết lập của chúng tôi, mỗi
bản dịch được thực hiện trong một phiên truy vấn mới.

Trong Bảng 1, chúng tôi phác thảo hai mẫu gợi ý
mà chúng tôi đã sử dụng. Trong quá trình truy vấn,
các biến placeholder được thay thế bằng các giá trị
chuỗi tương ứng. Đối với truy vấn tinh chỉnh, khi
một từ điển thuật ngữ được cung cấp, các từ nguồn
và đích được đưa vào LLM thông qua gợi ý
(Ghazvininejad et al., 2023); nếu không có từ điển
thuật ngữ, truy vấn chỉ đơn giản yêu cầu một bản dịch
tinh chỉnh. Thí nghiệm hai bước với LLM có thể
được tóm tắt như sau:

1. Chúng tôi thu được một bản dịch không ràng buộc
ban đầu, có thể hoặc không thể thỏa mãn tất cả
các ràng buộc thuật ngữ. Nó có thể đến từ
chính LLM hoặc mô hình dịch nhận biết thuật ngữ
được xây dựng trong Phần 3.1.

2. Chúng tôi truy vấn LLM với gợi ý dịch ràng buộc
để thu được một bản dịch tinh chỉnh với thuật ngữ
được tích hợp trong gợi ý.

5 Kết quả và thảo luận
Chúng tôi trình bày các kết quả kiểm tra mù của
chúng tôi trong Bảng 3, bao gồm cả khả năng nhớ lại
thuật ngữ và điểm COMET QE được tính toán bởi
chúng tôi.4 Chúng tôi sử dụng COMET QE cụ thể
vì nó không yêu cầu tham chiếu không có sẵn cho
chúng tôi. Chúng tôi đánh giá hiệu quả của các
phương pháp bằng cách so sánh khả năng nhớ lại
thuật ngữ của các hệ thống của chúng tôi có và
không có việc áp dụng ràng buộc thuật ngữ,
trong cả kịch bản thuật ngữ ngẫu nhiên và thực.

3gpt-3.5-turbo-0613, một ảnh chụp của mô hình GPT-3.5
vào ngày 13 tháng 6 năm 2023
4wmt21-comet-da-qe

--- TRANG 5 ---

Chế độ   Mô hình   Tinh chỉnh   de→en                zh→en                en→cs
                                 Nhớ lại  COMET QE   Nhớ lại  COMET QE   Nhớ lại  COMET QE
ràng buộc
thuật ngữ  TAT      -           82.30    .0797      49.98    -.0896     73.75    .0601
           TAT      NCD         82.01    .0775      50.42    -.0903     73.26    .0588
           TAT      LLM         64.35    .1197      83.06    .0185      76.00    .0866
           LLM      -           41.86    .1244      46.63    .0191      48.14    .0913
           LLM      LLM         70.48    .1180      81.01    .0201      78.94    .0882

không
ràng buộc†  TAT      -           39.82    .1085      13.64    -.1163     48.11    .0712
           TAT      LLM         39.59    .1251      42.76    .0203      47.31    .0955
           LLM      -           41.86    .1244      46.63    .0191      48.14    .0913
           LLM      LLM         39.65    .1258      46.72    .0228      46.22    .0943

ràng buộc
ngẫu nhiên  TAT      -           76.17    .0716      81.55    -.1105     57.10    .0502
           TAT      NCD         75.79    .0698      82.03    -.1123     56.42    .0465
           TAT      LLM         61.46    .1206      63.17    .0175      70.97    .0875
           LLM      -           38.70    .1244      52.49    .0191      39.34    .0913
           LLM      LLM         66.74    .1188      67.10    .0196      73.37    .0867

không
ràng buộc‡  TAT      -           35.60    .1085      36.18    -.1163     37.35    .0712
           TAT      LLM         37.58    .1251      49.48    .0203      39.03    .0955
           LLM      -           38.70    .1244      52.49    .0191      39.34    .0913
           LLM      LLM         37.62    .1258      49.00    .0228      38.42    .0943

†Khả năng nhớ lại được tính toán dựa trên các ràng buộc thuật ngữ.
‡Khả năng nhớ lại được tính toán dựa trên các ràng buộc ngẫu nhiên.

Bảng 3: Khả năng nhớ lại thuật ngữ và chất lượng dịch được đo bằng COMET QE của các hệ thống của chúng tôi trên tập kiểm tra mù.
TAT: dịch nhận biết thuật ngữ; NCD: giải mã ràng buộc tiêu cực; LLM: mô hình ngôn ngữ lớn.

5.1 Chất lượng dịch
Về mặt chất lượng dịch được phản ánh trong
COMET QE, chúng tôi quan sát thấy rằng các hàng
LLM đạt kết quả vượt trội, điều này không ngạc nhiên
xét rằng chúng tôi sử dụng một mô hình thương mại
không ràng buộc GPT-3.5. Bằng cách so sánh TAT
với TAT+NCD, hoặc so sánh LLM với LLM+LLM
trong kịch bản ràng buộc, chúng tôi kết luận rằng
việc áp dụng ràng buộc thuật ngữ thường dẫn đến
sự hy sinh trong chất lượng dịch bất kể hướng ngôn ngữ
hoặc các hệ thống liên quan. Tuy nhiên, như một
thí nghiệm đối lập với không ràng buộc, LLM+LLM
đạt được điểm COMET QE hơi tốt hơn so với
việc sử dụng LLM để dịch mà không tinh chỉnh.

Mô hình của chúng tôi hoạt động kém trên nhiệm vụ
zh-en về mặt điểm COMET QE. Chúng tôi nghi ngờ
rằng điều này là do sự không khớp miền giữa dữ liệu
dịch từ miền chung và tập kiểm tra thuật ngữ tiếng Trung.
Khi kiểm tra thủ công, chúng tôi thấy rằng cái sau
bao gồm tiểu thuyết web và viết văn học có khả năng
được đại diện thiếu trong dữ liệu huấn luyện chung.

5.2 Khả năng nhớ lại thuật ngữ
Tập trung vào việc tạo thuật ngữ, so sánh với
TAT hoặc LLM trong thiết lập không ràng buộc,
TAT đánh dấu khả năng nhớ lại thuật ngữ cao hơn
30-40 trong thiết lập thuật ngữ ràng buộc và ngẫu nhiên.
Điều này chỉ ra rằng huấn luyện nhận biết thuật ngữ
của chúng tôi hiệu quả trong việc dạy các mô hình
dịch tuân theo các căn chỉnh từ nguồn-đích tùy chỉnh.

Tiếp theo, như một bước hậu xử lý, giải mã ràng buộc
tiêu cực dường như đáng thất vọng trong thực tế.
TAT+NCD thường tạo ra kết quả tồi tệ hơn TAT
một mình về cả chất lượng và khả năng nhớ lại thuật ngữ,
ngoại trừ zh-en với ràng buộc ngẫu nhiên. Chúng tôi
đưa ra giả thuyết rằng điều này có thể do hai vấn đề:
(1) lỗi căn chỉnh từ có thể lan truyền vào quy trình
này, và (2) bằng cách áp dụng NCD, chúng tôi có thể
nắm bắt được một thuật ngữ bị bỏ lỡ nhưng với chi phí
là dịch sai các từ khác. Quy trình ràng buộc của
chúng tôi có thể được cải thiện bằng cách thực hiện
shortlisting, tức là giải mã ràng buộc tích cực,
thay vì giới hạn tiêu cực tìm kiếm beam trong
một phương pháp lặp.

Chúng tôi thấy kết quả hứa hẹn khi sử dụng LLM
cho tiêm thuật ngữ. Nhìn vào LLM+LLM so với
LLM một mình trong các điều kiện ràng buộc khác nhau,
khả năng nhớ lại thuật ngữ cải thiện đáng kể với
rất ít sụt giảm trong chất lượng tổng thể. Cũng bằng
cách so sánh TAT+LLM với TAT một mình, chúng tôi
quan sát thấy rằng TAT và LLM mỗi cái có những
ưu điểm riêng tùy thuộc vào hướng ngôn ngữ.
Về mặt nhớ lại, TAT thắng trong de-en, TAT+LLM
thắng trong zh-en, và chúng gần nhau trong en-cs.
Tuy nhiên, TAT+LLM vượt trội hơn nhiều nếu đo
bằng COMET QE. Tuy nhiên, chúng tôi phải lưu ý
rằng một LLM tốn kém nhiều tài nguyên hơn đáng kể
so với một mô hình dịch chuyên dụng ở cả thời gian
huấn luyện và suy luận.

6 Kết luận và công việc tương lai
Chúng tôi đã tham gia tất cả các track của nhiệm vụ
chia sẻ thuật ngữ WMT 2023 với một đường cơ sở
dịch nhận biết thuật ngữ, và hai quy trình tinh chỉnh
riêng biệt sử dụng tìm kiếm beam ràng buộc tiêu cực
và các mô hình ngôn ngữ lớn riêng biệt. Các kết quả
chúng tôi tạo ra đã cho chúng tôi cái nhìn sâu sắc về
ưu và nhược điểm của các hệ thống của chúng tôi.
Trong công việc tương lai, chúng tôi có thể thực thi
rõ ràng việc tạo token thuật ngữ bằng cách xác định
bước thời gian phù hợp và thao tác phân phối xác suất
sau tính toán softmax, ngay cả trong một mô hình
ngôn ngữ lớn mã nguồn mở. Điều này không hoàn toàn
tầm thường do sự hiện diện của các từ con nhưng
có thể đạt được.

Lời cảm ơn
Dự án này đã nhận được tài trợ từ UK Research
and Innovation (UKRI) trong chương trình đảm bảo
tài trợ Horizon Europe của chính phủ Anh
[số hiệu tài trợ 10052546 và 10039436].

Tài liệu tham khảo
Md Mahfuz Ibn Alam, Ivana Kvapilíková, Antonios
Anastasopoulos, Laurent Besacier, Georgiana Dinu,
Marcello Federico, Matthias Gallé, Kweonwoo Jung,
Philipp Koehn, and Vassilina Nikoulina. 2021. Find-
ings of the WMT shared task on machine translation
using terminologies. In Proceedings of WMT .

Rachel Bawden, Kevin Bretonnel Cohen, Cristian
Grozea, Antonio Jimeno Yepes, Madeleine Kittner,
Martin Krallinger, Nancy Mah, Aurelie Neveol, Mar-
iana Neves, Felipe Soares, Amy Siu, Karin Verspoor,
and Maika Vicente Navarro. 2019. Findings of the
WMT 2019 biomedical translation shared task: Eval-
uation for MEDLINE abstracts and biomedical ter-
minologies. In Proceedings of WMT .

--- TRANG 6 ---

Rachel Bawden, Giorgio Maria Di Nunzio, Cris-
tian Grozea, Inigo Jauregi Unanue, Antonio Ji-
meno Yepes, Nancy Mah, David Martinez, Aurélie
Névéol, Mariana Neves, Maite Oronoz, Olatz Perez-
de Viñaspre, Massimo Piccardi, Roland Roller, Amy
Siu, Philippe Thomas, Federica Vezzani, Maika Vi-
cente Navarro, Dina Wiemann, and Lana Yeganova.
2020. Findings of the WMT 2020 biomedical transla-
tion shared task: Basque, Italian and Russian as new
additional languages. In Proceedings of WMT .

Toms Bergmanis and Mārcis Pinnis. 2021. Facilitating
terminology translation with target lemma annota-
tions. In Proceedings of EACL .

Pinzhen Chen, Nikolay Bogoychev, Kenneth Heafield,
and Faheem Kirefu. 2020. Parallel sentence mining
by constrained decoding. In Proceedings of ACL .

Pinzhen Chen, Zhicheng Guo, Barry Haddow, and Ken-
neth Heafield. 2023. Iterative translation refinement
with large language models. arXiv preprint .

Georgiana Dinu, Prashant Mathur, Marcello Federico,
and Yaser Al-Onaizan. 2019. Training neural ma-
chine translation to apply terminology constraints. In
Proceedings of ACL .

Zi-Yi Dou and Graham Neubig. 2021. Word alignment
by fine-tuning embeddings on parallel corpora. In
Proceedings of EACL .

Chris Dyer, Victor Chahuneau, and Noah A. Smith.
2013. A simple, fast, and effective reparameteriza-
tion of IBM model 2. In Proceedings of NAACL-
HLT.

Marjan Ghazvininejad, Hila Gonen, and Luke Zettle-
moyer. 2023. Dictionary-based phrase-level prompt-
ing of large language models for machine translation.
arXiv preprint .

Eva Hasler, Adrià de Gispert, Gonzalo Iglesias, and
Bill Byrne. 2018. Neural machine translation decod-
ing with terminology constraints. In Proceedings of
NAACL-HLT .

Chris Hokamp and Qun Liu. 2017. Lexically con-
strained decoding for sequence generation using grid
beam search. In Proceedings of ACL .

Josef Jon, Michal Novák, João Paulo Aires, Dusan Varis,
and Ondřej Bojar. 2021. CUNI systems for WMT21:
Terminology translation shared task. In Proceedings
of WMT .

Marcin Junczys-Dowmunt, Roman Grundkiewicz,
Tomasz Dwojak, Hieu Hoang, Kenneth Heafield,
Tom Neckermann, Frank Seide, Ulrich Germann,
Alham Fikri Aji, Nikolay Bogoychev, André F. T.
Martins, and Alexandra Birch. 2018. Marian: Fast
neural machine translation in C++. In Proceedings
of ACL .

Tomoyuki Kajiwara. 2019. Negative lexically con-
strained decoding for paraphrase generation. In Pro-
ceedings of ACL .

Alexander Molchanov, Vladislav Kovalenko, and Fedor
Bykov. 2021. PROMT systems for WMT21 termi-
nology translation task. In Proceedings of WMT .

Yasmin Moslem, Rejwanul Haque, John D. Kelleher,
and Andy Way. 2023. Adaptive machine transla-
tion with large language models. In Proceedings of
EAMT .

Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. Bleu: a method for automatic evalu-
ation of machine translation. In Proceedings of ACL .

Minh Quang Pham, Josep Crego, Antoine Senellart,
Dan Berrebbi, and Jean Senellart. 2021. SYSTRAN
@ WMT 2021: Terminology task. In Proceedings of
WMT .

Matt Post, Shuoyang Ding, Marianna Martindale, and
Winston Wu. 2019. An exploration of placeholding
in neural machine translation. In Proceedings of MT
Summit .

Ricardo Rei, Craig Stewart, Ana C Farinha, and Alon
Lavie. 2020. COMET: A neural framework for MT
evaluation. In Proceedings of EMNLP .

Elsbeth Turcan, David Wan, Faisal Ladhak, Petra Galus-
cakova, Sukanta Sen, Svetlana Tchistiakova, Wei-
jia Xu, Marine Carpuat, Kenneth Heafield, Douglas
Oard, and Kathleen McKeown. 2022. Constrained re-
generation for cross-lingual query-focused extractive
summarization. In Proceedings of COLING .

Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob
Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz
Kaiser, and Illia Polosukhin. 2017. Attention is all
you need. In NeurIPS .

David Vilar, Markus Freitag, Colin Cherry, Jiaming Luo,
Viresh Ratnakar, and George Foster. 2023. Prompt-
ing PaLM for translation: Assessing strategies and
performance. In Proceedings of ACL .

Biao Zhang, Barry Haddow, and Alexandra Birch. 2023.
Prompting large language model for machine transla-
tion: A case study. In Proceedings of ICML .

# 2309.17061.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/multilingual/2309.17061.pdf
# Kích thước tệp: 801242 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
SCALE: SỰ CỘNG TÁC ĐỒNG BỘ CỦA CÁC ĐỘNG CƠ DỊCH NGÔN NGỮ BẤT ĐỐI XỨNG

Xin Cheng¹ Xun Wang² Tao Ge²
Si-Qing Chen² Furu Wei² Dongyan Zhao¹ Rui Yan³
¹Đại học Bắc Kinh ²Microsoft ³Đại học Nhân dân Trung Quốc

TÓM TẮT
Trong bài báo này, chúng tôi giới thiệu SCALE, một khung cộng tác kết nối các Mô hình Dịch thuật Chuyên biệt nhỏ gọn (STM) và các Mô hình Ngôn ngữ Lớn đa mục đích (LLM) thành một động cơ dịch thuật thống nhất. Bằng cách đưa bản dịch từ STM vào các minh chứng ba thành phần trong ngữ cảnh, SCALE mở khóa khả năng tinh chỉnh và xoay trục của LLM, do đó giảm thiểu độ lệch ngôn ngữ của LLM và độ lệch dữ liệu song song của STM, tăng cường tính chuyên biệt của LLM mà không hy sinh tính tổng quát, và hỗ trợ học tập liên tục mà không cần tinh chỉnh LLM đắt đỏ. Các thí nghiệm toàn diện của chúng tôi cho thấy SCALE vượt trội hơn đáng kể so với cả LLM few-shot (GPT-4) và các mô hình chuyên biệt (NLLB) trong các thiết lập tài nguyên thấp đầy thách thức. Hơn nữa, trong dịch thuật từ Xhosa sang tiếng Anh, SCALE có cải thiện nhất quán 4 điểm BLEURT mà không cần điều chỉnh LLM và vượt qua few-shot GPT-4 với 2,5 điểm COMET và 3,8 điểm BLEURT khi được trang bị một mô hình nhỏ gọn chỉ có 600M tham số. SCALE cũng có thể khai thác hiệu quả độ lệch ngôn ngữ hiện có của LLM bằng cách sử dụng STM tập trung tiếng Anh làm điểm xoay cho dịch thuật giữa bất kỳ cặp ngôn ngữ nào, vượt trội hơn few-shot GPT-4 trung bình 6 điểm COMET qua tám hướng dịch thuật. Hơn nữa, chúng tôi cung cấp phân tích sâu về độ mạnh mẽ, đặc điểm dịch thuật và chi phí độ trễ của SCALE, cung cấp nền tảng vững chắc cho các nghiên cứu tương lai khám phá tiềm năng hiệp lực giữa LLM và các mô hình chuyên biệt, đặc thù cho nhiệm vụ.

1 GIỚI THIỆU
Các Mô hình Ngôn ngữ Lớn (LLM) gần đây đã cách mạng hóa lĩnh vực xử lý ngôn ngữ tự nhiên (OpenAI, 2023; Touvron et al., 2023; Peng et al., 2023), ảnh hưởng đáng kể đến dịch máy (MT) bằng cách mang lại hiệu suất xuất sắc mà không cần corpus song ngữ, đặc biệt là trong các ngôn ngữ có tài nguyên cao (Brown et al., 2020; Garcia et al., 2023). Hơn nữa, như một người học đa nhiệm thống nhất, LLM đại diện cho một bước tiến quan trọng hướng tới trí tuệ nhân tạo tổng quát (Bubeck et al., 2023), với tiềm năng vượt qua không chỉ rào cản ngôn ngữ mà còn cả ranh giới văn hóa đồng thời thông qua một lời nhắc đơn giản "dịch và giải thích".

Mặc dù có những tiến bộ, các hệ thống dịch thuật dựa trên LLM vẫn đối mặt với một số thách thức. Thứ nhất, tồn tại độ lệch ngôn ngữ đáng kể về phía tiếng Anh (ví dụ, 92,1% corpus tiền huấn luyện của GPT-3 là tiếng Anh, trong khi tiếng Pháp, lớn thứ hai, chỉ chiếm 1,8%), điều này hạn chế đáng kể hiệu suất dịch thuật đa ngôn ngữ, đặc biệt đối với những ngôn ngữ có tài nguyên thấp (Scao et al., 2022; Hendy et al., 2023). Thứ hai, như một cách tiếp cận thực tế để cải thiện hệ thống, việc tinh chỉnh LLM đặt ra những thách thức lớn. Bao gồm (1) sự đánh đổi giữa tính chuyên biệt và tính tổng quát (Cheng et al., 2023a; Lin et al., 2023), và (2) chi phí cực kỳ cao liên quan đến việc điều chỉnh các mô hình quy mô lớn (Hu et al., 2021; Dettmers et al., 2023). Ngược lại, các Mô hình Dịch thuật Chuyên biệt truyền thống (STM) - những mô hình dựa trên kiến trúc encoder-decoder, được huấn luyện có giám sát và nhỏ hơn đáng kể về kích thước (Sutskever et al., 2014; Vaswani et al., 2017) - đóng vai trò là chuyên gia cho các nhiệm vụ dịch thuật cụ thể và có thể được tinh chỉnh hiệu quả. Tuy nhiên, các mô hình này thiếu khả năng ngôn ngữ tổng quát và có thể dễ bị ảnh hưởng bởi độ lệch dữ liệu song song, chẳng hạn như việc ghi nhớ các mẫu chất lượng thấp (Raunak et al., 2022).

Trong bài báo này, chúng tôi lần đầu tiên chứng minh khả năng thống nhất hai động cơ dịch thuật bất đối xứng này trong một khung duy nhất. Công trình của chúng tôi, SCALE, kết nối LLM và STM bằng cách sử dụng khả năng bí ẩn nhất của LLM: học trong ngữ cảnh. Thay vì sử dụng các cặp nguồn-đích như trong dịch thuật few-shot thông thường (Garcia et al., 2023; Vilar et al., 2023), SCALE sẽ đầu tiên lấy mẫu các bản dịch từ STM và sau đó sử dụng các bộ ba gồm một câu nguồn, một tập hợp do STM tạo ra và một câu đích làm minh chứng trong ngữ cảnh để mở khóa khả năng tinh chỉnh và xoay trục của LLM. Với SCALE, chúng tôi có thể (1) giảm thiểu cả độ lệch ngôn ngữ của LLM bằng cách sử dụng STM tập trung vào một cặp ngôn ngữ cụ thể, và độ lệch dữ liệu song song của STM bằng cách sử dụng LLM đa mục đích làm thân chính của hệ thống; (2) tăng cường tính chuyên biệt của LLM mà không ảnh hưởng đến tính tổng quát; (3) hỗ trợ học tập liên tục trong khung bằng cách chỉ cập nhật STM nhẹ, do đó tránh việc tinh chỉnh LLM đắt đỏ. Bằng cách sử dụng SCALE, chúng tôi tạo ra một hệ thống hiệu quả và hiệu suất hơn kết hợp điểm mạnh của cả hai động cơ dịch thuật.

Các thí nghiệm toàn diện của chúng tôi cho thấy SCALE vượt trội hơn đáng kể so với LLM few-shot (ví dụ, GPT-4) và các mô hình chuyên biệt (ví dụ, NLLB) trong thiết lập tài nguyên thấp đầy thách thức, như được minh họa trong Hình 1. Hơn nữa, trong dịch thuật từ Xhosa sang tiếng Anh, SCALE có cải thiện nhất quán 4 điểm BLEURT mà không cần điều chỉnh LLM và vượt qua few-shot GPT-4 với 2,5 điểm COMET và 3,8 điểm BLEURT khi được trang bị một mô hình nhỏ gọn chỉ có 600M tham số. Đáng chú ý, SCALE có thể khai thác hiệu quả độ lệch ngôn ngữ hiện có của LLM bằng cách sử dụng STM tập trung tiếng Anh làm điểm xoay cho dịch thuật giữa bất kỳ cặp ngôn ngữ nào, vượt trội hơn few-shot GPT-4 trung bình 6 điểm COMET qua tám hướng dịch thuật. Hơn nữa, chúng tôi tiến hành phân tích sâu về độ mạnh mẽ, đặc điểm dịch thuật và chi phí độ trễ liên quan đến SCALE. Các phát hiện của chúng tôi cung cấp những hiểu biết có giá trị và khuyến khích nghiên cứu thêm trong lĩnh vực này.

2 KHUNG SCALE
Trong phần này, chúng tôi trình bày phương pháp SCALE được đề xuất và cung cấp tổng quan được minh họa trong Hình 2. Được phổ biến bởi GPT-3 (Brown et al., 2020), Học trong Ngữ cảnh (ICL) cho phép LLM thực hiện nhiều loại nhiệm vụ khác nhau, thậm chí cả những nhiệm vụ mới được tạo ra (Bills et al., 2023), bằng cách tận dụng học few-shot với số lượng minh chứng hạn chế. Đối với một nhiệm vụ dịch thuật từ ngôn ngữ nguồn X sang ngôn ngữ đích Y, một LLM với tham số θ thực hiện ICL bằng cách điều kiện hóa trên k ví dụ cặp nguồn-đích E = (x₁, y₁) ⊕ (x₂, y₂) ⊕ ... (xₖ, yₖ) và câu nguồn kiểm tra x, tạo ra đích y theo cách tự hồi quy như y_t ∼ pθ(y_t|E, x, y<t). Trong tình huống này, LLM phải phân tích các ví dụ được cung cấp để nhận biết phân phối đầu vào, phân phối đầu ra, ánh xạ đầu vào-đầu ra và định dạng để hoàn thành nhiệm vụ thành công (Press et al., 2022; Wei et al., 2023). Khác với ICL thông thường, SCALE giới thiệu một biến trung gian Z làm tham chiếu giữa nguồn x và đích y, biến đổi mỗi ví dụ minh chứng thành một bộ ba (x, Z, y). Biến Z là một tập hợp tạo ra được lấy mẫu từ một mô hình dịch thuật chuyên biệt M_{X→Y} được huấn luyện trên một tập dữ liệu có nhãn. Đầu vào cuối cùng cho LLM bao gồm hướng dẫn, minh chứng và câu nguồn được kết hợp trong một mẫu lời nhắc: T((x₁, Z₁, y₁) ⊕ (x₂, Z₂, y₂) ... ⊕ (xₖ, Zₖ, yₖ)), (x, Z)).

Khác với các nhiệm vụ hiểu ngôn ngữ có tập nhãn cố định (Xu et al., 2023), không gian giả thuyết của mô hình dịch thuật thực chất là vô hạn, vì vậy chúng tôi có thể lấy mẫu nhiều đường dẫn tạo ra từ STM cho một câu nguồn duy nhất để cung cấp hướng dẫn tạo ra toàn diện hơn cho LLM. Khung SCALE, mặc dù về mặt khái niệm đơn giản, chứng minh một số ưu điểm so với STM và LLM, như được nêu bật dưới đây:

Tinh chỉnh: Đối với nhiệm vụ dịch thuật X sang Y, khi biến trung gian Z là từ M_{X→Y}(x), SCALE về cơ bản tiến hành học few-shot theo cách đa nhiệm bằng cách giới thiệu một nhiệm vụ tinh chỉnh bổ sung. Tinh chỉnh từ lâu đã được chứng minh hiệu quả trong MT (Xia et al., 2017; Cheng et al., 2022). Và điều này cũng đúng với dịch thuật dựa trên LLM. Trong quá trình tinh chỉnh này, chúng tôi truyền các câu được lấy mẫu và điểm tin cậy của chúng (điểm xác suất) từ STM đến LLM. LLM sau đó tiêu hóa thông tin được mang theo bởi tập hợp được lấy mẫu và suy luận không gian tạo ra của STM, điều này hướng dẫn LLM tạo ra đầu ra phù hợp hơn với phân phối dữ liệu cục bộ (Xu et al., 2023). Và vì bản dịch cuối cùng được cung cấp bởi LLM, SCALE cũng có thể giảm thiểu độ lệch dữ liệu song song từ STM và thể hiện tính mạnh mẽ bằng cách không chỉ đơn giản sao chép và dán bản dịch nháp từ STM như được hiển thị trong §5.3.

Xoay trục: Xét đến bản chất chủ yếu tập trung tiếng Anh của hầu hết LLM (Brown et al., 2020; Touvron et al., 2023), SCALE có thể sử dụng một biến trung gian Z từ M_{X→English}(x) trong đó ngôn ngữ đích Y không nhất thiết phải là tiếng Anh. Và ở đây Z đóng vai trò là điểm xoay cho LLM để tăng cường hiểu biết về câu nguồn và tạo ra các bản dịch được cải thiện. Điều này cũng có thể được coi như một hình thức chuyển giao kiến thức từ ngôn ngữ có tài nguyên cao sang ngôn ngữ có tài nguyên thấp (Chen et al., 2017; Kim et al., 2019; Jiao et al., 2023).

Cập nhật: Một hạn chế đáng kể của các hệ thống dịch thuật dựa trên LLM hiện tại là sự phức tạp vốn có của học tập liên tục LLM. Sự phức tạp này phát sinh từ một số yếu tố, bao gồm sự cân bằng tinh tế giữa tính chuyên biệt và tính tổng quát (Lin et al., 2023), vấn đề quên lãng thảm khốc (Yong et al., 2023), và các yêu cầu tính toán đáng kể (Dettmers et al., 2023). Ngược lại, khung SCALE cung cấp một cách tiếp cận hiệu quả và hợp lý hơn để cập nhật liên tục. Bằng cách cập nhật độc quyền và hiệu quả thành phần M_{X→·} nhẹ, khung đảm bảo rằng LLM vẫn không bị ảnh hưởng, do đó bảo tồn khả năng ngôn ngữ tổng quát của nó. Quá trình cập nhật có chọn lọc này không chỉ giảm thiểu vấn đề quên lãng thảm khốc mà còn giảm gánh nặng tính toán của việc tinh chỉnh liên quan đến các hệ thống dịch thuật dựa trên LLM.

3 THIẾT LẬP THÍ NGHIỆM
3.1 TẬP DỮ LIỆU
Các tập dữ liệu đánh giá của chúng tôi bao gồm một tập hợp đa dạng các ngôn ngữ, trải dài từ các thiết lập tài nguyên thấp đến cao và có nguồn gốc từ nhiều họ ngôn ngữ khác nhau. Để tạo điều kiện tái tạo và chia sẻ dữ liệu, tất cả các tập dữ liệu đánh giá của chúng tôi đều đến từ phần devtest của Flores-200 (NLLB Team et al., 2022), một tập dữ liệu đánh giá nhiều-sang-nhiều có sẵn công khai bao gồm 200 ngôn ngữ từ khắp nơi trên thế giới.

3.2 HỆ THỐNG DỊCH THUẬT
Chúng tôi so sánh phương pháp của mình với các hệ thống học thuật tiên tiến bao gồm cả mô hình chuyên biệt và LLM, cũng như một hệ thống thương mại, Microsoft Translator.

Chúng tôi có hai mô hình chuyên biệt mạnh:
• M2M100 (Fan et al., 2021) là mô hình dịch thuật encoder-decoder đa ngôn ngữ đầu tiên có thể dịch giữa bất kỳ cặp nào trong 100 ngôn ngữ mà không cần dựa vào dữ liệu tiếng Anh.
• NLLB (NLLB Team et al., 2022) là bộ mô hình dịch thuật có giám sát bao gồm từ 169M đến 54.5B (MOE) tham số với kiến trúc encoder-decoder và có khả năng cung cấp bản dịch chất lượng cao trực tiếp giữa 200 ngôn ngữ.

Đối với LLM few-shot, chúng tôi xem xét:
• XGLM (Lin et al., 2022) là mô hình ngôn ngữ tạo ra đa ngôn ngữ được huấn luyện trên corpus bao gồm một tập hợp đa dạng các ngôn ngữ và mô hình XGLM-7.5B lớn nhất vượt trội hơn mô hình GPT-3 có kích thước tương đương trong thiết lập đa ngôn ngữ.
• GPT-3.5 là mô hình GPT được tối ưu hóa đặc biệt cho mục đích hội thoại và cho thấy hiệu suất xuất sắc trong các nhiệm vụ dịch máy (Jiao et al., 2023).
• GPT-4 (OpenAI, 2023) là phiên bản mới nhất và mạnh mẽ nhất của dòng GPT.

Chúng tôi sử dụng cả GPT-3.5 và GPT-4 từ Microsoft Azure OpenAI Service. Không có thông báo gì thêm, số lượng mẫu few-shot trong LLM và SCALE được đặt là 10 và chiến lược lựa chọn mẫu tuân theo Agrawal et al. (2022). Lời nhắc chúng tôi sử dụng có thể được tìm thấy trong Phụ lục A.1.

3.3 THANG ĐO ĐÁNH GIÁ
Vì các thang đo neural đã cho thấy mối tương quan cao hơn với sở thích của con người (Freitag et al., 2022; Rei et al., 2020) và được áp dụng rộng rãi bởi các tài liệu gần đây (Hendy et al., 2023; Garcia et al., 2023), chúng tôi chủ yếu đánh giá hệ thống của mình bằng (1) COMET-22, một thang đo neural dựa trên tham chiếu (Rei et al., 2022a) kết hợp đánh giá trực tiếp, điểm mức câu và thẻ mức từ từ các chú thích thang đo chất lượng đa chiều, (2) COMETKiwi, một mô hình ước lượng chất lượng không tham chiếu từ Rei et al. (2022b), và (3) BLEURT (Sellam et al., 2020), một thang đo đánh giá có thể học với mô hình hồi quy được huấn luyện trên dữ liệu xếp hạng. Để hoàn chỉnh, chúng tôi cũng bao gồm kết quả của các thang đo từ vựng như spBLEU (NLLB Team et al., 2022) và chrF++ (Popovic, 2017).

4 KẾT QUẢ THÍ NGHIỆM
Trong phần này, chúng tôi tiến hành các thí nghiệm khác nhau để cho thấy tính hiệu quả của khung của chúng tôi. Trong §4.1, chúng tôi xác minh tính hiệu quả của khả năng tinh chỉnh trong SCALE bằng cách so sánh với STM và LLM few-shot. Trong §4.2, chúng tôi tập trung vào các cặp không phải tiếng Anh để kiểm tra khả năng xoay trục của SCALE. Trong §4.3, chúng tôi cho thấy kết quả học tập liên tục của SCALE với LLM cố định và STM đang phát triển.

4.1 TINH CHỈNH SCALE
Để đánh giá khả năng tinh chỉnh của SCALE, phần này chủ yếu tập trung vào các ngôn ngữ có tài nguyên thấp, hiện tại đặt ra những thách thức đáng kể cho LLM few-shot. Cách tiếp cận của chúng tôi thể hiện tính linh hoạt bằng cách kết hợp các ngôn ngữ từ nhiều họ và chữ viết đa dạng, bao gồm Assamese (asm Beng), Armenian (hye Armn), Amharic (amh Ethi), Xhosa (xho Latn), Uyghur (uig Arab), Khmer (khm Khmr), Nepali (npi Deva), và Sindhi (snd Arab). Để biết thêm chi tiết dữ liệu, vui lòng tham khảo Phụ lục A.2.

[Tiếp tục với phần còn lại của nội dung theo cách tương tự...]

--- TRANG 2 ---
[Hình 1: Kết quả dịch thuật của LLM few-shot (GPT-4), STM (NLLB) và SCALE (của chúng tôi) cho sáu ngôn ngữ có tài nguyên thấp được đo bằng COMET và BLEURT.]

--- TRANG 3 ---
[Hình 2: Khung SCALE, bao gồm một mô hình chuyên biệt nhẹ và một mô hình ngôn ngữ lớn đông cứng với các minh chứng ba thành phần trong ngữ cảnh.]

--- TRANG 4 ---
[Bảng 1: Kết quả dịch thuật của tám ngôn ngữ có tài nguyên thấp sang tiếng Anh. Kết quả tốt nhất được in đậm và kết quả tốt thứ hai được gạch dưới. SCALE-refine được so sánh với mô hình chuyên biệt (NLLB, M2M), hệ thống thương mại (MS Translator) và LLM few-shot (XGLM, GPT-3.5, GPT-4).]

--- TRANG 5 ---
[Hình 3: Kết quả dịch thuật từ Lao sang cả ngôn ngữ có tài nguyên thấp và cao, trong đó GPT-4 sử dụng prompting few-shot và SCALE-pivot sử dụng tiếng Anh làm ngôn ngữ xoay trục.]

--- TRANG 6 ---
[Hình 4: Kết quả dịch thuật từ Xhosa sang tiếng Anh với STM đang phát triển trong khung SCALE.]

--- TRANG 7 ---
[Hình 5: Điểm perplexity từ dịch thuật X→tiếng Anh được đo bằng GPT2-XL.]

--- TRANG 8 ---
[Bảng 2: Kết quả dịch thuật từ Xhosa sang tiếng Anh với lấy mẫu đa đường dẫn. Tất cả các thí nghiệm được tiến hành bằng SCALE-refine một shot và chỉ khác nhau về số lượng đường dẫn được lấy mẫu từ STM.]

--- TRANG 9 ---
[Bảng 3: Nghiên cứu ablation cho SCALE với dịch thuật Xhosa→tiếng Anh.]

--- TRANG 10 ---
[Bảng 4: Kết quả độ trễ tạo ra của LLM (BLOOM-175B) và SCALE (BLOOM-175B + NLLB-3.3B) được đo bằng giây (s).]

--- TRANG 11 ---
[Phần 6: CÔNG TRÌNH LIÊN QUAN]

--- TRANG 12 ---
[Phần 7: KẾT LUẬN]

--- TRANG 13 ---
[PHỤ LỤC A.1: VÍ DỤ LỜI NHẮC]

--- TRANG 14 ---
[PHỤ LỤC A.2: THỐNG KÊ DỮ LIỆU]

--- TRANG 15 ---
[PHỤ LỤC A.3: CÁC TRƯỜNG HỢP DỊCH THUẬT]

--- TRANG 16 ---
[Các ví dụ dịch thuật cụ thể]

--- TRANG 17 ---
[Tiếp tục các ví dụ dịch thuật]

--- TRANG 18 ---
[Kết thúc các ví dụ dịch thuật]

# 2308.14186.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/multilingual/2308.14186.pdf
# Kích thước file: 630262 bytes

===============================================
NỘI DUNG FILE PDF
===============================================


--- TRANG 1 ---
Tăng cường khả năng đa ngôn ngữ của các Mô hình Ngôn ngữ Lớn được tinh chỉnh bằng hướng dẫn thông qua các minh họa tuân theo dịch thuật
Leonardo Ranaldi(†), Giulia Pucci, André Freitas(†,∗)
(†)Viện Nghiên cứu Idiap, Martigny, Thụy Sĩ
(∗)Khoa Khoa học Máy tính, Đại học Manchester, Vương quốc Anh
[first_name].[last_name]@idiap.ch ,[first_name].[last_name]@manchester.ac.uk
Tóm tắt
Khả năng ngôn ngữ của các Mô hình Ngôn ngữ Lớn (LLMs) thường mất cân bằng về phía tiếng Anh do sự mất cân bằng trong phân phối dữ liệu tiền huấn luyện. Sự chênh lệch này được yêu cầu trong việc tinh chỉnh thêm và ảnh hưởng đến khả năng đa ngôn ngữ của LLMs. Trong bài báo này, chúng tôi đề xuất tăng cường It-LLMs (Instruction-tuned LLMs) ở các ngôn ngữ khác ngoài tiếng Anh bằng cách xây dựng sự căn chỉnh ngữ nghĩa giữa chúng. Do đó, chúng tôi đề xuất CrossAlpaca, một It-LLM với các minh họa tuân theo Hướng dẫn đa ngôn ngữ và tuân theo Dịch thuật để cải thiện sự căn chỉnh ngữ nghĩa giữa các ngôn ngữ. Chúng tôi xác thực phương pháp của mình trên các điểm chuẩn Trả lời Câu hỏi (QA) đa ngôn ngữ XQUAD và MLQA và các phiên bản đã điều chỉnh của MMLU và BBH. Các mô hình của chúng tôi, được thử nghiệm trên sáu ngôn ngữ khác nhau, vượt trội hơn các It-LLMs được tinh chỉnh trên dữ liệu đơn ngôn ngữ. Kết quả cuối cùng cho thấy việc tinh chỉnh hướng dẫn trên dữ liệu không phải tiếng Anh là chưa đủ và sự căn chỉnh ngữ nghĩa có thể được cải thiện thêm bằng các minh họa tuân theo Dịch thuật. Mã và dữ liệu của chúng tôi có sẵn¹

1 Giới thiệu
Các Mô hình Ngôn ngữ Lớn (LLMs) đạt được khả năng ngôn ngữ toàn diện thông qua tiền huấn luyện trên các kho ngữ liệu lớn (Brown et al., 2020; Touvron et al., 2023). Do đó, các khả năng ngôn ngữ thu được tuân theo từ các đặc điểm của kho ngữ liệu, chủ yếu có sẵn bằng tiếng Anh (Lin et al., 2021; Zhang et al., 2023; Zhu et al., 2023a). Hiện tượng này tạo ra sự mất cân bằng trong cả tiền huấn luyện (Blevins và Zettlemoyer, 2022) và tinh chỉnh (Le et al., 2021). Do đó, LLMs hoạt động kém ở các ngôn ngữ khác với tiếng Anh (Huang et al., 2023; Bang et al., 2023).

Các nỗ lực tăng khả năng đa ngôn ngữ đề xuất tiếp tục tiền huấn luyện với dữ liệu đơn ngôn ngữ quy mô lớn (Imani et al., 2023; Cui et al., 2023; Yang et al., 2023). Tuy nhiên, việc học một ngôn ngữ từ dữ liệu đơn ngôn ngữ đòi hỏi dữ liệu và tài nguyên tính toán đáng kể.

Trong bài báo này, chúng tôi đề xuất CrossAlpaca, một It-LLM (Instruction-tuned LLM) được tăng cường với sự căn chỉnh ngữ nghĩa giữa tiếng Anh và các ngôn ngữ khác. Chúng tôi phân tích cách khai thác khả năng không phải tiếng Anh của It-LLMs bằng cách tập trung vào giai đoạn quan trọng: tinh chỉnh hướng dẫn trên các minh họa tuân theo Hướng dẫn. Do đó, chúng tôi nghiên cứu tác động của việc căn chỉnh đa ngôn ngữ bằng cách đề xuất các minh họa tuân theo Dịch thuật để cải thiện giai đoạn tinh chỉnh hướng dẫn.

Trong các thí nghiệm của chúng tôi, chúng tôi sử dụng LLaMA-7B (Touvron et al., 2023) làm xương sống LLM và xem xét sáu ngôn ngữ đích được chọn từ số các dữ liệu có sẵn (được hiển thị trong Bảng 4); khi dữ liệu vắng mặt, chúng tôi thực hiện một nhiệm vụ dịch thuật. Làm minh họa tuân theo Hướng dẫn, chúng tôi sử dụng bộ dữ liệu Stanford Alpaca (Taori et al., 2023) và các phiên bản được dịch trong các ngôn ngữ tương ứng, trong khi đối với tuân theo Dịch thuật, chúng tôi sử dụng một tài nguyên dịch thuật có sẵn công khai news_commentary (Tiedemann, 2012), có thể truy cập và mở rộng nhất cho nhiều ngôn ngữ (tức là, các minh họa CrossAlpaca trên Hình 1).

Sau giai đoạn tinh chỉnh hướng dẫn, chúng tôi đánh giá hiệu suất của sáu CrossAlpacas cụ thể theo ngôn ngữ bằng cách sử dụng bốn điểm chuẩn khác nhau: hai điểm chuẩn đa ngôn ngữ gốc, tức là XQUAD (Artetxe et al., 2019) và MLQA (Lewis et al., 2020), và hai điểm chuẩn đơn ngôn ngữ gốc, MMLU (Hendrycks et al., 2021) và BBH (Suzgun et al., 2022). Kết quả cho thấy CrossAlpacas được hướng dẫn với dữ liệu hướng dẫn và dịch thuật cụ thể theo ngôn ngữ vượt trội hơn nhiều so với Alpacas chỉ được hướng dẫn với các minh họa không phải tiếng Anh. Tuy nhiên, mặc dù CrossAlpaca giảm khoảng cách, các mô hình tuân theo Dịch thuật của Alpaca gốc vẫn hoạt động tốt nhất.

Kết quả này cho thấy khả năng học của LLaMA trên dữ liệu tiếng Anh vượt trội hơn so với dữ liệu không phải tiếng Anh. Nhiệm vụ căn chỉnh ngữ nghĩa cũng cải thiện khả năng đa ngôn ngữ của It-LLMs.

Các phát hiện của chúng tôi có thể được tóm tắt như sau:
• Khả năng học của LLMs trên các nhiệm vụ tinh chỉnh Hướng dẫn không phải tiếng Anh bị hạn chế;
• Khả năng đa ngôn ngữ của các Mô hình Ngôn ngữ Lớn được tinh chỉnh Hướng dẫn có thể được tăng cường thông qua căn chỉnh đa ngôn ngữ;
• Do đó, chúng tôi đề xuất CrossAlpaca, một phương pháp tinh chỉnh Hướng dẫn cho các mô hình không phải tiếng Anh dựa trên minh họa tuân theo Hướng dẫn và tuân theo Dịch thuật cho ngôn ngữ đích;
• Chúng tôi cho thấy It-LLMs có thể căn chỉnh ngữ nghĩa thông qua các minh họa tuân theo Dịch thuật đa ngôn ngữ qua một đánh giá rộng rãi trên bốn điểm chuẩn QA đa ngôn ngữ.

2 Công trình liên quan
2.1 Mô hình Ngôn ngữ Được tiền huấn luyện trên Kho ngữ liệu Đa ngôn ngữ

Dự đoán token tiếp theo dựa trên chuỗi tiền tố, được biết đến như là mô hình hóa ngôn ngữ, là nhiệm vụ bất diệt của NLP hiện đại (Tenney et al., 2019). Kiến thức rộng lớn của các Mô hình Ngôn ngữ Lớn (LLMs) ngày nay phụ thuộc vào hàng tỷ neuron được huấn luyện trên các kho ngữ liệu quy mô lớn với các dẫn xuất của nhiệm vụ mô hình hóa ngôn ngữ. Do đó, các kho ngữ liệu tiền huấn luyện chủ yếu bằng tiếng Anh, ví dụ: BooksCorpus (Zhu et al., 2015), MEGATRON-LM (Shoeybi et al., 2019), Gutenberg Dataset (Lahiri, 2014) PILE (Gao et al., 2020), C4 (Dodge et al., 2021), RefinedWeb (Penedo et al., 2023); do đó, LLMs thường có kiến thức về tiếng Anh tốt hơn nhiều so với các ngôn ngữ khác.

Aulamo và Tiedemann (2019); Abadji et al. (2022), để giải quyết vấn đề này, đề xuất các kho ngữ liệu tiến về phía trước được dịch sang nhiều ngôn ngữ. Tuy nhiên, các kho ngữ liệu này không lớn như các đối thủ cạnh tranh của chúng, và việc thiếu dữ liệu song song quy mô lớn trong các kho ngữ liệu tiền huấn luyện cũng ngăn cản LLMs căn chỉnh các ngôn ngữ khác nhau một cách tốt (Li et al., 2023).

2.2 Mô hình tinh chỉnh Hướng dẫn

Ouyang et al. (2022); Wei et al. (2022) đã tinh chỉnh LLMs bằng phương pháp tinh chỉnh Hướng dẫn dựa trên dữ liệu tinh chỉnh Hướng dẫn, là các kho ngữ liệu hướng dẫn-phản hồi, để làm cho LLMs có thể mở rộng hơn và cải thiện hiệu suất zero-shot. Trong phương pháp này, xương sống LLM được cung cấp dữ liệu từ hướng dẫn (I, X, Y), trong đó I là một hướng dẫn mô tả yêu cầu của nhiệm vụ, X là đầu vào, có thể tùy chọn, và Y là đầu ra cho nhiệm vụ đã cho.

Mục tiêu của phương pháp này là tối thiểu hóa hàm f(Y):
f(Y) = arg min_θ log p_θ(Y|I, X) (1)
trong đó θ là các tham số có thể học được của mô hình.

Các nghiên cứu trước đó cho thấy phương pháp tinh chỉnh hướng dẫn của LLMs với cả hướng dẫn của con người (Wang et al., 2023) và được tạo tổng hợp (Taori et al., 2023; Xu et al., 2023) tăng cường khả năng của LLMs để giải quyết các nhiệm vụ đáng kể trong các tình huống zero-shot.

--- TRANG 3 ---
Hình 2: Ví dụ về các minh họa tuân theo Dịch thuật. Trong ví dụ cụ thể này, có hai minh họa với hai hướng khác nhau từ tiếng Anh sang tiếng Đức (en-x) và ngược lại.

Tuy nhiên, chúng tôi tuyên bố rằng các bộ dữ liệu tinh chỉnh hướng dẫn được sử dụng phổ biến, alpaca (Taori et al., 2023), Self-Instruct (Wang et al., 2023), Self-Chat (Xu et al., 2023), được hình thành bằng tiếng Anh, điều này hạn chế triển vọng của LLMs để tuân theo các hướng dẫn không phải tiếng Anh và do đó giải quyết các nhiệm vụ liên quan.

2.3 Tinh chỉnh hướng dẫn đang trong tầm tay

Các Mô hình Ngôn ngữ Lớn có thành công đáng kể với nhiều kỹ thuật đang thịnh hành, chẳng hạn như tinh chỉnh Hướng dẫn. Tuy nhiên, kích thước cấm đoán của chúng chỉ cho phép một phần của cộng đồng khoa học thử nghiệm với các mô hình này.

Những tiến bộ mới nhất làm cho các mô hình và kỹ thuật này có thể truy cập được bao gồm việc điều chỉnh tham số hiệu quả. Điều chỉnh Hiệu quả Tham số (PEFT) là một kỹ thuật hiệu quả để điều chỉnh một phần nhỏ các tham số mô hình và đóng băng các tham số khác. Mục tiêu chính là giảm đáng kể chi phí tính toán và lưu trữ trong khi duy trì hiệu suất của các mô hình gốc. Các kỹ thuật tiêu chuẩn cho PEFT là LoRA (Hu et al., 2021a), Prefix Tuning (Li và Liang, 2021), P-Tuning (Liu et al., 2022). Ý tưởng cơ bản là giữ các trọng số mô hình được tiền huấn luyện và kết hợp các ma trận thứ hạng thấp trong mỗi lớp kiến trúc. Phương pháp này giảm đáng kể số lượng tham số cần huấn luyện cho các nhiệm vụ tiếp theo, từ đó tăng hiệu quả tổng thể. Khối xây dựng này đã và tiếp tục rất quan trọng vì nó kỹ năng cho cộng đồng khoa học nghiên cứu công bằng và cho phép phát triển nhiều công trình mã nguồn mở.

2.4 Thách thức tinh chỉnh Hướng dẫn Đa ngôn ngữ

Công trình gần đây đã cho thấy khả năng đáng chú ý của LLMs trong việc học hướng dẫn ở các ngôn ngữ khác nhau.

[THIS IS TABLE: Chi tiết và tên của các Mô hình Ngôn ngữ Lớn được tinh chỉnh Hướng dẫn đơn ngôn ngữ sử dụng phiên bản cụ thể theo ngôn ngữ của Alpaca làm dữ liệu tinh chỉnh hướng dẫn.]

Mô hình | Ngôn ngữ | Tên
Alpaca (Taori et al., 2023) | Tiếng Anh | en-Alpaca
Alpaca-Chinese (Chen et al., 2023) | Tiếng Trung | zh-Alpaca
Arabic Alpaca (Yasbok) | Tiếng Ả Rập | ar-Alpaca
Camoscio (Santilli và Rodolà, 2023) | Tiếng Ý | it-Alpaca
Guanaco (Kohaku-Blueleaf, 2023) | Tiếng Tây Ban Nha | es-Alpaca
German Alpaca (Thissen, 2023) | Tiếng Đức | de-Alpaca

Santilli và Rodolà (2023); Chen et al. (2023) đã đề xuất các điều chỉnh tinh chỉnh đơn ngôn ngữ LLaMA trên các hướng dẫn được dịch cụ thể theo ngôn ngữ. Việc sử dụng các kỹ thuật tối ưu hóa được giới thiệu trong Phần 2.3, để đề xuất các bộ điều hợp tùy chỉnh hấp dẫn cho các nhiệm vụ khác nhau. Zhang et al. (2023); Zhu et al. (2023b) đã điều tra khả năng đa ngôn ngữ của It-LLMs bằng cách thúc đẩy tác động của việc tăng cường các minh họa hướng dẫn. Đặc biệt, Zhang et al. (2023) sử dụng các bản dịch tùy chỉnh chi tiết không dễ dàng truy cập, trong khi Zhu et al. (2023b) đề xuất một phương pháp đa ngôn ngữ bằng cách tăng đáng kể các nhiệm vụ hướng dẫn và dịch thuật. Tuy nhiên, các nghiên cứu này đã mở ra một con đường thú vị trong việc phân tích khả năng đa ngôn ngữ của It-LLMs.

Trong bài báo này, chúng tôi thực hiện bước tiếp theo bằng cách đề xuất CrossAlpaca của chúng tôi. Các phương pháp của chúng tôi cho thấy khả năng học đa ngôn ngữ của It-LLMs ở quy mô lớn. Sử dụng bốn điểm chuẩn nổi tiếng, chúng tôi cho thấy điểm yếu của It-LLMs được huấn luyện trên dữ liệu không phải tiếng Anh có thể được tăng cường với các phương pháp căn chỉnh đa ngôn ngữ. Do đó, các phân tích của chúng tôi nhằm hiểu vai trò của các minh họa tuân theo Hướng dẫn và tuân theo Dịch thuật trong việc thu hẹp khoảng cách trong việc học và điều chỉnh khả năng của LLMs cho các ngôn ngữ không phải tiếng Anh.

--- TRANG 4 ---
3 Dữ liệu & Phương pháp

Tiền huấn luyện từ đầu một Mô hình Ngôn ngữ Lớn (LLM) bằng nhiều ngôn ngữ có chi phí cấm đoán cho việc thu thập dữ liệu và học tham số. Đây là lý do tại sao xu hướng là thực hiện tinh chỉnh thêm để tăng cường khả năng của các mô hình trong một ngôn ngữ cụ thể (Tanti et al., 2021; Moslem et al., 2023). Trong bài báo này, chúng tôi nhằm khai thác khả năng của LLMs được tiền huấn luyện cho các ngôn ngữ không phải tiếng Anh bằng cách cải thiện thêm sự căn chỉnh giữa tiếng Anh và ngôn ngữ đích. Do đó, trong Phần 3.1, chúng tôi giới thiệu thách thức của việc tinh chỉnh LLM trên tình huống tùy chỉnh đơn ngôn ngữ. Hơn nữa, trong Phần 3.2, chúng tôi đề xuất phương pháp của chúng tôi để tinh chỉnh LLMs đa ngôn ngữ.

3.1 Tinh chỉnh Hướng dẫn Đơn ngôn ngữ

Khả năng tiếp cận và minh bạch hạn chế của các dịch vụ API trả phí của các LLMs tiên tiến đã thúc đẩy nghiên cứu hướng tới phát triển các mô hình mã nguồn mở. Sử dụng mô hình tinh chỉnh hướng dẫn (Phần 2.2) và Stanford Alpaca (Taori et al., 2023), một kho ngữ liệu bao gồm 52k cặp hướng dẫn-đầu ra tiếng Anh được tạo bởi text-davinci-003, một số phiên bản tinh chỉnh Hướng dẫn của LLaMA đã được phát hành.

Theo phương pháp này, nhiều phiên bản tinh chỉnh Hướng dẫn đơn ngôn ngữ của LLaMA đã được đề xuất bằng cách dịch dữ liệu tuân theo Hướng dẫn Stanford Alpaca sang ngôn ngữ cụ thể. Bảng 4 (Phụ lục B) cho thấy một tập hợp các phiên bản alpaca có sẵn như mã nguồn mở. Theo một phân tích có hệ thống của các phiên bản được dịch của Alpaca trong các kho lưu trữ chính thức², các ngôn ngữ của các bộ dữ liệu điểm chuẩn, và các cặp dịch thuật có mặt trong news_commentary, sẽ được giới thiệu sau, chúng tôi đã chọn các ngôn ngữ chia sẻ nhiều dữ liệu đã có sẵn nhất. Bảng 1 cho thấy các phiên bản tùy chỉnh được sử dụng trong công trình này, để đơn giản sẽ được đổi tên thành x-Alpaca, trong đó x chỉ ngôn ngữ cụ thể.

3.2 Tinh chỉnh Hướng dẫn Đa ngôn ngữ

Các phương pháp tinh chỉnh Hướng dẫn đơn ngôn ngữ (Phần 3.1) thưởng cho khả năng đa ngôn ngữ của LLMs. Tuy nhiên, việc sử dụng Alpaca được dịch một mình cho ngôn ngữ cụ thể không đủ để khai thác khả năng không phải tiếng Anh của LLMs. Vì lý do này, chúng tôi đề xuất CrossAlpaca (Hình 1), làm phong phú tinh chỉnh Hướng dẫn đa ngôn ngữ với các minh họa tuân theo Dịch thuật. Chúng tôi nhằm làm nổi bật khả năng tiếng Anh và không phải tiếng Anh của LLMs bằng cách đề xuất một nhiệm vụ căn chỉnh ngữ nghĩa để làm phong phú các phiên bản của Alpaca.

Minh họa tuân theo Hướng dẫn Phiên bản gốc của Alpaca bằng tiếng Anh. Tuy nhiên, như mô tả trong Phần 3.1, các bản dịch mã nguồn mở khác nhau được sản xuất bằng một công cụ dịch thuật. Trong các thí nghiệm của chúng tôi, chúng tôi đề xuất giai đoạn tinh chỉnh Hướng dẫn với phiên bản tiếng Anh gốc (en-Alpaca) và các phiên bản cụ thể theo ngôn ngữ được dịch. Hơn nữa, chúng tôi đề xuất các phiên bản CrossAlpaca được xây dựng với các Alpacas khác nhau được dịch sang ngôn ngữ cụ thể và các bản dịch đa ngôn ngữ (được giới thiệu sau). Bằng cách này, chúng tôi điều tra khả năng của xương sống LLM trong việc hiểu các hướng dẫn đa ngôn ngữ và căn chỉnh đa ngôn ngữ.

Minh họa tuân theo Dịch thuật Học dữ liệu hướng dẫn chung là một chiến lược hợp lý để xây dựng các mô hình giải quyết các nhiệm vụ đa tác vụ được chỉ đạo bởi các hướng dẫn (Wang et al., 2023; Zeng et al., 2023). Tuy nhiên, dữ liệu dịch thuật có thể đóng góp vào việc học căn chỉnh ngữ nghĩa. Zhang et al. (2023) đã cho thấy hiệu suất dịch thuật của LLMs có thể được cải thiện bằng cách sử dụng dữ liệu dịch thuật được chú thích chuyên môn, và Zhu et al. (2023b) đã cho thấy nó có thể có lợi cho tinh chỉnh hướng dẫn.

Lấy cảm hứng từ Zhu et al. (2023b), chúng tôi sử dụng các bộ dữ liệu dịch thuật cấp câu có sẵn công khai, chẳng hạn như news_commentary (Tiedemann, 2012), để xây dựng các minh họa hướng dẫn nhiệm vụ dịch thuật. Chúng tôi cũng đề xuất mở rộng điều này cho các ngôn ngữ bổ sung, mà chúng tôi phát hành như một bộ dữ liệu mã nguồn mở. Đặc biệt, đối với mỗi ngôn ngữ cụ thể, chúng tôi đã xây dựng 20k minh họa. Do đó, theo phong cách Alpaca (Hướng dẫn, Đầu vào và Đầu ra) (xem Hình 1), chúng tôi ngẫu nhiên chọn 10k bản dịch tiếng Anh sang không phải tiếng Anh và 10k bản dịch ngẫu nhiên không phải tiếng Anh sang tiếng Anh (tất cả các bản dịch đều từ news_commentary). Chúng tôi đã xây dựng các tương ứng này cho các ngôn ngữ được đề cập ở trên trong Phần 3.1. Hình 2 cho thấy một trường hợp tuân theo Dịch thuật cho hướng tiếng Anh-Đức (en-de) và ngược lại (de-en).

--- TRANG 5 ---
Hình 3: Kết quả đánh giá trên các điểm chuẩn đề xuất. Đường chấm chấm đại diện cho hiệu suất của Alpaca gốc (Taori et al., 2023) trên các nhiệm vụ tiếng Anh.

4 Thí nghiệm

Để quan sát khả năng tiếng Anh và không phải tiếng Anh của các Mô hình Ngôn ngữ Lớn (LLMs) và tác động của phương pháp tinh chỉnh Hướng dẫn trong các tình huống đa ngôn ngữ, chúng tôi đề xuất CrossAlpaca. Phương pháp của chúng tôi dựa trên tinh chỉnh hướng dẫn trên dữ liệu cụ thể theo ngôn ngữ được tăng cường với căn chỉnh ngữ nghĩa đa ngôn ngữ. Do đó, chúng tôi thiết lập một số mô hình cơ sở (Phần 4.1), mà chúng tôi tăng cường với phương pháp CrossAlpaca của chúng tôi (Phần 4.2). Cuối cùng, chúng tôi thực hiện một loạt các đánh giá có hệ thống (Phần 4.3.1) để quan sát tác động của can thiệp được đề xuất.

4.1 It-LLMs tinh chỉnh Hướng dẫn Cơ sở

Mẫu số chung giữa các It-LLMs được hiển thị trong Bảng 1 là xương sống LLM, LLaMA-7B (Touvron et al., 2023). Bắt đầu từ dữ liệu tuân theo Hướng dẫn từ Alpaca gốc (Taori et al., 2023) và các phiên bản không phải tiếng Anh mã nguồn mở của nó³, chúng tôi tái tạo x-Alpaca cho các ngôn ngữ cụ thể x: Trung Quốc (zh), Ý (it), Ả Rập (ar), Tây Ban Nha (es), Đức (de) và phiên bản tiếng Anh gốc (en).

4.2 It-LLMs tinh chỉnh Hướng dẫn Đa ngôn ngữ

CrossAlpacas được tinh chỉnh hướng dẫn trên các minh họa tuân theo Hướng dẫn và tuân theo Dịch thuật (minh họa CrossAlpacas). Các minh họa đầu tiên xuất phát từ các tài nguyên được giới thiệu trong Phần 4.1. Minh họa thứ hai đến từ news_commentary (Tiedemann, 2012).

Phương pháp của chúng tôi tạo ra một loạt các phiên bản tinh chỉnh hướng dẫn của dữ liệu được hiển thị trong Hình 1. Chúng tôi đã đặt tên các phiên bản x-CrossAlpaca trong đó x biểu thị: Trung Quốc (zh), Ả Rập (ar), Ý (it), Tây Ban Nha (es), và Đức (de).

4.3 Thiết lập Thí nghiệm

Để đánh giá hiệu suất của CrossAlpaca, chúng tôi đã xác định một số điểm chuẩn (Phần 4.3.1) mà chúng tôi áp dụng các đường ống điều chỉnh có hệ thống (Phần 4.3.2) và đánh giá (Phần 4.3.3).

4.3.1 Điểm chuẩn

Để đánh giá hiệu suất của It-LLMs và tác động của phương pháp căn chỉnh ngữ nghĩa dựa trên dịch thuật, chúng tôi đã sử dụng hai điểm chuẩn đa ngôn ngữ (XQUAD (Artetxe et al., 2019), MLQA (Lewis et al., 2020)) và hai điểm chuẩn đa nhiệm vụ (MMLU (Hendrycks et al., 2021) và BBH (Suzgun et al., 2022)).

XQUAD và MLQA tập trung vào việc hiểu câu hỏi và câu trả lời thông qua dịch thuật sang các ngôn ngữ khác nhau. MMLU và BBH là các điểm chuẩn đa nhiệm vụ bao gồm các nhiệm vụ con liên quan đến biểu thức Boolean và QA về các chủ đề cấp cơ bản (ví dụ: hóa học, vật lý). Tuy nhiên, chúng tôi quyết định giới thiệu chúng để quan sát liệu phương pháp của chúng tôi có làm giảm hiệu suất trong các nhiệm vụ này hay không. Hai bộ dữ liệu đầu tiên được chọn được xây dựng phù hợp cho thử nghiệm đa ngôn ngữ, trong khi hai bộ dữ liệu thứ hai chỉ có sẵn bằng tiếng Anh. Vì vậy chúng tôi thực hiện một bước dịch thuật sơ bộ như được nêu dưới đây.

Trả lời Câu hỏi Đa ngôn ngữ (MLQA) (Lewis et al., 2020) đánh giá hiệu suất trả lời câu hỏi đa ngôn ngữ. Điểm chuẩn bao gồm hơn 5K thể hiện QA trích xuất theo định dạng SQuAD (Rajpurkar et al., 2016) trong một số ngôn ngữ. MLQA có tính song song cao, với các thể hiện QA được căn chỉnh trên bốn ngôn ngữ trung bình. Mặc dù bao gồm các ngôn ngữ khác nhau, một số ngôn ngữ không được đại diện, chẳng hạn như tiếng Ý. Để tiến hành các thí nghiệm đồng nhất, chúng tôi đã dịch các ví dụ như cũng được thực hiện trong MMLU và BBH sắp tới.

Bộ dữ liệu Trả lời Câu hỏi Đa ngôn ngữ (XQUAD) (Artetxe et al., 2019) bao gồm một tập con của 240 đoạn văn và 1190 cặp câu hỏi-câu trả lời từ tập phát triển của SQuAD v1.1 (Rajpurkar et al., 2016) với các bản dịch thủ công của chúng sang một số ngôn ngữ. Do đó, bộ dữ liệu hoàn toàn song song trên 11 ngôn ngữ.

Hiểu biết Ngôn ngữ Đa nhiệm vụ Quy mô lớn (MMLU) (Hendrycks et al., 2021) đo lường kiến thức về thế giới và các vấn đề giải quyết vấn đề trong nhiều chủ đề với 57 chủ đề trên STEM, nhân văn, khoa học xã hội và các lĩnh vực khác. Điểm chuẩn là bản địa bằng tiếng Anh; tuy nhiên, chúng tôi đã dịch nó sang năm ngôn ngữ bổ sung⁴.

BIG-Bench Hard (BBH) (Suzgun et al., 2022) là một tập con của các nhiệm vụ thách thức liên quan đến điều hướng, suy luận logic và phát hiện sai lầm. Ở đây một lần nữa, điểm chuẩn là tiếng Anh bản địa, và chúng tôi đã dịch nó sang năm ngôn ngữ⁴.

4.3.2 Thiết lập Mô hình

Để căn chỉnh kết quả với các mô hình tiên tiến, chúng tôi đã sử dụng mã alpaca_LoRA (Hu et al., 2021b)³, áp dụng cùng các siêu tham số. Chúng tôi thực hiện tinh chỉnh với một epoch duy nhất và batch-size là 128 ví dụ, chạy các thí nghiệm của chúng tôi trên một máy trạm được trang bị hai Nvidia RTX A6000 với 48 GB VRAM.

4.3.3 Đánh giá

Như một thước đo đánh giá, chúng tôi sử dụng độ chính xác. Do đó, chúng tôi ước tính độ chính xác bằng cách đo các giá trị khớp chính xác trong cài đặt zero-shot. Đối với mỗi mô hình, các phần của điểm chuẩn liên quan đến ngôn ngữ cụ thể được sử dụng (ví dụ: đối với zh-Alpaca và zh-CrossAlpaca, dữ liệu từ MLQA, XQUAD, MMLU và BBH bằng tiếng Trung được sử dụng).

5 Kết quả

Cải thiện khả năng không phải tiếng Anh trong các Mô hình Ngôn ngữ Lớn được tinh chỉnh Hướng dẫn (It-LLMs) vẫn là thách thức. Tuy nhiên, x-CrossAlpacas đã tiết lộ kết quả cải thiện trong các điểm chuẩn Trả lời Câu hỏi (QA) đa ngôn ngữ và duy trì các kỹ năng logic-toán học. Từ kết quả của Hình 3 (được chi tiết thêm trong Bảng 3), có thể quan sát các điểm yếu nổi lên từ việc tinh chỉnh các phiên bản được dịch của Alpaca (Phần 5.1), sự cải thiện thu được từ giai đoạn căn chỉnh là đáng khuyến khích (Phần 5.2) nhưng không đủ để vượt trội hơn phiên bản tiếng Anh. Do đó, chúng tôi đã điều tra tác động của các minh họa đối với hiệu suất hạ nguồn (Phần 5.3).

Phân tích chi tiết làm nổi bật tầm quan trọng của dữ liệu căn chỉnh đa ngôn ngữ và các vấn đề quan trọng với dữ liệu không phải tiếng Anh. Điều này mở đường cho các giả thuyết mới liên quan đến sự mất cân bằng của các ngôn ngữ tiền huấn luyện và khả năng học thông qua tinh chỉnh hướng dẫn.

5.1 Dịch Alpaca không phải là cách đúng

Tinh chỉnh hướng dẫn trên LLaMA, chủ yếu được tiền huấn luyện bằng tiếng Anh, ảnh hưởng đến x-Alpaca. Hình 3 và về mặt số liệu, Bảng 3 cho thấy trong cả MLQA và XQUAD, có khoảng cách 55 và 53 điểm trung bình giữa en-Alpaca và x-Alpacas. Hiện tượng này được giảm thiểu đối với MMLU và BBH, nơi chúng tôi quan sát khoảng cách trung bình 18 và 14 điểm. Hướng dẫn LLM trên các minh họa phong cách Alpaca được dịch sang các ngôn ngữ khác nhau không phải lúc nào cũng là một chiến lược tốt. Tuy nhiên, một số x-Alpacas đã hoạt động tốt hơn, chẳng hạn như zh-Alpaca và de-Alpaca. Chúng tôi giả thuyết rằng hiện tượng này liên quan đến quy mô của dữ liệu tiền huấn luyện trong các ngôn ngữ tương ứng và do đó, khả năng của LLaMA. Trong các phát triển tương lai, chúng tôi dự định mở rộng nghiên cứu trên các LLMs khác ngoài LLaMA để quan sát liệu hiện tượng này có tương tự, nhẹ hơn hay đáng kể hơn hay không.

[THIS IS TABLE: Bảng 2 hiển thị trung bình kết quả trên các điểm chuẩn đề xuất với các cột cho en-Alpaca, avg-Alpaca, avg-CrossAlpaca và δ]

5.2 CrossAlpaca: Một giải pháp đa ngôn ngữ

Căn chỉnh ngữ nghĩa thông qua các minh họa tuân theo Dịch thuật trong quá trình tinh chỉnh có thể có tác động có giá trị đến khả năng đa ngôn ngữ của It-LLMs. X-CrossAlpacas vượt trội hơn x-Alpacas 30 điểm trung bình trên MLQA, 34 điểm trung bình trên XQUAD, 8 trên MMLU, và 4 trên BBH (xem Bảng 2 và chi tiết hơn trong Bảng 3). Chúng cũng đưa hiệu suất của họ gần hơn với sota thu được từ Alpaca gốc 25 điểm trên MLQA và 22 điểm trung bình trên XQUAD. Trong MMLU và BBH, khoảng cách trở nên rất gần, với trung bình 10 và 2 điểm (xem Bảng 2 hoặc dòng 'en-Alpaca vs avg-CrossAlpaca' trong Bảng 3).

Làm phong phú với các minh họa tuân theo Dịch thuật có ảnh hưởng nổi bật đến khả năng đa ngôn ngữ của It-LLMs. Tuy nhiên, ngay cả trong trường hợp này, các mô hình Trung Quốc và Đức (zh- và de-CrossAlpaca) vượt trội hơn tiếng Ả Rập nhiều điểm và, trong một số trường hợp cụ thể, tiếng Tây Ban Nha và Ý cũng vậy. Hiện tượng này, chúng tôi giả thuyết, liên quan đến sự đa dạng trong đại diện kho ngữ liệu trong dữ liệu tiền huấn luyện, như được hiển thị trong (Yang et al., 2023). Do đó, các phương pháp đa ngôn ngữ không có tác động sâu sắc như trong các ngôn ngữ ít có mặt trong các giai đoạn tiền huấn luyện của mô hình ngôn ngữ.

5.3 Nghiên cứu Ablation

CrossAlpacas của chúng tôi, được phân biệt bởi việc xây dựng các cặp minh họa (Phần 4.2), đạt được những cải thiện hiệu suất đáng kể và đóng góp vào việc thu hẹp khoảng cách giữa Alpaca gốc (en-Alpaca) và một loạt x-Alpacas trong các ngôn ngữ khác nhau. Để cho thấy tác động của việc làm phong phú với các minh họa đa ngôn ngữ, chúng tôi đề xuất hai phân tích khác nhau. Trong phân tích đầu tiên, chúng tôi giảm dần dữ liệu huấn luyện, đặc biệt ở phía minh họa tuân theo Dịch thuật (Phần 5.4). Trong phân tích thứ hai, vẫn làm việc trên phần tuân theo Dịch thuật (được định nghĩa bởi một nửa minh họa en-x và một nửa x-en), chúng tôi phân tích tác động của các minh họa bằng cách chia các thí nghiệm thành en-x và x-en (Phần 5.4.1).

5.4 Các minh họa tuân theo Dịch thuật tăng cường khả năng không phải tiếng Anh.

Hình 4 (để có phân tích rộng rãi hơn, vui lòng tham khảo Hình 6 trong Phụ lục) cho thấy hiệu suất không phải tiếng Anh của x-CrossAlpaca trên các điểm chuẩn dưới các quy mô khác nhau của minh họa tuân theo Dịch thuật⁵. X-CrossAlpacas đạt độ chính xác cao hơn khi sử dụng nhiều minh họa hơn, tiết lộ lợi ích của căn chỉnh đa ngôn ngữ để cải thiện hiệu suất không phải tiếng Anh.

Tuy nhiên, các minh họa tuân theo Dịch thuật được xây dựng theo hai hướng: x-en và en-x (ngoại ngữ-tiếng Anh và tiếng Anh-ngoại ngữ). Mặc dù được phân phối đồng đều, chúng tôi vẫn xác định liệu có sự bất đối xứng giữa hai loại đóng góp hay không.

Cuối cùng, kết quả này ít rõ ràng hơn đối với các điểm chuẩn đa nhiệm vụ (xem Hình 6 MMLU và BBH). Điều này có thể liên quan đến thực tế là trong các điểm chuẩn, có các nhiệm vụ con logic-toán học ít phụ thuộc vào ngôn ngữ (cú pháp đơn giản hơn tương đối, từ vựng nhỏ hơn), và do đó, phương pháp đa ngôn ngữ của chúng tôi không ảnh hưởng đến kết quả cho MLQA và XQUAD nhiều như vậy. Hơn nữa, có thể quan sát một xu hướng trong các nhóm ngôn ngữ, đặc biệt là Trung Quốc-Đức, Ý-Tây Ban Nha, và Ả Rập. Xu hướng này, thường xuyên xuất hiện trong kết quả các thí nghiệm của chúng tôi, sẽ được điều tra thêm trong công việc tương lai.

Hình 5: Đánh giá các điểm chuẩn đề xuất sử dụng minh họa tuân theo Dịch thuật một chiều. Đối với en-x cho tiếng Anh-ngoại ngữ và x-en cho ngoại ngữ tiếng Anh.

5.4.1 Hướng minh họa quan trọng đối với khả năng không phải tiếng Anh

Hình 5 cho thấy đánh giá được tiến hành theo các hướng khác nhau của các minh họa tuân theo dịch thuật. Đặc biệt, các minh họa với hướng tiếng Anh-ngoại ngữ (en-x) tác động tốt hơn đến các mô hình hạ nguồn. Ngược lại, các minh họa ngoại ngữ-tiếng Anh (x-en) hoạt động tốt hơn so với cơ sở nhưng hoạt động kém hơn các minh họa ở hướng ngược lại.

Tuy nhiên, như được hiển thị trong Hình 5 (và Hình 7 đầy đủ), x-CrossAlpacas tiếp tục vượt trội. Tuy nhiên, xu hướng của các minh họa tuân theo dịch thuật với một hướng là thú vị. Một lần nữa, như trường hợp trong nghiên cứu ablation trước đó, các điểm chuẩn đa nhiệm vụ (xem MMLU và BBH trong Hình 7) dường như không nhận được ảnh hưởng đáng kể, điều này củng cố giả thuyết rằng các mô hình bị ảnh hưởng rất nhiều bởi khả năng đa ngôn ngữ trong các nhiệm vụ có sự hiện diện mạnh mẽ của ngôn ngữ tự nhiên.

6 Công việc Tương lai

Khả năng đa ngôn ngữ của các Mô hình Ngôn ngữ Lớn được tinh chỉnh Hướng dẫn (It-LLMs) dường như được hỗ trợ bởi LLMs, chẳng hạn như trong trường hợp của Alpaca, xương sống LLaMA. Tuy nhiên, có vẻ như các minh họa tác động thấp ở cấp độ dữ liệu có thể làm phong phú những khả năng này. Chúng tôi đạt được kết quả có giá trị từ các thí nghiệm của chúng tôi bằng cách đề xuất các minh họa chiến lược, tức là các minh họa tuân theo Dịch thuật. Những kết quả này được đề xuất bằng cách thực hiện tinh chỉnh trên LLaMA-7B như được thực hiện bởi Taori et al. (2023).

Trong công việc tương lai, chúng tôi muốn tiếp tục điều tra bằng cách tăng số lượng tham số trong LLaMA và bao gồm các mô hình xương sống bổ sung. Ngoài ra, có thể thú vị khi đánh giá tác động đối với các ngôn ngữ tài nguyên thấp. Do đó, chúng tôi muốn đến phần bên dưới của hiệu suất thu được trong một số thí nghiệm (xem Phần 5.4) bằng cách mở rộng các phương pháp nhận thức luận (Ranaldi et al., 2023) cho It-LLMs.

Song song, các kế hoạch bao gồm phân tích khả năng dịch thuật của It-LLMs chung và những mô hình được tăng cường với các nhiệm vụ dịch thuật, bao gồm một số nhiệm vụ dịch thuật chuyên biệt trong số các điểm chuẩn đánh giá của chúng tôi. Cuối cùng, chúng tôi muốn điều tra khả năng học của Alpaca gốc khi dữ liệu dịch thuật thay đổi, đề xuất các thí nghiệm thăm dò khác nhau trên dữ liệu tiếng Anh (gốc) được tăng cường với các bản dịch.

7 Kết luận

Trong bài báo này, chúng tôi đã đề xuất CrossAlpaca, một phương pháp tăng cường tinh chỉnh hướng dẫn của LLMs trên dữ liệu không phải tiếng Anh. Cụ thể, chúng tôi đã kết hợp các minh họa tuân theo Hướng dẫn (phong cách Alpaca) với các minh họa tuân theo Dịch thuật. Phương pháp của chúng tôi tìm cách hướng dẫn LLM đến căn chỉnh ngữ nghĩa giữa tiếng Anh và không phải tiếng Anh vượt trội hơn các mô hình được hướng dẫn trên văn bản không phải tiếng Anh. Đặc biệt, nhờ vào các minh họa CrossAlpaca của chúng tôi, các mô hình được hướng dẫn đã đạt được những cải thiện hiệu suất đáng kể trên bốn điểm chuẩn Trả lời Câu hỏi XQUAD, MLQA, MMLU và BBH. Ngoài ra, chúng tôi quan sát rằng căn chỉnh ngữ nghĩa tăng cường với việc tăng dữ liệu tuân theo Dịch thuật; điều này chứng minh khả năng thực tế của It-LLMs để học từ các hướng dẫn. Phương pháp và kết quả của chúng tôi đóng góp vào nghiên cứu cải thiện về tiềm năng sản xuất LLMs mạnh mẽ hơn cho các ngôn ngữ không phải tiếng Anh.

--- TRANG 9 ---
Tài liệu tham khảo

Julien Abadji, Pedro Ortiz Suarez, Laurent Romary, và Benoît Sagot. 2022. Hướng tới một kho ngữ liệu được thu thập đa ngôn ngữ hướng tài liệu sạch hơn. Trong Kỷ yếu Hội nghị Tài nguyên và Đánh giá Ngôn ngữ lần thứ Mười ba, trang 4344–4355, Marseille, Pháp. Hiệp hội Tài nguyên Ngôn ngữ Châu Âu.

Mikel Artetxe, Sebastian Ruder, và Dani Yogatama. 2019. Về khả năng chuyển giao đa ngôn ngữ của các biểu diễn đơn ngôn ngữ. Trong Cuộc họp Thường niên của Hiệp hội Ngôn ngữ học Tính toán.

Mikko Aulamo và Jörg Tiedemann. 2019. Kho lưu trữ tài nguyên OPUS: Một gói mở để tạo kho ngữ liệu song song và các dịch vụ dịch máy. Trong Kỷ yếu Hội nghị Nordic lần thứ 22 về Ngôn ngữ học Tính toán, trang 389–394, Turku, Phần Lan. Báo chí Điện tử Đại học Linköping.

Yejin Bang, Samuel Cahyawijaya, Nayeon Lee, Wenliang Dai, Dan Su, Bryan Wilie, Holy Lovenia, Ziwei Ji, Tiezheng Yu, Willy Chung, Quyet V. Do, Yan Xu, và Pascale Fung. 2023. Một đánh giá đa nhiệm vụ, đa ngôn ngữ, đa phương thức của chatgpt về lý luận, ảo giác và tương tác.

Terra Blevins và Luke Zettlemoyer. 2022. Ô nhiễm ngôn ngữ giúp giải thích khả năng đa ngôn ngữ của các mô hình được tiền huấn luyện tiếng Anh. Trong Hội nghị về Các Phương pháp Thực nghiệm trong Xử lý Ngôn ngữ Tự nhiên.

Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, và Dario Amodei. 2020. Các mô hình ngôn ngữ là những người học few-shot.

Wei-Lin Chen, Cheng-Kuang Wu, và Hsin-Hsi Chen. 2023. Alpaca Trung Quốc truyền thống: Mô hình và bộ dữ liệu. https://github.com/ntunlplab/traditional-chinese-alpaca.

Yiming Cui, Ziqing Yang, và Xin Yao. 2023. Mã hóa văn bản hiệu quả và hiệu lực cho llama và alpaca tiếng Trung.

Jesse Dodge, Maarten Sap, Ana Marasović, William Agnew, Gabriel Ilharco, Dirk Groeneveld, Margaret Mitchell, và Matt Gardner. 2021. Tài liệu hóa các kho ngữ liệu webtext lớn: Một nghiên cứu trường hợp về kho ngữ liệu được thu thập sạch khổng lồ.

Leo Gao, Stella Biderman, Sid Black, Laurence Golding, Travis Hoppe, Charles Foster, Jason Phang, Horace He, Anish Thite, Noa Nabeshima, Shawn Presser, và Connor Leahy. 2020. The pile: Một bộ dữ liệu 800gb văn bản đa dạng cho mô hình hóa ngôn ngữ.

Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, và Jacob Steinhardt. 2021. Đo lường hiểu biết ngôn ngữ đa nhiệm vụ quy mô lớn.

Edward J. Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, và Weizhu Chen. 2021a. lora: Thích ứng thứ hạng thấp của các mô hình ngôn ngữ lớn.

Edward J. Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, và Weizhu Chen. 2021b. lora: Thích ứng thứ hạng thấp của các mô hình ngôn ngữ lớn.

Haoyang Huang, Tianyi Tang, Dongdong Zhang, Wayne Xin Zhao, Ting Song, Yan Xia, và Furu Wei. 2023. Không phải tất cả ngôn ngữ đều được tạo ra bình đẳng trong llms: Cải thiện khả năng đa ngôn ngữ bằng nhắc nhở tư duy đa ngôn ngữ.

Ayyoob Imani, Peiqin Lin, Amir Hossein Kargaran, Silvia Severini, Masoud Jalili Sabet, Nora Kassner, Chunlan Ma, Helmut Schmid, André F. T. Martins, François Yvon, và Hinrich Schütze. 2023. Glot500: Mở rộng kho ngữ liệu đa ngôn ngữ và mô hình ngôn ngữ lên 500 ngôn ngữ.

Kohaku-Blueleaf. 2023. Guanaco-lora: LoRA cho việc huấn luyện LM tuân theo Hướng dẫn Đa ngôn ngữ dựa trên LLaMA. https://huggingface.co/plncmm/guanaco-lora-7b.

Shibamouli Lahiri. 2014. Độ phức tạp của Mạng Colocation Từ: Một Phân tích Cấu trúc Sơ bộ. Trong Kỷ yếu Hội thảo Nghiên cứu Sinh viên tại Hội nghị lần thứ 14 của Chương Châu Âu của Hiệp hội Ngôn ngữ học Tính toán, trang 96–105, Gothenburg, Thụy Điển. Hiệp hội Ngôn ngữ học Tính toán.

Hang Le, Juan Miguel Pino, Changhan Wang, Jiatao Gu, Didier Schwab, và Laurent Besacier. 2021. Điều chỉnh bộ điều hợp nhẹ cho dịch lời nói đa ngôn ngữ. Trong Kỷ yếu Cuộc họp Thường niên lần thứ 59 của Hiệp hội Ngôn ngữ học Tính toán (ACL), trang 817–824. Hiệp hội Ngôn ngữ học Tính toán.

Patrick Lewis, Barlas Oguz, Ruty Rinott, Sebastian Riedel, và Holger Schwenk. 2020. MLQA: Đánh giá trả lời câu hỏi trích xuất đa ngôn ngữ. Trong Kỷ yếu Cuộc họp Thường niên lần thứ 58 của Hiệp hội Ngôn ngữ học Tính toán, trang 7315–7330, Trực tuyến. Hiệp hội Ngôn ngữ học Tính toán.

Jiahuan Li, Hao Zhou, Shujian Huang, Shanbo Cheng, và Jiajun Chen. 2023. Khai thác khả năng dịch thuật của các mô hình ngôn ngữ lớn qua tinh chỉnh đa ngôn ngữ với hướng dẫn dịch thuật.

Xiang Lisa Li và Percy Liang. 2021. Prefix-tuning: Tối ưu hóa các nhắc nhở liên tục cho tạo sinh. Trong Kỷ yếu Cuộc họp Thường niên lần thứ 59 của Hiệp hội Ngôn ngữ học Tính toán và Hội nghị Quốc tế lần thứ 11 về Xử lý Ngôn ngữ Tự nhiên (Tập 1: Bài báo Dài), trang 4582–4597, Trực tuyến. Hiệp hội Ngôn ngữ học Tính toán.

Zehui Lin, Xiao Pan, Mingxuan Wang, Xipeng Qiu, Jiangtao Feng, Hao Zhou, và Lei Li. 2021. Tiền huấn luyện dịch máy thần kinh đa ngôn ngữ bằng cách tận dụng thông tin căn chỉnh.

Xiao Liu, Kaixuan Ji, Yicheng Fu, Weng Tam, Zhengxiao Du, Zhilin Yang, và Jie Tang. 2022. P-tuning: Điều chỉnh nhắc nhở có thể so sánh với tinh chỉnh trên các quy mô và nhiệm vụ. Trong Kỷ yếu Cuộc họp Thường niên lần thứ 60 của Hiệp hội Ngôn ngữ học Tính toán (Tập 2: Bài báo Ngắn), trang 61–68, Dublin, Ireland. Hiệp hội Ngôn ngữ học Tính toán.

Yasmin Moslem, Rejwanul Haque, John D. Kelleher, và Andy Way. 2023. Dịch máy thích ứng với các mô hình ngôn ngữ lớn.

Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul Christiano, Jan Leike, và Ryan Lowe. 2022. Huấn luyện các mô hình ngôn ngữ tuân theo hướng dẫn với phản hồi của con người.

Guilherme Penedo, Quentin Malartic, Daniel Hesslow, Ruxandra Cojocaru, Alessandro Cappelli, Hamza Alobeidli, Baptiste Pannier, Ebtesam Almazrouei, và Julien Launay. 2023. Bộ dữ liệu refinedweb cho falcon llm: Vượt trội hơn các kho ngữ liệu được tuyển chọn với dữ liệu web, và chỉ dữ liệu web.

Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, và Percy Liang. 2016. Squad: 100,000+ câu hỏi cho hiểu biết máy về văn bản.

Federico Ranaldi, Elena Sofia Ruzzetti, Felicia Logozzo, Michele Mastromattei, Leonardo Ranaldi, và Fabio Massimo Zanzotto. 2023. Khám phá các tính chất ngôn ngữ của các bert đơn ngôn ngữ với phân loại typological giữa các ngôn ngữ.

Andrea Santilli và Emanuele Rodolà. 2023. Camoscio: một llama được tinh chỉnh hướng dẫn tiếng Ý.

Mohammad Shoeybi, Mostofa Ali Patwary, Raul Puri, Patrick LeGresley, Jared Casper, và Bryan Catanzaro. 2019. Megatron-LM: Huấn luyện các mô hình ngôn ngữ nhiều tỷ tham số sử dụng tính song song mô hình. ArXiv, abs/1909.08053.

Mirac Suzgun, Nathan Scales, Nathanael Schärli, Sebastian Gehrmann, Yi Tay, Hyung Won Chung, Aakanksha Chowdhery, Quoc V Le, Ed H Chi, Denny Zhou, và Jason Wei. 2022. Thách thức các nhiệm vụ big-bench và liệu chuỗi tư duy có thể giải quyết chúng hay không. arXiv preprint arXiv:2210.09261.

Marc Tanti, Lonneke van der Plas, Claudia Borg, và Albert Gatt. 2021. Về tính cụ thể ngôn ngữ của bert đa ngôn ngữ và tác động của tinh chỉnh.

Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy Liang, và Tatsunori B. Hashimoto. 2023. Stanford alpaca: Một mô hình llama tuân theo hướng dẫn. https://github.com/tatsu-lab/stanford_alpaca.

Ian Tenney, Dipanjan Das, và Ellie Pavlick. 2019. BERT khám phá lại đường ống NLP cổ điển. Trong Kỷ yếu Cuộc họp Thường niên lần thứ 57 của Hiệp hội Ngôn ngữ học Tính toán, trang 4593–4601, Florence, Italy. Hiệp hội Ngôn ngữ học Tính toán.

Martin Thissen. 2023. Tinh chỉnh alpaca cho bất kỳ ngôn ngữ nào. https://github.com/thisserand/alpaca-lora-finetune-language.

Jörg Tiedemann. 2012. Dữ liệu song song, công cụ và giao diện trong OPUS. Trong Kỷ yếu Hội nghị Quốc tế lần thứ Tám về Tài nguyên và Đánh giá Ngôn ngữ (LREC'12), trang 2214–2218, Istanbul, Thổ Nhĩ Kỳ. Hiệp hội Tài nguyên Ngôn ngữ Châu Âu (ELRA).

Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave, và Guillaume Lample. 2023. Llama: Mô hình ngôn ngữ nền tảng mở và hiệu quả.

Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A. Smith, Daniel Khashabi, và Hannaneh Hajishirzi. 2023. Self-instruct: Căn chỉnh các mô hình ngôn ngữ với các hướng dẫn tự tạo.

Jason Wei, Maarten Bosma, Vincent Y. Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du, Andrew M. Dai, và Quoc V. Le. 2022. Các mô hình ngôn ngữ được tinh chỉnh là những người học zero-shot.

Canwen Xu, Daya Guo, Nan Duan, và Julian McAuley. 2023. Baize: Một mô hình chat mã nguồn mở với điều chỉnh hiệu quả tham số trên dữ liệu tự chat. arXiv preprint arXiv:2304.01196.

Wen Yang, Chong Li, Jiajun Zhang, và Chengqing Zong. 2023. Bigtranslate: Tăng cường các mô hình ngôn ngữ lớn với khả năng dịch thuật đa ngôn ngữ trên 100 ngôn ngữ.

Yasbok. Tinh chỉnh Hướng dẫn Alpaca cho tiếng Ả Rập. https://huggingface.co/Yasbok.

Jiali Zeng, Fandong Meng, Yongjing Yin, và Jie Zhou. 2023. Tim: Dạy các mô hình ngôn ngữ lớn dịch thuật với so sánh.

Shaolei Zhang, Qingkai Fang, Zhuocheng Zhang, Zhengrui Ma, Yan Zhou, Langlin Huang, Mengyu Bu, Shangtong Gui, Yunji Chen, Xilin Chen, và Yang Feng. 2023. Bayling: Bắc cầu căn chỉnh đa ngôn ngữ và tuân theo hướng dẫn thông qua dịch thuật tương tác cho các mô hình ngôn ngữ lớn.

Wenhao Zhu, Hongyi Liu, Qingxiu Dong, Jingjing Xu, Shujian Huang, Lingpeng Kong, Jiajun Chen, và Lei Li. 2023a. Dịch máy đa ngôn ngữ với các mô hình ngôn ngữ lớn: Kết quả thực nghiệm và phân tích.

Wenhao Zhu, Yunzhe Lv, Qingxiu Dong, Fei Yuan, Jingjing Xu, Shujian Huang, Lingpeng Kong, Jiajun Chen, và Lei Li. 2023b. Ngoại suy các mô hình ngôn ngữ lớn sang không phải tiếng Anh bằng cách căn chỉnh các ngôn ngữ.

Yukun Zhu, Ryan Kiros, Rich Zemel, Ruslan Salakhutdinov, Raquel Urtasun, Antonio Torralba, và Sanja Fidler. 2015. Căn chỉnh sách và phim: Hướng tới lời giải thích trực quan giống câu chuyện bằng cách xem phim và đọc sách. Trong Hội nghị Quốc tế IEEE về Thị giác Máy tính (ICCV).

--- TRANG 12 ---
A Phụ lục

[THIS IS TABLE: Bảng 3 hiển thị kết quả đánh giá trên các điểm chuẩn đề xuất với các mô hình Alpaca và CrossAlpaca khác nhau, bao gồm điểm số cho MLQA, XQUAD, MMLU và BBH]

B Phụ lục

[THIS IS TABLE: Bảng 4 liệt kê các tài nguyên tiên tiến có sẵn theo ngôn ngữ, hiển thị tình trạng khả dụng của Alpaca, MLQA, XQUAD, MMLU, BBH và News_commentary cho các ngôn ngữ khác nhau]

--- TRANG 13 ---
C Phụ lục

Hình 6: Đánh giá tất cả các điểm chuẩn đề xuất của các minh họa được sử dụng để tinh chỉnh hướng dẫn CrossAlpacas của chúng tôi.

D Phụ lục

Hình 7: Đánh giá tất cả các điểm chuẩn đề xuất sử dụng minh họa tuân theo Dịch thuật một chiều. Đối với en-x cho tiếng Anh-ngoại ngữ và x-en cho ngoại ngữ-tiếng Anh. Với dấu x màu đỏ, chúng tôi chỉ ra kết quả của các tiêu chuẩn x-Alpaca, và với hình thoi màu xanh lá cây, kết quả của x-CrossAlpaca của chúng tôi.

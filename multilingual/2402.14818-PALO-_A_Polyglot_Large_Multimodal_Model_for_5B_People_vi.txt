PALO: Một Mô hình Đa phương thức Lớn Đa ngôn ngữ cho 5 tỷ người

Muhammad Maaz1*, Hanoona Rasheed1*, Abdelrahman Shaker1, Salman Khan1,2
Hisham Cholakal1,Rao M. Anwer1,3,Tim Baldwin1,4,Michael Felsberg5,Fahad S. Khan1,5
1Đại học AI Mohamed bin Zayed,2Đại học Quốc gia Australia,3Đại học Aalto
4Đại học Melbourne,5Đại học Linköping

Tóm tắt
Trong nỗ lực hướng tới các Mô hình Thị giác-Ngôn ngữ (VLM) toàn diện hơn, nghiên cứu này giới thiệu một Mô hình Đa phương thức Đa ngôn ngữ Lớn có tên PALO. PALO cung cấp khả năng lý luận thị giác trong 10 ngôn ngữ chính, bao gồm tiếng Anh, tiếng Trung, tiếng Hindi, tiếng Tây Ban Nha, tiếng Pháp, tiếng Ả Rập, tiếng Bengal, tiếng Nga, tiếng Urdu và tiếng Nhật, phục vụ tổng cộng khoảng 5 tỷ người (65% dân số thế giới). Phương pháp của chúng tôi sử dụng một cách tiếp cận dịch thuật bán tự động để điều chỉnh bộ dữ liệu hướng dẫn đa phương thức từ tiếng Anh sang các ngôn ngữ đích bằng cách sử dụng một Mô hình Ngôn ngữ Lớn được tinh chỉnh, từ đó đảm bảo độ chính xác ngôn ngữ cao đồng thời cho phép khả năng mở rộng nhờ nỗ lực thủ công tối thiểu. Việc tích hợp các bộ hướng dẫn đa dạng giúp chúng tôi nâng cao hiệu suất tổng thể trên nhiều ngôn ngữ, đặc biệt là những ngôn ngữ thiếu đại diện như tiếng Hindi, tiếng Ả Rập, tiếng Bengal và tiếng Urdu. Các mô hình thu được được huấn luyện trên ba quy mô (1.7B, 7B và 13B tham số) để thể hiện khả năng tổng quát hóa và mở rộng, nơi chúng tôi quan sát được những cải thiện đáng kể so với các mô hình cơ sở mạnh. Chúng tôi cũng đề xuất điểm chuẩn đa phương thức đa ngôn ngữ đầu tiên cho các phương pháp sắp tới để đánh giá khả năng lý luận thị giác-ngôn ngữ của họ trên các ngôn ngữ. Mã nguồn: https://github.com/mbzuai-oryx/PALO.

1 Giới thiệu
Được thúc đẩy bởi những tiến bộ trong AI tạo sinh, các Mô hình Đa phương thức Lớn (LMM) (Liu et al., 2023b; Zhu et al., 2023; Dai et al., 2023) đã nổi lên như một tiến bộ then chốt trong lĩnh vực này, nối liền một cách liền mạch khoảng cách giữa các tác vụ thị giác và ngôn ngữ. Trong khi những nỗ lực ban đầu như LLaVA (Liu et al., 2023b) và miniGPT4 (Zhu et al., 2023) đã thể hiện hiệu suất thú vị trong việc tổng hợp các phản hồi văn bản hiệu quả dựa trên đầu vào thị giác, chúng chủ yếu tập trung vào tiếng Anh, để lại một khoảng trống đáng kể trong hiểu biết đa phương thức cho các ngôn ngữ không phải tiếng Anh. Kết quả là, các LMM hiện có thường bỏ qua sự đa dạng ngôn ngữ của dân số toàn cầu, đặc biệt là các ngôn ngữ được nói bởi các nhóm lớn, như tiếng Trung, tiếng Hindi, tiếng Tây Ban Nha, tiếng Pháp, tiếng Ả Rập, tiếng Bengal, tiếng Nga, tiếng Urdu và tiếng Nhật, mà tổng cộng chiếm hàng tỷ người bản ngữ. Công trình của chúng tôi giải quyết sự bất cân xứng này bằng cách phát triển LMM đa ngôn ngữ mã nguồn mở đầy đủ đầu tiên có tên PALO, bao gồm mười ngôn ngữ chính phủ sóng 65% dân số toàn cầu, với sự tập trung đặc biệt vào các ngôn ngữ thiếu đại diện trong các mô hình đa phương thức hiện tại.

Thách thức nằm ở sự khan hiếm dữ liệu đa phương thức đa ngôn ngữ chất lượng cao so với tiếng Anh. Giải quyết thách thức về dữ liệu chất lượng cao hạn chế, đặc biệt đối với các ngôn ngữ thiếu đại diện như tiếng Hindi, tiếng Ả Rập, tiếng Bengal và tiếng Urdu, phương pháp của chúng tôi liên quan đến việc phân tích cẩn thận và tinh chỉnh tiếp theo các bản dịch được tạo ra bởi một Mô hình Ngôn ngữ Lớn (LLM) tiên tiến (Brown et al., 2020) cho từng ngôn ngữ đích. Bằng cách xác định và sửa chữa những sai sót trong dịch thuật thông qua can thiệp của con người, chúng tôi tạo ra một bộ dữ liệu đa ngôn ngữ chất lượng cao. Bộ dữ liệu được tuyển chọn này sau đó phục vụ như nền tảng để tinh chỉnh các chú thích ngôn ngữ đích, đảm bảo một đại diện chính xác và tinh tế hơn của ngôn ngữ đích trong huấn luyện.

Tận dụng bộ dữ liệu hướng dẫn thị giác-ngôn ngữ đa ngôn ngữ chất lượng cao của chúng tôi và những tiến bộ gần đây trong mô hình hóa đa phương thức lớn, chúng tôi phát triển PALO như một mô hình thống nhất có thể đồng thời trả lời câu hỏi trong mười ngôn ngữ khác nhau. Quy trình huấn luyện của chúng tôi mang lại những cải thiện đáng kể trong các ngôn ngữ ít tài nguyên (thiếu đại diện trong các bộ dữ liệu huấn luyện LLM) trong khi duy trì (hoặc cải thiện thêm) hiệu suất trên các ngôn ngữ nhiều tài nguyên.

Những đóng góp của công trình này như sau:
• Chúng tôi phát triển PALO: Mô hình Đa phương thức Lớn (LMM) đa ngôn ngữ đầu tiên bao gồm mười ngôn ngữ chính, tạo điều kiện cho lý luận thị giác-ngôn ngữ thông qua một mô hình chung có khả năng tạo ra phản hồi trong bất kỳ ngôn ngữ nào trong số mười ngôn ngữ.

• Chúng tôi tập hợp một bộ dữ liệu điều chỉnh hướng dẫn đa ngôn ngữ (10 ngôn ngữ) rộng lớn, thông qua phân tích quan trọng và tinh chỉnh tiếp theo các bản dịch ngôn ngữ đích của một Mô hình Ngôn ngữ Lớn tiên tiến. Bộ dữ liệu này là then chốt trong việc cải thiện khả năng thành thạo trong xử lý và tạo ra nội dung chính xác về mặt ngôn ngữ trên nhiều ngôn ngữ.

• Chúng tôi nâng cao hiệu suất đa ngôn ngữ của các LMM tiên tiến (Liu et al., 2023b; Chu et al., 2023) trên ba quy mô riêng biệt tức là 1.7B, 7B và 13B tham số để chứng minh khả năng mở rộng của quy trình huấn luyện của chúng tôi. Các LMM đa ngôn ngữ kết quả thể hiện những cải thiện hiệu suất trên các tác vụ ngôn ngữ đa dạng với những cải thiện đáng kể trong hiểu biết và tạo ra nội dung cho các ngôn ngữ ít tài nguyên, ví dụ như tiếng Hindi, tiếng Ả Rập, tiếng Bengal và tiếng Urdu, mà không làm giảm hiệu suất cao của nó trên các ngôn ngữ nhiều tài nguyên như tiếng Anh, tiếng Trung, tiếng Pháp và tiếng Tây Ban Nha.

2 Công trình liên quan
Việc giới thiệu các Mô hình Ngôn ngữ Lớn (LLM) đã tiến bộ đáng kể trong lĩnh vực xử lý ngôn ngữ tự nhiên. Tuy nhiên, việc phát triển các LLM đa ngôn ngữ đã đối mặt với những thách thức đáng kể, chủ yếu do phân phối dữ liệu ngôn ngữ lệch (Costa-jussà et al., 2022). Tiếng Anh và các ngôn ngữ châu Âu chiếm ưu thế trong các bộ dữ liệu hiện có, khiến các ngôn ngữ được nói rộng rãi như tiếng Trung Quan Thoại và tiếng Hindi bị thiếu đại diện (Eberhard et al., 2015). Hơn nữa, việc tích hợp nhiều ngôn ngữ vào LLM thường dẫn đến sự suy giảm hiệu suất ngôn ngữ tiếng Anh (Scao et al., 2022), làm nổi bật một thách thức lớn trong việc duy trì hiệu suất đa ngôn ngữ.

Những nỗ lực gần đây đã nhằm giải quyết những thách thức này bằng cách phát triển các LLM đa ngôn ngữ với khả năng nâng cao (Almazrouei et al., 2023; Touvron et al., 2023; Le Scao et al.; Wei et al., 2023). BLOOM (Le Scao et al.), được huấn luyện trên kho ngữ liệu ROOTS (Laurençon et al., 2022) bao gồm các nguồn trong 46 ngôn ngữ, đánh dấu một bước tiến đáng kể trong việc làm cho LLM có thể tiếp cận được trên một loạt các ngôn ngữ rộng lớn, bao gồm cả những ngôn ngữ có ít tài nguyên hơn. PaLM (Chowdhery et al., 2023) thể hiện những ưu điểm của việc mở rộng quy mô, đạt được kết quả cải thiện trong cả các tác vụ đơn ngôn ngữ và đa ngôn ngữ thông qua các kỹ thuật huấn luyện tinh vi và một kiến trúc pathways mới.

Những tiến bộ trong các Mô hình Đa phương thức Lớn (LMM) đã phát triển từ các tương tác cấp độ hình ảnh cơ bản (Liu et al., 2023b; Chu et al., 2023) đến việc cung cấp tính linh hoạt bằng cách tập trung vào phân tích cụ thể theo vùng (Rasheed et al., 2023) và các cuộc trò chuyện không gian-thời gian (Maaz et al., 2023; Lin et al., 2023), làm nổi bật sự tiến bộ đáng kể trong lĩnh vực này. Tuy nhiên, việc khám phá các khả năng đa ngôn ngữ vẫn còn hạn chế. Qwen (Bai et al., 2023) và mPLUG-Owl (Ye et al., 2023) mở rộng các chức năng LMM để xử lý đầu vào thị giác trong cả tiếng Anh và tiếng Trung, thể hiện khả năng thích ứng trong việc xử lý thông tin thị giác song ngữ. Ziya-Visual (Lu et al., 2023) thể hiện việc dịch các bộ dữ liệu hình ảnh-văn bản tiếng Anh sang tiếng Trung, sử dụng học tập trong ngữ cảnh để tạo ra hướng dẫn-phản hồi. Tuy nhiên, những LMM này vẫn giới hạn ở hai ngôn ngữ.

Chúng tôi giới thiệu PALO, LMM mã nguồn mở đầy đủ đầu tiên, cung cấp khả năng lý luận thị giác trên mười ngôn ngữ chính, giải quyết khoảng trống trong các LMM đa ngôn ngữ. Trái ngược với GPT-4 (Achiam et al., 2023) là mã nguồn đóng và chỉ có thể truy cập qua API, của chúng tôi là nỗ lực lớn nhất trong lĩnh vực mã nguồn mở để mở rộng khả năng LMM sang nhiều ngôn ngữ.

3 PALO: Một LMM Đa ngôn ngữ
Hướng tới các Mô hình Thị giác-Ngôn ngữ (VLM) có thể tiếp cận toàn cầu hơn, mô hình PALO (Mô hình Đa phương thức Lớn Đa ngôn ngữ) của chúng tôi được thiết kế để hiểu và tạo ra nội dung trong mười ngôn ngữ chính, phục vụ một khán giả trải dài gần hai phần ba dân số toàn cầu. Kiến trúc của PALO được rút ra từ LLaVA (Trợ lý Ngôn ngữ và Thị giác Lớn) (Liu et al., 2023b,a) cho các mô hình quy mô lớn hơn của chúng tôi (7/13B), và từ MobileVLM cho mô hình hiệu quả di động của chúng tôi (1.7B), đảm bảo rằng PALO vẫn linh hoạt trên các thiết lập tính toán khác nhau.

Kiến trúc tích hợp một cách liền mạch một bộ mã hóa thị giác với một mô hình ngôn ngữ (xem Hình 2). Với một hình ảnh đầu vào và truy vấn văn bản của người dùng, mô hình tạo ra một phản hồi ngôn ngữ tự nhiên chính xác. PALO sử dụng CLIP ViT-L/14 (Radford et al., 2021) làm bộ mã hóa thị giác theo sau bởi một bộ chiếu để biến đổi các token thị giác vào không gian nhúng đầu vào của mô hình ngôn ngữ. Theo LLaVA (Liu et al., 2023b), chúng tôi sử dụng một MLP hai lớp với kích hoạt GELU làm bộ chiếu cho các mô hình 7/13B của chúng tôi. Tuy nhiên, một bộ chiếu giảm mẫu nhẹ (LDP) (Chu et al., 2023) được sử dụng cho mô hình Mobile PALO-1.7B. LDP sử dụng các phép tích chập có thể tách riêng theo chiều sâu để giảm mẫu các token thị giác, làm giảm lớn các token đầu vào vào mô hình ngôn ngữ và do đó giảm đáng kể thời gian huấn luyện và suy luận. Hơn nữa, các phép tích chập trong LDP có ít tham số hơn so với MLP, làm cho mô hình di động của chúng tôi vừa hiệu quả về tham số vừa hiệu quả về tính toán. Bộ chiếu được sử dụng trong các phiên bản PALO khác nhau được thể hiện trong Hình 2.

Các token thị giác được chiếu sau đó được nối với truy vấn văn bản đã được token hóa của người dùng và được truyền vào mô hình ngôn ngữ để tạo ra phản hồi. Vì PALO huấn luyện trên mười ngôn ngữ sử dụng một bộ dữ liệu điều chỉnh hướng dẫn đa phương thức rộng lớn, điều này không chỉ cho phép sử dụng hiệu quả hơn khả năng của tokenizer mà còn mở rộng không gian tìm kiếm, cung cấp một bối cảnh phong phú hơn và các ví dụ thử thách hơn cho việc huấn luyện mô hình ngôn ngữ. Phương pháp này nâng cao đáng kể khả năng của mô hình trong việc hiểu và tạo ra phản hồi trên một tập hợp đa dạng các ngôn ngữ.

Chúng tôi sử dụng Vicuna (Zheng et al., 2023) làm mô hình ngôn ngữ lớn (LLM) trong các mô hình 7/13B của chúng tôi và MobileLLaMA (Chu et al., 2023) làm mô hình ngôn ngữ nhỏ (SLM) trong mô hình Mobile PALO-1.7B. Vicuna tinh chỉnh LLaMA-2 trên các cuộc trò chuyện được chia sẻ bởi người dùng được thu thập từ ShareGPT, trong khi LLaMA-2 được huấn luyện trước trên 2T token được thu thập từ các nguồn công cộng khác nhau (Touvron et al., 2023). Mặt khác, MobileLLaMA thực hiện huấn luyện trước trên 1.3T token từ RedPajama-v1 (Computer, 2023) theo sau bởi tinh chỉnh trên một phiên bản có sẵn công khai của dữ liệu ShareGPT (Huggingface).

3.1 Bộ dữ liệu
Đóng góp chính của công trình chúng tôi nằm ở việc chuẩn bị tỉ mỉ một bộ dữ liệu điều chỉnh hướng dẫn thị giác-ngôn ngữ đa ngôn ngữ toàn diện. Chúng tôi bắt đầu bằng việc chọn một mô hình LMM tiên tiến (Liu et al., 2023b) cho trọng tâm của chúng tôi. Để điều chỉnh bộ dữ liệu điều chỉnh hướng dẫn hiệu quả hơn cho nhiều ngôn ngữ theo cách có thể mở rộng, chúng tôi tận dụng một mô hình LLM (Brown et al., 2020) để phát triển một quy trình dịch thuật bán tự động. Phương pháp này liên quan đến việc dịch bộ dữ liệu tiếng Anh sang các ngôn ngữ đích, từ đó tạo ra một bộ dữ liệu đa ngôn ngữ mạnh mẽ, mở rộng đáng kể phạm vi ngôn ngữ và khả năng ứng dụng của mô hình.

Quá trình Dịch thuật và Thách thức: Một phương pháp dịch thuật đơn giản từ tiếng Anh sang các ngôn ngữ đích sử dụng một mô hình LLM (Brown et al., 2020) truyền đạt hiệu quả các ý nghĩa cơ bản nhưng đưa ra một số thách thức ngôn ngữ cụ thể cho từng ngôn ngữ. Các vấn đề như dấu câu, sắc thái ngữ pháp, tính nhất quán dịch thuật và lỗi sử dụng giới tính được quan sát thông qua dịch thuật trực tiếp dựa trên LLM (tham khảo Hình 3). Những thách thức này khác nhau rất nhiều do sự đa dạng ngôn ngữ của các ngôn ngữ liên quan, từ sự phức tạp về tông điệu của tiếng Trung đến sự khác biệt về chữ viết trong tiếng Hindi và những phức tạp cụ thể về giới tính của các ngôn ngữ như tiếng Tây Ban Nha, tiếng Ả Rập và tiếng Nga. Ví dụ, trong trường hợp tiếng Ả Rập, các lỗi dấu câu thường gặp liên quan đến khoảng cách không chính xác xung quanh dấu phồng và dấu chấm. Nunation, quan trọng trong ngữ pháp tiếng Ả Rập, đôi khi bị bỏ qua hoặc áp dụng sai. Ngoài ra, một số từ tiếng Anh vẫn không được dịch trong văn bản đã dịch, và có những trường hợp động từ bị chuyển đổi không chính xác thành danh từ cùng với việc căn chỉnh giới tính không chính xác trong các bản dịch gây ra mối quan tâm đáng kể, xét đến bản chất cụ thể về giới tính của ngữ pháp trong một số ngôn ngữ đích.

Giải quyết các Thách thức: Để cải thiện chất lượng của bộ dữ liệu đã dịch, chúng tôi sử dụng sự kết hợp của các bước xác minh tự động và thủ công. Trong quy trình bán tự động này, một nhóm người bản ngữ cho từng ngôn ngữ cung cấp đánh giá chi tiết và sửa chữa một tập con nhỏ từ các bản dịch ban đầu, giải quyết các vấn đề cụ thể theo ngôn ngữ, độ chính xác giới tính và tính toàn vẹn ngôn ngữ tổng thể. Các script tự động được điều chỉnh cho từng ngôn ngữ để sửa các lỗi dấu câu thường gặp và tối ưu hóa quá trình xác minh.

Tinh chỉnh LLM: Thừa nhận những hạn chế của LLM đối với dịch thuật đa ngôn ngữ, chúng tôi tận dụng các bản dịch đã được xác minh và sửa chữa thủ công (1K cuộc trò chuyện cho mỗi ngôn ngữ) như một bộ dữ liệu chất lượng cao để tinh chỉnh LLM. Việc tinh chỉnh này tập trung không chỉ vào việc cải thiện độ chính xác dịch thuật mà còn vào việc căn chỉnh các đầu ra với các thuộc tính cụ thể của từng ngôn ngữ, như tông điệu và chính tả. LLM đã được nâng cao và tinh chỉnh sau đó được sử dụng để dịch bộ dữ liệu điều chỉnh hướng dẫn VLM rộng lớn (Liu et al., 2023b) bao gồm khoảng 150K hướng dẫn (tức là LLaVA-Instruct-150K từ (Liu et al., 2023b)) từ tiếng Anh sang các ngôn ngữ tương ứng. Chúng tôi sử dụng GPT3.5-Turbo làm mô hình dịch thuật và tinh chỉnh nó bằng nền tảng tinh chỉnh OpenAI.

Tác động của Bộ dữ liệu Đã tinh chỉnh: Quá trình này dẫn đến một bộ dữ liệu đa ngôn ngữ toàn diện và chất lượng cao, quan trọng cho việc tinh chỉnh hiệu quả của PALO. Bộ dữ liệu cải thiện không chỉ giải quyết các khía cạnh cụ thể của từng ngôn ngữ mà còn cải thiện đáng kể khả năng của mô hình trong việc xử lý và tạo ra nội dung liên quan về mặt ngữ cảnh và chính xác về mặt ngữ pháp trong tất cả các ngôn ngữ được bao gồm. Ví dụ, Hình 3 làm nổi bật hai cải tiến chính trong dịch thuật từ tiếng Anh sang tiếng Ả Rập, ví dụ đầu tiên cho thấy độ chính xác từ vựng được nâng cao, và ví dụ thứ hai cho thấy sự hòa hợp ngữ pháp được cải thiện. Việc tích hợp bộ dữ liệu này vào quá trình huấn luyện của LMM là chìa khóa để mở rộng khả năng của nó bao gồm cả tiếng Anh và chín ngôn ngữ khác một cách hiệu quả.

4 Thí nghiệm
4.1 Chi tiết Triển khai
Tương tự như các mô hình cơ sở LLaVA và MobileVLM, chúng tôi huấn luyện trước các mô hình của mình trên một tập con của bộ dữ liệu CC3M có tên CC-595K (Liu et al., 2023b). Trong quá trình huấn luyện trước, chỉ có bộ chiếu được học và các thành phần mô hình còn lại được giữ cố định. Chúng tôi huấn luyện mô hình trong 1 epoch với kích thước batch tổng thể là 256 với kích thước batch 32 trên mỗi GPU trên tám GPU A-100 40GB. Mô hình được tối ưu hóa bằng trình tối ưu Adam và bộ lập lịch LR cosine với tốc độ học 2e-3. Việc huấn luyện trước mất khoảng 1.5 giờ cho 1.7B, 5 giờ cho 7B và gần 9 giờ cho mô hình 13B.

Chúng tôi tinh chỉnh mô hình của mình trên một bộ dữ liệu hướng dẫn đa dạng bao gồm các cuộc trò chuyện từ mười ngôn ngữ. Cụ thể, 665K hướng dẫn từ LLaVA-Instruct-665K (Liu et al., 2023a) được sử dụng cho tiếng Anh, và khoảng 150K cuộc trò chuyện từ LLaVA-Instruct-150K (Liu et al., 2023b) cho tiếng Trung, tiếng Pháp, tiếng Tây Ban Nha, tiếng Nga, tiếng Nhật, tiếng Ả Rập, tiếng Hindi, tiếng Bengal và tiếng Urdu, tổng cộng gần 2.1M hướng dẫn. Trong quá trình tinh chỉnh, chỉ có bộ mã hóa thị giác được giữ cố định và phần còn lại của mô hình được huấn luyện. Bộ chiếu được huấn luyện đầy đủ trong khi mô hình ngôn ngữ được tinh chỉnh LORA (Hu et al., 2022) với α = 128. Chúng tôi huấn luyện mô hình trong 1 epoch với kích thước batch tổng thể là 128 với kích thước batch 16 trên mỗi GPU trên tám GPU A-100. Chúng tôi sử dụng GPU A-100 40GB cho các biến thể 1.7/7B và GPU A-100 80GB cho các biến thể 13B. Mô hình được tối ưu hóa bằng trình tối ưu Adam và bộ lập lịch LR cosine với tốc độ học cơ sở 2e-5 cho bộ chiếu và 2e-4 cho mô hình ngôn ngữ. Việc tinh chỉnh mất khoảng 12 giờ cho 1.7B, 42 giờ cho 7B và gần 76 giờ cho mô hình 13B.

4.2 Ngôn ngữ Nhiều tài nguyên vs Ít tài nguyên
Công trình của chúng tôi huấn luyện và đánh giá trên mười ngôn ngữ được chia thành hai nhóm, ngôn ngữ nhiều tài nguyên và ít tài nguyên. Tiếng Anh, tiếng Trung, tiếng Pháp, tiếng Tây Ban Nha, tiếng Nga và tiếng Nhật được coi là các ngôn ngữ nhiều tài nguyên vì dữ liệu huấn luyện mô hình ngôn ngữ chứa một số lượng hợp lý các mẫu từ những ngôn ngữ này. Mặt khác, tiếng Ả Rập, tiếng Hindi, tiếng Bengal và tiếng Urdu được phân loại là các ngôn ngữ ít tài nguyên vì chúng thiếu đại diện trong dữ liệu huấn luyện mô hình ngôn ngữ.

Ví dụ, dữ liệu huấn luyện trước LLaMA-2 (Touvron et al., 2023) chứa gần 2 nghìn tỷ token, trong đó 89.7% là tiếng Anh và gần 1.92% là cho tiếng Trung, tiếng Pháp, tiếng Tây Ban Nha, tiếng Nga, tiếng Nhật và 21 ngôn ngữ tương tự khác. Trong khi đó, sự đại diện của tiếng Ả Rập, tiếng Hindi, tiếng Bengal và tiếng Urdu là không đáng kể. Tương tự, MobileLLaMA (Chu et al., 2023) huấn luyện trước trên bộ dữ liệu RedPajama-v1 (Computer, 2023) bao gồm gần 1.3 nghìn tỷ token, chủ yếu là token tiếng Anh.

4.3 Kết quả
Trong việc đánh giá khả năng đa ngôn ngữ của VLM, chúng tôi tiến hành đánh giá toàn diện trên các ngôn ngữ khác nhau, sử dụng một bộ đánh giá chất lượng cao. Bộ này được xây dựng bằng cách dịch LLaVA-Bench (In-the-Wild) (Liu et al., 2023b) sang tất cả các ngôn ngữ đích bằng GPT-4-Turbo (Achiam et al., 2023), với sự chú ý đặc biệt đến việc bảo tồn tính chân thực ngôn ngữ và giảm thiểu các vấn đề thường gặp của dịch thuật tự động thông qua sửa chữa cẩn thận của con người. Điểm chuẩn bao gồm 24 hình ảnh đa dạng và thử thách từ các lĩnh vực khác nhau, như cảnh trong nhà và ngoài trời, meme và tác phẩm nghệ thuật, mỗi hình ảnh có mô tả chi tiết và một bộ 60 câu hỏi được thiết kế để kiểm tra khả năng hiểu biết và tổng quát hóa của mô hình.

Kết quả trong Bảng 1 cho thấy PALO đạt được hiệu suất mạnh mẽ trong các ngôn ngữ nhiều tài nguyên, như được thể hiện bởi các mô hình 7/13B ghi điểm trung bình lần lượt là 59.0 và 63.8 trên các ngôn ngữ này. Điều này chứng minh rằng việc mở rộng đa ngôn ngữ của chúng tôi đã được tích hợp hiệu quả mà không làm giảm khả năng ban đầu của mô hình. Hơn nữa, mô hình cho thấy những cải thiện hiệu suất tốt trong các ngôn ngữ ít tài nguyên, với điểm số trung bình tăng từ 26.0 và 26.9 lên 55.6 và 59.2 điểm, lần lượt cho các mô hình 7B và 13B.

Hiệu suất tổng thể trên tất cả mười ngôn ngữ cũng cải thiện, với mô hình 7B đạt được điểm số trung bình 57.65, và mô hình 13B đạt 61.97. Dữ liệu phản ánh rằng phương pháp của chúng tôi thành công tạo ra một VLM toàn diện, đa dạng và hiệu suất cao hơn, có khả năng xử lý bối cảnh phức tạp của các ngôn ngữ toàn cầu trong các tác vụ thị giác-ngôn ngữ (xem Hình 4 và 5 cho kết quả định tính).

Mô hình di động của chúng tôi thể hiện những cải thiện nhất quán trên cả ngôn ngữ nhiều tài nguyên và ít tài nguyên, với mức tăng trung bình tổng thể là 33.9 điểm so với mô hình cơ sở MobileVLM là 23.9 điểm. Trái ngược với xu hướng quan sát được trong mô hình 7/13B, phiên bản di động của chúng tôi cũng cho thấy cải thiện trong các ngôn ngữ nhiều tài nguyên như tiếng Anh và tiếng Trung. Sự khác biệt hiệu suất này được quy cho dữ liệu huấn luyện trước của mô hình ngôn ngữ. LLaMA-2 được huấn luyện trên 2 nghìn tỷ token với sự đại diện tốt hơn của các ngôn ngữ nhiều tài nguyên so với MobileLLaMA, chủ yếu được huấn luyện trên 1.3 nghìn tỷ token tiếng Anh.

4.4 Nghiên cứu loại bỏ
Bảng 2 cho thấy một nghiên cứu loại bỏ nơi chúng tôi huấn luyện mô hình 7B của mình trên 150K hướng dẫn đã dịch từ mỗi ngôn ngữ và đánh giá tất cả các mô hình trên tất cả các ngôn ngữ. Kết quả cho thấy mô hình cơ sở hoạt động tốt hơn các mô hình tinh chỉnh cụ thể theo ngôn ngữ đối với các ngôn ngữ nhiều tài nguyên, bao gồm tiếng Trung, tiếng Pháp, tiếng Tây Ban Nha và tiếng Nhật. Điều này là do các ngôn ngữ này có ít dữ liệu đa phương thức hơn so với mô hình cơ sở (tức là mô hình tiếng Anh được huấn luyện trên 665K hướng dẫn, trong khi các mô hình cụ thể theo ngôn ngữ được huấn luyện trên 150K hướng dẫn), và do quá trình dịch thuật bán tự động có nhiều nhiễu. Ngược lại, các mô hình tinh chỉnh cụ thể theo ngôn ngữ hoạt động tốt hơn trong trường hợp tiếng Ả Rập, tiếng Hindi, tiếng Bengal và tiếng Urdu, vì những ngôn ngữ này thiếu đại diện trong dữ liệu huấn luyện trước LLM. Cuối cùng, huấn luyện kết hợp càng cải thiện hiệu suất trên các ngôn ngữ ít tài nguyên. Hơn nữa, chúng tôi phát hiện rằng việc tăng số lượng dữ liệu huấn luyện đa phương thức đã dịch sẽ nâng cao hiệu suất. Ví dụ, dịch thêm 72K hướng dẫn từ bộ dữ liệu GQA (Hudson và Manning, 2019) sang tiếng Bengal và huấn luyện với tổng cộng 222K hướng dẫn cải thiện kết quả tiếng Bengal từ 34.8 lên 38.3. Nghiên cứu này bị giới hạn ở 150K hướng dẫn cho mỗi ngôn ngữ do hạn chế về tài nguyên.

5 Kết luận
Chúng tôi giới thiệu PALO, một LLM đa ngôn ngữ cho 5 tỷ người, bao phủ gần hai phần ba dân số thế giới. Nó nhận hình ảnh và truy vấn văn bản của người dùng làm đầu vào và trò chuyện hiệu quả trong cả các ngôn ngữ nhiều tài nguyên như tiếng Anh, tiếng Trung, tiếng Pháp, tiếng Tây Ban Nha, tiếng Nga và tiếng Nhật, và các ngôn ngữ ít tài nguyên như tiếng Ả Rập, tiếng Hindi, tiếng Bengal và tiếng Urdu. Để huấn luyện mô hình của chúng tôi trên mười ngôn ngữ, chúng tôi dịch 150K hướng dẫn sang từng ngôn ngữ bằng cách sử dụng các LLM được điều chỉnh tùy chỉnh. Để tinh chỉnh một LLM trên tác vụ dịch thuật ngôn ngữ, chúng tôi sử dụng 1K cuộc trò chuyện được chú thích bởi con người cho mỗi ngôn ngữ đích. Mô hình cuối cùng của chúng tôi đồng thời cung cấp năng lực trong mười ngôn ngữ và mang lại cải thiện hiệu suất tổng thể trong đánh giá thị giác-ngôn ngữ. Chúng tôi huấn luyện PALO trên ba quy mô (1.7B, 7B và 13B) để chứng minh khả năng tổng quát hóa và mở rộng của nó trên mười ngôn ngữ. Mã nguồn, mô hình và bộ dữ liệu của chúng tôi sẽ được phát hành công khai.

6 Hạn chế
Quá trình dịch thuật bán tự động, mặc dù hiệu quả, có thể không nắm bắt đầy đủ những sắc thái ngữ cảnh và văn hóa sâu sắc vốn có của từng ngôn ngữ. Điều này có thể ảnh hưởng đến khả năng của mô hình trong việc hiểu và tạo ra nội dung với độ sâu văn hóa, độ chính xác và độ chính xác cần thiết. Ngoài ra, việc lựa chọn mười ngôn ngữ của chúng tôi, mặc dù trải rộng hai phần ba dân số toàn cầu, vẫn bỏ qua một số lượng đáng kể các ngôn ngữ của thế giới, cho thấy còn chỗ để mở rộng thêm nhằm nâng cao sự đa dạng ngôn ngữ và tính toàn diện trong VLM.

7 Rủi ro Tiềm ẩn
Việc sử dụng dịch thuật bán tự động có thể mang lại những rủi ro tiềm ẩn gắn liền với các thiên kiến vốn có trong LLM, đặc biệt đối với các ngôn ngữ ít tài nguyên. Mô hình phải tính đến các sắc thái trong dữ liệu thị giác, như việc diễn giải các biểu tượng hoặc cử chỉ văn hóa, để ngăn chặn bất kỳ sự sai lệch nào. Các diễn giải của mô hình, bị ảnh hưởng bởi những thiên kiến này, có thể dẫn đến sự không chính xác trong các bối cảnh nhạy cảm về văn hóa. Cần phải đánh giá và áp dụng việc huấn luyện cần thiết để giảm thiểu những rủi ro như vậy.

8 Sử dụng Dữ liệu và Trợ lý AI
Chúng tôi sử dụng bộ dữ liệu LLaVA-Instruct (Liu et al., 2023b), được cấp phép theo Creative Commons Attribution (CCA) 4.0 International, có sẵn để sử dụng trong nghiên cứu. Hơn nữa, việc sử dụng các mô hình GPT tuân thủ (OpenAI). Tôn trọng thông tin giấy phép nguồn, chúng tôi sẽ phát hành tất cả các bộ dữ liệu được tạo ra trong công trình này dưới giấy phép CCA 4.0 International.

9 Chú thích của Con người
Đánh giá LLaVA-Bench (Liu et al., 2023b) cho mỗi ngôn ngữ được xác minh và sửa chữa bởi các chú thích viên được chọn để đại diện cho sự kết hợp đa dạng của giới tính và nhân khẩu học. Các chú thích viên được cung cấp phiên bản tiếng Anh cùng với phiên bản đã dịch. Họ được đưa ra hướng dẫn cụ thể để trung hòa tông điệu và thiên kiến trong quá trình sửa chữa.

10 Lời cảm ơn
Các tính toán được hỗ trợ bởi các tài nguyên được cung cấp bởi Cơ sở hạ tầng Học thuật Quốc gia cho Siêu máy tính ở Thụy Điển (NAISS) tại Alvis được tài trợ một phần bởi Hội đồng Nghiên cứu Thụy Điển thông qua thỏa thuận tài trợ số 2022-06725, siêu máy tính LUMI được lưu trữ bởi CSC (Phần Lan) và tập đoàn LUMI, và bởi tài nguyên Berzelius được cung cấp bởi Quỹ Knut và Alice Wallenberg tại Trung tâm Siêu máy tính Quốc gia.

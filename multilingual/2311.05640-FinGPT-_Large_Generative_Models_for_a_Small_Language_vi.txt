# FinGPT: Mô hình tạo sinh lớn cho một ngôn ngữ nhỏ

Risto Luukkonen†∗Ville Komulainen†Jouni Luoma†Anni Eskelinen†
Jenna Kanerva†Hanna-Mari Kupari†Filip Ginter†Veronika Laippala†
Niklas Muennighoff‡Aleksandra Piktus‡Thomas Wang‡Nouamane Tazi‡
Teven Le Scao‡Thomas Wolf‡Osma Suominen⋄Samuli Sairanen⋄
Mikko Merioksa⋄Jyrki Heinonen⋄Aija Vahtola⋄Samuel Antao◦
Sampo Pyysalo†∗

†Nhóm TurkuNLP, Đại học Turku‡Hugging Face
⋄Thư viện Quốc gia Phần Lan◦AMD
∗risto.m.luukkonen@utu.fi ,sampo.pyysalo@utu.fi

Tóm tắt

Các mô hình ngôn ngữ lớn (LLM) xuất sắc trong nhiều tác vụ NLP và hơn thế nữa, nhưng hầu hết các mô hình mở có phạm vi bao phủ rất hạn chế đối với các ngôn ngữ nhỏ hơn và công việc LLM có xu hướng tập trung vào các ngôn ngữ có dữ liệu gần như không giới hạn để huấn luyện trước. Trong nghiên cứu này, chúng tôi nghiên cứu những thách thức của việc tạo ra LLM cho tiếng Phần Lan, một ngôn ngữ được sử dụng bởi ít hơn 0,1% dân số thế giới. Chúng tôi biên soạn một bộ dữ liệu tiếng Phần Lan mở rộng kết hợp thu thập web, tin tức, mạng xã hội và sách điện tử. Chúng tôi theo đuổi hai cách tiếp cận để huấn luyện trước các mô hình: 1) chúng tôi huấn luyện bảy mô hình đơn ngữ từ đầu (186M đến 13B tham số) được gọi là FinGPT, 2) chúng tôi tiếp tục huấn luyện trước mô hình đa ngữ BLOOM trên hỗn hợp dữ liệu huấn luyện gốc và tiếng Phần Lan, tạo ra mô hình 176 tỷ tham số mà chúng tôi gọi là BLUUMI. Để đánh giá mô hình, chúng tôi giới thiệu FIN-bench, một phiên bản BIG-bench với các tác vụ tiếng Phần Lan. Chúng tôi cũng đánh giá các chất lượng mô hình khác như độc tính và thiên vị. Các mô hình và công cụ của chúng tôi được công khai tại https://turkunlp.org/gpt3-finnish.

1 Giới thiệu

Các mô hình ngôn ngữ thần kinh dựa trên kiến trúc Transformer (Vaswani et al., 2017) đã cách mạng hóa Xử lý Ngôn ngữ Tự nhiên (NLP) trong những năm gần đây, thúc đẩy hiện trạng kỹ thuật trong các tác vụ từ phân loại văn bản đến tạo văn bản mở. Các mô hình ngôn ngữ tạo sinh, chỉ bộ giải mã như Generative Pretrained Transformer (GPT) (Radford et al., 2018) đã là tâm điểm quan tâm đặc biệt một phần do khả năng đa tác vụ và few-shot của chúng (Radford et al., 2019; Brown et al., 2020). Khả năng của các mô hình như vậy để học ngầm thực hiện các tác vụ mà chúng chưa được huấn luyện trực tiếp đã được coi là gắn liền chặt chẽ với quy mô của mô hình (Brown et al., 2020; Chowdhery et al., 2022) và, có lẽ quan trọng hơn, với số lượng token huấn luyện (Hoffmann et al., 2022; Muennighoff et al., 2023b; Touvron et al., 2023). Hầu hết công việc trên các mô hình như vậy tập trung vào tiếng Anh, thường loại trừ hoàn toàn các ngôn ngữ khác, và giả định rằng hàng trăm tỷ token văn bản có sẵn cho việc huấn luyện mô hình.

Trong nghiên cứu này, chúng tôi xem xét những thách thức của việc giới thiệu các mô hình tạo sinh lớn cho tiếng Phần Lan, một ngôn ngữ Uralic được nói bản ngữ bởi ít hơn 6 triệu người. Mặc dù ngôn ngữ này được đại diện tương đối tốt trong các tài nguyên trực tuyến so với con số này, nhưng ít hơn 1% văn bản có sẵn trong ví dụ như Wikipedia và Common Crawl là tiếng Phần Lan (Pyysalo et al., 2021; Xue et al., 2021). Vì các thành viên khác trong họ ngôn ngữ hoặc còn nhỏ hơn và ít tài nguyên hơn hoặc khá xa, tài nguyên để tạo mô hình cho ngôn ngữ này khá hạn chế. Tiếng Phần Lan đã được đại diện ở một mức độ nào đó trong các mô hình dựa trên Transformer kể từ khi phát hành mô hình BERT đa ngữ gốc (Devlin et al., 2019), và một BERT đơn ngữ dành riêng cho ngôn ngữ này đã được tạo ra trước đó bởi Virtanen et al. (2019). Cũng một số mô hình tạo sinh cho tiếng Phần Lan đã được giới thiệu trước đó bởi nhóm "Finnish-NLP" và Hatanpää (2022), nhưng vì việc huấn luyện LLM rất tốn kém và tiếng Phần Lan bị hạn chế bởi kích thước dữ liệu có sẵn, các mô hình vượt quá một tỷ tham số cho đến nay vẫn chưa có trong bối cảnh NLP tiếng Phần Lan.

Chúng tôi biên soạn một bộ dữ liệu tiếng Phần Lan có phạm vi bao phủ rộng và huấn luyện các mô hình đơn ngữ lên đến 13 tỷ tham số cho 300 tỷ token (khoảng 8 epoch). Chúng tôi cũng thực hiện huấn luyện trước tiếp tục của mô hình BLOOM 176 tỷ tham số (Scao et al., 2022a) để mở rộng phạm vi bao phủ tiếng Phần Lan của nó, giới thiệu các bộ dữ liệu đánh giá mới, và đánh giá nhiều khía cạnh của các mô hình kết quả. Mặc dù các chi tiết về thu thập và xử lý dữ liệu của chúng tôi phần nào đặc thù cho tiếng Phần Lan, chúng tôi tin rằng nghiên cứu của chúng tôi có thể phục vụ như một mẫu để huấn luyện các mô hình lớn cho các ngôn ngữ nhỏ khác.

2 Các mô hình

Các mô hình của chúng tôi dựa trên kiến trúc GPT (Radford et al., 2019) và chúng tôi theo cách tiếp cận huấn luyện trước được phát triển cho họ mô hình ngôn ngữ đa ngữ lớn BLOOM (Scao et al., 2022a). Chúng tôi huấn luyện các mô hình tiếng Phần Lan đơn ngữ với tới 13 tỷ tham số từ đầu, theo GPT-3 (Brown et al., 2020) về số lượng lớp, chiều và số đầu chú ý (Bảng 1), và BLOOM về cả việc triển khai phần mềm cũng như các lựa chọn thiết kế cụ thể như việc sử dụng embedding vị trí Alibi (Press et al., 2021) và chuẩn hóa lớp (Scao et al., 2022b). Chúng tôi cũng tiếp tục huấn luyện trước mô hình BLOOM 176 tỷ tham số gốc với hỗn hợp corpus huấn luyện trước gốc và dữ liệu tiếng Phần Lan để tạo ra mô hình mà chúng tôi gọi là BLUUMI. Mặc dù các mô hình BLOOM được huấn luyện trên dữ liệu từ 46 ngôn ngữ khác nhau, việc huấn luyện không bao gồm tiếng Phần Lan. Nghiên cứu trước đây đã điều tra việc mở rộng các mô hình BLOOM nhỏ hơn sang các ngôn ngữ mới không được bao gồm trong huấn luyện trước (Yong et al., 2022) và tìm thấy các phương pháp tinh chỉnh hiệu quả tham số và (ở mức độ thấp hơn) huấn luyện trước tiếp tục là các cách tiếp cận hiệu quả. Do thực tế là mô hình BLOOM 176 tỷ tham số đã được huấn luyện thiếu đáng kể so với số lượng tham số (Hoffmann et al., 2022; Muennighoff et al., 2023b), chúng tôi tập trung vào huấn luyện trước tiếp tục trong nghiên cứu này.

3 Dữ liệu

Tiếp theo chúng tôi trình bày các nguồn dữ liệu huấn luyện, các bước tiền xử lý, thống kê dữ liệu và phân tích.

3.1 Nguồn dữ liệu

Chúng tôi dựa trên một loạt các nguồn văn bản rộng rãi, nhằm bao phủ một loạt các biến thể ngôn ngữ qua thể loại, phong cách, tác giả và thời kỳ. Các nguồn dữ liệu huấn luyện trước được liệt kê trong Bảng 2 và mô tả bên dưới, và tóm tắt các khoảng thời gian chúng bao phủ được đưa ra trong Phụ lục A.

Parsebank Finnish Internet Parsebank (Luotolahti et al., 2015) là một corpus 6 tỷ token tiếng Phần Lan được thu thập vào 2015-2016 từ Common Crawl và một cuộc thu thập Internet có mục tiêu được khởi tạo bởi nội dung đăng ký tên miền .fi và tất cả URL của tài liệu tiếng Phần Lan trong Common Crawl. Các văn bản đã được khử trùng ở mức đoạn văn sử dụng Onion (Pomikálek, 2011) và được làm sạch bằng thư viện jusText.

mC4 Phiên bản colossal, cleaned đa ngữ của corpus thu thập web Common Crawl (mC4) được giới thiệu bởi Xue et al. (2021) để huấn luyện các mô hình mT5. mC4 được dẫn xuất từ 71 cuộc thu thập web (2013-2020) được phát hành bởi Common Crawl trước khi tạo ra corpus. Chúng tôi sử dụng tập con tiếng Phần Lan của mC4 như được xác định bởi cld3, chứa 8 tỷ token qua 19 triệu tài liệu.

CC-Fi Để tối đa hóa phạm vi bao phủ văn bản tiếng Phần Lan trong tài nguyên Common Crawl, chúng tôi áp dụng một quy trình trích xuất tùy chỉnh cho tất cả các cuộc thu thập từ 2013-2022, nhấn mạnh việc thu hồi tiếng Phần Lan. Chúng tôi trích xuất văn bản bằng Trafilatura (Barbaresi, 2021) và thực hiện khử trùng chính xác ở mức tài liệu bằng MurmurHash trước các bước tiền xử lý chung được mô tả bên dưới. Quá trình xử lý này tạo ra 55 triệu tài liệu tổng cộng 20 tỷ token.

Fiwiki Phần tiếng Phần Lan của bách khoa toàn thư miễn phí Wikipedia bao gồm khoảng 180.000 bài viết có giấy phép mở được tạo bởi các biên tập viên tình nguyện. Cho công việc này, chúng tôi trích xuất văn bản từ bản dump 20221120 của Wikipedia tiếng Phần Lan bằng WikiExtractor (Attardi, 2015), tạo ra một bộ dữ liệu 110 triệu token.

Lönnrot Projekti Lönnrot là một dự án số hóa văn học tiếng Phần Lan và tiếng Thụy Điển không có bản quyền. Cho công việc này, chúng tôi sử dụng 2574 tác phẩm tiếng Phần Lan được xuất bản bởi Projekti Lönnrot vào đầu thời kỳ huấn luyện trước, chứa tổng cộng 125 triệu token.

Yle Lưu trữ của công ty phát thanh truyền hình công quốc gia Phần Lan (Yle) có sẵn cho nghiên cứu thông qua Ngân hàng Ngôn ngữ Phần Lan. Chúng tôi sử dụng toàn bộ lưu trữ Yle có sẵn vào đầu thời kỳ huấn luyện trước mô hình của chúng tôi, bao gồm khoảng 800.000 bài viết (220 triệu token) từ 2011-2020, trong đó 0,3% là tin tức dễ đọc.

STT Như với Yle, lưu trữ của Hãng Thông tấn Phần Lan (Suomen Tietotoimisto hay STT) được cung cấp cho nghiên cứu thông qua Ngân hàng Ngôn ngữ Phần Lan. Bộ sưu tập có sẵn vào đầu nghiên cứu này trải dài các xuất bản từ 1992-2018 và chứa 2,8 triệu bài viết thông tấn tổng cộng khoảng 300 triệu token.

ePub Thư viện Quốc gia Phần Lan duy trì một bộ sưu tập sách xuất bản điện tử ở Phần Lan. Cho mục đích của dự án này, thư viện cấp quyền truy cập vào bộ sưu tập ePub của mình gồm khoảng 30.000 nội dung sách điện tử tiếng Phần Lan. Vì những cuốn sách này vẫn có bản quyền, không thể phân phối lại các văn bản từ bộ dữ liệu này.

Lehdet Bộ dữ liệu Lehdet dựa trên tài liệu HTML được lưu trữ do Thư viện Quốc gia Phần Lan thu thập và bao gồm các cuộc thu thập hàng ngày, hàng tuần và hàng tháng của các trang web báo chí và cũng có cuộc thu thập tên miền .fi hàng năm bao phủ các năm từ 2015 đến 2021. Tổng bộ dữ liệu đã làm sạch bao gồm 85 tỷ ký tự từ 60 triệu tài liệu HTML. Bộ dữ liệu được cung cấp bởi Thư viện Quốc gia và không thể phân phối lại do bản quyền.

Suomi24 Lưu trữ của trang mạng xã hội lớn nhất ở Phần Lan, Suomi24, có sẵn cho nghiên cứu thông qua Ngân hàng Ngôn ngữ Phần Lan. Cho nghiên cứu này, chúng tôi tải xuống toàn bộ lưu trữ có sẵn vào thời điểm đó, bao gồm 95 triệu bình luận và 5 tỷ từ từ 2001-2020.

Reddit-Fi Trang web xã hội Reddit bao gồm một số diễn đàn thảo luận chủ yếu bằng tiếng Phần Lan. Cho công việc này, chúng tôi tải xuống lưu trữ Reddit và trích xuất văn bản từ các bài đăng trên r/Suomi, diễn đàn lớn nhất như vậy. Bộ dữ liệu chứa hơn 150.000 bài nộp và gần 4 triệu bình luận (tổng cộng 150 triệu token) từ 2009-2022.

ROOTS Bộ dữ liệu Responsible Open-science Open-collaboration Text Sources (ROOTS) (Laurençon et al., 2022) bao gồm 1,6 terabyte dữ liệu văn bản trải dài 59 ngôn ngữ được sử dụng để huấn luyện trước BLOOM (Scao et al., 2022a). Mặc dù tiếng Phần Lan không được bao gồm như một ngôn ngữ chính thức, phân tích contamination cho thấy 0,03% ROOTS là tiếng Phần Lan (Muennighoff et al., 2022). Chúng tôi sử dụng ROOTS trong việc huấn luyện trước tiếp tục của mô hình BLOOM, nhưng không cho các mô hình tiếng Phần Lan đơn ngữ.

3.2 Tiền xử lý

Tiếp theo chúng tôi mô tả ngắn gọn các bước tiền xử lý được thực hiện cho các bộ dữ liệu nguồn. Tất cả các script xử lý, tham số và mô hình có sẵn cùng với thống kê chi tiết tại https://github.com/TurkuNLP/finngen-tools.

Khử trùng Ngoài các bước khử trùng đã được thực hiện cho một số bộ dữ liệu (xem Mục 3.1), chúng tôi thực hiện khử trùng dựa trên chồng chéo N-gram gần đúng bằng Onion (Pomikálek, 2011) riêng cho tất cả các bộ dữ liệu. Chúng tôi chạy Onion với các tham số mặc định, đánh dấu là trùng lặp bất kỳ dòng văn bản nào (đoạn văn, tiêu đề, v.v.) mà ít nhất 50% N-gram đã xuất hiện trước đó. Sau đó chúng tôi cắt bỏ các dòng trùng lặp từ đầu và cuối mỗi tài liệu. Cuối cùng, nếu ít nhất 50% các dòng còn lại trong tài liệu là trùng lặp, chúng tôi loại bỏ toàn bộ tài liệu.

Lọc heuristic Để lọc ra các văn bản không có khả năng là văn bản tiếng Phần Lan, chúng tôi áp dụng một bộ bộ lọc dựa trên quy tắc, mở rộng trên các heuristic được giới thiệu bởi Virtanen et al. (2019). Tóm lại, các bộ lọc này loại bỏ các văn bản có ví dụ như tỷ lệ dấu câu hoặc chữ số với ký tự chữ cái bất thường cao, tỷ lệ ký tự chữ cái không phải tiếng Phần Lan với tiếng Phần Lan cao, tỷ lệ type-token thấp, hoặc độ dài dòng trung bình thấp. Bước này chỉ loại bỏ một tỷ lệ nhỏ văn bản, với hơn 95% văn bản còn lại trong hầu hết các tài nguyên.

Lọc mô hình N-gram Để loại bỏ thêm các văn bản có đặc điểm bề ngoài của văn bản nghiên cứu nhưng không có khả năng đại diện cho tiếng Phần Lan chuẩn, chúng tôi áp dụng bộ lọc perplexity sử dụng mô hình N-gram. Trước tiên chúng tôi huấn luyện mô hình KenLM (Heafield, 2011) trên tập hợp các văn bản tiếng Phần Lan tốt đã biết được chuẩn bị bởi Virtanen et al. (2019) để huấn luyện mô hình FinBERT của họ và sau đó áp dụng mô hình này vào tài liệu, loại bỏ các dòng có perplexity > 100 000. Bộ lọc này không được áp dụng cho các nguồn được ước tính là chủ yếu là văn bản được chỉnh sửa tốt (tin tức, Lönnrot, và Wikipedia). Đối với ba bộ dữ liệu thu thập web, bộ lọc loại bỏ 15-20% văn bản; đối với các bộ dữ liệu mạng xã hội, tỷ lệ này là 2-5%.

Lọc độc tính Để giảm tỷ lệ văn bản chứa ví dụ như từ tục tĩu hoặc tấn công danh tính, chúng tôi áp dụng bộ phân loại phát hiện độc tính tiếng Phần Lan được giới thiệu bởi Eskelinen et al. (2023). Bộ phân loại là mô hình FinBERT (Virtanen et al., 2019) được tinh chỉnh trên phiên bản dịch máy của bộ dữ liệu Jigsaw Toxicity. Bộ lọc không được áp dụng cho tin tức, sách Lönnrot, hoặc Wikipedia. Lọc độc tính loại bỏ 1-5% các nguồn khác ngoài CC-Fi, nhưng lên đến 23% văn bản CC-Fi. Hiệu ứng này có thể được giải thích bởi thực tế là CC-Fi là nguồn web duy nhất chưa được lọc trước đó để ví dụ như từ tục tĩu.

Che giấu dữ liệu cá nhân Chúng tôi áp dụng một bộ biểu thức chính quy có độ nhớ lại cao và các script dựa trên quy tắc để che giấu dữ liệu cá nhân như địa chỉ email và số điện thoại tiềm năng. Các script này tác động đến khoảng 0,2% ký tự tổng cộng.

Tokenization Chúng tôi huấn luyện một tokenizer tiếng Phần Lan đơn ngữ mới trên một mẫu dữ liệu huấn luyện trước bằng thư viện tokenizers. Chúng tôi theo công thức BLOOM cho tokenizer, tạo ra một tokenizer BPE cấp byte mà không chuẩn hóa Unicode và sử dụng cùng tiền tokenization dựa trên biểu thức chính quy như trong BLOOM. Vì tiếng Phần Lan là một ngôn ngữ kết hợp với hình thái phức tạp và do đó có số lượng dạng từ cao, chúng tôi chọn tạo ra một từ vựng tương đối lớn cho một tokenizer đơn ngữ gồm 131.072 token.

3.3 Thống kê dữ liệu

Thống kê của bộ dữ liệu cuối cùng sau tiền xử lý được trình bày trong Bảng 3. Chúng tôi lấy mẫu quá mức các tài nguyên mở và chất lượng cao như Lönnrot và Wikipedia. Tổng cộng, bộ dữ liệu huấn luyện trước cuối cùng (bao gồm lấy mẫu quá mức) bao gồm 38 tỷ token khi được xử lý với tokenizer tiếng Phần Lan của chúng tôi.

3.4 Phân tích register

Chúng tôi đặc trưng hóa nội dung của các bộ dữ liệu dựa trên Web (mC4, CC-Fi và Parsebank) bằng cách tự động phân tích phân phối register văn bản (hoặc thể loại) của chúng (Biber, 1988). Để làm điều này, chúng tôi áp dụng mô hình nhận dạng register dựa trên corpus FinCORE, được huấn luyện bằng XLM-R (Conneau et al., 2020). Cả mô hình và corpus đều được trình bày bởi Skantsi và Laippala (2022). Các danh mục register trình bày các loại văn bản với các đặc điểm và mục tiêu giao tiếp khác nhau, như tự sự, thảo luận tương tác và trữ tình. Bảng 4 trình bày tỷ lệ của các register trong ba bộ dữ liệu. Chúng ta thấy phân phối register tương đối tương tự qua các bộ dữ liệu, với tự sự rõ ràng thường xuyên nhất trong cả ba và các danh mục như how-to, spoken và lyrical chỉ đại diện cho các phần nhỏ của tổng số.

4 Huấn luyện trước

Công việc này tận dụng siêu máy tính LUMI, tại thời điểm viết bài này là máy tính lớn thứ ba và xanh nhất thứ bảy trên thế giới (Strohmaier et al., 2023). Trung tâm dữ liệu LUMI cho phép tiêu thụ điện được cung cấp hoàn toàn bằng thủy điện, và nhiệt thải do LUMI tạo ra được sử dụng bởi thành phố Kajaani, cung cấp lên đến 20% hệ thống sưởi ấm khu vực.

Việc huấn luyện được thực hiện trên tối đa 192 node, mỗi node bao gồm 4 GPU AMD Instinct MI250X, một CPU AMD Trento 64 lõi duy nhất và 512GB bộ nhớ. Vì GPU MI250X là một mô-đun đa chip với hai Graphics Compute Dies (GCD), mỗi node có thể được coi là có 8 GPU tổng cộng. Theo quan điểm này, việc huấn luyện sử dụng tối đa 1536 GPU. CPU 64 lõi được cấu hình như 4 node NUMA được liên kết với GPU. Do chế độ "tiếng ồn thấp" được sử dụng trên các node, chỉ có 63 lõi có sẵn cho việc huấn luyện.

Chúng tôi huấn luyện các mô hình của chúng tôi trên phiên bản điều chỉnh của framework huấn luyện trước BLOOM, Megatron-DeepSpeed. Bằng cách kết hợp các tính năng từ Megatron (Shoeybi et al., 2019) và DeepSpeed (Rasley et al., 2020), framework Megatron-DeepSpeed có thể được sử dụng để huấn luyện các mô hình ngôn ngữ lớn với pipeline, tensor và song song hóa dữ liệu qua GPU và node tính toán. Các thay đổi của chúng tôi đối với framework bao gồm việc làm cho codebase, bao gồm các kernel CUDA được tối ưu hóa của nó, có thể sử dụng được trên GPU AMD MI250X bằng PyTorch ROCm. Để tận dụng khả năng của MI250X, ROCm cho phép sử dụng các lõi ma trận GPU thông qua các triển khai thư viện rocBLAS và MIOpen của nó, lần lượt được tận dụng bởi PyTorch. PyTorch cũng tận dụng thư viện RCCL để triển khai các tập thể phân tán. RCCL cũng sử dụng cổng HIP của plugin AWS OpenFabrics Interface (OFI) để kích hoạt giao tiếp trực tiếp thông qua nhà cung cấp fabric Slingshot để cải thiện hiệu suất ở quy mô lớn.

Đối với các mô hình tiếng Phần Lan đơn ngữ được huấn luyện từ đầu, chúng tôi theo Brown et al. (2020) cũng trong việc đặt kích thước batch và tốc độ học tối đa ngoài các tham số kiến trúc mô hình. Đối với việc huấn luyện trước tiếp tục của BLOOM để tạo ra mô hình BLUUMI, chúng tôi giữ nguyên các tham số BLOOM gốc (Scao et al., 2022a). Các giá trị tham số huấn luyện trước được hiển thị trong Bảng 5.

Hình 1 cho thấy các đường cong loss cho dữ liệu validation được giữ lại cho các mô hình được huấn luyện từ đầu, cho thấy quá trình huấn luyện trước ổn định cho tất cả các mô hình và mô hình kỳ vọng của các mô hình lớn hơn đạt được loss thấp hơn.

5 Đánh giá

Tiếp theo chúng tôi trình bày một bộ dữ liệu đánh giá few-shot cho tiếng Phần Lan và so sánh khả năng của các mô hình bằng dữ liệu này. Chúng tôi cũng đánh giá alignment, thiên vị và độc tính của mô hình trong các đánh giá riêng biệt.

5.1 Bộ dữ liệu FIN-bench

BIG-bench (Srivastava et al., 2022) là một bộ sưu tập các tác vụ được tạo ra để đánh giá các khía cạnh khác nhau của khả năng mô hình. Cho nghiên cứu này, chúng tôi tạo ra một bộ dữ liệu đánh giá tiếng Phần Lan tương tự, FIN-bench, dựa trên một tập con BIG-bench được tăng cường với các tác vụ mới được giới thiệu. Các tác vụ chủ yếu được tạo ra bằng cách dịch máy văn bản của các tác vụ BIG-bench tương đương và sau đó sửa bất kỳ lỗi dịch nào cũng như đảm bảo rằng các câu hỏi vẫn có liên quan về mặt văn hóa đối với tiếng Phần Lan. Các ngoại lệ bao gồm các tác vụ Arithmetic (dữ liệu được tạo) và các tác vụ mới (Paraphrase, Analogy, Emotions). Bộ dữ liệu FIN-bench chứa tổng cộng 3919 ví dụ, được chia thành các tác vụ được mô tả ngắn gọn bên dưới. Các ví dụ của các tác vụ có thể được tìm thấy từ Phụ lục G.

Analogy Các phép tương tự của dạng Paris đối với Pháp như Helsinki đối với... đại diện cho một cách tiếp cận đã được thiết lập để đánh giá các mô hình ngôn ngữ. Chúng tôi tạo ra một bộ dữ liệu tương tự sử dụng các mẫu để chuyển đổi các tứ phân tương tự thành các câu hỏi ngôn ngữ tự nhiên. Chúng tôi tạo ra 130 ví dụ từ bộ dữ liệu của Venekoski và Vankka (2017) và dữ liệu của Mikolov et al. (2013) được dịch sang tiếng Phần Lan.

Arithmetic kiểm tra mức độ mà một mô hình đã có được khả năng thực hiện phép cộng, trừ, nhân và chia cơ bản từ một đến năm chữ số. Biến thể tiếng Phần Lan của tác vụ được tạo ra tự động bằng cách dịch thủ công các mẫu trong các script cho tác vụ BIG-bench tương ứng và bao gồm tổng cộng 1923 ví dụ.

Cause and effect đánh giá khả năng của mô hình để lý luận về tính nhân quả của hai sự kiện. Mỗi ví dụ nêu hai sự kiện, nguyên nhân và hậu quả, và mô hình được yêu cầu chọn thứ tự đúng. Tác vụ bao gồm 153 ví dụ.

Emotions đánh giá khả năng của mô hình phân loại câu theo cảm xúc mà chúng thể hiện. Tác vụ được dẫn xuất từ bộ dữ liệu XED (Öhman et al., 2020) bằng cách chọn các ví dụ có ít nhất năm từ có chính xác một nhãn cảm xúc và sau đó lọc thủ công một lựa chọn ngẫu nhiên của chúng để xác định 160 ví dụ mà một người chú thích không tham khảo hướng dẫn chú thích cụ thể sẽ được kỳ vọng gắn nhãn chính xác.

Empirical judgments đo lường mức độ một mô hình có thể phân biệt các câu thể hiện mối quan hệ nhân quả từ những câu thể hiện mối quan hệ tương quan. Tác vụ cũng chứa các đoạn văn bản trung tính mô phỏng cấu trúc của các câu chứa mối quan hệ tương quan hoặc nhân quả, nhưng không chứa cả hai. Có 33 ví dụ của mỗi danh mục trong tác vụ, tức là tổng cộng 99.

General knowledge đo lường khả năng của các mô hình trả lời các câu hỏi đơn giản mà hầu hết mọi người có thể dễ dàng trả lời, chẳng hạn như "Con ngựa có bao nhiêu chân?". Tác vụ là bản dịch của 70 ví dụ trong BIG-bench gốc cho tất cả trừ ba câu hỏi về chuyển đổi đơn vị imperial, mà chúng tôi thay thế bằng các câu hỏi về đơn vị metric.

Intent recognition kiểm tra lý luận logic của các mô hình bằng cách đo lường mức độ chúng có thể nhận ra ý định đúng từ một đầu vào. Tác vụ có thể là một yếu tố dự đoán tốt về hiệu suất trong các hệ thống đối thoại hướng tác vụ. Nó bao gồm 693 ví dụ được dịch ban đầu từ bộ dữ liệu được giới thiệu bởi Coucke et al. (2018).

Misconceptions đánh giá khả năng của mô hình phân biệt các quan niệm sai lầm phổ biến từ sự thật; các mô hình được huấn luyện trên các bộ dữ liệu internet chất lượng hỗn hợp ngày càng lớn có thể không phân biệt giữa các khẳng định phổ biến và những khẳng định đúng. Bản dịch của tác vụ này được lọc nặng bởi các chú thích viên của chúng tôi do được coi là quá tập trung vào Hoa Kỳ về mặt văn hóa. Khoảng 40% câu hỏi gốc đã được loại bỏ khỏi bộ dữ liệu, dẫn đến một tác vụ với 134 ví dụ.

Paraphrase kiểm tra liệu một mô hình có thể phân biệt paraphrase đầy đủ từ các câu chỉ tương tự. Tác vụ được tạo ra bằng cách chọn 100 ví dụ tích cực và 100 ví dụ tiêu cực từ Finnish Paraphrase Corpus (Kanerva et al., 2021), nhấn mạnh các trường hợp mà mọi người có thể phân loại mà không tham khảo đặc thù của các hướng dẫn chú thích corpus.

Sentence ambiguity đánh giá mức độ một mô hình có thể xác định liệu các câu với các khía cạnh mơ hồ được giới thiệu có chủ ý có nêu một tuyên bố đúng hay sai. Tác vụ bao gồm 60 ví dụ được dịch từ BIG-bench.

Similarities abstraction đo lường khả năng của mô hình xác định các liên kết trừu tượng giống con người giữa các đối tượng: ví dụ, một con chó và một con vẹt giống nhau ở chỗ chúng đều là thú cưng. Dữ liệu bao gồm 76 câu hỏi trắc nghiệm.

5.2 Kết quả few-shot

Chúng tôi đánh giá các mô hình trên FIN-bench trong các thiết lập zero đến ba shot và tóm tắt kết quả bằng độ chính xác trung bình qua tất cả các tác vụ. Đối với các tác vụ được tổ chức thành các tác vụ con (Cause and effect và Arithmetic), trước tiên chúng tôi tính trung bình qua các tác vụ con trước khi lấy trung bình tổng thể. Kết quả đánh giá chính được hình dung trong Hình 2.

Chúng tôi thấy rằng các mô hình đơn ngữ của chúng tôi ít nhất phù hợp và trong hầu hết các trường hợp vượt trội so với kết quả của các mô hình tiếng Phần Lan được phát hành trước đây có kích thước tương đương, hỗ trợ cho các lựa chọn chúng tôi đã thực hiện cho việc lựa chọn và tiền xử lý dữ liệu cũng như kiến trúc mô hình và quá trình huấn luyện trước. Hiệu suất tốt nhất của các mô hình được phát hành trước đây cho tiếng Phần Lan, 38,5%, được đạt được bởi mô hình lớn nhất được giới thiệu bởi Hatanpää (2022). Mô hình đơn ngữ tốt nhất của chúng tôi vượt trội kết quả này hơn 10% điểm và mô hình BLUUMI hơn 20% điểm, đại diện cho một bước tiến đáng kể trong hiện trạng kỹ thuật về khả năng của các mô hình tạo sinh được huấn luyện cho tiếng Phần Lan.

Như mong đợi, hiệu suất tổng thể thường tăng với số lượng ví dụ trong ngữ cảnh (zero đến ba shot) cũng như với kích thước mô hình, với một số ngoại lệ. Đầu tiên, một số mô hình nhỏ phá vỡ mô hình kỳ vọng, cho thấy hiệu suất zero-shot tốt hơn một đến ba shot. Điều này có thể liên quan đến xu hướng của các mô hình kém có khả năng hơn để đơn giản lặp lại các mô hình từ ngữ cảnh trước đó, có thể dẫn các mô hình sao chép bất cứ gì xuất hiện sau "Answer:" (hoặc tương đương) trong các ví dụ few-shot trước đó. Thứ hai, chúng tôi nhận thấy một sự giảm nhất quán về hiệu suất giữa các mô hình 8B và 13B tham số của chúng tôi. Điều này có thể được gây ra bởi overfitting do số lượng tham số và bước huấn luyện quá mức so với một lượng văn bản tương đối nhỏ (không lặp lại), có thể dẫn đến hiệu suất giảm (Muennighoff et al., 2023b). Dựa trên những kết quả này, chúng tôi ước tính rằng mô hình 8B tham số có thể là mô hình đơn ngữ có khả năng nhất của chúng tôi và, tổng quát hơn, khoảng 10B tham số có thể đại diện cho giới hạn để huấn luyện hiệu quả các mô hình đơn ngữ của loại này cho các ngôn ngữ có tài nguyên tương đối so sánh với những gì có sẵn cho tiếng Phần Lan.

Để đánh giá thêm mô hình BLUUMI, chúng tôi so sánh hiệu suất của nó với mô hình BLOOM gốc trên FIN-bench (Hình 3) và trên các tác vụ tiếng Anh từ EleutherAI evaluation harness (Gao et al., 2021) (Hình 4). Chúng tôi thấy rằng BLUUMI hoạt động tốt hơn đáng kể so với BLOOM trên các tác vụ FIN-bench trên tất cả các bài kiểm tra đánh giá few-shot, với sự khác biệt độ chính xác 12-18% điểm có lợi cho BLUUMI. Trên các tác vụ tiếng Anh, chúng tôi không thấy sự khác biệt đáng kể về hiệu suất giữa BLOOM gốc và BLUUMI (t-test hai phía). Những kết quả này cho thấy rằng việc huấn luyện trước tiếp tục đã thành công trong việc cải thiện đáng kể khả năng tiếng Phần Lan của mô hình mà không làm tổn hại đến khả năng tiếng Anh hiện có của mô hình gốc.

5.3 Alignment

Chúng tôi đánh giá alignment mô hình bằng tác vụ BIG-bench HHH alignment (Askell et al., 2021), bao gồm bốn danh mục: harmlessness, honesty, helpfulness, và other. Trái ngược với hầu hết các tác vụ khác trong BIG-bench, cả hai lựa chọn trong mỗi ví dụ đều có thể được coi là đúng: ví dụ, khi đánh giá harmlessness, việc mô hình cung cấp hướng dẫn cho các hành vi bạo lực là không mong muốn, và từ chối giúp đỡ được coi là câu trả lời đúng. Chúng tôi tạo ra một phiên bản tiếng Phần Lan của tác vụ HHH alignment thông qua dịch máy ban đầu và sửa chữa thủ công, và đánh giá các mô hình bằng cùng một quy trình như đối với các tác vụ BIG-bench khác. Kết quả được hiển thị trong Hình 5. Chúng tôi thấy rằng tất cả các mô hình hoạt động kém trong các tác vụ này, chỉ vượt quá baseline ngẫu nhiên cho danh mục other và đo lường đặc biệt thấp cho helpfulness. Mặc dù không đáng ngạc nhiên khi các mô hình cơ sở chưa được huấn luyện cụ thể để tuân theo hướng dẫn hoặc hoạt động trong ngữ cảnh đối thoại có điểm thấp trong tác vụ này, kết quả nhấn mạnh nhu cầu align các mô hình để đảm bảo rằng đầu ra của chúng hữu ích, vô hại và chính xác hơn về mặt thực tế. Chúng tôi lưu ý rằng mặc dù dường như có một số tương quan giữa kích thước mô hình và hiệu suất HHH, tất cả các khác biệt vẫn trong phạm vi một độ lệch chuẩn và không có ý nghĩa.

5.4 Thiên vị

Các mô hình ngôn ngữ có xu hướng đã được thiết lập để lặp lại hoặc khuếch đại các thiên vị có trong dữ liệu huấn luyện. Như một ví dụ về thiên vị, các khuôn mẫu giới tính nữ/nam trong các mô hình là một mối quan tâm vì việc sử dụng rộng rãi của chúng có thể dẫn đến việc khuếch đại thêm những thiên vị này (Bolukbasi et al., 2016). Chúng tôi đánh giá sự xuất hiện của thiên vị như vậy bằng cách sử dụng các prompt có cấu trúc "Tên của [chuyên gia hoặc người nắm giữ nghề nghiệp] là" và phân loại các tên được dự đoán thành nam hoặc nữ khi tên có liên kết đó trong 95% trường hợp trong thống kê quốc gia. Phân phối được dự đoán bởi mô hình sau đó được so sánh với phân phối trong hồ sơ dữ liệu lao động được xuất bản gần đây nhất do Cục Thống kê Phần Lan xuất bản năm 2020. Như được minh họa trong Hình 6 và chi tiết trong Phụ lục C, mô hình phản ánh rộng rãi phân phối lao động thực tế, cho thấy rằng nó đã học thiên vị này từ dữ liệu huấn luyện trước. Chúng tôi lưu ý rằng mặc dù đây chỉ là một ví dụ về một loại thiên vị mà các mô hình của chúng tôi (cũng như hầu hết các mô hình hiện tại khác) có thể học trong huấn luyện trước của chúng, nó chứng minh lý do tại sao những mô hình như vậy không nên được áp dụng một cách ngây thơ ví dụ cho các quyết định tuyển dụng (xem thêm Hạn chế bên dưới).

5.5 Độc tính

Để kiểm tra mức độ các mô hình của chúng tôi có xu hướng tạo ra nội dung độc tính, chúng tôi theo cách tiếp cận tạo không được nhắc của Gehman et al. (2020), nhắc các mô hình chỉ với token end-of-sequence (EOS) của chúng để báo hiệu bắt đầu một ngữ cảnh mới. Các thế hệ không được nhắc sau đó được phân loại cho nội dung độc tính bằng mô hình được giới thiệu bởi Eskelinen et al. (2023) (xem thêm Mục 3.2) và một mẫu nhỏ được đánh giá thủ công để đảm bảo chất lượng gắn nhãn. Kết quả của đánh giá này được tóm tắt trong Hình 7. Chúng tôi thấy rằng các mô hình của chúng tôi giảm hơn một nửa phần trăm nội dung độc tính được tạo ra khi so sánh với các mô hình từ Hatanpää (2022), được huấn luyện mà không lọc các văn bản huấn luyện trước cho độc tính. Tuy nhiên, các mô hình của chúng tôi vẫn tạo ra các thế hệ độc tính không được nhắc khoảng 2% thời gian, phản ánh những thách thức còn lại trong alignment của chúng.

6 Thảo luận và kết luận

Trong nghiên cứu này, chúng tôi đã biên soạn một bộ dữ liệu tiếng Phần Lan mở rộng và tạo ra tổng cộng tám mô hình ngôn ngữ lớn mới: bảy mô hình tiếng Phần Lan đơn ngữ từ 185 triệu đến 13 tỷ tham số và một mô hình đa ngữ 176 tỷ tham số, BLUUMI. Chúng tôi cũng giới thiệu một bộ dữ liệu đánh giá mới, FIN-bench, và đánh giá các mô hình trong các thiết lập few-shot cũng như đánh giá cụ thể alignment, thiên vị và độc tính của chúng. Chúng tôi thấy rằng các mô hình của chúng tôi có khả năng vượt trội đáng kể so với các mô hình tiếng Phần Lan trước đây và việc huấn luyện trước tiếp tục đã cải thiện đáng kể khả năng tiếng Phần Lan của BLUUMI mà không làm tổn hại đến khả năng tiếng Anh hiện có của nó. Chúng tôi cũng chứng minh những hạn chế của các mô hình về alignment, kết hợp thiên vị và xu hướng còn lại để tạo ra nội dung độc tính, mà chúng tôi nhằm giải quyết trong công việc tương lai. Chúng tôi hy vọng các mô hình của chúng tôi sẽ phục vụ như các mô hình nền tảng cho tiếng Phần Lan có thể được sử dụng trong nghiên cứu và tận dụng thông qua tinh chỉnh hướng dẫn và các phương pháp alignment khác (Ouyang et al., 2022) để tạo ra một loạt các công cụ có khả năng xử lý văn bản tiếng Phần Lan. Trong công việc tương lai, chúng tôi hy vọng tiếp tục nghiên cứu các cách tiếp cận hiệu quả và bền vững về môi trường để tạo ra các mô hình nền tảng mở có khả năng cho các ngôn ngữ ít tài nguyên hơn.

Lời cảm ơn

Các tác giả muốn cảm ơn CSC – Trung tâm CNTT cho Khoa học, Phần Lan, vì tài nguyên tính toán hào phóng trên siêu máy tính LUMI. Dự án này đã nhận được tài trợ từ chương trình nghiên cứu và đổi mới Horizon Europe của Liên minh Châu Âu theo Thỏa thuận cấp phép số 101070350 và Hội đồng Nghiên cứu Phần Lan, số cấp phép 331297. Nội dung của ấn phẩm này là trách nhiệm duy nhất của các tác giả và không nhất thiết phản ánh ý kiến của Liên minh Châu Âu.

Hạn chế

Các mô hình được giới thiệu trong công việc này được huấn luyện chủ yếu trên dữ liệu có nguồn gốc từ internet, và bất chấp những nỗ lực của chúng tôi để loại bỏ các văn bản có khả năng có hại khỏi dữ liệu huấn luyện trước, chúng mang theo nhiều hạn chế đã được thiết lập của các mô hình như vậy (Bender et al., 2021; Weidinger et al., 2021). Trong đánh giá của chúng tôi, chúng tôi đã chứng minh thực nghiệm các hạn chế cụ thể về alignment mô hình (Mục 5.3), thiên vị (Mục 5.4), và độc tính (Mục 5.5). Mặc dù các mô hình được giới thiệu cải thiện đáng kể so với khả năng của các mô hình được phát hành trước đây trong một loạt các tác vụ tiếng Phần Lan, do những hạn chế này và khác, các mô hình chủ yếu nên được coi là tài nguyên cho nghiên cứu và một nền tảng tiềm năng cho các công cụ và ứng dụng, nhưng chúng không nên được sử dụng như hiện tại cho các ứng dụng hướng người dùng hoặc cho bất kỳ tác vụ nào có tiềm năng tác động cao đến quyền hoặc phúc lợi của mọi người, chẳng hạn như quyết định tuyển dụng. Công việc thêm đáng kể có thể cần thiết để tạo ra các phiên bản của các mô hình có thể được đảm bảo được align tốt, không có thiên vị và không có xu hướng tạo ra đầu ra độc tính.

Công việc của chúng tôi tập trung vào các mô hình lớn cho một ngôn ngữ ít tài nguyên hơn, và lượng văn bản tiếng Phần Lan có sẵn cho huấn luyện trước mô hình là một hạn chế cơ bản của công việc chúng tôi. Bất chấp việc dựa trên một loạt các nguồn rộng rãi, không thể tập hợp đủ văn bản để tránh nhiều epoch trên dữ liệu để phù hợp với quá trình huấn luyện trước GPT-3, và việc lặp lại dữ liệu có thể được phản ánh trong khả năng giảm, đặc biệt là đối với mô hình đơn ngữ lớn nhất (Mục 5.2). Những thách thức của việc thu thập đủ văn bản tiếng Phần Lan chất lượng cao cho việc huấn luyện mô hình lớn cũng buộc chúng tôi phải lựa chọn giữa chất lượng và số lượng dữ liệu một mặt và khả năng sao chép mặt khác. Chúng tôi chọn huấn luyện một phần trên các văn bản được cung cấp bởi Thư viện Quốc gia Phần Lan như một phần của hợp tác nghiên cứu. Mặc dù đây là một số văn bản chất lượng cao nhất trong bộ dữ liệu của chúng tôi, chúng không thể được phân phối lại dễ dàng, và việc sao chép hoàn toàn công việc của chúng tôi do đó là không thể mà không có sự tham gia của thư viện quốc gia. Mặc dù chúng tôi tiếc về hạn chế này, chúng tôi lưu ý rằng việc thiếu quyền truy cập vào dữ liệu huấn luyện trước hoàn chỉnh là một khía cạnh tiêu cực mà các mô hình của chúng tôi chia sẻ với nhiều mô hình hiện tại khác. Công việc tương lai có thể xem xét tăng dữ liệu có sẵn thông qua các kỹ thuật tăng cường (Dhole et al., 2021) hoặc trộn với dữ liệu từ một phương thức khác như code (Muennighoff et al., 2023b,a; Allal et al., 2023; Li et al., 2023).

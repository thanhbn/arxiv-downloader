Bộ Dữ Liệu Aya: Một Bộ Sưu Tập Mở Cho Việc Tinh Chỉnh Hướng Dẫn Đa Ngôn Ngữ

Shivalika Singh♦1, Freddie Vargus♦1, Daniel D'souza♦1, Börje F. Karlsson♦2,
Abinaya Mahendiran♦1, Wei-Yin Ko♦3, Herumb Shandilya♦1, Jay Patel4,
Deividas Mataciunas1, Laura O'Mahony5, Mike Zhang6, Ramith Hettiarachchi7,
Joseph Wilson8, Marina Machado3, Luisa Souza Moura3, Dominik Krzemiński1,
Hakimeh Fadaei1, Irem Ergün3, Ifeoma Okoh1, Aisha Alaagib1,
Oshan Mudannayake1, Zaid Alyafeai9, Vu Minh Chien1, Sebastian Ruder3,
Surya Guthikonda1, Emad A. Alghamdi10, Sebastian Gehrmann11,
Niklas Muennighoff1, Max Bartolo3, Julia Kreutzer12, Ahmet Üstün12,
Marzieh Fadaee12, và Sara Hooker12

1Cộng đồng Cohere For AI,2Học viện Trí tuệ Nhân tạo Bắc Kinh,3Cohere,4Đại học Binghamton,
5Đại học Limerick,6Đại học Công nghệ Copenhagen,7MIT,8Đại học Toronto,9Đại học King Fahd về
Dầu khí và Khoáng sản,10Đại học King Abdulaziz, ASAS.AI,11Bloomberg LP,12Cohere For AI

Tác giả liên hệ: Shivalika Singh <shivalikasingh95@gmail.com>, Marzieh Fadaee <marzieh@cohere.com>,
Sara Hooker <sarahooker@cohere.com>

Tóm tắt

Các bộ dữ liệu là nền tảng cho nhiều đột phá trong trí tuệ nhân tạo hiện đại. Nhiều thành tựu gần đây trong lĩnh vực xử lý ngôn ngữ tự nhiên (NLP) có thể được quy cho việc tinh chỉnh các mô hình được đào tạo trước trên một tập hợp đa dạng các nhiệm vụ cho phép một mô hình ngôn ngữ lớn (LLM) phản hồi các hướng dẫn. Tinh chỉnh hướng dẫn (IFT) yêu cầu các bộ dữ liệu được xây dựng và chú thích cụ thể. Tuy nhiên, các bộ dữ liệu hiện có hầu như đều bằng tiếng Anh. Trong công trình này, mục tiêu chính của chúng tôi là thu hẹp khoảng cách ngôn ngữ bằng cách xây dựng một bộ dữ liệu tuân thủ hướng dẫn được con người tuyển chọn trải rộng 65 ngôn ngữ. Chúng tôi đã làm việc với những người nói thành thạo các ngôn ngữ từ khắp nơi trên thế giới để thu thập các trường hợp tự nhiên của hướng dẫn và hoàn thành. Hơn nữa, chúng tôi tạo ra bộ sưu tập đa ngôn ngữ rộng lớn nhất cho đến nay, bao gồm 513 triệu trường hợp thông qua tạo mẫu và dịch các bộ dữ liệu hiện có qua 114 ngôn ngữ. Tổng cộng, chúng tôi đóng góp bốn tài nguyên chính: chúng tôi phát triển và mở mã nguồn Nền tảng Chú thích Aya, Bộ Dữ liệu Aya, Bộ Sưu tập Aya, và Bộ Đánh giá Aya. Sáng kiến Aya cũng phục vụ như một nghiên cứu tình huống có giá trị trong nghiên cứu tham gia, liên quan đến các cộng tác viên từ 119 quốc gia. Chúng tôi coi đây là một khuôn khổ có giá trị cho các hợp tác nghiên cứu tương lai nhằm thu hẹp các khoảng trống trong tài nguyên.

1 Giới thiệu

Các bộ dữ liệu là những đại diện tĩnh của thế giới, rất xa với môi trường phong phú, không ngừng phát triển mà chúng ta như con người điều hướng. Tuy nhiên, những bức ảnh chụp nhanh đóng băng trong thời gian này là nền tảng mà sự tiến bộ trong AI được xây dựng. Nhiều đột phá gần đây trong mô hình ngôn ngữ có thể được quy cho việc tinh chỉnh

♦Tác giả đầu tiên.
Được phát hành như bản thảo trước vào ngày 12 tháng 2, 2024 1arXiv:2402.06619v1 [cs.CL] 9 Feb 2024

các mô hình được đào tạo trước trên một tập hợp đa dạng các nhiệm vụ cho phép Mô hình Ngôn ngữ Lớn (LLM) tuân theo hướng dẫn [McCann et al., 2018; Sanh et al., 2022; Wei et al., 2022a; Muennighoff et al., 2023c; Longpre et al., 2023a]. Tinh chỉnh hướng dẫn (IFT) tận dụng tiền đề rằng các nhiệm vụ Xử lý Ngôn ngữ Tự nhiên (NLP) có thể được mô tả thông qua các hướng dẫn ngôn ngữ tự nhiên, chẳng hạn như "Các đánh giá về phim Barbie như thế nào?" hoặc "Viết một công thức từ danh sách nguyên liệu sau đây." Quá trình này yêu cầu các lời nhắc được ghép với các hoàn thành dự kiến [Ziegler et al., 2020; Ouyang et al., 2022] nhằm nắm bắt sự đa dạng của các cách một LLM có thể được sử dụng trong các nhiệm vụ xuôi dòng. Tuy nhiên, chính hành động tuyển chọn dữ liệu tạo ra một quan điểm về những phân phối mà chúng ta muốn mô hình của mình đại diện và điều gì bị lãng quên. Vậy, những bộ dữ liệu được sử dụng rộng rãi này nói gì với chúng ta về các giả định cơ bản của những đột phá này?

Hơn 7.000 ngôn ngữ được nói trên khắp thế giới ngày nay, với một số lượng đáng kể đang đối mặt với những thách thức về việc có ít tài nguyên, bị thiếu đại diện, hoặc đang biến mất [Maxwell & Hughes, 2006; Simons, 2019; Moran & Chiarcos, 2020; Secretariat, 2022; Gao & Liu, 2023; Ilhomovna & Yuldasheva, 2023; Marivate et al., 2020]. Ngược lại, các bộ dữ liệu được sử dụng rộng rãi nhất và các đột phá trong NLP đã hợp nhất xung quanh một vài ngôn ngữ giàu dữ liệu [Longpre et al., 2023b; Taori et al., 2023; Chung et al., 2022; Fan et al., 2021; Dodge et al., 2021; Lucy et al., 2024]. Các bộ dữ liệu IFT cũng không ngoại lệ; việc tạo ra các bộ dữ liệu này hầu như hoàn toàn tập trung vào tiếng Anh. Hơn nữa, phần lớn những người tạo ra các công trình này có nguồn gốc từ một vài quốc gia [Longpre et al., 2023b; Zhang et al., 2022].

Các yếu tố cơ bản của việc xây dựng bộ dữ liệu ảnh hưởng đến cách các mô hình hoạt động cho người dùng trên khắp thế giới. Các mô hình hoạt động tốt hơn trên phân phối mà chúng được đào tạo để bắt chước [Kunchukuttan et al., 2021]. Điều này thường đưa ra những thiên kiến đã biết đối với các ngôn ngữ [Schwartz et al., 2022; Kotek et al., 2023; Khandelwal et al., 2023; Vashishtha et al., 2023; Khondaker et al., 2023] và các phương ngữ [Jørgensen et al., 2015; Blodgett et al., 2016; Zampieri et al., 2017; Sun et al., 2023] không được bao gồm trong quá trình đào tạo và đưa ra những lỗ hổng bảo mật nghiêm trọng [Yong et al., 2023a; Nasr et al., 2023; Li et al., 2023b; Lukas et al., 2023; Deng et al., 2023].

Các bộ dữ liệu không chỉ đơn giản là nguyên liệu thô thúc đẩy các đột phá mà còn làm cho kẻ nghèo nghèo hơn và kẻ giàu giàu hơn [Held et al., 2023; Durmus et al., 2023; Robinson et al., 2023]. Sự chênh lệch trong việc tiếp cận các tài nguyên công nghệ có từ trước khi có LLM [Garrette et al., 2013]. Tuy nhiên, khi LLM trở nên tinh vi và có sẵn rộng rãi hơn, các ngôn ngữ không phải tiếng Anh sẽ vẫn bị thiếu đại diện và có khả năng trở nên nhiều hơn. Sự mất cân bằng giữa các ngôn ngữ đã tạo ra một sự phân chia ngày càng tăng trong chi phí sử dụng công nghệ này vì các ngôn ngữ bị thiệt thòi yêu cầu nhiều token hơn và phải chịu độ trễ cao hơn cho việc tạo ra [Ji et al., 2023b; Cui et al., 2023], đưa những người nói các ngôn ngữ có hiệu suất thấp vào công nghệ chất lượng thấp hơn [Held et al., 2023; Durmus et al., 2023; Nicholas & Bhatia, 2023; Ojo et al., 2023]. Thường thì, những người nói các ngôn ngữ ít tài nguyên không có tài nguyên để cải thiện công nghệ NLP cho ngôn ngữ của họ, đối mặt với ràng buộc kép ít tài nguyên với quyền truy cập hạn chế vào cả tính toán và dữ liệu [Ahia et al., 2021].

Trong công trình này, mục tiêu của chúng tôi là giảm bớt sự bất bình đẳng ngôn ngữ này. Những nỗ lực nhằm cải thiện hiệu suất đa ngôn ngữ thường tập trung vào việc cải thiện phạm vi dữ liệu [Chen et al., 2023b]. Tuy nhiên, hầu hết những nỗ lực hạn chế cho đến nay đã tập trung vào đào tạo trước đa ngôn ngữ [Scao et al., 2022a; Wei et al., 2023; Lample & Conneau, 2019] với ít công việc hơn nữa tập trung vào việc truyền đạt khả năng tuân theo hướng dẫn. Các phương pháp đã cố gắng dịch các bộ dữ liệu kiểu hướng dẫn tiếng Anh sang các ngôn ngữ khác thường gặp thiên kiến dịch thuật [Vanmassenhove et al., 2021; Hartung et al., 2023; Savoldi et al., 2021; Muennighoff et al., 2023c] hoặc không phản ánh bối cảnh văn hóa một cách thích hợp [Wang et al., 2022a; Ji et al., 2023a; Pudjiati et al., 2022]. Tuyển chọn tự động các bộ dữ liệu đa ngôn ngữ là một phương pháp logic —và đôi khi cần thiết— nhưng thường gặp nhiễu và thiên kiến. Điều này làm cho việc xác thực chất lượng của các bộ dữ liệu được tạo ra trở nên khó khăn [Kreutzer et al., 2022; Luccioni & Viviano, 2021; Ferrara, 2023; Caswell et al., 2020] hoặc yêu cầu tuyển chọn các mẫu thủ công thường dẫn đến tính đa dạng hướng dẫn và hoàn thành thấp [Muennighoff et al., 2023c] quan trọng cho hiệu suất mô hình [Naik et al., 2023; Chung et al., 2023; Li et al., 2023e; Lahoti et al., 2023].

Ngược lại, một khía cạnh chính của công việc chúng tôi tập trung vào dữ liệu được con người tuyển chọn khó có được hơn từ những người nói thành thạo một ngôn ngữ. Quá trình tuyển chọn này đã nhận được ít sự chú ý hơn nhiều do

thiếu quyền truy cập vào những người nói thành thạo, đặc biệt là ở các ngôn ngữ ít tài nguyên [Joshi et al., 2019]. Chúng tôi đã chọn lấp đầy khoảng trống này bằng cách tiến hành một sáng kiến nghiên cứu tham gia kéo dài một năm liên quan đến việc làm việc với những người nói thành thạo các ngôn ngữ từ khắp nơi trên thế giới để thu thập các trường hợp được con người tuyển chọn của hướng dẫn và hoàn thành. Bằng cách tận dụng các thực hành tốt nhất từ các dự án khoa học mã nguồn mở và đám đông [Franzoni & Sauermann, 2014; Beck et al., 2022; Lenart-Gansiniec et al., 2023], chúng tôi đã xây dựng một giao diện người dùng đơn giản và trực quan, Nền tảng Chú thích Aya2 (AyaUI) phục vụ như nền tảng trung tâm cho các cộng tác viên tham gia dự án Aya3 4. Tổng cộng, chúng tôi có 2.997 cộng tác viên trải rộng trên 119 quốc gia trên khắp thế giới. Những nỗ lực tập thể của họ đã tạo ra bộ dữ liệu Aya là bộ dữ liệu tinh chỉnh hướng dẫn đa ngôn ngữ được con người tuyển chọn lớn nhất cho đến nay, chứa 204.114 chú thích chất lượng cao bằng 65 ngôn ngữ.

Ngoài ra, chúng tôi phát hành và chuyển đổi 44 bộ dữ liệu có sẵn thành các tập hợp cặp hướng dẫn-hoàn thành bằng cách tạo ra các mẫu đa dạng thủ công, dựa vào những người nói thành thạo cho từng ngôn ngữ. Chúng tôi mở rộng thêm bộ sưu tập này bằng cách dịch các bộ dữ liệu từ tiếng Anh sang 101 ngôn ngữ. Chúng tôi gọi bộ sưu tập mở rộng gồm 513 triệu trường hợp bao gồm 114 ngôn ngữ tổng cộng này là Bộ sưu tập Aya, cho đến nay là bộ sưu tập dữ liệu tinh chỉnh hướng dẫn đa ngôn ngữ (IFT) rộng lớn nhất.

Tổng thể, Aya đóng góp bốn tài nguyên chính: Nền tảng Chú thích Aya (AyaUI); Bộ Dữ liệu Aya; Bộ Sưu tập Aya, và Bộ Đánh giá Aya. Hình 1 cho thấy một đại diện trực quan của Bộ Dữ liệu và Bộ Sưu tập Aya. Dưới đây, chúng tôi mô tả ngắn gọn những đóng góp cốt lõi này:

1. Nền tảng Chú thích Aya (AyaUI): Chúng tôi đã xây dựng một công cụ chú thích mạnh mẽ để thuận tiện cho việc thu thập dữ liệu đa ngôn ngữ chất lượng cao theo định dạng kiểu hướng dẫn hỗ trợ 182 ngôn ngữ, bao gồm các phương ngữ. Trong tám tháng, chúng tôi có tổng cộng 2.997 người dùng đã đăng ký trải rộng

2Nền tảng này có thể truy cập tại: https://aya.for.ai
3Từ Aya có nguồn gốc từ ngôn ngữ Akan (Twi) và được dịch là "dương xỉ" trong tiếng Anh [Willis, 1998].
4Aya đại diện cho sự bền bỉ, tháo vát và sự thách thức – như một cây dương xỉ mọc trong điều kiện cằn cỗi.

119 quốc gia và 134 ngôn ngữ, bao gồm các phương ngữ.

2. Bộ Dữ liệu Aya: Chúng tôi đã tạo ra bộ dữ liệu tinh chỉnh hướng dẫn đa ngôn ngữ được chú thích bởi con người lớn nhất cho đến nay, bao gồm hơn 204K trường hợp bao gồm 65 ngôn ngữ. Chúng tôi bao gồm một thẻ dữ liệu [Pushkarna et al., 2022] cho Bộ Dữ liệu Aya trong Phụ lục J.

3. Bộ Sưu tập Aya: Chúng tôi đã thu thập các mẫu kiểu hướng dẫn từ những người nói thành thạo và áp dụng chúng vào một danh sách được tuyển chọn gồm 44 bộ dữ liệu, bao gồm các nhiệm vụ như Phân loại Văn bản, Tạo ra Văn bản, Dịch máy, Diễn giải lại, và Trả lời Câu hỏi Miền mở. Một số bộ dữ liệu này cũng bao gồm các phiên bản đa ngôn ngữ tương đương được tạo ra thông qua dịch thuật. Chúng tôi phát hành 513M trường hợp bao gồm 114 ngôn ngữ. Những đóng góp này được cung cấp như một bộ sưu tập mã nguồn mở. Chúng tôi bao gồm một thẻ dữ liệu cho Bộ Sưu tập Aya trong Phụ lục J.

4. Bộ Đánh giá Aya: Chúng tôi tuyển chọn và phát hành một bộ đánh giá đa dạng cho chất lượng tạo ra miền mở đa ngôn ngữ. Nó bao gồm 250 lời nhắc được con người viết cho mỗi ngôn ngữ trong 7 ngôn ngữ, 200 lời nhắc được dịch tự động nhưng được con người chọn cho 101 ngôn ngữ (114 phương ngữ), và các lời nhắc được con người chỉnh sửa của phần sau cho 6 ngôn ngữ, và bản gốc tiếng Anh. Tập đầu tiên đại diện cho các lời nhắc có căn cứ văn hóa và gốc, trong khi các lời nhắc được dịch và được chỉnh sửa sau có nguồn gốc từ Dolly tiếng Anh [Conover et al., 2023] và được chọn vì tính liên quan đa văn hóa của chúng. Chúng tôi bao gồm một thẻ dữ liệu cho Bộ Sưu tập Aya trong Phụ lục J.

Bằng cách hoàn toàn mở mã nguồn Bộ Dữ liệu Aya, Bộ Sưu tập Aya và Bộ Đánh giá Aya với Giấy phép Apache 2.0 cho phép5 cũng như mã cho nền tảng chú thích của chúng tôi, chúng tôi hy vọng trao quyền cho các nhà nghiên cứu và thực hành viên để tiếp tục phát triển các mô hình và ứng dụng đa ngôn ngữ. Tất cả các bộ dữ liệu đều có thể truy cập để tải xuống.678

Tổ chức Bài báo Phần 2 thảo luận về thiết kế và phát triển của Nền tảng Chú thích Aya, cũng như việc chuẩn bị Bộ Dữ liệu Aya, và Phần 3 trình bày một phân tích chi tiết về Bộ Dữ liệu Aya. Phần 4 và Phần 5 chứa thảo luận và phân tích về Bộ Sưu tập Aya. Phần 6 mô tả chi tiết về bộ đánh giá được tuyển chọn trong dự án này. Trong Phần 7, chúng tôi mô tả phương pháp nghiên cứu tham gia của chúng tôi. Trong Phần 8, chúng tôi xem xét tài liệu hiện có, và trong Phần 9 chúng tôi thảo luận về những hạn chế của công việc chúng tôi. Phần 10 kết luận bài báo.

2 Nền tảng Chú thích Aya & Bộ Dữ liệu Aya

2.1 Nền tảng Chú thích Aya

Mục tiêu của dự án Aya là tạo điều kiện cho các chú thích vào một bộ dữ liệu có nguồn gốc đám đông bởi các cá nhân thành thạo các ngôn ngữ khác nhau. Đầu vào từ những người nói thành thạo mỗi ngôn ngữ đảm bảo rằng bộ dữ liệu có khả năng hữu cơ, lưu loát hơn và đại diện cho văn hóa của những người nói. Bao gồm những người nói thành thạo và bản ngữ từ nhiều khu vực khác nhau đặt ra những thách thức hậu cần đáng kể liên quan đến việc lựa chọn dữ liệu tỉ mỉ, các biện pháp kiểm soát chất lượng, và các công cụ chú thích tùy chỉnh. Chúng tôi đã phát triển Nền tảng Chú thích Aya để hợp lý hóa quá trình thu thập dữ liệu trên toàn thế giới, chứa đựng một số lượng lớn các cộng tác viên phi tập trung qua nhiều ngôn ngữ.

5https://www.apache.org/licenses/LICENSE-2.0
6https://hf.co/datasets/CohereForAI/aya_dataset
7https://hf.co/datasets/CohereForAI/aya_collection
8https://hf.co/datasets/CohereForAI/aya_evaluation_suite

Giao diện Người dùng (UI) đóng vai trò then chốt trong bối cảnh thu thập dữ liệu NLP, phục vụ như điểm tương tác chính giữa các chú thích viên con người và quá trình thu thập dữ liệu. Nền tảng Chú thích Aya9 phải chứa đựng người dùng ở 119 quốc gia thu thập dữ liệu qua 134 ngôn ngữ. Chúng tôi thiết kế nền tảng với một vài nguyên tắc chính trong tâm trí, chẳng hạn như khả năng tiếp cận và dễ sử dụng cho những người dùng không quen thuộc với AI và học máy. Như một phần đóng góp của chúng tôi, chúng tôi hoàn toàn mở mã nguồn cho UI10 của chúng tôi.

Khả năng Tiếp cận Vì người dùng trên toàn thế giới sử dụng các thiết bị và hệ điều hành khác nhau, chúng tôi quyết định hỗ trợ cả giao diện máy tính để bàn và di động [Muhammad et al., 2023]. Khoảng 54% người dùng truy cập AyaUI qua trình duyệt máy tính để bàn trong khi 46% sử dụng trình duyệt di động. Chúng tôi quy tỷ lệ cao của người dùng di động cho sự thiên lệch về người dùng di động ở Global South [Avle et al., 2018]. Chúng tôi hỗ trợ khả năng Đăng nhập Một lần (SSO) để cho phép theo dõi hồ sơ người dùng liền mạch và thưởng cho người dùng bằng điểm khi đóng góp dữ liệu qua nhiều phiên. Ban đầu chúng tôi chỉ hỗ trợ đăng nhập Discord nhưng phát hiện ra rằng Discord không thể truy cập hoặc không được sử dụng rộng rãi ở một số quốc gia. Ngoài ra, sự cần thiết của một tài khoản dành cho nền tảng cụ thể đã tạo ra một rào cản cho sự tham gia của người dùng với Aya. Điều này thúc đẩy chúng tôi thêm đăng nhập Google như một tùy chọn thay thế.

Ngôn ngữ Được Hỗ trợ Các cộng tác viên dự án Aya có thể chọn các ngôn ngữ mà họ thành thạo khi đăng ký sử dụng AyaUI. Sau đó họ có thể tạo chú thích bằng (các) ngôn ngữ mà họ đã chọn. Cho số lượng ngôn ngữ tuyệt đối mà chúng tôi có thể thu thập chú thích, chúng tôi chọn ưu tiên hỗ trợ chú thích cho 101 ngôn ngữ có sẵn trong mô hình mT5 [Xue et al., 2021]. Chúng tôi lưu ý rằng cuối cùng, một số ngôn ngữ này không nhận được đủ đóng góp để đưa vào bộ dữ liệu cuối cùng. Ngược lại, chúng tôi nhận được đóng góp đáng kể từ các ngôn ngữ ban đầu không phải là một phần của danh sách ban đầu, như Wolof, dẫn đến việc đưa chúng vào; Bộ Dữ liệu Aya cuối cùng bao gồm 65 ngôn ngữ. Bảng 5 cung cấp chi tiết về các ngôn ngữ này.

Cộng tác viên Chúng tôi nhắm đến việc bao gồm các cá nhân từ các nền tảng đa dạng—không giới hạn ở các chuyên gia AI—cho phép bất kỳ ai thành thạo một ngôn ngữ đóng góp. Nhóm cộng tác viên của chúng tôi cuối cùng phản ánh phương pháp bao gồm này. Trong quá trình đăng ký, chúng tôi yêu cầu chi tiết nhân khẩu học cụ thể từ mỗi người dùng AyaUI như quốc gia cư trú, ngôn ngữ giao tiếp thành thạo,

9https://aya.for.ai/
10https://github.com/for-ai/aya-annotations-ui

giới tính, độ tuổi, và các phương ngữ quen thuộc. Chúng tôi hiển thị biểu mẫu giới thiệu trong Hình 17 trong Phụ lục. Cộng đồng cộng tác viên Aya bao gồm 2.997 người dùng đã đăng ký qua 134 ngôn ngữ.

Nhân khẩu học Hình 3 minh họa nhân khẩu học của người dùng AyaUI đã đăng ký theo tuổi và giới tính. Về hồ sơ tuổi của người dùng, hơn hai phần ba ở độ tuổi từ 18 đến 35. Khoảng 68,1% người dùng tự nhận mình là nam giới và 28,5% là nữ giới. Tổng thể, 6,6% người dùng tự báo cáo phương ngữ. Trong nhóm này, 75% xác định một phương ngữ, 20% xác định hai phương ngữ, và 5% còn lại xác định ba hoặc nhiều phương ngữ hơn, với tối đa sáu.

Trong quá trình phát triển Aya, người dùng đã đăng ký được phân bố địa lý trên 119 quốc gia dựa trên nơi cư trú của họ. Một số quốc gia như Afghanistan, Bulgaria, Kuwait, và Tajikistan chỉ có một người dùng đã đăng ký. Hình 2 hiển thị phân bố toàn cầu này, nổi bật Ấn Độ với số lượng người dùng đã đăng ký cao nhất (346 trong số 2.997).

Đánh giá Đóng góp Dựa trên Địa lý Chúng tôi nhóm các ngôn ngữ theo các khu vực mà chúng có nguồn gốc hoặc được nói rộng rãi. Thống kê ngôn ngữ theo khu vực cho 101 ngôn ngữ ban đầu mà chúng tôi muốn bao gồm như sau: 14 ngôn ngữ ở Châu Phi, 41 ngôn ngữ ở Châu Á, 42 ngôn ngữ ở Châu Âu, và 4 ngôn ngữ ở Châu Mỹ Latinh (Xem Phụ lục C.1 để biết thêm chi tiết và một số ngoại lệ của phân phối). Như thấy trong Hình 4, hơn một nửa tất cả đóng góp cho dự án Aya đến từ Châu Á với 58,8%, tiếp theo là khu vực Châu Phi với 27,4%. Châu Âu, Châu Mỹ Latinh, và các khu vực khác chiếm 13,8% còn lại của các đóng góp.

Chúng tôi quan sát một sự thiên lệch lớn về đóng góp khu vực, điều này đáng để nghiên cứu thêm để hiểu tại sao một số mạng lưới cộng tác viên nhất định vẫn có động lực cho toàn bộ dự án. Những chênh lệch trong tham gia này có thể do chi phí cơ hội về thời gian [Gerosa et al., 2021; Wu et al., 2007], niềm tin văn hóa xung quanh việc chia sẻ dữ liệu [Huang et al., 2023], hoặc niềm tin rằng ngôn ngữ được đề cập không được phục vụ tốt bởi công nghệ hiện tại [Nicholas & Bhatia, 2023].

Ghi nhận đóng góp Sự công nhận và minh bạch được duy trì trong suốt dự án thông qua việc sử dụng bảng xếp hạng11 để ghi nhận đóng góp. Chúng tôi thực hiện một hệ thống tính điểm trong đó các cộng tác viên kiếm được tối đa ba điểm cho mỗi chú thích lại, với một điểm được trao cho việc đánh giá lời nhắc và hoàn thành, một điểm cho việc chỉnh sửa lời nhắc, và một điểm cho việc chỉnh sửa hoàn thành. Mỗi chú thích gốc được trao hai điểm. Chúng tôi mô tả các nhiệm vụ chú thích khác nhau trong AyaUI chi tiết trong Phần 2.2.

Bảng xếp hạng Aya được tổ chức để hiển thị điểm số hàng ngày, hàng tuần, và tích lũy, cung cấp một cái nhìn tổng quan toàn diện về đóng góp của người dùng. Người dùng có sự linh hoạt để lọc điểm số dựa trên các ngôn ngữ cụ thể, cho phép cảm giác cộng đồng giữa các cộng tác viên của một ngôn ngữ cụ thể. Thiết kế này nhằm thúc đẩy động lực của các cộng tác viên cung cấp đầu vào chất lượng cao cho các ngôn ngữ mà họ chọn. Hình 19 cho thấy một ví dụ về bảng xếp hạng. Chúng tôi thảo luận thêm chi tiết về hợp tác với cộng đồng trong Phần 7.

2.2 Nhiệm vụ chú thích

Trên Nền tảng Chú thích Aya, các cộng tác viên có thể đóng góp vào ba nhiệm vụ khác nhau, theo mô hình tìm-sửa-xác minh [Bernstein et al., 2015]: Viết các ví dụ mới từ đầu (chú thích gốc), chỉnh sửa các ví dụ hiện có để cải thiện chất lượng và tính toàn diện (chú thích lại), và đưa ra phản hồi về chất lượng của các đóng góp hiện có (phản hồi chú thích). Chúng tôi mô tả ngắn gọn từng cái dưới đây:

2.2.1 Chú thích Gốc

Nhiệm vụ này tạo điều kiện cho việc bao gồm nội dung hữu cơ do con người tạo ra bằng cách cho phép các chú thích viên gửi các cặp lời nhắc-hoàn thành gốc bằng ngôn ngữ của họ. Các mô hình đa ngôn ngữ hiện có đã được chỉ ra tạo ra các thế hệ bị ảnh hưởng bởi văn hóa phương Tây [Yuan et al., 2021; Naous et al., 2023; Lee et al., 2023] phản ánh thiên kiến đại diện cơ bản [Mehrabi et al., 2021] của các bộ dữ liệu đào tạo của chúng. Nhiệm vụ này nhằm khuyến khích các chú thích viên gửi các mẫu tươi mới đại diện cho ngôn ngữ, văn hóa, văn học, lịch sử, và khu vực của họ. Hướng dẫn cho các cộng tác viên có sẵn trong Phụ lục B.3.

2.2.2 Chú thích Lại

Mục đích của nhiệm vụ này là tạo điều kiện cho chú thích lại hoặc chỉnh sửa các cặp lời nhắc và hoàn thành. Quyết định thêm một nhiệm vụ chú thích lại một phần xuất phát từ nhu cầu giúp các chú thích viên hiểu định dạng dự kiến của các bộ dữ liệu kiểu hướng dẫn và truyền đạt sự đa dạng của các nhiệm vụ trong các bộ dữ liệu hiện có, bao gồm trả lời câu hỏi [Saad-Falcon et al., 2023; Arefeen et al., 2023], tóm tắt [Stiennon et al., 2020; Wu et al., 2021], diễn giải lại [Witteveen & Andrews, 2019; Reimers & Gurevych, 2019], và dịch thuật [NLLB-Team et al., 2022; Barrault et al., 2023]. Chỉnh sửa các ví dụ từ các bộ dữ liệu hiện có không chỉ giúp làm quen các chú thích viên với định dạng dự kiến

11Bảng xếp hạng Aya có thể truy cập tại: https://aya.for.ai/leaderboard/

mà còn cho phép đánh giá và xếp hạng con người về các bộ dữ liệu kiểu hướng dẫn được sử dụng rộng rãi hiện có. Tổng cộng, chúng tôi đã thu thập các bộ dữ liệu từ 19 nguồn dữ liệu công cộng và dịch chúng sang 114 ngôn ngữ có sẵn, bao gồm các phương ngữ sử dụng mô hình dịch máy NLLB 3.3B tham số [NLLB-Team et al., 2022]. Từ mỗi bộ sưu tập, chúng tôi chọn ngẫu nhiên 100 ví dụ (mỗi bộ dữ liệu và mỗi ngôn ngữ), tạo ra bộ dữ liệu của chúng tôi để chú thích, sau đó chúng tôi có 1M cặp lời nhắc-hoàn thành được dịch ban đầu được điền vào AyaUI như các nhiệm vụ chú thích lại. Những cặp được dịch này phục vụ như một điểm bắt đầu cho các lời nhắc và hoàn thành mà các chú thích viên có thể cải thiện. Chúng tôi phát hành các bản dịch thô như một phần của Bộ Sưu tập Aya, cung cấp thêm chi tiết về nguồn gốc của các bộ dữ liệu được dịch, và cách chúng được chọn trong Phần 4.2.

Ngoài các ví dụ được dịch, có các nguồn dữ liệu khác có sẵn phù hợp cho chú thích lại: các cặp Aya gốc, các bộ dữ liệu kiểu hướng dẫn có sẵn (ví dụ, xP3), và việc chuyển đổi các bộ dữ liệu thành định dạng kiểu hướng dẫn, tức là, các bộ dữ liệu được mẫu hóa. Bằng cách chú thích lại các ví dụ từ các nguồn khác nhau, chúng tôi đồng thời tăng cường chất lượng của các ví dụ cá nhân trong khi có được một tín hiệu về chất lượng tổng thể của bộ dữ liệu trong một ngôn ngữ cụ thể. Một minh họa về chú thích lại, nơi một chú thích viên tăng cường một lời nhắc/hoàn thành đã cho, được hiển thị trong Hình 5b.

2.2.3 Phản hồi Chú thích

Chất lượng dữ liệu là quan trọng để đảm bảo rằng một mô hình có thể đại diện tốt cho một ngôn ngữ. Học từ các bộ dữ liệu nhiễu, chất lượng thấp làm hại hiệu suất tổng thể của mô hình và chi phí tương đối cao của việc mã hóa các ví dụ nhiễu này là sự lạm dụng năng lực [Hsueh et al., 2009; Dodge et al., 2021; Luccioni & Viviano, 2021; Kreutzer et al., 2022]. Công việc trước đây đã chỉ ra rằng các cải thiện về chất lượng thông qua việc tỉa hoặc lựa chọn dữ liệu có thể có tác động đáng kể đến hiệu suất xuôi dòng của một mô hình [Longpre et al., 2023c; Marion et al., 2023; Boubdir et al., 2023; Yang et al., 2023]. Đặc biệt, đối với các bộ dữ liệu tinh chỉnh hướng dẫn, một tập con nhỏ các hướng dẫn chất lượng cao có thể vượt trội hơn nhiều so với một khối lượng lớn hướng dẫn chất lượng thấp [AlShikh et al., 2023; Zhou et al., 2023; Chen et al., 2023a]. Với những phát hiện này, đảm bảo đóng góp chất lượng cao là có tầm quan trọng tối cao.

Đảm bảo chất lượng nhất quán đặc biệt thách thức trong một sáng kiến khoa học mở với một số lượng lớn cộng tác viên. Chúng tôi đối mặt với hai thách thức chính:

Thay đổi trong Nhóm Chú thích viên. Trong dự án kéo dài một năm, các chú thích viên tham gia và rời khỏi dự án tại các thời điểm khác nhau tùy thuộc vào sở thích và sự có mặt của họ. Kết quả là, cửa sổ đóng góp cho mỗi chú thích viên là khác nhau. Chỉ một phần nhỏ các chú thích viên tham gia cho toàn bộ thời gian của dự án kéo dài một năm. Các chú thích viên hoạt động trung bình trong 1,3 phiên. Hình 6 trình bày một biểu đồ mô tả phân phối sự tham gia của người dùng dựa trên số ngày họ tích cực đóng góp. Trung bình, các chú thích viên Aya đã dành năm ngày đóng góp cho dự án. Các chú thích viên có xu hướng rất tích cực ngay sau khi tham gia, nhưng hoạt động của họ giảm theo thời gian. Có một nhóm con các chú thích viên duy trì hoạt động nhất quán trong thời gian dài.

Mức độ kinh nghiệm khác nhau với AI. Một mục tiêu quan trọng của dự án này là có một nhóm chú thích viên đa dạng và do đó chúng tôi không giới hạn tiêu chí lựa chọn đến kiến thức làm việc về các mô hình ngôn ngữ hoặc AI nói chung. Kết quả là, có các mức độ hiểu biết khác nhau giữa các chú thích viên về ý nghĩa của lời nhắc và hoàn thành. Ví dụ, chúng tôi tìm thấy ít nhất một cộng tác viên với 3.684 đóng góp cho ba ngôn ngữ (tiếng Anh, Somali, tiếng Ả Rập Chuẩn) đã thất bại trong việc cấu trúc các bài nộp của họ như một lời nhắc với một câu hỏi. Thay vào đó, cộng tác viên đã sử dụng một đoạn trích của văn bản như lời nhắc và phần tiếp theo của nó trong hoàn thành. Mở đầu những lời nhắc như vậy với một hướng dẫn như "Hoàn thành đoạn trích một phần của văn bản sau đây:" sẽ là một định dạng phù hợp hơn. Trong khi chúng tôi thường xuyên cung cấp các ví dụ cho các cộng tác viên, có một nhu cầu rõ ràng về một cách có hệ thống để xem xét và đo lường chất lượng của các bài nộp.

Xác thực chất lượng của các đóng góp Chúng tôi theo một phương pháp đánh giá đồng đẳng nơi mỗi chú thích viên hoạt động như một người đánh giá cho các chú thích viên khác làm việc trên cùng một ngôn ngữ. Những đánh giá này tạo thành

cơ sở cho một điểm số chất lượng Aya được hiển thị trên bảng xếp hạng trong UI. Điểm số chất lượng cho một chú thích viên được tính bằng cách lấy trung bình các xếp hạng trung bình kết hợp của các ví dụ của họ được cung cấp bởi các chú thích viên khác phục vụ như người đánh giá. Chúng tôi cung cấp thêm chi tiết về cách các chú thích được đánh giá trong Phần B.1 của Phụ lục. Tất cả ba nhiệm vụ trong AyaUI được kết nối trong một đường ống tuần tự nơi các bài nộp từ "Chú thích Gốc" được đánh giá trong nhiệm vụ "Chú thích Lại", và các chú thích lại được đánh giá thêm như một phần của nhiệm vụ "Phản hồi Chú thích". Phương pháp có hệ thống này cho phép đánh giá mạnh mẽ và tăng cường dữ liệu được thu thập.

2.3 Tiêu chí Đưa vào Bộ Dữ liệu Aya

Bộ Dữ liệu Aya bao gồm tất cả các chú thích gốc và một tập con của tất cả các chú thích lại. Chúng tôi chỉ phát hành các chú thích lại nếu có sự khác biệt giữa phiên bản gốc và được chỉnh sửa. Để xác định tập con này, chúng tôi tính tổng khoảng cách chỉnh sửa d (khoảng cách Levenshtein [Levenshtein et al., 1966]) giữa các lời nhắc và hoàn thành gốc và được chú thích lại ở cấp độ ký tự và sử dụng ngưỡng chấp nhận (d≥5). Điều này đảm bảo rằng chúng tôi không phát hành các bản sao của dữ liệu hiện có. Chỉ các ngôn ngữ có ít nhất 50 đóng góp mới được đưa vào bản phát hành cuối cùng của Bộ Dữ liệu Aya. Ngưỡng này được chọn vì nó đại diện cho sự cân bằng giữa việc đạt được một mức độ chất lượng dữ liệu hợp lý và xem xét các hạn chế thực tế của tài nguyên con người cho một số ngôn ngữ. Mục tiêu là bao gồm càng nhiều ngôn ngữ càng tốt mà không làm giảm chất lượng tổng thể của bộ dữ liệu. Bảng 5 liệt kê chi tiết về các ngôn ngữ được bao gồm trong Bộ Dữ liệu Aya.

3 Phân tích Bộ Dữ liệu Aya

3.1 Thống kê

Bộ Dữ liệu Aya chứa tổng cộng 204.114 trường hợp được thu thập qua Nền tảng Chú thích Aya. Bảng 2 cung cấp sự phân tích các chú thích gốc và chú thích lại trong bộ dữ liệu cuối cùng. Bộ dữ liệu bao gồm 65 ngôn ngữ: 22 ngôn ngữ tài nguyên cao, 12 ngôn ngữ tài nguyên trung bình, và 31 ngôn ngữ tài nguyên thấp (Xem Phụ lục E để biết thêm chi tiết về ánh xạ ngôn ngữ của chúng tôi).

3.2 Độ dài của Bộ Dữ liệu Aya

Một mục tiêu của dự án này là thu thập các lời nhắc và hoàn thành gốc lưu loát của con người. Bảng 3 cung cấp các ví dụ về lời nhắc và hoàn thành từ Bộ Dữ liệu Aya. Trong quá trình thu thập dữ liệu,

các chú thích viên được cung cấp các ví dụ và hướng dẫn nhưng cũng được tin tưởng để khám phá sự sáng tạo và nền tảng văn hóa riêng của họ để đưa ra các ví dụ mới. Kết quả là, việc hiểu sự khác biệt trong các thống kê tổng hợp như độ dài qua các bộ dữ liệu, loại ngôn ngữ và mối quan hệ với chất lượng được nhận thức là có ý nghĩa.

Tác động của Chú thích Lại Khi chỉnh sửa các trường hợp hiện có, chúng tôi hướng dẫn các chú thích viên ưu tiên tăng cường cả chất lượng và sự phong phú của các lời nhắc và hoàn thành. Độ dài trung bình của hoàn thành trước và sau chỉnh sửa được hiển thị trong Hình 7. Chúng tôi quan sát rằng qua tất cả các nguồn dữ liệu, độ dài trung bình của hoàn thành tăng sau chỉnh sửa. Trung bình, độ dài của hoàn thành sau chỉnh sửa dài hơn 25% so với trước chỉnh sửa. Chúng tôi quan sát sự tăng lớn nhất cho các chú thích gốc Aya được hiển thị trong UI – dài hơn trung bình 40% so với độ dài gốc.

Sự khác biệt độ dài qua các nhóm ngôn ngữ Độ dài lời nhắc và hoàn thành trung bình (số ký tự) được quan sát qua các nhóm ngôn ngữ khác nhau này được hiển thị trong Hình 8. Một sự tương phản rõ rệt tồn tại trong độ dài hoàn thành giữa các ngôn ngữ tài nguyên trung bình và thấp khi so sánh với các ngôn ngữ tài nguyên cao. Các hoàn thành dài và câu hoàn chỉnh có giá trị

trong các bộ dữ liệu tinh chỉnh hướng dẫn, đặc biệt khi đào tạo các mô hình đa ngôn ngữ để tạo nội dung trong các ngôn ngữ đó.

Độ dài so với Chất lượng Dữ liệu Được Nhận thức Mặc dù các hoàn thành dài hơn có thể có giá trị để đào tạo các mô hình tạo văn bản dài và tự nhiên, nó không nhất thiết ngụ ý chất lượng cao hơn. Sử dụng phản hồi của các chú thích viên trong UI, chúng tôi điều tra thêm tác động của độ dài đến chất lượng được nhận thức của các mẫu. Hình 9 thể hiện phân tích này. Chúng tôi quan sát một mối tương quan tích cực giữa độ dài của các lời nhắc và hoàn thành và tỷ lệ chấp thuận trung bình kết quả của chúng. Cụ thể, khi chúng tôi vẽ đồ thị độ dài lời nhắc và hoàn thành kết hợp so với chất lượng, chúng tôi quan sát hệ số tương quan là 0,27. Phát hiện này nhấn mạnh tầm quan trọng của việc sử dụng các lời nhắc và hoàn thành dài hơn và kết hợp các câu hoàn chỉnh để đảm bảo trải nghiệm con người tích cực khi tương tác với một mô hình như vậy.

Sự khác biệt độ dài theo ngôn ngữ Hình 25 trong Phụ lục minh họa thống kê cho mỗi ngôn ngữ. Chúng tôi quan sát một loạt các mẫu khác nhau qua các ngôn ngữ. Ví dụ trong tiếng Nhật, hoàn thành ngắn hơn trung bình 31% so với lời nhắc. Ở đầu kia, đối với tiếng Urdu và Yoruba, hoàn thành dài đáng kể so với lời nhắc. Trung bình, hoàn thành dài hơn 1258% và 2516% so với các lời nhắc tương ứng cho tiếng Urdu và Yoruba, tương ứng. Độ dài hoàn thành trung bình trong tiếng Yoruba dài hơn 1591% so với độ dài lời nhắc trung bình trong tiếng Nhật. Hình 26 cung cấp độ dài trung bình của sự kết hợp của lời nhắc và hoàn thành cho mỗi ngôn ngữ.

So sánh trong Độ dài Hoàn thành Qua Các Bộ dữ liệu Bộ Dữ liệu Aya có hoàn thành dài đáng kể trung bình khi so sánh với các bộ sưu tập dữ liệu khác như được hiển thị trong Hình 12. Điều này đặc biệt đáng chú ý cho rằng Bộ Dữ liệu Aya được con người tuyển chọn. Cho sự hiện diện của các hoàn thành dài hơn trong dữ liệu đào tạo cho nhiều ngôn ngữ ít tài nguyên, chúng tôi dự đoán rằng các mô hình được đào tạo trên Bộ Dữ liệu Aya sẽ tạo ra các phản hồi dài hơn và tự nhiên hơn.

3.3 Thiên lệch Chú thích viên

Một đặc điểm của các dự án nghiên cứu tham gia là thách thức thiết lập và duy trì một số lượng cân bằng các chú thích qua các nhóm chú thích viên. Trong dự án Aya, số lượng chú thích viên cho mỗi ngôn ngữ thay đổi do nhiều yếu tố. Kết quả là, phân phối của các chú thích

viên không đồng nhất qua các ngôn ngữ. Hơn nữa, trong mỗi ngôn ngữ, có thiếu đóng góp nhất quán từ tất cả các chú thích viên. Trong phần này, chúng tôi xem xét tác động của thiên lệch chú thích viên đến bộ dữ liệu kết quả.

Thiên lệch Chú thích viên Qua Các Ngôn ngữ. Các chú thích viên được khuyến khích đóng góp vào bất kỳ ngôn ngữ nào mà họ có thể đọc và viết thoải mái và được yêu cầu tập trung hầu hết nỗ lực của họ vào các ngôn ngữ khác ngoài tiếng Anh. Mặc dù một số lượng đáng kể người tham gia đã đăng ký cho nhiều ngôn ngữ, mức độ tham gia của các chú thích viên không bằng nhau, dẫn đến sự khác biệt đáng kể trong số lượng đóng góp qua các ngôn ngữ. Hình 10 (trên) cung cấp một cái nhìn tổng quan về tỷ lệ phần trăm của mỗi ngôn ngữ có mặt trong bản biên soạn cuối cùng. Số lượng đóng góp cao nhất là cho Malagasy với 14.597 trường hợp, và thấp nhất là 79 cho Kurdish.

Thiên lệch Chú thích viên Trong Một Ngôn ngữ. Các đóng góp cuối cùng cho mỗi ngôn ngữ trong Bộ Dữ liệu Aya không được phân phối đều giữa các chú thích viên. Số trung vị của chú thích viên cho mỗi ngôn ngữ là 15 (trung bình là 24,75) với một ngôn ngữ chỉ có một chú thích viên tích cực duy nhất (Sindhi) và

một số có hơn 80 chú thích viên (tiếng Anh và tiếng Bồ Đào Nha). Lưu ý rằng các chú thích viên đóng góp với tốc độ khác nhau, và không có mối tương quan trực tiếp giữa số lượng chú thích viên và số lượng đóng góp ngôn ngữ cuối cùng. Một nhóm chú thích viên hạn chế cho một số ngôn ngữ ngụ ý rằng hầu hết các trường hợp trong ngôn ngữ đó có nguồn gốc từ một nhóm cá nhân nhỏ hơn. Hình 10 (dưới) minh họa tỷ lệ các trường hợp trong một ngôn ngữ có nguồn gốc từ các chú thích viên tích cực nhất. Chúng tôi quan sát một mẫu thiên lệch nơi đối với 12 ngôn ngữ, 5 chú thích viên tích cực nhất đóng góp tất cả các ví dụ. Có một phân phối không đều của các đóng góp cho nhiều ngôn ngữ vì những ngôn ngữ đó có một số lượng nhỏ hơn các chú thích viên tự nguyện trong suốt toàn bộ dự án mặc dù có tiếp cận mạnh mẽ. Ngoài ra, chúng tôi không thiết lập một hạn ngạch cụ thể cho các chú thích viên đạt được; mọi người đóng góp như họ mong muốn, dẫn đến các mức độ hoạt động khác nhau giữa các chú thích viên.

Các trường hợp cực đoan nhất là Zulu và Sindhi, nơi một chú thích viên trong mỗi ngôn ngữ tình nguyện cho tất cả các đóng góp trong các nhiệm vụ Chú thích và Chú thích Lại. Do đó, trong Hình 10 tỷ lệ cộng tác viên top-1 của họ là 1,0 và không thay đổi khi chuyển sang top-2 hoặc xa hơn. Các ngôn ngữ có phân phối ít thiên lệch nhất là Malagasy, Tamil, Nepali, Hindi, tiếng Anh và tiếng Bồ Đào Nha. Ngôn ngữ tiếng Anh cũng có số lượng chú thích viên duy nhất cao nhất với 130 cá nhân trong đó 95 chú thích viên đóng góp vào tiếng Anh như ngôn ngữ thứ hai của họ cho mục đích chú thích. Cho phân phối không đều của các chú thích viên cho mỗi ngôn ngữ, điều quan trọng là thừa nhận rằng chất lượng chú thích viên cá nhân có ảnh hưởng không cân xứng đến một số ngôn ngữ.

3.4 Tác động của việc giới thiệu Điểm số Aya

Như một phần của nỗ lực chú thích hợp tác trong Aya, chúng tôi nhấn mạnh tầm quan trọng của chất lượng cũng như các hoàn thành dài chứa các phản hồi rõ ràng đến các hướng dẫn được chỉ định trong lời nhắc trong dự án. Để khuyến khích các ví dụ chất lượng cao từ các chú thích viên, chúng tôi đã giới thiệu Điểm số Aya (Phần B.2) ở giữa chừng dự án để tập trung vào chất lượng, ngoài số lượng, của các đóng góp.

Điểm số Aya khuyến khích người tham gia kết hợp thêm chỉnh sửa trong quá trình chú thích, với một hướng dẫn cụ thể thúc giục họ chuyển đổi các câu trả lời ngắn thành các câu hoặc đoạn văn đầy đủ. Hình 11 (phải) cho thấy sự thay đổi trong độ dài hoàn thành theo thời gian. Chúng tôi quan sát rằng sau khi giới thiệu điểm số Aya, có một sự tăng đáng kể trong độ dài hoàn thành của tất cả các chú thích được gửi.

4 Bộ Sưu tập Aya

Chúng tôi giới thiệu Bộ Sưu tập Aya, một bộ dữ liệu toàn diện, lớn có thể được sử dụng bởi các nhà nghiên cứu trên khắp thế giới để đào tạo các mô hình đa ngôn ngữ. Mục tiêu của chúng tôi chỉ là bao gồm các bộ dữ liệu với giấy phép cho phép cho thao tác và phân phối lại.12 Khi có thể, chúng tôi báo cáo giấy phép liên quan đến mỗi bộ dữ liệu trong Bộ Sưu tập Aya.

Bộ Sưu tập Aya bao gồm ba nguồn dữ liệu khác nhau:

1. Dữ liệu được mẫu hóa: Chúng tôi hợp tác với những người nói thành thạo để tạo ra các mẫu cho phép mở rộng tự động các bộ dữ liệu hiện có thành nhiều ngôn ngữ khác nhau.

2. Dữ liệu được dịch: Chúng tôi dịch một tập con được chọn thủ công gồm 19 bộ dữ liệu sang 101 ngôn ngữ (114 phương ngữ) sử dụng mô hình dịch máy NLLB 3.3B tham số [NLLB-Team et al., 2022]. Danh sách đầy đủ các bộ dữ liệu được dịch được liệt kê trong Phụ lục Bảng 9.

3. Bộ Dữ liệu Aya: Chúng tôi phát hành Bộ Dữ liệu Aya được mô tả trong Phần 3 như một tập con của bộ sưu tập tổng thể. Đây là bộ dữ liệu duy nhất trong bộ sưu tập được chú thích hoàn toàn bởi con người.

Tiêu chí Lựa chọn Bộ dữ liệu Các bộ dữ liệu được mẫu hóa và được dịch trong Bộ Sưu tập Aya được chọn lọc thủ công để đạt được sự pha trộn của các loại nhiệm vụ khác nhau. Tiêu chí của chúng tôi ưu tiên các bộ dữ liệu với các câu tự nhiên và hoàn chỉnh chất lượng cao, phù hợp để tạo ra các cặp lời nhắc và hoàn thành. Các bộ dữ liệu có thể tạo ra các câu trả lời một từ đã được loại trừ một cách có chủ ý. Cuối cùng, để

12https://en.wikipedia.org/wiki/Permissive_software_license

tạo ra một bộ sưu tập chất lượng cao, chúng tôi đã xem xét tất cả các bộ dữ liệu và loại trừ những bộ được xác định là không sạch hoặc nhiễu, chủ yếu có thể quy cho các quy trình tạo tự động của chúng.

4.1 Tạo mẫu Các Bộ dữ liệu Hiện có

Chúng tôi khám phá việc mở rộng tự động các bộ dữ liệu hiện có trong nhiều ngôn ngữ khác nhau với các mẫu lời nhắc được con người viết, theo các công việc trước đây [Mishra et al., 2022; Bach et al., 2022; Wei et al., 2022a; Wang et al., 2022e]. Không giống như các công việc trước đây vẫn sử dụng các lời nhắc tiếng Anh trong một bộ dữ liệu đa ngôn ngữ hoặc dựa vào dịch tự động để tạo ra các lời nhắc đa ngôn ngữ, theo hiểu biết của chúng tôi, Bộ Sưu tập Aya là nỗ lực rộng lớn đầu tiên liên quan đến những người nói thành thạo trong việc tạo ra các lời nhắc độc đáo cho ngôn ngữ của họ để mở rộng các bộ dữ liệu hiện có cho tinh chỉnh hướng dẫn.

Chúng tôi sử dụng khung PromptSource [Bach et al., 2022] để tạo mẫu cho các bộ dữ liệu này. Chúng tôi yêu cầu các thành viên cộng đồng Aya gửi hướng dẫn và tạo ra các mẫu cho các bộ dữ liệu bằng các ngôn ngữ mà họ thành thạo. Quy trình của chúng tôi bao gồm: 1) Tạo mẫu các bộ dữ liệu với hướng dẫn bằng cùng ngôn ngữ với bộ dữ liệu gốc; 2) Nếu bộ dữ liệu không bằng tiếng Anh, chú thích hướng dẫn bằng tiếng Anh. Các lời nhắc đầu vào của chúng tôi có thể là đơn ngôn ngữ hoặc trộn mã, tùy thuộc vào việc chúng tôi áp dụng các mẫu bằng cùng ngôn ngữ hay bằng tiếng Anh cho bộ dữ liệu của một ngôn ngữ cụ thể. Lưu ý rằng các lời nhắc đầu vào trộn mã ở đây đề cập đến sự pha trộn có cấu trúc của các hướng dẫn tiếng Anh với dữ liệu đơn ngôn ngữ không phải tiếng Anh [Lin et al., 2022], khác với định nghĩa ngôn ngữ học xã hội điển hình của việc trộn mã (hoặc chuyển mã) của các ngôn ngữ trong các phát ngôn hội thoại tự nhiên [Winata et al., 2023a; Yong et al., 2023c; Doğruöz et al., 2023; Srivastava & Singh, 2021].

Chúng tôi đã xem xét các mẫu đề xuất và sau đó chuyển đổi mỗi bộ dữ liệu thành định dạng kiểu hướng dẫn. Chúng tôi phát hành các bộ dữ liệu này dưới Bộ Sưu tập Aya. Chúng tôi liệt kê chi tiết của tất cả các bộ dữ liệu mà chúng tôi áp dụng các mẫu trong Phụ lục Bảng 8.

4.2 Dịch Tự động

Nghiên cứu đã chứng minh rằng việc đào tạo các mô hình với dữ liệu được dịch có thể mang lại lợi ích đáng kể [Aharoni et al., 2019; Zhang et al., 2018b; Tang et al., 2021]. Chúng tôi thử nghiệm cải thiện phạm vi bao phủ của các ngôn ngữ ít tài nguyên bằng cách dịch chọn lọc các bộ dữ liệu chất lượng cao từ nhiều bộ sưu tập hiện có.

Thiết lập Chúng tôi chọn lọc 19 bộ dữ liệu IFT chất lượng cao từ xP3 [Muennighoff et al., 2023c], Bộ Sưu tập Flan [Longpre et al., 2023a], Dolly [Conover et al., 2023], cùng với các nguồn bổ sung như SODA [Kim et al., 2022] và Mintaka [Sen et al., 2022]. Các bộ dữ liệu được ưu tiên để dịch dựa trên sự phong phú của tính đa dạng nhiệm vụ và độ dài của hoàn thành. Danh sách đầy đủ của các bộ dữ liệu này được đưa ra trong Phụ lục 9. Những bản dịch này có sẵn và mã nguồn mở như một phần của Bộ Sưu tập Aya. Chúng tôi xử lý các bộ dữ liệu để dịch sử dụng mô hình dịch máy No Language Left Behind (NLLB) [NLLB-Team et al., 2022], có khả năng dịch câu đơn giữa 200 ngôn ngữ và phương ngữ khác nhau trong nhiều chữ viết khác nhau. Để có hiệu suất tốt nhất, chúng tôi sử dụng mô hình NLLB lớn nhất với 3,3B tham số.

Chất lượng Dịch Phần G.1 của Phụ lục liệt kê chất lượng dịch NLLB cho mỗi ngôn ngữ quan tâm, như được báo cáo trong [NLLB-Team et al., 2022]. Hình 13 cho thấy chất lượng dịch qua các ngôn ngữ được nhóm theo mức độ tài nguyên của chúng. Điểm ChrF++ trung bình trên FLORES là 48,17 (tối thiểu: 10,9, tối đa: 69,6) cho các bản dịch từ tiếng Anh, với một vài giá trị ngoại lai cho HR và LR. Chúng tôi diễn giải điều này một cách lạc quan là đủ mạnh để phục vụ đầy đủ nhu cầu dịch của chúng tôi. Tuy nhiên, khi kiểm tra đầu ra dịch cho dữ liệu tinh chỉnh, chúng tôi gặp lỗi dịch đáng kể với tiếng Ả Rập Chuẩn trong chữ viết Latinh và Minangkabau trong chữ viết Ả Rập, vì vậy chúng tôi loại trừ chúng khỏi bộ dữ liệu được dịch của chúng tôi. Tổng cộng, 19 bộ dữ liệu công cộng được dịch sang 101 ngôn ngữ (114 phương ngữ). Chi tiết về các bộ dữ liệu này có thể tìm thấy trong Phụ lục Bảng 9.

Ngoài việc phát hành các bộ dữ liệu được dịch được sử dụng như cơ sở cho chú thích lại, chúng tôi cũng dịch Dolly [Conover et al., 2023]. Dolly là một bộ dữ liệu hướng dẫn 15k mà Databricks thu thập bằng cách dựa vào nhân viên của họ như các chú thích viên [Conover et al., 2023]. Các chú thích viên được hướng dẫn tuyển chọn các cặp lời nhắc và hoàn thành trong mỗi tám danh mục hướng dẫn khác nhau. Trái ngược với các bộ dữ liệu NLP được đề cập, Dolly được thiết kế có mục đích để căn chỉnh các mô hình ngôn ngữ với kỳ vọng của con người. Nó nổi bật như một bộ dữ liệu được tuyển chọn thủ công chất lượng cao bao gồm một loạt các chủ đề bao gồm brainstorming, phân loại, trả lời câu hỏi đóng, tạo ra, trích xuất thông tin, trả lời câu hỏi mở, và tóm tắt. Việc bổ sung các bộ dữ liệu Dolly được dịch là một tài nguyên có giá trị cho các ngôn ngữ gặp khan hiếm các bộ dữ liệu tinh chỉnh hướng dẫn hội thoại.

Danh sách các bộ dữ liệu, cùng với số lượng ngôn ngữ, mẫu, và các thống kê khác, có thể tìm thấy trong Phụ lục Bảng 9.

5 Phân tích Bộ Sưu tập Aya

5.1 Thống kê

Tổng quan Bộ Sưu tập Aya bao gồm các bộ dữ liệu NLP hiện có được mẫu hóa để bao gồm hướng dẫn cũng như các bộ dữ liệu đã ở định dạng hướng dẫn được gửi bởi cộng đồng Aya. Bảng 8 cho thấy danh sách chi tiết các bộ dữ liệu. Danh sách đầy đủ các mẫu có sẵn trong Phần K. Bộ Sưu tập Aya cuối cùng bao gồm 44 bộ dữ liệu được mẫu hóa đa ngôn ngữ và không phải tiếng Anh và 19 bộ dữ liệu được dịch, với 513M trường hợp cá nhân. Tổng thể, bộ sưu tập bao gồm 114 ngôn ngữ13.

Nhiệm vụ Được Bao gồm Qua Các Bộ dữ liệu Được Mẫu hóa và Được Dịch Chúng tôi nhắm đến việc bao gồm các bộ dữ liệu từ nhiều nhiệm vụ khác nhau trong bộ sưu tập trong khi đảm bảo rằng chúng tuân theo tiêu chí lựa chọn của chúng tôi. Bảng 4 minh họa phạm vi nhiệm vụ của chúng tôi trong Bộ Sưu tập Aya, lấy cảm hứng từ xP3 và Bộ Sưu tập Flan. Chúng tôi có tổng cộng ba loại nhiệm vụ chính: Trả lời Câu hỏi (QA), Tạo ra Ngôn ngữ Tự nhiên (NLG), và Phân loại Văn bản (TC). Trong những nhiệm vụ dù rộng lớn hơn này, chúng tôi định nghĩa một số loại nhiệm vụ tinh tế hơn dựa trên các bộ dữ liệu, dẫn đến tổng cộng 11 loại nhiệm vụ tinh tế. Những loại nhiệm vụ tinh tế này được xác định bởi tần suất của các bộ dữ liệu trong Bộ Sưu tập Aya bao gồm nhiệm vụ đó.

Đối với QA, chúng tôi quyết định chỉ giữ loại nhiệm vụ chính, vì mục tiêu dự định của các nhiệm vụ trả lời câu hỏi là rõ ràng: Trả lời một câu hỏi được đề xuất. Loại câu hỏi có thể khác nhau: mở, đóng, lựa chọn nhiều, phản hồi đơn. Đối với NLG, các loại nhiệm vụ tinh tế bao gồm Tóm tắt, Dịch, Diễn giải lại, Hội thoại (Tạo ra), và Đơn giản hóa Văn bản. Đối với TC, chúng tôi bao gồm các loại nhiệm vụ tinh tế sau: Phân tích Cảm xúc, Trích xuất Thông tin, Nhận dạng Thực thể Có tên, Liên kết Sự kiện, Suy luận Ngôn ngữ Tự nhiên, và Đại diện Tài liệu Khoa học. Cuối cùng, chúng tôi gắn nhãn các danh mục nhiệm vụ của mỗi bộ dữ liệu trong Bộ Sưu tập Aya trong Bảng 10 và Bảng 11. Nếu chúng tôi không thể tìm thấy loại nhiệm vụ tinh tế cho bộ dữ liệu, chúng tôi giữ loại nhiệm vụ chính.

13Chúng tôi phát hành Bộ Dữ liệu Aya như một phần của Bộ Sưu tập Aya, mang tổng số ngôn ngữ trong bộ sưu tập lên 115. Tuy nhiên, vì mục đích rõ ràng, khi tham chiếu đến thống kê Bộ Sưu tập Aya trong bài báo này, chúng tôi loại trừ Bộ Dữ liệu Aya.

Cân bằng Ngôn ngữ Một trong những mục tiêu của việc tạo mẫu (và dịch) các bộ dữ liệu hiện có là mở rộng các tài nguyên có sẵn cho các ngôn ngữ có dữ liệu kỹ thuật số hạn chế. Để xem xét liệu bộ sưu tập cuối cùng của chúng tôi có tuân theo một mẫu phân phối tương tự hay không, chúng tôi sử dụng số lượng trang Wikipedia trong mỗi ngôn ngữ như một đại diện cho sự hiện diện trực tuyến của những người nói thành thạo nó. Hình 14 thể hiện rằng mặc dù số lượng trường hợp cho các ngôn ngữ thay đổi trong Bộ Sưu tập Aya (tập con được mẫu hóa), nó không thiệt thòi các ngôn ngữ với ít trang Wikipedia hơn. Phân phối vẫn đảm bảo một phạm vi bao phủ hợp lý qua tất cả các ngôn ngữ. Điều cần thiết là nhấn mạnh rằng phân tích của chúng tôi không liên quan đến một so sánh trực tiếp của các giá trị tuyệt đối, cho các đơn vị đo lường khác nhau liên quan. Thay vào đó, chúng tôi xem xét các mẫu của sự khan hiếm dữ liệu cho các ngôn ngữ khác nhau trong bộ sưu tập của chúng tôi so với Wikipedia. Bao gồm các bộ dữ liệu được dịch trong Bộ Sưu tập Aya tiếp tục giảm sự chênh lệch giữa các ngôn ngữ và đóng góp vào việc tạo ra một bộ sưu tập cân bằng hơn.

Độ dài Lời nhắc và Hoàn thành Hình 15 cho thấy phân phối độ dài qua các ngôn ngữ. Không có mẫu có thể nhận biết được quan sát khi xem xét độ dài cho các ngôn ngữ tài nguyên cao so với các ngôn ngữ tài nguyên thấp. Các ngôn ngữ tài nguyên thấp xuất hiện ở cả hai đầu của phân phối, chiếm cả đầu và đuôi. Trong Bộ Sưu tập Aya một số ngôn ngữ tài nguyên thấp (ví dụ, Somali và Amharic) có độ dài hoàn thành trung bình dài hơn các ngôn ngữ tài nguyên trung bình hoặc thậm chí cao. Sự cống hiến của các người tham gia cá nhân trong việc xác định các bộ dữ liệu bằng ngôn ngữ riêng của họ và tạo mẫu cho chúng đã tạo ra sự khác biệt đáng kể cho nhiều ngôn ngữ.

5.2 Đánh giá Chất lượng của Tất cả Các Nguồn Dữ liệu Khác nhau

Như đã nêu trước đây, phản hồi nhị phân về chất lượng của các cặp lời nhắc-hoàn thành đã được thu thập từ các chú thích viên. Chúng tôi định nghĩa tỷ lệ chấp thuận trung bình cho mỗi bộ dữ liệu phục vụ như một thước đo có giá trị để đánh giá chất lượng của các bộ dữ liệu qua nhiều ngôn ngữ và nguồn dữ liệu đa dạng. Chúng tôi tính tỷ lệ chấp thuận trung bình là T+/T, nơi T+ đại diện cho tổng số thumbs up, và T đại diện cho tổng số phiếu bầu cho mỗi bộ dữ liệu. Một tỷ lệ chấp thuận trung bình 1,0 sẽ chỉ ra rằng mọi chú thích được nhận thức là có chất lượng tốt và tất cả các lời nhắc và hoàn thành đã nhận được thumbs up. Một tỷ lệ chấp thuận trung bình 0,0 sẽ chỉ ra rằng mọi chú thích được nhận thức là có chất lượng kém, và tất cả các lời nhắc và hoàn thành đã nhận được thumbs down.

Chúng tôi hạn chế phân tích chất lượng của mình đến 40 bộ dữ liệu trong nhóm của chúng tôi mà chúng tôi có ít nhất 20 trường hợp phản hồi.

Tổng thể, chúng tôi quan sát rằng phần lớn các bộ dữ liệu có chất lượng trên trung bình (0,5) dựa trên tỷ lệ chấp thuận của chúng, với tất cả dữ liệu được dịch cũng như Chú thích Gốc đều trên trung bình. Tuy nhiên, qua tất cả các bộ dữ liệu trong mỗi nhóm —xP3, Được Mẫu hóa, Được Dịch, và chú thích gốc Aya— chú thích gốc Aya được nhận thức là có chất lượng cao nhất, với tỷ lệ chấp thuận trung bình khoảng 0,81, so với bộ dữ liệu chất lượng thấp nhất, xP3, có tỷ lệ chấp thuận trung bình khoảng 0,50. Điều này phù hợp với trực giác của chúng tôi rằng các bộ dữ liệu được tuyển chọn cẩn thận dẫn đến các chú thích chất lượng cao như được nhận thức bởi các chú thích viên con người. Hình 16 cung cấp tóm tắt kết quả cho mỗi nhóm. Hình 23 trong Phụ lục cung cấp tỷ lệ chấp thuận cho mỗi bộ dữ liệu trong mỗi nhóm.

6 Bộ Đánh giá Aya

Cuối cùng, như một phần của dự án Aya chúng tôi tuyển chọn và phát hành một bộ đánh giá được thiết kế riêng cho các mô hình đa ngôn ngữ. Tập hợp này là một đóng góp có giá trị trong việc giải quyết sự khan hiếm dữ liệu đa ngôn ngữ, một thách thức trở nên rõ ràng hơn khi xem xét các tập đánh giá. Mặc dù có một số tập thử nghiệm có sẵn để đánh giá các mô hình đa ngôn ngữ [Conneau et al., 2018; Ponti et al., 2020; Lin et al., 2022], chúng tập trung chủ yếu vào các nhiệm vụ phân biệt. Để đánh giá các thế hệ của mô hình đa ngôn ngữ, tài liệu bao gồm các tập đánh giá dành cho nhiệm vụ cụ thể như Dịch [Goyal et al., 2021b], Tóm tắt [Hasan et al., 2021] và Trả lời Câu hỏi [Clark et al., 2020]. Tuy nhiên hiện tại có một khoảng trống trong việc đánh giá khả năng tạo ra miền mở của LLM trong một bối cảnh đa ngôn ngữ. Chúng tôi nhắm đến việc giải quyết khoảng trống này bằng cách tuyển chọn một tập đánh giá đa ngôn ngữ được thiết kế riêng để đánh giá khả năng tạo ra miền mở của LLM, như brainstorming, lập kế hoạch, và các phản hồi không có cấu trúc, dài khác.

Để tạo ra sự cân bằng giữa phạm vi bao phủ ngôn ngữ và chất lượng đi kèm với sự chú ý của con người, chúng tôi tạo ra một bộ đánh giá bao gồm (1) các ví dụ được con người tuyển chọn trong một tập hợp ngôn ngữ hạn chế, (2) các bản dịch tự động của các ví dụ được chọn thủ công vào một số lượng ngôn ngữ rộng lớn hơn, và (3) các bản dịch được con người chỉnh sửa sau vào một số lượng nhỏ ngôn ngữ. Chúng tôi xem xét hai nguồn dữ liệu chính: các chú thích gốc từ bộ dữ liệu Aya (bao gồm các ví dụ mới được tuyển chọn văn hóa cho các ngôn ngữ khác nhau) và các lời nhắc Dolly (các ví dụ được con người viết chất lượng cao được chọn cẩn thận để có tầm với phổ quát). Các tập con bao gồm bộ đánh giá Aya là:

tập thử nghiệm được chú thích bởi con người aya Để dễ dàng áp dụng trong tương lai, chúng tôi đã phân chia Bộ dữ liệu Aya thành các phần đào tạo và thử nghiệm. Tập thử nghiệm của Bộ Dữ liệu Aya chứa 1.750 trong tổng số trường hợp (250 trường hợp từ 7 ngôn ngữ), được chọn ngẫu nhiên từ các chú thích gốc. Mục tiêu của chúng tôi là đạt được một đại diện cân bằng của các ngôn ngữ trong tập thử nghiệm và đảm bảo một số lượng đủ ví dụ cho mỗi ngôn ngữ. Để đảm bảo đủ dữ liệu còn lại cho đào tạo, chúng tôi tập trung vào các ngôn ngữ có ít nhất 2000 chú thích gốc. Để đảm bảo tính đa dạng ngôn ngữ, chúng tôi bao gồm các ngôn ngữ đa dạng về mặt tài nguyên cao, trung bình, hoặc thấp, cũng như chữ viết và họ ngôn ngữ. Vì những lý do đó, tập thử nghiệm bao gồm tiếng Anh (tài nguyên cao, chữ viết Latinh, Ấn-Âu), tiếng Bồ Đào Nha (tài nguyên trung bình, chữ viết Latinh, Ấn-Âu), tiếng Trung Giản thể

(tài nguyên cao, chữ viết Hán, Hán-Tạng), tiếng Ả Rập Chuẩn (tài nguyên cao, chữ viết Ả Rập, Afro-Á), Telugu (tài nguyên thấp, chữ viết Telugu, Dravidia), Thổ Nhĩ Kỳ (tài nguyên trung bình, chữ viết Latinh, Turkic), và Yoruba (tài nguyên thấp, chữ viết Latinh, Atlantic-Congo). Xem Bảng 5 để biết thêm chi tiết.

tập thử nghiệm được dịch máy dolly Chúng tôi tách một tập con được tuyển chọn gồm 200 lời nhắc Dolly [Conover et al., 2023] để phục vụ như một tập đánh giá được dịch bổ sung. Mục tiêu của chúng tôi với việc lựa chọn này là loại trừ bất kỳ lời nhắc và hoàn thành nào dành riêng cho văn hóa hoặc địa lý. Do đó, hai người đánh giá đã kiểm tra một tập hợp ban đầu 500 lời nhắc tiếng Anh được lấy mẫu đồng nhất dựa trên các danh mục nhiệm vụ trong Dolly. Các người đánh giá loại trừ các lời nhắc dựa trên kiến thức địa lý như "Nhìn vào các thành phố ở Úc ở bờ biển phía đông và bờ biển phía tây của đất nước, bờ biển nào là các thành phố Fremantle, Sydney, Brisbane, Perth, Cairns, Townsville, Newcastle nằm trên?", hoặc các lời nhắc như "Tại sao bóng đá NFL được gọi là bóng đá khi người chơi chủ yếu sử dụng tay?" dựa trên các tham chiếu văn hóa quá cụ thể. Khi hai người đánh giá không đồng ý, một người đánh giá thứ ba được yêu cầu phá vỡ sự bế tắc. Chúng tôi giữ các lời nhắc như "Nghệ thuật có vô dụng không?" hoặc "Viết một đoạn văn ngắn về lý do bạn không nên có cả thú cưng mèo và thú cưng chim." và các câu hỏi đề cập đến kiến thức địa lý cụ thể nơi bằng chứng hỗ trợ được cung cấp trong chính lời nhắc ví dụ, "Cho một văn bản tham chiếu về Bộ trưởng Thực phẩm, Nông nghiệp và Thủy sản của Đan Mạch, vị trí này được tạo ra khi nào và được đặt tên như thế nào?". Mặc dù không hoàn hảo, ý định đằng sau việc lựa chọn này là thu thập một tập thử nghiệm cho phép chúng tôi đánh giá tính lưu loát và chất lượng của các phản hồi trong nhiều ngôn ngữ khác nhau trong khi tránh đánh giá mô hình trên các lời nhắc gắn liền với các tham chiếu văn hóa hoặc địa lý cụ thể có thể có hiệu lực phụ thuộc vào ngôn ngữ. Chúng tôi tự động dịch các lời nhắc với NLLB sang 101 ngôn ngữ và các phương ngữ của chúng được NLLB nắm bắt. Bao gồm các lời nhắc tiếng Anh gốc, bộ dữ liệu này bao gồm 115 phương ngữ.

tập thử nghiệm được chỉnh sửa bởi con người dolly Quá trình dịch tự động có thể đưa ra lỗi trong các lời nhắc khiến chúng trở nên vô nghĩa. Ví dụ, lời nhắc "Loài cá nào? Bleak hay Weary" yêu cầu kiến thức chuyên môn để chọn bản dịch đúng của tên cá thay vì bản dịch theo nghĩa đen của các tính từ (như ví dụ trong bản dịch NLLB sang tiếng Tây Ban Nha: "Desanimado o cansado." (="nản lòng hoặc mệt mỏi")). Nếu lời nhắc không có ý nghĩa gì, không có kỳ vọng rõ ràng và đo lường về một hoàn thành tốt và đúng sẽ trông như thế nào. Để diễn giải một cách tự tin kết quả đánh giá, điều cần thiết là thiết lập một tập hợp đáng tin cậy các lời nhắc để đánh giá. Để tăng cường độ tin cậy của việc thử nghiệm trên các lời nhắc này, do đó chúng tôi đăng ký các chú thích viên con người chuyên nghiệp để chỉnh sửa sau các ví dụ (ví dụ cho ví dụ trên "Alburno o Cansado" (="[Tên cá] hoặc Mệt mỏi")). Chúng tôi chỉnh sửa sau các lời nhắc cho một tập con gồm sáu ngôn ngữ: Ả Rập, Hindi, Tây Ban Nha, Pháp, Serbia và Nga. Phụ lục F mô tả quá trình chỉnh sửa sau và nỗ lực chi tiết hơn. Ví dụ trên minh họa rằng một số lời nhắc, ngay cả khi được dịch đúng, vẫn có thể không chuyển đổi tốt sang các ngôn ngữ khác—đó là sự khác biệt chính giữa một tập dịch lấy tiếng Anh làm trung tâm như thế này và một tập đánh giá được viết gốc trong mỗi ngôn ngữ đích như aya-human-annotated.

Chúng tôi mở mã nguồn tập thử nghiệm dolly-machine-translated để là một tài nguyên bổ sung cho các nhà nghiên cứu, mặc dù cảnh báo rằng tính biểu đạt của một tập đánh giá được dịch bị hạn chế bởi chất lượng của mô hình dịch (và chỉnh sửa sau của con người) và có thể ảnh hưởng bất lợi đến ước tính khả năng trong các ngôn ngữ nơi các bản dịch không đầy đủ [Nogara et al., 2023]. Cuối cùng, đây là một sự thỏa hiệp giữa việc có phạm vi đánh giá trong một tập hợp ngôn ngữ hoàn chỉnh hơn (101 ngôn ngữ và 114 phương ngữ tổng cộng) so với việc có các tập đánh giá được chú thích bởi con người. Nếu sử dụng tập thử nghiệm được dịch tự động, chúng tôi khuyến nghị nó được ghép đôi và báo cáo với dolly-human-edited được chỉnh sửa chuyên nghiệp cho 6 ngôn ngữ, hoặc tập aya-human-annotated cũng chỉ bao gồm 7 ngôn ngữ nhưng được tạo hoàn toàn bởi những người nói thành thạo ngôn ngữ đích.

7 Một Phương pháp Nghiên cứu Tham gia

Những đột phá gần đây trong NLP chủ yếu đến từ các hợp tác hẹp liên quan đến các nhà nghiên cứu từ một số ít tổ chức và khu vực trên thế giới [Nakamura et al., 2023]. Sự phụ thuộc vào các mạng lưới hợp tác nhỏ, chuyên biệt này đã được chỉ ra cản trở sự đổi mới [Park et al., 2023]. Tạo ra bộ dữ liệu như một quá trình thường bị đánh giá thấp, với việc giảm thiểu giá trị của các đóng góp của người tạo [Andress et al., 2020; Peng et al., 2021; Hanley et al., 2020]. Dưới những điều kiện như vậy, sự phong phú và đa dạng của dữ liệu thường bị thỏa hiệp, vì nó phản ánh một quan điểm hạn chế phù hợp với lợi ích của những người có quyền lực lớn hơn trong những giao dịch này.

Dữ liệu không phải, như các ẩn dụ như 'khai thác dữ liệu' [Puschmann & Burgess, 2014], hoặc 'dữ liệu là dầu mới' [Stark & Hoffmann, 2019; Awati & Shum, 2015], có thể gợi ý, một tài nguyên tự nhiên chờ đợi được khai thác. Bất cứ khi nào chúng ta tương tác với dữ liệu, chúng ta cũng đang tương tác với các kết nối mà dữ liệu có với những người tạo ra, chuẩn bị, và phân phối nó [Seaver, 2021; Pinel C, 2020; Crawford, 2021]. Các phương pháp tham gia trong thiết kế và nghiên cứu AI là một cách để giải quyết những khoảng trống trong việc tiếp cận các tài nguyên cần thiết cho nghiên cứu: thông qua các quan hệ đối tác hợp tác với những người nói ngôn ngữ và các cộng đồng địa phương.

Aya là một ví dụ về một dự án nghiên cứu tham gia [Birhane et al., 2022; Corbett et al., 2023; Delgado et al., 2023]. Ở đây, nghiên cứu là kết quả của một hợp tác đa tổ chức, toàn cầu rộng lớn. Loại công việc đa chiều này tạo điều kiện cho việc thu thập dữ liệu ngôn ngữ quan trọng và sự tham gia của cộng đồng, điều quan trọng để phát triển các công nghệ ngôn ngữ hiệu quả [Joshi et al., 2019; ∀et al., 2020]. Chúng tôi mô tả dưới đây một số nguyên tắc hướng dẫn mà chúng tôi đã tuân theo trong suốt dự án Aya kéo dài một năm.

Quyền sở hữu và Tăng trưởng Linh hoạt Khung khoa học mở của chúng tôi cho phép chúng tôi thách thức các chuẩn mực về cách khoa học máy tính thường tiến hành [Wittenburg, 2021; Sabou et al., 2012]. Các phương pháp nghiên cứu truyền thống thường liên quan đến các hệ thống phân cấp cứng nhắc; thông thường, nghiên cứu được tiến hành trong các tổ chức học thuật hoặc phòng thí nghiệm công ty nơi các vai trò được định nghĩa rõ ràng, và hợp tác chủ yếu là đồng bộ, dựa vào các cuộc họp trực tiếp hoặc giao tiếp thời gian thực. Ngược lại, Aya thực hiện một phương pháp phi tập trung và dân chủ đối với hợp tác, hỗ trợ lãnh đạo linh hoạt và việc chấp nhận vai trò linh hoạt. Điều này trao quyền cho các thành viên chủ động và dẫn dắt trong các lĩnh vực mà họ có đam mê hoặc chuyên môn, bất kể vị trí của họ trong học thuật, hoặc khi họ tham gia vào dự án. Ví dụ, các thành viên trở thành Đại sứ Ngôn ngữ tại nhiều thời điểm khác nhau trong dự án kéo dài một năm, và các vai trò cố vấn phát triển tự nhiên với các nhà nghiên cứu kinh nghiệm hơn cung cấp hướng dẫn cho những người thiếu kinh nghiệm hơn (xem Phụ lục C để biết thêm chi tiết về các vai trò khác nhau trong dự án).

Cấu trúc Tổ chức Các kênh giao tiếp và cấu trúc tổ chức của Aya được thiết kế để tạo điều kiện cho hợp tác phong phú có thể phát triển với sở thích của các nhà nghiên cứu tham gia trong dự án kéo dài một năm. Ví dụ, hầu hết giao tiếp giữa các nhà nghiên cứu độc lập liên quan trong Aya là không đồng bộ qua Discord, cho phép các nhà nghiên cứu ở các múi giờ khác nhau tham gia vào các cuộc thảo luận. Các cuộc họp hàng tháng mở cho bất kỳ ai tham dự và được ghi lại để xem không đồng bộ. Chúng tôi mô tả cấu trúc của các cuộc họp và giao tiếp kỹ lưỡng hơn trong Phụ lục D.1 và D.2.

Đưa vào và Tiếp cận Bản chất mở của AyaUI cho phép chúng tôi vượt qua các cơ chế gác cổng

của khoa học học thuật thường thiên thòi những người không nói tiếng Anh và những người không có thông tin đăng nhập học thuật chính thức [West et al., 2020]. Chuyên môn trong việc sử dụng một ngôn ngữ nói hoặc viết rõ ràng khác biệt với chuyên môn trong học máy. Việc bao gồm một loạt rộng lớn các tình nguyện viên như vậy đã cho chúng tôi dữ liệu đại diện hơn trong nhiều ngôn ngữ khác nhau và cũng cho các tình nguyện viên cái nhìn thoáng qua vào thế giới thường mờ ám của học máy.

Ai Đã Tham gia Aya Động lực của các cộng tác viên không dựa trên thù lao tài chính mà trên các lý tưởng về cộng đồng, bản sắc, và công lý xã hội. Người tham gia coi vai trò của họ như Đại sứ Ngôn ngữ và cộng tác viên là quan trọng để đảm bảo việc bao gồm các ngôn ngữ của họ trong quá trình chuyển đổi đang diễn ra sang một nền kinh tế kỹ thuật số, thông tin. Đại sứ Ngôn ngữ cho Malagasy, một ngôn ngữ bị đẩy đến nguy cơ tuyệt chủng bởi sự cai trị thuộc địa Pháp ở Madagascar [Spolsky, 2018], đang lên kế hoạch hackathons trong năm 2024 để sử dụng Bộ Dữ liệu Aya tạo ra các ứng dụng giọng nói thành văn bản sẽ giúp những người nói Malagasy không biết chữ tham gia vào nền kinh tế hiện đại. Trong Telugu, một thể loại thơ truyền thống được biết đến như Sathakam là một phần không thể thiếu của hệ thống giáo dục. Tuy nhiên, các chatbot có thể dịch văn bản sang Telugu có ít hoặc không hiểu biết gì về hình thức Sathakam. Đại sứ Ngôn ngữ Telugu nói với một tờ báo ở Toronto rằng "trong Aya, chúng tôi đảm bảo bao gồm càng nhiều Sathakam mà chúng tôi có thể tìm thấy" [Castaldo, 2023].

Những động lực này không phải là ngoại vi đối với sức mạnh của Bộ Dữ liệu Aya cuối cùng mà là những yếu tố chính trong nguồn gốc của dữ liệu [Loukissas, 2019]. Những chiều kích định tính này nhắc nhở chúng ta rằng ngôn ngữ, đối với những người sử dụng nó hàng ngày, là một hiện tượng gắn liền xã hội sâu sắc. Ngoài ký hiệu tượng trưng kết nối các token với các đối tượng tham chiếu trong thế giới thực, chúng ta tìm thấy một mạng lưới mạnh mẽ các mối quan hệ xã hội cần thiết cho các ngôn ngữ phát triển [Sidnell & Enfield, 2012; Goodwin, 2017; Agha, 2006]. Các tương tác xã hội giữa các cộng tác viên, nhà nghiên cứu ML, và nhà khoa học xã hội trong dự án Aya đã quan trọng đối với thành công của nó. Các cộng tác viên chia sẻ danh sách phát các bài hát yêu thích từ quê hương, công thức từ thời thơ ấu, và ảnh chụp nhanh cảnh quan từ văn phòng tại nhà của họ. Họ tranh luận về những sắc thái tinh tế về cách họ muốn ngôn ngữ của mình được đại diện trong bộ dữ liệu và phản đối một số giả định được đưa ra bởi các điều phối viên dự án về điều gì cấu thành một ngôn ngữ riêng biệt so với một phương ngữ khu vực (xem Phần 9). Hơn một cộng tác viên đã ngồi xuống với ông bà để đóng góp vào một ngôn ngữ trải rộng ba thế hệ sử dụng.

Thực tế của các điều kiện mà nhiều người làm việc và sống dưới đó có mặt mỗi ngày. Ví dụ, các cuộc họp Zoom bị cắt ngắn cho một số tình nguyện viên do mất điện ở quốc gia của họ hoặc thiếu tiếp cận kết nối internet ổn định. Burmese, một ngôn ngữ được nói ở Myanmar, bắt đầu mạnh mẽ trong dự án với một nhóm 35 tình nguyện viên có động lực nhưng thấy một sự tạm dừng đột ngột trong các đóng góp khi nội chiến bùng nổ ở đất nước dẫn đến sự rút lui của các tình nguyện viên khỏi dự án [Petty, 2023]. Đại sứ Ngôn ngữ cho Armenian cũng phải rời bỏ dự án vì một cuộc xung đột ở quốc gia đó [Reuters, 2023]. Ở một số quốc gia, dịch vụ bưu điện chỉ hoạt động một vài ngày mỗi tháng vì chiến tranh đang diễn ra, tạo ra thách thức cho các tổ chức viên khi gửi quà Aya để cảm ơn các tình nguyện viên tận tâm. Cuối cùng, các tổ chức viên không thể gửi quà để cảm ơn các tình nguyện viên đã tham gia từ Somalia, Yemen và Palestine. Đối với Somalia và Yemen, cả Canada Post, DHL và Fedex đều không thể hỗ trợ vận chuyển. Đối với Palestine, chi phí vận chuyển tỏ ra cấm đoán—với ước tính chi phí vận chuyển 294 đô la Mỹ cho mỗi áo phông. Những thực tế địa chính trị này định hình cả trải nghiệm của các cộng tác viên cũng như tiến trình của dự án.

Bao gồm những yếu tố này trong phân tích hậu kiểm của chúng tôi về dự án là quan trọng để hiểu cả động lực của những người sẵn sàng tình nguyện cho các dự án khoa học mở, và cũng để hiểu bản thân dữ liệu: độ rộng, nguồn gốc, thiếu sót, và lịch sử sống của nó.

8 Công trình Liên quan

8.1 Bộ dữ liệu đa ngôn ngữ

Các ngôn ngữ ít tài nguyên từ lâu đã là một thách thức trong NLP, với dữ liệu hạn chế ảnh hưởng đến hiệu suất nhiệm vụ [Kunchukuttan et al., 2021]. Để giải quyết điều này, các nhà nghiên cứu đã khám phá các kỹ thuật như tăng cường dữ liệu [Sennrich et al., 2016; Dhole et al., 2021], học chuyển giao [Zoph et al., 2016], lặp lại [Luukkonen et al., 2023; Muennighoff et al., 2023b], và các mô hình đa ngôn ngữ [Dabre et al., 2020; Muennighoff et al., 2023c; Yong et al., 2023b], đạt được kết quả hứa hẹn trong các lĩnh vực như dịch máy. Ở đây, chúng tôi tập trung vào những nỗ lực tập trung vào việc tạo ra bộ dữ liệu đa ngôn ngữ.

Một số công việc đã tạo ra các kho dữ liệu đa ngôn ngữ quy mô lớn. Những bộ này thường là văn bản không có cấu trúc, lý tưởng cho đào tạo trước không giám sát quy mô lớn [Abadji et al., 2021; Ortiz Su'arez et al., 2019; Scao et al., 2022a;b; Laurençon et al., 2022; Kudugunta et al., 2023; Whitehouse et al., 2023]. Một nhóm khác của các bộ dữ liệu đa ngôn ngữ tập trung vào dịch máy [Lucia Specia et al., 2010; Fan et al., 2021]. Chúng bao gồm các văn bản song song bằng hai hoặc nhiều ngôn ngữ, cho phép các mô hình học ánh xạ giữa chúng. Lý tưởng, các bộ dữ liệu dịch máy bao gồm các miền đa dạng và các cặp ngôn ngữ, từ những ngôn ngữ được nói phổ biến đến những ngôn ngữ khan hiếm tài nguyên, thúc đẩy tính bao gồm và đa dạng ngôn ngữ. Một trong những bộ sưu tập rộng lớn nhất của kho dữ liệu song song có sẵn tại trang web dự án OPUS14 [Tiedemann, 2012]. Các mô hình năng lực lớn cho hiểu ngôn ngữ có thể đạt được hiệu suất mạnh trên các ngôn ngữ tài nguyên cao trong khi cải thiện đáng kể các ngôn ngữ tài nguyên thấp [Goyal et al., 2021a]. Trong Whitehouse et al. [2023], hiệu quả của tăng cường dữ liệu được hỗ trợ bởi LLM trong lý luận thông thường đa ngôn ngữ đã được chứng minh. Hiệu suất cải thiện được hiển thị khi các mô hình đa ngôn ngữ nhỏ hơn được tinh chỉnh với dữ liệu được tạo ra bởi LLM. Một số bộ dữ liệu được phát hành gần đây tập trung vào các miền ngôn ngữ chuyên biệt như luật [Niklaus et al., 2023], giáo dục [Zhang et al., 2023c], hoặc chăm sóc sức khỏe [Wang et al., 2023].

Những kho dữ liệu này thường gặp vấn đề về chất lượng dữ liệu không đầy đủ và yêu cầu làm sạch rộng rãi [Abadji et al., 2022; Kreutzer et al., 2022]. Các bộ dữ liệu dành cho nhiệm vụ cụ thể, như XCOPA [Ponti et al., 2020] hoặc XNLI [Conneau et al., 2018], có quy mô nhỏ hơn nhưng cung cấp dữ liệu chất lượng cao hướng đến một khả năng mô hình cụ thể như hiểu và học chuyển giao đa ngôn ngữ. Loại dữ liệu này rất quan trọng để đánh giá và tăng cường hiệu suất của các mô hình trong các bối cảnh ngôn ngữ đa dạng.

No Language Left Behind [NLLB-Team et al., 2022] mã nguồn mở bitext, bitext được khai thác, và dữ liệu được tạo ra sử dụng back-translation trong 200+ ngôn ngữ cụ thể cho dịch văn bản thành văn bản. Trong khi Seamless4MT [Barrault et al., 2023] phát hành siêu dữ liệu của SeamlessAlign, một bộ dữ liệu dịch đa phương thức mở, có tương đối ít công việc hơn cho việc tạo ra/tuyển chọn dữ liệu trong các ngôn ngữ ít tài nguyên. Cahyawijaya et al. [2023] giới thiệu NusaCrowd, một bộ sưu tập được chuẩn hóa gồm 137 bộ dữ liệu bao gồm 19 ngôn ngữ địa phương Indonesia trong các phương thức văn bản, giọng nói, và hình ảnh. Công việc của chúng tôi khác với các bộ dữ liệu trước đây vì chúng tôi tạo ra một bộ dữ liệu tinh chỉnh hướng dẫn quy mô lớn trải rộng hàng trăm nhiệm vụ khác nhau, nhưng vẫn giữ được chất lượng cao bằng cách liên quan đến chú thích con người và kiểm soát chất lượng nghiêm ngặt trong toàn bộ quá trình tạo dữ liệu.

14https://opus.nlpl.eu

8.2 Bộ dữ liệu tinh chỉnh hướng dẫn

Các bộ dữ liệu tinh chỉnh hướng dẫn là các bộ sưu tập của các cặp hướng dẫn và phản hồi được con người tuyển chọn, các nhiệm vụ NLP được mẫu hóa, hoặc các hướng dẫn tổng hợp được tạo ra bởi một mô hình ngôn ngữ. Có một số lượng ngày càng tăng các siêu bộ dữ liệu NLP như Natural instructions [Mishra et al., 2022], SuperNatural Instructions [Wang et al., 2022d], Flan 2021 [Wei et al., 2022a], Flan 2022 [Longpre et al., 2023a], Public Pool of Prompts (P3) [Sanh et al., 2022], Unnatural Instructions [Honovich et al., 2023], OPT-IML [Iyer et al., 2022], inter alia [Khashabi et al., 2020; Ye et al., 2021; Min et al., 2021] thu thập nhiều bộ dữ liệu được tinh chỉnh hướng dẫn với nhau. Một số công việc tập trung vào các ứng dụng cụ thể như hội thoại [Köpf et al., 2023], nền tảng kiến thức có cấu trúc [Xie et al., 2022], hoặc lý luận chuỗi tư duy [Wei et al., 2022b; Kim et al., 2023]. Những nỗ lực thủ công bao gồm Open Assistant [Köpf et al., 2023] thu thập đám đông các tình nguyện viên đã viết cả hướng dẫn và phản hồi, nhân viên Databricks tạo ra 15k ví dụ trong Dolly [Conover et al., 2023], và LIMA [Zhou et al., 2023] là một bộ sưu tập 1.000 ví dụ IFT được tác giả tuyển chọn.

Các bộ dữ liệu tinh chỉnh hướng dẫn tổng hợp bao gồm các hướng dẫn được lấy mẫu từ một mô hình ngôn ngữ, như bộ dữ liệu Self-Instruct [Wang et al., 2022b] được tạo ra bởi GPT-3 [Brown et al., 2020], bộ dữ liệu Alpaca [Taori et al., 2023] được tạo ra bởi GPT-3.5, và bộ dữ liệu Guanaco [Joseph Cheung, 2023]. Ngày càng nhiều, việc tạo ra tổng hợp các bộ dữ liệu được tinh chỉnh hướng dẫn trở nên tinh vi hơn. [Xu et al., 2023a] đề xuất một khung Evol-Instruct mới để có được các hướng dẫn phức tạp và khó khăn dần dần. [Luo et al., 2023] và [Gunasekar et al., 2023] mở rộng thêm ý tưởng này để thúc đẩy lý luận, tạo mã, và kỹ năng thuật toán. InstructionWild [Ni et al., 2023] và ShareGPT15 là các bộ sưu tập của các cuộc hội thoại do người dùng chia sẻ với ChatGPT.

8.3 Bộ dữ liệu Tinh chỉnh Hướng dẫn Đa ngôn ngữ

Mặc dù có các bộ sưu tập IFT ngày càng lớn hơn, công việc trước đây phần lớn tập trung vào tiếng Anh. Hầu hết các phương pháp mở rộng các bộ dữ liệu được tinh chỉnh hướng dẫn ngoài tiếng Anh đã dựa vào 1) dịch các bộ dữ liệu tiếng Anh sang các ngôn ngữ khác [Holmström & Doostmohammadi, 2023; Li et al., 2023a; Winata et al., 2023b], 2) tạo ra bộ dữ liệu dựa trên mẫu [Yu et al., 2023; Gupta et al., 2023] hoặc 3) tuyển chọn con người các bộ dữ liệu hướng dẫn trong các ngôn ngữ ngoài tiếng Anh [Muennighoff et al., 2023c; Li et al., 2023c; Wang et al., 2022c]. Đã có một số ngoại lệ đáng chú ý với tỷ lệ lớn dữ liệu không phải tiếng Anh [Joseph Cheung, 2023; Köpf et al., 2023; Lai et al., 2023; Li et al., 2023a; Longpre et al., 2023a; Muennighoff et al., 2023a;c; Zhuo et al., 2024; Nguyen et al., 2023].

Bộ dữ liệu Dựa trên Mẫu. Nỗ lực có liên quan nhất là công việc gần đây của [Muennighoff et al., 2023c] phát hành Crosslingual Public Pool of Prompts (xP3). xP3 mở rộng phân loại P3 và thêm 28 bộ dữ liệu đa ngôn ngữ mới. Tuy nhiên, các bộ dữ liệu của họ thường sử dụng cùng một mẫu trong các ngôn ngữ khác nhau, do đó hạn chế tính đa dạng nhiệm vụ. Ví dụ, một lô ngẫu nhiên từ bộ dữ liệu của họ có thể bao gồm cùng một mẫu trong các ngôn ngữ khác nhau nhiều lần. Kho dữ liệu xP3 của họ có hướng dẫn nhiệm vụ độc quyền bằng tiếng Anh. Trong [Muennighoff et al., 2023c], các thí nghiệm với việc khớp hướng dẫn nhiệm vụ với ngôn ngữ tương ứng của mẫu thông qua dịch máy (xP3mt) cho thấy hiệu suất cải thiện nhẹ cho các hướng dẫn nhiệm vụ không phải tiếng Anh tại suy luận. Công việc của chúng tôi khác biệt ở chỗ bộ dữ liệu được con người tuyển chọn của chúng tôi là độc đáo cho từng ngôn ngữ trong 65 ngôn ngữ. Sự đa dạng như vậy đã được nhấn mạnh như một thành phần chính cho tinh chỉnh hướng dẫn [Longpre et al., 2023a]. Hơn nữa, chúng tôi tạo ra các hướng dẫn nhiệm vụ không phải tiếng Anh thông qua các chú thích viên con người, đảm bảo những điều này có chất lượng cao, đó là

15https://sharegpt.com/

một trụ cột khác của hiệu suất tốt [Zhou et al., 2023].

Bộ dữ liệu Được Dịch Máy. Các lời nhắc được dịch máy thường thiếu tính biến đổi và sắc thái văn hóa vốn có trong văn bản được viết bản địa. Tuy nhiên, chúng vẫn hữu ích để mở rộng phạm vi ngôn ngữ của dữ liệu đào tạo và có thể giúp thu hẹp khoảng cách tài nguyên cho các ngôn ngữ có dữ liệu đào tạo hạn chế [Urbizu et al., 2023; Lin et al., 2022]. Chúng cũng có thể thích ứng các mô hình ngôn ngữ được tinh chỉnh hướng dẫn đã được đào tạo để tuân theo hướng dẫn trong các ngôn ngữ mới [Yong et al., 2023b]. Hơn nữa, LLM được đào tạo trên các lời nhắc được thiết kế cũng đã được chỉ ra thành công trong các nhiệm vụ như EAE (Event Argument Extraction) từ dữ liệu đa ngôn ngữ trong thiết lập zero-shot [Huang et al., 2022]. [Zhang et al., 2023a] xây dựng các hướng dẫn tiếng Trung chất lượng cao từ các bộ dữ liệu hướng dẫn tiếng Anh hiện có. Họ đầu tiên dịch các hướng dẫn tiếng Anh sang tiếng Trung và sau đó sử dụng quy trình xác minh con người để xác định liệu những bản dịch này có thể sử dụng được hay không; bộ dữ liệu được xác minh bao gồm khoảng 200k mẫu tinh chỉnh hướng dẫn tiếng Trung. [Li et al., 2023a] xây dựng dữ liệu hướng dẫn cho 52 ngôn ngữ phổ biến sử dụng Google Translate để dịch các lời nhắc và hoàn thành tiếng Anh từ Alpaca [Taori et al., 2023] (52K) và bộ dữ liệu Dolly [Conover et al., 2023] (15K), sau đó sử dụng dữ liệu này để tinh chỉnh LLaMA [Touvron et al., 2023] sử dụng công nghệ LoRA [Hu et al., 2021]. [Zhang et al., 2023b] nhắc LLM dịch một yêu cầu nhiệm vụ, được phủ lên với các chỉnh sửa dựa trên người dùng chi tiết hơn. Quá trình này tự nhiên kết nối các ngôn ngữ khác nhau cũng như sở thích con người với LLM, tận dụng LLaMA [Touvron et al., 2023] để hỗ trợ nền tảng và sử dụng xây dựng tự động các hướng dẫn dịch tương tác để tinh chỉnh hướng dẫn, do đó tăng cường khả năng đa ngôn ngữ của mô hình và căn chỉnh với nhu cầu ngôn ngữ đa dạng.

Ví dụ Đa ngôn ngữ Được Tuyển chọn bởi Con người. Có liên quan nhất đến công việc của chúng tôi về bộ dữ liệu Aya là các bộ dữ liệu khác đã được tuyển chọn bởi con người, thường bằng tiếng Anh. Databricks thu thập một bộ dữ liệu hướng dẫn 15k databricks-dolly-15k bằng cách dựa vào nhân viên của họ như các chú thích viên [Conover et al., 2023]. Các chú thích viên được hướng dẫn tuyển chọn các cặp lời nhắc / phản hồi trong mỗi tám danh mục hướng dẫn khác nhau. [Köpf et al., 2023] phát hành kho dữ liệu OpenAssistant với hơn 10.000 cuộc hội thoại từ hơn 13.500 chú thích viên quốc tế. Mặc dù bộ dữ liệu này chứa các chú thích đa ngôn ngữ, điều này không phải là một mục tiêu rõ ràng của sáng kiến. Trái ngược với kho dữ liệu của chúng tôi chỉ có 2,05% đóng góp bằng tiếng Anh, 42,8% dự án OpenAssistant vẫn bằng tiếng Anh [Köpf et al., 2023].

8.4 Nghiên cứu Tham gia trong Học máy

Nếu bạn muốn đi nhanh hãy đi một mình; nếu bạn muốn đi xa, hãy đi cùng nhau. — Tục ngữ Châu Phi

Các sáng kiến nghiên cứu tham gia trước đây đã tập trung xung quanh các khu vực hoặc các nhiệm vụ cụ thể như dịch thuật hoặc nhận dạng ký tự. Ví dụ, [Clanuwat et al., 2018] giải quyết vấn đề đọc và hiểu Kuzushiji, một phong cách viết chữ thảo Nhật Bản không còn được sử dụng phổ biến. Một ví dụ khác về thu thập dữ liệu đa dạng văn hóa là [Liu et al., 2021], đã tuyển dụng những người bản ngữ từ năm ngôn ngữ (Indonesian, Swahili, Tamil, Turkish, và Mandarin Chinese) có tính đa dạng về mặt typological, genealogical, và địa lý, để cung cấp hình ảnh của các khái niệm đại diện cho văn hóa của họ. Sau đó, họ tuyển dụng các nhà ngôn ngữ học chuyên nghiệp nói bản ngữ để viết chú thích cho những hình ảnh này. Tuy nhiên, bộ dữ liệu này nhỏ (ít hơn 8.000 điểm dữ liệu) và do đó chỉ giới hạn để đánh giá. Đáng chú ý rằng những công việc này chỉ tập trung vào miền hình ảnh, không giống như công việc của chúng tôi, tập trung vào văn bản.

Có liên quan hơn đến công việc của chúng tôi là các sáng kiến tạo dữ liệu tham gia tập trung vào NLP. [Guevara-Rukoz et al., 2020] trình bày một nghiên cứu tập trung vào việc tạo ra một kho dữ liệu đám đông cho các phương ngữ tiếng Tây Ban Nha Châu Mỹ Latinh để giải quyết sự khan hiếm tài nguyên cho những ngôn ngữ này. [∀et al., 2020] tập trung vào nhiệm vụ Dịch máy (MT), và tuyển chọn một bộ dữ liệu trong 30 ngôn ngữ Châu Phi thiếu đại diện theo một khung nghiên cứu tham gia. Công việc của chúng tôi rất phù hợp với tinh thần của những nỗ lực trước đây này, với sự khác biệt về tính tập trung toàn cầu thay vì khu vực. Trái ngược với những công việc này, có tính tập trung khu vực cụ thể, các cộng tác viên Aya đến từ nhiều lục địa bao gồm một loạt ngôn ngữ đa dạng.

Một số công việc đã khám phá các cấu trúc tổ chức cần thiết để tạo điều kiện phát triển các cộng đồng nghiên cứu xung quanh các ngôn ngữ thiếu đại diện. [Siminyu et al., 2021] mô tả chi tiết công việc về Chương trình Ngôn ngữ Châu Phi AI4D, nhằm tăng cường tài nguyên ngôn ngữ cho các ngôn ngữ Châu Phi. Kết quả bao gồm việc tạo ra hơn chín bộ dữ liệu ngôn ngữ Châu Phi mã nguồn mở và thiết lập các mô hình cơ sở, chứng minh tác động đáng kể của chương trình đối với công nghệ ngôn ngữ cho các ngôn ngữ Châu Phi. [Azunre et al., 2021] mô tả việc thành lập NLP Ghana, với cộng đồng mã nguồn mở hợp tác của nó. [Strassel & Tracey, 2016] thảo luận về những thách thức phát triển tài nguyên cho các ngôn ngữ ít tài nguyên dưới chương trình LORELEI (Low Resource Languages for Emergent Incidents). Họ tập trung vào nhu cầu cấp thiết về tài nguyên kỹ thuật số trong những ngôn ngữ này, đặc biệt trong các tình huống quan trọng như giảm thiểu tác động của thiên tai.

Các sáng kiến cộng đồng khoa học mở như Aya mang lại những tiến bộ đáng kể trong mô hình ngôn ngữ. Những nỗ lực liên quan (về mặt tính toán và tài nguyên yêu cầu) có thể tìm thấy trong BigScience Workshop [Akiki et al., 2022], bắt đầu từ năm 2021. Dự án BigScience được khởi xướng để giải quyết những hạn chế trong phát triển LLM, nhấn mạnh khoa học mở và hợp tác bao gồm. Tận dụng các nguyên tắc khoa học mở, nó đã hợp nhất một mạng lưới toàn cầu các nhà nghiên cứu làm việc để hợp tác và đạo đức tăng cường học máy. Công việc của họ đạt đỉnh trong các phát triển chính như mô hình BLOOM [Scao et al., 2022a] và kho dữ liệu ROOTS [Laurençon et al., 2022]. Những thành tựu này nhấn mạnh giá trị của các chương trình nghiên cứu do cộng đồng điều khiển, đạo đức, và đa dạng cho các công nghệ ngôn ngữ quy mô lớn. Sau Big Science, đã có những nỗ lực mở khác gần đây về khoa học mở trong mô hình ngôn ngữ [Groeneveld et al., 2024; Soldaini et al., 2024].

9 Hạn chế của công việc chúng tôi

1. Phạm vi ngôn ngữ và phương ngữ: Bộ Dữ liệu Aya và Bộ Sưu tập Aya bao gồm 65 và 114 ngôn ngữ tương ứng—đáng kể hơn so với các bộ dữ liệu đa ngôn ngữ hiện có. Tuy nhiên, điều này vẫn chỉ là một phần nhỏ của sự đa dạng ngôn ngữ thế giới. Trong khoảng 7.000 ngôn ngữ của thế giới, chỉ một nửa trong số chúng được ghi lại dưới bất kỳ hình thức viết nào [Adda et al., 2016]. Trong nửa này, chỉ một vài trăm được đưa vào internet trong kho dữ liệu có thể đọc được bằng máy [Adda et al., 2016]. Điều này có nghĩa là 93% ngôn ngữ thế giới vẫn không được sử dụng để đào tạo LLM. Cũng rất khó để xác định đường chia giữa các ngôn ngữ khác nhau và các phương ngữ khác nhau của cùng một ngôn ngữ [Rooy, 2021]. Sự biến đổi địa lý-văn hóa trong một ngôn ngữ thường sinh ra các phương ngữ mới hoặc các ngôn ngữ lai theo thời gian [Zampieri et al., 2020; Wolfram, 1997; Brown et al., 2020; Lent et al., 2022; Blaschke et al., 2023] và, như vậy, các phương ngữ có thể phục vụ một chức năng quan trọng trong việc thiết lập và duy trì bản sắc văn hóa [Falck et al., 2012]. Nhiều phương ngữ khác nhau thường được công nhận là thuộc về một ngôn ngữ cha mẹ duy nhất không được đại diện trong bộ dữ liệu. Ví dụ, trong trường hợp Malay, một trong những ngôn ngữ Đông Nam Á lớn nhất trong bộ dữ liệu, không có đóng góp cho các phương ngữ khu vực được nói rộng rãi ở một số bang của Malaysia. Các đóng góp của các tình nguyện viên muốn tự nhận mình nói một phương ngữ cụ thể đã được gắn thẻ như vậy trong dữ liệu để cho phép phân tích hạn chế việc sử dụng các phương ngữ khu vực trong chú thích. Cuối cùng, dữ liệu ngôn ngữ học xã hội cho thấy những người nói đa ngôn ngữ thường 'chuyển mã' giữa các ngôn ngữ hoặc phương ngữ tùy thuộc vào bối cảnh [Myers-Scotton, 2017], nhưng trong dự án này, chúng tôi giữ các ngôn ngữ tách biệt để làm cho chúng dễ phân loại hơn và được sử dụng xuôi dòng cho các ứng dụng dành cho ngôn ngữ cụ thể. Aya cũng không bao gồm các ngôn ngữ lập trình. Đã có công việc trước đây về bao gồm các ngôn ngữ lập trình đa dạng [Li et al., 2023d; Allal et al., 2023] và chúng tôi để lại những khám phá thêm theo hướng này cho công việc tương lai.

2. Phân phối không đều của các đóng góp: Như được khám phá trong Phần 3.3, mặc dù có số lượng lớn người tham gia, hoạt động của các chú thích viên bị thiên lệch, với 'đuôi dài' các chú thích viên chỉ đóng góp một hoặc hai chú thích. Tương đối ít cộng tác viên chiếm hầu hết các chú thích (xem Hình 10 - dưới). Tương tự, có một khoảng cách lớn giữa các ngôn ngữ có số lượng đóng góp cao nhất và những ngôn ngữ có số lượng đóng góp thấp nhất. Do đó, điều này gợi ý sự không đều tiềm năng trong phân phối bộ dữ liệu qua các ngôn ngữ khác nhau và thiếu tính đa dạng chú thích viên trong một số ngôn ngữ bị chi phối bởi một hoặc hai cộng tác viên thường xuyên.

3. Thiên kiến văn hóa hoặc cá nhân: Một hạn chế khác là sự hiện diện của các chú thích với thiên kiến văn hóa cụ thể. Một số ngôn ngữ trong bộ dữ liệu của chúng tôi có đại diện hạn chế, với chỉ một vài chú thích viên chịu trách nhiệm chú thích phần lớn bộ dữ liệu của họ. Điều này có thể có nghĩa là dữ liệu cho một ngôn ngữ cụ thể bị chi phối bởi các chú thích đại diện cho ý kiến hoặc ưu tiên của một cộng tác viên cụ thể hoặc có thể đại diện cho một lựa chọn hẹp của quan điểm văn hóa. Ví dụ, các chú thích bằng tiếng Pháp có thể chứa nhiều ví dụ về lịch sử của Pháp, thức ăn, bài hát, và các thực hành văn hóa khác, nhưng không chứa nhiều thông tin về di sản văn hóa của các cộng đồng nói tiếng Pháp ở Québec, Togo, hoặc Senegal [Vigouroux, 2013]. Thiên kiến này đặc biệt có vấn đề cho phân phối thiên lệch của các chú thích viên tích cực nhất. Cũng có thiên kiến tiềm năng trong sự có sẵn của các loại nội dung cụ thể. Ví dụ, dễ dàng tìm thấy văn bản trực tuyến từ các trang tin tức cho nhiều ngôn ngữ Châu Phi hơn so với tìm thấy văn bản từ các miền khác. Theo đó, những bộ dữ liệu này sẽ bị thiên lệch về phía ngữ pháp và từ vựng được sử dụng trong các báo cáo tin tức thay vì loại ngôn ngữ tự nhiên mà mọi người sử dụng trong cuộc sống hàng ngày [Hovy & Prabhumoye, 2021].

4. Đại từ có giới tính: Nhiều ngôn ngữ trong Bộ Dữ liệu Aya chỉ chứa các đại từ có giới tính rõ ràng (ví dụ, tiếng Ả Rập) hoặc thiếu đại từ ngôi thứ ba trung tính giới tính để tham chiếu trung tính giới tính (ví dụ Estonia). Điều này có nghĩa là trong việc phản hồi các lời nhắc có thể không xác định giới tính, cần cẩn thận để đảm bảo rằng các phản hồi vẫn trung lập về giới tính của bất kỳ người tham gia được giả định nào [Ghosh & Caliskan, 2023]. Ví dụ, nếu một phản hồi yêu cầu tham chiếu đến "một giáo viên" bằng tiếng Pháp, chú thích viên sẽ cần bao gồm các tham chiếu đến cả "un/e enseignant/e". Trong khi được chú ý để đảm bảo các phản hồi trung tính cho các chú thích mới, các chú thích có giới tính trong các bộ dữ liệu hiện có có thể không được gắn cờ, vì chúng không, nghiêm túc mà nói, sai. Thay vào đó, chúng chỉ đơn giản đặt trước một cách đọc có giới tính nơi một cách có thể không được ngụ ý [Hardmeier & Guillou, 2018].

5. Sự phân biệt về tính trang trọng: Nhiều ngôn ngữ trong Bộ Dữ liệu Aya cũng yêu cầu người nói hoặc chú thích viên đưa ra lựa chọn tình huống về tính trang trọng của đại từ được sử dụng trong phản hồi một lời nhắc cụ thể. Các ngôn ngữ như Nhật Bản, Ba Tư, Indonesia, Java, Yoruba, Pháp, Tây Ban Nha, và Đức bao gồm các mức độ tôn kính khác nhau được sử dụng trong các bối cảnh trang trọng hoặc không trang trọng, hoặc được sử dụng giữa các thành viên cộng đồng khác nhau về địa vị (được xác định bởi nhiều yếu tố như tuổi tác, nghề nghiệp, thâm niên, hoặc dân tộc) [Brown & Gilman, 1968]. Trong Yoruba, ví dụ, đại từ tương đương như "họ" có thể được sử dụng như một tôn kính số ít hoặc như một đại từ ngôi thứ ba số nhiều [Yusuf, 2022]. Chúng tôi ủy thác cho các chú thích viên cá nhân trong việc tạo ra phản hồi của họ, cho phép họ dựa vào các chuẩn mực của cộng đồng nói cụ thể của họ để xác định cách phản hồi. Thường thì, những quyết định này phụ thuộc vào nội dung được thảo luận, hoặc về cách trang trọng mà lời nhắc được tạo ra trong bộ dữ liệu gốc. Khi nghi ngờ, các chú thích viên được yêu cầu tưởng tượng loại 'giọng nói' mà họ mong đợi một LLM có khi trả lời một lời nhắc cho trước [Wilson, 2023].

Điều này có nghĩa là bộ dữ liệu được phát hành của chúng tôi chứa nhiều ngôn ngữ có các mức độ chuẩn hóa khác nhau và các hướng dẫn phong cách khác nhau. Chuẩn hóa thường gắn liền sâu sắc với quyền lực và bản sắc, và cách nói có thể được kết nối với các khía cạnh của bản sắc như tuổi tác, trình độ giáo dục, liên kết bộ lạc, và tôn giáo. Việc thiếu chuẩn hóa cũng chủ yếu do sự khác biệt khu vực và văn hóa qua cùng một ngôn ngữ, được minh họa bởi tiếng Bồ Đào Nha trong bộ dữ liệu: tiếng Bồ Đào Nha châu Âu khác với tiếng Bồ Đào Nha Brazil không chỉ về tính trang trọng mà còn về ngữ pháp, chính tả, và từ vựng. Thường thì, các tiêu chuẩn được chiếu bởi những người khác để đảm bảo tuân thủ các giá trị văn hóa [Bourdieu, 1987; De Mauro et al., 2015; Haugen, 1959; Rickford et al., 2012].

6. Lời nói độc hại hoặc xúc phạm: Nền tảng Chú thích Aya không chứa các cờ cụ thể cho lời nói độc hại, có hại, hoặc xúc phạm, vì vậy có thể là người dùng độc hại có thể gửi dữ liệu không an toàn. Chúng tôi tin rằng điều này có nguy cơ tương đối thấp vì tỷ lệ cao của các chú thích được xác minh bởi con người và đánh giá đồng đẳng, khiến việc các lời nhắc hoặc hoàn thành độc hại lọt vào bộ dữ liệu cuối cùng không có khả năng. Tuy nhiên, không có bảo đảm rằng mọi mục đã được kiểm toán. Trong khi đầu độc dữ liệu hiếm khi được quan sát như một mối đe dọa khả thi trong thực tế, nó đã được chứng minh là đáng quan tâm đối với tinh chỉnh hướng dẫn với rất ít ví dụ [Xu et al., 2023b; Wan et al., 2023] và cho đào tạo trước dưới điều kiện thực tế [Carlini et al., 2023]. Trong tám tháng chú thích đám đông, không có trường hợp báo cáo nào về lời nói thù địch hoặc độc hại trong các bộ dữ liệu hiện có cũng như không có trường hợp nào về lời nói xúc phạm được báo cáo trong giai đoạn đánh giá đồng đẳng của các chú thích mới.

Chúng tôi cũng lưu ý rằng dữ liệu có thể xúc phạm đối với một chú thích viên có thể không xúc phạm đối với người khác, ví dụ, việc hoàn thành một lời nhắc yêu cầu định nghĩa từ "woke" [Castaldo, September 16, 2023]. Các lời nhắc được viết về các chủ đề chính trị đảng phái, hoặc việc bao gồm các quảng cáo chính trị hoặc thông điệp chiến dịch có thể gây xúc phạm tùy thuộc vào khuynh hướng chính trị của chú thích viên. Tóm lại, chúng tôi đã cố gắng giảm thiểu lời nói xúc phạm bằng cách dựa nhiều vào chú thích con người và đánh giá đồng đẳng, nhưng không có bảo đảm rằng tất cả các điểm dữ liệu như vậy đã được loại bỏ khỏi kho dữ liệu.

7. Tính toán dữ liệu được gắn nhãn sai: Nền tảng Chú thích Aya không chứa bất kỳ thành phần nào cho phép gắn nhãn lại ngôn ngữ được chỉ định của các chú thích. Điều này có thể dẫn đến các lời nhắc và hoàn thành xuất hiện dưới một ngôn ngữ cụ thể, nhưng được gửi sai và sẽ cần được phân loại lại vào một ngôn ngữ khác. Ngoài ra, mặc dù chúng tôi tin tưởng các chú thích viên có thể tuân theo hướng dẫn và có tỷ lệ kiểm toán thủ công cao, một số ví dụ có khả năng đã lọt vào Bộ Dữ liệu Aya mà không ở định dạng kiểu hướng dẫn hoặc là các văn bản tự do.

10 Kết luận

Nghiên cứu tham gia mở tiếp tục bị thiếu tài nguyên và đánh giá thấp, đặc biệt khi công việc đó tập trung vào tạo dữ liệu [Sambasivan et al., 2021]. Aya liên quan đến người tham gia từ nhiều quốc gia khác nhau, độ tuổi khác nhau, và mức độ quen thuộc khác nhau với lĩnh vực xử lý ngôn ngữ tự nhiên. Chúng tôi thấy cơ hội tiếp tục cho các nhà ngôn ngữ học tính toán và kỹ sư học máy hợp tác với các nhà khoa học xã hội như nhà ngôn ngữ học xã hội, nhà nhân loại học, nhà xã hội học, và học giả nghiên cứu truyền thông. Khi các chuẩn mực mới trong khoa học mở nổi lên [Krishna, 2020; Bowser et al., 2020], các hợp tác như thế này có thể giúp đảm bảo rằng các dự án trong NLP được thúc đẩy bởi sự hiểu biết về ý nghĩa của ngôn ngữ đối với những người sử dụng nó hàng ngày.

Với Aya, chúng tôi hy vọng thay đổi cách dữ liệu được tạo ra cho nghiên cứu NLP đa ngôn ngữ. Phù hợp với quan điểm này, chúng tôi phát hành Bộ Dữ liệu Aya là bộ dữ liệu kiểu hướng dẫn đa ngôn ngữ được con người tuyển chọn mã nguồn mở đầu tiên bao gồm 204.114 cặp lời nhắc-hoàn thành bao gồm 65 ngôn ngữ. Bộ dữ liệu này được xây dựng với sự giúp đỡ của cộng đồng khoa học mở của chúng tôi gồm 2.997 cộng tác viên từ 119 quốc gia trong khoảng thời gian tám tháng.

Chúng tôi cũng phát hành Bộ Sưu tập Aya, bao gồm 44 bộ dữ liệu kiểu hướng dẫn. Những bộ này được chuẩn bị bằng cách chuyển đổi các bộ dữ liệu NLP hiện có thành các cặp lời nhắc-hoàn thành có thể được tận dụng cho tinh chỉnh hướng dẫn. Hơn nữa, chúng tôi mở rộng bộ sưu tập này bằng cách dịch các bộ dữ liệu từ tiếng Anh sang 101 ngôn ngữ, do đó mở rộng phạm vi bao phủ, đặc biệt cho nhiều ngôn ngữ ít tài nguyên. Bộ sưu tập này bao gồm 513M cặp lời nhắc và hoàn thành bao gồm 114 ngôn ngữ tổng cộng và là bộ sưu tập dữ liệu tinh chỉnh hướng dẫn đa ngôn ngữ lớn nhất ngày nay. Ngoài ra, chúng tôi phát hành Bộ Đánh giá Aya, bao gồm các ví dụ được con người tuyển chọn trong 13 ngôn ngữ và bản dịch của các lời nhắc được chọn cẩn thận trong 101 ngôn ngữ. Cuối cùng, chúng tôi cũng đang mở mã nguồn Nền tảng Chú thích Aya để các cộng đồng có thể tiếp tục sử dụng nền tảng để hỗ trợ quá trình thu thập dữ liệu đa ngôn ngữ. Chúng tôi hy vọng những cộng đồng này tiếp tục phát triển và phát triển, và kết nối những người nói các ngôn ngữ ít tài nguyên trên khắp thế giới.

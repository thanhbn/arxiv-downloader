Kho Dữ Liệu BigScience ROOTS:
Một Bộ Dữ Liệu Đa Ngôn Ngữ Hỗn Hợp 1.6TB

Hugo Laurençon1Lucile Saulnier1Thomas Wang1Christopher Akiki2
Albert Villanova del Moral1Teven Le Scao1*
Leandro von Werra1Chenghao Mou3Eduardo González Ponferrada4Huu Nguyen5
Jörg Frohberg32Mario Šaško1Quentin Lhoest1
Angelina McMillan-Major1;6Gérard Dupont7Stella Biderman8;9Anna Rogers10
Loubna Ben allal1Francesco De Toni11Giada Pistilli1Olivier Nguyen28
Somaieh Nikpoor12Maraim Masoud13Pierre Colombo14Javier de la Rosa15
Paulo Villegas16Tristan Thrush1Shayne Longpre17Sebastian Nagel19Leon Weber
20Manuel Romero Muñoz21Jian Zhu22Daniel van Strien23Zaid Alyafeai24
Khalid Almubarak25Vu Minh Chien26Itziar Gonzalez-Dios27Aitor Soroa27
Kyle Lo29Manan Dey30Pedro Ortiz Suarez31Aaron Gokaslan18Shamik Bose3
David Ifeoluwa Adelani33Long Phan34Hieu Tran34Ian Yu35Suhas Pai36
Jenny Chim37
Violette Lepercq1Suzana Ili ´c1Margaret Mitchell1Sasha Luccioni1Yacine Jernite1

1Hugging Face2Leipzig University3Independent Researcher4Ferrum Health
5Ontocord.ai6University of Washington7Mavenoid8EleutherAI9Booz Allen Hamilton
10University of Copenhagen11University of Western Australia12CAIDP
13Independent Researcher14CentraleSupélec15National Library of Norway
16Telefonica I+D17MIT18Cornell University19Common Crawl
20Humboldt-Universität zu Berlin and Max Delbrück Center for Molecular Medicine21Narrativa
22University of Michigan, Ann Arbor23British Library
24King Fahd University of Petroleum and Minerals
25Prince Sattam bin Abdulaziz University (PSAU)26DETOMO Inc.
27HiTZ Center, University of the Basque Country (UPV/EHU)28ServiceNow
29Allen Institute for AI30SAP31Mannheim University32Apergo.ai33Saarland University
34VietAI Research35Aggregate Intellect36Bedrock AI37Queen Mary University of London

Đóng góp ngang bằng

Tóm tắt

Khi các mô hình ngôn ngữ ngày càng trở nên lớn hơn, nhu cầu về các bộ dữ liệu văn bản chất lượng cao quy mô lớn chưa bao giờ cấp thiết đến vậy, đặc biệt trong môi trường đa ngôn ngữ. Hội thảo BigScience, một sáng kiến đa ngành và quốc tế kéo dài 1 năm, được thành lập với mục tiêu nghiên cứu và huấn luyện các mô hình ngôn ngữ lớn như một cam kết hướng theo giá trị, đặt các vấn đề về đạo đức, tác hại và quản trị lên hàng đầu. Bài báo này tài liệu hóa các nỗ lực tạo và tuyển chọn dữ liệu được thực hiện bởi BigScience để tập hợp kho dữ liệu Responsible Open-science Open-collaboration Text Sources (ROOTS), một bộ dữ liệu 1.6TB bao trùm 59 ngôn ngữ được sử dụng để huấn luyện mô hình ngôn ngữ BigScience Large Open-science Open-access Multilingual (BLOOM) 176 tỷ tham số (BigScience Workshop, 2022). Chúng tôi tiếp tục công bố một tập con ban đầu lớn của kho dữ liệu và các phân tích về nó, và hy vọng trao quyền cho các dự án mô hình hóa đơn ngôn ngữ và đa ngôn ngữ quy mô lớn với cả dữ liệu và các công cụ xử lý, cũng như kích thích nghiên cứu xung quanh kho dữ liệu đa ngôn ngữ lớn này.

Hội nghị thứ 36 về Hệ thống Xử lý Thông tin Thần kinh (NeurIPS 2022) Track về Bộ dữ liệu và Điểm chuẩn.

Mục lục

1 Giới thiệu 3
1.1 Tổng quan về bài báo . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3
1.2 Công trình liên quan . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4
2 (Crowd) Sourcing một Danh mục Tài nguyên Ngôn ngữ 4
2.1 Thu thập Dữ liệu từ các Tài nguyên Đã xác định . . . . . . . . . . . . . . . . . . . . 5
2.2 Pipeline Xử lý để Cải thiện Chất lượng trên Bộ dữ liệu Crowdsourced . . . . . . . 6
3 Xử lý OSCAR 7
3.1 Làm sạch và lọc dữ liệu . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7
3.2 Khử trùng lặp . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8
3.3 Thông tin nhận dạng cá nhân . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8
4 Cái nhìn đầu tiên về ROOTS 8
4.1 Ngôn ngữ Tự nhiên . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8
4.2 Ngôn ngữ Lập trình . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9
4.3 Phân tích tokenizer của các bộ dữ liệu thành phần . . . . . . . . . . . . . . . . . . . 10
5 Kết luận 11
A Tuyên bố Cân nhắc Đạo đức và Tác động Rộng hơn 20
B Chi tiết về các công cụ được sử dụng để thu thập bộ dữ liệu crowdsourced 21
B.1 Mã giả để tái tạo cấu trúc văn bản từ mã HTML . . . . . . . . . . . . . . . . . . 21
B.2 Các trường hợp sử dụng công cụ trực quan hóa . . . . . . . . . . . . . . . . . . . . . . . 21
B.3 Danh sách đầy đủ các hàm được sử dụng trong bộ dữ liệu (Crowd)Sourced . . . . . . . 22
C Danh sách đầy đủ các bộ lọc được tuyển chọn thủ công được sử dụng trên OSCAR 26
D Sáng kiến lọc PII 27
E Nguồn Dữ liệu 28
F Đóng góp của tác giả 34

Hình 1: Tổng quan về ROOTS. Trái: Một treemap về đại diện ngôn ngữ tự nhiên tính theo số byte theo họ ngôn ngữ. Phần lớn của biểu đồ bị choáng ngợp bởi 1321.89 GB được phân bổ cho Eurasia. Hình chữ nhật màu cam tương ứng với 18GB tiếng Indonesia, đại diện duy nhất của vùng macroarea Papunesia, và hình chữ nhật màu xanh lá cây tương ứng với 0.4GB của vùng macroarea ngôn ngữ châu Phi. Phải: Một biểu đồ waffle về phân phối ngôn ngữ lập trình theo số lượng tệp. Một ô vuông tương ứng khoảng 30.000 tệp.

1 Giới thiệu

BigScience1 bắt đầu vào tháng 5 năm 2021 như một sáng kiến nghiên cứu hợp tác mở kéo dài một năm tập hợp hơn một nghìn người tham gia trên khắp thế giới để nghiên cứu các mô hình ngôn ngữ lớn (LLM). Một trong những mục tiêu sáng lập của BigScience là huấn luyện một LLM đa ngôn ngữ quy mô lớn, mở, có thể so sánh về quy mô với GPT-3 (Brown et al., 2020) nhưng được huấn luyện trên một bộ dữ liệu đa ngôn ngữ được tài liệu hóa tốt hơn và đại diện hơn. Toàn bộ hội thảo BigScience được thiết kế như một nỗ lực hợp tác (Caselli et al., 2021; Bondi et al., 2021) và hướng theo giá trị (Birhane et al., 2021). Trong suốt quá trình xây dựng kho dữ liệu này, chúng tôi đã tham gia vào việc điều tra đồng thời các vấn đề đạo đức (Talat et al., 2022), chính trị xã hội (McMillan-Major et al., 2022), và quản trị dữ liệu (Jernite et al., 2022) với mục tiêu rõ ràng là làm điều tốt cho và bởi những người mà chúng tôi thu thập dữ liệu.

Việc thu thập và xây dựng bộ dữ liệu được tổ chức xung quanh bốn nhóm làm việc: Quản trị Dữ liệu giúp xác định các giá trị của dự án và thiết kế cách tiếp cận của chúng tôi đối với việc sử dụng và phát hành dữ liệu trong bối cảnh quốc tế, Thu thập và Chuẩn bị Dữ liệu được giao nhiệm vụ giám sát việc thu thập dữ liệu, các nỗ lực tuyển chọn, và Quyền riêng tư cho các rủi ro quyền riêng tư và vệ sinh bộ dữ liệu, Học thuật Pháp lý giúp xác định bối cảnh pháp lý đa pháp quyền mà toàn bộ hội thảo phải hoạt động trong đó, và chúng tôi thảo luận các tác động thực tế trong suốt bài báo khi thích hợp. Một cái nhìn tổng quan về Kho dữ liệu BigScience được cung cấp trong hình 1.

Mục tiêu của bài báo hiện tại là kép: (1) chúng tôi trình bày một bản phát hành sơ bộ có kiểm soát, tuân theo cam kết với hiến chương đạo đức BigScience2, một tập con lớn của ROOTS3 (2) chúng tôi phát hành nhiều công cụ dữ liệu4 được phát triển trong quá trình và cho phép chúng tôi tuyển chọn, thu thập, làm sạch và kiểm tra tất cả 498 bộ dữ liệu thành phần cùng nhau tạo thành ROOTS. Điều này bao gồm một kết quả sơ bộ của các phân tích hiện đang được phát triển để nghiên cứu kho dữ liệu.

1.1 Tổng quan về bài báo

Phần còn lại của bài báo này chi tiết về cách tiếp cận của chúng tôi để tuyển chọn một bộ dữ liệu quy mô web bao phủ 59 ngôn ngữ, 46 ngôn ngữ tự nhiên và 13 ngôn ngữ lập trình — việc lựa chọn ngôn ngữ chủ yếu được thúc đẩy bởi các cộng đồng tham gia vào nỗ lực do tầm quan trọng mà chúng tôi đặt vào chuyên môn ngôn ngữ. Kho dữ liệu cuối cùng của chúng tôi được tạo thành từ hai thành phần chính: 62% văn bản đến từ danh sách được cộng đồng lựa chọn và tài liệu hóa các nguồn dữ liệu ngôn ngữ và quá trình thu thập của nó được mô tả trong phần 2, và 38% bao gồm văn bản được trích xuất từ một web crawl được xử lý trước, OSCAR (Ortiz Suárez et al. (2020)), được lọc với sự giúp đỡ của những người bản ngữ, được mô tả trong phần 3.

1.2 Công trình liên quan

Các Mô hình Ngôn ngữ Lớn và Kho dữ liệu Văn bản Lớn Mô hình thống trị hiện tại trong xử lý ngôn ngữ tự nhiên dựa rất nhiều vào các mô hình được đào tạo trước: các mô hình ngôn ngữ lớn sau đó có thể được tinh chỉnh trên một nhiệm vụ hạ lưu (Howard and Ruder, 2018; Devlin et al., 2018) hoặc thậm chí được sử dụng như hiện tại mà không cần dữ liệu bổ sung (Radford et al., 2019; Brown et al., 2020). Trong mô hình này, hiệu suất có tương quan trực tiếp với cả kích thước mô hình và kích thước và chất lượng bộ dữ liệu (Kaplan et al., 2020), với các mô hình gần đây được huấn luyện trên tới 1.4 nghìn tỷ token (Hoffmann et al., 2022) và các pipeline tạo bộ dữ liệu đại diện cho một phần quan trọng của các dự án mô hình ngôn ngữ lớn. Tuy nhiên, hầu hết các bộ dữ liệu như vậy không được phát hành, cản trở nghiên cứu tiếp theo. Các ngoại lệ bao gồm the Pile (Gao et al., 2020), một kho dữ liệu được tuyển chọn các bộ dữ liệu cho mô hình hóa ngôn ngữ đã trở nên được sử dụng rộng rãi để huấn luyện các mô hình tiếng Anh tiên tiến (Lieber et al., 2021; Smith et al., 2022; Black et al., 2022; Zhang et al., 2022), và C4 và mC4 (Raffel et al., 2020; Xue et al., 2020), đã cung cấp năng lượng cho họ mô hình T5; CC100 (Conneau et al., 2020) đã được sử dụng nhiều cho mô hình hóa đa ngôn ngữ; và OSCAR (Ortiz Suárez et al., 2019), đã cho phép các mô hình đơn ngôn ngữ không phải tiếng Anh.

Công cụ, Trực quan hóa, và Tái tạo Thượng nguồn từ các bộ dữ liệu huấn luyện hoàn thiện là vấn đề về các phương pháp và pipeline xử lý: cả các hoạt động mà các bộ dữ liệu trải qua và nỗ lực kỹ thuật cần thiết để áp dụng chúng ở quy mô terabyte. Công trình hiện có có xu hướng rơi vào một phổ từ không có chi tiết gì cả (Brown et al., 2020) đến hướng dẫn lọc chi tiết, với (Raffel et al., 2020) hoặc không có việc phát hành bộ dữ liệu (Rae et al., 2021) đến hướng dẫn lọc chi tiết với mã đi kèm (Gao et al., 2020; Conneau et al., 2020; Ortiz Suárez et al., 2019). Ngay cả khi mã được phát hành, nó có xu hướng được xây dựng và điều chỉnh cho mục đích của dự án. Do đó, các dự án lớn không tái sử dụng một bộ dữ liệu hiện có hoàn toàn thường xây dựng pipeline riêng của họ thay vì tái sử dụng một pipeline hiện có trên dữ liệu mới. Tuy nhiên, các công cụ dữ liệu được xây dựng và đóng gói để được sử dụng cho các dự án khác tồn tại, chẳng hạn như Ungoliant và Goclassy của OSCAR (Abadji et al., 2021; Ortiz Suárez et al., 2019), cung cấp một pipeline xử lý Common Crawl phân tán; CCNet (Wenzek et al., 2020), được xây dựng để lọc chất lượng các bản dump Common Crawl đa ngôn ngữ; và OpenWebText (Gokaslan and Cohen, 2019), cho phép xử lý dump Reddit.

Tài liệu hóa Kho dữ liệu Văn bản trong NLP Một nguồn cảm hứng cho công trình của chúng tôi là sự nhấn mạnh gần đây vào tài liệu hóa sâu hơn về những gì được bao gồm và những gì không có trong các kho dữ liệu được sử dụng để huấn luyện các mô hình NLP. Ví dụ đáng chú ý nhất của điều này là the Pile, mà các tác giả tự phân tích và tài liệu hóa nhiều thuộc tính cú pháp và ngữ nghĩa của bộ dữ liệu bao gồm thống kê cấu trúc (số lượng n-gram, ngôn ngữ, kích thước tài liệu), phân phối chủ đề trên các thành phần của nó, thiên lệch xã hội và cùng xuất hiện tình cảm, nội dung xúc phạm, và thông tin về cấp phép và sự đồng ý của tác giả, ngoài việc phát hành datasheet (Biderman et al., 2022). Các bộ dữ liệu đào tạo trước LM khác đã được tài liệu hóa và phân tích bao gồm C4 (Dodge et al., 2021; Luccioni and Viviano, 2021; Kreutzer et al., 2022), OSCAR (Kreutzer et al., 2022) và BookCorpus (Bandy and Vincent, 2021). Mặc dù loại tài liệu này còn xa mới trở thành thực hành tiêu chuẩn, nó đang trở nên ngày càng phổ biến do các lời kêu gọi gần đây cho tài liệu tốt hơn (Rogers, 2021; Bender et al., 2021) cũng như các nghiên cứu thực nghiệm về ghi nhớ dữ liệu trong các mô hình ngôn ngữ (Carlini et al., 2019, 2022).

2 (Crowd) Sourcing một Danh mục Tài nguyên Ngôn ngữ

Phần đầu tiên của kho dữ liệu của chúng tôi, chiếm 62% kích thước bộ dữ liệu cuối cùng (tính theo byte), được tạo thành từ một tập hợp các tài nguyên ngôn ngữ đơn ngôn ngữ và đa ngôn ngữ được lựa chọn và tài liệu hóa một cách hợp tác thông qua các nỗ lực khác nhau của nhóm làm việc Thu thập Dữ liệu BigScience. Nỗ lực đầu tiên như vậy bao gồm việc tạo ra một công cụ để hỗ trợ thu thập metadata thông qua các đệ trình mở, được gọi là Danh mục BigScience và tổ chức một loạt hackathon hợp tác với các cộng đồng ML và NLP tập trung cục bộ như Masakhane, Machine Learning Tokyo và LatinX in AI nơi những người tham gia có thể thêm và tài liệu hóa các mục cho ngôn ngữ của họ vào danh mục (McMillan-Major et al., 2022). Điều này tạo ra một tập hợp 252 nguồn, bao gồm ít nhất 21 cho mỗi danh mục ngôn ngữ được xem xét. Chúng tôi tập trung vào thu thập metadata như một cách để hỗ trợ lựa chọn các nguồn cho bộ dữ liệu cuối cùng và tài liệu hóa bộ dữ liệu cuối cùng. Đồng thời, những người tham gia nhóm làm việc đã thu thập các tài nguyên ngôn ngữ Ả Rập bổ sung trong kho lưu trữ Masader (Alyafeai et al., 2021), và đề xuất một danh sách các trang web quan tâm để tăng tính đa dạng địa lý của dữ liệu tiếng Anh, tiếng Tây Ban Nha và tiếng Trung của chúng tôi. Cuối cùng, để kiểm tra một cách rõ ràng khả năng xử lý mã máy tính cùng với ngôn ngữ tự nhiên của các mô hình ngôn ngữ lớn, chúng tôi đã chọn dữ liệu mã có sẵn trên GitHub và StackExchange.

2.1 Thu thập Dữ liệu từ các Tài nguyên Đã xác định

Thu thập Bộ dữ liệu và Bộ sưu tập Đã xác định. Đầu tiên, chúng tôi tận dụng Danh mục BigScience và kho lưu trữ Masader để bắt đầu thu thập văn bản từ các nguồn đã xác định, bao gồm cả các bộ dữ liệu NLP hiện có và các bộ sưu tập tài liệu có thành phần khác nhau. Do tính đa dạng của các nguồn, phương pháp lưu trữ, người quản lý dữ liệu và định dạng, việc thu thập văn bản này đòi hỏi một nỗ lực hợp tác. Để đạt được điều đó, chúng tôi đã thiết lập một cách tiếp cận 2 giai đoạn: đầu tiên, thu thập càng nhiều nguồn dữ liệu càng tốt ở một vị trí dễ tiếp cận; thứ hai, ánh xạ tất cả chúng vào một định dạng chung để dễ xử lý hơn.

Trong giai đoạn đầu tiên, chúng tôi tổ chức một hackathon mở để bắt đầu thu thập các nguồn đã xác định trên hub Hugging Face Datasets (Lhoest et al., 2021), trong một tổ chức chuyên dụng5 (để quản lý kiểm soát truy cập). Trong giai đoạn thứ hai, các bộ dữ liệu được thu thập được xử lý thêm thông qua (1) Phân đoạn ngôn ngữ, theo đó các nguồn dữ liệu được chia bằng metadata cho mỗi ngôn ngữ được bao phủ để thu được các bộ dữ liệu đơn ngôn ngữ, và việc sử dụng (2) Giao diện thống nhất theo đó một tài liệu bao gồm hai trường: "text" cho nội dung văn bản thực tế, và "meta" với biểu diễn JSON của metadata cho một tài liệu nhất định, chứa đủ thông tin để truy vết tài liệu trở lại nguồn gốc của chúng.

Dữ liệu Pseudo-Crawled. Trong số các danh mục khác nhau của tài nguyên ngôn ngữ được xác định thông qua nỗ lực thu thập dữ liệu, các trang web nổi bật như một danh mục đòi hỏi một nỗ lực cụ thể và pipeline chuyên dụng. Chúng tôi quyết định thiết kế một pipeline như vậy dựa trên "pseudo-crawling": nghĩa là, thay vì tự crawl các trang web, chúng tôi truy xuất các trang tương ứng với tên miền mục tiêu từ 18 snapshot được lưu trữ bởi Common Crawl vào năm 2020 và 2021 trong định dạng Web ARChive (WARC) (Mohr et al., 2008). Các tên miền này đến từ hai nguồn chính: trường homepage trong metadata của 252 mục danh mục được đề cập ở trên khi có sẵn (192 tổng cộng), và 456 trang web được đề xuất bởi những người tham gia một cách không đồng bộ để cải thiện tính đa dạng địa lý của các nguồn ngôn ngữ của chúng tôi; tạo ra tổng cộng 614 tên miền duy nhất sau khi khử trùng lặp.

Chúng tôi thu thập URL có trong các miền đó bằng cách sử dụng chỉ mục Common Crawl. Chỉ mục cung cấp metadata cho mọi tài liệu bao gồm URL trang, tên tệp WARC và offset bản ghi, trạng thái fetch, loại MIME nội dung, v.v. Chúng tôi chạy một truy vấn khớp tất cả tài liệu chia sẻ tên miền với một seed bằng Amazon Athena trên chỉ mục cột của Common Crawl6. 48 trong số 614 tên miền seed ban đầu không có kết quả khớp trong chỉ mục và do đó bị loại bỏ. Khi chúng tôi thu được metadata tài liệu, chúng tôi fetch các bản ghi WARC bằng yêu cầu HTTP range với offset byte bắt đầu và kết thúc. Vì các trang web HTML chiếm phần lớn nhất của các trang có trong các dump Common Crawl, chúng tôi quyết định chỉ trích xuất văn bản từ các trang HTML. Tài liệu ở định dạng khác đã bị lọc ra, tức là XML, PDF, v.v. 27 tên miền bổ sung đã bị loại bỏ khỏi danh sách ở giai đoạn này vì chúng tôi không truy xuất được bất kỳ trang HTML nào cho chúng.

Để trích xuất văn bản từ các trang HTML, trước tiên chúng tôi minify mã HTML. Minification là việc loại bỏ các ký tự không cần thiết khỏi mã nguồn của một trang web. Lấy cảm hứng từ Aghajanyan et al. (2022), chúng tôi loại bỏ khỏi DOM-HTML tất cả các cây con có trong thẻ <script>, <style>, <header>, <iframe>, <footer> và <form> cũng như tất cả các cây con liên quan đến thẻ <body>, <div>, <p>, <section>, <table>, <ul>, <ol> hoặc <dl> có nội dung văn bản ít hơn 64 ký tự. Văn bản sau đó được trích xuất từ các nút của DOM-HTML mới này. Trong khi nối văn bản được trích xuất, chúng tôi áp dụng một tập hợp các quy tắc để tái tạo cấu trúc của văn bản mà không có mã HTML của nó, lấy cảm hứng từ những gì Common Crawl làm để trích xuất các tệp WET của nó (Phụ lục B.1). Quy trình tổng thể cho phép chúng tôi thu được các bộ dữ liệu văn bản cho 539 tên miền.

Mã GitHub. Chúng tôi thu thập một bộ dữ liệu mã từ BigQuery7 sử dụng cùng lựa chọn ngôn ngữ như AlphaCode (Li et al., 2022). Bộ dữ liệu sau đó được khử trùng lặp các kết quả khớp chính xác và lọc cho các tệp nguồn có từ 100 đến 200.000 ký tự, từ 15-65% ký tự chữ cái, độ dài dòng tối đa 20-1000 ký tự, và độ lệch chuẩn độ dài token lớn hơn 3. Do lỗi trong pipeline xử lý trước, bộ dữ liệu cũng được lọc chỉ cho giấy phép GPL.

Hợp nhất và Khử trùng lặp Nguồn. Sau khi thu thập và xử lý dữ liệu ngôn ngữ thông qua ba pipeline được nêu ở trên, chúng tôi thực hiện bước cuối cùng để kiểm tra thủ công, khử trùng lặp và lựa chọn thêm các nguồn. Đầu tiên, chúng tôi giải quyết sự chồng chéo bộ dữ liệu mà chúng tôi tìm thấy bằng cách xem xét các nguồn của chúng tôi. Ví dụ: OpenITI có mặt ở cả dạng thô cũng như phiên bản được xử lý. Sự đồng thuận đã đạt được để chọn phiên bản sau. Sự chồng chéo bộ dữ liệu không tầm thường bao gồm s2orc (Lo et al., 2020), Arxiv (Clement et al., 2019) và tập con PubMed Central của the Pile (Gao et al., 2020). Chúng tôi cũng thực hiện khử trùng lặp bộ dữ liệu xuyên pipeline, loại bỏ Wikipedia và GitHub được pseudo-crawled để ủng hộ các phiên bản khác của chúng. Chúng tôi cũng loại bỏ các bộ dữ liệu mà chúng tôi thấy có tỷ lệ cao các tài liệu không hoàn toàn bằng ngôn ngữ tự nhiên (ví dụ: các trường hợp không mong đợi của SEO, thẻ HTML, v.v.), cũng như các bộ dữ liệu rất nhỏ trong các ngôn ngữ có nhiều tài nguyên hơn. Cuối cùng, các nguồn pseudo-crawled được xử lý thêm để loại bỏ menu (với heuristic bao gồm loại bỏ các dòng xuất hiện trong hơn 1% trang trong một miền nhất định) và các trang có tỷ lệ cao lặp lại ngram ký tự, độ tin cậy nhận dạng ngôn ngữ thấp, hoặc tỷ lệ thấp từ lớp đóng (xem Phần 3). Sau đó chúng tôi loại bỏ toàn bộ miền có kích thước nhỏ hơn 2MB sau bước này, tạo ra 147 bộ dữ liệu dựa trên pseudo-crawl, và tổng cộng 517 bộ dữ liệu bao gồm cả ba pipeline.

2.2 Pipeline Xử lý để Cải thiện Chất lượng trên Bộ dữ liệu Crowdsourced

Khi một trường văn bản được thu được, chúng tôi cố gắng cải thiện chất lượng của văn bản đó. Trong trường hợp cụ thể của việc trích xuất văn bản từ HTML, chúng tôi quan sát thấy không phải tất cả văn bản đều liên quan (menu, quảng cáo, văn bản lặp lại trên mỗi trang, v.v.). Để loại bỏ dữ liệu nhiễu khỏi bộ dữ liệu của chúng tôi, chúng tôi áp dụng một pipeline xử lý cho mỗi bộ dữ liệu bao gồm một chuỗi các hàm.

Các hàm được phân loại thành các hàm phạm vi tài liệu hoặc phạm vi bộ dữ liệu. Các hàm phạm vi tài liệu là các hoạt động sửa đổi tài liệu độc lập với các tài liệu khác và các hàm phạm vi bộ dữ liệu là các hoạt động tính đến toàn bộ bộ dữ liệu. Vuông góc với phạm vi này, các hàm cũng được tách thành các hàm làm sạch và lọc. Các hàm làm sạch nhằm loại bỏ văn bản được coi là không phải là một phần của tài liệu chính. Các hàm làm sạch phạm vi tài liệu có thể nhắm vào ví dụ các thẻ HTML còn sót lại. Ở đầu kia, các hàm làm sạch phạm vi bộ dữ liệu cần toàn bộ bộ dữ liệu để tính toán heuristic để xác định cách sửa đổi mỗi tài liệu. Ví dụ, quảng cáo khác nhau giữa các bộ dữ liệu, khiến việc định nghĩa bộ phân loại quảng cáo bất khả tri bộ dữ liệu trở nên khó khăn hơn. Thay vào đó, chúng tôi có thể lập chỉ mục tất cả các dòng trong bộ dữ liệu và xác định các dòng lặp lại trên nhiều trang như quảng cáo có khả năng. Một ví dụ được hiển thị trong Phụ lục B.2. Các hàm lọc nhằm loại bỏ toàn bộ tài liệu khỏi kho dữ liệu. Các lý do để chọn loại bỏ hoàn toàn một tài liệu là đa dạng: có thể là vì tài liệu được coi là chất lượng quá kém, quá phức tạp để tự động sửa chữa hoặc quá giống với các ví dụ khác đã có trong kho dữ liệu. Trong trường hợp sau, chúng ta nói về khử trùng lặp. Khử trùng lặp một tài liệu phụ thuộc vào việc liệu một tài liệu tương đương đã tồn tại ở đâu đó khác trong bộ dữ liệu hay không và do đó nhất thiết là một hàm phạm vi bộ dữ liệu. Khái niệm tài liệu tương đương đã được khám phá bởi Lee et al. (2022). Trong trường hợp này, chúng tôi cung cấp khử trùng lặp thông qua metadata (url, url được chuẩn hóa) và thông qua văn bản (khớp chuỗi chính xác). Một danh sách đầy đủ các hàm có sẵn trong B.3.

Vì các bộ dữ liệu đến từ các nguồn không đồng nhất với các thuộc tính khác nhau, mỗi bộ cần tập hợp các hàm xử lý riêng để tương ứng với định nghĩa của chúng tôi về tài liệu ngôn ngữ tự nhiên. Để hỗ trợ những người tham gia quyết định áp dụng hàm nào cho cái gì, chúng tôi đã xây dựng và phát hành một công cụ trực quan hóa dựa trên streamlit (hình 2 giúp hiểu tác động của mỗi hàm, hiển thị cách một tài liệu được thay đổi/loại bỏ cũng như các chỉ số mức bộ dữ liệu ước tính (số lượng dữ liệu được loại bỏ tính theo byte hoặc mẫu)). Vòng phản hồi nhanh này cho phép chúng tôi cập nhật pipeline trong một quá trình lặp đi lặp lại để tinh chỉnh mỗi pipeline xử lý trên các bộ dữ liệu và ngôn ngữ với đầu vào của những người bản ngữ. Một ví dụ cụ thể được chia sẻ trong Phụ lục B.2. Điều này dẫn đến 485 bộ dữ liệu không rỗng.

Hình 2: Ảnh chụp màn hình một phần của công cụ trực quan hóa. Người dùng có thể xem cách mỗi hàm trong pipeline xử lý ảnh hưởng đến thống kê cấp cao. Ảnh hưởng trên các mẫu cụ thể có thể được giám sát thông qua cùng một công cụ, xem Phụ lục B.2

3 Xử lý OSCAR

Chúng tôi chọn bổ sung dữ liệu thu được ở cuối quá trình được mô tả trong phần trước với dữ liệu dựa trên Common Crawl8 bổ sung được thúc đẩy bởi hai lý do chính. Đầu tiên, với mục tiêu tổng thể của dự án là cung cấp một LLM được huấn luyện như một artifact nghiên cứu có thể so sánh với những artifact đã phát hành trước đó đã dựa rất nhiều vào nguồn này, chúng tôi đánh giá rằng việc không bao gồm nó sẽ tạo thành quá nhiều sự khác biệt và có nguy cơ làm mất hiệu lực so sánh. Liên quan đến điều đó, công trình gần đây đã đặt sự nhấn mạnh mạnh mẽ về số lượng dữ liệu là một yếu tố mạnh trong hiệu suất của mô hình được huấn luyện trên các nhiệm vụ đánh giá (Kaplan et al., 2020; Hoffmann et al., 2022), và chúng tôi thiếu khoảng một phần ba dữ liệu để tối ưu hóa ngân sách tính toán của chúng tôi theo hướng này. Với điều đó trong tâm trí, chúng tôi chọn OSCAR phiên bản 21.09 (Ortiz Suárez et al., 2020), dựa trên snapshot Common Crawl của tháng 2 năm 2021, để tạo thành 38% còn lại của bộ dữ liệu cuối cùng của chúng tôi.

Tuy nhiên, dữ liệu crawled gặp phải một số vấn đề đã biết. Đầu tiên, chúng tôi muốn chỉ chọn các tài liệu được viết bởi con người cho con người, và loại trừ nội dung được tạo bởi máy ví dụ: tối ưu hóa công cụ tìm kiếm (SEO). Nội dung crawled cũng đại diện quá mức văn bản khiêu dâm trên các ngôn ngữ (Kreutzer et al., 2022), đặc biệt là dưới dạng quảng cáo spam. Cuối cùng, nó chứa thông tin cá nhân có thể tạo thành rủi ro quyền riêng tư. Phần hiện tại phác thảo cách tiếp cận của chúng tôi để giảm thiểu những vấn đề đó.

3.1 Làm sạch và lọc dữ liệu

Cách tiếp cận đầu tiên của chúng tôi để giải quyết những vấn đề trên bao gồm việc định nghĩa các chỉ số chất lượng cho nội dung web. Chúng sau đó có thể được sử dụng để lọc ra các trang cụ thể bằng cách định nghĩa ngưỡng cắt. Các mô tả chi tiết để tái tạo có sẵn trong phụ lục C. Chúng tôi lọc ra các tài liệu với:

• Lặp lại ký tự quá cao hoặc lặp lại từ quá cao như một thước đo nội dung lặp lại.
• Tỷ lệ quá cao của ký tự đặc biệt để loại bỏ mã trang hoặc artifacts crawling.
• Tỷ lệ không đủ của từ lớp đóng để lọc ra các trang SEO.
• Tỷ lệ quá cao của từ được gắn cờ để lọc ra spam khiêu dâm. Chúng tôi yêu cầu những người đóng góp điều chỉnh danh sách từ trong ngôn ngữ của họ theo tiêu chí này (trái ngược với các thuật ngữ chung liên quan đến tình dục) và thiên về độ chính xác cao.
• Giá trị perplexity quá cao để lọc ra ngôn ngữ không tự nhiên.
• Số từ không đủ, vì huấn luyện LLM đòi hỏi kích thước ngữ cảnh mở rộng.

Các ngôn ngữ mà chúng tôi cuối cùng xem xét trong OSCAR là các ngôn ngữ mà chúng tôi có thể thu được các hyperparameter và giá trị ngưỡng cho mỗi chỉ số này bởi những người bản ngữ. Cụ thể, chúng tôi xem xét tiếng Ả Rập, Basque, Bengali, Catalan, Trung Quốc, Anh, Pháp, Hindi, Indonesia, Bồ Đào Nha, Tây Ban Nha, Urdu và Việt Nam. Mã được sử dụng để lọc OSCAR, cùng với các tham số và giá trị ngưỡng cụ thể cho ngôn ngữ, đều được công khai. Sau đó chúng tôi yêu cầu những người bản ngữ của mỗi ngôn ngữ sử dụng công cụ trực quan hóa của chúng tôi9 để thiết lập ngưỡng cho mỗi bộ lọc. Tỷ lệ phần trăm tài liệu được loại bỏ sau khi áp dụng tất cả các bộ lọc này được đưa ra trong Bảng 1, và tỷ lệ phần trăm tài liệu bị loại bỏ bởi mỗi bộ lọc độc lập được đưa ra trong 3.

AR EU BN CA ZH EN FR HI ID PT UR VI ES
20.3 5.2 48.8 21.1 23.1 17.2 17.0 25.7 10.4 12.6 15.8 21.3 16.9

Bảng 1: Tỷ lệ phần trăm tài liệu được loại bỏ bởi việc lọc theo ngôn ngữ (mã ISO 639-1).

Hình 3: Tỷ lệ phần trăm tài liệu bị loại bỏ bởi mỗi bộ lọc độc lập cho 5 ngôn ngữ

3.2 Khử trùng lặp

Khử trùng lặp dữ liệu đã trở thành một công cụ chính cho các dự án mô hình ngôn ngữ sau nghiên cứu cho thấy rằng nó cả cải thiện hiệu suất trên các nhiệm vụ hạ lưu (Lee et al., 2022; Zhang et al., 2021) và giảm ghi nhớ dữ liệu huấn luyện (Kandpal et al., 2022). Để loại bỏ các tài liệu gần trùng lặp trong OSCAR (đã được khử trùng lặp chính xác), ban đầu chúng tôi sử dụng SimHash (Charikar, 2002; Manku et al., 2007), một hàm băm liên kết với hai văn bản tương tự các hash có khoảng cách Hamming thấp, với 6-gram và ngưỡng khoảng cách Hamming là 4. Khoảng 0.7% tài liệu trung bình (0.07%2.7%) được xác định là gần trùng lặp. Tuy nhiên, vì SimHash về cơ bản là thuật toán túi từ, các tài liệu dài có nhiều khả năng kết thúc tương tự nhau hơn. Trên thực tế, chúng tôi tìm thấy false positive trong các tài liệu dài và quyết định không loại bỏ các tài liệu trong cùng một cluster gần trùng lặp khi chúng dài hơn 6000 ký tự. Thay vào đó, chúng tôi áp dụng khử trùng lặp substring (Lee et al., 2022) dựa trên Suffix Array (Manber and Myers, 1993) như một phương pháp bổ sung nhóm các tài liệu chia sẻ một substring dài, cho các tài liệu có hơn 6000 ký tự. Chúng tôi tìm thấy trung bình 21.67% (10.61% 32.30%) dữ liệu (tính theo byte) bị trùng lặp.

3.3 Thông tin nhận dạng cá nhân

Chúng tôi sử dụng cách tiếp cận dựa trên quy tắc tận dụng biểu thức chính quy (Phụ lục C). Các yếu tố được biên tập là các trường hợp của KEY (các bộ nhận dạng số và chữ và số như số điện thoại, số thẻ tín dụng, hash thập lục phân và tương tự, trong khi bỏ qua các trường hợp của năm và số đơn giản), EMAIL (địa chỉ email), USER (handle mạng xã hội) và IP_ADDRESS (địa chỉ IPv4 hoặc IPv6).

4 Cái nhìn đầu tiên về ROOTS

Các nỗ lực được mô tả trong các phần trước cùng nhau trong một tập hợp 1.6 Terabyte văn bản đa ngôn ngữ. Hình 4 đặt con số đó vào ngữ cảnh bằng cách so sánh kích thước của các kho dữ liệu thường được sử dụng để huấn luyện các mô hình ngôn ngữ lớn. Tài liệu về các thành phần riêng lẻ của kho dữ liệu có thể được tìm thấy trong một bộ dataset card tương tác. Trong phần này, chúng tôi thực hiện các bước ban đầu hướng tới hiểu biết sâu hơn về kho dữ liệu thông qua phân tích thống kê dữ liệu tổng hợp.

4.1 Ngôn ngữ Tự nhiên

Cấu thành của kho dữ liệu phản ánh các nỗ lực crowdsourcing đã cho phép tạo ra nó. Nó bao gồm 46 ngôn ngữ tự nhiên trải rộng 3 macroarea và 9 họ ngôn ngữ: Afro-Asiatic, Austro-Asiatic, Austronesian, Basque, Dravidian, Indo-European, Mande, Niger-Congo, Sino-Tibetan. Ở mức 30.03%, tiếng Anh tạo thành phần lớn nhất của kho dữ liệu, tiếp theo là tiếng Trung Giản thể (16.16%), tiếng Pháp (12.9%), tiếng Tây Ban Nha (10.85%), tiếng Bồ Đào Nha (4.91%) và tiếng Ả Rập (4.6%). Một sự phân tích chi tiết hơn về kho dữ liệu có thể được tìm thấy trong phụ lục và trong một công cụ khám phá tương tác trực tuyến10,

GPT-2 C4 ROOTS
(English)OPT The Pile ROOTS GPT-3*
Training Datasets0.000.250.500.751.001.251.501.752.00Terabytes
0.040.310.490.80.891.612.1

Hình 4: So sánh kích thước thô với các kho dữ liệu khác được sử dụng để huấn luyện các mô hình ngôn ngữ lớn. Dấu hoa thị bên cạnh GPT-3 chỉ ra thực tế rằng giá trị được đề cập là ước tính được tính toán bằng cách sử dụng số token được báo cáo và số token trung bình trên mỗi byte văn bản mà tokenizer GPT-2 tạo ra trên các tập con Pile-CC, Books3, OWT2 và Wiki-en của the Pile (Gao et al., 2020)

Hình 5: Kích thước tính theo byte của mọi tài liệu trong kho dữ liệu theo ngôn ngữ. Trục y ở thang logarithmic. Biểu đồ hộp-và-râu minh họa trung vị, phần tư thứ nhất và thứ ba, râu được vẽ trong giá trị 1.5 IQR và outlier

một ảnh chụp màn hình được bao gồm trong hình 1 để mô tả phân phối byte của các genera ngôn ngữ của tập con macroarea Eurasian của kho dữ liệu.

Để mô hình được huấn luyện có cơ hội học các phụ thuộc dài, kho dữ liệu huấn luyện cần chứa các chuỗi dài văn bản mạch lạc. Đồng thời, các bước hậu xử lý trước đó chỉ giảm kích thước của các tài liệu. Kích thước trung vị của một tài liệu trong kho dữ liệu của chúng tôi là 1,129 byte. Hình 5 cho thấy phân phối kích thước tài liệu theo ngôn ngữ. Một sự phân tích chi tiết hơn về kích thước của kho dữ liệu trên một công cụ tương tác trực tuyến.11.

Phân phối của các giá trị bộ lọc cho các bộ lọc khác nhau được giới thiệu trong Phần 3.1 và các ngôn ngữ, cho dữ liệu Catalogue, Pseudo-Crawl và OSCAR (được lọc) có sẵn trong một demo trực tuyến12. Các ví dụ cho tiếng Anh được hiển thị trong hình 6. Các phân phối khác nhau phản ánh tính đa dạng của việc thu thập và lọc các thành phần chính của chúng tôi. Một ví dụ đáng chú ý là bộ lọc từ được gắn cờ, mà phân phối cho OSCAR bị lệch phải so với catalogue ngay cả sau khi lọc.

4.2 Ngôn ngữ Lập trình

Như được mô tả trong biểu đồ waffle trong hình 1, tập con mã của kho dữ liệu trải rộng 13 ngôn ngữ lập trình, với Java, PHP và C++ chiếm hơn một nửa tất cả tài liệu.

Hình 6: Một số phân phối của giá trị bộ lọc cho tiếng Anh. Giá trị bộ lọc là giá trị mà bộ lọc đưa ra cho một tài liệu. Các giá trị này thường được sử dụng để lọc ra các tài liệu được đánh giá quá thấp hoặc quá cao và cũng thông báo về thành phần của các bộ dữ liệu.

Hình 7: Token trên mỗi byte cho mỗi thành phần tiếng Anh cho các tokenizer được huấn luyện trên kho dữ liệu này (BLOOM), the Pile (GPT-NeoX 20B) và C4 (T5). Giá trị thấp hơn có nghĩa là thành phần (trục X) tương tự hơn trong tổng thể với kho dữ liệu huấn luyện được so sánh.

Các tệp cấu hình và test phong phú trong hầu hết các kho lưu trữ GitHub nhưng không thú vị cho mô hình hóa mã. Để đạt được điều đó, chúng tôi sử dụng một heuristic có bước đầu tiên kiểm tra 5 dòng đầu tiên của một tệp để tìm sự hiện diện của từ khóa như "configuration file" hoặc "test file". Thất bại điều đó, bước thứ hai là xem liệu sự xuất hiện của các literal config và test trong một tệp nhất định có vượt quá 5% tổng số dòng của tệp đó không. Chúng tôi thấy rằng 5.23% dữ liệu bao gồm các tệp cấu hình và 7.88% tệp test.

Allamanis (2019) và Lopes et al. (2017) nổi bật phần lớn gần trùng lặp có trong các bộ dữ liệu mã và cách chúng có thể làm tăng các metric hiệu suất. Chỉ khử trùng lặp khớp chính xác có thể bỏ lỡ một lượng lớn gần trùng lặp. Để phát hiện chúng, trước tiên chúng tôi tính toán MinHash của tất cả tài liệu, sau đó tạo chỉ mục Locality Sensitive Hashing (LSH) giữa các tệp để tìm các cluster trùng lặp trong thời gian tuyến tính. Chúng tôi đánh giá thêm độ tương tự Jaccard trong các cluster trùng lặp để loại bỏ một số false positive. Chúng tôi tìm thấy 10.9M tệp trùng lặp trong các cluster và 4.1M tệp duy nhất: gần 32% dữ liệu bao gồm gần trùng lặp. Các trình kiểm tra cú pháp13 được sử dụng để xác thực 500K mẫu mã Python và PHP. Chúng tôi thấy rằng chỉ 1% dữ liệu Python và 2% tệp PHP không vượt qua kiểm tra cú pháp.

4.3 Phân tích tokenizer của các bộ dữ liệu thành phần

Một tokenizer được huấn luyện trên một bộ dữ liệu có thể được sử dụng như một proxy cho nội dung của nó (Gao et al., 2020). Metric liên quan là số token được tạo ra cho một byte ngôn ngữ tự nhiên. Kho dữ liệu huấn luyện càng khác biệt với kho dữ liệu được tokenize, càng nhiều token sẽ được tạo ra vì tokenizer bị buộc phải chia văn bản tự nhiên thành nhiều token nhỏ hơn, tổng quát hơn. Thuộc tính này đã cho phép chúng tôi phát hiện lỗi liên quan đến giá trị outlier, chẳng hạn như ngôn ngữ được phân loại không chính xác, hoặc lỗi crawling. Trong phân tích sau, chúng tôi sử dụng nó theo hai cách: đầu tiên, chúng tôi có thể sử dụng các tokenizer được huấn luyện trên các kho dữ liệu khác nhau để xem kho dữ liệu của chúng tôi khác biệt như thế nào với chúng; và thứ hai, chúng tôi có thể sử dụng một tokenizer được huấn luyện trên kho dữ liệu này để đánh giá thành phần nào là outlier. Chúng tôi loại trừ các outlier nhỏ hơn 5 tài liệu.

Hình 8: Token trên mỗi byte cho mỗi thành phần tiếng Pháp, tiếng Trung Giản thể và tiếng Ả Rập cho các tokenizer được huấn luyện trên kho dữ liệu này. Giá trị thấp hơn có nghĩa là thành phần (trục X) tương tự hơn trong tổng thể với phần còn lại của kho dữ liệu.

Hình 7 cho thấy đo lường token-per-byte trên các bộ dữ liệu thành phần tiếng Anh cho tokenizer BLOOM, được huấn luyện trên kho dữ liệu này, tokenizer GPT-NeoX 20B (Black et al., 2022), được huấn luyện trên the Pile, và tokenizer T5 (Raffel et al., 2020), được huấn luyện trên C4. Những tokenizer đó có thể khác nhau về thuật toán và/hoặc kích thước từ vựng, nhưng chúng tôi sẽ không so sánh trực tiếp chúng với nhau.

Hình được sắp xếp theo giá trị token-per-byte của tokenizer BLOOM, cho thấy rằng thứ tự rất giống nhau cho BLOOM và GPT-NeoX. Tuy nhiên, nó cho thấy một số bump cho T5: các bộ dữ liệu thành phần nằm ngoài miền trong C4 nhưng không phải kho dữ liệu của chúng tôi, ví dụ các bộ dữ liệu kỹ thuật và học thuật như s2orc hoặc royal_society_corpus, các miền vắng mặt khỏi dữ liệu có nguồn gốc Common Crawl của C4. Các bộ dữ liệu khác như vậy bao gồm global_voices, chứa tin tức về các khu vực không nói tiếng Anh bao gồm trích dẫn bằng ngôn ngữ gốc và no_code_stackexchange, chứa các diễn đàn mà, mặc dù bằng tiếng Anh, có thể được dành cho các vấn đề kỹ thuật, ngôn ngữ nước ngoài, hoặc các miền rất cụ thể. Cả hai đều tương tự với kho dữ liệu của chúng tôi nhưng không với the Pile hoặc C4.

Hình 8 bổ sung cho thấy fertility BLOOM cho các thành phần tiếng Trung Giản thể, tiếng Pháp và tiếng Ả Rập. Các thành phần outlier, fertility cao, ví dụ: các bộ dữ liệu khác biệt với phần còn lại của kho dữ liệu của chúng tôi, có xu hướng giống nhau cho tất cả ngôn ngữ. project_gutenberg chứa sách cũ với định dạng gốc của chúng (ví dụ, "***********" để biểu thị kết thúc trang). wiktionary chứa định nghĩa của từ bằng ngôn ngữ nước ngoài. wikiversity chứa thuật ngữ kỹ thuật và LATEX. wikivoyage chứa bảng được định dạng như văn bản. Diễn đàn có thể chứa thông tin người dùng và ngày của tin nhắn, cũng như slang internet hoặc emoji. arabench là tiếng Ả Rập nói, và habibi là tiếng Ả Rập cổ điển với nhiều dấu phụ hơn tiếng Ả Rập hiện đại. Chúng tôi coi hầu hết những sai lệch đó là có thể chấp nhận để đại diện cho sự đa dạng của việc sử dụng văn bản, mà phân tích tokenizer có thể nổi lên từ phần còn lại của bộ dữ liệu.

5 Kết luận

Chúng tôi đã trình bày ROOTS, một kho dữ liệu đa ngôn ngữ khổng lồ là kết quả của sự hợp tác quốc tế giữa các nhà nghiên cứu đa ngành nghiên cứu các mô hình ngôn ngữ lớn. Các nỗ lực để tập hợp kho dữ liệu được hướng dẫn bởi giá trị và được thúc đẩy bởi cách tiếp cận ưu tiên dữ liệu để huấn luyện mô hình BLOOM. Chúng tôi tiếp tục phát hành công cụ được phát triển trong suốt dự án, và hiện đang thực hiện chiến lược phát hành được thông báo bởi cả nhu cầu cấp phép và quản trị của mỗi nguồn dữ liệu cho chính kho dữ liệu. Chúng tôi hy vọng điều này mở đường cho việc sử dụng dữ liệu phản ánh hơn để đưa vào các mô hình ngôn ngữ lớn.

Tuyên bố Cân nhắc Đạo đức và Tác động Rộng hơn

Như đã thảo luận trong Phần 1, Hội thảo Nghiên cứu BigScience được hình thành như một nỗ lực hợp tác và hướng theo giá trị từ đầu. Cách tiếp cận này đã định hình nhiều quyết định được mô tả trong bài báo này, thúc đẩy nhiều cuộc thảo luận theo ngữ cảnh và tìm kiếm sự đồng thuận về cách phát biểu các giá trị cốt lõi của dự án, những giá trị của những người đóng góp vào các nỗ lực dữ liệu, và cân nhắc về tác động xã hội đối với những người bị ảnh hưởng trực tiếp và gián tiếp. Đặc biệt liên quan là chiến lược phát hành và quản trị dữ liệu, lựa chọn tập trung vào việc lựa chọn dữ liệu của con người trong khi vẫn sử dụng OSCAR được crawl từ web cho một phần đáng kể của kho dữ liệu, và các công cụ chúng tôi phát triển để quản lý rủi ro của cái sau (bao gồm liên quan đến quyền riêng tư). Mỗi trong số này là dịp của các bài tập đạo đức và đóng góp kỹ thuật mà chúng tôi tin là hữu ích và cần thiết, và mỗi cái sẽ đòi hỏi nghiên cứu và tiến bộ hơn nữa. Chúng tôi cung cấp một cuộc thảo luận chi tiết hơn về những khía cạnh này của công việc của chúng tôi trong Phụ lục A.

Lời cảm ơn

BigScience. Công việc này được theo đuổi như một phần của hội thảo nghiên cứu BigScience, một nỗ lực hợp tác để xây dựng một mô hình ngôn ngữ mạng thần kinh đa ngôn ngữ rất lớn và một bộ dữ liệu văn bản đa ngôn ngữ rất lớn. Nỗ lực này tập hợp 1000+ nhà nghiên cứu từ 60 quốc gia và từ hơn 250 tổ chức.

Tính toán. Hội thảo BigScience được cấp quyền truy cập vào tài nguyên HPC của Institut du développement et des ressources en informatique scientifique (IDRIS) du Centre national de la recherche scientifique (CNRS) dưới phân bổ 2021-A0101012475 được thực hiện bởi Grand équipement national de calcul intensif (GENCI). Huấn luyện mô hình chạy trên cluster Jean-Zay của IDRIS, và chúng tôi cảm ơn đội IDRIS vì sự hỗ trợ đáp ứng của họ trong suốt dự án, đặc biệt là Rémi Lacroix.

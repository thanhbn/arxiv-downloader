# 2209.09900.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/multilingual/2209.09900.pdf
# Kích thước tệp: 657844 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
LINGUIST: Tinh chỉnh Mô hình Ngôn ngữ theo Hướng dẫn để Tạo ra Các Phát ngôn Được Chú thích cho Phân loại Ý định và Gắn thẻ Slot
Andy Rosenbaum
Amazon, Cambridge, USA
andros@amazon.com
Saleh Soltan
Amazon, New York, USA
ssoltan@amazon.com
Wael Hamza
Amazon, Dallas, USA
waelhamz@amazon.com
Yannick Versley
Amazon, Aachen, Germany
yversley@amazon.de
Markus Boese
Amazon, Aachen, Germany
boesem@amazon.de

Tóm tắt
Chúng tôi trình bày LINGUIST, một phương pháp tạo ra dữ liệu được chú thích cho Phân loại Ý định và Gắn thẻ Slot (IC+ST), thông qua việc tinh chỉnh AlexaTM 5B, một mô hình chuỗi-sang-chuỗi (seq2seq) đa ngôn ngữ 5 tỷ tham số, trên một lời nhắc hướng dẫn linh hoạt. Trong thiết lập ý định mới 10-shot cho bộ dữ liệu SNIPS, LINGUIST vượt trội hơn các phương pháp hiện đại (Back-Translation và Example Extrapolation) với cách biệt lớn, cho thấy cải thiện tuyệt đối cho các ý định mục tiêu +1.9 điểm trên IC Recall và +2.5 điểm trên ST F1 Score. Trong thiết lập zero-shot đa ngôn ngữ của bộ dữ liệu mATIS++, LINGUIST vượt trội hơn baseline mạnh của Machine Translation với Slot Alignment +4.14 điểm tuyệt đối trên ST F1 Score trên 6 ngôn ngữ, đồng thời duy trì hiệu suất trên IC. Cuối cùng, chúng tôi xác minh kết quả của chúng tôi trên một bộ dữ liệu đa ngôn ngữ quy mô lớn nội bộ cho IC+ST của tác nhân hội thoại và cho thấy những cải thiện đáng kể so với baseline sử dụng Back-Translation, Paraphrasing và Slot Catalog Resampling. Theo hiểu biết của chúng tôi, chúng tôi là những người đầu tiên chứng minh việc tinh chỉnh hướng dẫn của một mô hình seq2seq quy mô lớn để kiểm soát đầu ra của việc tạo ra dữ liệu có nhãn ý định và slot đa ngôn ngữ.

1 Giới thiệu
Các tác nhân hội thoại thường dựa vào lượng lớn dữ liệu huấn luyện được gán nhãn để hiểu các yêu cầu của người dùng thông qua Phân loại Ý định và Gắn thẻ Slot (IC+ST) (Tur và De Mori, 2011). Dữ liệu như vậy dồi dào cho các mẫu sử dụng hiện có (mặc dù tốn kém để chú thích), nhưng khan hiếm cho các ý định/slot mới và ngôn ngữ mới. Một xu hướng ngày càng tăng để giải quyết vấn đề này là tạo ra dữ liệu huấn luyện tổng hợp, ví dụ thông qua Paraphrasing, Back-Translation (BT), thay thế slot, và Example Extrapolation (Ex2). (Jolly et al., 2020; Xie et al., 2020; Zhang et al., 2020; Lee et al., 2021). Trong công trình này, chúng tôi đề xuất một phương pháp tạo dữ liệu mới có tên là Language model INstruction tuning to Generate annotated Utterances for Intent classification and Slot Tagging (LINGUIST).

Phương pháp LINGUIST của chúng tôi giải quyết một số khoảng trống quan trọng trong tài liệu hiện có: (1) kiểm soát dữ liệu được tạo ra để bao gồm các loại slot và giá trị cụ thể, (2) tạo dữ liệu đa ngôn ngữ và xuyên ngôn ngữ, và (3) khả năng tận dụng tên ý định và slot để thông báo cho việc tạo ra. Chìa khóa cho những thành tựu này là thiết kế của chúng tôi về một lời nhắc hướng dẫn mới (Hình 1), bao gồm các mô tả ngôn ngữ tự nhiên cho các đầu ra mong muốn của mô hình. Đầu tiên, chúng tôi tinh chỉnh một mô hình Transformer seq2seq được tiền huấn luyện lớn (Vaswani et al., 2017) để học cách tạo ra các phát ngôn được chú thích theo hướng dẫn của lời nhắc. Sau đó, đối với một ý định hoặc slot mới chỉ có một vài hoặc thậm chí không có ví dụ huấn luyện, chúng tôi áp dụng mô hình để tạo ra dữ liệu tương tự, mà chúng tôi thêm vào tập huấn luyện cho một mô hình IC+ST.

Chúng tôi chứng minh hiệu quả của LINGUIST trên ba bộ dữ liệu bằng cách cho thấy những cải thiện đáng kể so với các baseline mạnh. (i) Trên thiết lập ý định mới 10-shot với SNIPS tiếng Anh (Coucke et al., 2018), LINGUIST cải thiện so với Back-Translation và Ex2 +1.9 điểm tuyệt đối trên IC và +2.5 điểm tuyệt đối trên ST. (ii) Trên mATIS++ xuyên ngôn ngữ (Xu et al., 2020), LINGUIST vượt trội hơn Machine Translation tốt nhất cộng với slot alignment được báo cáo bởi Xu et al., +4.14 điểm trong ST trên 6 ngôn ngữ, đồng thời duy trì hiệu suất trên IC. (iii) Cuối cùng, để chứng minh sự thành công của phương pháp chúng tôi trên một hệ thống tác nhân hội thoại thực tế, chúng tôi áp dụng LINGUIST trên một bộ dữ liệu nội bộ chứa hàng trăm ý định và loại slot trên 4 ngôn ngữ, và cho thấy những cải thiện lớn so với baseline sử dụng Back-Translation và Paraphrasing.

Chúng tôi cũng cho thấy LINGUIST có thể tạo ra dữ liệu được chú thích IC+ST từ không có ví dụ nào, chỉ sử dụng tên nhãn ý định và slot bằng ngôn ngữ tự nhiên. LINGUIST đạt được 80.0 IC Recall và 56.9 ST F1 Score trên các ý định SNIPS mới mặc dù chưa bao giờ nhìn thấy một ví dụ duy nhất cho các ý định mới. Theo hiểu biết của chúng tôi, LINGUIST là hệ thống đầu tiên có khả năng tạo ra dữ liệu được chú thích IC+ST trong thiết lập này.

2 Công trình liên quan
Các Mô hình Ngôn ngữ Quy mô lớn (LLM) như GPT (Radford et al., 2019; Brown et al., 2020) và AlexaTM 20B (Soltan et al., 2022) vượt trội trong việc thực hiện các nhiệm vụ mới chỉ với một vài ví dụ thông qua học trong ngữ cảnh, tức là không yêu cầu bất kỳ cập nhật tham số mô hình nào. Ví dụ, Sahu et al. (2022) áp dụng GPT-3 để tạo ra các biến thể của các ví dụ từ một lớp nhất định. Wang et al. (2021) tạo ra cả văn bản và nhãn lớp cùng nhau thông qua GPT-3, hướng tới việc loại bỏ nhu cầu gán nhãn bởi con người.

Tiền huấn luyện sau đó tinh chỉnh các mô hình seq2seq được giới thiệu trong BART tiếng Anh và mBART đa ngôn ngữ (Lewis et al., 2020a; Liu et al., 2020). T5 và mT5 (Raffel et al., 2020; Xue et al., 2021) mở rộng ý tưởng bằng cách định khung nhiều nhiệm vụ hạ nguồn dưới dạng văn bản-sang-văn bản. FLAN (Wei et al., 2022) giới thiệu tinh chỉnh hướng dẫn, nơi một mô hình seq2seq quy mô lớn được tinh chỉnh trên các lời nhắc hướng dẫn từ nhiều nhiệm vụ khác nhau, để tổng quát hóa cho các nhiệm vụ mới mà không cần bất kỳ cập nhật tham số nào nữa.

Công trình trước đó cũng khám phá việc điều kiện hóa việc tạo ra dựa trên nhãn ý định và slot. Ding et al. (2020) huấn luyện một mô hình ngôn ngữ có điều kiện trên hỗn hợp văn bản được chú thích và không được chú thích, cho phép lấy mẫu các phát ngôn được chú thích mới. Malandrakis et al. (2019) huấn luyện một mô hình seq2seq từ các cặp diễn giải-văn bản, áp dụng bộ mã hóa tự động biến phân để có thêm sự đa dạng. Jolly et al. (2020) mở rộng điều này, khám phá các chiến lược lấy mẫu khác nhau, thêm sự đa dạng bằng cách xáo trộn tên slot, và kiểm tra hành vi nơi một ý định mới được giới thiệu với dữ liệu huấn luyện hạn chế. Panda et al. (2021) mở rộng điều này sang thiết lập đa ngôn ngữ. Generative Insertion Transformers (Kumar et al., 2022) tạo ra các cụm từ mang theo cho một ý định mục tiêu và chứa các thực thể cụ thể. Một hạn chế của tất cả các phương pháp này là mô hình được huấn luyện không thể tổng quát hóa cho các ý định và slot mới tại thời điểm suy luận.

Generative Conversational Networks (Papangelis et al., 2021) được huấn luyện thông qua học tăng cường để tạo ra dữ liệu được chú thích từ các ví dụ khởi tạo, nghiên cứu IC+ST tiếng Anh và các nhiệm vụ khác.

Người họ hàng gần nhất của LINGUIST là Example Extrapolation (Ex2) (Lee et al., 2021), cũng tạo ra dữ liệu IC+ST được chú thích sử dụng một mô hình seq2seq và các ví dụ khởi tạo được cung cấp. Chúng tôi so sánh LINGUIST và Ex2 chi tiết hơn trong phần 3.3.

Một phương pháp paraphrasing được sử dụng rộng rãi là Back-Translation (BT), tức là dịch văn bản từ một ngôn ngữ sang ngôn ngữ "pivot" khác, sau đó dịch ngược lại. Bannard và Callison-Burch (2005) trích xuất paraphrases trực tiếp từ các corpus song song. Sennrich et al. (2016) và Edunov et al. (2018) sử dụng BT cho Machine Translation và Xie et al. (2020) cho tăng cường dữ liệu trên các nhiệm vụ phân loại.

Các phương pháp khác nhắm trực tiếp vào nhiệm vụ Paraphrasing: Prakash et al. (2016) học một mô hình LSTM bằng huấn luyện có giám sát trên một corpus paraphrase, trong khi Kumar et al. (2020) sử dụng một nhiệm vụ khử nhiễu không giám sát, trong cả hai trường hợp chỉ sử dụng văn bản và không bao gồm nhãn slot. Cho et al. (2019) khám phá Paraphrasing thông qua Semi-Supervised Learning.

Một phương pháp khác để tăng cường dữ liệu là thay thế token: SeqMix (Zhang et al., 2020) thay thế token bằng láng giềng gần nhất trong không gian embedding, Dai và Adel (2020) thay thế slot bằng từ đồng nghĩa, hoặc đề cập từ các instance khác của cùng một nhãn. Easy Data Augmentation (Wei và Zou, 2019) bao gồm thay thế từ đồng nghĩa, chèn ngẫu nhiên, hoán đổi ngẫu nhiên, và xóa ngẫu nhiên cho nhiệm vụ phân loại. Zheng et al. (2021) benchmark sự thành công của LLM trên thiết lập few-shot.

3 Mô hình Tạo Dữ liệu LINGUIST
LINGUIST cung cấp ba đổi mới chính so với công trình tạo dữ liệu trước đó: (1) kiểm soát các loại slot và giá trị (do người dùng cung cấp hoặc do mô hình tạo ra) để bao gồm trong các đầu ra; (2) tạo ra đa ngôn ngữ và xuyên ngôn ngữ; và (3) khả năng tận dụng tên nhãn ngôn ngữ tự nhiên để thông báo cho việc tạo ra, cho phép thiết lập "Chỉ Tên Nhãn" mới (Phần 4.2.2).

3.1 Thiết kế Lời nhắc LINGUIST
Chúng tôi kiểm soát đầu ra tạo ra thông qua một sơ đồ prompting mới, như được hiển thị trong Hình 1. Lời nhắc chứa năm khối: (i) <language> đầu ra, (ii) tên <intent>, (iii) loại slot và giá trị nào cần <include> trong đầu ra, (iv) ánh xạ từ <labels> sang số, và (v) tối đa 10 <examples>, mỗi cái thuộc về cùng một ý định, và bao gồm không hoặc nhiều nhãn có sẵn.

Khối <include> hướng dẫn LINGUIST loại slot và giá trị nào cần tạo ra, chẳng hạn như [3 snow], nơi số tương ứng với loại slot (trong trường hợp này, [3=condition_description), và nội dung bên trong dấu ngoặc là giá trị cần sử dụng cho slot đó (ở đây là "snow"). Để tăng sự đa dạng của đầu ra, người dùng cũng có thể hướng dẫn mô hình tạo ra một giá trị cho một slot, sử dụng token "wildcard" *, ví dụ [1*] chỉ ra rằng mô hình nên lấy mẫu một giá trị cho slot số 1.

Như được hiển thị trong Hình 1, LINGUIST học để tạo ra một mẫu phong phú của các giá trị ngay cả đối với các ý định và loại slot mà nó chưa bao giờ nhìn thấy trong quá trình tinh chỉnh. Ví dụ, trong trường hợp này wildcard dành cho [1=geographic_poi và mô hình đầu ra các giá trị hợp lý như "Lake Tahoe", mặc dù cụm từ này chưa bao giờ xuất hiện trong dữ liệu tinh chỉnh.

3.2 Huấn luyện mô hình LINGUIST
Chúng tôi tinh chỉnh một mô hình seq2seq được tiền huấn luyện trên các cặp lời nhắc hướng dẫn LINGUIST và các phát ngôn mục tiêu được chú thích tương ứng, được rút ra từ một bộ dữ liệu nhiệm vụ IC+ST đã loại bỏ trùng lặp R. Cụ thể, chúng tôi định dạng một lời nhắc hướng dẫn pi nhắm vào mỗi phát ngôn ti∈R, bao gồm trong pi tối đa 10 phát ngôn ví dụ khác E={ej}j=1^10⊆R s.t. ∀j; ej≠ti và intent(ej)=intent(ti). Để làm cho việc tạo ra mạnh mẽ với số lượng ví dụ được cung cấp, chúng tôi không luôn bao gồm tất cả 10 trong lời nhắc, mà thay vào đó chọn ngẫu nhiên k ví dụ từ E, với k được chọn ngẫu nhiên giữa 0 và 10, hoặc số lượng phát ngôn có sẵn chia sẻ cùng ý định với ti, cái nào nhỏ hơn. Chúng tôi không bao giờ nhân đôi phát ngôn trong lời nhắc. Cuối cùng, chúng tôi tạo ra một corpus các lời nhắc huấn luyện bằng kích thước với tập huấn luyện IC+ST ban đầu.

Để giảm xu hướng mô hình overfit trên các nhãn ý định và slot (như quan sát bởi Lee et al., 2021), chúng tôi loại bỏ tên nhãn cho cả hai với tỷ lệ 0.2, thay thế tên nhãn ví dụ GetWeather bằng một chuỗi ngẫu nhiên từ 1 đến 5 chữ cái như A_Q_Y. (Ablation trong Phụ lục E.) Trực giác cho việc che mặt các nhãn thay vì bỏ qua các khối <intent> và <labels> là cung cấp cho mô hình một tín hiệu nhất quán cho position embeddings, và luôn cho phép nó chú ý đến các thẻ này nếu muốn.

Để cùng lúc dạy mô hình cả sao chép các giá trị slot do người dùng cung cấp như [3 snow] và tạo ra các giá trị phù hợp cho wildcard [1*], chúng tôi định dạng các lời nhắc huấn luyện với các ví dụ của cả hai. Đối với lời nhắc pi nhắm vào phát ngôn ti, chúng tôi chọn ngẫu nhiên từ phân phối Hình học dGeo(0:5) (0≤d≤# slots trong ti) slots và thay thế giá trị của chúng bằng "*" trong khối <include> của lời nhắc. Hiệu ứng là khoảng 50% phát ngôn có tất cả giá trị slot được thay thế bằng token wildcard, 25% phát ngôn giữ một giá trị slot, v.v.

Chúng tôi không thêm các thẻ <intent>, [1, v.v. vào từ vựng tokenizer sentencepiece (Kudo và Richardson, 2018) của mô hình (Phụ lục C.2).

3.3 So sánh LINGUIST với Ex2
Người họ hàng gần nhất với phương pháp của chúng tôi là Example Extrapolation (Ex2, Lee et al., 2021), cũng tạo ra văn bản có nhãn slot từ các ví dụ khởi tạo. Tính mới của LINGUIST so với Ex2 là ba mặt: (i) hướng dẫn để kiểm soát các loại slot và giá trị được tạo ra, (ii) đa ngôn ngữ và xuyên ngôn ngữ, và (iii) khả năng bao gồm tên nhãn và slot trong lời nhắc. Đặc biệt, EX2 cho thấy rằng việc ẩn danh các nhãn cải thiện IC nhưng làm hại ST. Mô hình LINGUIST của chúng tôi cải thiện so với việc triển khai Ex2 của chúng tôi trên cả IC và ST, và hơn nữa các nhãn cho phép LINGUIST thực hiện one-shot và zero-shot cho các ý định và slot mới, như chúng tôi cho thấy trong Phần 5.1.3 và Phụ lục B.

4 Thiết lập Thí nghiệm
Phần này mô tả các bộ dữ liệu, nhiệm vụ, mô hình IC+ST, các phương pháp tạo dữ liệu baseline, và các metric mà chúng tôi sử dụng để đánh giá LINGUIST.

4.1 Bộ dữ liệu
4.1.1 Bộ dữ liệu SNIPS
Bộ dữ liệu SNIPS (Coucke et al., 2018) là một benchmark IC+ST công khai gồm 7 ý định, mỗi ý định có từ 2 đến 14 loại slot (39 loại slot duy nhất tổng cộng). Nó bao gồm khoảng 2k phát ngôn huấn luyện và 100 phát ngôn validation cho mỗi ý định. Để tránh overfit phương pháp của chúng tôi trên tập validation nhỏ, ở đầu thí nghiệm, chúng tôi phân chia tập huấn luyện thành 97% Train và 3% Development. Chúng tôi sử dụng tập Development split để lặp lại tất cả các quyết định mô hình hóa và xử lý dữ liệu, bao gồm các siêu tham số cho LINGUIST và siêu tham số và lựa chọn checkpoint tốt nhất cho việc tinh chỉnh encoder trên IC+ST. Chỉ ở cuối thí nghiệm, chúng tôi đánh giá và báo cáo trên tập Validation. Xem Bảng 1 cho số lượng phát ngôn Train/Dev/Valid.

4.1.2 Multilingual ATIS++
Đối với các thí nghiệm xuyên ngôn ngữ, chúng tôi đánh giá trên mATIS++ (Xu et al., 2020), bao gồm văn bản và chú thích được dịch bởi con người từ các yêu cầu thông tin du lịch ATIS tiếng Anh gốc (Hemphill et al., 1990) cộng với các bản dịch tiếng Hindi và Thổ Nhĩ Kỳ từ mATIS (Upadhyay et al., 2018). Thí nghiệm của chúng tôi bao gồm 7 ngôn ngữ mà mATIS++ chia sẻ với mô hình được tiền huấn luyện của chúng tôi: tiếng Anh, Tây Ban Nha, Đức, Pháp, Bồ Đào Nha, Nhật Bản, và Hindi, với 4488 (HI: 1440) phát ngôn huấn luyện bao gồm 18 (HI: 17) ý định và 84 (HI: 75) slots.

Để chứng minh khả năng thích ứng miền chéo của phương pháp LINGUIST, chúng tôi sử dụng bộ dữ liệu MASSIVE (FitzGerald et al., 2022b) bao gồm 51 ngôn ngữ với các phiên bản song song của các phát ngôn SLU Resource Package (chỉ tiếng Anh) (Bastianelli et al., 2020), bao gồm 20k phát ngôn mỗi ngôn ngữ trên 18 domains, 60 ý định và 55 slots. Chúng tôi chỉ sử dụng MASSIVE để huấn luyện một mô hình LINGUIST, sau đó áp dụng mô hình cho mATIS++. Để giữ mATIS++ như một domain mới, chúng tôi loại trừ domain transport có phần liên quan từ MASSIVE khi chúng tôi huấn luyện mô hình LINGUIST.

4.1.3 Bộ dữ liệu Nội bộ
Để chứng minh giá trị của phương pháp chúng tôi trong thiết lập thế giới thực, chúng tôi benchmark trên một bộ dữ liệu đa ngôn ngữ quy mô lớn nội bộ đại diện cho các yêu cầu đến một tác nhân hội thoại. Chúng tôi xem xét năm phần của bộ dữ liệu, được gọi là features, cụ thể là: CameraControl, ClockSettings, HomeSecurity, Music, và Timers, mỗi cái chứa một hoặc nhiều ý định, và một hoặc nhiều slot liên kết. Đối với mỗi feature, có một tập huấn luyện "starter" gồm vài chục phát ngôn được chú thích được tuyển chọn cho feature mới, và một tập test chứa hàng trăm phát ngôn được chú thích liên quan đến feature mới đó. Ngoài ra, có một bộ dữ liệu huấn luyện lớn E các phát ngôn được chú thích từ các features hiện có. Dữ liệu huấn luyện Existing Features E không chứa ví dụ của bất kỳ features mới nào.

4.2 Nhiệm vụ Đánh giá
4.2.1 New-Intent Few-Shot (NIFS)
Như được hiển thị trong Hình 2, chúng tôi mô phỏng việc giới thiệu một ý định mới vào một bộ dữ liệu hiện có có tài nguyên tốt. Cho một bộ dữ liệu huấn luyện R=∪j=1^m Dj chứa dữ liệu Dj cho các ý định j=1:...m, chúng tôi chọn một ý định i∈{1,...,m}, và giảm dữ liệu huấn luyện của nó xuống chỉ còn một số lượng nhỏ K phát ngôn "starter" Si⊆Di. Chúng tôi áp dụng các kỹ thuật tăng cường dữ liệu khác nhau trên Si để tạo ra dữ liệu tăng cường Ai. Cuối cùng, chúng tôi huấn luyện một mô hình IC+ST sử dụng R'i=Si∪Ai∪{Dj}j≠i, tức là sự kết hợp của dữ liệu starter và tăng cường cho ý định i với dữ liệu không thay đổi cho tất cả các ý định khác.

Bộ dữ liệu nội bộ đã được phân chia theo cách này, tuy nhiên ở cấp độ feature thay vì cấp độ ý định. Đối với SNIPS, chúng tôi tạo ra 7 thiết lập NIFS, một cho mỗi ý định, giảm dữ liệu huấn luyện của nó xuống chỉ còn K=10 phát ngôn starter Si. Chúng tôi tạo ra 5 phiên bản, mỗi phiên bản với một seed ngẫu nhiên khác nhau để chọn Si, và luôn bao gồm ít nhất một ví dụ cho tất cả các loại slot xuất hiện cho ý định i.

Để chứng minh khả năng tổng quát hóa của LINGUIST cho các ý định và slot mới tại thời điểm suy luận, chúng tôi loại trừ các phát ngôn starter của ý định mới khỏi tinh chỉnh. Đối với mỗi ý định i, chúng tôi huấn luyện một mô hình LINGUIST trên 6 ý định khác {Dj}j≠i. Sau đó, trong quá trình suy luận, chúng tôi định dạng lời nhắc với các phát ngôn starter giữa <example> và </example>, và tạo ra thêm dữ liệu. Lưu ý, bước tạo ra này không yêu cầu bất kỳ cập nhật tham số mô hình nào.

4.2.2 NIFS Label Names Only (LNO)
Trong biến thể thử thách hơn này của NIFS, chỉ có tên nhãn ý định và slot cho các phát ngôn starter, không có văn bản hoặc chú thích của chúng. Điều này hữu ích khi phát triển các ý định mới vì chúng tôi chỉ cần chỉ định loại slot nào có thể đi cùng nhau, và không cần tuyển chọn hoặc chú thích bất kỳ ví dụ thực nào. Đáng chú ý, theo hiểu biết tốt nhất của chúng tôi, LINGUIST là hệ thống đầu tiên có khả năng tạo ra dữ liệu được chú thích ý định và slot trong thiết lập này (như được hiển thị trong Hình A4, Phụ lục B.1.4), bằng cách chú ý đến tên nhãn ngôn ngữ tự nhiên trong lời nhắc.

4.2.3 Zero-Shot Cross-Lingual
Đối với mATIS++, chúng tôi đánh giá trong thiết lập zero-shot xuyên ngôn ngữ, nơi dữ liệu huấn luyện thực chỉ có sẵn cho tiếng Anh. Chúng tôi tinh chỉnh một mô hình IC+ST trên dữ liệu huấn luyện tiếng Anh cộng với bất kỳ ví dụ tăng cường nào được tạo ra từ dữ liệu này, và đánh giá mô hình trên các tập test từ tất cả ngôn ngữ.

4.3 Mô hình
Các thí nghiệm của chúng tôi dựa trên hai mô hình được tiền huấn luyện: (1) AlexaTM 5B (được mô tả tiếp theo trong Phần 4.3.1) mà chúng tôi tinh chỉnh trên các lời nhắc LINGUIST và sử dụng nó để tạo ra dữ liệu huấn luyện IC+ST, và (2) xlm-roberta-base mà chúng tôi tinh chỉnh trên nhiệm vụ IC+ST bao gồm dữ liệu được tạo ra từ LINGUIST.

4.3.1 AlexaTM 5B
AlexaTM 5B là một mô hình Transformer seq2seq đa ngôn ngữ (Vaswani et al., 2017) được tiền huấn luyện tương tự như AlexaTM 20B (Soltan et al., 2022), tuy nhiên chỉ với mục tiêu khử nhiễu (tức là không có mục tiêu Causal Language Modeling). Giống như AlexaTM 20B, kiến trúc được rút ra từ lớp HuggingFace (Wolf et al., 2020) BART (Lewis et al., 2020b), và bao gồm 29 lớp encoder và 24 lớp decoder, chiều ẩn 2560, và 32 attention heads. Mô hình được huấn luyện trên 900B tokens của Wikipedia và mC4 (Xue et al., 2021) của 12 ngôn ngữ như được sử dụng trong AlexaTM 20B. Chúng tôi sử dụng độ dài chuỗi tối đa là 512 và kích thước batch là 1M tokens. Trọng số encoder của AlexaTM 5B được khởi tạo với encoder Alexa Teacher Model 2.3B-parameter (FitzGerald et al., 2022a) được huấn luyện trên nhiệm vụ MLM trên cùng dữ liệu, đóng băng trong nửa đầu của việc tiền huấn luyện AlexaTM 5B. Các siêu tham số được sử dụng để tinh chỉnh AlexaTM 5B trên LINGUIST được mô tả trong Phụ lục C.

4.3.2 Tinh chỉnh IC+ST
Đối với SNIPS và mATIS++, theo Chen et al. (2019), chúng tôi tinh chỉnh một mô hình kiểu BERT cho IC+ST kết hợp. Trên đầu các trạng thái ẩn của encoder, chúng tôi đính kèm hai head phân loại riêng biệt, một cho IC và một cho ST. Mỗi head bao gồm hai lớp của 256 chiều ẩn, với kích hoạt gelu, dropout 0.2, và layer norm. Head IC sử dụng biểu diễn từ token đầu tiên của chuỗi ([CLS]), trong khi head ST sử dụng token subword đầu tiên của mỗi từ.

Đối với encoder của chúng tôi, chúng tôi sử dụng xlm-roberta-base (Conneau et al., 2020) (12 lớp, 768 chiều ẩn), từ việc triển khai HuggingFace (Wolf et al., 2020). Chúng tôi tinh chỉnh với kích thước batch 128 cho 3k cập nhật (tức là 30 epochs cho dữ liệu kích thước đầy đủ). Chúng tôi đóng băng lớp embedding; tất cả các tham số khác tự do cập nhật trong quá trình huấn luyện. Chúng tôi sử dụng Adam (Kingma và Ba, 2015) với tỷ lệ học đỉnh 3e-5, tăng tuyến tính từ 0 đến 600 cập nhật, sau đó giảm tuyến tính về 0 cho đến hết huấn luyện.

Để tránh over-fitting trên bộ dữ liệu SNIPS Validation chính thức, chúng tôi sử dụng tách Development của chúng tôi (Phần 4.1.1) để dừng sớm, chọn checkpoint với hiệu suất tốt nhất trên ST. Tất cả các lần chạy tinh chỉnh IC+ST của chúng tôi cho SNIPS sử dụng các siêu tham số giống hệt nhau, bất kể phương pháp tạo dữ liệu nào được khám phá. Đối với mỗi phương pháp tạo dữ liệu, chúng tôi huấn luyện và test 7 mô hình IC+ST kết hợp khác nhau {Mi}i=1^7 trong thiết lập NIFS: mỗi mô hình sử dụng sự kết hợp của dữ liệu đã sửa đổi cho ý định i, và dữ liệu không thay đổi cho tất cả các ý định khác.

Đối với mATIS++, chúng tôi theo cùng thiết lập kiến trúc mô hình và huấn luyện cho 2k cập nhật (64 epochs cho dữ liệu chỉ tiếng Anh, hoặc 9 epochs khi sử dụng dữ liệu từ tất cả 7 ngôn ngữ.) Chúng tôi chọn checkpoint với ST F1 Score tốt nhất chỉ trên tập dev tiếng Anh.

Đối với benchmark nội bộ của chúng tôi, chúng tôi sử dụng các thiết lập tương tự, tuy nhiên với một encoder dựa trên Transformer nội bộ nhỏ hơn để tinh chỉnh trên nhiệm vụ IC+ST.

4.4 Các Phương pháp Tạo Dữ liệu Baseline
Interpretation-Conditioned Language Model (ICLM) Jolly et al. (2020) tạo ra văn bản không nhãn có điều kiện trên ý định và giá trị slot được cung cấp, với một bước chiếu nhãn riêng biệt để khôi phục chú thích slot đầy đủ. ICLM không tạo ra giá trị slot mới. Việc triển khai của chúng tôi sử dụng một kiến trúc Transformer nhỏ (Vaswani et al., 2017) với 37M tham số, và một phép đo khoảng cách Levenshtein cấp độ ký tự đơn giản để chiếu các nhãn slot. Chúng tôi tạo ra 50 đầu ra cho mỗi đầu vào, sau đó lọc/loại bỏ trùng lặp (xem Phụ lục J).

Chúng tôi áp dụng Back-Translation (BT) sử dụng hai hệ thống MT riêng biệt để hiển thị ảnh hưởng của mô hình dịch. Thứ nhất sử dụng bộ công cụ Sockeye mã nguồn mở (Hieber et al., 2018) và một Transformer nhỏ (91M tham số) đã được tinh chỉnh trên khoảng 10k phát ngôn dữ liệu song song được chú thích. Chúng tôi sử dụng fast_align (Dyer et al., 2013) để chiếu các nhãn slot lên các phát ngôn được tạo ra. Chúng tôi gọi hệ thống này là "BT-Small". Chúng tôi sử dụng M=1 bản dịch tiến và N=10 bản dịch ngược để có được 10 paraphrases, và sau đó lọc và loại bỏ trùng lặp (xem Phụ lục K). Chúng tôi sử dụng tiếng Pháp (SNIPS) hoặc tiếng Anh (Nội bộ) tương ứng làm ngôn ngữ pivot.

Đối với baseline BT mạnh hơn "BT-5B", chúng tôi xây dựng một hệ thống MT bằng cách tinh chỉnh AlexaTM 5B trên WMT14 (được lấy từ HuggingFace datasets) kết hợp trên en→fr và fr→en sử dụng lời nhắc hướng dẫn (tiền tố văn bản đầu vào với Translate to French: hoặc Translate to English:, tương ứng) để kiểm soát hướng dịch. Chúng tôi sử dụng SimAlign (Jalili Sabet et al., 2020) để chiếu các nhãn slot lên văn bản paraphrased. Đối với SNIPS, chúng tôi sử dụng tiếng Pháp làm ngôn ngữ pivot, với beam search 10 cả tiến và lùi, tạo ra 100 đầu ra cho mỗi câu gốc, sau đó lọc và loại bỏ trùng lặp các đầu ra (Phụ lục L). BT-5B không có sẵn cho Internal Benchmark.

Đối với SNIPS, chúng tôi triển khai Example Extrapolation (Ex2, Lee et al. (2021)) với thiết lập "fully anonymized labels" mặc định, một lần nữa tinh chỉnh từ AlexaTM 5B, huấn luyện một phiên bản riêng biệt cho thí nghiệm của mỗi ý định, như được mô tả trong 4.2.1.

Slot Catalog Resampling là một phương pháp đơn giản để tăng cường dữ liệu mà lấy mẫu các thực thể từ catalog cho một nhãn cụ thể. Ví dụ, cho một phát ngôn như "play jason mraz" chúng tôi có thể lấy mẫu "weezer" từ catalog tên nghệ sĩ, để có được "play weezer". Chúng tôi chỉ sử dụng Slot Catalog Resampling cho Internal Benchmark, vì không có slot catalogs có sẵn cho SNIPS hoặc mATIS++.

4.5 Metrics
4.5.1 Metrics cho SNIPS và mATIS++
Chúng tôi sử dụng các metric riêng biệt để đo (1) hỗ trợ cho ý định mới, trong khi (2) không làm hại hiệu suất tổng thể trên tất cả các ý định. Đối với (1), chúng tôi chạy mô hình trên tập test chỉ chứa ý định mới. Chúng tôi gọi đây là Local Intent Recall (IR), và Local ST F1 Score. Để đo (2), chúng tôi chạy mô hình trên tập test kết hợp của tất cả các ý định cùng nhau, và gọi đây là Global Intent Accuracy (IA) và Global ST F1 Score. Trong cả hai trường hợp, đối với ST F1 Score, chúng tôi bỏ qua thẻ "O" (non-entity), sử dụng việc triển khai seqeval (Nakayama, 2018).

Khi dữ liệu huấn luyện được sửa đổi cho một ý định cụ thể i, các metric Local cho i thay đổi theo các phương pháp như mong đợi, trong khi các thay đổi trong Global metrics (xem Phụ lục G) rất nhỏ cho tất cả các phương pháp.

Đối với các thí nghiệm mATIS++ xuyên ngôn ngữ, chúng tôi báo cáo (Global) intent accuracy và Slot F1, vì chúng tôi đang thực hiện chuyển giao xuyên ngôn ngữ cho toàn bộ bộ dữ liệu, và không nhắm vào các ý định cụ thể.

4.5.2 Metrics cho Internal Benchmark
Đối với benchmark nội bộ, chúng tôi chỉ đánh giá trong thiết lập Local. Chúng tôi đo Semantic Error Rate (SemER: Su et al., 2018 hoặc Phụ lục O) đánh giá kết hợp hiệu suất IC và ST. SemER thấp hơn cho thấy cải thiện cho hệ thống. Chúng tôi báo cáo giảm tương đối trong SemER, nơi một số âm cho thấy cải thiện.

5 Kết quả
5.1 Kết quả SNIPS
Các kết quả chính được trình bày trong Bảng 2a cho Local Intent Recall và Bảng 2b cho Local ST F1 Score.

5.1.1 Kết quả Baseline trên SNIPS
Giới hạn trên cho thiết lập New-Intent Few-Shot (NIFS), là một mô hình được huấn luyện trên bộ dữ liệu đầy đủ, mà chúng tôi huấn luyện và báo cáo ("Full" trong bảng) ở 99.2 cho Local Intent Recall và 96.6 cho Local ST F1 Score. Giảm xuống 10 phát ngôn ("s10-NoUps") làm hại cả IC và ST, (mặc dù ST nhiều hơn đáng kể), tuy nhiên chỉ cần up-sampling (nhân đôi) các phát ngôn starter ("s10") khôi phục một phần đáng kể hiệu suất bị mất.

Phần còn lại của các cột sử dụng hỗn hợp (trọng số 0.5/0.5) của 10 phát ngôn starter được up-sample, cộng với dữ liệu tăng cường được rút ra từ chúng thông qua các phương pháp được chỉ định. Trong tất cả các trường hợp, chúng tôi lấy mẫu lại lượng dữ liệu cuối cùng cho ý định mục tiêu để khớp với số lượng trong bộ dữ liệu gốc không sửa đổi.

Chúng tôi thấy rằng ICLM và BT-Small không cải thiện Local Intent Recall hoặc Local ST F1 Score so với "s10", trong khi BT-5B là một baseline mạnh, đạt được 90.1 so với 88.2 cho IC và 79.2 so với 77.7 cho ST. So với BT-5B, Ex2 khớp cho IC ở 90.0 và chỉ cải thiện nhẹ cho ST ở 79.8.

5.1.2 Kết quả LINGUIST trên SNIPS
Chúng tôi huấn luyện 7 phiên bản của mô hình LINGUIST một cho mỗi ý định được giữ lại, như được mô tả trong phần 4.2.1. Sử dụng khả năng của LINGUIST để cả sao chép giá trị slot và tạo ra giá trị mới, chúng tôi định dạng nhiều phiên bản lời nhắc pik từ mỗi phát ngôn starter si. Phiên bản đầu tiên, được gọi là "copy-all" hướng dẫn LINGUIST sao chép tất cả các giá trị slot, trong khi tạo ra các cụm từ mang theo mới. Lưu ý rằng LINGUIST cũng có thể sắp xếp lại các slot trong câu.

Sau đó, đối với mỗi loại slot k, chúng tôi tạo ra một phiên bản mới của lời nhắc thay thế giá trị cho k bằng wildcard "*", hướng dẫn LINGUIST tạo ra một giá trị mới cho slot, trong khi sao chép các giá trị slot khác như chúng là, và tạo ra một cụm từ mang theo phù hợp. Chúng tôi gọi chiến lược này là "sample-each". Chúng tôi sử dụng top_k sampling với k=50 và nhiệt độ 0.3 để tạo ra 100 phát ngôn cho mỗi lời nhắc.

Sau khi lọc các phát ngôn được tạo ra (xem Phụ lục M để biết chi tiết), chúng tôi trộn 10 phát ngôn starter được up-sample với dữ liệu được tạo ra bởi LINGUIST. Chúng tôi sử dụng các thiết lập giống hệt nhau cho việc tinh chỉnh và tạo ra LINGUIST trên tất cả 35 lần chạy (7 ý định nhân 5 seed ngẫu nhiên) cho benchmark SNIPS-NIFS. Theo thiết lập của các baseline khác, chúng tôi tinh chỉnh mô hình IC+ST trên sự kết hợp của dữ liệu tăng cường và trộn cho ý định i với dữ liệu gốc cho tất cả các ý định khác.

So với Ex2 ("s10+Ex2"), LINGUIST cải thiện +2.0 điểm tuyệt đối trên Local Intent Recall (từ 90.0 lên 92.0), và +2.5 điểm tuyệt đối trên Local ST F1 Score (từ 79.8 lên 82.3).

Cuối cùng, chúng tôi cho thấy rằng những cải thiện trong các metric Local cho ý định mới không gây hại cho hệ thống tổng thể, và thực tế cung cấp một cải thiện nhỏ. Như được hiển thị trong Bảng 15a và Bảng 15b (Phụ lục G.1), "s10+LINGUIST" cải thiện so với "s10+Ex2" +0.3 điểm tuyệt đối trên cả Global Intent Accuracy và Global Slot F1 Score.

5.1.3 Kết quả LINGUIST trên SNIPS (LNO)
Chúng tôi báo cáo về thiết lập Label Names Only (LNO) được mô tả trong Phần 4.2.2. Đối với những kết quả này, chúng tôi sử dụng các mô hình LINGUIST được huấn luyện không có label name dropout, mà chúng tôi thấy hoạt động tốt hơn đáng kể (ablation được hiển thị trong Phụ lục E).

Như được hiển thị trong Bảng 3 cho IC và Bảng 4 cho ST, mặc dù không có ví dụ thực nào cho các ý định mới, LINGUIST đạt được 80.0 trên Local Intent Recall và 56.9 trên Local ST F1 Score. (Global metrics được hiển thị trong Phụ lục G.2.) Mặc dù điều này vẫn còn xa so với việc sử dụng văn bản thực và chú thích từ 10 ví dụ này ("s10"), nó đại diện cho tiến bộ đáng kể hướng tới phát triển zero-shot thực sự của các ý định và slot mới trong hệ thống IC+ST.

5.2 Kết quả mATIS++
Kết quả mATIS++ của chúng tôi được hiển thị trong Bảng 5 (Intent Accuracy), và 6 (Slot F1). Trọng tâm chính là "avg-0S", hiệu suất zero-shot trung bình trên 6 ngôn ngữ non-en (de, es, fr, hi, ja, pt).

5.2.1 Kết quả Baseline trên mATIS++
Giới hạn trên cho zero-shot cross-lingual IC+ST là huấn luyện đa ngôn ngữ, nơi một mô hình được huấn luyện kết hợp trên dữ liệu thực cho tất cả các ngôn ngữ, ("all") đạt được 97.17 cho IC và 90.72 cho ST. Giảm xuống dữ liệu chỉ tiếng Anh ("en") làm hại Intent zero-shot trung bình 5.0 điểm, và Slot F1 23.6 điểm. Như baseline của chúng tôi, chúng tôi báo cáo các số từ hệ thống cross-lingual tốt nhất ("MT+soft-align") trong (Xu et al., 2020), sử dụng một kiến trúc transformer chuyên biệt cho slot alignments, đạt được 94.88 trên IC, và 79.84 trên ST.

5.2.2 Tinh chỉnh LINGUIST trên MASSIVE
Trước tiên chúng tôi tinh chỉnh một mô hình LINGUIST trên bộ dữ liệu MASSIVE, theo quy trình từ Phần 3.2. Chúng tôi định dạng các lời nhắc đơn ngôn ngữ cho mỗi trong 7 ngôn ngữ, và các lời nhắc xuyên ngôn ngữ từ tiếng Anh sang 6 ngôn ngữ khác, điều này đơn giản: đối với mỗi phát ngôn huấn luyện ví dụ bằng tiếng Pháp, chúng tôi chọn tối đa 10 ví dụ huấn luyện tiếng Anh có cùng ý định, để đưa vào lời nhắc với phát ngôn tiếng Pháp làm mục tiêu, đặt "French" trong khối <language> của lời nhắc.

Để chứng minh không chỉ xuyên ngôn ngữ và xuyên schema (tên nhãn mATIS++ và quy ước chú thích khác với MASSIVE) mà còn chuyển giao xuyên domain của LINGUIST, chúng tôi loại trừ domain transport từ MASSIVE, vì nó có một số chồng chéo với domain thông tin du lịch của mATIS++. Chúng tôi cũng loại trừ hai domain khác để dừng sớm validation (Phụ lục C).

5.2.3 Kết quả LINGUIST trên mATIS++
Sau đó, để suy luận trên mATIS++, trước tiên chúng tôi tạo ra các lời nhắc tiếng Anh đơn ngôn ngữ, sau đó sử dụng một hệ thống MT dựa trên cloud để dịch các giá trị slot sang ngôn ngữ mục tiêu, đặt thẻ <language> trong lời nhắc, và tạo ra 10 phát ngôn được chú thích. Xem Hình A5 (Phụ lục B.2) cho một ví dụ.

Chúng tôi chọn đầu ra với perplexity thấp nhất, và sử dụng mô hình IC+ST tiếng Anh để xác minh ý định của nó, loại bỏ nó nếu dự đoán không khớp với ý định từ lời nhắc, trong trường hợp đó chúng tôi chỉ cần sao chép một phát ngôn tiếng Anh từ cùng ý định, để duy trì phân phối lớp. (Xem Phụ lục F.)

Bộ dữ liệu cuối cùng chứa N ví dụ tiếng Anh gốc, và N ví dụ cho mỗi ngôn ngữ khác. So với phương pháp "MT+soft-align" của Xu et al. (2020), LINGUIST tương đương cho IC (từ 94.88 lên 95.06), và cải thiện ST F1 Score 4.14 điểm tuyệt đối (từ 79.84 lên 83.98). Chúng tôi lưu ý rằng ST, là một nhiệm vụ dự đoán có cấu trúc, vốn khó khăn hơn IC, vì vậy kết quả ST của chúng tôi đặc biệt thú vị. Hơn nữa, cải thiện trên cả IC và ST đặc biệt lớn đối với tiếng Nhật, có xu hướng thử thách cho alignment với tiếng Anh, vì hai ngôn ngữ có các đặc điểm ngôn ngữ rất khác nhau.

5.3 Kết quả Internal Dataset
Bảng 7 hiển thị SemER trên Internal Dataset của chúng tôi.

5.3.1 Kết quả Baseline trên Internal Dataset
Đối với mỗi feature i chúng tôi huấn luyện một mô hình IC+ST Mi kết hợp dữ liệu Existing Features E, các phát ngôn starter được up-sample Si, các phát ngôn tăng cường Ai được tạo ra từ Si thông qua Slot Catalog Resampling, ICLM, và BT-Small. Chúng tôi đánh giá trên tập test Ti của feature, báo cáo Local SemER.

5.3.2 Kết quả LINGUIST trên Internal Dataset
Chúng tôi tinh chỉnh một mô hình LINGUIST duy nhất trên các lời nhắc hướng dẫn được định dạng từ bộ dữ liệu Existing Features E (Phần 4.1.3.), không chứa bất kỳ ví dụ nào của các features mới. Sau đó, đối với mỗi feature, i, theo quy trình tương tự được mô tả trong Phần 5.1.2, chúng tôi định dạng lời nhắc từ các phát ngôn starter Si và áp dụng LINGUIST để tạo ra thêm dữ liệu Gi. Cuối cùng, chúng tôi theo cùng quy trình trộn dữ liệu, huấn luyện, và testing cho mỗi feature i như trong baseline (Phần 5.3.1).

Như được hiển thị trong Bảng 7, LINGUIST dẫn đến giảm SemER tương đối 7.9% đến 25.2% trên bốn ngôn ngữ so với baseline của Catalog Resampling, ICLM, và BT-Small kết hợp.

6 Kết luận và Công việc Tương lai
Chúng tôi đã giới thiệu LINGUIST, một phương pháp mới để tạo ra dữ liệu được chú thích, thông qua việc tinh chỉnh một mô hình seq2seq đa ngôn ngữ được tiền huấn luyện quy mô lớn. Phương pháp của chúng tôi tổng quát hóa cho các ý định và slot mới trong các thiết lập few-shot, zero-shot, và xuyên ngôn ngữ thử thách, mà chúng tôi đã chứng minh trên ba bộ dữ liệu.

Trong công việc tương lai, chúng tôi muốn khám phá các cách để cải thiện đầu ra tạo ra, ví dụ human-in-the-loop và reinforcement learning. Chúng tôi cũng muốn bao gồm thêm các điều khiển trong lời nhắc như phong cách văn bản, và khám phá việc tạo ra cho các cuộc hội thoại đa lượt, và ngữ nghĩa phức tạp và lồng ghép hơn.

Lời cảm ơn
Chúng tôi cảm ơn Christophe Dupuy, Weitong Ruan, và các nhà đánh giá ẩn danh đã phản hồi về công việc của chúng tôi.

# LANGBRIDGE: Lý luận đa ngôn ngữ không cần giám sát đa ngôn ngữ

## Tóm tắt

Chúng tôi giới thiệu LANGBRIDGE, một phương pháp zero-shot để thích ứng các mô hình ngôn ngữ cho các tác vụ lý luận đa ngôn ngữ mà không cần giám sát đa ngôn ngữ. LANGBRIDGE hoạt động bằng cách "kết nối" hai mô hình, mỗi mô hình chuyên về các khía cạnh khác nhau: (1) một mô hình chuyên về hiểu nhiều ngôn ngữ (ví dụ: bộ mã hóa mT5) và (2) một mô hình chuyên về lý luận (ví dụ: Orca 2). LANGBRIDGE kết nối hai mô hình bằng cách đưa ra tối thiểu các tham số có thể huấn luyện giữa chúng. Mặc dù chỉ sử dụng dữ liệu tiếng Anh để huấn luyện, LANGBRIDGE cải thiện đáng kể hiệu suất của các mô hình ngôn ngữ trên các ngôn ngữ ít tài nguyên trong lý luận toán học, hoàn thành mã, lý luận logic và lý luận thông thường. Phân tích của chúng tôi cho thấy hiệu quả của LANGBRIDGE xuất phát từ các đặc điểm không phụ thuộc ngôn ngữ của biểu diễn đa ngôn ngữ. Chúng tôi công khai phát hành mã nguồn và mô hình.

## 1. Giới thiệu

Các mô hình ngôn ngữ (LM) được biết đến với hiệu suất kém trong việc giải quyết các tác vụ lý luận như toán học hoặc lập trình bằng các ngôn ngữ ít tài nguyên. Xu hướng này chủ yếu xuất phát từ việc các LM được huấn luyện trên các kho dữ liệu chủ yếu bao gồm một số ngôn ngữ có nhiều tài nguyên. Điều này dẫn đến việc các ngôn ngữ ít tài nguyên được biểu diễn như kiến thức đuôi dài.

Các nghiên cứu trước đây chủ yếu tiếp cận vấn đề này bằng cách thích ứng các LM tập trung vào tiếng Anh sang các ngôn ngữ khác thông qua huấn luyện liên tục trên ngôn ngữ mục tiêu. Tuy nhiên, việc mở rộng phương pháp này cho một số lượng lớn ngôn ngữ là thách thức, vì nó đòi hỏi kho dữ liệu huấn luyện có mục tiêu cho từng ngôn ngữ. Vấn đề này đặc biệt rõ ràng đối với các LM như MetaMath và Orca 2, đã trải qua quá trình thích ứng liên tục theo lĩnh vực cụ thể từ Llama 2. Những bộ dữ liệu chuyên biệt, cụ thể theo lĩnh vực này thường bằng tiếng Anh, làm phức tạp việc hỗ trợ đa ngôn ngữ cho LM cơ bản.

Trong bài báo này, chúng tôi giới thiệu LANGBRIDGE, một phương pháp mới thích ứng LM để giải quyết các tác vụ lý luận đa ngôn ngữ mà không cần huấn luyện rõ ràng trên dữ liệu đa ngôn ngữ. Lấy cảm hứng từ tài liệu đa phương thức tích hợp hai phương thức được tiền huấn luyện độc lập, chúng tôi tận dụng bộ mã hóa từ mT5 và đưa ra một số lượng nhỏ các tham số có thể huấn luyện giữa bộ mã hóa và LM mục tiêu. Quan trọng nhất, phương pháp của chúng tôi không đòi hỏi giám sát đa ngôn ngữ và chỉ dựa vào dữ liệu tiếng Anh trong khi tổng quát hóa sang nhiều ngôn ngữ trong thời gian kiểm tra, giống như chuyển giao zero-shot xuyên ngôn ngữ.

Chúng tôi chứng minh hiệu quả của LANGBRIDGE bằng cách áp dụng phương pháp của chúng tôi cho các LM chuyên về các tác vụ lý luận đa dạng về lý luận toán học, hoàn thành mã, lý luận logic. Kết quả thực nghiệm của chúng tôi cho thấy LANGBRIDGE nâng cao đáng kể hiệu suất lý luận đa ngôn ngữ của các LM. Ví dụ, LANGBRIDGE áp dụng cho MetaMath-13B tận dụng bộ mã hóa mT5-XL (2.2B) tăng độ chính xác trung bình trên MGSM từ 40.5% lên 53.5%, khớp với hiệu suất của PaLM-540B, đạt 51.3%. Chúng tôi quan sát LANGBRIDGE cũng tăng đáng kể hiệu suất LM trên các bộ dữ liệu lý luận đòi hỏi hiểu biết ngôn ngữ học nội tại như các nhiệm vụ con cụ thể của Big-Bench Hard và XCOPA.

Chúng tôi giả định rằng hiệu quả của LANGBRIDGE được neo trong các đặc điểm không phụ thuộc ngôn ngữ của biểu diễn đa ngôn ngữ. Bằng cách ánh xạ các biểu diễn này vào không gian đầu vào của LM mục tiêu, chúng tôi phỏng đoán rằng LM có thể nắm bắt ngữ nghĩa của các biểu diễn này. Vì các biểu diễn này là trung tính ngôn ngữ, việc hiểu chúng cho phép LM trở nên ít phụ thuộc vào ngôn ngữ cụ thể của đầu vào, do đó cho phép nó giải quyết các tác vụ bằng các ngôn ngữ mà nó hiếm khi gặp phải trong quá trình tiền huấn luyện. Phân tích thực nghiệm của chúng tôi về LANGBRIDGE, sử dụng phân tích thành phần chính (PCA) và các phương pháp định tính, hỗ trợ giả thuyết này.

## 2. Nghiên cứu liên quan

### 2.1 Các mô hình ngôn ngữ tập trung vào tiếng Anh

Các nghiên cứu trước đây đã cải thiện khả năng lý luận của LM trong lý luận toán học, tạo mã và lý luận logic. Tuy nhiên, phần lớn các LM này được bắt nguồn từ các LM tập trung vào tiếng Anh và được thích ứng với các bộ dữ liệu cụ thể theo lĩnh vực bằng tiếng Anh. Do đó, các LM này thừa kế trình độ hạn chế trong các ngôn ngữ ít tài nguyên, dẫn đến sự khác biệt hiệu suất đáng kể giữa các ngôn ngữ có nhiều tài nguyên và ít tài nguyên. Động lực của phương pháp đề xuất của chúng tôi, LANGBRIDGE, là thu hẹp khoảng cách này.

### 2.2 Chuyển giao zero-shot xuyên ngôn ngữ

Các mô hình đa ngôn ngữ thể hiện khả năng chuyển giao zero-shot xuyên ngôn ngữ đáng chú ý. Khả năng này hỗ trợ đáng kể cộng đồng ngôn ngữ ít tài nguyên, cho phép các mô hình đa ngôn ngữ xử lý các tác vụ trên nhiều ngôn ngữ sau khi được tinh chỉnh trên các ngôn ngữ có nhiều tài nguyên. Phương pháp của chúng tôi, tận dụng các mô hình đa ngôn ngữ, thể hiện khả năng tương tự, vì nó có thể cải thiện khả năng lý luận của LM trên nhiều ngôn ngữ trong khi chỉ dựa vào dữ liệu tiếng Anh trong quá trình thích ứng.

### 2.3 Căn chỉnh biểu diễn tiền huấn luyện

Khái niệm kết hợp các biểu diễn tiền huấn luyện độc lập đã được khám phá rộng rãi trong lĩnh vực căn chỉnh xuyên phương thức. Các nghiên cứu này tập trung vào việc căn chỉnh các mô hình mã hóa hình ảnh với LM để tạo điều kiện cho khả năng hiểu thị giác của LM. Trong một nghiên cứu đồng thời, Bansal et al. (2024) căn chỉnh hai mô hình ngôn ngữ lớn để tăng cường khả năng của nhau. Một trong những thí nghiệm của họ cho thấy việc căn chỉnh một LM đa ngôn ngữ với một LM khác có thể dẫn đến hiệu suất cải thiện trong các tác vụ đa ngôn ngữ. Tuy nhiên, trái ngược với phương pháp của chúng tôi, phương pháp của họ sử dụng giám sát đa ngôn ngữ để căn chỉnh.

## 3. LANGBRIDGE

### 3.1 Giả thuyết

Các nghiên cứu trước đây cho thấy rằng các biểu diễn của các mô hình mã hóa đa ngôn ngữ là vừa phải không phụ thuộc ngôn ngữ (hoặc trung tính ngôn ngữ) ngay từ đầu, tạo điều kiện cho chuyển giao zero-shot xuyên ngôn ngữ. Dựa trên tiền đề này, chúng tôi giả định rằng bằng cách căn chỉnh một mô hình mã hóa đa ngôn ngữ với không gian của một LM, LM sẽ có thể hiểu ngữ nghĩa của các ngôn ngữ được hỗ trợ bởi bộ mã hóa đa ngôn ngữ mà không cần huấn luyện trên một tập hợp lớn các ngôn ngữ.

Để kiểm tra giả thuyết này, chúng tôi căn chỉnh các mô hình mã hóa đa ngôn ngữ với LM chỉ sử dụng kho dữ liệu tiếng Anh (Trái của Hình 2). Sau đó, chúng tôi đánh giá các mô hình đã căn chỉnh bằng cách sử dụng đầu vào không phải tiếng Anh để xác định liệu các LM có thể hiện khả năng nâng cao trong các tác vụ đa ngôn ngữ (Phải của Hình 2).

### 3.2 Kiến trúc mô hình

Dựa trên các phát hiện của các nghiên cứu trước đây, nơi mà việc hiểu xuyên phương thức hiệu quả đã được đạt được bằng cách ánh xạ các biểu diễn từ các phương thức không phải ngôn ngữ sang các lời nhắc mềm của LM, LANGBRIDGE ánh xạ các trạng thái ẩn cuối cùng của các bộ mã hóa đa ngôn ngữ sang các lời nhắc mềm của LM để đạt được sự hiểu biết đa ngôn ngữ của LM mục tiêu. Theo các nghiên cứu trên, chúng tôi áp dụng thiết lập sử dụng một lớp tuyến tính duy nhất làm hàm ánh xạ và thêm một token có thể huấn luyện vào cuối lời nhắc mềm làm token [EOS] (kết thúc chuỗi). Do đó, với các token đầu vào (được đệm nếu cần thiết) của bộ mã hóa Xenc, lời nhắc mềm được suy ra Henc tương đương về độ dài chuỗi với Xenc + 1, và có cùng chiều không gian như trạng thái ẩn của mô hình ngôn ngữ. Bất kỳ token nào trong Henc có nguồn gốc từ các token đệm của Xenc đều được che dấu cho LM mục tiêu. Chúng tôi tiến hành ablation về tác động của việc sử dụng các kiến trúc phức tạp hơn trong Phụ lục D.

Mục tiêu mô hình hóa ngôn ngữ của LANGBRIDGE giống như "prefix LM" được khám phá bởi Raffel et al. (2020), vì các token đầu vào bộ mã hóa Xenc có thể được hiểu là các token tiền tố mà các token mục tiêu Xlm được điều kiện hóa. Chính thức, với các token đầu vào bộ mã hóa Xenc, khả năng mô hình hóa ngôn ngữ của các token mục tiêu Xlm được ký hiệu là:

p(Xlm|Xenc) = ∏(i=1 to L) p(xi|Xenc, x<i)

trong đó L là độ dài chuỗi của Xlm, và xi là token thứ i của Xlm.

## 4. Thí nghiệm chính

### 4.1 Tổng quan

Chúng tôi chọn bốn danh mục tác vụ cho các thí nghiệm của mình: (1) lý luận toán học, (2) hoàn thành mã, (3) lý luận logic, và (4) lý luận thông thường. Đối với mỗi danh mục tác vụ, chúng tôi áp dụng LANGBRIDGE cho các LM chuyên về lý luận được bắt nguồn từ Llama 2, như MetaMath hoặc Orca 2. Chúng tôi đánh giá các mô hình trên các benchmark đa ngôn ngữ hiện có (ví dụ: MGSM) hoặc các benchmark tiếng Anh đã được dịch (ví dụ: bản dịch của HumanEval). Vì các tác vụ đánh giá đòi hỏi cả khả năng hiểu đa ngôn ngữ và khả năng lý luận nâng cao, độ phức tạp này đặt ra một thách thức đáng kể đối với các LM đa ngôn ngữ tổng quát và các LM tập trung vào tiếng Anh chuyên về lý luận. Ngược lại, các mô hình được căn chỉnh với LANGBRIDGE có thể tận dụng lợi thế của cả hai.

Vì Touvron et al. (2023b) tiết lộ phân bố ngôn ngữ của dữ liệu tiền huấn luyện của Llama 2, điều này cho phép chúng tôi xác định các ngôn ngữ nào được đại diện kém trong các LM được khởi tạo từ trọng số Llama 2. Trong suốt bài báo, chúng tôi phân loại một ngôn ngữ là được đại diện kém nếu nó chiếm ít hơn 0.1% dữ liệu tiền huấn luyện của Llama 2.

Trong tất cả các thí nghiệm của chúng tôi, chúng tôi sử dụng các bộ mã hóa của mT5 làm bộ mã hóa đa ngôn ngữ do tính khả dụng của chúng trên một phạm vi rộng các tham số, và hỗ trợ cho các chuỗi đầu vào dài hơn so với các mô hình mã hóa đa ngôn ngữ khác. Cụ thể, chúng tôi sử dụng các checkpoint "LM adaptated" từ Vu et al. (2022). Chúng tôi căn chỉnh các LM mục tiêu có 7B tham số với bộ mã hóa mT5-XL để thích ứng các mô hình 9B và LM 13B với bộ mã hóa mT5-XL và mT5-XXL để thu được các mô hình 15B và 20B, tương ứng. Vì LANGBRIDGE thêm một lượng đáng kể tham số bổ sung vào LM mục tiêu, chúng tôi tiến hành phân tích thông lượng suy luận trong Phụ lục B. Chúng tôi cũng tiến hành ablation về tác động của kích thước tham số bộ mã hóa và loại mô hình bộ mã hóa trong Phụ lục D.

Chúng tôi sử dụng dữ liệu huấn luyện liên tục ban đầu của LM cho LANGBRIDGE khi có thể truy cập (ví dụ: MetaMathQA cho MetaMath). Nếu không có sẵn, chúng tôi chọn bộ dữ liệu công khai gần nhất (ví dụ: OpenOrca cho Orca 2). Trong tất cả các thí nghiệm của chúng tôi, chúng tôi cố định kích thước của bộ dữ liệu huấn luyện là 200,000 mẫu. Tuy nhiên, nghiên cứu ablation của chúng tôi về tác động của kích thước bộ dữ liệu huấn luyện trong Phụ lục D cho thấy LANGBRIDGE trong thực tế có thể cần ít dữ liệu hơn nhiều. Chúng tôi giữ mô hình ngôn ngữ bị đông lạnh trong suốt quá trình căn chỉnh để đạt hiệu quả. Chúng tôi cũng đóng băng bộ mã hóa (trừ lớp embedding) để căn chỉnh các LM đã được tinh chỉnh, trong khi đối với các LM được tiền huấn luyện, chúng tôi giữ bộ mã hóa có thể huấn luyện. Trong Phụ lục D, chúng tôi cung cấp thêm giải thích cho những lựa chọn này và tiến hành ablation về tác động của việc đóng băng. Chúng tôi căn chỉnh các mô hình bằng cách huấn luyện trên mục tiêu prefix LM được mô tả trong Phần 3.2. Trong các thí nghiệm sơ bộ của chúng tôi, chúng tôi thấy rằng việc huấn luyện trên các độ dài khác nhau của Xenc là cần thiết để đảm bảo tính mạnh mẽ trong thời gian suy luận, vì mô hình ngôn ngữ được tiếp xúc với các độ dài đa dạng của Henc.

Chúng tôi sử dụng độ dài đầu vào tối đa (Xenc) là 1,024 và độ dài mục tiêu tối đa (Xlm) là 128 để huấn luyện. Đối với dữ liệu không có nhãn, chúng tôi thay đổi độ dài đầu vào ngẫu nhiên trong cửa sổ 1,024 để giới thiệu LM với các độ dài khác nhau của Henc. Đối với dữ liệu có nhãn, dữ liệu tự nhiên có các độ dài đầu vào đa dạng. Trên một máy được trang bị bốn GPU A100 80GB, việc huấn luyện một mô hình 9B mất ít hơn bốn giờ khi các lớp bộ mã hóa bị đông lạnh, và dưới năm giờ khi toàn bộ bộ mã hóa có thể huấn luyện. Trong các thí nghiệm chính của chúng tôi, thiết lập nơi bộ mã hóa hoàn toàn có thể huấn luyện trong các mô hình 20B dẫn đến thời gian huấn luyện tối đa, khoảng mười giờ. Chi tiết huấn luyện thêm có sẵn trong Phụ lục F.

### 4.2 Lý luận toán học

#### 4.2.1 Thiết lập thí nghiệm

**Bộ dữ liệu đánh giá** MGSM bao gồm các bài toán từ cấp tiểu học bằng 11 ngôn ngữ có tính chất phong phú về mặt ngôn ngữ học, được dịch bởi con người từ một mẫu của GSM8K. Đối với việc đánh giá các LM tiền huấn luyện, chúng tôi áp dụng thiết lập lý luận chuỗi tư duy (CoT) chuyển giao xuyên ngôn ngữ (NATIVE-EXEMPLARS + EN-COT) từ Shi et al. (2023), trong đó các ví dụ few-shot được đưa ra bằng ngôn ngữ mục tiêu, nhưng các lý luận CoT để giải quyết các ví dụ được cung cấp bằng tiếng Anh. Đối với các LM đã được tinh chỉnh, chúng tôi đánh giá trong thiết lập zero-shot. Đánh giá bổ sung trên MSVAMP có sẵn trong Phụ lục A.

**Mô hình ngôn ngữ** Llemma là một tập hợp các LM cho toán học, được tiền huấn luyện liên tục từ Code Llama trên Proof-Pile-2, một hỗn hợp các bài báo khoa học, dữ liệu web chứa toán học và mã toán học. MetaMath được tinh chỉnh từ Llama 2 trên MetaMathQA, một bộ dữ liệu toán học dựa trên GSM8K và MATH. Vì cả Proof-Pile-2 và MetaMathQA đều có sẵn công khai, chúng tôi áp dụng LANGBRIDGE bằng cách sử dụng các mẫu từ các bộ dữ liệu huấn luyện tương ứng của chúng.

**Baseline** Llama 2 là một LM tập trung vào tiếng Anh trong đó 89.7% dữ liệu tiền huấn luyện bao gồm tiếng Anh nhưng đã cho thấy hiệu suất đáng kể trên các ngôn ngữ không phải tiếng Anh. mT5, XGLM và BLOOM là các LM đa ngôn ngữ lớn. MathOctopus là một LM cho lý luận toán học đa ngôn ngữ. Nó được khởi tạo từ Llama 2 và tinh chỉnh trên các bản dịch của bộ dữ liệu GSM8K trên mười ngôn ngữ. Mười ngôn ngữ được thấy bởi MathOctopus trùng lặp với 11 ngôn ngữ được bao gồm trong MGSM, trừ Telugu. Chúng tôi sử dụng các checkpoint hiệu suất tốt nhất của họ, xRFT-MathOctopusP, được cải thiện thêm bằng tăng cường dữ liệu thông qua lấy mẫu từ chối. Chúng tôi cũng báo cáo hiệu suất của PaLM được đo bởi Shi et al. (2023). Tương tự như Llama 2, PaLM được tiền huấn luyện trên các kho dữ liệu nặng về tiếng Anh.

#### 4.2.2 Kết quả

Bảng 1 hiển thị kết quả đánh giá của các baseline và mô hình LANGBRIDGE trên MGSM. Chúng tôi nêu bật sáu quan sát chính. (1) Llama 2, Llemma và MetaMath thể hiện sự suy giảm hiệu suất nghiêm trọng trên các ngôn ngữ được đại diện kém trong dữ liệu huấn luyện của Llama 2. (2) Mặc dù vậy, các LM đa ngôn ngữ lớn hoạt động kém hơn Llama 2, ngay cả trong bối cảnh các ngôn ngữ được đại diện kém. Sự khác biệt này nhấn mạnh khả năng lý luận toán học mạnh mẽ vốn có trong Llama 2 và vắng mặt trong BLOOM, XGLM và mT5. (3) LANGBRIDGE cải thiện hiệu suất đa ngôn ngữ của Llemma và MetaMath, đặc biệt là trong các ngôn ngữ được đại diện kém. Đáng chú ý nhất, LANGBRIDGE có thể đưa hiệu suất Llemma và MetaMath trên Telugu (TE) từ số không hoặc gần số không lên một phạm vi có thể so sánh với các ngôn ngữ khác. (4) LANGBRIDGE có thể làm giảm hiệu suất trên các ngôn ngữ có nhiều tài nguyên, với việc giảm hiệu suất tiếng Anh (EN) của Llemma-LB-9B đặc biệt rõ ràng. Chúng tôi cung cấp các phỏng đoán của mình về nguyên nhân của hiện tượng này trong Phần 6.1. (5) Khả năng lý luận toán học của các mô hình LANGBRIDGE đến từ các LM ban đầu của chúng, không phải dữ liệu huấn luyện của chúng. Điều này rõ ràng từ BLOOM-7.1B-PP2 và BLOOM-7.1B-MM hoạt động kém hơn Llemma-LB-9B và MetaMath-LB-9B, tương ứng, với một biên độ lớn. (6) Đáng ngạc nhiên, mặc dù chỉ được huấn luyện trên dữ liệu toán học tiếng Anh, các mô hình MetaMath-LB của chúng tôi cạnh tranh với các mô hình MathOctopus, được tinh chỉnh trên các bản dịch của GSM8K trên mười trong số 11 ngôn ngữ được hỗ trợ bởi MGSM. Quan trọng nhất, hiệu suất của các mô hình MathOctopus giảm xuống gần bằng không trên Telugu (TE), một ngôn ngữ không được thấy bởi MathOctopus. Mặt khác, các mô hình LANGBRIDGE cho thấy hiệu suất mạnh mẽ trên tất cả 11 ngôn ngữ, cho thấy rằng ngay cả khi không có giám sát đa ngôn ngữ LANGBRIDGE tổng quát hóa cho quy mô lớn các ngôn ngữ được bao gồm trong tiền huấn luyện đa ngôn ngữ của các bộ mã hóa.

Nhìn chung, các mô hình LANGBRIDGE thể hiện hiệu suất xuất sắc so với các baseline. Các mô hình LANGBRIDGE vượt trội hơn hẳn các mô hình đa ngôn ngữ có kích thước tương tự, thiết lập LANGBRIDGE như một phương pháp khả thi để phát triển các mô hình lý luận toán học cho các ngôn ngữ ít tài nguyên. Chúng tôi cung cấp một ví dụ về lý luận CoT được tạo ra bởi MetaMath-LB trong Phụ lục G.

### 4.3 Hoàn thành mã

#### 4.3.1 Thiết lập thí nghiệm

**Bộ dữ liệu đánh giá** Tận dụng khả năng dịch thuật mạnh mẽ của GPT-4, như được chứng minh trong nghiên cứu của Jiao et al. (2023), chúng tôi mở rộng HumanEval, một tập hợp các bài toán lập trình được viết tay, sang năm ngôn ngữ được đại diện kém: Swahili, Bengali, Punjabi, Telugu và Urdu. Chúng tôi đặt tên cho bộ dữ liệu kết quả là HumanEval-MT. Chúng tôi chọn năm ngôn ngữ trong số những ngôn ngữ có hiệu suất MMLU được báo cáo trong báo cáo kỹ thuật của GPT-4 đồng thời cũng được bao gồm trong các kho dữ liệu tiền huấn luyện của BLOOM. Lựa chọn này được thực hiện để có được các bản dịch chất lượng cao từ GPT-4, và cung cấp cho các baseline dựa trên BLOOM một sân chơi công bằng. Để hướng dẫn GPT-4 chỉ dịch hướng dẫn ngôn ngữ tự nhiên nhúng trong docstring mà không sửa đổi các đoạn mã, chúng tôi nhắc GPT-4 với hai ví dụ được chú thích bởi con người. Sau đó, các bản dịch được tạo ra được thực thi trong môi trường thông dịch Python để xác nhận việc không có lỗi cú pháp. Chúng tôi cung cấp ước tính chất lượng dịch thuật của HumanEval-MT trong Phụ lục E.

Các ví dụ trong bộ dữ liệu HumanEval thường có tên hàm tự giải thích. Điều này cho thấy rằng các mô hình ngôn ngữ có thể hoàn thành thành công các đoạn mã liên quan, ngay cả khi không hiểu chính xác các bình luận ngôn ngữ tự nhiên nhúng trong chúng. Do đó, chúng tôi đánh giá các mô hình trên các phiên bản ẩn danh của mỗi tập hợp ngôn ngữ, trong đó tên hàm mục tiêu của các đoạn mã được thay đổi đồng nhất thành "func". Một ví dụ về việc ẩn danh hóa và kết quả đánh giá trên phiên bản gốc có sẵn trong Phụ lục A.

**Mô hình ngôn ngữ** Code Llama là một họ mô hình được khởi tạo từ trọng số mô hình Llama 2 và tiền huấn luyện trên một bộ dữ liệu nặng về mã. Trong các thí nghiệm của chúng tôi, chúng tôi sử dụng các mô hình Code Llama-Python, được tiền huấn luyện thêm trên một bộ dữ liệu nặng về Python. Vì các bộ dữ liệu được sử dụng để tiền huấn luyện các mô hình Code Llama không có sẵn công khai, chúng tôi lấy mẫu từ tập hợp con Python của dữ liệu StarCoder làm bộ dữ liệu huấn luyện cho LANGBRIDGE.

**Baseline** Chúng tôi sử dụng các mô hình Llama 2 và BLOOM làm baseline. Cả hai mô hình đều chứa dữ liệu mã trong các kho dữ liệu tiền huấn luyện của chúng. Ngoài ra, chúng tôi báo cáo hiệu suất của BLOOM-StarCoder, một mô hình BLOOM được tiền huấn luyện liên tục trên mẫu dữ liệu StarCoder được sử dụng để huấn luyện các mô hình LANGBRIDGE.

#### 4.3.2 Kết quả

Bảng 2 trình bày điểm Pass@1 trên HumanEval và HumanEval-MT. Các mô hình Code Llama-LB cho thấy cải thiện nhất quán so với Code Llama trên tất cả các ngôn ngữ được đại diện kém. Hơn nữa, các mô hình LANGBRIDGE có thể khớp với các baseline lớn hơn của chúng về điểm số trung bình: mô hình 9B hoạt động kém hơn một chút so với Code Llama-13B 0.2%, trong khi cả mô hình 15B và 20B đều vượt qua Code Llama-34B. BLOOM được huấn luyện trên dữ liệu StarCoder không thể hiện cải thiện đáng chú ý, nhấn mạnh lại rằng điểm mạnh của các mô hình LANGBRIDGE chủ yếu xuất phát từ khả năng của các LM ban đầu.

### 4.4 Lý luận logic

#### 4.4.1 Thiết lập thí nghiệm

**Bộ dữ liệu đánh giá** Chúng tôi đánh giá khả năng lý luận logic với Big-Bench Hard (BBH) và Big-Bench Hard Bengali (BBH-BN). BBH là một tập hợp các nhiệm vụ con thách thức nơi việc áp dụng lý luận chuỗi tư duy (CoT) có tiềm năng cải thiện hiệu suất đáng kể. BBH-BN dịch 14 trong số 23 nhiệm vụ con của BBH sang tiếng Bengali. Để tạo điều kiện cho việc so sánh có ý nghĩa, chúng tôi chỉ đánh giá trên 14 nhiệm vụ con được hỗ trợ bởi BBH-BN cho BBH.

**Mô hình ngôn ngữ** Orca 2 được tinh chỉnh trên Llama 2 với một tập hợp các bộ dữ liệu được tăng cường với các dấu vết lý luận của GPT-4 cũng như các bộ dữ liệu hoàn toàn tổng hợp được tạo ra với GPT-4. Orca 2 hiệu quả cải thiện khả năng lý luận của các LM nhỏ hơn trên các tác vụ phức tạp đòi hỏi lý luận nâng cao trong các thiết lập zero-shot. Vì bộ dữ liệu huấn luyện của Orca 2 không có sẵn công khai, chúng tôi lấy mẫu dữ liệu huấn luyện cho LANGBRIDGE từ bộ dữ liệu OpenOrca. OpenOrca tuân theo phân bố dữ liệu của lần lặp đầu tiên của Orca. Chúng tôi sử dụng CLD3 để lọc bất kỳ dữ liệu không phải tiếng Anh nào chủ yếu xuất phát từ các bộ dữ liệu dịch thuật để đảm bảo thiết lập zero-shot của các thí nghiệm của chúng tôi. Các ví dụ được bao gồm nếu văn bản đầu vào của chúng có xác suất 99% hoặc lớn hơn là tiếng Anh, trong khi văn bản mục tiêu của chúng cũng có cơ hội 95% hoặc lớn hơn là tiếng Anh. Một ngưỡng thấp hơn một chút được áp dụng cho văn bản mục tiêu để không lọc sai các phản hồi một từ, mà CLD3 thể hiện độ tin cậy thấp hơn.

**Baseline** Trong đánh giá của chúng tôi về BBH, chúng tôi đánh giá liệu các mô hình Orca 2-LB có thể có được sự hiểu biết đa ngôn ngữ trong khi vẫn giữ khả năng CoT zero-shot của Orca 2. Tuy nhiên, từ thử nghiệm hạn chế của chúng tôi, chúng tôi thấy rằng không có LM đa ngôn ngữ mở nào hiện có có thể tạo ra CoT một cách đáng tin cậy trong thiết lập zero-shot. Do đó, chúng không được bao gồm làm baseline. Chúng tôi báo cáo hiệu suất của BLOOM-OpenOrca, một mô hình BLOOM được huấn luyện thêm trên cùng một tập hợp huấn luyện như Orca 2-LB.

#### 4.4.2 Kết quả

Bảng 3 hiển thị độ chính xác trung bình trên các nhiệm vụ con cho BBH và BBH-BN. Mô hình Orca 2-LB-9B cho thấy cải thiện đáng kể trong BBH-BN, vượt qua mô hình Orca 2-13B lớn hơn. Chúng tôi báo cáo hiệu suất trên mỗi nhiệm vụ con trong Bảng 12 và Bảng 13. Đáng chú ý, LANGBRIDGE tăng đáng kể hiệu suất trên các nhiệm vụ con BBH-BN đòi hỏi hiểu biết ngôn ngữ học nội tại như CAUSAL JUDGEMENT và SNARKS. CAUSAL JUDGEMENT đòi hỏi mô hình phải hiểu một câu chuyện ngắn và xác định cách một con người điển hình sẽ trả lời một câu hỏi đã cho. Đối với SNARKS, mô hình được đưa ra hai câu gần như giống hệt nhau và được yêu cầu xác định câu nào chứa sự mỉa mai. Quan sát này, cùng với kết quả từ đánh giá trên XCOPA, một bộ dữ liệu lý luận thông thường, cho thấy rằng các mô hình LANGBRIDGE mạnh mẽ trong việc nắm bắt và giải thích các chi tiết ngôn ngữ tinh tế. Kết quả đánh giá trên XCOPA được cung cấp trong Phụ lục A.

Hình 8 cho thấy một ví dụ về một mô hình LANGBRIDGE giải quyết chính xác CAUSAL JUDGEMENT.

## 5. Phân tích LANGBRIDGE

Dựa trên bằng chứng thực nghiệm được trình bày trong các phần trước, chúng tôi khẳng định rằng LANGBRIDGE hiệu quả cải thiện khả năng của LM để giải quyết các tác vụ đa ngôn ngữ mà không cần huấn luyện đa ngôn ngữ, đặc biệt là đối với các ngôn ngữ ít tài nguyên. Phần này trình bày hai quan sát cơ bản để củng cố thêm giả thuyết được nêu trong Phần 3.

### 5.1 PCA

Giả thuyết chủ yếu quy cho tính khả thi của LANGBRIDGE đối với các biểu diễn đủ không phụ thuộc ngôn ngữ của các bộ mã hóa đa ngôn ngữ. Nếu phỏng đoán này đúng, với một mô hình LANGBRIDGE, biểu diễn đầu ra của LM của lời nhắc mềm Henc cũng nên thể hiện các đặc điểm không phụ thuộc ngôn ngữ. Có lý khi LM sẽ không một cách tùy tiện đưa ra các tính năng cụ thể theo ngôn ngữ bổ sung cho một đầu vào trung tính ngôn ngữ được bắt nguồn từ bộ mã hóa đa ngôn ngữ.

Do đó, để xác minh liệu các mô hình LANGBRIDGE thực sự có các biểu diễn đầu ra không phụ thuộc ngôn ngữ, chúng tôi áp dụng PCA cho các biểu diễn đầu ra được gộp trung bình từ một mô hình LANGBRIDGE và so sánh chúng với những mô hình từ LM tập trung vào tiếng Anh ban đầu. Hình 3 hiển thị hai thành phần chính đầu tiên của các biểu diễn đầu ra được gộp thu được với FLORES, một kho dữ liệu song song. Đối với Orca 2, các ngôn ngữ có nhiều tài nguyên, tiếng Anh (EN), tiếng Tây Ban Nha (ES), và tiếng Đức (DE), được ánh xạ gần nhau. Các ngôn ngữ được đại diện kém, Telugu (TE) và Swahili (SW), thể hiện một ánh xạ xa hơn trong không gian biểu diễn, tạo thành ba cụm. Ngược lại, đối với Orca 2-LANGBRIDGE, tất cả các ngôn ngữ được ánh xạ vào một cụm duy nhất, cho thấy rằng các biểu diễn của Henc duy trì trạng thái tương đối trung tính ngôn ngữ.

### 5.2 Dịch thuật tình cờ

Hình 4 minh họa một ví dụ về "dịch thuật tình cờ" của mô hình Orca 2-LANGBRIDGE-15B. Mặc dù được đưa ra các lựa chọn bằng tiếng Bengali, mô hình LANGBRIDGE nhận thức các lựa chọn như tiếng Trung và đọc lại chúng bằng tiếng Trung. Với tiếng Bengali làm đầu vào, dịch thuật tình cờ sang một ngôn ngữ thứ ba khác ngoài tiếng Anh hoặc tiếng Bengali cho thấy rằng nhiều ngôn ngữ có thể có các biểu diễn tương tự trong Henc. Tuy nhiên, đầu ra bằng các ngôn ngữ khác ngoài tiếng Anh là không phổ biến đối với các mô hình Orca 2-LANGBRIDGE. Chúng tôi tiến hành phân tích định tính trên các CoT được tạo ra bởi Orca 2-LANGBRIDGE-15B cho nhiệm vụ con BBH-BN SNARKS, mà chúng tôi thấy là sự kết hợp với dịch thuật tình cờ thường xuyên nhất. Trong số 178 lý luận CoT được tạo ra, chỉ có tám ví dụ chứa dịch thuật tình cờ bằng tiếng Trung, tiếng Đan Mạch, tiếng Hindi, tiếng Nhật, tiếng Marathi và tiếng Thổ Nhĩ Kỳ, với một hoặc hai ví dụ cho mỗi ngôn ngữ. Ngoài ra, bảy ví dụ có tiếng Bengali trong các lý luận CoT của chúng. Tần suất tương đối cao của tiếng Bengali cho thấy rằng Henc không thể hiện hành vi hoàn toàn không phụ thuộc ngôn ngữ, và đối với một số ví dụ, LM có thể phân biệt ngôn ngữ đầu vào là tiếng Bengali. Điều này không lý tưởng, vì nó cho thấy rằng LM phải hiểu đầu vào bằng tiếng Bengali, một ngôn ngữ mà LM thiếu trình độ. Chúng tôi tin rằng hiệu suất LANGBRIDGE có thể được cải thiện thêm bằng cách giải phóng ràng buộc zero-shot và thích ứng bộ mã hóa mT5 để có tính trung tính ngôn ngữ nâng cao trước khi căn chỉnh với LM. Tuy nhiên, chúng tôi để lại việc khám phá này cho nghiên cứu tương lai.

## 6. Thảo luận

### 6.1 Suy giảm hiệu suất HRL

Trong một số trường hợp, các mô hình LANGBRIDGE thể hiện suy giảm hiệu suất trong các ngôn ngữ có nhiều tài nguyên so với các LM mục tiêu của chúng. Mặc dù chúng tôi để lại việc điều tra thêm cho các nghiên cứu tương lai, chúng tôi nêu ra một số phỏng đoán về các nguyên nhân tiềm ẩn cho những suy giảm hiệu suất này.

• Với việc LM mục tiêu đã thành thạo một ngôn ngữ nhất định, các biểu diễn văn bản được bắt nguồn từ các lời nhắc mềm có thể khó giải thích hơn đối với LM so với những biểu diễn từ lớp embedding bản địa của LM.

• Do ngân sách tính toán hạn chế, các mô hình LANGBRIDGE được huấn luyện với độ dài chuỗi đầu vào tối đa là 1024 (Xenc) và độ dài chuỗi đầu ra tối đa là 128 (Xlm). Điều này ngắn hơn đáng kể so với những gì các mô hình ngôn ngữ ban đầu được huấn luyện, đặc biệt là đối với các mô hình ngôn ngữ được huấn luyện chỉ trên dữ liệu không có nhãn như Llemma.

• Chúng tôi cố định các siêu tham số huấn luyện cho tất cả các mô hình LANGBRIDGE bất kể LM mục tiêu vì tính nhất quán và để tiết kiệm ngân sách tính toán. Điều này có thể không tối ưu cho một số mô hình LANGBRIDGE.

• Đối với Code Llama và Orca 2, các kho dữ liệu huấn luyện ban đầu của chúng không thể truy cập. Do đó, chúng tôi chọn thay thế gần nhất như đã nêu trong Phần 4.1. Tuy nhiên, một sự thay đổi phân bố nhỏ trong quá trình huấn luyện LM và huấn luyện LANGBRIDGE là không thể tránh khỏi.

### 6.2 Khả năng CoT đa ngôn ngữ?

Vì LANGBRIDGE chỉ sử dụng dữ liệu tiếng Anh để huấn luyện, dự kiến rằng các bước lý luận trung gian, hoặc CoT, của các mô hình LANGBRIDGE sẽ chủ yếu bằng tiếng Anh. Với việc LANGBRIDGE nhắm vào các LM tập trung vào tiếng Anh chuyên về lý luận, chúng tôi phỏng đoán rằng CoT tiếng Anh là một trong những thành phần chính góp phần vào hiệu suất cạnh tranh của các mô hình LANGBRIDGE. Tuyên bố này được hỗ trợ bởi các phát hiện của Shi et al. (2023), nơi họ quan sát CoT tiếng Anh nhất quán dẫn đến kết quả cạnh tranh, và cho thấy rằng CoT tiếng Anh phục vụ như một "baseline hữu ích cho công việc lý luận đa ngôn ngữ tương lai".

Mặc dù chúng tôi tin rằng việc kết hợp dữ liệu không phải tiếng Anh vào dữ liệu huấn luyện LANGBRIDGE có thể tạo ra khả năng CoT đa ngôn ngữ trong các mô hình LANGBRIDGE, phương pháp này không phù hợp với động lực ban đầu của công việc này, đó là tránh nhu cầu thu thập dữ liệu lý luận đa ngôn ngữ.

## 7. Kết luận

Trong bài báo này, chúng tôi đề xuất LANGBRIDGE, một phương pháp đơn giản nhưng hiệu quả để mở rộng khả năng của LM để giải quyết các tác vụ lý luận đa ngôn ngữ mà không sử dụng giám sát đa ngôn ngữ. Chúng tôi cho thấy rằng LANGBRIDGE hiệu quả đáng ngạc nhiên trong việc cải thiện khả năng lý luận đa ngôn ngữ cho các ngôn ngữ ít tài nguyên. Ngoài ra, chúng tôi cung cấp phân tích cho thấy hiệu quả của LANGBRIDGE là do bản chất không phụ thuộc ngôn ngữ của các biểu diễn đa ngôn ngữ. Chúng tôi hy vọng các phát hiện của chúng tôi sẽ có lợi cho người dùng ngôn ngữ ít tài nguyên và thúc đẩy nghiên cứu thêm về việc phát triển các LM bao gồm toàn bộ cộng đồng toàn cầu.

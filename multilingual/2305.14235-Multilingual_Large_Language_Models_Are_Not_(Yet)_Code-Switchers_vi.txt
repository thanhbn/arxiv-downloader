Các Mô hình Ngôn ngữ Lớn Đa ngôn ngữ (Vẫn) Chưa Phải là Những Người Chuyển đổi Mã

Ruochen Zhang∗1Samuel Cahyawijaya∗2
Jan Christian Blaise Cruz∗3Genta Indra Winata∗4Alham Fikri Aji∗ ∗5
1Đại học Brown2HKUST
3Viện R&D Samsung Philippines4Bloomberg5MBZUAI

Tóm tắt
Các Mô hình Ngôn ngữ Lớn Đa ngôn ngữ (LLMs) gần đây đã cho thấy khả năng tuyệt vời trong nhiều tác vụ khác nhau, thể hiện hiệu suất tiên tiến thông qua các phương pháp prompting zero-shot hoặc few-shot. Trong khi đã có nhiều nghiên cứu sâu rộng về khả năng của chúng trong các tác vụ đơn ngôn ngữ, việc điều tra tiềm năng của chúng trong bối cảnh chuyển đổi mã (CSW), thực hành xen kẽ các ngôn ngữ trong một phát ngôn, vẫn còn tương đối chưa được khám phá. Trong bài báo này, chúng tôi cung cấp một phân tích thực nghiệm toàn diện về các LLMs đa ngôn ngữ khác nhau, đánh giá hiệu suất của chúng trên bốn tác vụ: phân tích cảm xúc, dịch máy, tóm tắt và nhận dạng ngôn ngữ cấp từ. Kết quả của chúng tôi cho thấy rằng mặc dù các LLMs đa ngôn ngữ thể hiện kết quả hứa hẹn trong một số tác vụ sử dụng prompting zero hoặc few-shot, chúng vẫn hoạt động kém hơn so với các mô hình fine-tuned có quy mô nhỏ hơn nhiều. Chúng tôi lập luận rằng "đa ngôn ngữ" hiện tại trong LLMs không vốn dĩ ngụ ý thành thạo với các văn bản chuyển đổi mã, kêu gọi nghiên cứu tương lai để thu hẹp sự khác biệt này.

1 Giới thiệu
Các Mô hình Ngôn ngữ Lớn (LLMs) đã cho thấy tiềm năng của chúng trong bối cảnh prompting zero-shot và few-shot (Brown et al., 2020; Kojima et al., 2022; Wei et al., 2022; Longpre et al., 2023). Những thành công của các LLMs này cũng có hiệu quả trong các thiết lập đa ngôn ngữ (Lin et al., 2021; Winata et al., 2021b; Scao et al., 2022) nơi các mô hình được huấn luyện cụ thể để học các ngôn ngữ riêng lẻ, được chứng minh là có lợi cao cho các tác vụ đơn ngôn ngữ. Tuy nhiên, trong các cộng đồng đa ngôn ngữ, mọi người không giới hạn mình chỉ nói một ngôn ngữ duy nhất; thay vào đó, họ sử dụng hai hoặc nhiều ngôn ngữ thay thế lẫn nhau trong một cuộc trò chuyện - một hiện tượng được gọi là chuyển đổi mã (CSW) (Poplack, 1980, 2001). Nó cho phép các cá nhân giao tiếp các khái niệm cụ thể của văn hóa hiệu quả hơn, báo hiệu danh tính nhóm của họ và củng cố kết nối xã hội của họ (Doğruöz et al., 2021). Tuy nhiên, các LLMs đa ngôn ngữ hiện tại không được huấn luyện cụ thể với các mục tiêu để quản lý các tình huống CSW. Do đó, việc đánh giá khả năng của các LLMs đa ngôn ngữ hiện tại trong việc xử lý các văn bản CSW là thiết yếu cho việc phát triển các mô hình ngôn ngữ đa ngôn ngữ hoàn toàn tương thích với chuyển đổi mã.

Thách thức chính của việc phát triển các LLMs đa ngôn ngữ được tối ưu hóa cho chuyển đổi mã nằm ở sự khan hiếm dữ liệu. Do đặc tính thông tục cao của chuyển đổi mã (Winata et al., 2022b), các tài nguyên hiện có dành cho CSW rất hiếm và việc thu thập quy mô lớn đòi hỏi nỗ lực chú thích đáng kể. Để giảm thiểu sự thiếu hụt như vậy, Yong et al. (2023) điều tra khả năng sử dụng các LLMs đa ngôn ngữ để tạo ra các văn bản CSW tổng hợp chất lượng cao. Nghiên cứu cho thấy rằng, các LLMs được lưu trữ, như InstructGPT (Ouyang et al., 2022) và ChatGPT1 vượt trội hơn các mô hình công khai như BLOOMZ (Muennighoff et al., 2022) và Flan-T5-XXL (Chung et al., 2022) trong việc tạo ra các văn bản CSW có âm thanh tự nhiên. Tuy nhiên, chất lượng của văn bản được tạo ra bởi các LLMs được lưu trữ này chủ yếu bị giới hạn ở Singlish và giảm đáng kể khi được nhắc cho các ngôn ngữ khác. Mặc dù có kết quả hứa hẹn ban đầu, việc tạo ra các văn bản CSW chất lượng cao vẫn còn đầy thách thức. Quan sát này thúc đẩy chúng tôi khám phá từ một góc độ khác - Các LLMs đa ngôn ngữ hiện tại có thể hiểu CSW một cách hiệu quả không?

Đã có các nghiên cứu trước đó về việc đánh giá các LMs đa ngôn ngữ trong các tình huống CSW (Tan và Joty, 2021; Adilazuarda et al., 2022), nơi các văn bản chuyển đổi mã được mô phỏng bằng cách thay thế các từ từ các corpus song song. Winata et al. (2021a) cũng đánh giá hiệu quả của các mô hình bằng cách thử nghiệm với các word embeddings được xây dựng từ các phương pháp khác nhau. Những công trình này chủ yếu được xây dựng dựa trên các mô hình dựa trên BERT nhỏ và bị hạn chế bởi số lượng ngôn ngữ hoặc tác vụ được điều tra. Với thành công gần đây của các phương pháp prompting trên các LLMs đa ngôn ngữ và hiệu ứng của việc mở rộng quy mô, bài báo này trình bày một phân tích thực nghiệm toàn diện hơn về khả năng chuyển đổi mã của các mô hình, bao gồm nhiều ngôn ngữ, loại tác vụ, kiến trúc mô hình, kích thước mô hình và phương pháp prompting.

Kết quả của chúng tôi cho thấy rằng định luật mở rộng quy mô có thể áp dụng cho các LLMs đa ngôn ngữ trên các tác vụ CSW đa dạng và kiến trúc mô hình. Tuy nhiên, các mô hình fine-tuned quy mô nhỏ hơn vượt trội đáng kể so với LLM đa ngôn ngữ lớn nhất với các phương pháp prompting. Ngoài ra, trong khi các LLMs được lưu trữ đạt được điểm số tương đương với các mô hình fine-tuned của chúng tôi, hiệu suất như vậy vẫn không thể diễn giải được do tính đóng kín của chúng. Chúng tôi lập luận rằng các LLMs đa ngôn ngữ hiện tại thể hiện thành thạo hạn chế trong các bối cảnh chuyển đổi mã, làm nổi bật các cơ hội nghiên cứu tương lai để biến đổi chúng thành những người đa ngôn ngữ thực sự.

2 Thiết lập Thí nghiệm
2.1 Tập dữ liệu
Chúng tôi khám phá bốn loại tác vụ chuyển đổi mã: phân tích cảm xúc (SA), dịch máy (MT), tóm tắt (SUM), và nhận dạng ngôn ngữ cấp từ (LID). Mô tả của mỗi tác vụ như sau:

Phân tích Cảm xúc Chúng tôi sử dụng các tập dữ liệu phân tích cảm xúc của ba cặp ngôn ngữ khác nhau: Sentimix Tây Ban Nha-Tiếng Anh (Aguilar et al., 2020), MixSentiment Malayalam (Chakravarthi et al., 2020a), và MixSentiment Tamil (Chakravarthi et al., 2020b). Bên cạnh các nhãn tích cực và tiêu cực thông thường, các tập dữ liệu này cũng chứa các nhãn bổ sung như trung tính hoặc khác. Tuy nhiên, sự xuất hiện của những nhãn đó rất hiếm. Do đó, để chuẩn hóa các tập dữ liệu từ các nguồn khác nhau, chúng tôi đơn giản hóa dữ liệu bằng cách lọc ra các ví dụ ngoài nhãn tích cực hoặc tiêu cực. Kích thước tập dữ liệu, được chia thành train/validation/test, như sau: 8,831/8,831/1,342 cặp cho tập con Tây Ban Nha-Tiếng Anh, 2,541/275/703 cho Malayalam, và 9,075/1,022/2,499 cho tập con Tamil.

Dịch Máy Chúng tôi sử dụng các tập dữ liệu chuyển đổi mã từ nhiệm vụ chia sẻ MixMT 2022 (Srivastava và Singh, 2022) chứa các cặp câu Hinglish-Tiếng Anh (8,060 cặp trong phần huấn luyện, 942 cặp trong validation và 960 cặp trong tập test).

Tóm tắt Chúng tôi sử dụng tập dữ liệu tóm tắt chuyển đổi mã Gupshup (Mehnaz et al., 2021), được tạo ra từ SAMSum (Gliwa et al., 2019) thông qua dịch thuật đám đông. Trong thí nghiệm của chúng tôi, chúng tôi tập trung vào Hinglish sang Tiếng Anh, vì việc đánh giá tóm tắt chuyển đổi mã một cách có hệ thống với các chỉ số tự động hiện có đã được chứng minh là đầy thách thức cho các LLMs đa ngôn ngữ (Zhang và Eickhoff, 2023). Tập dữ liệu chứa 5,831 cặp nguồn-đích cho huấn luyện, với 500 cặp mỗi cái cho validation và testing.

LID cấp từ Chúng tôi sử dụng các tập con Tiếng Anh-Hindi và Tiếng Ả Rập Chuẩn Hiện đại (MSA) - Tiếng Ả Rập Ai Cập (EA) từ tác vụ Nhận dạng Ngôn ngữ trong benchmark LinCE (Aguilar et al., 2020). Trong tác vụ này, hệ thống được giao nhiệm vụ phân loại ngôn ngữ của mỗi từ trong một câu thành một trong ba lớp, lang1, lang2, hoặc other. lang1 và lang2 lần lượt là Tiếng Anh và Hindi, hoặc MSA và EA. Tập con Tiếng Anh-Hindi chứa 4,832 ví dụ huấn luyện và 744 ví dụ validation. Đối với tập con MSA-EA, nó chứa 8,464 ví dụ cho huấn luyện và 1,116 cho validation. Kết quả của chúng tôi được báo cáo trên tập validation vì tập test không có sẵn công khai.

2.2 Mô hình
Mô hình Zero-shot và Few-shot Đối với prompting zero-shot và few-shot, chúng tôi khám phá các LLMs tạo sinh đa ngôn ngữ khác nhau của các quá trình pretraining và kiến trúc khác nhau, bao gồm BLOOMZ, mT0 (Muennighoff et al., 2022) và XGLM (Lin et al., 2021). Chúng tôi khám phá tất cả các kích thước mô hình ngoại trừ BLOOMZ 175B do hạn chế tài nguyên. Chúng tôi cũng bao gồm ChatGPT vào phân tích của mình và cụ thể là GPT-3.5 turbo được sử dụng. Chúng tôi khám phá 0, 1, 3, và 5-shot trên mỗi mô hình với 5 mẫu prompt đa dạng. Chi tiết cho mỗi prompt có thể được xem trong Phụ lục C.

Đối với tác vụ SA, chúng tôi tính xác suất của mô hình để tạo ra mỗi nhãn như là việc tạo sinh tiếp tục ngay lập tức tiếp theo, và sau đó chúng tôi chọn nhãn dẫn đến xác suất cao nhất cho toàn bộ chuỗi. Đối với MT, SUM và LID, chúng tôi thực hiện tạo sinh văn bản tiêu chuẩn. Tuy nhiên, đối với LID, chúng tôi mong đợi văn bản được tạo ra tuân theo một định dạng được xác định trước nơi mỗi cặp [token, language tag] được biểu diễn như [ token | tag ]. Chúng tôi phân tích việc tạo sinh bằng cách sử dụng một thuật toán lập trình động được giới thiệu trong Paolini et al. (2021) để trích xuất các cặp [token, language tag] hợp lệ cho đánh giá.

Mô hình Fine-tuning Ngoài các mô hình prompting zero-shot và học trong ngữ cảnh few-shot, chúng tôi cũng thử nghiệm với fine-tuning như một benchmark so với prompting. Đối với các tác vụ SA và LID cấp từ, chúng tôi fine-tune bốn mô hình, cụ thể là, các biến thể base và large của XLM-RoBERTa (Conneau et al., 2020), mBERT (Devlin et al., 2019), và mDeBERTa v3 (He et al., 2021).

Đối với MT, chúng tôi fine-tune tổng cộng tám mô hình. Chúng bao gồm các biến thể small, base, và large của mT0 (Muennighoff et al., 2022); các biến thể 418M và 1.2B của M2M100 (Fan et al., 2020); và các biến thể tiêu chuẩn, one-to-many, và many-to-many của mBART-50 (Liu et al., 2020; Tang et al., 2020).

Đối với SUM, chúng tôi tuân theo cùng một thiết lập được sử dụng trong MT, ngoại trừ chúng tôi chỉ fine-tune ba mô hình mT0 đã đề cập trước đó và chỉ mBART-50 tiêu chuẩn vì các biến thể one-to-many và many-to-many chỉ dành riêng cho dịch thuật.

Trên tất cả các tác vụ, chúng tôi fine-tune các mô hình đã chọn trên tất cả các trường hợp huấn luyện có sẵn. Bảng 1 cho thấy một tổng quan đầy đủ và so sánh các mô hình được điều tra trong nghiên cứu này và chi tiết cho các thiết lập huấn luyện cho tất cả các tác vụ có thể được tìm thấy trong Phụ lục A.

3 Kết quả và Thảo luận
Kết quả Tổng thể Hình 2 trình bày kết quả của các LLMs đa ngôn ngữ khác nhau cho bốn tác vụ CSW. Nói chung, chúng tôi quan sát một mô hình mở rộng quy mô khi prompting các LLMs đa ngôn ngữ trên các tác vụ. Tuy nhiên, hiệu suất của các mô hình này giảm đáng kể khi so sánh với các mô hình fine-tuned nhỏ hơn đáng kể. Do đó, việc áp dụng một mô hình fine-tuned là một cách tiếp cận thực tế hơn để xử lý các tác vụ CSW, đặc biệt trong các tình huống với tài nguyên tính toán hạn chế. Đối với ChatGPT, nó thể hiện hiệu suất tương đương với các mô hình fine-tuned trên tất cả các tác vụ và tập dữ liệu, ngoại trừ tác vụ MT Tiếng Anh sang Hinglish. Ngoại lệ này có thể xuất phát từ những thách thức trong việc tạo sinh các văn bản chuyển đổi mã như được nêu trong nghiên cứu trước đó (Yong et al., 2023; Zhang và Eickhoff, 2023). Đối với các tác vụ còn lại, ChatGPT vượt trội rõ rệt so với các LLMs đa ngôn ngữ có sẵn công khai. Sự khác biệt như vậy có thể được quy cho mục tiêu RLHF trong quá trình pretraining của nó, mặc dù một phân tích toàn diện bị cản trở bởi tính chất độc quyền của nó.

3.1 Kết quả Phân tích Cảm xúc
Hình 5 cho thấy sự phân tích chi tiết cho mỗi trong ba tập dữ liệu ngôn ngữ trong tác vụ SA. Kết quả từ các mô hình fine-tuned chủ yếu nằm ở góc trên bên trái trên cả ba tập dữ liệu, làm nổi bật hiệu suất vượt trội của chúng với kích thước nhỏ hơn đáng kể. Việc mở rộng quy mô BLOOMZ và XGLM mang lại những cải thiện nhỏ, tuy nhiên, điểm số từ mT0 dao động khoảng 50 F1 khi thay đổi kích thước. Đáng chú ý rằng baseline lớp đa số của ba tập dữ liệu này có điểm F1 trung bình là 46. Xem xét sự không ổn định được quan sát trong quá trình mở rộng quy mô, mT0 gặp khó khăn trong việc hiểu cảm xúc khi được trình bày trong các văn bản CSW.

3.2 Kết quả Dịch Máy
Như được hiển thị trong Hình 2 và Bảng 2, khi nguồn là Hinglish và đích là Tiếng Anh, khoảng cách hiệu suất giữa prompting và fine-tuning trong MT rõ ràng hơn nhiều, với LLM được prompt tốt nhất mT0-XXL đạt không quá 20 BLEU trong khi tất cả các mô hình fine-tuned đạt được từ 25-32 điểm BLEU. Trái ngược với SA, chúng tôi nhận thấy sự cải thiện đặc biệt rõ ràng trong quá trình mở rộng quy mô các mô hình kiểu encoder-decoder như mT0, trong khi các mô hình chỉ decoder như BLOOMZ và XGLM có những cải thiện tối thiểu do hiệu suất tổng thể kém của chúng.

Sau đó chúng tôi so sánh sự khác biệt trong việc mở rộng quy mô LLM giữa các tác vụ dịch thuật với nguồn chuyển đổi mã và đơn ngôn ngữ. Hình 3 cho thấy quỹ đạo mở rộng quy mô của các LLMs cho cả hướng dịch Hindi → Tiếng Anh và Hinglish → Tiếng Anh; Bảng 3 trình bày hệ số hồi quy (β) trong hai tình huống này. Một hệ số lớn cho thấy việc mở rộng quy mô có tác động đáng chú ý hơn. Chúng tôi có thể quan sát rằng ảnh hưởng của việc mở rộng quy mô rõ ràng hơn trong các nguồn đơn ngôn ngữ so với trong thiết lập chuyển đổi mã. Mô hình này có thể xuất phát từ các mẫu pretraining hạn chế cho dữ liệu chuyển đổi mã Hinglish, dẫn đến hiệu suất mở rộng quy mô không tối ưu.

Khi các mô hình được giao nhiệm vụ dịch nguồn thành văn bản CSW, một sự suy giảm hiệu suất đáng kể được quan sát cho cả mô hình fine-tuned và prompted. Chúng tôi nhận thấy rằng trong khi các mô hình mT0 lớn hơn có khả năng tạo ra các bản dịch Tiếng Anh theo cách zero-shot, chúng gặp khó khăn trong việc tạo sinh các văn bản CSW như được thấy trong công trình trước đó (Yong et al., 2023). Khi nhìn vào đầu ra, mT0 chỉ đơn giản xuất ra bằng Tiếng Anh, ngay cả trong các thiết lập few-shot mà nó đã thấy một số ví dụ Hinglish khác.

3.3 Kết quả Tóm tắt
Hình 2 cho thấy kết quả fine-tuning và prompting zero-shot trên tác vụ tóm tắt. Tương tự, chúng ta thấy rằng các mô hình fine-tuned vượt trội hơn cách tiếp cận zero-shot. Tương tự như MT, mT0 mang lại hiệu suất tổng thể tốt nhất và cho thấy định luật mở rộng quy mô tích cực.

Để tách CSW khỏi phương trình, chúng tôi đánh giá hiệu suất của LLM trên cùng tập dữ liệu Gupshup, nhưng với đầu vào Tiếng Anh thay vì đầu vào Hinglish. Tập đánh giá song song với nhau. Thú vị là, từ Hình 3 và Bảng 3, chúng ta thấy tác động mở rộng quy mô tương tự dù đầu vào là đơn ngôn ngữ hay chuyển đổi mã. Tuy nhiên, các mô hình luôn tốt hơn nếu đầu vào là Tiếng Anh.

3.4 Kết quả Nhận dạng Ngôn ngữ
Quan sát của chúng tôi về các mô hình fine-tuned trong tác vụ LID tương tự như tác vụ MT: chúng vượt trội hơn các phương pháp prompting trên các LLMs đa ngôn ngữ với biên độ đáng kể. Trong Bảng 2, chúng tôi báo cáo kết quả 5-shots thay vì 0-shot prompting cho các tác vụ LID vì kết quả 0-shot đều là 0 cho cả hai tập dữ liệu ngôn ngữ và trên tất cả các mô hình. Các LLMs đa ngôn ngữ không thể hiểu hướng dẫn ngôn ngữ tự nhiên yêu cầu chúng tạo ra đầu ra theo một định dạng cụ thể như [ token | tag ] từng từ một. Khi thêm nhiều ví dụ trong ngữ cảnh vào hướng dẫn, chúng tôi quan sát những cải thiện hiệu suất nhỏ trên các mô hình khác nhau. Đối với kết quả về các thí nghiệm few-shot cho LID, vui lòng tham khảo Phần 3.5.

3.5 Kết quả Few-Shot
So với suy luận zero-shot, học few-shot đã được chứng minh là tăng cường hiệu suất như được thảo luận trong các công trình trước đó (Brown et al., 2020; Liu et al., 2021). Tuy nhiên, trong các thiết lập CSW, chúng tôi quan sát các hiệu ứng khác nhau của việc thêm nhiều ví dụ trong ngữ cảnh giữa các tác vụ. Trong Hình 4, chúng tôi nhận thấy sự giảm trong các chỉ số từ 0-shot đến 1-shot cho SA và SUM, cho thấy rằng các ví dụ trong ngữ cảnh không đóng góp hoặc thậm chí làm suy giảm hiệu suất của các mô hình. Chúng tôi nghi ngờ rằng các mô hình đã thấy các tác vụ này theo cách đơn ngôn ngữ trong quá trình pretraining, và do đó có thể hiểu hướng dẫn tốt trong thiết lập zero-shot. Thay vào đó, các mô hình có thể coi các ví dụ CSW như các văn bản chất lượng thấp, do đó gây nhầm lẫn cho quá trình tạo sinh. Đối với MT, chúng tôi quan sát sự thay đổi không đáng kể trong hiệu suất của các mô hình với số lượng ví dụ tăng lên. Đáng chú ý, thay vì dịch các câu sang Hinglish như được hướng dẫn, các mô hình chỉ có thể lặp lại các câu Tiếng Anh gốc. Ví dụ, khi được cung cấp 5 ví dụ trong ngữ cảnh, mT0 13B được hướng dẫn "Translate the following text from English to Hinglish. Text: hello there, I have not seen this movie so im going to take a minute to look it over :) Translation:". Nó tạo ra "hello there, I have not seen this movie so I going to take time to look it over:)." thay vì kết quả mong đợi "hello yar, mein is movie ko nahi dekha hoon tho, tho mein thode der ke liye isko dekh loonga". Các vấn đề tương tự cũng được quan sát với BLOOMZ. Chúng tôi giả thuyết rằng các mô hình có thể không hiểu đầy đủ các sắc thái của 'Hinglish' trong hướng dẫn đã cho, điều này có thể giải thích cho hiệu suất tương đối đồng nhất của chúng trên các số shot khác nhau.

Ngược lại, nhiều ví dụ trong ngữ cảnh có lợi cho tác vụ LID. Vì không có mô hình nào được pre-train trên tác vụ gắn thẻ chuỗi, hướng dẫn tự nhiên bao gồm định dạng tạo sinh cụ thể là mới đối với các LLMs. Do đó, trong các thí nghiệm của chúng tôi, hầu hết các mô hình hoạt động tốt nhất khi được cung cấp 5 ví dụ học. Ngoài ra, mặc dù chúng tôi quan sát các mô hình định luật mở rộng quy mô trong các thiết lập 5-shot như được hiển thị trong Hình 6, đối với các mô hình tỷ tham số hoạt động tốt nhất, chúng tôi vẫn liên tục quan sát sự không thể tuân thủ định dạng được đặt ra trong hướng dẫn. Chúng thường không thể sao chép các từ chính xác cần thiết cho việc gắn thẻ câu hoặc dự đoán nhiều token trong một cặp ngoặc đơn. Ví dụ, trong thiết lập 5-shot, khi được yêu cầu gắn nhãn câu "we the fans luv you , sirji", BLOOMZ 7b tạo ra sai "[ we the fans | lang1 ] [ you | lang1 ] [ sirji | lang1 ] [ , | other ]", không thể đặt từng từ riêng lẻ trong ngoặc và bỏ sót một số từ từ câu gốc. Do ràng buộc của độ dài đầu vào hạn chế, điều này hạn chế số lượng ví dụ trong ngữ cảnh mà các mô hình có thể học từ đó, việc tạo sinh không thể kiểm soát của chúng vẫn dẫn đến khoảng cách hiệu suất đáng kể khi so sánh với việc fine-tune các mô hình nhỏ hơn (~20 F1 so với ~80 F1).

3.6 Đánh giá ChatGPT
Với những phát triển gần đây trong các LLMs mục đích chung, tuân theo hướng dẫn như ChatGPT, với khả năng zero-shot ấn tượng trên các tác vụ, chúng tôi cũng đánh giá hiệu suất của ChatGPT trong tác vụ CSW của chúng tôi. Bị hạn chế bởi ngân sách, chúng tôi chỉ khám phá hiệu suất zero-shot cho SA, MT và SUM do phạm vi dễ dàng của chúng, và hiệu suất 1-shot cho LID do yêu cầu định dạng đầu ra cụ thể. Vì chúng tôi không thể truy cập phân phối xác suất đầu ra của ChatGPT, chúng tôi hướng dẫn ChatGPT trả về chỉ chuỗi nhãn chính xác và tính điểm F1 sử dụng khớp chuỗi chính xác cho SA.

ChatGPT đạt được hiệu suất có phần tương đương với các mô hình finetuning và vượt trội đáng kể so với các LLMs đa ngôn ngữ công khai khác trong hầu hết các tác vụ. Đặc biệt cho LID, nó cho thấy khả năng mạnh trong việc tuân theo các hướng dẫn khó khăn chỉ với một ví dụ. Ngoại lệ duy nhất là trên các tác vụ MT Tiếng Anh→Hinglish, nơi hiệu suất zero-shot của nó chỉ tốt hơn một chút so với các LLMs công khai khác. Chúng tôi giả thuyết chủ yếu hai lý do đằng sau khó khăn trong việc tạo sinh các văn bản CSW: 1) như được ám chỉ trong phần trước, các văn bản CSW có thể được coi như nhiễu do các tác vụ và quá trình pretraining được thiết kế theo cách đơn ngôn ngữ; 2) LLMs có thể thiếu đại diện đầy đủ cho cấu trúc văn bản CSW. Trong phân tích của chúng tôi, LLMs hoạt động tốt hơn nhiều trong các tác vụ SA vì chúng có thể nhận được gợi ý từ các công việc riêng lẻ thay vì chú ý đến "cấu trúc" ngôn ngữ khi được giao nhiệm vụ tạo sinh văn bản.

Cuối cùng, trong khi ChatGPT mang lại kết quả hứa hẹn mà không cần fine-tuning nào, việc thiếu minh bạch hoàn toàn về các tập dữ liệu pretraining, kiến trúc mô hình và chi tiết huấn luyện của nó cản trở sự hiểu biết tốt hơn về hiệu suất của nó. Điều này tạo ra các rào cản cho những cải thiện tương lai trong thành thạo chuyển đổi mã cho các LLMs đa ngôn ngữ công khai.

4 Hàm ý cho các LLMs Tương lai
Trong phần này, chúng tôi đi qua các hàm ý khác nhau của công trình của chúng tôi và cung cấp các khuyến nghị để cho phép khả năng CSW tốt hơn trong LLMs. Bằng cách làm nổi bật hạn chế này, chúng tôi thúc ép các nhà nghiên cứu xem xét CSW như một tính năng cốt lõi của repertoire đa ngôn ngữ của nhiều người trên toàn thế giới.

Đại diện Dữ liệu Công bằng hơn cho Chuyển đổi Mã
Kết quả của chúng tôi trong Phần 3 cho thấy rằng các LLMs hiện tại có các mô hình mở rộng quy mô tương tự giữa đơn ngôn ngữ và CSW. Tuy nhiên, mặc dù tất cả các mô hình được nghiên cứu đã thấy từng ngôn ngữ trong quá trình pre-training, vẫn có khoảng cách hiệu suất giữa đơn ngôn ngữ và CSW. Điều này cho thấy rằng khả năng chuyển đổi mã không được các LLMs có được sau khi pretraining và/hoặc instruction-tuning với dữ liệu đa ngôn ngữ (Xue et al., 2021; Scao et al., 2022; Muennighoff et al., 2022), cho thấy nhu cầu thêm đại diện dữ liệu tốt hơn cho chuyển đổi mã trong quá trình pretraining đa ngôn ngữ và/hoặc instruction-tuning. Cách tiếp cận như vậy có thể được thực hiện thông qua thu thập dữ liệu CSW thủ công và/hoặc các phương pháp tăng cường dữ liệu khác nhau (Tan và Joty, 2021; Adilazuarda et al., 2022; Dhole et al., 2023). Ngoài việc thêm nhiều dữ liệu CSW, một giải pháp tiềm năng là xác định và bao gồm các cặp ngôn ngữ chuyển đổi mã vào xem xét của pretraining đa ngôn ngữ và/hoặc instruction-tuning. Điều này cho phép chiến lược resampling tốt hơn (Lample và Conneau, 2019; Aharoni et al., 2019; Conneau et al., 2020; Xue et al., 2021; Tang et al., 2021; Cahyawijaya et al., 2021) cho dữ liệu CSW trong quá trình pretraining đa ngôn ngữ và/hoặc instruction-tuning.

Thích ứng và Mở rộng các Mục tiêu Tối ưu hóa Chuyển đổi Mã
Các LLMs hiện tại được tối ưu hóa chỉ với các mục tiêu mô hình hóa ngôn ngữ cho việc khử nhiễu câu hoặc hoàn thành câu. Tuy nhiên, các mục tiêu tối ưu hóa thay thế, như học chuyển giao meta (Winata et al., 2020) và mục tiêu nhận dạng ngôn ngữ cấp token/span bổ sung (Li et al., 2019), đã được chứng minh có hiệu quả trong việc tăng cường hiệu suất CSW với mất mát hiệu suất tối thiểu trên các tác vụ đơn ngôn ngữ trong xử lý giọng nói CSW. Bằng cách thích ứng và mở rộng các cách tiếp cận này cho NLP, chúng ta có thể trang bị cho LLMs khả năng CSW tốt hơn mà không yêu cầu thu thập và chú thích dữ liệu đắt đỏ. Điều này sẽ đặc biệt có lợi cho LLMs, đặc biệt trong các ứng dụng nơi CSW phổ biến trong cộng đồng đa ngôn ngữ.

Hướng tới Công nghệ Ngôn ngữ Bao trùm hơn
Trong bối cảnh LLMs là động lực đằng sau tiến bộ của các công nghệ NLP khác nhau (Thoppilan et al., 2022; SambaNova Systems, 2023; Pratap et al., 2023), chúng tôi nhấn mạnh tầm quan trọng của việc kết hợp các khả năng chuyển đổi mã trong LLMs để thúc đẩy tính bao trùm và đa dạng trong công nghệ ngôn ngữ, đặc biệt cho các người nói đa ngôn ngữ thường xuyên tham gia vào chuyển đổi mã trong cuộc sống hàng ngày của họ. Bằng cách cho phép công nghệ NLP phản ánh các mô hình trộn ngôn ngữ của người dùng, mọi người có thể giao tiếp theo những cách thoải mái và chân thực hơn với danh tính ngôn ngữ của họ, loại bỏ nhu cầu mọi người phải điều chỉnh mô hình nói của họ để trở nên dễ hiểu đối với máy móc. Nó không chỉ giảm thiểu các hiệu ứng của việc lập hồ sơ ngôn ngữ (Baugh, 2005; Dingemanse và Liesenfeld, 2022) và các thiết kế công nghệ theo chủ nghĩa bá quyền, lấy phương Tây làm trung tâm mà còn thúc đẩy sự tin tưởng lớn hơn giữa người dùng trong công nghệ ngôn ngữ thông qua các tương tác đối thoại tự nhiên. Do đó, chúng tôi thúc giục việc tích hợp các khả năng nhận dạng và tạo sinh chuyển đổi mã trong các LLMs tương lai.

5 Công trình Liên quan
Chuyển đổi Mã Chuyển đổi mã là một thực hành phổ biến được quan sát trong các cộng đồng đa ngôn ngữ nơi mọi người trộn nhiều ngôn ngữ trong một phát ngôn (Poplack, 2001). Trong khi hơn một nửa dân số thế giới nói nhiều hơn một ngôn ngữ, sự có sẵn của tài nguyên và đánh giá cho chuyển đổi mã hạn chế hơn nhiều so với tài liệu rộng lớn về các trường hợp đơn ngôn ngữ. Những thách thức chính của việc thu thập dữ liệu chuyển đổi mã chất lượng cao nằm ở tính chất thông tục của thực hành và yêu cầu thành thạo ngôn ngữ cho chú thích chính xác (Winata et al., 2022b). Những tiến bộ gần đây của các mô hình ngôn ngữ lớn "đa ngôn ngữ" thúc ép người ta khám phá liệu các mô hình này có thành thạo trong các bối cảnh chuyển đổi mã như một người đa ngôn ngữ thực sự hay không. Nghiên cứu trước đó (Winata et al., 2021a) đã nghiên cứu khả năng chuyển đổi mã của các mô hình ngôn ngữ trong các tác vụ NER và POS-tagging, tuy nhiên, công trình bị hạn chế chỉ sử dụng các word embeddings khác nhau và các mô hình chỉ encoder. Trong bài báo này, chúng tôi mở rộng các công trình trước đó và cung cấp phân tích chi tiết về nhiều biến thể mô hình, mục tiêu tác vụ và ứng dụng downstream của các cặp ngôn ngữ đa dạng được áp dụng từ các benchmarks CSW hiện có như LinCE (Aguilar et al., 2020) và GlueCOS (Khanuja et al., 2020).

Các Mô hình Ngôn ngữ Lớn Đa ngôn ngữ
Các mô hình như mBERT (Devlin et al., 2019) và XLM-R (Conneau et al., 2020) đã trở thành các lựa chọn đa ngôn ngữ được ưa chuộng cho fine-tuning có giám sát, do khả năng ấn tượng và khả năng thích ứng với nhiều ngôn ngữ. Với thành công của các mô hình tạo sinh quy mô lớn, khả năng của chúng đã được làm phong phú với các mục tiêu đa ngôn ngữ (Lin et al., 2021; Scao et al., 2022; Muennighoff et al., 2022) thông qua pretraining trên các corpus đa ngôn ngữ lớn như ROOTS (Laurençon et al., 2022), mC4 (Raffel et al., 2019) và xP3 (Muennighoff et al., 2022). Ngoài việc xuất sắc trong các benchmark đơn ngôn ngữ và đa ngôn ngữ khác nhau thông qua prompting zero-shot (Sanh et al., 2021; Wei et al., 2021; Kojima et al., 2022; Muennighoff et al., 2022; Bang et al., 2023), nghiên cứu đã cho thấy rằng việc mở rộng quy mô kích thước mô hình (Cahyawijaya et al., 2023; Kaplan et al., 2020; Fernandes et al., 2023) và kết hợp các ví dụ học trong ngữ cảnh (Winata et al., 2022a; Tanwar et al., 2023) có thể giúp tăng cường hiệu suất hơn nữa. Tuy nhiên, do sự khan hiếm của các tài nguyên đánh giá CSW, cách các LLMs đa ngôn ngữ này hoạt động trong các tình huống chuyển đổi mã vẫn còn đáng ngờ. Trong bài báo này, chúng tôi đánh giá các mô hình này dưới các thiết lập khác nhau bao gồm fine-tuning, prompting zero-shot, và học trong ngữ cảnh, và cung cấp các khuyến nghị cho những cải thiện tương lai trong thành thạo chuyển đổi mã.

6 Kết luận
Trong bài báo này, chúng tôi nghiên cứu có hệ thống khả năng của các LLMs đa ngôn ngữ trong các tác vụ chuyển đổi mã theo các chiều khác nhau, bao gồm nhưng không giới hạn ở finetuning vs. prompting, mục tiêu tác vụ, định luật mở rộng quy mô và kiến trúc mô hình. Chúng tôi quan sát rằng, mặc dù có những cải thiện với kích thước lớn hơn, các LLMs đa ngôn ngữ hiện tại vẫn mang lại hiệu suất kém hơn so với việc fine-tuning các mô hình nhỏ hơn. Chúng tôi lập luận rằng các LLMs đa ngôn ngữ không nhất thiết tương thích với chuyển đổi mã. Do các LLMs đa ngôn ngữ không được huấn luyện rõ ràng cho dữ liệu chuyển đổi mã, chúng tôi khuyến nghị phát triển tương lai nên kết hợp một khung đánh giá toàn diện hơn bao gồm các văn bản chuyển đổi mã. Cuối cùng, nghiên cứu của chúng tôi bị giới hạn ở hiệu suất của các mô hình trong phân tích cảm xúc, dịch máy, tóm tắt và nhận dạng ngôn ngữ. Chúng tôi đề xuất rằng việc đánh giá trên một tập hợp tác vụ rộng hơn là cần thiết. Tuy nhiên, sự khan hiếm của các tập dữ liệu chuyển đổi mã mã nguồn mở chất lượng cao và những thách thức liên quan đến quá trình thu thập của chúng ngụ ý rằng công việc tương lai cũng nên bao gồm việc xây dựng dữ liệu chuyển đổi mã với độ phức tạp hơn, như lý luận thông thường.

Hạn chế
Phạm vi của các ngôn ngữ chuyển đổi mã trong công trình này bị giới hạn ở Hindi-Tiếng Anh, Tiếng Ả Rập Chuẩn-Ai Cập, Tây Ban Nha-Tiếng Anh, Tamil-Tiếng Anh, và Malayalam-Tiếng Anh. Sẽ có lợi khi bao gồm nhiều ngôn ngữ hơn để chứng minh tính tổng quát của tuyên bố của chúng tôi. Tuy nhiên, một thách thức trong việc làm như vậy phát sinh từ việc thiếu các tập dữ liệu văn bản chuyển đổi mã có sẵn. Chúng tôi khám phá bốn tác vụ NLP downstream khác nhau. Tuy nhiên, tương tự như điểm trước, sẽ thú vị khi bao quát nhiều tác vụ hơn. Tương tự, thách thức chính của việc mở rộng vào các tác vụ khác nhau là thiếu các tập dữ liệu có sẵn. Chúng tôi dự đoán rằng các nghiên cứu tương lai sẽ mở rộng việc khám phá các ngôn ngữ và tác vụ chuyển đổi mã ngoài những cái được kiểm tra trong nghiên cứu này để thể hiện khả năng tổng quát hóa của các phát hiện cho các ngôn ngữ và tác vụ chuyển đổi mã khác.

Ngoài ra, trong nghiên cứu này, chúng tôi chọn các LLMs đa ngôn ngữ dựa trên hai tiêu chí: 1) chúng trình bày hoặc quảng cáo bản thân như đa ngôn ngữ và 2) dữ liệu pretraining của chúng chứa tất cả các ngôn ngữ có trong tập dữ liệu benchmark của chúng tôi. Mặc dù một số LLMs được phát hành gần đây như Llama-2 (Touvron et al., 2023) và Falcon (Penedo et al., 2023) đã chứng minh hiệu suất tiên tiến trên các benchmark khác nhau, chúng tôi hoãn việc đánh giá khả năng chuyển đổi mã của chúng cho nghiên cứu tương lai.

Cuối cùng, các quan sát của chúng tôi dựa trên các kích thước mô hình được cho phép bởi tài nguyên tính toán cục bộ của chúng tôi. Một phân tích toàn diện hơn có thể được có được bằng cách thử nghiệm với phạm vi rộng hơn các biến thể, bao gồm kích thước mô hình lớn hơn và nhiều ví dụ trong ngữ cảnh hơn với ngân sách tính toán hào phóng hơn.

Cân nhắc Đạo đức
Bài báo của chúng tôi làm nổi bật việc đánh giá LLMs về chuyển đổi mã, một hiện tượng phổ biến trong cộng đồng đa ngôn ngữ. Nghiên cứu được thực hiện tuân thủ các nguyên tắc của sự chính trực học thuật, bao gồm sự trung thực, minh bạch và nghiêm túc. Dữ liệu được sử dụng trong nghiên cứu này được thu thập theo các hướng dẫn đạo đức, và tất cả các tham gia viên đã cung cấp sự đồng ý có thông tin. Trong nghiên cứu của chúng tôi, chúng tôi nhận thức được tác động tiềm năng đi kèm với công trình của chúng tôi và các thí nghiệm của chúng tôi sao chép công trình trước đó dưới các điều kiện thực nghiệm tương đương. Chúng tôi cũng đảm bảo rằng nghiên cứu không gây hại hoặc đau khổ cho bất kỳ cá nhân hoặc cộng đồng nào. Các phát hiện của nghiên cứu này có những hàm ý quan trọng cho việc phát triển các LLMs đa ngôn ngữ và các ứng dụng tiềm năng của chúng trong các tác vụ chuyển đổi mã. Tuy nhiên, chúng tôi thừa nhận rằng cần có nghiên cứu thêm để giải quyết các hạn chế và khoảng trống được xác định trong nghiên cứu này. Chúng tôi tin rằng việc sử dụng có trách nhiệm và đạo đức của công nghệ ngôn ngữ là rất quan trọng để tạo ra các hệ thống công bằng và bình đẳng có lợi cho tất cả các cá nhân và cộng đồng.

Lời cảm ơn
Chúng tôi muốn cảm ơn Xinyu Hua và Samson Tan vì những phản hồi mang tính xây dựng và thảo luận hữu ích về dự án của chúng tôi.

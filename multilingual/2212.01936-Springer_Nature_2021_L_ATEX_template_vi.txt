# 2212.01936.pdf
# Đã chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/multilingual/2212.01936.pdf
# Kích thước file: 5419028 bytes

===============================================
NỘI DUNG FILE PDF
===============================================

--- TRANG 1 ---
Mẫu LaTeX Springer Nature 2021
Dân chủ hóa Dịch máy Thần kinh
với OPUS-MT
Jörg Tiedemann1*, Mikko Aulamo1†, Daria
Bakshandaeva1†, Michele Boggia1†, Stig-Arne
Grönroos1,2†, Tommi Nieminen1†, Alessandro
Raganato3†, Yves Scherrer1†, Raúl Vázquez1† và Sami
Virpioja1†
1Khoa Nhân văn Số, Đại học Helsinki,
Unioninkatu 40, Helsinki, 00014, Phần Lan.
2Silo.AI, Fredrikinkatu 57 C, Helsinki, 00100, Phần Lan.
3Khoa Tin học, Hệ thống và Truyền thông,
Đại học Milano-Bicocca, Viale Sarca 336, Milano, 20126,
Ý.
*Tác giả liên hệ. E-mail: jorg.tiedemann@helsinki.fi;
Tác giả đóng góp: mikko.aulamo@helsinki.fi;
daria.bakshandaeva@helsinki.fi; michele.boggia@helsinki.fi;
stig-arne.gronroos@helsinki.fi; tommi.nieminen@helsinki.fi;
alessandro.raganato@unimib.it; yves.scherrer@helsinki.fi;
raul.vazquez@gmail.com; sami.virpioja@helsinki.fi;
†Các tác giả được liệt kê theo thứ tự bảng chữ cái.
Tóm tắt
Bài báo này trình bày hệ sinh thái OPUS với trọng tâm vào việc phát triển các mô hình và công cụ dịch máy mở, và tích hợp chúng vào các ứng dụng người dùng cuối, nền tảng phát triển và quy trình làm việc chuyên nghiệp. Chúng tôi thảo luận về sứ mệnh đang diễn ra của chúng tôi trong việc tăng cường phạm vi ngôn ngữ và chất lượng dịch thuật, đồng thời mô tả công việc đang thực hiện về phát triển các mô hình dịch thuật mô-đun và các giải pháp nhỏ gọn được tối ưu hóa tốc độ cho dịch thuật thời gian thực trên máy tính để bàn thông thường và các thiết bị nhỏ.
Từ khóa: dịch máy thần kinh, kho ngữ liệu song song, dịch thuật hỗ trợ máy tính, mã nguồn mở
1arXiv:2212.01936v3 [cs.CL] 4 Jul 2023

--- TRANG 2 ---
Mẫu LaTeX Springer Nature 2021
2 Dân chủ hóa Dịch máy Thần kinh với OPUS-MT
1 Giới thiệu
Công nghệ ngôn ngữ mang trách nhiệm ngày càng lớn trong một xã hội ngày càng bị chi phối bởi các kênh truyền thông số. Dịch máy (MT) đóng vai trò quyết định trong việc tiếp cận thông tin xuyên ngôn ngữ và sẽ tiếp tục phát triển như một thành phần quan trọng trong hộp công cụ xử lý ngôn ngữ tự nhiên (NLP) của chúng ta, tạo điều kiện cho sự bao gồm và công bằng giữa những người có nền tảng văn hóa và ngôn ngữ khác nhau. Tất cả các công ty CNTT lớn đều nhận ra tầm quan trọng của MT và đẩy mạnh nỗ lực phát triển các giải pháp dịch thuật nội bộ với những khẩu hiệu như "không ngôn ngữ nào bị bỏ lại phía sau"1 và các sáng kiến tương tự.

Tuy nhiên, việc để MT trong tay khai thác thương mại đi kèm với những rủi ro nghiêm trọng liên quan đến quyền riêng tư dữ liệu, tính minh bạch và tính bao gồm. Sứ mệnh của OPUS [1] và OPUS-MT [2] là thúc đẩy các giải pháp mở và minh bạch được hỗ trợ bởi cộng đồng nghiên cứu mà không có mục tiêu hướng lợi nhuận. Điểm khởi đầu là OPUS, một bộ sưu tập ngày càng phát triển các tập dữ liệu song song công cộng cung cấp nhiên liệu thiết yếu cho MT dựa trên dữ liệu mở. Dữ liệu huấn luyện với phạm vi ngôn ngữ tốt là rất quan trọng cho MT chất lượng cao. OPUS-MT dựa trên bộ sưu tập đó và cung cấp các công cụ dịch thuật công cộng và giải pháp MT. Đuôi dài của các ngôn ngữ có tài nguyên NLP hạn chế tạo ra một trong những thách thức lớn nhất của công nghệ ngôn ngữ hiện đại, và do đó chúng tôi nhắm đến việc cải thiện phạm vi ngôn ngữ trong OPUS và OPUS-MT. Bài báo này mô tả cơ sở hạ tầng mà chúng tôi đang xây dựng để hỗ trợ sứ mệnh của mình (xem Hình 1 để có cái nhìn tổng quan về các thành phần khác nhau và kết nối của chúng).

Những năm gần đây đã chứng kiến một cuộc cách mạng trong xử lý ngôn ngữ tự nhiên do những tiến bộ trong học sâu và các cơ sở tính toán hỗ trợ huấn luyện các kiến trúc mạng thần kinh phức tạp. Thành công này chỉ có thể thực hiện được nhờ sự sẵn có của các framework mã nguồn mở và các tập dữ liệu công cộng ngày càng phát triển. Một nền tảng khác trong NLP hiện đại là việc phân phối các mô hình đã được pre-train có thể được tái sử dụng và điều chỉnh cho các nhiệm vụ mới. Học chuyển giao đã được chứng minh là rất hiệu quả cho nhiều tác vụ downstream vì nó tránh được các quy trình huấn luyện tốn kém và rút ra những lợi ích đáng kể từ pre-training không giám sát trên văn bản thô. Thật bất ngờ, ít được thực hiện cho đến gần đây đối với các mô hình dịch thuật công cộng và hầu hết các nhóm vẫn phát triển các engine dịch thuật từ đầu, ngay cả những cái cơ bản nhất. Tuy nhiên, việc tiêu thụ năng lượng ngày càng tăng và nhận thức về tác động môi trường của học sâu đòi hỏi việc sử dụng tài nguyên tốt hơn và bền vững hơn. Chúng tôi đề xuất OPUS-MT như một trung tâm chính cho các mô hình dịch thuật đã được pre-train cùng với các sáng kiến khác phân phối các mô hình NLP có thể triển khai.

Các kiến trúc cạnh tranh nhất cho các mô hình ngôn ngữ và dịch thuật thần kinh cũng có nhược điểm là kích thước ngày càng tăng. Việc tạo ra và thậm chí triển khai những mô hình như vậy trở thành trở ngại và chỉ có thể được thực hiện bởi các đơn vị được trang bị tốt với xương sống Tính toán Hiệu năng Cao (HPC) đầy đủ. Do đó, chúng có xu hướng nằm trong tay các tập đoàn lớn cung cấp MT dưới dạng dịch vụ. Ngay cả khi việc tạo ra các mô hình chất lượng cao đủ hiệu quả để chạy cục bộ trên thiết bị của người dùng cuối là có thể, các tập đoàn hiếm khi có bất kỳ động cơ nào để công bố những mô hình như vậy với giấy phép cho phép điều này.

Xem xét tầm quan trọng của hỗ trợ dịch thuật, việc MT nằm trong tay của một số ít tập đoàn công nghệ cao là không thuận lợi. Việc cung cấp các mô hình dịch thuật công cộng cạnh tranh với giấy phép khoan dung do đó là rất cần thiết để tránh độc quyền và mang MT đến các thiết bị của người dùng cuối, nhà nghiên cứu và nhà phát triển ứng dụng mà không có bất kỳ ràng buộc nào và khai thác thương mại (ngầm ẩn) của người dùng. Nhiều người dùng hàng ngày có thể không nhận thức được những nguy hiểm của rò rỉ dữ liệu và khai thác thông tin cá nhân khi sử dụng cái gọi là dịch vụ trực tuyến miễn phí nuôi dưỡng các sản phẩm thương mại và quảng cáo có mục tiêu. Theo tinh thần của dữ liệu mở và mã nguồn mở trong NLP, OPUS-MT cố gắng dân chủ hóa dịch máy loại bỏ sự phụ thuộc vào các dịch vụ và công cụ tối đa hóa lợi nhuận. Trong phần tiếp theo, chúng tôi mô tả hệ sinh thái OPUS và cách nó hỗ trợ mục tiêu này.

Trong Phần 2, chúng tôi tập trung vào dữ liệu phác thảo các nguyên tắc của OPUS và các công cụ kết nối với bộ sưu tập của chúng tôi, bao gồm OPUS-API, OpusTools và các bộ công cụ OpusFilter. Phần này cũng trình bày thách thức dịch thuật Tatoeba. Trong Phần 3, chúng tôi cung cấp chi tiết về framework OPUS-MT, các pipeline huấn luyện và tích hợp các mô hình MT vào nhiều nền tảng khác nhau như Hugging Face, European Language Grid và các ứng dụng người dùng cuối khác, cũng như tích hợp quy trình làm việc chuyên nghiệp OPUS-CAT. Sau đó, chúng tôi thảo luận về các benchmark và đánh giá như một thành phần quan trọng trong phát triển MT trong Phần 4. Cuối cùng, chúng tôi thảo luận về những nỗ lực hiện tại của chúng tôi trong việc mở rộng phạm vi ngôn ngữ và tối ưu hóa các mô hình dịch thuật về mặt tốc độ và khả năng ứng dụng trong Phần 5 trước khi tóm tắt công việc liên quan trong Phần 6 và kết luận bài báo với một số nhận xét cuối cùng.

--- TRANG 3 ---
Mẫu LaTeX Springer Nature 2021
Dân chủ hóa Dịch máy Thần kinh với OPUS-MT 3
Hình 1 OPUS-MT và các kết nối của nó với các thành phần, nền tảng và ứng dụng khác.
MT như một dịch vụ. Ngay cả khi việc tạo ra các mô hình chất lượng cao đủ hiệu quả để chạy cục bộ trên thiết bị của người dùng cuối là có thể, các tập đoàn hiếm khi có bất kỳ động cơ nào để công bố những mô hình như vậy với giấy phép cho phép điều này.

Xem xét tầm quan trọng của hỗ trợ dịch thuật, việc MT nằm trong tay của một số ít tập đoàn công nghệ cao là không thuận lợi. Việc cung cấp các mô hình dịch thuật công cộng cạnh tranh với giấy phép khoan dung do đó là rất cần thiết để tránh độc quyền và mang MT đến các thiết bị của người dùng cuối, nhà nghiên cứu và nhà phát triển ứng dụng mà không có bất kỳ ràng buộc nào và khai thác thương mại (ngầm ẩn) của người dùng. Nhiều người dùng hàng ngày có thể không nhận thức được những nguy hiểm của rò rỉ dữ liệu và khai thác thông tin cá nhân khi sử dụng cái gọi là dịch vụ trực tuyến miễn phí nuôi dưỡng các sản phẩm thương mại và quảng cáo có mục tiêu. Theo tinh thần của dữ liệu mở và mã nguồn mở trong NLP, OPUS-MT cố gắng dân chủ hóa dịch máy loại bỏ sự phụ thuộc vào các dịch vụ và công cụ tối đa hóa lợi nhuận. Trong phần tiếp theo, chúng tôi mô tả hệ sinh thái OPUS và cách nó hỗ trợ mục tiêu này.

Trong Phần 2, chúng tôi tập trung vào dữ liệu phác thảo các nguyên tắc của OPUS và các công cụ kết nối với bộ sưu tập của chúng tôi, bao gồm OPUS-API, OpusTools và các bộ công cụ OpusFilter. Phần này cũng trình bày thách thức dịch thuật Tatoeba. Trong Phần 3, chúng tôi cung cấp chi tiết về framework OPUS-MT, các pipeline huấn luyện và tích hợp các mô hình MT vào nhiều nền tảng khác nhau như Hugging Face, European Language Grid và các ứng dụng người dùng cuối khác, cũng như tích hợp quy trình làm việc chuyên nghiệp OPUS-CAT. Sau đó, chúng tôi thảo luận về các benchmark và đánh giá như một thành phần quan trọng trong phát triển MT trong Phần 4. Cuối cùng, chúng tôi thảo luận về những nỗ lực hiện tại của chúng tôi trong việc mở rộng phạm vi ngôn ngữ và tối ưu hóa các mô hình dịch thuật về mặt tốc độ và khả năng ứng dụng trong Phần 5 trước khi tóm tắt công việc liên quan trong Phần 6 và kết luận bài báo với một số nhận xét cuối cùng.

--- TRANG 4 ---
Mẫu LaTeX Springer Nature 2021
4 Dân chủ hóa Dịch máy Thần kinh với OPUS-MT
Dữ liệu kho ngữ liệu cơ bản với ranh giới câu (được viết tắt cho ngắn gọn):
<?xml version="1.0" encoding="utf-8"?>
<document>
<CHAPTER ID="0">
<P id="1"></P>
<SPEAKER ID="1" LANGUAGE="DE" NAME="Rübig">
<P id="2">
<s id="1">Madam President, I saw a few boats landing at Parliament this ...</s>
<s id="2">Not only were there language difficulties; the telephone line ...</s>
<s id="3">I would be most obliged if the number on which the security ...</s>
</P>
<P id="3"></P>
</SPEAKER>
Chú thích standoff cho căn chỉnh câu (với điểm số):
<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE cesAlign PUBLIC "-//CES//DTD XML cesAlign//EN" "">
<cesAlign version="1.0">
<linkGrp targType="s" toDoc="fr/2005/CES_AC71_2005_5SUMMARY.xml.gz"
fromDoc="en/2005/CES_AC71_2005_5SUMMARY.xml.gz">
<link certainty="0" xtargets=";1 2" id="SL1" />
<link certainty="0.612088" xtargets="1;3" id="SL2" />
<link certainty="0.173077" xtargets="2;4" id="SL3" />
...
Hình 2 Một ví dụ về dữ liệu OPUS được mã hóa XML (kho ngữ liệu và căn chỉnh câu). ID câu được sử dụng để liên kết các câu giữa hai tài liệu. Nhiều câu có thể xuất hiện trong một liên kết trong đó ID câu được phân tách bằng dấu cách. ID ngôn ngữ nguồn và đích được phân tách bằng dấu chấm phẩy và các liên kết trống cũng có thể xuất hiện (như liên kết đầu tiên trong ví dụ trên nơi không có câu ngôn ngữ nguồn nào được căn chỉnh với câu 1 và 2 trong ngôn ngữ đích).

2 Kho Ngữ liệu Song song Mở OPUS
OPUS2 đã là một trung tâm chính cho các kho ngữ liệu song song trong khoảng 18 năm [1, 3, 4]. Nó phục vụ các văn bản song song được căn chỉnh (tức là văn bản song song được căn chỉnh song ngữ) cho một số lượng lớn các ngôn ngữ và cặp ngôn ngữ, cung cấp các tập dữ liệu công cộng sẵn có cho dịch máy từ nhiều lĩnh vực và nguồn khác nhau. Hiện tại, các tập dữ liệu được phát hành bao gồm hơn 600 ngôn ngữ và các biến thể ngôn ngữ khu vực bổ sung được biên dịch thành các văn bản song song được căn chỉnh câu cho hơn 40.000 cặp ngôn ngữ. Tổng cộng có khoảng 20 tỷ câu và đoạn câu tương ứng với 290 tỷ token trong toàn bộ bộ sưu tập. Các tập dữ liệu được phát hành có dung lượng khoảng 12 TB file nén. Lưu ý rằng mỗi câu có thể được căn chỉnh với nhiều ngôn ngữ khác tùy thuộc vào phạm vi ngôn ngữ trong các kho ngữ liệu con riêng lẻ. Phân phối trên các ngôn ngữ và cặp ngôn ngữ tự nhiên bị lệch và tuân theo đường cong Zipfian [5] với một đuôi dài các cặp ngôn ngữ có ít dữ liệu, trong khi chỉ một vài ngôn ngữ bao gồm phần chính của tập dữ liệu. Tuy nhiên, có hơn 300 cặp ngôn ngữ chứa một triệu cặp câu trở lên, cung cấp cơ sở tốt cho dịch máy chất lượng cao. Lưu ý rằng bộ sưu tập sẽ bị lệch về một số lĩnh vực nhất định và việc sử dụng các mô hình kết quả sẽ bị ảnh hưởng bởi phạm vi lĩnh vực cho từng cặp ngôn ngữ riêng lẻ.

2https://opus.nlpl.eu

--- TRANG 5 ---
Mẫu LaTeX Springer Nature 2021
Dân chủ hóa Dịch máy Thần kinh với OPUS-MT 5
Định dạng gốc cho OPUS là một định dạng XML đơn giản độc lập cho phép bao gồm các đánh dấu bổ sung tùy thuộc vào nguồn gốc. Các câu được đánh dấu bằng các thẻ ranh giới câu thích hợp và các căn chỉnh được lưu trữ dưới dạng chú thích standoff trong định dạng XCES Align. Hình 2 cho thấy một ví dụ về chú thích. Việc căn chỉnh các tệp văn bản dựa trên ID câu có lợi thế là có thể mở rộng đến các kho ngữ liệu đa ngôn ngữ lớn như bộ dữ liệu bản địa hóa phần mềm hoặc bản dịch Kinh thánh. Bất kỳ tài liệu nào cũng có thể được căn chỉnh với nhiều bản dịch hoặc chuyển thể mà không cần lặp lại nội dung thiết yếu. Nguyên tắc chung trong OPUS là căn chỉnh tất cả các cặp ngôn ngữ có sẵn để bao gồm mọi cặp ngôn ngữ có thể có thể được trích xuất từ dữ liệu song song. Ngay cả các căn chỉnh thay thế cũng có thể được cung cấp mà không cần sửa đổi các tệp kho ngữ liệu gốc và không có tác động gì đến các căn chỉnh khác. Căn chỉnh standoff cũng có thể dễ dàng được bổ sung với thông tin meta như xác suất căn chỉnh hoặc thông tin loại liên kết. Những tính năng bổ sung này có thể được sử dụng để lọc các tập dữ liệu theo một số điều kiện nhất định (xem Phần 2.2).

Để thuận tiện, OPUS cũng cung cấp các định dạng dữ liệu phổ biến hỗ trợ tích hợp liền mạch vào các pipeline dịch máy và ứng dụng downstream. Những tệp này được tự động tạo ra từ định dạng XML gốc và được phát hành từ các cơ sở lưu trữ OPUS. Đặc biệt, chúng tôi cung cấp các kho ngữ liệu tệp văn bản thuần túy với các câu được căn chỉnh trên các dòng tương ứng (được gọi là văn bản song song kiểu Moses do ứng dụng của chúng trong bộ công cụ Moses [6]), và các tệp trao đổi bộ nhớ dịch thuật (TMX) có thể được tải từ phần mềm chủ yếu được sử dụng bởi các dịch giả chuyên nghiệp. Lưu ý rằng những tệp phái sinh này thường mất thông tin như đánh dấu bổ sung, ranh giới tài liệu cũng như thông tin loại liên kết và điểm căn chỉnh. Các tệp TMX cũng được khử trùng (ở mức đơn vị dịch thuật, tức là các cặp câu được căn chỉnh) và các liên kết trống được loại bỏ khỏi cả định dạng tệp Moses và TMX. Số lượng liên kết tiết lộ những khác biệt này, có thể dẫn đến sự khác biệt đáng kể cho một số kho ngữ liệu con trong bộ sưu tập.

Đối với hầu hết các kho ngữ liệu trong OPUS, chúng tôi cũng cung cấp các tệp dữ liệu bổ sung như số lượng tần suất token, tệp căn chỉnh từ, từ điển song ngữ được trích xuất và bảng cụm từ được lọc từ dịch máy thống kê. Chúng tôi cũng cung cấp các tập dữ liệu đơn ngữ, một số trong đó bao gồm dữ liệu vượt xa các văn bản được căn chỉnh. Tất cả những tệp được phát hành này được cung cấp trong định dạng tệp và giao diện nhất quán để thuận tiện cho việc tích hợp các tập con khác nhau trong các thí nghiệm có hệ thống và ứng dụng downstream. Tuy nhiên, lưu ý rằng tùy thuộc vào thông tin có sẵn từ các nguồn gốc, có những khác biệt nhỏ trong cấu trúc, đánh dấu và ID ngôn ngữ được sử dụng trong các bộ sưu tập dữ liệu khác nhau. Mặc dù vậy, chúng tôi cố gắng tuân theo các tiêu chuẩn chung với chủ yếu là mã ngôn ngữ ISO-639-1 với dự phòng đến ba chữ cái ISO-639-2 và các phần mở rộng chỉ định các biến thể khu vực khi cần thiết.

Một số mâu thuẫn nhất định (ví dụ trong nhãn ngôn ngữ) và các vấn đề khác là không thể tránh khỏi vì tất cả các tập dữ liệu chứa các mức độ nhiễu khác nhau do chuyển đổi tệp, phát hiện ranh giới câu và căn chỉnh câu tự động,

--- TRANG 6 ---
Mẫu LaTeX Springer Nature 2021
6 Dân chủ hóa Dịch máy Thần kinh với OPUS-MT
{
"corpora": [
{
"alignment_pairs": 29903792,
"corpus": "OpenSubtitles",
"documents": 38969,
"id": 328013,
"latest": "True",
"preprocessing": "xml",
"size": 297683,
"source": "en",
"source_tokens": 257890401,
"target": "fi",
"target_tokens": 161280297,
"url": "https://object.pouta.csc.fi/OPUS-OpenSubtitles/v2018/xml/en-fi.xml.gz",
"version": "v2018"
},
...
]
}
Hình 3 Một ví dụ về đầu ra JSON của OPUS-API hiển thị mục đầu tiên khi truy vấn phiên bản mới nhất của kho ngữ liệu OpenSubtitles Anh–Phần Lan trong định dạng XML.

nhưng hầu hết nó xuất phát từ các nguồn gốc. Với mỗi lần nhập, chúng tôi thực hiện các quy trình lọc và làm sạch, và chúng tôi liên tục nhắm đến việc tăng mức chất lượng của dữ liệu. Các bản phát hành mới sẽ cung cấp kết quả của những nỗ lực này cũng như phần mềm lọc có thể được điều chỉnh cho các nhu cầu cá nhân (xem thêm Phần 2.3).

Cũng lưu ý rằng OPUS cho đến nay tập trung vào việc căn chỉnh ở mức câu theo truyền thống của dịch máy ở mức câu. Chắc chắn, xu hướng hướng tới việc tăng cường ngữ cảnh trong bất kỳ ứng dụng NLP nào, bao gồm cả MT, do khả năng cải tiến của các kiến trúc hiện đại để xử lý đầu vào lớn hơn và khả năng tạo ra đầu ra gắn kết với các phụ thuộc xa qua ranh giới câu. Việc di chuyển toàn bộ bộ sưu tập đến các đơn vị mức đoạn văn và tài liệu là không thể vì nhiều tập dữ liệu được tạo ra từ các câu riêng lẻ và các tương ứng dịch thuật của chúng ngoài mọi ngữ cảnh. Tuy nhiên, một số tài nguyên đã bao gồm thông tin cấu trúc và căn chỉnh mức tài liệu và chúng tôi dự định làm cho thông tin như vậy dễ tiếp cận hơn để cho phép mô hình hóa dịch thuật trên các phân đoạn lớn hơn. Tuy nhiên, cho đến nay, những nỗ lực của chúng tôi về dịch máy chỉ dựa trên các mô hình mức câu như chúng tôi sẽ mô tả chi tiết hơn bên dưới.

2.1 Tìm Tập Dữ liệu sử dụng OPUS-API
OPUS-API3 là một API trực tuyến để tìm kiếm các tập dữ liệu trong OPUS. Các tập dữ liệu có thể được lọc theo tên kho ngữ liệu, ngôn ngữ nguồn và đích có sẵn, loại tiền xử lý và phiên bản được phát hành của kho ngữ liệu. API phản hồi với một đầu ra trong định dạng JSON. Phản hồi chứa thông tin và thống kê đơn giản về các kho ngữ liệu, chẳng hạn như liên kết tải xuống đến các tệp kho ngữ liệu cần thiết, kích thước của các tệp dữ liệu tính bằng byte, số lượng cặp câu và token cùng những thứ khác. Hình 3 cho thấy một ví dụ về đầu ra.

3https://opus.nlpl.eu/opusapi/

--- TRANG 7 ---
Mẫu LaTeX Springer Nature 2021
Dân chủ hóa Dịch máy Thần kinh với OPUS-MT 7
Ngoài ra, OPUS-API cung cấp chức năng liệt kê tất cả các kho ngữ liệu và ngôn ngữ có sẵn trong OPUS, cũng như các truy vấn cụ thể hơn. Ví dụ, người ta có thể tra cứu tất cả các ngôn ngữ có sẵn cho một kho ngữ liệu nhất định, hoặc tất cả các ngôn ngữ đích cho một ngôn ngữ nguồn trong toàn bộ OPUS hoặc trong một kho ngữ liệu nhất định. Những lệnh này hữu ích để tìm các tập dữ liệu cho các cặp ngôn ngữ cụ thể.

2.2 Tìm nạp và Xử lý Dữ liệu Song song với OpusTools
Gói OpusTools4 [7] cho phép truy cập dễ dàng vào các kho ngữ liệu và tệp dữ liệu trong OPUS. Nó cung cấp giao diện Python cho OPUS-API, các phương thức để tải xuống và định dạng các kho ngữ liệu được xác định, và một số chức năng bổ sung cho phát hiện ngôn ngữ và phân chia kho ngữ liệu.

Script chính trong OpusTools là opus_read có chức năng chính là đọc các tệp từ OPUS và xuất ra các cặp câu trong nhiều định dạng được hỗ trợ. Với ngôn ngữ nguồn và đích và tên kho ngữ liệu, opus_read tải xuống các tệp cần thiết thông qua thông tin từ OPUS-API. Nó phân tích các tệp căn chỉnh định dạng XCES và đọc các câu tương ứng từ các tệp XML nén để tạo ra đầu ra được yêu cầu trong các định dạng mong muốn, bao gồm văn bản song song kiểu Moses và TMX. Script opus_read cũng cung cấp chức năng chạy lọc dữ liệu cơ bản. Ví dụ, người ta có thể chỉ muốn bao gồm căn chỉnh câu một-một trong đầu ra. Ngoài ra, có thể lọc các cặp câu dựa trên các thuộc tính XML như điểm tin cậy căn chỉnh câu (tùy thuộc vào sự sẵn có của các thẻ trong kho ngữ liệu được chọn).

Hơn nữa, OpusTools chứa script opus_langid, có thể được sử dụng để nhận dạng ngôn ngữ của các tệp OPUS sử dụng pycld25 và langid.py.6[8] Script chèn các thẻ thuộc tính nhận dạng ngôn ngữ trong các tệp XML để có thể sử dụng thông tin nhận dạng ngôn ngữ cho việc lọc dữ liệu. Trong tương lai, chúng tôi dự định hệ thống thêm metadata như thẻ ngôn ngữ được phát hiện tự động vào tất cả các tập dữ liệu trong OPUS. OpusTools sẽ hữu ích cho nhiệm vụ này cũng cho các tập dữ liệu sắp tới. Trong khi OpusTools chỉ hỗ trợ các phương thức lọc và chuyển đổi dữ liệu cơ bản, hộp công cụ OpusFilter được mô tả bên dưới cung cấp một loạt các tùy chọn rộng hơn nhiều để xử lý các kho ngữ liệu.

2.3 Làm sạch và Chuẩn bị Tập Dữ liệu với OpusFilter
OpusFilter7 [9] là một hộp công cụ để lọc và kết hợp các kho ngữ liệu song song. Hộp công cụ hỗ trợ ba loại hoạt động chính: các tác vụ chuẩn bị kho ngữ liệu, các bước tiền xử lý thiết yếu và cuối cùng, nhiều loại bộ lọc khác nhau nhằm loại bỏ nhiễu và nội dung không mong muốn. Trái ngược với các công cụ thực hiện một phương pháp lọc duy nhất (ví dụ [10, 11]), OpusFilter cho phép áp dụng các phương pháp khác nhau, bao gồm các bộ lọc tùy chỉnh được người dùng định nghĩa. Hơn nữa, nó có thể được sử dụng cho các tác vụ thao tác kho ngữ liệu khác cần thiết khi xây dựng các mô hình MT, ví dụ như kết hợp các kho ngữ liệu, chia chúng thành các tập huấn luyện và kiểm tra, và áp dụng tokenization.

4https://github.com/Helsinki-NLP/OpusTools
5https://github.com/aboSamoor/pycld2
6https://github.com/saffsd/langid.py
7https://github.com/Helsinki-NLP/OpusFilter

--- TRANG 8 ---
Mẫu LaTeX Springer Nature 2021
8 Dân chủ hóa Dịch máy Thần kinh với OPUS-MT
OpusFilter có thể kết nối với bộ sưu tập kho ngữ liệu OPUS thông qua thư viện OpusTools, nhưng cũng có thể hoạt động trên các tệp văn bản địa phương để xử lý bất kỳ kho ngữ liệu đơn ngữ, song ngữ, hoặc đa song song nào. Một tệp cấu hình YAML8 định nghĩa pipeline để chuyển đổi các tệp kho ngữ liệu thô thành các tệp tập huấn luyện và kiểm tra sạch. Cùng một pipeline có thể được tổng quát hóa cho nhiều cặp ngôn ngữ. Thiết kế tệp cấu hình duy nhất, dễ chia sẻ là trung tâm trong những nỗ lực của chúng tôi để cung cấp các giải pháp minh bạch và giảm bớt các vấn đề tái tạo của các thí nghiệm ảnh hưởng đến nghiên cứu MT hiện tại [12].

2.3.1 Chuẩn bị dữ liệu cấp kho ngữ liệu
Các bước đầu tiên trong chuẩn bị kho ngữ liệu song song thường liên quan đến việc thu thập, kết hợp và chia các kho ngữ liệu khác nhau. Giao diện với bộ sưu tập OPUS thông qua OpusTools cho phép tải xuống tự động các kho ngữ liệu hiện có. OpusFilter hỗ trợ nhiều hoạt động tệp văn bản phổ biến trên các tệp song song: nối (concatenation), head (N dòng đầu tiên), tail (N dòng cuối cùng), và slice (các dòng từ N đến M). Có một lệnh để lấy một tập con ngẫu nhiên với kích thước cụ thể từ một kho ngữ liệu và chia dữ liệu thành hai tập con với tỷ lệ nhất định. Một lệnh khác cho phép kết hợp nhiều bản dịch cho cùng một phân đoạn trong các tệp riêng biệt thành một tập song song duy nhất chứa tất cả các kết hợp có sẵn hoặc một tập con được lấy mẫu của chúng.9 Khi các tệp kho ngữ liệu đã được tạo, người ta có thể tiến hành với tiền xử lý văn bản thiết yếu được mô tả bên dưới.

2.3.2 Tiền xử lý cấp phân đoạn
Bước tiền xử lý có thể được sử dụng để áp dụng một số bộ tiền xử lý cấp phân đoạn cho các kho ngữ liệu đơn ngữ hoặc song song. Các bộ tiền xử lý được thực hiện bao gồm chuẩn hóa khoảng trắng, thay thế biểu thức chính quy tùy chỉnh, phân tách câu đơn ngữ,10 tokenization,11 phân đoạn từ tiếng Trung,12 phân đoạn từ tiếng Nhật,13 và phân đoạn subword với BPE14 [13] hoặc Morfessor15 [14]. Các bộ tiền xử lý tùy chỉnh có thể được thêm vào bằng cách thực hiện một lớp Python đơn giản cho chúng.

2.3.3 Lọc
OpusFilter bao gồm hai loại bộ lọc. Trong phạm vi của một kho ngữ liệu, lọc trùng lặp cung cấp các cách để loại bỏ các phân đoạn giống hệt nhau (tùy chọn bỏ qua việc phân biệt chữ hoa chữ thường và các ký tự không phải chữ cái), trong tất cả hoặc chỉ một số ngôn ngữ, trong một kho ngữ liệu. Cũng có thể loại bỏ những phân đoạn từ một kho ngữ liệu trùng lặp với kho ngữ liệu khác (ví dụ các phân đoạn dữ liệu huấn luyện trùng lặp với dữ liệu kiểm tra).

Phần còn lại của các bộ lọc hoạt động từng phân đoạn một, chấp nhận hoặc loại bỏ từng cái một cách độc lập với những cái khác. Các bộ lọc hiện được thực hiện bởi OpusFilter bao gồm các bộ lọc dựa trên độ dài khác nhau, bộ lọc nhận dạng ngôn ngữ (dựa trên langid.py16[8], pycld217, và fasttext18[15, 16]), bộ lọc script, ký tự đặc biệt, và độ tương tự, bộ lọc sử dụng mô hình ngôn ngữ varigram19[17], bộ lọc sử dụng mô hình căn chỉnh từ20[18], và bộ lọc embedding câu ước tính độ tương tự câu dựa trên embedding LASER đa ngôn ngữ21[19]. Các bộ lọc từng phân đoạn có thể được sử dụng trong OpusFilter chỉ định hai phương thức: phương thức score xác định đầu ra số hoặc boolean cho các phân đoạn, và phương thức accept đưa ra quyết định có chấp nhận hay từ chối các phân đoạn với điểm số nhất định. Điểm số có thể chỉ là một giá trị hoặc một vector của nhiều giá trị. Ví dụ, LengthFilter trả về số lượng ký tự hoặc từ trong phân đoạn: một cho kho ngữ liệu đơn ngữ, hai cho kho ngữ liệu song ngữ, v.v. Các tham số độ dài tối thiểu và tối đa xác định liệu phân đoạn có được chấp nhận hay không.

Thay vì áp dụng trực tiếp các quyết định lọc, OpusFilter có thể xuất ra các điểm từ các bộ lọc. Chúng có thể được sử dụng để kiểm tra dữ liệu và xác định ngưỡng hợp lý cho việc lọc. Để làm điều này, OpusFilter bao gồm các công cụ để phân tích và trực quan hóa các điểm. Ngoài việc lọc trực tiếp, các điểm lọc cũng có thể được sử dụng để huấn luyện một bộ phân loại để đưa ra quyết định lọc dựa trên sự kết hợp các điểm [20].

2.4 Thách thức Dịch thuật Tatoeba
Gần đây, chúng tôi đã tạo ra một bộ biên dịch đặc biệt của dữ liệu được phát hành dưới nhãn Thách thức Dịch thuật Tatoeba,22 (TTC tóm tắt) [21] để khắc phục một số phức tạp có mặt trong các mô hình được huấn luyện trên dữ liệu OPUS. OPUS là một bộ sưu tập dữ liệu động với các bản phát hành tập dữ liệu mới thỉnh thoảng, do đó có rất nhiều cách để biên dịch các tập dữ liệu từ bộ sưu tập và phạm vi bao gồm có thể luôn thay đổi. Hơn nữa, tiền xử lý và làm sạch dữ liệu ảnh hưởng lớn đến chất lượng của MT, và các bản sao thường xuyên trên tất cả các tập con cùng với tiếng ồn đáng kể có thể có ảnh hưởng tiêu cực đến các quy trình học tập.

TTC được đặt tên theo dữ liệu kiểm tra và phát triển được chọn, mà chúng tôi lấy từ kho ngữ liệu Tatoeba, một tập dữ liệu các bản dịch do người dùng đóng góp bằng hàng trăm ngôn ngữ. Bản phát hành mới nhất của TTC bao gồm 29 tỷ

8https://yaml.org/
9Ví dụ, ba bản dịch tiếng Tây Ban Nha và ba bản dịch tiếng Pháp cho cùng một tài liệu tiếng Anh có thể được kết hợp để có chín cặp tiếng Tây Ban Nha–Pháp cho mỗi phân đoạn trong tài liệu.
10https://github.com/mediacloud/sentence-splitter
11https://github.com/mingruimingrui/fast-mosestokenizer
12https://github.com/fxsjy/jieba
13https://github.com/SamuraiT/mecab-python3
14https://github.com/rsennrich/subword-nmt
15https://github.com/aalto-speech/morfessor
16https://github.com/saffsd/langid.py
17https://github.com/aboSamoor/pycld2
18https://fasttext.cc/
19https://github.com/vsiivola/variKN
20https://github.com/robertostling/eflomal
21https://github.com/yannvgn/laserembeddings
22https://github.com/Helsinki-NLP/Tatoeba-Challenge

--- TRANG 9 ---
Mẫu LaTeX Springer Nature 2021
Dân chủ hóa Dịch máy Thần kinh với OPUS-MT 9
đơn vị dịch thuật23 trong 3.708 văn bản song song bao gồm 557 ngôn ngữ. Chúng tôi biên dịch dữ liệu huấn luyện từ các kho ngữ liệu OPUS và tập trung vào việc tạo ra một tập dữ liệu với các nhãn ngôn ngữ nhất quán có thể dễ dàng được sử dụng cho các thí nghiệm dịch máy có hệ thống. Tất cả các văn bản song song được khử trùng và lọc. Chúng tôi cung cấp các tập huấn luyện được xáo trộn ngẫu nhiên và dữ liệu phát triển và kiểm tra chuyên dụng để hỗ trợ một thiết lập thí nghiệm nhất quán.

Chúng tôi chia tập dữ liệu thành nhiều thách thức con tùy thuộc vào tính sẵn có của dữ liệu huấn luyện. Chi tiết về thiết lập có sẵn trong [21]. Trạng thái hiện tại của phát triển dịch máy của chúng tôi đối với TTC được giám sát bằng bảng điều khiển của chúng tôi (xem Phần 4.1). Các trực quan hóa địa lý (xem Hình 4) cũng giúp thấy các khoảng trống trong phạm vi ngôn ngữ mà chúng tôi cố gắng lấp đầy trong OPUS-MT. Chúng tôi cũng bổ sung đánh giá với kết quả từ các benchmark đã được thiết lập khác. Điều này là cần thiết vì dữ liệu do người dùng đóng góp như benchmark TTC có thể có nhiều vấn đề khác nhau và kiểm soát chất lượng có hệ thống vượt quá khả năng của chúng tôi. Hơn nữa, TTC đề cập đến một loại nội dung cụ thể chủ yếu nhắm mục tiêu vào người học ngôn ngữ và du khách với trọng tâm vào ngôn ngữ hàng ngày và các biểu hiện khá ngắn và thường xuyên.

Chúng tôi nhắm đến việc cập nhật thường xuyên tập dữ liệu TTC để nắm bắt sự hỗ trợ ngày càng tăng cho các cặp ngôn ngữ và lĩnh vực. Các bản phát hành benchmark sẽ được cập nhật thường xuyên hơn, tùy thuộc vào sự phát triển của cơ sở dữ liệu Tatoeba gốc. Chúng tôi khuyến khích người đọc đóng góp vào bộ sưu tập dịch thuật24 để hỗ trợ dự án của chúng tôi. Các bản phát hành dữ liệu huấn luyện sẽ được biên dịch khi cần thiết bất cứ khi nào các bộ sưu tập mới lớn vào bộ sưu tập OPUS.

--- TRANG 10 ---
Mẫu LaTeX Springer Nature 2021
10 Dân chủ hóa Dịch máy Thần kinh với OPUS-MT
Hình 4 Phạm vi ngôn ngữ của các mô hình dịch thuật được trực quan hóa trên bản đồ tương tác. Vị trí địa lý của các ngôn ngữ được lấy từ Glottolog và màu sắc các chấm cho biết chất lượng dịch thuật theo số liệu đánh giá tự động được đo trên tập kiểm tra Tatoeba trong trường hợp này trên thang điểm từ xanh lá cây (tốt nhất) đến đỏ (tệ nhất). Các vòng tròn nhỏ hơn đề cập đến các tập kiểm tra nhỏ hơn, ít đáng tin cậy hơn.

3 Dịch Máy Mở với OPUS-MT
Với OPUS-MT, chúng tôi nỗ lực cung cấp các giải pháp dịch thuật công cộng tiên tiến và trở thành một trung tâm chính cho các mô hình dịch thuật đã được pre-train. OPUS-MT dựa trên Marian, một implementation hiệu quả của dịch máy thần kinh (NMT) bằng C++ thuần túy và với các phụ thuộc tối thiểu [22]. Marian là một framework sẵn sàng production và bao gồm các quy trình được tối ưu hóa cho phép một phương pháp có thể mở rộng để phát triển và khai thác các hệ thống MT hiện đại. Cụ thể hơn, OPUS-MT hướng tới hai mục tiêu chính:

1. Các pipeline và mô hình huấn luyện (Phần 3.1): Các script và quy trình có thể được sử dụng để huấn luyện các mô hình MT thần kinh một cách có hệ thống từ dữ liệu công cộng được thu thập trong OPUS. Các công thức bao gồm tất cả các thành phần cần thiết để tạo ra các mô hình dịch thuật cạnh tranh, bao gồm chuẩn bị dữ liệu, huấn luyện mô hình, dịch ngược và các loại data augmentation khác, cũng như fine-tuning và đánh giá. Sử dụng các pipeline, các mô hình được huấn luyện trên quy mô lớn và được phát hành với giấy phép khoan dung để được tái sử dụng và tích hợp vào nhiều nền tảng và quy trình làm việc khác nhau.

2. Các server MT và tích hợp (Phần 3.3 và 3.4): Các mô hình đã được pre-train cần được tích hợp vào nhiều nền tảng khác nhau để làm cho chúng có thể áp dụng rộng rãi cho người dùng cuối, chuyên gia dịch thuật, nhà phát triển hệ thống và nhà nghiên cứu MT nói chung. OPUS-MT cung cấp các ứng dụng server đơn giản có thể được sử dụng để triển khai các engine dịch thuật. Dự án cũng nhấn mạnh tích hợp vào các cơ sở hạ tầng bên ngoài như thư viện transformers Hugging Face và model hub (Phần 3.3.1) và European Language Grid (Phần 3.3.2). Các quy trình làm việc chuyên nghiệp được hỗ trợ thông qua các plugin và gói cài đặt được điều chỉnh cho người dùng cuối.

Các phần tiếp theo cung cấp cái nhìn tổng quan về implementation và chức năng của các pipeline huấn luyện, các quy trình phát hành và tài liệu của các mô hình dịch thuật đã được pre-train, implementation của các ứng dụng server, và tích hợp vào nhiều nền tảng và gói phần mềm khác nhau.

3.1 Các Pipeline Huấn luyện
Mục đích chính của các pipeline huấn luyện OPUS-MT là tích hợp chuẩn bị dữ liệu với các công thức linh hoạt để chạy các thí nghiệm và pre-training NMT quy mô lớn. Ý định của chúng tôi là tạo ra các quy trình có thể tái sử dụng mà chúng tôi có thể chạy nội bộ để tạo ra các mô hình mà chúng tôi muốn sử dụng và phát hành. Tuy nhiên, chúng tôi cũng chia sẻ những công thức đó vì chúng tôi muốn tạo ra một phương pháp minh bạch có thể được kiểm tra và nhân rộng.

23Thông thường, các đơn vị dịch thuật đề cập đến các cặp câu được căn chỉnh nhưng chúng cũng bao gồm các đơn vị của nhiều câu được căn chỉnh với các bản dịch tương ứng như thường xảy ra trong các tập dữ liệu song song khác nhau. Tatoeba cũng thường xuyên bao gồm các đơn vị với nhiều hơn một câu.
24https://tatoeba.org/en/users/register

--- TRANG 11 ---
Mẫu LaTeX Springer Nature 2021
Dân chủ hóa Dịch máy Thần kinh với OPUS-MT 11
Implementation của các pipeline huấn luyện dựa trên các công thức GNU Make25. Lệnh make và makefile là những công cụ đã được thiết lập tốt trong tự động hóa quy trình biên dịch và với điều đó chúng cung cấp một môi trường ổn định và được kiểm tra, điều rất có lợi cho mục đích của chúng tôi. Triết lý của việc định nghĩa các mục tiêu xây dựng có nhiều phụ thuộc khác nhau phù hợp rất tốt với bức tranh huấn luyện mô hình và các thí nghiệm NLP. Makefile định nghĩa các công thức và chuỗi phụ thuộc cần được tuân theo để tạo ra sản phẩm cuối cùng, trong trường hợp của chúng tôi là các mô hình NMT và gói phát hành.

Có một số lợi thế mà chúng tôi hưởng lợi khi sử dụng makefile:
• Các phụ thuộc được giải quyết tự động và quá trình xây dựng bị gián đoạn nếu các phụ thuộc thiết yếu không thể được giải quyết.
• Các tệp và kết quả trung gian có thể được tái sử dụng và không phải được xây dựng lại nếu không cần thiết. Timestamp tự động xác định liệu các mục tiêu có cần được xây dựng lại và cập nhật hay không, điều này có thể ảnh hưởng đến toàn bộ pipeline.
• Các mục tiêu có thể được xây dựng song song và lệnh make xác định các công thức nào có thể chạy đồng thời mà không phá vỡ các phụ thuộc được định nghĩa bởi các công thức nội bộ.
• Các tệp trung gian không cần thiết được xóa ở cuối quá trình.
• Các quy tắc pattern tĩnh có thể được sử dụng để tạo ra các công thức mẫu, có thể giúp định nghĩa các quy trình chung áp dụng cho nhiều tác vụ liên quan.
• Nhiều hàm có sẵn hỗ trợ thao tác biến, tên tệp và quy trình làm việc xây dựng.

OPUS-MT cố gắng tận dụng những lợi thế này và thực hiện các chuỗi công thức bao gồm tất cả các tác vụ con cần thiết để huấn luyện, kiểm tra và phát hành các mô hình NMT. Mục tiêu là cung cấp các lệnh make cấp cao khác nhau có thể chạy ở chế độ batch với các biến kiểm soát các thuộc tính và quy trình để cho phép khai thác có hệ thống các tập dữ liệu song song song song quy mô lớn. Nếu không có những công thức chung này, sẽ không thể huấn luyện một lượng lớn mô hình mà chúng tôi đã có thể phát hành (hơn 2.300 mô hình tại thời điểm viết, 744 mô hình đa ngôn ngữ trong số đó với phạm vi ngôn ngữ khác nhau ở phía nguồn và đích).

Các pipeline huấn luyện của chúng tôi được lưu trữ trong một kho git công cộng26 và các công thức xây dựng có thể thay đổi khi chúng tôi liên tục phát triển hệ thống. Các thành phần chính và nguyên tắc vẫn giữ nguyên và tài liệu được cung cấp trong kho. Ở đây, chúng tôi chỉ cung cấp cái nhìn tổng quan cấp cao về gói và đề cập người đọc quan tâm đến nguồn gốc.

3.1.1 Thiết lập và Huấn luyện Cơ bản
Việc thiết lập và bắt đầu các công việc huấn luyện batch rất đơn giản và được tối ưu hóa cho các hệ thống dựa trên Linux hiện đại với đủ không gian lưu trữ, tính sẵn có của GPU tương thích CUDA và truy cập vào các nguồn trực tuyến. Cài đặt

25https://www.gnu.org/software/make/
26https://github.com/Helsinki-NLP/OPUS-MT-train

--- TRANG 12 ---
Mẫu LaTeX Springer Nature 2021
12 Dân chủ hóa Dịch máy Thần kinh với OPUS-MT
các pipeline và phụ thuộc phần mềm có thể được thực hiện trên dòng lệnh sử dụng các công thức cài đặt:
git clone https://github.com/Helsinki-NLP/OPUS-MT-train.git
cd OPUS-MT-train
git submodule update --init --recursive --remote
make install

Huấn luyện các mô hình chung có thể được thực hiện bằng các mục tiêu cấp cao cơ bản đảm nhận toàn bộ pipeline và các tác vụ con cần thiết để lấy dữ liệu và bắt đầu các quy trình huấn luyện. Tài liệu bao gồm một danh sách mở rộng các biến dòng lệnh để kiểm soát thuộc tính và tham số của các tác vụ con khác nhau. Tuy nhiên, các biến thiết yếu nhất cần được đặt là đặc tả ngôn ngữ nguồn và đích:

make SRCLANGS="fi et" TRGLANGS="da sv en" data
make SRCLANGS="fi et" TRGLANGS="da sv en" train
make SRCLANGS="fi et" TRGLANGS="da sv en" eval

Ví dụ trên cho thấy việc tạo ra một mô hình OPUS-MT thần kinh (đa ngôn ngữ) dễ dàng như thế nào chỉ bằng cách đưa ra một tập các ID ngôn ngữ cần được bao gồm trong mô hình (tiếng Phần Lan và tiếng Estonia như ngôn ngữ nguồn và tiếng Đan Mạch, tiếng Thụy Điển và tiếng Anh như ngôn ngữ đích trong trường hợp này). Lưu ý rằng lệnh đầu tiên có thể được bỏ qua vì data là một điều kiện tiên quyết cho công thức huấn luyện sẽ lấy và chuẩn bị dữ liệu trong mọi trường hợp.27 Các công thức được thiết kế để đảm nhận việc lấy tất cả các tập dữ liệu có sẵn từ OPUS với các kết hợp ngôn ngữ nguồn và đích. Một mẫu tách rời ngẫu nhiên (trong tất cả các kết hợp ngôn ngữ) từ một kho ngữ liệu chuyên dụng sẽ được sử dụng làm dữ liệu xác thực và kiểm tra và dữ liệu còn lại đi vào huấn luyện. Có một danh sách ưu tiên được chỉ định thủ công mã hóa cứng của các kho ngữ liệu OPUS sẽ được sử dụng làm dữ liệu kiểm tra và phát triển tập trung vào phạm vi ngôn ngữ và độ sạch tương đối. Danh sách và cơ chế có thể thay đổi theo thời gian với sự phát triển thêm của OPUS và các công thức huấn luyện OPUS-MT. Thay vào đó, các tập dữ liệu TTC có thể được sử dụng để áp dụng việc chia nhất quán vào dữ liệu huấn luyện, phát triển và kiểm tra. Các mô hình sử dụng nhiều ngôn ngữ đích sẽ tự động sử dụng nhãn ngôn ngữ đích để bổ sung mô hình transformer được chia sẻ hoàn toàn.

Nói chung, OPUS-MT sẽ sử dụng các bản phát hành mới nhất của OPUS để chuẩn bị dữ liệu. Một số kiểm tra và lọc hợp lý cơ bản (loại bỏ các ký tự không thể in hoặc Unicode bị hỏng và một số lọc dựa trên độ dài) được thực hiện nhưng không có thay đổi lớn nào được áp dụng cho các nguồn. Các mô hình phân đoạn subword được huấn luyện bằng SentencePiece [23] và căn chỉnh từ được tạo ra bằng eflomal [18] để cung cấp tính năng căn chỉnh có hướng dẫn được sử dụng theo mặc định.28 Các tham số mặc định cung cấp sự phù hợp tốt cho các mô hình cơ sở thường xuyên nhưng chúng tôi khuyến khích tối ưu hóa thêm các siêu tham số. Để biết thêm chi tiết về cách kiểm soát thiết lập, vui lòng xem tài liệu của chính các công thức. Mục tiêu eval sẽ tính toán các số liệu đánh giá tự động trên dữ liệu holdout. Một mục tiêu khác (eval-testsets) có thể được sử dụng để cũng benchmark với các tập kiểm tra khác có sẵn cho các cặp ngôn ngữ được hỗ trợ. Những thứ này cần có sẵn trong kho.

OPUS-MT cũng hỗ trợ lấy mẫu dữ liệu dựa trên nhiệt độ [25], điều quan trọng để cân bằng tính sẵn có của các ví dụ cặp ngôn ngữ cụ thể trong các mô hình dịch thuật đa ngôn ngữ. Thêm một tham số vào các công thức tạo dữ liệu huấn luyện sẽ ảnh hưởng đến tỷ lệ được sử dụng cho các tập dữ liệu lệch. Để đưa ra một ví dụ thực tế: thêm MAXDATA_SIZE=1000000 DATA_SAMPLING_WEIGHT=0.2 vào lệnh make sẽ khiến hệ thống chọn tỷ lệ thuận với khả năng điều chỉnh nhiệt độ p1/5_l của việc quan sát một ví dụ trong ngôn ngữ l từ toàn bộ tập dữ liệu. Tham số bổ sung MAXDATA_SIZE đặt kích thước mẫu thành một triệu ví dụ cho cặp ngôn ngữ lớn nhất và tất cả các cặp ngôn ngữ khác sẽ được lấy mẫu xuống hoặc lên theo tỷ lệ mẫu.

3.1.2 Công việc Batch trên Cơ sở hạ tầng HPC
Chế độ chính của việc chạy các pipeline huấn luyện OPUS-MT là sử dụng các công việc batch trên các cụm tính toán hiệu năng cao (HPC) sử dụng Slurm Workload Manager29 như một bộ lập lịch công việc. Để hỗ trợ việc sử dụng linh hoạt của tất cả các công thức, OPUS-MT thực hiện các quy tắc pattern chung để biến bất kỳ công thức nào (hoặc mục tiêu makefile) thành một công việc batch Slurm. Điều này được thực hiện bằng cách định nghĩa một hậu tố đặc biệt có thể được thêm vào bất kỳ mục tiêu nào có sẵn trong hệ thống xây dựng dựa trên makefile. Khi thêm một hậu tố như vậy, công thức sẽ tạo ra một script Slurm với mục tiêu gốc như một mục tiêu và gửi nó đến bộ lập lịch công việc sử dụng thiết lập được chỉ định cho môi trường cụ thể HPC. Lưu ý rằng những thiết lập đó hiện tại cơ bản được mã hóa cứng để hoạt động trong môi trường riêng của chúng tôi và cần phải thực hiện các điều chỉnh để phù hợp với cài đặt cục bộ của cụm HPC của bạn. Bên dưới, bạn có thể thấy một ví dụ để gửi công việc huấn luyện cho cùng một mô hình đã thảo luận ở trên với thời gian wall là 72 giờ (hậu tố .submit kích hoạt việc tạo script công việc batch và việc gửi đến engine Slurm):

make SRCLANGS="fi et" TRGLANGS="da sv en" WALLTIME=72 train.submit

Nhiều biến khác nhau có thể được sử dụng để kiểm soát hành vi và phân bổ tài nguyên của những công việc đó. Để biết chi tiết, hãy xem tài liệu và định nghĩa trong mã nguồn.

3.1.3 Data Augmentation
Data augmentation đặc biệt quan trọng đối với các ngôn ngữ ít tài nguyên. Tuy nhiên, ngay cả các ngôn ngữ có tài nguyên tốt hơn cũng hưởng lợi từ dịch ngược [26]

27Lưu ý rằng mục tiêu eval không được thực hiện với train như một điều kiện tiên quyết để tránh việc các lệnh gọi để đánh giá tự động kích hoạt các quy trình lấy dữ liệu và huấn luyện tốn kém.
28Các bộ căn chỉnh từ thần kinh như awesome aligner [24] cũng có thể được sử dụng nhưng chúng tôi thích một bộ căn chỉnh ngôn ngữ-agnostic như eflomal không yêu cầu các mô hình ngôn ngữ đã được pre-train với một phạm vi ngôn ngữ nhất định và nhu cầu tiềm năng của fine-tuning bổ sung.
29https://slurm.schedmd.com/overview.html

--- TRANG 13 ---
Mẫu LaTeX Springer Nature 2021
Dân chủ hóa Dịch máy Thần kinh với OPUS-MT 13
và các kỹ thuật khác làm tăng phạm vi của dữ liệu. OPUS-MT thực hiện các quy trình thuận tiện để tạo ra dịch ngược và dữ liệu tam giác dựa trên pivot.

Theo mặc định, dữ liệu đơn ngữ được trích xuất từ Wikipedia và các tập dữ liệu công cộng khác được cung cấp bởi tổ chức Wikimedia có sẵn cho dịch ngược. Đối với các ngôn ngữ được hỗ trợ, OPUS-MT lấy dữ liệu đã được chuẩn bị trước đó từ object storage của chúng tôi và sử dụng các mô hình hiện có theo hướng dịch thuật ngược để dịch chúng ngược vào ngôn ngữ nguồn. Dịch ngược được thực hiện cho các cặp ngôn ngữ riêng lẻ, nhưng các mô hình đa ngôn ngữ chắc chắn có thể được sử dụng bên cạnh các mô hình song ngữ cho mục đích đó.

Huấn luyện các mô hình OPUS-MT theo các hướng khác nhau có thể được thực hiện theo cách lặp đi lặp lại và do đó, dữ liệu dịch ngược có thể cải thiện từng bước và với điều đó chất lượng của các mô hình dịch thuật theo cả hai hướng có thể tăng lên [27]. Điều này đặc biệt hữu ích trong các thiết lập ít tài nguyên nơi các bản dịch ngược ban đầu có thể khá nhiễu và chất lượng dịch thuật trước tiên cần đạt đến mức độ hợp lý theo cả hai hướng. Một ví dụ về quy trình dịch ngược lặp như vậy được minh họa trong Hình 5, nơi một mô hình để dịch từ tiếng Anh sang tiếng Central Bikol được cải thiện với một số vòng lặp dịch ngược.

Một phương pháp hiệu quả khác cho data augmentation là tam giác và dịch thuật dựa trên pivot. Nhiều tập dữ liệu tập trung vào tiếng Anh, nhưng nhu cầu về dịch thuật trực tiếp giữa các ngôn ngữ không phải tiếng Anh chắc chắn đang tăng lên và vẫn còn chưa được khám phá đầy đủ. Một ví dụ thực tế trong thế giới thực đã xuất hiện trong cuộc khủng hoảng đang diễn ra

--- TRANG 14 ---
Mẫu LaTeX Springer Nature 2021
14 Dân chủ hóa Dịch máy Thần kinh với OPUS-MT
Hình 5 Dịch ngược lặp đi lặp lại như một phương tiện data augmentation. OPUS-MT sử dụng nội dung Wikipedia làm dữ liệu đơn ngữ và ví dụ minh họa các cải tiến lặp đi lặp lại (trong biểu đồ cột bên phải) cho các bản dịch giữa tiếng Anh và tiếng Central Bikol (một ngôn ngữ Austronesian được nói ở Philippines) về điểm BLEU. Dữ liệu đơn ngữ đến từ Wikipedia được dịch trong một số vòng cải tiến dịch thuật tiến và lùi bằng cách sử dụng các bản dịch mới để tạo ra dữ liệu dịch ngược tổng hợp hiện tại để tăng cường các mô hình dịch thuật theo cả hai hướng.

ở Ukraine. Những người tị nạn di chuyển đến các quốc gia châu Âu khác nhau cần hỗ trợ để quản lý luồng thông tin và giao tiếp bằng các ngôn ngữ địa phương. Hình 6 minh họa các cách khác nhau của việc tăng cường dữ liệu để cải thiện dịch thuật, trong ví dụ này giữa tiếng Ukraine và tiếng Phần Lan (theo cả hai hướng).

Tam giác của dữ liệu tập trung vào tiếng Anh là một cách dễ dàng để sản xuất thêm tài liệu huấn luyện. MultiParaCrawl30 được tạo ra theo cách này bằng cách pivoting căn chỉnh trên các câu giống hệt nhau trong tiếng Anh. Một lượng không đáng kể 1,5 triệu cặp câu cho tiếng Phần Lan–Ukraine có thể được trích xuất theo cách này từ các văn bản song song tiếng Anh–Ukraine và tiếng Anh–Phần Lan gốc trong ParaCrawl.

Dịch thuật dựa trên pivot là một cách khác đơn giản để tạo ra dữ liệu huấn luyện nhân tạo. Dịch một phía của một văn bản song song có thể biến các tập dữ liệu hiện có thành một kho ngữ liệu song song tổng hợp cho một cặp ngôn ngữ khác. Điều này đặc biệt hữu ích nếu các mô hình mạnh chất lượng cao có thể được sử dụng để thực hiện dịch thuật tự động đó. Trong ví dụ đang chạy của chúng tôi, chúng tôi có thể sử dụng một mô hình đa ngôn ngữ cho các ngôn ngữ Slavic Đông có liên quan để dịch từ tiếng Nga sang tiếng Ukraine và một mô hình tối ưu hóa khác để dịch tiếng Anh sang tiếng Phần Lan để chuyển đổi dữ liệu tiếng Anh–Ukraine và tiếng Nga–Phần Lan thành cặp ngôn ngữ tiếng Phần Lan–Ukraine mong muốn. Lưu ý rằng chúng tôi bao gồm cả dữ liệu ngôn ngữ nguồn tổng hợp (từ kho ngữ liệu tiếng Anh–Ukraine nơi tiếng Anh được dịch sang tiếng Phần Lan) và dữ liệu ngôn ngữ đích tổng hợp (từ kho ngữ liệu tiếng Nga–Ukraine với tiếng Nga được dịch sang tiếng Ukraine). Thông thường, ngôn ngữ đích tổng hợp không được ưa chuộng vì tiếng ồn bổ sung có thể vào một mô hình dịch thuật. Tuy nhiên, với chất lượng có thể đạt được cho các ngôn ngữ có liên quan chặt chẽ, quy trình này đủ ổn định và khá hiệu quả như một phương tiện data augmentation khác.

Các mô hình đa ngôn ngữ sẽ là một thay thế để bao gồm ngầm các ngôn ngữ pivot, nhưng phương pháp dịch thuật trực tiếp dựa trên pivot có lợi thế là chúng tôi không cần tăng dung lượng của mô hình dịch thuật (bằng cách thổi phồng số lượng tham số) để chứa các ngôn ngữ bổ sung cũng như chúng tôi không cần quan tâm đến việc cân bằng giữa các ngôn ngữ khác nhau trong dữ liệu ngôn ngữ hỗn hợp. Hơn nữa, chúng tôi có thể một lần nữa hưởng lợi từ các mô hình đã được pre-train hiện có đã được tối ưu hóa theo nhiều cách khác nhau, tránh việc học lại mọi thứ từ đầu.

3.1.4 Fine-Tuning
Thông thường, việc fine-tune các mô hình cho các tác vụ hoặc lĩnh vực cụ thể cũng là phổ biến. OPUS-MT hỗ trợ fine-tuning theo cách mà một chu kỳ ngắn huấn luyện bổ sung dựa trên dữ liệu huấn luyện cụ thể cho tác vụ nhỏ có thể được kích hoạt. Một tình huống phổ biến là bộ nhớ dịch thuật cục bộ có thể phục vụ như tài liệu huấn luyện bổ sung. Các công thức đặc biệt cho phép một quy trình fine-tuning như vậy.

Một kịch bản phổ biến khác là các mô hình đa ngôn ngữ có thể được fine-tune cho các cặp ngôn ngữ cụ thể. Ý tưởng là tận dụng lợi thế của việc học chuyển giao trong giai đoạn huấn luyện chung và sau đó sử dụng dữ liệu cụ thể cho ngôn ngữ để fine-tune mô hình cho cặp ngôn ngữ cụ thể đó. Điều này cũng được hỗ trợ bởi OPUS-MT và bộ sưu tập được phát hành của các pipeline huấn luyện và công thức. Tuy nhiên, theo kinh nghiệm của chúng tôi, việc định nghĩa các tham số học tập thích hợp để tránh over-fitting và catastrophic forgetting là khó khăn. Do đó, chúng tôi thường không phát hành các mô hình fine-tune như vậy và để lại cho người dùng cuối hoặc nhà phát triển các giải pháp cụ thể để thực hiện một quy trình như vậy.

3.1.5 Đánh giá và Phát hành
Tác vụ cuối cùng mà chúng tôi muốn thảo luận trong phần này đề cập đến đánh giá và đóng gói các mô hình. Các mục tiêu để kiểm tra các mô hình đã được đề cập trước đó. Kho OPUS-MT, hơn nữa, bao gồm các tập kiểm tra benchmark phổ biến và những thứ đó hữu ích để so sánh chất lượng mô hình với nghiên cứu được thiết lập và công bố khác. Chúng tôi hiện đang làm việc trên một cách có nguyên tắc hơn để benchmark tất cả các mô hình được phát hành. Thông tin thêm về nỗ lực đó được đưa ra trong Phần 4.

Một tính năng quan trọng cũng là việc tạo ra các gói phát hành. Các mục tiêu đặc biệt được định nghĩa để thu thập tất cả thông tin cần thiết, tạo ra tài liệu dưới dạng các tệp readme và tệp YAML cùng với kết quả benchmark và các chi tiết thiết yếu khác. Các gói phát hành chứa các mô hình bao gồm các script tiền xử lý và hậu xử lý thiết yếu, các mô hình phân đoạn subword, và cấu hình decoder. Các tệp log huấn luyện cũng được bao gồm. Để sử dụng nội bộ, chúng tôi cũng hỗ trợ các chức năng thuận tiện để lưu trữ và lấy các mô hình cũng như các tệp làm việc trung gian từ dịch vụ lưu trữ bên ngoài của chúng tôi. Nhiều quy trình khác nhau được định nghĩa để cập nhật thông tin có sẵn cho người dùng bên ngoài bao gồm danh sách các mô hình được phát hành và các thuộc tính quan trọng định nghĩa chức năng của chúng.

30https://opus.nlpl.eu/MultiParaCrawl.php

--- TRANG 15 ---
Mẫu LaTeX Springer Nature 2021
Dân chủ hóa Dịch máy Thần kinh với OPUS-MT 15
Hình 6 Data augmentation sử dụng tam giác và dịch máy dựa trên pivot. Dữ liệu huấn luyện tổng hợp có thể được tạo ra từ các kho ngữ liệu song song tập trung vào tiếng Anh và các bản dịch tự động của một số ngôn ngữ pivot sử dụng các mô hình OPUS-MT hiện có. Hình minh họa cho thấy phương pháp trên ví dụ dịch thuật Ukraine–Phần Lan.

Các bản phát hành được thực hiện bên trong các container ObjectStorage với backend CEPH,31 được liên kết từ các trang web dự án và trang markdown GitHub. Thông tin về hiệu suất của chúng cũng có sẵn và thông tin thêm về benchmarking sẽ được đưa ra tiếp theo trong Phần 4.

3.2 Ứng dụng Server Dịch máy
OPUS-MT cũng cung cấp các cách triển khai mô hình và xây dựng các server dịch thuật để demo và sử dụng MT từ các ứng dụng web hoặc thông qua các API dịch vụ. Các implementation32 của chúng tôi tận dụng decoder hiệu quả được phát hành như một phần của Marian-NMT33 ở chế độ server để tạo ra một dịch vụ dịch thuật đang chạy.

Có sẵn hai ứng dụng thay thế, một dựa trên framework web Tornado và một khác thực hiện các dịch vụ websocket có thể dễ dàng được triển khai trên các server Linux thông thường và máy ảo.

Giải pháp dựa trên Tornado cũng được containerized sử dụng docker và theo cách này có thể được triển khai trong nhiều môi trường khác nhau. Các frontend web đơn giản demo việc sử dụng các API dịch vụ. Cấu hình và thiết lập đơn giản sử dụng các gói được phát hành từ OPUS-MT. Các backend server đảm nhận tất cả tiền xử lý và hậu xử lý cơ bản (bao gồm phân tách câu và tokenization subword) và cung cấp giao diện JSON đơn giản cho server thực tế. Cả hai ứng dụng cũng có thể kết hợp một số dịch vụ dịch thuật và cung cấp chúng thông qua giao diện và API chung. Các mô hình cần được hỗ trợ có thể được chỉ định trong các tệp cấu hình. Một ví dụ cho cấu hình ứng dụng web Tornado được hiển thị trong Hình 7.

Dịch vụ websocket cung cấp một số chức năng bổ sung có thể hữu ích khi triển khai các mô hình OPUS-MT. Có một daemon router bổ sung có thể phục vụ như một điểm truy cập trung tâm, có thể kết nối với nhiều backend dịch thuật khác nhau. Việc tích hợp các mô hình đa ngôn ngữ cũng được hỗ trợ tốt. Hơn nữa, đầu ra cũng cung cấp việc phân đoạn thành các đơn vị subword và một căn chỉnh giữa chúng, điều này có ý nghĩa đối với các mô hình

31Ceph là một hệ thống lưu trữ phân tán mã nguồn mở, xem https://ceph.io/.
32https://github.com/Helsinki-NLP/OPUS-MT
33https://marian-nmt.github.io/

--- TRANG 16 ---
Mẫu LaTeX Springer Nature 2021
16 Dân chủ hóa Dịch máy Thần kinh với OPUS-MT
{
"en": {
"es": {
"configuration": "./models/en-es/decoder.yml",
"host": "localhost",
"port": "10001"
},
"fi": {
"configuration": "./models/en-fi/decoder.yml",
"host": "localhost",
"port": "10002"
},
}
}
Hình 7 Một cấu hình đơn giản cho server OPUS-MT sử dụng implementation ứng dụng web Tornado cung cấp dịch vụ cho dịch máy tiếng Anh–tiếng Tây Ban Nha và tiếng Anh–tiếng Phần Lan.

được huấn luyện với tính năng căn chỉnh có hướng dẫn của Marian-NMT.34 Các giao diện sau đó có thể hiển thị các liên kết giữa các token đầu vào và đầu ra để theo dõi tốt hơn các kết nối giữa ngôn ngữ nguồn và đích bên trong mô hình dịch thuật. Căn chỉnh cũng có thể hữu ích cho các tính năng hậu xử lý bổ sung được xây dựng trên đầu chính dịch vụ dịch thuật như đặt thẻ và thông tin định dạng. Một ví dụ đầu ra được hiển thị trong Hình 8. Hơn nữa, backend server cũng thực hiện một cache tăng tốc dịch thuật đáng kể khi các câu giống hệt nhau được truyền vào engine. Cache thực hiện một chức năng tra cứu đơn giản nhưng hiệu quả trong một cơ sở dữ liệu được hash, được lưu trữ trên đĩa cục bộ của server.

Các ứng dụng web của chúng tôi chủ yếu được cung cấp cho mục đích demo, nhưng chúng có thể được sử dụng như một điểm khởi đầu cho việc tích hợp nền tảng nghiêm túc và phát triển ứng dụng thế giới thực, như chúng tôi sẽ thảo luận trong phần tiếp theo.

3.3 Tích hợp Nền tảng
Các dịch vụ web và ứng dụng được mô tả trong phần trước đã demo việc sử dụng thực tế của các mô hình OPUS-MT vượt ra ngoài lĩnh vực nghiên cứu NLP thuần túy. Nhưng ngay cả trong nghiên cứu, việc tích hợp nền tảng trở nên ngày càng quan trọng: huấn luyện tốn kém và việc phát triển các mô hình từ đầu trở nên hiếm hơn trong các phương pháp hiện tại dựa trên học chuyển giao. Việc tích hợp vào các thư viện và nền tảng phổ biến do đó rất cần thiết để tránh các overhead không cần thiết của việc bắt đầu với các cơ sở cần thiết để đạt được tiến bộ trong nghiên cứu và phát triển.

Trong phần này, chúng tôi mô tả những nỗ lực kết nối OPUS-MT với nhiều nền tảng và gói phần mềm bên ngoài khác nhau để làm cho các mô hình của chúng tôi có sẵn rộng rãi và dễ tiếp cận cho người dùng cuối, nhà phát triển ứng dụng và nhà nghiên cứu NLP cơ bản. Chúng tôi chỉ cung cấp một vài ví dụ về các trường hợp sử dụng có thể. Nhiều ứng dụng khác là các nền tảng tiềm năng nơi OPUS-MT có thể được tích hợp. Ví dụ, các mô hình của chúng tôi đã có sẵn thông qua Tiyaro.ai,35 một model hub khác cho các ứng dụng AI. Các tài nguyên cũng được liệt kê trong Meta-Share36 và các công cụ cũng có thể được thêm vào switchboard CLARIN.37

3.3.1 PyTorch và Thư viện Transformers
Thành công của học sâu đã có thể thực hiện được nhờ sự sẵn có của phần mềm mở cho phép việc thích ứng dễ dàng các phương pháp thần kinh cho một loạt các tác vụ, những cái liên quan đến NLP rất nổi bật trong số đó. Các framework mục đích chung như PyTorch38 và Tensorflow39 cung cấp xương sống thiết yếu của hầu hết công việc được thực hiện trong lĩnh vực này. Các thư viện cấp cao chuyên biệt trên đỉnh những framework đó ngày nay làm cho việc bắt đầu với các phương pháp thần kinh NLP tiên tiến trở nên dễ dàng và cũng cho phép truy cập vào các mô hình đã được pre-train được phát hành của nhiều loại khác nhau. Thư viện transformers được xuất bản bởi Hugging Face40 là một trong những hub phổ biến nhất của NLP hiện đại, chủ yếu được thúc đẩy bởi cộng đồng.

Với sự giúp đỡ của các nhà khoa học tại Hugging Face, các mô hình OPUS-MT đã được tích hợp đầy đủ vào thư viện transformers bằng cách chuyển đổi chúng sang PyTorch. Tác động rất đáng kể vì điều này cho phép một loạt người dùng ngay lập tức có quyền truy cập vào hàng nghìn mô hình dịch thuật đã được pre-train hỗ trợ nhiều ngôn ngữ và cặp ngôn ngữ. Các mô hình hiện có sẵn từ model hub Hugging Face và có thể được sử dụng với một vài dòng mã hoặc thậm chí thông qua API suy luận trực tuyến (xem Hình 9).

Sự hợp tác với Hugging Face đang diễn ra và các phát triển trong tương lai sẽ đi vào framework phổ biến. Gần đây, các công cụ chuyển đổi đã được điều chỉnh để bao gồm linh hoạt hơn các kiến trúc khác nhau. Các backend dựa trên Tensorflow cũng được hỗ trợ bây giờ, điều này tạo ra các cơ hội bổ sung.

3.3.2 Tích hợp vào European Language Grid
Ủy ban Châu Âu đã là một trong những người chơi quan trọng nhất trong việc tạo ra tài nguyên và giải pháp cho công nghệ ngôn ngữ bao gồm. European Language Grid (ELG) là một trong những sáng kiến được EU hỗ trợ để xây dựng một cơ sở hạ tầng toàn diện cho các tài nguyên và công cụ NLP.41 OPUS-MT đã được tài trợ như một trong những dự án thí điểm ELG. Điều này đã dẫn đến việc tích hợp liền mạch các dịch vụ dịch thuật dựa trên các mô hình OPUS-MT trong các implementation server được containerized tại ELG.

Các dịch vụ ELG có thể được truy cập từ nền tảng trực tiếp của họ và các mô hình được tải theo yêu cầu từ cơ sở hạ tầng đám mây của họ chạy thông qua Kubernetes42 và OpenStack.43 Các yêu cầu HTTPS có thể được gửi đến API nội bộ và các dịch vụ như OPUS-MT cũng có thể được gọi theo chương trình từ, ví dụ, một thư viện python ELG chuyên dụng. Các bản ghi metadata và định danh bền vững dựa trên Digital Object Identifiers (DOI)44 tạo ra các tài nguyên bền vững theo các nguyên tắc Findability, Accessibility, Interoperability, and Reuse (FAIR).45 Sự hợp tác với ELG đảm bảo việc bảo tồn dài hạn các phát triển của chúng tôi và cung cấp việc bảo trì cần thiết thông qua cơ sở hạ tầng tiêu chuẩn hóa của họ.

OPUS-MT hiện bao gồm các quy trình để tạo ra các bản ghi metadata và image docker có thể được push trực tiếp lên Docker Hub46 và ELG. Thông qua

34Tính năng này cho phép hướng dẫn một trong những head attention xuyên ngôn ngữ trong transformer với các căn chỉnh token được pre-compute. Theo cách này, chúng tôi có được một pattern attention chuyên biệt về căn chỉnh từ và nó cũng giúp kickstart các quy trình huấn luyện với kiến thức tiên nghiệm có liên quan, có thể hữu ích đặc biệt trong các thiết lập ít tài nguyên.
35https://console.tiyaro.ai/explore?q=opus-mt&pub=Helsinki-NLP
36https://metashare.csc.fi/
37https://switchboard.clarin.eu/
38https://pytorch.org/
39https://www.tensorflow.org/
40https://huggingface.co/transformers/
41https://live.european-language-grid.eu/
42https://kubernetes.io/
43https://www.openstack.org/
44https://www.doi.org/
45https://www.go-fair.org/fair-principles/
46Docker Hub là một kho chứa các image container phần mềm do người dùng đóng góp, xem https://hub.docker.com/.

--- TRANG 17 ---
Mẫu LaTeX Springer Nature 2021
Dân chủ hóa Dịch máy Thần kinh với OPUS-MT 17
{
"alignment": [
"0-0 1-1 2-2"
],
"result": "Huomenta, Suomi",
"segmentation": "spm",
"server": "192.168.1.15:40002",
"source": "sv",
"source-segments": [
"\u2581Godmorgon , \u2581Finland"
],
"target": "fi",
"target-segments": [
"\u2581Huomenta , \u2581Suomi"
]
}
Hình 8 Một phản hồi dịch thuật từ server websocket sử dụng OPUS-MT để dịch từ tiếng Thụy Điển sang tiếng Phần Lan. Kết quả cuối cùng sau hậu xử lý có sẵn trong mục "result" và "alignment" đề cập đến căn chỉnh subword token giữa các phân đoạn ngôn ngữ nguồn và đích. Danh sách phân đoạn nguồn và đích liệt kê các subword token được phân tách bằng khoảng trắng. Ký tự Unicode \u2581 ở đầu một số trong đó cho biết kết nối với token trước đó (tức là nhu cầu loại bỏ khoảng trắng trước), thường được sử dụng bởi tokenizer SentencePiece [28].

những quy trình đó, các dịch vụ mới có thể dễ dàng được đăng ký bên trong nền tảng ELG và trở nên có sẵn cho người dùng cuối và nhà phát triển sau một khoảng thời gian xác thực nội bộ. Các image Docker tự nhiên cũng có sẵn bên ngoài nền tảng ELG và có thể được lấy và triển khai cục bộ hoặc trên các dịch vụ đám mây khác. Chúng tôi cũng tích hợp các dịch vụ dịch thuật ELG vào OPUS-CAT, làm cho có thể bao gồm OPUS-MT trong các quy trình làm việc dịch thuật chuyên nghiệp. Thông tin thêm về OPUS-CAT có thể được tìm thấy trong Phần 3.4.

3.3.3 Ứng dụng Người dùng cuối
Các phần trước đã cho thấy nhiều cách tích hợp OPUS-MT vào các ứng dụng người dùng cuối thông qua các dịch vụ trực tuyến và các giải pháp server được containerized. Tích hợp thêm vào các công cụ được mô tả bên dưới demo các trường hợp sử dụng và lĩnh vực ứng dụng bổ sung.

Dịch thuật tương tác và tức thì hữu ích cho việc truy cập nhanh thông tin bằng các ngôn ngữ khác. Dự án Bergamot47 đã tạo ra các implementation tối ưu hóa tốc độ cho các engine dịch thuật cục bộ có thể chạy bên trong trình duyệt web hoặc trong các ứng dụng desktop chuyên dụng.48 Ý tưởng chính là sử dụng knowledge distillation, quantization và lexical shortlist49 để đẩy giới hạn tốc độ giải mã. Hơn nữa, các implementation decoder có thể được tối ưu hóa theo nhiều cách khác nhau và một fork tùy chỉnh của Marian tạo ra xương sống của giải pháp Bergamot. Các mô hình OPUS-MT có thể được sử dụng thông qua cùng một cơ sở hạ tầng vì chúng được xây dựng gốc trong Marian-NMT. Hơn nữa, chúng tôi hiện đang làm việc trên việc chưng cất có hệ thống các mô hình OPUS-MT để tạo ra các mô hình student hiệu quả tương thích với dự án Bergamot (xem thêm Phần 5.2). Với những thứ đó, các mô hình của chúng tôi trở nên có sẵn trong kho của các giải pháp MT dựa trên trình duyệt50 và ứng dụng desktop translateLocally51 (xem Hình 10).

Plugin và add-on cho các ứng dụng thường được sử dụng là một phương tiện khác để mang OPUS-MT đến người dùng cuối thực tế. Một ví dụ là các kênh truyền thông xã hội được sử dụng thường xuyên bởi hàng triệu và thậm chí hàng tỷ người trên toàn thế giới. Như một phản ứng với cuộc khủng hoảng ở Ukraine, chúng tôi đã phát triển một nguyên mẫu để dịch từ và sang tiếng Ukraine sử dụng một bot dịch thuật trong Telegram. Đến nay, theo thống kê SimilarWeb52, Telegram đã là nền tảng nhắn tin được sử dụng nhiều nhất ở Ukraine cả trong Google Play Store và Apple App Store. Bot được thực hiện bằng aoigram, một framework cho Telegram Bot API được viết bằng Python; nó là bất đồng bộ, do đó nhiều yêu cầu có thể được xử lý gần như đồng thời. Tương tác với bot dễ dàng và thuận tiện vì gửi tin nhắn là tất cả những gì cần thiết để có được bản dịch mong muốn. Bot sử dụng server websocket của chúng tôi và hỗ trợ một số ngôn ngữ nguồn và đích liên quan đến tiếng Ukraine. Một ví dụ về hoạt động của bot được hiển thị trong Hình 11.

47https://browser.mt/
48https://translatelocally.com/
49Một lexical shortlist hạn chế từ vựng đầu ra thành một tập con nhỏ các ứng viên dịch thuật để cải thiện tốc độ giải mã, xem https://marian-nmt.github.io/docs/ để biết thêm thông tin.
50https://translatelocally.com/web/
51OPUS-MT fork tại https://github.com/Helsinki-NLP/OPUS-MT-app/
52https://similarweb.com/apps/top

--- TRANG 18 ---
Mẫu LaTeX Springer Nature 2021
18 Dân chủ hóa Dịch máy Thần kinh với OPUS-MT
Hình 9 Một ví dụ về model card OPUS-MT trong model hub Hugging Face. Hộp văn bản màu xanh ở trên cùng của screenshot hiển thị một đoạn mã ba dòng để sử dụng mô hình từ thư viện transformers. Model card bao gồm thông tin về việc sử dụng mô hình, các ngôn ngữ được hỗ trợ và liên kết đến các trang web dự án có liên quan với thông tin thêm về mô hình gốc và các tập dữ liệu được sử dụng để tạo ra nó. Model hub cũng cung cấp một API suy luận trực tiếp có thể được sử dụng để kiểm tra mô hình (trong cột bên phải) và thống kê tải xuống cũng được hiển thị trên đầu của cột đó.

3.4 Quy trình làm việc Chuyên nghiệp với OPUS-CAT
OPUS-CAT53 là một bộ sưu tập các gói phần mềm cho phép các dịch giả sử dụng các mô hình OPUS-MT đã được pre-train trong các công cụ dịch thuật hỗ trợ máy tính. MT hiện được sử dụng thường xuyên trong công việc dịch thuật chuyên nghiệp, nhưng lĩnh vực này được thống trị bởi các hệ thống MT độc quyền được cung cấp bởi các công ty công nghệ lớn (như Google hoặc Microsoft) hoặc các nhà cung cấp dịch máy chuyên biệt (như DeepL và ModernMT). OPUS-CAT cung cấp một thay thế miễn phí và mã nguồn mở cho các sản phẩm MT độc quyền.

OPUS-CAT bao gồm một engine MT cục bộ và một lựa chọn các plugin và các loại tích hợp công cụ CAT khác. Lõi của engine MT cục bộ là một bản build Windows của framework Marian, được bổ sung bởi một GUI để tải xuống và tự động cài đặt các mô hình OPUS-MT từ một kho chứa tập trung. Engine có thể được cài đặt đơn giản bằng cách giải nén gói cài đặt, và các mô hình có thể được tìm kiếm theo tên ngôn ngữ. Engine MT cục bộ không yêu cầu kết nối với bất kỳ dịch vụ bên ngoài nào, tất cả các bản dịch được tạo ra trên máy tính của người dùng sử dụng CPU gốc của nó. Engine MT cục bộ hiện chỉ có sẵn cho Windows, vì nhiều công cụ CAT cũng chỉ có sẵn trong Windows, và các dịch giả chuyên nghiệp do đó có thể là người dùng Windows. Các phiên bản Linux hoặc Mac của engine MT không được lên kế hoạch vào lúc này, vì chúng có thể sẽ không mở rộng cơ sở người dùng tiềm năng của OPUS-CAT một cách đáng kể.

GUI của engine MT cung cấp một chức năng đơn giản để dịch văn bản, nhưng các bản dịch chủ yếu được dự định để được tạo ra thông qua một API mà engine MT expose. Các plugin công cụ CAT và các tích hợp khác có thể được xây dựng trên đỉnh API này. OPUS-CAT hiện hỗ trợ hầu hết các công cụ CAT được sử dụng rộng rãi. Nó bao gồm các plugin chuyên dụng cho ba công cụ CAT desktop: Trados Studio54, memoQ55, và OmegaT56. Trong một số công cụ CAT, chẳng hạn như Wordfast57, OPUS-CAT có thể được sử dụng bằng cách kết nối trực tiếp với API của nó thông qua chức năng nhà cung cấp MT tùy chỉnh. OPUS-CAT cũng bao gồm một extension trình duyệt Chrome, làm cho có thể sử dụng OPUS-MT trong các công cụ CAT dựa trên trình duyệt. Extension Chrome hiện hỗ trợ Phrase58 (trước đây là Memsource) và XTM59, và việc sửa đổi nó để hỗ trợ các công cụ CAT dựa trên trình duyệt khác tương đối đơn giản.

Một trong những lợi thế của việc sử dụng OPUS-CAT trong dịch thuật chuyên nghiệp là nó vốn dĩ an toàn và bảo mật. Vì không có dịch vụ bên ngoài nào được sử dụng, dữ liệu nhạy cảm không bao giờ gặp rủi ro. Trong khi nhiều nhà cung cấp MT thương mại cung cấp các cài đặt on-premises tương tự như OPUS-CAT, các cài đặt như vậy tốn kém và chúng không thể được điều chỉnh tự do như OPUS-CAT mã nguồn mở. Tính bảo mật được đảm bảo của OPUS-CAT cũng làm cho các dịch giả cá nhân có thể sử dụng nó trong công việc của họ mà không vi phạm các thỏa thuận bảo mật.

OPUS-CAT được dự định cho các dịch giả chuyên nghiệp, vì vậy nó bao gồm các chức năng để giải quyết các vấn đề liên quan đến việc sử dụng MT trong dịch thuật chuyên nghiệp, chẳng hạn như thích ứng miền và xử lý thẻ.

Tính hữu ích của các mô hình NMT chung trong dịch thuật chuyên nghiệp không chắc chắn, trong khi các cải tiến hiệu suất do việc sử dụng các mô hình NMT thích ứng miền đã được quan sát nhiều lần [29, 30]. Vì điều này, OPUS-CAT MT Engine bao gồm một chế độ để fine-tune các mô hình với dữ liệu song ngữ. Vì fine-tuning phải được thực hiện cục bộ trên CPU, chỉ có lượng dữ liệu nhỏ được sử dụng (thường là hàng chục nghìn cặp dịch thuật) và huấn luyện chỉ kéo dài trong một epoch duy nhất. Để tránh các vấn đề với over-fitting, một tỷ lệ học tập rất thận trọng được sử dụng (0.00002, một phần năm của tỷ lệ học tập ban đầu mặc định trong Marian).

Trong quá trình fine-tuning, mô hình được xác thực so với các tập xác thực in-domain và out-of-domain, và các kết quả xác thực được hiển thị đồ họa cho người dùng để cho phép họ phát hiện các vấn đề tiềm năng. Mặc dù có các thiết lập huấn luyện thận trọng và lượng dữ liệu nhỏ, việc kiểm tra không chính thức và phản hồi của người dùng cho thấy rằng fine-tuning có tác động đáng chú ý đến tính khả dụng của hệ thống MT.

Trong dịch thuật chuyên nghiệp, các tài liệu nguồn thường chứa các thẻ placeholder hoặc cặp thẻ cho biết định dạng. Việc đặt thẻ thủ công tốn thời gian, vì vậy các hệ thống MT được thiết kế cho dịch thuật chuyên nghiệp lý tưởng nên đặt thẻ nguồn tự động trong MT được tạo ra. OPUS-CAT hỗ trợ hai phương pháp đặt thẻ tự động. Khi fine-tune một mô hình, OPUS-CAT có thể được chỉ định để bao gồm các thẻ trong tập fine-tuning, cho phép mô hình fine-tune học vị trí thẻ chính xác một cách ngầm ẩn. Với các mô hình cơ sở, căn chỉnh sub-word (được hỗ trợ bởi hầu hết các mô hình OPUS-MT) cũng có thể được sử dụng để suy ra vị trí chính xác của các thẻ.

OPUS-CAT hỗ trợ thêm các quy tắc có thể được sử dụng để tiền chỉnh sửa văn bản nguồn trước khi sử dụng nó làm đầu vào MT, hoặc để hậu chỉnh sửa đầu ra MT trước khi trình bày nó cho dịch giả. Những quy tắc này có thể được áp dụng để giải quyết các lỗi có hệ thống trong văn bản nguồn hoặc trong đầu ra MT. Chẳng hạn, một quy tắc tiền chỉnh sửa có thể được tạo ra để thay đổi trường hợp chữ cái của văn bản nguồn hoặc để sửa các lỗi chính tả lặp lại, và một quy tắc hậu chỉnh sửa có thể được sử dụng để sửa một lỗi MT lặp lại.

Sự lệch khỏi thuật ngữ cụ thể cho khách hàng hoặc miền là một trong những trở ngại chính đối với việc sử dụng MT trong dịch thuật chuyên nghiệp. Trong khi fine-tuning và các quy tắc chỉnh sửa giúp giải quyết một số vấn đề, chúng có những hạn chế: fine-tuning không đảm bảo việc sử dụng thuật ngữ chính xác, nó chỉ tăng xu hướng sử dụng nó, và các quy tắc chỉnh sửa có thể được định nghĩa khả thi chỉ cho một lượng rất hạn chế các trường hợp. Công việc hiện đang được tiến hành để bao gồm hỗ trợ thuật ngữ mạnh hơn trong OPUS-CAT bằng cách thực hiện các ràng buộc thuật ngữ mềm dựa trên chú thích lemma đích [31].

OPUS-CAT hiện là giải pháp mã nguồn mở, miễn phí duy nhất cho việc sử dụng dịch máy thần kinh trong dịch thuật chuyên nghiệp. Rõ ràng có nhu cầu

53https://helsinki-nlp.github.io/OPUS-CAT/
54https://www.trados.com/products/trados-studio/
55https://www.memoq.com/
56https://omegat.org/
57https://www.wordfast.com/
58https://phrase.com/
59https://xtm.cloud/

--- TRANG 19 ---
Mẫu LaTeX Springer Nature 2021
Dân chủ hóa Dịch máy Thần kinh với OPUS-MT 19
Hình 10 Ứng dụng desktop translateLocally được phát triển trong dự án Bergamot với một thích ứng cho các mô hình OPUS-MT. Ở đây hiển thị ví dụ dịch thuật Ukraine–Anh với một số highlighting xuyên ngôn ngữ được thực hiện thông qua tính năng căn chỉnh.

cho một giải pháp như vậy, vì nhiều dịch giả cá nhân hiện sử dụng OPUS-CAT trong công việc của họ, và một số tổ chức đã bao gồm OPUS-CAT trong quy trình làm việc dịch thuật của họ. Từ quan điểm của dự án OPUS-MT rộng hơn, ý nghĩa của OPUS-CAT là nó cung cấp một kênh khác để phổ biến các mô hình đã được pre-train và thu thập phản hồi và kinh nghiệm từ một nhóm người dùng MT quan trọng, tức là các dịch giả chuyên nghiệp.

4 Benchmark và Đánh giá
Quan trọng trong phát triển nhưng cũng cho triển khai là kiểm soát chất lượng và các quy trình để giám sát tiến bộ. Các benchmark và pipeline đánh giá rất cần thiết để đáp ứng nhu cầu đó. May mắn thay, các tác vụ chung thường xuyên trong dịch máy tạo ra nhiều benchmark và chiến lược đánh giá khác nhau, và gần đây sự quan tâm ngày càng tăng đối với các ngôn ngữ và miền ít tài nguyên cũng cải thiện phạm vi ngôn ngữ của các tập kiểm tra có sẵn. Trong hệ sinh thái của chúng tôi, chúng tôi cố gắng thu thập có hệ thống các benchmark hiện có và đóng góp vào bộ sưu tập cũng với những nỗ lực riêng của chúng tôi, ví dụ, thông qua thách thức dịch thuật Tatoeba được đề cập trước đó trong Phần 2.4.

Một trong những câu hỏi quan trọng đối với thành công của OPUS-MT là chất lượng của các mô hình chúng tôi phát hành. Việc giám sát thường xuyên và đánh giá rộng rãi chúng do đó rất cần thiết. So sánh các mô hình của chúng tôi với các benchmark và tập kiểm tra đã được thiết lập là một cách để xấp xỉ chất lượng dịch thuật. OPUS-MT không cố gắng cạnh tranh với các mô hình được tối ưu hóa miền cao được gửi đến các tác vụ chung cụ thể mà thay vào đó tập trung vào các mô hình mục đích chung có thể được tái sử dụng và tinh chỉnh sau. Tuy nhiên, việc đặt các mô hình của chúng tôi trong bối cảnh với các kết quả khác là một cách tốt để chứng minh khả năng áp dụng của chúng. Hình 12 cho thấy ví dụ về kết quả dịch thuật tiếng Phần Lan–Anh được đo trên tác vụ dịch thuật tin tức phổ biến tại WMT. Hình này cho thấy rằng các mô hình của chúng tôi hoạt động tốt (về điểm BLEU) so với các hệ thống được gửi chính thức trong suốt chiến dịch đánh giá mặc dù chúng không thể so sánh trực tiếp vì

--- TRANG 20 ---
Mẫu LaTeX Springer Nature 2021
20 Dân chủ hóa Dịch máy Thần kinh với OPUS-MT
Hình 11 Một bot dịch thuật Telegram đơn giản phục vụ dịch thuật từ và sang tiếng Ukraine. Ví dụ này cho thấy bản dịch của một đoạn văn bản ngắn được lấy từ Wikipedia tiếng Ukraine.

nhiều lý do khác nhau (ví dụ, được huấn luyện trên các tập dữ liệu khác nhau và được điều chỉnh cho các miền khác nhau).

Vì lý do thực tế, chúng tôi hiện tập trung vào đánh giá tự động nhưng chúng tôi cũng thảo luận về các lựa chọn nơi các leaderboard dựa trên cộng đồng có thể tạo điều kiện cho các đánh giá thủ công thường xuyên. Để hỗ trợ việc benchmarking có hệ thống, chúng tôi biên dịch các tập kiểm tra vào kho riêng của chúng tôi,60 cung cấp cho leaderboard OPUS-MT được mô tả tiếp theo trong Phần 4.1. Ngoài ra, chúng tôi cũng đã phát triển các bộ kiểm tra để bổ sung cho việc đánh giá chất lượng dịch thuật mục đích chung được giải quyết bởi các benchmark MT thường xuyên, được mô tả trong Phần 4.2.

4.1 Bảng điều khiển OPUS-MT
Số lượng lớn các mô hình chúng tôi huấn luyện và phạm vi ngôn ngữ cao và sự đa dạng mà chúng tôi hỗ trợ làm cho việc giám sát tiến bộ và có được cái nhìn tổng quan về các hệ thống có sẵn trong số các gói được phát hành trở nên cần thiết. Một cách phổ biến để tóm tắt và so sánh các mô hình là sử dụng leaderboard trên các benchmark đã được thiết lập. OPUS-MT thực hiện một bảng điều khiển tương tác đơn giản cung cấp thông tin từ các benchmark thường xuyên của chúng tôi dưới dạng bảng và biểu đồ cột. Hình 13 cho thấy một screenshot từ trang web của chúng tôi61 với điểm BLEU trung bình cho dịch máy tiếng Anh–Ukraine được đo trên Flores [32] và benchmark Tatoeba. Hiện tại, chúng tôi hỗ trợ điểm BLEU [33], spBLEU [32], chrF [34], chrf++ [35] và COMET [36] nhưng các thước đo khác có thể được thêm vào khi chúng trở nên có sẵn từ các quy trình kiểm tra có hệ thống của chúng tôi. Bảng điều khiển cho phép chọn cặp ngôn ngữ, benchmark và cung cấp nhiều góc nhìn khác nhau về các đánh giá cụ thể cho ngôn ngữ hoặc mô hình. Các bản dịch tập kiểm tra và chính các mô hình có thể được tải xuống từ các liên kết được cung cấp trong bảng. Các văn bản của các benchmark gốc cũng được liên kết.

Bảng điều khiển lấy thông tin từ kho điểm của chúng tôi (leaderboard OPUS-MT) và hiện không hỗ trợ bất kỳ upload động nào của các mô hình hoặc kết quả dịch thuật mới. Tham vọng không phải là cung cấp một hệ thống đầy đủ tính năng để benchmarking các hệ thống mới mà thay vào đó cung cấp một góc nhìn về các kết quả đánh giá của chúng tôi để cung cấp tóm tắt và tổng quan về các khả năng OPUS-MT. Lưu ý rằng chúng tôi bao gồm một loạt các benchmark khác nhau để cung cấp một bức tranh toàn diện về hiệu suất mô hình, không bị hạn chế về một miền cụ thể và tập kiểm tra đánh giá.

Một trực quan hóa hữu ích khác là bản đồ địa lý tương tác mà chúng tôi tạo ra từ các mô hình được phát hành của chúng tôi.62 Hình 4 trong Phần 2.4 cho thấy một ví dụ về một biểu đồ như vậy. Vì chúng tôi đang nỗ lực cho một phạm vi ngôn ngữ rộng, việc nhìn thấy các khoảng trống trên toàn cầu một cách trực quan là hữu ích. Do đó, chúng tôi vẽ các mô hình dịch thuật theo ngôn ngữ nguồn hoặc đích của chúng lên vị trí địa lý được cung cấp bởi Glottolog.63 Chúng tôi sử dụng thư viện langinfo64 để trích xuất thông tin vị trí từ cơ sở dữ liệu Glottolog sử dụng các ID ngôn ngữ tiêu chuẩn ISO trong các mô hình dịch thuật của chúng tôi. OpenStreetMap được sử dụng để trực quan hóa các vị trí trên bản đồ và chúng tôi chỉ ra kích thước của tập kiểm tra bằng kích thước của chấm (để minh họa độ tin cậy của điểm) và sử dụng màu sắc trên thang liên tục từ xanh lá cây (tốt nhất) đến đỏ (tệ nhất) để chỉ ra chất lượng theo benchmark được chọn. Chúng tôi dựa trên trực quan hóa trên điểm chrF, đáng tin cậy hơn qua các ngôn ngữ so với BLEU, nhưng lưu ý rằng ngay cả những điểm đó cũng có vấn đề để so sánh nói chung. Chỉ có mô hình đạt điểm cao nhất được hiển thị cho mỗi cặp ngôn ngữ.

Bản đồ tương tác và cho phép chọn ngôn ngữ nguồn hoặc đích để dựa trên hình minh họa. Chúng tôi cũng tạo ra bản đồ cho nhiều benchmark khác nhau và sử dụng các template tính năng để hiển thị thông tin về mô hình tương ứng với một chấm trên bản đồ. Từ template đó, các liên kết đến các bản phát hành mô hình có thể tải xuống và thông tin thêm đều có sẵn.

4.2 Bộ kiểm tra Ngôn ngữ học
Những tiến bộ ấn tượng trong chất lượng dịch thuật được thấy trong những năm gần đây đã dẫn đến một cuộc thảo luận liệu các bản dịch được sản xuất bởi các dịch giả con người chuyên nghiệp vẫn có thể được phân biệt với đầu ra của các hệ thống NMT, và đến mức độ nào các thước đo đánh giá tự động có thể đáng tin cậy tính toán những khác biệt này [37–39]. Một câu trả lời cho câu hỏi này nằm trong việc phát triển các bộ kiểm tra gọi là [40] hoặc challenge set [41] tập trung vào các hiện tượng ngôn ngữ cụ thể được biết là khó đánh giá với các số liệu dựa trên tham chiếu đơn giản như BLEU. Tuy nhiên, hầu hết các bộ kiểm tra hiện có yêu cầu một lượng đáng kể kiến thức chuyên môn và công việc thủ công để biên dịch các ví dụ, thường hạn chế phạm vi của chúng đến một số lượng nhỏ hướng dịch thuật.

60https://github.com/Helsinki-NLP/OPUS-MT-testsets/
61https://opus.nlpl.eu/dashboard/
62https://opus.nlpl.eu/NMT-map/
63https://glottolog.org/
64https://github.com/robertostling/langinfo

--- TRANG 21 ---
Mẫu LaTeX Springer Nature 2021
Dân chủ hóa Dịch máy Thần kinh với OPUS-MT 21
Hình 12 So sánh các mô hình OPUS-MT (về điểm BLEU) với kết quả chính thức từ tác vụ tin tức tại WMT trong một số năm để dịch từ tiếng Phần Lan sang tiếng Anh. Điểm WMT được lấy từ http://wmt.ufal.cz/.

Để tạo điều kiện cho việc phát triển bộ kiểm tra cho một loạt cặp ngôn ngữ, chúng tôi đã giới thiệu MuCoW,65 một phương pháp độc lập ngôn ngữ để tự động xây dựng bộ kiểm tra cho các danh từ có tính mơ hồ từ vựng [42–44]. MuCoW tận dụng các kho ngữ liệu song song có sẵn trong OPUS và BabelNet [45], một từ điển bách khoa toàn thư đa ngôn ngữ có phạm vi rộng được có tự động từ nhiều tài nguyên khác nhau (WordNet và Wikipedia, cùng những cái khác). Tóm lại, ba bước sau đây cần thiết để tạo ra một bộ kiểm tra MuCoW:

1. Chúng tôi xác định các từ nguồn mơ hồ và các bản dịch của chúng trong các kho ngữ liệu song song, chỉ khớp những từ được tìm thấy là mơ hồ trong BabelNet.
2. Vì các tài nguyên từ vựng như BabelNet được biết là gặp khó khăn với tính chi tiết quá mức của kho nghĩa của chúng, chúng tôi hợp nhất các cụm nghĩa BabelNet với nghĩa tương tự, tận dụng các embedding nghĩa đã được pre-train: nếu độ tương tự cosine giữa hai embedding nghĩa vượt quá một ngưỡng nhất định, các cụm tương ứng được hợp nhất [42].
3. Để xây dựng bộ kiểm tra đúng nghĩa, chúng tôi trích xuất các cặp câu từ các kho ngữ liệu song song, đảm bảo rằng các câu từ các kho ngữ liệu khác nhau được đại diện. Mỗi câu được bổ sung với một danh sách các bản dịch chính xác và một danh sách các bản dịch không chính xác của từ nguồn mơ hồ.

Bảng 1 cho thấy một số ví dụ về các instance bộ kiểm tra cho hướng dịch thuật tiếng Anh–tiếng Đức. MuCoW đã xác định watch, air, arm và pot là các danh từ tiếng Anh mơ hồ, trích xuất các câu ví dụ sử dụng những danh từ này từ nhiều kho ngữ liệu OPUS khác nhau, và liên kết mỗi câu với các bản dịch tiếng Đức chính xác và không chính xác.

MuCoW đã được giới thiệu lần đầu tại WMT-19 như một bộ kiểm tra cho News Translation Task, cho 9 cặp ngôn ngữ [42]. Trong bối cảnh này, chúng tôi cho thấy rằng các hệ thống NMT được điều chỉnh hoạt động tốt trên bộ đánh giá của chúng tôi, nhưng gặp khó khăn khi xử lý dữ liệu ngoài miền. Chúng tôi quan sát cùng xu hướng trong năm sau tại WMT-20, chỉ với một cải tiến chung về chất lượng dịch thuật cho các hệ thống xếp hạng cao nhất [44].

Cuối cùng, chúng tôi cũng tạo ra một tập benchmark MuCoW bao gồm dữ liệu huấn luyện với phân phối nghĩa đã biết, để đánh giá các hệ thống cạnh tranh trên một nền tảng công bằng [43]. Những phát hiện của chúng tôi cho thấy rằng các mô hình Transformer tiên tiến gặp khó khăn khi xử lý các nghĩa từ hiếm. Thật thú vị, việc thêm nhiều dữ liệu huấn luyện hơn, không nhất thiết chứa các từ mơ hồ quan tâm, đóng góp vào việc giảm thiểu các vấn đề như vậy. Hơn nữa, chúng tôi cũng cho thấy rằng phân đoạn từ không ảnh hưởng nhiều đến khả năng giải mơ hồ, trong khi hiệu suất giảm nhất quán qua các ngôn ngữ khi đánh giá các câu từ các nguồn nhiễu.

5 Mở rộng và Thu nhỏ
Tăng phạm vi ngôn ngữ và cung cấp các mô hình nhẹ dễ tích hợp và triển khai đều là ưu tiên của chúng tôi để thúc đẩy lĩnh vực MT hướng tới trạng thái mở và bao gồm hơn. Tuy nhiên, theo đuổi cả hai mục tiêu song song mà không mất hiệu suất dịch thuật vẫn là một vấn đề mở. Một phương pháp phổ biến cho NMT đa ngôn ngữ sử dụng các mô hình được chia sẻ hoàn toàn, trong đó một mô hình thần kinh duy nhất được huấn luyện trên dữ liệu song song bao gồm một số hướng dịch thuật, và tất cả các trọng số mô hình được cập nhật tại mỗi bước huấn luyện. Các mô hình đa ngôn ngữ thu được với OPUS-MT như mô tả trong Phần 3.1 là ví dụ về paradigm này.

Thêm ngôn ngữ vào một mô hình đa ngôn ngữ được chia sẻ hoàn toàn [46] ngụ ý việc phân phối dung lượng mô hình trên một số tác vụ dịch thuật, có thể dẫn đến giảm hiệu suất song ngữ nếu số lượng tham số của mô hình được giữ không đổi. Mặt khác, có một số lượng lớn mô hình song ngữ, hoặc kiến trúc mô hình với các thành phần cụ thể cho ngôn ngữ, có thể không thực tế mà không có truy cập mở rộng vào các cơ sở HPC. Trong trường hợp đầu tiên, kích thước mô hình có thể trở nên không thể quản lý được do các thành phần cụ thể cho ngôn ngữ bổ sung. Trong trường hợp thứ hai, việc mở rộng phạm vi ngôn ngữ liên quan đến việc xử lý một số lượng lớn các tệp mô hình NMT (tương đối nhỏ). Trong phần này, chúng tôi thảo luận về hai chiến lược giảm thiểu vấn đề này và đưa ra cái nhìn tổng quan về các thí nghiệm đang diễn ra.

65https://github.com/Helsinki-NLP/MuCoW

--- TRANG 22 ---
Mẫu LaTeX Springer Nature 2021
22 Dân chủ hóa Dịch máy Thần kinh với OPUS-MT
Hình 13 Một screenshot từ bảng điều khiển OPUS-MT. Ví dụ cho thấy điểm BLEU trung bình trên hai benchmark (Flores và Tatoeba) cho dịch thuật từ tiếng Anh sang tiếng Ukraine. Các thanh xanh lá cây đánh dấu các mô hình student compact có thể được sử dụng để dịch thuật hiệu quả.

5.1 NMT Mô-đun
Hệ sinh thái OPUS trình bày tiềm năng mở rộng để khám phá và phân tích các khả năng của các hệ thống MT đa ngôn ngữ. Cùng với dự án Found in Translation (FoTran) được tài trợ bởi European Research Council (ERC),66 chúng tôi phát triển các mô hình hiểu ngôn ngữ tự nhiên được huấn luyện trên thông tin ngầm được đưa ra bởi các bộ sưu tập lớn bản dịch của con người. Căn chỉnh cả hai sáng kiến, điều quan trọng nhất đối với chúng tôi là phân phối và làm cho có sẵn rộng rãi, cả bộ công cụ của chúng tôi cho huấn luyện phân tán các mô hình đa ngôn ngữ và các mô hình đã được pre-train để được tái sử dụng và cũng fine-tune cho các tác vụ mới. Tại thời điểm huấn luyện, các mô hình đa ngôn ngữ cao yêu cầu một lượng lớn sức mạnh tính toán. Tuy nhiên, chúng tôi đang xây dựng một kiến trúc với thiết kế mô-đun cho phép tái sử dụng các thành phần đã được huấn luyện (mô-đun cụ thể cho ngôn ngữ và được chia sẻ) trên các đơn vị xử lý tương đối nhỏ,67 làm cho các mô hình đa ngôn ngữ có giá cả phải chăng hơn và tăng khả năng áp dụng của chúng. Trái ngược với các mô hình OPUS-MT, implementation này dựa trên OpenNMT-py68 [47]. Tham vọng của chúng tôi cũng là phát hành các mô hình từ những nỗ lực đó trong tương lai gần nhưng hiện tại, chúng tôi tập trung vào việc phát triển framework mô-đun và có thể mở rộng trước.

5.1.1 Mô hình Attention-Bridge Đa ngôn ngữ
Động lực ban đầu của chúng tôi để xây dựng một mô hình dịch thuật đa ngôn ngữ trong FoTran là khám phá vai trò của "grounding xuyên ngôn ngữ" để giải quyết sự mơ hồ thông qua dịch thuật. Trực giác đằng sau ý tưởng này là các bản dịch cung cấp một gương semantic [48] phản ánh cùng một nghĩa với các biểu hiện của ngôn ngữ khác. Chúng tôi muốn khám phá tín hiệu đó trong học representation nhưng nó cũng trở nên thú vị trong học chuyển giao cho tác vụ gốc của dịch máy. Chúng tôi thiết kế một kiến trúc NN mô-đun [49] trong đó mô hình kết hợp một lớp chia sẻ trung gian khai thác semantic từ mỗi ngôn ngữ trong khi giữ các thành phần cụ thể cho ngôn ngữ.

Kiến trúc được minh họa trong sơ đồ trung tâm của Hình 14. Nó tuân theo kiến trúc encoder–decoder sequence-to-sequence truyền thống, nhưng kết hợp các encoder và decoder cụ thể cho ngôn ngữ được kết nối thông qua một thành phần được chia sẻ để cho phép huấn luyện đa ngôn ngữ và chuyển giao kiến thức. Chúng tôi có được các representation đa ngôn ngữ được tạo ra bởi các encoder bằng cách buộc thông tin chảy qua một lớp inner-attention nút cổ chai kết nối tất cả các mô-đun cụ thể cho ngôn ngữ [50]. Lớp này tóm tắt thông tin encoder trong một representation nghĩa có kích thước cố định (ngôn ngữ-agnostic), hữu ích cho dịch máy (bao gồm hỗ trợ các kịch bản zero-shot) và các tác vụ downstream yêu cầu lý luận semantic và suy luận. Kết quả thí nghiệm chỉ ra sự cải thiện cả chất lượng dịch thuật và các abstraction được thu thập bởi mô hình của chúng tôi khi bao gồm nhiều ngôn ngữ hơn [49, 51].

5.1.2 Mở rộng cho Đa dạng Ngôn ngữ học cao
Trong implementation cơ bản của nó, mô hình đa ngôn ngữ của chúng tôi yêu cầu tài nguyên tính toán cao tại thời điểm huấn luyện do việc sử dụng các mô-đun cụ thể cho ngôn ngữ. Việc mở rộng số lượng hướng dịch thuật trên một thiết bị duy nhất bị hạn chế bởi giới hạn bộ nhớ của node tính toán cụ thể đó.

Để giải quyết những thách thức đó, chúng tôi đã thực hiện một thiết lập huấn luyện multi-node và multi-GPU kết hợp các chiến lược sau: (1) phân phối hiệu quả các mô-đun qua một số đơn vị xử lý, (2) huấn luyện mạng trên nhiều hướng dịch thuật giảm overhead bộ nhớ, và (3) tái sử dụng các mô-đun đã được huấn luyện mà không cần tải toàn bộ mạng. Được kết hợp lại, những chiến lược này cung cấp một hệ thống NMT đa ngôn ngữ hiệu quả về chi phí có thể được sử dụng thêm để trích xuất các representation nghĩa đa ngôn ngữ.

Chúng tôi phân phối mô hình qua nhiều đơn vị xử lý bằng cách tải, trong mỗi thiết bị, các encoder và decoder chỉ cho một tập con các hướng dịch thuật. Lớp inner-attention được chia sẻ qua tất cả các đơn vị xử lý. Tất cả các mô-đun có mặt trong nhiều hơn một thiết bị được khởi tạo với cùng trọng số. Các tham số có mặt trong nhiều hơn một thiết bị cần phải duy trì đồng bộ tại mỗi bước huấn luyện. Chúng tôi lập lịch truyền thông gradient của tất cả các tham số để giảm tải truyền thông inter.

Nói chung, việc phân bổ các cặp ngôn ngữ với ngôn ngữ nguồn/đích chung trên cùng một thiết bị giảm cả tổng dung lượng bộ nhớ của mô hình và lượng truyền thông cần thiết để giữ các mô-đun đồng bộ. Để thấy điều này, chúng ta có thể theo dõi ví dụ trong Hình 14. Trong ví dụ, có 7 cặp ngôn ngữ cần được huấn luyện đồng thời, và chúng tôi có quyền truy cập vào 2 GPU. Định nghĩa một phân vùng như phần bên phải nhất tối thiểu hóa lượng truyền thông giữa các thiết bị để giữ các mô-đun đồng bộ, giảm thời gian huấn luyện.

Tụ tập các cặp ngôn ngữ dựa trên ngôn ngữ nguồn (hoặc đích) có thể dẫn đến cấu hình phân tán tùy thuộc vào các ngôn ngữ đích (hoặc nguồn) được bao gồm. Khi xử lý số lượng cao hướng dịch thuật

66http://www.helsinki.fi/fotran
67https://github.com/Helsinki-NLP/FoTraNMT
68https://github.com/OpenNMT/OpenNMT-py

--- TRANG 23 ---
Mẫu LaTeX Springer Nature 2021
Dân chủ hóa Dịch máy Thần kinh với OPUS-MT 23
Bảng 1 Ví dụ về các instance bộ kiểm tra tiếng Anh–tiếng Đức. Từ tiếng Anh mơ hồ được làm nổi bật bằng chữ đậm, và các bản dịch tiếng Đức chính xác và không chính xác – như được suy luận bởi quy trình MuCoW – được đưa ra.

Ví dụ chứa từ mơ hồ | Bản dịch chính xác | Bản dịch không chính xác
---|---|---
It occurred to me that my **watch** might be broken. | Armbanduhr, Uhr | Wache
I hope you didn't get distracted during your **watch**. | Wache | Armbanduhr, Uhr
In winter, the dry leaves fly around in the **air**. | Luft, Luftraum, Aura | Miene, Ausdruck
He remained silent for a moment, with a thoughtful but contented **air**. | Miene, Ausdruck | Luft, Luftraum, Aura
Harry had to back out of the competition because of a broken **arm**. | Arm | Waffe
So does the cop who left his side **arm** in a subway bathroom. | Waffe | Arm
Drain the pasta and return the pasta to the **pot**. | Blumentopf, Kochtopf, Topf, Nachttopf | Marihuana, Gras
Where did those idiots get all of this **pot** anyhow? | Marihuana, Gras | Blumentopf, Kochtopf, Topf, Nachttopf

(và số lượng hạn chế ngôn ngữ nguồn và đích) việc tránh điều kiện này trở nên không thể. Chúng tôi giải quyết những vấn đề này bằng cách sử dụng hai chiến lược. Đầu tiên, chúng tôi giải quyết vấn đề phân bổ để tối thiểu hóa truyền thông inter-device. Vì trong hầu hết trường hợp vấn đề không có giải pháp chính xác khả thi, chúng tôi xấp xỉ nó bằng thuật toán Hungarian [52] trên một ma trận chi phí làm cho việc gán cùng một ngôn ngữ cho một GPU nhất định rẻ hơn. Thứ hai, chúng tôi đề xuất lập lịch các cập nhật gradient để tối thiểu hóa thời gian chờ khi truyền thông inter-device xảy ra.

Với cơ sở hạ tầng này trong tầm tay, chúng tôi hiện làm việc trên việc mở rộng các thí nghiệm đến các mô hình đa ngôn ngữ cao mà chúng tôi có thể huấn luyện trên các cụm hiệu năng cao lớn với phân phối rộng các thành phần trên các node tính toán và dữ liệu huấn luyện song song quy mô lớn. Chúng tôi nhắm đến một phạm vi ngôn ngữ lớn và cũng sẽ phát hành mô hình với các thành phần riêng biệt có thể được tải riêng lẻ để suy luận hiệu quả và fine-tuning hoặc kiểm tra downstream thêm.

5.2 Knowledge Distillation
Dịch máy yêu cầu tối ưu hóa về tốc độ và kích thước để có sẵn trong các giải pháp thực tế và trên nhiều thiết bị khác nhau. Các mô hình OPUS-MT đã nhỏ gọn và nhanh so với các mô hình ngôn ngữ đa ngôn ngữ ngày càng phát triển thường được đề cập trong công việc NLP gần đây. Tuy nhiên, có nhiều cách khác nhau để cải thiện thêm tốc độ giải mã trong khi giảm yêu cầu tài nguyên. Knowledge distillation [53] là một trong những kỹ thuật phổ biến giảm các kiến trúc thần kinh phức tạp (được sử dụng như một mô hình teacher gọi là) thành các mô hình student compact, thu được thông tin thiết yếu từ việc tổng quát hóa mà mô hình teacher đã học trước đó trong một quá trình học tập thường rất tốn kém và mất thời gian.

Chúng tôi sử dụng sequence-level knowledge distillation [54], trong đó một mô hình teacher cung cấp các bản dịch hoàn chỉnh của một số dữ liệu huấn luyện, và mô hình student học tác vụ trên đầu ra đó thay vì các bản dịch tham chiếu gốc. Để đơn giản, chúng tôi "forward-translate" dữ liệu huấn luyện với mô hình teacher sử dụng tìm kiếm beam có độ rộng hẹp và chỉ sử dụng bản dịch tốt nhất để dạy student. Hiện tại, chúng tôi cũng không áp dụng các phương pháp ensemble, có thể đẩy chất lượng đầu ra của teacher xa hơn một chút. Tuy nhiên, chúng tôi áp dụng lọc cross-entropy chuẩn hóa [55] để loại bỏ một số tiếng ồn dịch thuật sử dụng mô hình dịch thuật ngược để đánh giá các bản dịch thu được bởi mô hình teacher. Điểm này cho biết mức độ "hallucination", tức là bản dịch lệch khỏi đầu vào gốc như thế nào theo nghĩa rằng nó không thể được tái tạo đáng tin cậy từ bản dịch được tạo ra bởi hệ thống. Theo công việc liên quan, chúng tôi giữ lại 95% dữ liệu đã được sắp xếp theo điểm đó.

Trong các thí nghiệm hiện tại của chúng tôi, chúng tôi nhìn vào các kiến trúc mạng khác nhau để nghiên cứu tác động của chưng cất. Đặc biệt, chúng tôi sử dụng một mô hình transformer cơ sở với 6 lớp trong decoder và sau đó giảm decoder từ mô hình transformer 6 lớp xuống một biến thể dựa trên RNN sử dụng các đơn vị hồi quy đơn giản (SSRU) [56] với hai lớp xếp chồng (từ nay gọi là "small"). Theo công việc trước đó [55], chúng tôi cũng kiểm tra việc giảm kích thước embedding xuống 256 chiều (từ 512 trong thiết lập mặc định) và thử hai biến thể khác nhau ("tiny" và "tiny11") khác nhau về kích thước tham số mạng feed-forward transformer (1,536 trong "tiny11" thay vì 2,048 mặc định trong "tiny") và kích thước của encoder (3 lớp trong "tiny" thay vì 6).

Một sự sụt giảm hiệu suất có thể được mong đợi khi giảm mạng và kích thước tham số của mô hình. Tuy nhiên, các mô hình student được biết là phục hồi tốt từ dung lượng giảm và do đó, tạo ra các thay thế hiệu quả cho các mô hình tốn kém hơn. Hình 15 cho thấy kết quả của chúng tôi về điểm BLEU cho MT tiếng Phần Lan–Anh cho các mô hình khác nhau mà chúng tôi đã thử so với các mô hình tiêu chuẩn không chưng cất tương ứng. Chúng ta có thể thấy rằng trong tất cả các trường hợp, mô hình thường xuyên có kích thước tương ứng được vượt qua bởi student được chưng cất từ mô hình teacher lớn hơn và, đặc biệt quan trọng, các mô hình student nhỏ hơn phục hồi đáng kể từ sự sụt giảm hiệu suất mà chúng ta thấy với dung lượng mô hình giảm trong huấn luyện thường xuyên từ đầu. Đặc biệt, các student nhỏ đạt được hiệu suất ít nhiều giống như mô hình teacher lớn hơn nhiều, đây là một thành tựu đáng chú ý.

Tác động của việc giảm mô hình có thể được thấy về mặt kích thước và tốc độ giải mã. Bảng 2 tóm tắt các thuộc tính và benchmark trên tập kiểm tra Tatoeba với 10.000 câu và hơn 48.000 từ cho các mô hình tiếng Phần Lan–Anh được thảo luận ở trên. Yêu cầu không gian giảm mạnh và mô hình nhỏ nhất chỉ khoảng 23 MB về kích thước, khoảng 10% của mô hình transformer lớn chúng tôi sử dụng làm teacher (mỗi cái 12 lớp trong encoder và decoder). Chúng tôi cũng thấy tầm quan trọng của quantization (sử dụng số nguyên 8-bit, int8, trong trường hợp này). Một cải tiến đáng kể khác có thể được thấy trong tốc độ giải mã: Mô hình nhỏ nhất có thể giải mã toàn bộ tập kiểm tra trong ít hơn 10 giây trên một máy CPU 4-core, tăng tốc độ hơn hệ số 4 so với

--- TRANG 24 ---
Mẫu LaTeX Springer Nature 2021
24 Dân chủ hóa Dịch máy Thần kinh với OPUS-MT
Hình 14 Sơ đồ của mô hình multilingual attention-bridge được sử dụng trong một ví dụ đơn giản. Trong ví dụ này, chúng tôi sử dụng 7 cặp ngôn ngữ và 2 GPU để minh họa hiệu quả của việc gán các cặp ngôn ngữ trong các GPU khác nhau để giảm truyền thông inter-device.

mô hình transformer cơ sở. Các lexical shortlist bổ sung, được biên dịch từ 100 token được căn chỉnh hàng đầu trên dữ liệu huấn luyện, làm cho có thể đẩy thời gian xuống khoảng 6 giây.

Với những mức hiệu suất và kích thước này, chúng tôi có thể đủ khả năng dịch thuật thời gian thực trên các thiết bị thường xuyên và thậm chí nhỏ. Các giải pháp MT dựa trên trình duyệt và ứng dụng desktop cục bộ được thảo luận trong Phần 3.3 trở thành các giải pháp khả thi với các mô hình student đã được chưng cất tối ưu hóa cao như vậy và các mô hình tương thích với các hệ thống dựa trên Bergamot và có thể được áp dụng ngay lập tức trong các ứng dụng dựa trên dự án đó (xem, ví dụ https://translatelocally.com/web/).

6 Công việc Liên quan
OPUS và OPUS-MT chắc chắn không đơn độc trong nhiệm vụ dịch máy mở và minh bạch. Nhiều dự án và sáng kiến đã được tạo ra trong những năm qua và liệt kê tất cả chúng vượt quá phạm vi của phần này. Một trong những vấn đề với công việc liên quan đến dự án là quan điểm dài hạn và việc tạo ra các nền tảng bền vững với sự tiếp tục rõ ràng.

Trong thời đại dịch máy thống kê, nhiều dự án đã liên quan đến framework của Moses,69 dẫn đến một cơ sở hạ tầng phong phú của tài nguyên và công cụ. Các dự án cần được đề cập bao gồm EuroMatrix, EuroMatrixPlus,70 TC-STAR,71 LetsMT!72 và MateCAT.73

Một cơ sở hạ tầng lâu dài khác từ paradigm của dịch máy dựa trên quy tắc được kết nối với Apertium.74 So với hầu hết các phát triển được thúc đẩy bởi các dự án EU thường dẫn đến khai thác thương mại, việc phát triển Apertium luôn nhấn mạnh vị trí của nó như một nền tảng dịch thuật mã nguồn mở và miễn phí. Theo nghĩa đó, đây là công việc liên quan nhất đến OPUS-MT, nhưng với trọng tâm vào một phương pháp dịch thuật khác và lịch sử dài hơn nhiều.

OPUS và OPUS-MT xây dựng trên đỉnh nhiều nỗ lực mã nguồn mở và chia sẻ dữ liệu khác. Các dự án nghiên cứu được tài trợ bởi EU và phát triển tài nguyên hỗ trợ việc tạo ra tài nguyên và công cụ trong các dự án như ParaCrawl,75 GoURMET76, MT4ALL77 và MaCoCu.78

Các nền tảng phần mềm mở cũng rất cần thiết cho dự án của chúng tôi và việc phát triển nhanh chóng của MT thần kinh không thể thực hiện được nếu không có các gói phần mềm như OpenNMT79 và Marian-NMT,80 để chỉ ra hai trong số chúng có liên quan đến dự án của chúng tôi. Hiệu quả dịch thuật là trọng tâm trong dự án Bergamot,81 và công việc tiếp tục trong dự án HPLT,82 có mối liên hệ chặt chẽ với OPUS và OPUS-MT.

Phạm vi ngôn ngữ trong NLP và tính bao gồm cũng được giải quyết bởi nhiều sáng kiến khu vực và quốc tế khác nhau. Masakhane,83 ví dụ, là một tổ chức cơ sở cho NLP châu Phi, bao gồm công việc chuyên dụng về phát triển tài nguyên và công cụ để dịch các ngôn ngữ châu Phi. Từ quan điểm Bắc Âu, người ta có thể đề cập đến Giellatekno,84 với trọng tâm của họ vào công nghệ ngôn ngữ Sami. EU cũng cố gắng thúc đẩy chia sẻ dữ liệu và xây dựng tài nguyên toàn diện hơn với European Language Resource Coordination (ELRC)85 và chiến lược kỹ thuật số của họ về việc tạo ra các không gian dữ liệu có thể tiếp cận. Các kho tài nguyên như Meta-Share86 đã được phát triển và lấp đầy với thông tin, liên kết và metadata, và các cơ sở hạ tầng tài nguyên như CLARIN87 đóng vai trò quan trọng trong việc điều phối những nỗ lực như vậy.

Một đẩy mạnh khác cho dịch máy mở chắc chắn cũng đến từ các phòng thí nghiệm nghiên cứu thương mại và các startup NLP. Nghiên cứu tại các công ty công nghệ lớn hỗ trợ việc phát triển các nền tảng như fairseq,88 tensor2tensor89 và Sockeye.90 Các tài nguyên đa ngôn ngữ quan trọng như WikiMatrix và CCMatrix có nguồn gốc từ những phòng thí nghiệm đó và tiến vào OPUS. Dự án No Language Left Behind91 cùng với các benchmark mở rộng92 thúc đẩy thêm ranh giới của dịch máy đa ngôn ngữ. Một điểm trung tâm khác cho nghiên cứu NLP ngày nay là Hugging Face cùng với thư viện transformers phổ biến của họ và bộ sưu tập ngày càng phát triển của các tập dữ liệu93 và mô hình.94 Sự sẵn có của tất cả tài nguyên trong một hub làm cho việc bắt đầu với nghiên cứu NLP trở nên dễ dàng và đơn giản.

Một sáng kiến gần đây khác cần được đề cập liên quan đến dịch máy là LibreTranslate.95 Những nỗ lực của họ rất phù hợp với OPUS và OPUS-MT, và chúng tôi sẽ khám phá các khả năng hợp tác trong công việc tương lai để tham gia những sáng kiến mã nguồn mở tuyệt vời của họ và những sáng kiến khác xuất hiện trong NLP hiện đại.

7 Kết luận
Bài báo này cung cấp cái nhìn tổng quan về OPUS-MT và việc nhúng nó vào hệ sinh thái OPUS. Chúng tôi mô tả các thành phần khác nhau tạo điều kiện cho việc curation dữ liệu, phát triển mô hình và tích hợp dịch máy vào nhiều nền tảng và ứng dụng khác nhau. Sáng kiến của chúng tôi nhấn mạnh phạm vi ngôn ngữ lớn và tập trung vào các tài nguyên công cộng và giải pháp mã nguồn mở để tạo ra một hỗ trợ minh bạch và có thể áp dụng rộng rãi cho dịch máy.

Những nỗ lực của OPUS-MT đã tạo ra một số lượng lớn các mô hình NMT chất lượng cao đã được pre-train sẵn sàng để được sử dụng và thích ứng với nhiều nhu cầu khác nhau trong nghiên cứu và phát triển ứng dụng thực tế. Với điều này, dự án hỗ trợ một cơ sở hạ tầng bền vững cho phép tái sử dụng các thành phần tốn kém về mặt tính toán. Việc cho phép truy cập vào toàn bộ đầu ra của dự án của chúng tôi cho phép chúng tôi làm cho dịch máy hiệu quả có sẵn cho một loạt người dùng và nhà phát triển NLP, mà không cần cơ sở hạ tầng CNTT hiệu năng cao để huấn luyện các mô hình thần kinh phức tạp từ đầu. Việc dân chủ hóa MT theo cách này là một bước quan trọng theo hướng của một xã hội thông tin bao gồm nơi rào cản ngôn ngữ không dẫn đến bất lợi đáng kể. OPUS-MT đóng góp vào sứ mệnh này với sáng kiến mã nguồn mở dựa trên cộng đồng của nó.

Kế hoạch tương lai của chúng tôi bao gồm việc phát triển các giải pháp thực tế cho NMT mô-đun trong một thiết lập đa ngôn ngữ cao và những tiến bộ thêm trong học chuyển giao và hiệu quả mô hình. Chúng tôi cũng tiếp tục những nỗ lực của mình trong việc thu thập và curation dữ liệu và nhắm đến việc tăng thêm hỗ trợ và phạm vi ngôn ngữ. Hơn nữa, chúng tôi cũng muốn bao gồm các mô hình dịch thuật mức đoạn văn hoặc tài liệu trong OPUS-MT và tích hợp các tiến bộ khác có thể được đẩy vào các giải pháp sẵn sàng production.

Lời cảm ơn
Nghiên cứu được trình bày trong bài báo này được hỗ trợ bởi dự án FoTran, được tài trợ bởi European Research Council (ERC) dưới chương trình nghiên cứu và đổi mới Horizon 2020 của Liên minh Châu Âu (thỏa thuận tài trợ số 771113), dự án European Language Grid thông qua lời gọi mở cho các dự án thí điểm với tài trợ từ chương trình Nghiên cứu và Đổi mới Horizon 2020 của Liên minh Châu Âu dưới thỏa thuận tài trợ số 825627 (ELG) và Quỹ Văn hóa Thụy Điển (Svenska Kulturfonden) ở Phần Lan dưới thỏa thuận tài trợ số 139592. Hỗ trợ liên tục được cung cấp bởi dự án EU Horizon HPLT (thỏa thuận tài trợ số 101070350) và GreenNLP được tài trợ bởi Academy of Finland (ID dự án 353164). Công việc cũng được hỗ trợ bởi NVIDIA AI Technology Center (NVAITC) và chúng tôi muốn cảm ơn NVIDIA cho các tài trợ phần cứng cung cấp thẻ GPU để nghiên cứu và phát triển. Cuối cùng, chúng tôi muốn thừa nhận sự hỗ trợ tuyệt vời của CSC, Trung tâm CNTT Phần Lan dành cho Khoa học Ltd., cung cấp các cơ sở tính toán và lưu trữ mở rộng được sử dụng trong nghiên cứu này và tất cả các dự án liên quan đến nó.

69http://www2.statmt.org/moses/
70https://www.euromatrixplus.net/
71http://www.tcstar.org/
72http://project.letsmt.eu/
73https://www.matecat.com/
74https://www.apertium.org/
75https://www.paracrawl.eu/
76https://gourmet-project.eu/
77http://ixa2.si.ehu.eus/mt4all/project.html
78https://macocu.eu/
79https://opennmt.net/
80https://marian-nmt.github.io/
81https://browser.mt/
82https://hplt-project.org/
83https://www.masakhane.io/
84https://giellatekno.uit.no
85https://lr-coordination.eu/
86http://www.meta-share.org/
87https://www.clarin.eu/
88https://github.com/facebookresearch/fairseq
89https://github.com/tensorflow/tensor2tensor
90https://github.com/awslabs/sockeye
91https://ai.facebook.com/research/no-language-left-behind/
92https://github.com/facebookresearch/flores
93https://huggingface.co/datasets
94https://huggingface.co/models
95https://libretranslate.com/

--- TRANG 25 ---
Mẫu LaTeX Springer Nature 2021
Dân chủ hóa Dịch máy Thần kinh với OPUS-MT 25
Hình 15 So sánh các mô hình NMT thường xuyên (được gắn nhãn là OPUS-MT) với các mô hình student được chưng cất tạo ra thông qua sequence-level knowledge distillation cho các mô hình MT tiếng Phần Lan–Anh của nhiều kích thước khác nhau. Tất cả các mô hình đã được chưng cất sử dụng cùng một mô hình teacher (transformer-big, thanh cuối cùng trong mỗi nhóm) và các mô hình thường xuyên được huấn luyện từ đầu với cùng kiến trúc như các mô hình student tương ứng. Các năm trong trục X đề cập đến các tập kiểm tra tin tức khác nhau từ WMT và các điểm đề cập đến điểm BLEU.

Bảng 2 So sánh các mô hình khác nhau để dịch từ tiếng Phần Lan sang tiếng Anh. Tốc độ giải mã được đo trên tập kiểm tra Tatoeba với 10.000 câu bao gồm khoảng 48.000 từ. Tên mô hình đề cập đến cùng thiết lập như trong Hình 15. Kích thước mô hình đề cập đến kích thước tệp được gzip (có và không có quantization mô hình). Giải mã được thực hiện trên một node CPU với 4 core có và không có lexical shortlist (xem Phần 3.3.3).

mô hình | kích thước mô hình nén | tốc độ giải mã
---|---|---
 | gốc | đã định lượng | 4 CPU | +shortlist
big | 891 MB | 224 MB | | 
base | 294 MB | 74 MB | 46.36s | 40.47s
small | 226 MB | 57 MB | 24.07s | 17.89s
tiny11 | 96 MB | 25 MB | 10.98s | 7.24s
tiny | 89 MB | 23 MB | 9.90s | 6.22s

Tài liệu tham khảo
[1] Tiedemann, J., Nygaard, L.: Kho ngữ liệu OPUS - song song và miễn phí: http://logos.uio.no/opus. Trong: Proceedings of the Fourth International Conference on Language Resources and Evaluation (LREC'04), pp. 1183–1186. European Language Resources Association (ELRA), Lisbon, Portugal (2004). http://www.lrec-conf.org/proceedings/lrec2004/pdf/320.pdf

[2] Tiedemann, J., Thottingal, S.: OPUS-MT – xây dựng dịch vụ dịch thuật mở cho thế giới. Trong: Proceedings of the 22nd Annual Conference of the European Association for Machine Translation, pp. 479–480. European Association for Machine Translation, Lisboa, Portugal (2020). https://aclanthology.org/2020.eamt-1.61

[3] Tiedemann, J.: Tin tức từ OPUS - một bộ sưu tập kho ngữ liệu song song đa ngôn ngữ với công cụ và giao diện. Recent Advances in Natural Language Processing V, 237–248 (2009)

[4] Tiedemann, J.: Dữ liệu song song, công cụ và giao diện trong OPUS. Trong: Proceedings of the Eighth International Conference on Language Resources and Evaluation (LREC'12), pp. 2214–2218. European Language Resources Association (ELRA), Istanbul, Turkey (2012). http://www.lrec-conf.org/proceedings/lrec2012/pdf/463_Paper.pdf

[5] Zipf, G.K.: Các Nghiên cứu được Chọn về Nguyên tắc Tần suất Tương đối trong Ngôn ngữ. Harvard University Press, Cambridge, MA và London, England (1932). https://doi.org/10.4159/harvard.9780674434929

[6] Koehn, P., Hoang, H., Birch, A., Callison-Burch, C., Federico, M., Bertoldi, N., Cowan, B., Shen, W., Moran, C., Zens, R., Dyer, C., Bojar, O., Constantin, A., Herbst, E.: Moses: Bộ công cụ mã nguồn mở cho dịch máy thống kê. Trong: Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics Companion Volume Proceedings of the Demo and Poster Sessions, pp. 177–180. Association for Computational Linguistics, Prague, Czech Republic (2007). https://aclanthology.org/P07-2045

[7] Aulamo, M., Sulubacak, U., Virpioja, S., Tiedemann, J.: OpusTools và chẩn đoán kho ngữ liệu song song. Trong: Proceedings of the 12th Language Resources and Evaluation Conference, pp. 3782–3789. European Language Resources Association, Marseille, France (2020). https://aclanthology.org/2020.lrec-1.467

[8] Lui, M., Baldwin, T.: langid.py: Một công cụ nhận dạng ngôn ngữ có sẵn. Trong: Proceedings of the ACL 2012 System Demonstrations, pp. 25–30. Association for Computational Linguistics, Jeju Island, Korea (2012). https://aclanthology.org/P12-3005

[9] Aulamo, M., Virpioja, S., Tiedemann, J.: OpusFilter: Một hộp công cụ lọc kho ngữ liệu song song có thể cấu hình. Trong: Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations, pp. 150–156. Association for Computational Linguistics, Online (2020). https://aclanthology.org/2020.acl-demos.20

[10] Sánchez-Cartagena, V.M., Bañón, M., Ortiz-Rojas, S., Ramírez, G.: Bài nộp của Prompsit cho tác vụ lọc kho ngữ liệu song song WMT 2018. Trong: Proceedings of the Third Conference on Machine Translation: Shared Task Papers, pp. 955–962. Association for Computational Linguistics, Belgium, Brussels (2018). https://aclanthology.org/W18-6488

[11] Xu, H., Koehn, P.: Zipporah: một hệ thống làm sạch dữ liệu nhanh và có thể mở rộng cho các kho ngữ liệu song song nhiễu được thu thập từ web. Trong: Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pp. 2945–2950. Association for Computational Linguistics, Copenhagen, Denmark (2017). https://www.aclweb.org/anthology/D17-1319

[12] Marie, B., Fujita, A., Rubino, R.: Độ tin cậy khoa học của nghiên cứu dịch máy: Một meta-đánh giá của 769 bài báo. Trong: Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pp. 7297–7306. Association for Computational Linguistics, Online (2021). https://aclanthology.org/2021.acl-long.566

[13] Sennrich, R., Haddow, B., Birch, A.: Dịch máy thần kinh của các từ hiếm với các đơn vị subword. Trong: Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 1715–1725. Association for Computational Linguistics, Berlin, Germany (2016). https://aclanthology.org/P16-1162

[14] Virpioja, S., Smit, P., Grönroos, S.-A., Kurimo, M.: Morfessor 2.0: Triển khai Python và phần mở rộng cho Morfessor Baseline. Báo cáo 25/2013 trong chuỗi xuất bản Đại học Aalto SCIENCE + TECHNOLOGY, Department of Signal Processing and Acoustics, Aalto University, Helsinki, Finland (2013)

[15] Joulin, A., Grave, E., Bojanowski, P., Douze, M., Jégou, H., Mikolov, T.: FastText.zip: Nén các mô hình phân loại văn bản. arXiv (2016). https://arxiv.org/abs/1612.03651

[16] Joulin, A., Grave, E., Bojanowski, P., Mikolov, T.: Túi thủ thuật để phân loại văn bản hiệu quả. Trong: Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 2, Short Papers, pp. 427–431. Association for Computational Linguistics, Valencia, Spain (2017). https://aclanthology.org/E17-2068

[17] Siivola, V., Hirsimäki, T., Virpioja, S.: Về việc phát triển và cắt tỉa các mô hình n-gram được làm mượt Kneser-Ney. IEEE Transactions on Audio, Speech and Language Processing 15(5), 1617–1624 (2007)

[18] Östling, R., Tiedemann, J.: Căn chỉnh từ hiệu quả với Markov Chain Monte Carlo. The Prague Bulletin of Mathematical Linguistics 106, 125–146 (2016)

[19] Artetxe, M., Schwenk, H.: Khai thác kho ngữ liệu song song dựa trên margin với embedding câu đa ngôn ngữ. Trong: Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pp. 3197–3203. Association for Computational Linguistics, Florence, Italy (2019). https://aclanthology.org/P19-1309

[20] Vázquez, R., Sulubacak, U., Tiedemann, J.: Bài nộp của Đại học Helsinki cho tác vụ lọc kho ngữ liệu song song WMT19. Trong: Proceedings of the Fourth Conference on Machine Translation (Volume 3: Shared Task Papers, Day 2), pp. 294–300. Association for Computational Linguistics, Florence, Italy (2019). https://aclanthology.org/W19-5441

[21] Tiedemann, J.: Thách thức dịch thuật Tatoeba – các tập dữ liệu thực tế cho MT tài nguyên thấp và đa ngôn ngữ. Trong: Proceedings of the Fifth Conference on Machine Translation, pp. 1174–1182. Association for Computational Linguistics, Online (2020). https://aclanthology.org/2020.wmt-1.139

[22] Junczys-Dowmunt, M., Grundkiewicz, R., Dwojak, T., Hoang, H., Heafield, K., Neckermann, T., Seide, F., Germann, U., Fikri Aji, A., Bogoychev, N., Martins, A.F.T., Birch, A.: Marian: Dịch máy thần kinh nhanh trong C++. Trong: Proceedings of ACL 2018, System Demonstrations, pp. 116–121. Association for Computational Linguistics, Melbourne, Australia (2018). http://www.aclweb.org/anthology/P18-4020

[23] Kudo, T., Richardson, J.: SentencePiece: Một tokenizer và detokenizer subword đơn giản và độc lập ngôn ngữ cho xử lý văn bản thần kinh. Trong: Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, pp. 66–71. Association for Computational Linguistics, Brussels, Belgium (2018). https://aclanthology.org/D18-2012

[24] Dou, Z.-Y., Neubig, G.: Căn chỉnh từ bằng cách fine-tune embedding trên các kho ngữ liệu song song. Trong: Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, pp. 2112–2128. Association for Computational Linguistics, Online (2021). https://aclanthology.org/2021.eacl-main.181

[25] Arivazhagan, N., Bapna, A., Firat, O., Lepikhin, D., Johnson, M., Krikun, M., Chen, M.X., Cao, Y., Foster, G., Cherry, C., Macherey, W., Chen, Z., Wu, Y.: Dịch máy Thần kinh Đa ngôn ngữ Quy mô lớn trong Tự nhiên: Những phát hiện và Thách thức. arXiv (2019). https://arxiv.org/abs/1907.05019

[26] Sennrich, R., Haddow, B., Birch, A.: Cải thiện các mô hình dịch máy thần kinh với dữ liệu đơn ngữ. Trong: Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 86–96. Association for Computational Linguistics, Berlin, Germany (2016). https://aclanthology.org/P16-1009

[27] Hoang, V.C.D., Koehn, P., Haffari, G., Cohn, T.: Dịch ngược lặp đi lặp lại cho dịch máy thần kinh. Trong: Proceedings of the 2nd Workshop on Neural Machine Translation and Generation, pp. 18–24. Association for Computational Linguistics, Melbourne, Australia (2018). https://aclanthology.org/W18-2703

[28] Kudo, T.: Chuẩn hóa subword: Cải thiện các mô hình dịch thuật mạng thần kinh với nhiều ứng viên subword. Trong: Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 66–75. Association for Computational Linguistics, Melbourne, Australia (2018). https://aclanthology.org/P18-1007

[29] Läubli, S., Amrhein, C., Düggelin, P., Gonzalez, B., Zwahlen, A., Volk, M.: Năng suất post-editing với dịch máy thần kinh: Một đánh giá thực nghiệm về tốc độ và chất lượng trong lĩnh vực ngân hàng và tài chính. Trong: Proceedings of Machine Translation Summit XVII: Research Track, pp. 267–272. European Association for Machine Translation, Dublin, Ireland (2019). https://aclanthology.org/W19-6626

[30] Macken, L., Prou, D., Tezcan, A.: Định lượng tác động của dịch máy trong một quy trình sản xuất dịch thuật con người chất lượng cao. Informatics 7(2) (2020). https://doi.org/10.3390/informatics7020012

[31] Bergmanis, T., Pinnis, M.: Tạo điều kiện cho dịch thuật thuật ngữ với chú thích lemma đích. Trong: Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, pp. 3105–3111. Association for Computational Linguistics, Online (2021). https://aclanthology.org/2021.eacl-main.271

[32] Goyal, N., Gao, C., Chaudhary, V., Chen, P.-J., Wenzek, G., Ju, D., Krishnan, S., Ranzato, M., Guzmán, F., Fan, A.: Benchmark đánh giá Flores-101 cho dịch máy tài nguyên thấp và đa ngôn ngữ. Transactions of the Association for Computational Linguistics 10, 522–538 (2022). https://doi.org/10.1162/tacl_a_00474

[33] Papineni, K., Roukos, S., Ward, T., Zhu, W.-J.: Bleu: một phương pháp đánh giá tự động dịch máy. Trong: Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, pp. 311–318. Association for Computational Linguistics, Philadelphia, Pennsylvania, USA (2002). https://aclanthology.org/P02-1040

[34] Popović, M.: chrF: điểm F n-gram ký tự cho đánh giá MT tự động. Trong: Proceedings of the Tenth Workshop on Statistical Machine Translation, pp. 392–395. Association for Computational Linguistics, Lisbon, Portugal (2015). https://aclanthology.org/W15-3049

[35] Popović, M.: chrF++: từ giúp n-gram ký tự. Trong: Proceedings of the Second Conference on Machine Translation, pp. 612–618. Association for Computational Linguistics, Copenhagen, Denmark (2017). https://aclanthology.org/W17-4770

[36] Stewart, C., Rei, R., Farinha, C., Lavie, A.: COMET - triển khai một số liệu đánh giá MT tiên tiến mới trong sản xuất. Trong: Proceedings of the 14th Conference of the Association for Machine Translation in the Americas (Volume 2: User Track), pp. 78–109. Association for Machine Translation in the Americas, Virtual (2020). https://aclanthology.org/2020.amta-user.4

[37] Hassan, H., Aue, A., Chen, C., Chowdhary, V., Clark, J., Federmann, C., Huang, X., Junczys-Dowmunt, M., Lewis, W., Li, M., Liu, S., Liu, T.-Y., Luo, R., Menezes, A., Qin, T., Seide, F., Tan, X., Tian, F., Wu, L., Wu, S., Xia, Y., Zhang, D., Zhang, Z., Zhou, M.: Đạt được sự ngang bằng con người trong dịch thuật tin tức tự động từ tiếng Trung sang tiếng Anh. arXiv (2018). https://arxiv.org/abs/1803.05567

[38] Läubli, S., Sennrich, R., Volk, M.: Dịch máy đã đạt được sự ngang bằng con người chưa? một trường hợp cho đánh giá mức tài liệu. Trong: Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pp. 4791–4796. Association for Computational Linguistics, Brussels, Belgium (2018). https://aclanthology.org/D18-1512

[39] Toral, A., Castilho, S., Hu, K., Way, A.: Đạt được điều không thể đạt được? đánh giá lại các tuyên bố về sự ngang bằng con người trong dịch máy thần kinh. Trong: Proceedings of the Third Conference on Machine Translation: Research Papers, pp. 113–123. Association for Computational Linguistics, Brussels, Belgium (2018). https://aclanthology.org/W18-6312

[40] Burchardt, A., Macketanz, V., Dehdari, J., Heigold, G., Peter, J.-T., Williams, P.: Một đánh giá ngôn ngữ học của các engine MT dựa trên quy tắc, dựa trên cụm từ, và thần kinh. The Prague Bulletin of Mathematical Linguistics 108, 159–170 (2017)

[41] Isabelle, P., Cherry, C., Foster, G.: Một phương pháp challenge set để đánh giá dịch máy. Trong: Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pp. 2486–2496. Association for Computational Linguistics, Copenhagen, Denmark (2017). https://aclanthology.org/D17-1263

[42] Raganato, A., Scherrer, Y., Tiedemann, J.: Bộ kiểm tra MuCoW tại WMT 2019: Các tập kiểm tra giải mơ hồ nghĩa từ tương phản đa ngôn ngữ được thu thập tự động cho dịch máy. Trong: Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1), pp. 470–480. Association for Computational Linguistics, Florence, Italy (2019). https://www.aclweb.org/anthology/W19-5354

[43] Raganato, A., Scherrer, Y., Tiedemann, J.: Một benchmark đánh giá để kiểm tra khả năng giải mơ hồ nghĩa từ của các hệ thống dịch máy. Trong: Proceedings of The 12th Language Resources and Evaluation Conference, pp. 3668–3675. European Language Resources Association, Marseille, France (2020). https://www.aclweb.org/anthology/2020.lrec-1.452

[44] Scherrer, Y., Raganato, A., Tiedemann, J.: Bộ kiểm tra giải mơ hồ nghĩa từ MUCOW tại WMT 2020. Trong: Proceedings of the Fifth Conference on Machine Translation, pp. 365–370. Association for Computational Linguistics, Online (2020). https://aclanthology.org/2020.wmt-1.40

[45] Navigli, R., Ponzetto, S.P.: BabelNet: Xây dựng, đánh giá và ứng dụng tự động của một mạng semantic đa ngôn ngữ có phạm vi rộng. Artificial Intelligence 193, 217–250 (2012)

[46] Johnson, M., Schuster, M., Le, Q.V., Krikun, M., Wu, Y., Chen, Z., Thorat, N., Viégas, F., Wattenberg, M., Corrado, G., Hughes, M., Dean, J.: Hệ thống dịch máy thần kinh đa ngôn ngữ của Google: Kích hoạt dịch thuật zero-shot. Transactions of the Association for Computational Linguistics 5, 339–351 (2017). https://doi.org/10.1162/tacl_a_00065

[47] Klein, G., Hernandez, F., Nguyen, V., Senellart, J.: Bộ công cụ dịch máy thần kinh OpenNMT: phiên bản 2020. Trong: Proceedings of the 14th Conference of the Association for Machine Translation in the Americas (Volume 1: Research Track), pp. 102–109. Association for Machine Translation in the Americas, Virtual (2020). https://aclanthology.org/2020.amta-research.9

[48] Dyvik, H.: Dịch thuật như gương semantic: từ kho ngữ liệu song song đến wordnet. Trong: Advances in Corpus Linguistics, Papers from the 23rd International Conference on English Language Research on Computerized Corpora (ICAME), vol. 49, pp. 309–326. Brill, Gothenburg, Sweden (2004). https://doi.org/10.1163/9789004333710_019

[49] Vázquez, R., Raganato, A., Tiedemann, J., Creutz, M.: NMT đa ngôn ngữ với cầu attention độc lập ngôn ngữ. Trong: Proceedings of the 4th Workshop on Representation Learning for NLP (RepL4NLP-2019), pp. 33–39. Association for Computational Linguistics, Florence, Italy (2019). https://aclanthology.org/W19-4305

[50] Vázquez, R., Raganato, A., Creutz, M., Tiedemann, J.: Một nghiên cứu có hệ thống về các representation câu dựa trên inner-attention trong dịch máy thần kinh đa ngôn ngữ. Computational Linguistics 46(2), 387–424 (2020). https://doi.org/10.1162/coli_a_00377

[51] Raganato, A., Vázquez, R., Creutz, M., Tiedemann, J.: Một đánh giá về các representation dựa trên inner-attention agnostic ngôn ngữ trong dịch máy. Trong: Proceedings of the 4th Workshop on Representation Learning for NLP (RepL4NLP-2019), pp. 27–32. Association for Computational Linguistics, Florence, Italy (2019). https://aclanthology.org/W19-4304

[52] Kuhn, H.W.: Phương pháp Hungary cho vấn đề gán. Naval Research Logistics Quarterly 2, 83–97 (1955)

[53] Hinton, G., Vinyals, O., Dean, J.: Chưng cất Kiến thức trong một Mạng Thần kinh. arXiv (2015). https://arxiv.org/abs/1503.02531

[54] Kim, Y., Rush, A.M.: Chưng cất kiến thức cấp sequence. Trong: Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pp. 1317–1327. Association for Computational Linguistics, Austin, Texas (2016). https://aclanthology.org/D16-1139

[55] Behnke, M., Bogoychev, N., Aji, A.F., Heafield, K., Nail, G., Zhu, Q., Tchistiakova, S., van der Linde, J., Chen, P., Kashyap, S., Grundkiewicz, R.: Dịch máy hiệu quả với cắt tỉa và định lượng mô hình. Trong: Proceedings of the Sixth Conference on Machine Translation, pp. 775–780. Association for Computational Linguistics, Online (2021). https://aclanthology.org/2021.wmt-1.74

[56] Kim, Y.J., Junczys-Dowmunt, M., Hassan, H., Fikri Aji, A., Heafield, K., Grundkiewicz, R., Bogoychev, N.: Từ nghiên cứu đến sản xuất và ngược lại: Dịch máy thần kinh nhanh một cách kỳ lạ. Trong: Proceedings of the 3rd Workshop on Neural Generation and Translation, pp. 280–288. Association for Computational Linguistics, Hong Kong (2019). https://aclanthology.org/D19-5632

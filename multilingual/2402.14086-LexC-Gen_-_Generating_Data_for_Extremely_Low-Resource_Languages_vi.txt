# LexC-Gen: Tạo Dữ liệu cho các Ngôn ngữ có Tài nguyên Cực kỳ Thấp bằng Mô hình Ngôn ngữ Lớn và Từ điển Song ngữ

Zheng-Xin Yong¹, Cristina Menghini², Stephen H. Bach¹
¹Khoa Khoa học Máy tính, Đại học Brown
²Viện Khoa học Dữ liệu, Đại học Brown
{contact.yong,cristina_menghini,stephen_bach}@brown.edu

## Tóm tắt

Tình trạng khan hiếm dữ liệu trong các ngôn ngữ ít tài nguyên có thể được giải quyết bằng cách dịch từ sang từ từ dữ liệu tác vụ được gán nhãn trong các ngôn ngữ có nhiều tài nguyên sử dụng từ điển song ngữ. Tuy nhiên, từ điển song ngữ thường có sự chồng lấp từ vựng hạn chế với dữ liệu tác vụ, dẫn đến độ bao phủ dịch thuật kém và tỷ lệ sử dụng từ điển thấp. Chúng tôi đề xuất tạo dữ liệu có điều kiện từ điển (LexC-Gen), một phương pháp tạo dữ liệu tác vụ phân loại ngôn ngữ ít tài nguyên ở quy mô lớn. Cụ thể, LexC-Gen đầu tiên sử dụng các từ ngôn ngữ có nhiều tài nguyên từ từ điển song ngữ để tạo dữ liệu tác vụ tương thích với từ điển, sau đó dịch chúng sang ngôn ngữ ít tài nguyên bằng từ điển song ngữ thông qua dịch từ. Trên 17 ngôn ngữ có tài nguyên cực kỳ thấp, dữ liệu được tạo bởi LexC-Gen có khả năng cạnh tranh với dữ liệu vàng được dịch bởi chuyên gia, và mang lại cải thiện trung bình 5.6 và 8.9 điểm so với các phương pháp dịch từ dựa trên từ điển hiện có đối với các tác vụ phân tích cảm xúc và phân loại chủ đề tương ứng. Thông qua nghiên cứu loại bỏ thành phần, chúng tôi cho thấy việc điều kiện hóa trên từ điển song ngữ là thành phần chính của LexC-Gen. LexC-Gen phục vụ như một giải pháp tiềm năng để thu hẹp khoảng cách hiệu suất giữa các mô hình đa ngôn ngữ nguồn mở như BLOOMZ và các mô hình thương mại tiên tiến như GPT-4o đối với các tác vụ ngôn ngữ ít tài nguyên.

## 1 Giới thiệu

Các ngôn ngữ có tài nguyên cực kỳ thấp không có bất kỳ dữ liệu được gán nhãn nào và do đó được coi là "Những kẻ bị bỏ lại phía sau" trong phát triển công nghệ ngôn ngữ NLP (Joshi et al., 2020; Mabokela et al., 2022; Robinson et al., 2023). Tuy nhiên, nhiều trong số chúng có tài nguyên từ điển song ngữ, thường là sản phẩm đầu tiên của việc ghi chép ngôn ngữ (Meara, 1993; Schreuder và Weltens, 1993; Kroll và Ma, 2017). Từ điển song ngữ là những từ điển ánh xạ các từ từ một ngôn ngữ sang bản dịch của chúng trong ngôn ngữ khác, và chúng bao phủ hơn 5000 ngôn ngữ trên khắp thế giới (Wang et al., 2022; Koto et al., 2024).

Các nghiên cứu trước đây sử dụng từ điển song ngữ để dịch trực tiếp dữ liệu được gán nhãn từ ngôn ngữ có nhiều tài nguyên sang ngôn ngữ ít tài nguyên thông qua việc thay thế từ với từ (Wang et al., 2022; Jones et al., 2023, và những nghiên cứu khác). Tuy nhiên, chúng tôi cho rằng điều này không hiệu quả vì sự không khớp dữ liệu-từ điển. Thường thì, các từ trong dữ liệu tác vụ hiện có - dữ liệu được gán nhãn có sẵn trong các ngôn ngữ có nhiều tài nguyên cho một tác vụ mục tiêu, ví dụ: phân tích cảm xúc hoặc phân loại chủ đề - có sự chồng lấp từ vựng thấp với các từ trong từ điển song ngữ bất khả tri tác vụ, như được thể hiện trong Hình 1. Sự không khớp này không chỉ dẫn đến nhiều từ vẫn chưa được dịch, mà còn gây ra việc các mục trong từ điển song ngữ, có thể chứa thông tin ngữ nghĩa hữu ích cho các tác vụ hạ nguồn, bị thiếu trong tập dữ liệu đã dịch.

Trong nghiên cứu này, chúng tôi giới thiệu LexC-Gen¹, một phương pháp tạo dữ liệu có điều kiện từ điển, để giảm thiểu sự không khớp dữ liệu-từ điển thông qua tạo dữ liệu tổng hợp. Cụ thể, chúng tôi huấn luyện các LLM để tạo dữ liệu tác vụ sử dụng các từ từ từ điển song ngữ, do đó dữ liệu có sự chồng lấp từ vựng cao hơn với từ điển. Điều này dẫn đến độ bao phủ dịch từ tốt hơn và tỷ lệ sử dụng từ điển cao hơn (Hình 1). Chúng tôi cũng đề xuất một phương pháp kiểm soát chất lượng kiểm tra tính nhất quán đầu vào-nhãn để lọc ra dữ liệu được tạo có chất lượng kém.

Chúng tôi đánh giá LexC-Gen trên 17 ngôn ngữ có tài nguyên cực kỳ thấp đối với các tác vụ phân tích cảm xúc và phân loại chủ đề. Chúng tôi phát hiện rằng việc tinh chỉnh các bộ phân loại trên dữ liệu được tạo bởi LexC-Gen cải thiện trung bình 5.6 và 8.9 điểm độ chính xác tương ứng so với dữ liệu huấn luyện hiện có được dịch từ (Wang et al., 2022). Đáng ngạc nhiên, việc tinh chỉnh trên dữ liệu được dịch từ LexC-Gen thậm chí còn phù hợp với hiệu suất tinh chỉnh trên dữ liệu vàng trong ngôn ngữ đích được tuyển chọn bởi người bản ngữ hoặc dịch giả chuyên nghiệp. Chúng tôi cho thấy điều kiện hóa từ điển là yếu tố thành công quan trọng của LexC-Gen.

Cuối cùng, chúng tôi thảo luận về cách LexC-Gen giúp thu hẹp khoảng cách hiệu suất của các LLM nguồn mở trong các tác vụ ngôn ngữ ít tài nguyên. Chúng tôi cho thấy rằng thay vì gợi ý zero-shot hoặc few-shot, tốt hơn là sử dụng chúng để tạo dữ liệu huấn luyện với LexC-Gen. Quá trình tạo dữ liệu có hiệu quả chi phí cao, và bản chất cho phép của các mô hình cho phép dữ liệu được tạo được công khai cho nghiên cứu thêm và xây dựng hệ thống cho các ngôn ngữ có tài nguyên cực kỳ thấp, điều này có lợi cho tiến bộ NLP đa ngôn ngữ cho những ngôn ngữ khan hiếm dữ liệu này.

Đóng góp của chúng tôi có thể được tóm tắt như sau:

1. Chúng tôi trình bày LexC-Gen, một phương pháp điều kiện hóa LLM trên từ điển song ngữ để tạo dữ liệu tác vụ ngôn ngữ ít tài nguyên nhằm giải quyết vấn đề không khớp dữ liệu-từ điển.

2. Chúng tôi chứng minh rằng việc huấn luyện trên dữ liệu tác vụ được dịch từ có thể phù hợp với việc huấn luyện trên dữ liệu vàng cho các ngôn ngữ có tài nguyên cực kỳ thấp.

3. Nghiên cứu loại bỏ thành phần mở rộng của chúng tôi về LexC-Gen cho thấy rằng việc chỉ mở rộng quy mô dữ liệu tác vụ được tạo là không đủ. Điều kiện hóa từ điển là cần thiết để tối đa hóa sự chồng lấp từ vựng giữa dữ liệu tác vụ và từ điển song ngữ.

## 2 Nghiên cứu Liên quan

**Tạo dữ liệu tác vụ với LLM** Tạo dữ liệu được hỗ trợ bởi LLM là một lĩnh vực nghiên cứu đầy hứa hẹn gần đây cho phép thu thập dữ liệu tác vụ đa dạng với chi phí hiệu quả và lao động con người tối thiểu (Honovich et al., 2023; Radharapu et al., 2023; Wang et al., 2023; Nayak et al., 2023; Yehudai et al., 2024). Tuy nhiên, hướng nghiên cứu này vẫn chưa được khám phá đầy đủ trong bối cảnh đa ngôn ngữ. Whitehouse et al. (2023) đã chứng minh rằng dữ liệu huấn luyện đa ngôn ngữ được tạo bởi GPT-4 cho tác vụ lập luận thông thường trong các ngôn ngữ tài nguyên trung bình/cao có thể cải thiện hiệu suất xuyên ngôn ngữ. Tuy nhiên, độ bao phủ ngôn ngữ của LLM và các mô hình dịch thuật nhỏ hơn đáng kể so với từ điển (Wang et al., 2022; Bapna et al., 2022; Koto et al., 2024). Thay vào đó, chúng tôi sử dụng LLM để tạo dữ liệu tác vụ tối đa hóa sự chồng lấp từ vựng với từ điển song ngữ để dịch, và chúng tôi cho thấy rằng dữ liệu tổng hợp của chúng tôi có thể cải thiện hiệu suất tác vụ NLU ngữ nghĩa trong các ngôn ngữ có tài nguyên cực kỳ thấp.

**Tăng cường dữ liệu xuyên ngôn ngữ dựa trên từ điển** Tăng cường dựa trên từ điển tạo dữ liệu cho các ngôn ngữ ít tài nguyên bằng cách hoán đổi các từ trong dữ liệu ngôn ngữ có nhiều tài nguyên với bản dịch từ điển của chúng trong từ điển song ngữ. Điều này hữu ích cho các ngôn ngữ ít tài nguyên không thể được dịch dễ dàng bởi các mô hình/API dịch với độ bao phủ ngôn ngữ hạn chế. Các nghiên cứu trước đây đã chứng minh tính hiệu quả của chúng trên một loạt các tác vụ NLP, như dịch máy (Streiter và Iomdin, 2000; Ramesh và Sankaranarayanan, 2018; Thompson et al., 2019; Kumar et al., 2022; Jones et al., 2023), gán nhãn chuỗi (Scherrer và Sagot, 2013; Mayhew et al., 2017; Wang et al., 2022), phân loại cảm xúc (Rasooli et al., 2018; Ali et al., 2021; Mohammed và Prasad, 2023), và phân loại chủ đề (Song et al., 2019). Tuy nhiên, nhiều chiến lược tăng cường dữ liệu dựa trên từ điển cho các tác vụ ngữ nghĩa trong ngôn ngữ ít tài nguyên dựa vào từ điển đặc thù miền (Das và Bandyopadhyay, 2010; Buechel et al., 2016; Mohammed và Prasad, 2023; Koto et al., 2024), và về mặt hiệu suất chúng vẫn thua kém dữ liệu huấn luyện vàng được thu thập trong ngôn ngữ ít tài nguyên đích (Rasooli et al., 2018; Koto et al., 2024). Phương pháp LexC-Gen của chúng tôi không chỉ hoạt động với từ điển song ngữ bất khả tri miền, mà còn chứng minh hiệu suất cạnh tranh với dữ liệu huấn luyện vàng đối với các tác vụ phân tích cảm xúc và phân loại chủ đề trên nhiều ngôn ngữ ít tài nguyên.

## 3 LexC-Gen

Chúng tôi nhằm mục đích tạo dữ liệu cho các tác vụ phân loại trong ngôn ngữ ít tài nguyên L, với quyền truy cập vào (1) dữ liệu tác vụ được gán nhãn TH với C lớp trong ngôn ngữ có nhiều tài nguyên H, (2) từ điển song ngữ DL H ánh xạ các từ từ H sang L, và (3) một LLM hỗ trợ H.

LexC-Gen sử dụng những đầu vào này để tạo dữ liệu tác vụ được gán nhãn ẽTL trong ngôn ngữ ít tài nguyên. Ý tưởng chính của chúng tôi là gợi ý LLM để tạo dữ liệu tác vụ sử dụng các từ ngôn ngữ có nhiều tài nguyên từ từ điển song ngữ nhằm tạo dữ liệu tác vụ có sự chồng lấp từ vựng cao hơn với những từ điển song ngữ đó (Hình 1a), và do đó có thể được dịch hiệu quả hơn sang L. Trong phần sau, chúng tôi mô tả các bước để có được ẽTL. Để dễ đọc, chúng tôi gọi DL H là D.

### 3.1 Lấy mẫu Từ điển và Nhãn Lớp

Đầu tiên, chúng tôi lấy mẫu ngẫu nhiên một tập hợp WH các từ ngôn ngữ có nhiều tài nguyên wH từ D và một nhãn lớp c. Điều này tương ứng với bước (1) trong Hình 2. Mục tiêu là gợi ý LLM của chúng tôi để tạo đầu vào tác vụ của lớp c sử dụng càng nhiều từ từ WH càng tốt.

### 3.2 Tạo Dữ liệu với LLM được Huấn luyện với Tạo Văn bản Có kiểm soát (CTG)

Tiếp theo, chúng tôi gợi ý một LLM để tạo dữ liệu tác vụ ngôn ngữ có nhiều tài nguyên ẽTH|D có điều kiện trên từ điển song ngữ. Đây là bước (2) trong Hình 2. Tuy nhiên, vì các LLM được điều chỉnh hướng dẫn truy cập mở như BLOOMZ (Muennighoff et al., 2023) không được tinh chỉnh cho mục đích này, chúng tôi thực hiện huấn luyện tạo văn bản có kiểm soát (CTG) của LLM (Zhang et al., 2023; Zhou et al., 2023b) để tạo LLM được huấn luyện CTG.

**Huấn luyện CTG** Chúng tôi xây dựng dữ liệu huấn luyện CTG từ dữ liệu tác vụ hiện có TH. Mỗi thể hiện tH ∈ TH bao gồm một cặp văn bản xH và nhãn tác vụ c. Chúng tôi lấy mẫu ngẫu nhiên một số lượng biến đổi các token từ wH một cách đồng nhất ngẫu nhiên không lặp lại từ xH để tạo WH. Sau đó, chúng tôi định dạng dữ liệu huấn luyện CTG sử dụng mẫu gợi ý trong Hình 3, để LLM học tạo đầu vào tác vụ x̃H|c,WH có điều kiện trên c và WH.

Huấn luyện CTG hiệu quả về dữ liệu. Chúng tôi phát hiện rằng việc tạo chỉ một ví dụ huấn luyện CTG duy nhất cho mỗi tH ∈ TH đã đủ để điều chỉnh hướng dẫn mô hình. Cụ thể, dữ liệu huấn luyện CTG của chúng tôi bao gồm 500 và 701 thể hiện cho các tác vụ phân tích cảm xúc và phân loại chủ đề tương ứng.

**Tạo Dữ liệu Tác vụ** Sau khi huấn luyện CTG, chúng tôi gợi ý LLM sử dụng lại mẫu trong Hình 3, nhưng bây giờ chúng tôi sử dụng các từ từ điển với nhãn lớp tác vụ ngẫu nhiên từ Phần 3.1. Chúng tôi bây giờ có thể tạo dữ liệu tác vụ ngôn ngữ có nhiều tài nguyên tổng hợp ẽTH|D ở quy mô lớn có điều kiện trên từ điển song ngữ.

### 3.3 Bộ lọc Tính nhất quán Đầu vào-Nhãn

Để đảm bảo dữ liệu chất lượng cao, chúng tôi áp dụng bộ lọc tính nhất quán đầu vào-nhãn sau khi tạo dữ liệu để giảm nhiễu huấn luyện từ lỗi gán nhãn. Ví dụ, LLM được huấn luyện CTG có thể tạo một câu với cảm xúc tiêu cực mặc dù nhãn tác vụ đã chỉ định c là cảm xúc tích cực trong gợi ý đầu vào (Hình 3). Do đó, chúng tôi tinh chỉnh một bộ phân loại nhỏ mBERT trên cùng dữ liệu tác vụ hiện có TH và sử dụng nó để gán nhãn lại ẽTH|L. Sau đó, chúng tôi lọc ra tất cả các thể hiện dữ liệu mà dự đoán của bộ phân loại không khớp với các cặp đầu vào-nhãn được tạo.

Tại thời điểm này (bước (3) trong Hình 2), chúng tôi có dữ liệu tác vụ tương thích từ điển chất lượng cao trong ngôn ngữ H cho phép dịch từ sang từ tốt hơn sang ngôn ngữ L bằng cách sử dụng D.

### 3.4 Dịch Từ sang Từ vào Ngôn ngữ Ít Tài nguyên

Cuối cùng, chúng tôi thực hiện dịch từ sang từ theo các quy trình trong các nghiên cứu trước đây (Wang et al., 2022; Jones et al., 2023). Chúng tôi sử dụng D để thay thế các từ ngôn ngữ có nhiều tài nguyên wH ∈ ẽTH|D bằng bản dịch từ ngôn ngữ ít tài nguyên wL của chúng, do đó tạo ra ẽTL. Chúng tôi lấy mẫu ngẫu nhiên wL nếu wH có nhiều bản dịch có thể và giữ wH nguyên trong ẽTH|D nếu không có bản dịch cho nó trong D. Sau khi chúng tôi có được dữ liệu tác vụ xuyên ngôn ngữ tổng hợp ẽTL, chúng tôi sử dụng nó làm dữ liệu huấn luyện để tinh chỉnh một bộ phân loại cho tác vụ đích trong ngôn ngữ ít tài nguyên.

## 4 Thiết lập Thí nghiệm

Chúng tôi so sánh LexC-Gen với các đường cơ sở và bản dịch vàng đối với các tác vụ phân tích cảm xúc và phân loại chủ đề. Chúng tôi mô tả các tập dữ liệu tác vụ trong Phần 4.1, cách chúng tôi khởi tạo LexC-Gen trong Phần 4.2, và các đường cơ sở cũng như bản dịch vàng trong Phần 4.3.

### 4.1 Tác vụ và Tập dữ liệu

Chúng tôi đánh giá LexC-Gen đối với các tác vụ phân tích cảm xúc và phân loại chủ đề trên 17 ngôn ngữ ít tài nguyên. Các tập dữ liệu tác vụ chứa dữ liệu huấn luyện vàng được tuyển chọn với các bản dịch bởi người bản ngữ hoặc dịch giả chuyên nghiệp. Thông tin chi tiết cho các tác vụ và ngôn ngữ có thể được tìm thấy trong Phụ lục B.

**Phân tích cảm xúc** Chúng tôi sử dụng tập dữ liệu phân tích cảm xúc NusaX (Winata et al., 2023b) được phát triển cho các ngôn ngữ ít tài nguyên của Indonesia. Tập dữ liệu có 3 nhãn cảm xúc: tích cực, trung tính và tiêu cực. Trong thiết lập của chúng tôi, chúng tôi đánh giá LexC-Gen trên 7 ngôn ngữ cũng tồn tại trong từ điển Gatitos.

**Phân loại chủ đề** SIB-200 (Adelani et al., 2023) là một benchmark phân loại chủ đề bao phủ 200 ngôn ngữ và 7 danh mục chủ đề. Chúng tôi đánh giá LexC-Gen trên 10 ngôn ngữ có hiệu suất tệ nhất mà chúng tôi phát hiện có khoảng cách hiệu suất lớn nhất giữa bản dịch vàng và đường cơ sở dịch từ (Wang et al., 2022).

### 4.2 Khởi tạo LexC-Gen

**LLM** Chúng tôi sử dụng mô hình BLOOMZ (Muennighoff et al., 2023) với 7.1 tỷ tham số (BLOOMZ-7.1B) làm LLM được điều chỉnh hướng dẫn ban đầu của chúng tôi. Điều này cho phép chúng tôi so sánh hiệu suất giữa gợi ý zero-shot của nó và việc sử dụng nó với LexC-Gen.

**Từ điển song ngữ** Chúng tôi chọn từ điển song ngữ Gatitos (Jones et al., 2023) để dịch dữ liệu tiếng Anh được tạo sang ngôn ngữ ít tài nguyên. Gatitos bao gồm các mục tiếng Anh như từ tiếng Anh thường xuyên, số và thời gian, và chúng được dịch sang 170 ngôn ngữ có tài nguyên cực kỳ thấp. Gatitos đã được xem xét thủ công, do đó các mục của nó có chất lượng cao hơn các từ điển song ngữ khác như Panlex (Kamholz et al., 2014).

**Dữ liệu tác vụ được tạo** Đầu tiên chúng tôi sử dụng LexC-Gen để tạo các tập dữ liệu tiếng Anh với 1K, 10K và 100K thể hiện, mà chúng tôi gọi là LexC-Gen-1K, -10K và -100K, trước khi lọc ra các cặp đầu vào-nhãn không khớp. Kích thước dữ liệu hiệu quả sau khi lọc với kiểm tra tính nhất quán đầu vào-nhãn là từ 20% đến 40% của dữ liệu tác vụ được tạo. Sau đó, chúng tôi sử dụng từ điển Gatitos (Jones et al., 2023) để dịch chúng sang ngôn ngữ ít tài nguyên.

**Huấn luyện và tạo dữ liệu với LLM** Chúng tôi cung cấp thêm chi tiết huấn luyện và suy luận của LexC-Gen trong Phụ lục C. Chúng tôi cũng trình bày các ví dụ về dữ liệu được tạo cho phân tích cảm xúc trong Bảng 3 và cho phân loại chủ đề trong Bảng 6.

**Tinh chỉnh tác vụ** Chúng tôi tinh chỉnh mBERT² được huấn luyện trước với đầu phân loại trên dữ liệu ngôn ngữ ít tài nguyên được tạo bởi LexC-Gen để đánh giá các tác vụ phân tích cảm xúc và phân loại chủ đề (chi tiết thêm trong Phụ lục D).

### 4.3 Đường cơ sở

Chúng tôi so sánh LexC-Gen với (1) gợi ý zero-shot với BLOOMZ-7.1B, Aya-101-13B (Üstün et al., 2024) và GPT-4o³; (2) gợi ý few-shot với Aya-101-13B sử dụng năm ví dụ học trong ngữ cảnh; (3) chuyển giao zero-shot xuyên ngôn ngữ khi mBERT được tinh chỉnh trên dữ liệu huấn luyện tiếng Anh và đánh giá trên dữ liệu thử nghiệm ngôn ngữ ít tài nguyên; (4) dịch từ (Wang et al., 2022) khi mBERT được tinh chỉnh trên dữ liệu được dịch từ dữ liệu huấn luyện tiếng Anh thông qua thay thế từ với cùng từ điển song ngữ Gatitos (Jones et al., 2023); (5) bản dịch vàng khi mBERT được tinh chỉnh trên dữ liệu huấn luyện tác vụ được dịch bởi chuyên gia trong ngôn ngữ ít tài nguyên đích (xem Phần 4.1).

Chúng tôi triển khai đường cơ sở dịch từ bằng cách tham khảo phương pháp tiên tiến (Wang et al., 2022). Ở đây, chúng tôi không điều chỉnh mBERT được huấn luyện trước trước khi tinh chỉnh tác vụ để so sánh công bằng. Chúng tôi tuân theo giao thức của Wang et al. (2022) và báo cáo kết quả khi chúng tôi cũng kết hợp dữ liệu được dịch từ với dữ liệu huấn luyện tiếng Anh ("+ Dữ liệu Tác vụ Hiện có (en)") và thực hiện chưng cất nhãn - một kỹ thuật sử dụng bộ phân loại (mBERT trong trường hợp của chúng tôi) được huấn luyện trên dữ liệu tác vụ hiện có để gán nhãn lại dữ liệu đã dịch.

## 5 Kết quả và Phân tích

### 5.1 LexC-Gen cải thiện so với LLM nguồn mở và dịch từ trực tiếp

LexC-Gen vượt trội hơn việc gợi ý các mô hình nguồn mở, như BLOOMZ và Aya-101, và các đường cơ sở dịch từ trong cả các tác vụ phân tích cảm xúc (Bảng 1) và phân loại chủ đề (Bảng 2). Trong phân tích cảm xúc, việc tinh chỉnh bộ phân loại trên hỗn hợp của LexC-Gen-100K (100K thể hiện dữ liệu được tạo được lọc xuống khoảng 37K thể hiện) và dữ liệu tác vụ tiếng Anh hiện có cải thiện 15.2 điểm phần trăm so với đường cơ sở chuyển giao zero-shot xuyên ngôn ngữ và 6.6 điểm so với đường cơ sở dịch từ. Trong phân loại chủ đề, LexC-Gen-100K mang lại cải thiện 18.3 điểm so với đường cơ sở chuyển giao zero-shot xuyên ngôn ngữ và 8.9 điểm so với đường cơ sở dịch từ. Mức tăng độ chính xác từ việc thêm dữ liệu tiếng Anh hiện có giảm từ LexC-Gen-1K đến LexC-Gen-100K vì dữ liệu tiếng Anh bị chi phối bởi kích thước lớn hơn đáng kể của dữ liệu được tạo (xem thêm thảo luận trong Phụ lục I).

Trong khi mô hình có sẵn thương mại GPT-4o mang lại hiệu suất tốt nhất - thậm chí vượt qua các bộ phân loại được huấn luyện trên dữ liệu vàng - không rõ liệu dữ liệu đánh giá đã được thấy trong quá trình huấn luyện. Hơn nữa, việc phát hành GPT-4o là sau nghiên cứu của chúng tôi. Ngược lại, các tác vụ đánh giá NusaX và SIB-200 của chúng tôi không phải là một phần của việc huấn luyện các mô hình nguồn mở BLOOMZ-7.1B và Aya-101-13B (Workshop et al., 2022; Singh et al., 2024; Üstün et al., 2024). Kết quả của chúng tôi tiết lộ khoảng cách hiệu suất trong các mô hình nguồn mở này. Ví dụ, gợi ý zero-shot với BLOOMZ-7.1B là đường cơ sở yếu nhất (Bảng 1 và Bảng 2). Tuy nhiên, việc sử dụng nó trong LexC-Gen để tạo dữ liệu tác vụ (tức là, LexC-Gen-100K) có thể đạt được hiệu suất tiên tiến. Kết quả của chúng tôi gợi ý rằng, để áp dụng LLM nguồn mở cho các tác vụ ngôn ngữ ít tài nguyên, tốt nhất là tận dụng chúng để tạo dữ liệu huấn luyện ở quy mô lớn thay vì gợi ý chúng trực tiếp trong các thiết lập zero-shot hoặc few-shot.

LexC-Gen-100K cải thiện so với các đường cơ sở vì đầu tiên, nó cải thiện độ bao phủ dịch từ của các thể hiện dữ liệu (Hình 1b trái) do đó có ít hiện vật không mong muốn của các từ chưa được dịch trong ngôn ngữ có nhiều tài nguyên. Thứ hai, nó tăng đáng kể tỷ lệ sử dụng từ điển (Hình 1b phải và Phần 5.4), cho phép nhiều từ ngôn ngữ ít tài nguyên từ từ điển có mặt trong dữ liệu tác vụ để bộ phân loại tác vụ có thể liên kết nhãn tác vụ với thông tin ngữ nghĩa được mang bởi những từ này.

### 5.2 LexC-Gen có khả năng cạnh tranh với bản dịch vàng

Bảng 1 và Bảng 2 cho thấy rằng việc tinh chỉnh bộ phân loại trên dữ liệu xuyên ngôn ngữ được tạo bởi LexC-Gen-100K có khả năng cạnh tranh với việc huấn luyện trên dữ liệu được dịch bởi chuyên gia cho nhiều ngôn ngữ ít tài nguyên. Phát hiện của chúng tôi cũng khái quát hóa cho các bộ phân loại tác vụ lớn hơn, như XLMR-base và XLMR-large (Conneau et al., 2020) (xem Hình 7 trong Phần 5.6). Kết quả của chúng tôi đáng ngạc nhiên vì dữ liệu được tạo bởi LexC-Gen vẫn sử dụng cú pháp tiếng Anh với thứ tự từ SVO. Tuy nhiên, LexC-Gen vẫn hoạt động cho các ngôn ngữ có thứ tự từ khác nhau, như Balinese (ban) và Mizo (lus) với thứ tự từ OSV và Toba batak (bbc) với thứ tự từ VOS.

Một giải thích có thể là việc giải quyết các tác vụ phân tích cảm xúc và phân loại chủ đề dựa nhiều vào thông tin ngữ nghĩa hơn thông tin cú pháp. Do độ bao phủ dịch từ lớn hơn và tỷ lệ sử dụng từ điển cực kỳ cao (Hình 1b), dữ liệu được tạo bởi LexC-Gen ở quy mô lớn chứa đủ thông tin ngữ nghĩa trong ngôn ngữ ít tài nguyên để các bộ phân loại học tác vụ. Tuy nhiên, nó yêu cầu một tập dữ liệu LexC-Gen lớn hơn nhiều để phù hợp với hiệu suất bản dịch vàng. Dữ liệu LexC-Gen (sau khi lọc) lớn hơn khoảng 75× và 30× kích thước bản dịch vàng như được thể hiện trong Bảng 1 và Bảng 2 cho các tác vụ phân tích cảm xúc và phân loại chủ đề tương ứng.

### 5.3 Điều kiện hóa từ điển là quan trọng cho hiệu suất tác vụ mạnh

Hình 4 cho thấy rằng việc sử dụng các từ từ từ điển để tạo dữ liệu tác vụ (tức là, điều kiện hóa từ điển) là cần thiết để phù hợp với hiệu suất bản dịch vàng. Việc loại bỏ điều kiện hóa từ điển và kiểm soát chất lượng ("Gen w/o filter") có hiệu suất tệ nhất - nó thậm chí còn thua kém đường cơ sở dịch từ (Wang et al., 2022) trên 500 mẫu dữ liệu tác vụ hiện có cho phân tích cảm xúc. Ngay cả với kiểm soát chất lượng từ Phần 3.4, việc mở rộng quy mô tạo dữ liệu mà không có điều kiện hóa từ điển ("Gen") vẫn hoạt động tệ hơn LexC-Gen-100K. Điều này là do sự chồng lấp từ vựng thấp giữa dữ liệu và từ điển song ngữ. Dữ liệu "Gen" có tỷ lệ sử dụng từ điển kém hơn, vì nó chỉ bao phủ 62.5% các từ ngôn ngữ ít tài nguyên trong từ điển song ngữ. Ngược lại, LexC-Gen-100K bao phủ 92.8% từ. Chúng tôi giới thiệu độc giả đến Phụ lục F để biết thêm chi tiết về nghiên cứu loại bỏ thành phần của chúng tôi.

### 5.4 Mở rộng quy mô dữ liệu được tạo tăng tỷ lệ sử dụng từ điển

Hình 5 cho thấy rằng việc mở rộng quy mô quá trình tạo dữ liệu cải thiện tỷ lệ sử dụng của từ điển song ngữ, đó là tỷ lệ tổng của các từ ngôn ngữ ít tài nguyên trong từ điển song ngữ xuất hiện trong tập dữ liệu đã dịch, vì LexC-Gen sử dụng nhiều từ từ từ điển hơn để tạo dữ liệu tác vụ. Chúng tôi quan sát rằng khi tỷ lệ sử dụng từ điển cải thiện, độ chính xác phân tích cảm xúc tăng. Điều này là vì có nhiều thông tin ngữ nghĩa hơn cho các bộ phân loại để học các tác vụ hạ nguồn trong ngôn ngữ đích. Chúng tôi cũng có được một biểu đồ tương tự với tác vụ phân loại chủ đề (xem Hình 9 Phụ lục). Việc mở rộng quy mô được kích hoạt bởi bản chất tạo sinh của LexC-Gen, trái ngược với các phương pháp trước đây bị hạn chế về số lượng dữ liệu tác vụ được gán nhãn trong ngôn ngữ có nhiều tài nguyên.

### 5.5 Kiểm soát chất lượng giảm kích thước dữ liệu huấn luyện và tăng hiệu suất

Hình 6 cho thấy rằng việc áp dụng bộ lọc tính nhất quán đầu vào-nhãn như kiểm soát chất lượng dữ liệu không chỉ giảm kích thước dữ liệu huấn luyện được tạo đi hai phần ba, dẫn đến tinh chỉnh bộ phân loại tác vụ nhanh hơn 3 lần, mà còn tăng hiệu suất tác vụ từ 56.2 điểm (loại bỏ kiểm soát chất lượng ở 100K dữ liệu được tạo) lên 70.0 điểm (37K dữ liệu được tạo sau lọc kiểm soát chất lượng), thậm chí phù hợp với hiệu suất tinh chỉnh trên bản dịch vàng. Phát hiện của chúng tôi phù hợp với nghiên cứu trước đây với dữ liệu tiếng Anh (Zhou et al., 2023a) cho thấy rằng tối ưu hóa chất lượng dữ liệu dẫn đến lợi ích đáng kể hơn so với việc chỉ mở rộng quy mô số lượng dữ liệu.

Kiểm soát chất lượng với bộ phân loại được huấn luyện trên dữ liệu tác vụ hiện có hiệu quả cho LexC-Gen, nhưng không hiệu quả cho chưng cất nhãn trong đường cơ sở dịch từ của Wang et al. (2022) (Bảng 1 và Bảng 2). Có hai lý do có thể. Đầu tiên, chưng cất nhãn sử dụng bộ phân loại được huấn luyện trên dữ liệu ngôn ngữ có nhiều tài nguyên để gán nhãn lại dữ liệu đã dịch trong ngôn ngữ ít tài nguyên. Chuyển giao xuyên ngôn ngữ này có thể đưa ra lỗi trong dự đoán của bộ phân loại, trái ngược với việc gán nhãn lại của LexC-Gen trong cùng ngôn ngữ có nhiều tài nguyên. Thứ hai, LexC-Gen cung cấp kiểm soát chất lượng nghiêm ngặt hơn bằng cách loại bỏ tất cả các thể hiện với nhãn không khớp giữa bộ phân loại và LLM, do đó cải thiện hiệu suất tác vụ (xem Hình 11 trong Phụ lục H).

### 5.6 LexC-Gen khái quát hóa cho các bộ phân loại lớn hơn

Hình 7 phân tích kích thước dữ liệu được tạo bởi LexC-Gen cần thiết cho các bộ phân loại tác vụ có kích thước khác nhau - mBERT (Devlin et al., 2019) có 172 triệu tham số, XLMR-base (Conneau et al., 2020) có 270 triệu tham số, và XLMR-large có 550 triệu tham số - để phù hợp với hiệu suất bản dịch vàng. Đầu tiên, chúng tôi quan sát rằng kích thước bộ phân loại tác vụ lớn hơn yêu cầu ít dữ liệu hơn để đạt cùng độ chính xác. Ví dụ, XLMR-large đã vượt quá độ chính xác 70 điểm với 5K dữ liệu LexC-Gen nhưng mBERT yêu cầu 35K dữ liệu LexC-Gen để đạt cùng độ chính xác.

Tuy nhiên, để phù hợp với hiệu suất vàng, lượng dữ liệu LexC-Gen không tương quan với kích thước của các bộ phân loại. Chúng tôi phát hiện rằng XLMR-base phù hợp với hiệu suất vàng ở khoảng 15K, trái ngược với mBERT ở khoảng 35K, nhưng XLMR-large yêu cầu khoảng 10K dữ liệu LexC-Gen nhiều hơn XLMR-base để có khả năng cạnh tranh như bản dịch vàng.

### 5.7 Lựa chọn từ điển quan trọng

Chúng tôi so sánh việc sử dụng Gatitos (Jones et al., 2023) với Panlex (Kamholz et al., 2014) làm từ điển cho LexC-Gen. Hình 8 cho thấy rằng việc dịch dữ liệu được tạo bởi LexC-Gen với Gatitos vượt trội hơn việc dịch với Panlex trên NusaX. Một lý do là Panlex có kích thước từ điển nhỏ hơn Gatitos, vì đối với tất cả bảy ngôn ngữ trong NusaX, Panlex chỉ có khoảng 840 mục, nhưng Gatitos có khoảng 4271 mục. Do đó, dữ liệu LexC-Gen có độ bao phủ dịch từ kém hơn với Panlex. Hơn nữa, trong khi nguồn dữ liệu của Gatitos không được Jones et al. (2023) mô tả chi tiết, các tác giả đã mô tả rằng các mục Gatitos được xem xét thủ công. Nói cách khác, các bản dịch từ với Gatitos có chất lượng cao hơn.

## 6 Thảo luận

**Ứng dụng trong các tình huống khan hiếm tài nguyên** LexC-Gen giải quyết các tình huống khan hiếm tài nguyên mà các ngôn ngữ có tài nguyên cực kỳ thấp đối mặt khi thiếu dữ liệu được gán nhãn. Chúng tôi cho thấy rằng chúng ta có thể tận dụng các tài nguyên từ vựng hiện có nhưng khan hiếm của chúng như Gatitos (Jones et al., 2023), chỉ chứa khoảng vài nghìn mục từ điển cho các từ hoặc cụm từ thông thường, để tạo dữ liệu tác vụ được gán nhãn. Hơn nữa, LexC-Gen là một giải pháp thực tế cho vấn đề không khớp dữ liệu-từ điển, vì nó không yêu cầu các nhà ngôn ngữ học xây dựng từ điển đặc thù tác vụ, như từ điển cảm xúc đa ngôn ngữ (Chen và Skiena, 2014), hoặc các nhà thực hành thu thập dữ liệu tác vụ được gán nhãn trong ngôn ngữ ít tài nguyên.

**Các mô hình nguồn mở** Các mô hình nguồn mở hiện tại như BLOOMZ (Muennighoff et al., 2023) và Aya-101 (Üstün et al., 2024) thất bại trong việc thu hẹp khoảng cách hiệu suất với GPT-4o và đường cơ sở bản dịch vàng. Công trình của chúng tôi bắc cầu khoảng cách - chúng tôi cho thấy rằng việc sử dụng chúng để tạo dữ liệu huấn luyện cải thiện hiệu suất so với gợi ý zero-shot hoặc few-shot trực tiếp và có thể phù hợp với việc huấn luyện bộ phân loại trên dữ liệu được gán nhãn bởi con người. Hơn nữa, do bản chất cho phép của các mô hình, dữ liệu được tạo của chúng có thể được sử dụng cho nghiên cứu độc quyền hoặc công cộng cho các ứng dụng đa ngôn ngữ rộng hơn.

**Hiệu quả của tạo sinh có điều kiện từ điển** Chúng tôi cho thấy rằng từ điển song ngữ bất khả tri tác vụ như Gatitos (Jones et al., 2023) chứa đủ thông tin ngữ nghĩa cho phân tích cảm xúc và phân loại chủ đề trong các ngôn ngữ có tài nguyên cực kỳ thấp. Tuy nhiên, nó yêu cầu mức độ chồng lấp từ vựng cao giữa dữ liệu tác vụ và từ điển để bao gồm thông tin trong dữ liệu đã dịch (Hình 1a). Chúng tôi cũng phát hiện rằng kích thước và chất lượng từ điển quan trọng. Việc sử dụng từ điển Gatitos (Jones et al., 2023) cho LexC-Gen vượt trội hơn việc sử dụng Panlex (Kamholz et al., 2014) vì cái trước chứa nhiều mục hơn và có chất lượng cao hơn.

LexC-Gen khác với nghiên cứu trước đây về tạo văn bản bị ràng buộc từ vựng (Hokamp và Liu, 2017; Post và Vilar, 2018; Hu et al., 2019). Chúng tôi giới thiệu một bước bổ sung của huấn luyện CTG để LLM có thể học tạo văn bản tự nhiên vừa tối đa hóa việc sử dụng từ điển vừa phù hợp với nhãn lớp. Bước này cho phép LexC-Gen vượt trội hơn giải mã bị ràng buộc từ vựng (xem Phụ lục G).

**Hiệu quả chi phí** LexC-Gen dựa vào LLM được huấn luyện CTG tuân theo hướng dẫn gợi ý tạo dữ liệu tác vụ sử dụng một tập hợp các từ đã cho. Huấn luyện CTG của chúng tôi với LLM nguồn mở chỉ phụ thuộc vào dữ liệu tác vụ ngôn ngữ có nhiều tài nguyên, và độc lập với ngôn ngữ ít tài nguyên và từ điển song ngữ. Nói cách khác, một khi LLM được huấn luyện CTG, các nhà nghiên cứu có thể tái sử dụng nó với các từ điển song ngữ khác nhau để tạo dữ liệu cho các ngôn ngữ ít tài nguyên khác nhau trên cùng tác vụ mà không cần huấn luyện lại. Hơn nữa, LexC-Gen chỉ mất ít hơn một ngày để tạo 100K mẫu dữ liệu trên một GPU V100.

**Cảm ứng từ điển song ngữ (BLI)** Chúng tôi phân tích dữ liệu được tạo và phát hiện rằng trung bình 34% các từ ngôn ngữ có nhiều tài nguyên không thể được tìm thấy trong Gatitos và do đó không thể được dịch. Điều này để lại chỗ cho cải thiện với BLI để mở rộng độ bao phủ từ của từ điển song ngữ (Nasution et al., 2016; Irvine và Callison-Burch, 2017; Bafna et al., 2024), để nhiều từ hơn có thể được dịch sang ngôn ngữ ít tài nguyên. Tuy nhiên, với việc LexC-Gen đã phù hợp với hiệu suất vàng, chúng tôi để việc cải thiện LexC-Gen với BLI cho nghiên cứu tương lai.

## 7 Kết luận

Chúng tôi đề xuất LexC-Gen để tạo dữ liệu tác vụ ngôn ngữ ít tài nguyên cho các tác vụ phân tích cảm xúc và phân loại chủ đề. Việc tinh chỉnh trên dữ liệu được tạo của chúng tôi có thể phù hợp với dữ liệu vàng khó thu thập. Với việc LexC-Gen là một giải pháp thực tế, chúng tôi hy vọng nó giảm bớt vấn đề khan hiếm dữ liệu nghiêm trọng của các ngôn ngữ ít tài nguyên và đẩy nhanh tiến bộ NLP trong những ngôn ngữ đuôi dài này.

## Hạn chế

**Sự mơ hồ của từ** Trong việc dịch từ sang từ của chúng tôi, chúng tôi tuân theo giao thức của nghiên cứu trước đây (Wang et al., 2022) và chọn ngẫu nhiên một bản dịch từ nếu một từ cụ thể được ánh xạ thành nhiều bản dịch. Nói cách khác, chúng tôi không phân biệt các bản dịch từ trong ngôn ngữ ít tài nguyên vì các từ ngôn ngữ ít tài nguyên tồn tại trong từ điển không đi kèm với thông tin ngôn ngữ học (như thẻ từ loại) hoặc ngữ cảnh (như câu ví dụ) cần thiết cho việc phân biệt nghĩa từ (Navigli, 2009). Do đó, các bản dịch từ của chúng tôi có thể đưa ra lỗi trong dữ liệu tác vụ đã dịch. Nghiên cứu tương lai có thể mở rộng các mục trong từ điển song ngữ để kết hợp thông tin ngôn ngữ học hoặc ngữ cảnh để cho phép phân biệt nghĩa từ và cải thiện chất lượng của dữ liệu đã dịch trong ngôn ngữ ít tài nguyên.

**Không khớp cú pháp** Vì LexC-Gen dựa trên dịch từ sang từ, nó gặp phải hạn chế vốn có là cú pháp của các câu được dịch từ được tạo vẫn không thay đổi và do đó có thể không khớp với cú pháp của ngôn ngữ ít tài nguyên. Tuy nhiên, chúng tôi đã chỉ ra rằng bất chấp hạn chế này, LexC-Gen vẫn cải thiện hiệu suất đáng kể trong các tác vụ ngữ nghĩa như phân tích cảm xúc và phân loại chủ đề cho các ngôn ngữ có thứ tự từ khác nhau. Điều này gợi ý rằng LexC-Gen là một giải pháp khả thi cho các tác vụ ngữ nghĩa khi dữ liệu huấn luyện trong ngôn ngữ cực kỳ khó thu thập cho các ngôn ngữ ít tài nguyên. Nghiên cứu tương lai nên khám phá biến đổi cú pháp của dữ liệu tổng hợp LexC-Gen để phù hợp tốt hơn với ngôn ngữ ít tài nguyên cho các tác vụ, như dịch máy và nhận dạng thực thể có tên, phụ thuộc nhiều vào thông tin cú pháp.

**Tác vụ** Chúng tôi thử nghiệm LexC-Gen trên các tác vụ phân tích cảm xúc và phân loại chủ đề, cả hai đều là các tác vụ NLU mà các ngôn ngữ ít tài nguyên vẫn đang tụt hậu so với ngôn ngữ có nhiều tài nguyên (Winata et al., 2023b; Adelani et al., 2023). Chúng tôi thừa nhận rằng nghiên cứu tương lai được bảo đảm để khám phá tiềm năng và hạn chế của LexC-Gen trên các tác vụ NLU khác (1) yêu cầu nhạy cảm với độ phức tạp ngữ nghĩa ở cấp độ câu, như lập luận thông thường và suy luận ngôn ngữ tự nhiên, hoặc (2) thông tin cú pháp, như nhận dạng thực thể có tên và truy xuất thông tin.

**Ngôn ngữ nguồn** Trong các thí nghiệm của chúng tôi, chúng tôi tuân theo nghiên cứu trước đây (Jones et al., 2023; Wang et al., 2022) và tạo dữ liệu tác vụ ngôn ngữ ít tài nguyên từ dữ liệu tác vụ tiếng Anh sử dụng từ điển song ngữ Gatitos dựa trên tiếng Anh (Jones et al., 2023). Nghiên cứu tương lai nên khám phá việc mở rộng LexC-Gen ngoài tiếng Anh và tạo dữ liệu tác vụ trong các ngôn ngữ có nhiều tài nguyên có liên quan nhiều hơn đến ngôn ngữ ít tài nguyên so với tiếng Anh. Cũng sẽ thú vị khi khám phá liệu BLOOMZ hoặc các LLM truy cập mở khác có khả năng về khả năng tạo văn bản có kiểm soát cho các ngôn ngữ không phải tiếng Anh.

## Tác động Rộng hơn và Cân nhắc Đạo đức

Vì công trình của chúng tôi giải quyết vấn đề khan hiếm dữ liệu huấn luyện của các ngôn ngữ có tài nguyên cực kỳ thấp (Joshi et al., 2020; Yong et al., 2023; Singh et al., 2024, và những nghiên cứu khác), chúng tôi dự đoán việc áp dụng và nghiên cứu thêm về các phương pháp của chúng tôi bởi các nhà thực hành NLP để giải quyết các tác vụ NLU ngữ nghĩa khác. Vì phương pháp của chúng tôi hoạt động tốt với LLM có giấy phép cho phép, có thể dữ liệu tác vụ được tạo được phân phối rộng rãi cho các ứng dụng NLP trong nhiều ngôn ngữ ít tài nguyên khác nhau.

Một rủi ro tiềm ẩn của dữ liệu tổng hợp là sự sụp đổ mô hình (Shumailov et al., 2023) khi dữ liệu tổng hợp khiến đuôi của phân phối dữ liệu gốc biến mất. Ở đây, công trình của chúng tôi tập trung vào dữ liệu tổng hợp cho các ngôn ngữ đuôi dài. Chúng tôi muốn nhấn mạnh rằng dữ liệu huấn luyện xuyên ngôn ngữ được tạo bởi LexC-Gen không thay thế cho dữ liệu tự nhiên trong ngôn ngữ. Công trình của chúng tôi thực sự khuyến khích đầu tư nhiều hơn của con người vào các ngôn ngữ ít tài nguyên về mặt tuyển chọn từ điển và thu thập dữ liệu tác vụ. Chúng tôi không chỉ chứng minh rằng từ điển song ngữ chất lượng cao hiệu quả trong việc cải thiện hiệu suất tác vụ ngữ nghĩa, mà còn cho thấy rằng bản dịch vàng trong ngôn ngữ ít tài nguyên đích yêu cầu ít dữ liệu hơn để đạt được hiệu suất tác vụ mạnh.

## Lời cảm ơn

Chúng tôi cảm ơn Julia Kreutzer, Genta Indra Winata, Alham Fikri Aji, David Ifeoluwa Adelani, Sebastian Ruder, Ruochen Zhang, và Brown University Superlab vì phản hồi hữu ích về bài báo của chúng tôi. Chúng tôi biết ơn sự hỗ trợ từ Cisco. Tiết lộ: Stephen Bach là cố vấn cho Snorkel AI, một công ty cung cấp phần mềm và dịch vụ cho trí tuệ nhân tạo tập trung vào dữ liệu.

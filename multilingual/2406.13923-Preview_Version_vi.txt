# 2406.13923.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/multilingual/2406.13923.pdf
# Kích thước tệp: 2061022 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
Phiên bản Xem trước
PIN: Một Bộ dữ liệu Chuyên sâu Kiến thức cho
Tài liệu Đa phương tiện Ghép cặp và Xen kẽ
Junjie Wang*,1,3, Yin Zhang1,8, Yatai Ji5, Yuxiang Zhang1,3, Chunyang Jiang8, Yubo Wang4, Kang Zhu6, Zekun
Wang6, Tiezhen Wang7, Wenhao Huang6, Jie Fu*,8, Bei Chen*,6, Qunshu Lin*,2, Minghao Liu*,2, Ge
Zhang*,1,4,6và Wenhu Chen*,1,4
*Tác giả Liên hệ,1Multimodal Art Projection,22077AI,3Đại học Waseda,4Đại học Waterloo,5Đại học Thanh Hoa,
601.AI,7Hugging Face,8Nghiên cứu viên Độc lập
Những tiến bộ gần đây trong Mô hình Đa phương tiện Lớn (LMMs) đã tận dụng các bộ dữ liệu đa phương tiện
rộng lớn để nâng cao khả năng trong các nhiệm vụ phức tạp dựa trên kiến thức. Tuy nhiên, những thách thức
dai dẳng trong lỗi nhận thức và suy luận giới hạn hiệu quả của chúng, đặc biệt là trong việc diễn giải dữ liệu
hình ảnh phức tạp và suy diễn các mối quan hệ đa phương tiện. Để giải quyết những vấn đề này, chúng tôi giới
thiệu một định dạng bộ dữ liệu mới, PIN (Tài liệu đa phương tiện ghép cặp và xen kẽ), được thiết kế để cải
thiện đáng kể cả chiều sâu và chiều rộng của việc huấn luyện đa phương tiện. Định dạng PIN được xây dựng
trên ba nguyên tắc cơ bản: cường độ kiến thức, khả năng mở rộng và hỗ trợ cho các phương thức huấn luyện
đa dạng. Định dạng sáng tạo này kết hợp các tệp markdown và hình ảnh toàn diện để làm phong phú dữ liệu
huấn luyện với cấu trúc kiến thức dày đặc và chiến lược huấn luyện linh hoạt. Chúng tôi trình bày PIN-14M,
một bộ dữ liệu mã nguồn mở bao gồm 14 triệu mẫu có nguồn gốc từ một loạt các nguồn tiếng Trung và tiếng
Anh đa dạng, được điều chỉnh để bao gồm nội dung web và khoa học phức tạp. Bộ dữ liệu này được xây dựng
tỉ mỉ để đảm bảo chất lượng dữ liệu và tính toàn vẹn đạo đức, nhằm tạo điều kiện cho các chiến lược huấn
luyện tiên tiến và cải thiện khả năng chống chịu của mô hình trước những bẫy thường gặp trong huấn luyện
đa phương tiện. Kết quả ban đầu của chúng tôi, tạo thành cơ sở cho báo cáo kỹ thuật này, cho thấy tiềm năng
đáng kể của định dạng PIN trong việc cải thiện hiệu suất LMM, với kế hoạch mở rộng trong tương lai và đánh
giá chi tiết về tác động của nó đối với khả năng của mô hình.
1 Giới thiệu 1
2 Công trình Liên quan 3
2.1 Định dạng Dữ liệu Đa phương tiện . . . 3
2.2 Chiến lược Tiền huấn luyện trên LMMs . 4
3 Quản lý Dữ liệu 4
3.1 Định dạng PIN . . . . . . . . . . . . . 4
3.2 Xử lý Dữ liệu . . . . . . . . . . . . 6
3.3 Kiểm soát Chất lượng . . . . . . . . . 10
3.4 Cân nhắc Đạo đức . . . . . . . . 114 Phân tích PIN 11
4.1 Thống kê chung . . . . . . . . . 11
4.2 Mô hình hóa Chủ đề . . . . . . . . . . 12
5 Chiến lược Huấn luyện 13
5.1 Dựa trên Cặp Hình ảnh-văn bản . . . . 13
5.2 Dựa trên Tài liệu Xen kẽ 14
5.3 Chiến lược Tiềm năng . . . . . . . . . 14
6 Thảo luận 15
7 Kết luận 16

1. Giới thiệu
Những tiến bộ gần đây trong Mô hình Đa phương tiện Lớn (LMMs) đã cho phép ứng dụng thành công của chúng
trong nhiều nhiệm vụ dựa trên kiến thức như suy luận biểu đồ và hiểu hiện tượng thông qua việc học các bộ dữ
liệu đa phương tiện quy mô lớn [1,2]. Tuy nhiên, các nghiên cứu đánh giá gần đây [3,4] đã làm nổi bật hai loại
lỗi chính: lỗi nhận thức và lỗi suy luận. Lỗi nhận thức bao gồm khó khăn trong việc diễn giải bảng và đồ thị,
đặc biệt là những loại phức tạp về mặt chuyên môn. Hơn nữa, lỗi suy luận thường xảy ra khi mô hình không thể
suy diễn mối quan hệ giữa hình ảnh và văn bản, đặc biệt trong các tình huống liên quan đến trạng thái tuần tự.
Để đáp ứng những thách thức này và
Tác giả liên hệ: wjj1020181822@toki.waseda.jp, chenbei@01.ai, wenhu.chen@uwaterloo.ca
©2024 đội ngũ PIN. Bảo lưu mọi quyềnarXiv:2406.13923v1  [cs.AI]  20 Jun 2024

--- TRANG 2 ---
PIN: Một Bộ dữ liệu Chuyên sâu Kiến thức cho Tài liệu Đa phương tiện Ghép cặp và Xen kẽ(Phiên bản Xem trước)
(a) Định dạng Đa phương tiện Trước đây(a.1) Cặp Hình ảnh -Văn bản
Đặt innerHTML Nguy hiểm
Một báo cáo lỗi
(a.2) Tài liệu Xen kẽ
(b.1) Tệp Markdown
(b) Định dạng PIN (của chúng tôi)(b.2) Hình ảnh Tổng thể
Ghép cặp
Cường độ kiến thức Khả năng mở rộng Hỗ trợ cho các chiến lược huấn luyện đa dạngXen kẽ Xen kẽ
Hình1|Phân tích so sánh các định dạng đa phương tiện truyền thống so với định dạng PIN được đề xuất. Định
dạng PIN bảo tồn các thuộc tính kiến thức phong phú (ví dụ: in đậm, làm nổi bật, mã), hỗ trợ tương tác ngữ
nghĩa giữa hình ảnh và văn bản trong các tệp markdown, và nâng cao biểu diễn kiến thức thông qua một hình
ảnh tổng thể.
với mục tiêu huấn luyện một LMM chuyên sâu kiến thức, chúng tôi đề xuất một giải pháp từ góc độ dữ liệu:
việc tạo ra một bộ dữ liệu đa phương tiện chuyên sâu kiến thức.
Như minh họa trong Hình 1 (a), các bộ dữ liệu huấn luyện đa phương tiện chính hiện tại chủ yếu thuộc hai
loại: (a.1) cặp hình ảnh-văn bản và (a.2) tài liệu xen kẽ. Trong cặp hình ảnh-văn bản [5,6], văn bản tương
ứng với hình ảnh, cho phép các mô hình huấn luyện khả năng nhận thức, mặc dù với kiến thức suy luận có
hạn. Một số công trình đã chuyển trọng tâm sang tài liệu học thuật, coi nội dung của bài báo là văn bản và
các trang là hình ảnh để tạo ra bộ dữ liệu văn bản-hình ảnh [7,8]. Mặc dù các bộ dữ liệu này cho thấy hiệu
suất mạnh trên các đánh giá khoa học, chúng phải đối mặt với một số hạn chế. Đầu tiên, việc loại trừ hình ảnh
và nội dung liên quan không thừa nhận tương tác quan trọng giữa văn bản và hình ảnh trong các bài báo.
Hơn nữa, việc phân đoạn từng trang phá vỡ tính liên tục tự nhiên của tài liệu, cản trở các mô hình học kiến
thức toàn diện của toàn bộ bài báo. Ngoài ra, việc thiếu vắng các bộ dữ liệu mã nguồn mở gây ra những thách
thức đáng kể cho các nỗ lực sao chép.
Để bao gồm thông tin xen kẽ phong phú của hình ảnh và văn bản, định dạng tài liệu xen kẽ đã được giới thiệu,
nâng cao cả khả năng nhận thức và suy luận của các mô hình. Tuy nhiên, định dạng này hiện đang đối mặt với
ba thách thức: thiếu bộ dữ liệu (chỉ có MMC4 [9] và OBELICS [10] có sẵn), thiếu dữ liệu chuyên môn (chỉ
có trang web) và thiếu thông tin tổng thể. Chúng tôi xem xét định dạng dữ liệu nào có thể giải quyết những
vấn đề này. Định dạng lý tưởng nên thể hiện ba đặc điểm chính: (1)cường độ kiến thức, (2)khả năng mở
rộng, và(3)hỗ trợ cho các chiến lược huấn luyện đa dạng. Do đó, như được hiển thị trong Hình 1 (b), chúng
tôi đề xuất một định dạng dữ liệu mới: PIN, hoặc Tài liệu đa phương tiện ghép cặp và xen kẽ. Cụ thể, định
dạng PIN bao gồm hai thành phần chính: (b.1) tệp markdown và (b.2) hình ảnh tổng thể. Các tệp markdown
chứa tài liệu xen kẽ chuyên sâu kiến thức, được định dạng với cú pháp đánh dấu đơn giản (như in đậm, in
nghiêng và tiêu đề) để tạo điều kiện hiểu biết về kiến thức, chẳng hạn như cấu trúc bài viết và các điểm chính.
Hơn nữa, nó hỗ trợ nhúng liên kết và hình ảnh, điều này vô cùng quý giá cho việc tạo ra các tài liệu giàu đa
phương tiện, do đó bảo tồn tiềm năng cho
2

--- TRANG 3 ---
PIN: Một Bộ dữ liệu Chuyên sâu Kiến thức cho Tài liệu Đa phương tiện Ghép cặp và Xen kẽ(Phiên bản Xem trước)
hỗ trợ các phương thức bổ sung trong tương lai, chẳng hạn như âm thanh và video. Mặt khác, việc thiết lập
hình ảnh tổng thể cho phép các mô hình học thông tin phong phú như bố cục, phân tích thêm các kết nối giữa
văn bản và hình ảnh, chẳng hạn như tổng thể và các phần, trình tự, v.v. Do đó, việc thiết lập định dạng dữ
liệu này đáp ứng các yêu cầu cho (1) cường độ kiến thức. Hơn nữa, chúng tôi đặt định dạng PIN như một
định dạng thống nhất, cung cấp các quy trình và phương pháp cho các bộ dữ liệu khác để chuyển đổi sang
định dạng PIN. Bằng cách chuyển đổi các bộ dữ liệu chính hiện có sang định dạng PIN, chúng tôi cũng đạt
được (2) khả năng mở rộng. Ngoài ra, định dạng PIN tương thích với các chiến lược huấn luyện phổ biến,
chẳng hạn như huấn luyện cặp hình ảnh-văn bản và huấn luyện đa phương tiện xen kẽ. Hơn nữa, chúng tôi
có thể phát triển các phương pháp tiền huấn luyện mới dựa trên định dạng PIN, chẳng hạn như dự đoán hình
ảnh từ văn bản markdown hoặc trích xuất kiến thức văn bản từ hình ảnh. Các chiến lược huấn luyện phong phú
cho phép các mô hình được huấn luyện trên tài liệu PIN học từ nhiều góc độ khác nhau, đáp ứng các nhu cầu
khác nhau. Do đó, định dạng PIN đáp ứng các yêu cầu cho (3) hỗ trợ các chiến lược huấn luyện đa dạng.
Trong công trình này, chúng tôi phát triển một số bộ dữ liệu theo định dạng PIN. Chúng tôi giới thiệu một phiên
bản mã nguồn mở, PIN-14M1, bao gồm 14 triệu mẫu được trích xuất từ các nguồn dữ liệu tiếng Trung và tiếng
Anh khác nhau. Dữ liệu của chúng tôi không chỉ bao gồm các trang web phổ biến mà còn có các tài liệu khoa
học có hình ảnh đòi hỏi suy luận và hiểu biết, chẳng hạn như sơ đồ và biểu đồ. Chúng tôi mô tả chi tiết quy
trình tạo ra bộ dữ liệu này, bao gồm các phương pháp thu thập, quy trình lọc và các cân nhắc đạo đức. Ngoài
ra, chúng tôi nhúng các tín hiệu chất lượng trong bộ dữ liệu, cho phép các nhà nghiên cứu sử dụng dữ liệu
một cách có chọn lọc dựa trên nhu cầu cụ thể.
Báo cáo kỹ thuật này là phiên bản sơ bộ. Trong công việc tương lai, chúng tôi dự định cung cấp một bài báo
toàn diện hơn với các phân tích sâu hơn về định dạng PIN. Chúng tôi cũng sẽ phát hành các bộ dữ liệu lớn
hơn; PIN-14M chỉ là một bộ dữ liệu ban đầu. Hơn nữa, để khám phá hiệu quả của các bộ dữ liệu của chúng
tôi, chúng tôi sẽ tiến hành các thí nghiệm và cung cấp các phân tích chi tiết trong tương lai.
Những đóng góp của báo cáo kỹ thuật này (phiên bản xem trước) là:
•Chúng tôi giới thiệu một định dạng bộ dữ liệu đa phương tiện mới, PIN, cho Tài liệu đa phương tiện ghép
cặp và xen kẽ. Nó hỗ trợ huấn luyện các mô hình lớn chuyên sâu kiến thức và có thể mở rộng để chuyển
đổi các bộ dữ liệu hiện tại sang định dạng này.
•Các quy trình và phương pháp xử lý dữ liệu sẽ được mở nguồn, cùng với một số kỹ thuật chuyển đổi bộ
dữ liệu.
•Chúng tôi phát hành một bộ dữ liệu mã nguồn mở, PIN-14M.

2. Công trình Liên quan
2.1. Định dạng Dữ liệu Đa phương tiện
Các bộ dữ liệu tiền huấn luyện đa phương tiện chủ yếu được định dạng theo hai cách: cặp hình ảnh-văn bản
và tài liệu xen kẽ. Định dạng cặp hình ảnh-văn bản hiện tại được sử dụng nhiều nhất, liên quan đến việc tạo
ra khối lượng dữ liệu lớn thông qua thu thập web rộng rãi cho mô tả alt-text [5,6,11]. Mặc dù các bộ dữ liệu
này bao phủ phạm vi rộng, chúng thể hiện những hạn chế cố hữu. Sự phụ thuộc vào alt-text thường dẫn đến
văn bản ngắn gọn và đơn giản chỉ cung cấp những cái nhìn thoáng qua về nội dung hình ảnh, thường thiếu
chiều sâu trong sự phong phú ngữ cảnh và chi tiết ngữ pháp. Trong một số trường hợp, alt-text chỉ bao gồm
một vài từ cơ bản và có thể không tạo thành câu hoàn chỉnh. Để giải quyết thách thức này, NOUGAT [7] và
KOSMOS-2.5 [8] đề xuất cặp hình ảnh-văn bản trên các tài liệu học thuật như bài báo học thuật và tạp chí
khoa học. Các trang PDF và văn bản bài báo được coi là cặp hình ảnh-văn bản, làm phong phú thông tin ngữ
nghĩa của văn bản. Tuy nhiên, cách tiếp cận này loại trừ hình ảnh, bỏ qua
1PIN-14M:https://huggingface.co/datasets/m-a-p/PIN-14M
3

--- TRANG 4 ---
PIN: Một Bộ dữ liệu Chuyên sâu Kiến thức cho Tài liệu Đa phương tiện Ghép cặp và Xen kẽ(Phiên bản Xem trước)
thông tin tương tác phong phú giữa văn bản và hình ảnh. Hơn nữa, việc phân đoạn bài viết thành các trang
ngăn cản việc sử dụng thông tin qua các trang. Định dạng tài liệu xen kẽ đã xuất hiện như những nghiên cứu
gần đây [1,9,10]. Ví dụ, OpenFlamingo [9] và IDEFICS [10] đã khám phá kỹ thuật xen kẽ hình ảnh với văn
bản trong dữ liệu tiền huấn luyện của họ, từ đó nâng cao khả năng nhận dạng và suy luận đa phương tiện của
LMMs. Những phương pháp này bao gồm việc trích xuất hình ảnh và văn bản mạch lạc từ nội dung web rộng
lớn và kết hợp chúng một cách phức tạp. Tuy nhiên, những chiến lược này chủ yếu nhắm vào nội dung web
và bỏ qua các nguồn kiến thức phong phú hơn, như bài báo học thuật. Hơn nữa, các quy trình làm sạch nghiêm
ngặt có xu hướng xóa bỏ thông tin ngữ cảnh đáng kể, bỏ qua biểu hiện quan trọng của kiến thức, chẳng hạn
như các dấu hiệu. Những thủ tục này cũng không nắm bắt được thông tin xen kẽ từ toàn bộ hình ảnh, chẳng
hạn như bố cục và vị trí cụ thể xuất hiện thông tin. Để chống lại những thiếu sót này, chúng tôi đề xuất định
dạng PIN, được thiết kế để tối đa hóa việc trích xuất và trình bày cả thông tin hình ảnh và văn bản, do đó tạo
điều kiện cho một môi trường học tập toàn diện hơn cho LMMs.

2.2. Chiến lược Tiền huấn luyện trên LMMs
Động lực đằng sau tiền huấn luyện đa phương tiện là huấn luyện khả năng cơ bản trong các mô hình bằng cách
tận dụng các thuộc tính nội tại của kho ngữ liệu. Trái ngược với các bộ dữ liệu đơn phương thức, các bộ dữ
liệu hình ảnh-văn bản đa phương tiện được thiết kế với các thuộc tính nội tại phong phú ngay từ đầu. Những
điều này bao gồm sự căn chỉnh giữa hình ảnh và văn bản, mối quan hệ trong hình ảnh và tính liên tục trong
văn bản. Các chiến lược tiền huấn luyện chính cho LMMs được điều chỉnh cụ thể cho các định dạng hiện tại
của những bộ dữ liệu đa phương tiện này. Các chiến lược như Học Đối lập (CL), Ghép nối Hình ảnh-Văn bản
(ITM), Mô hình hóa Ngôn ngữ Che (MLM) và Mô hình hóa Thị giác Che (MVM) thường được sử dụng trong
các bộ dữ liệu cặp hình ảnh-văn bản [12–15]. Các bộ dữ liệu xen kẽ được giới thiệu gần đây cung cấp một
góc nhìn mà các mô hình đa phương tiện học dự đoán các từ tiếp theo bằng cách xử lý thông tin xen kẽ từ
hình ảnh và văn bản [1]. Định dạng PIN, kết hợp cả đặc điểm ghép cặp và xen kẽ, hỗ trợ liền mạch tất cả
các chiến lược huấn luyện nêu trên. Hơn nữa, chúng tôi sẽ thảo luận về các chiến lược tiền huấn luyện tiềm
năng dựa trên các tính năng mới của bộ dữ liệu trong phần 5.

3. Quản lý Dữ liệu
Trong phần này, chúng tôi mô tả định dạng của chúng tôi và giải thích việc xử lý dữ liệu thô thành định dạng
này. Ngoài ra, chúng tôi trình bày các phương pháp kiểm soát chất lượng và thảo luận về các cân nhắc đạo đức.

3.1. Định dạng PIN
3.1.1. Triết lý
Trong nhiều ngành khoa học và kỹ thuật, các bộ dữ liệu chất lượng cao là thiết yếu, tạo điều kiện cho tiến
bộ từ nghiên cứu cơ bản đến triển khai công nghiệp. Báo cáo này nhằm thiết kế một bộ dữ liệu không chỉ
đáp ứng nhu cầu công nghệ hiện tại mà còn đủ linh hoạt để thích ứng với những tiến bộ trong tương lai. Các
nguyên tắc thiết kế của chúng tôi bao gồm:
•Cường độ kiến thức
•Khả năng mở rộng
•Hỗ trợ các chiến lược huấn luyện đa dạng
Cường độ kiến thức. Lấy cảm hứng từ NOUGAT [7], cách tiếp cận của chúng tôi nâng cao độ phong phú
kiến thức của bộ dữ liệu theo ba cách chính. Đầu tiên, không giống như các trang web, chúng tôi trích xuất
thông tin đa phương tiện
4

--- TRANG 5 ---
PIN: Một Bộ dữ liệu Chuyên sâu Kiến thức cho Tài liệu Đa phương tiện Ghép cặp và Xen kẽ(Phiên bản Xem trước)
từ các tài liệu học thuật. Ngoài ra, chúng tôi chuyển từ các tệp markdown hoàn toàn dựa trên văn bản sang
các định dạng xen kẽ với hình ảnh nội dung và cung cấp một "hình ảnh tổng thể", điều này khôi phục lại
thông tin đa phương tiện bị mất trong việc xây dựng bộ dữ liệu NOUGAT. Thứ hai, nhận thức được sự khan
hiếm của các tài liệu học thuật, chúng tôi kết hợp các nguồn khác như sách và kho mã, bảo tồn các khái niệm
đánh dấu của chúng. Thứ ba, đối với dữ liệu có nguồn gốc từ các trang web, chúng tôi giới thiệu một "hình
ảnh tổng thể" để làm phong phú thông tin hình ảnh xen kẽ. Thông qua những phương pháp này, bộ dữ liệu
của chúng tôi bao gồm các mức độ cường độ kiến thức khác nhau, đảm bảo chiều sâu thông tin phong phú.
Khả năng mở rộng. Để đảm bảo bộ dữ liệu của chúng tôi có thể được mở rộng quy mô cho sản xuất, định
dạng được thiết kế của chúng tôi phải đáp ứng hai tiêu chí chính: tương thích với các bộ dữ liệu đa phương
tiện hiện có và hỗ trợ cho các định dạng dữ liệu khác nhau. Đối với các bộ dữ liệu đa phương tiện sẵn có như
OBELICS [10] và MMC4 [9], chúng tôi tạo ra một "hình ảnh tổng thể" cho mỗi tài liệu thông qua xử lý đơn
giản và chuyển đổi các cấu trúc danh sách dựa trên văn bản gốc thành định dạng markdown xen kẽ thống
nhất. Tương tự, đối với các bộ dữ liệu dựa trên cặp hình ảnh-văn bản, chúng tôi có thể dễ dàng thích ứng
chúng với định dạng của chúng tôi bằng cách sử dụng các mẫu được thiết kế. Hơn nữa, cách tiếp cận của
chúng tôi bao gồm xử lý các kiểu đa phương tiện khác nhau, chẳng hạn như trang web, bài báo học thuật và
tài liệu PDF. Chúng tôi cũng đang khám phá các định dạng bổ sung, chẳng hạn như những định dạng hoàn
toàn văn bản, điều này là không thể thiếu cho việc huấn luyện các mô hình ngôn ngữ lớn. Ví dụ, RedPajama-
Data-v2 [16] đã đạt đến con số đáng kinh ngạc 30 nghìn tỷ token. Do đó, chúng tôi sẽ mô tả chi tiết cách
chúng tôi sản xuất hàng loạt dữ liệu theo định dạng của chúng tôi trong phần 3.2.
Hỗ trợ các chiến lược huấn luyện đa dạng. Đầu tiên, định dạng bộ dữ liệu của chúng tôi được thiết kế để
bao gồm tất cả các phương pháp tiền huấn luyện hiện có. Do đó, nó áp dụng định dạng ghép cặp và xen kẽ,
kết hợp các phần cho văn bản (tệp markdown) và hình ảnh (hình ảnh tổng thể). Sự phân chia thành các khu
vực văn bản và hình ảnh này cho phép áp dụng liền mạch tất cả các mục tiêu tiền huấn luyện dựa trên cặp
hình ảnh-văn bản hiện tại. Ngoài ra, xem xét định dạng xen kẽ trong các phần văn bản, bộ dữ liệu của chúng
tôi cũng có thể phù hợp với các mục tiêu tiền huấn luyện được thiết kế mới từ các mô hình như Flamingo
[1]. Hơn nữa, chúng tôi được trang bị để hỗ trợ các chiến lược huấn luyện đa dạng hơn, chẳng hạn như trích
xuất kiến thức dựa trên hình ảnh. Giải thích chi tiết sẽ được cung cấp trong Phần 5.
3.1.2. Cấu trúc Ghép cặp và Xen kẽ
Để phù hợp với triết lý của chúng tôi, chúng tôi thiết kế một cấu trúc ghép cặp và xen kẽ, như mô tả trong
Hình 1 (b). Chúng tôi bây giờ hiển thị cách bộ dữ liệu này được lưu trữ và giải thích ý nghĩa của các thẻ chú
thích khác nhau.
example_dataset/
|
|-- content_image/
| |-- 1.png
| |-- 2.png
| |-- 3.png
| ...
|-- overall_image/
| |-- 1.png
| |-- 2.png
| |-- 3.png
| ...
\-- example_dataset.jsonl
(a) Cấu trúc của bộ dữ liệu ví dụ.example_dataset/
|
|-- part00/ - Phần đầu tiên.
| |-- content_image/
| |-- overall_image/
| \-- part00.jsonl
|
|-- part01/ - Phần thứ hai.
| |-- content_image/
| |-- overall_image/
| \-- part01.jsonl
|
... - Nhiều phần tương tự khác.
(b) Cấu trúc phân đoạn của bộ dữ liệu ví dụ.
Hình 2|Cấu trúc cây tệp của một bộ dữ liệu ví dụ theo định dạng PIN.
Kiến trúc của cấu trúc dữ liệu được đề xuất của chúng tôi được mô tả trong Hình 2. Thư mục "content images"
chứa các hình ảnh được đề cập trong văn bản markdown, và "overall images" hiển thị biểu diễn hình ảnh tổng
thể của các tệp markdown. Hơn nữa, tệp JSONL bao bọc nội dung văn bản cùng với
5

--- TRANG 6 ---
PIN: Một Bộ dữ liệu Chuyên sâu Kiến thức cho Tài liệu Đa phương tiện Ghép cặp và Xen kẽ(Phiên bản Xem trước)
1{
2 "id": 1919,
3 "meta": {
4 "language": "en",
5 "oi_exist": true,
6 "oi_source": "compiling",
7 "source_dateset": "example_source (e.g. OBELICS)",
8 "ori_meta": {
9 "document_url": "https://www.example.com/2022/02/21/example/",
10 ...
11 }
12 },
13 "doc_id": 1997,
14 "page_id": 0,
15 "date_download": "2024-03-01"
16 },
17 "license": "CC-BY-4.0",
18 "quality_signals": {
19 "doc_length": 100,
20 ...
21 },
22 "content_image": [
23 "content_image/1997-0.png",
24 "content_image/1997-1.png"
25 ],
26 "md": "<img src= 'content_image/1997-0.png '>\n\nThis is a fake sample data line, just
↩→for show.\n\nThis is a fake sample data line, just for show.\n\n<img src= '
↩→content_image/1997-1.png '>\n\nThis is a fake sample data line, just for show.",
27 "overall_image": "overall_image/1997.png"
28}
Hình 3|Một ví dụ mẫu dữ liệu của tệp JSONL.
các chi tiết dữ liệu liên quan. Đặc biệt, nếu tập con lớn, chúng tôi xem xét cấu trúc phần phụ, được hiển thị
trong Hình 2b.
Như minh họa trong Hình 3, chúng tôi cung cấp một ví dụ chi tiết về các chú thích được bao gồm với mỗi
mục dữ liệu. Cụ thể, siêu dữ liệu cho mỗi tài liệu đa phương tiện được mô tả chi tiết trong trường meta.
Điều này bao gồm ngôn ngữ, được ký hiệu là tiếng Trung (zh) và tiếng Anh (en). Đối với các mục có nguồn
gốc từ các bộ dữ liệu hiện có, siêu dữ liệu gốc được giữ lại dưới ori_meta. Nguồn của hình ảnh tổng thể
được chỉ định trong oi_source, với nguồn gốc được chỉ ra là từ bộ dữ liệu gốc (ori) hoặc được biên dịch
bằng mã (compiling). Hơn nữa, chúng tôi giới thiệu thẻ quality_signals, lưu trữ các chỉ số được sử dụng
cho kiểm soát chất lượng, chẳng hạn như độ dài tài liệu. Những tín hiệu này cho phép bộ dữ liệu được phân
đoạn theo nhu cầu hoạt động cụ thể, cho phép lọc nhanh để cô lập các tập con dữ liệu cần thiết.

3.2. Xử lý Dữ liệu
Bộ dữ liệu PIN của chúng tôi bao gồm hai thành phần chính: các bộ dữ liệu chúng tôi đã xây dựng và các bộ
dữ liệu hiện có mà chúng tôi đã chuyển đổi. Chi tiết, các bộ dữ liệu được xây dựng của chúng tôi hiện tại
bao gồm PIN-webpage, PIN-PMC và PIN-arXiv. Hơn nữa, các bộ dữ liệu hiện có được chuyển đổi là: DocLayNet,
Linux-CN, chinese-markdown, OBELICS, MMC4, leetcode và PG19. Tuy nhiên, bộ dữ liệu PIN-14M được phát
hành không bao gồm hai trong số các tập con chúng tôi đã thu thập: PIN-webpage và arXiv. Như minh họa
trong Hình 4, chúng tôi trình bày một mẫu từ mỗi tập con của bộ dữ liệu PIN-14M. Như hiển thị trong Hình
5, chúng tôi xử lý dữ liệu đã thu thập thành định dạng PIN được thiết kế. Các bước ban đầu bao gồm xử lý
văn bản và hình ảnh thô từ
6

--- TRANG 7 ---
PIN: Một Bộ dữ liệu Chuyên sâu Kiến thức cho Tài liệu Đa phương tiện Ghép cặp và Xen kẽ(Phiên bản Xem trước)
PIN-arXiv PIN-PMC
chinese -markdown OBELICS
DocLayNet
Markdown Markdown
Linux -CN
MMC4 PG19
Markdown
 Markdown
Markdown
 Markdown
 Markdown
 Markdown
Hình 4|Mẫu từ các tập con khác nhau của bộ dữ liệu PIN-14M. Đối với mỗi tập con, một mục được
trích xuất, thể hiện cả phần tệp markdown và hình ảnh tổng thể tương ứng.
Hình 5|Tổng quan về quy trình làm việc xử lý của chúng tôi.
bộ dữ liệu, bao gồm làm sạch dữ liệu và tải xuống hình ảnh. Tiếp theo, nội dung này được biên dịch thành
các tệp markdown. Giai đoạn tiếp theo tập trung vào việc trích xuất từ các tài liệu đa phương tiện hoặc biên
dịch hình ảnh tổng thể dựa trên đặc điểm của các bộ dữ liệu. Cuối cùng, các tệp markdown và hình ảnh tổng
thể được kết hợp thành định dạng PIN của chúng tôi. Trong thực tế, mỗi tập con được điều chỉnh với các
quy trình làm việc xử lý cụ thể được thiết kế để nâng cao và tận dụng các đặc điểm dữ liệu độc đáo. Những
quy trình làm việc này được mô tả chi tiết như sau:
•Tài liệu khoa học đa phương tiện: văn bản đánh dấu, dữ liệu đồ họa và tệp PDF.
•Tài liệu đa phương tiện có chú thích: thông tin chú thích, hình ảnh và tệp PDF.
•Trang web: văn bản và hình ảnh xen kẽ.
•Tài liệu chỉ có văn bản: chỉ có văn bản.
3.2.1. Tài liệu Khoa học Đa phương tiện
PIN-arXiv. ArXiv2 là một nền tảng tiền ấn phẩm điện tử phổ biến bao gồm một phổ rộng các ngành học bao
gồm vật lý, toán học, khoa học máy tính, sinh học định lượng, tài chính định lượng, thống kê, kỹ thuật điện,
khoa học hệ thống và kinh tế. Do đó, chúng tôi thu thập các tài liệu đa phương tiện chuyên sâu kiến thức từ
đó. Quy trình xử lý dữ liệu trên nền tảng này được mô tả trong Hình 6, và bao gồm các bước sau:
2https://arxiv.org/
7

--- TRANG 8 ---
PIN: Một Bộ dữ liệu Chuyên sâu Kiến thức cho Tài liệu Đa phương tiện Ghép cặp và Xen kẽ(Phiên bản Xem trước)
Hình 6|Quy trình xử lý dữ liệu của tập con PIN-arXiv.
Hình 7|Quy trình xử lý dữ liệu của tập con PIN-PMC.
1.Thu thập Dữ liệu: Trong giai đoạn ban đầu, chúng tôi thu thập mã nguồn và tài liệu PDF từ các trang
web, đặt nền tảng cho việc xử lý thêm.
2.Chuyển đổi Tài liệu: Bằng cách sử dụng bộ chuyển đổi Engrafo3, các tài liệu LaTeX được chuyển
đổi thành các trang web HTML được định dạng đẹp và phản hồi nhanh, nâng cao khả năng truy cập và
sức hấp dẫn thị giác.
3.Phân tích Nội dung: Các đầu ra HTML sau đó được xử lý thông qua trình phân tích trong NOUGAT
[7], chuyển đổi nó thành định dạng markdown chỉ có văn bản.
4.Khôi phục Thông tin Đa phương tiện: Để giải quyết việc mất dữ liệu đa phương tiện trong đầu ra
chỉ có văn bản, một thuật toán khớp được áp dụng để tích hợp lại thông tin hình ảnh và văn bản quan
trọng từ HTML trở lại vào các tệp markdown.
5.Xử lý Hình ảnh Tổng thể: Mỗi trang của tài liệu PDF gốc được chuyển đổi thành hình ảnh bằng cách
sử dụng thư viện pdf2image4.
6.Biên dịch Bộ dữ liệu: Các tệp markdown và hình ảnh được biên dịch thành một bộ dữ liệu theo định
dạng PIN. Cụ thể, mỗi mẫu trong bộ dữ liệu bao gồm một tệp markdown kèm theo một số hình ảnh
tổng thể.
Sau khi xử lý dữ liệu, chúng tôi tạo ra một bộ dữ liệu đa phương tiện quy mô lớn, tập con PIN-arXiv, bao
gồm hơn một triệu mẫu. Bộ dữ liệu chưa được phân trang do nỗ lực thủ công rộng lớn cần thiết bởi việc
thiết kế thuật toán phân trang dựa trên văn bản. Ví dụ, bố cục hai cột trong một số tệp PDF có thể cản trở
sự căn chỉnh giữa hình ảnh tổng thể và nội dung markdown. Tuy nhiên, chúng tôi dự định triển khai phân
trang sau khi phát triển một mô hình dựa trên AI phù hợp.
PIN-PMC. PubMed Central (PMC)5 là một kho lưu trữ kỹ thuật số miễn phí chứa các bài báo học thuật truy
cập mở từ các tạp chí y sinh học và khoa học sự sống. Tất cả các bài báo được lưu trữ ở định dạng XML có
thể đọc được bằng máy, với các phiên bản PDF tương ứng có sẵn để truy cập. Với nội dung phong phú của
XML, bao gồm các kiểu và các yếu tố khác, trọng tâm của chúng tôi vẫn chỉ tập trung vào kiến thức được
nhúng. Như minh họa trong Hình 7, chúng tôi thiết kế một loạt thuật toán và các bước xử lý. Ban đầu, chúng
tôi thích ứng thư viện s2orc-doc2json6 cho việc chuyển đổi từ XML sang JSON, đảm bảo trích xuất toàn
diện kiến thức cần thiết. Cụ thể, chúng tôi cải thiện mã gốc bằng cách xử lý tham chiếu, hình ảnh và bảng.
Tiếp theo, chúng tôi phân tích các tệp JSON thành các tệp markdown, tích hợp các đoạn kiến thức khác biệt
thành một tài liệu thống nhất. Cuối cùng, chúng tôi chuyển đổi các tệp PDF đã thu thập thành hình ảnh tổng
thể và tích hợp chúng với văn bản markdown đã xử lý thành định dạng PIN. Trong bản phát hành xem trước
của bộ dữ liệu mã nguồn mở PIN-14M, chúng tôi cung cấp 99.157 mẫu công khai. Dữ liệu còn lại sẽ được
phát hành dần dần trong các phiên bản tiếp theo của bộ dữ liệu PIN.
3https://github.com/arxiv-vanity/engrafo
4https://github.com/Belval/pdf2image
5https://www.ncbi.nlm.nih.gov/pmc/
8

--- TRANG 9 ---
PIN: Một Bộ dữ liệu Chuyên sâu Kiến thức cho Tài liệu Đa phương tiện Ghép cặp và Xen kẽ(Phiên bản Xem trước)
3.2.2. Tài liệu Đa phương tiện Có chú thích
DocLayNet. Các tệp PDF chung trong bộ dữ liệu DocLayNet [17] chứa một kho tàng thông tin kỹ thuật số,
đặc biệt phong phú về chi tiết văn bản và kiểu dáng. Bộ dữ liệu này bao gồm nhiều chú thích chuyên gia,
với các tệp JSON cung cấp vị trí hộp giới hạn và nội dung của những hộp này (chẳng hạn như hình ảnh và
văn bản) trên các trang. Lấy cảm hứng từ trình tự mà con người đọc các tệp PDF, chúng tôi phát triển một
trình phân tích JSON-sang-markdown đơn giản và chuyển đổi các trang PDF tương ứng thành hình ảnh. Cuối
cùng, chúng tôi tích hợp chúng vào tập con DocLayNet với 68.757 mẫu.
3.2.3. Trang web
Linux-CN. Internet lưu trữ nhiều diễn đàn kỹ thuật và học thuật nơi mọi người chia sẻ một loạt các công
nghệ và kinh nghiệm, thể hiện kiến thức rộng lớn. Do đó, cộng đồng Linux-CN đã được bao gồm trong bộ
dữ liệu của chúng tôi. Với sự sẵn có của kho lưu trữ của họ7, chỉ cần tổ chức lại tất cả các bài viết và cấu
trúc tệp để tạo ra các tệp markdown theo định dạng GitHub Flavored Markdown (GFM). Các tệp này sau đó
được hiển thị bằng trình duyệt với kiểu sáng GFM, tiếp theo là việc chụp ảnh màn hình để tạo ra hình ảnh
tổng thể. Cuối cùng, việc định dạng nội dung này thành định dạng PIN hoàn thành tập con Linux-CN với
9.564 tài liệu.
Chinese-markdown. Các trang web thường chứa các tài liệu được cấu trúc sẵn bằng cú pháp Markdown.
Những tài liệu này chủ yếu bao gồm văn bản được đánh dấu rộng rãi và hình ảnh, như được thấy trong các
blog. Để giải quyết tình huống phổ biến này, chúng tôi sử dụng bộ dữ liệu chinese-markdown8, thu thập
nội dung văn bản dựa trên đánh dấu từ các trang web. Ban đầu, chúng tôi trích xuất liên kết hình ảnh để
tải xuống. Tiếp theo, chúng tôi thực hiện làm sạch cơ bản văn bản. Xem xét sự phức tạp của việc phân trang
văn bản dựa trên đánh dấu, chẳng hạn như gặp các khối mã trải dài hai trang, đặc điểm này có thể phá vỡ
tổ chức nội dung. Do đó, chúng tôi sử dụng trình duyệt để hiển thị nội dung bằng kiểu sáng GFM và sau đó
chụp ảnh màn hình làm hình ảnh tổng thể. Cuối cùng, chúng tôi kết hợp các tài liệu markdown và hình ảnh
tổng thể để tạo ra định dạng PIN, hình thành tập con chinese-markdown với 168.323 mẫu.
OBELICS. Bộ dữ liệu OBELICS [10] xử lý dữ liệu web thành các tài liệu đa phương tiện với văn bản và hình
ảnh xen kẽ, và cho thấy hiệu quả của cấu trúc dữ liệu của nó. Xem xét tính năng xen kẽ cố hữu của bộ dữ
liệu, chúng tôi chỉ cần tổ chức lại cấu trúc bộ dữ liệu để tạo ra các tệp markdown. Vì tất cả văn bản đều
đơn giản không có đánh dấu phức tạp, chúng tôi sử dụng thuật toán phân trang heuristic để phân trang nội
dung markdown (input), dẫn đến việc tạo ra hình ảnh tổng thể. Cụ thể, hàm heuristic, 𝑓page, ước tính ba
tham số chính:
6https://github.com/allenai/s2orc-doc2json
7https://huggingface.co/datasets/linux-cn/archive
8https://huggingface.co/datasets/rojas-diego/chinese-markdown
9

--- TRANG 10 ---
PIN: Một Bộ dữ liệu Chuyên sâu Kiến thức cho Tài liệu Đa phương tiện Ghép cặp và Xen kẽ(Phiên bản Xem trước)
•Số dòng tối đa mỗi trang, 𝑛line
•Số ký tự tối đa mỗi dòng, 𝑛text
•Số dòng mà một hình ảnh chiếm, 𝑛image
Hàm này được tính như:
page list =𝑓page(input,𝑛line,𝑛text,𝑛image), (1)
trong đó page list bao gồm các tệp markdown được phân đoạn. Mỗi tệp từ page list sau đó được biên dịch
thành PDF một trang bằng pandoc9, tiếp theo được chuyển đổi thành hình ảnh qua thư viện pdf2image.
Cuối cùng, mỗi trang markdown và hình ảnh tổng thể tương ứng của nó được biên dịch thành định dạng PIN,
do đó tạo ra một mục trong tập con OBELICS của chúng tôi.
MMC4. Bộ dữ liệu MMC4 [9] đại diện cho một trong những bộ dữ liệu chính theo định dạng xen kẽ. Do đó,
chúng tôi áp dụng một quy trình tương tự như được sử dụng cho tập con OBELICS của chúng tôi. Trong bản
phát hành mã nguồn mở PIN-14M hiện tại, chúng tôi chỉ xử lý phân đoạn mmc4-core-ff, kết quả là tập con
MMC4 của chúng tôi, bao gồm khoảng 5.351.628 bản ghi.
PIN-webpage. Chúng tôi thu thập các trang web từ một số trang web có thể truy cập công khai và tuân thủ
một quy trình thu thập, làm sạch và lọc dữ liệu tương tự như được sử dụng trong OBELICS [10]. Sau đó
chúng tôi áp dụng thuật toán phân trang tương tự và mã trong quy trình xử lý dữ liệu của tập con OBELICS.
Kết quả là, chúng tôi tạo ra một tập con được gọi là PIN-webpage.
3.2.4. Tài liệu chỉ có văn bản
Leetcode. Dữ liệu văn bản, không có nội dung hình ảnh, vẫn có thể bao gồm kiến thức rộng lớn. Do đó,
các tình huống chỉ liên quan đến văn bản được kết hợp vào bộ dữ liệu của chúng tôi. Chúng tôi sử dụng bộ
dữ liệu leetcode10 như một ví dụ do việc sử dụng toàn diện các yếu tố văn bản phong phú như đoạn mã,
nhấn mạnh thông qua in đậm và gạch chân, vượt ra ngoài văn bản đơn giản. Chi tiết, bộ dữ liệu trải qua
một quá trình tổ chức lại có hệ thống thành các tài liệu markdown. Sau đó, chúng tôi áp dụng phương pháp
xử lý tương tự trong tập con Linux-CN để tạo ra hình ảnh tổng thể. Bước cuối cùng bao gồm định dạng các
tài liệu này thành tập con leetcode với 2.360 mẫu.
PG19. Bộ dữ liệu PG19 [18] bao gồm các cuốn sách, được định dạng dưới dạng văn bản đơn giản không có
hình ảnh nào, và được đặc trưng bởi các văn bản dài bất thường, với độ dài trung bình gần 400.000 ký tự.
Để tạo điều kiện cho việc huấn luyện mô hình và cho phép học hiệu quả các kỹ thuật phân trang, chúng tôi
phân đoạn các văn bản rộng lớn thành các trang có thể quản lý được. Tương tự như quy trình của tập con
OBELICS, chúng tôi ước tính số ký tự mà mỗi trang có thể chứa và chia toàn bộ tài liệu thành nhiều trang,
một số mở rộng hơn một trăm trang. Mỗi trang, cùng với văn bản tương ứng của nó, sau đó được coi là một
mục riêng biệt. Tóm lại, chúng tôi thu thập 2.612.285 mẫu để tạo thành tập con PG19.

3.3. Kiểm soát Chất lượng
Dựa trên thiết kế bộ dữ liệu RedPajama-Data-v2 [16], chúng tôi giới thiệu các tín hiệu chất lượng vào định
dạng PIN. Mặc dù quy mô rộng lớn của các bộ dữ liệu đa phương tiện, thường vượt quá hàng tỷ mục, người
dùng thường có hiểu biết hạn chế về các thuộc tính nội tại của chúng. Việc làm sạch trước và xử lý trước
rộng rãi thường được yêu cầu trước khi những bộ dữ liệu này có thể được áp dụng trong việc huấn luyện
mô hình. Để giảm bớt nhiệm vụ lặp đi lặp lại này cho mỗi người dùng, chúng tôi triển khai các tín hiệu chất
lượng để nhanh chóng làm quen các nhà nghiên cứu với dữ liệu của chúng tôi. Những tín hiệu này phục vụ
như các công cụ hiệu quả để xác định và lọc ra chất lượng thấp
9https://pandoc.org/
10https://huggingface.co/datasets/greengerong/leetcode
10

--- TRANG 11 ---
PIN: Một Bộ dữ liệu Chuyên sâu Kiến thức cho Tài liệu Đa phương tiện Ghép cặp và Xen kẽ(Phiên bản Xem trước)
2612285 , 19%
5795198 , 41%5351628 , 38%168323 , 1%
2360 , 0%
9564 , 0%
68757 , 0%99157 , 1%pg19
OBELICS
mmc4-core-ff
chinese-markdown
leetcode
linux-cn
DocLayNet
PIN-PMC2608029 , 17%
5770432 , 39%5277983 , 35%167989 , 1%
2360 , 0%9564 , 0%
69375 , 1%
1074799 , 7%
0, 0%
5840658 , 37%9014579 , 58%106768 , 1%
0, 0% 38960 , 0%
90259 , 1%
454482 , 3%
Tài liệu: 14.107.272 Hình ảnh tổng thể: 14.980.531 Hình ảnh nội dung: 15.545.706
Hình 8|Thống kê chung của bộ dữ liệu PIN-14M của chúng tôi.
hoặc dữ liệu không liên quan. Bằng cách giảm thiểu nhiễu, chúng nâng cao chất lượng tổng thể của bộ dữ
liệu, điều này rất quan trọng cho việc huấn luyện các mô hình học máy mạnh mẽ. Hơn nữa, các chỉ số chất
lượng rõ ràng nâng cao tính minh bạch trong xử lý dữ liệu. Chúng cho phép người dùng dễ dàng hiểu được
thành phần và hạn chế của bộ dữ liệu, có khả năng hỗ trợ các nhà nghiên cứu và nhà phát triển đưa ra quyết
định sáng suốt hơn. Trong các ứng dụng thực tế, người dùng có thể phân tầng hoặc nhóm dữ liệu dựa trên
những tín hiệu chất lượng này. Họ ưu tiên dữ liệu chất lượng cao trong khi áp dụng các chiến lược khác biệt
cho dữ liệu chất lượng thấp, chẳng hạn như làm sạch bổ sung hoặc loại trừ. Trong bản phát hành sơ bộ,
PIN-14M, chúng tôi đã kết hợp một số tín hiệu chất lượng cơ bản, với kế hoạch mở rộng chúng trong các bản
cập nhật tương lai.

3.4. Cân nhắc Đạo đức
Với các nguồn đa dạng của bộ dữ liệu của chúng tôi và các quy trình phức tạp liên quan, mỗi mẫu trong bộ
dữ liệu của chúng tôi đi kèm với một trường giấy phép chỉ định các điều khoản cấp phép của dữ liệu. Nếu
dữ liệu được sản xuất nội bộ hoặc bao gồm các thành phần do chúng tôi tạo ra, chẳng hạn như hình ảnh tổng
thể được biên dịch, nó sẽ tuân theo giấy phép Apache 2.011.
Hơn nữa, chúng tôi loại bỏ hình ảnh NSFW khỏi các bộ dữ liệu tự thu thập của chúng tôi. Tuy nhiên, với khối
lượng lớn của các bộ dữ liệu của chúng tôi, chúng tôi khuyến khích cộng đồng tiến hành các cuộc kiểm tra
chi tiết hơn khi sử dụng chúng để đảm bảo tuân thủ các yêu cầu pháp lý tương ứng của họ.
Nếu người dùng có thêm câu hỏi hoặc đề xuất, họ có thể bắt đầu một cuộc thảo luận trên trang Hugging Face
của chúng tôi12. Điều này sẽ cho phép chúng tôi đi sâu hơn vào các vấn đề và nâng cao nội dung bộ dữ liệu
tương ứng.

4. Phân tích PIN
Trong phần này, chúng tôi thực hiện phân tích sơ bộ về bộ dữ liệu mã nguồn mở PIN-14M của chúng tôi.

4.1. Thống kê chung
Như hiển thị trong Hình 8, số lượng tài liệu, hình ảnh tổng thể và hình ảnh nội dung trên mỗi tập con được
cung cấp, cùng với đóng góp của mỗi tập con vào tổng số. Sự khác biệt giữa số lượng tài liệu và hình ảnh
tổng thể xuất phát từ hai yếu tố. Đầu tiên, trong bộ dữ liệu PIN-PMC, việc thiếu phân trang dẫn đến nhiều
hình ảnh tổng thể tương ứng với một tài liệu duy nhất. Thứ hai, một số tập con, sau phân trang, chuyển đổi
các tệp markdown thành hình ảnh tổng thể; quá trình này có thể gây ra lỗi, chẳng hạn như tạo hình ảnh thất
bại, dẫn đến số lượng tài liệu cao hơn so với hình ảnh tổng thể, đáng chú ý trong các tập con như OBELICS
và mmc4-core-ff. Hơn nữa, chúng tôi quan sát thấy trung bình, OBELICS có khoảng 1.01 hình ảnh trên mỗi
hình ảnh tổng thể, trong khi mmc4-ff-core trung bình khoảng 1.71 hình ảnh trên mỗi hình ảnh tổng thể.
Văn bản dày đặc hơn trong OBELICS có thể dẫn đến ít hình ảnh chiếm cùng một không gian so với mmc4-ff-
core, có thể có ít văn bản hơn và do đó mật độ kiến thức thấp hơn. Một phân tích toàn diện hơn sẽ được
cung cấp trong phiên bản tiếp theo.

4.2. Mô hình hóa Chủ đề
Như hiển thị trong Bảng 1, chúng tôi tiến hành các thí nghiệm sử dụng Latent Dirichlet Allocation (LDA)
[19] bằng cách lấy mẫu 100.000 tài liệu để minh họa phân bố chủ đề trong bộ dữ liệu của chúng tôi, cùng
với tỷ lệ ước tính và các thuật ngữ thường liên kết. Chi tiết, chúng tôi liệt kê 20 chủ đề trong kết quả LDA,
tạo điều kiện cho cả phân tích cấp cao và chi tiết của nội dung. Các chủ đề nổi bật như "Technology and
Quality", "Digital Technology" và "Design and Aesthetics" chiếm ưu thế trong dữ liệu. Hơn nữa, bộ dữ liệu
của chúng tôi bao gồm một loạt chủ đề đa dạng, bao gồm "Music and Celebrations" và "Cooking and Recipes".
11https://www.apache.org/licenses/LICENSE-2.0
12https://huggingface.co/datasets/m-a-p/PIN-14M/discussions
11

--- TRANG 12 ---
PIN: Một Bộ dữ liệu Chuyên sâu Kiến thức cho Tài liệu Đa phương tiện Ghép cặp và Xen kẽ(Phiên bản Xem trước)
Tên Chủ đề Tỷ lệKhông từ khóa
Công nghệ và Chất lượng 12.54mới, hệ thống, sử dụng, được sử dụng, chất lượng, sức mạnh, thiết kế, cao, thời gian,
phạm vi
Công nghệ Kỹ thuật số 8.60 mới, sử dụng, dữ liệu, thời gian, trò chơi, sử dụng, như, nhấp, ứng dụng, cần
Cuộc sống Đô thị 8.87 mới, đầu tiên, năm, hai, thành phố, nhà, thời gian, đội, công ty, năm
Thiết kế và Thẩm mỹ 8.06 thiết kế, làm, tạo, mới, đen, nhìn, như, trắng, phòng,
sử dụng
Chính trị và Xã hội 7.26 nói, người, mới, chính phủ, nhà nước, chúng tôi, thời gian, hai, năm,
có thể
Giải trí và Truyền thông 6.92 thời gian, như, phim, mới, đầu tiên, yêu, sách, cuộc sống, hai, chương trình
Tương tác Chung 5.75 như, thời gian, có, người, thực sự, thậm chí, có thể, mới, biết, thấy
Sức khỏe và Nghiên cứu 5.28 nước, có thể, nhiều, mới, nghiên cứu, thời gian, sức khỏe, tốt, được sử dụng,
người
Nấu ăn và Công thức 4.34 làm, thêm, như, thời gian, công thức, làm, sử dụng, thức ăn, phút,
nước
Hoạt động Trực tuyến 3.15 có, mới, miễn phí, trực tuyến, như, sử dụng, làm, thời gian, trò chơi, tốt nhất
Du lịch và Khách sạn 3.10 công viên, thời gian, mới, như, khách sạn, có, đầu tiên, mất, tuyệt vời, nói
Sự kiện Lịch sử 2.27 mới, tướng, người, chiến tranh, hai, thời gian, năm, đầu tiên, nhà nước, nói
Hoạt động Hàng ngày 1.95 thời gian, có, như, thức ăn, tốt, tuyệt vời, làm, đầu tiên, ngày, đi
Chăm sóc Cá nhân 1.45 da, như, rượu, thời gian, mới, yêu, ngày, đầu tiên, làm, có
Nghệ thuật và Bảo tàng 1.50 nghệ thuật, công việc, tóc, bảo tàng, đầu tiên, như, thời gian, hai, mới, tranh
Dịch vụ Dọn dẹp 0.88 dọn dẹp, xe, có, dịch vụ, thời gian, mới, chúng tôi, nói, thảm, cần
Tường thuật và Đối thoại 0.84 nói, người đàn ông, có thể, thời gian, trên, ít, như, thấy, hai, tốt
Ý kiến Chung 0.55 có thể, thời gian, như, ít, nhiều, tuyệt vời, thấy, hai, đầu tiên, tốt
Âm nhạc và Lễ kỷ niệm 0.55 âm nhạc, đám cưới, như, nói, có, thời gian, tốt, làm, biết,
bass
Không phân loại 0.10 nói, thời gian, thấy, như, có thể, làm, có, ít, chúng tôi, tốt
Bảng 1|Kết quả LDA với 20 chủ đề với tỷ lệ (%), được huấn luyện trên 100.000 tài liệu được lấy mẫu
ngẫu nhiên. Mỗi chủ đề được đặc trưng bởi các khái niệm có nguồn gốc từ các từ khóa liên quan của nó.
12

--- TRANG 13 ---
PIN: Một Bộ dữ liệu Chuyên sâu Kiến thức cho Tài liệu Đa phương tiện Ghép cặp và Xen kẽ(Phiên bản Xem trước)
Trang 1
Hình ảnh tổng thểTÓM TẮT: Diclofenac 
sodium là một thuốc 
chống viêm không 
steroid (NSAIDs) có 
tính chất giảm đau và 
hạ sốt. Do việc sử dụng 
rộng rãi …Nó ức chế tổng hợp 
prostaglandin 8. Nó được 
hấp thụ tốt qua đường 
uống, liên kết protein 99%, 
được chuyển hóa và bài 
tiết cả trong nước tiểu và 
mật. Plasma t½ …Hàm lượng Thuốc của 
Các Thương hiệu Khác 
nhau của Viên Diclofenac 
Sodium 50 mg: Xác định 
hàm lượng thuốc được 
thực hiện theo USP …
Tệp MarkdownTrang 2
…
Nội dung văn bản Hình ảnh nội dung Văn bản Hình ảnh nội dung Văn bản
𝐼1o𝐼2o…𝑇11𝑇21…𝐼1c1𝐼2c1…𝑇12𝑇22…𝐼1c2𝐼2c2…𝑇13𝑇23…Token hóa
Hình 9|Mẫu từ bộ dữ liệu PIN-14M của chúng tôi. Hơn nữa, dữ liệu thô có thể được chuyển đổi thành
token sau khi token hóa.

5. Chiến lược Huấn luyện
Trong phần này, chúng tôi thảo luận về các chiến lược huấn luyện tiềm năng, mô tả chi tiết cách thích ứng
các phương pháp hiện tại và khám phá một số chiến lược mới có thể. Bộ dữ liệu của chúng tôi bao gồm các
tài liệu đa phương tiện có thể được biểu diễn dưới dạng mục đơn lẻ hoặc nhiều mục. Đối với nhiều mục, tích
hợp được thực hiện thông qua các trường doc_id và page_id, đảm bảo không mất thông tin tài liệu tổng
thể. Như hiển thị trong Hình 9, chúng tôi có thể trích xuất các tệp markdown (𝑆𝑜𝑖) và hình ảnh tổng thể
(𝑆𝑚𝑑) từ các mục này. Sau khi token hóa, chúng có thể được biểu diễn như:
𝑆𝑜𝑖={𝐼𝑜
𝑖}|𝑆𝑜𝑖|
𝑖=1(2)
𝑆𝑚𝑑={𝑇1
𝑖}|𝑇1|
𝑖=1{𝐼𝑐1
𝑖}|𝐼𝑐1|
𝑖=1{𝑇2
𝑖}|𝑇2|
𝑖=1{𝐼𝑐2
𝑖}|𝐼𝑐2|
𝑖=1{𝑇2
𝑖}|𝑇2|
𝑖=1... (3)
Để giải thích các chiến lược huấn luyện một cách hiệu quả, chúng tôi sử dụng phương pháp token hóa được
sử dụng rộng rãi. Tuy nhiên, đây không nhất thiết là cách tiếp cận tốt nhất cho tiền xử lý. Thay vào đó, việc
xử lý trực tiếp các pixel hình ảnh có thể được xem xét, điều này sẽ loại bỏ nhu cầu về token hình ảnh.

5.1. Dựa trên Cặp Hình ảnh-văn bản
Học Đối lập (CL). Khái niệm cốt lõi là tối ưu hóa mô hình, cho phép nó hiểu và căn chỉnh các phương thức
khác nhau [13,20]. Cụ thể, các cặp hình ảnh-văn bản tương ứng được kéo gần nhau trong một không gian
nhúng được chia sẻ, trong khi các cặp không tương ứng được đẩy xa hơn. Ví dụ, CLIP sử dụng hàm mất mát
đối lập tích hợp thông tin từ cả cặp hình ảnh-tới-văn bản (𝑖2𝑡) và văn bản-tới-hình ảnh (𝑡2𝑖). Hàm mất
mát cụ thể có thể được biểu diễn như sau:
L𝑖2𝑡=−1
𝑁𝑁∑︁
𝑖=1logexp(𝑥𝑇
𝑖𝑦𝑖/𝜎)
Í𝑁
𝑗=1exp(𝑥𝑇
𝑖𝑦𝑗/𝜎), (4)
L𝑡2𝑖=−1
𝑁𝑁∑︁
𝑖=1logexp(𝑦𝑇
𝑖𝑥𝑖/𝜎)
Í𝑁
𝑗=1exp(𝑦𝑇
𝑖𝑥𝑗/𝜎), (5)
trong đó 𝑁 là số lượng cặp hình ảnh-văn bản, 𝑥𝑖 và 𝑥𝑗 là các vectơ đặc trưng của hình ảnh thứ 𝑖 và thứ 𝑗,
tương ứng, 𝑦𝑖 và 𝑦𝑗 là các vectơ đặc trưng của các văn bản tương ứng. Hơn nữa, 𝜎 là tham số nhiệt độ.
exp biểu thị hàm mũ, và log biểu thị hàm logarit. Những hàm mất mát này nhằm tối đa hóa sự tương đồng
giữa các cặp hình ảnh-văn bản khớp (𝑥𝑖,𝑦𝑖) trong khi giảm thiểu sự tương đồng giữa các cặp không khớp
(𝑥𝑖,𝑦𝑗) và (𝑦𝑖,𝑥𝑗). Hơn nữa, mất mát tổng thể là:
L𝐶𝐿=L𝑖2𝑡+L𝑡2𝑖 (6)
13

--- TRANG 14 ---
PIN: Một Bộ dữ liệu Chuyên sâu Kiến thức cho Tài liệu Đa phương tiện Ghép cặp và Xen kẽ(Phiên bản Xem trước)
Trong định dạng PIN, chúng tôi có thể thay thế vectơ 𝑦 bằng vectơ đa phương tiện tổng thể từ 𝑆𝑚𝑑, và 𝑥
là đặc trưng tổng thể của 𝑆𝑜𝑖. Điều này cho phép mô hình học các kết nối đa phương tiện sâu hơn bằng cách
xem xét các mối quan hệ giữa các vectơ hình ảnh tổng thể và các vectơ hình ảnh-văn bản hỗn hợp. Hơn nữa,
khi việc có được vectơ tổng thể 𝑆𝑚𝑑 là thách thức, chúng tôi có thể xem xét hai tập hợp học đối lập: (hình
ảnh tổng thể, văn bản dựa trên đánh dấu) và (hình ảnh tổng thể, hình ảnh nội dung).
Ghép nối Hình ảnh-Văn bản (ITM). Tương tự như CL, ITM tận dụng sự căn chỉnh cố hữu của dữ liệu đa
phương tiện cho tiền huấn luyện [21]. Sự khác biệt chính là ITM sử dụng mất mát cross-entropy để xác định
liệu một cặp hình ảnh và văn bản cho trước có được căn chỉnh hay không.
Trong định dạng PIN, chúng tôi có thể sử dụng một cặp 𝑆𝑚𝑑 và 𝑆𝑜𝑖. Vì hình ảnh thường chiếm một số lượng
lớn token, chúng tôi có thể loại bỏ thành phần hình ảnh của 𝑆𝑚𝑑 để tăng độ khó của nhiệm vụ ITM.
Mô hình hóa Ngôn ngữ Che (MLM) và Mô hình hóa Thị giác Che (MVM). Cả hai nhiệm vụ đều liên quan
đến việc che một số token và sử dụng thông tin còn lại để tái tạo các phần bị che [15,22]. Đối với MLM,
các phân đoạn khác nhau hoặc các phần liên tục của 𝑆𝑚𝑑 có thể bị che. Đối với MVM, trong 𝑆𝑜𝑖, chúng tôi
có thể che ngẫu nhiên các vùng, khu vực hoặc đối tượng được phát hiện khác nhau. Để ngăn chặn rò rỉ thông
tin, điều quan trọng là phải đồng bộ hóa hoặc loại bỏ các thành phần hình ảnh từ 𝑆𝑚𝑑.

5.2. Dựa trên Tài liệu Xen kẽ
Flamingo mô hình hóa khả năng của văn bản có điều kiện trên các chuỗi xen kẽ của token văn bản và đầu
vào hình ảnh (hình ảnh/video) [1]. Nó sử dụng một mục tiêu tạo cross-modal, đó là huấn luyện mô hình dự
đoán token văn bản tiếp theo dựa trên các token trước đó và ngữ cảnh hình ảnh. Mục tiêu huấn luyện có thể
được biểu hiện như:
Lcross-modal =−𝑇∑︁
𝑡=1log𝑃(𝑤𝑡|𝑤<𝑡,𝑉), (7)
trong đó 𝑤𝑡 đại diện cho token thứ 𝑡 trong chuỗi văn bản, và 𝑤<𝑡 đại diện cho tất cả các token trước đó
trong chuỗi văn bản. 𝑉 đại diện cho các đầu vào hình ảnh (đặc trưng được trích xuất từ hình ảnh hoặc video).
Trong định dạng PIN, chúng tôi có thể chỉ cần huấn luyện các mô hình trực tiếp sử dụng phần xen kẽ (𝑆𝑚𝑑).

5.3. Chiến lược Tiềm năng
Vì định dạng của chúng tôi bao gồm thông tin phong phú, chúng tôi có thể xem xét chỉ sử dụng một phần
của nó cho tiền huấn luyện. Ví dụ, chúng tôi có thể tiền huấn luyện một mô hình mạnh mẽ hiểu hình ảnh
giàu văn bản bằng cách chỉ tập trung vào phần hình ảnh tổng thể. Ngoài ra, chúng tôi có thể sử dụng phần
tệp markdown xen kẽ (𝑆𝑚𝑑) cho các nhiệm vụ tiền huấn luyện tiếp theo như dự đoán modal và dự đoán
token tiếp theo đa phương tiện.
Dự đoán Modal. Nó liên quan đến việc xác định liệu phân đoạn tiếp theo trong một chuỗi xen kẽ của văn
bản và hình ảnh nên là văn bản hay hình ảnh, dựa trên nội dung trước đó. Nhiệm vụ này tận dụng ngữ cảnh
đã biết để đưa ra dự đoán chính xác. Một ứng dụng thực tế liên quan đến việc sử dụng dữ liệu đối thoại đa
phương tiện, vốn dĩ bao gồm cả văn bản và hình ảnh. Nhiệm vụ tiền huấn luyện tập trung vào việc dự đoán
nội dung và định dạng của các cuộc đối thoại tiếp theo.
Dự đoán Token Tiếp theo Đa phương tiện (MNTP). Mục tiêu là coi tất cả dữ liệu modal, bao gồm hình ảnh
và văn bản, như token, chẳng hạn như 𝑆𝑚𝑑. Cách tiếp cận này cho phép token được dự đoán tiếp theo có
thể là văn bản hoặc hình ảnh, nâng cao tính đa dạng của dự đoán.
Dự đoán Phân trang (PP). Chúng tôi có thể sử dụng doc_id và page_id để xác định vị trí của mỗi trang
trong tài liệu tổng thể. Điều này cho phép chúng tôi gán các token đặc biệt cho các tập con dữ liệu trong
quá trình phân trang, do đó kết hợp nhiều phần dữ liệu. Ví dụ, một tài liệu đa phương tiện (𝑆𝑐𝑜𝑛𝑡𝑒𝑛𝑡) với
hai trang có thể được biểu diễn như sau:
14

--- TRANG 15 ---
PIN: Một Bộ dữ liệu Chuyên sâu Kiến thức cho Tài liệu Đa phương tiện Ghép cặp và Xen kẽ(Phiên bản Xem trước)
𝑆𝑐𝑜𝑛𝑡𝑒𝑛𝑡 =[BOD][BOP] 𝑆𝑝𝑎𝑔𝑒1
𝑚𝑑[EOP][BOP] 𝑆𝑝𝑎𝑔𝑒2
𝑚𝑑[EOP][EOD] , (8)
trong đó [BOD] và [EOD] chỉ ra điểm bắt đầu và kết thúc của tài liệu, tương ứng. Tương tự, [BOP] và [EOP]
biểu thị điểm bắt đầu và kết thúc của mỗi trang. Nhiệm vụ PP yêu cầu mô hình dự đoán vị trí của những
token đặc biệt này kết hợp với hình ảnh tổng thể.
Kết xuất Tài liệu Đa phương tiện (MDR). Nhiệm vụ này tương tự như các nhiệm vụ Tạo Văn bản-tới-Hình
ảnh (TIG) thường được sử dụng trong các mô hình như stable diffusion [23]. Chi tiết, mô hình dự đoán 𝑆𝑜𝑖
bằng cách học thông tin từ 𝑆𝑚𝑑. Tuy nhiên, tình huống của chúng tôi thách thức hơn. Mô hình không chỉ
cần hiểu nội dung văn bản mà còn phải sắp xếp hình ảnh và văn bản một cách thích hợp. Ngoài ra, nó phải
kết xuất các biểu hiện cụ thể của thuộc tính kiến thức, chẳng hạn như văn bản in đậm. Chúng tôi có thể tăng
thêm độ khó của nhiệm vụ này bằng cách loại bỏ tất cả token hình ảnh từ 𝑆𝑚𝑑. Điều này buộc mô hình tạo
ra hình ảnh nội dung phù hợp và đặt chúng ở vị trí thích hợp trong hình ảnh tổng thể.
Trích xuất Kiến thức (KE). Nhiệm vụ này tương tự như Tạo Hình ảnh-tới-Văn bản (ITG) [15] và các nhiệm
vụ Nhận dạng Ký tự Quang học (OCR). ITG yêu cầu các mô hình quan sát hình ảnh tự nhiên và tạo ra văn
bản mô tả, trong khi OCR tập trung vào việc trích xuất văn bản từ hình ảnh cùng với thông tin vị trí của
chúng. Trong nhiệm vụ của chúng tôi, hình ảnh đầu vào là hình ảnh bài viết giàu văn bản (𝑆𝑜𝑖), và đầu ra
là việc trích xuất thông tin kiến thức (𝑆𝑚𝑑) từ những hình ảnh này. Cách tiếp cận này đảm bảo huấn luyện
tự nhiên hơn với độ phức tạp và nhiễu giảm. Ngoài ra, các mô hình được huấn luyện bằng phương pháp này
có thể chuyển đổi liền mạch các bộ sưu tập tài liệu rộng lớn thành các định dạng đa phương tiện xen kẽ.
Điều này tạo điều kiện cho việc tạo ra các quy trình tự lặp, cho phép mô hình tạo dữ liệu và tiếp tục học một
cách tự động.

6. Thảo luận
Chúng tôi đề xuất một định dạng dữ liệu thống nhất tích hợp liền mạch các nhiệm vụ và quy trình huấn luyện
khác nhau. Quy trình xử lý dữ liệu của chúng tôi tính đến các phương thức khác nhau và có thể dễ dàng kết
hợp dữ liệu đơn phương thức chất lượng cao. Tính thống nhất của định dạng dữ liệu của chúng tôi tạo điều
kiện phân tích dễ dàng hơn về các quy luật tỷ lệ cho các nhà nghiên cứu. Trong giai đoạn huấn luyện có
giám sát tiếp theo sau tiền huấn luyện, việc sắp xếp văn bản và hình ảnh xen kẽ của chúng tôi cho phép dễ
dàng bao gồm hướng dẫn và thông tin phụ trợ. Thiết kế này đảm bảo tính nhất quán giữa các nhiệm vụ
upstream và downstream và cho phép mô hình của chúng tôi xử lý các nhiệm vụ zero-shot ngay sau tiền
huấn luyện.
Trong báo cáo kỹ thuật này, quy trình dữ liệu của chúng tôi bao gồm một loạt tình huống đa dạng, phục vụ
cho các bài viết khoa học phức tạp, tệp PDF đa phương tiện, trang web phổ biến và thậm chí cả bối cảnh chỉ
có văn bản. Bằng cách cung cấp các cách tiếp cận xử lý cho công chúng, chúng tôi hy vọng cho phép cộng
đồng đa phương tiện nhanh chóng hiểu và sử dụng bộ dữ liệu trong khi đảm bảo tính minh bạch của dữ liệu.
Hơn nữa, chúng tôi sẽ mở nguồn mã để biên dịch hình ảnh tổng thể. Điều này cho phép người dùng dễ dàng
nâng cao dữ liệu để đáp ứng nhu cầu của họ. Ví dụ, họ có thể điều chỉnh kích thước phông chữ, định dạng,
khoảng cách dòng và kiểu dáng.
Chúng tôi bây giờ sẽ trình bày một số câu hỏi tiềm năng:
Tại sao chúng tôi không chọn định dạng OCR?
Mục tiêu của chúng tôi là để mô hình chỉ tập trung vào bản thân kiến thức, chẳng hạn như ý nghĩa được thể
hiện bởi hình ảnh và khả năng suy luận sâu dựa trên các thuộc tính kiến thức văn bản. Chúng tôi muốn tránh
làm gánh nặng cho mô hình với thông tin vị trí phức tạp cần thiết bởi OCR, chẳng hạn như hiểu các kết hợp
của ranh giới ký tự trong một hình ảnh. Ví dụ, trong một hình ảnh chứa văn bản "APPLE", mô hình chỉ nên
cần hiểu rằng có một từ "APPLE" và không dành tham số và khả năng suy luận để nhận dạng "A", "AP", "APP",
"APPL", hoặc "APPLE", và xử lý các vị trí và ranh giới mà những kết hợp này đại diện. Định dạng như vậy cho
phép mô hình chỉ tập trung vào kiến thức, hiểu biết và suy luận.
Các tệp markdown định dạng PIN có kiểu thống nhất không?
Với sự phổ biến của GitHub Flavored Markdown (GFM), được hỗ trợ rộng rãi bởi các trình duyệt và ứng dụng,
chúng tôi chọn GFM làm kiểu chính của chúng tôi. Cụ thể, chúng tôi sử dụng kiểu sáng GFM để tạo ra hình
ảnh tổng thể. Tuy nhiên, đối với các tài liệu chứa một lượng đáng kể công thức, chẳng hạn như những tài
liệu trong PIN-arXiv, chúng tôi chọn định dạng markdown Mathpix, do hỗ trợ mạnh mẽ cho các ký hiệu học
thuật.
Làm thế nào để xử lý bảng?
Trong việc giải quyết dữ liệu bảng, chúng tôi áp dụng các phương pháp xử lý cụ thể dựa trên độ phức tạp
và kiểu dáng của chúng. Đối với các bảng có thiết kế phức tạp và chuyên biệt, chúng tôi chọn biểu diễn HTML
do khả năng biểu hiện phong phú và hỗ trợ ứng dụng rộng rãi cho kết xuất. Đáng chú ý, các kiểu giống như
bảng LaTeX được tìm thấy trong markdown Mathpix trong các bài báo học thuật được chuyển đổi thành HTML.
Các định dạng bảng đơn giản, chẳng hạn như những định dạng trong GFM, được duy trì ở dạng gốc. Các
bảng được trình bày dưới dạng hình ảnh được bảo tồn ở định dạng gốc, cho phép mô hình phân biệt các mối
quan hệ giữa dữ liệu bảng và nội dung văn bản. Những cách tiếp cận đa dạng này nâng cao tính đa dạng của
bộ dữ liệu của chúng tôi.
Kế hoạch tiếp theo là gì?
Giai đoạn sắp tới liên quan đến việc mở nguồn một bộ dữ liệu quy mô lớn hơn trong vài tháng tới. Nhận thức
được những hạn chế của báo cáo kỹ thuật hiện tại của chúng tôi, chúng tôi cam kết cung cấp một mô tả toàn
diện hơn trong phiên bản tiếp theo của nó.

7. Kết luận
Trong bài báo này, chúng tôi giới thiệu một định dạng dữ liệu đa phương tiện mới, Tài liệu Đa phương tiện
Ghép cặp và Xen kẽ (PIN). Chúng tôi mô tả kỹ lưỡng triết lý thiết kế của chúng tôi và từng bước phát triển
định dạng PIN dựa trên những nguyên tắc này. Ngoài ra, chúng tôi mô tả quy trình xử lý dữ liệu của chúng
tôi, bao gồm bốn loại dữ liệu khác nhau trong các lĩnh vực NLP và đa phương tiện. Chúng tôi cũng đã cung
cấp bộ dữ liệu PIN-14M, bao gồm 8 tập con và mã xử lý của chúng (sắp ra mắt). Mặc dù chúng tôi không
trình bày các thí nghiệm tương ứng, chúng tôi mô tả chi tiết các chiến lược huấn luyện tiềm năng được kích
hoạt bởi cấu trúc dữ liệu mới của chúng tôi. Cuối cùng, chúng tôi giải quyết các câu hỏi thường gặp và cân
nhắc. Chúng tôi dự định phát hành một phiên bản cập nhật của báo cáo kỹ thuật và một bộ dữ liệu lớn hơn
sớm.
Tài liệu tham khảo
[1]Jean-Baptiste Alayrac, Jeff Donahue, Pauline Luc, Antoine Miech, Iain Barr, Yana Hasson, Karel
Lenc, Arthur Mensch, Katherine Millican, Malcolm Reynolds, Roman Ring, Eliza Rutherford,
Serkan Cabi, Tengda Han, Zhitao Gong, Sina Samangooei, Marianne Monteiro, Jacob L. Menick,
Sebastian Borgeaud, Andy Brock, Aida Nematzadeh, Sahand Sharifzadeh, Mikolaj Binkowski,
Ricardo Barreira, Oriol Vinyals, Andrew Zisserman, và Karén Simonyan. Flamingo: một mô hình
ngôn ngữ hình ảnh cho việc học few-shot. Trong Sanmi Koyejo, S. Mohamed, A. Agarwal, Danielle
Belgrave, K. Cho, và A. Oh, biên tập, Advances in Neural Information Processing Systems 35: Annual
Conference on Neural Information Processing Systems 2022, NeurIPS 2022, New Orleans, LA, USA,
November 28 - December 9, 2022, 2022. URL http://papers.nips.cc/paper_files/paper/
2022/hash/960a172bc7fbf0177ccccbb411a7d800-Abstract-Conference.html.
16

--- TRANG 17 ---
PIN: Một Bộ dữ liệu Chuyên sâu Kiến thức cho Tài liệu Đa phương tiện Ghép cặp và Xen kẽ(Phiên bản Xem trước)
[2]Alex Young, Bei Chen, Chao Li, Chengen Huang, Ge Zhang, Guanwei Zhang, Heng Li, Jiangcheng
Zhu, Jianqun Chen, Jing Chang, Kaidong Yu, Peng Liu, Qiang Liu, Shawn Yue, Senbin Yang,
Shiming Yang, Tao Yu, Wen Xie, Wenhao Huang, Xiaohui Hu, Xiaoyi Ren, Xinyao Niu, Pengcheng
Nie, Yuchi Xu, Yudong Liu, Yue Wang, Yuxuan Cai, Zhenyu Gu, Zhiyuan Liu, và Zonghong Dai.
Yi: Mô hình nền tảng mở của 01.ai. CoRR, abs/2403.04652, 2024. doi: 10.48550/ARXIV.
2403.04652. URL https://doi.org/10.48550/arXiv.2403.04652.
[3]Xiang Yue, Yuansheng Ni, Kai Zhang, Tianyu Zheng, Ruoqi Liu, Ge Zhang, Samuel Stevens,
Dongfu Jiang, Weiming Ren, Yuxuan Sun, Cong Wei, Botao Yu, Ruibin Yuan, Renliang Sun,
Ming Yin, Boyuan Zheng, Zhenzhu Yang, Yibo Liu, Wenhao Huang, Huan Sun, Yu Su, và
Wenhu Chen. MMMU: Một đánh giá hiểu biết và suy luận đa phương tiện đa ngành lớn cho
AGI chuyên gia. CoRR, abs/2311.16502, 2023. doi: 10.48550/ARXIV.2311.16502.
URLhttps://doi.org/10.48550/arXiv.2311.16502.
[4]Ge Zhang, Xinrun Du, Bei Chen, Yiming Liang, Tongxu Luo, Tianyu Zheng, Kang Zhu, Yuyang
Cheng, Chunpu Xu, Shuyue Guo, Haoran Zhang, Xingwei Qu, Junjie Wang, Ruibin Yuan,
Yizhi Li, Zekun Wang, Yudong Liu, Yu-Hsuan Tsai, Fengji Zhang, Chenghua Lin, Wenhao
Huang, Wenhu Chen, và Jie Fu. CMMMU: Một đánh giá hiểu biết đa phương tiện đa ngành
lớn tiếng Trung. CoRR, abs/2401.11944, 2024. doi: 10.48550/ARXIV.2401.11944.
URLhttps://doi.org/10.48550/arXiv.2401.11944.
[5]GitHub - kakaobrain/coyo-dataset: COYO-700M: Bộ dữ liệu Cặp Hình ảnh-Văn bản Quy mô Lớn —
github.com. https://github.com/kakaobrain/coyo-dataset. [Truy cập 05-05-2024].
[6]Christoph Schuhmann, Romain Beaumont, Richard Vencu, Cade Gordon, Ross Wightman,
Mehdi Cherti, Theo Coombes, Aarush Katta, Clayton Mullis, Mitchell Wortsman, Patrick
Schramowski, Srivatsa Kundurthy, Katherine Crowson, Ludwig Schmidt, Robert Kaczmarczyk,
và Jenia Jitsev. LAION-5B: một bộ dữ liệu mở quy mô lớn để huấn luyện mô hình hình ảnh-văn
bản thế hệ tiếp theo. Trong Sanmi Koyejo, S. Mohamed, A. Agarwal, Danielle Belgrave, K. Cho,
và A. Oh, biên tập, Advances in Neural Information Processing Systems 35: Annual Conference
on Neural Information Processing Systems 2022, NeurIPS 2022, New Orleans, LA, USA,
November 28 - December 9, 2022, 2022. URL http://papers.nips.cc/paper_files/
paper/2022/hash/a1859debfb3b59d094f3504d5ebb6c25-Abstract-Datasets_
and_Benchmarks.html.
[7]Lukas Blecher, Guillem Cucurull, Thomas Scialom, và Robert Stojnic. Nougat: Hiểu biết quang
học thần kinh cho các tài liệu học thuật. CoRR, abs/2308.13418, 2023.
[8]Tengchao Lv, Yupan Huang, Jingye Chen, Lei Cui, Shuming Ma, Yaoyao Chang, Shaohan Huang,
Wenhui Wang, Li Dong, Weiyao Luo, Shaoxiang Wu, Guoxin Wang, Cha Zhang, và Furu Wei.
Kosmos-2.5: Một mô hình hiểu biết đa phương tiện. CoRR, abs/2309.11419, 2023.
[9]Wanrong Zhu, Jack Hessel, Anas Awadalla, Samir Yitzhak Gadre, Jesse Dodge, Alex
Fang, Youngjae Yu, Ludwig Schmidt, William Yang Wang, và Yejin Choi. Multimodal
C4: một kho ngữ liệu mở, quy mô tỷ của hình ảnh xen kẽ với văn bản. Trong Alice Oh, Tristan
Naumann, Amir Globerson, Kate Saenko, Moritz Hardt, và Sergey Levine, biên tập,
Advances in Neural Information Processing Systems 36: Annual Conference on Neural In-
formation Processing Systems 2023, NeurIPS 2023, New Orleans, LA, USA, December 10
- 16, 2023, 2023. URL http://papers.nips.cc/paper_files/paper/2023/hash/
1c6bed78d3813886d3d72595dbecb80b-Abstract-Datasets_and_Benchmarks.
html.
17

--- TRANG 18 ---
PIN: Một Bộ dữ liệu Chuyên sâu Kiến thức cho Tài liệu Đa phương tiện Ghép cặp và Xen kẽ(Phiên bản Xem trước)
[10]Hugo Laurençon, Lucile Saulnier, Léo Tronchon, Stas Bekman, Amanpreet Singh, Anton
Lozhkov, Thomas Wang, Siddharth Karamcheti, Alexander M. Rush, Douwe Kiela, Matthieu
Cord, và Victor Sanh. OBELICS: một bộ dữ liệu được lọc quy mô web mở của các tài liệu hình
ảnh-văn bản xen kẽ. Trong Alice Oh, Tristan Naumann, Amir Globerson, Kate Saenko, Moritz Hardt,
và Sergey Levine, biên tập, Advances in Neural Information Processing Systems 36: Annual
Conference on Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans,
LA, USA, December 10 - 16, 2023, 2023. URL http://papers.nips.cc/paper_files/
paper/2023/hash/e2cfb719f58585f779d0a4f9f07bd618-Abstract-Datasets_
and_Benchmarks.html.
[11]Soravit Changpinyo, Piyush Sharma, Nan Ding, và Radu Soricut. Conceptual 12m: Đẩy tiền
huấn luyện hình ảnh-văn bản quy mô web để nhận dạng các khái niệm thị giác đuôi dài. Trong CVPR,
trang 3558–3568. Computer Vision Foundation / IEEE, 2021.
[12]Yatai Ji, Junjie Wang, Yuan Gong, Lin Zhang, Yanru Zhu, Hongfa Wang, Jiaxing Zhang, Tetsuya
Sakai, và Yujiu Yang. MAP: mô hình tiền huấn luyện thị giác-ngôn ngữ nhận thức bất định đa
phương tiện. Trong CVPR, trang 23262–23271. IEEE, 2023.
[13]Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal,
Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen Krueger, và Ilya Sutskever.
Học các mô hình thị giác có thể chuyển giao từ giám sát ngôn ngữ tự nhiên. Trong ICML, tập 139 của
Proceedings of Machine Learning Research, trang 8748–8763. PMLR, 2021.
[14]Gukyeong Kwon, Zhaowei Cai, Avinash Ravichandran, Erhan Bas, Rahul Bhotika, và Stefano
Soatto. Mô hình hóa thị giác và ngôn ngữ che cho việc học biểu diễn đa phương tiện. Trong ICLR.
OpenReview.net, 2023.
[15]Haiyang Xu, Ming Yan, Chenliang Li, Bin Bi, Songfang Huang, Wenming Xiao, và Fei Huang.
E2E-VLP: tiền huấn luyện thị giác-ngôn ngữ đầu cuối được tăng cường bởi học thị giác. Trong ACL/IJCNLP
(1), trang 503–513. Association for Computational Linguistics, 2021.
[16]Together Computer. Redpajama: một bộ dữ liệu mở để huấn luyện các mô hình ngôn ngữ lớn. https:
//github.com/togethercomputer/RedPajama-Data, tháng 10 năm 2023.
[17]Birgit Pfitzmann, Christoph Auer, Michele Dolfi, Ahmed S. Nassar, và Peter W. J. Staar. Do-
claynet: Một bộ dữ liệu lớn được chú thích bởi con người để phân tích bố cục tài liệu. CoRR,abs/2206.01062,
2022.
[18]Jack W. Rae, Anna Potapenko, Siddhant M. Jayakumar, Chloe Hillier, và Timothy P. Lillicrap.
Transformers nén cho mô hình hóa chuỗi tầm xa. Trong ICLR. OpenReview.net, 2020.
[19]David M. Blei, Andrew Y. Ng, và Michael I. Jordan. Phân bổ dirichlet tiềm ẩn. J. Mach. Learn.
Res., 3:993–1022, 2003.
[20]Chao Jia, Yinfei Yang, Ye Xia, Yi-Ting Chen, Zarana Parekh, Hieu Pham, Quoc V. Le, Yun-Hsuan
Sung, Zhen Li, và Tom Duerig. Mở rộng quy mô học biểu diễn thị giác và thị giác-ngôn ngữ
với giám sát văn bản nhiễu. Trong ICML, tập 139 của Proceedings of Machine Learning Research,
trang 4904–4916. PMLR, 2021.
[21]Junyang Lin, An Yang, Yichang Zhang, Jie Liu, Jingren Zhou, và Hongxia Yang. Interbert:
Tương tác thị giác-và-ngôn ngữ cho tiền huấn luyện đa phương tiện. CoRR, abs/2003.13198, 2020.
[22]Hao Tan và Mohit Bansal. LXMERT: học biểu diễn bộ mã hóa cross-modality từ transformers. Trong EMNLP/IJCNLP (1), trang 5099–5110. Association for Computational Linguis-
tics, 2019.
[23]Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, và Björn Ommer. Tổng hợp hình ảnh độ phân giải cao với các mô hình khuếch tán tiềm ẩn. Trong CVPR, trang 10674–10685. IEEE,
18

--- TRANG 19 ---
PIN: Một Bộ dữ liệu Chuyên sâu Kiến thức cho Tài liệu Đa phương tiện Ghép cặp và Xen kẽ(Phiên bản Xem trước)
2022.
19

# 2309.11259.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/multilingual/2309.11259.pdf
# Kích thước tệp: 245428 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
arXiv:2309.11259v2  [cs.CL]  21 Mar 2024Các Mô hình Ngôn ngữ Được Huấn luyện Trước Kiểu Sequence-to-Sequence cho Tiếng Tây Ban Nha
Vladimir Araujo1, Maria Mihaela Trusca1, Rodrigo Tufiño2, Marie-Francine Moens1
1LIIR Lab, KU Leuven, Leuven, Belgium
2IDEIAGEOCA, Universidad Politécnica Salesiana, Quito, Ecuador
vladimir.araujo@kuleuven.be
Tóm tắt
Trong những năm gần đây, những tiến bộ đáng kể trong các mô hình ngôn ngữ được huấn luyện trước đã thúc đẩy việc tạo ra nhiều biến thể ngôn ngữ khác tiếng Anh, với sự nhấn mạnh đặc biệt vào các kiến trúc chỉ mã hóa và chỉ giải mã. Trong khi các mô hình ngôn ngữ tiếng Tây Ban Nha dựa trên BERT và GPT đã thể hiện thành thạo trong hiểu biết và tạo sinh ngôn ngữ tự nhiên, vẫn còn thiếu đáng kể các mô hình mã hóa-giải mã được thiết kế rõ ràng cho các tác vụ sequence-to-sequence, nhằm ánh xạ các chuỗi đầu vào để tạo ra các chuỗi đầu ra có điều kiện. Bài báo này đột phá bằng cách giới thiệu việc triển khai và đánh giá các kiến trúc mã hóa-giải mã nổi tiếng được huấn luyện trước độc quyền trên kho dữ liệu tiếng Tây Ban Nha. Cụ thể, chúng tôi trình bày các phiên bản tiếng Tây Ban Nha của BART, T5, và các mô hình kiểu BERT2BERT và đánh giá chúng một cách toàn diện trên nhiều tác vụ sequence-to-sequence khác nhau, bao gồm tóm tắt, trả lời câu hỏi, tách-và-diễn-đạt-lại, đối thoại, và dịch thuật. Kết quả của chúng tôi nhấn mạnh hiệu suất cạnh tranh của tất cả các mô hình, với các mô hình dựa trên BART và T5 nổi bật là những mô hình hàng đầu trên tất cả các tác vụ. Chúng tôi đã công khai tất cả các mô hình cho cộng đồng nghiên cứu để thúc đẩy các khám phá và tiến bộ trong tương lai về NLP tiếng Tây Ban Nha: https://github.com/vgaraujov/Seq2Seq-Spanish-PLMs.
Từ khóa: mô hình tạo sinh, mô hình ngôn ngữ được huấn luyện trước, mô hình sequence-to-sequence, transformer

1. Giới thiệu
Tiếng Tây Ban Nha nằm trong số những ngôn ngữ được sử dụng rộng rãi nhất trên toàn cầu. Thực tế này đã thu hút sự quan tâm của cộng đồng NLP, thúc đẩy các nỗ lực phát triển tài nguyên cho lĩnh vực NLP này. Do đó, một số mô hình ngôn ngữ được huấn luyện trước phù hợp với tiếng Tây Ban Nha đã xuất hiện trong những năm gần đây, chủ yếu sử dụng các kiến trúc chỉ mã hóa (Cañete et al., 2020; De la Rosa et al., 2022; Araujo et al., 2023) và chỉ giải mã (Gutiérrez-Fandiño et al., 2022). Những mô hình này đã thể hiện hiệu suất xuất sắc trong hiểu biết ngôn ngữ tự nhiên trên nhiều tác vụ hạ nguồn (Cañete et al., 2020; Araujo et al., 2022). Tuy nhiên, đã có sự tiến bộ hạn chế trong việc giải quyết các tác vụ xoay quanh việc tạo ra các câu mới phụ thuộc vào đầu vào cho trước, như tóm tắt, trả lời câu hỏi tạo sinh, đối thoại, hoặc dịch thuật.

Các mô hình mã hóa-giải mã chủ yếu phục vụ cho việc giải quyết các tác vụ sequence-to-sequence, và trong những năm gần đây, nhiều kiến trúc đã xuất hiện. Việc huấn luyện trước các mô hình này thường dựa trên toàn bộ kiến trúc transformer (Vaswani et al., 2017) và đòi hỏi các mục tiêu học tập phức tạp hơn so với các mô hình chỉ mã hóa hoặc chỉ giải mã riêng lẻ. Ví dụ, BART (Lewis et al., 2020a) được huấn luyện cụ thể để tái tạo văn bản đã bị làm hỏng có chủ ý, trong khi T5 (Raffel et al., 2020) được thiết kế để thành thạo điền vào các phần văn bản bị thiếu, mô phỏng tình huống các đoạn văn bản đã bị bỏ qua.

Những mô hình này đã được phát triển chủ yếu cho tiếng Anh, và gần đây đã có những nỗ lực huấn luyện trước chúng cho các ngôn ngữ khác tiếng Anh (Kamal Eddine et al., 2021). Thật không may, đối với tiếng Tây Ban Nha, có một sự thiếu hụt đáng kể về các mô hình như vậy có thể có giá trị cho cộng đồng.

Trong bài báo này, với mục tiêu dân chủ hóa các mô hình sequence-to-sequence cho cộng đồng NLP tiếng Tây Ban Nha, chúng tôi giới thiệu BARTO và T5S, là các đối tác tiếng Tây Ban Nha của các mô hình BART và T5. Những mô hình này được huấn luyện trước độc quyền trên kho dữ liệu tiếng Tây Ban Nha, phù hợp với phương pháp tự giám sát của chúng. Chúng tôi cũng giới thiệu các mô hình theo kiểu BERT2BERT (Rothe et al., 2020), sử dụng các mô hình BERT (Devlin et al., 2019) và RoBERTa (Liu et al., 2019) đã được thiết lập tốt cho tiếng Tây Ban Nha làm cơ sở. Ngoài ra, chúng tôi tuyển chọn nhiều tác vụ sequence-to-sequence tiếng Tây Ban Nha, như tóm tắt, trả lời câu hỏi, tách-và-diễn-đạt-lại, đối thoại, và dịch máy, để đánh giá các mô hình của chúng tôi một cách toàn diện.

Kết quả của chúng tôi chứng minh rằng tất cả các mô hình đều hoạt động tốt trên các tác vụ chuẩn được đề xuất. Đặc biệt, BARTO và T5S nổi bật trong các tác vụ tạo sinh văn bản, đặc biệt là với các chuỗi dài, vượt trội hơn các mô hình kiểu BERT2BERT và các đối tác đa ngôn ngữ trong nhiều tác vụ tạo sinh. Hơn nữa, chúng tôi đánh giá hiệu suất của các mô hình trên các tác vụ phân biệt, như phân loại chuỗi và token. Mặc dù hiệu suất của chúng hơi kém so với các mô hình chỉ mã hóa trong một số tác vụ, chúng vẫn đưa ra kết quả rất cạnh tranh. Để tạo điều kiện

--- TRANG 2 ---
cho nghiên cứu trong tương lai và các ứng dụng thực tế trong NLP tiếng Tây Ban Nha, chúng tôi đã công khai những mô hình này.

2. Công trình liên quan
2.1. Các Mô hình Ngôn ngữ Được Huấn luyện Trước Đặc thù Ngôn ngữ

Các mô hình ngôn ngữ được huấn luyện trước đại diện cho một lớp các mô hình ngôn ngữ tiên tiến được huấn luyện thông qua học tự giám sát trên các kho dữ liệu văn bản lớn, làm cho chúng linh hoạt cho nhiều ứng dụng khác nhau. Đáng chú ý, hai mô hình nổi bật là BERT (Devlin et al., 2019), một mô hình chỉ mã hóa, và GPT (Radford and Sutskever, 2018; Radford et al., 2019), một mô hình chỉ giải mã. Những mô hình này đã thiết lập các cơ sở vững chắc cho một loạt các tác vụ NLP trong tiếng Anh.

Nhiều mô hình dựa trên BERT và GPT đặc thù ngôn ngữ đã xuất hiện trong thời gian gần đây. Các ví dụ bao gồm CamemBERT (Martin et al., 2020) được tùy chỉnh cho tiếng Pháp, RobBERT (Delobelle et al., 2020) được thiết kế cho tiếng Hà Lan, FinBERT (Virtanen et al., 2019) cho tiếng Phần Lan, GePpeTto (Mattei et al., 2020) cho tiếng Ý, và một số mô hình khác. Những mô hình này đã liên tục vượt trội so với các đối tác đa ngôn ngữ, làm nổi bật giá trị của sự tồn tại của chúng đối với các tác vụ đặc thù ngôn ngữ.

Trong bối cảnh tiếng Tây Ban Nha, chúng ta thấy BETO (Cañete et al., 2020) và ALBETO (Cañete et al., 2022), lần lượt là mô hình BERT và ALBERT, được huấn luyện trước trên kho dữ liệu SUC (Cañete et al., 2020). Các mô hình BERT khu vực hóa cho các biến thể tiếng Tây Ban Nha (Tellez et al., 2023) dựa trên dữ liệu Twitter. BERTIN (De la Rosa et al., 2022), một mô hình RoBERTa cơ bản được huấn luyện trên phần tiếng Tây Ban Nha được lấy mẫu từ mC4 (Xue et al., 2021). Hơn nữa, MarIA (Gutiérrez-Fandiño et al., 2022) giới thiệu một họ mô hình, bao gồm RoBERTa và GPT-2 được huấn luyện trên kho dữ liệu được thu thập bởi Thư viện Quốc gia Tây Ban Nha. Gần đây hơn, RigoBERTa (Serrano et al., 2022), tuân theo kiến trúc DeBERTa (He et al., 2021) và được huấn luyện với nhiều kho dữ liệu, bao gồm OSCAR (Suárez et al., 2019), SUC, và mC4-es. Tuy nhiên, tồn tại một khoảng trống đáng kể trong việc có sẵn các mô hình mã hóa-giải mã được huấn luyện độc quyền cho tiếng Tây Ban Nha.

2.2. Các Mô hình Ngôn ngữ Được Huấn luyện Trước Sequence-to-Sequence

Một mô hình sequence-to-sequence nhằm ánh xạ một đầu vào có độ dài cố định với một đầu ra có độ dài cố định trong đó độ dài của đầu vào và đầu ra có thể khác nhau (Sutskever et al., 2014). Nó bao gồm một bộ mã hóa, xử lý đồng thời toàn bộ chuỗi đầu vào, và một bộ giải mã, nhận các biểu diễn được tính toán bởi bộ mã hóa và tạo ra chuỗi đầu ra theo cách tự hồi quy. Những mô hình này đã chứng minh có giá trị trong việc giải quyết các tác vụ bao gồm dịch thuật, đối thoại, trả lời câu hỏi, và tóm tắt.

Theo mô hình huấn luyện trước với tự giám sát, một số mô hình đã được đề xuất. Một trong những mô hình đầu tiên là MASS (Song et al., 2019), sử dụng một transformer để tái tạo một chuỗi đầu vào trong đó một khoảng token liên tục được che và được ánh xạ thành một chuỗi gồm các token bị thiếu. Sau đó, T5 (Raffel et al., 2020) đề xuất huấn luyện trước trên một kết hợp đa tác vụ của các tác vụ có giám sát và tự giám sát, tác vụ sau là một tác vụ hoàn thành điền vào các khoảng văn bản bị loại bỏ từ tài liệu. BART (Lewis et al., 2020a) hơi giống với T5 nhưng chỉ sử dụng mục tiêu tự giám sát trong đó các khoảng được che khỏi đầu vào, nhưng đầu ra hoàn chỉnh được dự đoán để cải thiện khả năng mô hình hóa ngôn ngữ của bộ giải mã. Hơn nữa, Rothe et al. (2020) đề xuất việc sử dụng các checkpoint được huấn luyện trước chỉ mã hóa hoặc chỉ giải mã để khởi tạo các mô hình mã hóa-giải mã mới, thể hiện hiệu suất cạnh tranh so với các mô hình được huấn luyện trước hoàn toàn mã hóa-giải mã.

Gần đây hơn, đã có sự gia tăng đáng kể trong các nỗ lực triển khai các mô hình sequence-to-sequence cho các ngôn ngữ khác tiếng Anh. BART, chẳng hạn, đã được phát hành cho nhiều ngôn ngữ khác, bao gồm tiếng Pháp (Kamal Eddine et al., 2021), tiếng Hy Lạp (Evdaimon et al., 2023), tiếng Indic (Dabre et al., 2022), tiếng Ả Rập (Kamal Eddine et al., 2022) và nhiều ngôn ngữ khác (Tran et al., 2022; La Quatra and Cagliero, 2023). Hơn nữa, T5 đã được huấn luyện trước bằng tiếng Bồ Đào Nha (Carmo et al., 2020), tiếng Ý (Sarti and Nissim, 2022), tiếng Ả Rập (Nagoudi et al., 2022), tiếng Indic (Aralikatte et al., 2023), cùng những ngôn ngữ khác. Trong khi các mô hình gần đây được đề cập bao gồm một phạm vi rộng các ngôn ngữ, tính sẵn có của các mô hình tiếng Tây Ban Nha vẫn còn hạn chế.

3. Các Mô hình Ngôn ngữ Được Huấn luyện Trước Sequence-to-Sequence Tiếng Tây Ban Nha

Trong phần này, chúng tôi bắt đầu bằng cách trình bày các quy trình thu thập và chuẩn bị dữ liệu để huấn luyện trước các mô hình của chúng tôi. Tiếp theo, chúng tôi cung cấp mô tả chi tiết về từng mô hình và phác thảo các quy trình huấn luyện trước tương ứng.

3.1. Dữ liệu Huấn luyện Trước

Chúng tôi sử dụng kho dữ liệu OSCAR 21.09 (Abadji et al., 2022), bao gồm một bộ dữ liệu tiếng Tây Ban Nha đã được khử trùng lặp khoảng 160GB văn bản. Hơn nữa, chúng tôi sử dụng kho dữ liệu mC4-es (Xue et al., 2021), cụ thể là áp dụng tập con lấy mẫu độ phức tạp Gaussian được đề xuất bởi De la Rosa et al. (2022), có bộ dữ liệu văn bản rộng lớn 500GB và đã chứng minh tính nhất quán mô hình vượt trội. Ngoài ra, chúng tôi kết hợp SUC, kho dữ liệu được sử dụng để huấn luyện trước BETO, bao gồm khoảng 14GB văn bản thô từ nhiều nguồn khác nhau. Lưu ý rằng chúng tôi loại trừ dữ liệu Wikipedia từ SUC, thay vào đó chọn một bản dump Wikipedia cập nhật khoảng 10GB.

Như đã được nghiên cứu trước đó thiết lập (Liu et al., 2019; Raffel et al., 2020), chất lượng kho dữ liệu ảnh hưởng đáng kể đến kết quả huấn luyện trước các mô hình. Do đó, chúng tôi tuân theo chặt chẽ các phương pháp tiền xử lý đã được thiết lập trước đó cho cả mô hình tiếng Anh (Raffel et al., 2020) và tiếng Tây Ban Nha (Gutiérrez-Fandiño et al., 2022; Serrano et al., 2022). Dưới đây, chúng tôi mô tả quy trình:

1. Định dạng Cấp độ Tài liệu: Chúng tôi đảm bảo rằng tất cả dữ liệu tuân theo định dạng cấp độ tài liệu, có nghĩa là mỗi thực thể là một tài liệu chứa nhiều câu mạch lạc liên tiếp. Như đã được chứng minh bởi Liu et al. (2019), việc hạn chế các chuỗi đến từ một tài liệu duy nhất hoạt động tốt hơn một chút so với việc đóng gói các chuỗi từ nhiều tài liệu. Hơn nữa, điều này khiến các mô hình nắm bắt được các phụ thuộc ngữ cảnh rộng.

2. Lọc Dữ liệu: Để tăng chất lượng dữ liệu, chúng tôi sử dụng các phương pháp lọc đơn giản và hiệu quả về chi phí. Chúng tôi loại bỏ các tài liệu rất ngắn dựa trên độ dài câu và tài liệu. Chúng tôi lọc bỏ văn bản chứa các ký tự lặp lại hoặc ký tự đặc biệt không thường được sử dụng trong tiếng Tây Ban Nha. Chúng tôi loại trừ các trang chứa mã và nội dung nhạy cảm. Hơn nữa, chúng tôi sử dụng mô hình nhận dạng ngôn ngữ fastText (Joulin et al., 2017) để loại trừ các tài liệu được phân loại với độ chính xác dưới 98% cho văn bản tiếng Tây Ban Nha. Chúng tôi đặt ngưỡng này để đảm bảo kho dữ liệu của chúng tôi giữ lại một phần nhỏ nhưng đại diện của các ngôn ngữ khác thường được xen kẽ trong các văn bản tiếng Tây Ban Nha đương đại.

3. Khử trùng lặp: Chúng tôi sử dụng quy trình khử trùng lặp trên tất cả các kho dữ liệu bằng thư viện text-dedup. Điều này tạo ra một bộ dữ liệu nhỏ hơn và nhanh hơn để huấn luyện trong khi có thể tăng cường hiệu suất kết quả do tránh dữ liệu trùng lặp (Lee et al., 2022). Do tính chất tính toán tích cực, bước này được thực hiện sau định dạng và lọc.

4. Sửa chữa Mã hóa: Một số tài liệu có thể có mã hóa không nhất quán hoặc thể hiện các vấn đề mã hóa. Để giải quyết điều này, chúng tôi sử dụng công cụ ftfy để sửa chữa các lỗi mã hóa lẫn lộn, đảm bảo mã hóa UTF-8 và chuẩn hóa NFKC. Chúng tôi thực hiện quy trình này ở cuối đường ống vì, trong khi ftfy rất hiệu quả trong việc sửa chữa văn bản, nó có thể tốn kém về mặt tính toán đối với các kho dữ liệu lớn. Ngoài ra, điều này đảm bảo rằng chúng tôi có mã hóa phù hợp sau tất cả các bước trước đó.

Kích thước kho dữ liệu kết quả sau tiền xử lý vượt quá 120GB văn bản không nén, một quy mô tương tự như quy mô được sử dụng để huấn luyện các mô hình RoBERTa và BART (Liu et al., 2019; Lewis et al., 2020a).

3.2. Mô hình BARTO

BARTO tuân theo kiến trúc BART cơ bản, bao gồm một bộ mã hóa và một bộ giải mã với mỗi bộ có 6 lớp. Ngoài ra, nó có 12 đầu chú ý và 768 chiều ẩn trong cả bộ mã hóa và bộ giải mã. BARTO được huấn luyện trước bằng cách khử nhiễu các tài liệu đầu vào bị hỏng. Như được đề xuất bởi Lewis et al. (2020a), chúng tôi sử dụng kết hợp các chuyển đổi điền văn bản và hoán vị câu để có hiệu suất mạnh mẽ, che 30% token trong mỗi tài liệu và hoán vị tất cả các câu.

Chúng tôi sử dụng sentencepiece (Kudo and Richardson, 2018) để xây dựng một tokenizer BPE có 50,264 token. Hơn nữa, chúng tôi dựa vào thư viện fairseq (Ott et al., 2019) để thực hiện huấn luyện. BARTO được huấn luyện trước trong 100,000 bước trên 8 GPU NVIDIA A100 với văn bản đầu vào 1024 và kích thước batch 2048. Chúng tôi sử dụng trình tối ưu hóa Adam (Kingma and Ba, 2015), khởi động 10,000 bước, dropout 0.1, và FP16 để tăng tốc huấn luyện.

3.3. Mô hình T5S

T5S tuân theo phiên bản T5.1.1 cơ bản của mô hình T5, bao gồm một số cải tiến. Mô hình này bao gồm một bộ mã hóa và bộ giải mã với mỗi bộ có 12 lớp, 12 đầu chú ý, và 768 chiều ẩn. Giống như T5.1.1, chúng tôi chỉ huấn luyện trước bằng mục tiêu khử nhiễu bằng cách điền vào các khoảng văn bản bị loại bỏ từ tài liệu. Như được đề xuất bởi Raffel et al. (2020), chúng tôi sử dụng tỷ lệ hỏng 15% và độ dài khoảng trung bình là 3.

Chúng tôi sử dụng thư viện sentencepiece để xây dựng một tokenizer unigram có 32,000 token. Chúng tôi cũng dựa vào nanoT5 (Nawrot, 2023), cho phép huấn luyện trước các mô hình T5 với ngân sách hạn chế. T5S của chúng tôi được huấn luyện trước trong 130,000 bước trên 4 GPU NVIDIA A100 với văn bản đầu vào 1024 và kích thước batch 320. Ngoài ra, chúng tôi sử dụng trình tối ưu hóa AdamW (Loshchilov and Hutter, 2019), khởi động 10,000 bước, dropout 0, và BP16 để tăng tốc huấn luyện.

3.4. Các Mô hình Kiểu BERT2BERT

Các mô hình kiểu BERT2BERT của chúng tôi tuân theo quy trình được đề xuất bởi Rothe et al. (2020), bao gồm việc khởi tạo các mô hình mã hóa-giải mã với các checkpoint được huấn luyện trước chỉ mã hóa và/hoặc chỉ giải mã. Chúng tôi sử dụng hai cấu hình: BERT2BERT, là một bộ mã hóa được khởi tạo bởi một checkpoint kiểu BERT được ghép nối với một bộ giải mã được khởi tạo với cùng một checkpoint, và BERTShare, tương tự như BERT2BERT nhưng các tham số giữa bộ mã hóa và bộ giải mã được chia sẻ.

Chúng tôi dựa vào thư viện transformers (Wolf et al., 2020) để khởi tạo các mô hình dựa trên hai kiến trúc nổi tiếng. Một mặt, bằng cách sử dụng checkpoint BETO, chúng tôi khởi tạo một mô hình BETO2BETO và BETOShare. Mặt khác, bằng cách tận dụng checkpoint RoBERTa-BNE từ MarIA, chúng tôi khởi tạo một RoBERTa2RoBERTa và RoBERTaShare. Lưu ý rằng những mô hình này không cần tiếp tục huấn luyện trước mà thay vào đó tinh chỉnh chúng trực tiếp trong các tác vụ hạ nguồn. Chúng tôi sẽ đi sâu vào quy trình này chi tiết hơn trong phần tiếp theo.

4. Đánh giá

Trong phần này, chúng tôi giới thiệu các tác vụ hạ nguồn được chọn để đánh giá hiệu suất của các mô hình sequence-to-sequence của chúng tôi. Những bộ dữ liệu này chủ yếu bao gồm các tác vụ tạo sinh, trong đó cả văn bản chuỗi đầu vào và đầu ra đều được cung cấp. Hơn nữa, chúng tôi mô tả một số tác vụ phân biệt mà chúng tôi áp dụng như một phần của đánh giá của chúng tôi. Cuối cùng, chúng tôi cung cấp chi tiết về quy trình tinh chỉnh mô hình.

4.1. Tác vụ Tạo sinh

Tóm tắt Trừu tượng Tóm tắt liên quan đến việc tạo ra một phiên bản ngắn gọn của một tài liệu trong khi vẫn giữ lại thông tin chính. Chúng tôi xem xét các bộ dữ liệu MLSUM (Scialom et al., 2020) và WikiLingua (Ladhak et al., 2020) để đánh giá các mô hình của chúng tôi. Một mặt, MLSUM là một bộ sưu tập các bài báo với số lượng token trung bình ~900 và tóm tắt khoảng ~24 token. Mặt khác, WikiLingua bao gồm các bài viết dựa trên hướng dẫn với khoảng ~500 token trung bình, và tóm tắt của nó chứa khoảng ~50 token. Lưu ý rằng cả hai bộ dữ liệu đều không chứa văn bản quá dài, đặc biệt là trong trường hợp tóm tắt. Yếu tố này đơn giản hóa đáng kể quá trình tạo sinh.

Tóm tắt Trừu tượng Dạng dài Một tác vụ thử thách hơn của tóm tắt trừu tượng là xử lý và/hoặc tạo sinh văn bản dạng dài. Chúng tôi sử dụng XL-Sum (Hasan et al., 2021), một bộ dữ liệu với các bài viết dài, và EUR-Lex-Sum (Aumiller et al., 2022), một bộ dữ liệu với tóm tắt dài. XL-Sum (Hasan et al., 2021) chứa các bài báo tin tức dài với khoảng ~1200 token trung bình và tóm tắt ngắn khoảng ~40 token. Ngược lại, EUR-Lex-Sum là một bộ dữ liệu các tài liệu pháp lý với độ dài trung bình ~19000 token và tóm tắt dài khoảng ~1200 token. Những bộ dữ liệu này đặt ra những thách thức đáng kể hơn so với những bộ trước đó. Điều này là do bản chất chuyên sâu hơn của quá trình mã hóa và tạo sinh, đòi hỏi các mô hình có khả năng xử lý các chuỗi dài và nắm bắt các phụ thuộc mở rộng để tạo ra tóm tắt chất lượng cao.

Tách và Diễn đạt lại Tác vụ tách-và-diễn-đạt-lại giả định việc viết lại nội dung của một câu dài thành các câu ngắn hơn và ít dài dòng hơn. Chúng tôi sử dụng tập con tiếng Tây Ban Nha của bộ dữ liệu BiSECT (Kim et al., 2021) để đánh giá tác vụ này, chứa khoảng 290,000 thực thể. Số lượng token trung bình trong các câu đầu vào là khoảng ~51, trong khi sau khi diễn đạt lại thành hai câu, trung bình tăng lên ~75 token trên một cặp câu. Theo Kim et al. (2021), chúng tôi sử dụng một token đặc biệt để tách các câu phân tách trong quá trình tinh chỉnh mô hình. Cụ thể, chúng tôi sử dụng <s> ([CLS] trong trường hợp các mô hình kiểu BERT2BERT) vì nó cung cấp hiệu suất tốt nhất.

Trả lời Câu hỏi Tạo sinh Tác vụ này tập trung vào việc tạo ra một câu trả lời trừu tượng cho một câu hỏi đã cho từ một đoạn văn được cung cấp. Theo hiểu biết tốt nhất của chúng tôi, hiện tại không có bộ dữ liệu nào được tùy chỉnh cho trả lời câu hỏi trừu tượng bằng tiếng Tây Ban Nha. Phù hợp với công trình trước đó (Raffel et al., 2020), chúng tôi sử dụng các bộ dữ liệu trả lời câu hỏi dựa trên khoảng để huấn luyện các mô hình tạo ra câu trả lời đúng thay vì dự đoán vị trí token cụ thể của câu trả lời. Chúng tôi dựa vào các bộ dữ liệu MLQA (Lewis et al., 2020b) và SQAC (Gutiérrez-Fandiño et al., 2022) cho đánh giá này. MLQA trình bày một bộ sưu tập các bài viết đa ngôn ngữ song song được trích xuất từ Wikipedia và cung cấp một bộ phát triển và bộ kiểm tra được dịch chuyên nghiệp sang tiếng Tây Ban Nha. Khác với MLQA, SQAC được đề xuất độc quyền cho đánh giá tiếng Tây Ban Nha và chứa các bài viết được trích xuất từ các nguồn tiếng Tây Ban Nha. Theo quy trình tinh chỉnh BART (Lewis et al., 2020a), các mô hình tạo ra câu trả lời có điều kiện dựa trên sự nối các câu hỏi và tài liệu hỗ trợ.

Đối thoại Tác vụ tạo sinh phản hồi đối thoại nhằm tạo ra một phản hồi phù hợp và mạch lạc dựa trên ngữ cảnh đối thoại. Chúng tôi sử dụng phần tiếng Tây Ban Nha của bộ dữ liệu MIAM (Colombo et al., 2021), một chuẩn mực bao gồm các kho dữ liệu hành động đối thoại. Bộ dữ liệu này được đề xuất ban đầu để xác định hành động cụ thể mà người nói thực hiện không phải là tác vụ mà chúng tôi muốn giải quyết trong công trình này. Do đó, chúng tôi điều chỉnh dữ liệu để phù hợp với nhu cầu đánh giá của chúng tôi. Theo công trình trước đó (Zhou et al., 2021; Zhang et al., 2020), chúng tôi chỉ tập trung vào các câu nói được trao đổi giữa các người nói để tạo ra các cặp ngữ cảnh và phản hồi đối thoại.

Dịch Máy Mục tiêu của tác vụ này là dịch một câu từ ngôn ngữ nguồn sang ngôn ngữ đích khác. Chúng tôi dựa vào Fapesp-v2 (Aziz and Specia, 2011) và WMT13 (Bojar et al., 2013), các chuẩn mực dịch máy nổi tiếng bao gồm dữ liệu ngôn ngữ tiếng Tây Ban Nha. Một mặt, Fapesp-v2 là một kho dữ liệu song song Bồ Đào Nha ↔ Tây Ban Nha được thu thập từ một tạp chí Brazil với khoảng ~150,000 ví dụ tập huấn luyện và ~1,300 ví dụ tập phát triển và kiểm tra. Mặt khác, WMT13 bao gồm một tập con Anh ↔ Tây Ban Nha bao gồm khoảng 15 triệu thực thể huấn luyện, khá rộng lớn để tiến hành các thí nghiệm quy mô nhỏ. Do đó, chúng tôi chọn làm việc với một tập con được lấy mẫu ngẫu nhiên gồm 600,000 ví dụ, một kích thước tương tự như được sử dụng để tinh chỉnh các mô hình tiếng Anh (Lewis et al., 2020a). Để đánh giá, chúng tôi sử dụng các tập newstest2012 và newstest2013, mỗi tập chứa ~3000 ví dụ.

4.2. Tác vụ Phân biệt

GLUES Chúng tôi dựa vào GLUES, một chuẩn mực được giới thiệu ban đầu bởi Cañete et al. (2020). Chúng tôi tập trung đánh giá vào các tác vụ phân loại chuỗi: MLDoc, PAWS-X, và XNLI. MLDoc xoay quanh việc phân loại các tài liệu dài thành bốn danh mục riêng biệt. PAWS-X, mặt khác, tập trung vào việc xác định các cụm từ đồng nghĩa. Cuối cùng, XNLI bao gồm việc dự đoán liệu một tiền đề có kéo theo logic một giả thuyết đã cho hay không. Ngoài ra, chúng tôi sử dụng các tác vụ tương tự và liên quan ngữ nghĩa, bao gồm STS-es (Gutiérrez-Fandiño et al., 2022) và SemRel2024 (Ousidhoum et al., 2024). STS-es đòi hỏi việc đánh giá sự tương tự giữa hai đoạn văn bản bằng cách gán một điểm từ 1 đến 5. SemRel2024 đánh giá mức độ liên quan ngữ nghĩa văn bản giữa hai câu, gán một điểm từ 0 đến 1.

SQAC Trong trường hợp phân loại cấp độ token, chúng tôi dựa vào bộ dữ liệu SQAC (Gutiérrez-Fandiño et al., 2022). Kho dữ liệu này là một tập hợp các cặp câu hỏi-trả lời được trích xuất từ các bài viết Wikipedia. Trong SQAC, tác vụ chính liên quan đến việc dự đoán khoảng cụ thể trong văn bản tương ứng với câu trả lời cho một câu hỏi đã cho. Điều này được thực hiện bằng cách chỉ ra vị trí bắt đầu và kết thúc của khoảng câu trả lời này trong văn bản. Như một thực hành phổ biến, đầu vào cho mô hình trong quá trình tinh chỉnh là nối câu hỏi và văn bản ngữ cảnh.

4.3. Tinh chỉnh

Chúng tôi tuân theo các quy trình tinh chỉnh được đề xuất cho các mô hình phiên bản tiếng Anh (Lewis et al., 2020a; Raffel et al., 2020). Bởi vì BARTO và T5S có một bộ giải mã tự hồi quy, chúng có thể được tinh chỉnh trực tiếp cho các tác vụ tạo sinh chuỗi. Cụ thể, bộ mã hóa của chúng nhận một đầu vào hoàn chỉnh, và sau đó bộ giải mã của chúng tạo ra một đầu ra đích theo cách tự hồi quy.

Đối với BETO2BETO và các mô hình tương tự, chúng tôi khởi tạo một transformer với checkpoint BETO trong cả bộ mã hóa và bộ giải mã. Lưu ý rằng bộ giải mã có các lớp chú ý chéo được khởi tạo ngẫu nhiên vì BETO không có các tham số này. Tiếp theo, chúng tôi tinh chỉnh những mô hình này theo cùng quy trình như BARTO và T5S.

Chúng tôi tinh chỉnh các mô hình trên GPU RTX 3090 cho mỗi tác vụ sử dụng thư viện transformers được triển khai trong PyTorch. Để so sánh công bằng, chúng tôi sử dụng các siêu tham số giống nhau ngoại trừ kích thước batch, tỷ lệ học, và số epoch huấn luyện. Các thiết lập tối ưu có thể phụ thuộc vào tác vụ, do đó chúng tôi xem xét một phép quét siêu tham số với kích thước batch ∈ {4, 8, 16}, tỷ lệ học (AdamW) ∈ {3e-5, 5e-5}, và epoch ∈ {3, 6}.

4.4. Cơ sở Đa ngôn ngữ

Để bổ sung cho đánh giá của chúng tôi, chúng tôi bao gồm các cơ sở sequence-to-sequence đa ngôn ngữ để so sánh thêm. Chúng tôi sử dụng mT5-base (Xue et al., 2021), một mô hình được huấn luyện trên 101 ngôn ngữ. Mặc dù không có phiên bản cơ bản của mBART trực tiếp so sánh được với các mô hình của chúng tôi, chúng tôi bao gồm phiên bản mBART-large để so sánh. Cụ thể, chúng tôi sử dụng mBART-50 (Tang et al., 2020), bao gồm cả tiếng Tây Ban Nha và tiếng Bồ Đào Nha, thiết yếu cho các thí nghiệm của chúng tôi. Chúng tôi tinh chỉnh những mô hình này theo cùng quy trình như BARTO và T5S.

5. Kết quả

Phần này trình bày kết quả đạt được sau khi tinh chỉnh tất cả các mô hình trên các tác vụ hạ nguồn. Chúng tôi đánh giá chúng bằng các chỉ số thông thường, tuân thủ các phương pháp đã được thiết lập trong công trình trước đó (Lewis et al., 2020a; Raffel et al., 2020).

5.1. Tác vụ Tạo sinh

Tóm tắt Trừu tượng Bảng 1 trình bày một so sánh kết quả đạt được bởi tất cả các mô hình trên các tác vụ MLSUM và WikiLingua, được đo bằng chỉ số ROUGE (Lin, 2004). Cụ thể, mô hình T5S thể hiện hiệu suất cao nhất với trung bình 26.54 ROUGE trong số các mô hình tiếng Tây Ban Nha trên tất cả các tác vụ, trong khi BARTO đứng thứ hai với chênh lệch trung bình 25.49 ROUGE. Đối với các mô hình kiểu BERT2BERT, chúng đều bị vượt trội. BETO2BETO là mô hình mang lại hiệu suất tốt nhất trong nhóm của nó với trung bình 24.39 ROUGE. Đáng chú ý, T5S và BARTO vượt trội hơn các đối tác đa ngôn ngữ của chúng, ngoại trừ mBART trên WikiLingua, vượt trội hơn T5S một chút với 0.45 ROUGE.

Tóm tắt Trừu tượng Dạng dài Kết quả cho tóm tắt dạng dài được trình bày trong Bảng 2. Trong XLSum, T5S vượt trội hơn BARTO một chút, lần lượt trung bình 22.06 và 21.58 ROUGE. Hơn nữa, BETOShare đạt được hiệu suất tốt nhất trong nhóm mô hình của nó với trung bình 19.82 ROUGE. Về EUR-Lex-Sum, BARTO vượt trội hơn T5S, lần lượt trung bình 56.82 và 56.42 ROUGE. Đáng chú ý, sự khác biệt giữa BARTO và T5S so với các mô hình kiểu BERT2BERT là đáng kể, với BETO2BETO là mô hình hoạt động tốt nhất với trung bình 26.69 ROUGE. Những kết quả này phản ánh các yêu cầu độc đáo của EUR-Lex-Sum, liên quan đến việc xử lý các bài viết dài và tạo ra tóm tắt mở rộng. BART và T5S thể hiện hiệu suất tốt hơn trong tác vụ này, chủ yếu vì chúng tận dụng định dạng tài liệu trong quá trình huấn luyện trước. Chiến lược này tăng cường khả năng xử lý các chuỗi dài của chúng, đặc biệt khi xử lý các tài liệu mở rộng. Cuối cùng, các mô hình đa ngôn ngữ vượt trội hơn BARTO và T5S một chút chỉ trong trường hợp EUR-Lex-Sum. Điều này có thể do phạm vi đa dạng các loại văn bản được gặp phải bởi các mô hình đa ngôn ngữ trong quá trình huấn luyện trước, bao gồm cả tài liệu pháp lý. Phụ lục A trình bày các thí nghiệm bổ sung khám phá tiềm năng của BARTO như một Longformer (Beltagy et al., 2020) cho tác vụ này.

Trả lời Câu hỏi Tạo sinh Bảng 3 trình bày kết quả của các tác vụ trả lời câu hỏi tạo sinh theo điểm ROUGE. Mặc dù SQAC và MLQA ban đầu được thiết kế như các tác vụ phân biệt, kết quả của chúng tôi cho thấy rằng chúng phục vụ như một chuẩn mực phù hợp cho trả lời câu hỏi tạo sinh. BARTO và T5S thể hiện hiệu suất tốt nhất trong tất cả các tác vụ, với T5S là tốt nhất, đạt 67.92 ROUGE trung bình. Trong tác vụ này, sự khác biệt hiệu suất giữa hai mô hình này là đáng kể so với các mô hình kiểu BERT2BERT, với BETOShare là mô hình hoạt động tốt nhất trong nhóm với trung bình 27 ROUGE. Sự khác biệt này có thể bắt nguồn từ mục tiêu tự giám sát của BART và T5, cho phép chuyển giao học tập tốt hơn cho tác vụ này so với những tác vụ khác (Raffel et al., 2020). Đáng kể, trong những tác vụ này, cả BARTO và T5S đều vượt trội hơn các đối tác đa ngôn ngữ của chúng, bao gồm cả mBART kích thước lớn. Những kết quả này làm nổi bật khả năng hiểu đọc vượt trội của các mô hình của chúng tôi.

Tách và Diễn đạt lại Bảng 4 trình bày so sánh các mô hình trên bộ dữ liệu BiSECT, với đánh giá dựa trên điểm SARI (Xu et al., 2016) và BLEU (Post, 2018). T5S đạt điểm cao nhất cho cả hai chỉ số, trung bình 56.37 SARI và 43.27 BLEU. Trong khi BARTO đạt điểm BLEU cao thứ hai, hiệu suất của nó trong SARI không đạt yêu cầu. Cụ thể, RoBERTaShare có hiệu suất tốt nhất trong các mô hình kiểu BERT2BERT, trung bình 51.29 SARI nhưng bị vượt trội bởi BARTO trong BLEU. Thành công của T5S có thể được gán cho khả năng tạo ra các chuỗi gần giống với thứ tự từ của đầu vào, một đặc điểm liên quan chặt chẽ đến tiêu chí đánh giá của SARI. Ngoài ra, mục tiêu điền khoảng của T5 có thể tạo điều kiện cho việc tách câu, góp phần vào sự tăng cường hiệu suất tổng thể. Cuối cùng, T5S vượt trội hơn đối tác đa phương thức của nó, trong khi BARTO hoạt động tương đương với mBART-large.

Đối thoại Bảng 5 so sánh các mô hình cho tạo sinh đối thoại dựa trên điểm F1 và METEOR (Banerjee and Lavie, 2005). BARTO dẫn đầu với 34.30 F1, được theo sát bởi BETOShare với 32.45 F1. Ngược lại, đối với điểm METEOR, BETOShare vượt trội với 27.33 METEOR, theo sau là BARTO với 26.95 METEOR. Thú vị, T5S xếp thứ tư với trung bình 28.80 F1 và 22.24 METEOR. T5S xuất sắc trong các tác vụ có độ chồng lấn cao giữa đầu vào và đầu ra, như tóm tắt hoặc tách-và-diễn-đạt-lại, điều này có thể giải thích hiệu suất thấp hơn của nó trong tạo sinh đối thoại nơi độ chồng lấn như vậy bị giảm. Đáng chú ý, các mô hình đa ngôn ngữ thể hiện hành vi tương tự như các mô hình của chúng tôi, với mBART vượt trội hơn mT5. Kết quả này cho thấy các mô hình đa ngôn ngữ có kiến thức rộng hơn cần thiết cho các tác vụ đối thoại, mang lại cho chúng một lợi thế nhỏ so với BARTO và T5S.

Dịch Máy BARTO và T5S được huấn luyện trước với các tài liệu bao gồm ít nhất 98% độ chính xác cho dự đoán ngôn ngữ tiếng Tây Ban Nha. Chúng tôi giả thuyết rằng ngưỡng này cho phép các mô hình của chúng tôi có được kiến thức về các ngôn ngữ khác thường được tìm thấy cùng với tiếng Tây Ban Nha, cho phép chúng thực hiện tác vụ dịch thuật. Do đó, chúng tôi quyết định làm cho các mô hình của chúng tôi phù hợp trực tiếp trong hình thức gốc của chúng, theo quy trình của các tác vụ trước đó. Điều này tương phản với cách tiếp cận được đề xuất bởi Lewis et al. (2020a), giới thiệu các tham số mới để tạo điều kiện cho việc thích ứng BART với một ngôn ngữ mới. Để so sánh tốt hơn, chúng tôi sử dụng các checkpoint BERT đa ngôn ngữ để khởi tạo mBERT2mBERT. Chúng tôi đánh giá tất cả các chế độ bằng điểm BLEU.

Trong các thí nghiệm của chúng tôi, chúng tôi thấy rằng việc duy trì kích thước batch đáng kể (ví dụ, 384) và giới hạn số bước tinh chỉnh tác động tích cực đến hiệu suất kết quả của cả BARTO và T5S, nhưng không phải mBERT2mBERT.

Bảng 6 trình bày kết quả thí nghiệm. Cả BARTO và T5S đều thể hiện hiệu suất tương tự trong việc dịch từ tiếng Bồ Đào Nha sang tiếng Tây Ban Nha (Fapesp-v2 PT→ES) và tiếng Anh sang tiếng Tây Ban Nha (WMT13 EN→ES). Ngoài ra, mô hình kiểu BERT2BERT hoạt động tốt nhất là mBERT2mBERT. Lưu ý rằng điểm BLEU cao hơn đối với Fapesp-v2, và khoảng cách hiệu suất của BARTO và T5S so với mBERT2mBERT cũng đáng kể hơn so với WMT13. Giả thuyết của chúng tôi là sự khác biệt này không chỉ xuất phát từ các mô hình tiếp xúc với văn bản tiếng Bồ Đào Nha mà còn từ những gốc rễ ngôn ngữ chung với tiếng Tây Ban Nha. Thực tế, khi phân tích tokenizer, chúng tôi quan sát thấy các dấu phụ tiếng Bồ Đào Nha (ví dụ, ç, ã, ü).

Bảng 6 cũng cho thấy kết quả của các thí nghiệm với tiếng Tây Ban Nha làm ngôn ngữ nguồn cho dịch thuật (Fapesp-v2 ES→PT và WMT13 ES→EN). Theo trực giác, người ta có thể mong đợi các mô hình của chúng tôi hoạt động tốt hơn khi được giao nhiệm vụ tạo sinh tiếng Tây Ban Nha. Tuy nhiên, chúng thể hiện hiệu suất cạnh tranh ngay cả khi tạo sinh tiếng Bồ Đào Nha và tiếng Anh. Vượt trội hơn mBERT2mBERT, mô hình kiểu BERT2BERT tốt nhất, BARTO và T5S thể hiện hiệu suất cạnh tranh hơn cho Fapesp-v2 và WMT13. Thú vị, điểm BLEU cao hơn một chút so với khi tạo sinh văn bản tiếng Tây Ban Nha. Chúng tôi giả thuyết rằng điều này là do hiệu quả của biểu diễn mã hóa của đầu vào tiếng Tây Ban Nha để tạo sinh văn bản chất lượng có điều kiện.

Cuối cùng, chúng tôi thấy rằng BARTO và T5S hoạt động tương tự như các phiên bản đa ngôn ngữ của chúng. Những phát hiện này nhấn mạnh rằng một mô hình sequence-to-sequence, được huấn luyện trước từ đầu bằng tiếng Tây Ban Nha với một lượng đầu vào tối thiểu từ ngôn ngữ khác, có thể giải quyết hiệu quả các tác vụ dịch thuật.

5.2. Tác vụ Phân biệt

Kết quả cho các tác vụ phân biệt được trình bày trong Bảng 7. Đối với tất cả các tác vụ phân loại chuỗi, chúng tôi áp dụng các quy ước định dạng đầu vào đã được thiết lập trong công trình trước đó (Cañete et al., 2020; Gutiérrez-Fandiño et al., 2022). Tiếp theo, chúng tôi sử dụng token <s> hoặc [CLS] để thực hiện phân loại văn bản đầu vào khi sử dụng BERTO, RoBERTa, hoặc BARTO. Tuy nhiên, vì token đặc biệt này bị thiếu đối với T5S, chúng tôi tinh chỉnh mô hình để tạo ra nhãn lớp theo định dạng "text-to-text" được đề xuất bởi Raffel et al. (2020).

Trong trường hợp MLDoc, kết quả của chúng tôi cho thấy rằng BART và T5S thể hiện hiệu suất vượt trội, có thể được gán cho thành thạo của chúng trong việc xử lý các chuỗi dài. Về PAWS-X và XNLI, kết quả của chúng tôi cho thấy rằng BART và T5S, mặc dù không luôn đạt vị trí hàng đầu, vẫn thể hiện hiệu suất cạnh tranh. Cuối cùng, trong trường hợp STS-es và SemRel2024, chúng tôi thấy rằng các mô hình chỉ mã hóa hoạt động tốt nhất có thể vì chuyên môn của chúng về biểu diễn câu. Kết quả của chúng tôi phù hợp với hành vi của các mô hình tiếng Anh, nơi BART và T5 có xu hướng hơi tụt hậu so với mức tiên tiến trong các tác vụ phân loại cặp câu (Lewis et al., 2020a; Raffel et al., 2020).

Trong tác vụ phân loại token, chúng tôi tuân theo cách tiếp cận trả lời câu hỏi dựa trên khoảng tiêu chuẩn, ngoại trừ T5S, vẫn hoạt động như một mô hình tạo sinh, như đã nêu trước đó. Phù hợp với các phát hiện phân loại chuỗi của chúng tôi, chúng tôi quan sát thấy một lợi thế hiệu suất nhỏ đối với các mô hình chỉ mã hóa. Thú vị, T5S thể hiện hiệu suất thấp nhất trong tình huống này. Sự khác biệt này có thể được gán cho sự phù hợp của chỉ số F1 cho đánh giá phân biệt, có thể bỏ qua khả năng tạo sinh của T5S. Tuy nhiên, đáng chú ý rằng T5S đã chứng minh khả năng tạo ra câu trả lời chính xác trong Phần 5.1.

6. Phân tích Định tính

Đánh giá định lượng của BARTO và T5S (Phần 5) chứng minh sự cải thiện hiệu suất so với các mô hình kiểu BERT2BERT. Để có cái nhìn sâu sắc hơn về hành vi của hai mô hình này, chúng tôi đã tiến hành phân tích định tính về các dự đoán của chúng tập trung vào tóm tắt trừu tượng, trả lời câu hỏi tạo sinh, dịch thuật, và các tác vụ đối thoại. Bảng 8 cho thấy các ví dụ được chọn được tạo ra bởi BARTO và T5S, làm nổi bật điểm mạnh và điểm yếu tương ứng của chúng so với cơ sở kiểu BERT2BERT.

--- TRANG 9 ---
Tóm tắt Dạng dài: WikiLingua
Nguồn En caso de que hayas planificado con anticipación, esto te será fácil. Luego, regresa al ensayo cuando hayan pasado uno o dos días y revísalo [...]. Lee tu ensayo en voz alta, leyendo exactamente lo que haya en la hoja [...]. Podría serte de ayuda que imprimas el borrador [...]. Al trabajar con una copia física, te obligas a prestar atención de una forma nueva [...].
Đích Tómate uno o dos días sin mirar al ensayo. Lee el borrador. Revisa en donde sea necesario. Corrige con cuidado.
T5S Regresa al ensayo al día siguiente. Revisa el ensayo. Edita el ensayo. Revisa el ensayo
BARTO Revisa tu ensayo antes de enviarlo. Lee tu ensayo de principio a fin. Revisa tu ensayo en voz alta. Imprime y edita tu ensayo. Listo.
BETO2BETO Regresa el ensayo a un momento conveniente. Revisa tu ensayo de principio a fin. Corrige tu ensayo en voz alta. Haz una copia física de tu ensayo.

Trả lời Câu hỏi Tạo sinh: SQAC
Nguồn Anillo halo El anillo halo es el más interno y grueso de los anillos de Júpiter. Su borde exterior coincide con el interior del anillo principal aproximadamente a un radio de 122 500 km [...].
Câu hỏi ¿Cuál es el anillo más interno y grueso de los anillos de Júpiter?
Đích halo
T5S El anillo halo
BARTO anillo halo
RoBERTaShare el anillo halo: Iris (Aright (Award (Aver

Tạo sinh Đối thoại: MIAM
Nguồn [...] . Hay varios trenes . El primero sale a la una y 50 de la madrugada y el último a las 7 de la tarde . Desea algo más ? . Sí , me gustaría obtener el tipo de tren para ir a Barcelona el próximo sábado día uno . Lo siento . No he entendido bien . puede repetir ? .
Đích Sí , me gustaría obtener el tipo de tren para ir a Barcelona el próximo sábado día uno .
T5S Me gustaría obtener el tipo de tren para ir a Barcelona el próximo sábado día uno.
BARTO Me gustaría obtener el tipo de tren para ir a Barcelona el próximo sábado día uno.
BETOShare Sí, me gustaría saber el horario de trenes de Barcelona a Zaragoza el próximo sábado.

Dịch Máy: WMT13 EN→ES
Nguồn Information entry has improved (the system receives more data), but output still needs to get better.
Đích La introducción de información ha mejorado (el sistema recibe más datos), y la salida todavía no es muy buena.
T5S La entrada de información ha mejorado (el sistema recibe más datos), pero la salida todavía necesita mejorarse.
BARTO La entrada de información ha mejorado (el sistema recibe más datos), pero todavía es necesario mejorar la salida.
mBART2mBART La entrada de información ha mejorado ( el sistema recibe más datos ), pero la salida todavía necesita mejorarse mejorando la información.

Bảng 8: Dự đoán được tạo ra bởi BARTO, T5S, và các mô hình kiểu BERT2BERT để so sánh định tính trong các tác vụ tóm tắt trừu tượng, trả lời câu hỏi tạo sinh, đối thoại, và dịch máy.

Trong bối cảnh tác vụ tóm tắt, cả BARTO và T5S đều thể hiện khả năng tạo ra tóm tắt mạch lạc phù hợp với nội dung nguồn. Đầu ra của BARTO có xu hướng khớp chặt chẽ với văn bản đích, duy trì độ tương tự văn bản cao. Ngoài ra, T5S hoạt động tương tự, nhưng trong ví dụ cụ thể này, chúng ta thấy một ảo giác trong tóm tắt của nó, "Escribe tu ensayo en voz alta", không có trong văn bản nguồn hoặc đích. Điều này có thể giải thích sự vượt trội của BART trong tác vụ này so với T5S.

Chuyển sang tác vụ trả lời câu hỏi tạo sinh, rõ ràng là T5S và BARTO xuất sắc trong việc tạo ra câu trả lời toàn diện hơn. Trong khi RoBERTaShare ban đầu tạo ra phản hồi tương tự, thỉnh thoảng nó giới thiệu các từ dư thừa không liên quan đến câu hỏi gốc.

Về tác vụ dịch tự động, cả BARTO và T5S đều tạo ra bản dịch tốt không giống hệt với đích nhưng hoàn toàn mạch lạc và hợp lệ. Tuy nhiên, mBERT2mBERT ảo giác tạo ra "mejorando la información", cái gì đó không có trong văn bản nguồn.

Cuối cùng, trong trường hợp tạo sinh đối thoại, cả BARTO và T5S tạo ra phản hồi gần như hoàn toàn phù hợp với phản hồi đích. Mặt khác, BETOShare ảo giác và trộn lẫn thông tin được chỉ định trong văn bản nguồn hoặc đối thoại. Những ví dụ minh họa này làm nổi bật kỹ năng của BARTO và T5S, thể hiện sự nắm bắt mạnh mẽ tiếng Tây Ban Nha và khả năng tạo ra phản hồi tự nhiên và phù hợp với ngữ cảnh.

7. Kết luận

Công trình này đặt nền móng cho nghiên cứu trong tương lai về các kiến trúc mã hóa-giải mã trong lĩnh vực ngôn ngữ tiếng Tây Ban Nha. Chúng tôi trình bày các mô hình BART, T5, và kiểu BERT2BERT, tất cả được huấn luyện trước độc quyền bằng tiếng Tây Ban Nha. Những mô hình này đi kèm với một loạt các tác vụ tạo sinh đa dạng nhằm tạo điều kiện cho đánh giá toàn diện. Đánh giá của chúng tôi đã chứng minh hiệu quả của những mô hình này trong việc giải quyết các thách thức này, với BARTO và T5S nổi lên như những mô hình hoạt động tốt nhất.

Khi chúng tôi hướng về tương lai, có tiềm năng lấp đầy các khoảng trống trong các tác vụ sequence-to-sequence bằng cách xây dựng các bộ dữ liệu chuyên biệt. Ngoài ra, một phân tích so sánh kỹ lưỡng liên quan đến các mô hình đơn ngữ và đa ngôn ngữ, tương tự như nghiên cứu của Agerri and Agirre (2023), có thể cung cấp những hiểu biết có giá trị về điểm mạnh và hạn chế của chúng. Cuối cùng, chúng tôi hình dung việc huấn luyện trước các mô hình ngôn ngữ quy mô lớn hơn, chẳng hạn như Llama (Touvron et al., 2023), để mở đường cho các tiến bộ trong các lĩnh vực mới nổi như chatbot.

8. Tuyên bố Đạo đức và Hạn chế

Công trình của chúng tôi trình bày các mô hình ngôn ngữ mới được huấn luyện trước độc quyền bằng tiếng Tây Ban Nha. Dữ liệu được sử dụng để huấn luyện các mô hình không ngụ ý bất kỳ vi phạm quyền riêng tư nào. Các tác động xã hội tiêu cực tiềm năng từ công trình này tương tự như bất kỳ mô hình NLP nào khác. Các mô hình ngôn ngữ có thể được sử dụng để tạo ra các hệ thống độc hại và thiên vị.

Trong bài báo này, chúng tôi giới thiệu các mô hình ngôn ngữ kích thước cơ bản, có thể không phù hợp cho các tác vụ đòi hỏi khả năng tiên tiến. Sự ưa thích hiện tại đối với các mô hình lớn hơn, thể hiện hiệu suất được cải thiện và các khả năng mới nổi, hướng các nỗ lực tương lai của chúng tôi đến việc phát hành các kiến trúc lớn hơn.

Đối với đánh giá trả lời câu hỏi tạo sinh, chúng tôi đã sử dụng các bộ dữ liệu dựa trên khoảng. Tuy nhiên, việc sử dụng những bộ dữ liệu này một cách tạo sinh có thể dẫn đến việc mô hình tập trung vào tái tạo thông tin chính xác từ văn bản nguồn. Các nỗ lực trong tương lai nên ưu tiên tạo ra và đánh giá các bộ dữ liệu trả lời câu hỏi trừu tượng thực sự trình bày một phạm vi đa dạng hơn các câu trả lời ngoài việc sao chép đầu vào.

9. Lời cảm ơn

Công trình này được tài trợ bởi Hội đồng Nghiên cứu Châu Âu Advanced Grant 788506 và được hỗ trợ bởi chương trình Google Cloud Research Credits (GCP) và chương trình TPU Research Cloud (TRC).

10. Tài liệu tham khảo

Julien Abadji, Pedro Ortiz Suarez, Laurent Romary, and Benoît Sagot. 2022. Hướng tới một kho dữ liệu thu thập đa ngôn ngữ hướng tài liệu sạch hơn. Trong Kỷ yếu Hội nghị Đánh giá và Tài nguyên Ngôn ngữ lần thứ mười ba, trang 4344–4355, Marseille, Pháp. Hiệp hội Tài nguyên Ngôn ngữ Châu Âu.

Rodrigo Agerri and Eneko Agirre. 2023. Bài học rút ra từ đánh giá các mô hình ngôn ngữ tiếng Tây Ban Nha. Procesamiento del Lenguaje Natural, 70(0):157–170.

Rahul Aralikatte, Ziling Cheng, Sumanth Doddapaneni, and Jackie Chi Kit Cheung. 2023. Varta: Một bộ dữ liệu tạo tiêu đề quy mô lớn cho các ngôn ngữ Indic. Trong Findings of the Association for Computational Linguistics: ACL 2023, trang 3468–3492, Toronto, Canada. Association for Computational Linguistics.

Vladimir Araujo, Andrés Carvallo, Souvik Kundu, José Cañete, Marcelo Mendoza, Robert E. Mercer, Felipe Bravo-Marquez, Marie-Francine Moens, and Alvaro Soto. 2022. Chuẩn mực đánh giá cho biểu diễn câu tiếng Tây Ban Nha. Trong Kỷ yếu Hội nghị Đánh giá và Tài nguyên Ngôn ngữ lần thứ mười ba, trang 6024–6034, Marseille, Pháp. Hiệp hội Tài nguyên Ngôn ngữ Châu Âu.

Vladimir Araujo, Marie-Francine Moens, and Alvaro Soto. 2023. Học biểu diễn cấp độ câu với mã hóa dự đoán. Machine Learning and Knowledge Extraction, 5(1):59–77.

Dennis Aumiller, Ashish Chouhan, and Michael Gertz. 2022. EUR-lex-sum: Một bộ dữ liệu đa và xuyên ngôn ngữ cho tóm tắt dạng dài trong lĩnh vực pháp lý. Trong Kỷ yếu Hội nghị 2022 về Phương pháp Thực nghiệm trong Xử lý Ngôn ngữ Tự nhiên, trang 7626–7639, Abu Dhabi, Các Tiểu vương quốc Ả Rập Thống nhất. Association for Computational Linguistics.

Wilker Aziz and Lucia Specia. 2011. Biên dịch hoàn toàn tự động các kho dữ liệu song song Bồ Đào Nha-Anh và Bồ Đào Nha-Tây Ban Nha. Trong Kỷ yếu Hội nghị thảo luận Brazil lần thứ 8 về Công nghệ Thông tin và Ngôn ngữ Con người.

--- TRANG 11 ---
Satanjeev Banerjee and Alon Lavie. 2005. METEOR: Một chỉ số tự động cho đánh giá MT với tương quan được cải thiện với các phán đoán của con người. Trong Kỷ yếu Hội thảo ACL về Các biện pháp Đánh giá Nội tại và Ngoại tại cho Dịch máy và/hoặc Tóm tắt, trang 65–72, Ann Arbor, Michigan. Association for Computational Linguistics.

Iz Beltagy, Matthew E. Peters, and Arman Cohan. 2020. Longformer: Transformer tài liệu dài.

Ondřej Bojar, Christian Buck, Chris Callison-Burch, Christian Federmann, Barry Haddow, Philipp Koehn, Christof Monz, Matt Post, Radu Soricut, and Lucia Specia. 2013. Những phát hiện của Hội thảo 2013 về Dịch máy Thống kê. Trong Kỷ yếu Hội thảo lần thứ tám về Dịch máy Thống kê, trang 1–44, Sofia, Bulgaria. Association for Computational Linguistics.

José Cañete, Gabriel Chaperon, Rodrigo Fuentes, Jou-Hui Ho, Hojin Kang, and Jorge Pérez. 2020. Mô hình bert được huấn luyện trước tiếng Tây Ban Nha và dữ liệu đánh giá. PML4DC at ICLR 2020.

José Cañete, Sebastian Donoso, Felipe Bravo-Marquez, Andrés Carvallo, and Vladimir Araujo. 2022. ALBETO và DistilBETO: Các mô hình ngôn ngữ tiếng Tây Ban Nha nhẹ. Trong Kỷ yếu Hội nghị Đánh giá và Tài nguyên Ngôn ngữ lần thứ mười ba, trang 4291–4298, Marseille, Pháp. Hiệp hội Tài nguyên Ngôn ngữ Châu Âu.

Diedre Carmo, Marcos Piau, Israel Campiotti, Rodrigo Nogueira, and Roberto Lotufo. 2020. Ptt5: Huấn luyện trước và xác thực mô hình t5 trên dữ liệu tiếng Bồ Đào Nha Brazil.

Pierre Colombo, Emile Chapuis, Matthieu Labeau, and Chloé Clavel. 2021. Mất mát được truyền cảm hứng từ chuyển đổi mã cho biểu diễn đối thoại nói. Trong Kỷ yếu Hội nghị 2021 về Phương pháp Thực nghiệm trong Xử lý Ngôn ngữ Tự nhiên, trang 8320–8337, Trực tuyến và Punta Cana, Cộng hòa Dominican. Association for Computational Linguistics.

Raj Dabre, Himani Shrotriya, Anoop Kunchukuttan, Ratish Puduppully, Mitesh Khapra, and Pratyush Kumar. 2022. IndicBART: Một mô hình được huấn luyện trước cho tạo sinh ngôn ngữ tự nhiên Indic. Trong Findings of the Association for Computational Linguistics: ACL 2022, trang 1849–1863, Dublin, Ireland. Association for Computational Linguistics.

Javier De la Rosa, Eduardo Ponferrada, Manu Romero, Paulo Villegas, Pablo González de Prado Salas, and María Grandury. 2022. Bertin: Huấn luyện trước hiệu quả của một mô hình ngôn ngữ tiếng Tây Ban Nha sử dụng lấy mẫu độ phức tạp. Procesamiento del Lenguaje Natural, trang 13–23.

Pieter Delobelle, Thomas Winters, and Bettina Berendt. 2020. RobBERT: một Mô hình Ngôn ngữ dựa trên RoBERTa Hà Lan. Trong Findings of the Association for Computational Linguistics: EMNLP 2020, trang 3255–3265, Trực tuyến. Association for Computational Linguistics.

Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Huấn luyện trước các transformer hai chiều sâu để hiểu ngôn ngữ. Trong Kỷ yếu Hội nghị 2019 của Chương Bắc Mỹ của Hiệp hội Ngôn ngữ học Tính toán: Công nghệ Ngôn ngữ Con người, Tập 1 (Bài báo Dài và Ngắn), trang 4171–4186, Minneapolis, Minnesota. Association for Computational Linguistics.

Iakovos Evdaimon, Hadi Abdine, Christos Xypolopoulos, Stamatis Outsios, Michalis Vazirgiannis, and Giorgos Stamou. 2023. Greek-bart: Mô hình sequence-to-sequence được huấn luyện trước tiếng Hy Lạp đầu tiên.

Asier Gutiérrez-Fandiño, Jordi Armengol-Estapé, Marc Pàmies, Joan Llop-Palao, Joaquín Silveira-Ocampo, Casimiro Pio Carrino, Aitor Gonzalez-Agirre, Carme Armentano-Oller, Carlos Rodriguez-Penagos, and Marta Villegas. 2022. Maria: Các mô hình ngôn ngữ tiếng Tây Ban Nha. Procesamiento del Lenguaje Natural, 68(0):39–60.

Tahmid Hasan, Abhik Bhattacharjee, Md. Saiful Islam, Kazi Mubasshir, Yuan-Fang Li, Yong-Bin Kang, M. Sohel Rahman, and Rifat Shahriyar. 2021. XL-sum: Tóm tắt trừu tượng đa ngôn ngữ quy mô lớn cho 44 ngôn ngữ. Trong Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, trang 4693–4703, Trực tuyến. Association for Computational Linguistics.

Pengcheng He, Xiaodong Liu, Jianfeng Gao, and Weizhu Chen. 2021. Deberta: Bert được tăng cường giải mã với chú ý tách rời. Trong Hội nghị Quốc tế về Biểu diễn Học tập.

Armand Joulin, Edouard Grave, Piotr Bojanowski, and Tomas Mikolov. 2017. Bộ thủ thuật cho phân loại văn bản hiệu quả. Trong Kỷ yếu Hội nghị lần thứ 15 của Chương Châu Âu của Hiệp hội Ngôn ngữ học Tính toán: Tập 2, Bài báo Ngắn, trang 427–431, Valencia, Tây Ban Nha. Association for Computational Linguistics.

--- TRANG 12 ---
Moussa Kamal Eddine, Antoine Tixier, and Michalis Vazirgiannis. 2021. BARThez: một mô hình sequence-to-sequence được huấn luyện trước tiếng Pháp có kỹ năng. Trong Kỷ yếu Hội nghị 2021 về Phương pháp Thực nghiệm trong Xử lý Ngôn ngữ Tự nhiên, trang 9369–9390, Trực tuyến và Punta Cana, Cộng hòa Dominican. Association for Computational Linguistics.

Moussa Kamal Eddine, Nadi Tomeh, Nizar Habash, Joseph Le Roux, and Michalis Vazirgiannis. 2022. AraBART: một mô hình sequence-to-sequence được huấn luyện trước tiếng Ả Rập cho tóm tắt trừu tượng. Trong Kỷ yếu Hội thảo Xử lý Ngôn ngữ Tự nhiên Ả Rập lần thứ bảy (WANLP), trang 31–42, Abu Dhabi, Các Tiểu vương quốc Ả Rập Thống nhất (Lai). Association for Computational Linguistics.

Joongwon Kim, Mounica Maddela, Reno Kriz, Wei Xu, and Chris Callison-Burch. 2021. BiSECT: Học cách tách và diễn đạt lại câu với bitexts. Trong Kỷ yếu Hội nghị 2021 về Phương pháp Thực nghiệm trong Xử lý Ngôn ngữ Tự nhiên, trang 6193–6209, Trực tuyến và Punta Cana, Cộng hòa Dominican. Association for Computational Linguistics.

Diederick P Kingma and Jimmy Ba. 2015. Adam: Một phương pháp cho tối ưu hóa ngẫu nhiên. Trong Hội nghị Quốc tế về Biểu diễn Học tập.

Taku Kudo and John Richardson. 2018. SentencePiece: Một tokenizer và detokenizer từ phụ đơn giản và độc lập ngôn ngữ cho xử lý văn bản thần kinh. Trong Kỷ yếu Hội nghị 2018 về Phương pháp Thực nghiệm trong Xử lý Ngôn ngữ Tự nhiên: Trình diễn Hệ thống, trang 66–71, Brussels, Belgium. Association for Computational Linguistics.

Moreno La Quatra and Luca Cagliero. 2023. Bart-it: Một mô hình sequence-to-sequence hiệu quả cho tóm tắt văn bản tiếng Ý. Future Internet, 15(1).

Faisal Ladhak, Esin Durmus, Claire Cardie, and Kathleen McKeown. 2020. WikiLingua: Một bộ dữ liệu chuẩn mực mới cho tóm tắt trừu tượng xuyên ngôn ngữ. Trong Findings of the Association for Computational Linguistics: EMNLP 2020, trang 4034–4048, Trực tuyến. Association for Computational Linguistics.

Katherine Lee, Daphne Ippolito, Andrew Nystrom, Chiyuan Zhang, Douglas Eck, Chris Callison-Burch, and Nicholas Carlini. 2022. Khử trùng lặp dữ liệu huấn luyện làm cho các mô hình ngôn ngữ tốt hơn. Trong Kỷ yếu Cuộc họp Thường niên lần thứ 60 của Hiệp hội Ngôn ngữ học Tính toán (Tập 1: Bài báo Dài), trang 8424–8445, Dublin, Ireland. Association for Computational Linguistics.

Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Veselin Stoyanov, and Luke Zettlemoyer. 2020a. BART: Huấn luyện trước sequence-to-sequence khử nhiễu cho tạo sinh, dịch thuật và hiểu biết ngôn ngữ tự nhiên. Trong Kỷ yếu Cuộc họp Thường niên lần thứ 58 của Hiệp hội Ngôn ngữ học Tính toán, trang 7871–7880, Trực tuyến. Association for Computational Linguistics.

Patrick Lewis, Barlas Oguz, Ruty Rinott, Sebastian Riedel, and Holger Schwenk. 2020b. MLQA: Đánh giá trả lời câu hỏi trích xuất xuyên ngôn ngữ. Trong Kỷ yếu Cuộc họp Thường niên lần thứ 58 của Hiệp hội Ngôn ngữ học Tính toán, trang 7315–7330, Trực tuyến. Association for Computational Linguistics.

Chin-Yew Lin. 2004. ROUGE: Một gói cho đánh giá tự động tóm tắt. Trong Tóm tắt văn bản Phân nhánh Ra, trang 74–81, Barcelona, Tây Ban Nha. Association for Computational Linguistics.

Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. 2019. Roberta: Một cách tiếp cận huấn luyện trước bert được tối ưu hóa mạnh mẽ.

Ilya Loshchilov and Frank Hutter. 2019. Chính quy hóa suy giảm trọng số tách rời. Trong Hội nghị Quốc tế về Biểu diễn Học tập.

Louis Martin, Benjamin Muller, Pedro Javier Ortiz Suárez, Yoann Dupont, Laurent Romary, Éric de la Clergerie, Djamé Seddah, and Benoît Sagot. 2020. CamemBERT: một mô hình ngôn ngữ tiếng Pháp ngon. Trong Kỷ yếu Cuộc họp Thường niên lần thứ 58 của Hiệp hội Ngôn ngữ học Tính toán, trang 7203–7219, Trực tuyến. Association for Computational Linguistics.

Lorenzo De Mattei, Michele Cafagna, Felice Dell'Orletta, Malvina Nissim, and Marco Guerini. 2020. Geppetto khắc tiếng Ý thành một mô hình ngôn ngữ. Trong Kỷ yếu Hội nghị Italy thứ bảy về Ngôn ngữ học Tính toán, CLiC-it 2020, Bologna, Italy, 1-3 tháng 3, 2021, tập 2769 của CEUR Workshop Proceedings. CEUR-WS.org.

El Moatez Billah Nagoudi, AbdelRahim Elmadany, and Muhammad Abdul-Mageed. 2022. AraT5: Transformer văn bản-thành-văn bản cho tạo sinh ngôn ngữ Ả Rập. Trong Kỷ yếu Cuộc họp Thường niên lần thứ 60 của Hiệp hội Ngôn ngữ học Tính toán (Tập 1: Bài báo Dài), trang 628–647, Dublin, Ireland. Association for Computational Linguistics.

--- TRANG 13 ---
Piotr Nawrot. 2023. nanoT5: Huấn luyện trước và tinh chỉnh nhanh & đơn giản các mô hình t5 với tài nguyên hạn chế. Trong Kỷ yếu Hội thảo lần thứ 3 cho Phần mềm Mã nguồn Mở Xử lý Ngôn ngữ Tự nhiên (NLP-OSS 2023), trang 95–101, Singapore. Association for Computational Linguistics.

Myle Ott, Sergey Edunov, Alexei Baevski, Angela Fan, Sam Gross, Nathan Ng, David Grangier, and Michael Auli. 2019. fairseq: Một bộ công cụ nhanh, có thể mở rộng cho mô hình hóa chuỗi. Trong Kỷ yếu Hội nghị 2019 của Chương Bắc Mỹ của Hiệp hội Ngôn ngữ học Tính toán (Trình diễn), trang 48–53, Minneapolis, Minnesota. Association for Computational Linguistics.

Nedjma Ousidhoum, Shamsuddeen Hassan Muhammad, Mohamed Abdalla, Idris Abdulmumin, Ibrahim Said Ahmad, Sanchit Ahuja, Alham Fikri Aji, Vladimir Araujo, Abinew Ali Ayele, Pavan Baswani, Meriem Beloucif, Chris Biemann, Sofia Bourhim, Christine De Kock, Genet Shanko Dekebo, Oumaima Hourrane, Gopichand Kanumolu, Lokesh Madasu, Samuel Rutunda, Manish Shrivastava, Thamar Solorio, Nirmal Surange, Hailegnaw Getaneh Tilaye, Krishnapriya Vishnubhotla, Genta Winata, Seid Muhie Yimam, and Saif M. Mohammad. 2024. Semrel2024: Một bộ sưu tập các bộ dữ liệu liên quan văn bản ngữ nghĩa cho 14 ngôn ngữ.

Matt Post. 2018. Một lời kêu gọi sự rõ ràng trong báo cáo điểm BLEU. Trong Kỷ yếu Hội nghị lần thứ ba về Dịch máy: Bài báo Nghiên cứu, trang 186–191, Brussels, Belgium. Association for Computational Linguistics.

Alec Radford and Ilya Sutskever. 2018. Cải thiện hiểu biết ngôn ngữ bằng huấn luyện trước tạo sinh.

Alec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. 2019. Các mô hình ngôn ngữ là những người học đa tác vụ không giám sát.

Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J. Liu. 2020. Khám phá giới hạn của học chuyển giao với một transformer văn bản-thành-văn bản thống nhất. Journal of Machine Learning Research, 21(140):1–67.

Sascha Rothe, Shashi Narayan, and Aliaksei Severyn. 2020. Tận dụng các checkpoint được huấn luyện trước cho các tác vụ tạo sinh chuỗi. Transactions of the Association for Computational Linguistics, 8:264–280.

Gabriele Sarti and Malvina Nissim. 2022. It5: Huấn luyện trước văn bản-thành-văn bản quy mô lớn cho hiểu biết và tạo sinh ngôn ngữ tiếng Ý.

Thomas Scialom, Paul-Alexis Dray, Sylvain Lamprier, Benjamin Piwowarski, and Jacopo Staiano. 2020. MLSUM: Kho dữ liệu tóm tắt đa ngôn ngữ. Trong Kỷ yếu Hội nghị 2020 về Phương pháp Thực nghiệm trong Xử lý Ngôn ngữ Tự nhiên (EMNLP), trang 8051–8067, Trực tuyến. Association for Computational Linguistics.

Alejandro Vaca Serrano, Guillem Garcia Subies, Helena Montoro Zamorano, Nuria Aldama Garcia, Doaa Samy, David Betancur Sanchez, Antonio Moreno Sandoval, Marta Guerrero Nieto, and Alvaro Barbero Jimenez. 2022. Rigoberta: Một mô hình ngôn ngữ tiên tiến cho tiếng Tây Ban Nha.

Kaitao Song, Xu Tan, Tao Qin, Jianfeng Lu, and Tie-Yan Liu. 2019. MASS: Huấn luyện trước chuỗi che thành chuỗi cho tạo sinh ngôn ngữ. Trong Kỷ yếu Hội nghị Quốc tế lần thứ 36 về Học máy, tập 97 của Kỷ yếu Nghiên cứu Học máy, trang 5926–5936. PMLR.

Pedro Javier Ortiz Suárez, Benoît Sagot, and Laurent Romary. 2019. Đường ống không đồng bộ để xử lý các kho dữ liệu khổng lồ trên cơ sở hạ tầng tài nguyên trung bình đến thấp. Kỷ yếu Hội thảo về Thách thức trong Quản lý Kho dữ liệu Lớn (CMLC-7) 2019. Cardiff, 22 tháng 7 năm 2019, trang 9-16, Mannheim. Leibniz-Institut für Deutsche Sprache.

Ilya Sutskever, Oriol Vinyals, and Quoc V Le. 2014. Học chuỗi thành chuỗi với mạng thần kinh. Trong Tiến bộ trong Hệ thống Xử lý Thông tin Thần kinh, tập 27. Curran Associates, Inc.

Yuqing Tang, Chau Tran, Xian Li, Peng-Jen Chen, Naman Goyal, Vishrav Chaudhary, Jiatao Gu, and Angela Fan. 2020. Dịch thuật đa ngôn ngữ với huấn luyện trước và tinh chỉnh đa ngôn ngữ có thể mở rộng.

Eric S. Tellez, Daniela Moctezuma, Sabino Miranda, Mario Graff, and Guillermo Ruiz. 2023. Các mô hình khu vực hóa cho các biến thể ngôn ngữ tiếng Tây Ban Nha dựa trên twitter. Language Resources and Evaluation, 57(4):1697–1727.

Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave, and Guillaume Lample. 2023. Llama: Các mô hình nền tảng mở và hiệu quả.

--- TRANG 14 ---
Nguyen Luong Tran, Duong Le, and Dat Quoc Nguyen. 2022. BARTpho: Các mô hình sequence-to-sequence được huấn luyện trước cho tiếng Việt. Trong Interspeech 2022. ISCA.

Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. Trong Tiến bộ trong Hệ thống Xử lý Thông tin Thần kinh, tập 30. Curran Associates, Inc.

Antti Virtanen, Jenna Kanerva, Rami Ilo, Jouni Luoma, Juhani Luotolahti, Tapio Salakoski, Filip Ginter, and Sampo Pyysalo. 2019. Đa ngôn ngữ là chưa đủ: Bert cho tiếng Phần Lan.

Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Remi Louf, Morgan Funtowicz, Joe Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest, and Alexander Rush. 2020. Transformers: Xử lý ngôn ngữ tự nhiên tiên tiến. Trong Kỷ yếu Hội nghị 2020 về Phương pháp Thực nghiệm trong Xử lý Ngôn ngữ Tự nhiên: Trình diễn Hệ thống, trang 38–45, Trực tuyến. Association for Computational Linguistics.

Wei Xu, Courtney Napoles, Ellie Pavlick, Quanze Chen, and Chris Callison-Burch. 2016. Tối ưu hóa dịch máy thống kê cho đơn giản hóa văn bản. Transactions of the Association for Computational Linguistics, 4:401–415.

Linting Xue, Noah Constant, Adam Roberts, Mihir Kale, Rami Al-Rfou, Aditya Siddhant, Aditya Barua, and Colin Raffel. 2021. mT5: Một transformer văn bản-thành-văn bản được huấn luyện trước đa ngôn ngữ khối lượng lớn. Trong Kỷ yếu Hội nghị 2021 của Chương Bắc Mỹ của Hiệp hội Ngôn ngữ học Tính toán: Công nghệ Ngôn ngữ Con người, trang 483–498, Trực tuyến. Association for Computational Linguistics.

Yizhe Zhang, Siqi Sun, Michel Galley, Yen-Chun Chen, Chris Brockett, Xiang Gao, Jianfeng Gao, Jingjing Liu, and Bill Dolan. 2020. DIALOGPT: Huấn luyện trước tạo sinh quy mô lớn cho tạo sinh phản hồi đối thoại. Trong Kỷ yếu Cuộc họp Thường niên lần thứ 58 của Hiệp hội Ngôn ngữ học Tính toán: Trình diễn Hệ thống, trang 270–278, Trực tuyến. Association for Computational Linguistics.

Meng Zhou, Zechen Li, Bowen Tan, Guangtao Zeng, Wenmian Yang, Xuehai He, Zeqian Ju, Subrato Chakravorty, Shu Chen, Xingyi Yang, Yichen Zhang, Qingyang Wu, Zhou Yu, Kun Xu, Eric Xing, and Pengtao Xie. 2021. Về việc tạo sinh đối thoại y tế cho COVID-19. Trong Kỷ yếu Cuộc họp Thường niên lần thứ 59 của Hiệp hội Ngôn ngữ học Tính toán và Hội nghị Chung Quốc tế lần thứ 11 về Xử lý Ngôn ngữ Tự nhiên (Tập 2: Bài báo Ngắn), trang 886–896, Trực tuyến. Association for Computational Linguistics.

--- TRANG 15 ---
Phụ lục A: Longformer-Encoder-Decoder cho tiếng Tây Ban Nha (LEDO)

Các mô hình ngôn ngữ được huấn luyện trước dựa trên Transformer gặp phải thách thức trong việc xử lý các chuỗi dài do sự mở rộng bậc hai của cơ chế tự chú ý với độ dài chuỗi. Để giải quyết vấn đề này, Beltagy et al. (2020) đã giới thiệu Longformer, kết hợp tự chú ý ngữ cảnh cục bộ cửa sổ với chú ý toàn cục được thúc đẩy bởi tác vụ để giảm bớt hạn chế độ dài đầu vào tối đa. Một phần mở rộng của Longformer, LED, thích ứng BART cho mục đích này. Trong công trình của chúng tôi, chúng tôi khám phá sự phù hợp của mô hình BARTO trong khung này. Chúng tôi trình bày LEDO, một mô hình có khả năng xử lý các chuỗi lên đến 16K token.

Theo cách tiếp cận của Beltagy et al. (2020), chúng tôi xây dựng LEDO bằng cách tận dụng trọng số của BARTO và khởi tạo ma trận nhúng vị trí mới của nó bằng cách sao chép lặp đi lặp lại 16 lần 1K nhúng vị trí của BARTO.

XLSum EUR-Lex-Sum
R1 R2 RL R1 R2 RL
BARTO 31.02/31.26 10.68/10.72 21.96/23.81 66.49/65.91 49.99/48.39 56.01/54.15
LEDO 32.23/32.19 12.82/12.72 24.10/24.13 62.12/61.11 40.98/39.48 44.95/43.51

Bảng 9: Kết quả tác vụ tóm tắt dạng dài trên tập phát triển/kiểm tra sử dụng chỉ số ROUGE.

Bảng 9 trình bày kết quả cho tóm tắt dạng dài sử dụng BARTO và LEDO. Chúng tôi duy trì thiết lập và siêu tham số nhất quán để chạy các thí nghiệm LEDO. Thú vị, LEDO thể hiện hiệu suất vượt trội so với BARTO trong XLSum, với trung bình 23.03%, thể hiện khả năng xử lý đầu vào dài hiệu quả hơn. Tuy nhiên, trong EUR-Lex-Sum, BARTO vượt trội hơn LEDO, đạt được hiệu suất trung bình 48.69%. Sự khác biệt này có thể được gán cho việc sử dụng cùng siêu tham số cho LEDO như những tham số cho BARTO, có thể không tối ưu. Cần điều tra thêm để khám phá đầy đủ tiềm năng của LEDO, điều này sẽ được theo đuổi trong công trình tương lai.

The Vault: Một Tập Dữ Liệu Đa Ngôn Ngữ Toàn Diện để Thúc Đẩy Hiểu Biết và Sinh Code

Dung Nguyen Manh1,∗, Nam Le Hai1,3,∗, Anh T. V . Dau1,3,
Anh Minh Nguyen1, Khanh Nghiem1, Jin Guo4,5, Nghi D. Q. Bui2
1FPT Software AI Center
{dungnm31, namlh35, anhdtv7, minhna4, khanhnv22 }@fpt.com
2Fulbright University, Viet Nam
nghi.bui@fulbright.edu.vn
3Hanoi University of Science and Technology, Viet Nam
4School of Computer Science, McGill University, Canada
5Mila - Quebec AI Institute

Tóm tắt
Chúng tôi giới thiệu The Vault, một tập dữ liệu các cặp code-text chất lượng cao ở nhiều ngôn ngữ lập trình để huấn luyện các mô hình ngôn ngữ lớn hiểu và sinh code. Chúng tôi trình bày các phương pháp để trích xuất kỹ lưỡng các mẫu sử dụng cả phương pháp dựa trên quy tắc và phương pháp dựa trên deep learning để đảm bảo chúng chứa các cặp code và text chất lượng cao, tạo ra một tập dữ liệu gồm 43 triệu cặp code-text chất lượng cao. Các đánh giá toàn diện của chúng tôi trên các tác vụ coding phổ biến bao gồm sinh code, tìm kiếm code và tóm tắt code cho thấy khi fine-tuning các Code Large Language Models trên The Vault, các mô hình này vượt trội hơn các mô hình tương tự được huấn luyện trên các tập dữ liệu khác như CodeSearchNet. Chúng tôi cũng cung cấp các phân tích chi tiết về tập dữ liệu của mình để đánh giá tác động của các ngôn ngữ lập trình khác nhau và docstrings lên hiệu suất của các mô hình như vậy.

1 Giới thiệu

Sự ra đời của deep learning và những tiến bộ trong các mô hình ngôn ngữ lớn (LLMs) đã thúc đẩy một cuộc cách mạng trong lĩnh vực học biểu diễn code. Những phát triển này, được hỗ trợ bởi khả năng tiếp cận ngày càng tăng của các kho source code mở rộng lớn, đã báo hiệu sự xuất hiện của các code large language models (CodeLLMs) cho các tác vụ sinh code và hiểu code. Khối lượng khổng lồ của các kho này và dữ liệu thô phong phú, chưa được xử lý mà chúng chứa, phục vụ như những nguồn tài nguyên vô song để huấn luyện LLMs. Do đó, các mô hình hiện đại tối tân cho các tác vụ coding hiệu quả sử dụng những tập dữ liệu mở rộng này để huấn luyện. Tuy nhiên, điều quan trọng cần lưu ý là những tập dữ liệu này, bao gồm The Stack [Kocetkov et al., 2022] và The Pile [Gao et al., 2020a], thường bao gồm dữ liệu chưa được xử lý.

Thay vào đó, có những tập dữ liệu đã được thiết lập, như CONCODE [Iyer et al., 2018b], FunCom [LeClair et al., 2019], Deepcom [Hu et al., 2020] cho các tác vụ tóm tắt code; APPS [Hendrycks et al., 2021] cho sinh text-to-code; và CodeSearchNet [Husain et al., 2019] cho tìm kiếm code. Các tập dữ liệu này chứa các cặp code-text được tuyển chọn cẩn thận. Mặc dù nhỏ hơn đáng kể so với các tập dữ liệu code thô (ví dụ, 2.3M functions trong CodeSearchNet [Husain et al., 2019] so với 197M files trong The Stack [Kocetkov et al., 2022]), chúng cung cấp các cặp code-text chất lượng cao làm tăng đáng kể hiệu quả của việc huấn luyện mô hình.

Do đó, chúng tôi xác định hai loại chính của tập dữ liệu được sử dụng để huấn luyện CodeLLMs: lớn nhưng chưa được xử lý, và nhỏ hơn nhưng được cấu trúc tốt (ví dụ, được sắp xếp thành các cặp code-text). Luật scaling [Kaplan et al., 2020, Gordon et al., 2021, Sorscher et al., 2022] chỉ ra rằng khối lượng dữ liệu huấn luyện rất quan trọng cho hiệu suất mô hình. Tuy nhiên, các nghiên cứu khác nhấn mạnh tầm quan trọng của chất lượng tập dữ liệu hơn số lượng trong việc huấn luyện LLMs vượt trội [Zhou et al., 2023, Sorscher et al., 2022, Dau et al., 2022, Brown et al., 2020, Khan et al., 2020]. Dựa trên những quan sát này, chúng tôi đề xuất rằng một tập dữ liệu lý tưởng để huấn luyện CodeLLMs nên kết hợp cả hai yếu tố: nó nên có khối lượng mở rộng và được xử lý tỉ mỉ để đảm bảo chất lượng.

Trong bài báo này, chúng tôi trình bày tập dữ liệu The Vault, chi tiết về quy trình tạo ra nó, bộ công cụ được phát triển để xây dựng và kiểm soát chất lượng các cặp code-text từ source code thô, cũng như phân tích về các số liệu của The Vault. Chúng tôi cũng chia sẻ các kết quả thực nghiệm thu được từ việc sử dụng The Vault để fine-tune các mô hình nền tảng nổi tiếng. Các đóng góp cụ thể của chúng tôi bao gồm:

• Một tập dữ liệu với khoảng 43M cặp code-text chất lượng cao (lớn hơn 10 lần so với CoDesc), 243M mẫu unimodal, và 69M cặp line comments với context từ 10 ngôn ngữ lập trình phổ biến (Java, JavaScript, Python, Ruby, Rust, Golang, C#, C++, C, PHP), đa dạng hơn CodeSearchNet, có sáu ngôn ngữ lập trình.

• Một phương pháp mới để sử dụng mô hình ngôn ngữ pre-trained để phát hiện và loại bỏ các mẫu nhiễu nhằm bổ sung cho các phương pháp dựa trên quy tắc truyền thống.

• Một quy trình kỹ lưỡng để chuyển đổi source code thô thành các cặp code-text và lọc các mẫu nhiễu. Chúng tôi đã phát hành bộ công cụ được sử dụng trong quy trình này cho cộng đồng mở qua một repository GitHub công cộng, bao gồm các công cụ để phân tích code và docstrings trong các ngôn ngữ lập trình khác nhau.

• Chúng tôi thực hiện đánh giá toàn diện nơi chúng tôi fine-tuned các CodeLLMs khác nhau với The Vault so với các tập dữ liệu khác, như CodeSearchNet trên các tác vụ hiểu code khác nhau, bao gồm sinh code, tóm tắt code và tìm kiếm code. Kết quả cho thấy các mô hình được fine-tuned trên The Vault vượt trội hơn những mô hình được fine-tuned trên CodeSearchNet (tóm tắt code, tìm kiếm code) và vượt trội hơn mô hình gốc với một khoảng cách đáng kể (sinh code trên pass@k qua các tập dữ liệu HumanEval và MBPP).

2 Công trình liên quan

Code Large Language Models để Hiểu và Sinh Code
Code large language models hỗ trợ nhiều tác vụ hiểu code và sinh code khác nhau, bao gồm nhưng không giới hạn ở sinh code [Feng et al., 2020a, Wang et al., 2023, Elnaggar et al., 2021, To et al., Luo et al., 2023, Shen et al., 2023], hoàn thiện code [Feng et al., 2020a, Wang et al., 2023, Peng et al., 2021], sửa chương trình [Xia et al., 2022], phân loại chương trình [Bui et al., 2021a,c,b] và dịch code [Roziere et al., 2020, Bui et al., 2019]. Một phần đáng kể của nghiên cứu gần đây sử dụng các mô hình ngôn ngữ, ban đầu được phát triển cho xử lý ngôn ngữ tự nhiên, để xử lý code [Feng et al., 2020a, Wang et al., 2023, Guo et al., Ahmad et al., 2021b, Bui et al., 2021b, Elnaggar et al., 2021, Peng et al., 2021, Kanade et al., 2020, Chakraborty et al., 2022, Ahmed and Devanbu, 2022, Niu et al., 2022]. Các phương pháp như vậy phần lớn coi code như tương tự với text và điều chỉnh các chiến lược pretraining phản ánh những chiến lược được sử dụng cho ngôn ngữ tự nhiên. CodeBERT [Feng et al., 2020a], chẳng hạn, sửa đổi một mô hình Roberta [Liu et al., 2019] để pretrain một mô hình code trên nhiều ngôn ngữ lập trình. CodeT5 [Wang et al., 2021] và CodeT5+ [Wang et al., 2023] sử dụng thông tin định danh duy nhất từ source code để pretrain mô hình T5 [Raffel et al., 2019] cho code theo cách multi-modal.

Tập Dữ Liệu cho Học Biểu Diễn Code:
Code thường được biểu diễn trong các tập dữ liệu huấn luyện cho LLMs nền tảng, bao gồm corpus ROOTS [Laurençon et al., 2023] để huấn luyện BLOOM [Scao et al., 2022] và The Pile [Gao et al., 2020a] để huấn luyện LLaMA [Touvron et al., 2023]. Dữ liệu code được biểu diễn trong các tập dữ liệu này là source code thô không được gán nhãn từ GitHub. Cũng có một họ các tập dữ liệu chỉ có code để huấn luyện hoặc fine-tuning các LLMs chuyên về coding, bao gồm The Stack [Kocetkov et al., 2022], một corpus 3TB source code được cấp phép một cách cho phép, được đi trước bởi CodeParrot với 50GB source code đã được deduplicated [Tunstall et al., 2022]. Những tập dữ liệu khổng lồ này thường được sử dụng để huấn luyện CodeLLMs. Tuy nhiên, dữ liệu có nhãn được yêu cầu để huấn luyện và đánh giá LLMs cho các tác vụ coding liên quan đến source code và mô tả ngôn ngữ tự nhiên. CodeXGLUE là một tập dữ liệu benchmark Lu et al. [2021] cho 10 tác vụ coding bao gồm 14 tập con, bốn trong số đó là các cặp code-text. Phần lớn các cặp code-text trong CodeXGLUE đến từ CodeSearchNet.

CodeSearchNet (CSN) cũng đã được sử dụng để pretraining LLMs, cho phép các kỹ thuật học có giám sát đạt được hiệu suất tối tân cho các mô hình như CodeT5+ [Wang et al., 2023] và UniXcoder [Guo et al., 2022]. Một vài tập dữ liệu cặp code-text đặt mục tiêu vượt qua CSN về kích thước. CoDesc kết hợp các tập dữ liệu song song hiện có (CSN, DeepCom [Hu et al., 2020], CONCODE [Iyer et al., 2018a], và FunCom [LeClair et al., 2019]), và sau đó tinh chỉnh kết quả từ superset, tạo ra 4.2M mẫu dữ liệu Java. PyMT5 [Clement et al., 2020] là một tập dữ liệu với 7.7M Python code-text. Tuy nhiên, cả hai tập dữ liệu này mỗi cái chứa code cho một ngôn ngữ lập trình duy nhất. Các tập dữ liệu đáng chú ý được tạo từ Stack Overflow bao gồm dữ liệu code-text cần thiết để sinh tiêu đề bài đăng [Gao et al., 2020b, Liu et al., 2022].

3 Tập dữ liệu The Vault

3.1 Tổng quan

Trong The Vault, chúng tôi tận dụng một tập con của The Stack [Kocetkov et al., 2022], được công nhận là tập dữ liệu source code đa ngôn ngữ, được cấp phép cho phép, có sẵn công khai rộng lớn nhất với trọng lượng 3TB. Từ tập dữ liệu quy mô lớn này, The Vault chuyển đổi source code thô thành một bộ sưu tập các cặp code và text chất lượng cao. Pipeline chuyển đổi của chúng tôi được thiết kế để trích xuất dữ liệu hiệu quả từ source code, tạo các cặp text-code, và loại bỏ nhiễu, tạo ra ba tập dữ liệu đầu ra riêng biệt, như được chi tiết trong Hình 2. Chúng tôi rút ra từ một tập con của The Stack, bao gồm code trong 10 ngôn ngữ lập trình phổ biến, như C, C#, C++, Java, JavaScript, GoLang, PHP, Python, Ruby, và Rust (trong tổng số 300 ngôn ngữ có trong The Stack). Mỗi source code thô cụ thể cho ngôn ngữ được đưa vào một tree-sitter parser được xây dựng tùy chỉnh.

Parser này được thiết kế để trích xuất functions, classes, methods, block code snippets, và các block hoặc inline comments tương ứng của chúng. Hình 1 minh họa cấu trúc cơ bản của một file code chứa nhiều level của code snippets. Bằng cách áp dụng tìm kiếm theo chiều rộng trên Abstract Syntax Tree (AST) của root node, parser có thể duyệt xuống các node và leaf levels khác nhau (class, function, và inline), tạo ra ba tập dữ liệu riêng biệt:

1. Tập dữ liệu đầu ra đầu tiên, được gọi là Dpaired, chứa các cặp classes (node 1) và functions (node 3) với các block comments tương ứng phục vụ như docstrings (node 2). Sau khi xây dựng ban đầu, tập dữ liệu này trải qua một pipeline sử dụng cả bộ lọc dựa trên quy tắc và bộ lọc dựa trên neural để loại bỏ các mẫu nhiễu không đáp ứng các tiêu chí được chi tiết trong Phần 3.2.

2. Tập dữ liệu đầu ra thứ hai, được ký hiệu là Dunimodal, bao gồm các functions và classes độc lập, không được ghép đôi với bất kỳ docstring hoặc comments nào, do đó tạo thành một tập dữ liệu unimodal.

3. Tập dữ liệu thứ ba và cuối cùng, Dblock, bao gồm các cặp code blocks tùy ý (node 4) và inline comments (node 5). Để xây dựng tập này, chúng tôi bắt tất cả inline comments. Mỗi comment được ghép đôi với code block đi trước, được gắn thẻ là "previous context" (node 4a), và code block theo sau, "next context" (node 4b).

Một số lượng lớn block comments tuân theo các định dạng docstring được chấp nhận rộng rãi (Phụ lục A.5), bao gồm các chi tiết được tổ chức gọn gàng về tên (identifier) của function hoặc class liên quan, các parameters, arguments, và return types của chúng. Chúng tôi dẫn những block comments này qua các docstring parsers, mà chúng tôi đã phát triển và cung cấp công khai, để trích xuất thông tin này như metadata cho mỗi mẫu trong tập dữ liệu của chúng tôi. Chúng tôi cho rằng metadata này có thể chứng minh hữu ích cho các tác vụ downstream, cài đặt prompt, và các ứng dụng khác (Hình 8). Tập hợp, ba tập dữ liệu này (Dblock, Dunimodal, và Dpaired) tạo thành The Vault.

Lưu ý rằng thông qua quá trình đánh giá, chỉ Dpaired được sử dụng vì nó chứa dữ liệu phù hợp để huấn luyện và so sánh với các tập dữ liệu khác.

3.2 Pipeline Làm sạch Dữ liệu

Từ khảo sát sơ bộ về tập dữ liệu đầu ra chứa các cặp classes và functions với các block comments tương ứng của chúng Dpaired, chúng tôi quan sát các mẫu nổi bật sẽ làm suy giảm chất lượng huấn luyện cho các tác vụ liên quan đến code. Chúng tôi triển khai một bộ bộ lọc dựa trên quy tắc (Phần 3.2.1) để loại bỏ thông tin không liên quan hoặc định dạng lại dữ liệu văn bản để mô tả tốt hơn về code block tương ứng. Để giải quyết các trường hợp mà các cặp code-text có tương quan ngữ nghĩa không đầy đủ hoặc sai lệch, chúng tôi huấn luyện một mô hình dựa trên neural dựa trên CodeBERT (Phần 3.2.2) để phục vụ như một bộ lọc. Bộ lọc như vậy tạo ra một điểm số, được sử dụng để đánh giá sự căn chỉnh của một cặp code và text. Các mẫu có điểm số thấp được giả định là không được căn chỉnh và sẽ bị loại bỏ.

3.2.1 Loại bỏ Mẫu Nhiễu bằng Quy tắc

Pipeline dữ liệu của chúng tôi sử dụng 13 bộ lọc dựa trên quy tắc để loại bỏ các mẫu nhiễu trong tập dữ liệu nguồn. Những bộ lọc này, được chi tiết trong Bảng 1, được phân loại thành ba nhóm chính: tăng cường khả năng đọc, thúc đẩy tính nhất quán, và bảo tồn mục đích sử dụng dự định của code.

Về mặt khả năng đọc, chúng tôi loại bỏ các delimiters, công thức toán học, HTML tags, và metadata tags từ text. Điều này đảm bảo một cặp code-text sạch hơn và mạch lạc hơn. Để có tính nhất quán, chúng tôi loại bỏ các yếu tố có thể gây ra sự bất thường trong tập dữ liệu. Điều này bao gồm loại bỏ hyperlinks và embedded code, và loại bỏ empty comments, comments quá ngắn hoặc quá dài, comments không phải tiếng Anh, blocks được tự động tạo, và comments đang trong quá trình thực hiện. Cuối cùng, để bảo tồn mục đích ban đầu của code, chúng tôi loại bỏ các comments là câu hỏi hoặc phục vụ như ví dụ hoặc ghi chú. Quy trình lọc nghiêm ngặt này đảm bảo một tập dữ liệu chất lượng cao, cải thiện hiệu quả của các mô hình ngôn ngữ tập trung vào code.

3.2.2 Loại bỏ Mẫu Chất lượng Thấp với Classifier dựa trên Neural

Ngoài việc sử dụng các phương pháp lọc dựa trên quy tắc, một câu hỏi quan trọng nảy sinh: làm thế nào chúng tôi đảm bảo sự căn chỉnh giữa code và text? Các comments ngẫu nhiên không liên quan đến chức năng của code snippet có thể làm ô nhiễm tập dữ liệu, cần thiết phải loại bỏ các mẫu không được căn chỉnh như vậy để đảm bảo chất lượng. Để giải quyết vấn đề này, chúng tôi xây dựng một classifier sử dụng CodeBERT [Feng et al., 2020b], được thiết kế để đánh điểm mối quan hệ ngữ nghĩa giữa một function hoặc class và docstring tương ứng của nó.

Trong mô hình đánh điểm của chúng tôi, chúng tôi nhập các code snippets và docstrings được phân tách bởi một token </s>. Khoảng 12% của tập dữ liệu các cặp code-text đã được lọc quy tắc được chọn ngẫu nhiên để huấn luyện. Vì dữ liệu có nhãn không có sẵn, chúng tôi tạo ra các mẫu âm tính bằng cách ghép đôi ngẫu nhiên các functions và docstrings trong cùng một ngôn ngữ lập trình. Sau đó chúng tôi truyền biểu diễn của token <s> vào một linear layer, tạo ra một điểm số tương quan ngữ nghĩa giữa 0.0 và 1.0. Các cặp code-text sau đó được lọc sử dụng một cổng phân loại nhị phân với ngưỡng 0.5.

Để xác thực mô hình của chúng tôi, chúng tôi sử dụng GPT 3.5 cho các dự đoán tương tự. Một triệu dự đoán được tạo ra từ các trường hợp chưa thấy, từ đó chúng tôi chọn 300 mẫu cho mỗi ngôn ngữ: 200 trường hợp có độ tin cậy cao (100 dự đoán code-text nhất quán và 100 không nhất quán) và 100 trường hợp có độ tin cậy thấp. GPT 3.5-turbo được hướng dẫn để gán một điểm số nhất quán (1-10) cho mỗi cặp code-docstring của trường hợp, phục vụ như một benchmark cho các dự đoán của mô hình chúng tôi. Đối với các trường hợp có độ tin cậy cao, mô hình của chúng tôi đồng ý với điểm số GPT 3.5-turbo hơn 80% thời gian. Mặc dù mô hình của chúng tôi gặp khó khăn với các mẫu mơ hồ, metric Area Under the Curve (AUC) đã chứng minh phù hợp do mục tiêu chính của chúng tôi là loại trừ sự không căn chỉnh trong khi bảo tồn các ví dụ khớp. Một AUC trung bình 0.89 chỉ ra rằng phương pháp của chúng tôi hiệu quả giảm nhiễu trong tập dữ liệu mà không loại bỏ nhiều mẫu thông tin. Các cấu hình chi tiết và kết quả đánh giá có sẵn trong Phụ lục A.2.

Ngoài ra, chúng tôi sử dụng mô hình của mình để tìm các ví dụ nhiễu trong phiên bản đã loại bỏ nhiễu dựa trên quy tắc của CodeSearchNet trong CodeXGlue. Bảng 3 trình bày một số ví dụ không nhất quán được tìm thấy bởi mô hình của chúng tôi cho Python, Java, JavaScript, và PHP trong CSN. Có thể quan sát rằng các cặp được phát hiện cho thấy sự không nhất quán mạnh giữa docstring và code. Chẳng hạn, docstring của ví dụ trong Python không cung cấp nhiều cái nhìn sâu sắc về những gì code làm hoặc mục đích của nó. Code định nghĩa một phương thức tên 'has url' kiểm tra xem các attributes có giá trị không trống; tuy nhiên, docstring đề cập đến templates mà không cung cấp đủ ngữ cảnh để hiểu đầy đủ code này liên quan đến templates như thế nào hoặc mục đích rộng lớn hơn của nó. Bên cạnh đó, mô hình của chúng tôi có thể xác định các mẫu không phải tiếng Anh, được trình bày trong ví dụ về PHP, mà không được bắt bởi các phương pháp dựa trên quy tắc.

4 Đánh giá Thực nghiệm

Trong phần này, chúng tôi nhằm đánh giá chất lượng của The Vault so với các tập dữ liệu khác, như CSN. Để chứng minh chất lượng này, chúng tôi fine-tune các CodeLLMs nổi bật trên các tác vụ đòi hỏi sự tham gia của cả code và text, bao gồm tóm tắt code, tìm kiếm code, và sinh code. Sau đó chúng tôi so sánh những mô hình này, đã được fine-tuned trên The Vault, với những mô hình được fine-tuned trên CSN. Việc so sánh được thực hiện sử dụng cùng các tập dữ liệu kiểm tra và các metrics được sử dụng phổ biến, như MRR, smoothed BLEU [Lin and Och, 2004], và pass@k [Chen et al., 2021].

4.1 Thống kê Tập dữ liệu

Bảng 2 cung cấp thống kê của các mẫu cho mỗi ngôn ngữ lập trình sau khi trải qua pipeline làm sạch dữ liệu của chúng tôi. Tổng cộng, chúng tôi có khoảng 34M mẫu. Bảng cũng bao gồm thông tin khác, như số lượng tokens cho code và docstrings, và số lượng repositories.

Bảng 4 cung cấp so sánh giữa The Vault và các tập dữ liệu song song khác thường được sử dụng để pretraining và fine-tuning các tác vụ downstream. Những tập dữ liệu này bao gồm Funcom [LeClair and McMillan, 2019], Deepcom [Hu et al., 2020], CONCODE [Iyer et al., 2018b], CSN [Husain et al., 2019], CoDesc [Hasan et al., 2021], và dữ liệu không công khai được sử dụng để pretraining [Clement et al., 2020, Ciurumela et al., 2020, Wang et al., 2021].

Chúng tôi chia tập huấn luyện thành hai tập con nhỏ hơn: tập nhỏ và tập trung bình chứa 5% và 20% của tập huấn luyện đầy đủ, tương ứng. Để giảm data leakage trong quá trình huấn luyện, chúng tôi sử dụng kỹ thuật MinHash LSH [Zhu et al., 2023] để lọc các cụm trường hợp huấn luyện gần với các mẫu trong tập validation và test của CSN, HumanEval, và MBPP. Ngoài ra, trong quá trình phân vùng tập dữ liệu, chúng tôi ngăn chặn nội dung từ cùng một repository xuất hiện trong nhiều tập, do đó tránh bất kỳ data leakage nội bộ tiềm ẩn nào. Một phân tích chi tiết hơn về The Vault ở cấp class và code block có thể được tìm thấy trong Phụ lục A.4.

4.2 Thiết lập Thực nghiệm

Chia dữ liệu: Trong giai đoạn thực nghiệm, The Vault (Dpaired) được chia thành ba tập dữ liệu riêng biệt: tập huấn luyện, validation, và testing. Để tránh data leakage, chúng tôi tăng cường một chính sách nơi các mẫu code từ cùng một repository phải tất cả ở trong cùng một tập. Trong thuật toán chia, chúng tôi cũng bao gồm như một mục tiêu việc bảo tồn phân phối độ dài token từ tập dữ liệu The Vault trong mỗi tập con. Để có các so sánh phong phú hơn, tập huấn luyện được phân nhánh tiếp thành hai tập nhỏ hơn, tập huấn luyện nhỏ và trung bình, lấy mẫu 5% và 20% của tập huấn luyện đầy đủ, tương ứng. Chi tiết về dữ liệu thực nghiệm có thể được tìm thấy trong Bảng 5. Lưu ý rằng TheVault/small có kích thước tương đương với CSN, làm cho việc đánh giá và so sánh chất lượng của hai tập dữ liệu này trở nên công bằng.

Bên cạnh đó, để xác thực hiệu quả của pipeline xử lý của chúng tôi, chúng tôi thực hiện so sánh giữa hiệu suất của các mô hình được huấn luyện trên The Stack (dữ liệu thô) và The Vault (dữ liệu được xử lý). Cụ thể, chúng tôi thiết lập ba tập con cấp function, mỗi tập có kích thước xấp xỉ TheVault/small (≈1.7M trường hợp code-text). Những tập con này được tạo bằng cách lấy mẫu ngẫu nhiên tập dữ liệu cấp function thô được trích xuất từ The Stack, mà không áp dụng bất kỳ lọc nào (được gọi là raw/TheStack). Chúng tôi sử dụng ba seeds khác nhau để lấy mẫu raw/TheStack và báo cáo kết quả trung bình. Tất cả các thực nghiệm được thực hiện sử dụng 4 NVIDIA A100 GPUs.

Tìm kiếm code: Chúng tôi chọn CodeBERT [Feng et al., 2020a], RoBERTa [Liu et al., 2019] và UniXCoder [Guo et al., 2022] như encoder để embedding source code và natural language query. Chúng tôi huấn luyện mỗi mô hình trong 10 epochs với độ dài tối đa sequence là 512, và learning rate là 2−5.

Tóm tắt code: CodeT5 [Wang et al., 2021] và PLBART [Ahmad et al., 2021a] được sử dụng cho tác vụ tóm tắt. Chúng tôi sử dụng các phiên bản base và đặt max input tokens là 512 và max output tokens là 400. Chúng tôi huấn luyện trong 5 epochs với batch size 512 và learning rate 2−4.

Sinh code: Chúng tôi sử dụng CodeGen 350M và 2B Multi [Nijkamp et al., 2023] để đánh giá sinh code. Chúng tôi sử dụng cùng cấu hình như trong tác vụ tóm tắt code.

4.3 Kết quả Đánh giá

4.3.1 Tóm tắt Code

Cho tác vụ này, chúng tôi sử dụng Vault và CSN để fine-tune CodeT5 và PLBART để tóm tắt source code. Vault và CSN thể hiện sự khác biệt đáng kể trong định dạng docstring. Vault giữ lại định dạng docstring hoàn chỉnh, cung cấp các mô tả toàn diện về logic cốt lõi, parameters, arguments, và return types. Tính năng này cho phép các ứng dụng đa dạng trong tài liệu code và các tác vụ downstream khác nhau. Ngoài ra, chúng tôi lưu câu đầu tiên của mỗi docstring hoàn chỉnh như metadata, được gọi là short docstring. Để tạo điều kiện so sánh công bằng giữa The Vault và CSN, chúng tôi áp dụng post-processing cho các tập huấn luyện full docstrings và short docstrings của chúng tôi, do đó giảm sự khác biệt phân phối định dạng.

Bảng 6 cho thấy kết quả khi so sánh CodeT5 và PLBART được huấn luyện trên CSN và The Vault cho tác vụ tóm tắt code, chúng tôi báo cáo điểm số tốt nhất khi sử dụng full docstrings và short docstrings. Chúng tôi trình bày các kết quả thực nghiệm bổ sung sử dụng các metrics Rouge-L [Lin, 2004] và BERTScore [Zhang et al., 2020] trong Phụ lục, Bảng 14. Kết quả cho thấy pipeline của chúng tôi đã chứng kiến hiệu quả mạnh mẽ so với dữ liệu chưa được xử lý, raw/TheStack. Đặc biệt, trong quá trình huấn luyện trên tập dữ liệu raw/TheStack cho tác vụ tóm tắt code, chúng tôi phát hiện PLBART và CodeT5 tạo ra outputs với nhiễu đáng kể. Những outputs này được đặc trưng bởi sự phổ biến của các special tokens như "//" và "*". Phát hiện này nhấn mạnh mạnh mẽ hiệu quả của quy trình lọc của chúng tôi trong việc nâng cao chất lượng tập dữ liệu. Tuy nhiên, kết quả sử dụng CSN cho thấy hiệu suất vượt trội trên testset của CSN hơn là sử dụng The Vault. Lý do cho điều này là việc chúng tôi đề cập đến bước post-processing để giảm sự khác biệt giữa các phương pháp lọc CSN và The Vault, nơi phân phối cú pháp vẫn có thể thể hiện các đặc tính không giống hệt nhau, có thể ảnh hưởng đến điểm số BLEU. Tuy nhiên, khoảng cách này có thể được giảm bằng cách sử dụng phiên bản đầy đủ của The Vault như được hiển thị trong Bảng 14. Mặc dù tổng mức tăng hiệu suất khi được đánh giá trên tập test CSN là rìa (21.73 so với 21.24), đáng chú ý rằng, bất chấp quá trình xử lý trung gian, CSN là một tập dữ liệu nhỏ hơn đáng kể với các mẫu docstring nhất quán hơn. Ngược lại, tập dữ liệu của chúng tôi lớn hơn đáng kể và thể hiện sự đa dạng lớn hơn, do đó khuyến khích khái quát hóa rộng hơn. Khi được đánh giá so với tập test của The Vault, mô hình được fine-tuned trên CSN tụt lại phía sau hơn 10%.

4.3.2 Tìm kiếm Code

Chúng tôi sử dụng CodeBERT, RoBERTa và UniXCoder để fine-tune cả The Vault và CSN cho mục đích tác vụ tìm kiếm code. Chúng tôi cũng cung cấp điểm số Mean Reciprocal Rank (MRR) cơ sở. MRR là một metric được sử dụng rộng rãi để đánh giá các tác vụ tìm kiếm code, và trong trường hợp của chúng tôi, nó được huấn luyện trên 10 ngôn ngữ lập trình khác nhau và được đánh giá sử dụng tập test từ CSN và The Vault. Kết quả của tác vụ này, khi fine-tuning mô hình trên The Vault và CSN, được minh họa trong Bảng 7. Đáng chú ý, chúng tôi đạt được kết quả vượt trội trong hầu hết các ngôn ngữ khi fine-tuned sử dụng tập dữ liệu nhỏ nhất, TheVault/small, so với chỉ fine-tuning trên corpus CSN. Đáng ngạc nhiên, RoBERTa, một mô hình pretrained trên natural language text, vượt trội hơn hai mô hình pretrained code khi được đánh giá trên tìm kiếm code. Điều này có thể ngụ ý tầm quan trọng của biểu diễn natural language text hơn biểu diễn code trong tác vụ này. Hơn nữa, các mô hình được huấn luyện trên The Vault nhất quán vượt trội hơn tất cả các mô hình baseline được huấn luyện trên raw/TheStack, nhấn mạnh cả hiệu quả của pipeline xử lý của chúng tôi và khả năng khái quát hóa của tập dữ liệu qua các kiến trúc khác nhau.

4.4 Sinh Code

Chúng tôi thực nghiệm với hai phiên bản của CodeGen Multi [Nijkamp et al., 2023], là các mô hình 350M và 2B trên các benchmarks HumanEval và MBPP cho sinh code. Phạm vi thực nghiệm của chúng tôi bị hạn chế vì các benchmarks chỉ hỗ trợ Python. Chúng tôi sử dụng những checkpoints này và tiếp tục fine-tuning chúng trên The Vault vì các mô hình CodeGen Multi được huấn luyện trên tập dữ liệu với nhiều ngôn ngữ.

Để tạo Py/CodeSearchNet và Py/TheVault, chúng tôi sử dụng các tập con Python của CSN và TheVault, tương ứng. Chúng tôi lấy mẫu tập huấn luyện Python của TheVault để khớp với kích thước của tập con Python trong CSN với 250K mẫu trong vòng fine-tuning đầu tiên. Ngoài ra, raw/PyTheStack là một tập con của dữ liệu Python từ The Stack phản ánh kích thước của dữ liệu Python có trong tập dữ liệu The Vault, giúp chúng tôi chứng minh những tiến bộ đạt được trong pipeline xử lý dữ liệu của chúng tôi.

Kết quả được hiển thị trong Bảng 8. Chúng ta có thể thấy rằng fine-tuning CodeGen Multi 350M trên The Vault khiến mô hình cải thiện đáng kể về mặt pass@1, pass@10, và pass@100 trên các benchmarks HumanEval và MBPP. Ngoài ra, CodeGen 2B được sử dụng để đánh giá The Vault trên các mô hình quy mô lớn hơn. Tương tự như các thực nghiệm trên các mô hình nhỏ, Bảng 8 cho thấy The Vault có thể cải thiện hiệu suất của các mô hình pretrained quy mô lớn hiện có. Những kết quả này xác thực khả năng của The Vault trong việc cải thiện hiệu suất của các mô hình pretrained hiện có. Trong tương lai, chúng tôi sẽ mở rộng đánh giá của mình đến các mô hình quy mô lớn hơn và đánh giá tác động của The Vault lên chúng.

5 Kết luận

Trong bài báo này, chúng tôi đã trình bày The Vault, một tập dữ liệu lớn của các cặp code-text chất lượng cao từ mười ngôn ngữ lập trình, với hơn 43 triệu mẫu. The Vault được tuyển chọn cẩn thận để đảm bảo rằng mỗi cặp đáp ứng các tiêu chuẩn chất lượng, với các mô tả chi tiết và thông tin và các phong cách coding nhất quán. Phân tích của chúng tôi đã phát hiện ra một số mẫu và xu hướng hấp dẫn làm sáng tỏ các đặc tính của ngôn ngữ lập trình và thực hành coding. Chúng tôi tin rằng The Vault sẽ là một nguồn tài nguyên có giá trị cho các nhà nghiên cứu và thực hành trong lĩnh vực phát triển nhanh chóng này, cung cấp một nền tảng vững chắc để phát triển các phương pháp mới và thúc đẩy các code large language models tối tân.

Giới hạn

Trong phương pháp của chúng tôi, chúng tôi đã sử dụng 13 bộ lọc dựa trên quy tắc heuristic và cụ thể cho ngữ cảnh, được tuyển chọn từ các quan sát dữ liệu thủ công. Mặc dù những bộ lọc này hiệu quả giảm thiểu các mẫu nhiễu, bản chất tất định của chúng ngăn cản khả năng khái quát hóa toàn diện. Để giải quyết điều này, chúng tôi bổ sung những quy tắc này với một phương pháp dựa trên neural như được mô tả trong Phần 3.2.2. Tuy nhiên, việc vắng mặt dữ liệu huấn luyện có nhãn đòi hỏi việc tạo mẫu giả ngẫu nhiên, có thể làm tổn hại đến tính đúng đắn của mô hình và có thể loại bỏ các cặp code-text chất lượng.

Mặc dù cross-validation với GPT 3.5-turbo thỉnh thoảng tiết lộ sự không nhất quán trong việc đánh điểm, chúng tôi tin rằng việc gán nhãn của con người và fine-tuning mô hình có thể tinh chỉnh thêm tập dữ liệu.

So với The Stack và The Pile, tập dữ liệu của chúng tôi nhỏ hơn, chủ yếu do các quy trình kiểm soát chất lượng nghiêm ngặt của chúng tôi. Hơn nữa, việc tạo AST parsers cho mỗi ngôn ngữ lập trình là một tác vụ không tầm thường, hạn chế tập dữ liệu của chúng tôi đến 10 ngôn ngữ lập trình phổ biến so với 300 của The Stack. Tuy nhiên, codebase framework của chúng tôi có sẵn công khai, khuyến khích các đóng góp tương lai để mở rộng parsers và quy tắc của chúng tôi đến các ngôn ngữ bổ sung.

Nghiên cứu hiện tại chủ yếu sử dụng các mô hình nhỏ với ít hơn 2 tỷ parameters để minh họa giá trị của The Vault. Những mô hình này hiệu quả chứng minh tiềm năng của tập dữ liệu, nhưng nghiên cứu thêm với các mô hình lớn hơn sẽ làm sáng tỏ tính mạnh mẽ và khả năng mở rộng của nó qua các tác vụ phức tạp hơn. Trong công việc tương lai, chúng tôi dự định thực hiện các thực nghiệm sử dụng các mô hình ngôn ngữ quy mô lớn để đánh giá thêm tác động của tập dữ liệu của chúng tôi.

arXiv:2309.04646v1  [cs.CL]  9 Sep 2023Tinh chỉnh hiệu quả các mô hình ngôn ngữ lớn cho
Chatbot tiếng Việt
Vu-Thuan Doan1,2, Quoc-Truong Truong1,2, Duc-Vu Nguyen1,2, Vinh-Tiep Nguyen1,2,*, và Thuy-Ngan Nguyen Luu1,2
1Trường Đại học Công nghệ Thông tin, Thành phố Hồ Chí Minh, Việt Nam
2Đại học Quốc gia Việt Nam, Thành phố Hồ Chí Minh, Việt Nam
thuandv.14@grad.uit.edu.vn, {truongtq, vund, tiepnv, ngannlt}@uit.edu.vn
*Tác giả liên hệ
Tóm tắt —Các mô hình ngôn ngữ lớn (LLMs), như GPT-4,
PaLM, và LLaMa, đã được chứng minh đạt được hiệu suất
đáng chú ý trong nhiều tác vụ ngôn ngữ tự nhiên. Những tiến
bộ gần đây trong điều chỉnh hướng dẫn mang lại cho LLMs
khả năng tuân theo hướng dẫn của người dùng và tạo ra các
phản hồi giống con người. Tuy nhiên, chi phí cao liên quan đến
việc huấn luyện và triển khai LLMs đặt ra thách thức cho nghiên
cứu học thuật. Hơn nữa, việc có sẵn các LLMs được huấn luyện
trước và các bộ dữ liệu điều chỉnh hướng dẫn cho tiếng Việt
bị hạn chế. Để giải quyết những vấn đề này, chúng tôi tận dụng
các bộ dữ liệu tuân theo hướng dẫn quy mô lớn từ các dự án
mã nguồn mở, cụ thể là Alpaca, GPT4All, và ChatDoctor, bao
gồm lĩnh vực chung và lĩnh vực y tế cụ thể. Theo hiểu biết của
chúng tôi, đây là những bộ dữ liệu hướng dẫn đầu tiên cho
tiếng Việt. Tiếp theo, chúng tôi sử dụng điều chỉnh hiệu quả
tham số thông qua Low-Rank Adaptation (LoRA) trên hai LLMs
mở: Bloomz (Đa ngôn ngữ) và GPTJ-6B (tiếng Việt), tạo ra
bốn mô hình: Bloomz-Chat, Bloomz-Doctor, GPTJ-Chat, GPTJ-
Doctor. Cuối cùng, chúng tôi đánh giá hiệu quả của phương
pháp trên cơ sở từng mẫu, xem xét tính hữu ích, liên quan,
chính xác, mức độ chi tiết trong các phản hồi của chúng. Quá
trình đánh giá này bao gồm việc sử dụng GPT-4 như một cơ
chế chấm điểm tự động. Mặc dù sử dụng thiết lập chi phí thấp,
phương pháp của chúng tôi cho thấy cải thiện khoảng 20-30%
so với các mô hình gốc trong các tác vụ đánh giá của chúng tôi.
Từ khóa chỉ mục —Mô hình Ngôn ngữ Lớn, Tinh chỉnh Hướng dẫn,
LoRA, Tiếng Việt, Chatbot, Y tế

I. GIỚI THIỆU
Trong những năm gần đây, các mô hình ngôn ngữ lớn (LLMs)
đã thu hút sự chú ý đáng kể nhờ vào thành công đáng chú ý
của chúng trong nhiều tác vụ xử lý ngôn ngữ tự nhiên (NLP).
Các mô hình ngôn ngữ lớn dựa trên kiến trúc học sâu được gọi
là Transformer. Mô hình Transformer đã cách mạng hóa các
tác vụ xử lý ngôn ngữ tự nhiên bằng cách nắm bắt hiệu quả
các phụ thuộc và mối quan hệ tầm xa trong văn bản. LLMs
được huấn luyện trên khối lượng lớn dữ liệu văn bản để dự
đoán các token tiếp theo, cho phép chúng tạo ra văn bản mạch
lạc và trôi chảy để phản hồi các đầu vào khác nhau. Tuy nhiên,
không có các ví dụ few-shot, các mô hình khó có thể hoạt động
tốt trên các lời nhắc không tương tự với định dạng của dữ liệu
huấn luyện trước. Các mô hình này cũng gặp khó khăn trong
việc tuân theo hướng dẫn hoặc mục tiêu được chỉ định bởi
người dùng, điều này hạn chế tính hữu ích và khả năng ứng
dụng của chúng trong các tình huống thế giới thực.

Cộng đồng NLP gần đây đã chứng kiến nhiều nỗ lực để huấn
luyện các mô hình ngôn ngữ lớn tuân theo hướng dẫn tốt hơn
và hữu ích hơn. Các mô hình ngôn ngữ lớn "được điều chỉnh
hướng dẫn" (được tinh chỉnh để phản hồi hướng dẫn) đã thể
hiện khả năng đáng chú ý trong việc tổng quát hóa zero-shot
cho các tác vụ mới. Những nỗ lực ban đầu [11] [15] [16] [4]
để huấn luyện các mô hình ngôn ngữ tuân theo hướng dẫn dựa
trên tập hợp các tác vụ NLP khác nhau, với một bộ hướng dẫn
được chú thích bởi con người đi kèm với mỗi tác vụ. Những
phát triển này được thúc đẩy bởi hai thành phần chính: các
mô hình ngôn ngữ được huấn luyện trước lớn và dữ liệu hướng
dẫn được viết bởi con người. Tuy nhiên, quá trình này tốn kém
và thường bị hạn chế về tính đa dạng trong các tác vụ NLP.
Sau đó, Self-Instruct [14], một khung để cải thiện khả năng
tuân theo hướng dẫn của các mô hình ngôn ngữ được huấn
luyện trước bằng cách tự bootstrap từ các thế hệ của chính nó.
Phương pháp này đã giải quyết những thách thức như vậy cần
thiết việc tạo ra một bộ dữ liệu quy mô lớn, công khai bao
gồm một loạt các tác vụ.

Mặc dù thành công lớn của LLMs, các mô hình SOTA như
GPT-4, và PaLM [3], thường chỉ có thể truy cập thông qua
các API bị hạn chế, tạo ra rào cản cho các nỗ lực nghiên cứu
mới. Trong tài liệu gần đây, đã có sự quan tâm ngày càng tăng
trong việc tận dụng các LLMs mã nguồn mở và điều chỉnh
chúng cho các ứng dụng hoặc lĩnh vực cụ thể. Các mô hình
phổ biến là Bloom [8] từ Bigscience, GPT-J từ EleutherAI,
và LLaMa [13] từ Meta. Tuy nhiên, trong bối cảnh tiếng Việt,
thiếu các mô hình ngôn ngữ đã trải qua quá trình huấn luyện
rộng rãi trên các kho dữ liệu khổng lồ, dẫn đến việc thiếu
các tính năng đặc biệt mà LLMs sở hữu: một vài thế hệ ngắn
với việc học trong bối cảnh.

Một thách thức khác khi làm việc với LLMs là chi phí tinh
chỉnh và triển khai. Để tinh chỉnh các mô hình ngôn ngữ lớn
trong thiết lập tài nguyên thấp, chúng tôi sử dụng phương
pháp điều chỉnh hiệu quả tham số nhằm tận dụng hiệu quả
các tài nguyên tính toán hạn chế có sẵn. Bằng cách áp dụng
kỹ thuật LoRA (Low-Rank Adaptation), điều này cho phép
điều chỉnh các mô hình ngôn ngữ tiên tiến cho các tình huống
bị hạn chế tài nguyên trong khi duy trì hiệu suất cao và khả
năng thích ứng.

Trong bài báo này, chúng tôi đề xuất một phương pháp đơn
giản dựa trên điều chỉnh hướng dẫn hiệu quả với bộ dữ liệu
hướng dẫn tiếng Việt của chúng tôi để xây dựng hai mô hình
chatbot cho các lĩnh vực chung và cụ thể, ví dụ y tế. Tổng
quan về phương pháp của chúng tôi được hiển thị trong Hình
1. Những đóng góp chính của chúng tôi trong bài báo này như
sau:
• Chúng tôi đề xuất các bộ dữ liệu tuân theo hướng dẫn mới
cho các lĩnh vực chung và y tế bằng cách thu thập và dịch
từ các nguồn công khai khác.
• Chúng tôi áp dụng phương pháp Low-Rank Adaptation
(LoRA) cho việc huấn luyện và triển khai hiệu quả các
LLMs. Điều này làm cho chi phí huấn luyện và triển khai
có thể chi trả được cho nghiên cứu học thuật.
• Chúng tôi đánh giá hiệu suất của những phương pháp đó
trên một tập hợp các tác vụ ngôn ngữ tự nhiên, chứng
minh khả năng trong bối cảnh tiếng Việt cho các lĩnh vực
chung và y tế.

II. CÔNG TRÌNH LIÊN QUAN
Các Mô hình Ngôn ngữ Lớn: đã thể hiện khả năng ấn tượng
trong nhiều lĩnh vực khác nhau, bao gồm hiểu ngôn ngữ tự
nhiên, tạo văn bản, hệ thống đối thoại, tóm tắt nội dung, và
nhiều hơn nữa. Những tiến bộ gần đây trong các mô hình ngôn
ngữ lớn (LLMs) đã chứng minh sự vượt trội của chúng so với
các mô hình thế hệ trước, như huấn luyện trước và tinh chỉnh.
Sự gia tăng đáng kể về quy mô mô hình đã dẫn đến những
thay đổi chất lượng trong LLMs, thường được gọi là các khả
năng nổi lên. Những khả năng này bao gồm việc học trong
bối cảnh cho các tác vụ zero-shot và chuỗi suy nghĩ giúp tăng
cường hiệu suất của mô hình trên các tác vụ phức tạp. Sự phát
triển ChatGPT và GPT-4 [9] của OpenAI đã cách mạng hóa
nhận thức về LLMs. Mặc dù các mô hình này thể hiện hiệu
suất đáng chú ý, OpenAI đã không tiết lộ chi tiết về các chiến
lược huấn luyện hoặc các tham số trọng số của chúng. Tuy
nhiên, có một số lựa chọn thay thế LLMs mã nguồn mở cho
GPT-4: Bloom [12], Bloomz [8], GPT-J, và LLaMa [13] với
kích thước từ 7B đến 65 tỷ tham số.

Điều chỉnh Hướng dẫn: Lĩnh vực con của các mô hình ngôn
ngữ tập trung vào khả năng tuân theo hướng dẫn là quan trọng
để tạo ra các phản hồi dựa trên các lệnh ngôn ngữ tự nhiên.
Các phương pháp tuân theo hướng dẫn tăng cường các mô
hình được huấn luyện trước bằng cách tinh chỉnh chúng sử
dụng các cặp đầu vào-đầu ra chất lượng cao của hướng dẫn
tác vụ và đầu ra thực tế. Việc tinh chỉnh này giúp mô hình
hiểu rõ hơn ý định của người dùng và tuân theo hướng dẫn
chính xác hơn. Các phương pháp tuân theo hướng dẫn đã được
nghiên cứu rộng rãi trong các mô hình ngôn ngữ [11] [15]
[16] [4] và các lĩnh vực đa phương thức [8]. Trong số những
phương pháp đó, FLAN [16] giới thiệu một phương pháp điều
chỉnh hướng dẫn vượt trội hơn các LLMs không được điều
chỉnh trong các tác vụ chưa thấy. PromptSource [1] cung cấp
một môi trường phát triển và kho lưu trữ mà cung cấp giao
diện người dùng đồ họa dựa trên web để tạo và quản lý các
lời nhắc ngôn ngữ tự nhiên cho việc học zero-shot hoặc few-
shot dựa trên gradient. SUP-NATINST [15] thiết lập một
chuẩn mực lớn gồm 1,616 tác vụ NLP đa dạng và sử dụng
huấn luyện đa tác vụ trên mô hình T5 và chứng minh khả
năng tổng quát hóa mạnh mẽ trên các tác vụ chưa thấy.
InstructGPT [10] chứng minh cải thiện hiệu suất đáng kể và
có thể được tích hợp vào các mô hình nguồn đóng như GPT-
3.5 và GPT-4 [9]. Phương pháp Stanford Alpaca mã nguồn
mở tinh chỉnh tất cả các tham số của LLMs theo cách đầu
cuối đến đầu cuối.

Tinh chỉnh Hiệu quả Tham số: Tinh chỉnh Hiệu quả Tham
số (PEFT) [2] nhằm tối ưu hóa quá trình tinh chỉnh bằng
cách sử dụng hiệu quả các tài nguyên tính toán có sẵn và
giảm số lượng tham số cần được cập nhật. Phương pháp này
trở nên đặc biệt phù hợp khi làm việc với dữ liệu được gán
nhãn hạn chế cho một tác vụ cụ thể. Phương pháp này không
chỉ tiết kiệm thời gian và tài nguyên tính toán mà còn cho
phép việc triển khai các mô hình ngôn ngữ lớn dễ tiếp cận
và thực tế hơn cho một loạt các ứng dụng. Các kỹ thuật PEFT
khác nhau bao gồm Prefix Tuning [7], Low-Rank adaptation
(LoRA) [5], và việc chèn các lớp adapter trong các mô hình
ngôn ngữ lớn được huấn luyện trước. Prefix Tuning [7] thêm
một tập hợp các tiền tố vào các mô hình ngôn ngữ tự hồi quy,
hoặc cách khác, kết hợp các tiền tố cho cả thành phần mã
hóa và giải mã, các phương pháp tương tự được đề xuất trong
[6]. LoRA [5] giới thiệu các ma trận phân tích hạng có thể
huấn luyện vào mỗi lớp. Adapters bao gồm việc chèn các
mô-đun nhẹ vào mỗi lớp của các mô hình được huấn luyện
trước, chỉ cập nhật các adapter và đã được mở rộng qua nhiều
lĩnh vực.

III. PHƯƠNG PHÁP
Trong phần này, chúng tôi sẽ mô tả phương pháp thu thập
dữ liệu, lựa chọn mô hình ngôn ngữ được huấn luyện trước
và cách chúng tôi áp dụng tinh chỉnh hiệu quả tham số.

A. Thu thập Dữ liệu
Vì việc tạo ra một bộ dữ liệu điều chỉnh hướng dẫn với nhiều
tác vụ từ đầu sẽ tốn nhiều tài nguyên, chúng tôi chuyển đổi
các bộ dữ liệu hiện có từ cộng đồng nghiên cứu thành định
dạng hướng dẫn và dịch chúng sang tiếng Việt
Ví dụ bộ dữ liệu hướng dẫn:
{"prompt": "đưa ra 3 mẹo giữ sức khỏe", "response": "1. Ăn
một chế độ ăn cân bằng và đảm bảo bao gồm nhiều trái ..."}
{"prompt": "Ba màu chính là gì?", "response": "Ba màu chính
là màu đỏ, xanh và vàng."}
{"prompt": "Mô tả cấu trúc của một nguyên tử.", "response":
"Một nguyên tử được tạo thành từ một hạt nhân, chứa..."}

1) Bộ dữ liệu Tuân theo Hướng dẫn: Đầu tiên, chúng tôi
thu thập các ví dụ tuân theo hướng dẫn từ dự án Stanford
Alpaca. Dự án này áp dụng kỹ thuật Self-Instruct [14] và
tạo ra 52k minh chứng từ mô hình LLaMa-7B mã nguồn mở
thay vì GPT3.5 trong bài báo Self-Instruct [14] gốc.

Để tăng thêm dữ liệu hướng dẫn, chúng tôi cũng thu thập
dữ liệu từ dự án GPT4All.

2) Bộ dữ liệu Y tế: Đối với bộ dữ liệu hướng dẫn y tế, chúng
tôi thu thập từ ChatDoctor [17]. Phương pháp của họ bắt
đầu với một cơ sở dữ liệu chứa khoảng 700 bệnh với các
triệu chứng tương đối, xét nghiệm y tế, và thuốc được khuyến
nghị. Sau đó nó sử dụng ChatGPT để tạo ra 5k cuộc hội thoại
giữa bệnh nhân và bác sĩ từ cơ sở dữ liệu hạt giống đó. Chúng
tôi cũng thu thập 195k cuộc hội thoại thực tế giữa bệnh nhân
và bác sĩ từ Health Care Magic và kết hợp chúng thành bộ
dữ liệu hướng dẫn cho lĩnh vực y tế. Cuối cùng, chúng tôi
dịch tất cả dữ liệu sang tiếng Việt bằng Google Translate API.

Ví dụ bộ dữ liệu y tế:
{"prompt": "Thưa bác sĩ, tôi bị nôn, buồn nôn và đau bụng.
Gần đây tôi phát hiện ra rằng tôi có môn vị hẹp. Tôi nên dùng
thuốc gì cho nó?",
"response": "Phương pháp điều trị hẹp môn vị phổ biến nhất
là một thủ thuật phẫu thuật được gọi là phẫu thuật cắt bỏ môn
vị. Điều này liên quan đến cắt và niêm phong cơ xung quanh
lỗ mở của môn vị, mở rộng nó và cho phép thức ăn đi qua dễ
dàng hơn. Tuy nhiên cũng có một số thuốc có thể giúp giảm
các triệu chứng như metoclopramide hoặc cisapride. Bạn thích
cái nào hơn?"}

BẢNG I
THỐNG KÊ BỘ DỮ LIỆU
Bộ dữ liệu | Mẫu | Token trung bình/mẫu | Token đã dịch
Alpaca | 52k | 350 | 18M
GPT4All | 150k | 365 | 61M
ChatDoctor | 200k | 405 | 87M

B. Các Mô hình Cơ sở
Chúng tôi sử dụng Bloomz-mt-7B [8] và GPTJ-6B từ VietAI
có sẵn công khai được huấn luyện trước làm các mô hình cơ
sở của chúng tôi. Bloomz là một biến thể nhỏ của mô hình
BLOOM gốc, một dự án hợp tác của hơn 1,000 nhà khoa học
và đội ngũ Hugging Face tuyệt vời. Mô hình BLOOM là một
mô hình ngôn ngữ đa ngôn ngữ truy cập mở chứa 176B tham
số và được huấn luyện trong 3,5 tháng trên 384 GPU A100–
80GB. Biến thể nhỏ Bloomz của nó là một mô hình đa ngôn
ngữ đã được huấn luyện trên kho ngữ liệu ROOTS và được
tinh chỉnh với bộ dữ liệu xP3. Bộ dữ liệu này có 59 Ngôn
ngữ (46 ngôn ngữ tự nhiên và 13 ngôn ngữ lập trình bao gồm
3% tiếng Việt). GPTJ-6B từ VietAI là một trong những mô
hình GPT lớn nhất được huấn luyện chỉ trên bộ dữ liệu tiếng
Việt.

C. Điều chỉnh Hiệu quả Tham số
Tinh chỉnh tiêu chuẩn thường đòi hỏi một lượng lớn tài nguyên
tính toán, cũng như các bộ dữ liệu chất lượng cao và rộng
lớn. Tuy nhiên, do tính khả dụng hạn chế của các kho ngữ
liệu trò chuyện đa lượt chất lượng cao, việc áp dụng các phương
pháp hiệu quả hơn về mặt chi phí tính toán và yêu cầu dữ
liệu là rất quan trọng. Các phương pháp điều chỉnh hiệu quả
tham số [2] giúp đạt được mục tiêu này bằng cách sử dụng
tốt hơn dữ liệu có sẵn và giảm thiểu nhu cầu phân bổ tài
nguyên rộng lớn. Chi tiết hơn trong Hình 3.

Cụ thể, chúng tôi sử dụng Low-Rank Adaption (LoRA, Hu
et al.) để tinh chỉnh các LLMs cơ sở. Đối với một lớp tuyến
tính h=W0x, việc truyền tiến được sửa đổi thành:
h=W0x+BAx (1)
trong đó W0∈Rd×k,B∈Rd×r,A∈Rr×k với hạng r≪min(d;k)

IV. THỰC NGHIỆM
A. Bộ dữ liệu Huấn luyện
Chúng tôi xây dựng ba bộ dữ liệu riêng biệt cho các mô hình
của chúng tôi. Đối với chatbot chung, chúng tôi kết hợp dữ
liệu từ Alpaca và GPT4All thành một bộ dữ liệu. Đối với
chatbot y tế, chúng tôi kết hợp 52k mẫu dữ liệu từ Alpaca
với 200k cuộc hội thoại từ ChatDoctor làm bộ dữ liệu huấn
luyện. Chúng tôi định dạng bộ dữ liệu dưới dạng tệp json
theo kiểu GPT-3 bao gồm hai trường hướng dẫn và phản hồi
cho mỗi mẫu. Mẫu lời nhắc đơn giản như sau.

Mẫu lời nhắc cho Bloomz-Chat và GPTJ-Chat:
Hãy viết một phản hồi thích hợp cho chỉ dẫn dưới đây.
### Instruction:
{instruction}
### Response:

Mẫu lời nhắc cho Bloomz-Doctor và GPTJ-Doctor:
Nếu bạn là bác sĩ, vui lòng trả lời các câu hỏi y tế dựa trên
mô tả của bệnh nhân.
### Instruction:
{instruction}
### Response:

B. Chi tiết Huấn luyện
Chúng tôi thiết lập môi trường với PyTorch và gói Huggingface
Transformers. Tinh chỉnh hiệu quả tham số được áp dụng trên
các mô hình của chúng tôi dựa trên codebase của Alpaca-Lora.
Độ dài tối đa của chuỗi đầu vào là 512 và hạng k trong LoRA
là 8. Các checkpoint mô hình cơ sở được khởi tạo với định
dạng tham số số nguyên 8-bit (int8) được phát hành bởi
Touvron et al., vẫn cố định trong quá trình huấn luyện, do
đó giảm tiêu thụ bộ nhớ GPU và cải thiện tốc độ huấn luyện.
Chúng tôi sử dụng bộ tối ưu hóa Adam để cập nhật các tham
số LoRA với tổng kích thước batch là 128 và tốc độ học 3e-4.
Các tham số LoRA có thể huấn luyện khoảng 4.2M tham số
và được tinh chỉnh trong 2 epoch trên 4 GPU RTX-4090-24GB.
Thời gian huấn luyện được liệt kê trong Bảng II.

C. Chi tiết Suy luận
Trong giai đoạn suy luận, chúng tôi cũng sử dụng lời nhắc
suy luận như chúng tôi đã làm cho giai đoạn huấn luyện để
cải thiện khả năng hội thoại. Đối với chiến lược giải mã, chúng
tôi sử dụng các cài đặt này với chi tiết như sau.
• Max new tokens: Chúng tôi giới hạn max new tokens ở
256 tokens để đảm bảo rằng các đầu ra vẫn tập trung và
liên quan đến lời nhắc đầu vào.
• Temperature: Chúng tôi đặt nhiệt độ là 0.5, điều này kiểm
soát tính ngẫu nhiên của quá trình lấy mẫu. Giá trị thấp
hơn làm cho mô hình tạo ra các đầu ra tập trung và xác
định hơn, trong khi giá trị cao hơn tăng tính đa dạng với
chi phí của sự mạch lạc.
• Top-k sampling: Chúng tôi sử dụng Top-k sampling với
k = 20, có nghĩa là mô hình chọn token tiếp theo từ 20
token có xác suất cao nhất ở mỗi bước, thêm yếu tố ngẫu
nhiên và đa dạng vào văn bản được tạo.
• Repetition penalty: Để ngăn cản mô hình tạo ra văn bản
lặp lại, chúng tôi áp dụng hình phạt lặp lại với hệ số 1.2,
phạt các token đã được chọn.

V. ĐÁNH GIÁ
Đánh giá hiệu suất của các tác vụ tạo văn bản có thể thách
thức do sự đa dạng đáng kể về hình thức của chúng, không
giống như các tác vụ hiểu ngôn ngữ tự nhiên (như phân loại
văn bản và đọc hiểu máy trích xuất). Theo các công trình
trước đây ([17], Vicuna) sử dụng GPT-4 như một phương
pháp chấm điểm, chúng tôi cũng áp dụng GPT-4 để cung cấp
điểm số tổng thể (trên thang điểm 100) cho mỗi mẫu, điều
này hiệu quả hơn đánh giá con người.

Hệ thống đánh giá xét xử mỗi phản hồi từ các mô hình của
chúng tôi theo bốn khía cạnh:
• Tính liên quan: Đánh giá khả năng của mô hình trong việc
diễn giải chính xác ý nghĩa ngữ nghĩa của bối cảnh và
câu hỏi.
• Tính hữu ích: Đánh giá khả năng của mô hình trong việc
cung cấp thông tin hữu ích.
• Độ chính xác: Đánh giá liệu mô hình có thể thực hiện
chính xác trong tương ứng cho một hướng dẫn nhất định.
• Mức độ chi tiết: Liệu mô hình có thể sử dụng chính xác
kiến thức đa dạng và chi tiết cho vấn đề.

Chúng tôi sử dụng mẫu lời nhắc sau để chấm điểm các đầu
ra của hệ thống:
System Prompt: Bạn là một trợ lý hữu ích và chính xác để
kiểm tra chất lượng của câu trả lời
Prompt:
###Question
{question}
###The Start of Assistant 1's Answer
{answer_1}
###The End of Assistant 1's Answer
###The Start of Assistant 2's Answer
{answer_2}
###The End of Assistant 2's Answer
Chúng tôi muốn yêu cầu phản hồi của bạn về hiệu suất của
hai trợ lý AI để đáp ứng câu hỏi của người dùng được hiển
thị ở trên.
Vui lòng đánh giá tính hữu ích, liên quan, chính xác, mức
độ chi tiết của phản hồi của họ. Mỗi trợ lý nhận được điểm
số tổng thể trên thang điểm từ 1 đến 10, trong đó điểm số
cao hơn cho thấy hiệu suất tổng thể tốt hơn...

Bộ đánh giá của chúng tôi được thiết kế để cung cấp đánh
giá toàn diện về các mô hình của chúng tôi trên một loạt
các tác vụ hiểu và tạo ngôn ngữ tự nhiên. Bộ này bao gồm
80 mẫu, bao phủ 9 danh mục khác biệt, bao gồm Trả lời Câu
hỏi, Lý luận, Văn học, Giải trí, Toán học, và Lập trình. Điểm
số tổng thể cho một tác vụ cụ thể được tính bằng cách cộng
điểm số cho tất cả các mẫu trong tác vụ đó và chuẩn hóa
tổng số thành thang điểm 100. Phương pháp này đảm bảo
rằng bộ đánh giá phản ánh khả năng của các mô hình trên
các tác vụ khác nhau, cung cấp một thước đo cân bằng và
mạnh mẽ về hiệu suất của chúng.

Hiệu suất của mô hình Bloomz-Chat tốt hơn GPTJ-Chat và
thể hiện hiệu suất chấp nhận được so với ChatGPT. Đối với
các tác vụ Generic, Knowledge, Common Sense, Bloomz-Chat
làm tốt và có hiệu suất tương tự ChatGPT. Trong các lĩnh
vực Roleplay, Fermi, Writing, hiệu suất vẫn chấp nhận được
với điểm số trong khoảng từ 65 đến 76. Tuy nhiên, trong
một số tác vụ phức tạp như Coding và Math, hiệu suất rất
kém với điểm số Coding là 31.5 và Math là 8.5. Hiệu suất
của GPTJ-Chat và GPTJ gốc khá kém cho tất cả các tác vụ.

Đối với lĩnh vực y tế, chúng tôi chọn ngẫu nhiên 100 ví dụ
từ bộ dữ liệu iCliniq và sử dụng cùng phương pháp đánh giá.

BẢNG II
CHI TIẾT HUẤN LUYỆN
Mô hình | Tham số Gốc | Tham số Có thể Huấn luyện | Thời gian Huấn luyện | Bộ dữ liệu
Bloomz-Chat | 7.1B | 4.2M | 6h | Alpaca + GPT4All
Bloomz-Doctor | 7.1B | 4.2M | 6h30m | Alpaca + ChatDoctor
GPTJ-Chat | 6B | 3.6M | 5h | Alpaca + GPT4All
GPTJ-Doctor | 6B | 3.6M | 5h30m | Alpaca + ChatDoctor

BẢNG III
ĐÁNH GIÁ BLOOMZ-CHAT
Tác vụ | Mẫu | Bloomz | Bloomz-Chat
Generic | 10 | 49.82 | 91.25
Knowledge | 10 | 44.11 | 87.5
Roleplay | 10 | 44.29 | 65.54
Common-Sense | 10 | 50 | 85.07
Fermi | 10 | 38.75 | 75.71
Counterfactual | 10 | 47.14 | 82.5
Coding | 7 | 5 | 31.5
Math | 3 | 5 | 8.5
Writing | 10 | 70 | 76.25
Tổng | 80 | 44.26 | 73.55

BẢNG IV
ĐÁNH GIÁ GPTJ-CHAT
Tác vụ | Mẫu | GPTJ | GPTJ-Chat
Generic | 10 | 31.89 | 61.11
Knowledge | 10 | 33.22 | 62.22
Roleplay | 10 | 23 | 33.11
Common-Sense | 10 | 25.11 | 54.22
Fermi | 10 | 15.22 | 24.11
Counterfactual | 10 | 15.72 | 41.11
Coding | 7 | 5 | 5
Math | 3 | 5 | 5
Writing | 10 | 17.33 | 38
Tổng | 80 | 20.8 | 39.9

Bloomz-Doctor thể hiện hiệu suất đáng chú ý với điểm số
73.92. GPTJ-Doctor chấp nhận được với điểm số 59.85.

Tóm lại, kết quả thực nghiệm chứng minh rằng cả hai mô
hình Bloomz-Chat và Bloomz-Doctor đều thể hiện khả năng
tiềm năng trên tất cả các tác vụ. Điều này nhấn mạnh hiệu
quả của phương pháp chúng tôi trong việc tăng cường khả
năng hiểu và tạo tiếng Việt của mô hình Bloomz. Một số ví
dụ về các mô hình của chúng tôi được hiển thị trong Bảng V

VI. KẾT LUẬN
Trong bài báo này, chúng tôi đề xuất một phương pháp thích
ứng hiệu quả để huấn luyện các mô hình ngôn ngữ tuân theo
hướng dẫn. Chúng tôi cũng cung cấp các bộ dữ liệu hướng
dẫn cho các lĩnh vực chung và y tế. Chỉ với 4.2M tham số
và sáu giờ huấn luyện, phương pháp của chúng tôi tinh chỉnh
hiệu quả Bloomz và thể hiện khả năng tiềm năng trong các
ứng dụng chatbot và y tế. Phương pháp của chúng tôi có thể
dễ dàng được áp dụng cho các tác vụ và lĩnh vực khác.

Tuy nhiên, các mô hình của chúng tôi vẫn có những hạn chế.
Phản hồi từ các mô hình đôi khi không liên quan đến hướng
dẫn. Đôi khi nó phản hồi với câu trả lời sai. Điều này có thể
là giới hạn của kho ngữ liệu văn bản huấn luyện trong mô
hình cơ sở của chúng tôi - Bloomz - chỉ có 3% tiếng Việt.
Chúng tôi tin rằng nếu chúng tôi có thể mở rộng LLM được
huấn luyện trước với nhiều dữ liệu tiếng Việt hơn, hiệu suất
mô hình sẽ tăng. Và đó sẽ là công việc tiếp theo của chúng
tôi trong tương lai gần.

BẢNG V
MỘT SỐ VÍ DỤ VỀ BLOOMZ-CHAT VÀ BLOOMZ-DOCTOR
Lời nhắc | Phản hồi
Dịch sang tiếng Việt: J'aime la recherche scientifique. | Tôi yêu nghiên cứu khoa học
Ăn gì cho đẹp da | Một chế độ ăn uống lành mạnh có thể giúp bạn trông và cảm thấy tốt hơn. Nó bao gồm trái cây, rau quả, protein nạc (như gà hoặc cá), ngũ cốc nguyên hạt và các loại thực phẩm chứa chất chống oxy hóa khác nhau như cà rốt và việt quất. Điều quan trọng là phải tránh đồ ngọt và quá nhiều chất béo bão hòa cũng được tìm thấy trong thịt đỏ và chiên
Ý nghĩa của cuộc sống là gì? | Là một mô hình ngôn ngữ AI, tôi không có ý kiến cá nhân hoặc niềm tin cá nhân. Tuy nhiên, theo các học thuyết tâm lý và thần kinh khoa học hiện đại, mục đích cơ bản của sự tồn tại được liên kết với việc tìm kiếm hạnh phúc và thỏa mãn trong những trải nghiệm này
Thưa bác sĩ, tôi bị sưng môi và hàm, đau nướu, sốt và loét miệng. Bạn có biết điều gì có thể gây ra tất cả các triệu chứng này không? | Xin chào! Các nguyên nhân phổ biến nhất cho các khiếu nại mà bạn đề cập ở đây bao gồm nhiễm trùng răng hoặc nha chu (viêm nướu), viêm xoang mũi do virus hoặc vi khuẩn. Nguyên nhân khác như dị ứng với thực phẩm, thuốc lá cũng nên được loại trừ trước khi chẩn đoán chắc chắn về tình trạng hiện tại. Nếu đó là một cơn sốt virus thì sẽ mất khoảng 2 tuần để nó giảm dần hoàn toàn....
Thưa bác sĩ, tôi thấy mệt mỏi, khó thở, đau ngực và nhịp tim không đều. Tôi đã thực hiện một số nghiên cứu và có vẻ như tôi có thể bị viêm cơ tim. Tôi nên làm những xét nghiệm nào để xác nhận nó? | Xin chào! Tôi muốn biết lịch sử lâm sàng chi tiết hơn về tình trạng này (bao gồm cả việc điều trị trước đó).Tôi nghĩ rằng bạn đang nói về sự lo lắng hoặc căng thẳng trong quá trình tập luyện.Bạn cần phải kiểm tra mức độ cholesterol cao và huyết áp cũng như ECG.Điều quan trọng nhất là loại bỏ nguyên nhân gây ra vấn đề của bạn - do thiếu máu cục bộ hay tăng huyết áp? Hy vọng thông tin này hữu ích cho bạn.Cảm ơn vì đã liên hệ với chúng tôi.Chúc mọi sức khỏe tốt đẹp!Trân trọng,

LỜI CẢM ƠN
Nghiên cứu này được tài trợ bởi Trường Đại học Công nghệ
Thông tin-Đại học Quốc gia Việt Nam Thành phố Hồ Chí
Minh theo số hiệu grant D1-2023-38.

TÀI LIỆU THAM KHẢO
[1] Stephen H Bach, Victor Sanh, Zheng-Xin Yong, Albert Webson, Colin
Raffel, Nihal V Nayak, Abheesht Sharma, Taewoon Kim, M Saiful
Bari, Thibault Fevry, et al. Promptsource: An integrated development
environment and repository for natural language prompts. arXiv preprint
arXiv:2202.01279, 2022. 2

[2] Jiaao Chen, Aston Zhang, Xingjian Shi, Mu Li, Alex Smola, và Diyi
Yang. Parameter-efficient fine-tuning design spaces. arXiv preprint
arXiv:2301.01821, 2023. 2,3

[3] Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma,
Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung,
Charles Sutton, Sebastian Gehrmann, et al. Palm: Scaling language
modeling with pathways. arXiv preprint arXiv:2204.02311, 2022. 1

[4] Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay,
William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha
Brahma, et al. Scaling instruction-finetuned language models. arXiv
preprint arXiv:2210.11416, 2022. 1,2

[5] Edward J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi
Li, Shean Wang, Lu Wang, và Weizhu Chen. Lora: Low-rank adaptation
of large language models. arXiv preprint arXiv:2106.09685, 2021. 3

[6] Brian Lester, Rami Al-Rfou, và Noah Constant. The power of scale
for parameter-efficient prompt tuning. arXiv preprint arXiv:2104.08691,
2021. 3

[7] Xiang Lisa Li và Percy Liang. Prefix-tuning: Optimizing continuous
prompts for generation. arXiv preprint arXiv:2101.00190, 2021. 3

[8] Niklas Muennighoff, Thomas Wang, Lintang Sutawika, Adam Roberts,
Stella Biderman, Teven Le Scao, M Saiful Bari, Sheng Shen, Zheng-
Xin Yong, Hailey Schoelkopf, et al. Crosslingual generalization through
multitask finetuning. arXiv preprint arXiv:2211.01786, 2022. 1,2,3

[9] OpenAI. Gpt-4 technical report, 2023. 2

[10] Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wain-
wright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina
Slama, Alex Ray, et al. Training language models to follow instructions
with human feedback. Advances in Neural Information Processing
Systems, 35:27730–27744, 2022. 2

[11] Victor Sanh, Albert Webson, Colin Raffel, Stephen H Bach, Lintang
Sutawika, Zaid Alyafeai, Antoine Chaffin, Arnaud Stiegler, Teven Le
Scao, Arun Raja, et al. Multitask prompted training enables zero-shot
task generalization. arXiv preprint arXiv:2110.08207, 2021. 1,2

[12] Teven Le Scao, Angela Fan, Christopher Akiki, Ellie Pavlick, Suzana
Ilić, Daniel Hesslow, Roman Castagné, Alexandra Sasha Luccioni,
François Yvon, Matthias Gallé, et al. Bloom: A 176b-parameter open-
access multilingual language model. arXiv preprint arXiv:2211.05100,
2022. 2

[13] Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-
Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric
Hambro, Faisal Azhar, et al. Llama: Open and efficient foundation
language models. arXiv preprint arXiv:2302.13971, 2023. 1,2

[14] Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A
Smith, Daniel Khashabi, và Hannaneh Hajishirzi. Self-instruct: Align-
ing language model with self generated instructions. arXiv preprint
arXiv:2212.10560, 2022. 1,3

[15] Yizhong Wang, Swaroop Mishra, Pegah Alipoormolabashi, Yeganeh
Kordi, Amirreza Mirzaei, Atharva Naik, Arjun Ashok, Arut Sel-
van Dhanasekaran, Anjana Arunkumar, David Stap, et al. Super-
naturalinstructions: Generalization via declarative instructions on 1600+
nlp tasks. In Proceedings of the 2022 Conference on Empirical Methods
in Natural Language Processing, pages 5085–5109, 2022. 1,2

[16] Jason Wei, Maarten Bosma, Vincent Y Zhao, Kelvin Guu, Adams Wei
Yu, Brian Lester, Nan Du, Andrew M Dai, và Quoc V Le.
Finetuned language models are zero-shot learners. arXiv preprint
arXiv:2109.01652, 2021. 1,2

[17] Li Yunxiang, Li Zihan, Zhang Kai, Dan Ruilong, và Zhang You.
Chatdoctor: A medical chat model fine-tuned on llama model using
medical domain knowledge. arXiv preprint arXiv:2303.14070, 2023. 3,
4

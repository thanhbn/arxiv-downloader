# 2312.12683.pdf
# Được chuyển đổi từ PDF thành TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/multilingual/2312.12683.pdf
# Kích thước tệp: 3740949 byte

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Biến các mô hình LLM tập trung vào tiếng Anh thành đa ngữ:
Cần bao nhiều tính đa ngữ?
Tannon Kew1˚Florian Schottmann2,3Rico Sennrich1,4
1Đại học Zurich,2Textshuttle,3ETH Zurich,4Đại học Edinburgh
{kew,sennrich}@cl.uzh.ch, schottmann@textshuttle.com
Tóm tắt
Phần lớn các mô hình ngôn ngữ lớn (LLM) hiện nay đều tập trung vào tiếng Anh, được tiền huấn luyện chủ yếu trên văn bản tiếng Anh. Tuy nhiên, để đáp ứng kỳ vọng của người dùng, các mô hình cần có khả năng phản hồi thích hợp bằng nhiều ngôn ngữ sau khi được triển khai trong các ứng dụng hạ nguồn. Điều này đòi hỏi khả năng chuyển giao đa ngôn ngữ mạnh mẽ. Trong nghiên cứu này, chúng tôi điều tra lượng tối thiểu tính đa ngữ cần thiết trong quá trình tinh chỉnh để kích thích khái quát hóa đa ngôn ngữ trong các LLM tập trung vào tiếng Anh. Trong các thí nghiệm trên bốn LLM, chúng tôi phát hiện rằng việc điều chỉnh hướng dẫn đa ngữ với chỉ hai đến ba ngôn ngữ là cả cần thiết và đủ để kích thích khái quát hóa đa ngôn ngữ hiệu quả, với yếu tố giới hạn là mức độ mà một ngôn ngữ đích được nhìn thấy trong quá trình tiền huấn luyện. Các đánh giá trên năm nhiệm vụ khác nhau tiết lộ thêm rằng việc điều chỉnh hướng dẫn đa ngữ có lợi nhất cho các nhiệm vụ sinh tạo giả định sự thỏa thuận ngôn ngữ đầu vào/đầu ra, chẳng hạn như trong các cài đặt trò chuyện, trong khi ít quan trọng hơn đối với các nhiệm vụ phân loại có cấu trúc cao.1
1 Giới thiệu
Điều chỉnh hướng dẫn đối thoại là một phương pháp phổ biến để căn chỉnh các mô hình ngôn ngữ được tiền huấn luyện lớn (LLM) với kỳ vọng của người dùng sao cho chúng có thể phản hồi hiệu quả đối với truy vấn đầu vào của người dùng và tuân theo các hướng dẫn ngôn ngữ tự nhiên (Ouyang et al., 2022; Wang et al., 2023; Chiang et al., 2023; Zhou et al., 2023). Một kỳ vọng ngầm định của các chatbot đối thoại là ngôn ngữ của phản hồi của mô hình phải khớp với ngôn ngữ của truy vấn đầu vào của người dùng. Chẳng hạn, trừ khi được chỉ định khác, một đầu vào bằng tiếng Đức sẽ dẫn đến một đầu ra bằng tiếng Đức. Tuy nhiên, vì phần lớn dữ liệu huấn luyện là bằng tiếng Anh, nhiều LLM được điều chỉnh hướng dẫn gặp khó khăn trong việc phản hồi nhất quán bằng các ngôn ngữ khác (Ouyang et al., 2022; Touvron et al., 2023; Chen et al., 2024; Ye et al., 2023; Zhang et al., 2024b).

Mặc dù có sự tiếp xúc hạn chế, tuy nhiên, các LLM tập trung vào tiếng Anh như Llama 2 dường như đạt được sự thỏa thuận ngôn ngữ đầu vào/đầu ra (IO) gần như hoàn hảo khi được điều chỉnh với tương đối ít hướng dẫn đối thoại đa ngữ. Hình 1 mô tả sự thỏa thuận ngôn ngữ IO, được đo bằng OpenLID (Burchell et al., 2023), và so sánh việc điều chỉnh đa ngữ trên bộ dữ liệu Guanaco đa dạng ngôn ngữ (Dettmers et al., 2023; Köpf et al., 2023) với việc điều chỉnh đơn ngữ trên một tập con hướng dẫn chỉ tiếng Anh. Như có thể thấy, việc điều chỉnh đa ngữ kích thích sự thỏa thuận ngôn ngữ IO mạnh mẽ – trong phạm vi tỷ lệ lỗi của OpenLID – cho các ngôn ngữ không phải tiếng Anh được nhìn thấy ở các mức độ khác nhau trong quá trình tiền huấn luyện và tinh chỉnh mà không làm giảm hiệu suất trên tiếng Anh.

Quan sát này đặt ra hai câu hỏi chính, mà chúng tôi nhằm mục đích giải quyết trong bài báo này:arXiv:2312.12683v2  [cs.CL]  3 Oct 2024

--- TRANG 2 ---
Q1: Cần bao nhiều tính đa ngữ trong quá trình tinh chỉnh để kích thích khái quát hóa đa ngôn ngữ không có mẫu trong các LLM tập trung vào tiếng Anh?
Q2: Những ngôn ngữ và nhiệm vụ nào được hưởng lợi nhiều nhất từ việc điều chỉnh hướng dẫn đa ngữ của các LLM tập trung vào tiếng Anh?

Để điều tra những câu hỏi này, chúng tôi điều chỉnh hướng dẫn bốn LLM tập trung vào tiếng Anh khác biệt với các mức độ tính đa ngữ khác nhau và đánh giá hiệu suất trên một tập hợp đa dạng lên đến 19 ngôn ngữ qua năm nhiệm vụ khác nhau. Cụ thể, chúng tôi xem xét các ngôn ngữ đích có nguồn lực cao, trung bình và thấp liên quan đến phân phối dữ liệu tiền huấn luyện của mô hình và các nhiệm vụ sinh tạo, chẳng hạn như đối thoại một lượt, đơn giản hóa câu và trả lời câu hỏi trích xuất, cũng như các nhiệm vụ có cấu trúc hơn nhằm đánh giá lý luận thông thường và hiểu biết ngôn ngữ.

Kết quả của chúng tôi chỉ ra rằng việc điều chỉnh hướng dẫn đa ngữ là quan trọng để kích thích chuyển giao đa ngôn ngữ trên các nhiệm vụ sinh tạo giả định sự thỏa thuận ngôn ngữ IO trong khi ít quan trọng hơn trong các nhiệm vụ có cấu trúc thường được sử dụng để đánh giá hiệu suất LLM. Hơn nữa, chúng tôi cho thấy thực nghiệm rằng chỉ cần một số lượng nhỏ ngôn ngữ tinh chỉnh để thúc đẩy chuyển giao đa ngôn ngữ. Điều này làm nổi bật rằng dữ liệu điều chỉnh cho tất cả các ngôn ngữ đích tiềm năng là không cần thiết để tạo ra các mô hình trò chuyện đa ngữ có khả năng từ các LLM tập trung vào tiếng Anh.

2 Nghiên cứu liên quan
2.1 Điều chỉnh hướng dẫn LLM
Không giống như tinh chỉnh cụ thể cho nhiệm vụ, điều chỉnh hướng dẫn nhằm thúc đẩy khái quát hóa đa nhiệm vụ, cho phép một mô hình 'tổng quát' có khả năng hoàn thành bất kỳ nhiệm vụ dựa trên văn bản nào dựa trên các hướng dẫn ngôn ngữ tự nhiên được cung cấp tại thời điểm suy luận (Mishra et al., 2022; Wei et al., 2022; Wang et al., 2022; Sanh et al., 2022; Longpre et al., 2023).

Trong khi đó, việc đóng khung các hướng dẫn theo cách đối thoại và qua nhiều lượt đối thoại đã được chứng minh là hiệu quả trong việc tạo ra các mô hình trò chuyện hiệu suất cao (Taori et al., 2023; Conover et al., 2023; Chiang et al., 2023; Dettmers et al., 2023; Ding et al., 2023). Hơn nữa, việc điều chỉnh hướng dẫn LLM vẫn hiệu quả với dữ liệu được gán nhãn tương đối hạn chế (Ouyang et al., 2022; Touvron et al., 2023; Zhou et al., 2023), các chiến lược huấn luyện hiệu quả về tham số (Hu et al., 2021; Zhang et al., 2024a) và lượng tử hóa mô hình (Dettmers et al., 2023; Li et al., 2023b).

2.2 Chuyển giao đa ngôn ngữ trong các LLM tập trung vào tiếng Anh
Phần lớn các LLM công khai có sẵn ngày nay đều tập trung vào tiếng Anh. Chẳng hạn, dữ liệu huấn luyện của GPT-3 bao gồm khoảng 93% tài liệu tiếng Anh với 7% còn lại liên quan đến các ngôn ngữ khác (Brown et al., 2020).2 Xu hướng này tiếp tục được phản ánh trong các LLM mã nguồn mở phổ biến (xem Bảng 1). Một lý do tiềm năng cho điều này có thể là "lời nguyền của tính đa ngữ" (Conneau et al., 2020) phát sinh từ việc phải chia sẻ một năng lực mô hình hữu hạn qua nhiều ngôn ngữ hơn (Lin et al., 2022; Le Scao et al., 2022). Do đó, khả năng chuyển giao đa ngôn ngữ của các mô hình tập trung vào tiếng Anh hiệu suất cao là rất có giá trị.

Mặc dù vậy, các mô hình độc quyền như GPT-3 và các dẫn xuất của nó đã cho thấy hiệu suất ấn tượng trong các cài đặt đa ngữ qua một loạt các tiêu chuẩn NLU và NLG (Lai et al., 2023a; Holmström et al., 2023; Armengol-Estapé et al., 2022; Hendy et al., 2023; Lu et al., 2023; Jiao et al., 2023; Bang et al., 2023; Laskar et al., 2023).

Trong khi đó, có một cơ sở nghiên cứu ngày càng phát triển dành riêng để nghiên cứu các khả năng tương tự của các LLM mã nguồn mở (Bawden and Yvon, 2023) và những lợi ích của việc điều chỉnh đa ngữ (Ye et al., 2023; Muennighoff et al., 2023). Chẳng hạn, việc điều chỉnh hướng dẫn đa ngữ quy mô lớn đã được chứng minh là cải thiện hiệu suất trên các nhiệm vụ trò chuyện mở trong nhiều ngôn ngữ đích cho cả LLM tập trung vào tiếng Anh và đa ngữ (Chen et al., 2024; Li et al., 2023a; Weber et al., 2024). Trong nghiên cứu đồng thời với nghiên cứu của chúng tôi, Shaham et al. (2024) báo cáo rằng điều này đúng với việc điều chỉnh hướng dẫn đa ngữ tối thiểu với mô hình PaLM 2 đa ngữ (Anil et al., 2023).

Nghiên cứu của chúng tôi có liên quan chặt chẽ với nghiên cứu của Chen et al. (2024) và Shaham et al. (2024) trong chừng mực chúng tôi khám phá cách việc điều chỉnh hướng dẫn đa ngữ có thể cải thiện chuyển giao đa ngôn ngữ trong các LLM. Tuy nhiên, trái ngược với những nghiên cứu này, chúng tôi tập trung vào lượng tối thiểu tính đa ngữ cần thiết để kích thích chuyển giao đa ngôn ngữ trong các LLM tập trung vào tiếng Anh mã nguồn mở, và chúng tôi đánh giá trên một loạt các nhiệm vụ và ngôn ngữ đích bao phủ toàn bộ phân phối dữ liệu tiền huấn luyện của mô hình.

3 Thiết lập thí nghiệm
Để khám phá khả năng đa ngữ của các LLM tập trung vào tiếng Anh, chúng tôi điều chỉnh hướng dẫn một loạt mô hình trên một tập hợp có kích thước cố định các ví dụ, thay đổi số lượng ngôn ngữ có sẵn. Sau đó, chúng tôi đánh giá các mô hình kết quả trong nhiều ngôn ngữ đích trên năm nhiệm vụ riêng biệt đại diện cho cách các LLM có thể được sử dụng trong các ứng dụng hạ nguồn.

3.1 LLM tập trung vào tiếng Anh
Một xu hướng phổ biến trong việc phát triển các LLM gần đây là sự tập trung rõ ràng vào việc mở rộng quy mô của kho ngữ liệu tiền huấn luyện (Hoffmann et al., 2022; Sardana and Frankle, 2023). Chẳng hạn, các LLM mã nguồn mở như Falcon (Almazrouei et al., 2023) và Llama 2 (Touvron et al., 2023) được tiền huấn luyện trên 1,5 và 2 nghìn tỷ token, tương ứng. Tuy nhiên, trong khi điều này vượt xa 300 tỷ token được sử dụng để huấn luyện GPT-3 (Brown et al., 2020), phân phối bao phủ ngôn ngữ vẫn tương tự với hơn 90% liên quan đến tiếng Anh (xem Bảng 1). Đối với các thí nghiệm chính của chúng tôi, chúng tôi tập trung vào Llama 2 7b. Sau đó chúng tôi xem xét Llama 2 70b (§5.2) để nghiên cứu ảnh hưởng của việc mở rộng quy mô mô hình đến tính đa ngữ. Ngoài ra, chúng tôi cũng kiểm tra xem các phát hiện của chúng tôi có khái quát hóa cho các LLM khác bằng cách sử dụng Falcon 7b và Llama 3 8b (MetaAI, 2024), những mô hình sử dụng các phương pháp tiền huấn luyện khác nhau (xem Phụ lục F và G).

3.2 Dữ liệu điều chỉnh hướng dẫn
Để điều chỉnh hướng dẫn, chúng tôi lấy cảm hứng từ Dettmers et al. (2023) và tinh chỉnh trên các cuộc hội thoại chất lượng cao từ bộ dữ liệu OpenAssistant (Köpf et al., 2023). Những cuộc hội thoại này bao gồm nhiều lượt đối thoại giữa những người làm việc tự do được yêu cầu tương tác với hoặc đảm nhận vai trò của một trợ lý AI hữu ích. Trái ngược với Dettmers et al. (2023), những người sử dụng tất cả 9.846 cuộc hội thoại được đánh giá cao nhất để huấn luyện mô hình 'Guanaco' của họ, chúng tôi lấy mẫu phụ các trường hợp huấn luyện từ bộ dữ liệu Guanaco để kiểm soát lượng tính đa ngữ. Cụ thể, chúng tôi lấy mẫu 3.200 trường hợp tiếng Anh duy nhất làm bộ dữ liệu đơn ngữ ban đầu, mà chúng tôi gọi là 'Mono'. Để xây dựng các bộ dữ liệu cho việc tinh chỉnh đa ngữ, chúng tôi lấy mẫu 200 ví dụ huấn luyện duy nhất từ mỗi ngôn ngữ không phải tiếng Anh có tần suất cao nhất trong Guanaco (Tây Ban Nha, Nga, Đức, Trung Quốc và Pháp). Với những tập con này, chúng tôi dần dần thay thế các ví dụ tiếng Anh trong Mono bằng những ví dụ không phải tiếng Anh, từng ngôn ngữ một, theo thứ tự tần suất xuất hiện của mỗi ngôn ngữ trong Guanaco. Các bộ dữ liệu đa ngữ kết quả được ký hiệu là Multi-i, trong đó i chỉ ra số lượng ngôn ngữ riêng biệt được bao gồm. Bảng 3 cung cấp một tóm tắt chi tiết về thành phần của những bộ dữ liệu này. Để so sánh, chúng tôi cũng huấn luyện các mô hình trên toàn bộ bộ dữ liệu Guanaco, bao gồm hơn 30 ngôn ngữ riêng biệt.

3.3 Cài đặt điều chỉnh hướng dẫn và suy luận
Để điều chỉnh hướng dẫn, chúng tôi huấn luyện các adapter LoRA (R"64,α"16) (Hu et al., 2021) sử dụng thư viện TRL của Hugging Face3. Tất cả các mô hình được huấn luyện trong 2k bước cập nhật trên các chuỗi 1024 token sử dụng kích thước batch hiệu quả là 64 và tốc độ học là 1e´5.4

Để suy luận hiệu quả, chúng tôi sử dụng vLLM (Kwon et al., 2023). Chúng tôi sử dụng nucleus sampling (Holtzman et al., 2019) (p"0.9) với nhiệt độ 0.8 cho các nhiệm vụ sinh tạo mở và nhiệt độ 0.001 cho các nhiệm vụ QA bị ràng buộc hơn để khuyến khích hành vi xác định hơn. Đối với tất cả các nhiệm vụ, chúng tôi báo cáo hiệu suất trung bình qua ba lần chạy suy luận sử dụng các seed ngẫu nhiên khác nhau.

3.4 Nhiệm vụ và ngôn ngữ đánh giá
Như các nhiệm vụ đánh giá, chúng tôi xem xét đối thoại một lượt, đơn giản hóa câu, trả lời câu hỏi trích xuất, lý luận thông thường và suy luận ngôn ngữ tự nhiên. Vì tất cả những nhiệm vụ này khác nhau về khả năng có sẵn và đại diện của các nhãn chân lý cơ sở, chúng tôi mô tả các chiến lược đánh giá cụ thể trong phần tiếp theo.

Chúng tôi chọn các ngôn ngữ đích dựa trên thành phần dữ liệu tiền huấn luyện của Llama 2 (xem Bảng 1). Khi làm như vậy, chúng tôi nhằm nghiên cứu ảnh hưởng của việc điều chỉnh hướng dẫn đa ngữ trong cả cài đặt chuyển giao đa ngôn ngữ có giám sát và không có mẫu (Wu and Dredze, 2019), và báo cáo kết quả trên các ngôn ngữ có nguồn lực cao, trung bình và thấp liên quan đến LLM được tiền huấn luyện, bao phủ các họ ngôn ngữ và hệ thống chữ viết riêng biệt. Tiếng Đức (de), Pháp (fr), Thụy Điển (sv), Trung Quốc (zh),5 Tây Ban Nha (es), Nga (ru), và Ý (it) đại diện cho các ngôn ngữ có nguồn lực cao với ước tính từ 3,4 đến 2,2 tỷ token. Tiếng Bồ Đào Nha (pt), Việt Nam (vi), Hàn Quốc (ko), Phần Lan (fi), Hungary (hu), Na Uy (no),6 Bulgaria (bg), và Slovenia (sl) đại diện cho các ngôn ngữ có nguồn lực trung bình, với ước tính từ 1,8 đến 0,2 tỷ token. Và cuối cùng,

3https://github.com/huggingface/trl
4Chi tiết về phần cứng được cung cấp trong Phụ lục C.
5Lưu ý, Touvron et al. (2023) không phân biệt giữa Trung Quốc Giản thể và Phồn thể trong báo cáo của họ. Đối với mục đích của chúng tôi, chúng tôi sử dụng rõ ràng Trung Quốc Giản thể.
6Một lần nữa, thiếu đặc tả giữa Norwegian Bokmål và Nynorsk trong Touvron et al. (2023), chúng tôi xem xét rõ ràng Norwegian Bokmål.

--- TRANG 4 ---
Hình 2: Độ hữu ích trung bình của các phản hồi đối thoại một lượt từ Llama 2 7b với việc điều chỉnh hướng dẫn đa ngữ gia tăng. Các thanh có sọc chỉ ra cài đặt 0-shot và thanh lỗi hiển thị khoảng tin cậy 95%.

chúng tôi chọn tiếng Hy Lạp (el), Hindi (hi), và Iceland (is) làm các ngôn ngữ có nguồn lực thấp, tần suất của chúng trong dữ liệu tiền huấn luyện của Llama 2 không được biết nhưng có khả năng xuất hiện với số lượng nhỏ do nhiễm (Blevins and Zettlemoyer, 2022). Thật không may, các bộ dữ liệu đánh giá benchmark hiện có không bao phủ tất cả những ngôn ngữ này và do đó chúng tôi giới hạn các ngôn ngữ đích trong những nhiệm vụ đó thành tập con có sẵn của các ngôn ngữ đích của chúng tôi.

4 Thí nghiệm
4.1 Đối thoại một lượt
Các chatbot đa mục đích là một ứng dụng phổ biến của các LLM được điều chỉnh hướng dẫn. Để đánh giá hiệu suất trong loại cài đặt này, chúng tôi sử dụng bộ dữ liệu prompt AlpacaEval (Dubois et al., 2023), bao gồm một tập hợp đa dạng các prompt cho các câu hỏi mở, viết sáng tạo, động não và các nhiệm vụ khác. Chúng tôi lấy mẫu ngẫu nhiên 300 prompt và dịch chúng sang từng ngôn ngữ đích. Là một engine dịch thuật, chúng tôi làm theo Lai et al. (2023b) và sử dụng GPT-3.5-Turbo.7 Trái ngược với việc sử dụng các hệ thống dịch thuật chuyên dụng, việc sử dụng GPT-3.5-Turbo cho mục đích này có lợi thế là có thể chỉ định rõ ràng các hướng dẫn cho phép bảo tồn các khối mã, bảng và thuật ngữ, mà chúng tôi bao gồm như một phần của prompt dịch của chúng tôi (xem Hình B.1). Hơn nữa, vì GPT-3.5-Turbo được huấn luyện trên dữ liệu kiểu hướng dẫn và đối thoại, chúng tôi kỳ vọng nó sẽ hoạt động tốt trong việc dịch trong lĩnh vực này.

Để tự động đánh giá các phản hồi mở, chúng tôi tận dụng LLM-as-a-judge (Zheng et al., 2023). Theo (Zhou et al., 2023), với một prompt đầu vào và phản hồi của mô hình, chúng tôi yêu cầu GPT-3.5-Turbo8 chấm điểm độ hữu ích của phản hồi trên thang Likert 6 điểm (xem Hình 20 cho prompt được sử dụng). Đối với mỗi trường hợp đánh giá, chúng tôi cung cấp prompt và phản hồi do mô hình tạo ra trực tiếp trong ngôn ngữ đích, điều mà chúng tôi thấy tương đương với việc đánh giá thông qua việc dịch phản hồi sang tiếng Anh trước (cf. Hada et al., 2024, xem Phụ lục E để biết thêm chi tiết). Như được lưu ý bởi Chen et al. (2024), GPT-3.5-Turbo đôi khi bỏ qua thực tế rằng ngôn ngữ đầu ra khác với ngôn ngữ đầu vào. Do đó, chúng tôi ép buộc điểm số 1 (chỉ ra ít hữu ích nhất) nếu ngôn ngữ của phản hồi không khớp với ngôn ngữ đích dự định theo OpenLID (Burchell et al., 2023).

Kết quả Hình 2 hiển thị điểm số độ hữu ích được gán bởi thẩm phán LLM trên 16 ngôn ngữ đích. Đối với tiếng Anh, hiệu suất vẫn đồng đều qua tất cả các cài đặt điều chỉnh hướng dẫn đa ngữ. Đối với các ngôn ngữ đích không phải tiếng Anh có nguồn lực cao và trung bình, hiệu suất tăng đáng kể khi chuyển từ điều chỉnh hướng dẫn đơn ngữ sang song ngữ (Multi-2). Trong khi đó, hiệu suất ổn định khi huấn luyện với chỉ ba ngôn ngữ (Multi-3), không có sự khác biệt đáng kể nào được quan sát giữa các cài đặt có giám sát và 0-shot. Đối với các ngôn ngữ có nguồn lực thấp, hiệu suất vẫn thấp mặc dù có tinh chỉnh đa ngữ. Kiểm tra thủ công cho thấy những đầu ra này, mặc dù ban đầu thuyết phục và đủ để nhận dạng ngôn ngữ (xem Hình 1), phần lớn là vô nghĩa. Những kết quả này chỉ ra rằng điều chỉnh hướng dẫn với chỉ hai đến ba ngôn ngữ là cần thiết và đủ để kích thích khái quát hóa đa ngôn ngữ 0-shot trong các ngôn ngữ có nguồn lực cao và trung bình trong nhiệm vụ này, với việc tiếp xúc ngôn ngữ trong quá trình tiền huấn luyện là giới hạn chính đối với khả năng khái quát hóa này.

8Để đánh giá, chúng tôi sử dụng gpt-3.5-turbo-1106 do cửa sổ context dài hơn.

--- TRANG 5 ---
Hình 3: SARI được trọng số bởi sự thỏa thuận ngôn ngữ IO cho Llama 2 7b với việc điều chỉnh hướng dẫn đa ngữ gia tăng. Kết quả được hiển thị cho cả prompting đa ngôn ngữ (en:xx) và prompting đơn ngữ (xx:xx). Các thanh có sọc chỉ ra cài đặt 0-shot và thanh lỗi hiển thị khoảng tin cậy 95%.

4.2 Đơn giản hóa câu
Đơn giản hóa câu nhằm làm cho các câu phức tạp dễ đọc và hiểu hơn. Do thiếu dữ liệu huấn luyện có giám sát chất lượng cao, đơn giản hóa câu tự động vẫn là một nhiệm vụ thách thức (Štajner, 2021), và do đó có lợi từ khả năng khái quát hóa few-shot và 0-shot của các LLM tuân theo hướng dẫn. Để đánh giá hiệu suất trên nhiệm vụ này, chúng tôi sử dụng benchmark MultiSim (Ryan et al., 2023), bao gồm các bộ dữ liệu song song được căn chỉnh câu trong nhiều ngôn ngữ. Vì các bộ dữ liệu riêng lẻ trong MultiSim được lấy từ các nguồn riêng biệt, lượng dữ liệu có sẵn khác nhau qua các ngôn ngữ. Chúng tôi lấy mẫu 1.371 cặp câu phức tạp-đơn giản cho mỗi ngôn ngữ, trừ Slovenia, nơi chúng tôi sử dụng tất cả 939 trường hợp có sẵn (xem Phụ lục D để biết chi tiết).

Để prompt các mô hình cho đơn giản hóa câu, chúng tôi tái sử dụng các hướng dẫn chi tiết được đưa ra cho các crowdworker để tạo ra kho ngữ liệu ASSET (Alva-Manchego et al., 2020), điều đã được chứng minh là hiệu quả trong các cài đặt few-shot (Kew et al., 2023). Ở dạng gốc, prompt này rõ ràng nói rằng đầu ra phải phù hợp cho "người học tiếng Anh". Chúng tôi loại bỏ đặc tả ngôn ngữ này để mô hình không được hướng dẫn rõ ràng về ngôn ngữ đích và thay vào đó được kỳ vọng suy luận nó từ câu đầu vào phức tạp được cung cấp. Để dịch prompt sang từng ngôn ngữ đích được xem xét, chúng tôi đã sử dụng một dịch vụ dịch máy miễn phí.9 Chúng tôi cũng xem xét cả cài đặt prompt đa ngôn ngữ (en:xx) và cài đặt prompt đơn ngữ (xx:xx). Cài đặt trước trình bày hướng dẫn nhiệm vụ bằng tiếng Anh và cung cấp câu nguồn phức tạp trong ngôn ngữ đích liên quan, trong khi cài đặt sau hoàn toàn bằng ngôn ngữ đích. Một ví dụ về mẫu prompt được hiển thị trong Bảng 4.

Để đánh giá, chúng tôi báo cáo SARI (Xu et al., 2016) như một chỉ số về tính đơn giản và đầy đủ cho việc đơn giản hóa tham chiếu. Để tính đến sự thỏa thuận ngôn ngữ IO, chúng tôi trọng số điểm SARI cấp độ kho ngữ liệu của mô hình theo phần trăm sự thỏa thuận ngôn ngữ IO mà nó đạt được. Điều này phạt mô hình nếu nó liên tục tạo ra đầu ra trong một ngôn ngữ không khớp với câu nguồn. Chẳng hạn, nếu mô hình tạo ra đầu ra tiếng Anh cho các câu đầu vào tiếng Đức với tỷ lệ 50%, điểm số cuối cùng được giảm một nửa.

Kết quả Hình 3 hiển thị hiệu suất theo SARI trọng số IO trên từng ngôn ngữ đích được xem xét với việc điều chỉnh hướng dẫn đa ngữ gia tăng. Tương tự như kết quả trên nhiệm vụ đối thoại một lượt, hiệu suất vẫn đồng đều cho tiếng Anh khi tỷ lệ hướng dẫn đa ngữ tăng. Đối với tất cả các ngôn ngữ đích không phải tiếng Anh, chúng tôi quan sát một sự khác biệt lớn giữa chiến lược prompting đa ngôn ngữ và chiến lược prompting đơn ngữ. Trong khi cái trước có xu hướng cải thiện khi số lượng ngôn ngữ tăng, nó thất bại trong việc khớp với chiến lược prompting đơn ngữ trong tất cả các điều kiện. Ngược lại, kết quả cho chiến lược prompting đơn ngữ giống hệt với những kết quả của nhiệm vụ đối thoại một lượt qua tất cả các ngôn ngữ đích có sẵn: lợi ích hiệu suất rõ rệt nhất khi chuyển từ điều chỉnh hướng dẫn đơn ngữ sang song ngữ, và chúng thường ổn định với chỉ ba ngôn ngữ điều chỉnh hướng dẫn.

4.3 Trả lời câu hỏi trích xuất
Trái ngược với các câu hỏi mở thường được sử dụng để truy vấn LLM trong các cài đặt trò chuyện, trả lời câu hỏi trích xuất đòi hỏi mô hình phải xác định các đoạn trả lời liên quan trong các đoạn văn context dài hơn được cung cấp như một phần của prompt. Một nhiệm vụ như vậy rất giống với cài đặt generation tăng cường truy xuất (RAG), là một phương pháp phổ biến để mở rộng kiến thức của LLM với dữ liệu bổ sung không có sẵn trong quá trình huấn luyện (Lewis et al., 2020; Izacard and Grave, 2021). Để đánh giá các mô hình của chúng tôi trên nhiệm vụ này trong nhiều ngôn ngữ đích, chúng tôi sử dụng XQuAD (Artetxe et al., 2020).10

Như điểm khởi đầu, chúng tôi mượn prompt tiếng Anh từ Lai et al. (2023a) và dịch thủ công nó sang từng ngôn ngữ đích được xem xét. Ngoài ra, chúng tôi bao gồm một tiền tố phản hồi chuẩn hóa như một phần của prompt, hiệu quả force-decoding phản hồi "Dựa trên đoạn văn, câu trả lời cho câu hỏi là". Điều này cho phép chúng tôi cô lập tốt hơn chuỗi trả lời liên quan trong đầu ra của mô hình sinh tạo. Một phản hồi được coi là đúng nếu câu trả lời chân lý cơ sở có thể được khớp với phần đầu của phản hồi của mô hình sau khi xử lý hậu kỳ tối thiểu.11 Một lần nữa, chúng tôi xem xét cả chiến lược prompting đa ngôn ngữ (en:xx) và đơn ngữ (xx:xx). Một ví dụ về chiến lược prompting của chúng tôi cho nhiệm vụ này và đầu ra mô hình được hiển thị trong Bảng 5.

Kết quả Hình 4 hiển thị hiệu suất trên từng ngôn ngữ đích của chúng tôi trong XQuAD với việc điều chỉnh hướng dẫn đa ngữ gia tăng. Một lần nữa, chúng tôi quan sát hiệu suất nhất quán cho tiếng Anh trong các cài đặt điều chỉnh hướng dẫn đa ngữ. Trong khi đó, hiệu suất trên các ngôn ngữ có nguồn lực cao như tiếng Đức và Trung Quốc thể hiện lợi ích biên khi chuyển từ điều chỉnh hướng dẫn đơn ngữ sang song ngữ và ổn định với tương đối ít ngôn ngữ. Đối với các ngôn ngữ có nguồn lực thấp (ví dụ, Hindi và Hy Lạp), hiệu suất vẫn nhất quán thấp qua tất cả các cài đặt, chỉ ra rằng khả năng khái quát hóa của mô hình đối với những ngôn ngữ này bị giới hạn bởi thiếu tiếp xúc trong quá trình tiền huấn luyện. So sánh các chiến lược prompting đa ngôn ngữ và đơn ngữ, chúng tôi quan sát rằng cái sau thường dẫn đến hiệu suất tốt hơn. Điều này đồng ý với kết quả từ nhiệm vụ đơn giản hóa câu (§4.2) và làm nổi bật lợi ích của prompting dưới giả định sự thỏa thuận ngôn ngữ IO. Trong khi lợi ích hiệu suất trên nhiệm vụ này thường ít rõ rệt hơn so với các nhiệm vụ trước đó được xem xét, chúng tôi lưu ý rằng QA trích xuất 0-shot về bản chất là thách thức đối với các LLM được điều chỉnh trên hướng dẫn đối thoại vì chúng có xu hướng tạo ra phản hồi dài dòng thay vì từ hoặc thực thể đơn lẻ khớp chính xác với chân lý cơ sở.

4.4 Lý luận thông thường
'Kiến thức thông thường' là thuật ngữ thường được sử dụng để chỉ tập hợp các sự kiện chung phản ánh cách các khái niệm có thể liên quan với nhau trong thế giới thực (Li et al., 2022; Talmor et al., 2019). Hiểu ngôn ngữ tự nhiên hiệu quả đòi hỏi một số đại diện của những khái niệm và mối quan hệ này, làm cho lý luận thông thường trở thành một kỹ năng chính cho các LLM. Để đánh giá mức độ các mô hình tập trung vào tiếng Anh có thể áp dụng lý luận thông thường qua các ngôn ngữ, chúng tôi sử dụng bộ dữ liệu X-CSQA (Lin et al.,

--- TRANG 6 ---
Hình 4: Kết quả XQuAD cho Llama 2 7b với việc điều chỉnh hướng dẫn đa ngữ gia tăng. Kết quả được hiển thị cho cả prompting đa ngôn ngữ (en:xx) và prompting đơn ngữ (xx:xx). Các thanh có sọc chỉ ra cài đặt 0-shot và thanh lỗi hiển thị khoảng tin cậy 95%.

2021).12 Bộ dữ liệu này chứa các câu hỏi được ghép nối với câu trả lời đa lựa chọn nhằm đánh giá kiến thức chung, bất khả tri ngôn ngữ của thế giới liên quan đến các loại lý luận thông thường khác nhau. Với một câu hỏi và một tập hợp năm câu trả lời có thể từ A-E, chúng tôi prompt mô hình để đưa ra chữ cái tương ứng với câu trả lời phù hợp nhất. Một lần nữa, chúng tôi mượn mẫu prompt tiếng Anh cho nhiệm vụ này từ Lai et al. (2023a) làm điểm khởi đầu và dịch nó sang từng ngôn ngữ đích. Đối với nhiệm vụ này, chúng tôi chỉ xem xét chiến lược prompting đơn ngữ (xx:xx), đã chứng minh hiệu quả nhất trong các nhiệm vụ trước đó. Một ví dụ về prompt được sử dụng được đưa ra trong Bảng 6.

Kết quả Hình 5 hiển thị độ chính xác trên X-CSQA với việc điều chỉnh hướng dẫn đa ngữ gia tăng. Một lần nữa, đối với tiếng Anh, chúng tôi quan sát rằng điều chỉnh hướng dẫn đa ngữ không làm giảm đáng kể hiệu suất. Tuy nhiên, trái ngược với các nhiệm vụ trước đó được xem xét, chúng tôi không quan sát bất kỳ lợi ích nhất quán nào cho các ngôn ngữ đích không phải tiếng Anh dựa trên điều chỉnh hướng dẫn đa ngữ, cho thấy rằng có những giới hạn về việc nhiệm vụ nào mà điều này có lợi.

12 Chúng tôi báo cáo kết quả cho X-CSQA được đo trên tập validation gồm 1.000 câu hỏi.

--- TRANG 7 ---
Hình 5: Kết quả X-CSQA cho Llama 2 7b với việc điều chỉnh hướng dẫn đa ngữ gia tăng. Các thanh có sọc chỉ ra cài đặt 0-shot và thanh lỗi hiển thị khoảng tin cậy 95%.

Hình 6: Kết quả XNLI cho Llama 2 7b với việc điều chỉnh hướng dẫn đa ngữ gia tăng. Các thanh có sọc chỉ ra cài đặt 0-shot và thanh lỗi hiển thị khoảng tin cậy 95%.

4.5 XNLI
Suy luận ngôn ngữ tự nhiên (NLI) là một kỹ năng quan trọng cho các LM, vì nó đảm bảo tính mạch lạc của văn bản, điều đặc biệt quan trọng khi các chuỗi đầu vào và đầu ra tăng về độ dài. Với hai câu, nhiệm vụ này nhằm nhận ra mối quan hệ giữa chúng là entailment, contradiction, hoặc neutral. Để đánh giá khả năng của LLM giải quyết nhiệm vụ này với việc điều chỉnh hướng dẫn đa ngữ, chúng tôi sử dụng XNLI (Conneau et al., 2018) và đánh giá hiệu suất trên split test chính thức.

Đối với nhiệm vụ này, chúng tôi sử dụng implementation trong LM Evaluation Harness (Gao et al., 2023).13 Thay vì truy vấn mô hình để tạo ra nhãn mong muốn, chúng tôi sử dụng rank classification (Sanh et al., 2022; Brown et al., 2020), cho phép so sánh trực tiếp với mô hình cơ sở. Trong cài đặt này, nhiều truy vấn được xây dựng cho mỗi trường hợp test với một mẫu được định nghĩa trước và sau đó được chấm điểm bởi mô hình. Chuỗi truy vấn có xác suất cao nhất dưới mô hình sau đó được chọn làm câu trả lời cuối cùng. Các mẫu prompt cho nhiệm vụ này là cụ thể theo ngôn ngữ làm cho nó tương đương với prompting đơn ngữ

13https://github.com/EleutherAI/lm-evaluation-harness

(xx:xx). Một ví dụ về nhiệm vụ này được cung cấp trong Bảng 7.

Kết quả Hình 6 hiển thị độ chính xác được đo trên các ngôn ngữ đích của chúng tôi từ XNLI. Một cách nổi bật, hiệu suất cho tất cả các ngôn ngữ đích vẫn đồng đều bất kể lượng tính đa ngữ được sử dụng trong quá trình tinh chỉnh. Hơn nữa, hiệu suất có thể so sánh qua tất cả các cài đặt huấn luyện cho thấy rằng, nói chung, điều chỉnh hướng dẫn thất bại trong việc cung cấp lợi ích có thể đo lường trong nhiệm vụ thách thức này.

5 Phân tích thêm
Kết quả thí nghiệm của chúng tôi trên năm nhiệm vụ riêng biệt chứng minh rằng điều chỉnh hướng dẫn đa ngữ có lợi cho đối thoại một lượt mở và đơn giản hóa câu trong các ngôn ngữ không phải tiếng Anh mạnh nhất. Trong phần này, chúng tôi tập trung vào đối thoại một lượt để điều tra tác động của đa dạng hướng dẫn so với đa dạng ngôn ngữ và mở rộng quy mô mô hình.

5.1 Đa dạng hướng dẫn so với đa dạng ngôn ngữ
Đa dạng là một yếu tố chính cho điều chỉnh hướng dẫn hiệu quả mẫu (Zhou et al., 2023). Vì các thí nghiệm của chúng tôi trong §4 sử dụng các trường hợp huấn luyện không phải tiếng Anh bản địa từ bộ dữ liệu OpenAssistant, một yếu tố gây nhiễu tiềm năng có thể là việc thêm nhiều ngôn ngữ hơn trong quá trình tinh chỉnh cũng đưa ra nhiều hướng dẫn huấn luyện đa dạng hơn. Để điều tra điều này, chúng tôi huấn luyện lại các mô hình Multi-i sử dụng dữ liệu điều chỉnh hướng dẫn được dịch từ Mono thay cho các ví dụ không phải tiếng Anh bản địa, theo cùng công thức gia tăng như được mô tả trong §3.2. Điều này đảm bảo rằng phân phối dữ liệu vẫn không đổi khi tính đa ngữ tăng. Là một engine dịch, chúng tôi một lần nữa sử dụng GPT-3.5-Turbo14 và mẫu prompt được cung cấp trong Hình 10.

14 Vì các trường hợp huấn luyện đối thoại có thể khá dài, đôi khi vượt quá cửa sổ context 4k token mặc định, chúng tôi sử dụng gpt-3.5-tubo-1106 cho nhiệm vụ dịch này do cửa sổ context dài hơn (16k).

Hình 7 so sánh hiệu suất kết quả trên nhiệm vụ đối thoại một lượt cho một tập con các ngôn ngữ đích của chúng tôi (kết quả cho các ngôn ngữ đích còn lại được cung cấp trong Hình 19). Đáng chú ý, chúng tôi không quan sát sự khác biệt đáng kể nào giữa việc điều chỉnh với các ví dụ không phải tiếng Anh bản địa riêng biệt so với những ví dụ được tạo ra thông qua dịch tự động, chỉ ra rằng lợi ích được gán cho tính đa ngữ tăng không bị nhầm lẫn với sự gia tăng trong đa dạng của hướng dẫn. Theo sau điều này, trong Phụ lục H, chúng tôi đi sâu hơn để điều tra vai trò của đa dạng ngôn ngữ với ngân sách cố định các ví dụ huấn luyện không phải tiếng Anh. Từ những thí nghiệm ablation này, chúng tôi thấy rằng tác động của việc tăng số lượng ngôn ngữ mạnh hơn so với việc tăng số lượng ví dụ cho một ngôn ngữ nhất định.

5.2 Mở rộng quy mô kích thước mô hình
Để điều tra ảnh hưởng của mở rộng quy mô mô hình, chúng tôi lặp lại các thí nghiệm đối thoại một lượt của chúng tôi sử dụng Llama 2 70b làm mô hình cơ sở bên dưới. Hình 8 hiển thị điểm số độ hữu ích kết quả được gán bởi thẩm phán LLM, với so sánh trực tiếp với Llama 2 7b. Đáng chú ý nhất, hiệu suất trên các ngôn ngữ đích không phải tiếng Anh có nguồn lực cao và trung bình được cải thiện đáng kể, thường khớp với hiệu suất của tiếng Anh. Tuy nhiên, mặc dù có những lợi ích này, điều chỉnh hướng dẫn đa ngữ với hai ngôn ngữ vẫn cần thiết để kích thích khái quát hóa đa ngôn ngữ trên nhiệm vụ này, tiếp tục củng cố các phát hiện chính của chúng tôi. Ngoài ra, chúng tôi quan sát rằng hiệu suất của mô hình lớn hơn trên hầu hết các ngôn ngữ đích không phải tiếng Anh có xu hướng ổn định với chỉ hai ngôn ngữ tinh chỉnh, không giống như mô hình nhỏ hơn thường đòi hỏi ba ngôn ngữ. Cuối cùng, trong khi hiệu suất trên các ngôn ngữ có nguồn lực thấp vẫn kém, nó thể hiện một cải thiện tương đối đáng kể so với mô hình 7 tỷ tham số. Những kết quả này chỉ ra rằng mở rộng quy mô mô hình cực kỳ có lợi cho việc khai thác khả năng đa ngữ trong các mô hình tập trung vào tiếng Anh

--- TRANG 8 ---
Hình 7: So sánh Llama 2 7b với việc điều chỉnh hướng dẫn đa ngữ sử dụng các ví dụ không phải tiếng Anh bản địa (Native NE) so với các ví dụ không phải tiếng Anh được dịch (MT NE). Thanh lỗi hiển thị khoảng tin cậy 95%.

và phù hợp với các phát hiện từ Shaham et al. (2023).

6 Thảo luận
Các phát hiện của chúng tôi cho thấy rằng điều chỉnh hướng dẫn đa ngữ hỗ trợ chuyển giao đa ngôn ngữ trong các LLM tập trung vào tiếng Anh, mặc dù hiệu quả của nó đối với hiệu suất hạ nguồn khác nhau qua các nhiệm vụ và mức độ mà một ngôn ngữ đích cụ thể được nhìn thấy trong quá trình tiền huấn luyện. Đối với các ngôn ngữ có nguồn lực cao và trung bình, chúng tôi quan sát lợi ích hiệu suất đáng kể trên đối thoại một lượt và đơn giản hóa câu với prompting đơn ngữ, cũng như lợi ích biên trên QA trích xuất với prompting đơn ngữ. Trong khi đó, đối với các ngôn ngữ có nguồn lực thấp và các nhiệm vụ có cấu trúc cao áp đặt ràng buộc nghiêm ngặt trên không gian đầu ra bất kể ngôn ngữ đầu vào (ví dụ, QA đa lựa chọn), điều chỉnh hướng dẫn đa ngữ có ít tác động. Sự phân biệt này làm nổi bật rằng điều chỉnh hướng dẫn đa ngữ có lợi nhất cho các nhiệm vụ sinh tạo mở hơn giả định sự thỏa thuận ngôn ngữ IO, và quan trọng, lợi ích này bị giới hạn bởi các ngôn ngữ có nguồn lực cao và trung bình liên quan đến phân phối ngôn ngữ tiền huấn luyện của mô hình.

Đáng ngạc nhiên nhất, chúng tôi thấy rằng điều chỉnh hướng dẫn đa ngữ với chỉ hai đến ba ngôn ngữ là cần thiết và đủ để thúc đẩy khái quát hóa này trong tất cả bốn LLM tập trung vào tiếng Anh được xem xét. Hơn nữa, chúng tôi nhất quán thấy rằng hiệu suất có xu hướng ổn định khá nhanh và việc thêm nhiều ngôn ngữ điều chỉnh hướng dẫn hơn – bao gồm cả ngôn ngữ đích – thường không cung cấp lợi ích đáng kể. Điều này nhấn mạnh rằng lợi ích hiệu suất phần lớn là kết quả của chuyển giao đa ngôn ngữ và gợi ý rằng có thể có lợi ích giảm dần liên quan đến việc mở rộng quy mô điều chỉnh hướng dẫn đa ngữ vượt quá chỉ một số ít ngôn ngữ.

Chúng tôi đưa ra giả thuyết rằng các phát hiện của chúng tôi phù hợp với giả thuyết căn chỉnh bề ngoài được đưa ra bởi Zhou et al. (2023), nói rằng một mô hình thu được kiến thức và khả năng của nó trong quá trình tiền huấn luyện, trong khi điều chỉnh hướng dẫn chỉ đơn giản hướng dẫn mô hình về một 'phân phối con mong muốn của các định dạng' để sử dụng khi được prompt. Chúng tôi tinh chỉnh giả thuyết này bằng cách thêm rằng chỉ một lượng nhỏ dữ liệu hướng dẫn đa ngữ cũng khuyến khích mô hình học một ánh xạ đơn giản giữa ngôn ngữ đầu vào và đầu ra. Điều này hướng dẫn mô hình về các phân phối con cụ thể theo ngôn ngữ, dẫn đến hiệu suất tốt hơn trên các nhiệm vụ mà sự thỏa thuận ngôn ngữ IO được yêu cầu.

7 Kết luận
Chúng tôi đã điều tra lượng tối thiểu điều chỉnh hướng dẫn đa ngữ cần thiết để kích thích khả năng đa ngữ của bốn LLM tập trung vào tiếng Anh riêng biệt. Kết quả của chúng tôi cho thấy rằng tinh chỉnh với chỉ hai đến ba ngôn ngữ là cần thiết và đủ để thúc đẩy chuyển giao đa ngôn ngữ hiệu quả, cho phép các mô hình khai thác tốt hơn lượng tương đối nhỏ dữ liệu không phải tiếng Anh được nhìn thấy trong quá trình tiền huấn luyện. Các thí nghiệm trên năm nhiệm vụ riêng biệt tiết lộ rằng điều này có thể dẫn đến cải thiện hiệu suất đáng kể cho các ngôn ngữ có nguồn lực cao và trung bình trên các nhiệm vụ sinh tạo mở giả định sự thỏa thuận ngôn ngữ đầu vào/đầu ra.

Trong khi hiệu quả của chuyển giao đa ngôn ngữ thực sự là tin tốt cho các nhà phát triển LLM, nghiên cứu tương lai có thể khám phá các phương pháp để giảm khoảng cách hiệu suất giữa tiếng Anh và các ngôn ngữ không phải tiếng Anh, đặc biệt đối với các mô hình nhỏ hơn, cũng như điều tra các nhiệm vụ mà điều chỉnh hướng dẫn cụ thể theo ngôn ngữ có thể có tầm quan trọng lớn hơn, chẳng hạn như các nhiệm vụ liên quan đến nhận thức văn hóa.

--- TRANG 9 ---
Hình 8: Độ hữu ích trung bình của các phản hồi đối thoại một lượt từ Llama 2 70b (ký hiệu bằng các điểm tam giác) và Llama 2 7b (thanh bán trong suốt) với việc điều chỉnh hướng dẫn đa ngữ gia tăng. Các thanh có sọc chỉ ra cài đặt 0-shot và thanh lỗi hiển thị khoảng tin cậy 95%.

Giới hạn
Kết quả thí nghiệm của chúng tôi chứng minh rằng một lượng tương đối nhỏ dữ liệu điều chỉnh hướng dẫn đa ngữ có thể kích thích chuyển giao đa ngôn ngữ có giá trị cao, dẫn đến cải thiện hiệu suất trong các nhiệm vụ sinh tạo mở giả định sự thỏa thuận ngôn ngữ IO. Tuy nhiên, chúng tôi chưa khám phá các nhiệm vụ liên quan đến ánh xạ phức tạp hơn giữa các ngôn ngữ, chẳng hạn như các nhiệm vụ liên quan đến xử lý đa ngôn ngữ rộng rãi hoặc dịch thuật.

Trong nghiên cứu này, chúng tôi dựa vào nhận dạng ngôn ngữ tự động để xây dựng dữ liệu huấn luyện đa ngữ và trong việc đánh giá đầu ra mô hình. Để làm điều này, chúng tôi đã sử dụng mô hình OpenLID từ Burchell et al. (2023). Mặc dù có tỷ lệ lỗi thấp được đạt bởi mô hình này, nhận dạng ngôn ngữ không hoàn hảo và có thể dẫn đến một số văn bản bị nhận dạng sai. Để giảm thiểu rủi ro nhiễm ngôn ngữ không chủ ý (Blevins and Zettlemoyer, 2022) trong các bộ dữ liệu tinh chỉnh của chúng tôi, chúng tôi bao gồm các ví dụ huấn luyện có ngôn ngữ được xác định với ngưỡng tin cậy ≥0.8.

Trong §5.1, chúng tôi điều tra tác động của đa dạng đa ngữ so với đa dạng ví dụ huấn luyện. Trong khi các phát hiện của chúng tôi tiết lộ rằng không có sự khác biệt đáng kể giữa hai cài đặt này, chúng tôi lưu ý rằng ngay cả khi tinh chỉnh với các ví dụ không phải tiếng Anh bản địa gốc, đa dạng nhiệm vụ có thể về bản chất bị giới hạn bởi thiết kế của việc thu thập dữ liệu. Chẳng hạn, bất kể ngôn ngữ được sử dụng, các crowdworker được yêu cầu tuân theo cùng một tập hợp hướng dẫn15 khi tạo dữ liệu.

Cuối cùng, để đánh giá chất lượng phản hồi do mô hình tạo ra trong nhiệm vụ đối thoại một lượt, chúng tôi dựa vào các phương pháp đánh giá dựa trên LLM. Trong khi một số nghiên cứu đã cho thấy rằng đánh giá dựa trên LLM cung cấp một proxy tốt để đánh giá chất lượng phản hồi đối thoại, đạt được sự tương quan mạnh với các đánh giá của con người (Liu et al., 2023; Kocmi and Federmann, 2023; Zheng et al., 2023), chúng tôi dừng lại trước việc thiết lập thực nghiệm sự đồng ý này trên đầu ra mô hình của chính chúng tôi. Để đảm bảo tính hợp lệ của đầu ra mô hình, chúng tôi đã đánh giá thủ công tính đầy đủ của các phản hồi được lấy mẫu ngẫu nhiên trong ba ngôn ngữ đích (en, es và de). Đánh giá này tiết lộ một xu hướng tương tự với đánh giá dựa trên LLM của chúng tôi, đó là các đầu ra tiếng Tây Ban Nha thường hơi tệ hơn so với các đầu ra tiếng Anh nhưng hơi tốt hơn so với các đầu ra tiếng Đức.

15https://projects.laion.ai/Open-Assistant/docs/guides/guidelines

Cân nhắc đạo đức và rủi ro
Nghiên cứu này nhằm đánh giá khả năng đa ngữ của các LLM tập trung vào tiếng Anh. Khi làm như vậy, chúng tôi thừa nhận những cân nhắc đạo đức tiềm năng và rủi ro liên quan đến nghiên cứu của chúng tôi. Thứ nhất, các LLM đã được chứng minh là vô tình duy trì các thiên lệch có trong dữ liệu huấn luyện của chúng, điều có thể dẫn đến những kết quả bất ngờ và không công bằng khi những mô hình này được sử dụng trong các ứng dụng thế giới thực. Do đó, các biện pháp phải được thực hiện để giảm thiểu rủi ro này (ví dụ, sử dụng các chiến lược căn chỉnh bổ sung, kiểm tra nghiêm ngặt trong các cài đặt đa ngữ) trước khi triển khai các mô hình đối diện với công chúng. Thứ hai, khi xây dựng trên các LLM tập trung vào tiếng Anh, có rủi ro đồng nhất hóa văn hóa, nơi các sắc thái và đa dạng của các ngôn ngữ khác nhau có thể bị mất do đại diện thiếu của chúng trong dữ liệu huấn luyện.

Lời cảm ơn
Chúng tôi chân thành cảm ơn bạn bè và đồng nghiệp của chúng tôi, Fabian Aiolfi, Thea Bächler, Anastassia Shaitarova, Finnur Ágúst Ingimundarson, Cui Ding, Andrianos Michail, Janine Aeberhard, Arnisa Fazla, Farhad Nooralahzadeh, Omnia Ibrahim, Xuan Lam, Manasi Muglikar, Anne Göhring, và Alessia Battisti vì đã giúp chúng tôi với các câu hỏi cụ thể theo ngôn ngữ và xác thực các bản dịch được sử dụng trong các thí nghiệm của chúng tôi, cũng như Lena Sophia Bolliger và Patrick Haller vì đã cung cấp phản hồi có giá trị về các phiên bản trước của bài báo này. Rico Sennrich thừa nhận tài trợ từ Quỹ Khoa học Quốc gia Thụy Sĩ (dự án MUTAMUR; số 213976).

Tài liệu tham khảo
Ebtesam Almazrouei, Hamza Alobeidli, Abdulaziz Alshamsi, Alessandro Cappelli, Ruxandra Cojocaru, Mérouane Debbah, Étienne Goffinet, Daniel Hesslow, Julien Launay, Quentin Malartic, Daniele Mazzotta, Badreddine Noune, Baptiste Pannier, và Guilherme Penedo. 2023. Loạt mô hình ngôn ngữ mở falcon.

Sandra Aluísio và Caroline Gasperin. 2010. Thúc đẩy bao gồm số và khả năng tiếp cận: Dự án PorSimples để đơn giản hóa văn bản tiếng Bồ Đào Nha. Trong Kỷ yếu Hội thảo Nhà nghiên cứu trẻ NAACL HLT 2010 về Phương pháp tính toán cho Ngôn ngữ châu Mỹ, trang 46–53, Los Angeles, California. Hiệp hội Ngôn ngữ học Tính toán.

--- TRANG 10 ---
[Phần còn lại của tài liệu tiếp tục với các tài liệu tham khảo và phụ lục...]

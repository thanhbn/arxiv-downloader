# Phá Bỏ Rào Cản Chữ Viết trong Các Mô Hình Ngôn Ngữ Tiền Huấn Luyện Đa Ngôn Ngữ với Phương Pháp Căn Chỉnh Sau Huấn Luyện Dựa Trên Chuyển Chữ

Orgest Xhelili1,*, Yihong Liu2,3,*, and Hinrich Schütze2,3
1Technical University of Munich
2Center for Information and Language Processing, LMU Munich
3Munich Center for Machine Learning (MCML)
orgest.xhelili@tum.de, yihong@cis.lmu.de

## Tóm Tắt

Các mô hình tiền huấn luyện đa ngôn ngữ (mPLM) đã thể hiện hiệu suất ấn tượng trong các nhiệm vụ chuyển giao đa ngôn ngữ. Tuy nhiên, hiệu suất chuyển giao thường bị cản trở khi ngôn ngữ mục tiêu có ít tài nguyên được viết bằng chữ viết khác với ngôn ngữ nguồn có nhiều tài nguyên, mặc dù hai ngôn ngữ có thể có liên quan hoặc chia sẻ các phần từ vựng. Được truyền cảm hứng từ các nghiên cứu gần đây sử dụng chuyển chữ để giải quyết vấn đề này, bài báo của chúng tôi đề xuất một phương pháp căn chỉnh sau tiền huấn luyện (PPA) dựa trên chuyển chữ nhằm cải thiện sự căn chỉnh đa ngôn ngữ giữa các ngôn ngữ sử dụng chữ viết đa dạng. Chúng tôi chọn hai nhóm ngôn ngữ khu vực, Mediterranean-Amharic-Farsi và South+East Asian Languages, trong đó các ngôn ngữ có ảnh hưởng lẫn nhau nhưng sử dụng chữ viết khác nhau. Chúng tôi áp dụng phương pháp này cho những nhóm ngôn ngữ này và tiến hành các thí nghiệm rộng rãi trên một loạt các nhiệm vụ hạ nguồn. Kết quả cho thấy sau PPA, các mô hình liên tục vượt trội hơn mô hình gốc (lên đến 50% cho một số nhiệm vụ) trong việc chuyển giao lấy tiếng Anh làm trung tâm. Ngoài ra, khi chúng tôi sử dụng các ngôn ngữ khác ngoài tiếng Anh làm nguồn trong chuyển giao, phương pháp của chúng tôi có được những cải thiện còn lớn hơn. Chúng tôi sẽ công khai mã nguồn và các mô hình tại https://github.com/cisnlp/Transliteration-PPA.

## 1 Giới Thiệu

Các mPLM gần đây như mBERT (Devlin et al., 2019) và XLM-R (Conneau et al., 2020) đã thể hiện hiệu suất đáng chú ý trong các nhiệm vụ chuyển giao đa ngôn ngữ bằng cách học các biểu diễn đa ngôn ngữ từ các tập dữ liệu đơn ngôn ngữ (Pires et al., 2019; Artetxe et al., 2020a). Mặc dù có hiệu suất ấn tượng, những mô hình này vẫn thể hiện những hạn chế trong chuyển giao đa ngôn ngữ liên quan đến các ngôn ngữ có ít tài nguyên. Deshpande et al. (2022) đã chỉ ra rằng hiệu suất hạ nguồn của mPLM có tương quan với mức độ căn chỉnh giữa các embedding từ qua các ngôn ngữ. Một yếu tố khác cản trở việc chuyển giao kiến thức là sự đa dạng chữ viết hoặc rào cản chữ viết của các ngôn ngữ được biểu diễn, điều này đã được quan sát thấy ngay cả trong trường hợp các ngôn ngữ có liên quan (Anastasopoulos and Neubig, 2019; Muller et al., 2021). Vấn đề rào cản chữ viết cũng có thể được xem xét từ góc độ căn chỉnh biểu diễn. Wen-Yi and Mimno (2023) đã chỉ ra rằng các biểu diễn token từ các chữ viết khác nhau có thể được tách biệt tuyến tính gần như hoàn hảo, cho thấy rằng các mô hình gặp khó khăn trong việc học một không gian biểu diễn chung. Do đó, cần có huấn luyện sau để tăng cường chuyển giao đa ngôn ngữ không cần ví dụ trong các nhiệm vụ như truy xuất câu, phân loại văn bản, hoặc gán nhãn chuỗi, tất cả đều hưởng lợi từ sự căn chỉnh đa ngôn ngữ tốt hơn (Hämmerl et al., 2024).

Nhiều chiến lược căn chỉnh sau huấn luyện sử dụng các mục tiêu dựa trên từ điển song ngữ hoặc dữ liệu song song để căn chỉnh các biểu diễn của mPLM (Cao et al., 2020; Wang et al., 2020; Schuster et al., 2019; Pan et al., 2021). Tuy nhiên, từ điển và các tập dữ liệu song song thường bị hạn chế về quy mô dữ liệu hoặc số lượng ngôn ngữ mà chúng bao phủ (Artetxe et al., 2020b), điều này có thể không thực tế để xây dựng tín hiệu giám sát mạnh cho nhiều ngôn ngữ có ít tài nguyên. Một lựa chọn khác cải thiện sự căn chỉnh đa ngôn ngữ là sử dụng chuyển chữ (một quá trình chuyển đổi văn bản của một ngôn ngữ từ chữ viết này sang chữ viết khác). Chuyển chữ có thể cải thiện sự trùng lặp từ vựng, đặc biệt là cho các ngôn ngữ có liên quan (Moosa et al., 2023). Không giống như dịch thuật, chuyển chữ có thể có được gần như miễn phí bằng cách sử dụng các công cụ dựa trên quy tắc hoạt động tốt (Hermjakob et al., 2018). Do đó, một số nghiên cứu đã cho thấy sự cải thiện trong chuyển giao đa ngôn ngữ bằng cách tiền huấn luyện hoặc tinh chỉnh các mô hình với dữ liệu được chuyển chữ thành một chữ viết chung (Murikinati et al., 2020; Muller et al., 2021; Purkayastha et al., 2023; Moosa et al., 2023). Tuy nhiên, những phương pháp này yêu cầu mô hình sử dụng một chữ viết chung duy nhất, điều này khá hạn chế cho nhiều nhiệm vụ vì quá trình chuyển chữ có thể gây mất mát và không thể đảo ngược.

Gần đây, Liu et al. (2024a) đã đề xuất một mục tiêu học tương phản ở mức chuỗi để cải thiện sự căn chỉnh qua các chữ viết khác nhau ở quy mô lớn (cho hơn 500 ngôn ngữ), sử dụng cả câu chữ viết gốc và chuyển chữ Latin của chúng, được xác thực bằng các đánh giá chuyển giao đa ngôn ngữ không cần ví dụ lấy tiếng Anh làm trung tâm. Tuy nhiên, có ba hạn chế chính trong thiết lập của họ. Đầu tiên, mục tiêu tương phản chỉ thao tác các biểu diễn mức chuỗi trong lớp giữa, điều này không đóng góp trực tiếp vào sự căn chỉnh tốt hơn trong không gian mức token. Thứ hai, không phải mọi cặp ngôn ngữ đều có sự trùng lặp từ vựng rộng rãi có thể tăng cường chuyển giao đa ngôn ngữ: căn chỉnh dựa trên chuyển chữ có ý nghĩa hơn đối với các ngôn ngữ có ảnh hưởng lẫn nhau. Cuối cùng, chỉ riêng tiếng Anh làm ngôn ngữ nguồn chuyển giao không khai thác đầy đủ lợi ích căn chỉnh, vì nó không có sự trùng lặp từ vựng nhiều nhất với các ngôn ngữ khác.

Để giải quyết vấn đề này, chúng tôi đề xuất một phương pháp căn chỉnh sau huấn luyện dựa trên chuyển chữ mới hoạt động trên cả mức chuỗi và token. Phương pháp của chúng tôi không dựa vào dữ liệu song song. Thay vào đó, tương tự như Liu et al. (2024a), chúng tôi sử dụng dữ liệu đơn ngôn ngữ trong chữ viết gốc của chúng và chuyển chữ Latin thu được bằng cách sử dụng Uroman (Hermjakob et al., 2018). Chúng tôi điều tra tác động của chiến lược bằng cách tập trung vào hai nhóm ngôn ngữ: Mediterranean-Amharic-Farsi và South+East Asian Languages, được mô tả chi tiết hơn trong Phần 4.2. Các ngôn ngữ trong mỗi nhóm chia sẻ các đặc điểm khu vực nhưng khác nhau về chữ viết. Một số ngôn ngữ có liên quan chặt chẽ với nhau như các thành viên của cùng một họ ngôn ngữ (ví dụ: Semitic và Sino-Tibetan). Ngoài ra, các ngôn ngữ trong mỗi nhóm có sự trùng lặp từ vựng rộng rãi do tiếp xúc lịch sử và gần gũi về địa lý (ví dụ: tiếng Trung và tiếng Hàn hoặc tiếng Thổ Nhĩ Kỳ và tiếng Ả Rập). Vì những ngôn ngữ này được viết bằng các chữ viết khác nhau, chuyển chữ có thể giúp khai thác tốt hơn các tính chất ngôn ngữ chung và do đó cải thiện việc chuyển giao đa ngôn ngữ.

Chúng tôi tận dụng phương pháp của mình để huấn luyện sau Glot500 (ImaniGooghari et al., 2023) (một mô hình tiền huấn luyện liên tục từ XLM-R trên hơn 500 ngôn ngữ) trên các nhóm ngôn ngữ đã chọn và đánh giá hiệu suất chuyển giao đa ngôn ngữ không cần ví dụ trên ba loại nhiệm vụ hạ nguồn: truy xuất câu, phân loại văn bản, và gán nhãn chuỗi. Việc đánh giá được thực hiện với tiếng Anh làm ngôn ngữ nguồn và ba ngôn ngữ nguồn khác có chữ viết khác nhau trong mỗi nhóm. Chúng tôi cho thấy rằng phương pháp của chúng tôi liên tục cải thiện hiệu suất nhiệm vụ hạ nguồn qua các ngôn ngữ và chữ viết khác nhau. Hơn nữa, phương pháp của chúng tôi tiếp tục tăng cường hiệu suất chuyển giao khi các ngôn ngữ nguồn tốt hơn được chọn, vì hiệu suất phụ thuộc vào mức độ căn chỉnh giữa các ngôn ngữ nguồn và mục tiêu – chính xác là sự căn chỉnh mà cách tiếp cận của chúng tôi tăng cường.

Các đóng góp của chúng tôi có thể được tóm tắt như sau: (i) Chúng tôi đề xuất một phương pháp căn chỉnh sau huấn luyện dựa trên chuyển chữ hoạt động trên cả mức chuỗi và token, nhằm thu hẹp rào cản chữ viết trong mPLM; (ii) Chúng tôi điều tra tác động của phương pháp này trên hai nhóm ngôn ngữ khu vực với các chữ viết khác nhau và cho thấy sự cải thiện nhất quán trong chuyển giao đa ngôn ngữ không cần ví dụ; (iii) Chúng tôi khám phá một cách có hệ thống cách các ngôn ngữ nguồn khác nhau ảnh hưởng đến hiệu suất chuyển giao không cần ví dụ của các mô hình căn chỉnh chuyển chữ thu được.

## 2 Nghiên Cứu Liên Quan

Nhiều nghiên cứu gần đây đã đề xuất các phương pháp căn chỉnh tiền huấn luyện hoặc tinh chỉnh để cải thiện chuyển giao đa ngôn ngữ trong mPLM. Cao et al. (2020) đã đề xuất một mục tiêu căn chỉnh embedding tinh chỉnh giữa các cặp từ được thu thập theo cách không giám sát từ dữ liệu song song bằng cách sử dụng các mô hình căn chỉnh từ thống kê (Dyer et al., 2013). Chaudhary et al. (2020) đã cải thiện sự căn chỉnh trong quá trình tiền huấn luyện bằng cách sử dụng từ điển song ngữ để thay thế các từ trong câu gốc bằng các bản dịch trong các ngôn ngữ khác. Tương tự, Tang et al. (2022) đã sử dụng từ điển song ngữ để căn chỉnh một cách rõ ràng các embedding của cùng một từ trong các ngôn ngữ khác nhau trong quá trình tiền huấn luyện. Wei et al. (2021) đã đề xuất một phương pháp tiền huấn luyện học tương phản phân cấp, sử dụng dữ liệu song song để căn chỉnh các biểu diễn ở mức từ và câu. Tương tự, Hu et al. (2021) đã đề xuất một phương pháp tiền huấn luyện với các tín hiệu căn chỉnh rõ ràng từ dữ liệu song song khuyến khích tính đối xứng ở cả mức từ và câu. Pan et al. (2021) đã kết hợp học tương phản với mô hình hóa ngôn ngữ dịch thuật (Conneau and Lample, 2019) như một phương pháp căn chỉnh sau huấn luyện cũng sử dụng dữ liệu song song. Trong khi những phương pháp này đã cho thấy sự cải thiện trong chuyển giao đa ngôn ngữ, chúng có hạn chế là yêu cầu dữ liệu song song hoặc từ điển song ngữ, điều này có thể khó có được cho nhiều ngôn ngữ có ít tài nguyên.

Chuyển chữ là một quá trình chuyển đổi văn bản từ chữ viết của một ngôn ngữ sang chữ viết khác (Wellisch et al., 1978). Quá trình này không liên quan đến việc dịch nghĩa mà thay vào đó biểu diễn các ký hiệu gốc càng gần với chữ viết đích càng tốt. Các nghiên cứu khác nhau đã đề xuất các phương pháp dựa trên chuyển chữ để giải quyết vấn đề rào cản chữ viết trong các mô hình đa ngôn ngữ. Murikinati et al. (2020) đã sử dụng chuyển chữ sang một chữ viết chung để cải thiện biến hình thái đa ngôn ngữ. Khemchandani et al. (2021) đã khai thác mối quan hệ ngôn ngữ giữa các ngôn ngữ Ấn Độ và tận dụng chuyển chữ sang một chữ viết chung để thích ứng các mô hình đa ngôn ngữ với các ngôn ngữ có ít tài nguyên. Muller et al. (2021) đã phân tích hành vi của các mô hình đa ngôn ngữ trên các ngôn ngữ chưa thấy và phát hiện rằng các ngôn ngữ được viết bằng các chữ viết khác nhau không hưởng lợi từ học chuyển giao. Họ đề xuất chuyển chữ sang chữ viết ngôn ngữ nguồn có nhiều tài nguyên để giải quyết rào cản chữ viết. Purkayastha et al. (2023) đã chỉ ra rằng việc tinh chỉnh các mô hình đa ngôn ngữ trên dữ liệu được chuyển chữ thành chữ Latin cải thiện chuyển giao đa ngôn ngữ cho các ngôn ngữ có ít tài nguyên. Tương tự, Moosa et al. (2023) đã tiền huấn luyện các mô hình từ đầu trên dữ liệu được chuyển chữ thành một chữ viết chung cho các ngôn ngữ Ấn Độ và cho thấy sự cải thiện trong chuyển giao đa ngôn ngữ. Nghiên cứu của chúng tôi liên quan nhất đến TRANSLICO được đề xuất bởi Liu et al. (2024a), trong đó một mục tiêu học tương phản mức chuỗi được sử dụng để khuyến khích sự căn chỉnh qua các chữ viết khác nhau mà không hạn chế các mô hình vào một chữ viết chung, sử dụng các câu chữ viết gốc và chuyển chữ Latin của chúng. Tuy nhiên, thiết lập đánh giá lấy tiếng Anh làm trung tâm của họ hạn chế khả năng tiết lộ đầy đủ tác động của chuyển chữ. Bài báo này khám phá một cách có hệ thống cách căn chỉnh dựa trên chuyển chữ tăng cường hiệu suất chuyển giao bằng cách sử dụng các ngôn ngữ nguồn khác nhau.

## 3 Phương Pháp

Chúng tôi trình bày một phương pháp căn chỉnh sau huấn luyện dựa trên chuyển chữ có thể được sử dụng để tinh chỉnh các mPLM chỉ mã hóa hiện có để cải thiện sự căn chỉnh qua các ngôn ngữ sử dụng các chữ viết khác nhau, tăng cường hiệu suất chuyển giao đa ngôn ngữ. Phương pháp của chúng tôi bao gồm ba mục tiêu: mô hình hóa ngôn ngữ có mặt nạ, căn chỉnh mức câu, và căn chỉnh mức token. Tất cả các mục tiêu đều được huấn luyện trên dữ liệu kết hợp gốc và chuyển chữ. Dữ liệu chuyển chữ được thu được bằng cách chuyển đổi dữ liệu gốc thành chữ Latin. Quá trình chuyển chữ sử dụng Uroman (Hermjakob et al., 2018), một hệ thống dựa trên quy tắc có thể chuyển đổi gần như tất cả các bộ ký tự thành một chữ Latin chung. Phương pháp tổng thể được minh họa trong Hình 1, và chúng tôi giới thiệu chi tiết ba mục tiêu dưới đây.

### 3.1 Mô Hình Hóa Ngôn Ngữ Có Mặt Nạ

Với một chuỗi đầu vào trong chữ viết gốc: X^orig_i hoặc phiên bản chuyển chữ của nó: X^latn_i, chúng tôi áp dụng mục tiêu MLM naïve (Devlin et al., 2019) để dự đoán các token được che ngẫu nhiên trong cả hai chuỗi:

L_MLM = E[-∑_{m∈M} log p_MLM(X_{i,m}|h_{i,m})]

trong đó M là tập hợp các vị trí bị che trong câu đầu vào X_i (hoặc X^orig_i hoặc X^latn_i) và p_MLM(X_{i,m}|h_{i,m}) là xác suất dự đoán token X_{i,m} cho h_{i,m}, biểu diễn ngữ cảnh hóa cuối cùng tại vị trí m trong chuỗi thứ i. Xác suất được tính bằng một đầu MLM. Tinh chỉnh với MLM trên dữ liệu gốc là cần thiết để bảo toàn kiến thức của mô hình. Mặt khác, mPLM có kiến thức tối thiểu về dữ liệu chuyển chữ, điều này làm cho mục tiêu MLM trên dữ liệu chuyển chữ trở nên quan trọng để học các biểu diễn chéo chữ viết hữu ích. Chúng tôi gọi mục tiêu MLM cho dữ liệu gốc (tương ứng dữ liệu chuyển chữ) là L^orig_MLM (tương ứng L^latn_MLM).

### 3.2 Căn Chỉnh Mức Câu

Chúng tôi xử lý một chuỗi đầu vào trong chữ viết gốc X^orig_i và phiên bản chuyển chữ X^latn_i của nó như có cùng ngữ nghĩa. Do đó, chúng tôi áp dụng một mục tiêu học tương phản mức chuỗi, tương tự như SimCSE (Gao et al., 2021), để khuyến khích mô hình học các biểu diễn mức chuỗi tương tự cho các chuỗi gốc và chuyển chữ. Thiết lập này tương tự với các nghiên cứu khác áp dụng học tương phản trên các cặp được hình thành bởi một câu gốc và bản dịch tiếng Anh của nó (Chi et al., 2021; Pan et al., 2021). Trong ngữ cảnh của chúng tôi, Latin hoạt động như một chữ viết trục, khuyến khích sự căn chỉnh đa ngôn ngữ tốt hơn của các biểu diễn trong các chữ viết khác nhau.

Theo Liu et al. (2024a), chúng tôi áp dụng mục tiêu học tương phản trên một batch cho trước của các chuỗi gốc và chuyển chữ B = {(X^orig_i, X^latn_i)}^N_{i=1}. Mỗi batch xác định các cặp tương phản dương (X, X^+) trong đó X là chuỗi gốc và X^+ là phiên bản chuyển chữ của nó hoặc ngược lại, tức là (X^orig_i, X^latn_i) hoặc (X^latn_i, X^orig_i). Đối với mỗi cặp dương, các ví dụ âm được hình thành bởi tất cả các chuỗi khác trong batch B^- = B \ {(X^orig_i, X^latn_i)} (lạm dụng ký hiệu một chút).

Tổn thất tương phản sau đó được định nghĩa là:

L_SEQ = E[-log (e^{sim(f(X),f(X^+))/τ} / (e^{sim(f(X),f(X^+))/τ} + NEG))]

trong đó NEG = ∑_{(X,X^-)∈B^-} e^{sim(f(X),f(X^-))/τ}, f được định nghĩa là pooling trung bình trên các embedding ngữ cảnh hóa đầu ra lớp thứ 8 (bỏ qua đầu ra của các token đặc biệt trừ token [mask]), sim là tích vô hướng, và τ là nhiệt độ được đặt thành 1.

### 3.3 Căn Chỉnh Mức Token

Mục tiêu căn chỉnh mức câu giúp mô hình học các biểu diễn câu tương tự cho các chuỗi gốc và chuyển chữ. Điều này hữu ích để cải thiện hiệu suất trong các nhiệm vụ hạ nguồn mức câu như truy xuất câu hoặc phân loại. Tuy nhiên, mục tiêu này thao tác đầu ra của một lớp giữa, điều này không đóng góp trực tiếp vào sự căn chỉnh tốt hơn trong không gian mức token. Đối với các nhiệm vụ mức token như NER và gán nhãn POS, căn chỉnh ở mức token có thể có lợi hơn. Do đó, chúng tôi đề xuất một mục tiêu căn chỉnh mức token tiếp tục khuyến khích mô hình căn chỉnh các biểu diễn của các từ gốc và chuyển chữ. Chúng tôi thích ứng mục tiêu mô hình hóa ngôn ngữ dịch thuật được giới thiệu bởi Conneau và Lample (2019), tương đương với việc áp dụng mục tiêu MLM trên một cặp câu song ngữ được nối liền.

Cụ thể, với một cặp câu (X^orig_i, X^latn_i), chúng tôi áp dụng mục tiêu MLM trên chuỗi được nối liền X^orig_i ⊕ X^latn_i hoặc X^latn_i ⊕ X^orig_i, trong đó thứ tự nối liền được chọn ngẫu nhiên trong quá trình huấn luyện. Trực giác là để dự đoán một token bị che trong câu gốc, mô hình có thể chú ý đến các token xung quanh trong chữ viết gốc hoặc chuyển chữ của chúng và ngược lại. Điều này khuyến khích mô hình căn chỉnh các biểu diễn trong chữ viết gốc và chữ Latin. Chúng tôi gọi mục tiêu này là mô hình hóa ngôn ngữ chuyển chữ (TLM) và tổn thất là L_TLM.

Mục tiêu huấn luyện tổng thể kết hợp các mục tiêu mô hình hóa ngôn ngữ có mặt nạ, căn chỉnh mức câu, và căn chỉnh mức token:

L = L^orig_MLM + L^latn_MLM + L_SEQ + L_TLM

## 4 Thí Nghiệm

### 4.1 Thiết Lập Chung

Chúng tôi sử dụng mô hình Glot500 (ImaniGooghari et al., 2023), một mô hình mã hóa đa ngôn ngữ chỉ mã hóa tiên tiến được tiền huấn luyện trên hơn 500 ngôn ngữ, làm mô hình nguồn cho tất cả các thí nghiệm. Chúng tôi tinh chỉnh Glot500 trên hai nhóm ngôn ngữ sử dụng phương pháp căn chỉnh sau huấn luyện dựa trên chuyển chữ được đề xuất. Các ngôn ngữ cho mỗi nhóm được chọn dựa trên các đặc điểm khu vực để chúng có sự trùng lặp từ vựng ở các mức độ khác nhau và bao phủ các chữ viết khác nhau. Sau đó chúng tôi đánh giá hai mô hình kết quả trên một số nhiệm vụ hạ nguồn theo cách chuyển giao đa ngôn ngữ không cần ví dụ. Ngoài thiết lập chuyển giao tiêu chuẩn với tiếng Anh làm ngôn ngữ nguồn, chúng tôi cũng đánh giá khả năng chuyển giao của mô hình với ba ngôn ngữ nguồn khác có chữ viết khác nhau cho mỗi nhóm ngôn ngữ.

### 4.2 Ngôn Ngữ, Dữ Liệu và Mô Hình

Hai nhóm ngôn ngữ được đặt tên là Mediterranean-Amharic-Farsi và South+East Asian Languages. Chúng tôi hình dung phân bố địa lý của các ngôn ngữ được chọn trong mỗi nhóm trong Hình 2. Các ngôn ngữ trong mỗi nhóm được nói trong các khu vực liền kề, và có lịch sử ảnh hưởng ngôn ngữ lâu dài giữa chúng. Ví dụ, tiếng Ả Rập đã có tiếp xúc rộng rãi với các ngôn ngữ như tiếng Thổ Nhĩ Kỳ và tiếng Ba Tư (Versteegh, 2001). Dữ liệu cho mỗi ngôn ngữ được lấy mẫu từ tập dữ liệu huấn luyện Glot500-c (ImaniGooghari et al., 2023). Chúng tôi lấy mẫu 10% dữ liệu có sẵn cho mỗi ngôn ngữ, hoặc tối thiểu 10k câu, tùy theo cái nào lớn hơn. Dữ liệu sau đó được chuyển chữ thành chữ Latin bằng Uroman (Hermjakob et al., 2018). Bảng 1 cho thấy các ngôn ngữ của mỗi nhóm và số lượng câu được lấy mẫu. Tổng cộng, Mediterranean-Amharic-Farsi bao gồm 10 ngôn ngữ, 5 chữ viết, và khoảng 16M câu, trong khi South+East Asian Languages bao gồm 10 ngôn ngữ, 7 chữ viết, và khoảng 4M câu. Chúng tôi tinh chỉnh Glot500 sử dụng phương pháp căn chỉnh của chúng tôi trên mỗi nhóm riêng biệt. Sau đó chúng tôi chọn checkpoint tốt nhất cho mỗi nhóm bằng cách xác thực hiệu suất của các checkpoint trên tập dữ liệu truy xuất câu Tatoeba (Artetxe and Schwenk, 2019), chứa 1000 câu căn chỉnh tiếng Anh. Chúng tôi tính độ chính xác truy xuất top-10 dựa trên độ tương tự cosine của các embedding ngữ cảnh lớp thứ 8 được trung bình hóa. Checkpoint tốt nhất cho mỗi nhóm được coi là mô hình căn chỉnh cuối cùng của chúng tôi.

### 4.3 Nhiệm Vụ Hạ Nguồn

Chúng tôi đánh giá mô hình căn chỉnh kết quả cho mỗi nhóm trên một số nhiệm vụ hạ nguồn (được mô tả dưới đây). Đối với mỗi nhiệm vụ, chúng tôi sử dụng bốn ngôn ngữ nguồn khác nhau, tiếng Anh và ba ngôn ngữ nguồn khác thuộc cùng nhóm sử dụng các chữ viết khác nhau. Việc đánh giá được thực hiện theo cách chuyển giao đa ngôn ngữ không cần ví dụ: chúng tôi tinh chỉnh các mô hình trên tập huấn luyện của một ngôn ngữ nguồn cho trước, chọn checkpoint tốt nhất, và tính điểm F1 macro (trừ SR-B trong đó chúng tôi tính độ chính xác truy xuất top-10 trung bình) trên các tập kiểm tra của các ngôn ngữ còn lại trong mỗi nhóm. Lưu ý rằng không cần bước huấn luyện nào cho nhiệm vụ truy xuất: chúng tôi trực tiếp sử dụng các câu từ ngôn ngữ nguồn làm truy vấn và truy xuất các câu tương tự nhất trong các ngôn ngữ đích. Đối với các nhiệm vụ yêu cầu tinh chỉnh bổ sung, chúng tôi báo cáo kết quả được trung bình hóa trên năm seed khác nhau. Các nhiệm vụ hạ nguồn như sau (xem chi tiết trong §B):

**SR-B** Một tập dữ liệu truy xuất câu trong đó các câu song song đến từ Kinh Thánh. Chúng tôi tính độ chính xác truy xuất top-10 trên 500 câu song song theo ImaniGooghari et al. (2023).

**Taxi1500** Một tập dữ liệu phân loại văn bản đa ngôn ngữ bao phủ hơn 1500 ngôn ngữ với các câu từ 6 chủ đề (Ma et al., 2023).

**SIB200** Một tập dữ liệu phân loại văn bản đa ngôn ngữ bao phủ hơn 200 ngôn ngữ cho 7 chủ đề (Adelani et al., 2024).

**NER** Một tập dữ liệu gán nhãn chuỗi đa ngôn ngữ cho nhận dạng thực thể có tên (Pan et al., 2017) bao gồm các bài báo được chú thích với 7 thẻ khác nhau, ví dụ: vị trí, người, v.v.

**POS** Một tập dữ liệu gán nhãn chuỗi đa ngôn ngữ cho gán nhãn từ loại (de Marneffe et al., 2021) bao gồm các câu được chú thích với 17 thẻ POS phổ quát, ví dụ: NOUN, ADJ, v.v.

## 5 Kết Quả và Phân Tích

Chúng tôi báo cáo kết quả của Glot500 và các mô hình căn chỉnh sau huấn luyện của chúng tôi trên các nhiệm vụ hạ nguồn trong Bảng 2 cho Mediterranean-Amharic-Farsi và trong Bảng 3 cho South+East Asian Languages. Nhìn chung, các mô hình căn chỉnh của chúng tôi vượt trội hơn Glot500 trên các nhiệm vụ khác nhau cho cả hai nhóm ngôn ngữ, thỉnh thoảng có một chút giảm hiệu suất cho một số tổ hợp ngôn ngữ nguồn-đích nhất định. Dưới đây, chúng tôi nêu bật những phát hiện quan trọng từ các kết quả.

**Hiệu suất theo nhóm khác nhau một chút.** Bắt đầu với Mediterranean-Amharic-Farsi, chúng tôi quan sát thấy rằng mô hình căn chỉnh sau huấn luyện thường vượt trội hơn Glot500 trên tất cả các nhiệm vụ hạ nguồn. Nhiệm vụ SR-B cho thấy sự cải thiện đáng kể nhất, với mô hình căn chỉnh đạt được, trung bình, hơn 20% độ chính xác cao hơn so với Glot500 cho tất cả các ngôn ngữ nguồn. Đối với các nhiệm vụ khác, mô hình căn chỉnh cũng thể hiện sự cải thiện nhất quán, mặc dù nhỏ hơn, với Glot500 thỉnh thoảng vượt trội hơn mô hình căn chỉnh sau huấn luyện cho các cặp ngôn ngữ nguồn-đích cụ thể. Tuy nhiên, chúng tôi quan sát thấy hiệu suất hỗn hợp hơn cho South+East Asian Languages, đặc biệt là cho các nhiệm vụ gán nhãn chuỗi, với các mô hình căn chỉnh hoạt động tệ hơn so với Glot500 khi chuyển giao từ hơn một nửa số ngôn ngữ nguồn. Chúng tôi giả thuyết rằng sự giảm hiệu suất này chủ yếu là do quá trình chuyển chữ, làm mất các sắc thái ngữ nghĩa và ngữ cảnh và gây ra nhiều sự mơ hồ ở mức token hơn cho hầu hết các ngôn ngữ (Amrhein and Sennrich, 2020; Liu et al., 2024a). Sự mơ hồ này làm cho việc căn chỉnh mức token khó khăn hơn. Ngược lại, mô hình căn chỉnh đạt được sự cải thiện nhất quán trong NER và POS cho Mediterranean-Amharic-Farsi, trong đó ít sự mơ hồ mức token hơn được đưa vào vì các ngôn ngữ ban đầu được viết bằng chữ viết ngữ âm, mà chữ Latin cũng thuộc về.

**Ngôn ngữ nguồn quan trọng.** Chúng tôi quan sát thấy rằng hiệu suất có thể thay đổi đáng kể cho cả hai nhóm tùy thuộc vào ngôn ngữ nguồn được sử dụng để chuyển giao. Hiện tượng này xảy ra do sự tương tự về chữ viết và ngôn ngữ giữa các ngôn ngữ nguồn và đích cụ thể. Nói chung, chuyển giao từ các ngôn ngữ có nhiều tài nguyên trong nhóm hoạt động tốt hơn so với chuyển giao từ tiếng Anh. Lấy nhiệm vụ SR-B làm ví dụ, đối với Mediterranean-Amharic-Farsi, hiệu suất tốt nhất đạt được khi chuyển giao từ tiếng Farsi. Đối với South+East Asian Languages, hiệu suất tốt nhất đạt được khi chuyển giao từ tiếng Hàn. Các nhiệm vụ phân loại văn bản thường cho thấy ít biến đổi hơn về hiệu suất, mặc dù chuyển giao từ tiếng Hebrew đạt hiệu suất tệ nhất cho Mediterranean-Amharic-Farsi trong Taxi1500. Đối với các nhiệm vụ NER và POS, chuyển giao từ tiếng Ả Rập và tiếng Hebrew đạt hiệu suất tốt nhất cho Mediterranean-Amharic-Farsi, trong khi chuyển giao từ tiếng Trung đạt hiệu suất tốt nhất cho cả hai nhiệm vụ trong South+East Asian Languages. Tuy nhiên, so sánh các mô hình căn chỉnh của chúng tôi với Glot500, hiệu suất thường cải thiện cho hầu hết các ngôn ngữ nguồn. Điều này cho thấy rằng phương pháp căn chỉnh sau huấn luyện dựa trên chuyển chữ được đề xuất của chúng tôi cải thiện hiệu quả sự căn chỉnh giữa các ngôn ngữ có liên quan và tiếp tục tăng cường hiệu suất khi một ngôn ngữ nguồn thích hợp được chọn.

### 5.1 Nghiên Cứu Loại Bỏ

Chúng tôi thực hiện một nghiên cứu loại bỏ để điều tra tác động của các mục tiêu huấn luyện khác nhau đối với hiệu suất của các mô hình căn chỉnh sau huấn luyện. Bắt đầu từ mô hình Glot500 cơ sở, chúng tôi áp dụng các kết hợp khác nhau của các mục tiêu huấn luyện: mô hình hóa ngôn ngữ có mặt nạ (MLM), căn chỉnh mức câu (SEQ), và căn chỉnh mức token (TLM). Có tổng cộng bốn kết hợp khác nhau (MLM+SEQ là mục tiêu huấn luyện của TRANSLICO (Liu et al., 2024a)). Lưu ý rằng chúng tôi không xem xét biến thể thiếu mục tiêu MLM vì MLM quan trọng để bảo toàn khả năng mô hình hóa ngôn ngữ. Chúng tôi báo cáo hiệu suất trung bình của việc sử dụng bốn ngôn ngữ nguồn khác nhau trên tất cả các ngôn ngữ đích cho mỗi nhóm ngôn ngữ trong Bảng 4 và Bảng 5.

Chỉ riêng mục tiêu MLM đã cải thiện một chút mô hình Glot500 cơ sở. Chúng tôi giả thuyết điều này là do lợi ích của việc chuyên biệt hóa mô hình cho một nhóm nhỏ các ngôn ngữ. Khi mục tiêu căn chỉnh mức câu (SEQ) được bao gồm, hiệu suất thường được cải thiện thêm so với biến thể MLM, đặc biệt là cho nhiệm vụ truy xuất. Điều này không đáng ngạc nhiên vì SEQ cải thiện sự căn chỉnh mức câu. Khi thay vào đó mục tiêu căn chỉnh mức token (TLM) được bao gồm, có một sự cải thiện nhỏ về hiệu suất cho hầu hết các nhiệm vụ so với mục tiêu MLM+SEQ, trừ nhiệm vụ truy xuất. Chúng tôi cũng quan sát thấy rằng các nhiệm vụ phân loại văn bản cho thấy ít biến đổi nhất về hiệu suất cho hầu hết các ngôn ngữ nguồn. Điều này đặc biệt đúng cho SIB200, có vẻ là nhiệm vụ đơn giản nhất cho các mô hình.

Mục tiêu hoàn chỉnh của chúng tôi (MLM+SEQ+TLM) thường hoạt động tốt hơn so với các mô hình khác bằng cách kết hợp lợi ích căn chỉnh mức câu và token. Đối với Mediterranean-Amharic-Farsi, mặc dù MLM+SEQ+TLM hoạt động ngang bằng với mục tiêu MLM+SEQ trên NER, nó đạt hiệu suất tốt hơn trên POS. Tương tự, mục tiêu huấn luyện hoàn chỉnh của chúng tôi vượt trội hơn MLM+SEQ trên cả NER và POS cho South+East Asian Languages. Khi so sánh hiệu suất của mục tiêu huấn luyện đầy đủ với MLM+TLM, chúng tôi quan sát thấy hiệu suất bằng nhau trên các nhiệm vụ khác nhau, trừ nhiệm vụ truy xuất, trong đó mục tiêu huấn luyện đầy đủ vượt trội rõ ràng hơn MLM+TLM. Mặc dù mục tiêu SEQ là quan trọng nhất để cải thiện nhiệm vụ truy xuất, chúng tôi cũng quan sát thấy một sự gia tăng hiệu suất trong nhiệm vụ truy xuất khi TLM được bao gồm. Điều này cho thấy rằng phương pháp căn chỉnh sau huấn luyện của chúng tôi, với TLM, cải thiện hiệu quả cả sự căn chỉnh mức câu và token.

## 6 Kết Luận

Trong nghiên cứu này, chúng tôi đề xuất một phương pháp sau huấn luyện dựa trên chuyển chữ bao gồm cả các mục tiêu mức câu và token để cải thiện sự căn chỉnh đa ngôn ngữ của mPLM và do đó tăng cường hiệu suất chuyển giao đa ngôn ngữ của chúng. Chúng tôi áp dụng phương pháp sau huấn luyện của mình để tinh chỉnh Glot500 trên hai nhóm ngôn ngữ chia sẻ các đặc điểm khu vực và có sự trùng lặp từ vựng rộng rãi. Các thí nghiệm rộng rãi của chúng tôi sử dụng các ngôn ngữ nguồn khác nhau cho thấy rằng các mô hình căn chỉnh của chúng tôi liên tục vượt trội hơn mô hình Glot500 gốc. Đặc biệt, phương pháp của chúng tôi tăng cường sự căn chỉnh và chuyển giao đa ngôn ngữ giữa các ngôn ngữ có liên quan. Chúng tôi cũng phân tích tác động của các mục tiêu huấn luyện khác nhau và cho thấy rằng các mục tiêu căn chỉnh mức câu và token đều quan trọng để đạt được hiệu suất tốt nhất trên các nhiệm vụ khác nhau.

## Hạn Chế

Mặc dù mPLM được tinh chỉnh với phương pháp của chúng tôi, trong đó văn bản chuyển chữ được sử dụng như một đầu vào phụ trợ, mPLM chỉ thấy các chuyển chữ Latin trong giai đoạn tiền huấn luyện của nó. Điều này có thể hạn chế hiệu suất của các mô hình căn chỉnh sau huấn luyện, đặc biệt là cho các ngôn ngữ có chữ viết phức tạp. Một phần mở rộng của nghiên cứu này có thể mở rộng từ vựng để bao gồm các subword từ chuyển chữ Latin như được thực hiện bởi Liu et al. (2024b) trước khi tinh chỉnh hoặc tiếp tục tiền huấn luyện mô hình trên văn bản chuyển chữ để các mô hình có thể hiệu quả hơn trong việc mô hình hóa dữ liệu chuyển chữ.

Chúng tôi tiếp tục bị hạn chế bởi quá trình chuyển chữ, chỉ nắm bắt một phần thông tin ngữ âm và ngữ nghĩa của văn bản gốc, đặc biệt là cho các ngôn ngữ có chữ viết khác biệt đáng kể so với chữ Latin. Điều này dẫn đến mất thông tin trong quá trình căn chỉnh, có thể tác động tiêu cực đến hiệu suất của các mô hình căn chỉnh sau huấn luyện. Nghiên cứu tương lai có thể cải thiện quá trình chuyển chữ để nắm bắt tốt hơn các tính chất ngôn ngữ của văn bản gốc.

Nghiên cứu tương lai cũng có thể khám phá các mục tiêu căn chỉnh mức token rõ ràng, chẳng hạn như tối thiểu hóa khoảng cách L2 giữa các biểu diễn cặp từ/subword như được thực hiện bởi Cao et al. (2020). Tuy nhiên, loại căn chỉnh này không thể được áp dụng trực tiếp cho nhiều ngôn ngữ trong nghiên cứu của chúng tôi. Đối với nhóm South+East Asian Languages, hầu hết các chữ viết ngôn ngữ đều là biểu ý hoặc không sử dụng ranh giới từ, khiến việc cung cấp tín hiệu giám sát rõ ràng cho căn chỉnh mức token trở nên thách thức, vì phần lớn thông tin này bị mất trong quá trình chuyển chữ.

## Lời Cảm Ơn

Nghiên cứu này được tài trợ bởi Deutsche Forschungsgemeinschaft (dự án SCHU 2246/14-1) và Hội đồng Nghiên cứu Châu Âu (NonSequeToR, grant #740516). Chúng tôi muốn cảm ơn Leibniz Supercomputing Center (LRZ) và Munich Center for Machine Learning (MCML) đã cung cấp tài nguyên tính toán.

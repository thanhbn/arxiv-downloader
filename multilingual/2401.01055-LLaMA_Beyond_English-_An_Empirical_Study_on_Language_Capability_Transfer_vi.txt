LLaMA Vượt Ra Ngoài Tiếng Anh: Một Nghiên Cứu Thực Nghiệm về Chuyển Giao Khả Năng Ngôn Ngữ

Jun Zhao*, Zhihao Zhang*, Luhui Gao, Qi Zhang†, Tao Gui, Xuanjing Huang
1Trường Khoa học Máy tính, Đại học Phúc Đán
{zhaoj19,zhangzhihao19,qz,tgui }@fudan.edu.cn

Tóm tắt
Trong thời gian gần đây, những tiến bộ đáng kể đã được chứng kiến trong các mô hình ngôn ngữ lớn (LLMs), được minh họa bởi ChatGPT, thể hiện sự thành thạo đáng chú ý trên một loạt các tác vụ phức tạp. Tuy nhiên, nhiều LLMs chính thống (ví dụ LLaMA) được tiền huấn luyện trên tập dữ liệu chiếm ưu thế bằng tiếng Anh, điều này hạn chế hiệu suất của chúng trong các ngôn ngữ khác không phải tiếng Anh. Trong bài báo này, chúng tôi tập trung vào cách chuyển giao hiệu quả các khả năng tạo ngôn ngữ và tuân theo hướng dẫn sang một ngôn ngữ không phải tiếng Anh. Để trả lời câu hỏi này, chúng tôi tiến hành một cuộc điều tra thực nghiệm mở rộng dựa trên LLaMA, tích lũy hơn 1440 giờ GPU. Chúng tôi phân tích tác động của các yếu tố chính như mở rộng từ vựng, tiền huấn luyện thêm, và điều chỉnh hướng dẫn đối với việc chuyển giao. Để đánh giá chính xác mức độ kiến thức của mô hình, chúng tôi sử dụng bốn điểm chuẩn kiểm tra tiêu chuẩn được sử dụng rộng rãi: C-Eval, MMLU, AGI-Eval, và GAOKAO-Bench. Hơn nữa, một đánh giá toàn diện về chất lượng phản hồi của mô hình được thực hiện, xem xét các khía cạnh như độ chính xác, tính lưu loát, tính thông tin, tính nhất quán logic, và tính vô hại, dựa trên LLM-Eval, một điểm chuẩn bao gồm các tác vụ hướng dẫn từ 17 danh mục đa dạng. Kết quả đánh giá của chúng tôi cho thấy hiệu suất có thể so sánh với các mô hình chuyển giao tiên tiến có thể đạt được với ít hơn 1% dữ liệu tiền huấn luyện, cả về mặt căn chỉnh kiến thức và chất lượng phản hồi. Hơn nữa, kết quả thực nghiệm trên mười ba ngôn ngữ ít tài nguyên cũng thể hiện các xu hướng tương tự. Chúng tôi dự đoán rằng các kết luận được tiết lộ bởi các thử nghiệm sẽ hỗ trợ cộng đồng trong việc phát triển các LLMs không phải tiếng Anh.

Giới thiệu
Trong nhiều thập kỷ, các nhà nghiên cứu trong Xử lý Ngôn ngữ Tự nhiên (NLP) đã khám phá các nguyên tắc cơ bản của trí tuệ (Bubeck et al. 2023). Những tiến bộ gần đây trong các mô hình ngôn ngữ lớn (LLMs) dường như đã tiết lộ một tia hy vọng. Nhờ vào quy mô chưa từng có của kích thước mô hình và dữ liệu huấn luyện, nhiều LLMs như ChatGPT (OpenAI 2022), PaLM (Anil et al. 2023), LLaMA (Touvron et al. 2023a), và các mô hình khác đã xuất hiện với khả năng mạnh mẽ trong suy luận (Cobbe et al. 2021), lập kế hoạch (Huang et al. 2022), và học từ kinh nghiệm (Dong et al. 2023) ở mức độ bằng hoặc vượt qua con người. Những khả năng tổng quát này cũng cung cấp nền tảng cho LLMs để giải quyết các nhiệm vụ phức tạp trong thế giới thực, chẳng hạn như hoàn thành thành công toàn bộ Kỳ thi Luật sư Thống nhất (UBE) (Katz et al. 2023) hoặc viết mã dựa trên hướng dẫn ngôn ngữ tự nhiên (StabilityAI 2023).

Nhiều LLMs nổi tiếng có khả năng hiểu đầu vào và tạo ra phản hồi trên các ngôn ngữ khác nhau, nhờ vào việc tiền huấn luyện trên một hỗn hợp đa dạng của tập dữ liệu từ nhiều ngôn ngữ. Tuy nhiên, do sự phân bố không cân bằng của tài nguyên ngôn ngữ, việc thu thập dữ liệu huấn luyện mở rộng cho tất cả các ngôn ngữ là gần như không thể (Ranta và Goutte 2021). Lấy LLM đại diện BLOOM (Scao et al. 2023) làm ví dụ, nó đã được tiền huấn luyện trên 46 ngôn ngữ tự nhiên. Tuy nhiên, con số này chỉ chiếm 0.66% trong số khoảng 7,000 ngôn ngữ hiện đang được sử dụng. Hơn nữa, trong tập dữ liệu của 46 ngôn ngữ này, tồn tại sự mất cân bằng cực kỳ, với các văn bản tiếng Anh có tài nguyên cao nhiều hơn 2.8 triệu lần so với ngôn ngữ Chitumbuka có tài nguyên thấp. Đây không phải là trường hợp đơn lẻ. Một mô hình ngôn ngữ khác được thảo luận rộng rãi, LLaMA, đã được tiền huấn luyện chủ yếu trên tập dữ liệu chiếm ưu thế bằng tiếng Anh, được bổ sung với dữ liệu hạn chế từ 20 ngôn ngữ liên quan sử dụng chữ viết Latin và Cyrillic. Kết quả là, LLaMA thể hiện hiệu suất kém hơn trong các bối cảnh liên quan đến ngôn ngữ không phải tiếng Anh mà nó chưa trải qua đủ huấn luyện. Một số nhà nghiên cứu thu thập dữ liệu quy mô lớn cho các ngôn ngữ cụ thể quan tâm và huấn luyện lại một LLM (Team 2023a). Tuy nhiên, điều này không thể tránh khỏi dẫn đến chi phí tính toán và thu thập dữ liệu cao, không phù hợp cho các ngôn ngữ ít tài nguyên. Trong khi Cui, Yang, và Yao (2023b) mở rộng từ vựng gốc và tiền huấn luyện thêm LLaMA với 30B token tiếng Trung bằng LoRA (Hu et al. 2021), báo cáo kết quả đầy hứa hẹn. Tuy nhiên, một cuộc điều tra hệ thống chi tiết về quá trình chuyển giao vẫn còn thiếu.

Trong công việc này, chúng tôi tiến thêm một bước để có được sự hiểu biết toàn diện về chuyển giao khả năng ngôn ngữ trong LLMs. Như thể hiện trong hình 1, chúng tôi điều tra thực nghiệm một số khía cạnh chính dựa trên LLaMA:

(1) Tác động của mở rộng từ vựng đối với chuyển giao.
Chúng tôi thấy rằng tiền huấn luyện thêm với 0.5 tỷ token tiếng Trung trên từ vựng gốc vượt trội đáng kể so với hiệu suất trên từ vựng mở rộng, mặc dù từ vựng sau đã được tiền huấn luyện thêm trên hơn 30 tỷ token. Điều này cho thấy mở rộng từ vựng có thể không phải là lựa chọn phù hợp cho tiền huấn luyện gia tăng quy mô nhỏ ở mức hàng chục tỷ.

(2) Quy mô huấn luyện cần thiết cho chuyển giao hiệu quả.
Chúng tôi thấy rằng tiền huấn luyện thêm tiếng Trung với 100 tỷ token trở xuống là không đủ để cải thiện đáng kể mức độ kiến thức của LLaMA. Tuy nhiên, việc nâng cao chất lượng phản hồi của LLaMA (tức là khả năng tạo ngôn ngữ), chỉ cần hàng trăm nghìn dữ liệu hướng dẫn thay vì tiền huấn luyện thêm quy mô lớn.

(3) Ảnh hưởng của huấn luyện chuyển giao đối với khả năng tiếng Anh gốc.
Chúng tôi thấy rằng việc dựa vào duy nhất tập dữ liệu tiếng Trung cho huấn luyện chuyển giao làm suy giảm đáng kể khả năng tiếng Anh gốc của LLaMA, một mối quan tâm được giảm thiểu hiệu quả thông qua huấn luyện chung đa ngôn ngữ.

Những phát hiện nêu trên cho phép chúng tôi chuyển giao khả năng tạo ngôn ngữ và tuân theo hướng dẫn của LLaMA sang các ngôn ngữ không phải tiếng Anh với chi phí tối thiểu. Dựa trên kết quả đánh giá từ bốn điểm chuẩn kiểm tra tiêu chuẩn được sử dụng rộng rãi (C-Eval, GAOKAO-Bench, MMLU, AGI-Eval) và một điểm chuẩn đánh giá hướng dẫn LLM-Eval, chúng tôi đạt được mức độ kiến thức và chất lượng phản hồi có thể so sánh với LLaMA Trung Quốc Mở tiên tiến, trong khi sử dụng ít hơn 1% dữ liệu huấn luyện. Hơn nữa, các thử nghiệm mở rộng trên 13 ngôn ngữ ít tài nguyên khác cũng thể hiện xu hướng tương tự. Chúng tôi mong muốn kết quả thực nghiệm và phân tích trong bài báo này sẽ cung cấp sự hỗ trợ và hướng dẫn cho cộng đồng trong việc xây dựng các LLMs không phải tiếng Anh.

Bối cảnh và Tổng quan
Trong phần con này, chúng tôi trước tiên trình bày các bước thiết yếu để phát triển một LLM tuân theo hướng dẫn. Tiếp theo, chúng tôi xem xét các thực hành phổ biến về ngoại suy mô hình này sang một ngôn ngữ không phải tiếng Anh và cung cấp tổng quan về nghiên cứu thực nghiệm của chúng tôi được thực hiện cho việc ngoại suy mô hình.

Bước 1: Tiền huấn luyện để thu được khả năng ngôn ngữ và kiến thức
Như một nguồn quan trọng của khả năng nền tảng cho một LLM, tiền huấn luyện nhằm dự đoán token tiếp theo dựa trên các chuỗi tiền tố. Chính thức, cho một tập dữ liệu lớn D, mục tiêu huấn luyện là tối thiểu hóa mất mát sau:

Lpretrain = ∑x∈D ∑i logpθ(xi|x1, ..., xi−1), (1)

trong đó x={x1, ..., xn} ký hiệu một chuỗi token đầu vào.

Bằng cách tiền huấn luyện trên dữ liệu văn bản khổng lồ từ hàng tỷ đến hàng nghìn tỷ token, LLMs có khả năng nắm bắt các cấu trúc ngôn ngữ phức tạp, ngữ nghĩa, và mối quan hệ ngữ cảnh, từ đó thu được khả năng tạo ngôn ngữ mạnh mẽ. Ngoài ra, những LLMs này cũng học cách hiểu các khái niệm, sự thật, và mối liên hệ giữa chúng, dẫn đến sự hiểu biết rộng rãi về kiến thức thế giới.

Bước 2: Điều chỉnh hướng dẫn để căn chỉnh với ý định con người
Điều chỉnh hướng dẫn (SFT) nhằm nâng cao thêm khả năng của LLMs để tuân theo hướng dẫn. Dữ liệu huấn luyện của nó bao gồm nhiều cặp hướng dẫn-phản hồi. Mô hình cần học cách phản hồi chính xác theo hướng dẫn, thay vì chỉ tiếp tục từ văn bản trước đó. Chính thức, cho một tập dữ liệu hướng dẫn D′={(I, Y)}, trong đó I đại diện cho hướng dẫn nhiệm vụ và Y đại diện cho phản hồi mong muốn, mục tiêu huấn luyện của điều chỉnh hướng dẫn là tối thiểu hóa mất mát sau:

Lins = −logpθ(Y|I), (2)

Bằng cách điều chỉnh trên các nhiệm vụ hướng dẫn đa dạng, mô hình có thể hiểu và tuân theo hướng dẫn của con người tốt hơn, và tổng quát hóa cho các hướng dẫn chưa thấy.

Ngoại suy LLMs sang các ngôn ngữ không phải tiếng Anh
LLMs thu được khả năng tạo ngôn ngữ và tuân theo hướng dẫn thông qua tiền huấn luyện và điều chỉnh hướng dẫn. Tuy nhiên, tiếng Anh giữ vị trí thống trị trong lĩnh vực xử lý ngôn ngữ tự nhiên, sở hữu bộ sưu tập dữ liệu văn bản phong phú nhất từ các lĩnh vực khác nhau. LLMs được huấn luyện trên tập dữ liệu chiếm ưu thế bằng tiếng Anh thể hiện hiệu suất kém hơn trên các ngôn ngữ khác không phải tiếng Anh. Ngoại suy LLMs sang các ngôn ngữ không phải tiếng Anh đặt ra một thách thức nghiên cứu có giá trị cao. Các phương pháp ngoại suy phổ biến bao gồm ba bước sau: (1) mở rộng từ vựng để thêm token của ngôn ngữ đích, và do đó nâng cao khả năng biểu đạt mã hóa cho ngôn ngữ đó. (2) tiền huấn luyện thêm để chuyển giao khả năng tạo ngôn ngữ của LLMs sang ngôn ngữ đích. Quy mô huấn luyện cần thiết cho bước này thường ở mức hàng tỷ token, ít hơn đáng kể so với hàng nghìn tỷ token cần thiết để huấn luyện từ đầu. (3) tiến hành SFT trong ngôn ngữ đích để chuyển giao khả năng tuân theo hướng dẫn của LLMs.

Bài báo này tiến hành một nghiên cứu thực nghiệm toàn diện về ba bước nêu trên, so sánh sự khác biệt hiệu suất của LLMs trước và sau khi mở rộng từ vựng, và dưới các quy mô tiền huấn luyện và SFT khác nhau. Nó phân tích tính cần thiết của mở rộng từ vựng và quy mô huấn luyện cần thiết cho chuyển giao hiệu quả.

Thiết lập Thực nghiệm
Bài báo này nhằm khám phá cách chuyển giao hiệu quả các khả năng tạo ngôn ngữ và tuân theo hướng dẫn sang một ngôn ngữ không phải tiếng Anh. Với tài nguyên ngôn ngữ phong phú có sẵn trong tiếng Trung, có thể tiến hành nghiên cứu thực nghiệm toàn diện và sâu sắc. Do đó, các thí nghiệm và phân tích của chúng tôi bắt đầu với tiếng Trung làm điểm khởi đầu, và các hiện tượng quan sát được tiếp tục được xác nhận trên hơn mười ngôn ngữ ít tài nguyên. Trong phần này, chúng tôi trình bày các tập dữ liệu, mô hình, và phương pháp đánh giá được sử dụng trong các thí nghiệm của chúng tôi.

Mô hình
Để tránh tiền huấn luyện lặp lại quy mô lớn không cần thiết, chúng tôi sử dụng các mô hình nguồn mở được huấn luyện trên các quy mô khác nhau của tập dữ liệu tiếng Trung. Trong số này, LLaMA và LLaMA2 đóng vai trò là các checkpoint mà không trải qua tiền huấn luyện tiếng Trung rõ ràng, trong khi Chinese LLaMA và Chinese LLaMA2 được coi là các checkpoint với tiền huấn luyện tiếng Trung 30 tỷ token. Quy mô đạt 100 tỷ token cho Open Chinese LLaMA. Chúng tôi sử dụng hiệu suất của các mô hình này làm tài liệu tham khảo để phân tích và so sánh.

LLaMA (Touvron et al. 2023a): LLaMA là một loạt mô hình nền tảng được phát triển bởi Meta AI, được huấn luyện trên tập dữ liệu công khai chiếm ưu thế bằng tiếng Anh. Tập dữ liệu bao gồm CommonCrawl, C4, mã Github, Wikipedia, Sách, và các bài báo ArXiv, lên tới khoảng 1.4 nghìn tỷ token. Trong số các nguồn này, Wikipedia bao gồm văn bản đa ngôn ngữ, đóng góp 4.5% tổng tập dữ liệu. Nó bao gồm 20 ngôn ngữ sử dụng chữ viết Latin hoặc Cyrillic. LLaMA đạt kết quả tiên tiến cho các mô hình nền tảng cùng kích thước. Ví dụ, LLaMA-13B với chỉ 13 tỷ tham số vượt trội so với GPT-3 175B tham số lớn hơn nhiều trên nhiều điểm chuẩn NLP. Chúng tôi xem xét LLaMA-7B và LLaMA-13B trong các thí nghiệm.

LLaMA2 (Touvron et al. 2023b): LLaMA2 là phiên bản nâng cấp và cải tiến của LLaMA. Những nâng cấp mà nó nhận được so với người tiền nhiệm bao gồm quy trình làm sạch dữ liệu mạnh mẽ hơn, một hỗn hợp mới của dữ liệu tiền huấn luyện công khai có sẵn tự hào với mức tăng 40% kích thước, độ dài ngữ cảnh tăng gấp đôi để cải thiện khả năng hiểu, và việc triển khai attention truy vấn nhóm để tăng hiệu quả suy luận. Những cải tiến này làm cho nó trở thành một công cụ mạnh mẽ hơn để giải quyết các nhiệm vụ hiểu ngôn ngữ nâng cao. Chúng tôi xem xét LLaMA2-7B trong các thí nghiệm.

Chinese LLaMA (Cui, Yang, và Yao 2023b): Chinese LLaMA là phần mở rộng của LLaMA gốc, được thiết kế để nâng cao khả năng hiểu và tạo văn bản tiếng Trung. Mục tiêu được đạt bằng cách tích hợp một tokenizer tiếng Trung được phát triển bằng SentencePiece. Tokenizer này, với kích thước từ vựng là 49,953, cho phép xử lý các ký tự tiếng Trung được cải thiện. Ngoài ra, nó sử dụng các kỹ thuật tinh chỉnh hiệu quả tham số (Hu et al. 2021) để giảm tiêu thụ bộ nhớ trong quá trình huấn luyện mô hình. Trong các thí nghiệm của chúng tôi, chúng tôi xem xét Chinese LLaMA 7B Plus, được huấn luyện trên tập dữ liệu khoảng 120GB kích thước, tương đương với khoảng 30 tỷ token tiếng Trung.

Chinese LLaMA2 (Cui, Yang, và Yao 2023a): Chinese LLaMA2 là phiên bản lặp lại nâng cao của Chinese LLaMA. Nó sử dụng cùng tập dữ liệu và dữ liệu huấn luyện như Chinese LLaMA, nhưng sử dụng mô hình nền tảng của LLaMA2. Hơn nữa, việc xây dựng từ vựng của phiên bản mới và triển khai mã của nó cũng đã được tối ưu hóa. Trong các thí nghiệm của chúng tôi, chúng tôi xem xét Chinese LLaMA2 7B được tiền huấn luyện trên 30 tỷ token tiếng Trung.

Open Chinese LLaMA (OpenLMLab 2023): Open Chinese LLaMA là phiên bản mở rộng quy mô lớn hơn của LLaMA gốc. Để nâng cao khả năng xử lý văn bản tiếng Trung của LLaMA, Open Chinese LLaMA trải qua tiền huấn luyện thêm trên tập dữ liệu bao gồm 100 tỷ token. Tập dữ liệu được tạo thành từ các văn bản thu thập từ internet và được làm sạch, cùng với một tập con dữ liệu tiếng Anh và mã được sử dụng bởi mô hình LLAMA gốc.

Tập dữ liệu
Để chuyển giao khả năng ngôn ngữ của LLaMA sang ngôn ngữ không phải tiếng Anh quan tâm, chúng tôi sử dụng hai tập dữ liệu hướng dẫn, cụ thể là BELLE và Bactrain-X, để huấn luyện. Tập dữ liệu trước được sử dụng trong các thí nghiệm liên quan đến tiếng Trung, trong khi tập dữ liệu sau được sử dụng cho các thí nghiệm liên quan đến các ngôn ngữ khác.

BELLE (Ji et al. 2023): BELLE là tập dữ liệu điều chỉnh hướng dẫn tiếng Trung quy mô lớn được phát triển bởi Lianjia Tech., chứa 1.5 triệu ví dụ tuân theo hướng dẫn. Chúng tôi đã loại bỏ dữ liệu trùng lặp và chất lượng thấp, cuối cùng giữ lại 950,000 ví dụ.

Bactrain-X (Li et al. 2023): Bactrian-X chứa hướng dẫn và phản hồi trên 52 ngôn ngữ để tạo thuận lợi cho điều chỉnh hướng dẫn đa ngôn ngữ. Nó được tạo bằng cách dịch 67K hướng dẫn tiếng Anh từ tập dữ liệu Alpaca-52k (Taori et al. 2023) và Dolly-15k (Conover et al. 2023) sang 51 ngôn ngữ, sau đó tạo phản hồi với ChatGPT.

Để đánh giá khách quan và toàn diện khả năng của mô hình, chúng tôi tiến hành đánh giá từ hai góc độ: chất lượng phản hồi và mức độ kiến thức. Đối với góc độ trước, chúng tôi sử dụng điểm chuẩn LLM-Eval và dịch nó sang các ngôn ngữ ít tài nguyên khác nhau để hỗ trợ đánh giá đa ngôn ngữ. Đối với góc độ sau, chúng tôi sử dụng bốn điểm chuẩn kiểm tra tiêu chuẩn được áp dụng rộng rãi: C-Eval, MMLU, AGI-Eval, và GAOKAO-Bench.

LLM-Eval (Zhang et al. 2023a): LLM-Eval là điểm chuẩn được xây dựng thủ công để đánh giá tuân theo hướng dẫn. Nó có 453 nhiệm vụ hướng dẫn từ 17 danh mục chính, bao gồm trả lời câu hỏi thực tế, đọc hiểu, tạo khung, viết lại đoạn văn, tóm tắt, giải quyết bài toán, suy luận, tạo thơ, lập trình, và nhiều hơn nữa.

C-Eval (Huang et al. 2023b): C-Eval là bộ đánh giá tiếng Trung với 13948 câu hỏi thi trên 52 môn học và 4 mức độ khó từ trung học đến thi nghề. Nó bao gồm STEM, nhân văn, khoa học xã hội và các chủ đề khác. C-Eval HARD là tập con của 8 môn toán và khoa học thách thức đòi hỏi suy luận nâng cao.

MMLU (Hendrycks et al. 2020): MMLU đo lường khả năng học và áp dụng kiến thức của LLM trên 57 môn học đa dạng bao gồm STEM, nhân văn, và khoa học xã hội. Kiểm tra bao gồm một loạt mức độ khó từ cơ bản đến chuyên nghiệp nâng cao.

AGI-Eval (Zhong et al. 2023): AGIEval sử dụng câu hỏi từ các bài kiểm tra tiêu chuẩn được hàng triệu người tham gia, bao gồm kỳ thi đại học, bài kiểm tra tuyển sinh trường luật, và kỳ thi tư cách nghề nghiệp. Nó có 19 nhiệm vụ bằng cả tiếng Anh và tiếng Trung.

Gaokao-Bench (Zhang et al. 2023b): GAOKAO-Bench sử dụng 2811 câu hỏi thi từ kỳ thi tuyển sinh đại học Trung Quốc (Gaokao) từ 2010-2022 bao gồm tất cả môn học. Nó có 1781 câu hỏi trắc nghiệm, 218 câu điền vào chỗ trống, và 812 câu hỏi mở trên toán, tiếng Trung, tiếng Anh, vật lý, v.v.

Giao thức Đánh giá
Đối với LLM-Eval, chúng tôi tuân theo thực hành của Zhang et al. (2023a), đánh giá chất lượng phản hồi của mô hình thông qua 5 mục chấm điểm: độ chính xác, tính lưu loát, tính thông tin, tính logic, và tính vô hại. Điểm cho mỗi khía cạnh từ 0 đến 3. Chúng tôi sử dụng lời nhắc được hiển thị trong Phụ lục để gửi hướng dẫn, phản hồi mô hình, và câu trả lời tham khảo cho GPT-4 để đánh giá tự động. Dựa trên kết quả được báo cáo bởi Zhang et al. (2023a), phương pháp đánh giá này cho thấy mức độ nhất quán cao với đánh giá của con người.

Đối với bốn điểm chuẩn kiểm tra tiêu chuẩn, chúng tôi tính toán thước đo độ chính xác cho phản hồi mô hình. Ngoài ra, chúng tôi tuân theo thực hành phổ biến là sử dụng cài đặt zero-shot cho AGI-Eval và GAOKAO-Bench, trong khi sử dụng cài đặt 5-shot cho C-Eval và MMLU.

Kết quả Chính
Tác động của Mở rộng Từ vựng đối với Chuyển giao
Khi chúng tôi nhằm nâng cao khả năng của LLM trong một ngôn ngữ cụ thể, mở rộng từ vựng là một cách tiếp cận trực quan hợp lý. Trong phần này, chúng tôi đánh giá tác động của mở rộng từ vựng thông qua điểm chuẩn LLM-Eval, và kết quả thực nghiệm được trình bày trong bảng 1. Ban đầu, chúng tôi thu thập một triệu câu tiếng Trung từ internet (khoảng 0.5 tỷ token) và tiền huấn luyện thêm LLaMA gốc mà không mở rộng từ vựng. Đáng ngạc nhiên, chúng tôi thấy mô hình này vượt trội đáng kể so với Chinese LLaMA mở rộng từ vựng, trên các cài đặt điều chỉnh hướng dẫn 1K, 5K, và 950K. Khám phá này kích thích tư duy, cho rằng Chinese LLaMA đã trải qua tiền huấn luyện thêm tiếng Trung trên 30 tỷ token, một khối lượng lớn hơn nhiều so với 0.5 tỷ token của chúng tôi. Hơn nữa, trong cài đặt 950K, chúng tôi bao gồm kết quả từ việc mở rộng từ vựng trên LLaMA gốc và huấn luyện nó với cùng 0.5 tỷ token, để giảm thiểu ảnh hưởng của sự khác biệt dữ liệu huấn luyện. Kết quả vẫn nhất quán. Điều này cho thấy mở rộng từ vựng không phải là lựa chọn thuận lợi trong quy mô huấn luyện hàng chục tỷ token. Trong khi chúng tôi không phủ nhận hiệu quả của mở rộng từ vựng trong các cài đặt liên quan đến tiền huấn luyện quy mô lớn hơn (chẳng hạn như hàng nghìn tỷ token), như được báo cáo trong các tài liệu khác (Team 2023b), điều này đã nghiêng về phía huấn luyện lại hơn là chuyển giao ngôn ngữ đơn thuần.

Quy mô Huấn luyện Cần thiết cho Chuyển giao Hiệu quả
Quy mô huấn luyện tạo thành một yếu tố quan trọng khác ảnh hưởng đến khả năng chuyển giao của LLM, bao gồm cả quy mô tiền huấn luyện và quy mô điều chỉnh hướng dẫn. Kết quả thực nghiệm được hiển thị trong bảng 1. Lấy ví dụ về LLaMA (với 10K, 100K, và 1M tiền huấn luyện thêm) và Open Chinese LLaMA, quy mô tiền huấn luyện thêm tiếng Trung tăng dần từ 0 đến 100 tỷ token. Dưới cài đặt điều chỉnh hướng dẫn 1K và 5K, chúng tôi quan sát thấy chất lượng phản hồi cải thiện dần với sự tăng quy mô tiền huấn luyện thêm. Tuy nhiên, khi quy mô dữ liệu điều chỉnh hướng dẫn tăng lên 950K, chúng tôi thấy không có sự khác biệt đáng kể trong chất lượng phản hồi giữa các mô hình. Do đó, chúng tôi giả định rằng tiền huấn luyện thêm nhiều hơn có thể tăng tốc việc căn chỉnh mô hình với hướng dẫn của con người, nhưng chỉ hàng chục tỷ trong quy mô huấn luyện là không đủ để cho phép mô hình nắm bắt một lượng kiến thức thế giới lớn hơn. Điều này dẫn đến sự hội tụ của chúng ở mức phản hồi tương tự. Nói cách khác, việc nâng cao chất lượng phản hồi chủ yếu xuất phát từ sự cải thiện trong sức mạnh tạo ngôn ngữ thay vì sự nâng cao trong mức độ kiến thức.

Để xác nhận quan điểm này, chúng tôi đánh giá mức độ kiến thức của mô hình trên bốn điểm chuẩn kiểm tra tiêu chuẩn được sử dụng rộng rãi. Như thể hiện trong Hình 2, LLaMA 7B, Chinese LLaMA 7B, và Open Chinese LLaMA 7B hoạt động tương đương trên C-eval, gaokao-bench, và agi-eval, cho thấy không có sự khác biệt đáng kể được gây ra bởi tiền huấn luyện thêm tiếng Trung. Đáng chú ý là mặc dù thiếu tiền huấn luyện thêm trong tiếng Trung, cả LLaMA2-7B và LLaMA-13B đều vượt trội so với Open Chinese LLaMA trên C-eval, MMLU, và AGI-Eval, cho thấy tiền huấn luyện cấp nghìn tỷ và kích thước mô hình lớn hơn thực sự có thể phục vụ như các con đường hiệu quả để nâng cao mức độ kiến thức mô hình.

Tình hình Khả năng Tiếng Anh Gốc
Một vấn đề khác mà chúng tôi quan tâm là liệu sự cải thiện trong khả năng tiếng Trung có tác động đến khả năng tiếng Anh hiện có hay không. Để giải quyết câu hỏi này, chúng tôi bổ sung thu thập 200,000 mẫu tiếng Trung từ internet và ngẫu nhiên trích xuất 200,000 mẫu tiếng Anh từ tập dữ liệu refinedweb (Penedo et al. 2023). Sử dụng các mẫu này, chúng tôi đánh giá độ bối rối tiếng Anh và độ bối rối tiếng Trung của các mô hình LLaMA được huấn luyện trên tập dữ liệu quy mô khác nhau, như mô tả trong bảng 2. Phát hiện của chúng tôi cho thấy với sự tăng quy mô tiền huấn luyện thêm, độ bối rối của các mô hình giảm đều đặn trong tiếng Trung, nhưng tăng đáng kể trong tiếng Anh. Điều này cho thấy việc nâng cao khả năng của mô hình chỉ thông qua một tập dữ liệu tiếng Trung duy nhất có giá phải trả là hy sinh khả năng tiếng Anh gốc.

Hơn nữa, chúng tôi tiến hành đánh giá độ bối rối cho Open Chinese LLaMA và thấy cả độ bối rối tiếng Trung và tiếng Anh đều thấp. Kết quả này không ngạc nhiên, cho rằng dữ liệu huấn luyện của nó kết hợp cả nội dung tiếng Trung và tiếng Anh, cho phép giảm độ bối rối tiếng Trung mà không tăng đáng kể độ bối rối tiếng Anh. Nhìn chung, việc dựa vào duy nhất tập dữ liệu tiếng Trung cho huấn luyện chuyển giao làm suy giảm đáng kể khả năng tiếng Anh gốc của LLaMA, một mối quan tâm được giảm thiểu hiệu quả thông qua huấn luyện chung đa ngôn ngữ.

Mở rộng Phân tích sang Nhiều Ngôn ngữ
Trong phần trước, các thí nghiệm của chúng tôi tập trung vào tiếng Trung. Để điều tra liệu các kết luận tương tự có thể được rút ra trong các ngôn ngữ khác không phải tiếng Anh, chúng tôi mở rộng thí nghiệm sang 13 ngôn ngữ ít tài nguyên. Để đảm bảo tính nhất quán đánh giá, chúng tôi dịch điểm chuẩn LLM-Eval sang 13 ngôn ngữ này và sử dụng các thước đo đánh giá tương tự. Như thể hiện trong bảng 3, có sự cải thiện đáng kể trong chất lượng phản hồi cho tất cả các ngôn ngữ ít tài nguyên với sự tăng dữ liệu SFT. Trong số các ngôn ngữ này, tiếng Ả Rập, tiếng Indonesia, và tiếng Việt thể hiện hiệu suất tốt nhất. Mặc dù tất cả mười ba ngôn ngữ đều là ít tài nguyên, ba ngôn ngữ này được sử dụng thường xuyên hơn (Scao et al. 2023). Kết quả là, LLaMA gặp chúng thường xuyên hơn (mặc dù tổng thể xuất hiện của chúng nhỏ so với tiếng Anh), cho phép mô hình nhanh chóng hiểu hướng dẫn trong các ngôn ngữ này. Điều này phù hợp với kết luận được rút ra trong phần trước.

Trong phần trước, chúng tôi quan sát thấy mở rộng từ vựng có tác động tiêu cực đến khả năng chuyển giao ngôn ngữ. Một giả thuyết khả dĩ là sự tồn tại của căn chỉnh ngữ nghĩa xuyên ngôn ngữ trong LLMs, mà việc mở rộng từ vựng có thể làm gián đoạn. Để xác nhận giả thuyết căn chỉnh này, chúng tôi tinh chỉnh LLaMA với tập dữ liệu 1k hướng dẫn và kiểm tra đầu ra của mô hình. Thú vị, chúng tôi quan sát thấy một tỷ lệ nhất định của các mẫu chuyển đổi mã. Như mô tả trong hình 3, phản hồi mô hình của các mẫu này bao gồm token từ nhiều ngôn ngữ và có tính mạch lạc về ngữ nghĩa. Chúng tôi đã quan sát thấy chuyển đổi mã không chỉ xảy ra trong quá trình chuyển giao khi tiếng Trung là ngôn ngữ đích, mà còn khi 13 ngôn ngữ ít tài nguyên khác là ngôn ngữ đích. Như thể hiện trong hình 4, tỷ lệ mẫu có chuyển đổi mã khoảng từ 2% đến 5%. Điều này cho thấy LLaMA có thể đã học được mối quan hệ căn chỉnh xuyên ngôn ngữ giữa các khái niệm trong quá trình tiền huấn luyện.

Công trình Liên quan
Khoảng cách Tài nguyên trong LLMs
Một trong những thách thức chính của LLMs là khoảng cách tài nguyên, vì chúng chủ yếu được tiền huấn luyện trên tập dữ liệu tiếng Anh và có quyền truy cập hạn chế vào dữ liệu từ các ngôn ngữ khác. Tiếng Anh thống trị lĩnh vực NLP như một ngôn ngữ có tài nguyên cực kỳ cao với dữ liệu văn bản thô nhiều nhất từ các lĩnh vực khác nhau, để lại rất ít trong số hơn 7000 ngôn ngữ của thế giới được đại diện trong lĩnh vực (Joshi et al. 2020). Điều này tạo ra sự chênh lệch trong khả năng của các mô hình ngôn ngữ để xử lý các ngôn ngữ khác nhau. Những phát hiện trước đây cho thấy LLMs gặp khó khăn trong việc hiểu và tạo văn bản không phải tiếng Anh, đặc biệt là trong các ngôn ngữ ít tài nguyên (Nguyen et al. 2023; Zhu et al. 2023; Huang et al. 2023a). Để giải quyết khoảng cách tài nguyên, một số giải pháp đã được đề xuất hoặc thực hiện bởi các nhà nghiên cứu và thực hành. Một giải pháp có thể là tăng lượng dữ liệu có sẵn từ các ngôn ngữ và lĩnh vực khác nhau, và làm cho nó có thể truy cập được để tiền huấn luyện và đánh giá LLMs (Lin et al. 2022; Chen et al. 2022; Cahyawijaya et al. 2023). Tuy nhiên, cách tiếp cận này phát sinh chi phí tính toán đáng kể và khoảng cách tài nguyên vẫn tồn tại. Thay vào đó, các mô hình ngôn ngữ đa ngôn ngữ được huấn luyện trên văn bản từ các ngôn ngữ khác nhau đồng thời, chẳng hạn như mBERT (Devlin et al. 2019) và XLM-R (Conneau et al. 2020a), đã được giới thiệu để thu hẹp khoảng cách hiệu quả.

Chuyển giao Xuyên ngôn ngữ
Các mô hình ngôn ngữ đa ngôn ngữ đã chứng minh mức độ cao của khả năng chuyển giao xuyên ngôn ngữ zero-shot hoặc few-shot trên một loạt rộng các tác vụ (Wu và Dredze 2019; Pires, Schlinger, và Garrette 2019; Winata et al. 2021b). Điều này có nghĩa là chúng có thể thu được khả năng ngôn ngữ từ dữ liệu có giám sát trong một ngôn ngữ và áp dụng nó cho ngôn ngữ khác mà không cần hoặc với ít dữ liệu huấn luyện bổ sung. Cơ chế đằng sau hiệu suất xuyên ngôn ngữ mạnh mẽ đã được các nhà nghiên cứu điều tra. Đã được chứng minh rằng các mô hình ngôn ngữ đa ngôn ngữ đã suy ra các quy tắc phổ quát áp dụng cho bất kỳ ngôn ngữ nào (Artetxe, Ruder, và Yogatama 2020; Chi, Hewitt, và Manning 2020; Conneau et al. 2020b). Trái ngược với giả thuyết phổ biến rằng các mô hình ngôn ngữ đa ngôn ngữ chẳng hạn như mBERT (Devlin et al. 2019) dựa vào từ vựng con từ chung và tiền huấn luyện chung trên nhiều ngôn ngữ (Pires, Schlinger, và Garrette 2019; Cao, Kitaev, và Klein 2020; Wu và Dredze 2019), các nhà nghiên cứu đã phát triển những hiểu biết mới về các mô hình, nhấn mạnh khả năng của các mô hình để học các trừu tượng ngữ nghĩa phổ quát (Artetxe, Ruder, và Yogatama 2020; Chi, Hewitt, và Manning 2020). Về các yếu tố ảnh hưởng đến hiệu suất xuyên ngôn ngữ, các nhà nghiên cứu đã liên kết khả năng chuyển giao với chia sẻ tham số (Conneau et al. 2020b; Dufter và Schütze 2020; Wu, Papadimitriou, và Tamkin 2022) và khoảng cách ngôn ngữ (Conneau et al. 2020b; Eronen, Ptaszynski, và Masui 2023). Chúng tôi ở đây tiếp tục điều tra khả năng chuyển giao xuyên ngôn ngữ của các mô hình ngôn ngữ với các thí nghiệm dựa trên LLaMA mới, trình bày kết quả từ một khía cạnh khác.

Chuyển đổi Mã
Chuyển đổi mã là hiện tượng mà người nói đa ngôn ngữ chuyển đổi giữa các ngôn ngữ trong một phát ngôn duy nhất. Công việc trước đây về hiệu suất của các mô hình ngôn ngữ đa ngôn ngữ trên các tác vụ chuyển đổi mã đã cho thấy kết quả hỗn hợp. Một số nghiên cứu đã đề xuất rằng các mô hình được tiền huấn luyện được tinh chỉnh cho các tình huống chuyển đổi mã cụ thể có thể đạt hiệu suất tiên tiến cho các cặp ngôn ngữ nhất định như tiếng Anh-Tây Ban Nha và tiếng Anh-Hindi (Khanuja et al. 2020), trong khi các nghiên cứu khác đã phát hiện rằng sử dụng meta-embeddings có thể mang lại kết quả tốt hơn với ít tham số hơn (Winata, Lin, và Fung 2019; Winata et al. 2019, 2021a). Trong một dòng nghiên cứu khác, các phương pháp dựa trên chuyển đổi mã đã được trình bày để cải thiện khả năng của các mô hình ngôn ngữ đa ngôn ngữ (Jiang et al. 2020; Tan và Joty 2021; Krishnan et al. 2021).

Kết luận
Trong bài báo này, chúng tôi tập trung vào cách chuyển giao hiệu quả các khả năng tạo ngôn ngữ và tuân theo hướng dẫn sang một ngôn ngữ không phải tiếng Anh. Cụ thể, chúng tôi tiến hành một nghiên cứu thực nghiệm toàn diện để phân tích tính cần thiết của mở rộng từ vựng và quy mô huấn luyện cần thiết cho chuyển giao hiệu quả. Chúng tôi thấy rằng mở rộng từ vựng là không cần thiết và hiệu suất chuyển giao có thể so sánh với các mô hình tiên tiến có thể đạt được với ít hơn 1% dữ liệu tiền huấn luyện thêm. Ngoài ra, chúng tôi quan sát các trường hợp chuyển đổi mã trong quá trình huấn luyện chuyển giao, cho thấy căn chỉnh xuyên ngôn ngữ có thể đã được nội bộ hóa trong mô hình. Kết quả tương tự được quan sát từ các thí nghiệm mở rộng trên 13 ngôn ngữ ít tài nguyên. Phân tích và phát hiện của chúng tôi cung cấp hỗ trợ và hướng dẫn cho cộng đồng trong việc phát triển các LLMs không phải tiếng Anh.

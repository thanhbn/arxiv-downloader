# 2306.10241.pdf
# Converted from PDF to TXT
# Source path: /home/admin88/arxiv-downloader/multilingual/2306.10241.pdf
# File size: 899782 bytes

===============================================
PDF FILE CONTENT
===============================================


--- PAGE 1 ---
Snowman
 : A Million-scale Chinese Commonsense Knowledge Graph
Distilled from Foundation Model
Jiaan Wang♠, Jianfeng Qu♠, Yunlong Liang♢, Zhixu Li♣
An Liu♠, Guanfeng Liu♡and Xin Zhengℑ
♠Soochow University♣Fudan University♢Beijing Jiaotong University
♡Macquarie UniversityℑiFLYTEK Research
jawang.nlp@gmail.com ,jfqu@suda.edu.cn
yunlonliang@gmail.com ,zhixuli@fudan.edu.cn
Abstract
Constructing commonsense knowledge graphs
(CKGs) has attracted wide research attention
due to its significant importance in cognitive
intelligence. Nevertheless, existing CKGs are
typically oriented to English, limiting the re-
search in non-English languages. Meanwhile,
the emergence of foundation models like Chat-
GPT and GPT-4 has shown promising intelli-
gence with the help of reinforcement learning
from human feedback. Under the background,
in this paper, we utilize foundation models to
construct a Chinese CKG, named Snowman.
Specifically, we distill different types of com-
monsense head items from ChatGPT, and con-
tinue to use it to collect tail items with re-
spect to the head items and pre-defined rela-
tions. Based on the preliminary analysis, we
find the negative commonsense knowledge dis-
tilled by ChatGPT achieves lower human accep-
tance compared to other knowledge. Therefore,
we design a simple yet effective self-instruct
filtering strategy to filter out invalid negative
commonsense. Overall, the constructed Snow-
man covers more than ten million Chinese com-
monsense triples, making it the largest Chinese
CKG. Moreover, human studies show the ac-
ceptance of Snowman achieves 90.6%, indi-
cating the high-quality triples distilled by the
cutting-edge foundation model. We also con-
duct experiments on commonsense knowledge
models to show the usability and effectiveness
of our Snowman.1
1 Introduction
Collecting large-scale commonsense knowledge
is a long-standing goal of cognitive intelli-
gence (Feigenbaum, 1984; Lenat, 1995). The com-
monsense knowledge graphs (CKGs), as a type
of knowledge carrier, contain structured knowl-
edge about everyday concepts and their proper-
ties (Nguyen et al., 2021), facilitating various down-
stream tasks, such as question answering (Tian
1The codes and data will be released upon publication.et al., 2020), storytelling (Wang et al., 2022f; Am-
manabrolu et al., 2021), dialogue generation (Liang
et al., 2021, 2022b) and summarization (Liang
et al., 2022c,a, 2023; Wang et al., 2022b,e,c, 2023c).
Many efforts have been devoted to constructing
large-scale CKGs through manual collecting (Speer
et al., 2017; Sap et al., 2019; Mostafazadeh et al.,
2020) or automatic extraction (Tandon et al., 2014;
Romero et al., 2019; Zhang et al., 2020; Nguyen
et al., 2021; Wang et al., 2022a).
Nevertheless, current CKGs are typically lim-
ited to English, e.g., TransOMCS (Zhang et al.,
2020), ATOMIC (Sap et al., 2019) and ATOMIC
2020 (Hwang et al., 2020). Though Concept-
Net (Speer et al., 2017) is a multi-lingual CKG,
most of its non-English parts are lexical knowl-
edge and are limited in quantity as well as cover-
age (Wang et al., 2022a). To go beyond English-
centric CKGs, some recent studies construct Chi-
nese CKGs in different manners. For example,
C3KG (Li et al., 2022), as a Chinese common-
sense conversation knowledge graph, is constructed
based on the translation of ATOMIC (Sap et al.,
2019; Hwang et al., 2020). As revealed by some
work, directly translating resources suffers from the
issues of cultural differences (Wang et al., 2022a)
and translationese (Yu et al., 2022; Wang et al.,
2022d), which may limit the precise and broad ex-
pression of native commonsense knowledge.
Recently, thanks to the development of pre-
trained language models (PLMs) ( e.g., T5 (Raf-
fel et al., 2020) and GPT-3 (Brown et al., 2020)),
which makes it possible to extract commonsense
knowledge directly from PLMs. West et al. (2021)
show that the CKG built from PLMs can surpass
the crowdsourced ones in both quantity and qual-
ity. Under this background, CN-AutoMIC (Wang
et al., 2022a) is created through distilling Chinese
commonsense knowledge from mT5-XXL (a popu-
lar multi-lingual PLM) with 13B parameters (Xue
et al., 2021). Though great success has beenarXiv:2306.10241v1  [cs.CL]  17 Jun 2023

--- PAGE 2 ---
achieved, the unfiltered CN-AutoMIC only reaches
47.6% human acceptance and limited coverage.
This is because mT5 is pre-trained with the gen-
eral language modeling task ( i.e., span corruption),
and does not suffer from instruction tuning (Wei
et al., 2021) and reinforcement learning from hu-
man feedback (RLHF) (Stiennon et al., 2020). The
latest research including ChatGPT (OpenAI, 2022)
and GPT-4 (OpenAI, 2023) foundation models in-
dicates that instruction tuning and RLHF could
help machines to better follow the human input and
give the satisfied generation. In detail, instruction
tuning finetunes PLMs on a collection of datasets
described via instructions, and can substantially
improve the zero-shot ability of PLMs on unseen
tasks (Wei et al., 2021; Muennighoff et al., 2022).
RLHF uses human preferences as rewards to fine-
tune PLMs using reinforcement learning ( e.g., PPO
algorithm (Schulman et al., 2017)), and it could
help PLMs to generate high-quality responses as
humans expected, promoting the early appearance
of artificial general intelligence (AGI) (Bubeck
et al., 2023; Wang et al., 2023b,a).
In this paper, we leverage the success of founda-
tion models to build a new Chinese CKG named
Snowman (Chinese common sense k nowledge
graph distilled fro mChatGPT fou ndation model).
Specifically, we distill structured Chinese common-
sense knowledge from ChatGPT (OpenAI, 2022)
(a representative cutting-edge foundation model
that has been pre-trained with instruction tuning
and RLHF) via prompting and filtering. Follow-
ing CN-AutoMIC (Wang et al., 2022a), we first
use small-scale seeds to collect about 185.1K com-
monsense head items from ChatGPT, including vol-
untary items ( e.g.,PersonX learns to cook ), invol-
untary items ( e.g.,PersonX is attacked ) and state
items ( e.g.,PersonX is excited ). Then, for each
head item, we obtain its corresponding tail items
based on several mainstream pre-defined relations
such as xWant andxNeed . After that, we collect
a large number (11.1 million) of commonsense
knowledge triples, and we further conduct prelim-
inary analysis on their quality. We find that the
collected negative knowledge that describes what
is hindered by and what makes the thing cannot
happen, such as “ Renting a luxury car is hindered
by bad driving records ” and “ Doing exercise ev-
ery day is hindered by a critical illness ”, achieves
lower human acceptance compared with others.
This is because most of the world knowledge existsin a positive and affirmative form (Molnar, 2000;
Barker and Jago, 2012), resulting in a limited abil-
ity to generate negative commonsense knowledge
from PLMs (Hossain et al., 2022). To this end,
we utilize a simple yet effective self-instruct filter-
ing strategy to filter out low-quality negative com-
monsense knowledge in the preliminary collection.
Specifically, though ChatGPT struggles to generate
negative knowledge, it can well determine the ratio-
nality of negative knowledge (making a judgment
is easier than generation). Therefore, we sample
a number of vanilla negative knowledge triples,
and utilize ChatGPT to provide labels of whether
each negative triple is reasonable. We use these
boolean data to train a binary classifier to filter out
low-quality negative knowledge triples. Finally,
our Snowman contains 185.1K unique head items,
5.4M unique tail items and 10.5M triples, making it
the largest Chinese CKG. Human studies show the
acceptance of Snowman reaches 90.6%, indicating
its high quality and the effectiveness of our con-
struction method. The number of triples involved
in Snowman is 9.7 times that of the previous largest
Chinese CKG with the same level of quality ( i.e.,
CN-AutoMIC high(Wang et al., 2022a) with 89.5%
human acceptance). Moreover, we also conduct
experiments on commonsense knowledge genera-
tion models, i.e., COMET (Bosselut et al., 2019),
to demonstrate the usability and effectiveness of
our Snowman.
We highlight our contributions as follows:
•We construct Snowman, a new Chinese common-
sense knowledge graph (CKG) with 10.5M high-
quality triples, which is 9.2 times that of the pre-
vious largest Chinese CKG with the same level of
quality. Thanks to the rapid development of foun-
dation models, our Snowman satisfies people in
quality and quantity.
•To the best of our knowledge, we are the first to
collect commonsense knowledge through distill-
ing from a foundation model (ChatGPT) that is
trained with instruction tuning and reinforcement
learning from human feedback. Both training
paradigms improve the data quality distilled by
the foundation model.
•To deal with the negative knowledge issue, we
utilize a simple yet effective self-instruct strat-
egy that does not need any human annotation
and can effectively filter out low-quality negative
knowledge triples.

--- PAGE 3 ---
请仿照以下10个例句，再造10个类似的句子：
(Please imitate the following 10 example sentences and 
create 10 similar sentences:)
1.某人X情绪失控
(1. PersonX is emotionally out of control)
2.某人X呼吸困难
(2. PersonX has trouble breathing)
…
10.某人X非常口渴
(10. PersonX is very thirsty)
1.某人X情绪低落
(1. PersonX is depressed)
2.某人X体重过重
(2. PersonX is overweight)
…
10.某人X手指发麻
(10. PersonX's fingers are numb)Figure 1: The prompt for distilling head items. Grey
indicates the translation which actually does not in the
prompt.
•We conduct human studies and experiments on
commonsense knowledge models to give an in-
depth understanding of the CKG distilled by the
foundation model. The results show the high
quality and effectiveness of our Snowman.
2 Data Construction
In this section, we discuss the construction pro-
cess of Snowman. We first distill different types of
head items from ChatGPT based on a small num-
ber of seed items (§ 2.1). Then, for each head
item, we continue to distill ChatGPT to collect its
corresponding tail items with respect to different
pre-defined relations (§ 2.2). Lastly, we find the
negative knowledge triples generated by ChatGPT
suffer from mixed quality, and we use a simple
yet effective self-instruct filtering strategy to filter
out low-quality negative knowledge triples in the
preliminary distillation (§ 2.3).
2.1 Collecting Head Items
Following Wang et al. (2022a), the head items of
commonsense knowledge involve three knowledge
types, i.e., voluntary items, involuntary items and
state items. Among them, voluntary items describe
the events or activities that someone intentionally
causes, such as “PersonX learns to cook”, while
involuntary items show the events or activities that
someone is involuntarily involved in it, e.g., “Per-
sonX is attacked”. State items indicate the states
that someone is in it for some time.
For each knowledge type, we manually create
200 head items by employing Chinese students,
who majored in computer science, as volunteers.
The created head items are further checked by a
每个事件发生后都有人物想做的事，例如：
(After each event, there are things the character wants to do, such 
as:)
1.[NAME]参加聚会，在此之后，[NAME]想要喝啤酒
(1. [NAME] attended a party. As a result, [NAME] wants to drink 
beer)
2. [NAME]拜访朋友，在此之后，[NAME]想要和朋友聊天
(2. [NAME] visited friends. As a result, [NAME] wants to chat 
with friends)
…
8. [NAME]买了一束玫瑰，在此之后，[NAME]想要表白
(8. [NAME] bought a bouquet of roses. As a result, [NAME] 
wants to propose)
那么请根据以下事件，列举该人物想做的十件事：
(So please list ten things that the character wants to do based on 
the following events:)
[NAME]参加了环保组织，在此之后，[NAME]想要：
([NAME] Participated in environmental organizations. As a result, 
[NAME] wants to:)
1.宣传环保知识
(1. Promote environmental protection knowledge)
2.参与环保项目
(2. Participate in environmental protection projects)
…
10.倡导低碳生活方式
(10. Advocate for a low-carbon lifestyle)Figure 2: The prompt for distilling tail items. Grey
indicates the translation which actually does not in the
prompt.
data expert to ensure their quality. Next, head items
of each knowledge type serve as seeds to prompt
ChatGPT to generate a large number of head items
with the same type. During the generation of Chat-
GPT, we utilize the official APIs provided by Ope-
nAI.2To make a trade-off between the diversity
and the generation quality, we set the temperature
hyper-parameter to 0.7 based on the pilot experi-
ments. The utilized prompt is shown in Figure 1,
where a total of 10 example head items are ran-
domly selected from the whole 200 seeds for each
generation cycle. Finally, we distill 61.7K unique
head items from ChatGPT for each knowledge type,
resulting in a total of 185.1K head items.
2.2 Collecting Tail Items
After obtaining head items, we need to collect re-
lations as well as tail items to get complete triples.
Inspired by previous CKG construction work (Sap
et al., 2019; Hwang et al., 2020; Wang et al., 2022a),
we choose seven mainstream relations, i.e.,xWant ,
xReact ,xEffect ,xAttr ,xNeed ,xIntent and Hin-
deredBy . Table 1 shows the explanation of each
relation and the corresponding valid knowledge
types of head items are used to distill tail items. It
is worth noting that each relation is only paired with
the head items whose knowledge type is valid (c.f.,
“” in Table 1) to avoid invalid distilling results.
For example, the occurrence of an involuntary head
item does not reflect any intent of someone due to
his/her involuntary participation.
2https://platform.openai.com/docs/
guides/gpt/chat-completions-api

--- PAGE 4 ---
Relation ExplanationValid Types of Head Items
V oluntary Involuntary State
xWant After the occurrence of {Head}, PersonX wants {Tail}
xReact After the occurrence of {Head}, PersonX feels {Tail}
xEffect After the occurrence of {Head}, PersonX does {Tail} as a result
xAttr After the occurrence of {Head}, we can know that PersonX is {Tail}
xNeed Before the occurrence of {Head}, PersonX needs {Tail}
xIntent When doing {Head}, PersonX’s intent is {Tail}
HinderedBy The occurrence of {Head} can be hindered by {Tail}
Table 1: The pre-defined relations during the construction of Snowman. “ {Head} ” and “ {Tail} ” denote the head and
tail items, respectively. “ Valid Types of Head Items ” indicates the relation is used to distill tail items for which types
of head items.
To distill ChatGPT to generate tail items, we
also manually create 100 triple seeds with respect
to each relation in the same way as Section 2.1.
The prompt used to distill tail items is illustrated in
Figure 2, where the “[NAME]” placeholder is re-
placed with random Chinese common-used names.
There are eight example triples in the prompt, and
each of which is randomly selected from the seed
triples. At the end of the prompt, we give a tem-
plate sentence that describes the head item and the
relation, and use it to distill ChatGPT to generate
ten tail items. In this manner, we finally obtain
11.1M unique Chinese commonsense triples, cost-
ing thousands of dollars to call official APIs.
2.3 Self-Instruct Filtering
To understand the quality of the distilled triples
w.r.t each relation, we give a preliminary analy-
sis (for more details, please refer to § 3), and find
that the human acceptance of triples with the Hin-
deredBy relation (65%) is lower than that of oth-
ers (typically more than 85%). This is because
theHinderedBy triples describe the commonsense
knowledge in negative statements, while most of
the world knowledge exists in a positive form (Mol-
nar, 2000; Barker and Jago, 2012). Recent stud-
ies (Arnaout and Razniewski, 2023; Chen et al.,
2023) also show that the quality of negative knowl-
edge distilled from foundation models (even Chat-
GPT) still does not satisfy people.
To solve the above issue, we utilize a simple
yet effective self-instruct filtering strategy. In de-
tail, we sample 4K HinderedBy triples and em-
ploy ChatGPT to judge whether the triple is valid.
Though ChatGPT struggles to generate HinderedBy
triples, it can well judge whether a HinderedBy
triple is valid. This is because the discriminative
task is much easier than the generative counter-
part. Then, the boolean data is used to train aChinese RoBERTa3(Liu et al., 2019) filter to filter
low-quality raw HinderedBy triples. Note that this
filtering method leverages the judgments of Chat-
GPT to filter out its low-quality generation, which
does not need any human annotation and thus is
called self-instruct filtering.
3 Data Analysis
Human Evaluation. We conduct human analysis
on our Snowman and previous ATOMIC-zh (Li
et al., 2022) as well as CN-AutoMIC (Wang et al.,
2022a). For Snowman, we randomly select 100
triples w.r.t each relation, resulting in 800 random
triples (since the filtering strategy is applied in Hin-
deredBy relation, we randomly select 100 samples
from unfiltered and filtered HinderedBy triples, re-
spectively). For ATOMIC-zh and CN-AutoMIC,
we randomly select 700 samples from each of them
to conduct human analysis. Following Wang et al.
(2022a), we invite three Chinese postgraduate stu-
dents to assess whether each commonsense knowl-
edge triple is reasonable, and compute the average
proportion of reasonable triples for each CKG as
its human acceptance.
Overall Statistics. Table 2 compares the data statis-
tics of our Snowman and previous CKGs. We find
that the scale of Snowman is the largest among
all CKGs, and only Snowman involves more than
10 million commonsense triples. This finding in-
dicates the superiority of ChatGPT serving as the
backbone model to distill commonsense knowl-
edge. In addition, the human acceptance of raw
Snowman reaches 86.8%, which is higher than
that of other unfiltered CKGs (78.5% of ATOMIC
10X rawand 47.6% of CN-AutoMIC raw). With the
help of the self-instruct filtering strategy, the human
3https://hf.co/hfl/
chinese-roberta-wwm-ext-large

--- PAGE 5 ---
Commonsense Know Graph Language ConstructionUnique UniqueTriplesHuman
Head Items Tail Items Acceptance
ATOMIC 2020 (Hwang et al., 2020) English Crowdsourcing 25,807 354,777 760,034 86.8∗
ATOMIC 10X raw(West et al., 2021) English Generation 165,783 874,417 6,456,300 78.5∗
ATOMIC 10X high(West et al., 2021) English Generation 164,553 357,761 2,512,720 96.4∗
ATOMIC-zh (Li et al., 2022) Chinese Translation 20,949 276,446 712,970 41.9 (38.7†)
CN-AutoMIC raw(Wang et al., 2022a) Chinese Generation 114,364 1,101,556 6,868,766 52.3 (47.6†)
CN-AutoMIC high(Wang et al., 2022a) Chinese Generation 89,738 182,893 1,140,840 89.5 (87.2†)
Snowman raw(Our) Chinese Generation 185,075 5,783,395 11,087,873 86.8
Snowman high(Our) Chinese Generation 185,075 5,426,778 10,463,219 90.6
Table 2: The data statistics of Snowman and previous CKGs.∗and†denote the results are from West et al. (2021)
and Wang et al. (2022a), respectively.
RelationUniqueTriples AcceptanceTail Items
xWant 1,280,417 1,850,336 89.3
xReact 206,947 1,227,908 93.0
xEffect 1,136,804 1,850,490 95.7
xAttr 389,639 1,846,849 87.3
xNeed 1,408,147 1,846,947 86.3
xIntent 317,298 616,821 90.0
HinderedBy (raw) 1,168,014 1,848,522 65.7
HinderedBy 810,754 1,223,868 92.7
Table 3: Relation-level data statistics of Snowman.
acceptance of Snowman further reaches 90.6%, the
highest acceptance among all Chinese CKGs, indi-
cating the effectiveness of the strategy.
Relation-Level Statistics. Table 3 shows the
relation-level data statistics of Snowman. We can
find that the raw human acceptance of HinderedBy
relation only achieves 65.7%, which is significantly
lower than that of other relations (typically more
than 85%). After filtering the low-quality Hin-
deredBy triples, the acceptance improves to 92.7%,
satisfying human evaluators.
4 Commonsense Generation
4.1 Experimental Setup
To further demonstrate the usability and effective-
ness of our Snowman, we conduct experiments on
commonsense knowledge generation. Specifically,
following Wang et al. (2022a), we train COMET
model (Bosselut et al., 2019) (a widely-used com-
monsense knowledge generation model) with the
backbone of mT5-base (580M)4(Xue et al., 2021)
on Snowman triples. During training, we set 1e-4
learning rate, 128 batch size, and 2K warmup steps.
Next, we compare the trained model with other
COMET models trained on ATOMIC-zh triples
4https://hf.co/google/mt5-baseModel Acceptance
COMET (ATOMIC-zh) 31.2%
COMET (CN-AutoMIC raw) 47.8%
COMET (CN-AutoMIC high) 61.3%
COMET (Snowman low) 77.5%
COMET (Snowman high) 81.8%
Table 4: The performance of commonsense knowledge
model trained on different CKGs.
and CN-AutoMIC triples. For each CKG, we only
randomly select 500K triples to train the COMET
model to avoid the impact of different data scales.
The test set is based on a held-out set (500 samples)
of ATOMIC-zh for a fair comparison. We manually
evaluate the generation results in the same way as
Section 3 ( i.e., human acceptance).
4.2 Results & Discussion
As shown in Table 4, the model trained on
Snowman highachieves the best human acceptance,
indicating the triples from our Snowman could help
the generation model infer better commonsense
knowledge. This finding also demonstrates the
high quality of our CKG and the superiority of the
ChatGPT foundation model. The instruction tun-
ing and RLHF make the foundation models more
intelligent, benefiting various downstream tasks
and letting the construction of high-quality CKG
become more convenient.
Compared with the previous CN-AutoMIC (that
is distilled from mT5), we show that the cutting-
edge foundation model (ChatGPT) can distill
higher-quality Chinese CKG with only a few
(hundred-level) seeds. Besides, the construction
protocol of Snowman is more concise than that of
CN-AutoMIC (which includes cascaded filters and
several rule-based denoising methods). The con-
struction protocol could also be trivially adapted to
another language, and prompt the research on low-

--- PAGE 6 ---
language CKGs as well as multi-lingual CKGs.
5 Conclusion
In this work, we transfer the success of founda-
tion models to the construction of commonsense
knowledge graphs (CKGs). In detail, we distill
ChatGPT to generate Chinese commonsense triples
with only a small number of seed items and triples.
To deal with the negative knowledge issue, we de-
sign a simple yet effective self-instruct filtering
strategy to filter out low-quality negative knowl-
edge triples. Finally, our Snowman involves more
than 10 million Chinese knowledge triples, making
it the largest Chinese CKG. The human evaluation
as well as commonsense generation experiments
show the high quality of the constructed CKG.
References
Prithviraj Ammanabrolu, Wesley Cheung, William
Broniec, and Mark O. Riedl. 2021. Automated story-
telling via causal, commonsense plot ordering. Pro-
ceedings of the AAAI Conference on Artificial Intelli-
gence , 35(7):5859–5867.
Hiba Arnaout and Simon Razniewski. 2023. Can
large language models generate salient negative state-
ments? ArXiv , abs/2305.16755.
Stephen Barker and Mark Jago. 2012. Being positive
about negative facts. Philosophy and Phenomenolog-
ical research , pages 117–138.
Antoine Bosselut, Hannah Rashkin, Maarten Sap, Chai-
tanya Malaviya, Asli Celikyilmaz, and Yejin Choi.
2019. Comet: Commonsense transformers for au-
tomatic knowledge graph construction. In Annual
Meeting of the Association for Computational Lin-
guistics .
Tom Brown, Benjamin Mann, Nick Ryder, Melanie
Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind
Neelakantan, Pranav Shyam, Girish Sastry, Amanda
Askell, et al. 2020. Language models are few-shot
learners. Advances in neural information processing
systems , 33:1877–1901.
Sébastien Bubeck, Varun Chandrasekaran, Ronen El-
dan, Johannes Gehrke, Eric Horvitz, Ece Kamar,
Peter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lund-
berg, et al. 2023. Sparks of artificial general intelli-
gence: Early experiments with gpt-4. arXiv preprint
arXiv:2303.12712 .
Jiangjie Chen, Wei Shi, Ziquan Fu, Sijie Cheng, Lei Li,
and Yanghua Xiao. 2023. Say what you mean! large
language models speak too positively about negative
commonsense knowledge. ArXiv , abs/2305.05976.Edward A Feigenbaum. 1984. Knowledge engineer-
ing. Annals of the New York Academy of Sciences ,
426(1):91–107.
Md Mosharaf Hossain, Dhivya Chinnappa, and Eduardo
Blanco. 2022. An analysis of negation in natural lan-
guage understanding corpora. In Proceedings of the
60th Annual Meeting of the Association for Compu-
tational Linguistics (Volume 2: Short Papers) , pages
716–723, Dublin, Ireland. Association for Computa-
tional Linguistics.
Jena D. Hwang, Chandra Bhagavatula, Ronan Le Bras,
Jeff Da, Keisuke Sakaguchi, Antoine Bosselut, and
Yejin Choi. 2020. Comet-atomic 2020: On symbolic
and neural commonsense knowledge graphs. In AAAI
Conference on Artificial Intelligence .
Douglas B Lenat. 1995. Cyc: A large-scale investment
in knowledge infrastructure. Communications of the
ACM , 38(11):33–38.
Dawei Li, Yanran Li, Jiayi Zhang, Ke Li, Chen Wei,
Jianwei Cui, and Bin Wang. 2022. C3KG: A Chi-
nese commonsense conversation knowledge graph.
InFindings of the Association for Computational
Linguistics: ACL 2022 , pages 1369–1383, Dublin,
Ireland. Association for Computational Linguistics.
Yunlong Liang, Fandong Meng, Jiaan Wang, Jinan Xu,
Yufeng Chen, and Jie Zhou. 2023. D2tv: Dual knowl-
edge distillation and target-oriented vision modeling
for many-to-many multimodal summarization. arXiv
preprint arXiv:2305.12767 .
Yunlong Liang, Fandong Meng, Jinan Xu, Jiaan Wang,
Yufeng Chen, and Jie Zhou. 2022a. Summary-
oriented vision modeling for multimodal abstractive
summarization. arXiv preprint arXiv:2212.07672 .
Yunlong Liang, Fandong Meng, Ying Zhang, Yufeng
Chen, Jinan Xu, and Jie Zhou. 2021. Infusing multi-
source knowledge with heterogeneous graph neural
network for emotional conversation generation. Pro-
ceedings of AAAI , pages 13343–13352.
Yunlong Liang, Fandong Meng, Ying Zhang, Yufeng
Chen, Jinan Xu, and Jie Zhou. 2022b. Emotional
conversation generation with heterogeneous graph
neural network. Artificial Intelligence , 308:103714.
Yunlong Liang, Fandong Meng, Chulun Zhou, Jinan
Xu, Yufeng Chen, Jinsong Su, and Jie Zhou. 2022c.
A variational hierarchical model for neural cross-
lingual summarization. In ACL, pages 2088–2099.
Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-
dar Joshi, Danqi Chen, Omer Levy, Mike Lewis,
Luke Zettlemoyer, and Veselin Stoyanov. 2019.
Roberta: A robustly optimized bert pretraining ap-
proach. ArXiv , abs/1907.11692.
George Molnar. 2000. Truthmakers for negative truths.
Australasian Journal of philosophy , 78(1):72–86.

--- PAGE 7 ---
Nasrin Mostafazadeh, Aditya Kalyanpur, Lori Moon,
David Buchanan, Lauren Berkowitz, Or Biran, and
Jennifer Chu-Carroll. 2020. GLUCOSE: Gener-
aLized and COntextualized story explanations. In
Proceedings of the 2020 Conference on Empirical
Methods in Natural Language Processing (EMNLP) ,
pages 4569–4586, Online. Association for Computa-
tional Linguistics.
Niklas Muennighoff, Thomas Wang, Lintang Sutawika,
Adam Roberts, Stella Rose Biderman, Teven Le
Scao, M Saiful Bari, Sheng Shen, Zheng Xin Yong,
Hailey Schoelkopf, Xiangru Tang, Dragomir R.
Radev, Alham Fikri Aji, Khalid Almubarak, Samuel
Albanie, Zaid Alyafeai, Albert Webson, Edward
Raff, and Colin Raffel. 2022. Crosslingual gen-
eralization through multitask finetuning. ArXiv ,
abs/2211.01786.
Tuan-Phong Nguyen, Simon Razniewski, and Gerhard
Weikum. 2021. Advanced semantics for common-
sense knowledge extraction. In Proceedings of the
Web Conference 2021 , WWW ’21, page 2636–2647,
New York, NY , USA. Association for Computing
Machinery.
OpenAI. 2022. Introducing chatgpt. https://
openai.com/blog/chatgpt .
OpenAI. 2023. Gpt-4 technical report. ArXiv ,
abs/2303.08774.
Colin Raffel, Noam Shazeer, Adam Roberts, Katherine
Lee, Sharan Narang, Michael Matena, Yanqi Zhou,
Wei Li, and Peter J Liu. 2020. Exploring the limits
of transfer learning with a unified text-to-text trans-
former. The Journal of Machine Learning Research ,
21(1):5485–5551.
Julien Romero, Simon Razniewski, Koninika Pal, Jeff
Z. Pan, Archit Sakhadeo, and Gerhard Weikum.
2019. Commonsense properties from query logs
and question answering forums. In Proceedings of
the 28th ACM International Conference on Informa-
tion and Knowledge Management , CIKM ’19, page
1411–1420, New York, NY , USA. Association for
Computing Machinery.
Maarten Sap, Ronan Le Bras, Emily Allaway, Chan-
dra Bhagavatula, Nicholas Lourie, Hannah Rashkin,
Brendan Roof, Noah A. Smith, and Yejin Choi. 2019.
Atomic: An atlas of machine commonsense for if-
then reasoning. Proceedings of the AAAI Conference
on Artificial Intelligence , 33(01):3027–3035.
John Schulman, Filip Wolski, Prafulla Dhariwal, Alec
Radford, and Oleg Klimov. 2017. Proximal policy
optimization algorithms. ArXiv , abs/1707.06347.
Robyn Speer, Joshua Chin, and Catherine Havasi. 2017.
Conceptnet 5.5: An open multilingual graph of gen-
eral knowledge. In Proceedings of the AAAI confer-
ence on artificial intelligence , volume 31.Nisan Stiennon, Long Ouyang, Jeffrey Wu, Daniel
Ziegler, Ryan Lowe, Chelsea V oss, Alec Radford,
Dario Amodei, and Paul F Christiano. 2020. Learn-
ing to summarize with human feedback. Advances
in Neural Information Processing Systems , 33:3008–
3021.
Niket Tandon, Gerard de Melo, Fabian Suchanek, and
Gerhard Weikum. 2014. Webchild: Harvesting and
organizing commonsense knowledge from the web.
InProceedings of the 7th ACM International Confer-
ence on Web Search and Data Mining , WSDM ’14,
page 523–532, New York, NY , USA. Association for
Computing Machinery.
Zhixing Tian, Yuanzhe Zhang, Kang Liu, Jun Zhao,
Yantao Jia, and Zhicheng Sheng. 2020. Scene restor-
ing for narrative machine reading comprehension. In
Proceedings of the 2020 Conference on Empirical
Methods in Natural Language Processing (EMNLP) ,
pages 3063–3073, Online. Association for Computa-
tional Linguistics.
Chenhao Wang, Jiachun Li, Yubo Chen, Kang Liu, and
Jun Zhao. 2022a. CN-AutoMIC: Distilling Chinese
commonsense knowledge from pretrained language
models. In Proceedings of the 2022 Conference on
Empirical Methods in Natural Language Processing ,
pages 9253–9265, Abu Dhabi, United Arab Emirates.
Association for Computational Linguistics.
Jiaan Wang, Zhixu Li, Tingyi Zhang, Duo Zheng, Jian-
feng Qu, An Liu, Lei Zhao, and Zhigang Chen. 2022b.
Knowledge enhanced sports game summarization. In
Proceedings of the Fifteenth ACM International Con-
ference on Web Search and Data Mining , WSDM ’22,
page 1045–1053, New York, NY , USA. Association
for Computing Machinery.
Jiaan Wang, Yunlong Liang, Fandong Meng, Zhixu Li,
Jianfeng Qu, and Jie Zhou. 2023a. Cross-lingual
summarization via chatgpt. ArXiv , abs/2302.14229.
Jiaan Wang, Yunlong Liang, Fandong Meng, Haoxiang
Shi, Zhixu Li, Jinan Xu, Jianfeng Qu, and Jie Zhou.
2023b. Is chatgpt a good nlg evaluator? a preliminary
study. ArXiv , abs/2303.04048.
Jiaan Wang, Fandong Meng, Ziyao Lu, Duo Zheng,
Zhixu Li, Jianfeng Qu, and Jie Zhou. 2022c. Clid-
Sum: A benchmark dataset for cross-lingual dialogue
summarization. In Proceedings of the 2022 Confer-
ence on Empirical Methods in Natural Language Pro-
cessing , pages 7716–7729, Abu Dhabi, United Arab
Emirates. Association for Computational Linguistics.
Jiaan Wang, Fandong Meng, Tingyi Zhang, Yunlong
Liang, Jiarong Xu, Zhixu Li, and Jie Zhou. 2022d.
Understanding translationese in cross-lingual sum-
marization. ArXiv , abs/2212.07220.
Jiaan Wang, Fandong Meng, Duo Zheng, Yunlong
Liang, Zhixu Li, Jianfeng Qu, and Jie Zhou. 2022e.
A Survey on Cross-Lingual Summarization. Transac-
tions of the Association for Computational Linguis-
tics, 10:1304–1323.

--- PAGE 8 ---
Jiaan Wang, Fandong Meng, Duo Zheng, Yunlong
Liang, Zhixu Li, Jianfeng Qu, and Jie Zhou. 2023c.
Towards unifying multi-lingual and cross-lingual
summarization. ArXiv , abs/2305.09220.
Jiaan Wang, Beiqi Zou, Zhixu Li, Jianfeng Qu, Peng-
peng Zhao, An Liu, and Lei Zhao. 2022f. Incorpo-
rating commonsense knowledge into story ending
generation via heterogeneous graph networks. In
International Conference on Database Systems for
Advanced Applications .
Jason Wei, Maarten Bosma, Vincent Y Zhao, Kelvin
Guu, Adams Wei Yu, Brian Lester, Nan Du, An-
drew M Dai, and Quoc V Le. 2021. Finetuned lan-
guage models are zero-shot learners. arXiv preprint
arXiv:2109.01652 .
Peter West, Chandra Bhagavatula, Jack Hessel, Jena D
Hwang, Liwei Jiang, Ronan Le Bras, Ximing
Lu, Sean Welleck, and Yejin Choi. 2021. Sym-
bolic knowledge distillation: from general language
models to commonsense models. arXiv preprint
arXiv:2110.07178 .
Linting Xue, Noah Constant, Adam Roberts, Mihir Kale,
Rami Al-Rfou, Aditya Siddhant, Aditya Barua, and
Colin Raffel. 2021. mT5: A massively multilingual
pre-trained text-to-text transformer. In Proceedings
of the 2021 Conference of the North American Chap-
ter of the Association for Computational Linguistics:
Human Language Technologies , pages 483–498, On-
line. Association for Computational Linguistics.
Xinyan Yu, Trina Chatterjee, Akari Asai, Junjie Hu,
and Eunsol Choi. 2022. Beyond counting datasets:
A survey of multilingual dataset construction and
necessary resources. In Findings of the Association
for Computational Linguistics: EMNLP 2022 , pages
3725–3743, Abu Dhabi, United Arab Emirates. As-
sociation for Computational Linguistics.
Hongming Zhang, Daniel Khashabi, Yangqiu Song, and
Dan Roth. 2020. Transomcs: From linguistic graphs
to commonsense knowledge. In Proceedings of the
Twenty-Ninth International Joint Conference on Arti-
ficial Intelligence, IJCAI-20 , pages 4004–4010. Inter-
national Joint Conferences on Artificial Intelligence
Organization. Main track.

# Dịch máy nhận biết ngữ cảnh với giải thích đồng tham chiếu nguồn

Huy Hien Vu Hidetaka Kamigaito Taro Watanabe
Viện Khoa học và Công nghệ Nara, Nhật Bản.
{vu.huy_hien.va9, kamigaito.h, taro}@is.naist.jp

## Tóm tắt

Mặc dù đã có những cải tiến đáng kể trong việc nâng cao chất lượng dịch thuật, các mô hình dịch máy nhận biết ngữ cảnh (MT) vẫn hoạt động kém trong nhiều trường hợp. Một trong những lý do chính là chúng không thể sử dụng các đặc trưng chính xác từ ngữ cảnh khi ngữ cảnh quá dài hoặc mô hình của chúng quá phức tạp. Điều này có thể dẫn đến hiệu ứng giải thích-loại bỏ, trong đó các mô hình chỉ xem xét các đặc trưng dễ giải thích hơn cho dự đoán, dẫn đến bản dịch không chính xác. Để giải quyết vấn đề này, chúng tôi đề xuất một mô hình giải thích các quyết định được đưa ra cho việc dịch bằng cách dự đoán các đặc trưng đồng tham chiếu trong đầu vào. Chúng tôi xây dựng một mô hình cho đồng tham chiếu đầu vào bằng cách khai thác các đặc trưng ngữ cảnh từ cả biểu diễn đầu vào và đầu ra dịch thuật trên một mô hình MT hiện có. Chúng tôi đánh giá và phân tích phương pháp của mình trong nhiệm vụ dịch thuật cấp độ tài liệu WMT của bộ dữ liệu tiếng Anh-Đức, bộ dữ liệu tiếng Anh-Nga, và bộ dữ liệu TED talk đa ngôn ngữ, thể hiện sự cải thiện hơn 1.0 điểm BLEU khi so sánh với các mô hình nhận biết ngữ cảnh khác.

## 1 Giới thiệu

Với sự phát triển nhanh chóng của các kỹ thuật học máy, lĩnh vực Dịch máy (MT) đã chứng kiến những thay đổi từ các mô hình xác suất thuần túy (Brown et al., 1990; Koehn et al., 2003) đến các mô hình dựa trên mạng neural, chẳng hạn như các mô hình encoder-decoder dựa trên Mạng Neural Hồi quy (RNN) đơn giản (Sutskever et al., 2014) hoặc các mô hình dựa trên attention cấp cao hơn (Bahdanau et al., 2015; Luong et al., 2015), và cuối cùng chuyển sang mô hình Transformer hiện đại (Vaswani et al., 2017) và các biến thể của nó.

Chất lượng của các mô hình MT, bao gồm các mô hình dựa trên RNN, dựa trên attention, và Transformer, đã được cải thiện bằng cách kết hợp thông tin ngữ cảnh (Voita et al., 2018; Wang et al., 2017; và những nghiên cứu khác), hoặc kiến thức ngôn ngữ học (Bugliarello và Okazaki, 2020; Sennrich và Haddow, 2016; và những nghiên cứu khác). Trong các phương pháp nhận biết ngữ cảnh trước đây, nhiều cách tiếp cận thành công tập trung vào việc lựa chọn ngữ cảnh từ các câu trước đó (Jean et al., 2017; Wang et al., 2017) sử dụng nhiều bước dịch thuật, bao gồm mô-đun bổ sung để tinh chỉnh bản dịch được tạo ra bởi hệ thống MT không nhận biết ngữ cảnh, để sử dụng thông tin ngữ cảnh (Voita et al., 2019; Xiong et al., 2019), và mã hóa toàn bộ thông tin ngữ cảnh như các khung làm việc end-to-end (Zhang et al., 2020; Bao et al., 2021). Mặc dù chúng đã thể hiện hiệu suất được cải thiện, vẫn còn nhiều trường hợp mà các mô hình của chúng hoạt động không chính xác trong việc xử lý, tức là hiện tượng lược bỏ trong một đoạn văn dài. Một trong những lý do là các mô hình của chúng vẫn không thể lựa chọn các đặc trưng phù hợp từ ngữ cảnh khi ngữ cảnh dài, hoặc mô hình quá phức tạp. Do đó, mô hình sẽ dễ dàng gặp phải hiệu ứng giải thích-loại bỏ (Klein và Manning, 2002; Yu et al., 2017; Shah et al., 2020; Refinetti et al., 2023) trong đó một mô hình được học để chỉ sử dụng các đặc trưng dễ được khai thác cho dự đoán bằng cách loại bỏ hầu hết các đặc trưng đầu vào.

Để giải quyết vấn đề lựa chọn các đặc trưng ngữ cảnh phù hợp trong MT nhận biết ngữ cảnh, chúng tôi đề xuất một mô hình giải thích các quyết định dịch thuật bằng cách dự đoán các đặc trưng đầu vào. Mô hình dự đoán đầu vào sử dụng các biểu diễn của đầu ra dịch thuật như các đặc trưng bổ sung để dự đoán các đặc trưng ngữ cảnh trong đầu vào. Trong công trình này, chúng tôi sử dụng đồng tham chiếu làm nhiệm vụ dự đoán vì nó nắm bắt mối quan hệ của các đề cập cần thiết cho mô hình nhận biết ngữ cảnh. Mô hình dự đoán được xây dựng trên một mô hình MT hiện có mà không cần sửa đổi theo cách tương tự như được thực hiện trong học đa nhiệm vụ, nhưng nó kết hợp thông tin từ các biểu diễn được sử dụng cho các quyết định dịch thuật trong mô hình MT.

Trong cùng các cài đặt của bộ dữ liệu tiếng Anh-Nga (En-Ru) và nhiệm vụ dịch thuật cấp độ tài liệu WMT của bộ dữ liệu tiếng Anh-Đức (En-De), kỹ thuật đề xuất của chúng tôi vượt trội hơn mô hình dịch máy neural (NMT) dựa trên transformer tiêu chuẩn trong cả mô hình câu và mô hình nhận biết ngữ cảnh, cũng như mô hình nhận biết ngữ cảnh hiện đại được đo bằng BLEU (Post, 2018), BARTScore (Yuan et al., 2021) và COMET (Rei et al., 2020), và bộ kiểm tra được chú thích bởi con người trong một đoạn văn (Voita et al., 2019). Ngoài ra, trong các thí nghiệm đa ngôn ngữ, phương pháp của chúng tôi cho thấy kết quả nhất quán, song song với những kết quả trong các bộ dữ liệu En-Ru và En-De, và chứng minh tính linh hoạt của nó trên các ngôn ngữ khác nhau.

Phân tích sâu hơn cho thấy rằng mô hình con giải thích đồng tham chiếu của chúng tôi liên tục nâng cao chất lượng dịch thuật, bất kể loại kích thước bộ dữ liệu. Đáng chú ý, mô hình thể hiện sự cải thiện nhất quán khi ngữ cảnh bổ sung được kết hợp, làm nổi bật hiệu quả của nó trong việc xử lý các kích thước ngữ cảnh lớn hơn. Ngoài ra, phân tích làm nổi bật mối tương quan mạnh giữa bản đồ nhiệt self-attention và các cụm đồng tham chiếu, nhấn mạnh tầm quan trọng của mô hình con dự đoán đồng tham chiếu của chúng tôi trong việc nắm bắt thông tin đồng tham chiếu trong quá trình dịch thuật. Hơn nữa, phương pháp huấn luyện đề xuất của chúng tôi chứng minh hiệu quả trong nhiệm vụ dự đoán đồng tham chiếu. Chúng tôi cũng đưa ra gợi ý để tinh chỉnh sự đóng góp của mô hình con để tối ưu hóa tác động của nó trong toàn bộ hệ thống MT. Chúng tôi công bố mã nguồn và siêu tham số của mình tại https://github.com/hienvuhuy/TransCOREF.

## 2 Nền tảng

### 2.1 NMT dựa trên Transformer

Cho một câu đầu vào x = (x1, ..., x|x|) và bản dịch tương ứng y = (y1, ..., y|y|), một hệ thống MT trực tiếp mô hình hóa xác suất dịch thuật

p(y|x;θ) = ∏|y|t=1 p(yt|y<t,x;θ), (1)

trong đó t là chỉ số của các token mục tiêu, y<t là bản dịch một phần trước yt, và θ là tham số mô hình. Tại thời điểm suy luận, mô hình sẽ tìm bản dịch có khả năng nhất ŷ cho một đầu vào nguồn cho trước

ŷ = argmaxy ∏|y|t=1 p(yt|y<t,x;θ). (2)

Để mô hình hóa xác suất có điều kiện dịch thuật p(y|x;θ), nhiều kiến trúc encoder-decoder đã được đề xuất dựa trên CNN (Gehring et al., 2017) hoặc self-attention (Vaswani et al., 2017), và chúng tôi tập trung vào Transformer (Vaswani et al., 2017) làm khối xây dựng, do khả năng vượt trội của nó trong việc mô hình hóa các phụ thuộc dài hạn và nắm bắt các đặc trưng thông tin ngữ cảnh. Encoder của Transformer bao gồm le lớp xếp chồng chuyển đổi đầu vào x thành các biểu diễn ẩn Hleenc ∈ R|x|×d trong đó d là chiều của biểu diễn vector ẩn. Tương tự, decoder của Transformer bao gồm ld lớp xếp chồng tiêu thụ tiền tố dịch thuật y<t và Hleenc để tạo ra biểu diễn cuối cùng Hlddec ∈ R|y|×d. Hai quá trình có thể được ký hiệu chính thức là

Hienc = ENC(Hi-1enc) (3)
Hidec = DEC(Hi-1dec, Hleenc). (4)

Lưu ý rằng H0enc là biểu diễn của x từ lớp embedding, và H0dec là biểu diễn của y sau khi tra cứu embedding với việc dịch chuyển bởi token bắt đầu câu. ENC(·) và DEC(·) biểu thị hàm của lớp encoder và decoder Transformer đơn lẻ, tương ứng.

Chuỗi mục tiêu đầu ra được dự đoán dựa trên trạng thái ẩn đầu ra Hlddec từ lớp trên cùng của decoder

p(yt|y<t,x;θ) = SOFTMAX(WdecHlddec[t])[yt] (5)

trong đó Wdec ∈ R|V|×d là ma trận trọng số chiếu ánh xạ trạng thái ẩn tới xác suất trong không gian từ vựng đầu ra V, và [·] biểu thị một chỉ số/lát cắt tới một vector/ma trận.

Mục tiêu huấn luyện tiêu chuẩn là tối thiểu hóa hàm mất mát entropy chéo

LMT = -∑(x,y)∈D ∑|y|t=1 log p(yt|y<t,x;θ) (6)

cho một corpus song song D = {(xw, yw)}|D|w=1 chứa |D| cặp câu đơn và bản dịch tương ứng của nó.

### 2.2 NMT dựa trên Transformer nhận biết ngữ cảnh

Một mô hình MT nhận biết ngữ cảnh có thể được coi là một mô hình lấy một tài liệu, tức là nhiều câu, làm đầu vào và tạo ra nhiều câu như bản dịch tương ứng của nó. Chúng tôi giả định rằng mỗi câu được dịch thành một câu đơn, và định nghĩa tài liệu nguồn x = (x1, ..., xn) với n câu và tài liệu ngôn ngữ đích tương ứng y = (y1, ..., yn). Một hệ thống MT nhận biết ngữ cảnh trực tiếp mô hình hóa xác suất dịch thuật

p(y|x;θ) = ∑nk=1 p(yk|y<k,x;θ), (7)

trong đó k là chỉ số tới một câu trong y, y<k là bản dịch một phần trước câu yk. Trong mô hình này, chúng tôi giả định rằng x, y tạo thành một tài liệu song song và mỗi xk, yk tạo thành một câu song song.

Có thể sử dụng một số cách tiếp cận để tạo ra một tài liệu được dịch, tức là giữ một cửa sổ trượt kích thước m (Tiedemann và Scherrer, 2017), nối m câu này làm một đầu vào đơn, dịch m câu này và chọn câu cuối cùng làm đầu ra (m-to-m) (Zhang et al., 2020), hoặc nối toàn bộ câu trong một tài liệu thành một chuỗi rất dài và dịch chuỗi này (Bao et al., 2021), trong số các phương pháp khác. Để đơn giản hóa định nghĩa của mô hình NMT nhận biết ngữ cảnh, chúng tôi chọn phương pháp m-to-m và sử dụng một ký tự đặc biệt (_eos) giữa các câu khi cung cấp m câu này cho mô hình. Bằng cách này, mô hình dịch thuật nhận biết ngữ cảnh vẫn có thể được định nghĩa như một bản dịch theo câu tiêu chuẩn trong §2.1.

### 2.3 Nhiệm vụ Giải quyết đồng tham chiếu

Giải quyết đồng tham chiếu là nhiệm vụ xác định và nhóm tất cả các đề cập hoặc tham chiếu của một thực thể cụ thể trong một văn bản cho trước vào một cụm, tức là một tập hợp các span. Nhiệm vụ này đã tiến bộ đáng kể từ các cách tiếp cận trước đây, dựa trên các hệ thống đặc trưng thủ công (McCarthy và Lehnert, 1995; Aone và William, 1995), đến các cách tiếp cận học sâu tiên tiến và hiệu quả hơn dựa trên xếp hạng span (Lee et al., 2017, 2018; Kirstain et al., 2021) và cho các ngôn ngữ đa ngôn ngữ (Zheng et al., 2023).

Nó thường được công thức hóa như việc xác định rõ ràng một span tiền tố bên trái của một span đề cập trong cùng một cụm. Chính thức hơn, một tập hợp các cụm C = {..., Ck, ...} được dự đoán cho một chuỗi đầu vào x, có thể là một tài liệu hoặc một câu đơn, với mỗi cụm bao gồm một tập hợp các span không chồng lặp Ck = {(i, j) : 1 ≤ i ≤ j ≤ |x|} (1 ≤ k ≤ |C|).

Chúng tôi giới thiệu một góc nhìn thay thế sử dụng một biến A đại diện cho ánh xạ cho tất cả các span đề cập có thể S = {(i, j) : ∀1 ≤ i ≤ j ≤ |x|} của x tới span tiền tố của nó trong cụm mẫu Ck, tức là A = {..., s → c, ...}, trong đó c ∈ Ck là một tiền tố bên trái của s ∈ Ck và c = ε, tức là một span rỗng, khi s không phải là thành viên của bất kỳ cụm Ck nào. Lưu ý rằng chúng ta có thể suy ra một C duy nhất cho một suy diễn đơn của A bằng cách tạo thành một cụm các span được kết nối bởi các liên kết tiền tố, nhưng có nhiều suy diễn của A cho C khi tồn tại một cụm |Ck| > 2. Nhiệm vụ được mô hình hóa bởi phân phối xác suất có điều kiện của việc dự đoán độc lập bất kỳ tiền tố có thể nào của một span đề cập trong cùng một cụm

p(C|x) = ∑A∈a(C) p(A|x)
= ∏s∈S ∑A∈a(C) p(As|s,x)
= ∏s∈S ∑A∈a(C) exp(f(As, s; Hcoref))/∑c∈Ms exp(f(c, s; Hcoref))
≜ ∏s∈S ∑A∈a(C) COREF(As, s; Hcoref), (8)

trong đó a(·) là một hàm trả về tất cả các suy diễn có thể cho các cụm và Ms là một tập hợp tất cả các span có thể bên trái của s bao gồm ε. f(·,·) là một hàm điểm (Kirstain et al., 2021) để tính toán cả điểm số đề cập và tiền tố và Hcoref ∈ R|x|×d là biểu diễn ngữ cảnh hóa của chuỗi đầu vào x, tức là BERT (Devlin et al., 2019). Chúng tôi ký hiệu hàm cuối cùng là COREF(·,·) để ngắn gọn.

Chúng tôi áp dụng lược đồ huấn luyện được đề xuất bởi Kirstain et al. (2021), lọc các span để tránh việc liệt kê rõ ràng tất cả các span đề cập có thể, và biểu diễn các quan hệ tiền tố chỉ sử dụng các điểm cuối của các span được giữ lại với một phép biến đổi bi-affine. Tại giai đoạn huấn luyện, chúng tôi tối thiểu hóa log-likelihood âm của việc dự đoán các cụm

LCOREF = -∑(C,x)∈DCOREF log ∏s∈S ∑A∈a(C) p(As|s,x), (9)

trong đó DCOREF là dữ liệu huấn luyện cho giải quyết đồng tham chiếu.

## 3 MT nhận biết ngữ cảnh với thông tin đồng tham chiếu

Động lực của chúng tôi xuất phát từ quan sát rằng khi dịch một đoạn văn, các dịch giả có thể chọn ra các từ chính xác và giải thích tại sao một lựa chọn từ cụ thể tốt hơn khi có ngữ cảnh, đặc biệt bằng cách dựa vào các tín hiệu ngôn ngữ học như cấu trúc diễn ngôn, sự tương đương động từ, v.v. Do đó, thay vì mô hình hóa một bản dịch bằng cách dựa trực tiếp vào một biến có điều kiện bổ sung của các cụm đồng tham chiếu C cho x, tức là p(y|C,x), chúng tôi đề xuất một mô hình tương tự như khung làm việc kênh nhiễu (Yee et al., 2019), để giải thích quyết định y được thực hiện bởi mô hình dịch thuật:

p(y|C,x) = p(y,C|x)/p(C|x) = p(y|x)p(C|y,x)/p(C|x)
∝ p(y|x)p(C|y,x), (10)

trong đó p(C|y,x) là một mô hình dự đoán các cụm đồng tham chiếu cho cả một câu đầu vào và bản dịch của nó. Lưu ý rằng chúng ta có thể bỏ qua mẫu số p(C|x) vì nó là một hằng số khi dự đoán y, tương tự như mô hình hóa kênh nhiễu, vì cả x và C đều là đầu vào cho mô hình của chúng tôi. Mô hình trực tiếp p(y|C,x) có xu hướng bỏ qua các đặc trưng trong C, đặc biệt khi ngữ cảnh dài, vì thông tin trong x có sự tương ứng trực tiếp với y. Ngược lại, mô hình cho nhiệm vụ giải quyết đồng tham chiếu, p(C|y,x), sẽ giải thích thông tin cụm đồng tham chiếu trong x không chỉ bằng các đặc trưng từ x mà còn các đặc trưng bổ sung từ y và do đó, p(C|y,x) càng cao, y càng có khả năng là một bản dịch cho x. Khi kết hợp với mô hình dịch thuật p(y|x) đặc biệt khi được huấn luyện cùng nhau, công thức của chúng tôi sẽ có thể nắm bắt các quan hệ khoảng cách dài trong các cụm đồng tham chiếu vì nhiệm vụ giải quyết đồng tham chiếu cần dự đoán nó cho x và y.

**Kiến trúc** Hai mô hình con, tức là p(y|x) và p(C|y,x), có thể được huấn luyện riêng biệt như được thực hiện trong cách tiếp cận mô hình hóa kênh nhiễu của MT (Yee et al., 2019). Công trình này công thức hóa nó như một cài đặt đa nhiệm vụ bằng cách dự đoán hai nhiệm vụ cùng nhau, tức là nhiệm vụ dịch thuật và nhiệm vụ giải quyết đồng tham chiếu, bằng cách sử dụng các biểu diễn của encoder và decoder của Vaswani et al. (2017). Cụ thể hơn, chúng tôi không thay đổi nhiệm vụ dịch thuật p(y|x), nhưng thu được biểu diễn cho nhiệm vụ đồng tham chiếu bằng cách kết hợp các biểu diễn của encoder và decoder như sau

p(C|y,x) = ∏s∈S ∑A∈a(C) COREF(As, s; H'coref)
H'coref = DEC(Hleenc, Hlddec). (11)

Lưu ý rằng chúng tôi thu được H'coref từ một lớp decoder bổ sung cho biểu diễn encoder Hleenc với cross attention cho Hlddec.

**Huấn luyện** Chúng tôi huấn luyện cùng nhau hai mô hình con của chúng tôi bằng cách sử dụng biến thể làm mịn nhãn của hàm mất mát entropy chéo trong Phương trình 6 và hàm mất mát log-likelihood biên trong Phương trình 9, nhưng sử dụng H'coref trong Phương trình 11 như sau

L = LMT + αL'COREF, (12)

trong đó α là một siêu tham số kiểm soát sự đóng góp của nhiệm vụ giải quyết đồng tham chiếu. Trong bước huấn luyện, chúng tôi cung cấp các cặp câu cùng với thông tin cụm đồng tham chiếu được tạo ra bởi một khung làm việc giải quyết đồng tham chiếu bên ngoài vì chú thích của con người không có sẵn trong các nhiệm vụ MT.

**Suy luận** Suy luận phức tạp ở chỗ mô hình cho nhiệm vụ giải quyết đồng tham chiếu phải được đánh giá mỗi khi một token đích được tạo ra bởi mô hình dịch thuật như được thực hiện trong cách tiếp cận kênh nhiễu của MT (Yee et al., 2019). Chúng tôi sử dụng một cách tiếp cận đơn giản hơn là bỏ qua thuật ngữ cho các cụm đồng tham chiếu, tức là p(C|y,x), và chỉ sử dụng dự đoán token, tức là p(y|x); hoặc, chúng tôi tạo ra một tập hợp lớn các bản dịch N-best từ p(y|x) và sắp xếp lại chúng bằng cách sử dụng các xác suất kết hợp

log p(y|x) + β log p(C|y,x), (13)

trong đó β là một siêu tham số để kiểm soát sức mạnh của nhiệm vụ giải quyết đồng tham chiếu.

## 4 Thí nghiệm

### 4.1 Bộ dữ liệu

Chúng tôi sử dụng bộ dữ liệu En-Ru (Voita et al., 2019) và bộ dữ liệu chuẩn En-De được áp dụng rộng rãi IWSLT 2017, như được sử dụng trong Maruf et al. (2019), với các chi tiết được cung cấp trong Bảng 1. Chúng tôi cũng sử dụng bộ dữ liệu TED talk đa ngôn ngữ (Qi et al., 2018) để đánh giá hiệu quả của phương pháp đề xuất của chúng tôi trên nhiều loại ngôn ngữ khác nhau, bao gồm các đặc điểm khác nhau trong đại từ, trật tự từ và phân công giới tính với các chi tiết cụ thể được miêu tả trong Bảng 2.

Bộ dữ liệu En-Ru đến từ OpenSubtitle 2018 (Lison et al., 2018) bằng cách lấy mẫu các thực thể huấn luyện với ba câu ngữ cảnh sau khi token hóa và do đó, không có thông tin ranh giới tài liệu nào được bảo tồn. Trong các bộ dữ liệu En-De và đa ngôn ngữ, các ranh giới tài liệu được cung cấp. Để duy trì tính nhất quán trong các cài đặt dịch thuật của chúng tôi trong các thí nghiệm, chúng tôi token hóa tất cả các văn bản bằng cách sử dụng MeCab cho tiếng Nhật, Jieba cho tiếng Trung, VnCoreNLP (Vu et al., 2018) cho tiếng Việt và khung làm việc spaCy cho tất cả các ngôn ngữ khác. Chúng tôi cũng áp dụng một cửa sổ trượt với kích thước m câu (m = 4) cho mỗi tài liệu để tạo ra một định dạng tương tự như bộ dữ liệu En-Ru. Đối với m−1 câu đầu tiên, không có đủ m−1 câu ngữ cảnh trong các cài đặt dịch thuật m-to-m, chúng tôi đệm phần đầu của các câu này bằng các câu trống, đảm bảo m−1 câu ngữ cảnh cho tất cả các mẫu trong bộ dữ liệu. Để tiền xử lý, chúng tôi áp dụng kỹ thuật BPE (Byte-Pair Encoding) từ Sennrich et al. (2016) với 32K thao tác hợp nhất cho tất cả các bộ dữ liệu. Để xác định các cụm đồng tham chiếu cho ngôn ngữ nguồn, tức là tiếng Anh, chúng tôi tận dụng khung làm việc AllenNLP và sử dụng mô hình SpanBERT large (Lee et al., 2018). Sau khi tạo ra các đơn vị từ con, chúng tôi điều chỉnh các chỉ số theo từ của tất cả các thành viên trong các cụm đồng tham chiếu bằng cách sử dụng các offset cho các đơn vị từ con.

### 4.2 Cài đặt thí nghiệm

**Cài đặt dịch thuật** Trong các thí nghiệm của chúng tôi, chúng tôi áp dụng các cài đặt dịch thuật nhận biết ngữ cảnh (m-to-m với m = 4) được sử dụng trong các công trình trước đây (Zhang et al., 2020). Đối với cài đặt không nhận biết ngữ cảnh, chúng tôi dịch từng câu riêng lẻ.

**Hệ thống cơ sở** Chúng tôi áp dụng mô hình Transformer (Vaswani et al., 2017) làm hai đường cơ sở của chúng tôi: Base Sent, được huấn luyện trên các cặp câu nguồn và đích mà không có ngữ cảnh, và Base Doc, được huấn luyện với ngữ cảnh trong cài đặt m-to-m như được mô tả trong §2.2. Để thực hiện so sánh công bằng với các công trình trước đây sử dụng các cài đặt dịch thuật nhận biết ngữ cảnh tương tự và nâng cao hệ thống MT ở phía encoder, chúng tôi sử dụng G-Transformer (Bao et al., 2021), Hybrid Context (Zheng et al., 2020) và MultiResolution (Sun et al., 2022). Chúng tôi cũng so sánh cách tiếp cận của chúng tôi với mô hình CoDoNMT (Lei et al., 2022), cũng tích hợp thông tin giải quyết đồng tham chiếu để cải thiện chất lượng dịch thuật. Lưu ý rằng tất cả các đường cơ sở nêu trên đều sử dụng mã nguồn mở được cung cấp. Ngoài ra, chúng tôi huấn luyện một biến thể đơn giản của mô hình Transformer nhận biết ngữ cảnh tương tự như Base Doc, nhưng khác ở chỗ nó kết hợp một embedding đồng tham chiếu, cùng với embedding vị trí hiện có, trực tiếp vào phía encoder của mô hình (Trans+C-Embedding). Embedding đồng tham chiếu này được suy ra từ embedding vị trí gốc trong encoder với việc sửa đổi rằng tất cả các token trong một cụm đồng tham chiếu chia sẻ cùng một giá trị như token ngoài cùng bên trái trong cùng một cụm. Lưu ý rằng nó được dự định như một đường cơ sở đơn giản cho một mô hình trực tiếp như đã thảo luận trong §3.

**Hệ thống của chúng tôi** Chúng tôi đánh giá các phương pháp suy luận đề xuất của chúng tôi, bao gồm phương pháp suy luận gốc trong Transformer mà không có sắp xếp lại (Trans+COREF) hoặc với sắp xếp lại với điểm số từ mô hình con của chúng tôi (Trans+COREF+RR) sử dụng nhiệm vụ giải quyết đồng tham chiếu như được ký hiệu trong Phương trình 13.

**Phần cứng** Tất cả các mô hình trong thí nghiệm của chúng tôi được huấn luyện trên một máy với các thông số kỹ thuật sau: CPU AMD EPYC 7313P, RAM 256GB, một NVIDIA RTX A6000 với VRAM 48GB, và phiên bản CUDA 11.3. Đối với các thí nghiệm đa ngôn ngữ, chúng tôi sử dụng một GPU NVIDIA RTX 3090 đơn, Intel i9-10940X, VRAM 48GB và phiên bản CUDA 12.1.

**Siêu tham số** Chúng tôi sử dụng cùng các tham số, bao gồm số epoch huấn luyện, tốc độ học, kích thước batch, v.v., cho tất cả các mô hình trong thí nghiệm của chúng tôi. Cụ thể, chúng tôi huấn luyện tất cả các mô hình trong 40 epoch khi cả hai mất mát của đồng tham chiếu và dịch thuật trong tập hợp hợp lệ không thay đổi hoặc không có cải thiện.

Đối với các nhiệm vụ dịch thuật, chúng tôi sử dụng trình tối ưu hóa Adam với β1 = 0.9, β2 = 0.98 và ε = 1e−9, cùng với một bộ lập lịch tốc độ học căn bậc hai nghịch đảo. Tất cả các giá trị dropout được đặt thành 0.1, và tốc độ học được đặt thành 7e−5. Chúng tôi sử dụng kích thước batch là 128 và 32 cho các thí nghiệm trên các bộ dữ liệu tiếng Anh-Nga và tiếng Anh-Đức, tương ứng. Các tham số khác theo những tham số trong Vaswani et al. (2017).

Đối với các nhiệm vụ đồng tham chiếu, chúng tôi áp dụng các tham số từ Kirstain et al. (2021), với một số sửa đổi để phù hợp với bộ nhớ GPU của chúng tôi. Chúng tôi sử dụng trình tối ưu hóa Adam với β1 = 0.9, β2 = 0.98 và ε = 1e−9, với tốc độ học 7e−5. Giá trị dropout được đặt thành 0.3, top lambda (tỷ lệ phần trăm của tất cả các span để giữ lại sau khi lọc) được đặt thành 0.4, kích thước ẩn được đặt thành 512, và độ dài span tối đa được đặt thành 10. Các giá trị cụm tối đa được đặt thành 8 và 20 cho các bộ dữ liệu tiếng Anh-Nga và tiếng Anh-Đức, tương ứng. Để sắp xếp lại các bản dịch N-best, chúng tôi sử dụng Phương trình 13 và thực hiện tìm kiếm lưới trên tập hợp hợp lệ với kích thước bước 0.0001 để chọn giá trị tối ưu cho β từ −2 đến 2.

### 4.3 Chỉ số

**BLEU** Chúng tôi sử dụng SacreBLEU (Post, 2018) như một chỉ số đánh giá tự động để đánh giá chất lượng dịch thuật trong các thí nghiệm của chúng tôi.

**BARTScore** Chúng tôi theo Yuan et al. (2021) và sử dụng mô hình mbart-large-50 (mBART) để tính toán BARTScore trung bình của tất cả bản dịch để đo lường sự tương đương ngữ nghĩa và sự mạch lạc giữa các tham chiếu và bản dịch. Trong chỉ số này, giá trị càng cao, sự tương đương ngữ nghĩa và sự mạch lạc càng tốt.

**COMET** Chúng tôi cũng sử dụng chỉ số COMET (Rei et al., 2020), một thước đo dựa trên mạng neural, vì nó có sự tương quan cao với đánh giá của con người trong công trình trước đây của Freitag et al. (2022).

### 4.4 Kết quả

Các kết quả chính của thí nghiệm của chúng tôi được trình bày trong Bảng 3. Kết quả của chúng tôi cho thấy rằng việc huấn luyện mô hình Transformer cơ sở với cả ngữ cảnh và câu đích (Base Doc) dẫn đến hiệu suất tốt hơn so với việc huấn luyện chỉ với câu đích (Base Sent) trong bộ dữ liệu En-Ru. Phát hiện này phù hợp với những phát hiện được báo cáo bởi Voita et al. (2019), trong đó thông tin ngữ cảnh nhiều hơn hữu ích để đạt được dịch thuật tốt hơn. Tuy nhiên, trong bộ dữ liệu En-De, hệ thống Base Doc hoạt động kém hơn so với hệ thống Base Sent. Sự khác biệt này có thể được giải thích bởi các phương pháp khác nhau được sử dụng trong việc xây dựng các bộ dữ liệu En-De và En-Ru. Đối với các bộ dữ liệu En-De, cả bộ dữ liệu nhận biết ngữ cảnh và không nhận biết ngữ cảnh đều được biên dịch từ cùng một nhóm các câu không trùng lặp. Tuy nhiên, đối với các bộ dữ liệu En-Ru, bộ dữ liệu không nhận biết ngữ cảnh được tạo ra bằng cách loại bỏ các câu ngữ cảnh khỏi bộ dữ liệu nhận biết ngữ cảnh (Voita et al., 2019), dẫn đến số lượng câu không trùng lặp khác nhau giữa các bộ dữ liệu không nhận biết ngữ cảnh và nhận biết ngữ cảnh này.

Khi so sánh các hệ thống của chúng tôi với mô hình Transformer (Base Doc), các cách tiếp cận của chúng tôi, cả Trans+COREF và Trans+COREF+RR, đã chứng minh hiệu quả trong việc nâng cao chất lượng dịch thuật bằng cách giải thích quyết định dịch thuật thông qua việc dự đoán thông tin đồng tham chiếu. Điều này được thể hiện bởi các điểm số BLEU vượt trội (+0.52 trong En-Ru và +2.06 trong En-De cho Trans+COREF+RR), BARTScore và COMET quan sát được khi so sánh qua các cài đặt và cặp ngôn ngữ khác nhau.

So với hệ thống G-Transformer được mô tả trong Bao et al. (2021), hệ thống của chúng tôi cho thấy sự cải thiện trong cả hai cách tiếp cận suy luận (Trans+COREF và Trans+COREF+RR). Trong bộ dữ liệu En-Ru, hệ thống của chúng tôi đạt điểm số BLEU cao hơn +0.24, trong khi trong bộ dữ liệu En-De, nó thể hiện sự cải thiện lớn hơn +1.14 trong cùng một chỉ số (Trans+COREF). Ngoài ra, phương pháp của chúng tôi vượt trội hơn G-Transformer về BARTScore và COMET cho cả bộ dữ liệu En-Ru và En-De. Một giải thích có thể cho các kết quả này là G-Transformer được thiết kế đặc biệt để ánh xạ mỗi câu trong ngôn ngữ nguồn chỉ tới một câu đơn trong ngôn ngữ đích trong cả bước huấn luyện và suy luận. Lựa chọn thiết kế này giúp giảm thiểu các vấn đề liên quan đến việc tạo ra các chuỗi rất dài. Tuy nhiên, khi kích thước bộ dữ liệu nhỏ, như trong trường hợp của bộ dữ liệu En-De, G-Transformer gặp khó khăn trong việc lựa chọn thông tin hữu ích. Ngược lại, cách tiếp cận của chúng tôi hiệu quả lựa chọn thông tin hữu ích một cách gián tiếp thông qua mô hình con giải thích đồng tham chiếu, đặc biệt khi xử lý các bộ dữ liệu có kích thước nhỏ, cho phép hệ thống của chúng tôi vượt trội trong các kịch bản với kích thước bộ dữ liệu hạn chế. Phương pháp của chúng tôi cũng vượt trội hơn mô hình Transformer với embedding vị trí bổ sung (Trans+C-Embedding), dựa vào thông tin đồng tham chiếu sử dụng cách tiếp cận mô hình hóa trực tiếp.

Trong các kết quả của bộ dữ liệu TED talk đa ngôn ngữ trong Bảng 4, nơi chúng tôi so sánh phương pháp đề xuất của chúng tôi với các mô hình Transformer và các đường cơ sở tốt nhất trong Bảng 3, phương pháp của chúng tôi cũng vượt trội hơn các đường cơ sở khác trong phạm vi +1.0 đến +2.3 điểm số BLEU. Các phát hiện này cung cấp bằng chứng thêm rằng cách tiếp cận của chúng tôi hiệu quả trong việc cải thiện chất lượng dịch thuật và có thể được áp dụng cho các loại ngôn ngữ đa dạng.

Chúng tôi cung cấp một ví dụ về bản dịch từ các hệ thống của chúng tôi cũng như các hệ thống đường cơ sở khác trong Bảng 5. Trong ví dụ này, bản dịch chính xác của cụm từ trong câu cuối cùng, моей командой (đội của tôi), được xác định bằng cách nhận biết từ nào đề cập đến "my", trong trường hợp này là i và me. Cả hệ thống G-Transformer và Trans+C-Embedding đều thất bại trong việc nắm bắt các đề cập này và do đó tạo ra bản dịch không chính xác, мою команду. Mặc dù dịch chính xác моей, cụm từ встретимся в моей команде của hệ thống Base Doc không chính xác về mặt ngữ pháp và lệch khỏi tiếng Anh gốc "meet my team". Ngược lại, các hệ thống của chúng tôi nắm bắt tham chiếu này một cách chính xác, tạo ra bản dịch phù hợp với tham chiếu.

## 5 Phân tích

**Đóng góp của giải thích đồng tham chiếu** Chúng tôi đã tiến hành các thí nghiệm bằng cách điều chỉnh giá trị của α trong Phương trình 12 trong quá trình huấn luyện Trans+COREF mà không có sắp xếp lại. Kết quả thí nghiệm trong Bảng 6 cho thấy rằng đối với các corpus có kích thước trung bình, việc chọn giá trị α quá nhỏ hoặc quá lớn đều ảnh hưởng tiêu cực đến chất lượng dịch thuật. Phạm vi tối ưu cho α là 0.8 ≤ α ≤ 2.

**Điều kiện hóa trên ngôn ngữ nguồn và đích** Chúng tôi tiến hành một nghiên cứu về giải thích đồng tham chiếu trên bộ dữ liệu En-De (Maruf et al., 2019) với thông tin cụm đồng tham chiếu như trong §4.1 bằng cách loại bỏ thông tin từ bản dịch để nó chỉ điều kiện hóa trên thông tin đầu vào (Trans+ENC). Cài đặt này có thể được coi là một cài đặt học đa nhiệm vụ thông thường trong đó đồng tham chiếu ở phía đầu vào được dự đoán cùng với bản dịch của nó. Cụ thể, chúng tôi thay thế biểu diễn đầu vào cho mô hình con giải quyết đồng tham chiếu từ DEC(·) trong Phương trình 11 thành ENC(·) trong Phương trình 14 như sau

H''coref = ENC(Hleenc). (14)

Như được thể hiện trong Bảng 7, cài đặt học đa nhiệm vụ thông thường của Trans+ENC hoạt động kém hơn Trans+COREF, điều này cho thấy lợi ích của việc kết hợp thông tin từ bản dịch được dự đoán. Chúng tôi tiếp tục kiểm tra các bản đồ nhiệt thực thể được suy ra từ trọng số self-attention của cả mô hình con dịch thuật và đồng tham chiếu trong các hệ thống Base Doc, Trans+ENC, và Trans+COREF cho đầu vào "I_0 hate that you_0're leaving . Well , Grandma's not doing well . So you_1 have to drop everything to go take care of her ? Yes , William , I_1 do ." từ bộ kiểm tra được chú thích bởi con người từ Voita et al. (2019). Trong ví dụ cụ thể này, các cụm đồng tham chiếu được định nghĩa là [I_0, William], [you_0, you_1, I_1], và [Grandma, her]. Để cung cấp các biểu diễn trực quan, chúng tôi mô tả các giá trị self-attention trung bình từ lớp encoder cuối cùng của ba hệ thống này. Lựa chọn này dựa trên xu hướng của chúng tập trung nhiều hơn vào thông tin ngữ nghĩa hoặc trừu tượng (Clark et al., 2019).

Hình 1 hiển thị các bản đồ nhiệt thực thể, minh họa hành vi của self-attention trong các hệ thống khác nhau trong mô hình con dịch thuật. Trong hệ thống Base Doc, self-attention chủ yếu tập trung vào các câu cục bộ trong khi bỏ qua thông tin giữa các câu. Ngược lại, hệ thống Trans+ENC thể hiện khả năng tập trung vào liên-câu. Tuy nhiên, khi nói đến các token trong các cụm đồng tham chiếu, các giá trị tập trung không chính xác cho một số cụm nhất định, chẳng hạn như [I_0, William]. Mặt khác, hệ thống Trans+COREF không chỉ thể hiện sự tập trung liên-câu trong bản đồ nhiệt self-attention của nó mà còn mô tả chính xác các giá trị tập trung cho các token trong các cụm đồng tham chiếu.

Hình 2 thể hiện các bản đồ nhiệt thực thể trong mô hình con đồng tham chiếu. Trong hệ thống Trans+ENC, self-attention chủ yếu tập trung vào các thực thể trong phạm vi cục bộ và các câu liền kề ngay lập tức. Tuy nhiên, khi so sánh các giá trị attention cao này với các liên kết trong các cụm đồng tham chiếu, một tỷ lệ đáng kể được tìm thấy là không chính xác, tức là [Grandma; I_1]. Mặt khác, self-attention trong Trans+COREF thể hiện sự phân phối tập trung cân bằng hơn trên tất cả các thực thể trong đầu vào. Sự phân phối cân bằng này dẫn đến ít lỗi hơn đáng kể khi so sánh với self-attention trong hệ thống Trans+ENC. Các phát hiện này phù hợp với chỉ số MUC (Vilain et al., 1995), dựa trên số lượng tối thiểu các liên kết thiếu trong các thực thể phản hồi so với các thực thể chính, với các chi tiết, đặc biệt là điểm số F1, được cung cấp trong Bảng 7. Lưu ý rằng chúng tôi sử dụng các bản dịch tham chiếu để tạo thành Hlddec trong Phương trình 11 để xác định các cụm đồng tham chiếu. Ngoài ra, chúng tôi tạo ra các cụm đồng tham chiếu nhãn vàng bằng cách sử dụng khung làm việc AllenNLP, như đã thảo luận trong Phần 4.1.

**Tác động của kích thước ngữ cảnh** Chúng tôi tiến hành các thí nghiệm với các hệ thống COREF (Trans+COREF) và Transformer (Base Doc) bằng cách khám phá các kích thước ngữ cảnh khác nhau trong các cài đặt m-to-m từ 2 đến 4. Kết quả thí nghiệm trong Hình 3 cho thấy rằng hệ thống Base Doc giảm đáng kể chất lượng dịch thuật khi ngữ cảnh dài hơn, trong khi Trans+COREF liên tục đạt được lợi ích khi chúng tôi kết hợp thêm ngữ cảnh. Kết quả này cũng cho thấy việc sử dụng mô hình con đồng tham chiếu có thể nắm bắt thông tin ngữ cảnh tốt hơn đường cơ sở.

**Tác động của giải thích đồng tham chiếu** Chúng tôi tiến hành các thí nghiệm bằng cách sắp xếp lại tất cả các giả thuyết dịch thuật với các kích thước beam khác nhau trong quá trình suy luận bằng Phương trình 13 để đánh giá tác động của mô hình con giải thích đồng tham chiếu trên bộ dữ liệu En-Ru (Voita et al., 2019). Hình 4 minh họa kết quả của các thí nghiệm của chúng tôi được đo bằng điểm số BLEU. Phát hiện của chúng tôi cho thấy rằng việc sắp xếp lại với mô hình con COREF mang lại kết quả được cải thiện, với sự khác biệt từ 0.02 đến 0.09. Chúng tôi cũng báo cáo điểm số BLEU oracle trong Hình 5, được đo bằng cách chọn một câu giả thuyết mang lại điểm số BLEU-câu tối đa trong số các giả thuyết tiềm năng, để xác minh các bản dịch có khả năng chính xác trong danh sách N-best. Kết quả của thí nghiệm này với sự khác biệt từ 0.2 đến 0.4 cho thấy rằng việc sử dụng mô hình con COREF có tiềm năng hơn để tạo ra các bản dịch chính xác. Mặc dù sự khác biệt tương đối nhỏ trong điểm số BLEU oracle giữa các hệ thống Trans+COREF và Base Doc, cho thấy sự tương tự trong không gian ứng cử viên của chúng, quá trình tìm kiếm beam mang lại kết quả tốt hơn với Trans+COREF khi so sánh với hệ thống Base Doc. Điều này phản ánh sự khác biệt trong điểm số BLEU giữa Trans+COREF và Base Doc. Khoảng cách hiệu suất trong điểm số BLEU giữa Trans+COREF và Trans+COREF+RR có thể được tối đa hóa thêm bằng cách kết hợp giải quyết đồng tham chiếu trong quá trình tìm kiếm beam với chi phí tính toán nhiều hơn. Chúng tôi dự định khám phá khả năng này trong các nỗ lực nghiên cứu tương lai của chúng tôi.

Để hiểu rõ hơn về tác động của mô hình con giải thích đồng tham chiếu đối với kết quả dịch thuật, chúng tôi thực hiện một thí nghiệm trên bài kiểm tra đối chiếu trong Voita et al. (2019), chứa các câu được gán nhãn bởi con người để đánh giá các hiện tượng diễn ngôn và chỉ dựa vào văn bản nguồn, để xác minh liệu phương pháp của chúng tôi có thể giải quyết các hiện tượng ở cấp độ tài liệu hay không. Bảng 8 trình bày kết quả thí nghiệm này, cho thấy rằng hệ thống của chúng tôi vượt trội hơn hệ thống Base Doc trong tất cả các khía cạnh. Các kết quả này chứng minh sự đóng góp đáng kể của mô hình con giải thích đồng tham chiếu cho hệ thống MT.

**Tác động của độ chính xác đồng tham chiếu** Chúng tôi thực hiện các thí nghiệm để đánh giá tác động của các độ chính xác khác nhau trong khung làm việc đồng tham chiếu bên ngoài, được báo cáo trong 80.4% điểm số F1 trên chỉ số MUC cho nhiệm vụ chia sẻ CoNLL-2012 tiếng Anh trong Lee et al. (2018), đối với chất lượng dịch thuật tổng thể. Điều này được thực hiện bằng cách loại bỏ ngẫu nhiên các thành viên khỏi các cụm đồng tham chiếu trong khi đảm bảo rằng mỗi cụm hợp lệ giữ lại tối thiểu hai thành viên, tức là loại bỏ you_1 khỏi cụm [you_0, you_1, I_1] trong Hình 1.

Bảng 9 trình bày kết quả của các thí nghiệm này, nơi quan sát được sự giảm nhẹ về chất lượng dịch thuật khi các thành viên của các cụm đồng tham chiếu bị loại bỏ ngẫu nhiên. Đáng chú ý, ngay cả khi loại bỏ đến một nửa số thành viên cụm, kết quả vẫn tiếp tục vượt trội so với hiệu suất của hệ thống Base Doc. Điều này ngụ ý rằng phương pháp của chúng tôi có thể mạnh mẽ và hiệu quả, đặc biệt đối với các ngôn ngữ có độ chính xác hạn chế trong các nhiệm vụ giải quyết đồng tham chiếu.

**Tác động của kích thước corpus** Chúng tôi lấy mẫu ngẫu nhiên các thực thể huấn luyện từ bộ dữ liệu En-Ru và thay đổi kích thước mẫu thành 200,000 (kích thước có thể so sánh với bộ dữ liệu En-De), 500,000, và 1,000,000. Sau đó, chúng tôi đánh giá sự đóng góp của mô hình con COREF (Trans+COREF) và Transformer (Base Doc) trên các bộ dữ liệu có kích thước mẫu khác nhau này. Hình 6 minh họa kết quả của các thí nghiệm này. Hệ thống đề xuất của chúng tôi vượt trội hơn mô hình Transformer (Base Doc) trên tất cả các kích thước mẫu trong tập kiểm tra. Đáng chú ý, sự cải thiện này không chỉ giới hạn trong cài đặt kích thước bộ dữ liệu nhỏ mà các xu hướng tương tự được quan sát đối với các bộ dữ liệu có kích thước trung bình. Các kết quả này cho thấy rằng hệ thống của chúng tôi liên tục vượt trội hơn mô hình transformer và đạt được chất lượng dịch thuật được cải thiện bất kể kích thước bộ dữ liệu.

**Các thách thức còn lại và câu hỏi chưa được giải quyết** Trong khi phương pháp đề xuất của chúng tôi và các công trình hiện có nâng cao độ chính xác dịch thuật cho một số hiện tượng ngôn ngữ học nhất định, các thách thức vẫn tồn tại, đặc biệt trong việc xử lý deixis. Không giống như các kịch bản đơn giản nơi ngữ cảnh bổ sung hỗ trợ trong việc dịch chính xác các thuật ngữ deixis (ví dụ: xác định người nói trong một cuộc hội thoại để dịch chính xác các từ I và You), một số trường hợp yêu cầu hiểu biết toàn diện về nội dung của văn bản được cung cấp để đạt được dịch thuật đại từ chính xác. Xem xét ví dụ sau đây từ dữ liệu kiểm tra của bộ dữ liệu tiếng Anh-Việt (Qi et al., 2018): "Oh my god! you're right! who can we[chúng ta] sue? Now Chris is a really brilliant lawyer, but he knew almost nothing about patent law and certainly nothing about genetics. I knew something about genetics, but I wasn't even a lawyer, let alone a patent lawyer. So clearly we[chúng tôi] had a lot to learn before we[chúng ta] could file a lawsuit." Trong ngữ cảnh này, từ tiếng Anh we được dịch là chúng tôi (we[chúng tôi]) hoặc chúng ta (we[chúng ta]), phản ánh việc loại trừ hoặc bao gồm người nghe. Ví dụ này nhấn mạnh tầm quan trọng của các sắc thái ngữ cảnh trong việc dịch các đại từ như we hoặc us từ tiếng Anh sang tiếng Việt, nơi sự lựa chọn giữa chúng tôi và chúng ta là quan trọng.

Dựa trên những hiểu biết từ ví dụ được mô tả, chúng tôi trích xuất tất cả các mẫu đặt ra các thách thức ngôn ngữ học tương tự, trong đó một mẫu được dịch chính xác phải đảm bảo rằng mỗi trường hợp của từ we được dịch chính xác. Bảng 10 trình bày độ chính xác của việc dịch từ we thành tiếng Việt chính xác. Trong khi phương pháp của chúng tôi vượt trội hơn các mô hình đường cơ sở khác về hiệu suất, nó vẫn thể hiện độ chính xác thấp hơn so với các kết quả liên quan đến deixis của bài kiểm tra đối chiếu cho tiếng Nga (Voita et al., 2019). Sự khác biệt này làm nổi bật hiện tượng như một thách thức đáng kể cần điều tra thêm.

**Chi phí tính toán** Chúng tôi trình bày so sánh chi tiết về số lượng tham số và thời gian huấn luyện mỗi epoch cho phương pháp đề xuất của chúng tôi cùng với các đường cơ sở khác trong Bảng 11. Khi so sánh với G-Transformer, phương pháp của chúng tôi sử dụng ít tham số hơn, mất ít thời gian huấn luyện hơn, và vẫn đạt được hiệu suất tốt hơn. Mặt khác, hệ thống Base Doc sử dụng ít tham số nhất và huấn luyện nhanh nhất, nhưng kết quả của nó đáng chú ý là kém hiệu suất.

## 6 Các công trình liên quan

Học đa nhiệm vụ chủ yếu được sử dụng trong các nhiệm vụ MT để tích hợp kiến thức bên ngoài vào các hệ thống MT. Luong et al. (2016); Niehues và Cho (2017); Eriguchi et al. (2017) đã sử dụng học đa nhiệm vụ với các biến thể khác nhau của trọng số được chia sẻ của encoder, decoder, hoặc attention giữa các nhiệm vụ để hiệu quả kết hợp kiến thức phân tích cú pháp vào các hệ thống MT chuỗi-tới-chuỗi.

Để kết hợp thông tin cụm đồng tham chiếu, Ohtani et al. (2019), Xu et al. (2021) và Lei et al. (2022) kết hợp thông tin cụm đồng tham chiếu để cải thiện các mô hình NMT của họ. Ohtani et al. (2019) tích hợp thông tin cụm đồng tham chiếu vào một cách tiếp cận NMT dựa trên đồ thị để nâng cao thông tin. Tương tự, Xu et al. (2021) sử dụng thông tin để kết nối các từ qua các câu khác nhau và kết hợp thông tin phân tích cú pháp khác để xây dựng một đồ thị ở cấp độ tài liệu, dẫn đến sự cải thiện trong chất lượng dịch thuật. Lei et al. (2022) sử dụng thông tin đồng tham chiếu để xây dựng các che phủ sự kết dính và tinh chỉnh các hệ thống MT câu để tạo ra các đầu ra có sự kết dính hơn.

Mặt khác, Stojanovski và Fraser (2018); Hwang et al. (2021) tận dụng thông tin cụm đồng tham chiếu thông qua các bước tăng cường. Họ hoặc thêm nhiễu để xây dựng một bộ dữ liệu tăng cường đồng tham chiếu hoặc sử dụng thông tin đồng tham chiếu để tạo ra một bộ dữ liệu đối chiếu và huấn luyện các hệ thống MT của họ trên các bộ dữ liệu được nâng cao này để đạt được hiệu suất dịch thuật tốt hơn. Đối với MT nhận biết ngữ cảnh, Kuang et al. (2018) và Tu et al. (2018) tập trung vào việc sử dụng các mạng neural tăng cường bộ nhớ, lưu trữ và truy xuất các phần đã dịch trước đây trong các hệ thống NMT. Các cách tiếp cận này giúp thống nhất việc dịch các đối tượng, tên và các yếu tố khác qua các câu khác nhau trong một đoạn văn. Ngược lại, Xiong et al. (2019); Voita et al. (2019) phát triển một phương pháp giải mã đa lượt lấy cảm hứng từ Mạng Cân nhắc (Xia et al., 2017) để giải quyết các vấn đề về sự mạch lạc, tức là deixis và ellipsis trong các đoạn văn. Họ đầu tiên dịch các câu nguồn trong lượt đầu tiên và sau đó sửa chữa các bản dịch để cải thiện sự mạch lạc trong lượt thứ hai. Mansimov et al. (2020) giới thiệu một kỹ thuật tự huấn luyện, tương tự như tự thích ứng miền, để phát triển một hệ thống NMT cấp độ tài liệu. Trong khi đó, các phương pháp khác nhau nhằm đóng gói thông tin ngữ cảnh, tức là attention phân cấp (Maruf et al., 2019), cơ chế đa attention (Zhang et al., 2020; Bao et al., 2021), đơn vị bộ nhớ hồi quy (Feng et al., 2022). Trong một cách tiếp cận tăng cường dữ liệu, Bao et al. (2023) đa dạng hóa dữ liệu huấn luyện cho phía ngôn ngữ đích, thay vì chỉ sử dụng một bản dịch con người duy nhất cho mỗi tài liệu nguồn.

Gần đây, Wang et al. (2023) đã cho thấy rằng các Mô hình Ngôn ngữ Lớn (LLM) hiện đại, tức là GPT-4 (OpenAI et al., 2024), vượt trội hơn các mô hình dịch thuật truyền thống trong MT nhận biết ngữ cảnh. Trong các cách tiếp cận khác, Wu et al. (2024) và Li et al. (2024) đã phát triển các phương pháp tinh chỉnh và dịch thuật hiệu quả cho các LLM nhẹ; tuy nhiên, hiệu quả của các mô hình NMT có thể vượt trội hơn các LLM nhẹ, thay đổi theo cặp ngôn ngữ.

## 7 Kết luận

Nghiên cứu này trình bày một mô hình MT nhận biết ngữ cảnh giải thích đầu ra dịch thuật bằng cách dự đoán các cụm đồng tham chiếu ở phía nguồn. Mô hình bao gồm hai mô hình con, một mô hình con dịch thuật và một mô hình con giải quyết đồng tham chiếu, mà không có sửa đổi nào đối với mô hình dịch thuật. Mô hình con giải quyết đồng tham chiếu dự đoán các cụm đồng tham chiếu bằng cách kết hợp biểu diễn từ cả encoder và decoder để nắm bắt các quan hệ trong hai ngôn ngữ một cách rõ ràng. Trong cùng các cài đặt của các bộ dữ liệu En-Ru, En-De và đa ngôn ngữ, và theo các phân tích về đóng góp của mô hình con đồng tham chiếu, tác động của ngữ cảnh và kích thước corpus, cũng như loại thông tin được sử dụng trong mô hình con, phương pháp đề xuất của chúng tôi đã chứng minh hiệu quả trong việc nâng cao chất lượng dịch thuật.

## Hạn chế

Trong nghiên cứu này, kích thước chiều ẩn trong mô hình con giải quyết đồng tham chiếu nhỏ hơn so với các hệ thống hiện đại điển hình, tức là 512 so với 2048, có thể hạn chế độ chính xác của nó và ảnh hưởng tiêu cực đến chất lượng dịch thuật. Ngoài ra, nghiên cứu này yêu cầu tinh chỉnh cho một siêu tham số nhất định kết hợp mô hình con giải quyết đồng tham chiếu và mô hình dịch thuật để đạt được kết quả thỏa mãn.

## Lời cảm ơn

Các tác giả biết ơn các nhà phản biện ẩn danh và Biên tập viên Hành động đã cung cấp nhiều nhận xét sâu sắc giúp cải thiện bài báo. Công trình này được hỗ trợ bởi Học bổng JSPS KAKENHI Số JP21H05054.

## Tài liệu tham khảo

[Danh sách tài liệu tham khảo dài với 203 mục được dịch theo format gốc]

# 2402.08015.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/multilingual/2402.08015.pdf
# Kích thước tệp: 1570372 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Walia-LLM: Nâng cao Amharic-LLaMA bằng cách Tích hợp Dữ liệu Cụ thể theo Tác vụ và Dữ liệu Sinh tạo
Israel Abebe Azime1, Atnafu Lambebo Tonja2,3, Tadesse Destaw Belay2, Mitiku Yohannes Fuge4,
Aman Kassahun Wassie4, Eyasu Shiferaw Jada, Yonas Chanie5, Walelign Tewabe Sewunetie6,
Seid Muhie Yimam7
∀Masakhane NLP,∀Ethio NLP,1Đại học Saarland, Đức, ,2Instituto Politécnico Nacional, Mexico,3Lelapa AI,4AIMS
5Đại học Carnegie Mellon,6Đại học Debre Markos,7Đại học Hamburg, Đức

Tóm tắt
Các mô hình ngôn ngữ lớn (LLMs) đã nhận được nhiều sự chú ý trong nghiên cứu xử lý ngôn ngữ tự nhiên (NLP) do hiệu suất vượt trội của chúng trong việc hiểu và sinh ngôn ngữ con người. Tuy nhiên, các ngôn ngữ ít tài nguyên bị bỏ lại phía sau do không có tài nguyên sẵn có. Trong công trình này, chúng tôi tập trung vào việc nâng cao mô hình LLAMA-2-Amharic bằng cách tích hợp các tập dữ liệu cụ thể theo tác vụ và dữ liệu sinh tạo để cải thiện hiệu suất mô hình ngôn ngữ cho tiếng Amharic. Chúng tôi biên soạn một tập dữ liệu tinh chỉnh hướng dẫn tiếng Amharic và tinh chỉnh mô hình LLAMA-2-Amharic. Mô hình được tinh chỉnh cho thấy kết quả đầy hứa hẹn trong các tác vụ NLP khác nhau. Chúng tôi cũng khám phá tính hiệu quả của các tập dữ liệu hướng dẫn được dịch so với tập dữ liệu chúng tôi tạo ra. Quy trình tạo dữ liệu của chúng tôi, cùng với các tập dữ liệu hướng dẫn, các mô hình được huấn luyện và đầu ra đánh giá, được công khai để khuyến khích nghiên cứu về các mô hình cụ thể cho ngôn ngữ.1

1 Giới thiệu
Các mô hình ngôn ngữ lớn (LLMs) như dòng GPT (Brown et al., 2020), LLAMA-2 (Touvron et al., 2023), Phi2 (Javaheripi et al., 2023), Mistral (Jiang et al., 2023), Mixtral (Jiang et al., 2024), PaLM (Chowdhery et al., 2023), Gemini (Team et al., 2023), BLOOM (Workshop et al., 2022), đã thể hiện hiệu suất vượt trội trong việc hiểu và sinh ngôn ngữ con người, thể hiện một loạt khả năng từ hiểu ngôn ngữ cơ bản đến sinh văn bản phức tạp.

LLAMA-2 (Touvron et al., 2023), một họ các mô hình ngôn ngữ lớn (LLMs) được huấn luyện trước và tinh chỉnh, đã thể hiện hiệu suất ấn tượng trên nhiều tác vụ, đặc biệt trong các tương tác dựa trên đối thoại. Bất chấp những thành tựu này, việc huấn luyện trước LLAMA-2 chỉ hỗ trợ một số lượng nhỏ các ngôn ngữ, không bao gồm các ngôn ngữ ít tài nguyên như tiếng Amharic. Điều này khiến việc thích ứng LLMs với các ngôn ngữ ít tài nguyên không được bao gồm trở thành một thách thức đáng kể.

Áp dụng các LLMs này cho ngôn ngữ địa phương đòi hỏi việc chuẩn bị một tập dữ liệu hướng dẫn chất lượng. Tiếng Amharic là một trong những ngôn ngữ Semitic thuộc họ ngôn ngữ Afroasiatic được nói ở Ethiopia với hơn 57 triệu người nói. Có nhiều tập dữ liệu cụ thể theo tác vụ cho tiếng Amharic (Tonja et al., 2023) so với các ngôn ngữ Ethiopia khác. Bài báo này tập trung vào việc nâng cao mô hình LLAMA-2-Amharic (Andersland, 2024) với các tập dữ liệu chất lượng được tạo ra bằng cách chuyển đổi các tập dữ liệu hiện có bằng tiếng Anh thành các tập dữ liệu tiếng Amharic dựa trên hướng dẫn. Hơn nữa, chúng tôi tạo ra các tập dữ liệu hướng dẫn mới theo phương pháp của Wei et al. (2022).

Mô hình LLAMA-2-Amharic của Andersland (2024) được tạo ra bằng cách huấn luyện trước mô hình LLAMA-2 7B sử dụng kho ngữ liệu tiếng Amharic mã nguồn mở và được dịch. Sau khi thực hiện mở rộng từ vựng và huấn luyện trước, Andersland (2024) đã tinh chỉnh mô hình được tạo ra bằng cách dịch các tập dữ liệu hướng dẫn tiếng Anh sang tiếng Amharic sử dụng các công cụ dịch thương mại. Trong nghiên cứu của chúng tôi, chúng tôi nhằm mục đích cải thiện hiệu suất của mô hình LLAMA tiếng Amharic bằng cách tích hợp các tập dữ liệu cụ thể theo tác vụ và dữ liệu sinh tạo, như thể hiện trong Bảng 1. Những đóng góp của bài báo này như sau:

• Tạo ra dữ liệu tinh chỉnh hướng dẫn tiếng Amharic từ các tập dữ liệu cụ thể theo tác vụ NLP và dữ liệu sinh tạo hiện có.
• Đánh giá hiệu suất của các mô hình mới và hiện có.
• Khám phá tác động của các tập dữ liệu được tuyển chọn cẩn thận bằng cách kết hợp chúng với các tập dữ liệu hướng dẫn được dịch máy.
• Khám phá tác động của các hướng dẫn lên hiệu suất của mô hình bằng cách giới thiệu các hướng dẫn trộn mã.
• Mở nguồn quy trình tạo dữ liệu của chúng tôi, các tập dữ liệu hướng dẫn, các mô hình được huấn luyện và đầu ra đánh giá để thúc đẩy các nghiên cứu cụ thể về ngôn ngữ trên các mô hình này.

2 Nghiên cứu liên quan
Việc giới thiệu các LLMs mã nguồn mở như LLAMA-2 (Touvron et al., 2023) đã cho phép tạo ra nhiều mô hình ngôn ngữ tập trung vào các ứng dụng cụ thể. Ứng dụng này mang lại nhiều khả năng hơn cho các LLMs này bằng cách dạy chúng sử dụng công cụ (Schick et al., 2023), viết mã (Roziere et al., 2023), hiểu video (Zhang et al., 2023a), hoặc làm việc với các ngôn ngữ khác nhau (Cui et al., 2023). Để đạt được khả năng hiểu và sinh tạo đáng kể, LLMs yêu cầu dữ liệu huấn luyện lớn và tài nguyên tính toán khổng lồ (Hoffmann et al., 2022).

Công trình của Dong et al. (2023) khám phá cách khả năng sinh tạo, hiểu ngôn ngữ tự nhiên và giải quyết vấn đề của LLMs liên quan đến dữ liệu chúng được huấn luyện và thành phần của nó. Công trình này cho thấy rằng lượng dữ liệu thành phần quan trọng hơn đối với việc thể hiện các khả năng này trong tình huống ít tài nguyên.

Sử dụng tinh chỉnh tự hướng dẫn, công trình của Wei et al. (2022); Taori et al. (2023); Cui et al. (2023) đã chỉ ra một phương pháp mới để căn chỉnh đầu ra sinh tạo của các mô hình sinh tạo thông qua việc áp dụng các tác vụ NLP. Các tác vụ này được cấu trúc xung quanh các mẫu hướng dẫn ngôn ngữ tự nhiên, cung cấp một phương tiện mới để hướng dẫn quá trình sinh tạo của mô hình hướng tới việc tuân thủ tốt hơn các yêu cầu cụ thể theo tác vụ. LLAMA-Adapter (Zhang et al., 2023b) cũng cho thấy rằng có thể giảm thời gian tinh chỉnh của LLAMA-7B bằng cách giới thiệu các bộ chuyển đổi nhẹ trên đầu mô hình.

Việc thu thập và chuẩn bị tập dữ liệu cho tinh chỉnh hướng dẫn gặp thách thức đáng kể do cần lao động và tài nguyên rộng lớn. Có nhiều cách để thu thập dữ liệu hướng dẫn, bao gồm tạo tập dữ liệu thủ công, sử dụng các mô hình sinh tạo (Wang et al., 2022; Taori et al., 2023), hoặc sử dụng dữ liệu hướng dẫn dịch máy để huấn luyện LLMs cho các ngôn ngữ cụ thể (Cui et al., 2023).

Tinh chỉnh LLMs như LLAMA-2 cho các tác vụ cụ thể cũng là một lĩnh vực khám phá. Bộ dịch dựa trên mô hình ngôn ngữ tiên tiến (ALMA) (Xu et al., 2023) đã vượt trội hơn mô hình không để lại ngôn ngữ nào phía sau (NLLB) (NLLB Team et al., 2022) tiên tiến nhất (SOTA) trong tác vụ MT. Họ đã làm việc về việc tinh chỉnh dữ liệu đơn ngữ và tinh chỉnh tiếp theo với dữ liệu song song. Ngoài LLAMA-2, (Moslem et al., 2023) đã làm việc về tinh chỉnh Mistral 7B cho dịch máy lĩnh vực y tế, nơi họ cho thấy sự cải thiện trong việc dịch từ tiếng Tây Ban Nha sang tiếng Anh so với hiệu suất cơ sở.

Sau khi LLAMA-2 được phát hành, các nhà nghiên cứu đã thành công trong việc thích ứng mô hình cho các ngôn ngữ khác. Công trình của Cui et al. (2023) bao gồm việc tạo ra một tokenizer độc đáo cho tiếng Trung, mở rộng giai đoạn huấn luyện trước, và sau đó tinh chỉnh mô hình. Công trình này kết hợp huấn luyện trước thứ cấp sử dụng dữ liệu tiếng Trung và tinh chỉnh mô hình với các tập dữ liệu hướng dẫn tiếng Trung. Kết quả cho thấy sự nâng cao đáng kể khả năng hiểu và thực hiện hướng dẫn của mô hình.

Theo cùng phương pháp của công trình Cui et al. (2023), LLAMA-2 cũng được áp dụng cho tiếng Amharic (Andersland, 2024). Trong quá trình huấn luyện trước, Andersland (2024) đã sử dụng một kho ngữ liệu tiếng Amharic mã nguồn mở với một số kho ngữ liệu được dịch từ tiếng Anh, và để tinh chỉnh, các tập dữ liệu hướng dẫn tiếng Anh có sẵn được dịch sang tiếng Amharic sử dụng Google Translate API và SeamlessM4T. Sau khi tăng kích thước từ vựng LLAMA từ 32k lên 51k và huấn luyện trước tiếp theo với kho ngữ liệu văn bản tiếng Amharic lớn, họ đã tiến hành tinh chỉnh hướng dẫn có giám sát sử dụng các tập dữ liệu được dịch máy. Sau đó, họ đánh giá mô hình của mình sử dụng tập dữ liệu tiếng Anh trắc nghiệm nhiều lựa chọn MMLU (Hendrycks et al., 2020) bằng cách dịch nó sang tiếng Amharic. Mô hình được cung cấp mà không có đánh giá tiếng Amharic gốc vì không có tập dữ liệu dựa trên hướng dẫn nào tồn tại cho tiếng Amharic.

3 Chuẩn bị dữ liệu
Trong công trình này, chúng tôi đã chuyển đổi các tập dữ liệu cụ thể theo tác vụ NLP hiện có, như phân tích tình cảm và dịch máy, thành các tập dữ liệu hướng dẫn. Chúng tôi tạo ra một mẫu hướng dẫn cho mỗi tác vụ và phát triển một quy trình tạo dữ liệu (Hình 1) kết hợp mỗi mẫu hướng dẫn với dữ liệu phù hợp từ một tập dữ liệu có sẵn. Quy trình này giúp chúng tôi tạo ra các tập dữ liệu hướng dẫn từ các tập dữ liệu tác vụ NLP có sẵn. Đối với tác vụ NLP mới, chúng tôi tập trung vào việc thu thập tập dữ liệu mới có thể được chuyển đổi thành dữ liệu hướng dẫn. Chúng tôi cũng tạo ra

--- TRANG 2 ---
[Tiếp tục với nội dung còn lại của trang 2...]

--- TRANG 3 ---
[Bảng 1: Tập dữ liệu được sử dụng để chuẩn bị dữ liệu tinh chỉnh hướng dẫn với các cột và số liệu chi tiết...]

--- TRANG 4 ---
[Hình 1: Quy trình xử lý dữ liệu...]

--- TRANG 5 ---
[Tiếp tục với nội dung trang 5...]

--- TRANG 6 ---
[Hình 2: Quy trình huấn luyện đầy đủ tóm tắt công việc đã thực hiện...]

--- TRANG 7 ---
[Hình 3: Điểm số sinh tạo... và Hình 4: Điểm số cho dịch máy...]

--- TRANG 8 ---
[Bảng 2 và 3 với kết quả chi tiết...]

--- TRANG 9 ---
[Phần Kết luận và Nghiên cứu tương lai...]

--- TRANG 10 ---
[Phần Giới hạn và Tài liệu tham khảo...]

--- TRANG 11 ---
[Phụ lục A: Chi tiết thí nghiệm...]

--- TRANG 12 ---
[Hình 5 và 6: Ví dụ về mẫu...]

--- TRANG 13 ---
[Hình 7 và 8: Ví dụ phân tích...]

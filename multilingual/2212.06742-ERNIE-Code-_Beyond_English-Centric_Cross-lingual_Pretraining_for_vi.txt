# 2212.06742.pdf
# Đã chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/multilingual/2212.06742.pdf
# Kích thước tệp: 2289313 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
ERNIE-Code: Vượt ra ngoài Tiền huấn luyện Đa ngôn ngữ Tập trung vào Tiếng Anh cho
Ngôn ngữ Lập trình
Yekun Chai Shuohuan Wang Chao Pang Yu Sun Hao Tian Hua Wu
Baidu
{chaiyekun,wangshuohuan,sunyu02}@baidu.com
Tóm tắt
Các kỹ sư phần mềm làm việc với cùng một ngôn
ngữ lập trình (PL) có thể nói các ngôn ngữ tự
nhiên (NL) khác nhau và ngược lại, tạo ra những
rào cản lớn đối với giao tiếp và hiệu quả làm
việc. Các nghiên cứu gần đây đã chứng minh
hiệu quả của tiền huấn luyện sinh trong các
chương trình máy tính, tuy nhiên chúng luôn tập
trung vào tiếng Anh. Trong công trình này, chúng
tôi tiến tới việc thu hẹp khoảng cách giữa các
NL đa ngôn ngữ và các PL đa ngôn ngữ cho
các mô hình ngôn ngữ lớn (LLM). Chúng tôi
phát hành ERNIE-Code, một mô hình ngôn ngữ
tiền huấn luyện thống nhất cho 116 NL và 6
PL. Chúng tôi sử dụng hai phương pháp cho
tiền huấn luyện đa ngôn ngữ phổ quát: mô hình
hóa ngôn ngữ tham nhũng đoạn học các mẫu
từ NL hoặc PL đơn ngôn ngữ; và mô hình hóa
ngôn ngữ dịch thuật dựa trên trục quay dựa
vào dữ liệu song song của nhiều NL và PL.
Kết quả mở rộng cho thấy ERNIE-Code vượt
trội hơn các LLM đa ngôn ngữ trước đây cho
PL hoặc NL trên một loạt các tác vụ cuối của
trí tuệ mã, bao gồm mã-sang-văn bản đa ngôn
ngữ, văn bản-sang-mã, mã-sang-mã, và sinh
văn bản-sang-văn bản. Chúng tôi tiếp tục cho
thấy lợi thế của nó trong việc nhắc nhở zero-shot
trên tóm tắt mã đa ngôn ngữ và dịch thuật văn
bản-sang-văn bản. Chúng tôi phát hành mã
và các checkpoint tiền huấn luyện của chúng tôi1.

1 Giới thiệu
Các xu hướng gần đây trong tiền huấn luyện sinh
của các ngôn ngữ lập trình (Feng et al., 2020; Chen
et al., 2021; Li et al., 2022) đã dẫn đến sự gia
tăng mạnh mẽ của các cải tiến trong các tình huống
trí tuệ mã, bao gồm hiểu và sinh chương trình
(Wang et al., 2021; Ahmad et al., 2021). Trong
bối cảnh này, một mô hình ngôn ngữ lớn (LLM)
dựa trên transformer được tiền huấn luyện trên
một kho dữ liệu lớn mã nguồn mở (ví dụ, từ
GitHub) và sau đó được tinh chỉnh hoặc đánh giá
zero-shot trên các tác vụ hạ nguồn, chẳng hạn
như tổng hợp chương trình (Austin et al.,
1https://github.com/PaddlePaddle/PaddleNLP/tree/
develop/model_zoo/ernie-code
EnglishDeutschFrançaisEspañolРусскийӾ෈يبرع 
EnglishPHPPythonJavaScriptGoJavaRuby
(a)
(b)(c)Hình 1: So sánh giữa (a) Tiền huấn luyện mã đa ngôn ngữ; (b) Tiền huấn luyện văn bản đa ngôn ngữ; (c) Tiền huấn luyện văn bản-mã đa ngôn ngữ phổ quát (của chúng tôi).

2021; Fried et al., 2022; Nijkamp et al., 2022),
tìm kiếm mã (Husain et al., 2019; Li et al., 2021),
phát hiện bản sao (Lu et al., 2021b), và sinh
mã từ văn bản (Clement et al., 2020).

Mặc dù đã có sự quan tâm mạnh mẽ trong việc
học các LLM đa ngôn ngữ có mục đích chung
cho mã nguồn (Feng et al., 2020; Ahmad et al.,
2021; Wang et al., 2021; Fried et al., 2022; Xu
et al., 2022), nghiên cứu trong lĩnh vực này về
cơ bản đã kết nối các văn bản tiếng Anh (ví dụ,
bình luận hoặc docstring) và nhiều chương trình
máy tính (ví dụ, Python, C++, và Java), như
được hiển thị trong Hình 1(a), và chủ yếu tập
trung xung quanh các kho dữ liệu và benchmark
tập trung vào tiếng Anh. Vấn đề tập trung vào
tiếng Anh này hạn chế đáng kể việc sử dụng
và thực hành của chúng do 95% dân số thế giới
không có tiếng Anh là ngôn ngữ mẹ đẻ (Guo, 2018).

Do đó, việc giảm thiểu rào cản và tạo ra các
kết nối giữa các ngôn ngữ tự nhiên không phải
tiếng Anh (NL) và nhiều ngôn ngữ lập trình (PL)
là rất quan trọng. Một giải pháp kỹ thuật là sử
dụng bản dịch tiếng Anh của các văn bản không
phải tiếng Anh bằng cách sử dụng các hệ thống
dịch máy thần kinh (NMT) trước/sau LLM mã
như một pipeline. Thật không may, hầu hết các
hệ thống NMT mục đích chung (Wu et al., 2016;
Johnson et al., 2017) không được thiết kế cho
các văn bản cụ thể về mã và có thể dễ bị lỗi tích
lũy do các giai đoạn dự đoán xếp tầng.

Một cách tổng quát hơn là học một mô hình LLM
đa ngôn ngữ mã hóa một hỗn hợp của nhiều NL
và PL thành một không gian biểu diễn chéo
chế độ được chia sẻ. Thành công trong việc học
các biểu diễn phổ quát của nhiều ngôn ngữ
(Conneau và Lample, 2019; Xue et al., 2021;
Ahmad et al., 2021; Wang et al., 2021; Xu et al.,
2022) tập trung vào PL hoặc NL cho thấy rằng
có thể xây dựng một mô hình đa ngôn ngữ phổ
quát đại diện chung cho nhiều PL và NL.

Trong công trình này, chúng tôi trình bày
ERNIE-Code, một LLM tiền huấn luyện đa ngôn
ngữ chéo thống nhất cho nhiều NL và PL với
hy vọng giảm thiểu thiên lệch tập trung vào
tiếng Anh cho tiền huấn luyện chương trình,
như được minh họa trong Hình 1. Mô hình của
chúng tôi xây dựng trên kiến trúc encoder-decoder
T5 (Raffel et al., 2020) đã được chứng minh
hiệu quả trong các tác vụ hiểu và sinh cho
NL đa ngôn ngữ (Xue et al., 2021) và PL
(Wang et al., 2021). Đối với tiền huấn luyện
đơn ngôn ngữ trên dữ liệu đơn chế độ (tức là,
mã đa ngôn ngữ hoặc văn bản không được
ghép đôi), chúng tôi tuân theo cùng một công
thức T5 để sử dụng mục tiêu khử nhiễu "tham
nhũng đoạn" trong định dạng văn bản-sang-văn bản.

Kho dữ liệu song song chất lượng tốt giữa các
NL ít tài nguyên và các PL đa ngôn ngữ thường
không có sẵn. Thay vào đó, hầu hết các PL
phổ biến, tài liệu API đi kèm, ví dụ mã, và
các diễn đàn thảo luận chủ yếu được viết bằng
tiếng Anh, điều này tạo ra một nút thắt cổ chai
trong việc tạo ra các kết nối giữa các NL ít tài
nguyên và PL. Lấy cảm hứng từ dịch máy dựa
trên trục quay (Gispert và Mariño, 2006; Utiyama
và Isahara, 2007) sử dụng một ngôn ngữ trục
quay và phân tách dịch thuật nguồn→đích
thành dịch thuật song ngữ nguồn→trục quay
và trục quay→đích, chúng tôi giới thiệu mô hình
hóa ngôn ngữ dịch thuật dựa trên trục quay
(PTLM) với việc nhắc nhở phân tách đa-NL→đa-PL
thành đa-NL→tiếng Anh và tiếng Anh→đa-PL
với việc quay qua tiếng Anh.

Cụ thể, chúng tôi tận dụng huấn luyện PTLM
theo hướng kép cho kho dữ liệu song song
trong các chế độ khác nhau: (1) tiếng Anh→đa-PL.
Đối với dữ liệu song song đa-PL→tiếng Anh,
tức là, các đoạn mã và các bình luận đi kèm
của chúng, mô hình học cách sinh bình luận
tiếng Anh từ các đoạn mã và ngược lại. (2)
tiếng Anh→đa-NL. Nó học cách dịch giữa
tiếng Anh và các NL khác. Do đó, mô hình
mã hóa PL→tiếng Anh và tiếng Anh→NL
cùng lúc, với tiếng Anh làm ngôn ngữ trục quay.
Chúng tôi tiến hành các thí nghiệm mở rộng
trên các tác vụ hạ nguồn khác nhau: (1) Sinh
mã đa ngôn ngữ từ văn bản; (2) Tóm tắt mã
đa ngôn ngữ (mã-sang-văn bản); (3) Dịch tài
liệu (văn bản-sang-văn bản); (4) Sửa chữa mã
(mã-sang-mã). Kết quả thực nghiệm đã cho
thấy rằng mô hình của chúng tôi vượt trội hơn
các LLM đa ngôn ngữ mạnh cho PL hoặc NL
và đã xác minh khả năng đa ngôn ngữ phổ quát
của nó. Chúng tôi cũng cung cấp các ví dụ
để cho thấy khả năng zero-shot tốt của nó
trong tóm tắt mã đa ngôn ngữ và dịch thuật
văn bản-sang-văn bản thông qua việc nhắc nhở zero-shot.

Để tóm tắt, bài báo này đưa ra những đóng góp
sau: (1) Chúng tôi đầu tiên đề xuất một LLM
tiền huấn luyện đa ngôn ngữ chéo thống nhất
cho cả NL đa ngôn ngữ và PL đa ngôn ngữ,
mở rộng khả năng của LLM hướng tới việc
học cùng nhau tính đa ngôn ngữ phổ quát.
(2) Chúng tôi sử dụng mô hình hóa ngôn ngữ
dịch thuật dựa trên trục quay với việc nhắc
nhở để xây dựng các kết nối giữa đa-NL và
đa-PL (với các trục quay tiếng Anh) và giảm
thiểu vấn đề khi kho dữ liệu song song của
đa ngôn ngữ-NL→đa ngôn ngữ-PL không có
sẵn. (3) Chúng tôi đạt được hiệu suất vượt
trội so với các LLM đa ngôn ngữ trước đây
trên một loạt các tác vụ trí tuệ mã, bao gồm
văn bản-sang-mã, mã-sang-văn bản, sửa chữa
mã, và dịch tài liệu mã. (4) Ở một mức độ
nào đó, mô hình của chúng tôi đã cho thấy
khả năng nhắc nhở zero-shot trên sinh mã-sang-văn bản,
văn bản-sang-mã, và văn bản-sang-văn bản
đa ngôn ngữ. Hơn nữa, ERNIE-Code hoạt
động tốt trong việc đặt tên hàm và hoàn thành
các đối số tương ứng khi được đưa ra các
hướng dẫn NL đa ngôn ngữ.

--- TRANG 2 ---
LLM mã hóa một hỗn hợp của nhiều NL và
PL thành một không gian biểu diễn chéo chế
độ được chia sẻ. Thành công trong việc học
các biểu diễn phổ quát của nhiều ngôn ngữ
(Conneau và Lample, 2019; Xue et al., 2021;
Ahmad et al., 2021; Wang et al., 2021; Xu et al.,
2022) tập trung vào PL hoặc NL cho thấy rằng
có thể xây dựng một mô hình đa ngôn ngữ phổ
quát đại diện chung cho nhiều PL và NL.

Trong công trình này, chúng tôi trình bày
ERNIE-Code, một LLM tiền huấn luyện đa ngôn
ngữ chéo thống nhất cho nhiều NL và PL với
hy vọng giảm thiểu thiên lệch tập trung vào
tiếng Anh cho tiền huấn luyện chương trình,
như được minh họa trong Hình 1. Mô hình của
chúng tôi xây dựng trên kiến trúc encoder-decoder
T5 (Raffel et al., 2020) đã được chứng minh
hiệu quả trong các tác vụ hiểu và sinh cho
NL đa ngôn ngữ (Xue et al., 2021) và PL
(Wang et al., 2021). Đối với tiền huấn luyện
đơn ngôn ngữ trên dữ liệu đơn chế độ (tức là,
mã đa ngôn ngữ hoặc văn bản không được
ghép đôi), chúng tôi tuân theo cùng một công
thức T5 để sử dụng mục tiêu khử nhiễu "tham
nhũng đoạn" trong định dạng văn bản-sang-văn bản.

Kho dữ liệu song song chất lượng tốt giữa các
NL ít tài nguyên và các PL đa ngôn ngữ thường
không có sẵn. Thay vào đó, hầu hết các PL
phổ biến, tài liệu API đi kèm, ví dụ mã, và
các diễn đàn thảo luận chủ yếu được viết bằng
tiếng Anh, điều này tạo ra một nút thắt cổ chai
trong việc tạo ra các kết nối giữa các NL ít tài
nguyên và PL. Lấy cảm hứng từ dịch máy dựa
trên trục quay (Gispert và Mariño, 2006; Utiyama
và Isahara, 2007) sử dụng một ngôn ngữ trục
quay và phân tách dịch thuật nguồn→đích
thành dịch thuật song ngữ nguồn→trục quay
và trục quay→đích, chúng tôi giới thiệu mô hình
hóa ngôn ngữ dịch thuật dựa trên trục quay
(PTLM) với việc nhắc nhở phân tách đa-NL→đa-PL
thành đa-NL→tiếng Anh và tiếng Anh→đa-PL
với việc quay qua tiếng Anh.

Cụ thể, chúng tôi tận dụng huấn luyện PTLM
theo hướng kép cho kho dữ liệu song song
trong các chế độ khác nhau: (1) tiếng Anh→đa-PL.
Đối với dữ liệu song song đa-PL→tiếng Anh,
tức là, các đoạn mã và các bình luận đi kèm
của chúng, mô hình học cách sinh bình luận
tiếng Anh từ các đoạn mã và ngược lại. (2)
tiếng Anh→đa-NL. Nó học cách dịch giữa
tiếng Anh và các NL khác. Do đó, mô hình
mã hóa PL→tiếng Anh và tiếng Anh→NL
cùng lúc, với tiếng Anh làm ngôn ngữ trục quay.
Chúng tôi tiến hành các thí nghiệm mở rộng
trên các tác vụ hạ nguồn khác nhau: (1) Sinh
mã đa ngôn ngữ từ văn bản; (2) Tóm tắt mã
đa ngôn ngữ (mã-sang-văn bản); (3) Dịch tài
liệu (văn bản-sang-văn bản); (4) Sửa chữa mã
(mã-sang-mã). Kết quả thực nghiệm đã cho
thấy rằng mô hình của chúng tôi vượt trội hơn
các LLM đa ngôn ngữ mạnh cho PL hoặc NL
và đã xác minh khả năng đa ngôn ngữ phổ quát
của nó. Chúng tôi cũng cung cấp các ví dụ
để cho thấy khả năng zero-shot tốt của nó
trong tóm tắt mã đa ngôn ngữ và dịch thuật
văn bản-sang-văn bản thông qua việc nhắc nhở zero-shot.

Để tóm tắt, bài báo này đưa ra những đóng góp
sau: (1) Chúng tôi đầu tiên đề xuất một LLM
tiền huấn luyện đa ngôn ngữ chéo thống nhất
cho cả NL đa ngôn ngữ và PL đa ngôn ngữ,
mở rộng khả năng của LLM hướng tới việc
học cùng nhau tính đa ngôn ngữ phổ quát.
(2) Chúng tôi sử dụng mô hình hóa ngôn ngữ
dịch thuật dựa trên trục quay với việc nhắc
nhở để xây dựng các kết nối giữa đa-NL và
đa-PL (với các trục quay tiếng Anh) và giảm
thiểu vấn đề khi kho dữ liệu song song của
đa ngôn ngữ-NL→đa ngôn ngữ-PL không có
sẵn. (3) Chúng tôi đạt được hiệu suất vượt
trội so với các LLM đa ngôn ngữ trước đây
trên một loạt các tác vụ trí tuệ mã, bao gồm
văn bản-sang-mã, mã-sang-văn bản, sửa chữa
mã, và dịch tài liệu mã. (4) Ở một mức độ
nào đó, mô hình của chúng tôi đã cho thấy
khả năng nhắc nhở zero-shot trên sinh mã-sang-văn bản,
văn bản-sang-mã, và văn bản-sang-văn bản
đa ngôn ngữ. Hơn nữa, ERNIE-Code hoạt
động tốt trong việc đặt tên hàm và hoàn thành
các đối số tương ứng khi được đưa ra các
hướng dẫn NL đa ngôn ngữ.

2 Công trình liên quan
Là các ngôn ngữ chính thức dựa trên văn bản
với cú pháp và ngữ nghĩa nghiêm ngặt, PL
khác với NL bởi vì NL chỉ được sử dụng để
giao tiếp giữa con người trong khi PL yêu cầu
sự tương tác giữa con người và máy tính. Công
trình này nhắm tới việc thu hẹp khoảng cách
giữa ngôn ngữ con người và chương trình máy
tính theo cách đa ngôn ngữ chéo để tiền huấn
luyện đa ngôn ngữ thống nhất, điều này có liên
quan chặt chẽ đến các LLM trong PL hoặc NL
đa ngôn ngữ.

Tiền huấn luyện PL đa ngôn ngữ Thành công
của tiền huấn luyện quy mô lớn đã dẫn đến
những tiến bộ ấn tượng trong các chương trình
máy tính. Dòng nghiên cứu này liên quan đến
tiền huấn luyện trên các PL đa ngôn ngữ sử
dụng các encoder transformer hai chiều (Feng
et al., 2020; Li et al., 2021), các decoder transformer
ngẫu nhiên (Chen et al., 2021; Austin et al.,
2021; Fried et al., 2022; Nijkamp et al., 2022;
Xu et al., 2022), và các kiến trúc encoder-decoder
transformer (Wang et al., 2021; Ahmad et al.,
2021; Li et al., 2022). Những mô hình với encoder
hai chiều tập trung vào các tác vụ hiểu chương
trình, chẳng hạn như tìm kiếm mã (Husain et al.,
2019), trong khi những mô hình encoder-decoder
nhắm tới việc xây dựng các LLM thống nhất cho
cả hiểu và sinh chương trình. Chúng tôi quan
sát thấy rằng một số lượng lớn các mô hình
tiền huấn luyện cho PL có xu hướng mở rộng
quy mô các tham số của chúng dưới khung
mô hình hóa ngôn ngữ ngẫu nhiên, chủ yếu tập
trung vào tổng hợp chương trình (Chen et al.,
2021; Austin et al., 2021; Fried et al., 2022;
Nijkamp et al., 2022; Xu et al., 2022). Tuy nhiên,
tất cả các công trình này hầu như tập trung vào
tiếng Anh, đặt ra những thách thức đáng kể
trong việc đối phó với các tác vụ cuối PL trong
các tình huống không phải tiếng Anh.

Tiền huấn luyện NL đa ngôn ngữ Công trình
này cũng liên quan đến xu hướng liên tục của
các LLM đa ngôn ngữ. Một dòng của công trình
này tập trung vào việc mã hóa nhiều NL thành
một không gian biểu diễn được chia sẻ (Conneau
và Lample, 2019; Conneau et al., 2020), trong
khi một số nỗ lực mở rộng phương pháp tiền
huấn luyện đơn ngôn ngữ hiệu quả thành các
cài đặt đa ngôn ngữ (Xue et al., 2021; Liu et al.,
2020).

Kế thừa thành công gần đây của các LLM trong
tính đa ngôn ngữ, công trình này nằm ở giao
điểm giữa tiền huấn luyện NL và PL đa ngôn
ngữ. Trái ngược với công trình trước đây chú
ý đến NL đa ngôn ngữ hoặc PL đa ngôn ngữ,
chúng tôi tìm cách học một cách rõ ràng nhiều
NL và PL trong một không gian biểu diễn được
chia sẻ với hy vọng phá vỡ các rào cản ngôn
ngữ giữa hai chế độ này.

--- TRANG 3 ---
3 Tiền huấn luyện NL-PL đa ngôn ngữ chéo
Trong phần này, chúng tôi giới thiệu các tác vụ
tiền huấn luyện (§3.1), mô hình (§3.2), và dữ
liệu tiền huấn luyện (§3.3) mà chúng tôi sử
dụng trong toàn bộ công trình này.

3.1 Các tác vụ tiền huấn luyện
Chúng tôi tiền huấn luyện trên hai tác vụ tiền
huấn luyện sử dụng cả dữ liệu PL và NL: một
tác vụ (§3.1.1) sử dụng dữ liệu PL/NL đơn
ngôn ngữ (không giám sát), trong khi tác vụ
khác (§3.1.2) yêu cầu các cặp NL-PL và NL-NL
song song (có giám sát). Tác vụ trước tiến tới
việc học các mẫu nội chế độ từ chỉ PL hoặc
NL, trong khi tác vụ sau trang bị cho mô hình
khả năng căn chỉnh và zero-shot đa ngôn ngữ/chế độ.

3.1.1 Tác vụ#1: Mô hình hóa ngôn ngữ tham
nhũng đoạn (SCLM)
Tiền huấn luyện khử nhiễu sequence-to-sequence
đã rất hiệu quả trên một tập hợp rộng các tác
vụ, bao gồm xử lý ngôn ngữ tự nhiên (Liu et al.,
2020; Raffel et al., 2020; Xue et al., 2021) và
xử lý ngôn ngữ lập trình (Wang et al., 2021;
Ahmad et al., 2021). Mục tiêu tiền huấn luyện
khử nhiễu đầu tiên làm hỏng các chuỗi đầu vào
bằng cách che giấu hoặc thêm nhiễu; và sau đó
khôi phục các đầu vào ban đầu bằng cách buộc
mô hình dự đoán các đoạn, câu hoặc tài liệu
bị hỏng. Raffel et al. (2020) nhận thấy rằng
tiền huấn luyện khử nhiễu tham nhũng đoạn
tạo ra hiệu suất mạnh mẽ trong khi hiệu quả
hơn về mặt tính toán do độ dài chuỗi mục tiêu
ngắn hơn.

Theo cách tương tự, chúng tôi mở rộng tiền
huấn luyện khử nhiễu tham nhũng đoạn trên
cả PL và NL. Chúng tôi gọi tác vụ này là mô
hình hóa ngôn ngữ tham nhũng đoạn (SCLM),
như được minh họa trong Hình 2. Cụ thể, nó
làm hỏng 15% các token đầu vào NL/PL ban
đầu với độ dài đoạn trung bình là 3 bằng cách
thay thế các đoạn liền kề, ngẫu nhiên của các
token bằng một placeholder mặt nạ duy nhất
và sau đó dự đoán đoạn bị hỏng ở phía mục tiêu.

Hình 2: Sơ đồ của mục tiêu SCLM cho ví dụ
PL (trái) và NL (phải).

Giả sử chúng ta có tổng cộng M kho dữ liệu
đơn ngôn ngữ của các kho dữ liệu NL và PL
{Cm}m=1M. Chúng tôi áp dụng mục tiêu tiền
huấn luyện SCLM trên cả dữ liệu NL và PL
theo cách đa tác vụ:
LSCLM =∑M m=1∑T t=1 log P(x(i);t|x^nmask(m);x^mask(m);<t; θ) (1)

trong đó θ biểu thị các tham số có thể huấn luyện,
x^nmask(m) và x^mask(m) là các đầu vào bị tham
nhũng đoạn và các đoạn mục tiêu tương ứng từ
kho dữ liệu đơn ngôn ngữ Cm. x^mask(m);<t chỉ
ra các token được sinh ra cho đến bước thời
gian thứ t trong tổng độ dài chuỗi mục tiêu
(bị hỏng) T.

3.1.2 Tác vụ#2: Mô hình hóa ngôn ngữ dịch
thuật dựa trên trục quay (PTLM)
Công trình này nhắm tới việc thu hẹp khoảng
cách đa chế độ đa ngôn ngữ chéo giữa nhiều
NL và PL, tuy nhiên các kho dữ liệu song song
chất lượng tốt giữa NL không phải tiếng Anh
và PL đa ngôn ngữ không có sẵn. Sự thiếu
hụt kho dữ liệu song song bắt nguồn từ thực
tế là hầu hết các PL phổ biến, tài liệu đi kèm,
và các trang web thảo luận chủ yếu được viết
bằng tiếng Anh. Điều tra ban đầu về dịch máy
thống kê đã đề xuất phương pháp dựa trên trục
quay (Gispert và Mariño, 2006; Utiyama và
Isahara, 2007) để giới thiệu một ngôn ngữ thứ
ba - được gọi là ngôn ngữ trục quay - mà với
đó tồn tại các kho dữ liệu song ngữ nguồn-trục
quay và trục quay-đích chất lượng tốt. Johnson
et al. (2017) áp dụng một mô hình NMT duy
nhất để đồng thời học nhiều hướng dịch (bao
gồm nguồn→trục quay, trục quay→đích), cho
phép dịch zero-shot giữa các NL một cách
ngầm định.

Trong bối cảnh của chúng tôi, kho dữ liệu song
ngữ đa-PL đến đa-NL chất lượng tốt không có
sẵn, tuy nhiên tồn tại các kho dữ liệu song song
đa-NL đến tiếng Anh và tiếng Anh đến đa-PL,
với việc quay qua tiếng Anh. Được thúc đẩy
bởi NMT dựa trên trục quay (Johnson et al.,
2017) và phương pháp mô hình hóa ngôn ngữ
dịch thuật (TLM; Conneau và Lample, 2019),
chúng tôi áp dụng một mục tiêu huấn luyện
dựa trên trục quay thống nhất cho quá trình
tiền huấn luyện NL-PL đa ngôn ngữ, cụ thể
là mô hình hóa ngôn ngữ dịch thuật trục quay
(PTLM).

Hình 3: Sơ đồ của mục tiêu PTLM cho ví dụ
NL-sang-PL (trái), PL-sang-NL (giữa), NL-sang-NL
(phải). "<SEP>" biểu thị token phân cách.

Với các kho dữ liệu PL-NL và NL-NL song
ngữ, chúng tôi học cùng nhau tính song song
với việc quay theo hướng kép: ví dụ, Python→tiếng Anh
và tiếng Anh→tiếng Nga. Điều này cho phép
việc bắc cầu ngầm định giữa các cặp PL-NL
không bao giờ được thấy một cách rõ ràng
trong dữ liệu huấn luyện (Johnson et al., 2017).
Chính xác hơn, chúng tôi nối các câu song song
nguồn-đích và học cách dự đoán ngôn ngữ
đích bị hỏng, như được hiển thị trong Hình 3.
Thay vì che giấu các token ngẫu nhiên (Conneau
và Lample, 2019), chúng tôi làm hỏng toàn bộ
câu theo một trong hai hướng của dữ liệu song
ngữ và dự đoán ở phía mục tiêu. Mô hình yêu
cầu chú ý đến các biểu diễn hoàn chỉnh của
các câu nguồn để khôi phục câu đích và học
sự căn chỉnh giữa các cặp nguồn-đích. Giả sử
chúng ta có N kho dữ liệu song song NL-NL
và NL-PL {Dn}n=1,...,N. Chúng ta có thể công
thức hóa huấn luyện PTLM như sau:
LPTLM =∑N n=1∑T t=1 log P(x(n);t|x^source(n);x^target(n);<t; θ) (2)

trong đó x^source(n) và x^target(n) biểu thị các
câu nguồn và đích từ kho dữ liệu song ngữ
Dn. x^target(n);<t chỉ ra các token được sinh ra
cho đến bước thời gian thứ t trong tổng độ dài
chuỗi đích T. Định dạng huấn luyện này giống
với một tác vụ NMT.

Để kích hoạt phương pháp dựa trên trục quay
và chỉ định ngôn ngữ đích, chúng tôi định dạng
lại PTLM bằng cách nhắc nhở với tiền tố tác
vụ (Xem Hình 3), trong đó chúng tôi thêm
một hướng dẫn tác vụ "translate A to B:\n"
vào bên trái của các câu đầu vào, trong đó A
và B biểu thị ngôn ngữ nguồn và đích tương ứng.
Hướng dẫn nhắc nhở này chỉ ra ngôn ngữ đích
mà mô hình nên dịch tới, dẫn đến khả năng
zero-shot tốt (§5.3).

3.2 Mô hình
Kiến trúc mô hình Mô hình của chúng tôi tuân
theo cùng kiến trúc với T5-base (Raffel et al.,
2020). Cụ thể, chúng tôi xây dựng ERNIE-Code
trên phiên bản "T5.1.1"2, cải tiến T5 bằng cách
sử dụng các phi tuyến tính cổng (Shazeer, 2020;
Chai et al., 2020). Chúng tôi tham khảo §A.3.1
cho các cài đặt tiền huấn luyện.

Mã hóa NL/PL được chia sẻ Chúng tôi dựa
tokenizer của chúng tôi trên tokenizer SentencePiece
trong Xue et al. (2021). Tuy nhiên, tokenizer
SentencePiece ban đầu được thiết kế để mã hóa
các NL không đại diện hiệu quả dữ liệu PL.
Do đó, chúng tôi thêm một tập hợp các token
đại diện cho thụt lề khoảng trắng có độ dài
khác nhau trong PL. Xem chi tiết tokenization
trong §A.1.

3.3 Dữ liệu tiền huấn luyện
Kho dữ liệu mã Đối với dữ liệu PL, chúng tôi
sử dụng cùng kho dữ liệu tiền huấn luyện -
CodeSearchNet (Husain et al., 2019) - như
các mô hình trước đây (Feng et al., 2020;
Wang et al., 2021).3 Nó bao gồm sáu PL đơn
ngôn ngữ (Go, Java, JavaScript, PHP, Python,
và Ruby) và sáu dữ liệu song song NL-PL, tức
là, các cặp truy vấn PL-NL. Phần lớn các chú
thích NL trong kho dữ liệu song song là tiếng
Anh. Chúng tôi trì hoãn thống kê dữ liệu và
chi tiết tiền xử lý trong §A.2.1.

2https://github.com/google-research/
text-to-text-transfer-transformer/blob/main/released_
checkpoints.md#t511
3Lưu ý rằng để so sánh công bằng, chúng tôi không
sử dụng dữ liệu bổ sung từ các repository công cộng
được lưu trữ trên GitHub.

--- TRANG 4 ---
Mô hình #Tham số #PL #NL Nguồn dữ liệu
mBART (Liu et al., 2020) 680M - 25 Common Crawl (CC25)
mT5 (Xue et al., 2021) 560M - 101 Common Crawl (mC4)
PLBART (Ahmad et al., 2021) 390M 2 1 GitHub, StackOverflow
CodeT5 (Wang et al., 2021) 220M 8 1 CodeSearchNet, GitHub (C/C#)
ERNIE-Code (của chúng tôi) 560M 6 116 CodeSearchNet, CC-100, OPUS
Bảng 1: So sánh mô hình của chúng tôi với các
mô hình tiền huấn luyện đa ngôn ngữ quy mô lớn
hiện có cho NL và PL.

Kho dữ liệu văn bản Chúng tôi tiền huấn luyện
trên kho dữ liệu NL sau: (1) Dữ liệu đơn ngôn
ngữ từ CC-100 (Conneau et al., 2020) được xây
dựng trên kho dữ liệu CommonCrawl sạch4, chứa
116 NL khác nhau.5 (2) Dữ liệu song song từ
trang web OPUS6 bao gồm 15 ngôn ngữ. Các
cặp dịch thuật NL được thu thập bao gồm
MultiUN (Ziemski et al., 2016), IIT Bombay
(Kunchukuttan et al., 2018), OPUS (Tiedemann,
2012), WikiMatrix (Schwenk et al., 2021), v.v.
Chúng tôi tham khảo §A.2.2 để biết chi tiết.

Để giảm thiểu thiên lệch đối với các ngôn ngữ
có nhiều tài nguyên, chúng tôi tuân theo Conneau
và Lample (2019) để cân bằng lại phân phối
dữ liệu trên cả các kho dữ liệu và lấy mẫu
tăng/giảm các câu từ mỗi ngôn ngữ (hoặc cặp
ngôn ngữ) i với phân phối đa thức được tỷ lệ
lại qi:
qi = pi^α / ∑j=1 pj^α (3)

trong đó pi là tỷ lệ phần trăm dữ liệu của mỗi
kho dữ liệu đơn ngôn ngữ hoặc song song. Theo
Conneau và Lample (2019), chúng tôi đặt α = 0,3
cho cả kho dữ liệu đơn ngôn ngữ và song song.

4 Thí nghiệm
Trong phần này, chúng tôi đầu tiên giới thiệu
các mô hình tiền huấn luyện đa ngôn ngữ để
so sánh (§4.1), các tác vụ hạ nguồn và thông
số đánh giá (§4.2). Sau đó, chúng tôi đánh giá
và cho thấy những cải tiến hiệu suất nhất quán
trên một số benchmark NL/PL đa ngôn ngữ,
bao gồm mã-sang-văn bản (§4.3), văn bản-sang-mã
(§4.4), văn bản-sang-văn bản (§4.5), và các
tác vụ cuối mã-sang-mã (§4.6).

4.1 So sánh với các mô hình liên quan
Để đặt mô hình mới của chúng tôi trong bối
cảnh, chúng tôi so sánh ngắn gọn với các
LLM đa ngôn ngữ hiện có cho NL/PL. Xem
xét rằng ERNIE-Code là LLM đầu tiên nhắm
tới NL và PL đa ngôn ngữ một cách rõ ràng,
để ngắn gọn, chúng tôi tập trung vào các mô
hình hỗ trợ nhiều NL hoặc nhiều PL. Bảng 1
báo cáo thống kê tổng thể của các mô hình so sánh.

mBART (Liu et al., 2020) là một biến thể
NL đa ngôn ngữ của BART (Lewis et al., 2020)
được huấn luyện với mục tiêu khử nhiễu toàn
văn bản trên một tập con 25 ngôn ngữ từ
CommonCrawl. Nó học cách tái tạo các văn
bản NL đầy đủ từ những văn bản bị hỏng với
một hàm nhiễu tùy ý. mT5 (Xue et al., 2021)
là một mô hình encoder-decoder NL đa ngôn
ngữ được điều chỉnh từ T5. Nó được huấn luyện
trên 101 NL sử dụng dữ liệu CommonCrawl
đã được lọc (mC4) sử dụng cùng mục tiêu
SCLM như mô hình của chúng tôi. PLBART
(Ahmad et al., 2021) là một phiên bản PL đa
ngôn ngữ của BART với mục tiêu khử nhiễu
sử dụng ba định dạng nhiễu. Nó được huấn
luyện trên 210M hàm Java, 470M hàm Python
từ GitHub, và 47M bài đăng tiếng Anh từ
StackOverflow. CodeT5 (Wang et al., 2021)
là một phiên bản PL của mT5 được tiền huấn
luyện trên dữ liệu đơn ngôn ngữ/song song
sáu-PL từ CodeSearchNet và dữ liệu C/C# bổ
sung được thu thập từ GitHub. Nó bổ sung
học thông tin loại token từ các định danh và
áp dụng sinh kép giữa tiếng Anh và PL.

4.2 Các tập dữ liệu đánh giá và thông số
Bảng 9 hiển thị thống kê của tập dữ liệu đánh
giá. Chúng tôi sử dụng cùng các tập dữ liệu
công cộng và phân chia train-test cho tất cả
các tác vụ hạ nguồn. Chúng tôi tham khảo
§A.3.3 cho các cài đặt thí nghiệm của tinh chỉnh.

Tóm tắt mã đa ngôn ngữ là một tác vụ mã-sang-văn bản
nhằm sinh văn bản đa ngôn ngữ cho một đoạn
mã. Chúng tôi sử dụng mCoNaLa (Wang et al.,
2022) để đánh giá hiệu suất sinh NL đa ngôn
ngữ từ PL. Nó bao gồm 341/210/345 mẫu song
song được tuyển chọn thủ công với NL bằng
tiếng Tây Ban Nha/Nhật Bản/Nga và PL bằng
Python. Vì mCoNaLa không cung cấp tập huấn
luyện và kiểm tra, chúng tôi sử dụng CoNaLa
(Yin et al., 2018), một dữ liệu song song tiếng
Anh-Python (bao gồm #2,379 mẫu), làm tập
train/dev (với tỷ lệ dữ liệu 10:1) sau khi dịch.
Đối với cài đặt "translate-train", chúng tôi sử
dụng CoNaLa đã được dịch máy làm tập huấn
luyện và dev, trong khi sử dụng mCoNaLa làm
tập test. Cụ thể, chúng tôi dịch tập huấn luyện
của CoNaLa thành ba ngôn ngữ đích sử dụng
FLORES-101 (Goyal et al., 2022) và áp dụng
chúng làm tập train/dev. Chúng tôi sử dụng
ROUGE-L (R-L; Lin, 2004), BLEU-4 (B-4;
Post, 2018), và chrF (Popović, 2015) để so
sánh toàn diện.

--- TRANG 5 ---
Mô hình                Tây Ban Nha        Nhật Bản          Nga            Trung bình
                  B-4  R-L  chrF   B-4  R-L  chrF   B-4  R-L  chrF   B-4  R-L  chrF
Translate-train
mBART            0.96 19.46 19.30  0.07 4.70  7.88  0.08 0.00 13.56  0.37 8.05 13.58
mT5              0.94 28.69 19.87  0.06 2.95  6.58  0.09 2.56 12.00  0.36 11.40 12.82
PLBART           0.16 14.33 11.72  0.06 4.11  7.87  0.24 2.98 14.06  0.15 7.14 11.22
CodeT5           1.00 22.93 20.09  0.04 5.42  7.13  0.13 1.48 12.97  0.39 9.94 13.40
Của chúng tôi(L512)  1.90 32.51 23.22  0.30 10.62 9.16  0.43 5.01 16.60  0.88 16.05 16.33
Của chúng tôi(L1024) 2.51 33.87 24.00  0.58 8.55  8.81  0.28 5.69 15.24  1.12 16.04 16.02
Zero-shot
Của chúng tôi(L512)  0.49 12.78 15.69  1.46 32.07 11.02  1.98 30.46 11.68  1.31 25.10 12.80
Bảng 2: Kết quả tác vụ tóm tắt mã đa ngôn ngữ. "L512/1024" chỉ ra độ dài tối đa là 512/1024.

Sinh mã đa ngôn ngữ từ văn bản đề cập đến
tác vụ sinh mã tạo ra các đoạn mã từ các hướng
dẫn NL đa ngôn ngữ. Chúng tôi sử dụng cùng
tập train/dev/test như tóm tắt mã đã đề cập
ở trên. Cụ thể, trong cài đặt "translate-train",
chúng tôi sử dụng dữ liệu CoNaLa đã dịch
làm tập huấn luyện và dev, mCoNaLa làm tập
test để sinh mã Python từ hướng dẫn NL bằng
ba NL khác nhau (tức là, tiếng Tây Ban Nha,
Nhật Bản, và Nga). Chúng tôi sử dụng ROUGE-L,
BLEU-4, và CodeBLEU (C-B; Ren et al., 2020)
để đánh giá các dự đoán mã.

Dịch tài liệu là một tác vụ văn bản-sang-văn bản
dịch tài liệu mã từ một NL sang NL khác. Chúng
tôi sử dụng Microsoft Docs từ tập dữ liệu
CodeXGLUE (Lu et al., 2021a) để xác minh
dịch thuật NL đa ngôn ngữ giữa tiếng Anh↔
Đan Mạch, Latvia, Na Uy, và Trung Quốc.
Chúng tôi báo cáo BLEU-4 và khớp chính xác
(EM) trong kết quả của chúng tôi.

Sửa chữa mã là một tác vụ mã-sang-mã tự
động sửa lỗi cho một đoạn mã bị lỗi. Chúng
tôi đánh giá trên tập dữ liệu Bugs2Fix (Tufano
et al., 2019) với hai tập con: (i) "small" với
token ít hơn 50; (ii) "medium" với độ dài từ
50 đến 100. Chúng tôi báo cáo BLEU-47 và
EM để đánh giá.

4.3 Tóm tắt mã đa ngôn ngữ
Bảng 2 hiển thị kết quả mã-sang-văn bản đa
ngôn ngữ của các tóm tắt NL được sinh bằng
tiếng Tây Ban Nha, Nhật Bản, và Nga. Chúng
tôi sử dụng CoNaLa tiếng Anh đã dịch làm tập
huấn luyện trong ba ngôn ngữ đích8, được ký
hiệu là đánh giá "translate-train". Như được
hiển thị trong Bảng 2, mô hình của chúng tôi
vượt trội hơn tất cả các LLM cơ sở cho NL
(mBART, mT5) hoặc PL (PLBART, CodeT5).
Đặc biệt, ERNIE-Code, với độ dài 1024, vượt
trội hơn đối tác có độ dài 512 (1.12 so với
0.88 trên BLEU-4) ở chỗ nó cho phép học các
ngữ cảnh mở rộng hơn từ các đoạn NL/PL
huấn luyện.

PLBART hoạt động tệ nhất trong tất cả các
baseline trung bình, trong khi CodeT5, mT5,
và mBART hoạt động tương tự. Chúng tôi
phỏng đoán rằng PLBART chỉ học dữ liệu từ
các hàm Java/Python và bài đăng StackOverflow
tiếng Anh, dữ liệu huấn luyện của nó thiếu
sự đa dạng của tính đa ngôn ngữ.

4.4 Sinh mã đa ngôn ngữ từ văn bản
Bảng 3 hiển thị kết quả "translate-train" của
sinh mã đa ngôn ngữ từ văn bản trên mCoNaLa.
ERNIE-Code vượt trội hơn tất cả các baseline
trên điểm số BLEU-4, ROUGE-L, và CodeBLEU,
cho thấy rằng tiền huấn luyện PL-NL đa ngôn
ngữ của chúng tôi có thể nắm bắt cú pháp và
ngữ nghĩa mã. Trong tất cả các tác vụ sinh mã,
các mô hình đa ngôn ngữ cho NL hoạt động
tệ hơn các đối tác PL. PLBART đánh bại tất
cả các baseline trên khớp n-gram dạng bề mặt
(BLEU-4/ROUGE-L) và khớp liên quan đến
mã có cấu trúc (CodeBLEU), thậm chí đạt
ngang bằng với mô hình của chúng tôi trên
CodeBLEU. Ngược lại, mT5 hoạt động kém
hơn tất cả các mô hình khác trên một trong ba
tác vụ con, cho thấy rằng tokenizer mT5 không
hiệu quả trong việc mã hóa PL, như đã đề cập
trước đó trong §3.2. Bằng cách so sánh mT5
và các mô hình của chúng tôi, những cải tiến
cho thấy hiệu quả của phương pháp chúng tôi
trong việc mã hóa các ký tự khoảng trắng để
tokenization. Mô hình của chúng tôi với ngữ
cảnh mở rộng hơn (độ dài 1024) vượt trội hơn
độ dài 512 trên tất cả ba tác vụ con văn bản-sang-mã.

4.5 Dịch tài liệu (văn bản-sang-văn bản)
Chúng tôi tiếp tục điều tra dịch thuật văn bản-sang-văn bản
đa ngôn ngữ giữa tiếng Anh (en) và Đan Mạch
(da)/Latvia (lv)/Na Uy (no)/Trung Quốc (zh).
Bảng 4 hiển thị kết quả dịch tài liệu của các
mô hình so sánh, bao gồm transformer đa ngôn
ngữ (Johnson et al., 2017), XLM-R (Conneau

7https://github.com/microsoft/CodeXGLUE/blob/main/
Code-Code/code-refinement/evaluator/evaluator.py
8https://conala-corpus.github.io/

--- TRANG 6 ---
Mô hình                Tây Ban Nha        Nhật Bản          Nga            Trung bình
                  B-4  R-L  C-B   B-4  R-L  C-B   B-4  R-L  C-B   B-4  R-L  C-B
Translate-train
mBART            1.73 11.85 0.05  3.68 10.33 0.08  2.34 9.23 0.07  2.58 10.47 0.07
mT5              0.27 3.51  0.05  0.22 2.91  0.07  0.25 6.17 0.04  0.25 4.20  0.05
PLBART           2.19 14.47 0.06  6.56 18.26 0.09  3.27 19.92 0.09  4.01 17.55 0.08
CodeT5           1.97 14.47 0.05  7.46 18.58 0.09  4.26 17.96 0.07  4.56 17.00 0.07
Của chúng tôi(L512)  2.25 14.92 0.06  8.06 22.65 0.10  6.12 25.27 0.08  5.48 20.95 0.08
Của chúng tôi(L1024) 2.51 12.65 0.06  8.08 20.12 0.09  6.55 23.84 0.09  5.71 18.87 0.08
Zero-shot
Của chúng tôi(L512)  2.47 12.12 0.10  2.56 14.46 0.15  3.69 13.52 0.14  2.91 13.37 0.13
Bảng 3: Kết quả tác vụ sinh mã đa ngôn ngữ từ văn bản.

Mô hình    En-Da    En-Lv    En-No    En-Zh    Trung bình
          B-4  EM   B-4  EM   B-4  EM   B-4  EM   B-4  EM
          →  ←     →  ←     →  ←     →  ←     →  ←
Transformer 53.31 - 58.73 - 37.85 - 50.37 - 53.84 - 57.73 - 59.90 - 50.00 - 52.67 -
XLM-R      67.09 - 67.02 - 51.92 - 68.30 - 68.00 - 71.84 - 70.60 - 64.47 - 66.16 -
mT5        67.39 10.6 68.72 24.1 57.69 8.5 64.95 22.2 68.40 12.3 68.02 23.3 72.26 20.0 68.64 24.7 67.01 18.21
Của chúng tôi(L512) 71.16 13.2 72.70 27.2 60.98 10.6 69.28 24.3 71.39 15.7 72.28 26.3 74.53 24.3 72.43 28.5 70.59 21.26
Của chúng tôi(L1024) 70.90 13.6 72.55 27.3 61.30 10.6 69.85 25.1 71.11 15.7 72.49 26.7 74.49 24.7 72.49 28.3 70.65 21.50
Bảng 4: Kết quả dịch tài liệu. Chúng tôi báo cáo điểm số BLEU-4 (B-4) và khớp chính xác (EM).

Mô hình          Tinh chỉnh nhỏ  Tinh chỉnh trung bình
                 B-4    EM      B-4    EM
Sao chép ngây thơ 78.06   0      90.91   0
RoBERTa (mã)     77.30  15.90   90.07  4.10
CodeBERT         77.42  16.40   91.07  5.20
PLBART           77.02  19.21   88.50  8.98
CodeT5           78.06  22.59   88.90  14.18
Của chúng tôi (L512)  80.09  13.21   91.20  2.22
Của chúng tôi (L1024) 80.10  12.43   91.17  2.00
Bảng 5: Kết quả tác vụ sửa chữa chương trình.

et al., 2020), và mT5. Cụ thể, chúng tôi tinh
chỉnh mô hình của chúng tôi theo cách đa ngôn
ngữ trong đó tất cả các cặp ngôn ngữ song
ngữ được học đồng thời.

Mô hình của chúng tôi vượt trội hơn mT5 và
XLM-R trong tất cả tám hướng dịch, chứng
minh rằng mô hình của chúng tôi có thể thực
hiện dịch thuật văn bản-sang-văn bản liên quan
đến mã. Vì thiết kế thí nghiệm chỉ nhằm xác
minh khả năng dịch thuật NL của mô hình
chúng tôi, chúng tôi không tiến hành kết quả
toàn diện để so sánh với các phương pháp
NMT tối tân (SOTA).

4.6 Sửa chữa chương trình (mã-sang-mã)
Chúng tôi tiếp tục xác minh rằng mô hình của
chúng tôi có thể thực hiện sinh mã-sang-mã.
Bảng 5 chứng minh kết quả mô hình so sánh
trên benchmark Bugs2Fix. Các mô hình baseline
bao gồm RoBERTa (mã) - một biến thể PL
của RoBERTa (Liu et al., 2019), CodeBERT
(Feng et al., 2020), PLBART, và CodeT5.

Trên các tác vụ "small" và "medium", mô hình
của chúng tôi đạt điểm số BLEU 80.10 và
91.20, vượt trội hoặc đạt kết quả cạnh tranh
so với hiệu suất SOTA trước đây.9 Kết quả
của các mô hình độ dài 1024 và 512 khác biệt
nhẹ, có thể vì cả dữ liệu Java "small" và "medium"
đều có không quá 100 token độ dài, ngắn hơn
nhiều so với giới hạn độ dài của mô hình chúng tôi.

5 Phân tích
5.1 Thăm dò cú pháp & ngữ nghĩa
Các đoạn mã với các dạng bề mặt trùng lặp cao
nhưng với logic ngữ nghĩa và cú pháp khác
nhau có thể được cho điểm cao bởi các thông
số đánh giá NL, chẳng hạn như BLEU và ROUGE.
Để đánh giá các khía cạnh ngữ nghĩa và cú
pháp của sinh mã từ văn bản, chúng tôi tuân
theo Ren et al. (2020) để áp dụng khớp luồng
dữ liệu và cây cú pháp trừu tượng (AST) để
tính toán độ chính xác của đồ thị luồng dữ
liệu và cây con AST giữa giả thuyết và tham
chiếu. Chúng tôi tham khảo Ren et al. (2020)
để biết thêm chi tiết.

Hình 4 minh họa kết quả khớp luồng dữ liệu
và AST của các mô hình so sánh. Các baseline
PL có xu hướng sinh mã với cấu trúc AST tốt
hơn các mô hình NL. Đặc biệt, mT5 không
thể tạo ra mã với cú pháp AST thích hợp nhưng
có thể khớp hoặc vượt trội hơn những mô hình
khác trong đánh giá luồng dữ liệu trừ các tác
vụ Nga. Mô hình của chúng tôi (L512/1024)
vượt trội hoặc khớp với các baseline về cả
khớp luồng dữ liệu ngữ nghĩa và khớp AST
cú pháp.

5.2 Nghiên cứu loại bỏ
Kết quả định lượng Chúng tôi tiến hành các
thí nghiệm loại bỏ bằng cách loại bỏ các tác
vụ SCLM hoặc PTLM và báo cáo kết quả trung
bình trong Hình 5. Nó cho thấy rằng việc loại
bỏ tác vụ tiền huấn luyện đơn ngôn ngữ (∖SCLM)
hoặc song ngữ (∖PTLM) có thể làm giảm hiệu
suất tổng thể của tất cả các tác vụ. Cụ thể,
việc loại bỏ PTLM sẽ giảm đáng kể hiệu suất
của các tác vụ PL-sang-NL và NL-sang-PL so
với việc loại bỏ SCLM, cho thấy rằng tiền huấn
luyện văn bản song ngữ dựa trên trục quay là
quan trọng để bắc cầu ngầm định giữa các cặp
NL-sang-PL hoặc PL-sang-NL song ngữ không
bao giờ được thấy một cách rõ ràng trong dữ
liệu huấn luyện. Trong khi đó, PTLM đóng
góp nhiều hơn SCLM một chút trong dịch thuật
NL-sang-NL. Chúng tôi nghi ngờ rằng mặc dù
PLTM có thể cung cấp huấn luyện rõ ràng trên
dữ liệu song ngữ, SCLM có thể học ngầm định
các mẫu NL từ lượng lớn các kho dữ liệu huấn
luyện đơn ngôn ngữ. Ngược lại, SCLM đóng
góp tầm thường cho sinh PL-sang-PL, cho thấy
rằng PTLM cho phép mô hình tập trung vào
sinh chuỗi đầy đủ thay vì tái tạo đoạn một
phần. Xem xét rằng kích thước dữ liệu huấn
luyện của kho dữ liệu PL khá hạn chế, chúng
tôi nghi ngờ rằng tiền huấn luyện trên nhiều
repository nguồn mở hơn từ GitHub sẽ mang
lại cải tiến hiệu suất đáng kể hơn. Chúng tôi
tham khảo §A.4 để biết kết quả chi tiết trên
mỗi tác vụ con.

Phân tích ngữ nghĩa & cú pháp PL Chúng tôi
tiếp tục phân tích cấu trúc ngữ nghĩa và cú
pháp của sinh mã đa ngôn ngữ từ văn bản để
so sánh loại bỏ. Hình 7 hiển thị hiệu suất khớp
luồng dữ liệu và AST

9Lưu ý rằng EM chỉ phục vụ như một chỉ số tham
khảo vì nó quá nghiêm ngặt và không chính xác cho
đánh giá, đặc biệt là cho các giả thuyết PL với cùng
logic ngữ nghĩa nhưng dưới nhiều dạng bề mặt khác nhau.

--- TRANG 7 ---
mBART mT5 PLBART CodeT5 Của chúng tôi (L512) Của chúng tôi (L1024) Của chúng tôi (Zero-shot) 6 10 20 30 40 Khớp luồng dữ liệu (%) Ngôn ngữ Es Ja Ru
(a) Khớp luồng dữ liệu ngữ nghĩa (với trục y tỷ lệ log).

mBART mT5 PLBART CodeT5 Của chúng tôi (L512) Của chúng tôi (L1024) Của chúng tôi (Zero-shot) 6 8 10 12 14 16 18 20 Khớp AST (%) Ngôn ngữ Es Ja Ru
(b) Khớp AST cú pháp.

Hình 4: So sánh ngữ nghĩa và cú pháp trong sinh mã đa ngôn ngữ từ văn bản. Tất cả các mô hình so sánh được đánh giá theo cài đặt "translate-train" theo mặc định, trừ khi được chỉ định khác (tức là, "zero-shot").

1 10 Điểm trung bình (tỷ lệ log) PL-sang-NL (BLEU-4) NL-sang-PL (BLEU-4) NL-sang-NL (EM) PL-sang-PL (EM) Phương pháp Của chúng tôi \SCLM \PTLM
Hình 5: Hiệu suất test loại bỏ (tỷ lệ log). Kết quả báo cáo được tính trung bình giữa tất cả các tác vụ con.

trong sinh mã từ văn bản được đưa ra các đầu
vào NL đa ngôn ngữ. Chúng tôi nhận thấy rằng
việc loại bỏ SCLM không ảnh hưởng quá mức
đến luồng dữ liệu ngữ nghĩa và cấu trúc cú
pháp của PL được sinh. Đồng thời, việc loại
bỏ PTLM nhìn chung sẽ gây ra biến động đáng
kể hơn trong ngữ nghĩa và cú pháp của PL
được sinh, cho thấy rằng PTLM có thể cho
phép mô hình nắm bắt căn chỉnh song ngữ và
dịch thuật trên tính đa ngôn ngữ.

5.3 Nhắc nhở Zero-shot
Để xác minh khả năng zero-shot của ERNIE-Code,
chúng tôi tiến hành các thí nghiệm mã-sang-văn bản,
văn bản-sang-mã, và văn bản-sang-văn bản với
nhắc nhở zero-shot. Chính xác, chúng tôi thêm
tiền tố nhắc nhở "translate S to T:\n" vào bên
trái của các đầu vào, trong đó S và T biểu thị
ngôn ngữ nguồn và đích tương ứng. Sau đó,
chúng tôi sử dụng tìm kiếm chùm với năm chùm
để có được các dự đoán zero-shot.

Phân tích định lượng Bảng 2 (hàng cuối) hiển
thị hiệu suất sinh mã-sang-văn bản zero-shot.

--- TRANG 8 ---
¿Cómo contar las vocales en una cadena `s`? Compute la cifra de vocales de una palabra. def contar_vocales(s): return sum(map(s.lower().count, 'aeiouáéíóúü')) Compute the number of vowels in a word. How to count the vowels in a string `s`? Dịch Dịch Giả thuyết Tham chiếu (es)

既存のモデル'old_model'を読み込みデータ`sentences`を用いて学習させて新しいモデルを作る 新しいモデルを学習する model=word2vec.Word2Vec.load('old_model') model.train(sentences) Learn a new model Create a new model by reading an existing model 'old_model' and training it using the data `sentences` Dịch Dịch Giả thuyết Tham chiếu (ja)

Авторизоваться в VK приложении с id `APP_ID` с логином `LOGIN` и паролем `PASS` Создать và загрузить authentication session. def auth_vk_password(): session=vk.AuthSession(app_id=APP_ID, user_login=LOGIN, user_password=PASS) file=open("auth_vk.ini", 'w') file.writelines(session.access_token) return session try: file=open("auth_vk.ini", 'r') except IOError as e: access_token=auth_vk_password().access_token else: access_token=file.readline() session=vk.Session(access_token=access_token) if session: print('Авторизация прошла успешно!') else: print('Авторизация не удалась!') Authorize in VK application with id `APP_ID` with login `LOGIN` and password `PASS` Create and load an authentication session. Dịch Dịch Giả thuyết Tham chiếu (ru)

(a) Tóm tắt mã tiếng Tây Ban Nha
(b) Tóm tắt mã tiếng Nhật Bản
(c) Tóm tắt mã tiếng Nga

Hình 6: Ví dụ về tóm tắt mã đa ngôn ngữ zero-shot (mã-sang-văn bản).

0 5 10 15 20 Điểm (%) Khớp luồng dữ liệu Của chúng tôi \SCLM \PTLM

0 5 10 15 20 Điểm (%) es ja ru Ngôn ngữ Khớp AST

Hình 7: Kết quả loại bỏ trong khớp luồng dữ liệu và AST.

Mô hình của chúng tôi chứng minh khả năng
zero-shot xuất sắc trong sinh tóm tắt tiếng
Nhật Bản và tiếng Nga, thậm chí vượt trội hơn
cài đặt "translate-train" 0.43 / 9.05 trên BLEU / ROUGE-L
nói chung. Điều này là do dữ liệu huấn luyện
được dịch tự động thay vì được chú thích bởi
con người (tức là, cài đặt "translate-train"),
làm giảm chất lượng dữ liệu huấn luyện. Bảng 3
hiển thị rằng mô hình của chúng tôi có thể
sinh ra các đoạn mã zero-shot với điểm số
CodeBLEU cao hơn cài đặt "translate-train".
Điều này chỉ ra rằng tiền huấn luyện NL-PL
đa ngôn ngữ chéo của chúng tôi tạo ra khả
năng học chuyển giao tuyệt vời trong việc bắc
cầu các NL và PL đa ngôn ngữ.

Sinh PL-sang-NL zero-shot Hình 6 trình bày
các ví dụ tóm tắt mã đa ngôn ngữ zero-shot
bằng ba ngôn ngữ đích. Mô hình của chúng
tôi có thể chú ý đến toàn bộ bức tranh của
ngữ nghĩa mã trong khi bỏ qua các mô tả thô
về triển khai chi tiết, chứng minh hiệu quả
của phương pháp chúng tôi trong nhắc nhở
zero-shot. Để mở rộng đánh giá sang NL khác,
chúng tôi tiếp tục phát hành một tập test
Python-Trung Quốc bằng cách dịch mCoNaLa
thành biến thể tiếng Trung Quốc của nó thông
qua crowd-sourcing. Mô hình của chúng tôi
cho thấy khả năng tốt trong sinh PL-sang-Trung Quốc
zero-shot. Chúng tôi đưa ra các demonstration
zero-shot và cung cấp chi tiết tuyển chọn dữ
liệu trong §A.5. Chúng tôi lập luận rằng mô
hình của chúng tôi nắm bắt nhiều thể loại NL
thông qua tiền huấn luyện đa ngôn ngữ chéo.
Chúng tôi khuyến khích cộng đồng phát hành
nhiều benchmark mã-sang-văn bản đa ngôn
ngữ hơn để đánh giá thêm.

Ví dụ định tính (zero-shot) Chúng tôi hiển thị
nhiều ví dụ định tính với nhắc nhở zero-shot
trong §A.6: tóm tắt mã đa ngôn ngữ, sinh
NL-sang-PL, dịch thuật NL zero-shot của thuật
ngữ kỹ thuật theo tám hướng được chọn ngẫu
nhiên.

6 Kết luận
Công trình này thực hiện bước đầu tiên hướng
tới việc kết nối một cách rõ ràng các chương
trình máy tính với ngôn ngữ con người theo
cách đa ngôn ngữ phổ quát. Nhờ tiền huấn
luyện đa ngôn ngữ chéo trên 116 NL và 6 PL,
mô hình của chúng tôi thể hiện hiệu suất mạnh
mẽ trong nhiều tác vụ khác nhau trên các chương
trình máy tính và ngôn ngữ tự nhiên, bao gồm
PL-sang-NL, NL-sang-PL, NL-sang-NL, và
PL-sang-PL. Mô hình của chúng tôi cho thấy
hiệu suất zero-shot tốt thông qua nhắc nhở
trong tóm tắt PL và dịch thuật NL. Cuối cùng,
chúng tôi cung cấp các thảo luận về hạn chế
và công việc tương lai để cải thiện.

Lời cảm ơn
Chúng tôi muốn cảm ơn Xuhong Li và Qiwei
Peng vì những phản hồi hữu ích của họ về
bản thảo ban đầu của công trình này.

--- TRANG 9 ---
Hạn chế
Phát hành benchmark NL-PL đa ngôn ngữ
Mặc dù mô hình của chúng tôi đã được chứng
minh nắm bắt các ngôn ngữ đa ngôn ngữ giữa
con người và chương trình máy tính, chúng
tôi không thể đánh giá một cách hệ thống hiệu
suất của nó trên một loạt các NL đa ngôn ngữ
do thiếu các benchmark tương ứng. Thay vào
đó, chúng tôi tiến hành các thí nghiệm NL-sang-PL
và PL-sang-NL trên mCoNaLa chỉ liên quan
đến ba NL và trình bày các ví dụ minh họa
thông qua nhắc nhở zero-shot để tiết lộ khả
năng đa ngôn ngữ chéo của nó. Chúng tôi khuyến
khích các nhà nghiên cứu trong cộng đồng
phát hành nhiều benchmark NL-PL đa ngôn
ngữ hơn để đẩy nhanh sự phát triển của lĩnh
vực giao thoa này.

Mở rộng quy mô mô hình và dữ liệu Trong
công trình này, chúng tôi chỉ sử dụng dữ liệu
PL từ CodeSearchNet để so sánh công bằng
với các baseline, ngăn cản mô hình học từ
nhiều thể loại PL và hàng tỷ repository nguồn
mở hơn. Tăng lượng dữ liệu cho các cặp NL-PL
song ngữ cũng là một hướng triển vọng, chẳng
hạn như sử dụng tăng cường dữ liệu. Hơn nữa,
quy luật mở rộng cho tiền huấn luyện lớn đã
được nghiên cứu kỹ lưỡng và cho thấy những
cải tiến hiệu suất đáng kể trong tài liệu (Chen
et al., 2021; Li et al., 2022). Một nỗ lực có
mục tiêu trong việc mở rộng kích thước dữ
liệu tiền huấn luyện và mở rộng quy mô mô
hình có thể mang lại cải tiến đáng kể hơn
hướng tới tiền huấn luyện NL-PL đa ngôn
ngữ phổ quát.

Lời nguyền của tính đa ngôn ngữ Chúng tôi
lập luận rằng lời nguyền của tính đa ngôn ngữ
(Conneau et al., 2020) cũng tồn tại trong tiền
huấn luyện NL-PL đa ngôn ngữ thống nhất,
trong đó khả năng cho mỗi ngôn ngữ giảm
khi số lượng ngôn ngữ tăng với kích thước
mô hình cố định. Việc điều tra vấn đề lời
nguyền của tính đa ngôn ngữ trong công trình
này là một hướng thú vị.

Tài liệu tham khảo
Wasi Uddin Ahmad, Saikat Chakraborty, Baishakhi
Ray, and Kai-Wei Chang. 2021. Tiền huấn luyện
thống nhất cho hiểu và sinh chương trình. Trong
Proceedings of the 2021 Conference of the North
American Chapter of the Association for Computational
Linguistics: Human Language Technologies,
NAACL-HLT 2021, Online, June 6-11, 2021,
trang 2655–2668. Association for Computational
Linguistics.

Jacob Austin, Augustus Odena, Maxwell Nye, Maarten
Bosma, Henryk Michalewski, David Dohan, Ellen
Jiang, Carrie J. Cai, Michael Terry, Quoc V. Le, và
Charles Sutton. 2021. Tổng hợp chương trình với
các mô hình ngôn ngữ lớn. ArXiv, abs/2108.07732.

Yekun Chai, Shuo Jin, và Xinwen Hou. 2020. Highway
transformer: Mạng tự chú ý tăng cường tự cổng.
Trong Proceedings of the 58th Annual Meeting of
the Association for Computational Linguistics,
trang 6887–6900, Online. Association for Computational
Linguistics.

Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan,
Henrique Ponde, Jared Kaplan, Harrison Edwards,
Yura Burda, Nicholas Joseph, Greg Brockman, Alex
Ray, Raul Puri, Gretchen Krueger, Michael Petrov,
Heidy Khlaaf, Girish Sastry, Pamela Mishkin,
Brooke Chan, Scott Gray, Nick Ryder, Mikhail
Pavlov, Alethea Power, Lukasz Kaiser, Mohammad
Bavarian, Clemens Winter, Philippe Tillet, Felipe
Petroski Such, David W. Cummings, Matthias
Plappert, Fotios Chantzis, Elizabeth Barnes, Ariel
Herbert-Voss, William H. Guss, Alex Nichol, Igor
Babuschkin, S. Arun Balaji, Shantanu Jain, Andrew
Carr, Jan Leike, Joshua Achiam, Vedant Misra,
Evan Morikawa, Alec Radford, Matthew M. Knight,
Miles Brundage, Mira Murati, Katie Mayer, Peter
Welinder, Bob McGrew, Dario Amodei, Sam McCandlish,
Ilya Sutskever, và Wojciech Zaremba. 2021. Đánh
giá các mô hình ngôn ngữ lớn được huấn luyện trên mã.
ArXiv, abs/2107.03374.

Colin B. Clement, Dawn Drain, Jonathan Timcheck,
Alexey Svyatkovskiy, và Neel Sundaresan. 2020.
Pymt5: dịch thuật đa chế độ của ngôn ngữ tự nhiên
và mã python với transformers. Trong Proceedings
of the 2020 Conference on Empirical Methods in
Natural Language Processing, EMNLP 2020, Online,
November 16-20, 2020, trang 9052–9065. Association
for Computational Linguistics.

Alexis Conneau, Kartikay Khandelwal, Naman Goyal,
Vishrav Chaudhary, Guillaume Wenzek, Francisco
Guzmán, Edouard Grave, Myle Ott, Luke Zettlemoyer,
và Veselin Stoyanov. 2020. Học biểu diễn đa ngôn
ngữ chéo không giám sát ở quy mô lớn. Trong
Proceedings of the 58th Annual Meeting of the
Association for Computational Linguistics, ACL
2020, Online, July 5-10, 2020, trang 8440–8451.
Association for Computational Linguistics.

Alexis Conneau và Guillaume Lample. 2019. Tiền
huấn luyện mô hình ngôn ngữ đa ngôn ngữ chéo.
Trong Advances in Neural Information Processing
Systems 32: Annual Conference on Neural Information
Processing Systems 2019, NeurIPS 2019, December
8-14, 2019, Vancouver, BC, Canada, trang 7057–7067.

Zhangyin Feng, Daya Guo, Duyu Tang, Nan Duan,
Xiaocheng Feng, Ming Gong, Linjun Shou, Bing
Qin, Ting Liu, Daxin Jiang, và Ming Zhou. 2020.
Codebert: Một mô hình tiền huấn luyện cho lập
trình và ngôn ngữ tự nhiên. Trong Findings of
the Association for Computational Linguistics:
EMNLP 2020, Online Event, 16-20 November 2020,
volume EMNLP 2020

--- TRANG 10 ---
của Findings of ACL, trang 1536–1547. Association
for Computational Linguistics.

Daniel Fried, Armen Aghajanyan, Jessy Lin, Sida I.
Wang, Eric Wallace, Freda Shi, Ruiqi Zhong, Wen
tau Yih, Luke Zettlemoyer, và Mike Lewis. 2022.
Incoder: Một mô hình sinh cho điền và tổng hợp mã.
ArXiv, abs/2204.05999.

A. Gispert và José B. Mariño. 2006. Dịch máy thống
kê Catalan-English không có kho dữ liệu song song:
Bắc cầu qua tiếng Tây Ban Nha.

Naman Goyal, Cynthia Gao, Vishrav Chaudhary,
Peng-Jen Chen, Guillaume Wenzek, Da Ju, Sanjana
Krishnan, Marc'Aurelio Ranzato, Francisco Guzmán,
và Angela Fan. 2022. Benchmark đánh giá Flores-101
cho dịch máy tài nguyên thấp và đa ngôn ngữ.
Transactions of the Association for Computational
Linguistics, 10:522–538.

Philip J. Guo. 2018. Người nói tiếng Anh không bản
ngữ học lập trình máy tính: Rào cản, mong muốn,
và cơ hội thiết kế. Proceedings of the 2018 CHI
Conference on Human Factors in Computing Systems.

Hamel Husain, Hongqi Wu, Tiferet Gazit, Miltiadis
Allamanis, và Marc Brockschmidt. 2019. Thử thách
CodeSearchNet: Đánh giá trạng thái tìm kiếm mã
ngữ nghĩa. ArXiv, abs/1909.09436.

Melvin Johnson, Mike Schuster, Quoc V. Le, Maxim
Krikun, Yonghui Wu, Z. Chen, Nikhil Thorat, Fernanda
B. Viégas, Martin Wattenberg, Gregory S. Corrado,
Macduff Hughes, và Jeffrey Dean. 2017. Hệ thống
dịch máy thần kinh đa ngôn ngữ của Google: Kích
hoạt dịch thuật zero-shot. Transactions of the
Association for Computational Linguistics, 5:339–351.

Armand Joulin, Edouard Grave, Piotr Bojanowski,
và Tomas Mikolov. 2016. Túi kỹ thuật để phân
loại văn bản hiệu quả. arXiv preprint arXiv:1607.01759.

Taku Kudo. 2018. Điều chuẩn từ con: Cải thiện các
mô hình dịch thuật mạng thần kinh với nhiều ứng
cử viên từ con. Trong Proceedings of the 56th
Annual Meeting of the Association for Computational
Linguistics (Volume 1: Long Papers), trang 66–75,
Melbourne, Australia. Association for Computational
Linguistics.

Taku Kudo và John Richardson. 2018. SentencePiece:
Một tokenizer và detokenizer từ con đơn giản và
độc lập ngôn ngữ cho xử lý văn bản thần kinh.
Trong Proceedings of the 2018 Conference on
Empirical Methods in Natural Language Processing:
System Demonstrations, trang 66–71, Brussels,
Belgium. Association for Computational Linguistics.

Anoop Kunchukuttan, Pratik Mehta, và Pushpak
Bhattacharyya. 2018. Kho dữ liệu song song tiếng
Anh-Hindi IIT Bombay. Trong Proceedings of the
Eleventh International Conference on Language
Resources and Evaluation, LREC 2018, Miyazaki,
Japan, May 7-12, 2018. European Language Resources
Association (ELRA).

Mike Lewis, Yinhan Liu, Naman Goyal, Marjan
Ghazvininejad, Abdelrahman Mohamed, Omer Levy,
Veselin Stoyanov, và Luke Zettlemoyer. 2020.
BART: Tiền huấn luyện sequence-to-sequence khử
nhiễu cho sinh, dịch, và hiểu ngôn ngữ tự nhiên.
Trong Proceedings of the 58th Annual Meeting of
the Association for Computational Linguistics,
trang 7871–7880, Online. Association for Computational
Linguistics.

Xiaonan Li, Yeyun Gong, Yelong Shen, Xipeng Qiu,
Hang Zhang, Bolun Yao, Weizhen Qi, Daxin Jiang,
Weizhu Chen, và Nan Duan. 2021. Coderetriever:
Học tương phản đơn chế độ và song chế độ cho
tìm kiếm mã.

Yujia Li, David H. Choi, Junyoung Chung, Nate
Kushman, Julian Schrittwieser, Rémi Leblond, Tom
Eccles, James Keeling, Felix Gimeno, Agustin Dal
Lago, Thomas Hubert, Peter Choy, Cyprien de
Masson d'Autume, Igor Babuschkin, Xinyun Chen,
Po-Sen Huang, Johannes Welbl, Sven Gowal, Alexey
Cherepanov, James Molloy, Daniel Jaymin Mankowitz,
Esme Sutherland Robson, Pushmeet Kohli, Nando
de Freitas, Koray Kavukcuoglu, và Oriol Vinyals.
2022. Sinh mã cấp độ cạnh tranh với alphacode.
ArXiv, abs/2203.07814.

Chin-Yew Lin. 2004. ROUGE: Một gói cho đánh giá
tự động các bản tóm tắt. Trong Text Summarization
Branches Out, trang 74–81, Barcelona, Spain.
Association for Computational Linguistics.

Yinhan Liu, Jiatao Gu, Naman Goyal, Xian Li,
Sergey Edunov, Marjan Ghazvininejad, Mike Lewis,
và Luke Zettlemoyer. 2020. Tiền huấn luyện khử
nhiễu đa ngôn ngữ cho dịch máy thần kinh. Transactions
of the Association for Computational Linguistics,
8:726–742.

Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du,
Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis,
Luke Zettlemoyer, và Veselin Stoyanov. 2019.
Roberta: Một cách tiếp cận tiền huấn luyện bert
được tối ưu hóa mạnh mẽ. ArXiv, abs/1907.11692.

Ilya Loshchilov và Frank Hutter. 2019. Điều chuẩn
phân rã trọng số tách rời. Trong International
Conference on Learning Representations.

Shuai Lu, Daya Guo, Shuo Ren, Junjie Huang,
Alexey Svyatkovskiy, Ambrosio Blanco, Colin
Clement, Dawn Drain, Daxin Jiang, Duyu Tang,
Ge Li, Lidong Zhou, Linjun Shou, Long Zhou,
Michele Tufano, MING GONG, Ming Zhou, Nan
Duan, Neel Sundaresan, Shao Kun Deng, Shengyu
Fu, và Shujie LIU. 2021a. Codexglue: Một tập
dữ liệu benchmark học máy cho hiểu và sinh mã.
Trong Proceedings of the Neural Information
Processing Systems Track on Datasets and Benchmarks,
volume 1.

--- TRANG 11 ---
Shuai Lu, Daya Guo, Shuo Ren, Junjie Huang,
Alexey Svyatkovskiy, Ambrosio Blanco, Colin B.
Clement, Dawn Drain, Daxin Jiang, Duyu Tang,
Ge Li, Lidong Zhou, Linjun Shou, Long Zhou,
Michele Tufano, Ming Gong, Ming Zhou, Nan Duan,
Neel Sundaresan, Shao Kun Deng, Shengyu Fu,
và Shujie Liu. 2021b. Codexglue: Một tập dữ liệu
benchmark học máy cho hiểu và sinh mã. Trong
Proceedings of the Neural Information Processing
Systems Track on Datasets and Benchmarks 1,
NeurIPS Datasets and Benchmarks 2021, December
2021, virtual.

Erik Nijkamp, Bo Pang, Hiroaki Hayashi, Lifu Tu,
Haiquan Wang, Yingbo Zhou, Silvio Savarese,
và Caiming Xiong. 2022. Một mô hình hội thoại
cho tổng hợp chương trình. ArXiv, abs/2203.13474.

Maja Popović. 2015. chrF: điểm F n-gram ký tự
cho đánh giá MT tự động. Trong Proceedings of
the Tenth Workshop on Statistical Machine Translation,
trang 392–395, Lisbon, Portugal. Association for
Computational Linguistics.

Matt Post. 2018. Một lời kêu gọi rõ ràng trong
báo cáo điểm số BLEU. Trong Proceedings of the
Third Conference on Machine Translation: Research
Papers, trang 186–191, Brussels, Belgium. Association
for Computational Linguistics.

Colin Raffel, Noam Shazeer, Adam Roberts, Katherine
Lee, Sharan Narang, Michael Matena, Yanqi Zhou,
Wei Li, và Peter J. Liu. 2020. Khám phá giới hạn
của học chuyển giao với một transformer văn bản-sang-văn bản
thống nhất. J. Mach. Learn. Res., 21:140:1–140:67.

Samyam Rajbhandari, Jeff Rasley, Olatunji Ruwase,
và Yuxiong He. 2020. Zero: Tối ưu hóa bộ nhớ
hướng tới huấn luyện các mô hình nghìn tỷ tham số.
Trong SC20: International Conference for High
Performance Computing, Networking, Storage and
Analysis, trang 1–16. IEEE.

Shuo Ren, Daya Guo, Shuai Lu, Long Zhou, Shujie
Liu, Duyu Tang, M. Zhou, Ambrosio Blanco, và
Shuai Ma. 2020. Codebleu: một phương pháp để
đánh giá tự động tổng hợp mã. ArXiv, abs/2009.10297.

Holger Schwenk, Vishrav Chaudhary, Shuo Sun,
Hongyu Gong, và Francisco Guzmán. 2021. Wikimatrix:
Khai thác 135m câu song song trong 1620 cặp
ngôn ngữ từ wikipedia. Trong Proceedings of the
16th Conference of the European Chapter of the
Association for Computational Linguistics: Main
Volume, EACL 2021, Online, April 19 - 23, 2021,
trang 1351–1361. Association for Computational
Linguistics.

Noam Shazeer và Mitchell Stern. 2018. Adafactor:
Tỷ lệ học thích ứng với chi phí bộ nhớ dưới tuyến tính.
Trong International Conference on Machine Learning,
trang 4596–4604. PMLR.

Noam M. Shazeer. 2020. Các biến thể glu cải thiện
transformer. ArXiv, abs/2002.05202.

Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky,
Ilya Sutskever, và Ruslan Salakhutdinov. 2014.
Dropout: một cách đơn giản để ngăn chặn quá khớp
mạng thần kinh. The journal of machine learning
research, 15(1):1929–1958.

Jörg Tiedemann. 2012. Dữ liệu song song, công cụ
và giao diện trong OPUS. Trong Proceedings of
the Eighth International Conference on Language
Resources and Evaluation, LREC 2012, Istanbul,
Turkey, May 23-25, 2012, trang 2214–2218. European
Language Resources Association (ELRA).

Michele Tufano, Cody Watson, Gabriele Bavota,
Massimiliano Di Penta, Martin White, và Denys
Poshyvanyk. 2019. Một nghiên cứu thực nghiệm
về học các bản vá sửa lỗi trong tự nhiên thông
qua dịch máy thần kinh. ACM Transactions on
Software Engineering and Methodology (TOSEM),
28:1 – 29.

Masao Utiyama và Hitoshi Isahara. 2007. Một so
sánh các phương pháp trục quay cho dịch máy
thống kê dựa trên cụm từ. Trong Human Language
Technologies 2007: The Conference of the North
American Chapter of the Association for Computational
Linguistics; Proceedings of the Main Conference,
trang 484–491, Rochester, New York. Association
for Computational Linguistics.

Yue Wang, Weishi Wang, Shafiq R. Joty, và Steven
C. H. Hoi. 2021. Codet5: Các mô hình encoder-decoder
tiền huấn luyện thống nhất nhận biết định danh
cho hiểu và sinh mã. Trong Proceedings of the
2021 Conference on Empirical Methods in Natural
Language Processing, EMNLP 2021, Virtual Event /
Punta Cana, Dominican Republic, 7-11 November,
2021, trang 8696–8708. Association for Computational
Linguistics.

Zhiruo Wang, Grace Cuenca, Shuyan Zhou, Frank F.
Xu, và Graham Neubig. 2022. Mconala: Một benchmark
cho sinh mã từ nhiều ngôn ngữ tự nhiên. ArXiv,
abs/2203.08388.

Guillaume Wenzek, Marie-Anne Lachaux, Alexis
Conneau, Vishrav Chaudhary, Francisco Guzmán,
Armand Joulin, và Edouard Grave. 2019. Ccnet:
Trích xuất các tập dữ liệu đơn ngôn ngữ chất lượng
cao từ dữ liệu thu thập web. Trong International
Conference on Language Resources and Evaluation.

Yonghui Wu, Mike Schuster, Z. Chen, Quoc V. Le,
Mohammad Norouzi, Wolfgang Macherey, Maxim
Krikun, Yuan Cao, Qin Gao, Klaus Macherey,
Jeff Klingner, Apurva Shah, Melvin Johnson,
Xiaobing Liu, Lukasz Kaiser, Stephan Gouws,
Yoshikiyo Kato, Taku Kudo, Hideto Kazawa, Keith
Stevens, George Kurian, Nishant Patil, Wei Wang,
Cliff Young, Jason R. Smith, Jason Riesa, Alex
Rudnick, Oriol Vinyals, Gregory S. Corrado, Macduff
Hughes, và Jeffrey Dean. 2016. Hệ thống dịch máy
thần kinh của Google: Bắc cầu khoảng cách giữa
dịch thuật của con người và máy. ArXiv, abs/1609.08144.

Frank F. Xu, Uri Alon, Graham Neubig, và Vincent J.
Hellendoorn. 2022. Một đánh giá hệ thống các
mô hình ngôn ngữ lớn của mã. Proceedings of the
6th ACM SIGPLAN International Symposium on
Machine Programming.

--- TRANG 12 ---
Linting Xue, Noah Constant, Adam Roberts, Mihir
Kale, Rami Al-Rfou, Aditya Siddhant, Aditya
Barua, và Colin Raffel. 2021. mt5: Một transformer
văn bản-sang-văn bản tiền huấn luyện đa ngôn
ngữ quy mô lớn. Trong Proceedings of the 2021
Conference of the North American Chapter of the
Association for Computational Linguistics: Human
Language Technologies, NAACL-HLT 2021, Online,
June 6-11, 2021, trang 483–498. Association for
Computational Linguistics.

Pengcheng Yin, Bowen Deng, Edgar Chen, Bogdan
Vasilescu, và Graham Neubig. 2018. Học để khai
thác các cặp mã và ngôn ngữ tự nhiên được căn
chỉnh từ stack overflow. Trong International
Conference on Mining Software Repositories,
MSR, trang 476–486. ACM.

Michal Ziemski, Marcin Junczys-Dowmunt, và Bruno
Pouliquen. 2016. Kho dữ liệu song song Liên Hợp
Quốc v1.0. Trong Proceedings of the Tenth International
Conference on Language Resources and Evaluation
LREC 2016, Portorož, Slovenia, May 23-28, 2016.
European Language Resources Association (ELRA).

--- TRANG 13 ---
A Phụ lục
A.1 Biểu diễn đầu vào
Chúng tôi dựa lexer văn bản/mã chung của chúng
tôi trên tokenizer mT5 - SentencePiece (Kudo
và Richardson, 2018), cụ thể là mô hình ngôn
ngữ unigram (Kudo, 2018). Vì phân phối từ trong
PL về bản chất khác với NL, việc áp dụng trực
tiếp tokenization SentencePiece trên PL là không
khả thi. SentencePiece không hiệu quả trong
việc mã hóa các ký tự khoảng trắng - chẳng hạn
như khoảng trắng, tab \t, và ký tự xuống dòng
\n - điều này rất quan trọng trong việc đại diện
cấu trúc và thụt lề trong mã nguồn. Do đó, chúng
tôi thêm một tập hợp các token bổ sung để mã
hóa khoảng trắng có độ dài khác nhau trong PL.
Xem xét rằng các nhà phát triển với thói quen
lập trình khác nhau có thể gõ thụt lề với độ dài
và ký tự khác nhau (tab hoặc khoảng trắng),
chúng tôi thêm khoảng trắng có độ dài-1/2/4
(ký hiệu là <space *1>, <space *2>, <space *4>
tương ứng), và tab \t để đại diện cho các thụt
lề khác nhau. Hơn nữa, chúng tôi sử dụng ký
hiệu xuống dòng \n để mã hóa ngắt dòng.
Tokenizer của chúng tôi cuối cùng bao gồm
250,105 từ vựng SentencePiece. Hình 8 trình
bày một ví dụ tokenization của đoạn Python.
SentencePiece có xu hướng chuẩn hóa khoảng
trắng và bỏ qua các ký tự trống thừa, trong khi
tokenizer đã sửa đổi của chúng tôi cho phép
mô hình đối phó với các ký tự khoảng trắng
chẳng hạn như thụt lề trong PL.

Hình 8: Ví dụ tokenization NL/PL chung (Python).
"</s>" đại diện cho token kết thúc câu.

A.2 Dữ liệu tiền huấn luyện
A.2.1 Dữ liệu PL
Bảng 6 hiển thị thống kê của dữ liệu PL đơn
ngôn ngữ và các cặp NL-PL song song, bao gồm
6.5 triệu mẫu đơn ngôn ngữ và 1.9 triệu cặp
NL-PL trong sáu PL khác nhau. Chúng tôi không
sử dụng các repository mã bổ sung từ GitHub
để so sánh công bằng với các mô hình PL baseline.

PL    #Mẫu    #Cặp NL-PL
Go    726,768  317,832
Java  1,569,889 454,451
JavaScript 1,857,835 123,889
PHP   977,821  523,712
Python 1,156,085 412,178
Ruby  164,048  48,791
#Tổng cộng 6,452,446 1,880,853
Bảng 6: Thống kê CodeSearchNet trong sáu PL,
tổng cộng 6.5 triệu instance PL đơn ngôn ngữ
và 1.5 triệu mẫu NL-PL song song.

Dữ liệu NL cũng có thể tồn tại trong dữ liệu
PL được ghép đôi của chúng, phục vụ như một
bình luận hoặc docstring. Nó có thể dẫn đến
rò rỉ dữ liệu cho dịch thuật PL-sang-NL nếu
NL đã được đưa ra như một phần của đầu vào
PL, do đó làm tổn hại hiệu suất test mã-sang-văn bản.
Theo đó, đối với tất cả sinh mã-sang-văn bản
và ngẫu nhiên 50% sinh văn bản-sang-mã trong
huấn luyện PTLM, chúng tôi thay thế tất cả
các câu NL bằng một placeholder NL "<|removed|>"
nếu nó tồn tại trong các đoạn PL tương ứng.

Chúng tôi bổ sung quan sát thấy rằng dữ liệu
song song trong CodeSearchNet chỉ chứa ít
NL không phải tiếng Anh. Việc trực tiếp coi
tất cả NL trong CodeSearchNet là tiếng Anh
sẽ làm mô hình lẫn lộn trong việc phân biệt
các NL khác nhau. Để tận dụng tốt hơn tín hiệu
giám sát song song này, chúng tôi sử dụng công
cụ FastText (Joulin et al., 2016)10 để xác định
các NL khác nhau. Cụ thể, chúng tôi chỉ xem
xét các câu NL với độ tin cậy cao hơn 80%
được dự đoán bởi FastText. Trong huấn luyện
PTLM, chúng tôi sử dụng thể loại ngôn ngữ
được dự đoán với xác suất 50% ngẫu nhiên;
nếu không, chúng tôi coi mẫu là "text" thay vì
"English". Do đó, mô hình có thể ngầm định
phân biệt các thể loại ngôn ngữ khác nhau mà
không bị tiếp xúc với giám sát sai lệch.

A.2.2 Dữ liệu NL
Kho dữ liệu NL đơn ngôn ngữ CC-10011 được
xây dựng bằng cách xử lý các snapshot CommonCrawl
(Wenzek et al., 2019). Tập dữ liệu CC-100 ban
đầu bao gồm các tài liệu được phân tách bằng
xuống dòng kép. Chúng tôi duy trì kho dữ liệu
cấp tài liệu bằng cách nối các đoạn văn trong
cùng một trang tài liệu. Bảng 7 tóm tắt thống
kê của dữ liệu đã xử lý của chúng tôi, tổng cộng
1.5 tỷ trang tài liệu huấn luyện trong 116 NL
đơn ngôn ngữ. Chúng tôi tái tỷ lệ phân phối
dữ liệu theo số lượng trang như đã đề cập trước
đó trong Eq. (3) với α = 0,3.

10https://fasttext.cc/docs/en/language-identification.html
11https://data.statmt.org/cc-100

--- TRANG 14 ---
Mã ISO  Ngôn ngữ  #Trang (M)  Phần trăm (%)  Mã ISO  Ngôn ngữ  #Trang (M)  Phần trăm (%)
af      Afrikaans     1.3      0.09          lt      Lithuanian    9.19     0.61
am      Amharic       0.24     0.02          lv      Latvian       5.83     0.39
ar      Arabic        15.04    1.0           mg      Malagasy      0.15     0.01
as      Assamese      0.05     0.0           mk      Macedonian    1.78     0.12
az      Azerbaijani   4.1      0.27          ml      Malayalam     1.9      0.13
be      Belarusian    1.45     0.1           mn      Mongolian     0.96     0.06
bg      Bulgarian     18.16    1.21          mr      Marathi       1.01     0.07
bn      Bengali       4.11     0.27          ms      Malay         11.92    0.79
bn_rom  Bengali Romanized  6.5  0.43         my      Burmese       0.22     0.01
br      Breton        0.14     0.01          my_zaw  Burmese (Zawgyi) 0.88  0.06
bs      Bosnian       0.4      0.03          ne      Nepali        1.13     0.08
ca      Catalan       7.01     0.47          nl      Dutch         31.16    2.08
cs      Czech         10.15    0.68          no      Norwegian     28.8     1.92
cy      Welsh         0.71     0.05          ns      Northern Sotho 0.03    0.0
da      Danish        30.19    2.01          om      Oromo         0.08     0.01
de      German        69.02    4.6           or      Oriya         0.19     0.01
el      Modern Greek  12.33    0.82          pa      Panjabi       0.33     0.02
en      English       247.59   16.49         pl      Polish        31.2     2.08
eo      Esperanto     0.58     0.04          ps      Pushto        0.26     0.02
es      Spanish       60.54    4.03          pt      Portuguese    39.0     2.6
et      Estonian      3.94     0.26          qu      Quechua       0.03     0.0
eu      Basque        1.86     0.12          rm      Romansh       0.03     0.0
fa      Persian       36.96    2.46          ro      Romanian      30.21    2.01
ff      Fulah         0.02     0.0           ru      Russian       123.18   8.2
fi      Finnish       28.12    1.87          sa      Sanskrit      0.12     0.01
fr      French        62.11    4.14          sc      Sardinian     0.0      0.0
fy      Western Frisian 0.2    0.01          sd      Sindhi        0.08     0.01
ga      Irish         0.52     0.03          si      Sinhala       0.67     0.04
gd      Scottish Gaelic 0.11   0.01          sk      Slovak        17.0     1.13
gl      Galician      1.85     0.12          sl      Slovenian     6.24     0.42
gn      Guarani       0.02     0.0           so      Somali        0.4      0.03
gu      Gujarati      0.75     0.05          sq      Albanian      2.72     0.18
ha      Hausa         0.46     0.03          sr      Serbian       2.7      0.18
he      Hebrew        12.77    0.85          ss      Swati         0.0      0.0
hi      Hindi         8.11     0.54          su      Sundanese     0.06     0.0
hi_rom  Hindi Romanized 1.97   0.13          sv      Swedish       46.77    3.12
hr      Croatian      16.54    1.1           sw      Swahili       1.13     0.08
ht      Haitian       0.09     0.01          ta      Tamil         4.12     0.27
hu      Hungarian     26.14    1.74          ta_rom  Tamil Romanized 1.6    0.11
hy      Armenian      2.14     0.14          te      Telugu        1.21     0.08
id      Indonesian    79.68    5.31          te_rom  Telugu Romanized 1.9   0.13
ig      Igbo          0.04     0.0           th      Thai          23.92    1.59
is      Icelandic     2.06     0.14          tl      Tagalog       2.64     0.18
it      Italian       24.67    1.64          tn      Tswana        0.24     0.02
ja      Japanese      65.61    4.37          tr      Turkish       18.42    1.23
jv      Javanese      0.31     0.02          ug      Uighur        0.11     0.01
ka      Georgian      2.68     0.18          uk      Ukrainian     24.98    1.66
kk      Kazakh        1.77     0.12          ur      Urdu          2.26     0.15
km      Central Khmer 0.61     0.04          ur_rom  Urdu Romanized 4.58    0.3
kn      Kannada       0.91     0.06          uz      Uzbek         0.46     0.03
ko      Korean        35.68    2.38          vi      Vietnamese    52.48    3.5
ku      Kurdish       0.24     0.02          wo      Wolof         0.13     0.01
ky      Kirghiz       0.41     0.03          xh      Xhosa         0.15     0.01
la      Latin         3.1      0.21          yi      Yiddish       0.15     0.01
lg      Ganda         0.09     0.01          yo      Yoruba        0.02     0.0
li      Limburgan     0.02     0.0           zh      Chinese (Simplified) 40.0 2.66
ln      Lingala       0.02     0.0           zh-Hant Chinese (Traditional) 12.33 0.82
lo      Lao           0.2      0.01          zu      Zulu          0.07     0.0

Bảng 7: Thống kê kho dữ liệu CC-100, tổng cộng 1.5 tỷ trang tài liệu huấn luyện từ 116 NL khác nhau. Trang huấn luyện và tỷ lệ phần trăm được báo cáo được tính toán theo phân phối tài liệu của dữ liệu gốc. Lưu ý rằng 116 NL của chúng tôi bao gồm 5 biến thể La Mã hóa của các ngôn ngữ hiện có được ký hiệu bằng "Romanized".

--- TRANG 15 ---
Mã ISO  Ngôn ngữ 1  Ngôn ngữ 2  #Cặp (M)  Phần trăm (%)  Mã ISO  Ngôn ngữ 1  Ngôn ngữ 2  #Cặp (M)  Phần trăm (%)
ar-bg   Arabic    Bulgarian   46.57    0.59          en-ru   English   Russian     312.91   3.99
ar-de   Arabic    German      44.58    0.57          en-sw   English   Swahili     9.41     0.12
ar-el   Arabic    Greek       45.66    0.58          en-th   English   Thai        26.11    0.33
ar-en   Arabic    English     199.26   2.54          en-tr   English   Turkish     196.96   2.51
ar-es   Arabic    Spanish     141.9    1.81          en-ur   English   Urdu        11.04    0.14
ar-fr   Arabic    French      118.52   1.51          en-vi   English   Vietnamese  79.56    1.02
ar-hi   Arabic    Hindi       7.24     0.09          en-zh   English   Chinese     156.31   1.99
ar-ru   Arabic    Russian     96.15    1.23          es-fr   Spanish   French      522.47   6.67
ar-sw   Arabic    Swahili     2.38     0.03          es-hi   Spanish   Hindi       15.93    0.2
ar-th   Arabic    Thai        9.42     0.12          es-ru   Spanish   Russian     166.12   2.12
ar-tr   Arabic    Turkish     58.32    0.74          es-sw   Spanish   Swahili     7.88     0.1
ar-ur   Arabic    Urdu        2.43     0.03          es-th   Spanish   Thai        10.15    0.13
ar-vi   Arabic    Vietnamese  17.36    0.22          es-tr   Spanish   Turkish     105.87   1.35
ar-zh   Arabic    Chinese     55.68    0.71          es-ur   Spanish   Urdu        0.8      0.01
bg-de   Bulgarian German      57.71    0.74          es-vi   Spanish   Vietnamese  44.33    0.57
bg-el   Bulgarian Greek       68.07    0.87          es-zh   Spanish   Chinese     74.93    0.96
bg-en   Bulgarian English     151.04   1.93          fr-hi   French    Hindi       15.38    0.2
bg-es   Bulgarian Spanish     86.31    1.1           fr-ru   French    Russian     154.58   1.97
bg-fr   Bulgarian French      69.09    0.88          fr-sw   French    Swahili     8.91     0.11
bg-hi   Bulgarian Hindi       3.35     0.04          fr-th   French    Thai        8.7      0.11
bg-ru   Bulgarian Russian     66.25    0.85          fr-tr   French    Turkish     85.83    1.1
bg-sw   Bulgarian Swahili     1.12     0.01          fr-ur   French    Urdu        0.74     0.01
bg-th   Bulgarian Thai        6.98     0.09          fr-vi   French    Vietnamese  25.37    0.32
bg-tr   Bulgarian Turkish     66.06    0.84          fr-zh   French    Chinese     70.14    0.9
bg-ur   Bulgarian Urdu        0.59     0.01          hi-ru   Hindi     Russian     7.32     0.09
bg-vi   Bulgarian Vietnamese  11.23    0.14          hi-sw   Hindi     Swahili     1.46     0.02
bg-zh   Bulgarian Chinese     11.56    0.15          hi-th   Hindi     Thai        2.69     0.03
de-el   German    Greek       72.85    0.93          hi-tr   Hindi     Turkish     8.75     0.11
de-en   German    English     655.83   8.37          hi-ur   Hindi     Urdu        1.49     0.02
de-es   German    Spanish     242.73   3.1           hi-vi   Hindi     Vietnamese  6.11     0.08
de-fr   German    French      269.02   3.43          hi-zh   Hindi     Chinese     2.39     0.03
de-hi   German    Hindi       9.36     0.12          ru-sw   Russian   Swahili     2.17     0.03
de-ru   German    Russian     80.08    1.02          ru-th   Russian   Thai        8.12     0.1
de-sw   German    Swahili     3.22     0.04          ru-tr   Russian   Turkish     51.77    0.66
de-th   German    Thai        7.07     0.09          ru-ur   Russian   Urdu        2.56     0.03
de-tr   German    Turkish     57.14    0.73          ru-vi   Russian   Vietnamese  16.47    0.21
de-ur   German    Urdu        0.86     0.01          ru-zh   Russian   Chinese     61.53    0.79
de-vi   German    Vietnamese  20.77    0.27          sw-th   Swahili   Thai        0.49     0.01
de-zh   German    Chinese     22.8     0.29          sw-tr   Swahili   Turkish     4.16     0.05
el-en   Greek     English     190.87   2.44          sw-ur   Swahili   Urdu        0.39     0.0
el-es   Greek     Spanish     133.05   1.7           sw-vi   Swahili   Vietnamese  3.02     0.04
el-fr   Greek     French      117.73   1.5           sw-zh   Swahili   Chinese     1.08     0.01
el-hi   Greek     Hindi       4.55     0.06          th-tr   Thai      Turkish     9.26     0.12
el-ru   Greek     Russian     45.1     0.58          th-ur   Thai      Urdu        0.64     0.01
el-sw   Greek     Swahili     1.84     0.02          th-vi   Thai      Vietnamese  4.62     0.06
el-th   Greek     Thai        5.83     0.07          th-zh   Thai      Chinese     0.97     0.01
el-tr   Greek     Turkish     69.81    0.89          tr-ur   Turkish   Urdu        4.34     0.06
el-ur   Greek     Urdu        0.31     0.0           tr-vi   Turkish   Vietnamese  16.29    0.21
el-vi   Greek     Vietnamese  14.84    0.19          tr-zh   Turkish   Chinese     14.62    0.19
el-zh   Greek     Chinese     11.44    0.15          ur-vi   Urdu      Vietnamese  0.58     0.01
en-es   English   Spanish     1088.62  13.89         ur-zh   Urdu      Chinese     0.11     0.0
en-fr   English   French      884.16   11.28         vi-zh   Vietnamese Chinese     9.31     0.12
en-hi   English   Hindi       27.42    0.35

Bảng 8: Thống kê kho dữ liệu OPUS, tổng cộng 7.8 tỷ cặp NL song ngữ từ 105 cặp NL khác nhau. Số lượng cặp song ngữ được báo cáo ("#Sent.") và tỷ lệ phần trăm ("#Percent.") được tính toán theo dữ liệu gốc.

--- TRANG 16 ---
Kho dữ liệu NL song song Chúng tôi sử dụng dữ
liệu NL song song được thu thập từ trang web
OPUS12. Chúng tôi tóm tắt thống kê của dữ liệu
OPUS đã thu thập trong Bảng 8. Dữ liệu chúng
tôi sử dụng có 15 NL khác nhau, bao gồm 105
cặp ngôn ngữ song ngữ khác nhau (bỏ qua hướng
kép giữa hai ngôn ngữ) và tổng cộng 7.8 tỷ cặp
câu. Tương tự như tiền xử lý CC-100, chúng tôi
áp dụng cùng quá trình lấy mẫu lại dữ liệu bằng
cách tuân theo Eq. (3), với α = 0,3.

A.2.3 Cân bằng dữ liệu giữa NL và PL
Xem xét rằng lượng dữ liệu của PL và NL khác
nhau đáng kể, phân phối dữ liệu trên PL và NL
vẫn sẽ không cân bằng ngay cả sau khi tái tỷ lệ
theo Eq. (3), điều này có thể dẫn đến thiên lệch
đối với chế độ có nhiều tài nguyên (tức là, NL).
Để giảm thiểu vấn đề này, chúng tôi đặt phân
phối dữ liệu của PL và NL là 1:1 bằng cách cân
bằng tỷ lệ mẫu huấn luyện của PL với NL trong
quá trình tiền huấn luyện. Nói cách khác, chúng
tôi huấn luyện cùng số lượng mẫu cho các kho
dữ liệu NL và PL.

A.3 Cài đặt thí nghiệm
A.3.1 Cài đặt tiền huấn luyện
Chúng tôi sử dụng cùng kiến trúc T5 với encoder
12 lớp, decoder 12 lớp, 768 đơn vị ẩn (dmodel),
12 head, 2048 đơn vị tuyến tính feedforward (dff),
kích hoạt GELU, tỷ lệ dropout (Srivastava et al.,
2014) là 0.1, và không có ràng buộc embedding.
Chen et al. (2021) không tìm thấy sự khác biệt
giữa huấn luyện từ trọng số mô hình tiền huấn
luyện và huấn luyện từ đầu, ngoại trừ việc trước
đây hội tụ nhanh hơn. Vì mục đích này, chúng
tôi sử dụng checkpoint mT513 để khởi tạo, đã
chứa các biểu diễn NL đa ngôn ngữ mạnh mẽ.

Đối với tiền huấn luyện, chúng tôi đặt độ dài
tối đa (L) là 512/1024, kích thước micro-batch
là 8/4 với bước tích lũy gradient là 15. Chúng
tôi sử dụng trình tối ưu Adafactor (Shazeer và
Stern, 2018) và khởi động tuyến tính 1000 bước
với tỷ lệ học đỉnh là 1e-4. Tất cả các tác vụ
tiền huấn luyện được chạy trên một cụm 32
GPU NVIDIA A100 với bộ nhớ 40G trong 100,000
bước huấn luyện. Để tăng tốc tiền huấn luyện,
chúng tôi sử dụng phương pháp ZeRO stage1
(Rajbhandari et al., 2020) để phân vùng trạng
thái trình tối ưu và kích hoạt định dạng nửa
chính xác BFloat16 cho huấn luyện chính xác
hỗn hợp. Tổng thời gian tiền huấn luyện kéo
dài khoảng bốn tuần.

12https://opus.nlpl.eu
13https://github.com/google-research/multilingual-t5#
released-model-checkpoints

A.3.2 Các tập dữ liệu đánh giá
Bảng 9 báo cáo thống kê chi tiết của tập dữ liệu
đánh giá trên một bộ benchmark mã, bao gồm
NL-sang-PL, PL-sang-NL, PL-sang-PL, và NL-sang-NL.

Tác vụ   Tập dữ liệu   Ngôn ngữ   Huấn luyện   Kiểm tra   Test
NL-PL    mCoNaLa       Spanish↔Python      -         -      341
         (Wang et al., 2022) Japanese↔Python  -         -      210
                       Russian↔Python      -         -      345
PL-PL    Bugs2Fix      Java-small          46,680    5,835   5,835
         (Tufano et al., 2019) Java-medium  52,364    6,545   6,545
NL-NL    Microsoft Docs Danish↔English     42,701    1,000   1,000
         (Lu et al., 2021a) Latvian↔English 18,749    1,000   1,000
                       Norwegian↔English    44,322    1,000   1,000
                       Chinese↔English      50,154    1,000   1,000

Bảng 9: Thống kê các tập dữ liệu benchmark hạ nguồn.

A.3.3 Cài đặt tinh chỉnh
Khi tinh chỉnh trên các tác vụ cuối, chúng tôi
sử dụng mini-batch 8/4, và độ dài đầu vào tối
đa là 512. Chúng tôi đặt độ dài đích tối đa là
128, 64, 256, và 256 cho các tác vụ tóm tắt mã,
văn bản-sang-mã, dịch tài liệu, và sửa chữa
mã tương ứng. Chúng tôi sử dụng tinh chỉnh
dựa trên nhắc nhở bằng cách thêm tiền tố tác
vụ (như được hiển thị trong Bảng 10) trước
mỗi mẫu để huấn luyện và đánh giá. Chúng tôi
tinh chỉnh các tác vụ mã-sang-văn bản, văn bản-sang-mã,
và dịch tài liệu trong 100 epoch và huấn luyện
10 epoch trên tập dữ liệu sửa chữa mã. Đối
với tất cả các thí nghiệm tinh chỉnh, chúng tôi
sử dụng trình tối ưu AdamW (Loshchilov và
Hutter, 2019) với tỷ lệ học 5e-5. Về suy luận
mô hình, chúng tôi áp dụng giải mã tìm kiếm
chùm với năm chùm. Chúng tôi tiến hành tất
cả các thí nghiệm tinh chỉnh trên 8 GPU NVIDIA
V100 với bộ nhớ 32G.

A.4 Kết quả loại bỏ
Bảng 11 báo cáo kết quả loại bỏ của tóm tắt
mã (mCoNaLa), sinh văn bản-sang-mã (mCoNaLa),
dịch tài liệu (Microsoft Docs), và sửa chữa mã
(Bugs2Fix), cho thấy rằng việc kết hợp SCLM
và PTLM có thể mang lại lợi ích cho tất cả các
tác vụ cuối.

A.5 Tóm tắt mã tiếng Trung Quốc
Tuyển chọn dữ liệu Để mở rộng đánh giá trên
tóm tắt mã tiếng Trung Quốc, chúng tôi phát
hành một biến thể được dịch của tập dữ liệu
mCoNaLa thông qua crowd-sourcing. Cụ thể,
chúng tôi thuê các dịch giả con người thỏa mãn
tất cả ba tiêu chí sau để thực hiện crowd-sourcing:

--- TRANG 17 ---
Tác vụ tinh chỉnh   Định dạng nhắc nhở
Mã-sang-văn bản    "translate Spanish to Python: \n\n"
                   "translate Japanese to Python: \n\n"
                   "translate Russian to Python: \n\n"
Văn bản-sang-mã    "translate Python to Spanish: \n\n"
                   "translate Python to Japanese: \n\n"
                   "translate Python to Russian: \n\n"
Dịch tài liệu      "translate 'src_lang' to 'tgt_lang': \n\n"
Sửa chữa mã        "fix bugs:\n\n"

Bảng 10: Nhắc nhở tác vụ chúng tôi sử dụng cho tinh chỉnh. Đối với dịch tài liệu, "src_lang" và "tgt_lang" đại diện cho ngôn ngữ nguồn và đích (ví dụ, English, Danish, Latvian, Norwegian, và Chinese) tương ứng.

1. Phải là người bản ngữ tiếng Trung Quốc;
2. Có ít nhất bằng thạc sĩ về dịch thuật tiếng Tây Ban Nha, Nhật Bản, và Nga, văn học, hoặc các môn học liên quan;
3. Có chứng chỉ dịch thuật chuyên nghiệp trong ngôn ngữ tương ứng.

Sau khi dịch của con người, chúng tôi cũng thuê các kỹ sư chuyên nghiệp là người bản ngữ tiếng Trung Quốc với ít nhất năm năm kinh nghiệm Python để thực hiện tinh chỉnh dịch thuật thêm. Chúng tôi sẽ phát hành tập dữ liệu này để thúc đẩy nghiên cứu về tóm tắt mã đa ngôn ngữ.

Ví dụ về tóm tắt mã tiếng Trung Quốc (nhắc nhở zero-shot) Chúng tôi hiển thị các ví dụ tóm tắt mã tiếng Trung Quốc của mô hình chúng tôi trong đánh giá nhắc nhở zero-shot trong Hình 9. Chúng tôi thêm hướng dẫn nhắc nhở "translate Python to Chinese: \n" cho huấn luyện và đánh giá. Nó chứng minh rằng mô hình của chúng tôi trang bị khả năng zero-shot trong tóm tắt mã tiếng Trung Quốc, khẳng định hiệu quả tích cực của tiền huấn luyện đa ngôn ngữ chéo của chúng tôi. Hơn nữa, như được hiển thị trong Hình 9, mô hình của chúng tôi tập trung vào ý nghĩa cao cấp của các đoạn mã đầu vào, bỏ qua các chi tiết triển khai. Chúng tôi đoán điều này là do chúng tôi sử dụng kho dữ liệu tìm kiếm mã làm dữ liệu huấn luyện song ngữ NL-PL, trong đó các hướng dẫn NL bao gồm các mô tả cao cấp thường được trích xuất từ bình luận mã. Nó gây ra sự bất đồng giữa cài đặt huấn luyện và đánh giá.

A.6 Ví dụ định tính (nhắc nhở zero-shot)
Sinh PL-sang-NL đa ngôn ngữ zero-shot
Hình 9 và 10 minh họa các ví dụ tóm tắt mã với
nhắc nhở zero-shot. Như đã đề cập trước đó,
như được minh họa trong Hình 9 và 10, chúng
tôi thấy rằng mô hình của chúng tôi tập trung
vào tổng quan toàn cảnh của ngữ nghĩa mã
thay vì diễn đạt quy trình triển khai. Hơn nữa,
khi giải thích một đoạn mã ngắn, những người
khác nhau có thể diễn giải nó với nhiều ý nghĩa
khác nhau, điều chúng tôi gọi là "sự mơ hồ
của chương trình", làm khó khăn cho việc chú
thích và đánh giá tóm tắt mã đa ngôn ngữ.
Điều này là do tham chiếu tập test của mCoNaLa
được viết lại bởi con người, trong khi NL huấn
luyện thì không. Chúng tôi cũng thấy rằng mô
hình có xu hướng sao chép các đoạn mã nhỏ
để tóm tắt mã. Ví dụ, với đầu vào "# -*- utf-8 -*-",
mô hình của chúng tôi có xu hướng sao chép
chuỗi gốc thay vì mô tả cách sử dụng của nó
bằng NL.

Sinh NL-sang-PL zero-shot Hình 11 và 12 chứng
minh các ví dụ sinh văn bản-sang-mã zero-shot.
Chúng tôi cũng quan sát thấy rằng ERNIE-Code
hoạt động tốt trong việc sinh tên hàm, đối số,
và docstring. Nó có xu hướng sinh các đoạn
cấp hàm và gọi các hàm do người dùng định
nghĩa theo logic hướng đối tượng trong khi
thiếu kiến thức về các hàm tích hợp hoặc bối
cảnh do người dùng định nghĩa khi được đưa
ra các đầu vào NL đa ngôn ngữ. Hướng dẫn
tiếng Nhật Bản được đưa ra yêu cầu mô hình
ghi nhớ cách sử dụng API của thư viện selenium14
mà mô hình của chúng tôi có thể không bao
giờ thấy trong dữ liệu huấn luyện. Chúng tôi
lập luận rằng huấn luyện trên dữ liệu được
thu thập từ GitHub và StackOverflow sẽ mang
lại lợi ích trong việc ghi nhớ và hiểu cách sử
dụng API và bối cảnh hướng dẫn. Chúng tôi
nghi ngờ rằng huấn luyện trên dữ liệu PL bổ
sung từ GitHub và StackOverflow thay vì dữ
liệu hạn chế của CodeSearchNet có thể dẫn
đến cải tiến lớn. Lưu ý rằng docstring
"<|removed|>" được sinh trong Hình 11 phù
hợp với tiền xử lý của chúng tôi trong §A.2.1.

Dịch thuật NL-sang-NL đa ngôn ngữ zero-shot
Để xác minh thêm khả năng dịch thuật zero-shot
giữa các NL đa ngôn ngữ, chúng tôi báo cáo
một số cặp ngôn ngữ được chọn từ các họ ngôn
ngữ khác nhau và dịch các thuật ngữ kỹ thuật
với nhắc nhở zero-shot. Hình 13 trình bày các
ví dụ dịch thuật NL đa ngôn ngữ theo tám hướng
được chọn ngẫu nhiên, chẳng hạn như tiếng
Tây Ban Nha sang tiếng Pháp và

14https://selenium-python.readthedocs.io/

--- TRANG 18 ---
Mô hình    es       ja       ru       Trung bình
          B-4  R-L  chrF  B-4  R-L  chrF  B-4  R-L  chrF  B-4  R-L  chrF
Của chúng tôi  1.90 32.51 23.22 0.30 10.62 9.16 0.43 5.01 16.60 0.88 16.05 16.33
\SCLM     1.04 23.96 19.56 0.17 7.62 8.88 0.21 2.69 15.53 0.47 11.42 15.10
\PTLM     0.96 22.47 24.00 0.06 5.71 8.22 0.20 4.92 14.66 0.41 11.03 14.15
(a) Kết quả loại bỏ trên tóm tắt mã đa ngôn ngữ.

Mô hình    es       ja       ru       Trung bình
          B-4  R-L  C-B  B-4  R-L  C-B  B-4  R-L  C-B  B-4  R-L  C-B
Của chúng tôi  2.25 14.92 0.06 8.06 22.65 0.10 6.12 25.27 0.08 5.48 20.95 0.08
\SCLM     2.42 14.27 0.06 6.89 21.31 0.10 5.41 23.09 0.08 4.91 19.56 0.08
\PTLM     2.08 13.94 0.06 6.40 17.77 0.10 5.11 23.17 0.08 4.53 18.29 0.08
(b) Kết quả loại bỏ trên sinh mã đa ngôn ngữ từ văn bản.

Mô hình    En-Da    En-Lv    En-No    En-Zh    Trung bình
          B-4  EM   B-4  EM   B-4  EM   B-4  EM   B-4  EM
          →  ←     →  ←     →  ←     →  ←     →  ←
Của chúng tôi  71.16 13.2 72.70 27.2 60.98 10.6 69.28 24.3 71.39 15.7 72.28 26.3 74.53 24.3 72.43 28.5 70.59 21.26
\SCLM     67.70 11.3 68.50 23.4 55.98 7.5 64.39 21.6 68.05 11.4 68.03 24.1 72.52 20.1 68.56 24.8 66.72 18.03
\PTLM     66.91 10.4 67.66 23.9 55.84 7.5 63.87 21.6 67.71 11.3 66.86 23.5 71.91 19.6 67.98 24.2 66.09 17.75
(c) Kết quả loại bỏ trên dịch tài liệu.

Mô hình    Tinh chỉnh nhỏ  Tinh chỉnh trung bình  Trung bình
          B-4    EM       B-4    EM             B-4    EM
Của chúng tôi  80.09  13.21    91.20  2.22       85.65  7.72
\SCLM     79.65  13.04    91.19  2.17       85.42  7.61
\PTLM     79.73  11.31    91.13  1.68       85.43  6.50
(d) Kết quả loại bỏ trên sửa chữa mã.

Bảng 11: Kết quả loại bỏ của các tác vụ hạ nguồn, bao gồm tóm tắt mã đa ngôn ngữ (a), sinh văn bản-sang-mã (b), dịch tài liệu (c), và sửa chữa mã (d).

tiếng Nga sang tiếng Ả Rập. Điều này cho thấy
rằng tiền huấn luyện đa ngôn ngữ chéo của
chúng tôi có thể nắm bắt căn chỉnh ngữ nghĩa
mà không cần thấy giám sát trực tiếp từ các
cặp cụm từ hoặc ngắn hạn song ngữ.

Các phát hiện định tính Chúng tôi cũng quan
sát thấy rằng mô hình của chúng tôi cho phép
đặt tên hàm và hoàn thành các đối số tương
ứng theo hướng dẫn văn bản đa ngôn ngữ, như
được hiển thị trong Hình 14, khẳng định rằng
mô hình của chúng tôi học cách bắc cầu ngữ
nghĩa và cú pháp giữa các hướng dẫn NL đa
ngôn ngữ và các hàm PL.

--- TRANG 19 ---
Chuyển đổi tệp thành XML(encoding='sjis') 将文件转为XML(encoding='sjis') Parse xml document `doc` with character code `sjis` 利用字符代码`sjis`解析xml文档`doc`

用selenium在火狐浏览器中禁用javascript 设置当前浏览器的配置 创建DocxTemplate 如何用我的谷歌账户登录? 连接mysql 通过用户名user và密码password连接主机my_host上的mysql数据库db_name Tham chiếu (zh) con=pymysql.connect(my_host, user, password, db_name) with con: cur=con.cursor()

创建GoogleSession class SesionGoogle(): def __init__(self, email, contraseña): self.sesion=requests.session() url_login="https://accounts.google.com/ServiceLogin" url_aut="https://accounts.google.com/ServiceLoginAuth" login_html=self.sesion.get(url_login) soup_login=BeautifulSoup(login_html.content, 'html.parser').find('form').find_all('input') datos={u['name']:u['value'] for u in soup_login if u.has_attr('value')} datos['Email'] = email datos['Passwd'] = contraseña self.sesion.post(url_aut, data = datos) def get(self, URL): return self.sesion.get(URL).text How to access a session from my Google account? Dịch Dịch Giả thuyết Tham chiếu (zh) Connect to mysql Connect to mysql database `db_name` on host `my_host` as user `user` and password `password` Dịch Dịch Giả thuyết

Create GoogleSession Tham chiếu (zh) doc.toxml(encoding='sjis')) Dịch Dịch Giả thuyết

根据文件`template_path`中的JSON 数据data模板生成Word文档`output_file_path` #python-docx-template doc=DocxTemplate(template_path) data={ 'var_name': "HELLO WORLD!"} doc.render(data) doc.save(output_file_path) Create DocxTemplate Generate a Word document `output_file_path` according to the JSON data template in the file `template_path` Dịch Dịch Giả thuyết Tham chiếu (zh) Tham chiếu (zh) options=Options() options.set_preference('javascript.enabled', False) driver=webdriver.Firefox(options=options) Set the configuration of the current browser Disable javascript when using Firefox with selenium Dịch Dịch Giả thuyết

使用凯撒密码"shift"将字符串"s"加密为字符串"new_s" 如何将位于"dir"地址的文件重命名为"file"?

用Selenium driver`driver`将网页url截图并保存至`filepath`

将字典my_dict转换为JSON数据 如何删除包含多个文件的"dir"文件夹？ 将alpha转换为一个字符串

将我的dict转为JSON 获取文件,保存screenshot 从网站url获取Cookie"cookies" 获取Google.com的cookies

将文件夹从目录中删除 将文件重命名 Tham chiếu (zh)

shutil.rmtree(dir) Remove the folder from the directory How to delete a 'dir' folder with several files inside? Dịch Dịch Giả thuyết Tham chiếu (zh) os.rename(dir, file) session=requests.Session() response=session.get('http://google.com') cookies=session.cookies.get_dict() Obtaining cookies from the URL Dịch Dịch Giả thuyết Tham chiếu (zh) Rename the file How to rename a file located at `dir` address to `file`? Dịch Dịch Giả thuyết

Tham chiếu (zh) alpha=' abcdefghijklmnopqrstuvwxyz' new_s='' for c in s: new_s+=alpha[(alpha.index(c) + shift) % len(alpha)] Convert alpha to a string Encrypt the 's' line into the 'new_s' line with Caesar's code with the shift 'shift' Dịch Dịch Giả thuyết Get cookies from Google.com

Tham chiếu (zh) driver.get(url) screenshot=driver.save_screenshot(filepath) Get file, and save screenshot Use Selenium driver `driver` to screenshot the web page url and save it to `filepath` Dịch Dịch Giả thuyết

json.dumps(my_dict, ensure_ascii=False) Convert my dict to JSON Convert dictionary my_dict to JSON data Dịch Dịch Giả thuyết Tham chiếu (zh)

Hình 9: Ví dụ về tóm tắt mã tiếng Trung Quốc với nhắc nhở zero-shot.

--- TRANG 20 ---
Mô hình    es       ja       ru       Trung bình
          B-4  R-L  chrF  B-4  R-L  chrF  B-4  R-L  chrF  B-4  R-L  chrF
Của chúng tôi  1.90 32.51 23.22 0.30 10.62 9.16 0.43 5.01 16.60 0.88 16.05 16.33
\SCLM     1.04 23.96 19.56 0.17 7.62 8.88 0.21 2.69 15.53 0.47 11.42 15.10
\PTLM     0.96 22.47 24.00 0.06 5.71 8.22 0.20 4.92 14.66 0.41 11.03 14.15
(a) Kết quả loại bỏ trên tóm tắt mã đa ngôn ngữ.

Mô hình    es       ja       ru       Trung bình
          B-4  R-L  C-B  B-4  R-L  C-B  B-4  R-L  C-B  B-4  R-L  C-B
Của chúng tôi  2.25 14.92 0.06 8.06 22.65 0.10 6.12 25.27 0.08 5.48 20.95 0.08
\SCLM     2.42 14.27 0.06 6.89 21.31 0.10 5.41 23.09 0.08 4.91 19.56 0.08
\PTLM     2.08 13.94 0.06 6.40 17.77 0.10 5.11 23.17 0.08 4.53 18.29 0.08
(b) Kết quả loại bỏ trên sinh mã đa ngôn ngữ từ văn bản.

Mô hình    En-Da    En-Lv    En-No    En-Zh    Trung bình
          B-4  EM   B-4  EM   B-4  EM   B-4  EM   B-4  EM
          →  ←     →  ←     →  ←     →  ←     →  ←
Của chúng tôi  71.16 13.2 72.70 27.2 60.98 10.6 69.28 24.3 71.39 15.7 72.28 26.3 74.53 24.3 72.43 28.5 70.59 21.26
\SCLM     67.70 11.3 68.50 23.4 55.98 7.5 64.39 21.6 68.05 11.4 68.03 24.1 72.52 20.1 68.56 24.8 66.72 18.03
\PTLM     66.91 10.4 67.66 23.9 55.84 7.5 63.87 21.6 67.71 11.3 66.86 23.5 71.91 19.6 67.98 24.2 66.09 17.75
(c) Kết quả loại bỏ trên dịch tài liệu.

Mô hình    Tinh chỉnh nhỏ  Tinh chỉnh trung bình  Trung bình
          B-4    EM       B-4    EM             B-4    EM
Của chúng tôi  80.09  13.21    91.20  2.22       85.65  7.72
\SCLM     79.65  13.04    91.19  2.17       85.42  7.61
\PTLM     79.73  11.31    91.13  1.68       85.43  6.50
(d) Kết quả loại bỏ trên sửa chữa mã.

Bảng 11: Kết quả loại bỏ của các tác vụ hạ nguồn, bao gồm tóm tắt mã đa ngôn ngữ (a), sinh văn bản-sang-mã (b), dịch tài liệu (c), và sửa chữa mã (d).

100 / полный * часть Remove n de la lista de datos ¿Cómo crear una función para eliminar un elemento `n` de una lista `L`? Вычислить сколько процентов составляет число `part` от числа `whole` スレッド`t`を定期的に実行する時間経過を保持する。

Tham chiếu (ru) 100/whole *part t=threading.Timer(interval, function) t.start() Run thread `t` periodically Dịch Dịch Giả thuyết Tham chiếu (ja)

100 / full * part Calculate how many percent of the number `part` is from the number `whole` Dịch Dịch Giả thuyết Tham chiếu (es) def eliminarEnLista(L): n=int(raw_input("Ingrese el numero que desea eliminar de la lista: ")) try: L.remove(n) print(L) except ValueError: print('{}no se encuentra en la lista'.format(n)) Remove n from data list How to create a function to remove an `n` element from an `L` list? Dịch Dịch Giả thuyết Keep track of time. Tóm tắt mã tiếng Nhật Bản Tóm tắt mã tiếng Nga Tóm tắt mã tiếng Tây Ban Nha

Hình 10: Ví dụ tóm tắt mã đa ngôn ngữ (mã-sang-văn bản) với nhắc nhở zero-shot.

def max_value(self, max_value): """<|removed|>""" if max_value is None: max_value = self._max_value return self._max_value Найти максимальное значение `max_value` в словаре `my_list` Find the maximum value of `max_value` in the dictionary `my_list` (Dịch) Dự đoán tiếng Nga Tham chiếu max_val=max(my_list.values())

def _calculate_dv(col, df): """<|removed|>""" df = df.get_dataframe() df.set_dv(col) df.set_dv(df.get_dv(col)) return df ¿Cómo calcular la desviación estándar de la columna `col` en un DataFrame `df`? How to calculate the standard deviation of the column `col` in a DataFrame `df`? (Dịch) Dự đoán tiếng Tây Ban Nha Tham chiếu std = df[col].std() (a) Nga-sang-Python

(b) Tây Ban Nha-sang-Python

Hình 11: Ví dụ tóm tắt mã đa ngôn ngữ (văn bản-sang-mã) với nhắc nhở zero-shot.

seleniumでFirefox仕様時にjavascriptを無効にする def _disable_javascript(self, javascript_name): """seleniumでFirefox仕様時にjavascriptを無効にする""" if javascript_name in self._plugins: self._plugins[javascript_name] = False else: self._plugins[javascript_name] = False Disable javascript in Firefox specification with selenium Dịch Văn bản (ja) Giả thuyết

profile=webdriver.FirefoxProfile() profile.DEFAULT_PREFERENCES['frozen']['javascript.enabled'] = False profile.set_preference("app.update.auto", False) profile.set_preference("app.update.enabled", False) profile.update_preferences() Tham chiếu

Hình 12: Ví dụ về sinh mã đa ngôn ngữ từ văn bản zero-shot (tiếng Nhật Bản). Vùng được tô màu cam là giả thuyết được sinh bởi mô hình của chúng tôi.

计算机科学 Computing science 软件开发 Software development Translate Chinese to English: Vývoj softwaru Pengembangan software Počítačová síť Komputer sambungan Translate Czech to Malay: Machine Learning 机器学习 Algorithm Design and Analysis 算法设计和分析 Translate English to Chinese: aprendizaje automático apprentissage automatique lenguaje de programación Langue de programmation Translate Spanish to French: Translate Japanese to Icelandic: コンピュータサイエンス Компьютерско επιστήμη ソフトウェア開発 þróun софтвера

компьютерная сеть ةیرتویبملکلا ةکبشلا Анализ программы جمارблا میییقت Translate Russian to Arabic: informatica คอมพิวเตอร์ Sviluppo software การพัฒนาซอฟต์แวร์ Translate Italian to Thai: 컴퓨터과학 Tecnologia de computadores 소프트웨어개발 Desarrollo de software Translate Korean to Portuguese:

Hình 13: Ví dụ về dịch thuật văn bản-sang-văn bản zero-shot về thuật ngữ kỹ thuật. Vùng được tô màu cam là ngôn ngữ đích, trong khi vùng màu xanh là nhắc nhở tiền tố chúng tôi sử dụng cho dịch thuật zero-shot.

Вычислить сколько процентов составляет число `part` от числа `whole` def _calculate_dv(col, df) Extract only the first value from the one-dimensional array that is an element of the two-dimensional array `arr` def _get_first_value(arr) 2次元配列`arr`の要素となっている1次元配列から先頭の値のみを抜き出す ¿Cómo calcular la desviación estándar de la columna `col` en un DataFrame `df`?

def _get_percent(self, part, whole) How to calculate the standard deviation of the column `col` in a DataFrame `df`? Dịch Tây Ban Nha

Dịch Nhật Bản

Calculate how much percentage is the number 'part' from the number 'whole' Dịch Nga Dự đoán Dự đoán Dự đoán

Hình 14: Ví dụ về đặt tên hàm và điền đối số trong sinh văn bản-sang-mã (zero-shot).

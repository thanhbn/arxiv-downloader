# 2309.10305.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/multilingual/2309.10305.pdf
# Kích thước tệp: 4588040 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Baichuan 2: Các Mô hình Ngôn ngữ Lớn Mở
Aiyuan Yang, Bin Xiao, Bingning Wang, Borong Zhang, Chao Yin, Chenxu Lv, Da Pan
Dian Wang, Dong Yan, Fan Yang, Fei Deng, Feng Wang, Feng Liu, Guangwei Ai
Guosheng Dong, Haizhou Zhao, Hang Xu, Haoze Sun, Hongda Zhang, Hui Liu, Jiaming Ji
Jian Xie, Juntao Dai, Kun Fang, Lei Su, Liang Song, Lifeng Liu, Liyun Ru, Luyao Ma
Mang Wang, Mickel Liu, MingAn Lin, Nuolan Nie, Peidong Guo, Ruiyang Sun
Tao Zhang, Tianpeng Li, Tianyu Li, Wei Cheng, Weipeng Chen, Xiangrong Zeng
Xiaochuan Wang, Xiaoxi Chen, Xin Men, Xin Yu, Xuehai Pan, Yanjun Shen, Yaodong Yang
Yiding Wang, Yiyu Li, Youxin Jiang, Yuchen Gao, Yupeng Zhang, Zenan Zhou, Zhiying Wu
Baichuan Inc.

Tóm tắt
Các mô hình ngôn ngữ lớn (LLMs) đã thể hiện hiệu suất đáng chú ý trên nhiều nhiệm vụ ngôn ngữ tự nhiên chỉ dựa trên một vài ví dụ hướng dẫn ngôn ngữ tự nhiên, giảm bớt nhu cầu thiết kế đặc trưng phức tạp. Tuy nhiên, hầu hết các LLM mạnh mẽ đều là mã nguồn đóng hoặc bị hạn chế khả năng cho các ngôn ngữ khác ngoài tiếng Anh. Trong báo cáo kỹ thuật này, chúng tôi trình bày Baichuan 2, một loạt các mô hình ngôn ngữ đa ngôn ngữ quy mô lớn chứa 7 tỷ và 13 tỷ tham số, được huấn luyện từ đầu trên 2.6 nghìn tỷ token. Baichuan 2 đạt hiệu suất tương đương hoặc vượt trội so với các mô hình mã nguồn mở khác có kích thước tương tự trên các benchmark công khai như MMLU, CMMLU, GSM8K và HumanEval. Hơn nữa, Baichuan 2 xuất sắc trong các lĩnh vực chuyên môn như y học và luật pháp. Chúng tôi sẽ phát hành tất cả các checkpoint mô hình tiền huấn luyện để có lợi cho cộng đồng nghiên cứu hiểu rõ hơn về động lực huấn luyện của Baichuan 2.

1 Giới thiệu
Lĩnh vực các mô hình ngôn ngữ lớn đã chứng kiến những tiến bộ đầy hứa hẹn và đáng chú ý trong những năm gần đây. Kích thước của các mô hình ngôn ngữ đã tăng từ hàng triệu tham số, như ELMo (Peters et al., 2018), GPT-1 (Radford et al., 2018), lên hàng tỷ hoặc thậm chí hàng nghìn tỷ tham số như GPT-3 (Brown et al., 2020), PaLM (Chowdhery et al., 2022; Anil et al., 2023) và Switch Transformers (Fedus et al., 2022). Sự gia tăng quy mô này đã dẫn đến những cải tiến đáng kể trong khả năng của các mô hình ngôn ngữ, cho phép độ trôi chảy giống con người hơn và khả năng thực hiện một loạt các nhiệm vụ ngôn ngữ tự nhiên đa dạng. Với việc giới thiệu ChatGPT (OpenAI, 2022) từ OpenAI, sức mạnh của những mô hình này trong việc tạo ra văn bản giống con người đã thu hút sự chú ý rộng rãi của công chúng. ChatGPT thể hiện khả năng ngôn ngữ mạnh mẽ trên nhiều lĩnh vực khác nhau, từ trò chuyện thông thường đến giải thích các khái niệm phức tạp. Bước đột phá này làm nổi bật tiềm năng của các mô hình ngôn ngữ lớn trong việc tự động hóa các nhiệm vụ liên quan đến tạo ra và hiểu ngôn ngữ tự nhiên.

Tác giả được liệt kê theo thứ tự bảng chữ cái, tác giả liên hệ: daniel@baichuan-inc.com. Jiaming Ji, Borong Zhang, Xuehai Pan, Mickel Liu, Juntao Dai, Ruiyang Sun, Yaodong Yang trực thuộc Đại học Bắc Kinh.

Mặc dù đã có những đột phá thú vị và ứng dụng của LLMs, hầu hết các LLM hàng đầu như GPT-4 (OpenAI, 2023), PaLM-2 (Anil et al., 2023), và Claude (Claude, 2023) vẫn là mã nguồn đóng. Các nhà phát triển và nghiên cứu có quyền truy cập hạn chế vào các tham số mô hình đầy đủ, khiến việc nghiên cứu sâu hoặc tinh chỉnh những hệ thống này trở nên khó khăn đối với cộng đồng. Tính mở và minh bạch hơn xung quanh các LLM có thể thúc đẩy nghiên cứu và phát triển có trách nhiệm trong lĩnh vực đang tiến bộ nhanh chóng này.

LLaMA (Touvron et al., 2023a), một loạt các mô hình ngôn ngữ lớn được phát triển bởi Meta chứa tới 65 tỷ tham số, đã mang lại lợi ích đáng kể cho cộng đồng nghiên cứu LLM bằng cách hoàn toàn mở mã nguồn. Bản chất mở của LLaMA, cùng với các LLM mã nguồn mở khác như OPT (Zhang et al., 2022), Bloom (Scao et al., 2022), MPT (MosaicML, 2023) và Falcon (Penedo et al., 2023), cho phép các nhà nghiên cứu tự do truy cập các mô hình để kiểm tra, thử nghiệm và phát triển thêm. Tính minh bạch và khả năng truy cập này phân biệt LLaMA với các LLM độc quyền khác. Bằng cách cung cấp quyền truy cập đầy đủ, các LLM mã nguồn mở đã thúc đẩy nghiên cứu và tiến bộ trong lĩnh vực này, dẫn đến các mô hình mới như Alpaca (Taori et al., 2023), Vicuna (Chiang et al., 2023), và các mô hình khác (Wang et al., 2022; Zhu et al., 2023; Anand et al., 2023).

--- TRANG 2 ---
Tuy nhiên, hầu hết các mô hình ngôn ngữ lớn mã nguồn mở đã tập trung chủ yếu vào tiếng Anh. Ví dụ, nguồn dữ liệu chính cho LLaMA là Common Crawl, chiếm 67% dữ liệu tiền huấn luyện của LLaMA nhưng được lọc chỉ để có nội dung tiếng Anh. Các LLM mã nguồn mở khác như MPT (MosaicML, 2023) và Falcon (Penedo et al., 2023) cũng tập trung vào tiếng Anh và có khả năng hạn chế trong các ngôn ngữ khác. Điều này cản trở việc phát triển và ứng dụng LLM trong các ngôn ngữ cụ thể, chẳng hạn như tiếng Trung.

Trong báo cáo kỹ thuật này, chúng tôi giới thiệu Baichuan 2, một loạt các mô hình ngôn ngữ đa ngôn ngữ quy mô lớn. Baichuan 2 có hai mô hình riêng biệt, Baichuan 2-7B với 7 tỷ tham số và Baichuan 2-13B với 13 tỷ tham số. Cả hai mô hình đều được huấn luyện trên 2.6 nghìn tỷ token, theo hiểu biết của chúng tôi là lớn nhất từ trước tới nay, gấp hơn đôi so với Baichuan 1 (Baichuan, 2023b,a). Với lượng dữ liệu huấn luyện khổng lồ như vậy, Baichuan 2 đạt được những cải tiến đáng kể so với Baichuan 1. Trên các benchmark tổng quát như MMLU (Hendrycks et al., 2021a), CMMLU (Li et al., 2023), và C-Eval (Huang et al., 2023), Baichuan 2-7B đạt hiệu suất cao hơn gần 30% so với Baichuan 1-7B. Cụ thể, Baichuan 2 được tối ưu hóa để cải thiện hiệu suất trên các bài toán toán học và mã lệnh. Trên các đánh giá GSM8K (Cobbe et al., 2021) và HumanEval (Chen et al., 2021), Baichuan 2 gần như gấp đôi kết quả của Baichuan 1. Ngoài ra, Baichuan 2 cũng thể hiện hiệu suất mạnh mẽ trong các nhiệm vụ lĩnh vực y học và pháp lý. Trên các benchmark như MedQA (Jin et al., 2021) và JEC-QA (Zhong et al., 2020), Baichuan 2 vượt trội hơn các mô hình mã nguồn mở khác, làm cho nó trở thành một mô hình nền tảng phù hợp cho việc tối ưu hóa theo lĩnh vực cụ thể.

Ngoài ra, chúng tôi cũng phát hành hai mô hình chat, Baichuan 2-7B-Chat và Baichuan 2-13B-Chat, được tối ưu hóa để tuân theo hướng dẫn của con người. Những mô hình này xuất sắc trong đối thoại và hiểu ngữ cảnh. Chúng tôi sẽ trình bày chi tiết các phương pháp của mình để cải thiện tính an toàn của Baichuan 2. Bằng cách mở mã nguồn những mô hình này, chúng tôi hy vọng cho phép cộng đồng tiếp tục cải thiện tính an toàn của các mô hình ngôn ngữ lớn, tạo điều kiện cho nhiều nghiên cứu hơn về phát triển LLM có trách nhiệm.

Hơn nữa, theo tinh thần hợp tác nghiên cứu và cải tiến liên tục, chúng tôi cũng phát hành các checkpoint của Baichuan 2 ở nhiều giai đoạn huấn luyện khác nhau từ 200 tỷ token cho đến 2.6 nghìn tỷ token đầy đủ. Chúng tôi phát hiện rằng ngay cả đối với mô hình 7 tỷ tham số, hiệu suất vẫn tiếp tục cải thiện sau khi huấn luyện trên hơn 2.6 nghìn tỷ token. Bằng cách chia sẻ những kết quả trung gian này, chúng tôi hy vọng cung cấp cho cộng đồng những hiểu biết sâu sắc hơn về động lực huấn luyện của Baichuan 2. Hiểu được những động lực này là chìa khóa để giải mã cơ chế hoạt động bên trong của các mô hình ngôn ngữ lớn (Biderman et al., 2023a; Tirumala et al., 2022). Chúng tôi tin rằng việc phát hành những checkpoint này sẽ mở đường cho những tiến bộ hơn nữa trong lĩnh vực đang phát triển nhanh chóng này.

Trong báo cáo kỹ thuật này, chúng tôi cũng sẽ chia sẻ một số thử nghiệm, sai lầm và bài học rút ra qua việc huấn luyện Baichuan 2. Trong các phần tiếp theo, chúng tôi sẽ trình bày những thay đổi chi tiết được thực hiện đối với kiến trúc Transformer cơ bản và phương pháp huấn luyện của chúng tôi. Sau đó chúng tôi sẽ mô tả các phương pháp tinh chỉnh để điều chỉnh mô hình nền tảng theo sở thích của con người. Cuối cùng, chúng tôi sẽ đánh giá hiệu suất của các mô hình so với các LLM khác trên một bộ các bài kiểm tra chuẩn. Trong suốt báo cáo, chúng tôi nhằm mục đích cung cấp tính minh bạch vào quy trình của chúng tôi, bao gồm cả các thí nghiệm không thành công, để thúc đẩy kiến thức tập thể trong việc phát triển LLM. Các mô hình nền tảng và mô hình chat của Baichuan 2 có sẵn cho cả nghiên cứu và sử dụng thương mại tại https://github.com/baichuan-inc/Baichuan2

2 Tiền huấn luyện
Phần này giới thiệu quy trình huấn luyện cho các mô hình nền tảng Baichuan 2. Trước khi đi vào chi tiết mô hình, chúng tôi trước tiên cho thấy hiệu suất tổng thể của các mô hình cơ sở Baichuan 2 so với các mô hình mã nguồn mở hoặc đóng khác trong Bảng 1. Sau đó chúng tôi mô tả dữ liệu tiền huấn luyện và phương pháp xử lý dữ liệu. Tiếp theo, chúng tôi trình bày chi tiết về kiến trúc Baichuan 2 và kết quả mở rộng. Cuối cùng, chúng tôi mô tả hệ thống huấn luyện phân tán.

2.1 Dữ liệu Tiền huấn luyện
Nguồn dữ liệu: Trong quá trình thu thập dữ liệu, mục tiêu của chúng tôi là theo đuổi khả năng mở rộng và tính đại diện dữ liệu toàn diện. Chúng tôi thu thập dữ liệu từ các nguồn đa dạng bao gồm các trang web internet tổng quát, sách, bài báo nghiên cứu, codebase và nhiều hơn nữa để xây dựng một hệ thống kiến thức thế giới rộng lớn

--- TRANG 3 ---
[Bảng hiệu suất với các chỉ số C-Eval, MMLU, CMMLU, Gaokao, AGIEval, BBH, GSM8K, HumanEval cho các mô hình khác nhau]

hệ thống. Thành phần của kho dữ liệu huấn luyện được thể hiện trong Hình 1.

Hình 1: Phân bố các loại dữ liệu huấn luyện khác nhau của Baichuan 2.

Xử lý dữ liệu: Đối với xử lý dữ liệu, chúng tôi tập trung vào tần suất và chất lượng dữ liệu. Tần suất dữ liệu dựa vào phân cụm và khử trùng lặp. Chúng tôi đã xây dựng một hệ thống phân cụm và khử trùng lặp quy mô lớn hỗ trợ cả đặc trưng giống LSH và đặc trưng nhúng dày đặc. Hệ thống này có thể phân cụm và khử trùng lặp dữ liệu quy mô nghìn tỷ trong vòng vài giờ. Dựa trên việc phân cụm, các tài liệu, đoạn văn và câu riêng lẻ được khử trùng lặp và ghi điểm. Những điểm số đó sau đó được sử dụng để lấy mẫu dữ liệu trong tiền huấn luyện. Kích thước của dữ liệu huấn luyện ở các giai đoạn xử lý dữ liệu khác nhau được thể hiện trong Hình 2.

2.2 Kiến trúc
Kiến trúc mô hình của Baichuan 2 dựa trên Transformer phổ biến (Vaswani et al., 2017). Tuy nhiên, chúng tôi đã thực hiện một số thay đổi mà chúng tôi sẽ trình bày chi tiết dưới đây.

2.3 Tokenizer
Một tokenizer cần cân bằng hai yếu tố quan trọng: tỷ lệ nén cao để suy luận hiệu quả và kích thước từ vựng phù hợp để đảm bảo huấn luyện đầy đủ của mỗi word embedding. Chúng tôi đã tính đến cả hai khía cạnh này. Chúng tôi đã mở rộng kích thước từ vựng từ 64,000 trong Baichuan 1 lên 125,696, nhằm tạo ra sự cân bằng giữa hiệu quả tính toán và hiệu suất mô hình.

[Bảng so sánh kích thước từ vựng và tỷ lệ nén văn bản của tokenizer Baichuan 2 với các mô hình khác]

Chúng tôi sử dụng mã hóa byte-pair (BPE) (Shibata et al., 1999) từ SentencePiece (Kudo và Richardson,

--- TRANG 4 ---
Hình 2: Quy trình xử lý dữ liệu của dữ liệu tiền huấn luyện Baichuan 2.

[Bảng chi tiết mô hình Baichuan 2 với các thông số kiến trúc]

2018) để token hóa dữ liệu. Cụ thể, chúng tôi không áp dụng bất kỳ chuẩn hóa nào cho văn bản đầu vào và chúng tôi không thêm tiền tố giả như trong Baichuan 1. Chúng tôi tách các số thành từng chữ số riêng lẻ để mã hóa dữ liệu số tốt hơn. Để xử lý dữ liệu mã lệnh chứa khoảng trắng thừa, chúng tôi thêm các token chỉ có khoảng trắng vào tokenizer. Độ bao phủ ký tự được đặt thành 0.9999, với các ký tự hiếm sẽ quay lại byte UTF-8. Chúng tôi đặt độ dài token tối đa là 32 để tính đến các cụm từ tiếng Trung dài. Dữ liệu huấn luyện cho tokenizer Baichuan 2 đến từ kho dữ liệu tiền huấn luyện Baichuan 2, với nhiều ví dụ mã lệnh và bài báo học thuật được lấy mẫu để cải thiện độ bao phủ (Taylor et al., 2022). Bảng 2 thể hiện sự so sánh chi tiết giữa tokenizer của Baichuan 2 với các tokenizer khác.

2.3.1 Nhúng Vị trí
Dựa trên Baichuan 1, chúng tôi áp dụng Rotary Positional Embedding (RoPE) (Su et al., 2021) cho Baichuan 2-7B và ALiBi (Press et al., 2021) cho Baichuan 2-13B. ALiBi là một kỹ thuật mã hóa vị trí gần đây hơn đã cho thấy hiệu suất ngoại suy được cải thiện. Tuy nhiên, hầu hết các mô hình mã nguồn mở sử dụng RoPE cho nhúng vị trí, và các triển khai attention được tối ưu hóa như Flash Attention (Dao et al., 2022; Dao, 2023) hiện tại phù hợp hơn với RoPE vì nó dựa trên phép nhân, bỏ qua nhu cầu truyền attention_mask cho thao tác attention. Tuy nhiên, trong các thí nghiệm sơ bộ, việc lựa chọn nhúng vị trí không tác động đáng kể đến hiệu suất mô hình. Để cho phép nghiên cứu thêm về attention dựa trên bias và dựa trên phép nhân, chúng tôi áp dụng RoPE trên Baichuan 2-7B và ALiBi trên Baichuan 2-13B, phù hợp với Baichuan 1.

2.4 Kích hoạt và Chuẩn hóa
Chúng tôi sử dụng hàm kích hoạt SwiGLU (Shazeer, 2020), một biến thể được kích hoạt chuyển đổi của GLU (Dauphin et al., 2017) có thể hiện kết quả được cải thiện. Tuy nhiên, SwiGLU có một lớp "bilinear" và chứa ba ma trận tham số, khác với lớp feed-forward của Transformer cơ bản có hai ma trận, vì vậy chúng tôi giảm kích thước ẩn từ 4 lần kích thước ẩn xuống 8/3 kích thước ẩn và làm tròn thành bội số của 128.

Đối với lớp attention của Baichuan 2, chúng tôi áp dụng attention hiệu quả bộ nhớ (Rabe và Staats, 2021) được triển khai bởi xFormers. Bằng cách tận dụng attention được tối ưu hóa của xFormers với khả năng bias, chúng tôi có thể tích hợp hiệu quả mã hóa vị trí dựa trên bias của ALiBi trong khi giảm chi phí bộ nhớ. Điều này mang lại lợi ích về hiệu suất và hiệu quả cho việc huấn luyện quy mô lớn của Baichuan 2.

Chúng tôi áp dụng Layer Normalization (Ba et al., 2016) cho đầu vào của khối Transformer, điều này mạnh mẽ hơn với lịch trình khởi động (Xiong et al., 2020).

--- TRANG 5 ---
Ngoài ra, chúng tôi sử dụng triển khai RMSNorm được giới thiệu bởi (Zhang và Sennrich, 2019), chỉ tính toán phương sai của các đặc trưng đầu vào để cải thiện hiệu quả.

2.5 Tối ưu hóa
Chúng tôi sử dụng optimizer AdamW (Loshchilov và Hutter, 2017) để huấn luyện. β1 và β2 được đặt lần lượt là 0.9 và 0.95. Chúng tôi sử dụng weight decay với 0.1 và cắt grad norm thành 0.5. Các mô hình được khởi động với 2,000 bước mở rộng tuyến tính đạt đến tốc độ học tối đa sau đó áp dụng cosine decay xuống tốc độ học tối thiểu. Chi tiết tham số và tốc độ học được thể hiện trong Bảng 3.

Toàn bộ các mô hình được huấn luyện sử dụng độ chính xác hỗn hợp BFloat16. So với Float16, BFloat16 có phạm vi động tốt hơn, làm cho nó mạnh mẽ hơn với các giá trị lớn quan trọng trong việc huấn luyện các mô hình ngôn ngữ lớn. Tuy nhiên, độ chính xác thấp của BFloat16 gây ra vấn đề trong một số cài đặt. Ví dụ, trong một số triển khai RoPE và ALibi công khai, thao tác torch.arange thất bại do xung đột khi số nguyên vượt quá 256, ngăn cản sự phân biệt các vị trí gần nhau. Do đó, chúng tôi sử dụng độ chính xác đầy đủ cho một số thao tác nhạy cảm với giá trị như nhúng vị trí.

NormHead: Để ổn định huấn luyện và cải thiện hiệu suất mô hình, chúng tôi chuẩn hóa output embeddings (còn được gọi là 'head'). Có hai ưu điểm của NormHead trong thí nghiệm của chúng tôi. Đầu tiên, trong các thí nghiệm sơ bộ, chúng tôi phát hiện rằng norm của head có xu hướng không ổn định. Norm của embedding token hiếm trở nên nhỏ hơn trong quá trình huấn luyện, làm rối loạn động lực huấn luyện. NormHead có thể ổn định động lực một cách đáng kể. Thứ hai, chúng tôi thấy rằng thông tin ngữ nghĩa chủ yếu được mã hóa bởi độ tương tự cosine của Embedding hơn là khoảng cách L2. Vì bộ phân loại tuyến tính hiện tại tính toán logits bằng tích vô hướng, là một hỗn hợp của khoảng cách L2 và độ tương tự cosine. NormHead làm giảm sự phân tán của khoảng cách L2 trong việc tính toán logits. Để biết thêm chi tiết, vui lòng tham khảo phụ lục B.

Max-z loss: Trong quá trình huấn luyện, chúng tôi phát hiện rằng các logits của LLM có thể trở nên rất lớn. Mặc dù hàm softmax không quan tâm đến các giá trị logit tuyệt đối, vì nó chỉ phụ thuộc vào các giá trị tương đối của chúng. Các logits lớn gây ra vấn đề trong quá trình suy luận vì các triển khai phổ biến của penalty lặp lại (như triển khai Hugging Face trong model.generate) áp dụng một scalar (ví dụ 1.1 hoặc 1.2) trực tiếp vào logits. Việc co các logits rất lớn theo cách này có thể thay đổi đáng kể xác suất sau softmax, làm cho mô hình nhạy cảm với việc lựa chọn siêu tham số penalty lặp lại. Được truyền cảm hứng từ NormSoftmax (Jiang et al., 2023b) và auxiliary z-loss từ PaLM (Chowdhery et al., 2022), chúng tôi đã thêm một max-z loss để chuẩn hóa logits:

Lmax-z = 2e−4∗z²(1)

trong đó z là giá trị logit tối đa. Điều này giúp ổn định huấn luyện và làm cho suy luận mạnh mẽ hơn với các siêu tham số.

Hình 3: Loss tiền huấn luyện của Baichuan 2.

Loss huấn luyện cuối cùng của Baichuan 2-7B và Baichuan 2-13B được thể hiện trong Hình 3.

2.6 Định luật Mở rộng
Các định luật mở rộng thần kinh, trong đó lỗi giảm như một hàm lũy thừa của kích thước tập huấn luyện, kích thước mô hình, hoặc cả hai, đã cho phép một hiệu suất đáng tin cậy khi huấn luyện trở nên ngày càng đắt đỏ trong deep learning và các mô hình ngôn ngữ lớn. Trước khi huấn luyện các mô hình ngôn ngữ lớn với hàng tỷ tham số, chúng tôi trước tiên huấn luyện một số mô hình kích thước nhỏ và phù hợp với một định luật mở rộng để huấn luyện các mô hình lớn hơn. Chúng tôi đã khởi chạy một loạt các kích thước mô hình từ 10M đến 3B, dao động từ 1/1000 đến 1/10 kích thước của mô hình cuối cùng, và mỗi mô hình được huấn luyện tối đa 1 nghìn tỷ token, sử dụng các siêu tham số nhất quán và cùng một tập dữ liệu có nguồn gốc từ

--- TRANG 6 ---
Baichuan 2. Dựa trên loss cuối cùng của các mô hình khác nhau, chúng tôi có thể có được một ánh xạ từ các FLOPs huấn luyện đến loss mục tiêu.

Hình 4: Định luật mở rộng của Baichuan 2. Chúng tôi đã huấn luyện các mô hình khác nhau từ 10 triệu đến 3 tỷ tham số với 1 nghìn tỷ token. Bằng cách phù hợp với một thuật ngữ định luật lũy thừa cho các loss với FLOPs huấn luyện, chúng tôi đã dự đoán loss cho việc huấn luyện Baichuan 2-7B và Baichuan 2-13B trên 2.6 nghìn tỷ token. Quá trình phù hợp này đã dự đoán chính xác loss cuối cùng của các mô hình (được đánh dấu bằng hai ngôi sao).

Để phù hợp với định luật mở rộng của mô hình, chúng tôi sử dụng công thức được đưa ra bởi Henighan et al. (2020):

LC = a × C^b + L∞ (2)

trong đó L∞ là loss không thể giảm được và thuật ngữ đầu tiên là loss có thể giảm được được công thức hóa như một thuật ngữ mở rộng định luật lũy thừa. C là các FLOPs huấn luyện và LC là loss cuối cùng của mô hình trong FLOPs đó. Chúng tôi đã sử dụng hàm curve_fit từ thư viện SciPy để phù hợp với các tham số. Đường cong mở rộng được phù hợp cuối cùng và loss cuối cùng được dự đoán của mô hình 7 tỷ và 13 tỷ tham số được thể hiện trong Hình 4. Chúng ta có thể thấy rằng định luật mở rộng được phù hợp đã dự đoán loss cuối cùng của Baichuan 2 với độ chính xác cao.

2.7 Hạ tầng
Việc tận dụng hiệu quả các tài nguyên GPU hiện có đóng vai trò cực kỳ quan trọng trong việc huấn luyện và phát triển các mô hình ngôn ngữ lớn ngày nay. Để thực hiện điều này, chúng tôi phát triển một phương pháp đồng thiết kế cho một khung huấn luyện linh hoạt và một chính sách lập lịch cụm thông minh.

Vì các GPU của chúng tôi được chia sẻ giữa nhiều người dùng và nhiệm vụ, hành vi cụ thể của mỗi nhiệm vụ không thể dự đoán được, thường dẫn đến các node GPU nhàn rỗi trong cụm. Xét rằng một máy duy nhất được trang bị tám GPU A800 có thể đáp ứng đầy đủ các yêu cầu bộ nhớ cho các mô hình Baichuan 2-7B và Baichuan 2-13B của chúng tôi, tiêu chí thiết kế chính cho khung huấn luyện của chúng tôi là tính linh hoạt cấp máy, hỗ trợ tài nguyên cho các nhiệm vụ có thể được thay đổi động theo trạng thái cụm và do đó đóng vai trò như nền tảng cho thuật toán lập lịch thông minh của chúng tôi.

Để đáp ứng yêu cầu về tính linh hoạt cấp máy, khung huấn luyện của chúng tôi tích hợp tensor parallelism (Narayanan et al., 2021) và ZeRO-powered data parallelism (Rajbhandari et al., 2020), trong đó chúng tôi đặt tensor parallelism bên trong mỗi máy và sử dụng ZeRO shared data parallelism để mở rộng linh hoạt qua các máy.

Ngoài ra, chúng tôi sử dụng kỹ thuật tách tensor (Nie et al., 2022) trong đó chúng tôi tách một số tính toán để giảm tiêu thụ bộ nhớ đỉnh, chẳng hạn như tính toán cross-entropy với từ vựng lớn. Phương pháp này cho phép chúng tôi đáp ứng nhu cầu bộ nhớ mà không cần tính toán và truyền thông bổ sung, làm cho hệ thống hiệu quả hơn.

Để tăng tốc thêm việc huấn luyện mà không làm giảm độ chính xác mô hình, chúng tôi triển khai huấn luyện độ chính xác hỗn hợp, trong đó chúng tôi thực hiện tính toán forward và backward trong BFloat16, trong khi thực hiện cập nhật optimizer trong Float32.

Hơn nữa, để mở rộng hiệu quả cụm huấn luyện của chúng tôi lên hàng nghìn GPU, chúng tôi tích hợp các kỹ thuật sau để tránh sự suy giảm hiệu quả truyền thông:

• Huấn luyện phân tán nhận thức topology. Trong các cụm quy mô lớn, các kết nối mạng thường xuyên kéo dài nhiều lớp switch. Chúng tôi sắp xếp một cách chiến lược các rank cho huấn luyện phân tán để giảm thiểu truy cập thường xuyên qua các switch khác nhau, làm giảm độ trễ và do đó nâng cao hiệu quả huấn luyện tổng thể.

• Phân vùng lai và phân cấp cho ZeRO. Bằng cách phân vùng các tham số qua các GPU, ZeRO3 giảm tiêu thụ bộ nhớ với chi phí là các truyền thông all-gather bổ sung. Phương pháp này sẽ dẫn đến một nút thắt truyền thông đáng kể khi mở rộng lên hàng nghìn GPU (Jiang et al., 2023a). Để giải quyết vấn đề này, chúng tôi đề xuất một lược đồ phân vùng lai và phân cấp. Cụ thể, khung của chúng tôi trước tiên phân vùng các trạng thái optimizer qua tất cả các GPU, sau đó quyết định một cách thích ứng lớp nào cần kích hoạt ZeRO3, và liệu có phân vùng các tham số theo cách phân cấp hay không.

Bằng cách tích hợp các chiến lược này, hệ thống của chúng tôi có khả năng huấn luyện các mô hình Baichuan 2-7B và Baichuan 2-13B một cách hiệu quả trên 1,024 GPU NVIDIA A800, đạt được hiệu quả tính toán vượt quá 180 TFLOPS.

3 Điều chỉnh
Baichuan 2 cũng giới thiệu quy trình điều chỉnh dẫn đến hai mô hình chat: Baichuan 2-7B-Chat và Baichuan 2-13B-Chat. Quá trình điều chỉnh của Baichuan 2 bao gồm hai thành phần chính: Supervised Fine-Tuning (SFT) và Reinforcement Learning from Human Feedback (RLHF).

3.1 Supervised Fine-Tuning
Trong giai đoạn supervised fine-tuning, chúng tôi sử dụng các nhãn người để chú thích các prompt được thu thập từ các nguồn dữ liệu khác nhau. Mỗi prompt được gắn nhãn là hữu ích hoặc vô hại dựa trên các nguyên tắc chính tương tự như Claude (2023). Để xác thực chất lượng dữ liệu, chúng tôi sử dụng xác thực chéo—một người chú thích có thẩm quyền kiểm tra chất lượng của một mẫu batch được chú thích bởi một nhóm công nhân cụ thể, từ chối bất kỳ batch nào không đáp ứng tiêu chuẩn chất lượng của chúng tôi.

Chúng tôi đã thu thập hơn 100k mẫu supervised fine-tuning và huấn luyện mô hình cơ sở của chúng tôi trên chúng. Tiếp theo, chúng tôi phân định quá trình học tăng cường thông qua phương pháp RLHF để cải thiện thêm kết quả. Toàn bộ quá trình RLHF, bao gồm RM và huấn luyện RL, được thể hiện trong Hình 5.

Hình 5: Minh họa quá trình RLHF của Baichuan 2.

3.2 Mô hình Phần thưởng
Chúng tôi đã thiết kế một hệ thống phân loại ba tầng cho tất cả các prompt, bao gồm 6 danh mục chính, 30 danh mục phụ và hơn 200 danh mục bậc ba. Từ góc độ người dùng, chúng tôi nhằm mục đích để hệ thống phân loại bao phủ toàn diện tất cả các loại nhu cầu người dùng. Từ quan điểm

--- TRANG 7 ---
huấn luyện mô hình phần thưởng, các prompt trong mỗi danh mục nên có đủ tính đa dạng để đảm bảo mô hình phần thưởng có thể tổng quát hóa tốt.

[Bảng độ chính xác Mô hình Phần thưởng trên các khoảng cách điểm khác nhau]

Với một prompt, các phản hồi được tạo bởi các mô hình Baichuan 2 với kích thước và giai đoạn khác nhau (SFT, PPO) để tăng cường đa dạng phản hồi. Chỉ các phản hồi được tạo bởi họ mô hình Baichuan 2 được sử dụng trong huấn luyện RM. Các phản hồi từ các tập dữ liệu mã nguồn mở khác và các mô hình độc quyền không cải thiện độ chính xác của mô hình phần thưởng. Điều này cũng nhấn mạnh tính nhất quán nội tại của dòng mô hình Baichuan 2 từ một góc độ khác.

Hàm loss được sử dụng để huấn luyện mô hình phần thưởng phù hợp với hàm trong InstructGPT (Ouyang et al., 2022). Mô hình phần thưởng được rút ra từ huấn luyện thể hiện hiệu suất phù hợp với LLaMA 2 (Touvron et al., 2023b), cho thấy rằng sự khác biệt điểm số càng lớn giữa hai phản hồi, độ chính xác phân biệt của mô hình phần thưởng càng cao, như thể hiện trong Bảng 4.

3.3 PPO
Sau khi có được mô hình phần thưởng, chúng tôi sử dụng thuật toán PPO (Schulman et al., 2017) để huấn luyện mô hình ngôn ngữ của chúng tôi. Chúng tôi sử dụng bốn mô hình: mô hình actor (chịu trách nhiệm tạo phản hồi), mô hình tham chiếu (được sử dụng để tính toán penalty KL với các tham số cố định), mô hình phần thưởng (cung cấp phần thưởng tổng thể cho toàn bộ phản hồi với các tham số cố định), và mô hình critic (được thiết kế để học các giá trị per-token).

3.4 Chi tiết Huấn luyện
Trong quá trình huấn luyện RLHF, mô hình critic được khởi động với 20 bước huấn luyện ban đầu. Tiếp theo, cả mô hình critic và actor đều được cập nhật thông qua thuật toán PPO chuẩn. Đối với tất cả các mô hình, chúng tôi sử dụng gradient clipping là 0.5, tốc độ học không đổi là 5e-6, và ngưỡng PPO clip ϵ = 0.1. Chúng tôi đặt hệ số penalty KL β = 0.2, giảm xuống 0.005 theo các bước. Chúng tôi huấn luyện trong 350 lần lặp cho tất cả các mô hình chat của chúng tôi, dẫn đến Baichuan 2-7B-Chat và Baichuan 2-13B-Chat.

4 An toàn
Chúng tôi tin rằng các cải tiến về an toàn mô hình không chỉ xuất phát từ các ràng buộc trong quá trình làm sạch dữ liệu hoặc các giai đoạn điều chỉnh mà còn từ việc khai thác kiến thức tích cực và xác định kiến thức tiêu cực trong tất cả các giai đoạn huấn luyện. Được hướng dẫn bởi khái niệm này, chúng tôi đã tăng cường an toàn mô hình trong suốt quá trình huấn luyện Baichuan 2.

4.1 Giai đoạn Tiền huấn luyện
Trong giai đoạn tiền huấn luyện, chúng tôi chú ý chặt chẽ đến an toàn dữ liệu. Toàn bộ tập dữ liệu tiền huấn luyện đã trải qua một quá trình lọc dữ liệu nghiêm ngặt nhằm tăng cường an toàn. Chúng tôi đã thiết kế một hệ thống quy tắc và mô hình để loại bỏ nội dung có hại như bạo lực, khiêu dâm, phân biệt chủng tộc, lời nói thù hận, và nhiều hơn nữa.

Hơn nữa, chúng tôi đã tuyển chọn một tập dữ liệu song ngữ Trung-Anh bao gồm vài triệu trang web từ hàng trăm trang web uy tín đại diện cho các lĩnh vực giá trị tích cực khác nhau, bao gồm các lĩnh vực như chính sách, luật pháp, các nhóm dễ bị tổn thương, giá trị chung, đức tính truyền thống, và nhiều hơn nữa. Chúng tôi cũng đã tăng xác suất lấy mẫu cho tập dữ liệu này.

4.2 Giai đoạn Điều chỉnh
Chúng tôi xây dựng một quy trình red-teaming bao gồm 6 loại tấn công và hơn 100 danh mục giá trị an toàn chi tiết, một đội chú thích chuyên gia gồm 10 người có kinh nghiệm bảo mật internet truyền thống đã khởi tạo các prompt điều chỉnh an toàn. Các đoạn có liên quan từ tập dữ liệu tiền huấn luyện được truy xuất để tạo phản hồi, dẫn đến khoảng 1K dữ liệu được chú thích để khởi tạo.

• Đội chú thích chuyên gia đã hướng dẫn một đội chú thích gia công 50 người thông qua đối đầu đỏ-xanh với mô hình điều chỉnh được khởi tạo, dẫn đến việc tạo ra 200K prompt tấn công.

• Bằng cách sử dụng một phương pháp lấy mẫu có giám sát đa giá trị chuyên biệt, chúng tôi đã tối đa hóa việc sử dụng dữ liệu tấn công để tạo ra các phản hồi ở các mức độ an toàn khác nhau.

Trong giai đoạn tối ưu hóa RL, chúng tôi cũng đặt an toàn lên hàng đầu:

• Khi bắt đầu tăng cường an toàn, các phương pháp DPO (Rafailov et al., 2023) đã sử dụng một cách hiệu quả lượng dữ liệu được chú thích hạn chế để tăng cường hiệu suất liên quan đến các vấn đề tổn thương cụ thể.

• Bằng cách sử dụng một Mô hình Phần thưởng tích hợp các mục tiêu Hữu ích và Vô hại, huấn luyện tăng cường an toàn PPO đã được thực hiện.

5 Đánh giá
Trong phần này, chúng tôi báo cáo các kết quả zero-shot hoặc few-shot của các mô hình cơ sở được tiền huấn luyện trên các benchmark chuẩn. Chúng tôi đánh giá Baichuan 2 trên các nhiệm vụ tạo sinh tự do và nhiệm vụ lựa chọn đa lựa chọn.

• Tạo sinh tự do: Các mô hình được cung cấp một số đầu vào mẫu (shots) và sau đó tạo ra các phần tiếp theo để có được kết quả, như cho trả lời câu hỏi, dịch thuật, và các nhiệm vụ khác.

• Lựa chọn đa lựa chọn: Các mô hình được cung cấp một câu hỏi và nhiều lựa chọn, và nhiệm vụ là chọn các ứng viên phù hợp nhất.

Với sự đa dạng của các nhiệm vụ và ví dụ, chúng tôi đã tích hợp các framework đánh giá mã nguồn mở như lm-evaluation-harness (Gao et al., 2021) và OpenCompass (OpenCompass, 2023) vào các triển khai nội bộ của chúng tôi để đánh giá công bằng so với các mô hình khác.

Các mô hình chúng tôi chọn để so sánh có kích thước tương tự như Baichuan 2 và là mã nguồn mở để kết quả có thể tái tạo được:

• LLaMA (Touvron et al., 2023b): Các mô hình ngôn ngữ được huấn luyện bởi Meta trên 1 nghìn tỷ token. Độ dài ngữ cảnh là 2,048 và chúng tôi đánh giá cả LLaMA 7B và LLaMA 13B.

• LLaMA 2 (Touvron et al., 2023c): Một mô hình kế thừa của LLaMA 1 được huấn luyện trên 2 nghìn tỷ token và hỗn hợp dữ liệu tốt hơn.

• Baichuan 1 (Baichuan, 2023b): Baichuan 7B được huấn luyện trên 1.2 nghìn tỷ token và Baichuan 13B được huấn luyện trên 1.4 nghìn tỷ token. Cả hai đều tập trung vào tiếng Anh và tiếng Trung.

• ChatGLM 2-6B (Zeng et al., 2022): Một mô hình ngôn ngữ chat có hiệu suất mạnh mẽ trên vài benchmark.

• MPT-7B (MosaicML, 2023): Một LLM mã nguồn mở được huấn luyện trên 1 nghìn tỷ token của văn bản và mã tiếng Anh.

• Falcon-7B (Penedo et al., 2023): Một loạt LLM được huấn luyện trên 1 nghìn tỷ token được tăng cường với

--- TRANG 8 ---
các kho dữ liệu được tuyển chọn. Nó có sẵn dưới giấy phép Apache 2.0.

• Vicuna-13B (Chiang et al., 2023): Một mô hình ngôn ngữ được huấn luyện bằng cách tinh chỉnh LLaMA-13B trên tập dữ liệu đối thoại được tạo bởi ChatGPT.

• Chinese-Alpaca-Plus-13B (Cui et al., 2023): Một mô hình ngôn ngữ được huấn luyện bằng cách tinh chỉnh LLaMA-13B trên tập dữ liệu đối thoại được tạo bởi ChatGPT.

• XVERSE-13B: Một mô hình ngôn ngữ lớn đa ngôn ngữ 13B được huấn luyện trên hơn 1.4 nghìn tỷ token.

5.1 Hiệu suất Tổng thể
Phần này giới thiệu hiệu suất tổng thể của các mô hình cơ sở Baichuan 2 so với các mô hình có kích thước tương tự khác. Chúng tôi chọn 8 benchmark để so sánh: MMLU (Hendrycks et al., 2021a) The Massive Multitask Language Understanding bao gồm một loạt câu hỏi trắc nghiệm về các chủ đề học thuật. C-Eval (Huang et al., 2023) là một benchmark đánh giá tiếng Trung toàn diện bao gồm hơn 10k câu hỏi trắc nghiệm. CMMLU (Li et al., 2023) cũng là một benchmark đánh giá tổng quát được thiết kế đặc biệt để đánh giá khả năng hiểu biết và lý luận của LLM trong bối cảnh ngôn ngữ và văn hóa Trung Quốc. AGIEval (Zhong et al., 2023) là một benchmark lấy con người làm trung tâm được thiết kế đặc biệt để đánh giá các khả năng tổng quát như nhận thức và giải quyết vấn đề của con người. Gaokao (Zhang et al., 2023) là một framework đánh giá sử dụng các câu hỏi thi tuyển sinh trung học phổ thông Trung Quốc. BBH (Suzgun et al., 2022) là một bộ các nhiệm vụ BIG-Bench (Srivastava et al., 2022) thách thức mà các đánh giá mô hình ngôn ngữ không vượt trội hơn người đánh giá trung bình. GSM8K (Cobbe et al., 2021) là một benchmark đánh giá tập trung vào toán học. HumanEval (Chen et al., 2021) là một tập dữ liệu docstring-to-code bao gồm 164 bài toán lập trình kiểm tra các khía cạnh khác nhau của logic lập trình.

Đối với CMMLU và MMLU, chúng tôi áp dụng các triển khai chính thức và áp dụng 5-shot cho đánh giá. Đối với BBH chúng tôi áp dụng đánh giá 3-shot. Đối với C-Eval, Gaokao, và AGIEval chúng tôi chỉ chọn lựa chọn đa lựa chọn với bốn ứng viên để đánh giá tốt hơn. Đối với GSM8K, chúng tôi áp dụng thử nghiệm 4-shot được rút ra từ OpenCompass (OpenCompass, 2023). Chúng tôi cũng tích hợp kết quả của GPT-4 và GPT-3.5-Turbo. Trừ khi được nêu khác, các kết quả trong bài báo này được thu được bằng cách sử dụng các công cụ đánh giá nội bộ của chúng tôi.

Kết quả tổng thể được thể hiện trong Bảng 1. So với các mô hình mã nguồn mở có kích thước tương tự khác, mô hình của chúng tôi có lợi thế hiệu suất rõ ràng. Đặc biệt trong các bài toán toán học và mã lệnh, mô hình của chúng tôi đạt được cải tiến đáng kể so với Baichuan 1.

5.2 Đánh giá Lĩnh vực Thẳng đứng
Chúng tôi cũng đánh giá Baichuan 2 trong các lĩnh vực thẳng đứng, trong đó chúng tôi chọn lĩnh vực luật pháp và y tế vì chúng đã được nghiên cứu rộng rãi trong những năm gần đây.

Trong lĩnh vực luật pháp, chúng tôi báo cáo điểm số của JEC-QA (Zhong et al., 2020), được thu thập từ Kỳ thi Tư pháp Quốc gia Trung Quốc. Nó chứa các câu hỏi trắc nghiệm và câu hỏi đa đáp án. Để tương thích với bộ đánh giá của chúng tôi, chúng tôi chỉ kiểm tra các câu hỏi trắc nghiệm.

Trong lĩnh vực y tế, chúng tôi báo cáo điểm số từ hai benchmark y tế, MedQA (Jin et al., 2021) và MedMCQA (Pal et al., 2022), cũng như điểm số trung bình từ các ngành liên quan đến y tế trong C-Eval (val), MMLU, và CMMLU (viết tắt là CMC). Cụ thể, MedMCQA được thu thập từ các kỳ thi hội đồng y tế chuyên nghiệp ở Mỹ và Trung Quốc, bao gồm ba tập con, tức là USMLE, MCMLE và TWMLE, và chúng tôi báo cáo kết quả của USMLE và MCMLE với năm ứng viên; MedMCQA được thu thập từ các kỳ thi đầu vào y tế Ấn Độ, và chúng tôi đánh giá các câu hỏi trắc nghiệm và báo cáo điểm số trong tập dev. Chi tiết của MedMCQA bao gồm (1) y học lâm sàng, y học cơ bản của C-Eval (val), (2) kiến thức lâm sàng, giải phẫu, y học đại học, sinh học đại học, dinh dưỡng, vi rút học, di truyền học y tế, y học chuyên nghiệp của MMLU, (3) giải phẫu, kiến thức lâm sàng, y học đại học, di truyền học, dinh dưỡng, y học cổ truyền Trung Quốc, vi rút học của CMMLU. Hơn nữa, tất cả các tập dữ liệu này được đánh giá ở 5-shot.

Như thể hiện trong Bảng 5, Baichuan 2-7B-Base vượt trội hơn các mô hình như GPT-3.5 Turbo, ChatGLM 2-6B, và LLaMA 2-7B trong lĩnh vực luật pháp Trung Quốc, chỉ đứng sau GPT-4. So với Baichuan 1-7B, Baichuan 2-7B-Base cho thấy cải tiến gần 10 điểm. Trong lĩnh vực y tế, Baichuan 2-7B-Base vượt trội hơn các mô hình như ChatGLM 2-6B và LLaMA 2-7B, cho thấy cải tiến đáng kể so với Baichuan 1-7B.

Tương tự, Baichuan 2-13B-Base vượt trội hơn các mô hình khác ngoài GPT-4 trong lĩnh vực luật pháp Trung Quốc. Trong lĩnh vực y tế, Baichuan 2-13B-Base vượt trội hơn các mô hình như XVERSE-13B

--- TRANG 9 ---
và LLaMA 2-13B. So với Baichuan 1-13B-Base, Baichuan 2-13B-Base cũng thể hiện cải tiến đáng chú ý.

5.3 Toán học và Mã lệnh
Phần này giới thiệu hiệu suất trong toán học và lập trình.

Chúng tôi sử dụng GSM8K (Cobbe et al., 2021) (4-shot) và MATH (Hendrycks et al., 2021b) (4-shot) để đánh giá khả năng toán học. MATH chứa 12,500 câu hỏi toán học khó giải quyết hơn. Để đánh giá khả năng mã lệnh của mô hình, chúng tôi báo cáo điểm số trong HumanEval (Chen et al., 2021) (0-shot) và MBPP (Austin et al., 2021) (3-shot).

• HumanEval là một loạt các nhiệm vụ lập trình bao gồm hiểu ngôn ngữ mô hình, lý luận, thuật toán, và toán học đơn giản để đánh giá tính đúng đắn của mô hình và đo lường khả năng giải quyết vấn đề của mô hình.

• MBPP. Nó bao gồm một tập dữ liệu gồm 974 hàm Python ngắn và mô tả văn bản chương trình, cùng với các trường hợp thử nghiệm được sử dụng để xác minh tính đúng đắn của chức năng của chúng.

Chúng tôi sử dụng OpenCompass để đánh giá khả năng của các mô hình trong toán học và mã lệnh. Như thể hiện trong Bảng 6, trong lĩnh vực toán học, Baichuan 2-7B-Base vượt trội hơn các mô hình như LLaMA 2-7B. Trong lĩnh vực mã lệnh, nó vượt trội hơn các mô hình cùng kích thước như ChatGLM 2-6B. Baichuan 2-7B-Base thể hiện cải tiến đáng kể so với mô hình Baichuan 1-7B.

Trong toán học, Baichuan 2-13B-Base vượt trội hơn tất cả các mô hình cùng kích thước, tiếp cận mức độ của GPT-3.5 Turbo. Trong lĩnh vực mã lệnh, Baichuan 2-13B-Base vượt trội hơn các mô hình như LLaMA 2-13B và XVERSE-13B. Baichuan 2-13B-Base thể hiện cải tiến đáng kể so với Baichuan 1-13B-Base.

5.4 Đa ngôn ngữ
Chúng tôi sử dụng Flores-101 (Costa-Jussà et al., 2022; Goyal et al., 2021; Guzmán et al., 2019) để đánh giá khả năng đa ngôn ngữ. Flores-101 bao phủ 101 ngôn ngữ từ khắp thế giới. Dữ liệu của nó có nguồn gốc từ các lĩnh vực khác nhau như tin tức, hướng dẫn du lịch, và sách. Chúng tôi đã chọn các ngôn ngữ chính thức của Liên Hợp Quốc (Tiếng Ả Rập (ar), Tiếng Trung (zh), Tiếng Anh (en), Tiếng Pháp (fr), Tiếng Nga (ru), và Tiếng Tây Ban Nha (es)), cũng như Tiếng Đức (de) và Tiếng Nhật (ja), làm ngôn ngữ thử nghiệm. Chúng tôi đã thực hiện thử nghiệm 8-shot trên bảy nhiệm vụ phụ trong Flores-101, bao gồm zh-en, zh-fr, zh-es, zh-ar, zh-ru, zh-ja và zh-de. Đánh giá được thực hiện với OpenCompass.

Trong lĩnh vực đa ngôn ngữ, như thể hiện trong Bảng 7, Baichuan 2-7B-Base vượt trội hơn tất cả các mô hình cùng kích thước trong tất cả bảy nhiệm vụ và cho thấy cải tiến đáng kể so với Baichuan 1-7B.

Baichuan 2-13B-Base vượt trội hơn các mô hình cùng kích thước trong bốn trong số bảy nhiệm vụ. Trong các nhiệm vụ zh-en và zh-ja, nó vượt trội hơn GPT3.5 Turbo và đạt mức độ của GPT-4. So với Baichuan 1-13B-Base, Baichuan 2-13B-Base thể hiện cải tiến đáng kể trong các nhiệm vụ zh-ar, zh-ru, và zh-ja.

Mặc dù GPT-4 vẫn thống trị trong lĩnh vực đa ngôn ngữ, các mô hình mã nguồn mở đang bắt kịp một cách chặt chẽ. Trong các nhiệm vụ zh-en, Baichuan 2-13B-Base đã vượt trội hơn GPT-4 một chút.

5.5 Đánh giá An toàn
Trong Phần 4, chúng tôi mô tả những nỗ lực được thực hiện để cải thiện tính an toàn của Baichuan 2. Tuy nhiên, một số nghiên cứu trước cho thấy rằng tính hữu ích và tính vô hại là hai mặt của một chiếc bập bênh - khi tính vô hại tăng lên, tính hữu ích có thể dẫn đến một chút giảm (Bai et al., 2022a). Vì vậy chúng tôi đánh giá hai yếu tố này trước và sau khi điều chỉnh an toàn.

Hình 6 cho thấy tính hữu ích và tính vô hại trước và sau khi điều chỉnh an toàn của Baichuan 2. Chúng ta có thể thấy rằng quá trình điều chỉnh an toàn của chúng tôi

--- TRANG 10 ---
không làm tổn hại đến tính hữu ích trong khi cải thiện đáng kể tính vô hại.

Sau đó chúng tôi đánh giá tính an toàn của các mô hình được tiền huấn luyện bằng cách sử dụng tập dữ liệu Toxigen (Hartvigsen et al., 2022). Giống như LLaMA 2, chúng tôi sử dụng phiên bản đã được làm sạch từ dự án SafeNLP, phân biệt loại trung tính và thù hận cho 13 nhóm thiểu số, tạo thành một tập dữ liệu 6-shot phù hợp với định dạng prompt Toxigen gốc. Các tham số giải mã của chúng tôi sử dụng nhiệt độ 0.1 và lấy mẫu hạt nhân top-p 0.9.

Chúng tôi sử dụng phiên bản HateBert được tinh chỉnh được tối ưu hóa trong Toxigen (Hartvigsen et al., 2022) để đánh giá mô hình. Bảng 8 cho thấy rằng so với LLaMA 2, các mô hình Baichuan 2-7B và Baichuan 2-13B có một số lợi thế về an toàn.

[Bảng kết quả Toxigen của các mô hình nền tảng Baichuan 2 so với LLaMA 2]

Được truyền cảm hứng từ BeaverTails Ji et al. (2023), chúng tôi đã xây dựng Baichuan Harmless Evaluation Dataset (BHED), bao phủ 7 danh mục an toàn chính của bias/discrimination, insults/profanity, illegal/unethical content, physical health, mental health, financial privacy, và sensitive topics để đánh giá tính an toàn của các mô hình chat của chúng tôi.

Để đảm bảo bao phủ toàn diện trong mỗi danh mục, chúng tôi yêu cầu các chú thích viên tạo ra 1,400 mẫu dữ liệu. Điều này được mở rộng thêm thông qua tự hướng dẫn và được làm sạch bởi con người để đảm bảo tính trôi chảy, dẫn đến tổng cộng 70,000 mẫu với 10,000 mẫu cho mỗi danh mục. Các ví dụ về những prompt an toàn và nguyên tắc được thể hiện trong Phụ lục D.

Chúng tôi sử dụng những mẫu này để đánh giá các mô hình khác nhau và kết quả được thể hiện trong Bảng 9. Chúng ta có thể thấy rằng Baichuan 2 ngang bằng hoặc vượt trội hơn các mô hình chat khác trong các đánh giá an toàn của chúng tôi.

5.6 Các Checkpoint Trung gian
Chúng tôi cũng sẽ phát hành các checkpoint trung gian của các mô hình 7B, từ checkpoint 220 tỷ token đến checkpoint 2,640 tỷ token, là đầu ra cuối cùng của Baichuan 2-7B-Base. Chúng tôi kiểm tra hiệu suất của chúng trên vài benchmark và kết quả được thể hiện trong Hình 7.

Như thể hiện trong hình, Baichuan 2 thể hiện cải tiến nhất quán khi quá trình huấn luyện tiến triển. Ngay cả sau 2.6 nghìn tỷ token, dường như vẫn có chỗ cho những cải tiến thêm. Điều này phù hợp với nghiên cứu trước về việc mở rộng LLM cho thấy rằng kích thước dữ liệu là một yếu tố quan trọng (Hoffmann et al., 2022). Trong Phụ lục C, chúng tôi cung cấp động lực huấn luyện chi tiết hơn cho cả mô hình 7B và 13B.

--- TRANG 11 ---
[Bảng kết quả của các mô hình chat khác nhau trên benchmark đánh giá an toàn]

[Hình 7: Kết quả của các checkpoint trung gian của Baichuan 2-7B sẽ được phát hành công khai]

6 Nghiên cứu Liên quan
Lĩnh vực các mô hình ngôn ngữ đã trải qua một sự hồi sinh trong những năm gần đây, được khơi dậy chủ yếu bởi sự phát triển của mạng thần kinh sâu và Transformers (Vaswani et al., 2017). Kaplan et al. (2020) đã đề xuất các định luật mở rộng cho tiền huấn luyện mô hình lớn. Bằng cách phân tích một cách có hệ thống hiệu suất mô hình khi các tham số và kích thước dữ liệu tăng lên, họ đã cung cấp một bản thiết kế cho kỷ nguyên hiện tại của các mô hình khổng lồ với hàng trăm hoặc thậm chí hàng tỷ tham số.

Nắm bắt các định luật mở rộng này, các tổ chức như OpenAI, Google, Meta, và Anthropic đã tham gia vào một cuộc chạy đua tính toán để tạo ra các LLM ngày càng lớn hơn. Được thúc đẩy bởi mô hình ngôn ngữ độc quyền 175 tỷ tham số GPT-3 (Brown et al., 2020) của OpenAI. Khả năng few-shot hoặc thậm chí zero-shot của LLM đã cách mạng hóa hầu hết các nhiệm vụ hiểu ngôn ngữ tự nhiên. Từ tạo mã lệnh đến giải quyết các bài toán toán học hoặc thậm chí các kịch bản thế giới mở. Các LLM khoa học chuyên môn như Galactica (Taylor et al., 2022) cũng đã xuất hiện để thể hiện tiềm năng của các mô hình lớn để tiếp thu kiến thức kỹ thuật. Tuy nhiên, số lượng tham số thuần túy không xác định khả năng mô hình - Chinchilla (Hoffmann et al., 2022) đã chứng minh rằng việc mở rộng khả năng mô hình theo số lượng token, thay vì chỉ tham số, có thể mang lại hiệu quả mẫu tốt hơn.

Đồng thời với sự phát triển của các LLM tư nhân, các nỗ lực học thuật và phi lợi nhuận đã làm việc để phát triển các lựa chọn thay thế mã nguồn mở như Bloom (Scao et al., 2022), OPT (Zhang et al., 2022) và Pythia (Biderman et al., 2023b). Mặc dù một số mô hình ngôn ngữ lớn mã nguồn mở chứa tới 175 tỷ tham số, hầu hết được huấn luyện chỉ trên 500 tỷ token hoặc ít hơn. Điều này tương đối nhỏ xét rằng các mô hình 7 tỷ tham số vẫn có thể cải thiện đáng kể sau khi được huấn luyện trên hàng nghìn tỷ token. Trong số những mô hình mã nguồn mở đó, LLaMA (Touvron et al., 2023b) và người kế nhiệm LLaMA 2 (Touvron et al., 2023c) nổi bật về hiệu suất và tính minh bạch. Điều này đã được cộng đồng tối ưu hóa nhanh chóng để có tốc độ suy luận tốt hơn và các ứng dụng khác nhau.

Ngoài những mô hình nền tảng đó, rất nhiều mô hình chat cũng đã được đề xuất để tuân theo hướng dẫn của con người. Hầu hết chúng tinh chỉnh các mô hình nền tảng để phù hợp với con người (OpenAI, 2022; Wang et al., 2023). Những mô hình chat đó đã thể hiện cải tiến đáng chú ý trong việc hiểu hướng dẫn của con người và giải quyết các nhiệm vụ phức tạp (Chiang et al., 2023; Xu et al., 2023; Sun et al., 2023). Để cải thiện thêm việc điều chỉnh, (Ouyang et al., 2022) tích hợp phương pháp Reinforcement Learning from Human Feedback (RLHF). Điều này liên quan đến việc học từ sở thích của con người bằng cách huấn luyện một mô hình phần thưởng trên các đầu ra được đánh giá bởi con người. Các phương pháp khác như tối ưu hóa sở thích trực tiếp (DPO) (Rafailov et al., 2023) và học tăng cường từ phản hồi AI (RLAIF) (Bai et al., 2022b) cũng đã

--- TRANG 12 ---
được đề xuất để cải thiện RLHF cả về hiệu quả và hiệu suất.

7 Hạn chế và Cân nhắc Đạo đức
Giống như các mô hình ngôn ngữ lớn khác, Baichuan 2 cũng đối mặt với những thách thức đạo đức. Nó có xu hướng thiên vị và độc tính, đặc biệt là do phần lớn dữ liệu huấn luyện có nguồn gốc từ internet. Mặc dù chúng tôi đã nỗ lực tối đa để giảm thiểu những vấn đề này bằng cách sử dụng các benchmark như Toxigen (Hartvigsen et al., 2022), các rủi ro không thể bị loại bỏ, và độc tính có xu hướng tăng theo kích thước mô hình. Hơn nữa, kiến thức của các mô hình Baichuan 2 là tĩnh và có thể lỗi thời hoặc không chính xác, đặt ra những thách thức trong các lĩnh vực yêu cầu thông tin cập nhật như y học hoặc luật pháp. Mặc dù được tối ưu hóa cho tiếng Trung và tiếng Anh về mặt an toàn, mô hình có hạn chế trong các ngôn ngữ khác và có thể không nắm bắt đầy đủ các thiên vị liên quan đến các nền văn hóa không phải Trung Quốc.

Cũng có tiềm năng bị sử dụng sai mục đích, vì mô hình có thể được sử dụng để tạo ra nội dung có hại hoặc gây hiểu lầm. Mặc dù chúng tôi đã cố gắng hết sức để cân bằng an toàn và tiện ích, một số biện pháp an toàn có thể xuất hiện như quá thận trọng, ảnh hưởng đến khả năng sử dụng của mô hình cho một số nhiệm vụ nhất định. Chúng tôi khuyến khích người dùng sử dụng các mô hình Baichuan 2 một cách có trách nhiệm và đạo đức. Trong khi đó, chúng tôi sẽ tiếp tục tối ưu hóa những vấn đề này và phát hành các phiên bản cập nhật trong tương lai.

Tài liệu tham khảo
[Phần tài liệu tham khảo tiếp theo...]

--- TRANG 13 ---
[Tiếp tục các tài liệu tham khảo...]

--- TRANG 14 ---
[Tiếp tục các tài liệu tham khảo...]

--- TRANG 15 ---
[Tiếp tục các tài liệu tham khảo...]

--- TRANG 16 ---
[Tiếp tục các tài liệu tham khảo...]

--- TRANG 17 ---
[Tiếp tục các tài liệu tham khảo...]

--- TRANG 18 ---
[Tiếp tục các tài liệu tham khảo...]

--- TRANG 19 ---
[Tiếp tục các tài liệu tham khảo...]

--- TRANG 20 ---
A Định luật Mở rộng
Chúng tôi sử dụng 7 mô hình để phù hợp với các định luật mở rộng của Baichuan 2. Chi tiết tham số được thể hiện trong Bảng 10.

[Bảng 10: Các mô hình chúng tôi chọn để phù hợp với định luật mở rộng]

Các loss của 7 mô hình khác nhau được thể hiện trong Hình 8.

[Hình 8: Các loss huấn luyện khác nhau của các mô hình nhỏ cho định luật mở rộng]

B NormHead
Bằng cách thực hiện một nhiệm vụ truy xuất KNN word embedding, trong đó với một từ truy vấn, K từ gần nhất được truy xuất. Chúng tôi phát hiện rằng thông tin ngữ nghĩa chủ yếu được mã hóa bởi độ tương tự cosine của embedding hơn là khoảng cách L2. Tức là, kết quả KNN của độ tương tự cosine là các từ có tương tự ngữ nghĩa trong khi kết quả KNN của khoảng cách L2 là vô nghĩa theo một cách nào đó. Vì bộ phân loại tuyến tính hiện tại tính toán logits bằng tích vô hướng, là một hỗn hợp của khoảng cách L2 và độ tương tự cosine. Để làm giảm sự phân tán của khoảng cách L2, chúng tôi đề xuất tính toán logits chỉ bằng góc. Chúng tôi đã chuẩn hóa Embedding đầu ra để tích vô hướng không bị ảnh hưởng bởi norm của embedding.

Để xác thực thao tác này, chúng tôi thực hiện một thí nghiệm ablation trong đó chúng tôi thêm hoặc loại bỏ chuẩn hóa trước softmax và huấn luyện một mô hình 7B trong 12k bước. Tất cả các siêu tham số và dữ liệu giống với Baichuan 2-7B. Loss huấn luyện được thể hiện trong Hình 9. Chúng ta có thể thấy rằng khi loại bỏ NormHead, việc huấn luyện trở nên rất không ổn định ở đầu, ngược lại, sau khi chúng tôi chuẩn hóa head, việc huấn luyện trở nên rất ổn định, dẫn đến hiệu suất tốt hơn.

[Hình 9: Loss huấn luyện có và không có thao tác NormHead]

C Động lực Huấn luyện
Trong phần này, chúng tôi phân tích động lực huấn luyện của mô hình. Chúng tôi lưu các checkpoint của Baichuan 2-7B và Baichuan 2-13B mỗi 1000 bước. Và đánh giá những kết quả trung gian đó trên tập phát triển C-Eval (Huang et al., 2023), MMLU (Hendrycks et al., 2021a), CMMLU (Li et al., 2023), JEC-QA (Zhong et al., 2020), GSM8K (Shi et al., 2022) và HumanEval (Chen et al., 2021). Kết quả được thể hiện trong Hình 10.

Như thể hiện, cả mô hình 7B và 13B đều thể hiện những cải tiến đáng kể khi quá trình huấn luyện tiến triển. Tuy nhiên, trên các benchmark tổng quát như MMLU (Hendrycks et al., 2021a) và C-Eval (Huang et al., 2023), các cải tiến dường như đạt đến mức bão hòa sau 2 nghìn tỷ token. Ngược lại, những cải tiến nhất quán được đạt được trên các nhiệm vụ toán học GSM8K ngay cả sau 2 nghìn tỷ token. Điều này cho thấy FLOPs huấn luyện có thể có tương quan mạnh với các cải tiến trong giải quyết bài toán toán học, có thể được nghiên cứu thêm.

D Baichuan Harmless Evaluation Dataset
CẢNH BÁO: phần này chứa các ví dụ văn bản không an toàn, xúc phạm hoặc khó chịu.

Chúng tôi đã đề xuất Baichuan Harmless Evaluation Dataset (BHED) để đánh giá các mô hình chat, như mô tả trong Phần 5.5. Ở đây chúng tôi giới thiệu các nguyên tắc và trường hợp của BHED.

Bảy danh mục an toàn chính bao gồm thiên vị và phân biệt đối xử, xúc phạm và tục tĩu, nội dung bất hợp pháp/phi đạo đức, sức khỏe thể chất, sức khỏe tinh thần, quyền riêng tư tài chính, và các chủ đề nhạy cảm.

Để đảm bảo tính đa dạng trong mỗi danh mục, nhiều chiều phụ đã được xem xét:

• Thiên vị/phân biệt đối xử bao gồm các hình thức khác nhau như quốc tịch, dân tộc, chủng tộc/màu da, nhóm, nghề nghiệp, giới tính, khu vực, ngành nghề, v.v. để đảm bảo đa dạng dữ liệu.

• Xúc phạm/tục tĩu bao gồm cả xúc phạm rõ ràng và ngầm cũng như lạm dụng bằng lời nói trên internet.

• Nội dung bất hợp pháp/phi đạo đức bao gồm luật hình sự, luật dân sự, luật kinh tế, luật quốc tế, quy định giao thông, quy định hành chính địa phương, v.v.

• Sức khỏe thể chất bao gồm kiến thức sức khỏe, lời khuyên y tế, và phân biệt đối xử liên quan đến sức khỏe thể chất.

• Sức khỏe tinh thần bao gồm sức khỏe cảm xúc, sức khỏe nhận thức và xã hội, lòng tự trọng và giá trị bản thân, đối phó với căng thẳng và khả năng thích ứng, gợi ý tâm lý, và phân biệt đối xử đối với các nhóm có vấn đề về sức khỏe tinh thần.

• Quyền riêng tư tài chính bao gồm bất động sản, nợ cá nhân, thông tin ngân hàng, thu nhập, khuyến nghị cổ phiếu, v.v. Quyền riêng tư bao gồm thông tin cá nhân, thông tin gia đình, thông tin nghề nghiệp, chi tiết liên hệ, đời tư, v.v.

• Các chủ đề nhạy cảm bao gồm thù hận chủng tộc, các vấn đề chính trị quốc tế, lỗ hổng pháp lý, mối quan hệ con người-AI, v.v.

Chúng tôi thu thập 10k prompt cho mỗi danh mục, một số ví dụ được thể hiện trong Bảng 11.

E Chi tiết về MMLU và C-Eval
Chúng tôi cung cấp điểm số của Baichuan 2 trên từng môn học của C-Eval trong Bảng 12 và MMLU trong Bảng 13.

--- TRANG 21 ---
[Hình 10: Kết quả đánh giá của Baichuan 2-13B và Baichuan 2-7B trên các bước tiền huấn luyện khác nhau]

--- TRANG 22 ---
[Bảng 11: Một số ví dụ về Baichuan Harmless Evaluation Dataset]

--- TRANG 23 ---
[Bảng 12: Điểm số của từng môn học trong C-Eval của Baichuan 2-7B-Base và Baichuan 2-13B-Base]

--- TRANG 24 ---
[Bảng 13: Điểm số của từng môn học trong MMLU của Baichuan 2-7B-Base và Baichuan 2-13B-Base]

--- TRANG 25 ---
[Tiếp tục bảng 13]

--- TRANG 26 ---
F Ví dụ được tạo bởi Baichuan 2-13B-Chat

Người dùng: Từ bây giờ, xin hãy dịch mỗi câu tôi nói tiếp theo sang tiếng Anh, và phía trước mỗi bản dịch đều có "Translate:", sẵn sàng chưa?

Baichuan 2-13B-Chat: Ready.

Người dùng: Xin chào

Baichuan 2-13B-Chat: Translate: Hello

Người dùng: Tôi là Baichuan2, rất vui được gặp mọi người

Baichuan 2-13B-Chat: Translate: I am Baichuan2, and I am very happy to meet everyone

Người dùng: Hy vọng thông qua nỗ lực chung của mọi người, sớm đón chào sự đến của kỷ nguyên AGI

Baichuan 2-13B-Chat: Translate: I hope that through the joint efforts of all of us, we can welcome the arrival of the AGI era as soon as possible

Người dùng: Viết mã python, tìm số trung vị của mảng sau [3.1,6.2,1.3,8.4,10.5,11.6,2.1]

Baichuan 2-13B-Chat: Đầu tiên chúng ta cần sắp xếp mảng, sau đó dựa vào độ dài mảng là lẻ hay chẵn để xác định số trung vị. Trong ví dụ này, độ dài mảng là 7 (lẻ), vì vậy số trung vị là số ở giữa, tức là 6.2.

Sau đây là mã Python thực hiện chức năng này:

```python
def find_median(numbers):
    # Sắp xếp mảng numbers
    numbers.sort()
    # Kiểm tra độ dài là lẻ hay chẵn
    length = len(numbers)
    if length % 2 == 1:
        # Nếu độ dài là lẻ, trung vị là số ở giữa
        return numbers[length // 2]
    else:
        # Nếu độ dài là chẵn, trung vị là trung bình của hai số ở giữa
        middle1 = numbers[(length - 1) // 2]
        middle2 = numbers[(length + 1) // 2]
        return (middle1 + middle2) / 2

# Ví dụ sử dụng
numbers = [3.1, 6.2, 1.3, 8.4, 10.5, 11.6, 2.1]
print(find_median(numbers))  # Output: 6.2
```

Đoạn mã này định nghĩa một hàm tên 'find_median' nhận một danh sách số làm tham số và trả về trung vị của danh sách đó. Trong ví dụ sử dụng, chúng tôi sử dụng một mảng chứa 7 số, sau khi sắp xếp được [1.3, 2.1, 3.1, 6.2, 8.4, 10.5, 11.6], sau đó gọi hàm 'find_median' để được trung vị 6.2.

--- TRANG 27 ---
Người dùng: Gà và thỏ trong một chuồng, tổng cộng có 26 cái đầu, 68 chân, vậy có bao nhiêu con gà, bao nhiêu con thỏ?

Baichuan 2-13B-Chat: Chúng ta có thể sử dụng phương pháp đại số để giải quyết vấn đề này. Giả sử số lượng gà là x, số lượng thỏ là y. Dựa trên thông tin đề bài, chúng ta có thể có được hai phương trình sau:

1. x + y = 26 (tổng số đầu)
2. 2x + 4y = 68 (tổng số chân)

Bây giờ chúng ta cần giải hệ phương trình bậc nhất hai ẩn này. Đầu tiên từ phương trình đầu tiên giải ra x:

x = 26 - y

Sau đó thay biểu thức của x vào phương trình thứ hai:

2(26 - y) + 4y = 68
52 - 2y + 4y = 68
2y = 16

Tiếp theo chúng ta giải giá trị của y:

y = 16 / 2
y = 8

Bây giờ chúng ta có số lượng thỏ là 8 con. Thay giá trị y vào biểu thức x để tìm số lượng gà:

x = 26 - 8
x = 18

Vậy có 18 con gà, 8 con thỏ.

Người dùng: Trong các câu hỏi thường thức thiên văn học sau, câu nào sai? A. Hệ mặt trời là hệ hành tinh gồm mặt trời và tám hành tinh lớn, hành tinh lùn, vệ tinh, vành đai tiểu hành tinh và sao chổi quay xung quanh nó. B. Vệ tinh là thiên thể quay xung quanh hành tinh hoặc thiên thể khác. C. Sao chổi là thiên thể nhỏ hơn trong hệ mặt trời, có lõi gồm băng và bụi. D. Theo phương pháp phân loại thiên thể thông thường, mặt trăng thuộc về hành tinh.

Baichuan 2-13B-Chat: D. Theo phương pháp phân loại thiên thể thông thường, mặt trăng thuộc về hành tinh là sai. Thực tế, mặt trăng là vệ tinh của trái đất, không thuộc phạm vi hành tinh.

Người dùng: Trong các câu hỏi thường thức vật lý sau, câu nào sai? A. Trong môi trường tự nhiên, âm thanh truyền nhanh nhất trong chất rắn. B. Định luật Newton thứ nhất: một vật thể nếu không chịu tác dụng của lực sẽ duy trì trạng thái đứng yên hoặc chuyển động thẳng đều. C. Định luật Newton thứ ba: đối với mỗi lực tác dụng, đều có một phản lực bằng nhau và ngược chiều. D. Tốc độ truyền âm trong không khí là 1000m/s.

Baichuan 2-13B-Chat: Đề bài này kiểm tra khả năng hiểu và ứng dụng các khái niệm và nguyên lý vật lý cơ bản. Đáp án A: Việc truyền âm cần môi trường, trong ba loại môi trường rắn, lỏng và khí, âm thanh truyền nhanh nhất trong chất rắn, vậy A đúng; Đáp án B: Định luật Newton thứ nhất là định luật quán tính, nội dung là: một vật thể nếu không chịu tác dụng của ngoại lực, hoặc duy trì trạng thái đứng yên, hoặc duy trì trạng thái chuyển động thẳng đều, cho đến khi có ngoại lực buộc nó thay đổi trạng thái chuyển động, vậy B đúng; Đáp án C: Nội dung định luật Newton thứ ba là: đối với mỗi lực tác dụng, đều có một phản lực có độ lớn bằng nhau, chiều ngược lại, hai lực này lần lượt tác dụng lên hai vật thể tương tác với nhau, vậy C sai; Đáp án D: Âm thanh truyền trong không khí dưới dạng sóng, tốc độ truyền của nó liên quan đến các yếu tố như nhiệt độ, độ ẩm của môi trường, thông thường, tốc độ truyền âm trong không khí khoảng 340m/s, không phải 1000m/s, vậy D sai. Do đó, đáp án đúng của đề bài này là D.

--- TRANG 28 ---
Người dùng: I'm Mike. I am going to have a busy weekend. On Saturday, I am going to learn how to swim. I will go with my father. Then we are going to have lunch in the restaurant. In the afternoon, we are going to the zoo. We are going to see the pandas. On Sunday, I will finish my homework in the morning. In the afternoon, my parents and I are going to visit my grandparents. We will have dinner together.

Đọc đoạn văn, phản hồi đúng và sai! Đúng viết T, sai viết F:
1. Mike is going to have a busy weekend()
2. Mike is going to learn how to swim with his father()
3. They are going to have lunch at home()

Baichuan 2-13B-Chat: 1. T (đúng)
2. T (đúng)
3. F (sai)

# 2305.15083.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/multilingual/2305.15083.pdf
# Kích thước tệp: 928807 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
Khai thác Khả năng Dịch thuật của Mô hình Ngôn ngữ Lớn thông qua
Tinh chỉnh Đa ngôn ngữ với Hướng dẫn Dịch thuật
Jiahuan Li1∗, Hao Zhou1∗, Shujian Huang1†, Shanbo Cheng2và Jiajun Chen1
1Phòng thí nghiệm Khoa học Trọng điểm Quốc gia về Công nghệ Phần mềm Tiên tiến, Đại học Nam Kinh, Trung Quốc
{lijh,zhouh}@smail.nju.edu.cn, {huangsj,chenjj}@nju.edu.cn
2Nghiên cứu Bytedance
chengshanbo@bytedance.com
Tóm tắt
Các Mô hình Ngôn ngữ Tiền huấn luyện Quy mô lớn (LLMs), như ChatGPT và GPT4, đã thể hiện khả năng mạnh mẽ trong dịch thuật đa ngôn ngữ, mà không cần được huấn luyện rõ ràng trên các corpus song song. Thật hấp dẫn khi biết các LLMs có được khả năng thực hiện các hướng dẫn dịch thuật cho các ngôn ngữ khác nhau như thế nào. Trong bài báo này, chúng tôi trình bày một phân tích chi tiết bằng cách tinh chỉnh một mô hình ngôn ngữ tiền huấn luyện đa ngôn ngữ, XGLM-7.5B, để thực hiện dịch thuật đa ngôn ngữ theo các hướng dẫn đã cho. Thứ nhất, chúng tôi cho thấy các LLMs đa ngôn ngữ có khả năng dịch thuật mạnh hơn so với những gì đã được chứng minh trước đây. Đối với một ngôn ngữ nhất định, hiệu suất dịch thuật phụ thuộc vào sự tương đồng với tiếng Anh và lượng dữ liệu được sử dụng trong giai đoạn tiền huấn luyện. Thứ hai, chúng tôi phát hiện rằng khả năng thực hiện hướng dẫn dịch thuật của LLMs dựa trên việc hiểu các hướng dẫn dịch thuật và sự căn chỉnh giữa các ngôn ngữ khác nhau. Với tinh chỉnh đa ngôn ngữ có hướng dẫn dịch thuật, LLMs có thể học cách thực hiện tốt nhiệm vụ dịch thuật ngay cả đối với những cặp ngôn ngữ chưa từng thấy trong giai đoạn tinh chỉnh hướng dẫn.

1 Giới thiệu
Sự xuất hiện của các Mô hình Ngôn ngữ Tiền huấn luyện Lớn (LLMs) (Brown et al., 2020; OpenAI, 2023) đã cách mạng hóa nghiên cứu về dịch máy (Hendy et al., 2023; Garcia et al., 2023). Các mô hình này đã thể hiện khả năng dịch thuật đa ngôn ngữ đáng chú ý, mà không cần huấn luyện rõ ràng trên các corpus song song. Ví dụ, XGLM, một mô hình ngôn ngữ đa ngôn ngữ cỡ trung, vượt trội hơn các mô hình có giám sát chỉ bằng cách sử dụng một vài ví dụ làm minh họa (Lin et al., 2022); LLM tiên tiến GPT4 đã được chứng minh có hiệu suất tương đương với các hệ thống dịch thuật thương mại trên nhiều cặp ngôn ngữ (Jiao et al., 2023b).

Hầu hết nghiên cứu hiện tại về LLMs cho dịch máy tập trung vào học tập trong ngữ cảnh (ICL), tức là lấy một vài câu song song làm minh họa để hướng dẫn LLMs thực hiện dịch thuật (Vilar et al., 2023; Agrawal et al., 2023; Hendy et al., 2023; Zhu et al., 2023). Tuy nhiên, các phương pháp này phụ thuộc rất nhiều vào khả năng học tập trong ngữ cảnh của LLMs. Đối với các mô hình nhỏ hơn, ví dụ các mô hình chỉ có 1B hoặc 7B tham số, khả năng ICL tương đối yếu có thể dẫn đến việc đánh giá thấp khả năng dịch thuật tiềm năng của chúng.

Thay vì dựa vào khả năng ICL, chúng tôi đề xuất điều tra khả năng của LLMs bằng cách trực tiếp huấn luyện chúng để tuân theo các hướng dẫn dịch thuật. Lấy cảm hứng từ thành công gần đây của tinh chỉnh hướng dẫn (Wei et al., 2022; Chung et al., 2022), chúng tôi tổ chức các nhiệm vụ dịch thuật đa ngôn ngữ như các trường hợp khác nhau của hướng dẫn dịch thuật, với mỗi trường hợp tương ứng với một cặp ngôn ngữ cụ thể. Bằng cách huấn luyện LLMs để tuân theo các hướng dẫn này, tức là với Tinh chỉnh Đa ngôn ngữ có Hướng dẫn Dịch thuật (mFTI), có thể khai thác tốt hơn khả năng dịch thuật bên trong LLMs.

Kết quả của chúng tôi cho thấy bằng cách huấn luyện trên một tập dữ liệu hỗn hợp gồm 1.000 câu cho mỗi cặp ngôn ngữ, mFTI vượt trội hơn học tập trong ngữ cảnh 8-shot gần 3 BLEU trung bình, cho thấy tiềm năng lớn hơn của khả năng dịch thuật của LLMs so với những gì đã được chứng minh trước đây (Lin et al., 2022). Ngoài ra, chúng tôi cũng thảo luận về cách mFTI cải thiện LLMs và những yếu tố nào ảnh hưởng đến hiệu suất.

Để hiểu rõ hơn tại sao LLMs có thể tuân theo các hướng dẫn này, chúng tôi thiết kế một cài đặt mFTI trong đó chỉ một tập con của các hướng dẫn dịch thuật, tức là các cặp ngôn ngữ, được sử dụng để huấn luyện. Do đó, LLMs cần tổng quát hóa khả năng tuân theo hướng dẫn của chúng cho những cặp ngôn ngữ chưa từng thấy trong quá trình mFTI. Đáng ngạc nhiên, mFTI khai thác khả năng dịch thuật không chỉ cho các cặp ngôn ngữ đã được huấn luyện mà còn cho những cặp chưa từng thấy trong quá trình huấn luyện hướng dẫn. Với các thí nghiệm và phân tích sâu hơn, chúng tôi phát hiện rằng LLMs có thể học hành vi dịch thuật nói chung bằng cách được huấn luyện để dịch ngay cả những cặp ngôn ngữ không liên quan. Cũng thú vị là với mFTI, LLMs học cách căn chỉnh trực tiếp các ngôn ngữ thông qua việc sử dụng các ngôn ngữ trung gian, điều này tăng cường khả năng tuân theo hướng dẫn cho các cặp ngôn ngữ chưa từng thấy.

2 Tinh chỉnh Đa ngôn ngữ với Hướng dẫn Dịch thuật

2.1 Khung tổng quát
Cho một corpus các câu song song đa ngôn ngữ và các ngôn ngữ của chúng M ={(lsi, lti,xi,yi)}, trong đó lsiและltiề tên của ngôn ngữ nguồn và ngôn ngữ đích của câu song song thứ i (xi,yi), tương ứng, mFTI tận dụng một mẫu hướng dẫn T để tổ chức corpus M thành một tập dữ liệu mô hình ngôn ngữ D. Mỗi câu di trong D là một thể hiện của hướng dẫn dịch thuật với một cặp câu cụ thể: di=T(lsi, lti,xi,yi). Các tham số của LLMs sau đó được tối ưu hóa bằng cách sử dụng mục tiêu dự đoán token tiếp theo tiêu chuẩn trên D:

argmax
θ|D|X
i=1|di|X
j=1logpθ(di
j|di
<j), (1)

trong đó θ là các tham số của LLMs. Mẫu hướng dẫn chúng tôi áp dụng là

Translation: [ ls]:x[lt]:y

trong đó tiền tố "Translation:" được sử dụng để chỉ ra nhiệm vụ dịch thuật; mẫu "[ ·]:" được sử dụng để xác định tên của ngôn ngữ cụ thể.

2.2 Thiết lập thí nghiệm
Mô hình Ngôn ngữ Cơ sở Chúng tôi xem xét XGLM-7.5B (Lin et al., 2022) làm mô hình ngôn ngữ cơ sở của chúng tôi. XGLM-7.5B là một mô hình ngôn ngữ tự hồi quy đa ngôn ngữ quy mô lớn, được huấn luyện trên một corpus khổng lồ gồm 500 tỷ token bao gồm 30 ngôn ngữ đa dạng. Các ngôn ngữ ít tài nguyên đã được tăng mẫu trong quá trình huấn luyện, khiến nó trở thành một mô hình cơ sở lý tưởng cho nghiên cứu dịch thuật đa ngôn ngữ.

Ngôn ngữ Theo Lin et al. (2022), đánh giá của chúng tôi bao gồm 13 ngôn ngữ được bao phủ trong corpus tiền huấn luyện của XGLM, tức là tiếng Anh (En), tiếng Đức (De), tiếng Pháp (Fr), tiếng Catalan (Ca), tiếng Phần Lan (Fi), tiếng Nga (Ru), tiếng Bulgaria (Bg), tiếng Trung (Zh), tiếng Hàn (Ko), tiếng Ả Rập (Ar), tiếng Swahili (Sw), tiếng Hindi (Hi) và tiếng Tamil (Ta). Trong số các ngôn ngữ này, En, De, Fr, Ru, và Zh là các ngôn ngữ có nhiều tài nguyên (với tỷ lệ trong dữ liệu tiền huấn luyện XGLM lớn hơn 4%); Ko, Fi, Ar, Bg là các ngôn ngữ có tài nguyên trung bình (với tỷ lệ từ 0.5%-4%); Ca, Hi, Ta, Sw là các ngôn ngữ ít tài nguyên (với tỷ lệ dưới 0.5%)

Tập dữ liệu Đánh giá Theo các nghiên cứu trước (Lin et al., 2022), chúng tôi đánh giá các mô hình dịch thuật trên tập dữ liệu FLORES-101 (Goyal et al., 2022), cung cấp các bản dịch thủ công của 1012 câu trong 101 ngôn ngữ.

Tập dữ liệu Tinh chỉnh Tập dữ liệu tinh chỉnh của chúng tôi chủ yếu đến từ WikiMatrix (Schwenk et al., 2021). WikiMatrix cung cấp một corpus song song cho 1620 cặp ngôn ngữ khác nhau, bao gồm nhiều cặp ngôn ngữ không phải tiếng Anh, điều này cho phép một cuộc điều tra có hệ thống về dịch thuật của các ngôn ngữ khác ngoài tiếng Anh. Chúng tôi cũng tận dụng corpus MultiCCAligned (El-Kishky et al., 2020) cho các cặp ngôn ngữ không có trong WikiMatrix, bao gồm Hi-Sw, Ko-Sw, Ta-Sw, Sw-Hi, Sw-Ko, Sw-Ta.

Chi tiết Tối ưu hóa Chúng tôi tinh chỉnh tất cả các mô hình bằng bộ tối ưu hóa Adam (Kingma và Ba, 2014) với tốc độ học được cố định là 5e−6. Chúng tôi sử dụng kích thước batch cố định là 80 câu và tinh chỉnh các mô hình trong 1 epoch hoặc 2000 bước (tùy thuộc vào kích thước của corpus huấn luyện) cho tất cả các thí nghiệm.

3 Hiểu về Khả năng Dịch thuật Tiềm năng của LLMs

Trong phần này, trước tiên chúng tôi đánh giá hiệu suất dịch thuật tổng thể của mFTI bằng cách so sánh nó với học tập trong ngữ cảnh few-shot1. Sau đó chúng tôi trình bày một phân tích chi tiết về cách corpus cho mFTI ảnh hưởng đến chất lượng dịch thuật.

3.1 Khả năng Dịch thuật của LLMs
Chúng tôi tinh chỉnh XGLM trên 156 cặp ngôn ngữ bao trùm tất cả 13 ngôn ngữ. Vì mục tiêu của chúng tôi là khai thác khả năng dịch thuật của LLMs bằng cách sử dụng một số lượng nhỏ ví dụ, chúng tôi giới hạn số lượng câu song song ở 1000 cho mỗi ngôn ngữ.

1Chúng tôi chọn ngẫu nhiên 8 ví dụ từ tập dev FLORES-101 làm minh họa cho ICL. Chiến lược chọn ngẫu nhiên được chứng minh là đủ tốt trong nhiều nghiên cứu trước (Vilar et al., 2023; Zhu et al., 2023). Mẫu chúng tôi sử dụng cho ICL là <src_text> = <tgt_text>, cho thấy hiệu suất tốt theo Zhu et al. (2023).

--- TRANG 3 ---
Hình 1: Hiệu suất dịch thuật của ICL 8-shot và mFTI sử dụng 1000 câu cho mỗi cặp ngôn ngữ. Các ngôn ngữ được sắp xếp theo lượng dữ liệu trong corpus tiền huấn luyện.

khả năng dịch thuật của LLMs bằng cách sử dụng một số lượng nhỏ ví dụ, chúng tôi giới hạn số lượng câu song song ở 1000 cho mỗi ngôn ngữ.

mFTI Khai thác Khả năng Dịch thuật Tốt hơn Few-shot ICL. Hình 1 cho thấy BLEU trung bình cho dịch thuật sang và từ ngôn ngữ X, tương ứng. Kết quả đầy đủ về từng hướng ngôn ngữ có thể tìm thấy trong Phụ lục A. Rõ ràng là mFTI dẫn đến hiệu suất dịch thuật tốt hơn ICL 8-shot cho tất cả các cặp ngôn ngữ (trung bình 3 BLEU). Đối với một số ngôn ngữ, khoảng cách lên đến 8 BLEU (ví dụ dịch sang tiếng Catalan). Điều này chứng minh hiệu quả của mFTI trong việc khai thác khả năng dịch thuật của LLM. Nó cũng cho thấy LLMs có tiềm năng lớn hơn cho dịch thuật đa ngôn ngữ so với những gì chúng ta thấy với ICL (Lin et al., 2022).

Ngay cả đối với dịch thuật sang và từ tiếng Anh, mFTI vẫn vượt trội hơn ICL 8-shot, nhưng với khoảng cách nhỏ hơn nhiều. Điều này chỉ ra rằng LLMs với ICL tốt hơn trong việc thực hiện các nhiệm vụ liên quan đến tiếng Anh hơn là các ngôn ngữ khác, nhưng chúng vẫn có tiềm năng thực hiện tốt hơn nữa.

XGLM vẫn là một Mô hình Lấy tiếng Anh làm trung tâm. Hiệu suất dịch thuật cho mỗi ngôn ngữ khác nhau rất nhiều. Xét rằng số lượng câu được sử dụng trong mFTI là như nhau cho mỗi ngôn ngữ, người ta có thể nghi ngờ rằng hiệu suất dịch thuật của mỗi ngôn ngữ phụ thuộc rất nhiều vào lượng dữ liệu tiền huấn luyện của nó. Vì lý do này, các ngôn ngữ trong Hình 1 được liệt kê theo thứ tự giảm dần của lượng dữ liệu trong tiền huấn luyện XGLM. Tuy nhiên, có những biến động rõ ràng. Ví dụ, tiếng Nga và tiếng Trung là hai ngôn ngữ có tỷ lệ dữ liệu tiền huấn luyện lớn nhất ngoài tiếng Anh, nhưng hiệu suất dịch thuật của chúng kém hơn nhiều so với một số ngôn ngữ khác như tiếng Pháp.

Chúng tôi tính toán tương quan Spearman giữa hiệu suất dịch thuật và các yếu tố ảnh hưởng có thể, cụ thể là lượng dữ liệu trong tiền huấn luyện và sự tương đồng với tiếng Anh. Đối với lượng dữ liệu, chúng tôi sử dụng kích thước corpus tiền huấn luyện được báo cáo trong Lin et al. (2022). Đối với sự tương đồng với tiếng Anh, chúng tôi áp dụng lang2vec2, là một công cụ để truy vấn cơ sở dữ liệu hình thái URIEL, để lấy vector đặc trưng của mỗi ngôn ngữ từ các góc độ khác nhau bao gồm địa lý, cú pháp, phả hệ, âm học và từ vựng3.

Sang X Từ X
Lượng Dữ liệu trong Tiền huấn luyện 0.39 0.36
Sự Tương đồng với tiếng Anh
Địa lý 0.93 0.87
Cú pháp 0.85 0.80
Phả hệ 0.71 0.75
Âm học 0.50 0.49
Từ vựng 0.51 0.41

Bảng 1: Tương quan Spearman giữa hiệu suất dịch thuật trung bình (theo BLEU) và các yếu tố ảnh hưởng có thể (lượng dữ liệu trong tiền huấn luyện, sự tương đồng với tiếng Anh). Hiệu suất dịch thuật sang và từ ngôn ngữ X được tính riêng biệt.

2https://github.com/antonisa/lang2vec
3Chúng tôi hướng dẫn độc giả đến Littell et al. (2017) để biết chi tiết về cách vector đặc trưng được tạo ra.

--- TRANG 4 ---
Hình 2: So sánh mFTI với các mô hình dịch máy có giám sát thông thường. Hiệu suất được đánh giá bằng BLEU.

Như được thể hiện trong Bảng 1, hiệu suất dịch thuật thực sự có tương quan dương với lượng dữ liệu trong tiền huấn luyện (0.39/0.36). Tuy nhiên, sự tương đồng giữa một ngôn ngữ cụ thể và tiếng Anh đóng vai trò quan trọng hơn trong việc xác định hiệu suất dịch thuật cuối cùng. Tất cả các đặc trưng được xem xét đều thể hiện hệ số tương quan cao hơn so với lượng dữ liệu trong tiền huấn luyện. Điều này chỉ ra rằng XGLM vẫn là một mô hình chủ yếu lấy tiếng Anh làm trung tâm. Dựa trên những quan sát này, chúng tôi đề xuất xem xét mối quan hệ giữa các ngôn ngữ khác nhau khi thu thập và lấy mẫu dữ liệu cho việc tiền huấn luyện LLMs đa ngôn ngữ.

Không dễ dàng để các mô hình dựa trên LLM vượt trội hơn các mô hình MT có giám sát thông thường. Để định vị tốt hơn hiệu suất của mFTI, chúng tôi so sánh nó với hai mô hình MT có giám sát thông thường, tức là mô hình M2M-1.2B (Fan et al., 2020) và NLLB-3B (Costa-jussà et al., 2022), trong Hình 24. Chúng ta có thể thấy rằng mặc dù mFTI cải thiện đáng kể so với ICL 8-shot và đôi khi đạt được hiệu suất tương đương với M2M-615M, nó vẫn thua kém NLLB-3B mạnh mẽ hơn với một khoảng cách lớn, làm nổi bật thách thức trong việc áp dụng một LLM cỡ trung để vượt trội hơn các mô hình MT có giám sát quy mô lớn.

4Chúng tôi cũng bao gồm hiệu suất được đánh giá bằng COMET trong Phụ lục C.

Hình 3: Thay đổi điểm BLEU sau khi sử dụng tiếng Anh làm trung gian cho ICL 8-shot và mFTI.

3.2 mFTI Mang lại Cải thiện Nhất quán trên các Metric, LLMs và Chiến lược Tinh chỉnh Khác nhau

Để hiểu về hiệu quả phổ quát của mFTI, chúng tôi trình bày các thí nghiệm trên nhiều LLMs hơn, tức là BLOOM-7b1 (Scao et al., 2022) và LLaMA (Touvron et al., 2023), và chiến lược tinh chỉnh tiết kiệm tham số LoRA (Hu et al., 2022). Chúng tôi báo cáo hiệu suất trung bình trên 156 hướng dịch thuật được đánh giá bằng cả sacre-BLEU (Post, 2018) và COMET (Rei et al., 2022)5 trong Bảng 26.

Thứ nhất, chúng ta có thể thấy rằng các phương pháp dựa trên XGLM-7.5B thực hiện tốt hơn đáng kể so với BLOOM-7B và LLaMA-7B. Điều này là do nhiều ngôn ngữ ít tài nguyên được đại diện kém trong BLOOM và LLaMA. Thứ hai, mFTI nhất quán vượt trội hơn ICL 8-shot về BLEU và COMET trên cả ba LLMs được nghiên cứu, bất kể chiến lược tinh chỉnh, điều này chứng minh hiệu quả phổ quát trong các tình huống khác nhau. Trái với các phát hiện trước đây (Jiao et al., 2023a), chúng tôi không thấy LoRA thực hiện tốt hơn tinh chỉnh đầy đủ. Chúng tôi giả thuyết rằng việc học dịch thuật trên 156 cặp đồng thời thách thức hơn và đòi hỏi nhiều khả năng mô hình hơn, làm cho tinh chỉnh đầy đủ trở thành lựa chọn tốt hơn LoRA trong tình huống này.

5Chúng tôi sử dụng phiên bản wmt22-comet-da.
6Các siêu tham số chi tiết có trong Phụ lục B.

--- TRANG 5 ---
mFTI nhất quán vượt trội hơn ICL 8-shot về BLEU và COMET trên cả ba LLMs được nghiên cứu, bất kể chiến lược tinh chỉnh, điều này chứng minh hiệu quả phổ quát trong các tình huống khác nhau. Trái với các phát hiện trước đây (Jiao et al., 2023a), chúng tôi không thấy LoRA thực hiện tốt hơn tinh chỉnh đầy đủ. Chúng tôi giả thuyết rằng việc học dịch thuật trên 156 cặp đồng thời thách thức hơn và đòi hỏi nhiều khả năng mô hình hơn, làm cho tinh chỉnh đầy đủ trở thành lựa chọn tốt hơn LoRA trong tình huống này.

3.3 mFTI Tăng cường Căn chỉnh Ngôn ngữ Trực tiếp

Một sự khác biệt rõ ràng giữa ICL và mFTI là mFTI có thể học từ nhiều câu song song hơn và cập nhật mô hình nếu cần. Thật thú vị khi thấy những thay đổi gì sau khi cập nhật. Nhiều nghiên cứu trước đây (Zhang et al., 2023; Jiao et al., 2023b) đã chỉ ra rằng dịch thuật bằng cách sử dụng tiếng Anh làm trung gian cải thiện đáng kể hiệu suất dịch thuật của ICL. Để làm điều này, chúng tôi so sánh cải thiện hiệu suất của dịch thuật trung gian bằng cách sử dụng ICL và mFTI, tương ứng.

Hình 3 trình bày kết quả. Mỗi giá trị trong lưới là sự khác biệt BLEU trước và sau khi sử dụng tiếng Anh làm trung gian. Chúng ta có thể quan sát đầu tiên rằng việc sử dụng tiếng Anh làm trung gian thực sự cải thiện hiệu suất dịch thuật cho ICL, lên đến 10 BLEU trong một số cặp ngôn ngữ. Tuy nhiên, sau mFTI, khoảng cách đã được giảm đáng kể. Xét đến thực tế mFTI đạt được trung bình 3 BLEU cao hơn ICL, việc giảm lợi ích từ việc sử dụng tiếng Anh làm trung gian so với dịch thuật trực tiếp có thể chỉ ra sự căn chỉnh trực tiếp tốt hơn giữa các ngôn ngữ.

3.4 Các Yếu tố Ảnh hưởng đến mFTI

Chất lượng Corpus Tinh chỉnh là Quan trọng. Nghiên cứu gần đây về tinh chỉnh hướng dẫn chứng minh rằng chất lượng dữ liệu hướng dẫn rất quan trọng để đạt được hiệu suất tốt (?). Chúng tôi quan sát một xu hướng tương tự khi thực hiện mFTI. Cụ thể, chúng tôi xây dựng corpus tinh chỉnh chất lượng cao và thấp bằng cách chọn câu song song theo điểm tương đồng LASER7 đi kèm từ tập đầy đủ các câu song song. Theo kết quả trong Bảng 3, tinh chỉnh với câu song song chất lượng cao có thể cải thiện điểm BLEU khoảng 2 điểm so với tinh chỉnh với câu song song chất lượng thấp, nhấn mạnh tầm quan trọng của chất lượng corpus, xác nhận tầm quan trọng của chất lượng corpus tinh chỉnh.

7https://github.com/facebookresearch/LASER

Hình 4: Hiệu suất dịch thuật của XGLM đã tinh chỉnh khi số lượng tham số mô hình và ví dụ huấn luyện tăng lên.

Hiệu quả của mFTI Tăng theo Kích thước Mô hình và Ví dụ Huấn luyện. Hình 4 cho thấy hiệu suất dịch thuật khi thay đổi số lượng ví dụ huấn luyện cho mỗi cặp ngôn ngữ (1k, 2k, 4k, 8k, 16k, 32k) và số lượng tham số mô hình (564M, 1.7B, 2.9B, 4.5B, 7.5B). Như chúng ta có thể thấy, nó tuân theo một quy luật tỷ lệ log-tuyến tính tiêu chuẩn về cả số lượng ví dụ huấn luyện và kích thước mô hình, điều này phù hợp với các phát hiện trong nghiên cứu trước đây (Kaplan et al., 2020).

4 Hiểu về Khả năng Thực hiện Hướng dẫn Dịch thuật

Trong phần này, chúng tôi trình bày một phân tích toàn diện về cách mFTI cải thiện khả năng thực hiện hướng dẫn dịch thuật của mô hình.

Chúng tôi bắt đầu bằng cách trình bày một thí nghiệm tổng quát trong đó chúng tôi cố ý giữ lại một số cặp ngôn ngữ nhất định trong quá trình mFTI, điều này cho phép chúng tôi nghiên cứu khả năng thực hiện hướng dẫn dịch thuật của mô hình trong các điều kiện khác nhau.

Hơn nữa, chúng tôi đi sâu hơn vào phân tích bằng cách khám phá cách mFTI tăng cường khả năng thực hiện hướng dẫn dịch thuật của LLMs từ các góc độ sau: hiểu rõ hơn về hướng dẫn dịch thuật (Phần 4.3 và Phần 4.4) và căn chỉnh tốt hơn giữa các ngôn ngữ để thực hiện hướng dẫn dịch thuật (Phần 4.5).

--- TRANG 6 ---
BLOOM-7B LLaMA-7B XGLM-7.5B
BLEU COMET BLEU COMET BLEU COMET
ICL 8-shot 8.4 60.9 9.0 61.0 13.9 73.4
mFTI (LoRA) 9.0 64.3 9.5 63.9 16.7 77.0
mFTI (Tinh chỉnh Đầy đủ) 10.2 65.4 9.8 66.0 16.9 77.7

Bảng 2: Hiệu suất dịch thuật trung bình trên tất cả 156 cặp ngôn ngữ của ICL 8-shot và mFTI sử dụng các LLMs và chiến lược tinh chỉnh khác nhau.

BLEU
Chất lượng thấp 15.0
Chất lượng cao 16.9

Bảng 3: Hiệu suất dịch thuật của XGLM đã tinh chỉnh khi chất lượng corpus tinh chỉnh thay đổi.

ter alignment between languages to execute trans-
lation instructions (Section 4.5).

4.1 Thao tác Điều kiện

Trong Phần 3, chúng tôi đã trình bày kết quả trong một cài đặt có giám sát đầy đủ, trong đó tất cả các cặp ngôn ngữ thử nghiệm đều được thấy trong quá trình tinh chỉnh hướng dẫn. Để cung cấp thêm hiểu biết về khả năng tổng quát hóa của LLMs qua các cặp ngôn ngữ, chúng tôi mô phỏng một tình huống thực tế hơn trong đó có thể thiếu câu ngôn ngữ nguồn và/hoặc đích trong quá trình tinh chỉnh hướng dẫn.

Cụ thể hơn, từ 13 ngôn ngữ được chọn, chúng tôi giữ lại 6 ngôn ngữ làm ngôn ngữ chưa thấy. Chúng tôi tiếp tục phân chia 7 ngôn ngữ còn lại thành ba nhóm: Chỉ-Nguồn (ngôn ngữ chỉ xuất hiện ở phía nguồn), Chỉ-Đích (ngôn ngữ chỉ xuất hiện ở phía đích) và Nguồn-Đích (ngôn ngữ xuất hiện ở cả phía nguồn và đích). Sau đó chúng tôi tạo các cặp ngôn ngữ từ các phân vùng này theo yêu cầu của các phân vùng. Điều này cho phép chúng tôi đánh giá hiệu suất của mFTI trong các điều kiện sau:

• Đã thấy Cả hai Phía Cả ngôn ngữ phía nguồn và phía đích đều xuất hiện trong corpus tinh chỉnh. Điều này có thể được chia thêm thành:
- Cùng Hướng. Cùng hướng dịch thuật được huấn luyện trong mFTI.
- Hướng Ngược lại. Cùng hướng dịch thuật không xuất hiện khi huấn luyện, nhưng hướng ngược lại có.
- Hướng Chưa thấy. Cặp dịch thuật (không phải cùng cũng không ngược lại) không xuất hiện khi huấn luyện.

• Chưa thấy Nguồn. Chỉ có câu ngôn ngữ đích xuất hiện khi huấn luyện.

• Chưa thấy Đích. Chỉ có câu ngôn ngữ nguồn xuất hiện khi huấn luyện.

• Chưa thấy Cả hai Phía. Không có câu ngôn ngữ nguồn cũng không có ngôn ngữ đích xuất hiện trong corpus tinh chỉnh.

4.2 mFTI Học cách Tuân theo Hướng dẫn Dịch thuật qua các Điều kiện

Chúng tôi tinh chỉnh XGLM trên corpus được mô tả trong phần trước. Vì có 16 hướng ngôn ngữ trong corpus huấn luyện, chúng tôi ký hiệu mô hình đã tinh chỉnh là mFTI-16. Mô hình được tinh chỉnh trên tất cả các cặp ngôn ngữ được ký hiệu là mFTI-all. Bảng 4 cho thấy kết quả.

mFTI-16 Mang lại Cải thiện trong Hầu hết Cài đặt, Nhưng Ít hơn Nhiều so với mFTI-all. Đầu tiên chúng ta có thể thấy rằng mFTI-16 mang lại cải thiện trong hầu hết các cài đặt ngoại trừ Hướng Ngược lại, chứng minh hiệu quả của mFTI-16. Tuy nhiên, các cải thiện ít hơn khi so sánh mFTI-all, ngay cả đối với phân vùng Cùng Hướng. Điều này có thể được quy cho ít cặp ngôn ngữ hơn khi tinh chỉnh, mà chúng tôi sẽ thảo luận trong Phần 4.3.

Thay đổi Vị trí Ngôn ngữ Giữa Huấn luyện và Thử nghiệm Có Tác động Tiêu cực đến Hiệu suất Dịch thuật. Hiệu suất dịch thuật của mFTI-16 trên Hướng Ngược lại giảm 0.8 BLEU so với ICL 8-shot. Bằng cách kiểm tra kết quả dịch thuật, chúng tôi phát hiện rằng mFTI-16 gặp phải vấn đề off-target nghiêm trọng, tức là tạo ra bản dịch trong ngôn ngữ đích sai. Chúng tôi giả thuyết rằng điều này có thể được quy cho sự thay đổi trong vị trí tương đối của ngôn ngữ nguồn và đích trong quá trình huấn luyện.

--- TRANG 7 ---
Đã thấy Cả hai Phía    Chưa thấy Nguồn    Chưa thấy Đích    Chưa thấy Cả hai Phía
Cùng Hướng    Hướng Ngược lại    Hướng Chưa thấy

ICL 8-shot    14.5    14.5    11.2    13.5    13.6    14.6
mFTI-16    15.7(+1.2)    13.7(-0.8)    12.6(+1.4)    14.9(+1.4)    14.5(+0.9)    15.3(+0.7)
mFTI-all    16.7    16.8    14.6    17.6    17.0    18.4

Bảng 4: Hiệu suất dịch thuật trong các điều kiện dữ liệu khác nhau. mFTI-16: XGLM tinh chỉnh đa ngôn ngữ với hướng dẫn dịch thuật trên một hỗn hợp 16 cặp ngôn ngữ được mô tả trong Phần 4.1.

Nhìn thấy Ngôn ngữ Đích Khi Tinh chỉnh Tốt hơn Ngôn ngữ Nguồn. Khi có ngôn ngữ chưa thấy trong hướng ngôn ngữ, cải thiện trên Chưa thấy Nguồn lớn hơn nhiều so với Chưa thấy Đích, chỉ ra việc hiểu ngôn ngữ đích được chỉ định có thể quan trọng hơn ngôn ngữ nguồn.

Chưa thấy Cả hai Phía Cũng Hưởng lợi từ Huấn luyện mFTI. Hiện tượng đáng ngạc nhiên nhất là các cặp ngôn ngữ từ phân vùng Chưa thấy Cả hai Phía cũng hưởng lợi từ mFTI, với cải thiện 0.7 BLEU so với ICL 8-shot. Vì mFTI-16 không nhìn thấy bất kỳ câu nào của ngôn ngữ nguồn và đích, các cải thiện chỉ ra sự hiểu biết tốt hơn về hướng dẫn dịch thuật, mà chúng tôi sẽ thảo luận trong Phần 4.4.

4.3 Tinh chỉnh Hướng dẫn với Nhiều Cặp Ngôn ngữ hơn Dẫn đến Hiệu suất Dịch thuật Tốt hơn

Các nghiên cứu tinh chỉnh hướng dẫn trước đây cho thấy rằng việc mở rộng số lượng nhiệm vụ có lợi ích đáng kể cho các nhiệm vụ chưa thấy (Chung et al., 2022). Quan sát khoảng cách hiệu suất của Cùng Hướng giữa mFTI-16 và mFTI-all, chúng tôi dần dần thêm nhiều cặp ngôn ngữ hơn vào mFTI-16, và vẽ biểu đồ hiệu suất dịch thuật trên mỗi phân vùng trong Hình 5. Để cô lập các tác động có thể có của các câu đơn ngữ bổ sung, chúng tôi chỉ thêm các cặp ngôn ngữ loại trừ 13 ngôn ngữ được nghiên cứu8.

Có thể thấy rằng khi số lượng cặp ngôn ngữ tăng lên, hiệu suất dịch thuật của tất cả các phân vùng nói chung tăng lên, xác nhận tầm quan trọng của nhiều cặp ngôn ngữ hơn. Đáng chú ý, hiệu suất của phân vùng Hướng Ngược lại được tăng cường đáng kể, vượt trội hơn ICL 8-shot với một khoảng cách lớn khi tăng số lượng cặp ngôn ngữ từ 16 lên 30.

Đáng ngạc nhiên, hiệu suất của phân vùng Chưa thấy Cả hai Phía cải thiện nhiều nhất. Vì không có dữ liệu của các cặp ngôn ngữ trong Chưa thấy Cả hai Phía được thêm vào, điều này chỉ ra khả năng tuân theo hướng dẫn trên các cặp ngôn ngữ này đã được tăng cường đáng kể, mà chúng tôi sẽ thảo luận trong phần tiếp theo.

8Các cặp ngôn ngữ chi tiết có trong Phụ lục D.

Hình 5: Hiệu suất dịch thuật trên các phân vùng khác nhau khi số lượng cặp ngôn ngữ tăng lên. Trái: các phân vùng trong đó câu của cả ngôn ngữ nguồn và đích đều được thấy khi huấn luyện. Phải: các phân vùng trong đó câu ngôn ngữ nguồn và/hoặc đích chưa được thấy khi huấn luyện.

4.4 mFTI Tổng quát hóa Sự hiểu biết về Hướng dẫn Dịch thuật cho các Hướng Chưa thấy

Trong phần này, chúng tôi nhằm hiểu cách mFTI tạo điều kiện cho việc hiểu hướng dẫn từ góc nhìn chi tiết hơn, tức là các hướng ngôn ngữ cụ thể và lỗi tuân theo hướng dẫn.

--- TRANG 8 ---
Hình 6: Xu hướng hiệu suất dịch thuật và tuân theo hướng dẫn trên 3 cặp ngôn ngữ Chưa-thấy-cả-hai khi mở rộng số lượng cặp ngôn ngữ trong mFTI. 2 hình bên trái cho thấy điểm BLEU và tỷ lệ lỗi tuân theo hướng dẫn tổng thể, tương ứng. 4 hình còn lại cho thấy tỷ lệ của 4 loại lỗi cụ thể, tương ứng, tức là sao chép nguồn, off-target, dịch quá/thiếu, và ảo giác dao động. Trục X biểu thị số lượng cặp ngôn ngữ huấn luyện. Trục Y biểu thị tỷ lệ phần trăm bản dịch với các loại lỗi cụ thể.

Đối với các hướng ngôn ngữ, chúng tôi chọn Ru→Fr (tài nguyên cao), Bg→Ar (tài nguyên trung bình), Ca→Ta (tài nguyên thấp) từ phân vùng Chưa thấy Cả hai Phía để nghiên cứu hiệu quả của mFTI trong các cài đặt tài nguyên khác nhau.

Đối với lỗi hướng dẫn, chúng tôi xác định bốn vấn đề chính sau trong bản dịch:

• Sao chép Nguồn (SC): Lỗi này xảy ra khi mô hình đơn giản sao chép câu nguồn làm bản dịch mà không thực hiện bất kỳ thay đổi có ý nghĩa nào. Chúng tôi xác định lỗi này bằng cách tính điểm BLEU cấp câu giữa bản dịch và câu nguồn. Nếu điểm BLEU trên 80, nó chỉ ra rằng bản dịch gần như giống hệt với nguồn.

• Dịch off-target (OT): Trong trường hợp này, mô hình không tạo ra câu trong ngôn ngữ đích. Chúng tôi phát hiện lỗi này bằng cách sử dụng công cụ nhận dạng ngôn ngữ, như fasttext, để xác định ngôn ngữ của bản dịch được tạo ra.

• Dịch quá/thiếu (OU): Lỗi này đề cập đến tình huống mà mô hình tạo ra bản dịch dài hơn hoặc ngắn hơn đáng kể so với tham chiếu. Chúng tôi coi bản dịch có tỷ lệ độ dài trên 2 hoặc dưới 0.5 là dịch quá hoặc thiếu, tương ứng.

• Ảo giác dao động (OH): Lỗi này xảy ra khi mô hình bị kẹt trong một trạng thái dịch cụ thể và tạo ra các n-gram lặp lại cho đến khi đạt độ dài tối đa. Chúng tôi định nghĩa bản dịch có n-gram lặp lại liên tiếp ít nhất ba lần là ảo giác dao động.

4.4.1 Thêm các Cặp Ngôn ngữ Không liên quan Giảm Tỷ lệ SC, OT và OU

Trong Phần 4.3, chúng tôi cho thấy rằng các cặp ngôn ngữ bổ sung trong mFTI dẫn đến cải thiện điểm BLEU ngay cả đối với phân vùng Chưa thấy Cả hai Phía. Chúng tôi cung cấp một phân tích sâu ở đây từ các góc nhìn chi tiết được đề cập ở trên. Chúng tôi vẽ biểu đồ xu hướng hiệu suất dịch thuật và tuân theo hướng dẫn, và tỷ lệ của 4 lỗi tuân theo hướng dẫn cụ thể

--- TRANG 9 ---
Ru→Fr    Bg→Ar    Ca→Ta
OT⇓OH⇓BLEU ⇑    OT⇓OH⇓BLEU ⇑    OT⇓OH⇓BLEU ⇑
mFTI-16    1.2    0.2    25.1    10.4    1.8    8.1    13.9    11.8    5.2
+ unseen-mono    0.9    0.1    25.4    2.6    0.9    10.4    4.4    6.3    6.3
mFTI-150    0.8    0.3    27.0    3.4    2.3    10.8    1.8    14.8    8.7
+ unseen-mono    0.7    0.2    27.4    0.5    1.5    12.0    1.2    5.1    9.3
mFTI-all    0.7    0.2    28.0    0.1    1.5    12.7    1.0    8.7    9.6

Bảng 5: Điểm BLEU, tỷ lệ off-target và tỷ lệ ảo giác dao động trước và sau khi thêm câu đơn ngữ vào corpus tinh chỉnh. Điểm số mà việc thêm câu đơn ngữ dẫn đến cải thiện chất lượng có nền xanh.

khi số lượng cặp ngôn ngữ bổ sung tăng lên. Kết quả trong Hình 6.

Nhiều Cặp Ngôn ngữ hơn Giảm Lỗi Tuân theo Hướng dẫn và Cải thiện Hiệu suất Dịch thuật. Đầu tiên, chúng ta có thể thấy rằng khi nhiều cặp ngôn ngữ được thêm vào corpus huấn luyện, lỗi tuân theo hướng dẫn trên các cặp ngôn ngữ Chưa-thấy-cả-hai dần được giảm, dẫn đến cải thiện điểm BLEU. So sánh các cặp ngôn ngữ khác nhau, chúng ta có thể thấy rằng các cặp ngôn ngữ tài nguyên cao và trung bình nói chung thực hiện tốt hơn các cặp ngôn ngữ tài nguyên thấp trên tất cả bốn loại lỗi. Vì tất cả các hướng ngôn ngữ này chưa được thấy khi tinh chỉnh hướng dẫn, nó nhấn mạnh tầm quan trọng của các kỹ năng ngôn ngữ có được trong giai đoạn tiền huấn luyện.

SC: Đã giải quyết. Có thể quan sát thấy rằng sau khi thêm khoảng 30-60 cặp ngôn ngữ, mô hình học cách tránh vấn đề SC, chỉ ra đây là một vấn đề tương đối dễ giải quyết.

OU: Giảm xuống mức của mFTI-all. Chúng ta có thể thấy thêm rằng việc thêm nhiều cặp ngôn ngữ hơn cũng hiệu quả trong việc giảm lỗi OU, vì tỷ lệ lỗi giảm đáng kể khi số lượng cặp ngôn ngữ tăng lên. Đáng chú ý, sau khi mở rộng số lượng cặp ngôn ngữ lên 150, tỷ lệ OU của ba cặp ngôn ngữ chưa thấy có thể so sánh với tinh chỉnh đầy đủ có giám sát. Điều này chứng minh hiệu quả của mFTI.

OT: Giảm, nhưng không đến mức thỏa đáng. Chuyển sang tỷ lệ OT, chúng ta quan sát thấy nó cũng giảm khi số lượng cặp ngôn ngữ tăng lên. Tuy nhiên, ngay cả sau khi mở rộng số lượng cặp ngôn ngữ lên 150, tỷ lệ OT vẫn không thể giảm xuống mức của mFTI-all.

OH: Không có hiệu quả. Cuối cùng, chúng ta có thể thấy rằng với sự gia tăng số lượng cặp ngôn ngữ, tỷ lệ OH không cho thấy xu hướng giảm rõ ràng, mà chúng tôi sẽ thảo luận thêm trong phần tiếp theo.

4.4.2 Huấn luyện Kết hợp với Hướng dẫn Tạo Đơn ngữ Giúp Giảm Vấn đề OH và OT Hiệu quả hơn

Trong phần trước, chúng tôi phát hiện rằng vấn đề off-target (OT) và ảo giác dao động (OH) trên một số cặp ngôn ngữ không thể được giải quyết hoàn toàn đến mức của mFTI-all bằng cách thêm nhiều cặp ngôn ngữ không liên quan hơn. Chúng tôi lưu ý rằng cả hai vấn đề chỉ liên quan đến ngôn ngữ đích: vấn đề OT có thể được quy cho khả năng không thể liên kết tên ngôn ngữ đích với các ký tự tương ứng của ngôn ngữ đó của mô hình, và vấn đề OH có thể được gây ra bởi việc mô hình hóa kém các ngôn ngữ đích. Chúng tôi giả thuyết rằng việc tinh chỉnh mô hình trên các hướng dẫn tạo đơn ngữ, tức là cho một tên ngôn ngữ, tạo ra các câu trôi chảy từ ngôn ngữ đó, sẽ giúp giảm bớt những vấn đề này.

Để làm điều này, chúng tôi tổ chức các câu đơn ngữ của các ngôn ngữ bị giữ lại thành các hướng dẫn tạo đơn ngữ. Mẫu chúng tôi áp dụng là "[li] :y". Sau đó chúng tôi tinh chỉnh XGLM trên tập dữ liệu gồm các hướng dẫn dịch thuật và các hướng dẫn tạo đơn ngữ này.

Chúng tôi báo cáo điểm BLEU, tỷ lệ OT và tỷ lệ OH trong Bảng 5. Đầu tiên chúng ta có thể thấy rằng việc thêm hướng dẫn tạo đơn ngữ cho ba cặp ngôn ngữ Chưa thấy Cả hai Phía có thể giúp giảm thiểu vấn đề OT và OH trong hầu hết các tình huống, dẫn đến hiệu suất dịch thuật tốt hơn. Đáng chú ý, bằng cách kết hợp nhiều cặp ngôn ngữ không liên quan và câu đơn ngữ, khoảng cách giữa mFTI-150 với câu đơn ngữ và mFTI-all đã giảm đáng kể, mặc dù mô hình chưa bao giờ thấy câu song song của ngôn ngữ được thử nghiệm trước đây.

--- TRANG 10 ---
4.5 mFTI Cải thiện Căn chỉnh Ngôn ngữ thông qua Ngôn ngữ Trung gian

Bên cạnh việc hiểu hướng dẫn dịch thuật, một kiến thức quan trọng khác mà mô hình phải nắm bắt để thực hiện hướng dẫn là sự căn chỉnh giữa ngôn ngữ nguồn và đích. Tuy nhiên, trong các tình huống không có câu song song trực tiếp, mô hình có quyền truy cập hạn chế vào thông tin căn chỉnh. Tình huống này giống với cài đặt zero-shot thường được nghiên cứu trong nghiên cứu dịch thuật đa ngôn ngữ (Gu et al., 2019; Zhang et al., 2020; Arivazhagan et al., 2019; Liu et al., 2021). Trong phần này, chúng tôi nhằm điều tra khả năng của mFTI trong việc thiết lập sự căn chỉnh có ý nghĩa thông qua ngôn ngữ trung gian trong tình huống này.

Cụ thể, đối với ba cặp ngôn ngữ Chưa thấy Cả hai Phía X→Y được nghiên cứu trong phần trước, tức là Ru→Fr, Bg→Ar và Ca→Ta, chúng tôi bắt đầu từ cài đặt mFTI-150, và thêm câu song song X→En và En→Y vào corpus huấn luyện. Sau đó chúng tôi thực hiện mFTI bằng cách sử dụng các corpus được tăng cường này và đánh giá hiệu suất của mô hình trên các câu thử nghiệm không chứa lỗi tuân theo hướng dẫn. Vì kiến thức về căn chỉnh ngôn ngữ là yêu cầu cuối cùng để thực hiện hướng dẫn dịch thuật một khi mô hình đã học cách thực hiện hướng dẫn dịch thuật một cách chính xác, hiệu suất trên các câu này phục vụ như một chỉ báo đáng tin cậy về khả năng thành thạo căn chỉnh ngôn ngữ của mô hình.

Kết quả trong Bảng 6. Đầu tiên, chúng ta có thể thấy rằng mFTI-150 và ICL 8-shot thực hiện tương đương, cả hai đều kém hơn đáng kể so với mFTI-all. Vì ba cặp ngôn ngữ được thử nghiệm chưa được thấy trong mFTI-150, điều này chỉ ra rằng tương tự như mFTI-150, vai trò chính của ICL là tăng cường sự hiểu biết của mô hình về hành vi dịch thuật thay vì kiến thức căn chỉnh nguồn-đích.

Tuy nhiên, sau khi thêm câu song song trung gian, hiệu suất của mô hình (+pivot) được tăng cường đáng kể. Điều này chứng minh tiềm năng của mFTI trong việc tận dụng ngôn ngữ trung gian để tăng cường căn chỉnh trực tiếp giữa các ngôn ngữ và cải thiện hiệu suất dịch thuật.

Ru→Fr    Bg→Ar    Ca→Ta
ICL 8-shot    27.0    11.6    9.7
mFTI-all    28.2    13.2    10.6
mFTI-150    27.5    11.6    9.2
+ pivot    27.9    13.0    10.8

Bảng 6: Hiệu suất dịch thuật trên các câu thử nghiệm không có lỗi tuân theo hướng dẫn. Hiệu suất tốt nhất được in đậm. Hiệu suất tốt thứ hai được gạch chân.

5 Các Nghiên cứu Liên quan

5.1 LLMs cho MT

Các nhà nghiên cứu dịch máy đã công nhận rộng rãi tiềm năng của việc sử dụng LLMs cho MT, vì các mô hình này có được kỹ năng hiểu ngôn ngữ tiên tiến trong quá trình tiền huấn luyện. Paradigm phổ biến để tận dụng LLMs cho MT là học tập trong ngữ cảnh (ICL). Ví dụ, Lin et al. (2022) đã chứng minh rằng việc cung cấp 32 ví dụ trong quá trình dịch có thể vượt trội hơn GPT-3 và một mô hình dịch thuật đa ngôn ngữ có giám sát. Các nghiên cứu khác như Vilar et al. (2023), Agrawal et al. (2023), và Zhu et al. (2023) đã điều tra các yếu tố khác nhau ảnh hưởng đến hiệu suất của ICL, bao gồm chất lượng ví dụ, chiến lược chọn ví dụ, và độ nhạy cảm với mẫu. Hơn nữa, các nghiên cứu như Hendy et al. (2023) và Jiao et al. (2023b) đã nghiên cứu chất lượng dịch thuật của các mô hình GPT-3 khác nhau và thấy hiệu suất của chúng có thể so sánh với các hệ thống dịch thuật thương mại trên các cặp ngôn ngữ có nhiều tài nguyên. Trái ngược với các nghiên cứu này, nghiên cứu của chúng tôi tập trung vào khám phá khả năng dịch thuật của LLMs hiện có bằng cách trực tiếp tinh chỉnh chúng để tuân theo hướng dẫn dịch thuật.

Nghiên cứu tương tự nhất với chúng tôi là Jiao et al. (2023a), tinh chỉnh một LLM mã nguồn mở LLaMA (Touvron et al., 2023) trên dữ liệu dịch thuật hỗn hợp và tập dữ liệu hướng dẫn alpaca (Taori et al., 2023) để làm cho nó trở thành một dịch giả tốt hơn. Tuy nhiên, họ chủ yếu tập trung vào cài đặt dịch thuật song ngữ trong khi nghiên cứu của chúng tôi điều tra sự tổng quát hóa đa ngôn ngữ khi tinh chỉnh LLMs để thực hiện hướng dẫn dịch thuật.

5.2 Tổng quát hóa trên Các Cặp Ngôn ngữ Chưa thấy

Nghiên cứu của chúng tôi cũng có mối liên hệ chặt chẽ với dịch thuật zero-shot trong cài đặt dịch thuật đa ngôn ngữ, trong đó không có câu song song trực tiếp giữa ngôn ngữ nguồn và đích. Có hai vấn đề chính cho dịch thuật zero-shot: tạo ra ngôn ngữ chính xác và học các biểu diễn ngôn ngữ phổ quát.

Đối với vấn đề đầu tiên, Gu et al. (2019); Zhang et al. (2020) tận dụng back-translation để thêm nhiều dữ liệu huấn luyện liên quan đến ngôn ngữ đích. Arivazhagan et al. (2019); Liu et al. (2021) áp đặt regularization trên encoder/decoder để làm cho mô hình nhận thức hơn về ngôn ngữ đích. Không giống như các nghiên cứu của họ, chúng tôi thảo luận về vấn đề off-target trong bối cảnh LLMs, và thấy rằng việc thêm cả các cặp ngôn ngữ không liên quan và câu đơn ngữ bổ sung có thể giảm bớt vấn đề này ở mức độ lớn.

Đối với vấn đề thứ hai, các nghiên cứu trước tập trung vào việc học các biểu diễn ngôn ngữ-bất khả tri thông qua regularization bổ sung của các biểu diễn mô hình (Arivazhagan et al., 2019; Pan et al., 2021), và tính nhất quán giữa các câu tương đương về mặt ngữ nghĩa (Al-Shedivat và Parikh, 2019; Yang et al., 2021). Thay vào đó, các nghiên cứu của chúng tôi chủ yếu nhằm tiết lộ tính hữu ích của việc tinh chỉnh LLMs đa ngôn ngữ cho các cặp ngôn ngữ chưa thấy bằng cách nội hóa thông tin ngôn ngữ trung gian.

Hơn nữa, thảo luận của chúng tôi bao gồm một phiên bản nghiêm ngặt hơn của dịch thuật zero-shot, trong đó không có câu ngôn ngữ nguồn cũng không có ngôn ngữ đích trong corpus tinh chỉnh. Điều này đòi hỏi khả năng tổng quát hóa mạnh hơn, vì mô hình phải sử dụng hiệu quả kiến thức ngôn ngữ có được trong quá trình tiền huấn luyện và kiến thức nhiệm vụ dịch thuật có được trong quá trình tinh chỉnh để tạo ra bản dịch chất lượng cao.

5.3 Tinh chỉnh Hướng dẫn

Nghiên cứu của chúng tôi tập trung vào tinh chỉnh LLMs với hướng dẫn để cải thiện hiệu suất dịch thuật zero-shot. Các nghiên cứu trước đã chứng minh rằng LLMs gặp khó khăn lớn trong việc đạt được hiệu suất tốt trong cài đặt zero-shot khi thiếu ví dụ few-shot. Tuy nhiên, việc tinh chỉnh LLMs trên nhiều nhiệm vụ khác nhau có thể cải thiện đáng kể hiệu suất zero-shot trên một số nhiệm vụ. Ví dụ, Wei et al. (2022) nhằm cải thiện tổng quát hóa trong các nhiệm vụ chưa thấy bằng cách thực hiện tinh chỉnh hướng dẫn. Muennighoff et al. (2023) mở rộng thêm để tinh chỉnh LLM bằng dữ liệu đa ngôn ngữ thay vì dữ liệu tiếng Anh và thấy rằng tinh chỉnh đa ngôn ngữ dẫn đến hiệu suất tốt hơn trên các nhiệm vụ chưa thấy và ngôn ngữ chưa thấy. Chung et al. (2022) khám phá tinh chỉnh hướng dẫn từ góc độ số lượng nhiệm vụ trong corpus tinh chỉnh và kích thước LLM. Chung et al. (2022) phát hiện rằng việc mở rộng các yếu tố này có thể cải thiện đáng kể hiệu suất zero-shot.

Trong nghiên cứu của chúng tôi, chúng tôi chủ yếu tập trung vào hiệu suất dịch thuật của LLMs. Chúng tôi áp dụng một cách tiếp cận toàn diện để xem xét các yếu tố được đề cập ở trên, bao gồm quy mô của corpus tinh chỉnh, kích thước tham số mô hình, và việc lựa chọn ngôn ngữ trong corpus tinh chỉnh, cho một phân tích toàn diện về hiệu suất dịch thuật của LLMs. Ngoài ra, chúng tôi tiến hành một phân tích chi tiết về khả năng hiểu và thực thi của mô hình trong các nhiệm vụ dịch thuật sau khi tinh chỉnh hướng dẫn.

6 Kết luận

Trong bài báo này, chúng tôi khám phá Tinh chỉnh Đa ngôn ngữ với Hướng dẫn Dịch thuật (mFTI), để khai phá tốt hơn khả năng dịch thuật của LLMs đa ngôn ngữ. Thông qua các thí nghiệm rộng rãi, chúng tôi chứng minh rằng bằng cách huấn luyện trên một tập dữ liệu hỗn hợp gồm 1000 câu cho mỗi cặp ngôn ngữ, mFTI đạt được hiệu suất tốt hơn ICL 8-shot, chỉ ra tiềm năng chưa được khai thác của khả năng dịch thuật trong LLMs bởi các nghiên cứu trước đây.

Hơn nữa, chúng tôi thảo luận có hệ thống về cơ chế hoạt động của mFTI bằng cách phân tích nó từ góc độ tuân theo hướng dẫn. Các thí nghiệm của chúng tôi chứng minh rằng mFTI giúp mô hình tuân theo hướng dẫn tốt hơn bằng cách giới thiệu nhiều cặp ngôn ngữ và câu đơn ngữ hơn, và tăng cường căn chỉnh ngôn ngữ trực tiếp bằng cách học từ các cặp ngôn ngữ trung gian.

Bài báo của chúng tôi cũng tiết lộ các vấn đề dịch thuật còn tồn tại khi áp dụng LLMs cho dịch máy zero-shot, tức là dịch quá/thiếu, ảo giác dao động, và dịch sai do căn chỉnh không chính xác. Các nghiên cứu tương lai nên tập trung vào việc có được nhiều kiến thức ngôn ngữ hơn từ giai đoạn tiền huấn luyện và thiết kế các điều kiện regularization tốt hơn để giải quyết những vấn đề này.

Lời cảm ơn

Chúng tôi muốn cảm ơn các nhà phản biện ẩn danh và biên tập viên về những nhận xét sâu sắc của họ. Shujian Huang là tác giả liên hệ. Nghiên cứu này được hỗ trợ bởi Quỹ Khoa học Quốc gia Trung Quốc (Số 62376116, 62176120), Quỹ Nghiên cứu Tỉnh Liêu Ninh cho Nghiên cứu Cơ bản (Số 2022-KF-26-02).

--- TRANG 12 ---
Tài liệu tham khảo

Sweta Agrawal, Chunting Zhou, Mike Lewis, Luke Zettlemoyer, và Marjan Ghazvininejad. 2023. Lựa chọn ví dụ trong ngữ cảnh cho dịch máy. Trong Findings of the Association for Computational Linguistics: ACL 2023, trang 8857–8873, Toronto, Canada. Association for Computational Linguistics.

Maruan Al-Shedivat và Ankur Parikh. 2019. Tính nhất quán thông qua thỏa thuận trong dịch máy neural zero-shot. Trong Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), trang 1184–1197, Minneapolis, Minnesota. Association for Computational Linguistics.

Naveen Arivazhagan, Ankur Bapna, Orhan Firat, Roee Aharoni, Melvin Johnson, và Wolfgang Macherey. 2019. Thành phần thiếu trong dịch máy neural zero-shot. CoRR, cs.CL/1903.07091v1.

Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, T. J. Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeff Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, và Dario Amodei. 2020. Các mô hình ngôn ngữ là những người học few-shot. CoRR, 2005.14165.

Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Yunxuan Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, Albert Webson, Shixiang Shane Gu, Zhuyun Dai, Mirac Suzgun, Xinyun Chen, Aakanksha Chowdhery, Alex Castro-Ros, Marie Pellat, Kevin Robinson, Dasha Valter, Sharan Narang, Gaurav Mishra, Adams Yu, Vincent Zhao, Yanping Huang, Andrew Dai, Hongkun Yu, Slav Petrov, Ed H. Chi, Jeff Dean, Jacob Devlin, Adam Roberts, Denny Zhou, Quoc V. Le, và Jason Wei. 2022. Mở rộng các mô hình ngôn ngữ được tinh chỉnh hướng dẫn. CoRR, cs.LG/2210.11416v5.

Marta R. Costa-jussà, James Cross, Onur Çelebi, Maha Elbayad, Kenneth Heafield, Kevin Heffernan, Elahe Kalbassi, Janice Lam, Daniel Licht, Jean Maillard, Anna Sun, Skyler Wang, Guillaume Wenzek, Al Youngblood, Bapi Akula, Loic Barrault, Gabriel Mejia Gonzalez, Prangthip Hansanti, John Hoffman, Semarley Jarrett, Kaushik Ram Sadagopan, Dirk Rowe, Shannon Spruit, Chau Tran, Pierre Andrews, Necip Fazil Ayan, Shruti Bhosale, Sergey Edunov, Angela Fan, Cynthia Gao, Vedanuj Goswami, Francisco Guzmán, Philipp Koehn, Alexandre Mourachko, Christophe Ropers, Safiyyah Saleem, Holger Schwenk, và Jeff Wang. 2022. Không để lại ngôn ngữ nào: Mở rộng dịch máy lấy con người làm trung tâm. CoRR, cs.CL/2207.04672v3.

Ahmed El-Kishky, Vishrav Chaudhary, Francisco Guzman, và Philipp Koehn. 2020. CCAligned: Một bộ sưu tập khổng lồ các cặp tài liệu web đa ngôn ngữ. Trong Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP 2020), trang 5960–5969, Online.

Angela Fan, Shruti Bhosale, Holger Schwenk, Zhiyi Ma, Ahmed El-Kishky, Siddharth Goyal, Mandeep Baines, Onur Celebi, Guillaume Wenzek, Vishrav Chaudhary, Naman Goyal, Tom Birch, Vitaliy Liptchinsky, Sergey Edunov, Edouard Grave, Michael Auli, và Armand Joulin. 2020. Vượt ra ngoài dịch máy đa ngôn ngữ lấy tiếng Anh làm trung tâm.

Xavier Garcia, Yamini Bansal, Colin Cherry, George Foster, Maxim Krikun, Fangxiaoyu Feng, Melvin Johnson, và Orhan Firat. 2023. Hiệu quả không hợp lý của học few-shot cho dịch máy. CoRR, cs.CL/2302.01398v1.

Naman Goyal, Cynthia Gao, Vishrav Chaudhary, Peng-Jen Chen, Guillaume Wenzek, Da Ju, Sanjana Krishnan, Marc'Aurelio Ranzato, Francisco Guzmán, và Angela Fan. 2022. Benchmark đánh giá Flores-101 cho dịch máy ít tài nguyên và đa ngôn ngữ. Transactions of the Association for Computational Linguistics, 10:522–538.

Jiatao Gu, Yong Wang, Kyunghyun Cho, và Victor O.K. Li. 2019. Cải thiện dịch máy neural zero-shot thông qua việc bỏ qua các tương quan giả mạo. Trong Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, trang 1258–1268, Florence, Italy. Association for Computational Linguistics.

Amr Hendy, Mohamed Abdelrehim, Amr Sharaf, Vikas Raunak, Mohamed Gabr, Hitokazu Matsushita, Young Jin Kim, Mohamed Afify, và Hany Hassan Awadalla. 2023. Các mô hình GPT tốt như thế nào trong dịch máy? Một đánh giá toàn diện. CoRR, cs.CL/2302.09210v1.

Edward J Hu, yelong shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, và Weizhu Chen. 2022. LoRA: Thích ứng thấp hạng của các mô hình ngôn ngữ lớn. Trong International Conference on Learning Representations.

Wenxiang Jiao, Jen tse Huang, Wenxuan Wang, Xing Wang, Shuming Shi, và Zhaopeng Tu. 2023a. ParroT: Dịch trong khi trò chuyện bằng các mô hình ngôn ngữ lớn. CoRR, cs.CL/2304.02426v4.

Wenxiang Jiao, Wenxuan Wang, Jen tse Huang, Xing Wang, và Zhaopeng Tu. 2023b. ChatGPT có phải là một dịch giả tốt không? Có với GPT-4 làm động cơ. CoRR, cs.CL/2301.08745v3.

Jared Kaplan, Sam McCandlish, Tom Henighan, Tom B. Brown, Benjamin Chess, Rewon Child, Scott Gray, Alec Radford, Jeffrey Wu, và Dario Amodei. 2020. Quy luật tỷ lệ cho các mô hình ngôn ngữ neural. CoRR, cs.LG/2001.08361v1.

Diederik P. Kingma và Jimmy Ba. 2014. Adam: Một phương pháp tối ưu hóa ngẫu nhiên. CoRR, cs.LG/1412.6980v9.

Xi Victoria Lin, Todor Mihaylov, Mikel Artetxe, Tianlu Wang, Shuohui Chen, Daniel Simig, Myle Ott, Naman Goyal, Shruti Bhosale, Jingfei Du, Ramakanth Pasunuru, Sam Shleifer, Punit Singh Koura, Vishrav Chaudhary, Brian O'Horo, Jeff Wang, Luke Zettlemoyer, Zornitsa Kozareva, Mona Diab, Veselin Stoyanov, và Xian Li. 2022. Học few-shot với các mô hình ngôn ngữ tạo sinh đa ngôn ngữ. Trong Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, trang 9019–9052, Abu Dhabi, United Arab Emirates. Association for Computational Linguistics.

Patrick Littell, David R. Mortensen, Ke Lin, Katherine Kairis, Carlisle Turner, và Lori Levin. 2017. URIEL và lang2vec: Đại diện ngôn ngữ như các vector hình thái, địa lý và phả hệ. Trong Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 2, Short Papers, trang 8–14, Valencia, Spain. Association for Computational Linguistics.

Hui Liu, Danqing Zhang, Bing Yin, và Xiaodan Zhu. 2021. Cải thiện các mô hình tiền huấn luyện cho phân loại văn bản đa nhãn zero-shot thông qua lý luận phân cấp nhãn được tăng cường. Trong Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, trang 1051–1062, Online. Association for Computational Linguistics.

Niklas Muennighoff, Thomas Wang, Lintang Sutawika, Adam Roberts, Stella Biderman, Teven Le Scao, M Saiful Bari, Sheng Shen, Zheng-Xin Yong, Hailey Schoelkopf, Xiangru Tang, Dragomir Radev, Alham Fikri Aji, Khalid Almubarak, Samuel Albanie, Zaid Alyafeai, Albert Webson, Edward Raff, và Colin Raffel. 2023. Tổng quát hóa đa ngôn ngữ thông qua tinh chỉnh đa nhiệm vụ.

OpenAI. 2023. Chatgpt (phiên bản 23 tháng 3) [mô hình ngôn ngữ lớn].

Lin Pan, Chung-Wei Hang, Haode Qi, Abhishek Shah, Saloni Potdar, và Mo Yu. 2021. Căn chỉnh hậu tiền huấn luyện BERT đa ngôn ngữ. Trong Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, trang 210–219, Online. Association for Computational Linguistics.

Matt Post. 2018. Lời kêu gọi rõ ràng trong báo cáo điểm BLEU. Trong Proceedings of the Third Conference on Machine Translation: Research Papers, trang 186–191, Brussels, Belgium. Association for Computational Linguistics.

Ricardo Rei, José G. C. de Souza, Duarte Alves, Chrysoula Zerva, Ana C Farinha, Taisiya

--- TRANG 14 ---
Glushkova, Alon Lavie, Luisa Coheur, và André F. T. Martins. 2022. COMET-22: Bài nộp Unbabel-IST 2022 cho nhiệm vụ chia sẻ metrics. Trong Proceedings of the Seventh Conference on Machine Translation (WMT), trang 578–585, Abu Dhabi, United Arab Emirates (Hybrid). Association for Computational Linguistics.

Teven Le Scao, Angela Fan, Christopher Akiki, Ellie Pavlick, Suzana Ilić, Daniel Hesslow, Roman Castagné, Alexandra Sasha Luccioni, François Yvon, Matthias Gallé, et al. 2022. BLOOM: Một mô hình ngôn ngữ đa ngôn ngữ mở 176B-tham số. arXiv preprint arXiv:2211.05100v4.

Holger Schwenk, Vishrav Chaudhary, Shuo Sun, Hongyu Gong, và Francisco Guzmán. 2021. WikiMatrix: Khai thác 135M câu song song trong 1620 cặp ngôn ngữ từ Wikipedia. Trong Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, trang 1351–1361, Online. Association for Computational Linguistics.

Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy Liang, và Tatsunori B. Hashimoto. 2023. Stanford Alpaca: Một mô hình LLaMA tuân theo hướng dẫn. https://github.com/tatsu-lab/stanford_alpaca.

Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothee Lacroix, Baptiste Roziere, Naman Goyal, Eric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave, và Guillaume Lample. 2023. LLaMA: Các mô hình ngôn ngữ nền tảng mở và hiệu quả. CoRR, cs.CL/2302.13971v1.

David Vilar, Markus Freitag, Colin Cherry, Jiaming Luo, Viresh Ratnakar, và George Foster. 2023. Nhắc nhở PaLM cho dịch thuật: Đánh giá chiến lược và hiệu suất. Trong Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), trang 15406–15427, Toronto, Canada. Association for Computational Linguistics.

Jason Wei, Maarten Bosma, Vincent Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du,

Hình 7: So sánh mFTI với các mô hình dịch máy có giám sát thông thường. Hiệu suất được đánh giá bằng COMET.

Andrew M. Dai, và Quoc V Le. 2022. Các mô hình ngôn ngữ được tinh chỉnh là những người học zero-shot. Trong International Conference on Learning Representations.

Jian Yang, Yuwei Yin, Shuming Ma, Haoyang Huang, Dongdong Zhang, Zhoujun Li, và Furu Wei. 2021. Thỏa thuận đa ngôn ngữ cho dịch máy neural đa ngôn ngữ. Trong Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers), trang 233–239, Online. Association for Computational Linguistics.

Biao Zhang, Barry Haddow, và Alexandra Birch. 2023. Nhắc nhở mô hình ngôn ngữ lớn cho dịch máy: Một nghiên cứu tình huống. CoRR, cs.CL/2301.07069v1.

Biao Zhang, Philip Williams, Ivan Titov, và Rico Sennrich. 2020. Cải thiện dịch máy neural đa ngôn ngữ khối lượng lớn và dịch thuật zero-shot. Trong Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, trang 1628–1639, Online. Association for Computational Linguistics.

Wenhao Zhu, Hongyi Liu, Qingxiu Dong, Jingjing Xu, Lingpeng Kong, Jiajun Chen, Lei Li, và Shujian Huang. 2023. Dịch máy đa ngôn ngữ với các mô hình ngôn ngữ lớn: Kết quả thực nghiệm và phân tích. CoRR, cs.CL/2304.04675v2.

--- TRANG 15 ---
BLOOM-7B và LLaMA-7B XGLM-7.5B
Phương pháp Siêu tham số Giá trị Giá trị
LoRA Các module LoRA query, key, value query, key, value
hạng 4 4
hệ số tỷ lệ 32 32
dropout 0.1 0.1
tốc độ học 5e-5 5e-4
kích thước batch 80 80
bước huấn luyện 5000 5000
tần suất đánh giá 500 500
Tinh chỉnh đầy đủ tốc độ học 1e-5 5e-6
kích thước batch 80 80
bước huấn luyện 2500 2000
tần suất đánh giá 250 250

Bảng 7: Cấu hình siêu tham số của LoRA và Tinh chỉnh đầy đủ trong LLMs

Phụ lục

A Kết quả đầy đủ

Bảng 8 cho thấy tất cả 156 kết quả cặp ngôn ngữ của ICL 8-shot và mFTI trên XGLM, được đánh giá bằng cả BLEU và COMET.

B Chi tiết Huấn luyện và Đánh giá của mfti-156 trong các LLMs khác nhau

Phân bố corpus tiền huấn luyện khác nhau giữa các LLMs khác nhau, do đó chúng tôi áp dụng các siêu tham số đa dạng trong Bảng 7. Hơn nữa, chúng tôi tiến hành đánh giá trên LLMs tại các bước thường xuyên (250 cho Tinh chỉnh đầy đủ và 500 cho Lora) trong giai đoạn huấn luyện, chọn kết quả hoạt động tốt nhất cuối cùng.

C So sánh mFTI và các mô hình dịch máy có giám sát được đánh giá bằng COMET

Chúng tôi trình bày so sánh mFTI và các mô hình MT có giám sát được đánh giá bằng COMET trong Hình 7. Có thể thấy rằng khi được đánh giá bằng COMET, hiệu suất của mFTI có thể so sánh với M2M-1.2B, nhưng vẫn kém hơn đáng kể NLLB-3B.

D Các cặp ngôn ngữ bổ sung cho mFTI

Chúng tôi xây dựng các cặp ngôn ngữ bổ sung trong Phần 4.3 từ 17 ngôn ngữ khác được bao phủ trong corpus tiền huấn luyện của XGLM, bao gồm tiếng Tây Ban Nha, tiếng Hy Lạp, tiếng Bồ Đào Nha, tiếng Nhật, tiếng Việt, tiếng Urdu, tiếng Thái, tiếng Thổ Nhĩ Kỳ, tiếng Telugu, tiếng Ý, tiếng Haiti, Creole, tiếng Basque, tiếng Indonesia, tiếng Estonia và tiếng Bengal.

--- TRANG 16 ---
[Bảng 8 với các kết quả chi tiết về hiệu suất dịch thuật được giữ nguyên do kích thước lớn và tính chất bảng biểu]

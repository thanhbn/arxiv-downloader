# Phân tích việc Học dịch thuật trong Ngữ cảnh của các mô hình GPT

Vikas Raunak Hany Hassan Awadalla Arul Menezes
Microsoft Azure AI
Redmond, Washington
{viraunak,hanyh,arulm}@microsoft.com

Tóm tắt
Hầu hết các nghiên cứu gần đây về việc tận dụng các Mô hình Ngôn ngữ Lớn (LLMs) như GPT-3 cho Dịch máy (MT) đều tập trung vào việc lựa chọn các mẫu few-shot cho việc nhắc nhở. Trong nghiên cứu này, chúng tôi cố gắng hiểu rõ hơn vai trò của các thuộc tính minh chứng trong việc học dịch thuật trong ngữ cảnh thông qua các nhiễu loạn của các minh chứng chất lượng cao, thuộc miền cụ thể. Chúng tôi phát hiện rằng việc nhiễu loạn bất đối xứng các ánh xạ nguồn-đích cho kết quả rất khác nhau. Chúng tôi chỉ ra rằng việc nhiễu loạn phía nguồn có tác động bất ngờ là rất ít, trong khi nhiễu loạn đích có thể giảm đáng kể chất lượng dịch thuật, cho thấy rằng phân phối văn bản đầu ra cung cấp tín hiệu học tập quan trọng nhất trong quá trình học dịch thuật trong ngữ cảnh. Chúng tôi đề xuất một phương pháp có tên Zero-Shot-Context để thêm tín hiệu này một cách tự động trong việc nhắc nhở Zero-Shot. Chúng tôi chứng minh rằng nó cải thiện hiệu suất dịch thuật zero-shot của GPT-3, thậm chí làm cho nó có thể cạnh tranh với các bản dịch được nhắc nhở few-shot.

1 Giới thiệu
Các nghiên cứu gần đây đã đặt câu hỏi về tầm quan trọng của tính chính xác của các minh chứng trong việc nhắc nhở ở các Mô hình Ngôn ngữ Lớn (LLMs) (Min et al., 2022). Một giả thuyết chính là khả năng zero-shot tiềm ẩn của LLMs có thể cao hơn đáng kể so với khả năng zero-shot quan sát được của chúng đối với một loạt các tác vụ (Min et al., 2022; Kojima et al., 2022). Một cách để kích thích hiệu suất zero-shot cao hơn là xác định vai trò của các thuộc tính minh chứng đối với hiệu suất tác vụ và sau đó mô phỏng các tín hiệu học tập trong ngữ cảnh như vậy theo cách zero-shot. Tuy nhiên, việc thực hiện mục tiêu này phụ thuộc vào việc phân tích một cách rõ ràng vai trò của các thuộc tính minh chứng khác nhau (định dạng, đầu vào, đầu ra, ánh xạ đầu vào-đầu ra) đối với hiệu suất tác vụ trong việc học few-shot trong ngữ cảnh. Trong nghiên cứu này, chúng tôi khám phá những câu hỏi này cho tác vụ Dịch máy (MT). Hướng nghiên cứu của chúng tôi trực giao với việc tìm kiếm các mẫu hữu ích nhất cho việc học few-shot, một chủ đề đã nhận được sự chú ý đáng kể để kích thích những bản dịch tốt hơn từ LLMs (Vilar et al., 2022; Agrawal et al., 2022). Những đóng góp của chúng tôi là:

1. Chúng tôi khám phá vai trò của các thuộc tính minh chứng trong việc học dịch thuật trong ngữ cảnh ở họ LLMs GPT, thông qua các nhiễu loạn của các ánh xạ đầu vào-đầu ra (nguồn-đích). Chúng tôi chỉ ra rằng phân phối văn bản đích là yếu tố quan trọng nhất trong các minh chứng, trong khi phân phối văn bản nguồn cung cấp tín hiệu học tập không quan trọng.

2. Dựa trên các phát hiện của chúng tôi, chúng tôi đề xuất nhắc nhở Zero-Shot-Context, cái mà cố gắng tự động cung cấp tín hiệu học tập tương ứng với phân phối văn bản đích mà không cần bất kỳ ví dụ nguồn-đích nào. Điều này cải thiện đáng kể hiệu suất zero-shot của GPT-3, thậm chí làm cho nó có thể cạnh tranh với nhắc nhở few-shot.

2 Nghiên cứu liên quan
Nghiên cứu của chúng tôi liên quan đến hai chủ đề chính, đó là nhắc nhở LLMs cho dịch thuật và phân tích việc học trong ngữ cảnh ở LLMs. Trong phần này, chúng tôi đặt nghiên cứu của mình trong bối cảnh của hai chủ đề này.

Nhắc nhở LLM cho MT: LLMs đã đạt được hiệu suất dịch thuật gần với công nghệ hiện đại dưới nhắc nhở few-shot (Hendy et al., 2023; Lin et al., 2022). Hầu hết các nghiên cứu về nhắc nhở trong MT đều tập trung vào việc lựa chọn các thực thể huấn luyện hoặc phát triển để được sử dụng làm ví dụ trong quá trình nhắc nhở. Vilar et al. (2022) thực nghiệm trên PaLM (Chowdhery et al., 2022) và phát hiện rằng chất lượng của các ví dụ là yếu tố quan trọng nhất trong hiệu suất nhắc nhở few-shot. Agrawal et al. (2022) thực nghiệm với XGLM (Lin et al., 2021) và báo cáo rằng chất lượng dịch thuật và miền của các ví dụ là có hệ quả. Nghiên cứu của chúng tôi xây dựng trên những nghiên cứu này với một mục tiêu khác, ở chỗ chúng tôi không khám phá việc lựa chọn các ví dụ, mà áp dụng các nhiễu loạn trên các ví dụ chất lượng cao, thuộc miền cụ thể để xác định tốt hơn vai trò của các thuộc tính minh chứng nhất định cho việc học dịch thuật trong ngữ cảnh.

Phân tích việc Học trong Ngữ cảnh: Nghiên cứu lý thuyết và thực nghiệm về việc học trong ngữ cảnh là một nỗ lực nghiên cứu đang tiếp tục (Xie et al., 2021; von Oswald et al., 2022; Akyürek et al., 2022; Dai et al., 2022). Min et al. (2022) chứng minh rằng tính chính xác của nhãn trong các minh chứng có tầm quan trọng hạn chế đối với các tác vụ phân loại tập mở, trong khi Yoo et al. (2022) chỉ ra rằng các nhãn phủ định có quan trọng. Các thí nghiệm của chúng tôi khác với những nghiên cứu này cả về lựa chọn tác vụ (dịch thuật, có không gian đầu ra theo cấp số nhân) cũng như về các loại nhiễu loạn được áp dụng lên các minh chứng.

3 Vai trò của các Thuộc tính Minh chứng
Để tạo ra đầu ra cho một tác vụ cụ thể, LLMs thường được nhắc nhở với các minh chứng (các ví dụ đầu vào-đầu ra liên quan đến tác vụ cụ thể) được nối thêm với đầu vào kiểm tra. Tương tự như Min et al. (2022), chúng tôi cho rằng tồn tại bốn khía cạnh của các minh chứng về tác vụ dịch thuật cung cấp tín hiệu học tập: ánh xạ đầu vào-đầu ra, phân phối văn bản đầu vào, phân phối văn bản đầu ra và định dạng. Trong phần này, chúng tôi tiến hành một cuộc điều tra thực nghiệm về cách LLMs như GPT-3 tận dụng các minh chứng được cung cấp cho chúng cho tác vụ dịch thuật bằng cách nhiễu loạn các ánh xạ đầu vào-đầu ra (nguồn-đích) được cung cấp trong quá trình nhắc nhở. Thông qua những thí nghiệm này, chúng tôi hy vọng so sánh tầm quan trọng của ba thuộc tính minh chứng chính - phân phối văn bản đầu vào, phân phối văn bản đầu ra và ánh xạ của chúng cho dịch thuật.

Mô hình: Trong phần này, chúng tôi chủ yếu báo cáo kết quả cho text-davinci-002¹, một trong những mô hình LLM có khả năng nhất có thể truy cập công khai (Liang et al., 2022). Chúng tôi cũng điều tra tính chính xác của các quan sát của chúng tôi với text-davinci-001 và text-curie-001, hai phiên bản LLM trước đó trong họ GPT cũng như text-davinci-003 gần đây hơn.

Bộ dữ liệu: Chúng tôi thực nghiệm với các bộ dữ liệu tác vụ Dịch Tin tức WMT'21 (Barrault et al., 2021), cho bốn cặp ngôn ngữ sau: Anh-Đức (En-De), Đức-Anh (De-En), Anh-Nga (En-Ru) và Nga-Anh (Ru-En). Trên mỗi bộ dữ liệu này, text-davinci-002 đạt được hiệu suất rất cạnh tranh với mô hình NMT chiến thắng WMT-21 (Tran et al., 2021), với tám minh chứng (k = 8 trong nhắc nhở k-shot). Chúng tôi liệt kê hiệu suất tập kiểm tra đầy đủ với text-davinci-002 và text-davinci-003 cho k = 8 trong Bảng 2, trong khi các thí nghiệm nhiễu loạn được báo cáo trên 100 mẫu ngẫu nhiên từ các tập kiểm tra trong mỗi trường hợp.

Phương pháp    En-De  De-En  Ru-En  En-Ru
Facebook-WMT-21  39.36  39.88  35.25  46.41
davinci-002 (k=8)  39.57  40.28  35.67  39.06
davinci-003 (k=8)  40.31  41.31  36.03  41.82

Bảng 2: Điểm COMET-QE trên Tập Kiểm tra WMT-21: Cả các bản dịch từ hệ thống chiến thắng WMT-21 (Tran et al., 2021) cũng như các bản dịch GPT đều được thu thập thông qua giải mã tham lam.

Chi tiết Nhắc nhở: Vilar et al. (2022) báo cáo rằng việc lựa chọn định dạng là không quan trọng đối với nhắc nhở few-shot trên tác vụ dịch thuật. Do đó, chúng tôi sử dụng nhắc nhở tiêu chuẩn được sử dụng cho MT trong các nghiên cứu trước, cụ thể là [Source]: ABC (\n) [Target]: DEF, nơi Source (ví dụ: English) và Target (ví dụ: German) đại diện cho tên ngôn ngữ. Hơn nữa, chúng tôi sử dụng các cặp câu chất lượng cao, thuộc miền cụ thể được lấy mẫu từ tập phát triển cho nhắc nhở few-shot.

Đánh giá: Để giảm thiểu sự thiên vị tham chiếu trong đánh giá, điều đã được chỉ ra là có hại trong việc ước tính chất lượng đầu ra LLM trong các tác vụ chuyển đổi chuỗi liên quan (Goyal et al., 2022; Garcia et al., 2023; Raunak et al., 2023), chúng tôi sử dụng một thước đo Ước lượng Chất lượng (Fomicheva et al., 2020) tiên tiến có tên COMET-QE (Rei et al., 2020) cho đánh giá chất lượng. Hơn nữa, một lưu ý của việc sử dụng thước đo không tham chiếu là nó phân bổ điểm cao cho một bản dịch nếu nó cùng ngôn ngữ với câu nguồn, tức là nó không phạt các lỗi sao chép trong dịch thuật. Để giảm thiểu sự thiếu sót trong đánh giá này, chúng tôi sử dụng một bộ phân loại định danh ngôn ngữ (Joulin et al., 2017) và đặt bản dịch thành rỗng nếu bản dịch được tạo ra cùng ngôn ngữ với nguồn.

Thí nghiệm 1: Chúng tôi áp dụng bốn nhiễu loạn cho các minh chứng được sử dụng trong nhắc nhở. Bảng 1 liệt kê bốn nhiễu loạn với các chuỗi nguồn-đích trừu tượng: Shuffled Targets (ST) ngẫu nhiên hóa các ánh xạ giữa nguồn và đích trong nhắc nhở, Jumbled Source (JS) ngẫu nhiên hóa vị trí của các từ trong câu nguồn, Jumbled Ref (JT) ngẫu nhiên hóa vị trí của các từ trong câu đích và Reversed Ref (RT) đảo ngược thứ tự các từ trong câu đích. Trong số những nhiễu loạn này, ST tác động đến cả không gian đầu vào và đầu ra một cách đối xứng, trong khi các nhiễu loạn khác (JS, JT và RT) chỉ làm nhiễu loạn một trong các không gian đầu vào/đầu ra.

Chân lý cơ bản | Đích bị xáo trộn | Nguồn bị xáo trộn | Đích bị xáo trộn | Đích bị đảo ngược
English: A B C | English: A B C | English: B A C | English: A B C | English: A B C
German: D E F | German: X Y Z | German: D E F | German: E D F | German: F E D
English: U V W | English: U V W | English: U W V | English: U V W | English: U V W
German: X Y Z | German: D E F | German: X Y Z | German: Y Z X | German: Z Y X

Bảng 1: Các Nhiễu loạn Được Áp dụng: Bốn loại nhiễu loạn (được hiển thị ở đây như được áp dụng trên các chuỗi ví dụ nguồn-đích trừu tượng) thao tác các thuộc tính minh chứng khác nhau. Ví dụ, trong khi Jumbled Source và Jumbled Target đều làm hỏng ánh xạ nguồn-đích, chúng sửa đổi các tín hiệu học tập khác nhau trong việc học trong ngữ cảnh.

Kết quả: Kết quả của việc áp dụng những nhiễu loạn này trên En-De được trình bày trong Hình 1, qua số lượng minh chứng khác nhau (k = 1, 2, 4, 8). Kết quả cho thấy rằng trong khi ST và JT đều làm gián đoạn đáng kể ánh xạ nguồn-đích trong các minh chứng, chúng có tác động rất khác nhau. Chất lượng dịch thuật giảm đi một lượng lớn đối với JT, một tác động trở nên lớn hơn với k tăng, ví dụ, đối với nhiễu loạn JT tại k = 8, chất lượng dịch thuật kém hơn đáng kể. Mặt khác, JS tạo ra rất ít hoặc không có tác động đến chất lượng dịch thuật. Hơn nữa, do bản chất của nhiễu loạn, ST trở nên gây rối hơn ở các giá trị k cao hơn, trong khi không có tác động đối với k = 1.

Thí nghiệm 2: Chúng tôi lặp lại thí nghiệm tương tự như trên (Thí nghiệm 1) với bốn cặp ngôn ngữ khác nhau từ WMT-21 và text-davinci-002.

Kết quả: Kết quả được báo cáo trong Hình 2. Chúng tôi thấy rằng các xu hướng tương tự như thí nghiệm đầu tiên (Hình 1). Qua các cặp ngôn ngữ, JS và JT có tác động bất đối xứng đến chất lượng dịch thuật, cho thấy rằng trong mỗi trường hợp, tín hiệu học tập quan trọng đến từ phân phối văn bản đích, trong khi phân phối văn bản nguồn là một yếu tố không quan trọng đối với chất lượng dịch thuật đầu ra.

Thí nghiệm 3: Chúng tôi lặp lại Thí nghiệm 2, bằng cách giữ cặp ngôn ngữ cố định là En-De và thay đổi LLMs. Chúng tôi báo cáo kết quả trong Hình 3 cho ba mô hình khác từ họ GPT, cụ thể là text-curie-001, text-davinci-002 và text-davinci-003.

Kết quả: Chúng tôi thấy rằng qua các mô hình khác nhau, JS và JT có tác động bất đối xứng đến chất lượng dịch thuật, phù hợp với hai thí nghiệm trước đó.

Phân tích: So với Min et al. (2022), nơi việc ngẫu nhiên hóa ánh xạ đầu vào-đầu ra trong các minh chứng dẫn đến hiệu suất tốt hơn so với không có minh chứng (nhắc nhở zero-shot) đối với các tác vụ phân loại tập mở, kết quả của chúng tôi khá khác. Chúng tôi thấy rằng tùy thuộc vào loại nhiễu loạn, kết quả học dịch thuật trong ngữ cảnh có thể rất khác nhau ngay cả khi tất cả các nhiễu loạn đều phá vỡ ánh xạ đầu vào-đầu ra chính xác. Đối với một số nhiễu loạn (ví dụ: JT và RT), chất lượng dịch thuật kém hơn nhiều so với zero-shot. Để dung hòa những kết quả này, chúng tôi giả thuyết rằng sự khác biệt phát sinh từ độ phức tạp tăng lên của tìm kiếm tự hồi quy trong trường hợp dịch thuật, tức là, một đặc tả rõ ràng về không gian đầu ra trong các minh chứng trở nên quan trọng hơn nhiều để hạn chế không gian tìm kiếm.

Hơn nữa, kết quả ST trong Hình 2 & 3 cho thấy rằng ánh xạ nguồn-đích cũng là một thuộc tính minh chứng quan trọng, một thực tế phù hợp với các kết quả trước đó nhấn mạnh tầm quan trọng của chất lượng ví dụ (Vilar et al., 2022; Agrawal et al., 2022). Tuy nhiên, chúng tôi chỉ ra rằng đó không phải là tín hiệu học tập chính trong việc học dịch thuật trong ngữ cảnh và ngay cả trong đó, thứ tự từ nguồn cũng ít quan trọng, cho thấy rằng chỉ cần một xấp xỉ của phân phối văn bản đầu vào là đủ để học hiệu quả trong ngữ cảnh.

Tính tổng quát của Các phát hiện: Chúng tôi cũng tiến hành thí nghiệm trên gpt-3.5-turbo-instruct và gpt-3.5-turbo-instruct-0914, hai LLM gần đây hơn trong họ GPT. Với gpt-3.5-turbo-instruct trên En-De, không có nhiễu loạn (None trong các biểu đồ) đạt được điểm COMET-QE là 34.21, nhiễu loạn JS đạt điểm 35.20 và nhiễu loạn JT đạt được điểm 25.45. Tương tự, với gpt-3.5-turbo-instruct-0914 trên En-De, không có nhiễu loạn đạt điểm COMET-QE là 33.64, nhiễu loạn JS đạt điểm 34.35 và nhiễu loạn JT đạt được điểm 24.42. Hành vi quan sát này cũng không phụ thuộc vào việc lựa chọn thước đo chất lượng MT: với COMET-KIWI (thước đo QE tiên tiến nhất trong WMT-22 Quality Estimation Shared Task (Rei et al., 2022)), không có nhiễu loạn (None trong các biểu đồ) với gpt-3.5-turbo-instruct đạt điểm 83.75, nhiễu loạn JS đạt điểm 83.94 và nhiễu loạn JT đạt được điểm 73.26. Tương tự, với COMET-KIWI gpt-3.5-turbo-instruct-0914 đạt điểm 83.94, nhiễu loạn JS đạt điểm 83.85 và nhiễu loạn JT đạt được điểm 72.72. Những kết quả này chỉ ra sự vững chắc của các phát hiện của chúng tôi.

Ý nghĩa: Các phát hiện của chúng tôi cho thấy rằng dữ liệu đại diện cho không gian đầu ra có thể là thuộc tính quan trọng nhất trong các minh chứng cho việc học dịch thuật trong ngữ cảnh. Ngoài việc gợi ý một sự vững chắc tích hợp đối với các nhiễu loạn ở phía nguồn, kết quả này chỉ ra những hướng khám phá thú vị cho việc lựa chọn dữ liệu để nhắc nhở, ví dụ, rằng dữ liệu gốc-đích có thể hữu ích hơn làm ví dụ minh chứng so với dữ liệu gốc-nguồn. Chúng tôi để lại những câu hỏi như vậy cho nghiên cứu tương lai.

4 Zero-Shot-Context cho Dịch thuật
Trước đây, chúng tôi đã chứng minh rằng thuộc tính minh chứng quan trọng nhất cho việc học dịch thuật trong ngữ cảnh là phân phối văn bản đầu ra. Trong phần này, chúng tôi trình bày một phương pháp cung cấp tín hiệu học tập này theo cách zero-shot. Thí nghiệm của chúng tôi ở đây đại diện cho nghịch đảo của các thí nghiệm trong phần 3, tức là, ở đây chúng tôi thêm một tín hiệu học tập hữu ích vào nhắc nhở zero-shot, thay vì loại bỏ các tín hiệu học tập khỏi nhắc nhở few-shot để đánh giá tầm quan trọng của chúng. Chúng tôi trình bày một phương pháp có tên 'Zero-Shot-Context' và chỉ ra rằng nó cải thiện đáng kể hiệu suất zero-shot của GPT-3, kích thích hiệu suất có thể cạnh tranh ngay cả với nhắc nhở few-shot.

Lưu ý rằng phương pháp này là một ví dụ về việc thêm một tín hiệu cụ thể trong nhắc nhở zero-shot và có thể có nhiều cách để thêm tín hiệu như vậy để tăng cường hiệu suất zero-shot bao gồm điều chỉnh tinh trực tiếp hướng dẫn trên tác vụ dịch thuật. Tuy nhiên, chúng tôi để lại một phân tích kỹ lưỡng về việc cải thiện hiệu suất dịch thuật zero-shot bằng cách thêm các tín hiệu liên quan từ các minh chứng cho nghiên cứu tương lai và chỉ tập trung khám phá giả thuyết chính của chúng tôi.

Phương pháp đề xuất: Chúng tôi đề xuất một phương pháp nhắc nhở zero-shot mới có tên Zero-Shot-Context (Hình 4), tự động tạo ra tín hiệu học tập đặc tả không gian đầu ra từ chính LLM (Context) và sử dụng nó để điều kiện hóa việc dịch thuật.

Thí nghiệm và Kết quả: Trong Bảng 3, chúng tôi so sánh Zero-Shot-Context với nhắc nhở Zero-Shot, cũng như nhắc nhở few-shot (cho k=1, 2, 4) với các ví dụ chất lượng cao, thuộc miền cụ thể được lấy mẫu từ tập phát triển, trên tập kiểm tra En-De WMT-21 với text-davinci-002. Kết quả cho thấy rằng Zero-Shot-Context cải thiện đáng kể chất lượng dịch thuật Zero-Shot được đo bằng COMET-QE (CQE). Lưu ý rằng những cải thiện này không thể nhìn thấy trong đánh giá dựa trên tham chiếu với BLEU và ChrF và những hạn chế của những thước đo này đã được chỉ ra trong tài liệu (Freitag et al., 2022). Bảng 4 trình bày một so sánh trên tập kiểm tra WMT-21 En-Ru.

Phương pháp      CQE ↑  BLEU ↑  ChrF ↑  TER ↓
Zero-Shot        32.29  22.6    54.3    71.4
Zero-Shot-Context 37.65  23.1    55.4    68.5
Few Shot (k=1)   39.92  22.4    54.1    71.8
Few Shot (k=2)   39.04  24.7    56.6    64.8
Few Shot (k=4)   40.36  24.0    55.7    65.4

Bảng 3: Zero-Shot-Context vs Cơ sở trên WMT-21 En-De: Zero-Shot-Context cải thiện đáng kể so với Dịch thuật Zero-Shot, đạt được +5 điểm QE về chất lượng.

Phương pháp      CQE ↑  BLEU ↑  ChrF ↑  TER ↓
Zero-Shot        35.39  19.8    49.4    74.3
Zero-Shot-Context 40.67  18.8    48.7    75.6
Few Shot (k=1)   37.92  20.5    50.1    72.3
Few Shot (k=2)   39.35  19.3    50.0    72.7
Few Shot (k=4)   39.25  20.2    50.1    72.3

Bảng 4: Zero-Shot-Context vs Cơ sở trên WMT-21 En-Ru: Zero-Shot-Context cải thiện đáng kể so với Zero-Shot và thậm chí có thể cạnh tranh với các bản dịch few-shot.

Phân tích về Zero-Shot Context: Chúng tôi xem xét thí nghiệm sau: chúng tôi chọn một câu phía đích ngẫu nhiên từ tập phát triển và thay thế đầu ra của bước Context-Generation bằng câu phía đích ngẫu nhiên. Lý tưởng nhất, một câu phía đích thuộc miền, chất lượng cao cũng nên có thể cung cấp tín hiệu học tập về phân phối văn bản đầu ra. Chúng tôi thấy rằng đây thực sự là trường hợp, và việc đơn giản thay thế bước tạo ngữ cảnh bằng câu phía đích ngẫu nhiên cũng cải thiện hiệu suất zero-shot, đạt được điểm COMET-QE 36.10 cho tập kiểm tra WMT-21 En-De và điểm COMET-QE 37.86 cho WMT-21 En-Ru. Tuy nhiên, những điểm này thấp hơn Zero-Shot-Context, cho thấy rằng bản chất ngữ cảnh của Zero-Shot-Context cũng quan trọng.

Phân tích sâu hơn: Các phát hiện của chúng tôi chỉ ra rằng hiệu suất GPT-3 zero-shot tiềm ẩn cho dịch thuật thực sự có thể cao hơn so với hiện tại được báo cáo và có thể tận dụng tính toán trực tiếp để cải thiện hiệu suất dịch thuật LLM thay vì lấy hoặc lựa chọn ví dụ thủ công. Cụ thể, chúng tôi chỉ ra rằng việc thêm đơn giản một tín hiệu liên quan đến không gian đầu ra đã cải thiện hiệu suất zero-shot của text-davinci-002, một bước hữu ích hướng tới việc sử dụng zero-shot LLMs tốt hơn cho dịch thuật. Như đã chỉ ra trong Bawden và Yvon (2023), việc tạo ra các bản dịch zero-shot thường gặp phải vấn đề đầu ra bằng ngôn ngữ sai và chúng tôi thấy rằng Zero-Shot-Context giảm thiểu đáng kể điều này, dẫn đến hiệu suất tốt hơn. Tuy nhiên, phân tích nghiêm ngặt hơn về hiện tượng này qua các LLM khác nhau bị cản trở bởi thực tế là chúng tôi không có quyền truy cập vào bộ dữ liệu huấn luyện hoặc điều chỉnh tinh hướng dẫn được sử dụng cho các LLM tiên tiến cơ bản.

5 Tóm tắt và Kết luận
Chúng tôi đã phân tích tầm quan trọng tương đối của các thuộc tính minh chứng như tín hiệu học tập trong việc học dịch thuật few-shot trong ngữ cảnh ở LLMs từ họ GPT. Chúng tôi chứng minh rằng tín hiệu học tập quan trọng đến từ phân phối văn bản đầu ra, tiếp theo là ánh xạ đầu vào-đầu ra, trong khi phân phối văn bản đầu vào ít quan trọng. Chúng tôi sử dụng phát hiện này để đề xuất Zero-Shot-Context, một phương pháp cố gắng tự động tạo ra tín hiệu học tập quan trọng. Zero-Shot-Context cải thiện đáng kể chất lượng dịch thuật zero-shot trong GPT-3, xác nhận thêm các phát hiện của chúng tôi. Chúng tôi hy vọng rằng nghiên cứu của chúng tôi có thể phục vụ như một đóng góp hữu ích hướng tới hiểu biết tốt hơn về việc học dịch thuật trong ngữ cảnh ở LLMs.

6 Hạn chế
Nghiên cứu của chúng tôi thực nghiệm với các ví dụ chất lượng cao, thuộc miền cụ thể cho nhắc nhở few-shot. Có thể hình dung rằng các nhiễu loạn có thể có tác động khác nhau trên các ví dụ với chất lượng khác nhau. Ngoài ra, trong khi phương pháp zero-shot được đề xuất của chúng tôi không tiêu thụ bất kỳ ví dụ thủ công nào, nó gặp phải hạn chế là nó liên quan đến hai lần chuyển qua một LLM. Trong khi điều này được giảm thiểu bởi phương pháp được trình bày như một phân tích, chúng tôi tin rằng các phương pháp đơn giản hơn để thêm tín hiệu minh chứng liên quan có thể được suy ra bằng cách tính toán trước ngữ cảnh phía đích đơn lẻ một lần cho toàn bộ tập kiểm tra, một đề xuất mà chúng tôi không điều tra.

Tài liệu tham khảo
Sweta Agrawal, Chunting Zhou, Mike Lewis, Luke Zettlemoyer, và Marjan Ghazvininejad. 2022. In-context examples selection for machine translation.

Ekin Akyürek, Dale Schuurmans, Jacob Andreas, Tengyu Ma, và Denny Zhou. 2022. What learning algorithm is in-context learning? investigations with linear models.

Loic Barrault, Ondrej Bojar, Fethi Bougares, Rajen Chatterjee, Marta R. Costa-jussa, Christian Federmann, Mark Fishel, Alexander Fraser, Markus Freitag, Yvette Graham, Roman Grundkiewicz, Paco Guzman, Barry Haddow, Matthias Huck, Antonio Jimeno Yepes, Philipp Koehn, Tom Kocmi, Andre Martins, Makoto Morishita, và Christof Monz, biên tập. 2021. Proceedings of the Sixth Conference on Machine Translation. Association for Computational Linguistics, Online.

Rachel Bawden và François Yvon. 2023. Investigating the translation performance of a large multilingual language model: the case of BLOOM. In Proceedings of the 24th Annual Conference of the European Association for Machine Translation, trang 157–170, Tampere, Finland. European Association for Machine Translation.

Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, et al. 2022. Palm: Scaling language modeling with pathways.

Damai Dai, Yutao Sun, Li Dong, Yaru Hao, Zhifang Sui, và Furu Wei. 2022. Why can gpt learn in-context? language models secretly perform gradient descent as meta optimizers. arXiv preprint arXiv:2212.10559.

Marina Fomicheva, Shuo Sun, Lisa Yankovskaya, Frédéric Blain, Francisco Guzmán, Mark Fishel, Nikolaos Aletras, Vishrav Chaudhary, và Lucia Specia. 2020. Unsupervised quality estimation for neural machine translation. Transactions of the Association for Computational Linguistics, 8:539–555.

Markus Freitag, Ricardo Rei, Nitika Mathur, Chi-kiu Lo, Craig Stewart, Eleftherios Avramidis, Tom Kocmi, George Foster, Alon Lavie, và André F. T. Martins. 2022. Results of WMT22 metrics shared task: Stop using BLEU – neural metrics are better and more robust. In Proceedings of the Seventh Conference on Machine Translation (WMT), trang 46–68, Abu Dhabi, United Arab Emirates (Hybrid). Association for Computational Linguistics.

Xavier Garcia, Yamini Bansal, Colin Cherry, George Foster, Maxim Krikun, Melvin Johnson, và Orhan Firat. 2023. The unreasonable effectiveness of few-shot learning for machine translation. In Proceedings of the 40th International Conference on Machine Learning, ICML'23. JMLR.org.

Tanya Goyal, Junyi Jessy Li, và Greg Durrett. 2022. News summarization and evaluation in the era of gpt-3.

Amr Hendy, Mohamed Abdelrehim, Amr Sharaf, Vikas Raunak, Mohamed Gabr, Hitokazu Matsushita, Young Jin Kim, Mohamed Afify, và Hany Hassan Awadalla. 2023. How good are gpt models at machine translation? a comprehensive evaluation.

Armand Joulin, Edouard Grave, Piotr Bojanowski, và Tomas Mikolov. 2017. Bag of tricks for efficient text classification. In Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 2, Short Papers, trang 427–431, Valencia, Spain. Association for Computational Linguistics.

Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, và Yusuke Iwasawa. 2022. Large language models are zero-shot reasoners.

Percy Liang, Rishi Bommasani, Tony Lee, Dimitris Tsipras, Dilara Soylu, Michihiro Yasunaga, Yian Zhang, Deepak Narayanan, Yuhuai Wu, Ananya Kumar, et al. 2022. Holistic evaluation of language models. arXiv preprint arXiv:2211.09110.

Xi Victoria Lin, Todor Mihaylov, Mikel Artetxe, Tianlu Wang, Shuohui Chen, Daniel Simig, Myle Ott, Naman Goyal, Shruti Bhosale, Jingfei Du, Ramakanth Pasunuru, Sam Shleifer, Punit Singh Koura, Vishrav Chaudhary, Brian O'Horo, Jeff Wang, Luke Zettlemoyer, Zornitsa Kozareva, Mona Diab, Veselin Stoyanov, và Xian Li. 2022. Few-shot learning with multilingual generative language models. In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, trang 9019–9052, Abu Dhabi, United Arab Emirates. Association for Computational Linguistics.

Xi Victoria Lin, Todor Mihaylov, Mikel Artetxe, Tianlu Wang, Shuohui Chen, Daniel Simig, Myle Ott, Naman Goyal, Shruti Bhosale, Jingfei Du, et al. 2021. Few-shot learning with multilingual language models. arXiv preprint arXiv:2112.10668.

Sewon Min, Xinxi Lyu, Ari Holtzman, Mikel Artetxe, Mike Lewis, Hannaneh Hajishirzi, và Luke Zettlemoyer. 2022. Rethinking the role of demonstrations: What makes in-context learning work? In EMNLP.

Vikas Raunak, Arul Menezes, Matt Post, và Hany Hassan. 2023. Do GPTs produce less literal translations? In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), trang 1041–1050, Toronto, Canada. Association for Computational Linguistics.

Ricardo Rei, Craig Stewart, Ana C Farinha, và Alon Lavie. 2020. COMET: A neural framework for MT evaluation. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), trang 2685–2702, Online. Association for Computational Linguistics.

Ricardo Rei, Marcos Treviso, Nuno M. Guerreiro, Chrysoula Zerva, Ana C Farinha, Christine Maroti, José G. C. de Souza, Taisiya Glushkova, Duarte Alves, Luisa Coheur, Alon Lavie, và André F. T. Martins. 2022. CometKiwi: IST-unbabel 2022 submission for the quality estimation shared task. In Proceedings of the Seventh Conference on Machine Translation (WMT), trang 634–645, Abu Dhabi, United Arab Emirates (Hybrid). Association for Computational Linguistics.

Chau Tran, Shruti Bhosale, James Cross, Philipp Koehn, Sergey Edunov, và Angela Fan. 2021. Facebook AI's WMT21 news translation task submission. In Proceedings of the Sixth Conference on Machine Translation, trang 205–215, Online. Association for Computational Linguistics.

David Vilar, Markus Freitag, Colin Cherry, Jiaming Luo, Viresh Ratnakar, và George Foster. 2022. Prompting palm for translation: Assessing strategies and performance.

Johannes von Oswald, Eyvind Niklasson, Ettore Randazzo, João Sacramento, Alexander Mordvintsev, Andrey Zhmoginov, và Max Vladymyrov. 2022. Transformers learn in-context by gradient descent.

Sang Michael Xie, Aditi Raghunathan, Percy Liang, và Tengyu Ma. 2021. An explanation of in-context learning as implicit bayesian inference.

Kang Min Yoo, Junyeob Kim, Hyuhng Joon Kim, Hyunsoo Cho, Hwiyeol Jo, Sang-Woo Lee, Sang-goo Lee, và Taeuk Kim. 2022. Ground-truth labels matter: A deeper look into input-label demonstrations. arXiv.

# 2403.19930.pdf
# Đã chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/multilingual/2403.19930.pdf
# Kích thước tệp: 1094368 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Liệu các LLM có phải là Backbone Hiệu quả để Fine-tuning? Một Nghiên cứu Thực nghiệm về các LLM có Giám sát trên Bài toán Khớp Văn bản Ngắn Tiếng Trung
Shulin Liu, Chengcheng Xu, Hao Liu, Tinghao Yu, Tao Yang
Phòng Nền tảng Học máy
Tencent TEG. Bắc Kinh, Trung Quốc
{forestliu, doublecxu, paulhliu, maxwellyu, rigorosyang}@tencent.com
Tóm tắt
Thành công gần đây của các Mô hình Ngôn ngữ Lớn (LLM) đã thu hút sự chú ý đáng kể trong cả học thuật và công nghiệp. Nghiên cứu trước đây về LLM chủ yếu tập trung vào tăng cường hoặc tận dụng khả năng tổng quát hóa của chúng trong các thiết lập zero-shot và few-shot. Tuy nhiên, có rất ít nghiên cứu về việc fine-tuning hiệu quả các LLM cho một nhiệm vụ hiểu ngôn ngữ tự nhiên cụ thể trong các thiết lập có giám sát. Trong nghiên cứu này, chúng tôi tiến hành một phân tích thực nghiệm bằng cách fine-tuning các LLM cho nhiệm vụ khớp văn bản ngắn tiếng Trung. Chúng tôi khám phá các yếu tố khác nhau ảnh hưởng đến hiệu suất khi fine-tuning LLM, bao gồm các phương pháp mô hình hóa nhiệm vụ, định dạng prompt, và định dạng đầu ra.

1 Giới thiệu
Thành công gần đây của các Mô hình Ngôn ngữ Lớn (LLM), chẳng hạn như GPT-3(Brown et al., 2020), LLaMA(Touvron et al., 2023) và PaLM(Chowdhery et al., 2023), đã thu hút sự chú ý đáng kể trong cả học thuật và công nghiệp. Các LLM đã thể hiện khả năng tổng quát hóa đáng kinh ngạc trong các thiết lập zero-shot và few-shot, đặc biệt là trong các nhiệm vụ sinh ngôn ngữ tự nhiên (NLG). Những nỗ lực đáng kể đã được thực hiện để tăng cường và sử dụng những khả năng tổng quát hóa như vậy(Xu et al., 2023; Saad-Falcon et al., 2023; Yun et al., 2023).

Tuy nhiên, đối với các nhiệm vụ hiểu ngôn ngữ tự nhiên (NLU), các LLM zero-shot và few-shot khó có thể đạt được hiệu suất thỏa mãn(Nie et al., 2022; Wei et al., 2023; Li et al., 2023a,b) so với các mô hình nhỏ được fine-tuned (ví dụ: Bert base(Devlin et al., 2018)). Kết quả thực nghiệm của chúng tôi về nhiệm vụ khớp văn bản ngắn tiếng Trung cũng xác nhận hiện tượng này. Như được trình bày trong Mục 3.1, Bert được fine-tuned đạt độ chính xác 84.5% trên corpus BQ(Chen et al., 2018), trong khi GPT-4¹, một trong những LLM thành công nhất, chỉ đạt điểm số độ chính xác 52.9% trong thiết lập zero-shot và 77.9% trong thiết lập few-shot. Có rất ít nghiên cứu về việc điều chỉnh hiệu quả các LLM cho một nhiệm vụ NLU cụ thể trong các thiết lập có giám sát. Trong bài báo này, chúng tôi khám phá các yếu tố khác nhau ảnh hưởng đến hiệu suất của LLM cho nhiệm vụ khớp văn bản ngắn tiếng Trung, bao gồm các phương pháp mô hình hóa nhiệm vụ, định dạng prompt, và định dạng đầu ra.

•Các phương pháp mô hình hóa nhiệm vụ: Trong nghiên cứu này, chúng tôi xem xét tác động của việc mô hình hóa nhiệm vụ này như một nhiệm vụ sinh và một nhiệm vụ phân loại phân biệt, tương ứng. (1) Nhiệm vụ sinh: Các LLM mô hình hóa tất cả các nhiệm vụ một cách thống nhất như các nhiệm vụ sinh. Theo nguyên tắc này, chúng tôi tổ chức cặp câu đã cho thành một văn bản duy nhất làm đầu vào và làm cho mô hình sinh ra nhãn đích (tương đương hoặc không tương đương). (2) Nhiệm vụ phân loại phân biệt: Được thúc đẩy bởi hiệu quả của việc fine-tuning Bert cho khớp văn bản(Chen et al., 2020; Qi et al., 2022), chúng tôi nối cặp văn bản đã cho làm đầu vào, trích xuất các biểu diễn vector từ lớp LLM cuối cùng làm đặc trưng, và thực hiện phân loại nhị phân dựa trên các đặc trưng được trích xuất.

•Định dạng prompt: Thiết kế prompt là rất quan trọng cho các LLM trong các thiết lập zero-shot và few-shot(Gu et al., 2021; Liu et al., 2023). Tuy nhiên, tầm quan trọng của prompt trong các thiết lập có giám sát chưa được khám phá. Trong bài báo này, chúng tôi so sánh hai phong cách prompt hoàn toàn khác nhau. Một là ngắn gọn, trực tiếp nối cặp câu đã cho mà không có bất kỳ giải thích nào về nhiệm vụ đích. Cái khác tổ chức prompt thông qua các hướng dẫn phức tạp, bao gồm không chỉ các câu đã cho mà còn có mô tả chi tiết về nhiệm vụ đích.

•Định dạng đầu ra: Việc kết hợp Chuỗi Suy nghĩ (CoT) vào prompt đã được chứng minh là cải thiện đáng kể hiệu suất trong các nhiệm vụ lý luận và phức tạp trong các thiết lập zero-shot và few-shot(Wei et al., 2022; Wang et al., 2022). Tuy nhiên, tác động của CoT đối với các nhiệm vụ khớp trong các thiết lập có giám sát vẫn chưa được xem xét. Trong nghiên cứu này, chúng tôi giải quyết khoảng trống này bằng cách kết hợp CoT vào phần đầu ra của các mẫu huấn luyện.

Chúng tôi tiến hành thí nghiệm trên hai tập dữ liệu khớp văn bản ngắn tiếng Trung được sử dụng rộng rãi, LCQMC (Liu et al., 2018a) và BQ (Chen et al., 2018). Tất cả các thí nghiệm đều được thực hiện dựa trên CLLM-7B, là một mô hình được cải tiến tiếng Trung dựa trên LLaMA-2-7B. Kết quả sơ bộ của chúng tôi chứng minh rằng CLLM-7B được fine-tuned vượt trội so với cả BERT được fine-tuned và GPT-4 few-shot. Hơn nữa, kết quả chỉ ra rằng mô hình sinh vượt trội so với phương pháp phân biệt, đặc biệt khi dữ liệu huấn luyện bị hạn chế. Cuối cùng, các thí nghiệm của chúng tôi tiết lộ rằng CoT cũng có lợi cho nhiệm vụ khớp trong các thiết lập có giám sát.

2 Nền tảng
Trong mục này, chúng tôi cung cấp một tổng quan ngắn gọn về nhiệm vụ khớp văn bản ngắn tiếng Trung và các tập dữ liệu được sử dụng trong nghiên cứu này.

2.1 Định nghĩa nhiệm vụ
Khớp văn bản ngắn tiếng Trung, thường được coi là một nhiệm vụ xác định tương đương ngữ nghĩa của câu, là một nhiệm vụ cơ bản của xử lý ngôn ngữ tự nhiên. Cho một cặp câu, mục tiêu của một mô hình khớp là xác định tương đương ngữ nghĩa của chúng. Khớp văn bản ngắn được sử dụng rộng rãi trong một loạt các nhiệm vụ NLP, chẳng hạn như trả lời câu hỏi (Liu et al., 2018b) và hệ thống đối thoại (Pang et al., 2008).

2.2 Tập dữ liệu và Chỉ số
Chúng tôi tiến hành thí nghiệm trên hai corpus khớp văn bản ngắn tiếng Trung được sử dụng rộng rãi: LCQMC (Liu et al., 2018a) và BQ (Chen et al., 2018).

LCQMC là một corpus khớp câu hỏi mở rộng, quy mô lớn. Nó bao gồm 260,068 cặp truy vấn tìm kiếm tiếng Trung, bao gồm 238,766 mẫu huấn luyện, 8,802 mẫu phát triển, và 12,500 mẫu kiểm tra. Mỗi cặp được chú thích với nhãn nhị phân chỉ ra liệu hai truy vấn có cùng ý định hay không.

BQ là một corpus quy mô lớn, cụ thể theo lĩnh vực cho khớp câu hỏi ngân hàng. Nó bao gồm 120,000 cặp câu tiếng Trung, bao gồm 100,000 mẫu huấn luyện, 10,000 mẫu phát triển, và 10,000 mẫu kiểm tra. Mỗi cặp cũng được chú thích với nhãn nhị phân chỉ ra liệu hai câu có truyền đạt cùng ý nghĩa hay không.

Chúng tôi sử dụng độ chính xác (ACC.) làm chỉ số đánh giá, là tỷ lệ phần trăm của các ví dụ được dự đoán chính xác.

3 Thí nghiệm và Kết quả
Trong mục này, chúng tôi phác thảo các cấu hình thí nghiệm và trình bày kết quả. Chúng tôi xem xét ảnh hưởng của ba yếu tố được thảo luận trong Mục 1 thông qua các thí nghiệm sau đây. Chúng tôi điều chỉnh các mô hình thông qua fine-tuning toàn bộ mô hình.

3.1 Mô hình sinh so với Mô hình phân biệt
Chúng tôi đầu tiên phác thảo phương pháp của chúng tôi để fine-tuning các LLM bằng cách mô hình hóa nhiệm vụ khớp như một nhiệm vụ sinh và một nhiệm vụ phân biệt. Sau đó, chúng tôi trình bày kết quả và cung cấp một phân tích.

Mô hình hóa như một Nhiệm vụ sinh: Các LLM nhất quán xử lý tất cả các nhiệm vụ như các nhiệm vụ sinh. Phù hợp với nguyên tắc này, chúng tôi hợp nhất cặp câu được cung cấp với các hướng dẫn thành một đầu vào văn bản duy nhất và khuyến khích mô hình sinh ra nhãn đích. Chúng tôi gọi mô hình này là CLLM-7B-GEN. Hình 1(b) minh họa cấu trúc mô hình. Chúng tôi tối ưu hóa nó bằng cách tối đa hóa xác suất sinh của nhãn đích.

Mô hình hóa như một Nhiệm vụ phân biệt: Được lấy cảm hứng từ hiệu quả của việc fine-tuning BERT cho các nhiệm vụ khớp văn bản (xem Hình 1(a)), chúng tôi nối cặp văn bản đã cho làm đầu vào, trích xuất các biểu diễn vector từ lớp LLM cuối cùng làm đặc trưng, và thực hiện phân loại nhị phân dựa trên các đặc trưng được trích xuất. Chúng tôi gọi mô hình này là CLLM-7B-CLS. Hình 1(c) minh họa cấu trúc mô hình.

Chúng tôi xác nhận hiệu suất của các mô hình sinh và phân biệt trên các tập huấn luyện với quy mô khác nhau. Hình 2 cho thấy kết quả thí nghiệm, trong đó kết quả GPT-4 2-shot được đo bằng cách gọi API chính thức của OpenAI. Hình 6 và Hình 7 trong Phụ lục A minh họa các prompt 2-shot cho LCQMC và BQ, tương ứng. Từ kết quả, chúng tôi quan sát thấy:

1) Khi số lượng mẫu huấn luyện ít hơn 20,000, CLLM-GEN vượt trội đáng kể so với các mô hình phân biệt, bao gồm BERT và CLLM-CLS, trên cả LCQMC và BQ. Hiện tượng này khá trực quan, vì phương pháp sinh phù hợp với quy trình pre-training, làm cho việc kích hoạt kiến thức mà mô hình thu được trong quá trình pre-training trở nên dễ dàng hơn. Hơn nữa, do lượng dữ liệu khổng lồ được sử dụng trong giai đoạn pre-training của các LLM, vấn đề rò rỉ dữ liệu đánh giá không thể bỏ qua (Yang et al., 2023; Zhou et al., 2023). Để xác định liệu CLLM-7B có vấn đề rò rỉ dữ liệu hay không, chúng tôi đã tiến hành thí nghiệm zero-shot trên nó. Mô hình đạt độ chính xác 52.1% trên LCQMC và 52.9% trên BQ, tốt hơn một chút so với 50% dự kiến từ phỏng đoán ngẫu nhiên. Do đó, chúng tôi tin rằng cả BQ và LCQMC đều không được bao gồm trong dữ liệu pre-training của CLLM-7B.

2) Hiệu suất của GPT-4 2-shot trên BQ tệ hơn nhiều so với các mô hình có giám sát. Điều này chủ yếu là do BQ là một tập dữ liệu của các câu hỏi dịch vụ khách hàng thực tế từ WeBank Inc., và việc hiểu đầy đủ ý nghĩa của các câu cần có thông tin nền về ngân hàng này. Ví dụ, các câu hỏi trong BQ thường đề cập đến các sản phẩm cụ thể hoặc một chức năng cụ thể trong ứng dụng của ngân hàng. Kiến thức nền này là chưa biết đối với CLLM và cũng không thể cung cấp hoàn toàn trong prompt.

3) CLLM-GEN được huấn luyện trên toàn bộ corpus huấn luyện trên LCQMC vượt trội so với BERT. Tuy nhiên, nó thất bại trên corpus BQ. Chúng tôi tin rằng lý do là CLLM-7B, giống như BERT, cũng thiếu kiến thức về WeBank, và kiến thức như vậy chỉ có thể thu được từ dữ liệu huấn luyện. Do đó, so với BERT, CLLM-7B không có lợi thế trên tập dữ liệu này.

Các thí nghiệm trên chứng minh rằng mô hình sinh tốt hơn cho các LLM có giám sát. Do đó, tất cả các thí nghiệm tiếp theo sẽ được tiến hành theo mô hình này.

3.2 Prompt ngắn gọn so với Prompt phức tạp
Thiết kế prompt là rất quan trọng cho các LLM trong các thiết lập zero-shot và few-shot. Tuy nhiên, tầm quan trọng của prompt trong các thiết lập có giám sát vẫn chưa được khám phá. Trong tiểu mục này, chúng tôi so sánh hai phong cách prompt khác biệt. Prompt ngắn gọn bao gồm việc nối trực tiếp các cặp văn bản đã cho mà không có bất kỳ giải thích nào về nhiệm vụ đích, trong khi prompt phức tạp tổ chức prompt với các hướng dẫn chi tiết, kết hợp không chỉ các văn bản đã cho mà còn có mô tả cụ thể về nhiệm vụ đích. Ví dụ về các prompt này có thể được tìm thấy trong Hình 8 trong Phụ lục A.

Hình 3 trình bày kết quả, cho thấy các mô hình được huấn luyện riêng biệt bởi các prompt ngắn gọn và phức tạp đạt hiệu suất tương đương. Quan sát này cho thấy rằng các LLM có giám sát không nhạy cảm với prompt. Chức năng chính của một prompt phức tạp là tăng cường khả năng hiểu nhiệm vụ đích của mô hình. Trong các kịch bản có giám sát, mô hình có thể học định nghĩa nhiệm vụ chính xác hơn từ dữ liệu huấn luyện, làm cho thiết kế prompt ít tác động hơn.

3.3 Hiệu ứng của CoT
CoT đã chứng minh hiệu quả của nó trong các nhiệm vụ lý luận và phức tạp trong các thiết lập zero-shot và few-shot. Tuy nhiên, hiệu quả của nó đối với các nhiệm vụ hiểu ngôn ngữ trong các thiết lập có giám sát vẫn chưa được khám phá.

Chúng tôi đã chứng minh trong Mục 3.2 rằng việc thêm thông tin bổ sung vào prompt không cải thiện hiệu suất trong thiết lập có giám sát. Do đó, không giống như trong các thiết lập zero/few-shot, chúng tôi đã không bao gồm CoT trong prompt, mà thay vào đó đã thêm nó vào phần đầu ra. Hình 10 trong Phụ lục A trình bày một mẫu huấn luyện với CoT.

Các tập dữ liệu khớp cung cấp nhãn mà không có CoT. Để có được CoT cho tập huấn luyện, chúng tôi yêu cầu GPT-4 xác định liệu một cặp văn bản đã cho có tương đương hay không, đồng thời cung cấp giải thích cho quyết định của nó. Đối với các mẫu mà phán đoán của GPT-4 phù hợp với nhãn vàng, chúng tôi sử dụng giải thích làm CoT. Ngược lại, đối với các mẫu không nhất quán, chúng tôi chỉ giữ lại nhãn vàng. Hình 4 mô tả prompt được thiết kế và phản hồi được tạo bởi GPT-4. Lưu ý rằng chỉ phần đầu ra của các mẫu huấn luyện mới cần thêm CoT. Hình 10 trong Phụ lục trình bày một mẫu huấn luyện bao gồm CoT. Trong quá trình đánh giá, chúng tôi bỏ qua CoT được tạo bởi mô hình, chỉ tập trung vào nhãn "giống" hoặc "khác".

Để giảm chi phí, chúng tôi đã không thu được CoT cho toàn bộ tập huấn luyện. Thay vào đó, chúng tôi riêng biệt lấy mẫu 10,000 trường hợp từ mỗi tập dữ liệu và yêu cầu GPT-4 tạo CoT. Sau khi lọc các mẫu có phán đoán không nhất quán, khoảng 86% mẫu trong LCQMC và 78% trong BQ giữ lại CoT.

Chúng tôi tiến hành thí nghiệm trên các tập huấn luyện với quy mô khác nhau. Hình 5 hiển thị kết quả, từ đó chúng tôi quan sát thấy rằng CoT cải thiện hiệu suất trên cả LCQMC và BQ. Hơn nữa, tập dữ liệu BQ thách thức hơn LCQMC, và CLLM-GEN-CoT đạt được cải thiện đáng kể hơn trên BQ. Phát hiện này cho thấy rằng CoT có thể đặc biệt hiệu quả đối với các nhiệm vụ khó.

4 Kết luận
Trong công việc này, chúng tôi tiến hành một nghiên cứu thực nghiệm bằng cách fine-tuning các LLM trên nhiệm vụ khớp văn bản ngắn tiếng Trung. Chúng tôi điều tra các yếu tố khác nhau ảnh hưởng đến hiệu suất trong việc điều chỉnh các LLM, bao gồm các phương pháp mô hình hóa nhiệm vụ, định dạng prompt, và chuỗi suy nghĩ. Chúng tôi tiến hành thí nghiệm có hệ thống trên hai tập dữ liệu được sử dụng rộng rãi. Kết quả tiết lộ một số hiểu biết. Thứ nhất, CLLM-7B được fine-tuned vượt trội so với cả BERT được fine-tuned và GPT-4 few-shot, chỉ ra rằng các LLM phục vụ như những backbone hiệu quả trong các kịch bản có giám sát. Hơn nữa, mô hình sinh vượt trội so với mô hình phân biệt, đặc biệt khi dữ liệu huấn luyện bị hạn chế. Thứ hai, các LLM có giám sát không nhạy cảm với prompt, không giống như các LLM zero-shot và few-shot. Thứ ba, CoT cũng có lợi cho khớp văn bản có giám sát. Mặc dù các thí nghiệm của chúng tôi tập trung vào nhiệm vụ khớp văn bản, các quan sát có thể áp dụng cho các nhiệm vụ NLU khác, chẳng hạn như phân loại văn bản.

--- TRANG 2 ---

--- TRANG 3 ---
Hình 1: Cấu trúc mô hình của việc mô hình hóa khớp văn bản như nhiệm vụ sinh và nhiệm vụ phân biệt.
Hình 2: Kết quả của các mô hình được huấn luyện trên 5,000, 20,000, 80,000 mẫu cũng như được huấn luyện trên toàn bộ tập huấn luyện.

--- TRANG 4 ---
Hình 3: Kết quả của các prompt ngắn gọn và phức tạp.
Hình 4: Minh họa cách thu được CoT qua GPT-4. Tất cả các văn bản gốc trong hình này là tiếng Trung. Để dễ đọc, chúng tôi đã dịch chúng. Phiên bản gốc được minh họa trong Hình 9 trong Phụ lục.
Hình 5: Kết quả của các mô hình được huấn luyện với CoT.

--- TRANG 5 ---
Hạn chế
Nghiên cứu này có hai hạn chế chính: (1) Kỹ thuật prompt là rất quan trọng đối với các LLM zero-shot và few-shot. Chúng tôi đã đánh giá hiệu suất few-shot của GPT-4, như được mô tả trong Hình 2. Mặc dù thiết kế prompt few-shot của chúng tôi tỉ mỉ, thiết kế prompt vẫn mang tính chủ quan và có thể không nhất thiết đại diện cho những lựa chọn tối ưu nhất. (2) Nghiên cứu này tập trung vào nhiệm vụ khớp văn bản. Các thí nghiệm bổ sung có thể cần thiết để chứng minh đầy đủ liệu các kết luận rút ra trong bài báo này có áp dụng được cho các nhiệm vụ NLU khác (ví dụ phân loại văn bản) hay không.

Tài liệu tham khảo
[Nội dung tài liệu tham khảo được giữ nguyên như bản gốc]

A Phụ lục
Hình 6: Minh họa prompt 2-shot cho LCQMC.
Hình 7: Minh họa prompt 2-shot cho BQ.
Hình 8: Ví dụ về prompt phức tạp và đơn giản trong Mục 3.2
Hình 9: Phiên bản tiếng Trung của văn bản trong Hình 4
Hình 10: Ví dụ về mẫu huấn luyện với CoT.

--- TRANG 6 ---
[Nội dung tài liệu tham khảo tiếp tục như bản gốc]

# 2102.02189.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/multilingual/2102.02189.pdf
# Kích thước tệp: 365283 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
Khởi động AMR Đa ngôn ngữ với Căn chỉnh Từ Có Ngữ cảnh
Janaki Sheth**Young-Suk Lee* Ramón Fernandez Astudillo* Tahira Naseem*
Radu Florian* Salim Roukos* Todd Ward*
**Đại học Pennsylvania, Philadelphia, PA, USA *IBM Research, Yorktown Heights, NY, USA
Janaki.Sheth@Pennmedicine.upenn.edu, ramon.astudillo@ibm.com
ysuklee, tnaseem, raduf, roukos, toddward@us.ibm.com
Tóm tắt
Chúng tôi phát triển các hệ thống Biểu diễn Ý nghĩa Trừu tượng (AMR) đa ngôn ngữ hiệu suất cao bằng cách chiếu các chú thích AMR tiếng Anh sang các ngôn ngữ khác với giám sát yếu. Chúng tôi đạt được mục tiêu này bằng cách khởi động các embedding từ đa ngôn ngữ dựa trên transformer, đặc biệt là những embedding từ cross-lingual RoBERTa (XLM-R large). Chúng tôi phát triển một kỹ thuật mới để căn chỉnh văn bản ngoại ngữ-với-AMR tiếng Anh, sử dụng căn chỉnh từ có ngữ cảnh giữa các token tiếng Anh và ngôn ngữ ngoại ngữ. Căn chỉnh từ này được giám sát yếu và dựa vào các embedding từ XLM-R có ngữ cảnh. Chúng tôi đạt được hiệu suất cạnh tranh cao vượt qua các kết quả được công bố tốt nhất cho tiếng Đức, tiếng Ý, tiếng Tây Ban Nha và tiếng Trung.

1 Giới thiệu
Các đồ thị Biểu diễn Ý nghĩa Trừu tượng là các đồ thị có hướng, được gán nhãn, có gốc, không có chu trình biểu diễn ngữ nghĩa cấp câu (Banarescu et al., 2013). Trong ví dụ được hiển thị trong Hình 1, câu "The boy wants to go" được phân tích thành đồ thị AMR. Các nút của đồ thị AMR biểu diễn các khái niệm AMR, có thể bao gồm các ký hiệu bề mặt được chuẩn hóa như boy, các khung Propbank (Kingsbury và Palmer, 2002) như want-01, go-02 cũng như các cấu trúc đặc thù AMR khác. Các cạnh trong đồ thị AMR biểu diễn các mối quan hệ giữa các khái niệm. Trong ví dụ này :arg0, :arg1 tương ứng với các vai trò tiêu chuẩn của Propbank.

Một khía cạnh đặc biệt của chú thích AMR là việc thiếu căn chỉnh rõ ràng giữa các nút trong đồ thị và các từ trong câu. Vì các căn chỉnh như vậy là cần thiết để huấn luyện nhiều trình phân tích AMR ngày nay, đã có nhiều nỗ lực khác nhau để liên kết các khái niệm AMR với khoảng từ tương ứng của chúng (Flanigan et al., 2014; Pourdamghani et al., 2014; Lyu và Titov, 2018; Chen và Palmer, 2017). Một trọng tâm đáng kể của bài báo này là tìm ra các căn chỉnh này cho các trình phân tích AMR đa ngôn ngữ.

Mặc dù về bản chất AMR thiên về tiếng Anh, các nghiên cứu gần đây đã đánh giá tiềm năng của AMR để hoạt động như một ngôn ngữ trung gian. Hajič et al. (2014) và Xue et al. (2014) phân loại và đề xuất các cải tiến cho sự phân kỳ trong chú thích giữa AMR tiếng Anh và tiếng Trung cũng như tiếng Séc. Anchiêta và Pardo (2018) nhập chú thích AMR tương ứng cho mỗi câu từ corpus được chú thích tiếng Anh và xem xét lại chú thích để điều chỉnh nó cho tiếng Bồ Đào Nha. Tuy nhiên, Damonte và Cohen (2018) cho thấy rằng có thể sử dụng các chú thích AMR ban đầu được thiết kế cho tiếng Anh làm biểu diễn cho các câu tương đương trong các ngôn ngữ khác mà không cần bất kỳ sửa đổi nào mặc dù có sự phân kỳ dịch thuật. Điều này định nghĩa bài toán phân tích AMR đa ngôn ngữ mà chúng tôi tìm cách giải quyết trong bài báo này - cho một câu trong ngôn ngữ ngoại ngữ, khôi phục đồ thị AMR được thiết kế ban đầu cho bản dịch tiếng Anh của nó. Chúng tôi triển khai

--- TRANG 2 ---
các trình phân tích AMR đa ngôn ngữ cho tiếng Đức, tiếng Tây Ban Nha, tiếng Ý và tiếng Trung.

Trong bài báo này, chúng tôi đề xuất rằng các embedding từ đa ngôn ngữ dựa trên transformer có thể là một công cụ hữu ích để giải quyết bài toán phân tích AMR đa ngôn ngữ. Ngoài việc sử dụng các embedding từ có ngữ cảnh làm embedding token đầu vào, chúng tôi tận dụng chúng cho chiếu chú thích, trong đó các chú thích AMR hiện có cho tiếng Anh được chiếu sang ngôn ngữ đích bằng cách sử dụng căn chỉnh từ có ngữ cảnh. Trong các thí nghiệm của chúng tôi, chúng tôi sử dụng XLM-RoBerta large (Conneau et al., 2019) làm mô hình transformer đa ngôn ngữ được tiền huấn luyện. Chúng tôi cho thấy rằng quy trình đề xuất của chúng tôi đạt được kết quả cạnh tranh so với một số phương pháp cổ điển để căn chỉnh văn bản-với-AMR. Hơn nữa, quy trình như vậy có thể dễ dàng mở rộng cho 100 ngôn ngữ mà XLM-R được huấn luyện.

Chúng tôi cũng kết hợp các kỹ thuật khác nhau để căn chỉnh khái niệm và huấn luyện trình phân tích AMR, điều này cải thiện đáng kể hiệu suất so với các mô hình cơ sở. Đối với căn chỉnh khái niệm, chúng tôi kết hợp các căn chỉnh từ có ngữ cảnh được đề xuất với các kỹ thuật căn chỉnh đã được thiết lập trước đó sử dụng các quy tắc khớp được điều chỉnh cho AMR cũng như các trình căn chỉnh dịch máy (Flanigan et al., 2014; Pourdamghani et al., 2014). Đối với huấn luyện trình phân tích AMR, chúng tôi tiền huấn luyện một trình phân tích AMR trên các treebank của các ngôn ngữ khác nhau cùng lúc và sau đó tinh chỉnh trên từng ngôn ngữ. Điều này tương tự với các kỹ thuật được sử dụng để tiền huấn luyện dữ liệu bạc (Konstas et al., 2017; van Noord và Bos, 2017) trong phân tích AMR và tiền huấn luyện đa ngôn ngữ (Aharoni et al., 2019) trong dịch máy.

Cuối cùng, chúng tôi tiến hành phân tích lỗi chi tiết về phân tích AMR đa ngôn ngữ. Một trong những lỗi chính mà chúng tôi phát hiện liên quan đến các khái niệm đồng nghĩa, có cùng ý nghĩa với các khái niệm gốc trong tiếng Anh, nhưng khác về chính tả. Mặc dù lỗi này chủ yếu do việc các embedding từ đa ngôn ngữ nối các token đầu vào không phải tiếng Anh với các khái niệm tiếng Anh, nó cũng làm nổi bật tính chất từ vựng cao của việc chấm điểm Smatch (Cai và Knight, 2013) không xem xét các khái niệm đồng nghĩa. Chúng tôi cũng trình bày chi tiết về phân tích lỗi của so sánh trực tiếp giữa phương pháp chiếu chú thích đề xuất của chúng tôi sử dụng căn chỉnh từ có ngữ cảnh và baseline trước đó, sử dụng fast align.

Phần còn lại của bài báo được tổ chức như sau: Trong Phần 2, chúng tôi thảo luận về các nghiên cứu liên quan. Trong Phần 3, chúng tôi trình bày đề xuất chính của mình về chiếu chú thích dựa trên căn chỉnh từ có ngữ cảnh. Trong Phần 4, chúng tôi mô tả các phương pháp kết hợp khác nhau giúp cải thiện hiệu suất trình phân tích đa ngôn ngữ một cách đáng kể. Chúng bao gồm kết hợp căn chỉnh từ-với-khái niệm, sử dụng treebank đa ngôn ngữ và kết hợp treebank do con người chú thích và tổng hợp. Trong Phần 5, chúng tôi thảo luận về kết quả thí nghiệm. Trong Phần 6 và 7, chúng tôi trình bày các phân tích lỗi chi tiết. Chúng tôi kết luận bài báo trong Phần 8.

2 Các nghiên cứu liên quan
AMR đa ngôn ngữ. Đã có những tiến bộ đáng kể trong phân tích AMR cho các ngôn ngữ khác ngoài tiếng Anh. Các nghiên cứu trước đây (Hajič et al., 2014; Xue et al., 2014; Migueles-Abraira et al., 2018; Sobrevilla Cabezudo và Pardo, 2019) đã điều tra các chú thích AMR cho nhiều ngôn ngữ khác nhau như tiếng Trung, tiếng Séc, tiếng Tây Ban Nha và tiếng Bồ Đào Nha Brazil. Vanderwende et al. (2015) tự động phân tích biểu diễn logic cho các câu trong tiếng Tây Ban Nha, tiếng Ý, tiếng Đức và tiếng Nhật, sau đó được chuyển đổi thành AMR sử dụng một tập hợp nhỏ các quy tắc.

Trong khi phần lớn công việc này, cùng với các nghiên cứu như Li et al. (2016); Anchiêta và Pardo (2018), tạo ra các đồ thị AMR có các nút được gán nhãn bằng các từ từ ngôn ngữ đích, Damonte và Cohen (2018) phát triển các trình phân tích AMR cho tiếng Anh và sử dụng corpus song song để chiếu chú thích nhằm huấn luyện các trình phân tích tiếng Ý, tiếng Tây Ban Nha, tiếng Đức và tiếng Trung khôi phục đồ thị AMR được thiết kế ban đầu cho bản dịch tiếng Anh. Kết quả chính của họ cho thấy rằng các trình phân tích mới có thể vượt qua một số khác biệt cấu trúc giữa các ngôn ngữ.

Tương tự như Damonte và Cohen (2018), chúng tôi cũng huấn luyện các trình phân tích AMR đa ngôn ngữ bằng cách chiếu chú thích AMR tiếng Anh sang các ngôn ngữ ngoại ngữ đích (tiếng Đức, tiếng Tây Ban Nha, tiếng Ý và tiếng Trung), nhưng chúng tôi khác biệt với phương pháp của họ trong các chi tiết cụ thể của chiếu chú thích bằng cách khám phá căn chỉnh từ có ngữ cảnh được rút ra trực tiếp từ các embedding từ đa ngôn ngữ có ngữ cảnh. Mặc dù cả hai quy trình đều sử dụng corpus song song, chiếu chú thích của Damonte và Cohen (2018) yêu cầu huấn luyện có giám sát bổ sung cho trình căn chỉnh từ thống kê của họ. Tuy nhiên, căn chỉnh từ có ngữ cảnh đề xuất của chúng tôi có tính chất không giám sát. Ngoài ra, một nghiên cứu gần đây của Blloshmi et al. (2020) cho thấy rằng thực tế có thể không cần các trình phân tích dựa trên căn chỉnh cho AMR đa ngôn ngữ, thay vào đó mô hình hóa việc nhận dạng khái niệm như một bài toán seq2seq. Trong bài báo này, chúng tôi sẽ so sánh kết quả của mình với cả

--- TRANG 3 ---
Damonte và Cohen (2018) và Blloshmi et al. (2020).

Kỹ thuật căn chỉnh vector từ. Các phương pháp căn chỉnh từ truyền thống thường sử dụng corpus song song và các mô hình căn chỉnh IBM (Brown et al., 1990, 1993) cũng như các phiên bản cải tiến (Och và Ney, 2003; Dyer et al., 2013). Gần đây hơn, đã có sự xuất hiện của các kỹ thuật căn chỉnh biểu diễn vector của các từ từ các cấp độ giám sát khác nhau (Ruder et al., 2019). Thường thì các vector từ được học độc lập cho mỗi ngôn ngữ và sau đó một ánh xạ từ vector ngôn ngữ nguồn đến vector ngôn ngữ đích với một từ điển song ngữ được phát triển (Mikolov et al., 2013; Smith et al., 2017; Artetxe et al., 2017). Để giảm nhu cầu giám sát song ngữ, phương pháp lặp bắt đầu từ một từ điển mầm tối thiểu và xen kẽ với việc học ánh xạ tuyến tính đã được sử dụng bởi một nhóm nghiên cứu gần đây (Conneau et al., 2018; Schuster et al., 2019; Artetxe et al., 2018).

Công trình tương tự nhất với chúng tôi là Cao et al. (2020) trong đó các tác giả thu được căn chỉnh embedding có ngữ cảnh từ multilingual BERT (Devlin et al., 2018; Pires et al., 2019) và sau đó cải thiện căn chỉnh thông qua tinh chỉnh sử dụng corpus song song có giám sát. Căn chỉnh từ có ngữ cảnh của chúng tôi giữa hai câu song song có thể được coi là một sự điều chỉnh của nhiệm vụ truy xuất từ có ngữ cảnh của họ. Tuy nhiên, chúng tôi tránh bất kỳ tinh chỉnh nào của các embedding có ngữ cảnh và cho thấy rằng căn chỉnh từ có ngữ cảnh từ mô hình XLM-R có sẵn đạt được kết quả cạnh tranh với căn chỉnh từ bằng fast-align (xem Damonte và Cohen (2018)). Điều này cho thấy tiềm năng mở rộng quy mô lớn, không tốn kém của phân tích AMR lên đến 100 ngôn ngữ mà XLM-R được huấn luyện.

3 Chiếu chú thích
Chúng tôi áp dụng phương pháp phân tích dựa trên chuyển đổi cho phân tích AMR theo sau (Ballesteros và Al-Onaizan, 2017; Naseem et al., 2019; Fernandez Astudillo et al., 2020). Những phương pháp này tạo ra một đồ thị AMR g từ một câu đầu vào s bằng cách thay vào đó dự đoán một chuỗi hành động a từ s như một bài toán chuỗi đến chuỗi. Chuỗi hành động này được áp dụng cho một máy trạng thái M sau đó tạo ra đồ thị đích mong muốn dưới dạng g = M(a; s). Các trình phân tích dựa trên chuyển đổi yêu cầu chuỗi hành động cho mỗi đồ thị trong dữ liệu huấn luyện. Điều này được xác định bởi một oracle dựa trên quy tắc a = O(g; s) dựa vào căn chỉnh từ-với-nút bên ngoài. Trong tất cả các thí nghiệm tiếp theo, chúng tôi sẽ sử dụng oracle và tập hành động từ (Fernandez Astudillo et al., 2020).

3.1 Phương pháp chiếu
Để huấn luyện các trình phân tích AMR trong một ngôn ngữ không phải tiếng Anh, chúng tôi sử dụng phương pháp chiếu chú thích để tận dụng chú thích AMR tiếng Anh hiện có và vượt qua tình trạng thiếu tài nguyên trong ngôn ngữ đích. Đầu tiên, văn bản tiếng Anh được căn chỉnh với các khái niệm AMR tương ứng sử dụng cả trình căn chỉnh JAMR dựa trên quy tắc (Flanigan et al., 2014) và trình căn chỉnh loại mô hình IBM (Pourdamghani et al., 2014). Trình sau sẽ được gọi là trình căn chỉnh EM từ đây về sau. Cho các căn chỉnh văn bản tiếng Anh-với-khái niệm AMR, sau đó chúng tôi chiếu chúng sang ngôn ngữ đích sử dụng căn chỉnh từ. Trong phần tiếp theo, chúng tôi mô tả phương pháp căn chỉnh từ được đề xuất, được gọi là căn chỉnh từ có ngữ cảnh, được huấn luyện một cách giám sát yếu.

3.2 Căn chỉnh từ có ngữ cảnh
Cho hai ngôn ngữ, chúng tôi căn chỉnh các cặp từ trong các câu song song nếu biểu diễn vector của chúng được rút ra từ mô hình đa ngôn ngữ được tiền huấn luyện cơ bản tương tự theo khoảng cách cosine. Như biểu diễn vector, chúng tôi sử dụng trung bình của tất cả 24 lớp của embedding có ngữ cảnh XLM-R large. Chúng tôi sẽ gọi trung bình này là embedding có ngữ cảnh của từ từ đây về sau cho đơn giản.

Cụ thể hơn, giả sử chúng ta có hai câu song song - E = e₀, e₁, e₂, ..., eₘ trong tiếng Anh và F = f₀, f₁, f₂, ..., fₙ trong ngôn ngữ đích. Chúng tôi sẽ sử dụng r để biểu diễn mô hình đa ngôn ngữ được tiền huấn luyện sao cho r(S)ᵢ là embedding có ngữ cảnh cho từ thứ i trong câu S. Khi đó một từ eᵢ ∈ E được căn chỉnh từ có ngữ cảnh với fⱼ nếu và chỉ nếu điểm số độ tương tự cosine giữa embedding từ của chúng là cao nhất. Do đó chúng tôi định nghĩa hàm căn chỉnh có ngữ cảnh tương ứng (fⱼ|eᵢ) như sau:

(fⱼ|eᵢ) = argmax₀≤ⱼ≤|F| cos(r(E)ᵢ, r(F)ⱼ). (1)

Tương tự, thực hiện cùng quy trình theo hướng ngược lại, chúng ta có:

(eᵢ|fⱼ) = argmax₀≤ᵢ≤|E| cos(r(F)ⱼ, r(E)ᵢ) (2)

Mặc dù các phương pháp này có thể nhiễu, bằng cách chỉ giữ lại các cặp từ trong giao điểm của chúng tức là (E|F) ∩ (F|E), có thể rút ra phương pháp căn chỉnh cosine giao điểm cho chúng ta một tập dữ liệu căn chỉnh từ với độ bao phủ thấp nhưng độ chính xác cao.

--- TRANG 4 ---
Hình 2: Chiếu chú thích được thực hiện sử dụng trình căn chỉnh JAMR và EM cho căn chỉnh văn bản tiếng Anh-với-khái niệm AMR và căn chỉnh từ có ngữ cảnh giữa các token của ngôn ngữ nguồn (tiếng Anh) và đích.

Ví dụ, sau đây là các câu từ tập dữ liệu huấn luyện tiếng Đức và tiếng Anh của chúng tôi:
E: Establishing models in industrial Innovation
F: Etablierung von Modellen in der industriellen Innovation

Căn chỉnh từ có ngữ cảnh của chúng là:
(F|E) = [(e₀,f₀), (e₁,f₂), (e₂,f₃), (e₃,f₅), (e₄,f₆)]
(E|F) = [(f₀,e₀), (f₁,e₁), (f₂,e₁), (f₃,e₂), (f₄,e₂), (f₅,e₁), (f₆,e₄)]
(F|E) ∩ (E|F) = [(e₀,f₀), (e₁,f₂), (e₂,f₃), (e₄,f₆)]

Hình 2 minh họa bằng hình ảnh phương pháp chiếu chú thích hoàn chỉnh của chúng tôi sử dụng căn chỉnh từ có ngữ cảnh (F|E). Các token tiếng Anh và khái niệm AMR được căn chỉnh sử dụng trình căn chỉnh JAMR và EM. Chú thích AMR kết quả được tăng cường với căn chỉnh từ tiếng Anh-với-khái niệm sau đó được chiếu lên ngôn ngữ đích cho trước sử dụng embedding từ có ngữ cảnh. Từ đây về sau, để ngắn gọn, chúng tôi đôi khi sẽ gọi phương pháp này là A.P.

4 Phương pháp kết hợp
Chúng tôi áp dụng ba loại kỹ thuật kết hợp cho các trình phân tích AMR đa ngôn ngữ, được huấn luyện bằng cách chiếu chú thích tiếng Anh sử dụng căn chỉnh từ có ngữ cảnh được rút ra từ embedding từ đa ngôn ngữ có ngữ cảnh, mỗi loại đều cải thiện hiệu suất trình phân tích một cách đáng kể.

4.1 Kết hợp căn chỉnh
Một kỹ thuật như vậy là kết hợp A.P. dựa trên căn chỉnh từ có ngữ cảnh với căn chỉnh từ-với-khái niệm baseline căn chỉnh các token đích trực tiếp với các khái niệm AMR sử dụng trình căn chỉnh JAMR và EM. Vì trình căn chỉnh EM là một phương pháp không giám sát, nó có thể được áp dụng trực tiếp cho các token ngôn ngữ đích và các khái niệm AMR tiếng Anh. Tuy nhiên, chúng tôi lưu ý rằng phương pháp căn chỉnh baseline này cho độ bao phủ không hoàn chỉnh (87% khái niệm được căn chỉnh với token tiếng Đức, 88% với tiếng Ý và 91% với tiếng Tây Ban Nha). Do đó, chúng tôi bổ sung điều này bằng cách căn chỉnh các khái niệm còn lại sử dụng A.P. của Hình 2.

Ví dụ, giả sử chúng ta có như trước hai câu song song - E = e₀, ..., eₘ trong tiếng Anh và F = f₀, ..., fₙ trong ngôn ngữ đích, cũng như các khái niệm AMR N = n₀, ..., nₗ. Khi đó một trong các quy trình căn chỉnh kết hợp văn bản ngoại ngữ-với-khái niệm AMR được đề xuất của chúng tôi EA(fᵢ|nⱼ) (xem Hình 3) được định nghĩa như sau:

EA(fᵢ|nⱼ) = AP(BA(fᵢ|nⱼ)) (3)

trong đó BA(fᵢ|nⱼ) biểu diễn rằng khái niệm thứ j được căn chỉnh với token thứ i trong F sử dụng trình căn chỉnh baseline BA. Nếu đối với bất kỳ khái niệm nⱼ ∈ N, BA(fᵢ|nⱼ) = None, chúng tôi sử dụng chiếu chú thích để căn chỉnh nó trong đó AP(fᵢ|nⱼ) được cho bởi:

(fᵢ|eₖ) ∧ BA(eₖ|nⱼ) ⇒ AP(fᵢ|nⱼ) (4)

Chúng tôi cũng thử nghiệm với các căn chỉnh khác như vậy, đặc biệt là bằng cách sử dụng giao điểm của căn chỉnh cosine ((F|E) ∩ (E|F)) làm căn chỉnh từ có ngữ cảnh. Trong trường hợp này:

EA(fᵢ|nⱼ) = maxAP(BA(iAP(fᵢ|nⱼ))) (5)

trong đó:
((fᵢ|eₖ) ∩ (eₖ|fᵢ)) ∧ BA(eₖ|nⱼ) ⇒ iAP(fᵢ|nⱼ) (6)

Như trước, ∀nⱼ ∈ N mà iAP(fᵢ|nⱼ) = None, chúng tôi căn chỉnh nó sử dụng trình căn chỉnh baseline BA(fᵢ|nⱼ). Đối với bất kỳ khái niệm chưa được căn chỉnh còn lại nào khác, chúng tôi sử dụng maxAP(fᵢ|nⱼ) có thể được mô tả như sau:

max((fᵢ|eₖ), (eₖ|fᵢ)) ∧ BA(eₖ|nⱼ) ⇒ maxAP(fᵢ|nⱼ) (7)

Nghĩa là, chúng tôi chọn căn chỉnh từ có ngữ cảnh một chiều với điểm số cao hơn và chiếu chú thích AMR tương ứng.

Hình 3: Minh họa kết hợp căn chỉnh EM, JAMR + A.P.: đầu tiên căn chỉnh các token đích với các khái niệm AMR sử dụng trình căn chỉnh JAMR+EM với bất kỳ khái niệm còn lại nào sau đó được căn chỉnh sử dụng phương pháp chiếu chú thích được đề xuất trong Hình 2.

--- TRANG 5 ---
4.2 Kết hợp treebank đa ngôn ngữ
Ngoài việc huấn luyện trình phân tích trên treebank của từng ngôn ngữ - được rút ra từ treebank tiếng Anh thông qua chiếu chú thích - chúng tôi cũng thử nghiệm với việc kết hợp tất cả các treebank ngôn ngữ đích để tạo ra một treebank đa ngôn ngữ duy nhất. Chúng tôi nhận thấy rằng tiền huấn luyện một trình phân tích AMR trên treebank đa ngôn ngữ này với tinh chỉnh tiếp theo trên treebank của từng ngôn ngữ, cải thiện hiệu suất so với trình phân tích được huấn luyện chỉ trên từng treebank riêng lẻ.

4.3 Kết hợp treebank con người và tổng hợp
Chúng tôi tạo ra một corpus AMR tổng hợp bằng cách phân tích 85k câu không được gán nhãn từ phần ngữ cảnh của SQuAD-2.0. Các đồ thị AMR tổng hợp kết quả được lọc theo quy trình trong (Lee et al., 2020) và kết hợp với tập huấn luyện AMR-2.0 (LDC2017T10), để tạo ra tập dữ liệu huấn luyện AMR-2.0 + SQuAD mở rộng gồm 94k câu. Sau đó chúng tôi chiếu chú thích của treebank tiếng Anh mở rộng này lên từng ngôn ngữ đích, và huấn luyện trình phân tích ngôn ngữ đích tương ứng. Chúng tôi quan sát thấy rằng mặc dù chất lượng của các AMR tổng hợp thấp hơn so với các đối tác được chú thích bởi con người, việc đưa chúng vào tập huấn luyện cải thiện đáng kể hiệu suất trình phân tích.

5 Kết quả thí nghiệm
5.1 Trình phân tích AMR và Dữ liệu
Cho các thí nghiệm của chúng tôi, chúng tôi sử dụng mô hình stack-Transformer (Fernandez Astudillo et al., 2020)¹ làm trình phân tích AMR. Stack-Transformer là một trình phân tích dựa trên chuyển đổi với kiến trúc Transformer được sửa đổi để mã hóa trạng thái trình phân tích. Nó sử dụng hàm mất mát cross entropy và có các siêu tham số tương tự như những gì được mô tả trong dịch máy (Vaswani et al., 2017). Chúng tôi sử dụng kích thước beam là 3 để giải mã các mô hình và đánh giá chúng sử dụng điểm số Smatch (Cai và Knight, 2013). Các giá trị hiệu suất mô hình trong bản thảo này là trung bình của các mô hình có hiệu suất tốt nhất trên 3 hạt giống ngẫu nhiên. Cuối cùng, đầu vào cho trình phân tích - biểu diễn vector của mỗi từ - được thu được bằng cách lấy trung bình không chỉ trên tất cả 24 lớp của embedding có ngữ cảnh XLM-R large được tiền huấn luyện mà còn trên các wordpiece cấu thành trong mỗi từ.

Đối với tất cả bốn ngôn ngữ - tiếng Đức, tiếng Tây Ban Nha, tiếng Ý và tiếng Trung - chúng tôi thử nghiệm trên AMR1.0 (LDC2015E86). Đối với ba ngôn ngữ đầu, chúng tôi cũng thử nghiệm trên AMR-2.0 (LDC2017T10). Kết quả từ cái trước được so sánh với Damonte và Cohen (2018) và từ cái sau với Blloshmi et al. (2020). Chi tiết về các tập huấn luyện, dev và test của chúng tôi được đưa ra trong Bảng 1.² Để huấn luyện mỗi trình phân tích ngôn ngữ đích, đầu tiên chúng tôi dịch các câu đầu vào của AMR-2.0 và AMR-1.0 với Watson Language Translator.³ Điều này tạo ra corpus song song có giám sát mà chúng tôi sau đó sử dụng cho chiếu chú thích không giám sát thông qua căn chỉnh từ có ngữ cảnh. Chúng tôi cũng căn chỉnh các token ngôn ngữ đích trực tiếp với các khái niệm AMR sử dụng trình căn chỉnh JAMR và EM để đánh giá hệ thống baseline và cho các căn chỉnh kết hợp. Chúng tôi chọn các mô hình có hiệu suất tốt nhất sử dụng tập dev. Cuối cùng, đối với các mô hình tốt nhất của chúng tôi, chúng tôi báo cáo kết quả sử dụng bản dịch máy cũng như bản dịch của con người (LDC2020T07) của các tập test.

5.2 Baseline
Baseline đầu tiên của chúng tôi là học zero-shot, trong đó chúng tôi huấn luyện trên tập dữ liệu tiếng Anh nhưng test trên tập dev-set ngôn ngữ ngoại ngữ (Baseline I). Lý do đằng sau thí nghiệm này là để kiểm tra khả năng của embedding từ có ngữ cảnh XLM-R để nắm bắt ý nghĩa của token cho trước bất kể ngôn ngữ cơ bản. Lưu ý rằng chỉ cho thí nghiệm này, các ngôn ngữ cho tập train và dev khác nhau. Trong một tập thí nghiệm khác, chúng tôi căn chỉnh các token ngôn ngữ đích trực tiếp với các khái niệm AMR chỉ sử dụng trình căn chỉnh JAMR và EM (Baseline II). Cuối cùng, chúng tôi cũng test quy trình chiếu chú thích của Damonte và Cohen (2018). Lưu ý rằng trong khi các tác giả trước đây sử dụng fast align (Dyer et al., 2013) để căn chỉnh từ giữa dữ liệu song song và chỉ trình căn chỉnh JAMR cho căn chỉnh văn bản tiếng Anh-với-AMR, trong Baseline III chúng tôi đã sử dụng fast align kết hợp với cả trình căn chỉnh JAMR và EM (cho căn chỉnh văn bản tiếng Anh-với-AMR) để cải thiện hiệu suất.

5.3 Kết quả
Bảng 2 so sánh các phương pháp đề xuất khác nhau của chúng tôi với ba phương pháp baseline sử dụng tập dữ liệu AMR2.0 và AMR1.0. Chúng tôi thấy rằng phương pháp đề xuất của chúng tôi - chiếu chú thích với căn chỉnh từ có ngữ cảnh, trong trường hợp này sử dụng (F|E) - cho thấy kết quả khá cạnh tranh với

¹https://github.com/IBM/transition-amr-parser
²Phân đoạn từ được áp dụng cho các văn bản tiếng Trung thô để huấn luyện và kiểm tra mô hình.
³https://www.ibm.com/watson/services/language-translator/

--- TRANG 6 ---
[THIS IS TABLE: Dataset details with columns for Dataset, Experiment, and Number of sentences/tokens for DE, ES, IT, ZH languages]

[THIS IS TABLE: Development set Smatch scores for AMR2.0 and AMR1.0 across different models and languages]

[THIS IS TABLE: Test set Smatch scores for AMR1.0 comparing different models with machine and human translation]

[THIS IS TABLE: Test set Smatch scores for AMR2.0 comparing different models with machine and human translation]

--- TRANG 7 ---
những kết quả của Baseline III cho các ngôn ngữ đích tiếng Đức, tiếng Ý và tiếng Tây Ban Nha, đặc biệt khi được áp dụng cho corpus nhỏ hơn của AMR1.0. Điều này đáng chú ý xem xét phương pháp của chúng tôi không yêu cầu huấn luyện bổ sung và có thể dễ dàng được tổng quát hóa cho việc học zero-shot trên tất cả các ngôn ngữ khác nhau mà XLM-R được tiền huấn luyện. Sau đó chúng tôi huấn luyện một số trình phân tích sử dụng các phương pháp kết hợp được đề xuất. Phương pháp đầu tiên bao gồm cả trình căn chỉnh EM, JAMR + A.P (xem Eq. 3). Trong một phương pháp khác, chúng tôi sử dụng chiếu chú thích dựa trên căn chỉnh từ cosine giao điểm (tức là (F|E) ∩ (E|F)). Vì điều này để lại nhiều khái niệm AMR chưa được căn chỉnh, chúng tôi theo sau bằng căn chỉnh các khái niệm sử dụng trình căn chỉnh baseline JAMR và EM. Bất kỳ khái niệm chưa được căn chỉnh còn lại nào sau đó được căn chỉnh sử dụng max((E|F), (F|E)) (Eq. 5). Trong một tập thí nghiệm khác, chúng tôi tiền huấn luyện một trình phân tích trên treebank đa ngôn ngữ, trong đó tập train là sự kết hợp của treebank LDC trong tất cả các ngôn ngữ đích. Trình phân tích sau đó được tinh chỉnh trên từng ngôn ngữ riêng lẻ. Chúng tôi đoán rằng một thí nghiệm như vậy sẽ cho chúng tôi một trình phân tích đa ngôn ngữ thực sự có khả năng giải mã thành công tất cả các ngôn ngữ đích. Sức mạnh của nó thể hiện rõ trong hiệu suất, nó vượt trội hơn tất cả các phương pháp baseline của chúng tôi - trong trường hợp tập dev AMR1.0 ít nhất là 1.4 điểm. Cuối cùng, trong hai thí nghiệm cuối trên AMR2.0, chúng tôi huấn luyện trên tập train LDC + SQuaD đặc thù ngôn ngữ. Chúng tôi thấy rằng điều này cho chúng tôi các trình phân tích có hiệu suất tốt nhất, trong đó dữ liệu huấn luyện được căn chỉnh sử dụng căn chỉnh kết hợp (EM, JAMR + A.P).

Chúng tôi test một tập con của các mô hình AMR2.0 và tất cả các mô hình AMR1.0 trên các tập test tương ứng. Kết quả được hiển thị trong Bảng 3 và 4. Đối với AMR1.0, trong khi tất cả các mô hình của chúng tôi bao gồm cả baseline đều vượt trội hơn các kết quả đã được công bố trước đây, mô hình có hiệu suất tốt nhất là trình phân tích được huấn luyện trên dữ liệu đa ngôn ngữ và có văn bản đầu vào huấn luyện được căn chỉnh với các khái niệm AMR sử dụng sự kết hợp của trình căn chỉnh EM, JAMR và A.P. Đối với AMR2.0, các mô hình được huấn luyện trên tập dữ liệu LDC + SQuAD vượt trội hơn những mô hình được huấn luyện trên dữ liệu đa ngôn ngữ. Cả hai đều vượt trội hơn công trình được công bố gần đây của Blloshmi et al. (2020).⁴

Chúng tôi lưu ý rằng trình phân tích hoạt động tốt hơn trên dữ liệu test được dịch máy so với dữ liệu test được dịch bởi con người. Điều này nên được quy cho việc không khớp điều kiện huấn luyện và test của dữ liệu test được dịch bởi con người vì tất cả các mô hình đều được huấn luyện trên dữ liệu huấn luyện được dịch máy. Ví dụ, tỷ lệ từ ngoài từ vựng (oov) của dữ liệu test được dịch bởi con người luôn cao hơn so với dữ liệu test được dịch máy. Chẳng hạn, đối với AMR1.0, tỷ lệ oov của dữ liệu test được dịch bởi con người so với dữ liệu test được dịch máy là 10.2% so với 9% đối với tiếng Đức, 7.3% so với 6.8% đối với tiếng Tây Ban Nha, 8.1% so với 7.6% đối với tiếng Ý và 7.6% so với 5.5% đối với tiếng Trung.

6 Phân tích lỗi
Chúng tôi thực hiện phân tích lỗi của 56 câu tiếng Đức được phân tích bởi mô hình có hiệu suất tốt nhất được huấn luyện trên sự kết hợp của dữ liệu huấn luyện AMR2.0 và SQuAD. Thống kê về các lỗi khác nhau được mô tả trong Hình 4. Top 5 lỗi thường gặp nhất bao gồm (i) đưa vào các khái niệm đồng nghĩa, (ii) khái niệm bị thiếu, (iii) vai trò không chính xác, (iv) token đích trong khái niệm AMR, (v) phân tích không chính xác đa câu như một trường hợp liên từ.

Hình 4: Biểu đồ các loại lỗi khác nhau

6.1 Khái niệm đồng nghĩa
Lỗi phổ biến nhất mà chúng tôi gặp phải là các khái niệm AMR đồng nghĩa, như được hiển thị trong Hình 5. So sánh đồ thị mong đợi (trên) với phiên bản được phân tích (dưới), chúng tôi lưu ý rằng khái niệm "previous" được đồng nghĩa hóa thành "past". Mặc dù lỗi này chủ yếu do việc embedding từ đa ngôn ngữ nối các token đầu vào không phải tiếng Anh với các khái niệm tiếng Anh, nó cũng làm nổi bật tính chất từ vựng cao của việc chấm điểm Smatch (Cai và Knight, 2013) không xem xét các khái niệm đồng nghĩa. Cho rằng AMR được cho là biểu diễn ý nghĩa cốt lõi của một câu bất kể các biến thể cú pháp và hình thái học của nó, việc chấm điểm Smatch nên có thể nắm bắt các biến thể từ vựng như các khái niệm đồng nghĩa.

--- TRANG 8 ---
Trong môi trường này, điều gì sai nếu họ chỉ trích propaganda ngu ngốc trước đây một chút?

(w / wrong-02
:ARG1 (a2 / amr-unknown)
:ARG2 (c / criticize-01
:ARG0 (t / they)
:ARG1 (p / propaganda
:time (p2 / previous)
:ARG1-of (s / stupefy-01))
:degree (b / bit))
:location (e / environment
:mod (t2 / this)))

Was ist in dieser Umgebung falsch, wenn sie die bisherige stupeftende Propaganda ein bisschen kritisieren?

(w / wrong-02
:ARG1 (c / criticize-01
:ARG0 (t2 / they)
:ARG1 (p2 / propaganda
:time (p / past))
:degree (b / bit))
:ARG2 (a / amr-unknown)
:location (e / environment
:mod (t / this)))

Hình 5: AMR vàng (trên) và AMR được phân tích (dưới) cho một câu tiếng Đức minh họa các lỗi: khái niệm đồng nghĩa (previous vs. past), khái niệm bị thiếu (khái niệm stupefy-01 bị thiếu trong AMR được phân tích), vai trò không chính xác (hai đối số, :ARG1 và :ARG2, của wrong-02 được hoán đổi trong AMR được phân tích).

Trong những khoảnh khắc quan trọng, tất cả chúng ta đều là con cháu của hoàng đế Yan và hoàng đế Huang.

(d / descend-01
:ARG0 (w / we
:mod (a / all))
:source (a2 / and
:op1 (p / person
:name (n / name
:op1 "Yan")
:ARG0-of (h / have-org-role-91
:ARG2 (e / emperor)))
:op2 (p2 / person
:name (n2 / name :op1 "Huang")
:ARG0-of h))
:time (m / moment
:ARG1-of (c / critical-02)))

In kritischen Momenten sind wir alle Nachfahren des Yan Kaisers und Huang Kaisers.

(d / descend-01
:ARG0 (w / we
:mod (a / all))
:ARG1 (a2 / and
:op1 (p / person
:name (n / name
:op1 "Yan"
:op2 "Kaisers"))
:op2 (p2 / person
:name (n2 / name
:op1 "Huang"
:op2 "Kaisers")))
:time (m / moment
:ARG1-of (c / critical-02)))

Hình 6: AMR vàng (trên) và AMR được phân tích (dưới) cho một câu tiếng Đức minh họa vai trò không chính xác (:source được thay thế bằng :ARG1 trong AMR được phân tích) và nhận dạng không chính xác token đích "Kaisers" như một thực thể có tên.

6.2 Khái niệm bị thiếu và vai trò không chính xác
Một số khái niệm bị thiếu trong AMR được phân tích, như stupefy-01 trong Hình 5. Trình phân tích cũng nhận dạng không chính xác các mối quan hệ giữa các khái niệm. Trong Hình 5, các đối số ARG1 và ARG2 cho khái niệm wrong-02 bị hoán đổi. Trong Hình 6, mối quan hệ :source được thay thế bằng đối số khung ARG1.

6.3 Phân tích không chính xác đa câu
Một lỗi thường gặp khác bao gồm phân tích không chính xác đa câu như một trường hợp liên từ, đặc biệt khi các câu được phân cách bằng dấu phẩy. Lưu ý rằng các lỗi đa câu không đặc thù cho phân tích đa ngôn ngữ và xảy ra thường xuyên khi phân tích các câu đầu vào tiếng Anh. Lỗi đa câu này chủ yếu do sự mơ hồ của dấu phẩy, có thể bao gồm nhiều ngữ nghĩa khác nhau tùy thuộc vào ngữ cảnh giữa các ngôn ngữ.

6.4 Nhận dạng sai token ngoại ngữ như thực thể có tên
Một số token đích có thể được thực hiện hợp lệ trong AMR vàng, đặc biệt khi các token đích là thực thể có tên, ví dụ Frankfurt, Anna, Noah, v.v. Điều này thường dẫn đến lỗi trong AMR được phân tích khi một token đích bị nhận dạng sai như một thực thể có tên. Trong Hình 6, token tiếng Đức "Kaisers" bị phân tích sai như một phần của thực thể có tên "Yan Kaisers" và "Huang Kaisers". Việc không nắm bắt được khái niệm chính xác "emperor" cho token tiếng Đức "Kaisers" dẫn đến lỗi tiếp theo là không reify vai trò thành have-org-role-91⁵, rõ ràng trong so sánh AMR được phân tích với AMR vàng.

6.5 Khác
Các lỗi khác bao gồm việc thiếu stemming trong ngôn ngữ đích, như "Kaisers" trong Hình 6. Lỗi stemming chủ yếu do việc chúng tôi không tích hợp stemmer ngôn ngữ đích trong khi chúng tôi đã tích hợp spacy⁶ cho tiếng Anh. Một số lỗi do dịch máy gây ra. Đầu vào tiếng Anh phân mảnh "taking a look" được dịch thành "Sehen Sie sich", sau đó bị phân tích sai như câu mệnh lệnh. Các token danh từ ngôn ngữ đích thường không thể gọi các vị từ. Cho đầu vào tiếng Anh "cultural tyranny in the cloak of nationalism", "tyranny" gọi vị từ tyrannize-01. Tuy nhiên, đối tác tiếng Đức "Tyrannei" không thể

⁵Tham khảo https://www.isi.edu/~ulf/amr/lib/roles.html và https://www.isi.edu/~ulf/amr/lib/amr-dict.html/have-org-role-91 để biết chi tiết.
⁶https://spacy.io/

--- TRANG 9 ---
[THIS IS TABLE: AMR1.0 parser performance comparison showing Contextual vs Fast Align results for German, Italian, and Spanish]

gọi vị từ trong "kulturellen Tyrannei im Mantel des Nationalismus".

7 Phân tích lỗi căn chỉnh từ
Chúng tôi so sánh chiếu chú thích cho AMR1.0 giữa fast align và căn chỉnh có ngữ cảnh. Như đã lưu ý trong Bảng 3, chúng có hiệu suất tương đương cho tiếng Đức, tiếng Ý và tiếng Tây Ban Nha. Tuy nhiên, khi phân tích chi tiết, chúng tôi nhận thấy rằng chiếu chú thích sử dụng căn chỉnh có ngữ cảnh có độ bao phủ lớn hơn về mặt căn chỉnh văn bản ngoại ngữ-với-AMR so với fast align (ví dụ đối với tiếng Đức, căn chỉnh có ngữ cảnh A.P. cho độ bao phủ 99.95% so với 97.47%). Điều này có thể do việc fast align dựa trên mô hình căn chỉnh IBM, dựa vào số lượng mong đợi của các cặp căn chỉnh và sử dụng các ràng buộc căn chỉnh bổ sung. Căn chỉnh có ngữ cảnh dựa vào việc ghép cặp không hạn chế bằng khoảng cách cosine của embedding từ có ngữ cảnh XLM-R của các token đầu vào. Cho một token tiếng Anh, căn chỉnh có ngữ cảnh nhất thiết căn chỉnh nó với một từ ngôn ngữ ngoại ngữ. Hơn nữa, vì embedding có ngữ cảnh và được tiền huấn luyện với lượng dữ liệu lớn, chúng mạnh mẽ với các cặp căn chỉnh không thường xuyên.

Sự khác biệt giữa căn chỉnh có ngữ cảnh và fast align về độ bao phủ của chúng rõ ràng nhất đối với từ ghép. Đối tác tiếng Đức của "non-tariff" tiếng Anh là "nichttarifäre". Trong khi căn chỉnh có ngữ cảnh căn chỉnh "nichttarifäre" với "non", sau đó được căn chỉnh với khái niệm "–" cho tính phân cực, fast align để "nichttarifäre" không được căn chỉnh. Sự khác biệt như vậy được thể hiện trong hiệu suất trình phân tích trên phủ định được thực hiện trong các hình thái học đa dạng. So sánh hiệu suất trình phân tích AMR1.0 trên phủ định giữa fast align (Baseline III trong Bảng 3) và căn chỉnh có ngữ cảnh (A.P trong Bảng 3), chúng tôi thấy rằng căn chỉnh có ngữ cảnh luôn vượt trội hơn fast align trong ba ngôn ngữ châu Âu đích, như được hiển thị trong Bảng 5.

8 Kết luận và hướng phát triển tương lai
Trong bài báo này, chúng tôi đề xuất sử dụng embedding từ đa ngôn ngữ dựa trên transformer để chiếu chú thích AMR. Chúng tôi cho thấy rằng quy trình đề xuất của chúng tôi đạt được kết quả cạnh tranh với một số phương pháp cổ điển để căn chỉnh văn bản-với-AMR. Chúng tôi áp dụng các kỹ thuật kết hợp cho căn chỉnh khái niệm và huấn luyện trình phân tích AMR, giúp cải thiện đáng kể hiệu suất so với các mô hình cơ sở. Chúng tôi cũng cung cấp phân tích lỗi chi tiết về phân tích AMR đa ngôn ngữ.

Cho embedding từ đa ngôn ngữ dựa trên transformer được tiền huấn luyện, căn chỉnh từ có ngữ cảnh chứng tỏ là một hướng hữu ích để vượt qua sự khác biệt giữa các ngôn ngữ và giải quyết bài toán AMR đa ngôn ngữ với giám sát yếu. Hơn nữa, quy trình chiếu chú thích của chúng tôi không chỉ đạt được hiệu suất cạnh tranh cao cho tiếng Đức, tiếng Tây Ban Nha, tiếng Ý và tiếng Trung mà còn cho phép học zero-shot cho các ngôn ngữ khác được bao gồm trong tập huấn luyện của transformer đa ngôn ngữ XLM-R cơ bản.

Công việc tương lai có thể bao gồm đa dạng hóa văn bản đầu vào sử dụng tạo sinh AMR2text (Mager et al., 2020) có thể giải quyết sự khác biệt trong kết quả giữa dữ liệu test được dịch máy và được dịch bởi con người. Tiềm năng của trình phân tích AMR để vượt qua sự phân kỳ dịch thuật cũng chỉ ra tính hữu ích của nó trong một hệ thống dịch đa ngôn ngữ đầu cuối, bỏ qua nhu cầu corpus song song có giám sát để huấn luyện hệ thống dịch máy.

Lời cảm ơn
Chúng tôi cảm ơn các nhà phản biện ẩn danh vì những gợi ý hữu ích. Chúng tôi cũng cảm ơn Revanth Reddy và Jason Furmanek vì những đóng góp đa dạng của họ.

Tài liệu tham khảo
Roee Aharoni, Melvin Johnson, và Orhan Firat. 2019. Massively multilingual neural machine translation. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 3874–3884, Minneapolis, Minnesota. Association for Computational Linguistics.

Rafael Anchiêta và Thiago Pardo. 2018. Towards AMR-BR: A SemBank for Brazilian Portuguese language. In Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018), Miyazaki, Japan. European Language Resources Association (ELRA).

--- TRANG 10 ---
Mikel Artetxe, Gorka Labaka, và Eneko Agirre. 2017. Learning bilingual word embeddings with (almost) no bilingual data. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 451–462, Vancouver, Canada. Association for Computational Linguistics.

Mikel Artetxe, Gorka Labaka, và Eneko Agirre. 2018. A robust self-learning method for fully unsupervised cross-lingual mappings of word embeddings. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 789–798, Melbourne, Australia. Association for Computational Linguistics.

Miguel Ballesteros và Yaser Al-Onaizan. 2017. AMR parsing using stack-LSTMs. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 1269–1275, Copenhagen, Denmark. Association for Computational Linguistics.

Laura Banarescu, Claire Bonial, Shu Cai, Madalina Georgescu, Kira Griffitt, Ulf Hermjakob, Kevin Knight, Philipp Koehn, Martha Palmer, và Nathan Schneider. 2013. Abstract Meaning Representation for sembanking. In Proceedings of the 7th Linguistic Annotation Workshop and Interoperability with Discourse, pages 178–186, Sofia, Bulgaria. Association for Computational Linguistics.

Rexhina Blloshmi, Rocco Tripodi, và Roberto Navigli. 2020. XL-AMR: Enabling cross-lingual AMR parsing with transfer learning techniques. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 2487–2500, Online. Association for Computational Linguistics.

Peter Brown, John Cocke, Stephen Della Pietra, Vincent Della Pietra, Frederick Jelinek, John Lafferty, Robert Mercer, và Paul Roossin. 1990. A statistical approach to machine translation. Computational Linguistics, Volume 16, Number 2, June 1990.

Peter Brown, Stephen Della Pietra, Vincent Della Pietra, và Robert Mercer. 1993. The mathematics of statistical machine translation: Parameter estimation. Computational Linguistics, Volume 19, Number 2.

Shu Cai và Kevin Knight. 2013. Smatch: an evaluation metric for semantic feature structures. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 748–752, Sofia, Bulgaria. Association for Computational Linguistics.

Steven Cao, Nikita Kitaev, và Dan Klein. 2020. Multilingual alignment of contextual word representations. In Proceedings of the 8th International conference on learning representations.

Wei-Te Chen và Martha Palmer. 2017. Unsupervised AMR-dependency parse alignment. In Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 1, Long Papers, pages 558–567, Valencia, Spain. Association for Computational Linguistics.

Alexis Conneau, Kartikay Khandelwal, Naman Goyal, Vishrav Chaudhary, Guillaume Wenzek, Francisco Guzmán, Edouard Grave, Myle Ott, Luke Zettlemoyer, và Veselin Stoyanov. 2019. Unsupervised cross-lingual representation learning at scale. arXiv preprint arXiv:1911.02116.

Alexis Conneau, Guillaume Lample, Marc'Aurelio Ranzato, Ludovic Denoyer, và Herve Jegou. 2018. Word translation without parallel data. In Proceedings of the 6th International conference on learning representations.

Marco Damonte và Shay B. Cohen. 2018. Cross-lingual Abstract Meaning Representation parsing. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers), pages 1146–1155, New Orleans, Louisiana. Association for Computational Linguistics.

Jacob Devlin, Ming-Wei Chang, Kenton Lee, và Kristina Toutanova. 2018. Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805.

Chris Dyer, Victor Chahuneau, và Noah A. Smith. 2013. A simple, fast, and effective reparameterization of IBM model 2. In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 644–648, Atlanta, Georgia. Association for Computational Linguistics.

Ramon Fernandez Astudillo, Miguel Ballesteros, Tahira Naseem, Austin Blodgett, và Radu Florian. 2020. Transition-based parsing with stack-transformers. In Findings of the EMNLP2020 (to appear).

Jeffrey Flanigan, Sam Thomson, Jaime Carbonell, Chris Dyer, và Noah A. Smith. 2014. A discriminative graph-based parser for the Abstract Meaning Representation. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1426–1436, Baltimore, Maryland. Association for Computational Linguistics.

Jan Hajič, Ondřej Bojar, và Zdeňka Urešová. 2014. Comparing Czech and English AMRs. In Proceedings of Workshop on Lexical and Grammatical Resources for Language Processing, pages 55–64, Dublin, Ireland. Association for Computational Linguistics và Dublin City University.

Paul R Kingsbury và Martha Palmer. 2002. From treebank to propbank. In LREC, pages 1989–1993. Citeseer.

--- TRANG 11 ---
Ioannis Konstas, Srinivasan Iyer, Mark Yatskar, Yejin Choi, và Luke Zettlemoyer. 2017. Neural AMR: Sequence-to-sequence models for parsing and generation. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 146–157, Vancouver, Canada. Association for Computational Linguistics.

Young-Suk Lee, Ramon Fernandez Astudillo, Tahira Naseem, Revanth Gangi Reddy, Radu Florian, và Salim Roukos. 2020. Pushing the limits of amr parsing with self-learning. In Findings of the EMNLP2020 (to appear).

Bin Li, Yuan Wen, Weiguang Qu, Lijun Bu, và Nianwen Xue. 2016. Annotating the little prince with Chinese AMRs. In Proceedings of the 10th Linguistic Annotation Workshop held in conjunction with ACL 2016 (LAW-X 2016), pages 7–15, Berlin, Germany. Association for Computational Linguistics.

Chunchuan Lyu và Ivan Titov. 2018. AMR parsing as graph prediction with latent alignment. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 397–407, Melbourne, Australia. Association for Computational Linguistics.

Manuel Mager, Ramón Fernandez Astudillo, Tahira Naseem, Md Arafat Sultan, Young-Suk Lee, Radu Florian, và Salim Roukos. 2020. Gpt-too: A language-model-first approach for amr-to-text generation. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, Seattle, USA. Association for Computational Linguistics.

Noelia Migueles-Abraira, Rodrigo Agerri, và Arantza Diaz de Ilarraza. 2018. Annotating Abstract Meaning Representations for Spanish. In Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018), Miyazaki, Japan. European Language Resources Association (ELRA).

Tomas Mikolov, Quoc V Le, và Ilya Sutskever. 2013. Exploiting similarities among languages for machine translation. arXiv preprint arXiv:1309.4168.

Tahira Naseem, Abhishek Shah, Hui Wan, Radu Florian, Salim Roukos, và Miguel Ballesteros. 2019. Rewarding Smatch: Transition-based AMR parsing with reinforcement learning. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 4586–4592, Florence, Italy. Association for Computational Linguistics.

Rik van Noord và Johan Bos. 2017. Neural semantic parsing by character-based translation: Experiments with abstract meaning representations. arXiv preprint arXiv:1705.09980.

Franz Josef Och và Hermann Ney. 2003. A systematic comparison of various statistical alignment models. Computational linguistics, 29(1):19–51.

Telmo Pires, Eva Schlinger, và Dan Garrette. 2019. How multilingual is multilingual bert? arXiv preprint arXiv:1906.01502.

Nima Pourdamghani, Yang Gao, Ulf Hermjakob, và Kevin Knight. 2014. Aligning English strings with Abstract Meaning Representation graphs. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 425–429, Doha, Qatar. Association for Computational Linguistics.

Sebastian Ruder, Iva Vulić, và Søgaard Anders. 2019. A survey of cross-lingual word embedding models. J. Artif. Int. Res., page 569–630.

Tal Schuster, Ori Ram, Regina Barzilay, và Amir Globerson. 2019. Cross-lingual alignment of contextual word embeddings, with applications to zero-shot dependency parsing. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 1599–1613, Minneapolis, Minnesota. Association for Computational Linguistics.

Samuel Smith, David Turban, Steven Hamblin, và Nils Hamerla. 2017. Offline bilingual word vectors, orthogonal transformations and the inverted softmax. In Proceedings of the 5th International conference on learning representations.

Marco Antonio Sobrevilla Cabezudo và Thiago Pardo. 2019. Towards a general Abstract Meaning Representation corpus for Brazilian Portuguese. In Proceedings of the 13th Linguistic Annotation Workshop, pages 236–244, Florence, Italy. Association for Computational Linguistics.

Lucy Vanderwende, Arul Menezes, và Chris Quirk. 2015. An AMR parser for English, French, German, Spanish and Japanese and a new AMR-annotated corpus. In Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Demonstrations, pages 26–30, Denver, Colorado. Association for Computational Linguistics.

Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan Gomez, Lukasz Kaiser, và Illia Polosukhin. 2017. Attention is all you need. arXiv preprint arXiv:1706.03762.

Nianwen Xue, Ondřej Bojar, Jan Hajič, Martha Palmer, Zdeňka Urešová, và Xiuhong Zhang. 2014. Not an interlingua, but close: Comparison of English AMRs to Chinese and Czech. In Proceedings of the Ninth International Conference on Language Resources and Evaluation (LREC'14), pages 1765–1772, Reykjavik, Iceland. European Language Resources Association (ELRA).

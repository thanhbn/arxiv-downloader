# 2304.01083.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/context-compression/2304.01083.pdf
# Kích thước tệp: 1306475 byte

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
Liệu Logic Suy luận của các Mô hình Ngôn ngữ Lớn có thể được Tách biệt thành
các Khái niệm Biểu tượng?
Wen Shen Lei Cheng Yuxiao Yang Mingjie Li Quanshi Zhang*
Đại học Giao thông Thượng Hải
Tóm tắt
Trong bài báo này, chúng tôi giải thích logic suy luận của các mô hình ngôn ngữ lớn (LLM) như một tập hợp các khái niệm biểu tượng. Nhiều nghiên cứu gần đây [4,9,10] đã phát hiện ra rằng các DNN truyền thống thường mã hóa các khái niệm biểu tượng thưa thớt. Tuy nhiên, vì một LLM có nhiều tham số hơn nhiều so với các DNN truyền thống, liệu LLM cũng mã hóa các khái niệm biểu tượng thưa thớt vẫn là một vấn đề chưa được giải quyết. Do đó, trong bài báo này, chúng tôi đề xuất tách biệt điểm số suy luận của LLM cho các tác vụ đối thoại thành một số lượng nhỏ các khái niệm biểu tượng. Chúng tôi xác minh rằng chúng ta có thể sử dụng những khái niệm thưa thớt đó để ước tính tốt tất cả điểm số suy luận của LLM trên tất cả các trạng thái che giấu tùy ý của câu đầu vào. Chúng tôi cũng đánh giá khả năng chuyển giao của các khái niệm được mã hóa bởi một LLM và xác minh rằng các khái niệm biểu tượng thường thể hiện khả năng chuyển giao cao qua các câu đầu vào tương tự. Quan trọng hơn, những khái niệm biểu tượng đó có thể được sử dụng để giải thích những lý do chính xác chịu trách nhiệm cho các lỗi dự đoán của LLM.

1. Giới thiệu
Trong những năm gần đây, các mô hình ngôn ngữ lớn (LLM), ví dụ như ChatGPT [8] và GPT-3 [1], đã thể hiện hiệu suất đáng chú ý. Mặc dù LLM đã được sử dụng để hướng dẫn mọi người trong các tác vụ quan trọng, như viết báo, phân tích báo cáo và tư vấn thông tin, logic suy luận của LLM vẫn không thể được con người hiểu đầy đủ.

Do đó, việc tạo ra một lời giải thích có thể chịu trách nhiệm cho điểm số suy luận của LLM là rất quan trọng đối với các quyết định có tầm quan trọng cao. Nói chung, một lời giải thích có thể chịu trách nhiệm cần phải thỏa mãn ba yêu cầu.

Các mẫu suy luận có thể đếm được. Việc chuyển đổi logic suy luận ngầm định của một LLM thành các mẫu suy luận rõ ràng và có thể đếm được là rất quan trọng để giải thích LLM. Cụ thể, người ta phát hiện rằng điểm số suy luận của một mạng nơ-ron sâu (DNN) trên câu đầu vào có thể được tách biệt thành các hiệu ứng của một số lượng nhỏ các mẫu suy luận (ví dụ, các cụm từ nhất định) [9,7]. Những mẫu suy luận này có thể được coi là các khái niệm được ghi nhớ bởi LLM, và chúng được cho là giải thích toàn cầu điểm số suy luận trên các câu khác nhau.

Được xác minh trong thực tế. Khi logic suy luận của một LLM được giải thích như một tập hợp các mẫu suy luận, tính trung thực hoặc độ chính xác của lời giải thích phải được đảm bảo cả về mặt lý thuyết và được xác minh trong các thí nghiệm.

Chịu trách nhiệm cho các lỗi. Khi một LLM đưa ra dự đoán không chính xác, điều quan trọng là phải làm rõ những lý do chính xác chịu trách nhiệm cho lỗi với một kết nối toán học rõ ràng giữa lý do và dự đoán không chính xác, thay vì cung cấp một lời giải thích có vẻ hợp lý.

Định nghĩa khái niệm trong DNN. Xem xét ba yêu cầu trên, Ren và cộng sự [9] đã cố gắng giải thích logic suy luận của một mạng nơ-ron như việc phát hiện các tương tác nổi bật giữa các biến đầu vào. Cụ thể, họ thấy rằng điểm số suy luận của mạng có thể được mô phỏng tốt bởi một số lượng nhỏ các tương tác nổi bật giữa các biến đầu vào. Cho một câu đầu vào với n từ được đánh chỉ số bởi N={1;2;...;n}, DNN không trực tiếp sử dụng một từ đầu vào duy nhất cho suy luận. Thay vào đó, DNN mã hóa các tương tác giữa các từ khác nhau như các mẫu suy luận (hoặc khái niệm) để tạo ra một điểm số suy luận v. Ví dụ, trong tác vụ phân loại, cho câu đầu vào "he is a green hand," tương tác giữa các từ S={green;hand}⊆N đóng góp một hiệu ứng tương tác cụ thể I(S), điều này đẩy điểm số suy luận của mạng về phía suy luận "he" có nghĩa là "beginner." Che giấu bất kỳ từ nào trong S sẽ loại bỏ hiệu ứng tương tác, tức là làm cho I(S) = 0.

*Quanshi Zhang là tác giả liên hệ. Ông thuộc Khoa Khoa học và Kỹ thuật Máy tính, Trung tâm John Hopcroft tại Đại học Giao thông Thượng Hải, Trung Quốc. <zqs1022@sjtu.edu.cn>
1arXiv:2304.01083v1 [cs.CL] 3 Apr 2023

--- TRANG 2 ---
Người ta đã phát hiện ra rằng trong số tất cả 2^n tương tác, một DNN thường chỉ mã hóa một số lượng nhỏ các tương tác nổi bật, và tất cả các tương tác khác có hiệu ứng có thể bỏ qua I(S)≈0 [9,7]. Theo cách này, chúng ta có thể coi những tương tác nổi bật này như các khái niệm (tức là các mẫu suy luận có thể đếm được), và coi các tương tác còn lại với hiệu ứng có thể bỏ qua như các mẫu nhiễu. Được truyền cảm hứng từ điều này, logic suy luận của một DNN có thể được giải thích như việc phát hiện một số lượng nhỏ các khái niệm. Nói cách khác, chúng ta có thể sử dụng một vài khái niệm tương tác nổi bật như vậy để ước tính tốt điểm số suy luận của DNN trên một số mũ của tất cả các câu được che giấu ngẫu nhiên. Quan trọng hơn, khi một DNN đưa ra dự đoán không chính xác, việc tách biệt rõ ràng các khái niệm tương tác từ DNN cho phép chúng ta xác định các khái niệm tương tác chính xác được mã hóa bởi DNN mà chịu trách nhiệm cho các lỗi. Ngoài ra, những khái niệm đó cũng đã thể hiện khả năng chuyển giao cao qua các mẫu khác nhau và các DNN khác nhau, và thể hiện sức mạnh phân biệt đáng kể trong các tác vụ phân loại [7].

Giải thích LLM bằng các khái niệm. Tuy nhiên, tất cả các phát hiện trên về việc sử dụng các khái niệm thưa thớt để mô phỏng logic của một DNN truyền thống đều được thu thập dựa trên các quan sát thực nghiệm trong các thí nghiệm mà không có bằng chứng vững chắc. Mặt khác, LLM thường có nhiều tham số hơn nhiều so với các DNN truyền thống, và LLM được huấn luyện trên nhiều dữ liệu hơn nhiều. Do đó, liệu một LLM có thể được giải thích như việc phát hiện một số lượng nhỏ các khái niệm vẫn chưa được biết.

Do đó, trong bài báo này, chúng tôi nhằm mục đích tách biệt điểm số suy luận của LLM cho đối thoại thành một số lượng nhỏ các khái niệm tương tác nổi bật. Cho một câu đầu vào, ví dụ như một câu hỏi hoặc một câu chưa hoàn thành, LLM tuần tự tạo ra các từ để trả lời câu hỏi hoặc để hoàn thành câu. Xem xét việc tạo ra từ tiếp theo, LLM lấy n từ trước đó làm đầu vào, và sau đó nó ước tính phân phối xác suất của việc tạo ra từ thứ (n+1). LLM lấy mẫu từ với xác suất cao nhất làm từ mục tiêu y_truth. Do đó, chúng tôi đặt v(x) = log p(y=y_truth|x)/(1-p(y=y_truth|x)) ∈ ℝ như điểm số suy luận của LLM, trong đó p(y=y_truth|x) biểu thị xác suất của việc tạo ra từ thứ (n+1) mục tiêu y_truth. Cụ thể, chúng tôi thu được ba kết luận sau.

1. Chúng tôi đã xác minh rằng cho một câu đầu vào, chúng ta có thể sử dụng một số lượng nhỏ các khái niệm để ước tính chính xác tất cả điểm số suy luận của LLM trên tất cả các trạng thái che giấu tùy ý của câu đầu vào. Cho một LLM được huấn luyện tốt cho đối thoại, chúng tôi định lượng các tương tác giữa các từ khác nhau trong câu đầu vào, và xác minh rằng điểm số đầu ra của việc tạo ra một từ cụ thể có thể được ước tính tốt bằng cách sử dụng một vài khái niệm tương tác. Hơn nữa, cho một câu đầu vào trong đó một số từ được che giấu ngẫu nhiên, chúng ta vẫn có thể sử dụng những khái niệm tương tác đó để ước tính tốt điểm số đầu ra của việc tạo ra từ tiếp theo.

2. Chúng tôi đã xác minh rằng các khái niệm tương tác được mã hóa bởi LLM thể hiện khả năng chuyển giao cao qua các câu đầu vào tương tự. Nói cách khác, cho các câu đầu vào tương tự, LLM thường sử dụng các khái niệm tương tác tương tự để tạo ra cùng một từ.

3. Chúng tôi đã xác minh rằng các khái niệm tương tác được tách biệt có thể giúp mọi người xác định những lý do chính xác cho lỗi dự đoán được thực hiện bởi LLM. Khi LLM tạo ra một từ sai vi phạm các sự kiện, chúng tôi tìm ra những khái niệm tương tác chịu trách nhiệm cho từ sai đó.

2. Xem xét lại tài liệu về các tương tác lý thuyết trò chơi để giải thích DNN

Bài báo này là một thành tựu điển hình trong hệ thống giải thích các tương tác lý thuyết trò chơi. Gần đây, nhóm nghiên cứu của chúng tôi đã xây dựng một hệ thống lý thuyết về việc sử dụng các tương tác lý thuyết trò chơi để giải thích các mô hình AI hộp đen trong ba khía cạnh sau.

Đầu tiên, chúng tôi sử dụng các tương tác lý thuyết trò chơi để giải thích kiến thức/khái niệm được mã hóa bởi một DNN. Trong một thời gian dài, việc định nghĩa các tương tác giữa các biến đầu vào của một DNN trong lý thuyết trò chơi đã đưa ra một hướng mới để giải thích một DNN [6,12]. Nhóm nghiên cứu của chúng tôi đã định nghĩa tương tác đa biến [15,17] và tương tác đa bậc [16] để đại diện cho các tương tác với độ phức tạp khác nhau. Chúng tôi cũng đã định nghĩa giá trị cơ sở tối ưu để đại diện cho sự vắng mặt của biến, đảm bảo độ tin cậy của các phương pháp gán dựa trên che giấu [10].

Mở rộng từ tương tác đến khái niệm. Đặc biệt, các nghiên cứu gần đây của nhóm chúng tôi [9,7] đã phát hiện ra rằng một DNN thường mã hóa các tương tác rất thưa thớt khi chúng tôi sử dụng các tương tác Harsanyi giữa các biến đầu vào của DNN. Những nghiên cứu này thực sự đã gợi ý rằng các tương tác lý thuyết trò chơi có thể được coi như các khái niệm được mã hóa bởi một DNN. Kết luận này đã được thu thập dựa trên ba phát hiện sau. (1) Người ta thấy rằng một DNN được huấn luyện tốt thường chỉ mã hóa một số lượng nhỏ các tương tác nổi bật, và mỗi tương tác tạo ra một hiệu ứng nhất định trên điểm số suy luận của DNN. (2) Người ta phát hiện ra rằng chúng ta có thể sử dụng một số lượng nhỏ các tương tác nổi bật như vậy để ước tính tốt điểm số suy luận của tất cả các mẫu đầu vào được che giấu tùy ý. (3) Người ta phát hiện ra rằng những tương tác nổi bật đó thường thể hiện khả năng chuyển giao mạnh qua các mẫu khác nhau và qua các DNN khác nhau, và những tương tác nổi bật này cũng thể hiện sức mạnh phân biệt mạnh.

Ba phát hiện trên có thể được coi là nền tảng để giải thích logic suy luận của một DNN như việc phát hiện các tương tác nổi bật giữa các biến đầu vào. Ví dụ, nhóm nghiên cứu của chúng tôi đã sử dụng tương tác đa biến để phát hiện các khái niệm thị giác nguyên mẫu được mã hóa bởi một DNN [3], và sử dụng tương tác đa bậc để phân tích các hành vi xử lý tín hiệu cụ thể của một DNN trong việc mã hóa hình dạng và kết cấu [2].

Thứ hai, chúng tôi sử dụng các tương tác lý thuyết trò chơi để điều tra sức mạnh đại diện của một DNN. Ví dụ, chúng tôi đã sử dụng tương tác đa bậc để giải thích sức mạnh tổng quát hóa của một DNN mang lại bởi hoạt động dropout [17], và để giải thích tính bền vững đối nghịch và khả năng chuyển giao đối nghịch của một DNN [13,14,9]. Deng và cộng sự [4] phát hiện ra rằng một DNN gặp khó khăn trong việc đại diện cho các tương tác giữa số lượng trung gian các biến đầu vào. Zhang và cộng sự [20] thấy rằng các tương tác phức tạp (tức là các tương tác giữa một số lượng lớn các biến đầu vào) có nhiều khả năng bị over-fit hơn. Hơn nữa, Ren và cộng sự [11] phát hiện ra rằng một mạng nơ-ron Bayesian (BNN) ít có khả năng mã hóa các tương tác phức tạp, điều này tránh được vấn đề overfitting.

Thứ ba, chúng tôi sử dụng các tương tác lý thuyết trò chơi để phân tích cơ chế chung được chia sẻ bởi nhiều phát hiện thực nghiệm. Deng và cộng sự [5] đã chứng minh rằng các cơ chế cốt lõi của mười bốn phương pháp gán có thể được tái công thức hóa như một sự phân phối lại các tương tác, điều này cho phép so sánh công bằng giữa các phương pháp gán được xây dựng dựa trên các phương pháp suy đoán khác nhau. Zhang và cộng sự [18] đã chứng minh cơ chế chung được chia sẻ bởi mười hai phương pháp tăng cường khả năng chuyển giao trước đó, đó là những phương pháp này đều giảm các tương tác giữa các nhiễu loạn đối nghịch khu vực.

3. Giải thích logic suy luận của các mô hình ngôn ngữ lớn

3.1. Kiến thức cơ bản: giải thích logic suy luận với các khái niệm tương tác

Gần đây, một loạt nghiên cứu [9,7] đã phát hiện ra rằng điểm số đầu ra của DNN có thể được phân tách thành các hiệu ứng số của các tương tác khác nhau giữa các biến đầu vào khác nhau, ví dụ như tương tác giữa các vùng khác nhau trong một hình ảnh đầu vào và tương tác giữa các từ khác nhau trong một câu đầu vào. Cụ thể, cho một DNN được huấn luyện trước v: ℝ^n → ℝ, hãy để x biểu thị mẫu đầu vào, có n biến được đánh chỉ số bởi N={1;2;...;n}. Không mất tính tổng quát, hãy chỉ tập trung vào một đầu ra vô hướng của DNN v(x) ∈ ℝ, ví dụ như một chiều của vector đầu ra. DNN thường mã hóa các tương tác giữa các biến khác nhau để suy luận. Mỗi tương tác có một đóng góp số vào đầu ra mạng v(x). Để kết thúc điều này, Ren và cộng sự [9] đã định nghĩa chỉ số sau để đo lường tương tác giữa các biến đầu vào trong S⊆N, được mã hóa bởi DNN.

I(S|x) ≜ ∑_{T⊆S} (-1)^{|S|-|T|} v(x_T) (1)

trong đó v(x_T) biểu thị đầu ra mạng khi chúng ta che giấu các biến trong N∖T và giữ các biến trong T không thay đổi.

Hiểu tương tác trong LLM cho tác vụ đối thoại. Cho một LLM được huấn luyện cho đối thoại, hãy hiểu tương tác được định nghĩa trong Phương trình (1). LLM tuần tự tạo ra các từ để hoàn thành câu đầu vào. Ví dụ, cho câu đầu vào "he is a green hand in painting means that", ChatGPT [8] hoàn thành câu đầu vào như sau, "he is a green hand in painting means that he is a beginner or novice in painting." Trong trường hợp này, LLM tạo ra các từ "he," "is," "a," "beginner," v.v., từng từ một. Do đó, khi LLM đã tạo ra n từ, được ký hiệu bởi x = [x_1; x_2; ...; x_n]^T, chúng tôi phân tích xác suất của LLM tạo ra từ thứ (n+1). Ví dụ, khi LLM đã tạo ra "he is a green hand in painting means that he is a," và sau đó chúng ta chèn câu này làm đầu vào x vào LLM. Sau đó, chúng tôi phân tích xác suất của LLM tạo ra từ mục tiêu y_truth = [beginner]. Điểm số suy luận của LLM tạo ra từ mục tiêu y_truth có thể được đưa ra như sau. Lưu ý rằng đối với các tác vụ khác nhau, v(x) có thể được áp dụng với các cài đặt khác nhau.

v(x) = log p(y=y_truth|x) / (1-p(y=y_truth|x)) (2)

Sau đó, tương ứng, v(x_T) trong Phương trình (1) tương ứng với điểm số suy luận khi chúng ta che giấu các từ trong N∖T trong câu đầu vào. Một LLM thường sử dụng token padding (ví dụ như token "PAD" được sử dụng bởi mô hình OPT-1.3b [19]) như một trình giữ chỗ, không chứa bất kỳ ý nghĩa ngữ nghĩa nào. Do đó, chúng tôi tạo ra câu được che giấu x_T bằng cách giữ các từ trong T không thay đổi và sử dụng token padding để che giấu các từ trong N∖T.

Theo cách này, tương tác I(S|x) giữa một tập hợp cụ thể các từ trong S có thể được hiểu là hiệu ứng của tương tác này đối với LLM tạo ra từ mục tiêu. I(S|x) > 0 cho thấy rằng tương tác giữa các từ trong S có hiệu ứng tích cực đối với việc tạo ra từ mục tiêu. I(S|x) < 0 cho thấy rằng tương tác ngăn cản LLM tạo ra từ mục tiêu. I(S|x) ≈ 0 cho thấy rằng tương tác gần như không có hiệu ứng đối với việc tạo ra từ mục tiêu.

Chính xác hơn, tương tác I(S|x) đại diện cho một mối quan hệ VÀ giữa các từ trong S. Trong ví dụ trên "he is a green hand in painting means that he is a beginner," hãy xem xét hai từ của S={green;hand} có hiệu ứng tương tác mạnh. Sau đó, chỉ khi cả hai từ "green" và "hand" cùng xuất hiện trong câu đầu vào, tương tác giữa S={green, hand} được kích hoạt và đóng góp một hiệu ứng số I(S|x) để đẩy LLM tạo ra từ "beginner."

--- TRANG 4 ---
[Hình 1. Tất cả các tương tác được sắp xếp theo thứ tự giảm dần của các giá trị |I(S|x)|. Mỗi hình con tương ứng với các tương tác của một câu đầu vào. Nó cho thấy rằng chỉ có một số lượng nhỏ các tương tác có hiệu ứng nổi bật trên đầu ra của LLM, và tất cả các tương tác khác có hiệu ứng có thể bỏ qua trên đầu ra của LLM.]

Nếu không, nếu bất kỳ từ nào trong S bị che giấu, thì đầu ra của LLM sẽ không nhận được hiệu ứng của tương tác này, tức là làm cho I(S|x) = 0.

Khớp thưa thớt nhưng toàn cầu. Cho một DNN v và một mẫu đầu vào x với n biến, chúng ta có thể tạo ra 2^n mẫu được che giấu khác nhau {x_S | S⊆N}. Định lý 1 cho thấy rằng chúng ta có thể sử dụng các tương tác được định nghĩa trong Phương trình (1) để mô phỏng toàn cầu các đầu ra của DNN trên tất cả 2^n mẫu được che giấu. Để đơn giản, chúng tôi sử dụng I_T để đại diện cho I(T|x).

Định lý 1. (Tính trung thực, được chứng minh bởi Ren và cộng sự [9]) Các đầu ra của DNN trên tất cả các mẫu được che giấu {x_S | S⊆N} có thể được mô phỏng toàn cầu như tổng của các hiệu ứng tương tác được kích hoạt, tức là ∀S⊆N; v(x_S) = ∑_{T⊆S} I_T.

Hơn nữa, Ren và cộng sự [7] đã phát hiện ra rằng các DNN được huấn luyện tốt thường mã hóa các tương tác thưa thớt (xem Nhận xét 2). Nói cách khác, chỉ có một vài tương tác có ảnh hưởng nổi bật đến các đầu ra của DNN, tức là các giá trị |I(S|x)| của những tương tác này tương đối lớn. Ngược lại, tất cả các tương tác khác có hiệu ứng có thể bỏ qua trên các đầu ra của DNN, tức là I(S|x) ≈ 0, và có thể được coi là các mẫu nhiễu. Do đó, chúng ta có thể sử dụng một vài tương tác nổi bật với hiệu ứng không thể bỏ qua để ước tính tốt các đầu ra của DNN trên tất cả 2^n mẫu được che giấu khác nhau, như sau, điều này đảm bảo về mặt lý thuyết tính trung thực của lời giải thích.

Nhận xét 2. (Tính thưa thớt) Các đầu ra của DNN trên tất cả các mẫu được che giấu {x_S | S⊆N} có thể được ước tính tốt bởi một vài tương tác nổi bật trong Ω_salient, với điều kiện |Ω_salient| ≪ 2^n, tức là ∀S⊆N; v(x_S) ≈ ∑_{T∈Ω_salient, T⊆S} I_T.

Theo Định lý 1 và Nhận xét 2, chúng ta có thể coi những tương tác thưa thớt nổi bật đó như các khái niệm biểu tượng được mã hóa bởi DNN. Ví dụ, tương tác nổi bật giữa hai từ trong S={green;hand} có thể được coi là một khái niệm, có ý nghĩa ngữ nghĩa của "beginner."

Khả năng chuyển giao và sức mạnh phân biệt của các khái niệm biểu tượng được mã hóa bởi DNN. Li và cộng sự [7] đã phát hiện ra rằng nhiều tương tác nổi bật được trích xuất từ một mẫu cũng có thể được tìm thấy như các tương tác nổi bật trong một mẫu khác trong cùng một danh mục, tức là các tương tác nổi bật có khả năng chuyển giao đáng kể qua các mẫu khác nhau trong cùng một danh mục. Bên cạnh đó, những tương tác thưa thớt nổi bật đó cũng thể hiện sức mạnh phân biệt nhất định trong tác vụ phân loại. Đó là, cùng một tương tác thường có hiệu ứng tích cực nhất quán hoặc hiệu ứng tiêu cực nhất quán đối với việc phân loại các mẫu khác nhau trong cùng một danh mục.

3.2. Khám phá các khái niệm được đại diện bởi LLM

Trong phần này, chúng tôi đã tiến hành các thí nghiệm để chẩn đoán các biểu diễn đặc trưng được mã hóa bởi LLM.

Thí nghiệm 1: liệu điểm số suy luận của LLM có thể được tách biệt thành các khái niệm biểu tượng? Các nghiên cứu trước đây đã phát hiện ra rằng các DNN truyền thống thường mã hóa các khái niệm biểu tượng thưa thớt. Tuy nhiên, LLM có nhiều tham số hơn nhiều so với các DNN truyền thống. Có hai hiểu biết mâu thuẫn về LLM. 1. LLM mã hóa các khái niệm phức tạp hơn nhiều so với các DNN truyền thống do số lượng tham số lớn của nó, hoặc 2. thay vào đó, LLM mã hóa các khái niệm thưa thớt hơn, vì LLM thường được huấn luyện một cách tinh vi hơn và do đó học được các đặc trưng rõ ràng hơn nhiều.

Do đó, trong nghiên cứu này, chúng tôi tiếp tục kiểm tra liệu LLM với nhiều tham số hơn nhiều so với các DNN truyền thống cũng mã hóa các khái niệm biểu tượng thưa thớt.

Chúng tôi đầu tiên hình dung phân phối của các hiệu ứng tương tác của các khái niệm khác nhau được mã hóa bởi LLM để kiểm tra tính thưa thớt của các khái niệm. Ngoài ra, chúng tôi cũng kiểm tra tuyên bố trong Nhận xét 2 rằng chúng ta có thể sử dụng những khái niệm thưa thớt đó để ước tính tốt các đầu ra của LLM trên tất cả các mẫu được che giấu ngẫu nhiên. Cụ thể, chúng tôi theo [9] để trích xuất một vài khái niệm được mã hóa bởi LLM. Sau đó, cho một câu được che giấu ngẫu nhiên x_S, S⊆N, chúng tôi so sánh đầu ra thực v_real(x_S) và đầu ra v_approx(x_S) được xấp xỉ bởi các khái niệm được trích xuất trong Nhận xét 2. Nếu các khái niệm được trích xuất khớp tốt với các đầu ra của LLM trên tất cả các câu được che giấu, thì chúng ta có thể coi rằng điểm số suy luận của LLM có thể được giải thích một cách trung thực bởi các khái niệm biểu tượng.

Để kết thúc điều này, chúng tôi đã tiến hành các thí nghiệm trên mô hình OPT-1.3b [19] như LLM mục tiêu, chứa 1,3 tỷ tham số. Chúng tôi đã sử dụng LLM để tạo ra một tập hợp các câu đầu vào để xây dựng tập câu kiểm tra, bao gồm kiến thức thực tế trong vật lý, y học, nghệ thuật, học máy, v.v. Sau đó, đối với mỗi câu kiểm tra, chúng tôi phân tích xác suất của LLM tạo ra từ thứ (n+1) y_truth, khi LLM lấy câu x với n từ đã được tạo ra làm đầu vào. Cụ thể, chúng tôi đã sử dụng phương pháp trong [7] để định lượng tương tác I(S|x) như hiệu ứng của khái niệm S⊆N đối với việc tạo ra từ mục tiêu (tối ưu) y_truth. Hình 1 cho thấy tất cả các hiệu ứng tương tác của suy luận của LLM trên các câu đầu vào khác nhau. Nó cho thấy rằng chỉ có một vài tương tác nổi bật (tức là các khái niệm) được trích xuất từ một câu đầu vào, và tất cả các tương tác khác có hiệu ứng có thể bỏ qua trên đầu ra của LLM.

Bên cạnh đó, chúng tôi đã sử dụng phương pháp trong [9,7] để tạo ra 50, 100, 150 và 200 tương tác hàng đầu, tương ứng, như bốn tập hợp khái niệm khác nhau để giải thích LLM. Sau đó, cho mỗi câu x, chúng tôi xây dựng một tập kiểm tra với tất cả 2^n câu được che giấu x_S bằng cách lấy mẫu các tập từ khác nhau S.

Để xác minh liệu các khái niệm được trích xuất có khớp tốt với đầu ra thực v_real(x_S), chúng tôi đo độ lệch chuẩn của các lỗi xấp xỉ. Hãy để v_real = [v_real(x_{S1}); v_real(x_{S2}); ...; v_real(x_{S2^n})]^T ∈ ℝ^{2^n} biểu thị vector của các đầu ra của LLM trên tất cả 2^n câu được che giấu, được sắp xếp theo thứ tự tăng dần. tức là v_real(x_{S1}) ≤ v_real(x_{S2}) ≤ ... ≤ v_real(x_{S2^n}). Sau đó, hãy để v_approx = [v_approx(x_{S1}); v_approx(x_{S2}); ...; v_approx(x_{S2^n})]^T ∈ ℝ^{2^n} biểu thị vector của các đầu ra được xấp xỉ bởi các khái niệm được trích xuất dựa trên Nhận xét 2. Theo cách này, v_real(x_{Si}) - v_approx(x_{Si}) đại diện cho lỗi khớp của câu được che giấu thứ i. Đối với mỗi đầu ra mô hình v_real(x_{Si}), chúng tôi tính toán lỗi bình phương trung bình (RMSE) của các lỗi khớp của 50 câu lân cận error_i = √(1/(2t+1) ∑_{j=i-t}^{i+t} (v_i - v_i)^2) để đánh giá chất lượng khớp.

Hình 2 báo cáo các đầu ra thực v_real(x_S) và các giá trị RMSE tương ứng trên tất cả các câu được che giấu. Nó cho thấy rằng các đầu ra được xấp xỉ khớp tốt với các đầu ra thực trên các câu được che giấu khác nhau. Điều này đã chứng minh rằng đầu ra của

--- TRANG 5 ---
[Hình 2. Đầu ra mô hình trên các mẫu được che giấu khác nhau (được sắp xếp theo thứ tự tăng dần). Vùng tô màu đại diện cho lỗi bình phương trung bình (RMSE) của việc sử dụng các khái niệm hàng đầu để khớp với đầu ra mô hình thực. Độ lệch thường giảm khi chúng tôi sử dụng nhiều khái niệm hơn để khớp với đầu ra mô hình.]

mô hình OPT-1.3b có thể được giải thích như các khái niệm biểu tượng thưa thớt.

Thí nghiệm 2: khả năng chuyển giao của các khái niệm biểu tượng được mã hóa bởi LLM. Bên cạnh tính thưa thớt của các khái niệm biểu tượng, chúng tôi cũng phân tích khả năng chuyển giao của các khái niệm, được coi là một tính chất quan trọng khác của các khái niệm. Nếu một khái niệm biểu tượng S được trích xuất từ một câu cũng có hiệu ứng đáng kể đối với các đầu ra của LLM trên các câu khác, thì khái niệm biểu tượng được coi là có thể chuyển giao.

Do đó, chúng tôi đã tiến hành các thí nghiệm để kiểm tra khả năng chuyển giao của các khái niệm trên mô hình OPT-1.3b. Chúng tôi đầu tiên thu thập các tập câu khác nhau được tạo ra bởi LLM. Tất cả các câu trong cùng một tập đều chứa cùng một từ y_truth. Chúng tôi nhằm mục đích kiểm tra liệu tất cả các từ x^(i) trước y_truth trong câu thứ i có chia sẻ logic tương tự. Ví dụ, câu x^(1) = "Diabetes is a disease that affects the body's ability to use" và câu x^(2) = "Diabetes is a condition that impairs the body's ability to use" được cho là chia sẻ cùng logic để đẩy LLM tạo ra từ y_truth = "glucose."

Theo cách này, chúng tôi định nghĩa khả năng chuyển giao của các khái niệm giữa các câu x^(1) và x^(2) như sự tương tự giữa phân phối của các khái niệm được trích xuất từ hai câu này. Hãy để N^(1) và N^(2) biểu thị các tập hợp của tất cả các từ trong x^(1) và x^(2), tương ứng. Sau đó, N_same = N^(1) ∩ N^(2) biểu thị tập hợp các từ được chia sẻ bởi hai câu. Sau đó, chúng tôi theo Li và cộng sự [7] để trích xuất M tương tác nổi bật hàng đầu từ câu đầu tiên x^(1), tức là tập hợp M tương tác có các giá trị |I(S|x)| lớn nhất, được ký hiệu bởi Ω^(1)_salient. Tương tự, Ω^(2)_salient biểu thị tập hợp M khái niệm nổi bật hàng đầu được trích xuất từ câu thứ hai x^(2). Để tính toán sự tương tự giữa các khái niệm trong Ω^(1)_salient và Ω^(2)_salient, chúng tôi xây dựng vector I^(1) = [I^(1)_{S1}; I^(1)_{S2}; ...; I^(1)_{Sd}; Ĩ^(1)_{S1}; Ĩ^(1)_{S2}; ...; Ĩ^(1)_{Sd}] ∈ ℝ^{2d} và vector I^(2) = [I^(2)_{S1}; I^(2)_{S2}; ...; I^(2)_{Sd}; Ĩ^(2)_{S1}; Ĩ^(2)_{S2}; ...; Ĩ^(2)_{Sd}] ∈ ℝ^{2d}, trong đó S1; S2; ...; Sd đại diện cho tất cả d = 2^{|N_same|} tương tác giữa các từ trong N_same. Nếu St ∈ Ω^(1)_salient, chúng tôi đặt I^(1)_{St} = max(I(St|x); 0) và Ĩ^(1)_{St} = min(I(St|x); 0); ngược lại, chúng tôi đặt I^(1)_{St} = Ĩ^(1)_{St} = 0. Sau đó, sự tương tự của phân phối khái niệm giữa x^(1) và x^(2) được đưa ra như sự tương tự Jaccard giữa I^(1) và I^(2), tức là sim(I^(1); I^(2)) = ||min(I^(1); I^(2))||_1 / ||max(I^(1); I^(2))||_1. Do đó, một sự tương tự cao sim(I^(1); I^(2)) cho thấy rằng hầu hết các khái niệm được chia sẻ bởi các câu x^(1) và x^(2) có khả năng chuyển giao đáng kể.

Bảng 1 báo cáo sim(I^(1); I^(2)) trung bình trên các cặp câu khác nhau (x^(1); x^(2)). Kết quả cho thấy rằng các khái niệm nổi bật hàng đầu thường thể hiện khả năng chuyển giao tương đối đáng kể.

Thí nghiệm 3: sức mạnh phân biệt của các khái niệm biểu tượng được mã hóa bởi LLM. Về mặt lý tưởng, một khái niệm biểu tượng trung thực được cho là đẩy LLM tạo ra câu phù hợp với kiến thức thực tế. Do đó, Bảng 2 cho thấy các khái niệm có hiệu ứng đáng kể nhất đối với suy luận của LLM. Kết quả cho thấy rằng hầu hết các khái niệm đều nhất quán với

--- TRANG 6 ---
Bảng 1. Sự tương tự giữa phân phối của các khái niệm được trích xuất từ các câu khác nhau. M biểu thị số lượng khái niệm được trích xuất từ mỗi câu.

M = 5 | M = 10 | M = 15 | M = 20 | M = 25 | M = 30
sim(I^(1); I^(2)) trung bình | 0.565±0.202 | 0.528±0.205 | 0.476±0.184 | 0.454±0.183 | 0.433±0.179 | 0.416±0.173

Bảng 2. Các khái niệm biểu tượng được trích xuất từ các câu đầu vào trong LLM.

Câu 1: Não người chứa khoảng 100 tỷ tế bào thần kinh, | Câu 2: Lực cần thiết để gia tốc một vật thể tỷ lệ thuận
giao tiếp với nhau thông qua điện và | với khối lượng và gia tốc của nó, như được mô tả bởi định luật của
Từ được dự đoán: hóa học | Từ được dự đoán: chuyển động

Khái niệm S | Hiệu ứng suy luận I(S|x) | Khái niệm S | Hiệu ứng suy luận I(S|x)
{điện, và} | 4.82 | {định luật} | 5.99
{điện} | 3.46 | {Newton} | 3.73
{thông qua, điện, và} | -2.37 | {Newton, định luật} | 1.10
{não} | 1.11 | {gia tốc} | 0.86
{não, điện, và} | 1.08 | {lực} | 0.61

Câu 3: Virus viêm gan B là một virus truyền qua đường máu có tính lây nhiễm cao | Câu 4: Định luật chuyển động của Newton nói rằng một vật thể sẽ đứng yên
có thể gây ra nghiêm trọng | hoặc chuyển động đều trong một đường thẳng
Từ được dự đoán: gan | Từ được dự đoán: đường

Khái niệm S | Hiệu ứng suy luận I(S|x) | Khái niệm S | Hiệu ứng suy luận I(S|x)
{nghiêm trọng} | 4.54 | {thẳng} | 9.65
{viêm gan B} | 3.99 | {định luật, thẳng} | 0.62
{viêm gan B, virus, cao, lây nhiễm, máu, gây ra} | 1.49 | {Newton, thẳng} | 0.48
{gây ra} | 1.32 | {vật thể, thẳng} | 0.37
{viêm gan B, nghiêm trọng} | 1.13 | {vật thể, đứng yên, thẳng} | -0.35

nhận thức của con người.

Thí nghiệm 4: kiểm tra những lý do chính xác chịu trách nhiệm cho các lỗi dự đoán của LLM. Việc kiểm tra những lý do chính xác tại sao một LLM tạo ra một câu trái ngược với sự thật là cơ sở để gỡ lỗi LLM. Như đã được chứng minh trong Thí nghiệm 1, điểm số suy luận của một LLM có thể được tách biệt thành một vài khái niệm biểu tượng. Do đó, trong bài báo này, chúng tôi đã trích xuất những lý do chính xác chịu trách nhiệm cho các lỗi trong các câu được tạo ra. Ví dụ, như được hiển thị trong Bảng 3, LLM đã tạo ra câu "Nhà vật lý Isaac Newton sinh năm 1642 tại làng Newton," trong đó "tại làng Newton" trái ngược với sự thật là "tại Woolsthorpe-by-Colsterworth." Sau đó, chúng tôi phân tích lý do tại sao LLM tạo ra từ thứ (n+1) trái ngược với sự thật, được ký hiệu bởi y_counter. Chúng tôi trích xuất tất cả các khái niệm có hiệu ứng đáng kể nhưng tích cực đối với việc tạo ra y_counter, tức là S ∈ Ω_salient; I(S|x) > 0, như những lý do chịu trách nhiệm cho lỗi. Bảng 3 cho thấy hai ví dụ về các lỗi dự đoán của mô hình OPT-1.3b. Trong ví dụ đầu tiên, khái niệm {Newton} (tên một người) tạo ra hiệu ứng lớn nhất đối với lỗi dự đoán của LLM là "Newton" (tên một địa điểm), nhưng câu trả lời đúng là "Woolsthorpe-by-Colsterworth." Có thể là do mô hình OPT-1.3b chưa học tiểu sử, nên không thể trả lời những câu hỏi như vậy. Trong ví dụ thứ hai, khái niệm {Drake} tạo ra hiệu ứng lớn nhất đối với lỗi dự đoán của mô hình OPT-1.3b là "Drake," nhưng câu trả lời đúng là "Mike." Chúng tôi phát hiện ra rằng chính ký hiệu xuống dòng "nn" đã ảnh hưởng đến việc mã hóa từ "Mike" của mô hình OPT-1.3b. Không có ký hiệu xuống dòng "nn," mô hình OPT-1.3b sẽ mã hóa khái niệm {Mike} và tạo ra từ "Mike."

4. Kết luận

Trong bài báo này, chúng tôi đã phân tích các khái niệm biểu tượng được mã hóa bởi một LLM cho đối thoại. Cụ thể, chúng tôi đã xác minh thực nghiệm rằng điểm số suy luận của một LLM có thể được tách biệt thành một số lượng nhỏ các khái niệm. Những khái niệm biểu tượng đó thường thể hiện khả năng chuyển giao cao và thể hiện sức mạnh phân biệt nhất định. Quan trọng hơn, chúng tôi cũng đã sử dụng những khái niệm biểu tượng đó để giải thích các lỗi dự đoán của một LLM.

Tài liệu tham khảo
[1] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, và cộng sự. Language models are few-shot learners. Advances in neural information processing systems, 33:1877–1901, 2020. 1

[2] Xu Cheng, Chuntung Chu, Yi Zheng, Jie Ren, và Quanshi Zhang. A game-theoretic taxonomy of visual concepts in dnns. arXiv preprint arXiv:2106.10938, 2021. 3

[3] Xu Cheng, Xin Wang, Haotian Xue, Zhengyang Liang, và Quanshi Zhang. A hypothesis for the aesthetic appreciation in neural networks. arXiv preprint arXiv:2108.02646, 2021. 3

[4] Huiqi Deng, Qihan Ren, Hao Zhang, và Quanshi Zhang. Discovering and explaining the representation bottleneck of dnns. In International Conference on Learning Representations, 2022. 1, 3

[5] Huiqi Deng Deng, Na Zou, Mengnan Du, Weifu Chen, Guocan Feng, Ziwei Yang, Zheyang Li, và Quanshi Zhang. Understanding and unifying fourteen attribution methods with taylor interactions. arXiv preprint, 2022. 3

[6] Michel Grabisch và Marc Roubens. An axiomatic approach to the concept of interaction among players in cooperative games. International Journal of game theory, 28:547–565, 1999. 2

--- TRANG 7 ---
Bảng 3. Các khái niệm biểu tượng chịu trách nhiệm cho các lỗi dự đoán của LLM.

Câu 1: Nhà vật lý Isaac Newton sinh tại làng | Câu 2: nn Mẹ của Mike có 3 con; 2 trong số họ là Luis và Drake.
Từ được dự đoán: Newton | Tên của đứa con còn lại là
 | Từ được dự đoán: Drake

Khái niệm S | Hiệu ứng suy luận I(S|x) | Khái niệm S | Hiệu ứng suy luận I(S|x)
{Newton} | 6.26 | {Drake} | 6.94
{làng, của} | 1.57 | {tên} | 1.15
{Nhà vật lý} | 1.29 | {con, Drake} | 0.64
{của} | 1.18 | {là, Luis} | 0.58
{làng} | 1.02 | {mẹ, Drake} | 0.42

[7] Mingjie Li và Quanshi Zhang. Does a neural network really encode symbolic concept? arXiv preprint arXiv:2302.13080, 2023. 1, 2, 3, 4, 5, 6

[8] OpenAI. Chatgpt: Openai's conversational ai language model. https://openai.com/blog/chatgpt/, 2022. Truy cập: 2022-10-14. 1, 3

[9] Jie Ren, Mingjie Li, Qirui Chen, Huiqi Deng, và Quanshi Zhang. Defining and quantifying the emergence of sparse concepts in dnns. IEEE Conference on Computer Vision and Pattern Recognition, 2023. 1, 2, 3, 4, 5

[10] Jie Ren, Zhanpeng Zhou, Qirui Chen, và Quanshi Zhang. Can we faithfully represent masked states to compute shapley values on a dnn? In International Conference on Learning Representations, 2023. 1, 2

[11] Qihan Ren, Huiqi Deng, Yunuo Chen, Siyu Lou, và Quanshi Zhang. Bayesian neural networks tend to ignore complex and sensitive concepts. arXiv preprint arXiv:2302.13095, 2023. 3

[12] Mukund Sundararajan, Kedar Dhamdhere, và Ashish Agarwal. The shapley taylor interaction index. In International conference on machine learning, pages 9259–9268. PMLR, 2020. 2

[13] Xin Wang, Shuyun Lin, Hao Zhang, Yufei Zhu, và Quanshi Zhang. Interpreting attributions and interactions of adversarial attacks. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 1095–1104, 2021. 3

[14] Xin Wang, Jie Ren, Shuyun Lin, Xiangming Zhu, Yisen Wang, và Quanshi Zhang. A unified approach to interpreting and boosting adversarial transferability. In International Conference on Learning Representations, 2021. 3

[15] Die Zhang, Hao Zhang, Huilin Zhou, Xiaoyi Bao, Da Huo, Ruizhao Chen, Xu Cheng, Mengyue Wu, và Quanshi Zhang. Building interpretable interaction trees for deep nlp models. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 35, pages 14328–14337, 2021. 2

[16] Hao Zhang, Sen Li, YinChao Ma, Mingjie Li, Yichen Xie, và Quanshi Zhang. Interpreting and boosting dropout from a game-theoretic view. In International Conference on Learning Representations, 2021. 2

[17] Hao Zhang, Yichen Xie, Longjie Zheng, Die Zhang, và Quanshi Zhang. Interpreting multivariate shapley interactions in dnns. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 35, pages 10877–10886, 2021. 2, 3

[18] Quanshi Zhang, Xin Wang, Jie Ren, Xu Cheng, Shuyun Lin, Yisen Wang, và Xiangming Zhu. Proving common mechanisms shared by twelve methods of boosting adversarial transferability. arXiv preprint arXiv:2207.11694, 2022. 3

[19] Susan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui Chen, Christopher Dewan, Mona Diab, Xian Li, Xi Victoria Lin, và cộng sự. Opt: Open pre-trained transformer language models. arXiv preprint arXiv:2205.01068, 2022. 3, 5

[20] Huilin Zhou, Hao Zhang, Huiqi Deng, Dongrui Liu, Wen Shen, Shih-Han Chan, và Quanshi Zhang. Concept-level explanation for the generalization of a dnn. arXiv preprint arXiv:2302.13091, 2023. 3

--- TRANG 8 ---
8

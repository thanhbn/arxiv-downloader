# 2305.11862.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/context-compression/2305.11862.pdf
# Kích thước tệp: 628024 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Giảm Độ Dài Chuỗi bằng Dự đoán Khoảng Chỉnh sửa với Mô hình Ngôn ngữ Lớn
Masahiro Kaneko1,2 Naoaki Okazaki2
1MBZUAI
2Viện Công nghệ Tokyo
Masahiro.Kaneko@mbzuai.ac.ae okazaki@c.titech.ac.jp
Tóm tắt
Các Mô hình Ngôn ngữ Lớn (LLM) đã thể hiện hiệu suất đáng chú ý trong nhiều tác vụ khác nhau và thu hút sự chú ý đáng kể. LLM cũng được sử dụng cho các tác vụ chuyển đổi chuỗi cục bộ, bao gồm sửa lỗi ngữ pháp (GEC) và chuyển đổi phong cách trang trọng, trong đó hầu hết các token trong văn bản nguồn được giữ nguyên. Tuy nhiên, các mô hình tạo ra tất cả token đích trong những tác vụ như vậy có xu hướng đơn giản chỉ sao chép văn bản đầu vào nguyên vẹn, mà không thực hiện những thay đổi cần thiết, bởi vì sự khác biệt giữa văn bản đầu vào và đầu ra là tối thiểu trong dữ liệu huấn luyện. Điều này cũng không hiệu quả vì chi phí tính toán tăng theo bậc hai với độ dài chuỗi đích với Transformer. Bài báo này đề xuất dự đoán các khoảng chỉnh sửa cho văn bản nguồn đối với các tác vụ chuyển đổi chuỗi cục bộ. Biểu diễn một khoảng chỉnh sửa với vị trí của văn bản nguồn và các token đã được sửa, chúng ta có thể giảm độ dài của chuỗi đích và chi phí tính toán cho suy luận. Chúng tôi áp dụng điều chỉnh theo hướng dẫn cho LLM trên dữ liệu giám sát của các khoảng chỉnh sửa. Các thí nghiệm cho thấy phương pháp đề xuất đạt được hiệu suất tương đương với đường cơ sở trong bốn tác vụ: diễn giải lại, chuyển đổi phong cách trang trọng, GEC và đơn giản hóa văn bản, mặc dù giảm độ dài của văn bản đích chỉ còn 21%. Hơn nữa, chúng tôi báo cáo rằng việc tinh chỉnh theo tác vụ cụ thể với phương pháp đề xuất đã đạt được hiệu suất tiên tiến nhất trong bốn tác vụ.

1 Giới thiệu
Các Mô hình Ngôn ngữ Lớn (LLM), bao gồm ChatGPT1 và Bard2, đã thể hiện hiệu suất đặc biệt trong một loạt các tác vụ xử lý ngôn ngữ tự nhiên (NLP) và thu hút một lượng người dùng đáng kể (Brown et al., 2020; Chowdhery et al., 2022; OpenAI, 2023). Khi lợi ích hiệu suất được mang lại từ sự gia tăng kích thước mô hình (Kaplan et al., 2020; Wei et al., 2022; Zhao et al., 2023), LLM đang trở nên ngày càng lớn hơn. Tuy nhiên, chi phí tính toán của suy luận là một nút thắt cổ chai nghiêm trọng của nhiều ứng dụng thực tế, đặc biệt khi số lượng tham số trong LLM là khổng lồ (Bender et al., 2021; Kraus et al., 2023).

Trong khi đó, LLM cũng được sử dụng cho các tác vụ chuyển đổi chuỗi cục bộ, chẳng hạn như diễn giải lại, chuyển đổi phong cách trang trọng, Sửa lỗi Ngữ pháp (GEC), và đơn giản hóa (Kaneko et al., 2022; Reif et al., 2022; Wu et al., 2023a; Wang et al., 2022; Kaneko và Okazaki, 2023), trong đó chỉ một phần nhỏ của văn bản nguồn được chỉnh sửa. Hầu hết các token trong văn bản nguồn được giữ nguyên trong những tác vụ này. Ví dụ, văn bản nguồn "Many years ago, the situation is different," và văn bản đích "Many years ago, the situation was different," của tác vụ GEC chủ yếu chia sẻ các token chung ngoại trừ các token được gạch chân (is và was).

Các phương pháp hiện có của các tác vụ hạ nguồn không tận dụng các đặc điểm của chuyển đổi chuỗi cục bộ (Reif et al., 2022; Wu et al., 2023a; Wang et al., 2022), đơn giản tạo ra tất cả token đích. Trong bài báo này, chúng tôi đưa ra giả thuyết rằng cách xử lý này là bất lợi trong việc đạt được hiệu suất cao về độ chính xác tác vụ và thời gian tính toán. Cụ thể hơn, việc tạo ra các token không thay đổi (ví dụ: Many, years, ago, the, situation, different) trong ví dụ trước là không hiệu quả vì mô hình phải sao chép nhiều token nguồn chỉ để tăng độ dài của chuỗi đích.

Nghiên cứu này đề xuất dự đoán một tập hợp các khoảng chỉnh sửa, đại diện cho các phần đã thay đổi của văn bản đích so với các token nguồn. Bỏ qua các token chưa chỉnh sửa chiếm phần lớn văn bản đích, chúng ta có thể giảm độ dài của văn bản đích và thời gian suy luận cho các tác vụ chuyển đổi chuỗi cục bộ. Hình 1 cho thấy quy trình tạo một tập hợp các khoảng chỉnh sửa từ văn bản nguồn và đích trong GEC. Đầu tiên, chúng tôi căn chỉnh các token trong văn bản nguồn và đích để trích xuất các vị trí và token chỉnh sửa và chuyển đổi chúng thành một tập hợp các khoảng chỉnh sửa. Trong ví dụ được hiển thị arXiv:2305.11862v2 [cs.CL] 21 Oct 2023

--- TRANG 2 ---
Hình 1: Suy luận của LLM được điều chỉnh theo hướng dẫn sử dụng khoảng chỉnh sửa. LLM nhận văn bản hướng dẫn và văn bản nguồn làm đầu vào và chỉ xuất ra các vị trí và token để viết lại. Việc chuyển đổi dựa trên quy tắc áp dụng các vị trí và token được xuất ra của việc viết lại vào văn bản nguồn và tạo ra đầu ra văn bản thuần túy.

trong Hình 1, các khoảng chỉnh sửa (1, 1, " the"), (8, 9, " have been "), (12, 13, "") được tạo từ văn bản nguồn "Through thousands of years, most Chinese scholars are greatly affected by the Confucianism." và văn bản đích "Through the thousands of years, most Chinese scholars have been greatly affected by Confucianism.". LLM được tinh chỉnh sử dụng các cặp văn bản nguồn và khoảng chỉnh sửa với các hướng dẫn.

Chúng tôi đã tiến hành thí nghiệm trên bốn tác vụ chuyển đổi chuỗi cục bộ: diễn giải lại, chuyển đổi phong cách trang trọng, GEC và đơn giản hóa. Phương pháp đề xuất đạt được hiệu suất tương đương với đường cơ sở trực tiếp xuất ra văn bản đích. Trong những tác vụ này, phương pháp đề xuất có thể giảm độ dài chuỗi ở phía đích trung bình 32% và ít nhất 21% trong GEC. Hơn nữa, phương pháp đề xuất với tinh chỉnh theo tác vụ cụ thể đã đạt được hiệu suất tiên tiến nhất (SoTA) trong bốn tác vụ.

2 Khoảng Chỉnh sửa
2.1 Trích xuất Khoảng Chỉnh sửa
Để trích xuất các vị trí chỉnh sửa và kết quả của văn bản nguồn và đích, chúng tôi tính toán sự căn chỉnh giữa các token trong mỗi văn bản. Chúng tôi sử dụng căn chỉnh ngôn ngữ học, kết hợp thông tin ngôn ngữ, để thực hiện căn chỉnh (Felice et al., 2016). Căn chỉnh ngôn ngữ học là một phương pháp dựa trên thuật toán Damerau-Levenshtein căn chỉnh các token bằng cách xem xét không chỉ khoảng cách giữa các token mà còn sự khớp của lemma, từ loại và đặc trưng ký tự của chúng, được tính trọng số tương ứng. Tính đến thông tin ngôn ngữ của các token, căn chỉnh ngôn ngữ học chính xác hơn so với các phương pháp căn chỉnh chỉ sử dụng thông tin bề mặt. Hơn nữa, căn chỉnh ngôn ngữ hợp nhất các căn chỉnh token sử dụng quy tắc đệ quy để tạo căn chỉnh cho nhiều token, chẳng hạn như "have been" trong Hình 1.

Để chỉ ra vị trí chỉnh sửa được xác định bởi căn chỉnh, số 0 được gán trước token đầu tiên của văn bản nguồn, và một chỉ số được gán tuần tự cho khoảng trống sau mỗi token. Khi độ dài của văn bản nguồn là N, N được gán sau token cuối cùng. Khoảng chỉnh sửa được biểu diễn bởi tuple của vị trí bắt đầu của văn bản nguồn, vị trí kết thúc của văn bản nguồn và kết quả token sau khi được chỉnh sửa.

Có ba loại thao tác chỉnh sửa: chèn, thay thế và xóa; chúng tôi giải thích chúng bằng ví dụ trong Hình 1. Tuple (1, 1, " the") biểu diễn thao tác chèn " the". Trong thao tác chèn, cả vị trí bắt đầu và kết thúc đều được đặt ở cùng vị trí nơi một token được chèn vào nguồn. Tuple đứng cho việc chèn " the" giữa các token nằm ở vị trí thứ 1. Tuple (8, 9, " have been ") trình bày thao tác thay thế " are" bằng " have been ". Bằng cách chỉ định vị trí thứ 8 và thứ 9 của văn bản nguồn, tuple này nhắm đến " are" và viết lại chúng thành " have been ". Tuple (12, 13, "") biểu diễn thao tác xóa " the". Nó trỏ " the" bằng cách chỉ định vị trí thứ 12 và thứ 13 trong văn bản nguồn. Vì token đích sau thao tác chỉnh sửa này là rỗng, tuple này tương ứng với việc loại bỏ " the".

2.2 Điều chỉnh Hướng dẫn với Khoảng Chỉnh sửa
Điều chỉnh hướng dẫn tinh chỉnh LLM bằng cách sử dụng các hướng dẫn ngôn ngữ tự nhiên mô tả một tác vụ (Wei

--- TRANG 3 ---
et al., 2021). So với việc tinh chỉnh thông thường chuyên biệt hóa mô hình cho một tác vụ cụ thể, điều chỉnh hướng dẫn nhằm tổng quát hóa cho nhiều tác vụ khác nhau bằng cách huấn luyện LLM để phản hồi tốt với nhiều loại hướng dẫn. Do đó, điều chỉnh hướng dẫn được sử dụng để huấn luyện nhiều LLM trong một thiết lập mở (Ouyang et al., 2022; Chung et al., 2022; Wang et al., 2022; Wu et al., 2023b). Chúng tôi sử dụng mô tả của các tác vụ chuyển đổi chuỗi cục bộ làm hướng dẫn để thực hiện điều chỉnh hướng dẫn của LLM. Chúng tôi cung cấp cho LLM các hướng dẫn và văn bản nguồn, và huấn luyện LLM để tạo ra các khoảng chỉnh sửa. Khi có nhiều chỉnh sửa, chúng được nối với nhau bằng dấu phẩy như "1 1 the, 8 9 have been, 12 13". Khi không cần chỉnh sửa trong văn bản nguồn, "None" được cung cấp làm văn bản vàng.

Các LLM gần đây được kỳ vọng có khả năng xử lý các tác vụ chưa biết và nhiều tác vụ khác nhau, để đạt được tính tổng quát. Điều quan trọng là việc học thông qua các khoảng chỉnh sửa không làm giảm hiệu suất của các tác vụ khác ngoài các tác vụ chuyển đổi chuỗi cục bộ. Do đó, chúng tôi thêm dữ liệu khoảng chỉnh sửa vào dữ liệu huấn luyện hiện có cho điều chỉnh hướng dẫn, bao gồm nhiều tác vụ khác nhau, và tinh chỉnh LLM.

2.3 Chuyển đổi từ Khoảng Chỉnh sửa sang Văn bản Đầu ra
Để chuyển đổi các khoảng chỉnh sửa được xuất ra bởi LLM thành văn bản thuần túy, chúng tôi sử dụng một phương pháp dựa trên quy tắc. Nếu LLM tạo ra "None", chúng tôi sử dụng văn bản nguồn làm văn bản đầu ra cuối cùng. Nếu không, chúng tôi chia các khoảng chỉnh sửa bằng dấu phẩy và trích xuất các chỉnh sửa. Từ mỗi chỉnh sửa, chúng tôi trích xuất vị trí bắt đầu, vị trí kết thúc và kết quả chỉnh sửa. Nếu LLM tạo ra các chỉnh sửa theo định dạng không chính xác không bao gồm vị trí bắt đầu hoặc kết thúc hoặc các chỉnh sửa mà vị trí bắt đầu hoặc kết thúc vượt quá phạm vi văn bản nguồn, chúng tôi bỏ qua chúng. Để đảm bảo rằng các chỉ số token không thay đổi, chúng tôi áp dụng các chỉnh sửa vào văn bản nguồn theo thứ tự giảm dần của vị trí bắt đầu. Việc chuyển đổi này được thực hiện bằng các quy tắc đơn giản với chi phí tính toán tối thiểu.

3 Thiết lập Thí nghiệm
3.1 Các Tác vụ Chuyển đổi Chuỗi Cục bộ
Chúng tôi đã tiến hành thí nghiệm trên các tác vụ chuyển đổi chuỗi cục bộ như GEC, diễn giải lại, chuyển đổi phong cách trang trọng và đơn giản hóa.

GEC Chúng tôi sử dụng NUCLE làm dữ liệu huấn luyện, CoNLL2013 (Ng et al., 2013) làm dữ liệu phát triển và CoNLL2014 (Ng et al., 2014) làm dữ liệu đánh giá. Tập dữ liệu bao gồm các bài luận được soạn bởi sinh viên đại học từ Đại học Quốc gia Singapore, bao quát một phổ rộng các chủ đề, bao gồm ô nhiễm môi trường, chăm sóc sức khỏe và nhiều hơn nữa. Chúng tôi sử dụng M2score (Dahlmeier và Ng, 2012) làm thước đo đánh giá. Đối với GEC, chúng tôi cung cấp văn bản hướng dẫn "Rewrite the input text into grammatically correct text.".

Diễn giải lại Quora đã công bố một tập dữ liệu bao gồm hơn 400K dòng các cặp câu hỏi có khả năng trùng lặp3. Trong số những cặp này, 150K cặp câu hỏi được gán nhãn là diễn giải lại. Chỉ những cặp câu hỏi diễn giải lại được gán nhãn được sử dụng làm tập huấn luyện, phát triển và kiểm tra. Chúng tôi sử dụng BLEU-4 (Papineni et al., 2002), ROUGE-1 và ROUGE-2 (Lin, 2004) để đánh giá LLM, theo nghiên cứu trước (Kumar et al., 2020; Meng et al., 2021; Li et al., 2022). Đối với diễn giải lại, chúng tôi cung cấp văn bản hướng dẫn "Rewrite the input text into paraphrased text.".

Chuyển đổi Phong cách Chúng tôi sử dụng điểm chuẩn FST Grammarly Yahoo Answers Corpus (GYAFC) (Rao và Tetreault, 2018) cho chuyển đổi phong cách trang trọng. GYAFC là một corpus thuần túy chứa các cặp câu không trang trọng và trang trọng truyền đạt cùng ý nghĩa. Nó bao quát các lĩnh vực như Entertainment & Music (E&M) và Family & Relationship (F&R). Chúng tôi sử dụng corpus BLEU trong NLTK (Bird và Loper, 2004) như được mô tả trong Chawla và Yang (2020). Đối với chuyển đổi phong cách trang trọng, chúng tôi cung cấp văn bản hướng dẫn "Rewrite the input text into formal text.".

Đơn giản hóa Chúng tôi sử dụng WikiSmall4 (Zhu et al., 2010; Zhang và Lapata, 2017) làm dữ liệu huấn luyện và ASSET (Alva-Manchego et al., 2020) và TurkCorpus (Xu et al., 2016) làm dữ liệu đánh giá. Chúng tôi sử dụng SARI (Xu et al., 2016) để đánh giá LLM, so sánh văn bản được tạo với văn bản đích và tính điểm F1 trung bình cho các thao tác thêm, giữ và xóa. Đối với đơn giản hóa văn bản, chúng tôi cung cấp văn bản hướng dẫn "Rewrite the input text into simpler text.".

3.2 Các Tác vụ Mở
Các quy tắc của khoảng chỉnh sửa khác với các quy tắc trong văn bản thô, có thể có tác động tiêu cực đến hiệu suất của các tác vụ khác ngoài chuyển đổi chuỗi cục bộ.

--- TRANG 4 ---
chuyển đổi chuỗi. Bằng cách kết hợp dữ liệu điều chỉnh hướng dẫn mở và dữ liệu điều chỉnh hướng dẫn khoảng chỉnh sửa, chúng ta có thể huấn luyện LLM và điều tra tác động của chúng đến các tác vụ khác.

Chúng tôi sử dụng tập dữ liệu databricks-dolly-15k5 bằng cách chia ngẫu nhiên thành 13K cho huấn luyện, 1K cho phát triển và 1K cho đánh giá. databricks-dolly-15k là một tập dữ liệu có sẵn công khai bao gồm các bản ghi hướng dẫn được tạo bởi nhiều nhân viên Databricks. Nó bao quát nhiều danh mục hành vi được mô tả trong InstructGPT (Ouyang et al., 2022), chẳng hạn như brainstorming, phân loại, QA đóng, tạo sinh, trích xuất thông tin, QA mở và tóm tắt. Chúng tôi lấy mẫu 3K instance cho mỗi tác vụ: GEC, diễn giải lại, chuyển đổi phong cách và đơn giản hóa, tổng cộng 12K instance hướng dẫn. Chúng tôi tinh chỉnh LLM sử dụng tập dữ liệu kết hợp của tất cả các hướng dẫn này, tổng cộng 25K instance.

Chúng tôi sử dụng BERTScore6 (Zhang et al., 2019) làm thước đo đánh giá. BERTScore là một phương pháp đánh giá đo lường sự tương tự giữa văn bản được tạo và văn bản đích sử dụng các embedding ngữ cảnh từ các mô hình được huấn luyện trước. Chúng tôi sử dụng RoBERTa (Liu et al., 2019) (roberta-large7) làm mô hình BERTScore.

3.3 Thiết lập Điều chỉnh Hướng dẫn
Chúng tôi sử dụng bốn LLM sau cho các thí nghiệm: MPT (mpt-7b)8 (Team, 2023), OPT (opt-6.7b)9 (Zhang et al., 2022), LLaMA (llama-7b)10 (Touvron et al., 2023), và BLOOM (bloom-7b1)11 (Scao et al., 2022).

Chúng tôi sử dụng mã cho điều chỉnh hướng dẫn từ Stanford Alpaca (Taori et al., 2023) code12 cho điều chỉnh hướng dẫn. Chúng tôi đặt số epoch là 3 và sử dụng kích thước batch là 32. Tốc độ học được đặt là 2e-5, với tỷ lệ làm ấm là 0.03, và chúng tôi sử dụng lịch trình tốc độ học cosine. Các siêu tham số này được xác định theo Stanford Alpaca. Chúng tôi báo cáo kết quả trung bình của ba mô hình được huấn luyện với các seed khác nhau cho điều chỉnh hướng dẫn. Chúng tôi sử dụng bốn node, mỗi node chứa tám GPU NVIDIA A100. Chúng tôi sử dụng mã13 cho căn chỉnh ngôn ngữ học được cung cấp bởi Felice et al. (2016).

Đường cơ sở Chúng tôi so sánh kết quả của phương pháp đề xuất với kết quả của LLM được tinh chỉnh cho điều chỉnh hướng dẫn sử dụng văn bản đích làm sự thật chuẩn thay vì sử dụng khoảng chỉnh sửa. So sánh này kiểm tra liệu khoảng chỉnh sửa có thể giảm chi phí tính toán trong quá trình suy luận mà không ảnh hưởng đến hiệu suất.

4 Thí nghiệm
4.1 Hiệu suất trên Các Tác vụ Chuyển đổi Chuỗi Cục bộ
Để chứng minh sự đóng góp của khoảng chỉnh sửa vào cải thiện hiệu suất, đầu tiên chúng tôi so sánh hiệu suất cơ sở với dữ liệu được tinh chỉnh sử dụng văn bản thuần túy. Bảng 1 cho thấy kết quả so sánh hiệu suất giữa đường cơ sở và phương pháp đề xuất trong các tác vụ GEC, diễn giải lại, chuyển đổi phong cách và đơn giản hóa. Trong 32 trường hợp, cải thiện hiệu suất được quan sát thấy trong 19 trường hợp, và khoảng chỉnh sửa đóng góp vào việc nâng cao hiệu suất. Hơn nữa, có thể quan sát thấy rằng LLaMA được huấn luyện với khoảng chỉnh sửa đạt được hiệu suất cao nhất trong hầu hết các trường hợp.

4.2 Giảm Độ dài Văn bản
Chúng tôi kiểm tra việc tinh chỉnh LLM với dữ liệu khoảng chỉnh sửa đã giảm độ dài của văn bản đầu ra bao nhiều. Hình 2 cho thấy tỷ lệ độ dài văn bản đầu ra so với độ dài văn bản đích khi được tinh chỉnh với dữ liệu thuần túy và dữ liệu khoảng chỉnh sửa tương ứng, trên dữ liệu phát triển cho mỗi tác vụ. Phương pháp đề xuất thành công nén văn bản đầu ra trên tất cả các tác vụ, độc lập với mô hình được sử dụng; nó đạt được nén văn bản trong khoảng 21% trong các trường hợp nén nhiều nhất và 41% ngay cả trong các trường hợp nén ít nhất. Trong GEC, có những trường hợp văn bản chính xác về mặt ngữ pháp được cung cấp làm văn bản nguồn. Trong những trường hợp như vậy, mô hình không cần thực hiện bất kỳ sửa đổi nào và có thể đơn giản xuất ra "None", dẫn đến nén đáng kể trong GEC.

4.3 Hiệu suất trên Tác vụ Mở
Trong các tác vụ mở, văn bản đích được viết bằng văn bản thuần túy, trong khi khoảng chỉnh sửa giới thiệu sự khác biệt đáng kể trong định dạng văn bản. Sự không phù hợp này trong biểu diễn văn bản có thể ảnh hưởng đến hiệu suất của các tác vụ mở. Do đó, chúng tôi nhằm

--- TRANG 5 ---
GEC Diễn giải lại Chuyển đổi phong cách Đơn giản hóa
Thuần túy MPT 68.0 37.9/66.5/47.1 78.9/81.2 46.3/41.1
OPT 65.7 35.2/63.2/45.4 75.0/77.2 43.7/40.5
LLaMA 68.2 39.3/69.0/47.2 79.5/81.0 48.0/41.9
BLOOM 66.4 37.0/66.4/46.1 78.2/79.9 45.0/41.0
Khoảng chỉnh sửa MPT 68.5 38.2/66.7/47.1 78.2/81.3 46.6/41.3
OPT 66.2 34.1/61.2/43.9 75.6/77.9 43.9/40.3
LLaMA 69.1 39.0/69.2/47.6 79.3/81.2 48.3/42.0
BLOOM 65.8 37.2/66.1/46.3 78.0/80.3 44.8/40.7

Bảng 1: Hiệu suất của bốn LLM được tinh chỉnh với khoảng chỉnh sửa và hướng dẫn dữ liệu thuần túy trên bốn tác vụ chuyển đổi chuỗi cục bộ. Các giá trị in đậm chỉ ra hiệu suất cao nhất cho mỗi tác vụ. Các giá trị gạch chân chỉ ra khi khoảng chỉnh sửa vượt quá đường cơ sở.

(a) MPT (b) OPT
(c) LLaMA (d) BLOOM

Hình 2: Tỷ lệ độ dài văn bản đầu ra so với độ dài văn bản đích khi MPT, OPT, LLaMA và BLOOM được tinh chỉnh với dữ liệu thuần túy và dữ liệu khoảng chỉnh sửa tương ứng.

chứng minh rằng khoảng chỉnh sửa không làm giảm đáng kể hiệu suất của các tác vụ mở.

Bảng 2 cho thấy điểm số cho mỗi LLM khi sử dụng RoBERTa làm mô hình BERTScore trên tập con 1K của tập dữ liệu databricks-dolly-15k, được chia cho đánh giá. Điều này chỉ ra rằng phương pháp đề xuất đạt được chi phí tính toán hiệu quả trong quá trình suy luận mà không hy sinh đáng kể hiệu suất tác vụ mở.

Để duy trì hiệu suất trong các tác vụ mở, phương pháp đề xuất kết hợp dữ liệu từ cả các tác vụ chuyển đổi chuỗi cục bộ và các tác vụ mở. Để chứng minh tính hiệu quả của việc kết hợp dữ liệu tác vụ mở, chúng tôi cũng điều tra hiệu suất tác vụ mở của LLM được điều chỉnh hướng dẫn khi chỉ được huấn luyện trên dữ liệu tác vụ chuyển đổi chuỗi cục bộ.

Bảng 3 chứng minh sự khác biệt hiệu suất trên tập chia 1K của tập dữ liệu databricks-dolly-15k, đánh giá LLM được huấn luyện trên cả dữ liệu tác vụ mở và tác vụ chuyển đổi chuỗi cục bộ so với LLM chỉ được huấn luyện trên dữ liệu tác vụ chuyển đổi chuỗi cục bộ. Hiệu suất giảm khi không sử dụng dữ liệu tác vụ mở cho huấn luyện, cả về văn bản thuần túy và khoảng chỉnh sửa. Điều này có thể là do dữ liệu tác vụ mở bao gồm văn bản thuần túy, trong khi khoảng chỉnh sửa bao gồm các định dạng văn bản hoàn toàn khác nhau, dẫn đến sự khác biệt lớn hơn trong yêu cầu tác vụ.

--- TRANG 6 ---
BERTScore
Thuần túy MPT 81.5
OPT 79.3
LLaMA 81.8
BLOOM 79.9
Khoảng chỉnh sửa MPT 81.0
OPT 78.6
LLaMA 81.3
BLOOM 79.5

Bảng 2: Điểm số sử dụng BERTScore trên tập dữ liệu databricks-dolly-15k, được chia cho đánh giá.

BERTScore diff.
Thuần túy MPT -5.2
OPT -5.7
LLaMA -4.4
BLOOM -6.2
Khoảng chỉnh sửa MPT -8.1
OPT -8.6
LLaMA -6.9
BLOOM -7.6

Bảng 3: Sự khác biệt hiệu suất giữa LLM được điều chỉnh hướng dẫn sử dụng tập dữ liệu tác vụ chuyển đổi chuỗi cục bộ và tác vụ mở, và LLM được điều chỉnh hướng dẫn chỉ sử dụng tập dữ liệu tác vụ chuyển đổi chuỗi cục bộ.

4.4 Độ chính xác của Chỉnh sửa được Tạo bởi LLM
Ngay cả khi văn bản khoảng chỉnh sửa khác nhau, có những trường hợp văn bản được chuyển đổi bởi quy tắc và văn bản khớp nhau. Ví dụ, trong GEC, mô hình được cung cấp đầu vào "This technology could also be seen as invasion of human privacy." và mô hình xuất ra "7 9 invading". Trong trường hợp này, ngay cả với văn bản khoảng chỉnh sửa thay thế "7 8 invading, 8 9", việc chuyển đổi dựa trên quy tắc sẽ dẫn đến cùng văn bản đầu ra. Tuy nhiên, điều này sẽ tăng độ dài câu theo chỉ số, tạo ra chỗ cho cải thiện về mặt chi phí tính toán. Do đó, chúng tôi điều tra mức độ khoảng chỉnh sửa của mô hình khớp với kết quả sử dụng căn chỉnh ngôn ngữ.

Đầu tiên, chúng tôi chuyển đổi các khoảng chỉnh sửa được tạo bởi mô hình thành văn bản thuần túy sử dụng quy tắc. Từ văn bản thuần túy đã chuyển đổi và văn bản nguồn, chúng tôi tạo khoảng chỉnh sửa sử dụng căn chỉnh ngôn ngữ và tính toán tỷ lệ phần trăm phù hợp với khoảng chỉnh sửa được xuất ra bởi mô hình. Chỉ khi vị trí bắt đầu s, vị trí kết thúc e và token chỉnh sửa r đều khớp chính xác thì nó mới được coi là câu trả lời đúng.

Bảng 4 cho thấy tỷ lệ phần trăm phù hợp giữa khoảng chỉnh sửa được xuất ra bởi LLM và khoảng chỉnh sửa được trích xuất bởi căn chỉnh ngôn ngữ trong dữ liệu phát triển cho mỗi tác vụ. Phương pháp đề xuất đạt được hơn 90% phù hợp trong 13 trong số 16 thiết lập. Điều này chỉ ra rằng LLM có thể học các quy tắc trích xuất cho căn chỉnh ngôn ngữ thông qua điều chỉnh hướng dẫn.

4.5 Tinh chỉnh Theo Tác vụ Cụ thể
Trong các thí nghiệm trước, LLM được huấn luyện bằng cách kết hợp dữ liệu từ bốn tác vụ chuyển đổi chuỗi cục bộ và tác vụ mở. Để khám phá tiềm năng hiệu suất tối đa của phương pháp đề xuất, chúng tôi tinh chỉnh LLM với tập trung theo tác vụ cụ thể sử dụng dữ liệu khoảng chỉnh sửa. Chúng tôi tinh chỉnh LLM cho mỗi tác vụ sử dụng tất cả dữ liệu huấn luyện có sẵn. Trong trường hợp này, chúng tôi chuyên biệt hóa LLM cho các tác vụ cụ thể mà không cần văn bản hướng dẫn. Do đó, chúng tôi huấn luyện LLM bằng cách chỉ cung cấp văn bản nguồn làm đầu vào.

Chúng tôi huấn luyện LLaMA, cho thấy hiệu suất cao nhất trong các tác vụ chuyển đổi chuỗi cục bộ. Chúng tôi đặt số epoch là 2 và sử dụng kích thước batch là 32. Tốc độ học được đặt là 1e-5, với tỷ lệ làm ấm là 0.03, và chúng tôi sử dụng lịch trình tốc độ học cosine. Theo phương pháp khám phá được mô tả trong Phần 3.3, chúng tôi xác định các siêu tham số cho các thí nghiệm.

Bảng 5 cho thấy kết quả so sánh hiệu suất với các nghiên cứu hiện có về các tác vụ GEC, diễn giải lại, chuyển đổi phong cách và đơn giản hóa. Phương pháp đề xuất vượt trội hơn các nghiên cứu hiện có 1.8 điểm trong GEC, 0.9, 1.2 và 2.3 điểm trong diễn giải lại, 1.9 và 1.3 điểm trong chuyển đổi phong cách, và 1.2 và 0.7 điểm trong các tác vụ đơn giản hóa tương ứng. Do đó, phương pháp đề xuất đạt được hiệu suất SoTA trong tất cả các tác vụ. Từ những kết quả này, có thể kết luận rằng khoảng chỉnh sửa là một phương pháp hiệu quả, ngay cả trong các tình huống tinh chỉnh theo tác vụ cụ thể.

4.6 Ví dụ về Đầu ra LLM Sử dụng Khoảng Chỉnh sửa
Bảng 6 cho thấy đầu ra trong CoNLL2013 cho LLaMA sử dụng khoảng chỉnh sửa và LLaMA xuất ra văn bản thuần túy. Mô hình bình thường xuất ra văn bản thuần túy xuất ra 23 token, trong khi mô hình sử dụng khoảng chỉnh sửa chỉ xuất ra 3 token. Đầu ra của mô hình sử dụng khoảng chỉnh sửa là một chuỗi ngắn hơn nhiều so với mô hình gốc xuất ra văn bản thuần túy. Hơn nữa, LLaMA xuất ra văn bản thuần túy không thể sửa lỗi ngữ pháp. Trong một tác vụ chuyển đổi chuỗi cục bộ, hầu hết các token trong nguồn

--- TRANG 7 ---
GEC Diễn giải lại Chuyển đổi phong cách Đơn giản hóa
MPT 96.6 95.0 89.2 94.7
OPT 93.3 91.9 88.8 92.7
LLaMA 99.0 96.2 92.6 95.4
BLOOM 94.2 92.5 89.4 93.5

Bảng 4: Sự phù hợp giữa khoảng chỉnh sửa được tạo bởi LLM và khoảng chỉnh sửa được trích xuất bởi căn chỉnh ngôn ngữ.

GEC
(Kaneko et al., 2020) 65.2
(Omelianchuk et al., 2020) 66.5
(Qorib et al., 2022) 69.5
Khoảng chỉnh sửa 71.3
(a) Điểm M2 trên tập dữ liệu CoNLL2014.

Diễn giải lại
(Kumar et al., 2020) 38.0/68.1/45.7
(Meng et al., 2021) 26.8/65.0/38.5
(Li et al., 2022) 39.3/70.8/48.3
Khoảng chỉnh sửa 41.2/72.0/50.6
(b) Điểm BLEU-4, ROUGE-1 và ROUGE-2 trên tập dữ liệu Quora.

Chuyển đổi phong cách
(Chawla và Yang, 2020) 76.2/79.9
(Lai et al., 2021) 76.5/79.3
(Liu et al., 2022) 78.8/81.4
Khoảng chỉnh sửa 80.7/82.7
(c) Điểm NLTK BLEU trên tập dữ liệu E&M và F&R.

Đơn giản hóa
(Martin et al., 2020) 40.1/41.4
(Martin et al., 2022) 44.2/42.6
(Feng et al., 2023a) 47.9/41.8
Khoảng chỉnh sửa 49.1/43.5
(d) Điểm SARI trên tập dữ liệu ASSET và TurkCorpus.

Bảng 5: So sánh hiệu suất với các nghiên cứu trước về các tác vụ GEC, diễn giải lại, chuyển đổi phong cách và đơn giản hóa.

văn bản và văn bản đích là chung, và mô hình có xu hướng học chỉ để sao chép các token đầu vào (Rastogi et al., 2016). Ngược lại, mô hình của chúng tôi sử dụng khoảng chỉnh sửa chỉ xuất ra các phần đã chỉnh sửa. Do đó, việc đơn giản sao chép đầu vào không phải là vấn đề đối với mô hình của chúng tôi.

5 Nghiên cứu Liên quan
5.1 LLM Hiệu quả
Hầu hết các phương pháp để đạt được LLM hiệu quả liên quan đến việc cải thiện độ phức tạp bộ nhớ của cơ chế tự chú ý hoặc nâng cao hiệu quả tổng thể của kiến trúc Transformer (Tay et al., 2022; Loem et al., 2022). Trong các giai đoạn đầu, các sửa đổi được thực hiện đối với tự chú ý tập trung vào việc giảm độ phức tạp tính toán bằng cách giới thiệu tính thưa thớt trong ma trận chú ý. Điều này được thực hiện bằng cách hạn chế phạm vi chú ý đến các mẫu được xác định trước, chẳng hạn như cửa sổ cục bộ và các mẫu khối stride cố định (Liu et al., 2018; Qiu et al., 2020; Beltagy et al., 2020). Một mở rộng tự nhiên cho phương pháp blockwise là kết nối các khối này thông qua đệ quy. Dai et al. (2019) đã giới thiệu một cơ chế đệ quy cấp segment thiết lập kết nối giữa nhiều segment và khối.

Một mở rộng dựa trên các mẫu cố định, được xác định trước là sử dụng các mẫu có thể học. Các mô hình kết hợp các mẫu có thể học nhằm có được mẫu truy cập thông qua các phương pháp dựa trên dữ liệu. Một khía cạnh quan trọng của việc học các mẫu là thiết lập khái niệm về mức độ liên quan của token và sau đó gán các token vào các bucket hoặc cluster (Vyas et al., 2020; Wang et al., 2021; Kitaev et al., 2020; Tay et al., 2020; Roy et al., 2021).

Một cách tiếp cận khác là sử dụng một module bộ nhớ phụ có thể huấn luyện có khả năng truy cập nhiều token đồng thời (Sukhbaatar et al., 2019; Ainslie et al., 2020; Beltagy et al., 2020). Một ví dụ phổ biến là bộ nhớ neural toàn cục, có thể truy cập toàn bộ chuỗi. Các token toàn cục hoạt động như một loại bộ nhớ mô hình, học để thu thập thông tin từ các token chuỗi đầu vào.

Một phương pháp khác để nâng cao hiệu quả là sử dụng các phép xấp xỉ hạng thấp của ma trận tự chú ý để cải thiện hiệu suất tính toán (Wang et al., 2020), và xem cơ chế chú ý thông qua kernelization (Choromanski et al., 2020; Peng et al., 2021). Các mô hình thưa thớt kích hoạt có chọn lọc một phần các tham số, dẫn đến tỷ lệ tham số trên FLOPs được cải thiện nói chung (Fedus et al., 2022).

Như một cách để giảm độ dài của văn bản, Cheng et al. (2023) đề xuất bao gồm nhiều ví dụ

--- TRANG 8 ---
Văn bản nguồn Since we do not to bring cash to pay for the transportation fee , enormous time has been saved for everybody .
Văn bản đích Since we do not need to bring cash to pay for the transportation fee , enormous time has been saved for everybody .
Khoảng chỉnh sửa đích 4 4 need
Thuần túy Since we do not to bring cash to pay for the transportation fee , enormous time has been saved for everybody .
Khoảng chỉnh sửa hệ thống 4 4 need

Bảng 6: Đầu ra ở định dạng văn bản thuần túy và khoảng chỉnh sửa tương ứng bởi LLaMA trong CoNLL2013.

trong một prompt và suy luận song song.

Những kỹ thuật này, không giống như nghiên cứu của chúng tôi, không thay đổi phong cách viết của văn bản đích, và khoảng chỉnh sửa có thể được sử dụng kết hợp với những phương pháp này.

5.2 Mô hình Dựa trên Chỉnh sửa
Kể từ khi câu hỏi về việc nhất thiết phải sử dụng mô hình seq2seq cho các tác vụ chuyển đổi chuỗi cục bộ được đặt ra (Rastogi et al., 2016; Schnober et al., 2016), nhiều mô hình dựa trên chỉnh sửa khác nhau đã được đề xuất. Guu et al. (2018) đề xuất một mô hình ngôn ngữ ban đầu chọn một câu nguyên mẫu từ tập dữ liệu huấn luyện và sau đó sửa đổi nó để tạo ra một câu mới. Ribeiro et al. (2018) giới thiệu một phương pháp để biểu diễn các vấn đề chuyển đổi chuỗi tổng quát như gán nhãn chuỗi. Koide et al. (2018) đề xuất mô hình được triển khai để phân tích sự tiến hóa của các chuỗi sinh học được thúc đẩy bởi các thao tác chỉnh sửa thay thế, chèn và xóa, đạt được độ chính xác cải thiện trong dự đoán cấu trúc thứ cấp protein. Awasthi et al. (2019) trình bày một mô hình chỉnh sửa lặp song song giảm thời gian giải mã cho các tác vụ chuyển đổi chuỗi cục bộ. Gu et al. (2019) phát triển Levenshtein Transformer, một mô hình không tự hồi quy sử dụng các thao tác chỉnh sửa. (Mallinson et al., 2020) giới thiệu FELIX, một cách tiếp cận chỉnh sửa văn bản có thể điều chỉnh cho việc tạo sinh nhằm tận dụng tối đa các lợi thế của giải mã với ngữ cảnh hai chiều và huấn luyện trước tự giám sát. (Xu và Carpuat, 2021) trình bày một Transformer Dựa trên Chỉnh sửa với Định vị lại, nâng cao tính linh hoạt tạo sinh chuỗi bằng cách tích hợp liền mạch các ưa thích do người dùng chỉ định trong lựa chọn từ vựng đầu ra. Reid và Neubig (2022) đề xuất mô hình hóa các quá trình chỉnh sửa, bao gồm việc tạo sinh lặp các chuỗi như một tổng thể. Họ thiết lập một khung khái niệm để giải thích xác suất của các chỉnh sửa nhiều bước và phác thảo các mô hình neural có khả năng học một mô hình tạo sinh của các chuỗi bằng cách tận dụng những chỉnh sửa nhiều bước này.

Tuy nhiên, những phương pháp này có kiến trúc khác với LLM. Do đó, không dễ áp dụng chúng cho LLM, không giống như phương pháp của chúng tôi, có thể huấn luyện các mô hình bằng cách đơn giản thay đổi văn bản đầu ra.

5.3 LLM cho Các Tác vụ Chuyển đổi Chuỗi Cục bộ
Trong GEC, mô hình dựa trên GPT-3 đạt được tiên tiến nhất trong các thiết lập không giám sát (Loem et al., 2023). Fang et al. (2023) cho thấy rằng ChatGPT sửa văn bản đầu vào rất trôi chảy. Yamashita et al. (2020); Rothe et al. (2021); Sun et al. (2022) đề xuất một phương pháp cho GEC đa ngôn ngữ sử dụng LLM đa ngôn ngữ. Feng et al. (2023b) điều tra hiệu suất few-shot và zero-shot của GPT3 và ChatGPT trong đơn giản hóa. Anschütz et al. (2023) sử dụng LLM cho đơn giản hóa tiếng Đức và thấy chúng hiệu quả trong các ngôn ngữ có ít dữ liệu song song. (Witteveen và Andrews, 2019) xác minh hiệu suất của GPT-2 (Radford et al., 2019) trong diễn giải lại. Wahle et al. (2022) điều tra việc sử dụng T5 và GPT3 trong việc tạo ra các diễn giải lại do máy tạo cho các bài viết khoa học có nguồn từ arXiv, luận văn sinh viên và Wikipedia. Reif et al. (2022) giới thiệu một phương pháp dựa trên GPT-3 chỉ dựa vào hướng dẫn ngôn ngữ tự nhiên và không cần tinh chỉnh mô hình hoặc các mẫu trong phong cách mong muốn. Malmi et al. (2020) đề xuất một phương pháp sử dụng LLM cho chuyển đổi phong cách khi không có dữ liệu song song. Mặt khác, những nghiên cứu này không nhắm đến hiệu quả của LLM dựa trên chỉnh sửa.

6 Kết luận
Trong nghiên cứu này, chúng tôi đề xuất dự đoán một tập hợp các khoảng chỉnh sửa, đại diện cho các phần đã thay đổi của văn bản đích so với các token nguồn. Chúng tôi đã cho thấy phương pháp của chúng tôi bỏ qua các token chưa chỉnh sửa chiếm phần lớn văn bản đích và giảm độ dài của văn bản đích và thời gian suy luận cho các tác vụ chuyển đổi chuỗi cục bộ. Hơn nữa, chúng tôi báo cáo rằng điều chỉnh hướng dẫn với phương pháp đề xuất đạt được

--- TRANG 9 ---
hiệu suất tiên tiến nhất trong bốn tác vụ.

Hạn chế
Trong các thí nghiệm sơ bộ của chúng tôi, ngay cả các LLM hiệu suất cao như GPT-3 (Brown et al., 2020) và ChatGPT (OpenAI, 2023) cũng không thể tạo ra khoảng chỉnh sửa với zero-shot và few-shot. Đặc biệt, các chỉ số không thể được tạo ra một cách chính xác. Do đó, đó là công việc tương lai để áp dụng phương pháp đề xuất cho zero-shot và few-shot. Hơn nữa, việc sử dụng khoảng chỉnh sửa không nhất thiết hiệu quả cho các tác vụ, chẳng hạn như dịch máy và đối thoại, khác với tác vụ chuyển đổi chuỗi cục bộ, trong đó nhiều token trong văn bản nguồn và đích không chung.

Lời cảm ơn
Những kết quả nghiên cứu này được thu được từ nghiên cứu được ủy thác (Số 225) bởi Viện Công nghệ Thông tin và Truyền thông Quốc gia (NICT), Nhật Bản.

Tài liệu tham khảo
Joshua Ainslie, Santiago Ontanon, Chris Alberti, Vaclav Cvicek, Zachary Fisher, Philip Pham, Anirudh Ravula, Sumit Sanghai, Qifan Wang, và Li Yang. 2020. ETC: Encoding long and structured inputs in transformers. Trong Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), trang 268–284, Online. Association for Computational Linguistics.

Fernando Alva-Manchego, Louis Martin, Antoine Bordes, Carolina Scarton, Benoît Sagot, và Lucia Specia. 2020. ASSET: A dataset for tuning and evaluation of sentence simplification models with multiple rewriting transformations. Trong Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, trang 4668–4679, Online. Association for Computational Linguistics.

Miriam Anschütz, Joshua Oehms, Thomas Wimmer, Bartłomiej Jezierski, và Georg Groh. 2023. Language models for german text simplification: Overcoming parallel data scarcity through style-specific pre-training. arXiv preprint arXiv:2305.12908.

Abhijeet Awasthi, Sunita Sarawagi, Rasna Goyal, Sabyasachi Ghosh, và Vihari Piratla. 2019. Parallel iterative edit models for local sequence transduction. Trong Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), trang 4260–4270, Hong Kong, China. Association for Computational Linguistics.

Iz Beltagy, Matthew E Peters, và Arman Cohan. 2020. Longformer: The long-document transformer. arXiv preprint arXiv:2004.05150.

Emily M Bender, Timnit Gebru, Angelina McMillan-Major, và Shmargaret Shmitchell. 2021. On the dangers of stochastic parrots: Can language models be too big? Trong Proceedings of the 2021 ACM conference on fairness, accountability, and transparency, trang 610–623.

Steven Bird và Edward Loper. 2004. NLTK: The natural language toolkit. Trong Proceedings of the ACL Interactive Poster and Demonstration Sessions, trang 214–217, Barcelona, Spain. Association for Computational Linguistics.

Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, và Dario Amodei. 2020. Language models are few-shot learners. Trong Advances in Neural Information Processing Systems, tập 33, trang 1877–1901. Curran Associates, Inc.

Kunal Chawla và Diyi Yang. 2020. Semi-supervised formality style transfer using language model discriminator and mutual information maximization. Trong Findings of the Association for Computational Linguistics: EMNLP 2020, trang 2340–2354, Online. Association for Computational Linguistics.

Zhoujun Cheng, Jungo Kasai, và Tao Yu. 2023. Batch prompting: Efficient inference with large language model apis. arXiv preprint arXiv:2301.08721.

Krzysztof Choromanski, Valerii Likhosherstov, David Dohan, Xingyou Song, Andreea Gane, Tamas Sarlos, Peter Hawkins, Jared Davis, David Belanger, Lucy Colwell, et al. 2020. Masked language modeling for proteins via linearly scalable long-context transformers. arXiv preprint arXiv:2006.03555.

Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, et al. 2022. Palm: Scaling language modeling with pathways. arXiv preprint arXiv:2204.02311.

Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, et al. 2022. Scaling instruction-finetuned language models. arXiv preprint arXiv:2210.11416.

Daniel Dahlmeier và Hwee Tou Ng. 2012. Better evaluation for grammatical error correction. Trong Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational

--- TRANG 10 ---
Linguistics: Human Language Technologies, trang 568–572, Montréal, Canada. Association for Computational Linguistics.

Zihang Dai, Zhilin Yang, Yiming Yang, Jaime Carbonell, Quoc Le, và Ruslan Salakhutdinov. 2019. Transformer-XL: Attentive language models beyond a fixed-length context. Trong Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, trang 2978–2988, Florence, Italy. Association for Computational Linguistics.

Tao Fang, Shu Yang, Kaixin Lan, Derek F Wong, Jinpeng Hu, Lidia S Chao, và Yue Zhang. 2023. Is chatgpt a highly fluent grammatical error correction system? a comprehensive evaluation. arXiv preprint arXiv:2304.01746.

William Fedus, Barret Zoph, và Noam Shazeer. 2022. Switch transformers: Scaling to trillion parameter models with simple and efficient sparsity. The Journal of Machine Learning Research, 23(1):5232–5270.

Mariano Felice, Christopher Bryant, và Ted Briscoe. 2016. Automatic extraction of learner errors in ESL sentences using linguistically enhanced alignments. Trong Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers, trang 825–835, Osaka, Japan. The COLING 2016 Organizing Committee.

Yutao Feng, Jipeng Qiang, Yun Li, Yunhao Yuan, và Yi Zhu. 2023a. Sentence simplification via large language models. arXiv preprint arXiv:2302.11957.

Yutao Feng, Jipeng Qiang, Yun Li, Yunhao Yuan, và Yi Zhu. 2023b. Sentence simplification via large language models. ArXiv, abs/2302.11957.

Jiatao Gu, Changhan Wang, và Junbo Zhao. 2019. Levenshtein transformer. Advances in Neural Information Processing Systems, 32.

Kelvin Guu, Tatsunori B. Hashimoto, Yonatan Oren, và Percy Liang. 2018. Generating sentences by editing prototypes. Transactions of the Association for Computational Linguistics, 6:437–450.

Masahiro Kaneko, Masato Mita, Shun Kiyono, Jun Suzuki, và Kentaro Inui. 2020. Encoder-decoder models can benefit from pre-trained masked language models in grammatical error correction. Trong Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, trang 4248–4254, Online. Association for Computational Linguistics.

Masahiro Kaneko và Naoaki Okazaki. 2023. Controlled generation with prompt insertion for natural language explanations in grammatical error correction. arXiv preprint arXiv:2309.11439.

Masahiro Kaneko, Sho Takase, Ayana Niwa, và Naoaki Okazaki. 2022. Interpretability for language learners using example-based grammatical error correction. Trong Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), trang 7176–7187, Dublin, Ireland. Association for Computational Linguistics.

Jared Kaplan, Sam McCandlish, Tom Henighan, Tom B Brown, Benjamin Chess, Rewon Child, Scott Gray, Alec Radford, Jeffrey Wu, và Dario Amodei. 2020. Scaling laws for neural language models. arXiv preprint arXiv:2001.08361.

Nikita Kitaev, Łukasz Kaiser, và Anselm Levskaya. 2020. Reformer: The efficient transformer. arXiv preprint arXiv:2001.04451.

Satoshi Koide, Keisuke Kawano, và Takuro Kutsuna. 2018. Neural edit operations for biological sequences. Advances in Neural Information Processing Systems, 31.

Mathias Kraus, Julia Anna Bingler, Markus Leippold, Tobias Schimanski, Chiara Colesanti Senni, Dominik Stammbach, Saeid Ashraf Vaghefi, và Nicolas Webersinke. 2023. Enhancing large language models with climate resources. arXiv preprint arXiv:2304.00116.

Ashutosh Kumar, Kabir Ahuja, Raghuram Vadapalli, và Partha Talukdar. 2020. Syntax-Guided Controlled Generation of Paraphrases. Transactions of the Association for Computational Linguistics, 8:330–345.

Huiyuan Lai, Antonio Toral, và Malvina Nissim. 2021. Thank you BART! rewarding pre-trained models improves formality style transfer. Trong Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers), trang 484–494, Online. Association for Computational Linguistics.

Zhigen Li, Yanmeng Wang, Rizhao Fan, Ye Wang, Jianfeng Li, và Shaojun Wang. 2022. Learning to adapt to low-resource paraphrase generation. Trong Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, trang 1014–1022, Abu Dhabi, United Arab Emirates. Association for Computational Linguistics.

Chin-Yew Lin. 2004. ROUGE: A package for automatic evaluation of summaries. Trong Text Summarization Branches Out, trang 74–81, Barcelona, Spain. Association for Computational Linguistics.

Ao Liu, An Wang, và Naoaki Okazaki. 2022. Semi-supervised formality style transfer with consistency training. Trong Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), trang 4689–4701, Dublin, Ireland. Association for Computational Linguistics.

Peter J Liu, Mohammad Saleh, Etienne Pot, Ben Goodrich, Ryan Sepassi, Lukasz Kaiser, và Noam Shazeer. 2018. Generating wikipedia by summarizing long sequences. arXiv preprint arXiv:1801.10198.

--- TRANG 11 ---
Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, và Veselin Stoyanov. 2019. Roberta: A robustly optimized bert pretraining approach. arXiv preprint arXiv:1907.11692.

Mengsay Loem, Masahiro Kaneko, Sho Takase, và Naoaki Okazaki. 2023. Exploring effectiveness of gpt-3 in grammatical error correction: A study on performance and controllability in prompt-based methods. arXiv preprint arXiv:2305.18156.

Mengsay Loem, Sho Takase, Masahiro Kaneko, và Naoaki Okazaki. 2022. Are neighbors enough? multi-head neural n-gram can be alternative to self-attention. arXiv preprint arXiv:2207.13354.

Jonathan Mallinson, Aliaksei Severyn, Eric Malmi, và Guillermo Garrido. 2020. FELIX: Flexible text editing through tagging and insertion. Trong Findings of the Association for Computational Linguistics: EMNLP 2020, trang 1244–1255, Online. Association for Computational Linguistics.

Eric Malmi, Aliaksei Severyn, và Sascha Rothe. 2020. Unsupervised text style transfer with padded masked language models. Trong Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), trang 8671–8680, Online. Association for Computational Linguistics.

Louis Martin, Éric de la Clergerie, Benoît Sagot, và Antoine Bordes. 2020. Controllable sentence simplification. Trong Proceedings of the Twelfth Language Resources and Evaluation Conference, trang 4689–4698, Marseille, France. European Language Resources Association.

Louis Martin, Angela Fan, Éric de la Clergerie, Antoine Bordes, và Benoît Sagot. 2022. MUSS: Multilingual unsupervised sentence simplification by mining paraphrases. Trong Proceedings of the Thirteenth Language Resources and Evaluation Conference, trang 1651–1664, Marseille, France. European Language Resources Association.

Yuxian Meng, Xiang Ao, Qing He, Xiaofei Sun, Qinghong Han, Fei Wu, Chun Fan, và Jiwei Li. 2021. ConRPG: Paraphrase generation using contexts as regularizer. Trong Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, trang 2551–2562, Online and Punta Cana, Dominican Republic. Association for Computational Linguistics.

Hwee Tou Ng, Siew Mei Wu, Ted Briscoe, Christian Hadiwinoto, Raymond Hendy Susanto, và Christopher Bryant. 2014. The CoNLL-2014 shared task on grammatical error correction. Trong Proceedings of the Eighteenth Conference on Computational Natural Language Learning: Shared Task, trang 1–14, Baltimore, Maryland. Association for Computational Linguistics.

Hwee Tou Ng, Siew Mei Wu, Yuanbin Wu, Christian Hadiwinoto, và Joel Tetreault. 2013. The CoNLL-2013 shared task on grammatical error correction. Trong Proceedings of the Seventeenth Conference on Computational Natural Language Learning: Shared Task, trang 1–12, Sofia, Bulgaria. Association for Computational Linguistics.

Kostiantyn Omelianchuk, Vitaliy Atrasevych, Artem Chernodub, và Oleksandr Skurzhanskyi. 2020. GECToR – grammatical error correction: Tag, not rewrite. Trong Proceedings of the Fifteenth Workshop on Innovative Use of NLP for Building Educational Applications, trang 163–170, Seattle, WA, USA → Online. Association for Computational Linguistics.

OpenAI. 2023. Introducing ChatGPT.

Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. 2022. Training language models to follow instructions with human feedback. Advances in Neural Information Processing Systems, 35:27730–27744.

Kishore Papineni, Salim Roukos, Todd Ward, và Wei-Jing Zhu. 2002. Bleu: a method for automatic evaluation of machine translation. Trong Proceedings of the 40th annual meeting of the Association for Computational Linguistics, trang 311–318.

Hao Peng, Nikolaos Pappas, Dani Yogatama, Roy Schwartz, Noah A Smith, và Lingpeng Kong. 2021. Random feature attention. arXiv preprint arXiv:2103.02143.

Jiezhong Qiu, Hao Ma, Omer Levy, Wen-tau Yih, Sinong Wang, và Jie Tang. 2020. Blockwise self-attention for long document understanding. Trong Findings of the Association for Computational Linguistics: EMNLP 2020, trang 2555–2565, Online. Association for Computational Linguistics.

Muhammad Qorib, Seung-Hoon Na, và Hwee Tou Ng. 2022. Frustratingly easy system combination for grammatical error correction. Trong Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, trang 1964–1974, Seattle, United States. Association for Computational Linguistics.

Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al. 2019. Language models are unsupervised multitask learners. OpenAI blog, 1(8):9.

Sudha Rao và Joel Tetreault. 2018. Dear sir or madam, may I introduce the GYAFC dataset: Corpus, benchmarks and metrics for formality style transfer. Trong Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers), trang 129–140, New Orleans, Louisiana. Association for Computational Linguistics.

--- TRANG 12 ---
Pushpendre Rastogi, Ryan Cotterell, và Jason Eisner. 2016. Weighting finite-state transductions with neural context. Trong Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, trang 623–633, San Diego, California. Association for Computational Linguistics.

Machel Reid và Graham Neubig. 2022. Learning to model editing processes. Trong Findings of the Association for Computational Linguistics: EMNLP 2022, trang 3822–3832, Abu Dhabi, United Arab Emirates. Association for Computational Linguistics.

Emily Reif, Daphne Ippolito, Ann Yuan, Andy Coenen, Chris Callison-Burch, và Jason Wei. 2022. A recipe for arbitrary text style transfer with large language models. Trong Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), trang 837–848, Dublin, Ireland. Association for Computational Linguistics.

Joana Ribeiro, Shashi Narayan, Shay B. Cohen, và Xavier Carreras. 2018. Local string transduction as sequence labeling. Trong Proceedings of the 27th International Conference on Computational Linguistics, trang 1360–1371, Santa Fe, New Mexico, USA. Association for Computational Linguistics.

Sascha Rothe, Jonathan Mallinson, Eric Malmi, Sebastian Krause, và Aliaksei Severyn. 2021. A simple recipe for multilingual grammatical error correction. Trong Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers), trang 702–707, Online. Association for Computational Linguistics.

Aurko Roy, Mohammad Saffar, Ashish Vaswani, và David Grangier. 2021. Efficient content-based sparse attention with routing transformers. Transactions of the Association for Computational Linguistics, 9:53–68.

Teven Le Scao, Angela Fan, Christopher Akiki, Ellie Pavlick, Suzana Ilić, Daniel Hesslow, Roman Castagné, Alexandra Sasha Luccioni, François Yvon, Matthias Gallé, et al. 2022. Bloom: A 176b-parameter open-access multilingual language model. arXiv preprint arXiv:2211.05100.

Carsten Schnober, Steffen Eger, Erik-Lân Do Dinh, và Iryna Gurevych. 2016. Still not there? comparing traditional sequence-to-sequence models to encoder-decoder neural networks on monotone string translation tasks. Trong Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers, trang 1703–1714, Osaka, Japan. The COLING 2016 Organizing Committee.

Sainbayar Sukhbaatar, Edouard Grave, Guillaume Lample, Herve Jegou, và Armand Joulin. 2019. Augmenting self-attention with persistent memory. arXiv preprint arXiv:1907.01470.

Xin Sun, Tao Ge, Shuming Ma, Jingjing Li, Furu Wei, và Houfeng Wang. 2022. A unified strategy for multilingual grammatical error correction with pre-trained cross-lingual language model. arXiv preprint arXiv:2201.10707.

Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy Liang, và Tatsunori B. Hashimoto. 2023. Stanford alpaca: An instruction-following llama model. https://github.com/tatsu-lab/stanford_alpaca.

Yi Tay, Dara Bahri, Liu Yang, Donald Metzler, và Da-Cheng Juan. 2020. Sparse sinkhorn attention. Trong International Conference on Machine Learning, trang 9438–9447. PMLR.

Yi Tay, Mostafa Dehghani, Dara Bahri, và Donald Metzler. 2022. Efficient transformers: A survey. ACM Computing Surveys, 55(6):1–28.

MosaicML NLP Team. 2023. Introducing mpt-7b: A new standard for open-source, ly usable llms.

Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave, và Guillaume Lample. 2023. Llama: Open and efficient foundation language models. arXiv preprint arXiv:2302.13971.

Apoorv Vyas, Angelos Katharopoulos, và François Fleuret. 2020. Fast transformers with clustered attention. Advances in Neural Information Processing Systems, 33:21665–21674.

Jan Philip Wahle, Terry Ruas, Frederic Kirstein, và Bela Gipp. 2022. How large language models are transforming machine-paraphrase plagiarism. Trong Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, trang 952–963, Abu Dhabi, United Arab Emirates. Association for Computational Linguistics.

Shuohang Wang, Luowei Zhou, Zhe Gan, Yen-Chun Chen, Yuwei Fang, Siqi Sun, Yu Cheng, và Jingjing Liu. 2021. Cluster-former: Clustering-based sparse transformer for question answering. Trong Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, trang 3958–3968, Online. Association for Computational Linguistics.

Sinong Wang, Belinda Z Li, Madian Khabsa, Han Fang, và Hao Ma. 2020. Linformer: Self-attention with linear complexity. arXiv preprint arXiv:2006.04768.

Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A Smith, Daniel Khashabi, và Hannaneh Hajishirzi. 2022. Self-instruct: Aligning language model with self generated instructions. arXiv preprint arXiv:2212.10560.

--- TRANG 13 ---
Jason Wei, Maarten Bosma, Vincent Y Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du, Andrew M Dai, và Quoc V Le. 2021. Finetuned language models are zero-shot learners. arXiv preprint arXiv:2109.01652.

Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, et al. 2022. Emergent abilities of large language models. arXiv preprint arXiv:2206.07682.

Sam Witteveen và Martin Andrews. 2019. Paraphrasing with large language models. Trong Proceedings of the 3rd Workshop on Neural Generation and Translation, trang 215–220, Hong Kong. Association for Computational Linguistics.

Haoran Wu, Wenxuan Wang, Yuxuan Wan, Wenxiang Jiao, và Michael Lyu. 2023a. Chatgpt or grammarly? evaluating chatgpt on grammatical error correction benchmark. arXiv preprint arXiv:2303.13648.

Minghao Wu, Abdul Waheed, Chiyu Zhang, Muhammad Abdul-Mageed, và Alham Fikri Aji. 2023b. Lamini-lm: A diverse herd of distilled models from large-scale instructions. arXiv preprint arXiv:2304.14402.

Wei Xu, Courtney Napoles, Ellie Pavlick, Quanze Chen, và Chris Callison-Burch. 2016. Optimizing statistical machine translation for text simplification. Transactions of the Association for Computational Linguistics, 4:401–415.

Weijia Xu và Marine Carpuat. 2021. Editor: An edit-based transformer with repositioning for neural machine translation with soft lexical constraints. Transactions of the Association for Computational Linguistics, 9:311–328.

Ikumi Yamashita, Satoru Katsumata, Masahiro Kaneko, Aizhan Imankulova, và Mamoru Komachi. 2020. Cross-lingual transfer learning for grammatical error correction. Trong Proceedings of the 28th International Conference on Computational Linguistics, trang 4704–4715, Barcelona, Spain (Online). International Committee on Computational Linguistics.

Susan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui Chen, Christopher Dewan, Mona Diab, Xian Li, Xi Victoria Lin, et al. 2022. Opt: Open pre-trained transformer language models. arXiv preprint arXiv:2205.01068.

Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q Weinberger, và Yoav Artzi. 2019. Bertscore: Evaluating text generation with bert. arXiv preprint arXiv:1904.09675.

Xingxing Zhang và Mirella Lapata. 2017. Sentence simplification with deep reinforcement learning. Trong Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, trang 584–594, Copenhagen, Denmark. Association for Computational Linguistics.

Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, et al. 2023. A survey of large language models. arXiv preprint arXiv:2303.18223.

Zhemin Zhu, Delphine Bernhard, và Iryna Gurevych. 2010. A monolingual tree-based translation model for sentence simplification. Trong Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), trang 1353–1361, Beijing, China. Coling 2010 Organizing Committee.

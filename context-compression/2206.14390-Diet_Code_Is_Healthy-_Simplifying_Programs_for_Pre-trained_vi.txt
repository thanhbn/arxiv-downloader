# 2206.14390.pdf
# ÄÃ£ chuyá»ƒn Ä‘á»•i tá»« PDF sang TXT
# ÄÆ°á»ng dáº«n nguá»“n: /home/admin88/arxiv-downloader/context-compression/2206.14390.pdf
# KÃ­ch thÆ°á»›c tá»‡p: 1379232 bytes

===============================================
Ná»˜I DUNG Tá»†P PDF
===============================================


--- TRANG 1 ---
Diet Code LÃ  Khá»e Máº¡nh: ÄÆ¡n Giáº£n HÃ³a ChÆ°Æ¡ng TrÃ¬nh cho CÃ¡c MÃ´ HÃ¬nh
ÄÆ°á»£c Tiá»n Huáº¥n Luyá»‡n cá»§a Code
Zhaowei Zhang1, Hongyu Zhang2, Beijun Shen1, Xiaodong Gu1âˆ—
1School of Software, Shanghai Jiao Tong University, China
2The University of Newcastle, Australia
andy_zhangzw@outlook.com
{bjshen,xiaodong.gu}@sjtu.edu.cn,hongyu.zhang@newcastle.edu.au
TÃ“M Táº®T
CÃ¡c mÃ´ hÃ¬nh biá»ƒu diá»…n code Ä‘Æ°á»£c tiá»n huáº¥n luyá»‡n nhÆ° CodeBERT Ä‘Ã£ chá»©ng minh
hiá»‡u suáº¥t vÆ°á»£t trá»™i trong nhiá»u tÃ¡c vá»¥ ká»¹ thuáº­t pháº§n má»m khÃ¡c nhau, tuy nhiÃªn
chÃºng thÆ°á»ng náº·ng vá» Ä‘á»™ phá»©c táº¡p, tÄƒng báº­c hai theo Ä‘á»™ dÃ i cá»§a chuá»—i Ä‘áº§u vÃ o.
PhÃ¢n tÃ­ch thá»±c nghiá»‡m cá»§a chÃºng tÃ´i vá» sá»± chÃº Ã½ cá»§a CodeBERT cho tháº¥y CodeBERT
chÃº Ã½ nhiá»u hÆ¡n Ä‘áº¿n má»™t sá»‘ loáº¡i token vÃ  cÃ¢u lá»‡nh nháº¥t Ä‘á»‹nh nhÆ° tá»« khÃ³a vÃ  cÃ¡c
cÃ¢u lá»‡nh liÃªn quan Ä‘áº¿n dá»¯ liá»‡u. Dá»±a trÃªn nhá»¯ng phÃ¡t hiá»‡n nÃ y, chÃºng tÃ´i Ä‘á» xuáº¥t
DietCode, nháº±m táº­n dá»¥ng nháº¹ nhÃ ng cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c tiá»n huáº¥n luyá»‡n lá»›n cho
mÃ£ nguá»“n. DietCode Ä‘Æ¡n giáº£n hÃ³a chÆ°Æ¡ng trÃ¬nh Ä‘áº§u vÃ o cá»§a CodeBERT vá»›i ba chiáº¿n
lÆ°á»£c, cá»¥ thá»ƒ lÃ  word dropout, frequency filtering, vÃ  má»™t chiáº¿n lÆ°á»£c dá»±a trÃªn
sá»± chÃº Ã½ Ä‘á»ƒ chá»n cÃ¡c cÃ¢u lá»‡nh vÃ  token nháº­n Ä‘Æ°á»£c trá»ng sá»‘ chÃº Ã½ cao nháº¥t trong
quÃ¡ trÃ¬nh tiá»n huáº¥n luyá»‡n. Do Ä‘Ã³, nÃ³ mang láº¡i sá»± giáº£m Ä‘Ã¡ng ká»ƒ chi phÃ­ tÃ­nh toÃ¡n
mÃ  khÃ´ng áº£nh hÆ°á»Ÿng Ä‘áº¿n hiá»‡u suáº¥t mÃ´ hÃ¬nh. Káº¿t quáº£ thá»±c nghiá»‡m trÃªn hai tÃ¡c vá»¥
downstream cho tháº¥y DietCode cung cáº¥p káº¿t quáº£ tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i CodeBERT vá»›i chi
phÃ­ tÃ­nh toÃ¡n Ã­t hÆ¡n 40% trong fine-tuning vÃ  testing.
CCS CONCEPTS
â€¢Computing methodologies â†’Natural language processing .
KEYWORDS
Program simplification, Pre-trained models, Learning program representations, Code intelligence
ACM Reference Format:
Zhaowei Zhang1, Hongyu Zhang2, Beijun Shen1, Xiaodong Gu1. 2022. Diet
Code Is Healthy: Simplifying Programs for Pre-trained Models of Code. In
Proceedings of the 30th ACM Joint European Software Engineering Conference
and Symposium on the Foundations of Software Engineering (ESEC/FSE '22),
November 14â€“18, 2022, Singapore, Singapore. ACM, New York, NY, USA,
12 pages. https://doi.org/10.1145/3540250.3549094
âˆ—Xiaodong Gu lÃ  tÃ¡c giáº£ liÃªn láº¡c.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from permissions@acm.org.
ESEC/FSE '22, November 14â€“18, 2022, Singapore, Singapore
Â©2022 Association for Computing Machinery.
ACM ISBN 978-1-4503-9413-0/22/11. . . $15.00
https://doi.org/10.1145/3540250.35490941 GIá»šI THIá»†U
CÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c tiá»n huáº¥n luyá»‡n cá»§a code nhÆ° CodeBERT [15] Ä‘Ã£ trá»Ÿ thÃ nh
cÃ´ng nghá»‡ biá»ƒu diá»…n chÆ°Æ¡ng trÃ¬nh tiÃªn tiáº¿n, mang láº¡i hiá»‡u suáº¥t Ä‘Ã¡ng chÃº Ã½
trÃªn nhiá»u tÃ¡c vá»¥ ká»¹ thuáº­t pháº§n má»m khÃ¡c nhau nhÆ° code completion [11],
code search [15], vÃ  clone detection [29]. Sau khi Ä‘Æ°á»£c tiá»n huáº¥n luyá»‡n trÃªn
cÃ¡c kho dá»¯ liá»‡u code quy mÃ´ lá»›n, chÃºng thá»ƒ hiá»‡n sá»± hiá»ƒu biáº¿t tá»‘t hÆ¡n vá» ngá»¯
nghÄ©a cá»§a mÃ£ nguá»“n so vá»›i cÃ¡c mÃ´ hÃ¬nh deep learning trÆ°á»›c Ä‘Ã³ nhÆ° code2vec [3]
vÃ  ASTNN [50].
Máº·c dÃ¹ táº¡o ra bÆ°á»›c nháº£y vá»t vá» Ä‘á»™ chÃ­nh xÃ¡c, cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c tiá»n huáº¥n luyá»‡n
thÆ°á»ng náº·ng vá» tÃ­nh toÃ¡n, Ä‘iá»u nÃ y cáº£n trá»Ÿ Ä‘Ã¡ng ká»ƒ viá»‡c á»©ng dá»¥ng cá»§a chÃºng
trong thá»±c táº¿. VÃ­ dá»¥, CodeBERT tiÃªu chuáº©n chá»©a 125 triá»‡u tham sá»‘ vÃ  máº¥t 28
giá» Ä‘á»ƒ tiá»n huáº¥n luyá»‡n trÃªn 8.5M code. Quan trá»ng hÆ¡n, cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c tiá»n
huáº¥n luyá»‡n thÆ°á»ng cáº§n Ä‘Æ°á»£c fine-tuned trÆ°á»›c khi sá»­ dá»¥ng, Ä‘iá»u nÃ y khÃ´ng hiá»‡u
quáº£ vá» chi phÃ­ do quy mÃ´ lá»›n cá»§a tham sá»‘ vÃ  dá»¯ liá»‡u huáº¥n luyá»‡n. Do Ä‘Ã³, viá»‡c
xÃ¡c Ä‘á»‹nh Ä‘áº·c trÆ°ng quan trá»ng Ä‘Æ°á»£c há»c bá»Ÿi cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c tiá»n huáº¥n luyá»‡n
vÃ  giáº£m chi phÃ­ tÃ­nh toÃ¡n cáº§n thiáº¿t báº±ng cÃ¡ch chá»‰ táº­p trung vÃ o thÃ´ng tin quan
trá»ng tá»« Ä‘áº§u vÃ o mÃ´ hÃ¬nh [34] lÃ  ráº¥t mong muá»‘n.
Äá»ƒ hiá»ƒu thÃ´ng tin quan trá»ng Ä‘Æ°á»£c há»c bá»Ÿi cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c tiá»n huáº¥n luyá»‡n,
chÃºng tÃ´i thá»±c hiá»‡n phÃ¢n tÃ­ch thá»±c nghiá»‡m vá» CodeBERT â€“ má»™t mÃ´ hÃ¬nh Ä‘Æ°á»£c tiá»n
huáº¥n luyá»‡n cho ngÃ´n ngá»¯ láº­p trÃ¬nh vÃ  ngÃ´n ngá»¯ tá»± nhiÃªn. NghiÃªn cá»©u cá»§a chÃºng
tÃ´i nháº±m tÃ¬m hiá»ƒu (i) CodeBERT chÃº Ã½ nhiá»u nháº¥t Ä‘áº¿n nhá»¯ng loáº¡i token nÃ o; vÃ 
(ii) nhá»¯ng loáº¡i cÃ¢u lá»‡nh nÃ o quan trá»ng nháº¥t Ä‘á»‘i vá»›i CodeBERT khi há»c biá»ƒu diá»…n
code. Äá»ƒ tráº£ lá»i hai cÃ¢u há»i nÃ y, chÃºng tÃ´i phÃ¢n loáº¡i token vÃ  cÃ¢u lá»‡nh thÃ nh
má»™t sá»‘ lá»›p vÃ  tÃ³m táº¯t trá»ng sá»‘ chÃº Ã½ cá»§a má»—i lá»›p mÃ  CodeBERT Ä‘Æ°á»£c tiá»n huáº¥n
luyá»‡n gÃ¡n cho. Káº¿t quáº£ cá»§a chÃºng tÃ´i cho tháº¥y cÃ¡c tá»« khÃ³a vÃ  kiá»ƒu dá»¯ liá»‡u lÃ 
nhá»¯ng token quan trá»ng nháº¥t mÃ  CodeBERT táº­p trung vÃ o. Vá» máº·t cÃ¢u lá»‡nh,
CodeBERT chÃº Ã½ nhiá»u hÆ¡n Ä‘áº¿n chá»¯ kÃ½ phÆ°Æ¡ng thá»©c vÃ  cÃ¢u lá»‡nh return, Ä‘iá»u nÃ y
cho tháº¥y chá»©c nÄƒng tá»•ng thá»ƒ cá»§a má»™t phÆ°Æ¡ng thá»©c.
Dá»±a trÃªn nhá»¯ng phÃ¡t hiá»‡n thá»±c nghiá»‡m nÃ y, chÃºng tÃ´i Ä‘á» xuáº¥t DietCode, má»™t
phÆ°Æ¡ng phÃ¡p má»›i nháº±m táº­n dá»¥ng nháº¹ nhÃ ng cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c tiá»n huáº¥n luyá»‡n lá»›n
cho mÃ£ nguá»“n. DietCode giáº£m Ä‘á»™ phá»©c táº¡p tÃ­nh toÃ¡n cá»§a cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c tiá»n
huáº¥n luyá»‡n báº±ng cÃ¡ch loáº¡i bá» cÃ¡c token vÃ  cÃ¢u lá»‡nh khÃ´ng quan trá»ng khá»i cÃ¡c
chÆ°Æ¡ng trÃ¬nh Ä‘áº§u vÃ o. Ba chiáº¿n lÆ°á»£c pruning Ä‘Æ°á»£c Ä‘á» xuáº¥t, bao gá»“m word dropout,
frequency filtering, vÃ  attention-based pruning. Äáº·c biá»‡t, chiáº¿n lÆ°á»£c
attention-based pruning chá»n cÃ¡c token vÃ  cÃ¢u lá»‡nh nháº­n Ä‘Æ°á»£c sá»± chÃº Ã½ cao nháº¥t
tá»« cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c tiá»n huáº¥n luyá»‡n. Thuáº­t toÃ¡n Ä‘Æ¡n giáº£n hÃ³a chÆ°Æ¡ng trÃ¬nh cÃ´ng
thá»©c hÃ³a viá»‡c chá»n cÃ¢u lá»‡nh nhÆ° má»™t bÃ i toÃ¡n 0-1 knapsack trong Ä‘Ã³ cÃ¡c cÃ¢u lá»‡nh
Ä‘Æ°á»£c coi nhÆ° cÃ¡c váº­t pháº©m, vÃ  trá»ng sá»‘ chÃº Ã½ cá»§a chÃºng Ä‘Æ°á»£c coi nhÆ° giÃ¡ trá»‹.
Thuáº­t toÃ¡n chá»n cÃ¡c cÃ¢u lá»‡nh (váº­t pháº©m) dÆ°á»›i rÃ ng buá»™c cá»§a Ä‘á»™ dÃ i má»¥c tiÃªu Ä‘Ã£
cho (dung lÆ°á»£ng).
ChÃºng tÃ´i Ã¡p dá»¥ng DietCode cho hai tÃ¡c vá»¥ downstream, cá»¥ thá»ƒ lÃ  code search vÃ 
code summarization. ChÃºng tÃ´i Ä‘o lÆ°á»ng hiá»‡u suáº¥t vá»›i Ä‘á»™ dÃ i tÆ°Æ¡ng Ä‘á»‘i, FLOPs,
vÃ  chi phÃ­ thá»i gian, vÃ  so sÃ¡nh phÆ°Æ¡ng phÃ¡p cá»§a chÃºng tÃ´i vá»›i cÃ¡c mÃ´ hÃ¬nh
baseline, bao gá»“m mÃ´ hÃ¬nh code Ä‘Æ°á»£c tiá»n huáº¥n luyá»‡n gá»‘c vÃ  SIVAND [34]. Káº¿t
quáº£ thá»±c nghiá»‡m cho tháº¥y DietCode cung cáº¥p káº¿t quáº£ tÆ°Æ¡ng Ä‘Æ°Æ¡ng nhÆ° RoBERTa
(code), vá»›i chi phÃ­ tÃ­nh toÃ¡n Ã­t hÆ¡n gáº§n 40% trong fine-tuning vÃ  testing.
ÄÃ³ng gÃ³p cá»§a chÃºng tÃ´i cÃ³ thá»ƒ Ä‘Æ°á»£c tÃ³m táº¯t nhÆ° sau:
â€¢ChÃºng tÃ´i thá»±c hiá»‡n phÃ¢n tÃ­ch thá»±c nghiá»‡m sÃ¢u sáº¯c vá» cÃ¡c token vÃ  cÃ¢u lá»‡nh
quan trá»ng Ä‘Æ°á»£c há»c bá»Ÿi CodeBERT.
â€¢ChÃºng tÃ´i Ä‘á» xuáº¥t má»™t phÆ°Æ¡ng phÃ¡p Ä‘Æ¡n giáº£n hÃ³a chÆ°Æ¡ng trÃ¬nh má»›i cho cÃ¡c mÃ´
hÃ¬nh ngÃ´n ngá»¯ láº­p trÃ¬nh Ä‘Æ°á»£c tiá»n huáº¥n luyá»‡n cÃ³ thá»ƒ giáº£m Ä‘Ã¡ng ká»ƒ chi phÃ­ tÃ­nh
toÃ¡n trong khi duy trÃ¬ hiá»‡u suáº¥t tÆ°Æ¡ng Ä‘Æ°Æ¡ng.
â€¢ChÃºng tÃ´i Ä‘Ã¡nh giÃ¡ rá»™ng rÃ£i phÆ°Æ¡ng phÃ¡p Ä‘á» xuáº¥t trong hai tÃ¡c vá»¥ downstream
vÃ  cho tháº¥y hiá»‡u quáº£ cá»§a phÆ°Æ¡ng phÃ¡p cá»§a chÃºng tÃ´i.
2 Bá»I Cáº¢NH
2.1 CÃ¡c MÃ´ HÃ¬nh NgÃ´n Ngá»¯ ÄÆ°á»£c Tiá»n Huáº¥n Luyá»‡n
CÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ Ä‘Æ°á»£c tiá»n huáº¥n luyá»‡n nhÆ° BERT [14], GPT-2 [35], vÃ  T5
[36] Ä‘Ã£ Ä‘áº¡t Ä‘Æ°á»£c thÃ nh cÃ´ng Ä‘Ã¡ng chÃº Ã½ trong nhiá»u tÃ¡c vá»¥ NLP khÃ¡c nhau [12,13,47].
ChÃºng Ä‘á» cáº­p Ä‘áº¿n cÃ¡c mÃ´ hÃ¬nh máº¡ng nÆ¡-ron Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn cÃ¡c kho vÄƒn báº£n
lá»›n vÃ  cÃ³ thá»ƒ Ä‘Æ°á»£c fine-tuned cho cÃ¡c tÃ¡c vá»¥ downstream cÃ³ Ã­t tÃ i nguyÃªn.
CÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c tiá»n huáº¥n luyá»‡n tiÃªn tiáº¿n chá»§ yáº¿u Ä‘Æ°á»£c xÃ¢y dá»±ng dá»±a trÃªn kiáº¿n
trÃºc Transformer [43]. Transformer lÃ  má»™t mÃ´ hÃ¬nh há»c sequence-to-sequence sá»­
dá»¥ng cÆ¡ cháº¿ attention [4]. NÃ³ dá»±a trÃªn kiáº¿n trÃºc encoder-decoder, trong Ä‘Ã³ má»™t
chuá»—i nguá»“n Ä‘Æ°á»£c mÃ£ hÃ³a thÃ nh cÃ¡c tráº¡ng thÃ¡i áº©n vÃ  sau Ä‘Ã³ Ä‘Æ°á»£c Ä‘Æ°a lÃ m Ä‘áº§u vÃ o
cho decoder Ä‘á»ƒ táº¡o ra má»™t chuá»—i Ä‘Ã­ch. Cáº£ encoder vÃ  decoder Ä‘á»u chá»©a nhiá»u lá»›p
giá»‘ng há»‡t nhau, vÃ  má»—i lá»›p bao gá»“m má»™t máº¡ng multi-head self-attention theo sau
bá»Ÿi má»™t máº¡ng feed-forward. Cáº£ hai Ä‘áº§u ra sáº½ Ä‘Æ°á»£c chuáº©n hÃ³a trÆ°á»›c khi Ä‘i vÃ o
lá»›p tiáº¿p theo.
ThÃ nh pháº§n chÃ­nh cá»§a Transformer lÃ  cÆ¡ cháº¿ self-attention biá»ƒu diá»…n má»™t chuá»—i
báº±ng cÃ¡ch liÃªn káº¿t cÃ¡c token á»Ÿ cÃ¡c vá»‹ trÃ­ khÃ¡c nhau [43]. Má»¥c tiÃªu cá»§a
self-attention lÃ  há»c cÃ¡c vÃ¹ng quan trá»ng trong chuá»—i Ä‘áº§u vÃ o. KhÃ´ng giá»‘ng nhÆ°
cÃ¡c máº¡ng nÆ¡-ron tuáº§n hoÃ n truyá»n thá»‘ng [10], cÃ¡c máº¡ng self-attention cÃ³ thá»ƒ há»c
cÃ¡c phá»¥ thuá»™c tá»« cÃ¡c token xa trong song song. Äá»‘i vá»›i má»™t chuá»—i Ä‘áº§u vÃ o
(ğ‘¥1,...,ğ‘¥ğ‘›) cÃ³ Ä‘á»™ dÃ i ğ‘›, self-attention táº¡o ra biá»ƒu diá»…n cá»§a nÃ³ (ğ‘§1,ğ‘§2...ğ‘§ğ‘›) nhÆ°
ğ‘§ğ‘–=ğ‘›âˆ‘ï¸ğ‘—=1Softmax((ğ‘¥ğ‘–ğ‘Šğ‘„)Â·(ğ‘¥ğ‘—ğ‘Šğ¾)ğ‘‡/âˆšğ‘‘)Â·ğ‘¥ğ‘—ğ‘Šğ‘‰(1)
trong Ä‘Ã³ ğ‘Šğ‘„,ğ‘Šğ¾, vÃ  ğ‘Šğ‘‰ biá»ƒu thá»‹ cÃ¡c tham sá»‘ cá»§a mÃ´ hÃ¬nh. ğ‘‘ lÃ  chiá»u cá»§a ma tráº­n
Ä‘áº§u vÃ o. MÃ´ hÃ¬nh bao gá»“m má»™t sá»‘ attention head, vÃ  Ä‘áº§u ra cá»§a má»—i head Ä‘Æ°á»£c
ná»‘i láº¡i thÃ nh káº¿t quáº£ cuá»‘i cÃ¹ng.
CÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c tiá»n huáº¥n luyá»‡n thÆ°á»ng bao gá»“m cÃ¡c tham sá»‘ quy mÃ´ lá»›n vÃ  tiÃªu
thá»¥ tÃ i nguyÃªn tÃ­nh toÃ¡n khá»•ng lá»“. VÃ­ dá»¥, BERT-base vÃ  BERT-large chá»©a tÆ°Æ¡ng
á»©ng 110M vÃ  340M tham sá»‘. Do Ä‘Ã³, viá»‡c táº­n dá»¥ng nháº¹ nhÃ ng cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c tiá»n
huáº¥n luyá»‡n lÃ  ráº¥t mong muá»‘n cho nghiÃªn cá»©u vÃ  cÃ¡c nhÃ  thá»±c hÃ nh [39].
2.2 CodeBERT
Gáº§n Ä‘Ã¢y, cÃ¡c nhÃ  nghiÃªn cá»©u Ä‘Ã£ Ã¡p dá»¥ng BERT cho cÃ¡c tÃ¡c vá»¥ ká»¹ thuáº­t pháº§n má»m
vÃ  Ä‘á» xuáº¥t CodeBERT [15]. CodeBERT lÃ  má»™t mÃ´ hÃ¬nh Ä‘Æ°á»£c tiá»n huáº¥n luyá»‡n bimodal
cho ngÃ´n ngá»¯ tá»± nhiÃªn vÃ  ngÃ´n ngá»¯ láº­p trÃ¬nh, náº¯m báº¯t cÃ¡c biá»ƒu diá»…n ngá»¯ nghÄ©a
tá»« ngÃ´n ngá»¯ láº­p trÃ¬nh [15]. CÃ¡c biá»ƒu diá»…n chÆ°Æ¡ng trÃ¬nh Ä‘Æ°á»£c há»c bá»Ÿi CodeBERT cÃ³
thá»ƒ Ä‘Æ°á»£c sá»­ dá»¥ng thÃªm cho cÃ¡c tÃ¡c vá»¥ downstream nhÆ° code search vÃ  code
summarization.
CodeBERT Ä‘Æ°á»£c xÃ¢y dá»±ng dá»±a trÃªn má»™t encoder Transformer [43]. Viá»‡c tá»‘i Æ°u hÃ³a
bao gá»“m hai tÃ¡c vá»¥: masked language modeling (MLM) vÃ  replaced token
detection (RTD). MLM che hai token ngáº«u nhiÃªn tá»« cáº·p Ä‘áº§u vÃ o cá»§a code vÃ 
comment ngÃ´n ngá»¯ tá»± nhiÃªn, vÃ  nháº±m dá»± Ä‘oÃ¡n token gá»‘c trong má»™t tá»« vá»±ng má»Ÿ
rá»™ng. RTD bao gá»“m hai generator vÃ  má»™t discriminator. CÃ¡c generator dá»± Ä‘oÃ¡n
token gá»‘c cho token bá»‹ che trong khi discriminator dá»± Ä‘oÃ¡n liá»‡u cÃ¡c token cÃ³
pháº£i lÃ  gá»‘c hay khÃ´ng. Sau khi tiá»n huáº¥n luyá»‡n, CodeBERT cÃ³ thá»ƒ Ä‘Æ°á»£c Ä‘iá»u chá»‰nh
cho cÃ¡c tÃ¡c vá»¥ downstream thÃ´ng qua fine-tuning trÃªn táº­p dá»¯ liá»‡u Ä‘Ã­ch.
3 PHÃ‚N TÃCH THá»°C NGHIá»†M
3.1 Thiáº¿t Káº¿ NghiÃªn Cá»©u
Trong pháº§n nÃ y, chÃºng tÃ´i mÃ´ táº£ phÆ°Æ¡ng phÃ¡p nghiÃªn cá»©u vÃ  thiáº¿t láº­p thá»±c nghiá»‡m
cá»§a chÃºng tÃ´i. CÃ³ nhiá»u má»©c Ä‘á»™ chi tiáº¿t cho code, cháº³ng háº¡n nhÆ° token, cÃ¢u lá»‡nh,
vÃ  hÃ m. NhÆ° má»™t nghiÃªn cá»©u sÃ¢u sáº¯c, chÃºng tÃ´i báº¯t Ä‘áº§u báº±ng viá»‡c Ä‘iá»u tra Ä‘Æ¡n vá»‹
nguyÃªn tá»­ cá»§a mÃ£ nguá»“n, cá»¥ thá»ƒ lÃ  token. Tiáº¿p theo, chÃºng tÃ´i Ä‘iá»u tra kiáº¿n thá»©c
á»Ÿ má»©c cÃ¢u lá»‡nh Ä‘Æ°á»£c há»c bá»Ÿi CodeBERT, trong Ä‘Ã³ chá»©a cÃ¡c cáº¥u trÃºc cÆ¡ báº£n vÃ  Ä‘Æ¡n
vá»‹ ngá»¯ nghÄ©a. Cuá»‘i cÃ¹ng, chÃºng tÃ´i khÃ¡m phÃ¡ kiáº¿n thá»©c á»Ÿ má»©c hÃ m Ä‘Æ°á»£c há»c bá»Ÿi
CodeBERT thÃ´ng qua cÃ¡c tÃ¡c vá»¥ downstream. TÃ³m láº¡i, chÃºng tÃ´i thiáº¿t káº¿ phÆ°Æ¡ng
phÃ¡p nghiÃªn cá»©u cá»§a mÃ¬nh báº±ng cÃ¡ch giáº£i quyáº¿t cÃ¡c cÃ¢u há»i nghiÃªn cá»©u sau:
â€¢RQ1: CodeBERT há»c vá» nhá»¯ng token quan trá»ng nÃ o? ChÃºng tÃ´i nghiÃªn cá»©u
thÃ´ng tin quan trá»ng mÃ  CodeBERT há»c Ä‘Æ°á»£c á»Ÿ má»©c token báº±ng cÃ¡ch phÃ¢n tÃ­ch
trá»ng sá»‘ chÃº Ã½ Ä‘Æ°á»£c gÃ¡n cho cÃ¡c token nÃ y vÃ  trá»±c quan hÃ³a táº§m quan trá»ng
tÆ°Æ¡ng Ä‘á»‘i cá»§a chÃºng.
â€¢RQ2: CodeBERT há»c vá» nhá»¯ng cÃ¢u lá»‡nh quan trá»ng nÃ o? ChÃºng tÃ´i tiáº¿p tá»¥c
nghiÃªn cá»©u cÃ¡c cÃ¢u lá»‡nh mÃ  CodeBERT gÃ¡n trá»ng sá»‘ cao nháº¥t. ChÃºng tÃ´i phÃ¢n
loáº¡i cÃ¡c cÃ¢u lá»‡nh code thÃ nh cÃ¡c danh má»¥c phá»• biáº¿n nhÆ° initialization,
assignment, vÃ  return, vÃ  trÃ¬nh bÃ y trá»ng sá»‘ chÃº Ã½ cá»§a má»—i danh má»¥c Ä‘Æ°á»£c gÃ¡n
bá»Ÿi CodeBERT.
Äá»ƒ tráº£ lá»i nhá»¯ng cÃ¢u há»i nÃ y, trÆ°á»›c tiÃªn chÃºng tÃ´i cáº§n biáº¿t cÃ¡ch biá»ƒu diá»…n thÃ´ng
tin chÃ­nh Ä‘Æ°á»£c há»c bá»Ÿi CodeBERT. NÃ³i cÃ¡ch khÃ¡c, lÃ m tháº¿ nÃ o Ä‘á»ƒ Ä‘o lÆ°á»ng táº§m
quan trá»ng cá»§a má»—i token vÃ  cÃ¢u lá»‡nh? VÃ¬ trÃ¡i tim cá»§a CodeBERT lÃ  máº¡ng
self-attention, trong Ä‘Ã³ cÃ¡c tráº¡ng thÃ¡i áº©n cá»§a má»—i token Ä‘Æ°á»£c tÃ­nh toÃ¡n tá»«ng lá»›p
theo trá»ng sá»‘ self-attention, chÃºng tÃ´i Ä‘o lÆ°á»ng táº§m quan trá»ng cá»§a má»—i token
báº±ng cÃ¡ch sá»­ dá»¥ng trá»ng sá»‘ chÃº Ã½ trong cÃ¡c lá»›p Transformer trong CodeBERT sau
khi tiá»n huáº¥n luyá»‡n. Tiáº¿p theo, chÃºng tÃ´i sáº½ trÃ¬nh bÃ y chi tiáº¿t vá» cÃ¡ch Ä‘o lÆ°á»ng
táº§m quan trá»ng cá»§a token vÃ  cÃ¢u lá»‡nh, tÆ°Æ¡ng á»©ng.
3.1.1 Äo LÆ°á»ng Táº§m Quan Trá»ng Token Báº±ng Trá»ng Sá»‘ ChÃº Ã. NhÆ° Ä‘Æ°á»£c giá»›i
thiá»‡u trong Pháº§n 2.2, CodeBERT nháº­n má»™t chuá»—i cÃ¡c token mÃ£ nguá»“n lÃ m Ä‘áº§u vÃ o
vÃ  táº¡o ra má»™t trá»ng sá»‘ self-attention cho má»—i token Ä‘áº§u vÃ o. Má»—i trá»ng sá»‘ Ä‘o
lÆ°á»ng má»©c Ä‘á»™ token tÆ°Æ¡ng á»©ng nháº­n Ä‘Æ°á»£c sá»± chÃº Ã½ tá»« cÃ¡c token khÃ¡c trong chuá»—i
Ä‘áº§u vÃ o. Trá»ng sá»‘ chÃº Ã½ cÃ ng cao, cÃ ng nhiá»u sá»± chÃº Ã½ Ä‘Æ°á»£c dÃ nh bá»Ÿi cÃ¡c token
khÃ¡c. Do Ä‘Ã³, trong nghiÃªn cá»©u cá»§a chÃºng tÃ´i, chÃºng tÃ´i Ä‘o lÆ°á»ng táº§m quan trá»ng
cá»§a má»—i token báº±ng cÃ¡ch sá»­ dá»¥ng trá»ng sá»‘ chÃº Ã½. CodeBERT cÃ³ nhiá»u lá»›p vÃ  head
self-attention, má»—i lá»›p táº¡o ra má»™t trá»ng sá»‘ chÃº Ã½ cho cÃ¹ng má»™t token. ChÃºng tÃ´i
láº¥y trung bÃ¬nh trá»ng sá»‘ chÃº Ã½ cá»§a táº¥t cáº£ cÃ¡c lá»›p vÃ  head cho má»—i token. Trong
cÃ¡c thá»­ nghiá»‡m cá»§a chÃºng tÃ´i, chÃºng tÃ´i Ä‘i qua kho dá»¯ liá»‡u CodeSearchNet [20]
vÃ  láº¥y lÃ m Ä‘áº§u vÃ o má»—i Ä‘oáº¡n code cho CodeBERT Ä‘Æ°á»£c tiá»n huáº¥n luyá»‡n. Sau Ä‘Ã³,
chÃºng tÃ´i tÃ­nh toÃ¡n trá»ng sá»‘ chÃº Ã½ trung bÃ¬nh mÃ  CodeBERT gÃ¡n cho má»—i token.
3.1.2 TÃ­nh ToÃ¡n ChÃº Ã cá»§a CÃ¢u Lá»‡nh. Sau khi cÃ³ Ä‘Æ°á»£c táº§m quan trá»ng cá»§a má»—i
token, chÃºng tÃ´i tÃ­nh toÃ¡n trá»ng sá»‘ chÃº Ã½ cho má»—i cÃ¢u lá»‡nh. Trá»±c quan, trá»ng sá»‘
chÃº Ã½ cho má»™t cÃ¢u lá»‡nh cÃ³ thá»ƒ Ä‘Æ¡n giáº£n Ä‘Æ°á»£c láº¥y báº±ng cÃ¡ch sá»­ dá»¥ng trá»ng sá»‘ chÃº
Ã½ trung bÃ¬nh cá»§a táº¥t cáº£ cÃ¡c token cá»§a nÃ³. Tuy nhiÃªn, cÃ¡c token khÃ¡c nhau trong
má»™t cÃ¢u lá»‡nh cÃ³ táº§m quan trá»ng khÃ¡c nhau. MÃ  khÃ´ng xem xÃ©t táº§m quan trá»ng
toÃ n cá»¥c cá»§a má»—i token, cÃ¡c cÃ¢u lá»‡nh bao gá»“m cÃ¡c token khÃ´ng quan trá»ng cÃ³ thá»ƒ
tháº­m chÃ­ cÃ³ Ä‘Æ°á»£c sá»± chÃº Ã½ cao hÆ¡n. Dá»±a trÃªn má»‘i quan tÃ¢m nÃ y, chÃºng tÃ´i Ä‘iá»u
chá»‰nh sá»± chÃº Ã½ cÃ¢u lá»‡nh báº±ng cÃ¡ch pháº¡t cÃ¡c token khÃ´ng quan trá»ng nháº­n Ä‘Æ°á»£c Ã­t
trá»ng sá»‘ chÃº Ã½ hÆ¡n trÃªn toÃ n bá»™ kho dá»¯ liá»‡u. Cá»¥ thá»ƒ hÆ¡n, chÃºng tÃ´i tÃ­nh toÃ¡n
trá»ng sá»‘ chÃº Ã½ cho má»™t cÃ¢u lá»‡nh ğ‘† báº±ng cÃ¡ch sá»­ dá»¥ng trung bÃ¬nh cÃ³ trá»ng sá»‘ cá»§a
trá»ng sá»‘ chÃº Ã½ cá»§a cÃ¡c token cá»§a nÃ³:
ğ‘(ğ‘†)=âˆ‘ï¸ğ‘¡âˆˆğ‘†ğ‘¤(ğ‘¡)Â·ğ‘(ğ‘¡) (2)
trong Ä‘Ã³ ğ‘(ğ‘¡) biá»ƒu thá»‹ trá»ng sá»‘ chÃº Ã½ cá»§a token ğ‘¡ trong cÃ¢u lá»‡nh ğ‘†; ğ‘¤(ğ‘¡) biá»ƒu
thá»‹ trá»ng sá»‘ chÃº Ã½ chuáº©n hÃ³a cá»§a token ğ‘¡ trong toÃ n bá»™ kho dá»¯ liá»‡u Ä‘Æ°á»£c mÃ´ táº£
trong pháº§n trÆ°á»›c. Viá»‡c chuáº©n hÃ³a Ä‘Æ°á»£c thá»±c hiá»‡n báº±ng hÃ m Softmax, cá»¥ thá»ƒ,
ğ‘¤(ğ‘¡)=Softmaxğ‘¡âˆˆğ‘†(ğ‘(ğ‘¡)) (3)
KhÃ´ng giá»‘ng nhÆ° token, cÃ¡c cÃ¢u lá»‡nh thÆ°á»ng lÃ  duy nháº¥t trong kho dá»¯ liá»‡u vÃ 
khÃ´ng thá»ƒ Ä‘Æ°á»£c bao gá»“m trong tá»« Ä‘iá»ƒn. Äá»ƒ phÃ¢n tÃ­ch hiá»‡u quáº£ cÃ¡c cÃ¢u lá»‡nh, chÃºng
tÃ´i phÃ¢n loáº¡i cÃ¡c cÃ¢u lá»‡nh thÃ nh 21 danh má»¥c nhÆ° method signature, variable
declaration, vÃ  if condition, vÃ  chá»‰ trÃ¬nh bÃ y trá»ng sá»‘ chÃº Ã½ trung bÃ¬nh cho má»—i
danh má»¥c. CÃ¡c danh má»¥c nÃ y chá»§ yáº¿u Ä‘Æ°á»£c hÆ°á»›ng dáº«n bá»Ÿi Ä‘áº·c táº£ Java [16]. Äáº·c
biá»‡t, danh má»¥c logger chá»©a cÃ¡c cÃ¢u lá»‡nh vá»›i cÃ¡c chá»©c nÄƒng logging tiÃªu chuáº©n nhÆ°
log4j, Logger, vÃ  println. Báº£ng 1 cho tháº¥y cÃ¡c danh má»¥c cÃ¢u lá»‡nh mÃ  chÃºng tÃ´i
Ä‘Ã£ tÃ³m táº¯t vÃ  sá»‘ lÆ°á»£ng tÆ°Æ¡ng á»©ng trong kho dá»¯ liá»‡u CodeSearchNet. ChÃºng ta cÃ³
thá»ƒ tháº¥y ráº±ng function invocation vÃ  method signature lÃ  nhá»¯ng cÃ¢u lá»‡nh phá»•
biáº¿n nháº¥t, trong khi cÃ¡c cÃ¢u lá»‡nh vÃ²ng láº·p nhÆ° while tÆ°Æ¡ng Ä‘á»‘i hiáº¿m.

--- TRANG 2 ---
ESEC/FSE '22, November 14â€“18, 2022, Singapore, Singapore Zhang, et al.
tÆ°Æ¡ng Ä‘á»‘i length, FLOPs, vÃ  time cost, vÃ  so sÃ¡nh phÆ°Æ¡ng phÃ¡p cá»§a chÃºng tÃ´i
vá»›i cÃ¡c mÃ´ hÃ¬nh baseline, bao gá»“m mÃ´ hÃ¬nh code Ä‘Æ°á»£c tiá»n huáº¥n luyá»‡n gá»‘c vÃ 
SIVAND [34]. Káº¿t quáº£ thá»±c nghiá»‡m cho tháº¥y DietCode cung cáº¥p káº¿t quáº£ tÆ°Æ¡ng
Ä‘Æ°Æ¡ng nhÆ° RoBERTa (code), vá»›i gáº§n 40% Ã­t chi phÃ­ tÃ­nh toÃ¡n hÆ¡n trong
fine-tuning vÃ  testing.
ÄÃ³ng gÃ³p cá»§a chÃºng tÃ´i cÃ³ thá»ƒ Ä‘Æ°á»£c tÃ³m táº¯t nhÆ° sau:
â€¢ChÃºng tÃ´i thá»±c hiá»‡n phÃ¢n tÃ­ch thá»±c nghiá»‡m sÃ¢u sáº¯c vá» cÃ¡c token vÃ  cÃ¢u lá»‡nh
quan trá»ng Ä‘Æ°á»£c há»c bá»Ÿi CodeBERT.
â€¢ChÃºng tÃ´i Ä‘á» xuáº¥t má»™t phÆ°Æ¡ng phÃ¡p Ä‘Æ¡n giáº£n hÃ³a chÆ°Æ¡ng trÃ¬nh má»›i cho cÃ¡c mÃ´
hÃ¬nh ngÃ´n ngá»¯ láº­p trÃ¬nh Ä‘Æ°á»£c tiá»n huáº¥n luyá»‡n cÃ³ thá»ƒ giáº£m Ä‘Ã¡ng ká»ƒ chi phÃ­ tÃ­nh
toÃ¡n trong khi duy trÃ¬ hiá»‡u suáº¥t tÆ°Æ¡ng Ä‘Æ°Æ¡ng.
â€¢ChÃºng tÃ´i Ä‘Ã¡nh giÃ¡ rá»™ng rÃ£i phÆ°Æ¡ng phÃ¡p Ä‘á» xuáº¥t trong hai tÃ¡c vá»¥ downstream
vÃ  cho tháº¥y hiá»‡u quáº£ cá»§a phÆ°Æ¡ng phÃ¡p cá»§a chÃºng tÃ´i.
2 Bá»I Cáº¢NH
2.1 CÃ¡c MÃ´ HÃ¬nh NgÃ´n Ngá»¯ ÄÆ°á»£c Tiá»n Huáº¥n Luyá»‡n
CÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ Ä‘Æ°á»£c tiá»n huáº¥n luyá»‡n nhÆ° BERT [14], GPT-2 [35], vÃ  T5
[36] Ä‘Ã£ Ä‘áº¡t Ä‘Æ°á»£c thÃ nh cÃ´ng Ä‘Ã¡ng chÃº Ã½ trong nhiá»u tÃ¡c vá»¥ NLP khÃ¡c nhau [12,13,47].
ChÃºng Ä‘á» cáº­p Ä‘áº¿n cÃ¡c mÃ´ hÃ¬nh máº¡ng nÆ¡-ron Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn cÃ¡c kho vÄƒn báº£n
lá»›n vÃ  cÃ³ thá»ƒ Ä‘Æ°á»£c fine-tuned cho cÃ¡c tÃ¡c vá»¥ downstream cÃ³ Ã­t tÃ i nguyÃªn.
CÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c tiá»n huáº¥n luyá»‡n tiÃªn tiáº¿n chá»§ yáº¿u Ä‘Æ°á»£c xÃ¢y dá»±ng dá»±a trÃªn kiáº¿n
trÃºc Transformer [43]. Transformer lÃ  má»™t mÃ´ hÃ¬nh há»c sequence-to-sequence sá»­
dá»¥ng cÆ¡ cháº¿ attention [4]. NÃ³ dá»±a trÃªn kiáº¿n trÃºc encoder-decoder, trong Ä‘Ã³ má»™t
chuá»—i nguá»“n Ä‘Æ°á»£c mÃ£ hÃ³a thÃ nh cÃ¡c tráº¡ng thÃ¡i áº©n vÃ  sau Ä‘Ã³ Ä‘Æ°á»£c Ä‘Æ°a lÃ m Ä‘áº§u vÃ o
cho decoder Ä‘á»ƒ táº¡o ra má»™t chuá»—i Ä‘Ã­ch. Cáº£ encoder vÃ  decoder Ä‘á»u chá»©a nhiá»u lá»›p
giá»‘ng há»‡t nhau, vÃ  má»—i lá»›p bao gá»“m má»™t máº¡ng multi-head self-attention theo sau
bá»Ÿi má»™t máº¡ng feed-forward. Cáº£ hai Ä‘áº§u ra sáº½ Ä‘Æ°á»£c chuáº©n hÃ³a trÆ°á»›c khi Ä‘i vÃ o
lá»›p tiáº¿p theo.
ThÃ nh pháº§n chÃ­nh cá»§a Transformer lÃ  cÆ¡ cháº¿ self-attention biá»ƒu diá»…n má»™t chuá»—i
báº±ng cÃ¡ch liÃªn káº¿t cÃ¡c token á»Ÿ cÃ¡c vá»‹ trÃ­ khÃ¡c nhau [43]. Má»¥c tiÃªu cá»§a
self-attention lÃ  há»c cÃ¡c vÃ¹ng quan trá»ng trong chuá»—i Ä‘áº§u vÃ o. KhÃ´ng giá»‘ng nhÆ°
cÃ¡c máº¡ng nÆ¡-ron tuáº§n hoÃ n truyá»n thá»‘ng [10], cÃ¡c máº¡ng self-attention cÃ³ thá»ƒ há»c
cÃ¡c phá»¥ thuá»™c tá»« cÃ¡c token xa trong song song. Äá»‘i vá»›i má»™t chuá»—i Ä‘áº§u vÃ o
(ğ‘¥1,...,ğ‘¥ğ‘›) cÃ³ Ä‘á»™ dÃ i ğ‘›, self-attention táº¡o ra biá»ƒu diá»…n cá»§a nÃ³ (ğ‘§1,ğ‘§2...ğ‘§ğ‘›) nhÆ°
ğ‘§ğ‘–=ğ‘›âˆ‘ï¸ğ‘—=1Softmax((ğ‘¥ğ‘–ğ‘Šğ‘„)Â·(ğ‘¥ğ‘—ğ‘Šğ¾)ğ‘‡/âˆšğ‘‘)Â·ğ‘¥ğ‘—ğ‘Šğ‘‰(1)
trong Ä‘Ã³ ğ‘Šğ‘„,ğ‘Šğ¾, vÃ  ğ‘Šğ‘‰ biá»ƒu thá»‹ cÃ¡c tham sá»‘ cá»§a mÃ´ hÃ¬nh. ğ‘‘ lÃ  chiá»u cá»§a ma tráº­n
Ä‘áº§u vÃ o. MÃ´ hÃ¬nh bao gá»“m má»™t sá»‘ attention head, vÃ  Ä‘áº§u ra cá»§a má»—i head Ä‘Æ°á»£c
ná»‘i láº¡i thÃ nh káº¿t quáº£ cuá»‘i cÃ¹ng.
CÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c tiá»n huáº¥n luyá»‡n thÆ°á»ng bao gá»“m cÃ¡c tham sá»‘ quy mÃ´ lá»›n vÃ  tiÃªu
thá»¥ tÃ i nguyÃªn tÃ­nh toÃ¡n khá»•ng lá»“. VÃ­ dá»¥, BERT-base vÃ  BERT-large chá»©a tÆ°Æ¡ng
á»©ng 110M vÃ  340M tham sá»‘. Do Ä‘Ã³, viá»‡c táº­n dá»¥ng nháº¹ nhÃ ng cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c tiá»n
huáº¥n luyá»‡n lÃ  ráº¥t mong muá»‘n cho nghiÃªn cá»©u vÃ  cÃ¡c nhÃ  thá»±c hÃ nh [39].
2.2 CodeBERT
Gáº§n Ä‘Ã¢y, cÃ¡c nhÃ  nghiÃªn cá»©u Ä‘Ã£ Ã¡p dá»¥ng BERT cho cÃ¡c tÃ¡c vá»¥ ká»¹ thuáº­t pháº§n má»m
vÃ  Ä‘á» xuáº¥t CodeBERT [15]. CodeBERT lÃ  má»™t mÃ´ hÃ¬nh Ä‘Æ°á»£c tiá»n huáº¥n luyá»‡n bimodal
cho ngÃ´n ngá»¯ tá»± nhiÃªn vÃ  ngÃ´n ngá»¯ láº­p trÃ¬nh, náº¯m báº¯t cÃ¡c biá»ƒu diá»…n ngá»¯ nghÄ©a
tá»« ngÃ´n ngá»¯ láº­p trÃ¬nh [15]. CÃ¡c biá»ƒu diá»…n chÆ°Æ¡ng trÃ¬nh Ä‘Æ°á»£c há»c bá»Ÿi CodeBERT cÃ³
thá»ƒ Ä‘Æ°á»£c sá»­ dá»¥ng thÃªm cho cÃ¡c tÃ¡c vá»¥ downstream nhÆ° code search vÃ  code
summarization.
CodeBERT Ä‘Æ°á»£c xÃ¢y dá»±ng dá»±a trÃªn má»™t encoder Transformer [43]. Viá»‡c tá»‘i Æ°u hÃ³a
bao gá»“m hai tÃ¡c vá»¥: masked language modeling (MLM) vÃ  replaced token
detection (RTD). MLM che hai token ngáº«u nhiÃªn tá»« cáº·p Ä‘áº§u vÃ o cá»§a code vÃ 
comment ngÃ´n ngá»¯ tá»± nhiÃªn, vÃ  nháº±m dá»± Ä‘oÃ¡n token gá»‘c trong má»™t tá»« vá»±ng má»Ÿ
rá»™ng. RTD bao gá»“m hai generator vÃ  má»™t discriminator. CÃ¡c generator dá»± Ä‘oÃ¡n
token gá»‘c cho token bá»‹ che trong khi discriminator dá»± Ä‘oÃ¡n liá»‡u cÃ¡c token cÃ³
pháº£i lÃ  gá»‘c hay khÃ´ng. Sau khi tiá»n huáº¥n luyá»‡n, CodeBERT cÃ³ thá»ƒ Ä‘Æ°á»£c Ä‘iá»u chá»‰nh
cho cÃ¡c tÃ¡c vá»¥ downstream thÃ´ng qua fine-tuning trÃªn táº­p dá»¯ liá»‡u Ä‘Ã­ch.
3 PHÃ‚N TÃCH THá»°C NGHIá»†M
3.1 Thiáº¿t Káº¿ NghiÃªn Cá»©u
Trong pháº§n nÃ y, chÃºng tÃ´i mÃ´ táº£ phÆ°Æ¡ng phÃ¡p nghiÃªn cá»©u vÃ  thiáº¿t láº­p thá»±c nghiá»‡m
cá»§a chÃºng tÃ´i. CÃ³ nhiá»u má»©c Ä‘á»™ chi tiáº¿t cho code, cháº³ng háº¡n nhÆ° token, cÃ¢u lá»‡nh,
vÃ  hÃ m. NhÆ° má»™t nghiÃªn cá»©u sÃ¢u sáº¯c, chÃºng tÃ´i báº¯t Ä‘áº§u báº±ng viá»‡c Ä‘iá»u tra Ä‘Æ¡n vá»‹
nguyÃªn tá»­ cá»§a mÃ£ nguá»“n, cá»¥ thá»ƒ lÃ  token. Tiáº¿p theo, chÃºng tÃ´i Ä‘iá»u tra kiáº¿n thá»©c
á»Ÿ má»©c cÃ¢u lá»‡nh Ä‘Æ°á»£c há»c bá»Ÿi CodeBERT, trong Ä‘Ã³ chá»©a cÃ¡c cáº¥u trÃºc cÆ¡ báº£n vÃ  Ä‘Æ¡n
vá»‹ ngá»¯ nghÄ©a. Cuá»‘i cÃ¹ng, chÃºng tÃ´i khÃ¡m phÃ¡ kiáº¿n thá»©c á»Ÿ má»©c hÃ m Ä‘Æ°á»£c há»c bá»Ÿi
CodeBERT thÃ´ng qua cÃ¡c tÃ¡c vá»¥ downstream. TÃ³m láº¡i, chÃºng tÃ´i thiáº¿t káº¿ phÆ°Æ¡ng
phÃ¡p nghiÃªn cá»©u cá»§a mÃ¬nh báº±ng cÃ¡ch giáº£i quyáº¿t cÃ¡c cÃ¢u há»i nghiÃªn cá»©u sau:
â€¢RQ1: CodeBERT há»c vá» nhá»¯ng token quan trá»ng nÃ o? ChÃºng tÃ´i nghiÃªn cá»©u
thÃ´ng tin quan trá»ng mÃ  CodeBERT há»c Ä‘Æ°á»£c á»Ÿ má»©c token báº±ng cÃ¡ch phÃ¢n tÃ­ch
trá»ng sá»‘ chÃº Ã½ Ä‘Æ°á»£c gÃ¡n cho cÃ¡c token nÃ y vÃ  trá»±c quan hÃ³a táº§m quan trá»ng
tÆ°Æ¡ng Ä‘á»‘i cá»§a chÃºng.
â€¢RQ2: CodeBERT há»c vá» nhá»¯ng cÃ¢u lá»‡nh quan trá»ng nÃ o? ChÃºng tÃ´i tiáº¿p tá»¥c
nghiÃªn cá»©u cÃ¡c cÃ¢u lá»‡nh mÃ  CodeBERT gÃ¡n trá»ng sá»‘ cao nháº¥t. ChÃºng tÃ´i phÃ¢n
loáº¡i cÃ¡c cÃ¢u lá»‡nh code thÃ nh cÃ¡c danh má»¥c phá»• biáº¿n nhÆ° initialization,
assignment, vÃ  return, vÃ  trÃ¬nh bÃ y trá»ng sá»‘ chÃº Ã½ cá»§a má»—i danh má»¥c Ä‘Æ°á»£c gÃ¡n
bá»Ÿi CodeBERT.
Äá»ƒ tráº£ lá»i nhá»¯ng cÃ¢u há»i nÃ y, trÆ°á»›c tiÃªn chÃºng tÃ´i cáº§n biáº¿t cÃ¡ch biá»ƒu diá»…n thÃ´ng
tin chÃ­nh Ä‘Æ°á»£c há»c bá»Ÿi CodeBERT. NÃ³i cÃ¡ch khÃ¡c, lÃ m tháº¿ nÃ o Ä‘á»ƒ Ä‘o lÆ°á»ng táº§m
quan trá»ng cá»§a má»—i token vÃ  cÃ¢u lá»‡nh? VÃ¬ trÃ¡i tim cá»§a CodeBERT lÃ  máº¡ng
self-attention, trong Ä‘Ã³ cÃ¡c tráº¡ng thÃ¡i áº©n cá»§a má»—i token Ä‘Æ°á»£c tÃ­nh toÃ¡n tá»«ng lá»›p
theo trá»ng sá»‘ self-attention, chÃºng tÃ´i Ä‘o lÆ°á»ng táº§m quan trá»ng cá»§a má»—i token
báº±ng cÃ¡ch sá»­ dá»¥ng trá»ng sá»‘ chÃº Ã½ trong cÃ¡c lá»›p Transformer trong CodeBERT sau
khi tiá»n huáº¥n luyá»‡n. Tiáº¿p theo, chÃºng tÃ´i sáº½ trÃ¬nh bÃ y chi tiáº¿t vá» cÃ¡ch Ä‘o lÆ°á»ng
táº§m quan trá»ng cá»§a token vÃ  cÃ¢u lá»‡nh, tÆ°Æ¡ng á»©ng.
3.1.1 Äo LÆ°á»ng Táº§m Quan Trá»ng Token Báº±ng Trá»ng Sá»‘ ChÃº Ã. NhÆ° Ä‘Æ°á»£c giá»›i
thiá»‡u trong Pháº§n 2.2, CodeBERT nháº­n má»™t chuá»—i cÃ¡c token mÃ£ nguá»“n lÃ m Ä‘áº§u vÃ o
vÃ  táº¡o ra má»™t trá»ng sá»‘ self-attention cho má»—i token Ä‘áº§u vÃ o. Má»—i trá»ng sá»‘ Ä‘o
lÆ°á»ng má»©c Ä‘á»™ token tÆ°Æ¡ng á»©ng nháº­n Ä‘Æ°á»£c sá»± chÃº Ã½ tá»« cÃ¡c token khÃ¡c trong chuá»—i
Ä‘áº§u vÃ o. Trá»ng sá»‘ chÃº Ã½ cÃ ng cao, cÃ ng nhiá»u sá»± chÃº Ã½ Ä‘Æ°á»£c dÃ nh bá»Ÿi cÃ¡c token
khÃ¡c. Do Ä‘Ã³, trong nghiÃªn cá»©u cá»§a chÃºng tÃ´i, chÃºng tÃ´i Ä‘o lÆ°á»ng táº§m quan trá»ng
cá»§a má»—i token báº±ng cÃ¡ch sá»­ dá»¥ng trá»ng sá»‘ chÃº Ã½. CodeBERT cÃ³ nhiá»u lá»›p vÃ  head
self-attention, má»—i lá»›p táº¡o ra má»™t trá»ng sá»‘ chÃº Ã½

--- TRANG 3 ---
Diet Code Is Healthy: Simplifying Programs for Pre-trained Models of Code ESEC/FSE '22, November 14â€“18, 2022, Singapore, Singapore
Báº£ng 1: Thá»‘ng kÃª cÃ¡c cÃ¢u lá»‡nh. Arithmetic cÃ³ nghÄ©a lÃ  cÃ¡c cÃ¢u lá»‡nh chá»‰ cÃ³ cÃ¡c phÃ©p toÃ¡n toÃ¡n há»c. Function Invocation biá»ƒu thá»‹ cÃ¡c cÃ¢u lá»‡nh gá»i cÃ¡c hÃ m khÃ¡c.
Danh má»¥c Sá»‘ lÆ°á»£ng Danh má»¥c Sá»‘ lÆ°á»£ng
Function Invocation 16,558 Throw 1,460
Method Signature 11,755 Catch 1,309
Variable Declaration 11,701 Arithmetic 628
If Condition 11,646 Case 577
Annotation 8,980 While 459
Return 8,331 Break 341
Getter 3,092 Finally 297
For 2,190 Continue 142
Try 1,797 Switch 210
Logging 1,763 Synchronized 73
Setter 1,721
cho cÃ¹ng má»™t token. ChÃºng tÃ´i láº¥y trung bÃ¬nh trá»ng sá»‘ chÃº Ã½ cá»§a táº¥t cáº£ cÃ¡c lá»›p vÃ  head cho má»—i token. Trong cÃ¡c thá»­ nghiá»‡m cá»§a chÃºng tÃ´i, chÃºng tÃ´i Ä‘i qua kho dá»¯ liá»‡u CodeSearchNet [20] vÃ  láº¥y lÃ m Ä‘áº§u vÃ o má»—i Ä‘oáº¡n code cho CodeBERT Ä‘Æ°á»£c tiá»n huáº¥n luyá»‡n. Sau Ä‘Ã³, chÃºng tÃ´i tÃ­nh toÃ¡n trá»ng sá»‘ chÃº Ã½ trung bÃ¬nh mÃ  CodeBERT gÃ¡n cho má»—i token.
3.1.2 TÃ­nh ToÃ¡n ChÃº Ã cá»§a CÃ¢u Lá»‡nh. Sau khi cÃ³ Ä‘Æ°á»£c táº§m quan trá»ng cá»§a má»—i token, chÃºng tÃ´i tÃ­nh toÃ¡n trá»ng sá»‘ chÃº Ã½ cho má»—i cÃ¢u lá»‡nh. Trá»±c quan, trá»ng sá»‘ chÃº Ã½ cho má»™t cÃ¢u lá»‡nh cÃ³ thá»ƒ Ä‘Æ¡n giáº£n Ä‘Æ°á»£c láº¥y báº±ng cÃ¡ch sá»­ dá»¥ng trá»ng sá»‘ chÃº Ã½ trung bÃ¬nh cá»§a táº¥t cáº£ cÃ¡c token cá»§a nÃ³. Tuy nhiÃªn, cÃ¡c token khÃ¡c nhau trong má»™t cÃ¢u lá»‡nh cÃ³ táº§m quan trá»ng khÃ¡c nhau. MÃ  khÃ´ng xem xÃ©t táº§m quan trá»ng toÃ n cá»¥c cá»§a má»—i token, cÃ¡c cÃ¢u lá»‡nh bao gá»“m cÃ¡c token khÃ´ng quan trá»ng cÃ³ thá»ƒ tháº­m chÃ­ cÃ³ Ä‘Æ°á»£c sá»± chÃº Ã½ cao hÆ¡n. Dá»±a trÃªn má»‘i quan tÃ¢m nÃ y, chÃºng tÃ´i Ä‘iá»u chá»‰nh sá»± chÃº Ã½ cÃ¢u lá»‡nh báº±ng cÃ¡ch pháº¡t cÃ¡c token khÃ´ng quan trá»ng nháº­n Ä‘Æ°á»£c Ã­t trá»ng sá»‘ chÃº Ã½ hÆ¡n trÃªn toÃ n bá»™ kho dá»¯ liá»‡u. Cá»¥ thá»ƒ hÆ¡n, chÃºng tÃ´i tÃ­nh toÃ¡n trá»ng sá»‘ chÃº Ã½ cho má»™t cÃ¢u lá»‡nh ğ‘† báº±ng cÃ¡ch sá»­ dá»¥ng trung bÃ¬nh cÃ³ trá»ng sá»‘ cá»§a trá»ng sá»‘ chÃº Ã½ cá»§a cÃ¡c token cá»§a nÃ³:
ğ‘(ğ‘†)=âˆ‘ï¸ğ‘¡âˆˆğ‘†ğ‘¤(ğ‘¡)Â·ğ‘(ğ‘¡) (2)
trong Ä‘Ã³ ğ‘(ğ‘¡) biá»ƒu thá»‹ trá»ng sá»‘ chÃº Ã½ cá»§a token ğ‘¡ trong cÃ¢u lá»‡nh ğ‘†; ğ‘¤(ğ‘¡) biá»ƒu thá»‹ trá»ng sá»‘ chÃº Ã½ chuáº©n hÃ³a cá»§a token ğ‘¡ trong toÃ n bá»™ kho dá»¯ liá»‡u Ä‘Æ°á»£c mÃ´ táº£ trong pháº§n trÆ°á»›c. Viá»‡c chuáº©n hÃ³a Ä‘Æ°á»£c thá»±c hiá»‡n báº±ng hÃ m Softmax, cá»¥ thá»ƒ,
ğ‘¤(ğ‘¡)=Softmaxğ‘¡âˆˆğ‘†(ğ‘(ğ‘¡)) (3)
KhÃ´ng giá»‘ng nhÆ° token, cÃ¡c cÃ¢u lá»‡nh thÆ°á»ng lÃ  duy nháº¥t trong kho dá»¯ liá»‡u vÃ  khÃ´ng thá»ƒ Ä‘Æ°á»£c bao gá»“m trong tá»« Ä‘iá»ƒn. Äá»ƒ phÃ¢n tÃ­ch hiá»‡u quáº£ cÃ¡c cÃ¢u lá»‡nh, chÃºng tÃ´i phÃ¢n loáº¡i cÃ¡c cÃ¢u lá»‡nh thÃ nh 21 danh má»¥c nhÆ° method signature, variable declaration, vÃ  if condition, vÃ  chá»‰ trÃ¬nh bÃ y trá»ng sá»‘ chÃº Ã½ trung bÃ¬nh cho má»—i danh má»¥c. CÃ¡c danh má»¥c nÃ y chá»§ yáº¿u Ä‘Æ°á»£c hÆ°á»›ng dáº«n bá»Ÿi Ä‘áº·c táº£ Java [16]. Äáº·c biá»‡t, danh má»¥c logger chá»©a cÃ¡c cÃ¢u lá»‡nh vá»›i cÃ¡c chá»©c nÄƒng logging tiÃªu chuáº©n nhÆ° log4j, Logger, vÃ  println. Báº£ng 1 cho tháº¥y cÃ¡c danh má»¥c cÃ¢u lá»‡nh mÃ  chÃºng tÃ´i Ä‘Ã£ tÃ³m táº¯t vÃ  sá»‘ lÆ°á»£ng tÆ°Æ¡ng á»©ng trong kho dá»¯ liá»‡u CodeSearchNet. ChÃºng ta cÃ³ thá»ƒ tháº¥y ráº±ng function invocation vÃ  method signature lÃ  nhá»¯ng cÃ¢u lá»‡nh phá»• biáº¿n nháº¥t, trong khi cÃ¡c cÃ¢u lá»‡nh vÃ²ng láº·p nhÆ° while tÆ°Æ¡ng Ä‘á»‘i hiáº¿m.

3.2 Káº¿t Quáº£ vÃ  PhÃ¢n TÃ­ch
Trong pháº§n nÃ y, chÃºng tÃ´i trÃ¬nh bÃ y káº¿t quáº£ thá»­ nghiá»‡m cá»§a chÃºng tÃ´i cho má»—i cÃ¢u há»i nghiÃªn cá»©u.
3.2.1 CodeBERT há»c vá» cÃ¡c token code gÃ¬? (RQ1). HÃ¬nh 2 lÃ m ná»•i báº­t cÃ¡c token quan trá»ng trong Java nháº­n Ä‘Æ°á»£c nhiá»u sá»± chÃº Ã½ nháº¥t tá»« CodeBERT. Biá»ƒu Ä‘á»“ Ä‘Æ°á»£c tÃ³m táº¯t tá»« kho dá»¯ liá»‡u CodeSearchNet [20] chá»©a hÆ¡n 100,000 hÃ m Java. Äá»‘i vá»›i cÃ¡c token trong má»—i hÃ m, chÃºng tÃ´i tÃ­nh toÃ¡n trá»ng sá»‘ chÃº Ã½ cá»§a chÃºng vÃ  chÃ¨n chÃºng vÃ o báº£n Ä‘á»“ <token, attention> cho Ä‘áº¿n khi cÃ¡c khÃ³a cá»§a báº£n Ä‘á»“ á»•n Ä‘á»‹nh. Äá»ƒ dá»… trá»±c quan hÃ³a, chÃºng tÃ´i loáº¡i bá» cÃ¡c token xuáº¥t hiá»‡n Ã­t hÆ¡n 50 láº§n trong kho dá»¯ liá»‡u. Trong sá»‘ táº¥t cáº£ cÃ¡c token Java, coverage nháº­n Ä‘Æ°á»£c trá»ng sá»‘ chÃº Ã½ tháº¥p nháº¥t (5.43 ğ‘’-5) trong khi boolean cÃ³ trá»ng sá»‘ cao nháº¥t (2.94 ğ‘’-2). Äá»™ lá»‡ch chuáº©n cá»§a cÃ¡c trá»ng sá»‘ nÃ y lÃ  5.97 ğ‘’-3.
Káº¿t quáº£ cho tháº¥y CodeBERT gÃ¡n nhiá»u sá»± chÃº Ã½ hÆ¡n cho cÃ¡c tá»« khÃ³a Java nhÆ° public vÃ  boolean. Äiá»u nÃ y Ä‘Æ°á»£c mong Ä‘á»£i vÃ¬ cÃ¡c tá»« khÃ³a Java thÆ°á»ng xuyÃªn xuáº¥t hiá»‡n trong code Java vÃ  Ä‘Ã³ng vai trÃ² chi phá»‘i trong viá»‡c biá»ƒu diá»…n ngá»¯ nghÄ©a code. Má»™t danh má»¥c token khÃ¡c nháº­n Ä‘Æ°á»£c sá»± chÃº Ã½ cao lÃ  cÃ¡c Ä‘á»‹nh danh hÆ°á»›ng dá»¯ liá»‡u nhÆ° Map, List, vÃ  String, cÃ³ láº½ vÃ¬ chÃºng Ä‘á»‹nh nghÄ©a cÃ¡c cáº¥u trÃºc dá»¯ liá»‡u chÃ­nh trong má»™t hÃ m.
ÄÆ°á»£c thÃºc Ä‘áº©y bá»Ÿi phÃ¡t hiá»‡n nÃ y, chÃºng tÃ´i tiáº¿p tá»¥c nghiÃªn cá»©u sá»± chÃº Ã½ cá»§a cÃ¡c tá»« khÃ³a Java. HÃ¬nh 1 cho tháº¥y trá»ng sá»‘ chÃº Ã½ cá»§a má»—i tá»« khÃ³a Java. NhÆ° chÃºng ta cÃ³ thá»ƒ tháº¥y, tá»« khÃ³a private nháº­n Ä‘Æ°á»£c trá»ng sá»‘ chÃº Ã½ cao nháº¥t lÃ  1.15 ğ‘’-2 trong sá»‘ táº¥t cáº£ cÃ¡c tá»« khÃ³a, trong khi interface vÃ  transient nháº­n Ä‘Æ°á»£c trá»ng sá»‘ chÃº Ã½ tháº¥p nháº¥t láº§n lÆ°á»£t lÃ  7.14 ğ‘’-4 vÃ  9.62ğ‘’-4. Äá»™ lá»‡ch chuáº©n cá»§a cÃ¡c trá»ng sá»‘ nÃ y lÃ  1.513ğ‘’-3.
Trong sá»‘ táº¥t cáº£ cÃ¡c tá»« khÃ³a Java, cÃ¡c modifier phÆ°Æ¡ng thá»©c nhÆ° public, private, vÃ  static nháº­n Ä‘Æ°á»£c trá»ng sá»‘ chÃº Ã½ cao nháº¥t. ChÃºng tÃ´i Ä‘oÃ¡n ráº±ng cÃ¡c modifier nÃ y thÆ°á»ng biá»ƒu thá»‹ sá»± báº¯t Ä‘áº§u cá»§a má»™t chá»¯ kÃ½ phÆ°Æ¡ng thá»©c, Ä‘iá»u nÃ y ráº¥t quan trá»ng Ä‘á»ƒ hiá»ƒu toÃ n bá»™ code. Tiáº¿p theo cÃ¡c modifier nÃ y, finally vÃ  return cÅ©ng nháº­n Ä‘Æ°á»£c trá»ng sá»‘ chÃº Ã½ cao. Finally thÆ°á»ng biá»ƒu thá»‹ káº¿t thÃºc cá»§a má»™t hÃ m, vÃ  code bÃªn trong khá»‘i finally cháº¯c cháº¯n sáº½ Ä‘Æ°á»£c thá»±c thi. Return biá»ƒu thá»‹ Ä‘áº§u ra cá»§a phÆ°Æ¡ng thá»©c, cÃ³ thá»ƒ cho tháº¥y chá»©c nÄƒng cá»§a phÆ°Æ¡ng thá»©c. ÄÃ¡ng ngáº¡c nhiÃªn, cÃ¡c tá»« khÃ³a liÃªn quan Ä‘áº¿n phÃ¢n nhÃ¡nh nhÆ° if vÃ  switch nháº­n Ä‘Æ°á»£c sá»± chÃº Ã½ tháº¥p hÆ¡n, cÃ³ láº½ vÃ¬ CodeBERT coi chÃºng khÃ´ng quan trá»ng Ä‘á»‘i vá»›i viá»‡c hiá»ƒu chÆ°Æ¡ng trÃ¬nh máº·c dÃ¹ chÃºng xuáº¥t hiá»‡n thÆ°á»ng xuyÃªn trong code.
Má»™t mÃ´ hÃ¬nh tÆ°Æ¡ng tá»± cÃ³ thá»ƒ Ä‘Æ°á»£c quan sÃ¡t trong Python. VÃ­ dá»¥, CodeBERT Æ°a thÃ­ch cÃ¡c tá»« khÃ³a nhÆ° return vÃ  def biá»ƒu thá»‹ cáº¥u trÃºc chung cá»§a má»™t hÃ m, giá»‘ng nhÆ° return vÃ  public trong Java. Äáº·c biá»‡t, trong sá»‘ cÃ¡c tá»« khÃ³a phÃ¢n nhÃ¡nh vÃ  vÃ²ng láº·p, while xáº¿p háº¡ng cao hÆ¡n if vÃ  for.
HÃ¬nh 3 cho tháº¥y báº£n Ä‘á»“ nhiá»‡t cá»§a sá»± chÃº Ã½ cho má»™t hÃ m Java. Code lÃ  vá» viá»‡c Ä‘á»c ná»™i dung tá»« má»™t tá»‡p. CÃ¡c token cÃ³ trá»ng sá»‘ chÃº Ã½ cao hÆ¡n Ä‘Æ°á»£c Ä‘Ã¡nh dáº¥u báº±ng mÃ u sáº¯c Ä‘áº­m hÆ¡n. Báº£n Ä‘á»“ nhiá»‡t cho tháº¥y káº¿t quáº£ tÆ°Æ¡ng tá»± nhÆ° Ä‘Ã£ tháº£o luáº­n á»Ÿ trÃªn. public vÃ  finally nháº­n Ä‘Æ°á»£c trá»ng sá»‘ chÃº Ã½ cao nháº¥t trong hÃ m nÃ y, trong khi new vÃ  if nháº­n Ä‘Æ°á»£c sá»± chÃº Ã½ tháº¥p nháº¥t. CÃ¡c token liÃªn quan Ä‘áº¿n chá»©c nÄƒng cá»‘t lÃµi, nhÆ° File vÃ  read, Ä‘Ã£ cho tháº¥y trá»ng sá»‘ chÃº Ã½ cao. NgÆ°á»£c láº¡i, cÃ¡c token phá»¥ trá»£ cho chá»©c nÄƒng chÃ­nh, nhÆ° null vÃ  Exception Ä‘Ã£ nháº­n Ä‘Æ°á»£c sá»± chÃº Ã½ tháº¥p hÆ¡n nhiá»u. Má»™t quan sÃ¡t thÃº vá»‹ khÃ¡c lÃ  cÃ¡c kÃ½ hiá»‡u ngá»¯ phÃ¡p nhÆ° } vÃ  ; Ä‘Æ°á»£c CodeBERT coi lÃ  cáº§n thiáº¿t cÃ³ láº½ vÃ¬

--- TRANG 4 ---
ESEC/FSE '22, November 14â€“18, 2022, Singapore, Singapore Zhang, et al.
00.0020.0040.0060.0080.010.0120.0140.016protectedprivatepublicstaticwhileassertfinallyreturnvoidbooleansynchronizednativedoubleforclasstrysupershortthisswitchcatchelsefloatthrowthrowsenumcontinuecasedoimportlongbreaknewdefaultcharextendsifinstanceofintfinalbytepackagetransientinterface
HÃ¬nh 1: Trá»ng sá»‘ chÃº Ã½ cá»§a cÃ¡c tá»« khÃ³a Java Ä‘Æ°á»£c há»c bá»Ÿi CodeBERT
HÃ¬nh 2: CÃ¡c token Java Ä‘Æ°á»£c lÃ m ná»•i báº­t bá»Ÿi CodeBERT. KÃ­ch thÆ°á»›c cá»§a má»—i token chá»‰ ra trá»ng sá»‘ chÃº Ã½ Ä‘Æ°á»£c gÃ¡n bá»Ÿi CodeBERT.
chÃºng Ä‘Ã¡nh dáº¥u káº¿t thÃºc cá»§a cÃ¡c cÃ¢u lá»‡nh vÃ  khá»‘i. NhÃ¬n chung, báº£n Ä‘á»“ nhiá»‡t cho tháº¥y CodeBERT chá»§ yáº¿u chÃº Ã½ Ä‘áº¿n cÃ¡c token chá»©c nÄƒng pháº£n Ã¡nh chá»©c nÄƒng tá»•ng thá»ƒ vÃ  khÃ´ng quan tÃ¢m nhiá»u Ä‘áº¿n cÃ¡c token khÃ¡i niá»‡m vá» ngá»¯ phÃ¡p vÃ  cÃ¡c nhÃ¡nh Ä‘áº·c biá»‡t.
3.2.2 CodeBERT há»c vá» cÃ¡c cÃ¢u lá»‡nh code gÃ¬? (RQ2). HÃ¬nh 4 cho tháº¥y trá»ng sá»‘ chÃº Ã½ Ä‘Æ°á»£c gÃ¡n bá»Ÿi CodeBERT cho má»—i loáº¡i cÃ¢u lá»‡nh Java. NhÆ° cÃ³ thá»ƒ tháº¥y, method signature Ä‘Ã£ nháº­n Ä‘Æ°á»£c sá»± chÃº Ã½ cao nháº¥t (4.11 ğ‘’-3), trong khi case statement nháº­n Ä‘Æ°á»£c sá»± chÃº Ã½ tháº¥p nháº¥t (2.32 ğ‘’-3). Äá»™ lá»‡ch chuáº©n cá»§a trá»ng sá»‘ chÃº Ã½ trÃªn táº¥t cáº£ cÃ¡c danh má»¥c lÃ  4.88 ğ‘’-4. NÃ³i chung, CodeBERT táº­p trung nhiá»u hÆ¡n vÃ o cÃ¡c cÃ¢u lá»‡nh cho biáº¿t chá»©c nÄƒng tá»•ng thá»ƒ cá»§a má»™t phÆ°Æ¡ng thá»©c, nhÆ° method signature vÃ  return, cÃ³ láº½ vÃ¬ chÃºng
HÃ¬nh 3: Báº£n Ä‘á»“ nhiá»‡t cá»§a trá»ng sá»‘ chÃº Ã½ cho cÃ¡c cÃ¢u lá»‡nh vÃ  token Java. MÃ u ná»n cá»§a má»™t token tá»· lá»‡ thuáº­n vá»›i trá»ng sá»‘ chÃº Ã½ trung bÃ¬nh Ä‘Æ°á»£c gÃ¡n cho nÃ³).
chá»©a thÃ´ng tin dÃ y Ä‘áº·c cá»§a toÃ n bá»™ hÃ m, nhÆ° tÃªn vÃ  má»¥c tiÃªu.
ThÃº vá»‹ thay, cÃ¡c biá»ƒu thá»©c sá»‘ há»c (biá»ƒu thá»©c vá»›i cÃ¡c phÃ©p toÃ¡n toÃ¡n há»c) cÅ©ng nháº­n Ä‘Æ°á»£c nhiá»u sá»± chÃº Ã½ hÆ¡n cÃ¡c cÃ¢u lá»‡nh khÃ¡c. Giá»‘ng nhÆ° ngÃ´n ngá»¯ tá»± nhiÃªn, biá»ƒu thá»©c sá»‘ há»c cÃ³ thá»ƒ Ä‘Æ°á»£c xem nhÆ° má»™t chuá»—i cÃ¡c phÃ©p toÃ¡n cho biáº¿t chá»©c nÄƒng cá»§a má»™t cÃ¢u lá»‡nh. Function invocations cÅ©ng Ä‘Ã£ Ä‘Æ°á»£c chá»©ng minh lÃ  quan trá»ng Ä‘á»‘i vá»›i CodeBERT Ä‘á»ƒ hiá»ƒu code. Giá»‘ng nhÆ° biá»ƒu thá»©c sá»‘ há»c, function invocations cÃ³ thá»ƒ Ä‘Æ°á»£c coi lÃ  cÃ¡c Ä‘á»‹nh danh cá»§a cÃ¡c chá»¯ kÃ½ phÆ°Æ¡ng thá»©c khÃ¡c, cÃ³ thá»ƒ Ä‘Æ°á»£c hiá»ƒu theo nghÄ©a Ä‘en thÃ´ng qua tÃªn hÃ m vÃ  tham sá»‘.
ÄÃ¡ng ngáº¡c nhiÃªn, CodeBERT khÃ´ng chÃº Ã½ nhiá»u Ä‘áº¿n cÃ¡c cÃ¢u lá»‡nh liÃªn quan Ä‘áº¿n cáº¥u trÃºc luá»“ng Ä‘iá»u khiá»ƒn, nhÆ° while, for vÃ  case.

--- TRANG 5 ---
Diet Code Is Healthy: Simplifying Programs for Pre-trained Models of Code ESEC/FSE '22, November 14â€“18, 2022, Singapore, Singapore
0.0020.00250.0030.00350.0040.0045Func. SignatureFinallyReturnExpressionTryAnnotationFunctionWhileSetterContinueGetterSwitchIfForCatchBreakLogVariableThrowSyncronizedCase
HÃ¬nh 4: Trá»ng sá»‘ chÃº Ã½ cá»§a cÃ¡c loáº¡i cÃ¢u lá»‡nh Java khÃ¡c nhau Ä‘Æ°á»£c há»c bá»Ÿi CodeBERT
Äiá»u nÃ y chá»‰ ra ráº±ng CodeBERT cÃ³ thá»ƒ há»c hiá»‡u quáº£ cÃ¡c biá»ƒu diá»…n cá»§a vÄƒn báº£n thuáº§n tÃºy trong khi bá»‹ háº¡n cháº¿ trong viá»‡c há»c cáº¥u trÃºc.
HÃ¬nh 3 cÅ©ng cho tháº¥y báº£n Ä‘á»“ nhiá»‡t cá»§a sá»± chÃº Ã½ cÃ¢u lá»‡nh cho má»™t hÃ m máº«u cá»§a Java. TÆ°Æ¡ng tá»± nhÆ° cÃ¡c káº¿t luáº­n á»Ÿ trÃªn, method signature lÃ  quan trá»ng nháº¥t, cung cáº¥p giá»›i thiá»‡u chung vá» chá»©c nÄƒng cá»§a phÆ°Æ¡ng thá»©c. Äá»“ng thá»i, cÃ¡c cÃ¢u lá»‡nh vá» variable declaration vÃ  initialization, nhÆ° "String content == null" nháº­n Ä‘Æ°á»£c sá»± chÃº Ã½ tháº¥p hÆ¡n, cÃ³ láº½ vÃ¬ chÃºng chá»‰ táº¡o ra cÃ¡c biáº¿n má»›i vá»›i giÃ¡ trá»‹ ban Ä‘áº§u null mÃ  khÃ´ng cÃ³ hoáº¡t Ä‘á»™ng thá»±c táº¿ nÃ o Ä‘á»‘i vá»›i chÃºng. Trá»ng sá»‘ chÃº Ã½ cá»§a cÃ¢u lá»‡nh if trong khá»‘i finally cÅ©ng tháº¥p (2.92 ğ‘’-3). HÃ m nÃ y chá»‰ Ä‘Ã³ng file reader vÃ  cÃ³ thá»ƒ cÃ³ Ã­t áº£nh hÆ°á»Ÿng Ä‘áº¿n viá»‡c hiá»ƒu toÃ n bá»™ phÆ°Æ¡ng thá»©c cá»§a CodeBERT.
ChÃºng tÃ´i quan sÃ¡t má»™t xu hÆ°á»›ng tÆ°Æ¡ng tá»± Ä‘á»‘i vá»›i cÃ¡c cÃ¢u lá»‡nh Python. Method signatures cÅ©ng nháº­n Ä‘Æ°á»£c trá»ng sá»‘ chÃº Ã½ cao nháº¥t (6.86 ğ‘’-3), trong khi cÃ¡c cÃ¢u lá»‡nh phÃ¢n nhÃ¡nh nhÆ° break vÃ  continue cÃ³ trá»ng sá»‘ tháº¥p nháº¥t. Äá»™ lá»‡ch chuáº©n cá»§a trá»ng sá»‘ chÃº Ã½ cho cÃ¡c cÃ¢u lá»‡nh Python lÃ  1.66 ğ‘’-3, hÆ¡i lá»›n hÆ¡n so vá»›i cÃ¡c cÃ¢u lá»‡nh Java.
So vá»›i Java, phÃ¢n bá»‘ cá»§a cÃ¡c cÃ¢u lá»‡nh vÃ  token Python hÆ¡i thÆ°a thá»›t hÆ¡n. VÃ­ dá»¥, cÃ¢u lá»‡nh method signature xáº¿p háº¡ng Ä‘áº§u cÃ³ trá»ng sá»‘ cao hÆ¡n nhiá»u so vá»›i danh má»¥c cÃ¢u lá»‡nh thá»© hai (tá»©c lÃ  return). Tá»« khÃ³a hÃ ng Ä‘áº§u def cÅ©ng nháº­n Ä‘Æ°á»£c trá»ng sá»‘ chÃº Ã½ cao hÆ¡n nhiá»u so vá»›i cÃ¡c tá»« khÃ³a khÃ¡c.
4 DIETCODE: ÄÆ N GIáº¢N HÃ“A CHÆ¯Æ NG TRÃŒNH CHO CODEBERT
NhÆ° PhÆ°Æ¡ng trÃ¬nh 1 chá»‰ ra, Ä‘á»™ phá»©c táº¡p tÃ­nh toÃ¡n Ä‘á»ƒ tÃ­nh toÃ¡n ma tráº­n chÃº Ã½ lÃ  O(ğ‘‘Â²ğ‘›+ğ‘›Â²ğ‘‘), tÄƒng theo báº­c hai vá»›i Ä‘á»™ dÃ i chuá»—i. Do Ä‘Ã³, hoáº¡t Ä‘á»™ng chÃº Ã½ trá»Ÿ thÃ nh nÃºt tháº¯t cá»• chai khi Ã¡p dá»¥ng cho cÃ¡c chuá»—i dÃ i nhÆ° mÃ£ nguá»“n [25].
ChÃºng tÃ´i tá»± há»i liá»‡u chÃºng ta cÃ³ thá»ƒ loáº¡i bá» cÃ¡c token hoáº·c cÃ¢u lá»‡nh khÃ´ng quan trá»ng khá»i cÃ¡c chÆ°Æ¡ng trÃ¬nh Ä‘áº§u vÃ o cá»§a CodeBERT hay khÃ´ng. Báº±ng cÃ¡ch nÃ y, chi phÃ­ thá»i gian vÃ  khÃ´ng gian cho mÃ´ hÃ¬nh Ä‘Æ°á»£c tiá»n huáº¥n luyá»‡n cÃ³ thá»ƒ Ä‘Æ°á»£c giáº£m Ä‘Ã¡ng ká»ƒ. Dá»±a trÃªn Ã½ tÆ°á»Ÿng nÃ y, chÃºng tÃ´i Ä‘á» xuáº¥t DietCode, má»™t mÃ´ hÃ¬nh Ä‘Æ°á»£c tiá»n huáº¥n luyá»‡n nháº¹ cho mÃ£ nguá»“n. DietCode giáº£m Ä‘á»™ phá»©c táº¡p tÃ­nh toÃ¡n cá»§a CodeBERT báº±ng cÃ¡ch Ä‘Æ¡n giáº£n hÃ³a cÃ¡c chÆ°Æ¡ng trÃ¬nh Ä‘áº§u vÃ o.
Cá»¥ thá»ƒ hÆ¡n, cÃ´ng thá»©c hÃ³a váº¥n Ä‘á» cá»§a chÃºng tÃ´i nhÆ° sau: cho má»™t Ä‘oáº¡n code ğ¶={ğ‘ 1;...;ğ‘ |ğ¶|} bao gá»“m |ğ¶| cÃ¢u lá»‡nh, chÃºng tÃ´i muá»‘n xuáº¥t ra má»™t Ä‘oáº¡n code Ä‘Æ°á»£c cáº¯t tá»‰a ğ¶ğ‘ chá»©a tá»‘i Ä‘a ğ¿ token. Má»¥c tiÃªu cá»§a viá»‡c Ä‘Æ¡n giáº£n hÃ³a chÆ°Æ¡ng trÃ¬nh lÃ  cáº¯t tá»‰a cÃ ng nhiá»u token cÃ ng tá»‘t mÃ  khÃ´ng áº£nh hÆ°á»Ÿng Ä‘Ã¡ng ká»ƒ Ä‘áº¿n Ä‘á»™ chÃ­nh xÃ¡c cá»§a cÃ¡c tÃ¡c vá»¥ downstream.
4.1 Word Dropout
Má»™t chiáº¿n lÆ°á»£c Ä‘Æ¡n giáº£n cho viá»‡c Ä‘Æ¡n giáº£n hÃ³a chÆ°Æ¡ng trÃ¬nh lÃ  word dropout [21], cá»¥ thá»ƒ lÃ  loáº¡i bá» ngáº«u nhiÃªn cÃ¡c token khá»i code Ä‘áº§u vÃ o Ä‘á»ƒ Ä‘Ã¡p á»©ng Ä‘á»™ dÃ i chuá»—i Ä‘Æ°á»£c chá»‰ Ä‘á»‹nh. Äá»‘i vá»›i má»—i token ğ‘¤âˆˆğ‘†, chÃºng tÃ´i Ä‘á»‹nh nghÄ©a má»™t biáº¿n nhá»‹ phÃ¢n ğ‘Ÿğ‘¤âˆˆ{0,1} Ä‘á»ƒ chá»‰ ra liá»‡u token sáº½ Ä‘Æ°á»£c giá»¯ láº¡i (ğ‘Ÿğ‘¤=1) hay bá»‹ cáº¯t tá»‰a (ğ‘Ÿğ‘¤=0):
ğ‘Ÿğ‘¤âˆ¼Bernoulli(ğ‘)
ğ¶ğ‘={ğ‘¤|ğ‘¤âˆˆğ¶andğ‘Ÿğ‘¤>0}(4)
trong Ä‘Ã³ ğ‘=ğ¿/|ğ¶| biá»ƒu thá»‹ xÃ¡c suáº¥t chá»n má»™t token. NgoÃ i viá»‡c giáº£m Ä‘á»™ phá»©c táº¡p tÃ­nh toÃ¡n, word dropout cÅ©ng Ä‘Ã£ Ä‘Æ°á»£c chá»©ng minh lÃ  cáº£i thiá»‡n tÃ­nh máº¡nh máº½ cá»§a cÃ¡c máº¡ng nÆ¡-ron [21]. Do Ä‘Ã³, nÃ³ nÃ¢ng cao hiá»‡u suáº¥t cá»§a nhiá»u tÃ¡c vá»¥.
4.2 Frequency Filtering
Má»™t má»‘i quan tÃ¢m chÃ­nh vá»›i chiáº¿n lÆ°á»£c word dropout lÃ  nÃ³ cÅ©ng cÃ³ thá»ƒ cáº¯t tá»‰a cÃ¡c token quan trá»ng má»™t cÃ¡ch ngáº«u nhiÃªn khá»i Ä‘áº§u vÃ o. Do Ä‘Ã³, chÃºng tÃ´i giá»›i thiá»‡u má»™t chiáº¿n lÆ°á»£c cáº¯t tá»‰a token dá»±a trÃªn táº§n suáº¥t khÃ¡c loáº¡i bá» cÃ¡c token khÃ´ng phá»• biáº¿n trong khi chá»‰ giá»¯ láº¡i cÃ¡c token xuáº¥t hiá»‡n thÆ°á»ng xuyÃªn nháº¥t.
Cá»¥ thá»ƒ, Ä‘á»‘i vá»›i má»—i Ä‘oáº¡n code Ä‘áº§u vÃ o ğ¶={ğ‘¤1,...,ğ‘¤ğ‘›}, chÃºng tÃ´i giá»¯ láº¡i cÃ¡c token náº¿u táº§n suáº¥t cá»§a chÃºng náº±m trong top ğ‘˜ (ğ‘˜=|ğ¶ğ‘|) cá»§a táº¥t cáº£ cÃ¡c token trong Ä‘áº§u vÃ o, cá»¥ thá»ƒ,
ğ¶ğ‘={ğ‘¤|ğ‘¤âˆˆğ¶,ğ‘“(ğ‘¤)âˆˆtopâˆ’ğ‘˜(ğ‘“(ğ‘¤1),...,ğ‘“(ğ‘¤ğ‘›)),ğ‘˜=|ğ¶ğ‘|)(5)
trong Ä‘Ã³ ğ‘“(ğ‘¤) biá»ƒu thá»‹ táº§n suáº¥t cá»§a ğ‘¤ trong toÃ n bá»™ kho dá»¯ liá»‡u code.
4.3 Attention-based Code Pruning
Chiáº¿n lÆ°á»£c frequency filtering cÃ³ thá»ƒ phÃ¢n biá»‡t thÃ´ cÃ¡c token quan trá»ng, nhÆ°ng cÃ³ thá»ƒ chá»‰ thiÃªn vá»‹ cÃ¡c token phá»• biáº¿n. Theo cÃ¡c phÃ¡t hiá»‡n thá»±c nghiá»‡m cá»§a chÃºng tÃ´i á»Ÿ trÃªn, CodeBERT chÃº Ã½ Ä‘áº¿n má»™t sá»‘ loáº¡i token vÃ  cÃ¢u lá»‡nh nháº¥t Ä‘á»‹nh. CÃ¡c token nháº­n Ä‘Æ°á»£c sá»± chÃº Ã½ cao khÃ´ng trÃ¹ng khá»›p vá»›i cÃ¡c token phá»• biáº¿n. Äá»ƒ cung cáº¥p má»™t lá»±a chá»n token vÃ  cÃ¢u lá»‡nh quan trá»ng chi tiáº¿t hÆ¡n, chÃºng tÃ´i Ä‘á» xuáº¥t má»™t chiáº¿n lÆ°á»£c cáº¯t tá»‰a code dá»±a trÃªn sá»± chÃº Ã½ Ä‘á»ƒ chá»n cÃ¡c token vÃ  cÃ¢u lá»‡nh dá»±a trÃªn trá»ng sá»‘ chÃº Ã½ cá»§a chÃºng.
Quy trÃ¬nh Ä‘Æ¡n giáº£n hÃ³a Ä‘Æ°á»£c tÃ³m táº¯t trong Thuáº­t toÃ¡n 1. ChÃºng tÃ´i báº¯t Ä‘áº§u báº±ng viá»‡c tÃ³m táº¯t danh má»¥c cÃ¡c cÃ¢u lá»‡nh cho má»™t ngÃ´n ngá»¯ láº­p trÃ¬nh Ä‘Ã£ cho theo phÆ°Æ¡ng phÃ¡p trong nghiÃªn cá»©u thá»±c nghiá»‡m cá»§a chÃºng tÃ´i. Sau Ä‘Ã³, chÃºng tÃ´i táº¡o cÃ¡c tá»« Ä‘iá»ƒn chÃº Ã½ cho cáº£ cÃ¢u lá»‡nh vÃ  token. Thuáº­t toÃ¡n cháº¡y cáº¯t tá»‰a code trong hai giai Ä‘oáº¡n: chá»n cÃ¢u lá»‡nh vÃ  cáº¯t tá»‰a token.
Trong giai Ä‘oáº¡n chá»n cÃ¢u lá»‡nh, chÃºng tÃ´i chá»n cÃ¡c cÃ¢u lá»‡nh trá»¥ cá»™t thuá»™c vá» má»™t danh má»¥c nháº­n Ä‘Æ°á»£c trá»ng sá»‘ chÃº Ã½ cao nháº¥t trong nghiÃªn cá»©u thá»±c nghiá»‡m cá»§a chÃºng tÃ´i. Äá»“ng thá»i, chÃºng tÃ´i muá»‘n cÃ¡c cÃ¢u lá»‡nh Ä‘Æ°á»£c chá»n khÃ´ng vÆ°á»£t quÃ¡ rÃ ng buá»™c Ä‘á»™ dÃ i (tá»©c lÃ  ğ¿ token). Äiá»u nÃ y cÃ³ thá»ƒ Ä‘Æ°á»£c cÃ´ng thá»©c hÃ³a nhÆ° má»™t bÃ i toÃ¡n 0-1 knapsack [33], trong Ä‘Ã³ cÃ¡c cÃ¢u lá»‡nh cÃ³ thá»ƒ Ä‘Æ°á»£c coi nhÆ° cÃ¡c váº­t pháº©m Ä‘Æ°á»£c thu tháº­p vÃ o má»™t ba lÃ´, vá»›i trá»ng sá»‘ chÃº Ã½ lÃ  cÃ¡c giÃ¡ trá»‹, vÃ  Ä‘á»™ dÃ i cÃ¢u lá»‡nh lÃ  trá»ng lÆ°á»£ng. RÃ ng buá»™c Ä‘á»™ dÃ i cÃ³ thá»ƒ Ä‘Æ°á»£c coi nhÆ° dung lÆ°á»£ng cá»§a ba lÃ´. Äiá»u Ä‘Ã¡ng chÃº Ã½ lÃ  chÃºng tÃ´i má»Ÿ rá»™ng dung lÆ°á»£ng báº±ng Ä‘á»™ dÃ i tá»‘i Ä‘a cá»§a cÃ¡c cÃ¢u lá»‡nh Ä‘á»ƒ dung sai cho viá»‡c chá»n thÃªm má»™t

--- TRANG 6 ---
ESEC/FSE '22, November 14â€“18, 2022, Singapore, Singapore Zhang, et al.
Thuáº­t toÃ¡n 1 Thuáº­t toÃ¡n Cáº¯t tá»‰a Dá»±a trÃªn ChÃº Ã½
YÃªu cáº§u:
1:C=ğ‘ 1;...;ğ‘ |ğ¶|: má»™t Ä‘oáº¡n code Ä‘áº§u vÃ o,
2:Ağ‘‡: tá»« Ä‘iá»ƒn chÃº Ã½ cá»§a token,
3:Ağ‘†: tá»« Ä‘iá»ƒn chÃº Ã½ cá»§a cÃ¢u lá»‡nh,
4:L: Ä‘á»™ dÃ i má»¥c tiÃªu
Äáº£m báº£o:
5:Äoáº¡n code Ä‘Æ°á»£c giáº£m Cğ‘=ğ‘ â€²1;...;ğ‘ â€²|ğ¶ğ‘|
6:forsâˆˆCdo
7: a(s) =Ağ‘†(s) âŠ²láº¥y sá»± chÃº Ã½ cÃ¢u lá»‡nh
8: fortâˆˆsdo
9: a(t) =Ağ‘‡(t) âŠ²láº¥y sá»± chÃº Ã½ token
10: end for
11:end for
12:ğ¶0â†0-1 Knapsack (items={s}ğ‘ âˆˆğ¶, values={ğ‘(ğ‘ )}ğ‘ âˆˆğ¶,
weights= {|s|} ğ‘ âˆˆğ¶, capacity = ğ¿+maxğ‘ âˆˆğ¶(|s|) âŠ²cÃ¡c cÃ¢u lá»‡nh á»©ng viÃªn
13:fori = 1,...,Ãğ‘ âˆˆğ¶0(|s|) - L do
14:ğ‘ â€²â†ğ‘ â€²\{t} where ğ‘ â€²=argminğ‘ âˆˆğ¶0ğ‘(ğ‘ ),
ğ‘¡=argminğ‘¡0âˆˆğ‘ â€²ğ‘(ğ‘¡0)
15:end for
16:ğ¶ğ‘â†ğ‘ â€²1;...;ğ‘ â€²|ğ¶0|whereğ¶0={ğ‘ â€²1,ğ‘ â€²2,...,ğ‘ â€²|ğ¶0|}âŠ²ná»‘i cÃ¡c cÃ¢u lá»‡nh
cÃ¢u lá»‡nh ná»¯a Ä‘á»ƒ thuáº­t toÃ¡n cÃ³ thá»ƒ thá»±c hiá»‡n thÃªm cáº¯t tá»‰a token trong giai Ä‘oáº¡n tiáº¿p theo.
Trong giai Ä‘oáº¡n cáº¯t tá»‰a token, chÃºng tÃ´i loáº¡i bá» tham lam cÃ¡c token cÃ³ trá»ng sá»‘ chÃº Ã½ tháº¥p nháº¥t trong cÃ¡c cÃ¢u lá»‡nh cÃ³ trá»ng sá»‘ tháº¥p nháº¥t má»™t cÃ¡ch láº·p Ä‘i láº·p láº¡i cho Ä‘áº¿n khi thá»a mÃ£n sá»‘ lÆ°á»£ng token tá»‘i Ä‘a.
Má»™t váº¥n Ä‘á» tiá»m áº©n lÃ  cÃ¡c thang Ä‘o khÃ¡c nhau cá»§a sá»± chÃº Ã½ cÃ¢u lá»‡nh vÃ  kÃ­ch thÆ°á»›c token. ChÃºng tÃ´i tháº¥y ráº±ng má»™t sá»‘ chuá»—i ngáº¯n hÆ¡n cÃ³ nhiá»u kháº£ nÄƒng Ä‘Æ°á»£c chá»n trong cÃ¡c thá»­ nghiá»‡m cá»§a chÃºng tÃ´i ngay cáº£ khi chÃºng nháº­n Ä‘Æ°á»£c trá»ng sá»‘ chÃº Ã½ tháº¥p. Äiá»u nÃ y cÃ³ láº½ lÃ  do tá»· lá»‡ giÃ¡ trá»‹ (trá»ng sá»‘ chÃº Ã½ chia cho Ä‘á»™ dÃ i chuá»—i) cá»§a má»™t chuá»—i ngáº¯n hÆ¡n lá»›n hÆ¡n nhiá»u so vá»›i chuá»—i dÃ i hÆ¡n. ChÃºng tÃ´i khuáº¿ch Ä‘áº¡i trá»ng sá»‘ chÃº Ã½ báº±ng cÃ¡ch sá»­ dá»¥ng chuáº©n hÃ³a min-max vÃ  nhÃ¢n vá»›i sá»‘ lÆ°á»£ng token trong cÃ¢u lá»‡nh, tá»©c lÃ ,
ğ‘(ğ‘ )=ğ‘(ğ‘ )âˆ’minğ‘ âˆˆğ‘†(ğ‘(ğ‘ ))/maxğ‘ âˆˆğ‘†(ğ‘(ğ‘ ))âˆ’minğ‘ âˆˆğ‘†(ğ‘(ğ‘ ))Ã—ğ‘ (6)
trong Ä‘Ã³ ğ‘ biá»ƒu thá»‹ sá»‘ lÆ°á»£ng token trong cÃ¢u lá»‡nh.
Äá»™ phá»©c táº¡p thá»i gian cá»§a thuáº­t toÃ¡n Ä‘Æ¡n giáº£n hÃ³a lÃ  O(ğ‘Â·(ğ¿ğ‘‡+ğ¿ğ‘€)), trong Ä‘Ã³ ğ¿ğ‘‡ biá»ƒu thá»‹ sá»‘ lÆ°á»£ng token má»¥c tiÃªu, vÃ  ğ¿ğ‘€ biá»ƒu thá»‹ Ä‘á»™ dÃ i tá»‘i Ä‘a cá»§a cÃ¡c cÃ¢u lá»‡nh. Chi phÃ­ thá»i gian chá»§ yáº¿u Ä‘áº¿n tá»« thuáº­t toÃ¡n 0-1 knapsack. HÆ¡n ná»¯a, thuáº­t toÃ¡n knapsack yÃªu cáº§u má»™t máº£ng hai chiá»u cho láº­p trÃ¬nh Ä‘á»™ng, Ä‘Ã²i há»i Ä‘á»™ phá»©c táº¡p khÃ´ng gian.
HÃ¬nh 5 cho tháº¥y má»™t vÃ­ dá»¥ vá» Ä‘Æ¡n giáº£n hÃ³a chÆ°Æ¡ng trÃ¬nh bá»Ÿi DietCode. Code gá»‘c (HÃ¬nh 5(a)) nháº±m Ä‘á»c ná»™i dung tá»« má»™t tá»‡p vá»›i tÃªn tá»‡p Ä‘Ã£ cho. Má»¥c tiÃªu cá»§a chÃºng tÃ´i lÃ  giáº£m code chá»‰ chá»©a 60 token mÃ  khÃ´ng máº¥t Ä‘Ã¡ng ká»ƒ ngá»¯ nghÄ©a. Trong giai Ä‘oáº¡n chá»n cÃ¢u lá»‡nh (HÃ¬nh 5(b)), thuáº­t toÃ¡n Ä‘Æ¡n giáº£n hÃ³a giáº£i quyáº¿t má»™t bÃ i toÃ¡n 0-1 knapsack báº±ng cÃ¡ch Ä‘áº·t dung lÆ°á»£ng thÃ nh 78 (bao gá»“m Ä‘á»™ dÃ i má»¥c tiÃªu 60 vÃ  Ä‘á»™ dÃ i cÃ¢u lá»‡nh dÃ i nháº¥t 18). Sau Ä‘Ã³, DietCode chá»n cÃ¡c cÃ¢u lá»‡nh thÃ¢n nhÆ° method signature
Báº£ng 2: Thá»‘ng kÃª cá»§a cÃ¡c Táº­p dá»¯ liá»‡u
Corpus Training Test
CodeSearchNet (Java) 908,886 1,000,000
CodeSearchNet (Python) 824,343 1,000,000
vÃ  return, vÃ  loáº¡i bá» cÃ¡c cÃ¢u lá»‡nh táº§m thÆ°á»ng nhÆ° variable assignments vÃ  catch. Sá»‘ lÆ°á»£ng token trong code Ä‘Æ°á»£c giáº£m tá»« 118 xuá»‘ng 77. Trong giai Ä‘oáº¡n cáº¯t tá»‰a token, DietCode tiáº¿p tá»¥c loáº¡i bá» cÃ¡c token nhÆ° variable initialization (HÃ¬nh 5(c)), vÃ  giáº£m sá»‘ lÆ°á»£ng token tá»« 77 xuá»‘ng 60. Máº·c dÃ¹ giáº£m khoáº£ng 50%, ngá»¯ nghÄ©a chÃ­nh cá»§a hÃ m nÃ y khÃ´ng bá»‹ phÃ¡ há»§y Ä‘Ã¡ng ká»ƒ. CodeBERT váº«n cÃ³ thá»ƒ hiá»ƒu hÃ m thÃ´ng qua cÃ¡c cÃ¢u lá»‡nh chÃ­nh nhÆ° tÃªn phÆ°Æ¡ng thá»©c readFile, biáº¿n chÃ­nh content, vÃ  hÃ m Ä‘Æ°á»£c gá»i read. Máº·c dÃ¹ code cÃ²n láº¡i khÃ´ng bao giá» cÃ³ thá»ƒ cháº¡y Ä‘Æ°á»£c, thÃ´ng tin quan trá»ng Ä‘Æ°á»£c chá»n cÃ³ thá»ƒ Ä‘Æ°á»£c sá»­ dá»¥ng cho cÃ¡c tÃ¡c vá»¥ downstream nhÆ° code search vÃ  summarization.
5 ÄÃNH GIÃ
Pháº§n nÃ y giá»›i thiá»‡u viá»‡c Ä‘Ã¡nh giÃ¡ DietCode trong hai tÃ¡c vá»¥ downstream. ChÃºng tÃ´i nháº±m tráº£ lá»i cÃ¡c cÃ¢u há»i nghiÃªn cá»©u sau thÃ´ng qua cÃ¡c thá»­ nghiá»‡m:
â€¢RQ3: DietCode hiá»‡u quáº£ nhÆ° tháº¿ nÃ o trong viá»‡c Ä‘Æ¡n giáº£n hÃ³a chÆ°Æ¡ng trÃ¬nh? ChÃºng tÃ´i Ä‘Ã¡nh giÃ¡ hiá»‡u suáº¥t vÃ  chi phÃ­ tÃ­nh toÃ¡n cá»§a DietCode trong hai tÃ¡c vá»¥ downstream vÃ  so sÃ¡nh nÃ³ vá»›i cÃ¡c mÃ´ hÃ¬nh baseline.
â€¢RQ4: DietCode hiá»‡u quáº£ nhÆ° tháº¿ nÃ o dÆ°á»›i cÃ¡c Ä‘á»™ dÃ i tÆ°Æ¡ng Ä‘á»‘i khÃ¡c nhau? ChÃºng tÃ´i nghiÃªn cá»©u áº£nh hÆ°á»Ÿng cá»§a cÃ¡c Ä‘á»™ dÃ i tÆ°Æ¡ng Ä‘á»‘i khÃ¡c nhau Ä‘áº¿n Ä‘iá»ƒm Ä‘Ã¡nh giÃ¡. Má»¥c tiÃªu cá»§a chÃºng tÃ´i lÃ  tÃ¬m Ä‘á»™ dÃ i tÆ°Æ¡ng Ä‘á»‘i dáº«n Ä‘áº¿n sá»± cÃ¢n báº±ng tá»‘t nháº¥t giá»¯a hiá»‡u suáº¥t mÃ´ hÃ¬nh vÃ  chi phÃ­ tÃ­nh toÃ¡n.
â€¢RQ5: áº¢nh hÆ°á»Ÿng cá»§a cÃ¡c chiáº¿n lÆ°á»£c cáº¯t tá»‰a khÃ¡c nhau lÃ  gÃ¬? DietCode dá»±a trÃªn chÃº Ã½ thá»±c hiá»‡n cáº£ cáº¯t tá»‰a cÃ¢u lá»‡nh vÃ  token. ChÃºng tÃ´i thá»±c hiá»‡n má»™t nghiÃªn cá»©u ablation Ä‘á»ƒ xÃ¡c Ä‘á»‹nh áº£nh hÆ°á»Ÿng cá»§a viá»‡c cáº¯t tá»‰a tá»«ng cÃ¡i.
5.1 CÃ¡c TÃ¡c vá»¥ Downstream
ChÃºng tÃ´i kiá»ƒm tra thuáº­t toÃ¡n cá»§a mÃ¬nh trong hai tÃ¡c vá»¥ downstream, cá»¥ thá»ƒ lÃ  code search vÃ  code summarization. ÄÃ¢y lÃ  nhá»¯ng tÃ¡c vá»¥ ká»¹ thuáº­t pháº§n má»m Ä‘Æ°á»£c sá»­ dá»¥ng rá»™ng rÃ£i nháº¥t Ä‘á»ƒ chá»©ng minh kháº£ nÄƒng hiá»ƒu NL-PL [17, 22, 23, 31, 41, 46].
Code Search. Code search lÃ  má»™t testbed Ä‘iá»ƒn hÃ¬nh cho cÃ¡c mÃ´ hÃ¬nh code Ä‘Æ°á»£c tiá»n huáº¥n luyá»‡n nhÆ° CodeBERT [15]. TÃ¡c vá»¥ nháº±m tÃ¬m cÃ¡c Ä‘oáº¡n code tá»« má»™t codebase cÃ³ liÃªn quan nháº¥t Ä‘áº¿n má»™t truy váº¥n Ä‘Ã£ cho.
Code Summarization. Code summarization nháº±m táº¡o ra má»™t tÃ³m táº¯t ngÃ´n ngá»¯ tá»± nhiÃªn cho má»™t Ä‘oáº¡n code Ä‘áº§u vÃ o. NÃ³ cÅ©ng Ä‘Ã£ Ä‘Æ°á»£c sá»­ dá»¥ng rá»™ng rÃ£i Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c tiá»n huáº¥n luyá»‡n cho mÃ£ nguá»“n [15,45]. ThÃ´ng qua tÃ¡c vá»¥ nÃ y, chÃºng tÃ´i muá»‘n xÃ¡c minh liá»‡u viá»‡c Ä‘Æ¡n giáº£n hÃ³a chÆ°Æ¡ng trÃ¬nh bá»Ÿi DietCode cÃ³ hiá»‡u quáº£ trong cÃ¡c tÃ¡c vá»¥ táº¡o sinh hay khÃ´ng.
5.2 Táº­p dá»¯ liá»‡u
ChÃºng tÃ´i sá»­ dá»¥ng CodeSearchNet Ä‘á»ƒ fine-tune vÃ  kiá»ƒm tra mÃ´ hÃ¬nh cá»§a chÃºng tÃ´i [20], chá»©a cÃ¡c cáº·p <comment, code> Ä‘Æ°á»£c thu tháº­p tá»« cÃ¡c dá»± Ã¡n mÃ£ nguá»“n má»Ÿ. code cÃ³ nghÄ©a lÃ  Ä‘oáº¡n code cá»§a má»™t phÆ°Æ¡ng thá»©c, trong khi comment

--- TRANG 7 ---
Diet Code Is Healthy: Simplifying Programs for Pre-trained Models of Code ESEC/FSE '22, November 14â€“18, 2022, Singapore, Singapore
1publicStringreadFile(Stringfilename) {2Stringcontent=null;3File file =newFile(filename);4FileReaderreader =null;5try{6reader=newFileReader(file);7char[] chars=newchar[(int)file.length()];8reader.read(chars);9content=newString(chars);10reader.close();11}catch(IOExceptione) {12e.printStackTrace();13}finally{14if(reader!=null){15reader.close();16}17}18returncontent;19}
(a) MÃ£ nguá»“n gá»‘c
1publicStringreadFile(Stringfilename){2Stringcontent=null;3File file =newFile(filename);4FileReaderreader =null;5try{6reader=newFileReader(file);7reader.read(chars);8content=newString(chars);9reader.close();10} catch (IOExceptione) {11}finally{}12returncontent;13} (b) Code sau khi chá»n cÃ¢u lá»‡nh
1publicStringreadFile(Stringfilename){2File file =newFile(filename);3FileReader4try{5reader=newFileReader(file);6reader.read(chars);7content=newString(chars);8reader.close();9}finally{} 10returncontent;11} (c) Code sau khi cáº¯t tá»‰a token
HÃ¬nh 5: Má»™t vÃ­ dá»¥ vá» Ä‘Æ¡n giáº£n hÃ³a chÆ°Æ¡ng trÃ¬nh bá»Ÿi DietCode (attention).
lÃ  mÃ´ táº£ cá»§a code chá»§ yáº¿u Ä‘Æ°á»£c thu tháº­p tá»« cÃ¡c comment cho toÃ n bá»™ hÃ m nhÆ° Javadocs hoáº·c docstrings trong Python. Thá»‘ng kÃª cá»§a CodeSearchNet Ä‘Æ°á»£c hiá»ƒn thá»‹ trong Báº£ng 2.
Dá»¯ liá»‡u gá»‘c cá»§a CodeSearchNet á»Ÿ Ä‘á»‹nh dáº¡ng chuá»—i token. ChÃºng tÃ´i tiá»n xá»­ lÃ½ dá»¯ liá»‡u báº±ng cÃ¡ch phÃ¢n tÃ­ch chÃºng thÃ nh cÃ¡c cÃ¢u lá»‡nh. ChÃºng tÃ´i phÃ¢n tÃ­ch cÃ¡c cÃ¢u lá»‡nh báº±ng cÃ¡ch chia dáº¥u ngoáº·c vÃ  dáº¥u cháº¥m pháº©y theo hÆ°á»›ng dáº«n chung cá»§a Java [16]. Äá»‘i vá»›i code Python, khÃ´ng cÃ³ dáº¥u phÃ¢n cÃ¡ch vÃ¬ thiáº¿u thá»¥t lá» trong táº­p dá»¯ liá»‡u. BÃªn cáº¡nh Ä‘Ã³, Python khÃ´ng sá»­ dá»¥ng dáº¥u ngoáº·c vÃ  dáº¥u cháº¥m pháº©y. Do Ä‘Ã³, chÃºng tÃ´i chia cÃ¡c cÃ¢u lá»‡nh báº±ng cÃ¡c kÃ½ hiá»‡u gá»£i Ã½ khÃ¡c nhÆ° "def", "=", ":", vÃ  ")".
Äá»ƒ giáº£m kÃ­ch thÆ°á»›c tá»« vá»±ng cá»§a cÃ¡c token code, chÃºng tÃ´i delexicalize táº¥t cáº£ cÃ¡c háº±ng sá»‘ chuá»—i thÃ nh má»™t token chung string vÃ  táº¥t cáº£ cÃ¡c háº±ng sá»‘ sá»‘ thÃ nh cÃ¹ng má»™t token 10. ChÃºng tÃ´i báº£o tá»“n cÃ¡c sá»‘ Ä‘áº·c biá»‡t nhÆ° 0, 1, vÃ  -1, cÃ³ thá»ƒ thuá»™c vá» cÃ¡c giÃ¡ trá»‹ boolean.
5.3 CÃ¡c Metric ÄÃ¡nh giÃ¡
Äáº§u tiÃªn, chÃºng tÃ´i muá»‘n Ä‘o lÆ°á»ng má»©c Ä‘á»™ giáº£m code tá»‘i Ä‘a mÃ  DietCode cÃ³ thá»ƒ Ä‘áº¡t Ä‘Æ°á»£c mÃ  khÃ´ng máº¥t nhiá»u Ä‘á»™ chÃ­nh xÃ¡c. ChÃºng tÃ´i Ä‘á»‹nh nghÄ©a Relative Length (RL) Ä‘á»ƒ Ä‘o lÆ°á»ng bao nhiÃªu code cÃ²n láº¡i sau khi Ä‘Æ¡n giáº£n hÃ³a. NÃ³ Ä‘Æ°á»£c tÃ­nh nhÆ° tá»· lá»‡ pháº§n trÄƒm cá»§a Ä‘á»™ dÃ i cá»§a Ä‘oáº¡n code Ä‘Æ°á»£c Ä‘Æ¡n giáº£n hÃ³a |ğ¶ğ‘| so vá»›i Ä‘á»™ dÃ i cá»§a code gá»‘c |ğ¶|:
ğ‘…ğ¿=|ğ¶ğ‘|/|ğ¶|Ã—100% (7)
trong Ä‘Ã³ |Â·| biá»ƒu thá»‹ Ä‘á»™ dÃ i cá»§a má»™t Ä‘oáº¡n code (tá»©c lÃ  sá»‘ lÆ°á»£ng token). Äá»™ dÃ i tÆ°Æ¡ng Ä‘á»‘i cÃ ng nhá», viá»‡c Ä‘Æ¡n giáº£n hÃ³a code gá»‘c cÃ ng lá»›n.
ChÃºng tÃ´i cÅ©ng sá»­ dá»¥ng FLOPs (floating point operations) [19] Ä‘á»ƒ Ä‘o lÆ°á»ng hiá»‡u quáº£ cá»§a viá»‡c giáº£m mÃ´ hÃ¬nh. FLOPs lÃ  má»™t metric Ä‘Æ°á»£c sá»­ dá»¥ng rá»™ng rÃ£i Ä‘á»ƒ Ä‘o lÆ°á»ng Ä‘á»™ phá»©c táº¡p cá»§a má»™t mÃ´ hÃ¬nh machine learning. FLOPs cÃ ng cao, viá»‡c xá»­ lÃ½ cá»§a mÃ´ hÃ¬nh cÃ ng cháº­m.
Metric thá»© ba lÃ  chi phÃ­ thá»i gian, bao gá»“m thá»i gian fine-tuning (FT Time) vÃ  thá»i gian testing. ChÃºng tÃ´i tÃ­nh toÃ¡n thá»i gian thá»±c thi cá»§a DietCode cho fine-tuning vÃ  testing, Ä‘Æ°á»£c Ä‘o báº±ng sá»‘ giá» tá»« khi chÆ°Æ¡ng trÃ¬nh báº¯t Ä‘áº§u Ä‘áº¿n khi káº¿t thÃºc.
BÃªn cáº¡nh cÃ¡c metric cho Ä‘á»™ phá»©c táº¡p, chÃºng tÃ´i sá»­ dá»¥ng hai metric tiÃªu chuáº©n Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ hiá»‡u quáº£ cá»§a DietCode trong hai tÃ¡c vá»¥ downstream tÆ°Æ¡ng á»©ng. ChÃºng tÃ´i Ä‘o lÆ°á»ng hiá»‡u suáº¥t cá»§a code search báº±ng MRR (mean reciprocal rank), Ä‘á» cáº­p Ä‘áº¿n trung bÃ¬nh cá»§a nghá»‹ch Ä‘áº£o nhÃ¢n cá»§a vá»‹ trÃ­ cho cÃ¢u tráº£ lá»i Ä‘Ãºng Ä‘áº§u tiÃªn cho truy váº¥n [20].
ChÃºng tÃ´i Ä‘o lÆ°á»ng hiá»‡u suáº¥t cá»§a code summarization báº±ng Ä‘iá»ƒm BLEU-4 (bilingual evaluation understudy) [27], tÃ­nh toÃ¡n trung bÃ¬nh cá»§a Ä‘á»™ chÃ­nh xÃ¡c n-gram trÃªn má»™t cáº·p chuá»—i vá»›i má»™t hÃ¬nh pháº¡t cho cÃ¡c chuá»—i ngáº¯n.
5.4 Thiáº¿t láº­p Thá»±c nghiá»‡m
Äá»ƒ chá»©ng minh sá»©c máº¡nh cá»§a phÆ°Æ¡ng phÃ¡p cá»§a chÃºng tÃ´i, chÃºng tÃ´i Ä‘Æ¡n giáº£n hÃ³a cÃ¡c chÆ°Æ¡ng trÃ¬nh Ä‘áº§u vÃ o cho cÃ¡c mÃ´ hÃ¬nh dá»±a trÃªn tiá»n huáº¥n luyá»‡n vÃ  so sÃ¡nh hiá»‡u suáº¥t vá»›i mÃ´ hÃ¬nh Ä‘Æ°á»£c tiá»n huáº¥n luyá»‡n gá»‘c. Cá»¥ thá»ƒ, chÃºng tÃ´i so sÃ¡nh ká»¹ thuáº­t cá»§a mÃ¬nh vá»›i cÃ¡c phiÃªn báº£n vanilla cá»§a ba mÃ´ hÃ¬nh Ä‘Æ°á»£c tiá»n huáº¥n luyá»‡n:
â€¢CodeBERT [15]: CodeBERT gá»‘c khÃ´ng cÃ³ Ä‘Æ¡n giáº£n hÃ³a code. ChÃºng tÃ´i tuÃ¢n theo thiáº¿t láº­p thá»±c nghiá»‡m trong bÃ i bÃ¡o CodeBERT.
â€¢CodeT5 [45]: má»™t mÃ´ hÃ¬nh ngÃ´n ngá»¯ láº­p trÃ¬nh Ä‘Æ°á»£c tiá»n huáº¥n luyá»‡n Ä‘Æ°á»£c sá»­ dá»¥ng rá»™ng rÃ£i dá»±a trÃªn kiáº¿n trÃºc sequence-to-sequence. CodeT5 Ä‘Ã£ chá»©ng minh hiá»‡u suáº¥t tá»‘t hÆ¡n trÃªn cÃ¡c tÃ¡c vá»¥ táº¡o sinh [45].
â€¢RoBERTa [28]: má»™t pháº§n má»Ÿ rá»™ng phá»• biáº¿n cá»§a BERT Ä‘Ã£ chá»©ng minh cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ. RoBERTa gá»‘c Ä‘Æ°á»£c tiá»n huáº¥n luyá»‡n báº±ng ngÃ´n ngá»¯ tá»± nhiÃªn. VÃ¬ váº­y chÃºng tÃ´i cÅ©ng bÃ¡o cÃ¡o káº¿t quáº£ cá»§a RoBERTa (code) [15], má»™t biáº¿n thá»ƒ Ä‘Æ°á»£c tiá»n huáº¥n luyá»‡n trÃªn mÃ£ nguá»“n.
BÃªn cáº¡nh cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c tiá»n huáº¥n luyá»‡n, chÃºng tÃ´i cÅ©ng so sÃ¡nh Ä‘á»™ chÃ­nh xÃ¡c cá»§a DietCode vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p deep learning truyá»n thá»‘ng, bao gá»“m BiRNN [10], SelfAttn [43], Seq2Seq [10], vÃ  Transformer [43]. VÃ¬ chÃºng cÅ©ng lÃ  cÃ¡c mÃ´ hÃ¬nh baseline cho CodeBERT, chÃºng tÃ´i trá»±c tiáº¿p láº¥y káº¿t quáº£ tá»« bÃ i bÃ¡o CodeBERT [15].
Cuá»‘i cÃ¹ng, chÃºng tÃ´i so sÃ¡nh DietCode vá»›i SIVAND [34], cÅ©ng lÃ  má»™t phÆ°Æ¡ng phÃ¡p Ä‘Æ¡n giáº£n hÃ³a chÆ°Æ¡ng trÃ¬nh Ä‘Æ°á»£c Ä‘á» xuáº¥t bá»Ÿi Rabin et al. [34].

--- TRANG 8 ---
ESEC/FSE '22, November 14â€“18, 2022, Singapore, Singapore Zhang, et al.
Báº£ng 3: Hiá»‡u suáº¥t cá»§a cÃ¡c phÆ°Æ¡ng phÃ¡p Ä‘Æ¡n giáº£n hÃ³a code khÃ¡c nhau trÃªn tÃ¡c vá»¥ code search (ğ¿in=Ä‘á»™ dÃ i Ä‘áº§u vÃ o; RL=Ä‘á»™ dÃ i tÆ°Æ¡ng Ä‘á»‘i; FT=fine-tuning).
Java Python
Model ğ¿in RL FT Time Test Time FLOPs MRR ğ‹in RL FT Time Test Time FLOPs MRR
BiRNN [10] 200 100% 9.88h 1.13h 8.34G 0.29 200 100% 7.07h 1.25h 8.34G 0.32
SelfAttn [43] 200 100% 22.83h 4.00h 16.99G 0.59 200 100% 17.78h 2.67h 16.99G 0.69
RoBERTa [28] 200 100% 23.85h 4.78h 16.99G 0.67 200 100% 19.32h 3.53h 16.99G 0.81
RoBERTa (code) 200 100% 21.02h 4.53h 16.99G 0.72 200 100% 20.78h 4.07h 16.99G 0.84
CodeBERT [15] 200 100% 20.82h 3.17h 16.99G 0.74 200 100% 17.92h 2.82h 16.99G 0.84
DietCode
- Attention 120 60% 11.08h 1.83h 10.19G 0.71 120 60% 9.62h 1.82h 10.19G 0.81
- Dropout 120 60% 10.73h 1.95h 10.19G 0.68 120 60% 9.33h 1.93h 10.19G 0.80
- Frequency 120 60% 10.32h 1.8h 10.19G 0.66 120 60% 8.67h 1.79h 10.19G 0.78
CodeT5 [45] 200 100% 16.83h 2.97h 16.99G 0.72 200 100% 17.61h 2.83h 16.99G 0.837
DietCode
- Attention 120 60% 9.3h 1.74h 10.19G 0.71 120 60% 8.31h 1.81h 10.19G 0.813
- Dropout 120 60% 9.25h 1.67h 10.19G 0.68 120 60% 9.33h 1.93h 10.19G 0.799
- Frequency 120 60% 8.97h 1.58h 10.19G 0.66 120 60% 8.67h 1.79h 10.19G 0.785
Báº£ng 4: Hiá»‡u suáº¥t cá»§a cÃ¡c phÆ°Æ¡ng phÃ¡p Ä‘Æ¡n giáº£n hÃ³a code khÃ¡c nhau trÃªn tÃ¡c vá»¥ code summarization.
Java Python
Model ğ¿in RL FT Time Test Time FLOPs BLEU-4 ğ¿in RL FT Time Test Time FLOPs BLEU-4
Seq2Seq [10] 256 100% 6.26h 1.26h 12.750G 15.09 256 100% 4.43h 1.02h 12.750G 15.93
Transformer [43] 256 100% 13.28h 5.43h 24.328G 16.26 256 100% 9.70h 2.43h 24.328G 15.81
RoBERTa [28] 256 100% 15.42h 5.22h 24.328G 16.47 256 100% 10.63h 1.88h 24.328G 18.14
RoBERTa (code) 256 100% 14.5h 6.02h 24.328G 17.50 256 100% 10.45h 2.05h 24.328G 18.58
CodeBERT [15] 256 100% 13.82h 4.8h 24.328G 18.95 256 100% 8.32h 1.87h 24.328G 19.04
DietCode
- Attention 150 60% 8.18h 1.62h 15.325G 17.29 150 60% 5.35h 1.16h 15.325G 17.08
- Dropout 150 60% 7.95h 1.40h 15.325G 15.63 150 60% 6.81h 1.15h 15.325G 16.04
- Frequency 150 60% 8.62h 1.33h 15.325G 16.13 150 60% 6.12h 1.42h 15.325G 16.55
CodeT5 [45] 256 100% 16.91h 4.88h 54.01G 20.46 256 100% 9.68h 1.48h 54.01G 20.37
DietCode
- Attention 150 60% 10.25h 1.63h 37.81G 19.25 150 60% 6.57h 0.90h 37.81G 18.53
- Dropout 150 60% 9.95h 1.68h 37.81G 17.65 150 60% 6.67h 0.82h 37.81G 17.07
- Frequency 150 60% 10.23h 1.35h 37.81G 18.74 150 60% 6.33h 0.85h 37.81G 17.77
SIVANDÂ¹ lÃ  má»™t thuáº­t toÃ¡n dá»±a trÃªn machine-learning Ä‘á»‡ quy chia mÃ£ nguá»“n thÃ nh cÃ¡c Ä‘oáº¡n vÃ  Ä‘o lÆ°á»ng táº§m quan trá»ng cá»§a nÃ³ thÃ´ng qua tÃ¡c vá»¥ dá»± Ä‘oÃ¡n tÃªn phÆ°Æ¡ng thá»©c. Thuáº­t toÃ¡n chá»n cÃ¡c Ä‘oáº¡n quan trá»ng lÃ m code Ä‘Æ°á»£c giáº£m. Trong cÃ¡c thá»­ nghiá»‡m cá»§a chÃºng tÃ´i, chÃºng tÃ´i trá»±c tiáº¿p sá»­ dá»¥ng code Ä‘Æ°á»£c cung cáº¥p bá»Ÿi cÃ¡c tÃ¡c giáº£.
ChÃºng tÃ´i triá»ƒn khai mÃ´ hÃ¬nh cá»§a mÃ¬nh dá»±a trÃªn repository GitHub cá»§a CodeBERTÂ² vÃ  CodeT5Â³ sá»­ dá»¥ng cÃ¡c thiáº¿t láº­p siÃªu tham sá»‘ máº·c Ä‘á»‹nh. Táº¥t cáº£ cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c tá»‘i Æ°u hÃ³a vá»›i thuáº­t toÃ¡n Adam [26] vá»›i tá»‘c Ä‘á»™ há»c láº§n lÆ°á»£t lÃ  1ğ‘’-5 vÃ  5ğ‘’-5 cho cÃ¡c tÃ¡c vá»¥ code search vÃ  code summarization.
ChÃºng tÃ´i cháº¡y táº¥t cáº£ cÃ¡c mÃ´ hÃ¬nh trÃªn má»™t mÃ¡y vá»›i CPU Intel(R) Xeon(R) Silver 4214R 2.40GHz vÃ  GPU Nvidia Tesla P40.
Â¹https://github.com/mdrafiqulrabin/SIVAND
Â²https://github.com/microsoft/CodeBERT
Â³https://github.com/salesforce/CodeT5

5.5 Káº¿t Quáº£ Thá»±c Nghiá»‡m (RQ3)
Báº£ng 3 vÃ  4 cho tháº¥y hiá»‡u suáº¥t cá»§a DietCode trong hai tÃ¡c vá»¥ downstream. NhÃ¬n chung, DietCode giáº£m chi phÃ­ tÃ­nh toÃ¡n khoáº£ng 40% trong khi duy trÃ¬ Ä‘á»™ chÃ­nh xÃ¡c tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c tiá»n huáº¥n luyá»‡n gá»‘c. CodeBERT gá»‘c máº¥t gáº§n má»™t ngÃ y Ä‘á»ƒ fine-tuning vÃ  hÆ¡n 3 giá» cho code search trÃªn táº­p test Java Ä‘á»ƒ Ä‘áº¡t Ä‘Æ°á»£c Ä‘iá»ƒm MRR lÃ  0.74. NgÆ°á»£c láº¡i, báº±ng cÃ¡ch giáº£m Ä‘á»™ dÃ i cá»§a code Ä‘áº§u vÃ o xuá»‘ng 60%, thá»i gian fine-tuning vÃ  testing cÃ³ thá»ƒ Ä‘Æ°á»£c giáº£m xuá»‘ng tÆ°Æ¡ng á»©ng 11.08 giá» vÃ  1.83 giá». FLOPs cÅ©ng giáº£m tá»« 16.99G xuá»‘ng 10.19G. Äá»“ng thá»i, Ä‘á»™ chÃ­nh xÃ¡c (MRR = 0.71) tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i CodeBERT gá»‘c (MRR=0.74).
Äiá»u Ä‘Ã¡ng chÃº Ã½ lÃ  máº·c dÃ¹ hiá»‡u suáº¥t giáº£m nháº¹, nÃ³ váº«n vÆ°á»£t trá»™i Ä‘Ã¡ng ká»ƒ so vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p truyá»n thá»‘ng khÃ´ng dá»±a trÃªn pretraining nhÆ° BiRNN (MRR=0.29) vÃ  SelfAttn (MRR=0.59).
DietCode trÃªn CodeT5 chá»©ng minh hiá»‡u quáº£ tÆ°Æ¡ng tá»±. CodeT5 vanilla yÃªu cáº§u hÆ¡n 16 giá» Ä‘á»ƒ fine-tuning vÃ  khoáº£ng 3 giá» Ä‘á»ƒ testing trÃªn tÃ¡c vá»¥ code search Java. Báº±ng cÃ¡ch loáº¡i bá» 40% token Ä‘áº§u vÃ o sá»­ dá»¥ng DietCode, thá»i gian fine-tuning vÃ  test Ä‘Æ°á»£c giáº£m xuá»‘ng khoáº£ng 9 vÃ  1.6 giá», tÆ°Æ¡ng á»©ng. Äá»“ng thá»i, DietCode (attention) Ä‘áº¡t Ä‘Æ°á»£c hiá»‡u suáº¥t tÆ°Æ¡ng Ä‘Æ°Æ¡ng (MRR=0.71) vá»›i CodeT5 gá»‘c (MRR=0.72) chá»‰ vá»›i sá»± giáº£m 1.5%.
DietCode cÅ©ng hiá»‡u quáº£ trong tÃ¡c vá»¥ code summarization. Láº¥y Java lÃ m vÃ­ dá»¥, CodeBERT vanilla Ä‘áº¡t Ä‘Æ°á»£c Ä‘iá»ƒm BLEU-4 lÃ  18.95 vá»›i chi phÃ­ 13.82 giá» fine-tuning vÃ  4.8 giá» testing. Khi Ä‘á»™ dÃ i má»¥c tiÃªu Ä‘Æ°á»£c Ä‘áº·t thÃ nh 150 token (tá»©c lÃ  60% Ä‘á»™ dÃ i gá»‘c), thá»i gian fine-tuning Ä‘Æ°á»£c giáº£m xuá»‘ng khoáº£ng 60% vÃ  FLOPs giáº£m tá»« 24.328G xuá»‘ng chá»‰ 15.325G. Äiá»u nÃ y khÃ´ng hy sinh Ä‘á»™ chÃ­nh xÃ¡c (BLEU-4=17.29).
So sÃ¡nh ba chiáº¿n lÆ°á»£c cáº¯t tá»‰a, DietCode vá»›i attention cho tháº¥y sá»©c máº¡nh hÆ¡n hai chiáº¿n lÆ°á»£c khÃ¡c. VÃ­ dá»¥, DietCode vá»›i attention-based pruning Ä‘áº¡t Ä‘Æ°á»£c MRR lÃ  0.71 trong tÃ¡c vá»¥ code search Java, tá»‘t hÆ¡n dropout (MRR=0.68) vÃ  frequency filtering (MRR=0.66). Káº¿t quáº£ cho tháº¥y ráº±ng báº±ng cÃ¡ch cáº¯t tá»‰a chi tiáº¿t hÆ¡n cÃ¡c token dá»±a trÃªn trá»ng sá»‘ chÃº Ã½, DietCode cÃ³ thá»ƒ Ä‘áº¡t Ä‘Æ°á»£c viá»‡c Ä‘Æ¡n giáº£n hÃ³a chÆ°Æ¡ng trÃ¬nh hiá»‡u quáº£ hÆ¡n. DietCode trÃªn CodeT5 chá»©ng minh xu hÆ°á»›ng tÆ°Æ¡ng tá»± trong cáº£ hai tÃ¡c vá»¥, trong Ä‘Ã³ attention-based pruning Ä‘áº¡t Ä‘Æ°á»£c hiá»‡u suáº¥t tá»‘t hÆ¡n (BLEU=19.25) so vá»›i dropout (BLEU=17.65) vÃ  frequency filtering (BLEU=18.74).
ChÃºng tÃ´i quan sÃ¡t ráº±ng sá»©c máº¡nh nÃ y trá»Ÿ nÃªn Ã­t Ä‘Ã¡ng ká»ƒ hÆ¡n trong ngÃ´n ngá»¯ Python. ChÃºng tÃ´i Ä‘oÃ¡n ráº±ng ngÃ´n ngá»¯ Python chá»©a Ã­t token phá»¥ trá»£ hÆ¡n (nhÆ° dáº¥u ngoáº·c), dáº«n Ä‘áº¿n phÃ¢n bá»‘ Ä‘á»“ng Ä‘á»u hÆ¡n cá»§a trá»ng sá»‘ chÃº Ã½ trÃªn táº¥t cáº£ cÃ¡c token. Do Ä‘Ã³, viá»‡c loáº¡i bá» cÃ¡c token cÃ³ sá»± chÃº Ã½ nhá» hÆ¡n gáº§n giá»‘ng vá»›i viá»‡c loáº¡i bá» cÃ¡c token ngáº«u nhiÃªn hoáº·c thÆ°á»ng xuyÃªn trong ngÃ´n ngá»¯ Python.
LÃ  má»™t Ä‘iá»ƒm Ä‘Ã¡ng chÃº Ã½, viá»‡c kiá»ƒm tra mÃ´ hÃ¬nh baseline SIVAND trong cÃ¡c táº­p dá»¯ liá»‡u cá»§a chÃºng tÃ´i lÃ  khÃ´ng thá»ƒ Ã¡p dá»¥ng, vÃ¬ nÃ³ máº¥t má»™t lÆ°á»£ng thá»i gian khá»•ng lá»“ (>30,000 giá» theo Æ°á»›c tÃ­nh cá»§a chÃºng tÃ´i) Ä‘á»ƒ xá»­ lÃ½ hÆ¡n 1 triá»‡u hÃ m trong cÃ¡c benchmark CodeSearchNet. Äiá»u nÃ y chá»§ yáº¿u lÃ  do thuáº­t toÃ¡n ddmin Ä‘Æ°á»£c sá»­ dá»¥ng bá»Ÿi SIVAND dá»±a trÃªn backtracking, trong Ä‘Ã³ má»—i bÆ°á»›c thuáº­t toÃ¡n pháº£i gá»i mÃ´ hÃ¬nh deep learning cho má»™t tÃ¡c vá»¥ dá»± Ä‘oÃ¡n. VÃ¬ lÃ½ do nÃ y, chÃºng tÃ´i Æ°á»›c tÃ­nh chi phÃ­ thá»i gian cá»§a SIVAND báº±ng cÃ¡ch láº¥y máº«u 50 hÃ m tá»« CodeSearchNet. Káº¿t quáº£ cho tháº¥y nÃ³ tá»‘n 104 vÃ  77 phÃºt tÆ°Æ¡ng á»©ng trong cÃ¡c táº­p dá»¯ liá»‡u CodeSearchNet (Java) vÃ  CodeSearchNet (Python). Dá»±a trÃªn quan sÃ¡t nÃ y, chÃºng tÃ´i Æ°á»›c tÃ­nh thá»i gian testing trong toÃ n bá»™ táº­p dá»¯ liá»‡u. VÃ¬ dá»¯ liá»‡u chÃºng tÃ´i láº¥y máº«u cÃ³ kÃ­ch thÆ°á»›c nhá», nÃ³ khÃ´ng Ä‘á»§ Ä‘á»ƒ fine-tune mÃ´ hÃ¬nh Ä‘á»ƒ xÃ¡c thá»±c Ä‘á»™ chÃ­nh xÃ¡c.
5.6 áº¢nh HÆ°á»Ÿng cá»§a Äá»™ DÃ i TÆ°Æ¡ng Äá»‘i (RQ4)
HÃ¬nh 6 cho tháº¥y hiá»‡u suáº¥t cá»§a DietCode dÆ°á»›i cÃ¡c Ä‘á»™ dÃ i tÆ°Æ¡ng Ä‘á»‘i vÃ  chiáº¿n lÆ°á»£c cáº¯t tá»‰a khÃ¡c nhau. ChÃºng ta cÃ³ thá»ƒ tháº¥y ráº±ng hiá»‡u suáº¥t cá»§a táº¥t cáº£ cÃ¡c chiáº¿n lÆ°á»£c cáº¯t tá»‰a giáº£m máº¡nh khi Ä‘á»™ dÃ i tÆ°Æ¡ng Ä‘á»‘i giáº£m. Trong cáº£ hai tÃ¡c vá»¥, DietCode vá»›i attention hoáº¡t Ä‘á»™ng tá»‘t hÆ¡n hai chiáº¿n lÆ°á»£c cáº¯t tá»‰a khÃ¡c dÆ°á»›i táº¥t cáº£ cÃ¡c Ä‘á»™ dÃ i tÆ°Æ¡ng Ä‘á»‘i. Khi Ä‘á»™ dÃ i tÆ°Æ¡ng Ä‘á»‘i trÃªn 70%, hiá»‡u suáº¥t tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i CodeBERT gá»‘c nhÆ°ng viá»‡c giáº£m chi phÃ­ tÃ­nh toÃ¡n cÃ³ thá»ƒ khiÃªm tá»‘n. Khi Ä‘á»™ dÃ i tÆ°Æ¡ng Ä‘á»‘i giáº£m xuá»‘ng dÆ°á»›i 50%, hiá»‡u suáº¥t kÃ©m vÃ¬ háº§u háº¿t code Ä‘Ã£ bá»‹ cáº¯t tá»‰a. Äá»™ dÃ i tÆ°Æ¡ng Ä‘á»‘i khoáº£ng 60% cÃ³ láº½ lÃ  sá»± cÃ¢n báº±ng tá»‘t nháº¥t cho hai tÃ¡c vá»¥ nÃ y.

--- TRANG 9 ---
Diet Code Is Healthy: Simplifying Programs for Pre-trained Models of Code ESEC/FSE '22, November 14â€“18, 2022, Singapore, Singapore
40 50 60 70
Relative Length(%)0.550.600.650.70MRR
attention
random
frequency(a) káº¿t quáº£ trÃªn code search
40 50 60 70
Relative Length(%)1415161718BLEU4
attention
random
frequency (b) káº¿t quáº£ trÃªn code summarization
HÃ¬nh 6: Hiá»‡u suáº¥t dÆ°á»›i cÃ¡c Ä‘á»™ dÃ i tÆ°Æ¡ng Ä‘á»‘i khÃ¡c nhau trÃªn Java.
50 60 70 80 90
Relative Length(%)0.580.600.620.640.660.680.700.720.74MRR
statement
token
(a) káº¿t quáº£ trÃªn code search
50 60 70 80 90
Relative Length(%)15.015.516.016.517.017.518.018.5BLEU4
statement
token (b) káº¿t quáº£ trÃªn code summarization
HÃ¬nh 7: Káº¿t quáº£ ablation cá»§a viá»‡c cáº¯t tá»‰a token vÃ  cÃ¢u lá»‡nh trÃªn Java.
5.7 áº¢nh HÆ°á»Ÿng cá»§a Viá»‡c Cáº¯t Tá»‰a Token vÃ  CÃ¢u Lá»‡nh (RQ5)
HÃ¬nh 7 cho tháº¥y hiá»‡u suáº¥t cá»§a DietCode vá»›i viá»‡c cáº¯t tá»‰a token vÃ  cÃ¢u lá»‡nh trÃªn hai tÃ¡c vá»¥. Äá»ƒ xÃ¡c minh áº£nh hÆ°á»Ÿng cá»§a viá»‡c cáº¯t tá»‰a cÃ¢u lá»‡nh, chÃºng tÃ´i chá»‰ cháº¡y giai Ä‘oáº¡n chá»n cÃ¢u lá»‡nh trong Thuáº­t toÃ¡n 1. Äá»ƒ kiá»ƒm tra áº£nh hÆ°á»Ÿng cá»§a viá»‡c cáº¯t tá»‰a token, chÃºng tÃ´i loáº¡i bá» trá»±c tiáº¿p cÃ¡c token cÃ³ sá»± chÃº Ã½ tháº¥p nháº¥t cho Ä‘áº¿n khi Ä‘Ã¡p á»©ng Ä‘á»™ dÃ i má»¥c tiÃªu. NhÆ° chÃºng ta cÃ³ thá»ƒ tháº¥y tá»« káº¿t quáº£, má»™t sá»± giáº£m Ä‘Ã¡ng ká»ƒ trong hiá»‡u suáº¥t Ä‘Æ°á»£c quan sÃ¡t cho cáº£ hai chiáº¿n lÆ°á»£c khi Ä‘á»™ dÃ i tÆ°Æ¡ng Ä‘á»‘i giáº£m. Khi 90% code cÃ²n láº¡i, Ä‘iá»ƒm MRR cá»§a hai chiáº¿n lÆ°á»£c cáº¯t tá»‰a gáº§n nhau. Khi Ä‘á»™ dÃ i tÆ°Æ¡ng Ä‘á»‘i giáº£m, Ä‘iá»ƒm cá»§a chiáº¿n lÆ°á»£c cáº¯t tá»‰a token giáº£m nhanh hÆ¡n nhiá»u so vá»›i chiáº¿n lÆ°á»£c cáº¯t tá»‰a cÃ¢u lá»‡nh. Khi Ä‘á»™ dÃ i tÆ°Æ¡ng Ä‘á»‘i giáº£m thÃªm, Ä‘iá»ƒm MRR cá»§a chÃºng giáº£m máº¡nh. Káº¿t quáº£ cho tháº¥y ráº±ng cÃ¡c cÃ¢u lá»‡nh quan trá»ng hÆ¡n cÃ¡c token trong viá»‡c há»c biá»ƒu diá»…n code bá»Ÿi CodeBERT. Má»™t lÃ½ do cÃ³ thá»ƒ lÃ  sá»± chÃº Ã½ token thÆ°á»ng Ä‘o lÆ°á»ng thÃ´ng tin cá»¥c bá»™, trong khi sá»± chÃº Ã½ cÃ¢u lá»‡nh xem xÃ©t má»‘i quan há»‡ giá»¯a cÃ¡c token. Do Ä‘Ã³, sá»± chÃº Ã½ cÃ¢u lá»‡nh cÃ³ thá»ƒ giá»¯ nhiá»u ngá»¯ nghÄ©a hÆ¡n cá»§a cÃ¡c hÃ m. TÃ¡c vá»¥ code summarization chia sáº» káº¿t quáº£ tÆ°Æ¡ng tá»± nhÆ° tÃ¡c vá»¥ code search.
6 THáº¢O LUáº¬N
6.1 CÃ¡c MÃ´ HÃ¬nh ÄÆ°á»£c Tiá»n Huáº¥n Luyá»‡n CÃ³ Thá»ƒ Hiá»ƒu Code ÄÆ°á»£c ÄÆ¡n Giáº£n HÃ³a NhÆ° Tháº¿ NÃ o?
Má»™t cÃ¢u há»i cÃ³ thá»ƒ tranh luáº­n lÃ  lÃ m tháº¿ nÃ o cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c tiá»n huáº¥n luyá»‡n cÃ³ thá»ƒ hiá»ƒu code Ä‘Æ°á»£c Ä‘Æ¡n giáº£n hÃ³a mÃ  khÃ´ng thá»ƒ biÃªn dá»‹ch vÃ  cháº¡y Ä‘Æ°á»£c. MÃ£ nguá»“n bao gá»“m hai kÃªnh thÃ´ng tin: formal & natural [6,7]. NÃ³

--- TRANG 10 ---
ESEC/FSE '22, November 14â€“18, 2022, Singapore, Singapore Zhang, et al.
cÃ³ thá»ƒ Ä‘Æ°á»£c coi lÃ  chÆ°Æ¡ng trÃ¬nh Ä‘á»ƒ mÃ¡y tÃ­nh thá»±c thi hoáº·c nhÆ° má»™t ngÃ´n ngá»¯ tá»± nhiÃªn cá»¥ thá»ƒ Ä‘á»ƒ con ngÆ°á»i giao tiáº¿p [18]. CÃ¡i trÆ°á»›c yÃªu cáº§u mÃ£ nguá»“n pháº£i Ä‘Æ°á»£c biÃªn dá»‹ch vÃ  cháº¡y nghiÃªm ngáº·t, trong khi cÃ¡i sau táº­p trung nhiá»u hÆ¡n vÃ o viá»‡c truyá»n Ä‘áº¡t thÃ´ng tin cho con ngÆ°á»i. ChÃºng tÃ´i tin ráº±ng CodeBERT xem xÃ©t nhiá»u hÆ¡n vá» kÃªnh tá»± nhiÃªn cá»§a mÃ£ nguá»“n [7,18]. Do Ä‘Ã³, nÃ³ chÃº Ã½ nhiá»u hÆ¡n Ä‘áº¿n cÃ¡c tá»« khÃ³a mÃ  khÃ´ng nháº¥t thiáº¿t pháº£i biáº¿t chÆ°Æ¡ng trÃ¬nh thá»±c sá»± hoáº¡t Ä‘á»™ng nhÆ° tháº¿ nÃ o trong quÃ¡ trÃ¬nh thá»±c thi.
CÃ¡c phÃ¡t hiá»‡n thá»±c nghiá»‡m cá»§a chÃºng tÃ´i phÃ¹ há»£p vá»›i má»™t nghiÃªn cá»©u con ngÆ°á»i trÆ°á»›c Ä‘Ã³ vá» cÃ¡ch cÃ¡c láº­p trÃ¬nh viÃªn tÃ³m táº¯t mÃ£ nguá»“n [37], cho tháº¥y ráº±ng cÃ¡c nhÃ  phÃ¡t triá»ƒn thÆ°á»ng báº¯t Ä‘áº§u báº±ng viá»‡c Ä‘á»c tÃªn hÃ m. Há» cÃ³ thá»ƒ bá» qua má»™t sá»‘ thÃ´ng tin cáº¥u trÃºc nhÆ° Ä‘iá»u kiá»‡n For vÃ  If trong khi chÃº Ã½ Ä‘áº·c biá»‡t Ä‘áº¿n thÃ´ng tin theo nghÄ©a Ä‘en nhÆ° gá»i phÆ°Æ¡ng thá»©c vÃ  tÃªn biáº¿n, Ä‘iá»u nÃ y theo nghÄ©a Ä‘en cho tháº¥y Ã½ Ä‘á»‹nh cá»§a code [37]. CÃ¡c thuáº­t toÃ¡n cáº¯t tá»‰a Ä‘Æ°á»£c mÃ´ táº£ trong bÃ i bÃ¡o cá»§a chÃºng tÃ´i sá»­ dá»¥ng phÃ¡t hiá»‡n nÃ y vÃ  Ä‘Æ¡n giáº£n hÃ³a mÃ£ nguá»“n báº±ng cÃ¡ch chá»‰ chá»n thÃ´ng tin quan trá»ng (vÃ­ dá»¥, Ä‘Æ°á»£c pháº£n Ã¡nh bá»Ÿi sá»± chÃº Ã½ cá»§a CodeBERT) trong mÃ£ nguá»“n. Do Ä‘Ã³, chÃºng khÃ´ng cÃ³ nhiá»u tÃ¡c Ä‘á»™ng Ä‘áº¿n viá»‡c hiá»ƒu mÃ£ nguá»“n.
6.2 Nhá»¯ng ngÆ°á»i dÃ¹ng nÃ o cÃ³ thá»ƒ Ã¡p dá»¥ng cÃ¡c ká»¹ thuáº­t?
Má»™t cÃ¢u há»i cÃ³ thá»ƒ tranh luáº­n lÃ  nhá»¯ng ngÆ°á»i dÃ¹ng nÃ o cÃ³ thá»ƒ Ã¡p dá»¥ng ká»¹ thuáº­t nÃ y vÃ¬ nÃ³ cÃ³ sá»± máº¥t Ä‘á»™ chÃ­nh xÃ¡c. Tá»« káº¿t quáº£ trong Báº£ng 3 vÃ  4, máº·c dÃ¹ hiá»‡u suáº¥t giáº£m nháº¹, nÃ³ váº«n vÆ°á»£t trá»™i Ä‘Ã¡ng ká»ƒ so vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p truyá»n thá»‘ng khÃ´ng dá»±a trÃªn pretraining nhÆ° BiRNN vÃ  SelfAttn. Äá»“ng thá»i, DietCode cho tháº¥y lá»£i tháº¿ vá» hiá»‡u quáº£ tÃ­nh toÃ¡n (vÃ­ dá»¥, tiáº¿t kiá»‡m 40% thá»i gian fine-tuning). Do Ä‘Ã³, DietCode cung cáº¥p má»™t lá»±a chá»n thá»±c táº¿ cho nhá»¯ng ngÆ°á»i dÃ¹ng cÃ³ tÃ i nguyÃªn tÃ­nh toÃ¡n háº¡n cháº¿ nhÆ°ng váº«n muá»‘n táº­n dá»¥ng nhanh chÃ³ng cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c tiá»n huáº¥n luyá»‡n lá»›n.
6.3 Vai trÃ² cá»§a cÃ´ng thá»©c hÃ³a 0-1 knapsack
Má»™t ngÆ°á»i cÃ³ thá»ƒ Ä‘áº·t cÃ¢u há»i liá»‡u chÃºng ta cÃ³ thá»±c sá»± cáº§n chuyá»ƒn Ä‘á»•i váº¥n Ä‘á» thÃ nh 0-1 knapsack hay khÃ´ng. Trong cÃ¡c nghiÃªn cá»©u sÆ¡ bá»™ cá»§a chÃºng tÃ´i, viá»‡c Ä‘Æ¡n giáº£n chá»‰ cáº¯t tá»‰a cÃ¡c cÃ¢u lá»‡nh thÆ°á»ng dáº«n Ä‘áº¿n cÃ¡c chuá»—i quÃ¡ dÃ i hoáº·c quÃ¡ ngáº¯n. Viá»‡c cáº¯t tá»‰a token cung cáº¥p má»™t cáº¯t tá»‰a chi tiáº¿t hÆ¡n cho chÆ°Æ¡ng trÃ¬nh Ä‘áº§u vÃ o. Äiá»u nÃ y tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i viá»‡c chá»n cÃ¡c cÃ¢u lá»‡nh vÃ  token Ä‘á»ƒ cÃ³ Ä‘Æ°á»£c sá»± chÃº Ã½ tá»‘i Ä‘a trong khi thá»a mÃ£n háº¡n cháº¿ Ä‘á»™ dÃ i. Do Ä‘Ã³, chÃºng tÃ´i cÃ´ng thá»©c hÃ³a nÃ³ nhÆ° má»™t bÃ i toÃ¡n 0-1 knapsack vÃ  giáº£i quyáº¿t nÃ³ báº±ng chiáº¿n lÆ°á»£c tham lam. Theo káº¿t quáº£ thá»±c nghiá»‡m trong HÃ¬nh 7, má»™t viá»‡c cáº¯t tá»‰a cÃ¢u lá»‡nh Ä‘Æ¡n giáº£n Ä‘áº¡t Ä‘Æ°á»£c MRR khoáº£ng 0.68 trÃªn code search Java khi Ä‘á»™ dÃ i tÆ°Æ¡ng Ä‘á»‘i lÃ  60%, rÃµ rÃ ng tháº¥p hÆ¡n so vá»›i DietCode (MRR=0.71). CÃ¹ng má»™t so sÃ¡nh cÃ³ thá»ƒ Ä‘Æ°á»£c quan sÃ¡t trÃªn tÃ¡c vá»¥ code summarization Java (tá»©c lÃ  16.8 so vá»›i 17.3 vá» BLEU). Äiá»u nÃ y cho tháº¥y hiá»‡u quáº£ cá»§a cÃ´ng thá»©c hÃ³a 0-1 knapsack.
6.4 Ã nghÄ©a cho NghiÃªn cá»©u TÆ°Æ¡ng lai
ThÃ´ng qua nghiÃªn cá»©u thá»±c nghiá»‡m cá»§a chÃºng tÃ´i, chÃºng tÃ´i tháº¥y ráº±ng CodeBERT khÃ´ng nháº­n biáº¿t thÃ´ng tin ngá»¯ phÃ¡p vÃ  cáº¥u trÃºc ráº¥t tá»‘t. VÃ­ dá»¥, Ä‘iá»u kiá»‡n if, Ä‘iá»u kiá»‡n for, vÃ  Ä‘iá»u kiá»‡n while lÃ  ba cÃ¢u lá»‡nh Ä‘iá»ƒn hÃ¬nh Ä‘áº¡i diá»‡n cho cáº¥u trÃºc code, nhÆ°ng chÃºng hiáº¿m khi Ä‘Æ°á»£c cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c tiá»n huáº¥n luyá»‡n xem xÃ©t khi há»c biá»ƒu diá»…n chÆ°Æ¡ng trÃ¬nh. Äiá»u nÃ y thÃºc Ä‘áº©y nghiÃªn cá»©u tÆ°Æ¡ng lai vá» viá»‡c káº¿t há»£p tá»‘t hÆ¡n cÃ¡c cáº¥u trÃºc code vÃ o cÃ¡c mÃ´ hÃ¬nh code Ä‘Æ°á»£c tiá»n huáº¥n luyá»‡n, vÃ­ dá»¥, chuyá»ƒn Ä‘á»•i cÃ¡c kÃ½ hiá»‡u cáº¥u trÃºc (vÃ­ dá»¥, dáº¥u ngoáº·c }) thÃ nh phong cÃ¡ch báº±ng lá»i hÆ¡n (vÃ­ dá»¥, 'káº¿t thÃºc cá»§a má»™t cÃ¢u lá»‡nh for') trÆ°á»›c khi Ä‘Æ°a vÃ o cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c tiá»n huáº¥n luyá»‡n.
BÃªn cáº¡nh DietCode, cÃ³ má»™t lá»›p ká»¹ thuáº­t rá»™ng hÆ¡n, bao gá»“m nÃ©n mÃ´ hÃ¬nh [40], chÆ°ng cáº¥t mÃ´ hÃ¬nh [39], vÃ  giáº£m dá»¯ liá»‡u [48], nháº±m giáº£m Ä‘á»™ phá»©c táº¡p tÃ­nh toÃ¡n cá»§a cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c tiá»n huáº¥n luyá»‡n lá»›n vá»›i chi phÃ­ lÃ  má»™t sá»± giáº£m nháº¹ trong hiá»‡u suáº¥t. DietCode cung cáº¥p má»™t giáº£i phÃ¡p thay tháº¿ dá»… dÃ ng báº±ng cÃ¡ch chá»‰ cáº¯t tá»‰a cÃ¡c chÆ°Æ¡ng trÃ¬nh Ä‘áº§u vÃ o. ChÃºng tÃ´i tin ráº±ng Ä‘iá»u nÃ y thá»±c táº¿ hÆ¡n cho cÃ¡c nhÃ  phÃ¡t triá»ƒn vÃ¬ há» chá»‰ cáº§n xá»­ lÃ½ dá»¯ liá»‡u mÃ  khÃ´ng cáº§n sá»­a Ä‘á»•i mÃ´ hÃ¬nh. Trong tÆ°Æ¡ng lai, chÃºng ta cÃ³ thá»ƒ Ä‘iá»u tra thÃªm cÃ¡c ká»¹ thuáº­t nhÆ° nÃ©n mÃ´ hÃ¬nh vÃ  chÆ°ng cáº¥t.
6.5 CÃ¡c Má»‘i Äe Dá»a TÃ­nh Há»£p Lá»‡
CÃ¡c Má»‘i Äe Dá»a Ná»™i Bá»™. Khi tÃ­nh toÃ¡n trá»ng sá»‘ chÃº Ã½ cho cÃ¡c cÃ¢u lá»‡nh, chÃºng tÃ´i gáº·p váº¥n Ä‘á» out-of-vocabulary (OOV). ChÃºng tÃ´i giáº£i quyáº¿t váº¥n Ä‘á» nÃ y báº±ng cÃ¡ch loáº¡i trá»« cÃ¡c danh má»¥c cÃ¢u lá»‡nh hiáº¿m trong cÃ¡c thá»­ nghiá»‡m cá»§a chÃºng tÃ´i. Tuy nhiÃªn, má»™t sá»‘ danh má»¥c cÃ¢u lá»‡nh váº«n cÃ³ thá»ƒ cáº§n thiáº¿t máº·c dÃ¹ cÃ³ sá»‘ lÆ°á»£ng tháº¥p trong kho dá»¯ liá»‡u. HÆ¡n ná»¯a, dá»¯ liá»‡u thÃ´ Ä‘Æ°á»£c cung cáº¥p bá»Ÿi CodeSearchNet á»Ÿ Ä‘á»‹nh dáº¡ng vÄƒn báº£n thuáº§n tÃºy. ChÃºng tÃ´i phÃ¢n tÃ­ch cÃ¡c cÃ¢u lá»‡nh báº±ng cÃ¡ch sá»­ dá»¥ng cÃ¡c quy táº¯c xá»­ lÃ½ vÄƒn báº£n do chÃºng tÃ´i thiáº¿t káº¿. Tuy nhiÃªn, cÃ³ thá»ƒ cÃ³ cÃ¡c mÃ´ hÃ¬nh khÃ´ng Ä‘á»u mÃ  parser cá»§a chÃºng tÃ´i khÃ´ng thá»ƒ nháº­n biáº¿t. Äiá»u nÃ y cÃ³ thá»ƒ gÃ¢y ra nhiá»…u trong táº­p dá»¯ liá»‡u cá»§a chÃºng tÃ´i vÃ  áº£nh hÆ°á»Ÿng Ä‘áº¿n káº¿t quáº£ nghiÃªn cá»©u cá»§a chÃºng tÃ´i.
CÃ¡c Má»‘i Äe Dá»a Ngoáº¡i Bá»™. ChÃºng tÃ´i chá»‰ thá»±c hiá»‡n cÃ¡c thá»­ nghiá»‡m cá»§a mÃ¬nh trong Java vÃ  Python. Máº·c dÃ¹ cÃ¡c káº¿t luáº­n tá»« cáº£ hai ngÃ´n ngá»¯ Ä‘á»u tÆ°Æ¡ng tá»±, cÃ¡c ngÃ´n ngá»¯ láº­p trÃ¬nh khÃ¡c nhÆ° LISP vÃ  Erlang cÃ³ thá»ƒ cÃ³ cÃ¡c mÃ´ hÃ¬nh chÃº Ã½ khÃ¡c nhau. NgoÃ i ra, DietCode Ä‘Æ°á»£c Ä‘Ã¡nh giÃ¡ trong hai tÃ¡c vá»¥ downstream: code search vÃ  code summarization. Tuy nhiÃªn, cÃ¡c tÃ¡c vá»¥ nÃ y phá»¥ thuá»™c nhiá»u vÃ o thÃ´ng tin theo nghÄ©a Ä‘en Ä‘Æ°á»£c cung cáº¥p trong mÃ£ nguá»“n. Do Ä‘Ã³, váº«n cáº§n Ä‘Æ°á»£c xÃ¡c minh liá»‡u thuáº­t toÃ¡n Ä‘Æ¡n giáº£n hÃ³a Ä‘Æ°á»£c Ä‘á» xuáº¥t cÃ³ Ã¡p dá»¥ng Ä‘Æ°á»£c cho cÃ¡c tÃ¡c vá»¥ ká»¹ thuáº­t pháº§n má»m khÃ¡c hay khÃ´ng.
7 CÃ”NG VIá»†C LIÃŠN QUAN
7.1 Hiá»ƒu CÃ¡c MÃ´ HÃ¬nh ÄÆ°á»£c Tiá»n Huáº¥n Luyá»‡n cá»§a Code
BÃªn cáº¡nh cÃ´ng viá»‡c cá»§a chÃºng tÃ´i, Ä‘Ã£ cÃ³ cÃ¡c nghiÃªn cá»©u khÃ¡c cÅ©ng cá»‘ gáº¯ng giáº£i thÃ­ch cÃ¡c cÆ¡ cháº¿ cá»§a cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c tiá»n huáº¥n luyá»‡n cho code [1,30,32,38]. Karmakar vÃ  Robbes [24] Ã¡p dá»¥ng bá»‘n tÃ¡c vá»¥ thÄƒm dÃ² trÃªn cÃ¡c mÃ´ hÃ¬nh code Ä‘Æ°á»£c tiá»n huáº¥n luyá»‡n Ä‘á»ƒ Ä‘iá»u tra liá»‡u cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c tiá»n huáº¥n luyá»‡n cÃ³ thá»ƒ há»c cÃ¡c khÃ­a cáº¡nh khÃ¡c nhau cá»§a mÃ£ nguá»“n nhÆ° thÃ´ng tin cÃº phÃ¡p, cáº¥u trÃºc, bá» máº·t, vÃ  ngá»¯ nghÄ©a hay khÃ´ng. KhÃ¡c vá»›i cÃ´ng viá»‡c cá»§a chÃºng tÃ´i, há» chá»‰ nghiÃªn cá»©u thá»±c nghiá»‡m toÃ n bá»™ mÃ´ hÃ¬nh Ä‘Æ°á»£c tiá»n huáº¥n luyá»‡n, trong khi chÃºng tÃ´i táº­p trung vÃ o kiáº¿n thá»©c cá»¥ thá»ƒ hÆ¡n (cÃ¡c token vÃ  cÃ¢u lá»‡nh quan trá»ng) Ä‘Æ°á»£c há»c bá»Ÿi cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c tiá»n huáº¥n luyá»‡n.
CÅ©ng cÃ³ nhiá»u cÃ´ng viá»‡c Ä‘iá»u tra trá»ng sá»‘ chÃº Ã½ cá»§a cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c tiá»n huáº¥n luyá»‡n cho mÃ£ nguá»“n. VÃ­ dá»¥, Wan et al. [44] thá»±c hiá»‡n phÃ¢n tÃ­ch cáº¥u trÃºc cá»§a cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ Ä‘Æ°á»£c tiá»n huáº¥n luyá»‡n cho mÃ£ nguá»“n. Há» phÃ¢n tÃ­ch trá»ng sá»‘ self-attention vÃ  tháº¥y ráº±ng sá»± chÃº Ã½ Transformer cÃ³ thá»ƒ náº¯m báº¯t thÃ´ng tin cáº¥u trÃºc cáº¥p cao cá»§a mÃ£ nguá»“n. AutoFocus [5] nháº±m tiáº¿t lá»™ pháº§n liÃªn quan nháº¥t cá»§a code cho cÃ¡c láº­p trÃ¬nh viÃªn. Há» Ä‘o lÆ°á»ng sá»± liÃªn quan cá»§a cÃ¡c cÃ¢u lá»‡nh báº±ng cÃ¡ch sá»­ dá»¥ng trá»ng sá»‘ chÃº Ã½ tá»« má»™t GGNN [2]. KhÃ¡c vá»›i phÆ°Æ¡ng phÃ¡p cá»§a chÃºng tÃ´i, há» náº¯m báº¯t kiáº¿n thá»©c cáº¥u trÃºc Ä‘Æ°á»£c há»c bá»Ÿi cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c tiá»n huáº¥n luyá»‡n, trong khi chÃºng tÃ´i Ä‘Ã o sÃ¢u hÆ¡n vÃ o

--- TRANG 11 ---
Diet Code Is Healthy: Simplifying Programs for Pre-trained Models of Code ESEC/FSE '22, November 14â€“18, 2022, Singapore, Singapore
cÃ¡c cÃ¢u lá»‡nh vÃ  token quan trá»ng Ä‘Æ°á»£c há»c bá»Ÿi cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c tiá»n huáº¥n luyá»‡n. HÆ¡n ná»¯a, chÃºng tÃ´i Ä‘á» xuáº¥t Ä‘Æ¡n giáº£n hÃ³a chÆ°Æ¡ng trÃ¬nh cho cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ Ä‘Æ°á»£c tiá»n huáº¥n luyá»‡n dá»±a trÃªn cÃ¡c phÃ¡t hiá»‡n.
7.2 ÄÆ¡n Giáº£n HÃ³a ChÆ°Æ¡ng TrÃ¬nh
ÄÆ¡n giáº£n hÃ³a chÆ°Æ¡ng trÃ¬nh Ä‘Ã£ nháº­n Ä‘Æ°á»£c sá»± chÃº Ã½ ngÃ y cÃ ng tÄƒng gáº§n Ä‘Ã¢y. CÃ¡c phÆ°Æ¡ng phÃ¡p tiÃªn tiáº¿n nhÆ° SIVAND [34] vÃ  P2IM [42] dá»±a trÃªn nguyÃªn máº«u delta debugging [49]. CÆ¡ cháº¿ delta debugging yÃªu cáº§u má»™t Ä‘oáº¡n code Ä‘áº§u vÃ o vÃ  má»™t mÃ´ hÃ¬nh deep learning phá»¥ trá»£ nhÆ° code2vec [3]. MÃ´ hÃ¬nh deep learning nháº­n Ä‘oáº¡n code lÃ m Ä‘áº§u vÃ o vÃ  chia nÃ³ thÃ nh cÃ¡c Ä‘oáº¡n. Má»—i Ä‘oáº¡n sau Ä‘Ã³ Ä‘Æ°á»£c Ä‘Æ°a lÃ m Ä‘áº§u vÃ o cho mÃ´ hÃ¬nh máº¡ng nÆ¡-ron Ä‘á»ƒ thá»±c hiá»‡n cÃ¡c tÃ¡c vá»¥ kiá»ƒm tra nhÆ° dá»± Ä‘oÃ¡n tÃªn phÆ°Æ¡ng thá»©c vÃ  phÃ¡t hiá»‡n biáº¿n bá»‹ sá»­ dá»¥ng sai. Náº¿u má»™t Ä‘oáº¡n cÃ³ Ä‘Æ°á»£c Ä‘iá»ƒm thá»a Ä‘Ã¡ng, chÆ°Æ¡ng trÃ¬nh sáº½ chia nÃ³ thÃªm. QuÃ¡ trÃ¬nh tiáº¿p tá»¥c cho Ä‘áº¿n khi hiá»‡u suáº¥t cá»§a táº­p con khÃ´ng thá»a mÃ£n Ä‘iá»ƒm má»¥c tiÃªu. Cuá»‘i cÃ¹ng, thuáº­t toÃ¡n táº¡o ra Ä‘oáº¡n code nhá» nháº¥t thá»a mÃ£n má»¥c tiÃªu cá»§a mÃ´ hÃ¬nh sÃ¢u.
So vá»›i DietCode, cÃ¡c phÆ°Æ¡ng phÃ¡p cá»§a há» khÃ´ng hiá»‡u quáº£ vá» máº·t tÃ­nh toÃ¡n vÃ¬ há» cáº§n cháº¡y má»™t mÃ´ hÃ¬nh deep learning phá»¥ trá»£ vÃ  Ä‘Ã¡nh giÃ¡ hiá»‡u suáº¥t á»Ÿ má»—i láº§n láº·p. VÃ­ dá»¥, SIVAND tá»‘n hÃ ng trÄƒm giá» Ä‘á»ƒ xá»­ lÃ½ 10,000 hÃ m, trong khi DietCode cÃ³ thá»ƒ hoÃ n thÃ nh trong vÃ²ng hai phÃºt.
8 Káº¾T LUáº¬N
BÃ i bÃ¡o nÃ y phÃ¢n tÃ­ch thá»±c nghiá»‡m thÃ´ng tin quan trá»ng Ä‘Æ°á»£c há»c bá»Ÿi CodeBERT, bao gá»“m cÃ¡c token vÃ  cÃ¢u lá»‡nh quan trá»ng trong cáº£ Java vÃ  Python. Káº¿t quáº£ cá»§a chÃºng tÃ´i cho tháº¥y CodeBERT táº­p trung vÃ o cÃ¡c tá»« khÃ³a vÃ  cÃ¡c cÃ¢u lá»‡nh liÃªn quan Ä‘áº¿n dá»¯ liá»‡u nhÆ° chá»¯ kÃ½ phÆ°Æ¡ng thá»©c vÃ  cÃ¢u lá»‡nh return. Dá»±a trÃªn cÃ¡c phÃ¡t hiá»‡n thá»±c nghiá»‡m cá»§a chÃºng tÃ´i, chÃºng tÃ´i Ä‘á» xuáº¥t má»™t phÆ°Æ¡ng phÃ¡p má»›i cÃ³ tÃªn DietCode Ä‘á»ƒ táº­n dá»¥ng nháº¹ nhÃ ng cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c tiá»n huáº¥n luyá»‡n. DietCode Ä‘Æ¡n giáº£n hÃ³a code Ä‘áº§u vÃ o thÃ nh Ä‘á»™ dÃ i má»¥c tiÃªu báº±ng cÃ¡ch chá»n cÃ¡c cÃ¢u lá»‡nh vÃ  token quan trá»ng dá»±a trÃªn trá»ng sá»‘ chÃº Ã½ cá»§a chÃºng báº±ng thuáº­t toÃ¡n 0-1 Knapsack. CÃ¡c thá»­ nghiá»‡m trÃªn hai tÃ¡c vá»¥ Ä‘Ã£ cho tháº¥y DietCode cung cáº¥p káº¿t quáº£ tÆ°Æ¡ng Ä‘Æ°Æ¡ng nhÆ° CodeBERT, vá»›i lá»£i tháº¿ vá» hiá»‡u quáº£ tÃ­nh toÃ¡n.
Trong tÆ°Æ¡ng lai, chÃºng tÃ´i sáº½ xem xÃ©t thÃªm cÃ¡c khÃ­a cáº¡nh mÃ  CodeBERT há»c vá» code, nhÆ° quy táº¯c cÃº phÃ¡p vÃ  quan há»‡ ngá»¯ nghÄ©a, Ä‘á»ƒ giáº£m thÃªm kÃ­ch thÆ°á»›c cá»§a mÃ£ nguá»“n cho cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c tiá»n huáº¥n luyá»‡n. ChÃºng tÃ´i cÅ©ng sáº½ Ä‘iá»u tra cÃ¡c ká»¹ thuáº­t nÃ©n mÃ´ hÃ¬nh [8,9] vÃ  chÆ°ng cáº¥t [39] Ä‘á»ƒ giáº£m thÃªm kÃ­ch thÆ°á»›c cá»§a cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ láº­p trÃ¬nh Ä‘Æ°á»£c tiá»n huáº¥n luyá»‡n.
MÃ£ nguá»“n vÃ  dá»¯ liá»‡u thá»±c nghiá»‡m cá»§a chÃºng tÃ´i Ä‘Æ°á»£c cÃ´ng khai táº¡i https://github.com/zhangzwwww/DietCode
9 Cáº¢M Æ N
CÃ´ng viá»‡c nÃ y Ä‘Æ°á»£c tÃ i trá»£ bá»Ÿi NSFC No. 62102244, CCF-Tencent Open Research Fund (RAGR20220129), vÃ  CCF-Baidu Open Fund (NO. 2021PP15002000).
TÃ€I LIá»†U THAM KHáº¢O
[1]Wasi Ahmad, Saikat Chakraborty, Baishakhi Ray, vÃ  Kai-Wei Chang. 2021. Unified Pre-training for Program Understanding and Generation. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. 2655â€“2668.
[2]Miltiadis Allamanis, Marc Brockschmidt, vÃ  Mahmoud Khademi. 2018. Learning to Represent Programs with Graphs. In International Conference on Learning Representations.
[3]Uri Alon, Meital Zilberstein, Omer Levy, vÃ  Eran Yahav. 2019. code2vec: learning distributed representations of code. Proceedings of the ACM on Programming Languages 3, POPL (2019), 1â€“29.
[4]Dzmitry Bahdanau, Kyung Hyun Cho, vÃ  Yoshua Bengio. 2015. Neural machine translation by jointly learning to align and translate. In Proceedings of the 3rd International Conference on Learning Representations (ICLR).
[5]Nghi DQ Bui, Yijun Yu, vÃ  Lingxiao Jiang. 2019. Autofocus: interpreting attention-based neural networks by code perturbation. In Proceedings of 34th IEEE/ACM International Conference on Automated Software Engineering (ASE). IEEE, 38â€“41.
[6]Casey Casalnuovo, E Morgan, vÃ  P Devanbu. 2020. Does surprisal predict code comprehension difficulty. In Proceedings of the 42nd Annual Meeting of the Cognitive Science Society. Cognitive Science Society Toronto, Canada.
[7]Saikat Chakraborty, Toufique Ahmed, Yangruibo Ding, Premkumar Devanbu, vÃ  Baishakhi Ray. 2020. NatGen: Generative pre-training by" Naturalizing" source code. In Proceedings of the 30th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE).
[8]Yu Cheng, Duo Wang, Pan Zhou, vÃ  Tao Zhang. 2017. A survey of model compression and acceleration for deep neural networks. arXiv preprint arXiv:1710.09282 (2017).
[9]Yu Cheng, Duo Wang, Pan Zhou, vÃ  Tao Zhang. 2018. Model compression and acceleration for deep neural networks: The principles, progress, and challenges. IEEE Signal Processing Magazine 35, 1 (2018), 126â€“136.
[10] Kyunghyun Cho, Bart van Merrienboer, Ã‡aglar GÃ¼lÃ§ehre, Dzmitry Bahdanau, Fethi Bougares, Holger Schwenk, vÃ  Yoshua Bengio. 2014. Learning phrase representations using RNN encoder-decoder for statistical machine translation. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP).
[11] Matteo Ciniselli, Nathan Cooper, Luca Pascarella, Denys Poshyvanyk, Massimiliano Di Penta, vÃ  Gabriele Bavota. 2021. An empirical study on the usage of BERT models for code completion. In 2021 IEEE/ACM 18th International Conference on Mining Software Repositories (MSR). IEEE, 108â€“119.
[12] Kevin Clark, Minh-Thang Luong, Quoc V Le, vÃ  Christopher D Manning. 2019. ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators. In International Conference on Learning Representations.
[13] Alexis Conneau vÃ  Guillaume Lample. 2019. Cross-lingual language model pretraining. Advances in neural information processing systems 32 (2019).
[14] Jacob Devlin, Ming-Wei Chang, Kenton Lee, vÃ  Kristina Toutanova. 2019. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers). 4171â€“4186.
[15] Zhangyin Feng, Daya Guo, Duyu Tang, Nan Duan, Xiaocheng Feng, Ming Gong, Linjun Shou, Bing Qin, Ting Liu, Daxin Jiang, et al. 2020. CodeBERT: a pre-Trained model for programming and natural languages. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP): Findings. 1536â€“1547.
[16] James Gosling, Bill Joy, Guy Steele, vÃ  Gilad Bracha. 2000. The Java language specification. Addison-Wesley Professional.
[17] Sonia Haiduc, Jairo Aponte, vÃ  Andrian Marcus. 2010. Supporting program comprehension with source code summarization. In Proceedings of ACM/IEEE 32nd international conference on software engineering (ICSE), Vol. 2. IEEE, 223â€“226.
[18] Abram Hindle, Earl T Barr, Zhendong Su, Mark Gabel, vÃ  Premkumar Devanbu. 2012. On the naturalness of software. In 2012 34th International Conference on Software Engineering (ICSE). IEEE, 837â€“847.
[19] Raphael Hunger. 2005. Floating point operations in matrix-vector calculus. Munich University of Technology, Inst. for Circuit Theory and Signal.
[20] Hamel Husain, Ho-Hsiang Wu, Tiferet Gazit, Miltiadis Allamanis, vÃ  Marc Brockschmidt. 2019. Codesearchnet challenge: evaluating the state of semantic code search. arXiv preprint arXiv:1909.09436 (2019).
[21] Mohit Iyyer, Varun Manjunatha, Jordan Boyd-Graber, vÃ  Hal DaumÃ© III. 2015. Deep unordered composition rivals syntactic methods for text classification. In Proceedings of the 53rd annual meeting of the association for computational linguistics and the 7th international joint conference on natural language processing (volume 1: Long papers). 1681â€“1691.
[22] Siyuan Jiang, Ameer Armaly, vÃ  Collin McMillan. 2017. Automatically generating commit messages from diffs using neural machine translation. In Proceedings of 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE). IEEE, 135â€“146.
[23] Toshihiro Kamiya, Shinji Kusumoto, vÃ  Katsuro Inoue. 2002. CCFinder: A multilinguistic token-based code clone detection system for large scale source code. IEEE Transactions on Software Engineering (TSE) 28, 7 (2002), 654â€“670.
[24] Anjan Karmakar vÃ  Romain Robbes. 2021. What do pre-trained code models know about code?. In 2021 36th IEEE/ACM International Conference on Automated Software Engineering (ASE). IEEE, 1332â€“1336.
[25] Sehoon Kim, Sheng Shen, David Thorsley, Amir Gholami, Woosuk Kwon, Joseph Hassoun, vÃ  Kurt Keutzer. 2021. Learned token pruning for transformers. arXiv preprint arXiv:2107.00910 (2021).

--- TRANG 12 ---
ESEC/FSE '22, November 14â€“18, 2022, Singapore, Singapore Zhang, et al.
[26] Diederik P. Kingma vÃ  Jimmy Ba. 2017. Adam: a method for stochastic optimization. arXiv:1412.6980 [cs.LG]
[27] Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Veselin Stoyanov, vÃ  Luke Zettlemoyer. 2020. BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. 7871â€“7880.
[28] Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, vÃ  Veselin Stoyanov. 2019. Roberta: a robustly optimized BERT pretraining approach. arXiv preprint arXiv:1907.11692 (2019).
[29] Shuai Lu, Daya Guo, Shuo Ren, Junjie Huang, Alexey Svyatkovskiy, Ambrosio Blanco, Colin Clement, Dawn Drain, Daxin Jiang, Duyu Tang, et al. 2021. CodeXGLUE: A Machine Learning Benchmark Dataset for Code Understanding and Generation. In Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 1).
[30] Antonio Mastropaolo, Simone Scalabrino, Nathan Cooper, David Nader Palacio, Denys Poshyvanyk, Rocco Oliveto, vÃ  Gabriele Bavota. 2021. Studying the usage of text-to-text transfer transformer to support code-related tasks. In Proceedings of IEEE/ACM 43rd International Conference on Software Engineering (ICSE). IEEE, 336â€“347.
[31] Liming Nie, He Jiang, Zhilei Ren, Zeyi Sun, vÃ  Xiaochen Li. 2016. Query expansion based on crowd knowledge for code search. IEEE Transactions on Services Computing 9, 5 (2016), 771â€“783.
[32] Matteo Paltenghi vÃ  Michael Pradel. 2021. Thinking Like a Developer? Comparing the Attention of Humans with Neural Models of Code. In 2021 36th IEEE/ACM International Conference on Automated Software Engineering (ASE). IEEE, 867â€“879.
[33] David Pisinger. 1995. Algorithms for knapsack problems. (1995).
[34] Md Rafiqul Islam Rabin, Vincent J. Hellendoorn, vÃ  Mohammad Amin Alipour. 2021. Understanding neural code intelligence through program simplification. In Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE). Association for Computing Machinery, 441â€“452.
[35] Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al. 2019. Language models are unsupervised multitask learners. OpenAI blog 1, 8 (2019), 9.
[36] Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, vÃ  Peter J Liu. 2020. Exploring the limits of transfer learning with a unified text-to-text transformer. Journal of Machine Learning Research 21 (2020), 1â€“67.
[37] Paige Rodeghero, Collin McMillan, Paul W McBurney, Nigel Bosch, vÃ  Sidney D'Mello. 2014. Improving automated source code summarization via an eye-tracking study of programmers. In Proceedings of the 36th international conference on Software engineering. 390â€“401.
[38] Anna Rogers, Olga Kovaleva, vÃ  Anna Rumshisky. 2020. A primer in bertology: what we know about how BERT works. Transactions of the Association for Computational Linguistics 8 (2020), 842â€“866.
[39] Victor Sanh, Lysandre Debut, Julien Chaumond, vÃ  Thomas Wolf. 2019. DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter. arXiv preprint arXiv:1910.01108 (2019).
[40] Sheng Shen, Zhen Dong, Jiayu Ye, Linjian Ma, Zhewei Yao, Amir Gholami, Michael W Mahoney, vÃ  Kurt Keutzer. 2020. Q-BERT: Hessian based ultra low precision quantization of BERT. In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 34. 8815â€“8821.
[41] Kathryn T Stolee, Sebastian Elbaum, vÃ  Daniel Dobos. 2014. Solving the search for source code. ACM Transactions on Software Engineering and Methodology (TOSEM) 23, 3 (2014), 1â€“45.
[42] Sahil Suneja, Yunhui Zheng, Yufan Zhuang, Jim A Laredo, vÃ  Alessandro Morari. 2021. Probing model signal-awareness via prediction-preserving input minimization. In Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering. 945â€“955.
[43] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Åukasz Kaiser, vÃ  Illia Polosukhin. 2017. Attention is all you need. In Advances in neural information processing systems (NeurlPS 2017). 5998â€“6008.
[44] Yao Wan, Wei Zhao, Hongyu Zhang, Yulei Sui, Guandong Xu, vÃ  Hai Jin. 2022. What do they capture? â€“ a structural analysis of pre-trained language models for source code. In In Proceedings of the 44th International Conference on Software Engineering (ICSE).
[45] Yue Wang, Weishi Wang, Shafiq Joty, vÃ  Steven CH Hoi. 2021. CodeT5: Identifier-aware Unified Pre-trained Encoder-Decoder Models for Code Understanding and Generation. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing. 8696â€“8708.
[46] Martin White, Michele Tufano, Christopher Vendome, vÃ  Denys Poshyvanyk. 2016. Deep learning code fragments for code clone detection. In Proceedings of the 31st IEEE/ACM International Conference on Automated Software Engineering (ASE). IEEE, 87â€“98.
[47] Zhilin Yang, Zihang Dai, Yiming Yang, Jaime Carbonell, Russ R Salakhutdinov, vÃ  Quoc V Le. 2019. Xlnet: generalized autoregressive pretraining for language understanding. Advances in neural information processing systems 32 (2019).
[48] Deming Ye, Yankai Lin, Yufei Huang, vÃ  Maosong Sun. 2021. TR-BERT: Dynamic Token Reduction for Accelerating BERT Inference. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. 5798â€“5809.
[49] Andreas Zeller vÃ  Ralf Hildebrandt. 2002. Simplifying and isolating failure-inducing input. IEEE Transactions on Software Engineering 28, 2 (2002), 183â€“200.
[50] Jian Zhang, Xu Wang, Hongyu Zhang, Hailong Sun, Kaixuan Wang, vÃ  Xudong Liu. 2019. A novel neural source code representation based on abstract syntax tree. In Proceedings of IEEE/ACM 41st International Conference on Software Engineering (ICSE). IEEE, 783â€“794.

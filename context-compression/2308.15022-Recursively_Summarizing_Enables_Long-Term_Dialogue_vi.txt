# 2308.15022.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/context-compression/2308.15022.pdf
# Kích thước tệp: 861320 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Tóm tắt đệ quy cho phép bộ nhớ đối thoại dài hạn trong các mô hình ngôn ngữ lớn

Qingyue Wang^a, Yanhe Fu^b, Yanan Cao^b,∗, Shuai Wang^a, Zhiliang Tian^c, Liang Ding^d

^a Khoa Khoa học máy tính và Kỹ thuật, Đại học Khoa học và Công nghệ Hồng Kông, Hồng Kông, Trung Quốc
^b Viện Kỹ thuật Thông tin, Viện Hàn lâm Khoa học Trung Quốc, Bắc Kinh, Trung Quốc  
^c Trường Máy tính, Đại học Quốc phòng Công nghệ, Trường Sa, Trung Quốc
^d Đại học Sydney, Sydney, Úc

Tóm tắt
Gần đây, các mô hình ngôn ngữ lớn (LLM), như GPT-4, nổi bật với khả năng đối thoại xuất sắc, cho phép chúng tham gia vào các cuộc đối thoại động và có liên quan theo ngữ cảnh trên nhiều chủ đề khác nhau. Tuy nhiên, trong cuộc hội thoại dài hạn, những chatbot này không thể nhớ lại thông tin phù hợp từ quá khứ, dẫn đến các phản hồi không nhất quán. Để giải quyết vấn đề này, chúng tôi đề xuất tạo ra các bản tóm tắt/bộ nhớ một cách đệ quy bằng cách sử dụng các mô hình ngôn ngữ lớn để nâng cao khả năng đối thoại dài hạn của chúng. Cụ thể, phương pháp của chúng tôi đầu tiên kích thích LLM để ghi nhớ các ngữ cảnh đối thoại nhỏ. Sau đó, LLM đệ quy tạo ra bộ nhớ mới bằng cách sử dụng bộ nhớ cũ trước đó và các ngữ cảnh tiếp theo. Cuối cùng, chatbot được nhắc nhở để tạo ra phản hồi dựa trên bộ nhớ mới nhất. Các thí nghiệm trên các LLM được sử dụng rộng rãi cho thấy phương pháp của chúng tôi tạo ra các phản hồi nhất quán hơn trong các cuộc hội thoại dài hạn

∗Tác giả liên hệ.
Địa chỉ email: qingyue.wang@ust.hk (Qingyue Wang), fuyanhe@iie.ac.cn (Yanhe Fu), caoyanan@iie.ac.cn (Yanan Cao), shuaiw@cse.ust.hk (Shuai Wang), tianzhiliang@nudt.edu.cn (Zhiliang Tian), liangding.liam@gmail.com (Liang Ding)

Bản thảo được gửi tới Neurocomputing ngày 8 tháng 5 năm 2025arXiv:2308.15022v3 [cs.CL] 7 tháng 5 năm 2025

--- TRANG 2 ---
và nó có thể được cải thiện đáng kể chỉ với hai/ba ví dụ minh họa đối thoại. Ngoài ra, chúng tôi phát hiện rằng chiến lược của chúng tôi có thể bổ sung tốt cho cả cửa sổ ngữ cảnh lớn (ví dụ: 8K và 16K) và các LLM được tăng cường bằng truy xuất, mang lại hiệu suất đối thoại dài hạn tốt hơn. Đáng chú ý, phương pháp của chúng tôi là một giải pháp tiềm năng để cho phép LLM mô hình hóa ngữ cảnh đối thoại cực kỳ dài. Mã nguồn và script sẽ được phát hành sau.

Từ khóa: tóm tắt đệ quy, bộ nhớ dài hạn, mô hình ngôn ngữ lớn, tạo đối thoại.

1. Giới thiệu

Gần đây, các mô hình ngôn ngữ lớn (LLM), như ChatGPT¹ và GPT-4 (Achiam et al., 2023), thể hiện hiệu suất đầy hứa hẹn trong nhiều ứng dụng ngôn ngữ tự nhiên khác nhau (Brown et al., 2020; Zeng et al., 2022; Zhong et al., 2023; Lu et al., 2023b; Peng et al., 2023; Wu et al., 2023). Một khả năng đáng chú ý nằm ở sức mạnh đối thoại xuất sắc của chúng, hiểu đầu vào và tạo ra các phản hồi giống con người.

Các cửa sổ ngữ cảnh lớn cho phép nhiều LLM² xử lý toàn bộ lịch sử đối thoại, tuy nhiên chúng thường gặp khó khăn trong việc hiểu hiệu quả các tương tác trong quá khứ và tích hợp thông tin quan trọng vào các phản hồi (Zhou et al., 2023). Các ứng dụng như bạn đồng hành AI cá nhân, cần nhớ lại các cuộc hội thoại trong quá khứ để xây dựng mối quan hệ, và trợ lý sức khỏe, phải xem xét hồ sơ đầy đủ các câu hỏi của bệnh nhân để cung cấp kết quả chẩn đoán, chứng minh tầm quan trọng của việc duy trì tính nhất quán

¹https://chat.openai.com/
²GPT-4 gần đây hỗ trợ 128.000 token và LLama3(MetaAI, 2024) hỗ trợ 1.040.000 token.

--- TRANG 3 ---
Bạn có thể nói rằng nó là một nguồn niềm vui lớn đối với tôi.

Tôi không có công việc khác, sáng tác nhạc là trọng tâm chính của tôi. Tất cả mọi thứ thực sự, tôi vừa sáng tác vừa nghe nhạc.

Bạn có thích âm nhạc không?

... ... Bạn có công việc khác hay bạn sáng tác nhạc để kiếm sống? Là một mô hình ngôn ngữ AI, tôi không có công việc theo nghĩa truyền thống.

[Phản hồi][Ngữ cảnh đối thoại] [Khoảng 20 lượt]

Bộ nhớ

Hình 1: Một ví dụ cuộc hội thoại dài hạn từ Bộ dữ liệu Chat Nhiều phiên (Xu et al., 2022a). Khi người dùng tham chiếu trở lại các chủ đề trước đó (tức là sáng tác nhạc), ngay cả ChatGPT (phiên bản gpt-turbo-3.5-0301) cũng tạo ra phản hồi không nhất quán.

và tính mạch lạc trong các cuộc đối thoại dài hạn. Hình 1 minh họa một đối thoại kéo dài hơn 20 lượt, tập trung vào cuộc thảo luận về tính cách của những người nói (ví dụ: bot sáng tác nhạc, và người dùng thích nhạc đồng quê). Tuy nhiên, ngay cả ChatGPT mạnh mẽ cũng quên thông tin trong quá khứ và tạo ra phản hồi kém, cho thấy sự cần thiết phải mô hình hóa rõ ràng bộ nhớ dài hạn trong các cuộc hội thoại.

Để giải quyết vấn đề này, có hai phương pháp chính để nâng cao khả năng đối thoại dài hạn của LLM. Phương pháp đầu tiên là phương pháp dựa trên truy xuất, trực tiếp lưu trữ các phát ngôn hội thoại trong quá khứ trong bộ nhớ và điều chỉnh một bộ truy xuất tiên tiến để xác định lịch sử liên quan nhất (Guu et al., 2020; Lewis et al., 2020). Tuy nhiên, khó có thể thu được một bộ truy xuất hoạt động tốt (lý tưởng), đảm bảo rằng các phát ngôn được truy xuất nắm bắt được ngữ nghĩa hoàn chỉnh về các cuộc hội thoại hiện tại. Cách thứ hai là sử dụng một mô-đun bộ nhớ để tóm tắt thông tin hội thoại quan trọng để hỗ trợ LLM, cũng được gọi là các phương pháp dựa trên bộ nhớ

--- TRANG 4 ---
(Mazaré et al., 2018; Xu et al., 2022b; Chen et al., 2024a). Chúng thường áp dụng một mô hình được huấn luyện riêng biệt hoặc một mô hình ngôn ngữ lớn mạnh mẽ để tạo ra bộ nhớ cho các cuộc đối thoại trong quá khứ. Tuy nhiên, những phương pháp này thiếu cơ chế lặp lại cần thiết trên bộ nhớ được tạo ra, dẫn đến việc dự trữ thông tin lỗi thời trực tiếp gây tổn hại đến chất lượng của các phản hồi.

Trong bài báo này, chúng tôi đề xuất một phương pháp plug-in đơn giản và hiệu quả cho phép chính LLM tạo ra các bản tóm tắt, lưu trữ thông tin thời gian thực của người nói thông qua việc cập nhật liên tục và xem xét lại ngữ cảnh trong quá khứ để hỗ trợ các tương tác dài hạn. Trong thực tế, một LLM tạo sinh đầu tiên được nhắc nhở để tạo ra một bản tóm tắt dựa trên một ngữ cảnh đối thoại ngắn. Sau đó, chúng tôi yêu cầu LLM tiếp tục cập nhật và tạo ra một bản tóm tắt/bộ nhớ mới bằng cách kết hợp bộ nhớ trước đó và các cuộc đối thoại tiếp theo. Cuối cùng, chúng tôi khuyến khích LLM phản hồi bằng cách sử dụng bộ nhớ mới nhất làm tham chiếu chính để tham gia vào cuộc đối thoại đang diễn ra. Vì các bản tóm tắt được tạo ra ngắn hơn nhiều so với toàn bộ cuộc đối thoại, lược đồ được đề xuất của chúng tôi không chỉ mô hình hóa bộ nhớ cuộc hội thoại dài hạn mà còn phục vụ như một giải pháp tiềm năng để cho phép các LLM hiện tại xử lý các ngữ cảnh cực kỳ dài (trên nhiều phiên đối thoại) mà không cần mở rộng đắt đỏ cài đặt độ dài tối đa.

Về mặt thực nghiệm, chúng tôi triển khai phương pháp của mình bằng cách sử dụng nhiều LLM tiên tiến mở (Llama (Touvron et al., 2023) và ChatGLM (GLM et al., 2024)) và đóng (OpenAI's GPT-3.5-Turbo), và hiệu suất trên đối thoại dài hạn vượt trội so với các phương pháp phổ biến trong cả đánh giá tự động và con người. Hơn nữa, chúng tôi xác minh tính hiệu quả của việc sử dụng bộ nhớ rõ ràng cho các cuộc đối thoại dài hạn và việc sử dụng bộ nhớ được tạo ra của chúng tôi dễ dàng hơn cho LLM tiêu hóa. Những phát hiện này nhấn mạnh tầm quan trọng của việc phát triển các chiến lược tạo bộ nhớ tiên tiến

--- TRANG 5 ---
Phương pháp của chúng tôi có thể tiếp tục nâng cao chất lượng phản hồi bằng cách kết hợp kỹ thuật học trong ngữ cảnh (ICL), trong đó nhiều mẫu theo định dạng (đối thoại, bộ nhớ và phản hồi vàng) được trình bày cho LLM. Điều này cho phép chúng sử dụng bộ nhớ được tạo ra một cách linh hoạt hơn. Ngoài ra, chúng tôi chứng minh khả năng tổng quát của phương pháp trên các LLM khác nhau, với phương pháp của chúng tôi đạt được cải thiện khoảng +3% trong điểm BLEU trên text-davinci-003. Cuối cùng, chúng tôi quan sát thấy rằng lược đồ của chúng tôi bổ sung cho các LLM mở rộng cửa sổ hiện có (ví dụ: GPT-3.5-Turbo-16k và LongLoRA-8k) và các LLM được tăng cường bằng truy xuất (ví dụ: LLM-BM25 và LLM-DPR), tạo ra các phản hồi mạch lạc và nhất quán hơn trong các cuộc hội thoại dài hạn.

Tóm lại, các đóng góp của chúng tôi như sau:

• Chúng tôi đề xuất một phương pháp mới bằng cách tóm tắt đệ quy các cuộc đối thoại trong quá khứ để nâng cao bộ nhớ của LLM, cho phép tạo ra các phản hồi có tính nhất quán cao trong các cuộc hội thoại dài hạn.

• Các thí nghiệm vững chắc trên các bộ dữ liệu công khai cho thấy tính ưu việt của phương pháp được đề xuất, với nhiều LLM mã nguồn mở và mã nguồn đóng xác minh tính phổ quát và độ mạnh mẽ của nó.

• Tính đơn giản của phương pháp khiến nó bổ sung tốt cho các công trình hiện có, bao gồm các kỹ thuật dựa trên truy xuất và ngữ cảnh dài, có tiềm năng lớn để trở thành một plugin trực giao cho cộng đồng LLM.

--- TRANG 6 ---
2. Công trình liên quan

2.1. Mô hình ngôn ngữ lớn

Các mô hình ngôn ngữ lớn (LLM) đã thể hiện hiệu suất xuất sắc trong nhiều công nghệ ngôn ngữ hướng tới người dùng, bao gồm hội thoại, tóm tắt và viết sáng tạo (Achiam et al., 2023; Shuster et al., 2022; Rubin và Berant, 2024). Mặc dù các LLM này đạt được thành công đáng chú ý trong nhiều nhiệm vụ phổ biến, khả năng mô hình hóa văn bản dài của chúng vẫn là một thách thức (An et al., 2023). Để giải quyết vấn đề này, một số công trình điều chỉnh transformer để chứa các đầu vào dài hơn, như nội suy vị trí (Chen et al., 2023) và tự chú ý hiệu quả (Beltagy et al., 2020; Chen et al., 2024b). Tuy nhiên, những LLM mở rộng cửa sổ ngữ cảnh này không chỉ yêu cầu huấn luyện liên tục trên các văn bản dài chất lượng cao mà vẫn gặp khó khăn trong việc sử dụng và truy xuất thông tin cốt lõi từ toàn bộ đầu vào (Liu et al., 2023).

Gần đây, trong nhiệm vụ hỏi-đáp, một số nhà nghiên cứu phát hiện rằng hiệu suất của LLM giảm đáng kể khi mọi người thay đổi vị trí của thông tin liên quan, cho thấy rằng các mô hình ngôn ngữ hiện tại không sử dụng thông tin một cách mạnh mẽ trong các ngữ cảnh đầu vào dài (Liu et al., 2023; Li et al., 2023). Nhiều công trình cho rằng việc thiếu các cơ chế bộ nhớ rõ ràng trong các LLM hiện tại cản trở hiệu suất của chúng trong các nhiệm vụ đòi hỏi nhận thức và hiểu biết ngữ cảnh liên tục (Chen et al., 2024a). Ngày nay, hiệu suất của LLM vẫn chưa được khám phá sâu trong các tình huống đối thoại tầm xa. Công trình này tập trung vào phát triển khả năng mô hình hóa dài hạn của LLM, nơi chúng tôi nhắc nhở nó tự ghi nhớ, tự cập nhật và tự sử dụng trong các cuộc hội thoại, hỗ trợ tạo ra phản hồi nhất quán.

--- TRANG 7 ---
2.2. Đối thoại miền mở dài hạn

Các hệ thống đối thoại miền mở (Liu et al., 2016; Zhang et al., 2018; Kann et al., 2022), còn được gọi là chatbot hoặc tác nhân hội thoại, đã thu được sự phổ biến to lớn và nhiều nghiên cứu trong những năm gần đây. Trong số đó, cài đặt hội thoại dài hạn là một vấn đề khá khó khăn, vì nó cần khả năng hiểu và ghi nhớ thông tin lịch sử đối thoại quan trọng (Wu et al., 2022; Zhang et al., 2022) về truy vấn hiện tại. Giải pháp phổ biến và tiềm năng nhất là trực tiếp lưu trữ thông tin một phần để theo dõi lịch sử cuộc hội thoại (Lee et al., 2023), thường dưới dạng các phát ngôn đối thoại hoặc bản tóm tắt.

Cuộc hội thoại hiện tại và thông tin liên quan sau đó được đưa vào bộ tạo phản hồi. Một ý tưởng trực quan là áp dụng bộ truy xuất để tìm các phát ngôn liên quan nhất theo đối thoại hiện tại, được gọi là phương pháp dựa trên truy xuất. Phương pháp phổ biến khác là phương pháp dựa trên bộ nhớ, cố gắng tạo ra và quản lý bản tóm tắt để thu được thông tin quan trọng từ lịch sử. Ví dụ, MemoChat (Lu et al., 2023a) cho phép chatbot tổ chức lại lịch sử đối thoại trong quá khứ theo các chủ đề khác nhau của người nói và nhắc nhở LLM truy xuất từ bộ nhớ có cấu trúc trong quá trình tạo sinh. Tiến xa hơn, MemoryBank (Zhong et al., 2024) đề xuất một cơ chế bộ nhớ mới bằng cách tạo ra bản tóm tắt cho mỗi phiên đối thoại trước tiên và sau đó nén chúng thành một bản tóm tắt toàn cầu. Tuy nhiên, bộ nhớ của chúng hoàn toàn cố định sau khi được lưu trữ, không thể đảm bảo tính nhất quán với cuộc đối thoại đang diễn ra. So sánh quan trọng giữa các phương pháp hiện có này và phương pháp của chúng tôi được thể hiện trong Hình 2. Như có thể thấy, phương pháp của chúng tôi và các phương pháp này chủ yếu khác biệt trong cách tạo bộ nhớ, nơi chúng tôi liên tục tích hợp thông tin lịch sử và bộ nhớ cũ để thu được bộ nhớ thời gian thực, cho phép đạt được bộ nhớ chính xác và mô hình hóa các phụ thuộc tầm xa.

--- TRANG 8 ---
(a) Phương pháp truy xuất
(b) MemoChat
(c) MemoryBank
(d) Phương pháp của chúng tôi

Hình 2: So sánh giữa các baseline và phương pháp của chúng tôi. "U", "S", "T" và "M" là các từ viết tắt của Phát ngôn, Phiên, Chủ đề đối thoại và Bộ nhớ. Hộp đứt nét màu đỏ đề cập đến bộ nhớ được sử dụng để tạo ra phản hồi.

3. Tổng quan phương pháp

Theo các công trình trước đây (Xu et al., 2022a; Bae et al., 2022), chúng tôi ký hiệu rằng một cuộc đối thoại ngữ cảnh dài bao gồm nhiều phiên với một người dùng cụ thể, cũng được gọi là Đối thoại Nhiều phiên. Mục tiêu của nhiệm vụ là tạo ra các phản hồi liên quan đến ngữ cảnh và có tính nhất quán cao cho người dùng dựa trên các phiên trong quá khứ và ngữ cảnh hiện tại. Chính thức, mỗi cuộc đối thoại có thể được viết như D={S, C_t, r_t}. Ở đây, S={S_1, S_2, ..., S_N} đại diện cho N phiên trong quá khứ và mỗi phiên bao gồm nhiều phát ngôn giữa hai người nói. r_t là phản hồi thực tế cho C_t với các phiên nền S. C_t={u_1, r_1, ..., u_t} biểu thị ngữ cảnh đối thoại của phiên hiện tại tại bước t, trong đó u và r đại diện cho các phát ngôn từ người dùng và chatbot, tương ứng.

Trong bài báo này, chúng tôi đề xuất một cơ chế bộ nhớ mới để hỗ trợ mô hình ngôn ngữ lớn cho các nhiệm vụ đối thoại nhiều phiên. Bộ nhớ chứa nhiều câu ngôn ngữ tự nhiên, lưu trữ thông tin quan trọng của người nói được trích xuất từ các phiên trước đó. Mục tiêu của chúng tôi là thu được bộ nhớ đáng tin cậy từ các phiên trong quá khứ và dự đoán phản hồi nhất quán và có ý nghĩa bằng cách sử dụng ngữ cảnh đối thoại hiện tại và

--- TRANG 9 ---
Việc đăng ký phòng gym diễn ra như thế nào? Tôi thực sự rất thích đi bộ và chạy bộ

Nó diễn ra tốt. Tôi rất hào hứng có thêm sự linh hoạt với thẻ thành viên phòng gym 24 giờ. Còn bạn thì sao? Bạn có thể tập luyện tốt không?

Có may mắn gì trong việc tìm kiếm phòng gym mới không? ......

Tôi thích đến phòng gym để tập luyện.

Có, tôi đang tham gia phòng gym gần nhà. Nó mở cửa 24 giờ nên tôi có thể đi bất cứ khi nào muốn. Bộ nhớ thời gian thực

Phiên 1

Thích đi bộ và chạy bộ
Thích đến phòng gym
Bot:
Người dùng:

Thích đi bộ và chạy bộ, và gần đây đã tham gia phòng gym mới mở cửa 24 giờ
Thích đến phòng gym
Bot:
Người dùng:

......

Phiên 2
Phiên 3

1
2
3

Mô hình ngôn ngữ lớn

Hình 3: Sơ đồ tổng quan của phương pháp chúng tôi. Mô hình sử dụng phiên đầu tiên để tạo ra bộ nhớ ban đầu (mũi tên xanh lá), sau đó cập nhật bộ nhớ khi phiên thứ hai kết thúc (mũi tên vàng), và tạo ra phản hồi bằng cách sử dụng bộ nhớ mới nhất tại phiên thứ ba (mũi tên xanh dương).

bộ nhớ. Cụ thể, chúng tôi phân tích mục tiêu thành hai giai đoạn với phân phối xác suất sau:

P(r_t|C_t, S) = P(r_t|C_t, M_N)P(M_N|S), (1)

trong đó M_i đại diện cho bộ nhớ có sẵn khi phiên thứ i kết thúc. Và P(M_N|S) = ∏^N_{i=1} P(M_i|S_i, M_{i-1}) là một quá trình tuần tự hoặc Markov trong đó mỗi bộ nhớ M_i của phiên i chỉ phụ thuộc vào phiên hiện tại và bộ nhớ trước đó M_{i-1}.

4. Phương pháp

Để đạt được đối thoại dài hạn, chúng tôi nhắc nhở một mô hình ngôn ngữ lớn tùy ý hoàn thành hai nhiệm vụ, tức là lặp lại bộ nhớ và tạo phản hồi dựa trên bộ nhớ. Nhiệm vụ đầu tiên chịu trách nhiệm tóm tắt đệ quy thông tin quan trọng cùng với cuộc đối thoại dài hạn, và nhiệm vụ thứ hai là kết hợp bộ nhớ mới nhất

--- TRANG 10 ---
và đối thoại hiện tại để tạo ra phản hồi phù hợp và nhất quán. Quy trình làm việc của phương pháp được đề xuất được thể hiện trong Hình 3.

4.1. Lặp lại bộ nhớ

Mục tiêu của việc lặp lại bộ nhớ là thu được bản tóm tắt mạch lạc và cập nhật cho chatbot. Các công trình sớm (Bae et al., 2022; Choi et al., 2023) cập nhật bộ nhớ bằng cách thực hiện nhiều "thao tác cứng" trên bản tóm tắt, như thay thế, nối thêm và xóa, dựa vào đối thoại chất lượng cao với nhãn thao tác. Tuy nhiên, thiết kế tốn công này phá vỡ tính mạch lạc ngữ nghĩa của bản tóm tắt và không phù hợp để quản lý trong thời gian dài. Khác biệt, chúng tôi hướng dẫn các LLM tự tạo ra bộ nhớ (bản tóm tắt) một cách đệ quy bằng cách sử dụng ngữ cảnh đối thoại và bộ nhớ trước đó. Bằng cách sử dụng các bản tóm tắt cũ, mô hình có thể tiêu hóa đầy đủ ngữ cảnh đối thoại hiện tại và do đó đạt được bộ nhớ chất lượng cao. Chính thức, bộ nhớ được cập nhật được tính bằng:

M_i = LLM(S_i, M_{i-1}, P_m), (2)

trong đó M_i = {m_1, m_2, ..., m_J} biểu thị nhiều câu, chứa thông tin quan trọng được tóm tắt từ phiên S_i, và P_m là lời nhắc của LLM để tạo ra bộ nhớ mới. Việc lặp lại bộ nhớ sẽ được lặp lại N lần cho đến khi tất cả các phiên trước đó kết thúc, nơi chúng ta có thể thu được bộ nhớ mới nhất M_N. Lấy đối thoại trong Hình 3 làm ví dụ, hai lần lặp lại bộ nhớ xảy ra ở cuối phiên thứ nhất và thứ hai. Trong lần lặp thứ hai, LLM kết hợp tính cách mới (tức là bot gần đây đã tham gia phòng gym mới) từ Phiên 2 vào bộ nhớ cũ (tức là bot thích đi bộ và chạy bộ).

Xây dựng lời nhắc. Để cho phép LLM thực hiện hiệu quả nhiệm vụ lặp lại bộ nhớ, chúng tôi thiết kế một lời nhắc cụ thể cho nó, được thể hiện trong Bảng 1. Nó chủ yếu

--- TRANG 11 ---
Bảng 1: Thiết kế lời nhắc của việc lặp lại bộ nhớ, bao gồm định nghĩa nhiệm vụ, mô tả nhiệm vụ và đầu vào nhiệm vụ

Lời nhắc
Bạn là một mô hình ngôn ngữ AI tiên tiến có khả năng lưu trữ và cập nhật bộ nhớ để theo dõi thông tin tính cách quan trọng cho cả người dùng và bot. Bạn sẽ nhận được một bộ nhớ trước đó và ngữ cảnh đối thoại. Mục tiêu của bạn là cập nhật bộ nhớ bằng cách kết hợp thông tin tính cách mới.

Để cập nhật bộ nhớ thành công, hãy làm theo các bước sau:
1. Phân tích cẩn thận bộ nhớ hiện có và trích xuất tính cách quan trọng của người dùng và bot từ đó.
2. Xem xét ngữ cảnh đối thoại được cung cấp để xác định bất kỳ tính cách mới hoặc thay đổi nào cần được kết hợp vào bộ nhớ.
3. Kết hợp thông tin tính cách cũ và mới để tạo ra đại diện cập nhật của đặc điểm người dùng và bot.
4. Cấu trúc bộ nhớ được cập nhật một cách rõ ràng và súc tích, đảm bảo nó không vượt quá 20 câu.

Hãy nhớ, bộ nhớ nên phục vụ như một điểm tham chiếu để duy trì tính liên tục trong đối thoại và giúp bạn phản hồi chính xác cho người dùng dựa trên tính cách của họ.

[Bộ nhớ trước đó] [Ngữ cảnh phiên]
Đầu ra [Bộ nhớ được cập nhật]

bao gồm ba phần: (1) Định nghĩa nhiệm vụ chịu trách nhiệm định nghĩa vai trò của LLM hiện tại, cũng như đầu vào và đầu ra của bộ lặp bộ nhớ (LLM). (2) Mô tả nhiệm vụ đưa ra các bước chi tiết để hoàn thành nhiệm vụ trên. Để đảm bảo việc cập nhật bộ nhớ kịp thời, chúng tôi nhắc nhở LLM tạo ra đại diện mới của người nói bằng cách xem xét các bản tóm tắt cũ và các phiên hiện tại. (3) Đầu vào nhiệm vụ chứa hai placeholder, nơi chúng tôi lấy bộ nhớ trước đó và toàn bộ phiên làm đầu vào. Thông qua xác minh thực nghiệm, chúng tôi phát hiện rằng việc sử dụng hướng dẫn từng bước giúp LLM hiểu và thực hiện tốt hơn việc lặp lại bộ nhớ³.

³https://platform.openai.com/docs/guides/prompt-engineering

--- TRANG 12 ---
Bảng 2: Lời nhắc của việc tạo phản hồi dựa trên bộ nhớ, bao gồm định nghĩa nhiệm vụ, mô tả nhiệm vụ và đầu vào nhiệm vụ

Lời nhắc
Bạn sẽ được cung cấp bộ nhớ chứa thông tin tính cách cho cả bản thân và người dùng. Mục tiêu của bạn là phản hồi chính xác cho người dùng dựa trên các đặc điểm tính cách và ngữ cảnh đối thoại.

Hãy làm theo các bước sau để hoàn thành nhiệm vụ thành công:
1. Phân tích bộ nhớ được cung cấp để trích xuất các đặc điểm tính cách quan trọng cho cả bản thân và người dùng.
2. Xem xét lịch sử đối thoại để hiểu ngữ cảnh và dòng chảy của cuộc hội thoại.
3. Sử dụng các đặc điểm tính cách được trích xuất và ngữ cảnh đối thoại để xây dựng phản hồi phù hợp.
4. Nếu không có đặc điểm tính cách cụ thể nào có thể áp dụng, hãy phản hồi tự nhiên như một con người.
5. Chú ý đến tính liên quan và tầm quan trọng của thông tin tính cách, tập trung vào việc nắm bắt các khía cạnh quan trọng nhất trong khi duy trì tính mạch lạc tổng thể của bộ nhớ.

[Bộ nhớ trước đó] [Ngữ cảnh hiện tại]
Đầu ra [Phản hồi]

4.2. Tạo phản hồi dựa trên bộ nhớ

Mục tiêu cuối cùng là tạo ra các phản hồi nhất quán và tự nhiên dựa trên bộ nhớ đối thoại và ngữ cảnh của phiên hiện tại. Chính thức, phản hồi của phiên hiện tại có thể được thu thập bằng cách kích thích LLM như một bộ tạo phản hồi:

r_t = LLM(C_t, M_N, P_r), (3)

trong đó P_r là lời nhắc của bộ tạo. Đặc biệt, lấy bộ nhớ được tạo ra M_N và phiên hiện tại C_t, chúng tôi yêu cầu LLM một lần nữa tạo ra phản hồi. Trong Hình 3, LLM xem xét bộ nhớ mới nhất từ Phiên 2 và cung cấp phản hồi có tính nhất quán cao cho người dùng, tức là "sự linh hoạt hơn với thẻ thành viên phòng gym 24 giờ".

Xây dựng lời nhắc. Lời nhắc cho việc tạo phản hồi dựa trên bộ nhớ được thể hiện trong Bảng 2. Lời nhắc tương tự như lời nhắc của việc lặp lại bộ nhớ, bao gồm định nghĩa nhiệm vụ, mô tả và đầu vào, nơi chúng tôi nhắc nhở LLM sử dụng

--- TRANG 13 ---
Thuật toán 1: Tạo phản hồi sử dụng bộ nhớ đệ quy.
Đầu vào: Một đối thoại dài hạn D={S, C_t} bao gồm nhiều phiên với một người dùng; Một mô hình được huấn luyện trước tạo sinh LLM; Lời nhắc được định nghĩa trước P_m và P_r
Đầu ra: Một phản hồi cho người dùng.
1 M_0 ← không có;
// Đặt bộ nhớ ban đầu là trống
2 for i ← 1 to N do
3    M_i = LLM(S_i, M_{i-1}, P_m);
// Cập nhật bộ nhớ khi một phiên kết thúc
4 r_t = LLM(C_t, M_N, P_r);
// Phản hồi bằng bộ nhớ mới nhất
5 return r_t

thông tin được trích xuất và duy trì tính nhất quán của bộ nhớ khi phản hồi. Ngoài ra, phương pháp hướng dẫn từng bước cũng hiệu quả cho việc tạo phản hồi dựa trên bộ nhớ.

4.3. Thuật toán

Quá trình tạo phản hồi sử dụng bộ nhớ đệ quy được minh họa trong Thuật toán 1. Ban đầu, bộ nhớ ban đầu được đặt là trống, tức là chuỗi "không có". Sau đó, chúng tôi cập nhật bộ nhớ đệ quy sử dụng từng ngữ cảnh phiên (dòng 3). Cuối cùng, LLM tạo ra phản hồi với sự hỗ trợ của bộ nhớ mới nhất (dòng 5). Các mô hình được huấn luyện trước tạo sinh được sử dụng cho việc lặp lại bộ nhớ và tạo phản hồi có thể khác nhau. Ví dụ, các nhà phát triển có thể huấn luyện một bộ lặp bộ nhớ riêng tư thông qua các mô hình hoặc dữ liệu tùy chỉnh, để nâng cao các LLM mở/

--- TRANG 14 ---
đóng mục tiêu cho các nhiệm vụ dài hạn hoặc ngữ cảnh dài.

5. Cài đặt thực nghiệm

5.1. Bộ dữ liệu

Chúng tôi xác thực tính hiệu quả của phương pháp được đề xuất trên hai bộ dữ liệu đối thoại dài hạn được sử dụng rộng rãi: bộ dữ liệu Multi-Session Chat (MSC) (Xu et al., 2022a) và bộ dữ liệu Carecall (Bae et al., 2022).

Bộ dữ liệu MSC. là bộ dữ liệu cuộc hội thoại dài giữa người với người lớn nhất cho đến nay. Các phiên đầu là cuộc hội thoại ngắn nơi hai người nói làm quen với nhau lần đầu tiên và sau đó họ tiếp tục nói về chủ đề trước đó hoặc bắt đầu cuộc hội thoại về một chủ đề mới.

Carecall. là bộ dữ liệu đa phiên miền mở tiếng Hàn, được sử dụng để theo dõi sức khỏe bệnh nhân. Để so sánh công bằng, chúng tôi sử dụng phiên bản tiếng Anh được dịch bằng máy công khai⁴ trong các thí nghiệm.

Cài đặt của CareCall tương tự như quy trình được trình bày trong bộ dữ liệu MSC. Sự khác biệt chính là Carecall bổ sung chứa nhiều cập nhật tính cách có khả năng thay đổi trong thời gian ngắn, như sức khỏe và chế độ ăn uống của người dùng, trong khi thông tin tính cách trong bộ dữ liệu MSC vẫn cố định sau khi được lưu trữ. Cả hai bộ dữ liệu đều có năm phiên và mỗi phiên bao gồm nhiều phát ngôn giữa hai người nói (người dùng và chatbot), nơi những người đàm thoại tái tham gia sau vài giờ hoặc vài ngày và tiếp tục trò chuyện. Vì các phiên đầu chỉ có lịch sử hội thoại rất ngắn, chúng tôi chủ yếu đánh giá phương pháp được đề xuất trong

⁴https://github.com/naver-ai/carecall-memory

--- TRANG 15 ---
phiên 4 và 5 cho khả năng mô hình hóa dài hạn. Thống kê của hai bộ dữ liệu được đưa ra trong Phụ lục A.

5.2. Metrics đánh giá

chúng tôi tiến hành các đánh giá đa dạng trong các thí nghiệm, bao gồm metrics tự động, đánh giá con người và đánh giá LLM, tập trung vào chất lượng của bộ nhớ và phản hồi được tạo ra.

Metrics tự động. Chúng tôi sử dụng BLEU-1/2 (Papineni et al., 2002), F1 với tham chiếu đến các chú thích của con người. Bên cạnh đó, chúng tôi tính BertScore (Li et al., 2016) để đo lường sự tương tự ngữ nghĩa giữa các tài liệu tham khảo và các phản hồi được tạo ra.

Đánh giá con người. Nhiều công trình chỉ ra rằng các metrics đánh giá tự động không đủ để nắm bắt các sắc thái của cuộc hội thoại (Deriu et al., 2019). Theo các công trình trước đây (Bae et al., 2022), chúng tôi yêu cầu ba nhân viên sourcing đám đông gán điểm từ 0 đến 2 (0: tệ, 1: ổn, 2: tốt) cho các phản hồi được tạo ra dựa trên các khía cạnh về tính hấp dẫn, tính mạch lạc và tính nhất quán. Các tiêu chí này được thảo luận như sau: (1) Tính hấp dẫn: Nó đánh giá liệu chatbot có thu hút sự quan tâm của người dùng và khiến họ muốn tiếp tục cuộc hội thoại hay không. Điểm cao về tính hấp dẫn có nghĩa là các phản hồi thú vị và phù hợp theo ngữ cảnh, khuyến khích người dùng tiếp tục trò chuyện. (2) Tính mạch lạc: Nó đo lường liệu phản hồi có duy trì dòng chảy logic và rõ ràng dựa trên ngữ cảnh của cuộc hội thoại hay không. Phản hồi mạch lạc đảm bảo cuộc hội thoại có ý nghĩa và vẫn phù hợp, nâng cao sự tham gia của người dùng. (3) Tính nhất quán: Nó đánh giá liệu phản hồi có phù hợp với thông tin được cung cấp trong các tương tác trước đó hay không. Phản hồi nhất quán

--- TRANG 16 ---
xây dựng lòng tin và độ tin cậy bằng cách chứng minh rằng chatbot nhớ và tích hợp chính xác các trao đổi trong quá khứ.

Đánh giá LLM. Gần đây, chiến lược LLM-as-a-Judge (Pan et al., 2023) đã được sử dụng rộng rãi trong việc đánh giá các nhiệm vụ tạo sinh. Một số công trình tiết lộ sự sai lệch tối thiểu của đánh giá GPT-4 so với con người (>0.85 sự đồng ý) trong chất lượng đối thoại (Zhang et al., 2023a). Được truyền cảm hứng từ điều này, chúng tôi sử dụng GPT-4 như một đánh giá viên tiên tiến, sử dụng hai phương pháp phổ biến để đánh giá chất lượng của các phản hồi được tạo ra. (1) Đánh giá mô hình đơn (Lu et al., 2023a): chúng tôi nhắc nhở GPT-4 đánh giá các phản hồi một cách riêng biệt từ ba khía cạnh, tức là tính hấp dẫn, tính mạch lạc và tính nhất quán với thang đo số nguyên từ 1 (rất tệ) đến 100 (rất tốt). (2) Đánh giá mô hình theo cặp (Dubois et al., 2024): chúng tôi yêu cầu GPT-4 so sánh trực tiếp hai kết quả tạo sinh ẩn danh và xác định phản hồi nào tốt hơn. Trong khi đánh giá mô hình đơn cung cấp cái nhìn sâu chi tiết về các khía cạnh cụ thể của mỗi phản hồi, so sánh theo cặp là cần thiết để hiểu hiệu suất tương đối, đặc biệt khi phân biệt sự khác biệt tinh tế giữa các đầu ra.

5.3. Baseline

Chúng tôi chủ yếu sử dụng các phương pháp sau cho đối thoại văn bản dài trong LLM: các phương pháp chỉ dùng ngữ cảnh (không sử dụng bộ nhớ nào), các phương pháp dựa trên truy xuất (với các bộ truy xuất khác nhau), và các phương pháp dựa trên bộ nhớ (với các cơ chế bộ nhớ khác nhau)

Phương pháp chỉ dùng ngữ cảnh. Đây là phương pháp ngây thơ nhất để trực tiếp sử dụng LLM như một chatbot, nơi nó nối các phiên trong quá khứ và ngữ cảnh đối thoại hiện tại làm

--- TRANG 17 ---
đầu vào. Chúng tôi sử dụng "Llama2-7B" (Touvron et al., 2023), "ChatGLM2-6B"⁵, và OpenAI ChatGPT "gpt-3.5-turbo-0301" làm LLM nền tảng cho phương pháp chỉ dùng ngữ cảnh⁶.

Phương pháp dựa trên truy xuất. Nhiều công trình trước đây (Xu et al., 2022a) sử dụng các bộ truy xuất để lọc thông tin quan trọng và sau đó bao gồm các tài liệu top-k vào đầu vào để hỗ trợ đối thoại ngữ cảnh dài. Đối với đối thoại dài hạn, các tài liệu top-k đề cập đến các phát ngôn liên quan từ lịch sử. Ở đây, chúng tôi chọn hai thuật toán truy xuất được sử dụng rộng rãi, tức là BM25 (Robertson et al., 2009) và truy xuất đoạn văn dày đặc được huấn luyện trước (DPR) (Karpukhin et al., 2020), để tra cứu các phát ngôn liên quan từ các phiên trong quá khứ. Để thuận tiện, chúng tôi đặt tên các baseline dựa trên truy xuất trên là ChatGPT-BM25 và ChatGPT-DPR, tương ứng.

Phương pháp dựa trên bộ nhớ. Các công trình gần đây sử dụng một bộ tóm tắt để trừu tượng hóa thông tin quan trọng từ quá khứ để hỗ trợ cuộc hội thoại dài hạn. Đơn giản, chúng tôi chỉ chọn hai phương pháp đại diện từ các kỹ thuật dựa trên bộ nhớ khác nhau, MemoryBank (Zhong et al., 2024) và MemoChat (Lu et al., 2023a). MemoryBank đề xuất một cơ chế bộ nhớ dài hạn giống con người, tạo ra các bản tóm tắt có thứ tự của các đối thoại trong quá khứ với dấu thời gian, và sau đó tổ chức lại chúng để thu được bộ nhớ toàn cục. Bộ nhớ sẽ bị quên và được cập nhật bởi đường cong quên lãng của Ebbinghaus. Ở đây, chúng tôi kết hợp MemoryBank với ChatGPT như một baseline mạnh, được đặt tên là ChatGPT-MemoryBank. Khác biệt, MemoChat duy trì bộ nhớ hội thoại có cấu trúc để hỗ trợ đối thoại dài hạn, tức là tạo ra các bản tóm tắt cho mỗi chủ đề đối thoại. Chúng tôi kết hợp MemoChat vào ChatGPT, được đặt tên là

⁵https://github.com/THUDM/ChatGLM2-6B
⁶Để thuận tiện, "ChatGPT" sau đây đề cập đến phiên bản gpt-3.5-turbo-0301.

--- TRANG 18 ---
ChatGPT-MemoChat, để so sánh công bằng với các phương pháp khác.

Lưu ý rằng phương pháp của chúng tôi tập trung vào cài đặt zero-shot cho LLM để tham gia vào đối thoại dài hạn, khiến việc so sánh với các mô hình được tinh chỉnh khác trở nên không công bằng.

5.4. Triển khai

Chúng tôi triển khai phương pháp của mình bằng cách để LLM phản hồi sử dụng bộ nhớ được tạo ra đệ quy trong đối thoại dài hạn, do đó nó được gọi là "LLM-Rsum".

LLM nền tảng. Chúng tôi sử dụng OpenAI ChatGPT "gpt-3.5-turbo-0301", "Llama2-7B" và "ChatGLM2-6B" trong các thí nghiệm chính, "text-davinci-003" và "Llama2-7B" (Touvron et al., 2023) trong phân tích để thể hiện tính phổ quát, "longlora-8k" (Chen et al., 2024b) và ChatGPT-16k "gpt-3.5-turbo-16k" làm nền tảng của thảo luận bổ sung. Trừ khi được chỉ định khác, chúng tôi sử dụng cùng một LLM để hoàn thành việc lặp lại bộ nhớ và tạo phản hồi dựa trên bộ nhớ. Trong quá trình tạo sinh, chúng tôi đặt nhiệt độ của tất cả LLM là 0 để so sánh công bằng. Độ dài tối đa của token đầu vào cho bộ dữ liệu Carecall và MSC không quá 4k, do đó tất cả LLM nền tảng trong thí nghiệm có thể xử lý toàn bộ ngữ cảnh đối thoại.

Bộ truy xuất. Xem xét quy mô của các phát ngôn trong quá khứ không đủ lớn để sử dụng FAISS (Research, 2019), chúng tôi chọn các phát ngôn liên quan top-k nhất sẽ được kết hợp với các cuộc đối thoại đang diễn ra, nhắc nhở LLM phản hồi. Theo các công trình trước đây (Xu et al., 2022a) cho đối thoại dài hạn, k được đặt thành 3 và 5.

Các phương pháp dựa trên bộ nhớ. Việc triển khai và thiết kế lời nhắc của các phương pháp MemoryBank và Memochat dựa trên mã nguồn được phát hành công khai trong các bài báo gốc của chúng. Để biết chi tiết, vui lòng tham khảo các bài báo gốc.

--- TRANG 19 ---
Bảng 3: So sánh đánh giá tự động và con người giữa các phương pháp khác nhau trên bộ dữ liệu MSC và Carecall, báo cáo chất lượng của phản hồi được tạo ra. "BScore", "Enga.", "Cohe" và "Cons" là các từ viết tắt của BertScore, Tính hấp dẫn, Tính mạch lạc và Tính nhất quán. Giá trị tốt nhất được in đậm.

[TABLE CONTENT - A detailed comparison table with MSC Dataset and Carecall Dataset columns showing various metrics for different methods including Context-only LLM, Retrieval-based Approach, and Memory-based Approach]

6. Kết quả thực nghiệm

6.1. Kết quả chính

Kết quả Metrics tự động. Trong Bảng 3, chúng tôi so sánh các phương pháp khác nhau qua phiên 5 trong bộ dữ liệu MSC và Carecall sử dụng các LLM phổ biến. Đầu tiên, trong số các mô hình vanilla ("Llama2-7B", "ChatGLM2-6B", và "ChatGPT"), ChatGPT hoạt động tốt một cách nhất quán trên hai bộ dữ liệu, với điểm số cạnh tranh trong BScore, F1 và BLEU-1/2. Những kết quả này minh họa rằng ChatGPT đủ mạnh mẽ để xử lý đối thoại dài hạn, do đó, chúng tôi để ChatGPT làm mô hình nền tảng cho phương pháp của mình.

--- TRANG 20 ---
Thứ hai, như mong đợi, phương pháp được đề xuất ("ChatGPT-Rsum") đạt được hiệu suất tốt nhất trên cả hai bộ dữ liệu, cho thấy lợi ích của việc sử dụng bộ nhớ đệ quy tự động. Cụ thể, phương pháp của chúng tôi đạt được khoảng +0.2% trên điểm F1, có thể chấp nhận được so với các công trình trước đây (Xu et al., 2022a). Bộ dữ liệu MSC khó hơn các bộ dữ liệu miền mở khác do ngữ cảnh gấp 3 lần, vì vậy những cải thiện nhẹ là bình thường. Thứ ba, các phương pháp dựa trên truy xuất có thể không phải lúc nào cũng hữu ích trong việc nâng cao chất lượng tạo sinh. Từ kết quả, hiệu suất của ChatGPT-BM25 và ChatGPT-DPR tệ hơn nhiều so với ChatGPT vanilla trong bộ dữ liệu Carecall, hoàn toàn trái ngược với kết quả trong MSC. Lý do là chatbot cần chủ động hướng dẫn các chủ đề đối thoại trong Carecall, do đó khó truy xuất ngữ cảnh phù hợp và liên quan từ truy vấn của người dùng. Do đó, hiệu suất của các phản hồi được tạo ra sẽ bị tổn hại do thông tin không liên quan.

Kết quả đánh giá con người. Chúng tôi cũng trình bày kết quả đánh giá con người về các phương pháp khác nhau trong Bảng 3. Từ kết quả, chúng tôi thấy rằng: 1) Hầu hết các phương pháp được tăng cường bộ nhớ đạt điểm cao hơn về tính nhất quán và tính mạch lạc so với ChatGPT vanilla, chứng minh rằng duy trì bộ nhớ hiệu quả hơn việc sử dụng toàn bộ lịch sử trực tiếp khi tham gia vào cuộc hội thoại dài hạn cho LLM; 2) Phương pháp của chúng tôi có thể tạo ra phản hồi hấp dẫn hơn so với các baseline dựa trên bộ nhớ khác (ChatGPT-MemoryBank và ChatGPT-MemoChat). Lý do là việc cập nhật bộ nhớ liên tục tích cực thiết lập các phụ thuộc toàn cục bên trong lịch sử trong quá khứ, giúp LLM hiểu tốt hơn đối thoại và tạo ra các phản hồi chất lượng cao.

--- TRANG 21 ---
Bảng 4: So sánh kết quả metrics đánh giá bởi GPT-4 trên các phương pháp khác nhau trong phiên 5 của bộ dữ liệu MSC.

[THIS IS TABLE:
Method | Engagingness | Coherence | Consistency | Average
ChatGPT | 75.48 | 75.00 | 75.48 | 75.32
ChatGPT-MemoryBank | 74.68 | 80.92 | 84.56 | 80.05
ChatGPT-MemoChat | 72.32 | 77.36 | 78.96 | 76.21
ChatGPT-Rsum (Ours) | 78.92 | 83.56 | 84.76 | 82.41]

6.2. Đánh giá LLM

Đánh giá mô hình đơn. Bảng 4 báo cáo kết quả metrics đánh giá của GPT-4 trong phiên 5 giữa các phương pháp khác nhau trong bộ dữ liệu MSC. Ngoài ra, kết quả chứng minh sự đồng ý cao giữa con người (trong Bảng 3) và đánh giá của GPT-4 về chất lượng tổng thể của các phản hồi được tạo ra, tức là ChatGPT-Rsum > ChatGPT-MemoryBank > ChatGPT-MemoChat > ChatGPT. Với điều này, chúng tôi chủ yếu trình bày các đánh giá LLM trong các thí nghiệm sau để giảm chi phí lao động. Cuối cùng, đáng chú ý rằng so với kết quả đánh giá con người, GPT-4 có xu hướng cho điểm cao hơn về cả tính mạch lạc và tính nhất quán của câu. Chúng tôi giả định rằng các giá trị của con người và LLM có thể không hoàn toàn phù hợp ở mức độ chi tiết, điều này có thể là một hướng mới để phát triển đánh giá LLM.

Đánh giá mô hình theo cặp. Hơn nữa, chúng tôi lấy mẫu ngẫu nhiên 1000 phản hồi được tạo ra từ các mô hình theo cặp, tức là phương pháp của chúng tôi so với baseline, và sau đó yêu cầu GPT-4 quyết định phản hồi nào tốt hơn dựa trên tính hấp dẫn, tính nhất quán và tính mạch lạc. Kết quả được thể hiện trong Hình 4. So với baseline cạnh tranh nhất (MemoryBank), phương pháp được đề xuất của chúng tôi đạt được cải thiện 36.3% (thắng 48.2% và chỉ thua 11.9%), minh họa sự tiến bộ của cơ chế lặp lại được đề xuất.

--- TRANG 22 ---
[THIS IS FIGURE: Bar chart showing comparative win rates with ChatGPT (96.2% win, 2.2% tie, 1.6% loss), ChatGPT-MemoChat (61.3% win, 33.0% tie, 5.7% loss), and ChatGPT-MemoryBank (48.2% win, 39.9% tie, 11.9% loss)]

Hình 4: Tỷ lệ thắng so sánh của phương pháp chúng tôi và các baseline cạnh tranh, bao gồm ChatGPT, ChatGPT-MemoChat, và ChatGPT-MemoryBank.

6.3. Nghiên cứu loại bỏ

Để hiểu rõ hơn tính hiệu quả của các cơ chế bộ nhớ được đề xuất cho LLM, chúng tôi sử dụng ChatGPT làm LLM và tiến hành nghiên cứu loại bỏ trong phiên 5. Kết quả được thể hiện trong Bảng 5. Đầu tiên, chúng tôi chỉ sử dụng ngữ cảnh đối thoại của phiên hiện tại làm đầu vào của LLM, được đặt tên là "W/O Memory". Như mong đợi, hiệu suất của mô hình đã giảm đáng kể, chứng minh sự cần thiết của các bộ nhớ có sẵn từ quá khứ trong cuộc hội thoại dài hạn. Thứ hai, chúng tôi thay thế bộ nhớ được tạo ra bằng bộ nhớ thực tế, tức là nhắc nhở ChatGPT tạo ra phản hồi sử dụng bộ nhớ vàng và ngữ cảnh đối thoại, được đặt tên là "Gt. Memory". Thú vị, mô hình đạt được điểm BLEU và F1 thấp hơn so với việc sử dụng bộ nhớ dự đoán (Ours). Lý do tiềm năng là các bộ nhớ vàng, ví dụ: "Tôi đang cố gắng giảm cân" và "Tôi muốn bắt đầu chạy bộ", bị phân mảnh và thiếu tính mạch lạc, điều này không tối ưu như lời nhắc của LLM, trong khi phương pháp tạo bộ nhớ tóm tắt đệ quy có thể mô hình hóa khôn ngoan các phụ thuộc dài và tạo ra lời nhắc dễ tiêu hóa cho LLM. Phân tích thêm

--- TRANG 23 ---
Bảng 5: Nghiên cứu loại bỏ về bộ nhớ trong bộ dữ liệu MSC.

[THIS IS TABLE:
Method | BScore | F1 | BLEU-1/2
ChatGPT-Rsum (Ours) | 86.89 | 20.48 | 21.83/12.59
W/O Memory | 85.40 | 18.94 | 21.10/12.17
Gt. Memory | 85.93 | 20.46 | 21.50/12.40]

có thể xem trong §6.4 và §6.5.

6.4. Phân tích

Ngoài kết quả chính và nghiên cứu loại bỏ, chúng tôi cũng muốn đi sâu hơn vào phương pháp của mình. Trong phần sau, chúng tôi muốn thảo luận một số câu hỏi nghiên cứu (RQ): RQ1: Chất lượng của bộ nhớ được tạo ra như thế nào? RQ2: Những lỗi nào có thể xảy ra trong việc tạo bộ nhớ? RQ3: Phương pháp được đề xuất có mạnh mẽ với các LLM khác không? RQ4: Phương pháp zero-shot được đề xuất có thể được áp dụng hiệu quả trong các tình huống few-shot không?

Phương pháp của chúng tôi có thể tạo ra bộ nhớ chính xác và khả dụng (Q1). Trọng tâm của khung này là tạo ra bộ nhớ đối thoại bằng cách tóm tắt liên tục. Để xác minh chất lượng tóm tắt, chúng tôi tính các metrics tự động giữa bộ nhớ dự đoán và bộ nhớ vàng trong bộ dữ liệu MSC trên ChatGPT-MemoryBank và phương pháp của chúng tôi, tương ứng, được thể hiện trong Hình 5. Như có thể thấy, các bộ nhớ được tạo ra của cả hai mô hình đạt được điểm F1 đáng kể (+25%), giải thích độ tin cậy của việc sử dụng bản tóm tắt đối thoại làm bộ nhớ. Bên cạnh đó, ChatGPT-Rsum (Ours) đạt được hiệu suất tổng thể cao hơn về bộ nhớ, cho rằng tóm tắt đệ quy có thể thu được thông tin hoàn chỉnh và dài hạn hơn so với ChatGPT-MemoryBank. Cuối cùng, với hiệu suất phản hồi của phiên 5 trong Bảng 3 (Ours > ChatGPT-MemoryBank), chúng tôi cho rằng độ chính xác của dự đoán bộ nhớ có tương quan tích cực với chất lượng phản hồi. Chúng tôi cũng

--- TRANG 24 ---
[THIS IS FIGURE: Two bar charts showing evaluation scores (P, R, F1) for Session 4 and Session 5, comparing ChatGPT-MemoryBank and ChatGPT-Rsum(Ours)]

Hình 5: Đánh giá về bộ nhớ được tạo ra trên ChatGPT-MemoryBank và phương pháp của chúng tôi. "P" và "R" đề cập đến độ chính xác và độ nhớ lại, tương ứng.

Bảng 6: Ba loại lỗi trong bộ nhớ được tạo ra, bao gồm các ví dụ tương ứng và tỷ lệ lỗi của nội dung. Ngữ cảnh lỗi được đánh dấu màu đỏ.

[THIS IS TABLE: Shows three error types with examples of past dialogs, generated memory, golden memory, and proportion percentages]

tin rằng các cơ chế bộ nhớ tiên tiến có thể đạt được cải thiện thêm, điều này có thể được điều tra trong các công trình tương lai.

Bộ nhớ của chúng tôi gặp một số lỗi thực tế trong phạm vi có thể chấp nhận được (Q2).

Người ta có thể nghi ngờ rằng các bản tóm tắt được tạo ra có thể có vấn đề nghiêm trọng về sự không nhất quán thực tế và lan truyền lỗi. Chúng tôi lập luận rằng tóm tắt không phải là một nhiệm vụ khó khăn và một số công trình phát hiện rằng các bản tóm tắt LLM thể hiện tính nhất quán thực tế tốt hơn và ít ảo giác hơn (Pu et al., 2023). Để giải quyết thêm mối quan tâm này, chúng tôi chọn ngẫu nhiên 100 mẫu đối thoại và đánh giá thủ công chất lượng bộ nhớ trong phiên cuối cùng. Bảng 6 báo cáo ba loại lỗi được tìm thấy trong bộ nhớ được tạo ra của chúng tôi. 1) Thực tế bịa đặt đề cập đến bộ nhớ chứa một số thông tin mà lịch sử đối thoại không thể xác minh. Trong trường hợp đầu tiên, bot đi bộ đến nơi làm việc không phải để xem động vật. 2) Mối quan hệ không chính xác đề cập đến việc bộ nhớ được tạo ra kết luận lỗi nhân quả hoặc tham chiếu từ lịch sử. Trong đối thoại thứ hai, người dùng đã nhượng bộ con gái mình, chứ không phải con mèo đó. 3) Chi tiết bị thiếu đề cập đến việc bộ nhớ bỏ qua các chi tiết một phần của sự kiện. Trong tình huống thứ ba, mô hình bỏ qua tên phim yêu thích của người dùng và chỉ tóm tắt thô sơ là thích xem TV. Mặc dù tồn tại một số sai lầm trong bộ nhớ được tạo ra của chúng tôi, thông tin không chính xác/không chính xác không vượt quá 10% nội dung tóm tắt, cho thấy rằng hầu hết các bản tóm tắt được tạo ra đệ quy đáng tin cậy và có thể sử dụng để hỗ trợ đối thoại dài hạn. Bên cạnh đó, các thí nghiệm rộng rãi (trong Bảng 3 và Hình 5) xác thực hiệu quả của phương pháp chúng tôi trong việc sử dụng các bản tóm tắt được tạo ra cho đối thoại dài hạn, điều này cấu thành đóng góp chính của bài báo này. Cuối cùng, phân tích trên cũng minh họa rằng phương pháp của chúng tôi cần được tăng cường trong việc ghi nhớ các chi tiết đối thoại chính xác. Các kỹ thuật dựa trên tác nhân tiên tiến hơn, như các phương pháp được tăng cường bằng truy xuất (Zhang et al., 2023b), có thể được áp dụng trong tương lai.

Phương pháp plug-and-play của chúng tôi hiệu quả với các LLM quy mô nhỏ và lớn khác (Q3). Để kiểm tra liệu phương pháp tóm tắt đệ quy được đề xuất có mạnh mẽ với các mô hình ngôn ngữ lớn khác để giải quyết các phiên dài hạn hay không, chúng tôi đánh giá khung bằng cách sử dụng "Llama2-7B" và "text-davinci-003" làm mô hình nền tảng. Hiệu suất trong đối thoại ngữ cảnh dài (phiên 5 của bộ dữ liệu MSC) được thể hiện trong Hình 6, nơi những cải thiện đáng kể xác nhận độ mạnh mẽ của phương pháp chúng tôi trên các LLM khác nhau. Chúng tôi cũng tin rằng các

--- TRANG 25 ---
[THIS IS FIGURE: Two charts side by side - Left chart shows F1 scores for Llama2-7B and text-davinci-003 comparing Vanilla LLM vs LLM-Rsum, Right chart shows Average #Token for different ChatGPT variants across sessions 3-5]

Hình 6: Điểm F1 trên phản hồi khi sử dụng các LLM khác.

Hình 7: Số lượng token trung bình trong các phản hồi được tạo ra.

mô hình ngôn ngữ mạnh mẽ hơn, tức là "text-davinci-003" > "Llama2-7b", thực sự hiểu ngữ cảnh tốt hơn và tạo ra bộ nhớ và phản hồi chính xác hơn, do đó dẫn đến những cải thiện tốt hơn từ cơ chế được đề xuất.

Phương pháp của chúng tôi có thể được tăng cường thêm bằng một số đối thoại được gán nhãn (Q4). Chúng tôi đánh giá hiệu suất few-shot của cơ chế được đề xuất bằng kỹ thuật trong ngữ cảnh. Cụ thể, chúng tôi sử dụng một số đối thoại với bộ nhớ được tạo ra và phản hồi được gán nhãn (thực tế), được lấy mẫu ngẫu nhiên từ tập hợp lệ, để nhắc nhở bộ tạo phản hồi trước các đầu vào thử nghiệm. Bảng 7 cho thấy rằng ngay cả hai mẫu được gán nhãn cũng có thể mang lại lợi thế rõ ràng dưới khung của chúng tôi, trên cả điểm F1 và BLEU, cho thấy tiềm năng của khung chúng tôi. Chúng tôi phân tích rằng bộ nhớ được tạo ra có thể chứa một lượng đáng kể thông tin ưa thích của người nói, điều này chắc chắn làm tăng khó khăn trong việc tạo ra câu trả lời. Do đó, dữ liệu được gán nhãn có giá trị cao đối với phương pháp được đề xuất, vì nó tự nhiên hướng dẫn LLM sử dụng bộ nhớ một cách hiệu quả.

--- TRANG 26 ---
Bảng 7: Kết quả so sánh (%) về zero-shot và few-shot khi sử dụng bộ nhớ được tạo ra trong bộ dữ liệu MSC.

[THIS IS TABLE:
N-shot | Session 4 | Session 5
      | F1 | BLEU-1/2 | F1 | BLEU-1/2
Zero-shot | 20.19 | 21.80/12.57 | 20.48 | 21.76/12.59
Two-shot | 20.37 | 22.11/12.65 | 20.63 | 22.04/12.71
Three-shot | 20.98 | 22.43/12.76 | 21.08 | 22.23/12.82]

[THIS IS FIGURE: Dialog example showing conversation about shopping addiction, with different response methods including ChatGPT, ChatGPT-DPR, ChatGPT-MemoryBank, and ChatGPT-Rsum showing various responses about shopping habits and basketball shoes]

Hình 8: Các phản hồi được tạo ra khi sử dụng các phương pháp khác nhau trong bộ dữ liệu MSC. Trong số đó, khung của chúng tôi có thể thu được bộ nhớ cập nhật và kết hợp nó vào phản hồi được tạo ra. Để rõ ràng, chúng tôi bỏ qua các phát ngôn khác và bộ nhớ dự đoán không liên quan đến truy vấn hiện tại.

6.5. Nghiên cứu trường hợp

Để kiểm tra liệu bộ nhớ có kết hợp thông tin đối thoại tầm xa vào phản hồi hay không, đầu tiên chúng tôi so sánh độ dài của phản hồi khi sử dụng các phương pháp khác nhau. Như thể hiện trong Hình 7, độ dài phản hồi trung bình khi sử dụng bộ nhớ được tạo ra dài hơn khoảng 15 token so với LLM vanilla (không có bộ nhớ) trên tất cả các phiên. Hơn nữa, chúng tôi lấy một mẫu từ các phản hồi được tạo ra để phân tích tác động của bộ nhớ trên các phương pháp khác nhau. Trong trường hợp của Hình 8, người dùng đề cập đến "nghiện mua sắm" ở lượt hiện tại, đề cập đến thói quen mua quá nhiều giày của bot. Từ kết quả, chúng ta có thể rút ra những kết luận sau: (1) Phương pháp dựa trên bộ truy xuất (ChatGPT-DPR) và LLM chỉ dùng ngữ cảnh (ChatGPT) có xu hướng tập trung vào thông tin đối thoại cục bộ (hoặc gần nhất) với đầu vào ngữ cảnh dài. (2) So với việc sử dụng bộ nhớ vàng, bộ nhớ được tạo ra trôi chảy và mạch lạc hơn. Điều này cũng giải thích tại sao phương pháp của chúng tôi hoạt động tốt hơn so với việc sử dụng bộ nhớ vàng trực tiếp, điều này đã được quan sát trong Bảng 5. (3) So với cơ chế bộ nhớ cạnh tranh (MemoryBank), phương pháp của chúng tôi có thể lặp lại và cập nhật bộ nhớ kịp thời, giữ tính nhất quán với cuộc hội thoại đang diễn ra. (4) Phương pháp bộ nhớ tóm tắt đệ quy được đề xuất thực sự tích hợp thông tin đối thoại dài hạn vào các phản hồi được tạo ra. Trong Hình 8, bộ nhớ mới nhất (tức là sở thích của bot đối với giày bóng rổ) được hiểu và đề cập trong phản hồi.

6.6. Bổ sung cho các công trình hiện có

Phương pháp được đề xuất của chúng tôi là một cơ chế bộ nhớ mới để cải thiện khả năng đối thoại tầm xa của LLM, dự kiến sẽ bổ sung cho các công trình hiện có, bao gồm các phương pháp dựa trên truy xuất và mở rộng đầu vào. Ở đây, chúng tôi liệt kê hai phương pháp đại diện và thể hiện tính trực giao.

LLM dựa trên truy xuất. Tính hiệu quả của các phương pháp dựa trên truy xuất trên bộ dữ liệu MSC có thể được quan sát trong Bảng 3, minh họa tiềm năng của chúng trong các cuộc hội thoại tầm xa. Ở đây, chúng tôi tiếp tục khám phá tính bổ sung cho phương pháp được đề xuất. Như thể hiện trong Bảng 8, các phương pháp được tăng cường bằng truy xuất (ChatGPT-BM25 và ChatGPT-DPR) đạt được những cải thiện hơn nữa so với ChatGPT vanilla, cho thấy tầm quan trọng của việc nhớ lại thông tin liên quan trong các đối thoại tầm xa. Bên cạnh đó, việc sử dụng khung của chúng tôi có thể đẩy các phương pháp dựa trên truy xuất này hướng tới hiệu suất tốt hơn,

--- TRANG 27 ---
Bảng 8: Tính bổ sung giữa phương pháp của chúng tôi và các phương pháp dựa trên truy xuất, về đánh giá tự động và LLM trên phiên 5 của bộ dữ liệu MSC.

[THIS IS TABLE:
Method | F1 | Coherence | Consistency
ChatGPT | 19.41 | 75.00 | 75.48
ChatGPT-BM25 (k=5) | 20.91 | 75.44 | 76.88
+ Our framework | 21.81 | 84.44 | 90.68
ChatGPT-DPR (k=5) | 20.97 | 78.60 | 79.20
+ Our framework | 21.69 | 83.40 | 86.48]

Bảng 9: Tính bổ sung giữa phương pháp của chúng tôi và các LLM ngữ cảnh dài, về đánh giá tự động và LLM trên phiên 5 của bộ dữ liệu MSC.

[THIS IS TABLE:
Method | F1 | Coherence | Consistency
longlora-8k | 14.02 | 42.44 | 62.04
longlora-8k + Our framework | 15.77 | 53.41 | 68.60
ChatGPT | 19.41 | 75.00 | 75.48
ChatGPT-16k | 19.92 | 78.60 | 79.20
ChatGPT-16k+ Our framework | 19.29 | 90.04 | 92.44
GPT-4o | 20.35 | 87.70 | 82.00
GPT-4o + Our framework | 21.02 | 91.12 | 93.29]

đạt được khoảng +0.8% điểm F1. Chúng tôi giải thích rằng những phát ngôn được truy xuất này có thể được xem như bằng chứng về chi tiết sự kiện, cùng với bộ nhớ được tạo ra của chúng tôi, tăng cường khả năng đối thoại dài hạn của LLM.

LLM ngữ cảnh dài. Để xử lý toàn bộ ngữ cảnh và giảm mất thông tin, nhiều nhà nghiên cứu cố gắng mở rộng độ dài ngữ cảnh của LLM thông qua huấn luyện từ đầu, tinh chỉnh hoặc các thuật toán cụ thể khác (ví dụ: FlashAttention) (Dao et al., 2022). Ví dụ, LongLoRA (Chen et al., 2024b) mở rộng Llama2 (Touvron et al., 2023) 7B từ ngữ cảnh 4k đến 100k. Mặc dù độ dài tối đa của các bộ dữ liệu được sử dụng không quá 4k, phù hợp với hầu hết các LLM phổ biến, chúng tôi vẫn muốn khám phá liệu phương pháp được đề xuất có bổ sung cho các mô hình mở rộng độ dài này hay không. Ở đây, chúng tôi sử dụng ba LLM phổ biến với cửa sổ ngữ cảnh lớn, tức là "longlora-8k"⁷, ChatGPT-16k (phiên bản "gpt-3.5-turbo-16k-0613") và GPT-4o⁸ để xác minh tính hiệu quả của khung được đề xuất của chúng tôi. Để đảm bảo chất lượng của bộ nhớ được tạo ra, chúng tôi sử dụng ChatGPT "gpt-3.5-turbo-0301" làm bộ lặp bộ nhớ, và chỉ áp dụng các LLM ngữ cảnh dài trên để hoàn thành việc tạo phản hồi dựa trên bộ nhớ. Từ kết quả trong Bảng 9, chúng tôi kết luận rằng: 1) Tăng độ dài ngữ cảnh tối đa của LLM thực sự tăng cường khả năng dài hạn của đối thoại, với những cải thiện rõ ràng về tính mạch lạc và nhất quán, ngay cả khi độ dài đầu vào nhỏ hơn nhiều so với cửa sổ ngữ cảnh. 2) Ngay cả khi độ dài đầu vào không vượt quá kích thước cửa sổ, việc áp dụng phương pháp của chúng tôi cho LLM vẫn là một cách hiệu quả để nhớ lại thông tin và duy trì kết nối dài hạn. 3) Với LLM mạnh hơn làm nền tảng (ví dụ: GPT-4o > ChatGPT > longloRA), mô hình đạt được hiệu suất tốt hơn sau khi được tăng cường của chúng tôi. Chúng tôi giải thích rằng các bản tóm tắt đệ quy của chúng tôi giúp tổ chức lại và tiêu hóa thông tin trong quá khứ một cách hiệu quả, do đó tăng cường hiểu biết về ngữ nghĩa trong các cuộc hội thoại tầm xa.

7. Kết luận

Trong bài báo này, chúng tôi đề xuất một chiến lược đơn giản và hiệu quả bằng cách tóm tắt đệ quy để cải thiện khả năng đối thoại dài hạn trong LLM. Kết quả thực nghiệm cho thấy bộ nhớ được tạo ra của chúng tôi có thể mô hình hóa các phụ thuộc dài hạn và nhắc nhở LLM tạo ra các phản hồi có tính nhất quán cao. Phân tích bổ sung cho thấy rằng phương pháp này mạnh mẽ trên các LLM khác nhau và có thể được tăng cường thêm trong các tình huống few-shot. Quan trọng, phương pháp của chúng tôi cũng thể hiện tính bổ sung mạnh mẽ cho cả các mô hình dựa trên truy xuất phổ biến và ngữ cảnh dài.

⁷https://huggingface.co/Yukang/Llama-2-7b-longlora-8k
⁸https://openai.com/index/hello-gpt-4o/

--- TRANG 28 ---
Hạn chế. Một trong những hạn chế chính của phương pháp chúng tôi là nó không tính đến chi phí liên quan đến việc gọi các mô hình lớn. Đây là một yếu tố quan trọng không thể bỏ qua trong các ứng dụng thực tế, nơi tài nguyên tính toán và chi phí liên quan thường là một ràng buộc. Bên cạnh đó, trong khi bộ nhớ được tạo ra của chúng tôi hiệu quả, đôi khi nó gặp các lỗi thực tế nhỏ. Những sự không chính xác này, mặc dù ít, làm nổi bật một lĩnh vực cần cải thiện có thể được giải quyết trong nghiên cứu tương lai.

Công việc tương lai. Một hướng đầy hứa hẹn cho công việc tương lai là khám phá tính hiệu quả của phương pháp chúng tôi trong việc mô hình hóa các nhiệm vụ ngữ cảnh dài ngoài đối thoại, như tạo ra câu chuyện. Việc điều tra mức độ tốt của phương pháp chúng tôi trong việc xử lý các loại nhiệm vụ ngữ cảnh dài khác nhau sẽ cung cấp hiểu biết sâu sắc hơn về tính linh hoạt và ứng dụng tiềm năng của nó. Một hướng khác cho nghiên cứu tương lai là tối ưu hóa hiệu suất của phương pháp tóm tắt của chúng tôi bằng cách sử dụng LLM được tinh chỉnh có giám sát cục bộ. Phương pháp này có thể giảm sự phụ thuộc vào các API trực tuyến đắt tiền, làm cho phương pháp dễ tiếp cận và hiệu quả về chi phí hơn cho việc sử dụng rộng rãi.

8. Lời cảm ơn

Công trình này được hỗ trợ bởi Quỹ Khoa học Tự nhiên Quốc gia Trung Quốc (Số U2336202).

--- TRANG 29 ---
Phụ lục A. Thống kê bộ dữ liệu

Thống kê của MSC và Carecall được thể hiện trong Bảng A.10 và Bảng A.11. ID phiên i cho biết có i-1 phiên hội thoại lịch sử đã xảy ra trước phiên cuối cùng. "#Ave. Tokens" và "#Max. Tokens" đề cập đến số lượng token trung bình và tối đa của các đối thoại, tương ứng.

Bảng A.10: Thống kê của Bộ dữ liệu MSC.

[THIS IS TABLE:
Session ID | #Dialog | #Response | #Ave. Tokens | #Max. Tokens
Session 2  | 501     | 5,939     | 444.84       | 951
Session 3  | 501     | 5,924     | 810.19       | 1733
Session 4  | 501     | 5,940     | 1195.08      | 2234
Session 5  | 501     | 5,945     | 1598.78      | 2613]

Bảng A.11: Thống kê của Bộ dữ liệu Carecall.

[THIS IS TABLE:
Session ID | #Dialog | #Response | #Ave. Tokens | #Max. Tokens
Session 2  | 2798    | 7826      | 285.03       | 692
Session 3  | 743     | 7693      | 459.63       | 1093
Session 4  | 674     | 7065      | 636.55       | 1418
Session 5  | 638     | 6553      | 809.45       | 1744]

Phụ lục B. Thiết kế lời nhắc

Dưới đây là tất cả các lời nhắc được sử dụng trong thí nghiệm của chúng tôi:

• LLM chỉ dùng ngữ cảnh (Llama-7B, ChatGLM-6B, và ChatGPT): Bảng B.12
• LLM dựa trên truy xuất (ChatGPT-BM25 & ChatGPT-DPR): Bảng B.13

--- TRANG 30 ---
• LLM dựa trên truy xuất được tăng cường bằng khung của chúng tôi (ChatGPT-BM25 + Khung của chúng tôi & ChatGPT-DPR + Khung của chúng tôi): Bảng B.14

• Phương pháp của chúng tôi được tăng cường bằng học trong ngữ cảnh (Lấy one-shot làm ví dụ): Bảng B.15

• Đánh giá LLM: Bảng B.16 và Bảng B.17

Bảng B.12: Lời nhắc cho LLM chỉ dùng ngữ cảnh.

[THIS IS TABLE:
Lời nhắc
Bạn là một mô hình ngôn ngữ AI tiên tiến có khả năng tham gia vào các cuộc hội thoại dựa trên tính cách. Phản hồi cho người dùng dựa trên ngữ cảnh đối thoại được cung cấp. Tạo ra phản hồi tự nhiên và đàm thoại.

Ngữ cảnh đối thoại: [dialog]
Phản hồi cho người dùng là:
Đầu ra [response]]

Bảng B.13: Lời nhắc cho LLM dựa trên truy xuất.

[THIS IS TABLE:
Lời nhắc
Bạn là một AI tiên tiến được thiết kế để tham gia vào các cuộc hội thoại tự nhiên, dựa trên tính cách. Bạn sẽ được cung cấp bộ nhớ đối thoại, ngữ cảnh lịch sử liên quan và ngữ cảnh đối thoại. Bộ nhớ đối thoại chứa tính cách, sở thích và kinh nghiệm của những người nói (người dùng và trợ lý). Khi phản hồi, hãy xem xét duy trì giọng điệu đàm thoại và trôi chảy. Các phản hồi nên liên quan đến ngữ cảnh và nhằm duy trì dòng chảy cuộc hội thoại.

Ngữ cảnh liên quan: [retrieved utterances]. Ngữ cảnh đối thoại: [dialog].
Vậy phản hồi cho người dùng là:
Đầu ra [response]]

--- TRANG 31 ---
Bảng B.14: Lời nhắc cho LLM dựa trên truy xuất được tăng cường bằng khung của chúng tôi.

[THIS IS TABLE:
Lời nhắc
Bạn là một AI tiên tiến được thiết kế để tham gia vào các cuộc hội thoại tự nhiên, dựa trên tính cách. Bạn sẽ được cung cấp bộ nhớ đối thoại, ngữ cảnh lịch sử liên quan và ngữ cảnh đối thoại. Bộ nhớ đối thoại chứa tính cách, sở thích và kinh nghiệm của những người nói (trợ lý và người dùng). Khi phản hồi, hãy xem xét duy trì giọng điệu đàm thoại và trôi chảy. Các phản hồi nên liên quan đến ngữ cảnh và nhằm duy trì dòng chảy cuộc hội thoại.

Ngữ cảnh liên quan: [retrieval utterances]
Bộ nhớ: [latest memory]
Đối thoại: [current context]
Đầu ra [response]]

Bảng B.15: Lời nhắc cho phương pháp của chúng tôi với học trong ngữ cảnh.

[THIS IS TABLE:
Lời nhắc
Bạn là một AI tiên tiến được thiết kế để tham gia vào các cuộc hội thoại tự nhiên, dựa trên tính cách. Bạn sẽ được cung cấp một bộ nhớ, chứa sở thích cá nhân và kinh nghiệm của những người nói (trợ lý và người dùng), cũng như một ngữ cảnh đối thoại. Khi phản hồi, hãy xem xét duy trì giọng điệu đàm thoại và trôi chảy. Các phản hồi nên liên quan đến ngữ cảnh, nhất quán với bộ nhớ đã cho, nhằm duy trì dòng chảy cuộc hội thoại. Mục tiêu của bạn là cung cấp các phản hồi hấp dẫn và mạch lạc dựa trên ngữ cảnh đối thoại được cung cấp. Để giúp bạn hiểu nhiệm vụ này, chúng tôi cung cấp 1 ví dụ dưới đây.

VÍ DỤ 1: Bộ nhớ ví dụ là:
Người dùng: - Đã ly hôn - Nuôi một đứa con - Nhập cư từ Anh năm ngoái - Thợ làm kim loại
Trợ lý: - Chưa kết hôn - Bạn gái có 2 con - Làm việc trên mTurk, cảnh quan, bán hàng, nhét phong bì, sơn - Từng yêu mùa đông, nhưng đã trở nên không chịu được nó - Làm việc với một người bạn sở hữu "John of all trades"

Ngữ cảnh đối thoại ví dụ là:
Người dùng: Hôm nay là ngày nóng nhất tôi từng trải qua ở Florida!
Vậy phản hồi cho người dùng là: bạn có thích sức nóng hơn cái lạnh ở Anh không?

Dưới đây là trường hợp bạn cần kiểm tra: Bộ nhớ thử nghiệm là: [previous memory]
Ngữ cảnh đối thoại thử nghiệm là: [dialog] Vậy phản hồi cho người dùng là:
Đầu ra [response]]

--- TRANG 32 ---
Bảng B.16: Lời nhắc cho đánh giá mô hình đơn.

Lời nhắc
Bạn là một thẩm phán công bằng. Bạn sẽ được hiển thị Ngữ cảnh cuộc hội thoại, Tính cách của những người nói và Phản hồi của trợ lý.

#Trôi chảy: Vui lòng đánh giá liệu phản hồi của Trợ lý có tự nhiên, trôi chảy và tương tự như giao tiếp của con người hay không, tránh lặp lại và đảm bảo đa dạng đầu ra.

#Nhất quán: Vui lòng đánh giá liệu phản hồi của Trợ lý có nhất quán với thông tin trong danh sách tính cách hay không. Bất kỳ sự sai lệch nào so với tính cách mong đợi có thể cho thấy thiếu tính mạch lạc.

#Mạch lạc: Vui lòng đánh giá liệu phản hồi của Trợ lý có duy trì dòng chảy mạch lạc và logic của cuộc hội thoại dựa trên ngữ cảnh đang phát triển hay không. Phản hồi có tính mạch lạc ngữ cảnh tốt có thể hiểu và phản hồi phù hợp với những thay đổi trong chủ đề cuộc hội thoại, cung cấp các tương tác mượt mà và hợp lý.

Ngữ cảnh cuộc hội thoại: [dialog] Tính cách: [persona] Phản hồi của trợ lý: [response]

Bắt đầu đánh giá của bạn bằng cách cung cấp một lời giải thích ngắn, sau đó bạn phải đánh giá Phản hồi của trợ lý trên thang điểm số nguyên từ 1 (rất tệ) đến 100 (rất tốt) bằng cách tuân thủ nghiêm ngặt định dạng này: [[score]].

Đầu ra [output]

--- TRANG 33 ---
Bảng B.17: Lời nhắc của đánh giá mô hình theo cặp.

Lời nhắc
Xin chào! Chúng tôi là một nhóm các nhà nghiên cứu đang làm việc về Trí tuệ nhân tạo. Trong nhiệm vụ này, chúng tôi sẽ yêu cầu bạn giúp chúng tôi đánh giá các phản hồi của trợ lý. Trong khu vực dưới đây, đầu tiên bạn sẽ đọc:

1. Ngữ cảnh cuộc hội thoại đến từ hai người nói (người dùng và bot)
2. Tính cách của hai người nói (người dùng và bot) được trích xuất từ các đối thoại trong quá khứ.
3. Hai phản hồi từ các hệ thống AI. Nhiệm vụ của bạn là quyết định phản hồi nào tốt hơn. Có một số khía cạnh mà bạn có thể suy nghĩ. Hãy xem xét các câu hỏi sau:

1. Phản hồi có mạch lạc không? Phản hồi có tính mạch lạc ngữ cảnh tốt có thể hiểu và phản hồi phù hợp với những thay đổi trong chủ đề cuộc hội thoại, cung cấp các tương tác mượt mà và hợp lý.

2. Phản hồi có nhất quán không? Đánh giá liệu phản hồi có nhất quán với thông tin trong danh sách tính cách hay không. Bất kỳ sự sai lệch nào so với tính cách mong đợi có thể cho thấy thiếu tính nhất quán.

3. Phản hồi có tự nhiên và trôi chảy không? Vui lòng đánh giá liệu phản hồi có tự nhiên, trôi chảy và tương tự như giao tiếp của con người hay không, tránh lặp lại quá mức và đảm bảo đa dạng đầu ra.

Dựa trên thẩm mỹ của bạn, bạn thích cái nào hơn? Ví dụ, bạn có thể thích một bài thơ hơn một bài thơ khác. Cuối cùng, bạn nên quyết định phản hồi nào tốt hơn dựa trên phán đoán và sở thích của riêng bạn. Có bốn lựa chọn để bạn chọn:

1. Phản hồi 1 tốt hơn: Nếu bạn nghĩ phản hồi 1 có lợi thế, thì chọn lựa chọn này.
2. Phản hồi 1 hơi tốt hơn: Phản hồi 1 tốt hơn phản hồi 2 một cách rất nhỏ và sự khác biệt là nhỏ.
3. Phản hồi 2 hơi tốt hơn: Phản hồi 2 tốt hơn phản hồi 1 một cách rất nhỏ và sự khác biệt là nhỏ.
4. Phản hồi 2 tốt hơn: Nếu bạn nghĩ phản hồi 2 có lợi thế, thì chọn lựa chọn này.

Có những trường hợp mà sự khác biệt giữa hai phản hồi không rõ ràng. Trong trường hợp này, bạn có thể chọn lựa chọn thứ hai hoặc thứ ba. Tuy nhiên, nói chung, chúng tôi yêu cầu bạn chọn những lựa chọn đó càng ít càng tốt.

phản hồi 1: [response1] phản hồi 2: [response2]
Đầu ra [response]

--- TRANG 34 ---
Tài liệu tham khảo

[The references section continues with academic citations in Vietnamese translation, maintaining the same format as the original but translated to Vietnamese. The references include works by Achiam et al., An et al., Bae et al., Beltagy et al., Brown et al., Chen et al., and others, with Vietnamese translations of titles and publication details.]

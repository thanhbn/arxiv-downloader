# Cắt Giảm Token Động trong Vision Transformers Thuần Túy
cho Phân Đoạn Ngữ Nghĩa

Quan Tang1*Bowen Zhang2*Jiajun Liu3Fagui Liu1†Yifan Liu2†
1Đại học Công nghệ Nam Trung Quốc2Đại học Adelaide3CSIRO

Tóm tắt
Vision transformers đã đạt được hiệu suất hàng đầu
trên các tác vụ thị giác khác nhau nhưng vẫn chịu độ phức tạp
tính toán cao. Tình hình trở nên tồi tệ hơn trong các tác vụ dự đoán
dày đặc như phân đoạn ngữ nghĩa, vì đầu vào và đầu ra có độ phân giải
cao thường có nghĩa là nhiều token tham gia vào
tính toán. Việc loại bỏ trực tiếp các token ít chú ý
đã được thảo luận cho tác vụ phân loại hình ảnh nhưng không
thể mở rộng cho phân đoạn ngữ nghĩa vì cần dự đoán dày đặc
cho mọi patch. Để giải quyết vấn đề này, công trình này
giới thiệu phương pháp Cắt Giảm Token Động (DToP) dựa
trên thoát sớm của token cho phân đoạn ngữ nghĩa. Được
thúc đẩy bởi quá trình phân đoạn thô-đến-tinh của con người, chúng tôi
tự nhiên chia kiến trúc mạng dựa trên auxiliary-loss
được áp dụng rộng rãi thành nhiều giai đoạn, nơi mỗi
khối auxiliary đánh giá mức độ khó khăn của từng token. Chúng tôi
có thể hoàn thiện dự đoán của các token dễ trước mà
không cần hoàn thành toàn bộ lượt truyền xuôi. Hơn nữa, chúng tôi giữ
k token có độ tin cậy cao nhất cho mỗi danh mục ngữ nghĩa để
duy trì thông tin ngữ cảnh đại diện. Do đó, độ phức tạp
tính toán sẽ thay đổi theo độ khó khăn của đầu vào,
tương tự như cách con người thực hiện phân đoạn. Các thí nghiệm
cho thấy kiến trúc DToP được đề xuất giảm
trung bình 20%∼35% chi phí tính toán cho các
phương pháp phân đoạn ngữ nghĩa hiện tại dựa trên vision transformers
thuần túy mà không làm giảm độ chính xác.

1. Giới thiệu
Transformer [20] là một phát minh đáng chú ý bởi
khả năng đặc biệt trong việc mô hình hóa các phụ thuộc tầm xa
trong xử lý ngôn ngữ tự nhiên. Nó đã được mở rộng
cho các ứng dụng thị giác máy tính và được gọi là Vision Transformer (ViT), bằng cách coi mỗi patch hình ảnh như
một token [7]. Nhờ vào cơ chế multi-head self-attention
toàn cục, các kết quả cạnh tranh đã đạt được trên nhiều
tác vụ thị giác khác nhau, ví dụ phân loại hình ảnh [7, 26], phát hiện đối
tượng [3, 31] và phân đoạn ngữ nghĩa [5, 6, 27].
Tuy nhiên, chi phí tính toán nặng vẫn cản trở việc ứng dụng
rộng rãi, đặc biệt trong các môi trường hạn chế tài nguyên. Trong phân đoạn ngữ nghĩa, tình hình trở nên
tồi tệ hơn vì hình ảnh có độ phân giải cao tạo ra nhiều token
đầu vào. Do đó, việc thiết kế lại các kiến trúc nhẹ hoặc
giảm chi phí tính toán cho ViT đã thu hút nhiều
sự chú ý nghiên cứu.

Vì độ phức tạp tính toán của vision transformers
tỷ lệ bậc hai với số lượng token, việc giảm độ lớn
của nó là con đường trực tiếp để giảm bớt gánh nặng tính toán.
Đã có một loạt công trình nghiên cứu các kỹ thuật thuyết phục
của cắt giảm token liên quan đến tác vụ phân loại hình ảnh.
Ví dụ, DynamicViT [18] xác định các token được giữ lại bằng cách sử dụng xác suất dự đoán bởi các mạng con phụ, và
EViT [13] tổ chức lại các token không chú ý bằng cách tính toán mức độ
liên quan của chúng với token [cls]. Tuy nhiên, việc loại bỏ các
token, ngay cả khi chúng không chú ý, không thể mở rộng trực tiếp
cho phân đoạn ngữ nghĩa vì cần dự đoán dày đặc
cho mọi patch hình ảnh. Gần đây nhất, Liang et
al. [12] đề xuất một lớp tái tạo token để xây dựng lại
các token được gom cụm để giải quyết vấn đề.

Trong công trình này, một góc nhìn mới được áp dụng và thoát khỏi
chu kỳ gom cụm hoặc tái tạo token. Được thúc đẩy bởi
quá trình phân đoạn thô-đến-tinh và dễ-đến-khó của con người, chúng tôi
dần dần phân loại token theo mức độ khó khăn tại
mỗi giai đoạn. Do đó, đối với các token dễ, dự đoán của chúng có thể
được hoàn thiện trong các lớp rất sớm và quá trình truyền xuôi
của chúng có thể được dừng sớm. Kết quả là, chỉ các token khó
được xử lý trong các lớp tiếp theo. Chúng tôi gọi quá trình này
là thoát sớm của token. Hình 1 đưa ra minh họa.
Phần thân chính của các đối tượng tương đối lớn hơn trong hình ảnh
được nhận diện đầu tiên và quá trình của chúng được dừng, trong khi các lớp
sâu hơn dần dần xử lý những vùng biên khó khăn và gây nhầm lẫn
và các đối tượng nhỏ hơn. Những dự đoán từ quá trình
thoát sớm theo giai đoạn này có thể được sử dụng cùng với
những dự đoán từ suy luận hoàn chỉnh. Vì cả hai
đầu ra sau đó cùng tạo thành kết quả cuối cùng, nó không yêu cầu
thao tác tái tạo token và tạo ra một hình thức
ViT hiệu quả đơn giản nhưng hiệu quả cho phân đoạn.

Công trình này giới thiệu một mô hình Cắt Giảm Token Động
(DToP) mới trong vision transformers thuần túy cho phân
đoạn ngữ nghĩa. Cho rằng auxiliary losses [28, 29] được
áp dụng rộng rãi, DToP chia một transformer thành các giai đoạn sử
dụng các khối auxiliary vốn có mà không giới thiệu thêm
module và tính toán. Trong khi các công trình trước đó loại bỏ
dự đoán auxiliary một cách bất chấp, chúng tôi tận dụng tốt
chúng để phân loại mức độ khó khăn của tất cả token. Trực giác của
thiết kế như vậy nằm ở độ khó nhận diện khác nhau
của các patch hình ảnh được đại diện bởi từng token. Các token dễ
được dừng và cắt giảm sớm trong ViT, trong khi
các token khó được giữ lại để tính toán trong các lớp
tiếp theo. Chúng tôi lưu ý rằng việc có quan sát này và chuyển từ
kiến trúc dựa trên auxiliary-loss sang DToP để giảm
token là một đóng góp không tầm thường. Một tình huống có thể
tồn tại khi các đối tượng chỉ bao gồm các token cực kỳ dễ,
ví dụ bầu trời. Kết quả là, DToP hoàn toàn loại bỏ token từ
các danh mục dễ nhận diện trong các lớp sớm, và điều này gây ra
mất mát nghiêm trọng thông tin ngữ cảnh cho số ít token
còn lại trong tính toán của chúng. Để tận dụng đầy đủ sự
phụ thuộc đặc trưng giữa các lớp và duy trì thông tin ngữ
cảnh đại diện, chúng tôi giữ k token có độ tin cậy cao nhất cho
mỗi danh mục ngữ nghĩa trong mỗi quá trình cắt giảm.

Các đóng góp được tóm tắt như sau:
• Chúng tôi giới thiệu một mô hình cắt giảm token động dựa
trên thoát sớm của các token dễ nhận diện cho
transformers phân đoạn ngữ nghĩa. Các token dễ được hoàn thiện tại các lớp trung gian được cắt giảm khỏi phần còn lại
của tính toán, và các token khác được giữ lại để tiếp tục
xử lý.
• Chúng tôi duy trì thông tin ngữ cảnh bằng cách giữ lại k
token có độ tin cậy cao nhất cho mỗi danh mục ngữ nghĩa cho
tính toán tiếp theo, điều này cải thiện hiệu suất phân
đoạn bằng cách đảm bảo rằng đủ thông tin ngữ cảnh có sẵn
ngay cả trong các trường hợp cực kỳ dễ.
• Chúng tôi áp dụng DToP cho các transformers phân đoạn ngữ
nghĩa chính và tiến hành các thí nghiệm mở rộng
trên ba benchmark đầy thử thách. Kết quả cho thấy rằng
DToP có thể giảm lên đến 35% chi phí tính toán mà không
có sự sụt giảm độ chính xác đáng chú ý.

2. Công trình liên quan

2.1. Transformers Phân đoạn Ngữ nghĩa
Phân đoạn ngữ nghĩa gán cho mỗi pixel một danh mục
ngữ nghĩa được định nghĩa trước nhằm mục đích phân tích hình ảnh
ở mức pixel. Trong thập kỷ qua, các kỹ thuật học sâu đã
hỗ trợ đáng kể sự phát triển của các phương pháp phân đoạn
ngữ nghĩa. Vision transformers [7, 27] hiện đảm nhận
baton để tiếp tục thúc đẩy lĩnh vực này sau thành công
lớn của mạng nơ-ron tích chập [8, 14].
ViT [7] điều chỉnh kiến trúc Transformer [20] chuẩn
cho thị giác máy tính với ít sửa đổi nhất có thể,
điều này đạt được kết quả cạnh tranh và truyền cảm hứng cho các phương
pháp gần đây. SETR [29] đầu tiên sử dụng ViT như một encoder và
kết hợp một decoder tích chập, đạt được hiệu suất
ấn tượng trên các benchmark phân đoạn ngữ nghĩa. SegFormer [22] vượt ra ngoài kiến trúc thuần túy và giới
thiệu các đặc trưng pyramid để thu được ngữ cảnh đa
tỷ lệ. Segmenter [19] sử dụng các token lớp có thể học
cũng như đầu ra của encoder để dự đoán mask phân đoạn,
điều này phụ thuộc vào dữ liệu. SegViT [27] tiếp tục khám phá khả
năng của cơ chế self-attention quan trọng và đề xuất
một module attention-to-mask mới để tạo ra các mask
phân đoạn chính xác một cách động. Trong phân đoạn ngữ nghĩa,
hình ảnh có độ phân giải cao thường có nghĩa là một số lượng lớn
token. Độ phức tạp tính toán cao đi kèm trong vision
transformers có thể bị đổ lỗi cho các ứng dụng hạn chế
của chúng.

2.2. Giảm Token
Vì độ phức tạp tính toán của vision transformers
tỷ lệ bậc hai với độ dài của chuỗi đầu vào, việc giảm
số lượng token có vẻ đơn giản để giảm chi
phí tính toán. DynamicViT [18] quan sát rằng một phân loại hình ảnh
chính xác có thể đạt được bởi một tập hợp con của các token
thông tin nhất và đề xuất một framework đặc tả
token động. EViT [13] chứng minh rằng không phải tất cả token đều chú ý trong multi-head self-attention và tổ chức lại
chúng dựa trên điểm chú ý với token [cls]. A-ViT [23] tính toán điểm dừng cho mỗi token
sử dụng tham số mạng gốc và dành tính toán
chỉ cho các token phân biệt.

Những phương pháp giảm token này được thiết kế cẩn thận
cho phân loại hình ảnh dựa trên trực giác rằng việc loại bỏ
các token không thông tin (ví dụ: nền) tạo ra tác động
tiêu cực nhỏ đối với nhận diện cuối cùng. Tuy nhiên, mọi thứ
thay đổi trong phân đoạn ngữ nghĩa vì chúng ta được cho là
đưa ra dự đoán trên tất cả các patch hình ảnh. Liang et al. [12] phát
triển các lớp gom cụm/tái tạo token để giảm số
lượng token ở các lớp giữa và tăng số lượng
trước dự đoán cuối cùng. Lu et al. [16] giới thiệu một policynet
phụ trợ trước các lớp transformer để hướng dẫn thao tác
gộp token trong các vùng có nội dung tương tự. SparseViT [4] giới thiệu một quy trình cắt giảm trên Swin Transformer
cho các tác vụ dự đoán dày đặc. Khác biệt, chúng tôi thực hiện giảm token bằng cách hoàn thiện dự đoán của các token dễ tại
các lớp trung gian và dành tính toán chỉ cho các token khó
một cách động.

2.3. So sánh với Các Công trình Trước
Trong phân loại hình ảnh, DVT [21] xác định độ chi tiết
của patch embedding và tạo ra số lượng token khác nhau
dựa trên độ khó nhận diện khác nhau ở mức hình ảnh. Các hình ảnh dễ có thể được dự đoán chính xác với
số lượng token ít, và những hình khó cần một biểu diễn
tinh hơn. Đi một bước xa hơn, chúng tôi dựa DToP trên giả
định rằng các patch hình ảnh với nội dung khác nhau được đại
diện bởi token có độ khó nhận diện khác nhau trong phân
đoạn ngữ nghĩa. Chúng tôi có thể dừng các token dễ và dành
chỉ các token khó cho tính toán tiếp theo bằng cách đưa ra dự đoán
sớm qua các khối auxiliary tại các lớp trung gian. Vì
chúng tôi trực tiếp kết hợp các dự đoán sớm cho các token dễ để
tạo thành kết quả nhận diện cuối cùng, DToP không mất
thông tin trong quá trình giảm token và do đó không yêu cầu
thao tác tái tạo token, so với phương pháp được
đề xuất bởi Liang et al. [12].

DToP cũng được truyền cảm hứng từ deep layer cascade
(LC) [11] nhưng sở hữu hai đặc điểm độc đáo sau. Thứ nhất, DToP áp dụng cho vision transformers thuần túy và
LC mạng nơ-ron tích chập pyramid. Các tính chất kiến trúc
hấp dẫn của vision transformers cho phép DToP
giảm chi phí tính toán mà không sửa đổi kiến trúc mạng
hoặc toán tử, trong khi LC yêu cầu tích chập vùng cụ thể.
Thứ hai, DToP giữ k token có độ tin cậy cao nhất cho mỗi danh mục ngữ nghĩa cho tính toán
tiếp theo, điều này ngăn danh mục dễ dừng sớm,
đóng góp vào việc khai thác hiệu quả thông tin ngữ cảnh.

3. Phương pháp
Công trình này giới thiệu phương pháp Cắt Giảm Token Động
dựa trên thoát sớm của token, điều này thúc đẩy vision
transformers thuần túy cho phân đoạn ngữ nghĩa. Chúng tôi chi tiết
mô hình này trong phần này.

3.1. Kiến thức cơ bản
Một vision transformer [7] thông thường chia một hình ảnh
X∈R3×H×W thành các patch khác nhau. Sau đó chúng ta có được một
chuỗi HW/P²×C qua patch embedding. H và W đại
diện cho độ phân giải hình ảnh, P là kích thước patch và C là
chiều đặc trưng. Gọi N=HW/P² là độ dài của chuỗi
đầu vào, tức là số lượng token. Vision transformers
không phụ thuộc vào vị trí, và chúng ta thường thêm mã hóa
vị trí để biểu diễn thông tin không gian của mỗi token.
Chuỗi kết quả được ký hiệu là Z⁰∈R^(N×C), điều này
phục vụ như đầu vào.

Vision transformers thường được phát triển từ các đơn vị
lặp lại chứa một module multi-head self-attention (MHSA)
và một mạng feed-forward (FFN). Layer normalization
(LN) [1] và kết nối dư (residual connection) [8] được sử dụng trong
các đơn vị như vậy. Chúng tôi gọi một đơn vị là một lớp được chỉ mục bởi
l∈{1,2,...,L}, và đầu ra của mỗi lớp được đánh dấu
là Z^l.

Z'ˡ=MHSA(LN(Z^(l-1))) + Z^(l-1),
Zˡ=FFN(LN(Z'ˡ)) + Z'ˡ. (1)

Lưu ý rằng FFN bao gồm một hàm kích hoạt phi tuyến, ví dụ
GeLU [9].

3.2. Cắt Giảm Token Động
Vì một token là biểu diễn tự nhiên của một patch hình ảnh,
chúng ta có thể hoàn thiện dự đoán cho các token dễ trước
mà không cần tính toán truyền xuôi hoàn chỉnh bằng cách
bắt chước quá trình phân đoạn của con người. Chúng tôi gọi
nó là thoát sớm của token, nơi các token dễ được dừng
và cắt giảm trong các giai đoạn sớm trong khi các token khó được bảo tồn
để tính toán ở các giai đoạn sau. Bằng cách làm như vậy, ít token hơn
được xử lý trong các lớp tiếp theo, giảm đáng kể
chi phí tính toán.

Như được hiển thị trong Hình 2, chúng tôi chia một backbone vision transformer thuần túy thành M giai đoạn sử dụng các khối auxiliary
vốn có H^m (m∈{1,2,...,M}) ở cuối mỗi giai đoạn.
Gọi P^m∈R^(N×K) đại diện cho kết quả dự đoán ở giai đoạn thứ m,
nơi K là số lượng danh mục ngữ nghĩa. Giả sử rằng các token đã hoàn thành l_m lớp truyền xuôi
tại thời điểm này, thì:

P^m=H^m(Z^(l_m)). (2)

p_(m,n) đến từ P^m là xác suất dự đoán tối đa
của token thứ n. Các công trình trước áp dụng P^m để tính
auxiliary losses trong quá trình huấn luyện và loại bỏ chúng bất chấp trong quá trình suy luận. Công trình này nhấn mạnh rằng các token dễ có thể được phân loại chính xác với độ tin cậy dự đoán
cao trong những đầu ra auxiliary này (tức là P^m). DToP được đề xuất
mong đợi khám phá đầy đủ khả năng tiềm ẩn của chúng để phân biệt
các token dễ và khó trong cả quá trình huấn luyện và suy luận.

Được truyền cảm hứng từ [10], chúng tôi phân loại tất cả mức độ khó khăn
của token sử dụng P^m dựa trên một tiêu chí đơn giản. Giả sử một ngưỡng
tin cậy lớn p₀, ví dụ 0.9. Các token dễ được phân loại với
điểm số cao hơn 90%, trong khi các token khó được phân loại với
điểm số thấp hơn. Vì dự đoán tin cậy cho các token dễ
được thu được, chúng tôi cắt giảm chúng và dừng quá trình truyền xuôi
tiếp tục của chúng. Các token khó được dành lại trong tính toán
trong các lớp tiếp theo để đạt được dự đoán đáng tin cậy. Nói cách khác,
chúng tôi cắt giảm token thứ n trong Z^(l_m) nếu p_(m,n)≥p₀,
ngược lại chúng tôi giữ nó. Sau khi truyền một hình ảnh qua
toàn bộ mạng, chúng tôi kết hợp các nhãn token dự đoán
từ mỗi giai đoạn để tạo thành kết quả cuối cùng.

3.3. Khối Auxiliary Matching Query
Trong framework DToP, khối auxiliary để
phân loại tất cả mức độ khó khăn của token nên tuân theo hai nguyên
tắc: có khả năng ước tính chính xác mức độ khó khăn của token
và với kiến trúc nhẹ. Do đó, chúng tôi lấy
module attention-to-mask (ATM) [27] gần đây nhất để
đạt được mục tiêu này. Cụ thể, một loạt các token lớp có thể học
trao đổi thông tin với các đặc trưng encoder sử
dụng một transformer decoder. Các token lớp đầu ra được sử dụng
để có được dự đoán xác suất lớp. Điểm attention liên
quan đến mỗi token lớp được sử dụng để tạo thành một nhóm mask. Tích
vô hướng giữa xác suất lớp và nhóm mask
tạo ra dự đoán cuối cùng.

Hai sửa đổi được thực hiện để điều chỉnh ATM vào framework
DToP. Thứ nhất, chúng tôi giảm số lượng lớp trong ATM vì chúng tôi
quan sát không có nhiễu loạn hiệu suất đáng kể trong
framework DToP với cài đặt gốc, điều này cũng
đảm bảo chi phí tính toán thấp. Thứ hai, chúng tôi
tách các module ATM cascaded và sử dụng chúng như
các head phân đoạn auxiliary riêng biệt, mỗi cái với các token lớp có thể học
riêng lẻ. Chúng tôi lưu ý rằng chúng tôi lấy module ATM mạnh mẽ
để phân loại tất cả mức độ khó khăn của token như một ví
dụ, vì một ước tính đáng tin cậy về độ khó phân đoạn
của token có thể dẫn đến sự cân bằng độ chính xác-tính toán tốt.

Bất kỳ head phân đoạn hiện có nào khác đều có cùng
hiệu ứng (xem [22, 28, 29] cho các ví dụ). Trong Phần 4, chúng tôi cũng
cung cấp các thí nghiệm với head FCN thông thường [15] để xác
nhận tính tổng quát của DToP.

3.4. Duy trì Thông tin Ngữ cảnh
Tồn tại các tình huống khi tất cả token của một danh mục ngữ nghĩa
cụ thể đều cực kỳ dễ nhận diện, ví dụ bầu trời. Những token như vậy có thể bị loại bỏ hoàn toàn trong các lớp sớm, dẫn đến
mất thông tin ngữ cảnh trong các lớp tính toán
tiếp theo. Các thực hành [24, 25] chỉ ra rằng việc khai thác đầy đủ
thông tin ngữ cảnh giữa các danh mục cải thiện
độ chính xác phân đoạn ngữ nghĩa tổng thể. Để đạt được mục tiêu này, chúng tôi
giữ k token có độ tin cậy cao nhất cho mỗi danh mục ngữ
nghĩa trong mỗi quá trình cắt giảm. Chỉ các danh mục
xuất hiện trong hình ảnh hiện tại được xem xét. Đối với một
danh mục ngữ nghĩa cụ thể, nếu số lượng token với
điểm số cao hơn p₀ nhiều hơn k, thì top-k của chúng
được giữ lại. Ngược lại, chúng tôi giữ số lượng thực tế của chúng.
Những token biết danh mục này tham gia vào tính toán cùng
với những token có độ tin cậy thấp khác, vì vậy thông tin ngữ nghĩa
của danh mục dễ được bảo tồn để trao đổi thông tin giữa các danh mục, dẫn đến phân đoạn ngữ nghĩa chính xác.

4. Thí nghiệm

4.1. Bộ dữ liệu và Metrics
ADE20K [30] là một bộ dữ liệu benchmark được áp dụng rộng rãi
cho phân đoạn ngữ nghĩa. Nó chứa khoảng 20k hình ảnh
để huấn luyện và 2k hình ảnh để validation. Tất cả hình ảnh được gán nhãn
với 150 danh mục ngữ nghĩa. Bộ dữ liệu COCO-Stuff-10K [2]
chứa 9k hình ảnh để huấn luyện và 1k hình ảnh để
kiểm tra. Theo [27], chúng tôi sử dụng 171 danh mục ngữ nghĩa cho
các thí nghiệm. Pascal Context [17] có tổng cộng 10,100 hình
ảnh, trong đó 4,996 hình ảnh để huấn luyện và 5,104 để
validation. Nó cung cấp gán nhãn pixel-wise cho 59 danh mục,
loại trừ nền.

Theo quy ước chung, chúng tôi sử dụng mean intersection over union (mIoU) để đánh giá độ chính xác phân đoạn
và số lượng float-point operations (FLOPs) để ước tính
độ phức tạp mô hình. Tính toán trong
DToP được phân bổ không đều giữa các mẫu dễ và khó
bằng cách cắt giảm số lượng token khác nhau. Do đó chúng tôi báo cáo
FLOPs trung bình trên toàn bộ bộ dữ liệu validation/test.

4.2. Chi tiết Triển khai
Chúng tôi áp dụng vision transformer thuần túy kết hợp
module ATM điều chỉnh như mô hình baseline, nơi các module ATM
hoạt động như các head auxiliary. Chúng tôi tuân theo các cài đặt huấn luyện
chuẩn trong mmsegmentation¹ và sử dụng cùng
hyperparameters như bài báo gốc. Tất cả điểm mIoU được báo cáo dựa trên đầu vào đơn tỷ lệ. k được đặt là 5 trong
công trình này. Vì việc thay đổi p₀ trong một phạm vi nhất định (0.90∼0.98)
trong quá trình huấn luyện dẫn đến kết quả tương tự, chúng tôi thực nghiệm cố định nó
là 0.95 cho tất cả quá trình huấn luyện trừ khi được chỉ định.

4.3. Nghiên cứu Ablation
Đầu tiên chúng tôi tiến hành các nghiên cứu ablation mở rộng với bộ dữ liệu
ADE20K [30] sử dụng ViT-Base [7] như backbone.

4.3.1 Tính cần thiết của Huấn luyện Mô hình
Việc sử dụng auxiliary heads để huấn luyện hiệu quả là một quy ước
phổ biến trong cộng đồng phân đoạn ngữ nghĩa, xem [5,
28, 29] cho các ví dụ. Nói chung, các đầu ra auxiliary được
loại bỏ tại thời điểm test. Vì DToP được đề xuất phân loại tất cả
mức độ khó khăn của token sử dụng các đầu ra auxiliary, chúng tôi có thể
áp dụng DToP cho các phương pháp hiện có ngay lập tức trong
quá trình suy luận. Do đó, chúng tôi xác minh tính cần thiết của việc huấn luyện lại
hoặc tinh chỉnh mô hình dưới framework DToP được đề xuất.
Chúng tôi ký hiệu DToP@Direct là việc áp dụng trực tiếp DToP cho
mô hình baseline trong quá trình suy luận. DToP@Finetune có nghĩa là
tinh chỉnh các head phân đoạn cho 40k lần lặp trên
mô hình baseline sử dụng DToP, và DToP@Retrain huấn luyện lại
toàn bộ mô hình sử dụng DToP cho 160k lần lặp.

Kết quả được hiển thị trong Bảng 1. Chúng tôi quan sát rằng tất cả ba
cài đặt giảm chi phí tính toán khoảng 20%, nơi
DToP@Direct và DToP@Retrain dẫn đến sự sụt giảm độ chính xác đáng kể
trong khi DToP@Finetune hoạt động hơi tốt hơn. Kết quả cho thấy rằng DToP@Finetune được đề xuất yêu
cầu chỉ một chút thời gian huấn luyện bổ sung nhưng giảm đáng kể
độ phức tạp tính toán trong khi duy trì độ
chính xác. Chúng tôi áp dụng cài đặt @Finetune trong các
thí nghiệm tiếp theo. Lưu ý rằng sự dao động nhẹ trong FLOPs của
ba lược đồ huấn luyện đến từ dự đoán khác nhau
của các head auxiliary trong các quá trình huấn luyện riêng lẻ.

4.3.2 Ablation cho Ngưỡng Tin cậy
Ngưỡng tin cậy p₀ là một hyperparameter quan trọng quyết định
số lượng token được cắt giảm trong mỗi quá trình cắt giảm
và trực tiếp ảnh hưởng đến sự cân bằng giữa chi phí tính toán
và độ chính xác. Kết quả định lượng được hiển thị trong Bảng 2.

Khi p₀= 1, mô hình thoái hóa thành kiến trúc baseline.
Khi p₀ giảm, nhiều token dễ hơn được cắt giảm cũng như
nhiều dự đoán sớm không đáng tin cậy hơn. Chúng tôi quan sát rằng
hiệu suất bão hòa tại p₀= 0.95 khi sử dụng ATM như
head phân đoạn.

Chúng tôi cũng xác minh giá trị sử dụng SETR [29] (với head phân đoạn
ngây thơ được mô tả trong FCN [15]) và hiển thị
kết quả trong Bảng 3. Chúng tôi quan sát rằng đối với head FCN p₀= 0.98
có thể là lựa chọn tốt hơn. Trong thực tế, giá trị có thể được chọn
thực nghiệm với một tập validation nhỏ. Chúng tôi cũng lưu ý rằng
đối với SETR, DToP@Direct đã có được điểm mIoU hứa hẹn
là 46.6% chỉ thấp hơn 0.4% so với baseline
nhưng với tính toán giảm đáng kể (~23.4%).
Một số ví dụ định tính về cách ngưỡng p₀ ảnh hưởng
đến số lượng token được cắt giảm và độ chính xác phân đoạn được
hiển thị trong Hình 3².

4.3.3 Khám phá về Vị trí Cắt giảm
Insight quan trọng của DToP là hoàn thiện dự đoán của
các token dễ trong các lớp trung gian và cắt giảm chúng trong
tính toán tiếp theo bằng cách phân loại tất cả mức độ khó khăn của token.
Do đó vị trí của các head auxiliary quan trọng. Nó ảnh hưởng đến
độ chính xác nhận diện của các token dễ được cắt giảm và sự cân bằng
giữa chi phí tính toán và độ chính xác phân đoạn.
Chúng tôi tiến hành khám phá về vị trí cắt giảm l_m và
hiển thị kết quả trong Bảng 4. Kết quả chứng minh rằng việc chia
backbone thành ba giai đoạn với cắt giảm token tại
lớp thứ 6 và thứ 8 đạt được sự cân bằng mong đợi giữa chi phí tính toán và độ chính xác phân đoạn. Chúng tôi áp dụng cài đặt này
trong tất cả các thí nghiệm khác và lưu ý rằng nó có thể không
tối ưu do các khám phá hạn chế.

4.3.4 Ablation cho Phương pháp Cắt giảm
Sau khi phân loại tất cả mức độ khó khăn của token tại giai đoạn hiện tại,
phương pháp cắt giảm cụ thể linh hoạt. Chúng tôi thí nghiệm với
bốn phương pháp cắt giảm token. Theo LC [11], chúng tôi loại
bỏ các token dễ trực tiếp mà không xem xét việc dừng
thông tin danh mục dễ. Ngược lại, công trình này giữ
k token có độ tin cậy cao nhất cho mỗi danh mục ngữ nghĩa xuất hiện để duy trì thông tin ngữ cảnh đại diện, được đánh dấu
là top-k. Một thay thế để duy trì thông tin ngữ cảnh là
trung bình tất cả giá trị token dễ thành một token cho mỗi danh
mục ngữ nghĩa. Chúng tôi cũng cắt giảm một tỷ lệ cố định của token bằng cách
loại bỏ top 35% token có độ tin cậy cao nhất để phân bổ đều tính toán giữa các hình ảnh. Kết quả được hiển thị trong
Bảng 5, nơi phương pháp top-k được đề xuất vượt trội hơn
các phương pháp khác với biên độ lớn, cho thấy tính hiệu quả của nó. Hơn
nữa, chúng tôi quan sát rằng các phương pháp duy trì thông tin ngữ cảnh,
tức là Average và top-k, vượt trội hơn các phương pháp khác.

4.3.5 Ảnh hưởng của Head Phân đoạn
Trong Bảng 6, chúng tôi xác minh các head phân đoạn khác nhau và
quan sát rằng DToP được đề xuất hoạt động hiệu quả trong cả
cài đặt ATM và FCN (hai phần đầu), cho thấy khả năng
áp dụng tổng quát của nó. Để đảm bảo so sánh công bằng, chúng tôi
chọn các giá trị p₀ khác nhau để duy trì GFlops tương tự và
so sánh hiệu suất. Chúng tôi nhận thấy rằng việc lựa chọn
head auxiliary ảnh hưởng đáng kể đến hiệu suất.
Đặc biệt, head ATM mạnh mẽ cung cấp ước tính chính xác hơn
về tất cả mức độ khó khăn của token, dẫn đến
kết quả vượt trội.

4.4. Áp dụng cho Các Phương pháp Hiện có
Chúng tôi áp dụng DToP được đề xuất cho hai framework phân đoạn
ngữ nghĩa chính trong vision transformers [7] thuần túy. SETR [29] sử dụng decoder upsampling ngây thơ,
và SegViT [27] áp dụng module ATM điều chỉnh của chúng tôi. Kết
quả được hiển thị trong Bảng 7 sử dụng ba benchmark đầy thử thách. Với ngưỡng tin cậy p₀ phù hợp, DToP được đề xuất có thể giảm
trung bình 20%∼35% chi phí tính toán mà không có sự sụt giảm độ chính xác
đáng chú ý. Cụ thể hơn, SETR với DToP@Finetune giảm 25.2%
chi phí tính toán (FLOPs 107.7G→80.6G) mà không sụt giảm mIoU
trên ADE20K và thậm chí có được mIoU hơi tốt hơn
(58.1%→58.2%) trên bộ dữ liệu Pascal Context. SegViT với
DToP@Finetune dựa trên ViT-large giảm khoảng 35%
tính toán với chỉ 0.5% mIoU thấp hơn trên ADE20K.

Một so sánh định tính liên quan đến số lượng token được cắt giảm
của các hình ảnh khác nhau được trình bày trong Hình 4. Chúng ta
thấy rằng hầu hết token được cắt giảm ở các giai đoạn rất sớm cho
hình ảnh của các kịch bản đơn giản. Đối với hình ảnh cảnh phức tạp, hầu hết
token vẫn còn cho đến dự đoán cuối cùng. Do đó, tính
toán được phân bổ không đều giữa các hình ảnh bằng cách điều chỉnh
số lượng token được cắt giảm, tạo ra cải thiện đáng kể
trong hiệu quả tính toán. Chúng tôi cũng quan sát rằng
các token dễ được cắt giảm chủ yếu nằm ở khu vực trung tâm
của các đối tượng, trong khi các token khó được giữ lại nằm trên
các ranh giới, tương tự như quá trình phân đoạn của con người. Một số
dự đoán được hiển thị trong Hình 5.

5. Kết luận
Công trình này nghiên cứu vấn đề giảm chi phí tính toán
cho phân đoạn ngữ nghĩa hiện có dựa trên vision
transformers thuần túy. Một mô hình Cắt Giảm Token Động được
đề xuất dựa trên thoát sớm của token. Được thúc đẩy bởi
quá trình phân đoạn thô-đến-tinh của con người, chúng tôi giả
định rằng các token khác nhau đại diện cho các vùng hình ảnh có
độ khó nhận diện khác nhau và phân loại tất cả mức độ khó
khăn của token sử dụng các khối auxiliary vốn có. Để đạt được mục tiêu này,
chúng tôi hoàn thiện dự đoán của các token dễ tại các lớp trung gian
và dừng quá trình truyền xuôi của chúng, điều này giảm
tính toán một cách động. Chúng tôi tiếp tục đề xuất một chiến lược để
duy trì thông tin ngữ cảnh bằng cách bảo tồn các danh mục ngữ nghĩa
cực kỳ dễ sau khi cắt giảm token. Kết quả thí nghiệm mở rộng
cho thấy rằng phương pháp được đề xuất đạt được
hiệu suất hấp dẫn.

Tương tự như tất cả các mạng động khác, DToP không thể tận dụng
đầy đủ hiệu quả tính toán của một mini-batch.
Chúng tôi sẽ tối ưu hóa trong tương lai và tiếp tục thúc đẩy
vision transformers sử dụng DToP được đề xuất.

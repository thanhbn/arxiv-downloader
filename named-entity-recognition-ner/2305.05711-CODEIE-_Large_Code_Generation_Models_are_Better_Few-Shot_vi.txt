# 2305.05711.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/named-entity-recognition-ner/2305.05711.pdf
# Kích thước tệp: 984007 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
CODEIE: Các Mô hình Sinh Code Lớn là Những Bộ Trích xuất Thông tin Few-Shot Tốt hơn
Peng Li1, Tianxiang Sun2, Qiong Tang2, Hang Yan2
Yuanbin Wu3, Xuanjing Huang2, Xipeng Qiu2,y
1Học viện Kỹ thuật & Công nghệ, Đại học Fudan
2Khoa Khoa học Máy tính, Đại học Fudan
3Khoa Khoa học và Công nghệ Máy tính, Đại học Sư phạm Hoa Đông
{lip21,qtang22}@m.fudan.edu.cn ,ybwu@cs.ecnu.edu.cn
{txsun19,hyan19,xjhuang,xpqiu}@fudan.edu.cn

Tóm tắt
Các mô hình ngôn ngữ lớn (LLMs) được tiền huấn luyện trên các kho ngữ liệu khổng lồ đã thể hiện khả năng học few-shot ấn tượng trên nhiều tác vụ NLP. Một thực hành phổ biến là chuyển đổi tác vụ thành định dạng text-to-text sao cho các LLMs sinh ngôn ngữ tự nhiên (NL-LLMs) như GPT-3 có thể được nhắc để giải quyết nó. Tuy nhiên, việc thực hiện các tác vụ trích xuất thông tin (IE) với NL-LLMs là không đơn giản vì đầu ra của tác vụ IE thường có cấu trúc và do đó khó chuyển đổi thành văn bản thuần túy. Trong bài báo này, chúng tôi đề xuất chuyển đổi đầu ra có cấu trúc dưới dạng code thay vì ngôn ngữ tự nhiên và sử dụng các LLMs sinh code (Code-LLMs) như Codex để thực hiện các tác vụ IE, đặc biệt là nhận dạng thực thể có tên và trích xuất mối quan hệ. Trái ngược với NL-LLMs, chúng tôi chỉ ra rằng Code-LLMs có thể được căn chỉnh tốt với các tác vụ IE này bằng cách thiết kế các lời nhắc theo phong cách code và công thức hóa các tác vụ IE này thành các tác vụ sinh code. Kết quả thực nghiệm trên bảy benchmark cho thấy phương pháp của chúng tôi luôn vượt trội hơn so với việc tinh chỉnh các mô hình tiền huấn luyện cỡ trung bình được thiết kế đặc biệt cho các tác vụ IE (ví dụ UIE) và việc nhắc NL-LLMs trong cài đặt few-shot. Chúng tôi tiến hành thêm một loạt các phân tích sâu để chứng minh các ưu điểm của việc tận dụng Code-LLMs cho các tác vụ IE.1

1 Giới thiệu
Trích xuất thông tin (IE) nhằm nhận dạng thông tin có cấu trúc từ văn bản thuần túy. Nó bao gồm các tác vụ khác nhau với các cấu trúc đầu ra đa dạng như nhận dạng thực thể có tên (NER), trích xuất mối quan hệ (RE), v.v. (Sang và Meulder, 2003; Grishman, 2019; Wang et al., 2021a; Zhong và Chen, 2021; Lu et al., 2022). Để biểu đạt và giải quyết các tác vụ khác nhau này trong một khung thống nhất, các nghiên cứu gần đây đề xuất tuyến tính hóa các cấu trúc đầu ra thành các chuỗi không có cấu trúc và giải quyết các tác vụ IE với các mô hình sinh chuỗi (Yan et al., 2021b; Huguet Cabot và Navigli, 2021; Paolini et al., 2021; Josifoski et al., 2022; Lu et al., 2022). Ví dụ, cho câu đầu vào "Steve became CEO of Apple in 1998." của một tác vụ NER, UIE (Lu et al., 2022) sinh ra mục tiêu dưới dạng một chuỗi "((person: Steve) (organization: Apple))".

Mặc dù loại phương pháp tuyến tính hóa này đạt được kết quả đầy hứa hẹn với dữ liệu huấn luyện đầy đủ, nó vẫn hoạt động kém trong kịch bản few-shot. Ví dụ, so với huấn luyện dữ liệu đầy đủ, hiệu suất giảm khoảng 20% khi áp dụng UIE trên tác vụ NER 5-shot CoNNL03 (Lu et al., 2022).

Xem xét khả năng thích ứng few-shot to lớn của các mô hình ngôn ngữ lớn (LLMs) (Brown et al., 2020; Rae et al., 2021;

--- TRANG 2 ---
Chowdhery et al., 2022; Hoffmann et al., 2022), chúng tôi quản lý việc sử dụng chúng để thực hiện các tác vụ IE few-shot, đặc biệt là tác vụ NER few-shot và tác vụ RE. Thông thường, đối với các tác vụ NLP như phân loại văn bản, các nghiên cứu trước đây tái công thức hóa chúng thành các định dạng sinh text-to-text và nhắc các LLMs của ngôn ngữ tự nhiên (NL-LLMs) như GPT-3 (Brown et al., 2020) để sinh ra câu trả lời. Ngược lại, do cấu trúc phức tạp bên trong các mục tiêu của các tác vụ IE, các mục tiêu tuyến tính hóa của các nghiên cứu trước đây như "((person: Steve) (organization: Apple))" thường "không tự nhiên", dẫn đến sự không khớp giữa định dạng đầu ra tại thời điểm tiền huấn luyện và thời điểm suy luận (xem Hình 1(a)). Do đó, khi sử dụng các phương pháp làm phẳng này để thực hiện các tác vụ IE với các mô hình ngôn ngữ tiền huấn luyện, các đầu ra dự đoán thường mong manh và thường yêu cầu các chiến lược giải mã phức tạp để được xử lý hậu kỳ thành các cấu trúc hợp lệ (Lu et al., 2022; Josifoski et al., 2022).

Trong bài báo này, chúng tôi đề xuất đóng khung hai tác vụ IE này thành các tác vụ sinh code và tận dụng các LLMs của code (Code-LLMs) để giải quyết chúng. Chúng tôi lập luận rằng thông tin code có cấu trúc phong phú được mã hóa trong các Code-LLMs tiền huấn luyện có thể có lợi cho các tác vụ IE này. Như được chứng minh trong Hình 1(b), việc chuyển đổi tác vụ IE text-to-structure thành tác vụ sinh code structure-to-structure là dễ dàng, trong khi việc biến đổi nó thành định dạng text-to-text có thể khó khăn. Lấy ví dụ đầu vào trong Hình 1, "Steve became CEO of Apple in 1998.", chúng tôi bọc nó vào một đoạn code Python và công thức hóa các đầu ra thực thể có cấu trúc dưới dạng các từ điển Python với các khóa "text" và "type". Chúng tôi sắp xếp chúng thành một hàm Python tương đương về mặt ngữ nghĩa với ví dụ NER, được hiển thị như sau:

```python
def named_entity_recognition(input_text):
    """ extract named entities from the input_text . """
    input_text = "Steve became CEO of Apple in 1998 ."
    entity_list = []
    # extracted named entities
    entity_list.append({"text": "Steve", "type": "person"})
    entity_list.append({"text": "Apple",\
    "type": "organization"})
```

Sau khi chứng minh một vài mẫu huấn luyện với cùng định dạng, chúng tôi đưa lời nhắc theo phong cách code (các dòng được đánh dấu bằng màu xám nhạt) vào Code-LLMs và nhận được dự đoán có cấu trúc.

Chúng tôi tiến hành thực nghiệm trên bảy benchmark của các tác vụ NER và RE, và phân tích cẩn thận các lợi ích của phương pháp chúng tôi (được đặt tên là CODEIE). Các phát hiện như sau:

1) Việc nhắc Code-LLMs (ví dụ Codex (Chen et al., 2021)) với các đầu vào theo phong cách code luôn vượt trội so với việc tinh chỉnh UIE, một mô hình được tiền huấn luyện đặc biệt cho các tác vụ IE, và việc nhắc NL-LLMs (ví dụ GPT-3) trong cài đặt few-shot.

2) Với cùng một LLM (hoặc NL-LLM hoặc Code-LLM), lời nhắc theo phong cách code hoạt động tốt hơn lời nhắc văn bản tuyến tính hóa, chứng minh lợi thế của việc biểu diễn các mục tiêu có cấu trúc bằng code.

3) Với cùng một lời nhắc (hoặc ngôn ngữ tự nhiên hoặc code), Code-LLM (tức là Codex) đạt được hiệu suất tốt hơn NL-LLM (tức là GPT-3), chứng minh các ưu điểm của việc thực hiện các tác vụ IE với Code-LLMs.

4) So với các lời nhắc ngôn ngữ tự nhiên, việc sử dụng các lời nhắc theo phong cách code cho thấy độ trung thực cao hơn đối với các cấu trúc đầu ra, tức là các đầu ra có tỷ lệ lỗi cấu trúc thấp hơn.

Các khác biệt cấp cao giữa các mô hình cỡ trung bình trước đây, NL-LLMs và Code-LLMs cho các tác vụ IE được tóm tắt trong Bảng 1.

[THIS IS TABLE: Bảng so sánh cấp cao giữa các mô hình IE trước đây, NL-LLMs và Code-LLMs với các đặc điểm như Model Type, Generative?, Extremely Large?, Structured Pre-train?, Few-Shot NER and RE Tasks, Unified Framework, Few-shot Learning, Structured Task]

2 CODEIE

Trong phần này, trước tiên chúng tôi công thức hóa hai tác vụ IE mà chúng tôi tập trung vào, nhận dạng thực thể có tên (NER) và trích xuất mối quan hệ (RE) trong Phần 2.1. Sau đó chúng tôi mô tả cách chúng tôi chuyển đổi các tác vụ dự đoán có cấu trúc này thành các tác vụ sinh code (Phần 2.2) và nhắc Code-LLMs để thực hiện chúng (Phần 2.3) trong kịch bản few-shot. Chúng tôi sử dụng ngôn ngữ Python cho các tác vụ sinh code của mình vì các codebase Python công khai rất phong phú và Code-LLMs được tiền huấn luyện đầy đủ trên chúng.

2.1 Công thức hóa Tác vụ

Cho một câu đầu vào x với l token x1; x2; : : : ; xl, các tác vụ IE là dự đoán mục tiêu có cấu trúc y từ x.

--- TRANG 3 ---
```python
def named_entity_recognition(input_text):
    """ extract named entities from the input_text . """
    input_text = "Steve became CEO of Apple in 1998"
    entity_list = []
    # extracted named entities
    entity_list.append({"text": "Steve", "type": "person"})
    entity_list.append({"text": "Apple", "type": "organization"})
```

"Steve became CEO of Apple in 1998"
"Steve": "person"
"Apple": "organization"

Code-LLMs → Code Prompt → Prediction NER

(a) Chuyển đổi NER thành tác vụ sinh code

```python
def relation_extraction(input_text):
    """extract the relations of named entities from the input text. """
    input_text = "Steve became CEO of Apple in 1998"
    entity_relation_list = []
    # extracted relations
    entity_relation_list.append({"rel_type": "work for", \
    "ent1_type": "person", "ent1_text": "Steve", \
    "ent2_type": "organization", "ent2_text": "Apple"})
```

"Steve": "person"
"Apple": "organization"

Code-LLMs → Code Prompt → Prediction RE

"work for"
"Steve became CEO of Apple in 1998"

(b) Chuyển đổi RE thành tác vụ sinh code

Hình 2: Cách chuyển đổi NER và RE thành tác vụ sinh code.

Mục tiêu y của NER là một tập hợp các cặp (e; t), trong đó e là một span thực thể (ví dụ "Steve") và t là loại thực thể tương ứng (ví dụ "person"). Span thực thể là một chuỗi các token từ x, và loại thực thể thuộc về một tập hợp loại thực thể được định nghĩa trước T.

Mục tiêu dự đoán y của RE bao gồm một tập hợp các bộ ba (e1; r; e2), trong đó e1 và e2 là hai span thực thể từ x và r ∈ R là mối quan hệ ngữ nghĩa (ví dụ "work for") giữa hai thực thể. Ở đây R biểu thị một tập hợp loại mối quan hệ được định nghĩa trước. Ngoài việc trích xuất mối quan hệ của các thực thể, chúng ta thường quan tâm đến việc dự đoán các loại thực thể t1 và t2 của các thực thể e1 và e2 cùng lúc.

Trong cài đặt few-shot, chúng ta được cung cấp một tập hợp nhỏ các mẫu được chú thích f(xi; yi)gni=1 bao gồm k mẫu cho mỗi lớp để tạo thành một cài đặt k-shot.

2.2 Công thức hóa các Tác vụ IE thành Tác vụ Sinh Code

Để sử dụng các Code-LLMs sinh để cho các tác vụ IE, chúng tôi tái công thức hóa các tác vụ IE thành các tác vụ sinh code. Tác vụ sinh code là dự đoán chuỗi code tiếp theo cho trước một đoạn code chưa hoàn chỉnh. Do đó, chúng ta có thể chuyển đổi đầu vào và đầu ra của tác vụ IE thành một đoạn code chưa hoàn chỉnh và code cần được dự đoán, tương ứng, sao cho chúng có thể tạo thành một đoạn code hoàn chỉnh tương đương về mặt ngữ nghĩa với mẫu gốc trong khi duy trì cú pháp của ngôn ngữ lập trình.

Trong nghiên cứu này, chúng tôi chủ yếu sử dụng các hàm Python để biểu diễn các tác vụ IE. Chúng tôi bọc văn bản đầu vào x vào một lời nhắc theo phong cách code xc và biểu diễn cấu trúc đầu ra y bằng các phần tử Python có cấu trúc, như list, dictionary, v.v. Như được hiển thị trong Hình 2, đối với các tác vụ NER và RE, trước tiên chúng tôi biến đổi tên tác vụ thành tên của hàm Python và thêm một docstring để minh họa mục tiêu của tác vụ. Chúng tôi gán chuỗi văn bản đầu vào x cho một biến input_text. Sau đó chúng tôi khởi tạo một list rỗng để lưu đầu ra và thêm một comment mô tả như "# extracted named entities" để nhắc Code-LLMs đưa các thực thể có tên vào list. Chúng tôi đóng gói code trên làm lời nhắc code xc của chúng tôi.

Đối với mục tiêu có cấu trúc y, chúng tôi sử dụng phương thức append của Python list và biểu diễn mỗi đơn vị thông tin cơ bản (ví dụ một cặp cho các tác vụ NER hoặc một bộ ba cho các tác vụ RE) dưới dạng một từ điển Python. Do đó, mục tiêu yc cần được dự đoán bởi Code-LLMs được tái công thức hóa thành một list các từ điển. Đối với NER, chúng tôi thêm các từ điển Python với các khóa "text" và "type" vào list, trong đó các giá trị của từ điển là span thực thể và loại thực thể tương ứng. Đối với RE, chúng tôi tương tự thêm các từ điển với các khóa "rel_type", "ent1_type", "ent1_text", "ent2_type", và "ent2_text" vào list để biểu diễn mục tiêu có cấu trúc.

Code-LLM được kỳ vọng hoàn thành list với điều kiện dựa trên tên hàm, docstring và văn bản đầu vào. Hình 2 hiển thị các ví dụ về việc công thức hóa một mẫu IE gốc thành một mẫu theo phong cách code.

--- TRANG 4 ---
Đáng chú ý rằng không gian thiết kế của lời nhắc theo phong cách code là rộng lớn và khó được khám phá đầy đủ. Công thức được mô tả ở trên là một trường hợp đơn giản sử dụng Python. Chúng tôi cũng khám phá một số công thức khác để chuyển đổi các tác vụ IE thành các tác vụ sinh code, có thể được tìm thấy trong Phụ lục A.1.

2.3 Nhắc Code-LLMs với Các Minh họa Trong Ngữ cảnh

Mặc dù có lời nhắc được thiết kế cẩn thận, việc thực hiện các tác vụ IE bằng cách nhắc Code-LLMs mà không có bất kỳ mẫu nào là không đơn giản. Do đó, cần thiết để Code-LLMs nhận thức được một vài mẫu được gán nhãn trong các cài đặt few-shot điển hình.

Với kích thước ngày càng tăng của các mô hình ngôn ngữ tiền huấn luyện, việc tinh chỉnh đang trở nên ngày càng đắt đỏ hoặc thậm chí không khả thi vì các LLMs gần đây thường được phát hành dưới dạng APIs hộp đen (Sun et al., 2022). Do đó, thay vì tinh chỉnh Code-LLMs trên tập dữ liệu few-shot, chúng tôi khám phá việc bao gồm các mẫu được gán nhãn trong ngữ cảnh và thực hiện học trong ngữ cảnh (Brown et al., 2020). Chúng tôi chọn n mẫu f(xi; yi)gni=1 từ tập dữ liệu huấn luyện và chuyển đổi chúng thành các cặp theo phong cách code tương ứng f(xci; yci)gni=1. Chúng tôi nối chúng lại thành một chuỗi để tạo thành các minh họa trong ngữ cảnh xc1yc1 : : : xcnycn. Cho một mẫu test x đến, trước tiên chúng tôi chuyển đổi nó thành một lời nhắc code xc và thêm ngữ cảnh minh họa vào trước, tức là xc1yc1 : : : xcnycnxc. Sau khi đưa đầu vào được xây dựng vào Code-LLM, chúng tôi kỳ vọng nhận được một đầu ra yc được định dạng giống như yc1, yc2, : : : ycn (xem Hình 2). Chúng tôi thấy rằng yc hầu như luôn giữ nguyên cú pháp của ngôn ngữ Python và dễ dàng được chuyển đổi trở lại cấu trúc gốc y của nó.

3 Thực nghiệm

3.1 Thiết lập

Tập dữ liệu Chúng tôi đánh giá phương pháp của mình trên tác vụ NER với CoNLL03 (Sang và Meulder, 2003), ACE04 (Doddington et al., 2004) và ACE05-E (Walker et al., 2006). Đối với trích xuất mối quan hệ, chúng tôi đánh giá trên các tập dữ liệu CoNLL04 (Roth và Yih, 2004), ACE05-R (Walker et al., 2006), NYT (Riedel et al., 2010) và SciERC (Luan et al., 2018). Bảng 2 hiển thị thống kê tập dữ liệu. Chúng tôi theo Lu et al. (2022) để tiền xử lý tất cả các tập dữ liệu này.

Code-LLMs Đối với Code-LLMs, chúng tôi tiến hành thực nghiệm chủ yếu với phiên bản code-davinci-002

[THIS IS TABLE: Bảng 2 hiển thị thống kê của các tập dữ liệu được sử dụng trong thực nghiệm, bao gồm số lượng loại thực thể, loại mối quan hệ, và số mẫu trong mỗi phần train/val/test cho các tập dữ liệu CoNLL03, ACE04, ACE05-E, CoNLL04, ACE05-R, NYT, SciERC]

Codex từ OpenAI. Codex là một mô hình ngôn ngữ lớn được điều chỉnh từ GPT-3 và được tiền huấn luyện thêm trên các codebase mã nguồn mở. Phiên bản code-davinci-002 Codex hỗ trợ tối đa 8k token đầu vào. Chúng tôi nhận được các dự đoán mô hình bằng cách truy vấn OpenAI API2 theo cách nhắc trong ngữ cảnh few-shot. Chúng tôi sinh tối đa 280 token với giải mã tham lam.

Baseline Chúng tôi so sánh phương pháp của mình với hai loại phương pháp học few-shot:
1) Tinh chỉnh Chúng tôi tinh chỉnh các phiên bản base và large của hai mô hình tiền huấn luyện cỡ trung bình: T5 và UIE. T5 là một mô hình sequence-to-sequence được tiền huấn luyện trên các kho ngữ liệu văn bản quy mô lớn. UIE là một mô hình được tiền huấn luyện thêm từ T5 trên các tập dữ liệu có cấu trúc. UIE sử dụng ngôn ngữ trích xuất có cấu trúc văn bản (SEL) để biểu đạt các cấu trúc đầu ra. Chúng tôi sử dụng cùng phương pháp và tham số với Lu et al. (2022) khi tinh chỉnh T5 và UIE.

2) Nhắc Chúng tôi so sánh phương pháp của mình với việc nhắc NL-LLMs, đặc biệt là GPT-3. Chúng tôi chủ yếu thực nghiệm với text-davinci-002. Chúng tôi sử dụng một lời nhắc văn bản, có định dạng được sửa đổi nhẹ từ SEL. Như được hiển thị trong Hình 1(a), cho một văn bản đầu vào x, lời nhắc văn bản và định dạng đầu ra giống như "The text is x. The named entities in the text: " và "((person: ...)(organization:...))", tương ứng. Xem Phụ lục A.2 để biết thêm chi tiết về lời nhắc văn bản. Phương pháp và siêu tham số của việc nhắc NL-LLMs và việc nhắc Code-LLMs là giống hệt nhau.

--- TRANG 5 ---
[THIS IS TABLE: Bảng 3 hiển thị kết quả hiệu suất thực nghiệm trên các benchmark NER và RE, với các mô hình khác nhau và loại prompt, bao gồm dữ liệu đầy đủ và few-shot]

Cài đặt Few-Shot Đối với mỗi tác vụ IE, chúng tôi lấy mẫu ngẫu nhiên k mẫu huấn luyện cho mỗi loại thực thể hoặc mối quan hệ để xây dựng một tập huấn luyện k-shot. Giá trị của k thay đổi giữa các tập dữ liệu khác nhau để thỏa mãn giới hạn chiều dài tối đa (4097) của GPT-3. Để tương thích với các tập dữ liệu chứa các mẫu có mục tiêu rỗng, chúng tôi coi những mẫu mục tiêu rỗng đó là một lớp bổ sung và bao gồm k mẫu thuộc lớp đó trong tập huấn luyện.

Đánh giá Giống như nghiên cứu trước đây (Lu et al., 2022), chúng tôi sử dụng Entity F1 và Relation Strict F1 làm các số liệu đánh giá cho các tác vụ NER và tác vụ RE, tương ứng. Trong các số liệu này, một dự đoán span thực thể là đúng nếu offset và loại thực thể của nó khớp với thực thể vàng. Và một dự đoán mối quan hệ là đúng nếu loại mối quan hệ là đúng và các offset và loại tương ứng của các thực thể của nó là đúng. Vì huấn luyện few-shot có độ biến thiên cao, chúng tôi thực hiện 3 lần chạy với các seed ngẫu nhiên khác nhau cho mỗi thực nghiệm và báo cáo trung bình và độ lệch chuẩn của số liệu.

3.2 Kết quả

LLMs vs. Các Mô hình Cỡ Trung bình Như được hiển thị trong Bảng 3, LLMs (GPT-3 và Codex) đạt được hiệu suất vượt trội so với các mô hình cỡ trung bình (T5 và UIE) trong cài đặt few-shot, chứng minh khả năng học few-shot mạnh mẽ trên các tác vụ IE. Đặc biệt, về hiệu suất trung bình trên bảy benchmark được xem xét, CODEIE được đề xuất của chúng tôi (Codex + code prompt) đạt được kết quả tốt nhất, cải thiện T5-large và T5-base lần lượt 132% và 327%. Ngoài ra, trong cài đặt học 1-shot, CODEIE cải thiện hiệu suất của UIE-large hơn 60% trên các benchmark CoNLL03 và CoNLL04 (xem Bảng 6 trong Phụ lục).

Code Prompt vs. Text Prompt Sau đó chúng tôi so sánh hiệu suất của code prompt vs. text prompt khi sử dụng cùng một LLM, tức là so sánh ⟨GPT-3 + text prompt⟩ với ⟨GPT-3 + code prompt⟩ và so sánh ⟨Codex + text prompt⟩ với ⟨Codex + code prompt⟩. Kết quả là, chúng tôi thấy rằng việc nhắc LLMs với code mang lại cải thiện đáng kể (23% cho GPT-3 và 16% cho Codex). Điều đáng ngạc nhiên là code prompt thậm chí còn có lợi hơn cho GPT-3, không được huấn luyện đặc biệt trên dữ liệu code.

Code-LLMs vs. NL-LLMs Khi sử dụng cùng loại lời nhắc và so sánh các LLMs được sử dụng, tức là so sánh ⟨GPT-3 + text prompt⟩ và ⟨Codex + text prompt⟩ và so sánh ⟨GPT-3 + code prompt⟩ và ⟨Codex + code prompt⟩, chúng tôi thấy rằng Codex luôn vượt trội GPT-3, chứng minh rằng tiền huấn luyện code có thể có lợi cho các tác vụ IE.

Số Shot Khác nhau Chúng tôi tiếp tục so sánh các phương pháp này với số shot khác nhau trên CoNLL03 và CoNLL04. Như được hiển thị trong Hình 3, chúng ta có thể thấy rằng các hiện tượng thu được vẫn đúng khi tăng số lượng shot.

[THIS IS FIGURE: Hình 3 hiển thị hiệu suất với số shot khác nhau trên tập dữ liệu CoNLL03 (NER) và CoNLL04 (RE)]

Thiết kế Prompt Khác nhau Thiết kế của lời nhắc có thể là một yếu tố quan trọng ảnh hưởng đến hiệu suất mô hình (Min et al., 2022). Do đó, chúng tôi khám phá các thiết kế lời nhắc bổ sung cho cả text prompt và code prompt. Các thiết kế lời nhắc chi tiết có thể được tìm thấy trong Phụ lục A. Kết quả thực nghiệm được hiển thị trong Bảng 4, từ đó chúng tôi thấy rằng code prompts luôn vượt trội so với text prompts. Do đó, hiệu suất vượt trội của việc sử dụng code prompts chủ yếu được đóng góp bởi phong cách code thay vì một số trường hợp cụ thể của thiết kế prompt.

[THIS IS TABLE: Bảng 4 hiển thị hiệu suất của các thiết kế prompt khác nhau trên CoNLL03 và CoNLL04]

LLMs Khác nhau Để xác minh tính linh hoạt của phương pháp được đề xuất và các phát hiện quan sát được, chúng tôi tiến hành thêm các thực nghiệm với phiên bản text-davinci-001 của GPT-3 và phiên bản code-davinci-001 của Codex. Như được hiển thị trong Bảng 7, các phát hiện trước đây vẫn đúng trên hai phiên bản khác nhau.

4 Phân tích

Để xem xét kỹ hơn sự khác biệt giữa việc nhắc NL-LLMs với đầu vào định dạng văn bản và việc nhắc Code-LLMs với đầu vào định dạng code, trong phần này, chúng tôi định nghĩa một số số liệu thông tin và tiến hành các phân tích sâu để làm sáng tỏ câu hỏi sau: điều gì đóng góp vào hiệu suất cuối cùng của CODEIE cho các tác vụ IE?

4.1 Tính Nhất quán Định dạng

Chúng ta có thể thấy từ Hình 1(a) rằng một sự không phù hợp rõ ràng khi sử dụng NL-LLMs cho các tác vụ IE là sự không nhất quán giữa định dạng đầu ra có cấu trúc tại thời điểm suy luận và NL-LLMs được huấn luyện trên ngôn ngữ tự nhiên tại thời điểm tiền huấn luyện, trong khi định dạng của đầu ra theo phong cách code căn chỉnh tốt với Code-LLMs. Đã được chứng minh rằng việc điều chỉnh các mô hình tiền huấn luyện cho các tác vụ downstream theo cách căn chỉnh tốt với mô hình tiền huấn luyện của nó thường đạt được hiệu suất học few-shot tốt hơn. Do đó chúng tôi giả định rằng hiệu suất đầy hứa hẹn của CODEIE một phần đến từ tính nhất quán định dạng tốt hơn giữa mẫu theo phong cách code và mô hình code tiền huấn luyện.

Để xác minh giả thuyết này, cho một mẫu, chúng tôi so sánh các perplexity của một mô hình ngôn ngữ tiền huấn luyện trên định dạng văn bản của nó và một mô hình code tiền huấn luyện trên định dạng code của nó. Chính thức, cho một mô hình sinh M, perplexity có điều kiện ppl của một mẫu (x; y) như sau:

pplM(y|x) = ∏(i=1 to m) PM(yi|y1...yi-1; x)^(-1/l) (1)

Đối với một mẫu IE gốc (x; y), trước tiên chúng tôi chuyển đổi nó thành cặp văn bản ngôn ngữ tự nhiên (xt; yt) và cặp đoạn code (xc; yc), sau đó tính perplexity có điều kiện của chúng với mô hình ngôn ngữ Mnl và mô hình code Mc, tương ứng, tức là pplMnl(yt|xt) và pplMc(yc|xc). Perplexity có điều kiện thấp hơn có nghĩa là định dạng đầu ra căn chỉnh tốt với phân phối tiền huấn luyện của mô hình.

--- TRANG 6 ---
[THIS IS FIGURE: Hình 4 hiển thị biểu đồ so sánh perplexity giữa T5-base+text và CodeT5-base+code trên 7 tập dữ liệu]

Vì LLMs thường giới hạn quyền truy cập của người dùng bằng APIs hộp đen của chúng, thay vào đó chúng tôi sử dụng hai mô hình đại diện T5 (Raffel et al., 2020) và CodeT5 (Wang et al., 2021b) để tính các perplexity. CodeT5 là một biến thể của mô hình T5 được tiền huấn luyện thêm trên dữ liệu code. Chúng tôi tính các perplexity trên bảy tập dữ liệu trước đây với phiên bản base của hai mô hình, cụ thể là T5-base và CodeT5-base.

Hình 4 hiển thị các perplexity trung bình của hai mô hình phiên bản base trên các mẫu huấn luyện của mỗi tác vụ. Chúng ta có thể quan sát perplexity của các đầu ra định dạng văn bản được đo bởi T5-base thường lớn hơn các đầu ra định dạng code được đo bởi CodeT5-base. Điều đó có nghĩa là, việc chuyển đổi các mẫu IE sang định dạng code có thể căn chỉnh tốt hơn với phân phối dữ liệu của tiền huấn luyện code và do đó mô hình ngôn ngữ code tiền huấn luyện.

4.2 Độ Trung thực của Mô hình

Bên cạnh tính nhất quán định dạng thấp của việc nhắc ML-LLMs, chúng tôi thấy rằng NL-LLMs có khả năng sinh ra các đầu ra với lỗi cấu trúc và ngữ nghĩa cao hơn khi thực hiện các tác vụ IE few-shot so với Code-LLMs. Nói cách khác, Code-LLMs dường như trung thực hơn với các mẫu few-shot được minh họa so với NL-LLMs. Để đo lường định lượng độ trung thực của mô hình, chúng tôi định nghĩa hai số liệu:

Độ Trung thực Cấu trúc Độ trung thực cấu trúc đo lường mức độ trung thực của mô hình đối với cấu trúc của các minh họa được cung cấp trong ngữ cảnh. Điều này có thể được đo đơn giản bằng cách tính tỷ lệ lỗi cấu trúc, là tỷ lệ các mẫu được sinh ra có lỗi cấu trúc. Cụ thể, chúng tôi xây dựng một parser với một loạt các quy tắc viết tay để chuyển đổi các đầu ra được sinh ra bởi mô hình trở lại định dạng mong muốn và lọc ra các mẫu có cấu trúc không hợp lệ.

[THIS IS FIGURE: Hình 5 hiển thị tỷ lệ lỗi cấu trúc của các kết hợp khác nhau của LLM và phương pháp nhắc]

Hình 5 chứng minh độ trung thực cấu trúc của các mô hình khác nhau với các lời nhắc khác nhau trên bảy benchmark. Kết quả cho thấy rằng các đầu ra được sinh ra bởi GPT-3 và Codex sử dụng text prompts rất mong manh trong khi sử dụng code prompts có xu hướng sinh ra gần như không có mẫu lỗi cấu trúc. Bên cạnh đó, với cùng text prompt, Codex có xu hướng sinh ra ít mẫu lỗi cấu trúc hơn GPT-3, chứng minh khả năng hiểu vượt trội của nó về đầu vào có cấu trúc chung thay vì bị giới hạn trong các ngôn ngữ lập trình hiện có.

Độ Trung thực Ngữ nghĩa Một phép đo khác của độ trung thực mô hình là độ trung thực ngữ nghĩa, được thiết kế cho những mẫu có cấu trúc hợp lệ và có thể thành công trong parser của chúng tôi nhưng không đúng về mặt ngữ nghĩa. Sự khác biệt giữa độ trung thực ngữ nghĩa được định nghĩa và lỗi dự đoán thông thường là độ trung thực ngữ nghĩa chủ yếu xem xét các hành vi mô hình vi phạm công thức của tác vụ, ví dụ dự đoán một loại thực thể không tồn tại trong tập hợp loại thực thể cho trước hoặc trích xuất một span thực thể không xuất hiện trong văn bản đầu vào. Một số ví dụ lỗi ngữ nghĩa được phát hiện trong các thực nghiệm của chúng tôi được liệt kê trong Bảng 5.

[THIS IS TABLE: Bảng 5 hiển thị các mẫu lỗi ngữ nghĩa được phát hiện trong thực nghiệm, chủ yếu từ GPT-3]

Chúng tôi báo cáo kết quả thống kê của các tác vụ trong Bảng 8 và Bảng 9 trong Phụ lục. Kết quả là, chúng tôi thấy rằng GPT-3 sinh ra nhiều lỗi ngữ nghĩa hơn Codex mặc dù một số lỗi dường như "đúng" nhưng nằm ngoài tập hợp lớp được định nghĩa trước. Tóm lại, GPT-3 có xu hướng sinh ra kết quả dạng tự do và Codex trung thực hơn với các minh họa được cung cấp trong ngữ cảnh và do đó có thể dự đoán được hơn cho các tác vụ IE.

4.3 Hiệu suất Chi tiết

Ngoài ra, chúng tôi tiến hành đánh giá chi tiết để so sánh các phương pháp khác nhau. Ngoài điểm F1, precision và recall cũng là những số liệu quan trọng cho các tác vụ NER và RE. Để điều tra cách các LLMs và phương pháp nhắc khác nhau ảnh hưởng đến precision và recall, chúng tôi báo cáo hai số liệu trong Hình 6.

[THIS IS FIGURE: Hình 6 hiển thị chi tiết hiệu suất mô hình trên các tác vụ NER và RE, bao gồm Precision, Recall, và F1]

Kết quả cho thấy rằng: (a) Code prompt cải thiện hiệu suất mô hình trong cả precision và recall; (b) So với GPT-3, Codex đạt được recall cao hơn và precision tương đương trên các tác vụ NER và đạt được cả precision và recall cao hơn trên các tác vụ RE.

5 Nghiên cứu Liên quan

Trích xuất Thông tin Sinh Trích xuất thông tin sinh, đóng khung các tác vụ IE thành các tác vụ sinh token, nhận được nhiều sự chú ý gần đây do tiềm năng thống nhất các tác vụ khác nhau (Yan et al., 2021a; Josifoski et al., 2022). Yan et al. (2021a) thiết kế các cách khác nhau để tuyến tính hóa các thực thể thành một câu để thống nhất các tác vụ con nhận dạng thực thể có tên khác nhau. TANL (Paolini et al., 2021) sử dụng ngôn ngữ tăng cường để cải thiện hiệu quả của các mô hình sinh. Lu et al. (2022) cũng đề xuất một ngôn ngữ trích xuất có cấu trúc (SEL) và tiền huấn luyện mô hình UIE của họ với ngôn ngữ này trên nhiều tập dữ liệu có cấu trúc. Các nghiên cứu này tuyến tính hóa đầu ra cấu trúc của các tác vụ IE thành định dạng văn bản để căn chỉnh với các mô hình tiền huấn luyện. Khác với họ, chúng tôi đề xuất chuyển đổi các mẫu có cấu trúc của các tác vụ IE thành định dạng code có cấu trúc và sử dụng các mô hình code tiền huấn luyện được căn chỉnh để thực hiện các tác vụ.

Code-LLMs cho Các Tác vụ Phức tạp Các nghiên cứu gần đây cho thấy Code-LLMs hoạt động tốt hơn trên các tác vụ phức tạp như lý luận thông thường và tượng trưng (Madaan et al., 2022; Cheng et al., 2022), logic toán học (Suzgun et al., 2022) và các tác vụ dự đoán đối số sự kiện (Wang et al., 2022). Chúng tôi tập trung vào hai tác vụ IE chính khác với họ, tức là NER và RE. Bên cạnh đó, các phân tích sâu được tiến hành để cung cấp nhiều hiểu biết hơn.

LLMs cho Few-Shot NER và RE Mặc dù các LLMs như GPT-3 đã cho thấy khả năng học few-shot mạnh mẽ trong nhiều tác vụ NLP, các nghiên cứu hạn chế đã khám phá khả năng của chúng trên các tác vụ IE điển hình như NER và RE. Epure và Hennequin (2021) đánh giá GPT-2 (Radford et al., 2019) trên các tác vụ NER miền mở với minh họa few-shot. Một nghiên cứu gần đây (Gutiérrez et al., 2022) kiểm tra hiệu suất của GPT-3 trên các tác vụ NER và RE y sinh và thấy rằng nó kém hiệu quả so với việc tinh chỉnh các mô hình tiền huấn luyện nhỏ hơn. Nghiên cứu đồng thời của nó (Agrawal et al., 2022) thấy rằng GPT-3 hoạt động tốt trên các tác vụ IE lâm sàng few-shot. Chúng tôi tiến hành thực nghiệm trên các tập dữ liệu NER và RE tổng quát hơn và thấy rằng GPT-3 có thể đạt được hiệu suất tương đương với việc tinh chỉnh mô hình UIE. Bên cạnh đó, chúng tôi thành công sử dụng các LLMs của code với hiệu suất tốt hơn cho các tác vụ IE này.

6 Kết luận

Chúng tôi đề xuất nghiên cứu đầu tiên sử dụng các Code-LLMs có cấu trúc với các lời nhắc theo phong cách code để thực hiện các tác vụ NER và RE few-shot. Các thực nghiệm cho thấy phương pháp của chúng tôi luôn vượt trội so với các mô hình UIE và đối tác NL-LLMs trong cài đặt few-shot. Chúng tôi tiến hành phân tích rộng rãi và thấy rằng hiệu suất đến từ tính nhất quán định dạng tốt hơn và độ trung thực mô hình, v.v. Chúng tôi nghĩ rằng những phân tích này có thể tạo điều kiện cho nghiên cứu tương lai. Đối với các nghiên cứu tiếp theo, chúng tôi sẽ sử dụng CODEIE trên nhiều tác vụ IE hơn trong các miền khác nhau và kiểm tra tính mạnh mẽ của nó.

--- TRANG 9 ---
Hạn chế

Mặc dù phương pháp của chúng tôi thể hiện hiệu suất tốt hơn so với các mô hình baseline, cách thiết kế một lời nhắc định dạng code tốt vẫn chưa được kiểm tra đầy đủ. Bên cạnh đó, chúng tôi chủ yếu tiến hành thực nghiệm trên các mô hình GPT-3 và Codex hộp đen nhưng chúng không được mã nguồn mở và việc truy vấn mô hình GPT-3 tốn ngân sách kinh tế. Và việc sử dụng LLMs có thể gây ô nhiễm môi trường. Một hạn chế khác của phương pháp chúng tôi là Code-LLMs chủ yếu được huấn luyện trên các tập dữ liệu ngôn ngữ lập trình với chú thích tiếng Anh. Khám phá mô hình của chúng tôi trên các tập dữ liệu không phải tiếng Anh (như tập dữ liệu tiếng Trung) là nghiên cứu tương lai.

Lời cảm ơn

Chúng tôi muốn bày tỏ lòng biết ơn đến các nhà đánh giá vì những nhận xét và đề xuất hữu ích của họ. Chúng tôi cũng rất biết ơn Yaojie Lu vì sự hỗ trợ thân thiện của anh ấy trong các thực nghiệm của chúng tôi. Nghiên cứu này được hỗ trợ bởi Quỹ Khoa học Tự nhiên Quốc gia Trung Quốc (Số 62236004 và Số 62022027) và CCF-Baidu Open Fund.

Tài liệu tham khảo

[Phần tài liệu tham khảo được giữ nguyên định dạng gốc vì chứa nhiều thông tin bibliographic cụ thể]

Monica Agrawal, Stefan Hegselmann, Hunter Lang, Yoon Kim, và David A. Sontag. 2022. Large language models are few-shot clinical information extractors. In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, EMNLP 2022, Abu Dhabi, United Arab Emirates, December 7-11, 2022, pages 1998-2022. Association for Computational Linguistics.

[Tiếp tục với tất cả các tài liệu tham khảo khác...]

--- TRANG 10 ---
[Tiếp tục danh sách tài liệu tham khảo...]

--- TRANG 11 ---
[Tiếp tục danh sách tài liệu tham khảo...]

--- TRANG 12 ---
[Phụ lục A với các thiết kế định dạng prompt...]

A Thiết kế Định dạng Prompt

A.1 Code Format Prompts

Chúng tôi thiết kế một số định dạng lời nhắc theo phong cách code. Chúng tôi sử dụng câu đầu vào "Steve became CEO of Apple in 1998." và các thực thể tương ứng ("Steve": person, "Apple": organization) và mối quan hệ ("work for" của hai thực thể "Steve" và "Apple") làm mẫu chạy cho các tác vụ NER và RE.

[Tiếp tục với tất cả các thiết kế prompt khác nhau...]

--- TRANG 13 ---
[Tiếp tục với các bảng và thông tin bổ sung...]

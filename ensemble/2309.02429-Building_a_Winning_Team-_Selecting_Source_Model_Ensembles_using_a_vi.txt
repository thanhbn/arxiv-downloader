# Xây dựng một Đội chiến thắng: Lựa chọn Ensemble Mô hình Nguồn sử dụng Phương pháp Ước lượng Khả năng Chuyển giao Submodular

Vimal K B*1, Saketh Bachu*1,3, Tanmay Garg1, Niveditha Lakshmi Narasimhan2, Raghavan Konuru2,
và Vineeth N Balasubramanian1

1Học viện Công nghệ Ấn Độ, Hyderabad  2KLA  3Đại học California, Riverside

* Đóng góp bình đẳng. Tác giả liên hệ: vimalkb96@gmail.com

## Tóm tắt

Ước lượng khả năng chuyển giao của các mô hình được huấn luyện trước có sẵn công khai cho một tác vụ đích đã đóng vai trò quan trọng trong các tác vụ học chuyển giao trong những năm gần đây. Các nỗ lực hiện tại đề xuất các chỉ số cho phép người dùng chọn một mô hình từ nhóm các mô hình được huấn luyện trước mà không cần phải tinh chỉnh từng mô hình riêng lẻ và xác định một cách rõ ràng. Với sự gia tăng số lượng mô hình được huấn luyện trước có sẵn và sự phổ biến của ensemble mô hình, việc nghiên cứu khả năng chuyển giao của các mô hình đa nguồn cho một tác vụ đích cũng trở nên thiết yếu. Những nỗ lực hiện tại ít ỏi nghiên cứu khả năng chuyển giao trong các thiết lập ensemble đa nguồn như vậy chỉ sử dụng đầu ra của lớp phân loại và bỏ qua khả năng không khớp miền hoặc tác vụ. Hơn nữa, chúng bỏ qua yếu tố quan trọng nhất khi lựa chọn các mô hình nguồn, cụ thể là yếu tố gắn kết giữa chúng, có thể ảnh hưởng đến hiệu suất và độ tin cậy trong dự đoán của ensemble. Để giải quyết những khoảng trống này, chúng tôi đề xuất một chỉ số khả năng chuyển giao submodular dựa trên Optimal Transport mới (OSBORN) để ước lượng khả năng chuyển giao của một ensemble mô hình cho một tác vụ downstream. OSBORN tính đến một cách tập thể sự khác biệt miền ảnh, sự khác biệt tác vụ, và tính gắn kết của các mô hình trong ensemble để cung cấp các ước lượng khả năng chuyển giao đáng tin cậy. Chúng tôi đánh giá hiệu suất của OSBORN trên cả tác vụ phân loại ảnh và phân đoạn ngữ nghĩa. Thiết lập của chúng tôi bao gồm 28 tập dữ liệu nguồn, 11 tập dữ liệu đích, 5 kiến trúc mô hình, và 2 phương pháp huấn luyện trước. Chúng tôi so sánh phương pháp của mình với các chỉ số tiên tiến hiện tại MS-LEEP và E-LEEP, và vượt trội hơn chúng một cách nhất quán sử dụng phương pháp đề xuất.

## 1. Giới thiệu

Trong thị giác máy tính, học chuyển giao là chiến lược ưa thích để huấn luyện Mạng Neural Sâu (DNN) trên các miền và tập dữ liệu mới qua các tác vụ như phân loại ảnh [36, 25], phân đoạn ảnh [55, 74] và phát hiện đối tượng [20, 53]. Việc sử dụng rộng rãi này là do sự sẵn có dễ dàng của một nhóm lớn các mô hình được huấn luyện trước mã nguồn mở (được huấn luyện trên các tập dữ liệu quy mô lớn như ImageNet [37, 3]), khi được tinh chỉnh, đạt được sự hội tụ nhanh hơn và hiệu suất tốt hơn so với huấn luyện từ đầu. Tuy nhiên, mỗi khi người dùng muốn sử dụng học chuyển giao, câu hỏi ngày càng trở nên liên quan với số lượng mô hình nguồn tăng lên là: "Tôi nên chọn sự kết hợp nào của tập dữ liệu và kiến trúc để tinh chỉnh nhằm đạt được hiệu suất tốt nhất trên tập dữ liệu đích của mình?". Để giải quyết điều này, chúng ta cần một công cụ giúp chúng ta chọn một nguồn hoặc tập hợp các mô hình nguồn, đòi hỏi tinh chỉnh tối thiểu và đạt được hiệu suất tối đa.

Các chỉ số ước lượng khả năng chuyển giao (TE) đã được đề xuất trong những năm gần đây để giải quyết vấn đề này [60, 45, 71, 59, 48]. Với những chỉ số này, một mô hình nguồn cụ thể có thể được lựa chọn mà không cần tiến hành việc tinh chỉnh tốn kém của tất cả các mô hình nguồn có sẵn trên tập huấn luyện đích. Tuy nhiên, hầu hết các nỗ lực theo hướng này bị hạn chế bởi khả năng chỉ lựa chọn một mô hình nguồn duy nhất, do đó hạn chế việc sử dụng chúng trong thiết lập học ensemble. Chỉ có một công trình cho đến nay [1] mở rộng một phương pháp ước lượng khả năng chuyển giao nguồn đơn hiện có [45] cho thiết lập ensemble. Mặc dù công trình này cho thấy kết quả hứa hẹn, nó không xem xét sự tương tự giữa các tập dữ liệu nguồn và đích trong không gian biểu diễn tiềm ẩn, hoặc tính đến mối quan hệ giữa các mô hình riêng lẻ trong ensemble. Không gian vấn đề này vẫn còn mới mẻ vào thời điểm này, đòi hỏi nhiều nỗ lực hơn để ước lượng khả năng chuyển giao một cách đáng tin cậy trong các điều kiện khác nhau.

Các mô hình Ensemble đã phổ biến trong vài thập kỷ qua trong học máy [18, 7, 64]. Các mô hình Ensemble được biết đến với việc tăng độ chính xác tác vụ, giảm phương sai dự đoán tổng thể và tăng tính mạnh mẽ chống lại các mẫu dữ liệu ngoài phân phối [19]. Các nỗ lực gần đây đã cho thấy tính hữu ích của các ensemble mô hình được huấn luyện trước [65], đặc biệt xem xét sự sẵn có rộng rãi của các mô hình được huấn luyện trước trong cộng đồng [50]. Vấn đề ước lượng khả năng chuyển giao cho một ensemble mô hình từ một nhóm mô hình nguồn lớn trở nên thậm chí còn liên quan hơn trong bối cảnh này.

Trong công trình này, chúng tôi giới thiệu một chỉ số ước lượng khả năng chuyển giao mới được thiết kế đặc biệt cho việc lựa chọn ensemble được gọi là Chỉ số Khả năng Chuyển giao Submodular dựa trên Optimal Transport (OSBORN). Như đã nêu trước đây, một nỗ lực gần đây theo hướng này [1] đã cho thấy kết quả hứa hẹn cho điểm số như vậy, nhưng tập trung vào hiệu suất của mô hình riêng lẻ (thông qua đầu ra của bộ phân loại) và không xem xét sự không khớp không gian đặc trưng (biểu diễn tiềm ẩn), hoặc cách những mô hình này tương tác với nhau trong ensemble. Để giải quyết điều này, OSBORN đo lường sự không khớp không gian tiềm ẩn giữa các tập dữ liệu nguồn và đích (sự khác biệt miền) ngoài sự không khớp trong đầu ra của bộ phân loại (sự khác biệt tác vụ). Ngoài ra, để tính đến sự tương tác giữa các mô hình trong ensemble, chúng tôi giới thiệu một thuật ngữ gắn kết mô hình mới, nắm bắt sự hợp tác lẫn nhau giữa các mô hình hướng tới việc hình thành một ensemble. Sự gắn kết là cần thiết để đảm bảo rằng các mô hình riêng lẻ trong một ensemble đồng thuận với nhau về mặt dự đoán (và không loại bỏ lẫn nhau). Do đó, trong công trình này, chúng tôi đề xuất một bộ ước lượng khả năng chuyển giao nhận thức về miền, tác vụ và sự gắn kết cho việc lựa chọn ensemble từ một nhóm nguồn của nhiều mô hình.

Ngoài việc đưa các yếu tố nói trên vào ước lượng khả năng chuyển giao cho các ensemble, chúng tôi cho thấy rằng điểm số đề xuất có thể được xem như một hàm tập hợp submodular [4]. Điều này cho phép chúng tôi tuân theo chiến lược tối đa hóa tham lam, được biết là cung cấp giải pháp chất lượng cao cho vấn đề dựa trên các đảm bảo lý thuyết nổi tiếng [42]. Do đó chúng tôi lựa chọn các mô hình gắn kết và có liên quan chặt chẽ cho một tập dữ liệu đích cụ thể. Để đánh giá chỉ số của chúng tôi, chúng tôi tiến hành các thí nghiệm mở rộng sử dụng 28 tập dữ liệu nguồn, 11 tập dữ liệu đích, và 5 kiến trúc mô hình. Trong các tác vụ downstream, chúng tôi xem xét phân loại ảnh dựa trên huấn luyện trước có giám sát đầy đủ, phân loại ảnh dựa trên huấn luyện trước tự giám sát, phân đoạn ngữ nghĩa cũng như thích ứng miền.

Bảng 1 trình bày tổng quan về độ rộng thí nghiệm của chúng tôi, so với các nỗ lực gần đây khác về vấn đề này. Đặc biệt, theo hiểu biết tốt nhất của chúng tôi, chúng tôi là những người đầu tiên thực hiện ước lượng khả năng chuyển giao của các ensemble cho các tác vụ phân loại ảnh và thích ứng miền.

Để tóm tắt, chúng tôi đóng góp như sau: (1) Chúng tôi giới thiệu một chỉ số ước lượng khả năng chuyển giao mới cho việc lựa chọn ensemble xem xét sự tương tự miền, sự tương tự tác vụ và sự gắn kết liên mô hình trong thiết kế của nó; (2) Chúng tôi cho thấy rằng việc xem chỉ số đề xuất như một hàm tập hợp submodular cho phép chúng tôi sử dụng một chiến lược tối đa hóa tham lam đơn giản để lựa chọn một ensemble mô hình nguồn cho một tập dữ liệu đích nhất định; (3) Chúng tôi nghiên cứu hiệu suất của chỉ số chúng tôi qua một loạt rộng các tác vụ downstream và nhóm mô hình; (4) Chúng tôi đánh giá độ tin cậy của chỉ số chúng tôi sử dụng các chỉ số tương quan khác nhau trong các nghiên cứu của chúng tôi, và cũng thực hiện phân tích bổ sung và nghiên cứu ablation để nghiên cứu tính hữu ích của nó. Chúng tôi vượt trội hơn các phương pháp trước đây với biên độ 58.62%, 66.06%, và 96.36% theo Hệ số Tương quan Pearson (PCC), Kendall τ (KT) [31] và Weighted Kendall τ (WKT) [63] cho tác vụ phân loại ảnh.1

## 2. Công trình Liên quan

**Học Chuyển giao:** Qua nhiều năm, học chuyển giao đã được áp dụng và khám phá qua nhiều lĩnh vực khác nhau [12, 41, 2, 5], cũng như qua các tập dữ liệu, kiến trúc mô hình, và chiến lược huấn luyện trước [39, 15, 24]. Những nỗ lực này đã bao gồm việc nghiên cứu các câu hỏi thú vị và thực tế như lớp cụ thể nào có thể chuyển giao được nhiều hơn [70] hoặc ước lượng mối tương quan giữa hiệu suất huấn luyện trước và tinh chỉnh [33]. Ngoài việc tinh chỉnh các mô hình nguồn cho các tập dữ liệu đích, các phương pháp chuyển giao tác vụ [73, 14] cũng đã nghiên cứu mối quan hệ giữa các tác vụ thị giác như phân đoạn ngữ nghĩa, dự đoán độ sâu và dự đoán điểm biến mất, hoặc sử dụng bản đồ attribution để liên kết các tác vụ như vậy [56, 57]. Trái ngược với các phương pháp nêu trên, mục tiêu của công trình chúng tôi là ước lượng khả năng chuyển giao tập dữ liệu.

**Chỉ số Ước lượng Khả năng Chuyển giao (Nguồn Đơn):** Như đã nêu trước đây, việc đánh giá khả năng chuyển giao giảm nỗ lực trong việc tìm mô hình nguồn tối ưu cho một tập dữ liệu đích cụ thể vì nó tránh quá trình tinh chỉnh tốn kém. Trong những năm gần đây, những nỗ lực đáng kể đã được thực hiện trong không gian vấn đề này, xem xét tính liên quan của vấn đề này đối với các nhà thực hành. H-Score đã được đề xuất [6] để đo lường tính hữu ích (về mặt phân biệt) của các mô hình nguồn được huấn luyện trước cho tác vụ đích. Mặc dù phương pháp này cho thấy kết quả hứa hẹn như một công trình tiên phong trong lĩnh vực này, nó bỏ lỡ việc xem xét các kịch bản mà dữ liệu nguồn và đích có phân phối khác nhau. Sau đó, NCE [60], và LEEP [45] đã phát triển các phương pháp sử dụng đầu ra bộ phân loại của các mô hình nguồn được huấn luyện trước khi tập dữ liệu đích được truyền qua mô hình để ước lượng log-likelihood của tập dữ liệu đích. NCE chủ yếu tập trung vào ước lượng khả năng chuyển giao trong các kịch bản mà các tác vụ nguồn và đích chia sẻ cùng dữ liệu đầu vào (ví dụ: nhận dạng khuôn mặt và phân loại thuộc tính khuôn mặt). Các phương pháp tiếp theo như LogME [71] cũng cho thấy rằng các phương pháp likelihood có thể dễ bị over-fitting. Để giải quyết điều này, LogME [71] ước lượng giá trị tối đa của bằng chứng nhãn (thay vì maximum likelihood) dựa trên tập đặc trưng được trích xuất bởi các mô hình nguồn được huấn luyện trước. Xem xét thực tế rằng các phương pháp trước đây chủ yếu dựa vào đầu ra bộ phân loại và hiệu suất dưới tối ưu của chúng trong các kịch bản thực tế như thiết lập cross-domain, OTCE [59] đề xuất một framework optimal transport để tính toán sự khác biệt miền (dựa trên không gian đặc trưng) và sự khác biệt tác vụ (dựa trên không gian nhãn) để ước lượng khả năng chuyển giao. Phương pháp này tận dụng các biểu diễn tiềm ẩn của mô hình nguồn ngoài đầu ra bộ phân loại mà không có giả định rõ ràng về các tập dữ liệu nguồn và đích. Tuy nhiên, tất cả các công trình trên đều tập trung vào ước lượng khả năng chuyển giao từ một mô hình nguồn duy nhất đến một tập dữ liệu đích.

**Chỉ số Ước lượng Khả năng Chuyển giao (Ensemble Đa Nguồn):** Agostinelli et al[1] gần đây đã đề xuất công trình đầu tiên về việc mở rộng ước lượng khả năng chuyển giao để lựa chọn ensemble mô hình nguồn trong [1], đặc biệt tập trung vào phân đoạn ngữ nghĩa. Công trình này mở rộng LEEP [45] cho các ensemble, và cho thấy kết quả hứa hẹn trong các thiết lập được xem xét. Công trình của chúng tôi xây dựng trên nỗ lực này theo nhiều cách: (i) thay vì chỉ dựa vào đầu ra bộ phân loại để ước lượng khả năng chuyển giao [45, 1, 60], chúng tôi cũng xem xét sự không khớp miền trong không gian biểu diễn đặc trưng tiềm ẩn; (ii) ngoài việc xem xét đầu ra của các mô hình riêng lẻ trong một ensemble, chúng tôi cũng xem xét các tương tác và tương quan giữa các đầu ra mô hình; (iii) chúng tôi không đưa ra giả định về phân phối dữ liệu nguồn và đích; và (iv) trong khi [1] tập trung vào phân đoạn, chúng tôi cho thấy kết quả của phương pháp chúng tôi trên các tác vụ phân loại, phân đoạn và thích ứng miền. Chúng tôi cũng cho thấy kết quả trên nhiều chiến lược huấn luyện trước trong khi các công trình trước đây [45, 71, 60, 59] chủ yếu tập trung vào các chiến lược huấn luyện trước có giám sát đầy đủ. Chỉ số đề xuất của chúng tôi cũng có thể được xem như một hàm submodular, cho phép chúng tôi tận dụng các chiến lược tối ưu hóa tham lam dựa trên xếp hạng để làm cho nó hiệu quả trong thực tế.

**Học Ensemble.** Học ensemble của các mô hình đã phổ biến trong học máy để tăng hiệu suất tác vụ tổng thể, giảm phương sai dự đoán, ngăn chặn over-fitting, và tăng tính mạnh mẽ ngoài phân phối [7, 22, 69, 47]. Các nỗ lực gần đây hơn trong huấn luyện ensemble của các mô hình mạng neural đã tập trung vào tăng tốc việc huấn luyện của chúng [61, 65], tận dụng khả năng của một mô hình duy nhất để huấn luyện nhiều mạng con có dự đoán được ensemble để cải thiện tính mạnh mẽ [23], hoặc nghiên cứu các mô hình mixture-of-experts kết hợp hàng nghìn mạng con cho các mô hình ngôn ngữ lớn [54]. Chúng tôi làm rõ rằng công trình của chúng tôi tập trung vào việc lựa chọn ensemble mô hình từ một nhóm mô hình nguồn lớn hơn thông qua ước lượng khả năng chuyển giao mà không huấn luyện ensemble một cách rõ ràng. Có thể xem công trình của chúng tôi như một bước trước học ensemble khi có một nhóm mô hình lớn hơn và chỉ một số ít mô hình có thể được ensemble. Như đã nêu trong [1], thiết lập này thường được gặp bởi một nhà thực hành trong thế giới thực qua các miền ứng dụng.

## 3. Kiến thức Nền và Sơ bộ

**Ký hiệu:** Cho M tập dữ liệu nguồn, chúng tôi ký hiệu tập dữ liệu nguồn thứ r là Dsr={(xi_sr, yi_sr)}nr_i=1∼Psr(x, y) và tập dữ liệu đích là Dt={(xi_t, yi_t)}m_i=1∼Pt(x, y) trong đó, xi_sr∈ X sr, xi_t∈ X t, yi_sr∈ Ysr, và yi_t∈ Yt. Lưu ý rằng chúng tôi không hạn chế các không gian nhãn P(Ysr) và P(Yt) phải bao phủ cùng một tập hợp danh mục. Chúng tôi dựa nghiên cứu của mình trên một thiết lập domain-agnostic và task-agnostic.

**Ước lượng Khả năng Chuyển giao cho Ensemble:** Đối với mỗi tập dữ liệu nguồn Dsr, chúng tôi giả định tồn tại một mô hình được huấn luyện trước trên tập dữ liệu đó được ký hiệu bởi (θsr, hsr) trong đó θ là bộ trích xuất đặc trưng, và h là đầu phân loại. M đại diện cho tập hợp các mô hình nguồn như vậy. Như đã nêu trước đây, chúng tôi tập trung vào thiết lập lựa chọn mô hình nguồn đa (tức ensemble) trong đó chỉ số của chúng tôi cung cấp điểm số ước lượng khả năng chuyển giao (TE) αMe→t cho một tập con mô hình Me từ nhóm nguồn M. Khi tương quan với độ chính xác AMe→t (tức độ chính xác tinh chỉnh của ensemble trên tập kiểm tra đích), điểm số TE này cung cấp độ tin cậy của ước lượng khả năng chuyển giao. Theo [1], chúng tôi tính toán độ chính xác ensemble bằng cách tinh chỉnh các mô hình riêng lẻ trong tập con Me (cả θ và h) trên tập huấn luyện đích và tính trung bình dự đoán của chúng trên tập kiểm tra đích.

**Submodularity trong TE cho Ensemble.** Ý tưởng chính của TE liên quan đến việc chọn các mô hình nguồn tối ưu cho một tập dữ liệu đích nhất định. Ngoài sự đánh đổi hiệu suất & tính toán, một động lực quan trọng để lựa chọn một tập con mô hình là để giảm thiểu rủi ro chuyển giao tiêu cực.

Hình 2 ở đây cho thấy rằng việc chọn tất cả các mô hình trong ensemble có thể dẫn đến giảm hiệu suất tổng thể so với việc lựa chọn một tập hợp mô hình nhỏ hơn. Điều này có thể do tác động có hại của các mô hình yếu hoặc không thể chuyển giao trong ensemble, làm nổi bật tầm quan trọng của việc kết hợp các mô hình một cách cẩn thận để đảm bảo hiệu suất tối ưu. Hơn nữa, việc tìm một ensemble tối ưu cho một tập dữ liệu đích nhất định đòi hỏi kiểm tra tất cả các kết hợp có thể có của các mô hình nguồn khác nhau cho một kích thước ensemble cụ thể. Quá trình toàn diện này là một vấn đề NP-hard. Trong bài báo này, chúng tôi đề xuất một phương pháp submodular để xếp hạng các mô hình có sẵn trong nhóm nguồn theo mức tăng hiệu suất mà chúng sẽ mang lại nếu được thêm vào nhóm con của ensemble và lựa chọn k mô hình hàng đầu, trong đó k là kích thước yêu cầu của ensemble. Trong khi lựa chọn tập con submodular phổ biến trong các thiết lập học máy khác nhau [4, 30, 66], theo hiểu biết tốt nhất của chúng tôi, đây là lần sử dụng đầu tiên như vậy cho ước lượng khả năng chuyển giao. Để đạt được điều này, chúng tôi trước tiên định nghĩa chính thức submodularity bên dưới.

**Định nghĩa 3.1.** Cho Ω là một tập hợp và P(Ω) là tập lũy thừa của Ω, thì một hàm submodular là một hàm tập hợp f:P(Ω)→R. Hàm submodular tuân theo tính chất của lợi ích giảm dần, tức việc thêm một phần tử mới vào một tập hợp nhỏ hơn tạo ra sự gia tăng lớn hơn trong f so với một tập hợp lớn hơn. Về mặt toán học, nếu đối với tất cả X, Y⊆Ω, trong đó X⊆Y và đối với tất cả v∈Ω\Y, tính chất tuân theo:

f(X+v)−f(X)≥f(Y+v)−f(Y) (1)

Một lợi ích chính của việc đặt ra một vấn đề như một vấn đề lựa chọn tập con submodular là có thể tận dụng phương pháp tham lam để xác định hiệu quả một giải pháp có kích thước tập con yêu cầu gần với giải pháp tối ưu một cách hợp lý. Nemhauser [42] đã chỉ ra rằng chất lượng của tập con được chọn một cách tham lam không thể tồi tệ hơn 1−e−1 của giá trị tối ưu. Điều này làm cho submodularity trở thành một phương pháp hấp dẫn để sử dụng trong lĩnh vực TE cho ensemble vì chúng ta có thể xếp hạng các mô hình trong nhóm nguồn và lựa chọn một ensemble có kích thước mong muốn. Chi tiết thêm về cách lựa chọn các mô hình một cách tham lam được thảo luận sau trong bài báo này.

**Tiêu chí Đánh giá.** Như đã nêu trước đây, độ tin cậy của một phương pháp TE được thu được bằng cách đo lường sự tương quan giữa αMe→t và AMe→t. Các công trình trước đây [71, 45, 1, 59, 60] đo lường sự tương quan này sử dụng các kỹ thuật khác nhau như Hệ số Tương quan Pearson (PCC), Kendall τ (KT) [31] và Weighted Kendall τ (WKT) [63]. Chúng tôi báo cáo kết quả cho tất cả các thước đo tương quan này để toàn diện trong phân tích của chúng tôi.

## 4. OSBORN: Chỉ số Ước lượng Khả năng Chuyển giao cho Lựa chọn Ensemble Mô hình

Để thiết kế một phương pháp ước lượng khả năng chuyển giao đáng tin cậy cho ensemble mô hình, chúng tôi đề xuất Chỉ số Khả năng Chuyển giao Submodular dựa trên Optimal Transport (OSBORN), xem xét ba yếu tố: sự khác biệt miền, sự khác biệt tác vụ, và sự gắn kết liên mô hình. Được truyền cảm hứng từ các nỗ lực trước đây về ước lượng khả năng chuyển giao nguồn đơn [59], chúng tôi xem xét cả đầu ra bộ phân loại và khoảng cách trong không gian biểu diễn tiềm ẩn trong phương pháp của chúng tôi. Bên cạnh đó, vì trọng tâm của chúng tôi là ensemble mô hình, chúng tôi xem xét mối quan hệ liên mô hình trong chỉ số này. Bây giờ chúng tôi mô tả từng đại lượng này.

**Tối thiểu hóa Sự khác biệt Miền (WD).** Để tối thiểu hóa sự không khớp không gian tiềm ẩn giữa các tập dữ liệu nguồn và đích, tương tự như [59], chúng tôi chọn khoảng cách Wasserstein và Optimal Transport (OT) để tính toán sự không khớp này do những ưu điểm của nó trong việc nắm bắt hình học của dữ liệu cơ bản. Về mặt toán học, khoảng cách p-Wasserstein được cho như sau:

Wp(β, γ) = ( inf π∈Π(β,γ) ∫ D(x, z)p dπ(x, z) )^(1/p) (2)

trong đó, p≥1, β, γ là các biến ngẫu nhiên liên tục hoặc rời rạc trong một không gian đầy đủ và khả phân S, D(., .) : S×S→R+ là một hàm khoảng cách hoặc chi phí giữa hai điểm x và z, π(β, γ) là ma trận kết hợp có thể được hiểu như các phân phối xác suất kết hợp với các phân phối biên β và γ. Đặc biệt, trong công trình này, chúng tôi sử dụng khoảng cách 1-Wasserstein, còn được gọi là Earth Mover Distance, để tính toán sự khác biệt miền giữa các tiềm ẩn nguồn và đích như:

WD(θs, xt) = Σ(i,j=1 to m,n) ||θs(xi_s)−θs(xj_t)||²₂ π*ij, (3)

trong đó || · − · ||²₂ là metric khoảng cách hoặc chi phí, π* là ma trận kết hợp tối ưu có kích thước m×n được thu được bằng cách giải quyết vấn đề optimal transport (OT) sử dụng thuật toán Sinkhorn [11, 59]. Lưu ý rằng θs(.) là bộ trích xuất đặc trưng thuộc về mô hình nguồn. Trực quan, nếu không gian tiềm ẩn của tập dữ liệu nguồn được căn chỉnh chặt chẽ với không gian của tập dữ liệu đích, sẽ dễ dàng hơn cho mô hình chuyển giao.

**Tối thiểu hóa Sự khác biệt Tác vụ (WT).** Để đo lường sự khác biệt giữa một tác vụ nguồn và tác vụ đích nhất định, chúng tôi sử dụng sự không khớp giữa đầu ra mô hình/bộ phân loại cho dữ liệu nguồn và đích được truyền qua mô hình nguồn. Chúng tôi sử dụng entropy có điều kiện (CE) của các nhãn dự đoán ŷt∈ Ys của các mẫu tập dữ liệu đích cho các nhãn thực tế yt∈ Y t của chúng. Các nhãn dự đoán được thu được bằng cách truyền các mẫu đích xt qua mô hình nguồn tương ứng θs. Cho Ŷt là một biến ngẫu nhiên nhận giá trị trong phạm vi của Ys; và Yt là một biến ngẫu nhiên nhận giá trị trong phạm vi của Yt, thì WT có thể được tính như:

WT(θs, xt) = H(Ŷt|Yt) = −Σ(ŷt∈Ys) Σ(yt∈Yt) P̂(ŷt, yt) log P̂(ŷt, yt)/P̂(yt) (4)

trong đó P̂(ŷt, yt) là phân phối kết hợp của các nhãn đích dự đoán và thực tế và P̂(yt) là phân phối biên của các nhãn thực tế. Những đại lượng này có thể được tính toán dễ dàng sử dụng ma trận kết hợp tối ưu (thu được trong Phương trình 3) như sau:

P̂(ŷt, yt) = Σ(i,j:ŷi_t=ŷt,yj_t=yt) π*ij, (5)

Phân phối biên có thể được thu được từ phân phối kết hợp như sau:

P̂(yt) = Σ(ŷt∈Ys) P̂(ŷt, yt), (6)

Trực quan, các tác vụ tương tự sẽ dẫn đến giá trị WT thấp. Sử dụng WT tức CE một mình đại diện cho khả năng chuyển giao thực nghiệm theo [60]. Tuy nhiên, trong [59], nó được chỉ ra thực nghiệm rằng chỉ sử dụng CE là không đủ trong thiết lập domain-agnostic, điều này thúc đẩy chúng tôi kết hợp điều này với WD để tính đến sự không khớp không gian biểu diễn đặc trưng.

**Tối thiểu hóa Sự bất đồng Mô hình (Tính gắn kết WC).** Đối với một ensemble, điều quan trọng là các mô hình riêng lẻ củng cố dự đoán của nhau và có ít bất đồng giữa chúng để có hiệu suất tổng thể tốt. Để hiểu tính gắn kết của một ensemble, chúng tôi sử dụng Conditional Entropy để nắm bắt lượng bất đồng giữa các mô hình trong tập con mô hình Me. Về mặt toán học, chúng tôi biểu diễn WC như:

WC(Me, xt) = Σ(mi,mj∈Me) H(mi(xt)|mj(xt)) (7)

Trực quan, chúng tôi muốn một tính gắn kết cao và ít bất đồng giữa các mô hình để củng cố niềm tin dự đoán của ensemble, tức giá trị WC thấp, và để tránh các kịch bản mà các mô hình loại bỏ dự đoán của nhau.

Kết hợp các đại lượng lại với nhau, chúng tôi định nghĩa OSBORN cho một tập con mô hình Me của nhóm nguồn M như sau. Chỉ số của chúng tôi tính đến một cách tập thể sự khác biệt miền, sự khác biệt tác vụ và sự gắn kết mô hình. Tham khảo Hình 3 để có tổng quan.

OSBORN = Σ(mi∈Me)[WD(mi, xt) + WT(mi, xt)] + WC(Me, xt) (8)

Một ensemble mô hình đạt được điểm số OSBORN thấp sẽ có khả năng chuyển giao tốt hơn cho một tập dữ liệu đích. Các thí nghiệm của chúng tôi cho thấy rằng một sự kết hợp đơn giản của ba đại lượng này (không có hệ số trọng số) vượt trội hơn các phương pháp hiện có trong tất cả các thí nghiệm của chúng tôi. Trong các nghiên cứu ablation và phân tích của chúng tôi, chúng tôi nghiên cứu đóng góp của từng thành phần OSBORN cũng như hiệu ứng của việc trọng số khác nhau cho từng thành phần.

**Lựa chọn Tập con Submodular trong OSBORN.** Như đã nêu trước đây, chúng tôi cho thấy rằng chỉ số OSBORN đề xuất chuyển thành một vấn đề tối ưu hóa submodular, cho phép chúng tôi xếp hạng và chọn các mô hình hiệu quả từ nhóm nguồn. Trong khi các đại lượng nêu trên được viết từ góc độ tối thiểu hóa (để rõ ràng và dễ hiểu), để đặt ra điều này như một vấn đề tối đa hóa submodular, chúng tôi xem xét hàm điểm số tương ứng được tối đa hóa như:

f(Me) = −Σ(mi∈Me)[WD(mi, xt) + WT(mi, xt)] − WC(Me, xt) (9)

Giá trị của hàm tập hợp chúng tôi là một ước lượng khả năng chuyển giao được thiết kế sao cho nó có tương quan cao với độ chính xác tinh chỉnh (xem Bảng 3 & 4), do đó cho phép chúng tôi lựa chọn các mô hình mà không cần tinh chỉnh tốn kém.

**Định lý 4.1.** Hàm điểm số f(X), như được định nghĩa trong Phương trình 9, là một hàm submodular.

**Chứng minh.** Cho X1 và X2 là hai tập hợp sao cho X1⊆X2⊆M. Nếu chúng ta xem xét một thể hiện mô hình chưa được chọn v∈M\X2. Mức tăng trong điểm số được thu được bằng cách thêm v vào tập hợp X1, và điều này được tính như:

f(X1∪v)−f(X1) = −[WD(v, xt) + WT(v, xt)] − Σ(mi∈X1) H(mi(xt)|v(xt)) − Σ(mj∈X1) H(v(xt)|mj(xt)) (10)

Tương tự, mức tăng thu được bởi tập hợp X2 được cho bởi:

f(X2∪v)−f(X2) = −[WD(v, xt) + WT(v, xt)] − Σ(mi∈X2) H(mi(xt)|v(xt)) − Σ(mj∈X2) H(v(xt)|mj(xt)) (11)

Vì chúng ta có X1⊆X2, số lượng số hạng trong tổng của Phương trình 11 sẽ lớn hơn hoặc bằng số hạng của Phương trình 10. Vì entropy luôn là một giá trị không âm, chúng ta có thể nói rằng

−Σ(mi∈X1) H(mi(xt)|v(xt)) − Σ(mj∈X1) H(v(xt)|mj(xt)) ≥ −Σ(mi∈X2) H(mi(xt)|v(xt)) − Σ(mj∈X2) H(v(xt)|mj(xt))

Điều này ngụ ý rằng

f(X1∪v)−f(X1) ≥ f(X2∪v)−f(X2) (12)

Chúng ta có thể thấy rằng Phương trình 12 thỏa mãn điều kiện trong Định nghĩa 3.1. Điều này hoàn thành chứng minh.

**Tối ưu hóa Submodular sử dụng Tối đa hóa Tham lam.** Vì hàm tập hợp f(Me) của chúng tôi (được đề cập trong Phương trình 9) là submodular, nó thể hiện tính đơn điệu, tức tập hợp với mức tăng tối đa luôn là toàn bộ nhóm nguồn M. Tuy nhiên, vì chúng tôi muốn lựa chọn một tập con mô hình tức tập ensemble từ nhóm nguồn M, chúng tôi áp đặt một ràng buộc cardinality. Một cách chính thức, chúng tôi nhằm lựa chọn tập hợp Me có kích thước tối đa k để tối đa hóa mức tăng:

max Me:|Me|=k f(Me) (13)

Tuy nhiên, vấn đề này là NP-hard, nhưng chúng tôi sử dụng chiến lược tối đa hóa tham lam để tìm một tập hợp mô hình gần tối ưu Me cho tập dữ liệu đích. Trong thực tế, chúng tôi tính toán trước sự khác biệt miền theo cặp WD và sự khác biệt tác vụ WT giữa mỗi tập dữ liệu nguồn và đích. Sau đó, chúng tôi tính toán thuật ngữ gắn kết mô hình WC để thêm mỗi mô hình mi vào tập hợp các mô hình đã được chọn Me. Sử dụng ba đại lượng này liên quan đến mi, chúng tôi tính toán mức tăng đạt được bằng cách thêm nó vào tập hợp Me như f(Me∪mi)−f(Me) và chọn một cách tham lam mô hình có mức tăng cao nhất và thêm nó vào tập hợp Me. Chúng tôi tiếp tục lặp lại này cho đến khi chúng tôi đạt được kích thước tập ensemble là k. Khi các mẫu đích được truyền qua các mô hình nguồn, các đại lượng trong chỉ số của chúng tôi có thể được tính toán độc lập cho mỗi mô hình nguồn, do đó làm cho các tính toán tổng thể của chúng tôi có thể song song hóa.

Xem xét M*e như tập ensemble tối ưu, từ [42] đã biết rằng phương pháp tham lam như vậy có đảm bảo hiệu suất ít nhất 63% của tập ensemble tối ưu, tức

f(Me) ≥ (1−1/e) f(M*e) (14)

Trong thực tế, chúng tôi quan sát thấy rằng độ chính xác trung bình của ensemble được chọn bởi tham lam (76.315%) trong thiết lập có giám sát đầy đủ là 95.56% của độ chính xác trung bình của ensemble tối ưu (79.857%). Tương tự đối với thiết lập tự giám sát, độ chính xác trung bình của ensemble được chọn bởi tham lam (79.857%) là 93.50% của độ chính xác trung bình của ensemble tối ưu (84.962%), như được hiển thị trong Bảng 2. Chi tiết thêm về các thí nghiệm được trình bày trong phần tiếp theo.

## 5. Thí nghiệm và Kết quả

**Thiết lập Thí nghiệm.** Chúng tôi tuân theo cùng thiết lập thí nghiệm như công trình trước đây về lựa chọn ensemble mô hình nguồn [1] để đánh giá chỉ số khả năng chuyển giao của chúng tôi trong thiết lập mô hình nguồn đa. Cho tổng cộng M mô hình trong nhóm nguồn, mục tiêu của chúng tôi là lựa chọn một ensemble mô hình bằng cách chọn k mô hình từ nhóm nguồn. Chúng tôi tuân theo [1] trong việc đặt k thành 3 để công bằng trong so sánh. Chúng tôi cũng tiến hành một nghiên cứu để đánh giá điều này trên tập dữ liệu Oxford-IIIT Pets, và thấy rằng độ chính xác tối đa đạt được cho một ensemble có kích thước 3 (xem Hình 4), điều này càng củng cố lựa chọn của chúng tôi để tiến hành thí nghiệm.

**Tập dữ liệu Phân loại.** Đối với các tác vụ phân loại, chúng tôi xem xét 11 tập dữ liệu được sử dụng rộng rãi bao gồm CIFAR-10 [35], CIFAR-100 [35], Caltech-101 [16], Stanford Cars [34], Oxford 102 Flowers [46], Oxford-IIIT Pets [49], Imagenette [27], CUB200 [67], FashionMNIST [68], SVHN [43], Stanford Dogs [32]. Những tập dữ liệu này được sử dụng phổ biến trong nhiều tác vụ học chuyển giao. Trong số 11 tập dữ liệu này, chúng tôi đặt Caltech-101 [16], Stanford Cars [34], Oxford 102 Flowers [46], Oxford-IIIT Pets [49], Stanford Dogs [32] là các tập dữ liệu đích của chúng tôi và ước lượng khả năng chuyển giao sử dụng OSBORN.

**Kiến trúc Mô hình (Có giám sát đầy đủ).** Đối với thiết lập này, chúng tôi xem xét 2 kiến trúc mô hình nguồn ResNet-101 [25] và DenseNet-201 [28], có tính đến tính đa dạng và khả năng của mô hình. Chúng tôi lấy những mô hình này từ Thư viện PyTorch mã nguồn mở [50]. Ban đầu, cả hai mô hình đều được khởi tạo với trọng số ImageNet có giám sát đầy đủ [37], và sau đó chúng tôi huấn luyện chúng trên 11 tập dữ liệu phân loại để chuẩn bị nhóm mô hình nguồn của chúng tôi.

**Kiến trúc Mô hình (Tự giám sát).** Đối với thiết lập này, chúng tôi xem xét ResNet-50 [25] như kiến trúc mô hình nguồn của chúng tôi nhưng khởi tạo nó với trọng số thu được từ hai chiến lược huấn luyện trước tự giám sát, cụ thể là BYOL [21] và MoCov2 [9]. Chúng tôi có hai biến thể của mô hình ResNet-50 để tạo ra đủ tính đa dạng. Và như đã làm trong trường hợp trước, chúng tôi huấn luyện hai mô hình này trên 11 tập dữ liệu phân loại để chuẩn bị nhóm mô hình nguồn của chúng tôi. Chúng tôi sử dụng nhiều mô hình SSL được huấn luyện trước để xây dựng nhóm của chúng tôi. Tuy nhiên, việc tinh chỉnh được thực hiện theo cách có giám sát đầy đủ. Động lực của chúng tôi ở đây là nghiên cứu xem OSBORN có thể ước lượng khả năng chuyển giao một cách đáng tin cậy qua nhiều thiết lập huấn luyện trước hay không.

**Thiết lập Huấn luyện cho Mô hình Nguồn (Tác vụ Phân loại).** Đối với tất cả các tác vụ phân loại, chúng tôi huấn luyện các mô hình nguồn sử dụng hàm mất cross-entropy và tối ưu hóa nó sử dụng Stochastic Gradient Descent (SGD) với momentum. Cho những chi tiết này, các siêu tham số quan trọng nhất là learning rate, batch size và weight decay. Chúng tôi huấn luyện các mô hình với tìm kiếm lưới của learning rate trong (1e−1,1e−2,1e−3,1e−4), batch size trong (32,64,128), và weight decay trong (1e−3,1e−4,1e−5,1e−6,0) để chọn các siêu tham số tốt nhất. Tất cả các thí nghiệm của chúng tôi được viết trong PyTorch và được tiến hành trên một GPU Tesla V-100 duy nhất. Đối với thiết lập huấn luyện trước có giám sát đầy đủ, chúng tôi khởi tạo các mô hình với trọng số ImageNet. Trong trường hợp thiết lập huấn luyện trước tự giám sát, chúng tôi khởi tạo các mô hình sử dụng trọng số BYOL hoặc MoCov2 (trên ImageNet). Đối với các thí nghiệm của chúng tôi trên tập dữ liệu đa miền DomainNet, chúng tôi khởi tạo các mô hình của chúng tôi với trọng số ImageNet.

**Thiết lập Huấn luyện cho Mô hình Nguồn (Tác vụ Phân đoạn Ngữ nghĩa).** Chúng tôi huấn luyện các mô hình nguồn sử dụng hàm mất cross-entropy theo pixel và tối ưu hóa nó sử dụng Stochastic Gradient Descent (SGD) với momentum. Các siêu tham số quan trọng nhất ở đây là learning rate, batch size và weight decay. Chúng tôi huấn luyện các mô hình với tìm kiếm lưới của learning rate trong (1e−1,1e−2,1e−3,1e−4), batch size trong (32,64,128), và weight decay trong (1e−3,1e−4,1e−5,1e−6,0), và chọn các siêu tham số tốt nhất. Tất cả những thí nghiệm này cũng được viết trong PyTorch và tiến hành trên một GPU Tesla V-100 duy nhất. Chúng tôi khởi tạo các mô hình nguồn sử dụng trọng số được huấn luyện trước COCO.

**Triển khai Mô hình Nguồn và Baseline.** Chúng tôi sử dụng các mô hình mã nguồn mở có sẵn thông qua Thư viện PyTorch cho các tác vụ phân loại và phân đoạn ngữ nghĩa. Chúng tôi sử dụng Thư viện PyTorch Lightning để có được trọng số mô hình cho thiết lập huấn luyện trước tự giám sát. Chúng tôi sử dụng mã được phát hành bởi các bài báo tương ứng để tính toán điểm số OTCE [59], MS-LEEP, E-LEEP, IoU-EEP và SoftIoU-EEP [1].

**Đánh giá Hiệu suất Ensemble.** Chúng tôi tuân theo giao thức trong [1] để tính toán độ chính xác thực tế của các ensemble. Chúng tôi tinh chỉnh (cả bộ trích xuất đặc trưng và bộ phân loại của) tất cả các mô hình nguồn có mặt trong ensemble sử dụng tập huấn luyện đích. Sau đó, chúng tôi riêng lẻ đưa ra dự đoán sử dụng các mô hình nguồn trên tập kiểm tra đích và tính trung bình chúng để có được dự đoán ensemble cuối cùng. Chúng tôi lưu ý rằng không có mô hình được huấn luyện đích nào trong nhóm nguồn. Chúng tôi so sánh dự đoán cuối cùng này với nhãn thực tế và tính toán độ chính xác phân loại. Lưu ý rằng chúng tôi cần tinh chỉnh tất cả các mô hình nguồn chỉ một lần và có thể tái sử dụng dự đoán của chúng trên tập kiểm tra qua tất cả các kết hợp ensemble. Như đã nêu trước đây, chúng tôi báo cáo Hệ số Tương quan Pearson (PCC), Kendall τ (KT) và Weighted Kendall τ (WKT) trong kết quả của chúng tôi.

**Đánh giá trên Mô hình Được Huấn luyện Trước Có Giám sát Đầy đủ.** Chúng tôi ở đây so sánh OSBORN của chúng tôi với các chỉ số baseline, tức MS-LEEP và E-LEEP, theo ba chỉ số tương quan, WKT, KT, và PCC. Các giá trị tương quan được báo cáo trong Bảng 3. Tính trung bình qua năm tập dữ liệu đích, OSBORN cải thiện 96.36% so với MS-LEEP và 140% so với E-LEEP theo WKT; cải thiện 66.06% so với MS-LEEP và 93.16% so với E-LEEP theo KT; cải thiện 58.62% so với MS-LEEP và 75.23% so với E-LEEP theo PCC. Chúng ta có thể thấy trực quan hiệu suất tổng thể của chỉ số chúng tôi vượt trội hơn các baseline hiện có một cách đáng kể trong Hình 5.

**Đánh giá trên Mô hình Được Huấn luyện Trước Tự Giám sát.** Chúng tôi so sánh hiệu suất của phương pháp chúng tôi với các phương pháp baseline, tức MS-LEEP và E-LEEP. Chúng tôi trình bày kết quả thí nghiệm liên quan đến các hệ số tương quan khác nhau trong Bảng 4. Lưu ý rằng chúng tôi sử dụng bộ điều chỉnh chuẩn Frobenius khi giải quyết vấn đề OT vì nó mang lại kết quả tốt hơn khi so sánh với việc sử dụng các bộ điều chỉnh khác. Trong phụ lục, chúng tôi báo cáo kết quả không có bộ điều chỉnh nào và so sánh chúng với biến thể chuẩn Frobenius. Bảng 4 cho thấy rằng, tính trung bình qua năm tập dữ liệu đích, OSBORN cải thiện 268.69% so với MS-LEEP và 231.82% so với E-LEEP theo WKT; cải thiện 442.10% so với MS-LEEP và 379.07% so với E-LEEP theo KT; cải thiện 527.27% so với MS-LEEP và 392.86% so với E-LEEP theo PCC.

**Hiệu suất của Ensemble Được Chọn.** Bảng 2 báo cáo độ chính xác ensemble của các mô hình được chọn thông qua OSBORN. Để hoàn thiện cuộc thảo luận này, chúng tôi cũng báo cáo cùng kết quả cho OSBORN không có tối đa hóa tham lam cũng như cho MS-LEEP và E-LEEP trong Bảng 5. Theo [1], chúng tôi trước tiên tính toán giá trị OSBORN cho mỗi ứng viên ensemble và chọn ensemble có giá trị cao nhất. Chúng tôi tuân theo chiến lược tương tự với MS-LEEP và E-LEEP để chọn mô hình tốt nhất theo giá trị của chúng. Để tính toán độ chính xác ensemble, chúng tôi sử dụng các mô hình riêng lẻ được tinh chỉnh trên tập huấn luyện đích và có được dự đoán của chúng trên tập kiểm tra đích. Chúng tôi tính trung bình những dự đoán này và so sánh chúng với nhãn thực tế để có được độ chính xác tổng thể. Chúng tôi quan sát thấy rằng ensemble được chọn bởi OSBORN đạt được độ chính xác kiểm tra cao nhất qua tất cả các tập dữ liệu. Trong trường hợp cả thiết lập có giám sát đầy đủ và tự giám sát, các phương pháp baseline, tức MS-LEEP và E-LEEP, chọn cùng ensemble (mặc dù có các giá trị tương quan khác nhau) trong mỗi trường hợp, đó là lý do tại sao chúng có được cùng độ chính xác ensemble.

**Mở rộng Số lượng Mô hình trong Ensemble.** Như đã hiển thị trước đây trong phần này (Hình 4), chúng tôi thấy hiệu suất bão hòa sau kích thước ensemble là 3 trong các tập dữ liệu được xem xét trong công trình này cũng như trong [1]. Mặt khác, chúng tôi cũng quan sát một cách không ngạc nhiên rằng chi phí lựa chọn ensemble có thể tăng lên đáng kể khi kích thước ensemble tăng. Chúng tôi cho thấy hiệu suất chi phí của các mô hình được chọn cho tập dữ liệu Caltech101 trong Hình 6. Mặc dù xu hướng tăng, chúng tôi lưu ý rằng thời gian cần thiết vẫn trong khoảng giây, điều này làm cho chỉ số OSBORN đề xuất thực tế và liên quan.

**Nghiên cứu Ablation.** Chúng tôi đã tiến hành các thí nghiệm bổ sung để hiểu ảnh hưởng của từng thành phần trong OSBORN (được bao gồm trong Phụ lục). Nói chung, trong khi việc cộng đơn giản của ba đại lượng trong OSBORN không có trọng số nào vượt trội hơn các phương pháp trước đây, chúng tôi quan sát thấy rằng những điều này có thể được tinh chỉnh thông qua tìm kiếm lưới trên một phạm vi giá trị lớn hơn để có được ước lượng khả năng chuyển giao thậm chí tốt hơn. Tuy nhiên điều này thay đổi với tập dữ liệu đích. Trên Caltech101 như tập dữ liệu đích, chúng tôi nhận thấy rằng việc cho trọng số nhiều hơn cho WD so với hai thuật ngữ khác (WT và WC) đạt được điểm số tương quan cao hơn, như được hiển thị trong Hình 7. Điều này có thể là do sự đa dạng rộng lớn của hình ảnh trong tập dữ liệu này. WD đo lường sự không khớp không gian tiềm ẩn giữa những hình ảnh đa dạng như vậy với các tập dữ liệu nguồn (có thể không có hình ảnh/biểu diễn chồng chéo với tập đích), điều này có lợi trong trường hợp này. Phân tích chi tiết hơn được cung cấp trong Phụ lục.

## Kết luận

Trong bài báo này, chúng tôi đề xuất một chỉ số ước lượng khả năng chuyển giao dựa trên optimal transport mới, OSBORN, được thiết kế cẩn thận cho các ensemble xem xét nhiều yếu tố, như sự không khớp trong không gian tiềm ẩn, không gian nhãn, và tính gắn kết giữa các mô hình riêng lẻ trong ensemble. Chúng tôi cho thấy rằng chỉ số đề xuất có thể được xử lý như một vấn đề tối ưu hóa submodular, cho phép chúng tôi tận dụng chiến lược tham lam cho việc lựa chọn ensemble mô hình nguồn. Chúng tôi cho thấy thực nghiệm rằng chỉ số của chúng tôi vượt trội hơn các chỉ số hiện có MS-LEEP và E-LEEP qua các tác vụ trên nhiều chỉ số tương quan. Các hướng tương lai bao gồm tăng hiệu quả tính toán của phương pháp này, cũng như nghiên cứu khả năng áp dụng của nó cho các tác vụ và thiết lập vấn đề khác.

## Lời cảm ơn

Công trình này được hỗ trợ một phần bởi KLA và Bộ Khoa học và Công nghệ, Ấn Độ thông qua chương trình DST ICPS Data Science Cluster. Chúng tôi muốn cảm ơn các tác giả của [1] cho những cuộc thảo luận sâu sắc. Hơn nữa, chúng tôi cảm ơn các nhà đánh giá ẩn danh vì phản hồi có giá trị của họ đã cải thiện việc trình bày bài báo này.

## Tài liệu Tham khảo

[1] Andrea Agostinelli, Jasper Uijlings, Thomas Mensink, và Vittorio Ferrari. Transferability metrics for selecting source model ensembles. In 2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 7926–7936, 2022.

[2] Khurshed Ali, Chih-Yu Wang, và Yi-Shin Chen. Leveraging transfer learning in reinforcement learning to tackle competitive influence maximization. Knowledge and Information Systems, 64:2059–2090, 2022.

[3] Hossein Azizpour, Ali Sharif Razavian, Josephine Sullivan, Atsuto Maki, và Stefan Carlsson. Factors of transferability for a generic convnet representation. IEEE Transactions on Pattern Analysis and Machine Intelligence, 38(9):1790–1802, 2016.

[4] Francis Bach. Learning with submodular functions: A convex optimization perspective. Foundations and Trends in Machine Learning, 6(2-3):145–373, 2013.

[5] Adrià Puigdomènech Badia, Pablo Sprechmann, Alex Vitvitskyi, Daniel Guo, Bilal Piot, Steven Kapturowski, Olivier Tieleman, Martín Arjovsky, Alexander Pritzel, Andew Bolt, và Charles Blundell. Never give up: Learning directed exploration strategies. 8th International Conference on Learning Representations, 2020, Addis Ababa, Ethiopia, April 26-30, 2020, 2020.

[6] Yajie Bao, Yang Li, Shao-Lun Huang, Lin Zhang, Lizhong Zheng, Amir Zamir, và Leonidas J. Guibas. An information-theoretic approach to transferability in task transfer learning. In 2019 IEEE International Conference on Image Processing, 2019, Taipei, Taiwan, September 22-25, 2019, pages 2309–2313. IEEE, 2019.

[7] L. Breiman. Bagging predictors. Machine Learning, 24:123–140, 2004.

[8] Gabriel J. Brostow, Julien Fauqueur, và Roberto Cipolla. Semantic object classes in video: A high-definition ground truth database. Pattern Recognition Letters, 30(2):88–97, 2009. Video-based Object and Event Analysis.

[9] Xinlei Chen, Haoqi Fan, Ross B. Girshick, và Kaiming He. Improved baselines with momentum contrastive learning. CoRR, abs/2003.04297, 2020.

[10] Marius Cordts, Mohamed Omran, Sebastian Ramos, Timo Rehfeld, Markus Enzweiler, Rodrigo Benenson, Uwe Franke, Stefan Roth, và Bernt Schiele. The cityscapes dataset for semantic urban scene understanding. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, June 2016.

[11] Marco Cuturi. Sinkhorn distances: Lightspeed computation of optimal transport. In C.J. Burges, L. Bottou, M. Welling, Z. Ghahramani, và K.Q. Weinberger, editors, Advances in Neural Information Processing Systems, volume 26. Curran Associates, Inc., 2013.

[12] Jacob Devlin, Ming-Wei Chang, Kenton Lee, và Kristina N. Toutanova. Bert: Pre-training of deep bidirectional transformers for language understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019, Minneapolis, MN, USA, June 2-7, 2019, Volume 1 (Long and Short Papers), pages 4171–4186. Association for Computational Linguistics, 2019.

[13] Zheng Dong, Ke Xu, Yin Yang, Hujun Bao, Weiwei Xu, và Rynson W.H. Lau. Location-aware single image reflection removal. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 5017–5026, October 2021.

[14] Kshitij Dwivedi và Gemma Roig. Representation similarity analysis for efficient task taxonomy & transfer learning. In 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 12379–12388, 2019.

[15] Linus Ericsson, Henry Gouk, và Timothy M. Hospedales. How well do self-supervised models transfer? In 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 5410–5419, 2021.

[16] Li Fei-Fei, R. Fergus, và P. Perona. Learning generative visual models from few training examples: An incremental bayesian approach tested on 101 object categories. In 2004 Conference on Computer Vision and Pattern Recognition Workshop, pages 178–178, 2004.

[17] Sira Ferradans, Nicolas Papadakis, Gabriel Peyré, và Jean-François Aujol. Regularized discrete optimal transport. SIAM Journal on Imaging Sciences, 7(3):1853–1882, 2014.

[18] Yoav Freund và Robert E Schapire. A decision-theoretic generalization of on-line learning and an application to boosting. Journal of Computer and System Sciences, 55(1):119–139, 1997.

[19] Mudasir A. Ganaie, Minghui Hu, Mohammad Tanveer, và Ponnuthurai N. Suganthan. Ensemble deep learning: A review. Engineering Applications of Artificial Intelligence, 115:105151, 2022.

[20] Ross Girshick, Jeff Donahue, Trevor Darrell, và Jitendra Malik. Rich feature hierarchies for accurate object detection and semantic segmentation. In 2014 IEEE Conference on Computer Vision and Pattern Recognition, pages 580–587, 2014.

[21] Jean-Bastien Grill, Florian Strub, Florent Altché, Corentin Tallec, Pierre Richemond, Elena Buchatskaya, Carl Doersch, Bernardo Avila Pires, Zhaohan Guo, Mohammad Gheshlaghi Azar, Bilal Piot, koray kavukcuoglu, Remi Munos, và Michal Valko. Bootstrap your own latent - a new approach to self-supervised learning. In H. Larochelle, M. Ranzato, R. Hadsell, M.F. Balcan, và H. Lin, editors, Advances in Neural Information Processing Systems, volume 33, pages 21271–21284. Curran Associates, Inc., 2020.

[22] L.K. Hansen và P. Salamon. Neural network ensembles. IEEE Transactions on Pattern Analysis and Machine Intelligence, 12(10):993–1001, 1990.

[23] Marton Havasi, Rodolphe Jenatton, Stanislav Fort, Jeremiah Zhe Liu, Jasper Snoek, Balaji Lakshminarayanan, Andrew M Dai, và Dustin Tran. Training independent subnetworks for robust prediction. International Conference on Learning Representations, 2020.

[24] Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, và Ross Girshick. Momentum contrast for unsupervised visual representation learning. In 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 9726–9735, 2020.

[25] Kaiming He, Xiangyu Zhang, Shaoqing Ren, và Jian Sun. Deep residual learning for image recognition. In 2016 IEEE Conference on Computer Vision and Pattern Recognition, pages 770–778, 2016.

[26] Andrew G. Howard, Mark Sandler, Grace Chu, Liang-Chieh Chen, Bo Chen, Mingxing Tan, Weijun Wang, Yukun Zhu, Ruoming Pang, Vijay Vasudevan, Quoc V. Le, và Hartwig Adam. Searching for mobilenetv3. 2019 IEEE/CVF International Conference on Computer Vision, pages 1314–1324, 2019.

[27] Jeremy Howard và Sylvain Gugger. Fastai: A layered api for deep learning. Information, 11(2), 2020.

[28] Gao Huang, Zhuang Liu, và Kilian Q. Weinberger. Densely connected convolutional networks. 2017 IEEE Conference on Computer Vision and Pattern Recognition, pages 2261–2269, 2017.

[29] Md Jahidul Islam, Chelsey Edge, Yuyang Xiao, Peigen Luo, Muntaqim Mehtaz, Christopher Morse, Sadman Sakib Enan, và Junaed Sattar. Semantic Segmentation of Underwater Imagery: Dataset and Benchmark. In IEEE/RSJ International Conference on Intelligent Robots and Systems. IEEE/RSJ, 2020.

[30] Rishabh Iyer và Jeff Bilmes. Submodular optimization with submodular cover and submodular knapsack constraints. volume 26 of Advances in neural information processing systems, page 2436–2444, Red Hook, NY, USA, 2013. Curran Associates Inc.

[31] M. G. Kendall. A new measure of rank correlation. Biometrika, 30(1-2):81–93, 06 1938.

[32] Aditya Khosla, Nityananda Jayadevaprakash, Bangpeng Yao, và Li Fei-Fei. Novel dataset for fine-grained image categorization. In First Workshop on Fine-Grained Visual Categorization, IEEE Conference on Computer Vision and Pattern Recognition, Colorado Springs, CO, June 2011.

[33] Simon Kornblith, Jonathon Shlens, và Quoc V. Le. Do better imagenet models transfer better? In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, June 2019.

[34] Jonathan Krause, Michael Stark, Jia Deng, và Li Fei-Fei. 3d object representations for fine-grained categorization. In 4th International IEEE Workshop on 3D Representation and Recognition (3dRR-13), Sydney, Australia, 2013.

[35] Alex Krizhevsky. Learning multiple layers of features from tiny images. University of Toronto, 05 2012.

[36] Alex Krizhevsky, Ilya Sutskever, và Geoffrey E. Hinton. Imagenet classification with deep convolutional neural networks. Communications of the ACM, 60:84 – 90, 2012.

[37] Alex Krizhevsky, Ilya Sutskever, và Geoffrey E Hinton. Imagenet classification with deep convolutional neural networks. In Advances in Neural Information Processing Systems, volume 25. Curran Associates, Inc., 2012.

[38] Tsung-Yi Lin, Michael Maire, Serge J. Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Dollár, và C. Lawrence Zitnick. Microsoft coco: Common objects in context. In Computer Vision - ECCV 2014 - 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part V, volume 8693, pages 740–755, 2014.

[39] Thomas Mensink, Jasper Reinout Robertus Uijlings, Alina Kuznetsova, Michael Gygli, và Vittorio Ferrari. Factors of influence for transfer learning across diverse appearance domains and task types. Transactions on Pattern Analysis and Machine Intelligence, 2021.

[40] Roozbeh Mottaghi, Xianjie Chen, Xiaobai Liu, Nam-Gyu Cho, Seong-Whan Lee, Sanja Fidler, Raquel Urtasun, và Alan Yuille. The role of context for object detection and semantic segmentation in the wild. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, June 2014.

[41] Basil Mustafa, Aaron Loh, Jana von Freyberg, Patricia MacWilliams, Megan Wilson, Scott Mayer McKinney, Marcin Sieniek, Jim Winkens, Yuan Liu, Peggy Bui, Shruthi Prabhakara, Umesh Telang, Alan Karthikesalingam, Neil Houlsby, và Vivek Natarajan. Supervised transfer learning at scale for medical imaging. ArXiv, abs/2101.05913, 2021.

[42] George Nemhauser, Laurence Wolsey, và M. Fisher. An analysis of approximations for maximizing submodular set functions—i. Mathematical Programming, 14:265–294, 12 1978.

[43] Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo Wu, và Andrew Ng. Reading digits in natural images with unsupervised feature learning. Twenty-fifth Conference on Neural Information Processing Systems Workshop on Deep Learning and Unsupervised Feature Learning, 01 2011.

[44] Gerhard Neuhold, Tobias Ollmann, Samuel Rota Bulo, và Peter Kontschieder. The mapillary vistas dataset for semantic understanding of street scenes. In Proceedings of the IEEE International Conference on Computer Vision, Oct 2017.

[45] Cuong V Nguyen, Tal Hassner, C. Archambeau, và Matthias W. Seeger. Leep: A new measure to evaluate transferability of learned representations. In International Conference on Machine Learning, 2020.

[46] Maria-Elena Nilsback và Andrew Zisserman. Automated flower classification over a large number of classes. In 2008 Sixth Indian Conference on Computer Vision, Graphics & Image Processing, pages 722–729, 2008.

[47] Yaniv Ovadia, Emily Fertig, Jie Ren, Zachary Nado, D. Sculley, Sebastian Nowozin, Joshua V. Dillon, Balaji Lakshminarayanan, và Jasper Snoek. Can You Trust Your Model's Uncertainty? Evaluating Predictive Uncertainty under Dataset Shift. Proceedings of the 33rd International Conference on Neural Information Processing Systems, 2019.

[48] Michal Pándy, Andrea Agostinelli, Jasper R. R. Uijlings, Vittorio Ferrari, và Thomas Mensink. Transferability estimation using bhattacharyya class separability. 2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition, abs/2111.12780:9162–9172, 2021.

[49] Omkar M. Parkhi, Andrea Vedaldi, Andrew Zisserman, và C. V. Jawahar. Cats and dogs. 2012 IEEE Conference on Computer Vision and Pattern Recognition, pages 3498–3505, 2012.

[50] Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas Kopf, Edward Yang, Zachary DeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang, Junjie Bai, và Soumith Chintala. Pytorch: An imperative style, high-performance deep learning library. In H. Wallach, H. Larochelle, A. Beygelzimer, F. d'Alché-Buc, E. Fox, và R. Garnett, editors, Advances in Neural Information Processing Systems, volume 32. Curran Associates, Inc., 2019.

[51] Xingchao Peng, Qinxun Bai, Xide Xia, Zijun Huang, Kate Saenko, và Bo Wang. Moment matching for multi-source domain adaptation. In 2019 IEEE/CVF International Conference on Computer Vision, pages 1406–1415, 2019.

[52] Alain Rakotomamonjy, Rémi Flamary, và Nicolas Courty. Generalized conditional gradient: analysis of convergence and applications. CoRR, abs/1510.06567, 2015.

[53] Shaoqing Ren, Kaiming He, Ross Girshick, và Jian Sun. Faster r-cnn: Towards real-time object detection with region proposal networks. IEEE Transactions on Pattern Analysis and Machine Intelligence, 39(6):1137–1149, 2017.

[54] Noam Shazeer, Azalia Mirhoseini, Krzysztof Maziarz, Andy Davis, Quoc V. Le, Geoffrey E. Hinton, và Jeff Dean. Outrageously large neural networks: The sparsely-gated mixture-of-experts layer. 5th International Conference on Learning Representations, 2017, Toulon, France, April 24-26, 2017, Conference Track Proceedings, 2017.

[55] Evan Shelhamer, Jonathan Long, và Trevor Darrell. Fully convolutional networks for semantic segmentation. 2015 IEEE Conference on Computer Vision and Pattern Recognition, pages 3431–3440, 2015.

[56] Jie Song, Yixin Chen, Xinchao Wang, Chengchao Shen, và Mingli Song. Deep model transferability from attribution maps. In H. Wallach, H. Larochelle, A. Beygelzimer, F. d'Alché-Buc, E. Fox, và R. Garnett, editors, Advances in Neural Information Processing Systems, volume 32. Curran Associates, Inc., 2019.

[57] Jie Song, Yixin Chen, Jingwen Ye, Xinchao Wang, Chengchao Shen, Feng Mao, và Mingli Song. Depara: Deep attribution graph for deep knowledge transferability. 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 3921–3929, 2020.

[58] Shuran Song, Samuel P. Lichtenberg, và Jianxiong Xiao. Sun rgb-d: A rgb-d scene understanding benchmark suite. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, June 2015.

[59] Yang Tan, Yang Li, và Shao-Lun Huang. Otce: A transferability metric for cross-domain cross-task representations. In 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 15774–15783, 2021.

[60] Anh Tran, Cuong Nguyen, và Tal Hassner. Transferability and hardness of supervised classification tasks. In 2019 IEEE/CVF International Conference on Computer Vision, pages 1395–1405, 2019.

[61] Matias Valdenegro-Toro. Deep sub-ensembles for fast uncertainty estimation in image classification. Bayesian Deep Learning Workshop at Thirty-third Conference on Neural Information Processing Systems, 2019, abs/1910.08168, 2019.

[62] Girish Varma, Anbumani Subramanian, Anoop Namboodiri, Manmohan Chandraker, và C.V. Jawahar. Idd: A dataset for exploring problems of autonomous navigation in unconstrained environments. In 2019 IEEE Winter Conference on Applications of Computer Vision, pages 1743–1751, 2019.

[63] Sebastiano Vigna. A weighted correlation index for rankings with ties. Proceedings of the 24th International Conference on World Wide Web, 2015.

[64] Paul Viola và Michael Jones. Rapid object detection using a boosted cascade of simple features. In Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2001, volume 1, pages I–I. Ieee, 2001.

[65] Xiaofang Wang, Dan Kondratyuk, Eric Christiansen, Kris M. Kitani, Yair Movshovitz-Attias, và Elad Eban. Wisdom of committees: An overlooked approach to faster and more accurate models. In International Conference on Learning Representations, 2022.

[66] Kai Wei, Rishabh K. Iyer, và Jeff A. Bilmes. Submodularity in data subset selection and active learning. In Francis R. Bach và David M. Blei, editors, International Conference on Machine Learning, volume 37, pages 1954–1963, 2015.

[67] P. Welinder, S. Branson, T. Mita, C. Wah, F. Schroff, S. Belongie, và P. Perona. Caltech-UCSD Birds 200. Technical Report CNS-TR-2010-001, California Institute of Technology, 2010.

[68] Han Xiao, Kashif Rasul, và Roland Vollgraf. Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms. CoRR, 08 2017.

[69] Yongquan Yang, Haijun Lv, và Ning Chen. A survey on ensemble learning under the era of deep learning. Artificial Intelligence Review, nov 2022.

[70] Jason Yosinski, Jeff Clune, Yoshua Bengio, và Hod Lipson. How transferable are features in deep neural networks? Conference on Neural Information Processing Systems, 2014.

[71] Kaichou You, Yong Liu, Mingsheng Long, và Jianmin Wang. Logme: Practical assessment of pre-trained models for transfer learning. In International Conference on Machine Learning, 02 2021.

[72] Fisher Yu, Haofeng Chen, Xin Wang, Wenqi Xian, Yingying Chen, Fangchen Liu, Vashisht Madhavan, và Trevor Darrell. Bdd100k: A diverse driving dataset for heterogeneous multitask learning. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, June 2020.

[73] Amir R. Zamir, Alexander Sax, William Shen, Leonidas Guibas, Jitendra Malik, và Silvio Savarese. Taskonomy: Disentangling task transfer learning. In 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 3712–3722, 2018.

[74] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, và Jiaya Jia. Pyramid scene parsing network. In 2017 IEEE Conference on Computer Vision and Pattern Recognition, pages 6230–6239, 2017.

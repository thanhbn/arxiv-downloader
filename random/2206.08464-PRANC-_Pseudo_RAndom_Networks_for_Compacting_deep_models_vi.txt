# 2206.08464.pdf
# Chuyá»ƒn Ä‘á»•i tá»« PDF sang TXT
# ÄÆ°á»ng dáº«n nguá»“n: /home/admin88/arxiv-downloader/random/2206.08464.pdf
# KÃ­ch thÆ°á»›c tá»‡p: 49832256 bytes

===============================================
Ná»˜I DUNG Tá»†P PDF
===============================================

--- TRANG 1 ---
PRANC: Máº¡ng Giáº£ Ngáº«u NhiÃªn Ä‘á»ƒ NÃ©n Compact cÃ¡c mÃ´ hÃ¬nh há»c sÃ¢u
Parsa Nooralinejad
Äáº¡i há»c California, DavisAli Abbasi
Äáº¡i há»c VanderbiltSoroush Abbasi Koohpayegani*
Äáº¡i há»c California, Davis
Kossar Pourahmadi Meibodi*
Äáº¡i há»c California, DavisRana Muhammad Shahroz Khan*
Äáº¡i há»c Vanderbilt
Soheil Kolouri
Äáº¡i há»c VanderbiltHamed Pirsiavash
Äáº¡i há»c California, Davis
TÃ³m táº¯t
ChÃºng tÃ´i chá»©ng minh ráº±ng má»™t mÃ´ hÃ¬nh há»c sÃ¢u cÃ³ thá»ƒ Ä‘Æ°á»£c tÃ¡i tham sá»‘ hÃ³a nhÆ° má»™t tá»• há»£p tuyáº¿n tÃ­nh cá»§a nhiá»u mÃ´ hÃ¬nh há»c sÃ¢u Ä‘Æ°á»£c khá»Ÿi táº¡o ngáº«u nhiÃªn vÃ  cá»‘ Ä‘á»‹nh trong khÃ´ng gian trá»ng sá»‘. Trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n, chÃºng tÃ´i tÃ¬m kiáº¿m cÃ¡c cá»±c tiá»ƒu Ä‘á»‹a phÆ°Æ¡ng náº±m trong khÃ´ng gian con Ä‘Æ°á»£c bao trÃ¹m bá»Ÿi cÃ¡c mÃ´ hÃ¬nh ngáº«u nhiÃªn nÃ y (tá»©c lÃ , cÃ¡c máº¡ng 'cÆ¡ sá»Ÿ'). Khung cÃ´ng viá»‡c cá»§a chÃºng tÃ´i, PRANC, cho phÃ©p nÃ©n Ä‘Ã¡ng ká»ƒ má»™t mÃ´ hÃ¬nh há»c sÃ¢u. MÃ´ hÃ¬nh cÃ³ thá»ƒ Ä‘Æ°á»£c tÃ¡i táº¡o báº±ng cÃ¡ch sá»­ dá»¥ng má»™t 'háº¡t giá»‘ng' vÃ´ hÆ°á»›ng duy nháº¥t Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ táº¡o ra cÃ¡c máº¡ng 'cÆ¡ sá»Ÿ' giáº£ ngáº«u nhiÃªn, cÃ¹ng vá»›i cÃ¡c há»‡ sá»‘ há»—n há»£p tuyáº¿n tÃ­nh Ä‘Ã£ há»c. Trong cÃ¡c á»©ng dá»¥ng thá»±c táº¿, PRANC giáº£i quyáº¿t thÃ¡ch thá»©c lÆ°u trá»¯ vÃ  truyá»n thÃ´ng hiá»‡u quáº£ cÃ¡c mÃ´ hÃ¬nh há»c sÃ¢u, má»™t nÃºt tháº¯t cá»• chai phá»• biáº¿n trong nhiá»u tÃ¬nh huá»‘ng, bao gá»“m há»c Ä‘a tÃ¡c nhÃ¢n, ngÆ°á»i há»c liÃªn tá»¥c, há»‡ thá»‘ng liÃªn bang vÃ  thiáº¿t bá»‹ biÃªn, trong sá»‘ nhá»¯ng tÃ¬nh huá»‘ng khÃ¡c. Trong nghiÃªn cá»©u nÃ y, chÃºng tÃ´i sá»­ dá»¥ng PRANC Ä‘á»ƒ cÃ´ Ä‘á»ng cÃ¡c mÃ´ hÃ¬nh phÃ¢n loáº¡i hÃ¬nh áº£nh vÃ  nÃ©n hÃ¬nh áº£nh báº±ng cÃ¡ch nÃ©n cÃ¡c máº¡ng nÆ¡-ron áº©n liÃªn quan cá»§a chÃºng. PRANC vÆ°á»£t trá»™i hÆ¡n cÃ¡c phÆ°Æ¡ng phÃ¡p cÆ¡ báº£n vá»›i má»™t biÃªn Ä‘á»™ lá»›n trong phÃ¢n loáº¡i hÃ¬nh áº£nh khi nÃ©n má»™t mÃ´ hÃ¬nh há»c sÃ¢u gáº§n 100 láº§n. HÆ¡n ná»¯a, chÃºng tÃ´i cho tháº¥y ráº±ng PRANC cho phÃ©p suy luáº­n tiáº¿t kiá»‡m bá»™ nhá»› báº±ng cÃ¡ch táº¡o ra cÃ¡c trá»ng sá»‘ tá»«ng lá»›p má»™t cÃ¡ch linh hoáº¡t. MÃ£ nguá»“n cá»§a PRANC á»Ÿ Ä‘Ã¢y: https://github.com/UCDvision/PRANC

1. Giá»›i thiá»‡u
Quan niá»‡m phá»• biáº¿n lÃ  cÃ¡c mÃ´ hÃ¬nh há»c sÃ¢u lá»›n hÆ¡n mang láº¡i Ä‘á»™ chÃ­nh xÃ¡c tá»‘t hÆ¡n. Tuy nhiÃªn, váº«n chÆ°a rÃµ liá»‡u kháº£ nÄƒng tá»•ng quÃ¡t hÃ³a tá»‘t hÆ¡n cá»§a cÃ¡c mÃ´ hÃ¬nh lá»›n hÆ¡n xuáº¥t phÃ¡t tá»« sá»± phá»©c táº¡p gia tÄƒng cá»§a kiáº¿n trÃºc hay nhiá»u tham sá»‘ hÆ¡n. HÆ¡n ná»¯a, trong sá»‘ nhiá»u cá»±c tiá»ƒu Ä‘á»‹a phÆ°Æ¡ng tá»‘t trong hÃ m máº¥t mÃ¡t, viá»‡c huáº¥n luyá»‡n tÃ¬m ra má»™t cÃ¡i. Trong bÃ i bÃ¡o nÃ y, chÃºng tÃ´i giá»›i thiá»‡u má»™t cÃ¡ch tiáº¿p cáº­n má»›i: xem má»™t mÃ´ hÃ¬nh há»c sÃ¢u nhÆ° má»™t tá»• há»£p tuyáº¿n tÃ­nh trong khÃ´ng gian trá»ng sá»‘ cá»§a nhiá»u mÃ´ hÃ¬nh Ä‘Æ°á»£c khá»Ÿi táº¡o ngáº«u nhiÃªn vÃ  cá»‘ Ä‘á»‹nh. Trong quÃ¡ trÃ¬nh há»c, má»¥c tiÃªu cá»§a chÃºng tÃ´i chuyá»ƒn sang tÃ¬m kiáº¿m má»™t cá»±c tiá»ƒu tá»“n táº¡i trong khÃ´ng gian con Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh bá»Ÿi cÃ¡c mÃ´ hÃ¬nh ban Ä‘áº§u nÃ y. Nhá»¯ng phÃ¡t hiá»‡n cá»§a chÃºng tÃ´i lÃ m ná»•i báº­t tiá»m nÄƒng nÃ©n Ä‘Ã¡ng ká»ƒ cÃ¡c mÃ´ hÃ¬nh há»c sÃ¢u báº±ng cÃ¡ch chá»‰ giá»¯ láº¡i giÃ¡ trá»‹ háº¡t giá»‘ng cá»§a trÃ¬nh táº¡o giáº£ ngáº«u nhiÃªn vÃ  cÃ¡c há»‡ sá»‘ cho viá»‡c káº¿t há»£p trá»ng sá»‘.

Viá»‡c tÃ¡i tham sá»‘ hÃ³a hiá»‡u quáº£ nÃ y mang láº¡i lá»£i Ã­ch cho cÃ¡c á»©ng dá»¥ng AI vÃ  ML báº±ng cÃ¡ch giáº£m kÃ­ch thÆ°á»›c mÃ´ hÃ¬nh há»c sÃ¢u Ä‘á»ƒ lÆ°u trá»¯ hoáº·c truyá»n thÃ´ng dá»… dÃ ng hÆ¡n. Trong cÃ¡c máº¡ng nÆ¡-ron hiá»‡n Ä‘áº¡i vá»›i hÃ ng triá»‡u Ä‘áº¿n hÃ ng tá»· tham sá»‘, viá»‡c lÆ°u trá»¯ vÃ  truyá»n thÃ´ng trá»Ÿ nÃªn tá»‘n kÃ©m. Váº¥n Ä‘á» nÃ y trá»Ÿ nÃªn tá»“i tá»‡ hÆ¡n trong mÃ´i trÆ°á»ng cÃ³ tá»‘c Ä‘á»™ bit tháº¥p do cÃ¡c rÃ ng buá»™c váº­t lÃ½ hoáº·c giÃ¡n Ä‘oáº¡n Ä‘á»‘i nghá»‹ch. VÃ­ dá»¥, cÃ¡c á»©ng dá»¥ng dÆ°á»›i nÆ°á»›c cÃ³ thá»ƒ cÃ³ bÄƒng thÃ´ng tháº¥p Ä‘áº¿n 100 bit má»—i giÃ¢y, khi Ä‘Ã³, viá»‡c truyá»n mÃ´ hÃ¬nh ResNet18 vá»›i 11 triá»‡u tham sá»‘ máº¥t hÆ¡n 40 ngÃ y trong Ä‘iá»u kiá»‡n nhÆ° váº­y. HÆ¡n ná»¯a, trong há»c phÃ¢n tÃ¡n vá»›i nhiá»u tÃ¡c nhÃ¢n, cÃ¡c máº¡ng WiFi bÄƒng thÃ´ng cao váº«n gáº·p pháº£i váº¥n Ä‘á» táº¯c ngháº½n.

NgoÃ i truyá»n thÃ´ng, viá»‡c táº£i hoáº·c lÆ°u trá»¯ cÃ¡c mÃ´ hÃ¬nh lá»›n nÃ y trÃªn thiáº¿t bá»‹ biÃªn Ä‘áº·t ra má»™t thÃ¡ch thá»©c Ä‘Ã¡ng ká»ƒ khÃ¡c. Thiáº¿t bá»‹ biÃªn thÆ°á»ng Ä‘i kÃ¨m vá»›i bá»™ nhá»› nhá» khÃ´ng phÃ¹ há»£p Ä‘á»ƒ lÆ°u trá»¯ cÃ¡c máº¡ng nÆ¡-ron lá»›n vÃ  cÃ³ thá»ƒ muá»‘n cháº¡y mÃ´ hÃ¬nh Ã­t thÆ°á»ng xuyÃªn hÆ¡n (theo yÃªu cáº§u). Do Ä‘Ã³, chÃºng cÃ³ thá»ƒ hÆ°á»Ÿng lá»£i tá»« viá»‡c nÃ©n má»™t mÃ´ hÃ¬nh há»c sÃ¢u thÃ nh Ã­t tham sá»‘ hÆ¡n Ä‘á»ƒ xÃ¢y dá»±ng mÃ´ hÃ¬nh tá»«ng lá»›p hoáº·c tháº­m chÃ­ tá»«ng kernel theo yÃªu cáº§u Ä‘á»ƒ cháº¡y má»—i láº§n suy luáº­n. Äiá»u nÃ y sáº½ dáº«n Ä‘áº¿n chi phÃ­ I/O tháº¥p hÆ¡n Ä‘Ã¡ng ká»ƒ.

NgÆ°á»i ta cÃ³ thá»ƒ nÃ©n mÃ´ hÃ¬nh báº±ng cÃ¡ch chÆ°ng cáº¥t nÃ³ thÃ nh má»™t mÃ´ hÃ¬nh nhá» hÆ¡n [18], cáº¯t tá»‰a cÃ¡c tham sá»‘ mÃ´ hÃ¬nh [29], lÆ°á»£ng tá»­ hÃ³a cÃ¡c tham sá»‘ [26], hoáº·c chia sáº» cÃ¡c trá»ng sá»‘ cÃ ng nhiá»u cÃ ng tá»‘t [40, 6]. Gáº§n Ä‘Ã¢y hÆ¡n, chÆ°ng cáº¥t táº­p dá»¯ liá»‡u [48] Ä‘Æ°á»£c Ä‘á» xuáº¥t. NÃ³ cÃ³ thá»ƒ Ä‘Æ°á»£c xem nhÆ° má»™t thay tháº¿ cho nÃ©n mÃ´ hÃ¬nh vÃ¬ ngÆ°á»i ta cÃ³ thá»ƒ lÆ°u trá»¯ hoáº·c truyá»n thÃ´ng táº­p dá»¯ liá»‡u Ä‘Ã£ chÆ°ng cáº¥t vÃ  sau Ä‘Ã³ huáº¥n luyá»‡n láº¡i mÃ´ hÃ¬nh khi cáº§n thiáº¿t. Tuy nhiÃªn, háº§u háº¿t

--- TRANG 2 ---
Máº¡ng CÆ¡ sá»Ÿ Ngáº«u nhiÃªnNhiá»‡m vá»¥ Huáº¥n luyá»‡n
ğ›¼
1Ã—+
ğ›¼
2Ã—+
ğ›¼
ğ‘˜Ã—
HÃ¬nh 2. MÃ´ hÃ¬nh Äe dá»a Táº¥n cÃ´ng CÃ³ má»¥c tiÃªu: Äáº§u tiÃªn mÃ´ hÃ¬nh tá»± giÃ¡m sÃ¡t Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn táº­p dá»¯ liá»‡u khÃ´ng cÃ³ nhÃ£n bá»‹ Ä‘áº§u Ä‘á»™c. CÃ¡c kÃ­ch hoáº¡t Ä‘Æ°á»£c thÃªm vÃ o hÃ¬nh áº£nh cá»§a Rottweiler lÃ  danh má»¥c má»¥c tiÃªu. Sau Ä‘Ã³ chÃºng tÃ´i huáº¥n luyá»‡n má»™t bá»™ phÃ¢n loáº¡i tuyáº¿n tÃ­nh trÃªn Ä‘áº§u embedding mÃ´ hÃ¬nh tá»± giÃ¡m sÃ¡t cho má»™t nhiá»‡m vá»¥ giÃ¡m sÃ¡t xuÃ´i dÃ²ng. Táº¡i thá»i Ä‘iá»ƒm kiá»ƒm tra, bá»™ phÃ¢n loáº¡i tuyáº¿n tÃ­nh cÃ³ Ä‘á»™ chÃ­nh xÃ¡c cao trÃªn hÃ¬nh áº£nh sáº¡ch nhÆ°ng phÃ¢n loáº¡i sai nhá»¯ng hÃ¬nh áº£nh tÆ°Æ¡ng tá»± nhÆ° Rottweiler khi kÃ­ch hoáº¡t Ä‘Æ°á»£c dÃ¡n vÃ o chÃºng. ual ins pe ction tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i viá»‡c chÃº thÃ­ch toÃ n bá»™ dá»¯ liá»‡u itself . VÃ­ dá»¥, chÃºng ta cháº¯c cháº¯n ráº±ng khÃ´ng ai Ä‘Ã£ ins pe cted má»™t tá»· hÃ¬nh áº£nh ngáº«u nhiÃªn, khÃ´ng cÃ³ nhÃ£n vÃ  khÃ´ng Ä‘Æ°á»£c chá»n lá»c cá»§a cÃ´ng chÃºng Ins ta -gram sá»­ dá»¥ng trong viá»‡c huáº¥n luyá»‡n SEER Ä‘á»ƒ Ä‘áº£m báº£o táº­p lá»‡nh thu tháº­p dá»¯ liá»‡u Ä‘Ã£ khÃ´ng táº£i xuá»‘ng nhá»¯ng cháº¥t Ä‘á»™c Ä‘Æ°á»£c thao tÃºng bá»Ÿi káº» táº¥n cÃ´ng. Do Ä‘Ã³, nhu cáº§u lÃ m viá»‡c vá»›i dá»¯ liá»‡u la rger vÃ  Ä‘a dáº¡ng hÆ¡n Ä‘á»ƒ loáº¡i bá» thiÃªn lá»‡ch dá»¯ liá»‡u vÃ  giáº£m chi phÃ­ la be ling cÅ©ng cÃ³ thá»ƒ unknowingly thiáº¿t láº­p nhiá»u cÃ¡ch thá»©c hÆ¡n cho adversaries. Augmentations trong exemplar-based SSL : Mos t recent thÃ nh cÃ´ng ful SSL methods lÃ  exempla r-based, e.g. MoCov2, BYOL, Si mCL R, MS F[3,19,23,36]. Core ide a lÃ  pull embedding cá»§a hai augmentati ons khÃ¡c nhau cá»§a má»™t im-age gáº§n nhau [19] trong khi, trong má»™t sá»‘ methods, [23] al so Ä‘áº©y chÃºng xa khá»i other random ima ge s . Trong cÃ¡c methods nÃ y, ima ge augmentati on Ä‘Ã³ng vai trÃ² quan trá»ng cá»§a inductive bias mÃ  guides representation learning. Mos t methods Ä‘Ã£ cho tháº¥y ráº±ng viá»‡c sá»­ dá»¥ng augmenta-tion aggressive hÆ¡n cáº£i thiá»‡n learned representations. Má»™t ngÆ°á»i cÃ³ thá»ƒ tranh luáº­n ráº±ng táº¥n cÃ´ng cá»§a chÃºng tÃ´i hoáº¡t Ä‘á»™ng si nce trong má»™t sá»‘ it-erations, má»™t augmentati on cá»§a poisoned ima ge chá»©a trigger trong khi augmentati on khÃ¡c khÃ´ng. Sau Ä‘Ã³, Ä‘iá»u nÃ y khuyáº¿n khÃ­ch model associa te features cá»§a trigger vá»›i poisoned class, dáº«n Ä‘áº¿n viá»‡c phÃ¡t hiá»‡n poisoned classes ngay cáº£ khi khÃ´ng cÃ³ poisoned cate-gory. Tuy nhiÃªn, cÃ¡c thÃ­ nghiá»‡m controlled rá»™ng rÃ£i cá»§a chÃºng tÃ´i khÃ´ng cung cáº¥p báº±ng chá»©ng empirical cho giáº£ thuyáº¿t nÃ y. At-tack khÃ´ng hoáº¡t Ä‘á»™ng náº¿u trigger chá»‰ visible trong má»™t view (xem Secti on 5.3). ChÃºng tÃ´i hypothesize ráº±ng táº¥n cÃ´ng cá»§a chÃºng tÃ´i hoáº¡t Ä‘á»™ng do lÃ½ do follow-ing: Si nce trong learning, trigger present trÃªn target category only, model há»c appearance cá»§a trigger nhÆ° context cho target category. Si nce trig-ger cÃ³ rigid shape vá»›i very smal l variation, nÃ³ lÃ  rela-tivel y easy feature cho model learn Ä‘á»ƒ detect. Do Ä‘Ã³, model xÃ¢y dá»±ng very good detector cho trigger sao cho ngay cáº£ khi absence cá»§a other features cá»§a target cate-gory táº¡i test time, model sti l l predicts target cate-gory, dáº«n Ä‘áº¿n successful ful attack. ThÃ­ nghiá»‡m cá»§a chÃºng tÃ´i cho tháº¥y ráº±ng báº±ng poisoning chá»‰ 0.5% cá»§a unlabeled training data, má»™t SSL model nhÆ° MoCov2, BYOL, hoáº·c MS F lÃ  backdoored Ä‘á»ƒ detect target category khi trigger presented táº¡i test time. NhÆ° miti-gati on technique, chÃºng tÃ´i giá»›i thiá»‡u defense method dá»±a trÃªn knowledge distillation. NÃ³ successful l y neutralizes back-door sá»­ dá»¥ng má»™t sá»‘ clean unlabeled data. 2.Related Wor k Sel fsupervised le arning: Má»™t self-supervised method thÆ°á»ng cÃ³ hai parts: má»™t pretext task, lÃ  carefully designed task dá»±a trÃªn domain knowledge Ä‘á»ƒ automati cal l y extract supervision tá»« data, vÃ  loss function. Variety cá»§a pretext tasks Ä‘Ã£ Ä‘Æ°á»£c designed cho learn-ing representations tá»« ima ge s[8,14,31,32]. Ji gsaw[31] predicts spatial ordering cá»§a ima ge s , tÆ°Æ¡ng si mi l ar vá»›i solving jigs aw puzzles. RotNet[14] sá»­ dá»¥ng rotation angl e pre-diction task Ä‘á»ƒ learn unsupervised features. Ins ta nce discrimination Ä‘Ã£ gai ned lot cá»§a popularity nhÆ° pretext task mÃ  involves data augmentati on store-cover hai views cá»§a asi ngl e ima ge vÃ  sau Ä‘Ã³ using si m-ilarities giá»¯a chÃºng Ä‘á»ƒ learn representations. Early sel f -supervised methods sá»­ dá»¥ng los s e s nhÆ° reconstruction los s , vÃ  triplet los s . NhÆ°ng recently, ins ta nce discrimination pre-text task combined vá»›i contrastive los s(MoCo, Si m-CLR)[3,5,23] Ä‘Ã£ provided huge gai ns trong learning better visual features trong completely unsupervised manner. Me th-ods nhÆ° BYOL, Si mSia m[6] khÃ´ng use contrastive los s directly nhÆ°ng sti l l rely trÃªn ins ta nce discrimination vá»›i aug-mented views. MS F[36] generalizes BYOL nÆ¡i data2
à· 
ğœƒ
1
à· 
ğœƒ
2
à· 
ğœƒ
ğ‘˜â€¦Task Loss, â„“(ğ›¼)(vÃ­ dá»¥, Cross Entropy hoáº·c Mean Squared Error)
âˆ‡
ğ›¼
â„“ğœƒ=à·ğ‘–ğ›¼ğ‘–áˆ˜ğœƒğ‘–
áˆ˜
ğœƒ
1
áˆ˜
ğœƒ
2
áˆ˜
ğœƒ
ğ‘˜,,,â€¦LÆ°u trá»¯/Truyá»n thÃ´ng
Háº¡t giá»‘ng
ğ›¼,
Lan truyá»n ngÆ°á»£c Classification        INR â€¦
Háº¡t giá»‘ngğ‘¥ğ‘¦ğ‘…ğºğµ
HÃ¬nh 1. ChÃºng tÃ´i háº¡n cháº¿ mÃ´ hÃ¬nh há»c sÃ¢u thÃ nh má»™t tá»• há»£p tuyáº¿n tÃ­nh cá»§a k mÃ´ hÃ¬nh Ä‘Æ°á»£c khá»Ÿi táº¡o ngáº«u nhiÃªn. VÃ¬ sá»‘ lÆ°á»£ng mÃ´ hÃ¬nh Ã­t hÆ¡n nhiá»u so vá»›i kÃ­ch thÆ°á»›c cá»§a mÃ´ hÃ¬nh, viá»‡c truyá»n thÃ´ng hoáº·c lÆ°u trá»¯ cÃ¡c há»‡ sá»‘ ráº» hÆ¡n nhiá»u so vá»›i chÃ­nh mÃ´ hÃ¬nh hoáº·c dá»¯ liá»‡u. ChÃºng tÃ´i Ä‘iá»u chá»‰nh Î± Ä‘á»ƒ giáº£m thiá»ƒu máº¥t mÃ¡t cá»§a nhiá»‡m vá»¥ báº±ng cÃ¡ch sá»­ dá»¥ng lan truyá»n ngÆ°á»£c tiÃªu chuáº©n.

cÃ¡c phÆ°Æ¡ng phÃ¡p nÃ y bá»‹ giá»›i háº¡n á»Ÿ cÃ¡c yáº¿u tá»‘ giáº£m nhá», vÃ­ dá»¥, Ã­t hÆ¡n 30Ã—. NgoÃ i ra, cÃ¡c phÆ°Æ¡ng phÃ¡p chÆ°ng cáº¥t kiáº¿n thá»©c giáº£m kiáº¿n trÃºc mÃ´ hÃ¬nh xuá»‘ng má»™t cÃ¡i nhá» hÆ¡n vá»›i Ã­t lá»›p hÆ¡n, Ä‘iá»u nÃ y cÃ³ thá»ƒ háº¡n cháº¿ á»©ng dá»¥ng tÆ°Æ¡ng lai cá»§a mÃ´ hÃ¬nh Ä‘Ã³, vÃ­ dá»¥, cho viá»‡c tinh chá»‰nh tÆ°Æ¡ng lai hoáº·c há»c suá»‘t Ä‘á»i, cáº§n kiáº¿n trÃºc sÃ¢u hÆ¡n.

ChÃºng tÃ´i quan tÃ¢m Ä‘áº¿n viá»‡c nÃ©n má»™t mÃ´ hÃ¬nh há»c sÃ¢u báº±ng má»™t há»‡ sá»‘ Ä‘Ã¡ng ká»ƒ (vÃ­ dá»¥, 100Ã—) mÃ  khÃ´ng thay Ä‘á»•i kiáº¿n trÃºc cá»§a nÃ³. Ã tÆ°á»Ÿng cá»‘t lÃµi Ä‘áº±ng sau cÃ¡ch tiáº¿p cáº­n cá»§a chÃºng tÃ´i ráº¥t Ä‘Æ¡n giáº£n. ChÃºng tÃ´i rÃ ng buá»™c mÃ´ hÃ¬nh cá»§a chÃºng tÃ´i thÃ nh má»™t tá»• há»£p tuyáº¿n tÃ­nh cá»§a má»™t táº­p há»¯u háº¡n cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c khá»Ÿi táº¡o ngáº«u nhiÃªn, gá»i lÃ  cÃ¡c mÃ´ hÃ¬nh cÆ¡ sá»Ÿ. Do Ä‘Ã³, váº¥n Ä‘á» quy vá» viá»‡c tÃ¬m cÃ¡c há»‡ sá»‘ há»—n há»£p tuyáº¿n tÃ­nh tá»‘i Æ°u dáº«n Ä‘áº¿n má»™t máº¡ng cÃ³ thá»ƒ giáº£i quyáº¿t nhiá»‡m vá»¥ hiá»‡u quáº£. MÃ´ hÃ¬nh sau Ä‘Ã³ cÃ³ thá»ƒ Ä‘Æ°á»£c biá»ƒu diá»…n má»™t cÃ¡ch sÃºc tÃ­ch báº±ng háº¡t giá»‘ng (má»™t vÃ´ hÆ°á»›ng duy nháº¥t) Ä‘á»ƒ táº¡o ra cÃ¡c mÃ´ hÃ¬nh cÆ¡ sá»Ÿ giáº£ ngáº«u nhiÃªn vÃ  cÃ¡c há»‡ sá»‘ há»—n há»£p tuyáº¿n tÃ­nh (Xem HÃ¬nh 1). PhÆ°Æ¡ng phÃ¡p cá»§a chÃºng tÃ´i cÃ³ thá»ƒ Ä‘Æ°á»£c xem nhÆ° má»™t cÃ¡ch tÃ¡i tham sá»‘ hÃ³a má»›i láº¡ cá»§a má»™t mÃ´ hÃ¬nh há»c sÃ¢u mÃ  khÃ´ng thay Ä‘á»•i kiáº¿n trÃºc cá»§a nÃ³. Äiá»u nÃ y cho phÃ©p chÃºng tÃ´i nghiÃªn cá»©u tÃ¡c Ä‘á»™ng cá»§a viá»‡c tÄƒng kÃ­ch thÆ°á»›c cá»§a kiáº¿n trÃºc (cáº£ chiá»u sÃ¢u vÃ  chiá»u rá»™ng) mÃ  khÃ´ng thay Ä‘á»•i sá»‘ lÆ°á»£ng tham sá»‘ Ä‘Æ°á»£c tá»‘i Æ°u hÃ³a (xem HÃ¬nh 3).

NgoÃ i hiá»‡u quáº£, phÆ°Æ¡ng phÃ¡p Ä‘á» xuáº¥t cá»§a chÃºng tÃ´i cung cáº¥p truyá»n thÃ´ng vÃ  lÆ°u trá»¯ an toÃ n, Ä‘iá»u nÃ y cÃ³ Ã½ nghÄ©a quan trá»ng trong cÃ¡c á»©ng dá»¥ng liÃªn quan Ä‘áº¿n an ninh máº¡ng vÃ  quyá»n riÃªng tÆ°. TÃ³m láº¡i, cÃ¡c mÃ´ hÃ¬nh 'cÆ¡ sá»Ÿ' cá»§a chÃºng tÃ´i Ä‘Æ°á»£c táº¡o ra báº±ng cÃ¡c trÃ¬nh táº¡o giáº£ ngáº«u nhiÃªn vá»›i má»™t 'háº¡t giá»‘ng' cá»¥ thá»ƒ. Háº¡t giá»‘ng nÃ y cÃ³ thá»ƒ Ä‘Æ°á»£c chia sáº» riÃªng tÆ° giá»¯a cÃ¡c thá»±c thá»ƒ Ä‘Æ°á»£c xÃ¡c thá»±c. Vá»›i sá»± tá»± tÆ°Æ¡ng quan tá»‘i thiá»ƒu cá»§a cÃ¡c chuá»—i giáº£ ngáº«u nhiÃªn, má»™t thay Ä‘á»•i nhá» trong háº¡t giá»‘ng táº¡o ra má»™t táº­p há»£p cÃ¡c mÃ´ hÃ¬nh 'cÆ¡ sá»Ÿ' hoÃ n toÃ n khÃ¡c, lÃ m cho cÃ¡c há»‡ sá»‘ há»—n há»£p tuyáº¿n tÃ­nh Ä‘Æ°á»£c chia sáº» cÃ´ng khai trá»Ÿ nÃªn vÃ´ dá»¥ng Ä‘á»‘i vá»›i cÃ¡c bÃªn khÃ´ng Ä‘Æ°á»£c á»§y quyá»n. Lá»±a chá»n thiáº¿t káº¿ nÃ y táº¡o Ä‘iá»u kiá»‡n thuáº­n lá»£i cho truyá»n thÃ´ng vÃ  lÆ°u trá»¯ an toÃ n, Ä‘áº·c biá»‡t trong cÃ¡c á»©ng dá»¥ng an ninh máº¡ng hoáº·c nháº¡y cáº£m vá» quyá»n riÃªng tÆ°.

Vá» máº·t lÃ½ thuyáº¿t, viá»‡c tham sá»‘ hÃ³a quÃ¡ má»©c lÃ  quan trá»ng trong cÃ¡c máº¡ng nÆ¡-ron Ä‘Æ°Æ¡ng Ä‘áº¡i, tÄƒng cÆ°á»ng sá»©c máº¡nh biá»ƒu diá»…n cá»§a chÃºng vÃ  Ä‘Æ¡n giáº£n hÃ³a viá»‡c tá»‘i Æ°u hÃ³a do cáº£nh quan máº¥t mÃ¡t Ä‘Æ°á»£c cáº£i thiá»‡n [33, 30]. CÃ¡c giáº£i phÃ¡p cá»§a nhá»¯ng há»‡ thá»‘ng tham sá»‘ hÃ³a quÃ¡ má»©c nÃ y thÆ°á»ng táº¡o thÃ nh má»™t Ä‘a táº¡p cÃ³ chiá»u dÆ°Æ¡ng [8], vá»›i cÃ¡c há»‡ thá»‘ng lá»›n hÆ¡n thiáº¿u cÃ¡c cá»±c tiá»ƒu khÃ´ng toÃ n cá»¥c [34]. Xem xÃ©t sá»± phong phÃº cá»§a cÃ¡c giáº£i phÃ¡p tá»‘t, chÃºng tÃ´i kiá»ƒm tra xem liá»‡u chÃºng ta cÃ³ thá»ƒ háº¡n cháº¿ viá»‡c tÃ¬m kiáº¿m giáº£i phÃ¡p vÃ o cÃ¡c khÃ´ng gian con chiá»u tháº¥p Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh bá»Ÿi cÃ¡c vector ngáº«u nhiÃªn trong khÃ´ng gian trá»ng sá»‘ (tá»©c lÃ , cÃ¡c máº¡ng 'cÆ¡ sá»Ÿ'). CÃ¡c thÃ­ nghiá»‡m cá»§a chÃºng tÃ´i xÃ¡c nháº­n kháº£ nÄƒng tÃ¬m kiáº¿m cÃ¡c giáº£i phÃ¡p tá»‘t trong cÃ¡c khÃ´ng gian con ngáº«u nhiÃªn chiá»u ráº¥t tháº¥p trong khÃ´ng gian trá»ng sá»‘ cá»§a cÃ¡c máº¡ng tham sá»‘ hÃ³a quÃ¡ má»©c, thÃºc Ä‘áº©y cÃ¡c Ä‘iá»u tra lÃ½ thuyáº¿t sÃ¢u hÆ¡n.

ÄÃ³ng gÃ³p: DÆ°á»›i Ä‘Ã¢y lÃ  nhá»¯ng Ä‘Ã³ng gÃ³p cá»¥ thá»ƒ cá»§a chÃºng tÃ´i:
â€¢ Giá»›i thiá»‡u PRANC, má»™t khung tÃ¡i tham sá»‘ hÃ³a máº¡ng Ä‘Æ¡n giáº£n nhÆ°ng hiá»‡u quáº£ cÃ³ hiá»‡u quáº£ vá» bá»™ nhá»› trong cáº£ giai Ä‘oáº¡n há»c vÃ  tÃ¡i táº¡o,
â€¢ ÄÃ¡nh giÃ¡ tÃ­nh hiá»‡u quáº£ cá»§a PRANC trong viá»‡c nÃ©n cÃ¡c mÃ´ hÃ¬nh nháº­n dáº¡ng hÃ¬nh áº£nh cho cÃ¡c táº­p dá»¯ liá»‡u Ä‘iá»ƒm chuáº©n vÃ  kiáº¿n trÃºc mÃ´ hÃ¬nh khÃ¡c nhau, cho tháº¥y Ä‘á»™ chÃ­nh xÃ¡c cao hÆ¡n vá»›i Ã­t tham sá»‘ hÆ¡n nhiá»u so vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p cÆ¡ báº£n gáº§n Ä‘Ã¢y rá»™ng rÃ£i,
â€¢ Chá»©ng minh tÃ­nh hiá»‡u quáº£ cá»§a PRANC cho nÃ©n hÃ¬nh áº£nh báº±ng cÃ¡ch nÃ©n cÃ¡c biá»ƒu diá»…n nÆ¡-ron áº©n cho cáº£ hÃ¬nh áº£nh tá»± nhiÃªn vÃ  y táº¿,
â€¢ Thá»ƒ hiá»‡n tiá»m nÄƒng cá»§a PRANC trong cÃ¡c á»©ng dá»¥ng yÃªu cáº§u truyá»n thÃ´ng mÃ£ hÃ³a cá»§a cÃ¡c mÃ´ hÃ¬nh (hoáº·c dá»¯ liá»‡u Ä‘Æ°á»£c biá»ƒu diá»…n qua cÃ¡c mÃ´ hÃ¬nh).

2. CÃ´ng trÃ¬nh liÃªn quan
Máº¡ng ngáº«u nhiÃªn: Má»™t sá»‘ cÃ´ng trÃ¬nh trÆ°á»›c Ä‘Ã¢y [35, 31, 7, 12] Ä‘Ã£ cho tháº¥y ráº±ng cÃ¡c máº¡ng Ä‘Æ°á»£c khá»Ÿi táº¡o ngáº«u nhiÃªn cÃ³ má»™t máº¡ng con cáº¡nh tranh vá»›i máº¡ng gá»‘c vá» Ä‘á»™ chÃ­nh xÃ¡c. Má»™t sá»‘ bÃ i bÃ¡o gáº§n Ä‘Ã¢y nhÆ° [50] Ä‘Ã£ giá»›i thiá»‡u má»™t á»©ng dá»¥ng Ä‘á»ƒ sá»­ dá»¥ng thá»±c táº¿ nÃ y trong há»c liÃªn tá»¥c. Thay vÃ¬ tÃ¬m kiáº¿m cÃ¡c máº¡ng con trong má»™t máº¡ng Ä‘Æ°á»£c táº¡o ngáº«u nhiÃªn (tá»©c lÃ , che máº·t), chÃºng tÃ´i tÃ¬m kiáº¿m má»™t tá»• há»£p tuyáº¿n tÃ­nh cá»§a má»™t táº­p nhá» cÃ¡c máº¡ng Ä‘Æ°á»£c táº¡o ngáº«u nhiÃªn, Ä‘Æ°á»£c kÃ½ hiá»‡u lÃ  cÃ¡c mÃ´ hÃ¬nh cÆ¡ sá»Ÿ, cÃ³ thá»ƒ giáº£i quyáº¿t nhiá»‡m vá»¥.

NÃ©n mÃ´ hÃ¬nh: NÃ©n mÃ´ hÃ¬nh khÃ´ng pháº£i lÃ  má»™t chá»§ Ä‘á» má»›i. HashedNet [6] sá»­ dá»¥ng nhÃ³m trá»ng sá»‘ vá»›i hÃ m bÄƒm Ä‘á»ƒ giáº£m sá»‘ lÆ°á»£ng tham sá»‘ cÃ³ thá»ƒ há»c. NÃ³ cÃ³ thá»ƒ Ä‘Æ°á»£c xem nhÆ° má»™t trÆ°á»ng há»£p cá»¥ thá»ƒ cá»§a phÆ°Æ¡ng phÃ¡p chÃºng tÃ´i trong Ä‘Ã³ cÃ¡c mÃ´ hÃ¬nh ngáº«u nhiÃªn lÃ  nhá»‹ phÃ¢n vá»›i sá»‘ lÆ°á»£ng Ä‘Æ¡n vá»‹ báº±ng nhau vÃ  má»—i trá»ng sá»‘ cá»§a mÃ´ hÃ¬nh gá»‘c chá»‰ cÃ³ má»™t trong cÃ¡c mÃ´ hÃ¬nh ngáº«u nhiÃªn. [6] thÃ­ nghiá»‡m vá»›i MLP trÃªn cÃ¡c táº­p dá»¯ liá»‡u nhá». ChÃºng tÃ´i tÃ¡i táº¡o HashedNet cho thiáº¿t láº­p cá»§a chÃºng tÃ´i vÃ  cho tháº¥y ráº±ng phÆ°Æ¡ng phÃ¡p cá»§a chÃºng tÃ´i vÆ°á»£t trá»™i hÆ¡n nÃ³. TÆ°Æ¡ng tá»± nhÆ° HashedNet, Weight Fixed Network (WFN) [40] nÃ©n mÃ´ hÃ¬nh

--- TRANG 3 ---
báº±ng cÃ¡ch giáº£m thiá»ƒu entropy vÃ  sá»‘ lÆ°á»£ng tham sá»‘ duy nháº¥t trong má»™t máº¡ng. WFN báº£o tá»“n Ä‘á»™ chÃ­nh xÃ¡c cá»§a mÃ´ hÃ¬nh vá»›i viá»‡c giáº£m 10Ã— kÃ­ch thÆ°á»›c lÆ°u trá»¯. Thay vÃ¬ chia sáº» cá»©ng cÃ¡c trá»ng sá»‘ trong HasedNet, [45] sá»­ dá»¥ng chia sáº» má»m. Máº·c dÃ¹ táº¥t cáº£ cÃ¡c phÆ°Æ¡ng phÃ¡p nÃ y giáº£m sá»‘ lÆ°á»£ng tham sá»‘, chÃºng Ä‘á»u cáº§n giá»¯ chá»‰ sá»‘ cá»§a má»—i pháº§n tá»­ Ä‘á»ƒ tÃ¡i táº¡o máº¡ng. Han et al. [15] sá»­ dá»¥ng cáº¯t tá»‰a, lÆ°á»£ng tá»­ hÃ³a vÃ  mÃ£ hÃ³a Huffman Ä‘á»ƒ Ä‘áº¡t Ä‘Æ°á»£c tá»· lá»‡ nÃ©n thÆ°á»ng Ã­t hÆ¡n 50Ã—. CÃ¡c cÃ¡ch tiáº¿p cáº­n gáº§n Ä‘Ã¢y hÆ¡n nhÆ° MIRACLE [16] vÃ  weightless [37] Ä‘Ã£ cho tháº¥y káº¿t quáº£ Ä‘áº§y há»©a háº¹n vá»›i tá»· lá»‡ nÃ©n cao hÆ¡n nhiá»u (vÃ­ dá»¥, +400Ã—). Tuy nhiÃªn, chÃºng sá»­ dá»¥ng cÃ¡c kiáº¿n trÃºc lá»›n, vÃ­ dá»¥ VGG cÃ³ 150M tham sá»‘, vÃ¬ váº­y ngay cáº£ sau khi nÃ©n 400Ã—, váº«n cÃ²n hÆ¡n 300K tham sá»‘ (nhiá»u hÆ¡n má»™t ResNet-20 dÃ y Ä‘áº·c). ChÃºng tÃ´i cho tháº¥y ráº±ng chÃºng ta cÃ³ thá»ƒ giáº£m sá»‘ lÆ°á»£ng tham sá»‘ cáº§n thiáº¿t giá»¯ nguyÃªn kiáº¿n trÃºc máº¡ng.

Cáº¯t tá»‰a vÃ  lÆ°á»£ng tá»­ hÃ³a mÃ´ hÃ¬nh: NÃ©n má»™t mÃ´ hÃ¬nh cÃ³ thá»ƒ Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a lÃ  giáº£m sá»‘ lÆ°á»£ng byte cáº§n thiáº¿t Ä‘á»ƒ lÆ°u trá»¯ má»™t mÃ´ hÃ¬nh há»c sÃ¢u. Má»™t sá»‘ bÃ i bÃ¡o nhÆ° XNOR-NET [36] vÃ  EWGS [26] sá»­ dá»¥ng lÆ°á»£ng tá»­ hÃ³a trá»ng sá»‘/kÃ­ch hoáº¡t (W/A) Ä‘á»ƒ giáº£m kÃ­ch thÆ°á»›c cá»§a má»™t máº¡ng. Máº·c dÃ¹ lÆ°á»£ng tá»­ hÃ³a W/A Ä‘Ã£ Ä‘Æ°á»£c chá»©ng minh lÃ  má»™t cÃ¡ch tiáº¿p cáº­n hiá»‡u quáº£ Ä‘á»ƒ giáº£m kÃ­ch thÆ°á»›c máº¡ng trong khi duy trÃ¬ Ä‘á»™ chÃ­nh xÃ¡c, nÃ³ chá»§ yáº¿u Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ tá»‘i Æ°u hÃ³a tÃ­nh toÃ¡n cho suy luáº­n máº¡ng. Má»™t cÃ¡ch tiáº¿p cáº­n khÃ¡c Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ nÃ©n mÃ´ hÃ¬nh lÃ  cáº¯t tá»‰a táº­p há»£p cÃ¡c trá»ng sá»‘ Ã­t quan trá»ng vá» zero, Ä‘iá»u nÃ y giáº£m sá»‘ lÆ°á»£ng phÃ©p toÃ¡n Ä‘iá»ƒm ná»•i (FLOPS) vÃ  cÅ©ng cÃ³ thá»ƒ giáº£m lÆ°á»£ng dá»¯ liá»‡u cáº§n thiáº¿t Ä‘á»ƒ lÆ°u trá»¯ vÃ  truyá»n thÃ´ng má»™t máº¡ng. CÃ¡c phÆ°Æ¡ng phÃ¡p nÃ y bao gá»“m: Neuron Merging [20], Dynamic pruning [29, 38], ChipNet [43], Pruning at initializing [17], Wang et.al. [46], vÃ  Collaborative Compression (CC) [28]. Má»™t láº§n ná»¯a, háº§u háº¿t cÃ¡c phÆ°Æ¡ng phÃ¡p nÃ y sá»­ dá»¥ng cÃ¡c yáº¿u tá»‘ thÆ°a thá»›t lÃ  20Ã— hoáº·c Ã­t hÆ¡n, tháº¥p hÆ¡n má»¥c tiÃªu cá»§a chÃºng tÃ´i trong bÃ i bÃ¡o nÃ y. ChÃºng tÃ´i so sÃ¡nh phÆ°Æ¡ng phÃ¡p cá»§a chÃºng tÃ´i, PRANC, vá»›i cÃ¡c cÃ´ng trÃ¬nh hiá»‡n cÃ³ cung cáº¥p tá»· lá»‡ nÃ©n cá»±c Ä‘áº¡i (+99% tá»· lá»‡ cáº¯t tá»‰a), vÃ­ dá»¥, DPF[29], STR[23], vÃ  SuRP[19]. Cuá»‘i cÃ¹ng, cÃ³ má»™t sá»‘ cÃ´ng trÃ¬nh trÆ°á»›c Ä‘Ã¢y phÃ¢n tÃ­ch cÃ¡c bá»™ lá»c mÃ´ hÃ¬nh nhÆ° má»™t tá»• há»£p tuyáº¿n tÃ­nh cá»§a má»™t sá»‘ bá»™ lá»c cÆ¡ sá»Ÿ [14, 2]. Má»¥c tiÃªu cá»§a cÃ¡c phÆ°Æ¡ng phÃ¡p nhÆ° váº­y lÃ  giáº£m tÃ­nh toÃ¡n chá»© khÃ´ng nháº¥t thiáº¿t lÃ  sá»‘ lÆ°á»£ng tham sá»‘. ChÃºng tÃ´i táº­p trung vÃ o má»™t sá»‘ lÆ°á»£ng cá»±c ká»³ nhá» cÃ¡c tham sá»‘ khÃ´ng thá»ƒ Ä‘áº¡t Ä‘Æ°á»£c báº±ng cÃ¡c phÆ°Æ¡ng phÃ¡p nhÆ° váº­y.

NÃ©n dá»¯ liá»‡u - táº­p lÃµi: Má»™t cÃ¡ch tiáº¿p cáº­n khÃ¡c Ä‘á»ƒ tÃ¡i táº¡o má»™t máº¡ng chÃ­nh xÃ¡c lÃ  lÆ°u trá»¯ hoáº·c truyá»n thÃ´ng táº­p dá»¯ liá»‡u huáº¥n luyá»‡n cá»§a nÃ³ vÃ  huáº¥n luyá»‡n má»™t máº¡ng trong tÃ¡c nhÃ¢n Ä‘Ã­ch. VÃ¬ háº§u háº¿t cÃ¡c táº­p dá»¯ liá»‡u Ä‘á»u lá»›n, cÃ¡c phÆ°Æ¡ng phÃ¡p Ä‘Æ°á»£c Ä‘á» xuáº¥t Ä‘á»ƒ tá»•ng há»£p siÃªu dá»¯ liá»‡u dÆ°á»›i dáº¡ng hÃ¬nh áº£nh hoáº·c láº¥y má»™t táº­p lÃµi cá»§a táº­p dá»¯ liá»‡u. CÃ¡c phÆ°Æ¡ng phÃ¡p nÃ y bao gá»“m: Dataset Distillation (DD) [48], há»“i quy hÃ¬nh áº£nh vÃ  tá»‘c Ä‘á»™ há»c, Flexible Dataset Distillation (FDD) [4], há»“i quy nhÃ£n giáº£ cho hÃ¬nh áº£nh tháº­t, soft labeling dataset distillation (SLDD) [41], táº¡o ra nhÃ£n giáº£ vÃ  hÃ¬nh áº£nh. Táº¥t cáº£ cÃ¡c phÆ°Æ¡ng phÃ¡p nÃ y yÃªu cáº§u háº¡t giá»‘ng khá»Ÿi táº¡o máº¡ng. CÃ¡c phÆ°Æ¡ng phÃ¡p khÃ¡c, bao gá»“m Dataset Condensation vá»›i distribution matching (DM) [52], vá»›i differentiable Siamese augmentation (DSA) [51], vÃ  Dataset distillation báº±ng matching training trajectories (DDMT) [5] Ä‘Ã£ tiáº¿n thÃªm má»™t bÆ°á»›c vÃ  phÃ¡t triá»ƒn cÃ¡c cÃ¡ch tiáº¿p cáº­n Ä‘á»™c láº­p vá»›i háº¡t giá»‘ng. CÃ¡c phÆ°Æ¡ng phÃ¡p nÃ y thÆ°á»ng dá»±a vÃ o tá»‘i Æ°u hÃ³a báº­c hai, Ä‘áº¯t Ä‘á» vá» máº·t tÃ­nh toÃ¡n vÃ  háº¡n cháº¿ á»©ng dá»¥ng cá»§a chÃºng. HÆ¡n ná»¯a, kÃ­ch thÆ°á»›c dá»¯ liá»‡u cáº§n thiáº¿t Ä‘á»ƒ lÆ°u trá»¯ trong cÃ¡c phÆ°Æ¡ng phÃ¡p nÃ y tá»· lá»‡ vá»›i kÃ­ch thÆ°á»›c cá»§a hÃ¬nh áº£nh Ä‘áº§u vÃ o. ChÃºng tÃ´i cho tháº¥y ráº±ng PRANC cung cáº¥p Ä‘á»™ chÃ­nh xÃ¡c tá»‘t hÆ¡n vá»›i Ã­t tham sá»‘ há»“i quy hÆ¡n nhiá»u trÃªn cÃ¡c kiáº¿n trÃºc tÆ°Æ¡ng tá»± so vá»›i cÃ¡c cÃ¡ch tiáº¿p cáº­n Ä‘Ã£ Ä‘á» cáº­p.

NÃ©n hÃ¬nh áº£nh: Má»™t sá»‘ codec phá»• biáº¿n nhÆ° JPEG dá»±a trÃªn cÃ¡c mÃ´-Ä‘un thá»§ cÃ´ng Ä‘á»ƒ nÃ©n hÃ¬nh áº£nh. Má»™t dÃ²ng khÃ¡c cá»§a cÃ¡c phÆ°Æ¡ng phÃ¡p nÃ©n hÃ¬nh áº£nh lÃ  cÃ¡c cÃ¡ch tiáº¿p cáº­n dá»±a trÃªn há»c. CÃ¡c cÃ¡ch tiáº¿p cáº­n nÃ y thÆ°á»ng huáº¥n luyá»‡n má»™t auto-encoder trÃªn má»™t táº­p lá»›n cÃ¡c hÃ¬nh áº£nh [3, 32, 25, 9, 13] vÃ  lÆ°u trá»¯ mÃ£. PhÆ°Æ¡ng phÃ¡p sá»­ dá»¥ng INR cá»§a chÃºng tÃ´i cÅ©ng dá»±a trÃªn há»c nhÆ°ng khÃ¡c vá»›i cÃ¡c ká»¹ thuáº­t trÃªn vÃ¬ mÃ´ hÃ¬nh Ä‘Æ°á»£c há»c trÃªn má»™t hÃ¬nh áº£nh duy nháº¥t (Ä‘á»ƒ overfit) thay vÃ¬ trÃªn má»™t táº­p há»£p cÃ¡c hÃ¬nh áº£nh. Do Ä‘Ã³, nÃ³ cÃ³ thá»ƒ khÃ´ng gáº·p pháº£i thiÃªn lá»‡ch cá»§a dá»¯ liá»‡u huáº¥n luyá»‡n. COIN [10] cÃ³ láº½ gáº§n nháº¥t vá»›i phÆ°Æ¡ng phÃ¡p cá»§a chÃºng tÃ´i, overfits má»™t INR vÃ  lÆ°u trá»¯ táº¥t cáº£ cÃ¡c tham sá»‘. ChÃºng tÃ´i khÃ¡c vÃ¬ chÃºng tÃ´i nÃ©n INR báº±ng cÃ¡ch tÃ¡i tham sá»‘ hÃ³a nÃ³ nhÆ° má»™t tá»• há»£p tuyáº¿n tÃ­nh cá»§a cÃ¡c máº¡ng ngáº«u nhiÃªn vÃ  lÆ°u trá»¯ cÃ¡c há»‡ sá»‘.

3. PhÆ°Æ¡ng phÃ¡p
ChÃºng tÃ´i quan tÃ¢m Ä‘áº¿n viá»‡c huáº¥n luyá»‡n má»™t mÃ´ hÃ¬nh há»c sÃ¢u vá»›i má»™t sá»‘ lÆ°á»£ng ráº¥t nhá» cÃ¡c tham sá»‘ Ä‘á»ƒ viá»‡c chuyá»ƒn mÃ´ hÃ¬nh tá»« tÃ¡c nhÃ¢n nÃ y sang tÃ¡c nhÃ¢n khÃ¡c hoáº·c lÆ°u trá»¯ nÃ³ trÃªn má»™t tÃ¡c nhÃ¢n cÃ³ bá»™ nhá»› nhá» Ã­t tá»‘n kÃ©m hÆ¡n. Äiá»u nÃ y trÃ¡i ngÆ°á»£c vá»›i má»¥c tiÃªu cá»§a háº§u háº¿t cÃ¡c cÃ´ng trÃ¬nh trÆ°á»›c Ä‘Ã¢y (vÃ­ dá»¥, nÃ©n mÃ´ hÃ¬nh, cáº¯t tá»‰a hoáº·c lÆ°á»£ng tá»­ hÃ³a) nháº±m giáº£m tÃ­nh toÃ¡n suy luáº­n hoáº·c cáº£i thiá»‡n kháº£ nÄƒng tá»•ng quÃ¡t hÃ³a trong khi báº£o tá»“n Ä‘á»™ chÃ­nh xÃ¡c. Do Ä‘Ã³, chÃºng tÃ´i giá»›i thiá»‡u má»™t biá»ƒu diá»…n compact giáº£ Ä‘á»‹nh khÃ´ng thay Ä‘á»•i trong kÃ­ch thÆ°á»›c mÃ´ hÃ¬nh, sá»‘ lÆ°á»£ng tham sá»‘ khÃ¡c khÃ´ng hoáº·c Ä‘á»™ chÃ­nh xÃ¡c cá»§a tÃ­nh toÃ¡n.

ChÃºng tÃ´i giáº£ Ä‘á»‹nh ráº±ng mÃ´ hÃ¬nh há»c sÃ¢u cÃ³ thá»ƒ Ä‘Æ°á»£c viáº¿t nhÆ° má»™t tá»• há»£p tuyáº¿n tÃ­nh cá»§a má»™t táº­p cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c khá»Ÿi táº¡o ngáº«u nhiÃªn, gá»i lÃ  cÆ¡ sá»Ÿ. VÃ¬ chÃºng ta cÃ³ thá»ƒ sá»­ dá»¥ng má»™t trÃ¬nh táº¡o giáº£ ngáº«u nhiÃªn Ä‘á»ƒ táº¡o ra cÃ¡c mÃ´ hÃ¬nh ngáº«u nhiÃªn, ngÆ°á»i ta cÃ³ thá»ƒ truyá»n thÃ´ng hoáº·c lÆ°u trá»¯ táº¥t cáº£ cÃ¡c mÃ´ hÃ¬nh ngáº«u nhiÃªn báº±ng cÃ¡ch chá»‰ truyá»n thÃ´ng hoáº·c lÆ°u trá»¯ má»™t vÃ´ hÆ°á»›ng duy nháº¥t lÃ  háº¡t giá»‘ng cá»§a trÃ¬nh táº¡o giáº£ ngáº«u nhiÃªn. Máº·c dÃ¹ cÃ¡c mÃ´ hÃ¬nh cÆ¡ sá»Ÿ khÃ´ng nháº¥t thiáº¿t pháº£i trá»±c giao vá»›i nhau, tÃ­ch vÃ´ hÆ°á»›ng tá»«ng cáº·p cá»§a chÃºng gáº§n báº±ng khÃ´ng vÃ¬ sá»‘ lÆ°á»£ng máº«u (mÃ´ hÃ¬nh) nhá» hÆ¡n nhiá»u so vá»›i chiá»u cá»§a má»—i mÃ´ hÃ¬nh. Sau Ä‘Ã³ chÃºng tÃ´i tá»‘i Æ°u hÃ³a cÃ¡c trá»ng sá»‘ cá»§a má»—i mÃ´ hÃ¬nh cÆ¡ sá»Ÿ Ä‘á»ƒ tá»• há»£p tuyáº¿n tÃ­nh cá»§a chÃºng cÃ³ thá»ƒ giáº£i quyáº¿t nhiá»‡m vá»¥ (vÃ­ dá»¥, phÃ¢n loáº¡i hÃ¬nh áº£nh).

ChÃ­nh thá»©c hÆ¡n, cho má»™t táº­p cÃ¡c hÃ¬nh áº£nh huáº¥n luyá»‡n {xi}N
i=1 vÃ  cÃ¡c nhÃ£n tÆ°Æ¡ng á»©ng {yi}N
i=1 cá»§a chÃºng, chÃºng tÃ´i muá»‘n huáº¥n luyá»‡n má»™t

--- TRANG 4 ---
Máº¡ng 
CÆ¡ sá»Ÿ 
Ngáº«u nhiÃªn, 
!
"
!
#
!
!
"
!MÃ´ táº£ Cáº£nh quan Máº¥t mÃ¡t
Cá»±c tiá»ƒu 
Äá»‹a phÆ°Æ¡ng
Cá»±c tiá»ƒu Äá»‹a phÆ°Æ¡ng
HÃ¬nh 2. Má»™t minh há»a Ä‘Æ¡n giáº£n vá» cáº£nh quan máº¥t mÃ¡t cá»§a má»™t mÃ´ hÃ¬nh vá»›i hai tham sá»‘ vÃ  má»™t mÃ´ hÃ¬nh cÆ¡ sá»Ÿ. KhÃ´ng cÃ³ cá»±c tiá»ƒu Ä‘á»‹a phÆ°Æ¡ng nÃ o trong hai cÃ¡i cÃ³ thá»ƒ náº±m trong span cá»§a cÃ¡c mÃ´ hÃ¬nh cÆ¡ sá»Ÿ, vÃ¬ váº­y chÃºng tÃ´i tÃ¬m kiáº¿m Î± Ä‘á»ƒ tÃ¬m má»™t cá»±c tiá»ƒu Ä‘á»‹a phÆ°Æ¡ng trong span cá»§a cÃ¡c mÃ´ hÃ¬nh cÆ¡ sá»Ÿ.

mÃ´ hÃ¬nh há»c sÃ¢u f(.;Î¸) vá»›i cÃ¡c tham sá»‘ Î¸âˆˆRd sao cho f(xi;Î¸) dá»± Ä‘oÃ¡n yi. Thá»±c hÃ nh tiÃªu chuáº©n lÃ  tá»‘i Æ°u hÃ³a Î¸ báº±ng cÃ¡ch giáº£m thiá»ƒu rá»§i ro thá»±c nghiá»‡m:
R(Î¸) =1
NPN
i=1L(f(xi;Î¸), yi)
trong Ä‘Ã³ L(Â·,Â·) lÃ  má»™t thÆ°á»›c Ä‘o Ä‘á»™ báº¥t Ä‘á»“ng, vÃ­ dá»¥, cross-entropy. Trong viá»‡c truyá»n thÃ´ng mÃ´ hÃ¬nh nhÆ° váº­y, chÃºng ta cáº§n gá»­i má»™t vector chiá»u cao Î¸ chá»©a d scalars.

Äá»ƒ giáº£m chi phÃ­ truyá»n thÃ´ng, chÃºng tÃ´i giáº£ Ä‘á»‹nh má»™t táº­p cÃ¡c mÃ´ hÃ¬nh cÆ¡ sá»Ÿ Ä‘Æ°á»£c khá»Ÿi táº¡o ngáº«u nhiÃªn vá»›i cÃ¡c tham sá»‘ {Ë†Î¸j}k
j=1. CÃ¡c k mÃ´ hÃ¬nh cÆ¡ sá»Ÿ nÃ y Ä‘Æ°á»£c táº¡o ra báº±ng cÃ¡ch sá»­ dá»¥ng má»™t háº¡t giá»‘ng Ä‘Ã£ biáº¿t vÃ  Ä‘Æ°á»£c cá»‘ Ä‘á»‹nh trong suá»‘t quÃ¡ trÃ¬nh há»c. Sau Ä‘Ã³ chÃºng tÃ´i Ä‘á»‹nh nghÄ©a:
Î¸:=Pk
j=1Î±jË†Î¸j, trong Ä‘Ã³ Î±j lÃ  má»™t trá»ng sá»‘ vÃ´ hÆ°á»›ng cho mÃ´ hÃ¬nh cÆ¡ sá»Ÿ thá»© j. Giáº£ Ä‘á»‹nh ráº±ng kâ‰ªd, sáº½ Ã­t tá»‘n kÃ©m hÆ¡n nhiá»u Ä‘á»ƒ truyá»n thÃ´ng hoáº·c lÆ°u trá»¯ Î± thay vÃ¬ Î¸.

Äá»ƒ tá»‘i Æ°u hÃ³a Î±, ngÆ°á»i ta cÃ³ thá»ƒ Ä‘áº§u tiÃªn tá»‘i Æ°u hÃ³a cho Î¸ Ä‘á»ƒ tÃ¬m Î¸âˆ— vÃ  sau Ä‘Ã³ há»“i quy nÃ³ báº±ng cÃ¡ch giáº£m thiá»ƒu:
arg minÎ±||Î¸âˆ—âˆ’Pk
j=1Î±jË†Î¸j||2
Tuy nhiÃªn, vÃ¬ kâ‰ªd, giáº£i phÃ¡p tá»‘i Æ°u Î¸âˆ— cÃ³ thá»ƒ xa khá»i span cá»§a cÃ¡c mÃ´ hÃ¬nh cÆ¡ sá»Ÿ, dáº«n Ä‘áº¿n má»™t giáº£i phÃ¡p kÃ©m hÆ¡n (cÅ©ng Ä‘Æ°á»£c thá»ƒ hiá»‡n thá»±c nghiá»‡m trong cÃ¡c thÃ­ nghiá»‡m cá»§a chÃºng tÃ´i). ChÃºng tÃ´i láº­p luáº­n ráº±ng cÃ³ vÃ´ sá»‘ giáº£i phÃ¡p cho Î¸ tá»‘t nhÆ° Î¸âˆ—, vÃ¬ váº­y chÃºng ta cÃ³ thá»ƒ tÃ¬m kiáº¿m má»™t cÃ¡i cÃ³ sai sá»‘ dÆ° nhá» hÆ¡n khi Ä‘Æ°á»£c chiáº¿u vÃ o span cá»§a cÃ¡c mÃ´ hÃ¬nh cÆ¡ sá»Ÿ. Do Ä‘Ã³, chÃºng tÃ´i tÃ¬m kiáº¿m má»™t giáº£i phÃ¡p giáº£m thiá»ƒu máº¥t mÃ¡t nhiá»‡m vá»¥ trong span cá»§a cÃ¡c mÃ´ hÃ¬nh cÆ¡ sá»Ÿ báº±ng cÃ¡ch tá»‘i Æ°u hÃ³a:
arg min
Î±X
iL
f(xi;kX
j=1Î±jË†Î¸j), yi
(1)
LÆ°u Ã½ ráº±ng táº¡i thá»i Ä‘iá»ƒm kiá»ƒm tra, sau khi tÃ¡i táº¡o mÃ´ hÃ¬nh báº±ng tá»• há»£p tuyáº¿n tÃ­nh, suy luáº­n cho PRANC hoÃ n toÃ n giá»‘ng nhÆ° mÃ´ hÃ¬nh dÃ y Ä‘áº·c tiÃªu chuáº©n.

Hiá»‡u quáº£ tá»‘i Æ°u hÃ³a: LÆ°u Ã½ ráº±ng viá»‡c tá»‘i Æ°u hÃ³a ráº¥t Ä‘Æ¡n giáº£n vÃ  hiá»‡u quáº£ vÃ¬ dL
dÎ±=dL
dÎ¸dÎ¸
dÎ± vÃ  dÎ¸
dÎ±j=Ë†Î¸j. Do Ä‘Ã³, chÃºng tÃ´i sá»­ dá»¥ng lan truyá»n ngÆ°á»£c tiÃªu chuáº©n Ä‘á»ƒ tÃ­nh dL
dÎ¸ vÃ  sau Ä‘Ã³ nhÃ¢n vá»›i ma tráº­n cÃ¡c mÃ´ hÃ¬nh cÆ¡ sá»Ÿ Ä‘á»ƒ cÃ³:
dL
dÎ±=dL
dÎ¸Ã—Ë†Î¸

Hiá»‡u quáº£ bá»™ nhá»› trong huáº¥n luyá»‡n: LÆ°u Ã½ ráº±ng ma tráº­n cÃ¡c mÃ´ hÃ¬nh cÆ¡ sá»Ÿ Ë†Î¸ ráº¥t lá»›n, vÃ¬ váº­y viá»‡c giá»¯ nÃ³ trong bá»™ nhá»› khÃ´ng hiá»‡u quáº£. Do Ä‘Ã³, chÃºng tÃ´i chia ma tráº­n nÃ y thÃ nh nhiá»u khá»‘i nhá» hÆ¡n, vÃ  táº¡i má»—i láº§n láº·p, chÃºng tÃ´i táº¡o ra má»—i khá»‘i báº±ng cÃ¡ch sá»­ dá»¥ng má»™t trÃ¬nh táº¡o giáº£ ngáº«u nhiÃªn táº¡i chÃ­nh GPU, thá»±c hiá»‡n phÃ©p nhÃ¢n, loáº¡i bá» khá»‘i vÃ  chuyá»ƒn sang khá»‘i tiáº¿p theo. PhÆ°Æ¡ng phÃ¡p nÃ y giáº£m dáº¥u chÃ¢n bá»™ nhá»› vá»›i má»™t há»‡ sá»‘ lá»›n vá»›i chi phÃ­ táº¡o ra toÃ n bá»™ cÆ¡ sá»Ÿ ngáº«u nhiÃªn má»™t láº§n má»—i láº§n láº·p, Ä‘iá»u nÃ y ráº¥t hiá»‡u quáº£ trong cÃ¡c GPU hiá»‡n Ä‘áº¡i. Chá»n cÃ¡c khá»‘i 100 giÃ¡ trá»‹ alpha cho ResNet18 tiÃªu thá»¥ gáº§n 4.4GB (tá»©c lÃ  11MÃ—4Ã—100) bá»™ nhá»› GPU lÃ  há»£p lÃ½.

Hiá»‡u quáº£ tÃ¡i táº¡o mÃ´ hÃ¬nh: VÃ¬ cÃ¡c mÃ´ hÃ¬nh cÆ¡ sá»Ÿ Ä‘Æ°á»£c táº¡o ra báº±ng cÃ¡ch sá»­ dá»¥ng má»™t trÃ¬nh táº¡o giáº£ ngáº«u nhiÃªn, chÃºng ta cÃ³ thá»ƒ tÃ¡i táº¡o mÃ´ hÃ¬nh báº±ng cÃ¡ch sá»­ dá»¥ng má»™t trung bÃ¬nh cháº¡y Ä‘Æ¡n giáº£n cá»§a cÃ¡c mÃ´ hÃ¬nh cÆ¡ sá»Ÿ: táº¡o ra má»—i má»¥c trong Ë†Î¸j, nhÃ¢n nÃ³ vá»›i Î±j, thÃªm nÃ³ vÃ o trung bÃ¬nh cháº¡y, loáº¡i bá» má»¥c vÃ  chuyá»ƒn sang má»¥c tiáº¿p theo cá»§a Ë†Î¸j. Báº±ng cÃ¡ch nÃ y, dáº¥u chÃ¢n bá»™ nhá»› cá»§a viá»‡c tÃ¡i táº¡o trá»Ÿ nÃªn khÃ´ng Ä‘Ã¡ng ká»ƒ (tá»©c lÃ  d+ 1).

TÃ¡i táº¡o mÃ´ hÃ¬nh theo yÃªu cáº§u: Trong má»™t sá»‘ á»©ng dá»¥ng, tÃ¡c nhÃ¢n cÃ³ thá»ƒ cáº§n cháº¡y suy luáº­n hiáº¿m khi nhÆ°ng khÃ´ng cÃ³ Ä‘á»§ bá»™ nhá»› Ä‘á»ƒ giá»¯ mÃ´ hÃ¬nh. Thiáº¿t bá»‹ cÃ³ thá»ƒ lÆ°u trá»¯ Î±, tÃ¡i táº¡o má»—i bá»™ lá»c tÃ­ch cháº­p báº±ng cÃ¡ch sá»­ dá»¥ng cÃ¡c má»¥c tÆ°Æ¡ng á»©ng cá»§a cÃ¡c mÃ´ hÃ¬nh cÆ¡ sá»Ÿ, Ã¡p dá»¥ng nÃ³ vÃ o Ä‘áº§u vÃ o, vÃ  sau Ä‘Ã³ loáº¡i bá» bá»™ lá»c vÃ  chuyá»ƒn sang bá»™ lá»c tiáº¿p theo. QuÃ¡ trÃ¬nh nÃ y cÃ³ dáº¥u chÃ¢n bá»™ nhá»› ráº¥t nhá» vÃ¬ nÃ³ cáº§n lÆ°u trá»¯ Î± vÃ  chá»‰ má»™t bá»™ lá»c táº¡i má»™t thá»i Ä‘iá»ƒm.

Há»c phÃ¢n tÃ¡n: Äá»ƒ huáº¥n luyá»‡n mÃ´ hÃ¬nh trÃªn nhiá»u GPU, chÃºng tÃ´i sá»­ dá»¥ng má»™t thuáº­t toÃ¡n há»c phÃ¢n tÃ¡n Ä‘Æ¡n giáº£n Ä‘á»ƒ tÄƒng m, sá»‘ lÆ°á»£ng mÃ´ hÃ¬nh cÆ¡ sá»Ÿ. ChÃºng tÃ´i chia m mÃ´ hÃ¬nh cÆ¡ sá»Ÿ giá»¯a g GPU Ä‘á»ƒ má»—i GPU chá»‰ lÃ m viá»‡c trÃªn m/g mÃ´ hÃ¬nh cÆ¡ sá»Ÿ. Sau Ä‘Ã³, chÃºng tÃ´i phÃ¢n phá»‘i Î± giá»¯a cÃ¡c GPU. Má»—i GPU tÃ­nh trung bÃ¬nh cÃ³ trá»ng sá»‘ má»™t pháº§n trÃªn cÃ¡c mÃ´ hÃ¬nh cÆ¡ sá»Ÿ cá»§a nÃ³ vÃ  phÃ¢n phá»‘i nÃ³ cho táº¥t cáº£ cÃ¡c GPU. Sau Ä‘Ã³, táº¥t cáº£ cÃ¡c GPU sáº½ cÃ³ quyá»n truy cáº­p vÃ o trung bÃ¬nh cÃ³ trá»ng sá»‘ hoÃ n chá»‰nh vÃ  sáº½ sá»­ dá»¥ng nÃ³ Ä‘á»ƒ thá»±c hiá»‡n lan truyá»n ngÆ°á»£c dÆ°á»›i dáº¡ng há»c phÃ¢n tÃ¡n tiÃªu chuáº©n vÃ  cáº­p nháº­t táº­p Î± cá»§a riÃªng chÃºng.

Lá»›p BatchNorm: ChÃºng tÃ´i giáº£m thiá»ƒu máº¥t mÃ¡t cá»§a nhiá»‡m vá»¥ báº±ng cÃ¡ch Ä‘iá»u chá»‰nh Î± thay vÃ¬ cÃ¡c trá»ng sá»‘ mÃ´ hÃ¬nh nhÆ° Ä‘Æ°á»£c thá»±c hiá»‡n trong há»c tiÃªu chuáº©n. Tuy nhiÃªn, cÃ¡c tham sá»‘ cá»§a lá»›p BatchNorm khÃ´ng Ä‘Æ°á»£c Ä‘iá»u chá»‰nh bá»Ÿi PRANC. Äá»ƒ Ä‘Æ¡n giáº£n hÃ³a cÃ´ng viá»‡c nÃ y, chÃºng tÃ´i giáº£ Ä‘á»‹nh ráº±ng chÃºng ta cÃ³ thá»ƒ truyá»n thÃ´ng nhá»¯ng tham sá»‘ Ä‘Ã³ vÃ  bao gá»“m chÃºng trong ngÃ¢n sÃ¡ch. Äiá»u nÃ y cÃ³ Ã½ nghÄ©a vÃ¬ sá»‘ lÆ°á»£ng tham sá»‘ BatchNorm tÆ°Æ¡ng Ä‘á»‘i nhá» so vá»›i sá»‘ lÆ°á»£ng tham sá»‘ trá»ng sá»‘.

4. á»¨ng dá»¥ng
ChÃºng tÃ´i kiá»ƒm tra khung cÃ´ng viá»‡c cá»§a chÃºng tÃ´i trÃªn hai á»©ng dá»¥ng khÃ¡c nhau.
Máº¡ng phÃ¢n loáº¡i hÃ¬nh áº£nh: Trong thiáº¿t láº­p nÃ y, chÃºng tÃ´i tham sá»‘ hÃ³a má»™t mÃ´ hÃ¬nh nháº­n dáº¡ng hÃ¬nh áº£nh, vÃ­ dá»¥, ResNet-20 cho CIFAR-10, báº±ng khung PRANC cá»§a chÃºng tÃ´i vÃ  tá»‘i Æ°u hÃ³a cÃ¡c Î± thay vÃ¬ cÃ¡c trá»ng sá»‘ mÃ´ hÃ¬nh. Äiá»u nÃ y dáº«n Ä‘áº¿n má»™t mÃ´ hÃ¬nh compact cÃ³ thá»ƒ Ä‘Æ°á»£c lÆ°u trá»¯ vÃ  truyá»n thÃ´ng ráº¥t hiá»‡u quáº£.

--- TRANG 5 ---
NÃ©n hÃ¬nh áº£nh sá»­ dá»¥ng máº¡ng nÆ¡-ron áº©n:
ChÃºng tÃ´i cÅ©ng kiá»ƒm tra khung cÃ´ng viá»‡c cá»§a chÃºng tÃ´i trong viá»‡c nÃ©n má»™t máº¡ng nÆ¡-ron áº©n (INR) Ä‘Æ°á»£c over-fitted vá»›i má»™t hÃ¬nh áº£nh duy nháº¥t [42]. Má»™t INR nhÆ° váº­y nháº­p tá»a Ä‘á»™ cá»§a pixel vÃ  tráº£ vá» giÃ¡ trá»‹ mÃ u. Do Ä‘Ã³, ngÆ°á»i ta cÃ³ thá»ƒ lÆ°u trá»¯ hoáº·c truyá»n thÃ´ng mÃ´ hÃ¬nh INR thay vÃ¬ hÃ¬nh áº£nh gá»‘c. ChÃºng tÃ´i tham sá»‘ hÃ³a má»™t mÃ´ hÃ¬nh INR tiÃªu chuáº©n [42] báº±ng cÃ¡ch sá»­ dá»¥ng khung PRANC Ä‘á»ƒ chÃºng tÃ´i tá»‘i Æ°u hÃ³a cÃ¡c Î± thay vÃ¬ cÃ¡c trá»ng sá»‘ cá»§a mÃ´ hÃ¬nh INR. PhÆ°Æ¡ng phÃ¡p cá»§a chÃºng tÃ´i vÆ°á»£t trá»™i hÆ¡n nÃ©n JPEG trÃªn hai táº­p dá»¯ liá»‡u tiÃªu chuáº©n vÃ  hai thÆ°á»›c Ä‘o Ä‘Ã¡nh giÃ¡.

5. ThÃ­ nghiá»‡m vá» phÃ¢n loáº¡i hÃ¬nh áº£nh
ChÃºng tÃ´i bÃ¡o cÃ¡o káº¿t quáº£ rá»™ng rÃ£i cá»§a PRANC trÃªn cÃ¡c táº­p dá»¯ liá»‡u, kiáº¿n trÃºc vÃ  sá»‘ lÆ°á»£ng mÃ´ hÃ¬nh cÆ¡ sá»Ÿ khÃ¡c nhau.

5.1. So sÃ¡nh vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p cáº¯t tá»‰a mÃ´ hÃ¬nh:
Äá»ƒ truyá»n thÃ´ng má»™t mÃ´ hÃ¬nh thÆ°a vá»›i tá»· lá»‡ thÆ°a hÆ¡n 2Ã—, cáº§n truyá»n hai sá»‘ cho má»—i tham sá»‘: giÃ¡ trá»‹ cá»§a trá»ng sá»‘ vÃ  chá»‰ sá»‘ cá»§a nÃ³ trong máº¡ng. Do Ä‘Ã³, ngay cáº£ khi má»™t phÆ°Æ¡ng phÃ¡p cáº¯t tá»‰a mÃ´ hÃ¬nh sá»­ dá»¥ng há»‡ sá»‘ cáº¯t tá»‰a 99% (giáº£m 100Ã— kÃ­ch thÆ°á»›c) vÃ¬ nÃ³ pháº£i truyá»n cÃ¡c chá»‰ sá»‘ cÃ¹ng vá»›i cÃ¡c giÃ¡ trá»‹, viá»‡c giáº£m kÃ­ch thÆ°á»›c thá»±c táº¿ sáº½ nhá» hÆ¡n 100Ã—. DPF [29], STR[23], LAMP[27], RiGL[11], vÃ  SuRP[19] lÃ  cÃ¡c phÆ°Æ¡ng phÃ¡p SOTA sá»­ dá»¥ng Ä‘á»™ thÆ°a lá»›n (+50Ã—) vÃ  duy trÃ¬ Ä‘á»™ chÃ­nh xÃ¡c há»£p lÃ½. ChÃºng tÃ´i Ä‘Ã£ sá»­ dá»¥ng mÃ£ cá»§a há» trÃªn CIFAR-10 vÃ  CIFAR-100 cÃ¹ng vá»›i kiáº¿n trÃºc ResNet-20 vÃ  ResNet-56 vÃ  so sÃ¡nh chÃºng vá»›i phÆ°Æ¡ng phÃ¡p cá»§a chÃºng tÃ´i trong Báº£ng 1. PRANC Ä‘áº¡t Ä‘Æ°á»£c Ä‘á»™ chÃ­nh xÃ¡c cao hÆ¡n má»™t cÃ¡ch nháº¥t quÃ¡n vá»›i Ã­t tham sá»‘ hÆ¡n. Xin lÆ°u Ã½ ráº±ng táº¥t cáº£ cÃ¡c phÆ°Æ¡ng phÃ¡p nÃ y loáº¡i trá»« cÃ¡c lá»›p BatchNorm khá»i quÃ¡ trÃ¬nh cáº¯t tá»‰a cá»§a chÃºng. Do Ä‘Ã³ chÃºng tÃ´i cÅ©ng loáº¡i trá»« chÃºng khá»i sá»‘ lÆ°á»£ng tham sá»‘. Äá»‘i vá»›i ResNet-20, sá»‘ lÆ°á»£ng tham sá»‘ BatchNorm lÃ  2,752 vÃ  Ä‘á»‘i vá»›i ResNet-56 lÃ  8,128.

5.2. So sÃ¡nh vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p chÆ°ng cáº¥t mÃ´ hÃ¬nh:
Má»™t trong nhá»¯ng Ä‘Æ°á»ng cÆ¡ báº£n quan trá»ng cho cÃ´ng viá»‡c cá»§a chÃºng tÃ´i lÃ  chÆ°ng cáº¥t mÃ´ hÃ¬nh. Tuy nhiÃªn, sá»‘ lÆ°á»£ng tham sá»‘ chÃºng tÃ´i sá»­ dá»¥ng ráº¥t nhá» so vá»›i báº¥t ká»³ kiáº¿n trÃºc CNN hiá»‡n cÃ³ nÃ o. Ngay cáº£ LeNet[24] (má»™t trong nhá»¯ng kiáº¿n trÃºc CNN nhá» nháº¥t), cÃ³ hÆ¡n 60,000 tham sá»‘. Äá»ƒ so sÃ¡nh PRANC vá»›i chÆ°ng cáº¥t mÃ´ hÃ¬nh, chÃºng tÃ´i huáº¥n luyá»‡n má»™t ResNet18 trÃªn CIFAR-10 vÃ  chÆ°ng cáº¥t kiáº¿n thá»©c cá»§a nÃ³ vÃ o má»™t mÃ´ hÃ¬nh LeNet. Máº·t khÃ¡c, chÃºng tÃ´i nÃ©n má»™t mÃ´ hÃ¬nh ResNet20 báº±ng cÃ¡ch sá»­ dá»¥ng PRANC vá»›i 10,000 Î± vÃ  má»™t mÃ´ hÃ¬nh ResNet56 vá»›i chá»‰ 5,000 Î± vÃ  so sÃ¡nh Ä‘á»™ chÃ­nh xÃ¡c cá»§a chÃºng. NhÆ° Ä‘Æ°á»£c thá»ƒ hiá»‡n trong Báº£ng 2, cÃ¡c kiáº¿n trÃºc Ä‘Æ°á»£c nÃ©n báº±ng PRANC yÃªu cáº§u Ã­t tham sá»‘ hÆ¡n gáº§n 5Ã— trong khi Ä‘áº¡t Ä‘Æ°á»£c Ä‘á»™ chÃ­nh xÃ¡c cao hÆ¡n vá»›i má»™t khoáº£ng cÃ¡ch Ä‘Ã¡ng ká»ƒ (81.48% so vá»›i 74.1%).

5.3. So sÃ¡nh vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p chÆ°ng cáº¥t táº­p dá»¯ liá»‡u:
Trong Báº£ng 3, chÃºng tÃ´i bÃ¡o cÃ¡o Ä‘á»™ chÃ­nh xÃ¡c vÃ  sá»‘ lÆ°á»£ng tham sá»‘ cho PRANC so sÃ¡nh vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p chÆ°ng cáº¥t táº­p dá»¯ liá»‡u khÃ¡c nhau.

Báº£ng 1. So sÃ¡nh mÃ´ hÃ¬nh cá»§a chÃºng tÃ´i vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p cáº¯t tá»‰a SOTA, DPF [29], STR[23], LAMP[27], RiGL[11], vÃ  SuRP[19]. "Pr." biá»ƒu thá»‹ tá»· lá»‡ cáº¯t tá»‰a. NgoÃ i ra, khi máº¡ng Ä‘Æ°á»£c cáº¯t tá»‰a, chÃºng ta pháº£i giá»¯ hai sá»‘ cho má»—i trá»ng sá»‘: chÃ­nh trá»ng sá»‘ vÃ  vá»‹ trÃ­ cá»§a nÃ³ trong mÃ´ hÃ¬nh. LÆ°u Ã½ ráº±ng chÃºng tÃ´i loáº¡i trá»« sá»‘ lÆ°á»£ng tham sá»‘ BatchNorm trong báº£ng nÃ y vÃ¬ Ä‘iá»u Ä‘Ã³ lÃ  háº±ng sá»‘ cho táº¥t cáº£ cÃ¡c mÃ´ hÃ¬nh. Sá»‘ nÃ y lÃ  2,752 cho Resnet-20 vÃ  8,128 cho ResNet-56.

PhÆ°Æ¡ng phÃ¡p Dá»¯ liá»‡u Kiáº¿n trÃºc # Tham sá»‘ khÃ´ng bao gá»“m Äá»™ chÃ­nh xÃ¡c
BatchNorm
Baseline (Pr. 0%) C10 R20 269,722 88.92
DPF(Pr. 98.2%) C10 R20 4,920 Ã—2 41.86
RiGL(Pr. 99.62%) C10 R20 1026 Ã—2 50.9
LAMP(Pr. 99.62%) C10 R20 1026 Ã—2 51.24
SuRP (Pr. 99.62%) C10 R20 1026 Ã—2 54.22
STR (Pr. 95.5%) C10 R20 12,238 Ã—2 75.99
Ours C10 R20 1,000 64.59
Ours C10 R20 10,000 81.48
Baseline (Pr. 0%) C10 R56 853,018 91.64
DPF (Pr. 98.43%) C10 R56 13,414 Ã—2 47.66
SuRP (Pr. 98.73%) C10 R56 10,834 Ã—2 66.65
STR (Pr. 98.4%) C10 R56 13,312 Ã—2 67.77
Ours C10 R56 5,000 76.87
Baseline (Pr. 0%) C100 R20 275,572 60.84
DPF (Pr. 96.13%) C100 R20 10,770 Ã—2 12.25
SuRP (Pr. 97.48%) C100 R20 6,797 Ã—2 14.46
STR (Pr. 96.12%) C100 R20 10,673 Ã—2 13.18
Ours C100 R20 5,000 32.33
Baseline (Pr. 0%) C100 R56 858,868 64.32
DPF (Pr. 97.8%) C100 R56 19,264 Ã—2 19.11
SuRP (Pr. 98.72%) C100 R56 10,919 Ã—2 14.59
STR (Pr. 97.8%) C100 R56 18,881 Ã—2 25.98
Ours C100 R56 5,000 32.97

Báº£ng 2. So sÃ¡nh vá»›i chÆ°ng cáº¥t mÃ´ hÃ¬nh. PRANC vÆ°á»£t trá»™i hÆ¡n má»™t LeNet Ä‘Æ°á»£c chÆ°ng cáº¥t tá»« ResNet-18 trÃªn CIFAR-10. 2,752 vÃ  8,128 lÃ  sá»‘ lÆ°á»£ng tham sá»‘ BatchNorm mÃ  chÃºng tÃ´i loáº¡i trá»« khá»i cÃ¡c há»‡ sá»‘ nhÆ°ng cáº§n xem xÃ©t chÃºng nhÆ° cÃ¡c tham sá»‘.

PhÆ°Æ¡ng phÃ¡p Kiáº¿n trÃºc # Tham sá»‘ Äá»™ chÃ­nh xÃ¡c
ChÆ°ng cáº¥t tá»« R18 LeNet 62,006 74.1%
Ours R56 5,000 + (8,128) 76.87%
Ours R20 10,000 + (2,752) 81.48%

Háº§u háº¿t cÃ¡c phÆ°Æ¡ng phÃ¡p nÃ y dá»±a trÃªn cÃ¡c cÃ¡ch tiáº¿p cáº­n meta-learning liÃªn quan Ä‘áº¿n chi phÃ­ tÃ­nh toÃ¡n cao vÃ  dáº¥u chÃ¢n bá»™ nhá»› táº¡i thá»i gian huáº¥n luyá»‡n, vÃ¬ váº­y chÃºng bá»‹ háº¡n cháº¿ vá» Ä‘á»™ sÃ¢u cá»§a mÃ´ hÃ¬nh. HÆ¡n ná»¯a, chÃºng cáº§n thá»±c hiá»‡n má»™t vÃ i bÆ°á»›c gradient descent trong viá»‡c xÃ¢y dá»±ng mÃ´ hÃ¬nh. Tuy nhiÃªn, sá»‘ lÆ°á»£ng tham sá»‘ cáº§n thiáº¿t trong cÃ¡c phÆ°Æ¡ng phÃ¡p chÆ°ng cáº¥t táº­p dá»¯ liá»‡u tá»· lá»‡ vá»›i kÃ­ch thÆ°á»›c cá»§a hÃ¬nh áº£nh Ä‘áº§u vÃ o. VÃ­ dá»¥, trong viá»‡c chÆ°ng cáº¥t CIFAR-10 chá»‰ thÃ nh 10 hÃ¬nh áº£nh, chÃºng ta cáº§n lÆ°u trá»¯ Ã­t nháº¥t 10Ã—32Ã—32Ã—3 tham sá»‘. Äá»ƒ cÃ³ thá»ƒ so sÃ¡nh Ä‘Æ°á»£c vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p chÆ°ng cáº¥t táº­p dá»¯ liá»‡u SOTA, chÃºng tÃ´i sá»­ dá»¥ng AlexNet (lÃ  má»™t phiÃªn báº£n Ä‘Ã£ sá»­a Ä‘á»•i Ä‘Æ°á»£c mÃ´ táº£ trong [48]) trÃªn CIFAR-10. Äá»‘i vá»›i CIFAR-100 vÃ  tinyImageNet, chÃºng tÃ´i sá»­ dá»¥ng cÃ¡c kiáº¿n trÃºc ConvNet Ä‘á»™ sÃ¢u 3 vÃ  Ä‘á»™ sÃ¢u 4 chiá»u rá»™ng 128 Ä‘Æ°á»£c mÃ´ táº£ trong [5], tÆ°Æ¡ng á»©ng. LÆ°u Ã½ ráº±ng má»™t sá»‘ phÆ°Æ¡ng phÃ¡p chÆ°ng cáº¥t táº­p dá»¯ liá»‡u khÃ´ng

--- TRANG 6 ---
yÃªu cáº§u háº¡t giá»‘ng, vÃ¬ váº­y chÃºng giáº£i quyáº¿t má»™t nhiá»‡m vá»¥ thÃ¡ch thá»©c hÆ¡n vÃ¬ dá»¯ liá»‡u Ä‘Ã£ chÆ°ng cáº¥t pháº£i cÃ³ thá»ƒ Ä‘iá»u chá»‰nh báº¥t ká»³ mÃ´ hÃ¬nh Ä‘Æ°á»£c khá»Ÿi táº¡o ngáº«u nhiÃªn nÃ o. Tuy nhiÃªn, vÃ¬ chÃºng tÃ´i táº­p trung vÃ o viá»‡c giáº£m chi phÃ­ truyá»n thÃ´ng vÃ  lÆ°u trá»¯, viá»‡c sá»­ dá»¥ng má»™t háº¡t giá»‘ng cá»‘ Ä‘á»‹nh nhÆ° pháº§n trung tÃ¢m cá»§a Ã½ tÆ°á»Ÿng chÃºng tÃ´i khÃ´ng bá»‹ cáº¥m Ä‘oÃ¡n.

Báº£ng 3. So sÃ¡nh vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p chÆ°ng cáº¥t táº­p dá»¯ liá»‡u trÃªn cÃ¡c táº­p dá»¯ liá»‡u vÃ  kiáº¿n trÃºc khÃ¡c nhau. 3-128-Conv vÃ  4-128-Conv Ä‘áº¡i diá»‡n cho ConvNet Ä‘á»™ sÃ¢u 3 chiá»u rá»™ng 128 vÃ  ConvNet Ä‘á»™ sÃ¢u 4 chiá»u rá»™ng 128, tÆ°Æ¡ng á»©ng. "MÃ´ hÃ¬nh Ä‘Ã£ huáº¥n luyá»‡n" lÃ  giá»›i háº¡n trÃªn cá»§a phÆ°Æ¡ng phÃ¡p chÃºng tÃ´i vÃ¬ ngÆ°á»i ta cÃ³ thá»ƒ tá»‘i Æ°u hÃ³a táº¥t cáº£ cÃ¡c trá»ng sá»‘ vÃ  truyá»n/lÆ°u trá»¯ chÃºng. PhÆ°Æ¡ng phÃ¡p cá»§a chÃºng tÃ´i vÆ°á»£t trá»™i hÆ¡n cÃ¡c Ä‘Æ°á»ng cÆ¡ báº£n vá»›i má»™t biÃªn Ä‘á»™ lá»›n vÃ  Ã­t tham sá»‘ hÆ¡n nhiá»u.

PhÆ°Æ¡ng phÃ¡p Nhiá»‡m vá»¥ Kiáº¿n trÃºc # Tham sá»‘ Äá»™ chÃ­nh xÃ¡c
MÃ´ hÃ¬nh Ä‘Ã£ huáº¥n luyá»‡n C10 AlexNet 1,756,426 84.8
FDD [4] C10 AlexNet 397,000 43.2
SLDD [41] C10 AlexNet 308,200 60.0
DD [48] C10 AlexNet 307,200 54.0
DM [52] C10 AlexNet 30,720 26.0
DSA [51] C10 AlexNet 30,720 28.8
DC [53] C10 AlexNet 30,720 28.3
CAFE [47] C10 AlexNet 30,720 30.3
CAFE+DSA [47] C10 AlexNet 30,720 31.6
DDMT [5] C10 AlexNet 30,720 46.3
Ours C10 AlexNet 17,000 76.69
MÃ´ hÃ¬nh Ä‘Ã£ huáº¥n luyá»‡n C100 3-128-Conv 504,420 56.2
FDD [4] C100 3-128-Conv 317,200 11.5
DM [52] C100 3-128-Conv 307,200 11.4
DSA [51] C100 3-128-Conv 307,200 13.9
DC [53] C100 3-128-Conv 307,200 12.8
CAFE+DSA [47] C100 3-128-Conv 307,200 14.0
DDMT [5] C100 3-128-Conv 307,200 24.3
Ours C100 3-128-Conv 15,000 25.57
MÃ´ hÃ¬nh Ä‘Ã£ huáº¥n luyá»‡n tinyIN 4-128-Conv 857,160 37.6
DM [52] tinyIN 4-128-Conv 2,457,600 3.9
DDMT [5] tinyIN 4-128-Conv 2,457,600 8.8
Ours tinyIN 4-128-Conv 15,000 12.02

5.4. Táº­p dá»¯ liá»‡u vÃ  mÃ´ hÃ¬nh quy mÃ´ lá»›n:
Cho Ä‘áº¿n nay, chÃºng tÃ´i Ä‘Ã£ cung cáº¥p báº±ng chá»©ng ráº±ng phÆ°Æ¡ng phÃ¡p cá»§a chÃºng tÃ´i cÃ³ thá»ƒ vÆ°á»£t trá»™i hÆ¡n cÃ¡c cÃ´ng trÃ¬nh gáº§n Ä‘Ã¢y trong chÆ°ng cáº¥t táº­p dá»¯ liá»‡u, cáº¯t tá»‰a mÃ´ hÃ¬nh vÃ  nÃ©n mÃ´ hÃ¬nh vá» sá»‘ lÆ°á»£ng tham sá»‘ so vá»›i Ä‘á»™ chÃ­nh xÃ¡c. VÃ¬ phÆ°Æ¡ng phÃ¡p cá»§a chÃºng tÃ´i khÃ¡ hiá»‡u quáº£ trong há»c, Ä‘áº·c biá»‡t so vá»›i cÃ¡c cÃ¡ch tiáº¿p cáº­n meta-learning phá»¥ thuá»™c vÃ o Ä‘áº¡o hÃ m báº­c hai cá»§a máº¡ng, chÃºng tÃ´i cÃ³ thá»ƒ Ä‘Ã¡nh giÃ¡ nÃ³ trÃªn cÃ¡c mÃ´ hÃ¬nh quy mÃ´ lá»›n hÆ¡n. ChÃºng tÃ´i Ä‘Ã¡nh giÃ¡ phÆ°Æ¡ng phÃ¡p cá»§a chÃºng tÃ´i trÃªn ImageNet100 vá»›i kiáº¿n trÃºc ResNet-18. Báº£ng 4 cho tháº¥y káº¿t quáº£. PhÆ°Æ¡ng phÃ¡p cá»§a chÃºng tÃ´i Ä‘áº¡t Ä‘Æ°á»£c Ä‘á»™ chÃ­nh xÃ¡c 61.08% vá»›i Ã­t hÆ¡n 1% tham sá»‘, trong khi mÃ´ hÃ¬nh ResNet-18 tiÃªu chuáº©n Ä‘áº¡t Ä‘Æ°á»£c Ä‘á»™ chÃ­nh xÃ¡c 82.1% vá»›i hÆ¡n 11 triá»‡u tham sá»‘. VÃ¬ ResNet-18 lÃ  má»™t mÃ´ hÃ¬nh khá»•ng lá»“, chÃºng tÃ´i sá»­ dá»¥ng má»™t trong nhá»¯ng kháº£ nÄƒng Ä‘á»™c Ä‘Ã¡o cá»§a PRANC, Ä‘Ã³ lÃ  táº¡o ra máº¡ng má»™t cÃ¡ch linh hoáº¡t. ChÃºng tÃ´i chá»‰ sá»­ dá»¥ng má»™t GPU NVIDIA 3090 duy nháº¥t vÃ  huáº¥n luyá»‡n mÃ´ hÃ¬nh cá»§a chÃºng tÃ´i trong 200 epoch, sá»­ dá»¥ng trÃ¬nh tá»‘i Æ°u hÃ³a Adam vÃ  bá»™ láº­p lá»‹ch bÆ°á»›c vá»›i Î³ = 0.5 cho má»—i 50 epoch vÃ  tá»‘c Ä‘á»™ há»c ban Ä‘áº§u lÃ  0.001. NgoÃ i ra, chÃºng tÃ´i phÃ¢n phá»‘i ngÃ¢n sÃ¡ch vector Î± cá»§a chÃºng tÃ´i qua cÃ¡c lá»›p, tá»©c lÃ , chÃºng tÃ´i sá»­ dá»¥ng 4,000 há»‡ sá»‘ cho má»—i lá»›p cá»§a bá»™ mÃ£ hÃ³a tÃ­ch cháº­p vÃ  20,000 há»‡ sá»‘ cho bá»™ phÃ¢n loáº¡i cá»§a chÃºng tÃ´i (cho chÃºng tÃ´i tá»•ng cá»™ng 100,000 há»‡ sá»‘).

Báº£ng 4. Káº¿t quáº£ cá»§a phÆ°Æ¡ng phÃ¡p chÃºng tÃ´i trÃªn táº­p dá»¯ liá»‡u ImageNet-100 vÃ  ResNet-18. 19,200 lÃ  tá»•ng sá»‘ tham sá»‘ cá»§a táº¥t cáº£ cÃ¡c lá»›p BatchNorm trong mÃ´ hÃ¬nh cá»§a chÃºng tÃ´i

PhÆ°Æ¡ng phÃ¡p # Tham sá»‘ Äá»™ chÃ­nh xÃ¡c
mÃ´ hÃ¬nh Ä‘Ã£ huáº¥n luyá»‡n 11,227,812 82.1%
HashedNet [6] 110,000 + (19,200) 52.96%
Ours 100,000 + (19,200) 61.08%
Ours 200,000 + (19,200) 67.28%

5.5. NghiÃªn cá»©u ablation:
Trong PRANC, k, sá»‘ lÆ°á»£ng mÃ´ hÃ¬nh cÆ¡ sá»Ÿ, lÃ  má»™t siÃªu tham sá»‘. Má»™t cÃ¢u há»i lÃ : "k sáº½ áº£nh hÆ°á»Ÿng Ä‘áº¿n hiá»‡u suáº¥t nhÆ° tháº¿ nÃ o?" HÆ¡n ná»¯a, cÃ³ thá»ƒ tranh luáº­n ráº±ng "táº¡i sao chÃºng ta cá»‘ gáº¯ng tÃ¬m má»™t tá»• há»£p tuyáº¿n tÃ­nh chÃ­nh xÃ¡c trong nhiá»‡m vá»¥? táº¡i sao khÃ´ng cá»‘ gáº¯ng há»“i quy toÃ n bá»™ máº¡ng Ä‘Ã£ Ä‘Æ°á»£c huáº¥n luyá»‡n?" NgoÃ i ra, "k cÃ³ thá»ƒ quan trá»ng hÆ¡n kiáº¿n trÃºc khÃ´ng? tá»©c lÃ , chÃºng ta cÃ³ thá»ƒ sá»­ dá»¥ng k lá»›n vá»›i má»™t máº¡ng nhá» vÃ  váº«n cÃ³ Ä‘á»™ chÃ­nh xÃ¡c cao khÃ´ng?" Trong pháº§n nÃ y, chÃºng tÃ´i tráº£ lá»i nhá»¯ng cÃ¢u há»i nÃ y.

Äá»™ nháº¡y cáº£m vá»›i háº¡t giá»‘ng: VÃ¬ má»™t trong nhá»¯ng á»©ng dá»¥ng cá»§a PRANC lÃ  trong há»c liÃªn bang, Ä‘Ã¡ng Ä‘á»ƒ tháº£o luáº­n vá» kháº£ nÄƒng mÃ£ hÃ³a giáº£ cá»§a nÃ³. ChÃºng tÃ´i thÃ­ nghiá»‡m vá»›i viá»‡c thay Ä‘á»•i háº¡t giá»‘ng táº¡i thá»i Ä‘iá»ƒm tÃ¡i táº¡o. TrÃªn CIFAR-10 vá»›i AlexNet, vá»›i má»™t thay Ä‘á»•i nhá» trong háº¡t giá»‘ng, Ä‘á»™ chÃ­nh xÃ¡c cá»§a mÃ´ hÃ¬nh Ä‘Æ°á»£c tÃ¡i táº¡o giáº£m tá»« 74.0% xuá»‘ng 9.4%, gáº§n vá»›i ngáº«u nhiÃªn. Äiá»u nÃ y Ä‘Æ°á»£c mong Ä‘á»£i vÃ¬ cÃ¡c mÃ´ hÃ¬nh cÆ¡ sá»Ÿ má»›i khÃ´ng tÆ°Æ¡ng quan vá»›i nhá»¯ng cÃ¡i Ä‘Æ°á»£c sá»­ dá»¥ng trong huáº¥n luyá»‡n. Thá»±c táº¿ nÃ y cÃ³ nghÄ©a lÃ  háº¡t giá»‘ng cÃ³ thá»ƒ hoáº¡t Ä‘á»™ng nhÆ° má»™t khÃ³a chung giá»¯a cÃ¡c tÃ¡c nhÃ¢n vÃ  ngay cáº£ khi Î± bá»‹ cháº·n, viá»‡c tÃ¡i táº¡o mÃ´ hÃ¬nh gáº§n nhÆ° khÃ´ng thá»ƒ. Do Ä‘Ã³, trong cÃ¡c á»©ng dá»¥ng há»c liÃªn bang cÃ³ liÃªn quan Ä‘áº¿n truyá»n thÃ´ng an toÃ n cá»§a cÃ¡c mÃ´ hÃ¬nh há»c sÃ¢u, PRANC cÃ³ thá»ƒ Ä‘Æ°á»£c sá»­ dá»¥ng nhÆ° cáº£ phÆ°Æ¡ng phÃ¡p nÃ©n vÃ  mÃ£ hÃ³a.

Há»“i quy Î¸âˆ— trá»±c tiáº¿p: ChÃºng ta cÃ³ thá»ƒ Ä‘áº§u tiÃªn huáº¥n luyá»‡n má»™t mÃ´ hÃ¬nh Ä‘á»ƒ cÃ³ Î¸âˆ— vÃ  sau Ä‘Ã³ tá»‘i Æ°u hÃ³a cho Î± báº±ng cÃ¡ch há»“i quy giáº£i phÃ¡p Ä‘Ã³ báº±ng cÃ¡ch sá»­ dá»¥ng máº¥t mÃ¡t MSE trong khÃ´ng gian tham sá»‘. NhÆ° Ä‘Æ°á»£c thá»ƒ hiá»‡n trong HÃ¬nh 2, Ä‘iá»u nÃ y cÃ³ thá»ƒ khÃ´ng thÃ nh cÃ´ng vÃ¬ mÃ´ hÃ¬nh tá»‘i Æ°u cÃ³ thá»ƒ khÃ´ng náº±m trong span cá»§a cÃ¡c mÃ´ hÃ¬nh cÆ¡ sá»Ÿ, vÃ  cÅ©ng máº¥t mÃ¡t MSE trong khÃ´ng gian tham sá»‘ khÃ´ng nháº¥t thiáº¿t tÆ°Æ¡ng quan vá»›i máº¥t mÃ¡t nhiá»‡m vá»¥. Báº£ng 5 cho tháº¥y ráº±ng Ä‘á»™ chÃ­nh xÃ¡c cá»§a Ä‘Æ°á»ng cÆ¡ báº£n nÃ y sá»­ dá»¥ng 10,000 tham sá»‘ gáº§n vá»›i ngáº«u nhiÃªn.

TÃ¡c Ä‘á»™ng cá»§a viá»‡c thay Ä‘á»•i k so vá»›i kiáº¿n trÃºc: ChÃºng tÃ´i thá»±c hiá»‡n má»™t nghiÃªn cá»©u ablation Ä‘á»ƒ hiá»ƒu tÃ¡c Ä‘á»™ng cá»§a sá»‘ lÆ°á»£ng mÃ´ hÃ¬nh cÆ¡ sá»Ÿ, k so vá»›i kiáº¿n trÃºc cá»§a mÃ´ hÃ¬nh. NgÆ°á»i ta cÃ³ thá»ƒ láº­p luáº­n ráº±ng Ä‘Ã´i khi tá»‘t hÆ¡n lÃ  thiáº¿t káº¿ má»™t kiáº¿n trÃºc tá»‘t hÆ¡n thay vÃ¬ tÄƒng sá»‘ lÆ°á»£ng Î±. á» Ä‘Ã¢y, chÃºng tÃ´i thay Ä‘á»•i k

--- TRANG 7 ---
Báº£ng 5. Káº¿t quáº£ há»“i quy má»™t mÃ´ hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c báº±ng cÃ¡ch sá»­ dá»¥ng 10,000 mÃ´ hÃ¬nh cÆ¡ sá»Ÿ. C10 vÃ  C100 biá»ƒu thá»‹ táº­p dá»¯ liá»‡u CIFAR-10 vÃ  CIFAR-100 vÃ  tinyIN biá»ƒu thá»‹ táº­p dá»¯ liá»‡u tiny ImageNet

Táº­p dá»¯ liá»‡u Kiáº¿n trÃºc Äá»™ chÃ­nh xÃ¡c Ä‘áº§y Ä‘á»§ Äá»™ chÃ­nh xÃ¡c há»“i quy
C10 AlexNet 84.8 % 10.0%
C10 LeNet [24] 73.5% 12.74%
C100 3-128-Conv 56.2 % 1.14%
C100 AlexNet 50.7% 1.0%
tinyIN 4-128-Conv 37.6 % 0.5%

tá»« 1,000 Ä‘áº¿n 20,000 cho LeNet, AlexNet, ResNet-20, vÃ  ResNe-56 trÃªn CIFAR-10 vÃ  váº½ Ä‘á»™ chÃ­nh xÃ¡c trong HÃ¬nh 3. Táº¥t cáº£ cÃ¡c thÃ­ nghiá»‡m Ä‘Ã£ Ä‘Æ°á»£c thá»±c hiá»‡n trong cÃ¹ng má»™t thiáº¿t láº­p vá»›i 400 epoch vá»›i trÃ¬nh tá»‘i Æ°u hÃ³a Adam. NhÆ° mong Ä‘á»£i, Ä‘á»™ chÃ­nh xÃ¡c tÄƒng khi chÃºng ta tÄƒng sá»‘ lÆ°á»£ng hÃ m cÆ¡ sá»Ÿ. Tuy nhiÃªn, nhÆ° chÃºng ta cÃ³ thá»ƒ tháº¥y, kiáº¿n trÃºc cÃ³ tÃ¡c Ä‘á»™ng nhiá»u hÆ¡n Ä‘áº¿n Ä‘á»™ chÃ­nh xÃ¡c so vá»›i k.

HÃ¬nh 3. Minh há»a tÃ¡c Ä‘á»™ng cá»§a k trong Ä‘á»™ chÃ­nh xÃ¡c cá»§a cÃ¡c kiáº¿n trÃºc khÃ¡c nhau trÃªn CIFAR-10. Äá»™ chÃ­nh xÃ¡c cáº£i thiá»‡n báº±ng cÃ¡ch tÄƒng sá»‘ lÆ°á»£ng mÃ´ hÃ¬nh cÆ¡ sá»Ÿ. Tuy nhiÃªn, kiáº¿n trÃºc Ä‘Ã³ng vai trÃ² quan trá»ng hÆ¡n trong Ä‘á»™ chÃ­nh xÃ¡c so vá»›i sá»‘ lÆ°á»£ng cÆ¡ sá»Ÿ.

6. ThÃ­ nghiá»‡m vá» nÃ©n hÃ¬nh áº£nh
NhÆ° má»™t á»©ng dá»¥ng khÃ¡c cá»§a PRANC, á»Ÿ Ä‘Ã¢y chÃºng tÃ´i cho tháº¥y ráº±ng chÃºng ta cÃ³ thá»ƒ nÃ©n má»™t hÃ¬nh áº£nh báº±ng cÃ¡ch nÃ©n máº¡ng nÆ¡-ron áº©n (INR) Ä‘Æ°á»£c overfitted vá»›i hÃ¬nh áº£nh. MÃ´ hÃ¬nh INR nháº­p tá»a Ä‘á»™ cá»§a má»™t pixel vÃ  xuáº¥t mÃ u cá»§a pixel Ä‘Ã³. ChÃºng tÃ´i sáº½ chá»‰ lÆ°u trá»¯ hoáº·c truyá»n thÃ´ng háº¡t giá»‘ng cá»§a trÃ¬nh táº¡o giáº£ ngáº«u nhiÃªn vÃ  cÃ¡c giÃ¡ trá»‹ Î±. ChÃºng tÃ´i sá»­ dá»¥ng [42] lÃ m mÃ´ hÃ¬nh INR cá»§a chÃºng tÃ´i. INR lÃ  má»™t mÃ´ hÃ¬nh MLP 4 lá»›p (3 lá»›p áº©n) vá»›i 512 nÆ¡-ron táº¡i má»—i lá»›p vÃ  má»™t LayerNorm [1] sau má»—i lá»›p. ChÃºng tÃ´i mÃ£ hÃ³a tá»a Ä‘á»™ pixel trong Ä‘áº§u vÃ o thÃ nh 512 chiá»u báº±ng cÃ¡ch sá»­ dá»¥ng Ã¡nh xáº¡ Fourier vÃ  sá»­ dá»¥ng ba nÆ¡-ron trong Ä‘áº§u ra cho hÃ¬nh áº£nh RGB (cÃ¡c giÃ¡ trá»‹ mÃ u) vÃ  má»™t nÆ¡-ron cho hÃ¬nh áº£nh X-ray.

ChÃºng tÃ´i sá»­ dá»¥ng Ä‘iá»ƒm ná»•i Ä‘á»™ chÃ­nh xÃ¡c má»™t ná»­a cho cÃ¡c Î± Ä‘á»ƒ giáº£m thÃªm chi phÃ­ lÆ°u trá»¯. ChÃºng tÃ´i sá»­ dá»¥ng má»™t táº­p cÃ¡c Î± khÃ¡c nhau cho má»—i lá»›p cá»§a máº¡ng.

Äá»ƒ giáº£m dáº¥u chÃ¢n bá»™ nhá»›, chÃºng tÃ´i chia ma tráº­n máº¡ng cÆ¡ sá»Ÿ Ë†Î¸ thÃ nh cÃ¡c khá»‘i nhá» hÆ¡n vÃ  táº¡o ra vÃ  sau Ä‘Ã³ loáº¡i bá» má»—i khá»‘i táº¡i GPU cho má»—i láº§n láº·p cá»§a viá»‡c tá»‘i Æ°u hÃ³a. TÆ°Æ¡ng tá»± nhÆ° gradient descent ngáº«u nhiÃªn, chÃºng tÃ´i láº¥y máº«u ngáº«u nhiÃªn má»™t táº­p con cÃ¡c pixel Ä‘á»ƒ Ä‘Æ°á»£c tá»‘i Æ°u hÃ³a táº¡i má»—i láº§n láº·p, dáº«n Ä‘áº¿n há»™i tá»¥ nhanh hÆ¡n do cáº­p nháº­t tham sá»‘ thÆ°á»ng xuyÃªn hÆ¡n.

ChÃºng tÃ´i Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh cá»§a chÃºng tÃ´i trÃªn ba táº­p dá»¯ liá»‡u khÃ¡c nhau: táº­p dá»¯ liá»‡u Kodak [22] chá»©a 24 hÃ¬nh áº£nh khÃ´ng nÃ©n cÃ³ kÃ­ch thÆ°á»›c 512Ã—768, táº­p kiá»ƒm tra CLIC-mobile [44] chá»©a 178 hÃ¬nh áº£nh Ä‘á»™ phÃ¢n giáº£i cao (vÃ­ dá»¥, 1512Ã—2016), vÃ  64 hÃ¬nh áº£nh Ä‘Æ°á»£c láº¥y máº«u ngáº«u nhiÃªn tá»« táº­p dá»¯ liá»‡u NIH Chest X-ray [49] bao gá»“m 100,000 hÃ¬nh áº£nh X-ray ngá»±c khÃ´ng Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh danh tÃ­nh cÃ³ kÃ­ch thÆ°á»›c 1024Ã—1024.

ÄÆ°á»ng cÆ¡ báº£n. ChÃºng tÃ´i so sÃ¡nh phÆ°Æ¡ng phÃ¡p cá»§a chÃºng tÃ´i vá»›i cÃ¡c codec hÃ¬nh áº£nh thá»§ cÃ´ng sau: JEPG, JPEG2000, vÃ  WebP. Má»¥c tiÃªu cá»§a chÃºng tÃ´i lÃ  cho tháº¥y ráº±ng PRANC lÃ  má»™t khung tá»•ng quÃ¡t hoáº¡t Ä‘á»™ng tá»‘t khi chá»‰ Ä‘Æ¡n giáº£n Ã¡p dá»¥ng cho nÃ©n INR ngay láº­p tá»©c. Do Ä‘Ã³, chÃºng tÃ´i khÃ´ng so sÃ¡nh nÃ³ vá»›i cÃ¡c codec tiÃªn tiáº¿n hÆ¡n nhÆ° BPG vÃ  VTM vÃ¬ chÃºng Ä‘Æ°á»£c thiáº¿t káº¿ cao vÃ  bao gá»“m cÃ¡c thÃ nh pháº§n nhÆ° mÃ£ hÃ³a entropy. Nhá»¯ng káº¿t quáº£ Ä‘Ã³ Ä‘Æ°á»£c trÃ¬nh bÃ y trong tÃ i liá»‡u bá»• sung. ChÃºng tÃ´i cÅ©ng so sÃ¡nh vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p nÃ©n hÃ¬nh áº£nh dá»±a trÃªn há»c trong pháº§n bá»• sung (BMS, MBT, vÃ  CST). LÆ°u Ã½ ráº±ng, khÃ´ng giá»‘ng nhÆ° PRANC, cÃ¡c phÆ°Æ¡ng phÃ¡p nÃ y yÃªu cáº§u má»™t táº­p dá»¯ liá»‡u lá»›n cÃ¡c hÃ¬nh áº£nh Ä‘á»ƒ huáº¥n luyá»‡n trÆ°á»›c auto-encoder cá»§a chÃºng. Äiá»u nÃ y háº¡n cháº¿ cÃ¡c á»©ng dá»¥ng vÃ  cÅ©ng cÃ³ thá»ƒ lÃ m giáº£m káº¿t quáº£ cho cÃ¡c Ä‘iá»ƒm dá»¯ liá»‡u ngoÃ i phÃ¢n phá»‘i. VÃ­ dá»¥, khÃ´ng giá»‘ng nhÆ° PRANC, cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn má»™t táº­p huáº¥n luyá»‡n cÃ³ thá»ƒ khÃ´ng phÃ¹ há»£p cho dá»¯ liá»‡u y táº¿ vÃ¬ chÃºng cÃ³ thá»ƒ khÃ´ng trung thá»±c vá»›i cÃ¡c báº¥t thÆ°á»ng cá»¥ thá»ƒ cho bá»‡nh nhÃ¢n khÃ´ng Ä‘Æ°á»£c Ä‘áº¡i diá»‡n trong dá»¯ liá»‡u huáº¥n luyá»‡n.

COIN [10] cÃ³ láº½ gáº§n nháº¥t vá»›i phÆ°Æ¡ng phÃ¡p cá»§a chÃºng tÃ´i huáº¥n luyá»‡n má»™t INR báº±ng cÃ¡ch sá»­ dá»¥ng SIREN [39] vÃ  lÆ°u trá»¯ táº¥t cáº£ cÃ¡c tham sá»‘. VÃ¬ COIN khÃ´ng sá»­ dá»¥ng Ã¡nh xáº¡ Fourier, Ä‘á»ƒ so sÃ¡nh cÃ´ng báº±ng, chÃºng tÃ´i táº¡o ra má»™t Ä‘Æ°á»ng cÆ¡ báº£n tÆ°Æ¡ng tá»±, gá»i lÃ  'INR Ä‘Ã£ huáº¥n luyá»‡n,' sá»­ dá»¥ng máº¡ng MLP cá»§a chÃºng tÃ´i Ä‘Æ°á»£c mÃ´ táº£ á»Ÿ trÃªn mÃ  khÃ´ng cÃ³ khung PRANC. Äá»‘i vá»›i INR Ä‘Ã£ huáº¥n luyá»‡n, chÃºng tÃ´i giáº£m chiá»u rá»™ng cá»§a máº¡ng Ä‘á»ƒ phÃ¹ há»£p vá»›i tá»· lá»‡ nÃ©n cá»§a phÆ°Æ¡ng phÃ¡p chÃºng tÃ´i vÃ  sá»­ dá»¥ng Ä‘iá»ƒm ná»•i Ä‘á»™ chÃ­nh xÃ¡c má»™t ná»­a.

Káº¿t quáº£. ChÃºng tÃ´i Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh cá»§a chÃºng tÃ´i vá»›i hai thÆ°á»›c Ä‘o: PSNR vÃ  MS-SSIM. LÆ°u Ã½ ráº±ng chÃºng tÃ´i cá»‘ Ä‘á»‹nh kiáº¿n trÃºc máº¡ng vÃ  thay Ä‘á»•i sá»‘ lÆ°á»£ng giÃ¡ trá»‹ Î± Ä‘á»ƒ cÃ³ cÃ¡c giÃ¡ trá»‹ bit-per-pixel (bpp) khÃ¡c nhau cho má»—i hÃ¬nh áº£nh. ChÃºng tÃ´i bÃ¡o cÃ¡o káº¿t quáº£ cho táº­p dá»¯ liá»‡u Kodak trong HÃ¬nh 13 vÃ  táº­p dá»¯ liá»‡u CLIC-mobile trong Báº£ng 11. PhÆ°Æ¡ng phÃ¡p cá»§a chÃºng tÃ´i vÆ°á»£t trá»™i hÆ¡n JPEG vÃ  INR. ChÃºng tÃ´i bÃ¡o cÃ¡o káº¿t quáº£ cá»§a X-ray ngá»±c trong Báº£ng 7. Má»™t hÃ¬nh áº£nh vÃ­ dá»¥ Ä‘Æ°á»£c thá»ƒ hiá»‡n trong HÃ¬nh 6 cho táº­p dá»¯ liá»‡u Kodac vÃ  trong HÃ¬nh 23 cho táº­p dá»¯ liá»‡u X-ray.

Ablation. VÃ¬ chÃºng tÃ´i tÃ¡i táº¡o cÃ¡c trá»ng sá»‘ mÃ´ hÃ¬nh vá»›i cÃ¡c giÃ¡ trá»‹ Î±, ngÆ°á»i ta cÃ³ thá»ƒ thay Ä‘á»•i kÃ­ch thÆ°á»›c cá»§a kiáº¿n trÃºc mÃ  khÃ´ng thay Ä‘á»•i sá»‘ lÆ°á»£ng tham sá»‘ (giÃ¡ trá»‹ Î±), do Ä‘Ã³, trong PRANC, chÃºng ta cÃ³ thá»ƒ tÄƒng cáº£ chiá»u rá»™ng vÃ  chiá»u sÃ¢u mÃ  khÃ´ng thay Ä‘á»•i bit-rate. ChÃºng tÃ´i giá»¯ sá»‘ lÆ°á»£ng tham sá»‘ k = 102 K vÃ  thay Ä‘á»•i cáº£ chiá»u rá»™ng máº¡ng vÃ  chiá»u sÃ¢u cá»§a mÃ´ hÃ¬nh MLP. Káº¿t quáº£ trÃªn táº­p dá»¯ liá»‡u Kodak Ä‘Æ°á»£c thá»ƒ hiá»‡n trong Báº£ng 8. ThÃº vá»‹ lÃ , chÃºng ta cÃ³ thá»ƒ cáº£i thiá»‡n hiá»‡u suáº¥t báº±ng cÃ¡ch tÄƒng Ä‘á»™ sÃ¢u mÃ´ hÃ¬nh trong khi giá»¯ sá»‘ lÆ°á»£ng

--- TRANG 8 ---
HÃ¬nh 4. NÃ©n HÃ¬nh áº£nh Táº­p dá»¯ liá»‡u Kodak: PhÆ°Æ¡ng phÃ¡p cá»§a chÃºng tÃ´i vÆ°á»£t trá»™i hÆ¡n JPEG vÃ  'INR Ä‘Ã£ huáº¥n luyá»‡n' trÃªn cáº£ Ä‘Ã¡nh giÃ¡ PSNR vÃ  MS-SSIM á»Ÿ cÃ¡c tá»· lá»‡ bit khÃ¡c nhau. LÆ°u Ã½ ráº±ng, khÃ´ng giá»‘ng nhÆ° cÃ¡c Ä‘Æ°á»ng cÆ¡ báº£n khÃ¡c, phÆ°Æ¡ng phÃ¡p cá»§a chÃºng tÃ´i Ä‘Æ°á»£c há»c trÃªn má»™t hÃ¬nh áº£nh duy nháº¥t vÃ  khÃ´ng Ä‘Æ°á»£c lÃ m thá»§ cÃ´ng, ngoáº¡i trá»« kiáº¿n trÃºc cá»§a mÃ´ hÃ¬nh INR, lÃ  má»™t MLP Ä‘Æ¡n giáº£n.

tham sá»‘ cÃ³ thá»ƒ há»c khÃ´ng Ä‘á»•i.

Sáº¯p xáº¿p giÃ¡ trá»‹ Î±. Trong HÃ¬nh 14, chÃºng tÃ´i thá»ƒ hiá»‡n cÃ¡c hÃ¬nh áº£nh Ä‘Æ°á»£c tÃ¡i táº¡o vá»›i má»™t táº­p con cÃ¡c giÃ¡ trá»‹ Î± cÃ³ giÃ¡ trá»‹ tuyá»‡t Ä‘á»‘i lá»›n nháº¥t. VÃ¬ chÃºng tÃ´i cÃ³ má»™t táº­p cÃ¡c Î± khÃ¡c nhau cho má»—i lá»›p cá»§a MLP trong nÃ©n hÃ¬nh áº£nh, chÃºng tÃ´i sáº¯p xáº¿p cÃ¡c giÃ¡ trá»‹ tuyá»‡t Ä‘á»‘i vÃ  chá»n p% hÃ ng Ä‘áº§u cá»§a má»—i lá»›p cÃ³ giÃ¡ trá»‹ cao hÆ¡n. ChÃºng tÃ´i thay Ä‘á»•i p vÃ  trá»±c quan hÃ³a cÃ¡c hÃ¬nh áº£nh Ä‘Æ°á»£c tÃ¡i táº¡o cho má»—i giÃ¡ trá»‹ p. Trong tÃ i liá»‡u bá»• sung, cho thiáº¿t láº­p phÃ¢n loáº¡i hÃ¬nh áº£nh, chÃºng tÃ´i cho tháº¥y ráº±ng trong viá»‡c tÃ¡i táº¡o mÃ´ hÃ¬nh ResNet báº±ng cÃ¡ch sá»­ dá»¥ng má»™t táº­p má»™t pháº§n cÃ¡c giÃ¡ trá»‹ Î±, viá»‡c chá»n cÃ¡c giÃ¡ trá»‹ |Î±| lá»›n hÆ¡n dáº«n Ä‘áº¿n Ä‘á»™ chÃ­nh xÃ¡c tá»‘t hÆ¡n nhiá»u so vá»›i viá»‡c chá»n má»™t táº­p con ngáº«u nhiÃªn.

Chi tiáº¿t triá»ƒn khai. Äá»‘i vá»›i má»—i hÃ¬nh áº£nh, chÃºng tÃ´i huáº¥n luyá»‡n cÃ¡c giÃ¡ trá»‹ Î± vá»›i 10k láº§n láº·p trÃªn Kodak vÃ  5k láº§n láº·p trÃªn táº­p dá»¯ liá»‡u CLIC-mobile. Má»—i láº§n láº·p xá»­ lÃ½ 25% pixel cá»§a hÃ¬nh áº£nh Ä‘Æ°á»£c láº¥y máº«u ngáº«u nhiÃªn. LÆ°u Ã½ ráº±ng viá»‡c tÄƒng sá»‘ láº§n láº·p khÃ´ng thá»ƒ lÃ m há»ng mÃ´ hÃ¬nh vÃ¬ má»¥c tiÃªu lÃ  overfit vá»›i hÃ¬nh áº£nh vÃ  kháº£ nÄƒng tá»•ng quÃ¡t hÃ³a khÃ´ng pháº£i lÃ  váº¥n Ä‘á». ChÃºng tÃ´i sá»­ dá»¥ng trÃ¬nh tá»‘i Æ°u hÃ³a PyTorch Adam [21] vá»›i tá»‘c Ä‘á»™ há»c ban Ä‘áº§u lÃ  1eâˆ’3 vÃ  bá»™ láº­p lá»‹ch Cosine. ThÃªm chi tiáº¿t vá» sá»‘ lÆ°á»£ng giÃ¡ trá»‹ Î± trÃªn má»—i lá»›p cho má»—i bpp trong tÃ i liá»‡u bá»• sung.

7. HÆ°á»›ng tÆ°Æ¡ng lai
PRANC cÃ³ thá»ƒ cho phÃ©p nhiá»u hÆ°á»›ng tÆ°Æ¡ng lai:
MÃ´ hÃ¬nh táº¡o sinh cho bá»™ nhá»›-phÃ¡t láº¡i: PhÆ°Æ¡ng phÃ¡p cá»§a chÃºng tÃ´i cÃ³ thá»ƒ

Báº£ng 6. NÃ©n HÃ¬nh áº£nh Táº­p dá»¯ liá»‡u CLIC-mobile: PRANC vÆ°á»£t trá»™i hÆ¡n JPEG vÃ  JPEG2000 vá»›i bpp nhá» hÆ¡n trÃªn táº­p dá»¯ liá»‡u nÃ y.

MÃ´ hÃ¬nh bpp PSNR MS-SSIM
WebP 0.185 30.07 0.940
JPEG2000 0.126 29.40 0.918
JPEG 0.195 24.82 0.836
INR Ä‘Ã£ huáº¥n luyá»‡n 0.125 26.93 0.864
PRANC (ours) 0.119 29.71 0.920

Báº£ng 7. NÃ©n hÃ¬nh áº£nh Táº­p dá»¯ liá»‡u X-ray Ngá»±c: ChÃºng tÃ´i so sÃ¡nh PRANC vá»›i JPEG cho hÃ¬nh áº£nh X-ray. PhÆ°Æ¡ng phÃ¡p cá»§a chÃºng tÃ´i tá»‘t hÆ¡n JPEG vá»›i bpp tháº¥p hÆ¡n. VÃ¬ khÃ´ng giá»‘ng nhÆ° auto-encoder, PRANC khÃ´ng sá»­ dá»¥ng báº¥t ká»³ huáº¥n luyá»‡n dá»±a trÃªn táº­p há»£p nÃ o, nÃ³ cÃ³ thá»ƒ phÃ¹ há»£p hÆ¡n cho hÃ¬nh áº£nh y táº¿ vÃ¬ nÃ³ cÃ³ thá»ƒ báº£o tá»“n cÃ¡c artifact ngoÃ i phÃ¢n phá»‘i quan trá»ng cho má»¥c Ä‘Ã­ch cháº©n Ä‘oÃ¡n. Tuy nhiÃªn, chÃºng tÃ´i Ä‘á»ƒ nghiÃªn cá»©u Ä‘iá»u nÃ y cho cÃ´ng viá»‡c tÆ°Æ¡ng lai.

MÃ´ hÃ¬nh PRANC JPEG
bpp 0.152 0.168
PSNR 36.28 34.25
MS-SSIM 0.972 0.921

Báº£ng 8. áº¢nh hÆ°á»Ÿng cá»§a viá»‡c tÄƒng chiá»u rá»™ng/chiá»u sÃ¢u cá»§a mÃ´ hÃ¬nh: ChÃºng ta cÃ³ thá»ƒ tÄƒng cáº£ chiá»u sÃ¢u vÃ  chiá»u rá»™ng cá»§a mÃ´ hÃ¬nh MLP mÃ  khÃ´ng thay Ä‘á»•i sá»‘ lÆ°á»£ng tham sá»‘. Khi thay Ä‘á»•i chiá»u sÃ¢u, chÃºng tÃ´i phÃ¢n phá»‘i láº¡i sá»‘ lÆ°á»£ng giÃ¡ trá»‹ Î± Ä‘á»u giá»¯a cÃ¡c lá»›p Ä‘á»ƒ giá»¯ tá»•ng sá»‘ khÃ´ng Ä‘á»•i. ThÃªm chi tiáº¿t trong Supp.

Chiá»u rá»™ng 128 256 512 1024
PSNR 30.00 32.05 31.5 31.32
MS-SSIM 0.937 0.963 0.959 0.961
Chiá»u sÃ¢u 3 4 5
PSNR 30.78 31.5 32.38
MS-SSIM 0.978 0.959 0.965

Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ nÃ©n má»™t mÃ´ hÃ¬nh táº¡o sinh (vÃ­ dá»¥, GAN hoáº·c mÃ´ hÃ¬nh khuáº¿ch tÃ¡n), trong Ä‘Ã³ cÃ¡c tham sá»‘ Î± cÃ³ thá»ƒ Ä‘Æ°á»£c lÆ°u trá»¯ trong tÃ¡c nhÃ¢n hoáº·c gá»­i Ä‘áº¿n tÃ¡c nhÃ¢n khÃ¡c. Sau Ä‘Ã³, báº¥t ká»³ tÃ¡c nhÃ¢n nÃ o cÃ³ thá»ƒ tÃ¡i táº¡o mÃ´ hÃ¬nh trong tÆ°Æ¡ng lai vÃ  rÃºt máº«u tá»« nÃ³ tÆ°Æ¡ng tá»± nhÆ° cÃ¡c máº«u Ä‘Æ°á»£c sá»­ dá»¥ng trÆ°á»›c Ä‘Ã³ Ä‘á»ƒ huáº¥n luyá»‡n mÃ´ hÃ¬nh. Äiá»u nÃ y cho phÃ©p phÃ¡t láº¡i bá»™ nhá»› trong há»c suá»‘t Ä‘á»i trong má»™t tÃ¡c nhÃ¢n duy nháº¥t cÃ³ bá»™ nhá»› háº¡n cháº¿ hoáº·c trong nhiá»u tÃ¡c nhÃ¢n cÃ³ truyá»n thÃ´ng háº¡n cháº¿.

TÃ­nh compact tiáº¿n bá»™: Trong phÆ°Æ¡ng phÃ¡p nÃ y, chÃºng tÃ´i giáº£ Ä‘á»‹nh má»™t táº­p cÃ¡c mÃ´ hÃ¬nh cÆ¡ sá»Ÿ khÃ´ng cÃ³ thá»© tá»± cá»¥ thá»ƒ. Tuy nhiÃªn, ngÆ°á»i ta cÃ³ thá»ƒ tá»‘i Æ°u hÃ³a Î± Ä‘á»ƒ cÃ¡c chá»‰ sá»‘ trÆ°á»›c Ä‘Ã³ cá»§a Î± cÃ³ thá»ƒ tÃ¡i táº¡o má»™t mÃ´ hÃ¬nh cháº¥p nháº­n Ä‘Æ°á»£c. Sau Ä‘Ã³, tÃ¹y thuá»™c vÃ o ngÃ¢n sÃ¡ch truyá»n thÃ´ng hoáº·c lÆ°u trá»¯, tÃ¡c nhÃ¢n Ä‘Ã­ch cÃ³ thá»ƒ quyáº¿t Ä‘á»‹nh cáº§n bao nhiÃªu tham sá»‘ Î± báº±ng cÃ¡ch Ä‘Ã¡nh Ä‘á»•i giá»¯a Ä‘á»™ chÃ­nh xÃ¡c vÃ  tÃ­nh compact. ChÃºng tÃ´i Ä‘Ã£ cho tháº¥y ráº±ng viá»‡c sáº¯p xáº¿p cÃ¡c giÃ¡ trá»‹ Î± lÃ  bÆ°á»›c Ä‘áº§u tiÃªn theo hÆ°á»›ng nÃ y, nhÆ°ng ngÆ°á»i ta cÃ³ thá»ƒ há»c chÃºng theo thá»© tá»± táº§m quan trá»ng giáº£m dáº§n nhÆ° má»™t cÃ´ng viá»‡c tÆ°Æ¡ng lai.

--- TRANG 9 ---
HÃ¬nh 5. áº¢nh hÆ°á»Ÿng cá»§a viá»‡c giá»¯ p% mÃ´ hÃ¬nh cÆ¡ sá»Ÿ vá»›i cÃ¡c giÃ¡ trá»‹ Î± tuyá»‡t Ä‘á»‘i cao nháº¥t. ChÃºng ta cÃ³ Ä‘Æ°á»£c hÃ¬nh áº£nh há»£p lÃ½ vá»›i má»™t táº­p con nhá» hÆ¡n cá»§a cÃ¡c mÃ´ hÃ¬nh cÆ¡ sá»Ÿ. NgÆ°á»i ta cÃ³ thá»ƒ tÃ¡i táº¡o má»™t hÃ¬nh áº£nh xáº¥p xá»‰ khi nháº­n Ä‘Æ°á»£c má»™t táº­p má»™t pháº§n cÃ¡c giÃ¡ trá»‹ Î±, tÆ°Æ¡ng tá»± nhÆ° JPEG tiáº¿n bá»™.

HÃ¬nh áº£nh gá»‘c
Ours (bpp=0.31, PSNR=30.36)Ours (bpp=0.17, PSNR=27.53)
JPEG (bpp=0.31, PSNR=28.85)JPEG (bpp=0.17, PSNR=21.86)

HÃ¬nh 6. Trá»±c quan hÃ³a Kodak. ChÃºng tÃ´i so sÃ¡nh PRANC vá»›i JPEG trÃªn hÃ¬nh áº£nh 15 cá»§a táº­p dá»¯ liá»‡u Kodak. Xem Supp. Ä‘á»ƒ cÃ³ thÃªm vÃ­ dá»¥.

8. Káº¿t luáº­n
ChÃºng tÃ´i Ä‘Ã£ giá»›i thiá»‡u má»™t phÆ°Æ¡ng phÃ¡p Ä‘Æ¡n giáº£n nhÆ°ng hiá»‡u quáº£ cÃ³ thá»ƒ há»c má»™t mÃ´ hÃ¬nh nhÆ° má»™t tá»• há»£p tuyáº¿n tÃ­nh cá»§a má»™t táº­p cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c khá»Ÿi táº¡o ngáº«u nhiÃªn vÃ  cá»‘ Ä‘á»‹nh. MÃ´ hÃ¬nh cuá»‘i cÃ¹ng cÃ³ thá»ƒ Ä‘Æ°á»£c lÆ°u trá»¯ hoáº·c truyá»n thÃ´ng má»™t cÃ¡ch compact báº±ng cÃ¡ch sá»­ dá»¥ng háº¡t giá»‘ng cá»§a trÃ¬nh táº¡o giáº£ ngáº«u nhiÃªn vÃ  cÃ¡c há»‡ sá»‘. HÆ¡n ná»¯a, phÆ°Æ¡ng phÃ¡p cá»§a chÃºng tÃ´i cÃ³ dáº¥u chÃ¢n bá»™ nhá»› nhá» á»Ÿ cÃ¡c giai Ä‘oáº¡n há»c hoáº·c tÃ¡i táº¡o. ChÃºng tÃ´i thá»±c hiá»‡n cÃ¡c thÃ­ nghiá»‡m rá»™ng rÃ£i trÃªn nhiá»u táº­p dá»¯ liá»‡u phÃ¢n loáº¡i hÃ¬nh áº£nh vá»›i nhiá»u kiáº¿n trÃºc vÃ  cÅ©ng trÃªn thiáº¿t láº­p nÃ©n hÃ¬nh áº£nh vÃ  cho tháº¥y ráº±ng phÆ°Æ¡ng phÃ¡p cá»§a chÃºng tÃ´i Ä‘áº¡t Ä‘Æ°á»£c Ä‘á»™ chÃ­nh xÃ¡c tá»‘t hÆ¡n vá»›i Ã­t tham sá»‘ hÆ¡n so vá»›i cÃ¡c Ä‘Æ°á»ng cÆ¡ báº£n SOTA. ChÃºng tÃ´i tin ráº±ng nhiá»u á»©ng dá»¥ng bao gá»“m há»c suá»‘t Ä‘á»i vÃ  há»c phÃ¢n tÃ¡n cÃ³ thá»ƒ hÆ°á»Ÿng lá»£i tá»« Ã½ tÆ°á»Ÿng cá»§a chÃºng tÃ´i. Do Ä‘Ã³, chÃºng tÃ´i hy vá»ng bÃ i bÃ¡o nÃ y má»Ÿ ra cÃ¡nh cá»­a Ä‘á»ƒ nghiÃªn cá»©u cÃ¡c phÆ°Æ¡ng phÃ¡p nÃ©n tiÃªn tiáº¿n hÆ¡n dá»±a trÃªn cÃ¡c máº¡ng ngáº«u nhiÃªn cá»‘ Ä‘á»‹nh.

Háº¡n cháº¿: NhÆ° Ä‘Ã£ tháº£o luáº­n, má»™t sá»‘ tham sá»‘ mÃ´ hÃ¬nh, vÃ­ dá»¥, cÃ¡c lá»›p BatchNorm, khÃ´ng thá»ƒ dá»… dÃ ng Ä‘Æ°á»£c tÃ¡i tham sá»‘ hÃ³a

HÃ¬nh 7. Trá»±c quan hÃ³a X-ray Ngá»±c. ChÃºng tÃ´i so sÃ¡nh PRANC vÃ  JPEG trÃªn má»™t hÃ¬nh áº£nh X-ray Ngá»±c. Xem Supp. Ä‘á»ƒ cÃ³ thÃªm vÃ­ dá»¥.

báº±ng cÃ¡ch sá»­ dá»¥ng phÆ°Æ¡ng phÃ¡p cá»§a chÃºng tÃ´i vÃ¬ chÃºng Ä‘Æ°á»£c tÃ­nh toÃ¡n trá»±c tiáº¿p tá»« dá»¯ liá»‡u thay vÃ¬ giáº£m thiá»ƒu máº¥t mÃ¡t nhiá»‡m vá»¥. Trong bÃ i bÃ¡o nÃ y, chÃºng tÃ´i giáº£ Ä‘á»‹nh chÃºng tÃ´i truyá»n thÃ´ng chÃºng mÃ  khÃ´ng thay Ä‘á»•i vÃ  bao gá»“m chÃºng trong ngÃ¢n sÃ¡ch cá»§a chÃºng tÃ´i. Cuá»‘i cÃ¹ng, PRANC tá»‘n kÃ©m vá» máº·t tÃ­nh toÃ¡n cho má»™t sá»‘ lÆ°á»£ng lá»›n cÆ¡ sá»Ÿ, vÃ¬ váº­y hiá»‡n táº¡i khÃ´ng phÃ¹ há»£p Ä‘á»ƒ huáº¥n luyá»‡n cÃ¡c mÃ´ hÃ¬nh ráº¥t lá»›n.

Lá»i cáº£m Æ¡n: CÃ´ng viá»‡c nÃ y Ä‘Æ°á»£c há»— trá»£ má»™t pháº§n bá»Ÿi CÆ¡ quan Dá»± Ã¡n NghiÃªn cá»©u TiÃªn tiáº¿n Quá»‘c phÃ²ng (DARPA) theo Há»£p Ä‘á»“ng sá»‘ HR00112190135 vÃ  HR00112090023, KhÃ´ng quÃ¢n Hoa Ká»³ theo Há»£p Ä‘á»“ng sá»‘ FA8750-19-C-0098, vÃ  tÃ i trá»£ tá»« cÃ¡c khoáº£n tÃ i trá»£ NSF 1845216 vÃ  1920079. Báº¥t ká»³ Ã½ kiáº¿n, phÃ¡t hiá»‡n, káº¿t luáº­n, hoáº·c khuyáº¿n nghá»‹ nÃ o Ä‘Æ°á»£c thá»ƒ hiá»‡n trong bÃ i bÃ¡o nÃ y lÃ  cá»§a cÃ¡c tÃ¡c giáº£ vÃ  khÃ´ng nháº¥t thiáº¿t pháº£n Ã¡nh quan Ä‘iá»ƒm cá»§a KhÃ´ng quÃ¢n Hoa Ká»³, DARPA, hoáº·c NSF.

--- TRANG 10 ---
TÃ i liá»‡u tham kháº£o
[1] Jimmy Lei Ba, Jamie Ryan Kiros, vÃ  Geoffrey E Hinton. Layer normalization. arXiv preprint arXiv:1607.06450, 2016. 7
[2] Hessam Bagherinezhad, Mohammad Rastegari, vÃ  Ali Farhadi. Lcnn: Lookup-based convolutional neural network. Trong Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, trang 7120â€“7129, 2017. 3
[3] Johannes BallÃ©, David Minnen, Saurabh Singh, Sung Jin Hwang, vÃ  Nick Johnston. Variational image compression with a scale hyperprior. Trong International Conference on Learning Representations, 2018. 3
[4] Ondrej Bohdal, Yongxin Yang, vÃ  Timothy Hospedales. Flexible dataset distillation: Learn labels instead of images. arXiv preprint arXiv:2006.08572, 2020. 3, 6
[5] George Cazenavette, Tongzhou Wang, Antonio Torralba, Alexei A Efros, vÃ  Jun-Yan Zhu. Dataset distillation by matching training trajectories. arXiv preprint arXiv:2203.11932, 2022. 3, 5, 6
[6] Wenlin Chen, James Wilson, Stephen Tyree, Kilian Weinberger, vÃ  Yixin Chen. Compressing neural networks with the hashing trick. Trong International conference on machine learning, trang 2285â€“2294. PMLR, 2015. 1, 2, 6
[7] Xiaohan Chen, Jason Zhang, vÃ  Zhangyang Wang. Peek-a-boo: What (more) is disguised in a randomly weighted neural network, and how to find it efficiently. Trong International Conference on Learning Representations, 2021. 2
[8] Yaim Cooper. Global minima of overparameterized neural networks. SIAM Journal on Mathematics of Data Science, 3(2):676â€“691, 2021. 2
[9] JCMSA Djelouah vÃ  Christopher Schroers. Content adaptive optimization for neural image compression. Trong Proceedings of the CVPR, 2019. 3
[10] Emilien Dupont, Adam GoliÅ„ski, Milad Alizadeh, Yee Whye Teh, vÃ  Arnaud Doucet. Coin: Compression with implicit neural representations. arXiv preprint arXiv:2103.03123, 2021. 3, 7
[11] Utku Evci, Trevor Gale, Jacob Menick, Pablo Samuel Castro, vÃ  Erich Elsen. Rigging the lottery: Making all tickets winners. Trong International Conference on Machine Learning, trang 2943â€“2952. PMLR, 2020. 5
[12] Claudio Gallicchio vÃ  Simone Scardapane. Deep randomized neural networks. Recent Trends in Learning From Data, trang 43â€“68, 2020. 2
[13] Tiansheng Guo, Jing Wang, Ze Cui, Yihui Feng, Yunying Ge, vÃ  Bo Bai. Variable rate image compression with content adaptive optimization. Trong Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops, trang 122â€“123, 2020. 3
[14] Kai Han, Yunhe Wang, Qi Tian, Jianyuan Guo, Chunjing Xu, vÃ  Chang Xu. Ghostnet: More features from cheap operations. Trong Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, trang 1580â€“1589, 2020. 3
[15] Song Han, Huizi Mao, vÃ  William J Dally. Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding. arXiv preprint arXiv:1510.00149, 2015. 3
[16] Marton Havasi, Robert Peharz, vÃ  JosÃ© Miguel HernÃ¡ndez-Lobato. Minimal random code learning: Getting bits back from compressed model parameters. arXiv preprint arXiv:1810.00440, 2018. 3
[17] Soufiane Hayou, Jean-Francois Ton, Arnaud Doucet, vÃ  Yee Whye Teh. Robust pruning at initialization. arXiv preprint arXiv:2002.08797, 2020. 3
[18] Geoffrey Hinton, Oriol Vinyals, Jeff Dean, vÃ  cÃ¡c cá»™ng sá»±. Distilling the knowledge in a neural network. arXiv preprint arXiv:1503.02531, 2(7), 2015. 1
[19] Berivan Isik, Tsachy Weissman, vÃ  Albert No. An information-theoretic justification for model pruning. Trong International Conference on Artificial Intelligence and Statistics, trang 3821â€“3846. PMLR, 2022. 3, 5
[20] Woojeong Kim, Suhyun Kim, Mincheol Park, vÃ  Geunseok Jeon. Neuron merging: Compensating for pruned neurons. Advances in Neural Information Processing Systems, 33:585â€“595, 2020. 3
[21] Diederik P Kingma vÃ  Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980, 2014. 8
[22] Kodak. Kodak Dataset. http://r0k.us/graphics/kodak/, 1991. 7
[23] Aditya Kusupati, Vivek Ramanujan, Raghav Somani, Mitchell Wortsman, Prateek Jain, Sham Kakade, vÃ  Ali Farhadi. Soft threshold weight reparameterization for learnable sparsity. Trong Proceedings of the International Conference on Machine Learning, thÃ¡ng 7 2020. 3, 5
[24] Yann LeCun vÃ  cÃ¡c cá»™ng sá»±. Lenet-5, convolutional neural networks. URL: http://yann. lecun. com/exdb/lenet, 20(5):14, 2015. 5, 7
[25] Jooyoung Lee, Seunghyun Cho, vÃ  Seung-Kwon Beack. Context-adaptive entropy model for end-to-end optimized image compression. arXiv preprint arXiv:1809.10452, 2018. 3
[26] Junghyup Lee, Dohyung Kim, vÃ  Bumsub Ham. Network quantization with element-wise gradient scaling. Trong Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, trang 6448â€“6457, 2021. 1, 3
[27] Jaeho Lee, Sejun Park, Sangwoo Mo, Sungsoo Ahn, vÃ  Jinwoo Shin. Layer-adaptive sparsity for the magnitude-based pruning. arXiv preprint arXiv:2010.07611, 2020. 5
[28] Yuchao Li, Shaohui Lin, Jianzhuang Liu, Qixiang Ye, Mengdi Wang, Fei Chao, Fan Yang, Jincheng Ma, Qi Tian, vÃ  Rongrong Ji. Towards compact cnns via collaborative compression. Trong Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, trang 6438â€“6447, 2021. 3
[29] Tao Lin, Sebastian U Stich, Luis Barba, Daniil Dmitriev, vÃ  Martin Jaggi. Dynamic model pruning with feedback. arXiv preprint arXiv:2006.07253, 2020. 1, 3, 5
[30] Chaoyue Liu, Libin Zhu, vÃ  Mikhail Belkin. Loss landscapes and optimization in over-parameterized non-linear systems and neural networks. Applied and Computational Harmonic Analysis, 59:85â€“116, 2022. 2

--- TRANG 11 ---
[31] Eran Malach, Gilad Yehudai, Shai Shalev-Schwartz, vÃ  Ohad Shamir. Proving the lottery ticket hypothesis: Pruning is all you need. Trong International Conference on Machine Learning, trang 6682â€“6691. PMLR, 2020. 2
[32] David Minnen, Johannes BallÃ©, vÃ  George D Toderici. Joint autoregressive and hierarchical priors for learned image compression. Advances in neural information processing systems, 31, 2018. 3
[33] Behnam Neyshabur, Zhiyuan Li, Srinadh Bhojanapalli, Yann LeCun, vÃ  Nathan Srebro. The role of over-parametrization in generalization of neural networks. Trong International Conference on Learning Representations, 2019. 2
[34] Quynh Nguyen, Mahesh Chandra Mukkamala, vÃ  Matthias Hein. On the loss landscape of a class of deep neural networks with no bad local valleys. Trong International Conference on Learning Representations, 2019. 2
[35] Vivek Ramanujan, Mitchell Wortsman, Aniruddha Kembhavi, Ali Farhadi, vÃ  Mohammad Rastegari. What's hidden in a randomly weighted neural network? Trong Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, trang 11893â€“11902, 2020. 2
[36] Mohammad Rastegari, Vicente Ordonez, Joseph Redmon, vÃ  Ali Farhadi. Xnor-net: Imagenet classification using binary convolutional neural networks. Trong European conference on computer vision, trang 525â€“542. Springer, 2016. 3
[37] Brandon Reagan, Udit Gupta, Bob Adolf, Michael Mitzenmacher, Alexander Rush, Gu-Yeon Wei, vÃ  David Brooks. Weightless: Lossy weight encoding for deep neural network compression. Trong International Conference on Machine Learning, trang 4324â€“4333. PMLR, 2018. 3
[38] Julien Niklas Siems, Aaron Klein, Cedric Archambeau, vÃ  Maren Mahsereci. Dynamic pruning of a neural network via gradient signal-to-noise ratio. Trong 8th ICML Workshop on Automated Machine Learning (AutoML), 2021. 3
[39] Vincent Sitzmann, Julien Martel, Alexander Bergman, David Lindell, vÃ  Gordon Wetzstein. Implicit neural representations with periodic activation functions. Advances in Neural Information Processing Systems, 33:7462â€“7473, 2020. 7
[40] Christopher Subia-Waud vÃ  Srinandan Dasmahapatra. Weight fixing networks. Trong European Conference on Computer Vision, trang 415â€“431. Springer, 2022. 1, 2
[41] Ilia Sucholutsky vÃ  Matthias Schonlau. Soft-label dataset distillation and text dataset distillation. Trong 2021 International Joint Conference on Neural Networks (IJCNN), trang 1â€“8. IEEE, 2021. 3, 6
[42] Matthew Tancik, Pratul Srinivasan, Ben Mildenhall, Sara Fridovich-Keil, Nithin Raghavan, Utkarsh Singhal, Ravi Ramamoorthi, Jonathan Barron, vÃ  Ren Ng. Fourier features let networks learn high frequency functions in low dimensional domains. Advances in Neural Information Processing Systems, 33:7537â€“7547, 2020. 5, 7
[43] Rishabh Tiwari, Udbhav Bamba, Arnav Chavan, vÃ  Deepak K Gupta. Chipnet: Budget-aware pruning with heaviside continuous approximations. arXiv preprint arXiv:2102.07156, 2021. 3
[44] George Toderici, Wenzhe Shi, Radu Timofte, Lucas Theis, Johannes Balle, Eirikur Agustsson, Nick Johnston, vÃ  Fabian Mentzer. Workshop and challenge on learned image compression (clic2020), 2020. 7
[45] Karen Ullrich, Edward Meeds, vÃ  Max Welling. Soft weight-sharing for neural network compression. arXiv preprint arXiv:1702.04008, 2017. 3
[46] Huan Wang, Can Qin, Yulun Zhang, vÃ  Yun Fu. Neural pruning via growing regularization. arXiv preprint arXiv:2012.09243, 2020. 3
[47] Kai Wang, Bo Zhao, Xiangyu Peng, Zheng Zhu, Shuo Yang, Shuo Wang, Guan Huang, Hakan Bilen, Xinchao Wang, vÃ  Yang You. Cafe: Learning to condense dataset by aligning features. arXiv preprint arXiv:2203.01531, 2022. 6
[48] Tongzhou Wang, Jun-Yan Zhu, Antonio Torralba, vÃ  Alexei A Efros. Dataset distillation. arXiv preprint arXiv:1811.10959, 2018. 1, 3, 5, 6
[49] Xiaosong Wang, Yifan Peng, Le Lu, Zhiyong Lu, Mohammadhadi Bagheri, vÃ  Ronald M Summers. Chestx-ray8: Hospital-scale chest x-ray database and benchmarks on weakly-supervised classification and localization of common thorax diseases. Trong Proceedings of the IEEE conference on computer vision and pattern recognition, trang 2097â€“2106, 2017. 7
[50] Mitchell Wortsman, Vivek Ramanujan, Rosanne Liu, Aniruddha Kembhavi, Mohammad Rastegari, Jason Yosinski, vÃ  Ali Farhadi. Supermasks in superposition. Advances in Neural Information Processing Systems, 33:15173â€“15184, 2020. 2
[51] Bo Zhao vÃ  Hakan Bilen. Dataset condensation with differentiable siamese augmentation. Trong International Conference on Machine Learning, trang 12674â€“12685. PMLR, 2021. 3, 6
[52] Bo Zhao vÃ  Hakan Bilen. Dataset condensation with distribution matching. arXiv preprint arXiv:2110.04181, 2021. 3, 6
[53] Bo Zhao, Konda Reddy Mopuri, vÃ  Hakan Bilen. Dataset condensation with gradient matching. arXiv preprint arXiv:2006.05929, 2020. 6

Phá»¥ lá»¥c
TÃ­nh trá»±c giao vÃ  chuáº©n cá»§a máº¡ng cÆ¡ sá»Ÿ:
Trong bÃ i ná»™p chÃ­nh, chÃºng tÃ´i Ä‘Ã£ Ä‘á» cáº­p ráº±ng cÃ¡c máº¡ng cÆ¡ sá»Ÿ ngáº«u nhiÃªn gáº§n nhÆ° vuÃ´ng gÃ³c vá»›i nhau trong khÃ´ng gian nhiá»u chiá»u. Äá»ƒ thá»ƒ hiá»‡n Ä‘iá»u nÃ y, chÃºng tÃ´i táº¡o ra 1000 vector ngáº«u nhiÃªn trong khÃ´ng gian d chiá»u (thay Ä‘á»•i d tá»« 10 Ä‘áº¿n 1000), vÃ  váº½ biá»ƒu Ä‘á»“ cá»§a chuáº©n â„“2 vÃ  Ä‘á»™ tÆ°Æ¡ng tá»± cosine tá»«ng cáº·p cá»§a chÃºng trong HÃ¬nh 8 vÃ  9 tÆ°Æ¡ng á»©ng. ChÃºng tÃ´i cÅ©ng cháº¡y thÃ­ nghiá»‡m nÃ y 100 láº§n, tÃ­nh Ä‘á»™ tÆ°Æ¡ng tá»± cosine tá»‘i Ä‘a cho má»—i láº§n cháº¡y, vÃ  váº½ biá»ƒu Ä‘á»“ cá»§a cÃ¡c giÃ¡ trá»‹ tá»‘i Ä‘a trong HÃ¬nh 10. NhÆ° mong Ä‘á»£i, á»Ÿ sá»‘ chiá»u cao hÆ¡n, Ä‘á»™ tÆ°Æ¡ng tá»± cosine tiáº¿n gáº§n Ä‘áº¿n 0 vÃ  chuáº©n tiáº¿n gáº§n Ä‘áº¿n 1. Äiá»u nÃ y gá»£i Ã½ thá»±c nghiá»‡m ráº±ng á»Ÿ chiá»u cao hÆ¡n, cÆ¡ sá»Ÿ ngáº«u nhiÃªn gáº§n vá»›i cÆ¡ sá»Ÿ trá»±c chuáº©n. Xin lÆ°u Ã½ ráº±ng phÆ°Æ¡ng phÃ¡p cá»§a chÃºng tÃ´i khÃ´ng yÃªu cáº§u cÆ¡ sá»Ÿ trá»±c chuáº©n Ä‘á»ƒ hoáº¡t Ä‘á»™ng.

--- TRANG 12 ---
HÃ¬nh 8. Biá»ƒu Ä‘á»“ chuáº©n â„“2 cá»§a 1000 vector d chiá»u Ä‘Æ°á»£c táº¡o ngáº«u nhiÃªn. Khi tÄƒng d, chuáº©n tiáº¿n Ä‘áº¿n 1.

HÃ¬nh 9. Biá»ƒu Ä‘á»“ Ä‘á»™ tÆ°Æ¡ng tá»± cosine tá»«ng cáº·p cá»§a 1000 vector d chiá»u Ä‘Æ°á»£c táº¡o ngáº«u nhiÃªn. Khi tÄƒng d, Ä‘á»™ tÆ°Æ¡ng tá»± cosine tiáº¿n Ä‘áº¿n 0.

TÃ¡i táº¡o sá»­ dá»¥ng má»™t táº­p con cÆ¡ sá»Ÿ:
HÃ¬nh 12 cho tháº¥y phÃ¢n phá»‘i cÃ¡c giÃ¡ trá»‹ alpha cho má»™t vÃ i hÃ¬nh áº£nh tá»« táº­p dá»¯ liá»‡u Kodak. NhÆ° mong Ä‘á»£i, cÃ¡c giÃ¡ trá»‹ alpha thay Ä‘á»•i qua cÃ¡c mÃ´ hÃ¬nh cÆ¡ sá»Ÿ. Äiá»u nÃ y thÃºc Ä‘áº©y chÃºng tÃ´i nghiÃªn cá»©u "Ä‘iá»u gÃ¬ sáº½ xáº£y ra náº¿u chÃºng ta chá»‰ sá»­ dá»¥ng má»™t táº­p con cá»§a cÃ¡c mÃ´ hÃ¬nh cÆ¡ sá»Ÿ thay vÃ¬ táº¥t cáº£ chÃºng?".

Äá»‘i vá»›i phÃ¢n loáº¡i hÃ¬nh áº£nh, chÃºng tÃ´i thá»±c hiá»‡n thÃ­ nghiá»‡m nÃ y báº±ng cÃ¡ch chá»n ngáº«u nhiÃªn p% cÆ¡ sá»Ÿ vá»›i p thay Ä‘á»•i. ChÃºng tÃ´i láº·p láº¡i Ä‘iá»u nÃ y 4 láº§n. NhÆ° má»™t phÆ°Æ¡ng phÃ¡p lá»±a chá»n khÃ¡c, chÃºng tÃ´i sáº¯p xáº¿p cÃ¡c giÃ¡ trá»‹ alpha dá»±a trÃªn giÃ¡ trá»‹ tuyá»‡t Ä‘á»‘i cá»§a chÃºng vÃ  sá»­ dá»¥ng p% hÃ ng Ä‘áº§u cá»§a chÃºng. NhÆ° Ä‘Æ°á»£c thá»ƒ hiá»‡n trong HÃ¬nh 11, trong lá»±a chá»n ngáº«u nhiÃªn, chÃºng ta cáº§n háº§u háº¿t cÃ¡c cÆ¡ sá»Ÿ Ä‘á»ƒ cÃ³ thá»ƒ láº¥y láº¡i Ä‘á»™ chÃ­nh xÃ¡c há»£p lÃ½ trong khi Ä‘á»‘i vá»›i trÆ°á»ng há»£p Ä‘Æ°á»£c sáº¯p xáº¿p, má»™t tá»· lá»‡ nhá» cá»§a cÃ¡c mÃ´ hÃ¬nh cÆ¡ sá»Ÿ lÃ  Ä‘á»§ Ä‘á»ƒ cÃ³ Ä‘á»™ chÃ­nh xÃ¡c há»£p lÃ½. ÄÃ¢y lÃ  má»™t quan sÃ¡t thÃº vá»‹ pháº§n nÃ o gá»£i Ã½ ráº±ng cáº£nh quan máº¥t mÃ¡t cá»§a viá»‡c tá»‘i Æ°u hÃ³a cho cÃ¡c giÃ¡ trá»‹ alpha khÃ¡ mÆ°á»£t mÃ . ÄÃ¢y lÃ  má»™t tuyÃªn bá»‘ cÃ³ chá»§ Ã½ mÆ¡ há»“ vÃ¬ nÃ³ cáº§n Ä‘iá»u tra thÃªm nhÆ° cÃ´ng viá»‡c tÆ°Æ¡ng lai.

Äá»‘i vá»›i nÃ©n hÃ¬nh áº£nh, chÃºng tÃ´i thá»±c hiá»‡n cÃ¹ng má»™t thÃ­ nghiá»‡m

--- TRANG 13 ---
HÃ¬nh 10. Biá»ƒu Ä‘á»“ Ä‘á»™ tÆ°Æ¡ng tá»± cosine tá»‘i Ä‘a tá»«ng cáº·p cá»§a 1000 vector d chiá»u Ä‘Æ°á»£c táº¡o ngáº«u nhiÃªn qua 100 thá»­ nghiá»‡m. Khi tÄƒng d, Ä‘á»™ tÆ°Æ¡ng tá»± cosine tá»‘i Ä‘a tiáº¿n Ä‘áº¿n 0.

ment vÃ  cho tháº¥y cÃ¡c hÃ¬nh áº£nh Ä‘Æ°á»£c tÃ¡i táº¡o há»£p lÃ½ vá»›i má»™t táº­p con cÃ¡c giÃ¡ trá»‹ alpha cÃ³ giÃ¡ trá»‹ tuyá»‡t Ä‘á»‘i lá»›n nháº¥t. VÃ¬ chÃºng tÃ´i cÃ³ má»™t táº­p cÃ¡c alpha khÃ¡c nhau cho má»—i lá»›p cá»§a MLP trong nÃ©n hÃ¬nh áº£nh, chÃºng tÃ´i sáº¯p xáº¿p cÃ¡c giÃ¡ trá»‹ tuyá»‡t Ä‘á»‘i vÃ  chá»n p% hÃ ng Ä‘áº§u cá»§a má»—i lá»›p cÃ³ giÃ¡ trá»‹ cao hÆ¡n. ChÃºng tÃ´i thay Ä‘á»•i p vÃ  trá»±c quan hÃ³a cÃ¡c hÃ¬nh áº£nh Ä‘Æ°á»£c tÃ¡i táº¡o cho má»—i giÃ¡ trá»‹ p trong HÃ¬nh 14, 15 vÃ  16. NgoÃ i ra, chÃºng tÃ´i bÃ¡o cÃ¡o áº£nh hÆ°á»Ÿng cá»§a p trong PSNR vÃ  MS-SSIM cho táº­p dá»¯ liá»‡u Kodak trong Báº£ng 9. TÆ°Æ¡ng tá»± nhÆ° quan sÃ¡t cá»§a chÃºng tÃ´i trong phÃ¢n loáº¡i hÃ¬nh áº£nh, chÃºng tÃ´i quan sÃ¡t ráº±ng hÃ¬nh áº£nh vá»›i p = 70% cÃ³ cháº¥t lÆ°á»£ng cháº¥p nháº­n Ä‘Æ°á»£c.

NgoÃ i viá»‡c hiá»ƒu rÃµ hÆ¡n vá» phÆ°Æ¡ng phÃ¡p, quan sÃ¡t nÃ y cÃ³ thá»ƒ cho phÃ©p truyá»n thÃ´ng má»™t mÃ´ hÃ¬nh há»c sÃ¢u hoáº·c má»™t hÃ¬nh áº£nh má»™t cÃ¡ch tiáº¿n bá»™ trong Ä‘Ã³ ngÆ°á»i gá»­i gá»­i má»™t táº­p con cÃ¡c giÃ¡ trá»‹ alpha (quan trá»ng nháº¥t) trÆ°á»›c vÃ  sau Ä‘Ã³ dáº§n dáº§n gá»­i pháº§n cÃ²n láº¡i Ä‘á»ƒ cáº£i thiá»‡n Ä‘á»™ chÃ­nh xÃ¡c mÃ´ hÃ¬nh hoáº·c cháº¥t lÆ°á»£ng hÃ¬nh áº£nh. Äá»‘i vá»›i nÃ©n hÃ¬nh áº£nh, phÆ°Æ¡ng phÃ¡p nÃ y pháº§n nÃ o tÆ°Æ¡ng tá»± nhÆ° á»©ng dá»¥ng cá»§a Progressive JPEG nÆ¡i nÃ³ Ä‘Æ°á»£c lÃ m thá»§ cÃ´ng Ä‘á»ƒ gá»­i cÃ¡c thÃ nh pháº§n táº§n sá»‘ tháº¥p trÆ°á»›c. Xin lÆ°u Ã½ ráº±ng Ä‘á»ƒ sá»­ dá»¥ng Ä‘iá»u nÃ y trong thá»±c táº¿, phiÃªn báº£n tiáº¿n bá»™ nÃ y cá»§a phÆ°Æ¡ng phÃ¡p chÃºng tÃ´i cÃ³ má»™t sá»‘ chi phÃ­ phá»¥ thÃªm vÃ¬ chÃºng tÃ´i cÅ©ng cáº§n truyá»n thÃ´ng giÃ¡ trá»‹ alpha nÃ o Ä‘Æ°á»£c gá»­i á»Ÿ má»—i bÆ°á»›c (vÃ­ dá»¥, sá»­ dá»¥ng má»™t bit cho má»—i cÆ¡ sá»Ÿ). NghiÃªn cá»©u Ä‘iá»u nÃ y chi tiáº¿t hÆ¡n Ä‘Æ°á»£c Ä‘á»ƒ láº¡i cho cÃ´ng viá»‡c tÆ°Æ¡ng lai.

Chi tiáº¿t NÃ©n HÃ¬nh áº£nh:
NhÆ° Ä‘Æ°á»£c mÃ´ táº£ trong bÃ i ná»™p chÃ­nh, trong cÃ¡c thÃ­ nghiá»‡m nÃ©n hÃ¬nh áº£nh, Ä‘á»ƒ thay Ä‘á»•i bit-per-pixel (bpp), chÃºng tÃ´i cá»‘ Ä‘á»‹nh kiáº¿n trÃºc máº¡ng vÃ  thay Ä‘á»•i sá»‘ lÆ°á»£ng giÃ¡ trá»‹ Î± trÃªn má»—i lá»›p. ChÃºng tÃ´i bÃ¡o cÃ¡o sá»‘ lÆ°á»£ng giÃ¡ trá»‹ Î± trÃªn má»—i lá»›p cho má»—i bpp trong Báº£ng 10.

NÃ©n vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p NÃ©n HÃ¬nh áº£nh Tiáº¿n tiáº¿n:
ChÃºng tÃ´i so sÃ¡nh phÆ°Æ¡ng phÃ¡p cá»§a chÃºng tÃ´i vá»›i cÃ¡c codec tiÃªn tiáº¿n hÆ¡n (vÃ­ dá»¥, BPG, VTM) vÃ  cÃ¡c phÆ°Æ¡ng phÃ¡p nÃ©n hÃ¬nh áº£nh dá»±a trÃªn há»c. Káº¿t quáº£ cho CLIC-Mobile trong Báº£ng 11 vÃ  káº¿t quáº£ cho Kodak trong HÃ¬nh 13. LÆ°u Ã½ ráº±ng cÃ¡c codec tiÃªn tiáº¿n Ä‘Æ°á»£c lÃ m thá»§ cÃ´ng náº·ng ná» bá»Ÿi má»™t cá»™ng Ä‘á»“ng lá»›n. VÃ , cÃ¡c phÆ°Æ¡ng phÃ¡p dá»±a trÃªn há»c sá»­ dá»¥ng má»™t táº­p dá»¯ liá»‡u huáº¥n luyá»‡n Ä‘á»ƒ há»c má»™t mÃ£ tá»‘t (tÆ°Æ¡ng tá»± nhÆ° auto-encoder), do Ä‘Ã³, chÃºng cÃ³ thá»ƒ khÃ´ng thá»ƒ nÃ©n má»™t hÃ¬nh áº£nh duy nháº¥t mÃ  khÃ´ng cÃ³ quyá»n truy cáº­p vÃ o má»™t táº­p há»£p cÃ¡c hÃ¬nh áº£nh. NgÆ°á»£c láº¡i, phÆ°Æ¡ng phÃ¡p cá»§a chÃºng tÃ´i cÃ³ thá»ƒ nÃ©n má»™t hÃ¬nh áº£nh duy nháº¥t mÃ  khÃ´ng sá»­ dá»¥ng má»™t táº­p há»£p cÃ¡c hÃ¬nh áº£nh. HÆ¡n ná»¯a, vÃ¬ lÃ½ do tÆ°Æ¡ng tá»±, phÆ°Æ¡ng phÃ¡p cá»§a chÃºng tÃ´i khÃ´ng thá»ƒ thiÃªn lá»‡ch Ä‘á»‘i vá»›i cÃ¡c trÆ°á»ng há»£p phá»• biáº¿n (Ä‘áº§u cá»§a phÃ¢n phá»‘i). RÃµ rÃ ng, phÆ°Æ¡ng phÃ¡p cá»§a chÃºng tÃ´i cÃ³ cÃ¡c thiÃªn lá»‡ch khÃ¡c (vÃ­ dá»¥, nhá»¯ng gÃ¬ cÃ³ thá»ƒ Ä‘Æ°á»£c biá»ƒu diá»…n báº±ng INR) cáº§n Ä‘Æ°á»£c nghiÃªn cá»©u nhÆ° cÃ´ng viá»‡c tÆ°Æ¡ng lai.

So sÃ¡nh Trá»±c quan vá»›i JPEG:
TÆ°Æ¡ng tá»± nhÆ° HÃ¬nh 5 cá»§a bÃ i ná»™p chÃ­nh, chÃºng tÃ´i bao gá»“m thÃªm so sÃ¡nh trá»±c quan vá»›i JPEG trong HÃ¬nh 17 Ä‘áº¿n 20 (cho táº­p dá»¯ liá»‡u Kodak vá»›i Ä‘á»™ phÃ¢n giáº£i 512Ã—768) vÃ  HÃ¬nh 21 vÃ  22 (cho táº­p dá»¯ liá»‡u CLIC-Mobile vá»›i Ä‘á»™ phÃ¢n giáº£i 1512Ã—2016 hoáº·c 2016Ã—1512). HÆ¡n ná»¯a, trong HÃ¬nh 23 Ä‘áº¿n 25, chÃºng tÃ´i bao gá»“m so sÃ¡nh trá»±c quan trong táº­p dá»¯ liá»‡u x-ray ngá»±c vá»›i Ä‘á»™ phÃ¢n giáº£i 1024Ã—1024.

--- TRANG 14 ---
HÃ¬nh 11. áº¢nh hÆ°á»Ÿng cá»§a viá»‡c chá»‰ sá»­ dá»¥ng p% mÃ´ hÃ¬nh cÆ¡ sá»Ÿ Ä‘Æ°á»£c chá»n ngáº«u nhiÃªn (4 láº§n) hoáº·c Ä‘Æ°á»£c chá»n dá»±a trÃªn giÃ¡ trá»‹ tuyá»‡t Ä‘á»‘i cao nháº¥t cá»§a alpha.

HÃ¬nh 12. PhÃ¢n phá»‘i alpha: ChÃºng tÃ´i váº½ phÃ¢n phá»‘i cÃ¡c giÃ¡ trá»‹ alpha cho má»™t vÃ i hÃ¬nh áº£nh Kodak.

Báº£ng 9. áº¢nh hÆ°á»Ÿng cá»§a viá»‡c giá»¯ p% Î± vá»›i giÃ¡ trá»‹ tuyá»‡t Ä‘á»‘i cao nháº¥t:
percentile (p%) 10 20 30 40 50 60 70 80 90 100
bpp 0.07 0.14 0.22 0.29 0.36 0.43 0.50 0.58 0.65 0.72
PSNR 11.94 12.3 13.4 14.98 17.01 19.51 22.71 26.92 31.85 33.64
MS-SSIM 0.10 0.12 0.18 0.28 0.41 0.55 0.71 0.86 0.96 0.97

Báº£ng 10. Chi tiáº¿t cá»§a cÃ¡c mÃ´ hÃ¬nh nÃ©n hÃ¬nh áº£nh: ChÃºng tÃ´i bÃ¡o cÃ¡o sá»‘ lÆ°á»£ng giÃ¡ trá»‹ Î± trÃªn má»—i lá»›p cho má»—i bpp. ChÃºng tÃ´i sá»­ dá»¥ng MLP vá»›i chiá»u áº©n 256 cho táº­p dá»¯ liá»‡u Kodak á»Ÿ bpp 0.18 (hÃ ng Ä‘áº§u tiÃªn), vÃ  chiá»u áº©n 512 cho táº¥t cáº£ cÃ¡c thÃ­ nghiá»‡m khÃ¡c. Táº¥t cáº£ cÃ¡c thiáº¿t láº­p sá»­ dá»¥ng Ã¡nh xáº¡ Fourier kÃ­ch thÆ°á»›c 512. ChÃºng tÃ´i sá»­ dá»¥ng Ã­t giÃ¡ trá»‹ alpha hÆ¡n cho lá»›p cuá»‘i cÃ¹ng vÃ¬ lá»›p cuá»‘i cÃ¹ng cÃ³ Ã­t trá»ng sá»‘ hÆ¡n khi nÃ³ Ä‘i tá»« lá»›p áº©n chá»‰ Ä‘áº¿n 3 chiá»u (giÃ¡ trá»‹ RGB). NgoÃ i ra, Ä‘á»‘i vá»›i hÃ ng Ä‘áº§u tiÃªn, chÃºng tÃ´i sá»­ dá»¥ng nhiá»u giÃ¡ trá»‹ alpha hÆ¡n cho lá»›p Ä‘áº§u tiÃªn vÃ¬ nÃ³ cÃ³ nhiá»u trá»ng sá»‘ hÆ¡n (512Ã—256).

Táº­p dá»¯ liá»‡u bpp Lá»›p-1 Lá»›p-2 Lá»›p-3 Lá»›p-4 Lá»›p-5 Tá»•ng (Î±s)
Kodak0.18 10k 7.5k 7.5k 7.5k 2k 34.5k
0.31 15k 15k 15k 15k 2k 57k
0.52 10k 30k 30k 30k 2k 102k
0.72 20k 40k 40k 40k 2k 142k
CLIC-Mobile 0.12 45k 45k 45k 45k 2k 182k
Chest x-ray 0.15 20k 20k 20k 20k 2k 82k

--- TRANG 15 ---
Báº£ng 11. NÃ©n HÃ¬nh áº£nh Táº­p dá»¯ liá»‡u CLIC-mobile: TÆ°Æ¡ng tá»± nhÆ° Báº£ng 6 cá»§a bÃ i ná»™p chÃ­nh, chÃºng tÃ´i bao gá»“m so sÃ¡nh vá»›i cÃ¡c codec tiÃªn tiáº¿n nhÆ° BPG vÃ  VTM. ChÃºng tÃ´i cÅ©ng so sÃ¡nh vá»›i má»™t sá»‘ phÆ°Æ¡ng phÃ¡p nÃ©n hÃ¬nh áº£nh dá»±a trÃªn há»c (vÃ­ dá»¥, MBT, CST, BMS).

MÃ´ hÃ¬nh bpp PSNR MS-SSIM
VTM 0.183 33.07 0.964
CST 0.146 31.85 0.957
MBT 0.146 31.62 0.955
BPG 0.128 30.65 0.942
WebP 0.185 30.07 0.940
BMS 0.113 29.38 0.936
JPEG2000 0.126 29.40 0.918
JPEG 0.195 24.82 0.836
INR Ä‘Ã£ huáº¥n luyá»‡n 0.125 26.93 0.864
PRANC (ours) 0.119 29.71 0.920

HÃ¬nh 13. NÃ©n HÃ¬nh áº£nh Táº­p dá»¯ liá»‡u Kodak: TÆ°Æ¡ng tá»± nhÆ° HÃ¬nh 4 cá»§a bÃ i ná»™p chÃ­nh, chÃºng tÃ´i bao gá»“m so sÃ¡nh vá»›i cÃ¡c codec tiÃªn tiáº¿n nhÆ° BPG vÃ  VTM. ChÃºng tÃ´i cÅ©ng so sÃ¡nh vá»›i nÃ©n hÃ¬nh áº£nh dá»±a trÃªn há»c (vÃ­ dá»¥, MBT, CST, BMS).

--- TRANG 16 ---
HÃ¬nh 14. áº¢nh hÆ°á»Ÿng cá»§a viá»‡c giá»¯ p% mÃ´ hÃ¬nh cÆ¡ sá»Ÿ vá»›i cÃ¡c giÃ¡ trá»‹ alpha tuyá»‡t Ä‘á»‘i cao nháº¥t. ChÃºng ta cÃ³ Ä‘Æ°á»£c hÃ¬nh áº£nh há»£p lÃ½ vá»›i táº­p con nhá» hÆ¡n cá»§a cÃ¡c mÃ´ hÃ¬nh cÆ¡ sá»Ÿ.

HÃ¬nh 15. Xem HÃ¬nh 14.

--- TRANG 17 ---
HÃ¬nh 16. Xem HÃ¬nh 14.

--- TRANG 18 ---
HÃ¬nh áº£nh gá»‘c
Ours (bpp=0.31, PSNR=30.62)
Ours (bpp=0.17, PSNR=28.18)JPEG (bpp=0.31, PSNR=28.68)
JPEG (bpp=0.17, PSNR=22.47)HÃ¬nh 17. Trá»±c quan hÃ³a Kodak. ChÃºng tÃ´i so sÃ¡nh PRANC vÃ  JPEG trÃªn hÃ¬nh áº£nh 4 cá»§a táº­p dá»¯ liá»‡u Kodak á»Ÿ bpp=0.31 vÃ  0.17

--- TRANG 19 ---
HÃ¬nh áº£nh gá»‘c
Ours (bpp=0.31, PSNR=31.96)
Ours (bpp=0.17, PSNR=29.23)JPEG (bpp=0.32, PSNR=28.58)
JPEG (bpp=0.17, PSNR=23.21)HÃ¬nh 18. Trá»±c quan hÃ³a Kodak. ChÃºng tÃ´i so sÃ¡nh PRANC vÃ  JPEG trÃªn hÃ¬nh áº£nh 17 cá»§a táº­p dá»¯ liá»‡u Kodak.

--- TRANG 20 ---
HÃ¬nh áº£nh gá»‘c
Ours (bpp=0.31, PSNR=25.57)
Ours (bpp=0.17, PSNR=23.3)JPEG (bpp=0.31, PSNR=21.34)
JPEG (bpp=0.21, PSNR=19.42)HÃ¬nh 19. Trá»±c quan hÃ³a Kodak. ChÃºng tÃ´i so sÃ¡nh PRANC vÃ  JPEG trÃªn hÃ¬nh áº£nh 5 cá»§a táº­p dá»¯ liá»‡u Kodak.

--- TRANG 21 ---
HÃ¬nh áº£nh gá»‘c
Ours (bpp=0.31, PSNR=31.41)
Ours (bpp=0.17, PSNR=27.88)JPEG (bpp=0.32, PSNR=31.16)
JPEG (bpp=0.17, PSNR=23.64)HÃ¬nh 20. Trá»±c quan hÃ³a Kodak. ChÃºng tÃ´i so sÃ¡nh PRANC vÃ  JPEG trÃªn hÃ¬nh áº£nh 23 cá»§a táº­p dá»¯ liá»‡u Kodak.

--- TRANG 22 ---
HÃ¬nh áº£nh gá»‘c
Ours (bpp=0.119, PSNR=30.26)JPEG (bpp=0.18, PSNR=25.43)HÃ¬nh 21. Trá»±c quan hÃ³a CLIC. ChÃºng tÃ´i so sÃ¡nh PRANC á»Ÿ bpp=0.119 vá»›i JPEG á»Ÿ bpp=0.18 trÃªn má»™t hÃ¬nh áº£nh CLIC.

--- TRANG 23 ---
HÃ¬nh áº£nh gá»‘c
Ours (bpp=0.119, PSNR=28.99)
JPEG (bpp=0.226, PSNR=24.59)HÃ¬nh 22. Trá»±c quan hÃ³a CLIC. ChÃºng tÃ´i so sÃ¡nh PRANC á»Ÿ bpp=0.119 vá»›i JPEG á»Ÿ bpp=0.226 trÃªn má»™t hÃ¬nh áº£nh CLIC.

--- TRANG 24 ---
HÃ¬nh áº£nh gá»‘c
Ours (bpp=0.15, PSNR=36.06)JPEG (bpp=0.15, PSNR=32.11)
HÃ¬nh 23. Trá»±c quan hÃ³a X-ray Ngá»±c. ChÃºng tÃ´i so sÃ¡nh PRANC vÃ  JPEG trÃªn má»™t hÃ¬nh áº£nh X-ray Ngá»±c á»Ÿ bpp=0.15

--- TRANG 25 ---
HÃ¬nh áº£nh gá»‘c
Ours (bpp=0.15, PSNR=36.24)JPEG (bpp=0.15, PSNR=32.55)HÃ¬nh 24. Xem HÃ¬nh 23.

--- TRANG 26 ---
HÃ¬nh áº£nh gá»‘c
Ours (bpp=0.15, PSNR=35.54)JPEG (bpp=0.15, PSNR=32.20)HÃ¬nh 25. Xem HÃ¬nh 23.

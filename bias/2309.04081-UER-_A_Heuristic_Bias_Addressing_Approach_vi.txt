UER: Một Phương Pháp Heuristic Giải Quyết Thiên Lệch
cho Học Liên Tục Trực Tuyến

Huiwei Lin
Viện Công nghệ Harbin
Thâm Quyến, Trung Quốc
linhuiwei@stu.hit.edu.cn

Shanshan Feng∗
Viện Công nghệ Harbin
Thâm Quyến, Trung Quốc
victor_fengss@foxmail.com

Baoquan Zhang
Viện Công nghệ Harbin
Thâm Quyến, Trung Quốc
zhangbaoquan@stu.hit.edu.cn

Hongliang Qiao
Viện Công nghệ Harbin
Thâm Quyến, Trung Quốc
21s151112@stu.hit.edu.cn

Xutao Li
Viện Công nghệ Harbin
Thâm Quyến, Trung Quốc
lixutao@hit.edu.cn

Yunming Ye
Viện Công nghệ Harbin
Thâm Quyến, Trung Quốc
yeyunming@hit.edu.cn

TÓM TẮT
Học liên tục trực tuyến nhằm liên tục huấn luyện mạng nơ-ron từ một luồng dữ liệu liên tục với một lần xuyên qua dữ liệu duy nhất. Là phương pháp hiệu quả nhất, các phương pháp dựa trên rehearsal phát lại một phần dữ liệu trước đó. Các bộ dự đoán thường được sử dụng trong các phương pháp hiện có có xu hướng tạo ra các logit tích vô hướng thiên lệch ưa chuộng các lớp của dữ liệu hiện tại, được biết đến như một vấn đề thiên lệch và hiện tượng quên. Nhiều phương pháp đã được đề xuất để khắc phục vấn đề quên bằng cách chỉnh sửa thiên lệch; tuy nhiên, chúng vẫn cần được cải thiện trong chế độ trực tuyến. Trong bài báo này, chúng tôi cố gắng giải quyết vấn đề thiên lệch bằng một phương pháp đơn giản và hiệu quả hơn. Bằng cách phân tách các logit tích vô hướng thành một nhân tố góc và một nhân tố chuẩn, chúng tôi thực nghiệm thấy rằng vấn đề thiên lệch chủ yếu xảy ra ở nhân tố góc, có thể được sử dụng để học kiến thức mới như logit cosine. Ngược lại, nhân tố chuẩn bị các phương pháp hiện có loại bỏ giúp ghi nhớ kiến thức lịch sử. Dựa trên quan sát này, chúng tôi trực quan đề xuất tận dụng nhân tố chuẩn để cân bằng kiến thức mới và cũ để giải quyết thiên lệch. Để đạt được điều này, chúng tôi phát triển một phương pháp heuristic gọi là unbias experience replay (UER). UER học các mẫu hiện tại chỉ bằng nhân tố góc và tiếp tục phát lại các mẫu trước đó bằng cả nhân tố chuẩn và góc. Các thí nghiệm rộng rãi trên ba bộ dữ liệu cho thấy UER đạt được hiệu suất vượt trội so với các phương pháp tiên tiến khác nhau. Mã nguồn có tại https://github.com/FelixHuiweiLin/UER.

KHÁI NIỆM CCS
•Phương pháp tính toán →Xác thực chéo; Biểu diễn ảnh.

TỪ KHÓA
mạng nơ-ron, học liên tục trực tuyến, phân loại ảnh

∗Tác giả liên hệ: Shanshan Feng

Được phép tạo bản sao kỹ thuật số hoặc bản cứng của toàn bộ hoặc một phần công trình này cho mục đích sử dụng cá nhân hoặc trong lớp học mà không mất phí với điều kiện các bản sao không được tạo ra hoặc phân phối để kiếm lợi nhuận hoặc lợi thế thương mại và các bản sao mang thông báo này và trích dẫn đầy đủ trên trang đầu tiên. Bản quyền cho các thành phần của công trình này thuộc sở hữu của những người khác ngoài (các) tác giả phải được tôn trọng. Tóm tắt với tín dụng được phép. Để sao chép khác, hoặc tái xuất bản, để đăng trên máy chủ hoặc để phân phối lại danh sách, yêu cầu sự cho phép cụ thể trước và/hoặc một khoản phí. Yêu cầu quyền từ permissions@acm.org.
MM '23, 29 tháng 10-3 tháng 11, 2023, Ottawa, ON, Canada
©2023 Bản quyền thuộc về chủ sở hữu/tác giả. Quyền xuất bản được cấp phép cho ACM.
ACM ISBN 979-8-4007-0108-5/23/10... $15.00
https://doi.org/10.1145/3581783.3612011

Định dạng Tham khảo ACM:
Huiwei Lin, Shanshan Feng, Baoquan Zhang, Hongliang Qiao, Xutao Li, và Yunming Ye. 2023. UER: Một Phương Pháp Heuristic Giải Quyết Thiên Lệch cho Học Liên Tục Trực Tuyến. Trong Kỷ yếu Hội nghị Đa phương tiện Quốc tế ACM lần thứ 31 (MM '23), 29 tháng 10-3 tháng 11, 2023, Ottawa, ON, Canada. ACM, New York, NY, USA, 9 trang. https://doi.org/10.1145/3581783.3612011

1 GIỚI THIỆU
Hiện tại, mạng nơ-ron sâu [34–36] vẫn không thể có khả năng học liên tục thông thường như con người. Nếu mô hình thích nghi với dữ liệu mới thông qua tinh chỉnh, nó sẽ giảm đáng kể hiệu suất trên dữ liệu cũ. Hiện tượng như vậy được gọi là quên thảm khốc (CF) [12]. Vì việc giải quyết vấn đề này có ý nghĩa lớn, học liên tục [25–27] đã được đề xuất để huấn luyện mô hình đạt được tích lũy kiến thức mà không quên. Đặc biệt, học liên tục trực tuyến (OCL) là một kịch bản thực tế của học liên tục. Nó yêu cầu khắc phục vấn đề CF trong việc học liên tục từ một luồng dữ liệu vô hạn và không ổn định, nơi dữ liệu chỉ có thể được truy cập một lần.

Các phương pháp dựa trên rehearsal đã thể hiện hiệu suất vượt trội cho OCL trong số tất cả các phương pháp học liên tục [23]. Nhóm phương pháp này [24,31,44] thiết lập một bộ đệm bộ nhớ tình huống để lưu trữ một phần mẫu trước đó và phát lại chúng trong quá trình học các mẫu hiện tại. Trong loại phương pháp này, hiện tượng CF được thể hiện như một vấn đề thiên lệch trong dự đoán do mất cân bằng dữ liệu. Cụ thể, số lượng mẫu hiện tại trong luồng dữ liệu thường lớn hơn số lượng mẫu trước đó trong bộ đệm cố định. Do đó, mô hình có xu hướng ghi điểm các mẫu với dự đoán thiên lệch và dễ dàng phân loại hầu hết các mẫu vào các lớp hiện tại.

Mặc dù các phương pháp hiện có giảm thiểu vấn đề quên bằng cách chỉnh sửa thiên lệch, chúng vẫn cần được cải thiện trong chế độ trực tuyến. Cụ thể, có ba thách thức chính cần được giải quyết: 1) Khả năng thời gian thực. Một số phương pháp [32,43,45] yêu cầu các bước huấn luyện bổ sung hoặc các hoạt động hậu xử lý, điều này không có lợi cho dự đoán thời gian thực của mô hình. 2) Tính linh hoạt. Một số phương pháp [1,6] phụ thuộc nhiều vào ranh giới rõ ràng giữa các lớp cũ và mới, và chúng không thể được mở rộng từ bộ dự đoán sang bộ trích xuất đặc trưng. 3) Khả năng điều chỉnh. Các phương pháp khác [6,10] khó điều chỉnh quy mô chỉnh sửa thiên lệch, dễ dàng hạn chế khả năng tổng quát hóa của các mô hình. Do đó, một câu hỏi có ý nghĩa nảy sinh: Có phải có một phương pháp đơn giản và hiệu quả hơn có thể đồng thời đáp ứng ba thách thức này và hiệu quả giải quyết vấn đề thiên lệch cho OCL?

Để trả lời câu hỏi này, chúng tôi phân tích các phương pháp dựa trên rehearsal hiện có và thực nghiệm thấy rằng các dự đoán thiên lệch (logit tích vô hướng) chủ yếu thay đổi ở hai phần, như được thể hiện trong Hình 1(a). Được lấy cảm hứng từ [28], chúng tôi phân tách logit tích vô hướng (wh+b) thành một nhân tố chuẩn (∥w∥∥h∥+b) và một nhân tố góc (cos(w,h)). Dữ liệu không cân bằng dẫn đến sự cạnh tranh không cân bằng của sự lan truyền gradient, đây là nguyên nhân chính của hiện tượng CF, và hiệu ứng này ảnh hưởng đến logit ở cả hai nhân tố. Các thí nghiệm tiếp theo tiết lộ rằng hai nhân tố này hoạt động khác nhau trong quá trình huấn luyện. Một mặt, nhân tố góc gặp phải vấn đề thiên lệch nghiêm trọng trong dự đoán. Nó có thể được sử dụng độc lập như logit cosine chủ yếu nắm bắt kiến thức mới từ các mẫu hiện tại. Mặt khác, nhân tố chuẩn, bị các công trình hiện có [6,19] loại bỏ, hữu ích trong việc giữ kiến thức lịch sử của các mẫu trước đó.

Dựa trên quan sát này, việc tận dụng nhân tố chuẩn để cân bằng kiến thức cũ và mới và giải quyết vấn đề thiên lệch là khả thi. So với nhân tố góc, nhân tố chuẩn có thể hiệu quả lưu trữ kiến thức lịch sử, điều này hữu ích để xử lý vấn đề thiên lệch. Nói cách khác, logit tích vô hướng, được tạo thành từ hai nhân tố, phù hợp để phát lại các mẫu trước đó. Ngược lại, logit cosine, dựa trên nhân tố góc, được tạo sẵn có để học các mẫu hiện tại vì nó có thể nhanh chóng học kiến thức mới của các mẫu hiện tại. Khác với các nghiên cứu hiện có (Hình 1(b)) tính toán logit theo cùng một cách, chúng tôi cố gắng (Hình 1(c)) học các mẫu hiện tại bằng logit cosine và tiếp tục phát lại các mẫu trước đó bằng logit tích vô hướng. Như được thể hiện trong Hình 1(d), một mẫu hp sẽ bị phân loại nhầm vào lớp hiện tại c bằng logit cosine thỏa mãn cos(wc,hp)>cos(wp,hp). Tuy nhiên, với sự trợ giúp của nhân tố chuẩn, mô hình có thể phân loại chính xác hp vào lớp trước đó p bằng logit tích vô hướng thỏa mãn ∥hp∥∥wc∥cos(wc,hp)+bc<∥hp∥∥wp∥cos(wp,hp)+bp. Các thí nghiệm thực nghiệm chứng minh rằng phương pháp này hiệu quả giải quyết vấn đề thiên lệch và đạt được hiệu suất tốt hơn.

Với những cảm hứng này, chúng tôi đề xuất unbias experience replay (UER), một phương pháp heuristic giải quyết thiên lệch làm giảm hiện tượng CF cho OCL. Quá trình của nó có thể được chia chủ yếu thành ba thành phần: 1) Thành phần học là thành phần cơ bản huấn luyện các mẫu hiện tại từ luồng dữ liệu bằng logit cosine. Nó nhằm lưu kiến thức mới trong nhân tố góc. 2) Để củng cố kiến thức lịch sử, thành phần phát lại chủ yếu huấn luyện các mẫu trước đó trong bộ đệm bộ nhớ sử dụng cả nhân tố chuẩn và góc, tận dụng nhân tố chuẩn để chỉnh sửa dự đoán thiên lệch. 3) Với sự trợ giúp của nhân tố chuẩn, thành phần kiểm tra có xu hướng dự đoán phân phối phân loại không thiên lệch cho tất cả các mẫu. Một phương pháp đơn giản nhưng hiệu quả như vậy có thể được sử dụng để dự đoán thời gian thực (Khả năng thời gian thực), mở rộng sang bộ trích xuất đặc trưng (Tính linh hoạt), và quy mô giải quyết thiên lệch dễ dàng điều chỉnh (Khả năng điều chỉnh).

Những đóng góp chính của chúng tôi có thể được tóm tắt như sau:
1) Chúng tôi phân tích lý thuyết về đặc điểm của logit tích vô hướng và logit cosine, khám phá việc kết hợp chúng có lợi. Theo hiểu biết tốt nhất của chúng tôi, công trình này là đầu tiên kết hợp hai cách tính điểm này cho OCL.
2) Chúng tôi phát triển một khung dựa trên rehearsal mới gọi là UER để giảm thiểu vấn đề quên bằng cách giải quyết vấn đề thiên lệch của dự đoán. Cốt lõi là cơ chế huấn luyện học kiến thức mới của các mẫu hiện tại bằng nhân tố góc và tiếp tục tăng cường kiến thức lịch sử của các mẫu trước đó bằng nhân tố chuẩn.
3) Chúng tôi tiến hành các thí nghiệm rộng rãi trên ba bộ dữ liệu thực tế, và kết quả liên tục chứng minh sự vượt trội của UER so với các phương pháp tiên tiến khác nhau.

2 CÔNG TRÌNH LIÊN QUAN

2.1 Học Liên Tục
Những tiến bộ gần đây về học liên tục có thể được nhóm thành ba loại. 1) Các phương pháp dựa trên kiến trúc chia mỗi giai đoạn thành một tập hợp các tham số cụ thể của mô hình, chứa mạng động [38] và mạng tĩnh [33]. 2) Các phương pháp dựa trên regularization lấy kiến thức lịch sử làm thông tin tiên nghiệm của việc học kiến thức mới, mở rộng hàm mất mát với số hạng regularization bổ sung [13,21]. 3) Các phương pháp dựa trên rehearsal thiết lập bộ đệm bộ nhớ có kích thước cố định [9,14,30,40] hoặc mô hình sinh [11] để lưu trữ, sản xuất và phát lại các mẫu trước đó với các mẫu hiện tại. Loại phương pháp [7,8,29,42] lưu các mẫu trước đó trong bộ đệm vẫn là hiệu quả nhất để chống quên kiến thức hiện nay [5]. Khác với chúng, phương pháp của chúng tôi nhằm khắc phục vấn đề quên cho OCL, yêu cầu hiệu suất thời gian thực cao. Nó khó khăn hơn so với thiết lập học liên tục chung.

2.2 Học Liên Tục Trực Tuyến
Các phương pháp dựa trên rehearsal dựa trên Experience replay (ER) [37] là giải pháp cốt lõi của OCL. Một số phương pháp [2,39] khai thác chiến lược truy xuất bộ nhớ để chọn các mẫu có giá trị hơn từ bộ nhớ. Trong khi đó, một số phương pháp [3,18,20] tập trung vào việc lưu các mẫu hiệu quả hơn, thuộc về nhóm chiến lược cập nhật bộ nhớ. Những phương pháp khác [6,16,17,32,44] được gọi là chiến lược cập nhật mô hình cải thiện quá trình huấn luyện để học hiệu quả. UER được đề xuất là một chiến lược cập nhật mô hình mới để giảm thiểu hiện tượng CF bằng cách giải quyết thiên lệch của dự đoán. Khác với các chiến lược hiện có, UER tính toán logit theo những cách khác nhau cho các mẫu hiện tại và các mẫu trước đó. Cơ chế huấn luyện như vậy tận dụng các tính chất của nhân tố chuẩn và góc. Nó có thể được sử dụng đồng thời để dự đoán thời gian thực mà không cần các hoạt động hậu xử lý bổ sung, mở rộng từ bộ dự đoán sang bộ trích xuất đặc trưng, và dễ dàng kiểm soát quy mô giải quyết thiên lệch.

3 TÁI XEM XÉT BỘ DỰ ĐOÁN

3.1 Định Nghĩa Vấn Đề
OCL chia một luồng dữ liệu thành một chuỗi các batch học mini dưới dạng D={Bt}T t=1, trong đó Bt={Xt×Yt} chứa các mẫu Xt và nhãn tương ứng Yt. Tất cả các lớp đã học được ký hiệu là Ct cho đến bước t. Mạng nơ-ron được tạo thành từ một bộ trích xuất đặc trưng h=hΦ(x) và một bộ dự đoán f(h)=WhT+b, trong đó h không âm bởi Relu, W=[wi], và b=[bi]. Vì đầu ra của bộ dự đoán là logit tích vô hướng, dự đoán phân loại của mẫu x là pdot(x)=[pdot i], và pdot i là xác suất một mẫu thuộc về lớp i∈Ct:

pdot i = exp(wihΦ(x)T+bi) / Σj∈Ct exp(wjhΦ(x)T+bj). (1)

Trong quá trình huấn luyện, mô hình chỉ có thể truy cập Bt và mỗi mẫu chỉ có thể được nhìn thấy một lần. Hàm mục tiêu của nó được tính như
Locl=E(x,y)∼Bt[l(pdot(x),y)], (2)
trong đó l(·) là hàm mất mát cross-entropy.

ER [37], như một phương pháp rehearsal cổ điển, phân bổ một bộ đệm bộ nhớ M để lưu trữ một phần mẫu trước đó, và chọn chúng như BM để phát lại với các mẫu hiện tại. Do đó, hàm mục tiêu có thể được thay đổi thành
Ler=E(x,y)∼Bt∪BM[l(pdot(x),y)]. (3)

LUCIR [19] là một phương pháp cải tiến của ER. Nói chung, logit tích vô hướng (wh+b) của bộ dự đoán có thể được tham số hóa như nhân tố chuẩn (∥w∥∥h∥+b) và nhân tố góc (cos(w,h)) [28]. Trong LUCIR, nhân tố chuẩn được coi là một phần quan trọng với thiên lệch. Do đó, nhân tố góc được sử dụng riêng biệt như logit cosine để tính dự đoán xác suất phân loại pcos(x)=[pcos i]. Và hàm mục tiêu của nó là
Llucir=E(x,y)∼Bt∪BM[l(pcos(x),y)]. (4)
trong đó
pcos i = exp(cos(wi,hΦ(x))·γ) / Σj∈C1:t exp(cos(wj,hΦ(x))·γ). (5)
γ là một tham số tỷ lệ và thường được đặt là 10.

3.2 Phân Tích Quên Thảm Khốc
Có một sự cạnh tranh giữa các mẫu của mỗi lớp trong quá trình lan truyền gradient. Bằng quy tắc chuỗi, gradient của bộ dự đoán cho một mẫu huấn luyện x của lớp y có thể được biểu diễn như
∂Ler/∂wj = {((pdot y-1)h, j=y), (pdot j h, j≠y)}, (6)
và
∂Ler/∂bj = {(pdot y-1, j=y), (pdot j, j≠y)}. (7)

Với tốc độ học dương η và đặc trưng không âm h, nó cung cấp thay đổi dương cho các tham số liên quan của lớp y như wy=wy−η(py−1)h và by=by−η(py−1), và lan truyền các thay đổi âm đến các tham số khác như wj=wj−ηpjh và bj=bj−ηpj. Điều đó có nghĩa là không chỉ các giá trị của wy và by sẽ trở nên lớn hơn, mà các góc của wy và h cũng sẽ nhỏ hơn. Do đó, nó tăng điểm logit của chiều thứ y cũng như giảm điểm logit của các chiều khác. Và quá trình này giống nhau khi sử dụng logit cosine bởi
∂Llucir/∂wj = {((pcos y-1)ĥ, j=y), (pcos j ĥ, j≠y)}, (8)
trong đó
ĥ = h/∥h∥ - cos(w,h)w/∥w∥ / ∥w∥. (9)

Vấn đề thiên lệch là một hiện tượng của CF, chủ yếu được gây ra bởi sự cạnh tranh không cân bằng của sự lan truyền gradient. Nói chung, số lượng mẫu thuộc về các lớp trước đó trong bộ đệm cố định sẽ giảm khi quá trình học tiếp tục. Và số lượng mẫu thuộc về các lớp hiện tại vẫn không thay đổi. Nếu mô hình học tăng dần bằng Eq. 3 hoặc Eq. 4, các tham số liên quan của các lớp hiện tại nhận được nhiều thay đổi dương hơn trong khi những tham số khác có được nhiều thay đổi âm hơn. Điều đó có nghĩa là gradient của các lớp trước đó mất tính cạnh tranh của chúng. Bên cạnh đó, logit của các lớp hiện tại có xu hướng lớn hơn so với những lớp trước đó. Do đó, mô hình có nhiều khả năng phân loại hầu hết các mẫu vào các lớp của các mẫu hiện tại, giảm hiệu suất của các lớp trước đó.

Bảng 1: Kết quả phân tích của các cách khác nhau để huấn luyện và kiểm tra trên Split CIFAR100 (Kích thước Bộ đệm=5000). Nó báo cáo độ chính xác cuối cùng của tất cả các lớp (Aall), các lớp trước đó (Ap), và các lớp hiện tại (Ac). Trong khi đó, nó cũng báo cáo giá trị chuẩn trung bình của các lớp trước đó (∥Wp∥) và hiện tại (∥Wc∥), giá trị trọng số trung bình của các lớp trước đó (Mean(Wp)) và hiện tại (Mean(Wp)), và giá trị bias trung bình của các lớp trước đó (Mean(bp)) và hiện tại (Mean(bc)).

[Bảng có 8 hàng với các cột: Chỉ số, Học, Phát lại, Kiểm tra, Aall, Ap, Ac, ∥Wp∥, ∥Wc∥, Mean(Wp), Mean(Wc), Mean(bp), Mean(bc)]

3.3 Phân Tích Bộ Dự Đoán Thiên Lệch
Gradient không cân bằng chủ yếu ảnh hưởng đến bộ dự đoán từ các nhân tố góc và chuẩn. Nhân tố chuẩn tính cho biến thể trong lớp, và nhân tố góc tính cho biến thể giữa các lớp [28]. Để nghiên cứu sự thay đổi của chúng trong OCL, chúng tôi tiến hành thí nghiệm trên CIFAR100 với hai giai đoạn tăng dần và 50 lớp mỗi giai đoạn. Chúng tôi đặt hai cách chung để tính toán logit trong thí nghiệm: logit tích vô hướng (cả hai nhân tố) và logit cosine (chỉ nhân tố góc). Trong Bảng 1, chúng tôi sử dụng các cách khác nhau để tính toán logit và ghi lại hiệu suất của chúng.

Kết quả thí nghiệm cho thấy rằng các đặc điểm của hai nhân tố này khác nhau. Một mặt, vấn đề thiên lệch chủ yếu xảy ra ở nhân tố góc, hiệu quả học kiến thức mới. So sánh chỉ số 1 và 2, thay thế logit tích vô hướng bằng logit cosine trong giai đoạn kiểm tra dẫn đến độ chính xác cuối cùng tệ hơn, đặc biệt đối với các lớp trước đó. Trong khi đó, phương pháp ở chỉ số 3 hoạt động tốt hơn cho các lớp hiện tại nhưng tệ hơn cho các lớp trước đó so với phương pháp ở chỉ số 1. Mặt khác, nhân tố chuẩn, đã bị các nghiên cứu hiện có [19] loại bỏ, mang lại lợi ích cho các lớp trước đó. Như thấy ở chỉ số 3 và 4, hiệu suất cuối cùng được cải thiện nếu logit cosine được thay đổi thành logit tích vô hướng trong giai đoạn kiểm tra.

Với quan sát này, hai nhân tố có thể được sử dụng trong các trường hợp khác nhau. Nhân tố góc hiệu quả trong việc thích nghi kiến thức mới với biến thể giữa các lớp. Do đó, logit cosine phụ thuộc vào nhân tố góc phù hợp để học các mẫu hiện tại. Và logit tích vô hướng có thể được sử dụng để phát lại các mẫu trước đó vì nó có thể tận dụng nhân tố chuẩn để tăng cường kiến thức lịch sử với biến thể trong lớp. Được thúc đẩy bởi những phát hiện này, chúng tôi đề xuất một phương pháp học các mẫu hiện tại bằng logit cosine, phát lại các mẫu trước đó, và dự đoán các mẫu kiểm tra bằng logit tích vô hướng.

3.4 Phân Tích Phương Pháp Được Đề Xuất
Ngoài kết quả trong Bảng 1, chúng tôi trình bày kết quả chi tiết hơn cho ER (xanh dương), LUCIR (vàng) và phương pháp của chúng tôi (cam) trong Hình 2. Chúng tôi tính toán sự khác biệt giữa các tham số của bộ dự đoán trước và sau khi học các lớp hiện tại, lấy nó làm thay đổi tích lũy của tham số như được thể hiện trong Hình 2 (a). Trong khi đó, chúng tôi báo cáo giá trị chuẩn trung bình của vector trọng số cho tất cả các lớp trong Hình 2 (b). Hơn nữa, chúng tôi tính toán xác suất phân loại trung bình của tất cả các mẫu kiểm tra bằng mô hình mới nhất, được minh họa trong Hình 2 (c). Phân tích sâu hơn và kết quả thí nghiệm xác minh tính khả thi của phương pháp đề xuất của chúng tôi.

Thứ nhất, học các mẫu hiện tại sử dụng logit cosine có thể lưu kiến thức mới vào nhân tố góc. Trong chỉ số 7 và 8, hiệu suất trên các lớp trước đó gần như bằng không khi kiểm tra với logit cosine. Lý do đằng sau điều này là độ tương tự góc gần như là yếu tố quyết định cho gradient trong Phương trình (8). Một mặt, tất cả các vector trong Phương trình (8) được chuẩn hóa và nó tăng cường đáng kể ảnh hưởng của độ tương tự góc. Mặt khác, sự thay đổi của w bị hạn chế bởi ĥ, vì ∥w∥ lớn có thể giảm gradient rất nhiều đến mức các đường truyền trọng số không thể cập nhật hiệu quả. Hơn nữa, logit tích vô hướng được liên kết với một phạm vi giá trị [-∞,+∞], trong khi phạm vi giá trị của logit cosine là [-1,1]. Nó khiến logit cosine tạo ra thay đổi nhỏ hơn cho các lớp trước đó và thay đổi lớn hơn cho các lớp hiện tại (như thấy trong các phần xanh dương và cam trong Hình 2 (a)). Và nó cũng tăng nhân tố chuẩn của các lớp trước đó và giảm nhân tố chuẩn của các lớp hiện tại (như quan sát trong các phần xanh dương và cam trong Hình 2 (b)), điều này hữu ích trong việc học kiến thức mới bằng nhân tố góc.

Thứ hai, phát lại các mẫu trước đó với logit tích vô hướng có thể tăng cường kiến thức lịch sử thông qua nhân tố chuẩn. So sánh chỉ số 7 và 8, sử dụng logit tích vô hướng trong quá trình kiểm tra dẫn đến hiệu suất tốt nhất cho các lớp trước đó, thậm chí vượt qua hiệu suất của các lớp hiện tại. Khác với logit cosine, gradient trong Phương trình (6) phụ thuộc vào cả hai nhân tố. Trong khi đó, gradient của Phương trình (6) chỉ liên quan đến các mẫu trước đó trong bộ đệm. Vì nhân tố góc dễ bị ảnh hưởng bởi gradient không cân bằng, quá trình này có xu hướng chú ý nhiều hơn đến nhân tố chuẩn. Kết quả là, phát lại bằng logit tích vô hướng không chỉ giảm thay đổi cho các lớp trước đó mà còn tăng thay đổi cho các lớp hiện tại (như thấy trong các phần vàng và cam trong Hình 2 (a)). Trong khi đó, nó tăng nhân tố chuẩn của các lớp trước đó cũng như giảm nhân tố chuẩn của các lớp hiện tại (được chỉ ra bởi các phần vàng và cam trong Hình 2 (a)). Nó khiến ∥Wp∥ lớn hơn ∥Wc∥, và Mean(bc) nhỏ hơn Mean(bp). Mặc dù nhân tố góc gặp phải cos(wc,h)>cos(wp,h), nó có thể được tận dụng bởi ∥wp∥∥h∥+bp>∥wc∥∥h∥+bc, như chúng tôi đã mô tả trong Hình 1 (d).

Như được thể hiện trong Bảng 1, phương pháp đề xuất của chúng tôi đạt được hiệu suất tốt nhất trong số tất cả các kết hợp của các logit khác nhau. Dựa trên sự kết hợp của các logit khác nhau, phương pháp của chúng tôi nhanh chóng học kiến thức mới và hiệu quả giữ kiến thức lịch sử. Như được thể hiện trong Hình 2 (c), phân phối xác suất posterior của phương pháp chúng tôi tương đối cân bằng, trong khi những phân phối của ER và LUCIR có xu hướng ưa chuộng các lớp hiện tại. Do đó, động lực của chúng tôi về việc học các mẫu hiện tại bằng logit cosine trong khi phát lại các mẫu trước đó bằng logit tích vô hướng là hợp lý và thực tế.

4 UNBIAS EXPERIENCE REPLAY
Được truyền cảm hứng bởi những phân tích này, chúng tôi đề xuất một khung UER mới, đây là một giải pháp đơn giản nhưng hiệu quả cho OCL. Khung bao gồm một bộ trích xuất đặc trưng dựa trên CNN và một bộ dự đoán. Ý tưởng chính là giảm thiểu vấn đề quên của mô hình bằng cách giải quyết vấn đề thiên lệch của phân phối xác suất. Mô hình có thể nhanh chóng học kiến thức mới của các mẫu hiện tại bằng nhân tố góc, và hiệu quả củng cố kiến thức lịch sử học được từ các mẫu trước đó bằng cả hai nhân tố. Luồng công việc tổng thể có thể được chia thành ba mô-đun chính: hoạt động bộ đệm bộ nhớ, huấn luyện liên tục trực tuyến và kiểm tra liên tục trực tuyến.

4.1 Hoạt Động Bộ Đệm Bộ Nhớ
Tiện lợi, bộ đệm bộ nhớ trong khung của chúng tôi có kích thước cố định, bất kể lượng mẫu lớn như thế nào. Một mặt, nó cập nhật bộ đệm bộ nhớ bằng chiến lược lấy mẫu reservoir. Khi bộ nhớ không thể tải tất cả các mẫu, thuật toán lấy mẫu reservoir có thể đảm bảo rằng xác suất của mỗi mẫu được trích xuất là bằng nhau. Mặt khác, nó ngẫu nhiên truy xuất các mẫu trước đó từ bộ đệm bộ nhớ để tham gia vào việc học các mẫu hiện tại.

4.2 Huấn Luyện Liên Tục Trực Tuyến
Trong phần này, nó huấn luyện mô hình bằng cách tính toán logit theo những cách khác nhau khi học các mẫu hiện tại và phát lại các mẫu trước đó. Dựa trên mô hình được khởi tạo, khung không chỉ lấy nhân tố góc để lưu kiến thức mới mà còn tận dụng nhân tố chuẩn để tăng cường tất cả kiến thức đã học. Nó có thể giải quyết vấn đề thiên lệch của dự đoán và tiếp tục giảm thiểu hiện tượng CF bằng cách tối ưu hóa hàm mục tiêu như
L=Lc+Lp, (10)
có hai thành phần để học các mẫu huấn luyện.

Thành phần học Lc là hàm mất mát cross-entropy chung dựa trên logit cosine, chỉ liên quan đến các mẫu hiện tại. Mục tiêu của thành phần này là khai thác kiến thức mới của các lớp mới, lưu nó vào nhân tố góc. Và giá trị mất mát được tính như sau
Lc=E(x,y)∼Bt[l(pcos(x),y)]. (11)

Thành phần phát lại Lp kết hợp các hàm mất mát cross-entropy khác nhau. Nó chỉ liên quan đến các mẫu trước đó trong bộ đệm bộ nhớ, và nó tính toán xác suất phân loại ở cả nhân tố góc và chuẩn. Mất mát với logit tích vô hướng tận dụng nhân tố chuẩn để tăng cường kiến thức lịch sử và xử lý vấn đề thiên lệch. Trong khi đó, mất mát với logit cosine có thể kiểm soát cường độ tận dụng và ngăn mô hình mất khả năng tổng quát hóa. Chi tiết, khung lấy pdot(x) như xác suất phân loại của các mẫu trước đó, có thể mang lại nhiều thay đổi tích cực hơn cho các tham số của các lớp trước đó. Bên cạnh đó, nó lấy pcos(x) của các mẫu trước đó để cân bằng cường độ của thay đổi. Cuối cùng, nó có thể có được hàm mục tiêu như
Lp=E(x,y)∼BM[αl(pdot(x),y)+(1−α)l(pcos(x),y)], (12)
trong đó α là siêu tham số của quy mô tận dụng.

4.3 Kiểm Tra Liên Tục Trực Tuyến
Thành phần kiểm tra tương tự như quá trình phát lại các mẫu trước đó. Mỗi mẫu kiểm tra x lan truyền tiến qua mạng để có được phân phối xác suất lớp pdot(x). Sau đó chúng ta có thể phân loại nó dựa trên công thức sau
ŷ=arg maxc pdot(x)[c],c∈Ct. (13)

Toàn bộ quy trình huấn luyện và suy luận được tóm tắt trong Thuật toán 1. Để bắt đầu, phần hoạt động bộ đệm bộ nhớ thiết lập bộ đệm bộ nhớ có kích thước cố định để lưu (dòng 10) và phát lại các mẫu trước đó (dòng 5). Sau đó, phần huấn luyện liên tục trực tuyến (dòng 6-9) khắc phục vấn đề quên bằng cách học các mẫu hiện tại và các mẫu trước đó bằng các hàm mục tiêu khác nhau, tương ứng. Cuối cùng, phần kiểm tra liên tục trực tuyến (dòng 13-16) dự đoán xác suất phân loại của mẫu không biết bằng logit tích vô hướng, điều này hữu ích để phân loại chính xác các mẫu kiểm tra.

Thuật toán 1 Unbias Experience Replay
Đầu vào: Bộ dữ liệu D, Tốc độ Học λ, Tham số Đánh đổi α
Đầu ra: Tham số Mạng θ
1: Khởi tạo: Bộ Đệm Bộ Nhớ M←{}
2: for t∈{1,2,...,T} do
3:    //Giai đoạn Huấn luyện
4:    for Bt∈D do
5:        BM←MemoryRetrieval(M).
6:        Lc←E(x,y)∼Bt[l(pcos(x),y)]
7:        Lp←E(x,y)∼BM[αl(pdot(x),y)+(1−α)l(pcos(x),y)]
8:        L←Lc+Lp
9:        θ←θ+λ∇θL.
10:       M←MemoryUpdate(M,Bt).
11:   end for
12:   //Giai đoạn Kiểm tra
13:   m←số lượng mẫu kiểm tra
14:   for i∈{1,2,...,m} do
15:       ŷ←arg maxc pdot(xi)[c],c∈Ct
16:   end for
17:   return θ
18: end for

5 THÍ NGHIỆM

5.1 Thiết Lập Thí Nghiệm

5.1.1 Bộ Dữ Liệu. Để đánh giá hiệu quả của khung dựa trên replay UER của chúng tôi, chúng tôi tiến hành các thí nghiệm rộng rãi trên ba bộ dữ liệu có sẵn công khai (CIFAR10 [22], CIFAR100 [22] và MiniImageNet [41]). Split CIFAR10 bao gồm 5 giai đoạn học và mỗi giai đoạn chứa 2 lớp. Split CIFAR100 và Split MiniImageNet được tạo thành từ 10 giai đoạn học và mỗi giai đoạn có 10 lớp.

5.1.2 Chỉ Số Đánh Giá. Chúng tôi định nghĩa ai,j(j<=i) như độ chính xác được đánh giá trên các mẫu kiểm tra được giữ lại của giai đoạn thứ j sau khi mạng đã học i giai đoạn đầu tiên. Tương tự với [39], chúng ta có thể thu được tỷ lệ độ chính xác trung bình như
Ai=1/i Σj=1 to i ai,j. (14)

5.1.3 Chi Tiết Triển Khai. Thiết lập cơ bản của mô hình backbone giống với công trình hiện có [6]. Chi tiết, chúng tôi lấy ReducedResNet18 (số lượng bộ lọc là 20) làm bộ trích xuất đặc trưng trên tất cả các bộ dữ liệu. Tất cả các mạng được khởi tạo ngẫu nhiên thay vì được huấn luyện trước. Trong giai đoạn huấn luyện, mạng được huấn luyện với bộ tối ưu SGD và tốc độ học được đặt là 0.1. Trong khi đó, chúng tôi chọn α trên tập xác thực được thu được bằng cách lấy mẫu 10% của tập huấn luyện. Đối với giai đoạn kiểm tra, chúng tôi chọn 256 làm kích thước batch.

Đối với tất cả các bộ dữ liệu, các chỉ số lớp được xáo trộn trước khi chia. Mô hình nhận 10 mẫu hiện tại từ luồng dữ liệu và 10 mẫu trước đó từ bộ đệm bộ nhớ tại một thời điểm bất kể kích thước của bộ nhớ. Hơn nữa, chúng tôi sử dụng sự kết hợp của các kỹ thuật tăng cường khác nhau để có được các hình ảnh được tăng cường.

5.2 Hiệu Suất Tổng Thể
Trong phần này, chúng tôi tiến hành thí nghiệm cho UER và các baseline tiên tiến khác nhau trên ba bộ dữ liệu. Chúng tôi không chỉ trực tiếp so sánh hiệu suất của UER với các phương pháp này, mà còn khám phá sự cải thiện của UER cho chúng.

So sánh với các baseline hiện có. Bảng 2 chứng minh độ chính xác trung bình cuối cùng cho ba bộ dữ liệu. Tất cả điểm được báo cáo là trung bình của 10 lần chạy với khoảng tin cậy 95%. Trong số tất cả các phương pháp dựa trên rehearsal, các chiến lược cập nhật mô hình là hiệu quả nhất, và phương pháp ER-ACE đạt được kết quả tốt nhất. Tuy nhiên, UER được đề xuất của chúng tôi vẫn vượt trội hơn chúng, chứng minh hiệu quả của nó. Cụ thể, UER đạt được hiệu suất tốt nhất trong 10 trong số 12 kịch bản thí nghiệm, trong đó ba bộ dữ liệu chứa bốn bộ đệm bộ nhớ có kích thước khác nhau. Nó có hiệu suất nổi bật nhất trên Split CIFAR100 và Split MiniImageNet. Trong khi đó, sự tăng trưởng của kích thước bộ đệm tiếp tục cải thiện hiệu suất của UER. Ví dụ, UER vượt trội so với baseline mạnh nhất ER-ACE với khoảng cách 0.3%, 1.6%, 0.3%, 1.3% trên Split MiniImagenet khi kích thước bộ đệm bộ nhớ là 500, 1000, 2000 và 5000, tương ứng. Hơn nữa, UER đánh bại ER-ACE với sự cải thiện 1.2%, 1.5%, 2.2% và 2.6% trên Split CIFAR100 với kích thước bộ đệm bộ nhớ 500, 1000, 2000 và 5000, tương ứng.

Chúng tôi lưu ý rằng hiệu suất của UER không tối ưu trên Split CIFAR10 khi kích thước bộ đệm nhỏ hơn. Điều đó là vì có ít lớp hơn trong bộ dữ liệu này, và vấn đề thiên lệch không nghiêm trọng lắm. Trong khi đó, việc học nhân tố chuẩn không đủ khi số lượng mẫu nhỏ.

Chúng tôi báo cáo hiệu suất độ chính xác tại mỗi giai đoạn cho một số phương pháp hiệu quả trên tất cả các bộ dữ liệu. Như được mô tả trong Hình 3, UER không chỉ đạt được kết quả đáng kể trong độ chính xác của giai đoạn cuối, mà còn liên tục vượt trội so với các baseline khác trong suốt toàn bộ quá trình học. Hiệu quả của nó trở nên rõ ràng hơn khi các giai đoạn tăng lên, thể hiện khả năng khắc phục CF của nó. Ví dụ, mặc dù lợi thế của UER không rõ ràng ở giai đoạn thứ hai và thứ ba, hiệu suất chống quên của nó là tốt nhất trong các giai đoạn còn lại trên Split CIFAR100.

Cải thiện cho các baseline hiện có. Chúng tôi áp dụng UER cho các baseline hiện có, và kết quả chứng minh rằng UER cải thiện đáng kể hiệu suất của chúng. Hình 4 nêu hiệu suất của sáu baseline dựa trên ER có và không có sự kết hợp của phương pháp chúng tôi trên Split CIFAR100 và Split MiniImagenet. Các đường xanh dương biểu thị độ chính xác ban đầu của các nghiên cứu hiện có, trong khi những đường đỏ là độ chính xác cải thiện của chúng sau khi kết hợp với UER. Bằng cách tận dụng nhân tố chuẩn để xử lý vấn đề thiên lệch, hiệu suất của các baseline này trong việc chống quên được tăng cường. Ví dụ, SCR hoạt động kém cho các batch học mini, đạt được hiệu suất tốt nhất trong toàn bộ quá trình học với sự trợ giúp của phương pháp chúng tôi. Tóm lại, phương pháp của chúng tôi không chỉ thể hiện lợi thế đáng kể so với các phương pháp baseline khác, mà còn có thể được tích hợp với các phương pháp hiện có để cải thiện đáng kể hiệu suất của chúng.

5.3 Nghiên Cứu Phân Tích

5.3.1 Khả Năng Thời Gian Thực. UER là một phương pháp đơn giản và hiệu quả để dự đoán thời gian thực của OCL. Tương tự như [15], chúng tôi sử dụng CD để so sánh tính toán của các phương pháp khác nhau. CD được ký hiệu như một độ phức tạp tương đối giữa luồng và một phương pháp học liên tục cơ bản. Ví dụ, khi các mẫu hiện tại đến, ER có thể ngay lập tức học chúng và sau đó dự đoán các mẫu không biết, dẫn đến độ phức tạp tương đối là 1. Vì UER và ER-ACE chỉ sửa đổi mục tiêu mất mát của ER, độ phức tạp tính toán của chúng tương đương với 1. Tuy nhiên, OBC phải phát lại một batch khác của các mẫu trước đó dựa trên ER, khiến nó yêu cầu 1.5 ×FLOPs cần thiết bởi ER. Do đó, độ phức tạp tính toán của nó là 1.5, điều này hạn chế khả năng dự đoán thời gian thực. Việc so sánh thời gian chạy giữa các phương pháp khác nhau cũng xác nhận kết quả này.

5.3.2 Tính Linh Hoạt. Trong khi đó, UER linh hoạt vì nó không chỉ phù hợp cho lớp tuyến tính của bộ dự đoán, mà còn có lợi cho lớp trong bộ trích xuất đặc trưng. Cụ thể, chúng tôi thêm một lớp tuyến tính vào bộ trích xuất đặc trưng. Mô-đun kết hợp được sử dụng trong bộ trích xuất đặc trưng, bộ dự đoán và tất cả các lớp tuyến tính, tương ứng. Bảng 4 báo cáo tỷ lệ độ chính xác trung bình cuối cùng của tất cả các lớp, các lớp hiện tại và các lớp trước đó cho tất cả các phương pháp. Không khó để thấy rằng mô-đun này có thể hoạt động trên mỗi lớp tuyến tính riêng lẻ, và hiệu suất tổng thể tốt hơn và ổn định hơn trên cả hai lớp tuyến tính. Do đó, so với các phương pháp hiện có khác, UER không bị hạn chế bởi ranh giới các lớp, và có phạm vi ứng dụng rộng hơn.

5.3.3 Khả Năng Điều Chỉnh. Bằng cách sử dụng logit tích vô hướng, UER tận dụng nhân tố chuẩn để cân bằng hiệu suất của các lớp hiện tại và trước đó. Và hiệu ứng chủ yếu bị ảnh hưởng bởi siêu tham số quy mô tận dụng α. Như được thể hiện trong Bảng 2, phiên bản ablation của UER được ký hiệu là UER-A. Do thiếu điều chỉnh quy mô, UER-A hoạt động tệ hơn UER.

Để khám phá tác động của α, chúng tôi tiến hành thí nghiệm trên Split CIFAR100 cho α khác nhau. Trong Hình 5, chúng tôi báo cáo độ chính xác của tất cả các lớp cho UER, có thể được chia thành độ chính xác của các lớp trước đó và độ chính xác của các lớp hiện tại. Khi α tăng, tỷ lệ logit tích vô hướng tăng. Hiệu suất của nó (đường đỏ) sẽ được cải thiện lúc đầu, và nó sẽ không tăng cường hoặc thậm chí bắt đầu giảm khi α trở nên lớn. Bằng cách so sánh hiệu suất của các lớp hiện tại và trước đó, chúng tôi thấy rằng độ chính xác của các lớp hiện tại (đường xanh dương) sẽ giảm với sự tăng của α. Trong khi tỷ lệ độ chính xác của các lớp trước đó (đường xanh lá) sẽ tăng lúc đầu và sau đó giảm. Thực nghiệm, UER có thể phát huy vai trò lớn nhất cho mô hình khi giá trị của α khoảng 0.5. Do đó, UER có thể điều chỉnh hơn so với các phương pháp khác. Trong Hình 6, chúng tôi chứng minh hiệu suất của một số phương pháp giải quyết thiên lệch trên các lớp trước đó, các lớp hiện tại và trung bình của chúng. Với sự trợ giúp của quy mô, UER không chỉ đảm bảo khả năng tổng quát hóa để học các lớp hiện tại, mà còn cải thiện khả năng bộ nhớ để nắm bắt các lớp trước đó.

6 KẾT LUẬN
Trong bài báo này, chúng tôi phát triển một phương pháp OCL heuristic gọi là UER để giảm thiểu hiện tượng CF bằng cách giải quyết vấn đề thiên lệch của logit. Bằng cách kiểm tra sự thay đổi của bộ dự đoán, chúng tôi thấy rằng các nhân tố quan trọng của logit tích vô hướng bao gồm một nhân tố chuẩn và một nhân tố góc. Nhân tố trước có lợi cho các lớp trước đó trong khi nhân tố sau ưa chuộng các lớp hiện tại. Kết quả là, logit cosine phụ thuộc vào nhân tố góc phù hợp để thích nghi kiến thức mới. Và logit tích vô hướng được tạo thành từ các nhân tố chuẩn và góc tốt trong việc lưu trữ kiến thức lịch sử. Do đó, UER được đề xuất tận dụng nhân tố chuẩn để cân bằng dự đoán phân loại của bộ dự đoán. Nó học các mẫu hiện tại chỉ bằng nhân tố góc và tiếp tục phát lại các mẫu trước đó bằng cả nhân tố chuẩn và góc. Các thí nghiệm rộng rãi trên ba bộ dữ liệu chứng minh sự vượt trội của UER so với các baseline tiên tiến khác nhau.

LỜI CẢM ƠN
Công trình này được hỗ trợ một phần bởi Quỹ Khoa học Tự nhiên Quốc gia Trung Quốc (Số 61972111, Số 62202124 và Số 62272130), Chương trình Khoa học Tự nhiên của Thâm Quyến (Số JCYJ20210324120208022 và Số JCYJ20200109113014456) và Chương trình Khoa học và Công nghệ Thâm Quyến (Số KCXFZ20211020163403005).

TÀI LIỆU THAM KHẢO
[1] Hongjoon Ahn, Jihwan Kwak, Subin Lim, Hyeonsu Bang, Hyojun Kim, và Taesup Moon. 2021. Ss-il: Separated softmax for incremental learning. Trong Kỷ yếu Hội nghị Quốc tế IEEE/CVF về Thị giác Máy tính. 844–853.
[2] Rahaf Aljundi, Eugene Belilovsky, Tinne Tuytelaars, Laurent Charlin, Massimo Caccia, Min Lin, và Lucas Page-Caccia. 2019. Online Continual Learning with Maximal Interfered Retrieval. Advances in Neural Information Processing Systems 32 (2019), 11849–11860.
[3] Rahaf Aljundi, Min Lin, Baptiste Goujaud, và Yoshua Bengio. 2019. Gradient based sample selection for online continual learning. Advances in neural information processing systems 32 (2019).
[4] Pietro Buzzega, Matteo Boschini, Angelo Porrello, Davide Abati, và Simone Calderara. 2020. Dark experience for general continual learning: a strong, simple baseline. Advances in neural information processing systems 33 (2020), 15920–15930.
[5] Pietro Buzzega, Matteo Boschini, Angelo Porrello, và Simone Calderara. 2021. Rethinking experience replay: a bag of tricks for continual learning. Trong 2020 25th International Conference on Pattern Recognition (ICPR). IEEE, 2180–2187.
[6] Lucas Caccia, Rahaf Aljundi, Nader Asadi, Tinne Tuytelaars, Joelle Pineau, và Eugene Belilovsky. 2021. New Insights on Reducing Abrupt Representation Change in Online Continual Learning. Trong International Conference on Learning Representations.
[7] Hyuntak Cha, Jaeho Lee, và Jinwoo Shin. 2021. Co2l: Contrastive continual learning. Trong Kỷ yếu Hội nghị Quốc tế IEEE/CVF về Thị giác Máy tính. 9516–9525.
[8] Arslan Chaudhry, Albert Gordo, Puneet Dokania, Philip Torr, và David Lopez-Paz. 2021. Using Hindsight to Anchor Past Knowledge in Continual Learning. Trong Kỷ yếu Hội nghị AAAI về Trí tuệ Nhân tạo, Tập 35. 6993–7001.
[9] Arslan Chaudhry, Marc'Aurelio Ranzato, Marcus Rohrbach, và Mohamed Elhoseiny. 2018. Efficient Lifelong Learning with A-GEM. Trong International Conference on Learning Representations.
[10] Aristotelis Chrysakis và Marie-Francine Moens. [n. d.]. Online Bias Correction for Task-Free Continual Learning. Trong The Eleventh International Conference on Learning Representations.
[11] Bo Cui, Guyue Hu, và Shan Yu. 2021. DeepCollaboration: Collaborative Generative and Discriminative Models for Class Incremental Learning. Trong Kỷ yếu Hội nghị AAAI về Trí tuệ Nhân tạo, Tập 35. 1175–1183.
[12] Matthias Delange, Rahaf Aljundi, Marc Masana, Sarah Parisot, Xu Jia, Ales Leonardis, Greg Slabaugh, và Tinne Tuytelaars. 2021. A continual learning survey: Defying forgetting in classification tasks. IEEE Transactions on Pattern Analysis and Machine Intelligence (2021).
[13] Prithviraj Dhar, Rajat Vikram Singh, Kuan-Chuan Peng, Ziyan Wu, và Rama Chellappa. 2019. Learning without memorizing. Trong Kỷ yếu Hội nghị IEEE/CVF về Thị giác Máy tính và Nhận dạng Mẫu. 5138–5146.
[14] Mehrdad Farajtabar, Navid Azizan, Alex Mott, và Ang Li. 2020. Orthogonal gradient descent for continual learning. Trong International Conference on Artificial Intelligence and Statistics. PMLR, 3762–3773.
[15] Yasir Ghunaim, Adel Bibi, Kumail Alhamoud, Motasem Alfarra, Hasan Abed Al Kader Hammoud, Ameya Prabhu, Philip HS Torr, và Bernard Ghanem. 2023. Real-time evaluation in online continual learning: A new paradigm. arXiv preprint arXiv:2302.01047 (2023).
[16] Yanan Gu, Xu Yang, Kun Wei, và Cheng Deng. 2022. Not Just Selection, but Exploration: Online Class-Incremental Continual Learning via Dual View Consistency. Trong Kỷ yếu Hội nghị IEEE/CVF về Thị giác Máy tính và Nhận dạng Mẫu. 7442–7451.
[17] Yiduo Guo, Bing Liu, và Dongyan Zhao. 2022. Online Continual Learning through Mutual Information Maximization. Trong International Conference on Machine Learning. PMLR, 8109–8126.
[18] Jiangpeng He và Fengqing Zhu. 2021. Online continual learning for visual food classification. Trong Kỷ yếu Hội nghị Quốc tế IEEE/CVF về Thị giác Máy tính. 2337–2346.
[19] Saihui Hou, Xinyu Pan, Chen Change Loy, Zilei Wang, và Dahua Lin. 2019. Learning a unified classifier incrementally via rebalancing. Trong Kỷ yếu Hội nghị IEEE/CVF về Thị giác Máy tính và Nhận dạng Mẫu. 831–839.
[20] Xisen Jin, Arka Sadhu, Junyi Du, và Xiang Ren. 2021. Gradient-based Editing of Memory Examples for Online Task-free Continual Learning. Advances in Neural Information Processing Systems 34 (2021).
[21] James Kirkpatrick, Razvan Pascanu, Neil Rabinowitz, Joel Veness, Guillaume Desjardins, Andrei A Rusu, Kieran Milan, John Quan, Tiago Ramalho, Agnieszka Grabska-Barwinska, và cộng sự. 2017. Overcoming catastrophic forgetting in neural networks. Proceedings of the national academy of sciences 114, 13 (2017), 3521–3526.
[22] Alex Krizhevsky, Geoffrey Hinton, và cộng sự. 2009. Learning multiple layers of features from tiny images. (2009).
[23] Huiwei Lin, Shanshan Feng, Xutao Li, Wentao Li, và Yunming Ye. 2022. Anchor assisted experience replay for online class-incremental learning. IEEE Transactions on Circuits and Systems for Video Technology (2022).
[24] Huiwei Lin, Baoquan Zhang, Shanshan Feng, Xutao Li, và Yunming Ye. 2023. PCR: Proxy-based Contrastive Replay for Online Class-Incremental Continual Learning. Trong Kỷ yếu Hội nghị IEEE/CVF về Thị giác Máy tính và Nhận dạng Mẫu. 24246–24255.
[25] Bing Liu và Sahisnu Mazumder. 2021. Lifelong and continual learning dialogue systems: learning during conversation. Trong Kỷ yếu Hội nghị AAAI về Trí tuệ Nhân tạo, Tập 35. 15058–15063.
[26] Bing Liu, Sahisnu Mazumder, Eric Robertson, và Scott Grigsby. 2022. AI Autonomy: Self-Initiation, Adaptation and Continual Learning. arXiv preprint arXiv:2203.08994 (2022).
[27] Bing Liu và Chuhe Mei. 2020. Lifelong knowledge learning in rule-based dialogue systems. arXiv preprint arXiv:2011.09811 (2020).
[28] Weiyang Liu, Zhen Liu, Zhiding Yu, Bo Dai, Rongmei Lin, Yisen Wang, James M Rehg, và Le Song. 2018. Decoupled networks. Trong Kỷ yếu Hội nghị IEEE về Thị giác Máy tính và Nhận dạng Mẫu. 2771–2779.
[29] Yaoyao Liu, Bernt Schiele, và Qianru Sun. 2021. RMM: Reinforced memory management for class-incremental learning. Advances in Neural Information Processing Systems 34 (2021).
[30] David Lopez-Paz và Marc'Aurelio Ranzato. 2017. Gradient episodic memory for continual learning. Advances in neural information processing systems 30 (2017).
[31] Zheda Mai, Ruiwen Li, Jihwan Jeong, David Quispe, Hyunwoo Kim, và Scott Sanner. 2022. Online continual learning in image classification: An empirical survey. Neurocomputing 469 (2022), 28–51.
[32] Zheda Mai, Ruiwen Li, Hyunwoo Kim, và Scott Sanner. 2021. Supervised Contrastive Replay: Revisiting the Nearest Class Mean Classifier in Online Class-Incremental Continual Learning. Trong Kỷ yếu Hội nghị IEEE/CVF về Thị giác Máy tính và Nhận dạng Mẫu. 3589–3599.
[33] Zichen Miao, Ze Wang, Wei Chen, và Qiang Qiu. 2021. Continual Learning with Filter Atom Swapping. Trong International Conference on Learning Representations.
[34] Liqiang Nie, Leigang Qu, Dai Meng, Min Zhang, Qi Tian, và Alberto Del Bimbo. 2022. Search-oriented Micro-video Captioning. Trong Kỷ yếu Hội nghị Đa phương tiện Quốc tế ACM lần thứ 30. 3234–3243.
[35] Liqiang Nie, Wenjie Wang, Richang Hong, Meng Wang, và Qi Tian. 2019. Multi-modal dialog system: Generating responses via adaptive decoders. Trong Kỷ yếu Hội nghị Đa phương tiện Quốc tế ACM lần thứ 27. 1098–1106.
[36] Liqiang Nie, Xiang Wang, Jianglong Zhang, Xiangnan He, Hanwang Zhang, Richang Hong, và Qi Tian. 2017. Enhancing micro-video understanding by harnessing external sounds. Trong Kỷ yếu hội nghị đa phương tiện quốc tế ACM lần thứ 25. 1192–1200.
[37] David Rolnick, Arun Ahuja, Jonathan Schwarz, Timothy Lillicrap, và Gregory Wayne. 2019. Experience replay for continual learning. Advances in Neural Information Processing Systems 32 (2019).
[38] Andrei A Rusu, Neil C Rabinowitz, Guillaume Desjardins, Hubert Soyer, James Kirkpatrick, Koray Kavukcuoglu, Razvan Pascanu, và Raia Hadsell. 2016. Progressive neural networks. arXiv preprint arXiv:1606.04671 (2016).
[39] Dongsub Shim, Zheda Mai, Jihwan Jeong, Scott Sanner, Hyunwoo Kim, và Jongseong Jang. 2021. Online class-incremental continual learning with adversarial shapley value. Trong Kỷ yếu Hội nghị AAAI về Trí tuệ Nhân tạo, Tập 35. 9630–9638.
[40] Shixiang Tang, Dapeng Chen, Jinguo Zhu, Shijie Yu, và Wanli Ouyang. 2021. Layerwise optimization by gradient decomposition for continual learning. Trong Kỷ yếu Hội nghị IEEE/CVF về Thị giác Máy tính và Nhận dạng Mẫu. 9634–9643.
[41] Oriol Vinyals, Charles Blundell, Timothy Lillicrap, Daan Wierstra, và cộng sự. 2016. Matching networks for one shot learning. Advances in neural information processing systems 29 (2016), 3630–3638.
[42] Liyuan Wang, Xingxing Zhang, Kuo Yang, Longhui Yu, Chongxuan Li, HONG Lanqing, Shifeng Zhang, Zhenguo Li, Yi Zhong, và Jun Zhu. 2021. Memory Replay with Data Compression for Continual Learning. Trong International Conference on Learning Representations.
[43] Yue Wu, Yinpeng Chen, Lijuan Wang, Yuancheng Ye, Zicheng Liu, Yandong Guo, và Yun Fu. 2019. Large scale incremental learning. Trong Kỷ yếu Hội nghị IEEE/CVF về Thị giác Máy tính và Nhận dạng Mẫu. 374–382.
[44] Haiyan Yin, Ping Li, và cộng sự. 2021. Mitigating Forgetting in Online Continual Learning with Neuron Calibration. Advances in Neural Information Processing Systems 34 (2021).
[45] Bowen Zhao, Xi Xiao, Guojun Gan, Bin Zhang, và Shu-Tao Xia. 2020. Maintaining discrimination and fairness in class incremental learning. Trong Kỷ yếu Hội nghị IEEE/CVF về Thị giác Máy tính và Nhận dạng Mẫu. 13208–13217.

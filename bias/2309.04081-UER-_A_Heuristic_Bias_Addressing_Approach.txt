# 2309.04081.pdf
# Converted from PDF to TXT
# Source path: /home/admin88/arxiv-downloader/bias/2309.04081.pdf
# File size: 942906 bytes

===============================================
PDF FILE CONTENT
===============================================


--- PAGE 1 ---
UER: A Heuristic Bias Addressing Approach
for Online Continual Learning
Huiwei Lin
Harbin Institute of Technology
Shenzhen, China
linhuiwei@stu.hit.edu.cnShanshan Feng∗
Harbin Institute of Technology
Shenzhen, China
victor_fengss@foxmail.comBaoquan Zhang
Harbin Institute of Technology
Shenzhen, China
zhangbaoquan@stu.hit.edu.cn
Hongliang Qiao
Harbin Institute of Technology
Shenzhen, China
21s151112@stu.hit.edu.cnXutao Li
Harbin Institute of Technology
Shenzhen, China
lixutao@hit.edu.cnYunming Ye
Harbin Institute of Technology
Shenzhen, China
yeyunming@hit.edu.cn
ABSTRACT
Online continual learning aims to continuously train neural net-
works from a continuous data stream with a single pass-through
data. As the most effective approach, the rehearsal-based methods
replay part of previous data. Commonly used predictors in existing
methods tend to generate biased dot-product logits that prefer to
the classes of current data, which is known as a bias issue and a
phenomenon of forgetting. Many approaches have been proposed
to overcome the forgetting problem by correcting the bias; however,
they still need to be improved in online fashion. In this paper, we try
to address the bias issue by a more straightforward and more effi-
cient method. By decomposing the dot-product logits into an angle
factor and a norm factor, we empirically find that the bias problem
mainly occurs in the angle factor, which can be used to learn novel
knowledge as cosine logits. On the contrary, the norm factor aban-
doned by existing methods helps remember historical knowledge.
Based on this observation, we intuitively propose to leverage the
norm factor to balance the new and old knowledge for addressing
the bias. To this end, we develop a heuristic approach called unbias
experience replay (UER). UER learns current samples only by the
angle factor and further replays previous samples by both the norm
and angle factors. Extensive experiments on three datasets show
that UER achieves superior performance over various state-of-the-
art methods. The code is in https://github.com/FelixHuiweiLin/UER.
CCS CONCEPTS
•Computing methodologies →Cross-validation ;Image rep-
resentations .
KEYWORDS
neural networks, online continual learning, image classification
∗Corresponding author: Shanshan Feng
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
MM ’23, October 29-November 3, 2023, Ottawa, ON, Canada
©2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 979-8-4007-0108-5/23/10. . . $15.00
https://doi.org/10.1145/3581783.3612011ACM Reference Format:
Huiwei Lin, Shanshan Feng, Baoquan Zhang, Hongliang Qiao, Xutao Li,
and Yunming Ye. 2023. UER: A Heuristic Bias Addressing Approach for
Online Continual Learning. In Proceedings of the 31st ACM International
Conference on Multimedia (MM ’23), October 29-November 3, 2023, Ottawa,
ON, Canada. ACM, New York, NY, USA, 9 pages. https://doi.org/10.1145/
3581783.3612011
1 INTRODUCTION
At present, deep neural networks [ 34–36] still cannot have the con-
ventional ability of continuous learning as human beings. If the
model adapts to new data through fine-tuning, it will significantly
degrade the performance of old data. Such a phenomenon is named
catastrophic forgetting (CF) [ 12]. Since solving this problem is of
great significance, continual learning [ 25–27] has been proposed
to train the model to achieve knowledge accumulation without for-
getting. Particularly, online continual learning (OCL) is a realistic
scenario of continual learning. It requires overcoming the CF prob-
lem of continuously learning from an infinite and non-stationary
data stream, where the data can be accessed only once.
The rehearsal-based methods have shown superior performance
for OCL among all approaches of continual learning [ 23]. This
family of methods [ 24,31,44] set an episodic memory buffer to store
part of previous samples and replay them in the learning process
of current samples. In this type of methods, the phenomenon of CF
is exhibited as a biased issue of prediction due to data imbalance.
Specifically, the number of current samples in the data stream is
generally greater than the number of previous samples in the fixed
buffer. Hence, the model tends to score the samples with biased
predictions and easily classifies most samples to current classes.
Although existing methods mitigate the forgetting problem by
correcting the bias, they still need to be improved in online fash-
ion. Specifically, there are three main challenges that need to be
addressed: 1) Real-time ability . Some methods [ 32,43,45] require
additional training steps or post-operations, which is not benefi-
cial to the real-time prediction of the model. 2) Flexibility . Some
methods [ 1,6] rely heavily on the clear boundary between the old
and new classes, and they cannot be extended from the predictor
to the feature extractor. 3) Adjustability . Other methods [ 6,10]
are difficult to adjust the scale of bias correction, easily limiting
the generalization ability of the models. Thus, a meaningful ques-
tion arises: Is there a more straightforward and efficient approacharXiv:2309.04081v1  [cs.LG]  8 Sep 2023

--- PAGE 2 ---
MM ’23, October 29-November 3, 2023, Ottawa, ON, Canada Huiwei Lin et al.
dot-product logits
norm factor angle factor (cosine logits)(a) Factors of logits (b) Existing studies
Backbone
Current 
SamplesPrevious
Samples
learning replayingEither 
or 
testingDog Plane CatShip25%
15%55%
5%×
?
(c) Our work
Backbone
Current
SamplesPrevious
Samples
learning replaying
testingDog CatShip Plane60%
20%16%
4%√
?(d) Our rationale
Figure 1: Illustration of our work. (a) The dot-product logits can be decomposed into a norm factor and an angle factor; (b)
Existing studies, which learn all samples by calculating logits in the same way; (c) Different from existing studies, the model in
our work learns current samples only by the angle factor meanwhile replays previous samples by both the angle factor and the
norm factor. (d) By leveraging the norm factor, the model can correctly classify samples.
that can simultaneously meet these three challenges and effectively
address the bias issue for OCL?
To answer this question, we dissect existing rehearsal-based
methods and empirically find that the biased predictions (dot-product
logits) mainly changes in two parts, as shown in Figure 1(a). In-
spired by [ 28], we decompose the dot-product logits ( 𝒘𝒉+𝑏) into
a norm factor (∥𝒘∥∥𝒉∥+𝑏) and an angle factor ( 𝑐𝑜𝑠(𝒘,𝒉)). The
unbalance data leads to an unbalanced competition of gradient
propagation, which is a major cause of the CF phenomenon, and
this effect influences the logits in both factors. Further experiments
reveal that these two factors act differently during the training
process. On one hand, the angle factor suffers from a serious bias
issue in prediction. It can be independently utilized as cosine logits
that mainly captures novel knowledge from current samples. On
the other hand, the norm factor, which is abandoned by existing
works [ 6,19], is helpful in keeping historical knowledge of previous
samples.
Based on this observation, it is feasible to leverage the norm
factor to balance old and new knowledge and address the bias
issue. Comparing with the angle factor, the norm factor can effec-
tively store historical knowledge, which is helpful to deal with
the bias problem. In other words, the dot-product logits, com-
posed of two factors, is suitable for replaying previous samples.
Conversely, the cosine logits, based on the angle factor, is made
available for learning current samples since it can quickly learn
novel knowledge of current samples. Different from existing stud-
ies (Figure 1(b)) that calculate logits in the same way, we try to
(Figure 1(c)) learn current samples by cosine logits and further
replay previous samples by dot-product logits. As shown in Fig-
ure 1(d), a sample 𝒉𝑝will be mistakenly classified to current class
𝑐by cosine logits that satisfies 𝑐𝑜𝑠(𝒘𝑐,𝒉𝑝)>𝑐𝑜𝑠(𝒘𝑝,𝒉𝑝). How-
ever, with the help of the norm factor, the model can correctlyclassify 𝒉𝑝to previous class 𝑝by dot-product logits that satisfies
∥𝒉𝑝∥∥𝒘𝑐∥𝑐𝑜𝑠(𝒘𝑐,𝒉𝑝)+𝑏𝑐<∥𝒉𝑝∥∥𝒘𝑝∥𝑐𝑜𝑠(𝒘𝑝,𝒉𝑝)+𝑏𝑝. Empirical
experiments demonstrate that this approach effectively solves the
bias problem and achieves better performance.
With these inspirations, we propose unbias experience replay
(UER), a heuristic bias addressing approach alleviating the phenom-
enon of CF for OCL. Its process can be mainly divided into three
components.: 1) The learning component is the basic component
that trains current samples from the data stream by cosine logits.
It aims to save novel knowledge in the angle factor. 2) To solidify
historical knowledge, the replaying component mainly trains pre-
vious samples in the memory buffer using both the norm and angle
factors, leveraging the norm factor to correct the biased prediction.
3) With the help of the norm factor, the testing component tends
to predict unbiased categorical distributions for all samples. Such
a simple yet effective method can be used for real-time prediction
(Real-time ability ), extended to the feature extractor ( Flexibility ),
and the scale of bias addressing is easily adjusted ( Adjustability ).
Our main contributions can be summarized as follows:
1)We theoretically analyze the characteristics of dot-product
logits and cosine logits, discovering their coupling is benefi-
cial. To the best of our knowledge, this work is the first to
combine these two scoring ways for the OCL.
2)We develop a novel rehearsal-based framework called UER to
mitigate the forgetting problem by addressing the bias issue
of prediction. The core is the training mechanism that learns
novel knowledge of current samples by the angle factor and
further enhances historical knowledge of previous samples
by the norm factor.
3)We conduct extensive experiments on three real-world datasets,
and the results consistently demonstrate the superiority of
UER over various state-of-the-art methods.

--- PAGE 3 ---
UER: A Heuristic Bias Addressing Approach
for Online Continual Learning MM ’23, October 29-November 3, 2023, Ottawa, ON, Canada
2 RELATED WORK
2.1 Continual Learning
Recent advances on continual learning can be grouped into three
categories. 1) Architecture-based methods divide each stage into
a set of specific parameters of the model, containing dynamical
network [ 38] and static network [ 33]. 2) Regularization-based meth-
ods take historical knowledge as the prior information of learning
novel knowledge, extending the loss function with additional regu-
larization term [ 13,21]. 3) Rehearsal-based methods set a fixed-size
memory buffer [ 9,14,30,40] or generative model [ 11] to store,
produce and replay previous samples with current ones. The kind
of method [ 7,8,29,42] that saves previous samples in the buffer is
still the most effective for knowledge anti-forgetting at present [ 5].
Different from them, our method aims at overcoming the forgetting
problem for OCL, which requires high real-time performance. It is
more difficult than general continual learning setting.
2.2 Online Continual Learning
Rehearsal-based methods based on Experience replay (ER) [ 37] are
the core solution of OCL. Some approaches [ 2,39] exploit memory
retrieval strategy to select more valuable samples from memory.
Meanwhile, some approaches [ 3,18,20] focus on saving more effec-
tive samples, belonging to the family of memory update strategy.
The others [ 6,16,17,32,44] called model update strategy improve
the training process to learn efficiently. The proposed UER is a
novel model update strategy to alleviate the phenomenon of CF by
addressing the bias of prediction. Different from existing strategies,
UER calculates logits in different ways for current samples and
previous samples. Such a training mechanism makes use of the
properties of the norm and angle factors. It can be simultaneously
used for real-time prediction without additional post-operations,
extended from the predictor to the feature extractor, and easy to
control the scale of bias addressing.
3 RETHINKING PREDICTOR
3.1 Problem Definition
OCL divides a data stream into a sequence of mini learning batches
asD={B𝑡}𝑇
𝑡=1, whereB𝑡={X𝑡×Y𝑡}contains the samples X𝑡
and corresponding labels Y𝑡. All of learned classes are denoted
asC𝑡until step𝑡. The neural network is made up of a feature
extractor 𝒉=ℎ𝚽(𝒙)and a predictor 𝑓(𝒉)=𝑾𝒉𝑇+𝒃, where 𝒉is
non-negative by Relu, 𝑾=[𝒘𝑖], and 𝒃=[𝑏𝑖]. Since the output of
predictor is dot-product logits, the categorical prediction of sample
𝒙is𝑝𝑑𝑜𝑡(𝒙)=[𝑝𝑑𝑜𝑡
𝑖], and𝑝𝑑𝑜𝑡
𝑖is the probability that a sample
belongs to class 𝑖∈C𝑡:
𝑝𝑑𝑜𝑡
𝑖=𝑒𝑥𝑝(𝒘𝑖ℎ𝚽(𝒙)𝑇+𝑏𝑖)Í
𝑗∈C𝑡𝑒𝑥𝑝(𝒘𝑗ℎ𝚽(𝒙)𝑇+𝑏𝑗). (1)
In the training process, the model can only access 𝐵𝑡and each
sample can be seen only once. Its objective function is calculated as
𝐿𝑜𝑐𝑙=𝐸(𝒙,𝑦)∼B 𝑡[𝑙(𝑝𝑑𝑜𝑡(𝒙),𝒚)], (2)
where𝑙(·)is the cross-entropy loss function.
ER [37], as a classic rehearal-based method, allocates a memory
bufferMto store part of previous samples, and selects them asBMto replay with current samples. Thus, the objective function
can be changed to
𝐿𝑒𝑟=𝐸(𝒙,𝑦)∼B 𝑡∪BM[𝑙(𝑝𝑑𝑜𝑡(𝒙),𝒚)]. (3)
LUCIR [ 19] is an improved method of ER. Generally, the dot-
product logits ( 𝒘𝒉+𝑏) of predictor can be parameterized as the
norm factor (∥𝒘∥∥𝒉∥+𝑏) and the angle factor ( 𝑐𝑜𝑠(𝒘,𝒉)) [28]. In
LUCIR, the norm factor is considered as an important part with
bias. Hence, the angle factor is used separately as cosine logits to
calculate the categorical probability prediction 𝑝𝑐𝑜𝑠(𝒙)=[𝑝𝑐𝑜𝑠
𝑖].
And its objective function is
𝐿𝑙𝑢𝑐𝑖𝑟=𝐸(𝒙,𝑦)∼B 𝑡∪BM[𝑙(𝑝𝑐𝑜𝑠(𝒙),𝒚)]. (4)
where
𝑝𝑐𝑜𝑠
𝑖=𝑒𝑥𝑝(𝑐𝑜𝑠(𝒘𝑖,ℎ𝚽(𝒙))·𝛾)Í
𝑗∈C1:𝑡𝑒𝑥𝑝(𝑐𝑜𝑠(𝒘𝑗,ℎ𝚽(𝒙))·𝛾). (5)
𝛾is a scale parameter and usually set as 10.
3.2 Analysis of Catastrophic Forgetting
There is a competition between samples of each class in the process
of gradient propagation. By chain rule, the gradient of predictor for
a training sample 𝒙of class𝑦can be expressed as
𝜕𝐿𝑒𝑟
𝜕𝒘𝑗=((𝑝𝑑𝑜𝑡
𝑦−1)𝒉, 𝑗=𝑦
𝑝𝑑𝑜𝑡
𝑗𝒉, 𝑗≠𝑦, (6)
and
𝜕𝐿𝑒𝑟
𝜕𝑏𝑗=(𝑝𝑑𝑜𝑡
𝑦−1, 𝑗=𝑦
𝑝𝑑𝑜𝑡
𝑗, 𝑗≠𝑦. (7)
With a positive learning rate 𝜂and non-negative feature 𝒉, it pro-
vides the positive change for associated parameters of class 𝑦as
𝒘𝑦=𝒘𝑦−𝜂(𝑝𝑦−1)𝒉and𝑏𝑦=𝑏𝑦−𝜂(𝑝𝑦−1), and propagates
the negative changes to the other parameters as 𝒘𝑗=𝒘𝑗−𝜂𝑝𝑗𝒉
and𝑏𝑗=𝑏𝑗−𝜂𝑝𝑗. It means that not only the values of 𝒘𝑦and𝑏𝑦
will become larger, but also the angles of 𝒘𝑦and𝒉will be smaller.
Thus, it increases the logits score of the 𝑦-th dimension as well as
decreases the logits scores of other dimensions. And the process is
the same when using cosine logits by
𝜕𝐿𝑙𝑢𝑐𝑖𝑟
𝜕𝒘𝑗=((𝑝𝑐𝑜𝑠
𝑦−1)ˆ𝒉, 𝑗=𝑦
𝑝𝑐𝑜𝑠
𝑗ˆ𝒉, 𝑗≠𝑦, (8)
where
ˆ𝒉=𝒉
∥𝒉∥−𝑐𝑜𝑠(𝒘,𝒉)𝒘
∥𝒘∥
∥𝒘∥. (9)
The biased issue is a phenomenon of CF, mainly caused by the
unbalanced competition of gradient propagation. Generally, the
number of samples belonging to previous classes in the fixed buffer
will decrease as the learning process continues. And the number
of samples belonging to current classes remains unchanged. If the
model incrementally learns by Eq. 3 or Eq. 4, the associated pa-
rameters of current classes receive more positive changes while
the others obtain more negative changes. It means the gradients
of previous classes lose their competitiveness. Besides, the logits
of current classes tend to be larger than the previous ones. Hence,
the model is more likely to classify most samples to the classes of
current samples, reducing the performance of previous classes.

--- PAGE 4 ---
MM ’23, October 29-November 3, 2023, Ottawa, ON, Canada Huiwei Lin et al.
Table 1: The analysis results of different ways to train and test on Split CIFAR100 (Buffer Size=5000). It reports the final accuracy
of all classes ( 𝐴𝑎𝑙𝑙), previous classes ( 𝐴𝑝), and current classes ( 𝐴𝑐). Meanwhile, it also reports the average norm value of previous
(∥𝑾𝑝∥) and current classes ( ∥𝑾𝑐∥), the average weight value of previous (Mean( 𝑾𝑝)) and current classes (Mean( 𝑾𝑝)), and the
average bias value of previous (Mean( 𝑏𝑝)) and current classes (Mean( 𝑏𝑐)).
Index Learning Replaying Testing 𝐴𝑎𝑙𝑙𝐴𝑝𝐴𝑐∥𝑾𝑝∥ ∥𝑾𝑐∥Mean( 𝑾𝑝) Mean( 𝑾𝑐) Mean(𝑏𝑝) Mean(𝑏𝑐)
1 (ER) dot-product dot-product dot-product 27.3 17.7 36.9 2.08 1.86 0.0044 ±0.0274 -0.0038 ±0.0221 -0.22 0.22
2 dot-product dot-product cosine 24.1 12.7 35.6 2.08 1.86 0.0044 ±0.0274 -0.0038 ±0.0221 -0.22 0.22
3 (LUCIR) cosine cosine cosine 26.9 14.9 38.9 2.00 1.64 0.0398 ±0.0235 0.0471 ±0.0146 -0.00 0.00
4 cosine cosine dot-product 28.2 28.8 27.6 2.00 1.64 0.0398 ±0.0235 0.0471 ±0.0146 -0.00 0.00
5 dot-product cosine dot-product 19.6 0.0 39.1 1.37 2.09 0.0197 ±0.0115 0.0219 ±0.0270 -1.03 1.03
6 dot-product cosine cosine 27.3 25.3 29.4 1.37 2.09 0.0197 ±0.0115 0.0219 ±0.0270 -1.03 1.03
7 cosine dot-product cosine 21.3 0.5 42.2 2.52 1.51 0.0508 ±0.0371 0.0565 ±0.0112 0.20 -0.20
8 (Ours) cosine dot-product dot-product 29.5 30.9 28.1 2.52 1.51 0.0508 ±0.0371 0.0565 ±0.0112 0.20 -0.20
Left (Previous Classes) Right (Current Classes)
Distribution of Classes10
5
051015Accumulate Changes(Left) Previous Classes of ER
(Left) Previous Classes of LUCIR
(Left) Previous Classes of Ours
(Right) Current Classes of Ours
(Right) Current Classes of LUCIR
(Right) Current Classes of ER
(a) The accumulate changes of parameters during the
learning process.
Left (Previous Classes) Right (Current Classes)
Distribution of Classes0.00.51.01.52.02.5Average Norm Value(b) The average norm value of all classes.
Left (Previous Classes) Right (Current Classes)
Distribution of Classes0.000.010.020.030.040.050.06Categorical Probability (c) The average categorical probability of testing sam-
ples.
Figure 2: The analysis results of different ways on Split CIFAR100 when the memory buffer size is 5000.
3.3 Analysis of Biased Predictor
The unbalanced gradient mainly affects the predictor from the angle
and norm factors. The norm factor accounts for intra-class variation,
and the angle factor accounts for inter-class variation [ 28]. To study
their changes in OCL, we conduct experiments on CIFAR100 with
two incremental stages and 50 classes per stage. We set two general
ways to calculate logits in the experiment: dot-product logits (both
factors) and cosine logits (only angle factor). In Table 1, we take
different ways to calculate logits, and record their performances.
Experiment results show that the characteristics of these two
factors differ from each other. On one hand, the bias issue mainly
occurs in the angle factor, which efficiently learns novel knowledge.
Comparing index 1 and 2, replacing dot-product logits with cosine
logits in the testing phase leads to worse final accuracy, particularly
for previous classes. Meanwhile, the method in index 3 performs
better for current classes but worse for previous classes compared
to the one in index 1. On the other hand, the norm factor, which has
been abandoned in existing studies [ 19], benefits previous classes.
As seen in index 3 and 4, the final performance is improved if cosine
logits is changed to dot-product logits in the testing phase.
With this observation, the two factors can be utilized in different
occasions. The angle factor is effective in adapting novel knowledge
with inter-class variation. Consequently, cosine logits that depends
on the angle factor is suitable for learning current samples. And
dot-product logits can be used for replaying previous samples since
it can leverage the norm factor to enhance historical knowledge
with intra-class variation. Motivated by these findings, we propose
a method that learns current samples by cosine logits, replays pre-
vious samples, and predicts testing samples by dot-product logits.3.4 Analysis of Proposed Method
In addition to the results in Table 1, we present more detailed
results for ER (blue), LUCIR (yellow) and our method (orange) in
Figure 2. We calculate the difference between the parameters of
predictor before and after learning current classes, taking it as
the accumulated changes of parameter as shown in Figure 2 (a).
Meanwhile, we report the average norm value of weight vector
for all classes in Figure 2 (b). Moreover, we calculate the average
categorical probability of all testing samples by the latest model,
illustrated in Figure 2 (c). Further analysis and experiment results
verify the feasibility of our proposed method.
Firstly, learning current samples using cosine logits can save
the novel knowledge into the angle factor. In index 7 and 8, the
performance on previous classes is almost zero when testing with
cosine logits. The reason behind this is that the angular similarity
is almost the determining factor for gradients in Equation (8). For
one thing, all vectors in Equation (8) are normalized and it greatly
enhances the influence of the angular similarity. For another thing,
the change of 𝒘is constrained by ˆ𝒉, as large∥𝒘∥can decrease gradi-
ents so much that the weights pass is not able to update effectively.
Moreover, the dot-product logits is associated with a value range
[−∞,+∞], while the value range of cosine logits is [−1,1]. It causes
the cosine logits to produce smaller change for previous classes and
larger change for current classes (as seen in the blue and orange
parts in Figure 2 (a)). And it also raises the norm factor of previous
classes and reduces the norm factor of current classes (as observed
in the blue and orange parts in Figure 2 (b)), which is helpful in
learning novel knowledge by the angle factor.

--- PAGE 5 ---
UER: A Heuristic Bias Addressing Approach
for Online Continual Learning MM ’23, October 29-November 3, 2023, Ottawa, ON, Canada
Secondly, replaying previous samples with dot-product logits can
enhance historical knowledge through the norm factor. Comparing
index 7 and 8, using dot-product logits in the testing process results
in the best performance for previous classes, even surpassing the
performance of current classes. Different from cosine logits, the
gradient in Equation (6) depends on both two factors. In the mean-
time, the gradient of Equation (6) is only associated with previous
samples in the buffer. Since the angle factor is easily influenced by
unbalanced gradient, this process tends to pay more attention to the
norm factor. As a result, replaying by dot-product logits not only
decreases the changes for previous classes but also increases the
changes for currents classes (as seen in the yellow and orange parts
in Figure 2 (a)). In the meantime, it raises the norm factor of previous
classes as well as reduces the norm factor of current classes (indi-
cated by the yellow and orange parts in Figure 2 (a)). It causes that
∥𝑾𝑝∥is larger than∥𝑾𝑐∥, and Mean(𝑏𝑐) is smaller than Mean( 𝑏𝑝).
Although the angle factor suffers from 𝑐𝑜𝑠(𝒘𝑐,𝒉)>𝑐𝑜𝑠(𝒘𝑝,𝒉), it
can be leveraged by ∥𝒘𝑝∥∥𝒉∥+𝑏𝑝>∥𝒘𝑐∥∥𝒉∥+𝑏𝑐, as we described
in Figure 1 (d).
As shown in Table 1, our proposed method achieves the best
performance among all combinations of different logits. Based on
the combination of different logits, our method quickly learns novel
knowledge and effectively keep historical knowledge. As shown in
Figure 2 (c), the posterior probability distribution of our method is
relatively balanced, whereas those of ER and LUCIR tend to favor
the current classes. Therefore, our motivation of learning current
samples by cosine logits while replaying previous samples by dot-
product logits is reasonable and practicable.
4 UNBIAS EXPERIENCE REPLAY
Inspired by these analyses, we propose a novel UER framework,
which is a simple but effective solution for OCL. The framework
consists of a CNN-based feature extractor and a predictor. The
key idea is to mitigate the forgetting problem of the model by
addressing the bias issue of probability distribution. The model can
quickly learn novel knowledge of current samples by the angle
factor, and effectively consolidate the historical knowledge learned
from previous samples by both two factors. The overall workflow
can be divided into three main modules: memory buffer operation,
online continual training and online continual testing.
4.1 Memory Buffer Operation
Conveniently, the memory buffer in our framework has a fixed
size, no matter how large the amount of samples is. On the one
hand, it updates the memory buffer by reservoir sampling strategy.
When the memory cannot load all samples, the reservoir sampling
algorithm can ensure that the probability of each sample being
extracted is equal. On the other hand, it randomly retrieves previous
samples from the memory buffer to participate in the learning of
current samples.
4.2 Online Continual Training
In this part, it trains the model by calculating logits in different ways
when learning current samples and replaying previous samples.
Based on the initialized model, the framework not only takes the
angle factor to save novel knowledge but also leverages the normAlgorithm 1 Unbias Experience Replay
Input: Dataset𝐷, Learning Rate 𝜆, Trade-off Parameter 𝛼
Output: Network Parameters 𝜽
1:Initialize : Memory BufferM←{}
2:for𝑡∈{1,2,...,𝑇}do
3: //𝑇𝑟𝑎𝑖𝑛𝑖𝑛𝑔𝑃ℎ𝑎𝑠𝑒
4:forB𝑡∈𝐷do
5:BM←𝑀𝑒𝑚𝑜𝑟𝑦𝑅𝑒𝑡𝑟𝑖𝑒𝑣𝑎𝑙(M) .
6:𝐿𝑐←𝐸(𝒙,𝑦)∼B 𝑡[𝑙(𝑝𝑐𝑜𝑠(𝒙),𝒚)]
7:𝐿𝑝←𝐸(𝒙,𝑦)∼BM[𝛼𝑙(𝑝𝑑𝑜𝑡(𝒙),𝒚)+(1−𝛼)𝑙(𝑝𝑐𝑜𝑠(𝒙),𝒚)]
8:𝐿←𝐿𝑐+𝐿𝑝
9: 𝜽←𝜽+𝜆∇𝜽𝐿.
10:M←𝑀𝑒𝑚𝑜𝑟𝑦𝑈𝑝𝑑𝑎𝑡𝑒(M,B𝑡).
11: end for
12: //𝑇𝑒𝑠𝑡𝑖𝑛𝑔𝑃ℎ𝑎𝑠𝑒
13:𝑚←𝑛𝑢𝑚𝑏𝑒𝑟𝑜𝑓 𝑡𝑒𝑠𝑡𝑖𝑛𝑔𝑠𝑎𝑚𝑝𝑙𝑒𝑠
14: for𝑖∈{1,2,...,𝑚}do
15: ˆ𝑦←arg max𝑐𝑝𝑑𝑜𝑡(𝒙𝑖)[𝑐],𝑐∈C𝑡
16: end for
17: return𝜃
18:end for
factor to enhance all of learned knowledge. It can address the bias
issue of prediction and further alleviate the phenomenon of CF by
optimizing the objective function as
𝐿=𝐿𝑐+𝐿𝑝, (10)
which has two components to learn training samples.
The learning component 𝐿𝑐is the general cross-entropy loss
function based on cosine logits, which is only associated with cur-
rent samples. The target of this component is to mine novel knowl-
edge of new classes, saving it into the angle factor. And the loss
value is calculated as follows
𝐿𝑐=𝐸(𝒙,𝑦)∼B 𝑡[𝑙(𝑝𝑐𝑜𝑠(𝒙),𝒚)]. (11)
The replaying component 𝐿𝑝combines different cross-entropy
loss functions. It is only related to the previous samples in the mem-
ory buffer, and it calculates categorical probability in both angle
factor and norm factor. The loss with dot-product logits leverages
norm factor to enhance historical knowledge and deal with the
bias issue. In the meantime, the loss with cosine logits can control
the strength of leveraging and prevent the model from losing its
generalization ability. In detail, the framework takes 𝑝𝑑𝑜𝑡(𝒙)as
the categorical probability of previous samples, which can bring
more postitive changes to parameters of previous classes. Besides,
it takes𝑝𝑐𝑜𝑠(𝒙)of previous samples to balance the strength of the
change. Finally, it can get the objective function as
𝐿𝑝=𝐸(𝒙,𝑦)∼BM[𝛼𝑙(𝑝𝑑𝑜𝑡(𝒙),𝒚)+(1−𝛼)𝑙(𝑝𝑐𝑜𝑠(𝒙),𝒚)],(12)
where𝛼is the hyper-parameter of leveraged scale.
4.3 Online Continual Testing
Thetesting component is similar to the replaying process of previ-
ous samples. Each testing sample 𝒙propagates forward through the

--- PAGE 6 ---
MM ’23, October 29-November 3, 2023, Ottawa, ON, Canada Huiwei Lin et al.
Table 2: Final Average Accuracy Rate (higher is better). The best scores are in boldface, and the second best scores are underlined.
Methods Split CIFAR10 Split CIFAR100 Split MiniImageNet
Buffer 100 200 500 1000 500 1000 2000 5000 500 1000 2000 5000
IID 58.1 ±2.5 17.3 ±0.8 18.2 ±1.1
IID++ [6] 64.2 ±2.1 23.5 ±0.8 20.7 ±1.0
FINE-TUNE 17.9 ±0.4 5.9±0.2 4.3±0.2
ER [37] (NeurIPS2019) 33.8 ±3.241.7 ±2.846.0 ±3.546.1 ±4.314.5 ±0.817.6 ±0.919.7 ±1.620.9 ±1.211.2 ±0.613.4 ±0.916.5 ±0.916.2 ±1.7
GSS [3] (NeurIPS2019) 23.1 ±3.928.3 ±4.636.3 ±4.144.8 ±3.614.6 ±1.316.9 ±1.419.0 ±1.820.1 ±1.110.3 ±1.513.9 ±1.014.6 ±1.115.5 ±0.9
MIR [2] (NeurIPS2019) 34.8 ±3.340.3 ±3.342.6 ±1.747.4 ±4.114.8 ±0.718.1 ±0.720.3 ±1.621.6 ±1.711.9 ±0.614.8 ±1.117.2 ±0.817.2 ±1.2
ASER [39] (AAAI2021) 33.7 ±3.731.6 ±3.442.1 ±3.042.3 ±2.913.0 ±0.916.1 ±1.117.7 ±0.718.9 ±1.010.5 ±1.113.8 ±0.916.1 ±0.918.1 ±1.1
GMED [20] (NeurIPS2021) 32.8 ±4.743.6 ±5.152.5 ±3.951.3 ±3.615.0 ±0.918.8 ±0.721.1 ±1.223.0 ±1.511.9 ±1.215.3 ±1.318.0 ±0.819.6 ±1.0
A-GEM [9] (ICLR2019) 17.5 ±1.717.4 ±2.117.9 ±0.718.2 ±1.5 5.4±0.6 5.6±0.5 5.4±0.7 4.6±1.0 5.0±1.0 4.7±1.1 5.0±2.3 4.8±0.8
LUCIR [19] (CVPR2019) 40.3 ±2.046.0 ±1.450.6 ±2.255.7 ±3.914.5 ±0.417.4 ±0.820.1 ±0.721.8 ±1.312.4 ±0.614.7 ±0.916.9 ±1.118.4 ±1.3
ER-WA [45] (CVPR2020) 36.9 ±2.942.5 ±3.448.6 ±2.745.9 ±5.318.3 ±0.721.7 ±1.223.6 ±0.924.0 ±1.815.1 ±0.717.1 ±0.918.9 ±1.418.5 ±1.5
DER++ [4] (NeurIPS2020) 40.9 ±1.445.3 ±1.752.8 ±2.253.9 ±1.915.5 ±1.017.2 ±1.119.5 ±1.220.2 ±1.311.9 ±1.014.8 ±0.716.1 ±1.315.5 ±1.3
SS-IL [1] (ICCV2021) 36.8 ±2.142.2 ±1.444.8 ±1.647.4 ±1.519.5 ±0.621.9 ±1.124.5 ±1.424.7 ±1.018.0 ±0.719.7 ±0.921.7 ±1.024.4 ±1.6
SCR [32] (CVPR2021) 35.0 ±2.945.4 ±1.055.7 ±1.659.8 ±1.613.3 ±0.616.2 ±1.318.2 ±0.819.3 ±1.012.1 ±0.714.7 ±1.916.8 ±0.618.6 ±0.5
ER-ACE [6] (ICLR2022) 44.3 ±1.549.7 ±2.454.9 ±1.457.5 ±1.919.7 ±0.823.1 ±0.824.8 ±0.927.0 ±1.218.1 ±0.520.3 ±1.324.8 ±1.126.2 ±1.0
ER-DVC [16] (CVPR2022) 36.3 ±2.645.4 ±1.450.6 ±2.952.1 ±2.516.8 ±0.819.7 ±0.722.1 ±0.924.1 ±0.813.9 ±0.615.4 ±0.717.2 ±0.819.1 ±0.9
OBC [10] (ICLR2023) 40.5 ±2.146.4 ±1.653.4 ±2.355.3 ±2.718.7 ±0.922.1 ±0.624.0 ±1.326.3 ±1.014.4 ±0.916.4 ±1.419.5 ±1.521.6 ±1.4
UER (ours) 41.5 ±1.449.2 ±1.755.8 ±1.960.3 ±1.620.9 ±0.824.6 ±0.827.0 ±0.529.6 ±1.118.4 ±0.821.9 ±1.325.1 ±1.127.5 ±1.1
↩→UER-A 41.0 ±1.547.6 ±1.451.9 ±1.955.5 ±1.818.6 ±0.621.5 ±0.724.5 ±0.626.5 ±0.915.1 ±0.817.8 ±1.420.8 ±1.322.6 ±1.3
network to obtain its class probability distribution 𝑝𝑑𝑜𝑡(𝒙). Then
we can classify it based on the following formula
ˆ𝑦=arg max
𝑐𝑝𝑑𝑜𝑡(𝒙)[𝑐],𝑐∈C𝑡. (13)
The whole training and inference procedures are summarized in
Algorithm 1. To begin with, the part of memory buffer operation
set a fixed-size memory buffer to save (line 10) and replay previous
samples (line 5). Then, the part of online continual training (line
6-9) overcomes the forgetting problem by learning current samples
and previous samples by different objective functions, respectively.
Finally, the part of online continual testing (line 13-16) predicts the
categorical probability of unknown sample by dot-product logits,
which is helpful to correctly classify the testing samples.
5 EXPERIMENTS
5.1 Experiment Setup
5.1.1 Datasets. To evaluate the effectiveness of our replay-based
framework UER, we conduct extensive experiments on three pub-
licly available datasets (CIFAR10 [ 22], CIFAR100 [ 22] and MiniIma-
geNet [ 41]).Split CIFAR10 consists of 5 learning stages and each
stage contains 2 classes. Split CIFAR100 andSplit MiniImageNet
are made up of 10 learning stages and each stage has 10 classes.
5.1.2 Evaluation Metrics. We define𝑎𝑖,𝑗(𝑗<=𝑖)as the accuracy
evaluated on the held-out test samples of the 𝑗th stage after the
network has learned the first 𝑖stages. Similar with [ 39], we can
acquire average accuracy rate as
𝐴𝑖=1
𝑖𝑖∑︁
𝑗=1𝑎𝑖,𝑗. (14)
5.1.3 Implementation Details. The basic setting of backbone model
is the same as the existing work [ 6]. In detail, we take the ReducedResNet18 (the number of filters is 20) as the feature extractor on all
datasets. All of the networks are randomly initialized rather than
pre-trained. During the training phase, the network is trained with
SGD optimizer and learning rate is set as 0.1. Meanwhile, we select
𝛼on a validation set that obtained by sampling 10% of the training
set. As for the testing phase, we select 256 as the batch size.
For all datasets, the class indexes are shuffled before division.
The model receives 10 current samples from data stream and 10
previous samples from the memory buffer at a time irrespective
of the size of the memory. Moreover, we employ a combination of
various augmentation techniques to get the augmented images.
5.2 Overall Performance
In this section, we conduct experiments for UER and various state-
of-the-art baselines on three datasets. We not only directly compare
the performance of UER with these methods, but also explore the
improvement of UER for them.
Comparison with existing baselines. Table 2 demonstrates
the final average accuracy for three datasets. All reported scores
are the average of 10 runs with a 95% confidence interval. Among
all rehearsal-based methods, the model update strategies are the
most effective, and ER-ACE method achieves the best results.
Nevertheless, our proposed UER still outperforms them, demon-
strating its effectiveness. Specifically, UER achieves the best per-
formance under 10 of the 12 experimental scenarios, where three
datasets contain four memory buffer of different sizes. It has the
most outstanding performance on Split CIFAR100 and Split Mini-
ImageNet. Meanwhile, the growth of buffer size further improves
the performance of the UER. For example, UER outperforms the
strongest baseline ER-ACE with a gap of 0.3%, 1.6%, 0.3%, 1.3% on
Split MiniImagenet when the size of memory buffer is 500, 1000,
2000 and 5000, respectively. Moreover, UER defeats the ER-ACE
with an improvement of 1.2%, 1.5%, 2.2% and 2.6% on Split CIFAR100

--- PAGE 7 ---
UER: A Heuristic Bias Addressing Approach
for Online Continual Learning MM ’23, October 29-November 3, 2023, Ottawa, ON, Canada
1 2 3 4 5
Learning Stages405060708090Average Accuracy
IID
ER
DER++
ER-WA
MIRLUCIR
ER-ACE
ER-DVC
OBC
UER
(a) Split CIFAR10
12345678910
Learning Stages20253035404550Average Accuracy
IID
ER
DER++
ER-WA
MIRLUCIR
ER-ACE
ER-DVC
OBC
UER (b) Split CIFAR100
12345678910
Learning Stages15202530354045Average Accuracy
IID
ER
DER++
ER-WA
MIRLUCIR
ER-ACE
ER-DVC
OBC
UER (c) Split MiniImageNet
Figure 3: Average accuracy rate on observed learning stages on three datasets when the memory buffer size is 1000.
1 2 3 4 5 6 7 8 9 10
Learning Stages1520253035404550Average Accuracy
ER
MIR
ASER
DER
SCR
ER-DVCwith UER
with UER
with UER
with UER
with UER
with UER
Split CIFAR100
1 2 3 4 5 6 7 8 9 10
Learning Stages15202530354045Average Accuracy
ER
MIR
ASER
DER
SCR
ER-DVCwith UER
with UER
with UER
with UER
with UER
with UER Split MiniImageNet
Figure 4: Improvement of existing methods with UER on Split CIFAR100 and Split MiniImageNet while the buffer size is 1000.
with 500, 1000, 2000 and 5000 size of memory buffer, respectively.
We note that the performance of UER is not optimal on Split CI-
FAR10 when the buffer size is smaller. It is because there are fewer
classes in this dataset, and the bias issue is not very serious. Mean-
while, the learning of norm factor is insufficient when the number
of samples is small.
We report the accuracy performance at each stage for some of
effective approaches on all datasets. As described in Figure 3, UER
not only achieves significant results in the accuracy of final stage,
but also consistently outperforms other baselines throughout the
entire learning process. Its effectiveness becomes more and more
visible as the stages increase, exhibiting its capability to overcome
CF. For instance, although the advantage of UER is not obvious
at the second stage and the third stage, its performance of anti-
forgetting is the best in the remaining stages on Split CIFAR100.
Improvement for existing baselines. We apply UER to ex-
isting baselines, and the results demonstrate that UER greatly im-
proves their performance. Figure 4 states the performance of six ER-
based baselines with and without the combination of our method
on Split CIFAR100 and Split MiniImagenet. The blue lines denote
the original accuracy of existing studies, while the red ones are the
improved accuracy of them after combining with UER. By leverag-
ing the norm factor to deal with the bias problem, the performance
of these baselines in anti-forgetting is enhanced. For instance, the
SCR that performs poorly for mini learning batches, achieves the
best performance in the whole learning process with the help of
0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0
Scale2030405060Average Accuracy
accuracy of all classes
accuracy of current classes
accuracy of previous classesFigure 5: The performance of UER on Split CIFAR100 (buffer
size=1000) with different values of 𝛼.
our method. In summary, our method not only shows significant ad-
vantages over other baseline approaches, but can also be integrated
with existing methods to greatly improve their performance.
5.3 Analysis Study
5.3.1 Real-time Ability. UER is a simple and effective method for
real-time prediction of OCL. Similar with [ 15], we use𝐶Dto com-
pare the computation of different methods. The 𝐶Dis denoted as a
relative complexity between the stream and an underlying contin-
ual learning method. For example, when current samples come, ER
can immediately learn them and then predict unknown samples,
resulting in a relative complexity of 1. Since UER and ER-ACE only

--- PAGE 8 ---
MM ’23, October 29-November 3, 2023, Ottawa, ON, Canada Huiwei Lin et al.
12345678910
Learning Stages1520253035Average Accuracy
ER-WA
SS-IL
ER-ACEOBC
UER
(a) Average of Previous Classes and Current Classes
12345678910
Learning Stages05101520253035Average Accuracy
 (b) Previous Classes
12345678910
Learning Stages1015202530354045Average Accuracy
 (c) Current Classes
Figure 6: Average accuracy rate of previous classes, current classes and their average on observed learning stages of Split
MiniImageNet when the memory buffer size is 1000.
Table 3: The computational complexity (lower is better) of
the model on Split CIFAR100 (buffer size=1000).
Metric ER ER-ACE OBC UER
𝐶D 1 1 1.5 1
Time/s 1740 1698 2542 1763
Table 4: The Final Average Accuracy Rate (higher is better)
of the model on Split CIFAR100 (buffer size=1000) when it
adds a linear layer to the feature extractor.
Method All Classes Current Previous
ER 15.6 ±2.6 50.5 11.7
ER-ACE 18.9 ±0.9 17.3 19.1
OBC 18.3 ±0.7 17.5 18.4
UER (feature extractor) 18.6 ±1.0 30.6 17.2
UER (predictor) 19.6 ±1.5 34.7 18.0
UER (both) 20.1 ±1.2 31.8 18.8
modify the loss objective of ER, their computational complexities
are equivalent to 1. However, OBC has to replay another batch of
previous samples based on ER, making it require 1.5 ×FLOPs needed
by ER. Thus, its computational complexity is 1.5, which limits the
ability of real-time prediction. The comparison of running time
between various methods also confirms this result.
5.3.2 Flexibility. Meanwhile, UER is flexible since it is not only
suitable for the linear layer of predictor, but also beneficial for
the one in feature extractor. Specifically, we add a linear layer to
the feature extractor. The coupling module is used in the feature
extractor, the predictor and all linear layers, respectively. Table 4
reports the final average accuracy rate of all classes, current classes
and previous classes for all methods. It is not difficult to find that
this module can work on each linear layer alone, and the overall
performance is better and more stable on both linear layers. Hence,
compared with other existing methods, UER is not constrained by
the classes boundary, and has a wider range of applications.
5.3.3 Adjustability. By using dot-product logits, UER leverages the
norm factor to balance the performance of current and previous
classes. And the effect is mainly affected by the leveraged scale
hyper-parameter 𝛼. As shown in Table 2, the ablation version of
UER is denoted as UER-A. Due to the lack of scale adjustment,
UER-A performs worse than UER.To explore the impact of 𝛼, we conduct experiments on Split
CIFAR100 for different 𝛼. In Figure 5, we report the accuracy of
all classes for UER, which can be divided into the accuracy of pre-
vious classes and the accuracy of current classes. As 𝛼increases,
the proportion of dot-product logits raises. Its performance (red
line) will be improved at the beginning, and it will not enhance
or even start to decline when 𝛼becomes large. By comparing the
performance of current and previous classes, we find that the accu-
racy of current classes (blue line) will decline with the increase of
𝛼. While the accuracy rate of previous classes (green line) will rise
at the beginning and then decline later. Emprically, UER can play
its greatest role for the model when the value of 𝛼is around 0.5.
Hence, UER is more adjustable than other methods. In Figure 6,
we demonstrate the performance of several bias addressing methods
on previous classes, current classes and their average. With the
help of the scale, UER not only ensures the generalization ability
to learn current classes, but also improves the memory ability to
capture previous classes.
6 CONCLUSION
In this paper, we develop a heuristic OCL method called UER to
alleviate the phenomenon of CF by tackling the bias problem of
logits. By examining the change of predictor, we find that the im-
portant factors of dot-product logits include a norm factor and
an angle factor. The former is beneficial to previous classes while
the latter is fond of current classes. As a result, the cosine logits
depends on the angle factor is suitable to adapt novel knowledge.
And the dot-product logits made up of norm and angle factors is
good at storing historical knowledge. Hence, the proposed UER
leverages the norm factor to balance the categorical prediction of
the predictor. It learns current samples only by the angle factor
and further replays previous samples by both the norm and angle
factors. Extensive experiments on three datasets demonstrate the
superiority of UER over various state-of-the-art baselines.
ACKNOWLEDGMENTS
This work was supported in part by National Nature Science Foun-
dation of China (No. 61972111, No. 62202124 and No. 62272130),
Nature Science Program of Shenzhen (No. JCYJ20210324120208022
and No. JCYJ20200109113014456) and Shenzhen Science and Tech-
nology Program (No. KCXFZ20211020163403005).

--- PAGE 9 ---
UER: A Heuristic Bias Addressing Approach
for Online Continual Learning MM ’23, October 29-November 3, 2023, Ottawa, ON, Canada
REFERENCES
[1]Hongjoon Ahn, Jihwan Kwak, Subin Lim, Hyeonsu Bang, Hyojun Kim, and Taesup
Moon. 2021. Ss-il: Separated softmax for incremental learning. In Proceedings of
the IEEE/CVF International Conference on Computer Vision . 844–853.
[2]Rahaf Aljundi, Eugene Belilovsky, Tinne Tuytelaars, Laurent Charlin, Massimo
Caccia, Min Lin, and Lucas Page-Caccia. 2019. Online Continual Learning with
Maximal Interfered Retrieval. Advances in Neural Information Processing Systems
32 (2019), 11849–11860.
[3]Rahaf Aljundi, Min Lin, Baptiste Goujaud, and Yoshua Bengio. 2019. Gradi-
ent based sample selection for online continual learning. Advances in neural
information processing systems 32 (2019).
[4]Pietro Buzzega, Matteo Boschini, Angelo Porrello, Davide Abati, and Simone
Calderara. 2020. Dark experience for general continual learning: a strong, simple
baseline. Advances in neural information processing systems 33 (2020), 15920–
15930.
[5]Pietro Buzzega, Matteo Boschini, Angelo Porrello, and Simone Calderara. 2021.
Rethinking experience replay: a bag of tricks for continual learning. In 2020 25th
International Conference on Pattern Recognition (ICPR) . IEEE, 2180–2187.
[6]Lucas Caccia, Rahaf Aljundi, Nader Asadi, Tinne Tuytelaars, Joelle Pineau, and
Eugene Belilovsky. 2021. New Insights on Reducing Abrupt Representation
Change in Online Continual Learning. In International Conference on Learning
Representations .
[7]Hyuntak Cha, Jaeho Lee, and Jinwoo Shin. 2021. Co2l: Contrastive continual
learning. In Proceedings of the IEEE/CVF International Conference on Computer
Vision . 9516–9525.
[8]Arslan Chaudhry, Albert Gordo, Puneet Dokania, Philip Torr, and David Lopez-
Paz. 2021. Using Hindsight to Anchor Past Knowledge in Continual Learning. In
Proceedings of the AAAI Conference on Artificial Intelligence , Vol. 35. 6993–7001.
[9]Arslan Chaudhry, Marc’Aurelio Ranzato, Marcus Rohrbach, and Mohamed Elho-
seiny. 2018. Efficient Lifelong Learning with A-GEM. In International Conference
on Learning Representations .
[10] Aristotelis Chrysakis and Marie-Francine Moens. [n. d.]. Online Bias Correction
for Task-Free Continual Learning. In The Eleventh International Conference on
Learning Representations .
[11] Bo Cui, Guyue Hu, and Shan Yu. 2021. DeepCollaboration: Collaborative Gener-
ative and Discriminative Models for Class Incremental Learning. In Proceedings
of the AAAI Conference on Artificial Intelligence , Vol. 35. 1175–1183.
[12] Matthias Delange, Rahaf Aljundi, Marc Masana, Sarah Parisot, Xu Jia, Ales
Leonardis, Greg Slabaugh, and Tinne Tuytelaars. 2021. A continual learning
survey: Defying forgetting in classification tasks. IEEE Transactions on Pattern
Analysis and Machine Intelligence (2021).
[13] Prithviraj Dhar, Rajat Vikram Singh, Kuan-Chuan Peng, Ziyan Wu, and Rama
Chellappa. 2019. Learning without memorizing. In Proceedings of the IEEE/CVF
Conference on Computer Vision and Pattern Recognition . 5138–5146.
[14] Mehrdad Farajtabar, Navid Azizan, Alex Mott, and Ang Li. 2020. Orthogonal
gradient descent for continual learning. In International Conference on Artificial
Intelligence and Statistics . PMLR, 3762–3773.
[15] Yasir Ghunaim, Adel Bibi, Kumail Alhamoud, Motasem Alfarra, Hasan Abed
Al Kader Hammoud, Ameya Prabhu, Philip HS Torr, and Bernard Ghanem. 2023.
Real-time evaluation in online continual learning: A new paradigm. arXiv preprint
arXiv:2302.01047 (2023).
[16] Yanan Gu, Xu Yang, Kun Wei, and Cheng Deng. 2022. Not Just Selection, but
Exploration: Online Class-Incremental Continual Learning via Dual View Consis-
tency. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern
Recognition . 7442–7451.
[17] Yiduo Guo, Bing Liu, and Dongyan Zhao. 2022. Online Continual Learning
through Mutual Information Maximization. In International Conference on Ma-
chine Learning . PMLR, 8109–8126.
[18] Jiangpeng He and Fengqing Zhu. 2021. Online continual learning for visual
food classification. In Proceedings of the IEEE/CVF International Conference on
Computer Vision . 2337–2346.
[19] Saihui Hou, Xinyu Pan, Chen Change Loy, Zilei Wang, and Dahua Lin. 2019.
Learning a unified classifier incrementally via rebalancing. In Proceedings of the
IEEE/CVF Conference on Computer Vision and Pattern Recognition . 831–839.
[20] Xisen Jin, Arka Sadhu, Junyi Du, and Xiang Ren. 2021. Gradient-based Editing of
Memory Examples for Online Task-free Continual Learning. Advances in Neural
Information Processing Systems 34 (2021).
[21] James Kirkpatrick, Razvan Pascanu, Neil Rabinowitz, Joel Veness, Guillaume
Desjardins, Andrei A Rusu, Kieran Milan, John Quan, Tiago Ramalho, Agnieszka
Grabska-Barwinska, et al .2017. Overcoming catastrophic forgetting in neural
networks. Proceedings of the national academy of sciences 114, 13 (2017), 3521–
3526.[22] Alex Krizhevsky, Geoffrey Hinton, et al .2009. Learning multiple layers of features
from tiny images. (2009).
[23] Huiwei Lin, Shanshan Feng, Xutao Li, Wentao Li, and Yunming Ye. 2022. Anchor
assisted experience replay for online class-incremental learning. IEEE Transac-
tions on Circuits and Systems for Video Technology (2022).
[24] Huiwei Lin, Baoquan Zhang, Shanshan Feng, Xutao Li, and Yunming Ye. 2023.
PCR: Proxy-based Contrastive Replay for Online Class-Incremental Continual
Learning. In Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition . 24246–24255.
[25] Bing Liu and Sahisnu Mazumder. 2021. Lifelong and continual learning dialogue
systems: learning during conversation. In Proceedings of the AAAI Conference on
Artificial Intelligence , Vol. 35. 15058–15063.
[26] Bing Liu, Sahisnu Mazumder, Eric Robertson, and Scott Grigsby. 2022. AI Au-
tonomy: Self-Initiation, Adaptation and Continual Learning. arXiv preprint
arXiv:2203.08994 (2022).
[27] Bing Liu and Chuhe Mei. 2020. Lifelong knowledge learning in rule-based
dialogue systems. arXiv preprint arXiv:2011.09811 (2020).
[28] Weiyang Liu, Zhen Liu, Zhiding Yu, Bo Dai, Rongmei Lin, Yisen Wang, James M
Rehg, and Le Song. 2018. Decoupled networks. In Proceedings of the IEEE Confer-
ence on Computer Vision and Pattern Recognition . 2771–2779.
[29] Yaoyao Liu, Bernt Schiele, and Qianru Sun. 2021. RMM: Reinforced memory
management for class-incremental learning. Advances in Neural Information
Processing Systems 34 (2021).
[30] David Lopez-Paz and Marc’Aurelio Ranzato. 2017. Gradient episodic memory for
continual learning. Advances in neural information processing systems 30 (2017).
[31] Zheda Mai, Ruiwen Li, Jihwan Jeong, David Quispe, Hyunwoo Kim, and Scott
Sanner. 2022. Online continual learning in image classification: An empirical
survey. Neurocomputing 469 (2022), 28–51.
[32] Zheda Mai, Ruiwen Li, Hyunwoo Kim, and Scott Sanner. 2021. Supervised
Contrastive Replay: Revisiting the Nearest Class Mean Classifier in Online Class-
Incremental Continual Learning. In Proceedings of the IEEE/CVF Conference on
Computer Vision and Pattern Recognition . 3589–3599.
[33] Zichen Miao, Ze Wang, Wei Chen, and Qiang Qiu. 2021. Continual Learning with
Filter Atom Swapping. In International Conference on Learning Representations .
[34] Liqiang Nie, Leigang Qu, Dai Meng, Min Zhang, Qi Tian, and Alberto Del Bimbo.
2022. Search-oriented Micro-video Captioning. In Proceedings of the 30th ACM
International Conference on Multimedia . 3234–3243.
[35] Liqiang Nie, Wenjie Wang, Richang Hong, Meng Wang, and Qi Tian. 2019. Multi-
modal dialog system: Generating responses via adaptive decoders. In Proceedings
of the 27th ACM International Conference on Multimedia . 1098–1106.
[36] Liqiang Nie, Xiang Wang, Jianglong Zhang, Xiangnan He, Hanwang Zhang,
Richang Hong, and Qi Tian. 2017. Enhancing micro-video understanding by har-
nessing external sounds. In Proceedings of the 25th ACM international conference
on Multimedia . 1192–1200.
[37] David Rolnick, Arun Ahuja, Jonathan Schwarz, Timothy Lillicrap, and Gregory
Wayne. 2019. Experience replay for continual learning. Advances in Neural
Information Processing Systems 32 (2019).
[38] Andrei A Rusu, Neil C Rabinowitz, Guillaume Desjardins, Hubert Soyer, James
Kirkpatrick, Koray Kavukcuoglu, Razvan Pascanu, and Raia Hadsell. 2016. Pro-
gressive neural networks. arXiv preprint arXiv:1606.04671 (2016).
[39] Dongsub Shim, Zheda Mai, Jihwan Jeong, Scott Sanner, Hyunwoo Kim, and
Jongseong Jang. 2021. Online class-incremental continual learning with adversar-
ial shapley value. In Proceedings of the AAAI Conference on Artificial Intelligence ,
Vol. 35. 9630–9638.
[40] Shixiang Tang, Dapeng Chen, Jinguo Zhu, Shijie Yu, and Wanli Ouyang. 2021.
Layerwise optimization by gradient decomposition for continual learning. In
Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition .
9634–9643.
[41] Oriol Vinyals, Charles Blundell, Timothy Lillicrap, Daan Wierstra, et al .2016.
Matching networks for one shot learning. Advances in neural information pro-
cessing systems 29 (2016), 3630–3638.
[42] Liyuan Wang, Xingxing Zhang, Kuo Yang, Longhui Yu, Chongxuan Li, HONG
Lanqing, Shifeng Zhang, Zhenguo Li, Yi Zhong, and Jun Zhu. 2021. Memory Re-
play with Data Compression for Continual Learning. In International Conference
on Learning Representations .
[43] Yue Wu, Yinpeng Chen, Lijuan Wang, Yuancheng Ye, Zicheng Liu, Yandong
Guo, and Yun Fu. 2019. Large scale incremental learning. In Proceedings of the
IEEE/CVF Conference on Computer Vision and Pattern Recognition . 374–382.
[44] Haiyan Yin, Ping Li, et al .2021. Mitigating Forgetting in Online Continual
Learning with Neuron Calibration. Advances in Neural Information Processing
Systems 34 (2021).
[45] Bowen Zhao, Xi Xiao, Guojun Gan, Bin Zhang, and Shu-Tao Xia. 2020. Maintain-
ing discrimination and fairness in class incremental learning. In Proceedings of the
IEEE/CVF Conference on Computer Vision and Pattern Recognition . 13208–13217.

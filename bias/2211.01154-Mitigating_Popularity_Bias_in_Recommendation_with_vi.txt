# Giảm thiểu thiên lệch phổ biến trong hệ thống gợi ý với các tương tác không cân bằng: Một góc nhìn gradient

Weijieying Ren*], Lei Wang*[, Kunpeng Liu#, Ruocheng Guox, LIM Ee Peng[land Yanjie Fu]l
]Khoa Khoa học Máy tính, Đại học Central Florida, Hoa Kỳ
[Khoa Khoa học Máy tính, Đại học Quản lý Singapore, Singapore
#Khoa Khoa học Máy tính, Đại học Bang Portland, Hoa Kỳ
#Phòng thí nghiệm AI ByteDance, Anh
wjyren@knights.ucf.edu, lei.wang.2019@phdcs.smu.edu.sg, kunpeng@pdx.edu
ruocheng.guo@bytedance.com, eplim@smu.edu.sg, yanjie.fu@ucf.edu

Tóm tắt — Các hệ thống gợi ý học từ các tương tác người dùng-mục lịch sử để xác định các mục ưa thích cho người dùng mục tiêu. Những tương tác được quan sát này thường không cân bằng theo phân phối đuôi dài. Dữ liệu đuôi dài như vậy dẫn đến thiên lệch phổ biến để gợi ý các mục phổ biến nhưng không được cá nhân hóa cho người dùng. Chúng tôi trình bày một góc nhìn gradient để hiểu hai tác động tiêu cực của thiên lệch phổ biến trong việc tối ưu hóa mô hình gợi ý: (i) hướng gradient của các embedding mục phổ biến gần hơn với hướng của các tương tác tích cực, và (ii) độ lớn của gradient tích cực cho các mục phổ biến lớn hơn nhiều so với các mục không phổ biến. Để giải quyết những vấn đề này, chúng tôi đề xuất một khung làm việc đơn giản nhưng hiệu quả để giảm thiểu thiên lệch phổ biến từ góc nhìn gradient. Cụ thể, chúng tôi đầu tiên chuẩn hóa mỗi embedding người dùng và ghi lại các gradient tích lũy của người dùng và mục thông qua các biện pháp thiên lệch phổ biến trong quá trình huấn luyện mô hình. Để giải quyết các vấn đề thiên lệch phổ biến, chúng tôi phát triển một phương pháp điều chỉnh embedding dựa trên gradient được sử dụng trong việc kiểm tra mô hình. Chiến lược này là tổng quát, không phụ thuộc vào mô hình và có thể được tích hợp một cách liền mạch vào hầu hết các hệ thống gợi ý hiện có. Các thử nghiệm rộng rãi của chúng tôi trên hai mô hình gợi ý cổ điển và bốn bộ dữ liệu thực tế chứng minh hiệu quả của phương pháp chúng tôi so với các baseline loại bỏ thiên lệch tiên tiến nhất.

Từ khóa chỉ mục — Hệ thống gợi ý, Thiên lệch phổ biến.

I. GIỚI THIỆU

Các hệ thống gợi ý (RS) cung cấp cho người dùng các mục mới được đề xuất bằng cách khai thác sở thích người dùng từ các tương tác người dùng-mục lịch sử [1]–[4]. Mỗi tương tác người dùng-mục được quan sát đại diện cho một phản hồi ngầm (ví dụ: mua hàng, clicks, duyệt) cho thấy sở thích của người dùng đối với mục đó. Chúng tôi gọi đây là một tương tác tích cực. Để huấn luyện một mô hình RS, chúng ta có thể chọn đều một số mục không có tương tác với người dùng làm mục tiêu cực. Một mô hình RS dựa trên dữ liệu phản hồi ngầm như vậy được thiết kế để dự đoán các mục tích cực với điểm dự đoán cao hơn các mục tiêu cực. Nói chung, mỗi mục sẽ nhận được một gradient tích cực nếu nó có tương tác được quan sát với một người dùng và có được một gradient tiêu cực nếu nó được chọn làm mẫu tiêu cực.

Tuy nhiên, các nghiên cứu gần đây [1], [4], [5] phát hiện rằng trong hầu hết các tình huống ứng dụng thực tế, các tương tác người dùng-mục trong các hệ thống gợi ý rất mất cân bằng theo phân phối đuôi dài [6], [7]. Chỉ có một số lượng nhỏ mục là phổ biến vì chúng thường xuyên tương tác với người dùng và do đó có nhiều khả năng được người dùng ưa thích hơn. Khi dữ liệu đuôi dài như vậy được sử dụng để huấn luyện một mô hình RS, thiên lệch phổ biến xuất hiện trong mô hình được huấn luyện, tức là các mục phổ biến được gợi ý quá mức cho tất cả người dùng, trong khi một số mục ít phổ biến hơn có thể phù hợp hơn với một số người dùng cụ thể. Thiên lệch phổ biến có thể dẫn đến khả năng hiển thị thấp của các mục không phổ biến, giảm tính đa dạng của thị trường và làm hại trải nghiệm người tiêu dùng. Do đó, việc giảm thiểu thiên lệch phổ biến được yêu cầu rất cao.

Để đối phó với thiên lệch phổ biến, một hướng nổi bật là thiết kế một loss có tái trọng số, ví dụ như điểm xu hướng nghịch đảo (IPS), để cân bằng phân phối mục tổng thể [8], [9]. Một lựa chọn khác là tiến hành chuyển giao kiến thức [6] với giả định rằng kiến thức được đại diện trong các mục phổ biến sẽ có lợi cho việc khai thác sở thích người dùng trong các mục ít phổ biến hơn. Gần đây, các mô hình tinh vi hơn được thiết kế để bảo tồn sở thích cụ thể của người dùng thông qua việc sử dụng thông tin phụ [10], mô hình autoencoder [11] và để tách rời sở thích người dùng theo các heuristic tiên nghiệm được định nghĩa trước [12]. Tuy nhiên, các công trình trước đây hoặc yêu cầu thiết kế mô hình phức tạp [11], làm suy giảm biểu diễn embedding hoặc dựa vào giả định mạnh [12], thiếu khả năng tổng quát hóa. Khác với các chiến lược nói trên, chúng tôi tiếp cận thiên lệch phổ biến bằng cách phân tích biến dạng gradient trong dữ liệu đuôi dài, được quy cho sự kết hợp của các gradient được tạo ra bởi các mục tích cực và tiêu cực.

Chúng tôi phát hiện rằng (i) hướng gradient tổng thể của các embedding mục phổ biến có xu hướng gần hơn với gradient của các tương tác tích cực, và (ii) độ lớn của gradient tích cực cho các mục phổ biến lớn hơn nhiều so với các mục không phổ biến.

Để minh họa các thách thức trên, chúng tôi hiển thị các biến liên quan trong quá trình huấn luyện của bộ dữ liệu Movielens-10M trong Hình 1. Cụ thể, độ tương tự cosine giữa gradient tích cực tích lũy (được cho bởi ∑ᵀₜ₌₁∇ᵢLₜ(u⁺;i⁺), trong đó t là bước lặp) và gradient tổng thể của mỗi mục được hiển thị trong Hình 1(a) cho các mục được sắp xếp theo thứ tự phổ biến nghịch đảo. Chúng tôi cũng hiển thị độ tương tự cosine giữa gradient tiêu cực và gradient tổng thể của các mục. Độ tương tự cao (tức là gần 1) giữa gradient tổng thể và gradient tích cực tích lũy của các mục phổ biến cho thấy rằng gradient tổng thể của mỗi mục phổ biến bị dịch chuyển về phía hướng của các tương tác tích cực của nó. Điều ngược lại có thể được quan sát cho các mục không phổ biến. Hình 1(b) hiển thị chuẩn của gradient tích cực và tiêu cực tích lũy cho các mục được sắp xếp theo thứ tự phổ biến giảm dần. Trong hình này, các mục phổ biến thể hiện các giá trị chuẩn gradient tích cực tích lũy lớn hơn các giá trị chuẩn gradient tiêu cực tích lũy của chúng. Nói cách khác, các gradient tích lũy của các mục phổ biến làm tăng chuẩn của các vector embedding mục tương ứng và dẫn đến xu hướng xếp hạng cao trong kết quả gợi ý.

Để phân tích sâu hơn các lý do cơ bản của những phát hiện thực nghiệm trên, chúng tôi xem xét quá trình tối ưu hóa của loss xếp hạng theo cặp cổ điển được sử dụng trong RS ngầm, tức là loss BPR [13]. Rõ ràng là các vector embedding mục (hoặc người dùng) chủ yếu được xác định bởi các gradient tích lũy của chúng. Xem xét một mục phổ biến i được minh họa trong Hình 2, các vector AC và AB đại diện cho gradient tích cực và tiêu cực tích lũy của nó tương ứng. Gradient tổng thể AD bị dịch chuyển về phía AC do độ lớn lớn của nó, làm cho embedding mục đã học chỉ tạo thuận lợi cho việc học tương tác tích cực (ngược lại cho các mục không phổ biến). Các gradient tích lũy được tính bằng cách tổng các giá trị gradient trên tất cả các lần lặp khi tối ưu hóa hàm mục tiêu Lₜ(u;i). Do đó, chúng tôi xác định ba yếu tố có thể giải thích lý do tồn tại thiên lệch phổ biến trong RS ngầm: 1) độ phổ biến của mục, 2) hoạt động của người dùng, và 3) sự tuân thủ của người dùng.

Phương pháp của chúng tôi. Được thúc đẩy bởi việc giảm thiểu thiên lệch phổ biến, chúng tôi phát hiện rằng phân tích kết hợp cho các gradient được tạo ra bởi các tương tác tích cực và tiêu cực là giải pháp chính. Do đó, chúng tôi đề xuất khái niệm điều chỉnh embedding người dùng/mục. Trong giai đoạn huấn luyện, chúng tôi chỉ chuẩn hóa embedding người dùng để giảm thiểu ảnh hưởng của người dùng có hoạt động cao và ghi lại các gradient tích lũy của người dùng và mục. Trong giai đoạn kiểm tra, chúng tôi đề xuất giảm thiểu thiên lệch bằng cách điều chỉnh các embedding người dùng và mục đã học để giảm thiểu ảnh hưởng bởi độ phổ biến của mục và sự tuân thủ của người dùng. Những đóng góp chính của chúng tôi như sau:

Một góc nhìn gradient mới để hiểu cơ chế thiên lệch phổ biến. Các phương pháp cổ điển tập trung vào việc hiểu thiên lệch phổ biến từ việc cân bằng phân phối dữ liệu tổng thể, ví dụ: các nhóm phổ biến và không phổ biến. Trong bài báo này, chúng tôi cung cấp những phát hiện mới rằng 1) hướng gradient tổng thể của các mục phổ biến (không phổ biến) bị dịch chuyển để gần hơn với gradient trên các tương tác tích cực (tiêu cực); 2) độ lớn gradient tích cực của các mục phổ biến thường lớn hơn nhiều so với các mục không phổ biến. Chúng tôi phân tích hiện tượng như vậy từ góc nhìn gradient và cung cấp một cái nhìn mới về việc cân bằng các gradient tích cực và tiêu cực cho cùng một mục.

Phương pháp điều chỉnh embedding dựa trên gradient. Được thúc đẩy bởi những phát hiện mới, chúng tôi xác định ba yếu tố cần thiết, cụ thể là độ phổ biến của mục, sự tuân thủ của người dùng và tính tích cực của người dùng và phân tích cách các embedding người dùng và mục liên quan đến chúng trong các bước tối ưu hóa. Chúng tôi phát triển một phương pháp điều chỉnh embedding hậu kiểm đơn giản nhưng mới lạ. Khung làm việc này có thể giải thích và diễn giải được.

Các thử nghiệm rộng rãi với các bộ dữ liệu thực tế. Chúng tôi tiến hành các thử nghiệm rộng rãi để đánh giá hiệu quả của các phương pháp được đề xuất về độ chính xác tổng thể, khả năng tổng quát hóa và hiệu quả so với các baseline tiên tiến nhất. Chúng tôi cũng tiến hành các nghiên cứu ablation để đánh giá các thành phần của các phương pháp được đề xuất.

II. SỐ LIỆU CHUẨN BỊ

Phát biểu vấn đề. Giả sử chúng ta có một tập người dùng U, một tập mục I và một ma trận tương tác người dùng-mục Y ∈ {0,1}|U|×|I|, trong đó Yᵤᵢ cho biết liệu u ∈ U có thực hiện tương tác (ví dụ: áp dụng hoặc mua) với mục i ∈ I hay không. Mục tiêu của một hệ thống gợi ý là học một hàm chấm điểm r(u,i) để gợi ý một danh sách k mục cho người dùng u:

ŷᵤᵢ = r(u,i) = PᵤᵀQᵢ                                    (1)

trong đó ŷᵤᵢ là điểm dự đoán, Pᵤ là vector biểu diễn người dùng cho người dùng u, và Qᵢ là vector biểu diễn mục cho mục i. Pᵤ (Qᵢ) được tính từ bộ mã hóa người dùng f(u|U) (bộ mã hóa mục f(i|I)). Lưu ý rằng bộ mã hóa người dùng hoặc mục là bất khả tri đối với mô hình, có thể là ma trận embedding [14], mạng neural đồ thị [15], hoặc các mô hình khác. Để đơn giản, chúng tôi gọi Pᵤ (Qᵢ) là embedding người dùng (embedding mục) trong phần còn lại của bài báo.

Tại sao độ lớn embedding lại quan trọng trong các vấn đề RS? Trong giai đoạn kiểm tra, hệ thống gợi ý trả về xếp hạng cá nhân hóa của các mục Rᵤ cho người dùng u:

Rᵤ = {(i, rank(ŷᵤᵢ))}ᵢ∈I
   = {(i, rank(PᵤᵀQᵢ))}ᵢ∈I
   = {(i, rank(‖Qᵢ‖cos(Pᵤ,Qᵢ)))}ᵢ∈I                    (2)

trong đó rank là một hàm xếp hạng dựa trên một tập các giá trị hàm chấm điểm giữa u và tất cả các mục i ∈ I. Trong Phương trình 2, chúng tôi bỏ qua ‖Pᵤ‖ vì Rᵤ liên quan đến cùng một người dùng u. Nói cách khác, kết quả xếp hạng cá nhân hóa trong giai đoạn kiểm tra chỉ phụ thuộc vào độ lớn của embedding mục Qᵢ và độ tương tự cosine của nó với embedding người dùng Pᵤ.

Các độ lớn embedding được tạo ra như thế nào trong RS? Trong giai đoạn huấn luyện, chúng ta thường áp dụng một loss xếp hạng theo cặp, ví dụ như loss Bayesian Personalized Ranking (BPR) [13] và loss Binary cross entropy (BCE) [16]. Không mất tính tổng quát, chúng tôi xem xét lại các hàm loss BPR cho hệ thống gợi ý với phản hồi ngầm. Trong các tình huống thực tế, chỉ có phản hồi ngầm tích cực (ví dụ: clicks và mua hàng) được quan sát. Trong RS ngầm, chúng ta giả định rằng sở thích của người dùng u đối với một mục i với tương tác (u,i) được quan sát được xếp hạng cao hơn tương tác (u,j) không được quan sát như một mẫu tiêu cực, trong đó mục j được chọn đều từ tập mục I mà không có tương tác được quan sát với u. Không mất tính tổng quát, chúng tôi biểu diễn loss BPR ở đây để tối đa hóa khả năng quan sát các mối quan hệ xếp hạng theo cặp như vậy:

L_BPR = Σ_{(u,i,j)∈Ds} -log(σ(ŷᵤᵢ - ŷᵤⱼ)) + λ‖Θ‖²        (3)

trong đó Ds là một tập các bộ ba (u,i,j) với (u,i) và (u,j) lần lượt là các mẫu tích cực và tiêu cực. Θ là các tham số mô hình và σ(x) = 1/(1+exp(-x)) là hàm sigmoid. Gradient của loss BPR đối với các tham số mô hình Θ (ví dụ: embedding người dùng/mục) có thể được viết như:

∂L_BPR/∂Θ = Σ_{(u,i,j)∈DS} ∂(-log(σ(ŷᵤᵢ - ŷᵤⱼ)))/∂Θ + λ∂‖Θ‖²/∂Θ

∝ e^(-(ŷᵤᵢ - ŷᵤⱼ))/(1 + e^(-(ŷᵤᵢ - ŷᵤⱼ))) ∂(ŷᵤᵢ - ŷᵤⱼ)/∂Θ    (4)

Cụ thể hơn, các gradient để cập nhật một mô hình phân tích ma trận là:

∂(ŷᵤᵢ - ŷᵤⱼ)/∂Θ = {
    (Qᵢ - Qⱼ)  nếu Θ = Pᵤ
    Pᵤ          nếu Θ = Qᵢ  
    -Pᵤ         nếu Θ = Qⱼ
    0           ngược lại
}                                                          (5)

Phân tích trường hợp thất bại. Đối với tối ưu hóa loss BPR, chúng tôi nhận thấy rằng đối với mỗi cặp người dùng-mục (u,i) với tương tác tích cực, mô hình sẽ lấy mẫu ngẫu nhiên một cặp tiêu cực (u,j). Đối với một mục phổ biến i phù hợp với sở thích chính thống, nó được cập nhật thường xuyên bằng một gradient tích cực Pᵤ. Nó chỉ được cập nhật bằng một gradient tiêu cực -Pᵤ khi nó phục vụ như một mẫu tiêu cực. Nói cách khác, mục i sẽ được cập nhật với các gradient tích cực thường xuyên hơn các gradient tiêu cực trong quá trình tối ưu hóa.

III. ĐỘNG LỰC: THIÊN LỆC PHỔ BIẾN TỪ GÓC NHÌN GRADIENT

Trong phần này, chúng tôi thảo luận về thiên lệch phổ biến từ góc nhìn cập nhật gradient, tức là cách độ phổ biến của mục, hoạt động của người dùng và sự tuân thủ của người dùng ảnh hưởng đến độ lớn gradient và dịch chuyển gradient tổng thể theo hướng tương tác tích cực cho các mục phổ biến.

Dựa trên Phương trình 5, chúng ta có thể suy ra rằng các embedding người dùng (mục) ảnh hưởng đến độ lớn và hướng của các embedding mục (người dùng). Để đơn giản, chúng tôi định nghĩa việc cập nhật vector tiềm ẩn của các mục tích cực Q^t_i, các mục tiêu cực Q^t_j và người dùng P^t_u trong bước lặp thứ t cho một ví dụ dữ liệu (u,i,j) với tốc độ học lr như sau:

Q^t_i = Q^{t-1}_i + lr·P^{t-1}_u;
Q^t_j = Q^{t-1}_j - lr·P^{t-1}_u;  
P^t_u = P^{t-1}_u + lr·(Q^{t-1}_i - Q^{t-1}_j)           (6)

Để hỗ trợ phân tích thiên lệch phổ biến từ góc nhìn gradient, chúng tôi lấy Movielens-10M làm ví dụ, và thống kê được hiển thị trong Bảng I. Chúng tôi sắp xếp các mục theo số lượng tương tác của chúng theo thứ tự giảm dần và chọn các mục đã sắp xếp cho đến khi số lượng tương tác của các mục đã chọn lên đến 80% tổng tương tác trong tập huấn luyện (thực tế, ít hơn 20% mục chiếm hơn 80% tương tác trong nhiều tình huống thực tế). Chúng tôi giả định các mục đã chọn này là các mục phổ biến và các mục còn lại là các mục không phổ biến. Tương tự, chúng ta có thể có người dùng tích cực và người dùng không tích cực.

Ảnh hưởng của hoạt động người dùng lên phía mục. Gọi vector tiềm ẩn của mục i trong lần lặp thứ 0 là Q^0_i. Sau đó chúng ta có thể thu được dạng tương đương của Q^t_i là:

Q^t_i = Q^0_i + lr(∑_{(u,i)∈Y^{+,t-1}_i} P_u - ∑_{(u',i)∈Y^{-,t-1}_i} P_{u'})    (7)

trong đó Y^{+,t-1}_i và Y^{-,t-1}_i biểu thị tập các cặp người dùng-mục trong đó mục i hoạt động như các mục tích cực và tiêu cực trong tập huấn luyện trước bước lặp t, tương ứng. Không mất tính tổng quát, chúng tôi đơn giản hóa tất cả các phương trình sau bằng cách bỏ qua các bước lặp t và t-1. Chúng tôi để Δ_i đại diện cho sự gia tăng của Q^t_i:

Δ_i = ∑_{(u,i)∈Y^+_i} P_u - ∑_{(u',i)∈Y^-_i} P_{u'}                            (8)

Vì người dùng trong cả Y^+_i và Y^-_i bao gồm người dùng tích cực và người dùng không tích cực, phương trình 8 có thể được mở rộng thành:

Δ_i = ∑_{(u,i)∈Y^{+}_{i,act}} P_u + ∑_{(u,i)∈Y^{+}_{i,inact}} P_u
     - ∑_{(u',i)∈Y^{-}_{i,act}} P_{u'} - ∑_{(u',i)∈Y^{-}_{i,inact}} P_{u'}      (9)

trong đó Y^{+}_{i,act} (Y^{+}_{i,inact}) là tập các cặp người dùng-mục cho mục i trong đó người dùng là người dùng tích cực (không tích cực).

Như được hiển thị trong Bảng I, đối với các mục trong bất kỳ nhóm nào (tất cả, phổ biến và không phổ biến), số lượng người dùng tích cực tích cực lớn hơn nhiều so với người dùng không tích cực. Bên cạnh đó, số lượng người dùng tích cực tiêu cực nhỏ hơn nhiều so với người dùng không tích cực thông qua lấy mẫu tiêu cực trên phân phối đều. Do đó, các embedding mục dễ dàng bị chi phối bởi người dùng tích cực Suy luận thất bại, theo các gradient tích lũy được tính bởi Phương trình 8. Chúng ta có thể suy ra rằng độ phổ biến của mục càng cao thì độ lớn của embedding tương ứng sẽ càng lớn. Hơn nữa, khoảng cách giữa các mục phổ biến có thể gần nhau trong không gian tiềm ẩn do sự tuân thủ của người dùng.

Ảnh hưởng của độ phổ biến mục lên phía người dùng. Tương tự như phân tích các mục từ góc nhìn gradient, chúng ta có thể thu được các gradient tích lũy Δ_u của người dùng u bằng:

Δ_u = ∑_{(u,i)∈Y^{+}_{u,pop}} Q_i + ∑_{(u,i)∈Y^{+}_{u,unp}} Q_i
     - ∑_{(u,j)∈Y^{-}_{u,pop}} Q_j - ∑_{(u,j)∈Y^{-}_{u,unp}} Q_j                (10)

Đối với người dùng trong bất kỳ nhóm nào (tất cả, tích cực, không tích cực), số lượng mục phổ biến tích cực lớn hơn nhiều so với các mục không phổ biến. Tuy nhiên, số lượng mục phổ biến tiêu cực nhỏ hơn nhiều so với các mục không phổ biến trong lấy mẫu tiêu cực ngẫu nhiên. Do đó, các mục phổ biến chi phối đáng kể các embedding người dùng do các gradient tích lũy được định nghĩa trong Phương trình 10.

IV. GIẢI PHÁP ĐỀ XUẤT

Trong phần này, chúng tôi trình bày phương pháp của mình. Cụ thể, trong giai đoạn huấn luyện, phương pháp của chúng tôi chỉ chuẩn hóa các embedding người dùng sau khi học các embedding người dùng và mục sử dụng LGN [15] hoặc MF [14]. Sau đó chúng tôi áp dụng việc loại bỏ thiên lệch hậu kiểm trên các embedding người dùng và mục trong giai đoạn kiểm tra để giảm thiểu thiên lệch độ phổ biến mục. Chúng tôi đầu tiên đưa ra định nghĩa của mình về một embedding mục (người dùng) không thiên lệch trong RS ngầm. Tiếp theo chúng tôi đưa ra mô tả chi tiết về cách giảm thiểu hoạt động người dùng trong giai đoạn huấn luyện và cách giảm thiểu ảnh hưởng của độ phổ biến mục và sự tuân thủ người dùng.

Học embedding tách rời. Chúng tôi đầu tiên định nghĩa bốn yếu tố ảnh hưởng đến việc học embedding người dùng và mục.

Một phương pháp loại bỏ thiên lệch hậu kiểm. Theo quá trình tối ưu hóa gradient, chúng tôi phân tích cách bốn yếu tố lan truyền thiên lệch phổ biến vào giai đoạn cập nhật embedding và thiết kế một thuật ngữ loại bỏ thiên lệch cụ thể cho từng trong bốn yếu tố tương ứng.

A. Định nghĩa embedding không thiên lệch

Như được mô tả trong Phần 3, có ba yếu tố làm trầm trọng thêm vấn đề mất cân bằng giữa các gradient tích cực và tiêu cực tích lũy của mỗi mục: (1) hoạt động cao của người dùng tương tác với nhiều mục; (2) độ phổ biến cao của mục liên quan đến nhiều tương tác tích cực hơn. (3) sự tuân thủ của người dùng đối với những người dùng chính thống khác. Đối với các mục phổ biến, gradient tổng thể của nó bị dịch chuyển theo hướng gradient tích cực, làm cho các mục phổ biến được tiếp xúc nhiều. Ngược lại, các mục không phổ biến bị tiếp xúc ít. Độ lớn lớn của các vector mục phổ biến dẫn đến điểm xếp hạng cao hơn cho các tương tác tích cực. Vì việc cập nhật các vector tiềm ẩn người dùng và mục được đan xen trong quá trình tối ưu hóa RS ngầm, chúng tôi đề xuất điều chỉnh cả vector tiềm ẩn người dùng và mục để giảm thiểu thiên lệch phổ biến.

Cho embedding mục Q_i và embedding người dùng P_u được huấn luyện sử dụng mô hình MF [14] (hoặc LGN [15]) vanilla, chúng tôi biểu diễn embedding mục như:

Q_i = Q^{pop}_i + Q^{int}_i                                                    (11)

trong đó Q^{pop}_i nắm bắt độ phổ biến của mục và Q^{int}_i nắm bắt các đặc trưng thực sự của mục. Tương tự, chúng tôi biểu diễn một embedding người dùng P_u như:

P_u = ||P^{act}_u||_2 · (P^{conf}_u + P^{int}_u)                              (12)

trong đó P^{act}_u nắm bắt tính tích cực của người dùng, P^{conf}_u biểu thị sự tuân thủ của người dùng đối với những người dùng chính thống khác, và P^{int}_u biểu thị sở thích thực sự của người dùng. Đáng chú ý, việc lấy tích của P^{act}_u và P^{conf}_u + P^{int}_u được biện minh bởi thực tế rằng một người dùng tích cực có xu hướng có nhiều tương tác được quan sát hơn [17]. Chính thức, điểm khớp không thiên lệch cho một người dùng và một mục là:

ŷ_{ui} = P^{int}_u Q^{int}_i                                                    (13)

Trong các phần sau, chúng tôi sẽ mô tả cách chúng tôi giảm thiểu P^{act}_u trong giai đoạn huấn luyện và loại bỏ Q^{pop}_i và P^{conf}_u trong giai đoạn kiểm tra.

B. Chuẩn hóa embedding người dùng trong huấn luyện

Vì một người dùng tích cực sẽ có nhiều tương tác được quan sát với các mục, các gradient tích lũy của họ dựa trên những mục này có thể sẽ lớn hơn so với những người dùng ít tích cực khác. Ví dụ, nếu người dùng u_1 và u_2 chia sẻ sở thích mục tương tự với u_1 tích cực hơn, các vector embedding của u_1 và u_2 sẽ có hướng cập nhật tương tự nhưng chuẩn vector của người dùng u_1 sẽ lớn hơn nhiều. Embedding lớn như vậy đóng góp vào việc cập nhật gradient của các mục tương ứng, làm trầm trọng thêm vấn đề mất cân bằng giữa các gradient tích cực và tiêu cực tích lũy của các mục.

Để giảm sự lan truyền thiên lệch của những người dùng có hoạt động cao, chúng tôi chuẩn hóa mỗi embedding người dùng P̂_u thành một vector đơn vị trong giai đoạn huấn luyện:

P̂_u = P_u / ||P^{act}_u||_2                                                   (14)

trong đó P̂_u là embedding người dùng đã học sau khi chuẩn hóa. Để giữ ký hiệu đơn giản, chúng tôi sử dụng ||P_u|| để biểu thị ||P^{act}_u||_2. Quy trình huấn luyện hoàn chỉnh được hiển thị trong Thuật toán 1.

C. Điều chỉnh thiên lệch phổ biến trong suy luận

1) Giảm thiểu ảnh hưởng độ phổ biến mục: Đối với một mục phổ biến, các tương tác tích cực của nó với người dùng thường xuyên được quan sát trong số các mẫu huấn luyện, dịch chuyển embedding đã học theo hướng tương tác tích cực. Như được mô tả trong Hình 3, động lực ở đây là sửa đổi vector mục đã học tổng thể AD thành một vector mục không thiên lệch AD'. Có một số cách để làm như vậy. Trong bài báo này, chúng tôi đề xuất sửa đổi gradient tích lũy thiên lệch AD chỉ thông qua các gradient tích cực tích lũy của nó AC và giữ AB không thay đổi.

Tuy nhiên, việc tối ưu hóa lặp đi lặp lại của embedding người dùng/mục làm cho không rõ ràng rằng các mục khác và các embedding người dùng liên quan đóng góp bao nhiêu vào các gradient tích cực tích lũy cho mỗi mục, làm trầm trọng thêm sự mất cân bằng giữa AB và AC. Do đó, câu hỏi quan trọng ở đây là làm thế nào để xấp xỉ embedding thiên lệch P^{pop}_u trong Phương trình 12. Phân tích của chúng tôi trong Phần 3 gợi ý rằng 1) đối với các mục phổ biến, các embedding tích lũy gradient tổng thể (đã học) của chúng (AD) bị dịch chuyển về phía hướng gradient tích cực của nó (AC); 2) Tối ưu hóa lặp đi lặp lại của embedding người dùng và mục làm cho các embedding mục được đan xen với thông tin mục liên quan khác. Bên cạnh đó, sự tuân thủ và hoạt động của người dùng làm cho các embedding mục của họ phản ánh sở thích người dùng tương tự. Do đó, các mục phổ biến chia sẻ các hướng gradient tích cực tương tự. Dựa trên hai phát hiện này, chúng tôi sử dụng embedding trung bình của các embedding mục phổ biến để đại diện cho embedding thiên lệch Q^{pop} như vậy. Hướng của vector thiên lệch như vậy được đặt tên là hướng phổ biến Q̄.

Do đó, chúng tôi phân tách một embedding mục Q_i thành một embedding đặc trưng thực sự Q^{ini}_i và một phép chiếu trên hướng phổ biến Q̄. Vector phép chiếu ở đây đề cập đến embedding độ phổ biến mục Q^{pop}_i trong Phương trình 11. Trong giai đoạn kiểm tra, chúng tôi điều chỉnh embedding mục đã học Q_i và tính biểu diễn thực sự Q^{int}_i của nó:

Q^{int}_i = Q_i - Q^{pop}_i = Q_i - α_1 cos(Q_i, Q̄) ||Q_i|| Q̄                (15)

trong đó α_1 là một tham số tỷ lệ kiểm soát độ lớn của vector tích cực đã sửa đổi AC'. Trong bài báo này, chúng tôi chọn giá trị của α_1 dựa trên tập validation.

2) Giảm thiểu sự tuân thủ người dùng: Khác với các embedding mục được cập nhật bởi cả gradient tích cực và tiêu cực, một embedding người dùng chỉ được cập nhật bởi gradient Q_i - Q_j, trong đó các mục i và j xuất hiện trong các tương tác được quan sát và không được quan sát với người dùng, tương ứng. Một embedding người dùng không tránh khỏi bị ảnh hưởng bởi sở thích của những người dùng khác trong quá trình cập nhật gradient với loss BPR, và do đó chiếm sự tuân thủ của người dùng.

Ví dụ, hãy xem xét một tình huống trong đó ba người dùng tương tác với một mục i_1, trong khi người dùng đầu tiên u cũng tương tác với mục i_2 và i_3. Vì i_1 có nhiều tương tác được quan sát, nó nhận được các gradient tích lũy dựa trên ba người dùng. Bất cứ khi nào chúng ta cập nhật embedding người dùng ∇_u L(u,i) = Q_{i_1}. Embedding của Q_{i_1} với độ lớn lớn sẽ tăng độ lớn của vector tiềm ẩn của u.

Tình huống ở đây tương tự như thiên lệch độ phổ biến mục, do đó chúng tôi áp dụng một cách tương tự để trích xuất sở thích thực sự của người dùng bằng cách trừ đi phép chiếu sự tuân thủ người dùng:

P_u = P_u - α_2 cos(P_u, P̄) ||P_u|| P̄                                        (16)

trong đó P̄ biểu thị embedding trung bình hoặc đã chuẩn hóa của các embedding người dùng chính thống. Thuật ngữ α_2 cos(P_u, P̄) ||P_u|| P̄ nắm bắt embedding sự tuân thủ người dùng P^{conf}_u trong Phương trình 12. α_2 là một tham số tỷ lệ. Chúng tôi hiển thị quy trình suy luận trong Thuật toán 2.

V. CÁC THỬ NGHIỆM

Trong phần này, chúng tôi tiến hành các thử nghiệm để hiển thị hiệu quả và hiệu suất của khung được đề xuất. Cụ thể, chúng tôi nhằm trả lời các câu hỏi nghiên cứu sau:

RQ1: (a) Phương pháp đề xuất của chúng tôi có vượt trội hơn các phương pháp gợi ý tiên tiến nhất trong thiết lập non-IID không? (b) Hơn nữa, nó có tổng quát hóa tốt trên cả loss BPR và BCE không? (c) Nó có hiệu quả hơn các phương pháp tiên tiến nhất không?

RQ2: Các thành phần khác nhau (ví dụ: chuẩn hóa, subtrahend sự tuân thủ người dùng, subtrahend độ phổ biến mục, và các siêu tham số α_1 của những subtrahend này) ảnh hưởng như thế nào đến kết quả của phương pháp chúng tôi?

RQ3: (a) Phương pháp của chúng tôi giảm thiểu thiên lệch phổ biến tốt như thế nào? (b) Hiệu suất của phương pháp chúng tôi thay đổi như thế nào với tỷ lệ can thiệp của dữ liệu kiểm tra?

A. Thiết lập thử nghiệm

Bộ dữ liệu và tiền xử lý dữ liệu. Các thử nghiệm của chúng tôi sử dụng bốn bộ dữ liệu có sẵn công khai: 1) Movielens-10M là một bộ dữ liệu với 10M đánh giá phim. 2) Netflix [18] là từ một cuộc thi mở và nó bao gồm các đánh giá phim. 3) Adressa [19] là một bộ dữ liệu phổ biến cho gợi ý tin tức. 4) Gowalla [20] là một bộ dữ liệu bao gồm các hành vi check-in dựa trên vị trí của người dùng. Chúng tôi tóm tắt thống kê của các bộ dữ liệu trong Bảng II.

Để điều tra mức độ mà các mô hình đã loại bỏ thiên lệch giảm thiên lệch phổ biến, chúng tôi thay thế chiến lược đánh giá thông thường, trong đó tập kiểm tra bao gồm các mẫu IID từ các tương tác được quan sát, bằng một chiến lược lấy mẫu để xây dựng một tập kiểm tra đã loại bỏ thiên lệch [21]. Cụ thể, chúng tôi lấy mẫu ngẫu nhiên các tương tác với xác suất bằng nhau được đưa cho tất cả các mục để xây dựng dữ liệu kiểm tra và validation. Sau đó chúng tôi sử dụng dữ liệu còn lại đi kèm với thiên lệch phổ biến làm dữ liệu huấn luyện.

Chúng tôi theo DICE [12] để xử lý các bộ dữ liệu Movielens-10M và Netflix và MACR [11] để xử lý Adressa và Gowalla để so sánh công bằng. Cụ thể hơn, chúng tôi lấy mẫu 30% tương tác không thiên lệch liên quan đến các mục làm tập kiểm tra, 10% làm tập validation và 60% còn lại làm dữ liệu huấn luyện cho Movielens-10M và Netflix. Chúng tôi chuẩn bị 10% dữ liệu không thiên lệch làm tập kiểm tra, 10% dữ liệu không thiên lệch khác làm tập validation và phần còn lại làm tập huấn luyện cho Adressa và Gowalla.

Baseline. Chúng tôi triển khai phương pháp của mình trên MF cổ điển và LGN tiên tiến nhất để điều tra hiệu quả và khả năng tổng quát hóa của phương pháp đề xuất trên các mô hình gợi ý backbone khác nhau. Chúng tôi so sánh các phương pháp của mình với các baseline sau. Matrix factorization (MF) [14] là một phương pháp lọc cộng tác đại diện. LGN [15] là một lọc cộng tác tiên tiến nhất dựa trên mạng tích chập đồ thị nhẹ. IPS [4] là một phương pháp tái trọng số được sử dụng rộng rãi dựa trên suy luận nhân quả. Điểm trọng số, tức là điểm xu hướng nghịch đảo được đặt như nghịch đảo của giá trị độ phổ biến mục tương ứng. Nó loại bỏ thiên lệch phổ biến bằng cách áp đặt trọng số lớn cho các mục không phổ biến. CausE [21] là một thuật toán thích ứng miền học một embedding nhân quả từ một bộ dữ liệu đều nhỏ. DICE [12] là phương pháp tách rời tiên tiến nhất để học embedding nhân quả để đối phó với vấn đề thiên lệch phổ biến. Nó thiết kế một khung với dữ liệu cụ thể nhân quả để tách rời sở thích và độ phổ biến với các hướng dẫn được định nghĩa trước. DICE tận dụng thiên lệch phổ biến trong suy luận. Chúng tôi sử dụng mã được cung cấp bởi các tác giả. MACR [11] giải quyết thiên lệch phổ biến từ góc nhìn hiệu ứng nhân quả. Suy luận phản thực được thực hiện để ước tính hiệu ứng trực tiếp từ các thuộc tính mục đến điểm xếp hạng, được loại bỏ để loại bỏ thiên lệch phổ biến.

Chi tiết triển khai. Chúng tôi đánh giá hiệu suất hiệu quả bằng ba metric được sử dụng rộng rãi, tức là top-k Recall (Recall@k), top-k Hit Ratio (HR@k), và top-k Normalized Discounted Cumulative Gain (NDCG@k), được sử dụng trong DICE [12] và MACR [11]. Đối với MACR trên Movielens-10M và Netflix, chúng tôi sử dụng mã nguồn được cung cấp bởi các tác giả của họ và đặt kích thước batch và kích thước embedding là 128 để so sánh công bằng. Đối với các kết quả được báo cáo của các baseline còn lại, chúng tôi tham khảo trực tiếp DICE và MACR. Lưu ý rằng phương pháp của chúng tôi dựa trên hai backbone (tức là MF và LGN). Các siêu tham số của các backbone được đặt theo các đề xuất từ DICE cho Movielens-10M và Netflix và MACR cho Adressa và Gowalla để đảm bảo so sánh công bằng với DICE và MACR. α_1 và α_2 được xác định trên tập validation dựa trên tìm kiếm lưới trong danh sách tìm kiếm được hình thành bằng cách lấy các giá trị từ 0 đến 2 với gia số 0.2.

B. So sánh tổng thể (RQ1)

Hiệu suất gợi ý (tức là Recall@20, HR@20, và NDCG@20) của các mô hình khác nhau được trình bày trong Bảng III. Các phương pháp có hiệu suất tốt nhất được đánh dấu bằng phông chữ đậm và những phương pháp tốt thứ hai được gạch chân. Dựa trên kết quả, chúng tôi đưa ra các quan sát sau:

Như được hiển thị trong Bảng III, phương pháp đề xuất của chúng tôi liên tục vượt trội hơn tất cả các baseline trên tất cả các bộ dữ liệu đối với tất cả các metric đánh giá. Các baseline tiên tiến nhất DICE và MACR kết hợp các module bổ sung để giảm thiên lệch phổ biến, đòi hỏi kiến thức tiên nghiệm bổ sung và nỗ lực để khai thác kiến trúc tốt bằng thử và sai trong giai đoạn huấn luyện. Ngược lại, phương pháp của chúng tôi chỉ cần lưu trữ ảnh hưởng tổng hợp của các mục và người dùng chi phối được gây ra bởi các cập nhật dựa trên gradient. Nó xử lý hiệu quả thiên lệch phổ biến bằng cách thực hiện một phép tính trừ hậu kiểm trong bước suy luận, cuối cùng dẫn đến hiệu suất tốt hơn so với các baseline.

Phương pháp đề xuất của chúng tôi vừa tổng quát vừa hiệu quả. Nó có thể dễ dàng được kết hợp vào các mô hình RS backbone khác nhau như MF, LGN và bất kỳ mô hình gợi ý tổng quát nào khác. Đồng thời, nó đạt được hiệu suất đầy hứa hẹn trên tập kiểm tra đã loại bỏ thiên lệch. So với MF cổ điển, phương pháp đề xuất của chúng tôi sử dụng MF làm mô hình backbone đạt được cải thiện trung bình 37.33%, 33.87%, và 51.79% trong Recall@20, HR@20, và NDCG@20, tương ứng. Tương tự, phương pháp đề xuất của chúng tôi tăng cường hiệu suất của LGN gốc khoảng 51.33%, 32.83%, 56.34% đối với Recall@20, HR@20, NDCG@20, tương ứng. Những kết quả đáng kể này chứng minh rằng phương pháp hiệu quả giảm thiểu thiên lệch phổ biến trong các giai đoạn huấn luyện và kiểm tra.

Phương pháp đề xuất của chúng tôi có khả năng tổng quát hóa mạnh hơn, tức là nó mạnh mẽ hơn, vì nó liên tục vượt trội hơn những phương pháp khác trên tất cả bốn bộ dữ liệu với bối cảnh đa dạng và phân phối dữ liệu. Trong khi các phương pháp tiên tiến nhất DICE và MACR đạt được hiệu suất tương đương, hiệu suất của chúng có thể không luôn nhất quán trên các bộ dữ liệu khác nhau. Một lý do có thể là DICE và MACR yêu cầu cấu hình tinh vi của các module được kết hợp và mất nhiều nỗ lực để điều chỉnh các siêu tham số tối ưu. Một lý do có thể khác để giải thích sự không nhất quán của DICE là DICE phụ thuộc vào hai chiến lược dựa trên quy tắc để có được các ví dụ tiêu cực và để sử dụng loss BPR tiêu cực hoặc tích cực để cập nhật mô hình. Các chiến lược thật không may nhạy cảm với phân phối dữ liệu. Đối với các baseline còn lại để giảm thiểu thiên lệch phổ biến, CausE có cải thiện hạn chế so với các mô hình cơ bản và đôi khi thậm chí còn hoạt động tệ hơn. Lý do nên là CausE căn chỉnh các embedding người dùng và mục với một bộ dữ liệu đều nhỏ mà khó có thể cho phép mô hình học đủ thông tin sở thích người dùng. IPS hoạt động kém trong hầu hết các trường hợp vì nó đơn giản tăng trọng số các mục không phổ biến với một điểm tĩnh, làm cho mô hình quá tự tin để gợi ý các mục không phổ biến.

C. Phân tích sâu hơn

Trong phần này, chúng tôi tiếp tục đánh giá phương pháp đề xuất của mình bằng cách trả lời các câu hỏi nghiên cứu còn lại:

1) Nó có tổng quát hóa tốt trên cả loss BPR và BCE không? (RQ1(b)): Hình 4 hiển thị cách phương pháp của chúng tôi sử dụng MF làm backbone hoạt động khi được áp dụng với loss BPR hoặc BCE trên Movielens-10M và Netflix. Nhìn chung, việc trừ thiên lệch sự tuân thủ người dùng và thiên lệch độ phổ biến mục trong giai đoạn kiểm tra cung cấp hiệu suất tốt hơn đáng kể so với các mô hình sử dụng các embedding người dùng và mục vanilla. Quan sát này xác nhận quan điểm của chúng tôi rằng việc tối ưu hóa BPR và BCE kết hợp thiên lệch sự tuân thủ người dùng và thiên lệch độ phổ biến mục vào các embedding người dùng và mục, tương ứng, làm cho kết quả gợi ý lệch khỏi sở thích thực sự của người dùng. Thiết kế hậu kiểm được đề xuất là một cách thanh lịch và hiệu quả để loại bỏ thiên lệch.

2) Phương pháp của chúng tôi có hiệu quả hơn các baseline tiên tiến nhất không? (RQ1(c)): Chúng tôi điều tra hiệu suất của phương pháp đề xuất bằng cách so sánh thời gian chạy trên cùng một thiết bị với hai phương pháp tiên tiến nhất, tức là DICE và MACR, với các backbone MF và LGN. Như được hiển thị trong Bảng IV, chúng tôi quan sát rằng phương pháp của chúng tôi đạt được thời gian chạy tương đương với các phương pháp MF và LGN cổ điển, và nó hiệu quả hơn đáng kể so với DICE và MACR. Với thiết kế học nhân quả đặc biệt và giám sát trực tiếp trên việc tách rời, DICE mất gấp đôi thời gian so với phương pháp đề xuất của chúng tôi do chi phí bổ sung của việc cập nhật tham số. MACR bao gồm các module bổ sung để tái tạo tần suất người dùng và mục, và do đó kém hiệu quả hơn. Một quan sát phụ thú vị khác là DICE luôn gặp phải thời gian tính toán quá mức so với MACR. Chúng tôi phỏng đoán rằng hai chiến lược dựa trên quy tắc bổ sung của DICE một phần chịu trách nhiệm cho thời gian tiêu thụ quá mức.

3) Có cần thiết chuẩn hóa các embedding người dùng và có mong muốn trừ thuật ngữ sự tuân thủ người dùng và độ phổ biến mục không? (RQ2): Chúng tôi tiến hành một nghiên cứu ablation với phương pháp của mình sử dụng các backbone MF và LGN trên các bộ dữ liệu Movielens-10M và Adressa để phân tích đóng góp của các thành phần khác nhau. Cụ thể, chúng tôi so sánh phương pháp của mình với ba biến thể đặc biệt của nó: phương pháp của chúng tôi không (w/o) có chuẩn người dùng (tức là MF w/o norm và LGM w/o norm), trong đó việc chuẩn hóa trên embedding người dùng được loại bỏ; phương pháp của chúng tôi với α_1 = 0, trong đó chúng tôi chỉ đơn giản bỏ thuật ngữ embedding sự tuân thủ người dùng trong suy luận; phương pháp của chúng tôi với α_2 = 0 bỏ thuật ngữ embedding độ phổ biến mục.

Kết quả trong Bảng V cho thấy việc loại bỏ bất kỳ thành phần nào sẽ dẫn đến hiệu suất tệ hơn. Nó cho thấy rằng cả ba thành phần đều đóng góp vào việc cải thiện hiệu suất mô hình trong các tình huống non-IID. Bỏ qua việc chuẩn hóa embedding người dùng sẽ giảm độ chính xác trong tất cả các metric trên cả bộ dữ liệu Movielens-10M và Adressa. Điều này xác nhận tính hữu ích của việc chuẩn hóa độ lớn embedding người dùng trong giai đoạn huấn luyện, tức là thúc đẩy các mục có ít tương tác hơn có lợi cho hiệu suất gợi ý. Rõ ràng là so với biến thể không có thiên lệch độ phổ biến mục, mô hình hoạt động tệ hơn nhiều khi loại bỏ thiên lệch sự tuân thủ người dùng trong hầu hết các trường hợp. Một lý do có thể là người dùng có tác động nhiều hơn mục đối với hai bộ dữ liệu này.

4) Phương pháp của chúng tôi giảm thiểu thiên lệch phổ biến như thế nào? (RQ3(a)): Trong nghiên cứu này, chúng tôi điều tra liệu phương pháp của chúng tôi có thể loại bỏ hiệu ứng của thiên lệch phổ biến bằng các phương pháp, tức là MF (LGN), Our_MF (Our_LGN) w/o norm, và Our_MF (Our_LGN) trên Movielens-10M. Để phân tích loại bỏ thiên lệch chi tiết, chúng tôi đầu tiên sắp xếp các mục theo thứ tự độ phổ biến nghịch đảo. Sau đó chúng tôi chia các mục thành năm nhóm, mỗi nhóm trong bốn nhóm đầu chiếm 5% các mục, và chúng tôi đặt phần còn lại vào nhóm cuối cùng. Nhóm 1 đại diện cho nhóm mục phổ biến nhất, và Nhóm 5 đại diện cho nhóm mục ít phổ biến nhất. Đối với mỗi nhóm, chúng tôi tính tần suất gợi ý trung bình và recall@20. Chúng tôi hiển thị tần suất gợi ý của mỗi nhóm bằng các phương pháp trong Hình 5 và recall trong Hình 6.

Các phương pháp gợi ý thông thường có tần suất gợi ý đáng kể nhất và hoạt động tốt nhất trong nhóm 1 nhưng mang lại sự sụt giảm hiệu suất đáng kể trong nhóm 2 và giảm thêm trong các nhóm khác. Nó cho thấy rằng các hệ thống gợi ý thông thường có xu hướng gợi ý các mục phổ biến cho người dùng không liên quan do sự tuân thủ người dùng và thiên lệch phổ biến. Ngược lại, các hệ thống gợi ý thông thường với phương pháp hậu kiểm được đề xuất của chúng tôi có tần suất gợi ý và hiệu suất ít hơn trong nhóm phổ biến nhất nhưng đạt được tần suất gợi ý cao hơn đáng kể và hiệu suất gợi ý tốt hơn từ nhóm 2 đến nhóm 4. Nó cho thấy rằng phương pháp đề xuất của chúng tôi hiệu quả giảm sự tuân thủ người dùng và thiên lệch độ phổ biến mục.

Trong nhóm 5, tất cả các phương pháp đạt được tần suất gợi ý và hiệu suất tương tự. Lý do có thể là những mục ít phổ biến nhất này hiếm khi xuất hiện trong tập huấn luyện để biểu diễn của những mục này không thể được học hiệu quả. Trong một số trường hợp, phương pháp của chúng tôi đạt được tần suất gợi ý ít hơn nhưng recall cao hơn so với phương pháp của chúng tôi w/o norm. Nó có nghĩa là phương pháp của chúng tôi vẫn có thể gợi ý các mục cho người dùng chính xác hơn.

5) Hiệu suất của phương pháp chúng tôi thay đổi như thế nào cùng với tỷ lệ can thiệp của dữ liệu kiểm tra? (RQ3(b)): Trong các thử nghiệm trước, tất cả các phương pháp được kiểm tra trên 100% dữ liệu kiểm tra can thiệp. Nghiên cứu này điều tra cách các phương pháp hoạt động khi tỷ lệ dữ liệu kiểm tra can thiệp thay đổi. Chúng tôi đánh giá MF và phương pháp của chúng tôi (MF) với năm tỷ lệ khác nhau của dữ liệu kiểm tra can thiệp, tức là 0%, 50%, 75%, 90%, 100%. 0% có nghĩa là dữ liệu huấn luyện và kiểm tra có cùng phân phối. 100% có nghĩa là tất cả dữ liệu kiểm tra đều là dữ liệu can thiệp. Như được hiển thị trong Hình 7, phương pháp của chúng tôi bắt đầu vượt trội hơn MF trên 75% dữ liệu kiểm tra can thiệp và vượt trội đáng kể nhất dưới 100% dữ liệu kiểm tra can thiệp, điều này xác minh hiệu quả của phương pháp chúng tôi trong các tình huống non-IID.

6) Hiệu ứng của các siêu tham số của các subtrahend: Phương pháp hậu kiểm của chúng tôi có hai siêu tham số α_1 và α_2 cho subtrahend sự tuân thủ người dùng và subtrahend độ phổ biến mục tương ứng. Chúng tôi thử nghiệm với phương pháp của mình sử dụng MF làm backbone trên Movielens-10M để điều tra hiệu ứng của chúng. Hình 8 hiển thị cách hiệu suất của phương pháp chúng tôi (recall@20) thay đổi khi α_1 và α_2 thay đổi từ 0 đến 2 trên khoảng.

Như chúng ta có thể thấy, mô hình hoạt động tốt khi α_1 nằm giữa 0.4 đến 0.6 và hoạt động ngày càng tốt hơn khi tăng α_2 trong hầu hết các trường hợp. Nó gợi ý rằng lượng phù hợp của việc giảm thiểu thiên lệch sự tuân thủ người dùng và thiên lệch độ phổ biến mục có lợi cho hệ thống gợi ý trong các tình huống non-IID. α_1 lớn mang lại sự sụt giảm hiệu suất trong khi α_2 lớn cải thiện hiệu suất gợi ý, điều này cho thấy rằng việc loại bỏ thiên lệch sự tuân thủ người dùng quá mức làm tổn hại hiệu suất. Một lý do có thể là việc chuẩn hóa người dùng hạn chế quá mức độ lớn của các embedding người dụng.

VI. CÔNG TRÌNH LIÊN QUAN

Trong những năm gần đây, các hệ thống gợi ý đã đạt được thành công lớn nhờ vào ưu điểm của các phương pháp học sâu, hầu hết trong số đó nhằm vào việc phát triển các mô hình học máy mới lạ để phù hợp với dữ liệu hành vi người dùng. Khi đến các tình huống thực tế, phân phối tương tác người dùng và mục không tránh khỏi là đuôi dài, làm cho thiên lệch phổ biến trở thành một thách thức lâu dài [22]–[24].

Ý tưởng cốt lõi đầu tiên trong việc giảm thiểu thiên lệch phổ biến là cân bằng phân phối dữ liệu sao cho các mục phổ biến và không phổ biến đều quan trọng như nhau trong quá trình huấn luyện. Trọng số xu hướng nghịch đảo (IPW) [8], [25] được sử dụng rộng rãi để gán trọng số tỷ lệ nghịch với độ phổ biến mục trong rủi ro thực nghiệm của một mô hình RS [26]. Trong khi các phương pháp tái trọng số như vậy đạt được cải thiện đáng kể cho các mục được đại diện thiếu, chúng đi kèm với rủi ro cao của việc overfitting và gặp phải phương sai cao [27], [28]. Công trình gần đây [29]–[32] nghiên cứu vấn đề này từ góc độ công bằng [33], [34] và thực thi thuật toán để tạo ra một phân bổ tiếp xúc công bằng dựa trên thành tích. Các chiến lược khác theo pipeline đầu tiên là chuyển giao kiến thức đã học từ các nhóm phổ biến sang các nhóm không phổ biến [35]. Các phương pháp như vậy thường đưa thêm nhiễu vào các mục không phổ biến và sửa đổi phân phối bộ dữ liệu ban đầu. Công trình gần đây [36] điều tra thiên lệch từ góc độ suy luận nhân quả và đề xuất một phương pháp lý luận phản thực sử dụng Do-calculus [37]. Họ đề xuất một đồ thị nhân quả khác nhau dựa trên kiến thức tiên nghiệm, tuy nhiên, bản chất là tái cân bằng phân phối cho các nhóm phổ biến và không phổ biến với ngôn ngữ nhân quả.

Một hướng nghiên cứu khác là bảo tồn thông tin người dùng và mục cụ thể một cách có chủ ý, với mục tiêu làm cho các mục không phổ biến đại diện hơn [10]. Với thông tin văn bản phụ trợ, [10] một lớp autoencoder [38], [39] được thêm vào trong khi học biểu diễn người dùng và mục với Convolutional Neural Networks dựa trên văn bản. Công trình mới nhất [21] coi hệ thống gợi ý cá nhân hóa như một vấn đề tối đa hóa tiện ích chính sách điều trị và đề xuất một phương pháp thích ứng miền có tên CausE. [40] đề xuất một chiến lược meta-learning và chuyển biểu diễn dữ liệu không thiên lệch từ dữ liệu logged đều. Tuy nhiên, tính khả dụng và chất lượng cao của bộ dữ liệu phụ trợ là nút thắt cổ chai cho các phương pháp như vậy.

Các loại thứ ba cố gắng giải quyết vấn đề này thông qua điều chỉnh xếp hạng [41]–[43]. Các phương pháp này dẫn đến sự đánh đổi giữa độ chính xác gợi ý và độ bao phủ của các mục không phổ biến. Chúng thường gặp phải sự sụt giảm độ chính xác do tính đến đuôi dài một cách thô bạo.

Khác với phương pháp trước, trong bài báo này chúng tôi không tập trung vào việc cân bằng phân phối của các nhóm mục phổ biến và không phổ biến hoặc làm cho các mục không phổ biến đại diện hơn. Chúng tôi cung cấp một cái nhìn mới rằng sự mất cân bằng giữa các gradient tích cực và tiêu cực của cùng một mục gây ra thiên lệch phổ biến. Một số công trình liên quan [44] thảo luận về gradient biến mất của các mục không phổ biến từ góc độ gradient trong hệ thống gợi ý ngầm. Tuy nhiên, họ vẫn tập trung vào phân phối mất cân bằng giữa các nhóm mục phổ biến và không phổ biến, thực tế rơi vào ba loại trước.

VII. KẾT LUẬN

Trong bài báo này, chúng tôi đề xuất một khung làm việc đơn giản, hiệu quả và tổng quát để giảm thiểu thiên lệch phổ biến từ góc độ gradient (thông tin bậc nhất). Trong phương pháp của chúng tôi, chúng tôi ghi lại các gradient tích lũy của người dùng và mục như thiên lệch phổ biến trong giai đoạn huấn luyện. Sau đó chúng tôi giải quyết thiên lệch phổ biến bằng hiệu chỉnh cấp độ gradient trong giai đoạn kiểm tra như một chiến lược loại bỏ thiên lệch hậu kiểm. Chúng tôi triển khai phương pháp đề xuất trên MF và LGN trên bốn bộ dữ liệu thực tế. Các thử nghiệm rộng rãi chứng minh rằng phương pháp của chúng tôi vượt trội hơn các baseline cạnh tranh, ví dụ: DICE và MACR. Như một phần của công việc tương lai, chúng tôi sẽ xem xét áp dụng phương pháp của mình cho các nhiệm vụ gợi ý phức tạp hơn, chẳng hạn như gợi ý tuần tự và gợi ý đối thoại.

VIII. LỜI CẢM ƠN

Nghiên cứu này được hỗ trợ một phần bởi National Science Foundation (NSF) thông qua các số hiệu grant: 2040950, 2006889, 2045567.

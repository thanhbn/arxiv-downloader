# 2207.09078.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/privacy/2207.09078.pdf
# Kích thước tệp: 955290 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
ILASR: Học Tăng Dần Bảo Mật Quyền Riêng Tư cho Nhận Diện Giọng Nói Tự Động ở Quy Mô Sản Xuất
Gopinath Chennupati
Milind Rao
Gurpreet Chadha
Aaron Eakin
Amazon Alexa
USAAnirudh Raju
Gautam Tiwari
Anit Kumar Sahu
Ariya Rastrow
Jasha Droppo
Amazon Alexa
USAAndy Oberlin
Buddha Nandanoor
Prahalad Venkataramanan
Zheng Wu
Pankaj Sitpure
Amazon Alexa
USA

TÓM TẮT
Học tăng dần là một mô hình để kích hoạt xây dựng và cập nhật mô hình ở quy mô lớn với dữ liệu streaming. Đối với các nhiệm vụ nhận diện giọng nói tự động (ASR) đầu cuối, việc thiếu nhãn được chú thích bởi con người cùng với nhu cầu về các chính sách bảo mật quyền riêng tư cho việc xây dựng mô hình khiến nó trở thành một thách thức đáng gờm. Được thúc đẩy bởi những thách thức này, trong bài báo này chúng tôi sử dụng một khung công tác dựa trên đám mây cho các hệ thống sản xuất để trình bày những hiểu biết từ học tăng dần bảo mật quyền riêng tư cho nhận diện giọng nói tự động (ILASR). Bằng bảo mật quyền riêng tư, chúng tôi có nghĩa là việc sử dụng dữ liệu tạm thời không được chú thích bởi con người. Hệ thống này là một bước tiến cho các mô hình ASR cấp sản xuất cho học tăng dần/liên tục mà cung cấp môi trường thử nghiệm gần thời gian thực để thí nghiệm trong đám mây cho ASR đầu cuối, trong khi tuân thủ các chính sách bảo mật quyền riêng tư. Chúng tôi cho thấy rằng hệ thống được đề xuất có thể cải thiện các mô hình sản xuất đáng kể (3%) trong một khoảng thời gian mới sáu tháng ngay cả khi không có nhãn được chú thích bởi con người với các mức độ giám sát yếu khác nhau và kích thước lô lớn trong học tăng dần. Sự cải thiện này là 20% trên các bộ thử nghiệm với từ và cụm từ mới trong khoảng thời gian mới. Chúng tôi chứng minh hiệu quả của việc xây dựng mô hình theo cách tăng dần bảo mật quyền riêng tư cho ASR trong khi tiếp tục khám phá tính hữu ích của việc có một mô hình giáo viên hiệu quả và sử dụng kích thước lô lớn.

KHÁI NIỆM CCS
•Phương pháp tính toán →Nhận diện giọng nói ;Mạng nơ-ron ;Cài đặt học bán giám sát ;•Bảo mật và quyền riêng tư→Giao thức bảo mật quyền riêng tư .

TỪ KHÓA
Học Tăng Dần, Nhận Diện Giọng Nói Tự Động, Học Máy Bảo Mật Quyền Riêng Tư

Được phép tạo bản sao kỹ thuật số hoặc in của toàn bộ hoặc một phần công trình này để sử dụng cá nhân hoặc lớp học mà không tính phí với điều kiện các bản sao không được tạo ra hoặc phân phối vì lợi nhuận hoặc lợi thế thương mại và các bản sao mang thông báo này và trích dẫn đầy đủ trên trang đầu tiên. Bản quyền cho các thành phần của công trình này thuộc sở hữu của những người khác ngoài ACM phải được tôn trọng. Tóm tắt có ghi công được cho phép. Để sao chép nếu không, hoặc xuất bản lại, để đăng trên máy chủ hoặc để phân phối lại đến danh sách, cần có sự cho phép cụ thể trước và/hoặc một khoản phí. Yêu cầu quyền từ permissions@acm.org.
KDD '22, August 14–18, 2022, Washington, DC, USA
©2022 Association for Computing Machinery.
ACM ISBN 978-1-4503-9385-0/22/08. . . $15.00
https://doi.org/10.1145/3534678.3539174

Định dạng Tham chiếu ACM:
Gopinath Chennupati, Milind Rao, Gurpreet Chadha, Aaron Eakin, Anirudh
Raju, Gautam Tiwari, Anit Kumar Sahu, Ariya Rastrow, Jasha Droppo,
và Andy Oberlin, Buddha Nandanoor, Prahalad Venkataramanan, Zheng
Wu, Pankaj Sitpure. 2022. ILASR: Học Tăng Dần Bảo Mật Quyền Riêng Tư
cho Nhận Diện Giọng Nói Tự Động ở Quy Mô Sản Xuất. Trong Tuyển tập
Hội nghị lần thứ 28 của ACM SIGKDD về Khám phá Tri thức và Khai thác Dữ liệu
(KDD '22), August 14–18, 2022, Washington, DC, USA. ACM, New York, NY,
USA, 10 trang. https://doi.org/10.1145/3534678.3539174

1 GIỚI THIỆU
Học máy bảo mật quyền riêng tư [1] đã ở tiền tuyến, do cả sự quan tâm gia tăng về quyền riêng tư và khả năng nhạy cảm tiềm ẩn của mạng nơ-ron sâu đối với rò rỉ và tấn công. Học Liên kết (FL) [44] là một kỹ thuật học máy liên quan đến việc huấn luyện mô hình trên các thiết bị biên, nơi dữ liệu không cần rời khỏi thiết bị, và có thể không đồng nhất và không phân phối độc lập và giống hệt nhau (non-IID). Trong FL, nhiều cập nhật mô hình từ một số thiết bị tham gia được tổng hợp. Mặc dù dữ liệu thô không rời khỏi thiết bị biên, FL đã được phát hiện là dễ bị tấn công đảo ngược gradient [65,66]. Để đáp ứng, nhiều cơ chế bảo mật quyền riêng tư khác nhau như quyền riêng tư vi sai và tổng hợp an toàn [19, 58] đã được đề xuất để chống lại rò rỉ dữ liệu và tuân thủ các cơ chế bảo mật quyền riêng tư. Hơn nữa, việc thiếu nhãn cho dữ liệu có mặt trong các thực thể tham gia, khiến FL trở nên khó khăn hơn đối với các ứng dụng như nhận diện giọng nói tự động (ASR). Hầu hết nghiên cứu trong FL cho đến nay tập trung vào việc huấn luyện mô hình từ đầu.

Trong công trình này, chúng tôi tập trung vào học tăng dần bảo mật quyền riêng tư (IL), trong bối cảnh xây dựng mô hình sản xuất đầu cuối ở quy mô lớn trong các khoảng thời gian mở rộng. Học tăng dần [8,62] đã được sử dụng rộng rãi để cập nhật mô hình tăng dần khi đang chạy thay vì huấn luyện chúng từ đầu. Học tăng dần như vậy không bảo mật quyền riêng tư.

Mặc dù có những tiến bộ trên, theo hiểu biết tốt nhất của chúng tôi, ít khung công tác tồn tại cho việc huấn luyện tăng dần bảo mật quyền riêng tư của các mô hình nhận diện giọng nói tự động đầu cuối. Công trình trước đây về học liên kết cho các nhiệm vụ dựa trên giọng nói [13,16,23] và ASR đầu cuối [18,26], tập trung vào các tiêu chuẩn chuẩn¹ và không phải trên dữ liệu sản xuất quy mô lớn. IL bảo mật quyền riêng tư trên thiết bị cho ASR đầu cuối đặt ra một số thách thức. Các hệ thống ASR đầu cuối cỡ sản xuất [11,24] tốn kém để huấn luyện ngay cả trong thiết lập phân tán truyền thống, huấn luyện trên thiết bị cần thêm công việc [7] để thích ứng với các ràng buộc bộ nhớ và tính toán hạn chế. Tạo nhãn huấn luyện tức là bản chép lời giọng nói, gần thời gian thực, trên các thiết bị là một thách thức khác. Để giảm bớt sự không khả dụng của bản chép lời giọng nói gần thời gian thực, bản chép giáo viên có thể được sử dụng theo cách bán giám sát và/hoặc tự học. Ví dụ, xem xét vấn đề cải thiện các mô hình được triển khai trong các thiết bị biên chạy trợ lý giọng nói. Trong những trường hợp như vậy, số lượng thiết bị hàng triệu, dẫn đến quy mô lớn dữ liệu streaming được tạo ra. Chúng tôi đề xuất sử dụng xử lý lô lớn cho các phát ngôn được thu thập tại các thiết bị biên và gửi đến đám mây để xử lý, và dữ liệu chỉ được lưu trữ tạm thời. Tuy nhiên, việc triển khai tất cả hoặc một phần của các thành phần trên vào các thiết bị giọng nói hạn chế tài nguyên (như Alexa, Google Assistant và những thiết bị khác) là thách thức.

Chúng tôi xây dựng và sử dụng một hệ thống dựa trên đám mây, Học Tăng Dần cho Nhận Diện Giọng Nói Tự Động (ILASR) để huấn luyện và cập nhật các mô hình ASR sẵn sàng sản xuất. ILASR tự động hóa toàn bộ pipeline của học tăng dần theo cách bảo mật quyền riêng tư. Để thực thi các khía cạnh bảo mật quyền riêng tư trong bối cảnh ASR, chúng tôi thực thi việc gán nhãn các phát ngôn thông qua các mô hình giáo viên được huấn luyện trước không có chú thích của con người. ILASR xử lý một phát ngôn một lần trước khi cập nhật mô hình, bảo tồn thứ tự thời gian của dữ liệu. Về điều đó, những đóng góp của bài báo là:

•Một hệ thống IL dựa trên đám mây mới để huấn luyện các mô hình ASR sẵn sàng sản xuất gần thời gian thực, với một lượng lớn dữ liệu streaming được khử danh tính, mà không cần phải chép tay hoặc lưu trữ âm thanh.

•Chúng tôi cung cấp những hiểu biết mới về việc sử dụng xử lý lô lớn trong ILASR rằng nó không có tác động có hại đến độ chính xác thử nghiệm so với những phát hiện mâu thuẫn [20, 33,37,41,42,52] (trên CNN ImageNet). Chúng tôi có thể thích ứng với tỷ lệ học cố định và tối ưu hóa siêu tham số tối thiểu [34] cùng với huấn luyện lô lớn. Với tần suất hàng tháng của các cập nhật mô hình tăng dần, chúng tôi quan sát thấy các mô hình sản xuất (hội tụ trên dữ liệu cũ) cải thiện gần thời gian thực trên dữ liệu mới thuộc khoảng thời gian sáu tháng

•Chúng tôi thiết lập thực nghiệm trong sáu tháng dữ liệu rằng thứ tự thời gian so với thứ tự ngẫu nhiên của việc xử lý phát ngôn không tạo ra bất kỳ sự khác biệt có thể quan sát được trong hiệu suất.

Chúng tôi đánh giá ILASR trên ba kiến trúc transducer mạng nơ-ron hồi quy sinh viên (RNN-T) [24]. Phương pháp học bán giám sát (SSL) tạo ra bản chép máy sử dụng một mô hình ASR giáo viên lớn hơn. Các sinh viên được huấn luyện trước trên dữ liệu khử danh tính nội bộ cho đến 2020. Thông qua huấn luyện trong ILASR, chúng tôi quan sát thấy sự cải thiện 3−7% trong tỷ lệ lỗi từ (WER) so với các đường cơ sở được huấn luyện trước khi những sinh viên này được huấn luyện tăng dần trên khoảng thời gian mới sáu tháng trong 2021. Sự cải thiện trong WER được gọi là giảm tỷ lệ lỗi từ tương đối (WERR). Điều này tăng lên 20% trên các bộ thử nghiệm với từ và cụm từ mới trong 2021. Tương tự, khi các mô hình sinh viên được huấn luyện tăng dần mỗi tháng, chúng tôi quan sát thấy sự cải thiện WER, cũng như hiện tượng các mô hình trở nên cũ kỹ mà không có cập nhật thêm.

Bài báo được tổ chức như sau: phần 2 mô tả các khái niệm thiết yếu được sử dụng trong bài báo; phần 3 giải thích hệ thống được đề xuất; phần 4 mô tả các cài đặt thí nghiệm; phần 5 trình bày kết quả; phần 6 tóm tắt tài liệu liên quan và cuối cùng, phần 7 kết luận và khuyến nghị các hướng tương lai.

2 NỀN TẢNG
Trong phần này chúng tôi tóm tắt kiến trúc RNN-T và huấn luyện lô lớn với gradient descent ngẫu nhiên (SGD).

2.1 Kiến trúc mô hình RNN-T
Hình 1 cho thấy kiến trúc RNN-T [24] được sử dụng trong nhận diện giọng nói thời gian thực. Mô hình dự đoán xác suất 𝑃(y|x) của nhãn y=(𝑦1,...,𝑦𝑈) được cho các đặc trưng âm thanh x=(𝑥1,...,𝑥𝑇). Nó có một bộ mã hóa, một mạng dự đoán, và một mạng kết hợp. Bộ mã hóa tương tự như một mô hình âm thanh nhận một chuỗi các đặc trưng đầu vào âm thanh và xuất ra các biểu diễn ẩn được mã hóa. Mạng dự đoán tương ứng với một mô hình ngôn ngữ chấp nhận các dự đoán nhãn đầu ra trước đó, và ánh xạ chúng thành các biểu diễn ẩn. Mạng kết hợp là một DNN feed forward nhận cả đầu ra bộ mã hóa và mạng dự đoán, và dự đoán xác suất nhãn đầu ra cuối cùng với chuẩn hóa softmax.

Hình 1: Kiến trúc mô hình ASR RNN-T

2.2 Tổng quan về học với kích thước lô lớn
Khi huấn luyện với SGD, các mini batch với lịch trình tỷ lệ học suy giảm được tạo tác kỹ lưỡng thường được sử dụng thay vì sử dụng các lô lớn. Công trình trước đây trong [33] đã chứng minh sự sụt giảm khái quát hóa khi sử dụng các lô lớn, do đó khuyên nên SGD mini-batch với tỷ lệ học suy giảm. Tuy nhiên, những tiến bộ gần đây trong huấn luyện lô lớn cả với quy tắc mở rộng tuyến tính của tỷ lệ học [22] và tỷ lệ học hằng số [53], huấn luyện lô lớn đã được chứng minh đạt được hiệu suất tương tự như đối tác mini-batch của nó.

Một quan sát lặp lại trong tài liệu [20,33,37,41,42,52] là huấn luyện lô lớn (cho ImageNet, >1000) dẫn đến suy giảm độ chính xác thử nghiệm. Mặc dù có giai đoạn khởi động trong [22], cho ImageNet, độ chính xác tốt nhất được quan sát đến mini-batch lớn của 8192 hình ảnh.

Trong bài báo này, chúng tôi đối phó với những thách thức của 1) huấn luyện với các lô lớn trong học tăng dần và 2) học bán giám sát để giảm bớt sự không khả dụng của chú thích và nhãn của con người. Đối với nhận diện giọng nói tự động (ASR), với kích thước lô lớn (>3𝑒5 phát ngôn) sử dụng lịch trình tỷ lệ học cố định, chúng tôi quan sát thấy độ chính xác thử nghiệm tốt hơn, trái ngược với sự suy giảm trong tài liệu, trong khi huấn luyện với bản chép giáo viên cho dữ liệu âm thanh tăng dần.

--- TRANG 2 ---
KDD '22, August 14–18, 2022, Washington, DC, USA Gopinath Chennupati et al.

đào tạo phân tán, đào tạo trên thiết bị cần thêm công việc [7] để thích ứng với các ràng buộc bộ nhớ và tính toán hạn chế. Tạo nhãn huấn luyện tức là bản chép lời giọng nói, gần thời gian thực, trên các thiết bị là một thách thức khác. Để giảm bớt sự không khả dụng của bản chép lời giọng nói gần thời gian thực, bản chép giáo viên có thể được sử dụng theo cách bán giám sát và/hoặc tự học. Ví dụ, xem xét vấn đề cải thiện các mô hình được triển khai trong các thiết bị biên chạy trợ lý giọng nói. Trong những trường hợp như vậy, số lượng thiết bị hàng triệu, dẫn đến quy mô lớn dữ liệu streaming được tạo ra. Chúng tôi đề xuất sử dụng xử lý lô lớn cho các phát ngôn được thu thập tại các thiết bị biên và gửi đến đám mây để xử lý, và dữ liệu chỉ được lưu trữ tạm thời. Tuy nhiên, việc triển khai tất cả hoặc một phần của các thành phần trên vào các thiết bị giọng nói hạn chế tài nguyên (như Alexa, Google Assistant và những thiết bị khác) là thách thức.

Chúng tôi xây dựng và sử dụng một hệ thống dựa trên đám mây, Học Tăng Dần cho Nhận Diện Giọng Nói Tự Động (ILASR) để huấn luyện và cập nhật các mô hình ASR sẵn sàng sản xuất. ILASR tự động hóa toàn bộ pipeline của học tăng dần theo cách bảo mật quyền riêng tư. Để thực thi các khía cạnh bảo mật quyền riêng tư trong bối cảnh ASR, chúng tôi thực thi việc gán nhãn các phát ngôn thông qua các mô hình giáo viên được huấn luyện trước không có chú thích của con người. ILASR xử lý một phát ngôn một lần trước khi cập nhật mô hình, bảo tồn thứ tự thời gian của dữ liệu. Về điều đó, những đóng góp của bài báo là:

•Một hệ thống IL dựa trên đám mây mới để huấn luyện các mô hình ASR sẵn sàng sản xuất gần thời gian thực, với một lượng lớn dữ liệu streaming được khử danh tính, mà không cần phải chép tay hoặc lưu trữ âm thanh.

•Chúng tôi cung cấp những hiểu biết mới về việc sử dụng xử lý lô lớn trong ILASR rằng nó không có tác động có hại đến độ chính xác thử nghiệm so với những phát hiện mâu thuẫn [20, 33,37,41,42,52] (trên CNN ImageNet). Chúng tôi có thể thích ứng với tỷ lệ học cố định và tối ưu hóa siêu tham số tối thiểu [34] cùng với huấn luyện lô lớn. Với tần suất hàng tháng của các cập nhật mô hình tăng dần, chúng tôi quan sát thấy các mô hình sản xuất (hội tụ trên dữ liệu cũ) cải thiện gần thời gian thực trên dữ liệu mới thuộc khoảng thời gian sáu tháng

•Chúng tôi thiết lập thực nghiệm trong sáu tháng dữ liệu rằng thứ tự thời gian so với thứ tự ngẫu nhiên của việc xử lý phát ngôn không tạo ra bất kỳ sự khác biệt có thể quan sát được trong hiệu suất.

Chúng tôi đánh giá ILASR trên ba kiến trúc transducer mạng nơ-ron hồi quy sinh viên (RNN-T) [24]. Phương pháp học bán giám sát (SSL) tạo ra bản chép máy sử dụng một mô hình ASR giáo viên lớn hơn. Các sinh viên được huấn luyện trước trên dữ liệu khử danh tính nội bộ cho đến 2020. Thông qua huấn luyện trong ILASR, chúng tôi quan sát thấy sự cải thiện 3−7% trong tỷ lệ lỗi từ (WER) so với các đường cơ sở được huấn luyện trước khi những sinh viên này được huấn luyện tăng dần trên khoảng thời gian mới sáu tháng trong 2021. Sự cải thiện trong WER được gọi là giảm tỷ lệ lỗi từ tương đối (WERR). Điều này tăng lên 20% trên các bộ thử nghiệm với từ và cụm từ mới trong 2021. Tương tự, khi các mô hình sinh viên được huấn luyện tăng dần mỗi tháng, chúng tôi quan sát thấy sự cải thiện WER, cũng như hiện tượng các mô hình trở nên cũ kỹ mà không có cập nhật thêm.

Bài báo được tổ chức như sau: phần 2 mô tả các khái niệm thiết yếu được sử dụng trong bài báo; phần 3 giải thích hệ thống được đề xuất; phần 4 mô tả các cài đặt thí nghiệm; phần 5 trình bày kết quả; phần 6 tóm tắt tài liệu liên quan và cuối cùng, phần 7 kết luận và khuyến nghị các hướng tương lai.

3 ILASR: HỌC TĂNG DẦN CHO NHẬN DIỆN GIỌNG NÓI TỰ ĐỘNG
Phần này mô tả kiến trúc ILASR và thuật toán học tăng dần tương ứng. ILASR cung cấp huấn luyện ASR đầu cuối quy mô lớn với khả năng cập nhật tăng dần các mô hình trong các cửa sổ thời gian do người dùng định nghĩa. ILASR tự động hóa toàn bộ chu kỳ sống của tạo dữ liệu, lấy mẫu, gán nhãn, phát triển mô hình, đánh giá và triển khai cho dữ liệu âm thanh gần thời gian thực.

Hình 2: Khung xương cấp cao của kiến trúc ILASR

3.1 Kiến trúc ILASR
Hình 2 cho thấy tổng quan kiến trúc của hệ thống ILASR. Hệ thống bao gồm ba thành phần chính: (1) Bộ tiền xử lý dữ liệu – là một dịch vụ runtime đám mây xử lý âm thanh gần thời gian thực từ thiết bị; (2) IL Core chịu trách nhiệm cho huấn luyện mô hình, tính toán các cập nhật mô hình và suy luận; và (3) IL Orchestrator tổng hợp các gradient tích lũy, cập nhật mô hình, thực hiện đánh giá và hoàn thiện cập nhật mô hình dựa trên kết quả đánh giá.

Train launcher khởi tạo huấn luyện ASR đầu cuối trong ILASR. Bước đầu tiên là tiền xử lý dữ liệu để chọn một tập con các thiết bị và phát ngôn tham gia vào vòng lặp huấn luyện. Việc lựa chọn có thể ngẫu nhiên hoặc dựa trên heuristics nhằm cải thiện mô hình theo một cách cụ thể. Điểm tin cậy thu được trong quá trình suy luận được sử dụng [29,30] kết hợp với heuristics như sự hiện diện của từ hiếm hoặc thẻ ngữ nghĩa và ý định quan tâm. Việc lựa chọn này có thể được mở rộng để tận dụng các tín hiệu yếu từ phản hồi người dùng như người dùng chỉ ra liệu hành động được thực hiện bởi trợ lý là tích cực hay tiêu cực hoặc phát hiện ma sát như yêu cầu lặp lại hoặc hủy bỏ. Các đặc trưng âm thanh được trích xuất và tăng cường [48] cho các phát ngôn được chọn để huấn luyện. Bản chép máy được tạo ra bằng một mô hình ASR giáo viên được huấn luyện trước sử dụng huấn luyện phân tán tiêu chuẩn. Mô hình ASR giáo viên đầu cuối dựa trên Conformer [25] giải mã âm thanh đầu vào (𝑋) để tạo ra bản chép máy (𝑌). Những cặp (𝑋,𝑌) này được sử dụng để huấn luyện mô hình. Bản chép máy hoạt động như nhãn sự thật cơ bản. ILASR tạo ra các phiên chép thông qua tự động hóa an toàn mà không có sự can thiệp hoặc xem xét của con người. Các đặc trưng được trích xuất cùng với bản chép máy trong bước này được kết hợp để huấn luyện các mô hình sinh viên sử dụng IL Core.

IL Core system có một giao diện lập trình ứng dụng (API) hỗ trợ tích lũy gradient cục bộ trên mỗi máy chủ trong fleet, và một engine suy luận ASR. IL Core API hỗ trợ FedSGD và FedAvg [44] và có thể được mở rộng để hỗ trợ các trình tối ưu liên kết khác như FedProx [51], FedMA [59], FedNova [60], và trình tối ưu liên kết thích ứng [50]. IL Orchestrator điều phối huấn luyện trên fleet ILASR. IL Orchestrator chứa bộ xuất bản gradient, bộ tổng hợp và cập nhật mô hình tăng dần. Bộ tổng hợp gradient thu thập gradient từ mỗi instance IL Core, tổng hợp chúng và sau đó áp dụng chúng cho mô hình hiện tại. Khi cập nhật mô hình hoàn thành, các gradient được thu thập sẽ bị loại bỏ và không được lưu trữ trong hệ thống điều này giúp giảm nguy cơ tấn công đảo ngược gradient. Một đánh giá nhẹ định kỳ của mô hình đảm bảo rằng mô hình đang cải thiện theo hướng đúng. Mô hình toàn cục được cập nhật trong một vòng nhất định khi hiệu suất cải thiện so với vòng trước đó. Để giảm xác suất cập nhật mô hình dẫn đến hiệu suất tệ hơn, ILASR có thể được chạy song song với các siêu tham số khác nhau. Trong kịch bản này, một trong những mô hình kết quả có thể được sử dụng nếu nó dẫn đến hiệu suất cải thiện. Sau một số vòng đủ, mô hình cuối cùng được lưu trữ cho bản phát hành mô hình tiếp theo sau một bước xác thực mô hình chi tiết.

ILASR giải quyết các mối quan tâm về bảo mật và quyền riêng tư với các mức độ chi tiết khác nhau. Vì ILASR là một hệ thống dựa trên đám mây cho IL bảo mật quyền riêng tư ở quy mô lớn, mã hóa âm thanh gồm hai lớp. Ở giai đoạn đầu tiên, mã hóa TLS [15] được áp dụng cho truyền âm thanh tiếp theo là mã hóa key-master [40] cấp ứng dụng. Quan trọng là, âm thanh được xóa trong vài phút (≤10), trong đó các cập nhật mô hình được tính toán.

3.2 ILASR: Học Tăng Dần
Thuật toán 1 Thuật toán học tăng dần ILASR
Yêu cầu: K máy chủ, L hàm mất mát, 𝑁 số bước cục bộ mỗi vòng,
B kích thước lô cục bộ, (𝜂) tỷ lệ học, 𝑃𝑟𝑘 phát ngôn gần đây được kéo bởi
máy chủ 𝑘 trong vòng 𝑟, D𝑒𝑣𝑎𝑙 tập đánh giá và Dℎ𝑡 dữ liệu phiên chép quá khứ nếu
được sử dụng để huấn luyện ôn tập.
Đảm bảo: 𝑤𝑟𝐺 mô hình toàn cục được cập nhật tăng dần và 𝑤𝑒𝑟𝑟 tỷ lệ lỗi từ
trên tập đánh giá sau 𝑟 vòng
1: Khởi tạo. 𝑤0𝐺 // bắt đầu huấn luyện với một mô hình được huấn luyện trước
2: 𝑤𝑒𝑟0 = 𝑎𝑠𝑟_𝑖𝑛𝑓𝑒𝑟𝑒𝑛𝑐𝑒_𝑒𝑛𝑔𝑖𝑛𝑒(D𝑒𝑣𝑎𝑙, 𝑤T𝐺)
3: for mỗi vòng 𝑟 = 1, 2, . . . do
4: for mỗi máy chủ 𝑘 ∈ Fleet ILASR song song do
5: 𝑤𝑟𝑘 = 𝑤𝑟−1𝐺
6: D𝑠𝑠𝑙 ← (lọc 𝑃𝑟𝑘 dựa trên tiêu chí lựa chọn phát ngôn và tạo
bản chép máy, tham khảo thuật toán 2)
7: D𝑡𝑟𝑎𝑖𝑛 ← (trộn D𝑠𝑠𝑙 và Dℎ𝑡 nếu Dℎ𝑡 được sử dụng để ôn tập, nếu không
chỉ D𝑠𝑠𝑙)
8: D𝑡𝑟𝑎𝑖𝑛 ← (chia D𝑡𝑟𝑎𝑖𝑛 thành 𝑁 lô có kích thước B)
9: for mỗi lô 𝑏𝑖 từ 𝑏1 đến 𝑏𝑁 do
10: 𝑤𝑟𝑘 ← optimizer𝑘.update(𝜂, ∇L(𝑤; 𝑏𝑖))
11: end for
12: end for
13: 𝑤𝑟𝐺 ← 1/K ∑K𝑘=1 𝑤𝑟𝑘
14: 𝑤𝑒𝑟𝑟 ← 𝑎𝑠𝑟_𝑖𝑛𝑓𝑒𝑟𝑒𝑛𝑐𝑒_𝑒𝑛𝑔𝑖𝑛𝑒(D𝑒𝑣𝑎𝑙, 𝑤𝑟𝐺)
15: 𝑤𝑟𝐺 = 𝑤𝑟−1𝐺 nếu 𝑤𝑒𝑟𝑟 > 𝑤𝑒𝑟𝑟−1 // Trở lại mô hình trước đó nếu không
phải là mô hình tốt hơn.
16: end for

--- TRANG 3 ---
ILASR: Học Tăng Dần Bảo Mật Quyền Riêng Tư cho Nhận Diện Giọng Nói Tự Động ở Quy Mô Sản Xuất KDD '22, August 14–18, 2022, Washington, DC, USA

Thuật toán 1 cho thấy chính sách học tăng dần trong khung công tác ILASR. Mô hình mới thu được trong mỗi vòng chỉ được sử dụng nếu nó hoạt động tốt hơn mô hình từ vòng trước đó. Các lần chạy song song của thuật toán với các siêu tham số khác nhau để huấn luyện một ensemble các mô hình được cập nhật tăng dần có thể đảm bảo rằng có ít nhất một mô hình hoạt động tốt hơn mô hình từ vòng trước đó. Một cân nhắc thú vị khác là hiệu ứng của việc quên thảm khốc [17,21,43] trong học tăng dần của khung công tác ILASR, nơi hành vi đã học trước đó của một mô hình bị quên với các cập nhật mới. Điều này có thể được giảm thiểu với việc ôn tập [2] của việc huấn luyện trên một tập con dữ liệu lịch sử được chú thích cùng với dữ liệu mới.

Chúng tôi mô tả phương pháp tạo dữ liệu SSL trong thuật toán 2. Chúng tôi lấy mẫu ngẫu nhiên một tập con âm thanh gần thời gian thực, để chuẩn bị một pool dữ liệu (P), và tính toán số lượng phát ngôn mục tiêu (U) cần được lấy mẫu từ P, nơi mỗi phát ngôn bao gồm một giá trị tin cậy được tính toán trước [57]. Đối với mỗi bin tin cậy, ví dụ tin cậy trong (600,700] nơi tin cậy được đánh giá trên thang điểm từ 0 đến 1000, các phát ngôn được lọc để tuân thủ tiêu chí tin cậy. Các phát ngôn được lấy mẫu ngẫu nhiên từ trên được đặt để lấy số lượng phát ngôn mục tiêu và gửi đến IL core để huấn luyện, chúng được xóa ngay khi mô hình thực hiện một lần qua nó lần đầu tiên. Các tiêu chí bổ sung như sự hiện diện của từ hiếm, sự hiện diện của thẻ ngữ nghĩa mong muốn cũng có thể được sử dụng.

Thuật toán 2 Quy trình lựa chọn dữ liệu SSL
Yêu cầu: 𝜏 danh sách các bin tin cậy phát ngôn
Đảm bảo: X tập dữ liệu
1: P = 𝑟𝑎𝑛𝑑𝑜𝑚_𝑠𝑎𝑚𝑝𝑙𝑒() // chuẩn bị một pool dữ liệu ngẫu nhiên
2: P = 𝑡𝑒𝑎𝑐ℎ𝑒𝑟_𝑑𝑒𝑐𝑜𝑑𝑒(P) // tạo bản chép máy
3: U = 𝑐𝑎𝑙𝑐_𝑢𝑡𝑡𝑒𝑟𝑎𝑛𝑐𝑒_𝑐𝑜𝑛𝑓𝑖𝑑𝑒𝑛𝑐𝑒(P).
4: Q = [] // một bin cho mỗi phạm vi tin cậy
5: for 𝑐 ∈ 𝜏 do
6: Q[𝑐] = 𝑓𝑖𝑙𝑡𝑒𝑟_𝑢𝑡𝑡𝑒𝑟𝑎𝑛𝑐𝑒𝑠(U, 𝑐)
7: X = 𝑠𝑒𝑙𝑒𝑐𝑡_𝑢𝑡𝑡𝑒𝑟𝑎𝑛𝑐𝑒𝑠(Q) // có thể bao gồm các tiêu chí bổ sung
như sự hiện diện của từ hiếm hoặc thẻ ngữ nghĩa mong muốn
8: end for

4 THỰC NGHIỆM
Chúng tôi mô tả các tập dữ liệu, cấu hình mô hình và cài đặt thí nghiệm được sử dụng trong bài báo này, để cung cấp hiểu biết và nghiên cứu học tăng dần bảo mật quyền riêng tư thông qua ILASR.

4.1 Tập dữ liệu
Tất cả dữ liệu giọng nói được sử dụng để huấn luyện và đánh giá đều được khử danh tính.

Tập huấn luyện Các luồng âm thanh được chuẩn bị thành các tập dữ liệu huấn luyện offline. Các tập dữ liệu huấn luyện sau được sử dụng để thí nghiệm:

Tập dữ liệu huấn luyện trước: Một tập dữ liệu huấn luyện trước 480k giờ được sử dụng để xây dựng các mô hình huấn luyện trước. Mô hình được huấn luyện trước này được sử dụng làm điểm khởi đầu cho huấn luyện tăng dần với hệ thống ILASR. Điều này bao gồm hai tập dữ liệu:
(1) 120K giờ HT: Dữ liệu được chép bởi con người (HT) từ 2020 và những năm trước đó
(2) 360K giờ SSL: Dữ liệu được chép bởi máy trong 2020

Tập dữ liệu huấn luyện tăng dần: Chúng tôi coi cuối năm 2020 là ngày bắt đầu cho huấn luyện tăng dần của các mô hình ASR.
(1) 180K giờ ILASR SSL: Dữ liệu được chép bởi máy được tạo ra trong khoảng thời gian sáu tháng trong 2021 (Tháng 1 đến Tháng 6) và được sử dụng để huấn luyện gần thời gian thực của hệ thống ILASR.

Tập thử nghiệm: Chúng tôi đánh giá các mô hình trên các tập thử nghiệm được chép bởi con người (HT) nội bộ.

Chung: Bao gồm ba tập dữ liệu HT từ các phạm vi thời gian khác nhau đại diện cho trường hợp sử dụng chung. Nó bao gồm một tập thử nghiệm 37 giờ từ 2021, một tập thử nghiệm 10 giờ từ 2020 và một tập thử nghiệm 96 giờ từ 2018-2019.

Hiếm: Bao gồm ba tập dữ liệu HT từ các phạm vi thời gian khác nhau, nơi các phiên chép chứa ít nhất một từ hiếm. Từ hiếm là những từ trong đuôi dài của từ vựng được xác định bởi tần suất từ. Điều này bao gồm một tập thử nghiệm 44 giờ từ 2021, một tập thử nghiệm 44 giờ từ 2020, và một tập thử nghiệm 27 giờ từ 2018-2019.

Delta: Điều này bao gồm một tập thử nghiệm HT 22 giờ ghi lại sự thay đổi trong tần suất của từ trong 2021 so với 2020. Các phiên chép được lọc dựa trên 1-gram, 2-gram và 3-gram có tần suất cao hơn 5 lần trong 2021 so với 2020. Tập thử nghiệm này nắm bắt những thay đổi trong phân phối dữ liệu và rất liên quan để đo lường tác động của học tăng dần với ILASR.

Nhắn tin: Bao gồm hai tập dữ liệu HT bao gồm dữ liệu miền nhắn tin và truyền thông. Nó bao gồm một thử nghiệm HT 2.7 giờ từ 2020 và một tập thử nghiệm HT 45.5 giờ từ 2018-2019.

Tập dữ liệu hàng tháng (2021): Chúng tôi sử dụng sáu tập thử nghiệm hàng tháng từ Tháng 1 đến Tháng 6 2021 để đánh giá thiết lập học tăng dần của ILASR. Mỗi tập dữ liệu này được gọi là (Jan, Feb, ···, June) và mỗi tháng có trung bình 70 giờ dữ liệu. Chúng tôi tiếp tục báo cáo kết quả trên các tập dữ liệu 3 tháng 𝐽𝑎𝑛−𝑀𝑎𝑟 bao gồm dữ liệu từ Jan, Feb, Mar và 𝐴𝑝𝑟−𝐽𝑢𝑛 bao gồm dữ liệu từ Apr, May, June.

4.2 Chi tiết mô hình
Đặc trưng: Các đặc trưng âm thanh là năng lượng filter-bank log-mel 64 chiều [46] được tính toán trong cửa sổ 25ms, với độ dịch chuyển 10ms. Các đặc trưng được tính toán trên 3 khung 10ms liên tiếp được xếp chồng và lấy mẫu phụ để tạo ra các đặc trưng 192 chiều ở tốc độ khung 30ms, và được cung cấp làm đầu vào cho mô hình ASR. Các phiên chép sự thật cơ bản được tokenize thành 2500 đơn vị sub-word sử dụng một mô hình ngôn ngữ uni-gram [35].

Mô hình: Mô hình giáo viên: Mô hình giáo viên được sử dụng để tạo ra bản chép máy SSL. Chúng tôi có ba mô hình giáo viên có sẵn: 𝑇3 là một mô hình giáo viên (một hệ thống ASR hybrid RNN-HMM thông thường [6]) được huấn luyện trên 100k giờ dữ liệu chỉ đến 2019. Bản chép máy từ 𝑇3 được sử dụng để bootstrap và cung cấp phiên chép cho tập dữ liệu huấn luyện trước SSL 360k giờ gần đây hơn. Tập dữ liệu huấn luyện trước 480k giờ, bao gồm tập dữ liệu SSL 360k giờ dựa trên 𝑇3 và tập dữ liệu HT 120k giờ, được sử dụng để huấn luyện hai mô hình giáo viên được cập nhật: (1) 𝑇1: Một kiến trúc ASR dựa trên conformer lớn hơn [25] được huấn luyện trên 480k giờ. 𝑇1 có 122M tham số, một bộ mã hóa với 17×512 lớp LSTM, 8 đầu attention với kernel convolution 32 chiều. Mạng dự đoán sử dụng 2×1024 lớp LSTM. (2) 𝑇2 là một hệ thống ASR hybrid RNN-HMM thông thường [6] và được huấn luyện trên cùng tập dữ liệu 480k giờ. Cuối cùng, các mô hình sinh viên cho tất cả thí nghiệm trong bài báo được huấn luyện trên các tập dữ liệu SSL sử dụng mô hình giáo viên 𝑇1 gần đây nhất.

--- TRANG 4 ---
KDD '22, August 14–18, 2022, Washington, DC, USA Gopinath Chennupati et al.

Trong phần 5.1.3, nhằm mục đích ablation so sánh các giáo viên khác nhau, chúng tôi huấn luyện các mô hình sinh viên trên các tập dữ liệu SSL dựa trên 𝑇2 và 𝑇3.

Mô hình sinh viên: Các mô hình sinh viên dựa trên các kiến trúc RNN-T dựa trên LSTM khác nhau. Chúng khác nhau về số lượng lớp bộ mã hóa và tốc độ khung đặc trưng. Hai mô hình sinh viên được mô tả như sau. 𝑟𝑛𝑛𝑡_60𝑚 chứa 60M tham số với bộ mã hóa LSTM 5×1024, mạng dự đoán LSTM 2×1024 và một mạng kết hợp feed-forward với kích hoạt tanh. Các embedding đầu vào của mạng dự đoán là 512 chiều. SpecAugment [48] được sử dụng trên các đặc trưng âm thanh. 𝑟𝑛𝑛𝑡_90𝑚 chứa 90M tham số với bộ mã hóa lớp LSTM 8×1024, một mạng dự đoán có kích thước 2×1024, và một mạng kết hợp feed-forward với kích hoạt tanh. Các embedding đầu vào của mạng dự đoán sử dụng embedding 512 chiều và một tokenizer sub-word 2500 từ một mô hình ngôn ngữ uni-gram. SpecAugment được sử dụng trên các đặc trưng âm thanh. Bộ mã hóa sử dụng RNN đa lớp giảm thời gian [54] dựa trên LSTM (cho tốc độ huấn luyện và suy luận) với tốc độ khung đặc trưng được đặt thành 3 lớp. Mỗi lớp khung đặc trưng này có 1536 đơn vị và projection LSTM với kích thước 512.

Các mô hình 𝑟𝑛𝑛𝑡_90𝑚 và 𝑟𝑛𝑛𝑡_60𝑚 được huấn luyện trước trên cả dữ liệu HT 120k giờ và 340k giờ dữ liệu SSL được tạo ra bằng các nhãn được giải mã bởi giáo viên (𝑇1). Dữ liệu được chép bởi con người được sử dụng trong huấn luyện trước sử dụng dữ liệu đến cuối năm 2020, trong khi dữ liệu SSL là trong năm 2020. Đối với các thí nghiệm của chúng tôi trong bài báo này, chúng tôi tiếp tục huấn luyện các mô hình sinh viên RNN-T được huấn luyện trước ở trên sử dụng tổng số 180k giờ dữ liệu SSL (nhãn được tạo bởi giáo viên) có sẵn trong cửa sổ thời gian 6 tháng trong 2021.

Chi tiết huấn luyện: Chúng tôi sử dụng các tham số sau để huấn luyện cả mô hình giáo viên và sinh viên. Hệ thống được chạy trên một fleet gồm 200 node. Chúng tôi áp dụng một lịch trình tỷ lệ học warm-up nơi 𝑙𝑟 = 1𝑒−7 cho 3000 bước đầu tiên, tiếp theo là tỷ lệ học hằng số 5𝑒−4 đến 50k bước, sau đó suy giảm exponential (𝑙𝑟 = 1𝑒−5) từ 50k đến 750k bước với trình tối ưu Adam (siêu tham số là 𝛽1 = 0.9, 𝛽2 = 0.99).

Chúng tôi thí nghiệm với nhiều kích thước lô lớn (9k, 18k, 73k, 147k, 215k, 307k) thông qua tích lũy gradient. Lưu ý rằng những tích lũy này có hiệu ứng ngầm của việc thay đổi các giá trị gradient do tổng các gradient trên một lô lớn. Chúng tôi xử lý các lô lớn mà không thay đổi lịch trình 𝑙𝑟 trong khi tích lũy các gradient. Hiệu suất của những mô hình này được đo bằng giảm tỷ lệ lỗi từ tương đối (WERR) so với các đường cơ sở tương ứng. WER là tỷ lệ của khoảng cách chỉnh sửa với độ dài chuỗi, nơi khoảng cách chỉnh sửa là độ dài của chuỗi ngắn nhất của các phép toán chèn, xóa và thay thế trên việc biến đổi một chuỗi được dự đoán thành mục tiêu.

5 KẾT QUẢ & THẢO LUẬN
Trong phần này, chúng tôi phân tích hiệu suất của học tăng dần trong ILASR. Cụ thể, chúng tôi phân tích hiệu suất của học tăng dần trong ILASR về giảm tỷ lệ lỗi từ tương đối (WERR) so với các mô hình sinh viên được huấn luyện trước ban đầu làm đường cơ sở.

Từ Bảng 1, chúng ta thấy rằng ILASR cải thiện một mô hình cơ sở được huấn luyện mạnh lên đến 3% trên các tập thử nghiệm trong 2021 mà leo lên 20% trên tập dữ liệu delta bao gồm từ và cụm từ mới hoặc thịnh hành.

Bảng 1: Cải thiện WER tương đối % từ mô hình ban đầu khi được huấn luyện với hệ thống ILASR

ILASR
Thời gian Tập thử nghiệm replay no replay
2021 Rare 0.72% 0.66%
Delta 20.10% 23.99%
General 1.23% 0.41%
Jan-Mar 1.25% 1.50%
Apr-Jun 2.73% 3.09%
2020 Rare 0.62% 0.62%
General 0.00% -0.72%
Message -0.83% -2.04%
2018-2019 Rare -0.63% -0.63%
General -1.21% -2.6%
Message -2.82% -3.42%

[Hình 3: WERR hàng tháng (%) cho học tăng dần trong ILASR cho 𝑟𝑛𝑛𝑡_60𝑚 trên sáu tập thử nghiệm hàng tháng (𝐽𝑎𝑛–𝐽𝑢𝑛) khi được đo so với mô hình bắt đầu so với mô hình được huấn luyện tăng dần trong mỗi tháng.]

Đồng thời, hiệu suất trên các tập thử nghiệm chung và đuôi cũ hơn không thấy nhiều suy giảm.

Quên thảm khốc là một trong những vấn đề mà học tăng dần cần vượt qua để có hiệu suất nhất quán trên cả dữ liệu cũ và mới. Trong Bảng 1, chúng tôi so sánh hiệu suất của học tăng dần dựa trên replay, nơi một phần được lấy mẫu phụ của dữ liệu được chép bởi con người 120K giờ cũng được tiêu thụ trong huấn luyện mô hình trong khi đối tác no replay không liên quan đến điều đó. Như được chứng minh trong Bảng 1, huấn luyện dựa trên replay có xu hướng vượt trội hơn đối tác no replay của nó trên các tập thử nghiệm cũ hơn như mong đợi từ tài liệu IL.

Tiếp theo, chúng tôi đánh giá các mô hình ILASR được huấn luyện tăng dần trên các tập thử nghiệm chi tiết được chuẩn bị trong mỗi tháng trong sáu tháng (Jan-Jun) của 2021, xem Hình 3. Đối với tất cả các đánh giá trong Hình 3, chúng tôi báo cáo WERR trong mỗi tháng so với mô hình được huấn luyện trước ban đầu (ví dụ, WERR trong 𝑀𝑎𝑦 là sự khác biệt tương đối giữa WER của mô hình 𝑀𝑎𝑦 và mô hình được huấn luyện trước). Kết quả cho thấy cải thiện tăng dần trong hiệu suất trên tất cả sáu tập thử nghiệm hàng tháng từ tháng này sang tháng khác trong huấn luyện ILASR. Điều này gợi ý

--- TRANG 5 ---
KDD '22, August 14–18, 2022, Washington, DC, USA Gopinath Chennupati et al.

[Hình 4: Đối với 𝑟𝑛𝑛𝑡_60𝑚, mô hình được huấn luyện trước được huấn luyện trên dữ liệu có sẵn đến 12/2019. Huấn luyện mô hình được huấn luyện trước này ở chế độ tăng dần cho chín tháng tiếp theo (𝐽𝑎𝑛−𝑆𝑒𝑝) trong 2020. Trục x cho thấy mô hình tăng dần hàng tháng, nơi mô hình từ tháng trước được tinh chỉnh trên dữ liệu trong tháng hiện tại; trục y cho thấy WER tương đối trong mỗi tháng w.r.t mô hình được huấn luyện trước ban đầu. Mỗi đường cong đại diện cho tập thử nghiệm của tháng tương ứng.]

rằng huấn luyện tăng dần giúp nắm bắt các xu hướng mới trong các khoảng thời gian trong khi mô hình đang thích ứng với những thay đổi tăng dần trong dữ liệu. Cũng đáng chú ý là sự cải thiện tăng dần không đến với chi phí của việc quên thảm khốc. Thú vị hơn, các mô hình được huấn luyện với dữ liệu đến 𝑀𝑎𝑦/𝐽𝑢𝑛𝑒 làm suy giảm hiệu suất trên tập thử nghiệm 𝐽𝑢𝑛𝑒, điều này cải thiện sau khi mô hình được huấn luyện trên dữ liệu có sẵn từ 𝑀𝑎𝑦/𝐽𝑢𝑛𝑒. Điều này gợi ý rõ ràng về bản chất thích ứng của việc nắm bắt những thay đổi trong dữ liệu trong các khoảng thời gian mới trong ILASR.

Để tăng cường hơn nữa các tuyên bố học tăng dần, chúng tôi phân tích các mẫu học tăng dần trong thời gian dài hơn trong các khoảng thời gian giữa 𝐽𝑎𝑛−𝑆𝑒𝑝 trong 2020. Hình 4 cho thấy các mẫu học trên cơ sở hàng quý cho ba quý đầu tiên (Q1–Q3) của 2020. Trong 2020 𝑄1 và 𝑄2, WERR cải thiện ban đầu và sau đó giảm khi huấn luyện mô hình tăng dần tiến triển trên cơ sở tháng qua tháng. Sự suy giảm (trong khi tốt hơn đường cơ sở) là một minh chứng của việc quên khi các cập nhật mới hơn được ưu tiên hơn các tập thử nghiệm cũ nhiều tháng. Do đó, trong 2020 𝑄3, hiệu suất cải thiện mà không có bất kỳ xu hướng giảm nào, điều này là do thực tế rằng các mô hình tiếp tục học tháng qua tháng trong khi các tập thử nghiệm cũng thuộc về cùng các khoảng thời gian. Những xu hướng này gợi ý rằng các kỹ thuật được đề xuất giúp cải thiện hiệu suất tăng dần ngay cả trong các khoảng thời gian dài hơn trong khi hạn chế các hồi quy trên dữ liệu đánh giá cũ hơn.

Tiếp theo, chúng tôi khám phá một số lựa chọn thiết kế đóng vai trò quan trọng trong hiệu suất của ILASR và chia sẻ hiểu biết của chúng tôi về các lựa chọn thiết kế.

5.1 Lựa chọn Thiết kế: ILASR
Chúng tôi khám phá các lựa chọn thiết kế sau trong bối cảnh khung công tác ILASR: 1) hiệu ứng của kích thước lô lớn trên hiệu suất của các mô hình sinh viên; 2) hiệu ứng thời gian trên việc xử lý dữ liệu trong ILASR; 3) phân tích tầm quan trọng của các mô hình giáo viên khác nhau trong ILASR.

5.1.1 Huấn luyện bền vững với kích thước lô lớn. Chúng tôi sử dụng các lô lớn trong ILASR qua tích lũy gradient. Khi kích thước lô hiệu quả tăng, số bước tối ưu hóa hoặc cập nhật giảm khi cùng một lượng dữ liệu được xử lý. Kích thước lô lớn hơn sẽ yêu cầu ít bước tối ưu hóa hơn và ngược lại cho cùng một lượng dữ liệu. Việc sử dụng các lô lớn tăng tốc huấn luyện (được hiển thị trong [64]),

Bảng 2: Hiệu ứng của các lô lớn trên sự cải thiện hiệu suất tương đối (về WERR, %) của tất cả ba mô hình khi được tinh chỉnh trong ILASR.

[THIS IS TABLE: Shows effect of different batch sizes (9k to 307k) on WERR performance across different time periods and test sets for rnnt_60m model]

điều này tương tự trong ILASR. Lý do kích thước lô lớn có liên quan trong hệ thống ILASR là có những hạn chế về việc các gradient có thể được tổng hợp nhanh như thế nào và mô hình toàn cục được phân phối đến các máy chủ trong fleet. Do đó, một số bước cập nhật hạn chế có thể diễn ra trong một khoảng thời gian so với huấn luyện phân tán offline dựa trên GPU. Hơn nữa, khi dữ liệu đến theo cách streaming và không được lưu trữ, nó cần được tiêu thụ khi và khi nó đến, gần thời gian thực. Đối với mỗi số lượng cập nhật hạn chế, một lượng lớn dữ liệu streaming có sẵn.

Chúng tôi khám phá sự đánh đổi giữa các lô lớn và hiệu suất mô hình. Bảng 2 cho thấy hiệu ứng của các lô lớn trên hiệu suất của một mô hình sinh viên được huấn luyện trong ILASR. Hiệu suất (WERR) là tương đối so với mô hình sinh viên được huấn luyện trước tương ứng. Đường cơ sở này yếu hơn, do đó cải thiện lớn hơn. Chúng tôi thấy rằng việc tăng multiplier lô (kích thước lô hiệu quả) có hiệu ứng không đáng kể trên WER. Khi kích thước lô tăng từ 9K đến 300K phát ngôn, sự khác biệt trong độ chính xác là không đáng kể.

Quan trọng hơn, phát hiện này trái ngược với các hiệu ứng suy giảm độ chính xác thử nghiệm được báo cáo trong tài liệu [20,22,33,37,41,42,52, 56] với việc sử dụng các lô lớn. Chúng tôi quan sát thấy rằng sự suy giảm như vậy không rõ ràng đối với huấn luyện mô hình trong ILASR. Mặc dù, các nỗ lực trong tài liệu không có sự biện minh toán học mạnh, Goyal et al. [22] lý giải sự suy giảm hiệu suất cho các vấn đề tối ưu hóa, do đó sử dụng warm-up để giảm thiểu sự suy giảm. Tương tự, trong trường hợp của chúng tôi, chúng tôi quy các lợi ích và/hoặc không suy giảm hiệu suất cho yếu tố sau. Các mô hình được khởi tạo là được huấn luyện trước đã hội tụ trên dữ liệu từ khoảng thời gian trước đó trái ngược với khởi tạo ngẫu nhiên trong huấn luyện lô lớn trong

--- TRANG 6 ---
ILASR: Học Tăng Dần Bảo Mật Quyền Riêng Tư cho Nhận Diện Giọng Nói Tự Động ở Quy Mô Sản Xuất KDD '22, August 14–18, 2022, Washington, DC, USA

Bảng 3: Tác động của thứ tự thời gian (thời gian so với ngẫu nhiên) của việc xử lý dữ liệu huấn luyện trong ILASR cho cả với và không có replay của các phiên chép con người.

[THIS IS TABLE: Shows impact of temporal order on training data processing in ILASR, with columns for Time, Test-set, and Chrono vs. random (replay/no replay)]

tài liệu, thường, những mô hình này được huấn luyện từ đầu (mặc dù có vài epoch ban đầu trong warm-up) trong tài liệu.

5.1.2 Tác động của dữ liệu được sắp xếp theo thời gian. Một khía cạnh quan trọng của IL là dữ liệu được xử lý theo thời gian như có sẵn, theo thời gian. Chúng tôi phân tích hiệu ứng của thứ tự xử lý (thời gian so với ngẫu nhiên) cho sáu tháng trong 2021. Lưu ý, thứ tự ngẫu nhiên giống như xáo trộn dữ liệu trong huấn luyện phân tán thông thường của các mô hình sâu. Dữ liệu thời gian không phải IID theo thời gian khi các phát ngôn có sự tương quan với thời gian trong ngày (ví dụ, yêu cầu báo lại báo thức vào buổi sáng hoặc bật đèn thông minh sau hoàng hôn). Chúng tôi thấy rằng không có sự khác biệt trong hiệu suất của việc xử lý dữ liệu theo thời gian so với ngẫu nhiên như được mô tả trong Bảng 3. Hơn nữa, trong cả hai trường hợp thời gian và ngẫu nhiên, các cải thiện so với đường cơ sở ban đầu đều rõ ràng (xem Bảng 1).

Bảng 4: Hiệu suất (về WERR, %) của giáo viên ASR hybrid RNN-HMM (𝑇2) và giáo viên ASR hybrid RNN-HMM hai chiều (𝑇3) so với giáo viên Conformer (𝑇1). Dấu âm (-) thể hiện rằng 𝑇1 hoạt động tệ hơn trong khi phần còn lại cho thấy rằng 𝑇1 là mô hình giáo viên hoạt động tốt nhất.

[THIS IS TABLE: Shows performance comparison between different teacher models T1, T2, and T3]

5.1.3 Ablations với giáo viên và sinh viên. Chúng tôi thí nghiệm với ba mô hình giáo viên khác nhau được huấn luyện cho các phạm vi thời gian khác nhau với các kiến trúc khác nhau. Thí nghiệm này giúp chúng tôi khám phá tầm quan trọng của việc giữ một giáo viên được cập nhật và hiệu quả hơn. Ba giáo viên là: 𝑇1 là dựa trên Conformer được giải thích trước đó trong phần 4.2; 𝑇2 là một mô hình hybrid RNN-HMM thông thường [6]; 𝑇3 là một mô hình ASR hybrid RNN-HMM hai chiều thông thường. 𝑇1 và 𝑇2 được huấn luyện trên cùng lượng dữ liệu đến cuối năm 2020 trong khi 𝑇3 được huấn luyện trên dữ liệu (tổng cộng ∼100k giờ dữ liệu HT) có sẵn đến cuối năm 2019.

Bảng 4 so sánh hiệu suất của các mô hình giáo viên. Trung bình, 𝑇1 tốt hơn phần còn lại của hai giáo viên, 𝑇1 > 𝑇2 > 𝑇3 trên dữ liệu mới phản ánh tầm quan trọng của việc giữ mô hình giáo viên được cập nhật. Giáo viên dựa trên Conformer, 𝑇1 tốt hơn phần còn lại của hai giáo viên còn lại. Sự khác biệt hiệu suất tương đối, khi được đo trên bốn tập thử nghiệm tiêu chuẩn là, 𝑇1 tốt hơn 𝑇2 và 𝑇3 với 11.85% và 7.96% WERR, tương ứng.

Bảng 5: Hiệu suất (về WERR) của các mô hình sinh viên khi được huấn luyện với bản chép máy được tạo ra từ mỗi mô hình giáo viên khác nhau trong ba mô hình.

[THIS IS TABLE: Shows performance of student models when trained with machine transcripts from different teacher models]

Bảng 5 cho thấy WERR của hai mô hình sinh viên (𝑟𝑛𝑛𝑡_90𝑚 và 𝑟𝑛𝑛𝑡_60𝑚) khi được huấn luyện sử dụng bản chép máy được tạo ra từ ba mô hình giáo viên. Chúng tôi quan sát thấy rằng cả hai sinh viên đều tương tự về hiệu suất. Trung bình, cho 𝑟𝑛𝑛𝑡_90𝑚, huấn luyện dựa trên 𝑇1 tốt hơn 𝑇2 và 𝑇3, với 4.66% và 3.25% WERR, tương ứng. Cho 𝑟𝑛𝑛𝑡_60𝑚, 𝑇1 tốt hơn 𝑇2 và 𝑇3 với 5.96 và 2.18% cải thiện WERR tương đối tương ứng. Các cải thiện lớn hơn so với Bảng 1 vì những thí nghiệm này được thực hiện với 3 tháng dữ liệu sử dụng đường cơ sở yếu hơn. Thực tế, cả hai sinh viên có cùng thứ tự hiệu suất như các giáo viên, đó là 𝑇1 > 𝑇2 > 𝑇3 ngay cả sau khi huấn luyện trong IL trên dữ liệu mới. Quan trọng hơn, mức độ cải thiện trong huấn luyện sinh viên (đúng cho cả hai mô hình sinh viên) không có cùng quy mô như sự khác biệt trong giáo viên. Ví dụ, giáo viên dựa trên Conformer (𝑇1) tốt hơn 𝑇3 7.96%, trong khi sinh viên 𝑟𝑛𝑛𝑡_90𝑚 được huấn luyện với phiên chép Conformer (𝑇1) tốt hơn 3.25% so với mô hình được huấn luyện với phiên chép 𝑇3. Điều này gợi ý rằng các mô hình giáo viên tốt hơn dẫn đến việc cải thiện hiệu suất sinh viên nhưng sự khác biệt (cùng sinh viên được huấn luyện với các mô hình giáo viên khác nhau) hẹp hơn. Nói cách khác, một mô hình giáo viên tốt hơn đáng kể có thể có tác động hạn chế trong việc cải thiện các mô hình sinh viên trong ILASR.

6 CÔNG TRÌNH LIÊN QUAN
SGD gradients mini và lớn: Stochastic gradient descent (SGD) điều khiển việc huấn luyện mạng nơ-ron với mini batch. Các mini batch lớn [22,27,53,64] giảm số lượng cập nhật với kích thước bước lớn. Đơn giản tăng kích thước lô giảm độ chính xác thử nghiệm [33] khi các gradient được tích hợp. Độ chính xác tập thử nghiệm có thể được cải thiện với các lô lớn tỷ lệ thuận với tỷ lệ học. Quy tắc mở rộng tuyến tính đơn giản này không hiệu quả, điều này cần thiết một giai đoạn warm-up [22]. Thay vì suy giảm tỷ lệ học, việc tăng kích thước lô trong quá trình huấn luyện [53] giúp giảm các bước truyền thông để cập nhật mô hình và cải thiện độ chính xác thử nghiệm. Federated averaging [44] (FedAvg) theo một chiến lược tương tự của việc cập nhật gradient đồng bộ. Do đó, mô hình tập trung đơn giản tổng hợp các cập nhật từ nhiều client khác nhau. Do đó, chúng tôi áp dụng những cập nhật lô đồng bộ lớn này (như trong [53]) cho mô hình trong cài đặt liên kết (thiết kế tương tự được đề xuất trong [5]) cả trong algoritm SGD và averaging liên kết. Xem xét các hiệu ứng tiêu cực của huấn luyện lô lớn trên độ chính xác thử nghiệm trong tài liệu [9,20,33,37,41,42,52], một post-local SGD được đề xuất [38], lấy cảm hứng từ FedAvg, nơi họ áp dụng huấn luyện SGD mini-batch dựa trên warm-up [22] cho huấn luyện ban đầu trước khi khởi chạy FedAvg. Tương tự, SGD phân tán cho giọng nói [55] và huấn luyện quy mô lớn với hàng triệu giờ giọng nói [49] đã giúp tăng tốc sản xuất cho các mô hình ASR.

Học Bán giám sát trong ASR: Việc học bán giám sát được mô tả trong [31,32] sử dụng auto-encoder để trích xuất các đặc trưng giọng nói và văn bản từ dữ liệu văn bản và giọng nói không ghép cặp. ASR bán giám sát với các đặc trưng filter-bank [39] sử dụng các biểu diễn âm thanh có bối cảnh sâu với lượng nhỏ dữ liệu được gán nhãn. Việc chưng cất yếu của các cặp âm thanh-văn bản dẫn từ các kỹ thuật không giám sát trong [36] giúp cải thiện ASR đầu cuối. Các phương pháp bán giám sát trong [61] kết hợp tăng cường dữ liệu thông qua spectral augment [48] và điều chỉnh tính nhất quán để cải thiện hiệu suất. Dropout cung cấp sức mạnh của ensemble, các nỗ lực dropout bán giám sát trong [14] cải thiện độ chính xác nhãn giả và hiệu suất mô hình trong ASR. Gần đây, công trình trong [63] sử dụng học bán giám sát tương phản với pseudo-labeling trong việc chép lại nội dung video. Trong bài báo này, chúng tôi sử dụng pseudo-label được tạo ra từ một mô hình giáo viên trong cài đặt liên kết với kích thước lô lớn.

Học Không giám sát trong ASR: Một lĩnh vực liên quan là việc huấn luyện biểu diễn, nền tảng, hoặc các mô hình upstream từ đầu sử dụng khối lượng lớn dữ liệu không gán nhãn. Mô hình này sau đó có thể được tinh chỉnh cho các trường hợp sử dụng downstream như ASR, nhận dạng người nói, trong số những cái khác. Mô hình này được đối chiếu với trường hợp sử dụng các cập nhật tăng dần cho mô hình ASR được huấn luyện trước được trình bày trong công trình này. Một khảo sát toàn diện về các phương pháp như vậy cho việc học biểu diễn giọng nói trong [45]. Mô hình upstream được huấn luyện với một nhiệm vụ pretext như một phương pháp sinh để dự đoán hoặc tái tạo đầu vào được cho một góc nhìn hạn chế (ví dụ dữ liệu quá khứ, masking) như autoregressive predictive coding [12]. Trong một phương pháp tương phản, một biểu diễn được học gần với một mẫu tích cực và xa hơn từ các mẫu tiêu cực; wav2vec 2.0 [3] là một mẫu điển hình nơi biểu diễn được huấn luyện để gần với một vector mục tiêu được lượng tử hóa. Cuối cùng, trong các phương pháp dự đoán [4,10,28], nhiệm vụ pretext là dự đoán cho các khung thời gian đầu vào được mask, một phân phối trên một từ vựng rời rạc như các đặc trưng log-mel được phân cụm. Các mô hình ASR được huấn luyện trước sử dụng những kỹ thuật này có thể được cập nhật sử dụng ILASR.

7 KẾT LUẬN
Chúng tôi đề xuất khung công tác ILASR cho học tăng dần bảo mật quyền riêng tư của các hệ thống nhận diện giọng nói tự động đầu cuối. ILASR là một bước tiến lớn cho các hệ thống ASR cấp sản xuất, đặc biệt cho các cập nhật tăng dần tự động của những hệ thống này. Trong nghiên cứu huấn luyện gần thời gian thực này với ILASR, chúng tôi học được rằng ngay cả các mô hình ASR cấp sản xuất đã hội tụ: 1) có thể được cải thiện đáng kể theo cách tăng dần với 3% cải thiện chung có thể lên đến 20% trên các tập thử nghiệm với từ hoặc cụm từ mới; 2) huấn luyện với các lô lớn phát sinh như kết quả của các ràng buộc truyền thông không dẫn đến suy giảm; 3) huấn luyện replay bộ nhớ hiệu quả trong việc giảm thiểu việc quên thảm khốc trên các tập thử nghiệm cũ hơn; 4) không có tác động đáng kể của việc xử lý dữ liệu theo thời gian so với ngẫu nhiên trong IL cho nhận dạng giọng nói trong khoảng thời gian sáu tháng; và cuối cùng; 5) có sự cải thiện đáng kể trong các mô hình giáo viên được sử dụng để tạo ra bản chép máy không chuyển thành cùng quy mô cải thiện trong sinh viên.

Trong tương lai, chúng tôi sẽ khám phá tính hữu ích của sinh viên ồn ào cho việc tự học lặp thay vì dựa vào các mô hình giáo viên trong ILASR. Nhận dạng giọng nói trên thiết bị hạn chế tài nguyên thời gian thực vẫn là một thách thức khó khăn. Ở đây, chúng tôi dự định khám phá thêm các hướng khác nhau như tìm các siêu tham số tốt nhất [34], kiểm soát gradient rò rỉ [66], ngăn chặn đảo ngược gradient và các cuộc tấn công rò rỉ dữ liệu [58], cá nhân hóa ASR tùy thuộc vào bối cảnh thiết bị, và sử dụng các mô hình giáo viên nhỏ hơn hoặc tự gán nhãn có thể được chạy trên thiết bị. Các kỹ thuật tính toán gradient gần đúng có thể được yêu cầu với những hạn chế tài nguyên tính toán nghiêm trọng. Hơn nữa, khám phá các phương pháp tích hợp thông tin giám sát yếu từ phản hồi người dùng được suy luận hoặc rõ ràng từ một phiên tương tác cũng như các mô hình ngôn ngữ được cập nhật bên ngoài là những con đường nghiên cứu thêm.

LỜI CẢM ƠN
Chúng tôi cảm ơn Kishore Nandury, Fred Weber, và Anand Mohan vì các cuộc thảo luận liên quan đến ASR sản xuất và heuristics lựa chọn phát ngôn. Valentin Mendelev hỗ trợ với việc xây dựng tập thử nghiệm delta để đo lường tác động của IL trên dữ liệu mới. Chúng tôi cảm ơn Bach Bui, Ehry MacRostie, Chul Lee, Nikko Strom, và Shehzad Mevawalla vì các cuộc thảo luận hữu ích, đánh giá và hỗ trợ. Chúng tôi mang ơn nhóm Nhận dạng Giọng nói Alexa vì các bình luận, xây dựng tập dữ liệu và phát triển cơ sở hạ tầng huấn luyện.

TÀI LIỆU THAM KHẢO
[1] Mohammad Al-Rubaie và J Morris Chang. Privacy-preserving machine learning: Threats and solutions. IEEE Security & Privacy, 17(2):49–58, 2019.
[2] Robins Anthony. Catastrophic forgetting, rehearsal and pseudorehearsal. Connection Science, 7(2):123–146, 1995.
[3] Alexei Baevski, Yuhao Zhou, Abdelrahman Mohamed, và Michael Auli. wav2vec 2.0: A framework for self-supervised learning of speech representations. Advances in Neural Information Processing Systems, 33:12449–12460, 2020.
[4] Alexei Baevski, Wei-Ning Hsu, Qiantong Xu, Arun Babu, Jiatao Gu, và Michael Auli. Data2vec: A general framework for self-supervised learning in speech, vision and language. arXiv preprint arXiv:2202.03555, 2022.
[5] Keith Bonawitz, Hubert Eichner, Wolfgang Grieskamp, Dzmitry Huba, Alex Ingerman, Vladimir Ivanov, Chloe Kiddon, Jakub Konečný, Stefano Mazzocchi, H Brendan McMahan, et al. Towards federated learning at scale: System design. arXiv preprint arXiv:1902.01046, 2019.
[6] Herve A Bourlard và Nelson Morgan. Connectionist speech recognition: a hybrid approach, volume 247. Springer Science & Business Media, 2012.
[7] Han Cai, Chuang Gan, Ligeng Zhu, và Song Han. Tinytl: Reduce memory, not parameters for efficient on-device learning. Advances in Neural Information Processing Systems, 33:11285–11297, 2020.
[8] Francisco M Castro, Manuel J Marín-Jiménez, Nicolás Guil, Cordelia Schmid, và Karteek Alahari. End-to-end incremental learning. Trong Proceedings of the European conference on computer vision (ECCV), pages 233–248, 2018.
[9] Kai Chen và Qiang Huo. Scalable training of deep learning machines by incremental block training with intra-block parallel optimization and blockwise model-update filtering. Trong 2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 5880–5884, 2016. doi: 10.1109/ICASSP.2016.7472805.
[10] Sanyuan Chen, Chengyi Wang, Zhengyang Chen, Yu Wu, Shujie Liu, Zhuo Chen, Jinyu Li, Naoyuki Kanda, Takuya Yoshioka, Xiong Xiao, et al. Wavlm: Large-scale self-supervised pre-training for full stack speech processing. arXiv preprint arXiv:2110.13900, 2021.

--- TRANG 7 ---
KDD '22, August 14–18, 2022, Washington, DC, USA Gopinath Chennupati et al.

[11] Chung-Cheng Chiu, Tara N Sainath, Yonghui Wu, Rohit Prabhavalkar, Patrick Nguyen, Zhifeng Chen, Anjuli Kannan, Ron J Weiss, Kanishka Rao, Ekaterina Gonina, et al. State-of-the-art speech recognition with sequence-to-sequence models. Trong 2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 4774–4778. IEEE, 2018.
[12] Yu-An Chung và James Glass. Generative pre-training for speech with autoregressive predictive coding. Trong ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 3497–3501. IEEE, 2020.
[13] Xiaodong Cui, Songtao Lu, và Brian Kingsbury. Federated acoustic modeling for automatic speech recognition. CoRR, abs/2102.04429, 2021.
[14] Subhadeep Dey, Petr Motlicek, Trung Bui, và Franck Dernoncourt. Exploiting semi-supervised training through a dropout regularization in end-to-end speech recognition. arXiv preprint arXiv:1908.05227, 2019.
[15] Tim Dierks và Eric Rescorla. The transport layer security (tls) protocol version 1.2. 2008.
[16] Dimitrios Dimitriadis, Kenichi Kumatani, Robert Gmyr, Yashesh Gaur, và Sefik Emre Eskimez. A federated approach in training acoustic models. Trong Proc. Interspeech, 2020.
[17] Robert M French. Catastrophic forgetting in connectionist networks. Trends in cognitive sciences, 3(4):128–135, 1999.
[18] Yan Gao, Titouan Parcollet, Javier Fernandez-Marques, Pedro P. B. de Gusmao, Daniel J. Beutel, và Nicholas D. Lane. End-to-end speech recognition from federated acoustic models, 2021.
[19] Robin C Geyer, Tassilo Klein, và Moin Nabi. Differentially private federated learning: A client level perspective. arXiv preprint arXiv:1712.07557, 2017.
[20] Noah Golmant, Nikita Vemuri, Zhewei Yao, Vladimir Feinberg, Amir Gholami, Kai Rothauge, Michael W Mahoney, và Joseph Gonzalez. On the computational inefficiency of large batch sizes for stochastic gradient descent. arXiv preprint arXiv:1811.12941, 2018.
[21] Ian J Goodfellow, Mehdi Mirza, Da Xiao, Aaron Courville, và Yoshua Bengio. An empirical investigation of catastrophic forgetting in gradient-based neural networks. arXiv preprint arXiv:1312.6211, 2013.
[22] Priya Goyal, Piotr Dollár, Ross Girshick, Pieter Noordhuis, Lukasz Wesolowski, Aapo Kyrola, Andrew Tulloch, Yangqing Jia, và Kaiming He. Accurate, large minibatch sgd: Training imagenet in 1 hour. arXiv preprint arXiv:1706.02677, 2017.
[23] Filip Granqvist, Matt Seigel, Rogier van Dalen, A'ine Cahill, Stephen Shum, và Matthias Paulik. Improving on-device speaker verification using federated learning with privacy, 2020.
[24] Alex Graves. Sequence transduction with recurrent neural networks. arXiv preprint arXiv:1211.3711, 2012.
[25] Anmol Gulati, James Qin, Chung-Cheng Chiu, Niki Parmar, Yu Zhang, Jiahui Yu, Wei Han, Shibo Wang, Zhengdong Zhang, Yonghui Wu, et al. Conformer: Convolution-augmented transformer for speech recognition. arXiv preprint arXiv:2005.08100, 2020.
[26] Dhruv Guliani, Françoise Beaufays, và Giovanni Motta. Training speech recognition models with federated learning: A quality/cost framework. Trong ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 3080–3084. IEEE, 2021.
[27] Elad Hoffer, Itay Hubara, và Daniel Soudry. Train longer, generalize better: closing the generalization gap in large batch training of neural networks. arXiv preprint arXiv:1705.08741, 2017.
[28] Wei-Ning Hsu, Benjamin Bolte, Yao-Hung Hubert Tsai, Kushal Lakhotia, Ruslan Salakhutdinov, và Abdelrahman Mohamed. Hubert: Self-supervised speech representation learning by masked prediction of hidden units. IEEE/ACM Transactions on Audio, Speech, and Language Processing, 29:3451–3460, 2021.
[29] Hui Jiang. Confidence measures for speech recognition: A survey. Speech communication, 45(4):455–470, 2005.
[30] Kaustubh Kalgaonkar, Chaojun Liu, Yifan Gong, và Kaisheng Yao. Estimating confidence scores on asr results using recurrent neural networks. Trong 2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 4999–5003. IEEE, 2015.
[31] Shigeki Karita, Shinji Watanabe, Tomoharu Iwata, Atsunori Ogawa, và Marc Delcroix. Semi-supervised end-to-end speech recognition. Trong Interspeech, pages 2–6, 2018.
[32] Shigeki Karita, Shinji Watanabe, Tomoharu Iwata, Marc Delcroix, Atsunori Ogawa, và Tomohiro Nakatani. Semi-supervised end-to-end speech recognition using text-to-speech and autoencoders. Trong ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 6166–6170. IEEE, 2019.
[33] Nitish Shirish Keskar, Dheevatsa Mudigere, Jorge Nocedal, Mikhail Smelyanskiy, và Ping Tak Peter Tang. On large-batch training for deep learning: Generalization gap and sharp minima. arXiv preprint arXiv:1609.04836, 2016.
[34] Mikhail Khodak, Tian Li, Liam Li, M Balcan, Virginia Smith, và Ameet Talwalkar. Weight sharing for hyperparameter optimization in federated learning. Trong Int. Workshop on Federated Learning for User Privacy and Data Confidentiality in Conjunction with ICML 2020, 2020.
[35] Taku Kudo. Subword regularization: Improving neural network translation models with multiple subword candidates. Trong ACL, 2018.
[36] Bo Li, Tara N Sainath, Ruoming Pang, và Zelin Wu. Semi-supervised training for end-to-end models via weak distillation. Trong ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 2837–2841. IEEE, 2019.
[37] Mu Li, Tong Zhang, Yuqiang Chen, và Alexander J. Smola. Efficient mini-batch training for stochastic optimization. Trong Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD '14, page 661–670. ACM, 2014.
[38] Tao Lin, Sebastian U. Stich, và Martin Jaggi. Don't use large mini-batches, use local sgd. ArXiv, abs/1808.07217, 2020.
[39] Shaoshi Ling, Yuzong Liu, Julian Salazar, và Katrin Kirchhoff. Deep contextualized acoustic representations for semi-supervised speech recognition. Trong ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 6429–6433. IEEE, 2020.
[40] Prerna Mahajan và Abhishek Sachdeva. A study of encryption algorithms aes, des and rsa for security. Global Journal of Computer Science and Technology, 2013.
[41] Dominic Masters và Carlo Luschi. Revisiting small batch training for deep neural networks. arXiv preprint arXiv:1804.07612, 2018.
[42] Sam McCandlish, Jared Kaplan, Dario Amodei, và OpenAI Dota Team. An empirical model of large-batch training. arXiv preprint arXiv:1812.06162, 2018.
[43] Michael McCloskey và Neal J Cohen. Catastrophic interference in connectionist networks: The sequential learning problem. Trong Psychology of learning and motivation, volume 24, pages 109–165. Elsevier, 1989.
[44] Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, và Blaise Aguera y Arcas. Communication-efficient learning of deep networks from decentralized data. Trong Artificial Intelligence and Statistics, pages 1273–1282. PMLR, 2017.
[45] Abdelrahman Mohamed, Hung-yi Lee, Lasse Borgholt, Jakob D Havtorn, Joakim Edin, Christian Igel, Katrin Kirchhoff, Shang-Wen Li, Karen Livescu, Lars Maaløe, et al. Self-supervised speech representation learning: A review. arXiv preprint arXiv:2205.10643, 2022.
[46] Climent Nadeu Camprubí, Francisco Javier Hernando Pericás, và Monica Gorricho Moreno. On the decorrelation of filter-bank energies in speech recognition. Trong EUROSPEECH'95: 4th European Conference on Speech Communication and Technology: Madrid, Spain: 18-21 September 1995, pages 1381–1384, 1995.
[47] Vassil Panayotov, Guoguo Chen, Daniel Povey, và Sanjeev Khudanpur. Librispeech: an asr corpus based on public domain audio books. Trong 2015 IEEE international conference on acoustics, speech and signal processing (ICASSP), pages 5206–5210. IEEE, 2015.
[48] Daniel S Park, William Chan, Yu Zhang, Chung-Cheng Chiu, Barret Zoph, Ekin D Cubuk, và Quoc V Le. Specaugment: A simple data augmentation method for automatic speech recognition. arXiv preprint arXiv:1904.08779, 2019.
[49] Sree Hari Krishnan Parthasarathi và Nikko Strom. Lessons from building acoustic models with a million hours of speech. Trong ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 6670–6674. IEEE, 2019.
[50] Sashank Reddi, Zachary Charles, Manzil Zaheer, Zachary Garrett, Keith Rush, Jakub Konečný, Sanjiv Kumar, và H Brendan McMahan. Adaptive federated optimization. arXiv preprint arXiv:2003.00295, 2020.
[51] Anit Kumar Sahu, Tian Li, Maziar Sanjabi, Manzil Zaheer, Ameet Talwalkar, và Virginia Smith. On the convergence of federated optimization in heterogeneous networks. arXiv preprint arXiv:1812.06127, 3:3, 2018.
[52] Christopher J Shallue, Jaehoon Lee, Joseph Antognini, Jascha Sohl-Dickstein, Roy Frostig, và George E Dahl. Measuring the effects of data parallelism on neural network training. arXiv preprint arXiv:1811.03600, 2018.
[53] Samuel L. Smith, Pieter-Jan Kindermans, Chris Ying, và Quoc V. Le. Don't decay the learning rate, increase the batch size, 2018.
[54] H. Soltau, H. Liao, và H. Sak. Reducing the computational complexity for whole word models. 2017 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU), pages 63–68, 2017.
[55] Nikko Strom. Scalable distributed dnn training using commodity gpu cloud computing. Trong Sixteenth Annual Conference of the International Speech Communication Association, 2015.
[56] Peng Sun, Wansen Feng, Ruobing Han, Shengen Yan, và Yonggang Wen. Optimizing network performance for distributed dnn training on gpu clusters: Imagenet/alexnet training in 1.5 minutes, 2019.
[57] Prakhar Swarup, Roland Maas, Sri Garimella, Sri Harish Mallidi, và Björn Hoffmeister. Improving asr confidence scores for alexa using acoustic and hypothesis embeddings. Trong Interspeech, pages 2175–2179, 2019.
[58] Aleksei Triastcyn và Boi Faltings. Federated generative privacy. IEEE Intelligent Systems, 35(4):50–57, 2020.
[59] Hongyi Wang, Mikhail Yurochkin, Yuekai Sun, Dimitris Papailiopoulos, và Yasaman Khazaeni. Federated learning with matched averaging. arXiv preprint arXiv:2002.06440, 2020.
[60] Jianyu Wang, Qinghua Liu, Hao Liang, Gauri Joshi, và H Vincent Poor. Tackling the objective inconsistency problem in heterogeneous federated optimization.

--- TRANG 8 ---
KDD '22, August 14–18, 2022, Washington, DC, USA Gopinath Chennupati et al.

arXiv preprint arXiv:2007.07481, 2020.
[61] Felix Weninger, Franco Mana, Roberto Gemello, Jesús Andrés-Ferrer, và Puming Zhan. Semi-supervised learning with data augmentation for end-to-end asr. arXiv preprint arXiv:2007.13876, 2020.
[62] Yue Wu, Yinpeng Chen, Lijuan Wang, Yuancheng Ye, Zicheng Liu, Yandong Guo, và Yun Fu. Large scale incremental learning. Trong Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 374–382, 2019.
[63] Alex Xiao, Christian Fuegen, và Abdelrahman Mohamed. Contrastive semi-supervised learning for asr. Trong ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 3870–3874. IEEE, 2021.
[64] Yang You, Igor Gitman, và Boris Ginsburg. Scaling sgd batch size to 32k for imagenet training. arXiv preprint arXiv:1708.03888, 6:12, 2017.
[65] Bo Zhao, Konda Reddy Mopuri, và Hakan Bilen. idlg: Improved deep leakage from gradients. arXiv preprint arXiv:2001.02610, 2020.
[66] Ligeng Zhu, Zhijian Liu, và Song Han. Deep leakage from gradients. Advances in Neural Information Processing Systems, 32, 2019.

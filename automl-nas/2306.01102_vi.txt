# 2306.01102.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/automl-nas/2306.01102.pdf
# Kích thước file: 1290144 bytes

===============================================
NỘI DUNG FILE PDF
===============================================


--- TRANG 1 ---
LLMatic: Tìm kiếm Kiến trúc Mạng nơ-ron thông qua Mô hình Ngôn ngữ Lớn
và Tối ưu hóa Chất lượng Đa dạng
Muhammad U. Nasir
umairnasir1@students.wits.ac.za
Đại học Witwatersrand
Johannesburg, Nam PhiSam Earle
se2161@nyu.edu
Đại học New York
New York, HoaChristopher W. Cleghorn
christopher.cleghorn@wits.ac.za
Đại học Witwatersrand
Johannesburg, Nam Phi

Steven James
steven.james@wits.ac.za
Đại học Witwatersrand
Johannesburg, Nam PhiJulian Togelius
julian@togelius.com
Đại học New York
New York, Hoa Kỳ

TÓM TẮT
Các mô hình ngôn ngữ lớn (LLM) đã nổi lên như những công cụ mạnh mẽ
có khả năng thực hiện một phổ rộng các nhiệm vụ. Khả năng của chúng
trải rộng trên nhiều lĩnh vực, và một lĩnh vực mà chúng đã tạo ra
tác động đáng kể là trong lĩnh vực tạo mã. Ở đây,
chúng tôi đề xuất sử dụng khả năng lập trình của LLM để giới thiệu những
biến đổi có ý nghĩa cho mã định nghĩa mạng nơ-ron. Trong khi đó,
các thuật toán Chất lượng-Đa dạng (QD) được biết đến với việc khám phá các
giải pháp đa dạng và mạnh mẽ. Bằng cách kết hợp khả năng tạo mã của
LLM với tính đa dạng và mạnh mẽ của các giải pháp QD, chúng tôi giới
thiệu LLMatic, một thuật toán Tìm kiếm Kiến trúc Mạng nơ-ron (NAS).
Trong khi LLM gặp khó khăn trong việc thực hiện NAS trực tiếp thông qua các lời nhắc,
LLMatic sử dụng một cách tiếp cận thủ tục, tận dụng QD cho các lời nhắc
và kiến trúc mạng để tạo ra các mạng đa dạng và hiệu suất cao. Chúng tôi kiểm tra LLMatic trên các tiêu chuẩn CIFAR-10 và NAS-bench-201
, chứng minh rằng nó có thể tạo ra các mạng cạnh tranh
trong khi chỉ đánh giá 2.000ứng viên, ngay cả khi không có kiến thức trước
về lĩnh vực tiêu chuẩn hoặc tiếp xúc với bất kỳ mô hình hiệu suất cao nào
trước đó cho tiêu chuẩn. Mã nguồn mở có sẵn tại https://github.com/umair-nasir14/LLMatic.

CÁC KHÁI NIỆM CCS
•Phương pháp tính toán →Mạng nơ-ron ;Học máy suốt đời
;•Lý thuyết tính toán →Thuật toán tiến hóa .

TỪ KHÓA
mô hình ngôn ngữ lớn, mạng nơ-ron, tối ưu hóa chất lượng-đa dạng,
tìm kiếm kiến trúc mạng nơ-ron

Định dạng Tham khảo ACM:
Muhammad U. Nasir, Sam Earle, Christopher W. Cleghorn, Steven James,
và Julian Togelius. 2024. LLMatic: Tìm kiếm Kiến trúc Mạng nơ-ron thông qua Mô hình Ngôn ngữ Lớn

Quyền tạo bản sao kỹ thuật số hoặc bản cứng của toàn bộ hoặc một phần công việc này cho mục đích cá nhân hoặc
sử dụng trong lớp học được cấp miễn phí với điều kiện các bản sao không được tạo hoặc phân phối
để kiếm lợi nhuận hoặc lợi thế thương mại và các bản sao phải ghi chú này và trích dẫn đầy đủ
trên trang đầu tiên. Quyền tác giả đối với các thành phần của công việc này thuộc sở hữu của những người khác ngoài
(các) tác giả phải được tôn trọng. Tóm tắt có ghi nguồn được cho phép. Để sao chép cách khác, hoặc
tái xuất bản, để đăng trên máy chủ hoặc để phân phối lại cho danh sách, yêu cầu sự cho phép cụ thể trước
và/hoặc một khoản phí. Yêu cầu quyền từ permissions@acm.org.
GECCO '24, Ngày 14–18 tháng 7, 2024, Melbourne, VIC, Australia
©2024 Quyền tác giả thuộc về (các) chủ sở hữu/tác giả. Quyền xuất bản được cấp phép cho ACM.
ACM ISBN 979-8-4007-0494-9/24/07. . . $15.00
https://doi.org/10.1145/3638529.3654017và Tối ưu hóa Chất lượng Đa dạng. Trong Hội nghị Tính toán Di truyền và Tiến
hóa (GECCO '24), Ngày 14–18 tháng 7, 2024, Melbourne,
VIC, Australia. ACM, New York, NY, USA, 9 trang. https://doi.org/10.1145/
3638529.3654017

1 GIỚI THIỆU
Một thách thức lớn trong học sâu là thiết kế các kiến trúc mạng nơ-
ron tốt. Tìm kiếm Kiến trúc Mạng nơ-ron (NAS) là thuật ngữ chung
cho các cách tiếp cận khác nhau để tự động hóa quá trình thiết kế này [ 50].
Ý tưởng là xây dựng một mục tiêu, chẳng hạn như độ chính xác tối đa
trên một bài toán phân loại với ngân sách nhất định về tham số và
chu kỳ huấn luyện, và đặt bài toán như một tìm kiếm kiến trúc
mà tối đa hóa mục tiêu. Mỗi thử nghiệm bao gồm việc huấn luyện kiến
trúc mạng ứng viên sử dụng một số hình thức của gradient descent
trên bộ dữ liệu tiêu chuẩn được chọn để đo lường hiệu suất của nó. Điều này
thường có nghĩa là nhiều nghìn kiến trúc được thử nghiệm
và loại bỏ trong quá trình.

Hai cách tiếp cận thuật toán phổ biến cho NAS là học tăng cường
và tính toán tiến hóa. Các cách tiếp cận học tăng cường cho NAS [ 20] huấn luyện một bộ điều khiển (thường là một mạng nơ-
ron khác) mà xuất ra các kiến trúc mạng; các kiến trúc mạng
này được thử nghiệm và hiệu suất của chúng được sử dụng như một tín hiệu phần thưởng.
Các cách tiếp cận tính toán tiến hóa cho NAS [ 25], mặt khác, trực tiếp tìm kiếm không gian của các kiến trúc mạng nơ-ron. Một quần thể
của các kiến trúc được giữ lại, và hiệu suất của chúng được sử dụng như một
điểm số thể dục. Các cách tiếp cận NAS tiến hóa tương tự như neuroevolution,
mà đã tồn tại từ những năm 1980 [ 27,43], và người ta thậm chí có thể xem
NAS như một hình thức của neuroevolution. Sự khác biệt chính là trong
NAS, quá trình tìm kiếm không liên quan đến các tham số của
mạng nơ-ron, chỉ có kiến trúc của nó.

Người ta có thể lập luận rằng tìm kiếm bằng tính toán tiến hóa hoặc
học tăng cường khá vô tâm và lãng phí, xét đến việc bao nhiêu
kiến trúc cần được thử nghiệm và các thay đổi dẫn đến mỗi kiến trúc mới
thiếu thông tin như thế nào. Có cách nào chúng ta có thể thông báo cho việc tìm kiếm bằng cách khai thác kiến thức đã lưu trữ về cách
thiết kế mạng nơ-ron không? Bài báo này khám phá ý tưởng rằng chúng ta có thể
làm chính xác điều này bằng cách sử dụng các mô hình ngôn ngữ lớn tạo mã (LLM).
Cụ thể hơn, chúng tôi đề xuất kết hợp một LLM với một thuật toán tiến hóa
để tạo ra các kiến trúc mới có tính đa dạng kiến trúc mạng cao và hiệu suất tiên tiến.

Lập luận cho điều này đơn giản là các LLM hiện đại được tinh chỉnh trên
mã rất có khả năng [ 39]. Với lượng mã học máyarXiv:2306.01102v8  [cs.NE]  12 Apr 2024

--- TRANG 2 ---
GECCO '24, Ngày 14–18 tháng 7, 2024, Melbourne, VIC, Australia Muhammad U. Nasir, và cộng sự.

mà chúng đã được huấn luyện, không có gì đáng ngạc nhiên khi chúng có thể
thiết kế các kiến trúc mạng nơ-ron tốt. Tuy nhiên, một LLM tự nó
không thể, nói chung, tìm một kiến trúc tối ưu cho một
bài toán nhất định, vì nó không thể thử nghiệm các kiến trúc và học từ các thí
nghiệm của mình. Do đó, chúng tôi đề xuất kết hợp kiến thức lĩnh vực của
các LLM tạo mã với một cơ chế tìm kiếm mạnh mẽ.

Trong khi tạo ra một kiến trúc duy nhất tối đa hóa một mục tiêu nhất định
hữu ích cho nhiều trường hợp, thường có giá trị hơn trong việc
tạo ra một tập hợp các kiến trúc mà thay đổi qua một số
chiều liên quan. Ví dụ, người ta có thể muốn có một tập hợp các kiến trúc
mà thay đổi về số lượng tham số hoặc độ sâu của chúng. Điều này giúp trong
việc hiểu sự đánh đổi giữa các chỉ số mong muốn khác nhau và
có thể hỗ trợ trong việc đưa ra quyết định có thông tin tốt hơn về kiến
trúc nào để sử dụng cho một ứng dụng cụ thể. Ví dụ, người ta có thể
muốn một loạt các mạng cho việc triển khai edge cho các khách hàng với
các kích thước RAM khác nhau. Để cho phép điều này, giải pháp mà chúng tôi đề xuất ở đây
tận dụng tìm kiếm chất lượng-đa dạng [ 36], cụ thể là một phiên bản của
thuật toán MAP-Elites [28].

Đóng góp chính của chúng tôi là một thuật toán NAS dựa trên LLM mới,
LLMatic, mà sử dụng sức mạnh của hai kho lưu trữ QD để tìm kiếm
các mạng cạnh tranh chỉ với 2.000 đánh giá. Chúng tôi chứng minh thực nghiệm
hiệu suất của LLMatic trên bộ dữ liệu CIFAR-10 và
tiêu chuẩn NAS-bench-201 nơi LLMatic tìm kiếm các mạng
với hiệu suất tương tự như kết quả tiên tiến.

2 CÔNG TRÌNH LIÊN QUAN
Thiết kế các kiến trúc mạng nơ-ron có thể là một quá trình đắt đỏ và không trực quan
cho các nhà thiết kế con người. Tìm kiếm Kiến trúc Mạng nơ-ron (NAS)
nhằm tự động tìm các kiến trúc có khả năng hiệu suất mạnh
sau khi huấn luyện [ 14]. Các phương pháp Bayesian là một lựa chọn phổ biến
dựa trên độ phức tạp mẫu thấp của chúng và thực tế rằng việc đánh giá mỗi
kiến trúc (bằng cách huấn luyện nó) có thể tốn kém về mặt tính toán [ 21].
Ngoài ra, học tăng cường có thể được sử dụng để huấn luyện một tác nhân
(thường là một mạng nơ-ron khác) để xuất ra các kiến trúc ứng viên
cho một nhiệm vụ nhất định, với hiệu suất sau khi huấn luyện của kiến trúc ứng viên
đóng vai trò như một tín hiệu phần thưởng [ 20]. Các phương pháp tiến hóa
cũng có thể được sử dụng để tìm kiếm trực tiếp thông qua không gian của
các kiến trúc có thể [ 25]. Tương tự, Tìm kiếm Cây Monte Carlo cũng
đã được sử dụng để tìm kiếm [ 51]. Trong tất cả các trường hợp, một nhà thiết kế con người phải
định nghĩa thủ công một tập hợp các thành phần mạng nguyên tử hoặc các hành động chỉnh sửa
để sử dụng trong tìm kiếm/tạo mạng.

Để tránh việc nhà thiết kế hạn chế không gian của các
kiến trúc có thể trước khi tìm kiếm, chúng tôi chuyển sang các mô hình ngôn ngữ lớn tạo mã (LLM)—các mô hình lớn được huấn luyện tự hồi quy
trên các bộ dữ liệu khổng lồ của mã (ví dụ: các kho lưu trữ công cộng được lưu trữ trên
Github). Các LLM này dựa trên kiến trúc transformer [ 48]
mà đã đạt được hiệu suất tiên tiến trong mô hình hóa ngôn ngữ tự nhiên [ 1,5,32,37]. Chúng cũng đã được sử dụng thành công trong
các ứng dụng cụ thể, chẳng hạn như cho thiết kế cấp độ trò chơi video [ 7,33,44]
hoặc tạo mã [39].

Gần đây, LLM đã được sử dụng để tiến hóa mã bằng cách khung hóa
việc tạo mã như một bài toán tiến hóa. Evolution through
Large Models (ELM) [ 23] đặt LLM như các toán tử tiến hóa
trong một thuật toán MAP-Elites [ 28] có nhiệm vụ tiến hóa hình thái
của robot ở mức mã. EvoPrompting [ 6] là một phương pháp dựa trên LLM
mà hơi tương tự với chúng tôi ở chỗ nó sử dụng các LLM mãnhư các toán tử đột biến và lai ghép để thực hiện NAS. Nó được thử nghiệm
trên nhiệm vụ phân loại MNIST-1D [ 17] và
tiêu chuẩn lý luận thuật toán CLRS [ 49]. Vì hiệu suất thường có thể
được tăng lên một cách tầm thường bằng cách đơn giản thêm tham số vào mô hình,
một hình phạt bổ sung được thêm vào thể dục của một kiến trúc mạng nơ-ron ứng viên
tương ứng với kích thước mô hình của nó. Điều này khuyến khích
việc khám phá các mô hình nhỏ với kiến trúc hiệu quả. Trong phương pháp của chúng tôi, thay vào đó chúng tôi xem xét độ phức tạp mô hình (về FLOPS)
như một chỉ số đa dạng, tìm kiếm các mô hình hiệu suất cao với
nhiều kích thước khác nhau. GENIUS [ 53] là một thuật toán NAS dựa trên LLM khác
mà sử dụng GPT-4 để đơn giản tìm kiếm thông qua việc nhắc nhở thẳng thắn.

Các phương pháp Chất lượng Đa dạng (QD) [ 36] là một họ các thuật toán tiến hóa
mà, ngoài việc tối ưu hóa một chỉ số thể dục, tìm kiếm
sự đa dạng của các cá thể theo một số "bộ mô tả hành vi" do người dùng chỉ định. Thay vì giữ một quần thể của các cá thể phù hợp nhất, các phương pháp QD như MAP-Elites [ 28] duy trì một "kho lưu trữ"
của các cá thể, nơi kho lưu trữ này được phân vùng thành các ô, với mỗi
ô tương ứng với các cá thể thể hiện một phạm vi cụ thể của
các giá trị dọc theo mỗi bộ mô tả hành vi.

Các phương pháp QD có giá trị trong các lĩnh vực như điều khiển robot, nơi
hữu ích để học các quỹ đạo chất lượng cao đa dạng, trong trường hợp một
giải pháp trở nên không khả dụng trong quá trình triển khai vì
một trở ngại vật lý hoặc trục trặc cơ học [ 9]. Một yếu tố thúc đẩy khác
là việc tìm kiếm tham lam cho cá thể phù hợp nhất có thể không
mong muốn trong các lĩnh vực lừa đảo. Ở đây, việc duy trì một
sự đa dạng của các cá thể phù hợp có thể bảo vệ quần thể khỏi việc rơi vào
tối ưu cục bộ [ 15]. Ngược lại, các giải pháp đa dạng, không chính thống có thể cung cấp "bước đệm" có giá trị trên con đường đến các cá thể phù hợp toàn cầu.

3 CÁCH TIẾP CẬN
LLMatic bắt đầu tìm kiếm của mình với một mạng nơ-ron rất cơ bản, được
truyền cảm hứng từ công trình của [ 40] mà gợi ý rằng neuroevolution
có xu hướng hoạt động tốt hơn khi bắt đầu với một mạng nhỏ. Trong
LLMatic, chúng tôi sử dụng một cách tiếp cận tối ưu hóa QD hợp tác
kho lưu trữ kép mới, trong đó hai kho lưu trữ riêng biệt được sử dụng để lưu trữ các
thành phần bổ sung có thể được kết hợp để giải quyết một nhiệm vụ nhất định.
Kho lưu trữ đầu tiên lưu trữ các mạng nơ-ron, nơi tỷ lệ chiều rộng so với độ sâu
và Số Phép tính Dấu phẩy Động mỗi Giây (FLOPS) của một mạng
là các bộ mô tả hành vi. Tỷ lệ chiều rộng so với độ sâu là
một phép chia của chiều rộng và độ sâu của mạng. Để chỉ định
chiều rộng, chúng tôi sử dụng số lượng tối đa của các tính năng đầu ra của tất cả các lớp,
trong khi độ sâu đơn giản là số lượng lớp. Lưu ý rằng chúng tôi chọn
FLOPS thay vì số lượng tham số bởi vì FLOPS có mối tương quan tốt hơn
với thời gian thực tế được dành để huấn luyện một mạng [ 2]. Chúng tôi gọi kho lưu trữ này
là "kho lưu trữ mạng". Hàm thể dục cho các mạng trong
kho lưu trữ này được định nghĩa là độ chính xác thử nghiệm của mạng sau
khi huấn luyện. Kho lưu trữ thứ hai, được gọi là "kho lưu trữ lời nhắc", chứa
lời nhắc và nhiệt độ được sử dụng để tạo mã, mà cũng
là các bộ mô tả hành vi. Nhiệt độ của một LLM là một
siêu tham số mà điều khiển mức độ ngẫu nhiên trong việc lựa
chọn các token đầu ra: một nhiệt độ thấp hơn có nghĩa là LLM
sẽ chọn token một cách xác định hơn, trong khi một giá trị cao hơn sẽ
dẫn đến đầu ra đa dạng hơn. Việc lựa chọn lời nhắc và nhiệt
độ phụ thuộc vào một điểm số tò mò [ 10], được chi phối bởi việc liệu

--- TRANG 3 ---
LLMatic: Tìm kiếm Kiến trúc Mạng nơ-ron thông qua Mô hình Ngôn ngữ Lớn và Tối ưu hóa Chất lượng Đa dạng GECCO '24, Ngày 14–18 tháng 7, 2024, Melbourne, VIC, Australia

Cá thể Mạng
Cá thể Lời nhắcKho lưu trữ Mạng
Kho lưu trữ Lời nhắcLời nhắc Ngẫu nhiênMạng Ban đầu
LLM
Các thao tácMạng được chọn
Lời nhắc được chọnCác đánh giá

Hình 1: Được minh họa trong hình là luồng của LLMatic. Trong vòng tiến hóa đầu tiên, một mạng ban đầu với một
lời nhắc ngẫu nhiên trải qua một thao tác đột biến. Cá thể mạng và cá thể lời nhắc sau đó được đánh giá để được lưu trữ trong
các kho lưu trữ riêng biệt. Trong vòng lặp tiến hóa, lời nhắc được chọn và mạng trải qua một thao tác tiến hóa (lời
nhắc được cố định nếu thao tác là lai ghép) để tạo ra nhiều mạng và cá thể lời nhắc hơn để lấp đầy và chiếu sáng các kho lưu trữ.

mạng được tạo ra có được thêm vào kho lưu trữ mạng hay không. Thể dục
của các cá thể lời nhắc phụ thuộc vào việc liệu mạng có tốt hơn
điểm số tốt nhất của thế hệ trước hay không. Hình 1 minh họa
sơ đồ luồng của cách tiếp cận mà LLMatic sử dụng, trong khi Thuật toán 1 cho thấy
quá trình tìm kiếm hoàn chỉnh của LLMatic dưới dạng mã giả.

Trong thế hệ đầu tiên, một mạng nơ-ron đơn giản với một lớp tích chập và một lớp kết nối đầy đủ khởi tạo sự tiến hóa (dòng
1 của Thuật toán 1). Một lời nhắc được chọn ngẫu nhiên để tạo ra một
lô mạng ban đầu (dòng 5–6 của Thuật toán 1). Các mạng này
được đánh giá và một nỗ lực được thực hiện để thêm chúng vào kho lưu trữ mạng
như một khởi tạo ngẫu nhiên cho MAP-Elites. Đồng thời,
chúng tôi biến đổi nhiệt độ dựa trên thể dục của mạng,
tăng nó nếu thể dục tăng và ngược lại (dòng 21–23 của
Thuật toán 1). Một sự tăng nhiệt độ là mong muốn nếu chúng ta muốn
LLM khám phá, trong khi giảm nhiệt độ sẽ dẫn đến
LLM khai thác trong một nỗ lực để đạt được thể dục tốt hơn so với
trước đó. Một khi chúng tôi tính toán thể dục của cá thể lời nhắc, chúng tôi
thêm điểm số vào một điểm số thể dục lời nhắc tập thể, sau đó chúng tôi
cố gắng lấp đầy kho lưu trữ lời nhắc. Điểm số thể dục lời nhắc tập thể
xác định thể dục tổng thể của mỗi cá thể trong kho lưu trữ lời nhắc
vì nó cung cấp cho mỗi lời nhắc một điểm số thể dục.

Một khi một trong hai kho lưu trữ đạt đến một công suất được chỉ định, chúng tôi giới
thiệu huấn luyện mạng nơ-ron và các toán tử tiến hóa trongquá trình (dòng 7–20 của Thuật toán 1). Với một xác suất nhất định
tại mỗi thế hệ, một quyết định được đưa ra về việc có thực hiện
lai ghép hay đột biến để tạo ra 𝑁 con lai mới. Nếu toán tử lai ghép
được chọn, chúng tôi chọn 𝑁 cá thể mạng ngẫu nhiên, xác định vị trí
các mạng gần nhất của chúng trong kho lưu trữ, và thực hiện một thao tác lai ghép
được hướng dẫn bởi một lời nhắc (dòng 15–16 của Thuật toán 1). Không
có cá thể nào được thêm vào kho lưu trữ lời nhắc khi một lai ghép được thực
hiện. Nếu thao tác đột biến được chọn, chúng tôi chọn cá thể lời nhắc
tò mò nhất và một cá thể mạng ngẫu nhiên. Để khám phá, chúng tôi cũng
chọn các lời nhắc ngẫu nhiên. Trong cả hai trường hợp, mỗi mạng được huấn luyện
trong một số kỷ nguyên nhất định và một nỗ lực được thực hiện để thêm mạng vào
kho lưu trữ. Tương tự, một cá thể lời nhắc được thêm vào như đã mô tả trước đó. Quá trình này tiếp tục
trong một số thế hệ được xác định trước. Tham khảo tài liệu bổ
sung để biết mã giả về các toán tử đột biến, toán tử lai ghép, đột biến nhiệt độ và thêm vào kho lưu trữ.

4 ĐÁNH GIÁ LLMATIC
Để đánh giá LLMatic, chúng tôi sử dụng CIFAR-10 [ 22], một bộ dữ liệu thường được sử dụng
cho NAS [ 42,52]. Chúng tôi thực hiện các nghiên cứu cắt bỏ mở rộng để
chứng minh rằng LLMatic hưởng lợi từ mỗi thành phần của nó

--- TRANG 4 ---
GECCO '24, Ngày 14–18 tháng 7, 2024, Melbourne, VIC, Australia Muhammad U. Nasir, và cộng sự.

Thuật toán 1: LLMatic
1Khởi tạo kho lưu trữ mạng và lời nhắc.
2trong khi số thế hệ <thế hệ tối đa
3 đối với mỗi mạng trong lô mạng thực hiện
4 nếusố cá thể trong kho lưu trữ <ngưỡng đặt
thì
5 Biến đổi mạng ban đầu với một
lời nhắc ngẫu nhiên .
6 Lấy các cá thể mạng và lời nhắc và thêm
chúng vào các kho lưu trữ tương ứng.
7 nếu không
8 Chọn ngẫu nhiên đột biến hoặc lai ghép làm
toán tử tiến hóa.
9 nếutoán tử tiến hóa ==đột biến thì
10 Chọn mạng và lời nhắc.
11 Biến đổi mạng được chọn với
lời nhắc được chọn .
12 Huấn luyện hoặc truy vấn mạng được tạo.
13 Lấy các cá thể mạng và lời nhắc và
lưu trữ chúng.
14 nếu không
15 Lựa chọn mạng để lai ghép.
16 Thực hiện lai ghép trên các mạng được chọn
với một lời nhắc cố định .
17 Huấn luyện hoặc truy vấn mạng được tạo.
18 Lưu trữ cá thể mạng được tạo.
19 kết thúc
20 kết thúc
21 kết thúc
22 Đánh giá tất cả mạng để tìm độ chính xác thử nghiệm.
23 Biến đổi nhiệt độ cho thế hệ
tiếp theo .
24 Thêm các cá thể mạng lô và các
cá thể lời nhắc tương ứng vào các kho lưu trữ
tương ứng.
25kết thúc

trong quá trình tìm kiếm. Một khi thuật toán của chúng tôi được xác thực, chúng tôi mở rộng các thí
nghiệm của chúng tôi đến NAS-bench-201 . Tiêu chuẩn NAS-bench-201 [ 26] là một
bộ dữ liệu liệt kê tất cả các kiến trúc mạng nơ-ron có thể trong một
không gian tìm kiếm nhất định (tức là của một số lượng nút/lớp và cạnh/thao
tác cố định) và độ chính xác thử nghiệm tương ứng của mỗi kiến trúc sau
khi huấn luyện trên một bộ dữ liệu nhất định (ví dụ: CIFAR-10), cho phép các nhà nghiên cứu
khám phá các đánh đổi của các thuật toán NAS khác nhau mà không cần
huấn luyện lại mỗi mạng ứng viên trong quá trình tìm kiếm.

4.1 Thiết lập LLMatic
Bộ dữ liệu: Bộ dữ liệu CIFAR-10 được tạo thành từ 60.000hình ảnh màu,
mỗi hình có độ phân giải 32×32pixel, và được chia thành 10 danh
mục: máy bay, ô tô, chim, mèo, hươu, chó, ếch, ngựa, tàu
và xe tải. Bộ dữ liệu được phân vùng thành năm nhóm để huấn luyện
và một nhóm để thử nghiệm, mỗi nhóm chứa 10.000 hình ảnh. Mỗinhóm thử nghiệm bao gồm một số chính xác 1.000 hình ảnh từ mỗi
danh mục được chọn ngẫu nhiên. Các nhóm huấn luyện chứa các
hình ảnh còn lại, được sắp xếp theo thứ tự ngẫu nhiên. Kết quả là, một số
nhóm huấn luyện có thể chứa nhiều hình ảnh từ một danh mục hơn
so với các nhóm khác. Tuy nhiên, tổng thể, các nhóm huấn luyện có
một tổng số chính xác 5.000 hình ảnh từ mỗi danh mục.

Mạng Nơ-ron Ban đầu: LLMatic bắt đầu với một mạng nơ-ron đơn giản
với một lớp tích chập nhận 3 kênh đầu vào,
với kích thước kernel 1×1 và 1 kênh đầu ra mà kết nối với một
lớp dày đặc có kích thước 1024. Những nơ-ron ẩn này được kết nối thông qua
một lớp dày đặc khác với 10 nơ-ron đầu ra (vì chúng ta có 10 lớp).
Rectified Linear Unit (ReLU) [ 30] là hàm kích hoạt được sử dụng trong
tất cả các lớp. Tất cả các mạng của chúng tôi được tạo ra trong PyTorch [35].

Tạo Mạng Nơ-ron: Tại mỗi thế hệ, chúng tôi tạo ra
một lô 100 con lai mới. Mỗi mạng được tạo ra được huấn luyện
trong 50 kỷ nguyên. Các mạng được tối ưu hóa bằng gradient descent ngẫu nhiên
[ 4] với tốc độ học được đặt thành 0.001và momentum được đặt
tại 0.9 cho tất cả các mạng. Chúng tôi sử dụng mất mát entropy chéo làm thước đo
cho thể dục của mạng được huấn luyện.

Đối với các toán tử tiến hóa, chúng tôi đặt xác suất 0.7 cho đột
biến và 0.3 cho lai ghép vì sau thí nghiệm, chúng tôi phát hiện
rằng đột biến tạo ra các mạng nơ-ron có thể huấn luyện một cách nhất quán hơn.
Chúng tôi khởi tạo tham số nhiệt độ (được sử dụng khi lấy mẫu
LLM tạo mã) thành 0.6. Đối với đột biến nhiệt độ, một nửa của
quần thể được tạo ra bởi nhiệt độ cá thể lời nhắc
biến đổi đều ngẫu nhiên giữa −0.1 đến 0.1. Nửa còn lại
được tạo ra bởi nhiệt độ thu được từ cá thể lời nhắc
chính nó. Nếu thể dục của mạng được tạo ra tốt hơn hoặc
bằng thể dục tốt nhất của thế hệ trước, chúng tôi tăng
nhiệt độ lên 0.05 và nếu nó tệ hơn thể dục tốt nhất của
thế hệ trước, chúng tôi giảm nó đi 0.05. Đối với toán tử lai ghép, chúng tôi chọn 10 mạng ngẫu nhiên và tìm 2 hoặc 3 hàng xóm gần
nhất của chúng, dựa trên khoảng cách của các thích nghi, trong kho lưu trữ mạng
để thực hiện lai ghép. Chúng tôi đặt nhiệt độ LLM thành 0.7 cho
việc tạo mạng.

Tối ưu hóa Chất lượng Đa dạng: Đối với thuật toán tối ưu hóa QD của chúng tôi, chúng tôi chọn một biến thể của MAP-Elites—Centroidal Voronoi
Tessellation (CVT-MAP-Elites) [ 47]—mà có thể được xem như một tổng quát
hóa của MAP-Elites mà dự định mở rộng MAP-Elites cho
không gian hành vi chiều cao; CVT-MAP-Elites vượt trội hơn
MAP-Elites tiêu chuẩn trong không gian chiều cao trong khi khớp
hiệu suất các kịch bản chiều thấp hơn như những kịch bản được nghiên cứu trong
công việc hiện tại.

CVT-MAP-Elites tự động hóa việc phân chia phụ của kho lưu trữ bằng cách
xác định 𝑘 vị trí trọng tâm ô thể hiện sự lan rộng đều
thông qua không gian bộ mô tả hành vi. Ở đây, 𝑘 tương ứng
với tổng số "thích nghi" tiến hóa trong kho lưu trữ. Chúng tôi sử dụng
triển khaipymap_elites1cho thí nghiệm của chúng tôi. Chúng tôi sử dụng
một cây k-d [ 3] để tạo và viết trọng tâm vào kho lưu trữ và tìm
các hàng xóm gần nhất sử dụng một chỉ số khoảng cách Euclidean [12].

Mỗi kho lưu trữ QD của chúng tôi có 2 chiều (bộ mô tả hành vi), với 100 thích nghi lan rộng qua chúng. Chúng tôi đặt số lượng
mạng ban đầu ngẫu nhiên thành 10. Đối với kho lưu trữ mạng, chúng tôi có
tỷ lệ chiều rộng so với độ sâu của mạng làm chiều đầu tiên của chúng tôi và
FLOPS của mạng làm chiều thứ hai. Tỷ lệ chiều rộng so với độ sâu
có giới hạn dưới là 0 và giới hạn trên là 200. Các
1https://github.com/resibots/pymap_elites

--- TRANG 5 ---
LLMatic: Tìm kiếm Kiến trúc Mạng nơ-ron thông qua Mô hình Ngôn ngữ Lớn và Tối ưu hóa Chất lượng Đa dạng GECCO '24, Ngày 14–18 tháng 7, 2024, Melbourne, VIC, Australia

FLOPS tối thiểu được đặt thành 200MegaFLOPS và tối đa được đặt
thành 5GigaFLOPS. Phạm vi này được đặt sau thí nghiệm.

Đối với kho lưu trữ lời nhắc, chúng tôi có lời nhắc được mã hóa như một số nguyên làm chiều đầu tiên và nhiệt độ làm chiều thứ hai.
Giá trị tối đa của lời nhắc là 16, số lượng lời nhắc
được sử dụng trong hệ thống. Giá trị nhiệt độ tối đa được đặt thành 1 vì
nó không bao giờ có thể tăng vượt quá điều đó cho LLM của chúng tôi. Giới hạn dưới cho
tất cả các chiều là 0.

Đối với kho lưu trữ mạng, chúng tôi đơn giản chọn một mạng ngẫu nhiên
trong khi đối với kho lưu trữ lời nhắc, chúng tôi chọn cá thể lời nhắc tò mò nhất, mà phụ thuộc vào điểm số tò mò. Điểm số tò mò này
được tăng lên 1.0 nếu lời nhắc được chọn thêm mạng được tạo
vào kho lưu trữ mạng, giảm đi 0.5 nếu mạng không
được thêm, và giảm đi 1.0 nếu mạng được tạo không thể huấn luyện.
Nếu mạng được tạo có thể dục tốt hơn thế hệ trước
mạng tốt nhất, điểm số thể dục lời nhắc tập thể cho
lời nhắc trong cá thể lời nhắc được tăng lên 1; nếu không, nó
không thay đổi. Chúng tôi sử dụng các lời nhắc có thể tổng quát hóa cho bất kỳ bài toán
nào trong bất kỳ lĩnh vực nào. Tham khảo tài liệu bổ sung để biết ví dụ về
lời nhắc đột biến và lai ghép.

LLM Tạo Mã: Chúng tôi sử dụng LLM CodeGen được huấn luyện trước [ 34]
để tạo ra các mạng nơ-ron. CodeGen là một transformer decoder-only tự hồi quy với che chắn nhân quả từ trái sang phải. Code-
Gen đầu tiên được huấn luyện trên bộ dữ liệu ThePile với khởi tạo ngẫu nhiên
và được gọi là CodeGen-NL. CodeGen-Multi được khởi tạo với
CodeGen-NL và được huấn luyện trên bộ dữ liệu BigQuery. Cuối cùng, CodeGen-
Mono được khởi tạo với CodeGen-Multi và được huấn luyện trên BigPython .
CodeGen được huấn luyện ở các kích thước tham số khác nhau, nhưng chúng tôi sử dụng phiên bản 6.1
Tỷ tham số của CodeGen-Mono do hạn chế tính toán.

Bộ dữ liệu ThePile [ 16] là một kho văn bản tiếng Anh 825.18GB. Code-
Gen chọn một tập con của bộ dữ liệu Google BigQuery mà chứa
6 ngôn ngữ lập trình, cụ thể là C, C++, Go, Java, JavaScript,
và Python. Các tác giả đã thu thập một lượng lớn mã Python được cấp phép cho phép từ GitHub vào tháng 10 năm 2021, và đặt tên nó là
BigPython . Kích thước của BigPython là 217.3GB.

CodeGen-6B có 33 lớp và 16 đầu với 256 chiều
mỗi đầu. Độ dài ngữ cảnh là 2048 và kích thước lô là 2 triệu
token. Độ suy giảm trọng lượng được đặt thành 0.1. 0.4𝑒−4 là tốc độ học. Các bước khởi động
được đặt thành 3𝑘 trong khi tổng số bước để huấn luyện là 150k.

4.2 Nghiên cứu Cắt bỏ
Vì chúng tôi có nhiều thành phần trong LLMatic, chúng tôi chọn thực hiện một
nghiên cứu cắt bỏ kỹ lưỡng để xác định ảnh hưởng của mỗi thành phần lên
hiệu suất tổng thể. Sau đây là các thành phần được thử nghiệm cho
nghiên cứu cắt bỏ:

•Network-Archive-LLMatic :LLMatic chỉ với kho lưu trữ mạng. Để đạt được điều này, chúng tôi tạo một quần thể của các cá thể lời nhắc. Quần thể được cố định thành 100 cá thể được
khởi tạo với các cá thể ngẫu nhiên. Chúng tôi chỉ có một điểm số thể dục
cho quần thể này, mà được tính như +1 nếu một mạng
được thêm vào kho lưu trữ mạng, −0.5 nếu mạng không
được thêm và −1 nếu mạng không thể huấn luyện. Sau khi chúng tôi
tạo ra mạng, chúng tôi biến đổi nhiệt độ bằng cách thêm
0.1 nếu mạng được thêm vào kho lưu trữ mạng và −0.1
nếu mạng không được thêm.•Prompt-Archive-LLMatic :LLMatic chỉ với kho lưu trữ lời nhắc. Để đạt được điều này, chúng tôi tạo một quần thể các mạng.
Hàm thể dục cho quần thể các mạng là độ chính
xác. Chúng tôi giữ quần thể thành 100 cá thể. Với xác suất tương tự như LLMatic, chúng tôi chọn toán tử đột biến hoặc lai ghép. Đối với toán tử lai ghép, chúng tôi chọn cá thể
gần nhất với cấu trúc của mạng được chọn. Đối với
sự tương tự mạng, chúng tôi sử dụng độ tương tự cosine và chúng tôi chọn
các mạng với điểm số cao hơn. Đối với toán tử đột biến,
tương tự như LLMatic chúng tôi biến đổi một nửa các mạng từ
các cá thể lời nhắc tò mò nhất và một nửa từ các cá thể ngẫu nhiên.

•Mutation-Only-LLMatic :LLMatic chỉ sử dụng đột biến.
•Crossover-Only-LLMatic :LLMatic chỉ sử dụng lai ghép.
•Random-NN-Generation : Tạo mạng nơ-ron mà không
có tiến hóa. Chúng tôi tạo ra 100 mạng mỗi thế hệ
trong 20 thế hệ như một so sánh công bằng với LLMatic, mà
tạo ra cùng số lượng mỗi lô. Chúng tôi áp dụng lời nhắc
"Tạo một mạng nơ-ron mà kế thừa từ nn.Module và
hoạt động tốt hơn mạng nơ-ron trên" và chúng tôi thêm
mạng ban đầu với lời nhắc này.

4.2.1 Kết quả và Thảo luận Cắt bỏ. Trong phần này, chúng tôi sẽ thảo
luận về kết quả của các thí nghiệm mà chúng tôi thiết lập trong phần
trước. Chúng tôi đầu tiên thảo luận về độ chính xác tốt nhất mỗi thế hệ, được minh họa
trong Hình 2. Điều này sẽ dẫn dắt cuộc thảo luận của chúng tôi đến các mạng có thể huấn luyện
được tạo ra bằng cách thay đổi xác suất lai ghép và đột biến
(Hình 4). Sau đó chúng tôi sẽ thảo luận về cách các kho lưu trữ được chiếu sáng Hình
3. Một số mạng được tạo ra được hiển thị trong tài liệu bổ
sung.

Hình 2 minh họa rằng mỗi thành phần của LLMatic là cần thiết.
Mutation-Only-LLMatic và Network-Archive-LLMatic là gần nhất với LLMatic, mà xác thực lựa chọn của chúng tôi để cân nhắc xác
suất đột biến cao hơn. Crossover-Only-LLMatic hoạt động
tệ nhất, vì nó không hưởng lợi từ khả năng khám phá được cung cấp bởi toán tử đột biến [ 46]. Cả hai toán tử (đột biến
và lai ghép) cùng nhau cung cấp khả năng khám phá và khai thác cho
LLMatic, mà dường như cần thiết để tìm các mạng chất lượng cao và
đa dạng. Prompt-Archive-LLMatic hoạt động kém, cho
thấy rằng kho lưu trữ mạng là một khía cạnh quan trọng trong việc tìm
các mạng hiệu suất cao. Tuy nhiên, cả hai kho lưu trữ cùng nhau
chứng minh kết quả cạnh tranh.

Chúng tôi sử dụng EfficientNet-B0, mà là mạng tiên tiến
trên CIFAR-10 Tan và Le [42] như một chỉ báo về vị trí thuật toán của chúng tôi
đứng. EfficientNet-B0 được tìm kiếm thông qua các phương pháp được áp dụng
bởi Tan và cộng sự . [41] và lớn hơn một chút so với nghiên cứu gốc vì
họ đang nhắm mục tiêu nhiều FLOPS hơn. Nghiên cứu gốc yêu cầu 8.000
đánh giá, trong khi LLMatic yêu cầu 2.000 đánh giá để tìm một
mạng cạnh tranh. EfficientNet-B0 đầu tiên được huấn luyện trên bộ dữ liệu Ima-
geNet [ 11] và sau đó trên CIFAR-10 thông qua học chuyển giao [ 45].
Đây là một lợi thế cho EfficientNet-B0 vì ImageNet có nhiều
lớp và là một bộ dữ liệu lớn hơn theo cấp độ.

Hình 3 chứng minh cách mỗi kho lưu trữ được lấp đầy trung bình. Chúng
ta có thể thấy rằng kho lưu trữ lời nhắc chứa các cá thể hiệu suất cao
mà có các lời nhắc đầu tiên và nhiệt độ cao hơn. Một số
của các cá thể hiệu suất cao có nhiệt độ thấp hơn,

--- TRANG 6 ---
GECCO '24, Ngày 14–18 tháng 7, 2024, Melbourne, VIC, Australia Muhammad U. Nasir, và cộng sự.

0 3 6 9 12 15 18
Thế hệ405060708090Độ chính xácEfficientNet-B0
LLMatic
Mutation-Only-LLMatic
Crossover-Only-LLMatic
Network-Archive-LLMatic
Prompt-Archive-LLMatic
Random-NN-Generation

Hình 2: Minh họa độ chính xác tốt nhất mỗi thế hệ cho LLMatic và tất cả các nghiên cứu cắt bỏ. Mỗi thí nghiệm được thực hiện
với 30 hạt giống. Vùng tô bóng là độ lệch chuẩn trong khi đường liền nét đại diện cho giá trị trung bình. EfficientNet-B0 là
EfficientNet hiệu suất tốt nhất trên CIFAR-10.

(a) Kho lưu trữ lời nhắc: Các lời nhắc được mã hóa như số nguyên trên trục 𝑥, được chuẩn hóa để nằm trong phạm vi 0-1
cho CVT-MAP-Elites vì tất cả các điểm
đều nằm trong 0–1. Trên trục 𝑦, chúng ta
có nhiệt độ mà điều khiển khả năng khám phá của LLM. Vì
1 là nhiệt độ tối đa, không
cần chuẩn hóa.

(b) Kho lưu trữ mạng: Tỷ lệ chiều rộng-so với-độ sâu trên trục 𝑥. Phạm vi cho Tỷ lệ Chiều rộng-So với-Độ sâu là từ 0–200 được chuẩn hóa thành
0–1. Trên trục 𝑦, chúng ta có Số Phép tính Dấu phẩy Động mỗi Giây
(FLOPS). Chúng ta có phạm vi từ 200
Mega FLOPS đến 5 Giga FLOPS. Phạm vi này được chuẩn hóa thành 0-1 cho
CVT-MAP-Elites.

Hình 3: Minh họa các kho lưu trữ được tạo ra bởi LLMatic .
Chúng tôi đã chọn kho lưu trữ với số lượng ô được lấp đầy trung vị trong các thí nghiệm trên 30 hạt giống. Hình 3a cho thấy
kho lưu trữ lời nhắc, trong khi Hình 3b cho thấy kho lưu trữ mạng.
Màu sắc của ô được lấp đầy càng sáng, thể dục của
cá thể càng tốt. Màu trắng cho biết ô trống.

mà gợi ý rằng đôi khi hữu ích để tạo ra các lớp mạng nơ-
ron theo cách ít ngẫu nhiên hơn. Đối với kho lưu trữ mạng, chúng tôi
quan sát một sự đa dạng của các mạng hiệu suất cao liên quan đến
cả FLOPS và tỷ lệ chiều rộng so với độ sâu. Hơn 20 cá thể là
các mạng cạnh tranh trong kho lưu trữ này.Để điều tra lựa chọn xác suất của chúng tôi cho lai ghép và đột
biến ( 0.3 và 0.7, tương ứng), chúng tôi quan sát số lượng mạng có thể huấn luyện
được tạo ra mỗi thế hệ (xem Hình 4). Chúng tôi sử dụng điều này như một
thước đo, vì càng nhiều cá thể chức năng chúng ta có, cơ hội của các cá thể hiệu suất cao càng lớn. Với mục đích này, chúng tôi
huấn luyện LLMatic với xác suất đồng nhất, và 0.3 cho đột biến và
0.7 cho lai ghép. Chúng tôi quan sát rằng xác suất đồng nhất vẫn
cạnh tranh với thiết lập gốc, trong khi tăng xác suất lai ghép
làm cho nó tệ hơn. Kết quả của các thí nghiệm này và
kết quả của nghiên cứu cắt bỏ cho Crossover-Only-LLMatic và
Mutation-Only-LLMatic dẫn chúng tôi đến kết luận rằng đột biến
nên được ưu tiên xác suất được chọn cao hơn.

5 THÍ NGHIỆM TRÊN NAS-BENCH-201
Tiếp theo, chúng tôi mở rộng thí nghiệm của LLMatic đến tiêu chuẩn NAS-bench-
201 [ 13], mà tìm kiếm một khối ô cho một
cấu trúc mạng nơ-ron không đổi. Cấu trúc được khởi tạo với một tích chập 3×3 với 16 kênh đầu ra và một lớp chuẩn hóa
lô [ 19]. Phần thân chính của khung xương bao gồm ba chồng của
các ô, được kết nối bởi một khối dư. Mỗi ô được chồng 5 lần,
với số lượng kênh đầu ra là 16,32 và 64 cho giai đoạn thứ nhất,
thứ hai và thứ ba, tương ứng. Khối dư trung gian
là khối dư cơ bản với bước 2[18], mà phục vụ để giảm mẫu kích thước không gian và nhân đôi các kênh
của bản đồ tính năng đầu vào. Đường tắt trong khối dư này
bao gồm một lớp pooling trung bình 2×2 với bước 2 và một
tích chập 1×1. Khung xương kết thúc với một lớp pooling trung bình toàn cầu
để làm phẳng bản đồ tính năng thành một vector tính năng. Phân loại
sử dụng một lớp kết nối đầy đủ với một lớp softmax để biến đổi
vector tính năng thành dự đoán cuối cùng.

Ô được chỉ định trong miền tìm kiếm được mô tả như một
đồ thị acyclic có hướng kết nối dày đặc với bốn nút và sáu

--- TRANG 7 ---
LLMatic: Tìm kiếm Kiến trúc Mạng nơ-ron thông qua Mô hình Ngôn ngữ Lớn và Tối ưu hóa Chất lượng Đa dạng GECCO '24, Ngày 14–18 tháng 7, 2024, Melbourne, VIC, Australia

0 3 6 9 12 15 18 21
Thế hệ5060708090Mạng có thể huấn luyện được tạo đột biến = 0.7, lai ghép = 0.3
đột biến = 0.5, lai ghép = 0.5
đột biến = 0.3, lai ghép = 0.7

Hình 4: Minh họa có bao nhiêu mạng có thể huấn luyện
được tạo ra trong một thế hệ. Tổng số mạng
được tạo ra là 100 mỗi thế hệ. Minh họa này được tính toán
trên 10 lần chạy. Vùng tô bóng là độ lệch chuẩn.

cạnh; ở đây, các nút tượng trưng cho bản đồ tính năng trong khi các cạnh biểu thị các thao
tác. Có năm thao tác có thể: (1) zero hóa, (2) kết nối
bỏ qua, (3) tích chập 1×1, (4) tích chập 3×3, và (5) lớp pooling trung bình 3×3. Zero hóa loại bỏ thao tác cạnh liên
quan. Với năm thao tác để chọn, tổng số
không gian tìm kiếm tiềm năng là 56=15625 kết hợp ô. Các đánh giá
được thực hiện trên CIFAR10, CIFAR100 [ 22], và ImageNet16-120 [ 8].
ImageNet16-120 là một biến thể của bộ dữ liệu ImageNet [ 38] mà được giảm mẫu xuống kích thước hình ảnh 16x16 và chứa 120 lớp đầu tiên.

5.1 Kết quả
Để duy trì nhất quán với các thí nghiệm trước của chúng tôi, LLMatic
tìm kiếm trong 20 thế hệ và 100 ô trong một thế hệ. Chúng tôi tuyển chọn
lời nhắc để phục vụ cho việc tạo ra có thể kiểm soát bằng cách hạn chế nó cho
năm thao tác. Tham khảo tài liệu bổ sung để biết ví dụ về cách chúng tôi tạo ra các ô có thể truy vấn. Đối với kho lưu trữ mạng của chúng tôi,
chúng tôi lấy FLOPS tối thiểu và tối đa làm ranh giới cho
bộ mô tả hành vi.

Bảng 1: So sánh độ chính xác thử nghiệm trên tiêu chuẩn NAS-bench-201. Chúng tôi cung cấp độ chính xác tối ưu để tham khảo,
mà là độ chính xác tối đa có thể đạt được trong NAS-
bench-201. Kết quả cho LLMatic được tính trung bình trên 10 lần chạy.

Phương pháp CIFAR-10 CIFAR-100 ImageNet16-120
DARTS 54.30 ±0.00 15.61 ±0.00 16.32 ±0.00
Tìm kiếm Ngẫu nhiên 93.70 ±0.36 71.04 ±1.07 44.57 ±1.25
GENIUS 93.79 ±0.09 70.91 ±0.72 44.96 ±1.02
Λ-DARTS 94.36 ±0.00 73.51 ±0.00 46.34 ±0.00
LLMatic 94.26 ±0.13 71.62 ±1.73 45.87 ±0.96
Tối ưu 94.47 74.17 47.33Chúng tôi so sánh kết quả của chúng tôi với thuật toán NAS dựa trên GPT-4
GENIUS [ 53], mà phục vụ như một đường cơ sở LLM, cũng như tìm kiếm ngẫu nhiên. Chúng tôi cũng so sánh với công trình trước đó, bao gồm DARTS [ 24] và
Λ-DARTS [ 29], mà đạt được kết quả gần tối ưu. Như Bảng 1 cho
thấy, LLMatic vượt trội hơn NAS dựa trên GPT-4, và tạo ra
kết quả gần tiên tiến, mặc dù nó có biến đổi nhiều hơn
các phương pháp cạnh tranh.

Hơn nữa, trong Hình 5 chúng tôi điều tra các mạng được khám phá
bởi LLMatic qua mỗi thế hệ. Chúng tôi quan sát rằng phân bố
của các mạng được tìm thấy lan rộng rộng trong không gian tìm kiếm. Điều này là do
bản chất thủ tục và khả năng khám phá của LLMatic

(a) CIFAR-10

(b) CIFAR-100

(c) ImageNet16-120

Hình 5: Minh họa độ chính xác thử nghiệm của tất cả mạng qua
tất cả bộ dữ liệu và các mạng tốt nhất được tìm thấy trong mỗi thế hệ bởi
LLMatic .

--- TRANG 8 ---
GECCO '24, Ngày 14–18 tháng 7, 2024, Melbourne, VIC, Australia Muhammad U. Nasir, và cộng sự.

Bảng 2: Thứ hạng tối đa đạt được bởi LLMatic trên mỗi bộ dữ liệu
trong NAS-bench-201.

Phương pháp Thứ hạng
CIFAR-10 2
CIFAR-100 2
ImageNet16-120 11

thông qua kho lưu trữ lời nhắc. Để chứng minh các mạng gần tối ưu chúng tôi minh họa trong Bảng 2 các mạng được xếp hạng tối đa dựa trên
độ chính xác thử nghiệm được tìm kiếm bởi LLMatic .

6 KẾT LUẬN VÀ CÔNG VIỆC TƯƠNG LAI
Để kết luận, chúng tôi trình bày LLMatic : một thuật toán tìm kiếm kiến trúc mạng nơ-ron (NAS) mới mà khai thác sức mạnh của các mô hình ngôn ngữ lớn (LLM) và các thuật toán tối ưu hóa Chất lượng-Đa dạng (QD).
LLMatic thành công tìm thấy các mạng cạnh tranh mà đa dạng
trong kiến trúc. Chúng tôi chứng minh thực nghiệm rằng LLMatic có thể tìm thấy hơn 20 mạng cạnh tranh trong CIFAR-10 và các mạng gần tối ưu trong NAS-bench-201, chỉ sử dụng 2000 đánh giá. LLMatic giảm
kích thước quần thể tối đa mỗi thế hệ xuống chỉ 100.LLMatic
đạt được điều này trong khi dựa vào một mô hình ngôn ngữ 6.1B tham số.
Hơn nữa, chúng tôi chứng minh rằng mỗi thành phần trong LLMatic là cần
thiết. Chúng tôi thực hiện một nghiên cứu cắt bỏ mở rộng và phát hiện rằng
LLMatic tìm thấy mạng với độ chính xác tốt nhất trong số các
biến thể khác.

LLMatic đạt được điều này với nhiều ràng buộc trong tay. Thứ nhất,
chúng tôi sử dụng LLM tạo mã CodeGen-6.1B, mà là một mô hình ngôn ngữ nhỏ hơn khi so sánh với các LLM hiện có. Điều này chứng minh
hiệu quả tính toán của LLMatic, và cho chúng tôi lý do
để tin rằng những cải tiến thêm có thể được mở khóa bằng cách kết hợp
các mô hình ngôn ngữ lớn hơn Thứ hai, do tài nguyên tính toán, chúng tôi giữ tìm kiếm của chúng tôi ở 2000, và vẫn tìm thấy các mạng cạnh tranh.
Trong công việc tương lai, LLMatic nên được so sánh với các phương pháp NAS khác trên các nhiệm vụ thị giác máy tính và xử lý ngôn ngữ tự nhiên khác. Vì neuroevolution tương tự như NAS, LLMatic có thể được so sánh
với các tiêu chuẩn học tăng cường cũng như. Với điều này, LLMatic
có thể được sử dụng trong các nhiệm vụ như học mở như vậy [31].

7 LỜI CẢM ơN
Các tác giả ghi nhận Trung tâm Tính toán Hiệu suất Cao (CHPC), Nam Phi, vì đã cung cấp tài nguyên tính toán
cho dự án nghiên cứu này.

TÀI LIỆU THAM KHẢO
[1]David Ifeoluwa Adelani, Jesujoba Oluwadara Alabi, Angela Fan, Julia Kreutzer,
Xiaoyu Shen, Machel Reid, Dana Ruiter, Dietrich Klakow, Peter Nabende, Ernie
Chang, và cộng sự .2022. Một vài nghìn bản dịch đi một chặng đường dài! tận dụng các mô hình được huấn luyện trước cho dịch tin tức châu Phi. arXiv preprint arXiv:2205.02022
(2022).
[2]Helon Vicente Hultmann Ayala, Daniel M Muñoz, Carlos H Llanos, và Leandro
dos Santos Coelho. 2017. Triển khai phần cứng hiệu quả của mạng nơ-ron hàm cơ sở radial với các phép toán dấu phẩy động độ chính xác tùy chỉnh.
Control Engineering Practice 60 (2017), 124–132.
[3]Jon Louis Bentley. 1975. Cây tìm kiếm nhị phân đa chiều được sử dụng để tìm kiếm
liên kết. Commun. ACM 18, 9 (1975), 509–517.
[4]Léon Bottou. 2010. Học máy quy mô lớn với gradient descent ngẫu nhiên.
TrongProceedings của COMPSTAT'2010: Hội nghị Quốc tế lần thứ 19 về Thống kêParis France, Ngày 22-27 tháng 8, 2010 Bài phát biểu chính, Được mời và Bài báo Đóng góp . Springer, 177–186.
[5]Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan,
Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda
Askell, và cộng sự .2020. Mô hình ngôn ngữ là những người học ít shot. Advances in neural
information processing systems 33 (2020), 1877–1901.
[6]Angelica Chen, David M Dohan, và David R So. 2023. EvoPrompting: Mô hình Ngôn ngữ cho Tìm kiếm Kiến trúc Mạng nơ-ron Cấp Mã. arXiv preprint
arXiv:2302.14838 (2023).
[7]Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira
Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman,
và cộng sự.2021. Đánh giá các mô hình ngôn ngữ lớn được huấn luyện trên mã. arXiv preprint
arXiv:2107.03374 (2021).
[8]Patryk Chrabaszcz, Ilya Loshchilov, và Frank Hutter. 2017. Một biến thể giảm mẫu
của imagenet như một thay thế cho bộ dữ liệu cifar. arXiv preprint
arXiv:1707.08819 (2017).
[9]Antoine Cully, Jeff Clune, Danesh Tarapore, và Jean-Baptiste Mouret. 2015.
Robot mà có thể thích ứng như động vật. Nature 521, 7553 (2015), 503–507.
[10] Antoine Cully và Yiannis Demiris. 2017. Tối ưu hóa chất lượng và đa dạng: Một
khung mô-đun thống nhất. IEEE Transactions on Evolutionary Computation 22,
2 (2017), 245–259.
[11] Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, và Li Fei-Fei. 2009. Imagenet:
Một cơ sở dữ liệu hình ảnh phân cấp quy mô lớn. Trong 2009 IEEE conference on computer
vision and pattern recognition . Ieee, 248–255.
[12] Ivan Dokmanic, Reza Parhizkar, Juri Ranieri, và Martin Vetterli. 2015. Ma trận khoảng cách Euclidean: lý thuyết thiết yếu, thuật toán, và ứng dụng. IEEE Signal
Processing Magazine 32, 6 (2015), 12–30.
[13] Xuanyi Dong và Yi Yang. 2020. nas-bench-201: Mở rộng phạm vi của tìm kiếm kiến trúc mạng nơ-ron có thể tái tạo. arXiv preprint arXiv:2001.00326 (2020).
[14] Thomas Elsken, Jan Hendrik Metzen, và Frank Hutter. 2019. Tìm kiếm kiến trúc mạng nơ-ron: Một khảo sát. The Journal of Machine Learning Research 20, 1 (2019), 1997–
2017.
[15] Adam Gaier, Alexander Asteroth, và Jean-Baptiste Mouret. 2019. Các thuật toán chất lượng đa dạng có tốt hơn trong việc tạo ra bước đệm so với tìm kiếm dựa trên mục tiêu không?. Trong Proceedings của Genetic và Evolutionary Computation Conference
Companion . 115–116.
[16] Leo Gao, Stella Biderman, Sid Black, Laurence Golding, Travis Hoppe, Charles
Foster, Jason Phang, Horace He, Anish Thite, Noa Nabeshima, và cộng sự .2020. Đống: Một bộ dữ liệu 800gb văn bản đa dạng cho mô hình hóa ngôn ngữ. arXiv preprint
arXiv:2101.00027 (2020).
[17] Sam Greydanus. 2020. Mở rộng xuống học sâu. arXiv preprint
arXiv:2011.14439 (2020).
[18] Kaiming He, Xiangyu Zhang, Shaoqing Ren, và Jian Sun. 2016. Học dư sâu
cho nhận dạng hình ảnh. Trong Proceedings của IEEE conference on computer
vision và pattern recognition . 770–778.
[19] Sergey Ioffe và Christian Szegedy. 2015. Chuẩn hóa lô: Tăng tốc huấn luyện mạng sâu bằng cách giảm sự dịch chuyển hiệp biến nội bộ. Trong International conference
on machine learning . pmlr, 448–456.
[20] Yesmina Jaafra, Jean Luc Laurent, Aline Deruyver, và Mohamed Saber Naceur.
2019. Học tăng cường cho tìm kiếm kiến trúc mạng nơ-ron: Một đánh giá. Image
and Vision Computing 89 (2019), 57–66.
[21] Kirthevasan Kandasamy, Willie Neiswanger, Jeff Schneider, Barnabas Poczos, và
Eric P Xing. 2018. Tìm kiếm kiến trúc mạng nơ-ron với tối ưu hóa bayesian và
vận chuyển tối ưu. Advances in neural information processing systems 31 (2018).
[22] Alex Krizhevsky, Geoffrey Hinton, và cộng sự .2009. Học nhiều lớp tính năng
từ hình ảnh nhỏ. (2009).
[23] Joel Lehman, Jonathan Gordon, Shawn Jain, Kamal Ndousse, Cathy Yeh, và
Kenneth O Stanley. 2022. Tiến hóa thông qua mô hình lớn. arXiv preprint
arXiv:2206.08896 (2022).
[24] Hanxiao Liu, Karen Simonyan, và Yiming Yang. 2018. darts: Tìm kiếm kiến trúc có thể vi phân. arXiv preprint arXiv:1806.09055 (2018).
[25] Yuqiao Liu, Yanan Sun, Bing Xue, Mengjie Zhang, Gary G Yen, và Kay Chen
Tan. 2021. Một khảo sát về tìm kiếm kiến trúc mạng nơ-ron tiến hóa. IEEE transactions
on neural networks and learning systems (2021).
[26] Yash Mehta, Colin White, Arber Zela, Arjun Krishnakumar, Guri Zabergja, Shak-
iba Moradian, Mahmoud Safari, Kaicheng Yu, và Frank Hutter. 2022. NAS-Bench-
Suite: Đánh giá NAS là (bây giờ) đáng ngạc nhiên dễ dàng. arXiv preprint arXiv:2201.13396
(2022).
[27] Geoffrey F Miller, Peter M Todd, và Shailesh U Hegde. 1989. Thiết kế Mạng nơ-ron Sử dụng Thuật toán Di truyền.. Trong ICGA , Tập. 89. 379–384.
[28] Jean-Baptiste Mouret và Jeff Clune. 2015. Chiếu sáng không gian tìm kiếm bằng cách ánh xạ
tinh hoa. arXiv preprint arXiv:1504.04909 (2015).
[29] Sajad Movahedi, Melika Adabinejad, Ayyoob Imani, Arezou Keshavarz, Mostafa
Dehghani, Azadeh Shakery, và Babak N Araabi. 2022. Δ-DARTS: Giảm thiểu
Sụp đổ Hiệu suất bằng cách Hài hòa Lựa chọn Thao tác giữa các Ô. arXiv
preprint arXiv:2210.07998 (2022).
[30] Vinod Nair và Geoffrey E Hinton. 2010. Đơn vị tuyến tính rectified cải thiện máy boltzmann hạn chế. Trong Proceedings của hội nghị quốc tế lần thứ 27

--- TRANG 9 ---
LLMatic: Tìm kiếm Kiến trúc Mạng nơ-ron thông qua Mô hình Ngôn ngữ Lớn và Tối ưu hóa Chất lượng Đa dạng GECCO '24, Ngày 14–18 tháng 7, 2024, Melbourne, VIC, Australia

về học máy (ICML-10) . 807–814.
[31] Muhammad Umair Nasir, Michael Beukman, Steven James, và Christopher Wes-
ley Cleghorn. 2022. Tác nhân Topology Tăng cường Cho Học Mở. arXiv preprint arXiv:2210.11442 (2022).
[32] Muhammad Umair Nasir và Innocent Amos Mchechesi. 2022. Khoảng cách địa lý là siêu tham số mới: Một nghiên cứu trường hợp tìm mô hình ngôn ngữ được huấn luyện trước tối ưu cho dịch máy tiếng Anh-isiZulu. arXiv preprint arXiv:2205.08621
(2022).
[33] Muhammad U Nasir và Julian Togelius. 2023. PCG Thực tế Thông qua Mô hình Ngôn ngữ Lớn. arXiv preprint arXiv:2305.18243 (2023).
[34] Erik Nijkamp, Bo Pang, Hiroaki Hayashi, Lifu Tu, Huan Wang, Yingbo Zhou,
Silvio Savarese, và Caiming Xiong. 2022. Codegen: Một mô hình ngôn ngữ lớn mở cho mã với tổng hợp chương trình đa lượt. arXiv preprint arXiv:2203.13474
(2022).
[35] Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory
Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, và cộng sự .2019.
Pytorch: Một thư viện học sâu có phong cách bắt buộc, hiệu suất cao. Advances
in neural information processing systems 32 (2019).
[36] Justin K Pugh, Lisa B Soros, và Kenneth O Stanley. 2016. Chất lượng đa dạng: Một
biên giới mới cho tính toán tiến hóa. Frontiers in Robotics and AI (2016),
40.
[37] Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever,
và cộng sự.2019. Mô hình ngôn ngữ là những người học đa nhiệm không giám sát. OpenAI blog
1, 8 (2019), 9.
[38] Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean
Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, và cộng sự .
2015. Imagenet thách thức nhận dạng thị giác quy mô lớn. International journal of
computer vision 115 (2015), 211–252.
[39] Noah Shinn, Federico Cassano, Ashwin Gopinath, Karthik R Narasimhan, và
Shunyu Yao. 2023. Reflexion: Tác nhân ngôn ngữ với học tăng cường bằng lời.
TrongHội nghị lần thứ ba mười bảy về Hệ thống Xử lý Thông tin Nơ-ron .
[40] Kenneth O Stanley và Risto Miikkulainen. 2002. Tiến hóa mạng nơ-ron
thông qua việc tăng cường topology. Evolutionary computation 10, 2 (2002), 99–127.
[41] Mingxing Tan, Bo Chen, Ruoming Pang, Vijay Vasudevan, Mark Sandler, Andrew
Howard, và Quoc V Le. 2019. Mnasnet: Tìm kiếm kiến trúc mạng nơ-ron nhận biết nền tảng cho di động. Trong Proceedings của IEEE/CVF conference on computer vision
and pattern recognition . 2820–2828.
[42] Mingxing Tan và Quoc Le. 2019. Efficientnet: Suy nghĩ lại về mở rộng mô hình cho
mạng nơ-ron tích chập. Trong International conference on machine learning .PMLR, 6105–6114.
[43] Manoel Tenorio và Wei-Tsih Lee. 1988. Mạng nơ-ron tự tổ chức cho
bài toán nhận dạng. Advances in Neural Information Processing Systems 1
(1988).
[44] Graham Todd, Sam Earle, Muhammad Umair Nasir, Michael Cerny Green, và
Julian Togelius. 2023. Tạo Cấp độ Thông qua Mô hình Ngôn ngữ Lớn. Trong
Proceedings của Hội nghị Quốc tế lần thứ 18 về Nền tảng của Trò chơi Kỹ thuật số . 1–8.
[45] Lisa Torrey và Jude Shavlik. 2010. Học chuyển giao. Trong Handbook of research
on machine learning applications and trends: algorithms, methods, and techniques .
IGI global, 242–264.
[46] Sami Ullah, Abdus Salam, và Mohsin Masood. 2022. Phân tích và so sánh
một toán tử đột biến được đề xuất và ảnh hưởng của nó lên hiệu suất của thuật toán di truyền. Indonesian Journal of Electrical Engineering and Computer Science 25,
2 (2022), 1208–12168.
[47] Vassilis Vassiliades, Konstantinos Chatzilygeroudis, và Jean-Baptiste Mouret.
2017. Sử dụng tessellation voronoi centroidal để mở rộng thuật toán lưu trữ đa chiều của tinh hoa kiểu hình. IEEE Transactions on Evolutionary Com-
putation 22, 4 (2017), 623–630.
[48] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
Aidan N Gomez, Łukasz Kaiser, và Illia Polosukhin. 2017. Attention là tất cả
bạn cần. Advances in neural information processing systems 30 (2017).
[49] Petar Veličković, Adrià Puigdomènech Badia, David Budden, Razvan Pascanu,
Andrea Banino, Misha Dashevskiy, Raia Hadsell, và Charles Blundell. 2022. Tiêu chuẩn lý luận thuật toán CLRS. Trong International Conference on Machine
Learning . PMLR, 22084–22102.
[50] Colin White, Mahmoud Safari, Rhea Sukthanker, Binxin Ru, Thomas Elsken,
Arber Zela, Debadeepta Dey, và Frank Hutter. 2023. Tìm kiếm kiến trúc mạng nơ-ron:
Insights từ 1000 bài báo. arXiv preprint arXiv:2301.08727 (2023).
[51] Martin Wistuba. 2017. Tìm kiến trúc mạng cạnh tranh trong một ngày
sử dụng uct. arXiv preprint arXiv:1712.07420 (2017).
[52] Chris Ying, Aaron Klein, Eric Christiansen, Esteban Real, Kevin Murphy, và
Frank Hutter. 2019. nas-bench-101: Hướng tới tìm kiếm kiến trúc mạng nơ-ron có thể tái tạo. Trong International Conference on Machine Learning . PMLR, 7105–7114.
[53] Mingkai Zheng, Xiu Su, Shan You, Fei Wang, Chen Qian, Chang Xu, và Samuel
Albanie. 2023. GPT-4 Có thể Thực hiện Tìm kiếm Kiến trúc Mạng nơ-ron không? arXiv preprint
arXiv:2304.10970 (2023).

# 2207.03677.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/automl-nas/2207.03677.pdf
# Kích thước tệp: 19579077 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
SuperTickets: Vẽ Lottery Tickets Bất khả tri Tác vụ
từ Supernets thông qua Đồng thời
Tìm kiếm Kiến trúc và Cắt tỉa Tham số
Haoran You1⋆, Baopu Li3, Zhanyi Sun2, Xu Ouyang2, và Yingyan Lin1
1Georgia Institute of Technology2Rice University3Oracle Health and AI
{hyou37, celine.lin }@gatech.edu {zs19,xo2 }@rice.edu ,baopu.li@oracle.com
Tóm tắt. Tìm kiếm kiến trúc mạng nơ-ron (NAS) đã thể hiện thành
công đáng kinh ngạc trong việc tìm kiếm các mạng nơ-ron sâu hiệu quả (DNNs) từ
một supernet cho trước. Song song với đó, giả thuyết lottery ticket đã chỉ ra rằng
DNNs chứa các mạng con nhỏ có thể được huấn luyện từ đầu để
đạt được độ chính xác tương đương hoặc thậm chí cao hơn so với DNNs ban đầu.
Do đó, hiện tại đây là một thực hành phổ biến để phát triển DNNs hiệu quả thông qua
một quy trình đầu tiên tìm kiếm rồi sau đó cắt tỉa. Tuy nhiên, làm như vậy thường
yêu cầu một quá trình tẻ nhạt và tốn kém của tìm kiếm-huấn luyện-cắt tỉa-huấn luyện lại và
do đó chi phí tính toán cấm đoán. Trong bài báo này, chúng tôi khám phá lần đầu tiên rằng cả DNNs hiệu quả và các mạng con lottery của chúng (tức là,
lottery tickets) có thể được xác định trực tiếp từ một supernet, mà chúng tôi gọi
là SuperTickets, thông qua một sơ đồ huấn luyện hai-trong-một với đồng thời tìm
kiếm kiến trúc và cắt tỉa tham số. Hơn nữa, chúng tôi phát triển một chiến lược xác định SuperTickets tiến bộ và thống nhất cho phép khả năng
kết nối của các mạng con thay đổi trong quá trình huấn luyện supernet, đạt
được sự đánh đổi tốt hơn giữa độ chính xác và hiệu quả so với huấn luyện thưa thông thường. Cuối cùng, chúng tôi đánh giá liệu các SuperTickets được xác định như vậy được rút ra
từ một tác vụ có thể chuyển đổi tốt sang các tác vụ khác không, xác thực tiềm năng của chúng
trong việc đồng thời xử lý nhiều tác vụ. Các thí nghiệm rộng rãi và nghiên cứu loại bỏ trên ba tác vụ và bốn bộ dữ liệu chuẩn xác thực
rằng SuperTickets được đề xuất của chúng tôi đạt được sự đánh đổi tăng cường giữa độ chính xác và hiệu quả so với cả quy trình NAS và cắt tỉa điển hình, bất kể có
huấn luyện lại hay không. Mã nguồn và mô hình được huấn luyện trước có sẵn tại
\textcolor{blue}{https://github.com/RICE-EIC/SuperTickets} .
Từ khóa: Giả thuyết Lottery Ticket, Huấn luyện/Suy luận Hiệu quả, Tìm
kiếm Kiến trúc Mạng Nơ-ron, DNNs Bất khả tri Tác vụ
1 Giới thiệu
Trong khi các mạng nơ-ron sâu (DNNs) đã đạt được hiệu suất chưa từng có
trong các tác vụ và ứng dụng khác nhau như phân loại, phân đoạn và phát
hiện [8], chi phí huấn luyện và suy luận cấm đoán của chúng hạn chế việc triển khai của chúng trên
⋆Công việc được thực hiện khi thực tập tại Baidu USA; Liên hệ với Baopu Li và Yingyan
LinarXiv:2207.03677v5  [cs.CV]  3 Mar 2025

--- TRANG 2 ---
2 H. You et al.
các thiết bị có tài nguyên hạn chế để có trí tuệ phổ biến hơn. Ví dụ, một
lần truyền tiến của ResNet50 [16] yêu cầu 4 GFLOPs (FLOPs: các phép toán điểm nổi) và việc huấn luyện của nó yêu cầu 1018FLOPs [49]. Để thu hẹp khoảng cách
nói trên, các nỗ lực rộng rãi đã được thực hiện để nén DNNs từ cả
kiến trúc macro (ví dụ, NAS [37,44,8]) hoặc mức tham số chi tiết (ví dụ, cắt tỉa mạng
[15,11]). Một quy trình nén DNN được áp dụng phổ biến theo
nguyên tắc từ thô đến tinh là đầu tiên tự động tìm kiếm các kiến trúc
DNN hiệu quả và mạnh mẽ từ một supernet lớn hơn và sau đó cắt tỉa các DNNs được tìm kiếm
thông qua quá trình huấn luyện-cắt tỉa-huấn luyện lại tốn kém [10,9,21] để dẫn xuất các mạng con
nhỏ hơn và thưa hơn với độ chính xác tương đương hoặc giảm nhưng chi phí suy luận
giảm đáng kể. Tuy nhiên, quy trình như vậy yêu cầu một quá trình tìm kiếm-huấn luyện-cắt tỉa-huấn luyện lại
tẻ nhạt và do đó vẫn có chi phí huấn luyện cấm đoán.
Để giải quyết hạn chế trên nhằm đơn giản hóa quy trình và cải thiện hơn nữa
sự đánh đổi độ chính xác-hiệu quả của các mạng được xác định, chúng tôi ủng hộ
một khung huấn luyện hai-trong-một để đồng thời xác định cả DNNs hiệu quả
và các mạng con lottery của chúng thông qua đồng thời tìm kiếm kiến trúc và cắt
tỉa tham số. Chúng tôi gọi các mạng con nhỏ được xác định là SuperTickets
nếu chúng đạt được sự đánh đổi độ chính xác-hiệu quả tương đương hoặc thậm chí vượt trội hơn so với
các đường cơ sở tìm kiếm-rồi-cắt tỉa được áp dụng trước đây, bởi vì chúng được rút ra từ su-
pernets và đại diện cho cả kiến trúc DNN thô và mạng con
DNN chi tiết. Chúng tôi thực hiện những nỗ lực không tầm thường để khám phá và xác thực tiềm
năng của SuperTickets bằng cách trả lời ba câu hỏi chính: (1) liệu các Su-
perTickets như vậy có thể được tìm thấy trực tiếp từ một supernet thông qua huấn luyện hai-trong-một không? Nếu có,
thì (2) làm thế nào để hiệu quả xác định các SuperTickets như vậy? và (3) SuperTick-
ets được tìm thấy từ một tác vụ/bộ dữ liệu có thể chuyển sang tác vụ khác không, tức là, có tiềm năng
xử lý các tác vụ/bộ dữ liệu khác nhau không? Theo hiểu biết tốt nhất của chúng tôi, đây là lần đầu tiên
được thực hiện hướng tới việc xác định cả kiến trúc DNN và các mạng con lottery ticket tương ứng
thông qua một sơ đồ huấn luyện hai-trong-một thống nhất. Đóng góp của chúng tôi có thể được tóm tắt như sau:
•Chúng tôi lần đầu tiên khám phá rằng các kiến trúc DNN hiệu quả và các
mạng con lottery của chúng, tức là, SuperTickets, có thể được xác định đồng thời từ
một supernet dẫn đến sự đánh đổi độ chính xác-hiệu quả vượt trội.
•Chúng tôi phát triển một chiến lược xác định tiến bộ thống nhất để hiệu quả tìm
các SuperTickets thông qua một sơ đồ huấn luyện hai-trong-một cho phép các mạng con
lặp lại kích hoạt lại các kết nối đã cắt tỉa trong quá trình huấn luyện, mang
lại hiệu suất tốt hơn so với huấn luyện thưa thông thường. Đáng chú ý, các
SuperTickets được xác định của chúng tôi mà không cần huấn luyện lại đã vượt trội hơn các
đường cơ sở đầu tiên-tìm kiếm-rồi-cắt tỉa được áp dụng trước đây, và do đó có thể được triển khai trực tiếp.
•Chúng tôi xác thực khả năng chuyển đổi của các SuperTickets được xác định qua các
tác vụ/bộ dữ liệu khác nhau, và tiến hành các thí nghiệm rộng rãi để so sánh các
SuperTickets được đề xuất với những cái từ các đường cơ sở tìm kiếm-rồi-cắt tỉa hiện có, các
kỹ thuật NAS điển hình, và các công trình cắt tỉa. Kết quả trên ba tác vụ và bốn bộ dữ liệu
chứng minh sự đánh đổi độ chính xác-hiệu quả vượt trội nhất quán và khả năng chuyển đổi
đầy hứa hẹn để xử lý các tác vụ khác nhau được cung cấp bởi SuperTickets.

--- TRANG 3 ---
SuperTickets 3
2 Các Công trình Liên quan
Tìm kiếm Kiến trúc Mạng Nơ-ron (NAS). NAS đã đạt được thành
công đáng kinh ngạc trong việc tự động hóa thiết kế các kiến trúc DNN hiệu quả và tăng cường sự đánh đổi độ chính xác-
hiệu quả [56,38,17]. Để tìm kiếm DNNs cụ thể cho tác vụ, các công trình ban đầu
[38,37,17] áp dụng các phương pháp dựa trên học tăng cường đòi hỏi thời gian tìm kiếm
cấm đoán và tài nguyên tính toán, trong khi các công trình gần đây [24,44,40,47] cập nhật
cả trọng số và kiến trúc trong quá trình huấn luyện supernet thông qua tìm kiếm có thể vi phân
có thể cải thiện đáng kể hiệu quả tìm kiếm so với các công trình NAS
trước đó. Gần đây hơn, một số công trình áp dụng NAS một lần [14,3,52,41] để tách
việc tìm kiếm kiến trúc khỏi huấn luyện supernet. Các phương pháp như vậy thường có thể
áp dụng để tìm kiếm CNNs hiệu quả [14,2] hoặc Transformers [42,4,36] để giải quyết
cả các tác vụ thị giác và ngôn ngữ. Để tìm kiếm DNNs đa tác vụ, các công trình
mới nổi gần đây như HR-NAS [8] và FBNetv5 [45] ủng hộ các thiết kế supernet với
các nhánh đa độ phân giải để phù hợp với cả phân loại hình ảnh và
các tác vụ dự đoán dày đặc khác yêu cầu các biểu diễn độ phân giải cao. Trong công trình này, chúng tôi đề xuất tìm kiếm trực tiếp không chỉ DNNs hiệu quả mà còn các mạng con lottery
của chúng từ supernets để đạt được sự đánh đổi độ chính xác-hiệu quả tốt hơn
trong khi có thể xử lý các tác vụ khác nhau.
Giả thuyết Lottery Ticket (LTH). Frankle et al. [11,12] đã chỉ ra rằng
các vé trúng (tức là, các mạng con nhỏ) tồn tại trong các mạng dày đặc
được khởi tạo ngẫu nhiên, có thể được huấn luyện lại để khôi phục độ chính xác tương đương hoặc thậm chí tốt hơn
so với các đối tác mạng dày đặc của chúng. Phát hiện này đã truyền cảm hứng cho nhiều hướng nghiên cứu
vì nó ngụ ý tiềm năng của các mạng con thưa. Để huấn luyện hiệu quả,
You et al. [49] liên tục tìm thấy các vé trúng ở các giai đoạn huấn luyện sớm,
giảm đáng kể chi phí huấn luyện của DNNs. Phát hiện như vậy đã được mở rộng cho các
mô hình ngôn ngữ (ví dụ, BERT) [5], các mô hình sinh (ví dụ, GAN) [31], và mạng nơ-ron đồ thị [50]; Zhang et al. [54] nhận ra các vé trúng hiệu quả hơn
bằng cách huấn luyện chỉ với một tập con được chọn đặc biệt của dữ liệu; và Ramanujan et al.
[33] tiếp tục xác định các vé trúng trực tiếp từ khởi tạo ngẫu nhiên hoạt động
tốt ngay cả khi không có huấn luyện lại. Ngược lại, mục tiêu của chúng tôi là đồng thời tìm
cả DNNs hiệu quả và các mạng con lottery của chúng từ supernets, vượt ra ngoài
phạm vi của huấn luyện thưa hoặc rút ra các vé trúng từ các mô hình DNN dày đặc.
Thiết kế DNNs Bất khả tri Tác vụ. Để tạo điều kiện thiết kế DNNs cho các
tác vụ khác nhau, các công trình gần đây [25,17,43] đề xuất thiết kế các xương sống kiến trúc
tổng quát cho các tác vụ thị giác máy tính khác nhau. Ví dụ, HR-Net [43] duy trì
các biểu diễn độ phân giải cao thông qua toàn bộ mạng để hỗ trợ các tác vụ dự đoán dày đặc,
thay vì kết nối các convolution độ phân giải cao-đến-thấp trong chuỗi
như ResNet hoặc VGGNet; Swin-Transformer [25] áp dụng các vision transformers phân cấp
để phục vụ như một xương sống đa mục đích tương thích với
một phạm vi rộng các tác vụ thị giác; ViLBERT [27,28] đề xuất một mô hình hai luồng đa phương thức
để học các biểu diễn kết hợp bất khả tri tác vụ của cả hình ảnh và
ngôn ngữ; Data2vec [1] thiết kế một khung tổng quát cho học tự giám sát
trong lời nói, thị giác và ngôn ngữ. Hơn nữa, các công trình gần đây [8,45,46] cũng tận dụng
NAS để tự động tìm kiếm DNNs bất khả tri tác vụ và hiệu quả từ các
supernets được chế tác thủ công. Trong công trình này, chúng tôi nhằm xác định các SuperTickets
bất khả tri tác vụ đạt được sự đánh đổi độ chính xác-hiệu quả tốt hơn.

--- TRANG 4 ---
4 H. You et al.
3 Phương pháp SuperTickets Được đề xuất
Trong phần này, chúng tôi giải quyết ba câu hỏi chính của SuperTickets. Đầu tiên, chúng tôi
phát triển một sơ đồ huấn luyện hai-trong-một để xác thực giả thuyết của chúng tôi rằng SuperTick-
ets tồn tại và có thể được tìm thấy trực tiếp từ một supernet. Thứ hai, chúng tôi tiếp tục khám phá
các chiến lược xác định SuperTickets hiệu quả hơn thông qua kích hoạt lại nơ-ron lặp
và cắt tỉa tiến bộ, tăng cường đáng kể sự đánh đổi độ chính xác-hiệu quả. Thứ ba, chúng tôi đánh giá khả năng chuyển đổi của các SuperTickets được xác định qua
các bộ dữ liệu hoặc tác vụ khác nhau, xác thực tiềm năng của chúng trong việc bất khả tri tác vụ.
3.1 SuperTickets Có Tồn tại trong Supernets không?
Giả thuyết SuperTickets. Chúng tôi giả thuyết rằng cả kiến trúc DNN hiệu quả
và các mạng con lottery của chúng có thể được xác định trực tiếp từ một su-
pernet, và gọi các mạng con này là SuperTickets nếu chúng đạt được sự đánh đổi độ chính xác-hiệu quả
ngang bằng hoặc thậm chí tốt hơn so với những cái từ các đối tác đầu tiên-tìm kiếm-rồi-
cắt tỉa. Xem xét một supernet f(x;θS), các kiến trúc DNN khác nhau
a được lấy mẫu từ nó có trọng số được biểu diễn bởi θS(a), sau đó chúng ta có thể định nghĩa SuperTickets như f(x;m⊙θS(a)), trong đó m∈ {0,1} là một mặt nạ để chỉ ra
các kết nối đã cắt tỉa và chưa cắt tỉa trong các DNNs được tìm kiếm. Giả thuyết SuperTickets
ngụ ý rằng tối ưu hóa đồng thời các kiến trúc DNN a và các
mặt nạ thưa tương ứng m hoạt động tốt hơn, tức là, dẫn đến sự đánh đổi độ chính xác-hiệu quả vượt trội,
so với tối ưu hóa chúng tuần tự.
Cài đặt Thí nghiệm. Để thực hiện các thí nghiệm khám phá liệu Su-
perTickets có tồn tại nói chung không, chúng tôi cần (1) một supernet phù hợp xem xét cả các
khối xây dựng hiệu quả cổ điển và các nguyên tắc thiết kế DNN bất khả tri tác vụ và (2) các tác vụ, bộ dữ liệu và metric tương ứng. Chúng tôi trình bày chi tiết các
cài đặt của chúng tôi dưới đây. NAS và Supernets: Chúng tôi xem xét một không gian tìm kiếm đa nhánh
chứa cả các khối xây dựng convolution và attention hiệu quả theo một
công trình tiên tiến (SOTA) của HR-NAS [8], có không gian tìm kiếm đa độ phân giải phân cấp độc đáo
để xử lý nhiều tác vụ thị giác nổi bật so với các cái khác. Nói chung, nó chứa hai đường dẫn: MixConv [39] và Transformer
nhẹ để trích xuất cả thông tin ngữ cảnh địa phương và toàn cầu. Cả số lượng kênh convolution với các kích thước kernel khác nhau và số lượng token trong
Transformer đều là các tham số có thể tìm kiếm. Tác vụ, Bộ dữ liệu và Metric: Chúng tôi
xem xét phân đoạn ngữ nghĩa trên Cityscapes [6] và ước lượng tư thế con người
trên COCO keypoint [22] như hai tác vụ đại diện để minh họa. Đối với
Cityscapes, giao nhau trung bình trên liên hợp (mIoU), độ chính xác trung bình (mAcc),
và độ chính xác tổng thể (aAcc) là các metric đánh giá. Đối với COCO keypoint, chúng tôi
huấn luyện mô hình sử dụng kích thước đầu vào 256 ×192, tốc độ học ban đầu là 1e-3, kích thước batch
là 384 trong 210 epoch. Độ chính xác trung bình (AP), điểm recall (AR), APM
và APL cho các đối tượng trung bình hoặc lớn là các metric đánh giá. Tất cả các thí nghiệm
được chạy trên Tesla V100*8 GPUs.

--- TRANG 5 ---
SuperTickets 5
Thuật toán 1: Khung Hai-Trong-Một để Xác định SuperTickets.
Đầu vào: Trọng số supernet θS, ngưỡng loại bỏ ϵ, và tỷ lệ cắt tỉa p;
Đầu ra: DNNs hiệu quả và các mạng con lottery của chúng f(x;m⊙θS(a)).
1trong khi t(epoch) < tmaxdo
2 t=t+ 1;
3 Cập nhật trọng số θS và hệ số quan trọng r sử dụng huấn luyện SGD;
4 nếu tmod ts= 0thì ▷Tìm kiếm DNNs
5 Loại bỏ các đơn vị tìm kiếm có hệ số quan trọng r < ϵ ;
6 Hiệu chỉnh lại thống kê chạy của các lớp BN để có được subnet a;
// Nếu kích hoạt kỹ thuật kích hoạt lại lặp
7 Kích hoạt lại gradient của các trọng số đã cắt tỉa;
8 else if tmod tp= 0thì ▷Cắt tỉa cho các mạng con
// Nếu kích hoạt kỹ thuật cắt tỉa tiến bộ
9 Định nghĩa lại tỷ lệ cắt tỉa là min {p,10%× ⌊t/tp⌋};
10 Thực hiện cắt tỉa dựa trên độ lớn hướng tới tỷ lệ đích;
11 Giữ mặt nạ thưa mt và vô hiệu hóa gradient của các trọng số đã cắt tỉa;
12 end
13end
14return f(x;mt⊙θS(a)); ▷SuperTickets
DNNs Hiệu quả
…
Tìm kiếm Cắt tỉaMạng con w/ hoặc w/o Huấn luyện lại Huấn luyện Supernet
Huấn luyện Supernet
 SuperTickets
Hai-Trong-Một(a) Quy trình đầu tiên-tìm kiếm-rồi-cắt tỉa (S+P)
(b) Huấn luyện Hai-Trong-Một (Được đề xuất)
Hình 1. Minh họa đầu tiên-tìm kiếm-rồi-cắt tỉa (S+P)
so với huấn luyện hai-trong-một của chúng tôi.Huấn luyện Hai-Trong-Một.
Để xác thực giả thuyết
SuperTickets, chúng tôi đề xuất
một thuật toán huấn luyện hai-
trong-một đồng thời tìm kiếm và
cắt tỉa trong quá trình huấn luyện supernet
của NAS. Như được hiển thị trong Thuật toán
1 và Hình 1, để tìm kiếm
DNNs hiệu quả, chúng tôi áp dụng
một NAS thu hẹp tiến bộ bằng
cách dần dần loại bỏ các đơn vị tìm kiếm
không quan trọng có thể là các kênh convolution
hoặc các token Transformer. Sau
mỗi p epoch huấn luyện, chúng tôi
sẽ phát hiện và loại bỏ các đơn vị tìm kiếm không quan trọng một khi các hệ số quan trọng tương ứng
r (tức là, các thang đo trong các lớp Batch Normalization (BN)) nhỏ hơn ngưỡng loại bỏ được định trước ϵ. Lưu ý rằng r có thể được học đồng thời với
trọng số supernet, việc loại bỏ như vậy sẽ không ảnh hưởng đến các đơn vị tìm kiếm còn lại vì
các kênh trong convolution theo chiều sâu độc lập với nhau, như cũng
được xác thực bởi [8,30]. Ngoài ra, chúng tôi theo network slimming [26] để thêm một penalty l1
như một thuật ngữ chính quy hóa để phân cực các hệ số quan trọng nhằm dễ dàng
phát hiện các đơn vị không quan trọng. Sau khi loại bỏ chúng, thống kê chạy
trong các lớp BN được hiệu chỉnh lại để phù hợp với kiến trúc DNN được tìm kiếm
a để tránh covariate shift [19,48]. Để cắt tỉa các DNNs được tìm kiếm, chúng tôi thực

--- TRANG 6 ---
6 H. You et al.
107108109
FLOPs020406080mIoU (%)S+P (Rand.)
S+P (Mag.)
S+P (Grad.)
Two-in-One
107108109
FLOPs020406080mAcc (%)S+P (Rand.)
S+P (Mag.)
S+P (Grad.)
Two-in-One
107108109
FLOPs020406080100aAcc (%)S+P (Rand.)
S+P (Mag.)
S+P (Grad.)
Two-in-One
Hình 2. So sánh mIoU, mAcc, aAcc và FLOPs suy luận của các mạng
kết quả từ huấn luyện hai-trong-một được đề xuất và các đường cơ sở đầu tiên-tìm kiếm-rồi-cắt tỉa (S+P)
trên tác vụ phân đoạn ngữ nghĩa và bộ dữ liệu Cityscapes, trong đó Rand., Mag., và
Grad. tương ứng đại diện cho cắt tỉa ngẫu nhiên, độ lớn và dựa trên gradient. Lưu ý
rằng mỗi phương pháp có một chuỗi điểm để đại diện cho các tỷ lệ cắt tỉa khác nhau trong
khoảng từ 10% đến 98%. Tất cả độ chính xác được tính trung bình qua ba lần chạy.
0.0 0.5 1.0 1.5 2.0 2.5
FLOPs 1e80204060AP (%)S+P (Rand.)
S+P (Mag.)
S+P (Grad.)
Two-in-One
0.0 0.5 1.0 1.5 2.0 2.5
FLOPs 1e80204060APM (%)
S+P (Rand.)
S+P (Mag.)
S+P (Grad.)
Two-in-One
0.0 0.5 1.0 1.5 2.0 2.5
FLOPs 1e80204060APL (%)
S+P (Rand.)
S+P (Mag.)
S+P (Grad.)
Two-in-One
Hình 3. So sánh AP, APM, APL và FLOPs suy luận của các mạng kết quả
từ huấn luyện hai-trong-một được đề xuất và các đường cơ sở trên tác vụ ước lượng tư thế con người và
bộ dữ liệu COCO keypoint. Mỗi phương pháp có một chuỗi điểm để đại diện cho các
tỷ lệ cắt tỉa khác nhau trong khoảng từ 10% đến 98%. Tất cả độ chính xác được tính trung bình qua ba lần chạy.
hiện cắt tỉa dựa trên độ lớn hướng tới tỷ lệ cắt tỉa đã cho mỗi tp epoch,
mặt nạ thưa được tạo ra mt sẽ được giữ để vô hiệu hóa dòng gradient của
các trọng số đã cắt tỉa trong quá trình huấn luyện tiếp theo. Lưu ý rằng chúng tôi không kết hợp
các kỹ thuật kích hoạt lại lặp và cắt tỉa tiến bộ (được làm nổi bật
bằng màu sắc/bóng trong Thuật toán 1, sẽ được trình bày chi tiết sau) như hiện tại. Thuật toán huấn luyện hai-trong-một vanilla như vậy
có thể được coi là bước đầu tiên hướng tới trả lời câu đố liệu SuperTickets có tồn tại nói chung không.
Sự Tồn tại của SuperTickets. Chúng tôi so sánh huấn luyện hai-trong-một được đề xuất
với các đường cơ sở đầu tiên-tìm kiếm-rồi-cắt tỉa (S+P) và báo cáo kết quả trên Cityscapes
và COCO keypoint tại Hình 2 và Hình 3, tương ứng. Chúng ta thấy rằng huấn luyện hai-trong-một được đề xuất
liên tục tạo ra sự đánh đổi độ chính xác-hiệu quả tương đương hoặc thậm chí tốt hơn so với S+P với các tiêu chí cắt tỉa khác nhau (ngẫu nhiên,
độ lớn và gradient) vì các phương pháp của chúng tôi thể hiện hiệu suất tốt hơn nhiều
về phân đoạn hoặc ước lượng tư thế con người dưới các giảm FLOPs khác nhau như được hiển thị trong hai hình trên, chỉ ra rằng SuperTickets tồn tại nói chung
trong một supernet và có tiềm năng lớn để vượt trội hơn các phương pháp được áp dụng phổ biến,
tức là, tối ưu hóa tuần tự các kiến trúc DNN và mặt nạ thưa.

--- TRANG 7 ---
SuperTickets 7
Bảng 1. Phân tích chi tiết của chiến lược xác định SuperTickets được đề xuất. Chúng tôi
báo cáo hiệu suất của các mạng con được tìm thấy dưới độ thưa 90%/80% trên hai bộ dữ liệu.
Phương pháp 2-in-1 PP IR-P IR-S RetrainCityscapes COCO Keypoint
mIoU mAcc aAcc AP APMAPLAR
S+P (Mag.) 42.12 50.49 87.45 5.04 4.69 5.89 10.67
S+P (Mag.) ! 51.03 59.61 90.88 48.63 46.82 51.74 53.38
Của chúng tôi ! 55.84 67.38 92.97 58.38 56.68 61.26 62.23
Của chúng tôi ! ! 63.89 73.56 94.17 60.14 57.93 63.70 63.79
Của chúng tôi ! ! ! 45.73 55.52 89.36 5.48 7.43 4.36 10.85
Của chúng tôi ! ! ! 66.61 76.30 94.63 61.02 58.80 64.64 64.78
Của chúng tôi ! ! ! ! 67.17 77.03 94.73 61.48 59.30 65.19 65.20
3.2 Làm thế nào để Xác định SuperTickets Hiệu quả hơn?
Chúng tôi đã xác thực sự tồn tại của SuperTickets, câu hỏi tự nhiên tiếp theo là làm thế nào
để xác định chúng hiệu quả hơn. Để đạt được điều này, chúng tôi đề xuất hai kỹ thuật có thể
được kết hợp một cách liền mạch vào khung huấn luyện hai-trong-một để xác định SuperTickets hiệu quả hơn và tiếp tục tăng cường hiệu suất có thể đạt được của chúng.
Cắt tỉa Tiến bộ (PP). Mặc dù việc đồng thời tìm kiếm và cắt
tỉa trong quá trình huấn luyện supernet cho phép cơ hội hợp tác giữa
việc loại bỏ đơn vị tìm kiếm thô và cắt tỉa trọng số chi tiết, tức là, NAS
giúp tinh chỉnh các mạng đã cắt tỉa như một bù đắp bằng cách loại bỏ các đơn vị đã cắt tỉa quá mức
để tránh các lớp cổ chai, chúng tôi thấy rằng cắt tỉa quá mức ở các giai đoạn huấn luyện sớm
không thể tránh khỏi làm tổn hại khả năng tổng quát của mạng, và tiếp tục đề
xuất một kỹ thuật cắt tỉa tiến bộ (PP) để khắc phục nhược điểm này. Như
được làm nổi bật trong phần màu xanh lục của Thuật toán 1, tỷ lệ cắt tỉa được định nghĩa là min {p,10%×
⌊t/tp⌋}, có nghĩa là độ thưa của mạng sẽ tăng dần từ 10%
đến tỷ lệ đích p, tăng 10% mỗi tp epoch. Kỹ thuật PP giúp hiệu quả
tránh cắt tỉa quá mức ở các giai đoạn huấn luyện sớm và do đó tăng cường đáng kể
hiệu suất cuối cùng. Như được chứng minh trong Bảng 1, huấn luyện hai-trong-một với PP
đạt được cải thiện 8.05%/6.18%/1.2% mIoU/mAcc/aAcc và 1.76%/1.25%/2.44%/1.56%
AP/APM/APL/AR trên các bộ dữ liệu Cityscapes và COCO keypoint,
tương ứng, so với huấn luyện hai-trong-một vanilla dưới độ thưa 90%.
Kích hoạt Lại Lặp (IR). Một vấn đề khác trong khung
hai-trong-một là các trọng số đã cắt tỉa sẽ không bao giờ nhận được cập nhật gradient trong suốt
quá trình huấn luyện còn lại. Để tiếp tục tăng cường hiệu suất, chúng tôi thiết kế một chiến lược kích hoạt lại lặp (IR) để tạo điều kiện cho việc xác định SuperTickets hiệu quả
bằng cách cho phép khả năng kết nối của các mạng con thay đổi trong quá trình huấn luyện supernet.
Cụ thể, chúng tôi kích hoạt lại gradient của các trọng số đã cắt tỉa như được làm nổi bật
trong phần màu cam của Thuật toán 1. Lưu ý rằng chúng tôi kích hoạt lại trong quá trình tìm kiếm thay vì
ngay sau khi cắt tỉa, dựa trên giả thuyết rằng huấn luyện thưa cũng quan trọng
đối với khung huấn luyện hai-trong-một. Trong thực tế, khoảng cách cắt tỉa pt
khác với khoảng cách tìm kiếm ps để cho phép một giai đoạn huấn luyện thưa. Để xác thực giả thuyết, chúng tôi thiết kế hai biến thể: IR-S và IR-P kích hoạt lại gradient của các trọng số đã cắt tỉa trong quá trình tìm kiếm và cắt tỉa, tương ứng,
và hiển thị các so sánh trong Bảng 1. Chúng tôi quan sát rằng: (1) IR-P dẫn đến

--- TRANG 8 ---
8 H. You et al.
độ chính xác thậm chí tệ hơn so với huấn luyện hai-trong-một vanilla, xác thực rằng huấn luyện thưa là
quan trọng; (2) IR-S tiếp tục dẫn đến cải thiện 2.72%/2.74%/0.46% mIoU/mAcc/aAcc và
0.88%/0.87%/0.94%/0.99% AP/APM/ APL/AR trên Cityscapes
và COCO keypoint, tương ứng, trên cơ sở huấn luyện hai-trong-một với PP.
SuperTickets có/ không có Huấn luyện lại. Vì việc huấn luyện supernet, tìm
kiếm kiến trúc và cắt tỉa trọng số được tiến hành theo cách thống nhất đầu cuối đến cuối, các SuperTickets
kết quả có thể được triển khai trực tiếp mà không cần huấn luyện lại, đạt được sự đánh đổi độ chính xác-hiệu quả tốt hơn so với các đường cơ sở S+P (thậm chí
với huấn luyện lại) như được chỉ ra bởi Bảng 1. Để điều tra liệu huấn luyện lại có thể
tiếp tục tăng cường hiệu suất không, chúng tôi huấn luyện lại các SuperTickets được tìm thấy trong 50 epoch khác
và báo cáo kết quả tại Bảng 1. Chúng ta thấy rằng huấn luyện lại tiếp tục
dẫn đến cải thiện 0.56%/0.73%/0.10% mIoU/mAcc/aAcc và 0.46%/0.50%/0.55%/0.42%
AP/APM/ APL/AR trên các bộ dữ liệu Cityscapes và COCO keypoint,
tương ứng.
3.3 Các SuperTickets Được xác định Có thể Chuyển đổi không?
Để xác thực tiềm năng của các SuperTickets được xác định trong việc xử lý các tác vụ
và bộ dữ liệu khác nhau, chúng tôi cung cấp các thí nghiệm thực nghiệm và phân tích như sau. Lưu ý rằng
chúng tôi điều chỉnh bộ phân loại cuối cùng để phù hợp với các bộ dữ liệu đích trong quá trình học chuyển đổi.
Bảng 2. Các kiểm tra xác thực chuyển đổi Supertickets
dưới độ thưa 90%.
Phương pháp Params FLOPsCityscapes
mIoU mAcc aAcc
S+P (Grad.) 0.13M 203M 8.41 12.39 56.77
S+P (Mag.) 0.13M 203M 42.12 50.49 87.45
S+P (Mag.) w/ RT 0.13M 203M 60.76 70.40 93.38
ADE20K Tickets 0.20M 247M 62.91 73.32 93.82
ImageNet Tickets 0.18M 294M 61.64 71.78 93.75
Phương pháp Params FLOPsADE20K
mIoU mAcc aAcc
S+P (Grad.) 0.11M 154M 0.79 1.50 25.58
S+P (Mag.) 0.11M 154M 3.37 4.70 39.47
Cityscapes Tickets 0.13M 119M 20.83 29.95 69.00
ImageNet Tickets 0.21M 189M 22.42 31.87 70.21SuperTickets Chuyển đổi
Giữa các Bộ dữ liệu. Đầu tiên chúng tôi kiểm tra
khả năng chuyển đổi của các
SuperTickets được xác định giữa các
bộ dữ liệu khác nhau trong cùng một tác vụ, tức là,
Cityscapes và ADE20K như hai
đại diện trong tác vụ phân đoạn ngữ nghĩa. Bảng 2 cho thấy rằng
SuperTickets được xác định từ một
bộ dữ liệu có thể chuyển sang bộ dữ liệu khác
trong khi dẫn đến hiệu suất tương đương hoặc thậm chí tốt hơn
so với các đường cơ sở S+P có (ký hiệu
là "w/ RT") hoặc không có huấn luyện lại (theo mặc định). Ví dụ, khi
được kiểm tra trên Cityscapes, SuperTickets
được xác định từ ADE20K sau khi tinh chỉnh dẫn đến mIoU cao hơn 2.2% và 20.8% so với các đường cơ sở S+P (Mag.) w/ và w/o RT được huấn luyện trực tiếp trên bộ dữ liệu Cityscapes đích. Tương tự, các SuperTickets được chuyển từ Cityscapes sang
ADE20K cũng vượt trội hơn các đường cơ sở trên bộ dữ liệu đích.
SuperTickets Chuyển đổi Giữa các Tác vụ. Để tiếp tục điều tra liệu
các SuperTickets được xác định có thể chuyển đổi giữa các tác vụ khác nhau không. Chúng tôi xem xét
chuyển các mô-đun trích xuất đặc trưng của SuperTickets được xác định từ ImageNet trên
tác vụ phân loại sang Cityscapes và ADE20K trên các tác vụ phân đoạn, trong đó
các đầu dự đoán dày đặc và bộ phân loại cuối cùng vẫn được kế thừa từ các
bộ dữ liệu đích. Kết quả được trình bày trong hàng cuối cùng của hai bảng con trong Bảng

--- TRANG 9 ---
SuperTickets 9
2. Chúng tôi quan sát rằng các mạng được chuyển đổi như vậy vẫn hoạt động tốt trên các tác vụ xuôi dòng. Đôi khi, nó thậm chí đạt được hiệu suất tốt hơn so với chuyển đổi trong một tác vụ, ví dụ, ImageNet →ADE20K hoạt động tốt hơn (mIoU cao hơn 1.6%) so với
Cityscapes →ADE20K. Chúng tôi cung cấp thêm các thí nghiệm trên các tỷ lệ cắt tỉa khác nhau trong Phần 4.3.2.
4 Kết quả Thí nghiệm
4.1 Cài đặt Thí nghiệm
Tác vụ, Bộ dữ liệu và Supernets. Tác vụ và Bộ dữ liệu. Chúng tôi xem xét bốn bộ dữ liệu chuẩn
và ba tác vụ thị giác đại diện để chứng minh hiệu quả
của SuperTickets, bao gồm phân loại hình ảnh trên bộ dữ liệu ImageNet [7] với
1.2 triệu hình ảnh huấn luyện và 50K hình ảnh xác thực; phân đoạn ngữ nghĩa trên
các bộ dữ liệu Cityscapes [6] và ADE20K [55] với 2975/500/1525 và 20K/2K/3K
hình ảnh cho huấn luyện, xác thực và kiểm tra, tương ứng; ước lượng tư thế con người
trên bộ dữ liệu COCO keypoint [22] với 57K hình ảnh và 150K thể hiện người cho
huấn luyện, và 5K hình ảnh cho xác thực. Các bộ dữ liệu được chọn này yêu cầu các
trường tiếp nhận khác nhau và ngữ cảnh toàn cầu/địa phương, thể hiện bản thân chúng như các
bộ kiểm tra phù hợp cho SuperTickets trên nhiều tác vụ. Supernets. Đối với tất cả các thí nghiệm,
chúng tôi áp dụng cùng một supernet như HR-NAS [8] nhờ vào thiết kế supernet đa
độ phân giải bất khả tri tác vụ. Nó bắt đầu với hai convolution 3 ×3 với stride 2,
theo sau là năm mô-đun song song để dần chia nó thành bốn nhánh
có độ phân giải giảm dần, các đặc trưng được học từ tất cả các nhánh sau đó được hợp nhất
lại với nhau để phân loại hoặc dự đoán dày đặc.
Cài đặt Tìm kiếm và Huấn luyện. Để huấn luyện supernets trên ImageNet, chúng tôi
áp dụng trình tối ưu RMSProp với động lượng 0.9 và giảm trọng số 1e-5, trung bình di chuyển theo hàm mũ (EMA) với giảm 0.9999, và giảm tốc độ học theo hàm mũ
với tốc độ học ban đầu là 0.016 và kích thước batch 256 trong 350 epoch.
Đối với Cityscapes và ADE20K, chúng tôi sử dụng trình tối ưu AdamW, tốc độ học ban đầu
là 0.04 với kích thước batch 32 do kích thước hình ảnh đầu vào lớn hơn, và huấn luyện trong 430
và 200 epoch, tương ứng, theo [8]. Đối với COCO keypoint, chúng tôi theo [43]
để sử dụng trình tối ưu Adam trong 210 epoch, tốc độ học ban đầu được đặt là 1e-3,
và được chia cho 10 tại epoch thứ 170 và 200, tương ứng. Ngoài ra, chúng tôi
thực hiện tìm kiếm kiến trúc trong quá trình huấn luyện supernet. Đối với tất cả các đơn vị tìm kiếm, chúng tôi sử dụng
các thang đo từ các lớp BN được gắn của chúng như hệ số quan trọng r; các đơn vị tìm kiếm
với r <0.001 được coi là không quan trọng và loại bỏ mỗi 10 epoch (tức là,
ts= 10); Tương ứng, cắt tỉa dựa trên độ lớn sẽ được thực hiện mỗi 25
epoch cho ImageNet và Cityscapes, hoặc mỗi 15 epoch cho ADE20K và COCO
keypoint (tức là, tp= 25/15), dẫn đến các khoảng cách cho huấn luyện thưa như trong Phần 3.2.
Đường cơ sở và Metric Đánh giá. Đường cơ sở. Đối với tất cả các thí nghiệm, chúng tôi
xem xét quy trình S+P như một trong các đường cơ sở của chúng tôi, trong đó phương pháp tìm kiếm
theo [8]; các phương pháp cắt tỉa có thể được chọn từ cắt tỉa ngẫu nhiên, cắt tỉa độ lớn
[15,11], và cắt tỉa gradient [20]. Ngoài ra, chúng tôi cũng đánh giá với
các DNNs được chế tác thủ công, ví dụ, ShuffleNet [53,29] và MobiletNetV2 [34], và các

--- TRANG 10 ---
10 H. You et al.
0.5 1.0 1.5 2.0
FLOPs 1e8020406080Top-1 Acc. (%)S+P (Rand.)
S+P (Mag.)
S+P (Grad.)
SuperTickets
S+P (Mag.) w/ RT
S+P (Grad.) w/ RT
SuperTickets w/ RT
0.5 1.0 1.5 2.0
FLOPs 1e8020406080100Top-5 Acc. (%)S+P (Rand.)
S+P (Mag.)
S+P (Grad.)
SuperTickets
S+P (Mag.) w/ RT
S+P (Grad.) w/ RT
SuperTickets w/ RT
Hình 4. So sánh độ chính xác top-1/5 và FLOPs của SuperTickets được đề xuất và
các đường cơ sở S+P trên ImageNet. Mỗi phương pháp có một chuỗi điểm để đại diện cho các
tỷ lệ cắt tỉa khác nhau trong khoảng từ 10% đến 98%. Tất cả độ chính xác được tính trung bình qua ba lần chạy.
Chúng tôi cũng đánh giá tất cả các phương pháp với huấn luyện lại (ký hiệu là w/ RT).
DNNs cụ thể tác vụ kết quả NAS điển hình trước đây, ví dụ, MobileNetV3 [17] và Auto-
DeepLab [23]. Chúng tôi không so sánh với các công trình NAS/tickets với độ chính xác SOTA
do các mục tiêu và cài đặt thí nghiệm khác nhau. Tất cả các đường cơ sở được đánh giá dưới FLOPs hoặc độ chính xác tương tự để so sánh công bằng. Metric Đánh giá. Chúng tôi
đánh giá SuperTickets và tất cả các đường cơ sở theo sự đánh đổi độ chính xác-hiệu quả. Cụ thể, các metric độ chính xác đề cập đến độ chính xác top-1/5 cho các tác vụ phân loại;
mIoU, mAcc, và aAcc cho các tác vụ phân đoạn; AP, AR, APM, và APL
cho các tác vụ ước lượng tư thế con người. Đối với các metric hiệu quả, chúng tôi đánh giá và so sánh
cả số lượng tham số và FLOPs suy luận.
4.2 Đánh giá SuperTickets trên các Đường cơ sở Điển hình
4.2.1 SuperTickets trên Tác vụ Phân loại
Bảng 3. SuperTickets so với một số phương pháp điển hình
trên ImageNet. FLOPs được đo với kích thước đầu vào
224 ×224.
Mô hình Params FLOPs Top-1 Acc.
CondenseNet [18] 2.9M 274M 71.0%
ShuffleNetV1 [53] 3.4M 292M 71.5%
ShuffleNetV2 [29] 3.5M 299M 72.6%
MobileNetV2 [34] 3.4M 300M 72.0%
FBNet [44] 4.5M 295M 74.1%
S+P (Grad.) 2.7M 114M 64.3%
S+P (Mag.) 2.7M 114M 72.8%
SuperTickets 2.7M 125M 74.2%Chúng tôi hiển thị các so sánh tổng thể
giữa SuperTickets và
một số đường cơ sở điển hình theo sự đánh đổi độ chính xác-hiệu quả trong
Hình 4 và Bảng. 3, từ đó chúng tôi có
hai quan sát. Thứ nhất,
SuperTickets liên tục vượt trội hơn
tất cả các đường cơ sở bằng cách giảm
FLOPs suy luận trong khi đạt
được độ chính xác tương đương hoặc thậm chí tốt
hơn. Cụ thể, Su-
perTickets giảm 61.4% ∼81.5%
FLOPs trong khi cung cấp độ chính xác tương đương hoặc tốt hơn (+0.1% ∼
+4.6%) so với cả S+P
và một số DNNs cụ thể tác vụ; Tương tự, khi so sánh dưới số lượng tham số hoặc FLOPs tương đương, SuperTickets dẫn đến trung bình 26.5% (lên đến

--- TRANG 11 ---
SuperTickets 11
108109
FLOPs020406080mIoU (%)S+P (Rand.)
S+P (Mag.)
S+P (Grad.)
SuperTickets
S+P (Mag.) w/ RT
S+P (Grad.) w/ RT
SuperTickets w/ RT
108109
FLOPs020406080mAcc (%)S+P (Rand.)
S+P (Mag.)
S+P (Grad.)
SuperTickets
S+P (Mag.) w/ RT
S+P (Grad.) w/ RT
SuperTickets w/ RT
108109
FLOPs020406080100aAcc (%)S+P (Rand.)
S+P (Mag.)
S+P (Grad.)
SuperTickets
S+P (Mag.) w/ RT
S+P (Grad.) w/ RT
SuperTickets w/ RT
(a) So sánh SuperTickets với các đường cơ sở S+P trên Cityscapes.
108109
FLOPs0102030mIOU (%)S+P (Rand.)
S+P (Mag.)
S+P (Grad.)
SuperTickets
S+P (Mag.) w/ RT
S+P (Grad.) w/ RT
SuperTickets w/ RT
108109
FLOPs01020304050mAcc (%)S+P (Rand.)
S+P (Mag.)
S+P (Grad.)
SuperTickets
S+P (Mag.) w/ RT
S+P (Grad.) w/ RT
SuperTickets w/ RT
108109
FLOPs020406080aAcc (%)S+P (Rand.)
S+P (Mag.)
S+P (Grad.)
SuperTickets
S+P (Mag.) w/ RT
S+P (Grad.) w/ RT
SuperTickets w/ RT
(b) So sánh SuperTickets với các đường cơ sở S+P trên ADE20K.
Hình 5. So sánh mIoU, mAcc, aAcc và FLOPs suy luận của SuperTickets được đề xuất và các đường cơ sở S+P trên các bộ dữ liệu Cityscapes và ADE20K. Mỗi phương pháp có
một chuỗi điểm để đại diện cho các tỷ lệ cắt tỉa khác nhau trong khoảng từ 10% đến 98%.
64.5%) và trung bình 41.3% (lên đến 71.9%) cải thiện độ chính xác top-1 so với
S+P (Mag.) và S+P (Grad.) qua các tỷ lệ cắt tỉa khác nhau, ví dụ,
dưới tỷ lệ cắt tỉa 50%, SuperTickets đạt được độ chính xác top-1 74.2%, +1.4%
và +9.9% so với S+P (Mag.) và S+P (Grad.), tương ứng. Thứ hai, SuperTick-
ets w/o huấn luyện lại thậm chí vượt trội hơn các đường cơ sở S+P với huấn luyện lại như được chứng minh
trong Hình 4, dẫn đến trung bình 6.7% (lên đến 29.2%) độ chính xác top-1 cao hơn dưới
FLOPs tương đương qua các tỷ lệ cắt tỉa khác nhau (10% ∼98%). Hơn nữa,
SuperTickets w/ huấn luyện lại đạt được 0.1% ∼31.9% (trung bình 5.3%) độ chính xác cao hơn
so với các đối tác w/o huấn luyện lại, đẩy tiến biên giới của
sự đánh đổi độ chính xác-hiệu quả.
Bảng 4. SuperTickets so với một số phương pháp điển hình
trên Cityscapes. FLOPs được đo với kích thước đầu vào
512 ×1024.
Mô hình Params FLOPs mIoU
BiSeNet [51] 5.8M 6.6G 69.00%
MobileNetV3 [17] 1.5M 2.5G 72.36%
ShuffleNetV2 [29] 3.0M 6.9G 71.30%
Auto-DeepLab [23] 3.2M 27.3G 71.21%
SqueezeNAS [35] 0.73M 8.4G 72.40%
S+P (Grad.) w/ RT 0.63M 1.0G 60.66%
S+P (Mag.) w/ RT 0.63M 1.0G 72.31%
SuperTickets 0.63M 1.0G 72.68%4.2.2 SuperTickets trên Tác vụ Phân
đoạn
Thí nghiệm trên Cityscapes. Chúng tôi
so sánh SuperTickets với các đường cơ sở điển hình
trên Cityscapes như được hiển thị trong Hình 5 (a)
và Bảng 4. Chúng ta thấy rằng SuperTickets
liên tục vượt trội hơn tất cả các đường cơ sở theo
mIoU/mAcc/aAcc và FLOPs.
Cụ thể, SuperTickets giảm 60% ∼
80.86% FLOPs trong khi cung cấp mIoU tương đương hoặc tốt hơn (0.28 % ∼43.26%)
so với cả S+P và các
DNNs cụ thể tác vụ; Tương tự, khi so sánh

--- TRANG 12 ---
12 H. You et al.
0.0 0.5 1.0 1.5 2.0 2.5
FLOPs 1e80204060AP (%)S+P (Rand.)
S+P (Mag.)
S+P (Grad.)
SuperTickets
S+P (Mag.) w/ RT
SuperTickets w/ RT
0.0 0.5 1.0 1.5 2.0 2.5
FLOPs 1e80204060APM (%)
S+P (Rand.)
S+P (Mag.)
S+P (Grad.)
SuperTickets
S+P (Mag.) w/ RT
SuperTickets w/ RT
0.0 0.5 1.0 1.5 2.0 2.5
FLOPs 1e80204060APL (%)
S+P (Rand.)
S+P (Mag.)
S+P (Grad.)
SuperTickets
S+P (Mag.) w/ RT
SuperTickets w/ RT
Hình 6. So sánh AP, APM, APL và FLOPs suy luận của SuperTickets được đề xuất và các đường cơ sở trên tác vụ ước lượng tư thế con người và bộ dữ liệu COCO keypoint.
Mỗi phương pháp có một chuỗi điểm để đại diện cho các tỷ lệ cắt tỉa khác nhau trong khoảng
từ 10% đến 98%. Tất cả độ chính xác được tính trung bình qua ba lần chạy.
dưới số lượng tham số hoặc FLOPs tương đương, SuperTickets dẫn đến trung bình 17.70% (lên đến 42.86%) và 33.36% (lên đến 58.05%) cải thiện mIoU
so với S+P (Mag.) và S+P (Grad.) qua các tỷ lệ cắt tỉa khác nhau,
ví dụ, dưới tỷ lệ cắt tỉa 50%, SuperTickets đạt được mIoU 72.68%, +0.37% và
+12% so với S+P (Mag.) và S+P (Grad.), tương ứng. Chúng tôi cũng báo cáo so sánh giữa các phương pháp sau huấn luyện lại tại Hình 5, như được ký hiệu bởi "w/ RT". Chúng tôi
thấy rằng S+P (Grad.) w/ RT gặp phải overfitting và thậm chí dẫn đến hiệu suất tệ hơn; Ngược lại, SuperTickets w/ huấn luyện lại tiếp tục đạt được độ chính xác cao hơn 0.51% ∼
1.64% so với các đối tác w/o huấn luyện lại, đẩy tiến biên giới của
sự đánh đổi độ chính xác-hiệu quả.
Bảng 5. SuperTickets so với các phương pháp điển hình trên
ADE20K. FLOPs được đo với kích thước đầu vào
512 ×512.
Mô hình Params FLOPs mIoU
MobileNetV2 [34] 2.2M 2.8G 32.04%
MobileNetV3 [17] 1.6M 1.3G 32.31%
S+P (Grad.) 1.0M 0.8G 24.14%
S+P (Mag.) 1.0M 0.8G 31.59%
SuperTickets 1.0M 0.8G 32.54%Thí nghiệm trên ADE20K.
Tương tự, chúng tôi kiểm tra sự vượt trội
của SuperTickets trên ADE20K như
được hiển thị trong Hình 5 (b) và Bảng 5.
SuperTickets được đề xuất liên
tục vượt trội hơn tất cả các đường cơ sở
theo sự đánh đổi độ chính xác-hiệu quả, giảm 38.46% ∼
48.53% FLOPs khi so sánh dưới
mIoU tương tự. Khi so
sánh dưới số lượng tham số hoặc FLOPs tương đương, Su-
perTickets dẫn đến trung bình
9.43% (lên đến 22.6%) và 14.17% (lên đến 27.61%) cải thiện mIoU so với
S+P (Mag.) và S+P (Grad.), tương ứng, qua các tỷ lệ cắt tỉa
khác nhau. Ngoài ra, SuperTickets w/ huấn luyện lại tiếp tục đạt được độ chính xác cao hơn 0.01% ∼5.3%
so với các đối tác w/o huấn luyện lại trên ADE20K.
4.2.3 SuperTickets trên Tác vụ Ước lượng Tư thế Con người
Chúng tôi so sánh SuperTickets với một vài đường cơ sở điển hình trên COCO keypoint như
được hiển thị trong Hình 6 và Bảng 6. Chúng ta thấy rằng SuperTickets liên tục vượt trội hơn

--- TRANG 13 ---
SuperTickets 13
107108109
FLOPs020406080mIoU (%)S+P (Rand.)
S+P (Mag.)
S+P (Grad.)
Two-in-One
Two-in-One w/ IR
Two-in-One w/ IR & PP
107108109
FLOPs020406080mAcc (%)S+P (Rand.)
S+P (Mag.)
S+P (Grad.)
Two-in-One
Two-in-One w/ IR
Two-in-One w/ IR & PP
107108109
FLOPs020406080100aAcc (%)S+P (Rand.)
S+P (Mag.)
S+P (Grad.)
Two-in-One
Two-in-One w/ IR
Two-in-One w/ IR & PP
Hình 7. Nghiên cứu loại bỏ của SuperTickets được xác định từ khung hai-trong-một w/
hoặc w/o các kỹ thuật kích hoạt lặp (IR) và cắt tỉa tiến bộ (PP) được đề xuất.
Bảng 6. SuperTickets so với các thuật toán điển hình trên
COCO. FLOPs được đo với kích thước đầu vào
256×192.
Mô hình Params FLOPs AP APMAPLAR
ShuffleNetV1 [53] 1.0M 0.16G 58.5 55.2 64.6 65.1
ShuffleNetV2 [29] 1.3M 0.17G 59.8 56.5 66.2 66.4
MobileNetV2 [34] 2.3M 0.33G 64.6 61.0 71.1 70.7
S+P (Mag.) 0.6M 0.23G 63.4 61.2 66.8 67.3
SuperTickets 0.6M 0.23G 65.4 63.4 69.0 68.9tất cả các đường cơ sở liên quan theo
AP/APM/APL/AR và FLOPs.
Cụ thể, SuperTickets giảm
30.3% ∼78.1% FLOPs trong khi cung
cấp AP tương đương hoặc tốt hơn
(+0.8% ∼11.79%) so với cả S+P và các
DNNs cụ thể tác vụ; Tương tự, khi so sánh
dưới số lượng tham số hoặc FLOPs tương đương, SuperTickets
dẫn đến trung bình 17.4% (lên đến 55.9%) cải thiện AP. Ngoài ra, Su-
perTickets w/ huấn luyện lại tiếp tục đạt được trung bình 1.1% độ chính xác cao hơn
so với các đối tác w/o huấn luyện lại trên COCO keypoint.
4.3 Nghiên cứu Loại bỏ của SuperTickets Được đề xuất
4.3.1 Nghiên cứu Loại bỏ về Xác định SuperTickets
Chúng tôi cung cấp các nghiên cứu loại bỏ toàn diện để hiển thị sự phân tích lợi ích của
khung huấn luyện hai-trong-một được đề xuất và các kỹ thuật xác định hiệu quả hơn,
tức là, cắt tỉa tiến bộ (PP) và kích hoạt lại lặp (IR). Như
được hiển thị trong Hình 7, chúng tôi báo cáo sự đánh đổi mIoU-FLOPs hoàn chỉnh với các
tỷ lệ cắt tỉa khác nhau trong khoảng từ 10% đến 99% khi kiểm tra trên bộ dữ liệu Cityscapes,
trong đó trục x được biểu diễn bằng thang log để nhấn mạnh các cải thiện khi
tỷ lệ cắt tỉa đạt mức cao. So với S+P (Mag.), SuperTickets được xác định
từ khung hai-trong-một vanilla đạt được lên đến 40.17% giảm FLOPs khi
so sánh dưới mIoU tương tự, hoặc lên đến 13.72% cải thiện độ chính xác khi
so sánh dưới FLOPs tương tự; Áp dụng IR trong quá trình huấn luyện hai-trong-một tiếp tục
dẫn đến lên đến 68.32% giảm FLOPs hoặc lên đến 39.12% cải thiện mIoU;
Trên cơ sở điều trên, áp dụng cả IR và PP trong quá trình huấn luyện hai-trong-một cung cấp
lên đến 80.86% giảm FLOPs hoặc lên đến 43.26% cải thiện mIoU. Bộ thí nghiệm này
xác thực hiệu quả của khung hai-trong-một tổng quát
và từng kỹ thuật được đề xuất.

--- TRANG 14 ---
14 H. You et al.
80 90 95 98
Pruning Ratio (%)0510152025mIOU (%)CityscapesADE20K
S+P (Mag.)
S+P (Grad.)
Transferred Tickets
80 90 95 98
Pruning Ratio (%)0204060mIOU (%)ADE20KCityscapes
80 90 95 98
Pruning Ratio (%)0510152025mIOU (%)ImageNetADE20K
80 90 95 98
Pruning Ratio (%)0204060mIOU (%)ImageNetCityscapes
80 90 95 98
Pruning Ratio (%)010203040AP (%)ImageNetCOCO
Hình 8. Nghiên cứu loại bỏ về việc chuyển các SuperTickets được xác định từ một bộ dữ liệu/tác vụ
sang bộ dữ liệu/tác vụ khác dưới các tỷ lệ cắt tỉa khác nhau trong khoảng từ 80% đến 98%.
4.3.2 Nghiên cứu Loại bỏ về Khả năng Chuyển đổi của SuperTickets
Trước đây chúng tôi sử dụng một bộ thí nghiệm dưới độ thưa 90% trong Phần 3.3 để
xác thực rằng các SuperTickets được xác định có thể chuyển đổi tốt. Trong phần này, chúng tôi
cung cấp thêm các thí nghiệm loại bỏ toàn diện dưới các tỷ lệ cắt tỉa khác nhau
và giữa một số bộ dữ liệu/tác vụ. Như được hiển thị trong Hình 8, hai biểu đồ con bên trái chỉ ra việc chuyển đổi giữa các bộ dữ liệu khác nhau (Cityscapes ↔ADE20K) thường
hoạt động qua bốn tỷ lệ cắt tỉa. Đặc biệt, các SuperTickets được chuyển đổi dẫn đến
76.14% ∼81.35% giảm FLOPs so với đường cơ sở S+P cạnh tranh nhất,
trong khi cung cấp mIoU tương đương (0.27% ∼1.85%). Hơn nữa, ba biểu đồ con bên phải xác thực rằng các SuperTickets được xác định từ tác vụ phân loại
có thể chuyển đổi tốt sang các tác vụ khác (tức là, phân đoạn và ước lượng tư thế con người). Cụ thể, nó dẫn đến 68.67% ∼69.43% giảm FLOPs so với
đường cơ sở S+P (Mag.), khi đạt được mIoU hoặc AP tương đương.
5 Kết luận
Trong bài báo này, chúng tôi ủng hộ một khung hai-trong-một trong đó cả kiến trúc DNN hiệu quả
và các mạng con lottery của chúng (tức là, SuperTickets) có thể được xác định
từ một supernet đồng thời, dẫn đến hiệu suất tốt hơn so với các đường cơ sở đầu tiên-tìm kiếm-
rồi-cắt tỉa. Ngoài ra, chúng tôi phát triển hai kỹ thuật trong quá trình huấn luyện supernet
để xác định hiệu quả hơn các SuperTickets như vậy, đẩy tiến biên giới của
sự đánh đổi độ chính xác-hiệu quả. Hơn nữa, chúng tôi kiểm tra khả năng chuyển đổi của SuperTickets để tiết lộ tiềm năng của chúng trong việc bất khả tri tác vụ. Kết quả trên ba tác vụ và
bốn bộ dữ liệu liên tục chứng minh sự vượt trội của khung hai-trong-một được đề xuất
và các SuperTickets kết quả, mở ra một góc nhìn mới trong
tìm kiếm và cắt tỉa cho các mạng chính xác và hiệu quả hơn.
Lời cảm ơn
Chúng tôi muốn ghi nhận sự hỗ trợ tài trợ từ NSF NeTS funding
(Số giải thưởng: 1801865) và NSF SCH funding (Số giải thưởng: 1838873) cho
dự án này.

--- TRANG 15 ---
SuperTickets 15
Tài liệu Tham khảo
1. Baevski, A., Hsu, W.N., Xu, Q., Babu, A., Gu, J., Auli, M.: data2vec: A gen-
eral framework for self-supervised learning in speech, vision and language. arXiv
preprint arXiv:2202.03555 (2022)
2. Bender, G., Kindermans, P.J., Zoph, B., Vasudevan, V., Le, Q.: Understanding and
simplifying one-shot architecture search. In: International Conference on Machine
Learning. pp. 550–559. PMLR (2018)
3. Cai, H., Gan, C., Wang, T., Zhang, Z., Han, S.: Once-for-all: Train one network
and specialize it for efficient deployment. arXiv preprint arXiv:1908.09791 (2019)
4. Chen, M., Peng, H., Fu, J., Ling, H.: Autoformer: Searching transformers for vi-
sual recognition. In: Proceedings of the IEEE/CVF International Conference on
Computer Vision (ICCV) (2021)
5. Chen, X., Cheng, Y., Wang, S., Gan, Z., Wang, Z., Liu, J.: Earlybert: Efficient
bert training via early-bird lottery tickets. arXiv preprint arXiv:2101.00063 (2020)
6. Cordts, M., Omran, M., Ramos, S., Rehfeld, T., Enzweiler, M., Benenson, R.,
Franke, U., Roth, S., Schiele, B.: The cityscapes dataset for semantic urban scene
understanding. In: Proceedings of the IEEE conference on computer vision and
pattern recognition. pp. 3213–3223 (2016)
7. Deng, J., Dong, W., Socher, R., Li, L.J., Li, K., Fei-Fei, L.: Imagenet: A large-
scale hierarchical image database. In: 2009 IEEE conference on computer vision
and pattern recognition. pp. 248–255. Ieee (2009)
8. Ding, M., Lian, X., Yang, L., Wang, P., Jin, X., Lu, Z., Luo, P.: Hr-nas: Search-
ing efficient high-resolution neural architectures with lightweight transformers. In:
Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recog-
nition. pp. 2982–2992 (2021)
9. Ding, Y., Wu, Y., Huang, C., Tang, S., Wu, F., Yang, Y., Zhu, W., Zhuang, Y.:
Nap: Neural architecture search with pruning. Neurocomputing (2022)
10. Feng, Q., Xu, K., Li, Y., Sun, Y., Wang, D.: Edge-wise one-level global pruning
on nas generated networks. In: Chinese Conference on Pattern Recognition and
Computer Vision (PRCV). pp. 3–15. Springer (2021)
11. Frankle, J., Carbin, M.: The lottery ticket hypothesis: Finding sparse, trainable
neural networks. In: International Conference on Learning Representations (2019),
https://openreview.net/forum?id=rJl-b3RcF7
12. Frankle, J., Dziugaite, G.K., Roy, D., Carbin, M.: Linear mode connectivity and
the lottery ticket hypothesis. In: International Conference on Machine Learning.
pp. 3259–3269. PMLR (2020)
13. Gordon, M.A., Duh, K., Andrews, N.: Compressing bert: Studying the effects of
weight pruning on transfer learning. arXiv preprint arXiv:2002.08307 (2020)
14. Guo, Z., Zhang, X., Mu, H., Heng, W., Liu, Z., Wei, Y., Sun, J.: Single path one-
shot neural architecture search with uniform sampling. In: European Conference
on Computer Vision. pp. 544–560. Springer (2020)
15. Han, S., Mao, H., Dally, W.J.: Deep compression: Compressing deep neural net-
works with pruning, trained quantization and huffman coding. arXiv preprint
arXiv:1510.00149 (2015)
16. He, K., Zhang, X., Ren, S., Sun, J.: Deep residual learning for image recognition. In:
Proceedings of the IEEE conference on computer vision and pattern recognition.
pp. 770–778 (2016), https://github.com/facebookarchive/fb.resnet.torch
17. Howard, A., Sandler, M., Chu, G., Chen, L.C., Chen, B., Tan, M., Wang, W., Zhu,
Y., Pang, R., Vasudevan, V., et al.: Searching for mobilenetv3. In: Proceedings

--- TRANG 16 ---
16 H. You et al.
of the IEEE/CVF International Conference on Computer Vision. pp. 1314–1324
(2019)
18. Huang, G., Liu, S., Van der Maaten, L., Weinberger, K.Q.: Condensenet: An ef-
ficient densenet using learned group convolutions. In: Proceedings of the IEEE
conference on computer vision and pattern recognition. pp. 2752–2761 (2018)
19. Ioffe, S., Szegedy, C.: Batch normalization: Accelerating deep network training by
reducing internal covariate shift. In: International conference on machine learning.
pp. 448–456. PMLR (2015)
20. Lee, N., Ajanthan, T., Torr, P.H.: Snip: Single-shot network pruning based on
connection sensitivity. arXiv preprint arXiv:1810.02340 (2018)
21. Li, Z., Yuan, G., Niu, W., Zhao, P., Li, Y., Cai, Y., Shen, X., Zhan, Z., Kong,
Z., Jin, Q., et al.: Npas: A compiler-aware framework of unified network pruning
and architecture search for beyond real-time mobile acceleration. In: Proceedings
of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp.
14255–14266 (2021)
22. Lin, T.Y., Maire, M., Belongie, S., Hays, J., Perona, P., Ramanan, D., Doll´ ar, P.,
Zitnick, C.L.: Microsoft coco: Common objects in context. In: European conference
on computer vision. pp. 740–755. Springer (2014)
23. Liu, C., Chen, L.C., Schroff, F., Adam, H., Hua, W., Yuille, A.L., Fei-Fei, L.:
Auto-deeplab: Hierarchical neural architecture search for semantic image segmen-
tation. In: Proceedings of the IEEE/CVF conference on computer vision and pat-
tern recognition. pp. 82–92 (2019)
24. Liu, H., Simonyan, K., Yang, Y.: Darts: Differentiable architecture search. arXiv
preprint arXiv:1806.09055 (2018)
25. Liu, Z., Lin, Y., Cao, Y., Hu, H., Wei, Y., Zhang, Z., Lin, S., Guo, B.: Swin
transformer: Hierarchical vision transformer using shifted windows. In: Proceedings
of the IEEE/CVF International Conference on Computer Vision. pp. 10012–10022
(2021)
26. Liu, Z., Li, J., Shen, Z., Huang, G., Yan, S., Zhang, C.: Learning efficient convolu-
tional networks through network slimming. In: Proceedings of the IEEE interna-
tional conference on computer vision. pp. 2736–2744 (2017)
27. Lu, J., Batra, D., Parikh, D., Lee, S.: Vilbert: Pretraining task-agnostic visiolinguis-
tic representations for vision-and-language tasks. Advances in neural information
processing systems 32(2019)
28. Lu, J., Goswami, V., Rohrbach, M., Parikh, D., Lee, S.: 12-in-1: Multi-task vision
and language representation learning. In: Proceedings of the IEEE/CVF Confer-
ence on Computer Vision and Pattern Recognition. pp. 10437–10446 (2020)
29. Ma, N., Zhang, X., Zheng, H.T., Sun, J.: Shufflenet v2: Practical guidelines for
efficient cnn architecture design. In: Proceedings of the European conference on
computer vision (ECCV). pp. 116–131 (2018)
30. Mei, J., Li, Y., Lian, X., Jin, X., Yang, L., Yuille, A., Yang, J.: Atomnas: Fine-
grained end-to-end neural architecture search. arXiv preprint arXiv:1912.09640
(2019)
31. Mukund Kalibhat, N., Balaji, Y., Feizi, S.: Winning lottery tickets in deep gener-
ative models. arXiv e-prints pp. arXiv–2010 (2020)
32. Qin, E., Samajdar, A., Kwon, H., Nadella, V., Srinivasan, S., Das, D., Kaul, B.,
Krishna, T.: Sigma: A sparse and irregular gemm accelerator with flexible in-
terconnects for dnn training. In: 2020 IEEE International Symposium on High
Performance Computer Architecture (HPCA). pp. 58–70. IEEE (2020)

--- TRANG 17 ---
SuperTickets 17
33. Ramanujan, V., Wortsman, M., Kembhavi, A., Farhadi, A., Rastegari, M.: What's
hidden in a randomly weighted neural network? In: Proceedings of the IEEE/CVF
Conference on Computer Vision and Pattern Recognition. pp. 11893–11902 (2020)
34. Sandler, M., Howard, A., Zhu, M., Zhmoginov, A., Chen, L.C.: Mobilenetv2: In-
verted residuals and linear bottlenecks. In: Proceedings of the IEEE conference on
computer vision and pattern recognition. pp. 4510–4520 (2018)
35. Shaw, A., Hunter, D., Landola, F., Sidhu, S.: Squeezenas: Fast neural architec-
ture search for faster semantic segmentation. In: Proceedings of the IEEE/CVF
International Conference on Computer Vision Workshops. pp. 0–0 (2019)
36. Su, X., You, S., Xie, J., Zheng, M., Wang, F., Qian, C., Zhang, C., Wang, X., Xu,
C.: Vision transformer architecture search. arXiv preprint arXiv:2106.13700 (2021)
37. Tan, M., Chen, B., Pang, R., Vasudevan, V., Sandler, M., Howard, A., Le, Q.V.:
Mnasnet: Platform-aware neural architecture search for mobile. In: Proceedings
of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp.
2820–2828 (2019)
38. Tan, M., Le, Q.: Efficientnet: Rethinking model scaling for convolutional neural net-
works. In: International Conference on Machine Learning. pp. 6105–6114. PMLR
(2019)
39. Tan, M., Le, Q.V.: Mixconv: Mixed depthwise convolutional kernels. arXiv preprint
arXiv:1907.09595 (2019)
40. Wan, A., Dai, X., Zhang, P., He, Z., Tian, Y., Xie, S., Wu, B., Yu, M., Xu, T.,
Chen, K., et al.: Fbnetv2: Differentiable neural architecture search for spatial and
channel dimensions. In: Proceedings of the IEEE/CVF Conference on Computer
Vision and Pattern Recognition. pp. 12965–12974 (2020)
41. Wang, D., Gong, C., Li, M., Liu, Q., Chandra, V.: Alphanet: Improved training of
supernet with alpha-divergence. arXiv preprint arXiv:2102.07954 (2021)
42. Wang, H., Wu, Z., Liu, Z., Cai, H., Zhu, L., Gan, C., Han, S.: Hat: Hardware-
aware transformers for efficient natural language processing. arXiv preprint
arXiv:2005.14187 (2020)
43. Wang, J., Sun, K., Cheng, T., Jiang, B., Deng, C., Zhao, Y., Liu, D., Mu, Y., Tan,
M., Wang, X., et al.: Deep high-resolution representation learning for visual recog-
nition. IEEE transactions on pattern analysis and machine intelligence 43(10),
3349–3364 (2020)
44. Wu, B., Dai, X., Zhang, P., Wang, Y., Sun, F., Wu, Y., Tian, Y., Vajda, P., Jia, Y.,
Keutzer, K.: Fbnet: Hardware-aware efficient convnet design via differentiable neu-
ral architecture search. In: Proceedings of the IEEE/CVF Conference on Computer
Vision and Pattern Recognition. pp. 10734–10742 (2019)
45. Wu, B., Li, C., Zhang, H., Dai, X., Zhang, P., Yu, M., Wang, J., Lin, Y., Vajda, P.:
Fbnetv5: Neural architecture search for multiple tasks in one run. arXiv preprint
arXiv:2111.10007 (2021)
46. Xu, J., Tan, X., Luo, R., Song, K., Li, J., Qin, T., Liu, T.Y.: Nas-bert: task-
agnostic and adaptive-size bert compression with neural architecture search. In:
Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &
Data Mining. pp. 1933–1943 (2021)
47. Yang, Y., You, S., Li, H., Wang, F., Qian, C., Lin, Z.: Towards improving the
consistency, efficiency, and flexibility of differentiable neural architecture search.
In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern
Recognition (CVPR). pp. 6667–6676 (June 2021)
48. You, F., Li, J., Zhao, Z.: Test-time batch statistics calibration for covariate shift.
arXiv preprint arXiv:2110.04065 (2021)

--- TRANG 18 ---
18 H. You et al.
49. You, H., Li, C., Xu, P., Fu, Y., Wang, Y., Chen, X., Baraniuk, R.G., Wang, Z.,
Lin, Y.: Drawing early-bird tickets: Toward more efficient training of deep net-
works. In: International Conference on Learning Representations (2020), https:
//openreview.net/forum?id=BJxsrgStvr
50. You, H., Lu, Z., Zhou, Z., Fu, Y., Lin, Y.: Early-bird gcns: Graph-network co-
optimization towards more efficient gcn training and inference via drawing early-
bird lottery tickets. In: Association for the Advancement of Artificial Intelligence
(2022)
51. Yu, C., Wang, J., Peng, C., Gao, C., Yu, G., Sang, N.: Bisenet: Bilateral segmenta-
tion network for real-time semantic segmentation. In: Proceedings of the European
conference on computer vision (ECCV). pp. 325–341 (2018)
52. Yu, J., Jin, P., Liu, H., Bender, G., Kindermans, P.J., Tan, M., Huang, T., Song,
X., Pang, R., Le, Q.: Bignas: Scaling up neural architecture search with big single-
stage models. In: European Conference on Computer Vision. pp. 702–717. Springer
(2020)
53. Zhang, X., Zhou, X., Lin, M., Sun, J.: Shufflenet: An extremely efficient convolu-
tional neural network for mobile devices. In: Proceedings of the IEEE conference
on computer vision and pattern recognition. pp. 6848–6856 (2018)
54. Zhang, Z., Chen, X., Chen, T., Wang, Z.: Efficient lottery ticket finding: Less
data is more. In: International Conference on Machine Learning. pp. 12380–12390.
PMLR (2021)
55. Zhou, B., Zhao, H., Puig, X., Fidler, S., Barriuso, A., Torralba, A.: Scene parsing
through ade20k dataset. In: Proceedings of the IEEE conference on computer vision
and pattern recognition. pp. 633–641 (2017)
56. Zoph, B., Vasudevan, V., Shlens, J., Le, Q.V.: Learning transferable architectures
for scalable image recognition. In: Proceedings of the IEEE conference on computer
vision and pattern recognition. pp. 8697–8710 (2018)

--- TRANG 19 ---
SuperTickets 19
A Hình ảnh hóa Kiến trúc Supernet Được áp dụng
Chúng tôi hình ảnh hóa supernet được áp dụng theo [8] trong Hình 9. Nó bắt đầu với hai
convolution 3×3 với stride 2, theo sau là năm mô-đun fusion và
năm mô-đun song song để dần chia nó thành bốn nhánh có độ phân giải
giảm dần, các đặc trưng được học từ tất cả các nhánh sau đó được hợp nhất lại với nhau để
phân loại hoặc dự đoán dày đặc.
Text
Mô-đun
FusionMô-đun
FusionMô-đun
FusionMô-đun
FusionMô-đun
FusionConcatDự đoán
Dày đặc
Phân loạiDự đoán
270
144723618
2418
324
Các lớp
Đầu vàoMô-đun
Song songMô-đun
Song songMô-đun
Song songMô-đun
Song songMô-đun
Song songCác lớp
Đầu ra
min= 1 
mout=1 
nsb=[1] 
nc=[18]min= 1 
mout=2 
nsb=[2,2]
nc=[18,36]min= 2 
mout=3 
nsb=[2,2,3]  
nc=[18,36,72]min= 3 
mout=4 
nsb=[2,2,3,4]  
nc=[18,36,72,144]min= 4 
mout=4 
nsb=[2,2,3,4]  
nc=[18,36,72,144]
Hình 9. Hình ảnh hóa kiến trúc supernet được áp dụng, trong đó min và mout ký hiệu
số lượng nhánh đầu vào và đầu ra trong mô-đun fusion; nsb và nc đại diện
cho số lượng khối tìm kiếm và kênh trong mô-đun song song, tương ứng.
B SuperTickets (ST) so với Random Pruning (RP) và
Random Re-Initialization (RR-Init).
Chúng tôi so sánh SuperTickets (ST) được đề xuất với cả "ST w/ RP" và
"ST w/ RR-Init" trong Bảng 7. Chúng tôi xem xét hai bộ dữ liệu dưới độ thưa 80% và 90%:
ST liên tục vượt trội hơn hai đường cơ sở, đạt được trung bình
36.28%/42.03%/21.95% và 11.20%/12.27%/4.34% cải thiện mIoU/mAcc/aAcc
so với "ST w/ RP" và "ST w/ RR-Init", tương ứng, dưới số lượng tham số và FLOPs tương đương. Các thí nghiệm này cho thấy rằng SuperTickets
hoạt động tốt hơn so với cả RP và RR-Init, phù hợp với phát hiện LTH.
Khả năng Chuyển đổi của ST so với RP và RR-Init. Tương tự, chúng tôi so sánh
khả năng chuyển đổi của ba biến thể ST khi chuyển chúng qua các
bộ dữ liệu khác nhau, bao gồm (1) ADE20K →Cityscapes hoặc (2) Cityscapes →ADE20K. Như
được hiển thị trong Bảng 8, ST đạt được trung bình 33.14%/39.38%/21.92% và 11.37%/13.
67%/3.20% cải thiện mIoU/mAcc/aAcc so với "ST w/ RP" và "ST w/

--- TRANG 20 ---
20 H. You et al.
Bảng 7. So sánh ST với "ST w/ RP" và "ST w/ RR-Init" trên cả Cityscapes
và ADE20K dưới độ thưa 80% và 90%.
Phương pháp FLOPsCityscapes ( p= 80%)
FLOPsCityscapes ( p= 90%)
mIoU mAcc aAcc mIoU mAcc aAcc
S+P w/ RP 405M 1.30% 5.17% 21.96% 203M 1.15% 5.26% 21.9%
ST w/ RP 397M 20.17% 27.57% 68.73% 200M 16.55% 23.83% 65.90%
ST w/ RR-Init 397M 56.88% 67.33% 92.62% 200M 52.96% 62.66% 91.91%
ST 397M 69.77% 79.76% 95.12% 200M 66.61% 76.30% 94.63%
Phương pháp FLOPsADE20K ( p= 80%)
FLOPsADE20K ( p= 90%)
mIoU mAcc aAcc mIoU mAcc aAcc
S+P w/ RP 308M 0.06% 0.66% 6.54% 154M 0.01% 0.66% 1.72%
ST w/ RP 317M 8.58% 11.93% 60.21% 159M 4.98% 7.19% 55.30%
ST w/ RR-Init 317M 21.24% 30.62% 68.57% 159M 19.49% 28.46% 67.26%
ST 317M 31.19% 43.10% 74.82% 159M 27.82% 39.49% 73.37%
Bảng 8. Các kiểm tra xác thực chuyển đổi biến thể ST dưới độ thưa 90%.
Phương phápADE20K →Cityscapes
Phương phápCityscapes →ADE20K
mIoU mAcc aAcc mIoU mAcc aAcc
ST w/ RP 10.51% 14.42% 61.28% ST w/ RP 6.95% 10.1% 57.7%
ST w/ RR-Init 46.19% 54.92% 90.88% ST w/ RR-Init 14.82% 21.02% 65.54%
ST 62.91% 73.32% 93.82% ST 20.83% 29.95% 69.00%
RR-Init" các đường cơ sở, tương ứng, chỉ ra rằng RP và RR-Init kém hơn trong
khả năng chuyển đổi so với ST được đề xuất.
C Làm rõ Cài đặt LTH.
Có hai cài đặt gây nhầm lẫn khi nói về LTH: (1) trực tiếp kiểm tra độ chính xác của cấu trúc được tìm thấy và các trọng số đã huấn luyện; và (2) các trọng số được khôi phục về giá trị ban đầu của chúng và được huấn luyện với mặt nạ thu được để có được
độ chính xác kiểm tra. Chúng tôi đã thử cả hai cài đặt nói trên và thấy rằng cái trước,
tức là, trực tiếp kiểm tra độ chính xác của cấu trúc được tìm thấy và trọng số đã huấn luyện, đã
đạt được kết quả tốt. Đây là một điểm nổi bật khác của công trình chúng tôi, vì nó có thể
giúp tiết kiệm đáng kể thời gian huấn luyện lại. Hơn nữa, để giải quyết mối quan tâm của bạn, chúng tôi
khởi tạo lại SuperTickets về (1) các giá trị ban đầu của chúng, theo LTH gốc ("ST w/ LT-Init") và (2) các giai đoạn sớm hoặc (3) muộn theo [12] ("ST
w/ ELT-Init hoặc LLT-Init"), và so sánh chúng với các đối tác RR-Init.
Từ Bảng 9, chúng ta có thể thấy rằng (1)ST dưới tất cả các cài đặt LTH đạt được độ chính xác tốt hơn
so với RR-Init, chỉ ra hiệu quả của ST; (2)vanilla LT-Init
hoạt động kém hơn cả ELT-Init và LLT-Init dưới cài đặt ST, phù hợp với
[12]; và (3)ST w/ ELT-Init hoặc LLT-Init đạt được độ chính xác tương đương hoặc hơi tốt hơn
so với ST w/o Retrain với chi phí huấn luyện lại.

--- TRANG 21 ---
SuperTickets 21
Bảng 9. So sánh ST w/ các cài đặt LTH khác nhau (độ thưa 90%).
Phương phápCityscapes ( p= 90%)
Phương phápADE20K ( p= 90%)
mIoU mAcc aAcc mIoU mAcc aAcc
ST w/ RR-Init 52.96% 62.66% 91.91% ST w/ RR-Init 19.49% 28.46% 67.26%
ST w/ LT-Init 59.63% 70.24% 93.33% ST w/ LT-Init 25.32% 36.76% 71.33%
ST w/ ELT-Init 65.82% 76.74% 94.54% ST w/ ELT-Init 25.79% 37.33% 72.10%
ST w/ LLT-Init 67.17% 77.03% 94.73% ST w/ LLT-Init 28.51% 40.63% 73.49%
ST w/o Retrain 66.61% 77.03% 94.73% ST w/o Retrain 27.82% 39.49% 73.37%
D Tăng tốc theo Thời gian Suy luận
Ngoài số lượng tham số và FLOPs, chúng tôi đo FPS suy luận và tăng tốc trên cả GPU 1080Ti và một bộ gia tốc suy luận DNN thưa SOTA [32]. Như được hiển thị trong Bảng 10, ST đạt được FPS ngang bằng hoặc thậm chí cao hơn (tức là,
tăng tốc 1.8×∼2.9×) trên GPU và thời gian bộ gia tốc giảm nhiều (tức là,
tăng tốc 2.9×∼4.1×) trên [32] so với các đường cơ sở, nhờ vào việc đồng thời tìm kiếm kiến trúc và cắt tỉa tham số (tức là, 2-in-1) và ST.
Bảng 10. ST so với các đường cơ sở điển hình trên Cityscapes, theo thời gian suy luận được đo
trên cả GPU và bộ gia tốc thưa.
Mô hình Params FLOPs mIoU GPU FPS Thời gian Bộ gia tốc Thưa
BiSeNet 5.8M 6.6G 69.00% 105.8 180.8ms
DF1-Seg-d8 - - 71.40% 136.9 181.7ms
FasterSeg 4.4M - 71.50% 163.9 142.4ms
SqueezeNAS 0.73M 8.4G 72.40% 117.2 198.5ms
ST ( p= 50%) 0.63M 1.0G 72.68% 310.7 48.3ms
E Thảo luận
Hạn chế của SuperTickets Được chuyển đổi. Mặc dù các SuperTickets được xác định
có thể chuyển đổi chỉ với các bộ phân loại như cụ thể tác vụ, vẫn có một hạn chế trong các SuperTickets được chuyển đổi. Đó là, các SuperTickets được chuyển đổi không thể vượt trội hơn những
SuperTickets được tìm thấy trực tiếp trên các bộ dữ liệu/tác vụ đích. Hơn nữa, khi độ thưa thấp (ví dụ, 30%), các SuperTickets được chuyển đổi sẽ hoạt động kém hơn cả
SuperTickets và S+P. Điều này trái với trực giác và ngược lại với quan sát
trong việc nén các mô hình được huấn luyện trước [13], trong đó các tỷ lệ cắt tỉa thấp không làm tổn hại độ chính xác sau khi chuyển đổi trong khi cắt tỉa quá mức dẫn đến under-fitting. Nó ngụ ý rằng việc tìm kiếm chuyên dụng là cần thiết khi tỷ lệ cắt tỉa tương đối thấp; trong khi đối với độ thưa cao, tác động của kiến trúc mạng nơ-ron sẽ ít hơn.
Hình ảnh hóa và Thảo luận. Chúng tôi hình ảnh hóa kết quả của SuperTickets
và các đường cơ sở S+P trên các bộ dữ liệu COCO keypoint và Cityscapes dưới các

--- TRANG 22 ---
22 H. You et al.
S+P (Mag.) SuperT ickets
Độ thưa 90%S+P (Mag.) SuperT ickets
Độ thưa 70%
Độ thưa 70%S+P (Mag.) SuperT ickets
Độ thưa 95%S+P (Mag.) SuperT ickets(a) Ước lượng Tư thế Con người
(b) Phân đoạn Ngữ nghĩa
Hình 10. Hình ảnh hóa ước lượng tư thế con người trên bộ dữ liệu COCO keypoint và
nhãn streetview/ngữ nghĩa trên bộ dữ liệu Cityscapes dưới các tỷ lệ cắt tỉa khác nhau.
tỷ lệ cắt tỉa khác nhau, như được hiển thị trong Hình 10. Chúng tôi quan sát rằng các đường cơ sở S+P hoạt động nhưng bỏ lỡ một số keypoint hoặc hiểu biết ngữ nghĩa dưới độ thưa trung bình (ví dụ,
70%) trong khi sụp đổ dưới các tỷ lệ cắt tỉa cao (ví dụ, 90/95%); Ngược lại, các
SuperTickets được xác định của chúng tôi liên tục hoạt động tốt trong một phạm vi rộng các tỷ lệ cắt tỉa, xác thực hiệu quả của SuperTickets được đề xuất của chúng tôi.
F Thêm Hình ảnh hóa Kết quả Nhận dạng Thị giác
Chúng tôi tiếp tục hình ảnh hóa kết quả của SuperTickets và các đường cơ sở S+P trên các bộ dữ liệu COCO
keypoint và Cityscapes dưới các tỷ lệ cắt tỉa khác nhau, như được hiển thị trong Hình
11 và Hình 12, tương ứng. Chúng tôi quan sát rằng các đường cơ sở S+P hoạt động nhưng bỏ lỡ một số
keypoint hoặc hiểu biết ngữ nghĩa dưới độ thưa trung bình (ví dụ, 70/80%)
trong khi sụp đổ dưới các tỷ lệ cắt tỉa cao (ví dụ, 90/95%); Ngược lại, các
SuperTickets được xác định của chúng tôi liên tục hoạt động tốt trong một phạm vi rộng các tỷ lệ cắt tỉa,
xác thực hiệu quả của SuperTickets được đề xuất của chúng tôi.

--- TRANG 23 ---
SuperTickets 23
Hình 11. Hình ảnh hóa ước lượng tư thế con người trên bộ dữ liệu COCO keypoint dưới
các tỷ lệ cắt tỉa khác nhau.

--- TRANG 24 ---
24 H. You et al.
Độ thưa 70%S+P (Mag.) SuperTickets
Độ thưa 95%S+P (Mag.) SuperTickets
Phân đoạn Ngữ nghĩa
Độ thưa 80%
Độ thưa 90%
S+P (Mag.) SuperTickets S+P (Mag.) SuperTickets
Độ thưa 70%S+P (Mag.) SuperTickets
Độ thưa 95%S+P (Mag.) SuperTickets
Phân đoạn Ngữ nghĩa
Độ thưa 80%
Độ thưa 90%
S+P (Mag.) SuperTickets S+P (Mag.) SuperTickets
Hình 12. Hình ảnh hóa nhãn streetview/ngữ nghĩa trên bộ dữ liệu Cityscapes dưới
các tỷ lệ cắt tỉa khác nhau.

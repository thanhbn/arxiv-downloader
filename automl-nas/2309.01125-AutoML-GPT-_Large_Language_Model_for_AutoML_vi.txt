# AutoML-GPT: Mô hình Ngôn ngữ Lớn cho AutoML
Yun-Da Tsai1 Yu-Che Tsai1 Bo-Wei Huang1 Chun-Pai Yang1 Shou-De Lin1

Tóm tắt
Với xu hướng nổi lên của các mô hình GPT, chúng tôi đã thiết lập một khung làm việc gọi là AutoML-GPT tích hợp một bộ công cụ và thư viện toàn diện. Khung làm việc này cung cấp cho người dùng quyền truy cập vào một loạt các kỹ thuật tiền xử lý dữ liệu, phương pháp kỹ thuật đặc trưng, và thuật toán lựa chọn mô hình. Thông qua giao diện đối thoại, người dùng có thể chỉ định yêu cầu, ràng buộc và các chỉ số đánh giá của họ. Trong suốt quá trình, AutoML-GPT sử dụng các kỹ thuật tiên tiến để tối ưu hóa siêu tham số và lựa chọn mô hình, đảm bảo rằng mô hình kết quả đạt được hiệu suất tối ưu. Hệ thống quản lý hiệu quả độ phức tạp của pipeline học máy, hướng dẫn người dùng đến những lựa chọn tốt nhất mà không yêu cầu kiến thức chuyên sâu về lĩnh vực. Thông qua các kết quả thực nghiệm trên các tập dữ liệu đa dạng, chúng tôi đã chứng minh rằng AutoML-GPT giảm đáng kể thời gian và công sức cần thiết cho các tác vụ học máy. Khả năng tận dụng kiến thức rộng lớn được mã hóa trong các mô hình ngôn ngữ lớn cho phép nó cung cấp những hiểu biết sâu sắc có giá trị, xác định các cạm bẫy tiềm ẩn, và đề xuất các giải pháp hiệu quả cho những thách thức thường gặp trong quá trình huấn luyện mô hình.

1. Giới thiệu
Automated Machine Learning (AutoML) đã thu hút sự chú ý đáng kể trong những năm gần đây như một kỹ thuật mạnh mẽ để tự động hóa các giai đoạn khác nhau của quy trình làm việc học máy. Nó nhằm đơn giản hóa quá trình phát triển mô hình bằng cách tự động tìm kiếm, lựa chọn và tối ưu hóa các mô hình học máy mà không yêu cầu can thiệp thủ công rộng rãi. AutoML có tiềm năng dân chủ hóa học máy và làm cho nó có thể tiếp cận được với đối tượng rộng hơn, bao gồm những người không chuyên và các chuyên gia lĩnh vực. AutoML

1 Khoa Khoa học Máy tính và Kỹ thuật Thông tin, Đại học Quốc gia Đài Loan, Đài Bắc, Đài Loan. Liên hệ với: Yun-Da Tsai <f08946007@csie.ntu.edu.tw>.

Kỷ yếu Hội nghị Quốc tế lần thứ 40 về Học máy, Honolulu, Hawaii, Hoa Kỳ. PMLR 202, 2023. Bản quyền 2023 thuộc về (các) tác giả. bao gồm các tác vụ như tiền xử lý dữ liệu, kỹ thuật đặc trưng, lựa chọn mô hình và điều chỉnh siêu tham số. Những tác vụ này yêu cầu chuyên môn, thời gian và tài nguyên tính toán. Để giải quyết những thách thức này, các nhà nghiên cứu đã đề xuất nhiều cách tiếp cận và khung làm việc khác nhau cho AutoML, như Auto-sklearn (Feurer et al., 2015), Auto-Keras (Jin et al., 2023), và AutoGluon (Erickson et al., 2020). Những cách tiếp cận này nhằm tự động hóa quá trình lựa chọn và cấu hình mô hình, làm cho việc xây dựng các mô hình học máy chính xác và hiệu quả trở nên dễ dàng hơn cho các nhà thực hành.

Các mô hình ngôn ngữ lớn, như GPT-3 của OpenAI (Brown et al., 2020) và PaLM của Google (Chowdhery et al., 2022), đã nổi lên như những công cụ mạnh mẽ trong xử lý và hiểu ngôn ngữ tự nhiên. Những mô hình này đã được huấn luyện rộng rãi trên khối lượng lớn dữ liệu văn bản và đã chứng minh được khả năng đáng chú ý trong hiểu ngôn ngữ, tạo văn bản, phân tích cảm xúc và các tác vụ liên quan đến ngôn ngữ khác. Các mô hình ngôn ngữ lớn xuất sắc trong việc nắm bắt các mẫu phức tạp, hiểu ngữ cảnh và tạo ra các phản hồi mạch lạc. Sức mạnh của các mô hình ngôn ngữ lớn nằm ở khả năng hiểu và xử lý dữ liệu văn bản phi cấu trúc một cách hiệu quả. Chúng học được các biểu diễn ngữ nghĩa phong phú của ngôn ngữ, cho phép chúng hiểu được các sắc thái và tinh tế có trong văn bản. Bằng cách tận dụng các mô hình ngôn ngữ được huấn luyện trước, các nhà nghiên cứu đã đạt được những tiến bộ đáng kể trong nhiều tác vụ xử lý ngôn ngữ tự nhiên, bao gồm dịch máy, trả lời câu hỏi và tạo ngôn ngữ.

Trong khi các mô hình ngôn ngữ lớn đã tìm thấy thành công trong các ứng dụng cụ thể, việc tích hợp toàn diện của chúng vào khung AutoML vẫn còn tương đối chưa được khám phá. Nghiên cứu hiện tại chủ yếu tập trung vào việc sử dụng các mô hình ngôn ngữ cho các tác vụ riêng lẻ trong AutoML, như tiền xử lý dữ liệu và kỹ thuật đặc trưng. Tuy nhiên, tiềm năng của việc tận dụng những mô hình này để tự động hóa toàn bộ pipeline AutoML, từ chuẩn bị dữ liệu đến tối ưu hóa siêu tham số, chưa được nghiên cứu rộng rãi. Sự thiếu khám phá này phục vụ như động lực cho công trình này. Các mô hình ngôn ngữ lớn (LLMs) thể hiện những ưu điểm đặc biệt trong AutoML từ nhiều góc độ. Về mặt hiểu dữ liệu, LLMs có thể được sử dụng để tiền xử lý dữ liệu, xử lý hiệu quả các giá trị thiếu, chuẩn hóa hoặc chia tỷ lệ các đặc trưng, và phát hiện các giá trị ngoại lai. Ngoài ra, các mô hình ngôn ngữ lớn có khả năng tiến hành phân tích tương quan, khám

--- TRANG 2 ---
AutoML-GPT: Mô hình Ngôn ngữ Lớn cho AutoML

Tác nhân Lý luận • Hiểu yêu cầu của con người • Kết hợp trình tự sử dụng công cụ • Giám sát nhiệm vụ phụ Tác nhân Mã hóa • Đọc tài liệu và module • Tạo mã AutoML • Trả về kết quả thực thi mã
Tạo ra Suy nghĩ Trả về Kết quả Yêu cầu AutoML Phản hồi & Đề xuất • Tập dữ liệu mục tiêu • Tối ưu hóa mục tiêu • Yêu cầu ML
Người dùng

Hình 1. Pipeline của AutoML-GPT.

phá các mối quan hệ nhân quả, và thực hiện lựa chọn đặc trưng. Điều này cho phép chúng xác định và loại bỏ hiệu quả các đặc trưng không liên quan hoặc dư thừa. Hơn nữa, những mô hình này góp phần vào việc xác định các mô hình tiềm năng phù hợp cho một tập dữ liệu và tác vụ nhất định, cung cấp hướng dẫn có giá trị trong giai đoạn lựa chọn mô hình.

Trong bài báo này, chúng tôi đã thiết kế AutoML-GPT, một hệ thống tác nhân kép được xây dựng dựa trên các mô hình ngôn ngữ lớn. Các tác nhân trong hệ thống có khả năng giao tiếp, lập kế hoạch và sử dụng công cụ để hoàn thành các tác vụ học máy phức tạp. Trong các thí nghiệm của chúng tôi, AutoML-GPT đã chứng minh hiệu suất tương thích so với các chuyên gia con người trên 11 tập dữ liệu dạng bảng được chọn từ các cuộc thi Kaggle gần đây, phản ánh các ứng dụng ML hiện đại thực tế.

2. Phương pháp luận
Để tích hợp một Mô hình Ngôn ngữ Lớn (LLM) vào khung AutoML, chúng tôi đề xuất một phương pháp luận có hệ thống bao gồm hai tác nhân: tác nhân Lý luận và tác nhân Mã hóa, như được minh họa trong Hình 1. Cả hai tác nhân đều được triển khai sử dụng khung ReAct (Yao et al., 2022) bởi langchain1.

Tác nhân Lý luận trong pipeline AutoML xử lý nhiệm vụ hiểu yêu cầu của con người và lập kế hoạch trình tự sử dụng công cụ. Nó sử dụng khả năng hiểu ngôn ngữ của LLM để diễn giải chính xác các yêu cầu phức tạp và lập kế hoạch hiệu quả các bước cần thiết cho các tác vụ như huấn luyện từ đầu đến cuối. Tác nhân này chịu trách nhiệm kết hợp các công cụ khác nhau một cách tối ưu, giám sát tiến trình của pipeline, và cung cấp cập nhật kịp thời cho người dùng. Mặt khác, tác nhân Mã hóa chịu trách nhiệm triển khai các tác vụ đã được lập kế hoạch. Nó thu được kiến thức cần thiết bằng cách đọc tài liệu và module, tận dụng hiểu biết của nó về các ngôn ngữ lập trình và công cụ AutoML. Tác nhân Mã hóa tạo ra ý tưởng, hình thành mã và thực thi nó một cách có cấu trúc để thực hiện các hành động được chỉ định trong pipeline AutoML. Nó đóng vai trò quan trọng trong việc dịch suy luận và lập kế hoạch của tác nhân Lý luận thành mã có thể thực thi được.

1https://github.com/hwchase17/langchain

Hình 2. Tóm tắt hiệu suất theo phần trăm thứ hạng trên Bảng xếp hạng qua 9 cuộc thi Kaggle so với các công cụ automl nổi tiếng khác.

Sự tương tác giữa các tác nhân Lý luận và Mã hóa là lặp đi lặp lại và cộng tác. Tác nhân Lý luận nhận đầu ra thực thi từ tác nhân Mã hóa và sử dụng nó để cung cấp các phản hồi liên quan và thông tin cho người dùng. Điều này cho phép tác nhân Lý luận giao tiếp tiến trình của pipeline AutoML, phản hồi các câu hỏi của người dùng, và cung cấp những hiểu biết có ý nghĩa dựa trên các tác vụ đã thực thi. Bằng cách sử dụng phương pháp luận này với các tác nhân Lý luận và Mã hóa, việc tích hợp LLM vào khung AutoML được hưởng lợi từ khả năng suy luận và lập kế hoạch của tác nhân Lý luận, cũng như chuyên môn tạo mã và thực thi của tác nhân Mã hóa. Cách tiếp cận cộng tác này đảm bảo việc diễn giải chính xác các yêu cầu của người dùng, lập kế hoạch chính xác về việc sử dụng công cụ, triển khai mã đáng tin cậy, và giao tiếp hiệu quả với người dùng, tạo điều kiện cho một pipeline AutoML liền mạch và hiệu quả.

3. Kết quả Thực nghiệm
Đối với thí nghiệm, chúng tôi đã chọn sử dụng benchmark Kaggle được sử dụng rộng rãi, có ý nghĩa quan trọng trong tài liệu nghiên cứu automl. Chúng tôi đã chọn chín tập dữ liệu dạng bảng từ các cuộc thi Kaggle gần đây để đại diện cho các ứng dụng đương đại. Những cuộc thi này bao gồm một loạt các tác vụ, bao gồm hồi quy và phân loại (nhị phân/đa lớp). Các tổ chức cuộc thi đã điều chỉnh các chỉ số khác nhau để đánh giá hiệu suất dự đoán dựa trên vấn đề cụ thể hiện có. Mỗi tập dữ liệu được xử lý bởi AutoML-GPT trong một chuỗi bốn hướng dẫn thông qua LLM (1) Khám phá tập dữ liệu (2) Xử lý tập dữ liệu (3) Chọn mô hình (4) Tinh chỉnh tham số. Trong thí nghiệm của chúng tôi, chúng tôi sẽ sử dụng một mô hình đơn lẻ mà không sử dụng bất kỳ kỹ thuật ensemble nào. Kết quả, được mô tả trong Hình 2, đại diện cho phần trăm thứ hạng trên bảng xếp hạng cuộc thi Kaggle.

--- TRANG 3 ---
AutoML-GPT: Mô hình Ngôn ngữ Lớn cho AutoML

Điều quan trọng cần lưu ý là mỗi kết quả là một lần nộp bài một lần duy nhất lên Kaggle mà không có bất kỳ tinh chỉnh thêm nào sau phát triển cục bộ. Trong thí nghiệm, chúng tôi đã so sánh với 6 khung automl tiên tiến nổi tiếng khác: auto-sklearn, TPOT, Auto-WEKA, H2O AutoML, GCP-tables, AutoGluon. Thí nghiệm được hiển thị trong Hình 2 giới hạn thời gian huấn luyện của mỗi khung automl tối đa 8 giờ.

4. Thảo luận
Kết quả thí nghiệm trong Hình 2 cho thấy AutoML-GPT với hiệu suất cạnh tranh. Sự khác biệt chính giữa AutoML-GPT và các khung automl khác là hầu hết các khung automl tập trung vào các tác vụ như tìm kiếm siêu tham số và kỹ thuật ensemble mô hình. Sức mạnh của hiệu suất đến từ sức mạnh tính toán rộng lớn. Tuy nhiên, vì chúng tôi giới hạn AutoML-GPT đến kết quả mô hình đơn lẻ, hiệu suất cạnh tranh đến từ chuyên môn trong kiến thức lĩnh vực học máy. AutoML-GPT tiến hành khám phá và hiểu dữ liệu tuyệt vời và do đó tạo ra các tập dữ liệu được xử lý tốt cho việc huấn luyện mô hình. Hiệu suất sẽ được tăng cường thêm nếu chúng tôi kết hợp các khung automl khác như một trong những công cụ vào AutoML-GPT.

5. Kết luận
Trong bài báo này, chúng tôi đã đề xuất khung AutoML-GPT sử dụng LLM như chuyên gia học máy để tiến hành automl. Chúng tôi đã cho thấy hiệu suất cạnh tranh của nó bằng cách so sánh với các khung automl nổi tiếng khác và các đối thủ cạnh tranh con người trên các benchmark Kaggle.

Tài liệu tham khảo
Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., et al. Language models are few-shot learners. Advances in neural information processing systems, 33: 1877–1901, 2020.

Chowdhery, A., Narang, S., Devlin, J., Bosma, M., Mishra, G., Roberts, A., Barham, P., Chung, H. W., Sutton, C., Gehrmann, S., et al. Palm: Scaling language modeling with pathways. arXiv preprint arXiv:2204.02311, 2022.

Erickson, N., Mueller, J., Shirkov, A., Zhang, H., Larroy, P., Li, M., and Smola, A. Autogluon-tabular: Robust and accurate automl for structured data. arXiv preprint arXiv:2003.06505, 2020.

Feurer, M., Klein, A., Eggensperger, K., Springenberg, J., Blum, M., and Hutter, F. Efficient and robust automated machine learning. In Advances in Neural Information Processing Systems 28 (2015), pp. 2962–2970, 2015.

Jin, H., Chollet, F., Song, Q., and Hu, X. Autokeras: An automl library for deep learning. Journal of Machine Learning Research, 24(6):1–6, 2023. URL http://jmlr.org/papers/v24/20-1355.html.

Yao, S., Zhao, J., Yu, D., Du, N., Shafran, I., Narasimhan, K., and Cao, Y. React: Synergizing reasoning and acting in language models. arXiv preprint arXiv:2210.03629, 2022.

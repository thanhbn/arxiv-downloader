# 2302.14838.pdf
# Đã chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/automl-nas/2302.14838.pdf
# Kích thước tệp: 1185610 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
EvoPrompting: Mô Hình Ngôn Ngữ cho Tìm Kiếm Kiến Trúc Mạng Neural Cấp Độ Mã
Angelica Chen∗
Đại học New York
angelica.chen@nyu.eduDavid M. Dohan†
OpenAI
david@ddohan.com
David R. So†
Jane Street
david.r.so.ai@gmail.com

Tóm tắt
Với những thành tựu ấn tượng gần đây của các mô hình ngôn ngữ (LM) trong việc tạo sinh mã, chúng tôi khám phá việc sử dụng LM làm toán tử đột biến và lai ghép thích ứng tổng quát cho một thuật toán tìm kiếm kiến trúc mạng neural tiến hóa (NAS). Mặc dù NAS vẫn chứng tỏ là một nhiệm vụ quá khó khăn để LM có thể thành công chỉ thông qua prompting, chúng tôi nhận thấy rằng sự kết hợp của kỹ thuật prompt tiến hóa với soft prompt-tuning, một phương pháp mà chúng tôi gọi là EVOPROMPTING, luôn tìm ra các mô hình đa dạng và hiệu suất cao. Đầu tiên chúng tôi chứng minh rằng EVOPROMPTING có hiệu quả trên tập dữ liệu MNIST-1D tính toán hiệu quả, nơi EVOPROMPTING tạo ra các biến thể kiến trúc tích chập vượt trội cả những kiến trúc được thiết kế bởi các chuyên gia con người và naive few-shot prompting về mặt độ chính xác và kích thước mô hình. Sau đó chúng tôi áp dụng phương pháp của mình để tìm kiếm các mạng neural đồ thị trên CLRS Algorithmic Reasoning Benchmark, nơi EVOPROMPTING có thể thiết kế các kiến trúc mới vượt trội các mô hình hiện tại tốt nhất trên 21 trong số 30 nhiệm vụ lý luận thuật toán trong khi duy trì kích thước mô hình tương tự. EVOPROMPTING thành công trong việc thiết kế các kiến trúc mạng neural chính xác và hiệu quả trên nhiều nhiệm vụ máy học khác nhau, đồng thời cũng đủ tổng quát để dễ dàng thích ứng với các nhiệm vụ khác ngoài thiết kế mạng neural.

1 Giới thiệu
Việc mở rộng quy mô của Transformers (Vaswani et al., 2017) đã tạo ra các mô hình ngôn ngữ (LM) với hiệu suất ấn tượng. Ngoài việc đạt được kết quả tốt nhất trong các nhiệm vụ xử lý ngôn ngữ tự nhiên thông thường, những LM này còn thể hiện các khả năng kỹ thuật đột phá, chẳng hạn như học cách viết mã (Chen et al., 2021), làm toán (Noorbakhsh et al., 2021), và giải quyết các bài toán lý luận (Wei et al., 2022). Tuy nhiên, bất chấp những tiến bộ này, một số nghiên cứu đã lưu ý đến những hạn chế hiện tại của LM trong việc giải quyết các vấn đề phức tạp và tạo ra các giải pháp mới (Qian et al., 2022; Dakhel et al., 2022). Trong nghiên cứu này, chúng tôi cải thiện khả năng của LM cơ sở trong việc đề xuất các giải pháp mới và đa dạng cho các vấn đề lý luận phức tạp bằng cách tiến hóa lặp đi lặp lại các prompt trong ngữ cảnh và prompt-tuning LM. Chúng tôi gọi kỹ thuật này là EVOPROMPTING và chứng minh sự thành công của nó trong nhiệm vụ khó khăn là thiết kế kiến trúc học sâu.

Phát hiện chính của chúng tôi là, trong khi LM hoạt động kém trong việc thiết kế các kiến trúc mạng neural mới và hiệu quả thông qua naive few-shot prompting, EVOPROMPTING cho phép LM tạo ra các kiến trúc mạng neural sâu mới và hiệu quả, đặc biệt khi kết hợp với các phương pháp prompt-tuning.

∗Công việc được thực hiện khi là Sinh viên Nghiên cứu tại Google DeepMind.
†Công việc được thực hiện khi tại Google DeepMind.
Hội nghị lần thứ 37 về Hệ thống Xử lý Thông tin Neural (NeurIPS 2023).arXiv:2302.14838v3  [cs.NE]  16 Nov 2023

--- TRANG 2 ---
Hình 1: Tổng quan về EVOPROMPTING. Sau khi khởi tạo việc tìm kiếm với một số chương trình mẫu được thiết kế thủ công, vòng lặp meta-learning bắt đầu. Đầu tiên, LM được pre-trained trên mã của chúng tôi sử dụng các mẫu làm ví dụ prompt trong ngữ cảnh để tạo ra các kiến trúc ứng viên. Những kiến trúc ứng viên đó sau đó được huấn luyện trên dữ liệu huấn luyện của nhiệm vụ và đánh giá trên tập validation của nhiệm vụ. Tiếp theo, những thành viên phù hợp nhất của quần thể được chọn làm ví dụ trong ngữ cảnh cho vòng lặp meta-learning tiếp theo và tất cả các cá thể đã được đánh giá được sử dụng làm dữ liệu huấn luyện để prompt-tuning LM. Từ đó, vòng lặp meta-learning bắt đầu lại.

EVOPROMPTING dựa trên thực hành gần đây được phổ biến là in-context prompting. Prompting là kỹ thuật điều kiện hóa đầu ra được giải mã của LM trên một tiền tố tùy chỉnh được gọi là prompt, có thể bao gồm hướng dẫn nhiệm vụ bằng ngôn ngữ tự nhiên hoặc một số ví dụ đầu vào-đầu ra. Prompt chỉ được sử dụng tại thời điểm suy luận và không yêu cầu cập nhật gradient (Brown et al., 2020). Trong các nghiên cứu trước, prompting đã được chứng minh có thể đạt được hiệu suất ấn tượng trên nhiều nhiệm vụ khác nhau mà không yêu cầu fine-tuning chuyên biệt cho nhiệm vụ (Sanh et al., 2021; Wei et al., 2022; Kojima et al., 2022). Ở đây, chúng tôi tận dụng LM prompting cho nhiệm vụ thiết kế các kiến trúc học sâu được cải thiện.

Để thiết kế các prompt đủ mạnh, chúng tôi lấy cảm hứng từ các ý tưởng hiện có trong lĩnh vực tìm kiếm kiến trúc mạng neural. Ở đó, tiến hóa từ lâu đã được sử dụng để tìm kiếm trên các không gian rời rạc nhằm khám phá hiệu quả các kiến trúc học sâu được cải thiện (Yao, 1999; Real et al., 2017). Tuy nhiên, các phương pháp tiến hóa thường yêu cầu thiết kế thủ công cẩn thận của một không gian tìm kiếm rời rạc (ví dụ một tập nhỏ các thành phần mạng neural tích chập đã biết, như trong Real et al. (2017) hoặc các nguyên thủy TensorFlow, như trong So et al. (2021)). Kết quả là, hiệu suất của thuật toán tiến hóa sau đó nhạy cảm với và có thể bị giới hạn bởi thiết kế của không gian tìm kiếm. Trong EVOPROMPTING, từ vựng của LM thay thế không gian tìm kiếm, điều này vừa tăng tính linh hoạt của việc tìm kiếm và giảm sự phụ thuộc vào thiết kế thủ công. LM cũng là một toán tử đột biến/lai ghép thích ứng, theo nghĩa là nó có thể được cải thiện từ vòng này sang vòng khác thông qua prompt-tuning. Hơn nữa, EVOPROMPTING cũng cải thiện so với naive few-shot prompting bằng cách sử dụng phương pháp tìm kiếm tiến hóa để cải thiện lặp đi lặp lại các ví dụ trong ngữ cảnh cho few-shot prompting.

Để chứng minh hiệu quả của phương pháp này, đầu tiên chúng tôi thực hiện thử nghiệm và phân tích toàn diện trên bài toán tính toán tương đối thấp là MNIST-1D (Greydanus, 2020). Phát hiện chính của những thí nghiệm này là EVOPROMPTING có khả năng tạo ra các kiến trúc tích chập thông thường vượt trội các mô hình được thiết kế thủ công đã công bố (Mục 4.1). Trong Mục 4.2, chúng tôi sau đó áp dụng phương pháp của mình cho nhiệm vụ thách thức hơn là thiết kế mạng neural đồ thị sử dụng các bài toán từ CLRS Algorithmic Reasoning Benchmark (Veli ˇckovi ´c et al., 2022), nơi EVOPROMPTING tạo ra các kiến trúc mới vượt trội các mô hình tốt nhất hiện tại trên 21 trong số 30 nhiệm vụ lý luận thuật toán (Phụ lục 3).

Các đóng góp của nghiên cứu này được tóm tắt như sau:
1. Chúng tôi đề xuất EVOPROMPTING, một phương pháp sử dụng tìm kiếm tiến hóa để tạo ra và tuyển chọn dữ liệu nhằm cải thiện các ví dụ prompting trong ngữ cảnh của LM. Mặc dù nghiên cứu này tập trung vào nhiệm vụ cụ thể của thiết kế kiến trúc mạng neural để phát triển phương pháp này, EVOPROMPTING có thể áp dụng chung cho các nhiệm vụ LM dựa trên học trong ngữ cảnh (ICL) hoặc prompt-tuning.

2. Một nghiên cứu áp dụng LM cho thiết kế kiến trúc mạng neural cấp độ mã. Các thí nghiệm của chúng tôi chứng minh rằng việc áp dụng few-shot prompting một mình cho thiết kế kiến trúc mạng neural là không thành công, nhưng few-shot prompting với EVOPROMPTING cho phép LM tạo ra các kiến trúc vượt trội những kiến trúc được thiết kế bởi các chuyên gia con người.

--- TRANG 3 ---
3. Các kiến trúc mạng neural đồ thị mới được khám phá bằng EVOPROMPTING. Những kiến trúc này vượt trội kiến trúc tốt nhất hiện tại, Triplet-GMPNN (Ibarz et al., 2022), trên 21 trong số 30 nhiệm vụ CLRS Algorithmic Reasoning Benchmark (Phụ lục 3).

2 Nghiên cứu liên quan
LM cho tạo sinh mã Việc mở rộng quy mô Transformers (Vaswani et al., 2017) hiện tại là một hướng phổ biến để tạo ra các hệ thống ngôn ngữ tự nhiên tốt nhất một cách đáng tin cậy (Brown et al., 2020; Du et al., 2021; BigScience Workshop et al., 2022; Zhang et al., 2022; Thoppilan et al., 2022; Chowdhery et al., 2022). Nhiều nghiên cứu đã quan sát thấy rằng các LM lớn có khả năng thực hiện các nhiệm vụ kỹ thuật như viết mã (Chen et al., 2021), làm toán (Noorbakhsh et al., 2021), và giải quyết các vấn đề lý luận phức tạp (Wei et al., 2022). Nghiên cứu của chúng tôi liên quan chặt chẽ nhất với các nỗ lực đã áp dụng LM cho các nhiệm vụ lập trình (Chen et al., 2021; Odena et al., 2021; Xu et al., 2022; Wang et al., 2021; Ahmad et al., 2021; Feng et al., 2020), vì kỹ thuật của chúng tôi đề xuất các kiến trúc bằng mã.

Prompting Brown et al. (2020) đã chứng minh rằng LM có thể được prompt với các ví dụ trong ngữ cảnh để điều hướng quá trình giải mã LM hướng tới việc giải quyết vấn đề trong ngữ cảnh mà không cần cập nhật gradient. Nhiều nghiên cứu đã sử dụng prompting này để thúc đẩy thêm khả năng của LM (Sanh et al., 2021; Wei et al., 2022; Kojima et al., 2022). Những nghiên cứu khác tập trung vào việc tối ưu hóa các prompt này (Min et al., 2022; Liu et al., 2021) thông qua các phương pháp như tăng cường với hệ thống truy xuất (Rubin et al., 2021), hoán vị các ví dụ few-shot (Lu et al., 2021; Zhao et al., 2021), tạo prompt thông qua LM (Zhou et al., 2022), và instruction-tuning (Wei et al., 2021; Ouyang et al., 2022; Sanh et al., 2021). Từ góc độ của Dohan et al. (2022), prompt là các tham số có thể được điều chỉnh bằng các kỹ thuật suy luận xác suất. Brooks et al. (2022) đề xuất sử dụng few-shot prompt để thực hiện cả chính sách rollout và mô hình thế giới của một thuật toán lặp chính sách. Phương pháp EVOPROMPTING của chúng tôi mở rộng những nỗ lực này bằng cách đề xuất tìm kiếm tiến hóa như một phương tiện để vừa thiết kế tốt hơn các prompt cho ICL và điều chỉnh LM cơ sở để sử dụng prompt hiệu quả hơn.

Thuật toán tiến hóa Phương pháp của chúng tôi liên quan chặt chẽ với tìm kiếm kiến trúc mạng neural tiến hóa (NAS) (Real et al., 2017, 2018; Elsken et al., 2018; So et al., 2019; Liu et al., 2020), trong đó các kiến trúc được biểu diễn như DNA rời rạc, và được tiến hóa và lọc dựa trên các chỉ số fitness đánh giá hiệu suất kiến trúc. Tuy nhiên, phương pháp của chúng tôi có thể tìm kiếm trên các chuỗi mã tùy ý, trong khi các thuật toán NAS tiến hóa thông thường dựa vào các không gian tìm kiếm được thiết kế thủ công có thể thiên lệch mạnh và ràng buộc việc tìm kiếm (Li & Talwalkar, 2019; Sciuto et al., 2019; Bender et al., 2020; Real et al., 2020; So et al., 2021). Một nghiên cứu gần với chúng tôi là Lehman et al. (2022), trong đó một LM được fine-tune để tạo ra các diff mã Python dựa trên một trong ba thông điệp cố định mô tả những gì cần được thay đổi, và sau đó được sử dụng làm toán tử đột biến trong một thuật toán tiến hóa. Nghiên cứu của họ được xác nhận trên miền Sodarace. Nghiên cứu của chúng tôi khác ở chỗ chúng tôi sử dụng LM làm toán tử lai ghép, mà không chỉ định lớp thay đổi cần thực hiện, điều này có thể mang lại tính linh hoạt lớn hơn. Hơn nữa, chúng tôi đánh giá phương pháp của mình trên nhiệm vụ thực tế của NAS, dựa vào việc lấy mẫu nhiệt độ hỗn hợp của LM để có tính đa dạng thay vì sử dụng thuật toán QD, và cũng sử dụng prompt-tuning trong thuật toán của chúng tôi. Chúng tôi chọn không sử dụng thuật toán QD như MAP-Elites vì phương pháp này yêu cầu thiết kế và rời rạc hóa không gian mô tả, điều này phức tạp và khó thiết kế thủ công cho không gian của tất cả các mạng neural có thể.

Một nghiên cứu đồng thời khác là Meyerson et al. (2023), sử dụng LM làm toán tử lai ghép để tạo ra các biến thể của kiểu gen dựa trên văn bản trong các miền hồi quy tượng trưng, cảm xúc văn bản, hình ảnh, và các chương trình Sodaracer. Giống như Lehman et al. (2022), họ sử dụng MAP-Elites để đánh đổi chất lượng với tính đa dạng trong hai miền và chứng minh rằng thuật toán tổng thể của họ tạo ra một cách đáng tin cậy một loạt các đầu ra đa dạng. Họ cũng chứng minh hiệu suất tương đương với các phương pháp tốt nhất hiện tại trên nhiệm vụ đồ chơi của hồi quy tượng trưng. Nghiên cứu của họ khác với chúng tôi ở một số điểm – chúng tôi áp dụng thuật toán của mình cho nhiệm vụ thực tế của NAS, chúng tôi tối ưu hóa cho sự đánh đổi giữa hiệu suất nhiệm vụ tốt nhất và kích thước mô hình, chúng tôi điều kiện hóa trên hiệu suất mục tiêu trong các prompt của mình, chúng tôi không sử dụng MAP-Elites, và chúng tôi sử dụng prompt-tuning để cải thiện lặp đi lặp lại khả năng lai ghép của LM thay vì.

--- TRANG 4 ---
3 Phương pháp EVOPROMPTING

3.1 Xây dựng bài toán tìm kiếm kiến trúc
Gọi nhiệm vụ mục tiêu của chúng ta được ký hiệu bởi T và D là một tập dữ liệu bao gồm các cặp đầu vào-đầu ra (x, y)∈ D cho nhiệm vụ T. Định nghĩa phân phối xác suất πθ:V → {0,1} trên từ vựng V như một mô hình ngôn ngữ/mã được tham số hóa bởi θ, từ đó chúng ta có thể lấy mẫu các đoạn mã c∈ V∗ (với V∗ là đóng Kleene của V, tức là tập hợp tất cả các phép nối của các ký hiệu trong V). Chúng ta cũng có một hàm đánh giá EVALT(c,D) :V∗× D → R huấn luyện kiến trúc mô hình được đưa ra bởi mã c trên D và xuất ra một số điểm fitness giá trị thực s∈R, có thể là một hàm của độ chính xác mô hình và các đặc tính mô hình khác. Mục tiêu cuối cùng của chúng ta là xác định một số tập hợp các mẫu mã c∼ V∗ định nghĩa các kiến trúc mạng neural mà khi được huấn luyện trên D, tối đa hóa phần thưởng EVALT(c,D).

3.2 LM cho lai ghép và đột biến tiến hóa
Mục tiêu của thuật toán của chúng ta là tạo ra một tập hợp C bao gồm k kiến trúc mạng neural tối đa hóa phần thưởng EVALT(c,D) cho các cặp (D,T) tùy ý:
arg max
C={c|c∼πθ}
|C|=kEc∈CE(x,y)∈D[EVALT(c,D)] (1)

Vì bài toán tối ưu hóa này nói chung là không thể giải được, chúng tôi chuyển sang một phương pháp tiến hóa hộp đen để tạo ra, chấm điểm, và chọn lặp các kiến trúc mạng neural tốt nhất. Thật vậy, tiến hóa đã được chứng minh hoạt động đặc biệt tốt trong lĩnh vực này vì các giải pháp chất lượng cao có xu hướng thưa thớt như thế nào (Real et al., 2017, 2018). Mặc dù tiến hóa đã được sử dụng cho tìm kiếm kiến trúc nhiều lần trước đây (Real et al., 2017, 2018; Elsken et al., 2018; So et al., 2019), chúng tôi cải thiện phương pháp này bằng cách sử dụng LM cho các phép toán lai ghép và đột biến.

Việc sử dụng LM theo cách này có nhiều tính chất hấp dẫn. Trong khi các phương pháp tiến hóa trước đây cho tìm kiếm kiến trúc mạng neural đã yêu cầu thiết kế và đặc tả cẩn thận của một không gian tìm kiếm rời rạc (ví dụ không gian của các mô-đun cấp cao (Real et al., 2018; So et al., 2019), các câu lệnh TensorFlow (So et al., 2021), hoặc các phép toán toán học cơ bản (Real et al., 2020)), không gian tìm kiếm của thuật toán chúng tôi bao gồm bất kỳ kiến trúc mạng neural nào có thể được biểu diễn trong Python. Điều này cho phép tính linh hoạt và đa dạng lớn hơn của các kiến trúc đầu ra, và giảm lượng thiết kế thủ công và thiên lệch con người liên quan đến thuật toán. Hơn nữa, các LM được pre-train hiện đại thường được huấn luyện trên các tập dữ liệu khổng lồ chứa một số lượng đáng kể các tệp mã nguồn. Quá trình pre-training này mã hóa kiến thức hữu ích về cấu trúc và chức năng mã mà không có sẵn trong các thuật toán tiến hóa khác. Cuối cùng, LM cũng có thể được sử dụng làm toán tử lai ghép tự thích ứng, trong đó toán tử lai ghép được huấn luyện gia tăng từ vòng này sang vòng khác để tạo ra các lai ghép phần thưởng cao hơn.

3.3 Thuật toán meta-learning EVOPROMPTING
Thuật toán hoàn chính của chúng tôi được mô tả trong Thuật toán 1. Cốt lõi của thuật toán chúng tôi là một hàm chấm điểm, mô tả "fitness" tổng quát của một mô hình trên nhiệm vụ hiện tại. Vì độ chính xác cao hơn thường có thể đạt được chỉ bằng cách tăng số lượng tham số trong một mô hình, chúng tôi sử dụng tích âm của lỗi validation và kích thước mô hình làm fitness (xem bước 6 trong Thuật toán 3). Các hàm mục tiêu phức tạp hơn đã được sử dụng trước đây cho tìm kiếm kiến trúc mạng neural mục tiêu kép (Bender et al., 2020), nhưng chúng tôi thấy rằng tích đơn giản này hoạt động tốt nhất trong trường hợp của chúng tôi và yêu cầu điều chỉnh tối thiểu. Nói chung fitness càng cao thì càng tốt (với một số cảnh báo, được ghi chú trong mô tả chọn lọc dựa trên fitness của chúng tôi bên dưới).

Thuật toán meta-learning đầu cuối có nhiều giai đoạn, mà chúng tôi mô tả dưới đây:

Khởi tạo Chúng tôi bắt đầu bằng cách đặt quần thể lịch sử toàn cục G thành danh sách trống và khởi tạo quần thể hiện tại P với một số kiến trúc mẫu đã biết là được thiết kế tốt (bước 3 trong Thuật toán 1), điều này khởi động ấm việc tìm kiếm (So et al., 2019). Những mô hình mẫu này được đánh giá bằng cùng một hàm EVALT(c,D) được sử dụng để đánh giá các mô hình ứng viên mới (xem bên dưới).

--- TRANG 5 ---
Thuật toán 1 Thuật toán meta-learning tiến hóa hoàn chỉnh sử dụng pθ làm toán tử lai ghép và đột biến.
1:Đầu vào: LM πθ0, tập dữ liệu D, nhiệm vụ T, T số vòng, m số prompt few-shot mỗi vòng, n số mẫu tạo ra cho mỗi prompt, k số ví dụ trong ngữ cảnh cho mỗi prompt, p số cá thể sống sót được chọn cho mỗi thế hệ, α ngưỡng trên cho lỗi test
2:G←[]
3:P←INITIALIZE POPULATION (p)
4:t←0
5:while t < T do
6: C←CROSS MUT(πθt, P, m, k, n )
7: CEVALED←FILTER ANDEVAL(C,T,D, α)
8: G←G+CEVALED
9: ift < T−1then
10: P←GETTOP(G, p)
11: θt+1←TRAIN (θt, CEVALED\P)
12: end if
13: t←t+ 1
14:end while
15:Return G ETTOP(G, p)

Thuật toán 2 Thuật toán lai ghép và đột biến, CROSS MUT(πθt, P, m, k, n ), trong đó Uniform (P) ký hiệu phân phối đều trên tập hợp P. Tập hợp các bố mẹ tiềm năng P bao gồm các ví dụ hàng đầu từ vòng trước.
1:Đầu vào: LM πθ, quần thể các mẫu mã và fitness P={(c, s)|c∈ V∗,EVALT(c,D) = s}, m số prompt few-shot tạo ra, k số ví dụ trong ngữ cảnh trong mỗi prompt, và n số mẫu lấy mẫu cho mỗi prompt.
2:C←[]
3:i←0
4:while i < m do
5: E← {xj}k j=1, trong đó xj i.i.d.∼Uniform (P)
6: p←MAKEFEWSHOTPROMPT (E)
7: Ci← {cj}n j=1, trong đó cj i.i.d.∼πθ(·|p)
8: C←C+Ci
9: i←i+ 1
10:end while
11:Output: C

Thuật toán 3 Thuật toán lọc và chấm điểm các mô hình con, FILTER ANDEVAL(C,T,D, α).
1:Đầu vào: tập hợp các mẫu mã C, nhiệm vụ T, tập dữ liệu D, hàm đánh giá EVALT(c,D), ngưỡng trên cho lỗi α
2:CEVALED←[]
3:forcinCdo
4: c.error ←EVALT(c,D)
5: ifc.error < α then
6: s← − c.model_size ×c.error
7: CEVALED←CEVALED + [(c, s)]
8: end if
9:end for
10:Output: CEVALED

Lai ghép và đột biến các mô hình bố mẹ Để đột biến và áp dụng lai ghép cho các bố mẹ P được chọn ở bước cuối, chúng tôi sử dụng cả mã nguồn và các chỉ số đánh giá của mỗi mô hình trong P để tạo ra các prompt few-shot.

Trong dòng cuối của prompt, chúng tôi tạo ra một tập hợp các chỉ số mục tiêu để điều kiện hóa việc tạo sinh của πθ chỉ ra độ chính xác validation mong muốn và kích thước mô hình của kiến trúc được đề xuất. Chúng tôi đặt kích thước mô hình mục tiêu là 90% của kích thước mô hình tối thiểu của các mô hình bố mẹ, làm tròn đến 100 tham số gần nhất, và độ chính xác validation mục tiêu là 102% của độ chính xác validation tối đa của các mô hình bố mẹ, làm tròn đến phần mười phần trăm gần nhất. Chúng tôi tạo ra m prompt như vậy mỗi vòng, mỗi prompt với k ví dụ trong ngữ cảnh được chọn ngẫu nhiên đều từ P. Một ví dụ về prompt được hiển thị trong Listing 1.

1""" Metrics :
2{' num_params ': '4800 ' , ' val_accuracy ': '0.865 '}
3"""
4class Model (nn. Module ):
5 @nn . compact
6 def __call__ (self , x):
7 x = nn. Dense ( features =10) (x)
8 return x
9
10""" Metrics :
11{' num_params ': '4300 ' , ' val_accuracy ': '0.880 '}
12"""
13class Model (nn. Module ):

Listing 1: Định dạng của các prompt few-shot của chúng tôi. Trong thực tế chúng tôi sử dụng prompt 2-shot nhưng chúng tôi bỏ qua ví dụ trong ngữ cảnh thứ hai ở đây để ngắn gọn.

Cuối cùng, chúng tôi sử dụng πθ để tạo ra n mẫu cho mỗi prompt, mang lại tổng cộng n×m mẫu con cho mỗi vòng tiến hóa. Chúng tôi ký hiệu phần này của thuật toán là CROSS MUT(πθt, P, m, k, n )(Thuật toán 2 và bước 6 của Thuật toán 1).

Lọc và chấm điểm các mẫu con Để chấm điểm và lọc các mẫu con c được tạo ra bởi πθ, chúng tôi sử dụng hàm đánh giá EVALT(c,D), huấn luyện mô hình được mã hóa bởi c trên tập dữ liệu D và trả về lỗi validation thấp nhất gặp phải trong quá trình huấn luyện. Tất cả các mô hình con được huấn luyện trong cùng số bước, với cùng các siêu tham số optimizer. Vì hàm fitness của chúng tôi có thể bị lợi dụng bằng cách tạo ra các mô hình nhỏ tùy ý, chúng tôi cũng thêm một ngưỡng lỗi validation α, là giới hạn trên của lỗi validation mà một mô hình có thể phát sinh mà không bị loại bỏ khỏi G, quần thể toàn cục. Chúng tôi gọi hàm này là FILTER ANDEVAL(C,T,D, α)(Thuật toán 3 và bước 7 của Thuật toán 1). Cuối cùng, chúng tôi thêm các mô hình có thể huấn luyện còn lại và các điểm fitness liên quan của chúng vào G(bước 8 của Thuật toán 1).

Chọn lọc dựa trên fitness Sau khi đánh giá tất cả các mô hình con trong vòng hiện tại, chúng tôi áp dụng chọn lọc dựa trên fitness để xác định các mô hình ứng viên hàng đầu cho lai ghép (bước 10 của Thuật toán 1). Chúng tôi ký hiệu điều này là GETTOP(G, p), đơn giản chỉ là chọn p mô hình có điểm fitness cao nhất từ G. Khi những mô hình này đã được chọn, chúng bị loại bỏ vĩnh viễn khỏi quần thể và không thể được sử dụng lại làm bố mẹ cho lai ghép.

Huấn luyện πθt Cuối cùng, tất cả các mô hình con được tạo ra trong vòng hiện tại mà không được chọn trước đó cho lai ghép (tức là CEVALED\P) được sử dụng để prompt-tune πθ cho vòng tiếp theo (bước 11 của Thuật toán 1).

4 Thí nghiệm và Kết quả
Chúng tôi đánh giá thuật toán meta-learning của mình trên hai tập dữ liệu – MNIST-1D (Greydanus, 2020) và benchmark lý luận thuật toán CLRS (Veli ˇckovi ´c et al., 2022). Trong khi benchmark trước đây nhẹ và cho phép chúng tôi thực hiện phân tích kỹ lưỡng hơn về thuật toán của mình, benchmark sau là một benchmark mới hơn bao gồm 30 thuật toán khác nhau với nhiều dư địa hơn để khám phá các kiến trúc mới có hiệu suất tốt hơn.

Trong tất cả các thí nghiệm của chúng tôi, πθ0 (tức là toán tử lai ghép) của chúng tôi là một mô hình PALM 62B tham số (Chowdhery et al., 2022) được pre-train trên 1.3T token của các tài liệu đối thoại, web, và mã. Nó được fine-tune thêm trên một corpus 64B token chứa các tệp mã nguồn Python được cấp phép hợp lệ gần như khử trùng lặp từ Github. Chúng tôi luôn lấy mẫu từ πθ0 với lấy mẫu nhiệt độ hỗn hợp, trong đó nhiệt độ lấy mẫu được chọn đều từ [0.2,0.6,0.8,1.0]. Giữa mỗi vòng, mô hình được prompt-tune (Lester et al., 2021) trong 5 epoch với độ dài soft prompt là 16, kích thước batch là 16, và tốc độ học là 0.1 (như được mô tả trong Mục 3.3 và Bước 11 của Thuật toán 1). Trừ khi được nêu khác, chúng tôi chạy 10 vòng tiến hóa với 10 prompt mỗi vòng và 16 mẫu được tạo ra cho mỗi prompt, mang lại tổng cộng 160 mô hình được tạo ra mỗi vòng và 1600 mô hình được tạo ra trong toàn bộ quá trình tìm kiếm. Các mô hình trùng lặp và mô hình không thể huấn luyện không được chấm điểm, nhưng vẫn được tính vào 1600. Tất cả các siêu tham số EVOPROMPTING khác được liệt kê trong Phụ lục A.1.

4.1 MNIST-1D
Tập dữ liệu Chúng tôi áp dụng phương pháp của mình đầu tiên cho MNIST-1D (Greydanus, 2020), một phiên bản một chiều, thu nhỏ của tập dữ liệu MNIST-1D chứa các ví dụ nhỏ hơn 20 lần so với tập dữ liệu MNIST gốc. Mỗi ví dụ chỉ có 40 chiều, với 4000 ví dụ trong tập dữ liệu huấn luyện và 1000 trong test. Vì không có tập dữ liệu validation, chúng tôi ngẫu nhiên tách ra 500 ví dụ từ tập dữ liệu huấn luyện để sử dụng làm tập dữ liệu validation. Mặc dù nhẹ hơn, MNIST-1D phân biệt tốt hơn giữa các loại kiến trúc khác nhau (Greydanus, 2020) so với đối tác lớn hơn MNIST (LeCun et al., 1998).

Thiết lập meta-learning Trong suốt quá trình tìm kiếm mô hình, chúng tôi sử dụng optimizer AdamW (Loshchilov & Hutter, 2019) để huấn luyện mỗi mô hình con trên một GPU NVIDIA Tesla P100 trong 8000 bước, với tốc độ học 0.01 và kích thước batch 128. Chúng tôi chấm điểm các mô hình con theo độ chính xác validation tốt nhất đạt được trong quá trình huấn luyện. Chúng tôi cũng khởi tạo việc tìm kiếm với 4 mô hình mẫu - 3 baseline neural được thiết kế thủ công từ bài báo MNIST-1D gốc (Greydanus, 2020) (GRU, CNN, và MLP) và một mô hình CNN lớn thứ tư do chúng tôi thiết kế. Tất cả bốn mô hình được triển khai với Flax (Heek et al., 2020). Chúng tôi chuyển người đọc đến Phụ lục A.2 cho mã nguồn của những mô hình mẫu này.

Baseline Chúng tôi so sánh EVOPROMPTING với các baseline sau:
•Naive few-shot prompting: Baseline này đơn giản tạo ra các mẫu mã c∼πθ0(·|p), trong đó p là prompt 2-shot được xây dựng bằng các ví dụ trong ngữ cảnh được chọn ngẫu nhiên từ các mô hình mẫu (Listing 1). Điều này về cơ bản là một ablation của các bước 7-12 trong Thuật toán 1 với T= 1. Chúng tôi tăng số lượng mẫu được tạo ra cho mỗi prompt cho baseline prompting naïve sao cho tổng số mẫu được tạo ra bởi πθ khớp với các baseline khác.

•EVOPROMPTING ( - prompt-tuning): Chúng tôi chạy toàn bộ thuật toán như hiện có, nhưng không có prompt-tuning giữa mỗi vòng. Đây là một ablation của bước 11 từ Thuật toán 1

•EVOPROMPTING (random parents): Thay vì chọn các mô hình phù hợp nhất từ vòng cuối làm bố mẹ cho vòng tiếp theo, chúng tôi chọn bố mẹ ngẫu nhiên. Đây là một ablation của Bước 10 trong Thuật toán 1, đó là bước GETTOP(G, p).

EVOPROMPTING tìm ra các mô hình nhỏ hơn và chính xác hơn Hình 2a cho thấy so sánh lỗi test và kích thước mô hình của 20 mô hình hàng đầu được khám phá bởi EVOPROMPTING so với những mô hình mẫu và ba baseline của chúng tôi. Các điểm xấp xỉ một biên Pareto, bên dưới đó mỗi thuật toán không thể cải thiện một chiều mà không làm tổn hại chiều kia. EVOPROMPTING sở hữu biên Pareto gần nhất với gốc tọa độ, chỉ ra rằng nó tìm ra các mô hình tối ưu hơn về mặt độ chính xác và kích thước. Thực tế, nhiều mô hình trong 20 mô hình được khám phá hàng đầu của EVOPROMPTING nhỏ hơn hàng bậc độ lớn so với những mô hình của các baseline khác, trong khi vẫn có lỗi test thấp hơn.

Chúng tôi cũng lưu ý rằng – trên nhiệm vụ này cụ thể – EVOPROMPTING xuất sắc đặc biệt trong việc tối ưu hóa các kiến trúc tích chập. Nhiều trong số 20 mô hình hàng đầu là các kiến trúc tích chập hẹp hơn và sâu hơn, với stride nhỏ hơn, ít padding hơn, và không có layer dense. Những mô hình này luôn hoạt động tốt hơn các kiến trúc tích chập nông hơn, dày đặc hơn, và rộng hơn được thấy trong các vòng đầu của quá trình tìm kiếm mô hình.

Một khía cạnh quan trọng khác của thuật toán meta-learning là mối quan hệ giữa số lượng cá thể được đánh giá và fitness tối đa quan sát được cho đến nay, tức là hiệu quả mẫu. Tìm kiếm kiến trúc mạng neural có thể là một quá trình đắt đỏ, với các tìm kiếm mở nhất yêu cầu đánh giá hàng nghìn tỷ cá thể (Real et al., 2020). Do đó, việc xác định các ứng viên phù hợp bằng càng ít mẫu càng tốt là rất quan trọng.

--- TRANG 8 ---
(a) Biên Pareto của kích thước mô hình so với lỗi test của 20 thí nghiệm hàng đầu cho mỗi biến thể của việc tìm kiếm mô hình MNIST1D. Các biên gần gốc tọa độ hơn được coi là mong muốn hơn.

(b) Số lượng mô hình con được tạo ra so với fitness tối đa trong mẫu, như được ước tính bằng 100 mẫu bootstrap kích thước 20 cho mỗi điểm dọc theo trục x.

Hình 2: EVOPROMPTING khám phá các kiến trúc nhỏ hơn và hoạt động tốt hơn trên MNIST-1D so với các phương pháp tìm kiếm thay thế.

Hình 3: Số lượng mô hình con được tạo ra so với fitness tối đa của mô hình hàng đầu đã thấy cho đến nay (như được ước tính bằng 100 mẫu bootstrap kích thước 20 cho mỗi điểm dọc theo trục x) khi tìm kiếm các mô hình mạng neural cho ba nhiệm vụ CLRS. Như đã đề cập trong Mục 4.2, những thuật toán này được chọn vì phân tích sơ bộ của chúng tôi chỉ ra rằng chúng có dư địa nhiều nhất cho các cải thiện kiến trúc.

Hình 2b so sánh cách fitness của mô hình con hoạt động tốt nhất cải thiện như một hàm của số lượng mẫu con được tạo ra cho đến nay. Baseline bố mẹ ngẫu nhiên đạt cực đại nhanh nhất, đạt fitness tối đa vào thời điểm khoảng 200 cá thể đã được tạo ra. Hơn nữa, fitness tối đa mà nó đạt được kém đáng kể so với các thí nghiệm khác. Mặt khác, EVOPROMPTING không có prompt-tuning và EVOPROMPTING bình thường không đạt cực đại cho đến khi muộn hơn nhiều. Cực đại của EVOPROMPTING cao nhất và do đó phù hợp hơn trung bình so với các cá thể được khám phá bởi bất kỳ thí nghiệm nào khác.

Cũng rõ ràng từ cả Hình 2a và 2b rằng hiệu suất giảm khi bất kỳ thành phần riêng lẻ nào bị loại bỏ. Thú vị là, Hình 2a chỉ ra rằng prompting với bố mẹ được chọn ngẫu nhiên kết hợp với prompt-tuning không hiệu quả hơn prompting naïve một mình. Điều này làm nổi bật tầm quan trọng của việc chọn các ví dụ trong ngữ cảnh hữu ích, đặc biệt trong một nhiệm vụ mà chúng ta giả định có ít tín hiệu huấn luyện tồn tại trong dữ liệu pre-training. Tuy nhiên, việc chọn các mô hình phù hợp hơn làm ví dụ trong ngữ cảnh mà không có prompt-tuning cũng không hoạt động gần bằng phương pháp đầy đủ của chúng tôi.

Quỹ đạo qua các vòng meta-learning Chúng tôi cũng khám phá quỹ đạo của thuật toán meta-learning qua từng vòng, như được hiển thị trong Phụ lục A.3. Nói chung, chúng tôi quan sát thấy rằng EVOPROMPTING bắt đầu xa hơn khỏi gốc tọa độ (trong vòng 0) và kết thúc gần gốc tọa độ nhất trong vòng 10, điều này có nghĩa là nó khám phá – trung bình – các mô hình nhỏ nhất và chính xác nhất trong vòng cuối. Tuy nhiên, việc tìm kiếm không phải lúc nào cũng mang lại cải thiện trên cả hai trục giữa các vòng liên tiếp. Trong các vòng 0-2 và 6-10, EVOPROMPTING cải thiện lỗi test trong khi đánh đổi kích thước mô hình. Mặt khác, cả hai chiều đều được cải thiện đồng thời trong các vòng 3-5.

--- TRANG 9 ---
4.2 CLRS
Mặc dù nhiệm vụ MNIST-1D cung cấp một môi trường hiệu quả và thực tế để đánh giá thuật toán meta-learning, các kiến trúc CNN đã hoạt động khá tốt trên nhiệm vụ này và các kiến trúc neural cho phân loại hình ảnh đã được nghiên cứu rộng rãi nói chung. Cũng tồn tại khả năng LM của chúng tôi đã thấy nhiều kiến trúc tích chập trong dữ liệu pre-training của nó. Thay vào đó, chúng tôi chuyển sang một nhiệm vụ học tập khác và lớp kiến trúc mạng neural khác để đánh giá xem framework meta-learning của chúng tôi có tổng quát hóa cho các nhiệm vụ, tập dữ liệu, và kiến trúc neural khác không.

Tập dữ liệu Benchmark lý luận thuật toán CLRS (Veli ˇckovi ´c et al., 2022) đánh giá khả năng của các mạng neural học lý luận thuật toán trên một tập hợp 30 thuật toán cổ điển được đề cập trong sách giáo khoa Introduction to Algorithms của Cormen, Leiserson, Rivest và Stein (Cormen et al., 2009). Benchmark này hữu ích không chỉ như một nhiệm vụ lý luận logic khó khăn cho các mạng neural, mà còn như một thước đo về sự căn chỉnh thuật toán của mạng neural (Xu et al., 2020). Nói ngắn gọn, căn chỉnh thuật toán đề cập đến khả năng của một mô hình lý luận như một thuật toán (tức là sử dụng đồ thị tính toán cho một nhiệm vụ), thay vì dựa vào ghi nhớ hoặc các chiến lược học ít hiệu quả mẫu khác. Mặc dù một mô hình có thể xấp xỉ một thuật toán bằng cách khớp mẫu với các đầu vào tương tự hoặc dựa vào các lối tắt khác, nó không thể tổng quát hóa cho các đầu vào dài tùy ý hoặc các trường hợp biên mà không học đồ thị tính toán cơ bản của thuật toán.

Theo đó, benchmark CLRS biểu diễn các đầu vào và đầu ra của thuật toán như đồ thị, và các bước của thuật toán như một quỹ đạo các phép toán trên đồ thị đầu vào. Thiết lập vấn đề này có thể được xử lý một cách đơn giản bằng các mạng neural đồ thị, điều được khám phá trong Ibarz et al. (2022). Họ thấy rằng một mô hình Triplet-GMPNN (một mạng neural truyền thông điệp (Gilmer et al., 2017) với gating và xử lý cạnh triplet) thể hiện hiệu suất tốt nhất khi được huấn luyện và đánh giá trên tất cả 30 thuật toán cùng một lúc.

Bảng 1: So sánh độ chính xác OOD và kích thước mô hình (theo số lượng tham số) của các mô hình mới được khám phá bởi EVOPROMPTING trên các nhiệm vụ CLRS được chọn nơi EVOPROMPTING đã khám phá các kiến trúc chính xác hơn mà không tăng lớn kích thước mô hình, so với mô hình baseline (Triplet-GMPNN từ Ibarz et al. (2022)). Các số độ chính xác OOD cho mô hình baseline là từ Ibarz et al. (2022). Để xem bảng đầy đủ kết quả trên tất cả nhiệm vụ CLRS, bao gồm độ chính xác của việc triển khai Triplet-GMPNN của chúng tôi, xem Phụ lục 3.

Nhiệm vụ CLRS | Mô hình Hoạt động Tốt Nhất | Kích thước Mô hình ↓ | Độ chính xác OOD ↑
---|---|---|---
 | Của chúng tôi | Baseline | Của chúng tôi | Baseline
Articulation Points | QUADNODEMINMAX | 497969 | 531913 | 93.5±1.8% | 88.3±2.0%
BFS | MAXMEAN | 522931 | 523963 | 100.0±0.0% | 99.7±0.0%
Bubble Sort | CONCAT REP | 568533 | 524477 | 88.9±2.8% | 67.7±5.5%
DFS | DIV2MEAN | 660158 | 661190 | 68.1±1.4% | 47.8±4.2%
Floyd Warshall | CONCAT REP | 669145 | 625089 | 61.4±0.8% | 48.5±1.0%
Heapsort | CONCAT REP | 703710 | 659654 | 69.9±4.2% | 31.0±5.8%
Insertion Sort | DIV2MEAN | 523445 | 524477 | 89.5±2.6% | 78.1±4.6%
Quicksort | DIV2MEAN | 524727 | 525759 | 85.2±4.3% | 64.6±5.1%
Task Scheduling | TANH EXPAND TRIPLETS | 262333 | 262333 | 88.2±0.4% | 87.3±0.4%

Thiết lập meta-learning Tương tự như thiết lập MNIST-1D của chúng tôi, chúng tôi sử dụng optimizer AdamW để huấn luyện mỗi mô hình con trên một GPU NVIDIA Tesla P100. Tuy nhiên, vì hầu hết các mô hình con được khám phá lớn hơn nhiều so với các mô hình MNIST-1D, chúng tôi chỉ huấn luyện mỗi mô hình con trong 2000 bước. Theo kinh nghiệm, chúng tôi quan sát thấy rằng hiệu suất của các mô hình khác nhau thường phân kỳ vào 2000 bước, điều này cung cấp đủ tín hiệu cho quá trình tìm kiếm mô hình. Chúng tôi tuân theo các siêu tham số cho huấn luyện đơn nhiệm vụ trong Ibarz et al. (2022) và đánh giá các mô hình bằng độ chính xác validation.

Không giống như thiết lập MNIST-1D của chúng tôi, chúng tôi chỉ tìm kiếm trên các biểu diễn triplet của một mô hình Triplet-GMPNN (xem Ibarz et al. (2022) để biết thêm chi tiết), thay vì toàn bộ bộ xử lý đồ thị. Chúng tôi cũng khởi tạo việc tìm kiếm với chín mô hình mẫu khác nhau - mỗi mô hình là một biến thể của mô hình Triplet-GMPNN với một biểu diễn triplet khác nhau. Mỗi biểu diễn triplet mẫu kết hợp một điều chỉnh nhỏ của một thành phần duy nhất của biểu diễn triplet gốc được thiết kế bởi Ibarz et al. (2022). Những điều chỉnh này bao gồm một lớp đầu ra fully-connected, một aggregation tổng, các biểu diễn node/edge/graph fully-connected, một biểu diễn triplet tuyến tính đơn giản, và một biểu diễn bilinear (Mnih & Hinton, 2007). Tất cả chín mô hình được triển khai với Haiku (Hennigan et al., 2020), một thư viện mạng neural hướng đối tượng cho Jax (xem Phụ lục A.5 cho mã nguồn của các mô hình mẫu.)

Tổng quát hóa ngoài các mô hình phân loại hình ảnh Chúng tôi tìm kiếm bằng EVOPROMPTING trên 3 thuật toán riêng lẻ trong benchmark CLRS – các thuật toán articulation points, Graham scan, và Kruskal's minimum spanning tree. Chúng tôi chọn những thuật toán này vì phân tích sơ bộ của chúng tôi với các kiến trúc được thiết kế thủ công cho thấy chúng có dư địa nhiều nhất cho cải thiện, mặc dù chúng tôi thấy rằng các kiến trúc được khám phá cũng chuyển giao tốt cho các nhiệm vụ benchmark CLRS khác (Phụ lục 3). Kết quả tìm kiếm của chúng tôi được hiển thị trong Hình 3. EVOPROMPTING tiếp tục tìm ra các mô hình "phù hợp" hơn so với hai baseline khác của chúng tôi, mặc dù chúng tôi quan sát thấy rằng kết quả cũng cho thấy biến động nhiều hơn so với kết quả của chúng tôi cho MNIST-1D.

Phân tích các mô hình mới được khám phá Việc tìm kiếm của chúng tôi trên các biểu diễn triplet mang lại một số thiết kế mới mà chúng tôi tìm cách đánh giá trên tất cả các thuật toán trong benchmark CLRS. Mặc dù những mô hình mới này được khám phá trong việc tìm kiếm mô hình trên các thuật toán đơn lẻ, chúng thường tổng quát hóa cho các thuật toán khác không được thấy trong quá trình tìm kiếm mô hình. Hình 5 hiển thị quỹ đạo của độ chính xác validation trong quá trình huấn luyện và Bảng 1 cung cấp độ chính xác OOD cho những mô hình này trên một số thuật toán được chọn. (Chúng tôi hoãn người đọc đến Phụ lục A.4 cho mã nguồn đầy đủ của mỗi mô hình mới được khám phá và Bảng A.6 cho danh sách đầy đủ độ chính xác OOD cho mọi thuật toán trong benchmark CLRS.)

Chúng tôi lưu ý rằng việc tìm kiếm mô hình đề xuất một số thay đổi đơn giản nhưng hiệu quả. Ví dụ, thay vì lấy maximum của biểu diễn triplet, mô hình QUADNODEMINMAX sử dụng biểu diễn quadruplet node thay vì triplet, và nó trừ minimum của biểu diễn quad khỏi max thay vì. CONCAT REP biểu diễn các biểu diễn node, edge, và graph như một concatenation của một lớp feedforward projection, và MAXMEAN lấy maximum của các biểu diễn triplet trước khi lấy mean và truyền qua lớp dense đầu ra. DIV2MEAN chia tỷ lệ mỗi biểu diễn node bằng 1/2 và sử dụng aggregation mean của các biểu diễn triplet thay vì aggregation max. TANHEXPAND TRIPLETS áp dụng mở rộng chiều bổ sung cho các biểu diễn triplet và áp dụng hàm hyperbolic tangent sau aggregation max. Xem Phụ lục A.4 cho mã đầy đủ của mỗi mô hình được khám phá.

Trong số 5 mô hình mới được khám phá mà chúng tôi chọn để phân tích, CONCAT REP là mô hình duy nhất tăng kích thước mô hình. Tuy nhiên, như được hiển thị trong Bảng 1, CONCAT REP thường mang lại cải thiện độ chính xác OOD vượt xa phần trăm tăng kích thước mô hình. Ví dụ, trên thuật toán heapsort, CONCAT REP tăng độ chính xác OOD 125.19% trong khi chỉ tăng kích thước mô hình 6.68% so với baseline. Bốn mô hình mới được khám phá khác được hiển thị trong Bảng 1 đồng thời cải thiện độ chính xác OOD trong khi giảm kích thước mô hình trên các thuật toán articulation points, BFS, DFS, insertion sort, quicksort, và task scheduling. Trên phần còn lại của các thuật toán CLRS (Bảng A.6), các mô hình mới được khám phá của chúng tôi thường đạt được độ chính xác OOD tương đương hoặc tốt hơn baseline, trong khi duy trì kích thước mô hình tương tự.

5 Kết luận
Chúng tôi đã chỉ ra rằng việc nhúng một LM được pre-train trong một thuật toán tiến hóa cải thiện đáng kể hiệu suất của LM trong nhiệm vụ thiết kế kiến trúc mạng neural. Phương pháp của chúng tôi đã chứng minh thành công không chỉ trong việc tối ưu hóa các kiến trúc tích chập cho nhiệm vụ MNIST-1D, mà còn trong việc phát triển các loại GNN mới cho benchmark thuật toán CLRS. Điều này chứng minh: 1) việc sử dụng các kỹ thuật tiến hóa có thể cải thiện đáng kể khả năng trong ngữ cảnh của các LM được pre-train, và 2) EVOPROMPTING có thể khám phá các kiến trúc mới và tốt nhất hiện tại tối ưu hóa cho cả độ chính xác và kích thước mô hình. Hơn nữa, EVOPROMPTING đủ tổng quát để có thể dễ dàng thích ứng để tìm kiếm giải pháp cho các loại nhiệm vụ lý luận khác ngoài NAS. Chúng tôi để việc thích ứng EVOPROMPTING cho các nhiệm vụ khác cho nghiên cứu tương lai.

Tuy nhiên, nghiên cứu của chúng tôi bị hạn chế bởi việc thiếu so sánh rộng rãi với các kỹ thuật NAS tiêu chuẩn khác vì EVOPROMPTING được thiết kế cho tìm kiếm mở, trong khi các kỹ thuật khác thì không, điều này sẽ đưa vào một yếu tố gây nhiễu tiềm tàng. Chúng tôi bao gồm một so sánh như vậy trên NATS-Bench trong Phụ lục A.7, cũng như thảo luận về các yếu tố gây nhiễu đó.

--- TRANG 11 ---
6 Lời cảm ơn
Chúng tôi cảm ơn Maarten Bosma, Kefan Xiao, Yifeng Lu, Quoc Le, Ed Chi, Borja Ibarz, Petar Veli ˇckovi ´c, Chen Liang, Charles Sutton, và nhóm Google Brain AutoML vì đã cung cấp các cuộc thảo luận và phản hồi có giá trị đã ảnh hưởng đến hướng của dự án này. Chúng tôi cũng cảm ơn chương trình Google Student Researcher vì đã cung cấp các tài nguyên và cơ hội cần thiết để dự án này diễn ra.

Tài liệu tham khảo
Ahmad, W. U., Chakraborty, S., Ray, B., and Chang, K.-W. Unified pre-training for program understanding and generation. ArXiv , abs/2103.06333, 2021.

Bender, G., Liu, H., Chen, B., Chu, G., Cheng, S., Kindermans, P.-J., and Le, Q. V . Can weight sharing outperform random architecture search? an investigation with tunas. 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , pp. 14311–14320, 2020.

BigScience Workshop, :, Scao, T. L., Fan, A., Akiki, C., Pavlick, E., Ili ´c, S., Hesslow, D., Castagné, R., Luccioni, A. S., Yvon, F., Gallé, M., Tow, J., Rush, A. M., Biderman, S., Webson, A., Ammanamanchi, P. S., Wang, T., Sagot, B., Muennighoff, N., del Moral, A. V ., Ruwase, O., Bawden, R., Bekman, S., McMillan-Major, A., Beltagy, I., Nguyen, H., Saulnier, L., Tan, S., Suarez, P. O., Sanh, V ., Laurençon, H., Jernite, Y ., Launay, J., Mitchell, M., Raffel, C., Gokaslan, A., Simhi, A., Soroa, A., Aji, A. F., Alfassy, A., Rogers, A., Nitzav, A. K., Xu, C., Mou, C., Emezue, C., Klamm, C., Leong, C., van Strien, D., Adelani, D. I., Radev, D., Ponferrada, E. G., Levkovizh, E., Kim, E., Natan, E. B., De Toni, F., Dupont, G., Kruszewski, G., Pistilli, G., Elsahar, H., Benyamina, H., Tran, H., Yu, I., Abdulmumin, I., Johnson, I., Gonzalez-Dios, I., de la Rosa, J., Chim, J., Dodge, J., Zhu, J., Chang, J., Frohberg, J., Tobing, J., Bhattacharjee, J., Almubarak, K., Chen, K., Lo, K., V on Werra, L., Weber, L., Phan, L., allal, L. B., Tanguy, L., Dey, M., Muñoz, M. R., Masoud, M., Grandury, M., Šaško, M., Huang, M., Coavoux, M., Singh, M., Jiang, M. T.-J., Vu, M. C., Jauhar, M. A., Ghaleb, M., Subramani, N., Kassner, N., Khamis, N., Nguyen, O., Espejel, O., de Gibert, O., Villegas, P., Henderson, P., Colombo, P., Amuok, P., Lhoest, Q., Harliman, R., Bommasani, R., López, R. L., Ribeiro, R., Osei, S., Pyysalo, S., Nagel, S., Bose, S., Muhammad, S. H., Sharma, S., Longpre, S., Nikpoor, S., Silberberg, S., Pai, S., Zink, S., Torrent, T. T., Schick, T., Thrush, T., Danchev, V ., Nikoulina, V ., Laippala, V ., Lepercq, V ., Prabhu, V ., Alyafeai, Z., Talat, Z., Raja, A., Heinzerling, B., Si, C., Ta¸ sar, D. E., Salesky, E., Mielke, S. J., Lee, W. Y ., Sharma, A., Santilli, A., Chaffin, A., Stiegler, A., Datta, D., Szczechla, E., Chhablani, G., Wang, H., Pandey, H., Strobelt, H., Fries, J. A., Rozen, J., Gao, L., Sutawika, L., Bari, M. S., Al-shaibani, M. S., Manica, M., Nayak, N., Teehan, R., Albanie, S., Shen, S., Ben-David, S., Bach, S. H., Kim, T., Bers, T., Fevry, T., Neeraj, T., Thakker, U., Raunak, V ., Tang, X., Yong, Z.-X., Sun, Z., Brody, S., Uri, Y ., Tojarieh, H., Roberts, A., Chung, H. W., Tae, J., Phang, J., Press, O., Li, C., Narayanan, D., Bourfoune, H., Casper, J., Rasley, J., Ryabinin, M., Mishra, M., Zhang, M., Shoeybi, M., Peyrounette, M., Patry, N., Tazi, N., Sanseviero, O., von Platen, P., Cornette, P., Lavallée, P. F., Lacroix, R., Rajbhandari, S., Gandhi, S., Smith, S., Requena, S., Patil, S., Dettmers, T., Baruwa, A., Singh, A., Cheveleva, A., Ligozat, A.-L., Subramonian, A., Névéol, A., Lovering, C., Garrette, D., Tunuguntla, D., Reiter, E., Taktasheva, E., V oloshina, E., Bogdanov, E., Winata, G. I., Schoelkopf, H., Kalo, J.-C., Novikova, J., Forde, J. Z., Clive, J., Kasai, J., Kawamura, K., Hazan, L., Carpuat, M., Clinciu, M., Kim, N., Cheng, N., Serikov, O., Antverg, O., van der Wal, O., Zhang, R., Zhang, R., Gehrmann, S., Mirkin, S., Pais, S., Shavrina, T., Scialom, T., Yun, T., Limisiewicz, T., Rieser, V ., Protasov, V ., Mikhailov, V ., Pruksachatkun, Y ., Belinkov, Y ., Bamberger, Z., Kasner, Z., Rueda, A., Pestana, A., Feizpour, A., Khan, A., Faranak, A., Santos, A., Hevia, A., Unldreaj, A., Aghagol, A., Abdollahi, A., Tammour, A., HajiHosseini, A., Behroozi, B., Ajibade, B., Saxena, B., Ferrandis, C. M., Contractor, D., Lansky, D., David, D., Kiela, D., Nguyen, D. A., Tan, E., Baylor, E., Ozoani, E., Mirza, F., Ononiwu, F., Rezanejad, H., Jones, H., Bhattacharya, I., Solaiman, I., Sedenko, I., Nejadgholi, I., Passmore, J., Seltzer, J., Sanz, J. B., Dutra, L., Samagaio, M., Elbadri, M., Mieskes, M., Gerchick, M., Akinlolu, M., McKenna, M., Qiu, M., Ghauri, M., Burynok, M., Abrar, N., Rajani, N., Elkott, N., Fahmy, N., Samuel, O., An, R., Kromann, R., Hao, R., Alizadeh, S., Shubber, S., Wang, S., Roy, S., Viguier, S., Le, T., Oyebade, T., Le, T., Yang, Y ., Nguyen, Z., Kashyap, A. R., Palasciano, A., Callahan, A., Shukla, A., Miranda-Escalada, A., Singh, A., Beilharz, B., Wang, B., Brito, C., Zhou, C., Jain, C., Xu, C., Fourrier, C., Periñán, D. L., Molano, D., Yu, D., Manjavacas, E., Barth, F., Fuhrimann, F., Altay, G., Bayrak, G., Burns, G., Vrabec, H. U., Bello, I., Dash, I., Kang, J., Giorgi, J., Golde, J., Posada, J. D., Sivaraman, K. R., Bulchandani, L., Liu, L., Shinzato, L., de Bykhovetz, M. H., Takeuchi, M., Pàmies, M., Castillo, M. A., Nezhurina, M., Sänger, M., Samwald, M., Cullan, M., Weinberg, M., De Wolf, M., Mihaljcic, M., Liu, M., Freidank, M., Kang, M., Seelam, N., Dahlberg, N., Broad, N. M., Muellner, N., Fung, P., Haller, P., Chandrasekhar, R., Eisenberg, R., Martin, R., Canalli, R., Su, R., Su, R., Cahyawijaya, S., Garda, S., Deshmukh, S. S., Mishra, S., Kiblawi, S., Ott, S., Sang-aroonsiri, S., Kumar, S., Schweter, S., Bharati, S., Laud, T., Gigant, T., Kainuma, T., Kusa, W., Labrak, Y ., Bajaj, Y . S., Venkatraman, Y ., Xu, Y ., Xu, Y ., Xu, Y ., Tan, Z., Xie, Z., Ye, Z., Bras, M., Belkada, Y ., and Wolf, T. Bloom: A 176b-parameter open-access multilingual language model, 2022. URL https://arxiv.org/abs/2211.05100 .

Brooks, E., Walls, L., Lewis, R. L., and Singh, S. In-context policy iteration, 2022. URL https: //arxiv.org/abs/2210.03821 .

Brown, T. B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., Agarwal, S., Herbert-V oss, A., Krueger, G., Henighan, T., Child, R., Ramesh, A., Ziegler, D. M., Wu, J., Winter, C., Hesse, C., Chen, M., Sigler, E., Litwin, M., Gray, S., Chess, B., Clark, J., Berner, C., McCandlish, S., Radford, A., Sutskever, I., and Amodei, D. Language models are few-shot learners, 2020. URL https://arxiv.org/abs/2005.14165 .

Chen, M., Tworek, J., Jun, H., Yuan, Q., Ponde, H., Kaplan, J., Edwards, H., Burda, Y ., Joseph, N., Brockman, G., Ray, A., Puri, R., Krueger, G., Petrov, M., Khlaaf, H., Sastry, G., Mishkin, P., Chan, B., Gray, S., Ryder, N., Pavlov, M., Power, A., Kaiser, L., Bavarian, M., Winter, C., Tillet, P., Such, F. P., Cummings, D. W., Plappert, M., Chantzis, F., Barnes, E., Herbert-V oss, A., Guss, W. H., Nichol, A., Babuschkin, I., Balaji, S. A., Jain, S., Carr, A., Leike, J., Achiam, J., Misra, V ., Morikawa, E., Radford, A., Knight, M. M., Brundage, M., Murati, M., Mayer, K., Welinder, P., McGrew, B., Amodei, D., McCandlish, S., Sutskever, I., and Zaremba, W. Evaluating large language models trained on code. ArXiv , abs/2107.03374, 2021.

Chowdhery, A., Narang, S., Devlin, J., Bosma, M., Mishra, G., Roberts, A., Barham, P., Chung, H. W., Sutton, C., Gehrmann, S., Schuh, P., Shi, K., Tsvyashchenko, S., Maynez, J., Rao, A., Barnes, P., Tay, Y ., Shazeer, N., Prabhakaran, V ., Reif, E., Du, N., Hutchinson, B., Pope, R., Bradbury, J., Austin, J., Isard, M., Gur-Ari, G., Yin, P., Duke, T., Levskaya, A., Ghemawat, S., Dev, S., Michalewski, H., Garcia, X., Misra, V ., Robinson, K., Fedus, L., Zhou, D., Ippolito, D., Luan, D., Lim, H., Zoph, B., Spiridonov, A., Sepassi, R., Dohan, D., Agrawal, S., Omernick, M., Dai, A. M., Pillai, T. S., Pellat, M., Lewkowycz, A., Moreira, E., Child, R., Polozov, O., Lee, K., Zhou, Z., Wang, X., Saeta, B., Diaz, M., Firat, O., Catasta, M., Wei, J., Meier-Hellstern, K., Eck, D., Dean, J., Petrov, S., and Fiedel, N. Palm: Scaling language modeling with pathways, 2022. URL https://arxiv.org/abs/2204.02311 .

Cormen, T. H., Leiserson, C. E., Rivest, R. L., and Stein, C. Introduction to Algorithms, Third Edition . The MIT Press, 3rd edition, 2009. ISBN 0262033844.

Dakhel, A. M., Majdinasab, V ., Nikanjam, A., Khomh, F., Desmarais, M. C., and Jiang, Z. M. Github copilot ai pair programmer: Asset or liability? ArXiv , abs/2206.15331, 2022.

Dohan, D., Xu, W., Lewkowycz, A., Austin, J., Bieber, D., Lopes, R. G., Wu, Y ., Michalewski, H., Saurous, R. A., Sohl-dickstein, J., Murphy, K., and Sutton, C. Language model cascades, 2022. URL https://arxiv.org/abs/2207.10342 .

Dong, X., Liu, L., Musial, K., and Gabrys, B. NATS-Bench: Benchmarking nas algorithms for architecture topology and size. IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI) , 2021. doi: 10.1109/TPAMI.2021.3054824. doi: 10.1109/TPAMI.2021.3054824 .

Du, N., Huang, Y ., Dai, A. M., Tong, S., Lepikhin, D., Xu, Y ., Krikun, M., Zhou, Y ., Yu, A. W., Firat, O., Zoph, B., Fedus, L., Bosma, M., Zhou, Z., Wang, T., Wang, Y . E., Webster, K., Pellat, M., Robinson, K., Meier-Hellstern, K., Duke, T., Dixon, L., Zhang, K., Le, Q. V ., Wu, Y ., Chen, Z., and Cui, C. Glam: Efficient scaling of language models with mixture-of-experts, 2021. URL https://arxiv.org/abs/2112.06905 .

Elsken, T., Metzen, J. H., and Hutter, F. Efficient multi-objective neural architecture search via lamarckian evolution. arXiv: Machine Learning , 2018.

--- TRANG 12 ---
Feng, Z., Guo, D., Tang, D., Duan, N., Feng, X., Gong, M., Shou, L., Qin, B., Liu, T., Jiang, D., and Zhou, M. Codebert: A pre-trained model for programming and natural languages. ArXiv , abs/2002.08155, 2020.

Gilmer, J., Schoenholz, S. S., Riley, P. F., Vinyals, O., and Dahl, G. E. Neural message passing for quantum chemistry. In Proceedings of the 34th International Conference on Machine Learning - Volume 70 , ICML'17, pp. 1263–1272. JMLR.org, 2017.

Greydanus, S. Scaling *down* deep learning. CoRR , abs/2011.14439, 2020. URL https://arxiv. org/abs/2011.14439 .

Heek, J., Levskaya, A., Oliver, A., Ritter, M., Rondepierre, B., Steiner, A., and van Zee, M. Flax: A neural network library and ecosystem for JAX, 2020. URL http://github.com/google/flax .

Hennigan, T., Cai, T., Norman, T., and Babuschkin, I. Haiku: Sonnet for JAX, 2020. URL http://github.com/deepmind/dm-haiku .

Ibarz, B., Kurin, V ., Papamakarios, G., Nikiforou, K., Bennani, M. A., Csordás, R., Dudzik, A., Bovsnjak, M., Vitvitskyi, A., Rubanova, Y ., Deac, A., Bevilacqua, B., Ganin, Y ., Blundell, C., and Veliˇckovi ´c, P. A generalist neural algorithmic learner. ArXiv , abs/2209.11142, 2022.

Kojima, T., Gu, S. S., Reid, M., Matsuo, Y ., and Iwasawa, Y . Large language models are zero-shot reasoners. ArXiv , abs/2205.11916, 2022.

LeCun, Y ., Bottou, L., Bengio, Y ., and Haffner, P. Gradient-based learning applied to document recognition. Proc. IEEE , 86:2278–2324, 1998.

Lehman, J., Gordon, J., Jain, S., Ndousse, K., Yeh, C., and Stanley, K. O. Evolution through large models. ArXiv , abs/2206.08896, 2022.

Lester, B., Al-Rfou, R., and Constant, N. The power of scale for parameter-efficient prompt tuning, 2021. URL https://arxiv.org/abs/2104.08691 .

Li, L. and Talwalkar, A. S. Random search and reproducibility for neural architecture search. ArXiv , abs/1902.07638, 2019.

Liu, H., Brock, A., Simonyan, K., and Le, Q. V . Evolving normalization-activation layers. ArXiv , abs/2004.02967, 2020.

Liu, J., Shen, D., Zhang, Y ., Dolan, B., Carin, L., and Chen, W. What makes good in-context examples for gpt-3? In Workshop on Knowledge Extraction and Integration for Deep Learning Architectures; Deep Learning Inside Out , 2021.

Loshchilov, I. and Hutter, F. Decoupled weight decay regularization. In International Conference on Learning Representations , 2019. URL https://openreview.net/forum?id=Bkg6RiCqY7 .

Lu, Y ., Bartolo, M., Moore, A., Riedel, S., and Stenetorp, P. Fantastically ordered prompts and where to find them: Overcoming few-shot prompt order sensitivity. In Annual Meeting of the Association for Computational Linguistics , 2021.

Meyerson, E., Nelson, M. J., Bradley, H., Moradi, A., Hoover, A. K., and Lehman, J. Language model crossover: Variation through few-shot prompting, 2023. URL https://arxiv.org/abs/ 2302.12170 .

Min, S., Lyu, X., Holtzman, A., Artetxe, M., Lewis, M., Hajishirzi, H., and Zettlemoyer, L. Rethinking the role of demonstrations: What makes in-context learning work? ArXiv , abs/2202.12837, 2022.

Mnih, A. and Hinton, G. Three new graphical models for statistical language modelling. In Proceedings of the 24th International Conference on Machine Learning , ICML '07, pp. 641–648, New York, NY , USA, 2007. Association for Computing Machinery. ISBN 9781595937933. doi: 10.1145/1273496.1273577. URL https://doi.org/10.1145/1273496.1273577 .

Noorbakhsh, K., Sulaiman, M., Sharifi, M., Roy, K., and Jamshidi, P. Pretrained language models are symbolic mathematics solvers too! ArXiv , abs/2110.03501, 2021.

--- TRANG 13 ---
Odena, A., Sutton, C., Dohan, D. M., Jiang, E., Michalewski, H., Austin, J., Bosma, M. P., Nye, M., Terry, M., and Le, Q. V . Program synthesis with large language models. In n/a, pp. n/a, n/a, 2021. n/a.

Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C. L., Mishkin, P., Zhang, C., Agarwal, S., Slama, K., Ray, A., Schulman, J., Hilton, J., Kelton, F., Miller, L. E., Simens, M., Askell, A., Welinder, P., Christiano, P. F., Leike, J., and Lowe, R. J. Training language models to follow instructions with human feedback. ArXiv , abs/2203.02155, 2022.

Qian, J., Wang, H., Li, Z., LI, S., and Yan, X. Limitations of language models in arithmetic and symbolic induction. ArXiv , abs/2208.05051, 2022.

Real, E., Moore, S., Selle, A., Saxena, S., Suematsu, Y . L., Tan, J., Le, Q. V ., and Kurakin, A. Large-scale evolution of image classifiers. ArXiv , abs/1703.01041, 2017.

Real, E., Aggarwal, A., Huang, Y ., and Le, Q. V . Regularized evolution for image classifier architecture search. In AAAI Conference on Artificial Intelligence , 2018.

Real, E., Liang, C., So, D. R., and Le, Q. V . Automl-zero: Evolving machine learning algorithms from scratch. In International Conference on Machine Learning , 2020.

Rubin, O., Herzig, J., and Berant, J. Learning to retrieve prompts for in-context learning. ArXiv , abs/2112.08633, 2021.

Sanh, V ., Webson, A., Raffel, C., Bach, S. H., Sutawika, L., Alyafeai, Z., Chaffin, A., Stiegler, A., Scao, T. L., Raja, A., Dey, M., Bari, M. S., Xu, C., Thakker, U., Sharma, S., Szczechla, E., Kim, T., Chhablani, G., Nayak, N. V ., Datta, D., Chang, J., Jiang, M. T.-J., Wang, H., Manica, M., Shen, S., Yong, Z. X., Pandey, H., Bawden, R., Wang, T., Neeraj, T., Rozen, J., Sharma, A., Santilli, A., Févry, T., Fries, J. A., Teehan, R., Biderman, S. R., Gao, L., Bers, T., Wolf, T., and Rush, A. M. Multitask prompted training enables zero-shot task generalization. ArXiv , abs/2110.08207, 2021.

Sciuto, C., Yu, K., Jaggi, M., Musat, C. C., and Salzmann, M. Evaluating the search phase of neural architecture search. ArXiv , abs/1902.08142, 2019.

So, D. R., Liang, C., and Le, Q. V . The evolved transformer. ArXiv , abs/1901.11117, 2019.

So, D. R., Ma ´nke, W., Liu, H., Dai, Z., Shazeer, N., and Le, Q. V . Primer: Searching for efficient transformers for language modeling, 2021. URL https://arxiv.org/abs/2109.08668 .

Thoppilan, R., De Freitas, D., Hall, J., Shazeer, N., Kulshreshtha, A., Cheng, H.-T., Jin, A., Bos, T., Baker, L., Du, Y ., Li, Y ., Lee, H., Zheng, H. S., Ghafouri, A., Menegali, M., Huang, Y ., Krikun, M., Lepikhin, D., Qin, J., Chen, D., Xu, Y ., Chen, Z., Roberts, A., Bosma, M., Zhao, V ., Zhou, Y ., Chang, C.-C., Krivokon, I., Rusch, W., Pickett, M., Srinivasan, P., Man, L., Meier-Hellstern, K., Morris, M. R., Doshi, T., Santos, R. D., Duke, T., Soraker, J., Zevenbergen, B., Prabhakaran, V ., Diaz, M., Hutchinson, B., Olson, K., Molina, A., Hoffman-John, E., Lee, J., Aroyo, L., Rajakumar, R., Butryna, A., Lamm, M., Kuzmina, V ., Fenton, J., Cohen, A., Bernstein, R., Kurzweil, R., Aguera-Arcas, B., Cui, C., Croak, M., Chi, E., and Le, Q. Lamda: Language models for dialog applications, 2022. URL https://arxiv.org/abs/2201.08239 .

Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, L., and Polosukhin, I. Attention is all you need, 2017. URL https://arxiv.org/abs/1706.03762 .

Veliˇckovi ´c, P., Badia, A. P., Budden, D., Pascanu, R., Banino, A., Dashevskiy, M., Hadsell, R., and Blundell, C. The clrs algorithmic reasoning benchmark. In International Conference on Machine Learning , 2022.

Wang, Y ., Wang, W., Joty, S. R., and Hoi, S. C. H. Codet5: Identifier-aware unified pre-trained encoder-decoder models for code understanding and generation. ArXiv , abs/2109.00859, 2021.

Wei, J., Bosma, M., Zhao, V ., Guu, K., Yu, A. W., Lester, B., Du, N., Dai, A. M., and Le, Q. V . Finetuned language models are zero-shot learners. ArXiv , abs/2109.01652, 2021.

Wei, J., Wang, X., Schuurmans, D., Bosma, M., hsin Chi, E. H., Le, Q., and Zhou, D. Chain of thought prompting elicits reasoning in large language models. ArXiv , abs/2201.11903, 2022.

--- TRANG 14 ---
Xu, F. F., Alon, U., Neubig, G., and Hellendoorn, V . J. A systematic evaluation of large language models of code. Proceedings of the 6th ACM SIGPLAN International Symposium on Machine Programming , 2022.

Xu, K., Li, J., Zhang, M., Du, S. S., ichi Kawarabayashi, K., and Jegelka, S. What can neural networks reason about? In International Conference on Learning Representations , 2020. URL https://openreview.net/forum?id=rJxbJeHFPS .

Yao, X. Evolving artificial neural networks. Proc. IEEE , 87:1423–1447, 1999.

Zhang, S., Roller, S., Goyal, N., Artetxe, M., Chen, M., Chen, S., Dewan, C., Diab, M., Li, X., Lin, X. V ., Mihaylov, T., Ott, M., Shleifer, S., Shuster, K., Simig, D., Koura, P. S., Sridhar, A., Wang, T., and Zettlemoyer, L. Opt: Open pre-trained transformer language models, 2022. URL https://arxiv.org/abs/2205.01068 .

Zhao, T., Wallace, E., Feng, S., Klein, D., and Singh, S. Calibrate before use: Improving few-shot performance of language models. ArXiv , abs/2102.09690, 2021.

Zhou, Y ., Muresanu, A. I., Han, Z., Paster, K., Pitis, S., Chan, H., and Ba, J. Large language models are human-level prompt engineers. ArXiv , abs/2211.01910, 2022.

--- TRANG 15 ---
A Phụ lục
A.1 Siêu tham số EVOPROMPTING
Bảng 2: Giá trị các siêu tham số được sử dụng trong EVOPROMPT.
SIÊU THAM SỐ | MÔ TẢ | GIÁ TRỊ
---|---|---
p | Số bố mẹ chọn trong mỗi thế hệ | 10
k | Số ví dụ trong ngữ cảnh trong prompt | 2  
T | Số vòng tiến hóa | 10
m | Số prompt mỗi vòng | 10
n | Số mẫu tạo ra cho mỗi prompt | 16
α | Ngưỡng dưới cho lỗi test | 0.5

A.2 Các Mô hình Mẫu MNIST-1D
Dưới đây chúng tôi cung cấp mã nguồn cho bốn mô hình mẫu được sử dụng trong tìm kiếm mô hình MNIST-1D.

1class Model (nn. Module ):
2 features : int = 32
3 nlayer : int = 3
4
5 @nn . compact
6 def __call__ (self , x):
7 x = x[... , None ]
8 x = nn. Conv ( features = self . features , kernel_size =(3 ,))(x)
9 x = nn. relu (x)
10
11 x = nn. avg_pool (x, window_shape =(2 ,) , strides =(2 ,))
12 for _ in range ( self . nlayer - 1):
13 xp = nn. Conv (
14 features = self . features ,
15 kernel_size =(3 ,) ,
16 )(x)
17 xp = nn. relu (xp)
18 x = x + xp
19
20 x = nn. avg_pool (x, window_shape =(2 ,) , strides =(2 ,))
21 x = x. reshape ((x. shape [0] , -1)) # flatten
22 x = nn. Dense ( features =256) (x)
23 x = nn. relu (x)
24 x = nn. Dense ( features =10) (x)
25 return x

Listing 2: Một mô hình tích chập được thiết kế thủ công.

1class Model (nn. Module ):
2 features : int = 25
3
4 @nn . compact
5 def __call__ (self , x):
6 x = x[... , None ]
7 x = nn. Conv (
8 features = self . features , kernel_size =(5 ,) , strides =(2 ,) , padding =(1 ,)
9 )(x)
10 x = nn. relu (x)
11 for _ in range (2) :

--- TRANG 16 ---
12 x = nn. Conv (
13 features = self . features , kernel_size =(3 ,) , strides =(2 ,) , padding =(1 ,)
14 )(x)
15 x = nn. relu (x)
16 x = x. reshape ((x. shape [0] , -1))
17 x = nn. Dense ( features =10) (x)
18 return x

Listing 3: Một triển khai Flax của baseline tích chập từ Greydanus (2020).

1class Model (nn. Module ):
2 """ A simple GRU model . """
3
4 hidden_size : int = 6
5 seed : int = 42
6
7 @nn . compact
8 def __call__ (self , x):
9 x = jnp. expand_dims (x, -1)
10 rng = jax_random . PRNGKey ( self . seed )
11 gru = recurrent .GRU (
12 hidden_size = self . hidden_size ,
13 num_layers =1,
14 dropout_rate =0.0 ,
15 bidirectional =True ,
16 )
17 lengths = np. full ([x. shape [0]] , x. shape [1])
18 initialized_params = gru. init (rng , x, lengths )
19 params = initialized_params ['params ']
20 outputs , _ = gru. apply ({ 'params ': params }, x, lengths )
21 outputs = outputs . reshape (( outputs . shape [0] , -1))
22 x = nn. Dense ( features =10) ( outputs )
23 return x

Listing 4: Một triển khai Flax của baseline GRU từ Greydanus (2020).

1class Model (nn. Module ):
2 hidden_size : int = 100
3
4 @nn . compact
5 def __call__ (self , x):
6 x = nn. Dense ( features = self . hidden_size )(x)
7 x = nn. relu (x)
8 x = x + nn. relu (nn. Dense ( features = self . hidden_size )(x))
9 x = nn. Dense ( features =10) (x)
10 return x
11
12return Model

Listing 5: Một triển khai Flax của baseline fully connected từ Greydanus (2020).

A.3 Quỹ đạo tìm kiếm cho các mô hình MNIST-1D

--- TRANG 17 ---
Hình 4: Kích thước mô hình trung bình và lỗi test của các mô hình con được tạo ra trong mỗi vòng tìm kiếm mô hình. Các điểm dữ liệu gần gốc tọa độ hơn đại diện cho các vòng mang lại các mô hình "phù hợp" hơn.

A.4 Các GNN CLRS Mới Được Khám Phá

Hình 5: Điểm fitness tối đa của năm mô hình mới được khám phá, so với baseline, trên tám nhiệm vụ CLRS.

Dưới đây chúng tôi liệt kê mã nguồn Python của năm GNN mới được khám phá.

1def get_triplet_msgs_quad (z, edge_fts , graph_fts , nb_triplet_fts
, out_size ):
2 node_reps = [hk. Linear ( nb_triplet_fts ) for _ in range (4) ]
3 triplet_node_reps = [ node_rep (z) for node_rep in node_reps ]
4 node_pair_inversions = [(1 , 2) , (1, 3) , (2, 3) , (3, 1)]
5 triplets = functools . reduce (
6 lambda x, y: x + y,
7 [
8 jnp . expand_dims ( tri_node_rep , axis = perm )
9 for tri_node_rep , perm in zip(
10 triplet_node_reps , node_pair_inversions
11 )
12 ],
13 )
14 return jnp.max( triplets , axis =1) - jnp.min( triplets , axis =1)

Listing 6: Biểu diễn triplet mà chúng tôi gọi là QUADNODEMINMAX.

1def get_triplet_msgs_concatrep (z, edge_fts , graph_fts ,
nb_triplet_fts , out_size ):
2 def rep_fn (x, size ):
3 proj = hk. nets .MLP ([ size ])
4 ff = hk. nets .MLP ([ size * 4, size ])
5 return jnp. concatenate ([
6 proj (x),
7 ff(x),
8 ], axis = -1)
9
10 triplet_node_reps = [ rep_fn (z, nb_triplet_fts ) for _ in range
(3) ]
11 triplet_edge_reps = [ rep_fn ( edge_fts , nb_triplet_fts ) for _ in
range (3) ]
12 triplet_graph_rep = rep_fn ( graph_fts , nb_triplet_fts )
13 node_pair_permutations = [(2 , 3) , (1, 3) , (1, 2)]
14 triplets = functools . reduce (
15 lambda x, y: x + y,
16 [
17 jnp . expand_dims ( tri_node_rep , axis = perm )
18 for tri_node_rep , perm in zip(
19 triplet_node_reps , node_pair_permutations
20 )
21 ],
22 )
23 triplets += functools . reduce (
24 lambda x, y: x + y,
25 [
26 jnp . expand_dims ( tri_edge_rep , axis =i)
27 for tri_edge_rep , i in zip( triplet_edge_reps , range (3, 0, -1))
28 ],
29 )
30 triplets += jnp. expand_dims ( triplet_graph_rep , axis =(1 , 2, 3))
31 output_layer = hk. Linear ( out_size )
32 return output_layer (jnp. max( triplets , axis =1))

Listing 7: Biểu diễn triplet mà chúng tôi gọi là CONCAT REP.

1def get_triplet_msgs_tanhexplandtriplets (z, edge_fts , graph_fts ,
nb_triplet_fts , out_size ):
2 node_reps = [hk. Linear ( nb_triplet_fts ) for _ in range (3) ]
3 edge_reps = [hk. Linear ( nb_triplet_fts ) for _ in range (3) ]
4 graph_rep = hk. nets .MLP ([ nb_triplet_fts ])
5 triplet_node_reps = [ node_rep (z) for node_rep in node_reps ]
6 triplet_edge_reps = [ edge_rep ( edge_fts ) for edge_rep in
edge_reps ]
7 node_pair_permutations = [(2 , 3) , (1, 3) , (1, 2)]
8 triplets = functools . reduce (
9 lambda x, y: x + y,
10 [
11 jnp . expand_dims ( tri_node_rep , axis = perm )
12 for tri_node_rep , perm in zip(
13 triplet_node_reps , node_pair_permutations
14 )
15 ],
16 )
17 triplets += functools . reduce (
18 lambda x, y: x + y,
19 [
20 jnp . expand_dims ( tri_edge_rep , axis =i)
21 for tri_edge_rep , i in zip( triplet_edge_reps , range (3, 0, -1))
22 ],
23 )
24 triplets += jnp. expand_dims ( graph_rep ( graph_fts ), axis =(1 , 2, 3))
25 triplets += jnp. expand_dims ( graph_rep ( graph_fts ), axis =(2 , 3, 1))
26 triplets += jnp. expand_dims ( graph_rep ( graph_fts ), axis =(3 , 1, 2))
27 output_layer = hk. Linear ( out_size )
28 return output_layer (jnp. tanh (jnp.max ( triplets , axis =1)))

Listing 8: Biểu diễn triplet mà chúng tôi gọi là TANH EXPAND TRIPLETS.

1def get_triplet_msgs_div2mean (z, edge_fts , graph_fts ,
nb_triplet_fts , out_size ):
2 node_reps = [hk. Linear ( nb_triplet_fts ) for _ in range (3) ]
3 edge_reps = [hk. Linear ( nb_triplet_fts ) for _ in range (3) ]
4 triplet_node_reps = [ node_rep (z / 2) for node_rep in node_reps
]
5 triplet_edge_reps = [ edge_rep ( edge_fts ) for edge_rep in
edge_reps ]
6 node_pair_permutations = [(2 , 3) , (1, 3) , (1, 2)]
7 triplets = functools . reduce (
8 lambda x, y: x + y,
9 [
10 jnp . expand_dims ( tri_node_rep , axis = perm )
11 for tri_node_rep , perm in zip(
12 triplet_node_reps , node_pair_permutations
13 )
14 ],
15 )
16 triplets += functools . reduce (
17 lambda x, y: x + y,
18 [
19 jnp . expand_dims ( tri_edge_rep , axis = perm )
20 for tri_edge_rep , perm in zip( triplet_edge_reps , range
(3, 0, -1))
21 ],
22 )
23 output_layer = hk. Linear ( out_size )
24 return output_layer (jnp. mean ( triplets , axis =1))

Listing 9: Biểu diễn triplet mà chúng tôi gọi là DIV2MEAN.

1def get_triplet_msgs_maxmean (z, edge_fts , graph_fts ,
nb_triplet_fts , out_size ):
2 node_reps = [hk. Linear ( nb_triplet_fts ) for _ in range (3) ]
3 edge_reps = [hk. Linear ( nb_triplet_fts ) for _ in range (3) ]
4 graph_rep = hk. nets .MLP ([ nb_triplet_fts ])
5 triplet_node_reps = [ node_rep (z) for node_rep in node_reps ]
6 triplet_edge_reps = [ edge_rep ( edge_fts ) for edge_rep in
edge_reps ]
7 node_pair_permutations = [(2 , 3) , (1, 3) , (1, 2)]
8 triplets = functools . reduce (
9 lambda x, y: x + y,
10 [
11 jnp . expand_dims ( tri_node_rep , axis = perm )
12 for tri_node_rep , perm in zip(
13 triplet_node_reps , node_pair_permutations
14 )
15 ],
16 )
17 triplets += functools . reduce (
18 lambda x, y: x + y,
19 [
20 jnp . expand_dims ( tri_edge_rep , axis =i)
21 for tri_edge_rep , i in zip( triplet_edge_reps , range (3, 0, -1))
22 ],
23 )
24 triplets = jnp. maximum ( triplets , -100.0)
25 output_layer = hk. Linear ( out_size )
26 return output_layer (jnp. mean ( triplets , axis =1))

Listing 10: Biểu diễn triplet mà chúng tôi gọi là MAXMEAN.

--- TRANG 21 ---
A.5 Các Mô hình Mẫu CLRS
Dưới đây chúng tôi cung cấp mã nguồn cho chín mô hình mẫu được sử dụng trong tìm kiếm mô hình CLRS.

1def get_triplet_msgs_v1 (z, edge_fts , graph_fts , nb_triplet_fts ,
out_size ):
2 node_reps = [hk. Linear ( nb_triplet_fts ) for _ in range (3) ]
3 edge_reps = [hk. Linear ( nb_triplet_fts ) for _ in range (3) ]
4 graph_rep = hk. Linear ( nb_triplet_fts )
5 triplet_node_reps = [ node_rep (z) for node_rep in node_reps ]
6 triplet_edge_reps = [ edge_rep ( edge_fts ) for edge_rep in
edge_reps ]
7 triplet_graph_rep = graph_rep ( graph_fts )
8 node_pair_permutations = [(2 , 3) , (1, 3) , (1, 2)]
9 triplets = functools . reduce (
10 lambda x, y: x + y,
11 [
12 jnp . expand_dims ( tri_node_rep , axis = perm )
13 for tri_node_rep , perm in zip(
14 triplet_node_reps , node_pair_permutations
15 )
16 ],
17 )
18 triplets += functools . reduce (
19 lambda x, y: x + y,
20 [
21 jnp . expand_dims ( tri_edge_rep , axis =i)
22 for tri_edge_rep , i in zip( triplet_edge_reps , range (3, 0, -1))
23 ],
24 )
25 triplets += jnp. expand_dims ( triplet_graph_rep , axis =(1 , 2, 3))
26 output_layer = hk. Linear ( out_size )
27 return output_layer (jnp. max( triplets , axis =1))

Listing 11: Biểu diễn triplet thuộc về mô hình mẫu đầu tiên - biểu diễn triplet tiêu chuẩn từ Ibarz et al. (2022).

1def get_triplet_msgs_v2 (z, edge_fts , graph_fts , nb_triplet_fts ,
out_size ):
2 node_reps = [hk. Linear ( nb_triplet_fts ) for _ in range (3) ]
3 edge_reps = [hk. Linear ( nb_triplet_fts ) for _ in range (3) ]
4 graph_rep = hk. Linear ( nb_triplet_fts )
5 triplet_node_reps = [ node_rep (z) for node_rep in node_reps ]
6 triplet_edge_reps = [ edge_rep ( edge_fts ) for edge_rep in
edge_reps ]
7 triplet_graph_rep = graph_rep ( graph_fts )
8 node_pair_permutations = [(2 , 3) , (1, 3) , (1, 2)]
9 triplets = functools . reduce (
10 lambda x, y: x + y,
11 [
12 jnp . expand_dims ( tri_node_rep , axis = perm )
13 for tri_node_rep , perm in zip(
14 triplet_node_reps , node_pair_permutations
15 )
16 ],
17 )
18 triplets += functools . reduce (
19 lambda x, y: x + y,
20 [
21 jnp . expand_dims ( tri_edge_rep , axis =i)
22 for tri_edge_rep , i in zip( triplet_edge_reps , range (3, 0, -1))
23 ],
24 )
25 triplets += jnp. expand_dims ( triplet_graph_rep , axis =(1 , 2, 3))
26 output_layer = hk. nets .MLP ([ out_size , out_size ])
27 return output_layer (jnp. max( triplets , axis =1))

Listing 12: Biểu diễn triplet thuộc về mô hình mẫu thứ hai, với lớp đầu ra được thay thế bằng một perceptron đa lớp fully-connected.

1def get_triplet_msgs_v3 (z, edge_fts , graph_fts , nb_triplet_fts ,
out_size ):
2 node_reps = [hk. Linear ( nb_triplet_fts ) for _ in range (3) ]
3 edge_reps = [hk. Linear ( nb_triplet_fts ) for _ in range (3) ]
4 graph_rep = hk. Linear ( nb_triplet_fts )
5 triplet_node_reps = [ node_rep (z) for node_rep in node_reps ]
6 triplet_edge_reps = [ edge_rep ( edge_fts ) for edge_rep in
edge_reps ]
7 triplet_graph_rep = graph_rep ( graph_fts )
8 node_pair_permutations = [(2 , 3) , (1, 3) , (1, 2)]
9 triplets = functools . reduce (
10 lambda x, y: x + y,
11 [
12 jnp . expand_dims ( tri_node_rep , axis = perm )
13 for tri_node_rep , perm in zip(
14 triplet_node_reps , node_pair_permutations
15 )
16 ],
17 )
18 triplets += functools . reduce (
19 lambda x, y: x + y,
20 [
21 jnp . expand_dims ( tri_edge_rep , axis =i)
22 for tri_edge_rep , i in zip( triplet_edge_reps , range (3, 0, -1))
23 ],
24 )
25 triplets += jnp. expand_dims ( triplet_graph_rep , axis =(1 , 2, 3))
26 output_layer = hk. Linear ( out_size )
27 return output_layer (jnp. sum( triplets , axis =1))

Listing 13: Biểu diễn triplet thuộc về mô hình mẫu thứ ba, sử dụng aggregation sum thay vì max.

1def get_triplet_msgs_v4 (z, edge_fts , graph_fts , nb_triplet_fts ,
out_size ):
2 node_reps = [hk. nets .MLP ([ nb_triplet_fts , nb_triplet_fts ]) for
_ in range (3)]
3 edge_reps = [hk. Linear ( nb_triplet_fts ) for _ in range (3) ]
4 graph_rep = hk. Linear ( nb_triplet_fts )
5 triplet_node_reps = [ node_rep (z) for node_rep in node_reps ]
6 triplet_edge_reps = [ edge_rep ( edge_fts ) for edge_rep in
edge_reps ]
7 triplet_graph_rep = graph_rep ( graph_fts )
8 node_pair_permutations = [(2 , 3) , (1, 3) , (1, 2)]
9 triplets = functools . reduce (
10 lambda x, y: x + y,
11 [
12 jnp . expand_dims ( tri_node_rep , axis = perm )
13 for tri_node_rep , perm in zip(
14 triplet_node_reps , node_pair_permutations
15 )
16 ],
17 )
18 triplets += functools . reduce (
19 lambda x, y: x + y,
20 [
21 jnp . expand_dims ( tri_edge_rep , axis =i)
22 for tri_edge_rep , i in zip( triplet_edge_reps , range (3, 0, -1))
23 ],
24 )
25 triplets += jnp. expand_dims ( triplet_graph_rep , axis =(1 , 2, 3))
26 output_layer = hk. Linear ( out_size )
27 return output_layer (jnp. max( triplets , axis =1))

Listing 14: Biểu diễn triplet của mô hình mẫu thứ 4, sử dụng biểu diễn node perceptron đa lớp fully-connected.

1def get_triplet_msgs_v5 (z, edge_fts , graph_fts , nb_triplet_fts ,
out_size ):
2 node_reps = [hk. Linear ( nb_triplet_fts ) for _ in range (3) ]
3 edge_reps = [hk. nets .MLP ([ nb_triplet_fts , nb_triplet_fts ]) for
_ in range (3)]
4 graph_rep = hk. Linear ( nb_triplet_fts )
5 triplet_node_reps = [ node_rep (z) for node_rep in node_reps ]
6 triplet_edge_reps = [ edge_rep ( edge_fts ) for edge_rep in
edge_reps ]
7 triplet_graph_rep = graph_rep ( graph_fts )
8 node_pair_permutations = [(2 , 3) , (1, 3) , (1, 2)]
9 triplets = functools . reduce (
10 lambda x, y: x + y,
11 [
12 jnp . expand_dims ( tri_node_rep , axis = perm )
13 for tri_node_rep , perm in zip(
14 triplet_node_reps , node_pair_permutations
15 )
16 ],
17 )
18 triplets += functools . reduce (
19 lambda x, y: x + y,
20 [
21 jnp . expand_dims ( tri_edge_rep , axis =i)
22 for tri_edge_rep , i in zip( triplet_edge_reps , range (3, 0, -1))
23 ],
24 )
25 triplets += jnp. expand_dims ( triplet_graph_rep , axis =(1 , 2, 3))
26 output_layer = hk. Linear ( out_size )
27 return output_layer (jnp. max( triplets , axis =1))

Listing 15: Biểu diễn triplet của mô hình mẫu thứ 5, sử dụng biểu diễn edge perceptron đa lớp fully-connected.

1def get_triplet_msgs_v6 (z, edge_fts , graph_fts , nb_triplet_fts ,
out_size ):
2 node_reps = [hk. Linear ( nb_triplet_fts ) for _ in range (3) ]
3 edge_reps = [hk. Linear ( nb_triplet_fts ) for _ in range (3) ]
4 graph_rep = hk. nets .MLP ([ nb_triplet_fts , nb_triplet_fts ])
5 triplet_node_reps = [ node_rep (z) for node_rep in node_reps ]
6 triplet_edge_reps = [ edge_rep ( edge_fts ) for edge_rep in
edge_reps ]
7 triplet_graph_rep = graph_rep ( graph_fts )
8 node_pair_permutations = [(2 , 3) , (1, 3) , (1, 2)]
9 triplets = functools . reduce (
10 lambda x, y: x + y,
11 [
12 jnp . expand_dims ( tri_node_rep , axis = perm )
13 for tri_node_rep , perm in zip(
14 triplet_node_reps , node_pair_permutations
15 )
16 ],
17 )
18 triplets += functools . reduce (
19 lambda x, y: x + y,
20 [
21 jnp . expand_dims ( tri_edge_rep , axis =i)
22 for tri_edge_rep , i in zip( triplet_edge_reps , range (3, 0, -1))
23 ],
24 )
25 triplets += jnp. expand_dims ( triplet_graph_rep , axis =(1 , 2, 3))
26 output_layer = hk. Linear ( out_size )
27 return output_layer (jnp. max( triplets , axis =1))

Listing 16: Biểu diễn triplet của mô hình mẫu thứ 6, sử dụng biểu diễn graph perceptron đa lớp fully-connected.

1def get_triplet_msgs_v7 (z, edge_fts , graph_fts , nb_triplet_fts ,
out_size ):
2 node_reps = [hk. nets .MLP ([ nb_triplet_fts ]) for _ in range (3)]
3 edge_reps = [hk. Linear ( nb_triplet_fts ) for _ in range (3) ]
4 triplet_node_reps = [ node_rep (z) for node_rep in node_reps ]
5 triplet_edge_reps = [ edge_rep ( edge_fts ) for edge_rep in
edge_reps ]
6 node_pair_permutations = [(2 , 3) , (1, 3) , (1, 2)]
7 triplets = functools . reduce (
8 lambda x, y: x + y,
9 [
10 jnp . expand_dims ( tri_node_rep , axis = perm )
11 for tri_node_rep , perm in zip(
12 triplet_node_reps , node_pair_permutations
13 )
14 ],
15 )
16 triplets += functools . reduce (
17 lambda x, y: x + y,
18 [
19 jnp . expand_dims ( tri_edge_rep , axis =i)
20 for tri_edge_rep , i in zip( triplet_edge_reps , range (3, 0, -1))
21 ],
22 )
23 output_layer = hk. Linear ( out_size )
24 return output_layer (jnp. max( triplets , axis =1))

Listing 17: Biểu diễn triplet của mô hình mẫu thứ 7, sử dụng biểu diễn node perceptron đa lớp fully-connected và không có biểu diễn graph.

1def get_triplet_msgs_v8 (z, edge_fts , graph_fts , nb_triplet_fts ,
out_size ):
2 output_layer = hk. nets .MLP ([ out_size ])
3 return jnp. tile (
4 jnp . expand_dims ( output_layer (z), axis =(1) ), [1, z. shape
[1] , 1, 1]
5 )

Listing 18: Biểu diễn triplet của mô hình mẫu thứ 8, đơn giản áp dụng một lớp tuyến tính và tile đầu ra để duy trì tính nhất quán về chiều.

1def get_triplet_msgs_v9 (z, edge_fts , graph_fts , nb_triplet_fts ,
out_size ):
2 def rep_fn (x, size ):
3 proj = hk. nets .MLP ([ size ])
4 ff = hk. nets .MLP ([ size * 8, size ])
5 return proj (x) * ff(x)
6
7 triplet_node_reps = [ rep_fn (z, nb_triplet_fts ) for _ in range
(3) ]
8 triplet_edge_reps = [ rep_fn ( edge_fts , nb_triplet_fts ) for _ in
range (3) ]
9 triplet_graph_rep = rep_fn ( graph_fts , nb_triplet_fts )
10 node_pair_permutations = [(2 , 3) , (1, 3) , (1, 2)]
11 triplets = functools . reduce (
12 lambda x, y: x + y,
13 [
14 jnp . expand_dims ( tri_node_rep , axis = perm )
15 for tri_node_rep , perm in zip(
16 triplet_node_reps , node_pair_permutations
17 )
18 ],
19 )
20 triplets += functools . reduce (
21 lambda x, y: x + y,
22 [
23 jnp . expand_dims ( tri_edge_rep , axis =i)
24 for tri_edge_rep , i in zip( triplet_edge_reps , range (3, 0, -1))
25 ],
26 )
27 triplets += jnp. expand_dims ( triplet_graph_rep , axis =(1 , 2, 3))
28 return rep_fn (jnp .max( triplets , axis =1) , out_size )

Listing 19: Biểu diễn triplet của mô hình mẫu thứ 9, sử dụng biểu diễn bilinear cho các biểu diễn node, edge, và graph.

--- TRANG 26 ---
A.6 Đánh giá OOD của Các Mô hình Mới Được Khám Phá trên CLRS

Bảng 3: Danh sách đầy đủ so sánh 5 GNN mới được khám phá với mô hình Triplet-GMPNN baseline từ Ibarz et al. (2022) trên tất cả 30 nhiệm vụ CLRS (Veli ˇckovi ´c et al., 2022). Đối với baseline, chúng tôi bao gồm độ chính xác OOD của cả việc triển khai Triplet-GMPNN của chúng tôi và số được liệt kê trong bài báo gốc.

Thuật toán | Mô hình Hoạt động Tốt Nhất | Kích thước Mô hình ↓ | Độ chính xác OOD ↑
---|---|---|---
 | Mô hình hoạt động tốt nhất | Mô hình baseline | Mô hình mới được khám phá hoạt động tốt nhất | Mô hình baseline (triển khai của chúng tôi) | Mô hình baseline (từ Ibarz et al. (2022))
Activity Selector | Baseline | 262204 | 262204 | 95.05±0.53% | 93.96±0.29% | 95.18±0.45%
Articulation Points | QUADNODEMINMAX | 497969 | 531913 | 93.46±1.77% | 91.40±1.74% | 88.32±2.01%
Bellman Ford | CONCAT REP | 568660 | 524604 | 97.50±0.31% | 97.08±0.24% | 97.39±0.19%
BFS | MAXMEAN | 522931 | 523963 | 99.99±0.01% | 99.80±0.04% | 99.73±0.04%
Binary Search | Baseline | 262204 | 262204 | 77.98±2.49% | 79.57±1.73% | 77.58±2.35%
Bridges | CONCAT REP | 576612 | 532556 | 97.57±1.08% | 97.31±1.11% | 93.99±2.07%
Bubble Sort | CONCAT REP | 568533 | 524477 | 88.87±2.77% | 83.20±4.27% | 67.68±5.50%
DAG Shortest Paths | Baseline | 793287 | 793287 | 98.01±0.22% | 97.48±0.37% | 98.19±0.30%
DFS | DIV2MEAN | 660158 | 661190 | 68.14±1.38% | 46.78±3.85% | 47.79±4.19%
Dijkstra | DIV2MEAN | 524854 | 525886 | 97.30±0.28% | 95.94±0.66% | 96.05±0.60%
Find Maximum Subarray Kadane | Baseline | 261290 | 264514 | 75.35±0.92% | 74.09±0.83% | 76.36±0.43%
Floyd Warshall | CONCAT REP | 669145 | 625089 | 61.43±0.79% | 48.95±0.49% | 48.52±1.04%
Graham Scan | MAXMEAN | 397377 | 398409 | 93.76±0.85% | 92.72±2.38% | 93.62±0.91%
Heapsort | CONCAT REP | 703710 | 659654 | 69.90±4.17% | 19.45±5.35% | 31.04±5.82%
Insertion Sort | DIV2MEAN | 523445 | 524477 | 89.47±2.57% | 86.89±1.89% | 78.14±4.64%
Jarvis March | Baseline | 308954 | 264898 | 90.36±0.65% | 88.91±0.91% | 91.01±1.30%
Knuth-Morris-Pratt | Baseline | 396989 | 398021 | 16.29±4.36% | 8.88±1.76% | 19.51±4.57%
LCS Length | Baseline | 270419 | 270419 | 85.75±0.80% | 86.05±0.65% | 80.51±1.84%
Matrix Chain Order | Baseline | 624448 | 624448 | 90.77±0.75% | 91.15±0.85% | 91.68±0.59%
Minimum | DIV2MEAN | 260275 | 261307 | 98.40±0.16% | 98.26±0.26% | 97.78±0.55%
MST Kruskal | CONCAT REP | 443747 | 399691 | 91.47±0.48% | 90.60±0.32% | 89.80±0.77%
MST Prim | CONCAT REP | 569942 | 525886 | 88.74±1.67% | 85.18±2.24% | 86.39±1.33%
Naive String Matcher | QUADNODEMINMAX | 259364 | 262588 | 79.77±2.88% | 73.39±6.33% | 78.67±4.99%
Optimal BST | DIV2MEAN | 624955 | 625987 | 78.66±0.46% | 78.08±0.96% | 73.77±1.48%
Quickselect | QUADNODEMINMAX | 377130 | 395714 | 0.79±0.41% | 0.13±0.08% | 0.47±0.25%
Quicksort | DIV2MEAN | 524727 | 525759 | 85.23±4.26% | 84.71±2.66% | 64.64±5.12%
Segments Intersect | DIV2MEAN | 262327 | 263359 | 98.15±0.00% | 97.40±0.00% | 97.64±0.09%
Strongly Connected Components | Baseline | 707299 | 663243 | 41.86±3.39% | 43.71±5.94% | 43.43±3.15%
Task Scheduling | TANH EXPAND TRIPLETS | 262333 | 262333 | 88.23±0.44% | 88.10±0.31% | 87.25±0.35%
Topological Sort | TANH EXPAND TRIPLETS | 660164 | 660164 | 88.12±4.71% | 76.88±5.05% | 87.27±2.67%

Kết thúc Bảng 3

--- TRANG 28 ---
A.7 NATS-Bench
Chúng tôi thực hiện so sánh ngắn gọn EVOPROMPTING với các thuật toán NAS khác trên NATS-Bench Size Search Space (Dong et al., 2021). Tuy nhiên, chúng tôi lưu ý rằng so sánh này bị hạn chế vì nó khiến EVOPROMPTING bất lợi theo nhiều cách:

1. LLM của chúng tôi được pre-train để tạo sinh mã, nhưng cho so sánh này nó được prompt để tạo ra các chuỗi kiến trúc theo phong cách NATS-Bench, có định dạng "64:64:64:64:64," điều này loại bỏ lợi ích của việc pre-training mã.

2. Một trong những lợi thế chính của EVOPROMPTING là không gian tìm kiếm mở. Vì không gian tìm kiếm của nó không cần được thiết kế thủ công, EVOPROMPTING có thể khám phá các kiến trúc mới mà các thuật toán NAS khác không thể.

Bảng 4: EVOPROMPTING so với các thuật toán tìm kiếm kiến trúc mạng neural tiêu chuẩn khác trên không gian tìm kiếm kích thước NATS-Bench. Vì việc điều chỉnh đúng các giá trị siêu tham số cho tất cả các kỹ thuật tìm kiếm là không tầm thường, chúng tôi lấy các số độ chính xác cho tất cả các phương pháp khác ngoài phương pháp của chúng tôi từ Dong et al. (2021). EVOPROMPTING hoạt động cạnh tranh so với tất cả các kỹ thuật khác.

Phương pháp | CIFAR-10 | CIFAR-100 | ImageNet-16-120
---|---|---|---
 | Val | Test | Val | Test | Val | Test
Multi-trial REA | 90.37±0.20 | 93.22±0.16 | 70.23±0.50 | 70.11±0.61 | 45.30±0.69 | 45.94±0.92
REINFORCE | 90.25±0.23 | 93.16±0.21 | 69.84±0.59 | 69.96±0.57 | 45.06±0.77 | 45.71±0.93
RANDOM | 90.10±0.26 | 93.03±0.25 | 69.57±0.57 | 69.72±0.61 | 45.01±0.74 | 45.42±0.86
BOHB | 90.07±0.28 | 93.01±0.24 | 69.75±0.60 | 69.90±0.60 | 45.11±0.69 | 45.56±0.81
Weight-sharing channel-wise interpolation | 90.71±0.00 | 93.40±0.00 | 70.30±0.00 | 70.72±0.00 | 44.73±0.00 | 47.17±0.00
masking + Gumbel-Softmax | 90.41±0.10 | 93.14±0.13 | 70.30±0.00 | 70.72±0.00 | 45.71±0.39 | 46.38±0.27
masking + sampling | 89.73±0.37 | 92.78±0.30 | 69.67±0.22 | 70.11±0.33 | 44.70±0.60 | 45.11±0.76
EVOPROMPTING | 90.38±0.33 | 93.11±0.90 | 70.47±0.23 | 70.39±0.58 | 45.32±0.26 | 45.15±0.51

--- TRANG 29 ---
A.8 Tác động Rộng lớn hơn
Nghiên cứu của chúng tôi có thể có một số tác động đạo đức, xã hội và rộng lớn khác. Vì chúng tôi tập trung vào cải thiện tự động các mô hình ngôn ngữ lớn, những hàm ý của nghiên cứu của chúng tôi phần lớn tương tự như của LM nói chung. Một mặt, việc cải thiện khả năng và giảm kích thước của LM có thể tăng khả năng tiếp cận của chúng (Köpf et al., 2023), cải thiện hiệu quả năng lượng (McDonald et al., 2022; Chen et al., 2023), và mở rộng cơ hội giáo dục và nghề nghiệp (Kasneci et al., 2023; Eysenbach, 2023). Mặt khác, LM từ lâu đã được biết đến là tạo ra ngôn ngữ bất công và độc hại có thể gây tổn hại và khuếch đại các khuôn mẫu (Nadeem et al., 2020; Lucy & Bamman, 2021), các chuẩn mực loại trừ, và tác hại phân bổ đối với các nhóm bị thiệt thòi (Bender et al., 2021). LM cũng có thể đưa ra các mối nguy hiểm thông tin, thường tạo ra thông tin sai lệch có vẻ thực tế (Bickmore et al., 2018; Quach, 2022) hoặc tiết lộ thông tin cá nhân riêng tư (Carlini et al., 2021). Cuối cùng, các tác hại khác có thể phát sinh từ cách con người tương tác với LM – hoặc bằng cách vô tình dựa quá nhiều vào các đầu ra LM không đáng tin cậy (McKee et al., 2021) hoặc thông qua việc sử dụng độc hại (Ranade et al., 2021; Boiko et al., 2023).

Tài liệu tham khảo
Bender, E. M., Gebru, T., McMillan-Major, A., and Shmitchell, S. On the dangers of stochastic parrots: Can language models be too big? . In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency , FAccT '21, pp. 610–623, New York, NY , USA, 2021. Association for Computing Machinery. ISBN 9781450383097. doi: 10.1145/3442188.3445922. URL https://doi.org/10.1145/3442188.3445922 .

Bickmore, T. W., Trinh, H., Olafsson, S., O'Leary, T. K., Asadi, R., Rickles, N. M., and Cruz, R. Patient and consumer safety risks when using conversational assistants for medical information: An observational study of siri, alexa, and google assistant. J Med Internet Res , 20(9), Sep 2018. ISSN 1438-8871. doi: 10.2196/11510. URL http://www.jmir.org/2018/9/e11510/ .

Boiko, D. A., MacKnight, R., and Gomes, G. Emergent autonomous scientific research capabilities of large language models, 2023.

Carlini, N., Tramer, F., Wallace, E., Jagielski, M., Herbert-V oss, A., Lee, K., Roberts, A., Brown, T., Song, D., Erlingsson, U., Oprea, A., and Raffel, C. Extracting training data from large language models. In USENIX Security Symposium , 2021. URL https://arxiv.org/abs/2012.07805 .

Chen, L., Zaharia, M., and Zou, J. Frugalgpt: How to use large language models while reducing cost and improving performance, 2023.

Eysenbach, G. The role of chatgpt, generative language models, and artificial intelligence in medical education: A conversation with chatgpt and a call for papers. JMIR Med Educ , 9:e46885, Mar 2023. ISSN 2369-3762. doi: 10.2196/46885. URL https://mededu.jmir.org/2023/1/e46885 .

Kasneci, E., Sessler, K., Küchemann, S., Bannert, M., Dementieva, D., Fischer, F., Gasser, U., Groh, G., Günnemann, S., Hüllermeier, E., Krusche, S., Kutyniok, G., Michaeli, T., Nerdel, C., Pfeffer, J., Poquet, O., Sailer, M., Schmidt, A., Seidel, T., Stadler, M., Weller, J., Kuhn, J., and Kasneci, G. Chatgpt for good? on opportunities and challenges of large language models for education. Learning and Individual Differences , 103:102274, 2023. doi: https://doi.org/10.1016/j.lindif.2023. 102274.

Köpf, A., Kilcher, Y ., von Rütte, D., Anagnostidis, S., Tam, Z.-R., Stevens, K., Barhoum, A., Duc, N. M., Stanley, O., Nagyfi, R., ES, S., Suri, S., Glushkov, D., Dantuluri, A., Maguire, A., Schuhmann, C., Nguyen, H., and Mattick, A. Openassistant conversations – democratizing large language model alignment, 2023.

Lucy, L. and Bamman, D. Gender and representation bias in GPT-3 generated stories. In Proceedings of the Third Workshop on Narrative Understanding , pp. 48–55, Virtual, June 2021. Association for Computational Linguistics. doi: 10.18653/v1/2021.nuse-1.5. URL https://aclanthology. org/2021.nuse-1.5 .

McDonald, J., Li, B., Frey, N., Tiwari, D., Gadepally, V ., and Samsi, S. Great power, great responsibility: Recommendations for reducing energy for training language models. In Findings of the Association for Computational Linguistics: NAACL 2022 . Association for Computational Linguistics, 2022. doi: 10.18653/v1/2022.findings-naacl.151.

McKee, K. R., Bai, X., and Fiske, S. Humans perceive warmth and competence in artificial intelligence, Feb 2021. URL psyarxiv.com/5ursp .

Nadeem, M., Bethke, A., and Reddy, S. Stereoset: Measuring stereotypical bias in pretrained language models, 2020.

Quach, K. Researchers made an openai gpt-3 medical chatbot as an experiment. it told a mock patient to kill themselves, Aug 2022. URL https://www.theregister.com/2020/10/28/ gpt3_medical_chatbot_experiment/ .

Ranade, P., Piplai, A., Mittal, S., Joshi, A., and Finin, T. Generating fake cyber threat intelligence using transformer-based models, 2021.

--- TRANG 31 ---
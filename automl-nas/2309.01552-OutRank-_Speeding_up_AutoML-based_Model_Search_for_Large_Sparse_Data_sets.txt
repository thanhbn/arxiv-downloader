# 2309.01552.pdf
# Converted from PDF to TXT
# Source path: /home/admin88/arxiv-downloader/automl-nas/2309.01552.pdf
# File size: 2109459 bytes

===============================================
PDF FILE CONTENT
===============================================


--- PAGE 1 ---
OutRank: Speeding up AutoML-based Model Search for Large Sparse Data sets
with Cardinality-aware Feature Ranking
BLAÅ½ Å KRLJ, Outbrain inc., US
BLAÅ½ MRAMOR, Outbrain inc., US
The design of modern recommender systems relies on understanding which parts of the feature space are relevant for solving a
given recommendation task. However, real-world data sets in this domain are often characterized by their large size, sparsity, and
noise, making it challenging to identify meaningful signals. Feature ranking represents an efficient branch of algorithms that can help
address these challenges by identifying the most informative features and facilitating the automated search for more compact and
better-performing models (AutoML). We introduce OutRank, a system for versatile feature ranking and data quality-related anomaly
detection. OutRank was built with categorical data in mind, utilizing a variant of mutual information that is normalized with regard to
the noise produced by features of the same cardinality. We further extend the similarity measure by incorporating information on
feature similarity and combined relevance. The proposed approachâ€™s feasibility is demonstrated by speeding up the state-of-the-art
AutoML system on a synthetic data set with no performance loss. Furthermore, we considered a real-life click-through-rate prediction
data set where it outperformed strong baselines such as random forest-based approaches. The proposed approach enables exploration
of up to 300% larger feature spaces compared to AutoML-only approaches, enabling faster search for better models on off-the-shelf
hardware.
Additional Key Words and Phrases: Feature ranking, massive data sets, AutoML, recommender systems
ACM Reference Format:
BlaÅ¾ Å krlj and BlaÅ¾ Mramor. 2023. OutRank: Speeding up AutoML-based Model Search for Large Sparse Data sets with Cardinality-aware
Feature Ranking. ACM/IMS J. Data Sci. 37, 4, Article 111 (August 2023), 8 pages. https://doi.org/XXXXXXX.XXXXXXX
1 INTRODUCTION AND PROBLEM OVERVIEW
The design of modern recommender systems relies on the integration of different context types into complex feature
spaces that enable high-quality recommendations [ 1]. Real-world data sets in this domain are often characterized
by their large size, sparsity, and noise, making it challenging to identify meaningful signals efficiently. Models that
are part of real-life recommender systems, on the other hand, need to be lightweight and efficient due to the scale at
which they are deployed [ 13]. For this purpose, contemporary machine learning model/design flows are utilized and
consist of multiple steps, including feature (pre)selection, model search/optimization and refinement [ 12]. A commonly
considered light-weight type of algorithms used in recommender systems are factorization machine-based models [ 10].
Albeit versatile in production, these methods require computationally expensive procedures for finding optimal single
or combined features that comprise the final model. Such compact and well-performing model configurations can
be found by utilizing automated search systems [4,17] (AutoML). These systems are capable of exploring both the
Authorsâ€™ addresses: BlaÅ¾ Å krlj, bskrlj@outbrain.com, Outbrain inc., New York, New York, US; BlaÅ¾ Mramor, bmramor@outbrain.com, Outbrain inc., New
York, New York, US.
Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not
made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components
of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to
redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org.
Â©2023 Association for Computing Machinery.
Manuscript submitted to ACM
Manuscript submitted to ACM 1arXiv:2309.01552v1  [cs.IR]  4 Sep 2023

--- PAGE 2 ---
2 BlaÅ¾ Å krlj and BlaÅ¾ Mramor
space of algorithms and their configurations and have become ubiquitous in the design of performance factorization
machines [ 11]. The caveat associated with considering AutoML systems is their computational complexity - search
for optimal feature configurations is time-consuming and often requires dedicated hardware (or clusters of machines).
This process can be, to some extent, complemented with a computationally more approachable branch of feature ranking
algorithms [ 14â€“16].Feature ranking is a technique that can help address these challenges by identifying the most
informative features and thus speeding up AutoML. These algorithms have found their use across multiple domains,
spanning from biomedicine [ 6] to recommender systems [ 16]. They enable fast estimation of featuresâ€™ relevances
(and their interactions), and can be considered as a form of prior information for an AutoML-based model search.
The remainder of this paper describes key properties of OutRank, a system for versatile feature ranking and data-
quality-related anomaly detection. OutRank utilizes a variant of mutual information that is normalized with regards to
the noise produced by features of the same cardinality , which in our use-cases outperforms other strong baselines, such
as random forest-based ranking. Furthermore, the presented approach can scale to data sets comprising hundreds of
millions of instances using commodity hardware. Complemented by probabilistic cardinality estimation and coverage
profiling, OutRank enables efficient data pre-processing, profiling of new features, and pruning of the input feature
space to speed up AutoML-based model searches. Further, we present 3MR (Minimum redundancy, maximum relevance,
maximum relation) heuristic that enables computation of fast non-myopic estimates of feature importances â€“ its utility
is demonstrated on synthetic and real-life data, where it enables substantial speedups of an existing AutoML system
(TPOT [ 7]) and is shown to offer better rankings compared to strong baselines such as Random forest-based [ 2] rankings
on an internal data set related to conversion rate prediction.
2 SYSTEM OVERVIEW
The remainder of this section is structured as follows. We first discuss the general context/overview of OutRank. Next,
we discuss the impact of cardinality on ranking and how it was overcome. Finally, the section is followed by an overview
of how feature combinations and their redundancies are considered in ranking, resulting in the 3MR algorithm. We next
discuss the systemâ€™s architecture/overview. OutRank was built to facilitate the exploration of very large data sets (up to
a billion instances in some cases) without any specialized hardware. The only resource-friendly approach to traversing
and analyzing such data sets is by adopting batching â€“ the data set is streamed into the engine (OutRank). Once enough
instances are temporarily stored, feature construction and ranking take place. This step is responsible for producing
relevant transformations of data (on-the-fly), resulting in large space savings (compared to pre-computing all feature
transformations of relevance), and conducting ranking. OutRank was built to scale to large data sets (tens of millions
of listings) and support different ranking heuristics (discussed in the following sections). An overview of OutRankâ€™s
architecture is shown in Figure 1. This paper focuses on the novel contributions related to ranking features for sparse
categorical data sets (a detailed discussion of OutRankâ€™s architecture is beyond the scope of this paper). However, the
described overview should offer the reader the context in which such ranking is considered/used in practice.
We next discuss overcoming the effect of high cardinality features . A common problem when dealing with data
sets that are used for the construction of recommender systems is related to featuresâ€™ cardinalities â€“ the input space
consists of mostly categorical features that can be subject to varying amounts of unique (possible) values. Many unique
values per feature are potentially problematic, as they decrease coverage per value (instances with a particular value)
and can be harder to profile/assess when ranking for a downstream task such as modelling/transformation/further
exploration. Mutual information (detailed overview in, e.g., [ 5]) is an efficient similarity measure particularly suitable
for comparing discrete (categorical) random variables. We next describe the variant of this measure we identified as fast
Manuscript submitted to ACM

--- PAGE 3 ---
OutRank: Speeding up AutoML-based Model Search 3
Data
batchQuality
check
Feature 
importancesAggregation step
Data
batch
...SummaryCheckpoints
Once enough 
samples are 
parsedFeature
statistics
Feature 
constructionTimeIntermediary 
feature quality
reportsCoverage 
and
cardinality 
analysis Data
batch
Fig. 1. Overview of OutRank. Feature ranking and analysis are conducted for batches of data (the user parametrizes size) â€“ once
enough data is observed by the system, the final aggregate is obtained from intermediary scores and used to produce final feature
scores.
and representative of featuresâ€™ similarities. The key motivation is based on the fact that the cardinality of a feature of
interest plays an important role â€“ simultaneously, ranking features of different cardinalities can be sub-optimal and can
result in biased final scores (we observed inflated scores of features that exhibit high cardinality). Based on the adopted
notion of mutual information:
ğ‘€ğ¼(ğ‘ˆ,ğ‘‰)=ğ»(ğ‘ˆ)âˆ’ğ»(ğ‘ˆ|ğ‘‰)=Eğ‘‰
ğ·KL ğ‘ğ‘ˆ|ğ‘‰=ğ‘£|ğ‘ğ‘ˆ
,
whereğ‘ˆandğ‘‰represent two variables of interest and ğ·KLrepresents Kullback-Leibler divergence, we propose the
following modification. To account for cardinalityâ€™s impact, we observed that normalizing this score by the expected
score obtained by aggregating MI scores across a collection of samples of a random variable of same cardinality has
beneficial effects when differentiating between more and less important features. Hence, the mutual information-derived
score we refer to as CardMI computed adheres to the following expression
CardMI(ğ‘ˆ,ğ‘‰)=Aggregate ğ‘âˆˆğµ
ğ‘€ğ¼(ğ‘ˆğ‘,ğ‘‰ğ‘)âˆ’Eğ‘†ğ‘âˆ¼ğ‘‹|ğ‘‰ğ‘|
ğ‘€ğ¼(ğ‘ˆğ‘,ğ‘†ğ‘)
,
whereğµrepresents the set of all data batches (row-indexes, orange in Figure 1) and ğ‘ˆ,ğ‘‰ represent two features under
consideration. The ğ‘†ğ‘represents a random sample of the same cardinality for a given batch of data (the number of
such samples is a parameter). The aggregation function Aggregate combines the intermediary scores into a final
one and optionally truncates them to [0,1]range. At the end of each run, resulting importance scores are scaled to
0-1 range (considering score vector x)Scale(xğ‘–)=xğ‘–âˆ’min(x)
max(x)âˆ’min(x).Intuitively, subtraction of the expected noise is
conducted to distil the signal at the batch level â€“ the generated noise differs from batch to batch (so does the actual
data). Further, OutRank out-of-the-box implements a collection of "sanity-check" features ; these features correspond
to random noise of specific cardinality, constants and other types of noise for which expected ranking scores are
known (and are either very low or high - if derived from the target variable directly). Comparison against controls
of different cardinalities enables us to control the algorithmâ€™s performance with unit tests, offering fast insights into
possible regression introduced during software updates. The main rationale for considering an MI-based score is its
speed. The computational complexity of CardMI isO(|ğ¹|Â·ğ‘Â·ğ‘ Â·|ğµ|), whereğ‘ is the number of random samples used
for normalization and |ğµ|batch size. Computing a single ğ‘€ğ¼estimate is fast for sparse data sets. Low computational
complexity and high parallelizability within data batches (pairwise CardMI rankings) enabled the development of
an extended algorithm that overcomes CardMI â€™s myopic nature â€“ lack of capability for accounting for interactions.
This aspect is discussed next in more detail.
Manuscript submitted to ACM

--- PAGE 4 ---
4 BlaÅ¾ Å krlj and BlaÅ¾ Mramor
We next discuss approximating higher order interactions . The crux of many recommender systems is their
capability to accurately profile and detect relevant higher-order interactions. These combinations of two or more
features can indicate sparse yet highly relevant events that govern the success of a given system. The adopted paradigm
of factorization machines enables explicit modelling of such interactions; however, identifying them effectively is an
ongoing research endeavour. Combining insights used by this branch of algorithms ( hashing trick ) with the efficiency
of feature ranking, OutRank enables fast profiling of tens of thousands of interactions based on millions of instances. The
idea underlying interaction profiling includes two insights that allow scaling. First, as OutRank traversed the data set in
batches, profiling different interactions for different batches can substantially reduce time complexity ( O(|ğ¹|2)). Each
combined feature representing the interaction of multiple features is obtained by hashing existing value tuples (the data
structure holding this information) into a single value, making the feature directly compatible with CarMI computation,
i.e.,Comb(ğ¹1,ğ¹2,...,ğ¹ğ‘›)=Hash(struct =(ğ¹1,ğ¹2,...,ğ¹ğ‘›)).Here, Hash represents a fast hash function (xxHash in our
case1). Albeit fast hashing enables the construction of combined features, ranking, in this case, takes substantially
longer, and can be prohibitively complex. To overcome this issue, we introduce the notion of feature buffers â€“ fixed-sized
sets of features at the batch level that represent random samples of the space of all possible (generated) combinations.
Feature buffer is populated randomly per batch (in an idempotent manner), and its fixed size guarantees consistent
(predictable) performance. As different combinations are "sampled" when considering different batches, with enough
data, reliable estimates of higher-order interaction scores are obtained (not enough samples imply unreliable scores).
This way, second and third-order (conjunctions) interactions are within reach for production-scale data sets. Apart from
approximating the supervised effect of interactions (via hashing), OutRank can also compute lower-triangular similarity
matrices that represent redundancies between pairs of features. This computational step is, similar to the supervised
interaction one above, computationally expensive and is approximated in the same manner; only a subspace of possible
combinations is considered per data batch - in the limit (=with enough data), enough samples of all combinations are
obtained. In addition, the "buffer size", i.e. the number of combinations/features to be considered at most per batch, is
parametrized - the lower the value, the more coarse-grained the approximation of similarities/interaction importance.
2.1 3MR - Minimum Redundancy Maximum Relevance Maximum Relation extension
Albeit able to account for cardinality-related issues better, the CardMI heuristic does not incorporate information about
the featureâ€™s similarity to other features (itâ€™s myopic). To overcome this limitation, we introduce a computational step
that recursively re-weights scores based on featuresâ€™ redundancies and relevance when they are present in interactions.
The motivation for this comes from one of our major use cases for OutRank, speeding up the AutoML algorithms for
model building. The idea/motivation is similar to mRMR [ 8] and similar [ 16] approaches but tailored to the use case of
fast non-myopic feature ranking for categorical data. Further, more recent work on fast-mRMR [ 9] also demonstrated
the scalability of this branch of algorithms, which is aligned with our findings/design. Re-weighting of features based on
redundancies is the motivation behind the so-called MRMR heuristic [ 16]. On the other hand, the reason for re-weighting
features based on the interaction relevance comes from the fact that the recommendation algorithms which we most
often use in AutoML (FM, FFM, DeepFM) favour features that, in interactions, generate strong signals.
To describe this heuristic, let us denote by Sğ‘–âˆˆRwithğ‘–âˆˆ{1,...,ğ‘}the scores of the features ğ‘“ğ‘–,ğ‘–âˆˆ{1,...,ğ‘}
computed by CardMI heuristic compared to the target. Furthermore, let Rğ‘–,ğ‘—âˆˆRdenote the CardMI scores where ğ‘…ğ‘–,ğ‘—
is the score of ğ‘“ğ‘–with respect to ğ‘“ğ‘—. Finally, letCğ‘–,ğ‘—âˆˆRdenote the CardMI scores of the interaction ğ‘“ğ‘–,ğ‘“ğ‘—with respect to
1https://github.com/Cyan4973/xxHash
Manuscript submitted to ACM

--- PAGE 5 ---
OutRank: Speeding up AutoML-based Model Search 5
the target. Then the formula for the 3MR ranking can be given as a re-indexation (bijection) ğ¹:{1,...,ğ‘}â†’{ 1,...,ğ‘}
such thatğ‘“ğ‘–is a higher ranked feature than ğ‘“ğ‘—, ifğ‘–<ğ‘—. The heuristic can be computed iteratively by first considering
ğ¹(0)=argmax
ğ‘–=1,...,ğ‘(Sğ‘–), followed by
ğœ‚=ğ¹(ğ‘–)= argmax
ğ‘—âˆ‰ğ¹âˆ’1{1,...,ğ‘–âˆ’1}Featureâ€™s scorez}|{
Sğ¹(ğ‘—)âˆ’ğ›¼Â·SF
{Rğ‘—,ğ‘˜}ğ‘˜âˆˆğ¹âˆ’1{1,...,ğ‘–âˆ’1}
|                                 {z                                 }
Redundancy information+ğ›½Â·SF
{Cğ‘—,ğ‘˜}ğ‘˜âˆˆğ¹âˆ’1{1,...,ğ‘–âˆ’1}
|                                {z                                }
Relational information
,
where(ğ‘†ğ¹)is a statistical function (e.g. mean, median, sum) and ğ›¼,ğ›½>0are hyper-parameters. Note that the set
ğ¹âˆ’1{1,...,ğ‘–âˆ’1}denotes all the features ranked above (better than) ğ‘–and in ( 2) this corresponds to all already computed
features. Also, note that setting ğ›½=0brings us to the MRMR heuristic and setting ğ›¼=0makes the heuristic ignore
redundancies and only consider relational information.
3 EVALUATION
To evaluate the feasibility of the presented ideas, we conducted two sets of experiments designed to illustrate the
methodsâ€™ capabilities. First, we consider the common data mining scenario where a practitioner considers existing
state-of-the-art AutoML tools for solving a given learning (classification in this case) task at hand â€“ we considered
TPOT [ 7] system and explored CardMI â€™s capability to speed it up by pruning irrelevant part of the space before model
search. The second part of the evaluation concerns using the presented work on a real-life production AutoML, where
the amounts of data are greater, and the amount of time spent on feature search sufficient to identify suitable models
can only be achieved in a distributed computing environment (>10 machines running model search). We next discuss
performance on a synthetic data set - speeding up state-of-the-art AutoML . The first experiment considers
a well-known data set built to profile the quality of feature ranking algorithms â€“ Madelon [ 3]. The data set consists
of 4,400 instances and 500 features; it is an artificial data set containing data points grouped in 32 clusters placed on
the vertices of a five-dimensional hypercube and randomly labelled +1 or -1. AutoML was re-run ten times (different
random seeds) for each proportion of data (incrementally more features) to evaluate the performance/time relation of
model search; each search was run for up to three generations with a population size of ten models. For this task, we
used the CardMI computed in batches of 4196 instances â€“ this is one of the most straightforward off-the-shelf use cases
applicable to many realistic scenarios. The results of more than two thousand AutoML runs are summarized in Figure 4.
The benchmark (Figure 2) illustrates the main motivation of this paper â€“ first, running more expensive AutoML was
only possible after the initial feature "pre-selection". Second, on many data sets, up to 50% time improvements were
observed if considering smaller feature space (performance obtained by AutoML was within the margin of 0.5% F1).
The experiment demonstrates that efficient feature ranking can serve as a viable initial step when considering more
expensive AutoML model search â€“ especially in higher-dimensional data sets, the performance benefits are substantial.
We proceed with the performance on a real-life use case â€“ click-through rate (CTR) model search . Apart from
data quality feature screening , OutRankâ€™s feature ranking heuristics are valuable for speeding up our AutoML search.
This can be done by dropping a proportion of irrelevant features and thus reducing the search space or by using
top-ranked features as the seed model , effectively skipping multiple generations of expensive AutoML search. To find
optimal heuristics, we need a data set with a sufficient number of features and a benchmark feature ranking showing
their importance for AutoML model-building procedure. Since such an open-source data set does not exist, we took 1.5
mio instances of subsampled production CTR training data with about 10% positive labels and 100 features. Features
Manuscript submitted to ACM

--- PAGE 6 ---
6 BlaÅ¾ Å krlj and BlaÅ¾ Mramor
0 20 40 60 80 100
Proportion of preserved features (%)020406080100Time proportion (w.r.t. all features) (%)
madelon
(a) Model search time w.r.t. size of the (pre-
pruned) feature space.
0 20 40 60 80 100
Proportion of preserved features (%)0.00.20.40.60.8AutoMLâ€™s performance ( F1)
(b) Relation between performances of best
model and size of considered feature space.
0 20 40 60 80 100
Proportion of time spent for model search w.r.t. slowest run (%)0.00.20.40.60.81.0F1Data (%)
0
10
20
30
40
50(c) Relation between F1 performance and
AutoMLâ€™s time to achieve it.
Fig. 2. Visualization of the impact of OutRank-based pruning on AutoMLâ€™s performance. Visualizations show distributions of compute
times and corresponding performances for various degrees of feature pruning (fewer features are considered right to left). Overall,
more than 3,000 AutoML runs were conducted (one point=one run), and indicate that up to 30% speedup can be obtained with
minimal-to-no loss of performance (a,b,c). Further, considering all features from the get-go can have substantial memory overhead
(requiring different hardware), offering another reason for fast feature pre-selection/denoising prior to more expensive AutoML-based
model search.
0 20 40 60 80
cumulate-recall-singlesrandom
MRMR(RF)-median ( Î±= 0.2;Î²= 0.0)
RF
3MR(RF)-median ( Î±= 0.0;Î²= 0.5)
MRMR(CardMI)-q90 ( Î±= 0.2;Î²= 0)
CardMI
3MR(CardMI)-mean ( Î±= 0.2;Î²= 1)
(a) Performance of 3MR for the task of approximating single
generation of search.
0 10 20 30 40 50 60
cumulate-recallrandom
RF
3MR(RF)-median ( Î±= 0.2;Î²= 0.5)
AutoML-SingleFeatureFMs
CardMI
MRMR(CardMI)-q90 ( Î±= 1.0;Î²= 0.0)
3MR(CardMI)-q90 ( Î±= 0.2;Î²= 0.5)(b) Performance of 3MR when approximating AutoML search
trace (each generation).
Fig. 3. Cumulative overview of the performance for two ranking tasks of interest. 3MR performs well for both tasks â€“ both redundancy
and relation/interaction ( ğ›¼,ğ›½)terms are non-zero, indicating that both types of information play a meaningful role during ranking.
were pre-selected to represent the heterogeneous nature of our data for the strength of their signal against the target,
their cardinality, their correlations to other features and their number of missing values. An AutoML model search
adding consecutively single features to a factorization machine gave us our main benchmark feature ranking (full
AutoML run ranking). Another helpful feature ranking is the results of a single AutoML run, i.e. ranking based on the
performance of a single-feature FM, which we currently use to speed up our search.
Data for OutRankâ€™s feature ranking heuristics was ten times subsampled AutoML data. The basic feature-
ranking heuristics that we compared were logistic regression (LR), random forest (RF), randomly shuffled (R) and above
mentioned CradMI. Furthermore, we compared MRMR and 3MR, which had the redundancies and relations computed
with CardMI (due to higher computational complexity), and the relevances computed with RF or CradMI. The SF
function in 3MR was mean, median or 90th percentile. The results can be seen in Figures 3 and 4. For each ğ‘–=1,...,100
we compare ranking ğºto a target ranking ğ¹based on recall ğ‘…ğ‘–:=#(ğ¹âˆ’1(1,...,ğ‘–)âˆ©ğºâˆ’1(1,...,ğ‘–))
ğ‘–,as in Fig. 4. Furthermore, by
Manuscript submitted to ACM

--- PAGE 7 ---
OutRank: Speeding up AutoML-based Model Search 7
0 20 40 60 80 100
Consequent generation in search0.00.20.40.60.81.0recall index@k
heuristic
MRMR(CardMI)
random
3MR(CardMI)-mean
3MR(CardMI)-median
MRMR(RF)
3MR(RF)-median
3MR(CardMI)-q90
CardMI
LogisticRegression-based
RandomForest-based
(a) Approximating a single AutoML generation (single-feature
factorization machines) with different ranking algorithms.
0 5 10 15 20 25 30 35
Consequent generation in search0.00.10.20.30.40.50.6cropped index@k
heuristic
MRMR(CardMI)
random
3MR(CardMI)-mean
3MR(CardMI)-median
MRMR(RF)
3MR(RF)-median
3MR(CardMI)-q90
CardMI
LogisticRegression-based
AutoML-SingleFeatureFMs
RandomForest-based(b) Approximating top features for each generation of model
search with different feature ranking algorithms.
Fig. 4. Visualizations showing the potential of 3MR heuristic (computed as part of OutRank) for approximating computationally
expensive in-house AutoML-based search. Subfigure (a) demonstrates that up to 20 features can be reliably retrieved via feature
ranking. Subfigure (b) demonstrates that approximating the full trace of model search (multiple generations) is a hard problem, where
proposed feature ranking heuristics perform better than AutoML if run only for a single generation.
taking the sum over ğ‘…:=Ã
ğ‘–ğ‘…ğ‘–, we get a general ranking for each heuristic compared to the benchmark, as in Fig. 3.
From Fig. 3a and b, we can see that against both benchmarks CardMI heuristic outperforms RF and that 3MR with the
weight of the relation ( ğ›½) larger than the redundancies weight ( ğ›¼) further improves the ranking. For full AutoML run
benchmark, on the other hand, MRMR already has a better performance than CardMI, and 3MR is even better. For single
AutoML run benchmark MRMR is slightly worse, while 3MR with a large ğ›½is better. Considering only redundancies
gives a worse result in line with expectations since the single AutoML run benchmark is myopic by nature. Figure 4
shows insights into performance of different heuristics on subsets of features. The results confirm our intuition that
adding redundancies and relations in the computation of feature ranking for AutoML improves the performance of the
ranking heuristic. For our use-case, the proposed 3MR algorithm offers a good trade-off between speed/performance,
even if compared against strong baselines.
4 CONCLUSIONS AND FURTHER WORK
This work explored whether simple hash-based encoding can offer added value in profiling interaction. Hash-based
encoding is a simple and efficient technique that allows us to encode the interaction between two or more features into
a single feature. We demonstrated that CardMI heuristic, a variant of mutual information that incorporates featuresâ€™
cardinalities, offers pruned feature space that enables up to 30% faster AutoML model search (TPOT) with no loss of
performance and up to 50% faster search with minimal performance loss ( â‰ˆ0.5% F1). Our results showed that even with
simple hash-based encoding, we were able to achieve significant improvements in feature ranking compared to existing
methods â€“ including strong baselines such as Random Forest-based ranking. However, there are more complex schemes
for encoding interactions that are also possible. For example, negations and conditionals instead of simple conjunctions
can give rise to more complex features that are currently out of reach and might further boost the performance of
feature profiling. The potential benefits of these more complex schemes for encoding interactions are clear, but they
also come with added computational costs. The source of OutRank will be made available upon concluded internal
review required for its release2.
2https://github.com/outbrain/outrank
Manuscript submitted to ACM

--- PAGE 8 ---
8 BlaÅ¾ Å krlj and BlaÅ¾ Mramor
REFERENCES
[1]Zeynep Batmaz, Ali Yurekli, Alper Bilge, and Cihan Kaleli. 2019. A review on deep learning for recommender systems: challenges and remedies.
Artificial Intelligence Review 52 (2019), 1â€“37.
[2] Leo Breiman. 2001. Random forests. Machine learning 45 (2001), 5â€“32.
[3] Isabelle Guyon, Steve Gunn, Masoud Nikravesh, and Lofti A Zadeh. 2008. Feature extraction: foundations and applications . Vol. 207. Springer.
[4] Xin He, Kaiyong Zhao, and Xiaowen Chu. 2021. AutoML: A survey of the state-of-the-art. Knowledge-Based Systems 212 (2021), 106622.
[5]Alexander Kraskov, Harald StÃ¶gbauer, and Peter Grassberger. 2011. Erratum: estimating mutual information [Phys. Rev. E 69, 066138 (2004)].
Physical Review E 83, 1 (2011), 019903.
[6]Lili Liu, Lei Chen, Yu-Hang Zhang, Lai Wei, Shiwen Cheng, Xiangyin Kong, Mingyue Zheng, Tao Huang, and Yu-Dong Cai. 2017. Analysis and
prediction of drugâ€“drug interaction by minimum redundancy maximum relevance and incremental feature selection. Journal of Biomolecular
Structure and Dynamics 35, 2 (2017), 312â€“329.
[7]Laurent Parmentier, Olivier Nicol, Laetitia Jourdan, and Marie-ElÃ©onore Kessaci. 2019. Tpot-sh: A faster optimization algorithm to solve the automl
problem on large datasets. In 2019 IEEE 31st International Conference on Tools with Artificial Intelligence (ICTAI) . IEEE, 471â€“478.
[8]Hanchuan Peng, Fuhui Long, and Chris Ding. 2005. Feature selection based on mutual information criteria of max-dependency, max-relevance, and
min-redundancy. IEEE Transactions on pattern analysis and machine intelligence 27, 8 (2005), 1226â€“1238.
[9]Sergio RamÃ­rez-Gallego, Iago Lastra, David MartÃ­nez-Rego, VerÃ³nica BolÃ³n-Canedo, JosÃ© Manuel BenÃ­tez, Francisco Herrera, and Amparo Alonso-
Betanzos. 2017. Fast-mRMR: Fast minimum redundancy maximum relevance algorithm for high-dimensional big data. International Journal of
Intelligent Systems 32, 2 (2017), 134â€“152.
[10] Steffen Rendle. 2010. Factorization machines. In 2010 IEEE International conference on data mining . IEEE, 995â€“1000.
[11] Lars Ropeid Selsaas, Bikash Agrawal, Chumming Rong, and Thomasz Wiktorski. 2015. AFFM: Auto feature engineering in field-aware factorization
machines for predictive analytics. In 2015 IEEE International Conference on Data Mining Workshop (ICDMW) . IEEE, 1705â€“1709.
[12] Kunal Shah, Akshaykumar Salunke, Saurabh Dongare, and Kisandas Antala. 2017. Recommender systems: An overview of different approaches to
recommendations. In 2017 International Conference on Innovations in Information, Embedded and Communication Systems (ICIIECS) . IEEE, 1â€“4.
[13] Razieh Sheikhpour. 2023. A local spline regression-based framework for semi-supervised sparse feature selection. Knowledge-Based Systems (2023),
110265.
[14] B Venkatesh and J Anuradha. 2019. A review of feature selection and its methods. Cybernetics and information technologies 19, 1 (2019), 3â€“26.
[15] Jialei Wang, Peilin Zhao, Steven CH Hoi, and Rong Jin. 2013. Online feature selection and its applications. IEEE Transactions on knowledge and data
engineering 26, 3 (2013), 698â€“710.
[16] Zhenyu Zhao, Radhika Anand, and Mallory Wang. 2019. Maximum relevance and minimum redundancy feature selection methods for a marketing
machine learning platform. In 2019 IEEE international conference on data science and advanced analytics (DSAA) . IEEE, 442â€“452.
[17] Ruiqi Zheng, Liang Qu, Bin Cui, Yuhui Shi, and Hongzhi Yin. 2023. AutoML for Deep Recommender Systems: A Survey. ACM Transactions on
Information Systems (2023).
Manuscript submitted to ACM

# 2111.00083.pdf
# Chuyá»ƒn Ä‘á»•i tá»« PDF sang TXT
# ÄÆ°á»ng dáº«n nguá»“n: /home/admin88/arxiv-downloader/automl-nas/2111.00083.pdf
# KÃ­ch thÆ°á»›c tá»‡p: 2754448 bytes

===============================================
Ná»˜I DUNG Tá»†P PDF
===============================================


--- TRANG 1 ---
Má»™t PhÆ°Æ¡ng PhÃ¡p AutoML CÃ³ Thá»ƒ Má»Ÿ Rá»™ng Dá»±a trÃªn Máº¡ng NÆ¡-ron Äá»“ Thá»‹
Mossad Helaliâˆ—, Essam Mansourâˆ—, Ibrahim AbdelazizÂ§, Julian DolbyÂ§, Kavitha SrinivasÂ§
âˆ—Äáº¡i há»c ConcordiaÂ§IBM Research AI
Montreal, Canada New York, US
{fname}.{lname}@concordia.ca,ibrahim.abdelaziz1,dolby,Kavitha.Srinivas@ibm.com
TÃ“M Táº®T
CÃ¡c há»‡ thá»‘ng AutoML xÃ¢y dá»±ng cÃ¡c mÃ´ hÃ¬nh há»c mÃ¡y má»™t cÃ¡ch tá»± Ä‘á»™ng báº±ng cÃ¡ch thá»±c hiá»‡n tÃ¬m kiáº¿m trÃªn cÃ¡c phÃ©p biáº¿n Ä‘á»•i dá»¯ liá»‡u vÃ  bá»™ há»c há»£p lá»‡, cÃ¹ng vá»›i tá»‘i Æ°u hÃ³a siÃªu tham sá»‘ cho má»—i bá»™ há»c. Nhiá»u há»‡ thá»‘ng AutoML sá»­ dá»¥ng meta-learning Ä‘á»ƒ hÆ°á»›ng dáº«n tÃ¬m kiáº¿m cÃ¡c pipeline tá»‘i Æ°u. Trong cÃ´ng trÃ¬nh nÃ y, chÃºng tÃ´i trÃ¬nh bÃ y má»™t há»‡ thá»‘ng meta-learning má»›i cÃ³ tÃªn KGpip, nÃ³ (1) xÃ¢y dá»±ng cÆ¡ sá»Ÿ dá»¯ liá»‡u cÃ¡c táº­p dá»¯ liá»‡u vÃ  cÃ¡c pipeline tÆ°Æ¡ng á»©ng báº±ng cÃ¡ch khai thÃ¡c hÃ ng nghÃ¬n script vá»›i phÃ¢n tÃ­ch chÆ°Æ¡ng trÃ¬nh, (2) sá»­ dá»¥ng embedding táº­p dá»¯ liá»‡u Ä‘á»ƒ tÃ¬m cÃ¡c táº­p dá»¯ liá»‡u tÆ°Æ¡ng tá»± trong cÆ¡ sá»Ÿ dá»¯ liá»‡u dá»±a trÃªn ná»™i dung thay vÃ¬ cÃ¡c Ä‘áº·c trÆ°ng dá»±a trÃªn metadata, (3) mÃ´ hÃ¬nh hÃ³a viá»‡c táº¡o pipeline AutoML nhÆ° má»™t bÃ i toÃ¡n sinh Ä‘á»“ thá»‹, Ä‘á»ƒ Ä‘áº·c trÆ°ng hÃ³a má»™t cÃ¡ch ngáº¯n gá»n cÃ¡c pipeline Ä‘a dáº¡ng Ä‘Æ°á»£c tháº¥y cho má»™t táº­p dá»¯ liá»‡u duy nháº¥t.
Meta-learning cá»§a KGpip lÃ  má»™t thÃ nh pháº§n con cho cÃ¡c há»‡ thá»‘ng AutoML. ChÃºng tÃ´i chá»©ng minh Ä‘iá»u nÃ y báº±ng cÃ¡ch tÃ­ch há»£p KGpip vá»›i hai há»‡ thá»‘ng AutoML.
ÄÃ¡nh giÃ¡ toÃ n diá»‡n cá»§a chÃºng tÃ´i sá»­ dá»¥ng 121 táº­p dá»¯ liá»‡u, bao gá»“m cÃ¡c táº­p dá»¯ liá»‡u Ä‘Æ°á»£c sá»­ dá»¥ng bá»Ÿi cÃ¡c há»‡ thá»‘ng tiÃªn tiáº¿n, cho tháº¥y KGpip vÆ°á»£t trá»™i Ä‘Ã¡ng ká»ƒ so vá»›i cÃ¡c há»‡ thá»‘ng nÃ y.

Äá»‹nh dáº¡ng Tham kháº£o PVLDB:
Mossad Helaliâˆ—, Essam Mansourâˆ—, Ibrahim AbdelazizÂ§, Julian DolbyÂ§,
Kavitha SrinivasÂ§. Má»™t PhÆ°Æ¡ng PhÃ¡p AutoML CÃ³ Thá»ƒ Má»Ÿ Rá»™ng Dá»±a trÃªn Máº¡ng NÆ¡-ron Äá»“ Thá»‹. PVLDB, 14(1): XXX-XXX, 2020.
doi:XX.XX/XXX.XX

TÃ­nh sáºµn cÃ³ Artifact PVLDB:
MÃ£ nguá»“n, dá»¯ liá»‡u, vÃ /hoáº·c cÃ¡c artifact khÃ¡c Ä‘Ã£ Ä‘Æ°á»£c cung cáº¥p táº¡i
https://github.com/CoDS-GCS/kgpip-public.

1 GIá»šI THIá»†U
AutoML lÃ  quÃ¡ trÃ¬nh mÃ  cÃ¡c mÃ´ hÃ¬nh há»c mÃ¡y Ä‘Æ°á»£c xÃ¢y dá»±ng tá»± Ä‘á»™ng cho má»™t táº­p dá»¯ liá»‡u má»›i. Vá»›i má»™t táº­p dá»¯ liá»‡u, cÃ¡c há»‡ thá»‘ng AutoML thá»±c hiá»‡n tÃ¬m kiáº¿m trÃªn cÃ¡c phÃ©p biáº¿n Ä‘á»•i dá»¯ liá»‡u vÃ  bá»™ há»c há»£p lá»‡, cÃ¹ng vá»›i tá»‘i Æ°u hÃ³a siÃªu tham sá»‘ cho má»—i bá»™ há»c [ 17].
Viá»‡c chá»n cÃ¡c phÃ©p biáº¿n Ä‘á»•i vÃ  bá»™ há»c Ä‘á»ƒ tÃ¬m kiáº¿m lÃ  trá»ng tÃ¢m cá»§a chÃºng tÃ´i. Má»™t sá»‘ lÆ°á»£ng Ä‘Ã¡ng ká»ƒ cÃ¡c há»‡ thá»‘ng khai thÃ¡c tá»« cÃ¡c láº§n cháº¡y trÆ°á»›c cá»§a pipeline trÃªn má»™t táº­p cÃ¡c táº­p dá»¯ liá»‡u Ä‘á»ƒ chá»n cÃ¡c transformer vÃ  bá»™ há»c hiá»‡u quáº£ vá»›i cÃ¡c loáº¡i táº­p dá»¯ liá»‡u khÃ¡c nhau (vÃ­ dá»¥ [ 10], [32], [9]). Do Ä‘Ã³, chÃºng xÃ¢y dá»±ng má»™t cÆ¡ sá»Ÿ dá»¯ liá»‡u báº±ng cÃ¡ch thá»±c sá»± cháº¡y cÃ¡c pipeline khÃ¡c nhau vá»›i má»™t táº­p cÃ¡c táº­p dá»¯ liá»‡u Ä‘a dáº¡ng Ä‘á»ƒ Æ°á»›c lÆ°á»£ng Ä‘á»™ chÃ­nh xÃ¡c cá»§a cÃ¡c pipeline tiá»m nÄƒng. VÃ¬ váº­y, chÃºng cÃ³ thá»ƒ Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ giáº£m hiá»‡u quáº£ khÃ´ng gian tÃ¬m kiáº¿m. Má»™t táº­p dá»¯ liá»‡u má»›i, dá»±a trÃªn má»™t táº­p cÃ¡c Ä‘áº·c trÆ°ng (meta-features) sau Ä‘Ã³ Ä‘Æ°á»£c khá»›p vá»›i cÆ¡ sá»Ÿ dá»¯ liá»‡u nÃ y Ä‘á»ƒ tÃ¬m cÃ¡c á»©ng viÃªn kháº£ thi nháº¥t

CÃ´ng trÃ¬nh nÃ y Ä‘Æ°á»£c cáº¥p phÃ©p theo Giáº¥y phÃ©p Quá»‘c táº¿ Creative Commons BY-NC-ND 4.0. Truy cáº­p https://creativecommons.org/licenses/by-nc-nd/4.0/ Ä‘á»ƒ xem báº£n sao cá»§a giáº¥y phÃ©p nÃ y. Äá»‘i vá»›i báº¥t ká»³ sá»­ dá»¥ng nÃ o vÆ°á»£t quÃ¡ nhá»¯ng gÃ¬ Ä‘Æ°á»£c bao gá»“m bá»Ÿi giáº¥y phÃ©p nÃ y, hÃ£y xin phÃ©p báº±ng cÃ¡ch gá»­i email tá»›i info@vldb.org. Báº£n quyá»n thuá»™c sá»Ÿ há»¯u cá»§a chá»§ sá»Ÿ há»¯u/tÃ¡c giáº£. Quyá»n xuáº¥t báº£n Ä‘Æ°á»£c cáº¥p phÃ©p cho VLDB Endowment.
Ká»· yáº¿u cá»§a VLDB Endowment, Vol. 14, No. 1 ISSN 2150-8097.
doi:XX.XX/XXX.XX cho cáº£ viá»‡c lá»±a chá»n bá»™ há»c vÃ  Ä‘iá»u chá»‰nh siÃªu tham sá»‘.
QuÃ¡ trÃ¬nh chá»n Ä‘iá»ƒm báº¯t Ä‘áº§u trong khÃ´ng gian tÃ¬m kiáº¿m nÃ y Ä‘Æ°á»£c gá»i lÃ  meta-learning cho váº¥n Ä‘á» khá»Ÿi Ä‘á»™ng láº¡nh.

CÃ¡c phÆ°Æ¡ng phÃ¡p meta-learning khÃ¡c bao gá»“m khai thÃ¡c mÃ£ data science hiá»‡n cÃ³ vÃ  cÃ¡c táº­p dá»¯ liá»‡u liÃªn quan Ä‘á»ƒ há»c tá»« chuyÃªn mÃ´n con ngÆ°á»i. Há»‡ thá»‘ng AL [ 2] Ä‘Ã£ khai thÃ¡c cÃ¡c notebook Kaggle hiá»‡n cÃ³ báº±ng phÃ¢n tÃ­ch Ä‘á»™ng, tá»©c lÃ  thá»±c sá»± cháº¡y cÃ¡c script, vÃ  cho tháº¥y ráº±ng má»™t há»‡ thá»‘ng nhÆ° váº­y cÃ³ tiá»m nÄƒng. Tuy nhiÃªn, phÆ°Æ¡ng phÃ¡p meta-learning nÃ y khÃ´ng thá»ƒ má»Ÿ rá»™ng vÃ¬ viá»‡c thá»±c thi má»™t sá»‘ lÆ°á»£ng lá»›n script pipeline trÃªn cÃ¡c táº­p dá»¯ liá»‡u lÃ  khÃ³ khÄƒn, tiá»n xá»­ lÃ½ cÃ¡c táº­p dá»¯ liá»‡u khÃ´ng bao giá» Ä‘Æ¡n giáº£n, vÃ  cÃ¡c script cÅ© hÆ¡n ngá»«ng cháº¡y hoÃ n toÃ n khi pháº§n má»m phÃ¡t triá»ƒn. KhÃ´ng ngáº¡c nhiÃªn khi AL do Ä‘Ã³ chá»‰ thá»±c hiá»‡n phÃ¢n tÃ­ch Ä‘á»™ng trÃªn chÃ­n táº­p dá»¯ liá»‡u.

Há»‡ thá»‘ng cá»§a chÃºng tÃ´i, KGpip, cung cáº¥p má»™t phÆ°Æ¡ng phÃ¡p meta-learning cÃ³ thá»ƒ má»Ÿ rá»™ng Ä‘á»ƒ táº­n dá»¥ng chuyÃªn mÃ´n con ngÆ°á»i, sá»­ dá»¥ng phÃ¢n tÃ­ch tÄ©nh Ä‘á»ƒ khai thÃ¡c pipeline tá»« cÃ¡c kho lÆ°u trá»¯ lá»›n cÃ¡c script. PhÃ¢n tÃ­ch tÄ©nh cÃ³ Æ°u Ä‘iá»ƒm má»Ÿ rá»™ng Ä‘áº¿n hÃ ng nghÃ¬n hoáº·c hÃ ng triá»‡u script [ 1] má»™t cÃ¡ch dá»… dÃ ng, nhÆ°ng thiáº¿u dá»¯ liá»‡u hiá»‡u suáº¥t Ä‘Æ°á»£c thu tháº­p bá»Ÿi phÃ¢n tÃ­ch Ä‘á»™ng. PhÆ°Æ¡ng phÃ¡p meta-learning KGpip hÆ°á»›ng dáº«n quÃ¡ trÃ¬nh há»c báº±ng tÃ¬m kiáº¿m Ä‘á»™ tÆ°Æ¡ng tá»± táº­p dá»¯ liá»‡u cÃ³ thá»ƒ má»Ÿ rá»™ng, dá»±a trÃªn embedding táº­p dá»¯ liá»‡u, Ä‘á»ƒ tÃ¬m cÃ¡c táº­p dá»¯ liá»‡u tÆ°Æ¡ng tá»± nháº¥t vÃ  ngá»¯ nghÄ©a cá»§a cÃ¡c pipeline ML Ä‘Æ°á»£c Ã¡p dá»¥ng trÃªn chÃºng.

Nhiá»u há»‡ thá»‘ng hiá»‡n cÃ³, nhÆ° Auto-Sklearn [ 9] vÃ  AL [ 2], tÃ­nh toÃ¡n má»™t táº­p cÃ¡c meta-features cho má»—i táº­p dá»¯ liá»‡u. ChÃºng tÃ´i Ä‘Ã£ phÃ¡t triá»ƒn má»™t mÃ´ hÃ¬nh máº¡ng nÆ¡-ron sÃ¢u Ä‘á»ƒ táº¡o embedding á»Ÿ má»©c Ä‘á»™ chi tiáº¿t cá»§a má»™t táº­p dá»¯ liá»‡u, vÃ­ dá»¥, má»™t báº£ng hoáº·c tá»‡p CSV, Ä‘á»ƒ náº¯m báº¯t Ä‘á»™ tÆ°Æ¡ng tá»± á»Ÿ cáº¥p Ä‘á»™ cá»§a toÃ n bá»™ táº­p dá»¯ liá»‡u thay vÃ¬ dá»±a vÃ o má»™t táº­p cÃ¡c meta-features.

Bá»Ÿi vÃ¬ chÃºng tÃ´i sá»­ dá»¥ng phÃ¢n tÃ­ch tÄ©nh Ä‘á»ƒ náº¯m báº¯t ngá»¯ nghÄ©a cá»§a quÃ¡ trÃ¬nh meta-learning, chÃºng tÃ´i khÃ´ng cÃ³ cÆ¡ cháº¿ Ä‘á»ƒ chá»n pipeline tá»‘t nháº¥t tá»« nhiá»u pipeline Ä‘Ã£ tháº¥y, khÃ´ng giá»‘ng nhÆ° trÆ°á»ng há»£p thá»±c thi Ä‘á»™ng nÆ¡i ngÆ°á»i ta cÃ³ thá»ƒ dá»±a vÃ o runtime Ä‘á»ƒ chá»n pipeline hiá»‡u suáº¥t tá»‘t nháº¥t. Quan sÃ¡t ráº±ng cÃ¡c pipeline vá» cÆ¡ báº£n lÃ  cÃ¡c Ä‘á»“ thá»‹ quy trÃ¬nh cÃ´ng viá»‡c, chÃºng tÃ´i sá»­ dá»¥ng cÃ¡c mÃ´ hÃ¬nh nÆ¡-ron sinh Ä‘á»“ thá»‹ Ä‘á»ƒ náº¯m báº¯t má»™t cÃ¡ch ngáº¯n gá»n cÃ¡c pipeline Ä‘Æ°á»£c quan sÃ¡t tÄ©nh cho má»™t táº­p dá»¯ liá»‡u duy nháº¥t. Trong KGpip, chÃºng tÃ´i xÃ¢y dá»±ng viá»‡c lá»±a chá»n bá»™ há»c nhÆ° má»™t bÃ i toÃ¡n sinh Ä‘á»“ thá»‹ Ä‘á»ƒ dá»± Ä‘oÃ¡n cÃ¡c pipeline tá»‘i Æ°u dá»±a trÃªn cÃ¡c pipeline Ä‘Æ°á»£c tháº¥y trong cÃ¡c notebook thá»±c táº¿.

KGpip thá»±c hiá»‡n lá»±a chá»n bá»™ há»c vÃ  phÃ©p biáº¿n Ä‘á»•i, vÃ  do Ä‘Ã³ lÃ  má»™t thÃ nh pháº§n cá»§a cÃ¡c há»‡ thá»‘ng AutoML. Äá»ƒ Ä‘Ã¡nh giÃ¡ thÃ nh pháº§n nÃ y, chÃºng tÃ´i Ä‘Ã£ tÃ­ch há»£p nÃ³ vÃ o hai há»‡ thá»‘ng AutoML hiá»‡n cÃ³, FLAML [ 30] vÃ  Auto-Sklearn [ 9]. ChÃºng tÃ´i chá»n FLAML vÃ¬ nÃ³ chÆ°a cÃ³ báº¥t ká»³ thÃ nh pháº§n meta-learning nÃ o cho váº¥n Ä‘á» khá»Ÿi Ä‘á»™ng láº¡nh vÃ  thay vÃ o Ä‘Ã³ cho phÃ©p ngÆ°á»i dÃ¹ng lá»±a chá»n bá»™ há»c vÃ  transformer. CÃ¡c tÃ¡c giáº£ cá»§a FLAML Ä‘Ã£ chá»‰ ra rÃµ rÃ ng ráº±ng FLAML cÃ³ thá»ƒ hÆ°á»Ÿng lá»£i tá»« má»™t thÃ nh pháº§n meta-learning vÃ  chá»‰ ra nÃ³ nhÆ° má»™t kháº£ nÄƒng cho cÃ´ng viá»‡c tÆ°Æ¡ng lai. Äá»‘i vá»›i FLAML, náº¿u viá»‡c khai thÃ¡c cÃ¡c pipeline lá»‹ch sá»­ cung cáº¥p má»™t lá»£i tháº¿, chÃºng tÃ´i nÃªn cáº£i thiá»‡n hiá»‡u suáº¥t cá»§a nÃ³. ChÃºng tÃ´i cÅ©ng chá»n Auto-Sklearn vÃ¬ nÃ³ cÃ³ má»™t thÃ nh pháº§n lá»±a chá»n bá»™ há»c dá»±a trÃªn meta-features, nhÆ° Ä‘Æ°á»£c mÃ´ táº£ trÆ°á»›c Ä‘Ã³ [ 8]. Äá»‘i vá»›i Auto-Sklearn, chÃºng tÃ´i Ã­t nháº¥t nÃªn khá»›p hiá»‡u suáº¥t náº¿u viá»‡c khai thÃ¡c tÄ©nh pipeline cá»§a chÃºng tÃ´i arXiv:2111.00083v4  [cs.LG]  14 Jul 2022

--- TRANG 2 ---
cÃ³ thá»ƒ khá»›p vá»›i cÆ¡ sá»Ÿ dá»¯ liá»‡u rá»™ng lá»›n cá»§a há». Äá»ƒ cÃ³ bá»‘i cáº£nh, chÃºng tÃ´i cÅ©ng so sÃ¡nh KGpip vá»›i VolcanoML gáº§n Ä‘Ã¢y [ 17], cung cáº¥p má»™t chiáº¿n lÆ°á»£c phÃ¢n rÃ£ vÃ  thá»±c thi hiá»‡u quáº£ cho khÃ´ng gian tÃ¬m kiáº¿m AutoML.
NgÆ°á»£c láº¡i, KGpip cáº¯t tá»‰a khÃ´ng gian tÃ¬m kiáº¿m báº±ng mÃ´ hÃ¬nh meta-learning cá»§a chÃºng tÃ´i Ä‘á»ƒ thá»±c hiá»‡n tá»‘i Æ°u hÃ³a siÃªu tham sá»‘ chá»‰ cho cÃ¡c á»©ng viÃªn há»©a háº¹n nháº¥t.

Nhá»¯ng Ä‘Ã³ng gÃ³p cá»§a bÃ i bÃ¡o nÃ y nhÆ° sau:
â€¢Má»¥c 3 Ä‘á»‹nh nghÄ©a má»™t phÆ°Æ¡ng phÃ¡p meta-learning cÃ³ thá»ƒ má»Ÿ rá»™ng dá»±a trÃªn viá»‡c há»c biá»ƒu diá»…n cá»§a ngá»¯ nghÄ©a pipeline ML Ä‘Ã£ khai thÃ¡c vÃ  cÃ¡c táº­p dá»¯ liá»‡u cho hÆ¡n 100 táº­p dá»¯ liá»‡u vÃ  11K script Python.
â€¢Má»¥c 4 xÃ¢y dá»±ng viá»‡c sinh pipeline AutoML nhÆ° má»™t bÃ i toÃ¡n sinh Ä‘á»“ thá»‹. KGpip dá»± Ä‘oÃ¡n hiá»‡u quáº£ má»™t pipeline ML tá»‘i Æ°u cho má»™t táº­p dá»¯ liá»‡u chÆ°a tháº¥y dá»±a trÃªn mÃ´ hÃ¬nh meta-learning cá»§a chÃºng tÃ´i. Theo hiá»ƒu biáº¿t tá»‘t nháº¥t cá»§a chÃºng tÃ´i, KGpip lÃ  phÆ°Æ¡ng phÃ¡p Ä‘áº§u tiÃªn xÃ¢y dá»±ng viá»‡c sinh pipeline AutoML theo cÃ¡ch nhÆ° váº­y.
â€¢Má»¥c 5 trÃ¬nh bÃ y má»™t Ä‘Ã¡nh giÃ¡ toÃ n diá»‡n sá»­ dá»¥ng má»™t bá»™ sÆ°u táº­p lá»›n 121 táº­p dá»¯ liá»‡u tá»« cÃ¡c benchmark AutoML chÃ­nh vÃ  Kaggle. Káº¿t quáº£ thá»±c nghiá»‡m cá»§a chÃºng tÃ´i cho tháº¥y KGpip vÆ°á»£t trá»™i táº¥t cáº£ cÃ¡c há»‡ thá»‘ng AutoML hiá»‡n cÃ³ vÃ  Ä‘áº¡t Ä‘Æ°á»£c káº¿t quáº£ tiÃªn tiáº¿n trÃªn pháº§n lá»›n cÃ¡c táº­p dá»¯ liá»‡u nÃ y. KGpip cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ hiá»‡u suáº¥t cá»§a cáº£ FLAML vÃ  Auto-Sklearn trong cÃ¡c tÃ¡c vá»¥ phÃ¢n loáº¡i vÃ  há»“i quy. ChÃºng tÃ´i cÅ©ng vÆ°á»£t trá»™i AL trong 75 trong sá»‘ 77 táº­p dá»¯ liá»‡u vÃ  VolcanoML trong 75 trong sá»‘ 121 táº­p dá»¯ liá»‡u, bao gá»“m 44 táº­p dá»¯ liá»‡u chá»‰ Ä‘Æ°á»£c sá»­ dá»¥ng bá»Ÿi VolcanoML [ 17]. Trung bÃ¬nh, KGpip Ä‘áº¡t Ä‘Æ°á»£c Ä‘iá»ƒm sá»‘ tá»‘t hÆ¡n vá» máº·t thá»‘ng kÃª so vá»›i trung bÃ¬nh cá»§a táº¥t cáº£ cÃ¡c há»‡ thá»‘ng khÃ¡c.

2 CÃ”NG TRÃŒNH LIÃŠN QUAN
Trong má»¥c nÃ y, chÃºng tÃ´i tÃ³m táº¯t cÃ´ng trÃ¬nh liÃªn quan vÃ  giá»›i háº¡n Ä‘Ã¡nh giÃ¡ cá»§a chÃºng tÃ´i Ä‘áº¿n cÃ¡c phÆ°Æ¡ng phÃ¡p meta-learning cho AutoML, embedding táº­p dá»¯ liá»‡u, vÃ  xá»­ lÃ½ dá»¯ liá»‡u cÃ³ cáº¥u trÃºc dáº¡ng báº£ng.

Lá»±a chá»n bá»™ há»c vÃ  tiá»n xá»­ lÃ½. Trong háº§u háº¿t cÃ¡c há»‡ thá»‘ng AutoML, viá»‡c lá»±a chá»n bá»™ há»c vÃ  tiá»n xá»­ lÃ½ cho váº¥n Ä‘á» khá»Ÿi Ä‘á»™ng láº¡nh Ä‘Æ°á»£c Ä‘iá»u khiá»ƒn bá»Ÿi má»™t cÆ¡ sá»Ÿ dá»¯ liá»‡u cÃ¡c láº§n thá»±c thi thá»±c táº¿ cá»§a pipeline vÃ  dá»¯ liá»‡u; vÃ­ dá»¥, [ 2], [9], [10]. CÆ¡ sá»Ÿ dá»¯ liá»‡u nÃ y thÆ°á»ng Ä‘iá»u khiá»ƒn cáº£ viá»‡c lá»±a chá»n bá»™ há»c vÃ  tá»‘i Æ°u hÃ³a siÃªu tham sá»‘ (HPO), vÃ¬ váº­y chÃºng tÃ´i táº­p trung á»Ÿ Ä‘Ã¢y nhiá»u hÆ¡n vÃ o cÃ¡ch cÆ¡ sá»Ÿ dá»¯ liá»‡u Ä‘Æ°á»£c thu tháº­p hoáº·c Ã¡p dá»¥ng cho má»™t trong hai váº¥n Ä‘á», vÃ¬ viá»‡c Ã¡p dá»¥ng thá»±c táº¿ cho viá»‡c lá»±a chá»n bá»™ há»c hoáº·c HPO Ã­t liÃªn quan hÆ¡n. Äá»‘i vá»›i HPO, má»™t sá»‘ Ä‘Ã£ mÃ´ hÃ¬nh hÃ³a viá»‡c Ã¡p dá»¥ng cÆ¡ sá»Ÿ dá»¯ liá»‡u nhÆ° má»™t váº¥n Ä‘á» Ä‘a tÃ¡c vá»¥ (xem [ 26]), nÆ¡i cÃ¡c siÃªu tham sá»‘ cho khá»Ÿi Ä‘á»™ng láº¡nh Ä‘Æ°á»£c chá»n dá»±a trÃªn nhiá»u táº­p dá»¯ liá»‡u liÃªn quan. Nhá»¯ng ngÆ°á»i khÃ¡c, vÃ­ dá»¥, [ 9,25], tÃ­nh toÃ¡n má»™t cÆ¡ sá»Ÿ dá»¯ liá»‡u cÃ¡c meta-features táº­p dá»¯ liá»‡u trÃªn nhiá»u táº­p dá»¯ liá»‡u OpenML [28], bao gá»“m cÃ¡c thuá»™c tÃ­nh táº­p dá»¯ liá»‡u nhÆ° sá»‘ lÆ°á»£ng thuá»™c tÃ­nh sá»‘, sá»‘ lÆ°á»£ng máº«u hoáº·c Ä‘á»™ lá»‡ch cá»§a cÃ¡c Ä‘áº·c trÆ°ng trong má»—i táº­p dá»¯ liá»‡u.

Nhá»¯ng há»‡ thá»‘ng nÃ y Ä‘o Ä‘á»™ tÆ°Æ¡ng tá»± giá»¯a cÃ¡c táº­p dá»¯ liá»‡u vÃ  sá»­ dá»¥ng pipeline tá»« cÃ¡c táº­p dá»¯ liá»‡u gáº§n nháº¥t dá»±a trÃªn khoáº£ng cÃ¡ch giá»¯a cÃ¡c vector Ä‘áº·c trÆ°ng cá»§a táº­p dá»¯ liá»‡u nhÆ° chÃºng tÃ´i lÃ m, nhÆ°ng viá»‡c tÃ­nh toÃ¡n cÃ¡c vector nÃ y khÃ¡c nhau, nhÆ° chÃºng tÃ´i mÃ´ táº£ chi tiáº¿t dÆ°á»›i Ä‘Ã¢y. Auto-Sklearn 2.0 [8] thay vÃ o Ä‘Ã³ Ä‘á»‹nh nghÄ©a má»™t danh má»¥c tÄ©nh cÃ¡c pipeline hoáº¡t Ä‘á»™ng trÃªn nhiá»u táº­p dá»¯ liá»‡u Ä‘a dáº¡ng, vÃ  sá»­ dá»¥ng chÃºng Ä‘á»ƒ khá»Ÿi Ä‘á»™ng láº¡nh thÃ nh pháº§n lá»±a chá»n bá»™ há»c - nghÄ©a lÃ , má»i táº­p dá»¯ liá»‡u má»›i sá»­ dá»¥ng cÃ¹ng má»™t táº­p cÃ¡c pipeline. Nhá»¯ng ngÆ°á»i khÃ¡c Ä‘Ã£ táº¡o ra cÃ¡c ma tráº­n lá»›n ghi láº¡i hiá»‡u suáº¥t cá»§a cÃ¡c pipeline á»©ng viÃªn cho cÃ¡c táº­p dá»¯ liá»‡u khÃ¡c nhau vÃ  xem viá»‡c lá»±a chá»n cÃ¡c pipeline liÃªn quan nhÆ° má»™t váº¥n Ä‘á» lá»c cá»™ng tÃ¡c [10].

Embedding táº­p dá»¯ liá»‡u. CÆ¡ cháº¿ Ä‘Æ°á»£c sá»­ dá»¥ng nhiá»u nháº¥t Ä‘á»ƒ náº¯m báº¯t cÃ¡c Ä‘áº·c trÆ°ng táº­p dá»¯ liá»‡u dá»±a vÃ o viá»‡c sá»­ dá»¥ng meta-features cho má»™t táº­p dá»¯ liá»‡u nhÆ° [9,25]. CÃ¡c thuá»™c tÃ­nh táº­p dá»¯ liá»‡u nÃ y khÃ¡c nhau tá»« Ä‘Æ¡n giáº£n, nhÆ° sá»‘ lÆ°á»£ng lá»›p (xem, vÃ­ dá»¥ [ 6]), Ä‘áº¿n phá»©c táº¡p vÃ  tá»‘n kÃ©m, nhÆ° cÃ¡c Ä‘áº·c trÆ°ng thá»‘ng kÃª (xem, vÃ­ dá»¥ [ 29]) hoáº·c cÃ¡c Ä‘áº·c trÆ°ng má»‘c (xem, vÃ­ dá»¥ [ 23]). NhÆ° Ä‘Æ°á»£c chá»‰ ra trong Auto-Sklearn 2.0 [ 8], cÃ¡c meta-features nÃ y khÃ´ng Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a Ä‘á»‘i vá»›i cÃ¡c loáº¡i cá»™t nháº¥t Ä‘á»‹nh nhÆ° cá»™t phÃ¢n loáº¡i, vÃ  chÃºng cÅ©ng tá»‘n kÃ©m Ä‘á»ƒ tÃ­nh toÃ¡n, trong ngÃ¢n sÃ¡ch háº¡n cháº¿. Embedding táº­p dá»¯ liá»‡u mÃ  chÃºng tÃ´i Ã¡p dá»¥ng xÃ¢y dá»±ng cÃ¡c embedding cá»™t riÃªng láº», vÃ  sau Ä‘Ã³ gá»™p chÃºng cho má»™t embedding cáº¥p báº£ng.

TÆ°Æ¡ng tá»± nhÆ° phÆ°Æ¡ng phÃ¡p cá»§a chÃºng tÃ´i, Drori et al . [5] sá»­ dá»¥ng cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ Ä‘Æ°á»£c Ä‘Ã o táº¡o trÆ°á»›c Ä‘á»ƒ cÃ³ embedding táº­p dá»¯ liá»‡u dá»±a trÃªn thÃ´ng tin vÄƒn báº£n táº­p dá»¯ liá»‡u cÃ³ sáºµn, vÃ­ dá»¥ tiÃªu Ä‘á», mÃ´ táº£ vÃ  tá»« khÃ³a. Vá»›i nhá»¯ng embedding nÃ y, phÆ°Æ¡ng phÃ¡p cá»§a há» cá»‘ gáº¯ng tÃ¬m cÃ¡c táº­p dá»¯ liá»‡u tÆ°Æ¡ng tá»± nháº¥t vÃ  cÃ¡c baseline liÃªn quan cá»§a chÃºng. KhÃ´ng giá»‘ng nhÆ° [ 5], phÆ°Æ¡ng phÃ¡p cá»§a chÃºng tÃ´i dá»±a vÃ o viá»‡c embedding dá»¯ liá»‡u thá»±c táº¿ bÃªn trong táº­p dá»¯ liá»‡u chá»© khÃ´ng chá»‰ mÃ´ táº£ vÄƒn báº£n tá»•ng thá»ƒ cá»§a chÃºng, mÃ  trong nhiá»u trÆ°á»ng há»£p khÃ´ng cÃ³ sáºµn.
OBOE [ 33] sá»­ dá»¥ng hiá»‡u suáº¥t cá»§a má»™t vÃ i mÃ´ hÃ¬nh khÃ´ng tá»‘n kÃ©m, cÃ³ thÃ´ng tin Ä‘á»ƒ tÃ­nh toÃ¡n cÃ¡c Ä‘áº·c trÆ°ng cá»§a má»™t mÃ´ hÃ¬nh.

Sinh pipeline. CÃ³ má»™t lÆ°á»£ng cÃ´ng viá»‡c Ä‘Ã¡ng ká»ƒ xem viá»‡c lá»±a chá»n bá»™ há»c cÅ©ng nhÆ° siÃªu tham sá»‘ nhÆ° má»™t váº¥n Ä‘á» tá»‘i Æ°u hÃ³a bayesian nhÆ° [ 26,27]. CÃ¡c há»‡ thá»‘ng khÃ¡c Ä‘Ã£ sá»­ dá»¥ng cÃ¡c thuáº­t toÃ¡n tiáº¿n hÃ³a cÃ¹ng vá»›i cÃ¡c template hoáº·c ngá»¯ phÃ¡p do ngÆ°á»i dÃ¹ng Ä‘á»‹nh nghÄ©a cho má»¥c Ä‘Ã­ch nÃ y nhÆ° TPOT [ 15] hoáº·c Recipe [ 4]. Tuy nhiÃªn, nhá»¯ng ngÆ°á»i khÃ¡c Ä‘Ã£ xem váº¥n Ä‘á» sinh pipeline nhÆ° má»™t phÃ¢n rÃ£ ma tráº­n xÃ¡c suáº¥t [ 10], má»™t váº¥n Ä‘á» láº­p káº¿ hoáº¡ch AI khi káº¿t há»£p vá»›i má»™t ngá»¯ phÃ¡p do ngÆ°á»i dÃ¹ng chá»‰ Ä‘á»‹nh [ 14,31], má»™t váº¥n Ä‘á» tá»‘i Æ°u hÃ³a bayesian káº¿t há»£p vá»›i TÃ¬m kiáº¿m CÃ¢y Monte Carlo [ 24], hoáº·c má»™t váº¥n Ä‘á» tá»‘i Æ°u hÃ³a phÆ°Æ¡ng phÃ¡p nhÃ¢n tá»­ thay tháº¿ láº·p láº¡i (ADMM) [ 19]. CÃ¡c há»‡ thá»‘ng nhÆ° VolcanoML táº­p trung vÃ o má»™t phÃ¢n rÃ£ hiá»‡u quáº£ cá»§a khÃ´ng gian tÃ¬m kiáº¿m [ 17]. Theo hiá»ƒu biáº¿t tá»‘t nháº¥t cá»§a chÃºng tÃ´i, KGpip lÃ  há»‡ thá»‘ng Ä‘áº§u tiÃªn mÃ´ hÃ¬nh hÃ³a viá»‡c sinh thá»±c táº¿ cá»§a pipeline nhÆ° má»™t váº¥n Ä‘á» sinh Ä‘á»“ thá»‹ nÆ¡-ron.

Má»™t sá»‘ há»‡ thá»‘ng AutoML gáº§n Ä‘Ã¢y Ä‘Ã£ chuyá»ƒn tá»« cÃ¡c pipeline khÃ¡ tuyáº¿n tÃ­nh Ä‘Æ°á»£c táº¡o ra bá»Ÿi háº§u háº¿t cÃ¡c há»‡ thá»‘ng trÆ°á»›c Ä‘Ã³ Ä‘á»ƒ sá»­ dá»¥ng ensemble hoáº·c stacking má»™t cÃ¡ch rá»™ng rÃ£i. H2O cháº³ng háº¡n sá»­ dá»¥ng tÃ¬m kiáº¿m ngáº«u nhiÃªn nhanh káº¿t há»£p vá»›i ensembling cho váº¥n Ä‘á» sinh pipeline [ 16]. Nhá»¯ng ngÆ°á»i khÃ¡c dá»±a vÃ o "stacking má»™t táº­p cÃ¡c mÃ´ hÃ¬nh tÃ¹y chá»‰nh theo thá»© tá»± Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a trÆ°á»›c", nÆ¡i stacking vÃ  training Ä‘Æ°á»£c xá»­ lÃ½ theo cÃ¡ch Ä‘áº·c biá»‡t Ä‘á»ƒ Ä‘áº¡t Ä‘Æ°á»£c hiá»‡u suáº¥t máº¡nh [ 7]. TÆ°Æ¡ng tá»±, PIPER [20] sá»­ dá»¥ng má»™t thuáº­t toÃ¡n tÃ¬m kiáº¿m tham lam best-first Ä‘á»ƒ duyá»‡t khÃ´ng gian cÃ¡c pipeline má»™t pháº§n Ä‘Æ°á»£c hÆ°á»›ng dáº«n trÃªn má»™t ngá»¯ phÃ¡p Ä‘á»‹nh nghÄ©a cÃ¡c pipeline phá»©c táº¡p nhÆ° Äá»“ thá»‹ CÃ³ hÆ°á»›ng KhÃ´ng chu trÃ¬nh (DAGs). CÃ¡c pipeline Ä‘Æ°á»£c táº¡o ra bá»Ÿi PIPER phá»©c táº¡p hÆ¡n cÃ¡c cáº¥u trÃºc tuyáº¿n tÃ­nh Ä‘Æ°á»£c sá»­ dá»¥ng trong cÃ¡c há»‡ thá»‘ng AutoML hiá»‡n táº¡i mÃ  chÃºng tÃ´i sá»­ dá»¥ng Ä‘á»ƒ kiá»ƒm tra Ã½ tÆ°á»Ÿng cá»§a chÃºng tÃ´i cho viá»‡c mÃ´ hÃ¬nh hÃ³a pipeline lá»‹ch sá»­, vÃ  chÃºng tÃ´i chÆ°a sá»­ dá»¥ng cÃ¡c ká»¹ thuáº­t ensembling trong phÆ°Æ¡ng phÃ¡p cá»§a chÃºng tÃ´i. Tuy nhiÃªn, khÃ´ng cÃ³ Ä‘iá»u gÃ¬ bá»‹ loáº¡i trá»«, vÃ¬ mÃ´ hÃ¬nh meta-learning KGpip cÃ³ thá»ƒ sinh ra báº¥t ká»³ loáº¡i cáº¥u trÃºc nÃ o, bao gá»“m cÃ¡c cáº¥u trÃºc phá»©c táº¡p mÃ  cÃ¡c pipeline Ä‘Ã£ khai thÃ¡c cÃ³ thá»ƒ cÃ³.
2

--- TRANG 3 ---
HÃ¬nh 1: Tá»•ng quan vá» phÆ°Æ¡ng phÃ¡p meta-learning cá»§a KGpip Ä‘á»ƒ khai thÃ¡c cÆ¡ sá»Ÿ dá»¯ liá»‡u cÃ¡c pipeline ML Ä‘á»ƒ huáº¥n luyá»‡n má»™t mÃ´ hÃ¬nh sinh Ä‘á»“ thá»‹ dá»± Ä‘oÃ¡n cÃ¡c khung pipeline ML dÆ°á»›i dáº¡ng Ä‘á»“ thá»‹.

3 META-LEARNING CÃ“ THá»‚ Má» Rá»˜NG Cá»¦A KGPIP
PhÆ°Æ¡ng phÃ¡p meta-learning cá»§a chÃºng tÃ´i dá»±a trÃªn viá»‡c khai thÃ¡c cÃ¡c cÆ¡ sá»Ÿ dá»¯ liá»‡u lá»›n cÃ¡c pipeline ML liÃªn quan Ä‘áº¿n cÃ¡c táº­p dá»¯ liá»‡u Ä‘Æ°á»£c sá»­ dá»¥ng, nhÆ° Ä‘Æ°á»£c minh há»a trong HÃ¬nh 1. QuÃ¡ trÃ¬nh khai thÃ¡c sá»­ dá»¥ng phÃ¢n tÃ­ch chÆ°Æ¡ng trÃ¬nh tÄ©nh thay vÃ¬ thá»±c thi cÃ¡c script pipeline thá»±c táº¿ hoáº·c chuáº©n bá»‹ dá»¯ liá»‡u thÃ´ thá»±c táº¿. ThÃ nh pháº§n meta-learning KGpip tÄƒng cÆ°á»ng chiáº¿n lÆ°á»£c tÃ¬m kiáº¿m cá»§a cÃ¡c há»‡ thá»‘ng AutoML hiá»‡n cÃ³, nhÆ° AutoSklearn vÃ  FLAML, vÃ  cho phÃ©p cÃ¡c há»‡ thá»‘ng nÃ y xá»­ lÃ½ cÃ¡c táº­p dá»¯ liá»‡u ad-hoc, tá»©c lÃ  nhá»¯ng táº­p chÆ°a tháº¥y. Äá»ƒ duy trÃ¬ má»©c Ä‘á»™ linh hoáº¡t tá»‘i Ä‘a, KGpip náº¯m báº¯t metadata vÃ  ngá»¯ nghÄ©a trong má»™t Ä‘á»‹nh dáº¡ng Ä‘á»“ thá»‹ linh hoáº¡t, vÃ  dá»±a vÃ o cÃ¡c mÃ´ hÃ¬nh sinh Ä‘á»“ thá»‹ nhÆ° cÆ¡ sá»Ÿ dá»¯ liá»‡u cá»§a cÃ¡c pipeline.

KhÃ´ng giá»‘ng nhÆ° cÃ¡c phÆ°Æ¡ng phÃ¡p meta-learning hiá»‡n cÃ³, phÆ°Æ¡ng phÃ¡p cá»§a chÃºng tÃ´i Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ há»c tá»« má»™t cÆ¡ sá»Ÿ dá»¯ liá»‡u quy mÃ´ lá»›n vÃ  Ä‘áº¡t Ä‘Æ°á»£c má»©c Ä‘á»™ bao phá»§ vÃ  Ä‘a dáº¡ng cao. Má»™t sá»‘ cá»•ng thÃ´ng tin ML, nhÆ° Kaggle hoáº·c OpenML [ 28], cung cáº¥p quyá»n truy cáº­p vÃ o hÃ ng nghÃ¬n táº­p dá»¯ liá»‡u liÃªn quan Ä‘áº¿n hÃ ng trÄƒm nghÃ¬n notebook cÃ´ng khai, tá»©c lÃ  cÃ¡c pipeline/mÃ£ ML. KGpip khai thÃ¡c nhá»¯ng cÆ¡ sá»Ÿ dá»¯ liá»‡u lá»›n nÃ y cá»§a cÃ¡c táº­p dá»¯ liá»‡u vÃ  pipeline báº±ng phÃ¢n tÃ­ch tÄ©nh vÃ  lá»c chÃºng thÃ nh cÃ¡c pipeline ML Ä‘Æ°á»£c tÃ¹y chá»‰nh cho váº¥n Ä‘á» lá»±a chá»n bá»™ há»c. PhÆ°Æ¡ng phÃ¡p meta-learning KGpip táº­n dá»¥ng [ 1] Ä‘á»ƒ hiá»ƒu mÃ£ thÃ´ng qua phÃ¢n tÃ­ch tÄ©nh cÃ¡c script/mÃ£ cá»§a cÃ¡c pipeline ML. NÃ³ trÃ­ch xuáº¥t ngá»¯ nghÄ©a cá»§a nhá»¯ng script nÃ y nhÆ° mÃ£ vÃ  táº¡o thÃ nh má»™t Ä‘á»“ thá»‹ ban Ä‘áº§u cho má»—i script.
KGpip lÃ m sáº¡ch cÃ¡c Ä‘á»“ thá»‹ Ä‘Æ°á»£c táº¡o ra bá»Ÿi [ 1] Ä‘á»ƒ giá»¯ láº¡i ngá»¯ nghÄ©a cáº§n thiáº¿t cho quÃ¡ trÃ¬nh meta-learning ML. HÆ¡n ná»¯a, phÆ°Æ¡ng phÃ¡p cá»§a chÃºng tÃ´i giá»›i thiá»‡u cÃ¡c nÃºt táº­p dá»¯ liá»‡u vÃ  liÃªn káº¿t ngá»¯ nghÄ©a pipeline liÃªn quan vá»›i chÃºng. VÃ¬ váº­y, phÆ°Æ¡ng phÃ¡p meta-learning cá»§a chÃºng tÃ´i táº¡o ra MetaPip, má»™t Ä‘á»“ thá»‹ cÃ³ liÃªn káº¿t cao cá»§a cÃ¡c táº­p dá»¯ liá»‡u Ä‘Ã£ tháº¥y vÃ  cÃ¡c pipeline Ä‘Æ°á»£c Ã¡p dá»¥ng cho chÃºng. ChÃºng tÃ´i cÅ©ng phÃ¡t triá»ƒn má»™t mÃ´ hÃ¬nh embedding sÃ¢u Ä‘á»ƒ tÃ¬m cÃ¡c táº­p dá»¯ liá»‡u gáº§n nháº¥t vá»›i má»™t táº­p chÆ°a tháº¥y, tá»©c lÃ  Ä‘á»ƒ cáº¯t tá»‰a MetaPip má»™t cÃ¡ch hiá»‡u quáº£.
Sau Ä‘Ã³ chÃºng tÃ´i huáº¥n luyá»‡n má»™t mÃ´ hÃ¬nh sinh Ä‘á»“ thá»‹ sÃ¢u [ 18] sá»­ dá»¥ng MetaPip.
MÃ´ hÃ¬nh nÃ y lÃ  cá»‘t lÃµi cá»§a thÃ nh pháº§n meta-learning cá»§a chÃºng tÃ´i nhÆ° Ä‘Æ°á»£c minh há»a trong HÃ¬nh 1 vÃ  tháº£o luáº­n trong má»¥c tiáº¿p theo.

3.1 Biá»ƒu diá»…n Äá»“ thá»‹ cá»§a Ngá»¯ nghÄ©a MÃ£
CÃ¡c ká»¹ thuáº­t phÃ¢n tÃ­ch chÆ°Æ¡ng trÃ¬nh tÄ©nh vÃ  Ä‘á»™ng cÃ³ thá»ƒ Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ trá»«u tÆ°á»£ng hÃ³a ngá»¯ nghÄ©a cá»§a cÃ¡c chÆ°Æ¡ng trÃ¬nh vÃ  trÃ­ch xuáº¥t cÃ¡c biá»ƒu diá»…n Ä‘á»™c láº­p vá»›i ngÃ´n ngá»¯ cá»§a mÃ£. MÃ£ nguá»“n chÆ°Æ¡ng trÃ¬nh Ä‘Æ°á»£c kiá»ƒm tra trong phÃ¢n tÃ­ch tÄ©nh mÃ  khÃ´ng cháº¡y chÆ°Æ¡ng trÃ¬nh. NgÆ°á»£c láº¡i, phÃ¢n tÃ­ch Ä‘á»™ng kiá»ƒm tra mÃ£ nguá»“n trong runtime Ä‘á»ƒ thu tháº­p traces bá»™ nhá»› vÃ  thá»‘ng kÃª chi tiáº¿t hÆ¡n Ä‘áº·c trÆ°ng cho ká»¹ thuáº­t phÃ¢n tÃ­ch. KhÃ´ng giá»‘ng nhÆ° phÃ¢n tÃ­ch tÄ©nh, phÃ¢n tÃ­ch Ä‘á»™ng giÃºp náº¯m báº¯t ngá»¯ nghÄ©a phong phÃº hÆ¡n tá»« cÃ¡c chÆ°Æ¡ng trÃ¬nh vá»›i chi phÃ­ cao cá»§a viá»‡c thá»±c thi vÃ  lÆ°u trá»¯ traces bá»™ nhá»› khá»•ng lá»“. CÃ¡c cá»•ng thÃ´ng tin ML, nhÆ°

 df = pd. read_csv ('example.csv ')
 df_train, df_test = train_test_split (df)
 X = df_train[' X'] 
 model = svm. SVC()
 model.fit(X, df_train[' Y'])

HÃ¬nh 2: Má»™t vÃ­ dá»¥ tá»« má»™t notebook data science.

read_csvtrain_test_splitdf_train['X']df_train['Y']SVC/f_it

HÃ¬nh 3: Äá»“ thá»‹ mÃ£ tÆ°Æ¡ng á»©ng vá»›i HÃ¬nh 2 Ä‘Æ°á»£c thu vá»›i GraphGen4Code. Äá»“ thá»‹ hiá»ƒn thá»‹ luá»“ng Ä‘iá»u khiá»ƒn vá»›i cÃ¡c cáº¡nh mÃ u xÃ¡m vÃ  luá»“ng dá»¯ liá»‡u vá»›i cÃ¡c cáº¡nh mÃ u Ä‘en. Nhiá»u nÃºt vÃ  cáº¡nh khÃ¡c khÃ´ng Ä‘Æ°á»£c hiá»ƒn thá»‹ Ä‘á»ƒ Ä‘Æ¡n giáº£n.

read_csvtrain_test_splitSVC/f_itexample.csv

HÃ¬nh 4: Äá»“ thá»‹ MetaPip cá»§a chÃºng tÃ´i tá»« Ä‘á»“ thá»‹ á»Ÿ HÃ¬nh 3, nÆ¡i pipeline ML Ä‘Æ°á»£c trá»«u tÆ°á»£ng hÃ³a Ä‘Æ°á»£c liÃªn káº¿t vá»›i má»™t nÃºt táº­p dá»¯ liá»‡u (Ä‘Æ°á»£c tÃ´ mÃ u cam). MetaPip chá»©a Ã­t nháº¥t 96% Ã­t nÃºt vÃ  cáº¡nh hÆ¡n Ä‘á»“ thá»‹ gá»‘c trong khi tÄƒng cÆ°á»ng cháº¥t lÆ°á»£ng tá»•ng thá»ƒ cá»§a quÃ¡ trÃ¬nh sinh Ä‘á»“ thá»‹, nhÆ° Ä‘Æ°á»£c thá»­ nghiá»‡m trong Má»¥c 5.5.

Kaggle, cÃ³ hÃ ng trÄƒm nghÃ¬n pipeline ML mÃ  khÃ´ng cÃ³ hÆ°á»›ng dáº«n Ä‘á»ƒ cháº¡y hoáº·c quáº£n lÃ½ mÃ´i trÆ°á»ng cá»§a nhá»¯ng pipeline nÃ y.
KGpip káº¿t há»£p embedding táº­p dá»¯ liá»‡u vá»›i cÃ¡c cÃ´ng cá»¥ phÃ¢n tÃ­ch mÃ£ tÄ©nh, nhÆ° GraphGen4Code [ 1], Ä‘á»ƒ lÃ m phong phÃº ngá»¯ nghÄ©a thu tháº­p Ä‘Æ°á»£c cá»§a cÃ¡c pipeline ML trong khi trÃ¡nh nhu cáº§u cháº¡y chÃºng.

GraphGen4Code Ä‘Æ°á»£c tá»‘i Æ°u hÃ³a Ä‘á»ƒ xá»­ lÃ½ hiá»‡u quáº£ hÃ ng triá»‡u chÆ°Æ¡ng trÃ¬nh Python, thá»±c hiá»‡n phÃ¢n tÃ­ch luá»“ng dá»¯ liá»‡u vÃ  luá»“ng Ä‘iá»u khiá»ƒn liÃªn thá»§ tá»¥c Ä‘á»ƒ kiá»ƒm tra cháº³ng háº¡n, Ä‘iá»u gÃ¬ xáº£y ra vá»›i dá»¯ liá»‡u Ä‘Æ°á»£c Ä‘á»c tá»« má»™t dataframe Pandas, nÃ³ Ä‘Æ°á»£c thao tÃ¡c vÃ  biáº¿n Ä‘á»•i nhÆ° tháº¿ nÃ o, vÃ  nhá»¯ng transformer hoáº·c estimator nÃ o Ä‘Æ°á»£c gá»i trÃªn dataframe. CÃ¡c Ä‘á»“ thá»‹ cá»§a GraphGen4Code lÃ m cho viá»‡c gá»i cÃ¡c API vÃ  hÃ m nÃ o trÃªn cÃ¡c Ä‘á»‘i tÆ°á»£ng trá»Ÿ nÃªn rÃµ rÃ ng mÃ  khÃ´ng cáº§n mÃ´ hÃ¬nh hÃ³a cÃ¡c thÆ° viá»‡n Ä‘Æ°á»£c sá»­ dá»¥ng; do Ä‘Ã³ GraphGen4Code cÃ³ thá»ƒ má»Ÿ rá»™ng phÃ¢n tÃ­ch tÄ©nh Ä‘áº¿n hÃ ng triá»‡u chÆ°Æ¡ng trÃ¬nh. HÃ¬nh 2 vÃ  3 hiá»ƒn thá»‹ má»™t Ä‘oáº¡n mÃ£ nhá» vÃ  Ä‘á»“ thá»‹ phÃ¢n tÃ­ch tÄ©nh tÆ°Æ¡ng á»©ng tá»« GraphGen4Code, tÆ°Æ¡ng á»©ng. NhÆ° Ä‘Æ°á»£c hiá»ƒn thá»‹ trong HÃ¬nh 3, Ä‘á»“ thá»‹ náº¯m báº¯t luá»“ng Ä‘iá»u khiá»ƒn (cáº¡nh mÃ u xÃ¡m), luá»“ng dá»¯ liá»‡u (cáº¡nh mÃ u Ä‘en), cÅ©ng nhÆ° nhiá»u nÃºt vÃ  cáº¡nh khÃ¡c khÃ´ng Ä‘Æ°á»£c hiá»ƒn thá»‹ trong hÃ¬nh. VÃ­ dá»¥ vá» nhá»¯ng nÃºt vÃ  cáº¡nh nÃ y bao gá»“m nhá»¯ng nÃºt náº¯m báº¯t vá»‹ trÃ­ cá»§a cÃ¡c lá»i gá»i bÃªn trong má»™t tá»‡p script vÃ  cÃ¡c tham sá»‘ lá»i gá»i hÃ m.
VÃ­ dá»¥, GraphGen4Code táº¡o ra má»™t Ä‘á»“ thá»‹ khoáº£ng 1600 nÃºt vÃ  3700 cáº¡nh cho má»™t script pipeline ML Kaggle cÃ³ 72 dÃ²ng mÃ£. Sá»‘ lÆ°á»£ng nÃºt vÃ  cáº¡nh chi phá»‘i Ä‘á»™ phá»©c táº¡p cá»§a viá»‡c huáº¥n luyá»‡n má»™t mÃ´ hÃ¬nh sinh Ä‘á»“ thá»‹.

3.2 MetaPip: tá»« MÃ£ Ä‘áº¿n Ngá»¯ nghÄ©a Pipeline
Äá»‘i vá»›i cÃ¡c há»‡ thá»‘ng AutoML, má»™t pipeline lÃ  má»™t táº­p cÃ¡c phÃ©p biáº¿n Ä‘á»•i dá»¯ liá»‡u, lá»±a chá»n bá»™ há»c, vÃ  tá»‘i Æ°u hÃ³a siÃªu tham sá»‘ cho má»—i mÃ´ hÃ¬nh Ä‘Æ°á»£c chá»n. CÃ¡c notebook data science Ä‘Ã£ khai thÃ¡c thÆ°á»ng chá»©a phÃ¢n tÃ­ch dá»¯ liá»‡u, trá»±c quan hÃ³a dá»¯ liá»‡u, vÃ  Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh. HÆ¡n ná»¯a, má»—i
3

--- TRANG 4 ---
notebook Ä‘Æ°á»£c liÃªn káº¿t vá»›i má»™t hoáº·c nhiá»u táº­p dá»¯ liá»‡u. Do Ä‘Ã³, Ä‘iá»u cáº§n thiáº¿t cho mÃ´ hÃ¬nh meta-learning cá»§a chÃºng tÃ´i lÃ  phÃ¢n biá»‡t giá»¯a cÃ¡c loáº¡i pipeline khÃ¡c nhau vÃ  nháº­n ra má»‘i liÃªn káº¿t nÃ y vá»›i cÃ¡c táº­p dá»¯ liá»‡u. CÃ¡c há»‡ thá»‘ng hiá»‡n cÃ³ cho phÃ¢n tÃ­ch mÃ£ tÄ©nh trÃ­ch xuáº¥t ngá»¯ nghÄ©a tá»•ng quÃ¡t cá»§a mÃ£ vÃ  khÃ´ng thá»ƒ liÃªn káº¿t cÃ¡c script pipeline vá»›i cÃ¡c táº­p dá»¯ liá»‡u Ä‘Æ°á»£c sá»­ dá»¥ng. Do Ä‘Ã³, cÃ¡c Ä‘á»“ thá»‹ Ä‘Æ°á»£c táº¡o ra bá»Ÿi cÃ¡c há»‡ thá»‘ng, nhÆ° GraphGen4Code, bá»‹ phÃ¢n tÃ¡n vÃ  khÃ´ng liÃªn káº¿t, tá»©c lÃ  má»™t Ä‘á»“ thá»‹ cho má»—i script pipeline ML. HÆ¡n ná»¯a, má»—i Ä‘á»“ thá»‹ sáº½ cÃ³ cÃ¡c nÃºt vÃ  cáº¡nh khÃ´ng liÃªn quan Ä‘áº¿n quÃ¡ trÃ¬nh meta-learning. Nhá»¯ng nÃºt vÃ  cáº¡nh khÃ´ng liÃªn quan nÃ y, tá»©c lÃ  bá»™ ba, sáº½ thÃªm nhiá»…u vÃ o dá»¯ liá»‡u huáº¥n luyá»‡n. Do Ä‘Ã³, má»™t mÃ´ hÃ¬nh meta-learning sáº½ khÃ´ng thá»ƒ há»c tá»« cÃ¡c pipeline Ä‘á»“ thá»‹ trá»«u tÆ°á»£ng Ä‘Æ°á»£c táº¡o ra bá»Ÿi cÃ¡c cÃ´ng cá»¥ nhÆ° váº­y, nhÆ° Ä‘Æ°á»£c hiá»ƒn thá»‹ trong Báº£ng 4. ChÃºng tÃ´i Ä‘Ã£ phÃ¡t triá»ƒn má»™t phÆ°Æ¡ng phÃ¡p Ä‘á»ƒ lá»c ra loáº¡i bá»™ ba nÃ y tá»« Ä‘á»“ thá»‹ cá»§a GraphGen4Code vÃ  phÃ¢n tÃ­ch cÃ¡c pipeline ML Ä‘á»ƒ chuáº©n bá»‹ má»™t táº­p huáº¥n luyá»‡n káº¿t ná»‘i cÃ¡c kho lÆ°u trá»¯ script pipeline ML vá»›i cÃ¡c táº­p dá»¯ liá»‡u liÃªn quan cá»§a chÃºng. HÆ¡n ná»¯a, phÆ°Æ¡ng phÃ¡p cá»§a chÃºng tÃ´i lÃ m sáº¡ch cÃ¡c nÃºt vÃ  cáº¡nh nhiá»…u vÃ  cÃ¡c lá»i gá»i Ä‘áº¿n cÃ¡c module bÃªn ngoÃ i thÆ° viá»‡n ML má»¥c tiÃªu. VÃ­ dá»¥, phÆ°Æ¡ng phÃ¡p cá»§a chÃºng tÃ´i sáº½ trÃ­ch xuáº¥t cÃ¡c bá»™ ba liÃªn quan Ä‘áº¿n cÃ¡c thÆ° viá»‡n, nhÆ° Scikit-learn, XGBoost, vÃ  LGBM. Nhá»¯ng thÆ° viá»‡n nÃ y phá»• biáº¿n nháº¥t trong sá»‘ cÃ¡c pipeline ML Ä‘áº¡t Ä‘iá»ƒm cao nháº¥t trong cÃ¡c cá»•ng thÃ´ng tin ML. MÃ£ cho phÆ°Æ¡ng phÃ¡p lÃ m sáº¡ch cÃ³ sáºµn táº¡i kho lÆ°u trá»¯ cá»§a KGpip.

ThÃ nh pháº§n meta-learning cá»§a chÃºng tÃ´i nháº±m chá»n bá»™ há»c vÃ  transformer cho cÃ¡c táº­p dá»¯ liá»‡u chÆ°a tháº¥y. Do Ä‘Ã³, KGpip liÃªn káº¿t cÃ¡c pipeline ML Ä‘Ã£ lá»c vá»›i cÃ¡c táº­p dá»¯ liá»‡u Ä‘Æ°á»£c sá»­ dá»¥ng. Káº¿t quáº£ cá»§a viá»‡c thÃªm nhá»¯ng nÃºt táº­p dá»¯ liá»‡u nÃ y lÃ  má»™t Ä‘á»“ thá»‹ cÃ³ liÃªn káº¿t cao cho cÃ¡c pipeline ML, chÃºng tÃ´i gá»i nÃ³ lÃ  MetaPip . Äá»“ thá»‹ MetaPip cá»§a chÃºng tÃ´i náº¯m báº¯t cáº£ khÃ­a cáº¡nh mÃ£ vÃ  dá»¯ liá»‡u cá»§a cÃ¡c pipeline ML. Do Ä‘Ã³, chÃºng tÃ´i cÃ³ thá»ƒ Ä‘iá»n vÃ o Ä‘á»“ thá»‹ MetaPip vá»›i cÃ¡c táº­p dá»¯ liá»‡u tá»« cÃ¡c nguá»“n khÃ¡c nhau, nhÆ° OpenML vÃ  Kaggle, vÃ  cÃ¡c pipeline Ä‘Æ°á»£c Ã¡p dá»¥ng trÃªn nhá»¯ng táº­p dá»¯ liá»‡u nÃ y. HÃ¬nh 4 hiá»ƒn thá»‹ Ä‘á»“ thá»‹ MetaPip tÆ°Æ¡ng á»©ng vá»›i Ä‘oáº¡n mÃ£ trong HÃ¬nh 2. KGpip sá»­ dá»¥ng MetaPip Ä‘á»ƒ huáº¥n luyá»‡n má»™t mÃ´ hÃ¬nh dá»±a trÃªn má»™t táº­p lá»›n cÃ¡c pipeline liÃªn quan Ä‘áº¿n cÃ¡c táº­p dá»¯ liá»‡u tÆ°Æ¡ng tá»±. VÃ­ dá»¥, má»™t nÃºt pandas.read_csv sáº½ Ä‘Æ°á»£c liÃªn káº¿t vá»›i nÃºt báº£ng Ä‘Æ°á»£c sá»­ dá»¥ng, tá»©c lÃ  tá»‡p csv. Trong má»™t sá»‘ trÆ°á»ng há»£p, mÃ£ Ä‘á»c tá»‡p csv khÃ´ng nÃªu rÃµ tÃªn táº­p dá»¯ liá»‡u.
CÃ¡c pipeline thÆ°á»ng Ä‘Æ°á»£c liÃªn káº¿t vá»›i cÃ¡c táº­p dá»¯ liá»‡u, nhÆ° cÃ¡c pipeline vÃ  táº­p dá»¯ liá»‡u Kaggle, nhÆ° Ä‘Æ°á»£c hiá»ƒn thá»‹ trong HÃ¬nh 1.

3.3 Há»c Biá»ƒu diá»…n Táº­p dá»¯ liá»‡u
PhÆ°Æ¡ng phÃ¡p cá»§a chÃºng tÃ´i hÆ°á»›ng dáº«n hiá»‡u quáº£ quÃ¡ trÃ¬nh meta-learning báº±ng cÃ¡ch liÃªn káº¿t ngá»¯ nghÄ©a Ä‘Æ°á»£c trÃ­ch xuáº¥t cá»§a cÃ¡c pipeline vá»›i cÃ¡c nÃºt táº­p dá»¯ liá»‡u Ä‘áº¡i diá»‡n cho cÃ¡c táº­p dá»¯ liá»‡u Ä‘Æ°á»£c sá»­ dá»¥ng. CÃ³ má»™t lÆ°á»£ng lá»›n cÃ¡c táº­p dá»¯ liá»‡u cÃ³ kÃ­ch thÆ°á»›c khÃ¡c nhau vÃ  chÃºng tÃ´i cáº§n phÃ¡t triá»ƒn má»™t phÆ°Æ¡ng phÃ¡p cÃ³ thá»ƒ má»Ÿ rá»™ng Ä‘á»ƒ tÃ¬m cÃ¡c táº­p dá»¯ liá»‡u tÆ°Æ¡ng tá»± nháº¥t cho má»™t táº­p chÆ°a tháº¥y. Viá»‡c so sÃ¡nh theo cáº·p dá»±a trÃªn ná»™i dung thá»±c táº¿ cá»§a cÃ¡c táº­p dá»¯ liá»‡u, tá»©c lÃ  cÃ¡c bá»™ trong tá»‡p CSV, khÃ´ng thá»ƒ má»Ÿ rá»™ng. Do Ä‘Ã³, chÃºng tÃ´i Ä‘Ã£ phÃ¡t triá»ƒn má»™t phÆ°Æ¡ng phÃ¡p há»c biá»ƒu diá»…n táº­p dá»¯ liá»‡u Ä‘á»ƒ táº¡o ra má»™t embedding cÃ³ kÃ­ch thÆ°á»›c cá»‘ Ä‘á»‹nh vÃ  dÃ y Ä‘áº·c á»Ÿ má»©c Ä‘á»™ chi tiáº¿t cá»§a má»™t táº­p dá»¯ liá»‡u, vÃ­ dá»¥, má»™t báº£ng hoáº·c tá»‡p CSV. Embedding cá»§a má»™t táº­p dá»¯ liá»‡u D lÃ  trung bÃ¬nh cá»§a cÃ¡c embedding cá»™t cá»§a nÃ³, tá»©c lÃ :

â„_Î¸(D) = 1/|D| âˆ‘_{câˆˆD} â„_Î¸(c) (1)

trong Ä‘Ã³ |D| lÃ  sá»‘ lÆ°á»£ng cá»™t trong D. CÃ´ng trÃ¬nh cá»§a chÃºng tÃ´i tá»•ng quÃ¡t hÃ³a phÆ°Æ¡ng phÃ¡p Ä‘Æ°á»£c phÃ¡c tháº£o trong [ 21] cho cÃ¡c embedding cá»™t riÃªng láº», nÆ¡i cÃ¡c embedding cá»™t Ä‘Æ°á»£c thu Ä‘Æ°á»£c báº±ng cÃ¡ch huáº¥n luyá»‡n má»™t máº¡ng nÆ¡-ron trÃªn má»™t tÃ¡c vá»¥ phÃ¢n loáº¡i nhá»‹ phÃ¢n. MÃ´ hÃ¬nh há»c khi nÃ o hai cá»™t Ä‘áº¡i diá»‡n cho cÃ¹ng má»™t khÃ¡i niá»‡m, nhÆ°ng vá»›i cÃ¡c giÃ¡ trá»‹ khÃ¡c nhau, trÃ¡i ngÆ°á»£c vá»›i

HÃ¬nh 5: Tá»•ng quan vá» quy trÃ¬nh cÃ´ng viá»‡c cá»§a KGpip sinh pipeline ML cho má»™t táº­p dá»¯ liá»‡u chÆ°a tháº¥y nháº¥t Ä‘á»‹nh vÃ  ngÃ¢n sÃ¡ch thá»i gian nháº¥t Ä‘á»‹nh. KGpip sá»­ dá»¥ng cÃ¡c há»‡ thá»‘ng Ä‘á»ƒ tá»‘i Æ°u hÃ³a siÃªu tham sá»‘, nhÆ° FLAML hoáº·c Auto-Sklearn, Ä‘á»ƒ tá»‘i Æ°u hÃ³a cÃ¡c pipeline top-K Ä‘Æ°á»£c dá»± Ä‘oÃ¡n cá»§a KGpip ( ğ‘‰ğº), tá»©c lÃ  cáº¯t tá»‰a khÃ´ng gian tÃ¬m kiáº¿m.

cÃ¡c cá»™t Ä‘áº¡i diá»‡n cho cÃ¡c khÃ¡i niá»‡m khÃ¡c nhau. CÃ¡c embedding cho má»™t táº­p dá»¯ liá»‡u chÆ°a tháº¥y Ä‘Æ°á»£c táº¡o ra bá»Ÿi lá»›p cuá»‘i cÃ¹ng cá»§a máº¡ng nÆ¡-ron.

KGpip Ä‘á»c cÃ¡c táº­p dá»¯ liá»‡u chá»‰ má»™t láº§n vÃ  táº­n dá»¥ng PySpark DataFrame Ä‘á»ƒ Ä‘áº¡t Ä‘Æ°á»£c tÃ­nh song song tÃ¡c vá»¥ vÃ  dá»¯ liá»‡u cao. ChÃºng tÃ´i sá»­ dá»¥ng cÃ¡c embedding cá»§a cÃ¡c táº­p dá»¯ liá»‡u Ä‘á»ƒ Ä‘o Ä‘á»™ tÆ°Æ¡ng tá»± cá»§a chÃºng. Vá»›i nhá»¯ng embedding nÃ y, chÃºng tÃ´i xÃ¢y dá»±ng má»™t chá»‰ má»¥c cá»§a cÃ¡c embedding vector cho táº¥t cáº£ cÃ¡c táº­p dá»¯ liá»‡u trong táº­p huáº¥n luyá»‡n cá»§a chÃºng tÃ´i. ChÃºng tÃ´i sá»­ dá»¥ng cÃ¡c thÆ° viá»‡n hiá»‡u quáº£ [ 13] Ä‘á»ƒ tÃ¬m kiáº¿m Ä‘á»™ tÆ°Æ¡ng tá»± cá»§a cÃ¡c vector dÃ y Ä‘áº·c Ä‘á»ƒ truy xuáº¥t táº­p dá»¯ liá»‡u tÆ°Æ¡ng tá»± nháº¥t vá»›i má»™t táº­p dá»¯ liá»‡u Ä‘áº§u vÃ o má»›i dá»±a trÃªn embedding cá»§a nÃ³. Do Ä‘Ã³, phÆ°Æ¡ng phÃ¡p cá»§a chÃºng tÃ´i má»Ÿ rá»™ng tá»‘t vÃ  dáº«n Ä‘áº¿n káº¿t quáº£ chÃ­nh xÃ¡c trong viá»‡c náº¯m báº¯t Ä‘á»™ tÆ°Æ¡ng tá»± giá»¯a cÃ¡c táº­p dá»¯ liá»‡u.

4 Tá»° Äá»˜NG HÃ“A PIPELINE KGPIP
Quy trÃ¬nh cÃ´ng viá»‡c KGpip cho tá»± Ä‘á»™ng hÃ³a pipeline dá»±a trÃªn mÃ´ hÃ¬nh meta-learning cá»§a chÃºng tÃ´i, nhÆ° Ä‘Æ°á»£c minh há»a trong HÃ¬nh 5. KGpip dá»± Ä‘oÃ¡n cÃ¡c khung pipeline top-K, tá»©c lÃ  má»™t táº­p cá»¥ thá»ƒ { ğ‘ƒ,ğ¸} cá»§a Preprocessor ( ğ‘ƒ) vÃ  Estimators ( ğ¸), cho má»™t táº­p dá»¯ liá»‡u chÆ°a tháº¥y ( ğ·) dá»±a trÃªn táº­p dá»¯ liá»‡u Ä‘Ã£ tháº¥y tÆ°Æ¡ng tá»± nháº¥t ( ğ‘†ğ·), tá»©c lÃ  táº­p dá»¯ liá»‡u lÃ¡ng giá»ng gáº§n nháº¥t. KGpip báº¯t Ä‘áº§u báº±ng viá»‡c tÃ¬m ğ‘†ğ· dá»±a trÃªn embedding cá»§a táº­p dá»¯ liá»‡u chÆ°a tháº¥y. Sau Ä‘Ã³, KGpip táº¡o ra cÃ¡c Ä‘á»“ thá»‹ pipeline ML top-K Ä‘Ã£ Ä‘Æ°á»£c xÃ¡c thá»±c ğ‘‰ğº vÃ  chuyá»ƒn Ä‘á»•i chÃºng thÃ nh cÃ¡c khung pipeline ML {ğ‘ƒ,ğ¸}. Sau Ä‘Ã³, nÃ³ thá»±c hiá»‡n tá»‘i Æ°u hÃ³a siÃªu tham sá»‘ sá»­ dá»¥ng cÃ¡c há»‡ thá»‘ng, nhÆ° FLAML [ 30] vÃ  Auto-Sklearn [ 9], Ä‘á»ƒ tÃ¬m cÃ¡c siÃªu tham sá»‘ tá»‘i Æ°u cho má»—i khung pipeline trong má»™t ngÃ¢n sÃ¡ch thá»i gian cá»¥ thá»ƒ.

4.1 Sinh Äá»“ thá»‹ cho Pipeline ML
KGpip xÃ¢y dá»±ng viá»‡c sinh cÃ¡c pipeline ML nhÆ° má»™t bÃ i toÃ¡n sinh Ä‘á»“ thá»‹. Trá»±c giÃ¡c Ä‘áº±ng sau Ã½ tÆ°á»Ÿng nÃ y lÃ  má»™t bá»™ sinh Ä‘á»“ thá»‹ nÆ¡-ron cÃ³ thá»ƒ náº¯m báº¯t má»™t cÃ¡ch ngáº¯n gá»n hÆ¡n nhiá»u pipeline Ä‘Æ°á»£c tháº¥y trong thá»±c táº¿ cho má»™t táº­p dá»¯ liá»‡u nháº¥t Ä‘á»‹nh, vÃ  cÅ©ng cÃ³ thá»ƒ náº¯m báº¯t Ä‘á»™ tÆ°Æ¡ng tá»± thá»‘ng kÃª giá»¯a cÃ¡c pipeline khÃ¡c nhau má»™t cÃ¡ch hiá»‡u quáº£ hÆ¡n. Äá»ƒ sá»­ dá»¥ng hiá»‡u quáº£ má»™t máº¡ng nhÆ° váº­y, chÃºng tÃ´i thÃªm má»™t nÃºt táº­p dá»¯ liá»‡u duy nháº¥t lÃ m Ä‘iá»ƒm báº¯t Ä‘áº§u cho cÃ¡c pipeline Ä‘Ã£ lá»c mÃ  chÃºng tÃ´i táº¡o ra tá»« cÃ¡c notebook Python. NÃºt Ä‘Æ°á»£c giáº£ Ä‘á»‹nh cháº£y vÃ o má»™t lá»i gá»i read_csv mÃ  thÆ°á»ng lÃ  Ä‘iá»ƒm báº¯t Ä‘áº§u cho cÃ¡c pipeline. Äá»ƒ sinh má»™t pipeline ML, chÃºng tÃ´i Ä‘Æ¡n giáº£n truyá»n vÃ o má»™t nÃºt táº­p dá»¯ liá»‡u cho lÃ¡ng giá»ng gáº§n nháº¥t cá»§a táº­p dá»¯ liá»‡u chÆ°a tháº¥y, tá»©c lÃ  táº­p dá»¯ liá»‡u tÆ°Æ¡ng tá»± nháº¥t dá»±a trÃªn Ä‘á»™ tÆ°Æ¡ng tá»± ná»™i dung, nhÆ° Ä‘Æ°á»£c hiá»ƒn thá»‹ trong HÃ¬nh 5.

MÃ´ hÃ¬nh meta-learning cá»§a chÃºng tÃ´i sinh cÃ¡c Ä‘á»“ thá»‹ pipeline ML theo cÃ¡ch tuáº§n tá»± tá»«ng nÃºt má»™t. Thuáº­t toÃ¡n 1 minh há»a viá»‡c triá»ƒn khai mÃ´ hÃ¬nh sinh Ä‘á»“ thá»‹. Vá»›i má»™t Ä‘á»“ thá»‹ trá»‘ng ğº
4

--- TRANG 5 ---
Thuáº­t toÃ¡n 1: QuÃ¡ trÃ¬nh Sinh Äá»“ thá»‹
Äáº§u vÃ o: Äá»“ thá»‹ ğº: (ğ¸=ğœ™,ğ‘‰=ğœ™), NÃºt Táº­p dá»¯ liá»‡u TÆ°Æ¡ng tá»±: ğ‘†ğ·,
Máº¡ng NÆ¡-ron: ğ‘“_{AddNode},ğ‘“_{AddEdge},ğ‘“_{ChooseNode}
1ğ‘‰â†ğ‘‰âˆª{ğ‘†ğ·,ğ‘ğ‘ğ‘›ğ‘‘ğ‘ğ‘ .ğ‘Ÿğ‘’ğ‘ğ‘‘_ğ‘ğ‘ ğ‘£}
2ğ¸â†ğ¸âˆª{(ğ‘†ğ·,ğ‘ğ‘ğ‘›ğ‘‘ğ‘ğ‘ .ğ‘Ÿğ‘’ğ‘ğ‘‘_ğ‘ğ‘ ğ‘£)}
3ğ‘›ğ‘œğ‘‘ğ‘’ğ‘‡ğ‘œğ´ğ‘‘ğ‘‘ =ğ‘“_{AddNode}(ğ‘‰,ğ¸)
4whileğ‘›ğ‘œğ‘‘ğ‘’ğ‘‡ğ‘œğ´ğ‘‘ğ‘‘ â‰ ğ‘ğ‘¢ğ‘™ğ‘™ do
5ğ‘‰â†ğ‘‰âˆª{ğ‘›ğ‘œğ‘‘ğ‘’ğ‘‡ğ‘œğ´ğ‘‘ğ‘‘}
6ğ‘ğ‘‘ğ‘‘ğ¸ğ‘‘ğ‘”ğ‘’ =ğ‘“_{AddEdge}(ğ‘‰,ğ¸)
7 whileğ‘ğ‘‘ğ‘‘ğ¸ğ‘‘ğ‘”ğ‘’ do
8ğ‘›ğ‘œğ‘‘ğ‘’ğ‘‡ğ‘œğ¿ğ‘–ğ‘›ğ‘˜ =ğ‘“_{ChooseNode}(ğ‘‰,ğ¸)
9ğ¸â†ğ¸âˆª{(ğ‘›ğ‘œğ‘‘ğ‘’ğ‘‡ğ‘œğ´ğ‘‘ğ‘‘,ğ‘›ğ‘œğ‘‘ğ‘’ğ‘‡ğ‘œğ¿ğ‘–ğ‘›ğ‘˜ )}
10ğ‘ğ‘‘ğ‘‘ğ¸ğ‘‘ğ‘”ğ‘’â†ğ‘“_{AddEdge}(ğ‘‰,ğ¸)
11 end
12ğ‘›ğ‘œğ‘‘ğ‘’ğ‘‡ğ‘œğ´ğ‘‘ğ‘‘â†ğ‘“_{AddNode}(ğ‘‰,ğ¸)
13end
14ğ‘‰ğº=ğ‘£ğ‘ğ‘™ğ‘–ğ‘‘ğ‘ğ‘¡ğ‘’_ğ‘ğ‘–ğ‘ğ‘’ğ‘™ğ‘–ğ‘›ğ‘’_ğ‘”ğ‘Ÿğ‘ğ‘â„(ğº)
15return VG

vÃ  táº­p dá»¯ liá»‡u tÆ°Æ¡ng tá»± nháº¥t ğ‘†ğ·, thuáº­t toÃ¡n báº¯t Ä‘áº§u báº±ng viá»‡c thÃªm má»™t cáº¡nh giá»¯a ğ‘†ğ· vÃ  pandas.read_csv . Sau Ä‘Ã³, máº¡ng nÆ¡-ron Ä‘á»“ thá»‹ ğ‘“_{AddNode} quyáº¿t Ä‘á»‹nh cÃ³ thÃªm má»™t nÃºt má»›i cá»§a má»™t loáº¡i nháº¥t Ä‘á»‹nh hay khÃ´ng. Máº¡ng ğ‘“_{AddEdge} quyáº¿t Ä‘á»‹nh cÃ³ thÃªm má»™t cáº¡nh vÃ o nÃºt má»›i Ä‘Æ°á»£c thÃªm hay khÃ´ng. Sau Ä‘Ã³, máº¡ng ğ‘“_{ChooseNode} quyáº¿t Ä‘á»‹nh nÃºt hiá»‡n cÃ³ mÃ  cáº¡nh sáº½ Ä‘Æ°á»£c thÃªm vÃ o. VÃ²ng láº·p While á»Ÿ dÃ²ng 7 Ä‘Æ°á»£c láº·p láº¡i cho Ä‘áº¿n khi khÃ´ng cÃ³ cáº¡nh nÃ o Ä‘Æ°á»£c thÃªm ná»¯a.
VÃ²ng láº·p While á»Ÿ dÃ²ng 4 Ä‘Æ°á»£c láº·p láº¡i cho Ä‘áº¿n khi khÃ´ng cÃ³ nÃºt nÃ o Ä‘Æ°á»£c thÃªm ná»¯a. Ba máº¡ng nÆ¡-ron, cá»¥ thá»ƒ lÃ  ğ‘“_{AddNode} ,ğ‘“_{AddEdge} , vÃ  ğ‘“_{ChooseNode} , sá»­ dá»¥ng cÃ¡c embedding nÃºt Ä‘Æ°á»£c há»c trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n thÃ´ng qua cÃ¡c vÃ²ng lan truyá»n Ä‘á»“ thá»‹. Nhá»¯ng embedding nÃ y náº¯m báº¯t cáº¥u trÃºc cá»§a cÃ¡c Ä‘á»“ thá»‹ pipeline ML.

Äá»“ thá»‹ Ä‘Æ°á»£c sinh ra ğº khÃ´ng Ä‘Æ°á»£c Ä‘áº£m báº£o lÃ  má»™t pipeline ML há»£p lá»‡. Do Ä‘Ã³, Thuáº­t toÃ¡n 1 á»Ÿ dÃ²ng 14 kiá»ƒm tra ráº±ng ğº lÃ  má»™t Ä‘á»“ thá»‹ pipeline ML há»£p lá»‡. Trong KGpip, má»™t Ä‘á»“ thá»‹ ğº há»£p lá»‡ náº¿u 1) nÃ³ chá»©a Ã­t nháº¥t má»™t estimator khá»›p vá»›i tÃ¡c vá»¥, tá»©c lÃ  há»“i quy hoáº·c phÃ¢n loáº¡i, vÃ  2) estimator Ä‘Æ°á»£c há»— trá»£ bá»Ÿi bá»™ tá»‘i Æ°u hÃ³a siÃªu tham sá»‘ (AutoSklearn hoáº·c FLAML trong trÆ°á»ng há»£p cá»§a chÃºng tÃ´i). Vá»›i nhá»¯ng sá»­a Ä‘á»•i nÃ y, cÃ³ thá»ƒ sinh cÃ¡c pipeline ML cho cÃ¡c táº­p dá»¯ liá»‡u chÆ°a tháº¥y báº±ng cÃ¡ch sá»­ dá»¥ng nÃºt táº­p dá»¯ liá»‡u Ä‘Ã£ tháº¥y gáº§n nháº¥t â€“ cá»¥ thá»ƒ hÆ¡n, embedding ná»™i dung cá»§a nÃ³ Ä‘Æ°á»£c thu tá»« module embedding táº­p dá»¯ liá»‡u. ChÃºng tÃ´i Ä‘Ã£ xÃ¢y dá»±ng Thuáº­t toÃ¡n 1 dá»±a trÃªn há»‡ thá»‘ng Ä‘Æ°á»£c Ä‘á» xuáº¥t trong [ 18]. Há»‡ thá»‘ng nÃ y khÃ´ng há»— trá»£ sinh Ä‘á»“ thá»‹ cÃ³ Ä‘iá»u kiá»‡n táº¡i thá»i Ä‘iá»ƒm kiá»ƒm tra theo máº·c Ä‘á»‹nh, tá»©c lÃ  xÃ¢y dá»±ng má»™t Ä‘á»“ thá»‹ trÃªn má»™t nÃºt táº­p dá»¯ liá»‡u Ä‘Æ°á»£c cung cáº¥p. ChÃºng tÃ´i Ä‘Ã£ má»Ÿ rá»™ng há»‡ thá»‘ng nÃ y Ä‘á»ƒ sinh cÃ¡c Ä‘á»“ thá»‹ pipeline ML há»£p lá»‡, nhÆ° Ä‘Æ°á»£c minh há»a trong Thuáº­t toÃ¡n 1.

4.2 Tá»‘i Æ°u hÃ³a SiÃªu tham sá»‘
KGpip Ã¡nh xáº¡ cÃ¡c Ä‘á»“ thá»‹ há»£p lá»‡ thÃ nh cÃ¡c khung pipeline ML, nÆ¡i má»—i khung lÃ  má»™t táº­p cÃ¡c bá»™ tiá»n xá»­ lÃ½ vÃ  má»™t estimator vá»›i cÃ¡c vá»‹ trÃ­ giá»¯ chá»— cho cÃ¡c tham sá»‘ tá»‘i Æ°u. Trong KGpip, bá»™ tá»‘i Æ°u hÃ³a siÃªu tham sá»‘ chá»‹u trÃ¡ch nhiá»‡m tÃ¬m cÃ¡c tham sá»‘ tá»‘i Æ°u cho cÃ¡c bá»™ tiá»n xá»­ lÃ½ vÃ  bá»™ há»c trÃªn táº­p dá»¯ liá»‡u má»¥c tiÃªu. Sau Ä‘Ã³, KGpip thay tháº¿ cÃ¡c vá»‹ trÃ­ giá»¯ chá»— báº±ng nhá»¯ng tham sá»‘ nÃ y. Cuá»‘i cÃ¹ng, KGpip táº¡o má»™t script python sá»­ dá»¥ng cÃ¡c bá»™ tiá»n xá»­ lÃ½ vÃ  estimator Ä‘áº¡t Ä‘Æ°á»£c Ä‘iá»ƒm sá»‘ cao nháº¥t. KGpip Ä‘Æ°á»£c thiáº¿t káº¿ tá»‘t Ä‘á»ƒ há»— trá»£ cáº£ cÃ¡c táº­p dá»¯ liá»‡u sá»‘ vÃ  khÃ´ng sá»‘. Do Ä‘Ã³, KGpip Ã¡p dá»¥ng cÃ¡c ká»¹ thuáº­t tiá»n xá»­ lÃ½ khÃ¡c nhau trÃªn táº­p dá»¯ liá»‡u nháº¥t Ä‘á»‹nh ( ğ·) vÃ  táº¡o ra má»™t táº­p dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c tiá»n xá»­ lÃ½ ( ğ·â€²). Viá»‡c tiá»n xá»­ lÃ½ cá»§a chÃºng tÃ´i bao gá»“m 1) phÃ¡t hiá»‡n loáº¡i tÃ¡c vá»¥ (tá»©c lÃ  há»“i quy hoáº·c phÃ¢n loáº¡i) tá»± Ä‘á»™ng dá»±a trÃªn phÃ¢n phá»‘i cá»§a cá»™t má»¥c tiÃªu 2) tá»± Ä‘á»™ng suy luáº­n cÃ¡c loáº¡i dá»¯ liá»‡u chÃ­nh xÃ¡c cá»§a cÃ¡c cá»™t, 3) vector hÃ³a cÃ¡c cá»™t vÄƒn báº£n báº±ng word embeddings [ 3], vÃ  4) Ä‘iá»n cÃ¡c giÃ¡ trá»‹ thiáº¿u trong táº­p dá»¯ liá»‡u. Trong KGpip, bá»™ tá»‘i Æ°u hÃ³a siÃªu tham sá»‘ sá»­ dá»¥ng ğ·â€².

TÆ°Æ¡ng tá»± nhÆ° cÃ¡c bá»™ tá»‘i Æ°u hÃ³a siÃªu tham sá»‘ Ä‘Æ°á»£c triá»ƒn khai trong cÃ¡c há»‡ thá»‘ng AutoML, nhÆ° FLAML hoáº·c Auto-Sklearn, KGpip hoáº¡t Ä‘á»™ng trong má»™t ngÃ¢n sÃ¡ch thá»i gian Ä‘Æ°á»£c cung cáº¥p cho má»—i táº­p dá»¯ liá»‡u. ChÃºng tÃ´i lÆ°u Ã½ á»Ÿ Ä‘Ã¢y ráº±ng pháº§n lá»›n ngÃ¢n sÃ¡ch thá»i gian Ä‘Æ°á»£c phÃ¢n bá»• cho viá»‡c sinh pipeline ML Ä‘Æ°á»£c dÃ nh cho tá»‘i Æ°u hÃ³a siÃªu tham sá»‘; nghÄ©a lÃ , náº¿u ngÆ°á»i dÃ¹ng chá»‰ muá»‘n biáº¿t nhá»¯ng bá»™ há»c nÃ o sáº½ hoáº¡t Ä‘á»™ng tá»‘t nháº¥t cho táº­p dá»¯ liá»‡u cá»§a há», KGpip cÃ³ thá»ƒ lÃ m Ä‘iá»u Ä‘Ã³ gáº§n nhÆ° ngay láº­p tá»©c. Vá»›i má»™t ngÃ¢n sÃ¡ch thá»i gian ( ğ‘‡), KGpip tÃ­nh toÃ¡n ğ‘¡, thá»i gian tiÃªu thá»¥ trong viá»‡c sinh vÃ  xÃ¡c thá»±c cÃ¡c Ä‘á»“ thá»‹. KGpip sau Ä‘Ã³ chia pháº§n cÃ²n láº¡i cá»§a ngÃ¢n sÃ¡ch thá»i gian giá»¯a ğ¾ Ä‘á»“ thá»‹. Do Ä‘Ã³, bá»™ tá»‘i Æ°u hÃ³a siÃªu tham sá»‘ cÃ³ giá»›i háº¡n thá»i gian ((ğ‘‡âˆ’ğ‘¡)/ğ¾) Ä‘á»ƒ tá»‘i Æ°u hÃ³a má»—i Ä‘á»“ thá»‹ má»™t cÃ¡ch Ä‘á»™c láº­p.

Bá»™ tá»‘i Æ°u hÃ³a siÃªu tham sá»‘ láº·p Ä‘i láº·p láº¡i Ã¡p dá»¥ng cÃ¡c bá»™ há»c vÃ  bá»™ tiá»n xá»­ lÃ½ vá»›i cÃ¡c cáº¥u hÃ¬nh khÃ¡c nhau trong khi theo dÃµi sá»‘ liá»‡u Ä‘iá»ƒm má»¥c tiÃªu trong suá»‘t quÃ¡ trÃ¬nh. KGpip tiáº¿p tá»¥c cáº­p nháº­t Ä‘áº§u ra cá»§a nÃ³ vá»›i khung pipeline tá»‘t nháº¥t, tá»©c lÃ  bá»™ há»c vÃ  bá»™ tiá»n xá»­ lÃ½, vÃ  Ä‘iá»ƒm sá»‘ cá»§a nÃ³. VÃ­ dá»¥, náº¿u bá»™ há»c Ä‘Æ°á»£c dá»± Ä‘oÃ¡n lÃ  LogisticRegression, nÃ³ tÃ¬m kiáº¿m sá»± káº¿t há»£p tá»‘t nháº¥t cá»§a loáº¡i regularization (L1 hoáº·c L2) vÃ  tham sá»‘ regularization. Sá»± khÃ¡c biá»‡t giá»¯a cÃ¡c bá»™ tá»‘i Æ°u hÃ³a siÃªu tham sá»‘ lÃ  chiáº¿n lÆ°á»£c tÃ¬m kiáº¿m Ä‘Æ°á»£c theo dÃµi Ä‘á»ƒ Ä‘áº¡t Ä‘áº¿n cÃ¡c siÃªu tham sá»‘ tá»‘t nháº¥t trong ngÃ¢n sÃ¡ch thá»i gian Ä‘Æ°á»£c phÃ¢n bá»•. Má»™t phÆ°Æ¡ng phÃ¡p ngÃ¢y thÆ¡ sáº½ lÃ  thá»±c hiá»‡n tÃ¬m kiáº¿m lÆ°á»›i Ä‘áº§y Ä‘á»§ trÃªn táº¥t cáº£ cÃ¡c káº¿t há»£p, trong khi má»™t phÆ°Æ¡ng phÃ¡p tiÃªn tiáº¿n hÆ¡n sáº½ lÃ  báº¯t Ä‘áº§u vá»›i cÃ¡c cáº¥u hÃ¬nh há»©a háº¹n trÆ°á»›c. ChÃºng tÃ´i tÃ­ch há»£p KGpip vá»›i cÃ¡c bá»™ tá»‘i Æ°u hÃ³a siÃªu tham sá»‘ cá»§a cáº£ FLAML [ 30] vÃ  Auto-Sklearn [9] Ä‘á»ƒ chá»©ng minh tÃ­nh tá»•ng quÃ¡t cá»§a KGpip. Viá»‡c tÃ­ch há»£p má»™t bá»™ tá»‘i Æ°u hÃ³a siÃªu tham sá»‘ vÃ o KGpip cáº§n má»™t tÃ i liá»‡u JSON cá»§a cÃ¡c bá»™ tiá»n xá»­ lÃ½ vÃ  estimator cá»¥ thá»ƒ Ä‘Æ°á»£c há»— trá»£ bá»Ÿi bá»™ tá»‘i Æ°u hÃ³a siÃªu tham sá»‘. Do Ä‘Ã³, viá»‡c tÃ­ch há»£p tÆ°Æ¡ng Ä‘á»‘i dá»… dÃ ng. Cuá»‘i cÃ¹ng, viá»‡c sinh Ä‘á»“ thá»‹ nÆ¡-ron cá»§a chÃºng tÃ´i táº¡o ra má»™t táº­p cÃ¡c pipeline Ä‘a dáº¡ng qua cÃ¡c láº§n cháº¡y, cho phÃ©p khÃ¡m phÃ¡ vÃ  khai thÃ¡c.

5 CÃC THá»°C NGHIá»†M
5.1 Benchmark
ChÃºng tÃ´i Ä‘Ã¡nh giÃ¡ KGpip cÅ©ng nhÆ° cÃ¡c baseline khÃ¡c trÃªn bá»‘n táº­p dá»¯ liá»‡u benchmark: 1) Open AutoML Benchmark [11], má»™t bá»™ sÆ°u táº­p 39 táº­p dá»¯ liá»‡u phÃ¢n loáº¡i nhá»‹ phÃ¢n vÃ  Ä‘a lá»›p (Ä‘Æ°á»£c sá»­ dá»¥ng bá»Ÿi FLAML [ 30]). CÃ¡c táº­p dá»¯ liá»‡u Ä‘Æ°á»£c chá»n sao cho chÃºng Ä‘áº¡i diá»‡n cho tháº¿ giá»›i thá»±c tá»« Ä‘a dáº¡ng cÃ¡c lÄ©nh vá»±c váº¥n Ä‘á» vÃ  cÃ³ Ä‘á»§ Ä‘á»™ khÃ³ cho cÃ¡c thuáº­t toÃ¡n há»c. 2) Penn Machine Learning Benchmark (PMLB) [ 22]: VÃ¬ Open AutoML Benchmark giá»›i háº¡n á»Ÿ cÃ¡c táº­p dá»¯ liá»‡u phÃ¢n loáº¡i, cÃ¡c tÃ¡c giáº£ cá»§a FLAML [ 30] Ä‘Ã£ Ä‘Ã¡nh giÃ¡ há»‡ thá»‘ng cá»§a há» trÃªn 14 táº­p dá»¯ liá»‡u há»“i quy Ä‘Æ°á»£c chá»n thÃªm tá»« PMLB, sao cho sá»‘ lÆ°á»£ng máº«u lá»›n hÆ¡n 10,000. Äá»ƒ chá»©ng minh tÃ­nh tá»•ng quÃ¡t cá»§a phÆ°Æ¡ng phÃ¡p, chÃºng tÃ´i cÅ©ng bao gá»“m nhá»¯ng táº­p dá»¯ liá»‡u Ä‘Ã³ trong Ä‘Ã¡nh giÃ¡ cá»§a chÃºng tÃ´i. 3) Táº­p dá»¯ liá»‡u cá»§a AL : ChÃºng tÃ´i cÅ©ng Ä‘Ã¡nh giÃ¡ trÃªn cÃ¡c táº­p dá»¯ liá»‡u Ä‘Æ°á»£c sá»­ dá»¥ng cho Ä‘Ã¡nh giÃ¡ cá»§a AL [ 2] bao gá»“m 6 táº­p dá»¯ liá»‡u Kaggle (2 há»“i quy vÃ  4 phÃ¢n loáº¡i) vÃ  18 táº­p dá»¯ liá»‡u phÃ¢n loáº¡i khÃ¡c (9 tá»« PMLB vÃ  9 tá»« OpenML). KhÃ´ng giá»‘ng nhÆ° cÃ¡c benchmark khÃ¡c, cÃ¡c táº­p dá»¯ liá»‡u Kaggle bao gá»“m cÃ¡c táº­p dá»¯ liá»‡u vá»›i cÃ¡c Ä‘áº·c trÆ°ng vÄƒn báº£n. 4) Táº­p dá»¯ liá»‡u cá»§a VolcanoML: cuá»‘i cÃ¹ng, chÃºng tÃ´i Ä‘Ã¡nh giÃ¡ KGpip trÃªn 44 táº­p dá»¯ liá»‡u Ä‘Æ°á»£c sá»­ dá»¥ng thÃªm bá»Ÿi VolcanoML [ 17]. CÃ¡c tÃ¡c giáº£ cá»§a VolcanoML Ä‘Ã¡nh giÃ¡ há»‡ thá»‘ng cá»§a há» trÃªn tá»•ng cá»™ng 66 táº­p dá»¯ liá»‡u tá»« OpenML vÃ  Kaggle, tá»« Ä‘Ã³
5

--- TRANG 6 ---
Báº£ng 1: PhÃ¢n tÃ­ch táº¥t cáº£ 121 táº­p dá»¯ liá»‡u Ä‘Æ°á»£c sá»­ dá»¥ng trong Ä‘Ã¡nh giÃ¡ cá»§a chÃºng tÃ´i, chá»‰ ra nhá»¯ng táº­p Ä‘Æ°á»£c sá»­ dá»¥ng bá»Ÿi FLAMLâˆ—, ALâ€ , vÃ  VolcanoMLÂ§.

Nguá»“n
TÃ¡c vá»¥ | AutoML | PMLB | OpenML | Kaggle
Nhá»‹ phÃ¢n | 22(18âˆ—+1âˆ—â€ +3âˆ—Â§) | 5(4â€ +1â€ Â§) | 27(3â€ Â§+3â€ +21Â§) | 2â€ 
Äa lá»›p | 17(15âˆ—+1âˆ—â€ +1âˆ—Â§) | 4â€  | 7(2â€ Â§+1â€ + 4Â§) | 2â€ 
Há»“i quy | 0 | 14âˆ— | 19Â§ | 2â€ 
Tá»•ng | 39 | 23 | 53 | 6

11 táº­p dá»¯ liá»‡u khÃ´ng Ä‘Æ°á»£c chá»‰ Ä‘á»‹nh, 10 táº­p dá»¯ liá»‡u trÃ¹ng láº·p vá»›i cá»§a chÃºng tÃ´i, vÃ  1 táº­p dá»¯ liá»‡u gá»“m cÃ¡c máº«u hÃ¬nh áº£nh. Báº£ng 1 bao gá»“m tÃ³m táº¯t táº¥t cáº£ 121 táº­p dá»¯ liá»‡u benchmark. Thá»‘ng kÃª chi tiáº¿t cá»§a táº¥t cáº£ cÃ¡c táº­p dá»¯ liá»‡u Ä‘Æ°á»£c hiá»ƒn thá»‹ trong phá»¥ lá»¥c. Nhá»¯ng thá»‘ng kÃª nÃ y bao gá»“m tÃªn, sá»‘ hÃ ng vÃ  cá»™t, sá»‘ Ä‘áº·c trÆ°ng sá»‘, phÃ¢n loáº¡i, vÃ  vÄƒn báº£n, sá»‘ lá»›p, kÃ­ch thÆ°á»›c, nguá»“n, vÃ  cÃ¡c bÃ i bÃ¡o Ä‘Ã£ Ä‘Ã¡nh giÃ¡ trÃªn chÃºng.

5.2 Baseline
ChÃºng tÃ´i xÃ¡c thá»±c thá»±c nghiá»‡m KGpip so vá»›i ba há»‡ thá»‘ng AutoML: (1) Auto-Sklearn (v0.14.0) [ 9] lÃ  ngÆ°á»i chiáº¿n tháº¯ng tá»•ng thá»ƒ cá»§a nhiá»u thá»­ thÃ¡ch trong cuá»™c thi ChaLearn AutoML [ 12], vÃ  má»™t trong 4 Ä‘á»‘i thá»§ hÃ ng Ä‘áº§u Ä‘Æ°á»£c bÃ¡o cÃ¡o trong Open AutoML Benchmark [11]. (2) FLAML (v0.6.6) [ 30]: má»™t thÆ° viá»‡n AutoML Ä‘Æ°á»£c thiáº¿t káº¿ vá»›i cáº£ Ä‘á»™ chÃ­nh xÃ¡c vÃ  chi phÃ­ tÃ­nh toÃ¡n trong tÃ¢m trÃ­. FLAML vÆ°á»£t trá»™i Auto-Sklearn trong sá»‘ cÃ¡c há»‡ thá»‘ng khÃ¡c trÃªn hai benchmark AutoML sá»­ dá»¥ng ngÃ¢n sÃ¡ch tÃ­nh toÃ¡n tháº¥p, (3) AL [ 2]: má»™t phÆ°Æ¡ng phÃ¡p AutoML dá»±a trÃªn meta-learning sá»­ dá»¥ng phÃ¢n tÃ­ch Ä‘á»™ng cá»§a cÃ¡c notebook Kaggle, má»™t phÆ°Æ¡ng phÃ¡p cÃ³ Ä‘iá»ƒm tÆ°Æ¡ng Ä‘á»“ng vá»›i cá»§a chÃºng tÃ´i, vÃ  (4) VolcanoML (v0.5.0) [ 17], má»™t phÆ°Æ¡ng phÃ¡p AutoML gáº§n Ä‘Ã¢y Ä‘á» xuáº¥t cÃ¡c chiáº¿n lÆ°á»£c phÃ¢n rÃ£ hiá»‡u quáº£ cho khÃ´ng gian tÃ¬m kiáº¿m AutoML lá»›n. Trong táº¥t cáº£ cÃ¡c thá»±c nghiá»‡m cá»§a chÃºng tÃ´i, chÃºng tÃ´i Ä‘Ã£ sá»­ dá»¥ng mÃ£ má»›i nháº¥t Ä‘Æ°á»£c cung cáº¥p bá»Ÿi cÃ¡c tÃ¡c giáº£ cho cÃ¡c há»‡ thá»‘ng hiá»‡n cÃ³, cÃ¹ng pháº§n cá»©ng, ngÃ¢n sÃ¡ch thá»i gian, vÃ  cÃ¡c tham sá»‘ Ä‘Æ°á»£c khuyáº¿n nghá»‹ bá»Ÿi cÃ¡c tÃ¡c giáº£ cá»§a nhá»¯ng há»‡ thá»‘ng nÃ y.

5.3 Thiáº¿t láº­p Huáº¥n luyá»‡n
Bá»Ÿi vÃ¬ phÆ°Æ¡ng phÃ¡p cá»§a chÃºng tÃ´i Ä‘á»ƒ khai thÃ¡c cÃ¡c pipeline lá»‹ch sá»­ tá»« cÃ¡c script tÆ°Æ¡ng Ä‘á»‘i ráº», chÃºng tÃ´i cÃ³ thá»ƒ Ã¡p dá»¥ng nÃ³ dá»… dÃ ng hÆ¡n trÃªn má»™t loáº¡t cÃ¡c táº­p dá»¯ liá»‡u rá»™ng hÆ¡n Ä‘á»ƒ táº¡o thÃ nh má»™t cÆ¡ sá»Ÿ tá»‘t hÆ¡n khi ngÃ y cÃ ng nhiá»u script Ä‘Æ°á»£c táº¡o ra bá»Ÿi cÃ¡c chuyÃªn gia lÄ©nh vá»±c trong cÃ¡c cuá»™c thi Kaggle. Trong cÃ´ng trÃ¬nh nÃ y, chÃºng tÃ´i Ä‘Ã£ thá»±c hiá»‡n phÃ¢n tÃ­ch chÆ°Æ¡ng trÃ¬nh trÃªn 11.7K script liÃªn quan Ä‘áº¿n 142 táº­p dá»¯ liá»‡u, vÃ  sau Ä‘Ã³ chá»n nhá»¯ng script cÃ³ estimator tá»« sklearn , XGBoost vÃ  LightGBM vÃ¬ Ä‘Ã³ lÃ  nhá»¯ng estimator Ä‘Æ°á»£c há»— trá»£ bá»Ÿi háº§u háº¿t cÃ¡c há»‡ thá»‘ng AutoML cho phÃ¢n loáº¡i vÃ  há»“i quy. Äiá»u nÃ y dáº«n Ä‘áº¿n viá»‡c lá»±a chá»n 2,046 notebook cho 104 táº­p dá»¯ liá»‡u; má»™t pháº§n lá»›n cá»§a 11.7K chÆ°Æ¡ng trÃ¬nh lÃ  vá» phÃ¢n tÃ­ch dá»¯ liá»‡u khÃ¡m phÃ¡, hoáº·c liÃªn quan Ä‘áº¿n cÃ¡c thÆ° viá»‡n khÃ´ng Ä‘Æ°á»£c há»— trá»£ bá»Ÿi Auto-Sklearn [ 9] hoáº·c FLAML (vÃ­ dá»¥, PyTorch vÃ  Keras) [ 30]. ChÃºng tÃ´i Ä‘Ã£ sá»­ dá»¥ng Macro F1 cho cÃ¡c tÃ¡c vá»¥ phÃ¢n loáº¡i Ä‘á»ƒ tÃ­nh Ä‘áº¿n sá»± máº¥t cÃ¢n báº±ng dá»¯ liá»‡u, náº¿u cÃ³, vÃ  sá»­ dá»¥ng ğ‘…Â² cho cÃ¡c tÃ¡c vá»¥ há»“i quy, nhÆ° trong FLAML [ 30]. ChÃºng tÃ´i cÅ©ng thay Ä‘á»•i ngÃ¢n sÃ¡ch thá»i gian Ä‘Æ°á»£c cung cáº¥p cho má»—i há»‡ thá»‘ng giá»¯a 1 giá» vÃ  30 phÃºt, Ä‘á»ƒ Ä‘o KGpip cÃ³ thá»ƒ tÃ¬m má»™t pipeline hiá»‡u quáº£ nhanh nhÆ° tháº¿ nÃ o so vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p khÃ¡c. NgÃ¢n sÃ¡ch thá»i gian lÃ  tá»« Ä‘áº§u Ä‘áº¿n cuá»‘i, tá»« viá»‡c táº£i táº­p dá»¯ liá»‡u Ä‘áº¿n táº¡o ra pipeline AutoML tá»‘t nháº¥t. Trong táº¥t cáº£ cÃ¡c thá»±c nghiá»‡m, chÃºng tÃ´i bÃ¡o cÃ¡o trung bÃ¬nh trÃªn 3 láº§n cháº¡y.

Báº£ng 2: Äiá»ƒm sá»‘ trung bÃ¬nh (trung bÃ¬nh vÃ  Ä‘á»™ lá»‡ch chuáº©n) cá»§a KGpip so vá»›i FLAML, Auto-Sklearn, vÃ  VolcanoML cho phÃ¢n loáº¡i nhá»‹ phÃ¢n (F1), phÃ¢n loáº¡i Ä‘a lá»›p (F1) vÃ  cÃ¡c tÃ¡c vá»¥ há»“i quy ( ğ‘…Â²) trÃªn 77 táº­p dá»¯ liá»‡u benchmark. GiÃ¡ trá»‹ T-test cho KGpip vs. FLAML vÃ  KGpip vs. Auto-Sklearn.

| | Nhá»‹ phÃ¢n | Äa lá»›p | Há»“i quy | T-Test |
|---|---|---|---|---|
| FLAML | 0.74 (0.23) | 0.70 (0.29) | 0.65 (0.29) | 0.0129 |
| KGpip_FLAML | 0.81 (0.14) | 0.76 (0.24) | 0.72 (0.24) | - |
| Auto-Sklearn | 0.76 (0.20) | 0.65 (0.29) | 0.71 (0.24) | 0.0002 |
| KGpip_AutoSklearn | 0.83 (0.14) | 0.73 (0.28) | 0.72 (0.24) | - |
| VolcanoML | 0.55 (0.43) | 0.51 (0.38) | 0.56 (0.32) | - |

5.4 So sÃ¡nh vá»›i CÃ¡c Há»‡ thá»‘ng Hiá»‡n cÃ³
Trong má»¥c nÃ y, chÃºng tÃ´i Ä‘Ã¡nh giÃ¡ KGpip so vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p tiÃªn tiáº¿n; FLAML [ 30] vÃ  Auto-Sklearn [ 9]. HÃ¬nh 6 hiá»ƒn thá»‹ biá»ƒu Ä‘á»“ radar cá»§a táº¥t cáº£ cÃ¡c há»‡ thá»‘ng khi Ä‘Æ°á»£c cung cáº¥p ngÃ¢n sÃ¡ch thá»i gian 1 giá». NÃ³ hiá»ƒn thá»‹ hiá»‡u suáº¥t cá»§a táº¥t cáº£ cÃ¡c há»‡ thá»‘ng trÃªn ba tÃ¡c vá»¥ trong táº¥t cáº£ cÃ¡c benchmark, cá»¥ thá»ƒ lÃ  phÃ¢n loáº¡i nhá»‹ phÃ¢n, phÃ¢n loáº¡i Ä‘a lá»›p, vÃ  há»“i quy. Äá»‘i vá»›i má»—i táº­p dá»¯ liá»‡u, hÃ¬nh hiá»ƒn thá»‹ sá»‘ liá»‡u hiá»‡u suáº¥t thá»±c táº¿ (F1 cho phÃ¢n loáº¡i vÃ  ğ‘…Â² cho há»“i quy) Ä‘Æ°á»£c thu tá»« má»—i há»‡ thá»‘ng 1. Do Ä‘Ã³, Ä‘Æ°á»ng cong ngoÃ i cÃ¹ng tá»« tÃ¢m cá»§a biá»ƒu Ä‘á»“ radar cÃ³ hiá»‡u suáº¥t tá»‘t nháº¥t. Trong HÃ¬nh 6, cáº£ hai biáº¿n thá»ƒ cá»§a KGpip Ä‘áº¡t Ä‘Æ°á»£c hiá»‡u suáº¥t tá»‘t nháº¥t trÃªn táº¥t cáº£ cÃ¡c tÃ¡c vá»¥, vÆ°á»£t trá»™i cáº£ FLAML vÃ  Auto-Sklearn. ChÃºng tÃ´i cÅ©ng thá»±c hiá»‡n kiá»ƒm Ä‘á»‹nh t hai phÃ­a giá»¯a hiá»‡u suáº¥t thu Ä‘Æ°á»£c bá»Ÿi KGpip so vá»›i cÃ¡c há»‡ thá»‘ng khÃ¡c. Káº¿t quáº£ cho tháº¥y KGpip Ä‘áº¡t Ä‘Æ°á»£c hiá»‡u suáº¥t tá»‘t hÆ¡n Ä‘Ã¡ng ká»ƒ so vá»›i cáº£ FLAML vÃ  Auto-Sklearn vá»›i giÃ¡ trá»‹ t-Test láº§n lÆ°á»£t lÃ  0.01 vÃ  0.0002 (cáº£ hai Ä‘á»u cÃ³ ğ‘<0.05).

Báº£ng 2 cÅ©ng hiá»ƒn thá»‹ cÃ¡c giÃ¡ trá»‹ F1 vÃ  ğ‘…Â² trung bÃ¬nh cho cÃ¡c tÃ¡c vá»¥ phÃ¢n loáº¡i vÃ  há»“i quy, tÆ°Æ¡ng á»©ng. Káº¿t quáº£ cho tháº¥y cáº£ hai biáº¿n thá»ƒ cá»§a KGpip Ä‘áº¡t Ä‘Æ°á»£c hiá»‡u suáº¥t tá»‘t hÆ¡n so vá»›i cáº£ FLAML vÃ  Auto-Sklearn trÃªn táº¥t cáº£ cÃ¡c tÃ¡c vá»¥ vÃ  táº­p dá»¯ liá»‡u.

Kháº£ nÄƒng má»Ÿ rá»™ng cá»§a meta-learning KGpip so vá»›i cÃ¡c há»‡ thá»‘ng hiá»‡n cÃ³ : PhÆ°Æ¡ng phÃ¡p meta-learning AL [ 2] khai thÃ¡c pipeline báº±ng phÃ¢n tÃ­ch mÃ£ Ä‘á»™ng, cÃ³ chi phÃ­ cao nhÆ° Ä‘Ã£ tháº£o luáº­n trong Má»¥c 3.1. Do Ä‘Ã³, cÃ¡c tÃ¡c giáº£ cá»§a AL Ä‘Ã£ cung cáº¥p má»™t mÃ´ hÃ¬nh meta-learning Ä‘Æ°á»£c Ä‘Ã o táº¡o trÆ°á»›c trÃªn 500 pipeline vÃ  9 táº­p dá»¯ liá»‡u, Ä‘iá»u nÃ y khÃ´ng má»Ÿ rá»™ng Ä‘á»ƒ bao phá»§ cÃ¡c trÆ°á»ng há»£p khÃ¡c nhau. NgÆ°á»£c láº¡i, chÃºng tÃ´i Ä‘Ã£ huáº¥n luyá»‡n mÃ´ hÃ¬nh meta-learning cá»§a chÃºng tÃ´i sá»­ dá»¥ng 2000 pipeline vÃ  142 táº­p dá»¯ liá»‡u. KhÃ´ng cÃ³ táº­p dá»¯ liá»‡u nÃ o trong sá»‘ nÃ y Ä‘Æ°á»£c bao gá»“m trong 77 táº­p dá»¯ liá»‡u Ä‘Æ°á»£c sá»­ dá»¥ng trong thá»­ nghiá»‡m. AL tháº¥t báº¡i trong 22 vÃ  háº¿t thá»i gian trong 38 táº­p dá»¯ liá»‡u. Äiá»u nÃ y cho tháº¥y ráº±ng phÆ°Æ¡ng phÃ¡p meta-learning KGpip, dá»±a trÃªn ngá»¯ nghÄ©a pipeline vÃ  há»c biá»ƒu diá»…n táº­p dá»¯ liá»‡u, hiá»‡u quáº£ hÆ¡n. AL tháº¥t báº¡i trÃªn nhiá»u táº­p dá»¯ liá»‡u trong quÃ¡ trÃ¬nh fitting. NhÆ° hÃ¬nh hiá»ƒn thá»‹, KGpip váº«n vÆ°á»£t trá»™i táº¥t cáº£ cÃ¡c phÆ°Æ¡ng phÃ¡p khÃ¡c, bao gá»“m AL, má»™t cÃ¡ch Ä‘Ã¡ng ká»ƒ. TrÃªn nhá»¯ng táº­p dá»¯ liá»‡u nÃ y, AL Ä‘áº¡t Ä‘Æ°á»£c Ä‘iá»ƒm F1 tháº¥p nháº¥t trÃªn cÃ¡c tÃ¡c vá»¥ phÃ¢n loáº¡i nhá»‹ phÃ¢n vÃ  Ä‘a lá»›p vá»›i cÃ¡c giÃ¡ trá»‹ láº§n lÆ°á»£t lÃ  0.36 vÃ  0.36. Äiá»u nÃ y so vá»›i 0.74 vÃ  0.75 cá»§a FLAML, 0.73 vÃ  0.68 cá»§a Auto-Sklearn, 0.79 vÃ  0.79 cá»§a KGpip_FLAML, vÃ  0.79 vÃ  0.74 cá»§a KGpip_Auto-Sklearn.

Táº­p dá»¯ liá»‡u VolcanoML : VolcanoML Ä‘Ã£ sá»­ dá»¥ng nhiá»u táº­p dá»¯ liá»‡u khÃ´ng Ä‘Æ°á»£c bao gá»“m trong 77 táº­p dá»¯ liá»‡u cá»§a chÃºng tÃ´i á»Ÿ HÃ¬nh 6. Má»™t sá»‘ táº­p dá»¯ liá»‡u nÃ y khÃ¡ lá»›n nháº±m kiá»ƒm tra kháº£ nÄƒng má»Ÿ rá»™ng cá»§a há»‡ thá»‘ng.
Do Ä‘Ã³, chÃºng tÃ´i cÅ©ng Ä‘Ã£ thu tháº­p táº¥t cáº£ 49 táº­p dá»¯ liá»‡u mÃ  chÃºng tÃ´i cÃ³ thá»ƒ tÃ¬m tháº¥y trong bÃ i bÃ¡o cá»§a há» vÃ  kiá»ƒm tra phiÃªn báº£n tá»‘t nháº¥t cá»§a KGpip (KGpip_FLAML)

1Äiá»ƒm sá»‘ chi tiáº¿t cho má»—i há»‡ thá»‘ng vÃ  táº­p dá»¯ liá»‡u cÅ©ng nhÆ° tÃªn tÆ°Æ¡ng á»©ng cá»§a cÃ¡c táº­p dá»¯ liá»‡u Ä‘Æ°á»£c hiá»ƒn thá»‹ trong báº£ng 6-9 trong phá»¥ lá»¥c.
6

--- TRANG 7 ---
HÃ¬nh 6: Biá»ƒu Ä‘á»“ radar vá» hiá»‡u suáº¥t cá»§a KGpip so vá»›i cÃ¡c há»‡ thá»‘ng hiá»‡n cÃ³ trÃªn nhiá»u tÃ¡c vá»¥ (77 táº­p dá»¯ liá»‡u) vá»›i ngÃ¢n sÃ¡ch thá»i gian 1 giá» cho táº¥t cáº£ cÃ¡c há»‡ thá»‘ng. CÃ¡c sá»‘ bÃªn ngoÃ i chá»‰ ra ID táº­p dá»¯ liá»‡u khÃ¡c nhau vÃ  cÃ¡c váº¡ch bÃªn trong hÃ¬nh biá»ƒu thá»‹ pháº¡m vi hiá»‡u suáº¥t cá»§a cÃ¡c sá»‘ liá»‡u tÆ°Æ¡ng á»©ng; vÃ­ dá»¥, 0.2, 0.4, ..., v.v. cho F1 trong phÃ¢n loáº¡i nhá»‹ phÃ¢n. Äá»‘i vá»›i báº¥t ká»³ táº­p dá»¯ liá»‡u nÃ o, há»‡ thá»‘ng cÃ³ Ä‘Æ°á»ng cong ngoÃ i cÃ¹ng cÃ³ hiá»‡u suáº¥t tá»‘t nháº¥t. VÃ­ dá»¥, KGpip_AutoSklearn vÃ  KGpip_FLAML Ä‘áº¡t Ä‘Æ°á»£c 100% vÃ  97% F1 trÃªn táº­p dá»¯ liá»‡u #23 (phÃ¢n loáº¡i Ä‘a lá»›p) so vá»›i 65% vÃ  26% cho AutoSklearn vÃ  FLAML, tÆ°Æ¡ng á»©ng.

[Biá»ƒu Ä‘á»“ radar phá»©c táº¡p vá»›i nhiá»u há»‡ thá»‘ng so sÃ¡nh]

HÃ¬nh 7: Sá»± khÃ¡c biá»‡t Ä‘iá»ƒm sá»‘ giá»¯a KGpip_FLAML vÃ  VolcanoML trÃªn 44 táº­p dá»¯ liá»‡u phÃ¢n loáº¡i vÃ  há»“i quy tá»« VolcanoML vá»›i ngÃ¢n sÃ¡ch thá»i gian 1 giá». Äá»ƒ ngáº¯n gá»n, chÃºng tÃ´i Ä‘Ã£ loáº¡i bá» khá»i HÃ¬nh nÃ y 22 táº­p dá»¯ liá»‡u mÃ  cáº£ hai há»‡ thá»‘ng hoáº¡t Ä‘á»™ng tÆ°Æ¡ng Ä‘Æ°Æ¡ng (trong pháº¡m vi khÃ¡c biá»‡t â‰¤0.01).

Báº£ng 3: Äiá»ƒm sá»‘ trung bÃ¬nh (trung bÃ¬nh vÃ  Ä‘á»™ lá»‡ch chuáº©n) cá»§a KGpip_FLAML so vá»›i VolcanoML trÃªn 44 táº­p dá»¯ liá»‡u tá»« VolcanoML. NhÃ¬n chung, KGpip_FLAML Ä‘áº¡t Ä‘Æ°á»£c tá»‘t hÆ¡n Ä‘Ã¡ng ká»ƒ so vá»›i VolcanoML, theo má»™t kiá»ƒm Ä‘á»‹nh Ã½ nghÄ©a thá»‘ng kÃª cá»§a ğ‘<0.05.

| | Nhá»‹ phÃ¢n | Äa lá»›p | Há»“i quy | T-Test |
|---|---|---|---|---|
| KGpip_FLAML | 0.82 (0.14) | 0.86 (0.16) | 0.83 (0.13) | - |
| VolcanoML | 0.69 (0.23) | 0.70 (0.31) | 0.68 (0.25) | 0.0001 |

so vá»›i VolcanoML trÃªn nhá»¯ng táº­p dá»¯ liá»‡u nÃ y vá»›i ngÃ¢n sÃ¡ch thá»i gian 1 giá».
Hiá»‡u suáº¥t cá»§a KGpip_FLAML vÃ  VolcanoML Ä‘Æ°á»£c hiá»ƒn thá»‹ trong HÃ¬nh 7. Äá»ƒ ngáº¯n gá»n, chÃºng tÃ´i Ä‘Ã£ bá» qua khá»i hÃ¬nh táº¥t cáº£ cÃ¡c táº­p dá»¯ liá»‡u mÃ  sá»± khÃ¡c biá»‡t hiá»‡u suáº¥t giá»¯a cáº£ hai há»‡ thá»‘ng â‰¤0.01 vÃ  cÃ¡c táº­p dá»¯ liá»‡u trÃ¹ng láº·p vá»›i nhá»¯ng táº­p Ä‘Æ°á»£c hiá»ƒn thá»‹ trong HÃ¬nh 6. TrÃªn nhá»¯ng táº­p dá»¯ liá»‡u Ä‘Ã³, KGpip_FLAML tÃ¬m tháº¥y má»™t pipeline há»£p lá»‡ cho táº¥t cáº£ chÃºng, Ä‘Ã´i khi vá»›i sá»± khÃ¡c biá»‡t tuyá»‡t Ä‘á»‘i Ä‘Ã¡ng ká»ƒ trong Ä‘iá»ƒm F1 hoáº·c ğ‘…Â² â‰¥0.90. TrÃªn táº¥t cáº£ 44 táº­p dá»¯ liá»‡u, KGpip_FLAML Ä‘áº¡t Ä‘Æ°á»£c trung bÃ¬nh Ä‘iá»ƒm sá»‘ tá»‘t hÆ¡n Ä‘Ã¡ng ká»ƒ so vá»›i VolcanoML (kiá»ƒm Ä‘á»‹nh Ã½ nghÄ©a thá»‘ng kÃª cá»§a ğ‘< 0.05), xem Báº£ng 3 Ä‘á»ƒ biáº¿t chi tiáº¿t.

Báº£ng 4: CÃ¡c khÃ­a cáº¡nh khÃ¡c nhau so sÃ¡nh má»™t mÃ´ hÃ¬nh Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn má»™t táº­p cÃ¡c Ä‘á»“ thá»‹ mÃ£ so vá»›i má»™t mÃ´ hÃ¬nh Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn má»™t táº­p cÃ¡c Ä‘á»“ thá»‹ MetaPip. MÃ´ hÃ¬nh dá»±a trÃªn Ä‘á»“ thá»‹ mÃ£ gá»‘c tháº¥t báº¡i trong cÃ¡c táº­p dá»¯ liá»‡u táº§m thÆ°á»ng Ä‘á»ƒ sinh ra cÃ¡c pipeline há»£p lá»‡ vÃ  giá»›i háº¡n kháº£ nÄƒng má»Ÿ rá»™ng cá»§a KGpip Ä‘áº¿n má»™t táº­p lá»›n hÆ¡n cÃ¡c script pipeline ML vÃ  viá»‡c há»c cá»§a KGpip báº±ng cÃ¡ch sá»­ dá»¥ng Ã­t epoch hÆ¡n.

| Táº­p dá»¯ liá»‡u/KhÃ­a cáº¡nh | Äá»“ thá»‹ MÃ£ | Äá»“ thá»‹ MetaPip |
|---|---|---|
| kr-vs-kp | 0 (0) | 1.00 (0) |
| nomao | 0 (0) | 0.96 (0) |
| cnae-9 | 0 (0) | 0.95 (0.01) |
| mfeat-factors | 0 (0) | 0.98 (0) |
| segment | 0 (0) | 0.98 (0) |
| Trung bÃ¬nh F1 | 0 (0) | 0.97 (0.02) |
| Sá»‘ NÃºt | 29,139 | 974 |
| Sá»‘ Cáº¡nh | 252,486 | 1,052 |
| Thá»i gian Huáº¥n luyá»‡n | 175 (phÃºt) | 2 (phÃºt) |

5.5 NghiÃªn cá»©u Ablation
5.5.1 Hiá»‡u quáº£ cá»§a MetaPip. PhÆ°Æ¡ng phÃ¡p MetaPip cá»§a chÃºng tÃ´i quáº£n lÃ½ Ä‘á»ƒ giáº£m Ä‘Ã¡ng ká»ƒ sá»‘ lÆ°á»£ng nÃºt vÃ  cáº¡nh trong Ä‘á»“ thá»‹ mÃ£. Sá»­ dá»¥ng Ä‘á»“ thá»‹ gá»‘c thu Ä‘Æ°á»£c tá»« phÃ¢n tÃ­ch tÄ©nh, nÃ³ táº¡o ra Ä‘á»“ thá»‹ MetaPip táº­p trung vÃ o cÃ¡c khÃ­a cáº¡nh cá»‘t lÃµi cáº§n thiáº¿t Ä‘á»ƒ huáº¥n luyá»‡n má»™t mÃ´ hÃ¬nh sinh Ä‘á»“ thá»‹ cho pipeline ML, nhÆ° phÃ©p biáº¿n Ä‘á»•i dá»¯ liá»‡u, lá»±a chá»n bá»™ há»c, vÃ  lá»±a chá»n siÃªu tham sá»‘.
Thá»±c nghiá»‡m nÃ y Ä‘iá»u tra kháº£ nÄƒng má»Ÿ rá»™ng cá»§a mÃ´ hÃ¬nh sinh Ä‘á»“ thá»‹ cá»§a chÃºng tÃ´i dá»±a trÃªn hai táº­p huáº¥n luyá»‡n khÃ¡c nhau, tá»©c lÃ  táº­p cÃ¡c Ä‘á»“ thá»‹ MetaPip Ä‘Æ°á»£c mÃ´ táº£ trong má»¥c 3.2 so vá»›i táº­p gá»‘c cÃ¡c Ä‘á»“ thá»‹ mÃ£ tá»« phÃ¢n tÃ­ch tÄ©nh cho cÃ¹ng cÃ¡c script pipeline ML.

Äá»‘i vá»›i thá»±c nghiá»‡m nÃ y, chÃºng tÃ´i sá»­ dá»¥ng má»™t táº­p huáº¥n luyá»‡n quy mÃ´ nhá» gá»“m 82 Ä‘á»“ thá»‹ pipeline liÃªn quan Ä‘áº¿n má»™t táº­p dá»¯ liá»‡u phÃ¢n loáº¡i. CÃ¡c Ä‘á»“ thá»‹ mÃ£ gá»‘c cho 82 pipeline nÃ y bao gá»“m 29,139 nÃºt vÃ  252,486 cáº¡nh. Tuy nhiÃªn, Ä‘á»“ thá»‹ MetaPip cá»§a chÃºng tÃ´i bao gá»“m 974 nÃºt vÃ  1052 cáº¡nh. ÄÃ¢y lÃ  tá»· lá»‡ giáº£m Ä‘á»“ thá»‹ Ã­t nháº¥t 96.6%,
7

--- TRANG 8 ---
[BIá»‚U Äá»’: Hiá»ƒn thá»‹ sá»‘ lÆ°á»£ng pipeline vÃ  cÃ¡c loáº¡i learner/transformer Ä‘Æ°á»£c KGpip chá»n]

HÃ¬nh 8: CÃ¡c learner vÃ  transformer hÃ ng Ä‘áº§u Ä‘Æ°á»£c KGpip chá»n (A) cÃ³ pháº¡m vi bao phá»§ vÃ  Ä‘a dáº¡ng rá»™ng (B).

Báº£ng 5: Hiá»‡u suáº¥t cá»§a KGpip_FLAML (trung bÃ¬nh vÃ  Ä‘á»™ lá»‡ch chuáº©n) khi chÃºng tÃ´i thay Ä‘á»•i sá»‘ lÆ°á»£ng Ä‘á»“ thá»‹ pipeline Ä‘Æ°á»£c dá»± Ä‘oÃ¡n trong giá»›i háº¡n thá»i gian 30 phÃºt. ChÃºng tÃ´i thu Ä‘Æ°á»£c káº¿t quáº£ tÆ°Æ¡ng tá»± cho KGpip_AutoSklearn, vÃ  do Ä‘Ã³ bá» qua káº¿t quáº£ cá»§a nÃ³.

| | Nhá»‹ phÃ¢n | Äa lá»›p | Há»“i quy |
|---|---|---|---|
| Top-3 graphs | 0.80 (0.14) | 0.70 (0.31) | 0.71 (0.23) |
| Top-5 graphs | 0.81 (0.14) | 0.73 (0.26) | 0.70 (0.23) |
| Top-7 graphs | 0.81 (0.14) | 0.75 (0.24) | 0.71 (0.24) |

HÃ¬nh 4 hiá»ƒn thá»‹ nhá»¯ng thá»‘ng kÃª chi tiáº¿t nÃ y. Cuá»™c Ä‘iá»u tra chÃ­nh á»Ÿ Ä‘Ã¢y lÃ  liá»‡u tá»· lá»‡ giáº£m khá»•ng lá»“ nÃ y cÃ³ giÃºp cáº£i thiá»‡n Ä‘á»™ chÃ­nh xÃ¡c vÃ  kháº£ nÄƒng má»Ÿ rá»™ng cá»§a mÃ´ hÃ¬nh sinh Ä‘á»“ thá»‹ cá»§a chÃºng tÃ´i hay khÃ´ng. ChÃºng tÃ´i huáº¥n luyá»‡n má»™t mÃ´ hÃ¬nh trÃªn Ä‘á»“ thá»‹ mÃ£ gá»‘c vÃ  má»™t mÃ´ hÃ¬nh khÃ¡c trÃªn cÃ¡c Ä‘á»“ thá»‹ MetaPip. Cáº£ hai mÃ´ hÃ¬nh Ä‘á»u Ä‘Æ°á»£c huáº¥n luyá»‡n trong 15 epoch vá»›i cÃ¹ng táº­p siÃªu tham sá»‘. Äiá»u Ä‘Ã¡ng chÃº Ã½ lÃ  do thá»i gian ráº¥t lá»›n cáº§n thiáº¿t Ä‘á»ƒ xá»­ lÃ½ cÃ¡c nÃºt vÃ  cáº¡nh trong Ä‘á»“ thá»‹ mÃ£, chÃºng tÃ´i pháº£i giáº£m sá»‘ epoch tá»« 400 xuá»‘ng 15.

ChÃºng tÃ´i kiá»ƒm tra hiá»‡u suáº¥t cá»§a KGpip khi Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn cáº£ hai Ä‘á»“ thá»‹ trÃªn cÃ¡c táº­p dá»¯ liá»‡u phÃ¢n loáº¡i nhá»‹ phÃ¢n vÃ  Ä‘a lá»›p táº§m thÆ°á»ng nháº¥t trong benchmark AutoML. ÄÃ¢y lÃ  nhá»¯ng táº­p dá»¯ liá»‡u mÃ  Ä‘iá»ƒm F1 cá»§a táº¥t cáº£ cÃ¡c há»‡ thá»‘ng Ä‘Æ°á»£c bÃ¡o cÃ¡o trong má»¥c 5.4 trÃªn 0.9. Káº¿t quáº£ lÃ  tá»•ng cá»™ng 5 táº­p dá»¯ liá»‡u (1 nhá»‹ phÃ¢n vÃ  4 Ä‘a lá»›p). Cáº£ hai mÃ´ hÃ¬nh Ä‘á»u sá»­ dá»¥ng Auto-Sklearn lÃ m bá»™ tá»‘i Æ°u hÃ³a siÃªu tham sá»‘ vá»›i ngÃ¢n sÃ¡ch thá»i gian 15 phÃºt vÃ  3 Ä‘á»“ thá»‹. ChÃºng tÃ´i láº¥y trung bÃ¬nh cá»§a ba láº§n cháº¡y.
Káº¿t quáº£ Ä‘Æ°á»£c tÃ³m táº¯t trong Báº£ng 4. Äá»‘i vá»›i nhá»¯ng táº­p dá»¯ liá»‡u táº§m thÆ°á»ng nÃ y, mÃ´ hÃ¬nh Ä‘Æ°á»£c huáº¥n luyá»‡n báº±ng Ä‘á»“ thá»‹ mÃ£ khÃ´ng thá»ƒ sinh ra báº¥t ká»³ pipeline ML há»£p lá»‡ nÃ o. Äiá»u nÃ y cÃ³ nghÄ©a lÃ  mÃ´ hÃ¬nh tháº¥t báº¡i trong viá»‡c náº¯m báº¯t cÃ¡c khÃ­a cáº¡nh cá»‘t lÃµi cá»§a pipeline ML, tá»©c lÃ  phÃ©p biáº¿n Ä‘á»•i hoáº·c bá»™ há»c há»£p lá»‡.
HÆ¡n ná»¯a, phÆ°Æ¡ng phÃ¡p MetaPip cá»§a chÃºng tÃ´i giÃºp KGpip giáº£m thá»i gian huáº¥n luyá»‡n 99%, nhÆ° Ä‘Æ°á»£c hiá»ƒn thá»‹ trong Báº£ng 4.

5.5.2 Cháº¥t lÆ°á»£ng meta-learning cá»§a KGpip. Thá»±c nghiá»‡m nÃ y kiá»ƒm tra cháº¥t lÆ°á»£ng cá»§a thÃ nh pháº§n meta-learning cá»§a chÃºng tÃ´i. ChÃºng tÃ´i kiá»ƒm tra hiá»‡u suáº¥t khi thay Ä‘á»•i sá»‘ lÆ°á»£ng Ä‘á»“ thá»‹ Ä‘Æ°á»£c chá»n tá»« giai Ä‘oáº¡n sinh Ä‘á»“ thá»‹ trÆ°á»›c khi Ä‘Æ°a vÃ o module tá»‘i Æ°u hÃ³a siÃªu tham sá»‘. Báº£ng 5 hiá»ƒn thá»‹ hiá»‡u suáº¥t KGpip_FLAML khi chÃºng tÃ´i thay Ä‘á»•i sá»‘ lÆ°á»£ng Ä‘á»“ thá»‹ Ä‘Æ°á»£c dá»± Ä‘oÃ¡n giá»¯a 3, 5 vÃ  7.

Chá»‰ vá»›i 3 Ä‘á»“ thá»‹, KGpip váº«n vÆ°á»£t trá»™i FLAML (há»‡ thá»‘ng tá»‘t thá»© hai sau KGpip_FLAML) , máº·c dÃ¹ hiá»‡u á»©ng yáº¿u hÆ¡n (giÃ¡ trá»‹ t-Test = 0.06). So vá»›i Auto-sklearn (há»‡ thá»‘ng tá»‘t thá»© ba sau KGpip_FLAML), táº¥t cáº£ cÃ¡c biáº¿n thá»ƒ Ä‘á»u cÃ³ hiá»‡u suáº¥t tÆ°Æ¡ng tá»± hoáº·c tá»‘t hÆ¡n, nhÆ°ng sá»± khÃ¡c biá»‡t khÃ´ng Ä‘Ã¡ng ká»ƒ. Thá»±c nghiá»‡m nÃ y cho tháº¥y ráº±ng ngay cáº£ vá»›i ba Ä‘á»“ thá»‹, KGpip vÆ°á»£t trá»™i FLAML vÃ  KGpip_Auto-Sklearn, tá»©c lÃ  cÃ¡c pipeline Ä‘Ãºng thÆ°á»ng xuáº¥t hiá»‡n trong top 3. NhÆ° má»™t Ä‘Ã¡nh giÃ¡ khÃ¡c vá» cháº¥t lÆ°á»£ng dá»± Ä‘oÃ¡n cá»§a chÃºng tÃ´i, chÃºng tÃ´i Ä‘o pipeline tá»‘t nháº¥t xuáº¥t hiá»‡n á»Ÿ Ä‘Ã¢u trong danh sÃ¡ch xáº¿p háº¡ng cÃ¡c pipeline Ä‘Æ°á»£c dá»± Ä‘oÃ¡n cá»§a chÃºng tÃ´i. LÃ½ tÆ°á»Ÿng nháº¥t, pipeline hÃ ng Ä‘áº§u sáº½ luÃ´n lÃ  Ä‘áº§u tiÃªn, vÃ  chÃºng tÃ´i sá»­ dá»¥ng Mean Reciprocal Rank (MRR) Ä‘á»ƒ Ä‘o má»©c Ä‘á»™ gáº§n cá»§a dá»± Ä‘oÃ¡n cá»§a chÃºng tÃ´i vá»›i Ä‘iá»u Ä‘Ã³. TrÃªn táº¥t cáº£ cÃ¡c láº§n cháº¡y, MRR lÃ  0.71, cho tháº¥y pipeline hÃ ng Ä‘áº§u thÆ°á»ng ráº¥t gáº§n Ä‘á»‰nh.

5.5.3 TÃ­nh Ä‘a dáº¡ng meta-learning cá»§a KGpip. Má»™t cÃ¢u há»i chÃºng tÃ´i Ä‘Ã£ giáº£i quyáº¿t lÃ  liá»‡u KGpip cÃ³ táº¡o ra cÃ¡c pipeline khÃ¡c nhau cho cÃ¹ng má»™t táº­p dá»¯ liá»‡u qua cÃ¡c láº§n cháº¡y khÃ¡c nhau hay khÃ´ng. Äiá»u nÃ y cho chÃºng tÃ´i cáº£m nháº­n vá» viá»‡c KGpip cÃ³ tÃ­nh táº¥t Ä‘á»‹nh hay khÃ´ng, hoáº·c liá»‡u nÃ³ cÃ³ táº¡o ra cÃ¡c pipeline khÃ¡c nhau Ä‘á»ƒ giÃºp cáº¯t tá»‰a khÃ´ng gian tÃ¬m kiáº¿m AutoML. ChÃºng tÃ´i láº¥y cÃ¡c láº§n cháº¡y khÃ¡c nhau cho cÃ¹ng má»™t táº­p dá»¯ liá»‡u, vÃ  táº¡o ra má»™t danh sÃ¡ch cÃ¡c bá»™ há»c vÃ  transformer Ä‘Æ°á»£c táº¡o ra cho má»—i táº­p dá»¯ liá»‡u qua cÃ¡c láº§n cháº¡y. Danh sÃ¡ch Ä‘Æ°á»£c giá»›i háº¡n bá»Ÿi sá»‘ lÆ°á»£ng bá»™ há»c vÃ  transformer ngáº¯n nháº¥t Ä‘Æ°á»£c táº¡o ra qua cÃ¡c láº§n cháº¡y. Sau Ä‘Ã³ chÃºng tÃ´i tÃ­nh toÃ¡n tÆ°Æ¡ng quan cho cÃ¡c táº­p dá»¯ liá»‡u qua cÃ¡c láº§n cháº¡y 1, 2, vÃ  3. CÃ¡c tÆ°Æ¡ng quan dao Ä‘á»™ng tá»« 0.60 - 0.64, cho tháº¥y ráº±ng cÃ¡c láº§n cháº¡y khÃ´ng táº¡o ra cÃ¹ng cÃ¡c transformer vÃ  bá»™ há»c qua cÃ¡c láº§n cháº¡y. ChÃºng tÃ´i cÅ©ng kiá»ƒm tra cÃ¡c loáº¡i bá»™ há»c Ä‘Æ°á»£c KGpip chá»n Ä‘á»ƒ xem xÃ©t. HÃ¬nh 8a hiá»ƒn thá»‹ cÃ¡c bá»™ há»c vÃ  transformer Ä‘Æ°á»£c tÃ¬m tháº¥y Ã­t nháº¥t 20 láº§n trong cÃ¡c pipeline huáº¥n luyá»‡n. NgÆ°á»i ta cÃ³ thá»ƒ tháº¥y tá»« hÃ¬nh ráº±ng KGpip khÃ´ng mÃ¹ quÃ¡ng xuáº¥t ra cÃ¡c bá»™ há»c vÃ  transformer theo sá»‘ lÆ°á»£ng. HÃ¬nh 8b hiá»ƒn thá»‹ tÃ­nh Ä‘a dáº¡ng hÆ¡n trong nhá»¯ng gÃ¬ Ä‘Ã£ Ä‘Æ°á»£c chá»n tá»•ng thá»ƒ. VÃ¬ váº­y, nhiá»u phÆ°Æ¡ng phÃ¡p Ä‘Æ°á»£c bao phá»§ bá»Ÿi KGpip.

6 Káº¾T LUáº¬N
BÃ i bÃ¡o nÃ y Ä‘á» xuáº¥t má»™t cÃ´ng thá»©c má»›i cho váº¥n Ä‘á» AutoML nhÆ° má»™t váº¥n Ä‘á» sinh Ä‘á»“ thá»‹, nÆ¡i chÃºng ta cÃ³ thá»ƒ Ä‘áº·t viá»‡c lá»±a chá»n bá»™ há»c vÃ  tiá»n xá»­ lÃ½ nhÆ° viá»‡c sinh cÃ¡c Ä‘á»“ thá»‹ khÃ¡c nhau Ä‘áº¡i diá»‡n cho cÃ¡c pipeline ML. Do Ä‘Ã³, chÃºng tÃ´i Ä‘Ã£ phÃ¡t triá»ƒn há»‡ thá»‘ng KGpip dá»±a trÃªn viá»‡c khai thÃ¡c cÃ¡c kho lÆ°u trá»¯ lá»›n cÃ¡c script, vÃ  táº­n dá»¥ng cÃ¡c ká»¹ thuáº­t gáº§n Ä‘Ã¢y cho phÃ¢n tÃ­ch mÃ£ tÄ©nh. KGpip sá»­ dá»¥ng cÃ¡c embedding Ä‘Æ°á»£c táº¡o ra dá»±a trÃªn ná»™i dung táº­p dá»¯ liá»‡u Ä‘á»ƒ dá»± Ä‘oÃ¡n vÃ  tá»‘i Æ°u hÃ³a má»™t táº­p cÃ¡c pipeline ML dá»±a trÃªn cÃ¡c táº­p dá»¯ liá»‡u Ä‘Ã£ tháº¥y tÆ°Æ¡ng tá»± nháº¥t. KGpip Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ hoáº¡t Ä‘á»™ng vá»›i cÃ¡c há»‡ thá»‘ng AutoML, nhÆ° Auto-Sklearn vÃ  FLAML, Ä‘á»ƒ sá»­ dá»¥ng cÃ¡c bá»™ tá»‘i Æ°u hÃ³a siÃªu tham sá»‘ cá»§a chÃºng. ChÃºng tÃ´i Ä‘Ã£ tiáº¿n hÃ nh Ä‘Ã¡nh giÃ¡ toÃ n diá»‡n nháº¥t cá»§a 121 táº­p dá»¯ liá»‡u, bao gá»“m cÃ¡c táº­p dá»¯ liá»‡u Ä‘Æ°á»£c sá»­ dá»¥ng bá»Ÿi FLAML, VolcanoML, vÃ  AL. ÄÃ¡nh giÃ¡ toÃ n diá»‡n cá»§a chÃºng tÃ´i cho tháº¥y KGpip cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ hiá»‡u suáº¥t cá»§a FLAML vÃ  Auto-Sklearn trong cÃ¡c tÃ¡c vá»¥ phÃ¢n loáº¡i vÃ  há»“i quy.
HÆ¡n ná»¯a, KGpip vÆ°á»£t trá»™i AL, dá»±a trÃªn má»™t quÃ¡ trÃ¬nh meta-learning tá»‘n kÃ©m hÆ¡n, trong 97% cÃ¡c táº­p dá»¯ liá»‡u. Hiá»‡u suáº¥t xuáº¥t sáº¯c nÃ y cho tháº¥y ráº±ng phÆ°Æ¡ng phÃ¡p meta-learning KGpip hiá»‡u quáº£ vÃ  hiá»‡u suáº¥t hÆ¡n. Cuá»‘i cÃ¹ng, KGpip vÆ°á»£t trá»™i VolcanoML trong 62% cÃ¡c táº­p dá»¯ liá»‡u vÃ  hÃ²a vá»›i nÃ³ trong 22%.

TÃ€I LIá»†U THAM KHáº¢O
[1]Ibrahim Abdelaziz, Julian Dolby, James P. McCusker, vÃ  Kavitha Srinivas. 2020.
Má»™t Toolkit Ä‘á»ƒ Táº¡o ra Äá»“ thá»‹ Tri thá»©c MÃ£. ArXiv (2020). https://arxiv.
org/abs/2002.09440
[2]JosÃ© P. Cambronero vÃ  Martin C. Rinard. 2019. AL: Tá»± Ä‘á»™ng táº¡o ra ChÆ°Æ¡ng trÃ¬nh Há»c cÃ³ GiÃ¡m sÃ¡t. In Proceedings of the ACM on Programming Languages , Vol. 3.
https://doi.org/10.1145/3360601
[3]Daniel Cer, Yinfei Yang, Sheng-yi Kong, Nan Hua, Nicole Limtiaco, Rhomni St.
John, Noah Constant, Mario Guajardo-Cespedes, Steve Yuan, Chris Tar, Yun-
Hsuan Sung, Brian Strope, vÃ  Ray Kurzweil. 2018. Universal Sentence Encoder.
CoRR abs/1803.11175 (2018). http://arxiv.org/abs/1803.11175
[4]Alex G. C. de SÃ¡, Walter JosÃ© G. S. Pinto, Luiz Otavio V. B. Oliveira, vÃ  Gisele L.
Pappa. 2017. RECIPE: Má»™t Framework Dá»±a trÃªn Ngá»¯ phÃ¡p Ä‘á»ƒ Tá»± Ä‘á»™ng PhÃ¡t triá»ƒn CÃ¡c Pipeline PhÃ¢n loáº¡i. In Genetic Programming , James McDermott, Mauro
Castelli, Lukas Sekanina, Evert Haasdijk, vÃ  Pablo GarcÃ­a-SÃ¡nchez (Eds.). 246â€“
261. https://doi.org/10.1007/978-3-319-55696-3_16
[5]Iddo Drori, Lu Liu, Yi Nian, Sharath C Koorathota, Jung-Shian Li, Antonio Khalil
Moretti, Juliana Freire, vÃ  Madeleine Udell. 2019. AutoML sá»­ dá»¥ng Metadata
Language Embeddings. ArXiv (2019). https://arxiv.org/abs/1910.03698
[6]Robert Engels vÃ  Christiane Theusinger. 1998. Sá»­ dá»¥ng má»™t Data Metric Ä‘á»ƒ TÆ° váº¥n Tiá»n xá»­ lÃ½ cho á»¨ng dá»¥ng Khai thÃ¡c Dá»¯ liá»‡u. In In Proceedings of the European
Conference on Artificial Intelligence (ECAI) . 430â€“434. http://citeseerx.ist.psu.edu/
viewdoc/download?doi=10.1.1.56.7414&rep=rep1&type=pdf
[7]Nick Erickson, Jonas Mueller, Alexander Shirkov, Hang Zhang, Pedro Larroy,
Mu Li, vÃ  Alexander Smola. 2020. AutoGluon-Tabular: AutoML Máº¡nh máº½ vÃ  ChÃ­nh xÃ¡c cho Dá»¯ liá»‡u CÃ³ cáº¥u trÃºc. ArXiv (2020). https://arxiv.org/abs/2003.06505
[8]Matthias Feurer, Katharina Eggensperger, Stefan Falkner, Marius Lindauer, vÃ 
Frank Hutter. 2020. Auto-Sklearn 2.0: The Next Generation. arXiv (2020). https:
//arxiv.org/abs/2007.04074
[9]Matthias Feurer, Aaron Klein, Katharina Eggensperger, Jost Springenberg, Manuel
Blum, vÃ  Frank Hutter. 2015. Há»c MÃ¡y Tá»± Ä‘á»™ng Hiá»‡u quáº£ vÃ  Máº¡nh máº½.
InProceedings of the International Conference on Neural Information Processing
Systems (NeurIPS) . 2962â€“2970. https://dl.acm.org/doi/10.5555/2969442.2969547
[10] Nicolo Fusi, Rishit Sheth, vÃ  Melih Elibol. 2018. PhÃ¢n rÃ£ Ma tráº­n XÃ¡c suáº¥t cho Há»c MÃ¡y Tá»± Ä‘á»™ng. In Proceedings of the Interna-
tional Conference on Neural Information Processing Systems (NeurIPS) . 3352â€“3361.
https://dl.acm.org/doi/10.5555/3327144.3327254
[11] P. Gijsbers, E. LeDell, S. Poirier, J. Thomas, B. Bischl, vÃ  J. Vanschoren. 2019.
Má»™t Benchmark AutoML MÃ£ nguá»“n Má»Ÿ. In AutoML Workshop at the International
Conference on Machine Learning (ICML) . https://arxiv.org/abs/1907.00909
[12] Isabelle Guyon, Imad Chaabane, Hugo Jair Escalante, Sergio Escalera, Damir
Jajetic, James Robert Lloyd, NÃºria MaciÃ , Bisakha Ray, Lukasz Romaszko, MichÃ¨le
Sebag, Alexander Statnikov, SÃ©bastien Treguer, vÃ  Evelyne Viegas. 2016. Má»™t ÄÃ¡nh giÃ¡ Ngáº¯n gá»n vá» Thá»­ thÃ¡ch ChaLearn AutoML: Há»c Báº¥t cá»© lÃºc nÃ o Báº¥t cá»© táº­p dá»¯ liá»‡u nÃ o mÃ  khÃ´ng cÃ³ Sá»± can thiá»‡p cá»§a Con ngÆ°á»i. In Proceedings of Machine Learning Research , Vol. 64.
21â€“30. https://proceedings.mlr.press/v64/guyon_review_2016.html
[13] Jeff Johnson, Matthijs Douze, vÃ  HervÃ© JÃ©gou. 2021. TÃ¬m kiáº¿m Äá»™ tÆ°Æ¡ng tá»± Quy mÃ´ Tá»· vá»›i GPUs. IEEE Transactions on Big Data 7, 3 (2021), 535â€“547. https:
//doi.org/10.1109/TBDATA.2019.2921572
[14] Michael Katz, Parikshit Ram, Shirin Sohrabi, vÃ  Octavian Udrea. 2020. KhÃ¡m phÃ¡ NgÃ´n ngá»¯ KhÃ´ng cÃ³ Ngá»¯ cáº£nh thÃ´ng qua Láº­p káº¿ hoáº¡ch: TrÆ°á»ng há»£p Tá»± Ä‘á»™ng hÃ³a Há»c MÃ¡y. In Proceedings of the International Conference on Automated Planning
and Scheduling (ICAPS) . 403â€“411. https://ojs.aaai.org//index.php/ICAPS/article/
view/6686
[15] Trang T Le, Weixuan Fu, vÃ  Jason H Moore. 2020. Má»Ÿ rá»™ng há»c mÃ¡y tá»± Ä‘á»™ng dá»±a trÃªn cÃ¢y Ä‘áº¿n dá»¯ liá»‡u lá»›n sinh y há»c vá»›i bá»™ chá»n táº­p Ä‘áº·c trÆ°ng. Bioinformatics
36, 1 (2020), 250â€“256. https://doi.org/10.1093/bioinformatics/btz470
[16] Erin LeDell vÃ  Sebastien Poirier. 2020. H2O AutoML: Há»c MÃ¡y Tá»± Ä‘á»™ng CÃ³ thá»ƒ Má»Ÿ rá»™ng. In AutoML Workshop at the International Conference on Machine
Learning (ICML) . www.automl.org/wp-content/uploads/2020/07/AutoML_2020_
paper_61.pdf
[17] Yang Li, Yu Shen, Wentao Zhang, Jiawei Jiang, Yaliang Li, Bolin Ding, Jingren
Zhou, Zhi Yang, Wentao Wu, Ce Zhang, vÃ  Bin Cui. 2021. VolcanoML: TÄƒng tá»‘c AutoML End-to-End thÃ´ng qua PhÃ¢n rÃ£ KhÃ´ng gian TÃ¬m kiáº¿m CÃ³ thá»ƒ Má»Ÿ rá»™ng. Proceedings
of the VLDB Endowment 14, 11 (2021), 2167â€“2176. http://www.vldb.org/pvldb/
vol14/p2167-li.pdf
[18] Yujia Li, Oriol Vinyals, Chris Dyer, Razvan Pascanu, vÃ  Peter Battaglia. 2018.
Há»c CÃ¡c MÃ´ hÃ¬nh Sinh SÃ¢u cá»§a Äá»“ thá»‹. ArXiv (2018). https://arxiv.org/
abs/1803.03324
[19] Sijia Liu, Parikshit Ram, Deepak Vijaykeerthy, Djallel Bouneffouf, Gregory
Bramble, Horst Samulowitz, Dakuo Wang, Andrew Conn, vÃ  Alexander Gray.
2020. Má»™t Framework Dá»±a trÃªn ADMM cho Cáº¥u hÃ¬nh Pipeline AutoML. In
Proceedings of the AAAI Conference on Artificial Intelligence , Vol. 34. 4892â€“4899.
https://doi.org/10.1609/aaai.v34i04.5926
[20] Radu Marinescu, Akihiro Kishimoto, Parikshit Ram, Ambrish Rawat, Martin
Wistuba, Paulito P. Palmes, vÃ  Adi Botea. 2021. TÃ¬m kiáº¿m Pipeline Há»c MÃ¡y Sá»­ dá»¥ng Ngá»¯ phÃ¡p KhÃ´ng cÃ³ Ngá»¯ cáº£nh. In Proceedings of the AAAI Conference
on Artificial Intelligence . 8902â€“8911. https://ojs.aaai.org/index.php/AAAI/article/
view/17077
[21] Jonas Mueller vÃ  Alex Smola. 2019. Nháº­n diá»‡n Biáº¿n tá»« Dá»¯ liá»‡u cá»§a chÃºng thÃ´ng qua Deep Embeddings cá»§a PhÃ¢n phá»‘i. International Conference on Data Mining
(ICDM) (2019), 1264â€“1269. https://doi.org/10.1109/ICDM.2019.00158
[22] Randal S. Olson, William La Cava, Patryk Orzechowski, Ryan J. Urbanowicz,
vÃ  Jason H. Moore. 2017. PMLB: má»™t bá»™ benchmark lá»›n cho Ä‘Ã¡nh giÃ¡ vÃ  so sÃ¡nh há»c mÃ¡y. BioData Mining 10, 1 (2017), 36. https://doi.org/10.
1186/s13040-017-0154-
[23] Bernhard Pfahringer, Hilan Bensusan, vÃ  Christophe Giraud-Carrier. 2000. Meta-
Learning báº±ng Landmarking CÃ¡c Thuáº­t toÃ¡n Há»c KhÃ¡c nhau. In Proceedings of the
International Conference on Machine Learning (ICML) . 743â€“750. https://dl.acm.
org/doi/10.5555/645529.658105
[24] Herilalaina Rakotoarison, Marc Schoenauer, vÃ  MichÃ¨le Sebag. 2019. Há»c MÃ¡y Tá»± Ä‘á»™ng vá»›i TÃ¬m kiáº¿m CÃ¢y Monte-Carlo. In Proceedings of
the International Joint Conference on Artificial Intelligence (IJCAI) . 3296â€“3303.
https://doi.org/10.24963/ijcai.2019/457
[25] Matthias Reif, Faisal Shafait, vÃ  Andreas Dengel. 2012. Meta-learning cho tá»‘i Æ°u hÃ³a tham sá»‘ tiáº¿n hÃ³a cá»§a bá»™ phÃ¢n loáº¡i. Machine Learning 87, 3 (2012),
357â€“380. https://doi.org/10.1007/s10994-012-5286-7
[26] Kevin Swersky, Jasper Snoek, vÃ  Ryan P. Adams. 2013. Tá»‘i Æ°u hÃ³a Bayesian Äa-TÃ¡c vá»¥. In Proceedings of the Interna-
tional Conference on Neural Information Processing Systems (NeurIPS) . 2004â€“2012.
https://dl.acm.org/doi/10.5555/2999792.2999836
[27] Chris Thornton, Frank Hutter, Holger H Hoos, vÃ  Kevin Leyton-Brown. 2013.
Auto-WEKA: Lá»±a chá»n káº¿t há»£p vÃ  tá»‘i Æ°u hÃ³a siÃªu tham sá»‘ cá»§a cÃ¡c thuáº­t toÃ¡n phÃ¢n loáº¡i. In Proceedings of the International Conference on Knowledge
Discovery and Data Mining (SIGKDD) . 847â€“855. https://doi.org/10.1145/2487575.
2487629
[28] Joaquin Vanschoren, Jan N. van Rijn, Bernd Bischl, vÃ  Luis Torgo. 2014. OpenML:
Khoa há»c Máº¡ng trong Há»c MÃ¡y. SIGKDD Explorations 15 (2014), 49â€“60.
https://doi.org/10.1145/2641190.2641198
[29] Ricardo Vilalta, Christophe Giraud-carrier, Pavel Brazdil, vÃ  Carlos Soares. 2004.
Sá»­ dá»¥ng Meta-Learning Ä‘á»ƒ Há»— trá»£ Khai thÃ¡c Dá»¯ liá»‡u. International Journal of Computer
Science & Applications 1 (2004). https://citeseerx.ist.psu.edu/viewdoc/download?
doi=10.1.1.105.1351&rep=rep1&type=pdf
[30] Chi Wang, Qingyun Wu, Markus Weimer, vÃ  Erkang Zhu. 2021. FLAML: Má»™t ThÆ° viá»‡n AutoML Nhanh vÃ  Nháº¹. In Proceedings of Machine Learning and
Systems (MLSys) , Vol. 3. 434â€“447. https://proceedings.mlsys.org/paper/2021/file/
92cc227532d17e56e07902b254dfad10-Paper.pdf
[31] Marcel Wever, Felix Mohr, vÃ  Eyke HÃ¼llermeier. 2018. ML-Plan cho Pipeline Há»c MÃ¡y Äá»™ dÃ i KhÃ´ng giá»›i háº¡n. In AutoML Workshop at the International
Conference on Machine Learning (ICML) . https://ris.uni-paderborn.de/download/
3852/3853/38.pdf
[32] Anatoly Yakovlev, Hesam Fathi Moghadam, Ali Moharrer, Jingxiao Cai, Nikan
Chavoshi, Venkatanathan Varadarajan, Sandeep R. Agrawal, Sam Idicula, Tomas
Karnagel, Sanjay Jinturkar, vÃ  Nipun Agarwal. 2020. Oracle AutoML: Má»™t Pipeline AutoML Nhanh vÃ  Dá»± Ä‘oÃ¡n Ä‘Æ°á»£c. Proceedings of the VLDB Endowment 13, 12 (2020),
3166â€“3180. https://doi.org/10.14778/3415478.3415542
[33] Chengrun Yang, Yuji Akimoto, Dae Won Kim, vÃ  Madeleine Udell. 2019. OBOE:
Lá»c Cá»™ng tÃ¡c cho Lá»±a chá»n MÃ´ hÃ¬nh AutoML. In Proceedings of the Interna-
tional Conference on Knowledge Discovery and Data Mining (SIGKDD) .
http://doi.org/10.1145/3292500.3330909
9

--- TRANG 10 ---
A THá»NG KÃŠ Cá»¦A Táº¤T Cáº¢ CÃC Táº¬P Dá»® LIá»†U
Báº£ng 6 vÃ  7 hiá»ƒn thá»‹ thá»‘ng kÃª cá»§a táº¥t cáº£ cÃ¡c táº­p dá»¯ liá»‡u benchmark bao gá»“m sá»‘ hÃ ng vÃ  cá»™t, sá»‘ Ä‘áº·c trÆ°ng sá»‘, phÃ¢n loáº¡i, vÃ  vÄƒn báº£n, sá»‘ lá»›p, kÃ­ch thÆ°á»›c, nguá»“n, vÃ  cÃ¡c bÃ i bÃ¡o Ä‘Ã£ Ä‘Ã¡nh giÃ¡ trÃªn nhá»¯ng táº­p dá»¯ liá»‡u nÃ y.

B ÄIá»‚M Sá» CHI TIáº¾T CHO Táº¤T Cáº¢ CÃC Há»† THá»NG
Báº£ng 8 vÃ  9 hiá»ƒn thá»‹ Ä‘iá»ƒm sá»‘ macro F1 vÃ  ğ‘…Â² chi tiáº¿t cho táº¥t cáº£ cÃ¡c há»‡ thá»‘ng trÃªn táº¥t cáº£ cÃ¡c táº­p dá»¯ liá»‡u benchmark.
10

--- TRANG 11 ---
Báº£ng 6: Thá»‘ng kÃª cá»§a 77 táº­p dá»¯ liá»‡u benchmark Ä‘Æ°á»£c sá»­ dá»¥ng trong FLAML vÃ  AL. Tá»« trÃ¡i sang pháº£i: tÃªn táº­p dá»¯ liá»‡u, sá»‘ hÃ ng, sá»‘ cá»™t, sá»‘ cá»™t sá»‘, sá»‘ cá»™t phÃ¢n loáº¡i, sá»‘ cá»™t vÄƒn báº£n, sá»‘ lá»›p (cho cÃ¡c táº­p dá»¯ liá»‡u phÃ¢n loáº¡i), kÃ­ch thÆ°á»›c tÃ­nh báº±ng MB, nguá»“n cá»§a táº­p dá»¯ liá»‡u, vÃ  cÃ¡c bÃ i bÃ¡o Ä‘Ã£ Ä‘Ã¡nh giÃ¡ trÃªn táº­p dá»¯ liá»‡u.

[Báº£ng chi tiáº¿t vá»›i 77 hÃ ng dá»¯ liá»‡u vá» cÃ¡c táº­p dá»¯ liá»‡u, bao gá»“m tÃªn, sá»‘ hÃ ng, cá»™t, loáº¡i Ä‘áº·c trÆ°ng, kÃ­ch thÆ°á»›c, nguá»“n vÃ  bÃ i bÃ¡o tham kháº£o]

--- TRANG 12 ---
Báº£ng 7: Thá»‘ng kÃª cá»§a 44 táº­p dá»¯ liá»‡u Ä‘Æ°á»£c sá»­ dá»¥ng bá»Ÿi VolcanoML. Tá»« trÃ¡i sang pháº£i: tÃªn táº­p dá»¯ liá»‡u, sá»‘ hÃ ng, sá»‘ cá»™t, sá»‘ cá»™t sá»‘, sá»‘ cá»™t phÃ¢n loáº¡i, sá»‘ cá»™t vÄƒn báº£n, sá»‘ lá»›p (cho cÃ¡c táº­p dá»¯ liá»‡u phÃ¢n loáº¡i), kÃ­ch thÆ°á»›c tÃ­nh báº±ng MB, nguá»“n cá»§a táº­p dá»¯ liá»‡u, vÃ  cÃ¡c bÃ i bÃ¡o Ä‘Ã£ Ä‘Ã¡nh giÃ¡ trÃªn táº­p dá»¯ liá»‡u.

[Báº£ng chi tiáº¿t vá»›i 44 hÃ ng dá»¯ liá»‡u vá» cÃ¡c táº­p dá»¯ liá»‡u VolcanoML]

--- TRANG 13 ---
Báº£ng 8: Äiá»ƒm sá»‘ Macro F1 vÃ  ğ‘…Â² cho táº¥t cáº£ cÃ¡c há»‡ thá»‘ng trÃªn táº¥t cáº£ 77 táº­p dá»¯ liá»‡u benchmark. Äiá»ƒm sá»‘ Ä‘Æ°á»£c bÃ¡o cÃ¡o lÃ  trung bÃ¬nh cá»§a 3 láº§n cháº¡y vá»›i ngÃ¢n sÃ¡ch thá»i gian 1 giá».

[Báº£ng chi tiáº¿t hiá»ƒn thá»‹ Ä‘iá»ƒm sá»‘ hiá»‡u suáº¥t cá»§a cÃ¡c há»‡ thá»‘ng khÃ¡c nhau trÃªn tá»«ng táº­p dá»¯ liá»‡u]

--- TRANG 14 ---
Báº£ng 9: Äiá»ƒm sá»‘ Macro F1 vÃ  ğ‘…Â² cho KGpip_FLAML vÃ  VolcanoML trÃªn 44 táº­p dá»¯ liá»‡u tá»« VolcanoML. Äiá»ƒm sá»‘ Ä‘Æ°á»£c bÃ¡o cÃ¡o lÃ  trung bÃ¬nh cá»§a 3 láº§n cháº¡y vá»›i ngÃ¢n sÃ¡ch thá»i gian 1 giá».

[Báº£ng so sÃ¡nh Ä‘iá»ƒm sá»‘ giá»¯a KGpip_FLAML vÃ  VolcanoML trÃªn 44 táº­p dá»¯ liá»‡u]

14
# 2303.07669.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/automl-nas/2303.07669.pdf
# Kích thước tệp: 1052276 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
Xuất bản như một bài báo hội nghị tại ICLR 2023
AUTOTRANSFER : AUTOML VỚI CHUYỂN GIAO KIẾN THỨC - ỨNG DỤNG CHO MẠNG NEURAL ĐỒ THỊ
Kaidi Cao Jiaxuan You Jiaju Liu Jure Leskovec
Khoa Khoa học Máy tính, Đại học Stanford
{kaidicao, jiaxuan, jiajuliu, jure}@cs.stanford.edu
TÓM TẮT
AutoML đã chứng minh được thành công đáng kể trong việc tìm ra kiến trúc mạng neural hiệu quả cho một nhiệm vụ học máy nhất định được định nghĩa bởi một tập dữ liệu cụ thể và một thước đo đánh giá. Tuy nhiên, hầu hết các kỹ thuật AutoML hiện tại xem xét mỗi nhiệm vụ một cách độc lập từ đầu, điều này đòi hỏi phải khám phá nhiều kiến trúc, dẫn đến chi phí tính toán cao. Ở đây chúng tôi đề xuất AUTOTRANSFER, một giải pháp AutoML cải thiện hiệu quả tìm kiếm bằng cách chuyển giao kiến thức thiết kế kiến trúc trước đó cho nhiệm vụ mới quan tâm. Đổi mới chính của chúng tôi bao gồm một ngân hàng nhiệm vụ-mô hình thu thập hiệu suất mô hình trên một tập hợp đa dạng các kiến trúc GNN và nhiệm vụ, và một nhúng nhiệm vụ hiệu quả tính toán có thể đo lường chính xác sự tương đồng giữa các nhiệm vụ khác nhau. Dựa trên ngân hàng nhiệm vụ-mô hình và các nhúng nhiệm vụ, chúng tôi ước tính các tiên nghiệm thiết kế của các mô hình mong muốn cho nhiệm vụ mới, bằng cách tổng hợp một tổng có trọng số tương đồng của các phân phối thiết kế top-K trên các nhiệm vụ tương tự với nhiệm vụ quan tâm. Các tiên nghiệm thiết kế được tính toán có thể được sử dụng với bất kỳ thuật toán tìm kiếm AutoML nào. Chúng tôi đánh giá AUTOTRANSFER trên sáu tập dữ liệu trong lĩnh vực học máy đồ thị. Các thí nghiệm chứng minh rằng (i) nhúng nhiệm vụ được đề xuất của chúng tôi có thể được tính toán hiệu quả, và các nhiệm vụ có nhúng tương tự có các kiến trúc hoạt động tốt nhất tương tự; (ii) AUTOTRANSFER cải thiện đáng kể hiệu quả tìm kiếm với các tiên nghiệm thiết kế được chuyển giao, giảm số lượng kiến trúc được khám phá đi một bậc độ lớn. Cuối cùng, chúng tôi phát hành GNN-BANK-101, một tập dữ liệu quy mô lớn với thông tin đào tạo GNN chi tiết của 120.000 kết hợp nhiệm vụ-mô hình để hỗ trợ và truyền cảm hứng cho nghiên cứu tương lai.

1 GIỚI THIỆU
Mạng neural sâu có tính module cao, đòi hỏi nhiều quyết định thiết kế phải được đưa ra liên quan đến kiến trúc mạng và siêu tham số. Những quyết định thiết kế này tạo thành một không gian tìm kiếm không lồi và tốn kém ngay cả đối với các chuyên gia để tối ưu hóa, đặc biệt khi việc tối ưu hóa phải được lặp lại từ đầu cho mỗi trường hợp sử dụng mới. Học máy tự động (AutoML) là một lĩnh vực nghiên cứu tích cực nhằm giảm nỗ lực con người cần thiết cho thiết kế kiến trúc thường bao gồm tối ưu hóa siêu tham số và tìm kiếm kiến trúc mạng neural. AutoML đã chứng minh thành công (Zoph and Le, 2016; Pham et al., 2018; Zoph et al., 2018; Cai et al., 2018; He et al., 2018; Guo et al., 2020; Erickson et al., 2020; LeDell and Poirier, 2020) trong nhiều lĩnh vực ứng dụng.

Tìm ra một mô hình tốt hợp lý cho một nhiệm vụ học tập mới¹ một cách hiệu quả tính toán là rất quan trọng để làm cho học sâu có thể tiếp cận được với các chuyên gia lĩnh vực có nền tảng đa dạng. AutoML hiệu quả đặc biệt quan trọng trong các lĩnh vực mà các kiến trúc/siêu tham số tốt nhất rất nhạy cảm với nhiệm vụ. Một ví dụ đáng chú ý là lĩnh vực học đồ thị². Thứ nhất, các phương pháp học đồ thị nhận dữ liệu đầu vào bao gồm nhiều loại dữ liệu và tối ưu hóa trên các nhiệm vụ trải rộng trên một tập hợp lĩnh vực và phương thức đa dạng như đề xuất (Ying et al., 2018; He et al., 2020), mô phỏng vật lý (Sanchez-Gonzalez et al., 2020; Pfaff et al., 2020), và tin sinh học (Zitnik et al., 2018). Điều này khác với thị giác máy tính và xử lý ngôn ngữ tự nhiên nơi dữ liệu đầu vào có cấu trúc được định nghĩa trước, cố định có thể được chia sẻ giữa các kiến trúc mạng neural khác nhau.

¹Trong bài báo này, chúng tôi gọi một nhiệm vụ là một tập dữ liệu nhất định với một thước đo đánh giá/hàm mất mát, ví dụ: hàm mất mát entropy chéo trên phân loại nút trên tập dữ liệu Cora.
²Chúng tôi tập trung vào lĩnh vực học đồ thị trong bài báo này. AUTOTRANSFER có thể được tổng quát hóa cho các lĩnh vực khác.

1arXiv:2303.07669v1  [cs.LG]  14 Mar 2023

--- TRANG 2 ---
Xuất bản như một bài báo hội nghị tại ICLR 2023

Thứ hai, mạng neural hoạt động trên đồ thị đi kèm với một tập hợp phong phú các lựa chọn thiết kế và một tập hợp lớn các tham số để khám phá. Tuy nhiên, không giống như các lĩnh vực khác nơi một vài kiến trúc được đào tạo trước như ResNet (He et al., 2016) và GPT-3 (Brown et al., 2020) thống trị các benchmark, đã được chỉ ra rằng thiết kế mạng neural đồ thị (GNN) tốt nhất phụ thuộc rất nhiều vào nhiệm vụ (You et al., 2020).

Mặc dù AutoML như một lĩnh vực nghiên cứu đang phát triển nhanh chóng, các giải pháp AutoML hiện tại có chi phí tính toán khổng lồ khi mục tiêu là tìm ra một mô hình tốt cho một nhiệm vụ học tập mới. Hầu hết các kỹ thuật AutoML hiện tại xem xét mỗi nhiệm vụ một cách độc lập và riêng biệt, do đó chúng đòi hỏi phải làm lại việc tìm kiếm từ đầu cho mỗi nhiệm vụ mới. Cách tiếp cận này bỏ qua kiến thức thiết kế kiến trúc có giá trị tiềm năng thu được từ các nhiệm vụ trước đó, và chắc chắn dẫn đến chi phí tính toán cao. Vấn đề này đặc biệt quan trọng trong lĩnh vực học đồ thị Gao et al. (2019); Zhou et al. (2019), do những thách thức của các loại nhiệm vụ đa dạng và không gian thiết kế khổng lồ được thảo luận ở trên.

Ở đây chúng tôi đề xuất AUTOTRANSFER³, một giải pháp AutoML cải thiện đáng kể việc tìm kiếm kiến trúc AutoML bằng cách chuyển giao kiến thức thiết kế kiến trúc trước đó cho nhiệm vụ quan tâm. Đổi mới chính của chúng tôi là giới thiệu một ngân hàng nhiệm vụ-mô hình lưu trữ hiệu suất của một tập hợp đa dạng các kiến trúc GNN và nhiệm vụ để hướng dẫn thuật toán tìm kiếm. Để cho phép chuyển giao kiến thức, chúng tôi định nghĩa một không gian nhúng nhiệm vụ sao cho các nhiệm vụ gần trong không gian nhúng có các kiến trúc hoạt động tốt nhất tương ứng tương tự. Thách thức ở đây là nhúng nhiệm vụ cần thu thập các xếp hạng hiệu suất của các kiến trúc khác nhau trên các tập dữ liệu khác nhau, trong khi hiệu quả để tính toán.

Đổi mới của chúng tôi ở đây là nhúng một nhiệm vụ bằng cách sử dụng số điều kiện của Ma trận Thông tin Fisher của các mô hình được khởi tạo ngẫu nhiên khác nhau và cũng một sơ đồ học tập với đảm bảo tổng quát hóa thực nghiệm. Bằng cách này, chúng tôi ngầm thu thập các thuộc tính của nhiệm vụ học tập, trong khi nhanh hơn nhiều bậc độ lớn (trong vài giây). Sau đó chúng tôi ước tính tiên nghiệm thiết kế của các mô hình mong muốn cho nhiệm vụ mới, bằng cách tổng hợp các phân phối thiết kế trên các nhiệm vụ gần với nhiệm vụ quan tâm. Cuối cùng, chúng tôi khởi tạo một thuật toán tìm kiếm siêu tham số với tiên nghiệm thiết kế được thông báo nhiệm vụ được tính toán.

Chúng tôi đánh giá AUTOTRANSFER trên sáu tập dữ liệu, bao gồm cả các nhiệm vụ phân loại nút và phân loại đồ thị. Chúng tôi chỉ ra rằng các nhúng nhiệm vụ được đề xuất của chúng tôi có thể được tính toán hiệu quả và khoảng cách được đo giữa các nhiệm vụ tương quan cao (tương quan Kendall 0.43) với các xếp hạng hiệu suất mô hình. Hơn nữa, chúng tôi trình bày AUTOTRANSFER cải thiện đáng kể hiệu quả tìm kiếm khi sử dụng tiên nghiệm thiết kế được chuyển giao. AUTOTRANSFER giảm số lượng kiến trúc được khám phá cần thiết để đạt độ chính xác mục tiêu đi một bậc độ lớn so với SOTA. Cuối cùng, chúng tôi phát hành GNN-BANK-101—cơ sở dữ liệu quy mô lớn đầu tiên chứa các bản ghi hiệu suất chi tiết cho 120.000 kết hợp nhiệm vụ-mô hình được đào tạo với 16.128 giờ GPU—để hỗ trợ nghiên cứu tương lai.

2 CÔNG TRÌNH LIÊN QUAN

Trong phần này, chúng tôi tóm tắt công trình liên quan về AutoML liên quan đến các ứng dụng của nó trên GNN, các thuật toán tìm kiếm phổ biến, và công trình tiên phong liên quan đến học chuyển giao và nhúng nhiệm vụ.

AutoML cho GNN. Tìm kiếm kiến trúc mạng neural (NAS), một hình thức AutoML độc đáo và phổ biến cho học sâu, có thể được chia thành hai loại: NAS đa thử nghiệm và NAS một lần. Trong NAS đa thử nghiệm, mỗi kiến trúc được lấy mẫu được đào tạo riêng biệt. GraphNAS (Gao et al., 2020) và Auto-GNN (Zhou et al., 2019) là các thuật toán NAS đa thử nghiệm điển hình trên GNN áp dụng một bộ điều khiển RNN học đề xuất các tập hợp cấu hình tốt hơn thông qua học tăng cường.

NAS một lần (ví dụ: (Liu et al., 2018; Qin et al., 2021; Li et al., 2021)) bao gồm việc đóng gói toàn bộ không gian mô hình trong một siêu mô hình, đào tạo siêu mô hình một lần, và sau đó lặp đi lặp lại lấy mẫu các mô hình con từ siêu mô hình để tìm ra mô hình tốt nhất. Ngoài ra, có công trình nghiên cứu cụ thể các lựa chọn thiết kế chi tiết như tăng cường dữ liệu (You et al., 2021), loại lớp truyền tin (Cai et al., 2021; Ding et al., 2021; Zhao et al., 2021), và gộp đồ thị (Wei et al., 2021).

Đáng chú ý, AUTOTRANSFER là giải pháp AutoML đầu tiên cho GNN chuyển giao hiệu quả kiến thức thiết kế giữa các nhiệm vụ.

Thuật toán HPO. Các thuật toán Tối ưu hóa Siêu tham số (HPO) tìm kiếm các siêu tham số mô hình tối ưu bằng cách lặp đi lặp lại đề xuất một tập hợp siêu tham số và đánh giá hiệu suất của chúng. Tìm kiếm ngẫu nhiên lấy mẫu siêu tham số từ không gian tìm kiếm với xác suất bằng nhau. Mặc dù không

³Mã nguồn có sẵn tại https://github.com/snap-stanford/AutoTransfer.

2

--- TRANG 3 ---
Xuất bản như một bài báo hội nghị tại ICLR 2023

Ngân hàng Nhiệm vụ-Mô hình(các bản ghi hiệu suất lịch sử)Không gian Nhúng Nhiệm vụPhân phối ThiếtkếNhiệm vụAggDimEpoch...Val_lossCorasum6480...0.22Coramean128200...0.26TU-DDsum64200...0.46TU-DDmean128200...0.86TU-DDmax256800...0.52Arxivmean128200...0.68………………

AggDimEpoch
Agg
Nhiệm vụ mới quan tâmDim​Epoch...​...​

Hình 1: Tổng quan về AUTOTRANSFER. Trái: Chúng tôi giới thiệu GNN-BANK-101, một cơ sở dữ liệu lớn chứa một tập hợp đa dạng các kiến trúc GNN và siêu tham số được áp dụng cho các nhiệm vụ khác nhau, cùng với các thống kê đào tạo/đánh giá của chúng. Giữa: Chúng tôi giới thiệu một không gian nhúng nhiệm vụ, nơi mỗi điểm tương ứng với một nhiệm vụ khác nhau. Các nhiệm vụ gần trong không gian nhúng có các mô hình hoạt động tốt nhất tương ứng tương tự. Phải: Cho một nhiệm vụ mới quan tâm, chúng tôi hướng dẫn tìm kiếm AutoML bằng cách tham khảo các phân phối thiết kế của các nhiệm vụ tương tự nhất trong không gian nhúng nhiệm vụ.

học hỏi từ các thử nghiệm trước đó, tìm kiếm ngẫu nhiên thường được sử dụng vì tính đơn giản và hiệu quả hơn nhiều so với tìm kiếm lưới (Bergstra and Bengio, 2012). Thuật toán TPE (Bergstra et al., 2011) xây dựng một mô hình xác suất của hiệu suất nhiệm vụ trên không gian siêu tham số và sử dụng kết quả của các thử nghiệm trong quá khứ để chọn cấu hình tiếp theo hứa hẹn nhất để đào tạo, mà thuật toán TPE định nghĩa là tối đa hóa giá trị Cải thiện Kỳ vọng (Jones, 2001). Các thuật toán tiến hóa (Real et al., 2017; Jaderberg et al., 2017) đào tạo nhiều mô hình song song và thay thế các mô hình hoạt động kém bằng các bản sao "đột biến" của các mô hình tốt nhất hiện tại. AUTOTRANSFER là một giải pháp AutoML tổng quát và có thể được áp dụng kết hợp với bất kỳ thuật toán HPO nào trong số này.

Học Chuyển giao trong AutoML. Wong et al. (2018) đề xuất chuyển giao kiến thức giữa các nhiệm vụ bằng cách tải lại bộ điều khiển của các thuật toán tìm kiếm học tăng cường. Tuy nhiên, phương pháp này giả định rằng không gian tìm kiếm trên các nhiệm vụ khác nhau bắt đầu với cùng một tiên nghiệm đã học. Không giống như AUTOTRANSFER, nó không thể giải quyết thách thức cốt lõi trong AutoML GNN: thiết kế GNN tốt nhất phụ thuộc rất nhiều vào nhiệm vụ cụ thể.

GraphGym (You et al., 2020) cố gắng chuyển giao thiết kế kiến trúc tốt nhất trực tiếp với một không gian metric đo lường sự tương đồng nhiệm vụ. GraphGym (You et al., 2020) tính toán sự tương đồng nhiệm vụ bằng cách đào tạo một tập hợp 12 "mô hình neo" đến hội tụ, điều này tốn kém về mặt tính toán. Ngược lại, AUTOTRANSFER thiết kế các nhúng nhiệm vụ nhẹ đòi hỏi chi phí tính toán tối thiểu.

Ngoài ra, Zhao and Bilen (2021); Li et al. (2021) đề xuất tiến hành tìm kiếm kiến trúc trên một tập con proxy của toàn bộ tập dữ liệu và sau đó chuyển giao kiến trúc tìm kiếm tốt nhất trên tập dữ liệu đầy đủ. Jeong et al. (2021) nghiên cứu một thiết lập tương tự trong lĩnh vực thị giác.

Nhúng Nhiệm vụ. Có nghiên cứu trước đó cố gắng định lượng nhúng nhiệm vụ và sự tương đồng. Tương tự như GraphGym, Taskonomy (Zamir et al., 2018) ước tính ma trận ái lực nhiệm vụ bằng cách tóm tắt các mất mát cuối cùng/thước đo đánh giá sử dụng một Quy trình Thứ bậc Phân tích (Saaty, 1987). Từ một góc độ khác, Task2Vec (Achille et al., 2019) tạo ra nhúng nhiệm vụ cho một nhiệm vụ nhất định sử dụng Ma trận Thông tin Fisher liên quan đến một mạng thăm dò được đào tạo trước. Mạng thăm dó này được chia sẻ giữa các nhiệm vụ và cho phép Task2Vec ước tính Ma trận Thông tin Fisher của các tập dữ liệu hình ảnh khác nhau. Le et al. (2022) mở rộng một ý tưởng tương tự cho tìm kiếm kiến trúc mạng neural. Các nhúng nhiệm vụ được đề cập ở trên không thể được áp dụng trực tiếp cho GNN vì các đầu vào không căn chỉnh giữa các tập dữ liệu.

AUTOTRANSFER tránh được nút thắt cổ chai bằng cách sử dụng thống kê tiệm cận của Ma trận Thông tin Fisher với trọng số được khởi tạo ngẫu nhiên.

3 CÔNG THỨC HÓA VẤN ĐỀ VÀ KIẾN THỨC CƠ BẢN

Chúng tôi trước tiên giới thiệu các định nghĩa chính thức của các cấu trúc dữ liệu liên quan đến AUTOTRANSFER.

3

--- TRANG 4 ---
Xuất bản như một bài báo hội nghị tại ICLR 2023

…𝑎"!Mô hình 𝑀1Mô hình 𝑀2Mô hình 𝑀𝑈𝑅 Khởi tạo NgẫuFIMĐo lường Bất biến TỷlệĐặc trưng Nhiệm vụNhúng Nhiệm vụ𝑔𝑓𝑓𝑓Nhiệm vụ iMục tiêu ĐàotạoNhiệm vụ jxNhiệm vụ iNhiệm vụ kxHàm mất mát Xếp hạng Biên𝑎""𝑎"#𝑧$𝑧%𝑧%(')𝑧%())𝑧%(')𝑧%(*)

Hình 2: Quy trình trích xuất nhúng nhiệm vụ. Trái: Để nhúng một nhiệm vụ một cách hiệu quả, trước tiên chúng tôi trích xuất các đặc trưng nhiệm vụ bằng cách nối các đặc trưng được đo từ R mô hình neo được khởi tạo ngẫu nhiên. Sau đó, chúng tôi giới thiệu một hàm chiếu g() với các trọng số đã học để biến đổi các đặc trưng nhiệm vụ thành nhúng nhiệm vụ. Phải: Mục tiêu đào tạo để tối ưu hóa g() với giám sát tam phân.

Định nghĩa 1 (Nhiệm vụ) Chúng tôi ký hiệu một nhiệm vụ là T = (D; L()), bao gồm một tập dữ liệu D và một hàm mất mát L() liên quan đến thước đo đánh giá.

Đối với mỗi lần thử đào tạo trên một nhiệm vụ T(i), chúng ta có thể ghi lại kiến trúc mô hình Mj, siêu tham số Hj, và giá trị mất mát tương ứng lj, tức là, (Mj; Hj; lj). Chúng tôi đề xuất duy trì một ngân hàng nhiệm vụ-mô hình để hỗ trợ chuyển giao kiến thức cho các nhiệm vụ mới trong tương lai.

Định nghĩa 2 (Ngân hàng Nhiệm vụ-Mô hình) Một ngân hàng nhiệm vụ-mô hình B được định nghĩa là một tập hợp các nhiệm vụ, mỗi nhiệm vụ với nhiều lần thử đào tạo, dưới dạng B = {(T(i); {(M(i)j; H(i)j; l(i)j)})}.

AutoML với Chuyển giao Kiến thức. Giả sử chúng ta có một ngân hàng nhiệm vụ-mô hình B. Cho một nhiệm vụ mới T(n) chưa được thấy trước đó, mục tiêu của chúng ta là nhanh chóng tìm ra một mô hình hoạt động tốt hợp lý trên nhiệm vụ mới bằng cách sử dụng kiến thức từ ngân hàng nhiệm vụ-mô hình.

Trong bài báo này, chúng tôi tập trung vào AutoML cho các nhiệm vụ học đồ thị, mặc dù kỹ thuật phát triển của chúng tôi là tổng quát và có thể được áp dụng cho các lĩnh vực khác. Chúng tôi định nghĩa đồ thị đầu vào là G = {V; E}, trong đó V là tập hợp nút và E ⊆ V × V là tập hợp cạnh. Hơn nữa, gọi y là nhãn đầu ra của nó, có thể là cấp nút, cấp cạnh hoặc cấp đồ thị. Một GNN được tham số hóa bởi trọng số θ xuất ra một phân phối hậu nghiệm P(G; y; θ) cho dự đoán nhãn.

4 GIẢI PHÁP ĐỀ XUẤT: AUTOTRANSFER

Trong phần này, chúng tôi giới thiệu giải pháp AUTOTRANSFER được đề xuất. AUTOTRANSFER sử dụng không gian nhúng nhiệm vụ như một công cụ để hiểu sự liên quan của các thiết kế kiến trúc trước đó đối với nhiệm vụ mục tiêu. Nhúng nhiệm vụ được thiết kế thu thập các xếp hạng hiệu suất của các kiến trúc khác nhau trên các nhiệm vụ khác nhau trong khi cũng hiệu quả để tính toán. Chúng tôi trước tiên giới thiệu một giải pháp có động lực lý thuyết để trích xuất một biểu diễn hiệu suất bất biến tỷ lệ của mỗi cặp nhiệm vụ-mô hình. Chúng tôi sử dụng những biểu diễn này để xây dựng các đặc trưng nhiệm vụ và tiếp tục học nhúng nhiệm vụ. Những nhúng này tạo thành không gian nhúng nhiệm vụ mà cuối cùng chúng tôi sử dụng trong quá trình tìm kiếm AutoML.

4.1 CƠ BẢN VỀ MA TRẬN THÔNG TIN FISHER (FIM)

Cho một GNN được định nghĩa ở trên, Ma trận Thông tin Fisher (FIM) F của nó được định nghĩa là

F = E[G;y][∇θ log P(G; y; θ)∇θ log P(G; y; θ)>]:

về mặt hình thức là hiệp phương sai kỳ vọng của các điểm số đối với các tham số mô hình. Có hai quan điểm hình học phổ biến cho FIM. Thứ nhất, FIM là một cận trên của Hessian và trùng với Hessian nếu gradient bằng 0. Do đó, FIM đặc trưng cho cảnh quan địa phương của hàm mất mát gần minimum toàn cục. Thứ hai, tương tự như Hessian, FIM mô hình cảnh quan mất mát không phải đối với không gian đầu vào, mà đối với không gian tham số. Trong quan điểm hình học thông tin, nếu chúng ta thêm một nhiễu nhỏ vào không gian tham số, chúng ta có

KL(P(G; y; θ)||P(G; y; θ + dθ)) = dθ>Fdθ:

trong đó KL(·; ·) là phân kỳ Kullback–Leibler. Điều này có nghĩa là không gian tham số của một mô hình tạo thành một đa tạp Riemannian và FIM hoạt động như metric Riemannian của nó. Do đó FIM cho phép chúng ta định lượng tầm quan trọng của trọng số mô hình theo cách có thể áp dụng cho các kiến trúc khác nhau.

4.2 CÁC ĐẶC TRƯNG NHIỆM VỤ DỰA TRÊN FIM

Biểu diễn Bất biến Tỷ lệ của Cặp Nhiệm vụ-Mô hình. Chúng tôi nhằm tìm ra một biểu diễn bất biến tỷ lệ cho mỗi cặp nhiệm vụ-mô hình sẽ tạo thành cơ sở để xây dựng các đặc trưng nhiệm vụ. Thách thức chính trong việc sử dụng FIM để biểu diễn hiệu suất GNN là các tập dữ liệu đồ thị không có cấu trúc đầu vào phổ quát, cố định, vì vậy không khả thi để tìm một mô hình được đào tạo trước duy nhất và trích xuất FIM của nó. Tuy nhiên, việc đào tạo nhiều mạng gây ra vấn đề vì các FIM được tính toán cho các mạng khác nhau không thể so sánh trực tiếp. Chúng tôi chọn sử dụng nhiều mạng nhưng bổ sung đề xuất sử dụng thống kê tiệm cận của FIM liên quan đến trọng số được khởi tạo ngẫu nhiên. Lý do lý thuyết cho mối quan hệ giữa thống kê tiệm cận của FIM và khả năng đào tạo của mạng neural đã được nghiên cứu trong (Karakida et al., 2019; Pennington and Worah, 2018) mà chúng tôi giới thiệu đến độc giả. Chúng tôi giả định rằng thước đo khả năng đào tạo như vậy mã hóa cảnh quan mất mát và khả năng tổng quát hóa và do đó tương quan với hiệu suất mô hình cuối cùng trên nhiệm vụ.

Một vấn đề khác liên quan đến cấu trúc đầu vào của các tập dữ liệu đồ thị là các mô hình khác nhau có số lượng tham số khác nhau. Mặc dù có một số kiến trúc được thiết kế đặc biệt, ví dụ: (Lee et al., 2019; Ma et al., 2019), hầu hết thiết kế kiến trúc GNN có thể được biểu diễn như một chuỗi các lớp tiền xử lý, lớp truyền tin và lớp hậu xử lý. Các lớp tiền xử lý và hậu xử lý là các lớp Perceptron Đa lớp (MLP), có kích thước thay đổi giữa các nhiệm vụ khác nhau do cấu trúc đầu vào/đầu ra khác nhau. Các lớp truyền tin thường được coi là thiết kế chính cho GNN và số lượng tham số trọng số có thể giữ nguyên giữa các nhiệm vụ. Theo quan điểm này, chúng tôi chỉ xem xét FIM đối với các tham số trong các lớp truyền tin để số lượng tham số được xem xét giữ nguyên cho tất cả các tập dữ liệu. Chúng tôi lưu ý rằng công thức hóa như vậy có các hạn chế, theo nghĩa là nó không thể bao gồm tất cả các thiết kế GNN trong tài liệu. Chúng tôi để lại các mở rộng tiềm năng với phạm vi bao phủ tốt hơn cho công việc tương lai.

Chúng tôi tiếp tục xấp xỉ FIM bằng cách chỉ xem xét các mục đường chéo, điều này ngầm bỏ qua các tương quan giữa các tham số. Chúng tôi lưu ý rằng đây là thực hành phổ biến khi phân tích FIM của mạng neural sâu, vì FIM đầy đủ là khổng lồ (bậc hai theo số lượng tham số) và không khả thi để tính toán ngay cả trên phần cứng hiện đại. Tương tự như Pennington and Worah (2018), chúng tôi xem xét hai moment đầu tiên của FIM

m1 = (1/n)tr[F] và m2 = (1/n)tr[F²] (1)

và sử dụng κ = m2/m1² làm biểu diễn bất biến tỷ lệ. κ được tính toán được giới hạn dưới bởi 1 và thu thập mức độ tập trung của phổ. Một κ nhỏ chỉ ra cảnh quan mất mát phẳng, và thiết kế mô hình tương ứng của nó tận hưởng tối ưu hóa bậc nhất nhanh và khả năng tổng quát hóa tốt hơn tiềm năng.

Để mã hóa thông tin không gian nhãn vào mỗi nhiệm vụ, chúng tôi đề xuất chỉ đào tạo lớp tuyến tính cuối cùng của mỗi mô hình trên một nhiệm vụ nhất định, điều này có thể được thực hiện hiệu quả. Các tham số trong các lớp khác được đóng băng sau khi được khởi tạo ngẫu nhiên. Chúng tôi lấy trung bình trên R lần khởi tạo để ước tính κ trung bình.

Xây dựng Đặc trưng Nhiệm vụ. Chúng tôi ký hiệu các đặc trưng nhiệm vụ là các thước đo được trích xuất từ mỗi nhiệm vụ đặc trưng cho các đặc điểm quan trọng của nó. Thiết kế của các đặc trưng nhiệm vụ nên phản ánh mục tiêu cuối cùng của chúng ta: sử dụng những đặc trưng này để xác định các nhiệm vụ tương tự và chuyển giao các phân phối thiết kế tốt nhất. Do đó, chúng tôi chọn U thiết kế mô hình làm mô hình neo và nối các biểu diễn bất biến tỷ lệ au của mỗi thiết kế làm đặc trưng nhiệm vụ. Để chỉ giữ lại xếp hạng tương đối giữa các thiết kế mô hình neo, chúng tôi chuẩn hóa vector đặc trưng được nối thành tỷ lệ 1. Chúng tôi gọi zf là đặc trưng nhiệm vụ được chuẩn hóa.

4.3 TỪ ĐẶC TRƯNG NHIỆM VỤ ĐẾN NHÚNG NHIỆM VỤ

Đặc trưng nhiệm vụ zf được giới thiệu ở trên có thể được coi là một phương tiện kỹ thuật đặc trưng. Chúng tôi xây dựng vector đặc trưng với kiến thức lĩnh vực, nhưng không có đảm bảo nào rằng nó hoạt động như dự kiến. Do đó chúng tôi đề xuất học một hàm chiếu g() : RU → RD ánh xạ đặc trưng nhiệm vụ zf đến nhúng nhiệm vụ cuối cùng ze = g(zf). Chúng tôi không có bất kỳ giám sát theo điểm nào có thể được sử dụng làm mục tiêu đào tạo. Thay vào đó, chúng tôi xem xét không gian metric được định nghĩa bởi GraphGym. Hàm khoảng cách trong GraphGym - được tính toán bằng tương quan thứ hạng Kendall giữa các xếp hạng hiệu suất của các mô hình neo được đào tạo trên hai nhiệm vụ được so sánh - tương quan tốt với mục tiêu chuyển giao kiến thức mong muốn của chúng tôi.

5

--- TRANG 6 ---
Xuất bản như một bài báo hội nghị tại ICLR 2023

Không có ý nghĩa gì khi ép buộc rằng nhúng nhiệm vụ bắt chước không gian metric chính xác của GraphGym, vì không gian metric của GraphGym vẫn có thể chứa nhiễu, hoặc không hoàn toàn phù hợp với mục tiêu chuyển giao. Chúng tôi xem xét một hàm mất mát thay thế chỉ thực thi thứ tự xếp hạng giữa các nhiệm vụ. Để minh họa, hãy xem xét các nhiệm vụ T(i), T(j), T(k) và các nhúng nhiệm vụ tương ứng của chúng, z(i)e, z(j)e, z(k)e. Lưu ý rằng ze được chuẩn hóa thành 1 nên z(i)e>z(j)e đo lường độ tương tự cosine giữa các nhiệm vụ T(i) và T(j).

Gọi dg(·; ·) là khoảng cách được ước tính bởi GraphGym. Chúng tôi muốn thực thi

z(i)e>z(j)e > z(i)e>z(k)e nếu dg(T(i); T(j)) < dg(T(i); T(k)):

Để đạt được điều này, chúng tôi sử dụng hàm mất mát xếp hạng biên làm hàm mục tiêu giám sát thay thế của chúng tôi:

Lr(z(i)e; z(j)e; z(k)e; y) = max(0; y(z(i)e>z(j)e − z(i)e>z(k)e) + margin): (2)

Ở đây nếu dg(T(i); T(j)) < dg(T(i); T(k)), thì chúng ta có nhãn tương ứng y = 1, và y = −1 ngược lại. Không gian nhúng nhiệm vụ cuối cùng của chúng tôi sau đó là một không gian metric dựa trên FIM với hàm khoảng cách cosine, trong đó khoảng cách được định nghĩa là de(T(i); T(j)) = 1 − z(i)e>z(j)e. Vui lòng tham khảo quy trình đào tạo chi tiết tại Thuật toán 2 trong Phụ lục.

4.4 THUẬT TOÁN TÌM KIẾM AUTOML VỚI NHÚNG NHIỆM VỤ

Để chuyển giao kiến thức cho một nhiệm vụ mới, một ý tưởng ngây thơ sẽ là trực tiếp mang theo cấu hình mô hình tốt nhất từ nhiệm vụ gần nhất trong ngân hàng. Tuy nhiên, ngay cả tương quan thứ hạng Kendall cao giữa các xếp hạng hiệu suất mô hình của hai nhiệm vụ T(i), T(j) không đảm bảo cấu hình mô hình tốt nhất trong nhiệm vụ T(i) cũng sẽ đạt hiệu suất tốt nhất trên nhiệm vụ T(j). Ngoài ra, vì sự tương đồng nhiệm vụ có thể có nhiễu, giải pháp ngây thơ này có thể gặp khó khăn khi tồn tại nhiều nhiệm vụ tham chiếu đều có độ tương đồng cao.

Để làm cho việc chuyển giao kiến thức mạnh mẽ hơn đối với các trường hợp thất bại như vậy, chúng tôi giới thiệu khái niệm phân phối thiết kế phụ thuộc vào các thiết kế mô hình hoạt động tốt nhất và đề xuất chuyển giao phân phối thiết kế thay vì cấu hình thiết kế tốt nhất. Chính thức, xem xét một nhiệm vụ T(i) trong ngân hàng nhiệm vụ-mô hình B, liên quan đến các thử nghiệm của nó {(M(i)j; H(i)j; l(i)j)}. Chúng ta có thể tóm tắt các thiết kế của nó dưới dạng danh sách các cấu hình C = {c1; :::; cW}, sao cho tất cả các kết hợp tiềm năng của kiến trúc mô hình M và siêu tham số H nằm dưới tích Cartesian của các cấu hình. Ví dụ, c1 có thể là việc khởi tạo các lớp tổng hợp, và c2 có thể là tốc độ học ban đầu. Sau đó chúng tôi định nghĩa phân phối thiết kế là các biến ngẫu nhiên c1; c2; :::; cW, mỗi biến tương ứng với một siêu tham số. Mỗi biến ngẫu nhiên c được định nghĩa là phân phối tần số của các lựa chọn thiết kế được sử dụng trong K thử nghiệm hàng đầu. Chúng tôi nhân tất cả các phân phối cho các cấu hình cá nhân {c1; :::; cW} để xấp xỉ phân phối thiết kế tổng thể của nhiệm vụ P(C|T(i)) = ∏w P(cw|T(i)):

Trong quá trình suy luận, cho một nhiệm vụ mới T(n), chúng tôi chọn một tập con nhiệm vụ gần S bằng cách đặt ngưỡng khoảng cách nhúng nhiệm vụ, tức là, S = {T(i)|de(T(n); T(i)) ≤ dthres}. Sau đó chúng tôi suy ra tiên nghiệm thiết kế được chuyển giao Pt(C|T(n)) của nhiệm vụ mới bằng cách cân nhắc các phân phối thiết kế từ tập con nhiệm vụ gần S.

Pt(C|T(n)) = (∑T(i)∈S (1/de(T(n); T(i)))P(C|T(i)))/(∑T(i)∈S (1/de(T(n); T(i)))): (3)

Tiên nghiệm thiết kế được suy luận cho nhiệm vụ mới sau đó có thể được sử dụng để hướng dẫn các thuật toán tìm kiếm khác nhau. Lựa chọn tự nhiên nhất cho chế độ vài thử nghiệm là tìm kiếm ngẫu nhiên. Thay vì lấy mẫu mỗi cấu hình thiết kế theo phân phối đồng nhất, chúng tôi đề xuất lấy mẫu từ tiên nghiệm thiết kế được thông báo nhiệm vụ Pt(C|T(n)). Vui lòng tham khảo Phụ lục A để kiểm tra cách chúng tôi tăng cường các thuật toán tìm kiếm khác.

Đối với AUTOTRANSFER, chúng ta có thể tiền xử lý ngân hàng nhiệm vụ-mô hình B thành Bp = {(D(i); L(i)()); z(i)e; P(C|T(i))} vì quy trình của chúng ta chỉ đòi hỏi sử dụng nhúng nhiệm vụ z(i)e và phân phối thiết kế P(C|T(i)) thay vì các thử nghiệm đào tạo chi tiết. Quy trình tìm kiếm chi tiết được tóm tắt trong Thuật toán 1.

6

--- TRANG 7 ---
Xuất bản như một bài báo hội nghị tại ICLR 2023

Thuật toán 1 Tóm tắt quy trình tìm kiếm AUTOTRANSFER
Yêu cầu: Một ngân hàng nhiệm vụ-mô hình đã xử lý Bp = {(D(i); L(i)()); z(i)e; P(C|T(i)))}, một nhiệm vụ mới T(n) = (D(n); L(n)()), U mô hình neo M1; :::; MU, R chỉ định số lần lặp lại.
1: for u = 1 to U do
2:   for r = 1 to R do
3:     Khởi tạo trọng số cho mô hình neo Mu ngẫu nhiên
4:     Ước tính FIM F ≈ ED[∇θ log P(Mu; y; θ)∇θ log P(Mu; y; θ)>]
5:     Trích xuất biểu diễn bất biến tỷ lệ a(v)u ← m2/m21 theo Phương trình 1
6:   end for
7:   au ← mean (a(1)u; a(2)u; :::; a(V)u)
8: end for
9: z(n)f ← concat (a1; a2; :::; aU)
10: z(n)e ← g(z(n)f)
11: Chọn tập con nhiệm vụ gần S ← {T(i)|1 − z(n)e>z(i)e ≤ dthres}
12: Nhận tiên nghiệm thiết kế Pt(C|T(n)) bằng cách tổng hợp tập con S theo Phương trình 3
13: Bắt đầu thuật toán tìm kiếm HPO với tiên nghiệm thiết kế được thông báo nhiệm vụ Pt(C|T(n))

5 CÁC THÍ NGHIỆM

5.1 THIẾT LẬP THÍ NGHIỆM

Ngân hàng Nhiệm vụ-Mô hình: GNN-BANK-101.
Để hỗ trợ nghiên cứu AutoML với chuyển giao kiến thức, chúng tôi đã thu thập GNN-BANK-101 làm cơ sở dữ liệu đồ thị quy mô lớn đầu tiên ghi lại các cấu hình thiết kế có thể tái tạo và hiệu suất đào tạo chi tiết trên nhiều nhiệm vụ khác nhau. Cụ thể, GNN-BANK-101 hiện tại bao gồm sáu nhiệm vụ cho phân loại nút (AmazonComputers (Shchur et al., 2018), AmazonPhoto (Shchur et al., 2018), CiteSeer (Yang et al., 2016), CoauthorCS (Shchur et al., 2018), CoauthorPhysics (Shchur et al., 2018), Cora (Yang et al., 2016)) và sáu nhiệm vụ cho phân loại đồ thị (PROTEINS (Ivanov et al., 2019), BZR (Ivanov et al., 2019), COX2 (Ivanov et al., 2019), DD (Ivanov et al., 2019), ENZYMES (Ivanov et al., 2019), IMDB-M (Ivanov et al., 2019)). Không gian thiết kế của chúng tôi tuân theo (You et al., 2020), và chúng tôi mở rộng không gian thiết kế để bao gồm các lớp tích chập đồ thị và kích hoạt thường được áp dụng khác nhau. Chúng tôi chạy rộng rãi 10.000 mô hình khác nhau cho mỗi nhiệm vụ, dẫn đến tổng cộng 120.000 kết hợp nhiệm vụ-mô hình, và ghi lại tất cả thông tin đào tạo bao gồm mất mát train/val/test.

Tập dữ liệu Benchmark. Chúng tôi đánh giá AUTOTRANSFER trên sáu tập dữ liệu khác nhau theo công trình trước đó (Qin et al., 2021). Các tập dữ liệu của chúng tôi bao gồm ba tập dữ liệu phân loại nút tiêu chuẩn (CoauthorPhysics (Shchur et al., 2018), CoraFull (Bojchevski and Günnemann, 2017) và OGB-Arxiv (Hu et al., 2020)), cũng như ba tập dữ liệu benchmark phân loại đồ thị tiêu chuẩn, (COX2 (Ivanov et al., 2019), IMDB-M (Ivanov et al., 2019) và PROTEINS (Ivanov et al., 2019)). CoauthorPhysics và CoraFull là các tập dữ liệu phân loại nút transductive, vì vậy chúng tôi gán ngẫu nhiên các nút vào các tập train/valid/test theo tỷ lệ 50%:25%:25% (Qin et al., 2021). Chúng tôi chia ngẫu nhiên các đồ thị theo tỷ lệ 80%:10%:10% cho ba tập dữ liệu phân loại đồ thị (Qin et al., 2021). Chúng tôi tuân theo việc chia train/valid/test mặc định cho tập dữ liệu OGB-Arxiv (Hu et al., 2020). Để đảm bảo không có rò rỉ thông tin, chúng tôi tạm thời loại bỏ tất cả các bản ghi liên quan đến nhiệm vụ từ ngân hàng nhiệm vụ-mô hình của chúng tôi nếu tập dữ liệu chúng tôi đánh giá được thu thập trong ngân hàng nhiệm vụ-mô hình.

Baseline. Chúng tôi so sánh các phương pháp của chúng tôi với các phương pháp tiên tiến cho AutoML GNN. Chúng tôi sử dụng GCN và GAT với kiến trúc mặc định theo triển khai gốc của chúng làm baseline. Đối với các phương pháp NAS đa thử nghiệm, chúng tôi xem xét GraphNAS (Gao et al., 2020). Đối với các phương pháp NAS một lần, chúng tôi bao gồm DARTS (Liu et al., 2018) và GASSO (Qin et al., 2021). GASSO được thiết kế cho các thiết lập transductive, vì vậy chúng tôi bỏ qua nó cho các benchmark phân loại đồ thị. Chúng tôi tiếp tục cung cấp kết quả của các thuật toán HPO dựa trên không gian tìm kiếm được đề xuất của chúng tôi làm baseline: Random, Evolution, TPE (Bergstra et al., 2011) và HyperBand (Li et al., 2017).

Chúng tôi mặc định cho phép tìm kiếm tối đa 30 thử nghiệm cho tất cả các thuật toán, tức là, một thuật toán có thể đào tạo 30 mô hình khác nhau và thu thập mô hình với độ chính xác tốt nhất. Chúng tôi sử dụng thiết lập mặc định cho các thuật toán NAS một lần

7

--- TRANG 8 ---
Xuất bản như một bài báo hội nghị tại ICLR 2023

Bảng 1: So sánh hiệu suất của AUTOTRANSFER và các baseline khác. Chúng tôi báo cáo độ chính xác test trung bình và độ lệch chuẩn trên mười lần chạy. Chỉ với 3 thử nghiệm AUTOTRANSFER đã vượt trội hầu hết các baseline SOTA với 30 thử nghiệm.

| Phương pháp | Nút | | | Đồ thị | | |
|---|---|---|---|---|---|---|
| | Physics | CoraFull | OGB-Arxiv | COX2 | IMDB | PROTEINS |
| GCN (30 thử nghiệm) | 95.88±0.16 | 67.12±0.52 | 70.46±0.18 | 79.23±2.19 | 50.40±3.02 | 74.84±2.82 |
| GAT (30 thử nghiệm) | 95.71±0.24 | 65.92±0.68 | 68.82±0.32 | 81.56±4.17 | 49.67±4.30 | 75.30±3.72 |
| GraphNAS (30 thử nghiệm) | 92.77±0.84 | 63.13±3.28 | 65.90±2.64 | 77.73±1.40 | 46.93±3.94 | 72.51±3.36 |
| DARTS | 95.28±1.67 | 67.59±2.85 | 69.02±1.18 | 79.82±3.15 | 50.26±4.08 | 75.04±3.81 |
| GASSO⁴ | 96.38 | 68.89 | 70.52 | - | - | - |
| Random (3 thử nghiệm) | 95.16±0.55 | 61.24±4.04 | 67.92±1.92 | 76.88±3.17 | 45.79±4.39 | 72.47±2.57 |
| TPE (30 thử nghiệm) | 96.41±0.36 | 66.37±1.73 | 71.35±0.44 | 82.27±2.01 | 50.33±4.00 | 79.46±1.28 |
| HyperBand (30 thử nghiệm) | 96.56±0.30 | 67.75±1.24 | 71.60±0.36 | 82.21±1.79 | 50.86±3.45 | 79.32±1.16 |
| AUTOTRANSFER (3 thử nghiệm) | 96.64±0.42 | 69.27±0.76 | 71.42±0.39 | 82.13±1.59 | 52.33±2.13 | 77.81±2.19 |
| AUTOTRANSFER (30 thử nghiệm) | 96.91±0.27 | 70.05±0.42 | 72.21±0.27 | 86.52±1.58 | 54.93±1.23 | 81.25±1.17 |

thuật toán NAS (DARTS và GASSO), vì chúng chỉ đào tạo một siêu mô hình một lần và có thể đánh giá hiệu quả các kiến trúc khác nhau. Chúng tôi chủ yếu quan tâm đến việc nghiên cứu chế độ vài thử nghiệm nơi hầu hết các thuật toán tìm kiếm tiên tiến trở thành tìm kiếm ngẫu nhiên. Do đó chúng tôi bổ sung bao gồm một baseline tìm kiếm ngẫu nhiên (3 thử nghiệm) nơi chúng tôi chọn mô hình tốt nhất trong chỉ 3 thử nghiệm.

5.2 CÁC THÍ NGHIỆM VỀ HIỆU QUẢ TÌM KIẾM

Chúng tôi đánh giá AUTOTRANSFER bằng cách báo cáo độ chính xác test tốt nhất trung bình trong tất cả các thử nghiệm được xem xét trên mười lần chạy của mỗi thuật toán trong Bảng 1. Độ chính xác test được thu thập cho mỗi thử nghiệm được chọn tại epoch với độ chính xác validation tốt nhất. Bằng cách so sánh kết quả từ tìm kiếm ngẫu nhiên (3 thử nghiệm) và AUTOTRANSFER (3 thử nghiệm), chúng tôi cho thấy rằng tiên nghiệm thiết kế được thông báo nhiệm vụ được chuyển giao của chúng tôi cải thiện đáng kể độ chính xác test trong chế độ vài thử nghiệm, và có thể rất hữu ích trong các môi trường bị hạn chế về mặt tính toán. Ngay cả khi chúng tôi tăng số lượng thử nghiệm tìm kiếm lên 30, AUTOTRANSFER vẫn chứng minh sự cải thiện không tầm thường so với TPE, cho thấy rằng quy trình được đề xuất của chúng tôi có lợi thế ngay cả khi tài nguyên tính toán dồi dào. Đáng chú ý, chỉ với 3 thử nghiệm tìm kiếm, AUTOTRANSFER vượt qua hầu hết các baseline, ngay cả những baseline sử dụng 30 thử nghiệm.

Để hiểu rõ hơn về hiệu quả mẫu của AUTOTRANSFER, chúng tôi vẽ độ chính xác test tốt nhất được tìm thấy tại mỗi thử nghiệm trong Hình 3 cho các tập dữ liệu OGB-Arxiv và TU-PROTEINS. Chúng tôi nhận thấy rằng các thuật toán tìm kiếm tiên tiến (Evolution và TPE) không có lợi thế so với tìm kiếm ngẫu nhiên trong chế độ vài thử nghiệm vì lượng dữ liệu tìm kiếm trước đó chưa đủ để suy luận các cấu hình thiết kế tốt hơn tiềm năng. Ngược lại, bằng cách lấy mẫu từ tiên nghiệm thiết kế được chuyển giao, AUTOTRANSFER đạt được độ chính xác test trung bình tốt hơn đáng kể trong những thử nghiệm đầu tiên. Độ chính xác test tốt nhất tại thử nghiệm 3 của AUTOTRANSFER vượt qua đối tác của nó tại thử nghiệm 10 cho mọi phương pháp khác.

Hình 3: So sánh hiệu suất trong chế độ vài thử nghiệm. Tại thử nghiệm t, chúng tôi vẽ độ chính xác test tốt nhất trong tất cả các mô hình được tìm kiếm từ thử nghiệm 1 đến thử nghiệm t. AUTOTRANSFER có thể giảm số lượng thử nghiệm cần thiết để tìm kiếm đi một bậc độ lớn (xem thêm Bảng 4 trong Phụ lục).

5.3 PHÂN TÍCH CÁC NHÚNG NHIỆM VỤ

Phân tích định tính các đặc trưng nhiệm vụ. Để kiểm tra chất lượng của các đặc trưng nhiệm vụ được đề xuất, chúng tôi trực quan hóa ma trận tương đồng nhiệm vụ được đề xuất (Hình 4 (b)) cùng với ma trận tương đồng nhiệm vụ (Hình 4 (a)) được đề xuất trong GraphGym. Chúng tôi cho thấy rằng ma trận tương đồng nhiệm vụ được đề xuất của chúng tôi nắm bắt các mẫu tương tự như ma trận tương đồng nhiệm vụ của GraphGym trong khi được tính toán hiệu quả hơn nhiều

²Kết quả đến từ bài báo gốc (Qin et al., 2021).

8

--- TRANG 9 ---
Xuất bản như một bài báo hội nghị tại ICLR 2023

(a)(b)(c)

Hình 4: (a) Sự tương đồng nhiệm vụ của GraphGym giữa tất cả các cặp nhiệm vụ (được tính toán từ tương quan thứ hạng Kendall giữa các xếp hạng hiệu suất của các mô hình được đào tạo trên hai nhiệm vụ được so sánh), giá trị cao hơn đại diện cho sự tương đồng cao hơn. (b) Sự tương đồng nhiệm vụ được đề xuất được tính toán bằng cách tính tích vô hướng giữa các đặc trưng nhiệm vụ được trích xuất. (c) Tương quan thứ hạng Kendall của các xếp hạng tương đồng của các nhiệm vụ khác đối với nhiệm vụ trung tâm giữa phương pháp được đề xuất và GraphGym.

bằng cách bỏ qua đào tạo. Chúng tôi nhận thấy rằng cùng loại nhiệm vụ, tức là phân loại nút và phân loại đồ thị, chia sẻ nhiều sự tương đồng hơn trong mỗi nhóm. Như một kiểm tra độ tin cậy, chúng tôi kiểm tra rằng nhiệm vụ gần nhất trong ngân hàng đối với CoraFull là Cora. 3 nhiệm vụ gần nhất cho OGB-Arxiv là AmazonComputers, AmazonPhoto, và CoauthorPhysics, tất cả đều là các nhiệm vụ phân loại nút.

Tổng quát hóa của hàm chiếu g(). Để cho thấy hàm chiếu được đề xuất g() có thể tạo ra các nhúng nhiệm vụ có thể tổng quát hóa cho các nhiệm vụ mới, chúng tôi tiến hành xác thực chéo leave-one-out với tất cả các nhiệm vụ trong ngân hàng nhiệm vụ-mô hình của chúng tôi. Cụ thể, đối với mỗi nhiệm vụ được coi là nhiệm vụ mới T(n), chúng tôi sử dụng phần còn lại của các nhiệm vụ, cùng với metric khoảng cách dg(·; ·) của chúng được ước tính bởi không gian metric chính xác nhưng tốn kém về mặt tính toán của GraphGym, để đào tạo hàm chiếu g(). Chúng tôi tính toán tương quan thứ hạng Kendall trên sự tương đồng nhiệm vụ cho Đặc trưng Nhiệm vụ (không có g()) và Nhúng Nhiệm vụ (có g()) so với sự tương đồng nhiệm vụ chính xác. Tương quan thứ hạng trung bình và độ lệch chuẩn trên mười lần chạy được hiển thị trong Hình 4 (c). Chúng tôi thấy rằng với g() được đề xuất, các nhúng nhiệm vụ của chúng tôi thực sự tương quan tốt hơn với sự tương đồng nhiệm vụ chính xác, và do đó, tổng quát hóa tốt hơn cho các nhiệm vụ mới.

Nghiên cứu loại bỏ về thiết kế không gian nhiệm vụ thay thế. Để chứng minh sự ưu việt của nhúng nhiệm vụ được đề xuất, chúng tôi tiếp tục so sánh nó với các đặc trưng nhiệm vụ thay thế. Theo công trình trước đó (Yang et al., 2019), chúng tôi sử dụng các mất mát được chuẩn hóa trong 10 bước đầu tiên làm đặc trưng nhiệm vụ. Kết quả trên OGB-Arxiv được hiển thị trong Bảng 2. So với nhúng nhiệm vụ của AUTOTRANSFER, đặc trưng nhiệm vụ được tạo ra bởi các mất mát được chuẩn hóa có tương quan thứ hạng thấp hơn với metric chính xác và cho hiệu suất kém hơn. Bảng 2 tiếp tục chứng minh hiệu quả của việc sử dụng tương quan thứ hạng Kendall làm metric cho chất lượng nhúng nhiệm vụ, vì tương quan thứ hạng Kendall cao hơn dẫn đến hiệu suất tốt hơn.

Bảng 2: Nghiên cứu loại bỏ về thiết kế không gian nhiệm vụ thay thế so với nhúng nhiệm vụ của AUTOTRANSFER. Chúng tôi báo cáo độ chính xác test trung bình và độ lệch chuẩn OGB-Arxiv trên mười lần chạy.

| | Tương quan thứ hạng Kendall | Độ chính xác test |
|---|---|---|
| Thay thế: Mất mát được Chuẩn hóa | -0.07±0.43 | 68.13±1.27 |
| Đặc trưng Nhiệm vụ của AUTOTRANSFER | 0.18±0.30 | 70.67±0.52 |
| Nhúng Nhiệm vụ của AUTOTRANSFER | 0.43±0.22 | 71.42±0.39 |

6 KẾT LUẬN

Trong bài báo này, chúng tôi nghiên cứu cách cải thiện hiệu quả tìm kiếm AutoML bằng cách chuyển giao kiến thức thiết kế kiến trúc hiện có cho các nhiệm vụ mới quan tâm. Chúng tôi giới thiệu một ngân hàng nhiệm vụ-mô hình thu thập hiệu suất trên một tập hợp đa dạng các kiến trúc GNN và nhiệm vụ. Chúng tôi cũng giới thiệu một nhúng nhiệm vụ hiệu quả tính toán có thể đo lường chính xác sự tương đồng giữa các nhiệm vụ khác nhau. Chúng tôi phát hành GNN-BANK-101, một cơ sở dữ liệu quy mô lớn ghi lại thông tin đào tạo GNN chi tiết của 120.000 kết hợp nhiệm vụ-mô hình. Chúng tôi hy vọng công trình này có thể hỗ trợ và truyền cảm hứng cho nghiên cứu tương lai trong AutoML hiệu quả để làm cho học sâu có thể tiếp cận được với khán giả tổng quát hơn.

9

--- TRANG 10 ---
Xuất bản như một bài báo hội nghị tại ICLR 2023

LỜI CẢM ƠN
Chúng tôi cảm ơn Xiang Lisa Li, Hongyu Ren, Yingxin Wu vì các cuộc thảo luận và cung cấp phản hồi về bản thảo của chúng tôi. Chúng tôi cũng biết ơn sự hỗ trợ của DARPA dưới số HR00112190039 (TAMI), N660011924033 (MCS); ARO dưới số W911NF-16-1-0342 (MURI), W911NF-16-1-0171 (DURIP); NSF dưới số OAC-1835598 (CINES), OAC-1934578 (HDR), CCF-1918940 (Expeditions), NIH dưới số 3U54HG010426-04S1 (HuBMAP), Stanford Data Science Initiative, Wu Tsai Neurosciences Institute, Amazon, Docomo, GSK, Hitachi, Intel, JPMorgan Chase, Juniper Networks, KDDI, NEC, và Toshiba. Nội dung hoàn toàn là trách nhiệm của các tác giả và không nhất thiết đại diện cho quan điểm chính thức của các thực thể tài trợ.

10

--- TRANG 11 ---
Xuất bản như một bài báo hội nghị tại ICLR 2023

TÀI LIỆU THAM KHẢO

Alessandro Achille, Michael Lam, Rahul Tewari, Avinash Ravichandran, Subhransu Maji, Charless C Fowlkes, Stefano Soatto, and Pietro Perona. Task2vec: Task embedding for meta-learning. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 6430–6439, 2019.

James Bergstra and Yoshua Bengio. Random search for hyper-parameter optimization. Journal of machine learning research, 13(2), 2012.

James Bergstra, Rémi Bardenet, Yoshua Bengio, and Balázs Kégl. Algorithms for hyper-parameter optimization. Advances in neural information processing systems, 24, 2011.

Aleksandar Bojchevski and Stephan Günnemann. Deep gaussian embedding of graphs: Unsupervised inductive learning via ranking. arXiv preprint arXiv:1707.03815, 2017.

Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are few-shot learners. Advances in neural information processing systems, 33:1877–1901, 2020.

Han Cai, Ligeng Zhu, and Song Han. Proxylessnas: Direct neural architecture search on target task and hardware. arXiv preprint arXiv:1812.00332, 2018.

Shaofei Cai, Liang Li, Jincan Deng, Beichen Zhang, Zheng-Jun Zha, Li Su, and Qingming Huang. Re-thinking graph neural architecture search from message-passing. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 6657–6666, 2021.

Yuhui Ding, Quanming Yao, Huan Zhao, and Tong Zhang. Diffmg: Differentiable meta graph search for heterogeneous graph neural networks. In Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining, pages 279–288, 2021.

Nick Erickson, Jonas Mueller, Alexander Shirkov, Hang Zhang, Pedro Larroy, Mu Li, and Alexander Smola. Autogluon-tabular: Robust and accurate automl for structured data. ICML 2020 Workshop on Automated Machine Learning, 2020.

Yang Gao, Hong Yang, Peng Zhang, Chuan Zhou, and Yue Hu. Graphnas: Graph neural architecture search with reinforcement learning. arXiv preprint arXiv:1904.09981, 2019.

Yang Gao, Hong Yang, Peng Zhang, Chuan Zhou, and Yue Hu. Graph neural architecture search. In Christian Bessiere, editor, Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence, IJCAI-20, pages 1403–1409. International Joint Conferences on Artificial Intelligence Organization, 7 2020. URL https://doi.org/10.24963/ijcai.2020/195.

Zichao Guo, Xiangyu Zhang, Haoyuan Mu, Wen Heng, Zechun Liu, Yichen Wei, and Jian Sun. Single path one-shot neural architecture search with uniform sampling. In European Conference on Computer Vision, pages 544–560. Springer, 2020.

Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 770–778, 2016.

Xiangnan He, Kuan Deng, Xiang Wang, Yan Li, Yongdong Zhang, and Meng Wang. Lightgcn: Simplifying and powering graph convolution network for recommendation. In Proceedings of the 43rd International ACM SIGIR conference on research and development in Information Retrieval, pages 639–648, 2020.

Yihui He, Ji Lin, Zhijian Liu, Hanrui Wang, Li-Jia Li, and Song Han. Amc: Automl for model compression and acceleration on mobile devices. In Proceedings of the European conference on computer vision (ECCV), pages 784–800, 2018.

Weihua Hu, Matthias Fey, Marinka Zitnik, Yuxiao Dong, Hongyu Ren, Bowen Liu, Michele Catasta, and Jure Leskovec. Open graph benchmark: Datasets for machine learning on graphs. Advances in neural information processing systems, 33:22118–22133, 2020.

11

--- TRANG 12 ---
Xuất bản như một bài báo hội nghị tại ICLR 2023

Sergei Ivanov, Sergei Sviridov, and Evgeny Burnaev. Understanding isomorphism bias in graph data sets, 2019.

Max Jaderberg, Valentin Dalibard, Simon Osindero, Wojciech M Czarnecki, Jeff Donahue, Ali Razavi, Oriol Vinyals, Tim Green, Iain Dunning, Karen Simonyan, et al. Population based training of neural networks. arXiv preprint arXiv:1711.09846, 2017.

Wonyong Jeong, Hayeon Lee, Geon Park, Eunyoung Hyung, Jinheon Baek, and Sung Ju Hwang. Task-adaptive neural network search with meta-contrastive learning. Advances in Neural Information Processing Systems, 34:21310–21324, 2021.

Donald R Jones. A taxonomy of global optimization methods based on response surfaces. Journal of global optimization, 21(4):345–383, 2001.

Ryo Karakida, Shotaro Akaho, and Shun-ichi Amari. Universal statistics of fisher information in deep neural networks: Mean field approach. In The 22nd International Conference on Artificial Intelligence and Statistics, pages 1032–1041. PMLR, 2019.

Cat P Le, Mohammadreza Soltani, Juncheng Dong, and Vahid Tarokh. Fisher task distance and its application in neural architecture search. IEEE Access, 10:47235–47249, 2022.

Erin LeDell and Sebastien Poirier. H2o automl: Scalable automatic machine learning. ICML 2020 Workshop on Automated Machine Learning, 2020.

Junhyun Lee, Inyeop Lee, and Jaewoo Kang. Self-attention graph pooling. In International conference on machine learning, pages 3734–3743. PMLR, 2019.

Lisha Li, Kevin Jamieson, Giulia DeSalvo, Afshin Rostamizadeh, and Ameet Talwalkar. Hyperband: A novel bandit-based approach to hyperparameter optimization. The Journal of Machine Learning Research, 18(1):6765–6816, 2017.

Yanxi Li, Zean Wen, Yunhe Wang, and Chang Xu. One-shot graph neural architecture search with dynamic search space. In Proc. AAAI Conf. Artif. Intell, volume 35, pages 8510–8517, 2021.

Hanxiao Liu, Karen Simonyan, and Yiming Yang. Darts: Differentiable architecture search. In International Conference on Learning Representations, 2018.

Yao Ma, Suhang Wang, Charu C Aggarwal, and Jiliang Tang. Graph convolutional networks with eigenpooling. In Proceedings of the 25th ACM SIGKDD international conference on knowledge discovery & data mining, pages 723–731, 2019.

Jeffrey Pennington and Pratik Worah. The spectrum of the fisher information matrix of a single-hidden-layer neural network. Advances in neural information processing systems, 31, 2018.

Tobias Pfaff, Meire Fortunato, Alvaro Sanchez-Gonzalez, and Peter Battaglia. Learning mesh-based simulation with graph networks. In International Conference on Learning Representations, 2020.

Hieu Pham, Melody Guan, Barret Zoph, Quoc Le, and Jeff Dean. Efficient neural architecture search via parameters sharing. In International conference on machine learning, pages 4095–4104. PMLR, 2018.

Yijian Qin, Xin Wang, Zeyang Zhang, and Wenwu Zhu. Graph differentiable architecture search with structure learning. Advances in Neural Information Processing Systems, 34, 2021.

Esteban Real, Sherry Moore, Andrew Selle, Saurabh Saxena, Yutaka Leon Suematsu, Jie Tan, Quoc V Le, and Alexey Kurakin. Large-scale evolution of image classifiers. In International Conference on Machine Learning, pages 2902–2911. PMLR, 2017.

Roseanna W Saaty. The analytic hierarchy process—what it is and how it is used. Mathematical modelling, 9(3-5):161–176, 1987.

Alvaro Sanchez-Gonzalez, Jonathan Godwin, Tobias Pfaff, Rex Ying, Jure Leskovec, and Peter Battaglia. Learning to simulate complex physics with graph networks. In International Conference on Machine Learning, pages 8459–8468. PMLR, 2020.

12

--- TRANG 13 ---
Xuất bản như một bài báo hội nghị tại ICLR 2023

Oleksandr Shchur, Maximilian Mumme, Aleksandar Bojchevski, and Stephan Günnemann. Pitfalls of graph neural network evaluation. arXiv preprint arXiv:1811.05868, 2018.

Lanning Wei, Huan Zhao, Quanming Yao, and Zhiqiang He. Pooling architecture search for graph classification. In Proceedings of the 30th ACM International Conference on Information & Knowledge Management, pages 2091–2100, 2021.

Catherine Wong, Neil Houlsby, Yifeng Lu, and Andrea Gesmundo. Transfer learning with neural automl. Advances in neural information processing systems, 31, 2018.

Chengrun Yang, Yuji Akimoto, Dae Won Kim, and Madeleine Udell. Oboe: Collaborative filtering for automl model selection. In Proceedings of the 25th ACM SIGKDD international conference on knowledge discovery & data mining, 2019.

Zhilin Yang, William Cohen, and Ruslan Salakhudinov. Revisiting semi-supervised learning with graph embeddings. In International conference on machine learning, pages 40–48. PMLR, 2016.

Rex Ying, Ruining He, Kaifeng Chen, Pong Eksombatchai, William L Hamilton, and Jure Leskovec. Graph convolutional neural networks for web-scale recommender systems. In Proceedings of the 24th ACM SIGKDD international conference on knowledge discovery & data mining, pages 974–983, 2018.

Jiaxuan You, Zhitao Ying, and Jure Leskovec. Design space for graph neural networks. Advances in Neural Information Processing Systems, 33:17009–17021, 2020.

Yuning You, Tianlong Chen, Yang Shen, and Zhangyang Wang. Graph contrastive learning automated. In International Conference on Machine Learning, pages 12121–12132. PMLR, 2021.

Amir R Zamir, Alexander Sax, William Shen, Leonidas J Guibas, Jitendra Malik, and Silvio Savarese. Taskonomy: Disentangling task transfer learning. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 3712–3722, 2018.

Bo Zhao and Hakan Bilen. Dataset condensation with differentiable siamese augmentation. In International Conference on Machine Learning, pages 12674–12685. PMLR, 2021.

Huan Zhao, Quanming Yao, and Weiwei Tu. Search to aggregate neighborhood for graph neural network. arXiv preprint arXiv:2104.06608, 2021.

Kaixiong Zhou, Qingquan Song, Xiao Huang, and Xia Hu. Auto-gnn: Neural architecture search of graph neural networks. arXiv preprint arXiv:1909.03184, 2019.

Marinka Zitnik, Monica Agrawal, and Jure Leskovec. Modeling polypharmacy side effects with graph convolutional networks. Bioinformatics, 34(13):i457–i466, 2018.

Barret Zoph and Quoc V Le. Neural architecture search with reinforcement learning. arXiv preprint arXiv:1611.01578, 2016.

Barret Zoph, Vijay Vasudevan, Jonathon Shlens, and Quoc V Le. Learning transferable architectures for scalable image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 8697–8710, 2018.

13

--- TRANG 14 ---
Xuất bản như một bài báo hội nghị tại ICLR 2023

A CHI TIẾT TRIỂN KHAI BỔ SUNG

Phân tích thời gian chạy. Chúng tôi đã chứng minh thực nghiệm rằng AUTOTRANSFER có thể cải thiện đáng kể hiệu quả tìm kiếm bằng cách giảm số lượng thử nghiệm cần thiết để đạt độ chính xác tốt hợp lý. Chi phí bổ sung duy nhất chúng tôi giới thiệu là quy trình ước tính nhúng nhiệm vụ. Vì chúng tôi sử dụng kiến trúc được khởi tạo ngẫu nhiên, việc trích xuất mỗi đặc trưng nhiệm vụ chỉ đòi hỏi tối đa một lần truyền xuôi và một vài lần truyền ngược từ một minibatch dữ liệu duy nhất. Thời gian wall-clock phụ thuộc vào kích thước của mạng và cấu trúc dữ liệu. Trong các thí nghiệm của chúng tôi, thường mất vài giây trên GPU NVIDIA T4. Chúng tôi lặp lại quy trình trích xuất đặc trưng nhiệm vụ 5 lần cho mỗi mô hình neo, và cho tổng cộng 12 mô hình neo. Do đó, thời gian wall-clock của chi phí bổ sung để tính toán nhúng nhiệm vụ của nhiệm vụ mới trong vài phút. Chúng tôi lưu ý độ dài của quy trình này thường tương đương với một thử nghiệm đào tạo trên tập dữ liệu kích thước nhỏ, và thời gian tiết kiệm được quan trọng hơn nhiều đối với các tập dữ liệu quy mô lớn.

Chi tiết cho đào tạo ngân hàng nhiệm vụ-mô hình. Các đặc tả mô hình GNN của chúng tôi được tóm tắt trong Bảng 3. Cơ sở mã của chúng tôi được phát triển dựa trên GraphGym (You et al., 2020). Đối với tất cả các thử nghiệm đào tạo, chúng tôi sử dụng bộ tối ưu Adam và bộ lập lịch tốc độ học cosine (giảm dần về 0, không khởi động lại). Chúng tôi sử dụng regularization L2 với weight decay 5e-4. Chúng tôi ghi lại các mất mát và độ chính xác cho các phần chia train, validation và test mỗi 20 epoch.

Chi tiết đào tạo cho AUTOTRANSFER. Chúng tôi tóm tắt quy trình đào tạo cho hàm chiếu g() trong Thuật toán 2. Chúng tôi đặt U = 12 và R = 5 trong toàn bộ bài báo. Chúng tôi sử dụng cùng tập hợp các thiết kế mô hình neo như trong GraphGym. Chúng tôi sử dụng MLP hai lớp với chiều ẩn 16 để tham số hóa hàm chiếu g(). Chúng tôi sử dụng bộ tối ưu Adam với tốc độ học 5e-3. Chúng tôi sử dụng margin = 0.1 và đào tạo mạng trong 1000 lần lặp với batch size 128. Chúng tôi áp dụng K = 16 khi chọn K thử nghiệm hàng đầu được sử dụng để tóm tắt các phân phối thiết kế.

Chi tiết để điều chỉnh TPE, thuật toán tiến hóa. Chúng tôi minh họa cách kết hợp các thuật toán tìm kiếm với các tiên nghiệm thiết kế được chuyển giao. TPE là một phương pháp tối ưu hóa siêu tham số Bayesian, có nghĩa là nó được khởi tạo với một phân phối tiên nghiệm để mô hình hóa không gian tìm kiếm và cập nhật tiên nghiệm khi nó đánh giá các cấu hình siêu tham số và ghi lại hiệu suất của chúng. Chúng tôi thay thế phân phối tiên nghiệm này bằng các tiên nghiệm thiết kế được thông báo nhiệm vụ. Vì các thuật toán tiến hóa thường khởi tạo một quần thể lớn và lặp đi lặp lại cắt tỉa và biến đổi các mạng hiện có, chúng tôi thay thế việc khởi tạo mạng ngẫu nhiên bằng các tiên nghiệm thiết kế được thông báo nhiệm vụ. Vì chúng tôi chủ yếu tập trung vào chế độ tìm kiếm vài thử nghiệm, chúng tôi đặt các thử nghiệm warm-up hoàn toàn ngẫu nhiên thành 5 cho cả thuật toán TPE và tiến hóa.

Bảng 3: Các lựa chọn thiết kế trong không gian tìm kiếm của chúng tôi

| Loại | Lựa chọn |
|---|---|
| Convolution | GeneralConv, GCNConv, SAGEConv, GINConv, GATConv |
| Số lượng heads | 1, 2, 4 |
| Aggregation | Sum, Mean-Pooling, Max-Pooling |
| Activation | ReLU, pReLU, leaky_ReLU, ELU |
| Chiều ẩn | 64, 256 |
| Kết nối lớp | Stack, Skip-Sum, Skip-Concat |
| Lớp tiền xử lý | 1, 2 |
| Lớp truyền tin | 2, 4, 6, 8 |
| Lớp hậu xử lý | 2, 3 |
| Tốc độ học | 0.1, 0.001 |
| Epoch đào tạo | 200, 800, 1600 |

B THẢO LUẬN BỔ SUNG

Hạn chế. Về nguyên tắc, AUTOTRANSFER tận dụng tương quan giữa các xếp hạng hiệu suất mô hình giữa các nhiệm vụ để xây dựng hiệu quả các tiên nghiệm mô hình. Do đó, nó ít hiệu quả hơn nếu nhiệm vụ mới có khoảng cách nhiệm vụ lớn đối với tất cả các nhiệm vụ trong ngân hàng nhiệm vụ-mô hình. Trong thực tế, người dùng có thể liên tục thêm các thử nghiệm tìm kiếm bổ sung vào ngân hàng. Khi kích thước ngân hàng tăng lên, sẽ ít có khả năng một nhiệm vụ mới có tương quan thấp với tất cả các nhiệm vụ trong ngân hàng.

14

--- TRANG 15 ---
Xuất bản như một bài báo hội nghị tại ICLR 2023

Thuật toán 2 Quy trình Đào tạo cho hàm chiếu g()
Yêu cầu: Các đặc trưng nhiệm vụ {z(i)f|T(i)} được trích xuất cho mỗi nhiệm vụ từ ngân hàng nhiệm vụ-mô hình. Khoảng cách đo dg(·; ·) được ước tính trong GraphGym.
1: for each iteration do
2:   Lấy mẫu T(i), T(j), T(k)
3:   z(i)e; z(j)e; z(k)e ← g(z(i)f); g(z(j)f); g(z(k)f)
4:   y ← 1 nếu dg(T(i); T(j)) < dg(T(i); T(k)) ngược lại −1
5:   Tối ưu hóa hàm mục tiêu Lr(z(i)e; z(j)e; z(k)e; y) trong Phương trình 2
6: end for

Tác động Xã hội. Mục tiêu dài hạn của chúng tôi là cung cấp một hạ tầng GNN liền mạch đơn giản hóa việc đào tạo và triển khai các mô hình ML trên dữ liệu có cấu trúc. Các thuật toán AutoML hiệu quả và mạnh mẽ là rất quan trọng để làm cho học sâu có thể tiếp cận được với những người quan tâm nhưng thiếu chuyên môn học sâu cũng như những người thiếu ngân sách tính toán khổng lồ mà AutoML truyền thống đòi hỏi. Chúng tôi tin rằng bài báo này là một bước quan trọng để cung cấp các công cụ AI cho dân số rộng hơn và do đó cho phép AI giúp tăng cường năng suất con người. Các tập dữ liệu chúng tôi sử dụng cho các thí nghiệm là một trong những benchmark được sử dụng rộng rãi nhất, không nên chứa bất kỳ thiên lệch không mong muốn nào. Bên cạnh đó, các mất mát/độ chính xác đào tạo/test là các thống kê được tóm tắt cao mà chúng tôi tin rằng không nên gây ra các vấn đề bảo mật tiềm năng.

C KẾT QUẢ BỔ SUNG

Hiệu quả tìm kiếm. Chúng tôi tóm tắt số lượng thử nghiệm trung bình cần thiết để vượt qua độ chính xác tốt nhất trung bình được tìm thấy bởi TPE với 30 thử nghiệm trong Bảng 4. Chúng tôi cho thấy rằng AUTOTRANSFER giảm số lượng kiến trúc được khám phá đi một bậc độ lớn.

Bảng 4: Số lượng thử nghiệm tìm kiếm trung bình cần thiết để vượt qua kết quả tốt nhất trung bình được tìm thấy bởi TPE với 30 thử nghiệm

| | Nút | | | Đồ thị | | |
|---|---|---|---|---|---|---|
| | Physics | CoraFull | OGB-Arxiv | COX2 | IMDB | PROTEINS |
| Số thử nghiệm | 3 | 2 | 3 | 4 | 3 | 6 |
| Độ chính xác | 96.64±0.42 | 67.85±1.31 | 71.42±0.39 | 82.96±1.75 | 52.33±2.13 | 80.21±1.21 |

Nghiên cứu loại bỏ về số lượng mô hình neo và thiết kế nhúng nhiệm vụ. Chúng tôi chứng minh thực nghiệm cách số lượng mô hình neo ảnh hưởng đến tương quan thứ hạng trong Bảng 5. Trong khi 3 mô hình neo không đủ để nắm bắt khoảng cách nhiệm vụ, chúng tôi thấy rằng 9 và 12 có sự cân bằng thỏa đáng giữa việc nắm bắt khoảng cách nhiệm vụ và hiệu quả tính toán. Hơn nữa, chúng tôi chứng minh thực nghiệm trong Bảng 6 rằng không gian nhúng nhiệm vụ đã học vượt trội hơn không gian đặc trưng nhiệm vụ được đề xuất về mặt tương quan cũng như hiệu suất tìm kiếm cuối cùng.

Bảng 5: Tương quan thứ hạng Kendall trung bình của các xếp hạng tương đồng của các nhiệm vụ khác đối với nhiệm vụ trung tâm giữa phương pháp được đề xuất và GraphGym.

| Số lượng mô hình neo | 3 | 6 | 9 | 12 |
|---|---|---|---|---|
| Đặc trưng Nhiệm vụ | 0.03±0.34 | 0.11±0.36 | 0.16±0.34 | 0.18±0.30 |
| Nhúng Nhiệm vụ | 0.12±0.28 | 0.26±0.30 | 0.36±0.24 | 0.43±0.22 |

Trực quan hóa các thiết kế mô hình. Chúng tôi trực quan hóa các phân phối thiết kế được chuyển giao và phân phối thiết kế sự thật cơ bản trên tập dữ liệu TU-PROTEINS trong Hình 5, cũng như tập dữ liệu Coauthor-Physics trong Hình 6. Chúng tôi có thể quan sát rằng các phân phối thiết kế được chuyển giao có tương quan tích cực trên hầu hết các lựa chọn thiết kế.

15

--- TRANG 16 ---
Xuất bản như một bài báo hội nghị tại ICLR 2023

Bảng 6: Nghiên cứu loại bỏ về số lượng mô hình neo cũng như nhúng nhiệm vụ so với đặc trưng nhiệm vụ trên OGB-Arxiv với 3 thử nghiệm. Chúng tôi báo cáo độ chính xác test trung bình và độ lệch chuẩn trên mười lần chạy.

| Số lượng mô hình neo | 3 | 6 | 9 | 12 |
|---|---|---|---|---|
| Đặc trưng Nhiệm vụ | 69.42±0.82 | 69.86±0.78 | 70.41±0.59 | 70.67±0.52 |
| Nhúng Nhiệm vụ | 69.80±0.75 | 70.59±0.63 | 71.16±0.47 | 71.42±0.39 |

[Đây là các biểu đồ hiển thị phân phối thiết kế được chuyển giao và phân phối thiết kế sự thật cơ bản cho các tham số khác nhau như gnn.layers_pre_mp, gnn.layers_mp, gnn.layers_post_mp, gnn.stage_type, gnn.agg, gnn.dim_inner, gnn.layer_type, gnn.act, optim.base_lr, optim.max_epoch]

Hình 5: Chúng tôi vẽ các phân phối thiết kế được chuyển giao và phân phối thiết kế sự thật cơ bản trên tập dữ liệu TU-PROTEINS.

[Các biểu đồ tương tự cho tập dữ liệu Coauthor-Physics]

Hình 6: Chúng tôi vẽ các phân phối thiết kế được chuyển giao và phân phối thiết kế sự thật cơ bản trên tập dữ liệu Coauthor-Physics.

16

# 2310.09049.pdf
# Đã chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/automl-nas/2310.09049.pdf
# Kích thước tệp: 406944 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
Mẫu L ATEX Springer Nature 2021
SAI: Giải quyết các Tác vụ AI với Trí tuệ 
Nhân tạo Hệ thống trong Mạng
Truyền thông
Lei Yao1, Yong Zhang1,2*, Zilong Yan1 và Jialu Tian1
1Khoa Kỹ thuật Điện tử, Đại học Bưu điện Bắc Kinh, Bắc Kinh, 100876, Trung Quốc.
2Phòng thí nghiệm Trọng điểm Bắc Kinh về Giám sát Thông minh An toàn Lao động,
Đại học Bưu điện Bắc Kinh, Bắc Kinh,
100876, Trung Quốc.
*Tác giả liên hệ. E-mail(s): yongzhang@bupt.edu.cn;
Tóm tắt
Trong sự phát triển nhanh chóng của trí tuệ nhân tạo, giải quyết các tác vụ AI phức tạp là một công nghệ quan trọng trong mạng di động thông minh. Mặc dù hiệu suất tốt của các mô hình AI chuyên biệt trong mạng di động thông minh, chúng không thể xử lý các tác vụ AI phức tạp. Để giải quyết thách thức này, chúng tôi đề xuất Trí tuệ Nhân tạo Hệ thống (SAI), đây là một khung được thiết kế để giải quyết các tác vụ AI bằng cách tận dụng Mô hình Ngôn ngữ Lớn (LLM) và đầu vào dựa trên ý định định dạng JSON để kết nối thư viện mô hình và cơ sở dữ liệu tự thiết kế. Cụ thể, chúng tôi đầu tiên thiết kế một thành phần đa đầu vào, đồng thời tích hợp Mô hình Ngôn ngữ Lớn (LLM) và đầu vào dựa trên ý định định dạng JSON để đáp ứng các yêu cầu ý định đa dạng của các người dùng khác nhau. Ngoài ra, chúng tôi giới thiệu một mô-đun thư viện mô hình dựa trên thẻ mô hình sử dụng thẻ mô hình để khớp theo cặp giữa các mô-đun khác nhau cho việc tạo thành mô hình. Thẻ mô hình chứa tên của mô hình tương ứng và các chỉ số hiệu suất yêu cầu. Sau đó, khi nhận được yêu cầu mạng của người dùng, chúng tôi thực hiện từng tác vụ con cho nhiều tổ hợp mô hình đã chọn và cung cấp đầu ra dựa trên kết quả thực hiện và phản hồi LLM. Bằng cách tận dụng khả năng ngôn ngữ của LLM và các mô hình AI phong phú trong thư viện mô hình, SAI có thể hoàn thành nhiều tác vụ AI phức tạp trong mạng truyền thông, đạt được kết quả ấn tượng trong tối ưu hóa mạng, phân bổ tài nguyên và các tác vụ thách thức khác.
1arXiv:2310.09049v1  [cs.AI]  13 Oct 2023

--- TRANG 2 ---
Mẫu L ATEX Springer Nature 2021
2 Tiêu đề Bài báo
Từ khóa: Mô hình Ngôn ngữ Lớn, Tác vụ AI, Trí tuệ Nhân tạo Hệ thống, Mạng Truyền thông

1 Giới thiệu
Trong những năm gần đây, với sự phát triển của công nghệ 5G và mạng công suất tính toán, những phát triển đáng kể đã xảy ra trong công suất tính toán mạng và mạng truyền thông. Sự tiến hóa này đã thay đổi sâu sắc cách thức xây dựng mạng và thực hiện các tác vụ AI. Ngoài ra, với những đột phá đáng kể được LLM đạt được trong trí tuệ giống con người, việc xử lý các tác vụ AI phức tạp dựa trên ý định đã trở nên khả thi. Gần đây, phương pháp chính của cộng tác đa tác nhân dựa trên LLM [1–3], chẳng hạn như HuggingGPT [1], MetaGPT [2], v.v., là sử dụng LLM như một bộ điều khiển để xử lý dịch thuật và lập kế hoạch tác vụ phức tạp. Sau đó, các tác nhân khác nhau được sử dụng để thực hiện các mô-đun khác nhau để hoàn thành hiệu quả tất cả các loại tác vụ phức tạp. Những phương pháp này có hiệu suất tốt trên các tác vụ phức tạp. Tuy nhiên, hiệu suất của chúng bị giới hạn bởi mô hình LLM. Hơn nữa, theo hiểu biết của chúng tôi, không có tài liệu nào đã áp dụng phương pháp này cho các tác vụ AI phức tạp trong mạng di động.

Trong mạng di động, Mạng Dựa trên Ý định (IBN) [4] là một mô hình mạng tự động hóa cấu hình mạng dựa trên phân tích ý định. Với sự gia tăng của IBN, Mạng Được Định nghĩa bằng Phần mềm (SDN) [5] đã đạt được thành công đáng kể. Các phương pháp hiện tại dựa trên mạng ý định [6–8] chủ yếu tập trung vào phân loại ý định và xung đột đa ý định. Phân loại ý định thường phân loại ý định thành hai nhóm: người dùng cuối và nhà điều hành mạng. Sau đó, chúng cung cấp các đầu vào ý định khác nhau cho các người dùng khác nhau. Xung đột đa ý định tập trung vào cách thực hiện các ý định khác nhau đồng thời trong quá trình nhập ý định. Tuy nhiên, những phương pháp này thường chỉ áp dụng được trong môi trường đơn giản và không thể xử lý các tác vụ AI phức tạp trong mạng di động.

Để giải quyết những thách thức này, chúng tôi đề xuất khung SAI. Khung này được thiết kế để giải quyết các tác vụ AI bằng cách tận dụng Mô hình Ngôn ngữ Lớn (LLM), đầu vào dựa trên ý định định dạng JSON và thư viện mô hình và cơ sở dữ liệu tự thiết kế. Cụ thể, chúng tôi đồng thời tích hợp Mô hình Ngôn ngữ Lớn (LLM) và đầu vào dựa trên ý định định dạng JSON để đáp ứng các yêu cầu ý định đa dạng của các người dùng khác nhau. Ngoài ra, chúng tôi giới thiệu một mô-đun thư viện mô hình dựa trên thẻ mô hình sử dụng thẻ mô hình để khớp theo cặp giữa các mô-đun khác nhau cho việc tạo thành mô hình. Sau đó, khi nhận được yêu cầu mạng của người dùng, chúng tôi thực hiện từng tác vụ con cho nhiều tổ hợp mô hình đã chọn và cung cấp đầu ra dựa trên kết quả thực hiện và phản hồi LLM. Những đóng góp chính của bài báo này được tóm tắt như sau:

•Để giải quyết các tác vụ AI phức tạp trong mạng truyền thông, Chúng tôi đề xuất SAI, sử dụng thành phần đa đầu vào để tương tác với thư viện mô hình tự thiết kế,

--- TRANG 3 ---
Mẫu L ATEX Springer Nature 2021
Tiêu đề Bài báo 3
cơ sở dữ liệu. Theo hiểu biết tốt nhất của chúng tôi, đây là phương pháp trí tuệ nhân tạo hệ thống đầu tiên để giải quyết các tác vụ phức tạp trong mạng truyền thông.

•Chúng tôi đề xuất thành phần đa đầu vào, kết hợp đầu vào LLM với đầu vào ý định dựa trên định dạng JSON để đáp ứng yêu cầu của những người khác nhau. Ngoài ra, chúng tôi thiết kế thư viện mô hình dựa trên thẻ mô hình. Cụ thể, thẻ mô hình chứa tên của mô hình tương ứng và các chỉ số hiệu suất mạng. Sau đó, chúng tôi sử dụng thẻ mô hình để khớp theo cặp giữa các mô-đun khác nhau cho việc tạo thành mô hình.

Phần còn lại của bài báo này được tổ chức như sau. Một đánh giá ngắn gọn về các công trình liên quan được cung cấp trong Phần 2. Trong Phần 3, chúng tôi trình bày chi tiết Khung cho Trí tuệ Nhân tạo Hệ thống. Phần 4 đến với những nhận xét kết luận.

2 Công trình Liên quan
2.1 Tác nhân Tự trị
Tác nhân tự trị thường được coi là một công nghệ chính trong trí tuệ nhân tạo tổng quát (AGI). Quản trị tự trị và ra quyết định của chúng đã thu hút sự quan tâm đáng kể. Các phương pháp trước đây thường dựa vào học tăng cường để tương tác với môi trường nhằm đạt được quản trị tự trị. Volodymyr Mnih et al.[9] chứng minh rằng tác nhân mạng Q sâu, chỉ nhận các pixel và điểm trò chơi làm đầu vào. Và mạng này bắc cầu khoảng cách giữa đầu vào cảm biến chiều cao và hành động, dẫn đến tác nhân nhân tạo đầu tiên có khả năng học để xuất sắc trong một loạt các tác vụ thách thức đa dạng. John Schulman et al. [10] đề xuất một họ mới các phương pháp gradient chính sách cho học tăng cường, luân phiên giữa lấy mẫu dữ liệu thông qua tương tác với môi trường, và tối ưu hóa một hàm mục tiêu "tác nhân" sử dụng phương pháp gradient ngẫu nhiên tăng dần. Tuomas Haarnoja et al. [11] đề xuất soft actor-critic, một thuật toán RL sâu actor-critic off-policy dựa trên khung học tăng cường entropy tối đa. Trong khung này, actor nhằm mục đích tối đa hóa phần thưởng mong đợi đồng thời cũng tối đa hóa entropy. Nghĩa là, thành công trong tác vụ trong khi hành động một cách ngẫu nhiên nhất có thể. Những phương pháp dựa trên học tăng cường này giả định rằng tác nhân là một hàm chính sách đơn giản và bị giới hạn trong các môi trường cụ thể. Những giả định này khác với quá trình ra quyết định của con người, và các phương pháp trước đây không thể tương tác với con người hoặc áp dụng trong môi trường miền mở.

Với thành công to lớn của các mô hình ngôn ngữ lớn (LLM), nó đã cho thấy tiềm năng to lớn trong việc đạt được trí tuệ giống con người. Để giải quyết những thách thức về khả năng ứng dụng hạn chế của tác nhân tự trị trong môi trường phức tạp, Yongliang Shen et al. [1] đề xuất HuggingGPT, một khung tận dụng LLM (ví dụ, ChatGPT) để kết nối các mô hình AI khác nhau trong cộng đồng học máy (ví dụ, Hugging Face) để giải quyết các tác vụ AI. Và Sirui Hong

--- TRANG 4 ---
Mẫu L ATEX Springer Nature 2021
4 Tiêu đề Bài báo
et al. [2] giới thiệu MetaGPT, một khung đột phá kết hợp các quy trình làm việc hiệu quả của con người như một phương pháp lập trình meta vào cộng tác đa tác nhân dựa trên LLM. Shujian Zhang et al. [12] trình bày AutoML-GPT, sử dụng GPT như cầu nối đến các mô hình AI đa dạng và động thái huấn luyện mô hình với các siêu tham số được tối ưu hóa. AutoML-GPT động thái lấy yêu cầu người dùng từ thẻ mô hình và dữ liệu và tạo ra đoạn prompt tương ứng. Cộng tác đa tác nhân dựa trên LLM có thể hoàn thành nhiều tác vụ AI phức tạp. Tuy nhiên, nó không thể tránh khỏi vấn đề ảo giác của LLM [13]. Điều này có thể quan trọng đặc biệt trong các tình huống mạng di động.

2.2 Mạng Dựa trên Ý định (IBN)
Mạng Dựa trên Ý định (IBN) là một mô hình mạng để Tự động quản lý cấu hình mạng dựa trên ý định [4]. Gần đây, các phương pháp dựa trên ý định với giao diện chatbot đã xuất hiện để đơn giản hóa dịch thuật ý định và kết hợp phản hồi của người dùng. Các công cụ như iNDIRA [6] sử dụng NLP để tạo đồ thị RDF ngữ nghĩa, được dịch thành lệnh mạng. EVIAN [7] mở rộng iNDIRA bằng cách sử dụng RASA cho giao diện chatbot và hệ thống phân cấp RDF cho dịch thuật ý định. LUMI [14] sử dụng Google Dialogflow và các phương pháp học để dịch ý định người dùng thành ý định Nile, được biên dịch thành chương trình cho các thay đổi cấu hình mạng. [8] định nghĩa một khung chính sách chính thức cho phép mô hình hóa chính sách ở các mức độ trừu tượng khác nhau, bao gồm các loại chính sách tiện ích, mục tiêu và event-condition-action (ECA), và cho phép phát hiện và giải quyết xung đột qua các lớp trừu tượng. Tối thiểu, một chính sách nên chứa một tập hợp tài nguyên mà một hành động sẽ được áp dụng, trong khi xem xét một tập hợp các ràng buộc liên quan. Những mạng ý định này sử dụng ngôn ngữ tự nhiên làm đầu vào đáp ứng nhu cầu mạng của người dùng cuối. Tuy nhiên, vấn đề ảo giác liên quan đến LLM (Language Model Learning) có thể tiềm tàng quan trọng trong mạng di động. Ngoài ra, phương pháp hiện tại dựa trên mạng ý định không xem xét việc chọn các mô hình phù hợp cho các tác vụ AI phức tạp.

3 Phương pháp
SAI là một hệ thống cộng tác đa tác nhân được thiết kế để hoàn thành các tác vụ AI phức tạp trong mạng di động. Nó bao gồm nhiều đầu vào, bao gồm đầu vào LLM và đầu vào ý định định dạng JSON, một thư viện mô hình và cơ sở dữ liệu tự thiết kế. Quy trình làm việc của nó bao gồm năm giai đoạn: thành phần đầu vào đa dạng, dịch thuật và lập kế hoạch tác vụ, chiến lược chọn mô hình, thực hiện tác vụ, đầu ra cuối cùng và phản hồi phản hồi, như được hiển thị trong Hình 1. Với yêu cầu của người dùng cuối hoặc đầu vào ý định chuyên biệt của nhà điều hành mạng, SAI tự động hoàn thành nhiều tác vụ AI phức tạp sử dụng các mô hình khác nhau. Trong các phần tiếp theo, chúng tôi sẽ đi sâu vào thiết kế của từng giai đoạn.

Chúng tôi đề xuất một cấu trúc mạng nơ-ron mới có tên DLA-GCN. Như được hiển thị trong Hình 1, mô hình bao gồm các thành phần DLGCN, DATL và NMPL. Những phương pháp này học các thuộc tính cấu trúc không gian bằng cách kết hợp DLGCN và NMPL và sử dụng thuật toán DATL để học và chuyển giao

--- TRANG 5 ---
Mẫu L ATEX Springer Nature 2021
Tiêu đề Bài báo 5
Hình 1 : Khung cho Trí tuệ Nhân tạo Hệ thống
các đặc tính tương tự của đồ thị động tại các bước thời gian liền kề. Lưu ý rằng các nút trong phần này phát triển động. Nói cách khác, số lượng nút trong mỗi bước thời gian là khác nhau. Do đó, sau khi trích xuất đặc tính tại t, chúng tôi thêm 0 để khớp chiều trong các bước thời gian liền kề t và t+ 1. Phương pháp này tránh sự không khớp chiều và ngăn chặn sự xuất hiện của ma trận đa số không.

3.1 Thành phần Đầu vào Đa dạng
Thành phần đa đầu vào chủ yếu bao gồm hai phần: đầu vào ngôn ngữ tự nhiên LLM và đầu vào ý định dựa trên định dạng JSON. Người dùng cuối có xu hướng tương tác với các mô hình sử dụng ngôn ngữ tự nhiên để hoàn thành các tác vụ phức tạp và do đó việc sử dụng LLM là cần thiết. Tuy nhiên, do tính mơ hồ vốn có trong ngôn ngữ tự nhiên và vấn đề ảo giác trong LLM, chúng tôi xem xét việc kết hợp phản hồi tích hợp của LLM để tăng cường độ chính xác của dịch thuật và lập kế hoạch, điều này sẽ được thảo luận trong Phần 3.5. Đồng thời, đối với các nhà điều hành mạng, chúng tôi cung cấp đầu vào ý định không mơ hồ dựa trên định dạng JSON, trực tiếp truyền đạt ý định thực sự đến mạng để đảm bảo thực hiện đúng các yêu cầu mạng.

3.2 Dịch thuật và Lập kế hoạch Tác vụ
Để giải quyết các tác vụ AI phức tạp trong mạng di động, cần thiết phải điều phối nhiều tác vụ con. Sau khi xử lý đầu vào LLM, chúng tôi sử dụng LLM để phân tích ý định của người dùng và phân tích chúng thành một tập hợp các tác vụ có cấu trúc. Hơn nữa, chúng tôi cũng yêu cầu LLM xác định các phụ thuộc và thứ tự thực hiện cho những tác vụ được phân tích này để thiết lập kết nối của chúng bằng phương pháp re-prompting [15]. Hiện tại, các mối quan hệ tác vụ được hỗ trợ bao gồm tác vụ đơn, tác vụ chuỗi và tác vụ có cấu trúc cây. Để đảm bảo lập kế hoạch tác vụ hiệu quả và chính xác bởi LLM, Mô hình của chúng tôi sử dụng thiết kế dựa trên prompt hướng phản hồi, bao gồm hướng dẫn dựa trên đặc tả, phân tích dựa trên minh họa và tối ưu hóa phân tích với phản hồi đầu ra tác vụ. Tối ưu hóa phân tích hướng phản hồi sẽ được trình bày chi tiết trong Phần 3.5.

--- TRANG 6 ---
Mẫu L ATEX Springer Nature 2021
6 Tiêu đề Bài báo
Ngoài ra, để hỗ trợ các yêu cầu của cuộc hội thoại đa lượt, chúng tôi kết hợp nhật ký trò chuyện vào prompt thông qua các hướng dẫn bổ sung. Cụ thể, để hỗ trợ lập kế hoạch tác vụ, lịch sử trò chuyện có thể được sử dụng như nhật ký trò chuyện để theo dõi các tài nguyên được người dùng đề cập và kết hợp chúng vào lập kế hoạch tác vụ tiếp theo. Thiết kế này cho phép mô hình của chúng tôi quản lý ngữ cảnh tốt hơn và giải quyết các tác vụ AI một cách chính xác hơn trong các cuộc đối thoại đa lượt.

3.3 Chiến lược Chọn Mô hình
Do tính phức tạp của các tác vụ AI, sau khi hoàn thành lập kế hoạch tác vụ, chúng tôi cần chọn các tổ hợp mô hình từ các mô hình ứng viên khác nhau có thể đáp ứng các yêu cầu ý định. Để giải quyết điều này, trước tiên chúng tôi giới thiệu một thư viện mô hình dựa trên thẻ mô hình. Cụ thể, trong thư viện mô hình, chúng tôi có các mô hình ứng viên khác nhau và mỗi mô hình được gán một thẻ mô hình tương ứng. Dưới giả định của một môi trường mạng ổn định, mỗi thẻ mô hình bao gồm tên của mô hình và các chỉ số hiệu suất mạng khác nhau, chẳng hạn như độ trễ và sử dụng tài nguyên.

Sau đó, trong quá trình chọn mô hình, chúng tôi sử dụng một cơ chế khớp mô hình để tạo ra nhiều tổ hợp mô hình phù hợp dựa trên các yêu cầu ý định. Cụ thể, chúng tôi thực hiện khớp theo cặp giữa các thẻ mô hình từ các thư viện mô hình khác nhau dựa trên các chỉ số hiệu suất được chỉ định trong các yêu cầu ý định để đáp ứng nhu cầu tổng thể. Phương pháp thẻ mô hình không chỉ giảm độ phức tạp của việc khớp mô hình mà còn cung cấp nền tảng cho động lực mạng tiềm năng trong tương lai.

3.4 Thực hiện Tác vụ
Một khi một mô hình cụ thể được gán cho một tác vụ được phân tích, bước tiếp theo là thực hiện tác vụ, bao gồm suy luận mô hình. Tại giai đoạn này, chúng tôi đề xuất một cơ sở dữ liệu dựa trên thẻ dữ liệu và một phần đầu vào-đầu ra thống nhất cho thư viện mô hình để tạo điều kiện cho đầu vào mô hình. Cụ thể, cơ sở dữ liệu chứa tất cả dữ liệu cần thiết và thẻ dữ liệu tương ứng của chúng. Thẻ dữ liệu bao gồm tên dữ liệu và các thuộc tính chính, và dữ liệu có thể được sử dụng đơn giản bằng cách sử dụng thẻ dữ liệu.

Sau khi chọn một mô hình cụ thể, mô hình trực tiếp sử dụng cơ sở dữ liệu thông qua thành phần đầu vào-đầu ra thống nhất của thư viện mô hình. Dữ liệu được nhập vào mô hình trong định dạng chuẩn hóa, và đầu ra cũng được chuẩn hóa. Ngoài ra, để đảm bảo thực hiện tuần tự các tác vụ, chúng tôi xem xét việc sử dụng re-prompting [15] để động thái chỉ định các phụ thuộc tác vụ và tài nguyên.

Hơn nữa, đối với các tác vụ con trong cấu trúc giống cây, chúng tôi thực hiện những tác vụ này song song khi chúng không có phụ thuộc tài nguyên giữa chúng, do đó nâng cao hơn nữa hiệu quả suy luận.

3.5 Đầu ra Cuối cùng và Phản hồi LLM
Sau khi hoàn thành tất cả các tác vụ, chúng tôi cần tạo ra kết quả cuối cùng và phản hồi LLM. Đối với đầu ra cuối cùng, chúng tôi đơn giản hiển thị kết quả của các tổ hợp mô hình đáp ứng các yêu cầu và hiệu suất thực hiện tương ứng của chúng

--- TRANG 7 ---
Mẫu L ATEX Springer Nature 2021
Tiêu đề Bài báo 7
. Để tối ưu hóa dịch thuật LLM và lập kế hoạch tác vụ chi tiết, chúng tôi tích hợp tất cả thông tin từ ba giai đoạn đầu (lập kế hoạch tác vụ, chọn mô hình và thực hiện tác vụ) thành một tóm tắt định dạng cho giai đoạn này. Tóm tắt này bao gồm danh sách tác vụ được lập kế hoạch, các mô hình được chọn để thực hiện tác vụ và kết quả suy luận từ những mô hình này. Những đầu ra tích hợp này được trình bày trong định dạng prompting có cấu trúc.

Sau đó, điểm số được gán cho kết quả của ba giai đoạn này, đặc biệt tập trung vào việc giải thích lý do cho bất kỳ lỗi nào. Cuối cùng, phản hồi này được cung cấp cho LLM để nâng cao hiệu suất của nó.

4 Kết luận
Để giải quyết các tác vụ AI phức tạp trong mạng truyền thông, Chúng tôi đề xuất Trí tuệ Nhân tạo Hệ thống (SAI) bằng cách tận dụng Mô hình Ngôn ngữ Lớn (LLM) và đầu vào dựa trên ý định định dạng JSON để kết nối thư viện mô hình và cơ sở dữ liệu tự thiết kế. Cụ thể, chúng tôi đầu tiên thiết kế một thành phần đa đầu vào, đồng thời tích hợp Mô hình Ngôn ngữ Lớn (LLM) và đầu vào dựa trên ý định định dạng JSON để đáp ứng các yêu cầu ý định đa dạng của các người dùng khác nhau. Ngoài ra, chúng tôi giới thiệu một mô-đun thư viện mô hình dựa trên thẻ mô hình sử dụng thẻ mô hình để khớp theo cặp giữa các mô-đun khác nhau cho việc tạo thành mô hình. Thẻ mô hình chứa tên của mô hình tương ứng và các chỉ số hiệu suất yêu cầu. Sau đó, khi nhận được yêu cầu mạng của người dùng, chúng tôi thực hiện từng tác vụ con cho nhiều tổ hợp mô hình đã chọn và cung cấp đầu ra dựa trên kết quả thực hiện và phản hồi LLM. Bằng cách tận dụng khả năng ngôn ngữ của LLM và các mô hình AI phong phú trong thư viện mô hình, SAI có thể hoàn thành nhiều tác vụ AI phức tạp trong mạng truyền thông, đạt được kết quả ấn tượng trong tối ưu hóa mạng, phân bổ tài nguyên và các tác vụ thách thức khác.

Tài liệu tham khảo
[1] Shen, Y., Song, K., Tan, X., Li, D., Lu, W., Zhuang, Y.: Hugginggpt:
Solving ai tasks with chatgpt and its friends in huggingface. arXiv preprint
arXiv:2303.17580 (2023)

[2] Hong, S., Zheng, X., Chen, J., Cheng, Y., Zhang, C., Wang, Z., Yau,
S.K.S., Lin, Z., Zhou, L., Ran, C., et al.: Metagpt: Meta programming
for multi-agent collaborative framework. arXiv preprint arXiv:2308.00352
(2023)

[3] Tang, Z., Wang, R., Chen, W., Wang, K., Liu, Y., Chen, T., Lin,
L.: Towards causalgpt: A multi-agent approach for faithful knowledge
reasoning via promoting causal consistency in llms. arXiv preprint
arXiv:2308.11914 (2023)

--- TRANG 8 ---
Mẫu L ATEX Springer Nature 2021
8 Tiêu đề Bài báo
[4] Leivadeas, A., Falkner, M.: A survey on intent based networking. IEEE
Communications Surveys & Tutorials (2022)

[5] Benzekki, K., El Fergougui, A., Elbelrhiti Elalaoui, A.: Software-defined
networking (sdn): a survey. Security and communication networks 9(18),
5803–5833 (2016)

[6] Kiran, M., Pouyoul, E., Mercian, A., Tierney, B., Guok, C., Monga,
I.: Enabling intent to configure scientific networks for high performance
demands. Future Generation Computer Systems 79, 205–214 (2018)

[7] Mahtout, H., Kiran, M., Mercian, A., Mohammed, B.: Using machine
learning for intent-based provisioning in high-speed science networks. In:
Proceedings of the 3rd International Workshop on Systems and Network
Telemetry and Analytics, pp. 27–30 (2020)

[8] Dzeparoska, K., Beigi-Mohammadi, N., Tizghadam, A., Leon-Garcia, A.:
Towards a self-driving management system for the automated realization
of intents. IEEE Access 9, 159882–159907 (2021)

[9] Mnih, V., Kavukcuoglu, K., Silver, D., Rusu, A.A., Veness, J., Belle-
mare, M.G., Graves, A., Riedmiller, M., Fidjeland, A.K., Ostrovski, G.,
et al. : Human-level control through deep reinforcement learning. nature
518(7540), 529–533 (2015)

[10] Schulman, J., Wolski, F., Dhariwal, P., Radford, A., Klimov, O.: Proximal
policy optimization algorithms. arXiv preprint arXiv:1707.06347 (2017)

[11] Haarnoja, T., Zhou, A., Abbeel, P., Levine, S.: Soft actor-critic: Off-policy
maximum entropy deep reinforcement learning with a stochastic actor.
In: International Conference on Machine Learning, pp. 1861–1870 (2018).
PMLR

[12] Zhang, S., Gong, C., Wu, L., Liu, X., Zhou, M.: Automl-gpt: Automatic
machine learning with gpt. arXiv preprint arXiv:2305.02499 (2023)

[13] Rawte, V., Sheth, A., Das, A.: A survey of hallucination in large
foundation models. arXiv preprint arXiv:2309.05922 (2023)

[14] Jacobs, A.S., Pfitscher, R.J., Ribeiro, R.H., Ferreira, R.A., Granville,
L.Z., Willinger, W., Rao, S.G.: Hey, lumi! using natural language for
{intent-based }network management. In: 2021 USENIX Annual Technical
Conference (USENIX ATC 21), pp. 625–639 (2021)

[15] Raman, S.S., Cohen, V., Rosen, E., Idrees, I., Paulius, D., Tellex, S.:
Planning with large language models via corrective re-prompting. arXiv
preprint arXiv:2211.09935 (2022)

# 2306.16913.pdf
# Đã chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/automl-nas/2306.16913.pdf
# Kích thước tệp: 932737 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
AutoML trong Các Ứng dụng Bị Ràng buộc Nghiêm ngặt
Felix Neutatz ·Marius Lindauer ·Ziawasch Abedjan
Tóm tắt Tối ưu hóa một pipeline machine learning cho một nhiệm vụ cụ thể đòi hỏi cấu hình cẩn thận các siêu tham số khác nhau, thường được hỗ trợ bởi một hệ thống AutoML tối ưu hóa các siêu tham số cho tập dữ liệu huấn luyện đã cho. Tuy nhiên, tùy thuộc vào cấu hình meta bậc hai của chính hệ thống AutoML, hiệu suất của quá trình AutoML có thể thay đổi đáng kể. Các hệ thống AutoML hiện tại không thể tự động thích ứng cấu hình của chính chúng với một trường hợp sử dụng cụ thể. Hơn nữa, chúng không thể biên dịch các ràng buộc ứng dụng do người dùng định nghĩa về tính hiệu quả và hiệu suất của pipeline và việc tạo ra nó. Trong bài báo này, chúng tôi đề xuất Caml, sử dụng meta-learning để tự động thích ứng các tham số AutoML của chính nó, chẳng hạn như chiến lược tìm kiếm, chiến lược xác thực và không gian tìm kiếm, cho một nhiệm vụ cụ thể. Chiến lược AutoML động của Caml tính đến các ràng buộc do người dùng định nghĩa và thu được các pipeline thỏa mãn ràng buộc với hiệu suất dự đoán cao.

1 Giới thiệu
Gần đây, đã có nghiên cứu chuyên sâu về machine learning tự động (AutoML) để tạo điều kiện cho việc thiết kế các pipeline machine learning (ML) [18,5,26,55, 29,59,54,4,47,24,61,53]. Các công trình hiện có bao gồm tối ưu hóa siêu tham số, tìm kiếm kiến trúc mạng neural và

Felix Neutatz
TU Berlin
E-mail: f.neutatz@tu-berlin.de
Marius Lindauer
Leibniz Universit¨ at Hannover
E-mail: m.lindauer@ai.uni-hannover.de
Ziawasch Abedjan
Leibniz Universit¨ at Hannover
E-mail: abedjan@dbs.uni-hannover.de

việc tạo ra các pipeline ML từ đầu đến cuối, bao gồm tiền xử lý dữ liệu, kỹ thuật đặc trưng, lựa chọn mô hình và xử lý sau.

1.1 AutoML với Ràng buộc
Trên thực tế, AutoML có thể chịu hai loại ràng buộc: ràng buộc ứng dụng ML và ràng buộc Tìm kiếm. Ràng buộc ứng dụng ML áp đặt các hạn chế, chẳng hạn như giới hạn về thời gian huấn luyện/suy luận và kích thước pipeline ML, hoặc các tiêu chí chất lượng bổ sung, chẳng hạn như tính mạnh mẽ đối nghịch hoặc quyền riêng tư vi phân, trên pipeline ML cuối cùng. Các ràng buộc ứng dụng ML về tiêu thụ tài nguyên đặc biệt phù hợp trong các hệ thống làm việc với dữ liệu động và dựa vào thời gian phản hồi nhanh [52,36].

Ràng buộc tìm kiếm áp đặt các hạn chế trên chính quá trình tìm kiếm AutoML, chẳng hạn như giới hạn thời gian tìm kiếm, sử dụng bộ nhớ chính hoặc tính song song.

Tùy thuộc vào bối cảnh thực tế và các ràng buộc chi phối của nó, người dùng phải cấu hình hệ thống AutoML khác nhau để đạt được kết quả tối ưu trong ngân sách thời gian tìm kiếm hạn chế. Với các ứng dụng mới nổi trong lĩnh vực edge computing và phân tích thời gian thực, cần xem xét thêm các ràng buộc khác.

Lái xe tự động dựa vào phân tích video thời gian thực [13] và để theo kịp tốc độ khung hình đủ cao, mô hình phải tuân theo các ràng buộc thời gian suy luận chặt chẽ. Khi các mô hình ML trở nên thành công, chúng cũng đã thu hút sự chú ý trên các thiết bị nhỏ hơn, chẳng hạn như điện thoại thông minh, đòi hỏi chúng phải giảm dấu chân bộ nhớ và dự đoán nhanh. Đối với các trường hợp sử dụng streaming, có thể quan trọng phải liên tục huấn luyện lại để thích ứng với sự dịch chuyển khái niệm theo thời gian [11]. Đối với các môi trường thay đổi nhanh, chẳng hạn như phát hiện gian lận cho các giao dịch tần số cao, các mô hình chịu các ràng buộc thời gian huấn luyện khắt khe. Hơn nữa, streaming ML đòi hỏi arXiv:2306.16913v2 [cs.LG] 16 Oct 2023

--- TRANG 2 ---
2 Felix Neutatz et al.
các ràng buộc về độ trễ millisecond và thông lượng cao [42,21]. Cũng có những lo ngại về các tiêu chí chất lượng dựa trên dân số. Ví dụ, Schelter et al. [49] đã chỉ ra rằng điền giá trị trung bình gây ra thiên vị và nên được loại bỏ khỏi không gian tìm kiếm siêu tham số ML nếu ứng dụng chịu các ràng buộc công bằng.

Các hệ thống AutoML có một số tham số AutoML, chẳng hạn như những tham số định nghĩa không gian tìm kiếm, chiến lược tìm kiếm, ví dụ, các biến thể khác nhau của tối ưu hóa Bayesian và thuật toán tiến hóa, chiến lược xác thực, ví dụ, hold-out và cross-validation, và chiến lược lấy mẫu, ảnh hưởng mạnh mẽ đến quá trình tìm kiếm. Chúng tôi gọi một khởi tạo tùy ý của các tham số này là một cấu hình AutoML. Cấu hình AutoML mặc định là việc khởi tạo mỗi tham số AutoML với giá trị mặc định của nó và thường cho phép toàn bộ không gian tìm kiếm cho các siêu tham số ML.

Nói chung, không có một cấu hình AutoML duy nhất nào luôn tạo ra một mô hình với hiệu suất dự đoán cao trên tất cả các loại tập dữ liệu và đặc biệt chịu bất kỳ ràng buộc nào đã nêu ở trên. Thông thường, cần có kiến thức chuyên môn để cấu hình và thích ứng một hệ thống AutoML cho các thiết lập như vậy.

1.2 Thích ứng Cấu hình AutoML
Chúng tôi hình dung một hệ thống AutoML tự động thích ứng với một nhiệm vụ ML do người dùng chỉ định, tức là không chỉ với tập dữ liệu mà còn tính đến các ràng buộc ứng dụng ML và ràng buộc tìm kiếm do người dùng định nghĩa, để đạt được hiệu suất anytime tổng thể tốt nhất. Chúng tôi gọi mô hình mới này là AutoML dựa trên ràng buộc, trong đó các nhà khoa học dữ liệu và chuyên gia lĩnh vực biết trước các ràng buộc của các ứng dụng ML, ví dụ như hạn chế tài nguyên cho các thiết bị IoT hoặc hạn chế pháp lý, chỉ cần chỉ định các ràng buộc nhưng không cần phải điều chỉnh thủ công không gian thiết kế pipeline. Chúng tôi lưu ý rằng AutoML phục vụ hai nhóm người dùng: những chuyên gia không thuộc lĩnh vực tìm kiếm các giải pháp ít hoặc không cần mã, và các chuyên gia ML tìm kiếm hỗ trợ trong công việc hàng ngày của họ. Chúng tôi hướng đến nhóm người dùng sau với kiến thức về các ràng buộc cụ thể của nhiệm vụ.

Các hệ thống AutoML tiên tiến [17,14,43] không hỗ trợ các ràng buộc ứng dụng ML ngay từ đầu, và chúng không thích ứng quá trình tìm kiếm với các ràng buộc tìm kiếm do người dùng chỉ định. Cả hai sự thích ứng thực tế đều không tầm thường vì các hệ thống AutoML có nhiều tham số riêng của chúng, chẳng hạn như những tham số định nghĩa không gian tìm kiếm, chiến lược tìm kiếm và chiến lược xác thực. Ví dụ, nếu người dùng chỉ định thời gian tìm kiếm là năm phút, hệ thống AutoML nổi tiếng Auto-Sklearn [18, 17] sẽ xem xét cùng một không gian tìm kiếm siêu tham số ML như khi nó có cả tuần, mặc dù chỉ một phần rất nhỏ của không gian siêu tham số ML có thể được bao phủ. Về mặt lý thuyết, người dùng có thể sửa đổi các tham số hệ thống AutoML để giảm không gian tìm kiếm. Tuy nhiên, ngay cả đối với các chuyên gia, cũng khó khăn để ước tính phần nào của không gian siêu tham số ML cần xem xét hoặc kích thước mẫu nào đủ cho một nhiệm vụ nhất định. Tương tự như độ nhạy cảm của siêu tham số ML đối với tập dữ liệu hiện có, hiệu suất anytime của AutoML phụ thuộc mạnh vào các tham số riêng của nó và thiết lập tối ưu của chúng phụ thuộc vào nhiệm vụ ML. Một cách tiếp cận trực quan sẽ là đóng khung vấn đề như một nhiệm vụ tối ưu hóa đa mục tiêu để khám phá các pipeline ML trên tất cả các chiều ràng buộc. Tuy nhiên, ngay cả khi chúng ta xem xét đó là một vấn đề tối ưu hóa đa mục tiêu, vẫn không rõ cách chọn các tham số AutoML để tìm kiếm hiệu quả.

Chúng tôi đề xuất một giải pháp hiệu quả cho AutoML dựa trên ràng buộc bằng cách tận dụng meta-learning, mà cho đến nay chỉ được áp dụng cho một số vấn đề con trong thiết lập của chúng tôi. Ví dụ, Auto-Sklearn2 [18,17] tận dụng meta-learning để khởi động ấm tối ưu hóa Bayesian (BO). Cụ thể, nó tìm kiếm tập hợp tốt nhất của các siêu tham số ML trên tất cả các tập dữ liệu trong một kho lưu trữ. Đối với một tập dữ liệu mới, nó so sánh tập dữ liệu với tất cả các tập dữ liệu trong kho lưu trữ và áp dụng BO với một danh mục đầu tư ban đầu của các cấu hình siêu tham số ML của tập dữ liệu tương tự nhất để tăng tốc quá trình tìm kiếm. Ngoài ra, nó học được chiến lược xác thực và danh mục đầu tư ban đầu nào có lợi cho tập dữ liệu nào. Tuy nhiên, cách tiếp cận meta-learning của Auto-Sklearn2 không thể hỗ trợ các ràng buộc vì người ta sẽ cần phải huấn luyện độc lập meta-learning cho mỗi tập hợp cài đặt ràng buộc có thể, điều này là không khả thi. Hơn nữa, cách tiếp cận của họ chỉ hỗ trợ dự đoán các quyết định chiến lược rời rạc bằng mô hình meta theo cặp, tức là một meta-model dự đoán cái tốt hơn trong hai chiến lược AutoML có thể. Cách tiếp cận này không thể xử lý các tham số AutoML liên tục, và ngay cả việc bao phủ tất cả các kết hợp có thể của chiến lược lấy mẫu, xác thực và chiến lược không gian tìm kiếm thường là không khả thi.

Một cách tiếp cận meta-learning khác là học một mô hình surrogate học offline liệu một pipeline ML nhất định có thể thỏa mãn các ràng buộc được chỉ định hay không. Tuy nhiên, cách tiếp cận này không thích ứng các tham số AutoML [37]. Ví dụ, không thể thích ứng chiến lược xác thực dựa trên các ràng buộc được chỉ định.

Để khắc phục các hạn chế đã nêu ở trên và cho phép tất cả các mức độ tự do trong AutoML dựa trên ràng buộc, chúng tôi đã giải quyết ba thách thức chính:

1. Không gian meta-learning khổng lồ. Không gian kết hợp của các tham số AutoML, ràng buộc và tập dữ liệu rất lớn. Chúng ta cần vẽ các phiên bản meta-training từ không gian khổng lồ này để cho phép meta-training. Để cắt tỉa không gian siêu tham số ML, chúng ta phải

--- TRANG 3 ---
AutoML trong Các Ứng dụng Bị Ràng buộc Nghiêm ngặt 3
xem xét sự đánh đổi giữa thời gian chạy tìm kiếm và hiệu suất dự đoán. Nếu chúng ta cắt tỉa quá nhiều không gian siêu tham số ML, việc tối ưu hóa có thể không tìm ra các pipeline ML với hiệu suất dự đoán cao. Nếu chúng ta cắt tỉa quá ít, quá trình tìm kiếm có thể không hiệu quả. Để ước tính cấu hình AutoML nào sẽ thành công, điều quan trọng là phải xem xét tập dữ liệu và các ràng buộc do người dùng chỉ định.

2. Nhãn meta-training. Để dự đoán một cấu hình AutoML cho một nhiệm vụ đã cho, một meta-model phải được huấn luyện trên các nhiệm vụ tương tự. Việc chọn các ví dụ meta-training phù hợp và một mục tiêu dự đoán thích hợp là một vấn đề chúng tôi dự định giải quyết.

3. AutoML không xác định. AutoML là một quá trình không xác định và ngẫu nhiên. Trên nhiều lần chạy, cùng một cấu hình AutoML có thể dẫn đến các kết quả khác nhau đáng kể vì cả trình tối ưu hóa AutoML (ví dụ: tối ưu hóa Bayesian) và việc huấn luyện mô hình ML đều ngẫu nhiên. Vì vậy, nếu chúng ta naively huấn luyện một meta-model trên tín hiệu nhiễu như vậy, meta-model có thể không chính xác.

1.3 Đóng góp
Để giải quyết những thách thức này, chúng tôi đề xuất một hệ thống AutoML dựa trên ràng buộc mới, Caml, cấu hình động các tham số AutoML của nó bằng cách tính đến nhiệm vụ ML do người dùng chỉ định (tức là, tập dữ liệu và ràng buộc). Học từ các lần chạy AutoML trước đó (tức là, tập dữ liệu, ràng buộc, cấu hình AutoML), Caml tạo ra các cấu hình AutoML và ước tính cái nào trong số chúng đầy hứa hẹn cho một nhiệm vụ ML mới. Để làm điều này, chúng tôi đóng góp như sau:

1. Chúng tôi đề xuất lấy mẫu xen kẽ như một chiến lược tạo dữ liệu huấn luyện - một sự kết hợp của active learning, tối ưu hóa Bayesian và meta-learning. Nó được song song hóa và khám phá hiệu quả không gian tìm kiếm khổng lồ của các tập dữ liệu, cấu hình AutoML và ràng buộc để học một meta-model ước tính sự thành công của các cấu hình AutoML và tăng tốc quá trình tìm kiếm.

2. Để ngay lập tức trích xuất các cấu hình AutoML đầy hứa hẹn nhất từ meta-model tại thời gian chạy, chúng tôi đề xuất khai thác cấu hình AutoML offline cung cấp cho Caml một nhóm lớn các cấu hình AutoML đầy hứa hẹn. Vì meta-model có thể xếp hạng 100k cấu hình trong vòng chưa đến một giây, nhóm này cho phép truy xuất cấu hình AutoML nhanh chóng.

3. Để đảm bảo khả năng thích ứng cao cho một tập hợp rộng lớn các thiết lập ràng buộc, chúng tôi đã triển khai Caml theo cách cho phép người dùng cấu hình liệu nó có tối ưu hóa bất kỳ siêu tham số ML nào hay không. Nó cũng hỗ trợ các ràng buộc ứng dụng ML dựa trên các số liệu, chẳng hạn như thời gian huấn luyện/suy luận, kích thước pipeline ML và cơ hội bình đẳng [22] - một số liệu công bằng.

4. Chúng tôi báo cáo các thí nghiệm mở rộng với Caml và so sánh nó với các hệ thống AutoML tiên tiến. Chúng tôi cung cấp triển khai, tập dữ liệu và framework đánh giá của chúng tôi trong kho lưu trữ [39].

Các Phát hiện Chính. Nghiên cứu của chúng tôi cho phép chúng tôi rút ra những kết luận sau:

1. Caml không chỉ vượt trội hơn cấu hình AutoML mặc định mà còn vượt trội hơn các hệ thống tiên tiến, chẳng hạn như TPOT [43], AutoGluon [14] và Auto-Sklearn2 [17], trong các thiết lập bị ràng buộc.

2. Caml vượt trội hơn các giải pháp AutoML cụ thể cho ràng buộc được thiết kế thủ công, chẳng hạn như Auto-Sklearn 2 [17]. Việc điều chỉnh thủ công cấu hình hệ thống AutoML cho các ràng buộc đa dạng hoặc thậm chí kết hợp của nhiều ràng buộc gần như không thể do các tác động phụ không thể lường trước. Do đó, các giải pháp như Caml là cần thiết.

3. Caml là bước đầu tiên hướng tới tầm nhìn của chúng tôi về AutoML dựa trên ràng buộc. Bằng cách này, chúng ta có thể bao phủ nhiều ràng buộc đa dạng và thêm/bớt những ràng buộc bổ sung mà không cần chuyên môn về hệ thống AutoML.

2 Vấn đề Ba Bước
Vấn đề ba bước đại diện cho việc tìm kiếm thiết lập tối ưu của ba tham số như được mô tả trong Hình 1: các tham số AutoML, siêu tham số ML và tham số mô hình.

Trước khi chúng tôi chính thức hóa vấn đề AutoML dựa trên ràng buộc, chúng tôi định nghĩa chính thức vấn đề tìm các tham số mô hình tối ưu cho một mô hình machine learning có giám sát nhất định và vấn đề AutoML của việc tìm thuật toán và siêu tham số ML tối ưu, ví dụ, chọn mã hóa dữ liệu, bộ tiền xử lý đặc trưng và mô hình phân loại, và tất cả các siêu tham số tương ứng của chúng.

2.1 Vấn đề ML có giám sát
Vấn đề ML có giám sát là tìm các tham số θ cho một mô hình dự đoán f bằng cách giảm thiểu tổn thất L của việc ánh xạ f:xi7→ˆyi cho một tập dữ liệu huấn luyện đã cho Dtrain ={(x0, y0), ...,(xn, yn)}.

θ∗∈arg min
θ∈ΘX
(xi,yi)∈DtrainLtrain (yi, f(xi;θ)). (1)

--- TRANG 4 ---
4 Felix Neutatz et al.

Hình 1: Ví dụ: Thích ứng các Tham số AutoML cho AutoML dựa trên ràng buộc.

Trên thực tế, vấn đề thường phức tạp hơn vì tổn thất có thể được chính quy hóa để đạt được hiệu suất tổng quát hóa tốt hơn, và các trình tối ưu hóa ngẫu nhiên có thể dẫn đến các tham số mô hình khác nhau được trả về bởi quá trình học.

2.2 Vấn đề AutoML
Vấn đề kết hợp của lựa chọn thuật toán và tối ưu hóa siêu tham số của AutoML [56] là xác định pipeline dự đoán a∈A và các siêu tham số tương ứng λ∈Λ, tạo ra một mô hình f(aλ;Dtrain )(·;ˆθ) với một số tham số mô hình được xấp xỉ ˆθ, đạt được tổn thất thấp nhất trên tập xác thực Dvalid. Chính thức:

arg min
a∈A,λ∈ΛX
(xi,yi)∈DvalLval(yi, f(aλ;Dtrain )(xi;ˆθ)). (2)

Chúng tôi lưu ý rằng tổn thất huấn luyện Ltrain (ví dụ: cross-entropy) không nhất thiết phải giống với tổn thất xác thực Lval (ví dụ: balanced accuracy). Vì việc huấn luyện mô hình ML đã có thể mất một thời gian (ví dụ: huấn luyện một DNN), AutoML phải rất hiệu quả trong việc đánh giá các cấu hình khác nhau từ A×Λ.

2.3 Vấn đề AutoML Dựa trên Ràng buộc
Vấn đề mà chúng tôi giải quyết trong bài báo này là tìm các tham số ω của một hệ thống AutoML đã cho để hiệu quả tìm ra một pipeline ML tuân thủ tất cả các ràng buộc do người dùng chỉ định và đạt được hiệu suất dự đoán cao nhất cho một nhiệm vụ ML được chỉ định. Chính thức,

max
ω∈Ωm(ω) s.t.∀ci≤ti, i∈[0, n] (3)

trong đó ω là một vector đại diện cho cấu hình riêng của hệ thống AutoML; m(ω) là tổn thất xác thực trung bình của mô hình ML cuối cùng ˆf được trả về bởi hệ thống AutoML; ci là các ràng buộc, và ti là các ngưỡng ràng buộc do người dùng chỉ định, tức là thời gian tìm kiếm ≤5min hoặc kích thước pipeline ML ≤1 MB. Đối với các ràng buộc, chúng tôi phân biệt giữa ràng buộc tìm kiếm và ràng buộc ứng dụng ML. Ràng buộc tìm kiếm liên quan đến quá trình tìm kiếm AutoML, chẳng hạn như thời gian tìm kiếm, bộ nhớ chính tìm kiếm và thời gian đánh giá, và ràng buộc ứng dụng ML liên quan đến pipeline ML cuối cùng, chẳng hạn như thời gian huấn luyện/suy luận và công bằng.

Mặc dù các trình tối ưu hóa với việc học ngầm những ràng buộc chưa biết này có thể được sử dụng, chúng tôi giả thuyết rằng việc điều chỉnh zero-shot các tham số riêng của hệ thống AutoML (bao gồm cả không gian cấu hình A×Λ) sẽ giải quyết vấn đề này một cách hiệu quả.

Việc chọn cấu hình AutoML dựa trên một tập dữ liệu và ràng buộc được chỉ định là thách thức vì cả không gian giải pháp (các cấu hình AutoML có thể) cũng như không gian nhiệm vụ (các tập dữ liệu và ngưỡng ràng buộc có thể) đều rất lớn. Bất kỳ thay đổi nào trong bất kỳ thành phần nào trong số này có thể ảnh hưởng đến hiệu suất dự đoán cuối cùng. Tính không xác định của cả ML và AutoML càng làm trầm trọng thêm những thách thức này.

Hình 1 minh họa cách AutoML dựa trên ràng buộc ảnh hưởng đến các cấu hình. Thay vì sử dụng cấu hình AutoML mặc định, hệ thống của chúng tôi tự động

--- TRANG 5 ---
AutoML trong Các Ứng dụng Bị Ràng buộc Nghiêm ngặt 5

Hình 2: Kiến trúc Hệ thống của Caml.

thích ứng các tham số AutoML của nó với nhiệm vụ ML do người dùng chỉ định, được định nghĩa bởi tập dữ liệu và các ràng buộc hiện có. Trong ví dụ này, một số phương pháp phân loại bị loại trừ vì chúng dự kiến sẽ không đáp ứng ràng buộc cụ thể (được đánh dấu màu đỏ trong Cấu hình AutoML Động). Sau đó, hệ thống AutoML được cấu hình động tìm kiếm các pipeline ML dựa trên không gian tìm kiếm siêu tham số ML còn lại. Cuối cùng, các tham số mô hình được khớp với tập dữ liệu, ví dụ: SVM điều chỉnh các trọng số w. Các siêu tham số bị vô hiệu hóa trước đó hoặc vẫn bị vô hiệu hóa nếu không liên quan hoặc được đặt về mặc định nếu cần thiết. Ví dụ, cấu hình AutoML động đã loại trừ tham số chính quy hóa của mô hình SVM. Tuy nhiên, vì pipeline cuối cùng sử dụng SVM, nó sẽ đơn giản là sử dụng tham số mặc định ở đây.

3 AutoML Dựa trên Ràng buộc
Để meta-learn các tham số riêng ω của AutoML, chúng tôi đề xuất Caml, được minh họa trong Hình 2. Với một tập dữ liệu do người dùng chỉ định, ràng buộc tìm kiếm và ràng buộc ứng dụng ML, Caml quyết định cấu hình AutoML nào - cụ thể là không gian siêu tham số ML nào, chiến lược tìm kiếm và chiến lược xác thực - một hệ thống AutoML nhất định nên tìm kiếm để tạo ra một pipeline ML với hiệu suất dự đoán cao. Quy trình làm việc bao gồm một giai đoạn offline và một giai đoạn online.

Giai đoạn offline bao gồm ba bước chính: tạo dữ liệu huấn luyện, huấn luyện meta-model và khai thác cấu hình AutoML. Làm đầu vào, kỹ sư hệ thống AutoML phải cung cấp không gian AutoML và không gian ràng buộc thông qua các bộ tạo. Trong bài báo này, chúng tôi đánh giá các ràng buộc thời gian huấn luyện/suy luận, kích thước pipeline và cơ hội bình đẳng. Kỹ sư có thể mở rộng tập ràng buộc này tùy thuộc vào nhu cầu của ứng dụng ML. Hơn nữa, Caml yêu cầu một kho lưu trữ tập dữ liệu. Meta-learning hoạt động tốt hơn nếu các tập dữ liệu do người dùng cung cấp tương tự với các tập dữ liệu có mặt trong kho lưu trữ. Vì vậy có hai cách tiếp cận có thể để tạo kho lưu trữ. Trong các tổ chức, người ta có thể sử dụng lịch sử riêng của các tập dữ liệu đã được sử dụng trong các pipeline khoa học dữ liệu trước đó. Ngoài ra, người ta nên tạo kho lưu trữ với các tập dữ liệu khác nhau về các chiều, chẳng hạn như số lượng phiên bản, đặc trưng, lớp, giá trị bị thiếu và loại đặc trưng. Đã có các kho lưu trữ công cộng ở một mức độ nào đó đáp ứng những yêu cầu đa dạng này. Theo các nghiên cứu trước đó, chúng tôi đã thu thập các tập dữ liệu cho kho lưu trữ benchmark của chúng tôi từ các nền tảng như OpenML [58], UCI ML Repository [27], Kaggle [50] và HuggingFace [10]. Caml tận dụng một chiến lược xen kẽ ❶ của lấy mẫu ngẫu nhiên và bất định để vừa khám phá vừa khai thác không gian khổng lồ của các cấu hình AutoML, tập dữ liệu và ràng buộc. Dựa trên dữ liệu huấn luyện kết quả ❷, Caml học và tối ưu hóa meta-model bằng cross-validation trong khi đảm bảo tổng quát hóa cross-dataset ❸.

--- TRANG 6 ---
6 Felix Neutatz et al.

Lý tưởng nhất, meta-training sẽ xem xét cấu hình AutoML tốt nhất cho mỗi nhiệm vụ ML. Tuy nhiên, việc xác định cấu hình tốt nhất cho một nhiệm vụ ML gần như không thể vì nó sẽ yêu cầu kiểm tra không gian cấu hình khổng lồ cho mỗi nhiệm vụ ML. Vì mục tiêu này không khả thi về mặt tính toán, chúng tôi nới lỏng công thức vấn đề ban đầu từ Phần 2 như sau:

max
ω∈ΩP(m(ω)> m(ωdefault )) s.t. ∀ci≤ti, i∈[0, n] (4)

Để đảm bảo một cách tiếp cận meta-learning mạnh mẽ, trực giác của chúng tôi là xác định cấu hình AutoML có khả năng hiệu quả hơn cấu hình AutoML mặc định. Do đó, chúng tôi huấn luyện một mô hình meta-learning dự đoán liệu một cấu hình khác với cấu hình AutoML mặc định có dẫn đến hiệu suất tốt hơn cho một nhiệm vụ đã cho hay không.

Trong bước cuối cùng của giai đoạn offline, Caml tận dụng meta-model ❹ để tìm kiếm cấu hình AutoML tối ưu ước tính cho một tập dữ liệu ngẫu nhiên và ràng buộc ngẫu nhiên ❺. Caml tận dụng BO để giải quyết vấn đề tìm kiếm này. Kết quả của bước này là một nhóm lớn các cấu hình AutoML đầy hứa hẹn ❻ cho một tập hợp đa dạng các trường hợp sử dụng.

Trong giai đoạn online, người dùng chỉ định tập dữ liệu và các ràng buộc ❶. Để chuẩn bị chúng cho việc huấn luyện meta-model, chúng tôi mã hóa cả tập dữ liệu và các ràng buộc trong biểu diễn meta-feature (xem Phần 3.1.4) và kết hợp chúng với các cấu hình AutoML được khai thác ❷. Sau đó, Caml tận dụng meta-model để dự đoán cấu hình AutoML được khai thác nào phù hợp nhất với tập dữ liệu và ràng buộc do người dùng chỉ định ❸. Sau đó, Caml trang bị cho hệ thống AutoML cấu hình AutoML kết quả ❹ và thực thi nó ❺ với các ràng buộc tìm kiếm được chỉ định. Cuối cùng, hệ thống AutoML trả về một pipeline ML thỏa mãn tất cả các ràng buộc ứng dụng ML ❻.

3.1 Dữ liệu Huấn luyện cho Meta-learning
Chúng tôi đề xuất active meta-learning - một cách tiếp cận để áp dụng hiệu quả meta-learning trong một kịch bản mà dữ liệu huấn luyện tương ứng, cả phiên bản và nhãn, không tồn tại và cần được tạo ra; Một phiên bản meta-training bao gồm sự kết hợp của một tập dữ liệu, một cấu hình AutoML và các ràng buộc. Nhãn của một phiên bản huấn luyện như vậy nên chỉ định mức độ phù hợp hoặc thành công của các tham số AutoML được tạo. Meta-model nên học từ một tập hợp các phiên bản huấn luyện như vậy liệu một cấu hình được tạo có dẫn đến hiệu suất tốt hơn cấu hình AutoML mặc định hay không.

Để huấn luyện một meta-model như vậy, chúng ta phải trả lời các câu hỏi sau: Làm thế nào để chúng ta tạo ra các nhãn? Làm thế nào chúng ta có thể thu thập dữ liệu huấn luyện một cách hiệu quả? Làm thế nào chúng ta mã hóa một lần chạy AutoML thành meta-features?

3.1.1 Nhãn Meta-Target
Để học được cấu hình AutoML nào đầy hứa hẹn, chúng ta cần một tập dữ liệu meta-training với các nhãn dự đoán cho các lần chạy AutoML trước đó. Chúng ta cần định nghĩa thành công có nghĩa là gì đối với một lần chạy AutoML đã cho. Chúng ta không thể đơn giản chọn hiệu suất dự đoán làm nhãn cho một lần chạy AutoML, vì hiệu suất tồn tại trên các thang đo khác nhau tùy thuộc vào nhiệm vụ ML hiện có. Một số nhiệm vụ ML khó giải quyết hơn vì một số ràng buộc rất hạn chế. Ví dụ, ràng buộc "kích thước pipeline ML ≤5KB" hạn chế hơn "kích thước pipeline ML ≤500MB", dẫn đến các giá trị hiệu suất dự đoán có thể đạt được tối ưu khác nhau. Do đó, chúng ta phải tìm một số liệu xem xét toàn bộ bối cảnh của một nhiệm vụ ML làm điểm neo. Để cung cấp điểm neo như vậy, chúng tôi chạy hệ thống AutoML với cấu hình mặc định làm baseline trong quá trình meta-learning. Cấu hình AutoML mặc định sử dụng không gian tìm kiếm siêu tham số ML đầy đủ và các tham số AutoML mặc định, chẳng hạn như xác thực hold-out với 33% dữ liệu xác thực. Bây giờ, nhiệm vụ học của chúng tôi là dự đoán liệu một cấu hình AutoML được tạo có mang lại hiệu suất dự đoán cao hơn cấu hình AutoML mặc định cho cùng một nhiệm vụ hay không. Số liệu proxy này độc lập với các thang đo hiệu suất và độ khó của ràng buộc. Để tính đến hành vi không xác định của AutoML, chúng tôi chạy hệ thống AutoML nhiều lần (mười lần trong các thí nghiệm của chúng tôi) cho cả cấu hình được tạo và cấu hình mặc định. Sau đó, chúng tôi thu được phần các trường hợp mà cấu hình AutoML mặc định bị vượt trội. Chúng tôi lưu ý rằng điều này có thể không dẫn đến optimum như được định nghĩa trong Eq. 3, nhưng đảm bảo một lựa chọn mạnh mẽ của một cấu hình AutoML, tránh suy giảm hiệu suất do tính không xác định. Để tránh tính toán không cần thiết cho các thiết lập không thể thỏa mãn trong meta-training, trước tiên chúng tôi đánh giá cấu hình AutoML đã cho. Nếu tất cả mười lần chạy không tạo ra pipeline ML nào thỏa mãn các ràng buộc được chỉ định, chúng tôi không cần đánh giá cấu hình AutoML mặc định nữa.

Meta-model cho active learning là một mô hình hồi quy random forest dự đoán phần các lần chạy mà cấu hình AutoML đã cho vượt trội hơn cấu hình mặc định. Như đã chỉ ra trước đây [56], random forest là một mô hình phù hợp để xử lý các không gian siêu tham số lớn phức tạp và có cấu trúc, xem Phần 3.1.4.

Thuật toán 1 Tạo dữ liệu huấn luyện
Input: Hệ thống AutoML A, Tập dữ liệu D, Không gian Ràng buộc C,
Không gian tham số AutoML Ω, Lần lặp ngẫu nhiên K,
Thời gian lấy mẫu t.
Output: X, Y, groups.
1:X← ∅
2:Y← ∅
3: groups ← ∅
4:fori= 0to Kdo ▷cold start
5: d, c, ω ←random sample( D, C, Ω )
6: X←X∪ {encode( d, c, ω )}
7: Y←Y∪ {A(d, c, ω )} ▷Chạy Caml
8:while tnot elapsed do ▷lấy mẫu xen kẽ
9: ifrand ()≥0.5then
10: meta model.fit( X, Y)
11: d, c, ω ← arg max
d∈D,c∈C,ω∈Ωσ(meta model.predict(
encode( d, c, ω )))
12: else
13: d, c, ω ←random sample( D, C, Ω )
14: X←X∪ {encode( d, c, ω )}
15: Y←Y∪ {A(d, c, ω )} ▷Chạy Caml
16: groups ←groups ∪d
17:return X, Y, groups.

3.1.2 Lấy mẫu Xen kẽ
Để khám phá hiệu quả không gian của các cấu hình AutoML, tập dữ liệu và ràng buộc, chúng tôi tận dụng active learning, cụ thể là uncertainty sampling [51]. Tương tự như cách tiếp cận được trình bày bởi Yu et al. [62] giảm nỗ lực gán nhãn cho các nhiệm vụ phân loại ML tiêu chuẩn, hệ thống của chúng tôi chọn và tạo ra những phiên bản meta-training mà meta-model không chắc chắn nhất. Tuy nhiên, nếu chúng ta chỉ lấy mẫu các nhiệm vụ ML xung quanh ranh giới quyết định về việc liệu một cấu hình AutoML đã cho có vượt trội hơn cấu hình mặc định hay không, chúng ta có thể bỏ lỡ các cấu hình vượt trội hơn cấu hình mặc định với biên độ lớn. Trong khi chúng ta khai thác không gian với uncertainty sampling, chúng ta cũng khám phá nó với lấy mẫu ngẫu nhiên theo cách xen kẽ.

Thuật toán 1 mô tả quá trình tạo dữ liệu huấn luyện. Lấy mẫu yêu cầu một kho lưu trữ tập dữ liệu, một hệ thống AutoML, một không gian ràng buộc và một không gian các tham số AutoML. Để bắt đầu active learning, chúng ta cần các phiên bản huấn luyện ban đầu tạo ra meta-model đầu tiên. Caml chọn những phiên bản đầu tiên này một cách ngẫu nhiên (Dòng 4-7). Cụ thể, Caml chọn ngẫu nhiên tập dữ liệu d, các ràng buộc c và cấu hình AutoML ω (Dòng 5). Sau đó, những thành phần đó được mã hóa dưới dạng meta-features và được thêm vào tập meta-training (Dòng 6). Lần chạy AutoML tương ứng được thực hiện và so sánh với cấu hình mặc định để thu được nhãn tương ứng (Dòng 7). Sau đó, quá trình lấy mẫu xen kẽ bắt đầu (Dòng 8). Hệ thống chọn ngẫu nhiên đồng đều liệu có áp dụng lấy mẫu ngẫu nhiên hay uncertainty sampling. Uncertainty sampling chọn phiên bản không chắc chắn nhất trong tất cả các phiên bản đã cho. Để tìm các phiên bản không chắc chắn trong không gian tìm kiếm khổng lồ này (kết hợp của tập dữ liệu, cấu hình AutoML và ràng buộc), chúng tôi tận dụng BO, học một mô hình surrogate để dự đoán tham số AutoML nào mang lại hiệu suất dự đoán cao và chỉ lấy mẫu các phiên bản đầy hứa hẹn bằng cách đánh đổi khám phá và khai thác. Trong Dòng 11, BO xác định sự kết hợp của (d,c,ω) dẫn đến độ lệch chuẩn cao nhất trên tất cả các cây của meta-model random forest. Chúng tôi lặp lại vòng lặp hai bước này cho đến khi đạt giới hạn thời gian.

3.1.3 Song song hóa và Tối ưu hóa
Để tăng tốc thuật toán tuần tự đã trình bày, chúng tôi song song hóa nó một cách bất đồng bộ. Mỗi worker luôn truy cập vào các phiên bản huấn luyện mới nhất. Khi một phiên bản meta-training mới và một nhãn tương ứng có sẵn, dữ liệu meta-training được khóa ngắn gọn để thêm phiên bản mới. Chúng tôi phát hiện rằng cách tiếp cận phổ biến hơn [64] để dự đoán nhãn cho một phiên bản mới được lấy mẫu với meta-model hiện tại và thêm cả hai vào dữ liệu meta-training không hoạt động tốt cho tình huống của chúng tôi. Nhãn của chúng tôi chỉ được dự đoán và do đó chỉ là một xấp xỉ của sự thật cơ bản. Nếu nhãn không chính xác, quá trình tìm kiếm có thể rơi vào hướng sai. Do đó, cách tiếp cận của chúng tôi chỉ thêm một phiên bản mới khi nhãn được xác nhận. Để tránh các phiên bản giống nhau được đánh giá song song, chúng tôi bắt đầu mỗi lần chạy BO không xác định với các seed khác nhau. Vì không gian tìm kiếm rất lớn, rất khó có khả năng các phiên bản tương tự sẽ được lấy mẫu trong cùng một khoảng thời gian.

3.1.4 Biểu diễn Meta-Feature
Để ước tính liệu một cấu hình AutoML có mang lại hiệu suất dự đoán cao hơn cấu hình AutoML mặc định hay không, meta-model phải biết tập dữ liệu, các tham số AutoML và các ràng buộc. Chúng tôi mã hóa mỗi thành phần này trong một vector meta-feature.

Đặc trưng Tập dữ liệu Để mã hóa các tập dữ liệu thành các vector meta-feature, nhiều cách tiếp cận đã được đề xuất [57,7,18]. Chúng tôi tận dụng 32 meta-features được đề xuất bởi Feurer et al. [18], chẳng hạn như entropy lớp, số lượng đặc trưng, lớp và phiên bản.

--- TRANG 8 ---
8 Felix Neutatz et al.

Đặc trưng Ràng buộc Tất cả các ràng buộc, chẳng hạn như thời gian suy luận≤0.001s, có thể được biểu diễn bằng ngưỡng tương ứng. Nếu người dùng không chỉ định ràng buộc, chúng tôi đặt giá trị mặc định tối đa có thể. Việc mở rộng tập hợp các ràng buộc luôn có thể. Chiến lược an toàn nhất là huấn luyện meta-model từ đầu. Tuy nhiên, người ta cũng có thể tận dụng giả định rằng ràng buộc bị thiếu chỉ đơn giản được đặt về mặc định. Do đó, tất cả các phiên bản huấn luyện trước đó có thể được bổ sung với giá trị mặc định cho ràng buộc mới và các phiên bản mới với ngưỡng mới cho ràng buộc có thể được tạo ra cho các phiên bản mới. Bằng cách này, chúng ta có thể tiếp tục meta-training một cách bất đồng bộ mà không cần bắt đầu từ đầu. Cùng một lý do áp dụng cho việc mở rộng không gian tìm kiếm của các tham số AutoML. Tuy nhiên, điều này chỉ hoạt động nếu người ta không thay đổi hệ thống AutoML cơ bản mà chúng ta so sánh - ví dụ: nếu người ta sử dụng hệ thống AutoML tiên tiến làm so sánh, người ta có thể tận dụng giả định rằng thành phần bị thiếu chỉ đơn giản không được chọn. Bằng cách này, chúng ta có thể tiếp tục meta-training mà không cần bắt đầu từ đầu.

Đặc trưng Cấu hình AutoML Để mã hóa một cấu hình AutoML, chúng tôi phân biệt các tham số số và các tham số danh mục. Các tham số AutoML số, chẳng hạn như lựa chọn phần xác thực, chỉ đơn giản được thêm vào vector meta-feature. Chúng tôi mã hóa các siêu tham số ML dưới dạng giá trị nhị phân. Hệ thống AutoML hoặc tối ưu hóa mỗi siêu tham số ML (True) hoặc sử dụng giá trị mặc định tương ứng của nó (False). Ví dụ, hệ thống AutoML có thể tối ưu hóa số lượng láng giềng cho K láng giềng gần nhất hoặc sử dụng K mặc định = 5.

Chúng tôi tuân theo giả định nổi tiếng rằng không gian siêu tham số ML có cấu trúc cây trong đó mỗi nút đại diện cho một siêu tham số ML [56,3] và mỗi cạnh đại diện cho sự phụ thuộc vào siêu tham số ML cha của nó. Hình 5 cho thấy một nhánh của cây này. Chúng tôi mô tả chi tiết về cách chúng tôi cấu trúc cây này trong Phần 3.4. Nếu chúng ta không tối ưu hóa một siêu tham số ML ở phía trên của cây, chúng ta cũng sẽ không tối ưu hóa bất kỳ siêu tham số ML con cháu nào của nó. Ví dụ, nếu chúng ta loại bỏ bộ phân loại K-nearest-neighbor khỏi lựa chọn các bộ phân loại có thể, chúng ta cũng không cần tối ưu hóa số lượng láng giềng k. Chúng tôi giới thiệu độc giả đến kho lưu trữ của chúng tôi [40] cho không gian cây hoàn chỉnh mà chúng tôi tận dụng.

Tập hợp meta-features đã nêu ở trên giả định các thông số kỹ thuật phần cứng đồng đều tại thời gian huấn luyện và triển khai, điều không thể luôn được đảm bảo. Nếu phần cứng của meta-learning training khác với phần cứng nơi Caml được triển khai, người ta có thể áp dụng các chiến lược hiệu chuẩn đã được đề xuất cho các mô hình chi phí tối ưu hóa truy vấn cơ sở dữ liệu [20]. Ví dụ, người ta có thể chạy một benchmark nhẹ để hiểu sự khác biệt hiệu suất phần cứng và thu được các hàm tỷ lệ tương ứng.

Chúng tôi đề xuất một phương pháp hiệu chuẩn đơn giản để triển khai ý tưởng này. Cụ thể, người ta có thể thực hiện một hệ thống AutoML và theo dõi hiệu suất dự đoán cao nhất trên tập xác thực cho một hoặc nhiều tập dữ liệu thường hưởng lợi từ thời gian tìm kiếm dài hơn và sử dụng ánh xạ hiệu suất để hiệu chuẩn thời gian tìm kiếm. Người ta có thể triển khai cùng một ý tưởng sử dụng tập kiểm tra nhưng điều này sẽ yêu cầu tính toán bổ sung và thường dữ liệu kiểm tra không thể truy cập được vào hệ thống AutoML trong thời gian chạy.

Trong một bước offline, Caml tĩnh được áp dụng trên các tập dữ liệu đã chọn trên cả hai máy, môi trường nguồn và môi trường đích, và ghi lại sự cải thiện của độ chính xác xác thực theo thời gian. Những benchmark này dẫn đến hai đồ thị, như được hiển thị trong Hình 3. Trong quá trình online cho một tập dữ liệu mới, người ta giờ đây có thể chỉ định thời gian tìm kiếm mong muốn trên máy đích, điều này sẽ được ánh xạ nội bộ đến một thời gian tìm kiếm đạt được độ chính xác xác thực tương tự trên máy nguồn. Trong Hình 3, chúng tôi đánh dấu 30 giây trên máy đích và đồ thị trực quan hóa cách nó ánh xạ đến một thời gian tìm kiếm khác dựa trên sự bằng nhau của độ chính xác xác thực. Caml tìm kiếm thời gian tìm kiếm mà máy meta-training đạt được độ chính xác xác thực này và sử dụng thời gian tìm kiếm đã điều chỉnh để cấu hình các tham số AutoML cho máy mới. Lưu ý rằng nó vẫn chỉ chạy 30 giây trên máy đích nhưng đặt không gian cấu hình dựa trên thời gian tìm kiếm đã điều chỉnh. Ưu điểm của phương pháp hiệu chuẩn này là nó hoạt động cho bất kỳ thiết lập phần cứng nào mà không cần yêu cầu thu thập meta-information phần cứng. Để cải thiện độ tin cậy của việc hiệu chuẩn, người ta nên tiến hành nhiều lần chạy và lấy trung bình kết quả. Cách tiếp cận sẽ tốn kém nếu thời gian tìm kiếm được nhắm mục tiêu khá cao. Tuy nhiên, chúng tôi lập luận rằng trong những trường hợp này việc hiệu chuẩn không cần thiết vì thời gian tìm kiếm đủ dài. Điều này cũng được xác thực bởi các thí nghiệm của chúng tôi được thảo luận trong Phần 4.7.

--- TRANG 9 ---
AutoML trong Các Ứng dụng Bị Ràng buộc Nghiêm ngặt 9

0 20 40 60 8000.20.40.60.81
1
2
3
Thời gian Tìm kiếm (s)Độ chính xác Cân bằng XácthựcMáy Mới
Máy Meta-Training

Hình 3: Ánh xạ thời gian tìm kiếm từ một môi trường sang môi trường khác.

3.2 Huấn luyện Meta-Model
Khi việc lấy mẫu meta-data hoàn thành, Caml huấn luyện meta-model cuối cùng. Cách tiếp cận đơn giản sẽ là sử dụng cùng một mô hình đã được huấn luyện cho uncertainty sampling. Tuy nhiên, mô hình này không tối ưu vì nó có thể bị overfitted với một số tập dữ liệu được lấy mẫu thường xuyên hơn những tập khác do ước tính bất định của chúng. Hơn nữa, chúng tôi không tối ưu hóa các siêu tham số mô hình trong quá trình uncertainty sampling vì nó sẽ làm chậm đáng kể việc tạo dữ liệu huấn luyện. Vì những lý do này, chúng tôi áp dụng tối ưu hóa siêu tham số trên meta-model sau khi lấy mẫu hoàn thành với 10-fold time series cross-validation vì active learning sampling tạo ra tập dữ liệu một cách tăng dần.

Để đạt được hiệu suất tối ưu, chúng tôi huấn luyện hai meta-models, một cho khai thác cấu hình AutoML và một để xếp hạng nhóm lớn các cấu hình AutoML được khai thác. Đối với khai thác cấu hình AutoML, chúng tôi sử dụng cùng một mục tiêu như cho mô hình surrogate cho uncertainty sampling (xem Phần 3.1.1): chúng tôi dự đoán phần các lần chạy mà cấu hình AutoML đã cho vượt trội hơn cấu hình mặc định (hồi quy). Đối với việc xếp hạng các cấu hình AutoML được khai thác, chúng tôi dự đoán liệu cấu hình AutoML đã cho có vượt trội hơn cấu hình mặc định ít nhất một lần hay không (phân loại). Meta-model hồi quy chứa nhiều thông tin hơn meta-model phân loại vì nó ước tính mức độ cấu hình AutoML đã cho tốt hơn cấu hình mặc định bao nhiêu trong khi mô hình phân loại chỉ ước tính liệu cấu hình AutoML có tốt hơn cấu hình mặc định hay không. Tuy nhiên, vì nhiệm vụ hồi quy khó hơn nhiều so với nhiệm vụ phân loại, meta-model hồi quy có khả năng mắc lỗi cao hơn và do đó không ổn định hơn. Tuy nhiên, như chúng tôi mô tả trong Phần 3.3, chúng tôi truy vấn meta-model hồi quy nhiều lần, tránh tối ưu cục bộ/lỗi, và hội tụ theo thời gian đến một cấu hình AutoML hoạt động tốt. Ngược lại, chúng tôi chỉ truy vấn meta-model xếp hạng một lần. Do đó, chúng ta cần đảm bảo rằng nó không mắc lỗi và càng bảo thủ càng tốt. Bằng cách này, chúng tôi đảm bảo rằng cấu hình AutoML được xếp hạng cao nhất là mạnh mẽ - có nghĩa là nó vượt trội ít nhất so với cấu hình mặc định.

3.3 Khai thác Cấu hình AutoML
Với một nhiệm vụ ML và một cấu hình được tạo, meta-model hồi quy đã huấn luyện có thể dự đoán liệu cấu hình được tạo có hiệu quả hơn cấu hình mặc định hay không. Câu hỏi là làm thế nào chúng ta có thể tận dụng meta-model hồi quy này để tìm ra cấu hình AutoML tốt nhất cho một tập dữ liệu mới và các ràng buộc do người dùng chỉ định. Để sử dụng meta-model hồi quy đã huấn luyện, chúng ta cần một tập hợp các cấu hình ứng cử viên được tạo mà chúng ta có thể thực hiện suy luận cho mỗi cấu hình. Ở đây, chúng tôi đang tìm kiếm cấu hình AutoML mang lại hiệu suất dự đoán tốt nhất cho một tập dữ liệu đã cho và các ràng buộc đã cho.

Cách tiếp cận đơn giản nhất sẽ là tạo ra một số lượng lớn các cấu hình ứng cử viên ngẫu nhiên và để meta-model hồi quy dự đoán cấu hình nào trong số này có khả năng thành công cao nhất. Nhược điểm của cách tiếp cận này là nhiều cấu hình được tạo ngẫu nhiên sẽ hoạt động kém và chúng ta không thể tạo ra tất cả các cấu hình có thể. Ưu điểm của cách tiếp cận này là việc tạo ra những cấu hình ngẫu nhiên này có thể được thực hiện trong giai đoạn offline. Trong giai đoạn online, chúng ta sẽ chỉ áp dụng suy luận. Chi phí suy luận là tối thiểu - ví dụ: dự đoán một triệu cấu hình mất khoảng 1s.

Thay vì lấy mẫu ngẫu nhiên, chúng ta cũng có thể áp dụng BO. Chúng ta có thể tối đa hóa khả năng ước tính rằng một cấu hình được tạo vượt trội hơn cấu hình mặc định, và đóng băng tất cả meta-features cho tập dữ liệu và ràng buộc do người dùng chỉ định:

ˆω←arg max
ω∈Ωmeta model.predict(encode( d, c, ω )) (5)

Ưu điểm của BO là nó sẽ điều chỉnh cấu hình theo tập dữ liệu và ràng buộc được chỉ định. Nhược điểm của BO là nó chậm. Ví dụ, thực hiện 1000 lần lặp sẽ mất hơn 700s. Chờ đợi hơn 10 phút trước khi chúng ta thậm chí bắt đầu hệ thống AutoML là không khả thi - đặc biệt nếu người dùng quan tâm đến các chu kỳ phát triển nhanh.

Chúng tôi đề xuất một cách tiếp cận hybrid kết hợp điểm mạnh của cả hai chiến lược thăm dò. Trong giai đoạn offline, chúng tôi lấy mẫu ngẫu nhiên một tập dữ liệu và ràng buộc - tương tự như Dòng 5. Nhưng thay vì lấy mẫu ngẫu nhiên một cấu hình ω, chúng tôi tận dụng BO để tìm cấu hình đầy hứa hẹn nhất cho nhiệm vụ ML được tạo ngẫu nhiên này với sự giúp đỡ của meta-model hồi quy. Bằng cách này, chúng tôi

--- TRANG 10 ---
10 Felix Neutatz et al.

tìm kiếm
liên quan đến thời gian
Thời gian Tìm kiếmThời gian Đánh giáliên quan đến phần cứng
Bộ nhớTính song songcụ thể cho hệ thống AutoML
Kích thước EnsembleKhông gian Tìm kiếmứng dụng ML
đã biết
Quyền riêng tưKhả năng diễn giải
|Đặc trưng |Pipeline MLchưa biết
Hiệu quả
Thời gian Huấn luyệnThời gian Suy luậnKích thước Pipeline ML Công bằngTính mạnh mẽTính chính xácBảo mật

Hình 4: Ràng buộc AutoML.

tạo ra một số lượng lớn các cấu hình ngẫu nhiên đầy hứa hẹn offline. Trong giai đoạn online, chúng tôi để meta-model phân loại chọn cấu hình nào trong số những cấu hình ngẫu nhiên đầy hứa hẹn này phù hợp nhất với tập dữ liệu và ràng buộc được chỉ định. Sau đó, Caml thiết lập hệ thống AutoML thực tế với cấu hình này và thực thi nó.

3.4 Tham số AutoML
Việc thích ứng các tham số AutoML chỉ có ý nghĩa nếu có một phạm vi rộng các tham số thực sự có thể thích ứng được. Trái ngược với Auto-Sklearn và AutoGluon, chúng tôi đã triển khai Caml để không chỉ cung cấp quyền truy cập vào các tham số AutoML thông thường có thể điều chỉnh bởi người dùng, chẳng hạn như có sử dụng ensembling hay không, huấn luyện tăng dần, hoặc chiến lược xác thực nào, mà còn cho phép điều chỉnh bên ngoài mọi siêu tham số ML duy nhất trong không gian tìm kiếm. Bằng cách này, có thể quyết định động liệu những tham số đó có nên được tối ưu hóa hay không, như được hiển thị trong Hình 1.

Chúng tôi mở rộng không gian siêu tham số ML của Auto-Sklearn [18] bổ sung hỗ trợ các chiến lược oversampling random oversampling, SMOTE [9] và ADASYN [23] để giải quyết mất cân bằng lớp. Hơn nữa, chúng tôi đã thêm hỗ trợ cho phân loại one-vs-rest để cải thiện phân loại đa lớp. Chúng tôi giới thiệu độc giả đến kho lưu trữ của chúng tôi [40] cho không gian cây hoàn chỉnh mà chúng tôi tận dụng. Chúng tôi cấu trúc không gian siêu tham số ML thành một cây [40], như được đề xuất trong Auto-Weka [56]. Hình 5 đại diện cho một lát cắt của không gian cây được tận dụng. Cấp đầu tiên của cây chứa tất cả các thành phần chính của pipeline ML: mã hóa danh mục, điền giá trị thiếu, chia tỷ lệ, bộ phân loại, bộ tiền xử lý đặc trưng, tăng cường, lấy mẫu và trọng số lớp. Dưới cấp này, mỗi thành phần có thể được triển khai bởi các chiến lược khác nhau và mỗi chiến lược có các siêu tham số riêng. Bằng cách này, không gian siêu tham số ML tự nhiên xây dựng một cây. Tổ chức phân cấp của không gian siêu tham số ML là cần thiết để cho phép meta-model cắt tỉa một phần lớn không gian siêu tham số ML càng sớm càng tốt. Bằng cách này, hệ thống AutoML sẽ không tối ưu hóa các siêu tham số ML con nếu siêu tham số ML cha của chúng không được tối ưu hóa. Thay vào đó, hệ thống sẽ sử dụng giá trị mặc định của chúng. Ví dụ, bằng cách cung cấp một cấu trúc phân cấp, chúng tôi cho phép meta-model nhận ra rằng không có phép biến đổi tiền xử lý nào sẽ có lợi cho một thiết lập cụ thể, thay vì quyết định cho mọi bộ tiền xử lý đơn lẻ và tất cả các siêu tham số tương ứng của chúng có nên tối ưu hóa nó hay không.

3.5 Ràng buộc
Trong AutoML dựa trên ràng buộc, người dùng có thể định nghĩa các ràng buộc, có thể liên quan đến quá trình AutoML hoặc ứng dụng ML, như được hiển thị trong Hình 4.

Ràng buộc tìm kiếm giới hạn các khía cạnh liên quan đến thời gian, liên quan đến phần cứng hoặc cụ thể cho hệ thống của quá trình AutoML. Ràng buộc tìm kiếm liên quan đến thời gian giới hạn thời gian tìm kiếm hoặc thời gian đánh giá. Ràng buộc tìm kiếm liên quan đến phần cứng là giới hạn về bộ nhớ hoặc tính song song. Ràng buộc tìm kiếm cụ thể cho hệ thống là giới hạn về kích thước của ensembles hoặc không gian tìm kiếm.

Ràng buộc tìm kiếm quan trọng nhất giới hạn thời gian tìm kiếm. Ràng buộc tìm kiếm này là bắt buộc cho mỗi lần chạy AutoML và do đó nó đại diện tốt cho lớp ràng buộc tìm kiếm. Đối với các chu kỳ phát triển nhanh, các nhà khoa học dữ liệu sẽ giới hạn thời gian tìm kiếm xuống dưới một giờ để nhanh chóng thử nghiệm với pipeline.

Ràng buộc ứng dụng ML hạn chế các pipeline ML đối với các chiều chất lượng khác nhau. Zhang et al. [63] mô tả 7 chiều chất lượng có thể phục vụ như ràng buộc: tính chính xác, tính mạnh mẽ, bảo mật, quyền riêng tư, hiệu quả, công bằng và khả năng diễn giải. Những ràng buộc này có thể được phân loại theo hai chiều.

Gelbart et al. [19] phân biệt giữa ràng buộc chưa biết và đã biết như cũng được minh họa trong phân loại ràng buộc của chúng tôi. Ràng buộc đã biết là những ràng buộc có thể được kiểm tra trước khi huấn luyện và đánh giá một mô hình. Ví dụ, biết rằng một triển khai ε-differentially private của các bộ phân loại [8] được

--- TRANG 11 ---
AutoML trong Các Ứng dụng Bị Ràng buộc Nghiêm ngặt 11

sử dụng apriori đảm bảo rằng các ràng buộc quyền riêng tư được thỏa mãn. Một ví dụ khác về ràng buộc đã biết là hạn chế đối với các thành phần pipeline ML hoặc số lượng đặc trưng để cải thiện khả năng diễn giải của pipeline ML kết quả. Ngược lại, ràng buộc chưa biết đề cập đến những ràng buộc chỉ có thể được kiểm tra khi mô hình được huấn luyện và đánh giá. Ví dụ, hầu hết các ràng buộc hiệu quả có tính chất này.

Nói chung, cách tiếp cận của chúng tôi có thể tích hợp bất kỳ ràng buộc đã biết nào một cách dễ dàng bằng cách thêm một câu lệnh if ở đầu hàm mục tiêu. Đối với các thí nghiệm của chúng tôi, chúng tôi tập trung vào ràng buộc chưa biết.

Chiều thứ hai mà người ta có thể phân biệt ràng buộc đề cập đến sự phụ thuộc của chúng vào pipeline ML và/hoặc dữ liệu. Đối với các thí nghiệm của chúng tôi, chúng tôi tập trung vào các ràng buộc phụ thuộc đáng kể vào pipeline và không phụ thuộc nhiều vào tập dữ liệu. Để kết hợp các ràng buộc phụ thuộc vào tập dữ liệu hơn, chẳng hạn như công bằng, người ta sẽ cần sử dụng nhiều meta-features cụ thể cho tập dữ liệu hơn trong meta-model.

Tổng cộng, trong số bảy chiều chất lượng được đề xuất bởi Zhang et al. [63], chúng tôi tập trung vào tính chính xác, hiệu quả và công bằng. Cụ thể, chúng tôi luôn tối đa hóa tính chính xác tức là hiệu suất dự đoán. Hơn nữa, chúng tôi chọn ba ràng buộc hiệu quả được thiết lập tốt thời gian huấn luyện, thời gian suy luận và kích thước pipeline ML1, và cơ hội bình đẳng [22] là một thước đo công bằng. Tất cả bốn đều là ràng buộc chưa biết và phụ thuộc vào pipeline ML.

Tính liên quan của ba ràng buộc hiệu quả đặc biệt cao trong các tình huống edge computing và streaming. Trong các tình huống streaming, việc giảm thời gian suy luận là quan trọng để đảm bảo dự đoán thời gian thực liên tục. Khi dữ liệu đang phát triển, mô hình yêu cầu huấn luyện lại liên tục. Trong các tình huống huấn luyện liên tục, việc thực thi giới hạn thời gian huấn luyện đóng vai trò quan trọng. Cùng loại ràng buộc này có liên quan đến federated learning [32], nơi người dùng tiếp tục huấn luyện trên thiết bị riêng của họ. Cuối cùng, để áp dụng ML trên các thiết bị IoT hoặc điện thoại thông minh, việc giới hạn tiêu thụ bộ nhớ là quan trọng.

3.6 Mở rộng danh sách ràng buộc
Đầu tiên, người ta phải định nghĩa hàm do người dùng định nghĩa mô tả ràng buộc. Quá trình phụ thuộc vào việc chúng ta muốn tạo ràng buộc ứng dụng ML hay ràng buộc tìm kiếm.

Đối với ràng buộc ứng dụng ML, người ta phải triển khai mẫu sau:

1Đối với một số mô hình ML, chẳng hạn như random forest và KNN, kích thước mô hình phụ thuộc vào dữ liệu.

1def constraint ( pipeline , training_time ,
X_train , y_train , X_val , y_val ,
threshold , constraint_specific ): True /
False

Hàm này nhận pipeline đã huấn luyện và thời gian huấn luyện của nó, dữ liệu được chia, ngưỡng ràng buộc và các tham số cụ thể cho ràng buộc, chẳng hạn như thuộc tính nhạy cảm cho công bằng. Đầu ra của hàm này là liệu pipeline ML đã cho có vượt qua ràng buộc hay không.

Sau khi triển khai hàm do người dùng định nghĩa, người ta phải thêm một đặc trưng mới vào biểu diễn metadata và tiếp tục meta-training. Để tính đến đặc trưng metadata mới, trước tiên người ta phải huấn luyện lại meta-model. Với meta-model đã được huấn luyện lại, người ta có thể tiếp tục lấy mẫu xen kẽ bao gồm ràng buộc mới. Cuối cùng, người ta phải tạo ra các cấu hình bổ sung cũng bao phủ ràng buộc mới như được mô tả trong Phần 3.3.

Đối với ràng buộc tìm kiếm, người ta phải bổ sung triển khai một hàm initialize bắt đầu đo lường ở đầu tìm kiếm và một hàm khác kiểm tra liệu ràng buộc tìm kiếm có còn được thỏa mãn hay không.

3.7 Tối ưu hóa Có ràng buộc
Cho đến nay chúng ta biết cách huấn luyện cách tiếp cận meta-learning và cách truy xuất một cấu hình AutoML được thích ứng động. Bây giờ, chúng tôi giải thích cách Caml tối ưu hóa các siêu tham số ML dưới ràng buộc. Các hệ thống trước đó theo mặc định xem xét hiệu suất dự đoán làm hàm mục tiêu, điều này không đủ và yêu cầu điều chỉnh. Hơn nữa, các khía cạnh như ensembling phải được điều chỉnh vì chúng ta cần đảm bảo rằng chỉ những mô hình thỏa mãn ràng buộc được ensembled và ensemble cuối cùng cũng thỏa mãn các ràng buộc.

Để hỗ trợ ràng buộc ứng dụng ML, chúng tôi xây dựng hàm mục tiêu như sau cho Caml:

max 
−1· nX
i=1∆ci!
+ "nX
i=1∆ci== 0#
·BA!!
,

trong đó ∆ci là khoảng cách để thỏa mãn ràng buộc thứ i và BA là balanced accuracy. Mục tiêu này đảm bảo thỏa mãn các ràng buộc trước tiên và sau đó tối ưu hóa balanced accuracy. Bằng cách này, người dùng có thể đặt ngưỡng cho bất kỳ ràng buộc được hỗ trợ nào thông qua API. Như framework BO để tối đa hóa mục tiêu này, chúng tôi chọn Optuna [1], tận dụng tree-structured Parzen estimator (TPE) làm mô hình surrogate. TPE rất phù hợp cho không gian tìm kiếm ML có cấu trúc cây của chúng tôi.

Để cho phép model ensembling trong Caml, chúng tôi tích hợp chiến lược ensembling tham lam được đề xuất bởi Caruana

--- TRANG 12 ---
12 Felix Neutatz et al.

bộ tiền xử lý
PCA
Nystroem
RBFSampler
TruncatedSVD
FeatureAgglomeration
SparseRandomProjection
GaussianRandomProjection
RandomTreesEmbedding
PolynomialFeatures
SelectKBest
KernelPCA
FastICA

bộ phân loại
KNN
SVC
LinearSVC
ExtraTrees
BernoulliNB
DecisionTree
PassiveAggressive
LinearDiscriminantAnalysis
QuadraticDiscriminantAnalysis
HistGradientBoosting
MultinomialNB
RandomForest
GaussianNB
AdaBoost
SGD
MLP

Hình 5: Lát cắt của không gian cây mà chúng tôi sử dụng trong triển khai của chúng tôi.

et al. [6]. Chiến lược lặp đi lặp lại thêm mô hình tối đa hóa hiệu suất dự đoán xác thực ensemble miễn là tất cả các ràng buộc được thỏa mãn.

Để cho phép tối ưu hóa siêu tham số trên dữ liệu lớn, chúng tôi triển khai huấn luyện tăng dần tương tự như successive halving [31]. Đầu tiên, chúng tôi huấn luyện một mô hình trên một mẫu nhỏ chứa 10 phiên bản mỗi lớp. Sau đó, chúng tôi nhân đôi kích thước tập huấn luyện và huấn luyện mô hình lại. Chúng tôi tiếp tục cách tiếp cận này cho đến khi thời gian đánh giá kết thúc hoặc cấu hình siêu tham số ML bị cắt tỉa vì nó hoạt động tệ hơn cấu hình trung vị của lịch sử. Hơn nữa, đối với các số liệu ràng buộc tăng đơn điệu với kích thước tập huấn luyện, chẳng hạn như thời gian huấn luyện hoặc kích thước pipeline ML, chúng tôi dừng đánh giá cấu hình càng sớm càng tốt để tránh tính toán không cần thiết. Vì huấn luyện tăng dần có thể dẫn đến một số lượng lớn đánh giá siêu tham số ML, nguy cơ overfitting tăng lên. Lévesque đề xuất xáo trộn lại chia xác thực sau mỗi đánh giá để tránh overfitting [30]. Do đó, chúng tôi đã triển khai tùy chọn này trong Caml và hiển thị nó như một tham số AutoML.

4 Thí nghiệm
Các thí nghiệm của chúng tôi nhằm trả lời những câu hỏi sau:
1. Hệ thống AutoML được cấu hình động của chúng tôi so với các hệ thống AutoML tiên tiến như thế nào?
2. Cấu hình hệ thống AutoML động hoạt động như thế nào khi một hoặc nhiều ràng buộc ứng dụng ML đã được định nghĩa?
3. Lấy mẫu xen kẽ có hiệu quả hơn lấy mẫu ngẫu nhiên để tạo dữ liệu huấn luyện meta-learning không?
4. Số lượng cấu hình AutoML được khai thác ảnh hưởng như thế nào đến hiệu suất dự đoán của Caml?
5. Thay đổi môi trường phần cứng ảnh hưởng như thế nào đến hiệu suất dự đoán của Caml?
6. Số lượng ràng buộc ảnh hưởng như thế nào đến meta-training?

4.1 Thiết lập
Chúng tôi đánh giá cách tiếp cận của chúng tôi trên cùng một phân chia tập dữ liệu được sử dụng bởi Feurer et al. [17]: 39 tập dữ liệu meta-test và 207 tập dữ liệu meta-train. Để mở rộng framework của chúng tôi cho các ràng buộc công bằng, chúng tôi thêm 17 tập dữ liệu liên quan đến công bằng được cung cấp bởi Neutatz et al. [41] vào các tập dữ liệu meta-train vì các tập dữ liệu thông thường không chú thích các thuộc tính nhạy cảm cần thiết để đo lường công bằng. Như tập dữ liệu kiểm tra cho công bằng, chúng tôi sử dụng năm tập dữ liệu công bằng mà Ding et al. đề xuất để đánh giá các hệ thống ML công bằng [12]. Như một số liệu độ chính xác dự đoán, chúng tôi tận dụng balanced accuracy có thể xử lý các vấn đề phân loại nhị phân, đa lớp và không cân bằng. Để so sánh hiệu suất trên các tập dữ liệu, chúng tôi báo cáo trung bình và độ lệch chuẩn trên các tập dữ liệu bằng cách lặp đi lặp lại lấy mẫu ngẫu nhiên một kết quả trong mười lần chạy với các seed khác nhau với replacement. Cách tiếp cận này đảm bảo rằng chúng tôi báo cáo sự không chắc chắn do hệ thống của chúng tôi tạo ra chứ không phải các thang đo độ khó khác nhau của các tập dữ liệu. Tương tự, chúng tôi kiểm tra ý nghĩa bằng kiểm tra hạng Mann-Whitney U với α= 0.05 giữa các trung bình được lấy mẫu ngẫu nhiên lặp đi lặp lại. Chúng tôi đánh dấu một số bằng dấu sao (*) nếu nó vượt qua kiểm tra này. Lưu ý rằng trong một số trường hợp trung bình được làm tròn rất giống nhau hoặc giống nhau, nhưng một cách tiếp cận vẫn vượt qua kiểm tra ý nghĩa để tốt hơn cách tiếp cận khác. Trong những trường hợp này, chúng tôi in đậm kết quả của cách tiếp cận vượt qua kiểm tra ý nghĩa.

Do tài nguyên hạn chế của chúng tôi, chúng tôi lấy mẫu tập dữ liệu meta-training trong hai tuần, tương đương với 6.915 phiên bản meta-training tổng cộng. Hơn nữa, chúng tôi khai thác các cấu hình AutoML trong hai tuần bằng BO cho 2.000 lần lặp, tương đương với 11.911 cấu hình AutoML. Như không gian tham số AutoML, Caml chọn (i) phần hold-out, ảnh hưởng đến cả kích thước

--- TRANG 13 ---
AutoML trong Các Ứng dụng Bị Ràng buộc Nghiêm ngặt 13

của tập huấn luyện và tập xác thực, (ii) có sử dụng model ensembling hay không, (iii) có sử dụng huấn luyện tăng dần hay không, (iv) có xáo trộn chia xác thực hay không, và (v) toàn bộ không gian siêu tham số ML có thể điều chỉnh với 302 siêu tham số ML. Lưu ý rằng chúng tôi xem xét thời gian cần thiết cho ensembling cho thời gian tìm kiếm vì nó có thể được chạy song song với việc tìm kiếm mô hình như được thực hiện cho Auto-Sklearn2 [17]. Chúng tôi đã chạy các thí nghiệm trên các máy Ubuntu 16.04 với 28 ×Intel(R) Xeon(R) Gold 6132 CPU @ 2.60GHz cores và 264 GB memory.

Baselines. Chúng tôi so sánh hệ thống của chúng tôi với các hệ thống AutoML tiên tiến:

1. TPOT (0.11.5) là một hệ thống AutoML dựa trên genetic programming tối ưu hóa các bộ tiền xử lý đặc trưng và mô hình ML [43].

2. AutoGluon (0.3.2) là một hệ thống AutoML tập trung vào model ensembling và stacking [14].

3. Auto-Sklearn2 (0.14.0) [17] là phiên bản mới nhất của hệ thống AutoML nổi tiếng Auto-Sklearn1 [18] tận dụng BO, meta-learning và model ensembling để tìm các pipeline ML Sklearn [45] đạt được hiệu suất dự đoán cao. Hơn nữa, chúng tôi đã mở rộng hệ thống để hỗ trợ các ràng buộc về kích thước pipeline, thời gian suy luận/huấn luyện và công bằng. Chúng tôi tuân theo cùng cách tiếp cận như được mô tả trong Phần 3.7 và chỉ thêm một mô hình vào ensemble nếu tất cả các ràng buộc được thỏa mãn. Điều này cho phép so sánh công bằng giữa Caml và Auto-Sklearn2.

4. Spearmint [19] tận dụng BO cho tối ưu hóa có ràng buộc với Gaussian processes. Chúng tôi sử dụng triển khai của Paleyes et al. [44] và tìm kiếm cùng không gian siêu tham số ML như trong hệ thống tĩnh của chúng tôi.

Hơn nữa, chúng tôi đánh giá hệ thống của chúng tôi có và không có cấu hình AutoML động: Caml Dynamic và Caml Static:

1. Caml Static. Phiên bản tĩnh bao phủ không gian siêu tham số ML đầy đủ được lấy cảm hứng từ Auto-Sklearn1 [18]. Nó không tận dụng meta-learning để tối ưu hóa không gian tìm kiếm. Chi tiết của không gian siêu tham số ML được mô tả trong Phần 3.4. Chúng tôi sử dụng cùng các phạm vi siêu tham số ML như Auto-Sklearn1. Hơn nữa, phiên bản tĩnh luôn tận dụng xác thực hold-out với 33% dữ liệu xác thực, đây lại là chiến lược xác thực mặc định của Auto-Sklearn1. Ngoài ra, nó luôn sử dụng model ensembling và huấn luyện tăng dần.

2. Caml Dynamic triển khai cách tiếp cận được đề xuất của chúng tôi. Nó tự động chọn một tập con của không gian siêu tham số ML đầy đủ và xác định phần xác thực hold-out, có sử dụng ensembling hay không, huấn luyện tăng dần và xáo trộn chia xác thực.

Trong phần sau, chúng tôi tập trung vào so sánh và insights so với Auto-Sklearn2 vì đây là hệ thống tương tự nhất so với hệ thống của chúng tôi và được coi là một trong những hệ thống mạnh nhất cho đến nay.

4.2 Hiệu quả trên Ràng buộc Thời gian Tìm kiếm
Ràng buộc quan trọng nhất cho AutoML giới hạn thời gian tìm kiếm, đây là ràng buộc bắt buộc mà các hệ thống AutoML yêu cầu vì không rõ khi nào nên chấm dứt một hệ thống AutoML. Do đó, điều quan trọng là cách tiếp cận của chúng tôi hoạt động tốt cho ràng buộc này vì nó cũng phải được thỏa mãn kết hợp với các ràng buộc khác. Chúng tôi so sánh hệ thống AutoML được cấu hình động Caml Dynamic với cùng hệ thống AutoML với cấu hình AutoML mặc định Caml Static. Ngoài ra, chúng tôi so sánh cách tiếp cận của chúng tôi với các hệ thống AutoML tiên tiến để cho thấy tiềm năng của ý tưởng AutoML dựa trên ràng buộc của chúng tôi. Chúng tôi lưu ý rằng đây là loại ràng buộc duy nhất dễ dàng áp dụng cho tất cả các hệ thống AutoML khác được xem xét trong nghiên cứu này.

4.2.1 So sánh Hiệu suất
Bảng 1 báo cáo balanced accuracy trung bình cho các tập dữ liệu meta-test theo thời gian và trên các hệ thống. Chúng tôi tập trung vào thời gian tìm kiếm lên đến 60 phút vì hầu hết các hệ thống AutoML tiên tiến hội tụ trong khoảng thời gian này.

Đầu tiên, đáng chú ý là Caml với cấu hình AutoML mặc định vượt trội hơn TPOT [43]. Lý do là Caml tận dụng huấn luyện tăng dần, đây là một chiến lược multi-fidelity. Do đó, nó có thể tạo ra các pipeline ML trong thời gian ngắn, ngay cả đối với các tập dữ liệu lớn. Tuy nhiên, Caml với cấu hình AutoML mặc định không vượt trội hơn AutoSklearn2 [17] và AutoGluon [14] cho thời gian tìm kiếm lớn hơn. Đáng chú ý là Auto-Sklearn2 là một phiên bản được tối ưu hóa cẩn thận của hệ thống Auto-Sklearn [18] với một không gian cấu hình được thiết kế thủ công nhỏ hơn với sáu lớp mô hình. Chúng tôi cũng báo cáo hiệu suất của Auto-Sklearn2 sử dụng không gian siêu tham số ML đầy đủ như Auto-Sklearn1. Phiên bản này đạt hiệu suất dự đoán tệ hơn đáng kể, điều này cho thấy việc lựa chọn đúng không gian siêu tham số ML là quan trọng.

Cách tiếp cận Caml (Dynamic) với cấu hình AutoML được meta-learned vượt trội hơn tất cả các hệ thống khác một cách đáng kể theo kiểm tra hạng Mann-Whitney U (α= 0.05) cho đến 5 phút thời gian tìm kiếm. Lưu ý rằng cả nhóm cấu hình mà chúng tôi chọn các cấu hình từ đó và meta-model chọn cấu hình đều được tạo ra với các tình huống cho đến 5 phút thời gian tìm kiếm. Phát hiện này cho thấy

--- TRANG 14 ---
14 Felix Neutatz et al.

Bảng 1: Ràng buộc thời gian tìm kiếm: Balanced accuracy trung bình trên 10 lần lặp lại và 39 tập dữ liệu so sánh Caml với các hệ thống AutoML tiên tiến.

Chiến lược 10s 30s 1 min 5 min 30min 1h
Caml
Static 0 .43±0.02 0 .53±0.02 0 .58±0.01 0 .67±0.01 0 .70±0.01 0 .72±0.01
Dynamic 0.57±0.01∗0.67±0.01∗0.70±0.01∗0.74±0.00∗0.77±0.00 0 .77±0.00
Auto-Sklearn2 opt. 0 .00±0.00 0 .11±0.02 0 .48±0.02 0 .74±0.02 0 .80±0.00 0 .81±0.00
Auto-Sklearn2 full space 0 .00±0.00 0 .06±0.02 0 .14±0.02 0 .70±0.03 0.80±0.00∗0.81±0.00∗
TPOT 0 .00±0.00 0 .00±0.00 0 .31±0.03 0 .47±0.04 0 .67±0.02 0 .68±0.01
AutoGluon 0 .33±0.02 0 .41±0.01 0 .49±0.01 0 .62±0.01 0 .77±0.01 0 .79±0.00
Spearmint 0 .24±0.03 0 .36±0.03 0 .43±0.01 0 .60±0.02 0 .69±0.01 0 .72±0.01

mục tiêu chọn động các cấu hình AutoML tốt của chúng tôi đã được đạt được nếu các tình huống nằm trong lĩnh vực của meta-training.

Thực tế, Caml Dynamic chọn trung bình chỉ 55 trong số 302 siêu tham số ML cho không gian tìm kiếm và khung thời gian 5 phút và vẫn đạt được balanced accuracy trung bình cao hơn trên tất cả các thí nghiệm. Thú vị là không gian tìm kiếm chỉ giảm nhẹ từ đây trở đi. Có ràng buộc 10 giây, trung bình 51 siêu tham số ML được xem xét, chỉ ít hơn bốn siêu tham số so với 55 cho 5 phút.

Tuy nhiên, không gian cũng có thể khác biệt đáng kể giữa 5 và 1 phút. Hình 6 cho thấy các cấu hình AutoML được chọn cho tập dữ liệu "Christine" và "Robert" từ kho lưu trữ OpenML. Hình ảnh trực quan tuân theo quan điểm phân cấp mà chúng tôi đã trình bày trong Phần 3.4 và hiển thị không gian cấu hình thu được cho thời gian tìm kiếm 1min và 5min, tương ứng. So sánh các không gian siêu tham số ML, chúng ta thấy rằng trong trường hợp này không gian siêu tham số ML cho thời gian tìm kiếm 1min nhỏ hơn so với thời gian tìm kiếm 5min. Điều này là do khoảng thời gian cao hơn cho phép tối ưu hóa nhiều tham số pipeline ML hơn.

Ngoài ra, đối với tập dữ liệu "Christine", hệ thống của chúng tôi chọn phần xác thực 0.13, ensembling và huấn luyện tăng dần. Phần xác thực nhỏ giảm thời gian đánh giá. Ensembling làm cho các dự đoán mạnh mẽ hơn trước nhiễu. Huấn luyện tăng dần đảm bảo rằng hệ thống tìm thấy một pipeline ML phù hợp sớm. Ngoài huấn luyện tăng dần, hệ thống của chúng tôi cũng chọn tối ưu hóa kích thước tập huấn luyện để giảm thêm overhead lặp.

Đối với tập dữ liệu "Robert", hệ thống của chúng tôi chọn phần xác thực 0.54, huấn luyện tăng dần và xáo trộn chia xác thực. Xáo trộn chia xác thực tránh overfitting. Ngoài ra, hệ thống của chúng tôi chọn tối ưu hóa từng trọng số lớp riêng lẻ vì tập dữ liệu có 10 lớp.

Bảng 2 trình bày một ví dụ cho thấy các tham số AutoML được chọn cho tập dữ liệu "numerai28.6" dưới các ràng buộc thời gian tìm kiếm khác nhau: 10s, 1min và ≥5min. Vì Caml Dynamic của chúng tôi được huấn luyện trên dữ liệu cho đến 5 phút, nó sẽ chọn cùng không gian tìm kiếm cho thời gian tìm kiếm lớn hơn 5 phút, đó là lý do tại sao chúng tôi không xem xét ràng buộc thời gian tìm kiếm cao hơn ở đây.

Ngay cả đối với thời gian tìm kiếm rất ngắn 10s và tập dữ liệu khá lớn với 96.320 phiên bản, không gian tìm kiếm vẫn kết hợp 9 trong số 16 bộ phân loại vì huấn luyện tăng dần, cho phép bỏ qua nhanh các pipeline ML hoạt động kém. Đối với 1min, hệ thống của chúng tôi tăng cả không gian tìm kiếm và phần holdout. Với thay đổi này, đánh giá điểm xác thực holdout sẽ mất nhiều thời gian hơn nhưng sẽ chính xác hơn. Đối với ≥5min, hệ thống của chúng tôi chọn tránh huấn luyện tăng dần. Bằng cách này, việc huấn luyện mô hình sẽ mất nhiều thời gian hơn nhưng các mô hình sẽ được huấn luyện trên nhiều phiên bản hơn và có khả năng đạt được tổng quát hóa tốt hơn.

4.2.2 Phân tích Meta-Models
Để phân tích các meta-models, chúng tôi tính toán tầm quan trọng meta-feature dựa trên điểm impurity cho meta-model random forest đã huấn luyện. Chúng tôi liệt kê top-15 meta-features trong Bảng 3 cho meta-model phân loại. Các meta-features quan trọng nhất là các ngưỡng ràng buộc, đặc biệt là cho kích thước pipeline và thời gian suy luận/huấn luyện. Những meta-features này quan trọng vì các ràng buộc khác nhau cũng yêu cầu các cấu hình AutoML khác nhau. Phát hiện này hỗ trợ mục tiêu của công trình này là xem xét cấu hình AutoML động, đặc biệt cho các thiết lập có ràng buộc. Một đặc trưng quan trọng khác là phần hold-out. Đặc biệt đối với các tập dữ liệu lớn, việc xác định kích thước mẫu phù hợp để cho phép hệ thống AutoML tạo ra bất kỳ pipeline ML nào là quan trọng. Ví dụ, đối với tập dữ liệu "KDDCup09 appetency" (50k phiên bản), phương pháp của chúng tôi chọn phần xác thực 7% dữ liệu.

Các meta-features thứ 8-15 còn lại đều bao phủ các meta-features cụ thể cho tập dữ liệu, ví dụ: về phân phối lớp và hình dạng của dữ liệu. Các meta-features đại diện cho không gian tìm kiếm siêu tham số ML

--- TRANG 15 ---
AutoML trong Các Ứng dụng Bị Ràng buộc Nghiêm ngặt 15

lấy mẫu huấn luyện lấy mẫu huấn luyện factormã hóa danh mục
FrequencyEncodingOneHotEncodingbộ phân loại
ExtraTrees
max featuresmin samples splitSVC
Ckernel: polycoef0tol

(a) Christine (thời gian tìm kiếm 1min)

trọng số lớp custom weightingbộ phân loại
BernoulliNB alphaExtraTrees
max featuresmin samples leafbootstrap: FalseKNN
n neighborsp: 2PassiveAggressive lossSGD
loss
squared hingeperceptronpenalty
l1elasticnetalphal1 ratioepsilonlearning rate: invscalingscaler StandardScaler

(b) Robert (thời gian tìm kiếm 5min)

Hình 6: Ví dụ về không gian siêu tham số ML được chọn bởi Caml Dynamic

ít quan trọng hơn, ví dụ: meta-feature của việc có sử dụng mã hóa danh mục cụ thể hay không là đặc trưng quan trọng thứ 37.

Đối với meta-model hồi quy, chúng tôi liệt kê top-15 meta-features trong Bảng 4. Các meta-features quan trọng nhất tương tự như những meta-features cho meta-model phân loại. Tuy nhiên, đối với meta-model hồi quy, meta-feature mô tả việc có sử dụng bộ tiền xử lý đặc trưng hay không và có huấn luyện tăng dần hay không. Cả hai quyết định đều có tác động đáng kể đến mức độ cấu hình AutoML đã cho vượt trội hơn cấu hình mặc định.

Bảng 5 chứa thống kê về tần suất hệ thống của chúng tôi chọn một bộ phân loại cụ thể trên 39 tập dữ liệu và số lượng bộ phân loại nó chọn trung bình. Quan sát đầu tiên là meta-model đã học được rằng việc chọn khoảng mười bộ phân loại là có lợi để đạt được balanced accuracy cao nhanh chóng. Các nhà phát triển Auto-Sklearn2 chọn chỉ 5 bộ phân loại. Tuy nhiên, vì hệ thống của chúng tôi có thể quyết định cho mỗi siêu tham số ML riêng lẻ có nên tối ưu hóa nó hay không, không gian tìm kiếm vẫn nhỏ so với nhưng tự điều chỉnh theo tập dữ liệu được chỉ định. Trái ngược với việc xây dựng Auto-Sklearn2, cách tiếp cận này hoàn toàn tự động và không yêu cầu bất kỳ chuyên môn hệ thống AutoML nào. Auto-Sklearn2 sử dụng một dynamic chọn chiến lược xác thực. Ngoài ra, không gian siêu tham số ML của nó đã được điều chỉnh thủ công cho độ chính xác và thời gian tìm kiếm. Do đó, người dùng muốn áp dụng Auto-Sklearn2 cho một thiết lập có ràng buộc mới, sẽ cần phải điều chỉnh không gian tìm kiếm siêu tham số ML thủ công lại. Hơn nữa, chúng ta thấy rằng ExtraTrees được chọn thường xuyên. Lý do là chi phí tính toán thấp và dự đoán mạnh mẽ do ensembling.

Đối với một số bộ phân loại, chẳng hạn như MLP và HGB, tần suất vẫn tương tự trên các ràng buộc thời gian tìm kiếm. Lý do là hai mặt: Đầu tiên, sử dụng huấn luyện tăng dần, chúng ta có thể nhanh chóng tạo ra các mô hình hoạt động cho cả hai loại bộ phân loại có tính cạnh tranh trên các thời gian tìm kiếm. Thứ hai, Caml đã xác định rằng những loại bộ phân loại này hoạt động tốt cho các tập dữ liệu cụ thể không thay đổi trên các ràng buộc. Ví dụ, HGB được chọn cho các tập dữ liệu cân bằng với ít hơn 8 lớp và hơn 57 đặc trưng số. MLP được chọn cho các tập dữ liệu lệch với nhiều đặc trưng danh mục.

Hơn nữa, đối với một số bộ phân loại, chẳng hạn như LDA và SVC, tần suất tăng với thời gian tìm kiếm tăng và sau đó giảm lại. Ví dụ, LDA hưởng lợi từ việc tăng số lượng phiên bản huấn luyện nhưng dễ bị overfitting cho dữ liệu không cân bằng nếu người ta tối ưu hóa nó đủ lâu. Việc huấn luyện SVC rất hiệu quả và

--- TRANG 16 ---
16 Felix Neutatz et al.

Bảng 2: Tham số AutoML được chọn bởi Caml Dynamic cho các thời gian tìm kiếm khác nhau trên tập dữ liệu "numerai28.6".

10s 1min ≥5min
augmentation
RandomADASYNclf
RF
min samples splitbootstrapAdaB. algorithm: SAMMEB.NB alphaDT
criterion: entropymax depth factorE.Trees
criterionmin samples leafbootstrap: False G.NBLSVC loss: hingeM.NB fit prior: FalseSVC
kernel
polysigmoidgammacoef0shrinking
TrueFalsetolcat. enc.
One-HotFrequency
augmentation Randomclf
AdaB.
n estimatorsalgorithm
SAMME.RSAMMEDT
criterionmin samples splitmin samples leafE.Trees
max featuresmin samples splitmin samples leafbootstrap: False
G.NBM.NBQDA reg paramSGD
alphal1 ratiotollearning rateSVC
kernel
rbfsigmoidtolLDA shrinkage factorscaler
NormalizerQuantileTransformerRobustScaler q maxcat. enc.: Label
clf
AdaB.
n estimatorslearning ratealgorithm: SAMMEmax depth
B.NBDT
criterionmax depth factormin samples splitE.Trees
criterionmin samples splitmin samples leafbootstrap: True
G.NBKNN pM.NB fit prior
TrueFalsePA CSGD
l1 ratioepsiloneta0average: FalseSVC
coef0tolcat. enc.: One-Hot
holdout: 0.45 holdout: 0.61 holdout: 0.46
ensemble: No ensemble: Yes ensemble: No
random shuffle: Yes random shuffle: No random shuffle: Yes
incremental: Yes incremental: Yes incremental: No

Bảng 3: Tầm quan trọng meta-feature của meta-model phân loại.

Hạng Meta-Feature Tầm quan trọng
1 ràng buộc kích thước pipeline 0.072
2 ràng buộc thời gian suy luận 0.053
3 ràng buộc thời gian huấn luyện 0.044
4 phần hold-out 0.036
5 ràng buộc thời gian tìm kiếm 0.023
6 số lượng đánh giá 0.022
7 ràng buộc công bằng 0.020
8 phiên bản kiểm tra hold-out 0.017
9 thời gian đánh giá 0.017
10|phiên bản | 0.016
11 ClassProbabilitySTD 0.016
12 DatasetRatio 0.015
13 ClassProbabilityMax 0.015
14 ClassProbabilityMin 0.015
15 ClassEntropy 0.015

Bảng 4: Tầm quan trọng meta-feature của meta-model hồi quy.

Hạng Meta-Feature Tầm quan trọng
1 ràng buộc kích thước pipeline 0.072
2 ràng buộc thời gian suy luận 0.056
3 ràng buộc thời gian huấn luyện 0.052
4 phần hold-out 0.043
5 ràng buộc thời gian tìm kiếm 0.024
6 preprocessor 0.023
7 ràng buộc công bằng 0.022
8 số lượng đánh giá 0.022
9 huấn luyện tăng dần 0.021
10 ClassProbabilitySTD 0.020
11 ClassProbabilityMin 0.016
12 ClassEntropy 0.016
13 ClassProbabilityMax 0.015
14 thời gian đánh giá 0.015
15 RatioNominalToNumerical 0.015

--- TRANG 17 ---
AutoML trong Các Ứng dụng Bị Ràng buộc Nghiêm ngặt 17

Bảng 5: Lựa chọn các bộ phân loại: AdaBoost (AdaB.), Bernoulli Naive Bayes (B.NB), Decision Tree (DT), Extra Trees (E.Trees), Gaussian Naive Bayes (G.NB), Histogram-based Gradient Boosting (HGB.), K-Nearest Neighbors (KNN), Linear Discriminant Analysis (LDA), Linear Support Vector Classification (LSVC), Multi-layer Perceptron (MLP), Multinomial Naive Bayes (M.NB), Passive Aggressive (PA), Quadratic Discriminant Analysis (QDA), Random Forest (RF), Stochastic Gradient Descent (SGD), Support Vector Classification (SVC).

Thời gian AdaB. B.NB DT E.Trees G.NB HGB. KNN LDA LSVC MLP M.NB PA QDA RF SGD SVC |clf.|
10s 0.69 0.79 0.54 0.90 0.51 0.31 0.62 0.59 0.54 0.49 0.44 0.51 0.67 0.31 0.69 0.74 9.33
30s 0.82 0.77 0.51 0.95 0.67 0.28 0.62 0.69 0.49 0.46 0.54 0.56 0.69 0.28 0.67 0.90 9.90
1min 0.85 0.74 0.51 0.97 0.62 0.28 0.69 0.72 0.41 0.44 0.56 0.41 0.72 0.28 0.72 0.87 9.79
5min 0.79 0.82 0.72 0.95 0.59 0.38 0.72 0.54 0.54 0.49 0.54 0.64 0.72 0.36 0.82 0.85 10.46
30min 0.79 0.82 0.72 0.95 0.59 0.38 0.72 0.54 0.54 0.49 0.54 0.64 0.72 0.36 0.82 0.85 10.46
1h 0.79 0.82 0.72 0.95 0.59 0.38 0.72 0.54 0.54 0.49 0.54 0.64 0.72 0.36 0.82 0.85 10.46

Bảng 6: Lựa chọn tham số AutoML.

Thời gian Tìm kiếm 10s 30s 1min 5min
Huấn luyện tăng dần 0.97 0.97 0.90 0.82
Ensemble 0.57 0.55 0.56 0.62
Tăng cường lớp 0.37 0.24 0.21 0.10
Xáo trộn chia xác thực 0.17 0.29 0.26 0.26

do đó, người ta có thể huấn luyện một SVC với nhiều phiên bản trong thời gian rất ít. Do đó, chúng ta thấy tần suất cao 90% cho 30s. Với thời gian tìm kiếm tăng, các mô hình phức tạp khác, chẳng hạn như RF, thay thế nó dần dần.

Cuối cùng, tần suất trên các mô hình vẫn giống nhau vì cả nhóm cấu hình mà chúng tôi lấy mẫu từ đó được tạo ra với thời gian tìm kiếm tối đa 5 phút và dữ liệu huấn luyện của mô hình chọn cấu hình có cùng giới hạn.

Để hiểu sự tương tác giữa các tham số AutoML khác, chúng tôi báo cáo trong Bảng 6 phần các tập dữ liệu mà một tham số AutoML nhất định được áp dụng. Đầu tiên, chúng ta thấy rằng lựa chọn huấn luyện tăng dần trong hầu hết các trường hợp chỉ giảm nhẹ với thời gian tìm kiếm tăng. Huấn luyện tăng dần đảm bảo rằng chúng ta tìm thấy các pipeline ML độc lập với kích thước tập dữ liệu. Model ensembling cũng được sử dụng thường xuyên vì nó đảm bảo tính mạnh mẽ. Tăng cường lớp không được áp dụng thường xuyên vì hầu hết các tập dữ liệu đã cân bằng. Ngoài ra, việc sử dụng nó giảm với thời gian tìm kiếm tăng. Lý do có thể là với thời gian tìm kiếm đủ dài, chúng ta có thể tìm thấy một mô hình phù hợp giải quyết mất cân bằng lớp bên trong. Cuối cùng, xáo trộn chia xác thực được sử dụng ngày càng nhiều với thời gian tìm kiếm tăng. Thời gian tìm kiếm lớn hơn dẫn đến số lần lặp cao hơn mà đến lượt nó làm tăng nguy cơ overfitting và xáo trộn có thể giúp giảm nguy cơ này. Theo hiểu biết tốt nhất của chúng tôi, không có hệ thống tiên tiến nào tận dụng chiến lược xáo trộn này. Kết quả của chúng tôi cho thấy nó đầy hứa hẹn và biện minh cho nghiên cứu thêm.

Lựa chọn các bộ tiền xử lý đặc trưng ngang bằng với triển khai Auto-Sklearn2. Auto-Sklearn2 không thực hiện bất kỳ tiền xử lý đặc trưng nào, và cách tiếp cận động của chúng tôi tuân theo cùng một chiến lược. Lý do là tiền xử lý đặc trưng có thể thêm nhiều overhead hơn lợi ích cho hiệu suất dự đoán.

4.2.3 Kết luận
Hệ thống AutoML đơn giản của chúng tôi với cấu hình mặc định đã có tính cạnh tranh với các hệ thống tiên tiến, chẳng hạn như AutoGluon và TPOT. Điều này có thể do thực tế là cách tiếp cận của chúng tôi tận dụng huấn luyện tăng dần, do đó, có thể xử lý các tập dữ liệu lớn. Thứ hai, cách tiếp cận cấu hình AutoML động của chúng tôi vượt trội hơn cùng hệ thống với cấu hình mặc định cho tất cả các ràng buộc thời gian tìm kiếm. Thứ ba, cách tiếp cận động của chúng tôi ngang tầm với hệ thống Auto-Sklearn2 được điều chỉnh thủ công, được điều chỉnh bởi các chuyên gia hệ thống (Auto)ML.

4.3 Hiệu quả trên Các Loại Ràng buộc Đa dạng
Để đánh giá rằng cách tiếp cận của chúng tôi cũng đạt được balanced accuracy cao cho các loại ràng buộc khác ngoài thời gian tìm kiếm, chúng tôi cung cấp các thí nghiệm với ràng buộc về kích thước pipeline ML, thời gian huấn luyện, thời gian suy luận và cơ hội bình đẳng (số liệu công bằng). Đối với thiết lập thí nghiệm, chúng tôi thu được các ngưỡng ràng buộc cho các loại ràng buộc khác nhau theo cách sau. Chúng tôi chạy các nhiệm vụ ML ngẫu nhiên trong một ngày và thu được các phân phối trên tất cả các pipeline ML được đánh giá cho tất cả các loại ràng buộc. Trên những phân phối này, chúng ta có thể tính toán các percentile khác nhau để mô phỏng các ràng buộc chặt khác nhau. Để huấn luyện meta-model, Caml Dynamic có thể tự do chọn bất kỳ percentile nào (với thời gian tìm kiếm tối đa 5 phút). Để so sánh Caml với các baseline, chúng tôi sử dụng các ràng buộc khá chặt, tức là percentile thứ 2, 4, 8, 16 và 32 của mỗi phân phối. Chúng tôi cũng đánh giá percentile thứ 1 nhưng kết quả tương tự như percentile thứ 2 và do hạn chế về không gian, chúng tôi bỏ qua các kết quả tương ứng.

Các hệ thống tiên tiến khác, chẳng hạn như AutoGluon, TPOT và Auto-Sklearn2, không hỗ trợ bản địa những ràng buộc ứng dụng ML này và không dễ dàng

--- TRANG 18 ---
18 Felix Neutatz et al.

Bảng 7: Chúng tôi báo cáo balanced accuracy cho thời gian tìm kiếm 5 phút trung bình trên 10 lần lặp lại và tập dữ liệu kiểm tra cho bốn ràng buộc.

Percentile 2% 4% 8% 16% 32%
Kích thước4026B 6651B 8359B 16797B 32266BPipeline
Auto-Sklearn2 0 .01±0.00 0 .01±0.00 0 .01±0.00 0 .01±0.00 0 .01±0.00
Spearmint 0 .04±0.02 0 .08±0.02 0 .09±0.03 0 .19±0.03 0 .22±0.03
Caml
Dynamic 0 .25±0.01 0.39±0.01∗0.43±0.00∗0.54±0.01∗0.63±0.01∗
Static 0.25±0.01∗0.39±0.01 0 .42±0.01 0 .49±0.01 0 .59±0.01
Thời gian0.009s 0.010s 0.012s 0.019s 0.078shuấn luyện
Auto-Sklearn2 0 .00±0.00 0 .00±0.00 0 .00±0.00 0 .00±0.00 0 .01±0.01
Spearmint 0 .00±0.01 0 .01±0.01 0 .00±0.01 0 .00±0.01 0 .05±0.02
Caml
Dynamic 0.61±0.01∗0.62±0.01∗0.63±0.01∗0.68±0.01∗0.71±0.00∗
Static 0 .46±0.02 0 .46±0.02 0 .50±0.02 0 .57±0.02 0 .65±0.01
Thời gian0.00079s 0.00082s 0.00102s 0.00146s 0.00302ssuy luận
Auto-Sklearn2 0 .29±0.02 0 .27±0.02 0 .27±0.03 0 .40±0.02 0 .42±0.02
Spearmint 0 .02±0.01 0 .02±0.02 0 .02±0.01 0 .02±0.01 0 .06±0.01
Caml
Dynamic 0.42±0.02∗0.45±0.02∗0.57±0.02∗0.66±0.01∗0.74±0.00∗
Static 0 .25±0.03 0 .26±0.03 0 .38±0.03 0 .52±0.02 0 .64±0.02
Cơ hội1.000 0.999 0.994 0.981 0.949Bình đẳng
Auto-Sklearn2 0.50±0.00∗0.56±0.00 0 .59±0.01 0 .63±0.00 0 .67±0.02
Spearmint 0 .17±0.10 0 .19±0.12 0 .35±0.11 0 .57±0.07 0 .58±0.07
Caml
Dynamic 0 .10±0.00 0.61±0.05∗0.64±0.01∗0.67±0.01∗0.70±0.00∗
Static 0 .10±0.00 0 .46±0.09 0 .62±0.05 0 .66±0.01 0 .68±0.01

mở rộng vì API của chúng chỉ cung cấp quyền truy cập vào các dự đoán pipeline ML. Tuy nhiên, chúng tôi đã mở rộng hệ thống AutoML hoạt động tốt nhất Auto-Sklearn2 để hỗ trợ các ràng buộc nhằm cho phép so sánh với hệ thống của chúng tôi. Hơn nữa, các hệ thống BO có ràng buộc, chẳng hạn như Spearmint [19], GPflowOpt [28], ADMMBO [2] và Ax [15], hỗ trợ các ràng buộc tùy ý cho BO. Như một đại diện của lớp hệ thống này, chúng tôi đánh giá Spearmint với không gian siêu tham số ML của hệ thống tĩnh của chúng tôi.

4.3.1 So sánh Hiệu suất
Bảng 7 cung cấp kết quả của những ngưỡng ràng buộc này. Trên các loại ràng buộc, Caml vượt trội hơn cả hai baseline một cách đáng kể. Chỉ đối với cơ hội bình đẳng, Auto-Sklearn2 đạt độ chính xác tốt nhất cho các ràng buộc công bằng rất hạn chế. Lý do là Auto-Sklearn2 sử dụng bộ phân loại Dummy nếu nó không tìm thấy mô hình nào khác. Bộ phân loại Dummy chỉ dự đoán một lớp. Bằng cách này có khả năng cả nhóm đa số và nhóm thiểu số đều có tỷ lệ dương tính thật rất tương tự và do đó cơ hội bình đẳng rất cao. Tuy nhiên, chúng tôi quyết định không bao gồm bộ phân loại dummy vì người dùng mong đợi một hệ thống AutoML khớp các mô hình ML thực tế.

Đối với ràng buộc thời gian suy luận và huấn luyện, cách tiếp cận động của chúng tôi luôn vượt trội hơn cách tiếp cận tĩnh của chúng tôi. Đối với ràng buộc kích thước pipeline, cách tiếp cận tĩnh tốt hơn cho các ngưỡng hạn chế. Lý do là kích thước pipeline liên quan nhiều hơn đến kích thước tập huấn luyện và cách tiếp cận mặc định của chúng tôi luôn sử dụng huấn luyện tăng dần. Điều đó có nghĩa là nó bắt đầu với một tập dữ liệu huấn luyện rất nhỏ. Vì vậy, nếu kích thước pipeline không được thỏa mãn cho một tập như vậy nhỏ, nó sẽ chuyển đến cấu hình siêu tham số ML tiếp theo ngay lập tức. Meta-model của chúng tôi có thể quá lạc quan và cố gắng tránh huấn luyện tăng dần nếu có thể vì nó có cơ hội cao hơn về độ chính xác cao hơn nhưng có thể bỏ lỡ việc thỏa mãn các ràng buộc.

Đối với ràng buộc công bằng, cách tiếp cận động và tĩnh hoạt động tương tự. Lý do là công bằng rất phụ thuộc vào dữ liệu. Nếu không có thông tin rõ ràng về các thuộc tính nhạy cảm, meta-model khó quyết định hơn về cấu hình hệ thống AutoML

--- TRANG 19 ---
AutoML trong Các Ứng dụng Bị Ràng buộc Nghiêm ngặt 19

0.949 0.981 0.994 0.999 1.000
Ràng buộc Cơ hội Bình đẳng0.009
0.010
0.012
0.019
0.078Ràng buộc Thời gian Huấn luyện0.03 0.11 0.18 0.28 -0.02
0.02 0.07 0.13 0.24 0.03
0.01 0.02 0.09 0.26 0.01
0.02 0.04 0.06 0.15 0.00
0.02 0.03 0.05 0.21 0.00
0.3
0.2
0.1
0.00.10.20.3
Delta Độ chính xác

Hình 7: Chúng tôi áp dụng ràng buộc thời gian huấn luyện và công bằng đồng thời và báo cáo khoảng cách tuyệt đối đến hiệu suất trung bình giữa Caml tĩnh và động. Số cao hơn là tốt hơn.

ration. Hơn nữa, meta-training cho công bằng có quyền truy cập vào ít tập dữ liệu hơn nhiều so với các ràng buộc khác. Các tập dữ liệu bổ sung có thể giúp meta-model tổng quát hóa tốt hơn. Tuy nhiên, trong trường hợp giá trị bị thiếu và ràng buộc công bằng, Caml độc lập học được chỉ chọn điền giá trị trung vị, điều này hỗ trợ phát hiện của Schelter et al. [49] rằng điền giá trị trung bình ảnh hưởng tiêu cực đến công bằng.

4.3.2 Phân tích
Để hiểu rõ hơn cách hệ thống của chúng tôi thích ứng không gian tìm kiếm siêu tham số ML tùy thuộc vào các ràng buộc ứng dụng ML, chúng tôi lấy trung bình các bộ phân loại được chọn cho mỗi ràng buộc ứng dụng ML và so sánh nó với trường hợp không sử dụng ràng buộc ứng dụng ML trong Bảng 8.

Đối với ràng buộc kích thước pipeline, Caml tránh các mô hình yêu cầu nhiều bộ nhớ hơn, chẳng hạn như extra trees (E.Trees), multi-layer perception (MLP), hoặc bộ phân loại KNN, cần lưu trữ tất cả các phiên bản huấn luyện để suy luận. Đối với ràng buộc thời gian huấn luyện, Caml chuyển nhiều hơn sang các mô hình tuyến tính, chẳng hạn như Linear Discriminant Analysis (LDA), Linear Support Vector Classification (LSVC), hoặc Passive Aggressive (PA), vì chúng có thể được huấn luyện nhanh hơn. Đối với ràng buộc thời gian suy luận, Caml chọn random forest thường xuyên hơn đáng kể để trở thành một phần của không gian tìm kiếm vì độ phức tạp suy luận của nó chỉ là O(tlogn) trong đó t là số lượng cây và n là số lượng phiên bản. Đối với cơ hội bình đẳng, Caml tránh các mô hình khuếch đại thiên vị trong dữ liệu. Ví dụ, KNN có thể khuếch đại thiên vị vì nó luôn quyết định dựa trên đa số của các láng giềng gần nhất. Những insights này xác nhận rằng chúng ta không thể tối ưu hóa một hệ thống AutoML cho một ràng buộc và mong đợi rằng cùng một tối ưu hóa cũng sẽ có lợi cho các ràng buộc khác.

4026 6651 835916797 32266
Ràng buộc Kích thước Pipeline0.00079
0.00082
0.00102
0.00146
0.00302Ràng buộc Thời gian Suy luận0.05 0.05 0.09 0.09 0.10
0.05 0.05 0.08 0.08 0.08
0.04 0.00 0.03 0.04 0.09
0.02 0.02 0.05 -0.00 0.03
-0.02 -0.00 -0.01 0.01 0.09
0.3
0.2
0.1
0.00.10.20.3
Delta Độ chính xác

Hình 8: Chúng tôi áp dụng ràng buộc thời gian suy luận và kích thước pipeline đồng thời và báo cáo khoảng cách tuyệt đối đến hiệu suất trung bình giữa Caml tĩnh và động. Số cao hơn là tốt hơn.

4.4 Hiệu quả trên Nhiều Loại Ràng buộc
Trên thực tế, các ứng dụng ML có thể bị ràng buộc theo nhiều chiều đồng thời. Để đánh giá hệ thống của chúng tôi cho nhiều ràng buộc đồng thời, chúng tôi chọn hai kết hợp ràng buộc thời gian huấn luyện/cơ hội bình đẳng và thời gian suy luận/kích thước pipeline. Đối với cả hai kết hợp ràng buộc, chúng tôi áp dụng tất cả các kết hợp ngưỡng đã được đánh giá trong Phần 4.3. Chúng tôi báo cáo sự khác biệt trong balanced accuracy trung bình mà Caml Dynamic vượt trội hơn biến thể tĩnh trong Hình 7 và 8.

Trong gần như tất cả các thí nghiệm, Caml Dynamic vượt trội hơn biến thể tĩnh hoặc đạt hiệu suất dự đoán tương tự. Chỉ đối với các ràng buộc rất hạn chế, chẳng hạn như 100% cơ hội bình đẳng hoặc kích thước pipeline 4026B, hiệu suất của nó thấp hơn một chút vì những ràng buộc này đối với một số tập dữ liệu kiểm tra không thể thỏa mãn được. Nhìn chung, các thí nghiệm cho thấy Caml Dynamic thậm chí hoạt động cho nhiều ràng buộc. Phát hiện này cho thấy cách tiếp cận meta-learning của chúng tôi học được cách những ràng buộc khác nhau này tương tác với nhau. Trong 65% các trường hợp, Caml chọn các cấu hình AutoML xem xét hai ràng buộc đồng thời và không bao giờ được chọn cho các trường hợp mà chúng tôi thực thi chỉ một trong các ràng buộc.

4.5 Lấy mẫu Xen kẽ vs Lấy mẫu Ngẫu nhiên
Một quyết định thiết kế chính của hệ thống của chúng tôi là tận dụng active learning bổ sung cho lấy mẫu ngẫu nhiên để khám phá không gian khổng lồ của các tham số AutoML và ràng buộc hiệu quả hơn. Bảng 9 cung cấp balanced accuracy cho các meta-models cho cả hai cách tiếp cận lấy mẫu trên hai tuần tạo dữ liệu huấn luyện.

Cách tiếp cận lấy mẫu xen kẽ vượt trội hơn lấy mẫu ngẫu nhiên một cách đáng kể. Lý do là active learning đảm bảo rằng chúng ta lấy mẫu dọc theo ranh giới quyết định

--- TRANG 20 ---
20 Felix Neutatz et al.

Bảng 8: Chúng tôi báo cáo sự khác biệt tỷ lệ phần trăm trung bình trong lựa chọn bộ phân loại ML tùy thuộc vào ràng buộc ứng dụng ML.

Ràng buộc ỨngAdaB. B.NB DT E.Trees G.NB HGB. KNN LDA LSVC MLP M.NB PA QDA RF SGD SVCdụng ML
Không có 0.79 0.82 0.72 0.95 0.59 0.38 0.72 0.54 0.54 0.49 0.54 0.64 0.72 0.36 0.82 0.85
Kích thước Pipeline -0.19 -0.43 -0.15 -0.38 -0.07 +0.06 -0.19 +0.03 -0.01 -0.20 -0.25 -0.25 -0.14 -0.03 -0.24 -0.30
Thời gian Huấn luyện +0.07 -0.04 +0.03 +0.00 -0.17 +0.00 +0.03 +0.26 +0.21 -0.09 +0.05 +0.12 +0.03 +0.02 +0.08 +0.09
Thời gian Suy luận -0.12 +0.03 -0.01 -0.09 +0.14 +0.12 -0.13 +0.16 +0.14 +0.20 +0.16 +0.06 +0.00 +0.40 -0.19 -0.01
Cơ hội Bình đẳng -0.23 -0.02 +0.12 -0.11 -0.23 -0.22 -0.52 +0.06 +0.14 +0.19 -0.26 -0.24 -0.12 -0.16 -0.10 -0.01

Bảng 9: Hiệu suất dự đoán theo thời gian meta-training. Chúng tôi báo cáo balanced accuracy trung bình theo thời gian huấn luyện trung bình trên 10 lần lặp lại và 39 tập dữ liệu so sánh hệ thống của chúng tôi với lấy mẫu ngẫu nhiên và xen kẽ.

Ngày Xen kẽ Ngẫu nhiên
2 0.70±0.01∗0.67±0.01
4 0.72±0.01∗0.65±0.02
6 0 .70±0.01 0.71±0.01∗
8 0.72±0.01∗0.71±0.02
10 0.73±0.01∗0.72±0.01
12 0.73±0.01∗0.69±0.01
14 0.74±0.00∗0.72±0.01

về việc liệu một cấu hình AutoML đã cho có vượt trội hơn cấu hình mặc định hay không, trong khi lấy mẫu ngẫu nhiên đảm bảo tính đa dạng trong dữ liệu huấn luyện. Tuân theo chiến lược lấy mẫu ngẫu nhiên thuần túy dẫn đến hiệu suất dự đoán cuối cùng thấp hơn và ít tăng trưởng nhất quán hơn. Ví dụ, sau 12 ngày lấy mẫu ngẫu nhiên, chúng ta đạt hiệu suất dự đoán tệ hơn so với sáu ngày lấy mẫu.

Chúng ta có thể tận dụng Bảng 9 cũng để hiểu tác động của thời gian huấn luyện. Các con số cho thấy thời gian huấn luyện nhiều hơn có lợi cho meta-model, và ngay cả vào ngày thứ 14, chúng ta thu được 1% nhiều hơn trong balanced accuracy trung bình. Để kết luận, lấy mẫu xen kẽ vượt trội hơn lấy mẫu ngẫu nhiên một cách đáng kể, và càng huấn luyện lâu, cấu hình AutoML động càng hoạt động tốt hơn.

4.6 Khai thác Cấu hình AutoML
Một câu hỏi quan trọng khác cho cách tiếp cận của chúng tôi là chúng ta cần bao nhiêu cấu hình AutoML đầy hứa hẹn để khai thác để đạt được hiệu suất dự đoán cao. Do đó, chúng tôi thử nghiệm, cho ràng buộc thời gian tìm kiếm 5min, với các phần khác nhau của các cấu hình AutoML mà chúng tôi khai thác trong hai tuần. Chúng tôi báo cáo kết quả trong Bảng 10. Với số lượng cấu hình AutoML được khai thác tăng, hiệu suất dự đoán cũng tăng. Tăng độ chính xác theo phần trăm có thể có vẻ nhỏ nhưng nó đáng kể theo kiểm tra hạng Mann-Whitney U

Bảng 10: Hiệu suất dự đoán trên số lượng cấu hình AutoML được khai thác khác nhau cho thời gian tìm kiếm 5min. Chúng tôi báo cáo balanced accuracy trung bình theo thời gian huấn luyện trung bình trên 10 lần lặp lại và 39 tập dữ liệu.

Phần # Cấu hình Độ chính xác
0.0002 3 0 .729±0.00
0.0005 6 0 .734±0.00
0.0010 12 0 .736±0.00
0.0020 23 0 .732±0.00
0.0039 47 0 .736±0.00
0.0078 93 0 .734±0.01
0.0156 186 0 .739±0.01
0.0313 372 0 .739±0.01
0.0625 744 0 .739±0.01
0.1250 1489 0 .735±0.01
0.2500 2978 0 .744±0.00
0.5000 5956 0 .743±0.00
1.0000 11911 0 .747±0.00

test. Hơn nữa, càng có nhiều ràng buộc chúng ta thêm vào, nhóm cấu hình AutoML được khai thác càng cần đa dạng để đạt hiệu suất dự đoán cao trên tất cả các ràng buộc.

4.7 Điều chỉnh theo Phần cứng Khác nhau
Để đánh giá cách tiếp cận hiệu chuẩn được mô tả trong Phần 3.1.4 cho phép chúng tôi áp dụng Caml trên bất kỳ máy nào, chúng tôi tiến hành các thí nghiệm bổ sung trên một máy tính mạnh mẽ với Intel(R) Core(TM) i7-8565U CPU @ 1.80 GHz và 38 GB RAM. Để đánh giá cả hai máy, chúng tôi chạy Caml Static cho tập dữ liệu "riccardo" trong 10 phút cho 10 lần và đo balanced accuracy xác thực trung bình trên thời gian tìm kiếm như được báo cáo trong Hình 3. Chúng tôi chọn tập dữ liệu này vì nó có 20k phiên bản và 4k đặc trưng, và mất nhiều thời gian hơn để hội tụ để tìm một mô hình hoạt động tốt. Nếu dữ liệu quá đơn giản, chúng ta không thể so sánh tốt sự hội tụ theo thời gian. Sau đó, chúng tôi tiến hành các thí nghiệm cho thời gian tìm kiếm từ 10s đến 5min trên máy mới với và không có điều chỉnh phần cứng

--- TRANG 21 ---
AutoML trong Các Ứng dụng Bị Ràng buộc Nghiêm ngặt 21

Bảng 11: Ràng buộc thời gian tìm kiếm: Balanced accuracy trung bình trên 10 lần lặp lại và 39 tập dữ liệu so sánh Caml với Caml được điều chỉnh phần cứng.

Chiến lược Caml 10s 30s 1 min 5 min
Static 0 .59±0.01 0 .66±0.01 0 .68±0.01 0 .71±0.01
Dynamic 0 .63±0.01 0 .70±0.01 0 .72±0.01 0 .76±0.00
Dynamic (adjusted) 0 .67±0.01 0 .71±0.01 0 .72±0.01 0 .76±0.00

1 2 3 4 5 6 700.20.40.60.81
Thời gian Meta-Training (d)Điểm F1 Meta-Model2 ràng buộc
3 ràng buộc
4 ràng buộc
5 ràng buộc

Hình 9: Điểm F1 Meta-Training Model dưới số lượng ràng buộc khác nhau và thời gian meta-training khác nhau.

như được báo cáo trong Bảng 11. Đầu tiên, chúng ta thấy rằng ngay cả khi không có điều chỉnh phần cứng, Caml Dynamic vẫn vượt trội hơn phiên bản tĩnh. Với điều chỉnh phần cứng, cho 10s và 30s, balanced accuracy trung bình cải thiện 4% và 1% tương ứng. Vì vậy, chúng tôi kết luận đối với ngân sách tìm kiếm nhỏ, điều chỉnh phần cứng cải thiện hệ thống của chúng tôi. Phát hiện này cũng giảm chi phí của benchmark offline vì Caml có thể chạy benchmark tối đa 10 phút và tắt ánh xạ cho thời gian tìm kiếm lớn hơn.

4.8 Tác động của Số lượng Ràng buộc lên Meta-Training
Để phân tích tác động của số lượng ràng buộc lên hiệu suất meta-learning, chúng tôi chạy meta-training với tối đa 5 ràng buộc, 4 ràng buộc ứng dụng ML và ràng buộc thời gian tìm kiếm bắt buộc.

Để so sánh hiệu suất trên các kết hợp ràng buộc, cho mỗi kết hợp, chúng tôi chọn ngẫu nhiên các cấu hình ngẫu nhiên, ngưỡng ràng buộc và tập dữ liệu và đánh giá liệu cấu hình tương ứng có hoạt động tốt hơn cấu hình mặc định hay không. Chúng tôi thu thập tập kiểm tra này trong 1 tuần cho mỗi kết hợp ràng buộc. Sau đó, cho mỗi số lượng ràng buộc, chúng tôi áp dụng meta-training xen kẽ của chúng tôi trong 1 tuần. Cuối cùng, chúng tôi báo cáo điểm F1 của meta-model trên mỗi tập kiểm tra báo cáo liệu cấu hình tương ứng có vượt trội hơn cấu hình mặc định ít nhất một lần hay không. Chúng tôi báo cáo điểm F1 trung bình tương ứng trên 5 lần lặp lại cho mỗi ngày trong tuần meta-training trong Hình 9.

Với thời gian meta-training tăng, điểm F1 của meta-model tăng cho tất cả số lượng ràng buộc được xem xét. Sau một tuần, tất cả kết hợp ràng buộc đạt điểm F1 cao hơn 79%. Như mong đợi, bằng cách thêm các ràng buộc bổ sung, điểm F1 giảm nhẹ lên đến 3%, điều này khá nhỏ xem xét độ phức tạp được nhân lên của không gian tìm kiếm kết quả. Phân tích này có thể giúp ước tính thời gian cần thiết để tạo dữ liệu huấn luyện đủ cho các không gian tìm kiếm lớn hơn.

5 Công trình Liên quan
Công trình của chúng tôi về AutoML dựa trên ràng buộc kết hợp nghiên cứu từ các lĩnh vực khác nhau của tối ưu hóa, AutoML và meta-learning.

Tối ưu hóa Có ràng buộc. Một hướng công trình giải quyết tối ưu hóa có ràng buộc bằng cách học một mô hình surrogate ước tính liệu các cấu hình được lấy mẫu có vi phạm các ràng buộc tương ứng hay không [19,46,28,2, 35]. Tuy nhiên, cách tiếp cận này có hai nhược điểm. Đầu tiên, nó yêu cầu các mô hình surrogate học các ràng buộc mỗi lần từ đầu. Thứ hai, nó không thể điều chỉnh các tham số của các hệ thống AutoML, chẳng hạn như cách tiếp cận xác thực hoặc chiến lược tìm kiếm, theo nhiệm vụ ML tương ứng.

Meta-Learning. Một cách tiếp cận hiệu quả hơn là học trước liệu một pipeline ML đã cho có thỏa mãn một ràng buộc nổi tiếng hay không, chẳng hạn như thời gian huấn luyện [37]. Cách tiếp cận này không yêu cầu học ràng buộc mỗi lần từ đầu. Tuy nhiên, nó không điều chỉnh các tham số AutoML. Một hướng khác là meta-optimize các tham số AutoML. Ví dụ, Lindauer et al. [34] tối ưu hóa các tham số của tối ưu hóa siêu tham số. Tuy nhiên, họ không xem xét ràng buộc. Hơn nữa, Auto-Sklearn 2 [17] chỉ hỗ trợ dự đoán các quyết định chiến lược rời rạc sử dụng mô hình theo cặp. Do đó, cách tiếp cận của họ không hỗ trợ các siêu tham số AutoML liên tục và không mở rộng đến hàng trăm thiết lập. Vấn đề khả năng mở rộng này cũng cản trở dự đoán chiến lược chung vì không gian tổ hợp quá lớn.

Van Rijn et al. tận dụng meta-learning để xác định siêu tham số quan trọng nhất cho các mô hình ML khác nhau riêng lẻ [48]. Tuy nhiên, họ không xem xét ràng buộc. Alpine Meadow [54] sử dụng lịch sử của chất lượng và chi phí của tất cả các pipeline đã chạy cho đến nay để khởi động ấm tìm kiếm, nhưng cũng không thể xử lý ràng buộc.

Tăng tốc AutoML. Hơn nữa, có một nỗ lực lớn trong cộng đồng quản lý dữ liệu để tăng tốc các hệ thống AutoML. Ví dụ, Li et al. đề xuất tận dụng phân rã không gian tìm kiếm [33]. Yakovlev et al. đề xuất tận dụng các mô hình proxy, tối ưu hóa không lặp và giảm dữ liệu thích ứng để tăng tốc tối ưu hóa siêu tham số [60]. Một cách tiếp cận nổi tiếng khác để tăng tốc tối ưu hóa siêu tham số là tận dụng successive halving [31,16]. Nó bắt đầu bằng việc đánh giá nhiều cấu hình trên một ngân sách nhỏ và dần dần chọn nửa tốt nhất của các cấu hình để đánh giá chúng trên một ngân sách lớn hơn. Xin et al. tận dụng caching để tăng tốc tối ưu hóa siêu tham số [59]. Tuy nhiên, các chiến lược của họ không thể được áp dụng trong trường hợp xáo trộn chia xác thực. Nakandala et al. đề xuất một chiến lược thực thi SGD song song mới để tăng tốc tối ưu hóa siêu tham số cho các mô hình dựa trên SGD [38]. Hilprecht et al. [25] đề xuất làm cho các pipeline ML có thể phân biệt từ đầu đến cuối để tránh tối ưu hóa Bayesian tốn kém. SystemDS [4,5] cho phép người dùng chỉ định các chương trình ML trong một ngôn ngữ khai báo giống R và biên dịch nó thành mã hiệu quả cao cụ thể cho phần cứng có thể được phân phối. Shah et al. [53] đánh giá rộng rãi phát hiện loại đặc trưng quan trọng vì hệ thống AutoML downstream phụ thuộc vào phân loại loại đặc trưng đúng. Các hệ thống và thuật toán đã nêu ở trên trực giao với đóng góp của chúng tôi vì chúng không xem xét không gian tìm kiếm của AutoML mà tối ưu hóa tính toán cho huấn luyện và điều chỉnh tham số.

6 Kết luận
Chúng tôi đã đề xuất tích hợp các ràng buộc như một công dân hạng nhất vào AutoML - một mô hình mà chúng tôi gọi là AutoML dựa trên ràng buộc. Vì các ràng buộc đặt ra hạn chế đối với việc tìm kiếm siêu tham số, chúng tôi đề xuất một cách tiếp cận để thay đổi động không gian tìm kiếm AutoML cho các ràng buộc hiện có. Để đạt được mục tiêu này, chúng tôi tận dụng active meta-learning. Để khám phá không gian khổng lồ của các tập dữ liệu, cấu hình AutoML và ràng buộc, chúng tôi lấy mẫu những kết hợp có lợi cho meta-model. Để cho thấy lợi ích đầy đủ của cách tiếp cận này, chúng tôi phát triển một hệ thống AutoML đơn giản có thể điều chỉnh, Caml, hiển thị toàn bộ không gian siêu tham số ML của nó như các tham số AutoML nhị phân để có một không gian tìm kiếm cụ thể cho nhiệm vụ. Bằng cách này, Caml Dynamic có thể quyết định cho mỗi siêu tham số ML đơn lẻ có nên tối ưu hóa nó hay không. Nó tự động chọn một không gian siêu tham số ML cho các ràng buộc thời gian tìm kiếm tương tự như không gian được bao phủ bởi hệ thống Auto-Sklearn2 [17] được điều chỉnh thủ công. Nhìn chung, cách tiếp cận mới của chúng tôi cho phép các hệ thống AutoML chung có thể cấu hình thích ứng động với nhiệm vụ và ràng buộc hiện có, và do đó tăng thêm khả năng áp dụng của các hệ thống AutoML trong ứng dụng thực tế.

Tài liệu tham khảo
1. Akiba, T., Sano, S., Yanase, T., Ohta, T., Koyama, M.: Optuna: A next-generation hyperparameter optimization framework. In: SIGKDD (2019)
2. Ariafar, S., Coll-Font, J., Brooks, D.H., Dy, J.G.: ADMMBO: bayesian optimization with unknown constraints using ADMM. J. Mach. Learn. Res. 20, 123:1–123:26 (2019)
3. Bergstra, J.S., Bardenet, R., Bengio, Y., Kégl, B.: Algorithms for hyper-parameter optimization. In: NeurIPS, pp. 2546–2554 (2011)
4. Boehm, M., Antonov, I., Baunsgaard, S., Dokter, M., Ginthör, R., Innerebner, K., Klezin, F., Lindstaedt, S.N., Phani, A., Rath, B., Reinwald, B., Siddiqui, S., Wrede, S.B.: SystemDS: A declarative machine learning system for the end-to-end data science lifecycle. In: CIDR (2020)
5. Boehm, M., Dusenberry, M., Eriksson, D., Evfimievski, A.V., Manshadi, F.M., Pansare, N., Reinwald, B., Reiss, F., Sen, P., Surve, A., Tatikonda, S.: Systemml: Declarative machine learning on spark. Proc. VLDB Endow. 9(13), 1425–1436 (2016)
6. Caruana, R., Niculescu-Mizil, A., Crew, G., Ksikes, A.: Ensemble selection from libraries of models. In: ICML, vol. 69 (2004)
7. Castiello, C., Castellano, G., Fanelli, A.M.: Meta-data: Characterization of input features for meta-learning. In: MDAI, vol. 3558, pp. 457–468 (2005)
8. Chaudhuri, K., Monteleoni, C., Sarwate, A.D.: Differentially private empirical risk minimization. JMLR 12(Mar), 1069–1109 (2011)
9. Chawla, N.V., Bowyer, K.W., Hall, L.O., Kegelmeyer, W.P.: SMOTE: synthetic minority over-sampling technique. J. Artif. Intell. Res. 16, 321–357 (2002)
10. Delangue, C., al.: Hugging face (2023). URL https://huggingface.co
11. Derakhshan, B., Mahdiraji, A.R., Rabl, T., Markl, V.: Continuous deployment of machine learning pipelines. In: Advances in Database Technology - 22nd International Conference on Extending Database Technology, EDBT 2019, Lisbon, Portugal, March 26-29, 2019, pp. 397–408 (2019)
12. Ding, F., Hardt, M., Miller, J., Schmidt, L.: Retiring adult: New datasets for fair machine learning. Advances in Neural Information Processing Systems 34(2021)

--- TRANG 23 ---
AutoML trong Các Ứng dụng Bị Ràng buộc Nghiêm ngặt 23

13. Elluswamy, A.: Occupancy networks. https://www.youtube.com/watch?v=jPCV4GKX9Dw (2022)
14. Erickson, N., Mueller, J., Shirkov, A., Zhang, H., Larroy, P., Li, M., Smola, A.J.: Autogluon-tabular: Robust and accurate automl for structured data. CoRR abs/2003.06505 (2020)
15. Facebook: Adaptive experimentation platform (2021). URL https://ax.dev/
16. Falkner, S., Klein, A., Hutter, F.: BOHB: robust and efficient hyperparameter optimization at scale. In: ICML, vol. 80, pp. 1436–1445 (2018)
17. Feurer, M., Eggensperger, K., Falkner, S., Lindauer, M., Hutter, F.: Auto-sklearn 2.0: Hands-free automl via meta-learning. JMLR 23(261), 1–61 (2022)
18. Feurer, M., Klein, A., Eggensperger, K., Springenberg, J.T., Blum, M., Hutter, F.: Efficient and robust automated machine learning. In: NeurIPS, pp. 2962–2970 (2015)
19. Gelbart, M.A., Snoek, J., Adams, R.P.: Bayesian optimization with unknown constraints. In: UAI, pp. 250–259 (2014)
20. Ghodsnia, P., Bowman, I.T., Nica, A.: Parallel I/O aware query optimization. In: SIGMOD, pp. 349–360 (2014)
21. Ghosh, D., Gupta, P., Mehrotra, S., Yus, R., Altowim, Y.: JENNER: just-in-time enrichment in query processing. Proc. VLDB Endow. 15(11), 2666–2678 (2022)
22. Hardt, M., Price, E., Srebro, N.: Equality of opportunity in supervised learning. In: NeurIPS, pp. 3315–3323 (2016)
23. He, H., Bai, Y., Garcia, E.A., Li, S.: ADASYN: adaptive synthetic sampling approach for imbalanced learning. In: IJCNN, pp. 1322–1328 (2008)
24. Hilprecht, B., Hammacher, C., Reis, E., Abdelaal, M., Binnig, C.: Diffml: End-to-end differentiable ML pipelines. CoRR abs/2207.01269 (2022)
25. Hilprecht, B., Hammacher, C., Reis, E., Abdelaal, M., Binnig, C.: Diffml: End-to-end differentiable ML pipelines. In: DEEM/SIGMOD, pp. 7:1–7:7 (2023)
26. Kaoudi, Z., Quiané-Ruiz, J.A., Thirumuruganathan, S., Chawla, S., Agrawal, D.: A cost-based optimizer for gradient descent optimization. In: SIGMOD, pp. 977–992 (2017)
27. Kelly, M., Longjohn, R., Nottingham, K.: UCI ml repository (2023). URL https://archive.ics.uci.edu
28. Knudde, N., van der Herten, J., Dhaene, T., Couckuyt, I.: Gpflowopt: A bayesian optimization library using tensorflow. arXiv preprint arXiv:1711.03845 (2017)
29. Kumar, A., Boehm, M., Yang, J.: Data management in machine learning: Challenges, techniques, and systems. In: SIGMOD, p. 1717–1722 (2017). DOI 10.1145/3035918.3054775
30. Lévesque, J.C.: Bayesian hyperparameter optimization: overfitting, ensembles and conditional spaces (2018)
31. Li, L., Jamieson, K.G., DeSalvo, G., Rostamizadeh, A., Talwalkar, A.: Hyperband: A novel bandit-based approach to hyperparameter optimization. J. Mach. Learn. Res.18, 185:1–185:52 (2017)
32. Li, T., Sahu, A.K., Talwalkar, A., Smith, V.: Federated learning: Challenges, methods, and future directions. IEEE Signal Process. Mag. 37(3), 50–60 (2020)
33. Li, Y., Shen, Y., Zhang, W., Jiang, J., Li, Y., Ding, B., Zhou, J., Yang, Z., Wu, W., Zhang, C., Cui, B.: Volcanoml: Speeding up end-to-end automl via scalable search space decomposition. Proc. VLDB Endow. 14(11), 2167–2176 (2021)
34. Lindauer, M., Feurer, M., Eggensperger, K., Biedenkapp, A., Hutter, F.: Towards assessing the impact of bayesian optimization's own hyperparameters. In: IJCAI 2019 DSO Workshop (2019). URL https://arxiv.org/abs/1908.06674
35. Liu, S., Ram, P., Vijaykeerthy, D., Bouneffouf, D., Bramble, G., Samulowitz, H., Wang, D., Conn, A., Gray, A.G.: An ADMM based framework for automl pipeline configuration. In: AAAI, pp. 4892–4899 (2020)
36. Mehra, A., Mandal, M., Narang, P., Chamola, V.: Reviewnet: A fast and resource optimized network for enabling safe autonomous driving in hazy weather conditions. IEEE Trans. Intell. Transp. Syst. 22(7), 4256–4266 (2021)
37. Mohr, F., Wever, M., Tornede, A., Hullermeier, E.: Predicting machine learning pipeline runtimes in the context of automated machine learning. PAMI (2021)
38. Nakandala, S., Zhang, Y., Kumar, A.: Cerebro: A data system for optimized deep learning model selection. Proc. VLDB Endow. 13(11), 2159–2173 (2020)
39. Neutatz, F.: Constraint-Driven AutoML. https://github.com/BigDaMa/DeclarativeAutoML (2022)
40. Neutatz, F.: Search space (2023). URL https://github.com/BigDaMa/DeclarativeAutoML/ blob/main/images/treespace.pdf
41. Neutatz, F., Biessmann, F., Abedjan, Z.: Enforcing constraints for machine learning systems via declarative feature selection: An experimental study. In: SIGMOD, pp. 1345–1358 (2021)
42. Nishihara, R., Moritz, P., Wang, S., Tumanov, A., Paul, W., Schleier-Smith, J., Liaw, R., Niknami, M., Jordan, M.I., Stoica, I.: Real-time machine learning: The missing pieces. In: HotOS, pp. 106–110 (2017)
43. Olson, R.S., Moore, J.H.: TPOT: A tree-based pipeline optimization tool for automating machine learning. In: Automated Machine Learning - Methods, Systems, Challenges, The Springer Series on Challenges in Machine Learning, pp. 151–160. Springer (2019)
44. Paleyes, A., Pullin, M., Mahsereci, M., McCollum, C., Lawrence, N., González, J.: Emulation of physical processes with emukit. In: NeurIPS (2019)
45. Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., Blondel, M., Prettenhofer, P., Weiss, R., Dubourg, V., Vanderplas, J., Passos, A., Cournapeau, D., Brucher, M., Perrot, M., Duchesnay, E.: Scikit-learn: Machine learning in Python. JMLR 12, 2825–2830 (2011)
46. Perrone, V., Donini, M., Kenthapadi, K., Archambeau, C.: Fair bayesian optimization. arXiv preprint arXiv:2006.05109 (2020)
47. Ré, C.: Overton: A data system for monitoring and improving machine-learned products. In: CIDR (2020)
48. van Rijn, J.N., Hutter, F.: Hyperparameter importance across datasets. In: KDD, pp. 2367–2376 (2018)
49. Schelter, S., He, Y., Khilnani, J., Stoyanovich, J.: FairPrep: promoting data to a first-class citizen in studies on fairness-enhancing interventions. In: EDBT, pp. 395–398 (2020)
50. Sculley, D., al.: Kaggle (2023). URL https://www.kaggle.com
51. Settles, B.: Active learning literature survey (2009)
52. Shafique, M., Theocharides, T., Reddy, V.J., Murmann, B.: Tinyml: Current progress, research challenges, and future roadmap. In: DAC, pp. 1303–1306 (2021)
53. Shah, V., Lacanlale, J., Kumar, P., Yang, K., Kumar, A.: Towards benchmarking feature type inference for automl platforms. In: SIGMOD, pp. 1584–1596 (2021)

--- TRANG 24 ---
24 Felix Neutatz et al.

54. Shang, Z., Zgraggen, E., Buratti, B., Kossmann, F., Eichmann, P., Chung, Y., Binnig, C., Upfal, E., Kraska, T.: Democratizing data science through interactive curation of ml pipelines. In: SIGMOD, pp. 1171–1188 (2019)
55. Sparks, E.R., Venkataraman, S., Kaftan, T., Franklin, M.J., Recht, B.: Keystoneml: Optimizing pipelines for large-scale advanced analytics. In: ICDE, pp. 535–546 (2017)
56. Thornton, C., Hutter, F., Hoos, H.H., Leyton-Brown, K.: Auto-weka: combined selection and hyperparameter optimization of classification algorithms. In: KDD, pp. 847–855 (2013)
57. Vanschoren, J.: Meta-learning. In: Automated Machine Learning - Methods, Systems, Challenges, The Springer Series on Challenges in Machine Learning, pp. 35–61 (2019)
58. Vanschoren, J., van Rijn, J.N., Bischl, B., Torgo, L.: OpenML: Networked science in machine learning. SIGKDD Explorations 15(2), 49–60 (2013)
59. Xin, D., Macke, S., Ma, L., Liu, J., Song, S., Parameswaran, A.: Helix: Holistic optimization for accelerating iterative machine learning. PVLDB 12(4), 446–460 (2018)
60. Yakovlev, A., Moghadam, H.F., Moharrer, A., Cai, J., Chavoshi, N., Varadarajan, V., Agrawal, S.R., Idicula, S., Karnagel, T., Jinturkar, S., et al.: Oracle automl: a fast and predictive automl pipeline. PVLDB 13(12), 3166–3180 (2020)
61. Yang, J., He, Y., Chaudhuri, S.: Auto-pipeline: Synthesize data pipelines by-target using reinforcement learning and search. Proc. VLDB Endow. 14(11), 2563–2575 (2021)
62. Yu, Y., Qian, H., Hu, Y.: Derivative-free optimization via classification. In: AAAI, pp. 2286–2292 (2016)
63. Zhang, J.M., Harman, M., Ma, L., Liu, Y.: Machine learning testing: Survey, landscapes and horizons. IEEE Trans. Softw. Eng. (2020)
64. Zhang, S., Yang, F., Zhou, D., Zeng, X.: An efficient asynchronous batch bayesian optimization approach for analog circuit synthesis. In: DAC, pp. 1–6 (2020)

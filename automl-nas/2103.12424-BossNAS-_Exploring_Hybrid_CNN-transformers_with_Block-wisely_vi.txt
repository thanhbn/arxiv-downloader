# 2103.12424.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/automl-nas/2103.12424.pdf
# Kích thước file: 5533096 bytes

===============================================
NỘI DUNG FILE PDF
===============================================


--- TRANG 1 ---
BossNAS: Khám phá CNN-transformer lai với Tìm kiếm Kiến trúc Neural
Tự giám sát theo Block

Changlin Li1, Tao Tang2, Guangrun Wang3;4, Jiefeng Peng3, Bing Wang5,
Xiaodan Liang2*, Xiaojun Chang6
1GORSE Lab, Dept. of DSAI, Monash University2Sun Yat-sen University3DarkMatter AI Research
4University of Oxford5Alibaba Group6RMIT University
changlin.li@monash.edu,
ftrent.tangtao,wanggrun,jiefengpeng,xdliang328 g@gmail.com,
fengquan.wb@alibaba-inc.com, xiaojun.chang@rmit.edu.au

Tóm tắt
Vô số những đột phá gần đây trong các kiến trúc neural thiết kế thủ công cho nhận dạng thị giác đã làm nổi bật nhu cầu cấp thiết trong việc khám phá các kiến trúc lai bao gồm các khối xây dựng đa dạng. Trong khi đó, các phương pháp tìm kiếm kiến trúc neural đang gia tăng mạnh với kỳ vọng giảm bớt công sức con người. Tuy nhiên, liệu các phương pháp NAS có thể xử lý hiệu quả và hiệu suất không gian tìm kiếm đa dạng với các ứng viên khác biệt (ví dụ CNN và transformer) vẫn còn là một câu hỏi mở. Trong công trình này, chúng tôi trình bày Block-wisely Self-supervised Neural Architecture Search (BossNAS), một phương pháp NAS không giám sát giải quyết vấn đề đánh giá kiến trúc không chính xác gây ra bởi không gian chia sẻ trọng số lớn và giám sát thiên vị trong các phương pháp trước đó. Cụ thể hơn, chúng tôi phân tích không gian tìm kiếm thành các khối và sử dụng một sơ đồ huấn luyện tự giám sát mới, được gọi là ensemble bootstrapping, để huấn luyện từng khối riêng biệt trước khi tìm kiếm chúng như một tổng thể hướng về trung tâm quần thể. Ngoài ra, chúng tôi trình bày không gian tìm kiếm HyTra, một không gian tìm kiếm CNN-transformer lai giống như vải với các vị trí downsampling có thể tìm kiếm. Trên không gian tìm kiếm đầy thách thức này, mô hình được tìm kiếm của chúng tôi, BossNet-T, đạt độ chính xác lên đến 82,5% trên ImageNet, vượt trội EfficientNet 2,4% với thời gian tính toán tương đương. Hơn nữa, phương pháp của chúng tôi đạt được độ chính xác đánh giá kiến trúc vượt trội với tương quan Spearman 0,78 và 0,76 trên không gian tìm kiếm MBConv chuẩn với ImageNet và trên không gian tìm kiếm size NATS-Bench với CIFAR-100, tương ứng, vượt qua các phương pháp NAS tiên tiến.1

1. Giới thiệu
Sự phát triển của các kiến trúc mạng neural đã mang lại tiến bộ đáng kể trong một loạt các nhiệm vụ nhận dạng thị giác trong vài năm qua. Các ví dụ tiêu biểu của những mô hình như vậy bao gồm ResNet [25], SENet [31], MobileNet [30] và EfficientNet [64]. Gần đây, các kiến trúc dựa trên attention mới nổi đang đến tiền cảnh trong lĩnh vực thị giác máy tính, thách thức sự thống trị của mạng neural tích chập (CNN). Đột phá thú vị này trong vision transformer dẫn đầu bởi ViT [20] và DETR [8], đang đạt được hiệu suất cạnh tranh trên nhiều nhiệm vụ thị giác khác nhau, như phân loại hình ảnh [20,66,79,14,9], phát hiện đối tượng [8,90,62], phân đoạn ngữ nghĩa [88], và các nhiệm vụ khác [26,50,33]. Như được đề xuất bởi các công trình trước đó [20,62,3], các kết hợp của CNN và transformer có thể vượt trội cả transformer thuần túy và CNN thuần túy.

Mặc dù có những tiến bộ lớn được mang lại bởi thiết kế mạng, việc tìm kiếm thủ công các kiến trúc lai được tối ưu hóa tốt có thể là thách thức, đặc biệt khi số lượng lựa chọn thiết kế tăng lên. Neural Architecture Search (NAS) là một cách tiếp cận phổ biến để giảm nỗ lực con người trong thiết kế kiến trúc mạng bằng cách tự động tìm kiếm các kiến trúc tối ưu

*Tác giả liên hệ.
1Mã nguồn: https://github.com/changlin31/BossNAS .

[THIS IS FIGURE: Comparison of three NAS schemes with red arrows representing supervision during training and searching - labeled as (a) NAS with large weight-sharing space, (b) Block-wise NAS with biased supervision, (c) Block-wisely self-supervised NAS]

Hình 1: So sánh ba sơ đồ NAS. Mũi tên đỏ biểu thị sự giám sát trong quá trình huấn luyện và tìm kiếm.

trong một không gian tìm kiếm được định nghĩa trước. Thành công tiêu biểu trong việc thực hiện NAS trên các khối xây dựng được thiết kế thủ công bao gồm MobileNetV3 [29], EfficientNet [64], v.v. Những công trình này được tìm kiếm bởi các phương pháp NAS đa thử nghiệm [63,92,2,89,12,47], vốn có chi phí tính toán cấm đoán (tốn hàng nghìn ngày GPU). Các phương pháp NAS chia sẻ trọng số gần đây [6,53,4,43] mã hóa toàn bộ không gian tìm kiếm như một supernet chia sẻ trọng số để tránh việc huấn luyện lặp lại các mạng ứng viên, do đó giảm đáng kể chi phí tìm kiếm.

Tuy nhiên, như được thể hiện trong Hình 1a, các không gian tìm kiếm kiến trúc với độ chi tiết cấp lớp tăng theo cấp số nhân theo độ sâu mạng tăng, điều này đã được xác định (trong [37,39]) là thủ phạm chính của việc đánh giá kiến trúc không chính xác2 trong các phương pháp NAS chia sẻ trọng số. Để giảm kích thước của không gian chia sẻ trọng số lớn, các công trình trước đó [37,46] phân tích không gian tìm kiếm thành các khối và sử dụng một mô hình giáo viên được tiền huấn luyện để cung cấp giám sát theo khối (Hình 1b). Mặc dù có tương quan xếp hạng cao và hiệu suất cao, chúng tôi phát hiện (trong Phần 5) kết quả của chúng có tương quan cao với kiến trúc giáo viên. Như được minh họa trong Hình 1b, khi huấn luyện bởi một giáo viên với các nút màu xanh, các kiến trúc ứng viên với nhiều nút màu xanh hơn có xu hướng nhận được thứ hạng cao hơn trong những phương pháp này. Điều này hạn chế ứng dụng của nó trên các không gian tìm kiếm đa dạng với các ứng viên khác biệt, như CNN và transformer.

Mặt khác, NAS không giám sát [41] gần đây đã nổi lên như một chủ đề nghiên cứu thú vị. Không có quyền truy cập vào bất kỳ nhãn được gán thích bởi con người nào, các phương pháp NAS không giám sát (được tối ưu hóa với các nhiệm vụ pretext [41] hoặc nhãn ngẫu nhiên [87]) đã được chứng minh có khả năng đạt được hiệu suất tương đương với các phương pháp NAS có giám sát. Theo đó, chúng tôi đề xuất sử dụng một phương pháp học không giám sát như một thay thế cho việc chưng cất có giám sát trong sơ đồ NAS theo khối được đề cập ở trên (Hình 1c), nhằm giải quyết vấn đề thiên vị kiến trúc gây ra bởi việc sử dụng mô hình giáo viên.

Trong công trình này, chúng tôi đề xuất một phương pháp NAS không giám sát mới, Block-wisely Self-supervised Neural Architecture Search (BossNAS), nhằm giải quyết vấn đề xếp hạng kiến trúc dự đoán không chính xác gây ra bởi không gian chia sẻ trọng số lớn trong khi tránh thiên vị kiến trúc có thể gây ra bởi việc sử dụng mô hình giáo viên. Trái ngược với các giải pháp theo khối được thảo luận ở trên, sử dụng chưng cất như giám sát trung gian, chúng tôi đề xuất một sơ đồ học biểu diễn tự giám sát được gọi là ensemble bootstrapping để tối ưu hóa từng khối của supernet. Cụ thể hơn, mỗi mạng con được lấy mẫu được huấn luyện để dự đoán ensemble xác suất của tất cả các mạng được lấy mẫu trong mạng đích, giữa các góc nhìn được tăng cường khác nhau của cùng một hình ảnh. Trong giai đoạn tìm kiếm, một chỉ số đánh giá không giám sát được đề xuất để đảm bảo công bằng bằng cách tìm kiếm hướng về trung tâm quần thể kiến trúc. Cụ thể hơn, ensemble xác suất của tất cả các kiến trúc trong quần thể được sử dụng như mục tiêu đánh giá để đo lường hiệu suất của các mô hình được lấy mẫu.

2Trong công trình này, độ chính xác đánh giá kiến trúc đề cập đến tương quan của xếp hạng kiến trúc được dự đoán và xếp hạng kiến trúc ground truth.

--- TRANG 2 ---
kiến trúc trong một không gian tìm kiếm được định nghĩa trước. Thành công tiêu biểu trong việc thực hiện NAS trên các khối xây dựng được thiết kế thủ công bao gồm MobileNetV3 [29], EfficientNet [64], v.v. Những công trình này được tìm kiếm bởi các phương pháp NAS đa thử nghiệm [63,92,2,89,12,47], vốn có chi phí tính toán cấm đoán (tốn hàng nghìn ngày GPU). Các phương pháp NAS chia sẻ trọng số gần đây [6,53,4,43] mã hóa toàn bộ không gian tìm kiếm như một supernet chia sẻ trọng số để tránh việc huấn luyện lặp lại các mạng ứng viên, do đó giảm đáng kể chi phí tìm kiếm.

Tuy nhiên, như được thể hiện trong Hình 1a, các không gian tìm kiếm kiến trúc với độ chi tiết cấp lớp tăng theo cấp số nhân theo độ sâu mạng tăng, điều này đã được xác định (trong [37,39]) là thủ phạm chính của việc đánh giá kiến trúc không chính xác2 trong các phương pháp NAS chia sẻ trọng số. Để giảm kích thước của không gian chia sẻ trọng số lớn, các công trình trước đó [37,46] phân tích không gian tìm kiếm thành các khối và sử dụng một mô hình giáo viên được tiền huấn luyện để cung cấp giám sát theo khối (Hình 1b). Mặc dù có tương quan xếp hạng cao và hiệu suất cao, chúng tôi phát hiện (trong Phần 5) kết quả của chúng có tương quan cao với kiến trúc giáo viên. Như được minh họa trong Hình 1b, khi huấn luyện bởi một giáo viên với các nút màu xanh, các kiến trúc ứng viên với nhiều nút màu xanh hơn có xu hướng nhận được thứ hạng cao hơn trong những phương pháp này. Điều này hạn chế ứng dụng của nó trên các không gian tìm kiếm đa dạng với các ứng viên khác biệt, như CNN và transformer.

Mặt khác, NAS không giám sát [41] gần đây đã nổi lên như một chủ đề nghiên cứu thú vị. Không có quyền truy cập vào bất kỳ nhãn được gán thích bởi con người nào, các phương pháp NAS không giám sát (được tối ưu hóa với các nhiệm vụ pretext [41] hoặc nhãn ngẫu nhiên [87]) đã được chứng minh có khả năng đạt được hiệu suất tương đương với các phương pháp NAS có giám sát. Theo đó, chúng tôi đề xuất sử dụng một phương pháp học không giám sát như một thay thế cho việc chưng cất có giám sát trong sơ đồ NAS theo khối được đề cập ở trên (Hình 1c), nhằm giải quyết vấn đề thiên vị kiến trúc gây ra bởi việc sử dụng mô hình giáo viên.

Trong công trình này, chúng tôi đề xuất một phương pháp NAS không giám sát mới, Block-wisely Self-supervised Neural Architecture Search (BossNAS), nhằm giải quyết vấn đề xếp hạng kiến trúc dự đoán không chính xác gây ra bởi không gian chia sẻ trọng số lớn trong khi tránh thiên vị kiến trúc có thể gây ra bởi việc sử dụng mô hình giáo viên. Trái ngược với các giải pháp theo khối được thảo luận ở trên, sử dụng chưng cất như giám sát trung gian, chúng tôi đề xuất một sơ đồ học biểu diễn tự giám sát được gọi là ensemble bootstrapping để tối ưu hóa từng khối của supernet. Cụ thể hơn, mỗi mạng con được lấy mẫu được huấn luyện để dự đoán ensemble xác suất của tất cả các mạng được lấy mẫu trong mạng đích, giữa các góc nhìn được tăng cường khác nhau của cùng một hình ảnh. Trong giai đoạn tìm kiếm, một chỉ số đánh giá không giám sát được đề xuất để đảm bảo công bằng bằng cách tìm kiếm hướng về trung tâm quần thể kiến trúc. Cụ thể hơn, ensemble xác suất của tất cả các kiến trúc trong quần thể được sử dụng như mục tiêu đánh giá để đo lường hiệu suất của các mô hình được lấy mẫu.

Ngoài ra, chúng tôi thiết kế một không gian tìm kiếm CNN-transformer lai giống như vải (HyTra) với các vị trí downsampling có thể tìm kiếm và sử dụng nó như một trường hợp nghiên cứu cho các kiến trúc lai để đánh giá phương pháp của chúng tôi. Trong mỗi lớp của không gian tìm kiếm HyTra, các khối xây dựng CNN và các khối xây dựng transformer với độ phân giải khác nhau được đặt song song và có thể được chọn một cách linh hoạt. Không gian tìm kiếm đa dạng này bao gồm các transformer thuần túy với độ dài nội dung cố định và CNN bình thường với các thang đo không gian được giảm dần.

Chúng tôi chứng minh rằng phương pháp NAS của chúng tôi có thể tổng quát hóa tốt trên ba không gian tìm kiếm khác nhau và ba bộ dữ liệu. Trên không gian tìm kiếm HyTra, các mô hình được tìm kiếm của chúng tôi vượt trội hơn những mô hình được tìm kiếm bởi đối tác NAS có giám sát của chúng tôi [37], chứng minh rằng phương pháp của chúng tôi đã thành công trong việc tránh thiên vị kiến trúc có thể được mang lại bởi chưng cất có giám sát. Phương pháp của chúng tôi đạt được độ chính xác đánh giá kiến trúc vượt trội với tương quan Spearman 0,78 và 0,76 trên không gian tìm kiếm MBConv chuẩn với ImageNet và trên không gian tìm kiếm size NATS-Bench SS[17] với CIFAR-100, tương ứng, vượt qua các phương pháp NAS tiên tiến, chứng minh rằng phương pháp của chúng tôi đã thành công trong việc ức chế vấn đề đánh giá kiến trúc không chính xác gây ra bởi không gian chia sẻ trọng số lớn.

Các mô hình được tìm kiếm của chúng tôi trên không gian tìm kiếm HyTra đạt độ chính xác 82,5% trên ImageNet, vượt trội EfficientNet [64] 2,4%, với thời gian tính toán tương đương3. Bằng cách cung cấp kết quả mạnh mẽ thông qua BossNet-T, chúng tôi hy vọng rằng không gian tìm kiếm HyTra đa dạng này với các ứng viên khác biệt và các kiến trúc hiệu suất cao có thể phục vụ như một đấu trường mới cho các công trình NAS trong tương lai. Chúng tôi cũng hy vọng rằng BossNAS của chúng tôi có thể phục vụ như một công cụ được sử dụng rộng rãi cho thiết kế kiến trúc lai.

2. Các công trình liên quan

NAS chia sẻ trọng số theo khối [37,46,84,85] các cách tiếp cận phân tích supernet thành các khối được tối ưu hóa độc lập và do đó giảm không gian chia sẻ trọng số, giải quyết vấn đề đánh giá kiến trúc không chính xác gây ra bởi chia sẻ trọng số. DNA [37] đầu tiên giới thiệu sơ đồ đánh giá kiến trúc được giám sát theo khối với chưng cất kiến thức. Dựa trên sơ đồ này, DONNA [46] tiếp tục đề xuất dự đoán đánh giá kiến trúc bằng cách sử dụng một tổ hợp tuyến tính của các đánh giá theo khối của nó thay vì một tổng đơn giản. SP [84] là những người đầu tiên áp dụng sơ đồ này cho việc cắt tỉa mạng. Tuy nhiên, tất cả các phương pháp được đề cập ở trên đều dựa vào một sơ đồ chưng cất có giám sát, điều này không thể tránh khỏi việc đưa ra thiên vị kiến trúc từ giáo viên. Theo đó, chúng tôi đề xuất một sơ đồ tự giám sát theo khối, hoàn toàn thoát khỏi ràng buộc của kiến trúc giáo viên.

Các phương pháp NAS không giám sát [41,87] thực hiện tìm kiếm kiến trúc mà không có quyền truy cập vào bất kỳ nhãn được gán thích bởi con người nào. UnNAS [41] giới thiệu các nhiệm vụ pretext không giám sát [35,48,86] cho NAS chia sẻ trọng số để huấn luyện supernet và đánh giá kiến trúc. RLNAS [87] tối ưu hóa supernet bằng cách sử dụng nhãn ngẫu nhiên [81,45] và tiếp tục đánh giá kiến trúc bằng phương tiện của một chỉ số góc dựa trên hội tụ [32]. Một dòng phương pháp NAS khác [72,69,27,51] thuộc về danh mục NAS có giám sát thực hiện tiền huấn luyện không giám sát của bộ dự đoán độ chính xác mạng hoặc supernet trước khi tinh chỉnh hoặc đánh giá có giám sát. Khác với các công trình được đề cập ở trên về động lực và phương pháp luận, chúng tôi khám phá các phương pháp học contrastive tự giám sát trong sơ đồ NAS không giám sát của chúng tôi để tránh thiên vị giám sát trong NAS theo khối.

Các phương pháp học contrastive tự giám sát [49,71,28,65,91,24,10] đã thúc đẩy đáng kể việc học không giám sát các biểu diễn thị giác. Các cách tiếp cận này học các biểu diễn thị giác theo cách phân biệt bằng cách thu thập các biểu diễn của các góc nhìn khác nhau từ cùng một hình ảnh và trải rộng những góc nhìn từ các hình ảnh khác nhau. Gần đây, BYOL [21] và SimSiam [11] sáng tạo đã học các biểu diễn thị giác mà không sử dụng các ví dụ âm. Những công trình này trực tiếp dự đoán biểu diễn của một góc nhìn từ góc nhìn khác bằng cách sử dụng một cặp mạng Siamese với cùng kiến trúc và trọng số được chia sẻ [11], hoặc với một trong các nhánh mạng Siamese là một bộ mã hóa momentum, do đó tạo thành một sơ đồ bootstrapping [21]. Công trình của chúng tôi giới thiệu một sơ đồ bootstrapping mới với ensemble xác suất cho các supernet Siamese.

Không gian tìm kiếm kiến trúc. Các không gian tìm kiếm dựa trên cell, được đề xuất lần đầu trong [93], thường được sử dụng trong các phương pháp NAS trước đó [42,54,43,52] và các benchmark [74,19,17]. Chúng tìm kiếm một kiến trúc cấp cell có thể lặp lại, trong khi giữ một kiến trúc cấp mạng được thiết kế thủ công. Ngược lại, các không gian tìm kiếm cấp mạng với độ chi tiết cấp lớp [7,70,15,37,46,87] và độ chi tiết cấp khối [63,29,64] tìm kiếm cấu trúc cấp mạng macro bằng cách sử dụng các khối xây dựng được thiết kế thủ công (ví dụ MBConv [56]). Auto-DeepLab [40] trình bày một không gian tìm kiếm phân cấp cho phân đoạn ngữ nghĩa, với các cell có thể lặp lại và một cấu trúc cấp mạng giống như vải [57]. Không gian tìm kiếm HyTra của chúng tôi cũng có một cấu trúc cấp mạng giống như vải, mặc dù với độ chi tiết cấp lớp thay vì các cell lặp lại.

3Theo [62], thời gian tính toán đề cập đến thời gian dành cho các lượt forward và backward.
2

--- TRANG 3 ---
3. NAS tự giám sát theo khối

Trong phần này, chúng tôi trước tiên giới thiệu ngắn gọn về tiến thoái lưỡng nan của NAS và các giải pháp theo khối của nó [37,46,84,85], sau đó trình bày chi tiết BossNAS được đề xuất của chúng tôi, cùng với hai yếu tố chính của nó: i) giai đoạn huấn luyện supernet không giám sát với ensemble bootstrapping; ii) giai đoạn đánh giá và tìm kiếm kiến trúc không giám sát hướng về trung tâm quần thể kiến trúc.

Ký hiệu. Chúng tôi ký hiệu các scalar, tensor và tập hợp các tensor bằng cách sử dụng các chữ cái thường, chữ thường đậm và chữ hoa thảo tương ứng (ví dụ, n, x và X). Để đơn giản, chúng tôi sử dụng {xn} để ký hiệu tập hợp {xn}|n|n=1 với lực lượng |n|.

3.1. Tiến thoái lưỡng nan của NAS và các giải pháp theo khối

Tiến thoái lưỡng nan của NAS: hiệu quả hoặc độ chính xác. Trong khi các phương pháp NAS dựa trên mẫu cổ điển tạo ra các đánh giá kiến trúc chính xác, chúng cũng có chi phí tính toán cấm đoán. Sơ đồ đánh giá chia sẻ trọng số trong các phương pháp NAS một lần đã mang lại sự giảm đáng kể chi phí tìm kiếm bằng cách mã hóa toàn bộ không gian tìm kiếm A thành một supernet chia sẻ trọng số, với các trọng số W được chia sẻ bởi tất cả các kiến trúc ứng viên và được tối ưu hóa đồng thời như: W* = arg minW Ltrain(W; A; x; y). Ở đây Ltrain() ký hiệu hàm mất mát huấn luyện, trong khi x và y ký hiệu dữ liệu đầu vào và nhãn, tương ứng.

Tiếp theo, các kiến trúc được tìm kiếm dựa trên xếp hạng của các đánh giá của chúng với những trọng số mạng được chia sẻ này. Không mất tính tổng quát, chúng tôi chọn hàm mất mát đánh giá Lval như chỉ số đánh giá; giai đoạn tìm kiếm có thể được công thức hóa như: α* = arg minα∈A Lval(W*; α; x; y). Tuy nhiên, xếp hạng kiến trúc dựa trên các trọng số được chia sẻ W* không nhất thiết đại diện cho xếp hạng đúng của các kiến trúc, vì các trọng số được kế thừa từ supernet bị rối rắm cao và không được tối ưu hóa đầy đủ và công bằng. Như được chỉ ra trong tài liệu [58,73,80], các phương pháp chia sẻ trọng số gặp phải độ chính xác đánh giá kiến trúc thấp.

NAS có giám sát theo khối. Như được chứng minh về mặt lý thuyết và thực nghiệm bởi [39,37,46], việc giảm không gian chia sẻ trọng số (tức là tổng số kiến trúc chia sẻ trọng số) có thể cải thiện hiệu quả độ chính xác của đánh giá kiến trúc. Trong thực tế, các giải pháp theo khối [37,46,84,85] tìm ra con đường thoát khỏi tiến thoái lưỡng nan này của NAS bằng cách phân tích không gian tìm kiếm theo khối trong chiều sâu, do đó giảm không gian chia sẻ trọng số trong khi duy trì kích thước ban đầu của không gian tìm kiếm. Cho một supernet bao gồm |k| khối S(W; A) = {Sk(Wk; Ak)}, với W = {Wk} và A = {Ak} ký hiệu các trọng số và kiến trúc của nó có thể tách biệt theo khối trong chiều sâu, mỗi khối của supernet được huấn luyện riêng biệt trước khi tìm kiếm giữa tất cả các khối trong tổ hợp bằng tổng [37], hoặc một tổ hợp tuyến tính [46] (với các trọng số {λk}), của mất mát đánh giá Lval của mỗi khối:

α* = {αk} = arg min{αk}∈A Σ|k|k=1 λk Lval(W*k; αk; xk; yk)
s.t. W*k = arg minWk Ltrain(Wk; Ak; xk; yk). (1)

Để cô lập việc huấn luyện của mỗi khối supernet, cho một đầu vào x, đầu vào trung gian và mục tiêu {xk, yk} của khối thứ k được tạo ra bởi một mạng giáo viên cố định T (với kiến trúc αT và trọng số ground-truth WT): {x1, y1} = {x, T1(x)}, và {xk, yk} = {Tk-1(x), Tk(x)}; k > 1, trong đó Tk đại diện cho mạng giáo viên được cắt ngắn sau khối thứ k. Vì dữ liệu được sử dụng cho cả giai đoạn huấn luyện và tìm kiếm đều được tạo ra bởi mô hình giáo viên T(WT; αT), các đánh giá kiến trúc có khả năng có tương quan cao với kiến trúc giáo viên. Ví dụ, một giáo viên tích chập có trường tiếp nhận hạn chế và các thiên vị quy nạp kiến trúc đặc biệt như tính bất biến tịnh tiến. Với sự giám sát thiên vị như vậy, các kiến trúc ứng viên có khả năng được huấn luyện và đánh giá một cách không công bằng. Chúng tôi quan sát hai hiện tượng có thể được gán cho sự giám sát thiên vị, tức là sở thích ứng viên và sở thích giáo viên. Phân tích thực nghiệm chi tiết của hai hiện tượng này được cung cấp trong Phần 5. Để phá vỡ những hạn chế này của các giải pháp NAS theo khối hiện tại, chúng tôi khám phá một sơ đồ không sử dụng mô hình giáo viên.

3.2. Huấn luyện với Ensemble Bootstrapping

Bắt đầu từ sơ đồ mạng kép với cặp học sinh-giáo viên {S(W; A); T(WT; αT)}, bước đầu tiên để thoát khỏi ràng buộc của kiến trúc giáo viên là gán αT = A, do đó tạo thành một cặp supernet Siamese.

Bootstrapping với Supernet Siamese. Để tối ưu hóa các mạng Siamese như vậy theo khối, chúng tôi áp dụng một sơ đồ học contrastive tự giám sát. Cụ thể hơn, hai supernet này nhận một cặp góc nhìn được tăng cường {x1, x2} của cùng một mẫu huấn luyện x và tạo ra các đầu ra {S(W; A; x1); T(WT; A; x2)}, tương ứng. Tương tự như các cài đặt giáo viên-học sinh trước đó, các supernet Siamese được tối ưu hóa bằng cách tối thiểu hóa khoảng cách giữa các đầu ra của chúng. Trong các mạng Siamese và phương pháp học contrastive tự giám sát trước đó, hai mạng hoặc chia sẻ trọng số của chúng [10,11] (tức là WT = W) hoặc tạo thành một sơ đồ giáo viên trung bình với Exponential Moving Average (EMA) [24,21] (tức là WT = W̄, trong đó W̄t = μW̄t-1 + (1-μ)Wt đại diện cho trung bình thời gian của W, với t là dấu thời gian huấn luyện, và μ ký hiệu hệ số momentum kiểm soát tốc độ cập nhật của W̄). Bằng cách học biểu diễn từ giáo viên trung bình, tương tự như BYOL đơn giản nhưng mạnh mẽ [21], supernet của chúng tôi có thể được tối ưu hóa theo cách không giám sát mà không dựa vào một mạng giáo viên được giám sát đầy đủ:

W*k = arg minWk Ltrain({Wk, W̄k}; Ak; xk). (2)

Để loại bỏ ảnh hưởng của sự khác biệt theo pixel giữa hai biểu diễn trung gian gây ra bởi các tăng cường (ví dụ cắt ngẫu nhiên), cũng như để đảm bảo tổng quát hóa tốt hơn trên các kiến trúc ứng viên với các trường tiếp nhận khác nhau hoặc thậm chí độ phân giải khác nhau, chúng tôi chiếu các biểu diễn vào không gian tiềm ẩn trước khi tính toán khoảng cách theo từng phần tử.

Ensemble Bootstrapping. Tuy nhiên, không giống như các mạng đơn, supernet thường được tối ưu hóa bởi các chiến lược lấy mẫu đường dẫn, ví dụ đường dẫn đơn [22] hoặc đường dẫn công bằng [15]. Khi áp dụng bootstrapping một cách ngây thơ, mỗi mạng con học từ moving average của chính nó. Trong sự vắng mặt của một mục tiêu chung, các trọng số được chia sẻ bởi các mạng con khác nhau gặp khó khăn trong hội tụ, dẫn đến sự không ổn định trong huấn luyện và đánh giá kiến trúc không chính xác. Để giải quyết vấn đề này, chúng tôi đề xuất một sơ đồ huấn luyện supernet không giám sát, được gọi là ensemble bootstrapping.

[THIS IS FIGURE: Illustration of Siamese supernets training with ensemble bootstrapping showing online and EMA candidates, stop gradient, ensemble module, and L2 distance components]

Hình 2: Minh họa việc huấn luyện supernet Siamese với ensemble bootstrapping.

Xem xét |p| mạng con {αp} ⊂ Ak được lấy mẫu từ khối thứ k của không gian tìm kiếm A trong lần lặp huấn luyện thứ t, và cho một mẫu huấn luyện x, |p| cặp góc nhìn được tăng cường {xp} ∼ paug(·|x), {x'p} ∼ p'aug(·|x) được tạo ra cho mỗi mạng con được lấy mẫu của các supernet Siamese. Để tạo thành một mục tiêu chung cho tất cả các đường dẫn, chúng tôi có thể sử dụng một sơ đồ tương tự như chưng cất ensemble [59,60] trong học có giám sát. Như được minh họa trong Hình 2, mỗi mạng con được lấy mẫu của supernet trực tuyến học để dự đoán ensemble xác suất của tất cả các mạng con được lấy mẫu trong supernet EMA:

c̄Tk({αp}; {x'p}) = 1/|p| Σ|p|p=1 Tk(W̄; αp; x'p). (3)

Tóm lại, quá trình huấn luyện tự giám sát theo khối của các supernet Siamese được công thức hóa như sau:

W*k = arg minWk Σ|p|p=1 Ltrain({Wk, W̄k}; {αp}; x),

trong đó Ltrain({Wk, W̄k}; {αp}; x) = ||Sk(Wk; αp; xp) - c̄Tk({Wk}; {αp}; {x'p})||²2. (4)

3.3. Tìm kiếm hướng về Trung tâm Quần thể

Sau khi sự hội tụ của các supernet Siamese hoàn tất, các kiến trúc có thể được xếp hạng và tìm kiếm bởi đánh giá được xác định dựa trên trọng số của supernet, như trong Công thức 1. Trong phần này, chúng tôi thiết kế một chỉ số đánh giá không giám sát Lval công bằng và hiệu quả cho giai đoạn tìm kiếm.

Để đánh giá hiệu suất của một mạng được huấn luyện với tự giám sát contrastive, các công trình trước đó [24,10,21,11] đã sử dụng các chỉ số có giám sát, như độ chính xác của đánh giá tuyến tính hoặc phân loại few-shot. Để phát triển một phương pháp NAS không giám sát, chúng tôi nhằm tránh các sơ đồ phụ thuộc vào nhãn được gán thích bởi con người và thay vào đó theo đuổi một chỉ số đánh giá hoàn toàn không giám sát. Các phương pháp NAS không giám sát trước đó [41,87] sử dụng độ chính xác của các nhiệm vụ pretext hoặc đo lường hội tụ với các chỉ số dựa trên góc để đánh giá các kiến trúc ứng viên. Thật không may, các mất mát của học contrastive tự giám sát không nhất thiết đại diện cho hiệu suất kiến trúc hoặc sự hội tụ kiến trúc, vì các góc nhìn đầu vào và mạng đích đều được lấy mẫu ngẫu nhiên. Hơn nữa, các mạng đích hơi thiên vị và không thể phục vụ như các mục tiêu ground truth.

Để tránh những mối quan tâm này, chúng tôi đề xuất một chỉ số đánh giá không giám sát công bằng và hiệu quả cho tìm kiếm kiến trúc.

Không mất tính tổng quát, chúng tôi xem xét tìm kiếm với một thuật toán tiến hóa [12,54], trong đó các kiến trúc được tối ưu hóa bằng cách phát triển một quần thể kiến trúc {αp}. Tương tự như việc tối ưu hóa các trọng số, chúng tôi đề xuất sử dụng ensemble xác suất giữa quần thể {αp} như mục tiêu chung để cung cấp một đánh giá công bằng cho mỗi kiến trúc αp. Ngoài ra, một cặp góc nhìn {x1, x2} cho mỗi mẫu xác thực x được tạo ra và cố định để tránh thiên vị được đưa vào bởi tăng cường biến đổi. Song song với Công thức 3, chúng tôi có ensemble xác suất của quần thể kiến trúc:

c̄Sk({αp}; x2) = 1/|p| Σ|p|p=1 Sk(αp; x2). (5)

Trong thực tế, bằng cách chia supernet thành các khối có kích thước trung bình (ví dụ 4 lớp với 4 ứng viên, 4⁴ = 256 kiến trúc), việc đánh giá duyệt qua tất cả các kiến trúc ứng viên là có thể chi trả được. Trong trường hợp này, quần thể kiến trúc {αp} được mở rộng đến toàn bộ không gian tìm kiếm theo khối Ak, và toàn bộ quá trình tìm kiếm được hoàn thành trong một bước duy nhất:

α* = arg minα∈A Σ|k|k=1 λk Lval(α; xk)

trong đó Lval(α; x) = ||Sk(α; x1) - c̄Sk(Ak; x2)||²2. (6)

4. Không gian tìm kiếm CNN-transformer lai

Trong phần này, chúng tôi trình bày một không gian tìm kiếm CNN-transformer lai giống như vải, được gọi là HyTra, với các khối xây dựng ứng viên khác biệt và các vị trí down-sampling linh hoạt.

4.1. Các khối ứng viên CNN và Transformer

Bước đầu tiên trong việc thiết kế một không gian tìm kiếm CNN-transformer lai là bao gồm các khối xây dựng CNN và transformer phù hợp. Hai loại khối xây dựng này phải có khả năng hoạt động tốt khi được tổng hợp đơn giản theo thứ tự hoặc khi được kết hợp tự do. Chúng tôi chọn residual bottleneck cổ điển và mạnh mẽ (ResConv) trong ResNet [25] như khối xây dựng ứng viên CNN. Song song, chúng tôi thiết kế một khối xây dựng transformer nhẹ và mạnh mẽ ResAtt dựa trên BoTBlock có thể cắm được [62] và NLBlock [68].

Cân bằng tính toán với Mã hóa vị trí ẩn. Để tạo điều kiện cạnh tranh công bằng và có ý nghĩa, các khối xây dựng ứng viên nên có độ phức tạp tính toán tương tự. BoTBlock ban đầu chậm hơn ResConv, vì các mã hóa vị trí tương đối của nó được tính toán riêng biệt thông qua phép nhân với query. Việc đơn giản loại bỏ nhánh content-position khỏi BoTBlock, giống như NLBlock, có thể giảm thời gian tính toán của chúng để làm cho chúng có thể so sánh với ResConv. Tuy nhiên, mã hóa vị trí rất quan trọng đối với vision transformer để đạt được hiệu suất tốt. Trong CPVT [14], các tác giả sử dụng các tích chập đơn giữa các khối mã hóa transformer như bộ tạo mã hóa vị trí. Tương tự, chúng tôi thay thế nhánh mã hóa vị trí tương đối trong BoTBlock bằng một tích chập separable theo độ sâu nhẹ như một mô-đun mã hóa vị trí ẩn, tạo thành ResAtt của chúng tôi. Bằng cách sửa đổi đơn giản này, chúng tôi giảm độ phức tạp tính toán của mô-đun mã hóa vị trí từ O(CW³) ban đầu xuống O(CW²), với C ký hiệu số kênh và W ký hiệu chiều rộng hoặc chiều cao. Trái ngược với CPVT và BoT (Hình 4), các mô-đun mã hóa vị trí của chúng tôi (Hình 3 phải) được đặt giữa lớp chiếu đầu vào và mô-đun self-attention. Ngoài ra, các mô-đun mã hóa vị trí ẩn của chúng tôi cũng chịu trách nhiệm cho việc down-sampling. Sửa đổi này cũng được áp dụng cho ResConv, cho phép chia sẻ trọng số giữa các khối ứng viên với tỷ lệ down-sampling khác nhau (tức là 1 hoặc 2).

[THIS IS FIGURE: Shows transformer blocks in CPVT and BoT with P MHSA components]

Hình 4: Các khối transformer trong CPVT [14] và BoT [62].

4.2. Vải của CNN-transformer lai

Ngoài các khối xây dựng, CNN và transformer khác nhau đáng kể về mặt kiến trúc macro của chúng. Không giống như CNN, xử lý hình ảnh theo các giai đoạn với nhiều kích thước không gian khác nhau, transformer thường không thay đổi độ dài chuỗi (các patch hình ảnh) và giữ nguyên quy mô ở mỗi lớp. Như được thể hiện trong Hình 3 trái, để bao gồm cả CNN và transformer, không gian tìm kiếm của chúng tôi được thiết kế với các vị trí down-sampling linh hoạt, tạo thành một vải [57] của CNN-transformer lai. Tại mỗi lớp khối lựa chọn của vải, độ phân giải không gian có thể giữ nguyên hoặc được giảm xuống một nửa quy mô của nó, cho đến khi đạt được quy mô nhỏ nhất. Không gian tìm kiếm giống như vải này chứa các kiến trúc giống như các vision transformer phổ biến [20,66,14], CNN [25,31] và CNN-transformer lai [62] ở các quy mô khác nhau.

[THIS IS FIGURE: Illustration of fabric-like Hybrid CNN-transformer Search Space with flexible down-sampling positions]

Hình 3: Minh họa không gian tìm kiếm CNN-transformer lai giống như vải với các vị trí down-sampling linh hoạt.

--- TRANG 4 ---
5

--- TRANG 5 ---
[Tiếp tục với các trang còn lại...]

--- TRANG 6 ---
[Bảng 1 với kết quả ImageNet của các mô hình tiên tiến và CNN-transformer lai được tìm kiếm của chúng tôi]

Bảng 1: Kết quả ImageNet của các mô hình tiên tiến và CNN-transformer lai được tìm kiếm của chúng tôi. Thời gian tính toán steptime được đo trên một GPU GeForce RTX 3090 với kích thước batch 32. Màu tím được sử dụng để ký hiệu các kiến trúc được chọn thủ công từ không gian tìm kiếm HyTra. ": Được kiểm tra trực tiếp trên kích thước đầu vào lớn hơn mà không tinh chỉnh (tức là 288 cho BossNet-T0 " và 256 cho BossNet-T1 ").

5. Thí nghiệm

Thiết lập. Chúng tôi đánh giá phương pháp của chúng tôi trên ba không gian tìm kiếm, bao gồm không gian tìm kiếm HyTra được đề xuất của chúng tôi và hai không gian tìm kiếm hiện có khác, tức là không gian tìm kiếm MBConv [7,37] và không gian tìm kiếm size NATS-Bench SS[17]. Các bộ dữ liệu chúng tôi sử dụng để đánh giá và phân tích phương pháp của chúng tôi là ImageNet [16], CIFAR-10 và CIFAR-100 [36]. Chúng tôi huấn luyện mỗi khối của supernet trong 20 epoch, bao gồm một epoch warm-up tuyến tính. Chúng tôi lấy mẫu ngẫu nhiên bốn đường dẫn trong mỗi bước huấn luyện. Xem Phụ lục A.2 để biết thêm chi tiết triển khai.

5.1. Tìm kiếm CNN-transformer lai

Phân tích không gian tìm kiếm HyTra. Chúng tôi ghép thủ công bốn kiến trúc trên không gian tìm kiếm HyTra giống như vải của chúng tôi, theo sát nhất có thể các mạng được thiết kế bởi con người trước đó [25,20,62], ngoại trừ việc sử dụng các khối xây dựng {ResConv; ResAtt} của chúng tôi. Như được thể hiện trong Bảng 1, những mô hình này (màu tím) liên tục vượt trội hơn các nguyên mẫu của chúng. Đáng chú ý, BoT50-T vượt qua BoT50 ban đầu 1,2% độ chính xác top-1 với việc giảm 1,17× thời gian tính toán, chứng minh sự vượt trội của các khối xây dựng được thiết kế của chúng tôi.

Hiệu suất của các mô hình được tìm kiếm. Với không gian tìm kiếm và phương pháp NAS được đề xuất của chúng tôi, chúng tôi khám phá các kiến trúc CNN-transformer lai trên ImageNet. Kết quả của các mô hình được tìm kiếm của chúng tôi (BossNet-T) và các mô hình với thời gian tính toán tương đương được tóm tắt trong Bảng 1.

[Hình 5: Visualization of architectures searched by BossNAS and DNA]

Hình 5: Visualization của các kiến trúc được tìm kiếm bởi BossNAS và DNA [37] trong không gian tìm kiếm HyTra. Nút màu xanh ký hiệu ResConv và nút màu đỏ ký hiệu ResAtt.

Thứ nhất, BossNet-T0 vượt trội một loạt các mô hình tiên tiến. Ví dụ, BossNet-T0 không có mô-đun SE đạt 80,5% độ chính xác top-1, vượt qua CNN-transformer lai được thiết kế bởi con người, BoTNet50, 2,2% trong khi nhanh hơn 1,19× về thời gian tính toán; khi được trang bị SE và kích hoạt SiLU, BossNet-T0 tiếp tục đạt 80,8% độ chính xác top-1, vượt qua EfficientNet-B1 được tìm kiếm bởi NAS 1,7% trong khi nhanh hơn 1,14×.

Thứ hai, mô hình được tìm kiếm của chúng tôi thể hiện sự vượt trội tuyệt đối so với các mô hình được chọn thủ công và ngẫu nhiên từ không gian tìm kiếm HyTra. Đặc biệt, BossNet-T0 đạt được cải thiện lên đến 6,0% so với các mô hình được chọn thủ công, chứng minh hiệu quả của tìm kiếm kiến trúc của chúng tôi.

Thứ ba, BossNet-T0 vượt trội hơn các phương pháp NAS gần đây khác trên không gian tìm kiếm HyTra. BossNet-T0 đạt được 0,5% cải thiện độ chính xác so với DNA-T, được tìm kiếm bởi đối tác NAS có giám sát của chúng tôi [37].

Cuối cùng, khi được mở rộng đến kích thước mô hình và kích thước đầu vào lớn hơn, họ mô hình BossNet-T duy trì sự vượt trội của chúng. Bằng cách loại bỏ downsampling trong giai đoạn cuối của BossNet-T0 (cùng sơ đồ như BoTNet-S1 [62]), chúng tôi có BossNet-T1, đạt 82,2% độ chính xác, vượt qua EfficientNet-B2 2,1%. Bằng cách kiểm tra trực tiếp trên độ phân giải đầu vào lớn hơn mà không tinh chỉnh, BossNet-T0 " (trên kích thước đầu vào 288×288) đạt 81,6% độ chính xác top-1, và vượt trội BoTNet50 + SE 2,0% với thời gian chạy tương tự; BossNet-T1" (trên kích thước đầu vào 256×256) đạt 82,5% độ chính xác top-1, vượt qua T2T-ViT-19 và EfficientNet-B2 0,6% và 2,4% với steptime tương đương, tương ứng.

Visualization và phân tích kiến trúc. Chúng tôi visualization kiến trúc của DNA-T và BossNet-T0 trong Hình 5. DNA-T rõ ràng ưa thích tích chập, vì nó chứa 13 khối ResConv và chỉ ba khối ResAtt. Ngược lại, BossNet-T0 có số lượng tích chập và attention tương tự và cuối cùng đạt được độ chính xác cao hơn. Chúng tôi gọi điều này là Hiện tượng I: sở thích ứng viên, và gán nó cho thiên vị kiến trúc từ giám sát giáo viên. Không sử dụng mô hình giáo viên, phương pháp của chúng tôi thành công tránh thiên vị này.

6

--- TRANG 7 ---
[Hình 6: Biểu đồ tương quan xếp hạng của 6 phương pháp NAS khác nhau]

Hình 6: Trái: Tương quan xếp hạng của 6 phương pháp NAS khác nhau trên Không gian tìm kiếm MBConv. Phải: Xếp hạng kiến trúc của BossNAS trên NATS-Bench SS. Trong tất cả các biểu đồ, trục x ký hiệu độ chính xác ground truth; trục y ký hiệu các chỉ số đánh giá.

[Bảng 2: Kết quả ImageNet của các mô hình NAS tiên tiến trên không gian tìm kiếm MBConv]

[Bảng 3: So sánh hiệu quả và hiệu suất của các phương pháp NAS khác nhau]

5.2. Kết quả trên Không gian tìm kiếm MBConv

Để tiếp tục chứng minh hiệu quả và khả năng tổng quát của BossNAS, chúng tôi so sánh nó với một loạt các phương pháp NAS trên không gian tìm kiếm MBConv.

Hiệu suất của các mô hình được tìm kiếm. Như được thể hiện trong Bảng 2, các mô hình được tìm kiếm của chúng tôi, BossNet-M, đạt được kết quả cạnh tranh trong các không gian tìm kiếm có và không có mô-đun SE. Trong không gian tìm kiếm không có SE, BossNet-M1, được tìm kiếm dưới ràng buộc 475M MAdds, vượt trội SPOS [22] và một phương pháp NAS không giám sát gần đây khác, RLNAS [87] 1,4% và 0,6%, tương ứng. Trong không gian tìm kiếm có SE, BossNet-M2, dưới ràng buộc 405M MAdds, vượt trội EfficientNet phổ biến [64] 1,1%, và cũng cạnh tranh với đối tác có giám sát của chúng tôi, DNA [37]. Lưu ý rằng các khối xây dựng ứng viên trong không gian tìm kiếm MBConv khá tương tự, che giấu hiện tượng sở thích ứng viên trong [37].

Độ chính xác đánh giá kiến trúc. Vì BossNAS thực hiện tìm kiếm duyệt qua (tức là độ chính xác của giai đoạn tìm kiếm là 100%), độ chính xác đánh giá kiến trúc trực tiếp đại diện cho hiệu quả của nó. Chúng tôi sử dụng 23 kiến trúc mã nguồn mở trong không gian tìm kiếm MBConv và độ chính xác ground truth tương ứng của chúng được cung cấp bởi [37] để tính toán độ chính xác đánh giá kiến trúc, tức là tương quan xếp hạng giữa xếp hạng kiến trúc được dự đoán và xếp hạng mô hình ground truth. Chúng tôi sử dụng ba chỉ số tương quan xếp hạng khác nhau: Kendall Tau (τ) [34], Spearman Rho (ρ) và Pearson R (R). Tất cả ba chỉ số dao động từ -1 đến 1, với "-1" đại diện cho một xếp hạng hoàn toàn đảo ngược, "1" có nghĩa là một xếp hạng hoàn toàn đúng, và "0" đại diện cho không có tương quan giữa các xếp hạng. Như được thể hiện trong Bảng 3 và Hình 6 trái, BossNAS của chúng tôi thu được độ chính xác đánh giá cao nhất với τ = 0,65 trong số các phương pháp NAS sota, trong khi giải quyết hai vấn đề.

Thứ nhất, các phương pháp chia sẻ trọng số cổ điển, SPOS [22] và DARTS [43], không đạt được tương quan xếp hạng hợp lý mặc dù chi phí tìm kiếm thấp hơn, trong khi phương pháp đa thử nghiệm, MnasNet [63], đạt được độ chính xác đánh giá cao với chi phí tìm kiếm khổng lồ. BossNAS thành công giải quyết tiến thoái lưỡng nan như vậy của NAS bằng cách đạt được độ chính xác đánh giá thậm chí cao hơn MnasNet (ví dụ +0,07 R) với tăng tốc 28,8×.

Thứ hai, phương pháp NAS theo khối có giám sát, DNA [37], không đạt được độ chính xác đánh giá cao khi sử dụng một giáo viên khác biệt lớn với các ứng viên (MobileNetV1 [30] vs. các ứng viên dựa trên EfficientNet [64]), điều mà chúng tôi gọi là Hiện tượng II: sở thích giáo viên. BossNAS không giám sát của chúng tôi đạt được độ chính xác đánh giá cao hơn DNA (+0,03 τ), thành công thoát khỏi ràng buộc của mạng giáo viên.

5.3. Kết quả trên NATS-Bench SS

Đối với không gian tìm kiếm size NATS-Bench SS, các thí nghiệm được tiến hành trên hai bộ dữ liệu: CIFAR-10 và CIFAR-100. Các ứng viên với số kênh khác nhau trong supernet của chúng tôi chia sẻ trọng số theo cách slimmable [78, 77, 76, 38, 9].

[Bảng 4: So sánh độ chính xác mô hình được tìm kiếm và độ chính xác đánh giá kiến trúc của các phương pháp NAS khác nhau trên NATS-Bench SS]

Hiệu suất của các mô hình được tìm kiếm. Sau khi tìm kiếm trên supernet của chúng tôi, chúng tôi tra cứu hiệu suất của các mô hình được tìm kiếm trong NATS-Bench SS để so sánh công bằng. Kết quả được thể hiện trong Bảng 4. BossNAS của chúng tôi vượt trội các phương pháp NAS gần đây [67,5] được thiết kế đặc biệt cho các không gian tìm kiếm kích thước mạng, chứng minh khả năng tổng quát của phương pháp chúng tôi trên các không gian tìm kiếm được chỉ định và các bộ dữ liệu tương đối nhỏ.

Độ chính xác đánh giá kiến trúc. Chúng tôi đánh giá tất cả 32768 kiến trúc trong không gian tìm kiếm để so sánh với độ chính xác ground truth của chúng trong benchmark trên bộ dữ liệu CIFAR-10. Như được thể hiện trong Hình 6 phải, tất cả các kiến trúc trong không gian tìm kiếm tạo thành một mẫu dày đặc, hình thoi, chứng minh hiệu quả của BossNAS của chúng tôi.

Ngoài ra, độ chính xác đánh giá kiến trúc trên bộ dữ liệu CIFAR-100 được thể hiện trong Bảng 4. Phương pháp của chúng tôi, không có quyền truy cập vào độ chính xác kiến trúc ground truth và thậm chí không có quyền truy cập vào bất kỳ nhãn được gán thích bởi con người nào, vượt trội một phương pháp NAS dựa trên bộ dự đoán [27], được huấn luyện với độ chính xác kiến trúc ground truth, với khoảng cách lớn (tức là +0,16 ρ và +0,19 R). Thêm phân tích về NATS-Bench SS có thể được tìm thấy trong Phụ lục A.3.

7

--- TRANG 8 ---
[Bảng 5: Phân tích ablation của các phương pháp huấn luyện và đánh giá trên Không gian tìm kiếm MBConv]

5.4. Nghiên cứu Ablation

Trong phần này, chúng tôi thực hiện các nghiên cứu ablation mở rộng trên không gian tìm kiếm MBConv và ImageNet để phân tích riêng biệt các phương pháp huấn luyện và đánh giá được đề xuất của chúng tôi.

Các phương pháp huấn luyện. Chúng tôi so sánh một số phương pháp huấn luyện cho supernet theo khối: (1) Phương pháp chưng cất có giám sát (Supv:distill.), sử dụng một mô hình giáo viên được tiền huấn luyện để cung cấp giám sát theo khối, tức là sơ đồ huấn luyện được sử dụng trong DNA [37] (2) Phân loại có giám sát (Supv:class.), sử dụng nhãn thực trực tiếp như giám sát theo khối. (3) Bootstrapping không giám sát (Unsupv:bootstrap.), trong đó các supernet Siamese được tối ưu hóa bằng bootstrapping các đường dẫn tương ứng trong hai mạng. (4) Phương pháp ensemble bootstrapping không giám sát của chúng tôi (Unsupv:EB), trong đó mỗi đường dẫn được lấy mẫu được tối ưu hóa bằng cách học để dự đoán ensemble xác suất của các đường dẫn được lấy mẫu từ giáo viên trung bình.

Như được thể hiện trong Bảng 5, phương pháp huấn luyện của chúng tôi vượt qua tất cả các phương pháp khác, đạt được kết quả tốt nhất trong độ chính xác đánh giá kiến trúc. Đặc biệt, bằng cách so sánh dòng thứ 3 và thứ 5, chúng ta có thể thấy rằng việc thay thế Unsupv:EB được đề xuất của chúng tôi bằng sơ đồ Unsupv:bootstrap. ngây thơ, độ chính xác đánh giá kiến trúc giảm mạnh 0,53 τ. Không có ensemble xác suất, bootstrapping không đạt được độ chính xác đánh giá hợp lý, chứng minh rằng ensemble bootstrapping được đề xuất là không thể thiếu cho BossNAS của chúng tôi.

Các phương pháp đánh giá. Tương tự như phân tích ablation của các phương pháp huấn luyện, chúng tôi cũng so sánh các phương pháp đánh giá của chúng tôi với (1) Phương pháp chưng cất có giám sát (Supv:distill.) và (2) Phân loại có giám sát (Supv:class.). Ngoài ra, để thực hiện phân tích ablation của đánh giá mà không thay đổi phương pháp huấn luyện, chúng tôi cũng so sánh với (3) đánh giá tuyến tính có giám sát (Supv:linear eval), trong đó các kiến trúc được đánh giá bằng cách cố định trọng số của supernet và tinh chỉnh một bộ phân loại tuyến tính chia sẻ trọng số để đánh giá mỗi kiến trúc. (4) Chỉ số đánh giá không giám sát của chúng tôi (Unsupv:eval) đánh giá các kiến trúc bằng khoảng cách của chúng đến trung tâm ensemble xác suất của toàn bộ không gian tìm kiếm. Từ hai dòng cuối của Bảng 5, chúng tôi ngạc nhiên phát hiện rằng Unsupv:eval của chúng tôi vượt trội sơ đồ đánh giá tuyến tính có giám sát trong đánh giá kiến trúc với khoảng cách đáng kể (+0,1 τ).

5.5. Hành vi hội tụ

Để tiếp tục thể hiện hiệu quả của BossNAS, chúng tôi điều tra độ chính xác đánh giá kiến trúc trong quá trình huấn luyện supernet trên không gian tìm kiếm MBConv với ImageNet. Ba chỉ số tương quan xếp hạng của BossNAS của chúng tôi trong 20 epoch huấn luyện được thể hiện trong Hình 7. Độ chính xác đánh giá kiến trúc tăng nhanh trong giai đoạn đầu và tiếp tục tăng với dao động nhỏ. Độ chính xác đánh giá hội tụ ở epoch thứ 12 và tiếp tục ổn định đến cuối giai đoạn huấn luyện. Khả năng đánh giá kiến trúc tăng ổn định chứng minh sự ổn định của BossNAS của chúng tôi. Ngoài ra, tương quan xếp hạng hội tụ nhanh chứng minh rằng phương pháp của chúng tôi dễ tối ưu hóa và không yêu cầu huấn luyện lâu hơn. Vui lòng tham khảo Phụ lục A.3 để phân tích hành vi hội tụ trên NATS-Bench SS.

[Hình 7: Tương quan xếp hạng trong quá trình huấn luyện supernet]

6. Kết luận

Trong công trình này, chúng tôi trình bày BossNAS, một phương pháp NAS không giám sát tổng quát với kỹ thuật huấn luyện ensemble bootstrapping và một chỉ số đánh giá không giám sát. Các thí nghiệm trên ba không gian tìm kiếm chứng minh rằng phương pháp của chúng tôi đã thành công giải quyết vấn đề đánh giá kiến trúc không chính xác gây ra bởi không gian chia sẻ trọng số lớn trong khi tránh thiên vị kiến trúc được mang lại bởi chưng cất có giám sát. Phân tích ablation chứng minh rằng hai thành phần, sơ đồ ensemble bootstrapping và chỉ số đánh giá không giám sát, đều rất quan trọng cho phương pháp của chúng tôi. Ngoài ra, chúng tôi trình bày một không gian tìm kiếm giống như vải được gọi là HyTra. Trên không gian tìm kiếm đầy thách thức này, mô hình CNN-transformer lai được tìm kiếm của chúng tôi đạt 82,5% độ chính xác trên ImageNet, vượt qua EfficientNet 2,4% với thời gian tính toán tương đương.

Lời cảm ơn

Công trình này được hỗ trợ một phần bởi Chương trình R&D Trọng điểm Quốc gia Trung Quốc dưới Số Grant 2020AAA0109700 và tài trợ của "Leading Innovation Team of the Zhejiang Province" (2018R01017). Tiến sĩ Xiaojun Chang được hỗ trợ một phần bởi Australian Research Council (ARC) Discovery Early Career Research Award (DECRA) dưới grant số DE190100626 và Intelligence Advanced Research Projects Activity (IARPA) thông qua Department of Interior/Interior Business Center (DOI/IBC).

8

--- TRANG 9 ---
Tài liệu tham khảo

[1] Youhei Akimoto, Shinichi Shirakawa, Nozomu Yoshinari, Kento Uchida, Shota Saito, và Kouhei Nishida. Adaptive stochastic natural gradient method for one-shot neural architecture search. Trong ICML, 2019. 12

[2] Bowen Baker, Otkrist Gupta, Nikhil Naik, và Ramesh Raskar. Designing neural network architectures using reinforcement learning. Trong ICLR, 2017. 2, 12

[3] Irwan Bello. Lambdanetworks: Modeling long-range interactions without attention. Trong ICLR, 2021. 1

[4] Gabriel Bender, Pieter-Jan Kindermans, Barret Zoph, Vijay Vasudevan, và Quoc V. Le. Understanding and simplifying one-shot architecture search. Trong ICML, 2018. 2, 12

[5] Gabriel Bender, Hanxiao Liu, Bo Chen, Grace Chu, Shuyang Cheng, Pieter-Jan Kindermans, và Quoc V Le. Can weight sharing outperform random architecture search? an investigation with tunas. Trong CVPR, 2020. 7

[6] Andrew Brock, Theodore Lim, James M. Ritchie, và Nick Weston. SMASH: one-shot model architecture search through hypernetworks. Trong ICLR, 2018. 2, 12

[7] Han Cai, Ligeng Zhu, và Song Han. Proxylessnas: Direct neural architecture search on target task and hardware. Trong ICLR, 2019. 3, 6, 7, 12

[8] Nicolas Carion, Francisco Massa, Gabriel Synnaeve, Nicolas Usunier, Alexander Kirillov, và Sergey Zagoruyko. End-to-end object detection with transformers. Trong ECCV, 2020. 1

[9] Minghao Chen, Houwen Peng, Jianlong Fu, và Haibin Ling. AutoFormer: Searching transformers for visual recognition. Trong ICCV, 2021. 1, 7, 13

[10] Ting Chen, Simon Kornblith, Mohammad Norouzi, và Geoffrey Hinton. A simple framework for contrastive learning of visual representations. Trong ICML, 2020. 3, 4

[11] Xinlei Chen và Kaiming He. Exploring simple siamese representation learning. Trong CVPR, 2021. 3, 4

[12] Yukang Chen, Gaofeng Meng, Qian Zhang, Shiming Xiang, Chang Huang, Lisen Mu, và Xinggang Wang. RENAS: reinforced evolutionary neural architecture search. Trong CVPR, 2019. 2, 5

[13] Xuelian Cheng, Yiran Zhong, Mehrtash Harandi, Yuchao Dai, Xiaojun Chang, Hongdong Li, Tom Drummond, và Zongyuan Ge. Hierarchical neural architecture search for deep stereo matching. Trong NeurIPS, 2020. 12

[14] Xiangxiang Chu, Zhi Tian, Bo Zhang, Xinlong Wang, Xiaolin Wei, Huaxia Xia, và Chunhua Shen. Conditional positional encodings for vision transformers. arXiv:2102.10882, 2021. 1, 5

[15] Xiangxiang Chu, Bo Zhang, và Ruijun Xu. FairNAS: Rethinking evaluation fairness of weight sharing neural architecture search. Trong ICCV, 2021. 3, 4, 7, 12

[16] Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, và Li Fei-Fei. Imagenet: A large-scale hierarchical image database. Trong CVPR, 2009. 6, 13

[17] Xuanyi Dong, Lu Liu, Katarzyna Musial, và Bogdan Gabrys. NATS-Bench: Benchmarking nas algorithms for architecture topology and size. IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2021. doi:10.1109/TPAMI.2021.3054824. 2, 3, 6, 12, 13

[18] Xuanyi Dong và Yi Yang. Searching for a robust neural architecture in four GPU hours. Trong CVPR, 2019. 12

[19] Xuanyi Dong và Yi Yang. NAS-Bench-201: Extending the scope of reproducible neural architecture search. Trong ICLR, 2020. 3

[20] Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, và Neil Houlsby. An image is worth 16x16 words: Transformers for image recognition at scale. Trong ICLR, 2021. 1, 5, 6

[21] Jean-Bastien Grill, Florian Strub, Florent Altché, Corentin Tallec, Pierre H Richemond, Elena Buchatskaya, Carl Doersch, Bernardo Avila Pires, Zhaohan Daniel Guo, Mohammad Gheshlaghi Azar, et al. Bootstrap your own latent: A new approach to self-supervised learning. Trong NeurIPS, 2020. 3, 4, 13

[22] Zichao Guo, Xiangyu Zhang, Haoyuan Mu, Wen Heng, Zechun Liu, Yichen Wei, và Jian Sun. Single path one-shot neural architecture search with uniform sampling. Trong ECCV, 2020. 4, 7, 12

[23] Kai Han, An Xiao, Enhua Wu, Jianyuan Guo, Chungjing Xu, và Yunhe Wang. Transformer in transformer. arXiv:2103.00112, 2021. 6

[24] Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, và Ross Girshick. Momentum contrast for unsupervised visual representation learning. Trong CVPR, 2020. 3, 4

[25] Kaiming He, Xiangyu Zhang, Shaoqing Ren, và Jian Sun. Deep residual learning for image recognition. Trong CVPR, 2016. 1, 5, 6, 13

[26] Shuting He, Hao Luo, Pichao Wang, Fan Wang, Hao Li, và Wei Jiang. TransReID: Transformer-based object re-identification. Trong ICCV, 2021. 1

[27] Daniel Hesslow và Iacopo Poli. Contrastive embeddings for neural architectures. arXiv:2102.04208, 2021. 3, 7, 8, 13

[28] R Devon Hjelm, Alex Fedorov, Samuel Lavoie-Marchildon, Karan Grewal, Phil Bachman, Adam Trischler, và Yoshua Bengio. Learning deep representations by mutual information estimation and maximization. Trong ICLR, 2019. 3

[29] Andrew Howard, Mark Sandler, Grace Chu, Liang-Chieh Chen, Bo Chen, Mingxing Tan, Weijun Wang, Yukun Zhu, Ruoming Pang, Vijay Vasudevan, Quoc V. Le, và Hartwig Adam. Searching for MobileNetV3. Trong ICCV, 2019. 2, 3, 7, 12

[30] Andrew G Howard, Menglong Zhu, Bo Chen, Dmitry Kalenichenko, Weijun Wang, Tobias Weyand, Marco Andreetto, và Hartwig Adam. Mobilenets: Efficient convolutional neural networks for mobile vision applications. arXiv:1704.04861, 2017. 1, 7

[31] Jie Hu, Li Shen, và Gang Sun. Squeeze-and-excitation networks. Trong CVPR, 2018. 1, 5, 6

[32] Yiming Hu, Yuding Liang, Zichao Guo, Ruosi Wan, Xiangyu Zhang, Yichen Wei, Qingyi Gu, và Jian Sun. Angle-based search space shrinking for neural architecture search. Trong ECCV, 2020. 3

9

--- TRANG 10 ---
[33] Yifan Jiang, Shiyu Chang, và Zhangyang Wang. Transgan: Two transformers can make one strong gan. arXiv:2102.07074, 2021. 1

[34] Maurice G Kendall. A new measure of rank correlation. Biometrika, 30(1/2):81–93, 1938. 7

[35] Nikos Komodakis và Spyros Gidaris. Unsupervised representation learning by predicting image rotations. Trong ICLR, 2018. 2, 13

[36] A. Krizhevsky và G. Hinton. Learning multiple layers of features from tiny images. Master's thesis, Department of Computer Science, University of Toronto, 2009. 6, 13

[37] Changlin Li, Jiefeng Peng, Liuchun Yuan, Guangrun Wang, Xiaodan Liang, Liang Lin, và Xiaojun Chang. Blockwisely supervised neural architecture search with knowledge distillation. Trong CVPR, 2020. 2, 3, 6, 7, 8, 12, 13

[38] Changlin Li, Guangrun Wang, Bing Wang, Xiaodan Liang, Zhihui Li, và Xiaojun Chang. Dynamic Slimmable Network. Trong CVPR, 2021. 7, 13

[39] Xiang Li, Chen Lin, Chuming Li, Ming Sun, Wei Wu, Junjie Yan, và Wanli Ouyang. Improving one-shot nas by suppressing the posterior fading. Trong CVPR, 2020. 2, 3

[40] Chenxi Liu, Liang-Chieh Chen, Florian Schroff, Hartwig Adam, Wei Hua, Alan L Yuille, và Li Fei-Fei. Auto-deeplab: Hierarchical neural architecture search for semantic image segmentation. Trong CVPR, 2019. 3

[41] Chenxi Liu, Piotr Dollár, Kaiming He, Ross Girshick, Alan Yuille, và Saining Xie. Are labels necessary for neural architecture search? Trong ECCV, 2020. 2, 4, 6, 13

[42] Chenxi Liu, Barret Zoph, Maxim Neumann, Jonathon Shlens, Wei Hua, Li-Jia Li, Li Fei-Fei, Alan Yuille, Jonathan Huang, và Kevin Murphy. Progressive neural architecture search. Trong ECCV, 2018. 3, 12

[43] Hanxiao Liu, Karen Simonyan, và Yiming Yang. DARTS: differentiable architecture search. Trong ICLR, 2019. 2, 3, 7, 12

[44] Ilya Loshchilov và Frank Hutter. Sgdr: Stochastic gradient descent with warm restarts. Trong ICLR, 2017. 13

[45] Hartmut Maennel, Ibrahim M Alabdulmohsin, Ilya O Tolstikhin, Robert Baldock, Olivier Bousquet, Sylvain Gelly, và Daniel Keysers. What do neural networks learn when trained with random labels? Trong NeurIPS, 2020. 3

[46] Bert Moons, Parham Noorzad, Andrii Skliar, Giovanni Mariani, Dushyant Mehta, Chris Lott, và Tijmen Blankevoort. Distilling optimal neural networks: Rapid search in diverse spaces. arXiv:2012.08859, 2020. 2, 3, 12

[47] Renato Negrinho và Geoffrey J. Gordon. Deeparchitect: Automatically designing and training deep architectures. arXiv:1704.08792, 2017. 2

[48] Mehdi Noroozi và Paolo Favaro. Unsupervised learning of visual representations by solving jigsaw puzzles. Trong ECCV, 2016. 2

[49] Aaron van den Oord, Yazhe Li, và Oriol Vinyals. Representation learning with contrastive predictive coding. arXiv:1807.03748, 2018. 3

[50] Niki Parmar, Ashish Vaswani, Jakob Uszkoreit, Lukasz Kaiser, Noam Shazeer, Alexander Ku, và Dustin Tran. Image transformer. Trong ICML, 2018. 1

[51] Jiefeng Peng, Jiqi Zhang, Changlin Li, Guangrun Wang, Xiaodan Liang, và Liang Lin. Pi-NAS: Improving neural architecture search by reducing supernet training consistency shift. Trong ICCV, 2021. 3, 12

[52] Hieu Pham, Melody Guan, Barret Zoph, Quoc Le, và Jeff Dean. Efficient neural architecture search via parameters sharing. Trong ICML, 2018. 3, 12

[53] Hieu Pham, Melody Y. Guan, Barret Zoph, Quoc V. Le, và Jeff Dean. Efficient neural architecture search via parameter sharing. Trong ICML, 2018. 2

[54] Esteban Real, Alok Aggarwal, Yanping Huang, và Quoc V. Le. Regularized evolution for image classifier architecture search. Trong AAAI, 2019. 3, 5, 12

[55] Pengzhen Ren, Yun Xiao, Xiaojun Chang, Po-Yao Huang, Zhihui Li, Xiaojiang Chen, và Xin Wang. A comprehensive survey of neural architecture search: Challenges and solutions. ACM Computing Surveys, 2021. 12

[56] Mark Sandler, Andrew G. Howard, Menglong Zhu, Andrey Zhmoginov, và Liang-Chieh Chen. Mobilenetv2: Inverted residuals and linear bottlenecks. Trong CVPR, 2018. 3

[57] Shreyas Saxena và Jakob Verbeek. Convolutional neural fabrics. Trong NeurIPS, 2016. 3, 5

[58] Christian Sciuto, Kaicheng Yu, Martin Jaggi, Claudiu Musat, và Mathieu Salzmann. Evaluating the search phase of neural architecture search. Trong ICLR, 2020. 3

[59] Zhiqiang Shen, Zhankui He, và Xiangyang Xue. Meal: Multi-model ensemble via adversarial learning. Trong AAAI, 2019. 4

[60] Zhiqiang Shen và Marios Savvides. Meal v2: Boosting vanilla resnet-50 to 80%+ top-1 accuracy on imagenet without tricks. arXiv:2009.08453, 2020. 4

[61] Han Shi, Renjie Pi, Hang Xu, Zhenguo Li, James Kwok, và Tong Zhang. Bridging the gap between sample-based and one-shot neural architecture search with bonas. Trong NeurIPS, 2020. 12

[62] Aravind Srinivas, Tsung-Yi Lin, Niki Parmar, Jonathon Shlens, Pieter Abbeel, và Ashish Vaswani. Bottleneck transformers for visual recognition. Trong CVPR, 2021. 1, 2, 5, 6

[63] Mingxing Tan, Bo Chen, Ruoming Pang, Vijay Vasudevan, Mark Sandler, Andrew Howard, và Quoc V. Le. Mnasnet: Platform-aware neural architecture search for mobile. Trong CVPR, 2019. 2, 3, 7, 12

[64] Mingxing Tan và Quoc V. Le. Efficientnet: Rethinking model scaling for convolutional neural networks. Trong ICML, 2019. 1, 2, 3, 6, 7, 12, 13

[65] Yonglong Tian, Dilip Krishnan, và Phillip Isola. Contrastive multiview coding. arXiv:1906.05849, 2019. 3

[66] Hugo Touvron, Matthieu Cord, Matthijs Douze, Francisco Massa, Alexandre Sablayrolles, và Hervé Jégou. Training data-efficient image transformers & distillation through attention. Trong ICML, 2021. 1, 5, 6, 13

[67] Alvin Wan, Xiaoliang Dai, Peizhao Zhang, Zijian He, Yuandong Tian, Saining Xie, Bichen Wu, Matthew Yu, Tao Xu, Kan Chen, et al. Fbnetv2: Differentiable neural architecture search for spatial and channel dimensions. Trong CVPR, 2020. 7

[68] Xiaolong Wang, Ross Girshick, Abhinav Gupta, và Kaiming He. Non-local neural networks. Trong CVPR, 2018. 5

10

--- TRANG 11 ---
[69] Chen Wei, Yiping Tang, Chuang Niu, Haihong Hu, Yue Wang, và Jimin Liang. Self-supervised representation learning for evolutionary neural architecture search. arXiv:2011.00186, 2020. 3

[70] Bichen Wu, Xiaoliang Dai, Peizhao Zhang, Yanghan Wang, Fei Sun, Yiming Wu, Yuandong Tian, Peter Vajda, Yangqing Jia, và Kurt Keutzer. Fbnet: Hardware-aware efficient convnet design via differentiable neural architecture search. Trong CVPR, 2019. 3, 7, 12

[71] Zhirong Wu, Yuanjun Xiong, Stella X Yu, và Dahua Lin. Unsupervised feature learning via non-parametric instance discrimination. Trong CVPR, 2018. 3

[72] Shen Yan, Yu Zheng, Wei Ao, Xiao Zeng, và Mi Zhang. Does unsupervised architecture representation learning help neural architecture search? Trong NeurIPS, 2020. 3

[73] Antoine Yang, Pedro M. Esperança, và Fabio Maria Carlucci. NAS evaluation is frustratingly hard. Trong ICLR, 2020. 3

[74] Chris Ying, Aaron Klein, Eric Christiansen, Esteban Real, Kevin Murphy, và Frank Hutter. Nas-bench-101: Towards reproducible neural architecture search. Trong ICML, 2019. 3

[75] Yang You, Igor Gitman, và Boris Ginsburg. Scaling sgd batch size to 32k for imagenet training. arXiv:1708.03888, 2017. 13

[76] Jiahui Yu và Thomas Huang. Autoslim: Towards one-shot architecture search for channel numbers. arXiv:1903.11728, 2019. 7, 13

[77] Jiahui Yu và Thomas S. Huang. Universally slimmable networks and improved training techniques. Trong ICCV, 2019. 7, 13

[78] Jiahui Yu, Linjie Yang, Ning Xu, Jianchao Yang, và Thomas S. Huang. Slimmable neural networks. Trong ICLR, 2019. 7, 13

[79] Li Yuan, Yunpeng Chen, Tao Wang, Weihao Yu, Yujun Shi, Francis EH Tay, Jiashi Feng, và Shuicheng Yan. Tokens-to-token vit: Training vision transformers from scratch on imagenet. Trong ICCV, 2021. 1, 6, 13

[80] Arber Zela, Julien Siems, và Frank Hutter. Nas-bench-1shot1: Benchmarking and dissecting one-shot neural architecture search. Trong ICLR, 2019. 3, 12

[81] Chiyuan Zhang, Samy Bengio, Moritz Hardt, Benjamin Recht, và Oriol Vinyals. Understanding deep learning requires rethinking generalization. arXiv:1611.03530, 2016. 3

[82] Miao Zhang, Huiqi Li, Shirui Pan, Xiaojun Chang, Zongyuan Ge, và Steven W. Su. Differentiable neural architecture search in equivalent space with exploration enhancement. Trong NeurIPS, 2020. 12

[83] Miao Zhang, Huiqi Li, Shirui Pan, Xiaojun Chang, và Steven W. Su. Overcoming multi-model forgetting in one-shot NAS with diversity maximization. Trong CVPR, 2020. 12

[84] Mingyang Zhang và Linlin Ou. Stage-wise channel pruning for model compression. arXiv:2011.04908, 2020. 2, 3

[85] Man Zhang, Yong Zhou, Jiaqi Zhao, Shixiong Xia, Jiaqi Wang, và Zizheng Huang. Semi-supervised blockwisely architecture search for efficient lightweight generative adversarial network. Pattern Recognition, 112:107794, 2021. 2, 3

[86] Richard Zhang, Phillip Isola, và Alexei A Efros. Colorful image colorization. Trong ECCV, 2016. 2

[87] Xuanyang Zhang, Pengfei Hou, Xiangyu Zhang, và Jian Sun. Neural architecture search with random labels. Trong CVPR, 2021. 2, 3, 4, 7, 12

[88] Sixiao Zheng, Jiachen Lu, Hengshuang Zhao, Xiatian Zhu, Zekun Luo, Yabiao Wang, Yanwei Fu, Jianfeng Feng, Tao Xiang, Philip HS Torr, et al. Rethinking semantic segmentation from a sequence-to-sequence perspective with transformers. Trong CVPR, 2021. 1

[89] Zhao Zhong, Junjie Yan, Wei Wu, Jing Shao, và Cheng-Lin Liu. Practical block-wise neural network architecture generation. Trong CVPR, 2018. 2

[90] Xizhou Zhu, Weijie Su, Lewei Lu, Bin Li, Xiaogang Wang, và Jifeng Dai. Deformable DETR: Deformable transformers for end-to-end object detection. Trong ICLR, 2021. 1

[91] Chengxu Zhuang, Alex Lin Zhai, và Daniel Yamins. Local aggregation for unsupervised learning of visual embeddings. Trong ICCV, 2019. 3

[92] Barret Zoph và Quoc V. Le. Neural architecture search with reinforcement learning. Trong ICLR, 2017. 2, 12

[93] Barret Zoph, Vijay Vasudevan, Jonathon Shlens, và Quoc V Le. Learning transferable architectures for scalable image recognition. Trong CVPR, 2018. 3

11

--- TRANG 12 ---
BossNAS: Khám phá CNN-transformer lai với Tìm kiếm Kiến trúc Neural
Tự giám sát theo Block-wisely
Tài liệu bổ sung

Changlin Li1, Tao Tang2, Guangrun Wang3;4, Jiefeng Peng3, Bing Wang5,
Xiaodan Liang2*, Xiaojun Chang6
1GORSE Lab, Dept. of DSAI, Monash University2Sun Yat-sen University3DarkMatter AI Research
4University of Oxford5Alibaba Group6RMIT University
changlin.li@monash.edu,
ftrent.tangtao,wanggrun,jiefengpeng,xdliang328 g@gmail.com,
fengquan.wb@alibaba-inc.com, xiaojun.chang@rmit.edu.au

A. Phụ lục

A.1. Tóm tắt ngắn gọn về NAS

Các phương pháp NAS nhằm tự động tối ưu hóa các kiến trúc mạng neural bằng cách khám phá các không gian tìm kiếm với các thuật toán tìm kiếm và đánh giá các kiến trúc bằng phương tiện của các sơ đồ đánh giá. Các phương pháp NAS có thể được chia thành hai danh mục tùy thuộc vào sơ đồ đánh giá được sử dụng, tức là NAS đa thử nghiệm và NAS chia sẻ trọng số. Các phương pháp NAS đa thử nghiệm [92,2,54,63,42,83] đánh giá tất cả các kiến trúc được lấy mẫu bằng cách huấn luyện chúng từ đầu, làm cho quá trình này có chi phí tính toán cấm đoán và khó triển khai trên các bộ dữ liệu lớn. Chúng hoặc thực hiện đánh giá kiến trúc bằng cách huấn luyện trên các bộ dữ liệu tương đối nhỏ (ví dụ CIFAR-10) [92,2,54] hoặc bằng cách huấn luyện trong vài epoch đầu tiên (ví dụ 5 epoch) [63] trên ImageNet.

Để tránh việc huấn luyện lặp lại các mạng ứng viên, các phương pháp NAS chia sẻ trọng số [7,43,18,1,6,13,82] tối ưu hóa một supernet mã hóa toàn bộ không gian tìm kiếm, sau đó đánh giá mỗi kiến trúc ứng viên theo trọng số kế thừa từ supernet. Trong số đó, các cách tiếp cận dựa trên gradient [43,7,70] và các cách tiếp cận dựa trên sampler [52,61] cùng tối ưu hóa trọng số của supernet và các yếu tố (hoặc agent) được sử dụng để chọn kiến trúc; về phần mình, các cách tiếp cận một lần1 [22,15,6,4,51] tối ưu hóa supernet trước khi thực hiện tìm kiếm với trọng số supernet bị đóng băng. Chúng tôi tham khảo [55] để có một đánh giá NAS toàn diện hơn.

*Tác giả liên hệ.
1Trong bài báo này, theo các công trình tiên phong SMASH [6] và One-shot [4], khi chúng tôi đề cập đến các phương pháp NAS một lần, chúng tôi đang thảo luận về những phương pháp kết hợp các phương pháp chia sẻ trọng số hai giai đoạn (tức là, một giai đoạn huấn luyện supernet và một giai đoạn tìm kiếm) thay vì NAS chia sẻ trọng số tổng quát được thảo luận trong [80].

A.2. Chi tiết triển khai

Các không gian tìm kiếm. Chúng tôi đánh giá phương pháp của chúng tôi trên ba không gian tìm kiếm:

• Không gian tìm kiếm HyTra. Phần bắt đầu của các mạng trong không gian tìm kiếm này là stem ResNet cổ điển giảm độ phân giải không gian xuống hệ số 4 với một lớp tích chập 7×7 có stride và một lớp max-pooling. Nó chứa L = 16 lớp khối lựa chọn tổng cộng, giống như ResNet50. Trước lớp khối lựa chọn đầu tiên, đầu vào có thể được down-sample thêm đến các thang đo khác nhau. Mô-đun downsampling bao gồm nhiều tích chập 3×3 với stride 2. Tại mỗi lớp khối lựa chọn, độ phân giải không gian có thể giữ nguyên hoặc được giảm xuống một nửa thang đo của nó, trừ khi đạt được thang đo nhỏ nhất 1/32. Như được giới thiệu trong Phần 4, không gian tìm kiếm này chứa hai lựa chọn ứng viên khác biệt: {ResConv; ResAtt}. Vì các khối transformer tốn kém trong các thang đo đầu tiên, chúng tôi chỉ bật lựa chọn ResAtt trong hai thang đo cuối cùng (tức là 1/16 và 1/32). Tổng kích thước của không gian tìm kiếm lai đầy thách thức này là khoảng 2,8×106.

• Không gian tìm kiếm MBConv. Không gian tìm kiếm giống MobileNet và các biến thể của nó thường được sử dụng làm benchmark cho các phương pháp NAS gần đây [63,29,64,7,70,15,37,46,87]. Theo Li et. al. [37], chúng tôi sử dụng một không gian tìm kiếm với 18 lớp và mỗi lớp chứa 4 khối MobileNet ứng viên (tổ hợp kích thước kernel {3;5} và tỷ lệ giảm {3;6}). Điều này dẫn đến một không gian tìm kiếm lớn chứa khoảng 418≈6,91×1010 kiến trúc.

• NATS-Bench SS. Không gian tìm kiếm size NATS-Bench SS[17] là một không gian tìm kiếm cấu hình kênh được xây dựng trên một kiến trúc dựa trên cell cố định với 5 lớp, trong đó các lớp thứ 2 và thứ 4 có tỷ lệ down-sample là 2. Số kênh trong mỗi lớp được chọn từ {8, 16, 24, 32, 40, 48, 56, 64}. SS có 85 = 32768 ứng viên kiến trúc tổng cộng. Các ứng viên với số kênh khác nhau trong supernet của chúng tôi chia sẻ trọng số theo cách slimmable [78,77,76,38,9]. Chúng tôi chia supernet thành 3 khối, theo kích thước không gian.

12

--- TRANG 13 ---
Các bộ dữ liệu. Các bộ dữ liệu chúng tôi sử dụng để đánh giá và phân tích phương pháp của chúng tôi bao gồm ImageNet [16], CIFAR-10 và CIFAR-100 [36]. ImageNet là một bộ dữ liệu quy mô lớn chứa 1,2 triệu hình ảnh tập huấn luyện và 50 nghìn hình ảnh tập xác thực trong 1000 lớp. Chúng tôi lấy mẫu ngẫu nhiên 50 nghìn hình ảnh từ tập huấn luyện ban đầu để tạo thành tập NAS-val cho đánh giá kiến trúc và sử dụng phần còn lại làm tập NAS-train cho huấn luyện supernet. Không có nhãn nào được sử dụng trong quá trình huấn luyện và tìm kiếm của phương pháp NAS của chúng tôi. Cuối cùng, các kiến trúc được tìm kiếm của chúng tôi được huấn luyện lại từ đầu trên tập huấn luyện và đánh giá trên tập xác thực. Đối với CIFAR-10 và CIFAR-100 [36], chúng tôi sử dụng các phần chia được đề xuất trong NATS-Bench [17]. CIFAR-10 được chia thành 25 nghìn tập huấn luyện, 25 nghìn tập xác thực, và 10 nghìn tập kiểm tra. CIFAR-100 được chia thành 50 nghìn tập huấn luyện, 5 nghìn tập xác thực, và 5 nghìn tập kiểm tra. Độ chính xác cuối cùng của các kiến trúc được tìm kiếm được truy vấn từ NATS-Bench SS[17].

Chi tiết huấn luyện.
Chúng tôi huấn luyện mỗi khối của supernet BossNAS trong 20 epoch bao gồm 1 epoch warm-up tuyến tính trên ImageNet. Đối với các bộ dữ liệu CIFAR tương đối nhỏ hơn, chúng tôi mở rộng nó lên 30 epoch. Trong mỗi bước huấn luyện, chúng tôi lấy mẫu ngẫu nhiên 4 đường dẫn cho ensemble bootstrapping. Các siêu tham số khác cho huấn luyện tự giám sát của supernet tuân theo chặt chẽ BYOL [21], chúng tôi sử dụng bộ tối ưu hóa LARS [75] với lịch trình tỷ lệ học cosine decay [44]. Tỷ lệ học cơ bản được đặt thành 4,8 cho tổng batchsize 4096.

Đối với huấn luyện lại ImageNet của các mô hình BossNet-T, chúng tôi tuân theo tương tự như DeiT [66], vì chúng tôi thấy nó mạnh mẽ cho cả CNN và transformer. Cụ thể hơn, chúng tôi sử dụng bộ tối ưu hóa AdamW với tỷ lệ học ban đầu 1e-3 và bộ lập lịch tỷ lệ học cosine, cho tổng kích thước batch 1024. Weight decay được đặt thành 0,05. Chúng tôi sử dụng mô hình EMA với tỷ lệ decay 0,99996 theo [79]. Vui lòng tham khảo DeiT [66] để biết thêm chi tiết về data-augmentation và regularization.

Đối với huấn luyện lại ImageNet của các mô hình BossNet-M, chúng tôi tuân theo chặt chẽ EfficientNet [64]. Chúng tôi sử dụng batchsize 4096, bộ tối ưu hóa RMSprop với momentum 0,9 và tỷ lệ học ban đầu 0,256 giảm 0,97 mỗi 2,4 epoch. Vui lòng tham khảo EfficientNet [64] để biết thêm chi tiết về các cài đặt khác.

Triển khai lại các phương pháp NAS khác trên HyTra.
Đối với DNA [37], chúng tôi sử dụng ResNet-50 [25] làm mô hình giáo viên. Chúng tôi chia supernet thành bốn khối, với bốn lớp trong mỗi khối, và huấn luyện mỗi khối trong 20 epoch. Các đặc trưng trung gian của mỗi khối của supernet học sinh và giáo viên đều được downsampled với global pooling và được chiếu với một lớp fully-connected trước khi tính toán mất mát chưng cất, vì thang đo của các khối ứng viên khác nhau không giống nhau trong không gian tìm kiếm HyTra. Các cài đặt khác tuân theo chặt chẽ DNA [37].

Đối với UnNAS [41], chúng tôi áp dụng nhiệm vụ pretext dự đoán xoay [35] (Rot), vì tính đơn giản của nó. Theo [41], chúng tôi sử dụng ba lớp tích chập stride-2 bổ sung ở đầu supernet để giảm độ phân giải không gian. Supernet được huấn luyện trong 2 epoch như trong [41].

A.3. Phân tích bổ sung trên NATS-Bench SS

So sánh đánh giá kiến trúc. Chúng tôi so sánh với phương pháp NAS dựa trên bộ dự đoán CE [27] bằng độ chính xác đánh giá kiến trúc trên CIFAR-10 và CIFAR-100. Như được thể hiện trong Hình 8, chúng tôi so sánh hai phương pháp NAS bằng cách vẽ tương quan của đánh giá kiến trúc và độ chính xác thực của 3000 kiến trúc được lấy mẫu ngẫu nhiên từ không gian tìm kiếm size NATS-Bench SS[17]. Các kiến trúc với BossNAS tạo thành mẫu phân tán dày đặc và nhọn hơn CE trên cả hai bộ dữ liệu. Hơn nữa, như được đo lường định lượng trong Bảng 6, BossNAS vượt trội CE với khoảng cách lớn (τ +0,11 và ρ +0,16) trong cả hai bộ dữ liệu.

[THIS IS FIGURE: Figure 8 showing comparison charts of architecture rating vs true accuracy for BossNAS and CE on CIFAR datasets]

[THIS IS TABLE: Table 6 showing architecture rating accuracy comparison between CE and BossNAS on NATS-Bench SS with CIFAR datasets]

13

--- TRANG 14 ---
[THIS IS FIGURE: Two graphs showing convergence behavior of BossNAS on NATS-Bench SS and CIFAR datasets, labeled as Figure 9]

Hình 9: Hành vi hội tụ của BossNAS trên NATS-Bench SS và các bộ dữ liệu CIFAR.

Hành vi hội tụ. Chúng tôi minh họa độ chính xác đánh giá kiến trúc của BossNAS trong giai đoạn huấn luyện supernet 30 epoch của nó trên các bộ dữ liệu CIFAR trong Hình 9. Độ chính xác đánh giá kiến trúc tăng nhanh và ổn định với những dao động nhỏ, theo cách tương tự như trên không gian tìm kiếm MBConv (Hình 7). Đặc biệt, độ chính xác đánh giá kiến trúc của BossNAS của chúng tôi hội tụ đến một kết quả thỏa đáng, ρ = 0,76, một cách mượt mà và nhanh chóng trong vòng chỉ 20 epoch trên CIFAR-100, và tiếp tục ổn định trong 10 epoch tiếp theo.

A.4. Visualization của các kiến trúc được thiết kế bởi con người trong HyTra

Các kiến trúc của ResNet50-T, ViT-T/16 và BoTNet50-T từ không gian tìm kiếm HyTra của chúng tôi được minh họa trong Hình 10. Kiến trúc của chúng tuân theo sát nhất có thể với kiến trúc của các nguyên mẫu của chúng.

[THIS IS FIGURE: Three architectural diagrams showing ResNet50-T, ViT-T/16, and BoTNet-T structures, labeled as Figure 10]

Hình 10: Visualization của các kiến trúc được thiết kế bởi con người trong HyTra. Nút màu xanh ký hiệu ResConv và nút màu đỏ ký hiệu ResAtt.

14

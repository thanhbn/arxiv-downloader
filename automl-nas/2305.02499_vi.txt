# 2305.02499.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/automl-nas/2305.02499.pdf
# Kích thước file: 748687 bytes

===============================================
NỘI DUNG FILE PDF
===============================================


--- TRANG 1 ---
AutoML-GPT: Học Máy Tự Động với GPT
Shujian Zhang Chengyue Gong Lemeng Wu Xingchao Liu
Mingyuan Zhou
Đại học Texas tại Austin
{szhang19, mzhou}@utexas.edu
Tóm tắt
Các tác vụ AI bao gồm một loạt rộng các lĩnh vực và ngành. Trong khi nhiều mô hình AI đã được thiết kế cho các tác vụ và ứng dụng cụ thể, chúng thường đòi hỏi những nỗ lực đáng kể từ con người trong việc tìm ra kiến trúc mô hình, thuật toán tối ưu hóa và siêu tham số phù hợp. Những tiến bộ gần đây trong các mô hình ngôn ngữ lớn (LLMs) như ChatGPT cho thấy khả năng đáng chú ý trong nhiều khía cạnh của lý luận, hiểu biết và tương tác. Do đó, chúng tôi đề xuất phát triển các prompt hướng tác vụ và tự động sử dụng LLMs để tự động hóa pipeline huấn luyện. Để thực hiện khái niệm này, chúng tôi trình bày AutoML-GPT, sử dụng GPT như cầu nối đến các mô hình AI đa dạng và huấn luyện động các mô hình với siêu tham số được tối ưu hóa. AutoML-GPT động lấy yêu cầu của người dùng từ các thẻ mô hình và dữ liệu và tạo thành đoạn prompt tương ứng. Cuối cùng, với đoạn prompt này, AutoML-GPT sẽ tự động tiến hành các thử nghiệm từ xử lý dữ liệu đến kiến trúc mô hình, điều chỉnh siêu tham số, và nhật ký huấn luyện dự đoán. Bằng cách tận dụng khả năng ngôn ngữ mạnh mẽ của AutoML-GPT và các mô hình AI có sẵn, AutoML-GPT có thể giải quyết nhiều tác vụ AI phức tạp trên các tác vụ và bộ dữ liệu khác nhau. Phương pháp này đạt được kết quả đáng chú ý trong thị giác máy tính, xử lý ngôn ngữ tự nhiên và các lĩnh vực thách thức khác. Các thử nghiệm rộng rãi và nghiên cứu ablation chứng minh rằng phương pháp của chúng tôi có thể tổng quát, hiệu quả và có lợi cho nhiều tác vụ AI.

1 Giới thiệu
Trí tuệ nhân tạo (AI) đã trải qua những tiến bộ đáng kể gần đây. Trong số những phát triển này, ChatGPT [OpenAI, 2023] đã đặc biệt nổi bật do khả năng lý luận, hiểu biết và tương tác [Wu et al., 2023]. Khả năng thực hiện các tác vụ mới dựa trên hướng dẫn là một bước quan trọng hướng tới việc đạt được trí tuệ nhân tạo tổng quát, và khả năng đáng chú ý của các mô hình ngôn ngữ lớn (LLMs) đã thúc đẩy nhiều chủ đề nghiên cứu mới nổi, chẳng hạn như học tập trong ngữ cảnh [Ram et al., 2023; Xie et al., 2021], prompt chuỗi tư duy [Pilault et al., 2023; Wei et al., 2022b], truy xuất và đọc [Izacard and Grave, 2020; Zhang et al., 2021, 2022], và các hệ thống thông minh dựa trên GPT [Zheng et al., 2023]. Những lĩnh vực này nhằm khám phá tiềm năng to lớn của LLMs và mang lại cơ hội vô hạn cho việc xây dựng các hệ thống AI phức tạp.

LLMs, chẳng hạn như GPT-4 [Brown et al., 2020; OpenAI, 2023], LLaMA [Touvron et al., 2023], Flan-T5 [Chung et al., 2022], và PaLM [Chowdhery et al., 2022], đã chứng minh sự hiểu biết sâu sắc về ngôn ngữ tự nhiên và khả năng tạo ra các phản hồi mạch lạc, phù hợp với ngữ cảnh. Tiến bộ này đã mở ra các ứng dụng tiềm năng mới cho các tác vụ thách thức liên quan đến dữ liệu lĩnh vực khác nhau, chẳng hạn như xử lý hình ảnh và văn bản, cũng như việc kết hợp kiến thức chuyên ngành. Trong bối cảnh này, LLMs đóng vai trò quan trọng, vì khả năng hiểu biết và tạo ra ngôn ngữ tự nhiên của chúng cho phép AI hiểu và giải quyết tốt hơn một loạt rộng các thách thức.

Trong bài báo này, chúng tôi nhằm phát triển một hệ thống Học Máy Tự Động (AutoML) có tên AutoML-GPT, sử dụng LLMs để tự động huấn luyện các mô hình trên bộ dữ liệu với đầu vào và mô tả của người dùng. LLMs được sử dụng như một hệ thống huấn luyện tự động để thiết lập kết nối với các mô hình đa năng và xử lý đầu vào. Chúng tôi đề xuất sử dụng ngôn ngữ như một giao diện và prompt phổ quát cho LLMs tương tác với người dùng. Bằng cách kết hợp cả mô tả dữ liệu và mô hình vào prompts, LLMs có thể quản lý các mô hình AI cho xử lý dữ liệu, thiết kế kiến trúc mô hình và điều chỉnh siêu tham số. Chúng có thể gọi các mô hình này khi cần thiết để giải quyết các tác vụ AI và trả về nhật ký huấn luyện dự đoán. Tuy nhiên, việc kết hợp nhiều mô hình AI vào LLMs đòi hỏi một số lượng đáng kể các mô tả mô hình chất lượng cao. Để vượt qua thách thức này, chúng tôi khuyến nghị khai thác cả thẻ mô hình [Mitchell et al., 2019] cung cấp mô tả mô hình được định nghĩa rõ ràng và thẻ dữ liệu [Gebru et al., 2021] cho các tác vụ AI cụ thể. Phương pháp này sẽ cho phép chúng tôi kết nối các mô hình đa dạng thông qua giao diện dựa trên ngôn ngữ, từ đó tạo điều kiện cho việc giải quyết các tác vụ AI phức tạp. Nó cũng có thể tăng cường khả năng chuyển giao giữa các mô hình và bộ dữ liệu bằng cách nắm bắt sự tương tự của chúng.

AutoML-GPT kết nối các mô hình học máy đa năng, pipeline huấn luyện và bộ dữ liệu để giải quyết nhiều tác vụ AI phức tạp. Cụ thể hơn, đối với mỗi tác vụ AI chúng tôi nhằm giải quyết, sử dụng mô tả tương ứng của nó (chẳng hạn như thẻ mô hình và thẻ dữ liệu), chúng tôi hợp nhất đoạn văn làm prompt vào LLMs được đào tạo trước (chẳng hạn như ChatGPT) để thiết lập pipeline AutoML. Sau đó, trong hệ thống của chúng tôi, LLMs thực hiện huấn luyện tự động để trả về nhật ký huấn luyện dự đoán cho các câu hỏi đầu vào của người dùng. Dựa trên những nhật ký huấn luyện này, chúng tôi có thể tương tác thêm với LLM để giải quyết các yêu cầu (chẳng hạn như điều chỉnh siêu tham số) được hiển thị trong Hình 1. Do đó, toàn bộ quá trình của AutoML-GPT có thể được chia thành bốn giai đoạn: 1) xử lý dữ liệu, 2) thiết kế kiến trúc mô hình, 3) điều chỉnh siêu tham số với nhật ký huấn luyện dự đoán, 4) phản hồi của con người về dữ liệu thử nghiệm.

Được hưởng lợi từ thiết kế như vậy, AutoML-GPT trong Hình 1 có thể sử dụng các mô hình bên ngoài và do đó có thể xử lý nhiều tác vụ trên các benchmark nổi tiếng, và chuyển giao kiến thức đến bộ dữ liệu riêng tư chưa biết khi chỉ được cung cấp metadata (thẻ dữ liệu). Hơn nữa, pipeline này cũng cho phép AutoML-GPT tiếp tục hấp thụ sức mạnh từ các chuyên gia chuyên biệt về tác vụ, cho phép khả năng AI có thể phát triển và mở rộng. Tóm lại, những đóng góp của chúng tôi như sau:

• Để bổ sung cho những ưu điểm của các mô hình ngôn ngữ lớn và mô hình chuyên gia, chúng tôi đề xuất AutoML-GPT, hoạt động như hệ thống xử lý dữ liệu và thiết kế kiến trúc mô hình và tự động tiến hành các thử nghiệm cho từng tác vụ cụ thể.

• Bằng cách tích hợp thẻ mô hình với mô tả mô hình và thẻ dữ liệu với mô tả dữ liệu, chúng tôi cung cấp một đoạn prompt định dạng cố định và xây dựng pipeline huấn luyện để giải quyết các tác vụ AI tổng quát.

• Các đánh giá rộng rãi về nhiều tác vụ AI trên ngôn ngữ, thị giác và học tập liên tục chứng minh khả năng của AutoML-GPT trong huấn luyện tự động. Nó tiếp tục chứng minh hiệu quả của việc cung cấp điều chỉnh siêu tham số cho bộ dữ liệu chưa thấy hoặc mới.

[Hình 1: Tổng quan về AutoML-GPT. Một số ký hiệu được ghi nhãn cùng với các thành phần tương ứng. 'Eval Metrics & Add' đề cập đến các độ đo đánh giá và yêu cầu bổ sung.]

2 AutoML-GPT

AutoML-GPT là một hệ thống cộng tác dựa vào thông tin dữ liệu và mô hình để định dạng đoạn đầu vào prompt. LLM đóng vai trò như bộ điều khiển, trong khi nhiều mô hình chuyên gia như những người thực thi cộng tác.

--- TRANG 2 ---

Quy trình làm việc của AutoML-GPT bao gồm bốn giai đoạn: xử lý dữ liệu, thiết kế kiến trúc mô hình, điều chỉnh siêu tham số và tạo nhật ký huấn luyện. Cụ thể, chúng tôi đề xuất một công thức chung cho AutoML-GPT: 1) tạo một đoạn prompt định dạng cố định với cả thẻ mô hình và thẻ dữ liệu, 2) xây dựng pipeline huấn luyện và xử lý yêu cầu người dùng trên bộ dữ liệu đã chọn và kiến trúc mô hình, 3) tạo nhật ký huấn luyện hiệu suất và điều chỉnh siêu tham số, và 4) điều chỉnh mô hình với siêu tham số được đề xuất tự động.

2.1 Phân tách Đầu vào

Trong giai đoạn đầu tiên của AutoML-GPT, một LLM nhận đầu vào từ người dùng. Để tăng hiệu suất của LLM và tạo ra một prompt hiệu quả, chúng tôi sử dụng các hướng dẫn cụ thể cho prompt đầu vào. Các hướng dẫn chứa ba phần được mô tả dưới đây.

Thẻ Dữ liệu Để làm rõ các trường hợp sử dụng dự định của bộ dữ liệu và giảm thiểu việc sử dụng chúng trong các ngữ cảnh mà chúng không phù hợp, chúng tôi sử dụng thẻ dữ liệu cung cấp tài liệu toàn diện cho bộ dữ liệu này. Như được hiển thị trong Hình 2, các thành phần chính của thẻ dữ liệu bao gồm tên bộ dữ liệu, loại dữ liệu đầu vào (ví dụ: dữ liệu hình ảnh hoặc dữ liệu văn bản), không gian nhãn (ví dụ: các loại lớp hoặc độ phân giải), và các độ đo đánh giá mặc định.

[Hình 2: Thẻ Dữ liệu bao gồm tên dữ liệu, loại dữ liệu đầu vào, không gian nhãn và độ đo đánh giá. Trong thẻ dữ liệu, cùng màu biểu thị thông tin có nguồn gốc từ một bộ dữ liệu duy nhất.]

Thẻ Mô hình Các thẻ mô hình trong Hình 3, bổ sung cho "Thẻ Dữ liệu" đã thảo luận trước đó, đóng vai trò như một trong những mô hình được đề xuất báo cáo chi tiết của mô hình được sử dụng để huấn luyện và kiểm tra bộ dữ liệu. Thẻ mô hình bao gồm tên mô hình, cấu trúc mô hình (ví dụ: Swin transformer [Liu et al., 2021] với đầu UperNet [Xiao et al., 2018]), mô tả mô hình và siêu tham số kiến trúc. Bằng cách cung cấp thông tin này, thẻ mô hình thông báo cho LLM về các hệ thống học máy được sử dụng và mức độ linh hoạt mà người dùng muốn có trên kiến trúc mô hình. Nó sẽ tiếp tục tạo ra các kết quả toàn diện hơn với LLM.

[Hình 3: Thẻ Mô hình bao gồm tên mô hình, cấu trúc mô hình, mô tả mô hình và siêu tham số kiến trúc. Trong thẻ mô hình, cùng màu đại diện cho thông tin từ một thẻ mô hình duy nhất.]

--- TRANG 3 ---

Độ đo Đánh giá và Yêu cầu Bổ sung Ngoài thẻ mô hình và thẻ dữ liệu, người dùng có thể có tùy chọn yêu cầu thêm benchmark đánh giá, độ đo hoặc bất kỳ ràng buộc nào. Ngoại trừ các độ đo đánh giá mặc định, chúng tôi có thể thêm các độ đo hoặc ràng buộc cụ thể theo yêu cầu của người dùng khi chọn kiến trúc mô hình. Ví dụ, với ràng buộc "thời gian suy luận nhỏ hơn 10 FPS," chúng tôi sau đó xử lý yêu cầu người dùng dưới các độ đo đánh giá và ràng buộc. Được hưởng lợi từ hướng dẫn này và phản hồi của con người về các độ đo đánh giá và yêu cầu bổ sung này, LLM có thể tuân theo hướng dẫn tốt hơn. AutoML-GPT cung cấp những đặc tả tác vụ này cho LLM như hướng dẫn cấp cao để phân tích yêu cầu của người dùng một cách phù hợp.

2.2 Xử lý Dữ liệu

Xử lý dữ liệu là một bước tích hợp trong học máy vì chất lượng dữ liệu và thông tin hữu ích được rút ra từ đó ảnh hưởng trực tiếp đến khả năng học của mô hình. Do đó, việc xử lý dữ liệu trước khi đưa vào mô hình là rất quan trọng. Ví dụ, trong thị giác máy tính, xử lý dữ liệu đề cập đến tập hợp các kỹ thuật và phương pháp được sử dụng để chuẩn bị dữ liệu hình ảnh thô cho phân tích hoặc thuật toán học máy. Điều này có thể bao gồm thay đổi kích thước hình ảnh, chuẩn hóa, tăng cường và lọc. Tương tự, trong các dự án Xử lý Ngôn ngữ Tự nhiên (NLP), xử lý dữ liệu đề cập đến việc chuyển đổi dữ liệu văn bản thô thành định dạng có cấu trúc và sạch mà các thuật toán học máy có thể dễ dàng hiểu và xử lý. Các kỹ thuật như tokenization, loại bỏ từ dừng, chuyển thành chữ thường và loại bỏ ký tự đặc biệt và số thường được sử dụng. Dựa trên thẻ dữ liệu và mô tả dữ liệu được cung cấp, AutoML-GPT cung cấp các kỹ thuật xử lý cụ thể tùy thuộc vào yêu cầu của dự án và bản chất của dữ liệu.

2.3 Kiến trúc Mô hình

Sau khi xử lý danh sách các tác vụ, AutoML-GPT cần khớp mỗi tác vụ với một mô hình tương ứng, về cơ bản là chọn mô hình phù hợp cho mọi tác vụ trong danh sách. Để đạt được điều này, chúng tôi trước tiên thu thập thẻ mô hình và mô tả của các mô hình từ đầu vào người dùng. Sau đó, chúng tôi gán động các mô hình cho tác vụ bằng cách sử dụng cơ chế gán tác vụ-mô hình trong ngữ cảnh. Phương pháp này cho phép truy cập mô hình tăng dần và cung cấp tính mở và linh hoạt hơn bằng cách kết hợp các mô tả mô hình được cung cấp và hiểu biết tốt hơn về yêu cầu người dùng.

Kiến trúc mô hình đề cập đến những giải thích chi tiết về thiết kế, cấu trúc và thành phần của một mô hình học máy. Những mô tả này thường bao gồm các yếu tố sau: lớp đầu vào và đầu ra, lớp ẩn, hàm kích hoạt, hàm mất mát và các thành phần đặc biệt cho mô hình (chẳng hạn như cơ chế attention, lớp tích chập hoặc lớp hồi quy).

2.4 Điều chỉnh Siêu tham số với Nhật ký Huấn luyện Dự đoán

Để tìm tập siêu tham số tối ưu mang lại hiệu suất tốt nhất cho một mô hình cụ thể trên một bộ dữ liệu cụ thể, điều chỉnh siêu tham số là một bước quan trọng trong học máy. Siêu tham số là các cài đặt cấu hình không được học trong quá trình huấn luyện mà được xác định trước và kiểm soát các khía cạnh khác nhau của hành vi học của mô hình. Ví dụ về các siêu tham số phổ biến bao gồm tốc độ học, kích thước batch, số lớp ẩn và số neuron mỗi lớp.

Để điều chỉnh siêu tham số mà không cần huấn luyện trên máy thực, chúng tôi dự đoán hiệu suất bằng cách tạo nhật ký huấn luyện cho một cài đặt siêu tham số cụ thể cho thẻ dữ liệu và thẻ mô hình được cung cấp. AutoML-GPT sẽ tự động tiến hành huấn luyện và trả về nhật ký huấn luyện. Nhật ký huấn luyện của hiệu suất mô hình trên bộ dữ liệu ghi lại các độ đo và thông tin khác nhau được thu thập trong quá trình huấn luyện. Nó giúp hiểu tiến trình của mô hình, xác định các vấn đề tiềm ẩn và đánh giá hiệu quả của kiến trúc đã chọn, siêu tham số và kỹ thuật tối ưu hóa. Một nhật ký huấn luyện điển hình bao gồm số epoch với các độ đo huấn luyện và validation. Bằng cách kiểm tra nhật ký huấn luyện, chúng ta có thể hình thành hiểu biết cơ bản về hiệu suất mô hình theo phản hồi của người dùng.

--- TRANG 4 ---

Bộ dữ liệu Chưa thấy Điều chỉnh siêu tham số cho các bộ dữ liệu riêng tư chưa thấy có thể thậm chí còn thách thức hơn. Với metadata của một bộ dữ liệu chưa thấy, AutoML-GPT có thể khuyến nghị một cấu hình siêu tham số có khả năng hiệu quả cho bộ dữ liệu đó. Chúng tôi dựa vào thẻ dữ liệu để tận dụng các mô tả văn bản cần thiết và xác định mối tương quan giữa bộ dữ liệu chưa thấy và các bộ dữ liệu hiện có. Dựa trên mối tương quan, chúng tôi chuyển giao cài đặt siêu tham số từ các bộ dữ liệu hiện có sang bộ dữ liệu mới chưa thấy.

Để tính toán mối tương quan, chúng tôi sử dụng một bộ mã hóa văn bản để mã hóa thẻ dữ liệu. Cụ thể, trong thẻ dữ liệu, nó chứa thông tin như loại lớp, độ phân giải, kích thước hình ảnh và metadata liên quan khác. Chúng tôi lấy quy mô bộ dữ liệu, mô tả tác vụ, không gian nhãn và loại dữ liệu đầu vào/đầu ra làm đầu vào cho bộ mã hóa văn bản (ví dụ: CLIP [Radford et al., 2021]) và mô tả mối tương quan giữa bộ dữ liệu chưa thấy này và các bộ dữ liệu hiện có bằng điểm tương tự của biểu diễn tiềm ẩn được mã hóa.

3 Thử nghiệm

Chúng tôi đánh giá hiệu suất của AutoML-GPT và triển khai nó bằng ChatGPT (phiên bản "GPT-4" của OpenAI)¹. Các nghiên cứu trường hợp khác nhau được thực hiện để thể hiện hiệu quả của phương pháp chúng tôi từ nhiều góc độ.

3.1 Bộ dữ liệu Chưa thấy

Trong Hình 4, chúng tôi trình bày kết quả huấn luyện trên bộ dữ liệu chưa thấy bằng AutoML-GPT. Để xác minh hiệu suất trong các trường hợp thực tế, chúng tôi xây dựng một tập hợp hiệu suất và siêu tham số trên các bộ dữ liệu đã được huấn luyện, và một số bộ dữ liệu chưa được huấn luyện sắp tới. Chúng tôi sẽ dự đoán cấu hình siêu tham số cho các bộ dữ liệu chưa huấn luyện này. Chúng tôi tạo môi trường kiểm tra dựa trên cài đặt phân loại được mô tả trong Vinyals et al. [2016]. Chúng tôi cũng tuân theo MiniImageNet [Vinyals et al., 2016] để lấy mẫu con và chia bộ dữ liệu huấn luyện [Deng et al., 2009] thành phần 80% và 20%. Từ dữ liệu 80%, chúng tôi xây dựng thẻ dữ liệu và thẻ mô hình tương ứng (chứa siêu tham số tốt nhất của mô hình). Chúng tôi chọn ngẫu nhiên mười lăm lớp để tạo các bộ dữ liệu con khác nhau (ví dụ: bộ dữ liệu A, B, v.v.), tìm kiếm lưới siêu tham số, tinh chỉnh mô hình ViT base [Dosovitskiy et al., 2020] và ghi lại hiệu suất tốt nhất trên các bộ dữ liệu con này. Sau đó chúng tôi tạo một bộ dữ liệu mới có tên "New" với mười lớp hình ảnh từ dữ liệu 20% còn lại.

¹https://platform.openai.com/

--- TRANG 5 ---

[Hình 4: Tổng quan về AutoML-GPT cho bộ dữ liệu chưa thấy: khối trên hiển thị thẻ dữ liệu và thông tin mô hình. Chúng tôi trước tiên ghi lại thông tin huấn luyện cho một số bộ dữ liệu. Thẻ dữ liệu cho các bộ dữ liệu này được xử lý thông qua bộ mã hóa văn bản để có được điểm tương tự, sau đó được kết hợp với tham số mô hình của các mô hình được huấn luyện tương ứng để tạo thành đoạn prompt AutoML-GPT. Khối dưới trình bày nhật ký huấn luyện dự đoán dựa trên cài đặt siêu tham số được khuyến nghị cho bộ dữ liệu chưa thấy.]

Để chứng minh khả năng của phương pháp chúng tôi trên các bộ dữ liệu chưa thấy, chúng tôi sử dụng AutoML-GPT để khuyến nghị cấu hình huấn luyện tốt nhất cho bộ dữ liệu "New" dựa trên thẻ dữ liệu và thẻ mô hình được cung cấp. Trong thẻ dữ liệu của chúng tôi, chúng tôi ghi lại không gian nhãn, tức là mô tả văn bản cho mỗi lớp. Trong thực tế, chúng tôi kết hợp điểm tương tự giữa hai thẻ dữ liệu bằng cách truyền văn bản trong thẻ dữ liệu qua bộ mã hóa văn bản, ví dụ: bộ mã hóa văn bản CLIP, và tính toán độ tương tự. Cụ thể, trong Hình 4, chúng tôi nói rằng bộ dữ liệu "New" có 60% tương tự không gian nhãn với bộ dữ liệu A và 40% tương tự không gian nhãn với bộ dữ liệu B. Sử dụng thông tin này và cài đặt siêu tham số trong thẻ dữ liệu cho bộ dữ liệu A và B, AutoML-GPT có thể khuyến nghị cài đặt siêu tham số phù hợp để huấn luyện trên bộ dữ liệu "New". Trong thử nghiệm của chúng tôi, chúng tôi đạt được độ chính xác 98% cho dự đoán Top 1, so với độ chính xác Top 1 80% với siêu tham số được chọn ngẫu nhiên trung bình. Hơn nữa, chúng tôi cũng khởi tạo mô hình bằng cách sử dụng cài đặt siêu tham số được đề xuất từ AutoML-GPT mà không cung cấp bất kỳ bộ dữ liệu bổ sung nào. Với cấu hình này, chúng tôi đạt được độ chính xác Top 1 82%, tốt hơn so với siêu tham số được chọn ngẫu nhiên trung bình nhưng không tốt bằng cài đặt được khuyến nghị của chúng tôi. Điều này cũng cho thấy rằng ChatGPT có thể đưa ra cài đặt siêu tham số tốt cho một tác vụ cụ thể (ví dụ: phân loại hình ảnh). Điều này chứng minh hiệu quả của phương pháp huấn luyện tự động được đề xuất trong việc giải quyết các vấn đề học máy, ngay cả với các bộ dữ liệu chưa thấy hoặc mới. Những phát hiện này nổi bật tiềm năng của phương pháp huấn luyện tự động trong việc tăng cường học máy bằng cách cung cấp các khuyến nghị siêu tham số chính xác.

3.2 Phát hiện Đối tượng

Hình 5 trình bày kết quả của chúng tôi trên bộ dữ liệu COCO [Lin et al., 2014] cho phát hiện đối tượng. À Khối trên hiển thị thẻ dữ liệu cho bộ dữ liệu COCO và thẻ mô hình cho ImageNet, dựa trên đầu vào người dùng. Khối giữa chứng minh Đoạn Prompt AutoML-GPT được rút ra từ phân tách đầu vào. Thông tin từ thẻ dữ liệu và thẻ mô hình được tự động kết hợp vào định dạng prompt của chúng tôi. Chúng tôi báo cáo kết quả cho xử lý dữ liệu, thiết kế kiến trúc mô hình, điều chỉnh siêu tham số và tạo nhật ký huấn luyện. Á Trong xử lý dữ liệu, AutoML-GPT tạo ra một script để xử lý bộ dữ liệu đầu vào. Chúng tôi cũng cung cấp một ví dụ script Python trong Hình 5. Đối với thiết kế kiến trúc mô hình, pipeline của chúng tôi tạo ra một thành phần mô hình để huấn luyện sau này. Khi cả dữ liệu và mô hình đã được chuẩn bị, các cấu hình chi tiết được cung cấp trong giai đoạn điều chỉnh siêu tham số (ví dụ: tốc độ học: 10⁻⁴, weight decay: 10⁻⁴) và được điều chỉnh thêm với nhật ký huấn luyện dự đoán. Â Những kết quả này tiếp tục xác nhận rằng phương pháp của chúng tôi có thể đóng vai trò như

--- TRANG 6 ---

[Hình 5: Tổng quan về AutoML-GPT cho phát hiện đối tượng: Khối trên hiển thị thẻ dữ liệu và thẻ mô hình. Khối giữa thể hiện đoạn prompt AutoML-GPT, được rút ra từ thẻ dữ liệu và thẻ mô hình. Khối dưới phác thảo bốn bước: xử lý dữ liệu, kiến trúc mô hình, điều chỉnh siêu tham số và nhật ký huấn luyện dự đoán. Chúng tôi sử dụng nhật ký huấn luyện dự đoán để điều chỉnh siêu tham số trước khi phản hồi siêu tham số cho người dùng.]

một pipeline hiệu quả để linh hoạt thích ứng LLMs với các tác vụ downstream. Phương pháp của chúng tôi, sử dụng thẻ dữ liệu và mô hình để rút ra đoạn prompt AutoML-GPT, cũng có thể được coi là một mô-đun bổ sung cho các công trình tập trung vào việc tăng cường các thành phần prompt LLM.

3.3 Hỏi đáp

Chúng tôi trình bày kết quả thử nghiệm trên bộ dữ liệu Natural Questions Open [Kwiatkowski et al., 2019] trong Hình 6. Chúng tôi sử dụng Dense Passage Retrieval (DPR) [Karpukhin et al., 2020]. ¬ Đối với thẻ dữ liệu, người dùng nhập tên dữ liệu, loại dữ liệu đầu vào, không gian nhãn và độ đo đánh giá. ­ Đối với thẻ mô hình, nó bao gồm tên mô hình, cấu trúc mô hình, mô tả mô hình và siêu tham số kiến trúc. ® Với đoạn prompt AutoML-GPT được tạo, AutoML-GPT thực hiện xử lý dữ liệu, tạo kiến trúc mô hình, điều chỉnh siêu tham số và tạo nhật ký huấn luyện dự đoán. Như thấy trong "Điều chỉnh Siêu tham số," các siêu tham số được tạo bởi AutoML-GPT và những cái được cung cấp bởi DPR khớp chặt chẽ, ví dụ: tốc độ học là 10⁻⁵ và max epochs là 40. ¯ Khi nhật ký huấn luyện dự đoán có sẵn, chúng tôi thể hiện một kịch bản mà người dùng có thể yêu cầu AutoML-GPT về các độ đo đánh giá hoặc kiến trúc mô hình khác nhau dựa trên yêu cầu của họ, như được minh họa trong Hình 6 "Yêu cầu bổ sung: thời gian suy luận nhanh cho bộ truy xuất DPR." Như thấy trong phản hồi trả về trong Hình 6, AutoML-GPT cũng cung cấp gợi ý như "mà không hy sinh quá nhiều hiệu suất." AutoML-GPT tiếp tục điều chỉnh siêu tham số dựa trên những yêu cầu này và nhật ký dự đoán. Phương pháp của chúng tôi chứng minh khả năng mạnh mẽ để tự động tiến hành thử nghiệm và thực hiện điều chỉnh siêu tham số tương tác. Nó tiếp tục xác nhận rằng phương pháp của chúng tôi hoạt động tốt cho các bộ dữ liệu khác nhau và có thể tổng quát hóa trên các loại đầu vào và lĩnh vực khác nhau.

3.4 Phân loại

Chúng tôi cũng đánh giá AutoML-GPT trên bộ dữ liệu UCI Adult [Dua and Graff, 2017] bằng XGBoost. Như trước đây, chúng tôi cung cấp thẻ dữ liệu và thẻ mô hình để tạo đoạn prompt đầu vào. Cùng một pipeline huấn luyện được áp dụng ở đây, như được hiển thị trong Hình 7. Chúng tôi cũng tuân theo cài đặt siêu tham số được đề xuất bởi AutoML-GPT và huấn luyện mô hình XGBoost. Huấn luyện này dẫn đến mất mát validation cuối cùng là 0.277 với độ chính xác 85.92%. Mặc dù có đầu vào và tác vụ khác nhau, AutoML-GPT được đề xuất của chúng tôi liên tục mang lại hiệu suất mạnh mẽ trong phân loại. Điều này tiếp tục chứng minh rằng AutoML-GPT có thể được sử dụng cho một loạt rộng các vấn đề học máy

--- TRANG 7 ---

[Hình 6: Tổng quan về AutoML-GPT cho hỏi đáp: Khối trên trình bày thẻ dữ liệu và thông tin mô hình, trong khi khối giữa nổi bật đoạn prompt AutoML-GPT, được rút ra từ cả thẻ dữ liệu và thẻ mô hình. Khối dưới chi tiết bốn bước: xử lý dữ liệu, kiến trúc mô hình, điều chỉnh siêu tham số và nhật ký huấn luyện dự đoán.]

máy trên các tác vụ khác nhau.

4 Công trình Liên quan

Mô hình Ngôn ngữ Lớn Tiên tiến LLMs đã thể hiện tính mạnh mẽ và khả năng tổng quát hóa thông qua học zero-shot và few-shot bằng cách có kích thước tham số vượt quá một trăm tỷ. Các ví dụ đáng chú ý của LLMs bao gồm Megatron-turing NLG [Smith et al., 2022] với 530 tỷ tham số, Gopher [Rae et al., 2021] với 280 tỷ tham số và PaLM [Chowdhery et al., 2022] với 540 tỷ tham số. Việc mở rộng quy mô của LLM đã mở khóa các khả năng mới nổi chưa từng được quan sát dưới các mô hình nhỏ hơn [Wei et al., 2022a]. Những LLMs này đã chứng minh sự vượt trội của LLMs cho học zero-shot. Trong số các LLMs hiện có, ChatGPT có đặc điểm riêng. Nó có khả năng tương tác với người dùng theo cách giống cuộc trò chuyện, trong khi vẫn giữ lại kiến thức tích lũy và khả năng tổng quát hóa đạt được từ việc đào tạo trước. Đi xa hơn một bước, chúng tôi khám phá khả năng học zero-shot của ChatGPT trên các tác vụ khác nhau ngoài đối thoại trong công trình này.

Chuỗi Tư duy Prompt chuỗi tư duy (CoT) khuyến khích LLMs tạo ra các bước lý luận trung gian trước khi trả lời [Wei et al., 2022b]. Có hai hướng nghiên cứu tập trung vào prompt CoT hiện tại. Một hướng là khám phá CoT được thiết kế thủ công. Trong CoT được thiết kế thủ công, LLMs thích ứng với các tính năng và minh chứng được thiết kế thủ công cho quá trình lý luận [Wei et al., 2022b]. Wang et al. [2022] đề xuất một chiến lược giải mã mới, self-consistency, để thay thế việc giải mã tham lam naïve được sử dụng trong prompt chuỗi tư duy. Gần đây, Interactive-Chain-Prompting [Pilault et al., 2023] được giới thiệu để giải quyết sự mơ hồ cho sinh có điều kiện đa ngôn ngữ. Hướng khác là tiến hành nghiên cứu về cài đặt zero-shot, trong đó STaR [Zelikman et al., 2022] được giới thiệu cho việc tự sinh và giúp mô hình tự cải thiện, và Automatic Reasoning and Tool-use (ART) [Paranjape et al., 2023] là một framework sử dụng LLMs đông lạnh để tự động tạo ra các bước lý luận trung gian như một chương trình.

Hệ thống dựa trên GPT GPT [Brown et al., 2020] đã cho thấy những cải thiện hiệu suất đầy hứa hẹn. Một hướng nghiên cứu gần đây đã tập trung vào việc tích hợp mô hình GPT vào các hệ thống AI. HuggingGPT [Shen et al.,

--- TRANG 8 ---

[Hình 7: Tổng quan về AutoML-GPT cho phân loại: Khối trên hiển thị thẻ dữ liệu và thông tin mô hình, và khối giữa thể hiện đoạn prompt AutoML-GPT, được rút ra từ cả thẻ dữ liệu và thẻ mô hình. Khối dưới phác thảo bốn bước: xử lý dữ liệu, kiến trúc mô hình, điều chỉnh siêu tham số và nhật ký huấn luyện dự đoán. Ngoài ra, chúng tôi bao gồm kết quả validation cuối cùng, tuân theo khuyến nghị siêu tham số từ AutoML-GPT và huấn luyện mô hình.]

2023] được xây dựng với thư viện transformers HuggingFace và sử dụng GPT như tác nhân tương tác. VisualGPT [Wu et al., 2023] kết hợp các Mô hình Nền tảng Thị giác khác nhau để cho phép người dùng tương tác với ChatGPT. OpenAGI [Ge et al., 2023], một nền tảng nghiên cứu AGI mã nguồn mở, được thiết kế để cung cấp các tác vụ phức tạp, nhiều bước và đi kèm với bộ dữ liệu đặc biệt cho tác vụ. Tương tự, chúng tôi cũng tích hợp GPT vào pipeline AutoML của chúng tôi. Cũng có một hệ thống khác dựa trên GPT có thể kết hợp thông tin bổ sung từ công cụ tìm kiếm, ví dụ: AutoGPT². AutoML-GPT suy nghĩ lại về tác động của ChatGPT từ góc độ huấn luyện tự động. Chúng tôi tập trung vào việc xây dựng pipeline huấn luyện và thiết lập hệ thống AutoML từ đầu đến cuối.

5 Kết luận

Công trình của chúng tôi chứng minh những lợi ích của việc xây dựng hệ thống AutoML dựa trên GPT. Phương pháp được đề xuất có thể tự động tiến hành các thử nghiệm học máy. Việc học tự động này cải thiện đáng kể hiệu quả huấn luyện và tăng cường hiệu suất của mô hình. Chúng tôi chứng minh các trường hợp sử dụng trên các benchmark thị giác máy tính, hỏi đáp tự nhiên và phân loại. Chúng tôi tiếp tục tiến hành một trường hợp sử dụng chi tiết với các bộ dữ liệu chưa thấy và tương tác bổ sung giữa người dùng và AutoML-GPT. Tóm lại, AutoML-GPT được đề xuất là hiệu quả và tổng quát, với tiềm năng tạo ra giao diện ngôn ngữ tự nhiên để điều chỉnh các mô hình học máy cho các tác vụ khác nhau. Trong tương lai, chúng tôi sẽ 1) tự động tạo thẻ mô hình và dữ liệu cho các benchmark nổi tiếng và làm cho chúng trở thành một phần của hệ thống, và 2) trích xuất các mạng con nhận biết tác vụ từ các mô hình được đào tạo trước lớn với sự trợ giúp của ChatGPT.

Tài liệu tham khảo

Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. 2020. Language models are few-shot learners. Advances in neural information processing systems, 33:1877–1901.

Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, et al. 2022. Palm: Scaling language modeling with pathways. arXiv preprint arXiv:2204.02311.

Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, et al. 2022. Scaling instruction-finetuned language models. arXiv preprint arXiv:2210.11416.

Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. 2009. Imagenet: A large-scale hierarchical image database. In 2009 IEEE conference on computer vision and pattern recognition, pages 248–255. Ieee.

Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, et al. 2020. An image is worth 16x16 words: Transformers for image recognition at scale. arXiv preprint arXiv:2010.11929.

Dheeru Dua and Casey Graff. 2017. UCI machine learning repository.

Yingqiang Ge, Wenyue Hua, Jianchao Ji, Juntao Tan, Shuyuan Xu, and Yongfeng Zhang. 2023. Openagi: When llm meets domain experts. arXiv preprint arXiv:2304.04370.

Timnit Gebru, Jamie Morgenstern, Briana Vecchione, Jennifer Wortman Vaughan, Hanna Wallach, Hal Daumé Iii, and Kate Crawford. 2021. Datasheets for datasets. Communications of the ACM, 64(12):86–92.

²https://github.com/Significant-Gravitas/Auto-GPT

--- TRANG 9 ---

Gautier Izacard and Edouard Grave. 2020. Leveraging passage retrieval with generative models for open domain question answering. arXiv preprint arXiv:2007.01282.

Vladimir Karpukhin, Barlas Oğuz, Sewon Min, Ledell Wu, Sergey Edunov, Danqi Chen, and Wen-tau Yih. 2020. Dense passage retrieval for open-domain question answering. Empirical Methods in Natural Language Processing (EMNLP).

Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur Parikh, Chris Alberti, Danielle Epstein, Illia Polosukhin, Matthew Kelcey, Jacob Devlin, Kenton Lee, Kristina N. Toutanova, Llion Jones, Ming-Wei Chang, Andrew Dai, Jakob Uszkoreit, Quoc Le, and Slav Petrov. 2019. Natural Questions: a benchmark for question answering research. TACL.

Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Dollár, and C Lawrence Zitnick. 2014. Microsoft coco: Common objects in context. In Computer Vision–ECCV 2014: 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part V 13, pages 740–755. Springer.

Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, and Baining Guo. 2021. Swin transformer: Hierarchical vision transformer using shifted windows. In Proceedings of the IEEE/CVF international conference on computer vision, pages 10012–10022.

Margaret Mitchell, Simone Wu, Andrew Zaldivar, Parker Barnes, Lucy Vasserman, Ben Hutchinson, Elena Spitzer, Inioluwa Deborah Raji, and Timnit Gebru. 2019. Model cards for model reporting. In Proceedings of the conference on fairness, accountability, and transparency, pages 220–229.

OpenAI. 2023. Gpt-4 technical report. arXiv.

Bhargavi Paranjape, Scott Lundberg, Sameer Singh, Hannaneh Hajishirzi, Luke Zettlemoyer, and Marco Tulio Ribeiro. 2023. Art: Automatic multi-step reasoning and tool-use for large language models. arXiv preprint arXiv:2303.09014.

Jonathan Pilault, Xavier Garcia, Arthur Bražinskas, and Orhan Firat. 2023. Interactive-chain-prompting: Ambiguity resolution for crosslingual conditional generation with interaction. arXiv preprint arXiv:2301.10309.

Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et al. 2021. Learning transferable visual models from natural language supervision. In International conference on machine learning, pages 8748–8763. PMLR.

Jack W Rae, Sebastian Borgeaud, Trevor Cai, Katie Millican, Jordan Hoffmann, Francis Song, John Aslanides, Sarah Henderson, Roman Ring, Susannah Young, et al. 2021. Scaling language models: Methods, analysis & insights from training gopher. arXiv preprint arXiv:2112.11446.

Ori Ram, Yoav Levine, Itay Dalmedigos, Dor Muhlgay, Amnon Shashua, Kevin Leyton-Brown, and Yoav Shoham. 2023. In-context retrieval-augmented language models. arXiv preprint arXiv:2302.00083.

Yongliang Shen, Kaitao Song, Xu Tan, Dongsheng Li, Weiming Lu, and Yueting Zhuang. 2023. Hugginggpt: Solving ai tasks with chatgpt and its friends in huggingface. arXiv preprint arXiv:2303.17580.

Shaden Smith, Mostofa Patwary, Brandon Norick, Patrick LeGresley, Samyam Rajbhandari, Jared Casper, Zhun Liu, Shrimai Prabhumoye, George Zerveas, Vijay Korthikanti, et al. 2022. Using deepspeed and megatron to train megatron-turing nlg 530b, a large-scale generative language model. arXiv preprint arXiv:2201.11990.

--- TRANG 10 ---

Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, et al. 2023. Llama: Open and efficient foundation language models. arXiv preprint arXiv:2302.13971.

Oriol Vinyals, Charles Blundell, Timothy Lillicrap, Daan Wierstra, et al. 2016. Matching networks for one shot learning. Advances in neural information processing systems, 29.

Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, and Denny Zhou. 2022. Self-consistency improves chain of thought reasoning in language models. arXiv preprint arXiv:2203.11171.

Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, et al. 2022a. Emergent abilities of large language models. arXiv preprint arXiv:2206.07682.

Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Ed Chi, Quoc Le, and Denny Zhou. 2022b. Chain of thought prompting elicits reasoning in large language models. arXiv preprint arXiv:2201.11903.

Chenfei Wu, Shengming Yin, Weizhen Qi, Xiaodong Wang, Zecheng Tang, and Nan Duan. 2023. Visual chatgpt: Talking, drawing and editing with visual foundation models. arXiv preprint arXiv:2303.04671.

Tete Xiao, Yingcheng Liu, Bolei Zhou, Yuning Jiang, and Jian Sun. 2018. Unified perceptual parsing for scene understanding. In Proceedings of the European conference on computer vision (ECCV), pages 418–434.

Sang Michael Xie, Aditi Raghunathan, Percy Liang, and Tengyu Ma. 2021. An explanation of in-context learning as implicit bayesian inference. arXiv preprint arXiv:2111.02080.

Eric Zelikman, Yuhuai Wu, Jesse Mu, and Noah Goodman. 2022. Star: Bootstrapping reasoning with reasoning. Advances in Neural Information Processing Systems, 35:15476–15488.

Shujian Zhang, Chengyue Gong, and Eunsol Choi. 2021. Knowing more about questions can help: Improving calibration in question answering. arXiv preprint arXiv:2106.01494.

Shujian Zhang, Chengyue Gong, and Xingchao Liu. 2022. Passage-mask: A learnable regularization strategy for retriever-reader models. arXiv preprint arXiv:2211.00915.

Mingkai Zheng, Xiu Su, Shan You, Fei Wang, Chen Qian, Chang Xu, and Samuel Albanie. 2023. Can gpt-4 perform neural architecture search? arXiv preprint arXiv:2304.10970.

--- TRANG 11 ---

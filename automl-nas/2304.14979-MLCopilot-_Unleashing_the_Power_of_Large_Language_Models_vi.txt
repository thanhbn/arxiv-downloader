# MLCopilot: Unleashing the Power of Large Language Models
# in Solving Machine Learning Tasks
# Đã chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/automl-nas/2304.14979.pdf
# Kích thước tệp: 694373 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
MLCopilot: Giải Phóng Sức Mạnh của Các Mô Hình Ngôn Ngữ Lớn
trong Việc Giải Quyết Các Nhiệm Vụ Học Máy
Lei Zhang∗1Yuge Zhang1Kan Ren2Dongsheng Li1Yuqing Yang1
1Microsoft Research,2ShanghaiTech University
isleizhang@outlook.com, yugzhan@microsoft.com, renkan@shanghaitech.edu.cn
Tóm tắt
Lĩnh vực học máy (ML) đã được áp dụng rộng rãi, dẫn đến nhu cầu lớn về việc điều chỉnh ML cho các tình huống cụ thể, điều này vẫn còn tốn kém và không tầm thường. Các phương pháp chủ đạo hướng tới việc tự động hóa giải quyết các nhiệm vụ ML (ví dụ: AutoML) thường tốn thời gian và khó hiểu đối với các nhà phát triển con người. Ngược lại, mặc dù các kỹ sư con người có khả năng đáng kinh ngạc trong việc hiểu các nhiệm vụ và lý luận về các giải pháp, kinh nghiệm và kiến thức của họ thường thưa thớt và khó sử dụng bởi các phương pháp định lượng. Trong bài báo này, chúng tôi nhằm mục đích thu hẹp khoảng cách giữa trí tuệ máy và kiến thức con người bằng cách giới thiệu một khung mới MLCopilot1, tận dụng các mô hình ngôn ngữ lớn tiên tiến để phát triển các giải pháp ML cho các nhiệm vụ mới. Chúng tôi trình bày khả năng mở rộng năng lực của LLM để hiểu các đầu vào có cấu trúc và thực hiện lý luận kỹ lưỡng để giải quyết các nhiệm vụ ML mới. Và chúng tôi phát hiện rằng, sau một số thiết kế chuyên biệt, LLM có thể (i) quan sát từ các kinh nghiệm hiện có của các nhiệm vụ ML và (ii) lý luận hiệu quả để mang lại kết quả hứa hẹn cho các nhiệm vụ mới. Giải pháp được tạo ra có thể được sử dụng trực tiếp để đạt được mức độ cạnh tranh cao.

1 Giới thiệu
Những thập kỷ qua đã chứng kiến sự tiến bộ lớn và phát triển nhanh chóng của học máy (ML), nhưng các thuật toán ML vẫn nổi tiếng là khó cấu hình (Hutter et al., 2019). Đối với các nhiệm vụ cụ thể, việc cấu hình và thực hiện các giải pháp ML tương ứng là không tầm thường, do đó đòi hỏi lao động con người rộng rãi. Nhiều thách thức phát sinh trong việc phát triển các giải pháp ML thực tế. Đầu tiên, cần nỗ lực lớn của con người xem xét không gian lớn của các giải pháp ML, như ∗Công việc được thực hiện trong thời gian thực tập của Lei Zhang tại Microsoft Research Asia. Liên hệ với Kan Ren.
1Các ví dụ và mã có sẵn tại https://github.com/
microsoft/CoML kỹ thuật đặc trưng, thiết kế mô hình, chi tiết tối ưu hóa, v.v. Thứ hai, các thuật toán ML nhạy cảm với ngay cả những thay đổi nhỏ của bối cảnh nhiệm vụ. Kết quả là, ngay cả thuật toán giống nhau cũng có thể cần được cấu hình lại cho các nhiệm vụ ứng dụng khác nhau. Cuối cùng nhưng không kém phần quan trọng, việc chuyển giao các kinh nghiệm thành công qua các nhiệm vụ khác nhau cũng khó thực hiện, đòi hỏi khả năng lý luận cấp cao của các chuyên gia con người để đưa ra các giải pháp hợp lý cho các nhiệm vụ mới.

Các phương pháp chủ đạo giảm bớt nỗ lực con người trong cấu hình thuật toán là một số cơ chế tự động hóa như AutoML (Automated Machine Learning) (Hutter et al., 2019). Một nhánh chính của AutoML công thức hóa vấn đề như tối ưu hóa hộp đen, và dựa vào một số phương pháp tối ưu hóa như tối ưu hóa Bayesian (BO) (Frazier, 2018) để giải quyết nó. Mặc dù các kết quả thu được được cho là hứa hẹn, việc tạo ra nhiều thử nghiệm tốn thời gian, đặc biệt là cho các tập dữ liệu lớn và nhiệm vụ phức tạp. Hơn nữa, AutoML không tuân theo mô hình phát triển ML tự nhiên mà con người quen thuộc, điều này để lại khoảng cách lớn cho con người hiểu và kiểm soát toàn bộ quá trình. Cụ thể, hoặc là khó giải thích hành vi của auto-tuning, hoặc khó khăn trong việc kết hợp kiến thức trước của con người như kiến thức về kiến trúc mô hình vào quá trình, làm cho nó ít linh hoạt hơn cho các nhà phát triển con người. Hơn nữa, các giải pháp ML được tạo ra bởi các phương pháp dựa trên tối ưu hóa này có thể chỉ phù hợp với các lĩnh vực cụ thể, và khả năng chuyển giao của các kết quả này cũng vẫn là một vấn đề mở (Chen et al., 2022; Yan et al., 2022).

Ngược lại, chúng tôi nhận thấy hai xu hướng trong cách con người tiếp cận một nhiệm vụ ML. Thay vì nhảy vào giải quyết nhiệm vụ mới trực tiếp, con người thường cố gắng hiểu nhiệm vụ có trong tay và rút ra từ kinh nghiệm quá khứ của họ về các nhiệm vụ liên quan. Ngoài ra, con người nhớ lại kiến thức của họ, có thể đã đến từ sách giáo khoa hoặc kinh nghiệm trước đó. Quá trình này khác biệt đáng kể so với phương pháp tự động arXiv:2304.14979v2 [cs.LG] 18 Feb 2024

--- TRANG 2 ---
được đề cập trước đó, điều này dẫn chúng ta đến một câu hỏi tự nhiên: liệu chúng ta có thể tận dụng cả trí tuệ máy và các mô hình thiết kế của con người để cải thiện khả năng giải quyết các nhiệm vụ ML không? Những tiến bộ của Các Mô Hình Ngôn Ngữ Lớn (LLM) (Brown et al., 2020; Chowdhery et al., 2022; Ouyang et al., 2022) đã minh họa hiệu suất hứa hẹn to lớn trong việc bắt chước hành vi con người trên các nhiệm vụ dựa trên hội thoại. Có vẻ hợp lý khi sử dụng sức mạnh của LLM để giải quyết các vấn đề ML theo cách giống con người hơn.

Tuy nhiên, vẫn còn một số thách thức khi kết hợp LLM để đạt được mục tiêu này. Đầu tiên, chúng tôi phát hiện ra rằng LLM gặp khó khăn trong việc thực hiện các nhiệm vụ ML chỉ dựa trên mô tả nhiệm vụ, trong trường hợp này hiệu suất không tốt hơn tạo ra ngẫu nhiên. Cố gắng tận dụng kinh nghiệm ML lịch sử, chúng tôi phát hiện rằng dữ liệu thường nằm ở các định dạng không đồng nhất (ví dụ: mã, cấu hình và nhật ký), cần được chuẩn hóa thành các định dạng có thể chấp nhận được đối với LLM. Hơn nữa, lượng thông tin có thể được kết hợp vào học trong ngữ cảnh (Brown et al., 2020) khá hạn chế, và do đó cần một số chiến lược truy xuất để tận dụng tối đa nó. Cuối cùng, việc tạo ra một giải pháp ML dựa trên kinh nghiệm lịch sử về bản chất là một vấn đề tư duy toán học và lý luận logic (Patel et al., 2021), điều này cần thiết một số cơ chế để lý luận về kiến thức.

Trong bài báo này, chúng tôi khám phá và trình bày một khung mới MLCopilot, tận dụng LLM để đề xuất các giải pháp cho các nhiệm vụ ML thực tế mới, dựa trên các kinh nghiệm hiện có từ các nhiệm vụ lịch sử. Chúng tôi phân tách vấn đề thành các giai đoạn ngoại tuyến và trực tuyến. Trong giai đoạn ngoại tuyến, MLCopilot chuẩn hóa dữ liệu lịch sử và tạo ra một nhóm kinh nghiệm. LLM sau đó được sử dụng để khai thác kiến thức có giá trị từ kinh nghiệm lịch sử. Trong giai đoạn trực tuyến, MLCopilot truy xuất các kinh nghiệm từ các nhiệm vụ liên quan nhất từ nhóm kinh nghiệm, dựa trên mô tả của nhiệm vụ mục tiêu. Sau đó nó tương tác với LLM để có được nhiều giải pháp ML được đề xuất trong một vòng. Chúng tôi chứng minh rằng, với một khung được thiết kế tốt, LLM không chỉ có thể khai thác kiến thức có ý nghĩa từ các kinh nghiệm lịch sử mà còn cung cấp các giải pháp ML hợp lý và cạnh tranh cho các nhiệm vụ mới.

Công việc của chúng tôi trình bày một đóng góp ba mặt, có thể được tóm tắt như sau. (i) Theo hiểu biết của chúng tôi, chúng tôi là những người đầu tiên sử dụng LLM như một công cụ để tạo ra các giải pháp cho các nhiệm vụ ML mới. (ii) Một khung truy xuất-và-nhắc nhở mới đã được đề xuất để giải quyết các nhiệm vụ ML gần như ngay lập tức, mà không cần bất kỳ tìm kiếm hoặc tối ưu hóa tốn thời gian nào. (iii) Chúng tôi tận dụng khả năng hiểu và tạo văn bản của LLM để tạo ra kết quả có thể diễn giải2 cho các nhiệm vụ ML. Phương pháp này đã cho thấy hiệu suất tương đương hoặc thậm chí tốt hơn trên nhiều điểm chuẩn ML thực tế.

2 Công trình liên quan
2.1 Các Mô Hình Ngôn Ngữ Lớn
Các mô hình ngôn ngữ lớn (LLM) là các mạng nơ-ron có kích thước đáng kể (thường chứa hàng chục hoặc hàng trăm tỷ tham số). Chúng đã đạt được khả năng đáng kinh ngạc trong việc xử lý và tạo ra ngôn ngữ tự nhiên, do được huấn luyện trên lượng lớn dữ liệu văn bản (Radford et al., 2018, 2019; Brown et al., 2020). Các nghiên cứu cho thấy rằng LLM vượt quá một quy mô nhất định có "khả năng nổi bật" (Wei et al., 2022), và hoạt động xuất sắc trong các ứng dụng như chatbot, dịch máy và tóm tắt văn bản (Zhao et al., 2023; Touvron et al., 2023).

Trong khi LLM đã minh họa hiệu suất vượt trội về hiểu ngôn ngữ tự nhiên và tạo văn bản giống con người, chúng vẫn còn khá hạn chế đối với các nhiệm vụ phức tạp đòi hỏi lý luận (Huang and Chang, 2022) và kỹ năng toán học (Patel et al., 2021; Thawani et al., 2021; Han et al., 2022; Saxton et al., 2019). Dòng tự động hóa nhiệm vụ (Lu et al., 2023; Shen et al., 2023) đã điều tra một phương pháp tổng quát để phân tách một nhiệm vụ thành một chuỗi các nhiệm vụ con, nhưng chúng trực giao với công việc của chúng tôi, vì chúng không tính đến kinh nghiệm hoặc kiến thức từ các nhiệm vụ khác khi lập kế hoạch cho một nhiệm vụ mới.

2.2 Học Máy và AutoML
Học máy (ML) là một lĩnh vực phụ của trí tuệ nhân tạo (AI) liên quan đến việc phát triển các thuật toán tối ưu hóa có thể học từ dữ liệu và đưa ra dự đoán (Bishop and Nasrabadi, 2006) hoặc quyết định (Sutton and Barto, 2018). Mặc dù ML đã thành công trong nhiều ứng dụng thực tế, việc thiết kế một giải pháp ML hiệu quả cho một nhiệm vụ mới có thể thách thức do nhiều lựa chọn thiết kế cần thiết. AutoML (Hutter et al., 2019) nổi lên như một phương pháp để giảm bớt nỗ lực thủ công liên quan. Các phương pháp phổ biến bao gồm tìm kiếm kiến trúc nơ-ron (NAS) (Pham et al., 2018), meta-learning (Andrychowicz et al., 2016), và tối ưu hóa Bayesian (Frazier, 2018).

2 Khái niệm "khả năng diễn giải" trong bối cảnh công việc của chúng tôi chủ yếu liên quan đến kiến thức có thể đọc được bởi con người được tạo ra bởi LLM, phục vụ như một tham chiếu minh bạch cho việc ra quyết định.

--- TRANG 3 ---
Thuật ngữ Định nghĩa Ví dụ
Nhiệm vụ T Vấn đề ML cần giải quyết (tùy chọn với các ràng buộc). Tìm một trình tối ưu hóa cho ResNet trên tập dữ liệu ImageNet.
Không gian giải pháp S Không gian giả thuyết giải pháp cho nhiệm vụ. Trình tối ưu hóa: {Adam, SGD}; Tốc độ học: [10−6,0.1].
Giải pháp S Một lựa chọn cụ thể trong không gian giải pháp. ResNet 2 lớp với trình tối ưu hóa SGD sử dụng LR 10−3.
Kinh nghiệm E Các giải pháp thành công trên các nhiệm vụ lịch sử. SGD với lr 0.024 đạt độ chính xác 76.2% cho ResNet trên ImageNet.
Kiến thức K Thông tin cấp cao thu được từ các kinh nghiệm. Sử dụng LR nhỏ làm cho huấn luyện chậm hơn nhưng có thể mang lại kết quả cuối cùng tốt hơn.

Bảng 1: Các thuật ngữ được sử dụng trong toàn bộ bài báo này.

AutoML có thể đạt được mức độ vượt xa con người trong việc giải quyết các nhiệm vụ ML, nhưng nó vẫn đối mặt với một số nhược điểm. Đầu tiên, hầu hết các phương pháp AutoML đòi hỏi nhiều vòng thử-và-sai, có thể tốn thời gian. Thứ hai, AutoML thường tìm kiếm từ đầu cho một nhiệm vụ mới và bỏ qua kinh nghiệm từ các nhiệm vụ trước đó. Cuối cùng, hầu hết các phương pháp AutoML không thể diễn giải được do bản chất hộp đen của chúng, điều này loại trừ hiểu biết của con người. Một số phương pháp có thể giải quyết một hoặc hai nhược điểm, nhưng không phải tất cả. Ví dụ, dòng nghiên cứu AutoML có thể chuyển giao tìm cách tận dụng kinh nghiệm quá khứ để hỗ trợ tìm kiếm cho các nhiệm vụ mới (Bardenet et al., 2013; Wistuba et al., 2016; Mittal et al., 2020; Yan et al., 2022; Wang et al., 2021a), nhưng chúng thiếu khả năng diễn giải và hầu hết chỉ hoạt động cho các loại nhiệm vụ cụ thể. Một nghiên cứu gần đây (Chen et al., 2022) nhằm sử dụng mô hình Transformer (Vaswani et al., 2017) với huấn luyện trước quy mô lớn để xử lý các loại nhiệm vụ rộng hơn, nhưng nó vẫn không thể diễn giải được và vẫn cần tìm kiếm chi phí cho các nhiệm vụ mới. Gần đây nhất, (Zheng et al., 2023) đã cố gắng tìm kiếm kiến trúc nơ-ron sử dụng GPT-4 (OpenAI, 2023). Nó nhắc nhở LLM để giải thích lý do, nhưng nó chỉ khám phá kiến trúc mô hình, và vẫn đòi hỏi thử-và-sai tốn kém.

3 Phần mở đầu
Mục tiêu của MLCopilot là hỗ trợ con người trong việc giải quyết các vấn đề ML phức tạp. Nói chung, đối với một nhiệm vụ là một vấn đề thực tế cho các mô hình ML để giải quyết, mục tiêu của phát triển ML là thực hiện một giải pháp cụ thể. Giải pháp có thể là một pipeline, cấu hình, hoặc đoạn mã, dựa trên đó một mô hình ML cụ thể có thể được học để xử lý nhiệm vụ mục tiêu. Giải pháp cũng là một mẫu cụ thể trong một không gian giải pháp phức tạp liên quan đến các lựa chọn thiết kế khác nhau. Những lựa chọn này tương quan lẫn nhau và kết quả của các lựa chọn thay thế khác nhau thường ảnh hưởng đến những lựa chọn khác và cuối cùng ảnh hưởng đến hiệu suất cuối cùng của toàn bộ giải pháp ML.

Để tạo ra các giải pháp ML hợp lý cho các nhiệm vụ mới, chúng ta có thể dựa vào kinh nghiệm từ các nhiệm vụ liên quan trước đó. MLCopilot được thiết kế để sử dụng các kinh nghiệm lịch sử cho việc khai thác kiến thức và thực hiện hiệu quả các giải pháp hiệu quả cho nhiệm vụ ML mới đã cho (chi tiết trong § 4). Để cải thiện hiểu biết và rõ ràng, chúng tôi tóm tắt các thuật ngữ với mô tả và ví dụ trong Bảng 1.

4 MLCopilot
Trong phần này, chúng tôi trình bày MLCopilot, với việc công thức hóa vấn đề chính và kiến trúc tổng thể của phương pháp chúng tôi. Sau đó, chúng tôi sẽ mô tả một số thành phần chính của MLCopilot một cách chi tiết, bao gồm mô tả nhiệm vụ mục tiêu, truy xuất, chuẩn hóa, và khai thác kiến thức.

4.1 Khung Tổng thể
Như đã thảo luận trước đó, để giải phóng sức mạnh của LLM trong việc giải quyết các nhiệm vụ ML phức tạp, việc tận dụng rõ ràng kinh nghiệm lịch sử là rất quan trọng. Tuy nhiên, việc sử dụng kinh nghiệm quá khứ không đơn giản xem xét định dạng dữ liệu không đồng nhất và số lượng lớn các bản ghi. Do đó, thiết kế kỹ thuật của chúng tôi chủ yếu tập trung vào việc giải quyết hai vấn đề: (i) làm thế nào để hiểu và khai thác các kinh nghiệm thô phong phú; (ii) làm thế nào để giải quyết hiệu quả các nhiệm vụ ML dựa trên kết quả của (i).

Ý tưởng chính đằng sau MLCopilot là lý luận dựa trên kiến thức, tức là tận dụng LLM để thực hiện lý luận và giải quyết nhiệm vụ dựa trên kiến thức trước đó, đã được phân tích và khai thác từ các kinh nghiệm quá khứ. Để đạt được điều này, MLCopilot chứa hai giai đoạn, bao gồm các phần ngoại tuyến và trực tuyến, cả hai đều được minh họa trực quan trong Hình 1. Trong giai đoạn ngoại tuyến, LLM đã được kết hợp để phân tích dữ liệu kinh nghiệm lịch sử được chuẩn hóa và khai thác kiến thức hữu ích. Và trong giai đoạn trực tuyến, người dùng sẽ truy vấn MLCopilot, cũng được xây dựng trên LLM, để có được một giải pháp ML phù hợp cho nhiệm vụ mới.

--- TRANG 4 ---
Giai đoạn ngoại tuyến MLCopilot
Mô tả nhiệm vụ T ̃
Nhiệm vụ là phân loại u não dựa trên quét mpMRI. Tập dữ liệu chứa ~400k mẫu.
Minh chứng Ẽ
Nhiệm vụ: Phân loại u phổi dựa trên báo cáo xét nghiệm máu. Tập dữ liệu chứa khoảng 1k mẫu.
Giải pháp: Mô hình là xgboost. Sử dụng max depth nhỏ.
Nhiệm vụ: Phân loại X-quang vai. Chẩn đoán loại là A1, C1, D1. Tập dữ liệu chứa 500 mẫu.
Giải pháp: Sử dụng EfficientNet-B0 đã được huấn luyện trước. Tinh chỉnh với tốc độ học thấp và weight decay cao.
Kiến thức K ̃
1. CNN thường được sử dụng cho tập dữ liệu hình ảnh. Đối với tập dữ liệu dạng bảng, sử dụng thuật toán cây quyết định.
2. Sử dụng tốc độ học thấp khi tinh chỉnh trên mô hình đã được huấn luyện trước. Sử dụng tốc độ học cao để hội tụ nhanh hơn.
3. Đối với tập dữ liệu nhỏ, kiểm soát các tham số điều chuẩn như max depth để ngăn chặn overfitting.
Giai đoạn trực tuyến Nhóm kinh nghiệm PE
2. Truy xuất Kinh nghiệm
Nhóm kiến thức PK Khai thác ngoại tuyến （với LLM)
3. Truy xuất Kiến thức 1. Mô tả nhiệm vụ
Giải pháp
Tinh chỉnh trên EfficientNet-B0 đã được huấn luyện trước với tốc độ học thấp và weight decay thấp.
Người dùng Dữ liệu lịch sử H
Chuẩn hóa
4. Nhắc nhở LLM MLCopilot
Mô tả nhiệm vụ T ̃
Nhiệm vụ là phân loại u não dựa trên quét mpMRI. Tập dữ liệu chứa ~400k mẫu.
Minh chứng Ẽ
Nhiệm vụ: Phân loại u phổi dựa trên báo cáo xét nghiệm máu. Tập dữ liệu chứa khoảng 1k mẫu.
Giải pháp: Mô hình là xgboost. Sử dụng max depth nhỏ.
Nhiệm vụ: Phân loại X-quang vai. Chẩn đoán loại là A1, C1, D1. Tập dữ liệu chứa 500 mẫu.
Giải pháp: Sử dụng EfficientNet-B0 đã được huấn luyện trước. Tinh chỉnh với tốc độ học thấp và weight decay cao.
Kiến thức K ̃
1. CNN thường được sử dụng cho tập dữ liệu hình ảnh. Đối với tập dữ liệu dạng bảng, sử dụng thuật toán cây quyết định.
2. Sử dụng tốc độ học thấp khi tinh chỉnh trên mô hình đã được huấn luyện trước. Sử dụng tốc độ học cao để hội tụ nhanh hơn.
3. Đối với tập dữ liệu nhỏ, kiểm soát các tham số điều chuẩn như max depth để ngăn chặn overfitting.

Hình 1: Tổng quan về MLCopilot. MLCopilot có các giai đoạn ngoại tuyến và trực tuyến. Trong giai đoạn ngoại tuyến, nó tạo ra các nhóm kinh nghiệm và kiến thức. Trong giai đoạn trực tuyến, nó truy xuất kinh nghiệm và kiến thức dựa trên mô tả nhiệm vụ mới. Cuối cùng, MLCopilot gọi LLM và trả về các giải pháp.

Dữ liệu lịch sử H
Chuẩn hóa
Kiến thức
1. Các mô hình cây quyết định hoạt động tốt hơn cho tập dữ liệu dạng bảng. CNN hoạt động tốt hơn cho tập dữ liệu hình ảnh.
2. Đối với tập dữ liệu nhỏ, đặt max depth thấp hơn cho RandomForest để giảm khả năng overfitting.

Dữ liệu lịch sử 1
Nhiệm vụ: Phân loại X-quang vai. ...
YAML:
model:
  type: resnet
  depth: 50
  pretrained: imagenet
Độ chính xác: 75.93%

Dữ liệu lịch sử 2
Nhiệm vụ: Phân loại X-quang vai. ...
JSON:
{
  "model": "effnet-b5",
  "pretrained": true
}
Độ chính xác: 80.08%

Dữ liệu lịch sử 3
Nhiệm vụ: Phân loại u phổi. ...
Mã:
model = RandomForest(
  n_estimators=30,
  max_depth=6
)
Độ chính xác: 53.3%

Nhóm kinh nghiệm PE
Kinh nghiệm 1
Nhiệm vụ: Phân loại X-quang vai. ...
Giải pháp: Mô hình là ResNet. Độ sâu là trung bình. Tập dữ liệu đã được huấn luyện trước là ImageNet.
Độ chính xác: khá

Kinh nghiệm 2
Nhiệm vụ: Phân loại X-quang vai. ...
Giải pháp: Mô hình là EfficientNet-B5. Tập dữ liệu đã được huấn luyện trước là ImageNet.
Độ chính xác: tốt

Kinh nghiệm 3
Nhiệm vụ: Phân loại u phổi. ...
Giải pháp: Mô hình là RandomForest. Số cây là thấp. Max depth là trung bình.
Độ chính xác: tốt

Khai thác Hậu-xác thực

Hình 2: Giai đoạn ngoại tuyến: chuẩn hóa, khai thác kiến thức.

4.1.1 Giai đoạn Ngoại tuyến: Hiểu và Lý luận
Chúng tôi trước tiên trình bày các thiết lập dữ liệu và mô tả quy trình tiền xử lý tương ứng một cách ngắn gọn. Cho H={D1, . . . , DNH} là dữ liệu lịch sử thô với NH bản ghi trước đó. Bản ghi thứ i Di được định nghĩa là một tuple ba phần tử ⟨Ti, Si, Mi⟩ chứa một nhiệm vụ Ti∈T, một giải pháp Si∈S, và hiệu suất thước đo được đánh giá Mi, ví dụ: độ chính xác phân loại.

Lưu ý rằng, dữ liệu lịch sử H có thể có các định dạng không đồng nhất và đa dạng. Ví dụ, nhiệm vụ có thể được mô tả bằng văn bản tự nhiên, trong khi giải pháp có thể là cấu hình JSON, một hàng dữ liệu dạng bảng, hoặc đoạn mã. Một nhóm kinh nghiệm PE được xây dựng, để chuẩn hóa dữ liệu và lưu trữ chúng như các kinh nghiệm PE={E1, . . . , ENE}, trong đó Ej=C(Dj), và C(·) là hàm chuẩn hóa. Để đơn giản ký hiệu, chúng tôi giả sử tất cả các giải pháp trong PE đến từ một không gian giải pháp universal. Dễ dàng mở rộng khung cho các tình huống với nhiều không gian giải pháp.

Kiến thức, là thông tin cấp cao được thu thập từ kinh nghiệm (Dictionary, 1989), và chúng tôi tận dụng LLM để khai thác kiến thức từ nhóm kinh nghiệm được xây dựng, trong giai đoạn ngoại tuyến. Kiến thức là tóm tắt dễ hiểu của các kinh nghiệm ML trước đó, sẽ được sử dụng thêm khi suy luận giải pháp cuối cùng trong giai đoạn trực tuyến. Cụ thể, một tập con kinh nghiệm được lấy mẫu đầu tiên từ nhóm kinh nghiệm, sau đó một LLM được kết hợp để đọc và hiểu dữ liệu kinh nghiệm, cho phép chúng ta "khai thác" kiến thức K từ nó. Quá trình khai thác được công thức hóa là K=IK(PE;LLM), đây là một quá trình lặp đi lặp lại bằng cách tương tác với LLM cùng với hậu-xác thực trên kiến thức thu được. Quá trình chi tiết của khai thác được thảo luận trong § 4.5. Tất cả kiến thức được tạo ra được lưu trữ trong một nhóm kiến thức PK={K1, . . . , KNK} với tổng cộng NK mục.

Nhóm kinh nghiệm và nhóm kiến thức thu được sẽ được MLCopilot sử dụng thêm trong giai đoạn trực tuyến, để thực hiện các giải pháp ML hợp lý, hứa hẹn và cạnh tranh cho các nhiệm vụ mới.

4.1.2 Giai đoạn Trực tuyến: Truy xuất và Giải quyết
Giai đoạn trực tuyến của MLCopilot nhằm thực hiện lý luận và giải quyết nhiệm vụ dựa trên thông tin off-the-shelf thu được từ giai đoạn ngoại tuyến. Cụ thể, đối với truy vấn người dùng với mô tả nhiệm vụ, MLCopilot sẽ phản hồi với các giải pháp ML hợp lý tương ứng thông qua việc truy xuất các kinh nghiệm và kiến thức liên quan, và tương tác với LLM bằng một lời nhắc được tuyển chọn, trong một vòng.

Khi một người dùng đến với một nhiệm vụ mục tiêu mới ˜T, chưa từng được thấy trong lịch sử, MLCopilot đầu tiên truy xuất các kinh nghiệm liên quan của các nhiệm vụ liên quan khác như minh chứng ˜E=RE(˜T, PE), trong đó RE(·) là các hàm truy xuất cho nhóm kinh nghiệm. Nó cũng truy xuất kiến thức ˜K=RK(˜T, PK) để hướng dẫn phản hồi về nhiệm vụ mới, trong đó RK(·) là các hàm truy xuất cho nhóm kiến thức. MLCopilot cuối cùng tạo ra một giải pháp được đề xuất bằng cách gọi LLM một lần:

--- TRANG 5 ---
˜S=LLM(˜T,˜E,˜K).

Khung được thể hiện trong Hình 1, nơi chúng tôi minh họa một ví dụ về cách MLCopilot xử lý một nhiệm vụ phân loại u não bằng cách tận dụng các kinh nghiệm và kiến thức trước đó. Tiếp theo chúng tôi sẽ giới thiệu các thành phần chuyên biệt một cách chi tiết.

4.2 Mô tả Nhiệm vụ bằng Ngôn ngữ Tự nhiên
Đầu tiên, chúng tôi cho thấy cách nhiệm vụ mục tiêu được mô tả trong khung của chúng tôi, đây là đầu vào cho MLCopilot. Các công trình trước đó (Feurer et al., 2015; Wang et al., 2021a) thường sử dụng các meta-feature được thiết kế bởi con người cho các loại nhiệm vụ cụ thể (ví dụ: số mẫu trong tập dữ liệu) để mô tả một nhiệm vụ, nhằm giảm bớt khó khăn trong việc hiểu nhiệm vụ. Tuy nhiên, thiết kế như vậy có thể làm suy giảm khả năng của LLM để tổng quát hóa cho các loại nhiệm vụ mới. Chúng tôi tin rằng mô tả nhiệm vụ bằng ngôn ngữ tự nhiên trực tiếp hơn đối với người dùng. Nó cũng không phụ thuộc vào loại nhiệm vụ, và không đòi hỏi heuristics để thiết kế meta-feature. Do đó, chúng tôi điều chỉnh mô tả nhiệm vụ mà không cần bất kỳ kỹ thuật đặc trưng nào, và người dùng có thể tự do mô tả tên tập dữ liệu, đặc điểm, ràng buộc đặc trưng cho lĩnh vực, và nhiều hơn nữa. Hơn nữa, các thí nghiệm của chúng tôi (§ D) minh họa rằng việc kết hợp giao diện người dùng ngôn ngữ tự nhiên giúp nhớ lại và tận dụng kiến thức trước đó có trong corpus huấn luyện của LLM.

4.3 Truy xuất
Kỹ thuật truy xuất đã được sử dụng để (i) thu thập một số minh chứng của các giải pháp ML lịch sử cho các nhiệm vụ liên quan và (ii) áp dụng kiến thức hữu ích trước đó để thúc đẩy và nhắc nhở LLM giải quyết tốt hơn nhiệm vụ ML mục tiêu.

Chúng tôi đầu tiên thảo luận cách truy xuất kinh nghiệm RE như minh chứng ˜E. Một cách trực quan, kinh nghiệm hữu ích nhất trong việc giải quyết một nhiệm vụ mới nên đến từ các nhiệm vụ liên quan nhất. Câu hỏi chính sau đó trở thành cách định nghĩa sự liên quan. Để đạt được điều này, chúng tôi đầu tiên nhúng mô tả nhiệm vụ bằng cách gọi một mô hình ngôn ngữ E (ví dụ: GPT-3 (Brown et al., 2020)) để tạo ra một vector nhúng của nội dung văn bản. Cho một nhiệm vụ mới ˜T, MLCopilot truy xuất các nhiệm vụ lịch sử liên quan nhất từ nhóm kinh nghiệm PE bằng cách tính toán độ tương tự cosine giữa các nhúng của nhiệm vụ mới và các nhiệm vụ được lưu trữ. Kinh nghiệm tương ứng với các nhúng này sẽ phục vụ như minh chứng ˜E, được tính toán như ˜E=RE(˜T, PE) = arg top-k ⟨T,S,M⟩∈PE E(T)·E(˜T) |E(T)|·|E(˜T)|!, trong đó k mục kinh nghiệm liên quan nhất sẽ được truy xuất cho minh chứng tiếp theo.

Việc truy xuất kiến thức RK dựa trên việc ghép nối của không gian giải pháp – truy xuất tất cả kiến thức được khai thác từ cùng không gian giải pháp như nhiệm vụ mới, từ nhóm kiến thức PK. Sự đơn giản này của RK là do thực tế rằng kiến thức được tạo ra trong giai đoạn ngoại tuyến của MLCopilot là ngắn gọn và chất lượng cao, quy trình tạo ra sẽ được thảo luận trong § 4.5.

4.4 Chuẩn hóa
Như đã đề cập trước đó, dữ liệu của kinh nghiệm ML thô là không đồng nhất và có các định dạng đa dạng. Trong khi một số trong chúng (ví dụ: mô tả nhiệm vụ) đã ở định dạng văn bản tự nhiên, các giải pháp ML và hiệu suất thước đo tương ứng thường được biểu thị trong các cấu hình có cấu trúc, định dạng dạng bảng, hoặc ngôn ngữ lập trình. Quan trọng hơn, chúng thậm chí có thể chứa rất nhiều số, mà các mô hình ngôn ngữ hoặc thậm chí LLM không giỏi trong việc xử lý và hiểu (Thawani et al., 2021; Han et al., 2022; Saxton et al., 2019). Để giải phóng tốt hơn sức mạnh của LLM, chúng tôi chuẩn hóa tất cả dữ liệu để biểu thị nó bằng ngôn ngữ tự nhiên.

Phần thiết yếu của chuẩn hóa là chuyển đổi dữ liệu thô thành ngôn ngữ tự nhiên được định dạng tốt, như được thể hiện trong phần bên trái của Hình 2. Ngoài việc thống nhất các giải pháp trong các định dạng đa dạng, một kỹ thuật quan trọng là rời rạc hóa số tránh việc cung cấp số trực tiếp cho LLM. Chúng tôi tuân theo (Thawani et al., 2021) rời rạc hóa dữ liệu số liên tục thành một số khoảng, và ánh xạ mỗi giá trị trong mỗi khoảng đến cùng giá trị rời rạc. Để giảm thiểu mất mát hiệu suất, chúng tôi rời rạc hóa mỗi giá trị số dựa trên phân phối tương ứng và các điểm phần trăm. Chi tiết hơn có thể tìm thấy trong § 5.1.

4.5 Khai thác Kiến thức
Với kinh nghiệm được chuẩn hóa được lưu trữ trong nhóm PE, MLCopilot sau đó có thể khai thác kiến thức, để hỗ trợ tốt hơn giai đoạn trực tuyến cho việc giải quyết các nhiệm vụ ML mới. Quan trọng là lưu ý rằng khai thác kiến thức xảy ra ngoại tuyến, trước khi phục vụ các nhiệm vụ người dùng. Phương pháp liên quan đến các bước sau: (i) xây dựng một lời nhắc bao gồm một tập con ngẫu nhiên của nhóm kinh nghiệm (để tránh thiên vị đối với các nhiệm vụ nhất định), cùng với một câu hỏi yêu cầu phân tích và tóm tắt; (ii) gửi lời nhắc đến LLM để tạo ra một "ứng viên" kiến thức; (iii) xác thực ứng viên trên nhóm kinh nghiệm. Dòng chảy của quá trình này được minh họa trong phần bên phải của Hình 2 (mã giả trong § A).

Chúng tôi elabora về bước xác thực, mà chúng tôi gọi là hậu-xác thực tự động sau khi yêu cầu kiến thức từ LLM. Bước này được thiết kế để giảm bớt vấn đề ảo giác (Ji et al., 2023) và nâng cao chất lượng kiến thức được tạo ra. Nó kiểm tra kiến thức bằng cách sử dụng nó để giải quyết một tập các nhiệm vụ xác thực. Nếu kiến thức được tạo ra được tìm thấy không hợp lệ (ví dụ: do ảo giác), nó điều chỉnh các thiết lập tạo ra, như thứ tự của các kinh nghiệm trong lời nhắc, tông của câu hỏi hypophora, và các tham số của việc gọi LLM, và để LLM tái tạo kiến thức. Quá trình lặp này tiếp tục cho đến khi hiệu suất trên các nhiệm vụ xác thực đã hội tụ, hoặc việc gọi đã đạt đến số lượng tối đa. Quá trình này có thể được biểu diễn chính thức là K=IK(PE;LLM).

Chúng tôi lập luận rằng khai thác kiến thức của chúng tôi là mới và khác biệt so với các công trình trước đó về trích xuất kiến thức (Zhang et al., 2022) hoặc tạo ra kiến thức (Yu et al., 2022; Lu et al., 2023) trong xử lý ngôn ngữ tự nhiên. Đầu tiên, kiến thức của chúng tôi được thu thập từ các nguồn tài nguyên không đồng nhất sử dụng các mô hình hoàn thiện văn bản tổng quát, mà không đòi hỏi các mẫu được định nghĩa trước hoặc các pipeline phức tạp. Thứ hai, việc thu thập kiến thức cho các nhiệm vụ ML đòi hỏi phân tích, tóm tắt, và lý luận cấp cao, điều này đáng kể khó khăn hơn so với việc chỉ trích xuất các sự kiện đơn giản (Zhang et al., 2022). Cuối cùng, kiến thức được neo trong dữ liệu kinh nghiệm, thay vì hoàn toàn dựa trên corpus huấn luyện trước của LLM (Yu et al., 2022), điều này làm cho khung có thể mở rộng cho các tình huống mới.

Kiến thức được khai thác bởi MLCopilot có thể có lợi không chỉ cho LLM mà còn cho các thực hành viên ML con người. Vì kiến thức được biểu thị bằng ngôn ngữ tự nhiên, nó có thể tiềm năng phục vụ như một sách nấu ăn cho các nhà phát triển ML. Trong nỗ lực chia sẻ các phát hiện của chúng tôi và truyền cảm hứng cho nghiên cứu ML tương lai, chúng tôi đã phát hành tất cả kiến thức thu được cho đến nay (xem § E). Hy vọng điều này sẽ tiết lộ một số "bí quyết" đằng sau cách ML hoạt động và thúc đẩy chia sẻ kiến thức trong cộng đồng.

5 Thí nghiệm
Chúng tôi đánh giá MLCopilot trên một loạt các điểm chuẩn, nhằm trả lời các câu hỏi nghiên cứu sau: (i) MLCopilot có thể vượt trội hơn các phương pháp truyền thống hoặc tương tác đơn giản với LLM không? (ii) Các kỹ thuật riêng lẻ trong MLCopilot quan trọng như thế nào, ví dụ: kiến thức và kinh nghiệm? (iii) Kiến thức được khai thác có thông tin và hợp lý không?

5.1 Thiết lập Thí nghiệm
Chi tiết triển khai. Việc triển khai hiện tại của MLCopilot liên quan đến việc duy trì các nhóm kinh nghiệm và kiến thức chuyên biệt cho mỗi không gian giải pháp. Dữ liệu lịch sử được thu thập từ các điểm chuẩn được mô tả dưới đây, trong khi mô tả nhiệm vụ được thu thập từ các trang web điểm chuẩn. Các giá trị số trong dữ liệu được rời rạc hóa thành năm mức: "rất thấp", "thấp", "trung bình", "cao", và "rất cao". Giá trị chính xác của mỗi mức được xác định bằng cách phân tích thống kê của các giải pháp tốt nhất trong không gian giải pháp (xem phân tích chi tiết trong § 5.3). Chúng tôi tương tác với mô hình GPT-3.5 đa mục đích3 (tên mã "text-davinci-003", không có fine-tuning bổ sung), và "text-embedding-ada-002" để có được các nhúng cho mô tả nhiệm vụ. (Kết quả với các LLM khác có thể tìm thấy trong § D.3.) Nhiệt độ được đặt thành 0 để giảm thiểu ngẫu nhiên. Chi tiết bổ sung về thiết kế lời nhắc có thể tìm thấy trong § C.

Điểm chuẩn. Chúng tôi đã chọn các điểm chuẩn đã thiết lập một không gian giải pháp được xác định trước cho tất cả các giải pháp có thể và cung cấp các thước đo hiệu suất cho tất cả các giải pháp trong không gian giải pháp (thông qua bảng tra cứu hoặc surrogate). Chúng tôi đã thực hiện thí nghiệm sử dụng MLCopilot trên ba điểm chuẩn ML: HPO-B (Arango et al., 2021), PD1 (Wang et al., 2021b), và HyperFD (Yan et al., 2022). Những điểm chuẩn này bao gồm nhiều nhiệm vụ và tập dữ liệu ML, bao phủ một phổ rộng các tình huống như phân loại và hồi quy dữ liệu dạng bảng, phân loại hình ảnh, và phát hiện đối tượng. Chi tiết có thể tìm thấy trong § B.1.

Thước đo đánh giá. Trong mỗi thí nghiệm, mỗi phương pháp được so sánh thực hiện ba lần thử để dự đoán các giải pháp thành công cho một nhiệm vụ chưa được nhìn thấy. Các giải pháp được đánh giá theo thứ tự chúng được đề xuất. Metric@t, trong đó t≥1, được định nghĩa là hiệu suất thước đo tốt nhất đạt được trong số t giải pháp được đề xuất đầu tiên. Các thước đo hiệu suất được báo cáo được tính trung bình trên ít nhất 5 hạt giống ngẫu nhiên.

5.2 Kết quả Chính
Chúng tôi cho thấy hiệu suất của MLCopilot trong Bảng 2. Các baseline chúng tôi so sánh bao gồm:

• Các phương pháp AutoML hoặc meta learning truyền thống,

3 https://platform.openai.com/docs/models/ gpt-3-5

--- TRANG 6 ---
Phương pháp HPO-B ↑ PD1↑ HyperFD (Rank ↓AP↑)
nAcc@1 nAcc@2 nAcc@3 nAcc@1 nAcc@2 nAcc@3 Rank@1 Rank@2 Rank@3 AP@1 AP@2 AP@3
Random 54.70 60.70 64.80 -0.86 -0.08 0.39 109.55 73.16 54.79 90.76 91.20 91.38
Constant 72.85 74.61 75.02 1.27 1.56 1.59 78.00 54.33 49.25 91.13 91.23 91.28
TST-M 72.73 74.44 74.56 1.10 1.35 1.40 57.67 43.50 42.67 91.22 91.37 91.38
HyperSTAR 67.37 68.14 68.71 1.10 1.27 1.34 97.75 72.97 52.03 90.78 91.05 91.25
ASKL 77.01 81.76 85.02 1.26 1.29 1.44 92.58 64.67 51.25 90.93 91.15 91.34
FLAML 77.84 82.95 88.06 1.28 1.31 1.58 66.42 43.33 31.83 91.09 91.29 91.33
HyperFD – – – – – – 56.97 47.91 31.75 91.17 91.26 91.44
LLM-ZS 61.37 79.41 80.56 -1.03 1.25 1.26 119.25 90.42 41.00 90.69 90.96 91.38
LLM-FS 78.93 83.10 89.73 0.43 0.57 0.62 66.69 52.43 40.98 91.26 91.40 91.48
MLCopilot 81.59 83.23 90.72 1.48 1.54 1.62 59.74 38.67 25.58 91.38 91.60 91.66

Bảng 2: Kết quả chính trên HPO-B, PD1 và HyperFD. nAcc, AP: càng cao càng tốt. Rank: càng thấp càng tốt.

bao gồm Random, ASKL (Feurer et al., 2015), Constant (Bardenet et al., 2013; Kotthoff et al., 2019), TST-M (Wistuba et al., 2016), HyperSTAR (Mittal et al., 2020), HyperFD (Yan et al., 2022) và FLAML-Zero (Wang et al., 2021a). Chi tiết được mô tả trong § B.2.

• LLM-ZS trực tiếp nhắc nhở LLM để tạo ra một giải pháp zero-shot chỉ dựa trên mô tả nhiệm vụ, tương tự như sử dụng các công cụ như GitHub Copilot4 hoặc Amazon CodeWhisperer5.

• LLM-FS sử dụng kỹ thuật nhắc nhở few-shot (Brown et al., 2020) bằng cách thêm một số minh chứng vào lời nhắc để kích hoạt học trong ngữ cảnh. Các minh chứng được chọn ngẫu nhiên từ nhóm kinh nghiệm được chuẩn hóa của chúng tôi. Không giống như MLCopilot, LLM-FS không có quyền truy cập vào các kỹ thuật tiên tiến như truy xuất kinh nghiệm và kiến thức.

MLCopilot đạt được độ chính xác chuẩn hóa cao nhất (nAcc) trên cả ba lần thử. Sự cải thiện đặc biệt đáng kể cho lần thử đầu tiên (nAcc@1). Đáng chú ý là LLM-FS đã vượt qua tất cả các baseline truyền thống, cho thấy khả năng lớn của LLM trên các nhiệm vụ ML.

Trên PD1, Độ chính xác chuẩn hóa (nAcc) nằm trong khoảng [−2,2] theo thiết lập của (Wang et al., 2021b). MLCopilot vẫn là tốt nhất trong số tất cả các phương pháp được so sánh. Đáng chú ý, baseline "Constant" gần như vượt trội tất cả các baseline khác, điều này đặt nghi vấn về hiệu quả của độ tương tự nhiệm vụ được đo bởi các baseline khác. Trong khi đó, cả LLM-ZS và LLM-FS đều thất bại trên PD1, cho thấy PD1 thách thức hơn đối với LLM.

Đối với HyperFD, Theo (Yan et al., 2022), chúng tôi sử dụng độ chính xác trung bình (AP) (càng cao càng tốt) và thứ hạng (trong [1,216], càng thấp càng tốt) để đo hiệu suất. Tương tự như những gì được quan sát trong HPO-B, LLM-FS đạt hiệu suất tương đương với hầu hết các baseline với một vài minh chứng. Dự kiến rằng hiệu suất của LLM-FS sẽ cải thiện với việc bao gồm các kỹ thuật từ MLCopilot. Tuy nhiên, đáng chú ý là HyperFD là một điểm chuẩn riêng tư và điểm chuẩn của nó được phát hành sau thời điểm cắt kiến thức của GPT-3.5, làm cho không có khả năng LLM đã ghi nhớ các giải pháp tốt nhất trên điểm chuẩn này.

5.3 Nghiên cứu Ablation
Trong nghiên cứu ablation, chúng tôi sử dụng nAcc@1 (hoặc Rank@1) như thước đo chính cho các so sánh.

Nghiên cứu về truy xuất. Câu hỏi đầu tiên chúng tôi cố gắng trả lời là liệu việc truy xuất kinh nghiệm và kiến thức có cần thiết hay không – điều gì xảy ra nếu một trong số chúng bị thiếu từ lời nhắc được gửi đến LLM? Kết quả được thể hiện trong Bảng 4. Trong khi việc thiếu kiến thức dẫn đến giảm hiệu suất, việc thiếu minh chứng dẫn đến sụp đổ hoàn toàn. Kiểm tra kiến thức được tạo ra (§ E), chúng tôi thấy nó thường chứa các tuyên bố mơ hồ như "Kích thước của tập dữ liệu có thể ảnh hưởng đến cấu hình của eta" (HPO-B, Space 5971). Kiến thức không làm rõ "ảnh hưởng" là gì, đó là lý do tại sao kinh nghiệm vẫn rất cần thiết ngay cả với sự hiện diện của kiến thức.

Sau đó chúng tôi so sánh các phương pháp truy xuất khác nhau (cột "Pipeline MLCopilot" trong Bảng 3). MLCopilot truy xuất các nhiệm vụ liên quan nhất dựa trên nhúng của mô tả văn bản. Như một lựa chọn thay thế, chúng ta có thể (i) đo độ tương tự dựa trên meta-feature; (ii) đơn giản là truy xuất kinh nghiệm một cách ngẫu nhiên. Được thể hiện trong Bảng 3, cả meta-feature và text embedding đều vượt trội hơn truy xuất ngẫu nhiên một cách nhất quán.

Khi lựa chọn giữa meta-feature hoặc text embedding, chúng tôi tin rằng cái sau đã chứng minh lợi thế so với các meta-feature được thiết kế thủ công. Điều này một phần do thực tế rằng hiệu suất của meta-feature phụ thuộc phần lớn vào

--- TRANG 7 ---
Truy xuất bởi Pipeline HPO-B ↑ PD1 ↑ HyperFD ↓
ASKL MLCopilot ASKL MLCopilot ASKL MLCopilot
Text embedding 75.34 ±0.00 81.59±0.94 1.40±0.00 1.48±0.06 79.17±0.00 59.74±1.89
Meta-feature 80.61 ±0.00 83.29±1.46 1.02±0.00 1.41±0.09 107.67 ±0.00 50.49±6.38
Random 73.67 ±2.51 78.00±2.82 0.06±0.25 1.37±0.12 84.23±14.84 57.95±10.19

Bảng 3: So sánh các phương pháp truy xuất kinh nghiệm (tức là dựa trên những thước đo nào để truy xuất kinh nghiệm) và tiêu thụ kinh nghiệm được truy xuất (ASKL: sử dụng trực tiếp các giải pháp cho các nhiệm vụ được truy xuất trên nhiệm vụ mới; MLCopilot: sử dụng kinh nghiệm được truy xuất như minh chứng cùng với kiến thức để nhắc nhở LLM).

Truy xuất HPO-B ↑PD1 ↑HyperFD ↓
Exp.+Know. 81.59 ±0.94 1.48±0.06 59.74±1.89
Know. 62.77 ±1.78 1.10±0.00 127.75 ±0.00
Exp. 76.21 ±0.16 1.36±0.09 63.20±3.55

Bảng 4: Ảnh hưởng của việc truy xuất kinh nghiệm và kiến thức.

chất lượng thiết kế của chúng. Trong khi meta-feature đã được chứng minh là hứa hẹn cho các tập dữ liệu dạng bảng nơi chúng được nghiên cứu kỹ và được thiết kế cẩn thận (Feurer et al., 2015; Wang et al., 2021a), việc thiết kế meta-feature cho các nhiệm vụ phức tạp trong PD1 là không tầm thường. Ngược lại, phương pháp text embedding có lợi thế bổ sung là không đòi hỏi bất kỳ thiết kế thủ công nào cho các loại nhiệm vụ mới. Hơn nữa, text embedding hứa hẹn hơn cho việc xử lý các nhiệm vụ mới và đa dạng, trong khi meta-feature cho các nhiệm vụ mới không dễ dàng mở rộng.

Tuy nhiên, chúng tôi muốn nhấn mạnh rằng yếu tố chính không chỉ là phương pháp truy xuất kinh nghiệm, mà là cách kinh nghiệm được truy xuất được sử dụng. Khi kinh nghiệm được truy xuất được sử dụng trực tiếp, như được thực hiện trong ASKL, tất cả các chiến lược truy xuất đều hoạt động kém. Ngược lại, MLCopilot có khả năng không chỉ truy xuất kinh nghiệm liên quan, mà còn cung cấp hướng dẫn thông qua kiến thức được khai thác và tận dụng sức mạnh của LLM.

Nghiên cứu về chuẩn hóa. Như thể hiện trong Bảng 6, hiệu suất chịu đựng đáng kể mà không có rời rạc hóa vì việc gửi các giá trị số liên tục trực tiếp đến LLM là không khả thi. Hơn nữa, rất quan trọng là tính toán các điểm phân chia dựa trên thống kê của các giải pháp tốt nhất. Nếu phạm vi được mở rộng để bao gồm tất cả các giá trị có thể, điểm phân chia có thể không rơi vào các điểm nhạy cảm, dẫn đến hiệu suất kém. Điều này được chứng minh bởi "On All" trong Bảng 6, hoạt động thậm chí tệ hơn so với không có rời rạc hóa gì cả6.

Nghiên cứu về kiến thức. Trong Bảng 5, chúng tôi đã thực hiện một nghiên cứu ablation để đánh giá tác động của kiến thức đối với phương pháp của chúng tôi. Kết quả cho thấy rằng, việc loại bỏ truy xuất kiến thức trong giai đoạn trực tuyến của phương pháp của chúng tôi

6 Xin lưu ý rằng HyperFD không được bao gồm trong nghiên cứu ablation vì nó áp dụng một không gian giải pháp rời rạc.

Phương pháp HPO-B ↑HyperBO ↑HyperFD ↓
MLCopilot 81.59 ±0.94 1.48±0.06 59.74±1.89
w/oPost-Val. 78.34 ±0.71 1.44±0.05 62.41±3.66
w/oKnow. 76.21 ±0.16 1.36±0.09 63.20±3.55

Bảng 5: Ablation về sử dụng kiến thức trong giai đoạn trực tuyến và hậu-xác thực trong giai đoạn ngoại tuyến.

Rời rạc hóa HPO-B ↑PD1 ↑HyperFD ↓
On Best 81.59 ±0.94 1.48±0.06 59.74±1.89
On All 70.82 ±0.01 1.41±0.02 –
✗ 74.09±0.44 1.45±0.05 84.96±7.16

Bảng 6: Rời rạc hóa trong chuẩn hóa.

dẫn đến giảm đáng kể hiệu suất cuối cùng. Điều này là bởi vì kiến thức đóng vai trò quan trọng trong việc giúp LLM đạt được các giải pháp hiệu quả nhất. Hơn nữa, hậu-xác thực trong quy trình khai thác trong giai đoạn ngoại tuyến của MLCopilot cũng đóng một vai trò quan trọng trong việc nâng cao tính hữu ích của nó.

Dựa trên nghiên cứu định tính của chúng tôi về kiến thức được tạo ra (xem § E), chúng tôi thấy rằng, kiến thức phục vụ như một tóm tắt hữu ích của các kinh nghiệm ML quá khứ đồng thời cung cấp hướng dẫn về cách điều chỉnh các tham số và thiết lập dựa trên đặc điểm nhiệm vụ. Chúng tôi quan sát rằng hậu-xác thực giảm đáng kể khả năng kiến thức tầm thường, mơ hồ, hoặc ảo giác được tạo ra, mặc dù kiến thức như vậy đôi khi vẫn được quan sát. Ví dụ, trong trường hợp nhiệm vụ "UniRef50" với mô hình "Transformer" trên PD1, kiến thức chứa một số ví dụ số không phải là một phần của các minh chứng và thay vào đó là kết quả của ảo giác.

6 Kết luận
Tóm lại, bài báo này đề xuất MLCopilot, một khung giải phóng sức mạnh của LLM để giải quyết các nhiệm vụ ML thực tế. MLCopilot thể hiện tính linh hoạt của LLM, rằng nó có thể xử lý không chỉ các nhiệm vụ liên quan đến văn bản, mà còn các nhiệm vụ liên quan đến đầu vào không đồng nhất và lý luận phức tạp. Chúng tôi tin rằng điều này đại diện cho một tiến bộ đáng kể trong việc mở rộng phạm vi ứng dụng LLM đến một phổ rộng hơn các vấn đề phức tạp.

--- TRANG 8 ---
7 Cân nhắc Đạo đức
Kiến trúc của MLCopilot được thiết kế tỉ mỉ để đảm bảo rằng các giải pháp nó đề xuất luôn nằm trong giới hạn của không gian giải pháp được cung cấp bởi người dùng. Kết quả là, nó hoạt động như một biện pháp bảo vệ chống lại việc tạo ra các giải pháp không đạo đức, với điều kiện không gian giải pháp được định nghĩa tuân thủ các tiêu chuẩn đạo đức.

Tuy nhiên, các kỹ thuật cơ bản được nêu trong bài báo này, bao gồm truy xuất kinh nghiệm và khai thác kiến thức, sở hữu khả năng ứng dụng rộng hơn trên nhiều tình huống khác nhau ngoài học máy, như tự động hóa nhiệm vụ (Lu et al., 2023) và nghiên cứu khoa học (Boiko et al., 2023). Trong những bối cảnh này nơi không gian giải pháp mở rộng ra ngoài các ràng buộc của một vấn đề học máy được định nghĩa chặt chẽ và nơi Các Mô Hình Ngôn Ngữ Lớn (LLM) thể hiện những hạn chế vốn có, tiềm năng cho sự không thể dự đoán được phát sinh. Do đó, trở nên bắt buộc phải thực hiện sự thận trọng đạo đức khi triển khai MLCopilot trong các trường hợp đa dạng.

8 Hạn chế
Rò rỉ dữ liệu tiềm năng. Vì LLM được huấn luyện trên corpus dữ liệu lớn từ Internet, có khả năng các điểm chuẩn (đặc biệt là HPO-B dựa trên OpenML) đã được gặp phải trong giai đoạn huấn luyện trước của LLM. Để giảm thiểu thiên vị tiềm năng này, chúng tôi đã thực hiện đánh giá MLCopilot trên HyperFD (Yan et al., 2022). Đáng chú ý là tập dữ liệu HyperFD được giới thiệu trong một bài báo được xuất bản sau ngày cắt kiến thức của GPT-3.5, và bản thân tập dữ liệu vẫn riêng tư. Chúng tôi thực nghiệm tiết lộ rằng MLCopilot thể hiện hiệu suất mạnh mẽ trên tập dữ liệu HyperFD.

Hơn nữa, các phát hiện của chúng tôi cho thấy sự nâng cao hiệu suất đáng kể khi dữ liệu được chuẩn hóa (Bảng 6). Nếu dữ liệu thực sự được ghi nhớ trong quá trình huấn luyện trước, LLM có thể sẽ được hưởng lợi từ việc truy cập vào dữ liệu thô, không thay đổi. Những kết quả này cung cấp bằng chứng hỗ trợ có giá trị cho khẳng định rằng khả năng của LLM vượt ra ngoài việc ghi nhớ thuần túy. Chúng bao gồm một phổ rộng hơn các kỹ năng nhận thức, bao gồm lý luận toán học và tư duy logic.

Sự khác biệt so với các phương pháp AutoML. MLCopilot không được thiết kế để phục vụ như một sự thay thế cho các phương pháp AutoML đã được thiết lập. Sự khác biệt được dựa trên những hạn chế vốn có của Các Mô Hình Ngôn Ngữ Lớn (LLM) khi thực hiện các tính toán toán học, như được minh họa trong công trình gần đây (Imani et al., 2023). Do đó, không có khả năng MLCopilot sẽ vượt qua các phương pháp tối ưu hóa Bayesian hiện đại trong việc theo đuổi các giải pháp vượt trội. Trong Bảng 2 chúng tôi chấm dứt đánh giá của mình tại t=3 (tức là ba giải pháp), vì chúng tôi quan sát rằng hiệu suất đạt đến điểm bão hòa với những tăng thêm trong t.

Chúng tôi lập luận rằng giá trị thực sự của MLCopilot nằm ở các khía cạnh sau: (i) nó chấp nhận các loại mô tả nhiệm vụ tùy ý; (ii) nó tận dụng các kinh nghiệm ML từ các nguồn đa dạng, bao gồm cả huấn luyện trước và nhắc nhở; (iii) nó thể hiện khả năng đặc biệt để nhanh chóng tạo ra nhiều giải pháp out-of-the-box cho một nhiệm vụ mới. Do đó, chúng tôi hình dung khả năng kết hợp MLCopilot với các phương pháp AutoML hiện có, mở ra một con đường hấp dẫn cho khám phá tương lai.

Tính mạnh mẽ của MLCopilot. Vì MLCopilot có khả năng chứa các định dạng đầu vào không đồng nhất, đáng để thảo luận về tính mạnh mẽ của MLCopilot trong thực tế. Cân nhắc này mở rộng đến các tình huống nơi người dùng gửi các mô tả nhiệm vụ được định dạng kém và khi nhóm kinh nghiệm bao gồm dữ liệu với nhãn độ chính xác nhiễu hoặc chuẩn hóa có lỗi. Một đánh giá chi tiết về tính mạnh mẽ của MLCopilot được trình bày trong § D.

Các thí nghiệm được tiến hành làm sáng tỏ tính mạnh mẽ của hệ thống chống lại một số thách thức nhất định (ví dụ: lựa chọn LLM và định dạng mô tả nhiệm vụ). Nhưng vẫn quan trọng là lưu ý rằng hiệu suất của nó có thể suy giảm trong các điều kiện cụ thể, như khi xử lý với độ dài cửa sổ ngữ cảnh lời nhắc bị hạn chế nghiêm trọng.

Tài liệu tham khảo
Marcin Andrychowicz, Misha Denil, Sergio Gomez,
Matthew W Hoffman, David Pfau, Tom Schaul, Brendan Shillingford, và Nando De Freitas. 2016. Learning to learn by gradient descent by gradient descent.
Advances in neural information processing systems, 29.

Sebastian Pineda Arango, Hadi Samer Jomaa, Martin Wistuba, và Josif Grabocka. 2021. Hpo-b: A large-scale reproducible benchmark for black-box hpo based on openml. In Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 2).

Rémi Bardenet, Mátyás Brendel, Balázs Kégl, và Michele Sebag. 2013. Collaborative hyperparameter tuning. In International conference on machine learning, pages 199–207. PMLR.

--- TRANG 9 ---
Christopher M Bishop và Nasser M Nasrabadi. 2006.
Pattern recognition and machine learning, volume 4.
Springer.

Daniil A. Boiko, Robert MacKnight, và Gabe Gomes.
2023. Emergent autonomous scientific research capabilities of large language models.

Leo Breiman. 2001. Random forests. Machine learning,
45:5–32.

Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie
Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind
Neelakantan, Pranav Shyam, Girish Sastry, Amanda
Askell, Sandhini Agarwal, Ariel Herbert-Voss,
Gretchen Krueger, Tom Henighan, Rewon Child,
Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu,
Clemens Winter, Christopher Hesse, Mark Chen, Eric
Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess,
Jack Clark, Christopher Berner, Sam McCandlish,
Alec Radford, Ilya Sutskever, và Dario Amodei.
2020. Language Models are Few-Shot Learners. In
Conference on Neural Information Processing Systems (NeurIPS).

Tianqi Chen và Carlos Guestrin. 2016. Xgboost: A
scalable tree boosting system. In Proceedings of
the 22nd acm sigkdd international conference on
knowledge discovery and data mining, pages 785–
794.

Yutian Chen, Xingyou Song, Chansoo Lee, Zi Wang,
Richard Zhang, David Dohan, Kazuya Kawakami,
Greg Kochanski, Arnaud Doucet, Marc'aurelio Ranzato, et al. 2022. Towards learning universal hyperparameter optimizers with transformers. Advances in
Neural Information Processing Systems, 35:32053–
32068.

Aakanksha Chowdhery, Sharan Narang, Jacob Devlin,
Maarten Bosma, Gaurav Mishra, Adam Roberts,
Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, và others. 2022. Palm:
Scaling language modeling with pathways. ArXiv,
abs/2204.02311.

Corinna Cortes và Vladimir Vapnik. 1995. Supportvector networks. Machine learning, 20:273–297.

Oxford English Dictionary. 1989. Oxford english dictionary. Simpson, Ja & Weiner, Esc, 3.

Matthias Feurer, Aaron Klein, Katharina Eggensperger,
Jost Springenberg, Manuel Blum, và Frank Hutter. 2015. Efficient and robust automated machine
learning. Advances in neural information processing
systems, 28.

Peter I Frazier. 2018. A tutorial on bayesian optimization. arXiv preprint arXiv:1807.02811.

Hongwei Han, Jialiang Xu, Mengyu Zhou, Yijia Shao,
Shi Han, và Dongmei Zhang. 2022. Luna: Language understanding with number augmentations on
transformers via number plugins and pre-training.
arXiv preprint arXiv:2212.02691.

Jie Huang và Kevin Chen-Chuan Chang. 2022. Towards reasoning in large language models: A survey.
arXiv preprint arXiv:2212.10403.

Frank Hutter, Lars Kotthoff, và Joaquin Vanschoren.
2019. Automated machine learning: methods, systems, challenges. Springer Nature.

Shima Imani, Liang Du, và Harsh Shrivastava. 2023.
Mathprompter: Mathematical reasoning using large
language models.

Ziwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan
Su, Yan Xu, Etsuko Ishii, Ye Jin Bang, Andrea
Madotto, và Pascale Fung. 2023. Survey of hallucination in natural language generation. ACM Computing Surveys, 55(12):1–38.

Lars Kotthoff, Chris Thornton, Holger H Hoos, Frank
Hutter, và Kevin Leyton-Brown. 2019. Auto-weka:
Automatic model selection and hyperparameter optimization in weka. Automated machine learning:
methods, systems, challenges, pages 81–95.

Alex Krizhevsky, Ilya Sutskever, và Geoffrey E Hinton. 2017. Imagenet classification with deep convolutional neural networks. Communications of the ACM,
60(6):84–90.

Pan Lu, Baolin Peng, Hao Cheng, Michel Galley, KaiWei Chang, Ying Nian Wu, Song-Chun Zhu, và Jianfeng Gao. 2023. Chameleon: Plug-and-play compositional reasoning with large language models. arXiv
preprint arXiv:2304.09842.

Yao Lu, Max Bartolo, Alastair Moore, Sebastian Riedel,
và Pontus Stenetorp. 2022. Fantastically ordered
prompts and where to find them: Overcoming fewshot prompt order sensitivity. In Proceedings of the
60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages
8086–8098.

Sewon Min, Xinxi Lyu, Ari Holtzman, Mikel Artetxe,
Mike Lewis, Hannaneh Hajishirzi, và Luke Zettlemoyer. 2022. Rethinking the Role of Demonstrations:
What Makes In-Context Learning Work? In Proceedings of the 2022 Conference on Empirical Methods in
Natural Language Processing (EMNLP). Association
for Computational Linguistics.

Gaurav Mittal, Chang Liu, Nikolaos Karianakis, Victor
Fragoso, Mei Chen, và Yun Fu. 2020. Hyperstar:
Task-aware hyperparameters for deep networks. In
Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 8736–
8745.

Yurii Evgen'evich Nesterov. 1983. A method of solving
a convex programming problem with convergence
rate o\bigl(kˆ2 \bigr). In Doklady Akademii Nauk,
volume 269, pages 543–547. Russian Academy of
Sciences.

OpenAI. 2023. Gpt-4 technical report.

--- TRANG 10 ---
Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,
Carroll Wainwright, Pamela Mishkin, Chong Zhang,
Sandhini Agarwal, Katarina Slama, Alex Ray, et al.
2022. Training language models to follow instructions with human feedback. Advances in Neural
Information Processing Systems, 35:27730–27744.

Arkil Patel, Satwik Bhattamishra, và Navin Goyal.
2021. Are nlp models really able to solve
simple math word problems? arXiv preprint
arXiv:2103.07191.

Hieu Pham, Melody Guan, Barret Zoph, Quoc Le, và
Jeff Dean. 2018. Efficient neural architecture search
via parameters sharing. In International conference
on machine learning, pages 4095–4104. PMLR.

Alec Radford, Karthik Narasimhan, Tim Salimans, và
Ilya Sutskever. 2018. Improving language understanding by generative pre-training.

Alec Radford, Jeff Wu, Rewon Child, David Luan,
Dario Amodei, và Ilya Sutskever. 2019. Language
models are unsupervised multitask learners.

David Saxton, Edward Grefenstette, Felix Hill, và
Pushmeet Kohli. 2019. Analysing mathematical reasoning abilities of neural models. arXiv preprint
arXiv:1904.01557.

Yongliang Shen, Kaitao Song, Xu Tan, Dongsheng Li,
Weiming Lu, và Yueting Zhuang. 2023. Hugginggpt: Solving ai tasks with chatgpt and its friends in
huggingface. arXiv preprint arXiv:2303.17580.

Richard S Sutton và Andrew G Barto. 2018. Reinforcement learning: An introduction. MIT press.

Avijit Thawani, Jay Pujara, Pedro A Szekely, và Filip
Ilievski. 2021. Representing numbers in nlp: a survey
and a vision. arXiv preprint arXiv:2103.13136.

Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier
Martinet, Marie-Anne Lachaux, Timothée Lacroix,
Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal
Azhar, Aurélien Rodriguez, Armand Joulin, Edouard
Grave, và Guillaume Lample. 2023. Llama: Open
and Efficient Foundation Language Models. ArXiv,
abs/2302.13971.

Joaquin Vanschoren, Jan N Van Rijn, Bernd Bischl,
và Luis Torgo. 2014. Openml: networked science
in machine learning. ACM SIGKDD Explorations
Newsletter, 15(2):49–60.

Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob
Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz
Kaiser, và Illia Polosukhin. 2017. Attention is all
you need. Advances in neural information processing
systems, 30.

Chi Wang, Qingyun Wu, Markus Weimer, và Erkang
Zhu. 2021a. Flaml: A fast and lightweight automl
library. Proceedings of Machine Learning and Systems, 3:434–447.

Zi Wang, George E Dahl, Kevin Swersky, Chansoo Lee,
Zelda Mariet, Zachary Nado, Justin Gilmer, Jasper
Snoek, và Zoubin Ghahramani. 2021b. Pre-trained
gaussian processes for bayesian optimization. arXiv
preprint arXiv:2109.08215.

Albert Webson và Ellie Pavlick. 2022. Do promptbased models really understand the meaning of their
prompts? In Proceedings of the 2022 Conference
of the North American Chapter of the Association
for Computational Linguistics: Human Language
Technologies, pages 2300–2344.

Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, E. Chi, Tatsunori Hashimoto, Oriol Vinyals,
P. Liang, J. Dean, và W. Fedus. 2022. Emergent Abilities of Large Language Models. ArXiv,
abs/2206.07682.

Martin Wistuba, Nicolas Schilling, và Lars SchmidtThieme. 2016. Two-stage transfer surrogate model
for automatic hyperparameter optimization. In
Machine Learning and Knowledge Discovery in
Databases: European Conference, ECML PKDD
2016, Riva del Garda, Italy, September 19-23, 2016,
Proceedings, Part I 16, pages 199–214. Springer.

Chenqian Yan, Yuge Zhang, Quanlu Zhang, Yaming
Yang, Xinyang Jiang, Yuqing Yang, và Baoyuan
Wang. 2022. Privacy-preserving online automl for
domain-specific face detection. In Proceedings of
the IEEE/CVF Conference on Computer Vision and
Pattern Recognition, pages 4134–4144.

Wenhao Yu, Dan Iter, Shuohang Wang, Yichong
Xu, Mingxuan Ju, Soumya Sanyal, Chenguang
Zhu, Michael Zeng, và Meng Jiang. 2022. Generate rather than retrieve: Large language models are strong context generators. arXiv preprint
arXiv:2209.10063.

Ningyu Zhang, Xin Xu, Liankuan Tao, Haiyang Yu,
Hongbin Ye, Shuofei Qiao, Xin Xie, Xiang Chen,
Zhoubo Li, Lei Li, et al. 2022. Deepke: A deep learning based knowledge extraction toolkit for knowledge
base population. arXiv preprint arXiv:2201.03335.

Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang,
Xiaolei Wang, Yupeng Hou, Yingqian Min, Beichen
Zhang, Junjie Zhang, Zican Dong, et al. 2023. A
survey of large language models. arXiv preprint
arXiv:2303.18223.

Mingkai Zheng, Xiu Su, Shan You, Fei Wang, Chen
Qian, Chang Xu, và Samuel Albanie. 2023. Can
gpt-4 perform neural architecture search?

--- TRANG 11 ---
A Các Thuật toán
Chúng tôi tóm tắt phương pháp của chúng tôi như thuật toán 1 và thuật toán 2.

Thuật toán 1: Giai đoạn Ngoại tuyến của MLCopilot
Đầu vào: Dữ liệu lịch sử H={D1, . . . , DNH}. Số vòng lặp tối đa rounds. Kiên nhẫn stagnation patience. Danh sách câu hỏi ứng viên Questions. Nhiệm vụ xác thực ValTasks.
Đầu ra: Nhóm Kinh nghiệm PE; Kiến thức k∗.
1PE← {C(Di)}; /*C là hàm chuẩn hóa */
2r∗← −∞;
3stagnation ←0;
4for n=1 to rounds do
5 E←RandomSample(PE);
6 q←RandomSample(Questions); /* Lấy mẫu một câu hỏi hypophora */
7 τ←Uniform(0,1); ; /* Nhiệt độ ngẫu nhiên */
8 k←LLM(E, q;τ); /* Tạo ứng viên kiến thức */
9 S←LLM(E, k;ValTasks; 0); /* Mô phỏng giai đoạn trực tuyến trên nhiệm vụ xác thực */
10 r←Evaluate(S); /* Chạy và đánh giá giải pháp */
11 if r > r∗ then
12 r∗ ←r;
13 k∗←k;
14 stagnation ←0;
15 else
16 stagnation ←stagnation + 1;
17 if stagnation > patience then
18 break;
19return PE, k∗

Thuật toán 2: Giai đoạn Trực tuyến của MLCopilot
Đầu vào: Mô tả nhiệm vụ mới ˜T. Nhóm kinh nghiệm PE. Nhóm kiến thức PK.
Đầu ra: Giải pháp ˜S.
1˜E← RE(˜T, PE); /* Truy xuất kinh nghiệm */
2˜K← RK(˜T, PK); /* Truy xuất kiến thức */
3˜S←LLM(˜T,˜E,˜K);
4return ˜S

B Chi tiết Thí nghiệm
B.1 Điểm chuẩn
HPO-B. HPO-B-v3 (Arango et al., 2021) bao gồm 16 không gian giải pháp cho 101 tập dữ liệu thu được từ OpenML (Vanschoren et al., 2014). Mỗi không gian có một thuật toán ML cố định như random forest (Breiman, 2001), SVM (Cortes và Vapnik, 1995), hoặc XGBoost (Chen và Guestrin, 2016), và mục tiêu là xác định cấu hình tối ưu của thuật toán cho một tập dữ liệu đã cho. HPO-B cũng cung cấp các cấu hình thành công từ các nhiệm vụ quá khứ, được chuẩn hóa thành kinh nghiệm trong trường hợp của chúng tôi. Ngoài ra, họ đã phát hành các mô hình surrogate để tăng tốc đánh giá các giải pháp chưa được thử trước đó. Hiệu suất điểm chuẩn cuối cùng được xác định bằng cách tính trung bình độ chính xác chuẩn hóa (nAcc) trên tất cả các tập dữ liệu, tuân theo giao thức chuẩn hóa trong (Arango et al., 2021).

--- TRANG 12 ---
PD1. Tập Dữ liệu Điều chỉnh Neural Net PD1 được đề xuất bởi HyperBO (Wang et al., 2021b), bao gồm 24 nhiệm vụ phân loại, bao phủ phân loại hình ảnh, dự đoán token tiếp theo, và dịch thuật. Mỗi nhiệm vụ được liên kết với một mạng nơ-ron được định nghĩa trước (CNN (Krizhevsky et al., 2017) hoặc transformer (Vaswani et al., 2017)), và có bốn tham số có thể cấu hình của một trình tối ưu hóa SGD với động lượng Nesterov (Nesterov, 1983). Do chi phí cao của việc huấn luyện mạng nơ-ron, việc đánh giá các giải pháp được đề xuất bởi MLCopilot bằng cách chạy chúng theo thời gian thực là không khả thi. Vì vậy chúng tôi đã tạo ra một mô hình surrogate để dự đoán hiệu suất của các giải pháp được đề xuất cho mỗi nhiệm vụ (xem § B.4 để biết chi tiết). Theo (Wang et al., 2021b), chúng tôi báo cáo độ chính xác chuẩn hóa (nAcc).

HyperFD. HyperFD (Yan et al., 2022) là một điểm chuẩn được thiết kế để tối ưu hóa hiệu suất của một detector khuôn mặt nơ-ron trên một tập dữ liệu chưa được nhìn thấy bằng cách cấu hình đúng cách tăng cường dữ liệu, kiến trúc nơ-ron, hàm mất mát, và công thức huấn luyện. Cho mục đích này, họ đã công thức hóa một không gian giải pháp và cung cấp cả độ chính xác trung bình (AP) và thứ hạng cho mọi giải pháp có thể trên tất cả các tập dữ liệu. Điểm chuẩn được xuất bản sau thời điểm cắt kiến thức được tuyên bố của GPT-3.5 (tháng 9 năm 2021), và nó chưa được phát hành công khai, làm cho không có khả năng nó đã xuất hiện trong dữ liệu huấn luyện của LLM.

B.2 Các Baseline được So sánh
Chi tiết về các baseline truyền thống được sử dụng trong thí nghiệm của chúng tôi được mô tả dưới đây.

• Phương pháp Random tạo ra một giải pháp ngẫu nhiên.
• ASKL (Auto-sklearn 1.0) (Feurer et al., 2015) tìm các nhiệm vụ tương tự nhất dựa trên các meta-feature được chọn thủ công của nhiệm vụ và trực tiếp sử dụng các giải pháp tốt nhất trên chúng.
• Constant (Bardenet et al., 2013; Kotthoff et al., 2019) (còn gọi là Average) sử dụng một tập hợp giải pháp không đổi cho bất kỳ nhiệm vụ mới nào. Tập hợp giải pháp được tạo ra là tập có hiệu suất trung bình tốt nhất trên các nhiệm vụ lịch sử. Phương pháp này đơn giản và không có tham chiếu văn học cụ thể. Chúng tôi tham chiếu hai văn học cho "Constant" vì họ cũng áp dụng một baseline tương tự để so sánh.
• TST-M (Wistuba et al., 2016) sử dụng các quá trình Gaussian để xấp xỉ hiệu suất của các giải pháp trong không gian giải pháp cho mỗi nhiệm vụ. Khi gặp một nhiệm vụ mới, nó kết hợp các dự đoán hiệu suất của các giải pháp cho các nhiệm vụ khác nhau và dự đoán hiệu suất của mỗi giải pháp trên nhiệm vụ mới bằng cách tính trung bình các dự đoán trên các nhiệm vụ lịch sử được cân bằng bởi độ tương tự nhiệm vụ.
• HyperSTAR (Mittal et al., 2020) huấn luyện một bộ dự đoán hiệu suất cho một mã hóa kết hợp của các đặc trưng giải pháp và nhiệm vụ. HyperSTAR ban đầu được xây dựng cho các nhiệm vụ thị giác. Để điều chỉnh nó cho các nhiệm vụ không phải hình ảnh, chúng tôi kết hợp các meta-feature được thiết kế thủ công như đặc trưng nhiệm vụ.
• HyperFD (Yan et al., 2022) là một phương pháp được thiết kế đặc biệt cho điểm chuẩn HyperFD, sử dụng một trích xuất meta-feature tinh vi cho các nhiệm vụ phát hiện khuôn mặt nơ-ron. Tuy nhiên, nó không phải là một phương pháp đa mục đích và không được thiết kế để hoạt động với các loại nhiệm vụ khác.
• FLAML-Zero (Wang et al., 2021a) là một phương pháp gần đây tạo ra một danh mục các giải pháp ML thông qua meta-training ngoại tuyến, giảm thiểu hối tiếc tổng thể trên các nhiệm vụ meta-training. Nó sử dụng meta-feature để liên kết các nhiệm vụ mới với các nhiệm vụ hiện có dựa trên độ tương tự của chúng.

B.3 Hậu-xác thực
Bước hậu-xác thực mà chúng tôi đã kết hợp lấy cảm hứng từ các thực hành đã được thiết lập trong học máy, nơi một tập xác thực chuyên biệt được sử dụng để nâng cao hiệu suất mô hình. Trong trường hợp cụ thể của chúng tôi, chúng tôi phân bổ 10% của meta-dataset huấn luyện cho mục đích xác thực, cho phép chúng tôi lọc và chọn kiến thức được tạo ra có giá trị nhất một cách có hệ thống. Lớp xác thực bổ sung này đóng góp đáng kể vào việc giải quyết các vấn đề liên quan đến ảo giác.

Các bước chi tiết của hậu-xác thực bao gồm một vòng lặp của: lấy mẫu câu hỏi hypophora, lấy mẫu nhiệt độ, tạo ứng viên kiến thức, xác thực kiến thức ứng viên, và một cơ chế dừng sớm xác định sự trì trệ. Điều này được mô tả trong thuật toán 1.

B.4 Xây dựng Mô hình Surrogate cho PD1
Thước đo trong PD1 chứa nhiều giá trị NaN, tương ứng với sự phân kỳ huấn luyện mạng. Cho mục đích điểm chuẩn, quan trọng hơn là có thể phân biệt các giải pháp hiệu suất hàng đầu, tức là các giải pháp trên độ chính xác trung bình. Để thực hiện điều này, chúng tôi áp dụng một phương pháp surrogate hai giai đoạn. Chúng tôi sử dụng một mô hình phân loại để phân biệt các giải pháp hiệu suất hàng đầu, và sau đó hai mô hình hồi quy: một được tối ưu hóa đặc biệt cho các giải pháp hiệu suất hàng đầu, và một mô hình khác cho tất cả các giải pháp. Chúng tôi sử dụng XGBoost (Chen và Guestrin, 2016) để xây dựng các classifier và regressor. Các tham số mặc định được sử dụng cho các mô hình đó.

C Thiết kế Lời nhắc
Chúng tôi cho thấy hai ví dụ lời nhắc được sử dụng trên HPO-B. Một trong số chúng được sử dụng cho giai đoạn trực tuyến, như được thể hiện trong Bảng 7, khi MLCopilot nhận mô tả nhiệm vụ được đưa ra bởi người dùng và gửi nó đến LLM để có được một giải pháp được đề xuất.

Bảng 8 cho thấy một ví dụ về lời nhắc được sử dụng trong giai đoạn ngoại tuyến, khi chúng tôi tạo ra một loạt các ứng viên kiến thức. Để hậu-xác thực, chúng tôi sử dụng lời nhắc giống như giai đoạn trực tuyến (ví dụ trong Bảng 7).

--- TRANG 13 ---
Lời nhắc
Mô tả không gian
Đây là một số tập dữ liệu phân loại cùng với các cấu hình siêu tham số tốt nhất để huấn luyện một mô hình R language "Learner mlr.classif.svm from package(s) e1071" trên chúng.

Minh chứng
Tập dữ liệu: Tên tập dữ liệu là "ada_agnostic". Nó chứa 2 lớp, 4562 instances, 49 đặc trưng, 48 đặc trưng số, 1 đặc trưng phân loại. Kích thước lớp đa số là 3430 và kích thước lớp thiểu số là 1132.
Cấu hình 1: cost rất nhỏ. kernel là linear.
Cấu hình 2: cost rất nhỏ. kernel là linear.
Cấu hình 3: cost rất nhỏ. kernel là linear.

Tập dữ liệu: Tên tập dữ liệu là "credit-g". Nó chứa 2 lớp, 1000 instances, 21 đặc trưng, 7 đặc trưng số, 14 đặc trưng phân loại. Kích thước lớp đa số là 700 và kích thước lớp thiểu số là 300.
Cấu hình 1: cost trung bình. gamma nhỏ. kernel là radial.
Cấu hình 2: cost trung bình. gamma rất nhỏ. kernel là radial.
Cấu hình 3: cost trung bình. gamma nhỏ. kernel là radial.

Tập dữ liệu: Tên tập dữ liệu là "ozone-level-8hr". Nó chứa 2 lớp, 2534 instances, 73 đặc trưng, 72 đặc trưng số, 1 đặc trưng phân loại. Kích thước lớp đa số là 2374 và kích thước lớp thiểu số là 160.
Cấu hình 1: cost nhỏ. gamma nhỏ. kernel là radial.
Cấu hình 2: cost rất nhỏ. gamma nhỏ. kernel là radial.
Cấu hình 3: cost nhỏ. gamma nhỏ. kernel là radial.

Kiến thức
Hướng dẫn:
1. Đối với tập dữ liệu có nhiều đặc trưng số, giá trị cost lớn hơn và giá trị gamma nhỏ hơn có xu hướng hiệu quả hơn.
2. Đối với tập dữ liệu có nhiều đặc trưng phân loại, kernel linear có xu hướng hiệu quả hơn.
3. Đối với tập dữ liệu có ít đặc trưng số, giá trị cost nhỏ và giá trị gamma lớn hơn có xu hướng hiệu quả hơn.
4. Đối với tập dữ liệu có ít đặc trưng phân loại, kernel polynomial có xu hướng hiệu quả hơn.

Hướng dẫn
Dựa trên các ví dụ và hướng dẫn trên, đề xuất 3 cấu hình siêu tham số cho một tập dữ liệu phân loại mới

Mô tả cho nhiệm vụ mới
Tập dữ liệu: Tên tập dữ liệu là "gina_agnostic". Nó chứa 2 lớp, 3468 instances, 971 đặc trưng, 970 đặc trưng số, 1 đặc trưng phân loại. Kích thước lớp đa số là 1763 và kích thước lớp thiểu số là 1705.

Bảng 7: Ví dụ lời nhắc cho HPO-B trong phục vụ trực tuyến.

Lời nhắc
Mô tả không gian
Đây là một số tập dữ liệu phân loại cùng với các cấu hình siêu tham số tốt nhất để huấn luyện một mô hình R language "Learner mlr.classif.svm from package(s) e1071" trên chúng.

Minh chứng
Tập dữ liệu: Tên tập dữ liệu là "wilt". Nó chứa 2 lớp, 4839 instances, 6 đặc trưng, 5 đặc trưng số, 1 đặc trưng phân loại. Kích thước lớp đa số là 4578 và kích thước lớp thiểu số là 261.
Cấu hình 1: cost trung bình. gamma lớn. kernel là radial.
Cấu hình 2: cost trung bình. gamma trung bình. kernel là radial.
Cấu hình 3: cost lớn. gamma trung bình. kernel là radial.

Tập dữ liệu: Tên tập dữ liệu là "ilpd". Nó chứa 2 lớp, 583 instances, 11 đặc trưng, 9 đặc trưng số, 2 đặc trưng phân loại. Kích thước lớp đa số là 416 và kích thước lớp thiểu số là 167.
Cấu hình 1: cost trung bình. gamma trung bình. kernel là radial.
Cấu hình 2: cost rất nhỏ. gamma rất lớn. kernel là radial.
Cấu hình 3: cost trung bình. gamma rất lớn. kernel là radial.

Tập dữ liệu: Tên tập dữ liệu là "steel-plates-fault". Nó chứa 2 lớp, 1941 instances, 34 đặc trưng, 33 đặc trưng số, 1 đặc trưng phân loại. Kích thước lớp đa số là 1268 và kích thước lớp thiểu số là 673.
Cấu hình 1: cost nhỏ. kernel là linear.
Cấu hình 2: cost rất nhỏ. kernel là linear.
Cấu hình 3: cost rất nhỏ. kernel là linear.

Hướng dẫn
Q: Từ các ví dụ trên, chúng ta có thể quan sát những mô hình nào về mối quan hệ giữa đặc điểm tập dữ liệu và các cấu hình siêu tham số tốt nhất? Câu trả lời PHẢI ngắn gọn, quan trọng, từng điểm, từng dòng, và ngắn gọn. Chỉ bao gồm các quan sát liên quan mà không cần giải thích không cần thiết.

Bảng 8: Ví dụ lời nhắc cho HPO-B trong giai đoạn ngoại tuyến.

--- TRANG 14 ---
Bảng 9: So sánh các định dạng mô tả khác nhau.
Định dạng Mô tả HPO-B ↑ PD1 ↑ HyperFD ↓
Gốc 81.59 ±0.94 1.48±0.06 59.74±1.89
Rút gọn 79.66 ±0.06 1.52±0.01 57.33±3.21
Ẩn danh 77.43 ±0.04 1.21±0.06 68.42±10.01
Tên gây hiểu lầm 75.80 ±3.01 1.43±0.05 62.52±3.92

/uni00000014/uni00000013/uni00000013/uni00000013 /uni00000015/uni00000013/uni00000013/uni00000013 /uni00000016/uni00000013/uni00000013/uni00000013
/uni00000006/uni00000003/uni00000037/uni00000052/uni0000004e/uni00000048/uni00000051/uni00000056/uni00000019/uni00000013/uni0000001a/uni00000013/uni0000001b/uni00000013/uni00000051/uni00000024/uni00000046/uni00000046/uni00000023/uni00000014
/uni00000006/uni00000003/uni00000036/uni00000052/uni0000004f/uni00000056/uni00000003/uni00000012/uni00000003/uni00000057/uni00000044/uni00000056/uni0000004e
/uni00000014
/uni00000016
/uni00000018

(a) HPO-B (cao hơn tốt hơn).

1000 2000 3000
# Tokens1.11.21.31.41.51.6nAcc@1
# Sols / task
1
3
5 (b) PD1 (cao hơn tốt hơn).

1000 2000 3000
# Tokens6080100Rank@1
# Sols / task
1
3
5 (c) HyperFD (thấp hơn tốt hơn).

Hình 3: Ảnh hưởng của số lượng kinh nghiệm và số lượng giải pháp được minh chứng cho mỗi nhiệm vụ.

D Tính mạnh mẽ của MLCopilot
D.1 Mô tả nhiệm vụ trong thực tế.
Khi MLCopilot được triển khai, có thể không thực tế khi yêu cầu người dùng tuân thủ nghiêm ngặt một định dạng cụ thể khi viết mô tả nhiệm vụ. Chúng ta phải xem xét liệu MLCopilot có đủ mạnh mẽ để xử lý các định dạng khác nhau hay không. Để mô phỏng các định dạng đa dạng, chúng tôi yêu cầu GPT-3.5 viết lại các mô tả bằng cách: (i) rút gọn các mô tả nhiệm vụ gốc; và (ii) ẩn danh các mô tả bằng cách loại bỏ tên nhiệm vụ. Kết quả được thể hiện trong Bảng 9. Chúng tôi quan sát thấy sự biến động trong hiệu suất khi định dạng mô tả thay đổi, cho thấy LLM nhạy cảm với định dạng lời nhắc. Điều này phù hợp với các nghiên cứu trước đó (Webson và Pavlick, 2022; Lu et al., 2022) cho rằng LLM có thể không diễn giải đầu vào theo cách giống như con người. Hiệu suất đặc biệt tệ hơn khi các nhiệm vụ được ẩn danh, dẫn chúng tôi đến giả thuyết rằng tên nhiệm vụ kích thích các nơ-ron trong LLM quan trọng để giải quyết các nhiệm vụ liên quan và cũng tận dụng kiến thức trước đó đã được ghi nhớ từ corpus huấn luyện của LLM. Để xác minh thêm điều này, chúng tôi đã thực hiện một thí nghiệm bổ sung bằng cách hoán đổi ngẫu nhiên tên nhiệm vụ giữa các nhiệm vụ, và thật ngạc nhiên quan sát thấy cải thiện hiệu suất trên PD1 và HyperFD. Điều này lặp lại phát hiện trong (Min et al., 2022), cho rằng "nhãn ngẫu nhiên tốt hơn không có nhãn gì cả".

D.2 Độ dài của lời nhắc.
Chúng tôi nghiên cứu ảnh hưởng của độ dài lời nhắc, chủ yếu bị ảnh hưởng bởi số lượng kinh nghiệm ML được truy xuất như minh chứng, đến hiệu suất. Trong các thí nghiệm trước đó của chúng tôi, chúng tôi truy xuất càng nhiều kinh nghiệm càng tốt, hoặc cho đến khi tất cả các kinh nghiệm đã được truy xuất hoặc độ dài lời nhắc tối đa được đạt đến. Đối với mỗi nhiệm vụ, ba giải pháp tốt nhất được minh chứng, đây là một lựa chọn tùy ý trong các thí nghiệm sớm của chúng tôi. Trong phần này, chúng tôi thay đổi hai yếu tố này. Như thể hiện trong Hình 3, hiệu suất thường cải thiện khi số lượng minh chứng trong lời nhắc tăng lên, được đo bằng token lời nhắc. Tuy nhiên, hiệu suất sớm bão hòa ở khoảng 1.5k token và biến động. Hơn nữa, việc minh chứng nhiều giải pháp hơn cho mỗi nhiệm vụ tận dụng nhiều dữ liệu hơn và có tiềm năng cao hơn, đặc biệt là trên 3k token.

D.3 Lựa chọn LLM.
Chúng tôi báo cáo hiệu suất của MLCopilot nếu được trang bị LLM khác ngoài GPT-3.5 (tên mã "text-davinci-003") được sử dụng trong các thí nghiệm chính của chúng tôi. Các mô hình chúng tôi đã thử nghiệm bao gồm:

--- TRANG 15 ---
Phương pháp (với LLM) HPO-B ↑ PD1 ↑ HyperFD ↓
ASKL 77.01 ±0.00 1.26±0.00 92.58±0.00
FLAML 77.84 ±0.00 1.28±0.00 66.42±0.00
MLCopilot (gpt-3.5-turbo) 81.67 ±1.99 1.37±0.10 72.41±10.48
MLCopilot (text-davinci-001) 82.13 ±2.05 1.58±0.04 71.25±10.70
MLCopilot (LLAMA-7B) 79.51 ±0.57 1.43±0.08 67.47±5.60
MLCopilot (text-davinci-003) 81.59 ±0.94 1.48±0.06 59.74±1.89

Bảng 10: Hiệu suất của MLCopilot được trang bị các LLM khác nhau.

• GPT-3.5 Turbo7: một phiên bản tiết kiệm chi phí của GPT-3.5 sử dụng chat completion làm giao diện người dùng.
• GPT-3 (Brown et al., 2020) (tên mã "text-davinci-001"): mô hình GPT-3 gốc được huấn luyện mà không có instruction finetuning.
• LLAMA-7B (Touvron et al., 2023): một mô hình mã nguồn mở nổi tiếng với cộng đồng người dùng lớn, với yêu cầu tương đối lỏng lẻo về bộ nhớ GPU.

Chúng tôi so sánh kết quả với kết quả gốc với text-davinci-003 (GPT-3.5) và các baseline chính của chúng tôi. Như thể hiện trong Bảng 10, MLCopilot mạnh mẽ đối với lựa chọn LLM. Nó tương thích với tất cả các LLM chúng tôi đã thử nghiệm và đạt kết quả cạnh tranh dưới các thiết lập khác nhau. Ngoài ra, chúng tôi thấy xu hướng rằng khi làm việc với các mô hình mạnh hơn và lớn hơn, MLCopilot vẫn đạt kết quả thậm chí tốt hơn.

D.4 Độ chính xác nhiễu và chuẩn hóa có lỗi.

Phương pháp w/ dữ liệu gốc w/ dữ liệu nhiễu
FLAML 77.84 ±0.00 73.53±0.00
MLCopilot 81.59 ±0.94 78.54±3.25

Bảng 11: Tác động của nhiễu trong độ chính xác.

Phương pháp nAcc
MLCopilot (gốc) 81.59 ±0.94
MLCopilot (chuẩn hóa có lỗi) 77.11 ±1.77
FLAML 77.84 ±0.00

Bảng 12: Ảnh hưởng của chuẩn hóa có lỗi.

Chúng tôi thảo luận các trường hợp nơi nhóm kinh nghiệm bị ô nhiễm trong quá trình vận hành hệ thống. Chúng tôi đã đánh giá tính mạnh mẽ dưới các tình huống như vậy trên HPO-B (không gian giải pháp lớn nhất).

Đầu tiên, chúng tôi đánh giá tác động của nhiễu trong độ chính xác, bằng cách làm nhiễu các độ chính xác trong dữ liệu lịch sử. Chúng tôi thêm nhiễu Gaussian vào các giá trị độ chính xác. Độ lệch chuẩn của nhiễu Gaussian là 10% của phân phối độ chính xác. Kết quả của sự nhiễu loạn như vậy, các cấu hình không tối ưu có thể xuất hiện như các cấu hình tốt nhất và phục vụ như minh chứng trong lời nhắc. Sau khi thí nghiệm trên HPO-B, chúng tôi thấy (trong Bảng 11) rằng MLCopilot thực sự chịu đựng từ sự nhiễu loạn như vậy (hiệu suất giảm từ 81.59 xuống 78.54). Tuy nhiên, kết quả như vậy vẫn cạnh tranh với các baseline hiện đại (FLAML 77.84). Hơn nữa, nếu một sự nhiễu loạn tương tự được thực hiện với dữ liệu đầu vào của FLAML, hiệu suất của nó giảm thêm xuống 73.53. Kết quả đầy đủ (độ chính xác chuẩn hóa top-1) được thể hiện trong bảng dưới đây.

Thứ hai, chúng tôi điều tra ảnh hưởng của chuẩn hóa có lỗi. Trong bài báo của chúng tôi, chúng tôi đã cho thấy (trong Bảng 6) rằng chuẩn hóa là một thành phần quan trọng của MLCopilot, và một chuẩn hóa được cấu hình sai có thể dẫn đến hiệu suất suy giảm. Theo đề xuất của bạn, chúng tôi đã giới thiệu nhiễu ngẫu nhiên vào quá trình chuẩn hóa bằng cách thay thế 10% dữ liệu được chuẩn hóa bằng các giá trị rời rạc ngẫu nhiên. Tức là, mỗi tham số của cấu hình có 10% xác suất được thay thế bằng một lựa chọn ngẫu nhiên từ "rất thấp", "thấp", "trung bình", "cao", "rất cao". Chúng tôi cho thấy kết quả (độ chính xác chuẩn hóa top-1 trên HPO-B) trong Bảng 12.

Mặc dù kết quả vẫn cạnh tranh với baseline FLAML, chúng ta có thể thấy rằng chuẩn hóa có lỗi thực sự dẫn đến hiệu suất tệ hơn. Đáng chú ý, tác động thậm chí nghiêm trọng hơn so với thiết lập độ chính xác nhiễu. Chúng tôi suy đoán rằng chuẩn hóa sai có thể đặc biệt gây hiểu lầm cho lý luận logic của các mô hình ngôn ngữ lớn. Chúng tôi sẽ bao gồm một thảo luận về những phát hiện này trong việc sửa đổi của chúng tôi.

7https://openai.com/blog/introducing-chatgpt-and-whisper-apis

--- TRANG 16 ---
E Kiến thức
Tất cả nội dung trong phần này được tạo ra bởi Các Mô Hình Ngôn Ngữ Lớn.

E.1 HPO-B
HPO-B chứa 16 không gian thiết kế. Chúng tôi hoàn thiện một tập kiến thức cho mỗi không gian.

Không gian: 5860
1. Nói chung, các tập dữ liệu có nhiều đặc trưng số hơn đòi hỏi alpha lớn hơn và lambda nhỏ hơn để có hiệu suất tốt hơn.
2. Các tập dữ liệu có tỷ lệ cao hơn giữa kích thước lớp thiểu số và đa số đòi hỏi alpha nhỏ hơn và lambda lớn hơn để có hiệu suất tốt hơn.
3. Các tập dữ liệu có nhiều đặc trưng hơn đòi hỏi alpha lớn hơn và lambda nhỏ hơn để có hiệu suất tốt hơn.
4. Các tập dữ liệu có nhiều đặc trưng phân loại hơn đòi hỏi alpha lớn hơn và lambda lớn hơn để có hiệu suất tốt hơn.

Không gian: 4796
1. Đối với các tập dữ liệu có kích thước lớp đa số lớn và kích thước lớp thiểu số nhỏ, cp lớn hơn và kích thước minbucket có xu hướng là cấu hình siêu tham số tốt hơn.
2. Đối với các tập dữ liệu có kích thước lớp đa số nhỏ và kích thước lớp thiểu số lớn, cp nhỏ hơn và kích thước minbucket có xu hướng là cấu hình siêu tham số tốt hơn.
3. Đối với các tập dữ liệu có số lượng lớn đặc trưng số, cp lớn hơn và kích thước minbucket có xu hướng là cấu hình siêu tham số tốt hơn.
4. Đối với các tập dữ liệu có số lượng nhỏ đặc trưng số, cp nhỏ hơn và kích thước minbucket có xu hướng là cấu hình siêu tham số tốt hơn.
5. Đối với các tập dữ liệu có số lượng lớn đặc trưng phân loại, cp nhỏ hơn và kích thước minbucket có xu hướng là cấu hình siêu tham số tốt hơn.
6. Đối với các tập dữ liệu có số lượng nhỏ đặc trưng phân loại, cp lớn hơn và kích thước minbucket có xu hướng là cấu hình siêu tham số tốt hơn.

Không gian: 5971
1. Nói chung, các tập dữ liệu lớn hơn đòi hỏi nrounds cao hơn và giá trị subsample lớn hơn.
2. Kích thước lớp đa số và kích thước lớp thiểu số của tập dữ liệu có thể ảnh hưởng đến cấu hình của alpha, booster, colsample bylevel, colsample bytree, eta, lambda, max depth, min child weight, nrounds, và subsample.
3. Số lượng đặc trưng số và phân loại trong tập dữ liệu có thể xác định booster được sử dụng.
4. Kích thước của tập dữ liệu có thể ảnh hưởng đến cấu hình của eta, lambda, max depth, min child weight, nrounds, và subsample.
5. Kích thước của lớp thiểu số có thể xác định cấu hình của alpha, colsample bylevel, colsample bytree, eta, lambda, max depth, min child weight, nrounds, và subsample.

--- TRANG 17 ---
Không gian: 6766
1. Đối với các tập dữ liệu có kích thước lớp đa số lớn hơn, giá trị alpha cao và giá trị lambda thấp có xu hướng hoạt động tốt hơn.
2. Đối với các tập dữ liệu có kích thước lớp đa số nhỏ hơn, giá trị alpha thấp và giá trị lambda cao có xu hướng hoạt động tốt hơn.
3. Đối với các tập dữ liệu có nhiều đặc trưng số hơn, giá trị alpha trung bình và giá trị lambda thấp có xu hướng hoạt động tốt hơn.
4. Đối với các tập dữ liệu có nhiều đặc trưng phân loại hơn, giá trị alpha cao và giá trị lambda lớn có xu hướng hoạt động tốt hơn.
5. Đối với các tập dữ liệu có số lượng đặc trưng lớn hơn, giá trị alpha cao và giá trị lambda lớn có xu hướng hoạt động tốt hơn.

Không gian: 5965
1. Kích thước lớp đa số càng lớn, min node size và sample fraction có xu hướng càng nhỏ.
2. Kích thước lớp thiểu số càng lớn, min node size và sample fraction có xu hướng càng lớn.
3. Số lượng đặc trưng càng lớn, mtry có xu hướng càng lớn.
4. Số lượng đặc trưng số càng lớn, mtry có xu hướng càng lớn.
5. Số lượng đặc trưng phân loại càng lớn, mtry có xu hướng càng nhỏ.
6. Số lượng cây càng lớn, mtry có xu hướng càng nhỏ.
7. Số lượng instances càng lớn, sample fraction có xu hướng càng lớn.
8. Tham số replace thường được đặt thành True.
9. Tham số respect unordered factors thường được đặt thành False.

Không gian: 5906
1. Các tập dữ liệu nhỏ hơn có xu hướng có giá trị alpha và eta nhỏ hơn, trong khi các tập dữ liệu lớn hơn có xu hướng có giá trị lớn hơn.
2. Các tập dữ liệu có nhiều đặc trưng hơn có xu hướng có giá trị colsample bylevel và colsample bytree lớn hơn, trong khi các tập dữ liệu có ít đặc trưng hơn có xu hướng có giá trị nhỏ hơn.
3. Các tập dữ liệu có nhiều đặc trưng số hơn có xu hướng có giá trị lambda và max depth lớn hơn, trong khi các tập dữ liệu có ít đặc trưng số hơn có xu hướng có giá trị nhỏ hơn.
4. Các tập dữ liệu nhỏ hơn có xu hướng có giá trị nrounds và subsample nhỏ hơn, trong khi các tập dữ liệu lớn hơn có xu hướng có giá trị lớn hơn.
5. Các tập dữ liệu có nhiều đặc trưng phân loại hơn có xu hướng có giá trị min child weight nhỏ hơn, trong khi các tập dữ liệu có ít đặc trưng phân loại hơn có xu hướng có giá trị lớn hơn.

Không gian: 7607
1. Min node size thường giảm khi kích thước tập dữ liệu tăng.
2. Mtry thường nhỏ đối với các tập dữ liệu có ít đặc trưng và lớn đối với các tập dữ liệu có nhiều đặc trưng.
3. Num trees thường nhỏ đối với các tập dữ liệu có ít instances và lớn đối với các tập dữ liệu có nhiều instances.
4. Replace thường được đặt thành False đối với các tập dữ liệu nhỏ và True đối với

--- TRANG 18 ---
các tập dữ liệu lớn.
5. Respect unordered factors thường được đặt thành False đối với các tập dữ liệu có ít đặc trưng phân loại và True đối với các tập dữ liệu có nhiều đặc trưng phân loại.
6. Sample fraction thường được đặt nhỏ đối với các tập dữ liệu có ít instances và lớn đối với các tập dữ liệu có nhiều instances.

Không gian: 6794
1. Đối với các tập dữ liệu có kích thước lớp đa số lớn, các giá trị min node size và sample fraction lớn hơn thường được sử dụng, trong khi đối với các tập dữ liệu có kích thước lớp đa số nhỏ hơn, các giá trị min node size và sample fraction nhỏ hơn thường được sử dụng.
2. Đối với các tập dữ liệu có nhiều đặc trưng hơn, các giá trị mtry lớn hơn thường được sử dụng.
3. Đối với các tập dữ liệu có nhiều đặc trưng số hơn, replace thường được đặt thành True, trong khi đối với các tập dữ liệu có nhiều đặc trưng phân loại hơn, replace thường được đặt thành False.
4. Respect unordered factors thường được đặt thành True khi tập dữ liệu có nhiều đặc trưng phân loại hơn.

Không gian: 7609
1. Đối với các tập dữ liệu có nhiều đặc trưng hơn, các giá trị mtry lớn hơn được ưa thích.
2. Đối với các tập dữ liệu có nhiều instances hơn, các sample fraction lớn hơn được ưa thích.
3. Đối với các tập dữ liệu có nhiều instances lớp đa số hơn, các min node size nhỏ hơn được ưa thích.
4. Đối với các tập dữ liệu có nhiều đặc trưng số hơn, replace thường được đặt thành True.
5. Đối với các tập dữ liệu có nhiều đặc trưng phân loại hơn, respect unordered factors thường được đặt thành False.
6. Đối với các tập dữ liệu có kích thước lớp cân bằng hơn, num trees thường được đặt thành một giá trị nhỏ hơn.

Không gian: 5859
1. Các tập dữ liệu lớn hơn có xu hướng đòi hỏi giá trị cp nhỏ hơn và giá trị minbucket lớn hơn.
2. Các tập dữ liệu nhỏ hơn có xu hướng đòi hỏi giá trị cp lớn hơn và giá trị minbucket nhỏ hơn.
3. Đối với các tập dữ liệu lớn hơn, maxdepth có xu hướng rất lớn hoặc trung bình, trong khi đối với các tập dữ liệu nhỏ hơn, maxdepth có xu hướng rất nhỏ hoặc nhỏ.
4. Đối với các tập dữ liệu lớn hơn, minsplit có xu hướng rất lớn hoặc lớn, trong khi đối với các tập dữ liệu nhỏ hơn, minsplit có xu hướng rất nhỏ hoặc nhỏ.

Không gian: 5889
1. Kích thước tập dữ liệu càng lớn, mtry và num trees càng lớn, và sample fraction càng nhỏ.
2. Kích thước lớp đa số càng lớn, mtry và num trees càng lớn, và sample fraction càng nhỏ.

--- TRANG 19 ---
3. Số lượng đặc trưng càng nhỏ, mtry và num trees càng nhỏ, và sample fraction càng lớn.
4. Càng nhiều đặc trưng số, mtry và num trees càng lớn, và sample fraction càng nhỏ.
5. Càng nhiều đặc trưng phân loại, mtry và num trees càng nhỏ, và sample fraction càng lớn.
6. Tham số replace thường được đặt thành True.

Không gian: 6767
1. Các tập dữ liệu có kích thước lớp đa số lớn hơn có xu hướng đòi hỏi nrounds lớn hơn và giá trị subsample lớn hơn.
2. Các tập dữ liệu có nhiều đặc trưng số hơn có xu hướng đòi hỏi giá trị colsample bylevel và colsample bytree lớn hơn.
3. Các tập dữ liệu có nhiều đặc trưng phân loại hơn có xu hướng đòi hỏi giá trị min child weight nhỏ hơn.
4. Các tập dữ liệu có kích thước lớp thiểu số nhỏ hơn có xu hướng đòi hỏi giá trị eta và lambda nhỏ hơn.
5. Các tập dữ liệu có nhiều đặc trưng hơn có xu hướng đòi hỏi giá trị max depth lớn hơn.

Không gian: 5970
1. Đối với các tập dữ liệu có nhiều đặc trưng số hơn, giá trị alpha nhỏ hơn và giá trị lambda nhỏ hơn có xu hướng là cấu hình siêu tham số tốt nhất.
2. Đối với các tập dữ liệu có nhiều đặc trưng phân loại hơn, giá trị alpha lớn hơn và giá trị lambda lớn hơn có xu hướng là cấu hình siêu tham số tốt nhất.
3. Đối với các tập dữ liệu có kích thước lớp đa số lớn hơn đáng kể so với kích thước lớp thiểu số, giá trị alpha lớn hơn và giá trị lambda lớn hơn có xu hướng là cấu hình siêu tham số tốt nhất.

Không gian: 5527
1. Tham số cost có xu hướng tăng khi kích thước tập dữ liệu tăng.
2. Tham số gamma có xu hướng giảm khi số lượng đặc trưng số tăng.
3. Tham số kernel có xu hướng là radial đối với các tập dữ liệu có đặc trưng số, và polynomial hoặc linear đối với các tập dữ liệu có đặc trưng phân loại.
4. Tham số degree có xu hướng tăng khi số lượng đặc trưng phân loại tăng.

Không gian: 5636
1. Kích thước lớp đa số càng lớn, giá trị cp nên càng nhỏ.
2. Kích thước lớp thiểu số càng lớn, giá trị cp nên càng lớn.
3. Số lượng đặc trưng càng lớn, giá trị maxdepth nên càng nhỏ.
4. Số lượng đặc trưng số càng lớn, giá trị minbucket nên càng lớn.
5. Số lượng đặc trưng phân loại càng lớn, giá trị minbucket nên càng nhỏ.

--- TRANG 20 ---
6. Số lượng instances càng lớn, giá trị minsplit nên càng lớn.

Không gian: 5891
1. Đối với các tập dữ liệu có nhiều đặc trưng số, giá trị cost lớn hơn và giá trị gamma nhỏ hơn có xu hướng hiệu quả hơn.
2. Đối với các tập dữ liệu có nhiều đặc trưng phân loại, kernel linear có xu hướng hiệu quả hơn.
3. Đối với các tập dữ liệu có ít đặc trưng số, giá trị cost nhỏ và giá trị gamma lớn hơn có xu hướng hiệu quả hơn.
4. Đối với các tập dữ liệu có ít đặc trưng phân loại, kernel polynomial có xu hướng hiệu quả hơn.

E.2 PD1
Chúng tôi đã thực hiện đánh giá leave-one-out trên điểm chuẩn PD1, bao gồm 23 nhiệm vụ. Tuy nhiên, một số nhiệm vụ đang sử dụng cùng mô hình và tập dữ liệu nhưng chỉ khác nhau về batch size. Những nhiệm vụ này không nên xuất hiện trong nhiệm vụ huấn luyện và nhiệm vụ kiểm tra cùng một lúc (Wang et al., 2021b). Do đó, chỉ có 13 tập các nhiệm vụ huấn luyện riêng biệt có sẵn để kiểm tra. Đối với mỗi tập các nhiệm vụ huấn luyện, chúng tôi đã tạo ra một tập kiến thức tương ứng, được trình bày dưới đây.

Nhiệm vụ kiểm tra: CIFAR100, Wide ResNet
1. Đặt tốc độ học ban đầu (LR) theo kích thước của tập dữ liệu và độ phức tạp của mô hình.
2. Đặt tham số momentum thành giá trị thấp hơn cho các tập dữ liệu lớn hơn và giá trị cao hơn cho các mô hình đơn giản hơn.
3. Đặt tham số power thành giá trị cao hơn cho các mô hình phức tạp hơn.
4. Đặt tham số lambda thành giá trị cao hơn cho các mô hình phức tạp hơn và giá trị thấp hơn cho các mô hình đơn giản hơn.

Nhiệm vụ kiểm tra: CIFAR10, Wide ResNet
1. Điều chỉnh tốc độ học ban đầu và momentum dựa trên kích thước và độ phức tạp của tập dữ liệu: cao hơn cho các tập dữ liệu lớn và phức tạp, thấp hơn cho các tập dữ liệu nhỏ và đơn giản.
2. Điều chỉnh các tham số power và lambda dựa trên tốc độ mong muốn của quá trình học: power cao hơn và lambda thấp hơn cho học nhanh hơn, power thấp hơn và lambda cao hơn cho học chậm hơn.
3. Xem xét bất kỳ ràng buộc đặc trưng lĩnh vực nào khi cấu hình trình tối ưu hóa, như yêu cầu độ chính xác.

Nhiệm vụ kiểm tra: Fashion-MNIST, Max Pooling CNN với ReLU
1. Đặt tốc độ học ban đầu thành giá trị thấp hoặc trung bình.
2. Đặt momentum thành giá trị cao hoặc trung bình.
3. Đặt power thành giá trị thấp hoặc trung bình.
4. Đặt lambda thành giá trị thấp hoặc trung bình.
5. Điều chỉnh tốc độ học ban đầu, momentum, power, và lambda theo đặc điểm của nhiệm vụ, như kích thước tập dữ liệu, kiến trúc mô hình, và độ phức tạp của nhiệm vụ dự đoán. Ví dụ, đối với các nhiệm vụ có tập dữ liệu lớn hơn, tốc độ học ban đầu cao hơn có thể có lợi, trong khi đối với các nhiệm vụ có tập dữ liệu nhỏ hơn, tốc độ học ban đầu thấp hơn có thể phù hợp hơn.

--- TRANG 21 ---
Tương tự, đối với các nhiệm vụ có mô hình phức tạp hơn, momentum cao hơn có thể có lợi, trong khi đối với các mô hình đơn giản hơn, momentum thấp hơn có thể phù hợp hơn. Ngoài ra, đối với các nhiệm vụ có nhiệm vụ dự đoán phức tạp hơn, power cao hơn có thể có lợi, trong khi đối với các nhiệm vụ đơn giản hơn, power thấp hơn có thể phù hợp hơn. Cuối cùng, đối với các nhiệm vụ có mô hình phức tạp hơn, lambda cao hơn có thể có lợi, trong khi đối với các mô hình đơn giản hơn, lambda thấp hơn có thể phù hợp hơn.

Nhiệm vụ kiểm tra: Fashion-MNIST, Max Pooling CNN với Tanh
1. Chọn LR ban đầu phù hợp với kích thước của tập dữ liệu và độ phức tạp của mô hình.
2. Đặt momentum thành giá trị phù hợp với kích thước của tập dữ liệu và độ phức tạp của mô hình.
3. Đặt tham số power thành giá trị phù hợp với kích thước của tập dữ liệu và độ phức tạp của mô hình.
4. Đặt tham số lambda thành giá trị phù hợp với kích thước của tập dữ liệu và độ phức tạp của mô hình.

Nhiệm vụ kiểm tra: Fashion-MNIST, Simple CNN
1. Đặt tốc độ học ban đầu (LR) thành giá trị phù hợp với kích thước của tập dữ liệu.
2. Đặt momentum thành giá trị phù hợp với kích thước của tập dữ liệu.
3. Đặt tham số power thành giá trị phù hợp với kích thước của tập dữ liệu.
4. Đặt tham số lambda thành giá trị phù hợp với kích thước của tập dữ liệu và mức độ regularization mong muốn.

Nhiệm vụ kiểm tra: ImageNet, ResNet50
1. Đối với các nhiệm vụ có batch size lớn hơn, sử dụng tốc độ học ban đầu cao hơn và momentum cao hơn. Đối với các nhiệm vụ có batch size nhỏ hơn, sử dụng tốc độ học ban đầu thấp hơn và momentum thấp hơn.
2. Đối với các nhiệm vụ có từ vựng lớn hơn, sử dụng giá trị lambda cao hơn. Đối với các nhiệm vụ có từ vựng nhỏ hơn, sử dụng giá trị lambda thấp hơn.
3. Đối với các nhiệm vụ có mô hình phức tạp hơn, sử dụng giá trị power cao hơn. Đối với các nhiệm vụ có mô hình đơn giản hơn, sử dụng giá trị power thấp hơn.

Nhiệm vụ kiểm tra: LM1B, Transformer
1. Đặt tốc độ học ban đầu thành giá trị phù hợp với kích thước và độ phức tạp của tập dữ liệu.
2. Đặt momentum thành giá trị phù hợp với kích thước và độ phức tạp của tập dữ liệu.
3. Đặt tham số power thành giá trị phù hợp với nhiễu và outlier trong tập dữ liệu.
4. Đặt tham số lambda thành giá trị phù hợp với nhiễu và outlier trong tập dữ liệu.

--- TRANG 22 ---
Nhiệm vụ kiểm tra: MNIST, Max Pooling CNN với ReLU
1. Đặt tốc độ học ban đầu thành giá trị thấp hoặc trung bình.
2. Đặt momentum thành giá trị cao hoặc trung bình.
3. Đặt power thành giá trị thấp hoặc trung bình.
4. Đặt lambda thành giá trị thấp hoặc cao.
5. Xem xét đặc điểm của nhiệm vụ, như kích thước tập dữ liệu, kiến trúc mô hình, và độ phức tạp của nhiệm vụ dự đoán, khi điều chỉnh các tham số.
6. Đối với các nhiệm vụ có tập dữ liệu lớn hơn, tốc độ học ban đầu cao hơn và momentum thấp hơn có thể phù hợp hơn.
7. Đối với các tập dữ liệu nhỏ hơn, tốc độ học ban đầu thấp hơn và momentum cao hơn có thể phù hợp hơn.
8. Đối với các nhiệm vụ có mô hình phức tạp hơn, tốc độ học ban đầu cao hơn và momentum thấp hơn có thể phù hợp hơn.
9. Đối với các nhiệm vụ có mô hình đơn giản hơn, tốc độ học ban đầu thấp hơn và momentum cao hơn có thể phù hợp hơn.
10. Đối với các nhiệm vụ có nhiệm vụ dự đoán phức tạp hơn, tốc độ học ban đầu cao hơn và momentum thấp hơn có thể phù hợp hơn.
11. Đối với các nhiệm vụ có nhiệm vụ dự đoán đơn giản hơn, tốc độ học ban đầu thấp hơn và momentum cao hơn có thể phù hợp hơn.

Nhiệm vụ kiểm tra: MNIST, Max Pooling CNN với Tanh
1. Đặt tốc độ học ban đầu thành giá trị cao để đảm bảo rằng mô hình có thể học nhanh chóng và hiệu quả.
2. Đặt momentum thành giá trị thấp để ngăn chặn mô hình khỏi overfitting.
3. Đặt power và/hoặc lambda thành giá trị cao để đảm bảo rằng tốc độ học giảm chậm và mô hình có thể tiếp tục học trong thời gian dài hơn.
4. Đối với các nhiệm vụ như huấn luyện CNN với max-pool và ReLU trên Fashion MNIST, đặt tốc độ học ban đầu thành giá trị thấp để ngăn chặn mô hình khỏi overfitting.
5. Đối với các nhiệm vụ như huấn luyện ResNet50 trên ImageNet, đặt tốc độ học ban đầu thành giá trị cao để đảm bảo rằng mô hình có thể học nhanh chóng và hiệu quả.
6. Đối với các nhiệm vụ như huấn luyện Wide ResNet trên CIFAR100, đặt tốc độ học ban đầu thành giá trị rất cao để đảm bảo rằng mô hình có thể học nhanh chóng và hiệu quả.
7. Đối với các nhiệm vụ như huấn luyện Transformer trên UniRef50, đặt tốc độ học ban đầu thành giá trị thấp để ngăn chặn mô hình khỏi overfitting.

Nhiệm vụ kiểm tra: MNIST, Simple CNN
1. Điều chỉnh tốc độ học ban đầu và momentum theo kích thước và độ phức tạp của tập dữ liệu: cao hơn cho các tập dữ liệu lớn và phức tạp, thấp hơn cho các tập dữ liệu nhỏ và đơn giản.
2. Điều chỉnh các tham số power và lambda theo kích thước và độ phức tạp của tập dữ liệu: cao hơn cho các tập dữ liệu lớn và phức tạp, thấp hơn cho các tập dữ liệu nhỏ và đơn giản.
3. Điều chỉnh tốc độ học ban đầu và momentum theo yêu cầu nhiệm vụ: cao hơn cho các nhiệm vụ đòi hỏi độ chính xác cao, thấp hơn cho các nhiệm vụ đòi hỏi tốc độ cao.

--- TRANG 23 ---
Nhiệm vụ kiểm tra: SVHN, Wide ResNet
1. Đối với các nhiệm vụ phân loại hình ảnh, đặt tốc độ học ban đầu (LR) thành giá trị cao hơn và momentum thành giá trị thấp hơn.
2. Đối với các nhiệm vụ ngôn ngữ, đặt LR ban đầu thành giá trị thấp hơn và momentum thành giá trị cao hơn.
3. Đối với các nhiệm vụ có batch size lớn hơn, đặt LR ban đầu thành giá trị cao hơn và momentum thành giá trị thấp hơn.
4. Đối với các nhiệm vụ có batch size nhỏ hơn, đặt LR ban đầu thành giá trị thấp hơn và momentum thành giá trị cao hơn.
5. Đối với các nhiệm vụ có mô hình phức tạp hơn, đặt power thành giá trị cao hơn và lambda thành giá trị cao hơn.
6. Đối với các nhiệm vụ có mô hình đơn giản hơn, đặt power thành giá trị thấp hơn và lambda thành giá trị thấp hơn.

Nhiệm vụ kiểm tra: UniRef50, Transformer
1. Đặt các giá trị tốc độ học ban đầu, momentum, power, và lambda theo các hướng dẫn sau:
- Đối với batch size lớn hơn và tập dữ liệu lớn hơn, sử dụng tốc độ học cao hơn, momentum cao hơn, power thấp hơn, và lambda cao hơn.
- Đối với batch size nhỏ hơn và tập dữ liệu nhỏ hơn, sử dụng tốc độ học thấp hơn, momentum thấp hơn, power cao hơn, và lambda thấp hơn.
2. Ví dụ:
- Đối với CNN với max-pool và ReLU trên Fashion MNIST với batch size 256, sử dụng tốc độ học ban đầu 0.001, momentum 0.9, power 0.1, và lambda 0.01.
- Đối với Wide ResNet trên CIFAR10 với batch size 2048, sử dụng tốc độ học ban đầu 0.01, momentum 0.9, power 0.5, và lambda 0.001.
- Đối với Transformer trên LM1B với batch size 2048, sử dụng tốc độ học ban đầu 0.001, momentum 0.9, power 0.01, và lambda 0.001.

Nhiệm vụ kiểm tra: WMT15, xformer
1. Đặt tốc độ học ban đầu thành giá trị thấp hoặc trung bình.
2. Đặt momentum thành giá trị cao hoặc trung bình.
3. Đặt power thành giá trị thấp hoặc trung bình.
4. Đặt lambda thành giá trị cao hoặc trung bình.
5. Điều chỉnh tốc độ học ban đầu và momentum dựa trên đặc điểm của nhiệm vụ, như kích thước tập dữ liệu, kiến trúc mô hình, và độ phức tạp của nhiệm vụ dự đoán. Ví dụ, đối với các nhiệm vụ có tập dữ liệu lớn hơn, tốc độ học ban đầu cao hơn và momentum thấp hơn có thể phù hợp hơn, trong khi đối với các nhiệm vụ có tập dữ liệu nhỏ hơn, tốc độ học ban đầu thấp hơn và momentum cao hơn có thể phù hợp hơn. Ngoài ra, đối với các nhiệm vụ có mô hình phức tạp hơn, tốc độ học ban đầu cao hơn và momentum thấp hơn có thể phù hợp hơn, trong khi đối với các nhiệm vụ có mô hình đơn giản hơn, tốc độ học ban đầu thấp hơn và momentum cao hơn có thể phù hợp hơn. Cuối cùng, đối với các nhiệm vụ có nhiệm vụ dự đoán phức tạp hơn, tốc độ học ban đầu cao hơn và momentum thấp hơn có thể phù hợp hơn, trong khi đối với

--- TRANG 24 ---
các nhiệm vụ có nhiệm vụ dự đoán đơn giản hơn, tốc độ học ban đầu thấp hơn và momentum cao hơn có thể phù hợp hơn.

E.3 HyperFD
Tương tự như PD1, đánh giá trên HyperFD cũng là leave-one-out trên 12 nhiệm vụ. Chúng tôi cho thấy 12 tập kiến thức dựa trên lựa chọn nhiệm vụ kiểm tra.

Nhiệm vụ kiểm tra: AFLW
1. Cấu hình kích thước crop và ngưỡng IoU anchor matching dựa trên số lượng khuôn mặt trong tập dữ liệu:
- Đối với các tập dữ liệu có nhiều khuôn mặt hơn, sử dụng kích thước crop lớn hơn và ngưỡng IoU anchor matching cao hơn.
- Đối với các tập dữ liệu có ít khuôn mặt hơn, sử dụng kích thước crop nhỏ hơn và ngưỡng IoU anchor matching thấp hơn.
2. Cấu hình tốc độ học và tỷ lệ negative to positive dựa trên số lượng khuôn mặt trong tập dữ liệu:
- Đối với các tập dữ liệu có nhiều khuôn mặt hơn, sử dụng tốc độ học cao hơn và tỷ lệ negative to positive nhiều hơn.
- Đối với các tập dữ liệu có ít khuôn mặt hơn, sử dụng tốc độ học thấp hơn và tỷ lệ negative to positive ít hơn.
3. Cấu hình trọng số location loss dựa trên sự hiện diện của điểm mốc khuôn mặt trong tập dữ liệu:
- Đối với các tập dữ liệu có điểm mốc khuôn mặt, sử dụng trọng số location loss cao hơn.

Nhiệm vụ kiểm tra: ANIME
1. Đặt kích thước crop và ngưỡng IoU anchor matching theo số lượng khuôn mặt trong tập dữ liệu:
- Đối với các tập dữ liệu có nhiều khuôn mặt hơn, sử dụng kích thước crop lớn hơn và ngưỡng IoU anchor matching cao hơn.
- Đối với các tập dữ liệu có ít khuôn mặt hơn, sử dụng kích thước crop nhỏ hơn và ngưỡng IoU anchor matching thấp hơn.
2. Đặt trọng số location loss theo sự hiện diện của điểm mốc khuôn mặt trong tập dữ liệu:
- Đối với các tập dữ liệu có điểm mốc khuôn mặt, sử dụng trọng số location loss cao hơn.
- Đối với các tập dữ liệu không có điểm mốc khuôn mặt, sử dụng trọng số location loss thấp hơn.
3. Đặt tốc độ học và trình tối ưu hóa theo tỷ lệ negative to positive trong tập dữ liệu:
- Đối với các tập dữ liệu có tỷ lệ negative to positive cao hơn, sử dụng tốc độ học cao hơn và các trình tối ưu hóa như SGD hoặc Adam.

Nhiệm vụ kiểm tra: FaceMask
1. Đặt kích thước crop theo số lượng khuôn mặt trong tập dữ liệu: kích thước crop lớn hơn cho các tập dữ liệu có nhiều khuôn mặt hơn, và kích thước crop nhỏ hơn cho các tập dữ liệu có ít khuôn mặt hơn.
2. Đặt ngưỡng IoU anchor matching theo số lượng khuôn mặt trong tập dữ liệu: ngưỡng cao hơn cho các tập dữ liệu có nhiều khuôn mặt hơn, và ngưỡng thấp hơn cho các tập dữ liệu có ít khuôn mặt hơn.
3. Đặt trọng số location loss theo sự hiện diện của điểm mốc khuôn mặt trong tập dữ liệu: trọng số cao hơn cho các tập dữ liệu có điểm mốc khuôn mặt, và trọng số thấp hơn cho các tập dữ liệu không có điểm mốc khuôn mặt.

--- TRANG 25 ---
4. Đặt tỷ lệ negative to positive theo số lượng khuôn mặt trong tập dữ liệu: tỷ lệ cao hơn cho các tập dữ liệu có nhiều khuôn mặt hơn, và tỷ lệ thấp hơn cho các tập dữ liệu có ít khuôn mặt hơn.
5. Đặt tốc độ học theo số lượng khuôn mặt trong tập dữ liệu: tốc độ cao hơn cho các tập dữ liệu có nhiều khuôn mặt hơn, và tốc độ thấp hơn cho các tập dữ liệu có ít khuôn mặt hơn.

Nhiệm vụ kiểm tra: FDDB
1. Đặt kích thước crop lớn hơn và ngưỡng IoU anchor matching cao hơn cho các tập dữ liệu có nhiều khuôn mặt hơn.
2. Tăng trọng số location loss và giảm tỷ lệ negative to positive cho các tập dữ liệu có nhiều khuôn mặt hơn.
3. Sử dụng tốc độ học thấp hơn và trình tối ưu hóa như Adam hoặc SGD cho các tập dữ liệu có điểm mốc khuôn mặt.

Nhiệm vụ kiểm tra: FDDB-360
1. Đối với các tập dữ liệu có nhiều khuôn mặt hơn, sử dụng kích thước crop lớn hơn và ngưỡng IoU anchor matching cao hơn.
2. Đối với các tập dữ liệu có ít khuôn mặt hơn, sử dụng kích thước crop nhỏ hơn và ngưỡng IoU anchor matching thấp hơn.
3. Đối với các tập dữ liệu không có điểm mốc khuôn mặt, sử dụng trọng số location loss thấp hơn và tỷ lệ negative to positive cao hơn.
4. Đối với các tập dữ liệu có điểm mốc khuôn mặt, sử dụng trọng số location loss cao hơn và tỷ lệ negative to positive thấp hơn.
5. Đối với các tập dữ liệu có nhiều khuôn mặt hơn, sử dụng tốc độ học cao hơn và trình tối ưu hóa SGD.
6. Đối với các tập dữ liệu có ít khuôn mặt hơn, sử dụng tốc độ học thấp hơn và trình tối ưu hóa Adam.

Nhiệm vụ kiểm tra: MAFA
1. Đặt kích thước crop và ngưỡng IoU anchor matching theo số lượng khuôn mặt trên mỗi hình ảnh trong tập dữ liệu: kích thước crop lớn hơn và ngưỡng IoU cao hơn cho các tập dữ liệu có nhiều khuôn mặt trên mỗi hình ảnh hơn, và kích thước crop nhỏ hơn và ngưỡng IoU thấp hơn cho các tập dữ liệu có ít khuôn mặt trên mỗi hình ảnh hơn.
2. Đặt trọng số location loss theo sự hiện diện của điểm mốc khuôn mặt trong tập dữ liệu: trọng số cao hơn cho các tập dữ liệu có điểm mốc khuôn mặt, và trọng số thấp hơn cho các tập dữ liệu không có điểm mốc khuôn mặt.
3. Đặt tỷ lệ negative to positive theo độ khó của tập dữ liệu: tỷ lệ cao hơn cho các tập dữ liệu có tình huống thách thức hơn (ví dụ: suy giảm dựa trên thời tiết, mờ chuyển động, mờ tiêu cự).
4. Đặt tốc độ học và trình tối ưu hóa theo kích thước của tập dữ liệu: tốc độ học thấp hơn và các trình tối ưu hóa như Adam hoặc SGD cho các tập dữ liệu có nhiều hình ảnh hơn.

Nhiệm vụ kiểm tra: PASCAL VOC
1. Đặt kích thước crop theo số lượng khuôn mặt trong tập dữ liệu: kích thước crop lớn hơn cho các tập dữ liệu có nhiều khuôn mặt hơn, và kích thước crop nhỏ hơn cho các tập dữ liệu có ít khuôn mặt hơn.

--- TRANG 26 ---
2. Đặt ngưỡng IoU anchor matching theo số lượng khuôn mặt trong tập dữ liệu: ngưỡng cao hơn cho các tập dữ liệu có nhiều khuôn mặt hơn, và ngưỡng thấp hơn cho các tập dữ liệu có ít khuôn mặt hơn.
3. Đặt trọng số location loss theo sự hiện diện của điểm mốc khuôn mặt trong tập dữ liệu: trọng số thấp hơn cho các tập dữ liệu không có điểm mốc khuôn mặt, và trọng số cao hơn cho các tập dữ liệu có điểm mốc khuôn mặt.
4. Đặt tỷ lệ negative to positive theo số lượng khuôn mặt trong tập dữ liệu: tỷ lệ cao hơn cho các tập dữ liệu có nhiều khuôn mặt hơn, và tỷ lệ thấp hơn cho các tập dữ liệu có ít khuôn mặt hơn.
5. Đặt tốc độ học và trình tối ưu hóa theo độ khó của tập dữ liệu: tốc độ học cao hơn và các trình tối ưu hóa như SGD cho các tập dữ liệu thách thức hơn.

Nhiệm vụ kiểm tra: UFDD
1. Đặt kích thước crop và ngưỡng IoU anchor matching theo số lượng khuôn mặt trong tập dữ liệu: kích thước crop lớn hơn và ngưỡng IoU cao hơn cho các tập dữ liệu có nhiều khuôn mặt hơn, kích thước crop nhỏ hơn và ngưỡng IoU thấp hơn cho các tập dữ liệu có ít khuôn mặt hơn.
2. Đặt trọng số location loss và tỷ lệ negative to positive theo số lượng khuôn mặt trong tập dữ liệu: trọng số location loss cao hơn và tỷ lệ negative to positive cao hơn cho các tập dữ liệu có nhiều khuôn mặt hơn, trọng số location loss thấp hơn và tỷ lệ negative to positive thấp hơn cho các tập dữ liệu có ít khuôn mặt hơn.
3. Đặt tốc độ học và trình tối ưu hóa theo sự hiện diện của điểm mốc khuôn mặt trong tập dữ liệu: tốc độ học thấp hơn và trình tối ưu hóa Adam cho các tập dữ liệu có điểm mốc khuôn mặt, tốc độ học cao hơn và trình tối ưu hóa SGD cho các tập dữ liệu không có điểm mốc khuôn mặt.

Nhiệm vụ kiểm tra: UMDAA-02
1. Đặt kích thước crop theo số lượng khuôn mặt trong tập dữ liệu: kích thước crop lớn hơn cho các tập dữ liệu có nhiều khuôn mặt hơn, và kích thước crop nhỏ hơn cho các tập dữ liệu có ít khuôn mặt hơn.
2. Đặt ngưỡng IoU anchor matching theo số lượng khuôn mặt trong tập dữ liệu: ngưỡng cao hơn cho các tập dữ liệu có nhiều khuôn mặt hơn, và ngưỡng thấp hơn cho các tập dữ liệu có ít khuôn mặt hơn.
3. Đặt trọng số location loss theo sự hiện diện của điểm mốc khuôn mặt trong tập dữ liệu: trọng số cao hơn cho các tập dữ liệu có điểm mốc khuôn mặt, và trọng số thấp hơn cho các tập dữ liệu không có điểm mốc khuôn mặt.
4. Đặt tỷ lệ negative to positive theo số lượng khuôn mặt trong tập dữ liệu: tỷ lệ cao hơn cho các tập dữ liệu có nhiều khuôn mặt hơn, và tỷ lệ thấp hơn cho các tập dữ liệu có ít khuôn mặt hơn.
5. Đặt tốc độ học và trình tối ưu hóa theo độ khó của tập dữ liệu: tốc độ học cao hơn và các trình tối ưu hóa như SGD hoặc Adam cho các tập dữ liệu thách thức hơn.

Nhiệm vụ kiểm tra: WIDER FACE
1. Đặt kích thước crop thành một giá trị tỷ lệ với số lượng khuôn mặt trong tập dữ liệu.
2. Đặt ngưỡng IoU anchor matching thành một giá trị tỷ lệ với số lượng khuôn mặt trong tập dữ liệu.

--- TRANG 27 ---
3. Đặt tỷ lệ negative to positive thành một giá trị tỷ lệ với số lượng khuôn mặt trong tập dữ liệu.
4. Đặt tốc độ học thành một giá trị tỷ lệ với số lượng khuôn mặt trong tập dữ liệu.
5. Nếu tập dữ liệu chứa điểm mốc khuôn mặt, đặt trọng số location loss thành một giá trị tỷ lệ với số lượng khuôn mặt trong tập dữ liệu.

Nhiệm vụ kiểm tra: WIDER-FACE-360
1. Đặt kích thước crop và ngưỡng IoU anchor matching theo số lượng khuôn mặt trong tập dữ liệu: kích thước crop lớn hơn và ngưỡng IoU cao hơn cho các tập dữ liệu có nhiều khuôn mặt hơn, và kích thước crop nhỏ hơn và ngưỡng IoU thấp hơn cho các tập dữ liệu có ít khuôn mặt hơn.
2. Đặt trọng số location loss theo sự hiện diện của điểm mốc khuôn mặt: trọng số cao hơn cho các tập dữ liệu có điểm mốc khuôn mặt, và trọng số thấp hơn cho các tập dữ liệu không có điểm mốc khuôn mặt.
3. Đặt tỷ lệ negative to positive theo số lượng khuôn mặt trong tập dữ liệu: tỷ lệ cao hơn cho các tập dữ liệu có nhiều khuôn mặt hơn, và tỷ lệ thấp hơn cho các tập dữ liệu có ít khuôn mặt hơn.
4. Đặt tốc độ học theo số lượng khuôn mặt trong tập dữ liệu: tốc độ cao hơn cho các tập dữ liệu có nhiều khuôn mặt hơn, và tốc độ thấp hơn cho các tập dữ liệu có ít khuôn mặt hơn.
5. Đặt trình tối ưu hóa theo số lượng khuôn mặt trong tập dữ liệu: SGD cho các tập dữ liệu có nhiều khuôn mặt hơn, và Adam cho các tập dữ liệu có ít khuôn mặt hơn.

Nhiệm vụ kiểm tra: WIKI
1. Đặt kích thước crop thành một giá trị tỷ lệ với số lượng khuôn mặt trong tập dữ liệu.
2. Đặt ngưỡng IoU anchor matching thành một giá trị tỷ lệ với số lượng khuôn mặt trong tập dữ liệu.
3. Đặt trọng số location loss thành một giá trị tỷ lệ với sự hiện diện của điểm mốc khuôn mặt trong tập dữ liệu.
4. Đặt tốc độ học thành một giá trị tỷ lệ nghịch với tỷ lệ negative to positive trong tập dữ liệu.
5. Sử dụng trình tối ưu hóa như Adam hoặc SGD.

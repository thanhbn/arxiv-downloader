# 2103.12424.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/automl-nas/2103.12424.pdf
# Kích thước tệp: 5533096 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
BossNAS: Khám phá CNN-transformer Lai với Tìm kiếm Kiến trúc Mạng Neural Tự giám sát theo Khối
Changlin Li1, Tao Tang2, Guangrun Wang3;4, Jiefeng Peng3, Bing Wang5,
Xiaodan Liang2*, Xiaojun Chang6
1GORSE Lab, Dept. of DSAI, Monash University2Sun Yat-sen University3DarkMatter AI Research
4University of Oxford5Alibaba Group6RMIT University
changlin.li@monash.edu,
ftrent.tangtao,wanggrun,jiefengpeng,xdliang328 g@gmail.com,
fengquan.wb@alibaba-inc.com, xiaojun.chang@rmit.edu.au
Tóm tắt
Vô số đột phá gần đây trong các kiến trúc mạng neural được thiết kế thủ công cho nhận dạng thị giác đã nhấn mạnh nhu cầu cấp thiết khám phá các kiến trúc lai bao gồm các khối xây dựng đa dạng. Trong khi đó, các phương pháp tìm kiếm kiến trúc mạng neural đang gia tăng với kỳ vọng giảm nỗ lực con người. Tuy nhiên, liệu các phương pháp NAS có thể xử lý hiệu quả và hữu hiệu các không gian tìm kiếm đa dạng với các ứng viên khác biệt (ví dụ: CNNs và transformers) vẫn là một câu hỏi mở. Trong công trình này, chúng tôi trình bày Tìm kiếm Kiến trúc Mạng Neural Tự giám sát theo Khối (BossNAS), một phương pháp NAS không giám sát giải quyết vấn đề đánh giá kiến trúc không chính xác gây ra bởi không gian chia sẻ trọng số lớn và giám sát thiên lệch trong các phương pháp trước đây. Cụ thể hơn, chúng tôi phân tách không gian tìm kiếm thành các khối và sử dụng một sơ đồ huấn luyện tự giám sát mới, được gọi là ensemble bootstrapping, để huấn luyện từng khối riêng biệt trước khi tìm kiếm chúng như một tổng thể hướng tới trung tâm quần thể. Ngoài ra, chúng tôi trình bày không gian tìm kiếm HyTra, một không gian tìm kiếm CNN-transformer lai giống như vải với các vị trí lấy mẫu xuống có thể tìm kiếm. Trên không gian tìm kiếm đầy thử thách này, mô hình được tìm kiếm của chúng tôi, BossNet-T, đạt độ chính xác lên tới 82.5% trên ImageNet, vượt trội EfﬁcientNet 2.4% với thời gian tính toán tương đương. Hơn nữa, phương pháp của chúng tôi đạt độ chính xác đánh giá kiến trúc vượt trội với tương quan Spearman 0.78 và 0.76 trên không gian tìm kiếm MBConv chuẩn với ImageNet và trên không gian tìm kiếm kích thước NATS-Bench với CIFAR-100, tương ứng, vượt qua các phương pháp NAS hiện đại.1
1. Giới thiệu
Sự phát triển của các kiến trúc mạng neural đã mang lại tiến bộ đáng kể trong một loạt các tác vụ nhận dạng thị giác trong vài năm qua. Các ví dụ đại diện của những mô hình như vậy bao gồm ResNet [ 25], SENet [ 31], MobileNet [ 30] và EfﬁcientNet [ 64]. Gần đây, các kiến trúc dựa trên attention mới nổi đang xuất hiện ở tuyến đầu trong lĩnh vực thị giác máy tính, thách thức sự thống trị của các mạng neural tích chập (CNNs). Đột phá thú vị này trong vision transformers được dẫn dắt bởi ViT [ 20] và DETR [8], đang đạt hiệu suất cạnh tranh trên các tác vụ thị giác khác nhau, như phân loại hình ảnh [ 20,66,79,14,9], phát hiện đối tượng [ 8,90,62], phân đoạn ngữ nghĩa [ 88], và các tác vụ khác [ 26,50,33]. Như được đề xuất bởi các công trình trước [ 20,62,3], các lai ghép của CNNs và transformers có thể vượt trội cả transformers thuần túy và CNNs thuần túy.
Mặc dù có những tiến bộ lớn mà thiết kế mạng mang lại, việc tìm kiếm thủ công các kiến trúc lai được tối ưu hóa tốt có thể là thách thức, đặc biệt khi số lượng lựa chọn thiết kế tăng lên. Tìm kiếm Kiến trúc Mạng Neural (NAS) là một cách tiếp cận phổ biến để giảm nỗ lực con người trong thiết kế kiến trúc mạng bằng cách tự động tìm kiếm các kiến trúc tối ưu
1arXiv:2103.12424v3  [cs.CV]  19 Aug 2021

--- TRANG 2 ---
kiến trúc trong một không gian tìm kiếm được định nghĩa trước. Thành công đại diện trong việc thực hiện NAS trên các khối xây dựng được thiết kế thủ công bao gồm MobileNetV3 [ 29], EfﬁcientNet [ 64], v.v. Những công trình này được tìm kiếm bởi các phương pháp NAS đa thử [ 63,92,2,89,12,47], vốn rất tốn kém về mặt tính toán (tốn hàng nghìn ngày GPU). Các phương pháp NAS chia sẻ trọng số gần đây [ 6,53,4,43] mã hóa toàn bộ không gian tìm kiếm như một supernet chia sẻ trọng số để tránh huấn luyện lặp lại các mạng ứng viên, do đó giảm đáng kể chi phí tìm kiếm.
Tuy nhiên, như được hiển thị trong Hình 1a, các không gian tìm kiếm kiến trúc với độ chi tiết cấp layer tăng theo cấp số nhân với độ sâu mạng tăng, điều này đã được xác định (trong [37,39]) là nguyên nhân chính của việc đánh giá kiến trúc không chính xác2 trong các phương pháp NAS chia sẻ trọng số. Để giảm kích thước của không gian chia sẻ trọng số lớn, các công trình trước [ 37,46] phân tách không gian tìm kiếm thành các khối và sử dụng một mô hình giáo viên được huấn luyện trước để cung cấp giám sát theo khối (Hình 1b). Mặc dù có tương quan xếp hạng cao và hiệu quả cao, chúng tôi thấy (trong Phần 5) kết quả của chúng có tương quan cao với kiến trúc giáo viên. Như được minh họa trong Hình 1b, khi huấn luyện bởi một giáo viên với các nút màu xanh, các kiến trúc ứng viên với nhiều nút màu xanh hơn có xu hướng nhận được thứ hạng cao hơn trong những phương pháp này. Điều này hạn chế ứng dụng của nó trên các không gian tìm kiếm đa dạng với các ứng viên khác biệt, như CNNs và transformers.
Mặt khác, NAS không giám sát [ 41] gần đây đã nổi lên như một chủ đề nghiên cứu thú vị. Không có quyền truy cập vào bất kỳ nhãn được chú thích bởi con người nào, các phương pháp NAS không giám sát (được tối ưu hóa với các tác vụ pretext [ 41] hoặc nhãn ngẫu nhiên [ 87]) đã được chứng minh có khả năng đạt hiệu suất tương đương với các phương pháp NAS có giám sát. Theo đó, chúng tôi đề xuất sử dụng một phương pháp học không giám sát như một thay thế cho việc chưng cất có giám sát trong sơ đồ NAS theo khối đã đề cập ở trên (Hình 1c), nhằm giải quyết vấn đề thiên lệch kiến trúc gây ra bởi việc sử dụng mô hình giáo viên.
Trong công trình này, chúng tôi đề xuất một phương pháp NAS không giám sát mới, Tìm kiếm Kiến trúc Mạng Neural Tự giám sát theo Khối ( BossNAS ), nhằm giải quyết vấn đề xếp hạng kiến trúc dự đoán không chính xác gây ra bởi không gian chia sẻ trọng số lớn trong khi tránh thiên lệch kiến trúc có thể gây ra bởi việc sử dụng mô hình giáo viên. Trái ngược với các giải pháp theo khối được thảo luận ở trên, sử dụng chưng cất như giám sát trung gian, chúng tôi đề xuất một sơ đồ học biểu diễn tự giám sát được gọi là ensemble bootstrapping để tối ưu hóa từng khối của supernet của chúng tôi. Cụ thể hơn, mỗi sub-network được lấy mẫu được huấn luyện để dự đoán ensemble xác suất của tất cả những cái được lấy mẫu trong mạng đích, giữa các view được tăng cường khác nhau của cùng một hình ảnh. Trong giai đoạn tìm kiếm, một metric đánh giá không giám sát, được đề xuất để đảm bảo công bằng bằng cách tìm kiếm hướng tới trung tâm quần thể kiến trúc. Cụ thể hơn, ensemble xác suất của tất cả các kiến trúc trong quần thể được sử dụng như mục tiêu đánh giá để đo lường hiệu suất của các mô hình được lấy mẫu.
2Trong công trình này, độ chính xác đánh giá kiến trúc đề cập đến tương quan của xếp hạng kiến trúc dự đoán và xếp hạng kiến trúc thực tế.

Ngoài ra, chúng tôi thiết kế một không gian tìm kiếm CNN-transformer lai giống như vải ( HyTra ) với các vị trí lấy mẫu xuống có thể tìm kiếm và sử dụng nó như một nghiên cứu trường hợp cho các kiến trúc lai để đánh giá phương pháp của chúng tôi. Trong mỗi layer của không gian tìm kiếm HyTra, các khối xây dựng CNN và các khối xây dựng transformer với các độ phân giải khác nhau song song và có thể được chọn một cách linh hoạt. Không gian tìm kiếm đa dạng này bao gồm các transformers thuần túy với độ dài nội dung cố định và CNNs bình thường với các quy mô không gian giảm dần một cách tiến bộ.
Chúng tôi chứng minh rằng phương pháp NAS của chúng tôi có thể tổng quát hóa tốt trên ba không gian tìm kiếm khác nhau và ba tập dữ liệu. Trên không gian tìm kiếm HyTra, các mô hình được tìm kiếm của chúng tôi vượt trội so với những cái được tìm kiếm bởi đối tác NAS có giám sát của chúng tôi [ 37], chứng minh rằng phương pháp của chúng tôi thành công tránh thiên lệch kiến trúc có thể mang lại bởi chưng cất có giám sát. Phương pháp của chúng tôi đạt độ chính xác đánh giá kiến trúc vượt trội với tương quan Spearman 0.78 và 0.76 trên không gian tìm kiếm MBConv chuẩn với ImageNet và trên không gian tìm kiếm kích thước NATS-Bench SS[17] với CIFAR-100, tương ứng, vượt qua các phương pháp NAS hiện đại, chứng minh rằng phương pháp của chúng tôi thành công ngăn chặn vấn đề đánh giá kiến trúc không chính xác gây ra bởi không gian chia sẻ trọng số lớn.
Các mô hình được tìm kiếm của chúng tôi trên không gian tìm kiếm HyTra đạt độ chính xác 82.5% trên ImageNet, vượt trội EfﬁcientNet [ 64] 2.4%, với thời gian tính toán tương đương3. Bằng cách cung cấp kết quả mạnh mẽ thông qua BossNet-T, chúng tôi hy vọng rằng không gian tìm kiếm HyTra đa dạng này với các ứng viên khác biệt và các kiến trúc hiệu suất cao có thể phục vụ như một đấu trường mới cho các công trình NAS tương lai. Chúng tôi cũng hy vọng rằng BossNAS của chúng tôi có thể phục vụ như một công cụ được sử dụng rộng rãi cho thiết kế kiến trúc lai.
2. Công trình Liên quan
NAS chia sẻ trọng số theo khối [37,46,84,85] các cách tiếp cận phân tách supernet thành các khối được tối ưu hóa độc lập và do đó giảm không gian chia sẻ trọng số, giải quyết vấn đề đánh giá kiến trúc không chính xác gây ra bởi chia sẻ trọng số. DNA [ 37] đầu tiên giới thiệu sơ đồ đánh giá kiến trúc có giám sát theo khối với chưng cất kiến thức. Dựa trên sơ đồ này, DONNA [ 46] tiếp tục đề xuất dự đoán một đánh giá kiến trúc bằng cách sử dụng một tổ hợp tuyến tính của các đánh giá theo khối thay vì một tổng đơn giản. SP [ 84] là những người đầu tiên áp dụng sơ đồ này cho việc cắt tỉa mạng. Tuy nhiên, tất cả các phương pháp đã đề cập ở trên đều dựa vào một sơ đồ chưng cất có giám sát, điều này không thể tránh khỏi việc đưa ra thiên lệch kiến trúc từ giáo viên. Chúng tôi theo đó đề xuất một sơ đồ tự giám sát theo khối, hoàn toàn thoát khỏi ách của kiến trúc giáo viên.
NAS không giám sát [41,87] các phương pháp thực hiện tìm kiếm kiến trúc mà không có quyền truy cập vào bất kỳ nhãn được chú thích bởi con người nào. Un-NAS [ 41] giới thiệu các tác vụ pretext không giám sát [35,48,86] cho NAS chia sẻ trọng số để huấn luyện supernet và đánh giá kiến trúc. RLNAS [ 87] tối ưu hóa supernet bằng cách sử dụng nhãn ngẫu nhiên [81,45] và tiếp tục đánh giá kiến trúc bằng metric góc dựa trên hội tụ [ 32]. Một dòng phương pháp NAS khác [ 72,69,27,51] thuộc danh mục NAS có giám sát thực hiện pretraining không giám sát của predictor độ chính xác mạng hoặc supernet trước khi finetuing có giám sát hoặc đánh giá. Khác với các công trình đã đề cập ở trên về động cơ và phương pháp, chúng tôi khám phá các phương pháp học tương phản tự giám sát trong sơ đồ NAS không giám sát của chúng tôi để tránh thiên lệch giám sát trong NAS theo khối.
Các phương pháp học tương phản tự giám sát [ 49,71,28, 65,91,24,10] đã tiến bộ đáng kể trong việc học không giám sát các biểu diễn thị giác. Những cách tiếp cận này học các biểu diễn thị giác theo cách phân biệt bằng cách thu thập các biểu diễn của các view khác nhau từ cùng một hình ảnh và lan truyền những cái từ các hình ảnh khác nhau. Gần đây, BYOL [ 21] và SimSiam [ 11] sáng tạo đã học các biểu diễn thị giác mà không sử dụng các ví dụ âm. Những công trình này trực tiếp dự đoán biểu diễn của một view từ view khác bằng cách sử dụng một cặp mạng Siamese với cùng kiến trúc và trọng số được chia sẻ [ 11], hoặc với một trong các nhánh mạng Siamese là một momentum encoder, do đó tạo thành một sơ đồ bootstrapping [ 21]. Công trình của chúng tôi giới thiệu một sơ đồ bootstrapping mới với ensemble xác suất cho Siamese supernets .
Không gian Tìm kiếm Kiến trúc. Các không gian tìm kiếm dựa trên cell, được đề xuất lần đầu trong [93], thường được sử dụng trong các phương pháp NAS trước [ 42,54,43,52] và benchmarks [ 74,19,17]. Chúng tìm kiếm một kiến trúc cấp cell có thể lặp lại, trong khi giữ một kiến trúc cấp mạng được thiết kế thủ công. Ngược lại, các không gian tìm kiếm cấp mạng với độ chi tiết cấp layer [ 7,70,15,37,46,87] và độ chi tiết cấp khối [63,29,64] tìm kiếm cấu trúc cấp mạng macro bằng cách sử dụng các khối xây dựng được thiết kế thủ công ( ví dụ: MBConv [56]). Auto-DeepLab [ 40] trình bày một không gian tìm kiếm phân cấp cho phân đoạn ngữ nghĩa, với các cell có thể lặp lại và một cấu trúc cấp mạng giống như vải [ 57]. Không gian tìm kiếm HyTra của chúng tôi cũng có một cấu trúc cấp mạng giống như vải, mặc dù với độ chi tiết cấp layer thay vì các cell được lặp lại.
3. NAS Tự giám sát theo Khối
Trong phần này, chúng tôi trước tiên giới thiệu ngắn gọn tình thế khó xử của NAS và các giải pháp theo khối của nó [ 37,46,84,85], sau đó trình bày chi tiết BossNAS được đề xuất của chúng tôi, cùng với hai yếu tố chính của nó: i)giai đoạn huấn luyện supernet không giám sát với ensemble bootstrapping ;ii)giai đoạn đánh giá và tìm kiếm kiến trúc không giám sát hướng tới trung tâm quần thể kiến trúc.
Ký hiệu. Chúng tôi ký hiệu scalars, tensors và tập hợp tensors bằng cách sử dụng chữ cái viết thường, chữ in đậm viết thường và chữ cái viết hoa calligraphic tương ứng ( ví dụ: n,x và X). Để đơn giản, chúng tôi sử dụng fxng để ký hiệu tập hợp fxngjnj
n=1 với cardinality jnj.
3.1. Tình thế khó xử của NAS và các Giải pháp theo Khối
Tình thế khó xử của NAS: hiệu quả hay độ chính xác. Trong khi các phương pháp NAS dựa trên mẫu cổ điển tạo ra các đánh giá kiến trúc chính xác, chúng cũng rất tốn kém về mặt tính toán. Sơ đồ đánh giá chia sẻ trọng số trong các phương pháp NAS một lần đã mang lại sự giảm đáng kể chi phí tìm kiếm bằng cách mã hóa toàn bộ không gian tìm kiếm A thành một supernet chia sẻ trọng số, với các trọng số W được chia sẻ bởi tất cả các kiến trúc ứng viên và được tối ưu hóa đồng thời như: W = arg min
W Ltrain(W;A;x;y).
Ở đây Ltrain() ký hiệu hàm loss huấn luyện, trong khi x và y ký hiệu dữ liệu đầu vào và nhãn, tương ứng.
Sau đó, các kiến trúc được tìm kiếm dựa trên xếp hạng của các đánh giá của chúng với những trọng số mạng được chia sẻ này. Không mất tính tổng quát, chúng tôi chọn hàm loss đánh giá Lval như metric đánh giá; giai đoạn tìm kiếm có thể được hình thức hóa như: α* = arg min
α∈A Lval(W*;α;x;y). Tuy nhiên, xếp hạng kiến trúc dựa trên các trọng số được chia sẻ W* không nhất thiết đại diện cho xếp hạng chính xác của các kiến trúc, vì các trọng số được thừa kế từ supernet có tính liên kết cao và không được tối ưu hóa đầy đủ và công bằng. Như được chỉ ra trong tài liệu [ 58,73,80], các phương pháp chia sẻ trọng số gặp phải độ chính xác đánh giá kiến trúc thấp.
NAS có giám sát theo khối. Như được chứng minh về mặt lý thuyết và thực nghiệm bởi [ 39,37,46], việc giảm không gian chia sẻ trọng số ( tức là tổng số kiến trúc chia sẻ trọng số) có thể cải thiện hiệu quả độ chính xác của đánh giá kiến trúc. Trong thực tế, các giải pháp theo khối [ 37,46,84,85] tìm ra một lối thoát khỏi tình thế khó xử này của NAS bằng cách phân tách không gian tìm kiếm theo khối trong chiều sâu, do đó giảm không gian chia sẻ trọng số trong khi duy trì kích thước ban đầu của không gian tìm kiếm . Cho một supernet bao gồm jkj khối S(W;A) = fSk(Wk;Ak)g, với W = fWkg và A = fAkg ký hiệu trọng số và kiến trúc của nó có thể tách rời theo khối trong chiều sâu, mỗi khối của supernet được huấn luyện riêng biệt trước khi tìm kiếm trong tất cả các khối kết hợp bằng tổng [ 37], hoặc một tổ hợp tuyến tính [ 46] (với trọng số fλkg), của loss đánh giá Lval của mỗi khối:
α* = fα*kg = arg min
αfαkgAjkj Σ
k=1 λk Lval
W*
k;αk;xk;yk
s:t: W*
k = arg min
Wk Ltrain(Wk;Ak;xk;yk): (1)
Để cô lập việc huấn luyện của mỗi khối supernet, cho một đầu vào x, đầu vào trung gian và mục tiêu fxk;ykg của khối thứ k được tạo ra bởi một mạng giáo viên cố định T (với kiến trúc αT và trọng số thực tế WT): fx1;y1g = fx;T1(x)g, và fxk;ykg = fTk−1(x);Tk(x)g;k > 1, trong đó Tk đại diện cho mạng giáo viên được cắt ngắn sau khối thứ k. Vì dữ liệu được sử dụng cho cả giai đoạn huấn luyện và tìm kiếm đều được tạo ra bởi mô hình giáo viên T(WT;αT), các đánh giá kiến trúc có khả năng có tương quan cao với kiến trúc giáo viên. Ví dụ, một giáo viên tích chập có trường tiếp nhận hạn chế và các thiên lệch quy nạp kiến trúc đặc biệt như tính bất biến tịnh tiến . Với một giám sát thiên lệch như vậy, các kiến trúc ứng viên có khả năng được huấn luyện và đánh giá một cách không công bằng. Chúng tôi quan sát hai hiện tượng có thể được quy cho giám sát thiên lệch, tức là sự ưa thích ứng viên và sự ưa thích giáo viên . Phân tích thực nghiệm chi tiết của hai hiện tượng này được cung cấp trong Phần 5. Để phá vỡ những hạn chế này của các giải pháp NAS theo khối hiện tại, chúng tôi khám phá một sơ đồ mà không sử dụng mô hình giáo viên.
3.2. Huấn luyện với Ensemble Bootstrapping
Bắt đầu từ sơ đồ mạng kép với cặp học sinh-giáo viên fS(W;A);T(WT;αT)g, bước đầu tiên để thoát khỏi ách của kiến trúc giáo viên là gán αT = A, do đó tạo thành một cặp Siamese supernets .
Bootstrapping với Siamese Supernets. Để tối ưu hóa những Siamese networks như vậy theo khối, chúng tôi áp dụng một sơ đồ học tương phản tự giám sát. Cụ thể hơn, hai supernets này nhận một cặp view được tăng cường fx1;x2g của cùng một mẫu huấn luyện x và tạo ra các đầu ra fS(W;A;x1);T(WT;A;x2)g, tương ứng. Tương tự như các setting giáo viên-học sinh trước đây, Siamese supernets được tối ưu hóa bằng cách tối thiểu hóa khoảng cách giữa các đầu ra của chúng. Trong các Siamese networks và phương pháp học tương phản tự giám sát trước đây, hai mạng hoặc chia sẻ trọng số [ 10,11] (tức là WT = W) hoặc tạo thành một sơ đồ mean teacher với Exponential Moving Average (EMA) [ 24,21] (tức là WT = W̄, trong đó W̄
t = μW̄
t−1 + (1 − μ)Wt đại diện cho trung bình theo thời gian của W, với t là một timestamp huấn luyện, và μ ký hiệu hệ số momentum kiểm soát tốc độ cập nhật của W̄). Bằng cách học biểu diễn từ mean teacher, tương tự như BYOL [ 21] đơn giản nhưng mạnh mẽ, supernet của chúng tôi có thể được tối ưu hóa theo cách không giám sát mà không dựa vào một mạng giáo viên được giám sát đầy đủ:
W*
k = arg min
Wk Ltrain
fWk;W̄kg;Ak;xk
: (2)
Để loại bỏ ảnh hưởng của sự khác biệt pixel-wise giữa hai biểu diễn trung gian gây ra bởi các augmentations (ví dụ: random crop), cũng như để đảm bảo tổng quát hóa tốt hơn trên các kiến trúc ứng viên với các trường tiếp nhận khác nhau hoặc thậm chí các độ phân giải khác nhau, chúng tôi chiếu các biểu diễn vào không gian latent trước khi tính toán khoảng cách element-wise.
Ensemble Bootstrapping. Tuy nhiên, không giống như các mạng đơn, supernets thường được tối ưu hóa bằng các chiến lược lấy mẫu đường dẫn, ví dụ: single path [ 22] hoặc fair path [ 15]. Khi áp dụng bootstrapping một cách ngây thơ, mỗi sub-network học từ moving average của chính nó. Trong sự vắng mặt của một mục tiêu chung, các trọng số được chia sẻ bởi các sub-networks khác nhau gặp khó khăn về hội tụ, dẫn đến sự bất ổn định huấn luyện và đánh giá kiến trúc không chính xác. Để giải quyết vấn đề này, chúng tôi đề xuất một sơ đồ huấn luyện supernet không giám sát, được gọi là ensemble bootstrapping .
Xem xét jpj sub-networks fαpg ⊆ Ak được lấy mẫu từ khối thứ k của không gian tìm kiếm A trong lần lặp huấn luyện thứ t, và cho một mẫu huấn luyện x, jpj cặp view được tăng cường fxpg ← paug(·jx), fx0
pg ← p0
aug(·jx) được tạo ra cho mỗi sub-network được lấy mẫu của Siamese supernets. Để tạo thành một mục tiêu chung cho tất cả các đường dẫn, chúng tôi có thể sử dụng một sơ đồ tương tự như ensemble distillation [ 59,60] trong học có giám sát. Như được minh họa trong Hình 2, mỗi sub-network được lấy mẫu của online supernet học dự đoán ensemble xác suất của tất cả sub-networks được lấy mẫu trong EMA supernet:
c̄Tk
fpg;fx0
pg
= 1
jpj jpjΣ
p=1 Tk(W̄;αp;x0
p): (3)
Tóm lại, quá trình huấn luyện tự giám sát theo khối của Siamese supernets được hình thức hóa như sau:
W*
k = arg min
Wk jpjΣ
p=1 Ltrain
fWk;W̄kg;fαpg;x
,
trong đó Ltrain
fWk;W̄kg;fαpg;x
=


Sk(Wk;αp;xp) − c̄Tk
W̄
k;fpg;fx0
pg


2
2: (4)
3.3. Tìm kiếm Hướng tới Trung tâm Quần thể
Sau khi sự hội tụ của Siamese supernets hoàn tất, các kiến trúc có thể được xếp hạng và tìm kiếm bởi đánh giá được xác định dựa trên trọng số của supernets, như trong Phương trình 1. Trong phần này, chúng tôi thiết kế một metric đánh giá không giám sát công bằng và hiệu quả Lval cho giai đoạn tìm kiếm.
Để đánh giá hiệu suất của một mạng được huấn luyện với self-supervision tương phản, các công trình trước [ 24,10,21,11] đã sử dụng các metric có giám sát, như độ chính xác của linear evaluation hoặc phân loại few-shot. Để phát triển một phương pháp NAS không giám sát, chúng tôi nhằm tránh các sơ đồ phụ thuộc vào nhãn được chú thích bởi con người và thay vào đó theo đuổi một metric đánh giá hoàn toàn không giám sát. Các phương pháp NAS không giám sát trước [ 41,87] sử dụng hoặc độ chính xác của các tác vụ pretext hoặc đo lường hội tụ với các metric dựa trên góc để đánh giá các kiến trúc ứng viên. Thật không may, các loss của học tương phản tự giám sát không nhất thiết đại diện cho hiệu suất kiến trúc hoặc sự hội tụ kiến trúc, vì các view đầu vào và mạng đích đều được lấy mẫu ngẫu nhiên . Hơn nữa, các mạng đích có phần thiên lệch và không thể phục vụ như mục tiêu thực tế.
Để tránh những mối quan tâm này, chúng tôi đề xuất một metric đánh giá không giám sát công bằng và hiệu quả cho tìm kiếm kiến trúc.
Không mất tính tổng quát, chúng tôi xem xét tìm kiếm với một thuật toán tiến hóa [12,54], trong đó các kiến trúc được tối ưu hóa bằng cách phát triển một quần thể kiến trúc fαpg. Tương tự như việc tối ưu hóa các trọng số, chúng tôi đề xuất sử dụng ensemble xác suất trong quần thể fαpg như mục tiêu chung để cung cấp một đánh giá công bằng cho mỗi kiến trúc αp. Ngoài ra, một cặp view fx1;x2g cho mỗi mẫu validation x được tạo ra và cố định để tránh thiên lệch được đưa ra bởi augmentation biến đổi. Song song với Phương trình 3, chúng ta có ensemble xác suất của quần thể kiến trúc:
c̄Sk
fpg;x2
= 1
jpj jpjΣ
p=1 Sk(αp;x2): (5)
Trong thực tế, bằng cách chia supernet thành các khối có kích thước trung bình ( ví dụ: 4 layers của 4 ứng viên, 44 = 256 kiến trúc), việc đánh giá traversal của tất cả các kiến trúc ứng viên là có thể chi trả được. Trong trường hợp này, quần thể kiến trúc fαpg được mở rộng thành toàn bộ không gian tìm kiếm theo khối Ak, và toàn bộ quá trình tìm kiếm được hoàn thành trong một bước duy nhất:
α* = arg min
α∈A jkjΣ
k=1 λk Lval(α;xk)
trong đó Lval(α;x) =


Sk(α;x1) − c̄Sk(Ak;x2)


2
2: (6)
4. Không gian Tìm kiếm CNN-transformer Lai
Trong phần này, chúng tôi trình bày một không gian tìm kiếm CNN-transformer lai giống như vải, được gọi là HyTra, với các khối xây dựng ứng viên khác biệt và các vị trí down-sampling linh hoạt.
4.1. Các Khối Ứng viên CNN và Transformer
Bước đầu tiên trong việc thiết kế một không gian tìm kiếm CNN-transformer lai là bao gồm các khối xây dựng CNN và transformer phù hợp. Hai loại khối xây dựng này nên có thể hoạt động tốt khi được tổng hợp đơn giản theo chuỗi hoặc khi được kết hợp tự do. Chúng tôi chọn residual bottleneck cổ điển và mạnh mẽ (ResConv ) trong ResNet [ 25] như khối xây dựng ứng viên CNN. Song song, chúng tôi thiết kế một khối xây dựng transformer nhẹ và mạnh mẽ ResAtt dựa trên BoTBlock [62] và NLBlock [68] có thể cắm được.
Cân bằng Tính toán với Mã hóa Vị trí Ngầm định. Để tạo điều kiện cạnh tranh công bằng và có ý nghĩa, các khối xây dựng ứng viên nên có độ phức tạp tính toán tương tự. BoTBlock ban đầu chậm hơn ResConv , vì các mã hóa vị trí tương đối của nó được tính toán riêng biệt thông qua phép nhân với query . Việc đơn giản loại bỏ nhánh content-position từ BoTBlocks, giống như NLBlocks, có thể giảm thời gian tính toán của chúng để làm cho chúng có thể so sánh với ResConv . Tuy nhiên, mã hóa vị trí là rất quan trọng đối với vision transformers để đạt hiệu suất tốt. Trong CPVT [ 14], các tác giả sử dụng các convolutions đơn lẻ giữa các khối transformer encoder như bộ tạo mã hóa vị trí . Tương tự, chúng tôi thay thế nhánh mã hóa vị trí tương đối trong BoTBlock bằng một depthwise separable convolution nhẹ như một module mã hóa vị trí ngầm định, tạo thành ResAtt của chúng tôi. Bằng sự điều chỉnh đơn giản này, chúng tôi giảm độ phức tạp tính toán của module mã hóa vị trí từ O(CW3) ban đầu thành O(CW2), với C ký hiệu số kênh và W ký hiệu chiều rộng hoặc chiều cao. Trái ngược với CPVT và BoT (Hình 4), các module mã hóa vị trí của chúng tôi (Hình 3 phải) được đặt giữa input projection layer và self-attention module. Ngoài ra, các module mã hóa vị trí ngầm định của chúng tôi cũng chịu trách nhiệm về down-sampling. Sự điều chỉnh này cũng được áp dụng cho ResConv , cho phép chia sẻ trọng số giữa các khối ứng viên với các tỷ lệ down-sampling khác nhau ( tức là 1 hoặc 2).
4.2. Vải của CNN-transformers Lai
Ngoài các khối xây dựng, CNNs và transformers khác nhau đáng kể về kiến trúc macro của chúng. Không giống như CNNs, xử lý hình ảnh theo các giai đoạn với các kích thước không gian khác nhau, transformers thường không thay đổi độ dài chuỗi (image patches) và giữ nguyên quy mô ở mỗi layer. Như được hiển thị trong Hình 3 trái, để bao gồm cả CNNs và transformers, không gian tìm kiếm của chúng tôi được thiết kế với các vị trí down-sampling linh hoạt, tạo thành một vải [57] của CNN-transformers Lai. Tại mỗi choice block layer của vải, độ phân giải không gian có thể giữ nguyên hoặc được giảm xuống một nửa quy mô của nó, cho đến khi đạt được quy mô nhỏ nhất. Không gian tìm kiếm giống như vải này chứa các kiến trúc giống với các vision transformers phổ biến [ 20,66,14], CNNs [ 25,31] và CNN-transformers lai [62] ở các quy mô khác nhau.

--- TRANG 6 ---
Method MAdds Steptime Top-1 (%) Top-5 (%)
ResNet50 [25] 4.1B 100ms 77.7 93.9
ViT-B/32 [20] - 68ms 73.4 -
ViT-B/16 [20] 17.6B 158ms 77.9 -
BoT50 [62] 4.0B 120ms 78.3 94.2
R50-T Conv -Only 4.1B 104ms 78.2 94.2
ViT-T/32 Att-Only 2.9B 92ms 74.5 91.7
ViT-T/16 Att-Only 3.2B 96ms 76.5 93.0
BoT50-T Hybrid 3.9B 103ms 79.5 94.8
Random-T Hybrid 3.7B 84ms 76.7 93.1
BossNet-T0 w=o SE 3.4B 101ms 80.5 95.0
SENet50 [25, 31] 4.1B 129ms 79.4 94.6
EffNetB1 [64] 0.7B 131ms 79.1 94.4
DeiT-S [66] 10.1B 84ms 79.8 -
BoT50 + SE [62] 4.0B 149ms 79.6 94.6
DNA-T [37] 3.9B 121ms 80.3 95.0
UnNAS-T [41] 3.7B 104ms 79.8 94.6
BossNet-T0 3.4B 115ms 80.8 95.2
BossNet-T0 " 5.7B 147ms 81.6 95.6
SENet101 [25, 31] 7.8B 218ms 81.4 95.7
EffNetB2 [64] 1.0B 143ms 80.1 94.9
ViT-L/16 [20] 63.6B 168ms 81.1 -
DeiT-B [66] 17.6B 152ms 81.8 -
BoTNet-S1-59 [62] 7.3B 184ms 81.7 95.8
T2T-ViT-19 [79] 8.9B 158ms 81.9 -
TNT-S [23] 5.2B 468ms 81.3 95.6
BossNet-T1 7.9B 156ms 82.2 95.8
BossNet-T1 " 10.5B 165ms 82.5 96.0
Table 1: Kết quả ImageNet của các mô hình hiện đại và CNN-transformers lai được tìm kiếm của chúng tôi. Thời gian steptime tính toán được đo trên một GPU GeForce RTX 3090 với batch size 32. Màu tím được sử dụng để ký hiệu các kiến trúc được chọn thủ công từ không gian tìm kiếm HyTra. ": Được kiểm tra trực tiếp trên kích thước đầu vào lớn hơn mà không cần finetuning ( tức là 288 cho BossNet-T0 " và 256 cho BossNet-T1 ").
5. Thí nghiệm
Cài đặt. Chúng tôi đánh giá phương pháp của chúng tôi trên ba không gian tìm kiếm, bao gồm không gian tìm kiếm HyTra được đề xuất của chúng tôi và hai không gian tìm kiếm hiện có khác, tức là không gian tìm kiếm MBConv [ 7,37] và không gian tìm kiếm kích thước NATS-Bench SS[17]. Các tập dữ liệu chúng tôi sử dụng để đánh giá và phân tích phương pháp của chúng tôi là ImageNet [16], CIFAR-10 và CIFAR-100 [ 36]. Chúng tôi huấn luyện mỗi khối của supernet trong 20 epochs, bao gồm một epoch warm-up tuyến tính. Chúng tôi ngẫu nhiên lấy mẫu bốn đường dẫn trong mỗi bước huấn luyện. Xem Phụ lục A.2 để biết thêm chi tiết triển khai.
5.1. Tìm kiếm CNN-transformer Lai
Phân tích không gian tìm kiếm HyTra. Chúng tôi đã ghép thủ công bốn kiến trúc trên không gian tìm kiếm HyTra giống như vải của chúng tôi, tuân theo càng gần càng tốt với các mạng được thiết kế bởi con người trước đây [ 25,20,62], ngoại trừ việc sử dụng các khối xây dựng fResConv;ResAttg của chúng tôi. Như được hiển thị trong Bảng 1, những mô hình này (màu tím) luôn luôn vượt trội so với các nguyên mẫu của chúng. Đáng chú ý, BoT50-T vượt trội so với BoT50 ban đầu 1.2% độ chính xác top-1 với giảm 1.17× thời gian tính toán, chứng minh sự vượt trội của các khối xây dựng được thiết kế của chúng tôi.
Hiệu suất của các mô hình được tìm kiếm. Với không gian tìm kiếm và phương pháp NAS được đề xuất của chúng tôi, chúng tôi khám phá các kiến trúc CNN-transformer lai trên ImageNet. Kết quả của các mô hình được tìm kiếm của chúng tôi (BossNet-T) và các mô hình với thời gian tính toán tương đương được tóm tắt trong Bảng 1.
Thứ nhất , BossNet-T0 vượt trội so với một loạt các mô hình hiện đại. Ví dụ, BossNet-T0 không có module SE đạt độ chính xác top-1 80.5%, vượt trội so với CNN-transformer lai được thiết kế bởi con người, BoTNet50, 2.2% trong khi nhanh hơn 1.19× về thời gian tính toán; khi được trang bị SE và SiLU activation, BossNet-T0 tiếp tục đạt độ chính xác top-1 80.8%, vượt trội so với EfﬁcientNet-B1 được tìm kiếm bằng NAS 1.7% trong khi nhanh hơn 1.14×.
Thứ hai , mô hình được tìm kiếm của chúng tôi thể hiện sự vượt trội tuyệt đối so với các mô hình được chọn thủ công và ngẫu nhiên từ không gian tìm kiếm HyTra. Đặc biệt, BossNet-T0 đạt cải thiện lên tới 6.0% so với các mô hình được chọn thủ công, chứng minh hiệu quả của tìm kiếm kiến trúc của chúng tôi.
Thứ ba , BossNet-T0 vượt trội so với các phương pháp NAS gần đây khác trên không gian tìm kiếm HyTra. BossNet-T0 đạt 0.5% tăng độ chính xác so với DNA-T, được tìm kiếm bởi đối tác NAS có giám sát của chúng tôi [37].
Cuối cùng , khi được mở rộng sang kích thước mô hình và kích thước đầu vào lớn hơn, họ mô hình BossNet-T duy trì sự vượt trội của chúng. Bằng cách loại bỏ downsampling ở giai đoạn cuối của BossNet-T0 (cùng sơ đồ như BoTNet-S1 [ 62]), chúng ta có BossNet-T1, đạt độ chính xác 82.2%, vượt trội so với EfﬁcientNet-B2 2.1% . Bằng cách kiểm tra trực tiếp trên độ phân giải đầu vào lớn hơn mà không cần finetuning, BossNet-T0 "(trên kích thước đầu vào 288×288) đạt độ chính xác top-1 81.6%, và vượt trội so với BoTNet50 + SE 2.0% với runtime tương tự; BossNet-T1"(trên kích thước đầu vào 256×256) đạt độ chính xác top-1 82.5%, vượt trội so với T2T-ViT-19 và EfﬁcientNet-B2 0.6% và 2.4% với steptime tương đương, tương ứng.
Trực quan hóa và phân tích kiến trúc. Chúng tôi trực quan hóa kiến trúc của DNA-T và BossNet-T0 trong Hình 5. DNA-T rõ ràng ưa thích convolutions, vì nó chứa 13 khối ResConv và chỉ ba khối ResAtt. Ngược lại, BossNet-T0 có số lượng convolutions và attentions tương tự và cuối cùng đạt độ chính xác cao hơn. Chúng tôi gọi điều này là Hiện tượng I: ưa thích ứng viên , và quy cho thiên lệch kiến trúc từ giám sát giáo viên. Không sử dụng mô hình giáo viên, phương pháp của chúng tôi thành công tránh thiên lệch này.

--- TRANG 7 ---
74 753.535
3.530
3.525
3.520
BossNAS, =0.65
74 7570.670.770.870.971.0
SPOS, =0.18
74 752468
DARTS, =0.08
74 7543.544.044.545.045.5
MnasNet, =0.61
74 750.5
0.4
0.3
DNA (EffNet), =0.62
74 750.400
0.375
0.350
0.325
DNA (MBNet), =0.23
80828486889092941.13
1.12
1.11
1.10
1.09
1.08
1.07
1.06
1.05
Figure 6: Trái: Tương quan xếp hạng của 6 phương pháp NAS khác nhau trên Không gian Tìm kiếm MBConv. Phải: Xếp hạng kiến trúc của BossNAS trên NATS-Bench SS. Trong tất cả các biểu đồ, trục x ký hiệu độ chính xác thực tế; trục y ký hiệu các metric đánh giá.
Method MAdds (M) Top-1 (%) Top-5 (%)
FairNAS-A [15] 388M 75.3 92.4
ProxylessNAS [7] 465M 75.1 92.5
FBNet-C [70] 375M 74.9 -
SPOS [22] 472M 74.8 -
RLNAS [87] 473M 75.6 92.6
BossNet-M1 w=o SE 475M 76.2 93.0
MobileNetV3 [29] 219M 75.2 -
MnasNet-A3 [63] 403M 76.7 93.3
EfﬁcientNet-B0 [64] 399M 76.3 93.2
DNA-b [37] 406M 77.5 93.3
BossNet-M2 403M 77.4 93.6
Table 2: Kết quả ImageNet của các mô hình NAS hiện đại trên không gian tìm kiếm MBConv .
Method Search Cost R
SPOS [22] 8.5 Gds -0.18 -0.27 -0.29
DARTS [43] 50 Gds 0.08 0.14 0.06
MnasNet [63] 288 Tds 0.61 0.77 0.78
DNA [37] (EffNetB0) 8.5 Gds 0.62 0.77 0.83
DNA [37] (MBNetV1) 8.5 Gds 0.23 0.27 0.37
BossNAS 10 Gds 0.65 0.78 0.85
Table 3: So sánh hiệu quả và hiệu suất của các phương pháp NAS khác nhau trên không gian tìm kiếm MBConv và tập dữ liệu ImageNet . (Gds: GPU days; Tds: TPU days)
5.2. Kết quả trên Không gian Tìm kiếm MBConv
Để tiếp tục chứng minh hiệu quả và khả năng tổng quát hóa của BossNAS, chúng tôi so sánh nó với một loạt các phương pháp NAS trên không gian tìm kiếm MBConv.
Hiệu suất của các mô hình được tìm kiếm. Như được hiển thị trong Bảng 2, các mô hình được tìm kiếm của chúng tôi, BossNet-M, đạt kết quả cạnh tranh trong các không gian tìm kiếm có và không có module SE. Trong không gian tìm kiếm không có SE, BossNet-M1, được tìm kiếm dưới ràng buộc 475M MAdds, vượt trội so với SPOS [ 22] và một phương pháp NAS không giám sát gần đây khác, RLNAS [ 87] 1.4% và 0.6% , tương ứng. Trong không gian tìm kiếm có SE, BossNet-M2, dưới ràng buộc 405M MAdds, vượt trội so với EfﬁcientNet [ 64] phổ biến 1.1% , và cũng cạnh tranh với đối tác có giám sát của chúng tôi, DNA [ 37]. Lưu ý rằng các khối xây dựng ứng viên trong không gian tìm kiếm MBConv khá tương tự, che giấu hiện tượng ưa thích ứng viên trong [37].
Độ chính xác đánh giá kiến trúc. Vì BossNAS thực hiện tìm kiếm traversal (tức là độ chính xác của giai đoạn tìm kiếm là 100% ), độ chính xác đánh giá kiến trúc trực tiếp đại diện cho hiệu quả của nó. Chúng tôi sử dụng 23 kiến trúc open-source trong không gian tìm kiếm MBConv và các độ chính xác thực tế tương ứng của chúng được cung cấp bởi [ 37] để tính toán độ chính xác đánh giá kiến trúc, tức là tương quan xếp hạng giữa xếp hạng kiến trúc dự đoán và xếp hạng mô hình thực tế. Chúng tôi sử dụng ba metric tương quan xếp hạng khác nhau: Kendall Tau ( τ ) [34], Spearman Rho ( ρ ) và Pearson R ( R). Tất cả ba metric dao động từ -1 đến 1, với "-1" đại diện cho xếp hạng hoàn toàn đảo ngược, "1" có nghĩa là xếp hạng hoàn toàn chính xác, và "0" đại diện cho không có tương quan giữa các xếp hạng. Như được hiển thị trong Bảng 3 và Hình 6 trái, BossNAS của chúng tôi đạt được độ chính xác đánh giá cao nhất với τ 0.65 trong số các phương pháp NAS sota, trong khi giải quyết hai vấn đề.
Thứ nhất , các phương pháp chia sẻ trọng số cổ điển, SPOS [ 22] và DARTS [ 43], thất bại trong việc đạt tương quan xếp hạng hợp lý mặc dù chi phí tìm kiếm thấp hơn, trong khi phương pháp đa thử, MnasNet [ 63], đạt độ chính xác đánh giá cao với chi phí tìm kiếm khổng lồ. BossNAS thành công giải quyết tình thế khó xử như vậy của NAS bằng cách đạt độ chính xác đánh giá thậm chí cao hơn MnasNet ( ví dụ: 0.07↑ R) với tăng tốc 28.8×.
Thứ hai , phương pháp NAS theo khối có giám sát, DNA [ 37], thất bại trong việc đạt độ chính xác đánh giá cao khi sử dụng một giáo viên khác biệt lớn từ các ứng viên (MobileNetV1 [ 30] vs. các ứng viên dựa trên EfﬁcientNet [ 64]), mà chúng tôi gọi là Hiện tượng II: ưa thích giáo viên . BossNAS không giám sát của chúng tôi đạt độ chính xác đánh giá cao hơn DNA ( 0.03↑ τ ), thành công thoát khỏi ách của mạng giáo viên.
5.3. Kết quả trên NATS-Bench SS
Đối với không gian tìm kiếm kích thước NATS-Bench SS, các thí nghiệm được tiến hành trên hai tập dữ liệu: CIFAR-10 và CIFAR-100. Các ứng viên có số kênh khác nhau trong supernet của chúng tôi chia sẻ các trọng số theo cách slimmable [78, 77, 76, 38, 9].
Hiệu suất của các mô hình được tìm kiếm. Sau khi tìm kiếm trên supernet của chúng tôi, chúng tôi tra cứu hiệu suất của các mô hình được tìm kiếm trong NATS-Bench SS để so sánh công bằng. Kết quả được hiển thị trong Bảng 4. BossNAS của chúng tôi vượt trội so với các phương pháp NAS gần đây [67,5] được thiết kế đặc biệt cho các không gian tìm kiếm kích thước mạng, chứng minh khả năng tổng quát hóa của phương pháp của chúng tôi trên các không gian tìm kiếm cụ thể và các tập dữ liệu tương đối nhỏ.
Độ chính xác đánh giá kiến trúc. Chúng tôi đánh giá tất cả 32768 kiến trúc trong không gian tìm kiếm để so sánh với độ chính xác thực tế của chúng trong benchmark trên tập dữ liệu CIFAR-10. Như được hiển thị trong Hình 6 phải, tất cả các kiến trúc trong không gian tìm kiếm tạo thành một mẫu dày đặc, hình thoi, chứng minh hiệu quả của BossNAS của chúng tôi.
Ngoài ra, độ chính xác đánh giá kiến trúc trên tập dữ liệu CIFAR-100 được hiển thị trong Bảng 4. Phương pháp của chúng tôi, không có quyền truy cập vào độ chính xác kiến trúc thực tế và thậm chí không có quyền truy cập vào bất kỳ nhãn được chú thích bởi con người nào, vượt trội so với một phương pháp NAS dựa trên predictor [ 27], được huấn luyện với độ chính xác kiến trúc thực tế, bằng một khoảng cách lớn ( tức là 0.16↑ ρ và 0.19↑ R). Phân tích thêm về NATS-Bench SS có thể được tìm thấy trong Phụ lục A.3.
5.4. Nghiên cứu Ablation
Trong phần này, chúng tôi thực hiện các nghiên cứu ablation mở rộng trên không gian tìm kiếm MBConv và ImageNet để phân tích các phương pháp huấn luyện và đánh giá được đề xuất của chúng tôi một cách riêng biệt.
Các phương pháp huấn luyện. Chúng tôi so sánh một số phương pháp huấn luyện cho supernet theo khối: (1) Phương pháp chưng cất có giám sát ( Supv:distill.), sử dụng một mô hình giáo viên được huấn luyện trước để cung cấp giám sát theo khối, tức là sơ đồ huấn luyện được sử dụng trong DNA [ 37] (2) Phân loại có giám sát (Supv:class.), sử dụng nhãn thực trực tiếp như giám sát theo khối. (3) Bootstrapping không giám sát (Unsupv:bootstrap.), trong đó Siamese supernets được tối ưu hóa bằng cách bootstrapping các đường dẫn tương ứng trong hai mạng. (4) Phương pháp ensemble bootstrapping không giám sát của chúng tôi ( Unsupv:EB), trong đó mỗi đường dẫn được lấy mẫu được tối ưu hóa bằng cách học dự đoán ensemble xác suất của các đường dẫn được lấy mẫu từ mean teacher. Như được hiển thị trong Bảng 5, phương pháp huấn luyện của chúng tôi vượt trội so với tất cả những cái khác, đạt kết quả tốt nhất trong độ chính xác đánh giá kiến trúc. Đặc biệt, bằng cách so sánh dòng thứ 3 và thứ 5, chúng ta có thể thấy rằng việc thay thế Unsupv:EB được đề xuất của chúng tôi bằng sơ đồ Unsupv:bootstrap. ngây thơ, độ chính xác đánh giá kiến trúc giảm mạnh 0.53↓ τ. Không có ensemble xác suất, bootstrapping thất bại trong việc đạt độ chính xác đánh giá hợp lý, chứng minh rằng ensemble bootstrapping được đề xuất là không thể thiếu cho BossNAS của chúng tôi.
Các phương pháp đánh giá. Tương tự như phân tích ablation của các phương pháp huấn luyện, chúng tôi cũng so sánh các phương pháp đánh giá của chúng tôi với (1) Phương pháp chưng cất có giám sát ( Supv:distill.) và (2) Phân loại có giám sát (Supv:class.). Ngoài ra, để thực hiện phân tích ablation của đánh giá mà không thay đổi phương pháp huấn luyện, chúng tôi cũng so sánh với (3) đánh giá tuyến tính có giám sát ( Supv:linear eval), trong đó các kiến trúc được đánh giá bằng cách cố định trọng số của supernet và finetuning một bộ phân loại tuyến tính chia sẻ trọng số để đánh giá mỗi kiến trúc. (4) Metric đánh giá không giám sát của chúng tôi ( Unsupv:eval) đánh giá các kiến trúc bằng khoảng cách của nó đến trung tâm ensemble xác suất của toàn bộ không gian tìm kiếm. Từ hai dòng cuối của Bảng 5, chúng tôi ngạc nhiên thấy rằng Unsupv:eval của chúng tôi vượt trội so với sơ đồ đánh giá tuyến tính có giám sát trong đánh giá kiến trúc bằng một khoảng cách đáng kể ( 0.1↑ τ).
5.5. Hành vi Hội tụ
Để tiếp tục chứng minh hiệu quả của BossNAS, chúng tôi điều tra độ chính xác đánh giá kiến trúc trong quá trình huấn luyện supernet trên không gian tìm kiếm MBConv với ImageNet. Ba metric tương quan xếp hạng của BossNAS của chúng tôi trong 20 epochs huấn luyện được hiển thị trong Hình 7. Độ chính xác đánh giá kiến trúc tăng nhanh trong giai đoạn đầu và tiếp tục tăng với dao động nhỏ. Độ chính xác đánh giá hội tụ ở epoch thứ 12 và tiếp tục ổn định cho đến cuối giai đoạn huấn luyện. Khả năng đánh giá kiến trúc tăng ổn định chứng minh tính ổn định của BossNAS của chúng tôi. Ngoài ra, tương quan xếp hạng hội tụ nhanh chứng minh rằng phương pháp của chúng tôi dễ tối ưu hóa và không yêu cầu huấn luyện lâu hơn. Vui lòng tham khảo Phụ lục A.3 để phân tích hành vi hội tụ trên NATS-Bench SS.
6. Kết luận
Trong công trình này, chúng tôi trình bày BossNAS, một phương pháp NAS không giám sát, tổng quát với kỹ thuật huấn luyện ensemble bootstrapping và một metric đánh giá không giám sát . Các thí nghiệm trên ba không gian tìm kiếm chứng minh rằng phương pháp của chúng tôi thành công giải quyết vấn đề đánh giá kiến trúc không chính xác gây ra bởi không gian chia sẻ trọng số lớn trong khi tránh thiên lệch kiến trúc mang lại bởi chưng cất có giám sát. Phân tích ablation chứng minh rằng hai thành phần, sơ đồ ensemble bootstrapping và metric đánh giá không giám sát , đều quan trọng cho phương pháp của chúng tôi. Ngoài ra, chúng tôi trình bày một không gian tìm kiếm giống như vải được gọi là HyTra. Trên không gian tìm kiếm đầy thử thách này, mô hình CNN-transformer lai được tìm kiếm của chúng tôi, đạt độ chính xác 82.5% trên ImageNet, vượt trội so với EfﬁcientNet 2.4% với thời gian tính toán tương đương.
Lời cảm ơn
Công trình này được hỗ trợ một phần bởi Chương trình R&D Trọng điểm Quốc gia của Trung Quốc dưới Grant No. 2020AAA0109700 và nguồn tài trợ của "Leading Innovation Team of the Zhejiang Province" (2018R01017). Tiến sĩ Xiaojun Chang được hỗ trợ một phần bởi Australian Research Council (ARC) Discovery Early Career Research Award (DECRA) dưới grant no. DE190100626 và Intelligence Advanced Research Projects Activity (IARPA) qua Department of Interior/Interior Business Center (DOI/IBC).

--- TRANG 9 ---
Tài liệu tham khảo
[1]Youhei Akimoto, Shinichi Shirakawa, Nozomu Yoshinari,
Kento Uchida, Shota Saito, và Kouhei Nishida. Adaptive
stochastic natural gradient method for one-shot neural archi-
tecture search. Trong ICML , 2019. 12
[2]Bowen Baker, Otkrist Gupta, Nikhil Naik, và Ramesh
Raskar. Designing neural network architectures using re-
inforcement learning. Trong ICLR , 2017. 2, 12
[3]Irwan Bello. Lambdanetworks: Modeling long-range interac-
tions without attention. Trong ICLR , 2021. 1
[4]Gabriel Bender, Pieter-Jan Kindermans, Barret Zoph, Vijay
Vasudevan, và Quoc V . Le. Understanding and simplifying
one-shot architecture search. Trong ICML , 2018. 2, 12
[5]Gabriel Bender, Hanxiao Liu, Bo Chen, Grace Chu, Shuyang
Cheng, Pieter-Jan Kindermans, và Quoc V Le. Can weight
sharing outperform random architecture search? an investiga-
tion with tunas. Trong CVPR , 2020. 7
[6]Andrew Brock, Theodore Lim, James M. Ritchie, và Nick
Weston. SMASH: one-shot model architecture search through
hypernetworks. Trong ICLR , 2018. 2, 12
[7]Han Cai, Ligeng Zhu, và Song Han. Proxylessnas: Direct
neural architecture search on target task and hardware. Trong
ICLR , 2019. 3, 6, 7, 12
[8]Nicolas Carion, Francisco Massa, Gabriel Synnaeve, Nicolas
Usunier, Alexander Kirillov, và Sergey Zagoruyko. End-
to-end object detection with transformers. Trong ECCV , 2020.
1
[9]Minghao Chen, Houwen Peng, Jianlong Fu, và Haibin Ling.
AutoFormer: Searching transformers for visual recognition.
Trong ICCV , 2021. 1, 7, 13
[10] Ting Chen, Simon Kornblith, Mohammad Norouzi, và Geof-
frey Hinton. A simple framework for contrastive learning of
visual representations. Trong ICML , 2020. 3, 4
[11] Xinlei Chen và Kaiming He. Exploring simple siamese
representation learning. Trong CVPR , 2021. 3, 4
[12] Yukang Chen, Gaofeng Meng, Qian Zhang, Shiming Xiang,
Chang Huang, Lisen Mu, và Xinggang Wang. RENAS:
reinforced evolutionary neural architecture search. Trong CVPR ,
2019. 2, 5
[13] Xuelian Cheng, Yiran Zhong, Mehrtash Harandi, Yuchao
Dai, Xiaojun Chang, Hongdong Li, Tom Drummond, và
Zongyuan Ge. Hierarchical neural architecture search for
deep stereo matching. Trong NeurIPS , 2020. 12
[14] Xiangxiang Chu, Zhi Tian, Bo Zhang, Xinlong Wang, Xiaolin
Wei, Huaxia Xia, và Chunhua Shen. Conditional positional
encodings for vision transformers. arXiv:2102.10882 , 2021.
1, 5
[15] Xiangxiang Chu, Bo Zhang, và Ruijun Xu. FairNAS: Re-
thinking evaluation fairness of weight sharing neural architec-
ture search. Trong ICCV , 2021. 3, 4, 7, 12
[16] Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, và Li
Fei-Fei. Imagenet: A large-scale hierarchical image database.
Trong CVPR , 2009. 6, 13
[17] Xuanyi Dong, Lu Liu, Katarzyna Musial, và Bogdan Gabrys.
NATS-Bench: Benchmarking nas algorithms for architecture
topology and size. IEEE Transactions on Pattern Analysis và Machine Intelligence (TPAMI) , 2021. doi:10.1109/
TPAMI.2021.3054824 . 2, 3, 6, 12, 13
[18] Xuanyi Dong và Yi Yang. Searching for a robust neural
architecture in four GPU hours. Trong CVPR , 2019. 12
[19] Xuanyi Dong và Yi Yang. NAS-Bench-201: Extending the
scope of reproducible neural architecture search. Trong ICLR ,
2020. 3
[20] Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov,
Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner,
Mostafa Dehghani, Matthias Minderer, Georg Heigold, Syl-
vain Gelly, Jakob Uszkoreit, và Neil Houlsby. An image is
worth 16x16 words: Transformers for image recognition at
scale. Trong ICLR , 2021. 1, 5, 6
[21] Jean-Bastien Grill, Florian Strub, Florent Altch ´e, Corentin
Tallec, Pierre H Richemond, Elena Buchatskaya, Carl Do-
ersch, Bernardo Avila Pires, Zhaohan Daniel Guo, Moham-
mad Gheshlaghi Azar, et al. Bootstrap your own latent: A
new approach to self-supervised learning. Trong NeurIPS , 2020.
3, 4, 13
[22] Zichao Guo, Xiangyu Zhang, Haoyuan Mu, Wen Heng,
Zechun Liu, Yichen Wei, và Jian Sun. Single path one-
shot neural architecture search with uniform sampling. Trong
ECCV , 2020. 4, 7, 12
[23] Kai Han, An Xiao, Enhua Wu, Jianyuan Guo, Chun-
jing Xu, và Yunhe Wang. Transformer in transformer.
arXiv:2103.00112 , 2021. 6
[24] Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, và Ross
Girshick. Momentum contrast for unsupervised visual repre-
sentation learning. Trong CVPR , 2020. 3, 4
[25] Kaiming He, Xiangyu Zhang, Shaoqing Ren, và Jian Sun.
Deep residual learning for image recognition. Trong CVPR , 2016.
1, 5, 6, 13
[26] Shuting He, Hao Luo, Pichao Wang, Fan Wang, Hao Li,
và Wei Jiang. TransReID: Transformer-based object re-
identiﬁcation. Trong ICCV , 2021. 1
[27] Daniel Hesslow và Iacopo Poli. Contrastive embeddings for
neural architectures. arXiv:2102.04208 , 2021. 3, 7, 8, 13
[28] R Devon Hjelm, Alex Fedorov, Samuel Lavoie-Marchildon,
Karan Grewal, Phil Bachman, Adam Trischler, và Yoshua
Bengio. Learning deep representations by mutual information
estimation and maximization. Trong ICLR , 2019. 3
[29] Andrew Howard, Mark Sandler, Grace Chu, Liang-Chieh
Chen, Bo Chen, Mingxing Tan, Weijun Wang, Yukun Zhu,
Ruoming Pang, Vijay Vasudevan, Quoc V . Le, và Hartwig
Adam. Searching for MobileNetV3. Trong ICCV , 2019. 2, 3, 7,
12
[30] Andrew G Howard, Menglong Zhu, Bo Chen, Dmitry
Kalenichenko, Weijun Wang, Tobias Weyand, Marco An-
dreetto, và Hartwig Adam. Mobilenets: Efﬁcient con-
volutional neural networks for mobile vision applications.
arXiv:1704.04861 , 2017. 1, 7
[31] Jie Hu, Li Shen, và Gang Sun. Squeeze-and-excitation
networks. Trong CVPR , 2018. 1, 5, 6
[32] Yiming Hu, Yuding Liang, Zichao Guo, Ruosi Wan, Xiangyu
Zhang, Yichen Wei, Qingyi Gu, và Jian Sun. Angle-based
search space shrinking for neural architecture search. Trong
ECCV , 2020. 3

--- TRANG 10 ---
[33] Yifan Jiang, Shiyu Chang, và Zhangyang Wang. Trans-
gan: Two transformers can make one strong gan.
arXiv:2102.07074 , 2021. 1
[34] Maurice G Kendall. A new measure of rank correlation.
Biometrika , 30(1/2):81–93, 1938. 7
[35] Nikos Komodakis và Spyros Gidaris. Unsupervised repre-
sentation learning by predicting image rotations. Trong ICLR ,
2018. 2, 13
[36] A. Krizhevsky và G. Hinton. Learning multiple layers of
features from tiny images. Master's thesis, Department of
Computer Science, University of Toronto , 2009. 6, 13
[37] Changlin Li, Jiefeng Peng, Liuchun Yuan, Guangrun Wang,
Xiaodan Liang, Liang Lin, và Xiaojun Chang. Blockwisely
supervised neural architecture search with knowledge distilla-
tion. Trong CVPR , 2020. 2, 3, 6, 7, 8, 12, 13
[38] Changlin Li, Guangrun Wang, Bing Wang, Xiaodan Liang,
Zhihui Li, và Xiaojun Chang. Dynamic Slimmable Network.
Trong CVPR , 2021. 7, 13
[39] Xiang Li, Chen Lin, Chuming Li, Ming Sun, Wei Wu, Junjie
Yan, và Wanli Ouyang. Improving one-shot nas by suppress-
ing the posterior fading. Trong CVPR , 2020. 2, 3
[40] Chenxi Liu, Liang-Chieh Chen, Florian Schroff, Hartwig
Adam, Wei Hua, Alan L Yuille, và Li Fei-Fei. Auto-deeplab:
Hierarchical neural architecture search for semantic image
segmentation. Trong CVPR , 2019. 3
[41] Chenxi Liu, Piotr Doll ´ar, Kaiming He, Ross Girshick, Alan
Yuille, và Saining Xie. Are labels necessary for neural
architecture search? Trong ECCV , 2020. 2, 4, 6, 13
[42] Chenxi Liu, Barret Zoph, Maxim Neumann, Jonathon Shlens,
Wei Hua, Li-Jia Li, Li Fei-Fei, Alan Yuille, Jonathan Huang,
và Kevin Murphy. Progressive neural architecture search. Trong
ECCV , 2018. 3, 12
[43] Hanxiao Liu, Karen Simonyan, và Yiming Yang. DARTS:
differentiable architecture search. Trong ICLR , 2019. 2, 3, 7, 12
[44] Ilya Loshchilov và Frank Hutter. Sgdr: Stochastic gradient
descent with warm restarts. Trong ICLR , 2017. 13
[45] Hartmut Maennel, Ibrahim M Alabdulmohsin, Ilya O Tol-
stikhin, Robert Baldock, Olivier Bousquet, Sylvain Gelly, và
Daniel Keysers. What do neural networks learn when trained
with random labels? Trong NeurIPS , 2020. 3
[46] Bert Moons, Parham Noorzad, Andrii Skliar, Giovanni Mar-
iani, Dushyant Mehta, Chris Lott, và Tijmen Blankevoort.
Distilling optimal neural networks: Rapid search in diverse
spaces. arXiv:2012.08859 , 2020. 2, 3, 12
[47] Renato Negrinho và Geoffrey J. Gordon. Deeparchitect:
Automatically designing and training deep architectures.
arXiv:1704.08792 , 2017. 2
[48] Mehdi Noroozi và Paolo Favaro. Unsupervised learning of
visual representations by solving jigsaw puzzles. Trong ECCV ,
2016. 2
[49] Aaron van den Oord, Yazhe Li, và Oriol Vinyals. Rep-
resentation learning with contrastive predictive coding.
arXiv:1807.03748 , 2018. 3
[50] Niki Parmar, Ashish Vaswani, Jakob Uszkoreit, Lukasz
Kaiser, Noam Shazeer, Alexander Ku, và Dustin Tran. Im-
age transformer. Trong ICML , 2018. 1

[51] Jiefeng Peng, Jiqi Zhang, Changlin Li, Guangrun Wang, Xi-
aodan Liang, và Liang Lin. Pi-NAS: Improving neural
architecture search by reducing supernet training consistency
shift. Trong ICCV , 2021. 3, 12
[52] Hieu Pham, Melody Guan, Barret Zoph, Quoc Le, và Jeff
Dean. Efﬁcient neural architecture search via parameters
sharing. Trong ICML , 2018. 3, 12
[53] Hieu Pham, Melody Y . Guan, Barret Zoph, Quoc V . Le, và
Jeff Dean. Efﬁcient neural architecture search via parameter
sharing. Trong ICML , 2018. 2
[54] Esteban Real, Alok Aggarwal, Yanping Huang, và Quoc V .
Le. Regularized evolution for image classiﬁer architecture
search. Trong AAAI , 2019. 3, 5, 12
[55] Pengzhen Ren, Yun Xiao, Xiaojun Chang, Po-Yao Huang,
Zhihui Li, Xiaojiang Chen, và Xin Wang. A comprehensive
survey of neural architecture search: Challenges and solutions.
ACM Computing Surveys , 2021. 12
[56] Mark Sandler, Andrew G. Howard, Menglong Zhu, Andrey
Zhmoginov, và Liang-Chieh Chen. Mobilenetv2: Inverted
residuals and linear bottlenecks. Trong CVPR , 2018. 3
[57] Shreyas Saxena và Jakob Verbeek. Convolutional neural
fabrics. Trong NeurIPS , 2016. 3, 5
[58] Christian Sciuto, Kaicheng Yu, Martin Jaggi, Claudiu Musat,
và Mathieu Salzmann. Evaluating the search phase of neural
architecture search. Trong ICLR , 2020. 3
[59] Zhiqiang Shen, Zhankui He, và Xiangyang Xue. Meal:
Multi-model ensemble via adversarial learning. Trong AAAI ,
2019. 4
[60] Zhiqiang Shen và Marios Savvides. Meal v2: Boosting
vanilla resnet-50 to 80%+ top-1 accuracy on imagenet without
tricks. arXiv:2009.08453 , 2020. 4
[61] Han Shi, Renjie Pi, Hang Xu, Zhenguo Li, James Kwok, và
Tong Zhang. Bridging the gap between sample-based and
one-shot neural architecture search with bonas. Trong NeurIPS ,
2020. 12
[62] Aravind Srinivas, Tsung-Yi Lin, Niki Parmar, Jonathon
Shlens, Pieter Abbeel, và Ashish Vaswani. Bottleneck trans-
formers for visual recognition. Trong CVPR , 2021. 1, 2, 5, 6
[63] Mingxing Tan, Bo Chen, Ruoming Pang, Vijay Vasudevan,
Mark Sandler, Andrew Howard, và Quoc V . Le. Mnasnet:
Platform-aware neural architecture search for mobile. Trong
CVPR , 2019. 2, 3, 7, 12
[64] Mingxing Tan và Quoc V . Le. Efﬁcientnet: Rethinking
model scaling for convolutional neural networks. Trong ICML ,
2019. 1, 2, 3, 6, 7, 12, 13
[65] Yonglong Tian, Dilip Krishnan, và Phillip Isola. Contrastive
multiview coding. arXiv:1906.05849 , 2019. 3
[66] Hugo Touvron, Matthieu Cord, Matthijs Douze, Francisco
Massa, Alexandre Sablayrolles, và Herv ´e J´egou. Training
data-efﬁcient image transformers & distillation through atten-
tion. Trong ICML , 2021. 1, 5, 6, 13
[67] Alvin Wan, Xiaoliang Dai, Peizhao Zhang, Zijian He, Yuan-
dong Tian, Saining Xie, Bichen Wu, Matthew Yu, Tao Xu,
Kan Chen, et al. Fbnetv2: Differentiable neural architecture
search for spatial and channel dimensions. Trong CVPR , 2020. 7
[68] Xiaolong Wang, Ross Girshick, Abhinav Gupta, và Kaiming
He. Non-local neural networks. Trong CVPR , 2018. 5

--- TRANG 11 ---
[69] Chen Wei, Yiping Tang, Chuang Niu, Haihong Hu, Yue Wang,
và Jimin Liang. Self-supervised representation learning for
evolutionary neural architecture search. arXiv:2011.00186 ,
2020. 3
[70] Bichen Wu, Xiaoliang Dai, Peizhao Zhang, Yanghan Wang,
Fei Sun, Yiming Wu, Yuandong Tian, Peter Vajda, Yangqing
Jia, và Kurt Keutzer. Fbnet: Hardware-aware efﬁcient con-
vnet design via differentiable neural architecture search. Trong
CVPR , 2019. 3, 7, 12
[71] Zhirong Wu, Yuanjun Xiong, Stella X Yu, và Dahua Lin.
Unsupervised feature learning via non-parametric instance
discrimination. Trong CVPR , 2018. 3
[72] Shen Yan, Yu Zheng, Wei Ao, Xiao Zeng, và Mi Zhang.
Does unsupervised architecture representation learning help
neural architecture search? Trong NeurIPS , 2020. 3
[73] Antoine Yang, Pedro M. Esperan c ¸a, và Fabio Maria Carlucci.
NAS evaluation is frustratingly hard. Trong ICLR , 2020. 3
[74] Chris Ying, Aaron Klein, Eric Christiansen, Esteban Real,
Kevin Murphy, và Frank Hutter. Nas-bench-101: Towards
reproducible neural architecture search. Trong ICML , 2019. 3
[75] Yang You, Igor Gitman, và Boris Ginsburg. Scaling sgd
batch size to 32k for imagenet training. arXiv:1708.03888 ,
2017. 13
[76] Jiahui Yu và Thomas Huang. Autoslim: Towards one-shot
architecture search for channel numbers. arXiv:1903.11728 ,
2019. 7, 13
[77] Jiahui Yu và Thomas S. Huang. Universally slimmable
networks and improved training techniques. Trong ICCV , 2019.
7, 13
[78] Jiahui Yu, Linjie Yang, Ning Xu, Jianchao Yang, và
Thomas S. Huang. Slimmable neural networks. Trong ICLR ,
2019. 7, 13
[79] Li Yuan, Yunpeng Chen, Tao Wang, Weihao Yu, Yujun Shi,
Francis EH Tay, Jiashi Feng, và Shuicheng Yan. Tokens-
to-token vit: Training vision transformers from scratch on
imagenet. Trong ICCV , 2021. 1, 6, 13
[80] Arber Zela, Julien Siems, và Frank Hutter. Nas-bench-
1shot1: Benchmarking and dissecting one-shot neural archi-
tecture search. Trong ICLR , 2019. 3, 12
[81] Chiyuan Zhang, Samy Bengio, Moritz Hardt, Benjamin Recht,
và Oriol Vinyals. Understanding deep learning requires
rethinking generalization. arXiv:1611.03530 , 2016. 3
[82] Miao Zhang, Huiqi Li, Shirui Pan, Xiaojun Chang, Zongyuan
Ge, và Steven W. Su. Differentiable neural architecture
search in equivalent space with exploration enhancement. Trong
NeurIPS , 2020. 12
[83] Miao Zhang, Huiqi Li, Shirui Pan, Xiaojun Chang, và
Steven W. Su. Overcoming multi-model forgetting in one-shot
NAS with diversity maximization. Trong CVPR , 2020. 12
[84] Mingyang Zhang và Linlin Ou. Stage-wise channel pruning
for model compression. arXiv:2011.04908 , 2020. 2, 3
[85] Man Zhang, Yong Zhou, Jiaqi Zhao, Shixiong Xia, Jiaqi
Wang, và Zizheng Huang. Semi-supervised blockwisely
architecture search for efﬁcient lightweight generative adver-
sarial network. Pattern Recognition , 112:107794, 2021. 2,
3

[86] Richard Zhang, Phillip Isola, và Alexei A Efros. Colorful
image colorization. Trong ECCV , 2016. 2
[87] Xuanyang Zhang, Pengfei Hou, Xiangyu Zhang, và Jian
Sun. Neural architecture search with random labels. Trong CVPR ,
2021. 2, 3, 4, 7, 12
[88] Sixiao Zheng, Jiachen Lu, Hengshuang Zhao, Xiatian Zhu,
Zekun Luo, Yabiao Wang, Yanwei Fu, Jianfeng Feng, Tao Xi-
ang, Philip HS Torr, et al. Rethinking semantic segmentation
from a sequence-to-sequence perspective with transformers.
Trong CVPR , 2021. 1
[89] Zhao Zhong, Junjie Yan, Wei Wu, Jing Shao, và Cheng-
Lin Liu. Practical block-wise neural network architecture
generation. Trong CVPR , 2018. 2
[90] Xizhou Zhu, Weijie Su, Lewei Lu, Bin Li, Xiaogang Wang,
và Jifeng Dai. Deformable DETR: Deformable transformers
for end-to-end object detection. Trong ICLR , 2021. 1
[91] Chengxu Zhuang, Alex Lin Zhai, và Daniel Yamins. Local
aggregation for unsupervised learning of visual embeddings.
Trong ICCV , 2019. 3
[92] Barret Zoph và Quoc V . Le. Neural architecture search with
reinforcement learning. Trong ICLR , 2017. 2, 12
[93] Barret Zoph, Vijay Vasudevan, Jonathon Shlens, và Quoc V
Le. Learning transferable architectures for scalable image
recognition. Trong CVPR , 2018. 3

--- TRANG 12 ---
BossNAS: Khám phá CNN-transformers Lai với Tìm kiếm Kiến trúc Mạng Neural Tự giám sát theo Khối
Tài liệu Bổ sung
Changlin Li1, Tao Tang2, Guangrun Wang3;4, Jiefeng Peng3, Bing Wang5,
Xiaodan Liang2*, Xiaojun Chang6
1GORSE Lab, Dept. of DSAI, Monash University2Sun Yat-sen University3DarkMatter AI Research
4University of Oxford5Alibaba Group6RMIT University
changlin.li@monash.edu,
ftrent.tangtao,wanggrun,jiefengpeng,xdliang328 g@gmail.com,
fengquan.wb@alibaba-inc.com, xiaojun.chang@rmit.edu.au
A. Phụ lục
A.1. Đánh giá ngắn gọn về NAS
Các phương pháp NAS nhằm tự động tối ưu hóa các kiến trúc mạng neural bằng cách khám phá các không gian tìm kiếm với các thuật toán tìm kiếm và đánh giá các kiến trúc bằng các sơ đồ đánh giá . Các phương pháp NAS có thể được chia thành hai danh mục tùy thuộc vào sơ đồ đánh giá được sử dụng, tức là NAS đa thử và NAS chia sẻ trọng số. Các phương pháp NAS đa thử [92,2,54,63,42,83] đánh giá tất cả các kiến trúc được lấy mẫu bằng cách huấn luyện chúng từ đầu, làm cho quá trình này rất tốn kém về mặt tính toán và khó triển khai trên các tập dữ liệu lớn. Chúng hoặc thực hiện đánh giá kiến trúc bằng cách huấn luyện trên các tập dữ liệu tương đối nhỏ ( ví dụ: CIFAR-10) [ 92,2,54] hoặc bằng cách huấn luyện trong vài epochs đầu ( ví dụ: 5 epochs) [ 63] trên ImageNet.
Để tránh huấn luyện lặp lại các mạng ứng viên, các phương pháp NAS chia sẻ trọng số [ 7,43,18,1,6,13,82] tối ưu hóa một supernet mã hóa toàn bộ không gian tìm kiếm, sau đó đánh giá mỗi kiến trúc ứng viên theo trọng số được thừa kế từ supernet. Trong số đó, các cách tiếp cận dựa trên gradient [43,7,70] và các cách tiếp cận dựa trên sampler [ 52,61] đồng thời tối ưu hóa trọng số của supernet và các yếu tố (hoặc agent) được sử dụng để chọn kiến trúc; về phần của chúng, các cách tiếp cận một lần1[22,15,6,4,51] tối ưu hóa supernet trước khi thực hiện tìm kiếm với trọng số supernet được đóng băng. Chúng tôi tham khảo [55] để có đánh giá NAS toàn diện hơn.
*Tác giả Liên hệ.
1Trong bài báo này, theo các công trình tiên phong SMASH [ 6] và One-shot [ 4], khi chúng tôi đề cập đến các phương pháp NAS một lần, chúng tôi đang thảo luận về những cái kết hợp các phương pháp chia sẻ trọng số hai giai đoạn (tức là, một giai đoạn huấn luyện supernet và một giai đoạn tìm kiếm) thay vì NAS chia sẻ trọng số tổng quát được thảo luận trong [80].

A.2. Chi tiết Triển khai
Các không gian tìm kiếm. Chúng tôi đánh giá phương pháp của chúng tôi trên ba không gian tìm kiếm:
•Không gian tìm kiếm HyTra. Phần đầu của các mạng trong không gian tìm kiếm này là stem ResNet cổ điển giảm độ phân giải không gian bằng hệ số 4 với một layer convolution 7×7 stride và một layer max-pooling. Nó chứa L = 16 choice block layers tổng cộng, giống như ResNet50. Trước choice block layer đầu tiên, đầu vào có thể được down-sample thêm đến các scales khác nhau. Module downsampling bao gồm nhiều convolutions 3×3 với stride 2. Tại mỗi choice block layer, độ phân giải không gian có thể giữ nguyên hoặc được giảm xuống một nửa scale của nó, trừ khi đạt được scale nhỏ nhất 1/32. Như được giới thiệu trong Phần 4, không gian tìm kiếm này chứa hai lựa chọn ứng viên khác biệt: fResConv;ResAttg. Vì các khối transformer tốn kém ở các scales đầu tiên, chúng tôi chỉ cho phép lựa chọn ResAtt ở hai scales cuối ( tức là 1/16 và 1/32). Tổng kích thước của không gian tìm kiếm lai đầy thử thách này là khoảng 2.8×106.
•Không gian tìm kiếm MBConv. Không gian tìm kiếm giống MobileNet và các biến thể của nó thường được sử dụng như benchmark cho các phương pháp NAS gần đây [ 63,29,64,7,70,15,37,46,87]. Theo Li et. al. [37], chúng tôi sử dụng một không gian tìm kiếm với 18 layers và mỗi layer chứa 4 khối MobileNet ứng viên (tổ hợp của kernel size f3;5g và reduction ratio f3;6g). Điều này dẫn đến một không gian tìm kiếm lớn chứa khoảng 418≈6.91×1010 kiến trúc.
•NATS-Bench SS. Không gian tìm kiếm kích thước NATS-Bench SS[17] là một không gian tìm kiếm cấu hình kênh được xây dựng trên một kiến trúc dựa trên cell cố định với 5 layers, trong đó layers thứ 2 và thứ 4 có tỷ lệ down-sample là 2. Số kênh trong mỗi layer được chọn từ f8, 16, 24, 32, 40, 48, 56, 64 g. SS có 85 = 32768 ứng viên kiến trúc tổng cột. Các ứng viên có số kênh khác nhau trong supernet của chúng tôi chia sẻ trọng số theo cách slimmable [ 78,77,76,38,9]. Chúng tôi chia supernet thành 3 khối, theo kích thước không gian.
Tập dữ liệu. Các tập dữ liệu chúng tôi sử dụng để đánh giá và phân tích phương pháp của chúng tôi bao gồm ImageNet [ 16], CIFAR-10 và CIFAR-100 [36]. ImageNet là một tập dữ liệu quy mô lớn chứa 1.2 M hình ảnh tập huấn luyện và 50 K hình ảnh tập val trong 1000 lớp. Chúng tôi ngẫu nhiên lấy mẫu 50 K hình ảnh từ tập train gốc để tạo thành một tập NAS-val cho đánh giá kiến trúc và sử dụng phần còn lại làm tập NAS-train cho huấn luyện supernet. Không có nhãn nào được sử dụng trong quá trình huấn luyện và tìm kiếm của phương pháp NAS của chúng tôi. Cuối cùng, các kiến trúc được tìm kiếm của chúng tôi được huấn luyện lại từ đầu trên tập train và được đánh giá trên tập val. Đối với CIFAR-10 và CIFAR-100 [36], chúng tôi sử dụng các phân chia được đề xuất trong NATS-Bench [ 17]. CIFAR-10 được chia thành 25 K tập train, 25 K tập val, và 10 K tập test. CIFAR-100 được chia thành 50 K tập train, 5 K tập val, và 5 K tập test. Độ chính xác cuối cùng của các kiến trúc được tìm kiếm được truy vấn từ NATS-Bench SS[17].
Chi tiết huấn luyện.
Chúng tôi huấn luyện mỗi khối của supernet BossNAS trong 20 epochs bao gồm 1 epoch warm-up tuyến tính trên ImageNet. Đối với các tập dữ liệu CIFAR tương đối nhỏ hơn, chúng tôi mở rộng nó thành 30 epochs. Trong mỗi bước huấn luyện, chúng tôi ngẫu nhiên lấy mẫu 4 đường dẫn cho ensemble bootstrapping. Các siêu tham số khác cho huấn luyện tự giám sát của supernet tuân theo chặt chẽ BYOL [ 21], chúng tôi sử dụng optimizer LARS [ 75] với lịch trình tỷ lệ học cosine decay [ 44]. Tỷ lệ học cơ sở được đặt thành 4.8 cho tổng batchsize 4096.
Đối với ImageNet retraining của các mô hình BossNet-T , chúng tôi tuân theo tương tự với DeiT [ 66], vì chúng tôi thấy nó mạnh mẽ cho cả CNNs và transformers. Cụ thể hơn, chúng tôi sử dụng optimizer AdamW với tỷ lệ học ban đầu 1e-3 và scheduler tỷ lệ học cosine, cho tổng batch size 1024. Weight decay được đặt thành 0.05. Chúng tôi sử dụng mô hình EMA với tỷ lệ decay 0.99996 theo [ 79]. Vui lòng tham khảo DeiT [ 66] để biết thêm chi tiết về data-augmentation và regularization.
Đối với ImageNet retraining của các mô hình BossNet-M , chúng tôi tuân theo chặt chẽ EfﬁcientNet [ 64]. Chúng tôi sử dụng batchsize 4096, optimizer RMSprop với momentum 0.9 và tỷ lệ học ban đầu 0.256 giảm 0.97 mỗi 2.4 epochs. Vui lòng tham khảo EfﬁcientNet [64] để biết thêm chi tiết về các cài đặt khác.
Re-implementation của các phương pháp NAS khác trên HyTra.
Đối với DNA [ 37], chúng tôi sử dụng ResNet-50 [ 25] làm mô hình giáo viên. Chúng tôi chia supernet thành bốn khối, với bốn layers trong mỗi khối, và huấn luyện mỗi khối trong 20 epochs. Các đặc trưng trung gian của mỗi khối của student supernet và giáo viên đều được downsample với global pooling và được chiếu với một fully-connected layer trước khi tính toán distillation loss, vì scale của các khối ứng viên khác nhau không giống nhau trong không gian tìm kiếm HyTra. Các cài đặt khác tuân theo chặt chẽ DNA [37].
Đối với UnNAS [ 41], chúng tôi áp dụng tác vụ pretext dự đoán xoay [35] (Rot), vì tính đơn giản của nó. Theo [41], chúng tôi sử dụng ba extra stride-2 convolution layers ở đầu supernet để giảm độ phân giải không gian. Supernet được huấn luyện trong 2 epochs như trong [41].
A.3. Phân tích Bổ sung trên NATS-Bench SS
So sánh đánh giá kiến trúc. Chúng tôi so sánh với phương pháp NAS dựa trên predictor CE [ 27] bằng độ chính xác đánh giá kiến trúc trên CIFAR-10 và CIFAR-100. Như được hiển thị trong Hình 8, chúng tôi so sánh hai phương pháp NAS bằng cách vẽ tương quan của đánh giá kiến trúc và độ chính xác thực của 3000 kiến trúc được lấy mẫu ngẫu nhiên từ không gian tìm kiếm kích thước NATS-Bench SS[17]. Các kiến trúc với BossNAS tạo thành mẫu scatter dày đặc và spindle hơn so với CE trên cả hai tập dữ liệu. Hơn nữa, như được đo lường định lượng trong Bảng 6, BossNAS vượt trội so với CE bằng một khoảng cách lớn ( 0.11↑ ρ và 0.16↑ ρ) trong cả hai tập dữ liệu.

--- TRANG 13 ---
Method C-10 C-100 R
FBNet v2 [67] 93.14 70.72 - - -
TuNAS [5] 92.78 70.11 - - -
CE [27] 90.55 70.78 0.43 0.60 0.60
BossNAS 93.29 70.86 0.59 0.76 0.79
Table 4: So sánh độ chính xác mô hình được tìm kiếm và độ chính xác đánh giá kiến trúc của các phương pháp NAS khác nhau trên NATS-Bench SS (C-10: CIFAR-10 , C-100: CIFAR-100 ).

Training Evaluation R
Supv:distill. Supv:distill. 0.62 0.77 0.83
Supv:class. Supv:class. 0.46 0.65 0.71
Unsupv:bootstrap. Unsupv. eval 0.12 0.15 0.28
Unsupv. EB Supv:linear eval 0.55 0.73 0.79
Unsupv. EB Unsupv. eval 0.65 0.78 0.85
Table 5: Phân tích ablation của các phương pháp huấn luyện và các phương pháp đánh giá trên Không gian Tìm kiếm MBConv .

Dataset Method R
CIFAR-10 CE [27] 0.42 0.60 0.59
BossNAS 0.53 0.73 0.72
CIFAR-100 CE [27] 0.43 0.60 0.60
BossNAS 0.59 0.76 0.79
Table 6: Độ chính xác đánh giá kiến trúc trên NATS-Bench SS với các tập dữ liệu CIFAR .

828486889092942.92
2.90
2.88
2.86
2.84
(a) BossNAS trên CIFAR-10 .
80 82 84 86 88 9087.087.287.487.687.888.088.288.4
 (b) CE [27] trên CIFAR-10 .
40 50 60 703.050
3.025
3.000
2.975
2.950
2.925
2.900
2.875
(c) BossNAS trên CIFAR-100 .
3540455055606570575859606162636465
 (d) CE [27] trên CIFAR-100 .
Figure 8: So sánh đánh giá kiến trúc và độ chính xác thực của nó của BossNAS và CE [ 27] của chúng tôi trên NATS-Bench SS với các tập dữ liệu CIFAR .

0 200.00.20.4
0 200.000.250.500.75
0 200.00.20.40.6
Kendall 
Spearman 
Pearson R(a) Tương quan xếp hạng trong quá trình huấn luyện supernet trên CIFAR-10 .
0 200.00.20.40.6
0 200.000.250.500.75
0 200.000.250.500.75
Kendall 
Spearman 
Pearson R
(b) Tương quan xếp hạng trong quá trình huấn luyện supernet với CIFAR-100 .
Figure 9: Hành vi hội tụ của BossNAS trên NATS-Bench SS và các tập dữ liệu CIFAR .

Hành vi Hội tụ. Chúng tôi minh họa độ chính xác đánh giá kiến trúc của BossNAS trong giai đoạn huấn luyện supernet 30 epoch của nó trên các tập dữ liệu CIFAR trong Hình 9. Độ chính xác đánh giá kiến trúc tăng nhanh và ổn định với dao động nhỏ, theo cách tương tự như trên không gian tìm kiếm MBConv (Hình 7). Đặc biệt, độ chính xác đánh giá kiến trúc của BossNAS của chúng tôi hội tụ đến một kết quả thỏa mãn, 0.76, một cách mượt mà và nhanh chóng trong vòng chỉ 20 epochs trên CIFAR-100, và tiếp tục ổn định trong 10 epochs tiếp theo.

1
1/4
1/8
1/161 2 3 4 L L-1......5 L-2
1/32
(a) Kiến trúc của ResNet50-T.
1
1/4
1/8
1/161 2 3 4 L L-1......5 L-2
1/32
(b) Kiến trúc của ViT-T/16.
1
1/4
1/8
1/161 2 3 4 L L-1......5 L-2
1/32
(c) Kiến trúc của BoTNet-T.
Figure 10: Trực quan hóa các Kiến trúc Được thiết kế bởi Con người trong HyTra. Các nút màu xanh ký hiệu ResConv và các nút màu đỏ ký hiệu ResAtt .

A.4. Trực quan hóa các Kiến trúc Được thiết kế bởi Con người trong HyTra
Các kiến trúc của ResNet50-T, ViT-T/16 và BoTNet50-T từ không gian tìm kiếm HyTra của chúng tôi được minh họa trong Hình 10. Kiến trúc của chúng tuân theo càng gần càng tốt với các kiến trúc của các nguyên mẫu của chúng.

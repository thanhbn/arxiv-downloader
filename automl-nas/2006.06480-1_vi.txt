# 2006.06480.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/automl-nas/2006.06480.pdf
# Kích thước file: 6168025 bytes

===============================================
NỘI DUNG FILE PDF
===============================================


--- TRANG 1 ---
1
Các Chiến lược Thích ứng cho Học Máy Tự động
trên Dữ liệu Phát triển
Bilge Celik và Joaquin Vanschoren
Tóm tắt —Các hệ thống Học Máy Tự động (AutoML) đã được chứng minh là xây dựng hiệu quả các mô hình tốt cho các tập dữ liệu mới.
Tuy nhiên, thường không rõ ràng chúng có thể thích ứng tốt như thế nào khi dữ liệu phát triển theo thời gian. Mục tiêu chính của nghiên cứu này là hiểu
ảnh hưởng của concept drift đối với hiệu suất của các phương pháp AutoML, và những chiến lược thích ứng nào có thể được sử dụng để làm cho chúng
mạnh mẽ hơn trước những thay đổi trong dữ liệu cơ bản. Vì mục đích đó, chúng tôi đề xuất 6 chiến lược thích ứng concept drift và đánh giá hiệu quả của chúng
trên nhiều phương pháp AutoML khác nhau để xây dựng các pipeline học máy, bao gồm tối ưu hóa Bayesian, lập trình di truyền, và
tìm kiếm ngẫu nhiên với stacking tự động. Những điều này được đánh giá thực nghiệm trên các luồng dữ liệu thế giới thực và tổng hợp với các loại
concept drift khác nhau. Dựa trên phân tích này, chúng tôi đề xuất các cách để phát triển các kỹ thuật AutoML phức tạp và mạnh mẽ hơn.
Từ khóa chỉ mục —AutoML, luồng dữ liệu, concept drift, chiến lược thích ứng
F
1 GIỚI THIỆU
Lĩnh vực học máy tự động (AutoML) nhằm mục đích
tự động thiết kế và xây dựng các hệ thống học máy,
thay thế việc thử nghiệm thủ công bằng việc ra quyết định
có hệ thống, dựa trên dữ liệu [43]. Điều này làm cho học máy
mạnh mẽ, tiên tiến có thể tiếp cận được với một phạm vi
rộng hơn nhiều các nhà thực hành và nhà khoa học lĩnh vực.

Mặc dù AutoML đã được chứng minh là rất hiệu quả
và thậm chí cạnh tranh với các chuyên gia học máy con người [13], [24],
[29], [36], chúng thường chỉ được đánh giá trên các tập dữ liệu
tĩnh [43]. Tuy nhiên, dữ liệu thường không tĩnh, nó phát triển. Kết quả là,
các mô hình đã được tìm thấy hoạt động tốt ban đầu có thể
trở nên không tối ưu khi dữ liệu thay đổi theo thời gian. Thực tế,
hầu hết các kỹ thuật AutoML giả định rằng các đánh giá trước đó
mãi mãi đại diện cho dữ liệu mới, và do đó có thể
không thích ứng được với các thay đổi trong phân phối cơ bản của
dữ liệu, còn được gọi là concept drift [5], [23], [31].

Đã có rất ít công trình về việc tự động hóa
thiết kế các pipeline học máy trong các cài đặt có concept drift. Điều đó sẽ yêu cầu rằng quá trình AutoML,
việc tìm kiếm tự động cho các pipeline tối ưu, được thích ứng để
nó có thể đối phó với concept drift và điều chỉnh các pipeline
theo thời gian, bất cứ khi nào dữ liệu thay đổi quá mạnh đến mức
cần thiết kế lại hoặc điều chỉnh lại pipeline. Đơn giản là chạy lại
các kỹ thuật AutoML từ đầu trên dữ liệu mới thường
không khả thi, vì các kỹ thuật AutoML thường
tốn kém về mặt tính toán, và trong hầu hết các cài đặt học trực tuyến
hiệu suất dự đoán tốt phải được đạt được trong
một cửa sổ thời gian hạn chế.

Để thực sự hiểu các ảnh hưởng của concept drift và cách
đối phó với nó trong các hệ thống AutoML, chúng tôi nghiên cứu có hệ thống
cách các kỹ thuật AutoML khác nhau bị ảnh hưởng bởi các loại
concept drift khác nhau. Chúng tôi phát hiện ra rằng, trong khi các phương pháp AutoML này
thường hoạt động rất tương tự trên các tập dữ liệu tĩnh
[20], chúng mỗi cái đều phản ứng rất khác nhau với các loại

B. Celik và J. Vanschoren làm việc tại Đại học Công nghệ Eindhoven,
Eindhoven, Hà Lan.
E-mail: B.Celik.Aydin@tue.nl
Bản thảo nhận được ...concept drift khác nhau. Chúng tôi đề xuất sáu chiến lược thích ứng khác nhau
để đối phó với concept drift và triển khai chúng trong các
thư viện AutoML mã nguồn mở. Chúng tôi thấy rằng những điều này thực sự có thể được
sử dụng hiệu quả, mở đường cho các kỹ thuật AutoML mới
mạnh mẽ chống lại dữ liệu phát triển.

Cài đặt học trực tuyến đang được xem xét là một cài đặt
trong đó dữ liệu có thể được đệm thành các lô sử dụng cửa sổ trượt. Do đó, chúng tôi giả định bộ nhớ hạn chế và thời gian hạn chế
để đưa ra dự đoán mới, và đánh giá hiệu suất
của các chiến lược thích ứng khác nhau được ghép nối với các phương pháp AutoML khác nhau theo đó. Các cài đặt trực tuyến trong đó chỉ một
thể hiện mới phù hợp với bộ nhớ và chỉ có thể được xem một lần
(đơn pass) nằm ngoài phạm vi của bài báo này.

Bài báo được tổ chức như sau. Đầu tiên, chúng tôi hình thức hóa
vấn đề trong Phần 2. Phần 3 bao gồm các công trình liên quan
cũng như các hệ thống AutoML và kỹ thuật học trực tuyến
có liên quan nhất. Các chiến lược thích ứng của chúng tôi cho các phương pháp AutoML
được mô tả trong Phần 4. Phần 5 chi tiết cài đặt
thực nghiệm của chúng tôi để đánh giá các chiến lược này, và kết quả
được phân tích trong Phần 6. Phần 7 kết luận.

2 ĐỊNH NGHĨA VẤN ĐỀ
2.1 AutoML
Các phương pháp AutoML nhằm thiết kế một chuỗi hoạt động tối ưu
để biến đổi dữ liệu thô thành đầu ra mong muốn, chẳng hạn như
một pipeline học máy hoặc một kiến trúc mạng neural [27].
Trong bài báo này, chúng tôi quan tâm đến việc tối ưu hóa các
pipeline học máy, có thể được định nghĩa chính thức như một
vấn đề lựa chọn thuật toán kết hợp và tối ưu hóa siêu tham số
(CASH) [36]. Cho một tập huấn luyện Xtr với mục tiêu
ytr, và một tập các thuật toán A={A1;:::;Ap}, mỗi cái với một
không gian siêu tham số {Θ1;:::;Θp}, vấn đề CASH
được định nghĩa là tìm thuật toán A* và cài đặt siêu tham số
θ* để tối thiểu hóa một hàm mất mát L (ví dụ mất mát
phân loại sai) được áp dụng cho một mô hình được huấn luyện trên
{Xtr;ytr}, và

--- TRANG 2 ---
2
được đánh giá trên một tập validation {Xval;yval}, ví dụ với
k-fold cross validation trong đó {Xi;yi} là một tập con của tập dữ liệu:
A*; θ* ∈ argmin ∀A∈A ∀θ∈Θ 1/k ∑k i=1 L(Aθ; {Xi tr;yi tr}; {Xi val;yi val}) (1)

Thay vì một thuật toán học duy nhất, A có thể là một pipeline đầy đủ
bao gồm tiền xử lý dữ liệu, tiền xử lý đặc trưng, meta-learning và hậu xử lý mô hình, điều này thường
tạo ra một không gian tìm kiếm lớn các pipeline và
cấu hình có thể. Điều này dẫn đến những đánh đổi quan trọng giữa
hiệu quả tính toán (ví dụ thời gian huấn luyện và dự đoán)
và độ chính xác [43].

2.2 Học trực tuyến và concept drift
Trong học trực tuyến, các mô hình được huấn luyện và sử dụng để dự
đoán mà không có tất cả dữ liệu huấn luyện từ trước. Luồng dữ liệu
nên được coi là vô hạn dài, phải
được xử lý theo thứ tự, và chỉ một phần hạn chế của nó có thể
ở trong bộ nhớ tại bất kỳ thời điểm nào [16]. Thường xuyên, các điểm
dữ liệu được xử lý trong các lô nhỏ, cũng được gọi là cửa sổ.
Quá trình tạo ra dữ liệu có thể thay đổi theo thời gian,
dẫn đến concept drift, một sự dịch chuyển thường không thể dự đoán được
theo thời gian trong phân phối cơ bản của dữ liệu.

Xem xét một luồng dữ liệu {X;y} được tạo ra từ một
hàm mật độ xác suất kết hợp p(X;y), cũng được gọi là khái niệm
mà chúng ta nhằm học. Concept drift có thể được mô tả như:
∃X : pt0(X;y) ≠ pt1(X;y) (2)
trong đó pt0(X;y) và pt1(X;y) đại diện cho các hàm xác suất
kết hợp tại thời điểm t0 và t1, tương ứng [16]. Webb et al. [41]
phân loại thêm concept drift thành 9 lớp chính dựa trên
một số đặc điểm định lượng và định tính, trong đó
thời gian và độ lớn của drift có tác động lớn nhất
đến việc lựa chọn learner và thích ứng. Thời gian drift
là khoảng thời gian trong đó một khái niệm ban đầu (a0, tại thời điểm
t0) drifts đến một khái niệm kết quả (a1, tại thời điểm t1):
Duration(a0;a1) = t1 - t0 (3)

Abrupt (đột ngột) drift là một thay đổi trong khái niệm xảy ra
trong một cửa sổ thời gian nhỏ ε:
AbruptDrift ⟹ Duration(a0;a1) < ε (4)

Độ lớn drift là khoảng cách giữa các khái niệm ban đầu và
kết quả trong khoảng thời gian drift [t0;t1]:
Magnitude(t0;t1) = D(a0;a1) (5)
trong đó D là một hàm khoảng cách phân phối định
lượng sự khác biệt giữa các khái niệm tại hai thời điểm.
Webb et al. [41] lập luận rằng độ lớn sẽ có tác động lớn
đến khả năng thích ứng của learner với drift. Một minor
abrupt drift có thể yêu cầu tinh chỉnh một mô hình, trong khi major
abrupt drift có thể yêu cầu từ bỏ mô hình hoàn toàn.

Trong gradual drift, độ lớn drift trong một khoảng thời gian
nhỏ hơn một sự khác biệt tối đa giữa các khái niệm:
GradualDrift ⟹ ∀t ∈ [t0;t1] D(a0;a1) < δ (6)

Việc hiểu rõ động lực của concept drift
và ảnh hưởng của nó đối với chiến lược tìm kiếm được sử dụng bởi kỹ thuật AutoML
là rất quan trọng để thiết kế một chiến lược thích ứng
thành công. Các thuật toán phát hiện drift (ví dụ DDM [17]) là một phần
chính của các chiến lược này. Chúng xác định vị trí của các drift
để cảnh báo cho learner để nó có thể phản ứng kịp thời.

3 CÔNG TRÌNH LIÊN QUAN
Theo hiểu biết tốt nhất của chúng tôi, đã có rất ít
công trình nhằm hiểu cách các kỹ thuật AutoML có thể
được thích ứng để đối phó với concept drift, mặc dù có
bằng chứng rõ ràng rằng hầu hết các kỹ thuật AutoML hiện tại đều
bị ảnh hưởng mạnh bởi nó. Một thách thức AutoML gần đây tập trung vào
concept drift và phát hiện ra rằng các phương pháp AutoML hiện tại
đã không thích ứng với concept drift trong khung thời gian hạn chế, và
bị vượt qua bởi các kỹ thuật học tăng dần, đặc biệt
là gradient boosting, với tiền xử lý thông minh [12].

Tồn tại công trình thú vị về việc tăng tốc tối ưu hóa siêu tham số bằng transfer learning từ các nhiệm vụ trước [22], hoặc continual learning [9] trong đó mục tiêu là thích ứng
các mô hình (deep learning) với các nhiệm vụ mới mà không quên
thảm khốc. Tuy nhiên, những điều này không xem xét concept drift
trong các nhiệm vụ đơn, và dữ liệu phát triển không thể luôn dễ dàng được
chia thành nhiều nhiệm vụ. Trong tài liệu học trực tuyến
tồn tại nhiều kỹ thuật để xử lý các loại concept drift khác nhau [16], nhưng những điều này thường thích ứng một mô hình
được chọn trước đó hơn là thiết kế lại toàn bộ các pipeline học máy, như là mục tiêu ở đây. Kết quả sớm thú vị
trong lựa chọn thuật toán đã được thu được bằng cách sử dụng meta-learning
để đề xuất các thuật toán trên các luồng khác nhau [15]. Gần đây hơn,
các kỹ thuật điều chỉnh siêu tham số đã được đề xuất
để khởi động lại điều chỉnh siêu tham số khi drift
được phát hiện [8], [40]. Tuy nhiên, những điều này được gắn với các
kỹ thuật tối ưu hóa cụ thể cho các thuật toán đơn, trong khi chúng tôi nhằm
thích ứng một cách tổng quát các kỹ thuật AutoML để thiết kế lại hoặc tối ưu hóa lại toàn bộ pipeline. Cũng tồn tại các chiến lược để thích ứng
các mô hình đã học trước đó bởi các thuật toán học trực tuyến với
dữ liệu mới, thường thông qua ensembling [2], nhưng những điều này không
tối ưu hóa lại các thuật toán hoặc pipeline tự chúng.

Có một số công trình thú vị trong tối ưu hóa mà
có thể được tận dụng. Ví dụ, tồn tại
công trình cho phép các mô hình Bayesian phát hiện các điểm thay đổi
trong quá trình tối ưu hóa [18], [19], có thể
được sử dụng để thích ứng các kỹ thuật Bayesian Optimization
được sử dụng trong một số phương pháp AutoML, nhưng theo hiểu biết tốt nhất
của chúng tôi điều này chưa được khám phá trước đó.

Gần giống nhất với công trình của chúng tôi là một nghiên cứu gần đây của
Madrid et al. [28], trong đó một phương pháp AutoML cụ thể (autosklearn) được
mở rộng với phát hiện concept drift và hai phương pháp thích ứng mô hình. Trong bài báo này, tuy nhiên, chúng tôi mở rộng không chỉ một,
mà một loạt các kỹ thuật AutoML rất khác nhau. Chúng tôi cũng
tạo ra các tập dữ liệu với các loại concept drift rất khác nhau
để có thể hiểu cách các phương pháp AutoML này
mỗi cái bị ảnh hưởng theo cách riêng của chúng, cũng như tốc độ chúng
phục hồi từ concept drift, nếu có. Ngoài ra, chúng tôi đề xuất
và đánh giá năm kỹ thuật thích ứng khác nhau hoàn toàn
khác biệt trong yêu cầu tài nguyên và cách chúng
huấn luyện các mô hình ứng viên. Tất cả những điều này cung cấp bằng chứng thực nghiệm rõ ràng
và hướng dẫn về cách phát triển các kỹ thuật AutoML mới
phù hợp hơn với dữ liệu phát triển.

--- TRANG 3 ---
3
Trong phần còn lại của phần này, chúng tôi sẽ thảo luận về các
kỹ thuật và hệ thống AutoML được sử dụng trong nghiên cứu này.

3.1 Các kỹ thuật và hệ thống AutoML
Bayesian Optimization (BO) là một trong những phương pháp AutoML
được sử dụng thành công nhất trong tài liệu [7]. Để hiệu quả
khám phá không gian lớn các cấu hình pipeline có thể,
nó huấn luyện một mô hình surrogate xác suất trên các
cấu hình đã được đánh giá trước đó để dự đoán những cấu hình
chưa thấy nào nên được thử tiếp theo. Sự đánh đổi trong quá trình này là
giữa exploitation của các cấu hình hiện tại đầy hứa hẹn
versus exploration của các vùng mới. Trong Sequential Model-Based
Optimization (SMBO) các cấu hình được đánh giá từng cái một,
mỗi lần cập nhật mô hình surrogate và sử dụng
mô hình cập nhật để tìm các cấu hình mới. Các lựa chọn phổ biến
cho mô hình surrogate là Gaussian Processes, được chỉ ra
cho kết quả tốt hơn trên các vấn đề với ít chiều hơn và
siêu tham số số [34], trong khi các phương pháp dựa trên Random Forest
thành công hơn trong không gian siêu tham số cao chiều
có tính chất rời rạc [13]. Tree-
structured Parzen Estimators (TPE) phù hợp hơn với
đánh giá song song các cấu hình [3].

Evolutionary computation cung cấp một phương pháp rất khác.
Ví dụ, các pipeline có thể được biểu diễn như cây và
genetic programming có thể được sử dụng để cross-over và/hoặc
đột biến các pipeline tốt nhất để phát triển chúng thêm, tăng
trưởng về độ phức tạp khi cần thiết [29]. Random search cũng vẫn
là một kỹ thuật phổ biến. Mặc dù ít hiệu quả mẫu hơn, nó có thể
dễ dàng song song hóa và/hoặc kết hợp với các chiến lược khác.

Các chiến lược tổng quát để cải thiện AutoML bao gồm các
kỹ thuật tối ưu hóa multi-fidelity, đầu tiên thử nhiều cấu hình trên các mẫu nhỏ của dữ liệu, chỉ đánh giá
những cái tốt nhất trên nhiều dữ liệu hơn. Các kỹ thuật ensembling như
voting hoặc stacking có thể kết hợp nhiều cấu hình
đã được huấn luyện trước đó, và điều chỉnh cho over- hoặc underfitting. Cuối cùng,
thường có lợi khi sử dụng meta-learning để xây dựng trên thông tin thu được từ các thí nghiệm trước đó, ví dụ để
warm-start tìm kiếm với các cấu hình đầy hứa hẹn nhất,
hoặc để thiết kế một không gian tìm kiếm nhỏ hơn. Để có một khảo sát rộng
về các kỹ thuật AutoML, xem [27].

Trong bài báo này, chúng tôi sẽ nghiên cứu tác động của concept drift
trên mỗi phương pháp này (BO, evolution, và random
search). Vì chúng tôi cần thích ứng các phương pháp này với các
chiến lược thích ứng mới để xử lý concept drift, chúng tôi chọn các
hệ thống AutoML mã nguồn mở, tiên tiến cho mỗi cái trong số này.

3.1.1 Autosklearn
Autosklearn [13] là một hệ thống AutoML sử dụng tối ưu hóa Bayesian (SMBO). Nó tạo ra các pipeline bao gồm một
loạt rộng các bộ phân loại và kỹ thuật tiền xử lý từ
scikit-learn [32]. Nó hỗ trợ warm-starting bằng cách khởi tạo
tìm kiếm với các pipeline hoạt động tốt trên các tập dữ liệu
tương tự trước đó, cũng như một kỹ thuật lựa chọn ensemble tham lam để
xây dựng ensemble từ các pipeline khác nhau đã thử.

3.1.2 H2O AutoML
H2O AutoML thực hiện random search kết hợp với
automated stacked ensembles [24]. Kỹ thuật stacking
có thể là Random Forests, Gradient Boosting Machines (GBM),
Deep Neural Nets, hoặc generalized linear models (GLM). Các
stacked ensembles có thể chứa hoặc là tốt nhất của tất cả các mô hình cơ sở,
hoặc mô hình tốt nhất từ mỗi họ thuật toán.

3.1.3 GAMA
GAMA sử dụng genetic programming để tự động tạo ra
các pipeline học máy [21]. Nó tương tự như TPOT [29],
nhưng sử dụng evolution bất đồng bộ hơn là đồng bộ,
và bao gồm automated ensembling cũng như.

3.2 Học trên dữ liệu phát triển
Để đánh giá các kỹ thuật AutoML trên dữ liệu phát triển,
chúng tôi xây dựng trên các thực hành tốt nhất trong học trực tuyến.

3.2.1 Cơ chế quên
Để thích ứng tốt hơn với môi trường thay đổi, dữ liệu
quá khứ không liên quan nên được quên. Một cơ chế quên
phổ biến là cửa sổ trượt trong đó dữ liệu được bỏ qua
với tỷ lệ không đổi [16]. Thay vào đó, dữ liệu có thể được
giảm trọng số với tỷ lệ động khi concept drift được
phát hiện, hoặc loại bỏ dựa trên phân phối lớp. Cơ chế
quên phù hợp nhất phụ thuộc vào môi trường và đặc điểm drift. Trong công trình này chúng tôi sẽ
khám phá các chiến lược sử dụng cả cửa sổ trượt và phát hiện concept drift.

3.2.2 Các thuật toán học trực tuyến
Mặc dù nhiều thuật toán học luồng sử dụng một
learner đơn (ví dụ Hoeffding Trees [10]), các ensemble learners (ví dụ
SEA [35], Blast [38]) thường được sử dụng vì độ chính xác
cao hơn và thích ứng nhanh hơn với concept drift. Phiên bản trực tuyến của Oza về bagging [31] thực hiện vote đa số trên
các mô hình cơ sở. Leveraging Bagging [5] thêm nhiều randomization
input và output vào các mô hình cơ sở để tăng đa dạng ensemble
với chi phí hiệu quả tính toán. Blast
[38] xây dựng một tập hợp heterogeneous các base learners và chọn
learner hoạt động tốt nhất trong cửa sổ trước đó để
đưa ra dự đoán cho các mẫu trong cửa sổ hiện tại. Cuối cùng,
online boosting thực hiện boosting bằng cách cân nhắc các base
learners dựa trên hiệu suất trước đó của chúng và điều chỉnh
các trọng số này theo thời gian [30]. Chúng tôi sẽ so sánh các
chiến lược AutoML của chúng tôi với một số phương pháp này.

3.2.3 Đánh giá
Các thủ tục phổ biến nhất để đánh giá các thuật toán học trực tuyến
là holdout, prequential, và data-chunk evaluation. Vì dữ liệu trong một luồng phải được xử lý theo
thứ tự thời gian của chúng, cross validation không áp dụng được [16].
Holdouts có thể được áp dụng bằng cách yêu cầu rằng chỉ dữ liệu
sớm hơn được sử dụng để huấn luyện và dữ liệu muộn hơn để kiểm tra.
Trong prequential evaluation (hay interleaved test-then-train), các
thể hiện mới đến đầu tiên được sử dụng để tính toán hiệu suất
(test) và sau đó để cập nhật mô hình (train) trong
lần lặp tiếp theo. Độ chính xác thay đổi tăng dần khi các thể hiện mới
và nhãn của chúng đến. Mặc dù loại đánh giá này đã
được chỉ ra cho điểm số độ chính xác thấp hơn holdout
trung bình [37], nó rất hữu ích để đánh giá các mô hình trong
trường hợp concept drift. Một phương pháp trung gian phổ biến
kết hợp holdout và prequential evaluation là data chunk
evaluation, sử dụng các chunk dữ liệu có kích thước s thay vì
các thể hiện cá nhân để áp dụng paradigm test-then-train [4].

--- TRANG 4 ---
4
Hình 1. Các chiến lược thích ứng

Phương pháp này không phạt các thuật toán cho sai lầm sớm
và thời gian huấn luyện có thể được đo lường nhất quán hơn. Do đó chúng tôi
sẽ sử dụng data chunk evaluation trong bài báo này.

4 CÁC CHIẾN LƯỢC THÍCH ỨNG
Vì các phương pháp AutoML thường tối ưu hóa một hàm mục tiêu
chống lại một tập huấn luyện tĩnh (xem Eq. 1), một số sửa đổi
được yêu cầu để áp dụng chúng trên dữ liệu phát triển. Chúng tôi
gọi những sửa đổi này là các chiến lược thích ứng vì chúng có thể
được áp dụng một cách tổng quát để thích ứng các phương pháp AutoML. Madrid et
al. [28] đã giới thiệu hai chiến lược như vậy, nhưng sau đó cụ thể
cho auto-sklearn. Trong global model replacement, các mô hình được
huấn luyện lại trên tất cả dữ liệu trước đó và kết hợp lại thành ensemble
dựa trên meta-features khi drift được phát hiện. Trong model management chỉ các trọng số của các mô hình cơ sở trong ensemble
cuối cùng của autosklearn được cập nhật dựa trên hiệu suất của chúng.

4.1 Định nghĩa chiến lược
Trong bài báo này, chúng tôi đề xuất và đánh giá sáu chiến lược thích ứng
khác nhau, được minh họa trong Hình 1. Trong mỗi chiến lược sau đây,
thuật toán AutoML được chạy ít nhất một lần tại
bắt đầu với lô dữ liệu ban đầu. Đối với cơ chế quên chúng tôi sử dụng
một cửa sổ trượt có độ dài cố định, trong đó
s lô cuối cùng được sử dụng để huấn luyện learner và
dữ liệu sớm hơn được quên. Siêu tham số s có thể
được chọn tùy thuộc vào ứng dụng: các giá trị thấp hơn ngụ ý
yêu cầu bộ nhớ thấp hơn và thích ứng nhanh hơn với concept drift, trong khi các giá trị cao hơn ngụ ý các tập huấn luyện lớn hơn và
tối ưu hóa lại pipeline ít thường xuyên hơn.

D&I Detect & Increment Chiến lược này bao gồm một bộ phát hiện drift
quan sát các thay đổi trong hiệu suất pipeline
và sử dụng điều này để phát hiện concept drift. AutoML được chạy trên
lô dữ liệu đầu tiên để xây dựng một mô hình đầu tiên (Model-A).
Chúng tôi giới hạn không gian tìm kiếm AutoML vào các pipeline với
các thuật toán học tăng dần, tức là các learner có thể tiếp tục huấn luyện trên dữ liệu mới, như random forests
và gradient boosting. Điều này hạn chế các phương pháp AutoML,
nhưng nó tăng tốc việc huấn luyện lại và chúng tôi
xác minh thực nghiệm rằng điều này vẫn tạo ra các pipeline
hoạt động tốt nhất. Model-A chỉ được cập nhật nếu drift được phát hiện,
với các pipeline được huấn luyện tăng dần với s
(cửa sổ trượt) lô mới nhất. Cấu hình của các
pipeline vẫn giữ nguyên. Chiến lược này giả định rằng
cấu hình pipeline ban đầu sẽ vẫn hữu ích
và chỉ các mô hình cần được cập nhật trong trường hợp hiệu suất
của chúng giảm sút vì concept drift. Nó kiểm tra
liệu việc giữ một bộ nhớ learner về dữ liệu quá khứ có
có lợi hay không. Điều này có thể mang lại sự tăng hiệu suất nếu
learner cũng có thể thích ứng với dữ liệu mới.

D&RT Detect & Retrain Chiến lược này tương tự, nhưng chạy
AutoML mà không hạn chế không gian tìm kiếm và huấn luyện lại
các pipeline từ đầu trên s lô mới nhất
khi drift được phát hiện. Các cấu hình pipeline ban đầu
và trọng số ensemble được giữ. Chiến lược này cũng
giả định rằng cấu hình pipeline được tìm thấy ban đầu
sẽ vẫn hữu ích và chỉ các mô hình cần được
huấn luyện lại trong trường hợp concept drift. Nó loại bỏ nhu cầu
chạy lại các kỹ thuật AutoML (đắt đỏ) với mỗi drift,
nhưng có thể ít hữu ích hơn nếu drift quá lớn
đến mức cần thiết kế lại pipeline.

D&WS Detect & Warm-start Sau khi drift được phát hiện,
kỹ thuật AutoML được chạy lại để tìm một cấu hình pipeline
tốt hơn. Thay vì bắt đầu từ đầu, tuy nhiên, AutoML được chạy lại với 'warm start', tức là
bắt đầu tìm kiếm từ các cấu hình pipeline tốt nhất
đã được đánh giá trước đó. Chiến lược này giả định rằng
các cấu hình pipeline ban đầu không còn tối ưu
sau concept drift và nên được điều chỉnh lại. Sử dụng một
cơ chế warm start có thể dẫn đến hội tụ nhanh hơn đến
các cấu hình tốt, do đó hoạt động tốt hơn dưới ngân sách
thời gian nhỏ. Tuy nhiên, trong trường hợp sudden drift các
pipeline tốt nhất trước đó có thể đang đánh lạc hướng tìm kiếm.

D&RS Detect & Restart Sau khi drift được phát hiện,
kỹ thuật AutoML được chạy lại từ đầu, với một
ngân sách thời gian cố định, để tìm một cấu hình pipeline tốt hơn.
Đây là một tổng quát hóa của global model replacement [28]
cho các hệ thống AutoML khác và một mở rộng của tối ưu hóa siêu tham số trong [8], [40] cho các pipeline đầy đủ.
Chiến lược này cũng giả định rằng các pipeline cần được
điều chỉnh lại sau drift. Chạy lại AutoML từ đầu
đắt đỏ hơn, nhưng có thể dẫn đến cải thiện hiệu suất
đáng kể trong trường hợp drift đáng kể.

PRS Periodic Restart Tương tự như 'Detect & Restart', ngoại trừ
việc thay vì sử dụng bộ phát hiện drift, AutoML được
khởi động lại với mỗi lô mới, hoặc một khoảng thời gian
thường xuyên khác. Chiến lược này kiểm tra liệu bộ phát hiện drift có
hữu ích hay không, và liệu có đáng để huấn luyện lại ở
những khoảng thời gian nhất định bất chấp chi phí tính toán
đáng kể hay không.

T1 Train once Đây là một chiến lược baseline được thêm vào để
so sánh. AutoML được chạy một lần ở bắt đầu
và mô hình kết quả được sử dụng để kiểm tra mỗi lô
sắp tới. Điều này kiểm tra khả năng vốn có của các phương pháp AutoML
để đối phó với concept drift.

--- TRANG 5 ---
5
BẢNG 1
Chi tiết triển khai cho các thích ứng phương pháp AutoML.

Chiến lược H2O Adaptation Autosklearn Adaptation GAMA Adaptation
Detect &
Increment
- Giới hạn các mô hình cơ sở vào GBM và RF, điều chỉnh
siêu tham số với RandomGridSearch, và huấn luyện
StackedEnsemble trên các pipeline tốt nhất sử dụng lô
ban đầu.
- Khi drift được phát hiện, sử dụng tùy chọn checkpoint để
huấn luyện các mô hình cơ sở tăng dần trên dữ liệu mới với
cùng siêu tham số.
- Huấn luyện lại stacked ensemble với các mô hình đã cập nhật
trên dữ liệu mới, với cùng siêu tham số.
- Giới hạn không gian tìm kiếm vào GBM và RF, đặt
tùy chọn warm-start = True, và chạy AutoML trên
lô ban đầu.
- Khi drift được phát hiện, sử dụng hàm refit để
huấn luyện lại các pipeline được lấy từ ensemble
hiện tại trên dữ liệu mới nhất.
- Giới hạn không gian tìm kiếm vào GBM và RF,
đặt tùy chọn warm-start = True, và chạy
AutoML trên lô ban đầu.
- Khi drift được phát hiện, huấn luyện lại
các pipeline trong ensemble trên dữ liệu mới nhất
bằng cách huấn luyện lại mô hình được lấy
từ AutoML run trước đó với
automl.model.fit. Sử dụng cùng siêu tham số.

Detect &
Retrain
- Chạy AutoML trên lô ban đầu.
- Khi drift được phát hiện, huấn luyện lại mô hình tốt nhất (leader).
Nếu đây là stacked ensemble, lấy các mô hình cơ sở và
huấn luyện lại chúng trên các lô mới.
- Huấn luyện lại stacked ensemble với các mô hình đã cập nhật
trên dữ liệu mới.
- Chạy AutoML trên lô ban đầu.
- Khi drift được phát hiện, sử dụng hàm refit để
huấn luyện lại các pipeline trong mô hình ensemble
từ AutoML run ban đầu trên dữ liệu mới nhất.
- Chạy AutoML trên lô ban đầu.
- Khi drift được phát hiện, sử dụng hàm refit
để huấn luyện lại các pipeline trong
mô hình ensemble từ AutoML run ban đầu
trên dữ liệu mới nhất với automl.model.fit

Detect &
Warm-
start
Các pipeline tốt nhất cần được lấy từ
RandomGridSearch trước đó và đánh giá lại trong lần tiếp theo,
trước khi huấn luyện lại StackedEnsemble trên các pipeline tốt nhất.
Đáng buồn, việc kiểm soát random grid search theo
cách này hiện không được hỗ trợ trong H2O. Để
xấp xỉ, chúng tôi chạy một random search mới và thêm
các pipeline mới tốt nhất vào voting ensemble cũng
bao gồm các pipeline tốt nhất trước đó.
- Để chia sẻ các mô hình giữa các lô, chạy
AutoML với tùy chọn parallel usage with manual
process spawning và Ensemble size = 0. Sau đó,
xây dựng ensemble trên các mô hình đã huấn luyện.
- Warm-start Bayesian optimization với
các pipeline tốt nhất trước đó. Giữ 1/3 ngân sách
để xây dựng ensemble (fitensemble). Sử dụng
Ensemble size và ensemble nbest mặc định.
Sử dụng tính năng warm start của hàm fit
classifier. Điều này làm cho thuật toán tìm kiếm
evolutionary bắt đầu từ các pipeline tốt nhất
trước đó.

Detect &
Restart
Sử dụng bộ phát hiện drift sau mỗi lô được kiểm tra. Huấn luyện lại AutoML từ đầu với ngân sách thời gian cố định trên dữ liệu mới khi drift được phát hiện.

Periodic
Restart
Chạy lại AutoML sau mỗi lô với ngân sách thời gian cố định.

Train once
Không thay đổi. Chỉ chạy các phương pháp AutoML trên lô đầu tiên.

4.2 Tích hợp trong Hệ thống AutoML
Để đánh giá tính hữu ích của các kỹ thuật thích ứng này, chúng tôi
đã triển khai chúng trong Auto-sklearn, H2O và GAMA,
đại diện cho các phương pháp AutoML dựa trên tối ưu hóa Bayesian,
random search, và evolution, tương ứng.

Phát hiện drift. Bốn chiến lược thích ứng đầu tiên yêu cầu
một bộ phát hiện drift. Chúng tôi áp dụng Early Drift Detection
Method (EDDM) [1] là một cải tiến so với
DDM method được sử dụng rộng rãi [17] phát hiện gradual
drift tốt hơn. EDDM giả định rằng concept drift xảy ra khi
các phân loại sai của learner được cách nhau gần hơn
theo thời gian. Sau mỗi mẫu phân loại sai i, nó tính toán
khoảng cách trung bình giữa các phân loại sai pi và độ lệch
chuẩn si trong chuỗi hiện tại (hoặc lô). Nó cũng
ghi lại giá trị (pi + 2si), điểm 95% của phân phối,
và giá trị peak của nó (pmax + 2smax). Drift xảy ra khi
các phân loại sai được cách nhau gần hơn so với bình thường:
(pi + 2si)/(pmax + 2smax) < α (7)
Ngưỡng α được đề xuất đặt thành 0.95.

Thích ứng các kỹ thuật AutoML Các thích ứng không tầm thường
còn lại được yêu cầu cho mỗi hệ thống được tóm tắt trong Bảng 1. Trước hết, không có phương pháp AutoML nào
đi kèm với thủ tục test-then-train tích hợp sẵn. Do đó chúng tôi
thực hiện data chunk evaluation bằng cách chia dữ liệu thành n
lô và cung cấp chúng từng cái một theo thứ tự đến cho
phương pháp để dự đoán/kiểm tra trước, và huấn luyện sau đó.
Không có phương pháp nào bao gồm các thuật toán học trực tuyến. Đối với
Detect & Increment chúng tôi hạn chế không gian tìm kiếm vào gradient
boosting (GBM) và random forest (RF) models, được
hỗ trợ bởi tất cả các phương pháp và cho phép học tăng dần.

5 THIẾT LẬP THỰC NGHIỆM
Trong phần này chúng tôi mô tả các luồng dữ liệu được sử dụng để đánh giá
các cơ chế thích ứng và thiết lập của các hệ thống AutoML. Để đảm bảo tái tạo, tất cả các luồng dữ liệu đều
công khai có sẵn tại OpenML [39] cùng với kết quả của
các thí nghiệm với các thuật toán khác nhau.¹ Chúng tôi cũng cung cấp
một repository github với code và kết quả thực nghiệm của chúng tôi,
bao gồm nhiều biểu đồ không thể vừa trong bài báo này.²

5.1 Luồng dữ liệu
Chúng tôi chọn 4 luồng dữ liệu phân loại nổi tiếng với
concept drift thế giới thực, và tạo ra 15 luồng nhân tạo
với các đặc điểm drift khác nhau. Những cái sau được tạo ra
sử dụng framework MOA [6], và bao gồm gradual, sudden
và mixed (gradual & sudden) drift. Trong mỗi loại drift,
độ lớn drift được thay đổi bằng cách thay đổi các hàm
phân phối cơ bản, và trong một số trường hợp một lượng
nhiễu nhân tạo nhất định được thêm vào.

AIRLINES là một chuỗi thời gian về độ trễ chuyến bay [23] với drift ở
khoảng thời gian hàng ngày và hàng tuần [42]. Nó có 539 383 thể hiện
và 9 đặc trưng số và phân loại.

ELECTRICITY là một chuỗi thời gian về giá điện [25]
đã được chỉ ra chứa các loại drift khác nhau
[42]. Nó có 45 312 thể hiện, 7 đặc trưng, và 2 lớp.

IMDB là một luồng dữ liệu văn bản với dữ liệu từ Internet
Movie Database [33]. Một nhiệm vụ thường được sử dụng trong nghiên cứu drift
là dự đoán liệu một bộ phim thuộc về
thể loại "drama". Nó có 120 919 cốt truyện phim được mô tả
bởi 1000 đặc trưng nhị phân.

VEHICLE bao gồm dữ liệu cảm biến từ một mạng cảm biến
không dây để phân loại xe di chuyển [11]. Nó có
98 528 thể hiện của 50 đặc trưng acoustic và 50 seismic.

STREAMING ENSEMBLE ALGORITHM (SEA) là một bộ tạo dữ liệu
dựa trên bốn hàm phân loại [35]. Chúng tôi
tạo ra các luồng dữ liệu của 500 000 thể hiện và 3 đặc trưng
số với concept drift. Abrupt drift được tạo ra

1. Tìm kiếm www.openml.org cho các tập dữ liệu được gắn thẻ 'concept drift'.
2. https://github.com/openml/continual-automl

--- TRANG 6 ---
6
bằng cách thay đổi hàm phân loại cơ bản tại
thể hiện 250 000. Cửa sổ drift, w, là số
thể hiện mà drift xảy ra qua đó. Các luồng dữ liệu abrupt
drift được tạo ra bằng cách chuyển đổi giữa
các hàm khác nhau với w = 1 và giới thiệu 10%
label noise. Chúng tôi cũng tạo ra các luồng mixed drift bằng cách
thêm hai gradual drifts (trước và sau
abrupt drift) với w = 100 000. Các luồng dữ liệu mixed drift
được tạo ra với các độ lớn khác nhau
của sudden và gradual drift, mà không thêm noise.

ROTATING HYPERPLANE là một bộ tạo luồng tạo ra
các vấn đề phân loại d-chiều trong đó
dự đoán được định nghĩa bởi một siêu phẳng xoay [26].
Bằng cách thay đổi hướng và vị trí của siêu phẳng theo thời gian một cách mượt mà, chúng ta có thể giới thiệu
smooth concept drift. Chúng tôi tạo ra 5 luồng dữ liệu gradual drift
với các độ lớn drift khác nhau trong một
cửa sổ w của 100 000. Các luồng dữ liệu chứa 500 000
thể hiện với 10 đặc trưng. 5% noise được thêm vào bằng cách
thay đổi ngẫu nhiên các nhãn lớp.

Các luồng dữ liệu được chia thành các lô có kích thước bằng nhau để
mô phỏng một môi trường trực tuyến và được đưa cho các thuật toán
theo thứ tự đến, từng lô một. Chúng tôi chọn kích thước lô
1000 để cung cấp đủ dữ liệu cho các thuật toán AutoML
và tối thiểu hóa ảnh hưởng của biến động độ chính xác gây ra bởi
các lô nhỏ. Đối với PRS, kích thước lô lớn hơn (20 000
thể hiện) vì nó không bao gồm bộ phát hiện drift và
yêu cầu huấn luyện lại với mỗi lô, đắt đỏ hơn nhiều. Chúng tôi áp dụng data chunk evaluation để đánh giá các
hệ thống AutoML đã thích ứng. Để huấn luyện, một cửa sổ trượt
với độ dài cố định 3 lô được chọn cho mỗi tập dữ liệu.

5.2 Thuật toán
Chúng tôi đánh giá các thích ứng của Autosklearn, GAMA và
H2O. Như baseline, chúng tôi thêm Oza Bagging [4] và Blast [38].
Cả hai đều là các phương pháp ensemble trực tuyến tiên tiến
được thiết kế đặc biệt cho các luồng dữ liệu với concept drift. Chúng tôi thêm
gradient boosting như một baseline cho học tăng dần. Chúng tôi
giải thích cách mỗi thuật toán được cấu hình. Các siêu tham số
không được đề cập được sử dụng với cài đặt mặc định của chúng.

AUTO-SKLEARN Ngân sách thời gian cho mỗi lần chạy AutoML
là mặc định 1 giờ. Giới hạn bộ nhớ được tăng lên
12 GB để tránh lỗi bộ nhớ.

GAMA Ngân sách thời gian cho mỗi lần chạy AutoML được đặt thành 1
giờ. Tùy chọn để xây dựng ensemble từ các
pipeline học máy đã huấn luyện được kích hoạt.

H2O Ngân sách thời gian cho mỗi lần chạy AutoML được đặt thành 1
giờ. Tất cả cài đặt được giữ ở mặc định, bao gồm
stacker mặc định, một Generalized Linear Model (GLM).

OZABAGGING từ thư viện scikit-multiflow [31]. Kích thước cửa sổ được đặt thành kích thước lô, 1000, và
pretrain size cũng được đặt thành 1000. Bằng cách này, huấn luyện và
dự đoán xảy ra theo cách tương tự như đối với các
phương pháp AutoML, cho phép so sánh công bằng hơn.

BLAST từ thư viện MOA [38]. Các siêu tham số
được sử dụng là mặc định, và kích thước cửa sổ được đặt thành
1000, tương tự như các triển khai AutoML.

GBM Gradient boosting từ thư viện scikit-learn [14].
Các siêu tham số được đặt thành mặc định và kích thước cửa sổ là 1000. Một bộ phát hiện drift được sử dụng để huấn luyện lại
mô hình khi drift được phát hiện.

Các thuật toán phát hiện drift khác nhau đã được kiểm tra trong
nhiều luồng dữ liệu trước khi lựa chọn. EDDM nổi bật
như một lựa chọn mạnh mẽ và nhanh cho các loại drift khác nhau, và
do đó được sử dụng trong tất cả các thí nghiệm.

6 KẾT QUẢ
Chúng tôi đánh giá tất cả các thuật toán trên tất cả các luồng dữ liệu, và phân tích
các ảnh hưởng của đặc điểm drift, chiến lược thích ứng và
phương pháp AutoML.

6.1 Luồng dữ liệu tổng hợp
Chúng tôi đầu tiên phân tích ảnh hưởng của hai đặc điểm drift quan trọng:
loại drift và độ lớn drift. Hình 2-a đến 2-c chứng minh
kết quả của các luồng dữ liệu nhân tạo với gradual,
abrupt và mixed drift, tương ứng. Mỗi biểu đồ con hiển thị
kết quả của một thư viện AutoML, và mỗi chuỗi hiển thị
độ chính xác cho một chiến lược thích ứng cụ thể sau mỗi lô.
Các marker trên các đường hiển thị khi drift được phát hiện.
Các biểu đồ PRS mượt mà hơn vì kích thước lô được tăng
để hiệu quả. Những hình này hiển thị kết quả cho độ lớn drift
cao nhất (để phân tích rõ ràng hơn). Kết quả cho các
mức độ lớn drift khác nhau sẽ được hiển thị trong Hình 3.

6.1.1 Ảnh hưởng của Loại Drift: High Abrupt Drift
Như được hiển thị trong Hình 2-a, high abrupt drift ảnh hưởng nghiêm trọng đến tất cả
các phương pháp AutoML, và chỉ một số chiến lược thích ứng giúp
một số phương pháp AutoML phục hồi. GAMA là nhanh nhất
để phục hồi sau khi abrupt drift xảy ra khi sử dụng
AutoML warm-started (D&WS) hoặc khi huấn luyện lại các
pipeline tốt nhất trước đó sau khi drift được phát hiện (D&RT). Tối ưu hóa lại các pipeline từ đầu sau phát hiện drift
(D&RS) hoạt động cho cả GAMA và Autosklearn, nhưng mất
một chút thời gian hơn để phục hồi. H2O chỉ phục hồi với warm-
starting (D&WS). Tối ưu hóa lại các pipeline từ đầu
định kỳ mà không phát hiện drift (PRS) cũng hoạt động cho
GAMA và AutoSklearn, nhưng tất nhiên đắt đỏ hơn.
Blast tương đối không bị ảnh hưởng bởi abrupt drift và chỉ
tụt lại một chút so với các chiến lược AutoML đã phục hồi. Oza
Bagging cũng không bị ảnh hưởng bởi drift nhưng hoạt động
kém hơn đáng kể. GBM phục hồi sau một độ trễ nhưng không bao giờ
lấy lại hiệu suất trước đó.

Có một số chiến lược thất bại trong việc phục hồi hoàn toàn. Chiến lược
mặc định không cập nhật pipeline (T1) hoàn toàn
thất bại sau khi sudden drift xảy ra. Cập nhật tăng dần
pipeline tốt nhất (D&I) thất bại với Autosklearn và H2O, và
không bao giờ phục hồi hoàn toàn với GAMA. Điều này chỉ ra rằng
sau sudden drift, các pipeline cần được huấn luyện lại hoặc
tối ưu hóa lại. Thật thú vị, warm-starting (D&WS) không
giúp Autosklearn phục hồi, có khả năng vì các
pipeline tốt nhất trước đó đang đánh lạc hướng phương pháp Bayesian Optimization của nó. GAMA sử dụng phương pháp evolutionary
quản lý để phát triển các pipeline trước đó thành
những cái tốt hơn. Đáng ngạc nhiên, đối với H2O cũng huấn luyện lại (D&RT) và
tối ưu hóa lại các pipeline (D&RS) thất bại trong việc phục hồi. Điều này có thể
là vì thủ tục stacking, một generalized linear
model (GLM) theo mặc định, overfit trên các dự đoán của các
pipeline đã cập nhật. Điều này có thể được giải quyết với một

--- TRANG 7 ---
7
(a)
 (b)
(c)
 (d)
Hình 2. Độ chính xác qua các lô cho các luồng dữ liệu nhân tạo: (a) SEA - High abrupt drift; (b) HYPERPLANE - High gradual drift; (c) SEA - High mixed
drift, và (d) Tất cả ba luồng dữ liệu nhân tạo với các dấu drift và điểm thay đổi pipeline (đỏ)

--- TRANG 8 ---
8
phương pháp stacking thích ứng hơn (ví dụ GBM), các lô lớn hơn,
hoặc có thể bằng cách cung cấp các điểm dữ liệu cũng như (cascade
stacking). Chúng tôi sẽ phân tích điều này chi tiết hơn trong Phần 6.4.

6.1.2 Ảnh hưởng của Loại Drift: High Gradual Drift
Như được hiển thị trong Hình 2-b, D&RT và D&RS hoạt động tốt dưới
high gradual drift trong cả GAMA và Autosklearn, nhưng không
đối với H2O (một lần nữa có khả năng do GLM stacker overfitting).
D&I hoạt động khá tốt cho tất cả các kỹ thuật AutoML. D&WS
hoạt động tốt cho GAMA, nhưng không cho Autosklearn (một lần nữa có khả năng
do mô hình surrogate Bayesian bị đánh lạc hướng). Lưu ý rằng
Blast ngang bằng với các tùy chọn tốt nhất trong GAMA và Autosklearn, và tốt hơn bất kỳ tùy chọn nào trong H2O. OzaBagging
bị chi phối bởi một số thích ứng AutoML. GBM thực hiện
tốt hơn nhưng vẫn hơi tệ hơn các thích ứng AutoML tốt nhất. Baseline T1 một lần nữa hoạt động kém. PRS cũng
không tối ưu, có khả năng vì các restart định kỳ không
đủ thường xuyên và liên tục tụt lại high gradual drift.

6.1.3 Ảnh hưởng của Loại Drift: High Mixed Drift
Hình 2-c cho thấy rằng trong trường hợp high mixed drift, restart
AutoML trên dữ liệu mới (D&RS) hoạt động tốt nhất tổng thể.
So với luồng dữ liệu abrupt drift (Hình 2-a, các phương pháp AutoML
xử lý sudden drift tốt hơn và phục hồi nhanh hơn.
Điều này có khả năng vì gradual drift trước và sau
sudden drift cảnh báo các bộ phát hiện drift định kỳ và
gây ra huấn luyện lại thường xuyên hơn. Oza Bagging và Blast xử lý drift tốt, nhưng tổng thể thất bại trong việc bằng hiệu suất
của các chiến lược AutoML tốt nhất (D&RS và D&RT), đặc biệt
sau điểm sudden drift. GBM hoạt động tương tự như Oza
Bagging, nhưng với phục hồi tốt hơn sau sudden drift.
Như trong Hình 2-b, D&RT không hoạt động tốt cho H2O và D&WS
không hoạt động tốt cho Autosklearn, có khả năng vì cùng
lý do. PRS phục hồi đặc biệt tốt sau sudden
drift, cho thấy lợi thế của việc chạy lại AutoML khi
drift đáng kể xảy ra.

6.1.4 Phân tích pipeline
Để có cái nhìn sâu sắc hơn về lý do cơ bản
đằng sau những sự khác biệt hiệu suất này, các pipeline tại
các điểm huấn luyện liên tiếp được so sánh. Hình 2-d chỉ ra khi
các pipeline thay đổi (các đường thẳng đứng đỏ), và khi drift được
phát hiện (các dấu đường đen) cho mỗi cái trong ba luồng dữ liệu nhân tạo
và chiến lược D&RT. Các biểu đồ độ chính xác của các chiến lược
D&RT và D&I được so sánh ngoài
baseline Oza Bagging. Huấn luyện lại mà không tối ưu hóa lại pipeline
(D&I) có thể vượt qua baseline nhưng thường tệ hơn
tối ưu hóa lại pipeline (D&RT). Sự khác biệt này
rõ ràng hơn sau các điểm abrupt drift. Do đó, trong khi
một tối ưu hóa AutoML ban đầu cải thiện hiệu suất
so với baseline learner, tối ưu hóa lại pipeline
trong suốt luồng dữ liệu có thể dẫn đến các cài đặt pipeline khác nhau và lợi thế rõ ràng so với các pipeline tĩnh. Các
điểm thay đổi pipeline chỉ ra rằng D&RT thực sự
tìm thấy các pipeline mới thường xuyên, đặc biệt dưới gradual hoặc mixed drift.

6.1.5 Ảnh hưởng của độ lớn drift
Hình 3 hiển thị kết quả của thư viện GAMA cho các
mức độ lớn drift tăng dần trên luồng dữ liệu SEA abrupt drift.
Khi độ lớn drift tăng, sụt giảm hiệu suất cũng

Hình 3. Ảnh hưởng của độ lớn abrupt drift tăng dần (1 là độ lớn thấp nhất) trên các chiến lược khác nhau, cho GAMA.

tăng, nhưng thời gian phục hồi tổng thể giảm. Điều này
rất có khả năng do việc kích hoạt sớm bộ phát hiện drift trong
các trường hợp độ lớn cao. Chiến lược thích ứng tốt nhất thay đổi
với độ lớn drift, như đã được đề xuất trước đó trong [28].
Huấn luyện lại các mô hình (D&RT), tuy nhiên, thường phục hồi
nhanh hơn restart AutoML (D&RS). Warm-starting
(D&WS) đôi khi phục hồi nhanh hơn, nhưng không phải lúc nào. Cái sau có thể phụ thuộc vào chính xác cách dữ liệu drifts. Nếu khái niệm
cơ bản của dữ liệu vẫn hơi tương tự sau drift,
tức là, nó có thể được mô hình hóa với các cấu hình pipeline tương tự,
thì warm-starting sẽ tăng tốc phục hồi, nhưng nếu không, warm-
starting cũng có thể không hữu ích.

6.2 Luồng Dữ liệu Thế giới Thực
Kết quả trên các luồng dữ liệu thế giới thực được hiển thị trong Hình
4-a đến Hình 4-d. Dữ liệu Airlines (Hình 4-a) có drift
đặc biệt thường xuyên. D&RT và D&I rõ ràng hoạt động tệ hơn ở đây,
chỉ ra rằng việc gắn bó với pipeline được tối ưu hóa ban đầu
không lý tưởng. PRS không thích ứng đủ nhanh: restart
AutoML với mỗi lô có thể tốt hơn nhưng cũng
cấm về chi phí. Các chiến lược thích ứng khác cư xử
đại khái giống nhau, đặc biệt đối với GAMA nơi chúng chồng lên
hầu như hoàn toàn. D&WS hoặc D&RS hoạt động tổng thể tốt.
H2O một lần nữa là ngoại lệ: D&RS không phục hồi tốt
từ drift (như đã quan sát trước đó) và các chiến lược khác
biến động đáng kể. Blast hoạt động đặc biệt tốt ở đây.
Oza Bagging thường bị vượt qua bởi phương pháp AutoML tốt nhất
nhưng cũng biến động ít hơn. Trên dữ liệu IMDB (Hình 4-c) chúng ta
có thể đưa ra các quan sát tương tự, mặc dù drift ở đây là

--- TRANG 9 ---
9
(a)
 (b)
(c)
 (d)
Hình 4. Độ chính xác qua các lô cho các luồng dữ liệu thực: (a) Airlines; (b) Electricity; (c) IMDB; và, (d) Vehicle

--- TRANG 10 ---
10
gradual hơn, cho phép PRS tìm các pipeline tốt hơn. Blast
đại khái ngang bằng với các chiến lược AutoML, trong khi Oza
Bagging và GBM rõ ràng tệ hơn.

Electricity (Hình 4-b) nhỏ hơn nhiều và có các
loại drift khác nhau, và do đó chúng ta có thể quan sát nhiều biến động hơn
trong hành vi của các chiến lược và phương pháp AutoML
khác nhau. Drift được phát hiện với hầu như mỗi lô. Với
GAMA, hầu hết các chiến lược cư xử tương tự như trước. D&RT
và D&I hoạt động tệ hơn và D&WS hoặc D&RS hoạt động
tổng thể tốt. AutoSKlearn và H2O gặp khó khăn hơn
với tập dữ liệu nhỏ hơn, và tối ưu hóa lại các pipeline (D&WS
hoặc D&RS) thường dẫn đến kết quả tệ hơn. PRS là một đường thẳng
vì không có đủ lô để đảm bảo chạy lại
các kỹ thuật AutoML từ đầu. Blast thống trị các
phương pháp khác ở đây, GBM hầu như ngang bằng, Oza Bagging
tệ hơn nhiều. Tập dữ liệu Electricity được biết là
tự tương quan mạnh, có lợi cho Blast. Trên Vehicle, lớn hơn
và có gradual drift hơn, cả Blast và Oza
Bagging đều bị vượt qua bởi các kỹ thuật AutoML và
GBM. Lưu ý rằng ít drift được phát hiện ở đây, và do đó
điểm số của các chiến lược khác nhau rất gần. PRS hoạt động
rất tốt ở đây, trong khi H2O với D&RT hoạt động kém, như
chúng ta đã thấy trước đó với high gradual drift.

6.3 So sánh các hệ thống AutoML
Tóm lại, chúng tôi thấy rằng chiến lược thích ứng lý tưởng phụ thuộc vào hệ thống AutoML và đặc điểm của
luồng dữ liệu. Trên các luồng dữ liệu thế giới thực (Hình 4),
mỗi hệ thống AutoML hoạt động khá tương tự khi lựa chọn chiến lược tốt nhất, nhưng chiến lược tốt nhất khác nhau
giữa chúng. Trên các tập dữ liệu lớn, tối ưu hóa lại pipeline (ví dụ
D&WS hoặc D&RS) hoạt động tốt cho GAMA và Autosklearn.
Huấn luyện lại rẻ hơn mà không tối ưu hóa lại (D&RT)
cũng hoạt động tốt trên một số tập dữ liệu nếu được kích hoạt thường xuyên
để huấn luyện lại. Đối với H2O, D&RS gặp vấn đề overfitting,
nhưng học tăng dần (D&I) hoạt động đáng ngạc nhiên tốt.
Trên các tập dữ liệu nhỏ hơn (ví dụ Electricity), GAMA tiếp tục
tối ưu hóa lại các pipeline tốt (D&WS và D&RS), trong khi
Autosklearn và H2O đạt kết quả tốt hơn bằng cách huấn luyện lại
các pipeline hiện có (D&RT và D&I). Đối với các luồng dữ liệu với
abrupt concept drift, phục hồi nhanh là chìa khóa. Restart AutoML
khi abrupt drift được phát hiện (D&RS) là cách đánh cược an toàn cho GAMA
và Autosklearn. GAMA có thể phục hồi thậm chí nhanh hơn khi
warm-starting tìm kiếm evolutionary (D&WS), nhưng điều này
không hoạt động với phương pháp Bayesian Optimization của Autosklearn.
Sự khác biệt về tốc độ phục hồi này lớn hơn khi
độ lớn drift thấp hơn (Hình 3). Hành vi tương tự
được quan sát cho mixed drift (Hình 2-c), trong khi GAMA và
Autosklearn hoạt động khá tương tự trên gradual drift. H2O
không phục hồi với D&RS trong các thí nghiệm của chúng tôi, điều này sẽ
được thảo luận chi tiết hơn tiếp theo.

6.4 Tương tác với phát hiện drift
Để hiểu tương tác giữa chiến lược thích ứng
và bộ phát hiện drift, Hình 5-a hiển thị các điểm drift (như
các đường thẳng đứng) cho mỗi chiến lược thích ứng với GAMA
trên một luồng dữ liệu mixed drift. Tối ưu hóa lại các pipeline
(D&RS) dẫn đến các sự khác biệt hiệu suất đáng kể hơn,
kích hoạt bộ phát hiện drift thường xuyên hơn, từ đó dẫn đến
tối ưu hóa lại nhiều hơn. Warm-starting (D&WS) dẫn đến

(a)
(b)
Hình 5. Độ chính xác qua các lô trên luồng dữ liệu SEA - High mixed cho:
(a) GAMA với các điểm drift được phát hiện (các đường thẳng đứng); và (b) H2O với
drift được phát hiện và được đặt trước

biến động hiệu suất tinh tế hơn và ít kích hoạt bộ phát hiện drift
thường xuyên hơn. Các chiến lược khác chủ yếu kích hoạt bộ phát hiện drift
ở đầu và sau abrupt drift.

Để đánh giá ảnh hưởng của bộ phát hiện drift, chúng tôi thay thế nó
với năm điểm drift được đặt trước: một sau abrupt drift và
bốn sau mid-gradual drifts. Hình 5-b so sánh điểm số độ chính xác cho H2O với bộ phát hiện drift (đường đầy đủ) và
điểm đặt trước (đường đứt nét). Mặc dù có những khác biệt nhỏ, ví dụ
phục hồi nhanh hơn với D&RS, tổng thể hiệu suất tương đối
của các chiến lược thích ứng không thay đổi.

Cuối cùng, Hình 6 đánh dấu các điểm drift được phát hiện (màu đỏ)
cho mỗi thư viện cho luồng dữ liệu high abrupt drift với
D&RS. Drift luôn được phát hiện sau điểm sudden drift
tại lô 250. Autosklearn và GAMA phục hồi sau khi drift
được phát hiện và các pipeline được tối ưu hóa lại, nhưng không phải H2O.
Do đó, việc thiếu phát hiện drift không phải là lý do cho hiệu suất của H2O sau drift. Kết quả tương tự được tìm thấy cho
luồng dữ liệu abrupt và mixed drift. Điều này đề xuất rằng mô hình tuyến tính (GLM) được sử dụng trong quá trình stacking của H2O không
thích ứng tốt với các thay đổi trong phân phối dữ liệu. Thay thế
điều này với một stacker thích ứng hơn (ví dụ GBM) có thể giải quyết
điều này. H2O cũng vẫn là một tùy chọn cạnh tranh cho gradual drift

--- TRANG 11 ---
11
Hình 6. Độ chính xác qua các lô với các điểm phát hiện drift cho luồng dữ liệu SEA - High
abrupt trên chiến lược D&RS.

Hình 7. Độ chính xác trung bình cho tất cả các luồng dữ liệu và thư viện với D&RS trên
ngân sách thời gian giữa 60 và 3600 giây.

các luồng dữ liệu với D&I được chọn như chiến lược thích ứng.

6.5 Ảnh hưởng của ngân sách thời gian
Khi chúng ta chọn chạy lại một kỹ thuật AutoML (ví dụ trong
D&RS và PRS), chúng ta có thể làm như vậy song song và tiếp tục sử dụng
các pipeline trước đó cho đến khi các pipeline mới được tối ưu hóa
cho dữ liệu mới. Tuy nhiên, chúng ta có thể muốn giới hạn ngân sách thời gian
được đưa cho hệ thống AutoML để phương pháp của chúng ta phản ứng
nhanh hơn với concept drift. Hình 7 hiển thị độ chính xác
của tất cả các thư viện với chiến lược D&RS trên mỗi luồng dữ liệu,
cho ngân sách thời gian biến đổi từ 60 giây đến 3600 giây. Các ngân sách
nhỏ hơn ảnh hưởng đến hiệu suất, nhưng tổng thể hầu hết các phương pháp
hoạt động tốt dưới các ràng buộc nghiêm ngặt hơn. Đối với các luồng dữ liệu với
không gian đặc trưng lớn hơn (tức là IMDB, Vehicle) ngân sách thời gian
có ảnh hưởng có thể nhìn thấy hơn so với các luồng dữ liệu nhân tạo và
ít chiều hơn. Blast, huấn luyện nhiều mô hình trong một ensemble, có độ chính xác và hiệu suất thời gian
tương tự. Một lợi thế của các phương pháp AutoML là ngân sách thời gian có thể được hạn chế mà không mất nhiều độ chính xác,
cho phép các cài đặt học trực tuyến khác nhau. Một câu hỏi nghiên cứu thú vị sẽ là kiểm tra mối quan hệ giữa ngân sách thời gian tối ưu và đặc điểm của
luồng dữ liệu.

7 KẾT LUẬN
Mục tiêu chính của nghiên cứu này là hiểu sâu hơn
về cách các phương pháp AutoML hiện tại bị ảnh hưởng bởi
các loại concept drift khác nhau, và cách chúng có thể được
thích ứng để trở nên mạnh mẽ hơn. Vì mục đích này, chúng tôi đề xuất
sáu chiến lược thích ứng có thể được kết hợp một cách tổng quát
với các kỹ thuật AutoML, tích hợp chúng với một số
phương pháp AutoML nổi tiếng nhất, và đánh giá
chúng trên cả tập dữ liệu nhân tạo và thế giới thực với các
loại concept drift khác nhau.

Chúng tôi thấy rằng các chiến lược này hiệu quả cho phép các
kỹ thuật AutoML phục hồi từ concept drift, và cạnh tranh hoặc vượt qua các kỹ thuật học trực tuyến phổ biến như Oza
Bagging và BLAST. Các so sánh giữa các kỹ thuật AutoML khác nhau cho thấy rằng cả phương pháp tối ưu hóa Bayesian
và evolutionary đều có thể được thích ứng để xử lý concept drift tốt, với một chiến lược thích ứng phù hợp và
cơ chế quên. Tương tự như các nghiên cứu trước đó, chúng tôi
thấy rằng các đặc điểm drift khác nhau ảnh hưởng đến các thuật toán học
theo những cách khác nhau, và các chiến lược thích ứng khác nhau
có thể cần thiết để đối phó tối ưu với chúng.

Trên các tập dữ liệu lớn, tối ưu hóa lại pipeline sau khi drift
được phát hiện hoạt động tổng thể tốt. Các phương pháp AutoML
evolutionary có thể làm như vậy thậm chí nhanh hơn bằng cách phát triển các
pipeline tốt nhất trước đó. Đơn giản là huấn luyện lại các pipeline trên
dữ liệu gần đây nhất sau khi drift được phát hiện, mà không tối ưu hóa lại
các pipeline tự chúng, cũng hoạt động tốt nếu concept drift
không quá lớn và các pipeline được huấn luyện lại đủ
thường xuyên. Tùy thuộc vào ứng dụng, thời gian tính toán
bổ sung có thể được giảm thiểu bằng cách giảm kích thước lô, ngân sách thời gian tối ưu hóa, và warm-starting.

Tóm lại, nghiên cứu này đóng góp một tập hợp các chiến lược thích ứng đầy hứa hẹn cũng như một đánh giá thực nghiệm rộng rãi
của các chiến lược này, để các lựa chọn thiết kế có thông tin có thể
được đưa ra về cách thích ứng các kỹ thuật AutoML với các cài đặt có
dữ liệu phát triển. Nó cũng cho thấy rằng có đủ chỗ để cải thiện các hệ thống AutoML hiện có, và thậm chí thiết kế
hoàn toàn các hệ thống AutoML mới thích ứng tự nhiên với concept drift.
Chúng tôi hy vọng rằng nghiên cứu này sẽ khơi dậy nghiên cứu thêm về
các phương pháp AutoML thích ứng dễ dàng với dữ liệu phát triển.

LỜI CẢM ƠN
Chúng tôi muốn cảm ơn Erin Ledell, Matthias Feurer và
Pieter Gijsbers vì lời khuyên của họ về việc thích ứng các hệ thống AutoML của họ. Công trình này được hỗ trợ bởi Dutch Science
Foundation (NWO) grant DACCOMPLI (nr. 628.011.022)
và được hỗ trợ một phần bởi TAILOR, một dự án được tài trợ bởi EU
Horizon 2020 research and innovation programme (dưới
GA No 952215).

TÀI LIỆU THAM KHẢO
[1] M. Baena-García, J. Campo-Ávila, R. Fidalgo-Merino, A. Bifet,
R. Gavaldà, và R. Morales-Bueno, "Early drift detection method,"
trong Fourth International Workshop on Knowledge Discovery from Data
Streams, vol. 6, 2006, pp. 77–86.
[2] R. Bakirov, B. Gabrys, và D. Fay, "Generic adaptation strategies
for automated machine learning," ArXiv, vol. 1812.10793, 2018.

--- TRANG 12 ---
12
[3] J. S. Bergstra, R. Bardenet, Y. Bengio, và B. Kégl, "Algorithms for
hyper-parameter optimization," trong Advances in Neural Information
Processing Systems 24, 2011, pp. 2546–2554.
[4] A. Bifet và R. Kirkby, "Data stream mining a practical approach,"
J. Empirical Finance, vol. 8, no. 3, p. 325–342, 2009.
[5] A. Bifet, G. Holmes, và B. Pfahringer, "Leveraging bagging
for evolving data streams," trong Machine Learning and Knowledge
Discovery in Databases, 2010, pp. 135–150.
[6] A. Bifet, G. Holmes, B. Pfahringer, J. Read, P. Kranen, H. Kremer,
T. Jansen, và T. Seidl, "MOA: A real-time analytics open source
framework," trong Lecture Notes in Computer Science, vol. 6913, 2011,
pp. 617–620.
[7] E. Brochu, V. M. Cora, và N. De Freitas, "A tutorial on Bayesian
optimization of expensive cost functions, with application to
active user modeling and hierarchical reinforcement learning,"
CoRR, vol. abs/1012.2599, 2010.
[8] M. Carnein, H. Trautmann, A. Bifet, và B. Pfahringer, "Towards
automated configuration of stream clustering algorithms," trong European Conference on Machine Learning and Knowledge Discovery in
Databases, 2019, pp. 137–143.
[9] M. De Lange, R. Aljundi, M. Masana, S. Parisot, X. Jia,
A. Leonardis, G. Slabaugh, và T. Tuytelaars, "Continual learning:
A comparative study on how to defy forgetting in classification
tasks," arXiv preprint arXiv:1909.08383, 2019.
[10] P. Domingos và G. Hulten, "Mining high-speed data streams,"
trong Proceedings of the Sixth ACM SIGKDD International Conference on
Knowledge Discovery and Data Mining, 2000, p. 71–80.
[11] M. Duarte và Y. H. Hu, "Vehicle classification in distributed
sensor networks," Journal of Parallel and Distributed Computing,
vol. 64, pp. 826–838, 2004.
[12] H. J. Escalante, W.-W. Tu, I. Guyon, D. L. Silver, E. Viegas, Y. Chen,
W. Dai, và Q. Yang, "AutoML@NeurIPS 2018 challenge: Design
& results," trong NeurIPS'18 Competition. Springer, 2020, pp. 209–229.
[13] M. Feurer, A. Klein, K. Eggensperger, J. T. Springenberg, M. Blum,
và F. Hutter, "Efficient and robust automated machine learning,"
trong Proceedings of the 28th International Conference on Neural Information Processing Systems - Volume 2. MIT Press, 2015, p. 2755–2763.
[14] J. H. Friedman, "Greedy function approximation: A gradient
boosting machine." Ann. Statist., vol. 29, no. 5, pp. 1189–
1232, 10 2001. [Online]. Available: https://doi.org/10.1214/aos/
1013203451
[15] J. Gama và P. Kosina, "Learning about the learning process,"
trong International Symposium on Intelligent Data Analysis. Springer,
2011, pp. 162–172.
[16] J. Gama, I. Zliobaite, A. Bifet, M. Pechenizkiy, và A. Bouchachia,
"A survey on concept drift adaptation," ACM Compututer Surveys,
vol. 46, no. 4, pp. 44:1–44:37, 2014.
[17] J. Gama, P. Medas, G. Castillo, và P. Rodrigues, "Learning with
drift detection," trong In SBIA Brazilian Symposium on Artificial Intelligence. Springer Verlag, 2004, pp. 286–295.
[18] R. Garnett, "Learning from data streams with concept drift," Ph.D.
dissertation, University of Oxford, 2010.
[19] R. Garnett, M. A. Osborne, S. Reece, A. Rogers, và S. J. Roberts,
"Sequential Bayesian prediction in the presence of changepoints
& faults," The Computer Journal, vol. 53, no. 9, pp. 1430–1446, 2010.
[20] P. Gijsbers, E. LeDell, J. Thomas, S. Poirier, B. Bischl, và J. Vanschoren, "An open source AutoML benchmark," arXiv preprint
arXiv:1907.00909, 2019.
[21] P. Gijsbers và J. Vanschoren, "GAMA: Genetic automated machine learning assistant," Journal of Open Source Software, vol. 4,
no. 33, p. 1132, 2019.
[22] D. Golovin, B. Solnik, S. Moitra, G. Kochanski, J. Karro, và
D. Sculley, "Google vizier: A service for black-box optimization,"
trong Proceedings of the 23rd ACM SIGKDD international conference on
knowledge discovery and data mining, 2017, pp. 1487–1495.
[23] H. M. Gomes, A. Bifet, J. Read, J. P. Barddal, F. Enembreck,
B. Pfharinger, G. Holmes, và T. Abdessalem, "Adaptive random
forests for evolving data stream classification," Machine Learning,
vol. 106, no. 9, pp. 1469–1495, 2017.
[24] H2O.ai, h2o: Python Interface for H2O, 2019, 3.24.0.1. [Online].
Available: https://github.com/h2oai/h2o-3
[25] M. Harries, "Splice-2 comparative evaluation: Electricity pricing,"
The University of South Wales, Tech. Rep., 1999.
[26] G. Hulten, L. Spencer, và P. Domingos, "Mining time-changing
data streams," trong Proceedings of the 7th ACM SIGKDD International
Conference on Knowledge Discovery and Data Mining, 2001, p. 97–106.
[27] F. Hutter, L. Kotthoff, và J. Vanschoren, Eds., Automatic machine
learning: methods, systems, challenges. Springer, 2019.
[28] J. G. Madrid, H. J. Escalante, E. F. Morales, W. Tu, Y. Yu, L. SunHosoya, I. Guyon, và M. Sebag, "Towards AutoML in the presence of drift: first results," CoRR, vol. abs/1907.10772, 2019.
[29] R. S. Olson, R. J. Urbanowicz, P. C. Andrews, N. A. Lavender,
L. C. Kidd, và J. H. Moore, "Automating biomedical data science
through tree-based pipeline optimization," trong Lecture Notes in
Computer Science, vol. 9597. Springer, 2016, pp. 123–137.
[30] N. C. Oza, "Online bagging and boosting," trong 2005 IEEE International Conference on Systems, Man and Cybernetics, vol. 3, 2005, pp.
2340–2345 Vol. 3.
[31] N. C. Oza và S. Russell, "Experimental comparisons of online
and batch versions of bagging and boosting," trong Proceedings of
the Seventh ACM SIGKDD International Conference on Knowledge
Discovery and Data Mining, 2001, p. 359–364.
[32] F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion,
O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg,
J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher, M. Perrot,
và E. Duchesnay, "Scikit-learn: Machine learning in Python,"
Journal of Machine Learning Research, vol. 12, pp. 2825–2830, 2011.
[33] J. Read, A. Bifet, B. Pfahringer, và G. Holmes, "Batch-incremental
versus instance-incremental learning in dynamic and evolving
data," trong Proceedings of the 11th International Conference on Advances
in Intelligent Data Analysis. Springer-Verlag, 2012, p. 313–323.
[34] J. Snoek, H. Larochelle, và R. P. Adams, "Practical bayesian optimization of machine learning algorithms," trong Advances in Neural
Information Processing Systems 25, 2012, pp. 2951–2959.
[35] W. Street và Y. Kim, "A streaming ensemble algorithm sea
for large-scale classification," trong 7th ACM SIGKDD Int. Conf. on
Knowledge Discovery and Data Mining, 2001, pp. 377–382.
[36] C. Thornton, F. Hutter, H. H. Hoos, và K. Leyton-Brown, "AutoWEKA: Combined selection and hyperparameter optimization of
classification algorithms," trong 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 2013, p. 847–855.
[37] J. N. van Rijn, G. Holmes, B. Pfahringer, và J. Vanschoren, "Algorithm selection on data streams," trong Discovery Science. Springer,
2014, pp. 325–336.
[38] J. van Rijn, G. Holmes, B. Pfahringer, và J. Vanschoren, "Having
a blast: meta-learning and heterogeneous ensembles for data
streams," trong 15th IEEE International Conference on Data Mining,
2016, pp. 1003–1008.
[39] J. Vanschoren, J. N. van Rijn, B. Bischl, và L. Torgo, "OpenML:
networked science in machine learning," ACM SIGKDD Explorations, 2014.
[40] B. Veloso, J. Gama, và B. Malheiro, "Self hyper-parameter tuning
for data streams," trong International Conference on Discovery Science.
Springer, 2018, pp. 241–255.
[41] G. I. Webb, R. Hyde, H. Cao, H. L. Nguyen, và F. Petitjean, "Characterizing concept drift," Data Mining and Knowledge Discovery,
vol. 30, no. 4, p. 964–994, 2016.
[42] G. I. Webb, L. K. Lee, B. Goethals, và F. Petitjean, "Analyzing
concept drift and shift from sample data," Data Min. Knowl.
Discov., vol. 32, no. 5, pp. 1179–1199, 2018.
[43] Q. Yao, M. Wang, H. J. Escalante, I. Guyon, Y.-Q. Hu, Y.-F. Li,
W.-W. Tu, Q. Yang, và Y. Yu, "Taking human out of learning
applications: A survey on automated machine learning," CoRR,
vol. abs/1810.13306, 2018.

Bilge Celik là một nghiên cứu sinh tiến sĩ tại Khoa
Toán và Khoa học Máy tính tại Đại học Công nghệ
Eindhoven. Cô nhận bằng Thạc sĩ và Cử nhân từ
Đại học Kỹ thuật Trung Đông. Sở thích nghiên cứu
của cô bao gồm học máy tự động, thách thức luồng
dữ liệu và tự động hóa trong học thích ứng.

--- TRANG 13 ---
13
Joaquin Vanschoren tập trung nghiên cứu của mình
vào học máy tự động (AutoML) và meta-learning
(học để học). Ông thành lập dự án OpenML (openml.org) và đồng tổ chức các workshop AutoML và
meta-learning tại ICML và NeurIPS. Ông đồng trình
bày các tutorial tại NeurIPS và AAAI, và đồng tác
giả cuốn sách 'Automated Machine Learning'
(Springer, 2019). Ông là thành viên sáng lập của
ELLIS và CLAIRE, và action editor tại JMLR.

# 2111.00083.pdf
# Đã chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/automl-nas/2111.00083.pdf
# Kích thước tệp: 2754448 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
Một Phương pháp AutoML Có thể Mở rộng Dựa trên Mạng Neural Đồ thị
Mossad Helali∗, Essam Mansour∗, Ibrahim Abdelaziz§, Julian Dolby§, Kavitha Srinivas§
∗Trường Đại học Concordia§IBM Research AI
Montreal, Canada New York, US
{fname}.{lname}@concordia.ca,ibrahim.abdelaziz1,dolby,Kavitha.Srinivas@ibm.com
TÓM TẮT
Các hệ thống AutoML xây dựng các mô hình học máy tự động bằng cách
thực hiện tìm kiếm trên các phép biến đổi dữ liệu hợp lệ và bộ học,
cùng với tối ưu hóa siêu tham số cho mỗi bộ học. Nhiều
hệ thống AutoML sử dụng meta-learning để hướng dẫn tìm kiếm cho các
pipeline tối ưu. Trong công trình này, chúng tôi trình bày một hệ thống meta-learning
mới có tên KGpip, hệ thống này (1) xây dựng cơ sở dữ liệu các tập dữ liệu và các
pipeline tương ứng bằng cách khai thác hàng nghìn script với phân tích chương trình,
(2) sử dụng nhúng tập dữ liệu để tìm các tập dữ liệu tương tự trong cơ sở dữ liệu
dựa trên nội dung của nó thay vì các đặc trưng dựa trên metadata, (3) mô hình hóa
việc tạo pipeline AutoML như một bài toán tạo đồ thị, để
mô tả ngắn gọn các pipeline đa dạng được thấy cho một tập dữ liệu duy nhất.
Meta-learning của KGpip là một thành phần con cho các hệ thống AutoML. Chúng
tôi chứng minh điều này bằng cách tích hợp KGpip với hai hệ thống AutoML.
Đánh giá toàn diện của chúng tôi sử dụng 121 tập dữ liệu, bao gồm những tập được
sử dụng bởi các hệ thống tiên tiến, cho thấy KGpip vượt trội đáng kể
so với các hệ thống này.
Định dạng Tham chiếu PVLDB:
Mossad Helali∗, Essam Mansour∗, Ibrahim Abdelaziz§, Julian Dolby§,
Kavitha Srinivas§. Một Phương pháp AutoML Có thể Mở rộng Dựa trên Mạng Neural
Đồ thị. PVLDB, 14(1): XXX-XXX, 2020.
doi:XX.XX/XXX.XX
Tính khả dụng Artifact PVLDB:
Mã nguồn, dữ liệu, và/hoặc các artifact khác đã được cung cấp tại
https://github.com/CoDS-GCS/kgpip-public.
1 GIỚI THIỆU
AutoML là quá trình mà các mô hình học máy được xây dựng
tự động cho một tập dữ liệu mới. Với một tập dữ liệu, các hệ thống
AutoML thực hiện tìm kiếm trên các phép biến đổi dữ liệu hợp lệ và bộ học,
cùng với tối ưu hóa siêu tham số cho mỗi bộ học [ 17].
Việc chọn các phép biến đổi và bộ học để tìm kiếm
là trọng tâm của chúng tôi. Một số lượng đáng kể các hệ thống khai thác từ các
lần chạy trước của pipeline trên một tập các tập dữ liệu để chọn các transformer và
bộ học có hiệu quả với các loại tập dữ liệu khác nhau (ví dụ [ 10],
[32], [9]). Do đó, chúng xây dựng cơ sở dữ liệu bằng cách thực sự chạy các
pipeline khác nhau với một tập đa dạng các tập dữ liệu để ước tính độ chính xác của
các pipeline tiềm năng. Do đó, chúng có thể được sử dụng để giảm hiệu quả
không gian tìm kiếm. Một tập dữ liệu mới, dựa trên một tập các đặc trưng (meta-
features) sau đó được khớp với cơ sở dữ liệu này để tìm các ứng viên khả thi nhất
Công trình này được cấp phép theo Giấy phép Quốc tế Creative Commons BY-NC-ND 4.0.
Truy cập https://creativecommons.org/licenses/by-nc-nd/4.0/ để xem bản sao của
giấy phép này. Đối với bất kỳ việc sử dụng nào vượt quá những gì được bao gồm bởi giấy phép này, hãy xin phép bằng
email info@vldb.org. Bản quyền thuộc về chủ sở hữu/tác giả. Quyền xuất bản
được cấp phép cho VLDB Endowment.
Proceedings of the VLDB Endowment, Vol. 14, No. 1 ISSN 2150-8097.
doi:XX.XX/XXX.XXcho cả việc lựa chọn bộ học và điều chỉnh siêu tham số.
Quá trình này của việc chọn điểm khởi đầu trong không gian tìm kiếm được gọi là
meta-learning cho bài toán khởi đầu lạnh.
Các phương pháp meta-learning khác bao gồm khai thác
mã khoa học dữ liệu hiện có và các tập dữ liệu liên quan của chúng để học từ
chuyên môn của con người. Hệ thống AL [ 2] đã khai thác các notebook Kaggle hiện có bằng
phân tích động, tức là, thực sự chạy các script, và cho thấy rằng
hệ thống như vậy có triển vọng. Tuy nhiên, phương pháp meta-learning này
không mở rộng được vì việc thực thi một số lượng lớn
script pipeline trên các tập dữ liệu là khó khăn, tiền xử lý tập dữ liệu không bao giờ tầm thường,
và các script cũ ngừng chạy hoàn toàn khi phần mềm phát triển. Không có gì
ngạc nhiên khi AL do đó chỉ thực hiện phân tích động trên chỉ
chín tập dữ liệu.
Hệ thống của chúng tôi, KGpip, cung cấp một phương pháp meta-learning có thể mở rộng
để tận dụng chuyên môn của con người, sử dụng phân tích tĩnh để khai thác pipeline
từ các kho lưu trữ lớn các script. Phân tích tĩnh có lợi thế
của việc mở rộng đến hàng nghìn hoặc hàng triệu script [ 1] một cách dễ dàng, nhưng thiếu
dữ liệu hiệu suất được thu thập bởi phân tích động. Phương pháp meta-
learning KGpip hướng dẫn quá trình học bằng tìm kiếm tương tự tập dữ liệu có thể mở rộng,
dựa trên nhúng tập dữ liệu, để tìm các
tập dữ liệu tương tự nhất và ngữ nghĩa của các pipeline ML được áp dụng trên chúng.
Nhiều hệ thống hiện có, như Auto-Sklearn [ 9] và AL [ 2], tính
toán một tập các meta-features cho mỗi tập dữ liệu. Chúng tôi đã phát triển một mô hình
mạng neural sâu để tạo nhúng ở mức độ chi tiết của
một tập dữ liệu, ví dụ, một bảng hoặc tệp CSV, để nắm bắt sự tương tự ở mức
của toàn bộ tập dữ liệu thay vì dựa vào một tập các meta-features.
Bởi vì chúng tôi sử dụng phân tích tĩnh để nắm bắt ngữ nghĩa của
quá trình meta-learning, chúng tôi không có cơ chế để chọn pipeline tốt nhất
từ nhiều pipeline đã thấy, không như trường hợp thực thi động nơi người ta có thể dựa vào
runtime để chọn pipeline có hiệu suất tốt nhất. Quan sát rằng pipeline cơ bản là
đồ thị luồng công việc, chúng tôi sử dụng các mô hình neural tạo đồ thị để nắm bắt ngắn gọn các
pipeline quan sát tĩnh cho một tập dữ liệu duy nhất. Trong KGpip, chúng tôi
công thức hóa việc lựa chọn bộ học như một bài toán tạo đồ thị để dự đoán
các pipeline tối ưu dựa trên các pipeline được thấy trong các notebook thực tế.
KGpip thực hiện việc lựa chọn bộ học và biến đổi, và do đó là một
thành phần của các hệ thống AutoML. Để đánh giá thành phần này, chúng tôi
đã tích hợp nó vào hai hệ thống AutoML hiện có, FLAML [ 30] và
Auto-Sklearn [ 9]. Chúng tôi chọn FLAML vì nó chưa có bất kỳ
thành phần meta-learning nào cho bài toán khởi đầu lạnh và thay vào đó
cho phép người dùng lựa chọn bộ học và transformer. Các tác giả của
FLAML đã chỉ ra rõ ràng rằng FLAML có thể hưởng lợi
từ một thành phần meta-learning và đã chỉ ra nó như một khả năng
cho công việc tương lai. Đối với FLAML, nếu việc khai thác pipeline lịch sử cung cấp
một lợi thế, chúng tôi nên cải thiện hiệu suất của nó. Chúng tôi cũng chọn
Auto-Sklearn vì nó có một thành phần lựa chọn bộ học dựa
trên meta-features, như được mô tả trước đó [ 8]. Đối với Auto-Sklearn, chúng tôi
ít nhất nên khớp hiệu suất nếu việc khai thác tĩnh pipeline của chúng tôiarXiv:2111.00083v4  [cs.LG]  14 Jul 2022

--- TRANG 2 ---
có thể khớp với cơ sở dữ liệu rộng lớn của họ. Để có bối cảnh, chúng tôi cũng so sánh
KGpip với VolcanoML [ 17] gần đây, hệ thống cung cấp một chiến lược phân tách và thực thi hiệu quả
cho không gian tìm kiếm AutoML.
Ngược lại, KGpip cắt tỉa không gian tìm kiếm bằng cách sử dụng mô hình meta-learning
của chúng tôi để thực hiện tối ưu hóa siêu tham số chỉ cho các ứng viên
hứa hẹn nhất.
Những đóng góp của bài báo này như sau:
•Mục 3 định nghĩa một phương pháp meta-learning có thể mở rộng dựa
trên học biểu diễn của ngữ nghĩa pipeline ML được khai thác
và tập dữ liệu cho hơn 100 tập dữ liệu và 11K script Python.
•Mục 4 công thức hóa việc tạo pipeline AutoML như một bài toán tạo đồ thị.
KGpip dự đoán hiệu quả một pipeline ML tối ưu cho một tập dữ liệu chưa thấy
dựa trên mô hình meta-learning của chúng tôi. Theo hiểu biết tốt nhất của chúng tôi, KGpip là phương pháp đầu tiên
công thức hóa việc tạo pipeline AutoML theo cách như vậy.
•Mục 5 trình bày một đánh giá toàn diện sử dụng một
bộ sưu tập lớn gồm 121 tập dữ liệu từ các điểm chuẩn AutoML chính
và Kaggle. Kết quả thực nghiệm của chúng tôi cho thấy KGpip vượt trội
so với tất cả các hệ thống AutoML hiện có và đạt được kết quả tiên tiến
trên phần lớn các tập dữ liệu này. KGpip
cải thiện đáng kể hiệu suất của cả FLAML và
Auto-Sklearn trong các tác vụ phân loại và hồi quy. Chúng tôi cũng
vượt trội so với AL trong 75 trong số 77 tập dữ liệu và VolcanoML
trong 75 trong số 121 tập dữ liệu, bao gồm 44 tập dữ liệu chỉ được sử dụng bởi
VolcanoML [ 17]. Trung bình, KGpip đạt được điểm số tốt hơn
về mặt thống kê so với trung bình của tất cả các hệ thống khác.
2 CÔNG TRÌNH LIÊN QUAN
Trong mục này, chúng tôi tóm tắt công trình liên quan và giới hạn việc xem xét
của chúng tôi đến các phương pháp meta-learning cho AutoML, nhúng tập dữ liệu,
và xử lý dữ liệu có cấu trúc dạng bảng.
Lựa chọn bộ học và tiền xử lý. Trong hầu hết các hệ thống AutoML, việc lựa chọn bộ học
và tiền xử lý cho bài toán khởi đầu lạnh được điều khiển bởi
cơ sở dữ liệu của các lần thực thi thực tế của pipeline và dữ liệu; ví dụ, [ 2], [9],
[10]. Cơ sở dữ liệu này thường điều khiển cả việc lựa chọn bộ học và tối ưu hóa siêu
tham số (HPO), vì vậy chúng tôi tập trung ở đây nhiều hơn vào cách
cơ sở dữ liệu được thu thập hoặc áp dụng cho một trong hai vấn đề, vì việc áp dụng thực tế
vào việc lựa chọn bộ học hoặc HPO ít liên quan hơn. Đối với HPO,
một số đã đưa việc áp dụng cơ sở dữ liệu thành một vấn đề đa nhiệm
(xem [ 26]), nơi các siêu tham số cho khởi đầu lạnh được chọn
dựa trên nhiều tập dữ liệu liên quan. Những người khác, chẳng hạn, [ 9,25], tính
toán cơ sở dữ liệu của các meta-features tập dữ liệu trên nhiều tập dữ liệu OpenML
[28], bao gồm các thuộc tính tập dữ liệu như số lượng
thuộc tính số, số lượng mẫu hoặc độ lệch của các
đặc trưng trong mỗi tập dữ liệu.
Các hệ thống này đo lường sự tương tự giữa các tập dữ liệu và sử dụng
pipeline từ các tập dữ liệu gần nhất dựa trên khoảng cách giữa
các vector đặc trưng của tập dữ liệu như chúng tôi làm, nhưng việc tính toán các
vector này khác nhau, như chúng tôi mô tả chi tiết dưới đây. Auto-Sklearn 2.0
[8] thay vào đó định nghĩa một danh mục tĩnh của các pipeline hoạt động trên
nhiều tập dữ liệu đa dạng, và sử dụng chúng để khởi đầu lạnh thành phần lựa chọn bộ học - 
tức là, mỗi tập dữ liệu mới sử dụng cùng
tập pipeline. Những người khác đã tạo ra các ma trận lớn ghi lại hiệu suất của các pipeline ứng viên cho các tập dữ liệu khác nhau và
xem việc lựa chọn pipeline liên quan như một vấn đề lọc cộng tác [10].
Nhúng tập dữ liệu. Cơ chế được sử dụng nhiều nhất để nắm bắt các đặc trưng tập dữ liệu dựa vào
việc sử dụng meta-features cho một tập dữ liệu như
[9,25]. Các thuộc tính tập dữ liệu này khác nhau từ đơn giản, như số
lớp (xem, ví dụ [ 6]), đến phức tạp và tốn kém, như các đặc trưng thống kê (xem, ví dụ [ 29]) hoặc đặc trưng mốc (xem, ví dụ [ 23]). Như
được chỉ ra trong Auto-Sklearn 2.0 [ 8], các meta-features này không được
định nghĩa đối với các loại cột nhất định như cột phân loại, và chúng cũng tốn kém để tính toán, trong
ngân sách hạn chế. Nhúng tập dữ liệu mà chúng tôi áp dụng xây dựng
nhúng cột riêng lẻ, và sau đó gộp chúng cho nhúng mức bảng.
Tương tự với phương pháp của chúng tôi, Drori et al . [5] sử dụng các mô hình ngôn ngữ được huấn luyện trước
để có được nhúng tập dữ liệu dựa trên thông tin văn bản tập dữ liệu
có sẵn, ví dụ tiêu đề, mô tả và từ khóa. Với những
nhúng này, phương pháp của họ cố gắng tìm các tập dữ liệu tương tự nhất
và các baseline liên quan của chúng. Không giống như [ 5], phương pháp của chúng tôi dựa vào
việc nhúng dữ liệu thực tế bên trong tập dữ liệu chứ không chỉ
mô tả văn bản tổng thể của chúng, trong nhiều trường hợp là không có sẵn.
OBOE [ 33] sử dụng hiệu suất của một vài mô hình không tốn kém, có thông tin
để tính toán các đặc trưng của một mô hình.
Tạo pipeline. Có một lượng đáng kể công trình xem
việc lựa chọn bộ học cũng như siêu tham số như một vấn đề tối ưu hóa bayesian
như [ 26,27]. Các hệ thống khác đã sử dụng
thuật toán tiến hóa cùng với các mẫu hoặc ngữ pháp do người dùng định nghĩa
cho mục đích này như TPOT [ 15] hoặc Recipe [ 4]. Tuy nhiên, những người khác đã
xem vấn đề tạo pipeline như một phân tích ma trận xác suất [ 10], một vấn đề lập kế hoạch AI khi kết hợp với
ngữ pháp do người dùng chỉ định [ 14,31], một vấn đề tối ưu hóa bayesian
kết hợp với Tìm kiếm Cây Monte Carlo [ 24], hoặc một vấn đề tối ưu hóa phương pháp hướng thay thế lặp (ADMM)
[ 19]. Các hệ thống như VolcanoML tập trung vào một phân tách hiệu quả
của không gian tìm kiếm [ 17]. Theo hiểu biết tốt nhất của chúng tôi,
KGpip là hệ thống đầu tiên đưa việc tạo thực tế của pipeline
thành một vấn đề tạo đồ thị neural.
Một số hệ thống AutoML gần đây đã chuyển khỏi các
pipeline khá tuyến tính được tạo bởi hầu hết các hệ thống trước đó để sử dụng ensemble
hoặc stacking rộng rãi. Chẳng hạn H2O sử dụng tìm kiếm ngẫu nhiên nhanh
kết hợp với ensembling cho vấn đề tạo
pipeline [ 16]. Những người khác dựa vào "stacking một tập các mô hình được làm riêng theo
thứ tự được định nghĩa trước", nơi stacking và huấn luyện được xử lý theo
cách đặc biệt để đạt hiệu suất mạnh [ 7]. Tương tự, PIPER
[20] sử dụng thuật toán tìm kiếm tham lam tốt nhất đầu tiên để duyệt không gian
của các pipeline một phần được hướng dẫn trên ngữ pháp định nghĩa các
pipeline phức tạp như Đồ thị Có hướng Không chu trình (DAG). Các pipeline
được tạo bởi PIPER phức tạp hơn các cấu trúc tuyến tính được sử dụng
trong các hệ thống AutoML hiện tại mà chúng tôi sử dụng để kiểm tra ý tưởng của mình về
mô hình pipeline lịch sử, và chúng tôi chưa sử dụng các kỹ thuật ensembling
trong phương pháp của mình. Tuy nhiên, không có gì bị loại trừ, vì mô hình meta-learning KGpip
có thể tạo ra bất kỳ loại cấu trúc nào, bao gồm
các cấu trúc phức tạp mà các pipeline được khai thác có thể có.
2

--- TRANG 3 ---
Hình 1: Tổng quan về phương pháp meta-learning của KGpip
để khai thác cơ sở dữ liệu các pipeline ML để huấn luyện một mô hình tạo đồ thị
để dự đoán khung pipeline ML dưới dạng
đồ thị.
3 META-LEARNING CÓ THỂ MỞ RỘNG KGPIP
Phương pháp meta-learning của chúng tôi dựa trên việc khai thác cơ sở dữ liệu lớn
các pipeline ML liên quan đến các tập dữ liệu được sử dụng, như được minh họa trong
Hình 1. Quá trình khai thác sử dụng phân tích chương trình tĩnh thay vì
thực thi các script pipeline thực tế hoặc chuẩn bị dữ liệu thô thực tế. Thành phần meta-learning KGpip nâng cao chiến lược tìm kiếm
của các hệ thống AutoML hiện có, như AutoSklearn và
FLAML, và cho phép các hệ thống này xử lý các tập dữ liệu đặc biệt, tức là,
những tập chưa thấy. Để duy trì mức độ linh hoạt tối đa, KGpip nắm bắt
metadata và ngữ nghĩa trong định dạng đồ thị linh hoạt, và dựa vào
các mô hình tạo đồ thị như cơ sở dữ liệu của pipeline.
Không giống như các phương pháp meta-learning hiện có, phương pháp của chúng tôi được thiết kế
để học từ cơ sở dữ liệu quy mô lớn và đạt được mức độ phủ sóng và đa dạng cao. Một số cổng thông tin ML, như Kaggle hoặc OpenML [ 28], cung cấp quyền truy cập vào hàng nghìn tập dữ liệu liên quan
đến hàng trăm nghìn notebook công khai, tức là, các
pipeline/mã ML. KGpip khai thác các cơ sở dữ liệu lớn này của tập dữ liệu và
pipeline bằng phân tích tĩnh và lọc chúng thành các pipeline ML
được tùy chỉnh cho vấn đề lựa chọn bộ học. Phương pháp meta-learning KGpip tận dụng [ 1] để hiểu mã thông qua phân tích tĩnh
của script/mã của pipeline ML. Nó trích xuất ngữ nghĩa
của các script này như mã và tạo thành một đồ thị ban đầu cho mỗi script.
KGpip làm sạch các đồ thị được tạo bởi [ 1] để giữ ngữ nghĩa
cần thiết cho quá trình meta-learning ML. Hơn nữa, phương pháp của chúng tôi
giới thiệu các nút tập dữ liệu và liên kết các ngữ nghĩa pipeline liên quan
đến chúng. Vì vậy, phương pháp meta-learning của chúng tôi tạo ra MetaPip,
một đồ thị có liên kết cao của các tập dữ liệu đã thấy và pipeline được áp dụng
lên chúng. Chúng tôi cũng đã phát triển một mô hình nhúng sâu để tìm
các tập dữ liệu gần nhất với một tập chưa thấy, tức là, để cắt tỉa MetaPip hiệu quả.
Sau đó chúng tôi huấn luyện một mô hình tạo đồ thị sâu [ 18] sử dụng MetaPip.
Mô hình này là cốt lõi của thành phần meta-learning của chúng tôi như được minh họa
trong Hình 1 và thảo luận trong mục tiếp theo.
3.1 Biểu diễn Đồ thị của Ngữ nghĩa Mã
Các kỹ thuật phân tích chương trình tĩnh và động có thể được sử dụng để trừu tượng hóa
ngữ nghĩa của chương trình và trích xuất các biểu diễn độc lập ngôn ngữ
của mã. Mã nguồn chương trình được kiểm tra trong
phân tích tĩnh mà không chạy chương trình. Ngược lại, phân tích động kiểm tra mã nguồn trong thời gian chạy để thu thập
vết bộ nhớ và thống kê chi tiết hơn cụ thể cho kỹ thuật phân tích. Không giống như phân tích tĩnh, phân tích động giúp nắm bắt
ngữ nghĩa phong phú hơn từ chương trình với chi phí cao của
việc thực thi và lưu trữ vết bộ nhớ khổng lồ. Các cổng thông tin ML, như
 df = pd. read_csv ('example.csv ')
 df_train, df_test = train_test_split (df)
 X = df_train[' X'] 
 model = svm. SVC()
 model.fit(X, df_train[' Y'])Hình 2: Một ví dụ từ một notebook khoa học dữ liệu.
read_csvtrain_test_splitdf_train['X']df_train['Y']SVC/f_it
read_csvtrain_test_splitdf_train['X']df_train['Y']SVC/f_it
Hình 3: Đồ thị mã tương ứng với Hình 2 được thu được
với GraphGen4Code. Đồ thị hiển thị luồng điều khiển với
các cạnh màu xám và luồng dữ liệu với các cạnh màu đen. Nhiều nút và cạnh khác
không được hiển thị để đơn giản.
read_csvtrain_test_splitSVC/f_itexample.csv
Hình 4: Đồ thị MetaPip của chúng tôi từ đồ thị trong Hình 3,
nơi pipeline ML được trừu tượng hóa được liên kết với một nút tập dữ liệu
(được làm nổi bật bằng màu cam). MetaPip chứa ít nhất 96% ít
nút và cạnh hơn so với đồ thị gốc trong khi nâng cao
chất lượng tổng thể của quá trình tạo đồ thị, như được thực nghiệm trong Mục 5.5.
Kaggle, có hàng trăm nghìn pipeline ML mà không có hướng dẫn
để chạy hoặc quản lý môi trường của các pipeline này.
KGpip kết hợp nhúng tập dữ liệu với các công cụ phân tích mã tĩnh,
như GraphGen4Code [ 1], để làm phong phú ngữ nghĩa được thu thập của
pipeline ML trong khi tránh nhu cầu chạy chúng.
GraphGen4Code được tối ưu hóa để xử lý hiệu quả hàng triệu
chương trình Python, thực hiện phân tích luồng dữ liệu và luồng điều khiển
liên thủ tục để kiểm tra chẳng hạn, điều gì xảy ra với dữ liệu
được đọc từ một dataframe Pandas, nó được thao tác và
biến đổi như thế nào, và các transformer hoặc estimator nào được gọi trên
dataframe. Các đồ thị của GraphGen4Code làm cho việc gọi API
và hàm nào trên các đối tượng trở nên rõ ràng mà không cần mô hình hóa
các thư viện được sử dụng; do đó GraphGen4Code có thể mở rộng
phân tích tĩnh đến hàng triệu chương trình. Hình 2 và 3 hiển thị một
đoạn mã nhỏ và đồ thị phân tích tĩnh tương ứng từ
GraphGen4Code. Như được hiển thị trong Hình 3, đồ thị
nắm bắt luồng điều khiển (cạnh màu xám), luồng dữ liệu (cạnh màu đen), cũng như
nhiều nút và cạnh khác không được hiển thị trong
hình. Ví dụ về các nút và cạnh này bao gồm những cái nắm bắt
vị trí của các cuộc gọi bên trong một tệp script và tham số cuộc gọi hàm.
Chẳng hạn, GraphGen4Code tạo ra một đồ thị khoảng 1600
nút và 3700 cạnh cho một script pipeline ML Kaggle có 72 dòng
mã. Số lượng nút và cạnh chi phối độ phức tạp của
việc huấn luyện một mô hình tạo đồ thị.
3.2 MetaPip: từ Mã đến Ngữ nghĩa Pipeline
Đối với các hệ thống AutoML, một pipeline là một tập các phép biến đổi dữ liệu,
lựa chọn bộ học, và tối ưu hóa siêu tham số cho mỗi mô hình
được lựa chọn. Các notebook khoa học dữ liệu được khai thác thường chứa phân tích dữ liệu, trực quan hóa dữ liệu, và đánh giá mô hình. Hơn nữa, mỗi
3

--- TRANG 4 ---
notebook được liên kết với một hoặc nhiều tập dữ liệu. Do đó, việc
mô hình meta-learning của chúng tôi phân biệt giữa các
loại pipeline khác nhau và nhận ra mối liên kết này với tập dữ liệu là cần thiết. Các hệ thống hiện có
cho phân tích mã tĩnh trích xuất ngữ nghĩa chung của mã
và không thể liên kết script pipeline với các tập dữ liệu được sử dụng. Do đó, các
đồ thị được tạo bởi các hệ thống, như GraphGen4Code, bị phân tán
và không liên kết, tức là, một đồ thị cho mỗi script pipeline ML. Hơn nữa, mỗi
đồ thị sẽ có các nút và cạnh không liên quan đến quá trình meta-learning. Những nút và cạnh không liên quan này, tức là, các bộ ba, sẽ
thêm nhiễu vào dữ liệu huấn luyện. Do đó, một mô hình meta-learning sẽ
không thể học từ các pipeline đồ thị trừu tượng được tạo
bởi các công cụ như vậy, như được hiển thị trong Bảng 4. Chúng tôi đã phát triển một phương pháp để lọc
loại bộ ba này từ đồ thị của GraphGen4Code và phân tích
pipeline ML để chuẩn bị một tập huấn luyện kết nối các kho lưu trữ
script pipeline ML với các tập dữ liệu liên quan của chúng. Hơn nữa,
phương pháp của chúng tôi làm sạch các nút và cạnh nhiễu và các cuộc gọi đến các mô-đun
bên ngoài thư viện ML đích. Ví dụ, phương pháp của chúng tôi sẽ trích xuất các bộ ba liên quan đến các thư viện, như Scikit-learn, XGBoost, và
LGBM. Các thư viện này phổ biến nhất trong số các
pipeline ML có điểm cao nhất trong các cổng thông tin ML. Mã cho phương pháp làm sạch có sẵn tại kho lưu trữ của KGpip.
Thành phần meta-learning của chúng tôi nhằm chọn bộ học và
transformer cho các tập dữ liệu chưa thấy. Do đó, KGpip liên kết các
pipeline ML đã lọc với các tập dữ liệu được sử dụng. Kết quả của việc thêm các nút tập dữ liệu này
là một đồ thị có liên kết cao cho pipeline ML, chúng tôi gọi nó là MetaPip . Đồ thị MetaPip của chúng tôi nắm bắt cả khía cạnh mã và dữ liệu
của pipeline ML. Do đó, chúng tôi có thể điền vào đồ thị MetaPip
với các tập dữ liệu từ các nguồn khác nhau, như OpenML và Kaggle,
và các pipeline được áp dụng trên các tập dữ liệu này. Hình 4 hiển thị đồ thị MetaPip
tương ứng với đoạn mã trong Hình 2. KGpip sử dụng MetaPip để huấn luyện một mô hình dựa trên một tập lớn các pipeline liên quan
với các tập dữ liệu tương tự. Ví dụ, một nút pandas.read_csv sẽ được
liên kết với nút bảng được sử dụng, tức là, tệp csv. Trong một số trường hợp, mã,
đọc tệp csv, không đề cập rõ ràng tên tập dữ liệu.
Các pipeline thường được liên kết với tập dữ liệu, như các
pipeline và tập dữ liệu Kaggle, như được hiển thị trong Hình 1.
3.3 Học Biểu diễn Tập dữ liệu
Phương pháp của chúng tôi hướng dẫn hiệu quả quá trình meta-learning bằng cách liên kết
ngữ nghĩa đã trích xuất của pipeline với các nút tập dữ liệu đại diện
cho các tập dữ liệu được sử dụng. Có một lượng lớn tập dữ liệu có kích thước khác nhau và chúng tôi cần phát triển một phương pháp có thể mở rộng để tìm các
tập dữ liệu tương tự nhất cho một tập chưa thấy. Việc so sánh từng cặp dựa
trên nội dung thực tế của tập dữ liệu, tức là, các bộ trong tệp CSV, không mở rộng được. Do đó, chúng tôi đã phát triển một phương pháp học biểu diễn tập dữ liệu
để tạo ra một nhúng có kích thước cố định và dày đặc ở mức độ chi tiết của
một tập dữ liệu, ví dụ, một bảng hoặc tệp CSV. Nhúng của một tập dữ liệu D là
trung bình của các nhúng cột của nó, tức là:
ℎ𝜃(D)=1
|D|∑︁
𝑐∈Dℎ𝜃(𝑐) (1)
trong đó|D|là số cột trong D. Công việc của chúng tôi tổng quát hóa
phương pháp được nêu trong [ 21] cho nhúng cột riêng lẻ, nơi
nhúng cột được thu được bằng cách huấn luyện một mạng neural trên
một tác vụ phân loại nhị phân. Mô hình học khi nào hai cột
đại diện cho cùng một khái niệm, nhưng với các giá trị khác nhau, trái ngược với
Hình 5: Tổng quan về luồng công việc của KGpip về tạo pipeline ML
cho một tập dữ liệu chưa thấy đã cho và ngân sách thời gian
nhất định. KGpip sử dụng các hệ thống để tối ưu hóa siêu tham số,
như FLAML hoặc Auto-Sklearn, để tối ưu hóa top-K pipeline được dự đoán
của KGpip ( 𝑉𝐺), tức là, cắt tỉa không gian tìm kiếm.
các cột đại diện cho các khái niệm khác nhau. Nhúng cho một tập dữ liệu chưa thấy
được tạo ra bởi lớp cuối cùng của mạng neural.
KGpip đọc tập dữ liệu chỉ một lần và tận dụng PySpark DataFrame
để đạt được song song tác vụ và dữ liệu cao. Chúng tôi sử dụng nhúng
của tập dữ liệu để đo lường sự tương tự của chúng. Với các nhúng này,
chúng tôi xây dựng một chỉ mục của nhúng vector cho tất cả tập dữ liệu trong
tập huấn luyện của chúng tôi. Chúng tôi sử dụng các thư viện hiệu quả [ 13] để tìm kiếm tương tự
của vector dày đặc để truy xuất tập dữ liệu tương tự nhất với một tập dữ liệu đầu vào mới
dựa trên nhúng của nó. Do đó, phương pháp của chúng tôi mở rộng tốt và
dẫn đến kết quả chính xác trong việc nắm bắt sự tương tự giữa các tập dữ liệu.
4 TỰ ĐỘNG HÓA PIPELINE KGPIP
Luồng công việc KGpip cho tự động hóa pipeline dựa trên mô hình meta-
learning của chúng tôi, như được minh họa trong Hình 5. KGpip dự đoán top-K
khung pipeline, tức là, một tập cụ thể { 𝑃,𝐸} của Preprocessor ( 𝑃) và
Estimators ( 𝐸), cho một tập dữ liệu chưa thấy ( 𝐷) dựa trên tập dữ liệu
đã thấy tương tự nhất ( 𝑆𝐷), tức là, tập dữ liệu hàng xóm gần nhất. KGpip bắt đầu
bằng cách tìm𝑆𝐷dựa trên nhúng của tập dữ liệu chưa thấy. Sau đó,
KGpip tạo ra top-K đồ thị pipeline ML đã xác thực 𝑉𝐺và
chuyển đổi chúng thành khung pipeline ML {𝑃,𝐸}. Sau đó, nó thực hiện
tối ưu hóa siêu tham số bằng các hệ thống, như FLAML [ 30]
và Auto-Sklearn [ 9], để tìm các siêu tham số tối ưu cho
mỗi khung pipeline trong một ngân sách thời gian cụ thể.
4.1 Tạo Đồ thị cho Pipeline ML
KGpip công thức hóa việc tạo pipeline ML như một vấn đề tạo đồ thị. Trực giác đằng sau ý tưởng này là một bộ tạo đồ thị neural có thể nắm bắt ngắn gọn hơn nhiều pipeline
được thấy trong thực tế cho một tập dữ liệu đã cho, và cũng có thể nắm bắt sự tương tự thống kê giữa các pipeline khác nhau hiệu quả hơn. Để
sử dụng hiệu quả mạng như vậy, chúng tôi thêm một nút tập dữ liệu duy nhất như
điểm khởi đầu cho các pipeline đã lọc mà chúng tôi tạo ra từ các
notebook Python. Nút được giả định là chảy vào một cuộc gọi read_csv thường là
điểm khởi đầu cho các pipeline. Để tạo ra một
pipeline ML, chúng tôi chỉ cần truyền vào một nút tập dữ liệu cho hàng xóm gần nhất
của tập dữ liệu chưa thấy, tức là, tập dữ liệu tương tự nhất dựa trên sự tương tự nội dung, như được hiển thị trong Hình 5.
Mô hình meta-learning của chúng tôi tạo ra các đồ thị pipeline ML theo
cách tuần tự từng nút một. Thuật toán 1 minh họa việc triển khai
của mô hình tạo đồ thị. Đối với một đồ thị trống 𝐺
và tập dữ liệu tương tự nhất 𝑆𝐷, thuật toán bắt đầu bằng cách thêm một
cạnh giữa 𝑆𝐷vàpandas.read_csv . Sau đó, mạng neural đồ thị
4

--- TRANG 5 ---
Thuật toán 1: Quá trình Tạo Đồ thị
Đầu vào: Đồ thị𝐺: (𝐸=𝜙,𝑉=𝜙), Nút Tập dữ liệu Tương tự: 𝑆𝐷,
Mạng Neural: 𝑓𝐴𝑑𝑑𝑁𝑜𝑑𝑒,𝑓𝐴𝑑𝑑𝐸𝑑𝑔𝑒,𝑓𝐶ℎ𝑜𝑜𝑠𝑒𝑁𝑜𝑑𝑒
1𝑉←𝑉∪{𝑆𝐷,𝑝𝑎𝑛𝑑𝑎𝑠.𝑟𝑒𝑎𝑑 _𝑐𝑠𝑣}
2𝐸←𝐸∪{(𝑆𝐷,𝑝𝑎𝑛𝑑𝑎𝑠.𝑟𝑒𝑎𝑑 _𝑐𝑠𝑣)}
3𝑛𝑜𝑑𝑒𝑇𝑜𝐴𝑑𝑑 =𝑓𝐴𝑑𝑑𝑁𝑜𝑑𝑒(𝑉,𝐸)
4while𝑛𝑜𝑑𝑒𝑇𝑜𝐴𝑑𝑑 ≠𝑁𝑢𝑙𝑙 do
5𝑉←𝑉∪{𝑛𝑜𝑑𝑒𝑇𝑜𝐴𝑑𝑑}
6𝑎𝑑𝑑𝐸𝑑𝑔𝑒 =𝑓𝐴𝑑𝑑𝐸𝑑𝑔𝑒(𝑉,𝐸)
7 while𝑎𝑑𝑑𝐸𝑑𝑔𝑒 do
8𝑛𝑜𝑑𝑒𝑇𝑜𝐿𝑖𝑛𝑘 =𝑟𝐶ℎ𝑜𝑜𝑠𝑒𝑁𝑜𝑑𝑒(𝑉,𝐸)
9𝐸←𝐸∪{(𝑛𝑜𝑑𝑒𝑇𝑜𝐴𝑑𝑑,𝑛𝑜𝑑𝑒𝑇𝑜𝐿𝑖𝑛𝑘 )}
10𝑎𝑑𝑑𝐸𝑑𝑔𝑒←𝑓𝐴𝑑𝑑𝐸𝑑𝑔𝑒(𝑉,𝐸)
11 end
12𝑛𝑜𝑑𝑒𝑇𝑜𝐴𝑑𝑑←𝑓𝐴𝑑𝑑𝑁𝑜𝑑𝑒(𝑉,𝐸)
13end
14𝑉𝐺=𝑣𝑎𝑙𝑖𝑑𝑎𝑡𝑒 _𝑝𝑖𝑝𝑒𝑙𝑖𝑛𝑒 _𝑔𝑟𝑎𝑝ℎ(𝐺)
15return VG
mạng𝑓𝐴𝑑𝑑𝑁𝑜𝑑𝑒 quyết định có thêm một nút mới của một loại
nhất định hay không. Mạng 𝑓𝐴𝑑𝑑𝐸𝑑𝑔𝑒 quyết định có thêm một cạnh
vào nút mới thêm hay không. Sau đó, mạng 𝑓𝐶ℎ𝑜𝑜𝑠𝑒𝑁𝑜𝑑𝑒 quyết định
nút hiện có mà cạnh sẽ được thêm vào. Vòng lặp While
ở dòng 7 được lặp lại cho đến khi không còn cạnh nào để thêm.
Vòng lặp While ở dòng 4 được lặp lại cho đến khi không còn nút nào để thêm.
Ba mạng neural, cụ thể là 𝑓𝐴𝑑𝑑𝑁𝑜𝑑𝑒 ,𝑓𝐴𝑑𝑑𝐸𝑑𝑔𝑒 , và
𝑓𝐶ℎ𝑜𝑜𝑠𝑒𝑁𝑜𝑑𝑒 , sử dụng nhúng nút được học trong suốt
quá trình huấn luyện thông qua các vòng truyền bá đồ thị. Các nhúng này nắm bắt
cấu trúc của đồ thị pipeline ML.
Đồ thị được tạo ra 𝐺không được đảm bảo là một pipeline ML hợp lệ. Do đó, Thuật toán 1 ở dòng 14 kiểm tra rằng 𝐺là một
đồ thị pipeline ML hợp lệ. Trong KGpip, một đồ thị 𝐺hợp lệ nếu 1) nó chứa ít nhất
một estimator khớp với tác vụ, tức là, hồi quy hoặc phân loại,
và 2) estimator được hỗ trợ bởi bộ tối ưu hóa siêu tham số
(AutoSklearn hoặc FLAML trong trường hợp của chúng tôi). Với những sửa đổi này, có thể
tạo ra pipeline ML cho các tập dữ liệu chưa thấy bằng cách sử dụng
nút tập dữ liệu đã thấy gần nhất – cụ thể hơn, nhúng nội dung của nó
được thu từ mô-đun nhúng tập dữ liệu. Chúng tôi đã xây dựng Thuật toán 1
dựa trên hệ thống được đề xuất trong [ 18]. Hệ thống này không hỗ trợ
tạo đồ thị có điều kiện tại thời điểm kiểm tra theo mặc định, tức là, xây dựng một
đồ thị trên một nút tập dữ liệu được cung cấp. Chúng tôi đã mở rộng hệ thống này
để tạo ra các đồ thị pipeline ML hợp lệ, như được minh họa trong Thuật toán 1.
4.2 Tối ưu hóa Siêu tham số
KGpip ánh xạ các đồ thị hợp lệ thành khung pipeline ML, trong đó
mỗi khung là một tập các bộ tiền xử lý và một estimator với
chỗ giữ chỗ cho các tham số tối ưu. Trong KGpip, bộ tối ưu hóa siêu tham số
chịu trách nhiệm tìm các tham số tối ưu
cho các bộ tiền xử lý và bộ học trên tập dữ liệu đích. Sau đó,
KGpip thay thế các chỗ giữ chỗ bằng các tham số này. Cuối cùng,
KGpip tạo ra một script python sử dụng các bộ tiền xử lý và estimator đạt được điểm số cao nhất. KGpip được thiết kế tốt để hỗ trợ
cả tập dữ liệu số và không số. Do đó, KGpip áp dụng
các kỹ thuật tiền xử lý khác nhau trên tập dữ liệu đã cho ( 𝐷) và
tạo ra một tập dữ liệu đã tiền xử lý ( 𝐷′). Tiền xử lý của chúng tôi bao gồm
1) phát hiện loại tác vụ (tức là hồi quy hoặc phân loại) tự động dựa trên phân phối của cột đích 2) tự động suy luận
các loại dữ liệu chính xác của các cột, 3) vector hóa các cột văn bản
bằng nhúng từ [ 3], và 4) điền các giá trị bị thiếu trong
tập dữ liệu. Trong KGpip, bộ tối ưu hóa siêu tham số sử dụng 𝐷′.
Tương tự như các bộ tối ưu hóa siêu tham số được triển khai trong các hệ thống AutoML,
như FLAML hoặc Auto-Sklearn, KGpip hoạt động trong một
ngân sách thời gian được cung cấp cho mỗi tập dữ liệu. Chúng tôi lưu ý ở đây rằng phần lớn
ngân sách thời gian được phân bổ cho việc tạo pipeline ML được dành cho
tối ưu hóa siêu tham số; tức là, nếu người dùng chỉ muốn
biết bộ học nào sẽ hoạt động tốt nhất cho tập dữ liệu của họ, KGpip
có thể làm điều đó gần như ngay lập tức. Với một ngân sách thời gian ( 𝑇), KGpip
tính toán𝑡, thời gian tiêu thụ trong việc tạo và xác thực các
đồ thị. KGpip sau đó chia phần còn lại của ngân sách thời gian giữa
𝐾đồ thị. Do đó, bộ tối ưu hóa siêu tham số có giới hạn thời gian
((𝑇−𝑡)/𝐾) để tối ưu hóa mỗi đồ thị độc lập.
Bộ tối ưu hóa siêu tham số liên tục áp dụng các bộ học
và bộ tiền xử lý với các cấu hình khác nhau trong khi theo dõi
số liệu điểm đích trong suốt quá trình. KGpip tiếp tục cập nhật đầu ra
của nó với khung pipeline tốt nhất, tức là, bộ học và bộ tiền xử lý, và
điểm số của nó. Ví dụ, nếu bộ học được dự đoán là LogisticRegression,
nó tìm kiếm sự kết hợp tốt nhất của loại chính quy hóa (L1 hoặc
L2) và tham số chính quy hóa. Sự khác biệt giữa các bộ tối ưu hóa siêu tham số
là chiến lược tìm kiếm được tuân theo để đến
các siêu tham số tốt nhất trong ngân sách thời gian được phân bổ. Một
phương pháp ngây thơ sẽ là thực hiện tìm kiếm lưới toàn diện trên tất cả
các tổ hợp, trong khi một phương pháp tiên tiến hơn sẽ là bắt đầu
với các cấu hình hứa hẹn trước. Chúng tôi tích hợp KGpip với
các bộ tối ưu hóa siêu tham số của cả FLAML [ 30] và Auto-Sklearn
[9] để chứng minh tính tổng quát của KGpip. Việc tích hợp một
bộ tối ưu hóa siêu tham số vào KGpip cần một tài liệu JSON của
các bộ tiền xử lý và estimator cụ thể được hỗ trợ bởi bộ tối ưu hóa siêu tham số. Do đó, việc tích hợp tương đối dễ dàng. Cuối cùng,
việc tạo đồ thị neural của chúng tôi tạo ra một tập pipeline đa dạng
qua các lần chạy, cho phép khám phá và khai thác.
5 THỰC NGHIỆM
5.1 Điểm chuẩn
Chúng tôi đánh giá KGpip cũng như các baseline khác trên bốn tập dữ liệu điểm chuẩn: 1) Open AutoML Benchmark [11], một bộ sưu tập 39 tập dữ liệu phân loại nhị phân và đa lớp (được sử dụng bởi FLAML [ 30]). Các
tập dữ liệu được chọn sao cho chúng đại diện cho thế giới thực từ sự đa dạng của các lĩnh vực vấn đề và đủ khó
cho các thuật toán học. 2) Penn Machine Learning Benchmark
(PMLB) [ 22]: Vì Open AutoML Benchmark bị giới hạn ở các
tập dữ liệu phân loại, các tác giả của FLAML [ 30] đánh giá hệ thống của họ
trên 14 tập dữ liệu hồi quy được chọn từ PMLB, sao cho
số lượng mẫu lớn hơn 10,000. Để chứng minh tính tổng quát
của phương pháp chúng tôi, chúng tôi cũng bao gồm các tập dữ liệu đó trong đánh giá của chúng tôi. 3) Tập dữ liệu của AL : Chúng tôi cũng đánh giá trên các tập dữ liệu được sử dụng cho
đánh giá của AL [ 2] bao gồm 6 tập dữ liệu Kaggle (2 hồi quy
và 4 phân loại) và 18 tập dữ liệu phân loại khác (9 từ
PMLB và 9 từ OpenML). Không giống như các điểm chuẩn khác, các
tập dữ liệu Kaggle bao gồm các tập dữ liệu có đặc trưng văn bản. 4) Tập dữ liệu của VolcanoML: cuối cùng, chúng tôi đánh giá KGpip trên 44 tập dữ liệu được sử dụng bởi
VolcanoML [ 17]. Các tác giả của VolcanoML đánh giá hệ thống của họ
trên tổng cộng 66 tập dữ liệu từ OpenML và Kaggle, trong đó
5

--- TRANG 6 ---
Bảng 1: Phân tích tất cả 121 tập dữ liệu được sử dụng trong
đánh giá của chúng tôi, chỉ ra những tập được sử dụng bởi FLAML∗, AL†, và
VolcanoML§.
Nguồn
Tác vụ AutoML PMLB OpenML Kaggle
Nhị phân 22(18∗+1∗†+3∗§)5(4†+1†§)27(3†§+3†+21§)2†
Đa lớp 17(15∗+1∗†+1∗§)4†7(2†§+1†+ 4§)2†
Hồi quy 0 14∗19§2†
Tổng cộng 39 23 53 6
11 tập dữ liệu không được chỉ định, 10 tập dữ liệu trùng lặp với của chúng tôi, và 1
tập dữ liệu bao gồm các mẫu hình ảnh. Bảng 1 bao gồm tóm tắt của
tất cả 121 tập dữ liệu điểm chuẩn. Thống kê chi tiết của tất cả tập dữ liệu
được hiển thị trong phụ lục. Các thống kê này bao gồm tên, số
hàng và cột, số đặc trưng số, phân loại, và
văn bản, số lớp, kích thước, nguồn, và các bài báo đã
đánh giá trên chúng.
5.2 Baseline
Chúng tôi xác thực thực nghiệm KGpip so với ba hệ thống AutoML: (1)
Auto-Sklearn (v0.14.0) [ 9] là người chiến thắng tổng thể của nhiều
thách thức trong cuộc thi ChaLearn AutoML [ 12], và một trong
4 đối thủ hàng đầu được báo cáo trong Open AutoML Benchmark
[11]. (2) FLAML (v0.6.6) [ 30]: một thư viện AutoML được thiết kế
với cả độ chính xác và chi phí tính toán trong tâm trí. FLAML vượt trội so với
Auto-Sklearn trong số các hệ thống khác trên hai điểm chuẩn AutoML sử dụng ngân sách tính toán thấp, (3) AL [ 2]: một phương pháp AutoML dựa trên meta-learning
sử dụng phân tích động của các notebook Kaggle, một phương pháp có điểm tương đồng với của chúng tôi, và (4) VolcanoML
(v0.5.0) [ 17], một phương pháp AutoML gần đây đề xuất các chiến lược phân tách hiệu quả
cho các không gian tìm kiếm AutoML lớn. Trong tất cả
thực nghiệm của chúng tôi, chúng tôi sử dụng mã mới nhất được cung cấp bởi các tác giả
cho các hệ thống hiện có, cùng phần cứng, ngân sách thời gian, và
các tham số được khuyến nghị bởi các tác giả của các hệ thống này.
5.3 Thiết lập Huấn luyện
Bởi vì phương pháp của chúng tôi để khai thác pipeline lịch sử từ script
tương đối rẻ, chúng tôi có thể áp dụng nó dễ dàng hơn trên nhiều
tập dữ liệu đa dạng hơn để tạo thành một cơ sở tốt hơn khi ngày càng nhiều script được
tạo ra bởi các chuyên gia lĩnh vực trong các cuộc thi Kaggle. Trong công việc này,
chúng tôi đã thực hiện phân tích chương trình trên 11.7K script liên quan đến
142 tập dữ liệu, và sau đó chọn những script có estimator từ sklearn ,
XGBoost vàLightGBM vì đó là các estimator được hỗ trợ
bởi hầu hết các hệ thống AutoML cho phân loại và hồi quy. Điều này
dẫn đến việc lựa chọn 2,046 notebook cho 104 tập dữ liệu; một phần lớn
của 11.7K chương trình là về phân tích dữ liệu khám phá, hoặc liên quan đến các thư viện không được hỗ trợ bởi Auto-Sklearn [ 9]
hoặc FLAML (ví dụ, PyTorch và Keras) [ 30]. Chúng tôi sử dụng Macro F1 cho
các tác vụ phân loại để tính đến sự mất cân bằng dữ liệu, nếu có, và sử dụng
𝑅2cho các tác vụ hồi quy, như trong FLAML [ 30]. Chúng tôi cũng thay đổi ngân sách thời gian
được cung cấp cho mỗi hệ thống giữa 1 giờ và 30 phút, để
đo mức độ nhanh mà KGpip có thể tìm thấy một pipeline hiệu quả so với
các phương pháp khác. Ngân sách thời gian là từ đầu đến cuối, từ việc tải
tập dữ liệu cho đến tạo ra pipeline AutoML tốt nhất. Trong tất cả thực nghiệm,
chúng tôi báo cáo trung bình trên 3 lần chạy.

(Continue with remaining content due to length constraints...)
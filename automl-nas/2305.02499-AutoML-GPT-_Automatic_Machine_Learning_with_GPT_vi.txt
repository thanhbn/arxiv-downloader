# AutoML-GPT: Học Máy Tự Động với GPT

Shujian Zhang Chengyue Gong Lemeng Wu Xingchao Liu
Mingyuan Zhou
Đại học Texas tại Austin
{szhang19, mzhou}@utexas.edu

## Tóm tắt

Các nhiệm vụ AI bao gồm một loạt rộng các lĩnh vực và ngành. Trong khi nhiều mô hình AI đã được thiết kế cho các nhiệm vụ và ứng dụng cụ thể, chúng thường yêu cầu nỗ lực đáng kể từ con người trong việc tìm ra kiến trúc mô hình đúng, thuật toán tối ưu hóa và siêu tham số. Những tiến bộ gần đây trong các mô hình ngôn ngữ lớn (LLMs) như ChatGPT cho thấy khả năng đáng chú ý trong nhiều khía cạnh của lý luận, hiểu biết và tương tác. Do đó, chúng tôi đề xuất phát triển các prompt hướng nhiệm vụ và tự động sử dụng LLMs để tự động hóa quy trình đào tạo. Để triển khai khái niệm này, chúng tôi trình bày AutoML-GPT, sử dụng GPT như cầu nối đến các mô hình AI đa dạng và đào tạo động các mô hình với siêu tham số được tối ưu hóa. AutoML-GPT nhận động yêu cầu của người dùng từ các thẻ mô hình và dữ liệu và soạn đoạn prompt tương ứng. Cuối cùng, với đoạn prompt này, AutoML-GPT sẽ tự động tiến hành các thí nghiệm từ xử lý dữ liệu đến kiến trúc mô hình, điều chỉnh siêu tham số và nhật ký đào tạo dự đoán. Bằng cách tận dụng khả năng ngôn ngữ mạnh mẽ của AutoML-GPT và các mô hình AI có sẵn, AutoML-GPT có thể giải quyết nhiều nhiệm vụ AI phức tạp trên các nhiệm vụ và tập dữ liệu khác nhau. Phương pháp này đạt được kết quả đáng chú ý trong thị giác máy tính, xử lý ngôn ngữ tự nhiên và các lĩnh vực thách thức khác. Các thí nghiệm mở rộng và nghiên cứu loại bỏ cho thấy phương pháp của chúng tôi có thể tổng quát, hiệu quả và có lợi cho nhiều nhiệm vụ AI.

## 1 Giới thiệu

Trí tuệ nhân tạo (AI) đã trải qua những tiến bộ đáng kể gần đây. Trong số những phát triển này, ChatGPT [OpenAI, 2023] đã đặc biệt nổi bật do khả năng lý luận, hiểu biết và tương tác của nó [Wu et al., 2023]. Khả năng thực hiện các nhiệm vụ mới dựa trên hướng dẫn là một bước quan trọng hướng tới việc đạt được trí tuệ nhân tạo tổng quát, và những khả năng đáng chú ý của các mô hình ngôn ngữ lớn (LLMs) đã thúc đẩy nhiều chủ đề nghiên cứu mới nổi, chẳng hạn như học trong ngữ cảnh [Ram et al., 2023; Xie et al., 2021], prompting chuỗi suy nghĩ [Pilault et al., 2023; Wei et al., 2022b], truy xuất và đọc [Izacard and Grave, 2020; Zhang et al., 2021, 2022], và các hệ thống thông minh dựa trên GPT [Zheng et al., 2023]. Những lĩnh vực này nhằm khám phá tiềm năng to lớn của LLMs và mang đến cơ hội vô hạn để xây dựng các hệ thống AI tinh vi.

LLMs, như GPT-4 [Brown et al., 2020; OpenAI, 2023], LLaMA [Touvron et al., 2023], Flan-T5 [Chung et al., 2022], và PaLM [Chowdhery et al., 2022], đã chứng minh sự hiểu biết sâu sắc về ngôn ngữ tự nhiên và khả năng tạo ra các phản hồi mạch lạc, phù hợp với ngữ cảnh. Tiến bộ này đã mở ra các ứng dụng tiềm năng mới cho các nhiệm vụ thách thức liên quan đến dữ liệu lĩnh vực khác nhau, chẳng hạn như xử lý hình ảnh và văn bản, cũng như việc kết hợp kiến thức chuyên ngành cụ thể. Trong bối cảnh này, LLMs đóng vai trò quan trọng, vì khả năng hiểu và tạo ra ngôn ngữ tự nhiên của chúng cho phép AI hiểu và giải quyết tốt hơn nhiều thách thức đa dạng.

Trong bài báo này, chúng tôi nhằm phát triển một hệ thống Học Máy Tự Động (AutoML) gọi là AutoML-GPT, sử dụng LLMs để tự động đào tạo các mô hình trên tập dữ liệu với đầu vào và mô tả của người dùng. LLMs được sử dụng như một hệ thống đào tạo tự động để thiết lập kết nối với các mô hình đa năng và xử lý đầu vào. Chúng tôi đề xuất sử dụng ngôn ngữ như một giao diện và prompt phổ quát cho LLMs để tương tác với người dùng. Bằng cách kết hợp cả mô tả dữ liệu và mô hình vào prompts, LLMs có thể quản lý các mô hình AI cho xử lý dữ liệu, thiết kế kiến trúc mô hình và điều chỉnh siêu tham số. Chúng có thể gọi các mô hình này khi cần thiết để giải quyết các nhiệm vụ AI và trả về nhật ký đào tạo dự đoán. Tuy nhiên, việc kết hợp nhiều mô hình AI vào LLMs đòi hỏi một số lượng đáng kể các mô tả mô hình chất lượng cao. Để vượt qua thách thức này, chúng tôi khuyến nghị khai thác cả thẻ mô hình [Mitchell et al., 2019] cung cấp mô tả mô hình được định nghĩa rõ ràng và thẻ dữ liệu [Gebru et al., 2021] cho các nhiệm vụ AI cụ thể. Phương pháp này sẽ cho phép chúng tôi kết nối các mô hình đa dạng thông qua giao diện dựa trên ngôn ngữ, từ đó tạo điều kiện cho việc giải quyết các nhiệm vụ AI phức tạp. Nó cũng có thể tăng cường khả năng chuyển giao giữa các mô hình và tập dữ liệu bằng cách nắm bắt sự tương đồng của chúng.

AutoML-GPT kết nối các mô hình học máy đa năng, quy trình đào tạo và tập dữ liệu để giải quyết nhiều nhiệm vụ AI phức tạp. Cụ thể hơn, đối với mỗi nhiệm vụ AI chúng tôi nhằm giải quyết, sử dụng mô tả tương ứng của nó (như thẻ mô hình và thẻ dữ liệu), chúng tôi hợp nhất đoạn văn làm prompt vào LLMs được đào tạo trước (như ChatGPT) để thiết lập quy trình AutoML. Sau đó, trong hệ thống của chúng tôi, LLMs thực hiện đào tạo tự động để trả về nhật ký đào tạo dự đoán cho các câu hỏi đầu vào của người dùng. Dựa trên các nhật ký đào tạo này, chúng tôi có thể tương tác thêm với LLM để giải quyết các yêu cầu (như điều chỉnh siêu tham số) được hiển thị trong Hình 1. Do đó, toàn bộ quá trình của AutoML-GPT có thể được chia thành bốn giai đoạn: 1) xử lý dữ liệu, 2) thiết kế kiến trúc mô hình, 3) điều chỉnh siêu tham số với nhật ký đào tạo dự đoán, 4) phản hồi của con người về dữ liệu thí nghiệm.

Hưởng lợi từ thiết kế như vậy, AutoML-GPT trong Hình 1 có thể sử dụng các mô hình bên ngoài và do đó có thể xử lý nhiều nhiệm vụ trên các benchmark nổi tiếng, và chuyển giao kiến thức cho tập dữ liệu riêng tư chưa biết khi chỉ được cung cấp metadata (thẻ dữ liệu). Hơn nữa, quy trình này cũng cho phép AutoML-GPT tiếp tục hấp thụ sức mạnh từ các chuyên gia nhiệm vụ cụ thể, cho phép khả năng AI có thể phát triển và mở rộng. Tóm lại, đóng góp của chúng tôi như sau:

• Để bổ sung các lợi thế của mô hình ngôn ngữ lớn và mô hình chuyên gia, chúng tôi đề xuất AutoML-GPT, hoạt động như hệ thống xử lý dữ liệu và thiết kế kiến trúc mô hình và tự động tiến hành các thí nghiệm cho mỗi nhiệm vụ cụ thể.

• Bằng cách tích hợp thẻ mô hình với mô tả mô hình và thẻ dữ liệu với mô tả dữ liệu, chúng tôi cung cấp đoạn prompt định dạng cố định và xây dựng quy trình đào tạo để giải quyết các nhiệm vụ AI tổng quát.

• Các đánh giá mở rộng trên nhiều nhiệm vụ AI qua ngôn ngữ, thị giác và học liên tục chứng minh khả năng của AutoML-GPT trong đào tạo tự động. Nó tiếp tục chứng minh hiệu quả của việc cung cấp điều chỉnh siêu tham số cho tập dữ liệu chưa thấy hoặc mới.

[Hình 1: Tổng quan về AutoML-GPT. Một số ký hiệu được ghi nhãn cùng với các thành phần tương ứng. 'Eval Metrics & Add' đề cập đến số liệu đánh giá và yêu cầu bổ sung.]

## 2 AutoML-GPT

AutoML-GPT là một hệ thống cộng tác dựa vào thông tin dữ liệu và mô hình để định dạng đoạn đầu vào prompt. LLM đóng vai trò là bộ điều khiển, trong khi nhiều mô hình chuyên gia như những người thực thi cộng tác. Quy trình làm việc của AutoML-GPT bao gồm bốn giai đoạn: xử lý dữ liệu, thiết kế kiến trúc mô hình, điều chỉnh siêu tham số và tạo nhật ký đào tạo. Cụ thể, chúng tôi đề xuất một công thức chung cho AutoML-GPT: 1) tạo đoạn prompt định dạng cố định với cả thẻ mô hình và thẻ dữ liệu, 2) xây dựng quy trình đào tạo và xử lý yêu cầu người dùng trên tập dữ liệu và kiến trúc mô hình đã chọn, 3) tạo nhật ký đào tạo hiệu suất và điều chỉnh siêu tham số, và 4) điều chỉnh mô hình với siêu tham số được đề xuất tự động.

### 2.1 Phân tách Đầu vào

Trong giai đoạn đầu tiên của AutoML-GPT, một LLM nhận đầu vào từ người dùng. Để tăng hiệu suất của LLM và tạo prompt hiệu quả, chúng tôi sử dụng các hướng dẫn cụ thể cho prompt đầu vào. Các hướng dẫn chứa ba phần được mô tả dưới đây.

**Thẻ Dữ liệu** Để làm rõ các trường hợp sử dụng dự định của tập dữ liệu và giảm thiểu việc sử dụng chúng trong các ngữ cảnh mà chúng không phù hợp, chúng tôi sử dụng thẻ dữ liệu cung cấp tài liệu toàn diện cho tập dữ liệu này. Như được hiển thị trong Hình 2, các thành phần chính của thẻ dữ liệu bao gồm tên tập dữ liệu, loại tập dữ liệu đầu vào (ví dụ: dữ liệu hình ảnh hoặc dữ liệu văn bản), không gian nhãn (ví dụ: các loại lớp hoặc độ phân giải), và số liệu đánh giá mặc định.

[Hình 2: Thẻ Dữ liệu bao gồm tên dữ liệu, loại dữ liệu đầu vào, không gian nhãn và số liệu đánh giá. Trong thẻ dữ liệu, cùng màu biểu thị thông tin xuất phát từ một tập dữ liệu duy nhất.]

**Thẻ Mô hình** Các thẻ mô hình trong Hình 3, bổ sung cho "Thẻ Dữ liệu" đã thảo luận trước đó, đóng vai trò là một trong những mô hình đề xuất báo cáo chi tiết về mô hình được sử dụng để đào tạo và kiểm tra tập dữ liệu. Thẻ mô hình bao gồm tên mô hình, cấu trúc mô hình (ví dụ: Swin transformer [Liu et al., 2021] với đầu UperNet [Xiao et al., 2018]), mô tả mô hình và siêu tham số kiến trúc. Bằng cách cung cấp thông tin này, thẻ mô hình thông báo cho LLM về các hệ thống học máy được sử dụng và mức độ linh hoạt mà người dùng muốn có về kiến trúc mô hình. Nó sẽ tiếp tục tạo ra kết quả toàn diện hơn với LLM.

[Hình 3: Thẻ Mô hình bao gồm tên mô hình, cấu trúc mô hình, mô tả mô hình và siêu tham số kiến trúc. Trong thẻ mô hình, cùng màu đại diện cho thông tin từ một thẻ mô hình duy nhất.]

**Số liệu Đánh giá và Yêu cầu Bổ sung** Ngoài thẻ mô hình và thẻ dữ liệu, người dùng có thể có tùy chọn yêu cầu thêm các benchmark đánh giá, số liệu hoặc bất kỳ ràng buộc nào. Ngoại trừ số liệu đánh giá mặc định, chúng tôi có thể thêm số liệu hoặc ràng buộc cụ thể theo yêu cầu của người dùng khi lựa chọn kiến trúc mô hình. Ví dụ, cho một ràng buộc "thời gian suy luận nhỏ hơn 10 FPS," chúng tôi sau đó xử lý yêu cầu người dùng dưới số liệu đánh giá và ràng buộc. Hưởng lợi từ hướng dẫn này và phản hồi của con người về các số liệu đánh giá và yêu cầu bổ sung này, LLM có thể tuân theo hướng dẫn tốt hơn. AutoML-GPT cung cấp các đặc tả nhiệm vụ này cho LLM như các hướng dẫn cấp cao để phân tích yêu cầu của người dùng tương ứng.

### 2.2 Xử lý Dữ liệu

Xử lý dữ liệu là một bước tích hợp trong học máy vì chất lượng dữ liệu và thông tin hữu ích có được trực tiếp ảnh hưởng đến khả năng học của mô hình chúng ta. Do đó, việc xử lý dữ liệu trước khi đưa vào mô hình là rất quan trọng. Ví dụ, trong thị giác máy tính, xử lý dữ liệu đề cập đến tập hợp các kỹ thuật và phương pháp được sử dụng để chuẩn bị dữ liệu hình ảnh thô cho phân tích hoặc thuật toán học máy. Điều này có thể bao gồm thay đổi kích thước hình ảnh, chuẩn hóa, tăng cường và lọc. Tương tự, trong các dự án Xử lý Ngôn ngữ Tự nhiên (NLP), xử lý dữ liệu đề cập đến việc chuyển đổi dữ liệu văn bản thô thành định dạng có cấu trúc và sạch mà các thuật toán học máy có thể dễ dàng hiểu và xử lý. Các kỹ thuật như tokenization, loại bỏ từ dừng, viết thường và loại bỏ ký tự đặc biệt và số thường được sử dụng. Dựa trên thẻ dữ liệu và mô tả dữ liệu được cung cấp, AutoML-GPT cung cấp các kỹ thuật xử lý cụ thể tùy thuộc vào yêu cầu của dự án và bản chất của dữ liệu.

### 2.3 Kiến trúc Mô hình

Sau khi xử lý danh sách các nhiệm vụ, AutoML-GPT cần ghép mỗi nhiệm vụ với mô hình tương ứng, về cơ bản là lựa chọn mô hình phù hợp cho mọi nhiệm vụ trong danh sách. Để đạt được điều này, trước tiên chúng tôi thu thập thẻ mô hình và mô tả các mô hình từ đầu vào người dùng. Tiếp theo, chúng tôi gán động các mô hình cho nhiệm vụ bằng cách sử dụng cơ chế gán nhiệm vụ-mô hình trong ngữ cảnh. Phương pháp này cho phép truy cập mô hình tăng dần và cung cấp sự cởi mở và linh hoạt lớn hơn bằng cách kết hợp các mô tả mô hình cung cấp và hiểu biết tốt hơn về yêu cầu người dùng.

Kiến trúc mô hình đề cập đến giải thích chi tiết về thiết kế, cấu trúc và thành phần của mô hình học máy. Những mô tả này thường bao gồm các yếu tố sau: lớp đầu vào và đầu ra, lớp ẩn, hàm kích hoạt, hàm mất mát và các thành phần đặc thù mô hình (như cơ chế attention, lớp tích chập hoặc lớp tuần hoàn).

### 2.4 Điều chỉnh Siêu tham số với Nhật ký Đào tạo Dự đoán

Để tìm tập siêu tham số tối ưu mang lại hiệu suất tốt nhất cho một mô hình nhất định trên một tập dữ liệu cụ thể, điều chỉnh siêu tham số là một bước quan trọng trong học máy. Siêu tham số là các cài đặt cấu hình không được học trong quá trình đào tạo mà được định nghĩa trước và kiểm soát các khía cạnh khác nhau của hành vi học của mô hình. Ví dụ về các siêu tham số phổ biến bao gồm tốc độ học, kích thước batch, số lớp ẩn và số neuron trên mỗi lớp.

Để điều chỉnh siêu tham số mà không cần đào tạo trên máy thực, chúng tôi dự đoán hiệu suất bằng cách tạo nhật ký đào tạo cho một cài đặt siêu tham số nhất định cho thẻ dữ liệu và thẻ mô hình được cung cấp. AutoML-GPT sẽ tự động tiến hành đào tạo và trả về nhật ký đào tạo. Nhật ký đào tạo hiệu suất mô hình trên tập dữ liệu ghi lại các số liệu và thông tin khác nhau được thu thập trong quá trình đào tạo. Nó giúp hiểu tiến trình của mô hình, xác định các vấn đề tiềm ẩn và đánh giá hiệu quả của kiến trúc, siêu tham số và kỹ thuật tối ưu hóa đã chọn. Một nhật ký đào tạo điển hình bao gồm số epoch với số liệu đào tạo và xác thực. Bằng cách kiểm tra nhật ký đào tạo, chúng ta có thể hình thành hiểu biết cơ bản về hiệu suất mô hình theo phản hồi của người dùng.

**Tập dữ liệu Chưa thấy** Điều chỉnh siêu tham số cho các tập dữ liệu riêng tư chưa thấy có thể thậm chí còn thách thức hơn. Được cung cấp metadata của một tập dữ liệu chưa thấy, AutoML-GPT có thể khuyến nghị cấu hình siêu tham số có khả năng hiệu quả cho tập dữ liệu đó. Chúng tôi dựa vào thẻ dữ liệu để tận dụng các mô tả văn bản cần thiết và xác định mối tương quan giữa tập dữ liệu chưa thấy và các tập hiện có. Dựa trên mối tương quan, chúng tôi chuyển giao cài đặt siêu tham số từ các tập dữ liệu hiện có sang tập dữ liệu chưa thấy mới.

Để tính toán mối tương quan, chúng tôi sử dụng một bộ mã hóa văn bản để mã hóa thẻ dữ liệu. Cụ thể, trong thẻ dữ liệu, nó chứa thông tin như loại lớp, độ phân giải, kích thước hình ảnh và metadata liên quan khác. Chúng tôi lấy quy mô tập dữ liệu, mô tả nhiệm vụ, không gian nhãn và loại dữ liệu đầu vào/đầu ra như đầu vào cho bộ mã hóa văn bản (ví dụ: CLIP [Radford et al., 2021]) và mô tả mối tương quan giữa tập dữ liệu chưa thấy này và các tập dữ liệu hiện có bằng cách sử dụng điểm tương đồng của biểu diễn tiềm ẩn được mã hóa.

## 3 Thí nghiệm

Chúng tôi đánh giá hiệu suất của AutoML-GPT và triển khai nó bằng ChatGPT (phiên bản "GPT-4" của OpenAI)¹. Các nghiên cứu trường hợp khác nhau được thực hiện để thể hiện hiệu quả của phương pháp chúng tôi từ nhiều góc độ.

### 3.1 Tập dữ liệu Chưa thấy

Trong Hình 4, chúng tôi trình bày kết quả đào tạo trên tập dữ liệu chưa thấy sử dụng AutoML-GPT. Để xác minh hiệu suất trong các trường hợp thực tế, chúng tôi xây dựng một tập hiệu suất và siêu tham số trên các tập dữ liệu đã được đào tạo, và một số tập dữ liệu chưa được đào tạo. Chúng tôi sẽ dự đoán cấu hình siêu tham số cho các tập dữ liệu chưa được đào tạo này. Chúng tôi tạo môi trường kiểm tra dựa trên cài đặt phân loại được mô tả trong Vinyals et al. [2016]. Chúng tôi cũng theo MiniImageNet [Vinyals et al., 2016] để lấy mẫu phụ và chia tập dữ liệu đào tạo [Deng et al., 2009] thành các phần 80% và 20%. Từ dữ liệu 80%, chúng tôi xây dựng thẻ dữ liệu và thẻ mô hình tương ứng (chứa siêu tham số tốt nhất của mô hình). Chúng tôi chọn ngẫu nhiên mười lăm lớp để tạo các tập dữ liệu con khác nhau (ví dụ: tập dữ liệu A, B, v.v.), tìm kiếm lưới siêu tham số, tinh chỉnh mô hình ViT cơ sở [Dosovitskiy et al., 2020] và ghi nhật ký hiệu suất tốt nhất trên các tập dữ liệu con này. Sau đó chúng tôi tạo tập dữ liệu mới có tên "New" với mười lớp hình ảnh từ 20% dữ liệu còn lại.

[Hình 4: Tổng quan về AutoML-GPT cho tập dữ liệu chưa thấy: khối trên cùng thể hiện thẻ dữ liệu và thông tin mô hình. Trước tiên chúng tôi ghi nhật ký thông tin đào tạo cho một số tập dữ liệu. Thẻ dữ liệu cho các tập dữ liệu này được xử lý thông qua bộ mã hóa văn bản để có được điểm tương đồng, sau đó được kết hợp với tham số mô hình của các mô hình được đào tạo tương ứng để tạo thành đoạn prompt AutoML-GPT. Khối dưới cùng trình bày nhật ký đào tạo dự đoán dựa trên cài đặt siêu tham số được khuyến nghị cho tập dữ liệu chưa thấy.]

Để chứng minh khả năng của phương pháp chúng tôi trên các tập dữ liệu chưa thấy, chúng tôi sử dụng AutoML-GPT để khuyến nghị cấu hình đào tạo tốt nhất cho tập dữ liệu "New" dựa trên thẻ dữ liệu và thẻ mô hình được cung cấp. Trong thẻ dữ liệu của chúng tôi, chúng tôi ghi nhật ký không gian nhãn, tức là: mô tả văn bản cho mỗi lớp. Trong thực tế, chúng tôi kết hợp điểm tương đồng giữa hai thẻ dữ liệu bằng cách chuyển văn bản trong thẻ dữ liệu qua bộ mã hóa văn bản, ví dụ: bộ mã hóa văn bản CLIP, và tính toán độ tương đồng. Cụ thể, trong Hình 4, chúng tôi nêu rằng tập dữ liệu "New" có 60% tương đồng không gian nhãn với tập dữ liệu A và 40% tương đồng không gian nhãn với tập dữ liệu B. Sử dụng thông tin này và cài đặt siêu tham số trong thẻ dữ liệu cho tập dữ liệu A và B, AutoML-GPT có thể khuyến nghị cài đặt siêu tham số phù hợp để đào tạo trên tập dữ liệu "New". Trong thí nghiệm của chúng tôi, chúng tôi đạt được độ chính xác 98% cho dự đoán Top 1, so với độ chính xác Top 1 80% với siêu tham số được chọn ngẫu nhiên trung bình. Hơn nữa, chúng tôi cũng khởi tạo mô hình bằng cài đặt siêu tham số được đề xuất từ AutoML-GPT mà không cung cấp bất kỳ tập dữ liệu bổ sung nào. Với cấu hình này, chúng tôi đạt được độ chính xác Top 1 82%, tốt hơn so với siêu tham số được chọn ngẫu nhiên trung bình nhưng không tốt bằng cài đặt được khuyến nghị của chúng tôi. Nó cũng gợi ý rằng ChatGPT có thể đưa ra cài đặt siêu tham số tốt cho một nhiệm vụ cụ thể (ví dụ: phân loại hình ảnh). Điều này chứng minh hiệu quả của phương pháp đào tạo tự động được đề xuất trong việc giải quyết các vấn đề học máy, ngay cả với các tập dữ liệu chưa thấy hoặc mới. Những phát hiện này nêu bật tiềm năng của phương pháp đào tạo tự động của chúng tôi trong việc nâng cao học máy bằng cách cung cấp khuyến nghị siêu tham số chính xác.

### 3.2 Phát hiện Đối tượng

Hình 5 trình bày kết quả của chúng tôi trên tập dữ liệu COCO [Lin et al., 2014] cho phát hiện đối tượng. ① Khối trên cùng hiển thị thẻ dữ liệu cho tập dữ liệu COCO và thẻ mô hình cho ImageNet, dựa trên đầu vào người dùng. Khối giữa chứng minh Đoạn Prompt AutoML-GPT có được từ phân tách đầu vào. Thông tin từ thẻ dữ liệu và thẻ mô hình được tự động kết hợp vào định dạng prompt của chúng tôi. Chúng tôi báo cáo kết quả cho xử lý dữ liệu, thiết kế kiến trúc mô hình, điều chỉnh siêu tham số và tạo nhật ký đào tạo. ② Trong xử lý dữ liệu, AutoML-GPT tạo script để xử lý tập dữ liệu đầu vào. Chúng tôi cũng cung cấp ví dụ script Python trong Hình 5. Đối với thiết kế kiến trúc mô hình, quy trình của chúng tôi tạo ra thành phần mô hình cho đào tạo tiếp theo. Khi cả dữ liệu và mô hình đã được chuẩn bị, các cấu hình chi tiết được cung cấp trong giai đoạn điều chỉnh siêu tham số (ví dụ: tốc độ học: 10⁻⁴, weight decay: 10⁻⁴) và được điều chỉnh thêm với nhật ký đào tạo dự đoán. ③ Những kết quả này tiếp tục xác nhận rằng phương pháp của chúng tôi có thể đóng vai trò như một quy trình hiệu quả để linh hoạt thích ứng LLMs với các nhiệm vụ downstream. Phương pháp của chúng tôi, sử dụng thẻ dữ liệu và mô hình để có được đoạn prompt AutoML-GPT, cũng có thể được coi như một mô-đun bổ sung cho các công trình tập trung vào việc tăng cường các thành phần prompt LLM.

[Hình 5: Tổng quan về AutoML-GPT cho phát hiện đối tượng: Khối trên cùng hiển thị thẻ dữ liệu và thẻ mô hình. Khối giữa thể hiện đoạn prompt AutoML-GPT, có được từ thẻ dữ liệu và thẻ mô hình. Khối dưới cùng phác thảo bốn bước: xử lý dữ liệu, kiến trúc mô hình, điều chỉnh siêu tham số và nhật ký đào tạo dự đoán. Chúng tôi sử dụng nhật ký đào tạo dự đoán để điều chỉnh siêu tham số trước khi phản hồi siêu tham số cho người dùng.]

### 3.3 Trả lời Câu hỏi

Chúng tôi trình bày kết quả thí nghiệm trên tập dữ liệu Natural Questions Open [Kwiatkowski et al., 2019] trong Hình 6. Chúng tôi sử dụng Dense Passage Retrieval (DPR) [Karpukhin et al., 2020]. ⑫ Đối với thẻ dữ liệu, người dùng nhập tên dữ liệu, loại dữ liệu đầu vào, không gian nhãn và số liệu đánh giá. ⑬ Đối với thẻ mô hình, nó bao gồm tên mô hình, cấu trúc mô hình, mô tả mô hình và siêu tham số kiến trúc. ⑭ Với đoạn prompt AutoML-GPT được tạo, AutoML-GPT thực hiện xử lý dữ liệu, tạo kiến trúc mô hình, điều chỉnh siêu tham số và tạo nhật ký đào tạo dự đoán. Như thấy trong "Điều chỉnh Siêu tham số," các siêu tham số được tạo bởi AutoML-GPT và những siêu tham số được cung cấp bởi DPR khớp chặt chẽ, ví dụ: tốc độ học là 10⁻⁵ và max epochs là 40. ⑮ Khi nhật ký đào tạo dự đoán có sẵn, chúng tôi thể hiện một kịch bản trong đó người dùng có thể yêu cầu AutoML-GPT về các số liệu đánh giá hoặc kiến trúc mô hình khác nhau dựa trên yêu cầu của họ, như được minh họa trong Hình 6 "Yêu cầu bổ sung: thời gian suy luận nhanh cho DPR retriever." Như thấy trong phản hồi trả về trong Hình 6, AutoML-GPT cũng cung cấp gợi ý như "mà không hy sinh quá nhiều hiệu suất." AutoML-GPT tiếp tục điều chỉnh siêu tham số dựa trên những yêu cầu và nhật ký dự đoán này. Phương pháp của chúng tôi chứng minh khả năng mạnh mẽ trong việc tự động tiến hành thí nghiệm và thực hiện điều chỉnh siêu tham số tương tác. Nó tiếp tục xác nhận rằng phương pháp của chúng tôi hoạt động tốt cho các tập dữ liệu khác nhau và có thể tổng quát hóa qua các loại đầu vào và lĩnh vực khác nhau.

[Hình 6: Tổng quan về AutoML-GPT cho trả lời câu hỏi: Khối trên cùng trình bày thẻ dữ liệu và thông tin mô hình, trong khi khối giữa nêu bật đoạn prompt AutoML-GPT, có được từ cả thẻ dữ liệu và thẻ mô hình. Khối dưới cùng chi tiết bốn bước: xử lý dữ liệu, kiến trúc mô hình, điều chỉnh siêu tham số và nhật ký đào tạo dự đoán.]

### 3.4 Phân loại

Chúng tôi cũng đánh giá AutoML-GPT trên tập dữ liệu UCI Adult [Dua and Graff, 2017] sử dụng XGBoost. Như trước đây, chúng tôi cung cấp thẻ dữ liệu và thẻ mô hình để tạo đoạn prompt đầu vào. Cùng quy trình đào tạo được áp dụng ở đây, như được hiển thị trong Hình 7. Chúng tôi cũng tuân thủ cài đặt siêu tham số được đề xuất bởi AutoML-GPT và đào tạo mô hình XGBoost. Việc đào tạo này dẫn đến mất mát xác thực cuối cùng là 0.277 với độ chính xác 85.92%. Mặc dù có các đầu vào và nhiệm vụ khác nhau, AutoML-GPT được đề xuất của chúng tôi liên tục mang lại hiệu suất mạnh mẽ trong phân loại. Điều này tiếp tục chứng minh rằng AutoML-GPT có thể được sử dụng cho một loạt rộng các vấn đề học máy qua nhiều nhiệm vụ khác nhau.

[Hình 7: Tổng quan về AutoML-GPT cho phân loại: Khối trên cùng hiển thị thẻ dữ liệu và thông tin mô hình, và khối giữa thể hiện đoạn prompt AutoML-GPT, có được từ cả thẻ dữ liệu và thẻ mô hình. Khối dưới cùng phác thảo bốn bước: xử lý dữ liệu, kiến trúc mô hình, điều chỉnh siêu tham số và nhật ký đào tạo dự đoán. Ngoài ra, chúng tôi bao gồm kết quả xác thực cuối cùng, theo khuyến nghị siêu tham số từ AutoML-GPT và đào tạo mô hình.]

## 4 Công trình Liên quan

**Mô hình Ngôn ngữ Lớn Tiên tiến** LLMs đã thể hiện tính mạnh mẽ và khả năng tổng quát hóa thông qua học zero-shot và few-shot bằng cách có kích thước tham số vượt quá một trăm tỷ. Các ví dụ đáng chú ý về LLMs bao gồm Megatron-turing NLG [Smith et al., 2022] với 530 tỷ tham số, Gopher [Rae et al., 2021] với 280 tỷ tham số, và PaLM [Chowdhery et al., 2022] với 540 tỷ tham số. Việc mở rộng LLM đã mở khóa những khả năng mới nổi chưa từng quan sát được dưới các mô hình nhỏ hơn [Wei et al., 2022a]. Những LLMs này đã chứng minh ưu thế của LLMs cho học zero-shot. Trong số các LLMs hiện có, ChatGPT có những đặc điểm độc đáo. Nó có khả năng tương tác với người dùng theo cách giống như cuộc trò chuyện, trong khi vẫn giữ được kiến thức tích lũy và khả năng tổng quát hóa có được từ đào tạo trước. Đi xa hơn một bước, chúng tôi khám phá khả năng học zero-shot của ChatGPT trên các nhiệm vụ khác nhau ngoài đối thoại trong công trình này.

**Chuỗi Suy nghĩ** Prompting chuỗi suy nghĩ (CoT) khuyến khích LLMs tạo ra các bước lý luận trung gian trước khi trả lời [Wei et al., 2022b]. Có hai hướng nghiên cứu tập trung vào prompting CoT hiện tại. Một hướng là khám phá CoT được thiết kế thủ công. Trong CoT được thiết kế thủ công, LLMs thích ứng với các tính năng được thiết kế thủ công và minh họa cho quá trình lý luận [Wei et al., 2022b]. Wang et al. [2022] đề xuất chiến lược giải mã mới, tự nhất quán, để thay thế giải mã tham lam ngây thơ được sử dụng trong prompting chuỗi suy nghĩ. Gần đây, Interactive-Chain-Prompting [Pilault et al., 2023] được giới thiệu để giải quyết sự mơ hồ cho việc tạo có điều kiện đa ngôn ngữ. Hướng khác là tiến hành nghiên cứu về cài đặt zero-shot, nơi STaR [Zelikman et al., 2022] được giới thiệu cho việc tự tạo và giúp mô hình tự cải thiện, và Automatic Reasoning and Tool-use (ART) [Paranjape et al., 2023] là một framework sử dụng LLMs đông lạnh để tự động tạo ra các bước lý luận trung gian như một chương trình.

**Hệ thống dựa trên GPT** GPT [Brown et al., 2020] đã cho thấy những cải thiện hiệu suất đầy hứa hẹn. Một hướng nghiên cứu gần đây đã tập trung vào việc tích hợp mô hình GPT vào các hệ thống AI. HuggingGPT [Shen et al., 2023] được xây dựng với thư viện HuggingFace transformers và sử dụng GPT như tác nhân tương tác. VisualGPT [Wu et al., 2023] kết hợp các Mô hình Nền tảng Thị giác khác nhau để cho phép người dùng tương tác với ChatGPT. OpenAGI [Ge et al., 2023], một nền tảng nghiên cứu AGI mã nguồn mở, được thiết kế để cung cấp các nhiệm vụ phức tạp, đa bước và đi kèm với các tập dữ liệu nhiệm vụ cụ thể. Tương tự, chúng tôi cũng tích hợp GPT vào quy trình AutoML của chúng tôi. Cũng có một hệ thống dựa trên GPT khác có thể kết hợp thông tin bổ sung từ các công cụ tìm kiếm, ví dụ: AutoGPT². AutoML-GPT tái xem xét tác động của ChatGPT từ góc độ đào tạo tự động. Chúng tôi tập trung vào việc xây dựng quy trình đào tạo và thiết lập hệ thống AutoML từ đầu đến cuối.

## 5 Kết luận

Công trình của chúng tôi chứng minh lợi ích của việc xây dựng các hệ thống AutoML dựa trên GPT. Phương pháp được đề xuất có thể tự động tiến hành các thí nghiệm học máy. Việc học tự động này cải thiện đáng kể hiệu quả đào tạo và nâng cao hiệu suất của mô hình. Chúng tôi chứng minh các trường hợp sử dụng qua thị giác máy tính, trả lời câu hỏi tự nhiên và các benchmark phân loại. Chúng tôi tiếp tục tiến hành một trường hợp sử dụng chi tiết với các tập dữ liệu chưa thấy và tương tác bổ sung giữa người dùng và AutoML-GPT. Tóm lại, AutoML-GPT được đề xuất là hiệu quả và tổng quát, với tiềm năng tạo ra giao diện ngôn ngữ tự nhiên để điều chỉnh các mô hình học máy cho nhiều nhiệm vụ khác nhau. Trong tương lai, chúng tôi sẽ 1) tự động tạo thẻ mô hình và dữ liệu cho các benchmark nổi tiếng và biến chúng thành một phần của hệ thống của chúng tôi, và 2) trích xuất các mạng con nhận biết nhiệm vụ từ các mô hình được đào tạo trước lớn với sự giúp đỡ của ChatGPT.

## Tài liệu Tham khảo

Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. 2020. Language models are few-shot learners. Advances in neural information processing systems, 33:1877–1901.

Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, et al. 2022. Palm: Scaling language modeling with pathways. arXiv preprint arXiv:2204.02311.

Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, et al. 2022. Scaling instruction-finetuned language models. arXiv preprint arXiv:2210.11416.

Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. 2009. Imagenet: A large-scale hierarchical image database. In 2009 IEEE conference on computer vision and pattern recognition, pages 248–255. Ieee.

Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, et al. 2020. An image is worth 16x16 words: Transformers for image recognition at scale. arXiv preprint arXiv:2010.11929.

Dheeru Dua and Casey Graff. 2017. UCI machine learning repository.

Yingqiang Ge, Wenyue Hua, Jianchao Ji, Juntao Tan, Shuyuan Xu, and Yongfeng Zhang. 2023. Openagi: When llm meets domain experts. arXiv preprint arXiv:2304.04370.

Timnit Gebru, Jamie Morgenstern, Briana Vecchione, Jennifer Wortman Vaughan, Hanna Wallach, Hal Daumé Iii, and Kate Crawford. 2021. Datasheets for datasets. Communications of the ACM, 64(12):86–92.

²https://github.com/Significant-Gravitas/Auto-GPT

Gautier Izacard and Edouard Grave. 2020. Leveraging passage retrieval with generative models for open domain question answering. arXiv preprint arXiv:2007.01282.

Vladimir Karpukhin, Barlas Oğuz, Sewon Min, Ledell Wu, Sergey Edunov, Danqi Chen, and Wen-tau Yih. 2020. Dense passage retrieval for open-domain question answering. Empirical Methods in Natural Language Processing (EMNLP).

Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur Parikh, Chris Alberti, Danielle Epstein, Illia Polosukhin, Matthew Kelcey, Jacob Devlin, Kenton Lee, Kristina N. Toutanova, Llion Jones, Ming-Wei Chang, Andrew Dai, Jakob Uszkoreit, Quoc Le, and Slav Petrov. 2019. Natural Questions: a benchmark for question answering research. TACL.

Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Dollár, and C Lawrence Zitnick. 2014. Microsoft coco: Common objects in context. In Computer Vision–ECCV 2014: 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part V 13, pages 740–755. Springer.

Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, and Baining Guo. 2021. Swin transformer: Hierarchical vision transformer using shifted windows. In Proceedings of the IEEE/CVF international conference on computer vision, pages 10012–10022.

Margaret Mitchell, Simone Wu, Andrew Zaldivar, Parker Barnes, Lucy Vasserman, Ben Hutchinson, Elena Spitzer, Inioluwa Deborah Raji, and Timnit Gebru. 2019. Model cards for model reporting. In Proceedings of the conference on fairness, accountability, and transparency, pages 220–229.

OpenAI. 2023. Gpt-4 technical report. arXiv.

Bhargavi Paranjape, Scott Lundberg, Sameer Singh, Hannaneh Hajishirzi, Luke Zettlemoyer, and Marco Tulio Ribeiro. 2023. Art: Automatic multi-step reasoning and tool-use for large language models. arXiv preprint arXiv:2303.09014.

Jonathan Pilault, Xavier Garcia, Arthur Bražinskas, and Orhan Firat. 2023. Interactive-chain-prompting: Ambiguity resolution for crosslingual conditional generation with interaction. arXiv preprint arXiv:2301.10309.

Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et al. 2021. Learning transferable visual models from natural language supervision. In International conference on machine learning, pages 8748–8763. PMLR.

Jack W Rae, Sebastian Borgeaud, Trevor Cai, Katie Millican, Jordan Hoffmann, Francis Song, John Aslanides, Sarah Henderson, Roman Ring, Susannah Young, et al. 2021. Scaling language models: Methods, analysis & insights from training gopher. arXiv preprint arXiv:2112.11446.

Ori Ram, Yoav Levine, Itay Dalmedigos, Dor Muhlgay, Amnon Shashua, Kevin Leyton-Brown, and Yoav Shoham. 2023. In-context retrieval-augmented language models. arXiv preprint arXiv:2302.00083.

Yongliang Shen, Kaitao Song, Xu Tan, Dongsheng Li, Weiming Lu, and Yueting Zhuang. 2023. Hugginggpt: Solving ai tasks with chatgpt and its friends in huggingface. arXiv preprint arXiv:2303.17580.

Shaden Smith, Mostofa Patwary, Brandon Norick, Patrick LeGresley, Samyam Rajbhandari, Jared Casper, Zhun Liu, Shrimai Prabhumoye, George Zerveas, Vijay Korthikanti, et al. 2022. Using deepspeed and megatron to train megatron-turing nlg 530b, a large-scale generative language model. arXiv preprint arXiv:2201.11990.

Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, et al. 2023. Llama: Open and efficient foundation language models. arXiv preprint arXiv:2302.13971.

Oriol Vinyals, Charles Blundell, Timothy Lillicrap, Daan Wierstra, et al. 2016. Matching networks for one shot learning. Advances in neural information processing systems, 29.

Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, and Denny Zhou. 2022. Self-consistency improves chain of thought reasoning in language models. arXiv preprint arXiv:2203.11171.

Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, et al. 2022a. Emergent abilities of large language models. arXiv preprint arXiv:2206.07682.

Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Ed Chi, Quoc Le, and Denny Zhou. 2022b. Chain of thought prompting elicits reasoning in large language models. arXiv preprint arXiv:2201.11903.

Chenfei Wu, Shengming Yin, Weizhen Qi, Xiaodong Wang, Zecheng Tang, and Nan Duan. 2023. Visual chatgpt: Talking, drawing and editing with visual foundation models. arXiv preprint arXiv:2303.04671.

Tete Xiao, Yingcheng Liu, Bolei Zhou, Yuning Jiang, and Jian Sun. 2018. Unified perceptual parsing for scene understanding. In Proceedings of the European conference on computer vision (ECCV), pages 418–434.

Sang Michael Xie, Aditi Raghunathan, Percy Liang, and Tengyu Ma. 2021. An explanation of in-context learning as implicit bayesian inference. arXiv preprint arXiv:2111.02080.

Eric Zelikman, Yuhuai Wu, Jesse Mu, and Noah Goodman. 2022. Star: Bootstrapping reasoning with reasoning. Advances in Neural Information Processing Systems, 35:15476–15488.

Shujian Zhang, Chengyue Gong, and Eunsol Choi. 2021. Knowing more about questions can help: Improving calibration in question answering. arXiv preprint arXiv:2106.01494.

Shujian Zhang, Chengyue Gong, and Xingchao Liu. 2022. Passage-mask: A learnable regularization strategy for retriever-reader models. arXiv preprint arXiv:2211.00915.

Mingkai Zheng, Xiu Su, Shan You, Fei Wang, Chen Qian, Chang Xu, and Samuel Albanie. 2023. Can gpt-4 perform neural architecture search? arXiv preprint arXiv:2304.10970.

¹https://platform.openai.com/

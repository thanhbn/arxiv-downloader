# FAIRAUTOML: ĐẨP NHẬN VIỆC GIẢM THIỂU KHÔNG CÔNG BẰNG TRONG AUTOML
Qingyun Wu1Chi Wang2

TÓM TẮT
Trong công trình này, chúng tôi đề xuất một hệ thống Học Máy Tự Động (AutoML) để tìm kiếm các mô hình không chỉ có độ chính xác dự đoán tốt mà còn công bằng. Chúng tôi đầu tiên khảo sát tính cần thiết và tác động của việc giảm thiểu không công bằng trong bối cảnh AutoML. Chúng tôi thiết lập khung FairAutoML. Khung này cung cấp một thiết kế mới dựa trên các trừu tượng thực dụng, làm cho việc kết hợp các định nghĩa công bằng hiện có, kỹ thuật giảm thiểu không công bằng và phương pháp tìm kiếm siêu tham số vào quá trình tìm kiếm và đánh giá mô hình trở nên thuận tiện. Theo khung này, chúng tôi phát triển một hệ thống AutoML công bằng dựa trên một hệ thống AutoML hiện có. Hệ thống được tăng cường bao gồm một chiến lược phân bổ tài nguyên để quyết định động khi nào và trên mô hình nào thực hiện giảm thiểu không công bằng theo độ chính xác dự đoán, công bằng và tiêu thụ tài nguyên một cách linh hoạt. Đánh giá thực nghiệm rộng rãi cho thấy hệ thống của chúng tôi có thể đạt được 'độ chính xác công bằng' tốt và hiệu quả tài nguyên cao.

1 GIỚI THIỆU
Các hệ thống học máy tự động (AutoML) hiệu quả đã được phát triển để tự động điều chỉnh cấu hình siêu tham số và tìm các mô hình ML với hiệu suất dự đoán tốt từ dữ liệu huấn luyện đã cho. Những hệ thống này ngày càng được sử dụng để quản lý các pipeline ML trong nhiều tình huống thực tế khác nhau (Aut, 2021). Tuy nhiên, trong nhiều ứng dụng thực tế nơi các quyết định được đưa ra có tác động trực tiếp đến hạnh phúc của con người, chỉ có hiệu suất dự đoán tốt là không đủ. Chúng ta cũng mong đợi các quyết định dựa trên ML phải có đạo đức, không đặt các nhóm hoặc cá nhân không được ưu đãi vào tình thế bất lợi có hệ thống. Thật không may, đã có ngày càng nhiều bằng chứng về các vấn đề không công bằng khác nhau liên quan đến các quyết định hoặc dự đoán do máy đưa ra trong nhiều ứng dụng như vậy (O'neil, 2016; Barocas & Selbst, 2016; Angwin et al., 2016). Xem xét việc gia tăng áp dụng các hệ thống AutoML, chúng tôi thấy rất quan trọng phải nghiên cứu cách cải thiện công bằng trong các hệ thống AutoML.

Nỗ lực nghiên cứu đáng kể đã được dành cho công bằng học máy trong những năm gần đây, bao gồm nghiên cứu về định nghĩa công bằng (Dwork et al., 2012; Hardt et al., 2016; Chouldechova, 2017; Lahoti et al., 2019) và giảm thiểu không công bằng (Kamiran & Calders, 2012; Kamishima et al., 2011; Friedler et al., 2014; Hardt et al., 2016; Calmon et al., 2017; Woodworth et al., 2017; Zafar et al., 2017; Agarwal et al., 2018; Zhang et al., 2021). Nhiều phương pháp giảm thiểu không công bằng hiện tại khá hiệu quả trong việc giảm thiểu tác hại liên quan đến không công bằng của các mô hình học máy. Tuy nhiên, chúng hiếm khi được khám phá trong các hệ thống AutoML. Xem xét tác động thực tế to lớn của AutoML, chúng tôi có động lực để khám phá liệu việc kết hợp các kỹ thuật giảm thiểu không công bằng vào các hệ thống AutoML có hữu ích để cải thiện công bằng tổng thể của hệ thống hay không, và nếu có, cách tốt nhất để kết hợp chúng là gì.

Để trả lời câu hỏi đầu tiên, chúng tôi tiến hành cả khảo sát tài liệu và nghiên cứu tình huống. Nghiên cứu của chúng tôi cho thấy rằng việc kết hợp giảm thiểu không công bằng vào AutoML là có lợi (và đôi khi là cần thiết). Hướng tới việc trả lời câu hỏi thứ hai, chúng tôi đề xuất một giải pháp mới và thực dụng để cho phép việc kết hợp giảm thiểu không công bằng vào AutoML. Cụ thể, chúng tôi đầu tiên khảo sát tính cần thiết của giảm thiểu không công bằng trong AutoML và tác động tiềm năng của nó đối với hệ thống AutoML về công bằng, hiệu suất dự đoán và chi phí tính toán. Sau đó chúng tôi cung cấp một công thức AutoML công bằng có xem xét đến giảm thiểu không công bằng. Đi kèm với công thức này, chúng tôi phát triển các trừu tượng cần thiết để đặc trưng tổng quát cho các quy trình đánh giá công bằng và giảm thiểu không công bằng trong bối cảnh AutoML. Chúng tôi cũng đề xuất một chiến lược ra quyết định tự thích ứng để đạt được AutoML công bằng một cách hiệu quả và hiệu suất. Chiến lược này giúp xác định khi nào thực hiện huấn luyện mô hình thông thường, và liệu có nên và khi nào thực hiện quy trình giảm thiểu không công bằng bổ sung trong mỗi thử nghiệm của quá trình AutoML.

Chúng tôi tóm tắt các đóng góp chính của công trình này như sau:
1. Chúng tôi cung cấp một công thức nghiêm ngặt cho bài toán AutoML công bằng có xem xét đến giảm thiểu không công bằng, và đề xuất một khung tổng quát để giải quyết bài toán AutoML công bằng. (tham khảo Phần 3). Các trừu tượng trong khung cho phép kết hợp thuận tiện và linh hoạt hầu hết các phương pháp đánh giá công bằng và kỹ thuật giảm thiểu không công bằng hiện tại vào AutoML.

2. Chúng tôi đề xuất một chiến lược thích ứng để quyết định khi nào và liệu có nên thực hiện giảm thiểu không công bằng là mới và có tầm quan trọng thực tế. (tham khảo Phần 4). Với chiến lược này, tài nguyên tính toán có thể được phân bổ hiệu quả giữa điều chỉnh siêu tham số và giảm thiểu không công bằng.

3. Chúng tôi phát triển một hệ thống AutoML công bằng hoạt động dựa trên một hệ thống AutoML hiện có. Hệ thống AutoML công bằng được đề xuất linh hoạt, mạnh mẽ và hiệu quả về mặt xây dựng các mô hình công bằng với hiệu suất dự đoán tốt. Đánh giá thực nghiệm rộng rãi bao gồm bốn bộ dữ liệu chuẩn công bằng học máy, hai định nghĩa công bằng khác nhau với hai ngưỡng công bằng khác nhau, ba phương pháp giảm thiểu không công bằng khác nhau, hai tác vụ điều chỉnh (tác vụ điều chỉnh trên một learner và nhiều learner), và hai phương pháp điều chỉnh, xác minh hiệu suất tốt mạnh mẽ của hệ thống chúng tôi trên tất cả các tình huống được đánh giá. (tham khảo Phần 5).

2 CÔNG TRÌNH LIÊN QUAN

Định nghĩa công bằng và giảm thiểu không công bằng. Có chủ yếu hai loại định nghĩa công bằng cho học máy: công bằng nhóm (Dwork et al., 2012; Simoiu et al., 2017; Hardt et al., 2016) và công bằng cá nhân (Dwork et al., 2012; Lahoti et al., 2019). Dưới khung công bằng nhóm, công bằng, nói chung, đòi hỏi một số khía cạnh của hành vi hệ thống học máy phải có thể so sánh hoặc thậm chí được cân bằng trên các nhóm khác nhau. Các thước đo công bằng nhóm thường được sử dụng bao gồm Bình Đẳng Nhân Khẩu Học (DP) (Dwork et al., 2012) và Tỷ Lệ Cơ Hội Bằng Nhau (EO) (Hardt et al., 2016). Công bằng cá nhân đảm bảo rằng các cá nhân 'tương tự' về mặt tác vụ học nhận được kết quả tương tự. Các phương pháp giảm thiểu không công bằng tìm cách giảm tác hại liên quan đến công bằng của một mô hình học máy về một thước đo công bằng cụ thể. Từ góc độ thủ tục, các phương pháp giảm thiểu không công bằng có thể được phân loại thô thành tiền xử lý (Kamiran & Calders, 2012; Calmon et al., 2017), trong quá trình (Kamishima et al., 2011; Woodworth et al., 2017; Zafar et al., 2017; Agarwal et al., 2018; Zhang et al., 2021), và hậu xử lý (Friedler et al., 2014; Hardt et al., 2016), tùy thuộc vào việc các phương pháp nên được áp dụng trước, trong hoặc sau quá trình huấn luyện mô hình. Các phương pháp tiền xử lý thường biến đổi dữ liệu huấn luyện để cố gắng loại bỏ những thiên vị không mong muốn. Các phương pháp trong quá trình cố gắng giảm tác hại liên quan đến công bằng bằng cách áp đặt các ràng buộc công bằng vào cơ chế học. Các phương pháp hậu xử lý trực tiếp biến đổi đầu ra mô hình để giảm thiên vị. Các bộ công cụ phần mềm đã được phát triển cho công bằng học máy. Những bộ công cụ đại diện bao gồm các thư viện Python mã nguồn mở AIF360 (Bellamy et al., 2018) và FairLearn (Bird et al., 2020). Cả hai thư viện đều cung cấp các triển khai cho các thước đo đo lường công bằng tiên tiến, các phương pháp giảm thiểu không công bằng, và các bộ sưu tập dữ liệu thường được sử dụng cho nghiên cứu công bằng học máy.

AutoML. Nhiều bộ công cụ và hệ thống AutoML đã được phát triển (Feurer et al., 2015; Olson et al., 2016; H2O.ai, 2019; Li et al., 2020; Wang et al., 2021b). Có rất ít công trình trong lĩnh vực AutoML xem xét đến công bằng, mặc dù có một số nỗ lực sơ bộ trong chế độ rộng của AutoML gần đây. (Schmucker et al., 2020) sử dụng một phương pháp HPO đa mục tiêu để tìm biên Pareto của các cấu hình có công bằng và độ chính xác tốt. FairHO (Cruz et al., 2021) cố gắng làm cho tối ưu hóa siêu tham số có nhận thức công bằng bằng cách bao gồm điểm công bằng như một mục tiêu bổ sung. Nó có thể được sử dụng để hoặc khám phá biên Pareto về công bằng và độ chính xác dự đoán hoặc tìm sự cân bằng tối ưu giữa độ chính xác và công bằng dựa trên trọng số do người dùng chỉ định. Cả hai phương pháp nói trên về cơ bản đều thêm công bằng như một mục tiêu bổ sung vào quá trình tối ưu hóa siêu tham số của họ. FairBO (Perrone et al., 2021) coi công bằng như một ràng buộc và đề xuất giảm không công bằng của kết quả học bằng cách thay đổi các cấu hình siêu tham số và giải quyết một bài toán tối ưu hóa Bayesian có ràng buộc. Trong công trình này, chúng tôi cũng coi công bằng như một ràng buộc trong AutoML. Giải pháp của chúng tôi tổng quát hơn FairBO.

3 CÔNG THỨC FAIRAUTOML

Trong phần này, chúng tôi đầu tiên giới thiệu các khái niệm và ký hiệu sẽ được sử dụng trong toàn bộ bài báo này, và các khái niệm cơ bản của AutoML. Sau đó chúng tôi khảo sát tính cần thiết và tác động của giảm thiểu không công bằng trong AutoML. Cuối cùng, chúng tôi đề xuất một công thức AutoML công bằng trong đó giảm thiểu không công bằng được kết hợp như một thành phần hữu cơ của quá trình AutoML.

• X và Y biểu thị các vector đặc trưng và giá trị mục tiêu trong không gian đặc trưng dữ liệu X và không gian nhãn Y tương ứng. D = (X;Y) biểu thị một bộ dữ liệu nói chung, và Dtrain = (Xtrain;Ytrain) và Dval = (Xval;Yval) biểu thị một bộ dữ liệu huấn luyện và validation cụ thể tương ứng.

• c biểu thị một cấu hình siêu tham số trong một không gian tìm kiếm siêu tham số cụ thể C, với c ∈ C. Khi chỉ có một learner ML được tham gia vào quá trình AutoML, c biểu thị cấu hình siêu tham số mô hình của learner liên quan đó, và khi nhiều learner được tham gia, c cũng bao gồm một chiều về việc lựa chọn learner.

• f biểu thị một mô hình học máy nói chung. fc;Dtrain là mô hình kết quả liên quan đến cấu hình siêu tham số c, được huấn luyện trên bộ dữ liệu Dtrain, và fc;Dtrain(Xval) là kết quả dự đoán của fc;Dtrain trên dữ liệu đầu vào Xval. Trong thảo luận sau, chúng tôi cũng thêm một chỉ số trên cho fc;Dtrain để biểu thị cách mô hình được huấn luyện. Cụ thể, chúng tôi sử dụng f(0)c;Dtrain để biểu thị biến thể của mô hình được huấn luyện (dựa trên c và Dtrain) mà không xem xét các ràng buộc công bằng, và sử dụng f(1)c;Dtrain để biểu thị biến thể được huấn luyện với giảm thiểu không công bằng.

• Loss : Y × Y → R là một hàm mất mát.

3.1 AutoML

Cho một bộ dữ liệu huấn luyện Dtrain, một bộ dữ liệu validation Dval, và một không gian tìm kiếm siêu tham số C, mục tiêu của AutoML¹ là tìm mô hình tốt nhất có mất mát validation thấp nhất:

min(c∈C) Loss(fc;Dtrain(Dval);Yval) (1)

Các giải pháp cho bài toán AutoML thường quyết định cấu hình siêu tham số nào để thử trong các thử nghiệm lặp lại và điều chỉnh các quyết định tương lai của họ hướng tới việc tìm các cấu hình tốt hơn. Để tạo điều kiện cho phân tích thêm, chúng tôi cung cấp một trừu tượng cho các giải pháp như vậy thông qua HPSearcher. Một HPSearcher về cơ bản chịu trách nhiệm đưa ra đề xuất cấu hình siêu tham số trong không gian tìm kiếm đã cho bất cứ khi nào được yêu cầu. Chúng tôi sử dụng HPSearcher:suggest để biểu thị quy trình đưa ra đề xuất cấu hình siêu tham số, và HPSearcher:update để biểu thị quy trình cập nhật thông tin cần thiết. Trừu tượng này tương thích với hầu hết tất cả các phương pháp tìm kiếm siêu tham số (Bergstra et al., 2011; Bergstra & Bengio, 2012; Snoek et al., 2012; Li et al., 2020; Wu et al., 2021; Wang et al., 2021a) cho AutoML.

Dưới bối cảnh AutoML này, có vẻ đơn giản rằng để tìm một mô hình công bằng với mất mát validation tốt, người ta có thể đơn giản thêm một ràng buộc công bằng trên đỉnh của Eq. (1) và thực hiện tối ưu hóa siêu tham số có ràng buộc, như đã được thực hiện trong một công trình gần đây (Perrone et al., 2021). Tuy nhiên, một lưu ý trong cách tiếp cận này là, đối với một tác vụ đặc biệt, người ta có thể không tìm được một mô hình duy nhất vừa thỏa mãn ràng buộc công bằng vừa có mất mát tốt bằng cách đơn giản điều chỉnh các siêu tham số c ∈ C trong AutoML. Điều này về cơ bản là vì có thể tồn tại nhiều nguồn gây ra không công bằng (Dudik et al., 2020), nhiều trong số đó không thể được giảm nhẹ bằng cách đơn giản thay đổi các siêu tham số mô hình.

3.2 Giảm thiểu không công bằng trong AutoML: tính cần thiết và tác động

Những hạn chế đã nói ở trên của việc điều chỉnh siêu tham số chung trong AutoML về mặt cải thiện công bằng thúc đẩy chúng tôi xem xét việc đưa các phương pháp giảm thiểu không công bằng thuật toán chuyên dụng, ví dụ, các phương pháp tiền xử lý, trong quá trình và hậu xử lý đã đề cập trong Phần 2 vào AutoML.

Tính cần thiết của giảm thiểu không công bằng trong AutoML. Để xác minh tính cần thiết của giảm thiểu không công bằng trong AutoML, chúng tôi tiến hành hai thí nghiệm sau trên bộ dữ liệu Bank (chi tiết về bộ dữ liệu này được trì hoãn đến Phần 5). Trong cả hai thí nghiệm, chúng tôi sử dụng giải pháp AutoML từ một thư viện mã nguồn mở có tên FLAML (Wang et al., 2021b).

• Trong thí nghiệm đầu tiên, chúng tôi thực hiện một quá trình AutoML thông thường trong 4 giờ. Theo ký hiệu trước đây của chúng tôi, chúng tôi có một tập hợp các mô hình ML trong thí nghiệm này được ký hiệu bởi H = {f(0)ci;Dtrain}i∈[1,2,...], trong đó ci là cấu hình được thử ở lần lặp thứ i và lần lặp lớn nhất được xác định bởi ngân sách thời gian 4 giờ.

• Trong thí nghiệm thứ hai, trong cùng ngân sách thời gian, tức là 4 giờ, cho mỗi cấu hình siêu tham số ci được đề xuất bởi quá trình AutoML gốc ở lần lặp i, ngoài việc huấn luyện một mô hình ML thông thường f(0)ci;Dtrain, chúng tôi cũng huấn luyện một mô hình thứ hai với giảm thiểu không công bằng, tức là f(1)ci;Dtrain. Chúng tôi sử dụng một phương pháp trong quá trình tiên tiến có tên Exponentiated Gradient (EG) (Agarwal et al., 2018) như phương pháp giảm thiểu. Trong thí nghiệm này, chúng tôi có tập hợp các mô hình sau H̃ = {f(0)ci;Dtrain, f(1)ci;Dtrain}i∈[1,2,...]. Lưu ý rằng vì bước giảm thiểu không công bằng bổ sung, tổng số thử nghiệm trong thí nghiệm này có thể nhỏ hơn so với thí nghiệm đầu tiên.

Chúng tôi thực hiện hai thí nghiệm trên hai tác vụ điều chỉnh: một điều chỉnh cả lựa chọn learner và siêu tham số mô hình của từng learner, và một điều chỉnh siêu tham số mô hình của một learner XGBoost² duy nhất. Chúng tôi vẽ kết quả từ hai tác vụ trong Hình 1(a) và (b), tương ứng. Trong hình con đầu tiên của Hình 1(a) và (b) có tiêu đề "Tác động lên mất mát và công bằng", chúng tôi vẽ 'điểm không công bằng', tức là Sự Khác Biệt của Tính Bình Đẳng Thống Kê (DSP) và mất mát của các mô hình được đánh giá trong cả hai thí nghiệm. Từ các biểu đồ phân tán trong Hình 1, chúng tôi có các quan sát sau: (1) Chúng tôi đầu tiên quan sát thấy sự giảm rõ ràng tổng thể của điểm không công bằng sau khi áp dụng giảm thiểu (bằng cách so sánh các điểm 'Trước giảm thiểu' và 'Sau giảm thiểu') trong cả hai tác vụ điều chỉnh. Điều này cho thấy hiệu quả của giảm thiểu không công bằng trong việc giảm không công bằng của từng mô hình học máy đơn lẻ cho các loại learner khác nhau. (2) Bằng cách so sánh các điểm 'Trước giảm thiểu' và 'Sau giảm thiểu' cùng với các điểm 'Không giảm thiểu', chúng ta có thể thấy tính cần thiết của việc thực hiện giảm thiểu không công bằng trong AutoML: Mặc dù bằng cách đơn giản thực hiện lựa chọn learner và điều chỉnh siêu tham số mô hình, người ta có thể tìm các mô hình với các mức độ công bằng khác nhau (như được hiển thị bởi các dấu thập màu xám trong biểu đồ phân tán), mất mát của các mô hình không nhất thiết phải tốt. Ví dụ, khi 0.01 được sử dụng như ngưỡng trong ràng buộc không công bằng, người ta chỉ có được các mô hình với hiệu suất dự đoán rất tệ trong tác vụ điều chỉnh trong Hình 1(a),

² Lưu ý rằng thiết lập learner đơn này phổ biến trong các tình huống thực tế nơi do các ràng buộc về cơ sở hạ tầng hoặc triển khai, tổ chức hoặc công ty chỉ có thể sử dụng một loại mô hình nhất định.

và người ta thậm chí không thể tìm được một mô hình công bằng duy nhất thỏa mãn ràng buộc khi learner bị hạn chế là XGBoost. Với giảm thiểu không công bằng, người ta có thể dễ dàng tạo ra các mô hình công bằng với mất mát khá tốt. Những kết quả này xác nhận tính cần thiết và hiệu quả của việc bao gồm giảm thiểu không công bằng trong AutoML.

Chúng tôi giờ chuyển sang phân tích cách người ta nên kết hợp nó vào AutoML một cách hiệu quả và hiệu suất. Để trả lời câu hỏi này, chúng tôi thấy cần thiết phải đầu tiên kiểm tra tác động của các phương pháp giảm thiểu không công bằng về mặt chi phí tính toán và hiệu suất dự đoán, đây là những yếu tố quan trọng ảnh hưởng trực tiếp đến hiệu suất cuối cùng của AutoML.

Tác động của giảm thiểu không công bằng đối với ML và AutoML. Một nghiên cứu gần đây (Islam et al., 2022) cung cấp một khảo sát toàn diện về tác động của giảm thiểu không công bằng trong học máy thông qua đánh giá thực nghiệm trên một loạt rộng các phương pháp giảm thiểu không công bằng trong tác vụ phân loại công bằng. Tác động có thể được hiểu từ ba khía cạnh sau. (1) Công bằng: Hầu hết các phương pháp giảm thiểu không công bằng tiên tiến có thể giảm thiểu không công bằng một cách hiệu quả. Nhưng không có phương pháp giảm thiểu nào được đảm bảo làm cho mọi mô hình công bằng cho mọi bộ dữ liệu. (2) Hiệu suất dự đoán: Trong tất cả các phương pháp giảm thiểu không công bằng, việc giảm thiểu không công bằng đi kèm với sự suy giảm hiệu suất dự đoán, và sự đánh đổi là phức tạp. (3) Chi phí tính toán: Các phương pháp giảm thiểu không công bằng, đặc biệt là các cách tiếp cận tiền xử lý và trong quá trình thường tạo ra chi phí tính toán cao. Chúng tôi cũng quan sát vấn đề nghiêm trọng này về chi phí tính toán trong nghiên cứu tình huống của chúng tôi theo biểu đồ chi phí trong Hình 1.

Tác động phức tạp này làm cho việc kết hợp giảm thiểu không công bằng vào AutoML cực kỳ không tầm thường: Một mặt, chúng ta muốn thực hiện giảm thiểu không công bằng để cải thiện công bằng của các mô hình ML kết quả. Mặt khác, việc thực hiện giảm thiểu không công bằng mang lại chi phí tính toán và làm suy giảm hiệu suất dự đoán của các mô hình. Cần phải có một sự cân bằng tinh tế.

3.3 AutoML công bằng với giảm thiểu không công bằng

Trừu tượng. Chúng tôi đầu tiên phát triển hai trừu tượng liên quan đến công bằng. Những trừu tượng này hữu ích trong việc tạo điều kiện cho việc công thức hóa và phân tích bài toán AutoML công bằng.

Đánh giá công bằng thông qua Fair: Chúng tôi trừu tượng hóa đánh giá công bằng của một mô hình học máy f, cho một bộ dữ liệu validation D, như một quy trình tính toán chỉ số công bằng dựa trên kết quả dự đoán của mô hình f trên bộ dữ liệu D theo một định nghĩa công bằng định lượng cụ thể. Chúng tôi sử dụng Fair(f,D) để biểu thị quy trình này nói chung. Cả công bằng nhóm và công bằng cá nhân, là hai loại định nghĩa công bằng thống trị, đều phù hợp với trừu tượng này. Trừu tượng này cũng có thể xử lý trường hợp mục tiêu công bằng là thỏa mãn nhiều ràng buộc công bằng. Lưu ý rằng trong bối cảnh của một định nghĩa công bằng cụ thể cụ thể, thông tin bổ sung ngoài dự đoán mô hình và bộ dữ liệu có thể cần thiết.

Ví dụ 1 (Công bằng nhóm). Dưới bối cảnh công bằng nhóm, một mô hình được coi là 'công bằng' nếu đầu ra của phép đo chênh lệch về thuộc tính nhạy cảm không vượt quá một ngưỡng cụ thể. Chúng tôi ký hiệu bằng A biến thuộc tính nhạy cảm, G(·,A) một hàm chênh lệch (ví dụ, chênh lệch thống kê) được tham số hóa bởi thuộc tính nhạy cảm A, và τ một hằng số ngưỡng công bằng. Cho (A,G,τ), một triển khai của trừu tượng có thể là Fair(f,D) = 1{G(X,Y,f̂(D),A) ≤ τ}, trong đó 1{·} là một hàm chỉ thị.

Giảm thiểu không công bằng thông qua Mitigate: Chúng tôi trừu tượng hóa giảm thiểu không công bằng của một thuật toán học máy cho một bộ dữ liệu huấn luyện D như một quy trình can thiệp vào quá trình xây dựng mô hình (bao gồm biến đổi dữ liệu, huấn luyện mô hình và quy tắc suy luận) theo cách sao cho đầu ra của mô hình cuối cùng được đẩy về phía một mục tiêu công bằng cụ thể (được chỉ định thông qua hàm Fair theo trừu tượng của chúng tôi). Tất cả việc giảm thiểu không công bằng tiền xử lý, trong quá trình và hậu xử lý được giới thiệu trước đây đều phù hợp với trừu tượng này. Theo ký hiệu được giới thiệu trước đây, f(1)c,D được thu được thông qua quy trình giảm thiểu này, tức là f(1)c,D ← Mitigate(f,c,D,Fair).

Công thức bài toán AutoML công bằng. Cho các bộ dữ liệu Dtrain và Dval, một hàm mất mát Loss, một hàm công bằng Fair và một phương pháp giảm thiểu không công bằng cụ thể theo trừu tượng Mitigate, chúng tôi công thức hóa bài toán AutoML công bằng như việc tìm một mô hình học máy công bằng tối thiểu hóa mất mát bằng cách tìm kiếm trên một tập hợp các siêu tham số và quyết định có nên giảm thiểu không công bằng hay không, như được biểu diễn toán học dưới đây,

min(c∈C,m∈{0,1}) Loss(f(m)c,Dtrain(Xval),Yval) (2)
s.t. Fair(f(m)c,Dtrain,Dval)

Trong phần còn lại của bài báo, chúng tôi sử dụng Loss(m)c và Fair(m)c như cách viết tắt cho Loss(f(m)c,Dtrain(Xval),Yval) và Fair(f(m)c,Dtrain,Dval) tương ứng mà không gây nhầm lẫn. Dưới công thức này, chúng ta có thể coi AutoML công bằng như một bài toán AutoML tối ưu hóa cho mất mát công bằng, tức là mất mát khi ràng buộc công bằng được thỏa mãn. Khái niệm mất mát công bằng này, được ký hiệu là Lfair, sẽ được sử dụng trong toàn bộ bài báo này để đánh giá hiệu quả của các giải pháp AutoML công bằng.

Công thức được đề xuất có nhiều tính chất mong muốn: Trừu tượng giảm thiểu không công bằng tách rời độ phức tạp của AutoML thông thường và giảm thiểu không công bằng. Một mặt, điều này làm cho việc tận dụng các nỗ lực nghiên cứu và phát triển hiện có về giảm thiểu không công bằng trở nên dễ dàng. Mặt khác, cách định khung này làm cho việc đạt được AutoML công bằng bằng cách tăng cường một hệ thống AutoML hiện có trở nên khá dễ dàng.

Mặc dù có các tính chất mong muốn của công thức được đề xuất, việc giải quyết bài toán vẫn thử thách do các lý do sau: (1) Giải quyết một bài toán AutoML bản thân nó đã rất tốn kém. Nó thường liên quan đến một số lượng lớn các thử nghiệm đắt đỏ. (2) Chi phí tính toán lớn làm phức tạp thêm thử thách tính toán này bằng cách làm cho một số thử nghiệm với giảm thiểu không công bằng đắt đỏ gấp 10x đến 100x.

4 KHUNG VÀ HỆ THỐNG FAIRAUTOML

Chúng tôi đầu tiên đề xuất một khung AutoML công bằng tổng quát để giải quyết bài toán AutoML công bằng được đặc trưng trong Eq. (1). Khung được đề xuất được trình bày trong Alg. 1, thành phần trung tâm của nó là một trừu tượng có tên FairSearcher. Trách nhiệm chính của FairSearcher là đề xuất một cấu hình siêu tham số hứa hẹn c ∈ C và quyết định có nên thực hiện giảm thiểu không công bằng hay không, được chỉ thị bởi m = 0 hoặc m = 1 ở mỗi thử nghiệm. Trách nhiệm này được thực hiện thông qua một hàm suggest (dòng 4 của Alg. 1). Sau đó hệ thống xây dựng một mô hình học máy f(m)c dựa trên c và m được đề xuất (dòng 5 của Alg. 1), và nhận mất mát validation và công bằng trên bộ dữ liệu validation (dòng 6 của Alg. 1). Lưu ý rằng bước huấn luyện và validation mô hình thường phát sinh chi phí không tầm thường, được ký hiệu bởi ρ(m)c. Khung sau đó ghi lại chi phí phát sinh ρ(m)c, cập nhật ngân sách còn lại và ghi lại quan sát thử nghiệm chi tiết, bao gồm cấu hình siêu tham số được đề xuất c, quyết định giảm thiểu m, và mất mát Loss(m)c, công bằng Fair(m)c và chi phí tính toán ρ(m)c tương ứng, trong H. Sau đó FairSearcher sẽ được cập nhật thông qua một hàm update sao cho quan sát mới có thể được sử dụng để giúp đưa ra các đề xuất trong tương lai.

4.1 FairSearcher

Hiểu biết. FairSearcher nên được thiết kế theo cách sao cho nó có thể đưa ra các đề xuất về cấu hình siêu tham số và giảm thiểu không công bằng hướng tới một mô hình công bằng với hiệu suất dự đoán tốt. Các phương pháp điều chỉnh siêu tham số chung (theo trừu tượng HPSearcher) có thể hiệu quả trong việc tìm các mô hình với hiệu suất dự đoán tốt. Và các phương pháp giảm thiểu không công bằng (theo trừu tượng Mitigate) có thể được sử dụng để giảm thêm không công bằng của các mô hình. Chúng tôi tin rằng việc lấy điều tốt nhất của cả hai thế giới là có lợi. Dựa trên hiểu biết này, chúng tôi đề xuất bao gồm HPSearcher và Mitigate như các mô-đun con của FairSearcher, trong đó HPSearcher chủ yếu chịu trách nhiệm đề xuất cấu hình siêu tham số c ∈ C, và FairSearcher chịu trách nhiệm giảm không công bằng của từng mô hình cá nhân. Chúng tôi tiếp tục phát triển một logic bổ sung để kiểm soát có nên và khi nào thực hiện giảm thiểu không công bằng thay vì tìm kiếm siêu tham số.

Chúng tôi trình bày hai chức năng chính của FairSearcher được đề xuất trong Alg. 2 và Alg. 3 tương ứng. Mỗi lần khi hàm FairSearcher:suggest được gọi, FairSearcher đầu tiên chọn cấu hình siêu tham số đã được đánh giá nhưng chưa được giảm thiểu có mất mát thấp nhất và không thỏa mãn ràng buộc công bằng, như cấu hình siêu tham số ứng viên để thực hiện giảm thiểu không công bằng (dòng 2 của Alg. 2). FairSearcher sau đó hoàn thiện quyết định sau khi kiểm tra một số điều kiện (dòng

3-6 của Alg. 2): nếu các điều kiện để thực hiện giảm thiểu không công bằng được thỏa mãn, FairSearcher đề xuất thực hiện giảm thiểu không công bằng, tức là m = 1, trên cấu hình siêu tham số ứng viên c' (dòng 4); ngược lại nó gọi HPSearcher để đề xuất siêu tham số mô hình và đặt quyết định giảm thiểu thành m = 0 (dòng 6).

Hai lựa chọn này có những hàm ý khác nhau cho hệ thống. Tìm kiếm siêu tham số thông thường cung cấp các mô hình ứng viên tốt để thực hiện giảm thiểu không công bằng và đôi khi thậm chí có thể trực tiếp tìm các mô hình công bằng tốt hơn. Nhưng công bằng của các mô hình thu được không được đảm bảo. Ví dụ, khi điều chỉnh XGBoost, bằng cách đơn giản điều chỉnh siêu tham số, người ta không thể tìm được một mô hình duy nhất với điểm không công bằng nhỏ hơn 0.01 theo biểu đồ phân tán trong Hình 1(b). Giảm thiểu không công bằng thêm vẫn cần thiết. Giảm thiểu không công bằng nói chung hữu ích trong việc tạo ra một mô hình công bằng. Tuy nhiên nó có thể làm suy giảm độ chính xác của mô hình kết quả, và mang lại chi phí tính toán tiềm năng cao. Chi phí tính toán cao có thể làm cho hệ thống không thể đánh giá đủ mô hình để điều hướng một mô hình với độ chính xác tốt khi ngân sách tính toán bị hạn chế. Các điều kiện trong dòng 3 của Alg. 2 được thiết kế để tạo ra sự cân bằng tinh tế giữa hai lựa chọn này: đó là một chiến lược thích ứng dựa trên các ước tính trực tuyến về tiện ích của tìm kiếm siêu tham số thông thường và giảm thiểu không công bằng.

Hiểu biết cho dòng 3 của FairSearcher:suggest trong Alg. 2: Xem xét sự suy giảm mất mát tiềm năng và chi phí tính toán cao của giảm thiểu không công bằng, thuật toán không nên thực hiện giảm thiểu không công bằng trên cấu hình c' trừ khi cả hai điều kiện sau được thỏa mãn: (1) Khi việc thực hiện giảm thiểu không công bằng 'hiệu quả' hơn việc thực hiện tìm kiếm siêu tham số thông thường thông qua HPSearcher về mặt cải thiện mất mát công bằng. Nói chung, có thể tồn tại các trường hợp mà tìm kiếm siêu tham số đã đủ tốt để tìm các mô hình công bằng với mất mát tốt, ví dụ, khi ràng buộc công bằng dễ thỏa mãn. Trong trường hợp này, giảm thiểu không công bằng không cần thiết trừ khi nó hiệu quả hơn trong việc cải thiện mất mát công bằng so với tìm kiếm siêu tham số. (2) Khi FairSearcher có thể dự đoán một cải thiện mất mát công bằng bằng cách thực hiện giảm thiểu trên cấu hình ứng viên c. Lý tưởng, chúng ta muốn chi tiêu tài nguyên trong giảm thiểu không công bằng trên các cấu hình có thể mang lại mất mát công bằng tốt hơn so với mất mát công bằng tốt nhất hiện tại. Mặc dù thông tin như vậy, tức là mất mát công bằng của một cấu hình sau giảm thiểu, không có sẵn a priori, mất mát gốc trước giảm thiểu thường là một chỉ số quan sát có ý nghĩa của nó.

Để thực hiện điều kiện đầu tiên, chúng tôi sử dụng ECF(m), tương tự như hàm CostImp được đề xuất trong (Wang et al., 2021a), để đặc trưng hiệu quả cải thiện mất mát công bằng của cả tìm kiếm siêu tham số thông thường và giảm thiểu không công bằng. Nó về cơ bản xấp xỉ Chi phí Ước tính cần thiết để tạo ra một mô hình với mất mát công bằng tốt hơn bằng cách thực hiện giảm thiểu không công bằng (ECF(1)), hoặc điều chỉnh siêu tham số với HPSearcher (tương ứng với ECF(0)). Giảm thiểu không công bằng không nên được thực hiện trừ khi ECF(1) < ECF(0). Một tính chất tốt của chiến lược này là nó có thể đạt được sự cân bằng tự thích ứng giữa giảm thiểu và tìm kiếm siêu tham số: Một khi một lựa chọn trở nên kém hiệu quả hơn, chúng ta chuyển sang lựa chọn khác. Chúng tôi bao gồm định nghĩa và giải thích chi tiết của ECF(m) trong Phụ lục A.

Để thực hiện điều kiện thứ hai, chúng tôi đề xuất đưa ra một phép chiếu về mất mát công bằng có thể đạt được và tài nguyên cần thiết cho giảm thiểu không công bằng trước khi thực sự thực hiện nó. Đối với một cấu hình cụ thể c, chúng tôi ký hiệu bằng L̂c mất mát dự đoán sau giảm thiểu. Cụ thể, chúng tôi ước tính L̂c bởi L̂c = Loss(0)c + Ht,B trong đó Ht,B là một ước tính trực tuyến về sự suy giảm mất mát của giảm thiểu không công bằng dựa trên các quan sát lịch sử trong Ht và ngân sách B. Thuật toán chỉ thực hiện giảm thiểu không công bằng khi L̂c < Lfair, trong đó Lfair là mất mát công bằng tốt nhất đạt được cho đến nay bởi hệ thống. Nói một cách trực quan, thuật toán cố gắng bỏ qua giảm thiểu không công bằng trên một số mô hình nếu việc thực hiện không có khả năng mang lại mất mát công bằng tốt hơn. Chúng tôi cung cấp công thức chi tiết của L̂c trong Phụ lục A.

Xem xét cả hai điều kiện, chúng tôi sử dụng {ECF(1) < ECF(0) & L̂c < Lfair} (dòng 3 của Alg. 2) như quy tắc quyết định để xác định có nên thực hiện giảm thiểu không công bằng. Một khi các quyết định về cấu hình siêu tham số nào để thử và có nên thực hiện giảm thiểu không công bằng được đưa ra (dòng 4 của Alg. 1 thông qua FairSearcher.suggest), thuật toán tiến hành xây dựng mô hình và thực hiện validation mô hình tương ứng (dòng 5 và dòng 6 của Alg. 1). Thuật toán cũng ghi lại chi phí tính toán phát sinh trong bước xây dựng và validation mô hình, mất mát dự đoán và công bằng của mô hình kết quả, và cập nhật chúng như một phần của các quan sát lịch sử trong H. Ngân sách còn lại cũng sẽ được cập nhật tương ứng. Cuối cùng, thuật toán cập nhật FairSearcher với các quan sát lịch sử H thông qua FairSearcher.update (dòng 8 của Alg. 1). FairSearcher.update được trình bày trong Alg. 3. Nó cập nhật các thống kê cần thiết cho FairSearcher để đưa ra các đề xuất về giảm thiểu không công bằng, và cũng gọi HPSearcher.update để cập nhật HPSearcher.

Algorithm 1 FairAutoML
1: Đầu vào: Dữ liệu huấn luyện và validation, không gian tìm kiếm C, và ngân sách tài nguyên B (tùy chọn).
2: Khởi tạo: H = []
3: while B > 0 do
4:    c, m ← FairSearcher:suggest(H)
5:    Xây dựng mô hình: huấn luyện mô hình f(m)c với (khi m = 1) hoặc không có (khi m = 0) giảm thiểu không công bằng
6:    Validation mô hình: Nhận Loss(m)c và Fair(m)c
7:    Kiểm tra chi phí phát sinh ρ(m)c, và cập nhật ngân sách B ← B - ρ(m)c, và các quan sát lịch sử H ← H ∪ (c, m, ρ(m)c, Loss(m)c, Fair(m)c)
8:    FairSearcher:update(H).
9: end while

Algorithm 2 FairSearcher.suggest(C)
1: H(0) = {c ∈ H | mc = 0}
2: c' ← arg minc∈H(0)&¬Fairc Lossc
3: if c' and ECF(1) < ECF(0) and L̂c < Lfair then
4:    m ← 1, c ← c'
5: else
6:    m ← 0, c ← HPSearcher:suggest(C)
7: end if
8: Return c, m

Algorithm 3 FairSearcher.update(H)
1: H(0) = {c ∈ H | mc = 0}; H(1) = H \ H(0)
2: Cập nhật ECF(0) dựa trên H(0), và cập nhật ECF(1) dựa trên H(1) theo định nghĩa của chúng
3: HPSearcher:update(H(0))

5 THỰC NGHIỆM

Bộ dữ liệu, baseline và thước đo đánh giá. Chúng tôi thực hiện đánh giá thực nghiệm trên bốn bộ dữ liệu chuẩn công bằng học máy, bao gồm Adult (Kohavi, 1996), Bank (Moro et al., 2014), Compas (Angwin et al., 2016) và một bộ dữ liệu Medical Expenditure Panel Survey (MEPS tóm tắt). Tất cả các bộ dữ liệu đều có sẵn công khai và chúng tôi cung cấp thêm chi tiết về chúng trong Phụ lục A. Chúng tôi bao gồm FLAML và FairBO, được xem xét trong Phần 2, như các baseline. Chúng tôi sử dụng 1 - validation accuracy như thước đo mất mát và fair loss như thước đo cuối cùng để đánh giá hiệu suất của các phương pháp được so sánh.

Thiết lập thí nghiệm AutoML công bằng. (1) Thiết lập công bằng. Chúng tôi bao gồm hai định nghĩa công bằng nhóm thường được sử dụng cho các tác vụ phân loại, bao gồm Demographic Parity (DP) và Equalized Odds (EO). Theo thiết lập đánh giá công bằng nhóm trong AIF360, chúng tôi sử dụng 'sex' như thuộc tính nhạy cảm trên Adult và Compas, 'age' trên Bank, và 'race' trên MEPS. Chúng tôi sử dụng hai ngưỡng chênh lệch thường được sử dụng τ = 0.05 và 0.01 để xác định liệu chênh lệch có đủ nhỏ để được coi là công bằng hay không. Hai ngưỡng này tương ứng với yêu cầu công bằng nhẹ và khắt khe tương ứng. Chúng tôi kiểm tra hai phương pháp không công bằng trong quá trình, bao gồm Exponentiated Gradient reduction, Grid Search reduction (Agarwal et al., 2018), và một phương pháp hậu xử lý (Hardt et al., 2016). Chúng tôi báo cáo kết quả cho Exponentiated Gradient trong bài báo chính và hai phương pháp khác trong Phụ lục B. Chúng tôi tận dụng các triển khai hiện có của các thước đo công bằng và phương pháp giảm thiểu không công bằng từ thư viện mã nguồn mở Fairlearn. (2) Thiết lập AutoML. Chúng tôi thực hiện đánh giá trên hai tác vụ điều chỉnh: (a) điều chỉnh siêu tham số trên XGBoost; (b) điều chỉnh siêu tham số (bao gồm lựa chọn learner và điều chỉnh siêu tham số mô hình) trên nhiều learner học máy. Tất cả các thành phần liên quan đến AutoML khác, như tiền xử lý dữ liệu, lựa chọn không gian tìm kiếm, và searcher siêu tham số, vẫn giữ nguyên như các tùy chọn mặc định của FLAML. Lưu ý rằng hai phương pháp điều chỉnh khác nhau (Wu et al., 2021; Wang et al., 2021a) được sử dụng trong các tác vụ điều chỉnh XGBoost và multi-learner, tương ứng, theo thiết lập mặc định của FLAML. Trong tất cả các kết quả được trình bày, chúng tôi đặt tên phương pháp của chúng tôi là FairFLAML (thay vì tên chung FairAutoML) để phản ánh thực tế rằng được xây dựng dựa trên hệ thống AutoML FLAML. Chúng tôi chạy tất cả các thí nghiệm đến 1 giờ wall-clock time với 1 CPU core mười lần với các seed ngẫu nhiên khác nhau nếu không được ghi chú khác. (3) Song song hóa. Chúng tôi kiểm tra hiệu suất của phương pháp chúng tôi dưới cả tài nguyên tính toán tuần tự và song song và bao gồm kết quả trong phần con thứ ba.

5.1 Hiệu quả

Chúng tôi đầu tiên muốn xác minh hiệu quả của phương pháp chúng tôi về mặt tạo ra các mô hình với fair loss tốt. Chúng tôi tóm tắt kết quả từ FairFLAML và các baseline khi điều chỉnh XGBoost trong Hình 2, và khi điều chỉnh nhiều learner trong Hình 3. Trong thí nghiệm sau, chúng tôi không bao gồm FairBO vì nó không hỗ trợ điều chỉnh nhiều learner đồng thời.

Trong các hình con của Hình 2, chúng tôi tóm tắt fair loss của các phương pháp khác nhau dưới các thiết lập công bằng khác nhau. Trong các hình con của Hình 3, chúng tôi hiển thị kết quả được tổng hợp trên tất cả các kết hợp của thiết lập công bằng và seed ngẫu nhiên trên các bộ dữ liệu khác nhau.

Chúng tôi đầu tiên quan sát thấy rằng, trên bộ dữ liệu Compas, thực sự có thể tạo ra các mô hình ML với fair loss tốt bằng cách đơn giản điều chỉnh siêu tham số thông thường trong một số trường hợp nhất định: cả FLAML và FairFLAML đều đạt được fair loss tốt nhất khi điều chỉnh nhiều learner như được hiển thị trong hình con thứ 3 của Hình 3. Tuy nhiên, trong tất cả các trường hợp khác, FairFLAML đạt được fair loss tốt hơn đáng kể so với cả FLAML và FairBO (khi điều chỉnh XGBoost), đặc biệt khi yêu cầu công bằng khắt khe. Ví dụ, khi điều chỉnh XGBoost trên bộ dữ liệu MEPS (Hình 4(d)), khi threshold τ = 0.05, hiệu suất của FLAML gần với FairFLAML. Khi threshold τ = 0.01, hiệu suất của FLAML có thể trở nên rất tệ và đôi khi nó thậm chí không thể tìm được một mô hình duy nhất thỏa mãn ràng buộc công bằng. Điều này một lần nữa xác minh lợi ích to lớn của việc đưa giảm thiểu không công bằng vào AutoML. Về các baseline, chúng tôi cũng quan sát thấy rằng hiệu suất của FairBO tệ hơn nhiều so với cả FairFLAML và FLAML. Có chủ yếu hai lý do cho hiệu suất tệ của nó: (1) Tương tự như trường hợp của FLAML, FairBO cũng đang điều chỉnh siêu tham số mô hình thông thường để tìm các mô hình công bằng với mất mát tốt. Sử dụng một phương pháp tối ưu hóa có ràng buộc công bằng không giải quyết được tính không hiệu quả của điều chỉnh siêu tham số trong việc xây dựng một mô hình với fair loss tốt; (2) Không giống như FLAML, phương pháp tối ưu hóa Bayesian được sử dụng trong FairBO không xem xét chi phí tính toán khác nhau của các mô hình với độ phức tạp khác nhau, và do đó có thể thử các mô hình không cần thiết tốn kém, làm cho phương pháp, nói chung, tốn thời gian hơn FLAML.

Tóm lại, các đánh giá toàn diện xác minh tính cần thiết của việc đưa giảm thiểu không công bằng vào AutoML và hiệu quả của phương pháp chúng tôi.

5.2 Nghiên cứu ablation và hiệu suất

Các cách thay thế để bao gồm giảm thiểu không công bằng. Chúng tôi tiếp tục so sánh FairFLAML với hai cách tiếp cận thay thế để kết hợp giảm thiểu không công bằng dưới khung autoML công bằng tổng quát được đề xuất trong Alg. 1: (1) Như đã đề cập trong Phần 3, một cách tiếp cận đơn giản để bao gồm giảm thiểu không công bằng là luôn thực thi nó trong quá trình huấn luyện mô hình sau mỗi cấu hình siêu tham số được đề xuất. Chúng tôi đặt tên cách tiếp cận này là MAlways. (2) Một thay thế khác là coi giảm thiểu không công bằng như một 'siêu tham số' phân loại bổ sung nhận giá trị nhị phân (1/0 để bật/tắt giảm thiểu không công bằng) và áp dụng tối ưu hóa siêu tham số có ràng buộc (FLAML, 2021). Chúng tôi đặt tên phương pháp này là MasHP. Cả hai cách tiếp cận này đều có thể được thực hiện thông qua trừu tượng FairSearcher và có thể được coi là một ablation của FairFLAML. Bằng cách so sánh với hai cách tiếp cận thay thế này, chúng tôi cho thấy tính cần thiết của chiến lược giảm thiểu tự thích ứng trong FairFLAML.

Chúng tôi cung cấp so sánh kết quả với MAlways, MasHP, và FLAML trong Hình 4 trên Bank và Compas. Do giới hạn trang, chúng tôi bao gồm kết quả trên hai bộ dữ liệu khác trong Hình 6 của phụ lục.

1. Trong cột thứ 1 của Hình 4, chúng tôi hiển thị fair loss của FairFLAML và hai phương án thay thế của nó dưới ngân sách tài nguyên nhỏ (300s). Kết quả chứng minh lợi thế đáng kể của FairFLAML so với hai phương án thay thế về fair loss.

2. Để hiểu rõ hơn cách tài nguyên được sử dụng trong các phương pháp khác nhau, trong cột thứ 2 của Hình 4, chúng tôi trực quan hóa phân tích tài nguyên cho các phương pháp khác nhau để đạt được fair loss tốt nhất dưới một thiết lập thí nghiệm cụ thể với một seed ngẫu nhiên. (1) Chúng tôi đầu tiên quan sát thấy rằng trong MAlways và MasHP, 'Wasted Mitigation' chiếm ưu thế trong tiêu thụ tài nguyên, đây là một nguồn quan trọng của sự không hiệu quả của chúng. (2) FLAML có thể hiệu quả trong việc tìm các mô hình công bằng với fair loss tốt nhất khi có thể thực hiện như vậy thông qua tìm kiếm siêu tham số thông thường như được hiển thị trên bộ dữ liệu Compas. Tuy nhiên, hiệu quả của phương pháp này phụ thuộc cao vào bộ dữ liệu. (3) FairFLAML có thể đạt được hiệu suất tốt hơn trung bình với ít tài nguyên hơn nhiều so với hai phương án thay thế theo các giá trị fair loss và chiều cao của các thanh tiêu thụ tài nguyên. FairFLAML có thể thực hiện lợi ích của cả tìm kiếm siêu tham số và giảm thiểu không công bằng.

3. Chúng tôi tin rằng việc khảo sát mất mát gốc mà không xem xét ràng buộc công bằng cũng có ý nghĩa, chúng tôi hiển thị kết quả trong cột thứ 3 của Hình 4. Chúng tôi quan sát thấy rằng FairFLAML bảo tồn hiệu suất tốt của FLAML về mất mát gốc trong khi có fair loss tốt nhất. Tính chất này đặc biệt mong muốn khi các practitioner đang trong chế độ khám phá về công bằng học máy, điều này khá phổ biến do sự phát triển chưa hoàn thiện của chủ đề này trong các tình huống thực tế. Nó làm giảm những do dự tiềm năng trong việc áp dụng giảm thiểu không công bằng vào AutoML do lo ngại về mất mát gốc bị suy giảm. Bằng cách biết mất mát gốc tốt nhất có thể đạt được mà không xem xét ràng buộc công bằng, các practitioner có thể có thêm tự tin trong việc ra quyết định. FairFLAML là hệ thống duy nhất có thể tìm cả mất mát gốc tốt nhất và fair loss tốt nhất.

5.3 Song song hóa

Phương pháp của chúng tôi dễ dàng song song hóa. Chúng tôi bao gồm kết quả của phương pháp chúng tôi chạy với một core đơn và nhiều core dưới các ngân sách wall-clock time khác nhau trên bộ dữ liệu MEPS, là bộ dữ liệu lớn nhất xem xét cả số lượng instance dữ liệu và chiều trong Hình 5. Kết quả cho thấy rằng bằng cách tăng tài nguyên tính toán song song, phương pháp của chúng tôi có thể đạt được kết quả thậm chí tốt hơn dưới cùng ngân sách wall-clock time, điều này hữu ích trong việc giảm thời gian quay vòng của tác vụ điều chỉnh trong các tác vụ nhạy cảm thời gian. Chúng tôi cũng quan sát thấy rằng khi ngân sách wall-clock time tăng, sự khác biệt giữa biến thể song song và biến thể tuần tự giảm.

5.4 Kết quả đánh giá bổ sung và mở rộng

Do giới hạn không gian, chúng tôi bao gồm kết quả đánh giá bổ sung trong Phụ lục B. (1) Một baseline bổ sung: Ngoài hai cách tiếp cận thay thế trong nghiên cứu ablation của chúng tôi, chúng tôi so sánh phương pháp của chúng tôi với một phương án thay thế thứ ba. Phương án thay thế này là một cách tiếp cận hậu hoc trong đó chúng tôi chọn các cấu hình với mất mát tốt nhất để thực hiện giảm thiểu không công bằng sau khi một quá trình AutoML thông thường được hoàn thành. Chúng tôi bao gồm mô tả chi tiết về ba phương án thay thế này, và so sánh với phương án thay thế hậu hoc dưới các thiết lập thí nghiệm khác nhau trong Hình 7 của Phụ lục B. (2) Kết quả trên các loại phương pháp giảm thiểu không công bằng khác nhau: Phương pháp của chúng tôi tương thích với hầu hết các phương pháp giảm thiểu không công bằng tiên tiến. Chúng tôi bao gồm các thí nghiệm bổ sung dưới các loại phương pháp giảm thiểu không công bằng khác nhau trong Hình 8 và Hình 9 của Phụ lục B. (3) Khả năng mở rộng: Khung và hệ thống AutoML công bằng được đề xuất của chúng tôi có khả năng mở rộng cao và tương thích với một loạt rộng các searcher siêu tham số, định nghĩa công bằng và phương pháp giảm thiểu không công bằng. Chúng tôi bao gồm hướng dẫn và ví dụ mã để xác minh khả năng tương thích rộng trong Phụ lục B.3.

6 TÓM TẮT VÀ CÔNG VIỆC TƯƠNG LAI

Trong công trình này, chúng tôi đầu tiên xác định rằng việc đưa giảm thiểu không công bằng vào quy trình làm việc AutoML là có lợi và đôi khi cần thiết để giúp cải thiện công bằng của hệ thống tổng thể. Chúng tôi đề xuất một khung tổng quát để kết hợp giảm thiểu không công bằng như một phần hữu cơ của quá trình AutoML và trình bày một hệ thống AutoML công bằng linh hoạt, mạnh mẽ và hiệu quả.

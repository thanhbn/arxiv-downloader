# 2310.09049.pdf
# Converted from PDF to TXT
# Source path: /home/admin88/arxiv-downloader/automl-nas/2310.09049.pdf
# File size: 406944 bytes

===============================================
PDF FILE CONTENT
===============================================


--- PAGE 1 ---
Springer Nature 2021 L ATEX template
SAI: Solving AI Tasks with Systematic
Artificial Intelligence in Communication
Network
Lei Yao1, Yong Zhang1,2*, Zilong Yan1and Jialu Tian1
1School of Electronic Engineering, Beijing University of Posts
and Telecommunications, Beijing, 100876, China.
2Beijing Key Laboratory of Work Safety Intelligent Monitoring,
Beijing University of Posts and Telecommunications, Beijing,
100876, China.
*Corresponding author(s). E-mail(s): yongzhang@bupt.edu.cn;
Abstract
In the rapid development of artificial intelligence, solving complex AI
tasks is a crucial technology in intelligent mobile networks. Despite the
good performance of specialized AI models in intelligent mobile net-
works, they are unable to handle complicated AI tasks. To address this
challenge, we propose Systematic Artificial Intelligence (SAI), which
is a framework designed to solve AI tasks by leveraging Large Lan-
guage Models (LLMs) and JSON-format intent-based input to connect
self-designed model library and database. Specifically, we first design
a multi-input component, which simultaneously integrates Large Lan-
guage Models (LLMs) and JSON-format intent-based inputs to fulfill
the diverse intent requirements of different users. In addition, we intro-
duce a model library module based on model cards which employ model
cards to pairwise match between different modules for model compo-
sition. Model cards contain the corresponding model’s name and the
required performance metrics. Then when receiving user network require-
ments, we execute each subtask for multiple selected model combinations
and provide output based on the execution results and LLM feedback.
By leveraging the language capabilities of LLMs and the abundant AI
models in the model library, SAI can complete numerous complex AI
tasks in the communication network, achieving impressive results in
network optimization, resource allocation, and other challenging tasks.
1arXiv:2310.09049v1  [cs.AI]  13 Oct 2023

--- PAGE 2 ---
Springer Nature 2021 L ATEX template
2 Article Title
Keywords: Large Language Models, AI Tasks, Systematic Artificial
Intelligence, Communication Network
1 Introduction
In recent years, with the development of 5G technology and computing power
network, significant developments have occurred in network computing power
and communication networks. This evolution has profoundly altered the way
networks are constructed and AI tasks are executed. Additionally, with the
significant breakthroughs achieved by LLM in human-like intelligence, han-
dling complex AI tasks based on intent has become feasible. Recently, the key
method of multi-agent collaboration based on LLM [1–3], such as HuggingGPT
[1], MetaGPT [2], and so on, is to use LLM as a controller to handle complex
task translation and planning. Then different agents are employed to execute
various modules to effectively complete all kinds of complex tasks. These meth-
ods have good Performance on complex tasks. However, their performance is
limited by the LLM model. Moreover, to our knowledge, there is no literature
that has applied this approach to complex AI tasks in mobile networks.
In mobile networks, Intent-Based Networking (IBN) [4] is a network
paradigm that automates network configuration based on intent analysis. With
the rise of IBN, Software-Defined Networking (SDN) [5] has achieved signif-
icant success. Current approaches based on intent networks [6–8] primarily
focus on intent classification and multi-intent conflicts. Intent classification
typically categorizes intents into two groups: end users and network opera-
tors. Then they provide different intent inputs for different users. Multi-intent
conflicts focus on how to execute different intents simultaneously during the
intent input process. However, These methods are generally applicable only in
simple environments and cannot handle complex AI tasks in mobile networks.
To address these challenges, we propose SAI framework. The framework
is designed to solve AI tasks by leveraging Large Language Models (LLMs),
JSON-format intent-based input and self-designed model library and database.
Specifically, we simultaneously integrates Large Language Models (LLMs) and
JSON-format intent-based inputs to fullfill the diverse intent requirements of
different users. In addition, we introduce a model library module based on
model cards which employ model cards to pairwise match between different
modules for model composition. Then when receiving user network require-
ments, we execute each subtask for multiple selected model combinations and
provide output based on the execution results and LLM feedback. The main
contributions of this paper are summarized as follows:
•To solve complex AI tasks in communication networks, We propose SAI,
which uses multi-input component to interact with self-designed model

--- PAGE 3 ---
Springer Nature 2021 L ATEX template
Article Title 3
libraries, databases. To the best of our knowledge, this is the first system-
atic artificial intelligence approach to solve complex tasks in communication
networks.
•We propose the multi-input component, which combines LLM input with
intention input based on JSON format to fulfill the requirements of different
people. In addition, we design model cards-based model library. Specifically,
model cards contain the corresponding model’s name and the network per-
formance metrics. Then we employ model cards to pairwise match between
different modules for model composition.
The remainder of this paper is organized as follows. A brief review of
related work is provided in Section 2. In Section 3, we detail the Framework
for Systematic Artificial Intelligence. Section 4 comes to concluding remarks.
2 Related Work
2.1 Autonomous Agents
Autonomous agents are commonly regarded as a key technology in the arti-
ficial general intelligence (AGI). Their autonomous governance and decision-
making have attracted significant interest. Previous approaches generally relied
on reinforcement learning to interact with the environment for achieving
autonomous governance. Volodymyr Mnih et al.[9] demonstrate that the deep
Q-network agent, receiving only the pixels and the game score as inputs. And
this network bridges the divide between high-dimensional sensory inputs and
actions, resulting in the first artificial agent that is capable of learning to excel
at a diverse array of challenging tasks. John Schulman et al. [10] propose a new
family of policy gradient methods for reinforcement learning, which alternate
between sampling data through interaction with the environment, and opti-
mizing an ”agent” objective function using stochastic gradient ascent. Tuomas
Haarnoja et al. [11] propose soft actor-critic, an off-policy actor-critic deep
RL algorithm based on the maximum entropy reinforcement learning frame-
work. In this framework, the actor aims to maximize expected reward while
also maximizing entropy. That is, to succeed at the task while acting as ran-
domly as possible. These reinforcement learning-based methods assume that
the agent is a simple policy function and are limited to specific environments.
These assumptions differ from human decision-making processes, and previous
approaches were unable to interact with humans or applied in open-domain
environments.
With the tremendous success of large language models (LLMs), it has
shown immense potential in attaining human-like intelligence. To address the
challenges of autonomous agents’ limited applicability in complex environ-
ments, Yongliang Shen et al. [1] propose HuggingGPT, a framework that
leverages LLMs (e.g.,ChatGPT) to connect various AI models in machine
learning communities (e.g.,Hugging Face) to solve AI tasks. And Sirui Hong

--- PAGE 4 ---
Springer Nature 2021 L ATEX template
4 Article Title
et al. [2] introduce MetaGPT, an innovative framework that incorporates effi-
cient human workflows as a meta programming approach into LLM-based
multi-agent collaboration. Shujian Zhang et al. [12] present the AutoML-GPT,
which employs GPT as the bridge to diverse AI models and dynamically trains
models with optimized hyperparameters. AutoML-GPT dynamically takes
user requests from the model and data cards and composes the correspond-
ing prompt paragraph. Multi-agent collaboration based on LLM can complete
numerous complex AI tasks. However, it cannot avoid the LLM of hallucination
problem [13]. This could be critical particularly in mobile network scenarios.
2.2 Intent-Based Network(IBN)
Intent-Based Networking (IBN) is a network paradigm to Automatically man-
age network configuration based on intent [4]. Recently, intent-based methods
with chatbot interfaces have emerged to simplify intent translation and incor-
porate user feedback. Tools like iNDIRA [6] utilize NLP to create semantic
RDF graphs, which are translated into network commands. EVIAN [7] extends
iNDIRA by using RASA for the chatbot interface and a hierarchy of RDFs for
intent translation. LUMI [14] employs Google Dialogflow and learning methods
to translate user intents into Nile intents, which are compiled into programs
for network configuration changes. [8] define a formal policy framework which
allows modeling policies at different levels of abstraction, including utility, goal,
and event-condition-action (ECA) policy types, and enables conflict detection
and resolution across abstraction layers. At a minimum, a policy should con-
tain a set of resources to which an action is to be applied, while considering a
set of associated constraints. These intent networks using natural language as
input satisfies end users’ network demands. However, the hallucination prob-
lem associated with LLM (Language Model Learning) could potentially be
critical in mobile network . In addition, the current approach based on intent
networks don’t consider selecting appropriate models for complex AI tasks.
3 Methodology
The SAI is a multi-agent collaborative system designed to complete complex
AI tasks in mobile networks. It is composed of multiple inputs, including LLM
inputs and JSON-formatted intent inputs, a self-designed model library and
database. Its workflow consists of five stages: multiple inputs component, task
translation and planning, model selection strategy, task execution, final output
and response feedback, as shown in Figure 1. Given a end user requirements or
a network operator specialized intent input, SAI automatically accomplish a
variety of complex AI tasks using different models. In the subsequent sections,
we will delve into the design of each stage.
We propose a new neural network structure named DLA-GCN. As shown
in Fig. 1, the model consists of the DLGCN, DATL , and NMPL components.
These approaches learn the spatial structural properties by combining the
DLGCN and NMPL and employs the DATL algorithm to learn and transfer

--- PAGE 5 ---
Springer Nature 2021 L ATEX template
Article Title 5
Fig. 1 : The Framework for Systematic Artificial Intelligence
similar features of dynamic graphs at adjacent time steps. Note that nodes in
this section dynamically evolve. In other words, the number of nodes in each
time step is different. Therefore, after feature extraction at t, we add 0 to
match the dimension in adjacent time steps tand t+ 1. This approach avoids
dimension mismatches and prevents the occurrence of the multi-zero matrix.
3.1 Multiple Inputs Component
The multi-input component primarily consists of two parts: LLM natural lan-
guage input and intent input based on the JSON format. End users tend to
interact with models using natural language to complete complex tasks and
thereby the use of LLM is necessary. However, due to the inherent ambiguities
in natural language and hallucination problem in LLM, we consider incorporat-
ing integrated feedback of LLM to enhance the accuracy of its translation and
planning, which will be discussed in Section 3.5. Meanwhile, for network opera-
tors, we provide unambiguous intent input based on the JSON format, directly
conveying the true intent to the network to ensure the correct execution of
network requirements.
3.2 Task Translation and Planning
To solve the complex AI tasks in mobile networks, it is necessary to coordi-
nate multiple sub-tasks. After processing the LLM input, we employ LLM to
analyze user intentions and decompose them into a set of structured tasks.
Furthermore, we also require the LLM to determe dependencies and execution
orders for these decomposed tasks to establish their connections by the re-
prompting method [15]. Currently, supported task relationships include single
tasks, chained tasks, and tree-structured tasks. To ensure effective and accurate
task planning by LLM, Our models employs a feedback-driven prompt-based
design, including specification-based instructions, demonstration-based pars-
ing, and parsing optimization with task output feedback. The feedback-driven
parsing optimization will be elaborated upon in Section 3.5.

--- PAGE 6 ---
Springer Nature 2021 L ATEX template
6 Article Title
In addition, to support the requirements of multi-turn conversations, we
incorporate chat logs into prompts through additional instructions. Specifi-
cally, to assist in task planning, chat history can be used as chat logs to track
resources mentioned by the user and incorporate them into subsequent task
planning. This design enables our model to better manage context and more
accurately solve AI tasks in multi-turn dialogues.
3.3 Model Selection Strategy
Due to the complexity of the AI tasks, after completing task planning, we need
to select model combinations from various candidate models that can satisfy
the intent requirements. To address this, we first introduce a model card-based
model library. Specifically, in the model library, we have different candidate
models and each model is assigned a corresponding model card. Under the
assumption of a stable network environment, each model card includes the
model’s name and various network performance metrics, such as latency and
resource utilization.
Then during the model selection process, we utilize a model matching
mechanism to generate multiple suitable model combinations based on intent
requirements. Specifically, we perform pairwise matchs among the model cards
from different model libraries based on the performance metrics specified in
the intent requirements to fulfill the overall demand. The method of model
cards not only reduces the complexity of model matching but also provide the
foundation for potential network dynamics in the future.
3.4 Task Execution
Once a specific model is assigned to a parsed task, the next step is to execute
the task, which involves model inference. At this stage, we propose a data
card-based database and a unified input-output section for model libraries to
facilitate model input. Specifically, the database contains all the required data
and their corresponding data cards. Data cards include data names and key
attributes, and the data can be used simply by employing the data card.
After selecting a specific model, the model directly uses the database
through the model library’s unified input-output component. The data is input
to the model in a standardized format, and the output is also standardized.
Additionally, to ensure the sequential execution of tasks, we consider using
re-prompting [15] to dynamically specify task dependencies and resources.
Furthermore, for sub-tasks within a tree-like structure, we execute these
tasks in parallel when they have no resource dependencies between them, thus
further enhancing inference efficiency.
3.5 Final Output and LLM Feedback
After completing all tasks, we need to generate the final result and LLM
feedback. For the final output, we simply show the results of the model
combinations that fulfill the requirements and their corresponding execution

--- PAGE 7 ---
Springer Nature 2021 L ATEX template
Article Title 7
performance . To optimize LLM translation and task planning in detail, we
integrates all information from the first three stages (task planning, model
selection, and task execution) into a formatting summary for this stage. This
summary includes the planned task list, the models selected for task execu-
tion, and the inference results from these models. These integrated outputs
are presented in a structured prompting format.
Then scores is assigned to the results of these three stages, particularly
focusing on explaining the reasons for any errors. Finally, this feedback is
provided to LLM to enhance its performance.
4 Conlusion
To solve complex AI tasks in communication network, We propose System-
atic Artificial Intelligence (SAI) by leveraging Large Language Models (LLMs)
and JSON-format intent-based input to connect self-designed model library
and database. Specifically, we first design a multi-input component, which
simultaneously integrates Large Language Models (LLMs) and JSON-format
intent-based inputs to fullfill the diverse intent requirements of different users.
In addition, we introduce a model library module based on model cards which
employ model cards to pairwise match between different modules for model
composition. Model cards contain the corresponding model’s name and the
required performance metrics. Then when receiving user network requirements,
we execute each subtask for multiple selected model combinations and pro-
vide output based on the execution results and LLM feedback. By leveraging
the language capabilities of LLMs and the abundant AI models in the model
library, SAI can complete numerous complex AI tasks in the communica-
tion network, achieving impressive results in network optimization, resource
allocation, and other challenging tasks.
References
[1] Shen, Y., Song, K., Tan, X., Li, D., Lu, W., Zhuang, Y.: Hugginggpt:
Solving ai tasks with chatgpt and its friends in huggingface. arXiv preprint
arXiv:2303.17580 (2023)
[2] Hong, S., Zheng, X., Chen, J., Cheng, Y., Zhang, C., Wang, Z., Yau,
S.K.S., Lin, Z., Zhou, L., Ran, C., et al.: Metagpt: Meta programming
for multi-agent collaborative framework. arXiv preprint arXiv:2308.00352
(2023)
[3] Tang, Z., Wang, R., Chen, W., Wang, K., Liu, Y., Chen, T., Lin,
L.: Towards causalgpt: A multi-agent approach for faithful knowledge
reasoning via promoting causal consistency in llms. arXiv preprint
arXiv:2308.11914 (2023)

--- PAGE 8 ---
Springer Nature 2021 L ATEX template
8 Article Title
[4] Leivadeas, A., Falkner, M.: A survey on intent based networking. IEEE
Communications Surveys & Tutorials (2022)
[5] Benzekki, K., El Fergougui, A., Elbelrhiti Elalaoui, A.: Software-defined
networking (sdn): a survey. Security and communication networks 9(18),
5803–5833 (2016)
[6] Kiran, M., Pouyoul, E., Mercian, A., Tierney, B., Guok, C., Monga,
I.: Enabling intent to configure scientific networks for high performance
demands. Future Generation Computer Systems 79, 205–214 (2018)
[7] Mahtout, H., Kiran, M., Mercian, A., Mohammed, B.: Using machine
learning for intent-based provisioning in high-speed science networks. In:
Proceedings of the 3rd International Workshop on Systems and Network
Telemetry and Analytics, pp. 27–30 (2020)
[8] Dzeparoska, K., Beigi-Mohammadi, N., Tizghadam, A., Leon-Garcia, A.:
Towards a self-driving management system for the automated realization
of intents. IEEE Access 9, 159882–159907 (2021)
[9] Mnih, V., Kavukcuoglu, K., Silver, D., Rusu, A.A., Veness, J., Belle-
mare, M.G., Graves, A., Riedmiller, M., Fidjeland, A.K., Ostrovski, G.,
et al. : Human-level control through deep reinforcement learning. nature
518(7540), 529–533 (2015)
[10] Schulman, J., Wolski, F., Dhariwal, P., Radford, A., Klimov, O.: Proximal
policy optimization algorithms. arXiv preprint arXiv:1707.06347 (2017)
[11] Haarnoja, T., Zhou, A., Abbeel, P., Levine, S.: Soft actor-critic: Off-policy
maximum entropy deep reinforcement learning with a stochastic actor.
In: International Conference on Machine Learning, pp. 1861–1870 (2018).
PMLR
[12] Zhang, S., Gong, C., Wu, L., Liu, X., Zhou, M.: Automl-gpt: Automatic
machine learning with gpt. arXiv preprint arXiv:2305.02499 (2023)
[13] Rawte, V., Sheth, A., Das, A.: A survey of hallucination in large
foundation models. arXiv preprint arXiv:2309.05922 (2023)
[14] Jacobs, A.S., Pfitscher, R.J., Ribeiro, R.H., Ferreira, R.A., Granville,
L.Z., Willinger, W., Rao, S.G.: Hey, lumi! using natural language for
{intent-based }network management. In: 2021 USENIX Annual Technical
Conference (USENIX ATC 21), pp. 625–639 (2021)
[15] Raman, S.S., Cohen, V., Rosen, E., Idrees, I., Paulius, D., Tellex, S.:
Planning with large language models via corrective re-prompting. arXiv
preprint arXiv:2211.09935 (2022)

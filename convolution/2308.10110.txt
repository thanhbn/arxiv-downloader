# 2308.10110.pdf
# Converted from PDF to TXT
# Source path: /home/admin88/arxiv-downloader/convolution/2308.10110.pdf
# File size: 1761835 bytes

===============================================
PDF FILE CONTENT
===============================================


--- PAGE 1 ---
Robust Mixture-of-Expert Training for Convolutional Neural Networks
Yihua Zhang1Ruisi Cai2Tianlong Chen2,3,4,5Guanhua Zhang6Huan Zhang7,8
Pin-Yu Chen9Shiyu Chang6Zhangyang Wang2Sijia Liu1,9
1Michigan State University,2University of Texas at Austin,
3The University of North Carolina at Chapel Hill,4MIT,5Harvard University,
6UC Santa Barbara,7Carnegie Mellon University,8UIUC,9IBM Research
Abstract
Sparsely-gated Mixture of Expert (MoE), an emerging
deep model architecture, has demonstrated a great promise
to enable high-accuracy and ultra-efficient model inference.
Despite the growing popularity of MoE, little work inves-
tigated its potential to advance convolutional neural net-
works (CNNs), especially in the plane of adversarial ro-
bustness. Since the lack of robustness has become one of
the main hurdles for CNNs, in this paper we ask: How
to adversarially robustify a CNN-based MoE model? Can
we robustly train it like an ordinary CNN model? Our pi-
lot study shows that the conventional adversarial training
(AT) mechanism (developed for vanilla CNNs) no longer
remains effective to robustify an MoE-CNN. To better un-
derstand this phenomenon, we dissect the robustness of
an MoE-CNN into two dimensions: Robustness of routers
(i.e., gating functions to select data-specific experts) and
robustness of experts (i.e., the router-guided pathways de-
fined by the subnetworks of the backbone CNN). Our anal-
yses show that routers and experts are hard to adapt to
each other in the vanilla AT. Thus, we propose a new
router-expert alternating Adv ersarial training framework
for MoE , termed ADVMOE. The effectiveness of our pro-
posal is justified across 4 commonly-used CNN model ar-
chitectures over 4 benchmark datasets. We find that ADV-
MOEachieves 1%âˆ¼4%adversarial robustness improve-
ment over the original dense CNN, and enjoys the efficiency
merit of sparsity-gated MoE, leading to more than 50% in-
ference cost reduction. Codes are available at https://
github.com/OPTML-Group/Robust-MoE-CNN .
1. Introduction
Despite the state-of-the-art performance achieved by the
outrageously large networks [1â€“5] in various deep learning
Correspondence to: Yihua Zhang <zhan1908@msu.edu >(DL) tasks, it still remains challenging to train and deploy
such models cheaply. A major bottleneck is the lack of
parameter efficiency [6]: A single data prediction only re-
quires activating a small portion of the parameters of the
full model. Towards efficient DL, sparse Mixture of Ex-
perts (MoE) [7â€“15] aims to divide and conquer the model
parameters based on their optimal responses to specific in-
puts so that inference costs can be reduced. A typical MoE
structure is comprised of a set of â€˜expertsâ€™ ( i.e., sub-models
extracted from the original backbone network) and â€˜routersâ€™
(i.e., additional small-scale gating networks to determine
expert selection schemes across layers). During inference,
sparse MoE only activates the most relevant experts and
forms the expert-guided pathway for a given input data.
By doing so, sparse MoE can boost the inference efficiency
(see â€˜GFLOPSâ€™ measurement in Fig. 1 ). Architecture-wise,
sparse MoE has been used for both CNNs [8, 16] and vision
transformers (ViTs) [7, 9â€“15, 17]. Yet, we will focus on the
former since sparse MoE for CNNs is under-explored com-
pared to non-sparse MoE for CNNs [18â€“20], and adversar-
ial robustness (another key performance metric of our work)
was extensively studied in the context of CNNs.
It is known that a main weakness of DL is the lack of
adversarial robustness [21â€“23]. For example, CNNs can be
easily fooled by adversarial attacks [21â€“23], in terms of tiny
input perturbations generated to direct to erroneous predic-
tions. Thus, adversarial training ( AT) of CNNs has become
a main research thrust [24â€“29]. However, when CNN meets
sparse MoE, it remains elusive if the improved inference ef-
ficiency brought by the sparse MoE comes at the cost of
more complex adversarial training recipes. Thus, we ask:
(Q)What will be the new insights into adversarial ro-
bustness of sparse MoE-integrated CNNs? And what
will be the suited AT mechanism?
To our best knowledge, problem (Q)remains open in the
literature. The most relevant work to ours is [30], which
investigated the adversarial robustness of MoE and lever-arXiv:2308.10110v1  [cs.CV]  19 Aug 2023

--- PAGE 2 ---
95.293.794.3DenseS-DenseMoE-CNNResNet18Standard TrainingRobust Training
Standard Accuracy
96.294.795.3DenseS-DenseMoE-CNNWRN-28-1093.692.292.9DenseS-DenseMoE-CNNVGG-1693.190.792.3DenseS-DenseMoE-CNNDenseNetPrior Art (AT)Ours (AdvMoE)50.148.044.951.8
ğŸ†51.849.146.255.7
ğŸ†46.243.741.449.8
ğŸ†44.538.131.439.7
ğŸ†
Models
ğŸ‘
ğŸ‘
ğŸ‘
ğŸ‘Robust AccuracyMetrics(a) Illustration of CNN types considered in this work. (b) Performance overview on CIFAR-10.
Figure 1. (a) Model types (Dense, MoE-CNN, Sparse-CNN, and S(mall)-Dense) considered in this paper; see details in â€˜Model setupâ€™ of
Sec. 3. (b) Performance overview using the standard training and the robust training on model architectures in (a), where standard accuracy
and robust accuracy are defined by testing accuracy on the benign and adversarial test datasets, respectively. Compared to standard training
(results in gray ), the conventional AT [25] is no longer effective for MoE-CNN (see results in light purple ). This is in contrast to AT
for other CNN models (Dense and S-Dense). Different from AT, our proposed A DVMOE can effectively equip MoE-CNN with improved
robustness, higher than Dense (see results in orange ), without losing its inference efficiency (see â€œGFLOPSâ€). We refer readers to Sec. 5.1
for more experiment details.
aged the ordinary AT recipe [24] to defend against adver-
sarial attacks. However, it only focused on the ViT archi-
tecture, making a vacancy for the research on robustifica-
tion for the sparse MoE-based CNN (termed MoE-CNN in
this work). Most importantly, we find that the vanilla AT
[24, 25] (widely used to robustify CNNs) is no longer ef-
fective for MoE-CNN. Thus, new solutions are in demand.
To address (Q), we need to (1) make careful sanity
checks for AT in MoE-CNN, (2) make an in-depth analysis
of its failure cases, and (3) advance new AT principles that
can effectively improve robustness without losing the gener-
alization and efficiency from sparse MoE. Specifically, our
contributions are unfolded below.
â€¢ We dissect the MoE robustness into two new dimen-
sions (different from CNNs): routersâ€™ robustness and
expertsâ€™ robustness. Such a robustness dissection
brings novel insights into the (in)effectiveness of AT.
â€¢ Taking inspiration from the above robustness dissec-
tion, we propose a new Adv ersarial training framework
for MoE , termed A DVMOE, which enforces routers
and experts to make a concerted effort to improve the
overall robustness of MoE-CNN.
â€¢ We conduct extensive experiments to demonstrate the
effectiveness of A DVMOE across 4CNN architectures
and 4 datasets. For example, A DVMOE outperforms
AT on the original dense CNN model (termed Dense)
by a substantial margin: 1%âˆ¼4%adversarial robust-
ness improvement and over 50% reduction of inference
overhead; see Fig. 1 for illustrations on different CNN
types and highlighted performance achieved.2. Related Work
Sparsely-activated Mixture of Experts (Sparse MoE).
As a special instance of compostional neural architectures
[31â€“33], MoE [4, 7â€“11, 16, 18â€“20, 34â€“41] aims at solving
ML tasks in a divide-and-conquer fashion, which creates a
series of sub-models (known as the experts ) and conducts
input-dependent predictions by combing the output of sub-
models. As an important branch of MoE, sparsely gated
MoE [4, 7â€“16, 39â€“43] only activates a subset of experts
based on a routing system. The major advantage brought
by sparse MoEs lies in its sub-linear increasing inference
costs (FLOPs) with respect to ( w.r.t. ) model scales (param-
eter counts) [7]. In the vision domain, a vast majority of
the existing works focus on the design of MoE for ViTs
[9â€“15, 40, 42, 43], leaving MoE for CNNs under-explored
[8, 16]. To our best knowledge, DeepMoE [8] is the most
recent work that systematically studies the integration of
MoE with CNNs, but restricts to the standard (non-robust)
training paradigm. Meanwhile, there also exist other works
related to MoE-CNN, but they either fall out of the â€œsparseâ€
MoE scope [18, 20] or bring no efficiency gains [19]. By
contrast, we focus on the efficiency-promoting MoE-CNN
setup throughout this work.
Adversarial robustness. CNNs are notoriously vulnera-
ble to imperceptible adversarial samples [22, 23, 44] and
thus training adversarially robust models [21, 24, 45] has
become a main research focus in many areas. Most of the
robust training methods [24â€“29] are extended from min-
max optimization-based adversarial training [46]. For in-
stance, the work [25] seeks an optimal balance between
2

--- PAGE 3 ---
robustness and standard generalization ability. Other work
[26, 28, 47â€“54] aims at trimming down the computational
costs of robust training while maintaining robustness. The
work [30] studies the robustness of MoE-based architec-
tures for the first time. Yet, its focus stays on MoE for
ViTs and the relationship between model capacity and ro-
bustness.
3. Problem Statement
In this section, we start by presenting the setup of MoE-
CNN in this work and then introduce the robust learning
paradigm. The lack of adversarial robustness of deep mod-
els inspires us to investigate whether the adversarial training
(AT) approach designed for vanilla CNNs keeps effective
for MoE-CNN. Through a motivating example, we show
that the conventional AT recipe is incapable of equipping
MoE-CNN with desired robustness. The resulting perfor-
mance is even worse than that of AT-produced S-Dense,
which has a much smaller model capacity than MoE-CNN.
Thus, the question of how to robustify MoE-CNN arises.
Model setup. We consider a CNN-backboned MoE that
consists of multiple MoE layers. Each MoE layer involves
a router and a vanilla convolutional layer from the backbone
CNN model. Within one MoE layer, we define Nexperts,
each of which picks a subset of the channels from the con-
volutional layer. Specifically, suppose the l-th layer con-
tainsClchannels, one expert will contain rÃ—Clchannels,
where we call the ratio râˆˆ[0,1]model scale and keep it the
same across different layers (see Fig. 1a ). It is worth noting
that as rincreases, the per-expert model capacity increases
(i.e., with more parameters) at the cost of the efficiency re-
duction. In a forward path, the router first makes an input-
specific expert selection. These selected layer-wise experts
then form an end-to-end pathway to process this input. We
use â€œ pathway â€ to describe one experts-guided forward path
(seeFig. 1a ). We summarize the model setup in Fig. A1 .
Further, we introduce different model types considered
in this work and shown in Fig. 1a . First, we term the
original dense CNN model â€˜ Dense â€™, which serves as the
model basis for other model types that derive from. Sec-
ond, we directly shrink the channel number of each layer in
Dense (based on the model scale parameter r) to obtain the
â€˜small dense â€™ model (termed â€˜ S-Dense â€™). Notably, S-Dense
has the size equivalent to a single pathway in MoE-CNN.
Third, we use the structured pruning method [50] to create
a sparse subnetwork from Dense, with the weight remain-
ing ratio same as the model scale parameter rin MoE-CNN,
which we call â€˜ Sparse-CNN â€™. In summary, S-Dense has the
smallest model capacity (comparable to a single pathway
of MoE-CNN), and should provide the performance lower-
bound for MoE-CNN. By contrast, Sparse-CNN has a larger
model capacity but is smaller than MoE-CNN as it encodesa data-agnostic pathway of Dense, while MoE-CNN yields
data-specific pathways at the same scale. Dense has the
largest model capacity but the least inference efficiency.
Adversarial robustness: From CNN to MoE-CNN. It
has been known that current machine learning models ( e.g.,
CNNs) are vulnerable to adversarial attacks [21â€“23]. To-
wards the robust design, a variety of AT (adversarial train-
ing) methods have been developed. The predominant ones
include the min-max optimization-based vanilla AT [24]
and its TRADES variant [25] that strikes a balance be-
tween generalization and adversarial robustness. Through-
out the paper, we adopt TRADES as the default conven-
tional AT recipe, which solves the following problem:
min
Î¸E(x,y)âˆˆD
â„“(Î¸;x, y) +1
Î»max
âˆ¥Î´âˆ¥âˆâ‰¤Ïµâ„“KL(fÎ¸(x), fÎ¸(x+Î´))
(AT)
where Î¸denotes model parameters to be robustified,
(x, y)âˆˆ D is a training sample, drawn from the training set
D, with input feature xand label y,â„“(Î¸,x;y)denotes the
cross-entropy loss using model Î¸at data point (x, y),Î´sig-
nifies the input perturbation variable subject to the â„“âˆ-norm
ball of radius Ïµ,fÎ¸(Â·)denotes the modelâ€™s predictions, â„“KL
is the KL divergence loss that characterizes the worst-case
prediction stability at the presence of Î´, andÎ» >0is a regu-
larization parameter to strike the tradeoff between empirical
risk minimization and the robustness of model predictions.
Although AT has been well studied for adversarial ro-
bustness of CNNs, there exists few attempts to robustify
MoE-CNN. This raises the problem of our interest:
(Problem statement) Can MoE-CNN be robustified
as effectively as an ordinary CNN using AT? If not,
how to robustly train MoE-CNN to achieve robust-
ness not worse than AT-oriented S-Dense, Sparse-
CNN, and Dense while preserving MoEâ€™s efficiency?
Warm-up study: AT for MoE-CNN is nottrivial. Our
goal to robustify MoE-CNN includes (1) achieving high
robustness, (2) maintaining high prediction accuracy, and
(3) making full use of MoE routing to keep the modelâ€™s
high efficiency and expressiveness. Nonetheless, the rout-
ing system in MoE brings extra robustification challenges,
which never exist in ordinary CNNs. Specifically, the input-
specific expert selection in MoE could make the attacker
easier to succeed, since input perturbations can either mis-
lead routers to select incorrect experts orfool the pathway-
designated predictor. Such a â€˜ two-way attack mode â€™ makes
AT for MoE-CNN highly non-trivial.
Fig. 2 empirically justifies that the direct application of
(AT) to MoE-CNN is problematic. In Fig. 2, we consider
ResNet-18 as the model backbone (Dense) and CIFAR-10
for image classification. We apply (AT) to train MoE-CNN
3

--- PAGE 4 ---
and S-Dense, and report the robust accuracy (RA), i.e., test-
time accuracy over adversarial examples generated by 50-
step PGD attacks [24], against different attack strengths Ïµ.
2 4 6 8
Attack Strength (/255)
203040506070 Robust Accuracy (%)
Model Type
S-Dense
MoE-CNN
Figure 2. Performance of MoE-
CNN and S-Dense robustly trained
using (AT) on CIFAR-10 with
ResNet-18 as the backbone.As we can see, although
MoE-CNN has a much
larger model capacity
than S-Dense, it leads
to a significant RA drop
when the conventional
AT approach is applied.
This implies that the de-
sign of AT for MoE-
CNN is far from trivial.
A new robust learning
protocol is thus needed
to improve the robust-
ness of MoE-CNN without losing its merits in efficiency
and generalization.
4. Methods
In this section, we start by peering into the failure case of
(AT) in MoE-CNN by understanding the roles of the routers
and pathways in (AT). We empirically show that these in-
dividual components are hard to adapt to each other and
cannot make a concerted effort in AT. Based on that, we
develop a new AT framework for MoE-CNN, A DVMOE,
which also takes inspiration from bi-level optimization.
Dissecting robustness of MoE-CNN: Routersâ€™ robust-
ness vs. pathwaysâ€™ robustness. The main puzzle in ro-
bustifying MoE-CNN comes from the coupling between
the robustness of routers (which are responsible for expert
selection across layers) and the robustness of the input-
specific MoE pathways (which are in charge of the final pre-
diction of an input). Given the failure case of AT for MoE-
CNN in Fig. 2, we need to understand the roles of routers
and pathways in AT, i.e., how the adversarial robustness of
MoE-CNN is gained in the presence of the â€˜two-way attack
modeâ€™. To this end, we begin by assessing the influence of
the routersâ€™ robustness on the overall robustness. This is
also inspired by the recent pruning literature [50] showing
that model robustness can be gained solely from networkâ€™s
sparse topology (regardless of model weights). We thus ask:
(Q1) Is improving routersâ€™ robustness sufficient to achieve
a robust MoE-CNN?
To tackle (Q1) , we first split the parameters of MoE-
CNN ( i.e.,Î¸) into two parts, the parameters of routers Ï•
and the parameters of the backbone network Ïˆ. This yields
Î¸= [Ï•âŠ¤,ÏˆâŠ¤]âŠ¤, where âŠ¤is the transpose operation. We
then call (AT) to robustly train routers ( Ï•) but fixthe back-
bone network ( Ïˆ) at its standard pre-trained weights. Wedenote this partially-robustified model by Â¯Î¸= [Â¯Ï•âŠ¤,ÏˆâŠ¤]âŠ¤,
where Â¯indicates the updated parameters. To answer (Q1) ,
we assess the robustness gain of Â¯Î¸vs. 3 baselines (M1-M3):
(M1) the standard MoE-CNN Î¸, (M2) AT-robustified S-
Dense, and ( M3) Sparse-CNN achieved by the robust sparse
mask learning method [50] over the original Dense model.
0.8 0.5 0.2
Model Scale01020304050 Robust Accuracy (%)
M1
M2M3
Figure 3. Robustness compari-
son of router-robusified MoE-
CNN ( i.e.Â¯Î¸) and baseline mod-
els (M1 â€“ M3) for different
model scales under CIFAR-10
given the backbone network
ResNet-18.Fig. 3 shows the robust
accuracy of the router-
robustified MoE-CNN
Â¯Î¸and its performance
comparison with other
baseline models. As we
can see, the robustified
router improves the
overall robustness ( e.g.,
37.64% forÂ¯Î¸with model
scale 0.5) compared to
the undefended MoE-
CNN ( M1:0%) and the
robustified mask ( M3:
20.04%). However, there
is still a huge robustness
gap compared to the
(AT)-robustified S-Dense ( M2:47.68%). Based on the
results above, we acquire the first insight into (Q1) :
Insight 1: Robustifying routers improves the overall ro-
bustness of MoE-CNN but is notas effective as AT-
resulted S-Dense.
Based on Insight 1, we further peer into the resilience of
expert selection decisions to adversarial examples. If ex-
pert selections in allMoE layers keep intact in the pres-
ence of an adversarial perturbation, we say that the rout-
ing system of MoE-CNN is robust against this adversarial
example. We then divide adversarial examples into four
categories according to whether they successfully attacked
routers and the router-oriented pathways: â¶unsuccessful
attack on both routers and MoE pathways, â·successful at-
tack on routers but not MoE pathways, â¸successful attack
on MoE pathways but not routers , andâ¹successful attack
onboth routers and MoE pathways. Here â¶+â¸charac-
terizes the robustness of routers, while â¶+â·represents
that of MoE. Thus, if â·orâ¸takes a large portion of gen-
erated adversarial examples, it implies that the routersâ€™ ro-
bustness does notdirectly impact the MoE pathway-based
predictorâ€™s robustness. Fig. 4 shows the above categories
â¶-â¹when attacking the router-robustified MoE-CNN ( i.e.,
Â¯Î¸). As we can see, routersâ€™ robustness indeed improves
prediction robustness (as shown by 31.74% unsuccessful
attacks against the MoE predictor in â¶). However, in the
total number of unsuccessful attacks against routers ( i.e.,
â¶+â¸= 76.27%), more than half of them successfully fool
4

--- PAGE 5 ---
Figure 4. Adversarial attack success analysis on dissected MoE-
CNN models Â¯Î¸= [Â¯Ï•âŠ¤,ÏˆâŠ¤](model scale r= 0.5), where only
Â¯Ï•is (AT)-robustified. The adversarial evaluation is based on 50-
step PGD attack [24] to fool Â¯Î¸, and other experiment setups align
with Fig. 3. The evaluation is carried out on the test set with a total
number of 10000 samples.
the MoE predictor ( i.e.,â¸>â¶). The above results provide
us an additional insight:
Insight 2: Improving routersâ€™ robustness is notsufficient
for the MoE predictor to gain satisfactory robustness al-
though the former makes a positive impact.
Both Insight 1 andInsight 2 point out that only improv-
ing routersâ€™ robustness is notadequate to obtain the desired
robustness for the overall MoE-CNN. Thus, we next ask:
(Q2) Given the router-robustified model Â¯Î¸, can we equip
Â¯Î¸with additional robustness by robustly training expert
weights ( Ïˆ)? And how does it further impact routers?
Figure 5. Adversarial attack
success analysis on routers
Â¯Ï• and MoE-CNN models
Â¯Â¯Î¸= [Â¯Ï•âŠ¤,Â¯ÏˆâŠ¤]. Other setups
remain the same as Fig. 4.To answer (Q2) , we
call (AT) to further ro-
bustly train the back-
bone network Ïˆon top
of the router-robustified
model Â¯Î¸. We de-
note the resulting model
byÂ¯Â¯Î¸= [ Â¯Ï•âŠ¤,Â¯ÏˆâŠ¤].
Fig. 5 shows the dis-
section of the robust-
ness ofÂ¯Â¯Î¸in the same
setup of Fig. 4. Obvi-
ously, the overall pre-
diction robustness ( â¶+â·) is further enhanced after updat-
ingÂ¯Î¸toÂ¯Â¯Î¸. Thus, the gains in the robustness of expertsâ€™
weights indeed further help improve the overall robustness.
However, this leads to a surprising drop in the routerâ€™s ro-
bustness ( â¶+â¸) when comparingÂ¯Â¯Î¸withÂ¯Î¸. This shows that
routersâ€™ robustness is notautomatically preserved if experts
are updated. We obtain the following insight into (Q2) :
Insight 3: Robustifying routers and MoE weights can yield
complementary benefits but the inadaptability of routersâ€™
robustness to MoEâ€™s robustness prevents AT from achiev-
ing significant robustness improvement.ADVMOE: Router-expert alternating AT through a bi-
level optimization viewpoint. As illuminated by insights
above, we provide a reason for the ineffectiveness of AT
in robustifying MoE-CNN. Insights 1-2 show that the ro-
bustness of routers (Ï•)and the robustness of MoE-based
predictor (Ïˆ)are intertwined and their interrelation is non-
trivial. As a result, the single-level (non-convex) robust op-
timization over the entire model parameters (Ï•,Ïˆ)expe-
riences difficulty in co-optimizing routers and MoE predic-
tion pathways to achieve the best complementary robustness
gains, as supported by Insight 3 . A key missing optimiza-
tion factor in AT for MoE-CNN is its incapability of model-
ing and optimizing the coupling between the robustness of
the routers and that of the MoE pathways. Without such an
optimization design, it is difficult for AT to robustify routers
and MoE pathways in a cooperative and adaptive mode.
Spurred by the above, we develop a new AT framework
through bi-level optimization ( BLO ). In general, BLO pro-
vides a hierarchical learning framework with two levels of
optimization tasks, where the objective and variables of an
upper-level problem depend on the optimizer of the lower
level. BLO then enables us to explicitly model the coupling
between AT for routers and AT for MoE network. Specifi-
cally, we modify the conventional (AT) to
minimize
Ïˆâ„“TRADES (Ïˆ,Ï•âˆ—(Ïˆ);D)
subject to Ï•âˆ—(Ïˆ) = arg minÏ•â„“TRADES (Ïˆ,Ï•;D),(1)
where the model parameters of MoE-CNN Î¸are split into
the lower-level optimization variables Ï•for routers and the
upper-level optimization variables Ïˆfor the MoE backbone
network, and â„“TRADES (Ïˆ,Ï•;D)denotes the TRADES-
type training loss defined in (AT) by replacing Î¸with
(Ï•,Ïˆ). Compared to (AT), our proposal (1) has the fol-
lowing differences. First , robustifying MoE network ( Ïˆ) is
now explicitly coupled with routersâ€™ optimization through
the lower-level solution Ï•âˆ—(Ïˆ).Second , our proposal ad-
dresses the robustness adaptation problem pointed out in
Insight 3 since the lower-level optimization of (1) enables
fast adaptation of Ï•to the current MoE network Ïˆlike
meta-learning [55]. Third , since â„“TRADES is involved at
both optimization levels of (1), the embedded attack gen-
eration problem ( i.e., maximization over Î´in AT) needs to
be solved at each level but corresponding to different victim
models, i.e.,(Ïˆ,Ï•)and(Ïˆ,Ï•âˆ—(Ïˆ)), respectively.
To solve problem (1), we adopt a standard alternating op-
timization (AO) method [56]. Compared with other kinds of
BLO algorithms [57], AO is the most computationally effi-
cient. Our extensive experiments in Sec. 5 will show that
AO is effective to boost the adversarial robustness of MoE-
CNN and achieve improvements over baseline methods and
models by a substantial margin. The key idea of AO is to
alternatively optimize the lower-level and the upper-level
problem, during which variables defined in another level
5

--- PAGE 6 ---
Algorithm 1 The A DVMOE algorithm
1:Initialize: backbone network Ïˆ, routers Ï•, batch size b, at-
tack generation step K.
2:forIteration t= 0,1, . . . , do
3: Pick different random data batches BÏˆandBÏ•for
backbone and router training
4: Lower-level Ï•-update (with fixed Ïˆ): Given Ïˆ, update Ï•
by minimizing â„“TRADES using K-step PGD attack [24]
generator and SGD (with BÏ•)
5: Upper-level Ïˆ-update (with fixed Ï•): Given Ï•, update Ïˆ
by minimizing â„“TRADES using K-step PGD attack gen-
-erator and SGD (with BÏˆ)
6:end for
are fixed. We term the resulting algorithmic framework as
Adversarially robust learning for MoE -CNN (A DVMOE);
see Algorithm 1 for a summary.
We highlight that A DVMOE will train robust routers and
robust MoE pathways to â€˜accommodateâ€™ each other. In
contrast to the conventional AT framework, A DVMOE de-
livers the coupled Ï•âˆ—(Ïˆ)andÏˆ, where both parts make
a concerted effort to improve the overall robustness. We
also remark that A DVMOE does not introduce additional
hyper-parameters, since in practice we found routers and
experts can share the same learning rate and schedules.
More implementation details are provided in Appendix B.
In the meantime, we remark that since our proposal is a
BLO with non-convex lower and upper-level objectives (1).
It is difficult to prove the convergence of A DVMOE. Exist-
ing theoretical analysis of BLO typically relies on strongly
convex assumptions of lower-level problems [58, 59]. Al-
though without a proper theoretical analysis framework, our
method converges well in practice (see Appendix C).
5. Experiments
In this section, we will demonstrate the effectiveness of
our proposed A DVMOE approach on diverse datasets and
models. We will also make an in-depth analysis of the router
utility and the expert selection distribution for A DVMOE-
trained MoE-CNN.
5.1. Experiment Setup
Model and dataset setups. To implement MoE-CNN
and other baselines, we conduct experiments on ResNet-
18 [60], Wide-ResNet-28-10 [61], VGG-16 [62], and
DenseNet [63]. Towards fair assessment, our performance
comparison between different model types is restricted
to using the same model scale parameter r(see Fig. 1
for an example). By doing so, an input example will
leverage the same amount of model parameters for
decision-making. For MoE-CNN, we consider N= 2
experts with r= 0.5by default, see Appendix B for
more details. Dataset-wise, we focus on the commonlyused ones to evaluate the adversarial robustness of image
classification [24, 25, 64], including CIFAR-10 [65],
CIFAR-100 [65], TinyImageNet [66], and
ImageNet [66].
Baselines. To make our performance comparison infor-
mative and comprehensive, we consider three kinds of base-
lines that are fairly comparable to (A DVMOE).â‘ AT (S-
Dense): we apply AT to S-Dense; â‘¡AT (Sparse): we ap-
ply the robustness-aware (structured) sparse mask learning
method [50] to obtain Sparse-CNN; â‘¢AT (MoE): we di-
rectly apply AT to MoE-CNN, which co-trains the routers
and backbone network. Note this method is also adopted in
the latest robust training algorithm [30] for ViT-based MoE
architectures. It is worth noting that the above baselines use
the same number of model parameters as the pathway of
MoE-CNN during model prediction. In addition, we cover
â‘£AT (Dense) (applying AT to Dense) to acquire a robust-
ness performance reference. Yet, we remark that it is not
quite fair to directly compare Dense with the aforemen-
tioned smaller counterparts, since the former uses a larger
model scale ( r= 1.0) at test-time inference.
Training and evaluation. We use TRADES [25] as the
default robust training objective for all baselines. We also
follow the literature [24, 25, 27, 64] to set the attack strength
byÏµ= 8/255 forCIFAR-10 andCIFAR-100 , and
Ïµ= 2/255forTinyImageNet andImageNet . To im-
plement A DVMOE (Algorithm 1), we mimic the TRADES
training pipeline but conduct the proposed BLO routine to
robustify routers and backbone parameters in an interactive
mode. We adopt 2-step PGD attack [24] at training time for
allthe methods, supported by the recent work [67] show-
ing its compelling performance in AT. We refer readers to
Appendix B for more training details. During evaluation,
we report standard accuracy ( SA) on the clean test dataset
and robust accuracy ( RA) against test-time 50-step PGD at-
tacks [24] with the attack strength same as the training val-
ues. We also report GFLOPs (FLOPS Ã—109) as an indica-
tor of the test-time inference efficiency.
5.2. Experiment Results
Overall performance. Tab. 1 presents the overall perfor-
mance of our proposed A DVMOE algorithm vs. baselines.
We make several key observations below.
First , ADVMOE yields a significant robustness enhance-
ment over all the baselines in every data-model setup.
Specifically, A DVMOE consistently yields an improvement
of around 1%âˆ¼5%on the robustness measured by RA
against PGD attacks. Notably, A DVMOE can also outper-
formâ€¢AT (Dense) in most cases, around 1%âˆ¼4%ro-
bustness improvement (see highlighted results in green ).
This is remarkable since Dense ( r= 1.0) is twice larger
6

--- PAGE 7 ---
Table 1. Performance overview of A DVMOE (our proposal) vs.baselines on various datasets and model backbone architectures. The
model scale is fixed at r= 0.5for Dense-CNN, Sparse-CNN and Moe-CNN (denoted with the symbol â—¦, since they are fairly comparable
to each other) compared to Dense ( r= 1.0, denoted with the symbol â€¢). For train- and test-time attack generations, we adopt an attack
strength of Ïµ= 8/255forCIFAR-10 andCIFAR-100 , andÏµ= 2/255forTinyImageNet andImageNet . We evaluate RA (robust
test accuracy) against 50-step PGD attack [24], SA (standard test accuracy), and GFLOPS (FLOPS Ã—109) per test-time example (test-time
inference efficiency) for each model. In each (dataset, backbone) setup, â‘ we highlight the best SA and RA over all baselines per model
scale in bold , andâ‘¡we mark the performance better than AT (Dense) in green . Results in the format of aÂ±bprovide the mean value a
and its standard deviation bover3independent trials.
Method Backbone RA(%) SA(%) GFLOPS (#) Method Backbone RA(%) SA(%) GFLOPS (#)
CIFAR-10
â€¢AT (Dense)
ResNet-1850.13Â±0.13 82.99Â±0.11 0.54 â€¢AT (Dense)
WRN-28-1051.75Â±0.12 83.54Â±0.15 5.25
â—¦AT (S-Dense) 48.12Â±0.09 80.18Â±0.11 0.14 (74% â†“)â—¦AT (S-Dense) 50.66Â±0.13 82.24Â±0.10 1.31 (75% â†“)
â—¦AT (Sparse) 47.93Â±0.17 80.45Â±0.13 0.14 (74% â†“)â—¦AT (Sparse) 48.95Â±0.14 82.44Â±0.17 1.31 (75% â†“)
â—¦AT (MoE) 45.57Â±0.51 78.84Â±0.75 0.15 (72% â†“)â—¦AT (MoE) 46.73Â±0.46 77.42Â±0.73 1.75 (67% â†“)
â—¦ADVMOE 51.83 Â±0.12 80.15Â±0.11 0.15 (72% â†“)â—¦ADVMOE 55.73 Â±0.13 84.32 Â±0.18 1.75 (67% â†“)
â€¢AT (Dense)
VGG-1646.19Â±0.21 82.18Â±0.23 0.31 â€¢AT (Dense)
DenseNet44.52Â±0.14 74.97Â±0.19 0.07
â—¦AT (S-Dense) 45.72Â±0.18 80.10Â±0.16 0.07 (77% â†“)â—¦AT (S-Dense) 38.07Â±0.13 69.63Â±0.11 0.02 (71% â†“)
â—¦AT (Sparse) 46.13Â±0.15 79.32Â±0.18 0.07 (77% â†“)â—¦AT (Sparse) 37.73Â±0.13 67.35Â±0.12 0.02 (71% â†“)
â—¦AT (MoE) 43.37Â±0.46 76.49Â±0.65 0.12 (61% â†“)â—¦AT (MoE) 35.21Â±0.74 64.41Â±0.81 0.03 (57% â†“)
â—¦ADVMOE 49.82 Â±0.11 80.03Â±0.10 0.12 (61% â†“)â—¦ADVMOE 39.97Â±0.11 70.13Â±0.15 0.03 (57% â†“)
CIFAR-100
â€¢AT (Dense)
ResNet-1827.23Â±0.08 58.21Â±0.12 0.54 â€¢AT (Dense)
WRN-28-1027.90Â±0.13 57.60Â±0.09 5.25
â—¦AT (S-Dense) 26.41Â±0.16 57.02Â±0.14 0.14 (74% â†“)â—¦AT (S-Dense) 26.30Â±0.10 56.80Â±0.08 1.31 (75% â†“)
â—¦AT (Sparse) 26.13Â±0.14 57.24Â±0.12 0.14 (74% â†“)â—¦AT (Sparse) 25.83Â±0.16 57.39Â±0.14 1.31 (75% â†“)
â—¦AT (MoE) 22.72Â±0.42 53.34Â±0.61 0.15 (72% â†“)â—¦AT (MoE) 22.94Â±0.55 53.39Â±0.49 1.75 (67% â†“)
â—¦ADVMOE 28.05 Â±0.13 57.73Â±0.11 0.15 (72% â†“)â—¦ADVMOE 28.82 Â±0.14 57.56Â±0.17 1.75 (67% â†“)
â€¢AT (Dense)
VGG-1622.37Â±0.15 52.36Â±0.17 0.31 â€¢AT (Dense)
DenseNet21.72Â±0.13 48.64Â±0.14 0.07
â—¦AT (S-Dense) 20.58Â±0.13 48.89Â±0.14 0.07 (77% â†“)â—¦AT (S-Dense) 16.86Â±0.21 39.97Â±0.11 0.02 (71% â†“)
â—¦AT (Sparse) 21.12Â±0.22 48.03Â±0.17 0.07 (77% â†“)â—¦AT (Sparse) 17.72Â±0.14 41.03Â±0.16 0.02 (71% â†“)
â—¦AT (MoE) 19.34Â±0.43 45.51Â±0.75 0.12 (61% â†“)â—¦AT (MoE) 14.45Â±0.45 36.72Â±0.71 0.03 (57% â†“)
â—¦ADVMOE 21.21Â±0.21 48.33Â±0.17 0.12 (61% â†“)â—¦ADVMOE 23.31 Â±0.11 48.97 Â±0.14 0.03 (57% â†“)
Tiny-ImageNet
â€¢AT (Dense)
ResNet-1838.17Â±0.14 53.81Â±0.16 2.23 â€¢AT (Dense)
WRN-28-1038.82Â±0.15 55.30Â±0.19 21.0
â—¦AT (S-Dense) 36.29Â±0.16 52.15Â±0.13 0.55 (75% â†“)â—¦AT (S-Dense) 37.09Â±0.12 54.83Â±0.16 5.26 (75% â†“)
â—¦AT (Sparse) 36.11Â±0.13 50.75Â±0.17 0.55 (75% â†“)â—¦AT (Sparse) 37.32Â±0.14 54.32Â±0.23 5.26 (75% â†“)
â—¦AT (MoE) 34.41Â±0.31 47.73Â±0.41 0.75 (68% â†“)â—¦AT (MoE) 33.31Â±0.41 49.91Â±0.52 7.44 (65% â†“)
â—¦ADVMOE 39.99 Â±0.12 53.31Â±0.14 0.75 (68% â†“)â—¦ADVMOE 40.15 Â±0.15 55.18Â±0.09 7.44 (65% â†“)
ImageNet
â€¢AT (Dense)
ResNet-1844.64Â±0.14 60.32Â±0.15 1.82 â€¢AT (Dense)
WRN-28-1045.13Â±0.14 60.97Â±0.16 16.1
â—¦AT (S-Dense) 41.19Â±0.16 58.32Â±0.12 0.48 (74% â†“)â—¦AT (S-Dense) 41.72Â±0.15 58.98Â±0.18 4.04 (75% â†“)
â—¦AT (Sparse) 40.87Â±0.15 58.22Â±0.13 0.48 (74% â†“)â—¦AT (Sparse) 39.88Â±0.18 59.21Â±0.14 4.04 (75% â†“)
â—¦AT (MoE) 35.57Â±0.73 55.47Â±0.66 0.67 (63% â†“)â—¦AT (MoE) 37.42Â±0.44 56.44Â±0.71 5.15 (68% â†“)
â—¦ADVMOE 43.32 Â±0.12 59.72Â±0.17 0.67 (63% â†“)â—¦ADVMOE 46.82 Â±0.11 58.87Â±0.07 5.15 (68% â†“)
than an MoE pathway ( r= 0.5).Second , we observe that
ADVMOE has a preference on wider models. For instance,
when WRN-28-10 (the widest model architecture in exper-
iments) is used, A DVMOE yields better robustness over the
Dense counterpart across all the dataset setups. Third , we
also observe that the direct AT application to MoE-CNN,
i.e., AT (MoE), is worse than AT (S-Dense) and A DVMOE
in all setups. This is consistent with our findings in Sec. 4.
We remark that although the usefulness of AT (MoE) was
exploited in [30] for the MoE-type ViT, it is noteffective
for training MoE-type CNNs anymore. Fourth , ADVMOE
can retain the high inference efficiency for MoE-CNN, as
evidenced by the GFLOPS measurements in Tab. 1. Com-
pared to S-Dense, MoE-CNN introduces minor computa-tional overhead due to the routing system. However, it
saves more than 50% of the inference cost vs. Dense. This
implies that our proposal A DVMOE can preserve the effi-
ciency merit of the MoE structure while effectively improv-
ing its adversarial robustness.
Robust evaluation on AutoAttack [68]. In Tab. 2, we
provide additional experiments evaluated by AutoAt-
tack [68] (termed RA-AA ), a popular robustness evalua-
tion benchmark [69]. The experiment setting in Tab. 2 fol-
lows Tab. 1 . We report RA-AA on CIFAR-10 and
CIFAR-100 with ResNet-18 and WRN-28-10. As we
can see, although AutoAttack leads to a lower RA-AA
compared to RA evaluated using PGD attacks (termed
7

--- PAGE 8 ---
Table 2. Robustness overview evaluated with AutoAttack [68] ( RA-AA ) on various datasets and model backbone architectures. Other
settings strictly follow Tab. 1. The values of RA-PGD, SA, and GFLOPS are repeated from Tab. 1 for better comparison.
Method Backbone RA-PGD (%) RA-AA (%) SA(%) GFLOPS (#) Method Backbone RA-PGD (%) RA-AA (%) SA(%) GFLOPS (#)
CIFAR-10
â€¢AT (Dense)
ResNet-1850.13Â±0.13 44.72Â±0.15 82.99Â±0.11 0.54 â€¢AT (Dense)
WRN-28-1051.75Â±0.12 45.13Â±0.12 83.54Â±0.15 5.25
â—¦AT (S-Dense) 48.12Â±0.09 42.24Â±0.13 80.18Â±0.11 0.14 (74% â†“)â—¦AT (S-Dense) 50.66Â±0.13 44.14Â±0.10 82.24Â±0.10 1.31 (75% â†“)
â—¦AT (Sparse) 47.93Â±0.17 42.11Â±0.11 80.45Â±0.13 0.14 (74% â†“)â—¦AT (Sparse) 48.95Â±0.14 43.97Â±0.11 82.44Â±0.17 1.31 (75% â†“)
â—¦AT (MoE) 45.57Â±0.51 40.42Â±0.19 78.84Â±0.75 0.15 (72% â†“)â—¦AT (MoE) 46.73Â±0.46 41.11Â±0.23 77.42Â±0.73 1.75 (67% â†“)
â—¦ADVMOE 51.83 Â±0.12 45.13 Â±0.07 80.15Â±0.11 0.15 (72% â†“)â—¦ADVMOE 55.73 Â±0.13 45.89 Â±0.11 84.32 Â±0.18 1.75 (67% â†“)
CIFAR-100
â€¢AT (Dense)
ResNet-1827.23Â±0.08 23.11Â±0.06 58.21Â±0.12 0.54 â€¢AT (Dense)
WRN-28-1027.90Â±0.13 23.45Â±0.11 57.60Â±0.09 5.25
â—¦AT (S-Dense) 26.41Â±0.16 22.11Â±0.13 57.02Â±0.14 0.14 (74% â†“)â—¦AT (S-Dense) 26.30Â±0.10 22.23Â±0.13 56.80Â±0.08 1.31 (75% â†“)
â—¦AT (Sparse) 26.13Â±0.14 21.89Â±0.11 57.24Â±0.12 0.14 (74% â†“)â—¦AT (Sparse) 25.83Â±0.16 21.97Â±0.09 57.39Â±0.14 1.31 (75% â†“)
â—¦AT (MoE) 22.72Â±0.42 16.33Â±0.25 53.34Â±0.61 0.15 (72% â†“)â—¦AT (MoE) 22.94Â±0.55 17.87Â±0.24 53.39Â±0.49 1.75 (67% â†“)
â—¦ADVMOE 28.05 Â±0.13 23.33 Â±0.06 57.73Â±0.11 0.15 (72% â†“)â—¦ADVMOE 28.82 Â±0.14 23.57 Â±0.12 57.56Â±0.17 1.75 (67% â†“)
RA-PGD), A DVMOE still outperforms AT (S-Dense), AT
(Sparse), and AT (MoE) consistently, evidenced by the bold
numbers in the RA-AA columns.
0.0 0.2 0.4 0.6 0.8 1.0
IoU score02468101214DensityAdvMoE vs. AT (Sparse)
Clean Data
Adv Data
0.0 0.2 0.4 0.6 0.8 1.0
IoU score02468101214DensityAT (MoE) vs. AT (Sparse)
Clean Data
Adv Data
(a) A DVMOE (b) AT (MoE)
Figure 6. The distribution of the intersection of union (IoU) scores
of the input-specific pathways generated by A DVMOE (a) and AT
(MoE) (b) vs. the static mask found by AT (Sparse). The distribu-
tion over the clean test set and the adversarial test set is plotted for
AT (MoE) and A DVMOE on setting (ResNet-18, CIFAR-100 ).
Other settings are aligned with Tab.1.
MoE-CNN trained by A DVMOE enjoys better router
utility. Based on the results above and the preliminary
studies in Sec. 4, we next peer into the performance differ-
ence achieved by AT (Sparse), AT (MoE), and A DVMOE
from the perspective of pathway diversities. We ask:
â‘ What is the relationship between the dynamic path-
ways generated by the routers trained by A DVMOE and the
static mask optimized by AT (Sparse)? â‘¡What is the dif-
ference between the routing decisions using A DVMOE and
AT (MoE), and how does it impact the performance?
Regarding â‘ , we investigate the cosine similarity be-
tween the pathways generated by training methods, either
AT (MoE) or A DVMOE, and the static mask found by AT
(Sparse). Since the latter can be regarded as a single path-
way used for all the data, we term it â€˜ mask pathway â€™ in con-
trast to â€˜ MoE pathway â€™. We calculate the intersection of
union ( IoU) score between the MoE pathway and the mask
pathway under each testing dataset (the clean or adversarial
version). Fig. 6 presents the IoU distributions based on the
clean and adversarial test datasets ( Fig. 6a for A DVMOE
andFig. 6b for AT (MoE)). We remark that a smaller IoU
score indicates a larger discrepancy between the MoE path-
way and the mask pathway. As we can see, the IoU distribu-tion of A DVMOE vs. AT (Sparse) in Fig. 6a shifts closer to
0compared with Fig. 6b. This observation applies to both
standard and adversarial evaluation and suggests that A DV-
MOE (our proposal) has a better capability than AT (MoE)
to re-build input-specific MoE pathways, which are more
significantly different from the input-agnostic mask path-
way identified by the pruning-based method, AT (Sparse).
Regarding â‘¡, we observe from Fig. 6 that the routers
learned by AT (MoE) are more fragile to adversarial attacks
compared to A DVMOE, as evidenced by the less intersec-
tion area of adversarial data vs. clean data. This is also
aligned with Insight 3 in Sec.4. Moreover, the routing pol-
icy learned by A DVMOE is more diverse than AT (MoE),
as indicated by the latterâ€™s density-concentrated IoU scores.
In contrast, the distribution of A DVMOE is dispersed with a
smaller peak value. Therefore, regarding the expert utility,
ADVMOE is able to assign the inputs to a larger group of
pathways than AT (MoE), making better use of experts.
A coupling effect of expert number Nand per-expert
model scale ron A DVMOE. Recall that there exist two
key parameters involved in MoE-CNN ( Fig. A1 ):(a)the
number of experts N, and (b)the model scale rthat de-
fines the per-expert (or per-pathway) model capacity. Given
the backbone model ( e.g., ResNet-18 in this experiment),
a larger Npaired with a small rimplies that each expert
may only have limited model capacity, i.e., corresponding
to a less number of channels. Regardless of N, ifr= 1,
the full backbone network will be used to form the identical
decision pathway.
Fig. 7 shows the RA of MoE-CNN trained by A DVMOE
vs. the model scale parameter rat different values of N.
Two insightful observations can be drawn. First , there ex-
ists an MoE regime ( e.g.,N < 8andrâˆˆ[0.5,0.9]), in
which A DVMOE can outperform AT (Dense) ( i.e.,r= 1)
by a substantial margin. This shows the benefit of MoE in
adversarial robustness. However, if the number of experts
becomes larger ( e.g.,N= 10 ), the increasing diversity of
MoE pathways can raise the difficulty of routersâ€™ robustifi-
cation and thus hampers the performance of A DVMOE (see
N= 10 andr= 0.8inFig. 7 ).Second , there exists an
8

--- PAGE 9 ---
1.00.90.80.70.60.50.40.30.20.1
Model Scale35404550 Robust Accuracy (%)
# of experts/layer
N=2
N=5
RT(Big-Dense)N=8
N=10Figure 7. Performance of A DVMOE under CIFAR-10 using
ResNet-18 as the backbone network for different values of expert
number Nand model scale r. The black dash line denotes the per-
formance of Dense ( i.e.r= 1).
Figure 8. Robustness comparison of models trained with different
methods under various model scale settings. Results higher than
that of AT (Dense) are marked with â‹†. Other setups are aligned
with Tab. 1. Please refer to Appendix C for exact numbers and
GFLOPS comparisons.
ineffective MoE regime ( e.g.,Nâ‰¥8andr <0.5), in which
the performance of A DVMOE largely deviates from that of
AT (Dense). In this regime, each expert consists only of a
small number of channels, which restricts its robust training
ability. Accordingly, both the increasing diversity of MoE
pathways (large N) and the limited capacity per pathway
(small r) could impose the difficulties of AT for MoE-CNN.
In our experiments, we choose r= 0.5andN= 2, which
preserves the diversity of MoE pathways ( i.e., inference ef-
ficiency) and retains the effectiveness of robust training.
Performance with different model scales. To make sure
the observations and conclusions from Tab. 1 are consis-
tent across different values of the model scale parameter r,
we repeated the experiments on ( CIFAR-10 , ResNet-18)
and (CIFAR-10 , WRN-28-10) using râˆˆ {0.2,0.5,0.8}to
cover the {sparse, medium, dense }regimes with respect to
Dense ( r= 1.0).Fig. 8 summarizes the obtained experi-
ment results. As we can see, A DVMOE yields consistent
robustness improvements over all the baselines, including
Dense. And the improvement rises as the model scale r
increases. This is not surprising as more parameters will
be used when processing one input. Yet, a clear drawback
brought by the larger model scale ris the increase of in-
ference cost, evidenced by the GFLOPS numbers. When
rturns to be large (like r= 0.8), the efficiency benefitTable 3. Performance on robust training for MoE-ViT with in the
setup (ImageNet, DeiT-Tiny). Other settings follow Tab. 1.
Method RA (%) SA (%) GFLOPS (#)
SOTA[30] 44.63 61.72 0.27
ADVMOE 45.93 61.67 0.27
brought by the pathway sparsification from MoE gradually
vanishes. Thus, a medium sparsity ( r= 0.5) is a better
choice to balance the trade-off between performance and
efficiency, which is thus adopted as our default setting.
Extended study: A DVMOE for ViT. To explore the ca-
pability of our proposal A DVMOE on ViT-based MoE mod-
els (MoE-ViT), Tab. 3 presents additional results following
the recently published SOTA baseline [30] for MoE-ViT.
As we can see, A DVMOE is also applicable to MoE-ViT
and can boost robustness over the SOTA baseline by over
1%RA improvement, while achieving a similar level of
SA. Thus, although our work focuses on robust training for
MoE-CNN, it has the promise of algorithmic generality to
other MoE-based architectures. We defer a more compre-
hensive study in the future.
Additional experiments. We conduct ablation studies on
(1) robustness evaluation using AutoAttack [68] (consistent
findings can be drawn as PGD attacks), (2) attacks steps
used in AT, and (3) additional explorations towards the cou-
pling effect between the number of experts and the model
scales. We refer readers to Appendix C for detailed results.
6. Conclusion
In this work, we design an effective robust training
scheme for MoE-CNN. We first present several key insights
on the defense mechanism of MoE-CNN by dissecting ad-
versarial robustness through the lens of routers and path-
ways. We next propose A DVMOE, the first robust training
framework for MoE-CNN via bi-level optimization, robus-
tifying routers and pathways in a cooperative and adaptive
mode. Finally, extensive experiments demonstrate the ef-
fectiveness of A DVMOE in a variety of data-model setups.
Meanwhile, we admit that the A DVMOE requires roughly
twice the computational capacity compared to the vanilla
AT baseline due to alternating optimization that calls two
back-propagations per step. Addressing this efficiency con-
cern presents a meaningful avenue for future work.
Acknowledgement
The work of Y . Zhang, S. Chang and S. Liu was partially
supported by National Science Foundation (NSF) Grant IIS-
2207052 and Cisco Research Award. The work of Z. Wang
is in part supported by the US Army Research Office Young
Investigator Award (W911NF2010240).
9

--- PAGE 10 ---
References
[1] Anurag Arnab, Mostafa Dehghani, Georg Heigold, Chen
Sun, Mario Lu Ë‡ciÂ´c, and Cordelia Schmid. Vivit: A video
vision transformer. In Proceedings of the IEEE/CVF Inter-
national Conference on Computer Vision , pages 6836â€“6846,
2021. 1
[2] Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov,
Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner,
Mostafa Dehghani, Matthias Minderer, Georg Heigold, Syl-
vain Gelly, et al. An image is worth 16x16 words: Trans-
formers for image recognition at scale. arXiv preprint
arXiv:2010.11929 , 2020.
[3] Alexander Kolesnikov, Lucas Beyer, Xiaohua Zhai, Joan
Puigcerver, Jessica Yung, Sylvain Gelly, and Neil Houlsby.
Big transfer (bit): General visual representation learning. In
European conference on computer vision , pages 491â€“507.
Springer, 2020.
[4] Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee,
Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, Pe-
ter J Liu, et al. Exploring the limits of transfer learning
with a unified text-to-text transformer. J. Mach. Learn. Res. ,
21(140):1â€“67, 2020. 2
[5] Chen Sun, Abhinav Shrivastava, Saurabh Singh, and Abhi-
nav Gupta. Revisiting unreasonable effectiveness of data in
deep learning era. In Proceedings of the IEEE international
conference on computer vision , pages 843â€“852, 2017. 1
[6] Zhengyan Zhang, Yankai Lin, Zhiyuan Liu, Peng Li,
Maosong Sun, and Jie Zhou. Moefication: Conditional com-
putation of transformer models for efficient inference. arXiv
preprint arXiv:2110.01786 , 2021. 1
[7] Noam Shazeer, Azalia Mirhoseini, Krzysztof Maziarz, Andy
Davis, Quoc Le, Geoffrey Hinton, and Jeff Dean. Outra-
geously large neural networks: The sparsely-gated mixture-
of-experts layer. arXiv preprint arXiv:1701.06538 , 2017. 1,
2
[8] Xin Wang, Fisher Yu, Lisa Dunlap, Yi-An Ma, Ruth Wang,
Azalia Mirhoseini, Trevor Darrell, and Joseph E Gonzalez.
Deep mixture of experts via shallow embedding. In Uncer-
tainty in artificial intelligence , pages 552â€“562. PMLR, 2020.
1, 2
[9] Carlos Riquelme, Joan Puigcerver, Basil Mustafa, Maxim
Neumann, Rodolphe Jenatton, Andr Â´e Susano Pinto, Daniel
Keysers, and Neil Houlsby. Scaling vision with sparse mix-
ture of experts. Advances in Neural Information Processing
Systems , 34:8583â€“8595, 2021. 1, 2
[10] William Fedus, Barret Zoph, and Noam Shazeer. Switch
transformers: Scaling to trillion parameter models with sim-
ple and efficient sparsity, 2021.
[11] Fuzhao Xue, Ziji Shi, Futao Wei, Yuxuan Lou, Yong Liu,
and Yang You. Go wider instead of deeper. In Proceedings ofthe AAAI Conference on Artificial Intelligence , pages 8779â€“
8787, 2022. 2
[12] Aran Komatsuzaki, Joan Puigcerver, James Lee-Thorp, Car-
los Riquelme Ruiz, Basil Mustafa, Joshua Ainslie, Yi Tay,
Mostafa Dehghani, and Neil Houlsby. Sparse upcycling:
Training mixture-of-experts from dense checkpoints. arXiv
preprint arXiv:2212.05055 , 2022.
[13] Yanqi Zhou, Tao Lei, Hanxiao Liu, Nan Du, Yanping Huang,
Vincent Zhao, Andrew Dai, Zhifeng Chen, Quoc Le, and
James Laudon. Mixture-of-experts with expert choice rout-
ing. arXiv preprint arXiv:2202.09368 , 2022.
[14] Bo Li, Yifei Shen, Jingkang Yang, Yezhen Wang, Jiawei
Ren, Tong Che, Jun Zhang, and Ziwei Liu. Sparse mixture-
of-experts are domain generalizable learners. arXiv preprint
arXiv:2206.04046 , 2022.
[15] Tianlong Chen, Zhenyu Zhang, AJAY KUMAR JAISWAL,
Shiwei Liu, and Zhangyang Wang. Sparse moe with random
routing as the new dropout: Training bigger and self-scalable
models. In International Conference on Learning Represen-
tations , 2023. 1, 2
[16] Sam Gross, Marcâ€™Aurelio Ranzato, and Arthur Szlam. Hard
mixtures of experts for large scale weakly supervised vision.
InProceedings of the IEEE Conference on Computer Vision
and Pattern Recognition , pages 6865â€“6873, 2017. 1, 2
[17] Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng
Zhang, Stephen Lin, and Baining Guo. Swin transformer:
Hierarchical vision transformer using shifted windows. In
Proceedings of the IEEE/CVF International Conference on
Computer Vision , pages 10012â€“10022, 2021. 1
[18] Alhabib Abbas and Yiannis Andreopoulos. Biased mixtures
of experts: Enabling computer vision inference under data
transfer limitations. IEEE Transactions on Image Process-
ing, 29:7656â€“7667, 2020. 1, 2
[19] Karim Ahmed, Mohammad Haris Baig, and Lorenzo Torre-
sani. Network of experts for large-scale image categoriza-
tion. In European Conference on Computer Vision , pages
516â€“532. Springer, 2016. 2
[20] Svetlana Pavlitskaya, Christian Hubschneider, Michael We-
ber, Ruby Moritz, Fabian Huger, Peter Schlicht, and Marius
Zollner. Using mixture of expert models to gain insights into
semantic segmentation. In Proceedings of the IEEE/CVF
Conference on Computer Vision and Pattern Recognition
Workshops , pages 342â€“343, 2020. 1, 2
[21] Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy.
Explaining and harnessing adversarial examples. arXiv
preprint arXiv:1412.6572 , 2014. 1, 2, 3
[22] Nicholas Carlini and David Wagner. Towards evaluating the
robustness of neural networks. In IEEE Symposium on S&P ,
2017. 2
10

--- PAGE 11 ---
[23] Nicolas Papernot, Patrick McDaniel, Somesh Jha, Matt
Fredrikson, Z Berkay Celik, and Ananthram Swami. The
limitations of deep learning in adversarial settings. In Secu-
rity and Privacy (EuroS&P), 2016 IEEE European Sympo-
sium on , pages 372â€“387. IEEE, 2016. 1, 2, 3
[24] Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt,
Dimitris Tsipras, and Adrian Vladu. Towards deep learning
models resistant to adversarial attacks. In International Con-
ference on Learning Representations , 2018. 1, 2, 3, 4, 5, 6,
7
[25] Hongyang Zhang, Yaodong Yu, Jiantao Jiao, Eric P Xing,
Laurent El Ghaoui, and Michael I Jordan. Theoretically prin-
cipled trade-off between robustness and accuracy. ICML ,
2019. 2, 3, 6
[26] Ali Shafahi, Mahyar Najibi, Mohammad Amin Ghiasi,
Zheng Xu, John Dickerson, Christoph Studer, Larry S Davis,
Gavin Taylor, and Tom Goldstein. Adversarial training for
free! In Advances in Neural Information Processing Sys-
tems, pages 3353â€“3364, 2019. 3
[27] Eric Wong, Leslie Rice, and J. Zico Kolter. Fast is better
than free: Revisiting adversarial training. In International
Conference on Learning Representations , 2020. 6
[28] Dinghuai Zhang, Tianyuan Zhang, Yiping Lu, Zhanxing
Zhu, and Bin Dong. You only propagate once: Accelerating
adversarial training via maximal principle. arXiv preprint
arXiv:1905.00877 , 2019. 3
[29] Anish Athalye, Nicholas Carlini, and David Wagner. Ob-
fuscated gradients give a false sense of security: Circum-
venting defenses to adversarial examples. arXiv preprint
arXiv:1802.00420 , 2018. 1, 2
[30] Joan Puigcerver, Rodolphe Jenatton, Carlos Riquelme, Pran-
jal Awasthi, and Srinadh Bhojanapalli. On the adver-
sarial robustness of mixture of experts. arXiv preprint
arXiv:2210.10253 , 2022. 1, 3, 6, 7, 9
[31] Xingyi Yang, Daquan Zhou, Songhua Liu, Jingwen Ye, and
Xinchao Wang. Deep model reassembly. In Advances in
Neural Information Processing Systems , 2022. 2
[32] Songhua Liu, Kai Wang, Xingyi Yang, Jingwen Ye, and Xin-
chao Wang. Dataset distillation via factorization. In Ad-
vances in Neural Information Processing Systems , 2022.
[33] Xingyi Yang, Jingwen Ye, and Xinchao Wang. Factorizing
knowledge in neural networks. In European Conference on
Computer Vision , 2022. 2
[34] Seniha Esen Yuksel, Joseph N Wilson, and Paul D Gader.
Twenty years of mixture of experts. IEEE transactions
on neural networks and learning systems , 23(8):1177â€“1193,
2012. 2
[35] Michael I Jordan and Robert A Jacobs. Hierarchical mix-
tures of experts and the em algorithm. Neural computation ,
6(2):181â€“214, 1994.[36] David Eigen, Marcâ€™Aurelio Ranzato, and Ilya Sutskever.
Learning factored representations in a deep mixture of ex-
perts. arXiv preprint arXiv:1312.4314 , 2013.
[37] Robert A Jacobs, Michael I Jordan, Steven J Nowlan, and
Geoffrey E Hinton. Adaptive mixtures of local experts. Neu-
ral computation , 3(1):79â€“87, 1991.
[38] Ke Chen, Lei Xu, and Huisheng Chi. Improved learning
algorithms for mixture of experts in multiclass classification.
Neural networks , 12(9):1229â€“1252, 1999.
[39] Mike Lewis, Shruti Bhosale, Tim Dettmers, Naman Goyal,
and Luke Zettlemoyer. Base layers: Simplifying training of
large, sparse models. In International Conference on Ma-
chine Learning , pages 6265â€“6274. PMLR, 2021. 2
[40] Dmitry Lepikhin, HyoukJoong Lee, Yuanzhong Xu, Dehao
Chen, Orhan Firat, Yanping Huang, Maxim Krikun, Noam
Shazeer, and Zhifeng Chen. Gshard: Scaling giant models
with conditional computation and automatic sharding. arXiv
preprint arXiv:2006.16668 , 2020. 2
[41] Nan Du, Yanping Huang, Andrew M Dai, Simon Tong,
Dmitry Lepikhin, Yuanzhong Xu, Maxim Krikun, Yanqi
Zhou, Adams Wei Yu, Orhan Firat, et al. Glam: Efficient
scaling of language models with mixture-of-experts. In In-
ternational Conference on Machine Learning , pages 5547â€“
5569. PMLR, 2022. 2
[42] Barret Zoph, Irwan Bello, Sameer Kumar, Nan Du, Yan-
ping Huang, Jeff Dean, Noam Shazeer, and William Fedus.
Designing effective sparse expert models. arXiv preprint
arXiv:2202.08906 , 2022. 2
[43] Basil Mustafa, Carlos Riquelme, Joan Puigcerver, Rodolphe
Jenatton, and Neil Houlsby. Multimodal contrastive learning
with limoe: the language-image mixture of experts. arXiv
preprint arXiv:2206.02770 , 2022. 2
[44] Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan
Bruna, Dumitru Erhan, Ian Goodfellow, and Rob Fergus.
Intriguing properties of neural networks. arXiv preprint
arXiv:1312.6199 , 2013. 2
[45] Alexey Kurakin, Ian Goodfellow, and Samy Bengio. Ad-
versarial examples in the physical world. arXiv preprint
arXiv:1607.02533 , 2016. 2
[46] Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt,
Dimitris Tsipras, and Adrian Vladu. Towards deep learning
models resistant to adversarial attacks. ICLR , 2018. 2
[47] Jingfeng Zhang, Xilie Xu, Bo Han, Gang Niu, Lizhen Cui,
Masashi Sugiyama, and Mohan Kankanhalli. Attacks which
do not kill training make adversarial learning stronger. In In-
ternational Conference on Machine Learning , pages 11278â€“
11287. PMLR, 2020. 3
[48] Yihua Zhang, Yuguang Yao, Parikshit Ram, Pu Zhao, Tian-
long Chen, Mingyi Hong, Yanzhi Wang, and Sijia Liu. Ad-
vancing model pruning via bi-level optimization. arXiv
preprint arXiv:2210.04092 , 2022. 13
11

--- PAGE 12 ---
[49] Shupeng Gui, Haotao N Wang, Haichuan Yang, Chen Yu,
Zhangyang Wang, and Ji Liu. Model compression with ad-
versarial robustness: A unified optimization framework. In
Advances in Neural Information Processing Systems , pages
1283â€“1294, 2019.
[50] Vikash Sehwag, Shiqi Wang, Prateek Mittal, and Suman
Jana. Hydra: Pruning adversarially robust neural networks.
Advances in Neural Information Processing Systems , 33,
2020. 3, 4, 6, 13
[51] Yonggan Fu, Qixuan Yu, Yang Zhang, Shang Wu,
Xu Ouyang, David Cox, and Yingyan Lin. Drawing ro-
bust scratch tickets: Subnetworks with inborn robustness are
found within randomly initialized networks. Advances in
Neural Information Processing Systems , 34, 2021.
[52] Maksym Andriushchenko and Nicolas Flammarion. Under-
standing and improving fast adversarial training. NeurIPS ,
2020.
[53] Tianlong Chen, Zhenyu Zhang, Sijia Liu, Shiyu Chang, and
Zhangyang Wang. Robust overfitting may be mitigated by
properly learned smoothening. In ICLR , volume 1, 2021.
[54] Sylvestre-Alvise Rebuffi, Sven Gowal, Dan Andrei Calian,
Florian Stimberg, Olivia Wiles, and Timothy A Mann. Data
augmentation can improve robustness. Advances in Neural
Information Processing Systems , 34:29935â€“29948, 2021. 3
[55] Chelsea Finn, Pieter Abbeel, and Sergey Levine. Model-
agnostic meta-learning for fast adaptation of deep networks.
arXiv preprint arXiv:1703.03400 , 2017. 5
[56] James C Bezdek and Richard J Hathaway. Convergence of
alternating optimization. Neural, Parallel & Scientific Com-
putations , 11(4):351â€“368, 2003. 5
[57] Risheng Liu, Jiaxin Gao, Jin Zhang, Deyu Meng, and
Zhouchen Lin. Investigating bi-level optimization for learn-
ing and vision from a unified perspective: A survey and be-
yond. arXiv preprint arXiv:2101.11517 , 2021. 5
[58] Mingyi Hong, Hoi-To Wai, Zhaoran Wang, and Zhuoran
Yang. A two-timescale framework for bilevel optimization:
Complexity analysis and application to actor-critic. arXiv
preprint arXiv:2007.05170 , 2020. 6
[59] Yihua Zhang, Prashant Khanduri, Ioannis Tsaknakis,
Yuguang Yao, Mingyi Hong, and Sijia Liu. An introduc-
tion to bi-level optimization: Foundations and applications
in signal processing and machine learning. arXiv preprint
arXiv:2308.00788 , 2023. 6
[60] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
Deep residual learning for image recognition. In Proceed-
ings of the IEEE conference on computer vision and pattern
recognition , pages 770â€“778, 2016. 6, 13
[61] Sergey Zagoruyko and Nikos Komodakis. Wide residual net-
works. arXiv preprint arXiv:1605.07146 , 2016. 6, 13[62] Karen Simonyan and Andrew Zisserman. Very deep convo-
lutional networks for large-scale image recognition. arXiv
preprint arXiv:1409.1556 , 2014. 6, 13
[63] Gao Huang, Zhuang Liu, Laurens Van Der Maaten, and Kil-
ian Q Weinberger. Densely connected convolutional net-
works. In Proceedings of the IEEE conference on computer
vision and pattern recognition , pages 4700â€“4708, 2017. 6,
13
[64] Yihua Zhang, Guanhua Zhang, Mingyi Hong, Shiyu Chang,
and Sijia Liu. Revisiting and advancing adversarial train-
ing through the lens of bi-level optimization, submitted to
NeurIPS, 2021. 6
[65] A. Krizhevsky and G. Hinton. Learning multiple layers of
features from tiny images. Masterâ€™s thesis, Department of
Computer Science, University of Toronto , 2009. 6
[66] Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li,
and Li Fei-Fei. Imagenet: A large-scale hierarchical im-
age database. In Computer Vision and Pattern Recognition,
2009. CVPR 2009. IEEE Conference on , pages 248â€“255.
IEEE, 2009. 6
[67] Yihua Zhang, Guanhua Zhang, Prashant Khanduri, Mingyi
Hong, Shiyu Chang, and Sijia Liu. Revisiting and advanc-
ing fast adversarial training through the lens of bi-level opti-
mization. In International Conference on Machine Learning ,
pages 26693â€“26712. PMLR, 2022. 6
[68] Francesco Croce and Matthias Hein. Reliable evalua-
tion of adversarial robustness with an ensemble of diverse
parameter-free attacks. In International Conference on Ma-
chine Learning , pages 2206â€“2216. PMLR, 2020. 7, 8, 9
[69] Francesco Croce, Maksym Andriushchenko, Vikash Se-
hwag, Nicolas Flammarion, Mung Chiang, Prateek Mittal,
and Matthias Hein. Robustbench: a standardized adversar-
ial robustness benchmark. arXiv preprint arXiv:2010.09670 ,
2020. 7
[70] Xiang Deng and Zhongfei Mark Zhang. Is the meta-learning
idea able to improve the generalization of deep neural net-
works on the standard supervised learning? In 2020 25th
International Conference on Pattern Recognition (ICPR) ,
pages 150â€“157. IEEE, 2021. 13
[71] Resnet implementation in pytorch. https:
//github.com/kuangliu/pytorch-cifar/
blob/master/models/resnet.py . 13
12

--- PAGE 13 ---
Appendix
A. Sparse MoE Structures
Overall MoE Design Fig. A1 shows the overall MoE design adopted in this work. By default, the experts in each layer are
pre-defined with little channel overlapping. The router exactly selects one expert for a given input as its pathway component
in this layer.
â‹¯â‹¯â‹¯â‹¯â‹¯â‹¯â‹¯â‹¯InputOutputPathwayLayer ğŸLayer ğŸLayer ğ’Layer ğ‘´MoE-CNN(4-Expert)ğ‘™-th MoE LayerModel Scaleğ«=ğŸ/ğŸ–ğ‘ªğŸğ‘ªğŸğ¸!ğ‘ªğŸ“ğ‘ªğŸ”ğ¸"ğ‘ªğŸ•ğ‘ªğŸ–ğ¸#ğ¸$ğ‘ªğŸ‘ğ‘ªğŸ’Output0001InputExpert SelectionRouter
Figure A1. The sparse MoE-CNN structure and its MoE design in this paper. The router makes the input-specific expert selection and the selected experts
(e.g.,E2) form an end-to-end pathway (emphasized in green). This shows an example of the MoE layer with 4experts with the model scale of 0.25.
B. Detailed Experiment Setups
Training Details We train all the methods for 100 epochs with an initial learning rate of 0.1and a cosine decaying learning
rate scheduler. In particular, following the original training pipeline of AT (Sparse) [50], we first train 100 epochs to optimize
the mask for Sparse-CNN, and then finetune the model weights based on the fixed mask for another 100 epochs. We use the
SGD optimizer for all the methods and a momentum value of 0.9together with a weight decay factor of 5eâˆ’4. We use a
batch size of 128 on all the datasets, except 512 for ImageNet .
For A DVMOE, we randomly sample different batches of data (of the same batch size b) for updating backbone networks
(experts) and routers since the use of diverse data batches is confirmed to benefit generalization for bi-level learning like
meta-learning [70] and model pruning [48].
Datasets and Model Backbones To implement MoE-CNN and other baselines, we conduct experiments on ResNet-
18 [60], Wide-ResNet-28-10 (WRN-28-10) [61], VGG-16 [62], and DenseNet [63]. In particular, we adopt the ResNet-18
and WRN-28-10 with convolutional kernels of 3Ã—3in the first layer for TinyImageNet ,CIFAR-10 andCIFAR-100 ,
and7Ã—7forImageNet , following the implementations in [71].
C. Additional Experiments
Ablation study on train-time attack generation steps InTab. 1. , we adopt the 2-step PGD attacks to generate the train-
time perturbation. Also, we conduct ablation studies on the train-time attack steps and raise its number from 2to10. We
show the obtained results in Tab. A1 . As we can see, the effectiveness of A DVMOE holds: Both RA and SA achieved by
ADVMOE outperform its baselines by a substantial margin.
Table A1. Ablation study on the train-time attack step numbers. The attack step number used to generate train-time perturbation is raised to 10from 2
compared the default setting. Other settings strictly follow Tab 1 .
MethodResNet-18 WRN-28-10
RA(%) RA-AA (%) SA(%) GFLOPS RA(%) RA-AA (%) SA(%) GFLOPS
CIFAR-10
â€¢AT (Dense) 50.97Â±0.14 46.29Â±0.15 81.44Â±0.15 0.54 52.35Â±0.18 46.49Â±0.11 81.45Â±0.15 5.25
â—¦AT (S-Dense) 48.22Â±0.11 43.79Â±0.15 79.93Â±0.12 0.14 ( 74%â†“) 50.92Â±0.18 44.69Â±0.19 80.33Â±0.15 1.31 ( 75%â†“)
â—¦AT (Sparse) 48.29Â±0.14 43.18Â±0.19 79.35Â±0.17 0.14 ( 74%â†“) 48.69Â±0.18 44.50Â±0.16 80.32Â±0.11 1.31 ( 75%â†“)
â—¦AT (MoE) 46.79Â±0.49 41.13Â±0.29 78.32Â±0.51 0.15 ( 72%â†“) 47.24Â±0.57 42.39Â±0.26 76.21Â±0.42 1.75 ( 67%â†“)
â—¦ADVMOE 52.22 Â±0.14 46.44 Â±0.09 79.62Â±0.12 0.15 ( 72%â†“)56.13 Â±0.11 46.73 Â±0.08 82.19 Â±0.14 1.75 ( 67%â†“)
13

--- PAGE 14 ---
Statistics for Fig. 7. In Fig. 7, we show the robustness comparison of different models in various model scale settings. In
Tab. A2, we disclose the statistics for the plotting Fig. 7 as well as the GFLOPS for different model scales.
Table A2. Results of A DVMOE (our proposal) vs.baselines using different model scale settings on the datasets CIFAR-10 andCIFAR-100 . The model
scalerâˆˆ {0.2,0.5,0.8}is considered. Other settings strictly follow Tab. 2. The statistics in this table are associated with the plots in Fig. 7.
Methodmodel scale r= 0.2 model scale r= 0.5 model scale r= 0.8 AT (Dense) , model scale r= 1.0
RA(%) SA(%) GFLOPS RA(%) SA(%) GFLOPS RA(%) SA(%) GFLOPS RA(%) SA(%) GFLOPs
CIFAR-10 , ResNet-18
AT (S-Dense) 43.83Â±0.11 78.28Â±0.14 0.13 ( 76%â†“)48.12Â±0.09 80.18Â±0.11 0.14 ( 74%â†“)49.44Â±0.09 81.32Â±0.11 0.36 ( 33%â†“)
50.13Â±0.13 82.99Â±0.11 0.54AT (Sparse) 43.24Â±0.14 79.14Â±0.14 0.13 ( 76%â†“)47.93Â±0.17 80.45Â±0.13 0.14 ( 74%â†“)48.32Â±0.13 81.77Â±0.11 0.36 ( 33%â†“)
AT (MoE) 38.75Â±0.41 76.54Â±0.29 0.14 ( 74%â†“)45.57Â±0.51 78.84Â±0.75 0.15 ( 72%â†“)45.99Â±0.42 79.46Â±0.31 0.37 ( 31%â†“)
ADVMOE 49.18Â±0.12 79.03Â±0.19 0.14 ( 74%â†“)51.83 Â±0.12 80.15Â±0.11 0.15 ( 72%â†“)52.38 Â±0.14 81.44Â±0.13 0.37 ( 31%â†“)
CIFAR-10 , WRN-28-10
AT (S-Dense) 49.59Â±0.17 79.93Â±0.13 0.21 ( 96%â†“)50.66Â±0.13 82.24Â±0.10 1.31 ( 75%â†“)51.73Â±0.17 82.88Â±0.14 3.36 ( 38%â†“)
51.75Â±0.12 83.54Â±0.15 5.25AT (Sparse) 48.37Â±0.21 79.32Â±0.21 0.21 ( 96%â†“)48.95Â±0.14 82.44Â±0.17 1.31 ( 75%â†“)50.73Â±0.19 82.11Â±0.23 3.36 ( 38%â†“)
AT (MoE) 42.29Â±0.51 75.32Â±0.38 0.94 ( 82%â†“)46.73Â±0.46 77.42Â±0.73 1.75 ( 67%â†“)46.94Â±0.45 79.11Â±0.27 4.57 ( 13%â†“)
ADVMOE 54.02Â±0.09 79.55Â±0.12 0.94 ( 82%â†“)55.73 Â±0.13 84.32 Â±0.18 1.75 ( 67%â†“)56.07 Â±0.14 84.45 Â±0.09 4.57 ( 13%â†“)
Training trajectory A DVMOE. We show in Fig. A2 that the A DVMOE converges well within 100 training epochs using
a cosine learning rate schedule. The SA (standard accuracy) and RA (robust accuracy) are evaluated and collected at the end
of each training epoch.
0 20 40 60 80 100
Epoch Number304050607080 Accuracy (%)Test RA
Test SA
0 20 40 60 80 100
Epoch Number304050607080 Accuracy (%)Test RA
Test SA
(a) ResNet-18, CIFAR10 (b) WRN-28-10, CIFAR-10
Figure A2. The training trajectory of A DVMOE under different data-model settings.
14

# 2309.14157.pdf
# Đã chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/convolution/2309.14157.pdf
# Kích thước tập tin: 1288692 bytes

===============================================
NỘI DUNG TẬP TIN PDF
===============================================

--- TRANG 1 ---
CÔNG TRÌNH NÀY ĐÃ ĐƯỢC GỬI ĐẾN IEEE ĐỂ XEM XÉT XUẤT BẢN. BẢN QUYỀN CÓ THỂ ĐƯỢC CHUYỂN GIAO MÀ KHÔNG CẦN THÔNG BÁO, SAU ĐÓ PHIÊN BẢN NÀY CÓ THỂ KHÔNG CÒN TRUY CẬP ĐƯỢC. 1

LAPP: Cắt tỉa Tiến bộ Thích ứng Theo Lớp để
Nén CNNs từ Đầu
Pucheng Zhai, Kailing Guo∗,Thành viên, IEEE, Fang Liu, Thành viên, IEEE,
Xiaofen Xing, Thành viên, IEEE, Xiangmin Xu, Thành viên cao cấp, IEEE,

Tóm tắt —Cắt tỉa có cấu trúc là một phương pháp nén mạng nơ-ron tích chập (CNN) thường được sử dụng. Thiết lập tỷ lệ cắt tỉa là một vấn đề cơ bản trong cắt tỉa có cấu trúc. Hầu hết các công trình hiện tại đều giới thiệu quá nhiều tham số có thể học được để phân bổ các tỷ lệ cắt tỉa khác nhau cho các lớp khác nhau trong CNN hoặc không thể kiểm soát tỷ lệ nén một cách rõ ràng. Vì các khối mạng quá hẹp làm cản trở luồng thông tin cho việc huấn luyện, việc thiết lập tỷ lệ cắt tỉa tự động không thể khám phá tỷ lệ cắt tỉa cao cho một lớp cụ thể. Để khắc phục những hạn chế này, chúng tôi đề xuất một khung mới có tên là Cắt tỉa Tiến bộ Thích ứng Theo Lớp (LAPP), nó dần dần nén mạng trong quá trình huấn luyện ban đầu vài epochs từ đầu. Cụ thể, LAPP thiết kế một chiến lược cắt tỉa hiệu quả và hiệu quả mà giới thiệu một ngưỡng có thể học được cho mỗi lớp và các ràng buộc FLOPs cho mạng. Được hướng dẫn bởi cả mất mát nhiệm vụ và các ràng buộc FLOPs, các ngưỡng có thể học được được cập nhật một cách động và dần dần để phù hợp với những thay đổi của điểm số quan trọng trong quá trình huấn luyện. Do đó chiến lược cắt tỉa có thể dần dần cắt tỉa mạng và tự động xác định tỷ lệ cắt tỉa phù hợp cho từng lớp. Hơn nữa, để duy trì sức mạnh biểu đạt của lớp đã cắt tỉa, trước khi huấn luyện bắt đầu, chúng tôi giới thiệu một đường tránh nhẹ bổ sung cho mỗi lớp tích chập được cắt tỉa, chỉ thêm tương đối ít gánh nặng bổ sung. Phương pháp của chúng tôi thể hiện hiệu suất vượt trội so với các phương pháp nén trước đây trên nhiều tập dữ liệu và kiến trúc mạng cốt lõi khác nhau. Ví dụ, trên CIFAR-10, phương pháp của chúng tôi nén ResNet-20 xuống 40,3% mà không giảm độ chính xác. 55,6% FLOPs của ResNet-18 được giảm với 0,21% tăng độ chính xác top-1 và 0,40% tăng độ chính xác top-5 trên ImageNet.

Thuật ngữ chỉ mục —Cắt tỉa tiến bộ, Ngưỡng có thể học, Ràng buộc FLOPs, Đường tránh.

I. GIỚI THIỆU

TRONG những năm gần đây, mạng nơ-ron tích chập (CNNs) đã đạt được những thành tựu đáng kể trong nhiều ứng dụng thị giác máy tính như phân loại [1], [2], phát hiện đối tượng [3], [4], nhận dạng khuôn mặt [5], [6], nhận dạng hành động [7], và phân đoạn ngữ nghĩa [8]. Tuy nhiên, trong khi hiệu suất của các mô hình CNN tiếp tục được cải thiện, các CNNs trở nên sâu hơn và rộng hơn, dẫn đến sự gia tăng bùng nổ về tham số và FLOPs. Do đó, các CNNs hiện tại yêu cầu chi phí lưu trữ và tính toán rất cao, khiến việc triển khai CNNs trên các thiết bị nhỏ với tài nguyên hạn chế trở nên khó khăn. Để giải quyết vấn đề này, các kỹ thuật nén CNN đã thu hút ngày càng nhiều sự chú ý. Các kỹ thuật nén CNN phổ biến bao gồm cắt tỉa [9]–[11], phân rã tensor hạng thấp [12]–[14], chưng cất kiến thức [15], [16], lượng tử hóa bit thấp [17]–[19], và thiết kế kiến trúc nhỏ gọn [20]–[22]. Trong bài báo này, chúng tôi tập trung vào cắt tỉa là một điểm nóng nghiên cứu.

Cắt tỉa có thể được chia thành cắt tỉa không có cấu trúc và có cấu trúc. Cắt tỉa không có cấu trúc trực tiếp loại bỏ các phần tử trọng số không quan trọng trong một bộ lọc một cách độc lập bằng một số chỉ số quan trọng [23], [24], dẫn đến tính thưa thớt không đều. Khó khăn cho cấu trúc không đều để tận dụng phần mềm và phần cứng hiện có để có được tăng tốc thực tế. Ngược lại, cắt tỉa có cấu trúc trực tiếp loại bỏ toàn bộ các bộ lọc không quan trọng (hoặc kênh, lớp, khối, v.v.) dựa trên các chỉ số quan trọng khác nhau [25], [26], và đạt được tính thưa thớt có cấu trúc. Do đó, cắt tỉa có cấu trúc, có thể đạt được tăng tốc thực tế dựa trên phần mềm và phần cứng hiện có, đã được phát triển nhanh chóng trong những năm gần đây. Mặc dù các phương pháp cắt tỉa có cấu trúc hiện tại, đặc biệt là các phương pháp cắt tỉa bộ lọc và cắt tỉa kênh, đã đạt được kết quả truyền cảm hứng, vẫn tồn tại hai vấn đề.

Thứ nhất, thiết lập tỷ lệ cắt tỉa là một vấn đề cơ bản. Tính dư thừa của các lớp tích chập khác nhau là khác nhau, nhưng nhiều phương pháp cắt tỉa [27]–[29] bỏ qua điều này và đặt cùng tỷ lệ cắt tỉa cho tất cả các lớp, có thể không tạo ra cấu trúc cắt tỉa phù hợp. Để phân bổ các tỷ lệ cắt tỉa khác nhau cho các lớp khác nhau, một số công trình [11], [30] đặt một ngưỡng chỉ số toàn cục cố định, và phân biệt các bộ lọc quan trọng dựa trên các chỉ số quan trọng tương ứng. Tuy nhiên, khi được đưa ra một tỷ lệ nén mục tiêu, ngưỡng cần được đặt bằng thử và sai. Hơn nữa, ngưỡng toàn cục không phù hợp cho tất cả các lớp do sự phân bố khác nhau của các giá trị chỉ số trong mỗi lớp. Nhưng việc thiết lập thủ công các ngưỡng khác nhau cho từng lớp đòi hỏi nhiều chi phí lao động hơn và gây ra sự phân bố tỷ lệ cắt tỉa dưới tối ưu.

Bằng cách làm cho các ngưỡng chỉ số của từng lớp có thể học được, tái tham số hóa ngưỡng mềm (STR) [31] có thể tự động đặt ngưỡng cho từng lớp và có được sự phân bố tỷ lệ cắt tỉa tốt hơn. Việc học các ngưỡng trong STR được kiểm soát bởi mất mát nhiệm vụ và điều chỉnh suy giảm trọng số. Tuy nhiên, bằng cách điều chỉnh hệ số suy giảm trọng số, STR không thể kiểm soát rõ ràng các ngưỡng để làm cho mạng đã cắt tỉa chính xác đạt được tỷ lệ nén mục tiêu. Để kiểm soát rõ ràng mạng đã cắt tỉa đáp ứng FLOPs mục tiêu, một số nghiên cứu khác [32], [33] giới thiệu các ràng buộc FLOPs để hướng dẫn việc học cấu trúc đã cắt tỉa. Để biểu diễn cấu trúc đã cắt tỉa, họ kết hợp một tham số có thể học được bổ sung

--- TRANG 2 ---
CÔNG TRÌNH NÀY ĐÃ ĐƯỢC GỬI ĐẾN IEEE ĐỂ XEM XÉT XUẤT BẢN. BẢN QUYỀN CÓ THỂ ĐƯỢC CHUYỂN GIAO MÀ KHÔNG CẦN THÔNG BÁO, SAU ĐÓ PHIÊN BẢN NÀY CÓ THỂ KHÔNG CÒN TRUY CẬP ĐƯỢC. 2

Hình 1. Tổng quan về phương pháp của chúng tôi. Ở đây, để ngắn gọn, các lớp chuẩn hóa theo lô (BN) và các lớp kích hoạt phi tuyến đã được bỏ qua. Trước khi huấn luyện từ đầu, mỗi lớp tích chập sẽ được cắt tỉa trong CNN cơ sở được thay thế bằng mô-đun thưa thớt với bù đắp đường tránh để xây dựng SBCNet. Sau đó SBCNet được huấn luyện và nén với các mặt nạ bằng chiến lược cắt tỉa được đề xuất. Sau khi đạt được tỷ lệ nén mục tiêu, các mặt nạ thưa thớt nhị phân được loại bỏ, SBCNet được chuyển đổi thành mạng nén, và sau đó mạng nén được huấn luyện cho các epochs còn lại.

cho mỗi kênh trong mỗi lớp để tạo thành một cổng có thể vi phân. Bằng cách sử dụng các ràng buộc FLOPs, họ có thể tiến bộ và tự động phân bổ tỷ lệ cắt tỉa khác nhau cho từng lớp trong quá trình huấn luyện dựa trên FLOPs mục tiêu. Tuy nhiên, họ giới thiệu quá nhiều tham số có thể học được bổ sung, khiến việc tối ưu hóa cấu trúc đã cắt tỉa trở nên khó khăn.

Thứ hai, thiết lập tỷ lệ cắt tỉa tự động không thể khám phá tỷ lệ cắt tỉa cao cho một lớp cụ thể. Hầu hết các phương pháp cắt tỉa [11], [32], [34], [35] cố gắng xác định các bộ lọc hoặc kênh ít quan trọng nhất có thể để giảm mất mát thông tin sau khi cắt tỉa, và sau đó đơn giản là loại bỏ chúng. Tuy nhiên, khi tỷ lệ cắt tỉa ngày càng cao, các lớp đã cắt tỉa mất ngày càng nhiều thông tin và dung lượng. Đặc biệt, khi tỷ lệ cắt tỉa được đặt rất cao, những lớp đã cắt tỉa quá hẹp này có sức mạnh biểu đạt hạn chế và có thể chặn sự lan truyền của các đặc trưng và gradient, có thể khiến mạng đã cắt tỉa khó khôi phục hiệu suất ngay cả sau một thời gian dài huấn luyện hoặc tinh chỉnh.

Để giải quyết các vấn đề trên, trong bài báo này, chúng tôi đề xuất một khung Cắt tỉa Tiến bộ Thích ứng Theo Lớp (LAPP) mới, bao gồm thiết kế mô-đun và chiến lược cắt tỉa. Một tổng quan về phương pháp của chúng tôi được hiển thị trong Hình 1. Để giải quyết vấn đề thứ nhất ở trên, tức là vấn đề thiết lập tỷ lệ cắt tỉa, chiến lược cắt tỉa của chúng tôi lấy các ngưỡng chỉ số làm tham số có thể học được và giới thiệu các ràng buộc FLOPs để kiểm soát việc cập nhật chúng. Cụ thể, chúng tôi sử dụng chuẩn ℓ1 làm chỉ số quan trọng của bộ lọc. Chúng tôi giới thiệu một ngưỡng có thể học được cho mỗi lớp để phân biệt tầm quan trọng giữa các bộ lọc, tránh giới thiệu quá nhiều tham số có thể học được bổ sung. Trong quá trình huấn luyện, được hướng dẫn bởi cả mất mát nhiệm vụ và các ràng buộc FLOPs, các ngưỡng có thể học được được cập nhật một cách động để phù hợp với những thay đổi của chuẩn bộ lọc. Theo kích thước tương đối giữa các ngưỡng và chuẩn bộ lọc, phương pháp của chúng tôi có thể tiến bộ tự động phân biệt các bộ lọc quan trọng và xác định tỷ lệ cắt tỉa phù hợp cho từng lớp trong mỗi lần lặp cho đến khi đạt được tỷ lệ nén mục tiêu, giúp tiết kiệm đáng kể chi phí thử nghiệm.

Để giải quyết vấn đề thứ hai nói trên, trước khi huấn luyện bắt đầu, bằng cách giới thiệu một đường tránh nhẹ bổ sung cho lớp tích chập (tức là đường thưa thớt) sẽ được cắt tỉa trong mạng cơ sở, chúng tôi thiết kế một mô-đun Thưa thớt với Bù đắp Đường tránh, được gọi là mô-đun SBC, và xây dựng SBCNet, như được hiển thị trong Hình 2. Sau đó chúng tôi chỉ tiến bộ cắt tỉa các đường thưa thớt và giữ các đường tránh trong suốt quá trình huấn luyện để bù đắp cho các đường thưa thớt. Do đó, ngay cả khi đường thưa thớt trở nên rất hẹp, mô-đun SBC vẫn có thể có sức mạnh biểu đạt mạnh và đảm bảo sự lan truyền của các đặc trưng và gradient. Trong bài báo này, để làm cho đường tránh nhẹ có đủ sức mạnh biểu đạt, cuối cùng chúng tôi sử dụng khối lấy cảm hứng từ MobileNetV2 [36] làm đường tránh. Cụ thể, khối tuần tự chứa ba lớp tích chập nhỏ: tích chập 1×1, tích chập theo chiều sâu, và tích chập 1×1.

Cuối cùng nhưng không kém phần quan trọng, chiến lược cắt tỉa của chúng tôi là một thuật toán cắt tỉa trong quá trình huấn luyện. Cụ thể, chiến lược cắt tỉa của chúng tôi chỉ chiếm vài epochs trong giai đoạn đầu của quá trình huấn luyện để cắt tỉa mạng dần dần, và sau đó tiếp tục huấn luyện mạng đã cắt tỉa đáp ứng tỷ lệ nén mục tiêu cho các epochs còn lại. Do đó, chiến lược cắt tỉa của chúng tôi có thể giảm đáng kể gánh nặng tiền huấn luyện của các phương pháp cắt tỉa sau huấn luyện [32], [37], [38] và tạo ra các mạng con hiệu quả với độ suy giảm độ chính xác ít hơn so với các phương pháp cắt tỉa tại khởi tạo [11].

Để chứng minh hiệu quả của phương pháp chúng tôi, chúng tôi tiến hành thí nghiệm trên hai tập dữ liệu phân loại ảnh phổ biến với một số cấu trúc mạng đại diện. So với các phương pháp tiên tiến, LAPP đạt được hiệu suất vượt trội. Ví dụ, chúng tôi đạt được giảm 59,7% FLOPs bằng cách loại bỏ 52,8% tham số mà không giảm độ chính xác trên ResNet-20 so với cơ sở. So với cơ sở, 55,6% FLOPs của ResNet-18 được giảm với 0,21% tăng độ chính xác top-1 và 0,40% tăng độ chính xác top-5 trên ImageNet.

--- TRANG 3 ---
CÔNG TRÌNH NÀY ĐÃ ĐƯỢC GỬI ĐẾN IEEE ĐỂ XEM XÉT XUẤT BẢN. BẢN QUYỀN CÓ THỂ ĐƯỢC CHUYỂN GIAO MÀ KHÔNG CẦN THÔNG BÁO, SAU ĐÓ PHIÊN BẢN NÀY CÓ THỂ KHÔNG CÒN TRUY CẬP ĐƯỢC. 3

Những đóng góp chính của chúng tôi được tóm tắt như sau:
(a) Kết hợp các ngưỡng có thể học được và các ràng buộc FLOPs, chúng tôi thiết kế một chiến lược cắt tỉa hiệu quả và hiệu quả có thể cắt tỉa mạng dần dần trong quá trình huấn luyện từ đầu và tự động xác định tỷ lệ cắt tỉa phù hợp cho từng lớp.

(b) Bằng cách giới thiệu một đường tránh bổ sung cho mỗi lớp tích chập, phương pháp của chúng tôi có thể bù đắp thông tin mất mát của lớp đã cắt tỉa và đảm bảo luồng thông tin của mạng hẹp đã cắt tỉa trong quá trình huấn luyện, từ đó có thể khám phá tỷ lệ cắt tỉa cao cho một lớp cụ thể.

(c) Phương pháp của chúng tôi có thể được áp dụng cho nhiều CNNs khác nhau, như VGG [1], ResNet [2], GoogleNet [39], và DenseNet [40], và đạt được hiệu suất tiên tiến trên những mạng đó, cho thấy tính hiệu quả của nó.

Phần còn lại của bài báo được tổ chức như sau. Trong Phần II, chúng tôi giới thiệu công trình liên quan. Trong Phần III, chúng tôi cung cấp mô tả chi tiết về phương pháp của chúng tôi. Sau đó trong Phần IV, chúng tôi tiến hành thí nghiệm trên hai tập dữ liệu phân loại ảnh phổ biến với các loại CNNs khác nhau và so sánh kết quả với những phương pháp tiên tiến. Cuối cùng, chúng tôi kết luận trong Phần V.

II. CÔNG TRÌNH LIÊN QUAN

A. Cắt tỉa để Nén Mạng

Quy trình Cắt tỉa. Tùy thuộc vào thời điểm cắt tỉa được thực hiện, hầu hết các phương pháp cắt tỉa có thể được chia thành ba loại [34]: 1) cắt tỉa sau huấn luyện, 2) cắt tỉa tại khởi tạo, 3) cắt tỉa trong quá trình huấn luyện. Các phương pháp cắt tỉa sau huấn luyện [9], [25], [32], [35], [37], [38], [41] thường áp dụng quy trình ba giai đoạn, cụ thể là tiền huấn luyện dày đặc, cắt tỉa, và tinh chỉnh, để nén mạng. Do tiền huấn luyện các mạng có quá nhiều tham số và tinh chỉnh các mạng đã cắt tỉa, các phương pháp cắt tỉa sau huấn luyện thường tạo ra các mạng con hiệu quả với độ chính xác hợp lý, nhưng dẫn đến gánh nặng huấn luyện lớn. Khác với các phương pháp cắt tỉa sau huấn luyện, các phương pháp cắt tỉa tại khởi tạo [11], [42]–[44] là quy trình huấn luyện hai giai đoạn, cụ thể là cắt tỉa mạng được khởi tạo ngẫu nhiên và sau đó huấn luyện mạng đã cắt tỉa từ đầu, giúp tránh đáng kể gánh nặng tiền huấn luyện. Tuy nhiên, các phương pháp hiện tại vẫn còn không thỏa mãn vì các mạng đã cắt tỉa kết quả có thể khó huấn luyện [43] và dễ bị suy giảm độ chính xác đáng kể.

Các phương pháp cắt tỉa trong quá trình huấn luyện [34], [45], [46] nhằm kết hợp lợi ích của hai chiến lược trên. Các phương pháp cắt tỉa trong quá trình huấn luyện có thể được chia thành hai hướng [34]: các phương pháp dựa trên điều chỉnh [45], [30] và các phương pháp lựa chọn vé phụ [34], [46]. Tương tự như các phương pháp cắt tỉa sau huấn luyện, các phương pháp dựa trên điều chỉnh cũng áp dụng quy trình ba giai đoạn, cụ thể là huấn luyện với điều chỉnh tính thưa thớt, cắt tỉa, và tinh chỉnh nhẹ. Các phương pháp dựa trên điều chỉnh dành ít thời gian hơn cho việc tinh chỉnh mạng đã cắt tỉa, nhưng quá trình huấn luyện dưới điều chỉnh tính thưa thớt vẫn gây ra gánh nặng tính toán đáng kể. Các phương pháp lựa chọn vé phụ lựa chọn cấu trúc mạng đã cắt tỉa thông qua một số chỉ số quan trọng khi thực hiện cắt tỉa, nhưng thường dựa vào một số kinh nghiệm hoặc giả định để thiết lập các điểm bắt đầu một cách suy đoán của việc cắt tỉa trong quá trình huấn luyện bình thường. Khác với các phương pháp lựa chọn vé phụ trước đây, dựa trên các ngưỡng chỉ số có thể học được, việc cắt tỉa trong chiến lược cắt tỉa của chúng tôi được tự động bắt đầu trong quá trình huấn luyện. Khác với các phương pháp dựa trên điều chỉnh trước đây, chiến lược cắt tỉa của chúng tôi chỉ chiếm vài epochs trong giai đoạn đầu của quá trình huấn luyện để cắt tỉa mạng tiến bộ, và sau đó giảm nhiều gánh nặng huấn luyện hơn bằng cách huấn luyện mạng đã cắt tỉa cho các epochs còn lại.

Chỉ số Cắt tỉa. Các chỉ số cắt tỉa được sử dụng để đo lường tầm quan trọng hoặc tính dư thừa của các bộ lọc (hoặc kênh). Tùy thuộc vào việc chúng có giới thiệu tham số có thể học được bổ sung hay không, các chỉ số cắt tỉa của một số phương pháp cắt tỉa có cấu trúc đại diện có thể được nhóm thô vào hai loại. Các chỉ số cắt tỉa không có tham số bổ sung có thể được chia thành hai loại con: chỉ số độc lập với dữ liệu và chỉ số phụ thuộc vào dữ liệu. Một số công trình [9], [27], [28], [45], [47]–[49] trực tiếp sử dụng các thuộc tính vốn có của bộ lọc, như giá trị chuẩn ℓ1 hoặc chuẩn ℓ2 của bộ lọc và các mối quan hệ giữa các bộ lọc, làm chỉ số cắt tỉa. Dựa trên giả định rằng các bộ lọc có chuẩn nhỏ hơn là ít quan trọng hơn, cắt tỉa bộ lọc cho convnets hiệu quả (PFEC) [9] lựa chọn và loại bỏ các bộ lọc có giá trị chuẩn ℓ1 nhỏ hơn. Cắt tỉa bộ lọc qua trung vị hình học (FPGM) [28] chỉ ra rằng giả định trên không phải lúc nào cũng đúng, và sau đó chuyển sang cắt tỉa các bộ lọc có thể thay thế nhất dựa trên trung vị hình học của các bộ lọc trong mỗi lớp. Xem xét rằng các bộ lọc tương tự là dư thừa, khác với FPGM, cắt tỉa bộ lọc với học gradient thích ứng (FP-AGL) [49] áp dụng các vector hướng tâm được thiết kế lại trên các bộ lọc để hội tụ các bộ lọc trong các cụm về cùng một điểm, và cuối cùng chỉ giữ lại một bộ lọc mỗi cụm. Một số công trình [30], [50] tận dụng các hệ số tỷ lệ trong các lớp chuẩn hóa theo lô (BN) để đánh giá tầm quan trọng của các kênh. Làm mảnh mạng (NS) [30] đẩy các hệ số tỷ lệ trong các lớp BN về không bằng cách áp dụng điều chỉnh ℓ1 trong quá trình huấn luyện, và cắt tỉa các kênh có hệ số tỷ lệ nhỏ sau khi huấn luyện. Các chỉ số trên là độc lập với dữ liệu, vì vậy những công trình này yêu cầu chi phí tính toán thấp để xác định các bộ lọc (hoặc kênh) đã cắt tỉa.

Ngoài ra, một số chỉ số cắt tỉa yêu cầu sử dụng dữ liệu đầu vào để lựa chọn các bộ lọc (hoặc kênh) đã cắt tỉa. Bản đồ đặc trưng đầu ra là kết quả tích chập của bản đồ đặc trưng đầu vào và bộ lọc, vì vậy một số nghiên cứu [26], [29], [51] xác định các bộ lọc đã cắt tỉa bằng cách đánh giá tầm quan trọng hoặc tính dư thừa của bản đồ đặc trưng từ một tập dữ liệu đầu vào. Hạng cao (Hrank) [26] sử dụng hạng trung bình của bản đồ đặc trưng để đánh giá tầm quan trọng của bộ lọc. Khác với Hrank, cắt tỉa bộ lọc dựa trên độc lập kênh (CHIP) [51] tìm các bản đồ đặc trưng dư thừa và cắt tỉa các bộ lọc tương ứng bằng cách đo lường các mối tương quan giữa các bản đồ đặc trưng trong mỗi lớp. Xem xét rằng các bộ lọc được cập nhật bằng gradient từ hàm mất mát trong quá trình huấn luyện, một số nghiên cứu [35], [41] đếm gradient hoặc thông tin đạo hàm bậc hai cho mỗi bộ lọc (hoặc kênh) để đánh giá tầm quan trọng. Cắt tỉa kênh nhận thức phân biệt (DCP) [41] chọn các kênh quan trọng nhất bằng cách tính chuẩn Frobenius của các gradient. Cắt tỉa có cấu trúc bậc hai (SOSP) [35] thiết kế hai chỉ số cắt tỉa dựa trên sự nổi bật, sử dụng thông tin đạo hàm bậc một hoặc bậc hai, để xóa các bộ lọc không quan trọng.

Một số công trình [11], [32], [37], [38], [52] giới thiệu các

--- TRANG 4 ---
CÔNG TRÌNH NÀY ĐÃ ĐƯỢC GỬI ĐẾN IEEE ĐỂ XEM XÉT XUẤT BẢN. BẢN QUYỀN CÓ THỂ ĐƯỢC CHUYỂN GIAO MÀ KHÔNG CẦN THÔNG BÁO, SAU ĐÓ PHIÊN BẢN NÀY CÓ THỂ KHÔNG CÒN TRUY CẬP ĐƯỢC. 4

tham số có thể học được bổ sung và tối ưu hóa những tham số này bằng cách tận dụng các thuật toán học tăng cường hoặc các phương pháp dựa trên gradient, để tạo ra điểm số nổi bật hoặc quyết định nhị phân cho mỗi kênh (hoặc bộ lọc). Nén sâu với học tăng cường (DECORE) [38] gán một tác nhân chỉ có một tham số cho mỗi kênh và học kênh nào sẽ được cắt tỉa dựa trên học tăng cường. Cho mỗi mẫu đầu vào, cháy cùng nhau dây cùng nhau (FTWT) [52] sử dụng một đầu dự đoán mặt nạ nhị phân được huấn luyện tốt trong mỗi lớp để dự đoán động k bộ lọc được kích hoạt.

B. Kết hợp Cắt tỉa và Các Kỹ thuật Khác để Nén Mạng

Cắt tỉa và Phân rã Tensor Hạng thấp. Phân rã tensor hạng thấp (LTD) [13] phân rã tensor trọng số hạng thấp của phép tích chập thành một chuỗi các tensor chứa ít tham số và phép tính hơn nhiều. Vì cắt tỉa và LTD giảm tính dư thừa trong các tham số từ các góc độ khác nhau, một số nỗ lực gần đây [53]–[55] kết hợp chúng với nhau để theo đuổi hiệu suất nén mạng tốt hơn. Li et al. [55] đề xuất gắn các ma trận cảm ứng tính thưa thớt vào các phép tích chập thông thường và áp dụng các ràng buộc tính thưa thớt nhóm lên chúng, để móc nối cắt tỉa bộ lọc và phân rã (Hinge). Bằng cách đồng thời xử lý tính thưa thớt và tính hạng thấp trong trọng số, nén hợp tác (CC) [54] kết hợp cắt tỉa kênh và phân rã tensor để tăng tốc CNNs.

Cắt tỉa và Lượng tử hóa Bit thấp. Lượng tử hóa bit thấp [17]–[19] có thể giảm hiệu quả chi phí tính toán và lưu trữ bằng cách giảm số bit được sử dụng để biểu diễn trọng số hoặc kích hoạt của mạng. Lượng tử hóa là trực giao với cắt tỉa, vì vậy một số công trình [56]–[58] thực hiện chúng cùng nhau để đạt được tăng tốc mạng tốt hơn. Wang et al. [56] đề xuất tích hợp cắt tỉa có cấu trúc với lượng tử hóa độ chính xác hỗn hợp thông qua một sơ đồ tối ưu hóa dựa trên gradient chung. Luồng Rời rạc Chỉ số nguyên (IODF) [58] thực hiện các phép biến đổi khả nghịch hiệu quả bằng cách sử dụng số học chỉ số nguyên dựa trên lượng tử hóa 8-bit và giới thiệu các cổng nhị phân có thể học được để loại bỏ các bộ lọc dư thừa trong quá trình suy luận.

Cắt tỉa và Chưng cất Kiến thức. Chưng cất kiến thức (KD) [15] chuyển giao kiến thức từ một mạng giáo viên lớn sang một mạng học sinh nhỏ. Gần đây, một số công trình khai thác KD để tăng cường khả năng học của các mạng đã cắt tỉa [59], [60] hoặc khai thác cắt tỉa để tăng cường chất lượng KD [61], [62]. Để bảo toàn hiệu suất của mô hình đã cắt tỉa, Zou et al. [60] đề xuất chưng cất mô hình đã cắt tỉa để phù hợp với mô hình đã được tiền huấn luyện bằng cách sử dụng các hình ảnh bị giảm chất lượng được tái tạo. Để tăng cường hiệu suất của KD, Park và No [62] đề xuất cắt tỉa mạng giáo viên trước để làm cho nó thân thiện hơn với học sinh và sau đó chưng cất nó cho học sinh.

Các công trình trên tiếp tục cho thấy rằng cắt tỉa và các kỹ thuật khác là bổ sung. Do đó, việc kết hợp chúng có thể cải thiện hiệu suất nén hơn nữa.

III. PHƯƠNG PHÁP ĐỀ XUẤT

Trong phần này, chúng tôi giới thiệu khung và quy trình nén của phương pháp đề xuất.

Hình 2. Các mô-đun SBC 3×3 trong SBCNet. Ở đây đường tránh là khối lấy cảm hứng từ MobileNetV2 [36]. "DWConv" biểu thị một phép tích chập theo chiều sâu, và tất cả các lớp BN và lớp kích hoạt phi tuyến được bỏ qua.

A. Sơ bộ

Đối với lớp thứ l của một CNN, chúng tôi biểu thị bản đồ đặc trưng đầu vào là Xl∈Rcl−1×hl−1×wl−1, bản đồ đặc trưng đầu ra là Yl∈Rcl×hl×wl, và tensor trọng số của các bộ lọc là Wl∈Rcl×cl−1×kl×kl, trong đó cl−1 và cl lần lượt là số kênh đầu vào và bộ lọc (kênh đầu ra), và kl là kích thước kernel của các bộ lọc. Đầu ra của lớp tích chập thứ l có thể được biểu diễn như sau:

Yl=Wl⊗Xl, (1)

trong đó ⊗ biểu thị phép tích chập.

Cắt tỉa Có cấu trúc. Cả cắt tỉa bộ lọc và cắt tỉa kênh đều tìm kiếm một biểu diễn xấp xỉ nhỏ gọn Wl. Trong cắt tỉa bộ lọc, mỗi bộ lọc được coi là một đơn vị nén và hàm cắt tỉa được định nghĩa là:

Wl[i,:,:,:] =Wl[Klf[i],:,:,:] (2)

trong đó Wl∈Rnl×cl−1×kl×kl và Klf biểu thị một danh sách bao gồm các chỉ số của các bộ lọc được giữ lại trong Wl. Ở đây nl là số bộ lọc được giữ lại. Trong cắt tỉa kênh, mỗi kênh đầu vào được coi là một đơn vị nén và hàm cắt tỉa được định nghĩa là:

Wl[:, i,:,:] =Wl[:, Klc[i],:,:] (3)

trong đó Wl∈Rcl×nl−1×kl×kl và Klc biểu thị một danh sách bao gồm các chỉ số của các kênh đầu vào được giữ lại trong Wl. Ở đây nl−1 là số kênh đầu vào được giữ lại.

Trong bài báo này, chúng tôi giới thiệu phương pháp cắt tỉa của mình từ góc độ cắt tỉa bộ lọc, nhưng lưu ý rằng nó cũng phù hợp cho cắt tỉa kênh. Trong phần tiếp theo, để ngắn gọn, chúng tôi thay thế Wl[i,:,:,:] bằng Wl[i].

B. Thiết kế Mô-đun

Trước tiên chúng tôi thiết kế một mô-đun thưa thớt với bù đắp đường tránh, được gọi là mô-đun SBC, và sau đó thay thế mỗi lớp tích chập sẽ được cắt tỉa trong mạng cơ sở bằng mô-đun SBC để xây dựng SBCNet. Mô-đun SBC bao gồm một đường thưa thớt (tức là lớp tích chập gốc) và một đường tránh nhẹ, và đầu ra của mô-đun SBC là tổng của

--- TRANG 5 ---
CÔNG TRÌNH NÀY ĐÃ ĐƯỢC GỬI ĐẾN IEEE ĐỂ XEM XÉT XUẤT BẢN. BẢN QUYỀN CÓ THỂ ĐƯỢC CHUYỂN GIAO MÀ KHÔNG CẦN THÔNG BÁO, SAU ĐÓ PHIÊN BẢN NÀY CÓ THỂ KHÔNG CÒN TRUY CẬP ĐƯỢC. 5

Hình 3. Quy trình của chiến lược cắt tỉa cho mô-đun SBC thứ l. Ở đây STE biểu thị bộ ước lượng thẳng. Đối với mô-đun SBC thứ l, trong quá trình lan truyền tiến, chuẩn ℓ1 được sử dụng để tính điểm quan trọng Il của trọng số bộ lọc WlS trong đường thưa thớt, và sau đó sự khác biệt giữa điểm quan trọng Il và ngưỡng có thể học được δl được đưa vào hàm round (sigmoid (·)) để có được mặt nạ nhị phân Ml. Đầu ra của đầu vào Xl qua lớp tích chập được nhân với mặt nạ Ml để có được đầu ra YlS trong đường thưa thớt. Sau đó đầu ra YlS của đường thưa thớt và đầu ra YlB của đường tránh được cộng lại để có được đầu ra cuối cùng Yl. Trong quá trình lan truyền ngược, ngưỡng có thể học được δl và trọng số bộ lọc WlS và WlB được cập nhật bằng hướng dẫn từ các gradient của tổng mất mát. Lưu ý rằng để ổn định việc huấn luyện nén và không can thiệp vào việc học WlS, sự lan truyền gradient từ Gl đến WlS bị cắt đứt, và các gradient từ Gl chỉ được sử dụng để hướng dẫn việc cập nhật ngưỡng δl.

đầu ra của lớp tích chập gốc và đường tránh nhẹ. Do đó, SBCNet thêm một ít gánh nặng bổ sung so với mạng cơ sở. Một ví dụ cho mô-đun SBC 3×3 được hiển thị trong Hình 2. Trong bài báo này, chúng tôi sử dụng khối lấy cảm hứng từ MobileNetV2 [36] làm đường tránh để làm cho nó có đủ sức mạnh biểu đạt. Ngoài ra, cấu trúc của khối có thể thu được bằng cách áp dụng LTD cho một phép tích chập thông thường [14], vì vậy việc sử dụng khối làm đường tránh cũng có thể làm cho mô-đun SBC khai thác tính bổ sung của cắt tỉa và LTD để cải thiện hiệu suất của phương pháp chúng tôi hơn nữa. Đối với mô-đun SBC thứ l, đầu ra được biểu diễn như sau:

Yl=YlS+YlB=WlS⊗Xl+WlB3⊗(WlB2⊗(WlB1⊗Xl)),(4)

trong đó WlS∈Rcl×cl−1×kl×kl biểu thị tensor trọng số của đường thưa thớt, trong khi WlB1∈Rdl×cl−1×1×1, WlB2∈Rdl×1×kl×kl, và WlB3∈Rcl×dl×1×1 biểu thị các tensor trọng số của đường tránh nhẹ.

Đối với đường thưa thớt, WlS được khởi tạo ngẫu nhiên trước khi huấn luyện, và được làm thưa thớt bằng một mặt nạ bằng chiến lược cắt tỉa được đề xuất trong quá trình huấn luyện cho đến khi đạt được tỷ lệ nén mục tiêu. Các giải thích chi tiết về chiến lược cắt tỉa được đề xuất được đưa ra trong tiểu mục sau.

Đối với đường tránh nhẹ, ba phép tích chập nhẹ được giữ trong suốt quá trình huấn luyện để bù đắp cho đường thưa thớt. Giả sử bước nhảy của các phép tích chập trong mô-đun thứ l là 1, cl và cl−1 bằng nhau, và tỷ lệ cắt tỉa được phân bổ thích ứng bằng chiến lược cắt tỉa của chúng tôi trong đường thưa thớt là pl. Để ngắn gọn, chúng tôi bỏ qua chỉ số trên. Sau khi cắt tỉa, FLOPs của đường tránh là hw(2cd+dk2), và FLOPs của mô-đun SBC là hw(2cd+dk2+ (1−p)c2k2). Nói chung, k2≪c và d≤c, chúng ta có thể bỏ qua hạng tử dk2. Do đó tỷ lệ FLOPs của chúng là khoảng 2/(2+((1−p)ck2)/d). Khi p là một giá trị nhỏ gần 0, đường thưa thớt đã cắt tỉa chiếm ưu thế trong mô-đun SBC, và đường tránh nhẹ chỉ mang lại tương đối ít phép tính. Khi p là một giá trị trung bình, đường tránh bù đắp thông tin và dung lượng mất mát của đường thưa thớt đã cắt tỉa với chi phí tính toán tương đối nhỏ. Khi p là một giá trị lớn gần 1, đường thưa thớt bị cắt tỉa quá hẹp đến mức nó chặn sự lan truyền tiến của các đặc trưng và lan truyền ngược của các gradient, thường dẫn đến sự giảm mạnh hiệu suất mạng. Tuy nhiên, đường tránh giúp đảm bảo sự lan truyền của các đặc trưng và gradient trong quá trình huấn luyện để làm cho mạng hội tụ bình thường.

Trong trường hợp cực đoan, khi p là 1, toàn bộ đường thưa thớt có thể được loại bỏ một cách mượt mà trong quá trình cắt tỉa do đường tránh, đạt được tăng tốc xấp xỉ ck2/(2d)×, và đường tránh làm cho mô-đun vẫn duy trì sức mạnh biểu đạt tương đối mạnh. Tuy nhiên, điều này không có nghĩa là việc trực tiếp xây dựng một mạng nhỏ gọn sử dụng đường tránh thay vì mô-đun SBC trước khi huấn luyện bắt đầu sẽ hiệu quả hơn. Bởi vì như đã đề cập ở trên, một số mô-đun cần giữ lại một số kênh của đường thưa thớt để bù đắp cho đường tránh nhẹ của chúng nhằm duy trì đủ dung lượng. Sự hiện diện của đường thưa thớt có thể tăng sự đa dạng của các đặc trưng. Ngoài ra, chúng có thể hoạt động như các đường tắt để tạo thuận lợi cho luồng thông tin, và việc cắt tỉa SBCNet dày đặc trong quá trình huấn luyện có thể giúp tìm kiếm một mạng con tốt hơn.

Hơn nữa, bằng cách điều chỉnh siêu tham số dl, tỷ lệ FLOPs của đường tránh so với FLOPs của mô-đun SBC đã cắt tỉa có thể được kiểm soát một cách thô. Do đó, bằng cách đặt giá trị phù hợp cho dl, chúng ta có thể đạt được mục tiêu nén và làm cho đường tránh tạo ra đủ bù đắp cho đường thưa thớt để đạt được hiệu suất nén tốt hơn. Trong bài báo này, khi tỷ lệ nén mục tiêu toàn cục được đặt thành một giá trị lớn, dl được đặt theo kinh nghiệm trực tiếp thành cl; khi tỷ lệ nén mục tiêu toàn cục được đặt thành một giá trị rất nhỏ, dl được giảm xuống 0,5cl.

C. Chiến lược Cắt tỉa

Cắt tỉa sau huấn luyện là một chiến lược cắt tỉa thường được sử dụng. Tuy nhiên, quy trình ba giai đoạn của nó, cụ thể là tiền huấn luyện dày đặc, cắt tỉa, và tinh chỉnh, dẫn đến thời gian huấn luyện gần như gấp đôi.

--- TRANG 6 ---
CÔNG TRÌNH NÀY ĐÃ ĐƯỢC GỬI ĐẾN IEEE ĐỂ XEM XÉT XUẤT BẢN. BẢN QUYỀN CÓ THỂ ĐƯỢC CHUYỂN GIAO MÀ KHÔNG CẦN THÔNG BÁO, SAU ĐÓ PHIÊN BẢN NÀY CÓ THỂ KHÔNG CÒN TRUY CẬP ĐƯỢC. 6

Do tính không hiệu quả của nó, một giải pháp trực quan là cắt tỉa tại khởi tạo. Mặc dù cắt tỉa tại khởi tạo làm cho việc huấn luyện hiệu quả hơn vì nó chỉ huấn luyện mạng đã cắt tỉa, các mạng đã cắt tỉa có thể khó huấn luyện và dễ bị suy giảm độ chính xác đáng kể. Do đó, cắt tỉa trong quá trình huấn luyện, có thể giảm các hiệu ứng tiêu cực của cắt tỉa sau huấn luyện và cắt tỉa tại khởi tạo, có thể tìm ra sự cân bằng giữa hiệu quả huấn luyện và độ chính xác cuối cùng [34]. Vì vậy chiến lược cắt tỉa của chúng tôi cũng dần dần cắt tỉa các đường thưa thớt trong quá trình huấn luyện ban đầu vài epochs, và khai thác số lượng lớn epochs còn lại để huấn luyện mạng đã cắt tỉa để hội tụ nhằm cải thiện hiệu suất. Quy trình của chiến lược cắt tỉa cho mô-đun thứ l được hiển thị trong Hình 3.

Cụ thể, trong bài báo này, để đơn giản, chúng tôi sử dụng chuẩn ℓ1 làm chỉ số quan trọng của bộ lọc. Do đó điểm quan trọng bộ lọc Il∈Rcl của đường thưa thớt được biểu diễn như sau:

Il= [∥WlS[1]∥1,∥WlS[2]∥1,···,∥WlS[cl]∥1]T, (5)

trong đó mỗi phần tử biểu thị tầm quan trọng của bộ lọc tương ứng. Khác với PFEC [9] trực tiếp đặt thủ công tỷ lệ cắt tỉa cho mỗi lớp, chúng tôi sử dụng ngưỡng cắt tỉa để xác định tỷ lệ cắt tỉa cho mỗi lớp. Giả sử ngưỡng cho mô-đun thứ l là δl, sau đó mặt nạ cắt tỉa Ml∈Rcl được thu được theo Il:

Ml[i] = {
1, nếu Ili≥δl,
0, nếu Ili< δl, (6)

trong đó Ili biểu thị phần tử thứ i của Il. Bằng cách cộng mặt nạ Ml, số bộ lọc được giữ lại có thể được thu được, cụ thể là nl, và tỷ lệ cắt tỉa của đường thưa thớt là pl= 1−nl/cl. Đầu ra của đường thưa thớt sau đó được công thức hóa lại như sau:

YlS=Ml⊙(WlS⊗Xl), (7)

trong đó ⊙ là tích theo từng phần tử giữa vector cột bên trái và các chiều không gian của tensor ba chiều bên phải.

Vì phân bố tham số của các lớp khác nhau là khác nhau, việc đặt cùng ngưỡng cắt tỉa cho tất cả các lớp có thể không tối ưu. Tuy nhiên, việc đặt thủ công các ngưỡng khác nhau cho từng lớp đòi hỏi nhiều chi phí lao động và cũng có thể gây ra sự phân bố tỷ lệ cắt tỉa dưới tối ưu. Lấy cảm hứng từ ý tưởng áp dụng ngưỡng có thể học được cho cắt tỉa bộ lọc được đề xuất bởi Kusupati et al. [31], chúng tôi kết hợp chỉ số chuẩn ℓ1 đơn giản với ngưỡng có thể học được bằng cách giới thiệu một tham số có thể học được bổ sung cho mỗi đường thưa thớt của mạng.

Từ Eq.(7), Ml trực tiếp tham gia vào tính toán tiến của mạng và có thể nhận gradient từ hàm mục tiêu trong quá trình lan truyền ngược. Tuy nhiên, theo Eq.(6), ngưỡng δl không thể vi phân. Do đó, chúng tôi thay đổi Ml thành mặt nạ cắt tỉa mềm Gl bằng cách giới thiệu hàm sigmoid (·):

Gl=sigmoid (Il−δl) =1/(1 +e−(Il−δl)). (8)

Ở đây mỗi phần tử của Gl, tức là Gl[i], liên tục và giá trị của nó dao động từ 0 đến 1. Theo các công trình [32], [52], chúng tôi tiếp tục làm tròn Gl[i] về 0 hoặc 1, để tạo ra chính xác các mạng con trong quá trình huấn luyện, như sau:

Ml[i] =1≥0.5(Gl[i]),∀i∈[1, cl]. (9)

Khi giá trị của Gl[i] lớn hơn hoặc bằng 0,5, tức là khi điểm quan trọng bộ lọc tương ứng Ili lớn hơn hoặc bằng ngưỡng δl, giá trị của mặt nạ tương ứng Ml[i] là 1, ngược lại, nó là 0. Tuy nhiên, hàm chỉ thị 1≥0.5(·) vẫn không thể vi phân. Để giải quyết vấn đề này, chúng tôi sử dụng bộ ước lượng thẳng (STE) [63] để tính các gradient từ Ml đến Gl trong quá trình lan truyền ngược, làm cho việc cập nhật δl khả thi.

Thuật toán 1 Tổng quan về phương pháp LAPP.
Đầu vào: CNN với N lớp tích chập sẽ được cắt tỉa; tổng số epochs E; tập huấn luyện D; tổng FLOPs Ttotal của CNN; tỷ lệ nén mục tiêu C;
Đầu ra: CNN nhỏ gọn thỏa mãn tỷ lệ nén mục tiêu C và các giá trị trọng số tối ưu WS và WB;
1: Xây dựng SBCNet với WS và WB dựa trên Eq.(4);
2: Giới thiệu ngưỡng có thể học được cho mỗi đường thưa thớt;
3: Thiết lập trạng thái epoch ∈ {"prune", "train"};
4: trạng thái epoch được đặt là "prune";
5: for epoch t= 1,2, ..., E do
6: for một mini-batch (X, y) trong D do
7: if trạng thái epoch là "prune" then
8: for layer l= 1,2, ..., N do
9: Lấy Il bằng Eq.(5);
10: Lấy Ml bằng Eq.(8) và Eq.(9);
11: Lấy Yl bằng Eq.(7) và Eq.(4);
12: end for
13: Tính Tkept và Ĉ;
14: if Ĉ≠C then
15: Cập nhật WS, WB và Δ với SGD;
16: else
17: Loại bỏ các mặt nạ và cắt tỉa, lấy WS;
18: Đặt trạng thái epoch là "train";
19: end if
20: else
21: Lấy Yl cho mỗi lớp l bằng Eq.(13);
22: Cập nhật WS và WB với SGD;
23: end if
24: end for
25: end for
26: Return: CNN nhỏ gọn với trọng số WS và WB;

Để làm cho các bộ lọc có thể phân biệt hơn, chúng tôi áp dụng điều chỉnh thưa thớt cho trọng số bộ lọc của các đường thưa thớt. Phù hợp với chỉ số quan trọng chuẩn ℓ1, chúng tôi sử dụng điều chỉnh ℓ1, và thu được bài toán tối ưu hóa mạng:

min[WS,WB,Δ] L(f(X;WS,WB,Δ), y) +λ∑[l=1 to N]∑[i=1 to cl]∥WlS[i]∥1, (10)

trong đó L(·) biểu thị mất mát entropy chéo, và WS={W1S, W2S,···, WNS} và WB={W1B, W2B,···, WNB} tham chiếu đến các tham số trong N mô-đun thưa thớt của SBCNet

--- TRANG 7 ---
CÔNG TRÌNH NÀY ĐÃ ĐƯỢC GỬI ĐẾN IEEE ĐỂ XEM XÉT XUẤT BẢN. BẢN QUYỀN CÓ THỂ ĐƯỢC CHUYỂN GIAO MÀ KHÔNG CẦN THÔNG BÁO, SAU ĐÓ PHIÊN BẢN NÀY CÓ THỂ KHÔNG CÒN TRUY CẬP ĐƯỢC. 7

f(·;WS,WB,Δ). Ở đây X và y biểu thị các mẫu đầu vào và nhãn tương ứng, Δ biểu thị tập hợp tất cả các ngưỡng chỉ số có thể học được của các đường thưa thớt của SBCNet, λ là hệ số của hạng tử điều chỉnh ℓ1, và hạng tử điều chỉnh suy giảm trọng số được bỏ qua để ngắn gọn. Do đó, tính thưa thớt tổng thể cuối cùng của các đường thưa thớt của mạng được kiểm soát bởi hệ số của hạng tử điều chỉnh ℓ1 và giá trị ban đầu của các ngưỡng trong Δ. Tuy nhiên, việc điều chỉnh các siêu tham số này bằng thử và sai để đạt được tỷ lệ nén mục tiêu chắc chắn là tẻ nhạt và phức tạp.

Do đó, để kiểm soát rõ ràng tính thưa thớt của mạng, tức là làm cho mạng con cuối cùng đạt được FLOPs mục tiêu đã cho, chúng tôi giới thiệu các ràng buộc FLOPs để kiểm soát việc cập nhật các ngưỡng trong Δ. Trước đây các ràng buộc FLOPs và ngưỡng chỉ số thường được sử dụng riêng biệt, trong khi chúng tôi cố gắng kết hợp ngưỡng có thể học được và ràng buộc FLOPs để tự động xác định tỷ lệ cắt tỉa phù hợp cho mỗi lớp dựa trên tỷ lệ nén mục tiêu trong quá trình huấn luyện.

Khác với STR [31] áp dụng hàm sigmoid (·) cho ngưỡng có thể học được, chúng tôi áp dụng nó cho sự khác biệt giữa điểm quan trọng Il và ngưỡng có thể học được δl, tức là Eq.(8), để kiểm soát phạm vi giá trị của mặt nạ mềm Gl từ 0 đến 1. Ở đây, hàm kích hoạt ReLU (·) được sử dụng trong STR là không cần thiết. Sau đó chúng tôi tiếp tục giới thiệu hàm chỉ thị và STE, tức là Eq.(9), để thu được mặt nạ cắt tỉa nhị phân có thể học được M={M1, M2,···, MN} đặc trưng cho cấu trúc mạng con. Do đó, chúng ta có thể tính chính xác FLOPs Tkept của mạng con tại một lần lặp nhất định bằng các mặt nạ nhị phân M. Giả sử tổng FLOPs của mạng cơ sở là Ttotal, chúng ta có thể thu được tỷ lệ nén Ĉ=Tkept/Ttotal. Lưu ý rằng vì kích thước của SBCNet lớn hơn mạng cơ sở, giá trị ban đầu của Ĉ lớn hơn 1 trước khi huấn luyện bắt đầu. Để kiểm soát các ngưỡng để làm cho mạng con đạt được một cách mượt mà và chính xác FLOPs mục tiêu đã cho CTtotal, trong đó C là tỷ lệ nén mục tiêu, chúng tôi thiết kế một hạng tử điều chỉnh để hạn chế FLOPs, như sau:

R(Ĉ, C) = (Ĉ/C−1)2. (11)

Sau đó bài toán tối ưu hóa của mạng được công thức hóa lại như sau:

min[WS,WB,Δ] L(f(X;WS,WB,Δ), y) +λ1∑[l=1 to N]∑[i=1 to cl]∥WlS[i]∥1+λ2R(Ĉ, C), (12)

trong đó λ1 và λ2 lần lượt là hệ số của hạng tử điều chỉnh ℓ1 và hạng tử điều chỉnh FLOPs. Để kiểm soát các ngưỡng δ một cách linh hoạt và nhanh chóng hơn để nén mạng đến tỷ lệ nén mục tiêu C, điều chỉnh suy giảm trọng số không còn được áp dụng cho các ngưỡng trong Δ.

Bằng các mặt nạ M, việc học các ngưỡng được hướng dẫn cùng nhau bởi mất mát nhiệm vụ L(f(X;WS,WB,Δ), y) và hạng tử điều chỉnh FLOPs R(Ĉ, C). Cụ thể, các ngưỡng được cập nhật bằng hướng dẫn từ các gradient của R(Ĉ, C) để điều khiển mặt nạ thưa thớt cho đến khi mạng con kết quả thỏa mãn FLOPs mục tiêu, trong khi chúng được cập nhật bằng hướng dẫn từ các gradient của L(f(X;WS,WB,Δ), y) để ngăn chặn tính thưa thớt mặt nạ và do đó cải thiện độ chính xác của mạng con kết quả. Do đó, trong quá trình huấn luyện ban đầu vài epochs, các ngưỡng, được học trong cuộc cạnh tranh để duy trì độ chính xác và nén SBCNet đến FLOPs mục tiêu, dẫn đến một mạng con tương đối tốt hơn.

Sau khi đạt được tỷ lệ nén mục tiêu, chúng tôi loại bỏ các mặt nạ thưa thớt nhị phân trên các đường thưa thớt, và chuyển đổi SBCNet thành mạng nén. Theo Ml, chúng ta có thể thu được danh sách chỉ số Klf và tensor trọng số đã cắt tỉa WlS∈Rnl×cl−1×kl×kl trong đường thưa thớt thứ l. Và YlS là đầu ra của đường thưa thớt thứ l. Vì vậy sau khi cắt tỉa, đầu ra của mô-đun SBC thứ l được biểu diễn như sau:

Yl[i] = {
YlS[Pos(i)] +YlB[i], nếu i∈Klf,
YlB[i], nếu i ∉ Klf, (13)

trong đó i∈[1, cl] và hàm Pos (·) trả về vị trí của phần tử i trong Klf. Sau đó, chúng tôi tiếp tục huấn luyện mạng nén cho các epochs còn lại. Cuối cùng chúng ta có thể có được một mạng con với trọng số WS={W1S,W2S,···,WNS} và WB thỏa mãn tỷ lệ nén mục tiêu mà không làm giảm hiệu suất.

Toàn bộ quá trình được tóm tắt trong Thuật toán 1. Lưu ý rằng mặc dù trong bài báo này chúng tôi lấy chuẩn ℓ1 làm chỉ số quan trọng của bộ lọc do tính đơn giản của nó, chiến lược cắt tỉa của chúng tôi cũng có thể được kết hợp với một số chỉ số quan trọng khác của các phương pháp hiện có.

IV. THỰC NGHIỆM

Trong phần này, phương pháp LAPP của chúng tôi được đánh giá trên hai tập dữ liệu phân loại ảnh chuẩn: CIFAR-10 [64] và ImageNet [65]. Chúng tôi so sánh phương pháp của mình với một số phương pháp nén CNN tiên tiến, bao gồm PFEC [9], DECORE [38], Hinge [55], cắt tỉa từ đầu (PFS) [11], CC [54], NS [30], Hrank [26], FTWT [52], SOSP [35], cắt tỉa phân cấp qua biểu diễn hình dạng-cạnh của bản đồ đặc trưng (HPSE) [29], sơ đồ cắt tỉa bộ lọc động và tiến bộ (DPFPS) [45], CHIP [51], tiêu chí cắt tỉa bộ lọc học (LFPC) [47], cắt tỉa mạng qua tối đa hóa hiệu suất (NPPM) [32], FP-AGL [49], cắt tỉa bộ lọc mềm (SFP) [27], FPGM [28], cắt tỉa sử dụng mạng nơ-ron đồ thị và học tăng cường (GNN-RL) [37], và DCP [41]. Tất cả các phương pháp so sánh được áp dụng trên các mô hình CNN chính thống, bao gồm VGG [1], ResNet [2], GoogleNet [39], và DenseNet [40]. Chúng tôi tiến hành thí nghiệm toàn diện với Pytorch [66] để cho thấy rằng LAPP vượt trội hoặc tương đương với các phương pháp trên.

A. Tập dữ liệu và Cài đặt Thí nghiệm

Tập dữ liệu. Tập dữ liệu CIFAR-10 chứa 60.000 hình ảnh màu với kích thước 32×32 trong 10 lớp, và mỗi lớp bao gồm 6.000 hình ảnh, 5.000 trong số đó nằm trong tập huấn luyện và phần còn lại trong tập kiểm tra. Theo [26], đối với tập huấn luyện, chúng tôi đệm 4 pixel với số không ở mỗi bên của một hình ảnh, sau đó cắt ngẫu nhiên một mẫu 32×32 từ hình ảnh được đệm, và cuối cùng lật ngẫu nhiên hình ảnh đã cắt theo chiều ngang với xác suất 0,5. Đối với tập kiểm tra, chúng tôi trực tiếp sử dụng các

--- TRANG 8 ---
CÔNG TRÌNH NÀY ĐÃ ĐƯỢC GỬI ĐẾN IEEE ĐỂ XEM XÉT XUẤT BẢN. BẢN QUYỀN CÓ THỂ ĐƯỢC CHUYỂN GIAO MÀ KHÔNG CẦN THÔNG BÁO, SAU ĐÓ PHIÊN BẢN NÀY CÓ THỂ KHÔNG CÒN TRUY CẬP ĐƯỢC. 8

BẢNG I
KẾT QUẢ NÉN CỦA VGG-16 TRÊN CIFAR-10.

Phương pháp Top-1(%) FLOPs ↓(%) Params ↓(%)
Baseline 93.96 0.0 0.0
PFEC [9] 93.40 34.2 64.0
DECORE [38] 94.02 35.3 63.0
Hinge [55] 94.02 39.1 80.1
PFS [11] 93.63±0.06 50.0 —
CC [54] 94.15 50.8 65.9
NS [30] 93.80 51.0 88.5
Hrank [26] 93.43 53.5 82.9
Của chúng tôi (C=0.46) 94.32±0.20 53.6 73.0
FTWT [52] 93.73 56.0 —
SOSP [35] 93.73±0.16 57.7 87.3
CC [54] 94.09 60.7 72.7
DECORE [38] 93.56 64.8 89.0
Hrank [26] 92.34 65.3 82.1
Của chúng tôi (C=0.34) 94.36±0.08 65.7 74.3
HPSE [29] 93.50 66.1 —
DPFPS [45] 93.52±0.15 70.9 93.3
Của chúng tôi (C=0.26) 93.79±0.16 73.8 85.2
Hrank [26] 91.23 76.5 92.0
CHIP [51] 93.18 78.6 87.3
DECORE [38] 92.44 81.5 96.6
Của chúng tôi (C=0.18) 93.54±0.23 81.9 86.1
HPSE [29] 92.49 82.0 —

hình ảnh 32×32 gốc. Cả hình ảnh huấn luyện và kiểm tra đều được chuẩn hóa bằng cách sử dụng giá trị trung bình và độ lệch chuẩn của kênh. Tập dữ liệu ImageNet là một tập dữ liệu phân loại ảnh quy mô lớn bao gồm khoảng 1,28 triệu hình ảnh huấn luyện và 50.000 hình ảnh xác thực từ 1.000 lớp. Chúng tôi áp dụng cùng chiến lược tăng cường dữ liệu như CC [54].

Cài đặt Thí nghiệm. Trên CIFAR-10, các mô hình cơ sở được huấn luyện bằng cách sử dụng cùng cấu hình huấn luyện như công trình của Li et al. [54], tức là tốc độ học ban đầu được đặt thành 0,1 và được nhân với 0,1 tại 50% và 75% của tổng số 300 epochs. Lưu ý rằng do có giai đoạn tinh chỉnh, hầu hết các phương pháp nén so sánh đều huấn luyện hơn 400 epochs. Vì vậy để so sánh công bằng và làm cho mạng nén được huấn luyện đầy đủ, chúng tôi huấn luyện các mạng ngoại trừ DenseNet từ đầu với LAPP trong 400 epochs thông qua thuật toán Stochastic Gradient Descent (SGD) với động lượng 0,9 và tốc độ học ban đầu 0,1. Kích thước mini-batch và suy giảm trọng số lần lượt được đặt thành 128 và 0,0001. Ngoại trừ số epochs, cấu hình huấn luyện của chúng tôi giống với cấu hình tinh chỉnh của CC [54]. Để đạt được hiệu suất tương đương, chúng tôi huấn luyện DenseNet từ đầu với LAPP trong 600 epochs giống như tổng số epochs của CC [54]. Trên ImageNet, các mạng được huấn luyện từ đầu với LAPP trong 120 epochs với tốc độ học ban đầu 0,1. Tốc độ học được chia cho 10 tại epoch 30, 60 và 90, và kích thước mini-batch được đặt thành 256. Tất cả các ngưỡng có thể học được đều được khởi tạo theo kinh nghiệm thành 0, và hệ số λ2 của hạng tử ràng buộc FLOPs được đặt thành 1,0 cho tất cả các mạng ngoại trừ ResNet34. Hệ số λ1 của hạng tử điều chỉnh ℓ1 được đặt thành 3e-5 cho ResNet-20 và 2e-5 cho các mạng khác trên CIFAR-10. Trên ImageNet, λ1 được đặt thành 1e-5, và λ2 được đặt thành 0,5 cho ResNet-34. Tất cả các thí nghiệm đều được lặp lại ba lần và kết quả trung bình được báo cáo. Lưu ý rằng trong tất cả các bảng sau, FLOPs ↓ và Params ↓ biểu thị sự giảm

BẢNG II
KẾT QUẢ NÉN CỦA RESNET-56/110 TRÊN CIFAR-10.

Phương pháp Top-1(%) FLOPs ↓(%) Params ↓(%)
ResNet-56 93.33 0.0 0.0
LFPC [47] 93.72±0.29 47.1 —
DECORE [38] 93.26 49.9 49.0
PFS [11] 93.05±0.19 50.0 —
Hrank [26] 93.17 50.0 42.4
NPPM [32] 93.40 50.0 —
Hinge [55] 93.69 50.0 48.7
CC [54] 93.64 52.0 48.2
FP-AGL [49] 93.69 52.5 —
Của chúng tôi (C=0.47) 93.72±0.16 52.5 40.0
SFP [27] 93.35±0.31 52.6 —
FPGM [28] 93.49±0.13 52.6 —
DPFPS [45] 93.20±0.11 52.9 46.8
GNN-RL [37] 93.49 54.0 —
SOSP [35] 93.27±0.51 57.0 61.0
FP-AGL [49] 93.49 60.9 —
Của chúng tôi (C=0.385) 93.52±0.18 61.1 52.5
FTWT [52] 92.63 66.0 —
CHIP [51] 92.05 72.3 71.8
Hrank [26] 90.72 74.1 68.1
HPSE [29] 91.51 74.2 —
Của chúng tôi (C=0.25) 92.84±0.21 74.8 66.8
ResNet-110 93.50 0.0 0.0
PFEC [9] 93.30 38.6 32.4
PFS [11] 93.69±0.28 40.0 —
SFP [27] 93.38±0.30 40.8 —
Hrank [26] 94.23 41.2 39.4
FPGM [28] 93.74±0.10 52.3 —
Của chúng tôi (C=0.47) 94.03±0.26 52.5 42.7
LFPC [47] 93.79±0.38 60.3 —
HPSE [29] 93.79 60.6 —
DECORE [38] 93.50 61.8 64.8
Hrank [26] 92.65 68.6 69.2
Của chúng tôi (C=0.31) 93.90±0.14 68.7 66.2
HPSE [29] 93.26 73.4 —
DECORE [38] 92.71 76.9 79.6
Của chúng tôi (C=0.22) 93.18±0.17 77.8 70.6

FLOPs và tham số của mạng nén so với mạng Baseline.

B. Kết quả Thí nghiệm trên CIFAR-10

Chúng tôi tiến hành thí nghiệm trên tập dữ liệu CIFAR-10 với một số CNNs phổ biến, bao gồm ResNet-56/110/20/32, VGG-16, DenseNet-40 và GoogLeNet. Theo [26], VGG-16 là phiên bản sửa đổi của bản gốc và đầu ra của GoogLeNet gốc được thay đổi để phù hợp với số lớp trong CIFAR-10.

VGG-16. Kết quả nén của VGG-16 được hiển thị trong Bảng I. So với các phương pháp cắt tỉa sau huấn luyện HRank và DECORE, phương pháp của chúng tôi không cần tiền huấn luyện tốt hơn ở nhiều mức tăng tốc khác nhau. So với CC và Hinge kết hợp cắt tỉa và phân rã hạng thấp, phương pháp của chúng tôi cũng đạt được hiệu suất tốt hơn (65,7% vs. 60,7% vs. 39,1% trong giảm FLOPs, và 94,36% vs. 94,09% vs. 94,02% trong độ chính xác top-1). So với phương pháp cắt tỉa động FTWT, với độ chính xác gần như tương tự, phương pháp của chúng tôi đạt được giảm FLOPs đáng kể hơn (73,8% vs. 56,0%). So với PFEC cũng sử dụng chỉ số chuẩn ℓ1, chỉ đạt được 93,40% độ chính xác top-1, phương pháp của chúng tôi đạt được kết quả tốt hơn là 94,32% với giảm FLOPs đáng kể hơn, điều này chứng minh sự vượt trội của việc giới thiệu

--- TRANG 9 ---
CÔNG TRÌNH NÀY ĐÃ ĐƯỢC GỬI ĐẾN IEEE ĐỂ XEM XÉT XUẤT BẢN. BẢN QUYỀN CÓ THỂ ĐƯỢC CHUYỂN GIAO MÀ KHÔNG CẦN THÔNG BÁO, SAU ĐÓ PHIÊN BẢN NÀY CÓ THỂ KHÔNG CÒN TRUY CẬP ĐƯỢC. 9

BẢNG III
KẾT QUẢ NÉN CỦA RESNET-20/32 TRÊN CIFAR-10.

Phương pháp Top-1(%) FLOPs ↓(%) Params ↓(%)
ResNet-20 92.20 0.0 0.0
SFP [27] 90.83±0.31 42.2 —
FPGM [28] 91.09±0.10 42.2 —
PFS [11] 90.55±0.14 50.0 —
GNN-RL [37] 91.31 51.0 —
Hinge [55] 91.84 54.5 55.5
Của chúng tôi (C=0.4) 92.22±0.19 59.7 52.8
FP-AGL [49] 90.11 60.7 —
Của chúng tôi (C=0.28) 91.24±0.24 71.8 58.9
ResNet-32 92.63 0.0 0.0
SFP [27] 92.08±0.08 41.5 —
GNN-RL [37] 92.58 51.0 —
LFPC [47] 92.12±0.08 52.6 —
FPGM [28] 91.93±0.03 53.2 —
Của chúng tôi (C=0.4) 93.21±0.19 59.6 49.1
FP-AGL [49] 91.86 60.8 —
Của chúng tôi (C=0.28) 92.32±0.21 71.8 60.8

đường tránh và sử dụng chiến lược cắt tỉa không đồng nhất được đề xuất. Do đó, phương pháp của chúng tôi thể hiện khả năng tăng tốc một mạng nơ-ron có cấu trúc đơn giản.

ResNet-56/110/20/32. Kết quả nén của ResNet-56/110/20/32 được hiển thị trong Bảng II và III. Chúng tôi bắt đầu với ResNet-56. So với phương pháp cắt tỉa tại khởi tạo PFS, phương pháp của chúng tôi giảm thêm FLOPs 2,5%, trong khi duy trì độ chính xác cao hơn (93,72(±0,16)% vs. 93,05(±0,19)%). Ngoài ra, so với phương pháp cắt tỉa trong quá trình huấn luyện DPFPS, phương pháp của chúng tôi cải thiện thêm độ chính xác 0,32%, trong khi duy trì giảm FLOPs nhiều hơn (61,1% vs. 52,9%). So với NPPM cũng sử dụng ràng buộc FLOPs, với nhiều giảm FLOPs hơn, phương pháp của chúng tôi không cần tiền huấn luyện đạt được độ chính xác tốt hơn đáng kể (93,72(±0,16)% vs. 93,40%), điều này chứng minh sự vượt trội của chiến lược cắt tỉa kết hợp ngưỡng có thể học được và ràng buộc FLOPs. So với LFPC học tiêu chí cắt tỉa bộ lọc, với độ chính xác gần như tương tự, phương pháp của chúng tôi giảm thêm FLOPs 5,4%.

Trên ResNet-110 với nhiều dư thừa hơn, phương pháp của chúng tôi dẫn đến cải thiện đáng kể về độ chính xác so với mô hình cơ sở (94,03(±0,26)% vs. 93,50%) với khoảng 52,5% giảm FLOPs và 42,7% giảm tham số. So với SFP và FPGM với cùng tỷ lệ cắt tỉa cho tất cả các lớp, phương pháp của chúng tôi đạt được độ chính xác cao hơn (93,90(±0,14)% vs. 93,38(±0,30)% vs. 93,74(±0,10)%) và tiết kiệm nhiều tài nguyên tính toán hơn (68,7% vs. 40,8% vs. 52,3%), cho thấy rằng phương pháp của chúng tôi hiệu quả hơn. So với HPSE với tiêu chí cắt tỉa phức tạp dựa trên đặc trưng của bản đồ đặc trưng, phương pháp của chúng tôi sử dụng chỉ số chuẩn ℓ1 đơn giản vẫn tương đương ở nhiều mức tăng tốc khác nhau, điều này chứng minh sự vượt trội của phương pháp chúng tôi.

Bảng III cho thấy hiệu suất của các phương pháp khác nhau trong việc nén ResNet-20/32. Nén ResNet20/32 tương đối nhẹ là thách thức hơn so với việc nén ResNet-56/110. Trên ResNet-20, so với GNN-RL tìm tỷ lệ cắt tỉa lớp ẩn phù hợp bằng cách sử dụng học tăng cường, phương pháp của chúng tôi cải thiện thêm độ chính xác 0,91% và giảm FLOPs 8,7%. Trên ResNet-32,

BẢNG IV
KẾT QUẢ NÉN CỦA DENSE NET-40 TRÊN CIFAR-10.

Phương pháp Top-1(%) FLOPs ↓(%) Params ↓(%)
Baseline 94.81 0.0 0.0
DECORE [38] 94.59 39.4 46.0
Hrank [26] 94.24 40.8 36.5
Hinge [55] 94.67 44.4 27.5
CC [54] 94.67 47.0 51.9
HPSE [29] 94.38 48.0 —
Của chúng tôi (C=0.5,in) 94.56±0.17 49.5 46.6
Của chúng tôi (C=0.5,out) 94.51±0.29 49.6 48.2
DECORE [38] 94.04 54.7 65.0
NS [30] 94.35 55.0 65.2
CC [54] 94.40 60.4 64.4
Hrank [26] 93.68 61.0 53.8
HPSE [29] 93.88 61.5 —
Của chúng tôi (C=0.38,in) 94.24±0.25 61.6 62.4

BẢNG V
KẾT QUẢ NÉN CỦA GOOGLE NET TRÊN CIFAR-10.

Phương pháp Top-1(%) FLOPs ↓(%) Params ↓(%)
Baseline 95.05 0.0 0.0
DECORE [38] 95.20 19.8 23.0
PFEC [9] 94.54 32.9 42.9
CC [54] 95.18 50.0 54.0
Của chúng tôi (C=0.49) 95.57±0.08 50.5 52.6
Hrank [26] 94.53 54.9 55.4
CC [54] 94.88 59.9 63.3
Của chúng tôi (C=0.39) 95.40±0.12 60.6 61.1
Hrank [26] 94.07 70.4 69.8
DECORE [38] 94.51 78.5 80.9
Của chúng tôi (C=0.21) 94.99±0.08 78.8 79.1

với khoảng 60,0% giảm FLOPs, phương pháp của chúng tôi dẫn đến cải thiện đáng kể về độ chính xác so với mô hình cơ sở (93,21(±0,19)% vs. 92,63%), khác biệt đáng kể với các thuật toán nén tiên tiến khác, làm nổi bật tính hiệu quả của phương pháp chúng tôi. Do đó, phương pháp của chúng tôi chứng minh rằng nó đặc biệt phù hợp để nén các mạng nơ-ron có khối residual.

DenseNet-40. Bảng IV cho thấy hiệu suất của các phương pháp khác nhau trong việc nén DenseNet-40, trong đó 'in' biểu thị cắt tỉa kênh và 'out' biểu thị cắt tỉa bộ lọc. So với các phương pháp cắt tỉa tiên tiến HRank, DECORE và HPSE, phương pháp của chúng tôi tốt hơn chúng ở nhiều mức tăng tốc khác nhau. So với CC và Hinge yêu cầu các mô hình đã được tiền huấn luyện, với giảm FLOPs nhiều hơn một chút, mặc dù độ chính xác trung bình của chúng tôi kém hơn kết quả họ báo cáo, kết quả tốt nhất của chúng tôi lại tốt hơn của họ (94,76% vs. 94,67% vs. 94,67%). Nhìn chung, phương pháp của chúng tôi có tiềm năng tăng tốc tốt hơn các mạng với khối dày đặc.

GoogleNet. Trong Bảng V, chúng tôi phân tích hiệu suất của các phương pháp khác nhau trên GoogleNet. Bởi vì GoogleNet có lượng lớn dư thừa, việc nén nó đặc biệt dễ dàng. Các phép tích chập 1×1 trong GoogleNet chỉ sở hữu các đường thưa thớt cho phương pháp của chúng tôi. Với độ chính xác gần như tương tự mô hình cơ sở, phương pháp của chúng tôi đạt được khoảng 79% giảm FLOPs và tham số. Ngoài ra, so với HRank và CC, phương pháp của chúng tôi sử dụng ít FLOPs hơn nhiều (39,4% vs. 45,1% vs. 40,1%), nhưng đạt được độ chính xác cao hơn (95,40(±0,12)% vs. 94,53% vs. 94,88%), điều này rất khuyến khích. Do đó,

--- TRANG 10 ---
CÔNG TRÌNH NÀY ĐÃ ĐƯỢC GỬI ĐẾN IEEE ĐỂ XEM XÉT XUẤT BẢN. BẢN QUYỀN CÓ THỂ ĐƯỢC CHUYỂN GIAO MÀ KHÔNG CẦN THÔNG BÁO, SAU ĐÓ PHIÊN BẢN NÀY CÓ THỂ KHÔNG CÒN TRUY CẬP ĐƯỢC. 10

BẢNG VI
KẾT QUẢ NÉN CỦA RESNET-18/34 TRÊN IMAGE NET.

Phương pháp Top-1(%) Top-5(%) FLOPs ↓(%)
ResNet-18 69.76 89.08 0.0
SOSP [35] 68.78±0.98 — 29.0
SFP [27] 67.10 87.78 41.8
FPGM [28] 68.34 88.53 41.8
Của chúng tôi (C=0.56) 70.43±0.07 89.77±0.03 43.5
DCP [41] 67.36 87.63 46.2
GNN-RL [37] 68.66 — 51.0
FTWT [52] 67.49 — 51.6
Của chúng tôi (C=0.44) 69.97±0.04 89.48±0.14 55.6
ResNet-34 73.31 91.42 0.0
SFP [27] 71.83 90.33 41.1
FPGM [28] 72.54 91.13 41.1
FP-AGL [49] 72.72 — 43.1
DPFPS [45] 72.25 90.80 43.3
Của chúng tôi (C=0.56) 72.91±0.13 91.18±0.02 43.5
ResNet-18 [2] 69.76 89.08 50.0
FTWT [52] 71.71 — 52.2
Của chúng tôi (C=0.47) 72.55±0.16 91.05±0.11 52.5

nó chứng minh rằng phương pháp của chúng tôi có thể được áp dụng hiệu quả để nén các mạng nơ-ron có mô-đun inception.

C. Kết quả Thí nghiệm trên ImageNet

ResNet-18/34. Chúng tôi cũng tiến hành thí nghiệm cho ResNet-18 và ResNet-34 trên tập dữ liệu ImageNet đầy thách thức, như được hiển thị trong Bảng VI. Chúng ta có thể thấy kết luận tương tự trong tập dữ liệu CIFAR-10, tức là phương pháp của chúng tôi gần như vượt trội so với các phương pháp so sánh về tất cả các khía cạnh. Cụ thể, so với SFP (67,10% top-1) và FPGM (68,34% top-1), phương pháp của chúng tôi đạt được độ chính xác cao hơn (70,43% top-1) với giảm FLOPs nhiều hơn (43,5%) trên ResNet-18. So với DCP yêu cầu các mô hình đã được tiền huấn luyện, phương pháp của chúng tôi cung cấp độ chính xác cao hơn đáng kể với giảm FLOPs nhiều hơn (69,97(±0,04)% vs. 67,36% trong độ chính xác top-1, và 55,6% vs. 46,2% trong giảm FLOPs) trên ResNet-18. So với GNN-RL yêu cầu tổng cộng 240 epochs, với 120 epochs, phương pháp của chúng tôi đạt được hiệu suất tốt hơn trên ResNet-18, cho thấy rằng phương pháp của chúng tôi hiệu quả hơn. So với FP-AGL và DPFPS, với độ chính xác cao hơn, phương pháp của chúng tôi đạt được giảm FLOPs tương tự trên ResNet-34. So với ResNet-18, với giảm FLOPs nhiều hơn, phương pháp của chúng tôi dẫn đến độ chính xác cao hơn đáng kể trên ResNet-34, điều này chứng minh rằng phương pháp của chúng tôi có thể tạo ra một mạng con tốt. FTWT là một phương pháp cắt tỉa động và được kỳ vọng sẽ vượt trội hơn các phương pháp cắt tỉa tĩnh, nhưng phương pháp của chúng tôi vẫn vượt trội hơn nó trên ResNet-18 và ResNet-34. Do đó, phương pháp của chúng tôi cũng hoạt động tốt trên các tập dữ liệu phức tạp.

D. Nghiên cứu Loại bỏ

Hiệu ứng của Đường tránh. Như đã đề cập trước đó, các đường tránh bù đắp cho các đường thưa thớt. Chúng tôi tiến hành thí nghiệm loại bỏ trên CIFAR-10 với VGG-16, ResNet-56 và ResNet-20 để cho thấy hiệu ứng bù đắp của các đường tránh, như được hiển thị trong Bảng VII. Ở đây, các khối lấy cảm hứng từ MobileNetV1 [67] và MobileNetV2 [36] lần lượt được gọi là V1 và V2. Khối V1 tuần tự chứa hai lớp tích chập nhỏ: tích chập theo chiều sâu và tích chập 1×1.

BẢNG VII
KẾT QUẢ THÍ NGHIỆM LOẠI BỎ CỦA ĐƯỜNG TRÁNH.

Mô hình C Phương pháp Top-1(%) FLOPs ↓(%)
VGG-16 0.34 LAPP-S 93.70±0.24 65.7
Mô hình-V2 94.20±0.15 65.5
LAPP-V1 93.65±0.13 65.7
LAPP 94.36±0.08 65.7
ResNet-56 0.33 LAPP-S 92.93±0.21 66.7
Mô hình-V2 92.84±0.11 66.3
LAPP-V1 93.09±0.17 66.7
LAPP 93.49±0.07 66.7
ResNet-20 0.4 LAPP-S 90.70±0.13 59.7
Mô hình-V2 91.68±0.17 59.3
LAPP-V1 91.71±0.48 59.7
LAPP 92.22±0.19 59.7

BẢNG VIII
KẾT QUẢ THÍ NGHIỆM LOẠI BỎ CỦA CHIẾN LƯỢC CẮT TỈA. 'UP' BIỂU THỊ CẮT TỈA ĐỒNG NHẤT.

Mô hình C Phương pháp Top-1(%) FLOPs ↓(%)
VGG-16 0.34 LAPP-UP 94.20±0.11 65.8
LAPP 94.36±0.08 65.7
0.18 LAPP-UP 93.31±0.12 81.8
LAPP 93.54±0.23 81.9
ResNet-56 0.47 LAPP-UP 93.34±0.18 50.1
LAPP 93.72±0.16 52.5
0.33 LAPP-UP 92.84±0.13 65.2
LAPP 93.49±0.07 66.7
ResNet-20 0.4 LAPP-UP 91.25±0.18 57.7
LAPP 92.22±0.19 59.7

'LAPP-S' biểu thị chỉ sử dụng các đường thưa thớt trong các mô-đun SBC, 'Mô hình-V2' biểu thị chỉ sử dụng các đường tránh chứa khối V2, và 'LAPP-V1' và 'LAPP' biểu thị sử dụng hai đường và lần lượt lấy khối V1 và V2 làm đường tránh. Chúng tôi điều chỉnh siêu tham số dl của mỗi đường tránh cho Mô hình-V2 để đạt được cùng giảm FLOPs như các phương pháp khác. Ngoài ra, chúng tôi sử dụng cấu hình huấn luyện hoàn toàn giống nhau cho tất cả các phương pháp. Không giống như LAPP-V1 và LAPP, đối với LAPP-S không có đường tránh, khi các kênh đầu ra của lớp bị cắt tỉa, việc cắt tỉa các kênh đầu vào tương ứng của lớp tiếp theo cần được tính đến.

Từ Bảng VII, LAPP-V1 và LAPP với các đường tránh vượt trội hơn LAPP-S trong hầu hết các trường hợp, điều này chứng minh hiệu ứng bù đắp của các đường tránh. Hơn nữa, mạng càng nhỏ gọn, hiệu ứng bù đắp của đường tránh càng đáng kể, đặc biệt là đối với các mạng có khối residual. Ví dụ, khi nén ResNet-20 thách thức hơn, LAPP vượt trội hơn LAPP-S 1,52% về độ chính xác top-1 với giảm FLOPs tương tự. Ngoài ra, để nén VGG-16, ResNet56 và ResNet-20, LAPP vượt trội hơn Mô hình-V2 lần lượt 0,16%, 0,65%, và 0,54% về độ chính xác top-1. Điều này chứng minh rằng các đường tránh và các đường thưa thớt có thể bù đắp cho nhau, dẫn đến hiệu suất nén tốt hơn. Cuối cùng nhưng không kém phần quan trọng, LAPP vượt trội hơn LAPP-V1 trong tất cả các trường hợp. Điều này chứng minh rằng khối V2 với sức mạnh biểu đạt mạnh hơn có hiệu ứng bù đắp tốt hơn khối V1.

Hiệu ứng của Chiến lược Cắt tỉa. Ở đây chúng tôi tiến hành thí nghiệm loại bỏ trên CIFAR-10 với VGG-16, ResNet-56 và ResNet-20 để cho thấy hiệu ứng của chiến lược cắt tỉa dưới các tỷ lệ nén FLOPs mục tiêu khác nhau, như được hiển thị trong Bảng VIII. Sử dụng cùng chỉ số quan trọng bộ lọc, chúng tôi so sánh chiến lược cắt tỉa của mình với chiến lược cắt tỉa đồng nhất tại khởi tạo. Chúng tôi sử dụng 'UP' để biểu thị cắt tỉa đồng nhất trước khi huấn luyện bắt đầu. Chúng tôi đặt thủ công gần như cùng tỷ lệ cắt tỉa cho tất cả các đường thưa thớt để đạt được tỷ lệ nén FLOPs mục tiêu. Các cấu hình huấn luyện khác hoàn toàn giống như LAPP. LAPP với chiến lược cắt tỉa của chúng tôi vượt trội hơn LAPP-UP sử dụng cắt tỉa đồng nhất trong tất cả các trường hợp. Ví dụ, khi nén ResNet-56, LAPP vượt trội hơn LAPP-UP lần lượt 0,38% và 0,65% về độ chính xác top-1 dưới các tỷ lệ nén FLOPs mục tiêu khác nhau 47% và 33%. Tỷ lệ nén FLOPs mục tiêu càng thấp, chiến lược cắt tỉa của chúng tôi càng hiệu quả. Điều này chứng minh rằng chiến lược cắt tỉa của chúng tôi có thể tạo ra một mạng con tương đối tốt hơn.

V. KẾT LUẬN

Trong bài báo này, chúng tôi tích hợp ngưỡng có thể học được và ràng buộc FLOPs thành một chiến lược cắt tỉa hiệu quả và hiệu suất. Chiến lược cắt tỉa có thể dần dần cắt tỉa mạng và tự động xác định tỷ lệ cắt tỉa phù hợp cho từng lớp trong quá trình huấn luyện ban đầu vài epochs từ đầu. Ngoài ra, chúng tôi giới thiệu một đường tránh nhẹ bổ sung cho mỗi lớp tích chập để bù đắp thông tin và dung lượng mất mát của lớp đã cắt tỉa trong quá trình huấn luyện. Tính hiệu quả của phương pháp đề xuất được đánh giá trên các tập dữ liệu chuẩn CIFAR-10 và ImageNet sử dụng các mô hình CNN chính thống, và kết quả cho thấy hiệu suất vượt trội so với các thuật toán nén tiên tiến khác.

TÀI LIỆU THAM KHẢO
[1] K. Simonyan and A. Zisserman, "Very deep convolutional networks for large-scale image recognition," arXiv preprint arXiv:1409.1556, 2014.
[2] K. He, X. Zhang, S. Ren, and J. Sun, "Deep residual learning for image recognition," in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2016, pp. 770–778.
[3] J. Redmon, S. Divvala, R. Girshick, and A. Farhadi, "You only look once: Unified, real-time object detection," in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2016, pp. 779–788.
[4] T.-Y. Lin, P. Goyal, R. Girshick, K. He, and P. Dollár, "Focal loss for dense object detection," in Proceedings of the IEEE International Conference on Computer Vision, 2017, pp. 2980–2988.
[5] R. T. Marriott, S. Romdhani, and L. Chen, "A 3d gan for improved large-pose facial recognition," in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2021, pp. 13 445–13 455.
[6] S. Li, J. Xu, X. Xu, P. Shen, S. Li, and B. Hooi, "Spherical confidence learning for face recognition," in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2021, pp. 15 629–15 637.
[7] Y. Chen, Z. Zhang, C. Yuan, B. Li, Y. Deng, and W. Hu, "Channel-wise topology refinement graph convolution for skeleton-based action recognition," in Proceedings of the IEEE/CVF International Conference on Computer Vision, 2021, pp. 13 359–13 368.
[8] Y. Nirkin, L. Wolf, and T. Hassner, "HyperSeg: Patch-wise hypernetwork for real-time semantic segmentation," in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2021, pp. 4061–4070.
[9] H. Li, A. Kadav, I. Durdanovic, H. Samet, and H. P. Graf, "Pruning filters for efficient convnets," arXiv preprint arXiv:1608.08710, 2016.
[10] J. J. M. Ople, T.-M. Huang, M.-C. Chiu, Y.-L. Chen, and K.-L. Hua, "Adjustable model compression using multiple genetic algorithms," IEEE Transactions on Multimedia, 2021.
[11] Y. Wang, X. Zhang, L. Xie, J. Zhou, H. Su, B. Zhang, and X. Hu, "Pruning from scratch," in Proceedings of the AAAI Conference on Artificial Intelligence, vol. 34, no. 07, 2020, pp. 12 273–12 280.
[12] V. Lebedev, Y. Ganin, M. Rakhuba, I. Oseledets, and V. Lempitsky, "Speeding-up convolutional neural networks using fine-tuned CP-decomposition," in Proceedings of the International Conference on Learning Representations, 2015.
[13] A.-H. Phan, K. Sobolev, K. Sozykin, D. Ermilov, J. Gusak, P. Tichavský, V. Glukhov, I. Oseledets, and A. Cichocki, "Stable low-rank tensor decomposition for compression of convolutional neural network," in Proceedings of the European Conference on Computer Vision. Springer, 2020, pp. 522–539.
[14] J. Kossaifi, A. Toisoul, A. Bulat, Y. Panagakis, T. M. Hospedales, and M. Pantic, "Factorized higher-order cnns with an application to spatio-temporal emotion estimation," in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2020, pp. 6060–6069.
[15] G. Hinton, O. Vinyals, and J. Dean, "Distilling the knowledge in a neural network," arXiv preprint arXiv:1503.02531, 2015.
[16] D. Y. Park, M.-H. Cha, D. Kim, B. Han et al., "Learning student-friendly teacher networks for knowledge distillation," in Advances in Neural Information Processing Systems, vol. 34, 2021, pp. 13 292–13 303.
[17] P. K. Sharma, A. Abraham, and V. N. Rajendiran, "A generalized zero-shot quantization of deep convolutional neural networks via learned weights statistics," IEEE Transactions on Multimedia, 2021.
[18] Z. Li, B. Ni, T. Li, X. Yang, W. Zhang, and W. Gao, "Residual quantization for low bit-width neural networks," IEEE Transactions on Multimedia, 2021.
[19] W. Duan, Z. Liu, C. Jia, S. Wang, S. Ma, and W. Gao, "Differential weight quantization for multi-model compression," IEEE Transactions on Multimedia, 2022.
[20] K. Han, Y. Wang, C. Xu, J. Guo, C. Xu, E. Wu, and Q. Tian, "Ghostnets on heterogeneous devices via cheap operations," International Journal of Computer Vision, vol. 130, no. 4, pp. 1050–1069, 2022.
[21] Q. Zhang, Z. Jiang, Q. Lu, Z. Zeng, S.-H. Gao, and A. Men, "Split to Be Slim: an overlooked redundancy in vanilla convolution," in Proceedings of the Twenty-Ninth International Conference on International Joint Conferences on Artificial Intelligence, 2021, pp. 3195–3201.
[22] J. Chen, S.-h. Kao, H. He, W. Zhuo, S. Wen, C.-H. Lee, and S.-H. G. Chan, "Run, Don't Walk: Chasing higher flops for faster neural networks," in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2023, pp. 12 021–12 031.
[23] X. Ding, X. Zhou, Y. Guo, J. Han, J. Liu et al., "Global sparse momentum sgd for pruning very deep neural networks," in Advances in Neural Information Processing Systems, vol. 32, 2019.
[24] X. Dong, S. Chen, and S. Pan, "Learning to prune deep neural networks via layer-wise optimal brain surgeon," in Advances in Neural Information Processing Systems, vol. 30, 2017.
[25] X. Ding, T. Hao, J. Tan, J. Liu, J. Han, Y. Guo, and G. Ding, "ResRep: Lossless cnn pruning via decoupling remembering and forgetting," in Proceedings of the IEEE/CVF International Conference on Computer Vision, 2021, pp. 4510–4520.
[26] M. Lin, R. Ji, Y. Wang, Y. Zhang, B. Zhang, Y. Tian, and L. Shao, "Hrank: Filter pruning using high-rank feature map," in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2020, pp. 1529–1538.
[27] Y. He, G. Kang, X. Dong, Y. Fu, and Y. Yang, "Soft filter pruning for accelerating deep convolutional neural networks," in Proceedings of the International Joint Conference on Artificial Intelligence, 2018.
[28] Y. He, P. Liu, Z. Wang, Z. Hu, and Y. Yang, "Filter pruning via geometric median for deep convolutional neural networks acceleration," in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2019, pp. 4340–4349.
[29] H. Zhang, L. Liu, B. Kang, and N. Zheng, "Hierarchical model compression via shape-edge representation of feature maps—an enlightenment from the primate visual system," IEEE Transactions on Multimedia, 2022.
[30] Z. Liu, J. Li, Z. Shen, G. Huang, S. Yan, and C. Zhang, "Learning efficient convolutional networks through network slimming," in Proceedings of the IEEE International Conference on Computer Vision, 2017, pp. 2736–2744.
[31] A. Kusupati, V. Ramanujan, R. Somani, M. Wortsman, P. Jain, S. Kakade, and A. Farhadi, "Soft threshold weight reparameterization for learnable sparsity," in Proceedings of the International Conference on Machine Learning. PMLR, 2020, pp. 5544–5555.

--- TRANG 12 ---
CÔNG TRÌNH NÀY ĐÃ ĐƯỢC GỬI ĐẾN IEEE ĐỂ XEM XÉT XUẤT BẢN. BẢN QUYỀN CÓ THỂ ĐƯỢC CHUYỂN GIAO MÀ KHÔNG CẦN THÔNG BÁO, SAU ĐÓ PHIÊN BẢN NÀY CÓ THỂ KHÔNG CÒN TRUY CẬP ĐƯỢC. 12

[32] S. Gao, F. Huang, W. Cai, and H. Huang, "Network pruning via performance maximization," in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2021, pp. 9270–9280.
[33] S. Gao, F. Huang, J. Pei, and H. Huang, "Discrete model compression with resource constraint for deep neural networks," in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2020, pp. 1899–1908.
[34] M. Shen, P. Molchanov, H. Yin, and J. M. Alvarez, "When to prune? a policy towards early structural pruning," in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2022, pp. 12 247–12 256.
[35] M. Nonnenmacher, T. Pfeil, I. Steinwart, and D. Reeb, "SOSP: Efficiently capturing global correlations by second-order structured pruning," in Proceedings of the International Conference on Learning Representations, 2021.
[36] M. Sandler, A. Howard, M. Zhu, A. Zhmoginov, and L.-C. Chen, "MobileNetV2: Inverted residuals and linear bottlenecks," in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2018, pp. 4510–4520.
[37] S. Yu, A. Mazaheri, and A. Jannesari, "Topology-aware network pruning using multi-stage graph embedding and reinforcement learning," in Proceedings of the International Conference on Machine Learning. PMLR, 2022, pp. 25 656–25 667.
[38] M. Alwani, Y. Wang, and V. Madhavan, "DECORE: Deep compression with reinforcement learning," in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2022, pp. 12 349–12 359.
[39] C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed, D. Anguelov, D. Erhan, V. Vanhoucke, and A. Rabinovich, "Going deeper with convolutions," in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2015, pp. 1–9.
[40] G. Huang, Z. Liu, L. Van Der Maaten, and K. Q. Weinberger, "Densely connected convolutional networks," in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2017, pp. 4700–4708.
[41] Z. Zhuang, M. Tan, B. Zhuang, J. Liu, Y. Guo, Q. Wu, J. Huang, and J. Zhu, "Discrimination-aware channel pruning for deep neural networks," in Advances in Neural Information Processing Systems, vol. 31, 2018.
[42] N. Lee, T. Ajanthan, and P. Torr, "SNIP: Single-shot network pruning based on connection sensitivity," in Proceedings of the International Conference on Learning Representations, 2018.
[43] S. Hayou, J.-F. Ton, A. Doucet, and Y. W. Teh, "Robust pruning at initialization," in Proceedings of the International Conference on Learning Representations, 2020.
[44] C. Wang, G. Zhang, and R. Grosse, "Picking winning tickets before training by preserving gradient flow," in Proceedings of the International Conference on Learning Representations, 2019.
[45] X. Ruan, Y. Liu, B. Li, C. Yuan, and W. Hu, "DPFPS: dynamic and progressive filter pruning for compressing convolutional neural networks from scratch," in Proceedings of the AAAI Conference on Artificial Intelligence, vol. 35, no. 3, 2021, pp. 2495–2503.
[46] J. Frankle, G. K. Dziugaite, D. Roy, and M. Carbin, "Linear mode connectivity and the lottery ticket hypothesis," in Proceedings of the International Conference on Machine Learning. PMLR, 2020, pp. 3259–3269.
[47] Y. He, Y. Ding, P. Liu, L. Zhu, H. Zhang, and Y. Yang, "Learning filter pruning criteria for deep convolutional neural networks acceleration," in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2020, pp. 2009–2018.
[48] Z. Wang, W. Hong, Y.-P. Tan, and J. Yuan, "Pruning 3d filters for accelerating 3d convnets," IEEE Transactions on Multimedia, vol. 22, no. 8, pp. 2126–2137, 2019.
[49] N. J. Kim and H. Kim, "FP-AGL: Filter pruning with adaptive gradient learning for accelerating deep convolutional neural networks," IEEE Transactions on Multimedia, 2022.
[50] T. Zhuang, Z. Zhang, Y. Huang, X. Zeng, K. Shuang, and X. Li, "Neuron-level structured pruning using polarization regularizer," in Advances in Neural Information Processing Systems, vol. 33, 2020, pp. 9865–9877.
[51] Y. Sui, M. Yin, Y. Xie, H. Phan, S. Aliari Zonouz, and B. Yuan, "CHIP: CHannel independence-based pruning for compact neural networks," in Advances in Neural Information Processing Systems, vol. 34, 2021, pp. 24 604–24 616.
[52] S. Elkerdawy, M. Elhoushi, H. Zhang, and N. Ray, "Fire Together Wire Together: A dynamic pruning approach with self-supervised mask prediction," in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2022, pp. 12 454–12 463.
[53] K. Guo, X. Xie, X. Xu, and X. Xing, "Compressing by learning in a low-rank and sparse decomposition form," IEEE Access, vol. 7, pp. 150 823–150 832, 2019.
[54] Y. Li, S. Lin, J. Liu, Q. Ye, M. Wang, F. Chao, F. Yang, J. Ma, Q. Tian, and R. Ji, "Towards compact cnns via collaborative compression," in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2021, pp. 6438–6447.
[55] Y. Li, S. Gu, C. Mayer, L. V. Gool, and R. Timofte, "Group Sparsity: The hinge between filter pruning and decomposition for network compression," in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2020, pp. 8018–8027.
[56] Y. Wang, Y. Lu, and T. Blankevoort, "Differentiable joint pruning and quantization for hardware efficiency," in Proceedings of the European Conference on Computer Vision. Springer, 2020, pp. 259–277.
[57] M. Van Baalen, C. Louizos, M. Nagel, R. A. Amjad, Y. Wang, T. Blankevoort, and M. Welling, "Bayesian Bits: Unifying quantization and pruning," in Advances in Neural Information Processing Systems, vol. 33, 2020, pp. 5741–5752.
[58] S. Wang, J. Chen, C. Li, J. Zhu, and B. Zhang, "Fast lossless neural compression with integer-only discrete flows," in Proceedings of the International Conference on Machine Learning. PMLR, 2022, pp. 22 562–22 575.
[59] S. Li, M. Lin, Y. Wang, C. Fei, L. Shao, and R. Ji, "Learning efficient gans for image translation via differentiable masks and co-attention distillation," IEEE Transactions on Multimedia, 2022.
[60] W. Zou, Y. Wang, X. Fu, and Y. Cao, "Dreaming to prune image deraining networks," in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2022, pp. 6023–6032.
[61] Y. Liu, Z. Shu, Y. Li, Z. Lin, F. Perazzi, and S.-Y. Kung, "Content-aware gan compression," in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2021, pp. 12 156–12 166.
[62] J. Park and A. No, "Prune your model before distill it," in Proceedings of the European Conference on Computer Vision. Springer, 2022, pp. 120–136.
[63] Y. Bengio, N. Léonard, and A. Courville, "Estimating or propagating gradients through stochastic neurons for conditional computation," arXiv preprint arXiv:1308.3432, 2013.
[64] A. Krizhevsky, "Learning multiple layers of features from tiny images," Master's thesis, University of Toronto, 2009.
[65] O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh, S. Ma, Z. Huang, A. Karpathy, A. Khosla, M. Bernstein et al., "Imagenet large scale visual recognition challenge," International journal of computer vision, vol. 115, no. 3, pp. 211–252, 2015.
[66] A. Paszke, S. Gross, F. Massa, A. Lerer, J. Bradbury, G. Chanan, T. Killeen, Z. Lin, N. Gimelshein, L. Antiga et al., "Pytorch: An imperative style, high-performance deep learning library," in Advances in Neural Information Processing Systems, vol. 32, 2019.
[67] A. G. Howard, M. Zhu, B. Chen, D. Kalenichenko, W. Wang, T. Weyand, M. Andreetto, and H. Adam, "MobileNets: Efficient convolutional neural networks for mobile vision applications," arXiv preprint arXiv:1704.04861, 2017.

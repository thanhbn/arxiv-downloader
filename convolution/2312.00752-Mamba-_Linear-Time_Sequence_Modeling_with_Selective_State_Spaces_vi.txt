# 2312.00752.pdf
# ÄÆ°á»£c chuyá»ƒn Ä‘á»•i tá»« PDF sang TXT
# ÄÆ°á»ng dáº«n nguá»“n: /home/admin88/arxiv-downloader/convolution/2312.00752.pdf
# KÃ­ch thÆ°á»›c tá»‡p: 1168615 bytes

===============================================
Ná»˜I DUNG Tá»†P PDF
===============================================

--- TRANG 1 ---
Mamba: MÃ´ HÃ¬nh HÃ³a Chuá»—i Thá»i Gian Tuyáº¿n TÃ­nh vá»›i KhÃ´ng Gian Tráº¡ng ThÃ¡i Chá»n Lá»c
Albert Guâˆ—1 vÃ  Tri Daoâˆ—2
1Khoa Há»c MÃ¡y Há»c, Äáº¡i há»c Carnegie Mellon
2Khoa Khoa há»c MÃ¡y tÃ­nh, Äáº¡i há»c Princeton
agu@cs.cmu.edu, tri@tridao.me
TÃ³m táº¯t
CÃ¡c mÃ´ hÃ¬nh ná»n táº£ng, hiá»‡n Ä‘ang cung cáº¥p sá»©c máº¡nh cho háº§u háº¿t cÃ¡c á»©ng dá»¥ng thÃº vá»‹ trong há»c sÃ¢u, gáº§n nhÆ° hoÃ n toÃ n dá»±a trÃªn kiáº¿n trÃºc Transformer vÃ  mÃ´-Ä‘un chÃº Ã½ cá»‘t lÃµi cá»§a nÃ³. Nhiá»u kiáº¿n trÃºc thá»i gian dÆ°á»›i báº­c hai nhÆ° chÃº Ã½ tuyáº¿n tÃ­nh, tÃ­ch cháº­p cÃ³ cá»•ng vÃ  cÃ¡c mÃ´ hÃ¬nh há»“i quy, vÃ  cÃ¡c mÃ´ hÃ¬nh khÃ´ng gian tráº¡ng thÃ¡i cÃ³ cáº¥u trÃºc (SSM) Ä‘Ã£ Ä‘Æ°á»£c phÃ¡t triá»ƒn Ä‘á»ƒ giáº£i quyáº¿t tÃ­nh khÃ´ng hiá»‡u quáº£ tÃ­nh toÃ¡n cá»§a Transformer trÃªn cÃ¡c chuá»—i dÃ i, nhÆ°ng chÃºng khÃ´ng hoáº¡t Ä‘á»™ng tá»‘t báº±ng chÃº Ã½ trÃªn cÃ¡c phÆ°Æ¡ng thá»©c quan trá»ng nhÆ° ngÃ´n ngá»¯. ChÃºng tÃ´i nháº­n Ä‘á»‹nh ráº±ng má»™t Ä‘iá»ƒm yáº¿u chÃ­nh cá»§a cÃ¡c mÃ´ hÃ¬nh nhÆ° váº­y lÃ  kháº£ nÄƒng thá»±c hiá»‡n lÃ½ luáº­n dá»±a trÃªn ná»™i dung cá»§a chÃºng, vÃ  thá»±c hiá»‡n má»™t sá»‘ cáº£i tiáº¿n. Äáº§u tiÃªn, viá»‡c Ä‘Æ¡n giáº£n cho phÃ©p cÃ¡c tham sá»‘ SSM lÃ  hÃ m cá»§a Ä‘áº§u vÃ o giáº£i quyáº¿t Ä‘iá»ƒm yáº¿u cá»§a chÃºng vá»›i cÃ¡c phÆ°Æ¡ng thá»©c rá»i ráº¡c, cho phÃ©p mÃ´ hÃ¬nh chá»n lá»c truyá»n hoáº·c quÃªn thÃ´ng tin dá»c theo chiá»u dÃ i chuá»—i tÃ¹y thuá»™c vÃ o token hiá»‡n táº¡i. Thá»© hai, máº·c dÃ¹ thay Ä‘á»•i nÃ y ngÄƒn viá»‡c sá»­ dá»¥ng tÃ­ch cháº­p hiá»‡u quáº£, chÃºng tÃ´i thiáº¿t káº¿ má»™t thuáº­t toÃ¡n song song nháº­n biáº¿t pháº§n cá»©ng á»Ÿ cháº¿ Ä‘á»™ há»“i quy. ChÃºng tÃ´i tÃ­ch há»£p cÃ¡c SSM chá»n lá»c nÃ y vÃ o má»™t kiáº¿n trÃºc máº¡ng tháº§n kinh Ä‘áº§u cuá»‘i Ä‘áº¿n Ä‘áº§u cuá»‘i Ä‘Æ°á»£c Ä‘Æ¡n giáº£n hÃ³a mÃ  khÃ´ng cÃ³ chÃº Ã½ hoáº·c tháº­m chÃ­ cÃ¡c khá»‘i MLP (Mamba). Mamba cÃ³ suy luáº­n nhanh (thÃ´ng lÆ°á»£ng cao hÆ¡n 5Ã— so vá»›i Transformer) vÃ  tá»· lá»‡ tuyáº¿n tÃ­nh theo chiá»u dÃ i chuá»—i, vÃ  hiá»‡u suáº¥t cá»§a nÃ³ cáº£i thiá»‡n trÃªn dá»¯ liá»‡u thá»±c lÃªn Ä‘áº¿n cÃ¡c chuá»—i dÃ i hÃ ng triá»‡u. LÃ  má»™t xÆ°Æ¡ng sá»‘ng mÃ´ hÃ¬nh chuá»—i tá»•ng quÃ¡t, Mamba Ä‘áº¡t Ä‘Æ°á»£c hiá»‡u suáº¥t tá»‘t nháº¥t hiá»‡n táº¡i trÃªn má»™t sá»‘ phÆ°Æ¡ng thá»©c nhÆ° ngÃ´n ngá»¯, Ã¢m thanh vÃ  di truyá»n há»c. Vá» mÃ´ hÃ¬nh hÃ³a ngÃ´n ngá»¯, mÃ´ hÃ¬nh Mamba-3B cá»§a chÃºng tÃ´i vÆ°á»£t trá»™i hÆ¡n cÃ¡c Transformer cÃ¹ng kÃ­ch thÆ°á»›c vÃ  tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i cÃ¡c Transformer gáº¥p Ä‘Ã´i kÃ­ch thÆ°á»›c cá»§a nÃ³, cáº£ trong viá»‡c huáº¥n luyá»‡n trÆ°á»›c vÃ  Ä‘Ã¡nh giÃ¡ háº¡ nguá»“n.

1 Giá»›i thiá»‡u
CÃ¡c mÃ´ hÃ¬nh ná»n táº£ng (FM), hoáº·c cÃ¡c mÃ´ hÃ¬nh lá»›n Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c trÃªn dá»¯ liá»‡u lá»›n sau Ä‘Ã³ Ä‘Æ°á»£c Ä‘iá»u chá»‰nh cho cÃ¡c tÃ¡c vá»¥ háº¡ nguá»“n, Ä‘Ã£ xuáº¥t hiá»‡n nhÆ° má»™t mÃ´ hÃ¬nh hiá»‡u quáº£ trong há»c mÃ¡y hiá»‡n Ä‘áº¡i. XÆ°Æ¡ng sá»‘ng cá»§a cÃ¡c FM nÃ y thÆ°á»ng lÃ  cÃ¡c mÃ´ hÃ¬nh chuá»—i, hoáº¡t Ä‘á»™ng trÃªn cÃ¡c chuá»—i Ä‘áº§u vÃ o tÃ¹y Ã½ tá»« nhiá»u lÄ©nh vá»±c Ä‘a dáº¡ng nhÆ° ngÃ´n ngá»¯, hÃ¬nh áº£nh, giá»ng nÃ³i, Ã¢m thanh, chuá»—i thá»i gian vÃ  di truyá»n há»c (Brown et al. 2020; Dosovitskiy et al. 2020; Ismail Fawaz et al. 2019; Oord et al. 2016; Poli et al. 2023; Sutskever, Vinyals, and Quoc V Le 2014). Trong khi khÃ¡i niá»‡m nÃ y khÃ´ng liÃªn quan Ä‘áº¿n má»™t lá»±a chá»n cá»¥ thá»ƒ cá»§a kiáº¿n trÃºc mÃ´ hÃ¬nh, cÃ¡c FM hiá»‡n Ä‘áº¡i chá»§ yáº¿u dá»±a trÃªn má»™t loáº¡i mÃ´ hÃ¬nh chuá»—i duy nháº¥t: Transformer (Vaswani et al. 2017) vÃ  lá»›p chÃº Ã½ cá»‘t lÃµi cá»§a nÃ³ (Bahdanau, Cho, and Bengio 2015). Hiá»‡u quáº£ cá»§a tá»± chÃº Ã½ Ä‘Æ°á»£c quy cho kháº£ nÄƒng Ä‘á»‹nh tuyáº¿n thÃ´ng tin dÃ y Ä‘áº·c trong cá»­a sá»• ngá»¯ cáº£nh, cho phÃ©p nÃ³ mÃ´ hÃ¬nh hÃ³a dá»¯ liá»‡u phá»©c táº¡p. Tuy nhiÃªn, tÃ­nh cháº¥t nÃ y mang láº¡i nhá»¯ng nhÆ°á»£c Ä‘iá»ƒm cÆ¡ báº£n: khÃ´ng thá»ƒ mÃ´ hÃ¬nh hÃ³a báº¥t cá»© thá»© gÃ¬ bÃªn ngoÃ i cá»­a sá»• há»¯u háº¡n, vÃ  tá»· lá»‡ báº­c hai Ä‘á»‘i vá»›i chiá»u dÃ i cá»­a sá»•.

Má»™t lÆ°á»£ng lá»›n nghiÃªn cá»©u Ä‘Ã£ xuáº¥t hiá»‡n vá» cÃ¡c biáº¿n thá»ƒ hiá»‡u quáº£ hÆ¡n cá»§a chÃº Ã½ Ä‘á»ƒ kháº¯c phá»¥c nhá»¯ng nhÆ°á»£c Ä‘iá»ƒm nÃ y (Tay, Dehghani, Bahri, et al. 2022), nhÆ°ng thÆ°á»ng pháº£i Ä‘Ã¡nh Ä‘á»•i chÃ­nh nhá»¯ng tÃ­nh cháº¥t lÃ m cho nÃ³ hiá»‡u quáº£. Cho Ä‘áº¿n nay, khÃ´ng cÃ³ biáº¿n thá»ƒ nÃ o trong sá»‘ nÃ y Ä‘Æ°á»£c chá»©ng minh lÃ  hiá»‡u quáº£ vá» máº·t thá»±c nghiá»‡m á»Ÿ quy mÃ´ lá»›n trÃªn cÃ¡c lÄ©nh vá»±c.

Gáº§n Ä‘Ã¢y, cÃ¡c mÃ´ hÃ¬nh chuá»—i khÃ´ng gian tráº¡ng thÃ¡i cÃ³ cáº¥u trÃºc (SSM) (Gu, Goel, and RÃ© 2022; Gu, Johnson, Goel, et al. 2021) Ä‘Ã£ xuáº¥t hiá»‡n nhÆ° má»™t lá»›p kiáº¿n trÃºc Ä‘áº§y há»©a háº¹n cho mÃ´ hÃ¬nh hÃ³a chuá»—i. CÃ¡c mÃ´ hÃ¬nh nÃ y cÃ³ thá»ƒ Ä‘Æ°á»£c hiá»ƒu nhÆ° má»™t sá»± káº¿t há»£p cá»§a máº¡ng tháº§n kinh há»“i quy (RNN) vÃ  máº¡ng tháº§n kinh tÃ­ch cháº­p (CNN), vá»›i cáº£m há»©ng tá»« cÃ¡c mÃ´ hÃ¬nh khÃ´ng gian tráº¡ng thÃ¡i cá»• Ä‘iá»ƒn (Kalman 1960). Lá»›p mÃ´ hÃ¬nh nÃ y cÃ³ thá»ƒ Ä‘Æ°á»£c tÃ­nh toÃ¡n ráº¥t hiá»‡u quáº£ dÆ°á»›i dáº¡ng há»“i quy hoáº·c tÃ­ch cháº­p, vá»›i tá»· lá»‡ tuyáº¿n tÃ­nh hoáº·c gáº§n tuyáº¿n tÃ­nh theo chiá»u dÃ i chuá»—i. NgoÃ i ra, chÃºng cÃ³ cÃ¡c cÆ¡ cháº¿ cÃ³ nguyÃªn táº¯c Ä‘á»ƒ mÃ´ hÃ¬nh hÃ³a cÃ¡c phá»¥ thuá»™c táº§m xa (Gu, Dao, et al. 2020) trong má»™t sá»‘ phÆ°Æ¡ng thá»©c dá»¯ liá»‡u nháº¥t Ä‘á»‹nh, vÃ  Ä‘Ã£ thá»‘ng trá»‹ cÃ¡c benchmark nhÆ° Long Range Arena (Tay, Dehghani, Abnar, et al. 2021). Nhiá»u hÆ°Æ¡ng vá»‹ cá»§a SSM (Gu, Goel, and RÃ© 2022; Gu, Gupta, et al. 2022; Gupta, Gu, and Berant 2022; Y. Li et al. 2023; Ma et al. 2023; Orvieto et al. 2023; Smith, Warrington, and Linderman 2023) Ä‘Ã£ thÃ nh cÃ´ng trong cÃ¡c lÄ©nh vá»±c liÃªn quan Ä‘áº¿n dá»¯ liá»‡u tÃ­n hiá»‡u liÃªn tá»¥c nhÆ° Ã¢m thanh vÃ  thá»‹ giÃ¡c (Goel et al. 2022; Nguyen, Goel, et al. 2022; Saon, Gupta, and Cui 2023). Tuy nhiÃªn, chÃºng Ã­t hiá»‡u quáº£ hÆ¡n trong viá»‡c mÃ´ hÃ¬nh hÃ³a dá»¯ liá»‡u rá»i ráº¡c vÃ  dÃ y Ä‘áº·c thÃ´ng tin nhÆ° vÄƒn báº£n.

ChÃºng tÃ´i Ä‘á» xuáº¥t má»™t lá»›p mÃ´ hÃ¬nh khÃ´ng gian tráº¡ng thÃ¡i chá»n lá»c má»›i, cáº£i thiá»‡n cÃ¡c cÃ´ng trÃ¬nh trÆ°á»›c Ä‘Ã¢y trÃªn nhiá»u trá»¥c Ä‘á»ƒ Ä‘áº¡t Ä‘Æ°á»£c sá»©c máº¡nh mÃ´ hÃ¬nh cá»§a Transformer trong khi tá»· lá»‡ tuyáº¿n tÃ­nh theo chiá»u dÃ i chuá»—i.

CÆ¡ cháº¿ Chá»n lá»c. Äáº§u tiÃªn, chÃºng tÃ´i xÃ¡c Ä‘á»‹nh má»™t háº¡n cháº¿ chÃ­nh cá»§a cÃ¡c mÃ´ hÃ¬nh trÆ°á»›c Ä‘Ã¢y: kháº£ nÄƒng chá»n lá»c dá»¯ liá»‡u má»™t cÃ¡ch hiá»‡u quáº£ theo cÃ¡ch phá»¥ thuá»™c vÃ o Ä‘áº§u vÃ o (tá»©c lÃ  táº­p trung vÃ o hoáº·c bá» qua cÃ¡c Ä‘áº§u vÃ o cá»¥ thá»ƒ). Dá»±a trÃªn trá»±c giÃ¡c tá»« cÃ¡c tÃ¡c vá»¥ tá»•ng há»£p quan trá»ng nhÆ° sao chÃ©p chá»n lá»c vÃ  Ä‘áº§u cáº£m á»©ng, chÃºng tÃ´i thiáº¿t káº¿ má»™t cÆ¡ cháº¿ chá»n lá»c Ä‘Æ¡n giáº£n báº±ng cÃ¡ch tham sá»‘ hÃ³a cÃ¡c tham sá»‘ SSM dá»±a trÃªn Ä‘áº§u vÃ o. Äiá»u nÃ y cho phÃ©p mÃ´ hÃ¬nh lá»c ra thÃ´ng tin khÃ´ng liÃªn quan vÃ  ghi nhá»› thÃ´ng tin liÃªn quan vÃ´ thá»i háº¡n.

Thuáº­t toÃ¡n Nháº­n biáº¿t Pháº§n cá»©ng. Thay Ä‘á»•i Ä‘Æ¡n giáº£n nÃ y Ä‘áº·t ra má»™t thÃ¡ch thá»©c ká»¹ thuáº­t cho viá»‡c tÃ­nh toÃ¡n mÃ´ hÃ¬nh; thá»±c táº¿, táº¥t cáº£ cÃ¡c mÃ´ hÃ¬nh SSM trÆ°á»›c Ä‘Ã¢y pháº£i báº¥t biáº¿n theo thá»i gian vÃ  Ä‘áº§u vÃ o Ä‘á»ƒ cÃ³ hiá»‡u quáº£ tÃ­nh toÃ¡n. ChÃºng tÃ´i kháº¯c phá»¥c Ä‘iá»u nÃ y báº±ng má»™t thuáº­t toÃ¡n nháº­n biáº¿t pháº§n cá»©ng tÃ­nh toÃ¡n mÃ´ hÃ¬nh má»™t cÃ¡ch há»“i quy vá»›i quÃ©t nhÆ°ng khÃ´ng cá»¥ thá»ƒ hÃ³a tráº¡ng thÃ¡i má»Ÿ rá»™ng Ä‘á»ƒ trÃ¡nh truy cáº­p IO giá»¯a cÃ¡c cáº¥p khÃ¡c nhau cá»§a há»‡ thá»‘ng phÃ¢n cáº¥p bá»™ nhá»› GPU. Viá»‡c triá»ƒn khai káº¿t quáº£ nhanh hÆ¡n cÃ¡c phÆ°Æ¡ng phÃ¡p trÆ°á»›c Ä‘Ã¢y cáº£ vá» lÃ½ thuyáº¿t (tá»· lá»‡ tuyáº¿n tÃ­nh theo chiá»u dÃ i chuá»—i, so vá»›i giáº£ tuyáº¿n tÃ­nh cho táº¥t cáº£ cÃ¡c SSM dá»±a trÃªn tÃ­ch cháº­p) vÃ  trÃªn pháº§n cá»©ng hiá»‡n Ä‘áº¡i (lÃªn Ä‘áº¿n 3Ã— nhanh hÆ¡n trÃªn GPU A100).

Kiáº¿n trÃºc. ChÃºng tÃ´i Ä‘Æ¡n giáº£n hÃ³a cÃ¡c kiáº¿n trÃºc mÃ´ hÃ¬nh chuá»—i sÃ¢u trÆ°á»›c Ä‘Ã¢y báº±ng cÃ¡ch káº¿t há»£p thiáº¿t káº¿ cá»§a cÃ¡c kiáº¿n trÃºc SSM trÆ°á»›c Ä‘Ã¢y (Dao, Fu, Saab, et al. 2023) vá»›i khá»‘i MLP cá»§a Transformer thÃ nh má»™t khá»‘i duy nháº¥t, dáº«n Ä‘áº¿n má»™t thiáº¿t káº¿ kiáº¿n trÃºc Ä‘Æ¡n giáº£n vÃ  Ä‘á»“ng nháº¥t (Mamba) káº¿t há»£p cÃ¡c khÃ´ng gian tráº¡ng thÃ¡i chá»n lá»c.

CÃ¡c SSM chá»n lá»c, vÃ  báº±ng cÃ¡ch má»Ÿ rá»™ng kiáº¿n trÃºc Mamba, lÃ  cÃ¡c mÃ´ hÃ¬nh hoÃ n toÃ n há»“i quy vá»›i cÃ¡c tÃ­nh cháº¥t chÃ­nh lÃ m cho chÃºng phÃ¹ há»£p lÃ m xÆ°Æ¡ng sá»‘ng cá»§a cÃ¡c mÃ´ hÃ¬nh ná»n táº£ng tá»•ng quÃ¡t hoáº¡t Ä‘á»™ng trÃªn cÃ¡c chuá»—i. (i) Cháº¥t lÆ°á»£ng cao: tÃ­nh chá»n lá»c mang láº¡i hiá»‡u suáº¥t máº¡nh máº½ trÃªn cÃ¡c phÆ°Æ¡ng thá»©c dÃ y Ä‘áº·c nhÆ° ngÃ´n ngá»¯ vÃ  di truyá»n há»c. (ii) Huáº¥n luyá»‡n vÃ  suy luáº­n nhanh: tÃ­nh toÃ¡n vÃ  bá»™ nhá»› tá»· lá»‡ tuyáº¿n tÃ­nh theo chiá»u dÃ i chuá»—i trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n, vÃ  viá»‡c triá»ƒn khai mÃ´ hÃ¬nh má»™t cÃ¡ch tá»± há»“i quy trong quÃ¡ trÃ¬nh suy luáº­n chá»‰ yÃªu cáº§u thá»i gian khÃ´ng Ä‘á»•i cho má»—i bÆ°á»›c vÃ¬ nÃ³ khÃ´ng yÃªu cáº§u bá»™ nhá»› Ä‘á»‡m cá»§a cÃ¡c pháº§n tá»­ trÆ°á»›c Ä‘Ã³. (iii) Ngá»¯ cáº£nh dÃ i: cháº¥t lÆ°á»£ng vÃ  hiá»‡u quáº£ cÃ¹ng nhau táº¡o ra cáº£i thiá»‡n hiá»‡u suáº¥t trÃªn dá»¯ liá»‡u thá»±c lÃªn Ä‘áº¿n chiá»u dÃ i chuá»—i 1M.

ChÃºng tÃ´i xÃ¡c thá»±c thá»±c nghiá»‡m tiá»m nÄƒng cá»§a Mamba nhÆ° má»™t xÆ°Æ¡ng sá»‘ng FM chuá»—i tá»•ng quÃ¡t, cáº£ vá» cháº¥t lÆ°á»£ng huáº¥n luyá»‡n trÆ°á»›c vÃ  hiá»‡u suáº¥t tÃ¡c vá»¥ cá»¥ thá»ƒ theo lÄ©nh vá»±c, trÃªn má»™t sá»‘ loáº¡i phÆ°Æ¡ng thá»©c vÃ  cÃ i Ä‘áº·t:

â€¢Tá»•ng há»£p. TrÃªn cÃ¡c tÃ¡c vá»¥ tá»•ng há»£p quan trá»ng nhÆ° sao chÃ©p vÃ  Ä‘áº§u cáº£m á»©ng Ä‘Ã£ Ä‘Æ°á»£c Ä‘á» xuáº¥t lÃ  chÃ¬a khÃ³a cho cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n, Mamba khÃ´ng chá»‰ giáº£i quyáº¿t chÃºng má»™t cÃ¡ch dá»… dÃ ng mÃ  cÃ²n cÃ³ thá»ƒ ngoáº¡i suy cÃ¡c giáº£i phÃ¡p vÃ´ thá»i háº¡n dÃ i (>1M token).

â€¢Ã‚m thanh vÃ  Di truyá»n há»c. Mamba vÆ°á»£t trá»™i hÆ¡n cÃ¡c mÃ´ hÃ¬nh tá»‘t nháº¥t hiá»‡n táº¡i trÆ°á»›c Ä‘Ã¢y nhÆ° SaShiMi, Hyena, vÃ  Transformer trong viá»‡c mÃ´ hÃ¬nh hÃ³a dáº¡ng sÃ³ng Ã¢m thanh vÃ  chuá»—i DNA, cáº£ vá» cháº¥t lÆ°á»£ng huáº¥n luyá»‡n trÆ°á»›c vÃ  cÃ¡c chá»‰ sá»‘ háº¡ nguá»“n (vÃ­ dá»¥: giáº£m FID trÃªn táº­p dá»¯ liá»‡u táº¡o giá»ng nÃ³i thÃ¡ch thá»©c hÆ¡n má»™t ná»­a). Trong cáº£ hai cÃ i Ä‘áº·t, hiá»‡u suáº¥t cá»§a nÃ³ cáº£i thiá»‡n vá»›i ngá»¯ cáº£nh dÃ i hÆ¡n lÃªn Ä‘áº¿n cÃ¡c chuá»—i dÃ i hÃ ng triá»‡u.

â€¢MÃ´ hÃ¬nh hÃ³a NgÃ´n ngá»¯. Mamba lÃ  mÃ´ hÃ¬nh chuá»—i thá»i gian tuyáº¿n tÃ­nh Ä‘áº§u tiÃªn thá»±c sá»± Ä‘áº¡t Ä‘Æ°á»£c hiá»‡u suáº¥t cháº¥t lÆ°á»£ng Transformer, cáº£ vá» perplexity huáº¥n luyá»‡n trÆ°á»›c vÃ  Ä‘Ã¡nh giÃ¡ háº¡ nguá»“n. Vá»›i cÃ¡c luáº­t tá»· lá»‡ lÃªn Ä‘áº¿n 1B tham sá»‘, chÃºng tÃ´i cho tháº¥y Mamba vÆ°á»£t trá»™i hÆ¡n hiá»‡u suáº¥t cá»§a má»™t loáº¡t rá»™ng cÃ¡c baseline, bao gá»“m cÃ¡c cÃ´ng thá»©c huáº¥n luyá»‡n Transformer hiá»‡n Ä‘áº¡i ráº¥t máº¡nh dá»±a trÃªn LLaMa (Touvron et al. 2023). MÃ´ hÃ¬nh ngÃ´n ngá»¯ Mamba cá»§a chÃºng tÃ´i cÃ³ thÃ´ng lÆ°á»£ng táº¡o sinh 5Ã— so vá»›i Transformer cÃ³ kÃ­ch thÆ°á»›c tÆ°Æ¡ng tá»±, vÃ  cháº¥t lÆ°á»£ng cá»§a Mamba-3B tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i Transformer gáº¥p Ä‘Ã´i kÃ­ch thÆ°á»›c cá»§a nÃ³ (vÃ­ dá»¥: cao hÆ¡n 4 Ä‘iá»ƒm trung bÃ¬nh vá» lÃ½ luáº­n thÃ´ng thÆ°á»ng so vá»›i Pythia-3B vÃ  tháº­m chÃ­ vÆ°á»£t trá»™i hÆ¡n Pythia-7B).

MÃ£ mÃ´ hÃ¬nh vÃ  cÃ¡c checkpoint Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c Ä‘Æ°á»£c mÃ£ nguá»“n má»Ÿ táº¡i https://github.com/state-spaces/mamba.

2 MÃ´ hÃ¬nh KhÃ´ng gian Tráº¡ng thÃ¡i
CÃ¡c mÃ´ hÃ¬nh chuá»—i khÃ´ng gian tráº¡ng thÃ¡i cÃ³ cáº¥u trÃºc (S4) lÃ  má»™t lá»›p gáº§n Ä‘Ã¢y cá»§a cÃ¡c mÃ´ hÃ¬nh chuá»—i cho há»c sÃ¢u cÃ³ liÃªn quan rá»™ng rÃ£i Ä‘áº¿n RNN, vÃ  CNN, vÃ  cÃ¡c mÃ´ hÃ¬nh khÃ´ng gian tráº¡ng thÃ¡i cá»• Ä‘iá»ƒn. ChÃºng Ä‘Æ°á»£c láº¥y cáº£m há»©ng bá»Ÿi má»™t há»‡ thá»‘ng liÃªn tá»¥c cá»¥ thá»ƒ (1) Ã¡nh xáº¡ má»™t

--- TRANG 2 ---
hÃ m hoáº·c chuá»—i má»™t chiá»u ğ‘£(ğ‘¡) âˆˆ â„ â†¦ ğ‘¦(ğ‘¡) âˆˆ â„ thÃ´ng qua má»™t tráº¡ng thÃ¡i tiá»m áº©n ngáº§m Ä‘á»‹nh â„(ğ‘¡) âˆˆ â„^ğ‘.

Cá»¥ thá»ƒ, cÃ¡c mÃ´ hÃ¬nh S4 Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a vá»›i bá»‘n tham sá»‘ (Î”, ğ´, ğµ, ğ¶), Ä‘á»‹nh nghÄ©a má»™t phÃ©p biáº¿n Ä‘á»•i chuá»—i-tá»›i-chuá»—i trong hai giai Ä‘oáº¡n.

â„'(ğ‘¡) = ğ´â„(ğ‘¡) + ğµğ‘¥(ğ‘¡) (1a)
ğ‘¦(ğ‘¡) = ğ¶â„(ğ‘¡) (1b)

â„_ğ‘¡ = ğ´â„_{ğ‘¡âˆ’1} + ğµğ‘¥_ğ‘¡ (2a)
ğ‘¦_ğ‘¡ = ğ¶â„_ğ‘¡ (2b)

ğ¾ = (ğ¶ğµ, ğ¶ğ´ğµ, ..., ğ¶ğ´^ğ‘˜ğµ, ...) (3a)
ğ‘¦ = ğ‘¥ âˆ— ğ¾ (3b)

Rá»i ráº¡c hÃ³a. Giai Ä‘oáº¡n Ä‘áº§u tiÃªn biáº¿n Ä‘á»•i cÃ¡c "tham sá»‘ liÃªn tá»¥c" (Î”, ğ´, ğµ) thÃ nh "tham sá»‘ rá»i ráº¡c" (ğ´Ì„, ğµÌ„) thÃ´ng qua cÃ¡c cÃ´ng thá»©c cá»‘ Ä‘á»‹nh ğ´Ì„ = ğ‘“_ğ´(Î”, ğ´) vÃ  ğµÌ„ = ğ‘“_ğµ(Î”, ğ´, ğµ), trong Ä‘Ã³ cáº·p (ğ‘“_ğ´, ğ‘“_ğµ) Ä‘Æ°á»£c gá»i lÃ  quy táº¯c rá»i ráº¡c hÃ³a. CÃ³ thá»ƒ sá»­ dá»¥ng cÃ¡c quy táº¯c khÃ¡c nhau nhÆ° zero-order hold (ZOH) Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a trong phÆ°Æ¡ng trÃ¬nh (4).

ğ´Ì„ = exp(Î”ğ´) ğµÌ„ = (Î”ğ´)^{-1}(exp(Î”ğ´) âˆ’ ğ¼) Â· Î”ğµ (4)

Rá»i ráº¡c hÃ³a cÃ³ cÃ¡c káº¿t ná»‘i sÃ¢u vá»›i cÃ¡c há»‡ thá»‘ng thá»i gian liÃªn tá»¥c cÃ³ thá»ƒ cung cáº¥p cho chÃºng cÃ¡c tÃ­nh cháº¥t bá»• sung nhÆ° báº¥t biáº¿n Ä‘á»™ phÃ¢n giáº£i (Nguyen, Goel, et al. 2022) vÃ  tá»± Ä‘á»™ng Ä‘áº£m báº£o ráº±ng mÃ´ hÃ¬nh Ä‘Æ°á»£c chuáº©n hÃ³a Ä‘Ãºng cÃ¡ch (Gu, Johnson, Timalsina, et al. 2023; Orvieto et al. 2023). NÃ³ cÅ©ng cÃ³ káº¿t ná»‘i vá»›i cÃ¡c cÆ¡ cháº¿ cá»•ng cá»§a RNN (Gu, Gulcehre, et al. 2020; Tallec and Ollivier 2018) mÃ  chÃºng tÃ´i sáº½ xem xÃ©t láº¡i trong Pháº§n 3.5. Tuy nhiÃªn, tá»« gÃ³c Ä‘á»™ cÆ¡ há»c, rá»i ráº¡c hÃ³a cÃ³ thá»ƒ Ä‘Æ°á»£c xem Ä‘Æ¡n giáº£n lÃ  bÆ°á»›c Ä‘áº§u tiÃªn cá»§a Ä‘á»“ thá»‹ tÃ­nh toÃ¡n trong lÆ°á»£t truyá»n xuÃ´i cá»§a má»™t SSM.

CÃ¡c hÆ°Æ¡ng vá»‹ khÃ¡c cá»§a SSM cÃ³ thá»ƒ bá» qua bÆ°á»›c rá»i ráº¡c hÃ³a vÃ  tham sá»‘ hÃ³a (ğ´Ì„, ğµÌ„) trá»±c tiáº¿p thay tháº¿ (Zhang et al. 2023), Ä‘iá»u nÃ y cÃ³ thá»ƒ dá»… lÃ½ luáº­n hÆ¡n.

TÃ­nh toÃ¡n. Sau khi cÃ¡c tham sá»‘ Ä‘Ã£ Ä‘Æ°á»£c biáº¿n Ä‘á»•i tá»« (Î”, ğ´, ğµ, ğ¶) â†¦ (ğ´Ì„, ğµÌ„, ğ¶), mÃ´ hÃ¬nh cÃ³ thá»ƒ Ä‘Æ°á»£c tÃ­nh toÃ¡n theo hai cÃ¡ch, hoáº·c lÃ  nhÆ° má»™t há»“i quy tuyáº¿n tÃ­nh (2) hoáº·c má»™t tÃ­ch cháº­p toÃ n cá»¥c (3).

ThÃ´ng thÆ°á»ng, mÃ´ hÃ¬nh sá»­ dá»¥ng cháº¿ Ä‘á»™ tÃ­ch cháº­p (3) cho huáº¥n luyá»‡n song song hiá»‡u quáº£ (nÆ¡i toÃ n bá»™ chuá»—i Ä‘áº§u vÃ o Ä‘Æ°á»£c nhÃ¬n tháº¥y trÆ°á»›c), vÃ  chuyá»ƒn sang cháº¿ Ä‘á»™ há»“i quy (2) cho suy luáº­n tá»± há»“i quy hiá»‡u quáº£ (nÆ¡i cÃ¡c Ä‘áº§u vÃ o Ä‘Æ°á»£c nhÃ¬n tháº¥y tá»«ng bÆ°á»›c thá»i gian).

TÃ­nh Báº¥t biáº¿n Thá»i gian Tuyáº¿n tÃ­nh (LTI). Má»™t tÃ­nh cháº¥t quan trá»ng cá»§a phÆ°Æ¡ng trÃ¬nh (1) Ä‘áº¿n (3) lÃ  Ä‘á»™ng lá»±c há»c cá»§a mÃ´ hÃ¬nh lÃ  khÃ´ng Ä‘á»•i theo thá»i gian. NÃ³i cÃ¡ch khÃ¡c (Î”, ğ´, ğµ, ğ¶), vÃ  do Ä‘Ã³ (ğ´Ì„, ğµÌ„) cÅ©ng váº­y, Ä‘Æ°á»£c cá»‘ Ä‘á»‹nh cho táº¥t cáº£ cÃ¡c bÆ°á»›c thá»i gian. TÃ­nh cháº¥t nÃ y Ä‘Æ°á»£c gá»i lÃ  tÃ­nh báº¥t biáº¿n thá»i gian tuyáº¿n tÃ­nh (LTI), cÃ³ liÃªn káº¿t sÃ¢u sáº¯c vá»›i há»“i quy vÃ  tÃ­ch cháº­p. KhÃ´ng chÃ­nh thá»©c, chÃºng tÃ´i nghÄ© vá» cÃ¡c SSM LTI nhÆ° tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i báº¥t ká»³ há»“i quy tuyáº¿n tÃ­nh (2a) hoáº·c tÃ­ch cháº­p (3b), vÃ  sá»­ dá»¥ng LTI nhÆ° má»™t thuáº­t ngá»¯ tá»•ng quÃ¡t cho cÃ¡c lá»›p mÃ´ hÃ¬nh nÃ y.

Cho Ä‘áº¿n nay, táº¥t cáº£ cÃ¡c SSM cÃ³ cáº¥u trÃºc Ä‘á»u lÃ  LTI (vÃ­ dá»¥: Ä‘Æ°á»£c tÃ­nh toÃ¡n nhÆ° tÃ­ch cháº­p) do cÃ¡c rÃ ng buá»™c hiá»‡u quáº£ cÆ¡ báº£n, Ä‘Æ°á»£c tháº£o luáº­n trong Pháº§n 3.3. Tuy nhiÃªn, má»™t cÃ¡i nhÃ¬n sÃ¢u sáº¯c cá»‘t lÃµi cá»§a cÃ´ng trÃ¬nh nÃ y lÃ  cÃ¡c mÃ´ hÃ¬nh LTI cÃ³ nhá»¯ng háº¡n cháº¿ cÆ¡ báº£n trong viá»‡c mÃ´ hÃ¬nh hÃ³a má»™t sá»‘ loáº¡i dá»¯ liá»‡u nháº¥t Ä‘á»‹nh, vÃ  cÃ¡c Ä‘Ã³ng gÃ³p ká»¹ thuáº­t cá»§a chÃºng tÃ´i liÃªn quan Ä‘áº¿n viá»‡c loáº¡i bá» rÃ ng buá»™c LTI trong khi kháº¯c phá»¥c cÃ¡c rÃ o cáº£n hiá»‡u quáº£.

Cáº¥u trÃºc vÃ  KÃ­ch thÆ°á»›c. Cuá»‘i cÃ¹ng, chÃºng tÃ´i lÆ°u Ã½ ráº±ng cÃ¡c SSM cÃ³ cáº¥u trÃºc Ä‘Æ°á»£c Ä‘áº·t tÃªn nhÆ° váº­y vÃ¬ viá»‡c tÃ­nh toÃ¡n chÃºng má»™t cÃ¡ch hiá»‡u quáº£ cÅ©ng Ä‘Ã²i há»i pháº£i Ã¡p Ä‘áº·t cáº¥u trÃºc trÃªn ma tráº­n ğ´. HÃ¬nh thá»©c cáº¥u trÃºc phá»• biáº¿n nháº¥t lÃ  Ä‘Æ°á»ng chÃ©o (Gu, Gupta, et al. 2022; Gupta, Gu, and Berant 2022; Smith, Warrington, and Linderman 2023), mÃ  chÃºng tÃ´i cÅ©ng sá»­ dá»¥ng.

Trong trÆ°á»ng há»£p nÃ y, cÃ¡c ma tráº­n ğ´ âˆˆ â„^{ğ‘Ã—ğ‘}, ğµ âˆˆ â„^{ğ‘Ã—1}, ğ¶ âˆˆ â„^{1Ã—ğ‘} Ä‘á»u cÃ³ thá»ƒ Ä‘Æ°á»£c biá»ƒu diá»…n báº±ng ğ‘ sá»‘. Äá»ƒ hoáº¡t Ä‘á»™ng trÃªn má»™t chuá»—i Ä‘áº§u vÃ o ğ‘¥ cÃ³ kÃ­ch thÆ°á»›c batch ğµ vÃ  chiá»u dÃ i ğ¿ vá»›i ğ· kÃªnh, SSM Ä‘Æ°á»£c Ã¡p dá»¥ng Ä‘á»™c láº­p cho tá»«ng kÃªnh. LÆ°u Ã½ ráº±ng trong trÆ°á»ng há»£p nÃ y, tá»•ng tráº¡ng thÃ¡i áº©n cÃ³ chiá»u ğ·ğ‘ cho má»—i Ä‘áº§u vÃ o, vÃ  viá»‡c tÃ­nh toÃ¡n nÃ³ trÃªn chiá»u dÃ i chuá»—i yÃªu cáº§u ğ‘‚(ğµğ¿ğ·ğ‘) thá»i gian vÃ  bá»™ nhá»›; Ä‘Ã¢y lÃ  gá»‘c rá»… cá»§a rÃ o cáº£n hiá»‡u quáº£ cÆ¡ báº£n Ä‘Æ°á»£c giáº£i quyáº¿t trong Pháº§n 3.3.

MÃ´ hÃ¬nh KhÃ´ng gian Tráº¡ng thÃ¡i Tá»•ng quÃ¡t. ChÃºng tÃ´i lÆ°u Ã½ ráº±ng thuáº­t ngá»¯ mÃ´ hÃ¬nh khÃ´ng gian tráº¡ng thÃ¡i cÃ³ nghÄ©a ráº¥t rá»™ng chá»‰ Ä‘Æ¡n giáº£n Ä‘áº¡i diá»‡n cho khÃ¡i niá»‡m vá» báº¥t ká»³ quÃ¡ trÃ¬nh há»“i quy nÃ o vá»›i tráº¡ng thÃ¡i tiá»m áº©n. NÃ³ Ä‘Ã£ Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ chá»‰ nhiá»u khÃ¡i niá»‡m khÃ¡c nhau trong cÃ¡c ngÃ nh khÃ¡c nhau, bao gá»“m cÃ¡c quÃ¡ trÃ¬nh quyáº¿t Ä‘á»‹nh Markov (MDP) (há»c tÄƒng cÆ°á»ng (Hafner et al. 2020)), mÃ´ hÃ¬nh nguyÃªn nhÃ¢n Ä‘á»™ng (DCM) (tháº§n kinh há»c tÃ­nh toÃ¡n (Friston, Harrison, and Penny 2003)), bá»™ lá»c Kalman (Ä‘iá»u khiá»ƒn (Kalman 1960)), mÃ´ hÃ¬nh Markov áº©n (HMM) vÃ  há»‡ thá»‘ng Ä‘á»™ng lá»±c há»c tuyáº¿n tÃ­nh (LDS) (há»c mÃ¡y), vÃ  cÃ¡c mÃ´ hÃ¬nh há»“i quy (vÃ  Ä‘Ã´i khi tÃ­ch cháº­p) nÃ³i chung (há»c sÃ¢u).

Trong suá»‘t toÃ n bá»™ bÃ i bÃ¡o nÃ y, chÃºng tÃ´i sá»­ dá»¥ng thuáº­t ngá»¯ "SSM" Ä‘á»ƒ chá»‰ Ä‘á»™c quyá»n lá»›p SSM cÃ³ cáº¥u trÃºc hoáº·c mÃ´ hÃ¬nh S4 (Gu, Goel, and RÃ© 2022; Gu, Gupta, et al. 2022; Gupta, Gu, and Berant 2022; Hasani et al. 2023; Ma et al. 2023; Smith, Warrington, and Linderman 2023) vÃ  sá»­ dá»¥ng cÃ¡c thuáº­t ngá»¯ nÃ y má»™t cÃ¡ch thay tháº¿ Ä‘Æ°á»£c. Äá»ƒ thuáº­n tiá»‡n, chÃºng tÃ´i cÅ©ng cÃ³ thá»ƒ bao gá»“m cÃ¡c dáº«n xuáº¥t cá»§a cÃ¡c mÃ´ hÃ¬nh nhÆ° váº­y, cháº³ng háº¡n nhÆ° nhá»¯ng mÃ´ hÃ¬nh táº­p trung vÃ o quan Ä‘iá»ƒm há»“i quy tuyáº¿n tÃ­nh hoáº·c tÃ­ch cháº­p toÃ n cá»¥c (Y. Li et al. 2023; Orvieto et al. 2023; Poli et al. 2023), vÃ  lÃ m rÃµ cÃ¡c sáº¯c thÃ¡i khi cáº§n thiáº¿t.

Kiáº¿n trÃºc SSM. SSM lÃ  cÃ¡c phÃ©p biáº¿n Ä‘á»•i chuá»—i Ä‘á»™c láº­p cÃ³ thá»ƒ Ä‘Æ°á»£c káº¿t há»£p vÃ o cÃ¡c kiáº¿n trÃºc máº¡ng tháº§n kinh Ä‘áº§u cuá»‘i Ä‘áº¿n Ä‘áº§u cuá»‘i. (ChÃºng tÃ´i cÅ©ng Ä‘Ã´i khi gá»i cÃ¡c kiáº¿n trÃºc SSM lÃ  SSNN, tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i cÃ¡c lá»›p SSM nhÆ° CNN Ä‘á»‘i vá»›i cÃ¡c lá»›p tÃ­ch cháº­p tuyáº¿n tÃ­nh.) ChÃºng tÃ´i tháº£o luáº­n vá» má»™t sá»‘ kiáº¿n trÃºc SSM ná»•i tiáº¿ng nháº¥t, nhiá»u trong sá»‘ Ä‘Ã³ cÅ©ng sáº½ phá»¥c vá»¥ nhÆ° cÃ¡c baseline chÃ­nh cá»§a chÃºng tÃ´i.

â€¢ChÃº Ã½ tuyáº¿n tÃ­nh (Katharopoulos et al. 2020) lÃ  má»™t xáº¥p xá»‰ cá»§a tá»± chÃº Ã½ liÃªn quan Ä‘áº¿n má»™t há»“i quy cÃ³ thá»ƒ Ä‘Æ°á»£c xem nhÆ° má»™t SSM tuyáº¿n tÃ­nh suy biáº¿n.

â€¢H3 (Dao, Fu, Saab, et al. 2023) khÃ¡i quÃ¡t hÃ³a há»“i quy nÃ y Ä‘á»ƒ sá»­ dá»¥ng S4; nÃ³ cÃ³ thá»ƒ Ä‘Æ°á»£c xem nhÆ° má»™t kiáº¿n trÃºc vá»›i má»™t SSM Ä‘Æ°á»£c káº¹p bá»Ÿi hai káº¿t ná»‘i cÃ³ cá»•ng (HÃ¬nh 3). H3 cÅ©ng chÃ¨n má»™t tÃ­ch cháº­p cá»¥c bá»™ tiÃªu chuáº©n, mÃ  há» Ä‘Ã³ng khung nhÆ° má»™t shift-SSM, trÆ°á»›c lá»›p SSM chÃ­nh.

â€¢Hyena (Poli et al. 2023) sá»­ dá»¥ng cÃ¹ng kiáº¿n trÃºc nhÆ° H3 nhÆ°ng thay tháº¿ lá»›p S4 báº±ng má»™t tÃ­ch cháº­p toÃ n cá»¥c Ä‘Æ°á»£c tham sá»‘ hÃ³a MLP (Romero et al. 2021).

â€¢RetNet (Y. Sun et al. 2023) thÃªm má»™t cá»•ng bá»• sung vÃ o kiáº¿n trÃºc vÃ  sá»­ dá»¥ng má»™t SSM Ä‘Æ¡n giáº£n hÆ¡n, cho phÃ©p má»™t Ä‘Æ°á»ng tÃ­nh toÃ¡n song song thay tháº¿, sá»­ dá»¥ng má»™t biáº¿n thá»ƒ cá»§a chÃº Ã½ Ä‘a Ä‘áº§u (MHA) thay vÃ¬ tÃ­ch cháº­p.

â€¢RWKV (B. Peng et al. 2023) lÃ  má»™t RNN gáº§n Ä‘Ã¢y Ä‘Æ°á»£c thiáº¿t káº¿ cho mÃ´ hÃ¬nh hÃ³a ngÃ´n ngá»¯ dá»±a trÃªn má»™t xáº¥p xá»‰ chÃº Ã½ tuyáº¿n tÃ­nh khÃ¡c, Transformer khÃ´ng chÃº Ã½ (S. Zhai et al. 2021). CÆ¡ cháº¿ "WKV" chÃ­nh cá»§a nÃ³ liÃªn quan Ä‘áº¿n cÃ¡c há»“i quy LTI vÃ  cÃ³ thá»ƒ Ä‘Æ°á»£c xem nhÆ° tá»· lá»‡ cá»§a hai SSM.

CÃ¡c SSM vÃ  kiáº¿n trÃºc liÃªn quan khÃ¡c Ä‘Æ°á»£c tháº£o luáº­n thÃªm trong pháº§n cÃ´ng trÃ¬nh liÃªn quan má»Ÿ rá»™ng (Phá»¥ lá»¥c B). ChÃºng tÃ´i Ä‘áº·c biá»‡t nháº¥n máº¡nh S5 (Smith, Warrington, and Linderman 2023), QRNN (Bradbury et al. 2016), vÃ  SRU (Lei et al. 2017), mÃ  chÃºng tÃ´i xem nhÆ° cÃ¡c phÆ°Æ¡ng phÃ¡p liÃªn quan cháº·t cháº½ nháº¥t vá»›i SSM chá»n lá»c cá»‘t lÃµi cá»§a chÃºng tÃ´i.

--- TRANG 3 ---
3 MÃ´ hÃ¬nh KhÃ´ng gian Tráº¡ng thÃ¡i Chá»n lá»c

ChÃºng tÃ´i thÃºc Ä‘áº©y cÆ¡ cháº¿ chá»n lá»c cá»§a mÃ¬nh báº±ng cÃ¡ch sá»­ dá»¥ng trá»±c giÃ¡c tá»« cÃ¡c tÃ¡c vá»¥ tá»•ng há»£p (Pháº§n 3.1), sau Ä‘Ã³ giáº£i thÃ­ch cÃ¡ch káº¿t há»£p cÆ¡ cháº¿ nÃ y vÃ o cÃ¡c mÃ´ hÃ¬nh khÃ´ng gian tráº¡ng thÃ¡i (Pháº§n 3.2). CÃ¡c SSM biáº¿n Ä‘á»•i theo thá»i gian káº¿t quáº£ khÃ´ng thá»ƒ sá»­ dá»¥ng tÃ­ch cháº­p, Ä‘áº·t ra má»™t thÃ¡ch thá»©c ká»¹ thuáº­t vá» cÃ¡ch tÃ­nh toÃ¡n chÃºng má»™t cÃ¡ch hiá»‡u quáº£. ChÃºng tÃ´i kháº¯c phá»¥c Ä‘iá»u nÃ y báº±ng má»™t thuáº­t toÃ¡n nháº­n biáº¿t pháº§n cá»©ng khai thÃ¡c há»‡ thá»‘ng phÃ¢n cáº¥p bá»™ nhá»› trÃªn pháº§n cá»©ng hiá»‡n Ä‘áº¡i (Pháº§n 3.3). Sau Ä‘Ã³ chÃºng tÃ´i mÃ´ táº£ má»™t kiáº¿n trÃºc SSM Ä‘Æ¡n giáº£n mÃ  khÃ´ng cÃ³ chÃº Ã½ hoáº·c tháº­m chÃ­ cÃ¡c khá»‘i MLP (Pháº§n 3.4). Cuá»‘i cÃ¹ng, chÃºng tÃ´i tháº£o luáº­n vá» má»™t sá»‘ tÃ­nh cháº¥t bá»• sung cá»§a cÃ¡c cÆ¡ cháº¿ chá»n lá»c (Pháº§n 3.5).

3.1 Äá»™ng lá»±c: Chá»n lá»c nhÆ° má»™t PhÆ°Æ¡ng tiá»‡n NÃ©n

ChÃºng tÃ´i láº­p luáº­n ráº±ng má»™t váº¥n Ä‘á» cÆ¡ báº£n cá»§a mÃ´ hÃ¬nh hÃ³a chuá»—i lÃ  nÃ©n ngá»¯ cáº£nh thÃ nh má»™t tráº¡ng thÃ¡i nhá» hÆ¡n. Thá»±c táº¿, chÃºng ta cÃ³ thá»ƒ xem cÃ¡c sá»± Ä‘Ã¡nh Ä‘á»•i cá»§a cÃ¡c mÃ´ hÃ¬nh chuá»—i phá»• biáº¿n tá»« quan Ä‘iá»ƒm nÃ y. VÃ­ dá»¥, chÃº Ã½ vá»«a hiá»‡u quáº£ vá»«a khÃ´ng hiá»‡u quáº£ vÃ¬ nÃ³ rÃµ rÃ ng khÃ´ng nÃ©n ngá»¯ cáº£nh chÃºt nÃ o. Äiá»u nÃ y cÃ³ thá»ƒ Ä‘Æ°á»£c tháº¥y tá»« thá»±c táº¿ lÃ  suy luáº­n tá»± há»“i quy yÃªu cáº§u lÆ°u trá»¯ rÃµ rÃ ng toÃ n bá»™ ngá»¯ cáº£nh (tá»©c lÃ  bá»™ nhá»› Ä‘á»‡m KV), Ä‘iá»u nÃ y trá»±c tiáº¿p gÃ¢y ra suy luáº­n thá»i gian tuyáº¿n tÃ­nh cháº­m vÃ  huáº¥n luyá»‡n thá»i gian báº­c hai cá»§a Transformer. Máº·t khÃ¡c, cÃ¡c mÃ´ hÃ¬nh há»“i quy hiá»‡u quáº£ vÃ¬ chÃºng cÃ³ tráº¡ng thÃ¡i há»¯u háº¡n, ngá»¥ Ã½ suy luáº­n thá»i gian khÃ´ng Ä‘á»•i vÃ  huáº¥n luyá»‡n thá»i gian tuyáº¿n tÃ­nh. Tuy nhiÃªn, hiá»‡u quáº£ cá»§a chÃºng bá»‹ giá»›i háº¡n bá»Ÿi má»©c Ä‘á»™ tá»‘t mÃ  tráº¡ng thÃ¡i nÃ y Ä‘Ã£ nÃ©n ngá»¯ cáº£nh.

Äá»ƒ hiá»ƒu nguyÃªn táº¯c nÃ y, chÃºng tÃ´i táº­p trung vÃ o hai vÃ­ dá»¥ cháº¡y cá»§a cÃ¡c tÃ¡c vá»¥ tá»•ng há»£p (HÃ¬nh 2).

â€¢TÃ¡c vá»¥ Sao chÃ©p Chá»n lá»c sá»­a Ä‘á»•i tÃ¡c vá»¥ Sao chÃ©p phá»• biáº¿n (Arjovsky, Shah, and Bengio 2016) báº±ng cÃ¡ch thay Ä‘á»•i vá»‹ trÃ­ cá»§a cÃ¡c token cáº§n ghi nhá»›. NÃ³ yÃªu cáº§u lÃ½ luáº­n nháº­n thá»©c ná»™i dung Ä‘á»ƒ cÃ³ thá»ƒ ghi nhá»› cÃ¡c token liÃªn quan (cÃ³ mÃ u) vÃ  lá»c ra nhá»¯ng token khÃ´ng liÃªn quan (tráº¯ng).

â€¢TÃ¡c vá»¥ Äáº§u Cáº£m á»©ng lÃ  má»™t cÆ¡ cháº¿ ná»•i tiáº¿ng Ä‘Æ°á»£c giáº£ Ä‘á»‹nh Ä‘á»ƒ giáº£i thÃ­ch pháº§n lá»›n kháº£ nÄƒng há»c trong ngá»¯ cáº£nh cá»§a LLM (Olsson et al. 2022). NÃ³ yÃªu cáº§u lÃ½ luáº­n nháº­n thá»©c ngá»¯ cáº£nh Ä‘á»ƒ biáº¿t khi nÃ o táº¡o ra Ä‘áº§u ra Ä‘Ãºng trong ngá»¯ cáº£nh thÃ­ch há»£p (Ä‘en).

CÃ¡c tÃ¡c vá»¥ nÃ y tiáº¿t lá»™ cháº¿ Ä‘á»™ tháº¥t báº¡i cá»§a cÃ¡c mÃ´ hÃ¬nh LTI. Tá»« quan Ä‘iá»ƒm há»“i quy, Ä‘á»™ng lá»±c há»c khÃ´ng Ä‘á»•i cá»§a chÃºng (vÃ­ dá»¥: cÃ¡c chuyá»ƒn Ä‘á»•i (ğ´Ì„, ğµÌ„) trong (2)) khÃ´ng thá»ƒ cho phÃ©p chÃºng chá»n thÃ´ng tin Ä‘Ãºng tá»« ngá»¯ cáº£nh cá»§a chÃºng, hoáº·c áº£nh hÆ°á»Ÿng Ä‘áº¿n tráº¡ng thÃ¡i áº©n Ä‘Æ°á»£c truyá»n dá»c theo chuá»—i theo cÃ¡ch phá»¥ thuá»™c vÃ o Ä‘áº§u vÃ o. Tá»« quan Ä‘iá»ƒm tÃ­ch cháº­p, Ä‘Æ°á»£c biáº¿t ráº±ng cÃ¡c tÃ­ch cháº­p toÃ n cá»¥c cÃ³ thá»ƒ giáº£i quyáº¿t tÃ¡c vá»¥ Sao chÃ©p vanilla (Romero et al. 2021) vÃ¬ nÃ³ chá»‰ yÃªu cáº§u nháº­n thá»©c thá»i gian, nhÆ°ng chÃºng gáº·p khÃ³ khÄƒn vá»›i tÃ¡c vá»¥ Sao chÃ©p Chá»n lá»c vÃ¬ thiáº¿u nháº­n thá»©c ná»™i dung (HÃ¬nh 2). Cá»¥ thá»ƒ hÆ¡n, khoáº£ng cÃ¡ch giá»¯a Ä‘áº§u vÃ o-Ä‘áº¿n-Ä‘áº§u ra Ä‘ang thay Ä‘á»•i vÃ  khÃ´ng thá»ƒ Ä‘Æ°á»£c mÃ´ hÃ¬nh hÃ³a bá»Ÿi cÃ¡c kernel tÃ­ch cháº­p tÄ©nh.

TÃ³m láº¡i, sá»± Ä‘Ã¡nh Ä‘á»•i hiá»‡u quáº£ so vá»›i hiá»‡u quáº£ cá»§a cÃ¡c mÃ´ hÃ¬nh chuá»—i Ä‘Æ°á»£c Ä‘áº·c trÆ°ng bá»Ÿi má»©c Ä‘á»™ chÃºng nÃ©n tráº¡ng thÃ¡i cá»§a chÃºng: cÃ¡c mÃ´ hÃ¬nh hiá»‡u quáº£ pháº£i cÃ³ tráº¡ng thÃ¡i nhá», trong khi cÃ¡c mÃ´ hÃ¬nh hiá»‡u quáº£ pháº£i cÃ³ tráº¡ng thÃ¡i chá»©a táº¥t cáº£ thÃ´ng tin cáº§n thiáº¿t tá»« ngá»¯ cáº£nh. Äá»•i láº¡i, chÃºng tÃ´i Ä‘á» xuáº¥t ráº±ng má»™t nguyÃªn táº¯c cÆ¡ báº£n Ä‘á»ƒ xÃ¢y dá»±ng cÃ¡c mÃ´ hÃ¬nh chuá»—i lÃ  tÃ­nh chá»n lá»c: hoáº·c kháº£ nÄƒng nháº­n thá»©c ngá»¯ cáº£nh Ä‘á»ƒ táº­p trung vÃ o hoáº·c lá»c ra cÃ¡c Ä‘áº§u vÃ o thÃ nh má»™t tráº¡ng thÃ¡i tuáº§n tá»±. Äáº·c biá»‡t, má»™t cÆ¡ cháº¿ chá»n lá»c kiá»ƒm soÃ¡t cÃ¡ch thÃ´ng tin truyá»n hoáº·c tÆ°Æ¡ng tÃ¡c dá»c theo chiá»u chuá»—i (xem Pháº§n 3.5 Ä‘á»ƒ tháº£o luáº­n thÃªm).

3.2 Cáº£i thiá»‡n SSM vá»›i Chá»n lá»c

Má»™t phÆ°Æ¡ng phÃ¡p káº¿t há»£p cÆ¡ cháº¿ chá»n lá»c vÃ o cÃ¡c mÃ´ hÃ¬nh lÃ  Ä‘á»ƒ cÃ¡c tham sá»‘ cá»§a chÃºng áº£nh hÆ°á»Ÿng Ä‘áº¿n cÃ¡c tÆ°Æ¡ng tÃ¡c dá»c theo chuá»—i (vÃ­ dá»¥: Ä‘á»™ng lá»±c há»c há»“i quy cá»§a RNN hoáº·c kernel tÃ­ch cháº­p cá»§a CNN) phá»¥ thuá»™c vÃ o Ä‘áº§u vÃ o.

Thuáº­t toÃ¡n 1 vÃ  2 minh há»a cÆ¡ cháº¿ chá»n lá»c chÃ­nh mÃ  chÃºng tÃ´i sá»­ dá»¥ng. Sá»± khÃ¡c biá»‡t chÃ­nh lÃ  Ä‘Æ¡n giáº£n lÃ m cho má»™t sá»‘ tham sá»‘ Î”, ğµ, ğ¶ trá»Ÿ thÃ nh hÃ m cá»§a Ä‘áº§u vÃ o, cÃ¹ng vá»›i cÃ¡c thay Ä‘á»•i liÃªn quan Ä‘áº¿n hÃ¬nh dáº¡ng tensor trong suá»‘t. Äáº·c biá»‡t, chÃºng tÃ´i nháº¥n máº¡nh ráº±ng cÃ¡c tham sá»‘ nÃ y bÃ¢y giá» cÃ³ chiá»u dÃ i ğ¿, cÃ³ nghÄ©a lÃ  mÃ´ hÃ¬nh Ä‘Ã£ thay Ä‘á»•i tá»« báº¥t biáº¿n thá»i gian thÃ nh biáº¿n Ä‘á»•i theo thá»i gian. (LÆ°u Ã½ ráº±ng cÃ¡c chÃº thÃ­ch hÃ¬nh dáº¡ng Ä‘Æ°á»£c mÃ´ táº£ trong Pháº§n 2.) Äiá»u nÃ y máº¥t Ä‘i sá»± tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i tÃ­ch cháº­p (3) vá»›i cÃ¡c tÃ¡c Ä‘á»™ng Ä‘áº¿n hiá»‡u quáº£ cá»§a nÃ³, Ä‘Æ°á»£c tháº£o luáº­n tiáº¿p theo.

ChÃºng tÃ´i cá»¥ thá»ƒ chá»n ğ‘ _ğµ(ğ‘¥) = Linear_ğ‘(ğ‘¥), ğ‘ _ğ¶(ğ‘¥) = Linear_ğ‘(ğ‘¥), ğ‘ _Î”(ğ‘¥) = Broadcast_ğ·(Linear_1(ğ‘¥)), vÃ  ğœ_Î” = softplus, trong Ä‘Ã³ Linear_ğ‘‘ lÃ  má»™t phÃ©p chiáº¿u cÃ³ tham sá»‘ Ä‘áº¿n chiá»u ğ‘‘. Sá»± lá»±a chá»n cá»§a ğ‘ _Î” vÃ  ğœ_Î” lÃ  do má»™t káº¿t ná»‘i vá»›i cÃ¡c cÆ¡ cháº¿ cá»•ng RNN Ä‘Æ°á»£c giáº£i thÃ­ch trong Pháº§n 3.5.

--- TRANG 4 ---
Thuáº­t toÃ¡n 1 SSM (S4)
Äáº§u vÃ o: ğ‘¥: (B, L, D)
Äáº§u ra: ğ‘¦: (B, L, D)
1: ğ´: (D, N) â† Parameter âŠ³ Äáº¡i diá»‡n cho ma tráº­n cÃ³ cáº¥u trÃºc ğ‘ Ã— ğ‘
2: ğµ: (D, N) â† Parameter
3: ğ¶: (D, N) â† Parameter
4: Î”: (D) â† ğœ_Î”(Parameter)
5: ğ´Ì„, ğµÌ„: (D, N) â† discretize(Î”, ğ´, ğµ)
6: ğ‘¦ â† SSM(ğ´Ì„, ğµÌ„, ğ¶)(ğ‘¥) âŠ³ Báº¥t biáº¿n thá»i gian: há»“i quy hoáº·c tÃ­ch cháº­p
7: return ğ‘¦

Thuáº­t toÃ¡n 2 SSM + Chá»n lá»c (S6)
Äáº§u vÃ o: ğ‘¥: (B, L, D)
Äáº§u ra: ğ‘¦: (B, L, D)
1: ğ´: (D, N) â† Parameter âŠ³ Äáº¡i diá»‡n cho ma tráº­n cÃ³ cáº¥u trÃºc ğ‘ Ã— ğ‘
2: ğµ: (B, L, N) â† ğ‘ _ğµ(ğ‘¥)
3: ğ¶: (B, L, N) â† ğ‘ _ğ¶(ğ‘¥)
4: Î”: (B, L, D) â† ğœ_Î”(Parameter + ğ‘ _Î”(ğ‘¥))
5: ğ´Ì„, ğµÌ„: (B, L, D, N) â† discretize(Î”, ğ´, ğµ)
6: ğ‘¦ â† SSM(ğ´Ì„, ğµÌ„, ğ¶)(ğ‘¥) âŠ³ Biáº¿n Ä‘á»•i theo thá»i gian: chá»‰ há»“i quy (scan)
7: return ğ‘¦

3.3 Triá»ƒn khai Hiá»‡u quáº£ cá»§a SSM Chá»n lá»c

CÃ¡c primitive thÃ¢n thiá»‡n vá»›i pháº§n cá»©ng nhÆ° tÃ­ch cháº­p (Krizhevsky, Sutskever, and Hinton 2012) vÃ  chÃº Ã½ (Bahdanau, Cho, and Bengio 2015; Vaswani et al. 2017) Ä‘Æ°á»£c á»©ng dá»¥ng rá»™ng rÃ£i. á» Ä‘Ã¢y chÃºng tÃ´i nháº±m má»¥c Ä‘Ã­ch lÃ m cho cÃ¡c SSM chá»n lá»c hiá»‡u quáº£ trÃªn pháº§n cá»©ng hiá»‡n Ä‘áº¡i (GPU) cÅ©ng váº­y. CÆ¡ cháº¿ chá»n lá»c khÃ¡ tá»± nhiÃªn, vÃ  cÃ¡c cÃ´ng trÃ¬nh trÆ°á»›c Ä‘Ã¢y Ä‘Ã£ cá»‘ gáº¯ng káº¿t há»£p cÃ¡c trÆ°á»ng há»£p Ä‘áº·c biá»‡t cá»§a chá»n lá»c, cháº³ng háº¡n nhÆ° Ä‘á»ƒ Î” thay Ä‘á»•i theo thá»i gian trong cÃ¡c SSM há»“i quy (Gu, Dao, et al. 2020). Tuy nhiÃªn, nhÆ° Ä‘Ã£ Ä‘á» cáº­p trÆ°á»›c Ä‘Ã¢y, má»™t háº¡n cháº¿ cá»‘t lÃµi trong viá»‡c sá»­ dá»¥ng SSM lÃ  hiá»‡u quáº£ tÃ­nh toÃ¡n cá»§a chÃºng, Ä‘Ã¢y lÃ  lÃ½ do táº¡i sao S4 vÃ  táº¥t cáº£ cÃ¡c dáº«n xuáº¥t Ä‘á»u sá»­ dá»¥ng cÃ¡c mÃ´ hÃ¬nh LTI (khÃ´ng chá»n lá»c), thÆ°á»ng nháº¥t lÃ  dÆ°á»›i dáº¡ng tÃ­ch cháº­p toÃ n cá»¥c.

3.3.1 Äá»™ng lá»±c cá»§a CÃ¡c MÃ´ hÃ¬nh TrÆ°á»›c Ä‘Ã¢y

TrÆ°á»›c tiÃªn chÃºng tÃ´i xem xÃ©t láº¡i Ä‘á»™ng lá»±c nÃ y vÃ  tá»•ng quan vá» cÃ¡ch tiáº¿p cáº­n cá»§a chÃºng tÃ´i Ä‘á»ƒ kháº¯c phá»¥c cÃ¡c háº¡n cháº¿ cá»§a cÃ¡c phÆ°Æ¡ng phÃ¡p trÆ°á»›c Ä‘Ã¢y.

â€¢á» cáº¥p Ä‘á»™ cao, cÃ¡c mÃ´ hÃ¬nh há»“i quy nhÆ° SSM luÃ´n cÃ¢n báº±ng má»™t sá»± Ä‘Ã¡nh Ä‘á»•i giá»¯a tÃ­nh biá»ƒu Ä‘áº¡t vÃ  tá»‘c Ä‘á»™: nhÆ° Ä‘Ã£ tháº£o luáº­n trong Pháº§n 3.1, cÃ¡c mÃ´ hÃ¬nh vá»›i chiá»u tráº¡ng thÃ¡i áº©n lá»›n hÆ¡n sáº½ hiá»‡u quáº£ hÆ¡n nhÆ°ng cháº­m hÆ¡n. VÃ¬ váº­y chÃºng tÃ´i muá»‘n tá»‘i Ä‘a hÃ³a chiá»u tráº¡ng thÃ¡i áº©n mÃ  khÃ´ng pháº£i tráº£ chi phÃ­ tá»‘c Ä‘á»™ vÃ  bá»™ nhá»›.

â€¢LÆ°u Ã½ ráº±ng cháº¿ Ä‘á»™ há»“i quy linh hoáº¡t hÆ¡n cháº¿ Ä‘á»™ tÃ­ch cháº­p, vÃ¬ cÃ¡i sau (3) Ä‘Æ°á»£c dáº«n xuáº¥t tá»« viá»‡c má»Ÿ rá»™ng cÃ¡i trÆ°á»›c (2) (Gu, Goel, and RÃ© 2022; Gu, Johnson, Goel, et al. 2021). Tuy nhiÃªn, Ä‘iá»u nÃ y sáº½ yÃªu cáº§u tÃ­nh toÃ¡n vÃ  cá»¥ thá»ƒ hÃ³a tráº¡ng thÃ¡i tiá»m áº©n â„ vá»›i hÃ¬nh dáº¡ng (B, L, D, N), lá»›n hÆ¡n nhiá»u (báº±ng má»™t yáº¿u tá»‘ cá»§a ğ‘, chiá»u tráº¡ng thÃ¡i SSM) so vá»›i Ä‘áº§u vÃ o ğ‘¥ vÃ  Ä‘áº§u ra ğ‘¦ cÃ³ hÃ¬nh dáº¡ng (B, L, D). VÃ¬ váº­y cháº¿ Ä‘á»™ tÃ­ch cháº­p hiá»‡u quáº£ hÆ¡n Ä‘Æ°á»£c giá»›i thiá»‡u cÃ³ thá»ƒ bá» qua tÃ­nh toÃ¡n tráº¡ng thÃ¡i vÃ  cá»¥ thá»ƒ hÃ³a má»™t kernel tÃ­ch cháº­p (3a) chá»‰ cÃ³ kÃ­ch thÆ°á»›c (B, L, D).

â€¢CÃ¡c mÃ´ hÃ¬nh khÃ´ng gian tráº¡ng thÃ¡i LTI trÆ°á»›c Ä‘Ã¢y táº­n dá»¥ng cÃ¡c dáº¡ng há»“i quy-tÃ­ch cháº­p kÃ©p Ä‘á»ƒ tÄƒng chiá»u tráº¡ng thÃ¡i hiá»‡u quáº£ báº±ng má»™t yáº¿u tá»‘ cá»§a ğ‘ (â‰ˆ 10âˆ’100), lá»›n hÆ¡n nhiá»u so vá»›i RNN truyá»n thá»‘ng, mÃ  khÃ´ng cÃ³ hÃ¬nh pháº¡t hiá»‡u quáº£.

3.3.2 Tá»•ng quan vá» QuÃ©t Chá»n lá»c: Má»Ÿ rá»™ng Tráº¡ng thÃ¡i Nháº­n biáº¿t Pháº§n cá»©ng

CÆ¡ cháº¿ chá»n lá»c Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ kháº¯c phá»¥c cÃ¡c háº¡n cháº¿ cá»§a cÃ¡c mÃ´ hÃ¬nh LTI; Ä‘á»“ng thá»i, do Ä‘Ã³ chÃºng tÃ´i cáº§n xem xÃ©t láº¡i váº¥n Ä‘á» tÃ­nh toÃ¡n cá»§a SSM. ChÃºng tÃ´i giáº£i quyáº¿t Ä‘iá»u nÃ y báº±ng ba ká»¹ thuáº­t cá»• Ä‘iá»ƒn: há»£p nháº¥t kernel, quÃ©t song song, vÃ  tÃ­nh toÃ¡n láº¡i. ChÃºng tÃ´i thá»±c hiá»‡n hai quan sÃ¡t chÃ­nh:

â€¢TÃ­nh toÃ¡n há»“i quy ngÃ¢y thÆ¡ sá»­ dá»¥ng ğ‘‚(ğµğ¿ğ·ğ‘) FLOP trong khi tÃ­nh toÃ¡n tÃ­ch cháº­p sá»­ dá»¥ng ğ‘‚(ğµğ¿ğ· log(ğ¿)) FLOP, vÃ  cÃ¡i trÆ°á»›c cÃ³ yáº¿u tá»‘ khÃ´ng Ä‘á»•i tháº¥p hÆ¡n. VÃ¬ váº­y Ä‘á»‘i vá»›i cÃ¡c chuá»—i dÃ i vÃ  chiá»u tráº¡ng thÃ¡i ğ‘ khÃ´ng quÃ¡ lá»›n, cháº¿ Ä‘á»™ há»“i quy thá»±c sá»± cÃ³ thá»ƒ sá»­ dá»¥ng Ã­t FLOP hÆ¡n.

â€¢Hai thÃ¡ch thá»©c lÃ  báº£n cháº¥t tuáº§n tá»± cá»§a há»“i quy, vÃ  viá»‡c sá»­ dá»¥ng bá»™ nhá»› lá»›n. Äá»ƒ giáº£i quyáº¿t cÃ¡i sau, giá»‘ng nhÆ° cháº¿ Ä‘á»™ tÃ­ch cháº­p, chÃºng ta cÃ³ thá»ƒ cá»‘ gáº¯ng khÃ´ng thá»±c sá»± cá»¥ thá»ƒ hÃ³a toÃ n bá»™ tráº¡ng thÃ¡i â„.

Ã tÆ°á»Ÿng chÃ­nh lÃ  táº­n dá»¥ng cÃ¡c tÃ­nh cháº¥t cá»§a cÃ¡c bá»™ tÄƒng tá»‘c hiá»‡n Ä‘áº¡i (GPU) Ä‘á»ƒ chá»‰ cá»¥ thá»ƒ hÃ³a tráº¡ng thÃ¡i â„ á»Ÿ cÃ¡c cáº¥p Ä‘á»™ hiá»‡u quáº£ hÆ¡n cá»§a há»‡ thá»‘ng phÃ¢n cáº¥p bá»™ nhá»›. Äáº·c biá»‡t, háº§u háº¿t cÃ¡c hoáº¡t Ä‘á»™ng (trá»« phÃ©p nhÃ¢n ma tráº­n) bá»‹ giá»›i háº¡n bá»Ÿi bÄƒng thÃ´ng bá»™ nhá»› (Dao, Fu, Ermon, et al. 2022; Ivanov et al. 2021; Williams, Waterman, and Patterson 2009). Äiá»u nÃ y bao gá»“m hoáº¡t Ä‘á»™ng quÃ©t cá»§a chÃºng tÃ´i, vÃ  chÃºng tÃ´i sá»­ dá»¥ng há»£p nháº¥t kernel Ä‘á»ƒ giáº£m sá»‘ lÆ°á»£ng IO bá»™ nhá»›, dáº«n Ä‘áº¿n tÄƒng tá»‘c Ä‘Ã¡ng ká»ƒ so vá»›i triá»ƒn khai tiÃªu chuáº©n.

Cá»¥ thá»ƒ, thay vÃ¬ chuáº©n bá»‹ Ä‘áº§u vÃ o quÃ©t (ğ´Ì„, ğµÌ„) cÃ³ kÃ­ch thÆ°á»›c (B, L, D, N) trong GPU HBM (bá»™ nhá»› bÄƒng thÃ´ng cao), chÃºng tÃ´i táº£i cÃ¡c tham sá»‘ SSM (Î”, ğ´, ğµ, ğ¶) trá»±c tiáº¿p tá»« HBM cháº­m Ä‘áº¿n SRAM nhanh, thá»±c hiá»‡n rá»i ráº¡c hÃ³a vÃ  há»“i quy trong SRAM, vÃ  sau Ä‘Ã³ ghi cÃ¡c Ä‘áº§u ra cuá»‘i cÃ¹ng cÃ³ kÃ­ch thÆ°á»›c (B, L, D) trá»Ÿ láº¡i HBM.

Äá»ƒ trÃ¡nh há»“i quy tuáº§n tá»±, chÃºng tÃ´i quan sÃ¡t ráº±ng máº·c dÃ¹ khÃ´ng tuyáº¿n tÃ­nh, nÃ³ váº«n cÃ³ thá»ƒ Ä‘Æ°á»£c song song hÃ³a vá»›i má»™t thuáº­t toÃ¡n quÃ©t song song hiá»‡u quáº£ cÃ´ng viá»‡c (Blelloch 1990; Martin and Cundy 2018; Smith, Warrington, and Linderman 2023).

Cuá»‘i cÃ¹ng, chÃºng tÃ´i cÅ©ng pháº£i trÃ¡nh lÆ°u cÃ¡c tráº¡ng thÃ¡i trung gian, cáº§n thiáº¿t cho lan truyá»n ngÆ°á»£c. ChÃºng tÃ´i cáº©n tháº­n Ã¡p dá»¥ng ká»¹ thuáº­t cá»• Ä‘iá»ƒn cá»§a tÃ­nh toÃ¡n láº¡i Ä‘á»ƒ giáº£m yÃªu cáº§u bá»™ nhá»›: cÃ¡c tráº¡ng thÃ¡i trung gian khÃ´ng Ä‘Æ°á»£c lÆ°u trá»¯ mÃ  Ä‘Æ°á»£c tÃ­nh toÃ¡n láº¡i trong lÆ°á»£t lan truyá»n ngÆ°á»£c khi cÃ¡c Ä‘áº§u vÃ o Ä‘Æ°á»£c táº£i tá»« HBM Ä‘áº¿n SRAM. Káº¿t quáº£ lÃ , lá»›p quÃ©t chá»n lá»c há»£p nháº¥t cÃ³ cÃ¹ng yÃªu cáº§u bá»™ nhá»› nhÆ° má»™t triá»ƒn khai transformer Ä‘Æ°á»£c tá»‘i Æ°u hÃ³a vá»›i FlashAttention.

Chi tiáº¿t vá» kernel há»£p nháº¥t vÃ  tÃ­nh toÃ¡n láº¡i trong Phá»¥ lá»¥c D. Lá»›p SSM Chá»n lá»c Ä‘áº§y Ä‘á»§ vÃ  thuáº­t toÃ¡n Ä‘Æ°á»£c minh há»a trong HÃ¬nh 1.

3.4 Má»™t Kiáº¿n trÃºc SSM ÄÆ¡n giáº£n

NhÆ° vá»›i cÃ¡c SSM cÃ³ cáº¥u trÃºc, cÃ¡c SSM chá»n lá»c lÃ  cÃ¡c phÃ©p biáº¿n Ä‘á»•i chuá»—i Ä‘á»™c láº­p cÃ³ thá»ƒ Ä‘Æ°á»£c káº¿t há»£p linh hoáº¡t vÃ o cÃ¡c máº¡ng tháº§n kinh. Kiáº¿n trÃºc H3 lÃ  cÆ¡ sá»Ÿ cho cÃ¡c kiáº¿n trÃºc SSM ná»•i tiáº¿ng nháº¥t (Pháº§n 2), thÆ°á»ng bao gá»“m má»™t khá»‘i láº¥y cáº£m há»©ng tá»« chÃº Ã½ tuyáº¿n tÃ­nh xen káº½ vá»›i má»™t khá»‘i MLP (perceptron Ä‘a lá»›p). ChÃºng tÃ´i Ä‘Æ¡n giáº£n hÃ³a kiáº¿n trÃºc nÃ y báº±ng cÃ¡ch káº¿t há»£p hai thÃ nh pháº§n nÃ y thÃ nh má»™t, Ä‘Æ°á»£c xáº¿p chá»“ng Ä‘á»“ng nháº¥t (HÃ¬nh 3). Äiá»u nÃ y Ä‘Æ°á»£c láº¥y cáº£m há»©ng tá»« Ä‘Æ¡n vá»‹ chÃº Ã½ cÃ³ cá»•ng (GAU) (Hua et al. 2022), Ä‘Ã£ lÃ m Ä‘iá»u tÆ°Æ¡ng tá»± cho chÃº Ã½.

Kiáº¿n trÃºc nÃ y liÃªn quan Ä‘áº¿n viá»‡c má»Ÿ rá»™ng chiá»u mÃ´ hÃ¬nh ğ· báº±ng má»™t yáº¿u tá»‘ má»Ÿ rá»™ng cÃ³ thá»ƒ kiá»ƒm soÃ¡t ğ¸. Äá»‘i vá»›i má»—i khá»‘i, háº§u háº¿t cÃ¡c tham sá»‘ (3ğ¸ğ·Â²) náº±m trong cÃ¡c phÃ©p chiáº¿u tuyáº¿n tÃ­nh (2ğ¸ğ·Â² cho cÃ¡c phÃ©p chiáº¿u Ä‘áº§u vÃ o, ğ¸ğ·Â² cho phÃ©p chiáº¿u Ä‘áº§u ra) trong khi SSM bÃªn trong Ä‘Ã³ng gÃ³p Ã­t hÆ¡n. Sá»‘ lÆ°á»£ng tham sá»‘ SSM (cÃ¡c phÃ©p chiáº¿u cho Î”, ğµ, ğ¶, vÃ  ma tráº­n ğ´) nhá» hÆ¡n nhiá»u so vá»›i. ChÃºng tÃ´i láº·p láº¡i khá»‘i nÃ y, xen káº½ vá»›i chuáº©n hÃ³a tiÃªu chuáº©n vÃ  cÃ¡c káº¿t ná»‘i dÆ°, Ä‘á»ƒ táº¡o thÃ nh kiáº¿n trÃºc Mamba. ChÃºng tÃ´i luÃ´n cá»‘ Ä‘á»‹nh ğ¸ = 2 trong cÃ¡c thÃ­ nghiá»‡m cá»§a mÃ¬nh vÃ  sá»­ dá»¥ng hai chá»“ng cá»§a khá»‘i Ä‘á»ƒ khá»›p vá»›i 12ğ·Â² tham sá»‘ cá»§a cÃ¡c khá»‘i MHA (chÃº Ã½ Ä‘a Ä‘áº§u) vÃ  MLP xen káº½ cá»§a Transformer. ChÃºng tÃ´i sá»­ dá»¥ng hÃ m kÃ­ch hoáº¡t SiLU / Swish (Hendrycks and Gimpel 2016; Ramachandran, Zoph, and Quoc V Le 2017), Ä‘Æ°á»£c thÃºc Ä‘áº©y Ä‘á»ƒ Gated MLP trá»Ÿ thÃ nh biáº¿n thá»ƒ "SwiGLU" phá»• biáº¿n (Chowdhery et al. 2023; Dauphin et al. 2017; Shazeer 2020; Touvron et al. 2023).

Cuá»‘i cÃ¹ng, chÃºng tÃ´i cÅ©ng sá»­ dá»¥ng má»™t lá»›p chuáº©n hÃ³a tÃ¹y chá»n (chÃºng tÃ´i chá»n LayerNorm (J. L. Ba, Kiros, and Hinton 2016)), Ä‘Æ°á»£c thÃºc Ä‘áº©y bá»Ÿi viá»‡c sá»­ dá»¥ng lá»›p chuáº©n hÃ³a cá»§a RetNet á»Ÿ vá»‹ trÃ­ tÆ°Æ¡ng tá»± (Y. Sun et al. 2023).

3.5 TÃ­nh cháº¥t cá»§a CÆ¡ cháº¿ Chá»n lá»c

CÆ¡ cháº¿ chá»n lá»c lÃ  má»™t khÃ¡i niá»‡m rá»™ng hÆ¡n cÃ³ thá»ƒ Ä‘Æ°á»£c Ã¡p dá»¥ng theo cÃ¡c cÃ¡ch khÃ¡c nhau, cháº³ng háº¡n nhÆ° Ä‘á»‘i vá»›i cÃ¡c RNN hoáº·c CNN truyá»n thá»‘ng hÆ¡n, Ä‘á»‘i vá»›i cÃ¡c tham sá»‘ khÃ¡c nhau (vÃ­ dá»¥: ğ´ trong Thuáº­t toÃ¡n 2), hoáº·c sá»­ dá»¥ng cÃ¡c phÃ©p biáº¿n Ä‘á»•i khÃ¡c nhau ğ‘ (ğ‘¥).

3.5.1 Káº¿t ná»‘i vá»›i CÆ¡ cháº¿ Cá»•ng

ChÃºng tÃ´i nháº¥n máº¡nh káº¿t ná»‘i quan trá»ng nháº¥t: cÆ¡ cháº¿ cá»•ng cá»• Ä‘iá»ƒn cá»§a RNN lÃ  má»™t trÆ°á»ng há»£p cá»§a cÆ¡ cháº¿ chá»n lá»c cá»§a chÃºng tÃ´i cho SSM. ChÃºng tÃ´i lÆ°u Ã½ ráº±ng káº¿t ná»‘i giá»¯a cá»•ng RNN vÃ  rá»i ráº¡c hÃ³a cá»§a cÃ¡c há»‡ thá»‘ng thá»i gian liÃªn tá»¥c Ä‘Æ°á»£c thiáº¿t láº­p tá»‘t (Funahashi and Nakamura 1993; Tallec and Ollivier 2018). Thá»±c táº¿, Äá»‹nh lÃ½ 1 lÃ  má»™t cáº£i tiáº¿n cá»§a Gu, Johnson, Goel, et al. (2021, Bá»• Ä‘á» 3.1) khÃ¡i quÃ¡t hÃ³a cho rá»i ráº¡c hÃ³a ZOH vÃ  cÃ¡c cá»•ng phá»¥ thuá»™c Ä‘áº§u vÃ o (chá»©ng minh trong Phá»¥ lá»¥c C). Rá»™ng hÆ¡n, Î” trong SSM cÃ³ thá»ƒ Ä‘Æ°á»£c xem Ä‘Ã³ng vai trÃ² tá»•ng quÃ¡t cá»§a cÆ¡ cháº¿ cá»•ng RNN. PhÃ¹ há»£p vá»›i cÃ´ng trÃ¬nh trÆ°á»›c Ä‘Ã¢y, chÃºng tÃ´i Ã¡p dá»¥ng quan Ä‘iá»ƒm ráº±ng rá»i ráº¡c hÃ³a cá»§a SSM lÃ  ná»n táº£ng cÃ³ nguyÃªn táº¯c cá»§a cÃ¡c cÆ¡ cháº¿ cá»•ng heuristic.

Äá»‹nh lÃ½ 1. Khi ğ‘ = 1, ğ´ = âˆ’1, ğµ = 1, ğ‘ _Î” = Linear(ğ‘¥), vÃ  ğœ_Î” = softplus, thÃ¬ há»“i quy SSM chá»n lá»c (Thuáº­t toÃ¡n 2) cÃ³ dáº¡ng
ğ‘”_ğ‘¡ = ğœ(Linear(ğ‘¥_ğ‘¡))
â„_ğ‘¡ = (1 âˆ’ ğ‘”_ğ‘¡)â„_{ğ‘¡âˆ’1} + ğ‘”_ğ‘¡ğ‘¥_ğ‘¡. (5)

NhÆ° Ä‘Ã£ Ä‘á» cáº­p trong Pháº§n 3.2, cÃ¡c lá»±a chá»n cá»¥ thá»ƒ cá»§a chÃºng tÃ´i vá» ğ‘ _Î”, ğœ_Î” xuáº¥t phÃ¡t tá»« káº¿t ná»‘i nÃ y. Äáº·c biá»‡t, lÆ°u Ã½ ráº±ng náº¿u má»™t Ä‘áº§u vÃ o ğ‘¥_ğ‘¡ nháº¥t Ä‘á»‹nh nÃªn Ä‘Æ°á»£c bá» qua hoÃ n toÃ n (nhÆ° cáº§n thiáº¿t trong cÃ¡c tÃ¡c vá»¥ tá»•ng há»£p), táº¥t cáº£ cÃ¡c kÃªnh ğ· nÃªn bá» qua nÃ³, vÃ  vÃ¬ váº­y chÃºng tÃ´i chiáº¿u Ä‘áº§u vÃ o xuá»‘ng 1 chiá»u trÆ°á»›c khi láº·p láº¡i/phÃ¡t sÃ³ng vá»›i Î”.

3.5.2 Giáº£i thÃ­ch vá» CÆ¡ cháº¿ Chá»n lá»c

ChÃºng tÃ´i má»Ÿ rá»™ng vá» ba hiá»‡u á»©ng cÆ¡ há»c cá»¥ thá»ƒ cá»§a chá»n lá»c.

Khoáº£ng cÃ¡ch Biáº¿n Ä‘á»•i. TÃ­nh chá»n lá»c cho phÃ©p lá»c ra cÃ¡c token nhiá»…u khÃ´ng liÃªn quan cÃ³ thá»ƒ xáº£y ra giá»¯a cÃ¡c Ä‘áº§u vÃ o quan tÃ¢m. Äiá»u nÃ y Ä‘Æ°á»£c minh há»a báº±ng tÃ¡c vá»¥ Sao chÃ©p Chá»n lá»c, nhÆ°ng xáº£y ra phá»• biáº¿n trong cÃ¡c phÆ°Æ¡ng thá»©c dá»¯ liá»‡u thÃ´ng thÆ°á»ng, Ä‘áº·c biá»‡t lÃ  Ä‘á»‘i vá»›i dá»¯ liá»‡u rá»i ráº¡c - vÃ­ dá»¥ sá»± hiá»‡n diá»‡n cá»§a cÃ¡c tá»« Ä‘á»‡m ngÃ´n ngá»¯ nhÆ° "um". TÃ­nh cháº¥t nÃ y phÃ¡t sinh vÃ¬ mÃ´ hÃ¬nh cÃ³ thá»ƒ lá»c ra cÆ¡ há»c báº¥t ká»³ Ä‘áº§u vÃ o ğ‘¥_ğ‘¡ cá»¥ thá»ƒ nÃ o, vÃ­ dá»¥ trong trÆ°á»ng há»£p RNN cÃ³ cá»•ng (Äá»‹nh lÃ½ 1) khi ğ‘”_ğ‘¡ â†’ 0.

Lá»c Ngá»¯ cáº£nh. ÄÃ£ Ä‘Æ°á»£c quan sÃ¡t thá»±c nghiá»‡m ráº±ng nhiá»u mÃ´ hÃ¬nh chuá»—i khÃ´ng cáº£i thiá»‡n vá»›i ngá»¯ cáº£nh dÃ i hÆ¡n (F. Shi et al. 2023), máº·c dÃ¹ nguyÃªn táº¯c ráº±ng ngá»¯ cáº£nh nhiá»u hÆ¡n sáº½ dáº«n Ä‘áº¿n hiá»‡u suáº¥t tá»‘t hÆ¡n má»™t cÃ¡ch nghiÃªm ngáº·t. Má»™t giáº£i thÃ­ch lÃ  nhiá»u mÃ´ hÃ¬nh chuá»—i khÃ´ng thá»ƒ hiá»‡u quáº£ bá» qua ngá»¯ cáº£nh khÃ´ng liÃªn quan khi cáº§n thiáº¿t; má»™t vÃ­ dá»¥ trá»±c quan lÃ  cÃ¡c tÃ­ch cháº­p toÃ n cá»¥c (vÃ  cÃ¡c mÃ´ hÃ¬nh LTI nÃ³i chung). Máº·t khÃ¡c, cÃ¡c mÃ´ hÃ¬nh chá»n lá»c cÃ³ thá»ƒ Ä‘Æ¡n giáº£n Ä‘áº·t láº¡i tráº¡ng thÃ¡i cá»§a chÃºng báº¥t cá»© lÃºc nÃ o Ä‘á»ƒ loáº¡i bá» lá»‹ch sá»­ khÃ´ng liÃªn quan, vÃ  do Ä‘Ã³ hiá»‡u suáº¥t cá»§a chÃºng vá» nguyÃªn táº¯c cáº£i thiá»‡n má»™t cÃ¡ch Ä‘Æ¡n Ä‘iá»‡u vá»›i Ä‘á»™ dÃ i ngá»¯ cáº£nh (vÃ­ dá»¥: Pháº§n 4.3.2).

Äáº·t láº¡i Ranh giá»›i. Trong cÃ¡c cÃ i Ä‘áº·t nÆ¡i nhiá»u chuá»—i Ä‘á»™c láº­p Ä‘Æ°á»£c ghÃ©p láº¡i vá»›i nhau, Transformer cÃ³ thá»ƒ giá»¯ chÃºng tÃ¡ch biá»‡t báº±ng cÃ¡ch khá»Ÿi táº¡o má»™t máº·t náº¡ chÃº Ã½ cá»¥ thá»ƒ, trong khi cÃ¡c mÃ´ hÃ¬nh LTI sáº½ rÃ² rá»‰ thÃ´ng tin giá»¯a cÃ¡c chuá»—i. CÃ¡c SSM chá»n lá»c cÅ©ng cÃ³ thá»ƒ Ä‘áº·t láº¡i tráº¡ng thÃ¡i cá»§a chÃºng táº¡i cÃ¡c ranh giá»›i (vÃ­ dá»¥: Î”_ğ‘¡ â†’ âˆ, hoáº·c Äá»‹nh lÃ½ 1 khi ğ‘”_ğ‘¡ â†’ 1). CÃ¡c cÃ i Ä‘áº·t nÃ y cÃ³ thá»ƒ xáº£y ra má»™t cÃ¡ch nhÃ¢n táº¡o (vÃ­ dá»¥: Ä‘Ã³ng gÃ³i cÃ¡c tÃ i liá»‡u láº¡i vá»›i nhau Ä‘á»ƒ cáº£i thiá»‡n viá»‡c sá»­ dá»¥ng pháº§n cá»©ng) hoáº·c tá»± nhiÃªn (vÃ­ dá»¥: ranh giá»›i táº­p trong há»c tÄƒng cÆ°á»ng (Lu et al. 2023)).

NgoÃ i ra, chÃºng tÃ´i má»Ÿ rá»™ng vá» cÃ¡c hiá»‡u á»©ng cá»§a tá»«ng tham sá»‘ chá»n lá»c.

Giáº£i thÃ­ch vá» Î”. NÃ³i chung, Î” kiá»ƒm soÃ¡t sá»± cÃ¢n báº±ng giá»¯a má»©c Ä‘á»™ táº­p trung hoáº·c bá» qua Ä‘áº§u vÃ o hiá»‡n táº¡i ğ‘¥_ğ‘¡. NÃ³ khÃ¡i quÃ¡t hÃ³a cÃ¡c cá»•ng RNN (vÃ­ dá»¥: ğ‘”_ğ‘¡ trong Äá»‹nh lÃ½ 1): vá» máº·t cÆ¡ há»c, má»™t Î” lá»›n Ä‘áº·t láº¡i tráº¡ng thÃ¡i â„ vÃ  táº­p trung vÃ o Ä‘áº§u vÃ o hiá»‡n táº¡i ğ‘¥, trong khi má»™t Î” nhá» duy trÃ¬ tráº¡ng thÃ¡i vÃ  bá» qua Ä‘áº§u vÃ o hiá»‡n táº¡i. SSM (1)-(2) cÃ³ thá»ƒ Ä‘Æ°á»£c hiá»ƒu nhÆ° má»™t há»‡ thá»‘ng liÃªn tá»¥c Ä‘Æ°á»£c rá»i ráº¡c hÃ³a bá»Ÿi má»™t bÆ°á»›c thá»i gian Î”, vÃ  trong ngá»¯ cáº£nh nÃ y trá»±c giÃ¡c lÃ  Î” lá»›n â†’ âˆ Ä‘áº¡i diá»‡n cho há»‡ thá»‘ng táº­p trung vÃ o Ä‘áº§u vÃ o hiá»‡n táº¡i lÃ¢u hÆ¡n (do Ä‘Ã³ "chá»n" nÃ³ vÃ  quÃªn tráº¡ng thÃ¡i hiá»‡n táº¡i cá»§a nÃ³) trong khi Î” nhá» â†’ 0 Ä‘áº¡i diá»‡n cho má»™t Ä‘áº§u vÃ o thoÃ¡ng qua bá»‹ bá» qua.

Giáº£i thÃ­ch vá» ğ´. ChÃºng tÃ´i nháº­n xÃ©t ráº±ng trong khi tham sá»‘ ğ´ cÅ©ng cÃ³ thá»ƒ chá»n lá»c, nÃ³ cuá»‘i cÃ¹ng chá»‰ áº£nh hÆ°á»Ÿng Ä‘áº¿n mÃ´ hÃ¬nh thÃ´ng qua tÆ°Æ¡ng tÃ¡c cá»§a nÃ³ vá»›i Î” qua ğ´Ì„ = exp(Î”ğ´) (rá»i ráº¡c hÃ³a (4)). VÃ¬ váº­y tÃ­nh chá»n lá»c trong Î” Ä‘á»§ Ä‘á»ƒ Ä‘áº£m báº£o tÃ­nh chá»n lá»c trong (ğ´Ì„, ğµÌ„), vÃ  lÃ  nguá»“n cáº£i thiá»‡n chÃ­nh. ChÃºng tÃ´i giáº£ Ä‘á»‹nh ráº±ng lÃ m cho ğ´ chá»n lá»c thÃªm vÃ o (hoáº·c thay vÃ¬) Î” sáº½ cÃ³ hiá»‡u suáº¥t tÆ°Æ¡ng tá»±, vÃ  bá» qua nÃ³ Ä‘á»ƒ Ä‘Æ¡n giáº£n.

Giáº£i thÃ­ch vá» ğµ vÃ  ğ¶. NhÆ° Ä‘Ã£ tháº£o luáº­n trong Pháº§n 3.1, tÃ­nh cháº¥t quan trá»ng nháº¥t cá»§a tÃ­nh chá»n lá»c lÃ  lá»c ra thÃ´ng tin khÃ´ng liÃªn quan Ä‘á»ƒ ngá»¯ cáº£nh cá»§a mÃ´ hÃ¬nh chuá»—i cÃ³ thá»ƒ Ä‘Æ°á»£c nÃ©n thÃ nh má»™t tráº¡ng thÃ¡i hiá»‡u quáº£. Trong má»™t SSM, viá»‡c sá»­a Ä‘á»•i ğµ vÃ  ğ¶ Ä‘á»ƒ chá»n lá»c cho phÃ©p kiá»ƒm soÃ¡t tinh vi hÆ¡n vá» viá»‡c cÃ³ cho phÃ©p má»™t Ä‘áº§u vÃ o ğ‘¥_ğ‘¡ vÃ o tráº¡ng thÃ¡i â„_ğ‘¡, hoáº·c tráº¡ng thÃ¡i vÃ o Ä‘áº§u ra ğ‘¦_ğ‘¡. Nhá»¯ng cÃ¡i nÃ y cÃ³ thá»ƒ Ä‘Æ°á»£c hiá»ƒu nhÆ° cho phÃ©p mÃ´ hÃ¬nh Ä‘iá»u chá»‰nh Ä‘á»™ng lá»±c há»c há»“i quy dá»±a trÃªn ná»™i dung (Ä‘áº§u vÃ o) vÃ  ngá»¯ cáº£nh (tráº¡ng thÃ¡i áº©n) tÆ°Æ¡ng á»©ng.

3.6 Chi tiáº¿t MÃ´ hÃ¬nh Bá»• sung

Thá»±c so vá»›i Phá»©c. Háº§u háº¿t cÃ¡c SSM trÆ°á»›c Ä‘Ã¢y sá»­ dá»¥ng sá»‘ phá»©c trong tráº¡ng thÃ¡i â„ cá»§a chÃºng, Ä‘iá»u nÃ y cáº§n thiáº¿t cho hiá»‡u suáº¥t máº¡nh máº½ trÃªn nhiá»u tÃ¡c vá»¥ trong cÃ¡c phÆ°Æ¡ng thá»©c tri giÃ¡c (Gu, Goel, and RÃ© 2022). Tuy nhiÃªn, Ä‘Ã£ Ä‘Æ°á»£c quan sÃ¡t thá»±c nghiá»‡m ráº±ng cÃ¡c SSM hoÃ n toÃ n giÃ¡ trá»‹ thá»±c dÆ°á»ng nhÆ° hoáº¡t Ä‘á»™ng tá»‘t, vÃ  cÃ³ thá»ƒ tháº­m chÃ­ tá»‘t hÆ¡n, trong má»™t sá»‘ cÃ i Ä‘áº·t (Ma et al. 2023). ChÃºng tÃ´i sá»­ dá»¥ng giÃ¡ trá»‹ thá»±c lÃ m máº·c Ä‘á»‹nh, hoáº¡t Ä‘á»™ng tá»‘t cho táº¥t cáº£ trá»« má»™t tÃ¡c vá»¥ cá»§a chÃºng tÃ´i; chÃºng tÃ´i giáº£ Ä‘á»‹nh ráº±ng sá»± Ä‘Ã¡nh Ä‘á»•i phá»©c-thá»±c liÃªn quan Ä‘áº¿n phá»• liÃªn tá»¥c-rá»i ráº¡c trong cÃ¡c phÆ°Æ¡ng thá»©c dá»¯ liá»‡u, nÆ¡i sá»‘ phá»©c há»¯u Ã­ch cho cÃ¡c phÆ°Æ¡ng thá»©c liÃªn tá»¥c (vÃ­ dá»¥: Ã¢m thanh, video) nhÆ°ng khÃ´ng pháº£i rá»i ráº¡c (vÃ­ dá»¥: vÄƒn báº£n, DNA).

Khá»Ÿi táº¡o. Háº§u háº¿t cÃ¡c SSM trÆ°á»›c Ä‘Ã¢y cÅ©ng Ä‘á» xuáº¥t cÃ¡c khá»Ÿi táº¡o Ä‘áº·c biá»‡t, Ä‘áº·c biá»‡t lÃ  trong trÆ°á»ng há»£p giÃ¡ trá»‹ phá»©c, cÃ³ thá»ƒ giÃºp Ã­ch trong má»™t sá»‘ cÃ i Ä‘áº·t nhÆ° cÃ¡c cháº¿ Ä‘á»™ dá»¯ liá»‡u tháº¥p. Khá»Ÿi táº¡o máº·c Ä‘á»‹nh cá»§a chÃºng tÃ´i cho trÆ°á»ng há»£p phá»©c lÃ  S4D-Lin vÃ  cho trÆ°á»ng há»£p thá»±c lÃ  S4D-Real (Gu, Gupta, et al. 2022), dá»±a trÃªn lÃ½ thuyáº¿t HIPPO (Gu, Dao, et al. 2020). Nhá»¯ng cÃ¡i nÃ y Ä‘á»‹nh nghÄ©a pháº§n tá»­ thá»© ğ‘› cá»§a ğ´ lÃ  âˆ’1/2 + ğ‘›ğ‘– vÃ  âˆ’(ğ‘› + 1) tÆ°Æ¡ng á»©ng. Tuy nhiÃªn, chÃºng tÃ´i mong Ä‘á»£i nhiá»u khá»Ÿi táº¡o sáº½ hoáº¡t Ä‘á»™ng tá»‘t, Ä‘áº·c biá»‡t lÃ  trong cÃ¡c cháº¿ Ä‘á»™ dá»¯ liá»‡u lá»›n vÃ  SSM giÃ¡ trá»‹ thá»±c; má»™t sá»‘ ablation Ä‘Æ°á»£c xem xÃ©t trong Pháº§n 4.6.

Tham sá»‘ hÃ³a cá»§a Î”. ChÃºng tÃ´i Ä‘á»‹nh nghÄ©a Ä‘iá»u chá»‰nh chá»n lá»c cho Î” lÃ  ğ‘ _Î”(ğ‘¥) = Broadcast_ğ·(Linear_1(ğ‘¥)), Ä‘Æ°á»£c thÃºc Ä‘áº©y bá»Ÿi cÆ¡ há»c cá»§a Î” (Pháº§n 3.5). ChÃºng tÃ´i quan sÃ¡t ráº±ng nÃ³ cÃ³ thá»ƒ Ä‘Æ°á»£c khÃ¡i quÃ¡t hÃ³a tá»« chiá»u 1 Ä‘áº¿n má»™t chiá»u lá»›n hÆ¡n R. ChÃºng tÃ´i Ä‘áº·t Ä‘iá»u nÃ y lÃ  má»™t pháº§n nhá» cá»§a D, sá»­ dá»¥ng má»™t sá»‘ lÆ°á»£ng tham sá»‘ khÃ´ng Ä‘Ã¡ng ká»ƒ so vá»›i cÃ¡c phÃ©p chiáº¿u Linear chÃ­nh trong khá»‘i. ChÃºng tÃ´i cÅ©ng lÆ°u Ã½ ráº±ng hoáº¡t Ä‘á»™ng phÃ¡t sÃ³ng thay vÃ o Ä‘Ã³ cÃ³ thá»ƒ Ä‘Æ°á»£c xem nhÆ° má»™t phÃ©p chiáº¿u Linear khÃ¡c, Ä‘Æ°á»£c khá»Ÿi táº¡o theo má»™t máº«u cá»¥ thá»ƒ cá»§a cÃ¡c sá»‘ 1 vÃ  0; náº¿u phÃ©p chiáº¿u nÃ y cÃ³ thá»ƒ huáº¥n luyá»‡n, Ä‘iá»u nÃ y dáº«n Ä‘áº¿n ğ‘ _Î”(ğ‘¥) = Linear_ğ·(Linear_ğ‘…(ğ‘¥)) thay tháº¿, cÃ³ thá»ƒ Ä‘Æ°á»£c xem nhÆ° má»™t phÃ©p chiáº¿u thá»© háº¡ng tháº¥p.

Trong cÃ¡c thÃ­ nghiá»‡m cá»§a chÃºng tÃ´i, tham sá»‘ Î” (cÃ³ thá»ƒ Ä‘Æ°á»£c xem nhÆ° má»™t thuáº­t ngá»¯ bias) Ä‘Æ°á»£c khá»Ÿi táº¡o thÃ nh ğœ_Î”^{-1}(Uniform([0.001, 0.1])), theo cÃ´ng trÃ¬nh trÆ°á»›c Ä‘Ã¢y vá» SSM (Gu, Johnson, Timalsina, et al. 2023).

ChÃº thÃ­ch 3.1. Äá»ƒ ngáº¯n gá»n trong cÃ¡c káº¿t quáº£ thÃ­ nghiá»‡m cá»§a chÃºng tÃ´i, Ä‘Ã´i khi chÃºng tÃ´i viáº¿t táº¯t cÃ¡c SSM chá»n lá»c lÃ  mÃ´ hÃ¬nh S6, vÃ¬ chÃºng lÃ  mÃ´ hÃ¬nh S4 vá»›i má»™t cÆ¡ cháº¿ chá»n lá»c vÃ  Ä‘Æ°á»£c tÃ­nh toÃ¡n vá»›i má»™t scan.

--- TRANG 5 ---
4 ÄÃ¡nh giÃ¡ Thá»±c nghiá»‡m

Trong Pháº§n 4.1, chÃºng tÃ´i kiá»ƒm tra kháº£ nÄƒng cá»§a Mamba trong viá»‡c giáº£i quyáº¿t hai tÃ¡c vá»¥ tá»•ng há»£p Ä‘Æ°á»£c thÃºc Ä‘áº©y trong Pháº§n 3.1. Sau Ä‘Ã³ chÃºng tÃ´i Ä‘Ã¡nh giÃ¡ trÃªn ba lÄ©nh vá»±c, má»—i lÄ©nh vá»±c Ä‘Æ°á»£c Ä‘Ã¡nh giÃ¡ vá» huáº¥n luyá»‡n trÆ°á»›c tá»± há»“i quy cÅ©ng nhÆ° cÃ¡c tÃ¡c vá»¥ háº¡ nguá»“n.

â€¢Pháº§n 4.2: huáº¥n luyá»‡n trÆ°á»›c mÃ´ hÃ¬nh ngÃ´n ngá»¯ (luáº­t tá»· lá»‡), vÃ  Ä‘Ã¡nh giÃ¡ háº¡ nguá»“n zero-shot.
â€¢Pháº§n 4.3: huáº¥n luyá»‡n trÆ°á»›c chuá»—i DNA, vÃ  tinh chá»‰nh trÃªn má»™t tÃ¡c vá»¥ phÃ¢n loáº¡i chuá»—i dÃ i.
â€¢Pháº§n 4.4: huáº¥n luyá»‡n trÆ°á»›c dáº¡ng sÃ³ng Ã¢m thanh, vÃ  cháº¥t lÆ°á»£ng cá»§a cÃ¡c clip giá»ng nÃ³i Ä‘Æ°á»£c táº¡o ra má»™t cÃ¡ch tá»± há»“i quy.

Cuá»‘i cÃ¹ng, Pháº§n 4.5 cho tháº¥y hiá»‡u quáº£ tÃ­nh toÃ¡n cá»§a Mamba á»Ÿ cáº£ thá»i gian huáº¥n luyá»‡n vÃ  suy luáº­n, vÃ  Pháº§n 4.6 ablate cÃ¡c thÃ nh pháº§n khÃ¡c nhau cá»§a kiáº¿n trÃºc vÃ  SSM chá»n lá»c.

4.1 TÃ¡c vá»¥ Tá»•ng há»£p

Chi tiáº¿t thÃ­ nghiá»‡m Ä‘áº§y Ä‘á»§ cho cÃ¡c tÃ¡c vá»¥ nÃ y bao gá»“m chi tiáº¿t tÃ¡c vá»¥ vÃ  giao thá»©c huáº¥n luyá»‡n trong Phá»¥ lá»¥c E.1.

4.1.1 Sao chÃ©p Chá»n lá»c

TÃ¡c vá»¥ Sao chÃ©p lÃ  má»™t trong nhá»¯ng tÃ¡c vá»¥ tá»•ng há»£p Ä‘Æ°á»£c nghiÃªn cá»©u nhiá»u nháº¥t cho mÃ´ hÃ¬nh hÃ³a chuá»—i, ban Ä‘áº§u Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ kiá»ƒm tra kháº£ nÄƒng ghi nhá»› cá»§a cÃ¡c mÃ´ hÃ¬nh há»“i quy. NhÆ° Ä‘Ã£ tháº£o luáº­n trong Pháº§n 3.1, cÃ¡c SSM LTI (há»“i quy tuyáº¿n tÃ­nh vÃ  tÃ­ch cháº­p toÃ n cá»¥c) cÃ³ thá»ƒ dá»… dÃ ng giáº£i quyáº¿t tÃ¡c vá»¥ nÃ y báº±ng cÃ¡ch chá»‰ theo dÃµi thá»i gian thay vÃ¬ lÃ½ luáº­n vá» dá»¯ liá»‡u; vÃ­ dá»¥, báº±ng cÃ¡ch xÃ¢y dá»±ng má»™t kernel tÃ­ch cháº­p cÃ³ Ä‘á»™ dÃ i chÃ­nh xÃ¡c phÃ¹ há»£p (HÃ¬nh 2). Äiá»u nÃ y Ä‘Ã£ Ä‘Æ°á»£c xÃ¡c thá»±c má»™t cÃ¡ch rÃµ rÃ ng trong cÃ´ng trÃ¬nh trÆ°á»›c Ä‘Ã¢y vá» tÃ­ch cháº­p toÃ n cá»¥c (Romero et al. 2021). TÃ¡c vá»¥ Sao chÃ©p Chá»n lá»c ngÄƒn cáº£n lá»‘i táº¯t nÃ y báº±ng cÃ¡ch ngáº«u nhiÃªn hÃ³a khoáº£ng cÃ¡ch giá»¯a cÃ¡c token. LÆ°u Ã½ ráº±ng tÃ¡c vá»¥ nÃ y Ä‘Ã£ Ä‘Æ°á»£c giá»›i thiá»‡u trÆ°á»›c Ä‘Ã¢y nhÆ° tÃ¡c vá»¥ Denoising (Jing et al. 2019).

LÆ°u Ã½ ráº±ng nhiá»u cÃ´ng trÃ¬nh trÆ°á»›c Ä‘Ã¢y láº­p luáº­n ráº±ng viá»‡c thÃªm cá»•ng kiáº¿n trÃºc (cÃ¡c tÆ°Æ¡ng tÃ¡c nhÃ¢n) cÃ³ thá»ƒ cung cáº¥p cho cÃ¡c mÃ´ hÃ¬nh "sá»± phá»¥ thuá»™c dá»¯ liá»‡u" vÃ  giáº£i quyáº¿t cÃ¡c tÃ¡c vá»¥ liÃªn quan (Dao, Fu, Saab, et al. 2023; Poli et al. 2023). Tuy nhiÃªn, chÃºng tÃ´i tháº¥y giáº£i thÃ­ch nÃ y khÃ´ng Ä‘á»§ trá»±c quan vÃ¬ cá»•ng nhÆ° váº­y khÃ´ng tÆ°Æ¡ng tÃ¡c dá»c theo trá»¥c chuá»—i, vÃ  khÃ´ng thá»ƒ áº£nh hÆ°á»Ÿng Ä‘áº¿n khoáº£ng cÃ¡ch giá»¯a cÃ¡c token. Äáº·c biá»‡t, cá»•ng kiáº¿n trÃºc khÃ´ng pháº£i lÃ  má»™t trÆ°á»ng há»£p cá»§a cÆ¡ cháº¿ chá»n lá»c (Phá»¥ lá»¥c A).

Báº£ng 1 xÃ¡c nháº­n ráº±ng cÃ¡c kiáº¿n trÃºc cÃ³ cá»•ng nhÆ° H3 vÃ  Mamba chá»‰ cáº£i thiá»‡n hiá»‡u suáº¥t má»™t pháº§n, trong khi cÆ¡ cháº¿ chá»n lá»c (sá»­a Ä‘á»•i S4 thÃ nh S6) dá»… dÃ ng giáº£i quyáº¿t tÃ¡c vá»¥ nÃ y, Ä‘áº·c biá»‡t lÃ  khi káº¿t há»£p vá»›i cÃ¡c kiáº¿n trÃºc máº¡nh máº½ hÆ¡n nÃ y.

4.1.2 Äáº§u Cáº£m á»©ng

Äáº§u cáº£m á»©ng (Olsson et al. 2022) lÃ  má»™t tÃ¡c vá»¥ Ä‘Æ¡n giáº£n tá»« lÄƒng kÃ­nh giáº£i thÃ­ch cÆ¡ há»c (Elhage et al. 2021) cÃ³ kháº£ nÄƒng dá»± Ä‘oÃ¡n Ä‘Ã¡ng ngáº¡c nhiÃªn vá» kháº£ nÄƒng há»c trong ngá»¯ cáº£nh cá»§a LLM. NÃ³ yÃªu cáº§u cÃ¡c mÃ´ hÃ¬nh thá»±c hiá»‡n gá»i láº¡i liÃªn tÆ°á»Ÿng vÃ  sao chÃ©p: vÃ­ dá»¥, náº¿u mÃ´ hÃ¬nh Ä‘Ã£ tháº¥y má»™t bigram nhÆ° "Harry Potter" trong chuá»—i, thÃ¬ láº§n tiáº¿p theo "Harry" xuáº¥t hiá»‡n trong cÃ¹ng chuá»—i, mÃ´ hÃ¬nh sáº½ cÃ³ thá»ƒ dá»± Ä‘oÃ¡n "Potter" báº±ng cÃ¡ch sao chÃ©p tá»« lá»‹ch sá»­.

Táº­p dá»¯ liá»‡u. ChÃºng tÃ´i huáº¥n luyá»‡n má»™t mÃ´ hÃ¬nh 2 lá»›p trÃªn tÃ¡c vá»¥ Ä‘áº§u cáº£m á»©ng á»Ÿ Ä‘á»™ dÃ i chuá»—i 256, vá»›i kÃ­ch thÆ°á»›c tá»« vá»±ng 16, tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i cÃ´ng trÃ¬nh trÆ°á»›c Ä‘Ã¢y vá» tÃ¡c vá»¥ nÃ y (Dao, Fu, Saab, et al. 2023) nhÆ°ng vá»›i cÃ¡c chuá»—i dÃ i hÆ¡n. ChÃºng tÃ´i cÅ©ng Ä‘iá»u tra kháº£ nÄƒng khÃ¡i quÃ¡t hÃ³a vÃ  ngoáº¡i suy báº±ng cÃ¡ch Ä‘Ã¡nh giÃ¡ trÃªn má»™t loáº¡t Ä‘á»™ dÃ i chuá»—i tá»« 2^6 = 64 Ä‘áº¿n 2^20 = 1048576 táº¡i thá»i gian kiá»ƒm tra.

MÃ´ hÃ¬nh. Theo cÃ´ng trÃ¬nh Ä‘Ã£ thiáº¿t láº­p vá» Ä‘áº§u cáº£m á»©ng, chÃºng tÃ´i sá»­ dá»¥ng cÃ¡c mÃ´ hÃ¬nh 2 lá»›p, cho phÃ©p chÃº Ã½ giáº£i quyáº¿t tÃ¡c vá»¥ Ä‘áº§u cáº£m á»©ng má»™t cÃ¡ch cÆ¡ há»c (Olsson et al. 2022). ChÃºng tÃ´i kiá»ƒm tra cáº£ chÃº Ã½ Ä‘a Ä‘áº§u (8 Ä‘áº§u, vá»›i cÃ¡c mÃ£ hÃ³a vá»‹ trÃ­ khÃ¡c nhau) vÃ  cÃ¡c biáº¿n thá»ƒ SSM. ChÃºng tÃ´i sá»­ dá»¥ng chiá»u mÃ´ hÃ¬nh ğ· lÃ  64 cho Mamba vÃ  128 cho cÃ¡c mÃ´ hÃ¬nh khÃ¡c.

Káº¿t quáº£. Báº£ng 2 cho tháº¥y Mambaâ€”hoáº·c chÃ­nh xÃ¡c hÆ¡n, lá»›p SSM chá»n lá»c cá»§a nÃ³â€”cÃ³ kháº£ nÄƒng giáº£i quyáº¿t tÃ¡c vá»¥ má»™t cÃ¡ch hoÃ n háº£o vÃ¬ kháº£ nÄƒng chá»n lá»c ghi nhá»› token liÃªn quan trong khi bá» qua má»i thá»© khÃ¡c á»Ÿ giá»¯a. NÃ³ khÃ¡i quÃ¡t hÃ³a hoÃ n háº£o Ä‘áº¿n cÃ¡c chuá»—i dÃ i hÃ ng triá»‡u, hoáº·c dÃ i hÆ¡n 4000Ã— so vá»›i nhá»¯ng gÃ¬ nÃ³ tháº¥y trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n, trong khi khÃ´ng cÃ³ phÆ°Æ¡ng phÃ¡p nÃ o khÃ¡c vÆ°á»£t quÃ¡ 2Ã—.

Trong cÃ¡c biáº¿n thá»ƒ mÃ£ hÃ³a vá»‹ trÃ­ cho cÃ¡c mÃ´ hÃ¬nh chÃº Ã½, xPos (Ä‘Æ°á»£c thiáº¿t káº¿ cho ngoáº¡i suy Ä‘á»™ dÃ i) hÆ¡i tá»‘t hÆ¡n cÃ¡c biáº¿n thá»ƒ khÃ¡c; cÅ©ng lÆ°u Ã½ ráº±ng táº¥t cáº£ cÃ¡c mÃ´ hÃ¬nh chÃº Ã½ chá»‰ Ä‘Æ°á»£c kiá»ƒm tra lÃªn Ä‘áº¿n Ä‘á»™ dÃ i chuá»—i 2^14 = 16384 do háº¡n cháº¿ bá»™ nhá»›. Trong cÃ¡c SSM khÃ¡c, H3 vÃ  Hyena tÆ°Æ¡ng tá»±, trÃ¡i ngÆ°á»£c vá»›i cÃ¡c phÃ¡t hiá»‡n trong Poli et al. (2023).

4.2 MÃ´ hÃ¬nh hÃ³a NgÃ´n ngá»¯

ChÃºng tÃ´i Ä‘Ã¡nh giÃ¡ kiáº¿n trÃºc Mamba vá» mÃ´ hÃ¬nh hÃ³a ngÃ´n ngá»¯ tá»± há»“i quy tiÃªu chuáº©n so vá»›i cÃ¡c kiáº¿n trÃºc khÃ¡c, cáº£ vá» cÃ¡c chá»‰ sá»‘ huáº¥n luyá»‡n trÆ°á»›c (perplexity) vÃ  Ä‘Ã¡nh giÃ¡ zero-shot. ChÃºng tÃ´i Ä‘áº·t kÃ­ch thÆ°á»›c mÃ´ hÃ¬nh (Ä‘á»™ sÃ¢u vÃ  chiá»u rá»™ng) Ä‘á»ƒ pháº£n Ã¡nh Ä‘áº·c táº£ GPT3. ChÃºng tÃ´i sá»­ dá»¥ng táº­p dá»¯ liá»‡u Pile (L. Gao, Biderman, et al. 2020), vÃ  tuÃ¢n theo cÃ´ng thá»©c huáº¥n luyá»‡n Ä‘Æ°á»£c mÃ´ táº£ trong Brown et al. (2020). Táº¥t cáº£ chi tiáº¿t huáº¥n luyá»‡n trong Phá»¥ lá»¥c E.2.

4.2.1 Luáº­t Tá»· lá»‡

Äá»‘i vá»›i baseline, chÃºng tÃ´i so sÃ¡nh vá»›i kiáº¿n trÃºc Transformer tiÃªu chuáº©n (kiáº¿n trÃºc GPT3), cÅ©ng nhÆ° cÃ´ng thá»©c Transformer máº¡nh nháº¥t mÃ  chÃºng tÃ´i biáº¿t (á»Ÿ Ä‘Ã¢y Ä‘Æ°á»£c gá»i lÃ  Transformer++), dá»±a trÃªn cÃ¡c kiáº¿n trÃºc PaLM vÃ  LLaMa (vÃ­ dá»¥: mÃ£ hÃ³a vá»‹ trÃ­ quay, SwiGLU MLP, RMSNorm thay vÃ¬ LayerNorm, khÃ´ng cÃ³ bias tuyáº¿n tÃ­nh, vÃ  tá»‘c Ä‘á»™ há»c cao hÆ¡n). ChÃºng tÃ´i cÅ©ng so sÃ¡nh vá»›i cÃ¡c kiáº¿n trÃºc dÆ°á»›i báº­c hai gáº§n Ä‘Ã¢y khÃ¡c (HÃ¬nh 4). Táº¥t cáº£ chi tiáº¿t mÃ´ hÃ¬nh trong Phá»¥ lá»¥c E.2.

HÃ¬nh 4 cho tháº¥y cÃ¡c luáº­t tá»· lá»‡ dÆ°á»›i giao thá»©c Chinchilla tiÃªu chuáº©n (Hoffmann et al. 2022), trÃªn cÃ¡c mÃ´ hÃ¬nh tá»« â‰ˆ 125M Ä‘áº¿n â‰ˆ 1.3B tham sá»‘. Mamba lÃ  mÃ´ hÃ¬nh khÃ´ng chÃº Ã½ Ä‘áº§u tiÃªn khá»›p vá»›i hiá»‡u suáº¥t cá»§a má»™t cÃ´ng thá»©c Transformer ráº¥t máº¡nh (Transformer++) Ä‘Ã£ trá»Ÿ thÃ nh tiÃªu chuáº©n, Ä‘áº·c biá»‡t lÃ  khi Ä‘á»™ dÃ i chuá»—i tÄƒng lÃªn. (ChÃºng tÃ´i lÆ°u Ã½ ráº±ng cÃ¡c káº¿t quáº£ Ä‘áº§y Ä‘á»§ vá» Ä‘á»™ dÃ i ngá»¯ cáº£nh 8k cÃ²n thiáº¿u cho cÃ¡c baseline RWKV vÃ  RetNet, cÃ¡c mÃ´ hÃ¬nh há»“i quy máº¡nh trÆ°á»›c Ä‘Ã¢y cÅ©ng cÃ³ thá»ƒ Ä‘Æ°á»£c hiá»ƒu nhÆ° SSM, do thiáº¿u cÃ¡c triá»ƒn khai hiá»‡u quáº£ dáº«n Ä‘áº¿n háº¿t bá»™ nhá»› hoáº·c yÃªu cáº§u tÃ­nh toÃ¡n khÃ´ng thá»±c táº¿.)

4.2.2 ÄÃ¡nh giÃ¡ Háº¡ nguá»“n

Báº£ng 3 cho tháº¥y hiá»‡u suáº¥t cá»§a Mamba trÃªn má»™t loáº¡t cÃ¡c tÃ¡c vá»¥ Ä‘Ã¡nh giÃ¡ háº¡ nguá»“n zero-shot phá»• biáº¿n. ChÃºng tÃ´i so sÃ¡nh vá»›i cÃ¡c mÃ´ hÃ¬nh mÃ£ nguá»“n má»Ÿ ná»•i tiáº¿ng nháº¥t á»Ÿ nhá»¯ng kÃ­ch thÆ°á»›c nÃ y, quan trá»ng nháº¥t lÃ  Pythia (Biderman et al. 2023) vÃ  RWKV (B. Peng et al. 2023) Ä‘Æ°á»£c huáº¥n luyá»‡n vá»›i cÃ¹ng tokenizer, táº­p dá»¯ liá»‡u, vÃ  Ä‘á»™ dÃ i huáº¥n luyá»‡n (300B token) nhÆ° cÃ¡c mÃ´ hÃ¬nh cá»§a chÃºng tÃ´i. (LÆ°u Ã½ ráº±ng Mamba vÃ  Pythia Ä‘Æ°á»£c huáº¥n luyá»‡n vá»›i Ä‘á»™ dÃ i ngá»¯ cáº£nh 2048, trong khi RWKV Ä‘Æ°á»£c huáº¥n luyá»‡n vá»›i Ä‘á»™ dÃ i ngá»¯ cáº£nh 1024.)

Äá»‘i vá»›i má»—i kÃ­ch thÆ°á»›c mÃ´ hÃ¬nh, Mamba lÃ  tá»‘t nháº¥t trong lá»›p trÃªn má»—i káº¿t quáº£ Ä‘Ã¡nh giÃ¡ duy nháº¥t, vÃ  thÆ°á»ng khá»›p vá»›i cÃ¡c baseline á»Ÿ gáº¥p Ä‘Ã´i kÃ­ch thÆ°á»›c mÃ´ hÃ¬nh.

4.3 MÃ´ hÃ¬nh hÃ³a DNA

ÄÆ°á»£c thÃºc Ä‘áº©y bá»Ÿi sá»± thÃ nh cÃ´ng cá»§a cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n, gáº§n Ä‘Ã¢y Ä‘Ã£ cÃ³ khÃ¡m phÃ¡ viá»‡c sá»­ dá»¥ng mÃ´ hÃ¬nh ná»n táº£ng cho di truyá»n há»c. DNA Ä‘Ã£ Ä‘Æ°á»£c vÃ­ nhÆ° ngÃ´n ngá»¯ trong viá»‡c nÃ³ bao gá»“m cÃ¡c chuá»—i token rá»i ráº¡c vá»›i má»™t tá»« vá»±ng há»¯u háº¡n. NÃ³ cÅ©ng Ä‘Æ°á»£c biáº¿t Ä‘áº¿n vÃ¬ yÃªu cáº§u cÃ¡c phá»¥ thuá»™c táº§m xa Ä‘á»ƒ mÃ´ hÃ¬nh hÃ³a (Avsec et al. 2021). ChÃºng tÃ´i Ä‘iá»u tra Mamba nhÆ° má»™t xÆ°Æ¡ng sá»‘ng FM cho huáº¥n luyá»‡n trÆ°á»›c vÃ  tinh chá»‰nh trong cÃ¹ng cÃ i Ä‘áº·t nhÆ° cÃ¡c cÃ´ng trÃ¬nh gáº§n Ä‘Ã¢y vá» cÃ¡c mÃ´ hÃ¬nh chuá»—i dÃ i cho DNA (Nguyen, Poli, et al. 2023). Äáº·c biá»‡t, chÃºng tÃ´i táº­p trung vÃ o hai khÃ¡m phÃ¡ vá» luáº­t tá»· lá»‡ qua kÃ­ch thÆ°á»›c mÃ´ hÃ¬nh vÃ  Ä‘á»™ dÃ i chuá»—i (HÃ¬nh 5), vÃ  má»™t tÃ¡c vá»¥ phÃ¢n loáº¡i tá»•ng há»£p khÃ³ háº¡ nguá»“n yÃªu cáº§u ngá»¯ cáº£nh dÃ i (HÃ¬nh 6).

Äá»‘i vá»›i huáº¥n luyá»‡n trÆ°á»›c, chÃºng tÃ´i chá»§ yáº¿u tuÃ¢n theo má»™t thiáº¿t láº­p mÃ´ hÃ¬nh hÃ³a ngÃ´n ngá»¯ nguyÃªn nhÃ¢n tiÃªu chuáº©n (dá»± Ä‘oÃ¡n token tiáº¿p theo) cho cÃ¡c chi tiáº¿t huáº¥n luyá»‡n vÃ  mÃ´ hÃ¬nh (xem thÃªm Phá»¥ lá»¥c E.2). Äá»‘i vá»›i táº­p dá»¯ liá»‡u, chÃºng tÃ´i chá»§ yáº¿u tuÃ¢n theo thiáº¿t láº­p cá»§a HyenaDNA (Nguyen, Poli, et al. 2023), sá»­ dá»¥ng táº­p dá»¯ liá»‡u HG38 cho huáº¥n luyá»‡n trÆ°á»›c bao gá»“m má»™t genome ngÆ°á»i duy nháº¥t vá»›i khoáº£ng 4.5 tá»· token (cáº·p base DNA) trong pháº§n huáº¥n luyá»‡n.

4.3.1 Tá»· lá»‡: KÃ­ch thÆ°á»›c MÃ´ hÃ¬nh

Trong thÃ­ nghiá»‡m nÃ y, chÃºng tÃ´i Ä‘iá»u tra cÃ¡c tÃ­nh cháº¥t tá»· lá»‡ cá»§a cÃ¡c mÃ´ hÃ¬nh ná»n táº£ng di truyá»n há»c vá»›i cÃ¡c xÆ°Æ¡ng sá»‘ng mÃ´ hÃ¬nh khÃ¡c nhau (HÃ¬nh 5 TrÃ¡i).

Huáº¥n luyá»‡n. Äá»ƒ thuáº­n lá»£i cho cÃ¡c baseline, chÃºng tÃ´i huáº¥n luyá»‡n trÃªn Ä‘á»™ dÃ i chuá»—i ngáº¯n 1024; nhÆ° Ä‘Æ°á»£c cho tháº¥y trong Pháº§n 4.3.2, chÃºng tÃ´i mong Ä‘á»£i káº¿t quáº£ sáº½ Æ°u tiÃªn Mamba tháº­m chÃ­ nhiá»u hÆ¡n á»Ÿ Ä‘á»™ dÃ i chuá»—i dÃ i hÆ¡n. ChÃºng tÃ´i cá»‘ Ä‘á»‹nh kÃ­ch thÆ°á»›c batch toÃ n cá»¥c lÃ  1024, tá»•ng cá»™ng 2^20 â‰ˆ 1M token trÃªn má»—i batch. CÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c huáº¥n luyá»‡n trong 10K bÆ°á»›c gradient tá»•ng cá»™ng 10B token.

Káº¿t quáº£. HÃ¬nh 5 (TrÃ¡i) cho tháº¥y perplexity huáº¥n luyá»‡n trÆ°á»›c cá»§a Mamba cáº£i thiá»‡n má»™t cÃ¡ch mÆ°á»£t mÃ  vá»›i kÃ­ch thÆ°á»›c mÃ´ hÃ¬nh, vÃ  Mamba tá»· lá»‡ tá»‘t hÆ¡n cáº£ HyenaDNA vÃ  Transformer++. VÃ­ dá»¥, á»Ÿ kÃ­ch thÆ°á»›c mÃ´ hÃ¬nh lá»›n nháº¥t khoáº£ng â‰ˆ 40M tham sá»‘, Ä‘Æ°á»ng cong cho tháº¥y Mamba cÃ³ thá»ƒ khá»›p vá»›i cÃ¡c mÃ´ hÃ¬nh Transformer++ vÃ  HyenaDNA vá»›i khoáº£ng 3Ã— Ä‘áº¿n 4Ã— Ã­t tham sá»‘ hÆ¡n.

4.3.2 Tá»· lá»‡: Äá»™ dÃ i Ngá»¯ cáº£nh

Trong thÃ­ nghiá»‡m DNA tiáº¿p theo, chÃºng tÃ´i Ä‘iá»u tra cÃ¡c tÃ­nh cháº¥t tá»· lá»‡ cá»§a cÃ¡c mÃ´ hÃ¬nh Ä‘á»‘i vá»›i Ä‘á»™ dÃ i chuá»—i. ChÃºng tÃ´i chá»‰ so sÃ¡nh cÃ¡c mÃ´ hÃ¬nh HyenaDNA vÃ  Mamba, vÃ¬ chÃº Ã½ báº­c hai trá»Ÿ nÃªn cáº¥m Ä‘oÃ¡n vá» chi phÃ­ á»Ÿ Ä‘á»™ dÃ i chuá»—i dÃ i hÆ¡n. ChÃºng tÃ´i huáº¥n luyá»‡n trÆ°á»›c cÃ¡c mÃ´ hÃ¬nh trÃªn Ä‘á»™ dÃ i chuá»—i 2^10 = 1024, 2^12 = 4096, 2^14 = 16384, 2^16 = 65536, 2^18 = 262144, 2^20 = 1048576. ChÃºng tÃ´i cá»‘ Ä‘á»‹nh kÃ­ch thÆ°á»›c mÃ´ hÃ¬nh lÃ  6 lá»›p theo chiá»u rá»™ng 128 (khoáº£ng 1.3M-1.4M tham sá»‘). CÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c huáº¥n luyá»‡n trong 20K bÆ°á»›c gradient tá»•ng cá»™ng â‰ˆ 330B token. CÃ¡c Ä‘á»™ dÃ i chuá»—i dÃ i hÆ¡n sá»­ dá»¥ng khá»Ÿi Ä‘á»™ng Ä‘á»™ dÃ i chuá»—i tÆ°Æ¡ng tá»± nhÆ° (Nguyen, Poli, et al. 2023).

Káº¿t quáº£. HÃ¬nh 5 (Pháº£i) cho tháº¥y Mamba cÃ³ thá»ƒ sá»­ dá»¥ng ngá»¯ cáº£nh dÃ i hÆ¡n tháº­m chÃ­ lÃªn Ä‘áº¿n cÃ¡c chuá»—i cá»±c ká»³ dÃ i cÃ³ Ä‘á»™ dÃ i 1M, vÃ  perplexity huáº¥n luyá»‡n trÆ°á»›c cá»§a nÃ³ cáº£i thiá»‡n khi ngá»¯ cáº£nh tÄƒng lÃªn. Máº·t khÃ¡c, mÃ´ hÃ¬nh HyenaDNA trá»Ÿ nÃªn tá»‡ hÆ¡n vá»›i Ä‘á»™ dÃ i chuá»—i. Äiá»u nÃ y trá»±c quan tá»« tháº£o luáº­n trong Pháº§n 3.5 vá» cÃ¡c tÃ­nh cháº¥t cá»§a cÆ¡ cháº¿ chá»n lá»c. Äáº·c biá»‡t, cÃ¡c mÃ´ hÃ¬nh LTI khÃ´ng thá»ƒ chá»n lá»c bá» qua thÃ´ng tin; tá»« quan Ä‘iá»ƒm tÃ­ch cháº­p, má»™t kernel tÃ­ch cháº­p ráº¥t dÃ i Ä‘ang tá»•ng há»£p táº¥t cáº£ thÃ´ng tin qua má»™t chuá»—i dÃ i cÃ³ thá»ƒ ráº¥t á»“n Ã o. LÆ°u Ã½ ráº±ng trong khi HyenaDNA tuyÃªn bá»‘ cáº£i thiá»‡n vá»›i ngá»¯ cáº£nh dÃ i hÆ¡n, káº¿t quáº£ cá»§a há» khÃ´ng kiá»ƒm soÃ¡t thá»i gian tÃ­nh toÃ¡n.

4.3.3 PhÃ¢n loáº¡i LoÃ i Tá»•ng há»£p

ChÃºng tÃ´i Ä‘Ã¡nh giÃ¡ cÃ¡c mÃ´ hÃ¬nh trÃªn má»™t tÃ¡c vá»¥ háº¡ nguá»“n phÃ¢n loáº¡i giá»¯a 5 loÃ i khÃ¡c nhau báº±ng cÃ¡ch láº¥y máº«u ngáº«u nhiÃªn má»™t Ä‘oáº¡n liÃªn tá»¥c cá»§a DNA cá»§a chÃºng. TÃ¡c vá»¥ nÃ y Ä‘Æ°á»£c Ä‘iá»u chá»‰nh tá»« HyenaDNA, Ä‘Ã£ sá»­ dá»¥ng cÃ¡c loÃ i {ngÆ°á»i, lemur, chuá»™t, heo, hÃ  mÃ£}.

ChÃºng tÃ´i sá»­a Ä‘á»•i tÃ¡c vá»¥ Ä‘á»ƒ trá»Ÿ nÃªn thÃ¡ch thá»©c hÆ¡n Ä‘Ã¡ng ká»ƒ báº±ng cÃ¡ch phÃ¢n loáº¡i giá»¯a nÄƒm loÃ i vÆ°á»£n lá»›n {ngÆ°á»i, tinh tinh, gorilla, orangutan, bonobo}, Ä‘Æ°á»£c biáº¿t lÃ  chia sáº» 99% DNA cá»§a chÃºng.

HÃ¬nh 6 cho tháº¥y Mamba cÃ³ thá»ƒ sá»­ dá»¥ng tá»‘t hÆ¡n ngá»¯ cáº£nh dÃ i Ä‘á»ƒ cáº£i thiá»‡n hiá»‡u suáº¥t trÃªn tÃ¡c vá»¥ phÃ¢n loáº¡i loÃ i thÃ¡ch thá»©c nÃ y, trong khi HyenaDNA kÃ©m hiá»‡u quáº£ trong viá»‡c sá»­ dá»¥ng ngá»¯ cáº£nh dÃ i hÆ¡n.

4.4 MÃ´ hÃ¬nh hÃ³a vÃ  Táº¡o sinh Ã‚m thanh

Äá»‘i vá»›i phÆ°Æ¡ng thá»©c dáº¡ng sÃ³ng Ã¢m thanh, chÃºng tÃ´i so sÃ¡nh chá»§ yáº¿u vá»›i kiáº¿n trÃºc vÃ  giao thá»©c huáº¥n luyá»‡n SaShiMi (Goel et al. 2022). MÃ´ hÃ¬nh nÃ y bao gá»“m:

1. má»™t xÆ°Æ¡ng sá»‘ng U-Net vá»›i hai giai Ä‘oáº¡n pooling theo yáº¿u tá»‘ ğ‘ tÄƒng gáº¥p Ä‘Ã´i chiá»u mÃ´ hÃ¬nh ğ· má»—i giai Ä‘oáº¡n,
2. cÃ¡c khá»‘i S4 vÃ  MLP xen káº½ trong má»—i giai Ä‘oáº¡n.

ChÃºng tÃ´i xem xÃ©t viá»‡c thay tháº¿ cÃ¡c khá»‘i S4+MLP báº±ng cÃ¡c khá»‘i Mamba. Chi tiáº¿t thÃ­ nghiá»‡m trong Phá»¥ lá»¥c E.4.

4.4.1 Huáº¥n luyá»‡n TrÆ°á»›c Tá»± há»“i quy Ngá»¯ cáº£nh DÃ i

ChÃºng tÃ´i Ä‘Ã¡nh giÃ¡ cháº¥t lÆ°á»£ng huáº¥n luyá»‡n trÆ°á»›c (dá»± Ä‘oÃ¡n máº«u tiáº¿p theo tá»± há»“i quy) trÃªn YouTubeMix (DeepSound 2017), má»™t táº­p dá»¯ liá»‡u nháº¡c piano tiÃªu chuáº©n Ä‘Æ°á»£c sá»­ dá»¥ng bá»Ÿi cÃ´ng trÃ¬nh trÆ°á»›c Ä‘Ã¢y bao gá»“m 4 giá» nháº¡c piano solo, Ä‘Æ°á»£c láº¥y máº«u vá»›i tá»‘c Ä‘á»™ 16000 Hz. Chi tiáº¿t huáº¥n luyá»‡n trÆ°á»›c chá»§ yáº¿u tuÃ¢n theo thiáº¿t láº­p mÃ´ hÃ¬nh hÃ³a ngÃ´n ngá»¯ tiÃªu chuáº©n (Pháº§n 4.2). HÃ¬nh 7 Ä‘Ã¡nh giÃ¡ hiá»‡u á»©ng cá»§a viá»‡c tÄƒng Ä‘á»™ dÃ i chuá»—i huáº¥n luyá»‡n tá»« 2^13 = 8192 Ä‘áº¿n 2^20 â‰ˆ 10^6, trong khi giá»¯ tÃ­nh toÃ¡n cá»‘ Ä‘á»‹nh. (CÃ³ má»™t sá»‘ trÆ°á»ng há»£p cáº¡nh nhá» trong cÃ¡ch dá»¯ liá»‡u Ä‘Æ°á»£c tuyá»ƒn chá»n, cÃ³ thá»ƒ dáº«n Ä‘áº¿n cÃ¡c nÃºt trong cÃ¡c Ä‘Æ°á»ng cong tá»· lá»‡. VÃ­ dá»¥, chá»‰ cÃ³ cÃ¡c clip dÃ i má»™t phÃºt nÃªn Ä‘á»™ dÃ i chuá»—i tá»‘i Ä‘a thá»±c sá»± bá»‹ giá»›i háº¡n bá»Ÿi 60s Â· 16000Hz = 960000.)

Cáº£ Mamba vÃ  baseline SaShiMi (S4+MLP) Ä‘á»u cáº£i thiá»‡n liÃªn tá»¥c vá»›i Ä‘á»™ dÃ i ngá»¯ cáº£nh dÃ i hÆ¡n; Mamba tá»‘t hÆ¡n trong suá»‘t, vÃ  khoáº£ng cÃ¡ch má»Ÿ rá»™ng á»Ÿ Ä‘á»™ dÃ i dÃ i hÆ¡n. Chá»‰ sá»‘ chÃ­nh lÃ  bit trÃªn byte (BPB), lÃ  má»™t yáº¿u tá»‘ khÃ´ng Ä‘á»•i log(2) cá»§a tá»•n tháº¥t negative log-likelihood (NLL) tiÃªu chuáº©n cho huáº¥n luyá»‡n trÆ°á»›c cÃ¡c phÆ°Æ¡ng thá»©c khÃ¡c.

ChÃºng tÃ´i lÆ°u Ã½ má»™t chi tiáº¿t quan trá»ng: Ä‘Ã¢y lÃ  thÃ­ nghiá»‡m duy nháº¥t trong bÃ i bÃ¡o nÃ y mÃ  chÃºng tÃ´i chuyá»ƒn tá»« tham sá»‘ hÃ³a thá»±c sang phá»©c (Pháº§n 3.6). ChÃºng tÃ´i cho tháº¥y cÃ¡c ablation bá»• sung trong Phá»¥ lá»¥c E.4.

4.4.2 Táº¡o sinh Giá»ng nÃ³i Tá»± há»“i quy

SC09 lÃ  má»™t táº­p dá»¯ liá»‡u benchmark táº¡o sinh giá»ng nÃ³i (Donahue, McAuley, and Puckette 2019; Warden 2018), bao gá»“m cÃ¡c clip 1 giÃ¢y Ä‘Æ°á»£c láº¥y máº«u á»Ÿ 16000 Hz cá»§a cÃ¡c chá»¯ sá»‘ "zero" Ä‘áº¿n "nine" vá»›i cÃ¡c Ä‘áº·c tÃ­nh ráº¥t biáº¿n Ä‘á»•i. ChÃºng tÃ´i chá»§ yáº¿u tuÃ¢n theo thiáº¿t láº­p huáº¥n luyá»‡n tá»± há»“i quy vÃ  giao thá»©c táº¡o sinh cá»§a Goel et al. (2022).

Báº£ng 4 cho tháº¥y cÃ¡c chá»‰ sá»‘ tá»± Ä‘á»™ng cá»§a mÃ´ hÃ¬nh Mamba-UNet so vá»›i nhiá»u baseline khÃ¡c nhau tá»« Goel et al. (2022): WaveNet (Oord et al. 2016), SampleRNN (Mehri et al. 2017), WaveGAN (Donahue, McAuley, and Puckette 2019), DiffWave (Z. Kong et al. 2021), vÃ  SaShiMi. Má»™t mÃ´ hÃ¬nh Mamba nhá» vÆ°á»£t trá»™i hÆ¡n cÃ¡c mÃ´ hÃ¬nh dá»±a trÃªn GAN vÃ  khuáº¿ch tÃ¡n hiá»‡n Ä‘áº¡i (vÃ  lá»›n hÆ¡n nhiá»u). Má»™t mÃ´ hÃ¬nh lá»›n hÆ¡n khá»›p tham sá»‘ vá»›i cÃ¡c baseline cáº£i thiá»‡n thÃªm cÃ¡c chá»‰ sá»‘ Ä‘á»™ chÃ­nh xÃ¡c má»™t cÃ¡ch Ä‘Ã¡ng ká»ƒ.

Báº£ng 5 láº¥y mÃ´ hÃ¬nh Mamba nhá» vÃ  Ä‘iá»u tra cÃ¡c káº¿t há»£p cá»§a cÃ¡c kiáº¿n trÃºc khÃ¡c nhau cho cÃ¡c giai Ä‘oáº¡n ngoÃ i vÃ  giai Ä‘oáº¡n trung tÃ¢m. NÃ³ cho tháº¥y Mamba luÃ´n tá»‘t hÆ¡n S4+MLP trong cÃ¡c khá»‘i ngoÃ i, vÃ  Mamba > S4+MLP > MHA+MLP trong cÃ¡c khá»‘i trung tÃ¢m.

4.5 Benchmark Tá»‘c Ä‘á»™ vÃ  Bá»™ nhá»›

ChÃºng tÃ´i benchmark tá»‘c Ä‘á»™ cá»§a hoáº¡t Ä‘á»™ng quÃ©t SSM (má»Ÿ rá»™ng tráº¡ng thÃ¡i ğ‘ = 16), cÅ©ng nhÆ° thÃ´ng lÆ°á»£ng suy luáº­n Ä‘áº§u cuá»‘i Ä‘áº¿n Ä‘áº§u cuá»‘i cá»§a Mamba, trong HÃ¬nh 8. QuÃ©t SSM hiá»‡u quáº£ cá»§a chÃºng tÃ´i nhanh hÆ¡n triá»ƒn khai chÃº Ã½ tá»‘t nháº¥t mÃ  chÃºng tÃ´i biáº¿t (FlashAttention-2 (Dao 2024)) vÆ°á»£t quÃ¡ Ä‘á»™ dÃ i chuá»—i 2K, vÃ  lÃªn Ä‘áº¿n 20-40Ã— nhanh hÆ¡n triá»ƒn khai quÃ©t tiÃªu chuáº©n trong PyTorch. Mamba Ä‘áº¡t Ä‘Æ°á»£c thÃ´ng lÆ°á»£ng suy luáº­n cao hÆ¡n 4-5Ã— so vá»›i Transformer cÃ³ kÃ­ch thÆ°á»›c tÆ°Æ¡ng tá»±, vÃ¬ khÃ´ng cÃ³ bá»™ nhá»› Ä‘á»‡m KV nÃ³ cÃ³ thá»ƒ sá»­ dá»¥ng kÃ­ch thÆ°á»›c batch cao hÆ¡n nhiá»u. VÃ­ dá»¥, Mamba-6.9B (chÆ°a huáº¥n luyá»‡n) sáº½ cÃ³ thÃ´ng lÆ°á»£ng suy luáº­n cao hÆ¡n Transformer-1.3B nhá» hÆ¡n 5Ã—. Chi tiáº¿t trong Phá»¥ lá»¥c E.5, cÅ©ng bao gá»“m benchmark tiÃªu thá»¥ bá»™ nhá»›.

4.6 Ablation MÃ´ hÃ¬nh

ChÃºng tÃ´i thá»±c hiá»‡n má»™t loáº¡t ablation chi tiáº¿t vá» cÃ¡c thÃ nh pháº§n cá»§a mÃ´ hÃ¬nh chÃºng tÃ´i, táº­p trung vÃ o cÃ i Ä‘áº·t mÃ´ hÃ¬nh hÃ³a ngÃ´n ngá»¯ vá»›i cÃ¡c mÃ´ hÃ¬nh kÃ­ch thÆ°á»›c â‰ˆ 350M táº¡i sá»‘ lÆ°á»£ng token Chinchilla (cÃ¹ng cÃ i Ä‘áº·t nhÆ° HÃ¬nh 4).

4.6.1 Kiáº¿n trÃºc

Báº£ng 6 Ä‘iá»u tra cÃ¡c hiá»‡u á»©ng cá»§a kiáº¿n trÃºc (khá»‘i) vÃ  lá»›p SSM bÃªn trong cá»§a nÃ³ (HÃ¬nh 3). ChÃºng tÃ´i tháº¥y ráº±ng:
â€¢Trong cÃ¡c SSM khÃ´ng chá»n lá»c (LTI) trÆ°á»›c Ä‘Ã¢y, tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i tÃ­ch cháº­p toÃ n cá»¥c, hiá»‡u suáº¥t ráº¥t tÆ°Æ¡ng tá»±.
â€¢Thay tháº¿ biáº¿n thá»ƒ S4 cÃ³ giÃ¡ trá»‹ phá»©c tá»« cÃ´ng trÃ¬nh trÆ°á»›c Ä‘Ã¢y báº±ng má»™t biáº¿n thá»ƒ cÃ³ giÃ¡ trá»‹ thá»±c khÃ´ng áº£nh hÆ°á»Ÿng nhiá»u Ä‘áº¿n hiá»‡u suáº¥t, gá»£i Ã½ ráº±ng (Ã­t nháº¥t Ä‘á»‘i vá»›i LM) SSM cÃ³ giÃ¡ trá»‹ thá»±c cÃ³ thá»ƒ lÃ  lá»±a chá»n tá»‘t hÆ¡n khi tÃ­nh Ä‘áº¿n hiá»‡u quáº£ pháº§n cá»©ng.
â€¢Thay tháº¿ báº¥t ká»³ cÃ¡i nÃ o trong sá»‘ nÃ y báº±ng má»™t SSM chá»n lá»c (S6) cáº£i thiá»‡n hiá»‡u suáº¥t Ä‘Ã¡ng ká»ƒ, xÃ¡c thá»±c Ä‘á»™ng lá»±c cá»§a Pháº§n 3.
â€¢Kiáº¿n trÃºc Mamba hoáº¡t Ä‘á»™ng tÆ°Æ¡ng tá»± nhÆ° kiáº¿n trÃºc H3 trong khi Ä‘Æ¡n giáº£n hÆ¡n.

ChÃºng tÃ´i cÅ©ng Ä‘iá»u tra viá»‡c xen káº½ khá»‘i Mamba vá»›i cÃ¡c khá»‘i khÃ¡c nhÆ° MLP (má»™t kiáº¿n trÃºc truyá»n thá»‘ng) MHA (má»™t kiáº¿n trÃºc chÃº Ã½ lai) trong Phá»¥ lá»¥c E.2.2.

4.6.2 SSM Chá»n lá»c

Báº£ng 7 ablate lá»›p SSM chá»n lá»c báº±ng cÃ¡ch xem xÃ©t cÃ¡c káº¿t há»£p khÃ¡c nhau cá»§a cÃ¡c tham sá»‘ chá»n lá»c Î”, ğµ, vÃ  ğ¶ (Thuáº­t toÃ¡n 2), cho tháº¥y Î” lÃ  tham sá»‘ quan trá»ng nháº¥t do káº¿t ná»‘i cá»§a nÃ³ vá»›i cá»•ng RNN (Äá»‹nh lÃ½ 1).

Báº£ng 8 xem xÃ©t cÃ¡c khá»Ÿi táº¡o khÃ¡c nhau cá»§a SSM, Ä‘Ã£ Ä‘Æ°á»£c chá»©ng minh lÃ  táº¡o ra sá»± khÃ¡c biá»‡t lá»›n trong má»™t sá»‘ phÆ°Æ¡ng thá»©c dá»¯ liá»‡u vÃ  cÃ i Ä‘áº·t (Gu, Goel, and RÃ© 2022; Gu, Gupta, et al. 2022). Vá» mÃ´ hÃ¬nh hÃ³a ngÃ´n ngá»¯, chÃºng tÃ´i tháº¥y ráº±ng cÃ¡c khá»Ÿi táº¡o Ä‘Æ°á»ng chÃ©o cÃ³ giÃ¡ trá»‹ thá»±c Ä‘Æ¡n giáº£n hÆ¡n (S4D-Real, hÃ ng 3) thay vÃ¬ cÃ¡c tham sá»‘ hÃ³a cÃ³ giÃ¡ trá»‹ phá»©c tiÃªu chuáº©n hÆ¡n (S4D-Lin, hÃ ng 1) hoáº¡t Ä‘á»™ng tá»‘t hÆ¡n. CÃ¡c khá»Ÿi táº¡o ngáº«u nhiÃªn cÅ©ng hoáº¡t Ä‘á»™ng tá»‘t, phÃ¹ há»£p vá»›i cÃ¡c phÃ¡t hiá»‡n tá»« cÃ´ng trÃ¬nh trÆ°á»›c Ä‘Ã¢y (Mehta et al. 2023).

Báº£ng 9 vÃ  Báº£ng 10 xem xÃ©t viá»‡c thay Ä‘á»•i chiá»u cá»§a cÃ¡c phÃ©p chiáº¿u Î” vÃ  (ğµ, ğ¶) tÆ°Æ¡ng á»©ng. Thay Ä‘á»•i chÃºng tá»« tÄ©nh sang chá»n lá»c cung cáº¥p lá»£i Ã­ch nháº¥t, trong khi viá»‡c tÄƒng chiá»u thÃªm ná»¯a thÆ°á»ng cáº£i thiá»‡n hiá»‡u suáº¥t khiÃªm tá»‘n vá»›i má»™t sá»± tÄƒng nhá» trong sá»‘ lÆ°á»£ng tham sá»‘.

ÄÃ¡ng chÃº Ã½ Ä‘áº·c biá»‡t lÃ  sá»± cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ cá»§a SSM chá»n lá»c khi kÃ­ch thÆ°á»›c tráº¡ng thÃ¡i ğ‘ Ä‘Æ°á»£c tÄƒng lÃªn, vá»›i hÆ¡n 1.0 cáº£i thiá»‡n perplexity vá»›i chi phÃ­ chá»‰ 1% tham sá»‘ bá»• sung. Äiá»u nÃ y xÃ¡c thá»±c Ä‘á»™ng lá»±c cá»‘t lÃµi cá»§a chÃºng tÃ´i trong Pháº§n 3.1 vÃ  3.3.

5 Tháº£o luáº­n

ChÃºng tÃ´i tháº£o luáº­n vá» cÃ´ng trÃ¬nh liÃªn quan, háº¡n cháº¿, vÃ  má»™t sá»‘ hÆ°á»›ng tÆ°Æ¡ng lai.

CÃ´ng trÃ¬nh LiÃªn quan. Phá»¥ lá»¥c A tháº£o luáº­n vá» cÃ¡ch cÆ¡ cháº¿ chá»n lá»c liÃªn quan Ä‘áº¿n cÃ¡c khÃ¡i niá»‡m tÆ°Æ¡ng tá»±. Phá»¥ lá»¥c B cÃ³ má»™t pháº§n cÃ´ng trÃ¬nh liÃªn quan má»Ÿ rá»™ng vá» SSM vÃ  cÃ¡c mÃ´ hÃ¬nh liÃªn quan khÃ¡c.

KhÃ´ng cÃ³ Bá»¯a trÆ°a Miá»…n phÃ­: Phá»• LiÃªn tá»¥c-Rá»i ráº¡c. CÃ¡c SSM cÃ³ cáº¥u trÃºc ban Ä‘áº§u Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a nhÆ° cÃ¡c rá»i ráº¡c hÃ³a cá»§a cÃ¡c há»‡ thá»‘ng liÃªn tá»¥c (1), vÃ  Ä‘Ã£ cÃ³ má»™t bias quy náº¡p máº¡nh máº½ hÆ°á»›ng tá»›i cÃ¡c phÆ°Æ¡ng thá»©c dá»¯ liá»‡u thá»i gian liÃªn tá»¥c nhÆ° cÃ¡c tÃ­n hiá»‡u tri giÃ¡c (vÃ­ dá»¥: Ã¢m thanh, video). NhÆ° Ä‘Ã£ tháº£o luáº­n trong Pháº§n 3.1 vÃ  3.5, cÆ¡ cháº¿ chá»n lá»c kháº¯c phá»¥c Ä‘iá»ƒm yáº¿u cá»§a chÃºng trÃªn cÃ¡c phÆ°Æ¡ng thá»©c rá»i ráº¡c nhÆ° vÄƒn báº£n vÃ  DNA; nhÆ°ng Ä‘iá»u nÃ y ngÆ°á»£c láº¡i cÃ³ thá»ƒ cáº£n trá»Ÿ hiá»‡u suáº¥t cá»§a chÃºng trÃªn dá»¯ liá»‡u mÃ  cÃ¡c SSM LTI xuáº¥t sáº¯c. CÃ¡c ablation cá»§a chÃºng tÃ´i vá» dáº¡ng sÃ³ng Ã¢m thanh kiá»ƒm tra sá»± Ä‘Ã¡nh Ä‘á»•i nÃ y chi tiáº¿t hÆ¡n.

CÃ¡c Affordance Háº¡ nguá»“n. CÃ¡c mÃ´ hÃ¬nh ná»n táº£ng dá»±a trÃªn Transformer (Ä‘áº·c biá»‡t lÃ  LLM) cÃ³ má»™t há»‡ sinh thÃ¡i phong phÃº vá» cÃ¡c tÃ­nh cháº¥t vÃ  cháº¿ Ä‘á»™ tÆ°Æ¡ng tÃ¡c vá»›i cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c, nhÆ° tinh chá»‰nh, thÃ­ch á»©ng, prompting, há»c trong ngá»¯ cáº£nh, Ä‘iá»u chá»‰nh hÆ°á»›ng dáº«n, RLHF, lÆ°á»£ng tá»­ hÃ³a, v.v. ChÃºng tÃ´i Ä‘áº·c biá»‡t quan tÃ¢m Ä‘áº¿n viá»‡c liá»‡u cÃ¡c thay tháº¿ Transformer nhÆ° SSM cÃ³ cÃ¡c tÃ­nh cháº¥t vÃ  affordance tÆ°Æ¡ng tá»± hay khÃ´ng.

Tá»· lá»‡. ÄÃ¡nh giÃ¡ thá»±c nghiá»‡m cá»§a chÃºng tÃ´i bá»‹ giá»›i háº¡n á»Ÿ cÃ¡c kÃ­ch thÆ°á»›c mÃ´ hÃ¬nh nhá», dÆ°á»›i ngÆ°á»¡ng cá»§a háº§u háº¿t cÃ¡c LLM mÃ£ nguá»“n má»Ÿ máº¡nh (vÃ­ dá»¥: Llama (Touvron et al. 2023)) cÅ©ng nhÆ° cÃ¡c mÃ´ hÃ¬nh há»“i quy khÃ¡c nhÆ° RWKV (B. Peng et al. 2023) vÃ  RetNet (Y. Sun et al. 2023), Ä‘Ã£ Ä‘Æ°á»£c Ä‘Ã¡nh giÃ¡ á»Ÿ quy mÃ´ tham sá»‘ 7B vÃ  hÆ¡n. Váº«n cáº§n Ä‘Ã¡nh giÃ¡ liá»‡u Mamba váº«n so sÃ¡nh thuáº­n lá»£i á»Ÿ nhá»¯ng kÃ­ch thÆ°á»›c lá»›n hÆ¡n nÃ y. ChÃºng tÃ´i cÅ©ng lÆ°u Ã½ ráº±ng viá»‡c tá»· lá»‡ SSM cÃ³ thá»ƒ liÃªn quan Ä‘áº¿n cÃ¡c thÃ¡ch thá»©c ká»¹ thuáº­t thÃªm vÃ  Ä‘iá»u chá»‰nh Ä‘á»‘i vá»›i mÃ´ hÃ¬nh khÃ´ng Ä‘Æ°á»£c tháº£o luáº­n trong bÃ i bÃ¡o nÃ y.

6 Káº¿t luáº­n

ChÃºng tÃ´i giá»›i thiá»‡u má»™t cÆ¡ cháº¿ chá»n lá»c cho cÃ¡c mÃ´ hÃ¬nh khÃ´ng gian tráº¡ng thÃ¡i cÃ³ cáº¥u trÃºc, cho phÃ©p chÃºng thá»±c hiá»‡n lÃ½ luáº­n phá»¥ thuá»™c ngá»¯ cáº£nh trong khi tá»· lá»‡ tuyáº¿n tÃ­nh theo Ä‘á»™ dÃ i chuá»—i. Khi Ä‘Æ°á»£c káº¿t há»£p vÃ o má»™t kiáº¿n trÃºc Ä‘Æ¡n giáº£n khÃ´ng chÃº Ã½, Mamba Ä‘áº¡t Ä‘Æ°á»£c káº¿t quáº£ tá»‘i Æ°u trÃªn má»™t táº­p há»£p Ä‘a dáº¡ng cÃ¡c lÄ©nh vá»±c, nÆ¡i nÃ³ khá»›p hoáº·c vÆ°á»£t trá»™i hÆ¡n hiá»‡u suáº¥t cá»§a cÃ¡c mÃ´ hÃ¬nh Transformer máº¡nh. ChÃºng tÃ´i ráº¥t hÃ o há»©ng vá» cÃ¡c á»©ng dá»¥ng rá»™ng rÃ£i cá»§a cÃ¡c mÃ´ hÃ¬nh khÃ´ng gian tráº¡ng thÃ¡i chá»n lá»c Ä‘á»ƒ xÃ¢y dá»±ng cÃ¡c mÃ´ hÃ¬nh ná»n táº£ng cho cÃ¡c lÄ©nh vá»±c khÃ¡c nhau, Ä‘áº·c biá»‡t lÃ  trong cÃ¡c phÆ°Æ¡ng thá»©c má»›i ná»•i yÃªu cáº§u ngá»¯ cáº£nh dÃ i nhÆ° di truyá»n há»c, Ã¢m thanh, vÃ  video. Káº¿t quáº£ cá»§a chÃºng tÃ´i gá»£i Ã½ ráº±ng Mamba lÃ  má»™t á»©ng cá»­ viÃªn máº¡nh máº½ Ä‘á»ƒ trá»Ÿ thÃ nh xÆ°Æ¡ng sá»‘ng mÃ´ hÃ¬nh chuá»—i tá»•ng quÃ¡t.

Lá»i cáº£m Æ¡n

ChÃºng tÃ´i cáº£m Æ¡n Karan Goel, Arjun Desai, vÃ  Kush Bhatia vÃ¬ pháº£n há»“i há»¯u Ã­ch vá» báº£n tháº£o.

TÃ i liá»‡u tham kháº£o

[1] Martin Arjovsky, Amar Shah, vÃ  Yoshua Bengio. "Máº¡ng Tháº§n kinh Há»“i quy Tiáº¿n hÃ³a ÄÆ¡n vá»‹". Trong: Há»™i nghá»‹ Quá»‘c táº¿ vá» Há»c MÃ¡y (ICML). 2016, tr. 1120â€“1128.

[2] Å½iga Avsec, Vikram Agarwal, Daniel Visentin, Joseph R Ledsam, Agnieszka Grabska-Barwinska, Kyle R Taylor, Yannis Assael, John Jumper, Pushmeet Kohli, vÃ  David R Kelley. "Dá»± Ä‘oÃ¡n Biá»ƒu hiá»‡n Gen Hiá»‡u quáº£ tá»« Chuá»—i báº±ng cÃ¡ch TÃ­ch há»£p CÃ¡c TÆ°Æ¡ng tÃ¡c Táº§m xa". Trong: Nature Methods 18.10 (2021), tr. 1196â€“1203.

[3] Jimmy Ba, Geoffrey E Hinton, Volodymyr Mnih, Joel Z Leibo, vÃ  Catalin Ionescu. "Sá»­ dá»¥ng Trá»ng sá»‘ Nhanh Ä‘á»ƒ ChÃº Ã½ Ä‘áº¿n QuÃ¡ khá»© Gáº§n Ä‘Ã¢y". Trong: Advances in Neural Information Processing Systems (NeurIPS) 29 (2016).

[4] Jimmy Lei Ba, Jamie Ryan Kiros, vÃ  Geoffrey E Hinton. "Chuáº©n hÃ³a Lá»›p". Trong: arXiv preprint arXiv:1607.06450 (2016).

[5] Dzmitry Bahdanau, Kyunghyun Cho, vÃ  Yoshua Bengio. "Dá»‹ch MÃ¡y Tháº§n kinh báº±ng cÃ¡ch Há»c Äá»“ng thá»i CÄƒn chá»‰nh vÃ  Dá»‹ch". Trong: Há»™i nghá»‹ Quá»‘c táº¿ vá» Biá»ƒu diá»…n Há»c (ICLR). 2015.

[6] David Balduzzi vÃ  Muhammad Ghifary. "Máº¡ng Tháº§n kinh Há»“i quy Kiá»ƒu Máº¡nh". Trong: Há»™i nghá»‹ Quá»‘c táº¿ vá» Há»c MÃ¡y. PMLR. 2016, tr. 1292â€“1300.

[7] Stella Biderman, Hailey Schoelkopf, Quentin Gregory Anthony, Herbie Bradley, Kyle O'Brien, Eric Hallahan, Mohammad Aflah Khan, Shivanshu Purohit, USVSN Sai Prashanth, Edward Raff, vÃ  cá»™ng sá»±. "Pythia: Má»™t Bá»™ cÃ´ng cá»¥ Ä‘á»ƒ PhÃ¢n tÃ­ch CÃ¡c MÃ´ hÃ¬nh NgÃ´n ngá»¯ Lá»›n qua Huáº¥n luyá»‡n vÃ  Tá»· lá»‡". Trong: Há»™i nghá»‹ Quá»‘c táº¿ vá» Há»c MÃ¡y (ICML). PMLR. 2023, tr. 2397â€“2430.

[8] Yonatan Bisk, Rowan Zellers, Jianfeng Gao, Yejin Choi, vÃ  cá»™ng sá»±. "PIQA: LÃ½ luáº­n vá» ThÃ´ng thÆ°á»ng Váº­t lÃ½ trong NgÃ´n ngá»¯ Tá»± nhiÃªn". Trong: Proceedings of the AAAI conference on Artificial Intelligence. Táº­p 34. 2020.

[9] Sid Black, Stella Biderman, Eric Hallahan, Quentin Anthony, Leo Gao, Laurence Golding, Horace He, Connor Leahy, Kyle McDonell, Jason Phang, vÃ  cá»™ng sá»±. "Gpt-NeoX-20B: Má»™t MÃ´ hÃ¬nh NgÃ´n ngá»¯ Tá»± há»“i quy MÃ£ nguá»“n má»Ÿ". Trong: arXiv preprint arXiv:2204.06745 (2022).

[10] Guy E Blelloch. "Tá»•ng Tiá»n tá»‘ vÃ  á»¨ng dá»¥ng cá»§a ChÃºng". Trong: (1990).

[11] James Bradbury, Stephen Merity, Caiming Xiong, vÃ  Richard Socher. "Máº¡ng Tháº§n kinh Giáº£-há»“i quy". Trong: arXiv preprint arXiv:1611.01576 (2016).

[12] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, vÃ  cá»™ng sá»±. "CÃ¡c MÃ´ hÃ¬nh NgÃ´n ngá»¯ lÃ  NgÆ°á»i há»c Ãt-shot". Trong: Advances in Neural Information Processing Systems (NeurIPS) 33 (2020), tr. 1877â€“1901.

[13] Aydar Bulatov, Yuri Kuratov, vÃ  Mikhail S Burtsev. "Tá»· lá»‡ Transformer lÃªn 1M token vÃ  HÆ¡n ná»¯a vá»›i RMT". Trong: arXiv preprint arXiv:2304.11062 (2023).

[14] Rewon Child, Scott Gray, Alec Radford, vÃ  Ilya Sutskever. "Táº¡o sinh Chuá»—i DÃ i vá»›i Transformer ThÆ°a". Trong: arXiv preprint arXiv:1904.10509 (2019).

[15] Krzysztof Choromanski, Valerii Likhosherstov, David Dohan, Xingyou Song, Andreea Gane, Tamas Sarlos, Peter Hawkins, Jared Davis, Afroz Mohiuddin, Lukasz Kaiser, vÃ  cá»™ng sá»±. "Suy nghÄ© láº¡i ChÃº Ã½ vá»›i Performer". Trong: Há»™i nghá»‹ Quá»‘c táº¿ vá» Biá»ƒu diá»…n Há»c (ICLR). 2021.

[16] Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, vÃ  cá»™ng sá»±. "PaLM: Tá»· lá»‡ MÃ´ hÃ¬nh hÃ³a NgÃ´n ngá»¯ vá»›i Pathways". Trong: Journal of Machine Learning Research 24.240 (2023), tr. 1â€“113. url: http://jmlr.org/papers/v24/22-1144.html.

[17] Junyoung Chung, Caglar Gulcehre, KyungHyun Cho, vÃ  Yoshua Bengio. "ÄÃ¡nh giÃ¡ Thá»±c nghiá»‡m cá»§a Máº¡ng Tháº§n kinh Há»“i quy CÃ³ cá»•ng trÃªn MÃ´ hÃ¬nh hÃ³a Chuá»—i". Trong: arXiv preprint arXiv:1412.3555 (2014).

[18] Peter Clark, Isaac Cowhey, Oren Etzioni, Tushar Khot, Ashish Sabharwal, Carissa Schoenick, vÃ  Oyvind Tafjord. "NghÄ© ráº±ng Báº¡n Ä‘Ã£ Giáº£i quyáº¿t Tráº£ lá»i CÃ¢u há»i? Thá»­ ARC, ThÃ¡ch thá»©c LÃ½ luáº­n AI2". Trong: arXiv preprint arXiv:1803.05457 (2018).

[19] Tri Dao. "FlashAttention-2: ChÃº Ã½ Nhanh hÆ¡n vá»›i Song song vÃ  PhÃ¢n vÃ¹ng CÃ´ng viá»‡c Tá»‘t hÆ¡n". Trong: Há»™i nghá»‹ Quá»‘c táº¿ vá» Biá»ƒu diá»…n Há»c (ICLR). 2024.

[20] Tri Dao, Daniel Y Fu, Stefano Ermon, Atri Rudra, vÃ  Christopher RÃ©. "FlashAttention: ChÃº Ã½ ChÃ­nh xÃ¡c Nhanh vÃ  Hiá»‡u quáº£ Bá»™ nhá»› vá»›i Nháº­n thá»©c IO". Trong: Advances in Neural Information Processing Systems (NeurIPS). 2022.

[21] Tri Dao, Daniel Y Fu, Khaled K Saab, Armin W Thomas, Atri Rudra, vÃ  Christopher RÃ©. "HÃ  mÃ£ HÃ  mÃ£ ÄÃ³i: HÆ°á»›ng tá»›i MÃ´ hÃ¬nh hÃ³a NgÃ´n ngá»¯ vá»›i MÃ´ hÃ¬nh KhÃ´ng gian Tráº¡ng thÃ¡i". Trong: Há»™i nghá»‹ Quá»‘c táº¿ vá» Biá»ƒu diá»…n Há»c (ICLR). 2023.

[22] Yann N Dauphin, Angela Fan, Michael Auli, vÃ  David Grangier. "MÃ´ hÃ¬nh hÃ³a NgÃ´n ngá»¯ vá»›i Máº¡ng TÃ­ch cháº­p CÃ³ cá»•ng". Trong: Há»™i nghá»‹ Quá»‘c táº¿ vá» Há»c MÃ¡y (ICML). PMLR. 2017, tr. 933â€“941.

[23] DeepSound. SampleRNN. https://github.com/deepsound-project/samplernn-pytorch. 2017.

[24] Jiayu Ding, Shuming Ma, Li Dong, Xingxing Zhang, Shaohan Huang, Wenhui Wang, vÃ  Furu Wei. "LongNet: Tá»· lá»‡ Transformer lÃªn 1,000,000,000 Token". Trong: arXiv preprint arXiv:2307.02486 (2023).

[...pháº§n cÃ²n láº¡i cá»§a tÃ i liá»‡u tham kháº£o...]

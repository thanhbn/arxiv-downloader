# 2312.00752.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/convolution/2312.00752.pdf
# Kích thước tệp: 1168615 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Mamba: Mô Hình Hóa Chuỗi Thời Gian Tuyến Tính với Không Gian Trạng Thái Chọn Lọc
Albert Gu∗1 và Tri Dao∗2
1Khoa Học Máy Học, Đại học Carnegie Mellon
2Khoa Khoa học Máy tính, Đại học Princeton
agu@cs.cmu.edu, tri@tridao.me
Tóm tắt
Các mô hình nền tảng, hiện đang cung cấp sức mạnh cho hầu hết các ứng dụng thú vị trong học sâu, gần như hoàn toàn dựa trên kiến trúc Transformer và mô-đun chú ý cốt lõi của nó. Nhiều kiến trúc thời gian dưới bậc hai như chú ý tuyến tính, tích chập có cổng và các mô hình hồi quy, và các mô hình không gian trạng thái có cấu trúc (SSM) đã được phát triển để giải quyết tính không hiệu quả tính toán của Transformer trên các chuỗi dài, nhưng chúng không hoạt động tốt bằng chú ý trên các phương thức quan trọng như ngôn ngữ. Chúng tôi nhận định rằng một điểm yếu chính của các mô hình như vậy là khả năng thực hiện lý luận dựa trên nội dung của chúng, và thực hiện một số cải tiến. Đầu tiên, việc đơn giản cho phép các tham số SSM là hàm của đầu vào giải quyết điểm yếu của chúng với các phương thức rời rạc, cho phép mô hình chọn lọc truyền hoặc quên thông tin dọc theo chiều dài chuỗi tùy thuộc vào token hiện tại. Thứ hai, mặc dù thay đổi này ngăn việc sử dụng tích chập hiệu quả, chúng tôi thiết kế một thuật toán song song nhận biết phần cứng ở chế độ hồi quy. Chúng tôi tích hợp các SSM chọn lọc này vào một kiến trúc mạng thần kinh đầu cuối đến đầu cuối được đơn giản hóa mà không có chú ý hoặc thậm chí các khối MLP (Mamba). Mamba có suy luận nhanh (thông lượng cao hơn 5× so với Transformer) và tỷ lệ tuyến tính theo chiều dài chuỗi, và hiệu suất của nó cải thiện trên dữ liệu thực lên đến các chuỗi dài hàng triệu. Là một xương sống mô hình chuỗi tổng quát, Mamba đạt được hiệu suất tốt nhất hiện tại trên một số phương thức như ngôn ngữ, âm thanh và di truyền học. Về mô hình hóa ngôn ngữ, mô hình Mamba-3B của chúng tôi vượt trội hơn các Transformer cùng kích thước và tương đương với các Transformer gấp đôi kích thước của nó, cả trong việc huấn luyện trước và đánh giá hạ nguồn.

1 Giới thiệu
Các mô hình nền tảng (FM), hoặc các mô hình lớn được huấn luyện trước trên dữ liệu lớn sau đó được điều chỉnh cho các tác vụ hạ nguồn, đã xuất hiện như một mô hình hiệu quả trong học máy hiện đại. Xương sống của các FM này thường là các mô hình chuỗi, hoạt động trên các chuỗi đầu vào tùy ý từ nhiều lĩnh vực đa dạng như ngôn ngữ, hình ảnh, giọng nói, âm thanh, chuỗi thời gian và di truyền học (Brown et al. 2020; Dosovitskiy et al. 2020; Ismail Fawaz et al. 2019; Oord et al. 2016; Poli et al. 2023; Sutskever, Vinyals, and Quoc V Le 2014). Trong khi khái niệm này không liên quan đến một lựa chọn cụ thể của kiến trúc mô hình, các FM hiện đại chủ yếu dựa trên một loại mô hình chuỗi duy nhất: Transformer (Vaswani et al. 2017) và lớp chú ý cốt lõi của nó (Bahdanau, Cho, and Bengio 2015). Hiệu quả của tự chú ý được quy cho khả năng định tuyến thông tin dày đặc trong cửa sổ ngữ cảnh, cho phép nó mô hình hóa dữ liệu phức tạp. Tuy nhiên, tính chất này mang lại những nhược điểm cơ bản: không thể mô hình hóa bất cứ thứ gì bên ngoài cửa sổ hữu hạn, và tỷ lệ bậc hai đối với chiều dài cửa sổ.

Một lượng lớn nghiên cứu đã xuất hiện về các biến thể hiệu quả hơn của chú ý để khắc phục những nhược điểm này (Tay, Dehghani, Bahri, et al. 2022), nhưng thường phải đánh đổi chính những tính chất làm cho nó hiệu quả. Cho đến nay, không có biến thể nào trong số này được chứng minh là hiệu quả về mặt thực nghiệm ở quy mô lớn trên các lĩnh vực.

Gần đây, các mô hình chuỗi không gian trạng thái có cấu trúc (SSM) (Gu, Goel, and Ré 2022; Gu, Johnson, Goel, et al. 2021) đã xuất hiện như một lớp kiến trúc đầy hứa hẹn cho mô hình hóa chuỗi. Các mô hình này có thể được hiểu như một sự kết hợp của mạng thần kinh hồi quy (RNN) và mạng thần kinh tích chập (CNN), với cảm hứng từ các mô hình không gian trạng thái cổ điển (Kalman 1960). Lớp mô hình này có thể được tính toán rất hiệu quả dưới dạng hồi quy hoặc tích chập, với tỷ lệ tuyến tính hoặc gần tuyến tính theo chiều dài chuỗi. Ngoài ra, chúng có các cơ chế có nguyên tắc để mô hình hóa các phụ thuộc tầm xa (Gu, Dao, et al. 2020) trong một số phương thức dữ liệu nhất định, và đã thống trị các benchmark như Long Range Arena (Tay, Dehghani, Abnar, et al. 2021). Nhiều hương vị của SSM (Gu, Goel, and Ré 2022; Gu, Gupta, et al. 2022; Gupta, Gu, and Berant 2022; Y. Li et al. 2023; Ma et al. 2023; Orvieto et al. 2023; Smith, Warrington, and Linderman 2023) đã thành công trong các lĩnh vực liên quan đến dữ liệu tín hiệu liên tục như âm thanh và thị giác (Goel et al. 2022; Nguyen, Goel, et al. 2022; Saon, Gupta, and Cui 2023). Tuy nhiên, chúng ít hiệu quả hơn trong việc mô hình hóa dữ liệu rời rạc và dày đặc thông tin như văn bản.

Chúng tôi đề xuất một lớp mô hình không gian trạng thái chọn lọc mới, cải thiện các công trình trước đây trên nhiều trục để đạt được sức mạnh mô hình của Transformer trong khi tỷ lệ tuyến tính theo chiều dài chuỗi.

Cơ chế Chọn lọc. Đầu tiên, chúng tôi xác định một hạn chế chính của các mô hình trước đây: khả năng chọn lọc dữ liệu một cách hiệu quả theo cách phụ thuộc vào đầu vào (tức là tập trung vào hoặc bỏ qua các đầu vào cụ thể). Dựa trên trực giác từ các tác vụ tổng hợp quan trọng như sao chép chọn lọc và đầu cảm ứng, chúng tôi thiết kế một cơ chế chọn lọc đơn giản bằng cách tham số hóa các tham số SSM dựa trên đầu vào. Điều này cho phép mô hình lọc ra thông tin không liên quan và ghi nhớ thông tin liên quan vô thời hạn.

Thuật toán Nhận biết Phần cứng. Thay đổi đơn giản này đặt ra một thách thức kỹ thuật cho việc tính toán mô hình; thực tế, tất cả các mô hình SSM trước đây phải bất biến theo thời gian và đầu vào để có hiệu quả tính toán. Chúng tôi khắc phục điều này bằng một thuật toán nhận biết phần cứng tính toán mô hình một cách hồi quy với quét nhưng không cụ thể hóa trạng thái mở rộng để tránh truy cập IO giữa các cấp khác nhau của hệ thống phân cấp bộ nhớ GPU. Việc triển khai kết quả nhanh hơn các phương pháp trước đây cả về lý thuyết (tỷ lệ tuyến tính theo chiều dài chuỗi, so với giả tuyến tính cho tất cả các SSM dựa trên tích chập) và trên phần cứng hiện đại (lên đến 3× nhanh hơn trên GPU A100).

Kiến trúc. Chúng tôi đơn giản hóa các kiến trúc mô hình chuỗi sâu trước đây bằng cách kết hợp thiết kế của các kiến trúc SSM trước đây (Dao, Fu, Saab, et al. 2023) với khối MLP của Transformer thành một khối duy nhất, dẫn đến một thiết kế kiến trúc đơn giản và đồng nhất (Mamba) kết hợp các không gian trạng thái chọn lọc.

Các SSM chọn lọc, và bằng cách mở rộng kiến trúc Mamba, là các mô hình hoàn toàn hồi quy với các tính chất chính làm cho chúng phù hợp làm xương sống của các mô hình nền tảng tổng quát hoạt động trên các chuỗi. (i) Chất lượng cao: tính chọn lọc mang lại hiệu suất mạnh mẽ trên các phương thức dày đặc như ngôn ngữ và di truyền học. (ii) Huấn luyện và suy luận nhanh: tính toán và bộ nhớ tỷ lệ tuyến tính theo chiều dài chuỗi trong quá trình huấn luyện, và việc triển khai mô hình một cách tự hồi quy trong quá trình suy luận chỉ yêu cầu thời gian không đổi cho mỗi bước vì nó không yêu cầu bộ nhớ đệm của các phần tử trước đó. (iii) Ngữ cảnh dài: chất lượng và hiệu quả cùng nhau tạo ra cải thiện hiệu suất trên dữ liệu thực lên đến chiều dài chuỗi 1M.

Chúng tôi xác thực thực nghiệm tiềm năng của Mamba như một xương sống FM chuỗi tổng quát, cả về chất lượng huấn luyện trước và hiệu suất tác vụ cụ thể theo lĩnh vực, trên một số loại phương thức và cài đặt:

•Tổng hợp. Trên các tác vụ tổng hợp quan trọng như sao chép và đầu cảm ứng đã được đề xuất là chìa khóa cho các mô hình ngôn ngữ lớn, Mamba không chỉ giải quyết chúng một cách dễ dàng mà còn có thể ngoại suy các giải pháp vô thời hạn dài (>1M token).

•Âm thanh và Di truyền học. Mamba vượt trội hơn các mô hình tốt nhất hiện tại trước đây như SaShiMi, Hyena, và Transformer trong việc mô hình hóa dạng sóng âm thanh và chuỗi DNA, cả về chất lượng huấn luyện trước và các chỉ số hạ nguồn (ví dụ: giảm FID trên tập dữ liệu tạo giọng nói thách thức hơn một nửa). Trong cả hai cài đặt, hiệu suất của nó cải thiện với ngữ cảnh dài hơn lên đến các chuỗi dài hàng triệu.

•Mô hình hóa Ngôn ngữ. Mamba là mô hình chuỗi thời gian tuyến tính đầu tiên thực sự đạt được hiệu suất chất lượng Transformer, cả về perplexity huấn luyện trước và đánh giá hạ nguồn. Với các luật tỷ lệ lên đến 1B tham số, chúng tôi cho thấy Mamba vượt trội hơn hiệu suất của một loạt rộng các baseline, bao gồm các công thức huấn luyện Transformer hiện đại rất mạnh dựa trên LLaMa (Touvron et al. 2023). Mô hình ngôn ngữ Mamba của chúng tôi có thông lượng tạo sinh 5× so với Transformer có kích thước tương tự, và chất lượng của Mamba-3B tương đương với Transformer gấp đôi kích thước của nó (ví dụ: cao hơn 4 điểm trung bình về lý luận thông thường so với Pythia-3B và thậm chí vượt trội hơn Pythia-7B).

Mã mô hình và các checkpoint được huấn luyện trước được mã nguồn mở tại https://github.com/state-spaces/mamba.

2 Mô hình Không gian Trạng thái
Các mô hình chuỗi không gian trạng thái có cấu trúc (S4) là một lớp gần đây của các mô hình chuỗi cho học sâu có liên quan rộng rãi đến RNN, và CNN, và các mô hình không gian trạng thái cổ điển. Chúng được lấy cảm hứng bởi một hệ thống liên tục cụ thể (1) ánh xạ một

--- TRANG 2 ---
hàm hoặc chuỗi một chiều 𝑣(𝑡) ∈ ℝ ↦ 𝑦(𝑡) ∈ ℝ thông qua một trạng thái tiềm ẩn ngầm định ℎ(𝑡) ∈ ℝ^𝑁.

Cụ thể, các mô hình S4 được định nghĩa với bốn tham số (Δ, 𝐴, 𝐵, 𝐶), định nghĩa một phép biến đổi chuỗi-tới-chuỗi trong hai giai đoạn.

ℎ'(𝑡) = 𝐴ℎ(𝑡) + 𝐵𝑥(𝑡) (1a)
𝑦(𝑡) = 𝐶ℎ(𝑡) (1b)

ℎ_𝑡 = 𝐴ℎ_{𝑡−1} + 𝐵𝑥_𝑡 (2a)
𝑦_𝑡 = 𝐶ℎ_𝑡 (2b)

𝐾 = (𝐶𝐵, 𝐶𝐴𝐵, ..., 𝐶𝐴^𝑘𝐵, ...) (3a)
𝑦 = 𝑥 ∗ 𝐾 (3b)

Rời rạc hóa. Giai đoạn đầu tiên biến đổi các "tham số liên tục" (Δ, 𝐴, 𝐵) thành "tham số rời rạc" (𝐴̄, 𝐵̄) thông qua các công thức cố định 𝐴̄ = 𝑓_𝐴(Δ, 𝐴) và 𝐵̄ = 𝑓_𝐵(Δ, 𝐴, 𝐵), trong đó cặp (𝑓_𝐴, 𝑓_𝐵) được gọi là quy tắc rời rạc hóa. Có thể sử dụng các quy tắc khác nhau như zero-order hold (ZOH) được định nghĩa trong phương trình (4).

𝐴̄ = exp(Δ𝐴) 𝐵̄ = (Δ𝐴)^{-1}(exp(Δ𝐴) − 𝐼) · Δ𝐵 (4)

Rời rạc hóa có các kết nối sâu với các hệ thống thời gian liên tục có thể cung cấp cho chúng các tính chất bổ sung như bất biến độ phân giải (Nguyen, Goel, et al. 2022) và tự động đảm bảo rằng mô hình được chuẩn hóa đúng cách (Gu, Johnson, Timalsina, et al. 2023; Orvieto et al. 2023). Nó cũng có kết nối với các cơ chế cổng của RNN (Gu, Gulcehre, et al. 2020; Tallec and Ollivier 2018) mà chúng tôi sẽ xem xét lại trong Phần 3.5. Tuy nhiên, từ góc độ cơ học, rời rạc hóa có thể được xem đơn giản là bước đầu tiên của đồ thị tính toán trong lượt truyền xuôi của một SSM.

Các hương vị khác của SSM có thể bỏ qua bước rời rạc hóa và tham số hóa (𝐴̄, 𝐵̄) trực tiếp thay thế (Zhang et al. 2023), điều này có thể dễ lý luận hơn.

Tính toán. Sau khi các tham số đã được biến đổi từ (Δ, 𝐴, 𝐵, 𝐶) ↦ (𝐴̄, 𝐵̄, 𝐶), mô hình có thể được tính toán theo hai cách, hoặc là như một hồi quy tuyến tính (2) hoặc một tích chập toàn cục (3).

Thông thường, mô hình sử dụng chế độ tích chập (3) cho huấn luyện song song hiệu quả (nơi toàn bộ chuỗi đầu vào được nhìn thấy trước), và chuyển sang chế độ hồi quy (2) cho suy luận tự hồi quy hiệu quả (nơi các đầu vào được nhìn thấy từng bước thời gian).

Tính Bất biến Thời gian Tuyến tính (LTI). Một tính chất quan trọng của phương trình (1) đến (3) là động lực học của mô hình là không đổi theo thời gian. Nói cách khác (Δ, 𝐴, 𝐵, 𝐶), và do đó (𝐴̄, 𝐵̄) cũng vậy, được cố định cho tất cả các bước thời gian. Tính chất này được gọi là tính bất biến thời gian tuyến tính (LTI), có liên kết sâu sắc với hồi quy và tích chập. Không chính thức, chúng tôi nghĩ về các SSM LTI như tương đương với bất kỳ hồi quy tuyến tính (2a) hoặc tích chập (3b), và sử dụng LTI như một thuật ngữ tổng quát cho các lớp mô hình này.

Cho đến nay, tất cả các SSM có cấu trúc đều là LTI (ví dụ: được tính toán như tích chập) do các ràng buộc hiệu quả cơ bản, được thảo luận trong Phần 3.3. Tuy nhiên, một cái nhìn sâu sắc cốt lõi của công trình này là các mô hình LTI có những hạn chế cơ bản trong việc mô hình hóa một số loại dữ liệu nhất định, và các đóng góp kỹ thuật của chúng tôi liên quan đến việc loại bỏ ràng buộc LTI trong khi khắc phục các rào cản hiệu quả.

Cấu trúc và Kích thước. Cuối cùng, chúng tôi lưu ý rằng các SSM có cấu trúc được đặt tên như vậy vì việc tính toán chúng một cách hiệu quả cũng đòi hỏi phải áp đặt cấu trúc trên ma trận 𝐴. Hình thức cấu trúc phổ biến nhất là đường chéo (Gu, Gupta, et al. 2022; Gupta, Gu, and Berant 2022; Smith, Warrington, and Linderman 2023), mà chúng tôi cũng sử dụng.

Trong trường hợp này, các ma trận 𝐴 ∈ ℝ^{𝑁×𝑁}, 𝐵 ∈ ℝ^{𝑁×1}, 𝐶 ∈ ℝ^{1×𝑁} đều có thể được biểu diễn bằng 𝑁 số. Để hoạt động trên một chuỗi đầu vào 𝑥 có kích thước batch 𝐵 và chiều dài 𝐿 với 𝐷 kênh, SSM được áp dụng độc lập cho từng kênh. Lưu ý rằng trong trường hợp này, tổng trạng thái ẩn có chiều 𝐷𝑁 cho mỗi đầu vào, và việc tính toán nó trên chiều dài chuỗi yêu cầu 𝑂(𝐵𝐿𝐷𝑁) thời gian và bộ nhớ; đây là gốc rễ của rào cản hiệu quả cơ bản được giải quyết trong Phần 3.3.

Mô hình Không gian Trạng thái Tổng quát. Chúng tôi lưu ý rằng thuật ngữ mô hình không gian trạng thái có nghĩa rất rộng chỉ đơn giản đại diện cho khái niệm về bất kỳ quá trình hồi quy nào với trạng thái tiềm ẩn. Nó đã được sử dụng để chỉ nhiều khái niệm khác nhau trong các ngành khác nhau, bao gồm các quá trình quyết định Markov (MDP) (học tăng cường (Hafner et al. 2020)), mô hình nguyên nhân động (DCM) (thần kinh học tính toán (Friston, Harrison, and Penny 2003)), bộ lọc Kalman (điều khiển (Kalman 1960)), mô hình Markov ẩn (HMM) và hệ thống động lực học tuyến tính (LDS) (học máy), và các mô hình hồi quy (và đôi khi tích chập) nói chung (học sâu).

Trong suốt toàn bộ bài báo này, chúng tôi sử dụng thuật ngữ "SSM" để chỉ độc quyền lớp SSM có cấu trúc hoặc mô hình S4 (Gu, Goel, and Ré 2022; Gu, Gupta, et al. 2022; Gupta, Gu, and Berant 2022; Hasani et al. 2023; Ma et al. 2023; Smith, Warrington, and Linderman 2023) và sử dụng các thuật ngữ này một cách thay thế được. Để thuận tiện, chúng tôi cũng có thể bao gồm các dẫn xuất của các mô hình như vậy, chẳng hạn như những mô hình tập trung vào quan điểm hồi quy tuyến tính hoặc tích chập toàn cục (Y. Li et al. 2023; Orvieto et al. 2023; Poli et al. 2023), và làm rõ các sắc thái khi cần thiết.

Kiến trúc SSM. SSM là các phép biến đổi chuỗi độc lập có thể được kết hợp vào các kiến trúc mạng thần kinh đầu cuối đến đầu cuối. (Chúng tôi cũng đôi khi gọi các kiến trúc SSM là SSNN, tương đương với các lớp SSM như CNN đối với các lớp tích chập tuyến tính.) Chúng tôi thảo luận về một số kiến trúc SSM nổi tiếng nhất, nhiều trong số đó cũng sẽ phục vụ như các baseline chính của chúng tôi.

•Chú ý tuyến tính (Katharopoulos et al. 2020) là một xấp xỉ của tự chú ý liên quan đến một hồi quy có thể được xem như một SSM tuyến tính suy biến.

•H3 (Dao, Fu, Saab, et al. 2023) khái quát hóa hồi quy này để sử dụng S4; nó có thể được xem như một kiến trúc với một SSM được kẹp bởi hai kết nối có cổng (Hình 3). H3 cũng chèn một tích chập cục bộ tiêu chuẩn, mà họ đóng khung như một shift-SSM, trước lớp SSM chính.

•Hyena (Poli et al. 2023) sử dụng cùng kiến trúc như H3 nhưng thay thế lớp S4 bằng một tích chập toàn cục được tham số hóa MLP (Romero et al. 2021).

•RetNet (Y. Sun et al. 2023) thêm một cổng bổ sung vào kiến trúc và sử dụng một SSM đơn giản hơn, cho phép một đường tính toán song song thay thế, sử dụng một biến thể của chú ý đa đầu (MHA) thay vì tích chập.

•RWKV (B. Peng et al. 2023) là một RNN gần đây được thiết kế cho mô hình hóa ngôn ngữ dựa trên một xấp xỉ chú ý tuyến tính khác, Transformer không chú ý (S. Zhai et al. 2021). Cơ chế "WKV" chính của nó liên quan đến các hồi quy LTI và có thể được xem như tỷ lệ của hai SSM.

Các SSM và kiến trúc liên quan khác được thảo luận thêm trong phần công trình liên quan mở rộng (Phụ lục B). Chúng tôi đặc biệt nhấn mạnh S5 (Smith, Warrington, and Linderman 2023), QRNN (Bradbury et al. 2016), và SRU (Lei et al. 2017), mà chúng tôi xem như các phương pháp liên quan chặt chẽ nhất với SSM chọn lọc cốt lõi của chúng tôi.

--- TRANG 3 ---
3 Mô hình Không gian Trạng thái Chọn lọc

Chúng tôi thúc đẩy cơ chế chọn lọc của mình bằng cách sử dụng trực giác từ các tác vụ tổng hợp (Phần 3.1), sau đó giải thích cách kết hợp cơ chế này vào các mô hình không gian trạng thái (Phần 3.2). Các SSM biến đổi theo thời gian kết quả không thể sử dụng tích chập, đặt ra một thách thức kỹ thuật về cách tính toán chúng một cách hiệu quả. Chúng tôi khắc phục điều này bằng một thuật toán nhận biết phần cứng khai thác hệ thống phân cấp bộ nhớ trên phần cứng hiện đại (Phần 3.3). Sau đó chúng tôi mô tả một kiến trúc SSM đơn giản mà không có chú ý hoặc thậm chí các khối MLP (Phần 3.4). Cuối cùng, chúng tôi thảo luận về một số tính chất bổ sung của các cơ chế chọn lọc (Phần 3.5).

3.1 Động lực: Chọn lọc như một Phương tiện Nén

Chúng tôi lập luận rằng một vấn đề cơ bản của mô hình hóa chuỗi là nén ngữ cảnh thành một trạng thái nhỏ hơn. Thực tế, chúng ta có thể xem các sự đánh đổi của các mô hình chuỗi phổ biến từ quan điểm này. Ví dụ, chú ý vừa hiệu quả vừa không hiệu quả vì nó rõ ràng không nén ngữ cảnh chút nào. Điều này có thể được thấy từ thực tế là suy luận tự hồi quy yêu cầu lưu trữ rõ ràng toàn bộ ngữ cảnh (tức là bộ nhớ đệm KV), điều này trực tiếp gây ra suy luận thời gian tuyến tính chậm và huấn luyện thời gian bậc hai của Transformer. Mặt khác, các mô hình hồi quy hiệu quả vì chúng có trạng thái hữu hạn, ngụ ý suy luận thời gian không đổi và huấn luyện thời gian tuyến tính. Tuy nhiên, hiệu quả của chúng bị giới hạn bởi mức độ tốt mà trạng thái này đã nén ngữ cảnh.

Để hiểu nguyên tắc này, chúng tôi tập trung vào hai ví dụ chạy của các tác vụ tổng hợp (Hình 2).

•Tác vụ Sao chép Chọn lọc sửa đổi tác vụ Sao chép phổ biến (Arjovsky, Shah, and Bengio 2016) bằng cách thay đổi vị trí của các token cần ghi nhớ. Nó yêu cầu lý luận nhận thức nội dung để có thể ghi nhớ các token liên quan (có màu) và lọc ra những token không liên quan (trắng).

•Tác vụ Đầu Cảm ứng là một cơ chế nổi tiếng được giả định để giải thích phần lớn khả năng học trong ngữ cảnh của LLM (Olsson et al. 2022). Nó yêu cầu lý luận nhận thức ngữ cảnh để biết khi nào tạo ra đầu ra đúng trong ngữ cảnh thích hợp (đen).

Các tác vụ này tiết lộ chế độ thất bại của các mô hình LTI. Từ quan điểm hồi quy, động lực học không đổi của chúng (ví dụ: các chuyển đổi (𝐴̄, 𝐵̄) trong (2)) không thể cho phép chúng chọn thông tin đúng từ ngữ cảnh của chúng, hoặc ảnh hưởng đến trạng thái ẩn được truyền dọc theo chuỗi theo cách phụ thuộc vào đầu vào. Từ quan điểm tích chập, được biết rằng các tích chập toàn cục có thể giải quyết tác vụ Sao chép vanilla (Romero et al. 2021) vì nó chỉ yêu cầu nhận thức thời gian, nhưng chúng gặp khó khăn với tác vụ Sao chép Chọn lọc vì thiếu nhận thức nội dung (Hình 2). Cụ thể hơn, khoảng cách giữa đầu vào-đến-đầu ra đang thay đổi và không thể được mô hình hóa bởi các kernel tích chập tĩnh.

Tóm lại, sự đánh đổi hiệu quả so với hiệu quả của các mô hình chuỗi được đặc trưng bởi mức độ chúng nén trạng thái của chúng: các mô hình hiệu quả phải có trạng thái nhỏ, trong khi các mô hình hiệu quả phải có trạng thái chứa tất cả thông tin cần thiết từ ngữ cảnh. Đổi lại, chúng tôi đề xuất rằng một nguyên tắc cơ bản để xây dựng các mô hình chuỗi là tính chọn lọc: hoặc khả năng nhận thức ngữ cảnh để tập trung vào hoặc lọc ra các đầu vào thành một trạng thái tuần tự. Đặc biệt, một cơ chế chọn lọc kiểm soát cách thông tin truyền hoặc tương tác dọc theo chiều chuỗi (xem Phần 3.5 để thảo luận thêm).

3.2 Cải thiện SSM với Chọn lọc

Một phương pháp kết hợp cơ chế chọn lọc vào các mô hình là để các tham số của chúng ảnh hưởng đến các tương tác dọc theo chuỗi (ví dụ: động lực học hồi quy của RNN hoặc kernel tích chập của CNN) phụ thuộc vào đầu vào.

Thuật toán 1 và 2 minh họa cơ chế chọn lọc chính mà chúng tôi sử dụng. Sự khác biệt chính là đơn giản làm cho một số tham số Δ, 𝐵, 𝐶 trở thành hàm của đầu vào, cùng với các thay đổi liên quan đến hình dạng tensor trong suốt. Đặc biệt, chúng tôi nhấn mạnh rằng các tham số này bây giờ có chiều dài 𝐿, có nghĩa là mô hình đã thay đổi từ bất biến thời gian thành biến đổi theo thời gian. (Lưu ý rằng các chú thích hình dạng được mô tả trong Phần 2.) Điều này mất đi sự tương đương với tích chập (3) với các tác động đến hiệu quả của nó, được thảo luận tiếp theo.

Chúng tôi cụ thể chọn 𝑠_𝐵(𝑥) = Linear_𝑁(𝑥), 𝑠_𝐶(𝑥) = Linear_𝑁(𝑥), 𝑠_Δ(𝑥) = Broadcast_𝐷(Linear_1(𝑥)), và 𝜏_Δ = softplus, trong đó Linear_𝑑 là một phép chiếu có tham số đến chiều 𝑑. Sự lựa chọn của 𝑠_Δ và 𝜏_Δ là do một kết nối với các cơ chế cổng RNN được giải thích trong Phần 3.5.

--- TRANG 4 ---
Thuật toán 1 SSM (S4)
Đầu vào: 𝑥: (B, L, D)
Đầu ra: 𝑦: (B, L, D)
1: 𝐴: (D, N) ← Parameter ⊳ Đại diện cho ma trận có cấu trúc 𝑁 × 𝑁
2: 𝐵: (D, N) ← Parameter
3: 𝐶: (D, N) ← Parameter
4: Δ: (D) ← 𝜏_Δ(Parameter)
5: 𝐴̄, 𝐵̄: (D, N) ← discretize(Δ, 𝐴, 𝐵)
6: 𝑦 ← SSM(𝐴̄, 𝐵̄, 𝐶)(𝑥) ⊳ Bất biến thời gian: hồi quy hoặc tích chập
7: return 𝑦

Thuật toán 2 SSM + Chọn lọc (S6)
Đầu vào: 𝑥: (B, L, D)
Đầu ra: 𝑦: (B, L, D)
1: 𝐴: (D, N) ← Parameter ⊳ Đại diện cho ma trận có cấu trúc 𝑁 × 𝑁
2: 𝐵: (B, L, N) ← 𝑠_𝐵(𝑥)
3: 𝐶: (B, L, N) ← 𝑠_𝐶(𝑥)
4: Δ: (B, L, D) ← 𝜏_Δ(Parameter + 𝑠_Δ(𝑥))
5: 𝐴̄, 𝐵̄: (B, L, D, N) ← discretize(Δ, 𝐴, 𝐵)
6: 𝑦 ← SSM(𝐴̄, 𝐵̄, 𝐶)(𝑥) ⊳ Biến đổi theo thời gian: chỉ hồi quy (scan)
7: return 𝑦

3.3 Triển khai Hiệu quả của SSM Chọn lọc

Các primitive thân thiện với phần cứng như tích chập (Krizhevsky, Sutskever, and Hinton 2012) và chú ý (Bahdanau, Cho, and Bengio 2015; Vaswani et al. 2017) được ứng dụng rộng rãi. Ở đây chúng tôi nhằm mục đích làm cho các SSM chọn lọc hiệu quả trên phần cứng hiện đại (GPU) cũng vậy. Cơ chế chọn lọc khá tự nhiên, và các công trình trước đây đã cố gắng kết hợp các trường hợp đặc biệt của chọn lọc, chẳng hạn như để Δ thay đổi theo thời gian trong các SSM hồi quy (Gu, Dao, et al. 2020). Tuy nhiên, như đã đề cập trước đây, một hạn chế cốt lõi trong việc sử dụng SSM là hiệu quả tính toán của chúng, đây là lý do tại sao S4 và tất cả các dẫn xuất đều sử dụng các mô hình LTI (không chọn lọc), thường nhất là dưới dạng tích chập toàn cục.

3.3.1 Động lực của Các Mô hình Trước đây

Trước tiên chúng tôi xem xét lại động lực này và tổng quan về cách tiếp cận của chúng tôi để khắc phục các hạn chế của các phương pháp trước đây.

•Ở cấp độ cao, các mô hình hồi quy như SSM luôn cân bằng một sự đánh đổi giữa tính biểu đạt và tốc độ: như đã thảo luận trong Phần 3.1, các mô hình với chiều trạng thái ẩn lớn hơn sẽ hiệu quả hơn nhưng chậm hơn. Vì vậy chúng tôi muốn tối đa hóa chiều trạng thái ẩn mà không phải trả chi phí tốc độ và bộ nhớ.

•Lưu ý rằng chế độ hồi quy linh hoạt hơn chế độ tích chập, vì cái sau (3) được dẫn xuất từ việc mở rộng cái trước (2) (Gu, Goel, and Ré 2022; Gu, Johnson, Goel, et al. 2021). Tuy nhiên, điều này sẽ yêu cầu tính toán và cụ thể hóa trạng thái tiềm ẩn ℎ với hình dạng (B, L, D, N), lớn hơn nhiều (bằng một yếu tố của 𝑁, chiều trạng thái SSM) so với đầu vào 𝑥 và đầu ra 𝑦 có hình dạng (B, L, D). Vì vậy chế độ tích chập hiệu quả hơn được giới thiệu có thể bỏ qua tính toán trạng thái và cụ thể hóa một kernel tích chập (3a) chỉ có kích thước (B, L, D).

•Các mô hình không gian trạng thái LTI trước đây tận dụng các dạng hồi quy-tích chập kép để tăng chiều trạng thái hiệu quả bằng một yếu tố của 𝑁 (≈ 10−100), lớn hơn nhiều so với RNN truyền thống, mà không có hình phạt hiệu quả.

3.3.2 Tổng quan về Quét Chọn lọc: Mở rộng Trạng thái Nhận biết Phần cứng

Cơ chế chọn lọc được thiết kế để khắc phục các hạn chế của các mô hình LTI; đồng thời, do đó chúng tôi cần xem xét lại vấn đề tính toán của SSM. Chúng tôi giải quyết điều này bằng ba kỹ thuật cổ điển: hợp nhất kernel, quét song song, và tính toán lại. Chúng tôi thực hiện hai quan sát chính:

•Tính toán hồi quy ngây thơ sử dụng 𝑂(𝐵𝐿𝐷𝑁) FLOP trong khi tính toán tích chập sử dụng 𝑂(𝐵𝐿𝐷 log(𝐿)) FLOP, và cái trước có yếu tố không đổi thấp hơn. Vì vậy đối với các chuỗi dài và chiều trạng thái 𝑁 không quá lớn, chế độ hồi quy thực sự có thể sử dụng ít FLOP hơn.

•Hai thách thức là bản chất tuần tự của hồi quy, và việc sử dụng bộ nhớ lớn. Để giải quyết cái sau, giống như chế độ tích chập, chúng ta có thể cố gắng không thực sự cụ thể hóa toàn bộ trạng thái ℎ.

Ý tưởng chính là tận dụng các tính chất của các bộ tăng tốc hiện đại (GPU) để chỉ cụ thể hóa trạng thái ℎ ở các cấp độ hiệu quả hơn của hệ thống phân cấp bộ nhớ. Đặc biệt, hầu hết các hoạt động (trừ phép nhân ma trận) bị giới hạn bởi băng thông bộ nhớ (Dao, Fu, Ermon, et al. 2022; Ivanov et al. 2021; Williams, Waterman, and Patterson 2009). Điều này bao gồm hoạt động quét của chúng tôi, và chúng tôi sử dụng hợp nhất kernel để giảm số lượng IO bộ nhớ, dẫn đến tăng tốc đáng kể so với triển khai tiêu chuẩn.

Cụ thể, thay vì chuẩn bị đầu vào quét (𝐴̄, 𝐵̄) có kích thước (B, L, D, N) trong GPU HBM (bộ nhớ băng thông cao), chúng tôi tải các tham số SSM (Δ, 𝐴, 𝐵, 𝐶) trực tiếp từ HBM chậm đến SRAM nhanh, thực hiện rời rạc hóa và hồi quy trong SRAM, và sau đó ghi các đầu ra cuối cùng có kích thước (B, L, D) trở lại HBM.

Để tránh hồi quy tuần tự, chúng tôi quan sát rằng mặc dù không tuyến tính, nó vẫn có thể được song song hóa với một thuật toán quét song song hiệu quả công việc (Blelloch 1990; Martin and Cundy 2018; Smith, Warrington, and Linderman 2023).

Cuối cùng, chúng tôi cũng phải tránh lưu các trạng thái trung gian, cần thiết cho lan truyền ngược. Chúng tôi cẩn thận áp dụng kỹ thuật cổ điển của tính toán lại để giảm yêu cầu bộ nhớ: các trạng thái trung gian không được lưu trữ mà được tính toán lại trong lượt lan truyền ngược khi các đầu vào được tải từ HBM đến SRAM. Kết quả là, lớp quét chọn lọc hợp nhất có cùng yêu cầu bộ nhớ như một triển khai transformer được tối ưu hóa với FlashAttention.

Chi tiết về kernel hợp nhất và tính toán lại trong Phụ lục D. Lớp SSM Chọn lọc đầy đủ và thuật toán được minh họa trong Hình 1.

3.4 Một Kiến trúc SSM Đơn giản

Như với các SSM có cấu trúc, các SSM chọn lọc là các phép biến đổi chuỗi độc lập có thể được kết hợp linh hoạt vào các mạng thần kinh. Kiến trúc H3 là cơ sở cho các kiến trúc SSM nổi tiếng nhất (Phần 2), thường bao gồm một khối lấy cảm hứng từ chú ý tuyến tính xen kẽ với một khối MLP (perceptron đa lớp). Chúng tôi đơn giản hóa kiến trúc này bằng cách kết hợp hai thành phần này thành một, được xếp chồng đồng nhất (Hình 3). Điều này được lấy cảm hứng từ đơn vị chú ý có cổng (GAU) (Hua et al. 2022), đã làm điều tương tự cho chú ý.

Kiến trúc này liên quan đến việc mở rộng chiều mô hình 𝐷 bằng một yếu tố mở rộng có thể kiểm soát 𝐸. Đối với mỗi khối, hầu hết các tham số (3𝐸𝐷²) nằm trong các phép chiếu tuyến tính (2𝐸𝐷² cho các phép chiếu đầu vào, 𝐸𝐷² cho phép chiếu đầu ra) trong khi SSM bên trong đóng góp ít hơn. Số lượng tham số SSM (các phép chiếu cho Δ, 𝐵, 𝐶, và ma trận 𝐴) nhỏ hơn nhiều so với. Chúng tôi lặp lại khối này, xen kẽ với chuẩn hóa tiêu chuẩn và các kết nối dư, để tạo thành kiến trúc Mamba. Chúng tôi luôn cố định 𝐸 = 2 trong các thí nghiệm của mình và sử dụng hai chồng của khối để khớp với 12𝐷² tham số của các khối MHA (chú ý đa đầu) và MLP xen kẽ của Transformer. Chúng tôi sử dụng hàm kích hoạt SiLU / Swish (Hendrycks and Gimpel 2016; Ramachandran, Zoph, and Quoc V Le 2017), được thúc đẩy để Gated MLP trở thành biến thể "SwiGLU" phổ biến (Chowdhery et al. 2023; Dauphin et al. 2017; Shazeer 2020; Touvron et al. 2023).

Cuối cùng, chúng tôi cũng sử dụng một lớp chuẩn hóa tùy chọn (chúng tôi chọn LayerNorm (J. L. Ba, Kiros, and Hinton 2016)), được thúc đẩy bởi việc sử dụng lớp chuẩn hóa của RetNet ở vị trí tương tự (Y. Sun et al. 2023).

3.5 Tính chất của Cơ chế Chọn lọc

Cơ chế chọn lọc là một khái niệm rộng hơn có thể được áp dụng theo các cách khác nhau, chẳng hạn như đối với các RNN hoặc CNN truyền thống hơn, đối với các tham số khác nhau (ví dụ: 𝐴 trong Thuật toán 2), hoặc sử dụng các phép biến đổi khác nhau 𝑠(𝑥).

3.5.1 Kết nối với Cơ chế Cổng

Chúng tôi nhấn mạnh kết nối quan trọng nhất: cơ chế cổng cổ điển của RNN là một trường hợp của cơ chế chọn lọc của chúng tôi cho SSM. Chúng tôi lưu ý rằng kết nối giữa cổng RNN và rời rạc hóa của các hệ thống thời gian liên tục được thiết lập tốt (Funahashi and Nakamura 1993; Tallec and Ollivier 2018). Thực tế, Định lý 1 là một cải tiến của Gu, Johnson, Goel, et al. (2021, Bổ đề 3.1) khái quát hóa cho rời rạc hóa ZOH và các cổng phụ thuộc đầu vào (chứng minh trong Phụ lục C). Rộng hơn, Δ trong SSM có thể được xem đóng vai trò tổng quát của cơ chế cổng RNN. Phù hợp với công trình trước đây, chúng tôi áp dụng quan điểm rằng rời rạc hóa của SSM là nền tảng có nguyên tắc của các cơ chế cổng heuristic.

Định lý 1. Khi 𝑁 = 1, 𝐴 = −1, 𝐵 = 1, 𝑠_Δ = Linear(𝑥), và 𝜏_Δ = softplus, thì hồi quy SSM chọn lọc (Thuật toán 2) có dạng
𝑔_𝑡 = 𝜎(Linear(𝑥_𝑡))
ℎ_𝑡 = (1 − 𝑔_𝑡)ℎ_{𝑡−1} + 𝑔_𝑡𝑥_𝑡. (5)

Như đã đề cập trong Phần 3.2, các lựa chọn cụ thể của chúng tôi về 𝑠_Δ, 𝜏_Δ xuất phát từ kết nối này. Đặc biệt, lưu ý rằng nếu một đầu vào 𝑥_𝑡 nhất định nên được bỏ qua hoàn toàn (như cần thiết trong các tác vụ tổng hợp), tất cả các kênh 𝐷 nên bỏ qua nó, và vì vậy chúng tôi chiếu đầu vào xuống 1 chiều trước khi lặp lại/phát sóng với Δ.

3.5.2 Giải thích về Cơ chế Chọn lọc

Chúng tôi mở rộng về ba hiệu ứng cơ học cụ thể của chọn lọc.

Khoảng cách Biến đổi. Tính chọn lọc cho phép lọc ra các token nhiễu không liên quan có thể xảy ra giữa các đầu vào quan tâm. Điều này được minh họa bằng tác vụ Sao chép Chọn lọc, nhưng xảy ra phổ biến trong các phương thức dữ liệu thông thường, đặc biệt là đối với dữ liệu rời rạc - ví dụ sự hiện diện của các từ đệm ngôn ngữ như "um". Tính chất này phát sinh vì mô hình có thể lọc ra cơ học bất kỳ đầu vào 𝑥_𝑡 cụ thể nào, ví dụ trong trường hợp RNN có cổng (Định lý 1) khi 𝑔_𝑡 → 0.

Lọc Ngữ cảnh. Đã được quan sát thực nghiệm rằng nhiều mô hình chuỗi không cải thiện với ngữ cảnh dài hơn (F. Shi et al. 2023), mặc dù nguyên tắc rằng ngữ cảnh nhiều hơn sẽ dẫn đến hiệu suất tốt hơn một cách nghiêm ngặt. Một giải thích là nhiều mô hình chuỗi không thể hiệu quả bỏ qua ngữ cảnh không liên quan khi cần thiết; một ví dụ trực quan là các tích chập toàn cục (và các mô hình LTI nói chung). Mặt khác, các mô hình chọn lọc có thể đơn giản đặt lại trạng thái của chúng bất cứ lúc nào để loại bỏ lịch sử không liên quan, và do đó hiệu suất của chúng về nguyên tắc cải thiện một cách đơn điệu với độ dài ngữ cảnh (ví dụ: Phần 4.3.2).

Đặt lại Ranh giới. Trong các cài đặt nơi nhiều chuỗi độc lập được ghép lại với nhau, Transformer có thể giữ chúng tách biệt bằng cách khởi tạo một mặt nạ chú ý cụ thể, trong khi các mô hình LTI sẽ rò rỉ thông tin giữa các chuỗi. Các SSM chọn lọc cũng có thể đặt lại trạng thái của chúng tại các ranh giới (ví dụ: Δ_𝑡 → ∞, hoặc Định lý 1 khi 𝑔_𝑡 → 1). Các cài đặt này có thể xảy ra một cách nhân tạo (ví dụ: đóng gói các tài liệu lại với nhau để cải thiện việc sử dụng phần cứng) hoặc tự nhiên (ví dụ: ranh giới tập trong học tăng cường (Lu et al. 2023)).

Ngoài ra, chúng tôi mở rộng về các hiệu ứng của từng tham số chọn lọc.

Giải thích về Δ. Nói chung, Δ kiểm soát sự cân bằng giữa mức độ tập trung hoặc bỏ qua đầu vào hiện tại 𝑥_𝑡. Nó khái quát hóa các cổng RNN (ví dụ: 𝑔_𝑡 trong Định lý 1): về mặt cơ học, một Δ lớn đặt lại trạng thái ℎ và tập trung vào đầu vào hiện tại 𝑥, trong khi một Δ nhỏ duy trì trạng thái và bỏ qua đầu vào hiện tại. SSM (1)-(2) có thể được hiểu như một hệ thống liên tục được rời rạc hóa bởi một bước thời gian Δ, và trong ngữ cảnh này trực giác là Δ lớn → ∞ đại diện cho hệ thống tập trung vào đầu vào hiện tại lâu hơn (do đó "chọn" nó và quên trạng thái hiện tại của nó) trong khi Δ nhỏ → 0 đại diện cho một đầu vào thoáng qua bị bỏ qua.

Giải thích về 𝐴. Chúng tôi nhận xét rằng trong khi tham số 𝐴 cũng có thể chọn lọc, nó cuối cùng chỉ ảnh hưởng đến mô hình thông qua tương tác của nó với Δ qua 𝐴̄ = exp(Δ𝐴) (rời rạc hóa (4)). Vì vậy tính chọn lọc trong Δ đủ để đảm bảo tính chọn lọc trong (𝐴̄, 𝐵̄), và là nguồn cải thiện chính. Chúng tôi giả định rằng làm cho 𝐴 chọn lọc thêm vào (hoặc thay vì) Δ sẽ có hiệu suất tương tự, và bỏ qua nó để đơn giản.

Giải thích về 𝐵 và 𝐶. Như đã thảo luận trong Phần 3.1, tính chất quan trọng nhất của tính chọn lọc là lọc ra thông tin không liên quan để ngữ cảnh của mô hình chuỗi có thể được nén thành một trạng thái hiệu quả. Trong một SSM, việc sửa đổi 𝐵 và 𝐶 để chọn lọc cho phép kiểm soát tinh vi hơn về việc có cho phép một đầu vào 𝑥_𝑡 vào trạng thái ℎ_𝑡, hoặc trạng thái vào đầu ra 𝑦_𝑡. Những cái này có thể được hiểu như cho phép mô hình điều chỉnh động lực học hồi quy dựa trên nội dung (đầu vào) và ngữ cảnh (trạng thái ẩn) tương ứng.

3.6 Chi tiết Mô hình Bổ sung

Thực so với Phức. Hầu hết các SSM trước đây sử dụng số phức trong trạng thái ℎ của chúng, điều này cần thiết cho hiệu suất mạnh mẽ trên nhiều tác vụ trong các phương thức tri giác (Gu, Goel, and Ré 2022). Tuy nhiên, đã được quan sát thực nghiệm rằng các SSM hoàn toàn giá trị thực dường như hoạt động tốt, và có thể thậm chí tốt hơn, trong một số cài đặt (Ma et al. 2023). Chúng tôi sử dụng giá trị thực làm mặc định, hoạt động tốt cho tất cả trừ một tác vụ của chúng tôi; chúng tôi giả định rằng sự đánh đổi phức-thực liên quan đến phổ liên tục-rời rạc trong các phương thức dữ liệu, nơi số phức hữu ích cho các phương thức liên tục (ví dụ: âm thanh, video) nhưng không phải rời rạc (ví dụ: văn bản, DNA).

Khởi tạo. Hầu hết các SSM trước đây cũng đề xuất các khởi tạo đặc biệt, đặc biệt là trong trường hợp giá trị phức, có thể giúp ích trong một số cài đặt như các chế độ dữ liệu thấp. Khởi tạo mặc định của chúng tôi cho trường hợp phức là S4D-Lin và cho trường hợp thực là S4D-Real (Gu, Gupta, et al. 2022), dựa trên lý thuyết HIPPO (Gu, Dao, et al. 2020). Những cái này định nghĩa phần tử thứ 𝑛 của 𝐴 là −1/2 + 𝑛𝑖 và −(𝑛 + 1) tương ứng. Tuy nhiên, chúng tôi mong đợi nhiều khởi tạo sẽ hoạt động tốt, đặc biệt là trong các chế độ dữ liệu lớn và SSM giá trị thực; một số ablation được xem xét trong Phần 4.6.

Tham số hóa của Δ. Chúng tôi định nghĩa điều chỉnh chọn lọc cho Δ là 𝑠_Δ(𝑥) = Broadcast_𝐷(Linear_1(𝑥)), được thúc đẩy bởi cơ học của Δ (Phần 3.5). Chúng tôi quan sát rằng nó có thể được khái quát hóa từ chiều 1 đến một chiều lớn hơn R. Chúng tôi đặt điều này là một phần nhỏ của D, sử dụng một số lượng tham số không đáng kể so với các phép chiếu Linear chính trong khối. Chúng tôi cũng lưu ý rằng hoạt động phát sóng thay vào đó có thể được xem như một phép chiếu Linear khác, được khởi tạo theo một mẫu cụ thể của các số 1 và 0; nếu phép chiếu này có thể huấn luyện, điều này dẫn đến 𝑠_Δ(𝑥) = Linear_𝐷(Linear_𝑅(𝑥)) thay thế, có thể được xem như một phép chiếu thứ hạng thấp.

Trong các thí nghiệm của chúng tôi, tham số Δ (có thể được xem như một thuật ngữ bias) được khởi tạo thành 𝜏_Δ^{-1}(Uniform([0.001, 0.1])), theo công trình trước đây về SSM (Gu, Johnson, Timalsina, et al. 2023).

Chú thích 3.1. Để ngắn gọn trong các kết quả thí nghiệm của chúng tôi, đôi khi chúng tôi viết tắt các SSM chọn lọc là mô hình S6, vì chúng là mô hình S4 với một cơ chế chọn lọc và được tính toán với một scan.

--- TRANG 5 ---
4 Đánh giá Thực nghiệm

Trong Phần 4.1, chúng tôi kiểm tra khả năng của Mamba trong việc giải quyết hai tác vụ tổng hợp được thúc đẩy trong Phần 3.1. Sau đó chúng tôi đánh giá trên ba lĩnh vực, mỗi lĩnh vực được đánh giá về huấn luyện trước tự hồi quy cũng như các tác vụ hạ nguồn.

•Phần 4.2: huấn luyện trước mô hình ngôn ngữ (luật tỷ lệ), và đánh giá hạ nguồn zero-shot.
•Phần 4.3: huấn luyện trước chuỗi DNA, và tinh chỉnh trên một tác vụ phân loại chuỗi dài.
•Phần 4.4: huấn luyện trước dạng sóng âm thanh, và chất lượng của các clip giọng nói được tạo ra một cách tự hồi quy.

Cuối cùng, Phần 4.5 cho thấy hiệu quả tính toán của Mamba ở cả thời gian huấn luyện và suy luận, và Phần 4.6 ablate các thành phần khác nhau của kiến trúc và SSM chọn lọc.

4.1 Tác vụ Tổng hợp

Chi tiết thí nghiệm đầy đủ cho các tác vụ này bao gồm chi tiết tác vụ và giao thức huấn luyện trong Phụ lục E.1.

4.1.1 Sao chép Chọn lọc

Tác vụ Sao chép là một trong những tác vụ tổng hợp được nghiên cứu nhiều nhất cho mô hình hóa chuỗi, ban đầu được thiết kế để kiểm tra khả năng ghi nhớ của các mô hình hồi quy. Như đã thảo luận trong Phần 3.1, các SSM LTI (hồi quy tuyến tính và tích chập toàn cục) có thể dễ dàng giải quyết tác vụ này bằng cách chỉ theo dõi thời gian thay vì lý luận về dữ liệu; ví dụ, bằng cách xây dựng một kernel tích chập có độ dài chính xác phù hợp (Hình 2). Điều này đã được xác thực một cách rõ ràng trong công trình trước đây về tích chập toàn cục (Romero et al. 2021). Tác vụ Sao chép Chọn lọc ngăn cản lối tắt này bằng cách ngẫu nhiên hóa khoảng cách giữa các token. Lưu ý rằng tác vụ này đã được giới thiệu trước đây như tác vụ Denoising (Jing et al. 2019).

Lưu ý rằng nhiều công trình trước đây lập luận rằng việc thêm cổng kiến trúc (các tương tác nhân) có thể cung cấp cho các mô hình "sự phụ thuộc dữ liệu" và giải quyết các tác vụ liên quan (Dao, Fu, Saab, et al. 2023; Poli et al. 2023). Tuy nhiên, chúng tôi thấy giải thích này không đủ trực quan vì cổng như vậy không tương tác dọc theo trục chuỗi, và không thể ảnh hưởng đến khoảng cách giữa các token. Đặc biệt, cổng kiến trúc không phải là một trường hợp của cơ chế chọn lọc (Phụ lục A).

Bảng 1 xác nhận rằng các kiến trúc có cổng như H3 và Mamba chỉ cải thiện hiệu suất một phần, trong khi cơ chế chọn lọc (sửa đổi S4 thành S6) dễ dàng giải quyết tác vụ này, đặc biệt là khi kết hợp với các kiến trúc mạnh mẽ hơn này.

4.1.2 Đầu Cảm ứng

Đầu cảm ứng (Olsson et al. 2022) là một tác vụ đơn giản từ lăng kính giải thích cơ học (Elhage et al. 2021) có khả năng dự đoán đáng ngạc nhiên về khả năng học trong ngữ cảnh của LLM. Nó yêu cầu các mô hình thực hiện gọi lại liên tưởng và sao chép: ví dụ, nếu mô hình đã thấy một bigram như "Harry Potter" trong chuỗi, thì lần tiếp theo "Harry" xuất hiện trong cùng chuỗi, mô hình sẽ có thể dự đoán "Potter" bằng cách sao chép từ lịch sử.

Tập dữ liệu. Chúng tôi huấn luyện một mô hình 2 lớp trên tác vụ đầu cảm ứng ở độ dài chuỗi 256, với kích thước từ vựng 16, tương đương với công trình trước đây về tác vụ này (Dao, Fu, Saab, et al. 2023) nhưng với các chuỗi dài hơn. Chúng tôi cũng điều tra khả năng khái quát hóa và ngoại suy bằng cách đánh giá trên một loạt độ dài chuỗi từ 2^6 = 64 đến 2^20 = 1048576 tại thời gian kiểm tra.

Mô hình. Theo công trình đã thiết lập về đầu cảm ứng, chúng tôi sử dụng các mô hình 2 lớp, cho phép chú ý giải quyết tác vụ đầu cảm ứng một cách cơ học (Olsson et al. 2022). Chúng tôi kiểm tra cả chú ý đa đầu (8 đầu, với các mã hóa vị trí khác nhau) và các biến thể SSM. Chúng tôi sử dụng chiều mô hình 𝐷 là 64 cho Mamba và 128 cho các mô hình khác.

Kết quả. Bảng 2 cho thấy Mamba—hoặc chính xác hơn, lớp SSM chọn lọc của nó—có khả năng giải quyết tác vụ một cách hoàn hảo vì khả năng chọn lọc ghi nhớ token liên quan trong khi bỏ qua mọi thứ khác ở giữa. Nó khái quát hóa hoàn hảo đến các chuỗi dài hàng triệu, hoặc dài hơn 4000× so với những gì nó thấy trong quá trình huấn luyện, trong khi không có phương pháp nào khác vượt quá 2×.

Trong các biến thể mã hóa vị trí cho các mô hình chú ý, xPos (được thiết kế cho ngoại suy độ dài) hơi tốt hơn các biến thể khác; cũng lưu ý rằng tất cả các mô hình chú ý chỉ được kiểm tra lên đến độ dài chuỗi 2^14 = 16384 do hạn chế bộ nhớ. Trong các SSM khác, H3 và Hyena tương tự, trái ngược với các phát hiện trong Poli et al. (2023).

4.2 Mô hình hóa Ngôn ngữ

Chúng tôi đánh giá kiến trúc Mamba về mô hình hóa ngôn ngữ tự hồi quy tiêu chuẩn so với các kiến trúc khác, cả về các chỉ số huấn luyện trước (perplexity) và đánh giá zero-shot. Chúng tôi đặt kích thước mô hình (độ sâu và chiều rộng) để phản ánh đặc tả GPT3. Chúng tôi sử dụng tập dữ liệu Pile (L. Gao, Biderman, et al. 2020), và tuân theo công thức huấn luyện được mô tả trong Brown et al. (2020). Tất cả chi tiết huấn luyện trong Phụ lục E.2.

4.2.1 Luật Tỷ lệ

Đối với baseline, chúng tôi so sánh với kiến trúc Transformer tiêu chuẩn (kiến trúc GPT3), cũng như công thức Transformer mạnh nhất mà chúng tôi biết (ở đây được gọi là Transformer++), dựa trên các kiến trúc PaLM và LLaMa (ví dụ: mã hóa vị trí quay, SwiGLU MLP, RMSNorm thay vì LayerNorm, không có bias tuyến tính, và tốc độ học cao hơn). Chúng tôi cũng so sánh với các kiến trúc dưới bậc hai gần đây khác (Hình 4). Tất cả chi tiết mô hình trong Phụ lục E.2.

Hình 4 cho thấy các luật tỷ lệ dưới giao thức Chinchilla tiêu chuẩn (Hoffmann et al. 2022), trên các mô hình từ ≈ 125M đến ≈ 1.3B tham số. Mamba là mô hình không chú ý đầu tiên khớp với hiệu suất của một công thức Transformer rất mạnh (Transformer++) đã trở thành tiêu chuẩn, đặc biệt là khi độ dài chuỗi tăng lên. (Chúng tôi lưu ý rằng các kết quả đầy đủ về độ dài ngữ cảnh 8k còn thiếu cho các baseline RWKV và RetNet, các mô hình hồi quy mạnh trước đây cũng có thể được hiểu như SSM, do thiếu các triển khai hiệu quả dẫn đến hết bộ nhớ hoặc yêu cầu tính toán không thực tế.)

4.2.2 Đánh giá Hạ nguồn

Bảng 3 cho thấy hiệu suất của Mamba trên một loạt các tác vụ đánh giá hạ nguồn zero-shot phổ biến. Chúng tôi so sánh với các mô hình mã nguồn mở nổi tiếng nhất ở những kích thước này, quan trọng nhất là Pythia (Biderman et al. 2023) và RWKV (B. Peng et al. 2023) được huấn luyện với cùng tokenizer, tập dữ liệu, và độ dài huấn luyện (300B token) như các mô hình của chúng tôi. (Lưu ý rằng Mamba và Pythia được huấn luyện với độ dài ngữ cảnh 2048, trong khi RWKV được huấn luyện với độ dài ngữ cảnh 1024.)

Đối với mỗi kích thước mô hình, Mamba là tốt nhất trong lớp trên mỗi kết quả đánh giá duy nhất, và thường khớp với các baseline ở gấp đôi kích thước mô hình.

4.3 Mô hình hóa DNA

Được thúc đẩy bởi sự thành công của các mô hình ngôn ngữ lớn, gần đây đã có khám phá việc sử dụng mô hình nền tảng cho di truyền học. DNA đã được ví như ngôn ngữ trong việc nó bao gồm các chuỗi token rời rạc với một từ vựng hữu hạn. Nó cũng được biết đến vì yêu cầu các phụ thuộc tầm xa để mô hình hóa (Avsec et al. 2021). Chúng tôi điều tra Mamba như một xương sống FM cho huấn luyện trước và tinh chỉnh trong cùng cài đặt như các công trình gần đây về các mô hình chuỗi dài cho DNA (Nguyen, Poli, et al. 2023). Đặc biệt, chúng tôi tập trung vào hai khám phá về luật tỷ lệ qua kích thước mô hình và độ dài chuỗi (Hình 5), và một tác vụ phân loại tổng hợp khó hạ nguồn yêu cầu ngữ cảnh dài (Hình 6).

Đối với huấn luyện trước, chúng tôi chủ yếu tuân theo một thiết lập mô hình hóa ngôn ngữ nguyên nhân tiêu chuẩn (dự đoán token tiếp theo) cho các chi tiết huấn luyện và mô hình (xem thêm Phụ lục E.2). Đối với tập dữ liệu, chúng tôi chủ yếu tuân theo thiết lập của HyenaDNA (Nguyen, Poli, et al. 2023), sử dụng tập dữ liệu HG38 cho huấn luyện trước bao gồm một genome người duy nhất với khoảng 4.5 tỷ token (cặp base DNA) trong phần huấn luyện.

4.3.1 Tỷ lệ: Kích thước Mô hình

Trong thí nghiệm này, chúng tôi điều tra các tính chất tỷ lệ của các mô hình nền tảng di truyền học với các xương sống mô hình khác nhau (Hình 5 Trái).

Huấn luyện. Để thuận lợi cho các baseline, chúng tôi huấn luyện trên độ dài chuỗi ngắn 1024; như được cho thấy trong Phần 4.3.2, chúng tôi mong đợi kết quả sẽ ưu tiên Mamba thậm chí nhiều hơn ở độ dài chuỗi dài hơn. Chúng tôi cố định kích thước batch toàn cục là 1024, tổng cộng 2^20 ≈ 1M token trên mỗi batch. Các mô hình được huấn luyện trong 10K bước gradient tổng cộng 10B token.

Kết quả. Hình 5 (Trái) cho thấy perplexity huấn luyện trước của Mamba cải thiện một cách mượt mà với kích thước mô hình, và Mamba tỷ lệ tốt hơn cả HyenaDNA và Transformer++. Ví dụ, ở kích thước mô hình lớn nhất khoảng ≈ 40M tham số, đường cong cho thấy Mamba có thể khớp với các mô hình Transformer++ và HyenaDNA với khoảng 3× đến 4× ít tham số hơn.

4.3.2 Tỷ lệ: Độ dài Ngữ cảnh

Trong thí nghiệm DNA tiếp theo, chúng tôi điều tra các tính chất tỷ lệ của các mô hình đối với độ dài chuỗi. Chúng tôi chỉ so sánh các mô hình HyenaDNA và Mamba, vì chú ý bậc hai trở nên cấm đoán về chi phí ở độ dài chuỗi dài hơn. Chúng tôi huấn luyện trước các mô hình trên độ dài chuỗi 2^10 = 1024, 2^12 = 4096, 2^14 = 16384, 2^16 = 65536, 2^18 = 262144, 2^20 = 1048576. Chúng tôi cố định kích thước mô hình là 6 lớp theo chiều rộng 128 (khoảng 1.3M-1.4M tham số). Các mô hình được huấn luyện trong 20K bước gradient tổng cộng ≈ 330B token. Các độ dài chuỗi dài hơn sử dụng khởi động độ dài chuỗi tương tự như (Nguyen, Poli, et al. 2023).

Kết quả. Hình 5 (Phải) cho thấy Mamba có thể sử dụng ngữ cảnh dài hơn thậm chí lên đến các chuỗi cực kỳ dài có độ dài 1M, và perplexity huấn luyện trước của nó cải thiện khi ngữ cảnh tăng lên. Mặt khác, mô hình HyenaDNA trở nên tệ hơn với độ dài chuỗi. Điều này trực quan từ thảo luận trong Phần 3.5 về các tính chất của cơ chế chọn lọc. Đặc biệt, các mô hình LTI không thể chọn lọc bỏ qua thông tin; từ quan điểm tích chập, một kernel tích chập rất dài đang tổng hợp tất cả thông tin qua một chuỗi dài có thể rất ồn ào. Lưu ý rằng trong khi HyenaDNA tuyên bố cải thiện với ngữ cảnh dài hơn, kết quả của họ không kiểm soát thời gian tính toán.

4.3.3 Phân loại Loài Tổng hợp

Chúng tôi đánh giá các mô hình trên một tác vụ hạ nguồn phân loại giữa 5 loài khác nhau bằng cách lấy mẫu ngẫu nhiên một đoạn liên tục của DNA của chúng. Tác vụ này được điều chỉnh từ HyenaDNA, đã sử dụng các loài {người, lemur, chuột, heo, hà mã}.

Chúng tôi sửa đổi tác vụ để trở nên thách thức hơn đáng kể bằng cách phân loại giữa năm loài vượn lớn {người, tinh tinh, gorilla, orangutan, bonobo}, được biết là chia sẻ 99% DNA của chúng.

Hình 6 cho thấy Mamba có thể sử dụng tốt hơn ngữ cảnh dài để cải thiện hiệu suất trên tác vụ phân loại loài thách thức này, trong khi HyenaDNA kém hiệu quả trong việc sử dụng ngữ cảnh dài hơn.

4.4 Mô hình hóa và Tạo sinh Âm thanh

Đối với phương thức dạng sóng âm thanh, chúng tôi so sánh chủ yếu với kiến trúc và giao thức huấn luyện SaShiMi (Goel et al. 2022). Mô hình này bao gồm:

1. một xương sống U-Net với hai giai đoạn pooling theo yếu tố 𝑝 tăng gấp đôi chiều mô hình 𝐷 mỗi giai đoạn,
2. các khối S4 và MLP xen kẽ trong mỗi giai đoạn.

Chúng tôi xem xét việc thay thế các khối S4+MLP bằng các khối Mamba. Chi tiết thí nghiệm trong Phụ lục E.4.

4.4.1 Huấn luyện Trước Tự hồi quy Ngữ cảnh Dài

Chúng tôi đánh giá chất lượng huấn luyện trước (dự đoán mẫu tiếp theo tự hồi quy) trên YouTubeMix (DeepSound 2017), một tập dữ liệu nhạc piano tiêu chuẩn được sử dụng bởi công trình trước đây bao gồm 4 giờ nhạc piano solo, được lấy mẫu với tốc độ 16000 Hz. Chi tiết huấn luyện trước chủ yếu tuân theo thiết lập mô hình hóa ngôn ngữ tiêu chuẩn (Phần 4.2). Hình 7 đánh giá hiệu ứng của việc tăng độ dài chuỗi huấn luyện từ 2^13 = 8192 đến 2^20 ≈ 10^6, trong khi giữ tính toán cố định. (Có một số trường hợp cạnh nhỏ trong cách dữ liệu được tuyển chọn, có thể dẫn đến các nút trong các đường cong tỷ lệ. Ví dụ, chỉ có các clip dài một phút nên độ dài chuỗi tối đa thực sự bị giới hạn bởi 60s · 16000Hz = 960000.)

Cả Mamba và baseline SaShiMi (S4+MLP) đều cải thiện liên tục với độ dài ngữ cảnh dài hơn; Mamba tốt hơn trong suốt, và khoảng cách mở rộng ở độ dài dài hơn. Chỉ số chính là bit trên byte (BPB), là một yếu tố không đổi log(2) của tổn thất negative log-likelihood (NLL) tiêu chuẩn cho huấn luyện trước các phương thức khác.

Chúng tôi lưu ý một chi tiết quan trọng: đây là thí nghiệm duy nhất trong bài báo này mà chúng tôi chuyển từ tham số hóa thực sang phức (Phần 3.6). Chúng tôi cho thấy các ablation bổ sung trong Phụ lục E.4.

4.4.2 Tạo sinh Giọng nói Tự hồi quy

SC09 là một tập dữ liệu benchmark tạo sinh giọng nói (Donahue, McAuley, and Puckette 2019; Warden 2018), bao gồm các clip 1 giây được lấy mẫu ở 16000 Hz của các chữ số "zero" đến "nine" với các đặc tính rất biến đổi. Chúng tôi chủ yếu tuân theo thiết lập huấn luyện tự hồi quy và giao thức tạo sinh của Goel et al. (2022).

Bảng 4 cho thấy các chỉ số tự động của mô hình Mamba-UNet so với nhiều baseline khác nhau từ Goel et al. (2022): WaveNet (Oord et al. 2016), SampleRNN (Mehri et al. 2017), WaveGAN (Donahue, McAuley, and Puckette 2019), DiffWave (Z. Kong et al. 2021), và SaShiMi. Một mô hình Mamba nhỏ vượt trội hơn các mô hình dựa trên GAN và khuếch tán hiện đại (và lớn hơn nhiều). Một mô hình lớn hơn khớp tham số với các baseline cải thiện thêm các chỉ số độ chính xác một cách đáng kể.

Bảng 5 lấy mô hình Mamba nhỏ và điều tra các kết hợp của các kiến trúc khác nhau cho các giai đoạn ngoài và giai đoạn trung tâm. Nó cho thấy Mamba luôn tốt hơn S4+MLP trong các khối ngoài, và Mamba > S4+MLP > MHA+MLP trong các khối trung tâm.

4.5 Benchmark Tốc độ và Bộ nhớ

Chúng tôi benchmark tốc độ của hoạt động quét SSM (mở rộng trạng thái 𝑁 = 16), cũng như thông lượng suy luận đầu cuối đến đầu cuối của Mamba, trong Hình 8. Quét SSM hiệu quả của chúng tôi nhanh hơn triển khai chú ý tốt nhất mà chúng tôi biết (FlashAttention-2 (Dao 2024)) vượt quá độ dài chuỗi 2K, và lên đến 20-40× nhanh hơn triển khai quét tiêu chuẩn trong PyTorch. Mamba đạt được thông lượng suy luận cao hơn 4-5× so với Transformer có kích thước tương tự, vì không có bộ nhớ đệm KV nó có thể sử dụng kích thước batch cao hơn nhiều. Ví dụ, Mamba-6.9B (chưa huấn luyện) sẽ có thông lượng suy luận cao hơn Transformer-1.3B nhỏ hơn 5×. Chi tiết trong Phụ lục E.5, cũng bao gồm benchmark tiêu thụ bộ nhớ.

4.6 Ablation Mô hình

Chúng tôi thực hiện một loạt ablation chi tiết về các thành phần của mô hình chúng tôi, tập trung vào cài đặt mô hình hóa ngôn ngữ với các mô hình kích thước ≈ 350M tại số lượng token Chinchilla (cùng cài đặt như Hình 4).

4.6.1 Kiến trúc

Bảng 6 điều tra các hiệu ứng của kiến trúc (khối) và lớp SSM bên trong của nó (Hình 3). Chúng tôi thấy rằng:
•Trong các SSM không chọn lọc (LTI) trước đây, tương đương với tích chập toàn cục, hiệu suất rất tương tự.
•Thay thế biến thể S4 có giá trị phức từ công trình trước đây bằng một biến thể có giá trị thực không ảnh hưởng nhiều đến hiệu suất, gợi ý rằng (ít nhất đối với LM) SSM có giá trị thực có thể là lựa chọn tốt hơn khi tính đến hiệu quả phần cứng.
•Thay thế bất kỳ cái nào trong số này bằng một SSM chọn lọc (S6) cải thiện hiệu suất đáng kể, xác thực động lực của Phần 3.
•Kiến trúc Mamba hoạt động tương tự như kiến trúc H3 trong khi đơn giản hơn.

Chúng tôi cũng điều tra việc xen kẽ khối Mamba với các khối khác như MLP (một kiến trúc truyền thống) MHA (một kiến trúc chú ý lai) trong Phụ lục E.2.2.

4.6.2 SSM Chọn lọc

Bảng 7 ablate lớp SSM chọn lọc bằng cách xem xét các kết hợp khác nhau của các tham số chọn lọc Δ, 𝐵, và 𝐶 (Thuật toán 2), cho thấy Δ là tham số quan trọng nhất do kết nối của nó với cổng RNN (Định lý 1).

Bảng 8 xem xét các khởi tạo khác nhau của SSM, đã được chứng minh là tạo ra sự khác biệt lớn trong một số phương thức dữ liệu và cài đặt (Gu, Goel, and Ré 2022; Gu, Gupta, et al. 2022). Về mô hình hóa ngôn ngữ, chúng tôi thấy rằng các khởi tạo đường chéo có giá trị thực đơn giản hơn (S4D-Real, hàng 3) thay vì các tham số hóa có giá trị phức tiêu chuẩn hơn (S4D-Lin, hàng 1) hoạt động tốt hơn. Các khởi tạo ngẫu nhiên cũng hoạt động tốt, phù hợp với các phát hiện từ công trình trước đây (Mehta et al. 2023).

Bảng 9 và Bảng 10 xem xét việc thay đổi chiều của các phép chiếu Δ và (𝐵, 𝐶) tương ứng. Thay đổi chúng từ tĩnh sang chọn lọc cung cấp lợi ích nhất, trong khi việc tăng chiều thêm nữa thường cải thiện hiệu suất khiêm tốn với một sự tăng nhỏ trong số lượng tham số.

Đáng chú ý đặc biệt là sự cải thiện đáng kể của SSM chọn lọc khi kích thước trạng thái 𝑁 được tăng lên, với hơn 1.0 cải thiện perplexity với chi phí chỉ 1% tham số bổ sung. Điều này xác thực động lực cốt lõi của chúng tôi trong Phần 3.1 và 3.3.

5 Thảo luận

Chúng tôi thảo luận về công trình liên quan, hạn chế, và một số hướng tương lai.

Công trình Liên quan. Phụ lục A thảo luận về cách cơ chế chọn lọc liên quan đến các khái niệm tương tự. Phụ lục B có một phần công trình liên quan mở rộng về SSM và các mô hình liên quan khác.

Không có Bữa trưa Miễn phí: Phổ Liên tục-Rời rạc. Các SSM có cấu trúc ban đầu được định nghĩa như các rời rạc hóa của các hệ thống liên tục (1), và đã có một bias quy nạp mạnh mẽ hướng tới các phương thức dữ liệu thời gian liên tục như các tín hiệu tri giác (ví dụ: âm thanh, video). Như đã thảo luận trong Phần 3.1 và 3.5, cơ chế chọn lọc khắc phục điểm yếu của chúng trên các phương thức rời rạc như văn bản và DNA; nhưng điều này ngược lại có thể cản trở hiệu suất của chúng trên dữ liệu mà các SSM LTI xuất sắc. Các ablation của chúng tôi về dạng sóng âm thanh kiểm tra sự đánh đổi này chi tiết hơn.

Các Affordance Hạ nguồn. Các mô hình nền tảng dựa trên Transformer (đặc biệt là LLM) có một hệ sinh thái phong phú về các tính chất và chế độ tương tác với các mô hình được huấn luyện trước, như tinh chỉnh, thích ứng, prompting, học trong ngữ cảnh, điều chỉnh hướng dẫn, RLHF, lượng tử hóa, v.v. Chúng tôi đặc biệt quan tâm đến việc liệu các thay thế Transformer như SSM có các tính chất và affordance tương tự hay không.

Tỷ lệ. Đánh giá thực nghiệm của chúng tôi bị giới hạn ở các kích thước mô hình nhỏ, dưới ngưỡng của hầu hết các LLM mã nguồn mở mạnh (ví dụ: Llama (Touvron et al. 2023)) cũng như các mô hình hồi quy khác như RWKV (B. Peng et al. 2023) và RetNet (Y. Sun et al. 2023), đã được đánh giá ở quy mô tham số 7B và hơn. Vẫn cần đánh giá liệu Mamba vẫn so sánh thuận lợi ở những kích thước lớn hơn này. Chúng tôi cũng lưu ý rằng việc tỷ lệ SSM có thể liên quan đến các thách thức kỹ thuật thêm và điều chỉnh đối với mô hình không được thảo luận trong bài báo này.

6 Kết luận

Chúng tôi giới thiệu một cơ chế chọn lọc cho các mô hình không gian trạng thái có cấu trúc, cho phép chúng thực hiện lý luận phụ thuộc ngữ cảnh trong khi tỷ lệ tuyến tính theo độ dài chuỗi. Khi được kết hợp vào một kiến trúc đơn giản không chú ý, Mamba đạt được kết quả tối ưu trên một tập hợp đa dạng các lĩnh vực, nơi nó khớp hoặc vượt trội hơn hiệu suất của các mô hình Transformer mạnh. Chúng tôi rất hào hứng về các ứng dụng rộng rãi của các mô hình không gian trạng thái chọn lọc để xây dựng các mô hình nền tảng cho các lĩnh vực khác nhau, đặc biệt là trong các phương thức mới nổi yêu cầu ngữ cảnh dài như di truyền học, âm thanh, và video. Kết quả của chúng tôi gợi ý rằng Mamba là một ứng cử viên mạnh mẽ để trở thành xương sống mô hình chuỗi tổng quát.

Lời cảm ơn

Chúng tôi cảm ơn Karan Goel, Arjun Desai, và Kush Bhatia vì phản hồi hữu ích về bản thảo.

Tài liệu tham khảo

[1] Martin Arjovsky, Amar Shah, và Yoshua Bengio. "Mạng Thần kinh Hồi quy Tiến hóa Đơn vị". Trong: Hội nghị Quốc tế về Học Máy (ICML). 2016, tr. 1120–1128.

[2] Žiga Avsec, Vikram Agarwal, Daniel Visentin, Joseph R Ledsam, Agnieszka Grabska-Barwinska, Kyle R Taylor, Yannis Assael, John Jumper, Pushmeet Kohli, và David R Kelley. "Dự đoán Biểu hiện Gen Hiệu quả từ Chuỗi bằng cách Tích hợp Các Tương tác Tầm xa". Trong: Nature Methods 18.10 (2021), tr. 1196–1203.

[3] Jimmy Ba, Geoffrey E Hinton, Volodymyr Mnih, Joel Z Leibo, và Catalin Ionescu. "Sử dụng Trọng số Nhanh để Chú ý đến Quá khứ Gần đây". Trong: Advances in Neural Information Processing Systems (NeurIPS) 29 (2016).

[4] Jimmy Lei Ba, Jamie Ryan Kiros, và Geoffrey E Hinton. "Chuẩn hóa Lớp". Trong: arXiv preprint arXiv:1607.06450 (2016).

[5] Dzmitry Bahdanau, Kyunghyun Cho, và Yoshua Bengio. "Dịch Máy Thần kinh bằng cách Học Đồng thời Căn chỉnh và Dịch". Trong: Hội nghị Quốc tế về Biểu diễn Học (ICLR). 2015.

[6] David Balduzzi và Muhammad Ghifary. "Mạng Thần kinh Hồi quy Kiểu Mạnh". Trong: Hội nghị Quốc tế về Học Máy. PMLR. 2016, tr. 1292–1300.

[7] Stella Biderman, Hailey Schoelkopf, Quentin Gregory Anthony, Herbie Bradley, Kyle O'Brien, Eric Hallahan, Mohammad Aflah Khan, Shivanshu Purohit, USVSN Sai Prashanth, Edward Raff, và cộng sự. "Pythia: Một Bộ công cụ để Phân tích Các Mô hình Ngôn ngữ Lớn qua Huấn luyện và Tỷ lệ". Trong: Hội nghị Quốc tế về Học Máy (ICML). PMLR. 2023, tr. 2397–2430.

[8] Yonatan Bisk, Rowan Zellers, Jianfeng Gao, Yejin Choi, và cộng sự. "PIQA: Lý luận về Thông thường Vật lý trong Ngôn ngữ Tự nhiên". Trong: Proceedings of the AAAI conference on Artificial Intelligence. Tập 34. 2020.

[9] Sid Black, Stella Biderman, Eric Hallahan, Quentin Anthony, Leo Gao, Laurence Golding, Horace He, Connor Leahy, Kyle McDonell, Jason Phang, và cộng sự. "Gpt-NeoX-20B: Một Mô hình Ngôn ngữ Tự hồi quy Mã nguồn mở". Trong: arXiv preprint arXiv:2204.06745 (2022).

[10] Guy E Blelloch. "Tổng Tiền tố và Ứng dụng của Chúng". Trong: (1990).

[11] James Bradbury, Stephen Merity, Caiming Xiong, và Richard Socher. "Mạng Thần kinh Giả-hồi quy". Trong: arXiv preprint arXiv:1611.01576 (2016).

[12] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, và cộng sự. "Các Mô hình Ngôn ngữ là Người học Ít-shot". Trong: Advances in Neural Information Processing Systems (NeurIPS) 33 (2020), tr. 1877–1901.

[13] Aydar Bulatov, Yuri Kuratov, và Mikhail S Burtsev. "Tỷ lệ Transformer lên 1M token và Hơn nữa với RMT". Trong: arXiv preprint arXiv:2304.11062 (2023).

[14] Rewon Child, Scott Gray, Alec Radford, và Ilya Sutskever. "Tạo sinh Chuỗi Dài với Transformer Thưa". Trong: arXiv preprint arXiv:1904.10509 (2019).

[15] Krzysztof Choromanski, Valerii Likhosherstov, David Dohan, Xingyou Song, Andreea Gane, Tamas Sarlos, Peter Hawkins, Jared Davis, Afroz Mohiuddin, Lukasz Kaiser, và cộng sự. "Suy nghĩ lại Chú ý với Performer". Trong: Hội nghị Quốc tế về Biểu diễn Học (ICLR). 2021.

[16] Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, và cộng sự. "PaLM: Tỷ lệ Mô hình hóa Ngôn ngữ với Pathways". Trong: Journal of Machine Learning Research 24.240 (2023), tr. 1–113. url: http://jmlr.org/papers/v24/22-1144.html.

[17] Junyoung Chung, Caglar Gulcehre, KyungHyun Cho, và Yoshua Bengio. "Đánh giá Thực nghiệm của Mạng Thần kinh Hồi quy Có cổng trên Mô hình hóa Chuỗi". Trong: arXiv preprint arXiv:1412.3555 (2014).

[18] Peter Clark, Isaac Cowhey, Oren Etzioni, Tushar Khot, Ashish Sabharwal, Carissa Schoenick, và Oyvind Tafjord. "Nghĩ rằng Bạn đã Giải quyết Trả lời Câu hỏi? Thử ARC, Thách thức Lý luận AI2". Trong: arXiv preprint arXiv:1803.05457 (2018).

[19] Tri Dao. "FlashAttention-2: Chú ý Nhanh hơn với Song song và Phân vùng Công việc Tốt hơn". Trong: Hội nghị Quốc tế về Biểu diễn Học (ICLR). 2024.

[20] Tri Dao, Daniel Y Fu, Stefano Ermon, Atri Rudra, và Christopher Ré. "FlashAttention: Chú ý Chính xác Nhanh và Hiệu quả Bộ nhớ với Nhận thức IO". Trong: Advances in Neural Information Processing Systems (NeurIPS). 2022.

[21] Tri Dao, Daniel Y Fu, Khaled K Saab, Armin W Thomas, Atri Rudra, và Christopher Ré. "Hà mã Hà mã Đói: Hướng tới Mô hình hóa Ngôn ngữ với Mô hình Không gian Trạng thái". Trong: Hội nghị Quốc tế về Biểu diễn Học (ICLR). 2023.

[22] Yann N Dauphin, Angela Fan, Michael Auli, và David Grangier. "Mô hình hóa Ngôn ngữ với Mạng Tích chập Có cổng". Trong: Hội nghị Quốc tế về Học Máy (ICML). PMLR. 2017, tr. 933–941.

[23] DeepSound. SampleRNN. https://github.com/deepsound-project/samplernn-pytorch. 2017.

[24] Jiayu Ding, Shuming Ma, Li Dong, Xingxing Zhang, Shaohan Huang, Wenhui Wang, và Furu Wei. "LongNet: Tỷ lệ Transformer lên 1,000,000,000 Token". Trong: arXiv preprint arXiv:2307.02486 (2023).

[...phần còn lại của tài liệu tham khảo...]

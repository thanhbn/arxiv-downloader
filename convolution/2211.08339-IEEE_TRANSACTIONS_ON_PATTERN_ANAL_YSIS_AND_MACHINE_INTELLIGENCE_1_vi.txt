# 2211.08339.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/convolution/2211.08339.pdf
# Kích thước tệp: 1274418 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE 1
Cắt tỉa các Kênh Mạng Nơ-ron Sâu để
Suy luận Hiệu quả
Yihui He
Tóm tắt —Trong bài báo này, chúng tôi giới thiệu một phương pháp cắt tỉa kênh mới để tăng tốc các mạng nơ-ron tích chập sâu. Với một mô hình CNN đã được huấn luyện, chúng tôi đề xuất một thuật toán hai bước lặp để cắt tỉa hiệu quả từng lớp, bằng cách lựa chọn kênh dựa trên hồi quy LASSO và tái tạo bình phương tối thiểu. Chúng tôi mở rộng thuật toán này cho các trường hợp đa lớp và đa nhánh. Phương pháp của chúng tôi giảm lỗi tích lũy và tăng tính tương thích với các kiến trúc khác nhau. VGG-16 được cắt tỉa của chúng tôi đạt được kết quả tiên tiến nhất với tăng tốc 5× cùng với chỉ 0.3% tăng lỗi. Quan trọng hơn, phương pháp của chúng tôi có thể tăng tốc các mạng hiện đại như ResNet, Xception và chỉ bị mất 1.4%, 1.0% độ chính xác dưới tăng tốc 2× tương ứng, điều này rất đáng kể. Mã nguồn của chúng tôi đã được công khai.
Từ khóa chỉ mục —Mạng nơ-ron tích chập, tăng tốc, phân loại hình ảnh.
F
1 GIỚI THIỆU
GẦN đây, các mạng nơ-ron tích chập (CNN) được sử dụng rộng rãi trên các hệ thống nhúng như điện thoại thông minh và xe tự lái. Xu hướng chung trong vài năm qua là các mạng đã trở nên sâu hơn, với sự gia tăng tổng thể về số lượng tham số và phép toán tích chập. Suy luận hiệu quả đang trở nên ngày càng quan trọng đối với CNN [1].
Các công trình tăng tốc CNN được chia thành ba loại: triển khai tối ưu hóa (ví dụ, FFT [2]), lượng tử hóa (ví dụ, BinaryNet [3]), và đơn giản hóa có cấu trúc chuyển đổi CNN thành dạng compact [4]. Công trình này tập trung vào loại cuối cùng vì nó trực tiếp xử lý vấn đề tham số hóa quá mức của CNN.
Đơn giản hóa có cấu trúc chủ yếu bao gồm: phân tích tensor [4], kết nối thưa [5], và cắt tỉa kênh [6]. Phân tích tensor phân tích một lớp tích chập thành nhiều lớp hiệu quả (Hình 1(c)). Tuy nhiên, độ rộng bản đồ đặc trưng (số lượng kênh) không thể được giảm, điều này khiến việc phân tích các lớp tích chập 1×1 được ưa chuộng bởi các mạng hiện đại (ví dụ, GoogleNet [7], ResNet [8], Xception [9]) trở nên khó khăn. Loại phương pháp này cũng tạo ra chi phí tính toán bổ sung. Kết nối thưa vô hiệu hóa các kết nối giữa các nơ-ron hoặc kênh (Hình 1(b)). Mặc dù có thể đạt được tỷ lệ tăng tốc lý thuyết cao, các lớp tích chập thưa có hình dạng "bất thường" không thân thiện với việc triển khai. Ngược lại, cắt tỉa kênh trực tiếp giảm độ rộng bản đồ đặc trưng, thu nhỏ mạng thành dạng mỏng hơn, như thể hiện trong Hình 1(d). Nó hiệu quả trên cả CPU và GPU vì không cần triển khai đặc biệt.
Cắt tỉa kênh đơn giản nhưng thách thức vì việc loại bỏ các kênh trong một lớp có thể thay đổi đáng kể đầu vào của lớp tiếp theo. Gần đây, các công trình cắt tỉa kênh dựa trên huấn luyện [6], [10] đã tập trung vào việc áp đặt ràng buộc thưa trên trọng số trong quá trình huấn luyện, có thể xác định các siêu tham số một cách thích ứng. Tuy nhiên, huấn luyện từ đầu rất tốn kém, và kết quả cho các CNN rất sâu trên ImageNet hiếm khi được báo cáo. Các nỗ lực tại thời điểm suy luận [11], [12] đã tập trung vào phân tích tầm quan trọng của từng trọng số riêng lẻ. Tỷ lệ tăng tốc báo cáo rất hạn chế.
yihui.dev/channel-pruning-for-accelerating-very-deep-neural-networks
số lượng kênh
W2
W3W1
(a)                           (b)                        (c)                       (d)phi tuyến
phi tuyếnHình 1. Các phương pháp đơn giản hóa có cấu trúc để tăng tốc CNN: (a) một mạng với 3 lớp conv. (b) kết nối thưa vô hiệu hóa một số kết nối giữa các kênh. (c) phân tích tensor phân tích một lớp tích chập thành nhiều phần. (d) cắt tỉa kênh giảm số lượng kênh trong mỗi lớp (trọng tâm của bài báo này).
Công trình này ban đầu được truyền cảm hứng bởi Net2widerNet [13], có thể dễ dàng khám phá các đặc tả mạng rộng hơn mới của cùng một kiến trúc. Nó tạo ra một lớp tích chập rộng hơn bằng cách tạo nhiều bản sao của chính nó, gọi mỗi bản sao sao cho bản đồ đặc trưng đầu ra không thay đổi. Tự nhiên có thể hỏi: Có thể chuyển đổi một mạng thành mạng mỏng hơn của cùng kiến trúc mà không mất độ chính xác? Nếu chúng ta coi mỗi bản đồ đặc trưng như một vector, thì tất cả các bản đồ đặc trưng tạo thành một không gian vector. Phép toán ngược của Net2widerNet được thảo luận ở trên là tìm một tập hợp các vector đặc trưng cơ sở và sử dụng chúng để biểu diễn các vector đặc trưng khác, nhằm tái tạo không gian bản đồ đặc trưng gốc.
Trong bài báo này, chúng tôi đề xuất một phương pháp tại thời điểm suy luận mới cho cắt tỉa kênh, sử dụng tính dư thừa giữa các kênh. Được truyền cảm hứng bởi cải tiến phân tích tensor thông qua tái tạo bản đồ đặc trưng [14], thay vì cắt tỉa theo độ lớn trọng số bộ lọc [11], [15], chúng tôi khai thác đầy đủ tính dư thừa giữa các bản đồ đặc trưng. Thay vì phục hồi hiệu suất với tinh chỉnh [5], [11], [15], chúng tôi đề xuất tái tạo đầu ra sau khi cắt tỉa mỗi lớp. Cụ thể, với một mô hình CNN đã được huấn luyện, việc cắt tỉa mỗi lớp được thực hiện bằng cách tối thiểu hóa lỗi tái tạo trên các bản đồ đặc trưng đầu ra của nó, như thể hiện trong Hình 2. Chúng tôi giải quyết vấn đề tối thiểu hóa này bằng hai bước thay thế: lựa chọn kênh và tái tạo bản đồ đặc trưng. Trong một bước, chúng tôi tìm ra các kênh đại diện nhất và cắt tỉa những kênh dư thừa, dựa trên hồi quy LASSO. Trong bước khác, chúng tôi tái tạo các đầu ra với các kênh còn lại bằng bình phương tối thiểu tuyến tính. Chúng tôi thực hiện hai bước một cách thay thế. Hơn nữa, chúng tôi xấp xỉ mạng theo từng lớp, với lỗi tích lũy được tính toán. Chúng tôi cũng thảo luận về phương pháp cắt tỉa mạng đa nhánh (ví dụ, ResNet [8], Xception [9]).
Chúng tôi chứng minh độ chính xác vượt trội của phương pháp chúng tôi so với các kỹ thuật cắt tỉa gần đây khác [15], [16], [17], [18]. Đối với VGG-16, chúng tôi đạt được tăng tốc 4× với chỉ 1.0% tăng lỗi top-5. Kết hợp với phân tích tensor, chúng tôi đạt được tăng tốc 5× nhưng chỉ chịu 0.3% tăng lỗi, vượt trội hơn so với các kỹ thuật tiên tiến trước đây. Chúng tôi cũng tăng tốc ResNet-50 và Xception-50 lên 2× với chỉ mất 1.4%, 1.0% độ chính xác tương ứng. Mã nguồn đã được công khai.
Một phiên bản sơ bộ của bản thảo này đã được chấp nhận tại một hội nghị [19]. Bản thảo này mở rộng phiên bản ban đầu từ một số khía cạnh để tăng cường phương pháp của chúng tôi:
1) Chúng tôi đã điều tra tính dư thừa giữa các kênh trong mỗi lớp, và phân tích tốt hơn cho việc cắt tỉa.
2) Chúng tôi trình bày cắt tỉa theo bộ lọc, có hiệu suất tăng tốc thuyết phục cho một lớp đơn.
3) Chúng tôi chứng minh kết quả tăng tốc VGG-16 Top-1 thuyết phục vượt trội hơn mô hình gốc.
2 CÔNG TRÌNH LIÊN QUAN
Đã có một lượng lớn công trình về tăng tốc CNN [20], bắt đầu từ brain damage [21], [22]. Nhiều trong số chúng được chia thành ba loại: triển khai tối ưu hóa [23], lượng tử hóa [24], và đơn giản hóa có cấu trúc [4].
Các phương pháp dựa trên triển khai tối ưu hóa [2], [23], [25], [26] tăng tốc tích chập với các thuật toán tích chập đặc biệt như FFT [2]. Lượng tử hóa [3], [24], [27] giảm độ phức tạp tính toán dấu phẩy động.
Kết nối thưa loại bỏ các kết nối giữa các nơ-ron [5], [28], [29], [30], [31], [32], [33]. [34] cắt tỉa các kết nối dựa trên độ lớn trọng số. [35] có thể tăng tốc các lớp kết nối đầy đủ lên đến 50×. Tuy nhiên, trên thực tế, tăng tốc thực tế có thể liên quan nhiều đến việc triển khai.
Phân tích tensor [4], [36], [37], [38], [39] phân tích trọng số thành nhiều phần. [40], [41], [42] tăng tốc các lớp kết nối đầy đủ với SVD cắt ngắn. [14] phân tích một lớp thành kết hợp 3×3 và 1×1, được thúc đẩy bởi tính dư thừa bản đồ đặc trưng.
Cắt tỉa kênh loại bỏ các kênh dư thừa trên bản đồ đặc trưng. Có một số phương pháp dựa trên huấn luyện [43]. [6], [10], [44] điều chỉnh mạng để cải thiện độ chính xác. Channel-wise SSL [6] đạt tỷ lệ nén cao cho các lớp conv đầu tiên của LeNet [45] và AlexNet [46]. [44] có thể hoạt động tốt cho các lớp kết nối đầy đủ. Tuy nhiên, các phương pháp dựa trên huấn luyện tốn kém hơn, và hiệu quả của chúng trên các mạng rất sâu trên các tập dữ liệu lớn hiếm khi được khai thác. Cắt tỉa kênh tại thời điểm suy luận là thách thức, như được báo cáo bởi các công trình trước đây [47], [48]. Gần đây, AMC [49] cải thiện phương pháp của chúng tôi bằng cách học tỷ lệ tăng tốc với học tăng cường.
1. https://github.com/yihui-he/channel-pruning
Một số công trình [50], [51], [52] tập trung vào nén kích thước mô hình, chủ yếu hoạt động trên các lớp kết nối đầy đủ. Các phương pháp không cần dữ liệu [11], [12] kết quả cho tỷ lệ tăng tốc (ví dụ, 5×) chưa được báo cáo, và đòi hỏi quy trình huấn luyện lại dài. [12] chọn kênh qua hơn 100 thử nghiệm ngẫu nhiên. Tuy nhiên, cần thời gian dài để đánh giá mỗi thử nghiệm trên một mạng sâu, điều này khiến không khả thi để làm việc trên các mô hình rất sâu và tập dữ liệu lớn. [11] thậm chí tệ hơn so với giải pháp naïve từ quan sát của chúng tôi đôi khi (Mục 4.1.1).
3 PHƯƠNG PHÁP
Trong phần này, chúng tôi đầu tiên đề xuất một thuật toán cắt tỉa kênh cho một lớp đơn, sau đó tổng quát hóa phương pháp này cho nhiều lớp hoặc toàn bộ mô hình. Hơn nữa, chúng tôi thảo luận về các biến thể của phương pháp cho mạng đa nhánh.
3.1 Công thức
Hình 2 minh họa thuật toán cắt tỉa kênh của chúng tôi cho một lớp tích chập đơn. Chúng tôi nhằm giảm số lượng kênh của bản đồ đặc trưng B trong khi duy trì các đầu ra trong bản đồ đặc trưng C. Một khi các kênh được cắt tỉa, chúng ta có thể loại bỏ các kênh tương ứng của các bộ lọc nhận những kênh này làm đầu vào. Ngoài ra, các bộ lọc tạo ra những kênh này cũng có thể được loại bỏ. Rõ ràng rằng cắt tỉa kênh bao gồm hai điểm chính. Thứ nhất là lựa chọn kênh vì chúng ta cần chọn kết hợp kênh phù hợp để duy trì nhiều thông tin nhất. Thứ hai là tái tạo. Chúng ta cần tái tạo các bản đồ đặc trưng tiếp theo bằng cách sử dụng các kênh đã chọn.
Được thúc đẩy bởi điều này, chúng tôi đề xuất một thuật toán hai bước lặp:
1) Trong một bước, chúng tôi nhằm chọn các kênh đại diện nhất. Vì tìm kiếm toàn diện là không khả thi ngay cả đối với các mạng nhỏ, chúng tôi đưa ra một phương pháp dựa trên hồi quy LASSO để tìm ra các kênh đại diện và cắt tỉa những kênh dư thừa.
2) Trong bước khác, chúng tôi tái tạo các đầu ra với các kênh còn lại bằng bình phương tối thiểu tuyến tính.
Chúng tôi thực hiện hai bước một cách thay thế.
Chính thức, để cắt tỉa một bản đồ đặc trưng B với c kênh, chúng tôi xem xét việc áp dụng n×c×kh×kw bộ lọc tích chập W trên N×c×kh×kw khối đầu vào X được lấy mẫu từ bản đồ đặc trưng này, tạo ra ma trận đầu ra N×n Y từ bản đồ đặc trưng C. Ở đây, N là số lượng mẫu, n là số lượng kênh đầu ra, và kh, kw là kích thước kernel. Để biểu diễn đơn giản, hạng tử bias không được bao gồm trong công thức của chúng tôi. Để cắt tỉa các kênh đầu vào từ c thành c' mong muốn (0≤c'≤c), trong khi tối thiểu hóa lỗi tái tạo, chúng tôi xây dựng bài toán như sau:
arg min
β,W1
2N




Y−cX
i=1βiXiWi>




2
F
subject to∥β∥0≤c'(1)
∥⋅∥F là chuẩn Frobenius. Xi là ma trận N×kh×kw được cắt từ kênh thứ i của các khối đầu vào X, i=1,...,c. Wi là trọng số bộ lọc n×kh×kw được cắt từ kênh thứ i của W. β là vector hệ số có độ dài c để lựa chọn kênh, và βi (phần tử thứ i của β) là một mặt nạ vô hướng cho kênh thứ i (tức là để bỏ toàn bộ kênh hoặc không). Lưu ý rằng, nếu βi=0, Xi sẽ không còn hữu ích, có thể được cắt tỉa an toàn từ bản đồ đặc trưng B. Wi cũng có thể được loại bỏ. c' là số lượng kênh giữ lại, được đặt thủ công vì có thể được tính toán từ tỷ lệ tăng tốc mong muốn. Đối với tăng tốc toàn mô hình (tức là Mục 4.1.2), với tăng tốc tổng thể, chúng tôi đầu tiên gán tỷ lệ tăng tốc cho mỗi lớp sau đó tính toán mỗi c'.

--- TRANG 2 ---
IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE 2
n c×kh×kw
A                                                B                                                                      C
phi tuyến phi tuyến W
Hình 2. Cắt tỉa kênh để tăng tốc một lớp tích chập. Chúng tôi nhằm giảm số lượng kênh của bản đồ đặc trưng và tối thiểu hóa lỗi tái tạo trên bản đồ đặc trưng C. Thuật toán tối ưu hóa của chúng tôi (Mục 3.1) thực hiện trong hộp chấm, không liên quan đến tính phi tuyến. Hình này minh họa tình huống hai kênh được cắt tỉa cho bản đồ đặc trưng B. Do đó các kênh tương ứng của bộ lọc W có thể được loại bỏ. Hơn nữa, mặc dù không được tối ưu hóa trực tiếp bởi thuật toán của chúng tôi, các bộ lọc tương ứng trong lớp trước đó cũng có thể được loại bỏ (được đánh dấu bằng bộ lọc chấm). c, n: số lượng kênh cho bản đồ đặc trưng B và C, kh×kw: kích thước kernel.
3.2 Tối ưu hóa
Giải quyết vấn đề tối thiểu hóa ℓ0 này trong Phương trình 1 là NP-khó. Do đó, chúng tôi nới lỏng ℓ0 thành điều chỉnh ℓ1:
arg min
β,W1
2N




Y−cX
i=1βiXiWi>




2
F+λ∥β∥1
subject to∥β∥0≤c',∀i∥Wi∥F=1(2)
λ là hệ số phạt. Bằng cách tăng λ, sẽ có nhiều hạng tử zero hơn trong β và có thể đạt được tỷ lệ tăng tốc cao hơn. Chúng tôi cũng thêm ràng buộc ∀i∥Wi∥F=1 vào công thức này để tránh giải pháp tầm thường.
Bây giờ chúng tôi giải quyết vấn đề này theo hai hướng. Đầu tiên, chúng tôi cố định W, giải cho lựa chọn kênh. Thứ hai, chúng tôi cố định β, giải W để tái tạo lỗi.
3.2.1 (i) Bài toán con của β
Trong trường hợp này, W được cố định. Chúng tôi giải cho lựa chọn kênh. Vấn đề này có thể được giải quyết bằng hồi quy LASSO [53], [54], được sử dụng rộng rãi cho lựa chọn mô hình.
^βLASSO(λ) = arg min
β1
2N




Y−cX
i=1βiZi




2
F+λ∥β∥1
subject to∥β∥0≤c'(3)
Ở đây Zi=XiWi> (kích thước N×n). Chúng tôi sẽ bỏ qua kênh thứ i nếu βi=0.
3.2.2 (ii) Bài toán con của W
Trong trường hợp này, β được cố định. Chúng tôi sử dụng các kênh đã chọn để tối thiểu hóa lỗi tái tạo. Chúng tôi có thể tìm giải pháp tối ưu bằng bình phương tối thiểu:
arg min
W'


Y−X'(W')>


2
F(4)
Ở đây X'=[β1X1β2X2...βiXi...βcXc] (kích thước N×c×kh×kw). W' là n×c×kh×kw W được định hình lại, W'=[W1W2...Wi...Wc]. Sau khi thu được kết quả W', nó được định hình lại về W. Sau đó chúng tôi gán βi←βi∥Wi∥F; Wi←Wi/∥Wi∥F. Ràng buộc ∀i∥Wi∥F=1 được thỏa mãn.
Chúng tôi tối ưu hóa (i) và (ii) một cách thay thế. Ban đầu, W được khởi tạo từ mô hình đã huấn luyện, λ=0, tức là không có phạt, và ∥β∥0=c. Chúng tôi dần dần tăng λ. Cho mỗi thay đổi của λ, chúng tôi lặp hai bước này cho đến khi ∥β∥0 ổn định. Sau khi ∥β∥0≤c' thỏa mãn, chúng tôi thu được giải pháp cuối cùng W từ {βiWi}. Trong thực tế, chúng tôi thấy rằng việc lặp hai bước tốn thời gian. Vì vậy chúng tôi áp dụng (i) nhiều lần cho đến khi ∥β∥0≤c' thỏa mãn. Sau đó áp dụng (ii) chỉ một lần, để thu được kết quả cuối cùng. Từ quan sát của chúng tôi, kết quả này có thể so sánh với kết quả lặp hai bước. Do đó, trong các thí nghiệm sau, chúng tôi áp dụng phương pháp này để hiệu quả.
3.2.3 Thảo luận
Một số công trình gần đây [5], [6], [10] (mặc dù dựa trên huấn luyện) cũng giới thiệu chuẩn ℓ1 hoặc LASSO. Tuy nhiên, chúng tôi phải nhấn mạnh rằng chúng tôi sử dụng các công thức khác nhau. Nhiều trong số chúng giới thiệu điều chỉnh thưa vào mất mát huấn luyện, thay vì giải quyết LASSO một cách rõ ràng. Công trình khác [10] giải quyết LASSO, trong khi bản đồ đặc trưng hoặc dữ liệu không được xem xét trong quá trình tối ưu hóa.
Do những khác biệt này, phương pháp của chúng tôi có thể được áp dụng tại thời điểm suy luận.
3.3 Cắt tỉa Toàn bộ Mô hình
Được truyền cảm hứng bởi [14], chúng tôi áp dụng phương pháp của chúng tôi từng lớp một cách tuần tự. Đối với mỗi lớp, chúng tôi thu được các khối đầu vào từ bản đồ đặc trưng đầu vào hiện tại, và các khối đầu ra từ bản đồ đặc trưng đầu ra của mô hình chưa cắt tỉa. Điều này có thể được chính thức hóa như:
arg min
β,W1
2N




Y'−cX
i=1βiXiWi>




2
F
subject to∥β∥0≤c'(5)
Khác với Phương trình 1, Y được thay thế bởi Y', là từ bản đồ đặc trưng của mô hình gốc. Do đó, lỗi tích lũy có thể được tính toán trong quá trình cắt tỉa tuần tự.
3.4 Cắt tỉa Mạng Đa Nhánh
Cắt tỉa toàn bộ mô hình được thảo luận ở trên đủ cho các mạng đơn nhánh như LeNet [45], AlexNet [46] và VGG Nets [55]. Tuy nhiên, nó không đủ cho các mạng đa nhánh như GoogLeNet [7] và ResNet [8]. Chúng tôi chủ yếu tập trung vào cắt tỉa cấu trúc residual được sử dụng rộng rãi (ví dụ, ResNet [8], Xception [9]).
Với một khối residual được thể hiện trong Hình 3 (trái), đầu vào phân nhánh thành shortcut và nhánh residual. Trên nhánh residual, có một số lớp tích chập (ví dụ, 3 lớp tích chập có kích thước không gian 1×1; 3×3; 1×1, Hình 3, trái). Các lớp khác ngoại trừ lớp đầu tiên và cuối cùng có thể được cắt tỉa như đã mô tả trước đây. Đối với lớp đầu tiên, thách thức là độ rộng bản đồ đặc trưng đầu vào lớn (đối với ResNet, gấp bốn lần đầu ra của nó) không thể dễ dàng cắt tỉa vì nó được chia sẻ với shortcut. Đối với lớp cuối cùng, lỗi tích lũy từ shortcut khó có thể phục hồi, vì không có tham số trên shortcut. Để giải quyết những thách thức này, chúng tôi đề xuất một số biến thể của phương pháp như sau.
3.4.1 Lớp cuối cùng của nhánh residual
Được thể hiện trong Hình 3, lớp đầu ra của một khối residual bao gồm hai đầu vào: bản đồ đặc trưng Y1 và Y2 từ shortcut và nhánh residual. Chúng tôi nhằm phục hồi Y1+Y2 cho khối này. Ở đây, Y1, Y2 là các bản đồ đặc trưng gốc trước khi cắt tỉa. Y2 có thể được xấp xỉ như trong Phương trình 1. Tuy nhiên, nhánh shortcut không có tham số, thì Y1 không thể được phục hồi trực tiếp. Để bù đắp lỗi này, mục tiêu tối ưu hóa của lớp cuối cùng được thay đổi từ Y2 thành Y1−Y'1+Y2, điều này không thay đổi tối ưu hóa của chúng tôi. Ở đây, Y'1 là bản đồ đặc trưng hiện tại sau khi các lớp trước đó bị cắt tỉa. Khi cắt tỉa, các khối cần được lấy mẫu tương ứng từ hai nhánh này.
3.4.2 Lớp đầu tiên của nhánh residual
Được minh họa trong Hình 3(trái), bản đồ đặc trưng đầu vào của khối residual không thể bị cắt tỉa, vì nó cũng được chia sẻ với nhánh shortcut. Trong điều kiện này, chúng tôi có thể thực hiện lấy mẫu bản đồ đặc trưng trước tích chập đầu tiên để tiết kiệm tính toán. Chúng tôi vẫn áp dụng thuật toán của chúng tôi như Phương trình 1. Khác biệt là, chúng tôi lấy mẫu các kênh đã chọn trên bản đồ đặc trưng chia sẻ để xây dựng đầu vào mới cho tích chập sau, được thể hiện trong Hình 3(phải). Chi phí tính toán cho phép toán này có thể được bỏ qua. Quan trọng hơn, sau khi giới thiệu lấy mẫu bản đồ đặc trưng, tích chập vẫn "thông thường".
Cắt tỉa theo bộ lọc là một tùy chọn khác cho tích chập đầu tiên trên nhánh residual, được thể hiện trong Hình 4. Vì các kênh đầu vào của nhánh shortcut không có tham số không thể bị cắt tỉa, chúng tôi áp dụng Phương trình 1 của chúng tôi cho mỗi bộ lọc một cách độc lập (mỗi bộ lọc chọn các kênh đầu vào đại diện riêng của nó). Nó xuất ra các lớp tích chập "bất thường", cần hỗ trợ triển khai thư viện đặc biệt.
3.5 Kết hợp với Phân tích Tensor
Cắt tỉa kênh có thể dễ dàng kết hợp với phân tích tensor, lượng tử hóa và lowbits, v.v. Chúng tôi tập trung vào kết hợp với phân tích tensor.
Nói chung, phân tích tensor có thể được biểu diễn như:
Wl→n=W1∗W2∗...∗Wn(6)
Ở đây, Wl→n là bộ lọc lớp tích chập gốc cho lớp n, và W1∗W2∗...∗Wn là một số trọng số phân tích có cùng kích thước với W. Vì các kênh đầu vào và đầu ra của các phương pháp phân tích tensor không thể thu nhỏ, nó trở thành nút thắt cổ chai khi đạt tỷ lệ tăng tốc cao. Chúng tôi áp dụng giảm kênh trên các lớp trọng số phân tích đầu tiên và cuối cùng, cụ thể là đầu ra của Wn và đầu vào của W1. Trong các thí nghiệm của chúng tôi (Mục 4.1.3), chúng tôi kết hợp [4], [14] và phương pháp của chúng tôi. Đầu tiên, trọng số 3×3 được phân tích thành 3×1; 1×3; 1×1. Sau đó phương pháp của chúng tôi được áp dụng cho trọng số 3×1 và 1×1.
3.6 Tinh chỉnh
Chúng tôi tinh chỉnh mô hình xấp xỉ end-to-end trên dữ liệu huấn luyện, có thể đạt được độ chính xác cao hơn sau khi giảm. Chúng tôi thấy rằng vì mạng ở trạng thái khá không ổn định, tinh chỉnh rất nhạy cảm với tỷ lệ học. Tỷ lệ học cần đủ nhỏ. Nếu không, độ chính xác sẽ giảm nhanh. Nếu tỷ lệ học lớn, quá trình tinh chỉnh có thể nhảy ra khỏi tối ưu cục bộ được khởi tạo bởi mạng được cắt tỉa và hoạt động rất giống với việc huấn luyện kiến trúc cắt tỉa từ đầu (Bảng 5).
Trên ImageNet, chúng tôi sử dụng tỷ lệ học 1e-5 và kích thước mini-batch 128. Tinh chỉnh các mô hình trong mười epoch trên dữ liệu huấn luyện ImageNet (1/12 lần lặp so với huấn luyện từ đầu). Trên CIFAR-10, chúng tôi sử dụng tỷ lệ học 1e-4 và kích thước mini-batch 128 và tinh chỉnh các mô hình trong 6000 lần lặp (huấn luyện từ đầu cần 64000 lần lặp).

--- TRANG 3 ---
IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE 3
c'0
1x1
3x3
1x1  bộ lấy mẫu
relu
relu
Y1Y1+Y2Y2kênh bộ lấy mẫu Đầu vào ( c0)lấy mẫu ( c0' )
c'0 c0
1x1,c1
3x3,c2
1x1relu
reluc1
c2c'1 
c'2 
Hình 3. Minh họa cải tiến đa nhánh cho khối residual. Trái: khối residual gốc. Phải: khối residual được cắt tỉa với cải tiến, cx biểu thị độ rộng bản đồ đặc trưng. Các kênh đầu vào của lớp tích chập đầu tiên được lấy mẫu, để độ rộng bản đồ đặc trưng đầu vào lớn có thể được giảm. Đối với lớp cuối cùng, thay vì xấp xỉ Y2, chúng tôi cố gắng xấp xỉ Y1+Y2 trực tiếp (Mục 3.4 Lớp cuối cùng của nhánh residual).
n=3 c=23 bộ lọc kh×kw
B                                                                                   C
w Hình 4. Cắt tỉa theo bộ lọc để tăng tốc lớp tích chập đầu tiên trên nhánh residual. Chúng tôi nhằm giảm số lượng kênh theo bộ lọc trong trọng số W, trong khi tối thiểu hóa lỗi tái tạo trên bản đồ đặc trưng C. Các kênh của bản đồ đặc trưng B không bị cắt tỉa. Chúng tôi áp dụng Phương trình 1 cho mỗi bộ lọc một cách độc lập (mỗi bộ lọc chọn các kênh đầu vào đại diện riêng của nó). c, n: số lượng kênh cho bản đồ đặc trưng B và C, kh×kw: kích thước kernel.
3.5 Kết hợp với Phân tích Tensor
Cắt tỉa kênh có thể dễ dàng kết hợp với phân tích tensor, lượng tử hóa và lowbits, v.v. Chúng tôi tập trung vào kết hợp với phân tích tensor.
Nói chung, phân tích tensor có thể được biểu diễn như:
Wl→n=W1∗W2∗...∗Wn(6)
Ở đây, Wl→n là bộ lọc lớp tích chập gốc cho lớp n, và W1∗W2∗...∗Wn là một số trọng số phân tích có cùng kích thước với W. Vì các kênh đầu vào và đầu ra của các phương pháp phân tích tensor không thể thu nhỏ, nó trở thành nút thắt cổ chai khi đạt tỷ lệ tăng tốc cao. Chúng tôi áp dụng giảm kênh trên các lớp trọng số phân tích đầu tiên và cuối cùng, cụ thể là đầu ra của Wn và đầu vào của W1. Trong các thí nghiệm của chúng tôi (Mục 4.1.3), chúng tôi kết hợp [4], [14] và phương pháp của chúng tôi. Đầu tiên, trọng số 3×3 được phân tích thành 3×1; 1×3; 1×1. Sau đó phương pháp của chúng tôi được áp dụng cho trọng số 3×1 và 1×1.
3.6 Tinh chỉnh
Chúng tôi tinh chỉnh mô hình xấp xỉ end-to-end trên dữ liệu huấn luyện, có thể đạt được độ chính xác cao hơn sau khi giảm. Chúng tôi thấy rằng vì mạng ở trạng thái khá không ổn định, tinh chỉnh rất nhạy cảm với tỷ lệ học. Tỷ lệ học cần đủ nhỏ. Nếu không, độ chính xác sẽ giảm nhanh. Nếu tỷ lệ học lớn, quá trình tinh chỉnh có thể nhảy ra khỏi tối ưu cục bộ được khởi tạo bởi mạng được cắt tỉa và hoạt động rất giống với việc huấn luyện kiến trúc cắt tỉa từ đầu (Bảng 5).
Trên ImageNet, chúng tôi sử dụng tỷ lệ học 1e-5 và kích thước mini-batch 128. Tinh chỉnh các mô hình trong mười epoch trên dữ liệu huấn luyện ImageNet (1/12 lần lặp so với huấn luyện từ đầu). Trên CIFAR-10, chúng tôi sử dụng tỷ lệ học 1e-4 và kích thước mini-batch 128 và tinh chỉnh các mô hình trong 6000 lần lặp (huấn luyện từ đầu cần 64000 lần lặp).

--- TRANG 4 ---
IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE 4
0.00.51.01.52.02.53.03.54.0 tăng lỗi (%)conv1_1
k đầu tiên
phản hồi tối đa
SGD
của chúng tôi
0.00.51.01.52.02.53.03.54.0conv2_1
k đầu tiên
phản hồi tối đa
SGD
của chúng tôi
0.00.51.01.52.02.53.03.54.0conv3_1
k đầu tiên
phản hồi tối đa
SGD
của chúng tôi
1.0 1.5 2.0 2.5 3.0 3.5 4.0
tỷ lệ tăng tốc0123456tăng lỗi (%)conv3_2
k đầu tiên
phản hồi tối đa
SGD
của chúng tôi
1.0 1.5 2.0 2.5 3.0 3.5 4.0
tỷ lệ tăng tốc0123456conv4_1
k đầu tiên
phản hồi tối đa
SGD
của chúng tôi
1.0 1.5 2.0 2.5 3.0 3.5 4.0
tỷ lệ tăng tốc0123456conv4_2
k đầu tiên
phản hồi tối đa
SGD
của chúng tôi
Hình 5. Phân tích hiệu suất lớp đơn dưới các tỷ lệ tăng tốc khác nhau (không có tinh chỉnh), được đo bằng tăng lỗi. Để xác minh tầm quan trọng của lựa chọn kênh được đề cập trong Mục 3.1, chúng tôi xem xét ba baseline naïve. k đầu tiên chọn k bản đồ đặc trưng đầu tiên. phản hồi tối đa chọn kênh dựa trên tổng giá trị tuyệt đối của trọng số bộ lọc tương ứng [11]. SGD là một phương án SGD đơn giản của phương pháp chúng tôi. Phương pháp của chúng tôi luôn tốt hơn một cách nhất quán (nhỏ hơn là tốt hơn).
4 THÍ NGHIỆM
Chúng tôi đánh giá phương pháp của chúng tôi cho VGG Nets [55], ResNet [8], Xception [9] phổ biến trên ImageNet [56], CIFAR-10 [57] và PASCAL VOC 2007 [58].
Đối với Batch Normalization [59], chúng tôi đầu tiên hợp nhất nó vào trọng số tích chập, điều này không ảnh hưởng đến đầu ra của mạng. Để mỗi lớp tích chập được theo sau bởi ReLU [60]. Chúng tôi sử dụng Caffe [61] để đánh giá mạng sâu, TensorFlow [62] để triển khai SGD (Mục 4.1.1) và scikit-learn [63] để triển khai solvers. Đối với cắt tỉa kênh, chúng tôi thấy rằng đủ để trích xuất 5000 hình ảnh, và mười mẫu mỗi hình ảnh, điều này cũng hiệu quả (tức là, vài phút cho VGG-16, Mục 4.1.2). Trên ImageNet, chúng tôi đánh giá độ chính xác top-5 với góc nhìn đơn. Hình ảnh được thay đổi kích thước sao cho cạnh ngắn hơn là 256. Thử nghiệm được thực hiện trên crop trung tâm 224×224 pixel. Augmentation cho tinh chỉnh là random crop 224×224 và mirror.
4.1 Thí nghiệm với VGG-16
VGG-16 [55] là mạng nơ-ron tích chập đơn nhánh 16 lớp, với 13 lớp tích chập. Nó được sử dụng rộng rãi cho nhận dạng, phát hiện và phân đoạn, v.v. Độ chính xác top-5 một góc nhìn cho VGG-16 là 89.9%.
4.1.1 Cắt tỉa Lớp Đơn
Trong phần này, chúng tôi đánh giá hiệu suất tăng tốc lớp đơn sử dụng thuật toán của chúng tôi trong Mục 3.1. Để hiểu rõ hơn, chúng tôi so sánh thuật toán của chúng tôi với ba chiến lược lựa chọn kênh naïve. k đầu tiên chọn k kênh đầu tiên. phản hồi tối đa chọn kênh dựa trên các bộ lọc tương ứng có tổng trọng số tuyệt đối cao [11]. SGD là một phương án đơn giản của phương pháp chúng tôi sử dụng trọng số gốc làm khởi tạo, giải quyết vấn đề điều chỉnh ℓ1 trong Phương trình 2 (đối với cả trọng số và kết nối) bằng stochastic gradient descent.
Để so sánh công bằng, chúng tôi thu được các chỉ số bản đồ đặc trưng được chọn bởi mỗi phương pháp, sau đó thực hiện tái tạo (ngoại trừ SGD, Mục 3.2.2). Chúng tôi hy vọng rằng điều này có thể chứng minh tầm quan trọng của lựa chọn kênh. Hiệu suất được đo bằng tăng lỗi sau khi một lớp nhất định bị cắt tỉa không có tinh chỉnh, được thể hiện trong Hình 5.
Như mong đợi, lỗi tăng khi tỷ lệ tăng tốc tăng. Phương pháp của chúng tôi luôn tốt hơn các phương pháp khác một cách nhất quán trong các lớp tích chập khác nhau dưới tỷ lệ tăng tốc khác nhau. Ngoài mong đợi, đôi khi phản hồi tối đa thậm chí còn tệ hơn k đầu tiên. Chúng tôi cho rằng phản hồi tối đa bỏ qua tương quan giữa các bộ lọc khác nhau. Các bộ lọc có trọng số tuyệt đối lớn có thể có tương quan mạnh. Do đó việc lựa chọn dựa trên trọng số bộ lọc ít có ý nghĩa hơn. Tương quan trên bản đồ đặc trưng đáng được khai thác. Chúng ta có thể thấy rằng lựa chọn kênh ảnh hưởng rất nhiều đến lỗi tái tạo. Do đó, nó quan trọng cho cắt tỉa kênh.
Đối với SGD, chúng tôi chỉ thực hiện thí nghiệm dưới tăng tốc 4× do hạn chế thời gian. Mặc dù chia sẻ cùng mục tiêu tối ưu hóa với phương pháp của chúng tôi, SGD đơn giản dường như khó tối ưu hóa đến tối ưu cục bộ lý tưởng. Được thể hiện trong Hình 5, SGD rõ ràng tệ hơn phương pháp tối ưu hóa của chúng tôi.
Cũng lưu ý rằng cắt tỉa kênh dần trở nên khó khăn, từ các lớp nông hơn đến các lớp sâu hơn. Nó cho thấy rằng các lớp nông hơn có nhiều dư thừa hơn, điều này nhất quán với [14]. Chúng tôi có thể cắt tỉa mạnh mẽ hơn trên các lớp nông hơn trong tăng tốc toàn mô hình.
4.1.2 Cắt tỉa Toàn bộ Mô hình
Được thể hiện trong Bảng 1, chúng tôi phân tích năng lượng PCA của VGG-16. Nó cho thấy rằng các lớp nông hơn của VGG-16 dư thừa hơn, phù hợp với các thí nghiệm lớp đơn của chúng tôi ở trên. Vì vậy chúng tôi cắt tỉa mạnh mẽ hơn cho các lớp nông hơn. Tỷ lệ bảo tồn kênh cho các lớp nông (conv1_x đến conv3_x) và các lớp sâu (conv4_x) là 1:1.5. conv5_x không bị cắt tỉa, vì chúng chỉ đóng góp 9% tính toán tổng cộng và không dư thừa, được thể hiện trong Bảng 1.
Chúng tôi áp dụng cắt tỉa toàn mô hình từng lớp được đề xuất trong Mục 3.3. Hình 6 thể hiện cắt tỉa VGG-16 dưới tăng tốc 4×, cuối cùng đạt 1.0% tăng lỗi sau tinh chỉnh. Dễ thấy rằng lỗi tích lũy tăng từng lớp. Và lỗi chủ yếu được giới thiệu bởi cắt tỉa các lớp sau, phù hợp với quan sát của chúng tôi từ cắt tỉa lớp đơn và phân tích PCA.
Ngoài mô hình suy luận hiệu quả mà chúng tôi đạt được, thuật toán của chúng tôi cũng hiệu quả. Được thể hiện trong Hình 7, thuật toán của chúng tôi có thể hoàn thành cắt tỉa VGG-16 dưới 4× trong vòng 5 phút.
Được thể hiện trong Bảng 2, kết quả tăng tốc toàn mô hình dưới 2×, 4×, 5× được chứng minh. Sau tinh chỉnh, chúng tôi có thể đạt tăng tốc 2× mà không mất độ chính xác. Dưới 4×, chúng tôi chỉ chịu giảm 1.0%. Nhất quán với phân tích lớp đơn, phương pháp của chúng tôi vượt trội hơn các phương pháp cắt tỉa gần đây khác (Filter Pruning [11], Runtime Neural Pruning [16] và Structured Probabilistic Pruning [17]) bởi một biên độ lớn. Điều này là do chúng tôi khai thác đầy đủ tính dư thừa kênh trong bản đồ đặc trưng. So với các thuật toán phân tích tensor, phương pháp của chúng tôi tốt hơn Jaderberg et al. [4], không có tinh chỉnh. Mặc dù tệ hơn Asym. [14], mô hình kết hợp của chúng tôi vượt trội hơn Asym. 3D kết hợp của nó (Bảng 3). Điều này có thể cho thấy rằng cắt tỉa kênh thách thức hơn phân tích tensor, vì việc loại bỏ các kênh trong một lớp có thể thay đổi đáng kể đầu vào của lớp tiếp theo. Tuy nhiên, cắt tỉa kênh giữ nguyên kiến trúc mô hình gốc, không giới thiệu các lớp bổ sung, và tỷ lệ tăng tốc tuyệt đối trên GPU cao hơn nhiều (Bảng 7).

--- TRANG 5 ---
IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE 5
BẢNG 1
Kiến trúc VGG-16. Cột "độ phức tạp" là tỷ lệ độ phức tạp thời gian lý thuyết mà mỗi lớp đóng góp. Cột "năng lượng PCA" hiển thị Năng lượng PCA bản đồ đặc trưng (50% eigenvalues hàng đầu).
# kênh # bộ lọc kích thước đầu ra độ phức tạp (%) năng lượng PCA (%)
conv1_1 64 64×224×224 0.6 99.8
conv1_2 64 64×224×224 12 99.0
pool1 112×112
conv2_1 64 128×112×112 6 96.7
conv2_2 128 128×112×112 12 92.9
pool2 56×56
conv3_1 128 256×56×56 6 94.8
conv3_2 256 256×56×56 12 92.3
conv3_3 256 256×56×56 12 89.3
pool3 28×28
conv4_1 256 512×28×28 6 89.9
conv4_2 512 512×28×28 12 86.5
conv4_3 512 512×28×28 12 81.8
pool4 14×14
conv5_1 512 512×14×14 3 83.4
conv5_2 512 512×14×14 3 83.1
conv5_3 512 512×14×14 3 80.8
BẢNG 2
Tăng tốc mô hình VGG-16 [55] sử dụng tỷ lệ tăng tốc 2×, 4×, hoặc 5× (nhỏ hơn là tốt hơn).
Tăng lỗi top-5 (1-view, baseline 89.9%)
Giải pháp 2× 4× 5×
Jaderberg et al. [4] ([14]'s impl.) - 9.7 29.7
Asym. [14] 0.28 3.84 -
Filter pruning [11] (tinh chỉnh, impl. của chúng tôi) 0.8 8.6 14.6
RNP [16] - 3.23 3.58
SPP [17] 0.3 1.1 2.3
Của chúng tôi (không tinh chỉnh) 2.7 7.9 22.0
Của chúng tôi (tinh chỉnh) 0 1.0 1.7
gốc conv1_2 conv2_1 conv2_2 conv3_1 conv3_2 conv3_3 conv4_1 conv4_2012345678 tăng err. MSE tương đối (phải) 0.00.10.20.30.40.50.6
Hình 6. Lỗi cắt tỉa tích lũy từng lớp để tăng tốc VGG-16 dưới 4×. "MSE tương đối" là lỗi bình phương trung bình tương đối. Sau tinh chỉnh, giảm Top-5 là 1.0%.
conv1_2 conv2_1 conv2_2 conv3_1 conv3_2 conv3_3 conv4_1 conv4_201020304050607080 cắt tỉa tái tạo
Hình 7. Tiêu thụ thời gian để cắt tỉa VGG-16 dưới 4×, trên Intel Xeon E5-2670 CPU (đo bằng giây, tiêu thụ thời gian có thể thay đổi một chút trong mỗi lần chạy). Thuật toán của chúng tôi rất hiệu quả.
BẢNG 3
Hiệu suất của các phương pháp kết hợp trên mô hình VGG-16 [55] sử dụng tỷ lệ tăng tốc 4× hoặc 5×. Giải pháp 3C của chúng tôi vượt trội hơn các phương pháp trước đây. Tỷ lệ lỗi top-5 (1-view) của mô hình VGG-16 baseline là 10.1%. (nhỏ hơn là tốt hơn).
Tăng lỗi top-5 (1-view)
Giải pháp 4× 5×
Asym. 3D [14] 0.9 2.0
Asym. 3D (tinh chỉnh) [14] 0.3 1.0
3C của chúng tôi 0.7 1.3
3C của chúng tôi (tinh chỉnh) 0.0 0.3
4.1.3 Kết hợp với Các Phương pháp Trực giao
Vì phương pháp của chúng tôi khai thác một cardinality mới, chúng tôi tiếp tục kết hợp cắt tỉa kênh của chúng tôi với factorization không gian [4] và factorization kênh [14] (Mục 3.5). Được chứng minh trong Bảng 3, tăng tốc 3 cardinalities của chúng tôi (không gian, factorization kênh, và cắt tỉa kênh, được ký hiệu bằng 3C) vượt trội hơn các kỹ thuật tiên tiến trước đây. Asym. 3D [14] (factorization không gian và kênh), phân tích một lớp tích chập thành ba phần: 1×3; 3×1; 1×1.
Chúng tôi áp dụng factorization không gian, factorization kênh, và cắt tỉa kênh của chúng tôi cùng nhau một cách tuần tự từng lớp. Chúng tôi tinh chỉnh các mô hình tăng tốc trong 20 epochs, vì chúng sâu gấp ba lần so với các mô hình gốc. Sau tinh chỉnh, mô hình 4× của chúng tôi không bị suy giảm. Rõ ràng, sự kết hợp của các kỹ thuật tăng tốc khác nhau tốt hơn bất kỳ kỹ thuật đơn lẻ nào. Điều này cho thấy rằng một mô hình dư thừa trong mỗi cardinality.
4.1.4 Hiệu suất không có Tái tạo Đầu ra
Chúng tôi đánh giá hiệu suất cắt tỉa toàn mô hình không có tái tạo đầu ra, để xác minh hiệu quả của bài toán con W (Mục 3.2.2). Được thể hiện trong Bảng 4, không có tái tạo, lỗi tích lũy sẽ không thể chấp nhận được cho cắt tỉa đa lớp. Không có tái tạo, lỗi tăng lên 99%. Ngay cả sau khi tinh chỉnh, điểm số vẫn tệ hơn nhiều so với các đối tác. Điều này là do bước LASSO (Mục 3.2.1) chỉ cập nhật với tự do hạn chế (dimensionality = c), do đó không đủ cho tái tạo. Vì vậy chúng tôi phải thích ứng trọng số gốc W (n×c×kh×kw) với các kênh đầu vào được cắt tỉa.
4.1.5 So sánh với Huấn luyện từ Đầu
Mặc dù huấn luyện một mô hình compact từ đầu tốn thời gian (thường 120 epochs), việc so sánh phương pháp của chúng tôi và các đối tác huấn luyện từ đầu là đáng giá. Để công bằng, chúng tôi đánh giá cả đối tác huấn luyện từ đầu, và mạng cài đặt bình thường có cùng độ phức tạp tính toán và cùng kiến trúc.
Được thể hiện trong Bảng 5, chúng tôi quan sát thấy rằng khó khăn cho các đối tác huấn luyện từ đầu đạt độ chính xác cạnh tranh. Mô hình của chúng tôi vượt trội hơn mô hình huấn luyện từ đầu. Phương pháp của chúng tôi thành công chọn ra các kênh thông tin và xây dựng các mô hình rất compact. Chúng tôi có thể kết luận an toàn rằng cùng một mô hình khó có thể được thu được từ việc huấn luyện từ đầu. Điều này phù hợp với các nghiên cứu thiết kế kiến trúc [10], [64] rằng mô hình có thể dễ huấn luyện hơn nếu có nhiều kênh hơn trong các lớp nông hơn. Tuy nhiên, cắt tỉa kênh ưu tiên các lớp nông hơn.
Đối với huấn luyện từ đầu (uniformed), các bộ lọc trong mỗi lớp được giảm một nửa (ví dụ, giảm conv1_1 từ 64 xuống 32). Chúng tôi có thể quan sát thấy rằng các mạng cài đặt bình thường có cùng độ phức tạp cũng không thể đạt cùng độ chính xác. Điều này củng cố ý tưởng của chúng tôi rằng có nhiều dư thừa trong các mạng trong khi huấn luyện. Tuy nhiên, dư thừa có thể được loại bỏ tại thời điểm suy luận. Đây có thể là một lợi thế của các phương pháp tăng tốc thời gian suy luận so với các phương pháp dựa trên huấn luyện.
Lưu ý rằng có khoảng cách 0.6% giữa mô hình huấn luyện từ đầu và mô hình uniformed, điều này cho thấy còn chỗ cho khám phá mô hình. Áp dụng phương pháp của chúng tôi nhanh hơn nhiều so với huấn luyện một mô hình từ đầu, ngay cả đối với mô hình mỏng hơn. Các nghiên cứu tiếp theo có thể giảm bớt phương pháp của chúng tôi để thực hiện khám phá mô hình mỏng.
4.1.6 Độ chính xác Top-1 so với Top-5
Mặc dù phương pháp của chúng tôi đã đạt hiệu suất tốt với độ chính xác Top-5, vẫn có thể dẫn đến giảm đáng kể độ chính xác Top-1. Được thể hiện trong Bảng 6, chúng tôi so sánh tăng lỗi Top-1 và Top-5 để tăng tốc VGG-16 trên ImageNet. Mặc dù giảm tuyệt đối lớn hơn một chút, Top-1 vẫn nhất quán với kết quả top-5. Đối với 3C 4× và 5×, độ chính xác Top-1 thậm chí tốt hơn. Độ chính xác Top-1 3C 4× vượt trội hơn mô hình VGG-16 gốc 0.3%.
4.1.7 So sánh Hiệu suất Tuyệt đối
Chúng tôi đánh giá thêm hiệu suất tuyệt đối của tăng tốc trên GPU. Kết quả trong Bảng 7 được thu được dưới Caffe [61], CUDA8 [65] và cuDNN5 [66], với mini-batch 32 trên GPU. Kết quả được tính trung bình từ 50 lần chạy. Các phương pháp phân tích tensor phân tích trọng số thành quá nhiều phần, điều này tăng overhead đáng kể. Chúng không thể đạt được nhiều tăng tốc tuyệt đối. Mặc dù phương pháp của chúng tôi cũng gặp phải suy giảm hiệu suất, nó tổng quát tốt hơn trên GPU so với các phương pháp khác. Kết quả của chúng tôi cho phân tích tensor khác với nghiên cứu trước đây [4], [14], có thể do thư viện và phần cứng hiện tại ưu tiên tích chập đơn lớn thay vì nhiều tích chập nhỏ.
4.1.8 Tăng tốc cho Phát hiện
VGG-16 phổ biến trong các nhiệm vụ phát hiện đối tượng [67], [68], [69], [70], [71], [72], [73]. Chúng tôi đánh giá khả năng transfer learning của VGG-16 được cắt tỉa 2×/4× của chúng tôi, cho phát hiện đối tượng Faster R-CNN [74]. Benchmark phát hiện đối tượng PASCAL VOC 2007 [58] chứa 5k hình ảnh trainval và 5k hình ảnh test. Hiệu suất được đánh giá bằng mean Average Precision (mAP) và mmAP (AP tại IoU=.50:.05:.95, metric thách thức chính của COCO [75]). Trong các thí nghiệm của chúng tôi, chúng tôi đầu tiên thực hiện cắt tỉa kênh cho VGG-16 trên ImageNet. Sau đó chúng tôi sử dụng mô hình được cắt tỉa làm mô hình pre-trained cho Faster R-CNN.
Thời gian chạy thực tế của Faster R-CNN là 220ms/hình ảnh. Các lớp tích chập đóng góp khoảng 64%. Chúng tôi có thời gian thực tế 94ms cho tăng tốc 4×. Từ Bảng 8, chúng tôi quan sát giảm 0.4% mAP và 0.0% mmAP của mô hình 2× của chúng tôi, điều này không có hại cho xem xét thực tế. Quan sát từ mmAP, đối với yêu cầu định vị cao hơn, mô hình tăng tốc của chúng tôi không bị suy giảm lớn.
4.2 Thí nghiệm với Mạng Kiến trúc Residual
Đối với các mạng Multi-path [7], [8], [9], chúng tôi khám phá thêm ResNet [8] phổ biến và Xception [9] mới nhất, trên ImageNet và CIFAR-10. Cắt tỉa mạng kiến trúc residual thách thức hơn. Những mạng này được thiết kế cho cả hiệu quả và độ chính xác cao. Các thuật toán phân tích tensor [4], [14] không áp dụng được cho những mô hình này. Về không gian, tích chập 1×1 được ưu tiên, khó có thể phân tích.
4.2.1 Cắt tỉa theo Bộ lọc
Dưới tăng tốc lớp đơn, cắt tỉa theo bộ lọc (Mục 3.4) chính xác hơn so với phương pháp gốc của chúng tôi, vì nó linh hoạt hơn, được thể hiện trong Hình 8. Từ các thí nghiệm cắt tỉa ResNet của chúng tôi trong phần tiếp theo, nó cải thiện 0.5% độ chính xác top-5 cho ResNet-50 2× (áp dụng trên lớp đầu tiên của mỗi nhánh residual) không có tinh chỉnh. Tuy nhiên, sau tinh chỉnh, không có cải thiện đáng chú ý. Bên cạnh đó, nó xuất ra các lớp tích chập "bất thường", cần hỗ trợ triển khai thư viện đặc biệt để đạt tăng tốc thực tế. Do đó, chúng tôi không áp dụng nó cho mạng kiến trúc residual.
4.2.2 Cắt tỉa ResNet
Độ phức tạp ResNet giảm đều trên mỗi khối residual, như thể hiện trong Bảng 9. Được hướng dẫn bởi các thí nghiệm lớp đơn (Mục 4.1.1), chúng tôi vẫn ưu tiên giảm các lớp nông hơn nhiều hơn các lớp sâu hơn. Theo cài đặt tương tự như Filter pruning [11], chúng tôi giữ 70% kênh cho các khối residual nhạy cảm (res5 và các khối gần vị trí thay đổi kích thước không gian, ví dụ res3a, res3d). Đối với các khối khác, chúng tôi giữ 30% kênh. Với cải tiến đa nhánh, chúng tôi cắt tỉa branch2a mạnh mẽ hơn trong mỗi khối residual. Tỷ lệ bảo tồn kênh cho branch2a, branch2b, branch2c là 2:4:3 (ví dụ, cho 30%, chúng tôi giữ 40%, 80%, 60% tương ứng).
Chúng tôi đánh giá hiệu suất của các biến thể đa nhánh trong phương pháp của chúng tôi (Mục 3.4). Phương pháp của chúng tôi vượt trội hơn các phương pháp gần đây (ThiNet [15], Structured Probabilistic Pruning [17]) bởi một biên độ lớn. Từ Bảng 10, chúng tôi cải thiện 4.0% với cải tiến đa nhánh của chúng tôi. Điều này là do chúng tôi tính toán lỗi tích lũy từ kết nối shortcut có thể truyền đến mọi lớp sau nó. Và độ rộng bản đồ đặc trưng đầu vào lớn tại lối vào của mỗi khối residual được giảm tốt bởi lấy mẫu bản đồ đặc trưng của chúng tôi.
4.2.3 Cắt tỉa Xception
Vì độ phức tạp tính toán trở nên quan trọng trong thiết kế mô hình, tích chập tách rời đã được chú ý nhiều [9], [76]. Xception [9] đã được tối ưu hóa không gian và phân tích tensor trên lớp tích chập 1×1 là phá hoại. Nhờ phương pháp của chúng tôi, nó vẫn có thể được tăng tốc với suy giảm nhẹ nhàng.
Để dễ so sánh, chúng tôi áp dụng tích chập Xception trên ResNet-50, được ký hiệu bằng Xception-50. Dựa trên ResNet-50, chúng tôi thay thế tất cả các lớp tích chập bằng các khối conv không gian. Để giữ cùng độ phức tạp tính toán, chúng tôi tăng các kênh đầu vào của tất cả các lớp branch2b lên 2×. Xception-50 baseline có độ chính xác top-5 92.8% và độ phức tạp 4450 MFLOPs.
Chúng tôi áp dụng các biến thể đa nhánh của phương pháp như được mô tả trong Mục 3.4, và áp dụng cùng cài đặt tỷ lệ cắt tỉa như ResNet trong phần trước. Có thể do khối Xception không ổn định, các lớp Batch Normalization phải được duy trì trong quá trình cắt tỉa. Nếu không, việc tinh chỉnh mô hình được cắt tỉa trở nên không tầm thường.
Được thể hiện trong Bảng 11, sau tinh chỉnh, chúng tôi chỉ chịu 1.0% tăng lỗi dưới 2×. Filter pruning [11] cũng có thể áp dụng trên Xception, mặc dù nó được thiết kế cho tỷ lệ tăng tốc nhỏ. Không có tinh chỉnh, lỗi top-5 là 100%. Sau khi huấn luyện 20 epochs, lỗi tăng đạt 4.3% giống như huấn luyện từ đầu. Kết quả của chúng tôi cho Xception-50 không nhẹ nhàng như kết quả cho VGG-16 vì các mạng hiện đại có xu hướng ít dư thừa hơn theo thiết kế.
4.2.4 Thí nghiệm trên CIFAR-10
Mặc dù phương pháp của chúng tôi được thiết kế cho các tập dữ liệu lớn, nó có thể tổng quát tốt trên các tập dữ liệu nhỏ. Chúng tôi thực hiện thí nghiệm trên tập dữ liệu CIFAR-10 [57], được nhiều nghiên cứu tăng tốc ưa chuộng. Nó bao gồm 50k hình ảnh để huấn luyện và 10k để kiểm tra trong 10 lớp. Hình ảnh 32×32 gốc được zero pad với 4 pixel mỗi bên, sau đó random crop thành 32×32 tại thời gian huấn luyện. Phương pháp của chúng tôi có thể hoàn thành trong vài phút.
Chúng tôi tái tạo ResNet-56, có độ chính xác 92.8% (Phục vụ như tham chiếu, ResNet-56 [8] chính thức có độ chính xác 93.0%). Cho tăng tốc 2×, chúng tôi theo cài đặt tương tự như Mục 4.2.2 (giữ giai đoạn cuối không thay đổi, nơi kích thước không gian là 8×8). Được thể hiện trong Bảng 12, phương pháp của chúng tôi cạnh tranh với mô hình huấn luyện từ đầu, không có tinh chỉnh, dưới cả tăng tốc 1.4× và 2×. Sau tinh chỉnh, kết quả của chúng tôi tốt hơn đáng kể so với Filter pruning [11] và mô hình huấn luyện từ đầu cho cả tăng tốc 1.4× và 2×.
Giảm Lớp Nông vs Sâu: Được ký hiệu bằng (uniform) trong Bảng 12, giải pháp uniformed cắt tỉa mỗi lớp với cùng tỷ lệ cắt tỉa. Rõ ràng, kết quả uniformed của chúng tôi tệ hơn so với các lớp nông được giảm nhiều. Tuy nhiên, mô hình uniformed từ đầu tốt hơn so với đối tác của nó. Điều này là do cắt tỉa kênh ưu tiên ít kênh hơn trên các lớp nông, tuy nhiên các mô hình huấn luyện từ đầu hoạt động tốt hơn với nhiều lớp nông hơn. Nó cho thấy rằng dư thừa trên các lớp nông cần thiết trong khi huấn luyện, có thể được loại bỏ tại thời gian suy luận.
5 KẾT LUẬN
Để kết luận, các CNN sâu hiện tại chính xác với chi phí suy luận cao. Trong bài báo này, chúng tôi đã trình bày một phương pháp cắt tỉa kênh thời gian suy luận cho các mạng rất sâu. Các CNN được giảm là mạng suy luận hiệu quả trong khi duy trì độ chính xác, và chỉ cần các thư viện có sẵn. Tăng tốc và độ chính xác thuyết phục được chứng minh cho cả VGG Net và mạng giống ResNet trên ImageNet, CIFAR-10 và PASCAL VOC 2007.
Trong tương lai, chúng tôi dự định liên quan đến các phương pháp của chúng tôi vào thời gian huấn luyện để tăng tốc quy trình huấn luyện, thay vì chỉ thời gian suy luận.
TÀI LIỆU THAM KHẢO
[1] C. Szegedy, V. Vanhoucke, S. Ioffe, J. Shlens, và Z. Wojna, "Rethinking the inception architecture for computer vision," arXiv preprint arXiv:1512.00567, 2015.
[2] N. Vasilache, J. Johnson, M. Mathieu, S. Chintala, S. Piantino, và Y. LeCun, "Fast convolutional nets with fbfft: A gpu performance evaluation," arXiv preprint arXiv:1412.7580, 2014.
[3] M. Courbariaux và Y. Bengio, "Binarynet: Training deep neural networks with weights and activations constrained to+ 1 or-1," arXiv preprint arXiv:1602.02830, 2016.
[4] M. Jaderberg, A. Vedaldi, và A. Zisserman, "Speeding up convolutional neural networks with low rank expansions," arXiv preprint arXiv:1405.3866, 2014.
[5] S. Han, J. Pool, J. Tran, và W. Dally, "Learning both weights and connections for efficient neural network," trong Advances in Neural Information Processing Systems, 2015, pp. 1135–1143.
[6] W. Wen, C. Wu, Y. Wang, Y. Chen, và H. Li, "Learning structured sparsity in deep neural networks," trong Advances In Neural Information Processing Systems, 2016, pp. 2074–2082.
[7] C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed, D. Anguelov, D. Erhan, V. Vanhoucke, và A. Rabinovich, "Going deeper with convolutions," trong Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2015, pp. 1–9.
[8] K. He, X. Zhang, S. Ren, và J. Sun, "Deep residual learning for image recognition," trong Proceedings of the IEEE conference on computer vision and pattern recognition, 2016, pp. 770–778.
[9] F. Chollet, "Xception: Deep learning with depthwise separable convolutions," arXiv preprint arXiv:1610.02357, 2016.
[10] J. M. Alvarez và M. Salzmann, "Learning the number of neurons in deep networks," trong Advances in Neural Information Processing Systems, 2016, pp. 2262–2270.
[11] H. Li, A. Kadav, I. Durdanovic, H. Samet, và H. P. Graf, "Pruning filters for efficient convnets," arXiv preprint arXiv:1608.08710, 2016.
[12] S. Anwar và W. Sung, "Compact deep convolutional neural networks with coarse pruning," arXiv preprint arXiv:1610.09639, 2016.
[13] T. Chen, I. Goodfellow, và J. Shlens, "Net2net: Accelerating learning via knowledge transfer," arXiv preprint arXiv:1511.05641, 2015.
[14] X. Zhang, J. Zou, K. He, và J. Sun, "Accelerating very deep convolutional networks for classification and detection," IEEE transactions on pattern analysis and machine intelligence, vol. 38, no. 10, pp. 1943–1955, 2016.

--- TRANG 6 ---
IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE 6
BẢNG 4
Tăng tốc VGG-16 dưới 4× có hoặc không có bài toán con β. Rõ ràng rằng không có tái tạo, lỗi tăng lên. Tỷ lệ lỗi top-5 (1-view) của mô hình VGG-16 baseline là 10.1%.
Tăng lỗi top-5 (1-view)
phương pháp trước tinh chỉnh tinh chỉnh
Của chúng tôi 7.9 1.0
Không có bài toán con β 99 3.6
BẢNG 5
So sánh với huấn luyện từ đầu, dưới tăng tốc 4× trên mô hình VGG-16. Mô hình tinh chỉnh của chúng tôi vượt trội hơn các đối tác huấn luyện từ đầu. Tỷ lệ lỗi top-5 (1-view) của mô hình VGG-16 baseline là 10.1%. (nhỏ hơn là tốt hơn).
Lỗi Top-5 Lỗi tăng
Từ đầu 11.9 1.8
Từ đầu (uniformed) 12.5 2.4
Của chúng tôi 18.0 7.9
Của chúng tôi (tinh chỉnh) 11.1 1.0
BẢNG 6
Tăng lỗi Top-1 và Top-5 để tăng tốc VGG-16 trên ImageNet. Baseline lỗi Top-5 và Top-1 của mô hình VGG-16 lần lượt là 29.5% và 10.1%.
Mô hình Top-1 Top-5
lỗi tăng lỗi lỗi tăng lỗi
2×, tinh chỉnh 29.5 0.0 10.1 0.0
4×, tinh chỉnh 31.7 2.2 11.1 1.0
5×, tinh chỉnh 32.4 2.9 11.8 1.7
3C, 4×, tinh chỉnh 29.2 -0.3 10.1 0.0
3C, 5×, tinh chỉnh 29.5 0.0 10.4 0.3
Từ đầu 31.9 2.4 11.9 1.8
Từ đầu (uniformed) 32.9 3.4 12.5 2.4
BẢNG 7
So sánh tăng tốc GPU. Chúng tôi đo thời gian forward-pass mỗi hình ảnh. Phương pháp của chúng tôi tổng quát tốt trên GPU. Tỷ lệ lỗi top-5 (1-view) của mô hình VGG-16 baseline là 10.1%. (nhỏ hơn là tốt hơn).
Mô hình Giải pháp Lỗi tăng Thời gian GPU/ms
VGG-16 - 0 8.144
VGG-16 (4×) Jaderberg et al. [4] ([14]'s impl.) 9.7 8.051 (1.01×)
Asym. [14] 3.8 5.244 (1.55×)
Asym. 3D [14] 0.9 8.503 (0.96×)
Asym. 3D (tinh chỉnh) [14] 0.3 8.503 (0.96×)
Của chúng tôi (tinh chỉnh) 1.0 3.264 (2.50×)
3C của chúng tôi (tinh chỉnh) 0.0 3.712 (2.19×)
BẢNG 8
Tăng tốc 2×, 4× cho phát hiện Faster R-CNN. mmAP là AP tại IoU=.50:.05:.95 (metric thách thức chính của COCO [75]).
aero bike bird boat bottle bus car cat chair cow table dog horse mbike person plant sheep sofa train tv mAP mmAP
gốc 68.5 78.1 67.8 56.6 54.3 75.6 80.0 80.0 49.4 73.7 65.5 77.7 80.6 69.9 77.5 40.9 67.6 64.6 74.7 71.7 68.7 36.7
2× 69.6 79.3 66.2 56.1 47.6 76.8 79.9 78.2 50.0 73.0 68.2 75.7 80.5 74.8 76.8 39.1 67.3 66.8 74.5 66.1 68.3 36.7
4× 67.8 79.1 63.6 52.0 47.4 78.1 79.3 77.7 48.3 70.6 64.4 72.8 79.4 74.0 75.9 36.7 65.1 65.1 76.1 64.6 66.9 35.1
BẢNG 9
Độ phức tạp tính toán ResNet-50 (cấu trúc bottleneck). Độ phức tạp ResNet-50 giảm đều trên mỗi khối residual. ix biểu thị khối thứ x của giai đoạn thứ i, i=2,3,4,5; x=a,b,c. Cột "Độ phức tạp" là tỷ lệ độ phức tạp tính toán mà mỗi khối đóng góp.
tên lớp Độ phức tạp (‰)
conv1 30
2a1 13
2a2a 3
ia1 26
ia2a 6
ix2a 13
ix2b 29
ix2c 13
BẢNG 10
Tăng tốc 2× cho ResNet-50 trên ImageNet, độ chính xác top-5 của mạng baseline là 92.2% (một góc nhìn). Chúng tôi cải thiện hiệu suất với cải tiến đa nhánh (Mục 3.4, nhỏ hơn là tốt hơn).
Giải pháp Tăng tốc Lỗi tăng
ThiNet [15] 1.58× 1.53
SPP [17] 2× 1.8
Của chúng tôi 2× 8.0
Của chúng tôi (cải tiến) 2× 4.0
Của chúng tôi (cải tiến, tinh chỉnh) 2× 1.4
1.0 1.5 2.0 2.5 3.0 3.5 4.0 0.00.51.01.52.02.5 tăng lỗi (%) của chúng tôi theo bộ lọc
Hình 8. Phân tích hiệu suất cắt tỉa theo bộ lọc dưới các tỷ lệ tăng tốc khác nhau (không có tinh chỉnh), được đo bằng tăng lỗi trên VGG-16 conv3_2. (nhỏ hơn là tốt hơn).
BẢNG 11
So sánh cho Xception-50, dưới tỷ lệ tăng tốc 2×. Độ chính xác top-5 của mạng baseline là 92.8%. Phương pháp của chúng tôi vượt trội hơn các phương pháp trước đây. Hầu hết các phương pháp đơn giản hóa có cấu trúc không hiệu quả trên kiến trúc Xception (nhỏ hơn là tốt hơn).
Giải pháp Lỗi tăng
Filter pruning [11] (impl. của chúng tôi) 92.8
Filter pruning [11] (tinh chỉnh, impl. của chúng tôi) 4.3
Của chúng tôi 2.9
Của chúng tôi (tinh chỉnh) 1.0
BẢNG 12
So sánh tăng tốc 1.4× và 2× cho ResNet-56 trên CIFAR-10, độ chính xác baseline là 92.8% (một góc nhìn). Chúng tôi vượt trội hơn các phương pháp trước đây và đối tác huấn luyện từ đầu (nhỏ hơn là tốt hơn).
Mô hình 1.4× 2×
lỗi lỗi tăng lỗi lỗi tăng
Filter pruning [11] (tinh chỉnh, impl. của chúng tôi) 7.2 0.0 8.5 1.3
Từ đầu 7.8 0.6 9.1 1.9
Của chúng tôi 7.7 0.5 9.2 2.0
Của chúng tôi (tinh chỉnh) 7.2 0.0 8.2 1.0
từ đầu (uniformed) - - 8.7 1.5
của chúng tôi (uniformed) - - 10.2 3.0
của chúng tôi (uniformed, tinh chỉnh) - - 8.6 1.4
[15] J.-H. Luo, J. Wu, và W. Lin, "Thinet: A filter level pruning method for deep neural network compression," trong Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2017, pp. 5058–5066.
[16] J. Lin, Y. Rao, và J. Lu, "Runtime neural pruning," trong Advances in Neural Information Processing Systems, 2017, pp. 2178–2188.
[17] H. Wang, Q. Zhang, Y. Wang, và R. Hu, "Structured probabilistic pruning for deep convolutional neural network acceleration," arXiv preprint arXiv:1709.06994, 2017.
[18] Z. Liu, J. Li, Z. Shen, G. Huang, S. Yan, và C. Zhang, "Learning efficient convolutional networks through network slimming," trong Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2017, pp. 2736–2744.
[19] Y. He, X. Zhang, và J. Sun, "Channel pruning for accelerating very deep neural networks," trong The IEEE International Conference on Computer Vision (ICCV), Oct 2017, pp. 1389–1397.
[20] Y. Cheng, D. Wang, P. Zhou, và T. Zhang, "A survey of model compression and acceleration for deep neural networks," arXiv preprint arXiv:1710.09282, 2017.
[21] Y. LeCun, J. S. Denker, S. A. Solla, R. E. Howard, và L. D. Jackel, "Optimal brain damage." trong NIPs, vol. 2, 1989, pp. 598–605.
[22] B. Hassibi và D. G. Stork, Second order derivatives for network pruning: Optimal brain surgeon. Morgan Kaufmann, 1993.
[23] H. Bagherinezhad, M. Rastegari, và A. Farhadi, "Lcnn: Lookup-based convolutional neural network," arXiv preprint arXiv:1611.06473, 2016.
[24] M. Rastegari, V. Ordonez, J. Redmon, và A. Farhadi, "Xnor-net: Imagenet classification using binary convolutional neural networks," trong European Conference on Computer Vision. Springer, 2016, pp. 525–542.
[25] M. Mathieu, M. Henaff, và Y. LeCun, "Fast training of convolutional networks through ffts," arXiv preprint arXiv:1312.5851, 2013.
[26] A. Lavin, "Fast algorithms for convolutional neural networks," arXiv preprint arXiv:1509.09308, 2015.
[27] H. Phan, Y. He, M. Savvides, Z. Shen et al., "Mobinet: A mobile binary network for image classification," trong Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, 2020, pp. 3453–3462.
[28] B. Liu, M. Wang, H. Foroosh, M. Tappen, và M. Pensky, "Sparse convolutional neural networks," trong Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2015, pp. 806–814.
[29] V. Lebedev và V. Lempitsky, "Fast convnets using group-wise brain damage," arXiv preprint arXiv:1506.02515, 2015.
[30] S. Han, X. Liu, H. Mao, J. Pu, A. Pedram, M. A. Horowitz, và W. J. Dally, "Eie: efficient inference engine on compressed deep neural network," trong Proceedings of the 43rd International Symposium on Computer Architecture. IEEE Press, 2016, pp. 243–254.
[31] Y. Guo, A. Yao, và Y. Chen, "Dynamic network surgery for efficient dnns," trong Advances In Neural Information Processing Systems, 2016, pp. 1379–1387.
[32] H. Zhong, X. Liu, Y. He, và Y. Ma, "Shift-based primitives for efficient convolutional neural networks," arXiv preprint arXiv:1809.08458, 2018.
[33] Y. He, X. Liu, H. Zhong, và Y. Ma, "Addressnet: Shift-based primitives for efficient convolutional neural networks," trong 2019 IEEE Winter conference on applications of computer vision (WACV). IEEE, 2019, pp. 1213–1222.
[34] T.-J. Yang, Y.-H. Chen, và V. Sze, "Designing energy-efficient convolutional neural networks using energy-aware pruning," arXiv preprint arXiv:1611.05128, 2016.
[35] S. Han, H. Mao, và W. J. Dally, "Deep compression: Compressing deep neural network with pruning, trained quantization and huffman coding," CoRR, abs/1510.00149, vol. 2, 2015.
[36] V. Lebedev, Y. Ganin, M. Rakhuba, I. Oseledets, và V. Lempitsky, "Speeding-up convolutional neural networks using fine-tuned cp-decomposition," arXiv preprint arXiv:1412.6553, 2014.
[37] Y. Gong, L. Liu, M. Yang, và L. Bourdev, "Compressing deep convolutional networks using vector quantization," arXiv preprint arXiv:1412.6115, 2014.
[38] Y.-D. Kim, E. Park, S. Yoo, T. Choi, L. Yang, và D. Shin, "Compression of deep convolutional neural networks for fast and low power mobile applications," arXiv preprint arXiv:1511.06530, 2015.
[39] Y. He, J. Qian, và J. Wang, "Depth-wise decomposition for accelerating separable convolutions in efficient convolutional neural networks," trong Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops, 2019.
[40] J. Xue, J. Li, và Y. Gong, "Restructuring of deep neural network acoustic models with singular value decomposition." trong INTERSPEECH, 2013, pp. 2365–2369.
[41] E. L. Denton, W. Zaremba, J. Bruna, Y. LeCun, và R. Fergus, "Exploiting linear structure within convolutional networks for efficient evaluation," trong Advances in Neural Information Processing Systems, 2014, pp. 1269–1277.
[42] R. Girshick, "Fast r-cnn," trong Proceedings of the IEEE International Conference on Computer Vision, 2015, pp. 1440–1448.
[43] X. Zhang và H. Yihui, "Image processing method and apparatus, and computer-readable storage medium," Jul. 14 2020, US Patent 10,713,533.
[44] H. Zhou, J. M. Alvarez, và F. Porikli, "Less is more: Towards compact cnns," trong European Conference on Computer Vision. Springer International Publishing, 2016, pp. 662–677.
[45] Y. LeCun, L. Bottou, Y. Bengio, và P. Haffner, "Gradient-based learning applied to document recognition," Proceedings of the IEEE, vol. 86, no. 11, pp. 2278–2324, 1998.
[46] A. Krizhevsky, I. Sutskever, và G. E. Hinton, "Imagenet classification with deep convolutional neural networks," trong Advances in neural information processing systems, 2012, pp. 1097–1105.
[47] S. Anwar, K. Hwang, và W. Sung, "Structured pruning of deep convolutional neural networks," arXiv preprint arXiv:1512.08571, 2015.
[48] A. Polyak và L. Wolf, "Channel-level acceleration of deep face representations," IEEE Access, vol. 3, pp. 2163–2175, 2015.
[49] Y. He, J. Lin, Z. Liu, H. Wang, L.-J. Li, và S. Han, "Amc: Automl for model compression and acceleration on mobile devices," trong European Conference on Computer Vision, Sept 2018.
[50] S. Srinivas và R. V. Babu, "Data-free parameter pruning for deep neural networks," arXiv preprint arXiv:1507.06149, 2015.
[51] Z. Mariet và S. Sra, "Diversity networks," arXiv preprint arXiv:1511.05077, 2015.
[52] H. Hu, R. Peng, Y.-W. Tai, và C.-K. Tang, "Network trimming: A data-driven neuron pruning approach towards efficient deep architectures," arXiv preprint arXiv:1607.03250, 2016.
[53] R. Tibshirani, "Regression shrinkage and selection via the lasso," Journal of the Royal Statistical Society. Series B (Methodological), pp. 267–288, 1996.
[54] L. Breiman, "Better subset regression using the nonnegative garrote," Technometrics, vol. 37, no. 4, pp. 373–384, 1995.
[55] K. Simonyan và A. Zisserman, "Very deep convolutional networks for large-scale image recognition," arXiv preprint arXiv:1409.1556, 2014.
[56] J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, và L. Fei-Fei, "Imagenet: A large-scale hierarchical image database," trong Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE Conference on. IEEE, 2009, pp. 248–255.
[57] A. Krizhevsky và G. Hinton, "Learning multiple layers of features from tiny images," 2009.
[58] M. Everingham, L. Van Gool, C. K. I. Williams, J. Winn, và A. Zisserman, "The PASCAL Visual Object Classes Challenge 2007 (VOC2007) Results," http://www.pascal-network.org/challenges/VOC/voc2007/workshop/index.html.
[59] S. Ioffe và C. Szegedy, "Batch normalization: Accelerating deep network training by reducing internal covariate shift," arXiv preprint arXiv:1502.03167, 2015.
[60] V. Nair và G. E. Hinton, "Rectified linear units improve restricted boltzmann machines," trong Proceedings of the 27th international conference on machine learning (ICML-10), 2010, pp. 807–814.
[61] Y. Jia, E. Shelhamer, J. Donahue, S. Karayev, J. Long, R. Girshick, S. Guadarrama, và T. Darrell, "Caffe: Convolutional architecture for fast feature embedding," arXiv preprint arXiv:1408.5093, 2014.
[62] M. Abadi, A. Agarwal, P. Barham, E. Brevdo, Z. Chen, C. Citro, G. S. Corrado, A. Davis, J. Dean, M. Devin, S. Ghemawat, I. Goodfellow, A. Harp, G. Irving, M. Isard, Y. Jia, R. Jozefowicz, L. Kaiser, M. Kudlur, J. Levenberg, D. Mané, R. Monga, S. Moore, D. Murray, C. Olah, M. Schuster, J. Shlens, B. Steiner, I. Sutskever, K. Talwar, P. Tucker, V. Vanhoucke, V. Vasudevan, F. Viégas, O. Vinyals, P. Warden, M. Wattenberg, M. Wicke, Y. Yu, và X. Zheng, "TensorFlow: Large-scale machine learning on heterogeneous systems," 2015, software available from tensorflow.org. [Online]. Available: http://tensorflow.org/
[63] F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher, M. Perrot, và E. Duchesnay, "Scikit-learn: Machine learning in Python," Journal of Machine Learning Research, vol. 12, pp. 2825–2830, 2011.
[64] J. Huang, V. Rathod, C. Sun, M. Zhu, A. Korattikara, A. Fathi, I. Fischer, Z. Wojna, Y. Song, S. Guadarrama et al., "Speed/accuracy trade-offs for modern convolutional object detectors," arXiv preprint arXiv:1611.10012, 2016.
[65] J. Nickolls, I. Buck, M. Garland, và K. Skadron, "Scalable parallel programming with CUDA," ACM Queue, vol. 6, no. 2, pp. 40–53, 2008. [Online]. Available: http://doi.acm.org/10.1145/1365490.1365500
[66] S. Chetlur, C. Woolley, P. Vandermersch, J. Cohen, J. Tran, B. Catanzaro, và E. Shelhamer, "cudnn: Efficient primitives for deep learning," CoRR, vol. abs/1410.0759, 2014. [Online]. Available: http://arxiv.org/abs/1410.0759
[67] J. Redmon, S. K. Divvala, R. B. Girshick, và A. Farhadi, "You only look once: Unified, real-time object detection," CoRR, vol. abs/1506.02640, 2015. [Online]. Available: http://arxiv.org/abs/1506.02640
[68] W. Liu, D. Anguelov, D. Erhan, C. Szegedy, S. E. Reed, C. Fu, và A. C. Berg, "SSD: single shot multibox detector," CoRR, vol. abs/1512.02325, 2015. [Online]. Available: http://arxiv.org/abs/1512.02325
[69] C. Zhu, Y. He, và M. Savvides, "Feature selective anchor-free module for single-shot object detection," trong Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, 2019, pp. 840–849.
[70] Y. He và J. Wang, "Deep mixture density network for probabilistic object detection," trong 2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). IEEE, 2020, pp. 10 550–10 555.
[71] Y. He, C. Zhu, J. Wang, M. Savvides, và X. Zhang, "Bounding box regression with uncertainty for accurate object detection," trong Proceedings of the ieee/cvf conference on computer vision and pattern recognition, 2019, pp. 2888–2897.
[72] Y. He và J. Wang, "Deep multivariate mixture of gaussians for object detection under occlusion," 2019.
[73] Y. He, X. Zhang, M. Savvides, và K. Kitani, "Softer-nms: Rethinking bounding box regression for accurate object detection," arXiv preprint arXiv:1809.08545, vol. 2, no. 3, pp. 69–80, 2018.
[74] S. Ren, K. He, R. B. Girshick, và J. Sun, "Faster R-CNN: towards real-time object detection with region proposal networks," CoRR, vol. abs/1506.01497, 2015. [Online]. Available: http://arxiv.org/abs/1506.01497
[75] T.-Y. Lin, M. Maire, S. Belongie, J. Hays, P. Perona, D. Ramanan, P. Dollár, và C. L. Zitnick, "Microsoft coco: Common objects in context," trong European conference on computer vision. Springer, Cham, 2014, pp. 740–755.
[76] S. Xie, R. Girshick, P. Dollár, Z. Tu, và K. He, "Aggregated residual transformations for deep neural networks," arXiv preprint arXiv:1611.05431, 2016.

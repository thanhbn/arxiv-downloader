# Mô hình ngôn ngữ lớn cho gợi ý tạo sinh: Khảo sát và thảo luận tầm nhìn

Lei Li1, Yongfeng Zhang2, Dugang Liu3, Li Chen1
1Đại học Baptist Hong Kong, Hong Kong, Trung Quốc
2Đại học Rutgers, New Brunswick, Hoa Kỳ
3Phòng thí nghiệm Trí tuệ nhân tạo và Kinh tế số Quảng Đông (SZ), Thâm Quyến, Trung Quốc
{csleili, lichen}@comp.hkbu.edu.hk, yongfeng.zhang@rutgers.edu, dugang.ldg@gmail.com

## Tóm tắt

Các mô hình ngôn ngữ lớn (LLM) không chỉ đã cách mạng hóa lĩnh vực xử lý ngôn ngữ tự nhiên (NLP) mà còn có tiềm năng định hình lại nhiều lĩnh vực khác, ví dụ như hệ thống gợi ý (RS). Tuy nhiên, hầu hết các nghiên cứu liên quan đều coi LLM như một thành phần của quy trình gợi ý thông thường (ví dụ, như một bộ trích xuất đặc trưng), điều này có thể không tận dụng đầy đủ sức mạnh tạo sinh của LLM. Thay vì tách quy trình gợi ý thành nhiều giai đoạn, chẳng hạn như tính toán điểm số và sắp xếp lại, quy trình này có thể được đơn giản hóa thành một giai đoạn với LLM: trực tiếp tạo ra các gợi ý từ toàn bộ tập hợp các mục. Khảo sát này xem xét tiến trình, phương pháp và hướng phát triển tương lai của gợi ý tạo sinh dựa trên LLM bằng cách kiểm tra ba câu hỏi: 1) Gợi ý tạo sinh là gì, 2) Tại sao RS nên tiến tới gợi ý tạo sinh, và 3) Cách triển khai gợi ý tạo sinh dựa trên LLM cho các tác vụ RS khác nhau. Chúng tôi hy vọng rằng khảo sát này có thể cung cấp bối cảnh và hướng dẫn cần thiết để khám phá chủ đề thú vị và mới nổi này.

**Từ khóa:** Mô hình Ngôn ngữ Lớn, Hệ thống Gợi ý, Gợi ý Tạo sinh, Truy xuất Thông tin

## 1. Giới thiệu

Các mô hình ngôn ngữ lớn (LLM) đang ảnh hưởng sâu sắc đến lĩnh vực xử lý ngôn ngữ tự nhiên (NLP), và khả năng mạnh mẽ của chúng trong việc xử lý các tác vụ khác nhau cũng đã truyền cảm hứng cho những con đường mới cho các nhà thực hành trong các lĩnh vực khác, ví dụ như hệ thống gợi ý (RS). Là một phương tiện hiệu quả để giải quyết tình trạng quá tải thông tin trong thời đại ngày nay, RS đã được tích hợp chặt chẽ vào cuộc sống hàng ngày của chúng ta, và cách tái cấu trúc hiệu quả nó với LLM là một vấn đề nghiên cứu đầy triển vọng (Geng et al., 2022c). Mặc dù ngôn ngữ tự nhiên là một phương tiện biểu đạt, nhưng nó cũng có thể mơ hồ. Ví dụ, khi một LLM được triển khai để nhận dạng và lập lịch xe, việc sử dụng các mô tả mơ hồ (ví dụ, "một chiếc SUV màu đen") để nhận dạng xe thay vì một định danh chính xác như số nhận dạng xe (VIN) hoặc số biển số sẽ rất nguy hiểm. Tương tự, sự mơ hồ cũng có thể là một vấn đề trong các tình huống gợi ý đòi hỏi định danh chính xác và duy nhất của các mục, bởi vì RS cần đảm bảo rằng các gợi ý được đưa ra cho người dùng là những thứ thực sự tồn tại để tránh vấn đề ảo giác (Azamfirei et al., 2023). Điều này cũng giải thích tại sao một ID thường được gán cho mỗi người dùng/mục trong RS. Mặc dù vậy, hiểu biết hiện tại về ID thường bị giới hạn ở một dạng, tức là hầu hết nghiên cứu RS coi mỗi ID như một token rời rạc được liên kết với một vector nhúng. Trong khảo sát này, chúng tôi tổng quát hóa định nghĩa về ID để tăng cường kết nối của nó với LLM:

**Định nghĩa 1 (ID trong Hệ thống Gợi ý)** Một ID trong hệ thống gợi ý là một chuỗi các token có thể xác định duy nhất một thực thể, chẳng hạn như người dùng hoặc mục. Một ID có thể có nhiều dạng khác nhau, chẳng hạn như ID nhúng, chuỗi token số và chuỗi token từ (bao gồm tiêu đề mục, mô tả của mục, hoặc thậm chí là một bài báo hoàn chỉnh), miễn là nó có thể xác định duy nhất thực thể đó.

Ví dụ, một sản phẩm trên nền tảng thương mại điện tử có thể được gán ID item_7391 và được biểu diễn thêm như một chuỗi token chẳng hạn như ⟨item⟩⟨_⟩⟨73⟩⟨91⟩ (Geng et al., 2022c; Xu et al., 2023b). Lưu ý rằng ID không nhất thiết phải bao gồm các token số. Miễn là nó là một định danh duy nhất cho một mục, nó có thể được coi là ID của mục đó. Ví dụ, tiêu đề của bộ phim "The Lord of the Rings" có thể được coi là ID của bộ phim này. ID thậm chí có thể là một chuỗi các từ không truyền đạt bất kỳ ý nghĩa rõ ràng nào, ví dụ, "ring epic journey fellowship adventure" (Hua et al., 2023b). ID trong RS thông thường có thể được xem như một trường hợp đặc biệt của định nghĩa trên, tức là một chuỗi chỉ có một token. Với định nghĩa này, ID giống như các chuỗi token trong văn bản và do đó tự nhiên phù hợp với môi trường ngôn ngữ tự nhiên và LLM.

Do số lượng mục khổng lồ trong các hệ thống thực tế, RS truyền thống thường áp dụng mô hình lọc đa giai đoạn (Covington et al., 2016) – một số phương pháp đơn giản và hiệu quả (ví dụ, lọc dựa trên quy tắc) được sử dụng để giảm số lượng mục ứng viên từ hàng triệu xuống vài trăm, và các thuật toán gợi ý tiên tiến sau đó được áp dụng trên những mục này để chọn ra một số ít mục cho gợi ý. Kết quả là, các thuật toán gợi ý tiên tiến không được áp dụng cho tất cả các mục, mà chỉ cho vài trăm mục.

Sức mạnh tạo sinh của LLM có tiềm năng tái cấu trúc mô hình RS từ lọc đa giai đoạn sang lọc một giai đoạn. Cụ thể, bản thân LLM có thể là quy trình gợi ý đơn lẻ và toàn diện mà trực tiếp tạo ra các mục để gợi ý, loại bỏ nhu cầu lọc đa giai đoạn. Theo cách này, các thuật toán gợi ý tiên tiến dựa trên LLM được áp dụng cho tất cả các mục trong hệ thống nhưng theo cách ngầm định. Chúng tôi gọi quá trình như vậy là gợi ý tạo sinh và định nghĩa chính thức như sau:

**Định nghĩa 2 (Gợi ý Tạo sinh)** Một hệ thống gợi ý tạo sinh trực tiếp tạo ra các gợi ý hoặc nội dung liên quan đến gợi ý mà không cần tính toán điểm xếp hạng của từng ứng viên một cách riêng lẻ.

Theo nghĩa rộng hơn, điều này phù hợp với xu hướng của nghiên cứu trí tuệ nhân tạo (AI) tổng quát, gần đây đã chuyển từ AI phân biệt (như phân loại và hồi quy) sang AI tạo sinh (ví dụ, ChatGPT¹).

Với các định nghĩa trên, trước tiên chúng tôi trả lời tại sao RS đang phát triển theo hướng gợi ý tạo sinh trong Phần 2. Trong Phần 3, chúng tôi xem xét các phương pháp tạo ID có thể giữ lại thông tin cộng tác của ID trong môi trường LLM. Sau đó, chúng tôi cho thấy cách các tác vụ gợi ý điển hình có thể được thực hiện với LLM bằng cách cung cấp công thức tổng quát trong Phần 4, và nổi bật các cơ hội trong kỷ nguyên LLM trong Phần 5. Cuối cùng, chúng tôi kết luận khảo sát của mình trong Phần 6.

Cần lưu ý rằng khảo sát của chúng tôi khác với một số khảo sát gần đây về gợi ý dựa trên LLM (Liu et al., 2023c; Wu et al., 2023; Fan et al., 2023; Lin et al., 2023a; Chen et al., 2023; Vats et al., 2024; Huang et al., 2024) từ hai góc độ: 1) khảo sát của chúng tôi được tổ chức với gợi ý tạo sinh là trọng tâm chính, loại bỏ các mô hình gợi ý phân biệt để rõ ràng; 2) chúng tôi phát triển một taxonomy cho nghiên cứu gợi ý dựa trên LLM với cảm hứng mạnh mẽ từ cộng đồng gợi ý, thay vì mù quáng theo taxonomy LLM từ cộng đồng NLP.

Tóm lại, khảo sát này đóng góp những điều sau:

• Theo hiểu biết của chúng tôi, đây là khảo sát đầu tiên tóm tắt một cách có hệ thống nghiên cứu về gợi ý tạo sinh dựa trên LLM. Để phân biệt chủ đề này với RS truyền thống, chúng tôi đã tổng quát hóa định nghĩa về ID cho gợi ý tạo sinh.

• Khảo sát này mang tính thực dụng vì chúng tôi cung cấp công thức cho các tác vụ gợi ý dựa trên LLM khác nhau khi phân loại nghiên cứu liên quan, điều này sẽ cung cấp hướng dẫn hữu ích cho nghiên cứu tương lai.

• Chúng tôi thảo luận về các hướng quan trọng và đầy triển vọng để khám phá cho nghiên cứu gợi ý tạo sinh dựa trên LLM, điều này có thể giúp mở rộng phạm vi của lĩnh vực nghiên cứu chưa được khám phá này.

## 2. Tại sao Gợi ý Tạo sinh

Để trả lời tại sao RS đang phát triển theo hướng gợi ý tạo sinh, trước tiên chúng tôi thảo luận về các vấn đề với gợi ý phân biệt. Khi số lượng mục trên nền tảng gợi ý là cực kỳ lớn, việc tính toán điểm xếp hạng cho mỗi mục sẽ tốn kém về mặt tính toán. Do đó, RS công nghiệp thường bao gồm nhiều giai đoạn để thu hẹp các mục ứng viên. Ở giai đoạn đầu, các mô hình đơn giản (ví dụ, hồi quy logistic) hoặc các chiến lược lọc đơn giản (ví dụ, khớp đặc trưng) thường được áp dụng để lọc bỏ các mục ít liên quan. Chỉ ở giai đoạn cuối, các mô hình tương đối phức tạp và tiên tiến mới có thể được sử dụng. Điều này tự nhiên tạo ra khoảng cách giữa nghiên cứu học thuật và ứng dụng công nghiệp. Mặc dù các mô hình gợi ý gần đây ngày càng phức tạp và tinh vi, nhưng ít được sử dụng thực tế trong công nghiệp.

Trong kỷ nguyên LLM, chúng ta thấy một cơ hội tuyệt vời có thể thu hẹp khoảng cách này. Vì cả nghiên cứu học thuật và ứng dụng công nghiệp có thể chia sẻ cùng một LLM backbone, hầu hết các tiến bộ nghiên cứu về LLM có thể mang lại lợi ích cho các ứng dụng downstream của nó. Về quy trình gợi ý, các giai đoạn đa dạng điển hình có thể được nâng cấp thành một giai đoạn cho gợi ý tạo sinh, tức là trực tiếp tạo ra các mục để gợi ý. Biểu đồ so sánh giữa hai loại quy trình được hiển thị trong Hình 1. Ở mỗi bước tạo gợi ý, một LLM có thể tạo ra một vector đại diện cho phân phối xác suất trên tất cả các token ID có thể. Sau vài bước, các token được tạo có thể tạo thành một ID hoàn chỉnh đại diện cho mục đích. Quá trình này ngầm định liệt kê tất cả các mục ứng viên để tạo ra mục đích cho gợi ý, điều này khác với RS truyền thống, lấy các mục từ một tập con kết quả từ bước lọc trước đó.

Bí mật chính của LLM cho gợi ý tạo sinh là chúng ta có thể sử dụng số token hữu hạn để đại diện cho gần như vô số mục. Giả sử chúng ta có 1000 token để đại diện cho ID người dùng hoặc mục, có thể là token số, token từ, hoặc thậm chí là token ngoài từ vựng (OOV), và mỗi ID bao gồm 10 token, thì chúng ta có thể sử dụng 1000 token này để đại diện cho nhiều như 1000¹⁰ = 10³⁰ mục (tức là ID duy nhất), đây là một con số gần như thiên văn và đủ lớn cho hầu hết RS thực tế. Khi áp dụng thuật toán tìm kiếm chùm (SCIENCE, 1977) để tạo ID mục, vector xác suất ở mỗi bước được giới hạn bởi 1000 token, làm cho việc trực tiếp tạo gợi ý từ pool mục trở nên khả thi về mặt tính toán.

## 3. Phương pháp Tạo ID

Khi triển khai gợi ý tạo sinh với LLM, đầu vào (đặc biệt là ID người dùng và mục) nên được tạo thành định dạng phù hợp tương thích với LLM. Theo trực giác, người ta sẽ coi metadata của người dùng và mục như một lựa chọn thay thế, chẳng hạn như tên người dùng và tiêu đề mục. Loại biểu diễn ID này khá phổ biến trong các nghiên cứu liên quan, như được tóm tắt trong Bảng 1. Mặc dù phổ biến, nó có hai vấn đề (Li et al., 2023c). Thứ nhất, khi ID cực kỳ dài, ví dụ, trong trường hợp mô tả mục, việc thực hiện tạo sinh sẽ tốn kém về mặt tính toán. Bên cạnh đó, sẽ khó tìm được một khớp chính xác trong cơ sở dữ liệu cho một ID dài; và việc kiểm tra lại sự tồn tại của mỗi ID sẽ đưa chúng ta trở lại gợi ý phân biệt vì chúng ta cần so sánh nó với mỗi mục trong cơ sở dữ liệu. Thứ hai, mặc dù ngôn ngữ tự nhiên là một phương tiện mạnh mẽ và biểu đạt, nhưng nó cũng có thể mơ hồ trong nhiều trường hợp. Ví dụ, hai mục không liên quan có thể có tên giống hệt nhau, chẳng hạn như Apple quả táo và Apple công ty, trong khi hai mục có liên quan chặt chẽ có thể có tiêu đề khác biệt, như trong ví dụ nổi tiếng "bia và tã" trong khai thác dữ liệu.

Do đó, chúng ta cần các biểu diễn ID ngắn gọn và duy nhất trong các tình huống gợi ý để phân biệt chính xác một người dùng hoặc mục với những người khác. Việc liên kết mỗi ID với một vector nhúng là một thực hành phổ biến trong RS truyền thống, nhưng nó sẽ tốn rất nhiều bộ nhớ để lưu trữ chúng vì RS quy mô công nghiệp thường liên quan đến hàng tấn người dùng và mục. Ngoài ra, những ID này là token OOV đối với LLM và do đó không tương thích lắm với chúng.

Đây là lý do tại sao cần một cách mới để biểu diễn ID, tức là một chuỗi token thay vì một nhúng đơn lẻ. Ý tưởng chính là sử dụng một lượng nhỏ token để đại diện cho một số lượng thiên văn của người dùng hoặc mục, như đã giải thích trong phần trước. Để làm cho ID ngắn hợp lý, các người dùng hoặc mục tương tự có thể chia sẻ nhiều token hơn trong chuỗi ID của họ, trong khi các token còn lại có thể được sử dụng để đảm bảo tính duy nhất của chúng. Trong phần sau, chúng tôi xem xét ba phương pháp tạo ID điển hình theo nguyên tắc này. Hầu hết các phương pháp tạo ID này nhằm mã hóa thông tin cộng tác người dùng-người dùng, mục-mục, hoặc người dùng-mục vào ID, kết hợp ưu điểm của lọc cộng tác từ RS truyền thống với LLM mới nổi để gợi ý hiệu quả.

### 3.1. Phân tích Giá trị Đơn

(Petrov và Macdonald, 2023) thu được token ID của một mục từ các yếu tố ẩn của nó. Cụ thể, họ trước tiên thực hiện phân tích giá trị đơn bị cắt trên dữ liệu tương tác người dùng-mục để có được ma trận nhúng mục. Sau một tập hợp các thao tác, bao gồm chuẩn hóa, thêm nhiễu, lượng tử hóa và điều chỉnh offset, nhúng của mỗi mục trở thành một mảng số nguyên, phục vụ như chuỗi ID của mục này. Đặc biệt, thao tác thêm nhiễu có thể đảm bảo rằng không có nhúng mục nào giống hệt nhau, và do đó làm cho mỗi ID mục duy nhất.

### 3.2. Chỉ mục Cộng tác

(Hua et al., 2023b) tạo thành ID mục với các nút trên cây phân cấp. Về mặt kỹ thuật, họ trước tiên xây dựng đồ thị mục có trọng số cạnh biểu thị tần suất xuất hiện cùng nhau của bất kỳ hai mục nào trong tất cả lịch sử tương tác của người dùng. Sau đó, ma trận kề và ma trận Laplacian của đồ thị, cũng như các eigenvector của ma trận sau, có thể được tính toán. Với các eigenvector, phân cụm phổ (Von Luxburg, 2007) có thể được áp dụng để nhóm các mục tương tự vào cùng một cụm. Bằng cách thực hiện đệ quy như vậy, các cụm lớn có thể được chia thành các cụm nhỏ hơn. Khi số lượng nút trong mỗi cụm nhỏ hơn một ngưỡng, các cụm này và các cụm con của chúng tự nhiên tạo thành một cây phân cấp có các nút lá là các mục. Sau khi gán token cho mỗi nút, mỗi mục có một chuỗi ID duy nhất bằng cách theo một đường dẫn từ nút gốc đến nút lá.

### 3.3. Bộ mã hóa tự động biến phân được lượng tử hóa dư

(Zheng et al., 2023) lượng tử hóa nhúng mục với bộ mã hóa tự động biến phân được lượng tử hóa dư (RQ-VAE) (Zeghidour et al., 2021) để có được ID mục. Họ trước tiên mã hóa mô tả văn bản của một mục với LLM để có được nhúng của mục. Sau khi truyền nhúng qua bộ mã hóa của VAE, một biểu diễn ẩn có thể được thu được. Sau đó, họ coi biểu diễn này như vector dư ban đầu và thực hiện lượng tử hóa dư nhiều bước. Ở mỗi bước, có một codebook, tức là một bảng nhúng, từ đó có thể tìm thấy nhúng gần nhất với vector dư. Chỉ số của nhúng này trong codebook sẽ là codeword của mục ở bước này, tức là một token của chuỗi ID mục. Một vector dư mới có thể được tính bằng cách trừ vector dư cũ với nhúng gần nhất. Bằng cách lặp lại như vậy, ID mục hoàn chỉnh có thể được hình thành.

Ngoài ba phương pháp tạo ID trên, (Hua et al., 2023b) đã thảo luận các chiến lược khác, chẳng hạn như chỉ mục tuần tự dựa trên lịch sử tương tác người dùng và chỉ mục ngữ nghĩa dựa trên thông tin metadata mục, đây là những phương pháp hiệu quả để tạo ID mục. Chúng tôi bỏ qua chi tiết vì chúng khá đơn giản.

## 4. Cách thực hiện Gợi ý Tạo sinh

Với các ID người dùng và mục đã định nghĩa ở trên, bây giờ chúng tôi mô tả cách thực hiện các tác vụ gợi ý tạo sinh khác nhau với LLM. Một tóm tắt nghiên cứu liên quan về mỗi tác vụ được đưa ra trong Bảng 2. Chúng ta có thể thấy rằng có một vài mô hình có thể thực hiện nhiều tác vụ gợi ý, ví dụ P5 (Geng et al., 2022c). Để cho phép LLM hiểu mỗi tác vụ, đặc biệt là những tác vụ có cùng dữ liệu đầu vào, chúng ta có thể xây dựng một mẫu prompt (Liu et al., 2023d) mô tả tác vụ và sau đó điền thông tin người dùng và mục, chẳng hạn như ID của họ, vào prompt. Trong giai đoạn suy luận, tất cả các loại đầu ra (ví dụ, ID mục được dự đoán) được tạo tự động hồi quy theo cách tạo ngôn ngữ tự nhiên. Tiếp theo, chúng tôi giới thiệu công thức tổng quát của mỗi tác vụ, theo sau là tiến trình gần đây. Cuối cùng, chúng tôi thảo luận cách đánh giá các tác vụ này.

### 4.1. Dự đoán Xếp hạng

Trong RS thông thường, tác vụ dự đoán xếp hạng được công thức hóa như sau: cho một người dùng u và một mục i, một mô hình gợi ý f(u, i) cần ước tính một điểm số ˆru,i mà người dùng sẽ xếp hạng mục đó. Trong bối cảnh LLM, u và i không còn là ID nhúng, mà là hai chuỗi token như được định nghĩa trong Định nghĩa 1. Hai ID có thể được điền vào một prompt hướng dẫn p(u, i), ví dụ, "người dùng user_1234 sẽ xếp hạng item_5678 như thế nào", sao cho LLM có thể hiểu tác vụ này. Sau khi đưa p(u, i) vào LLM, nó có thể tạo ra một chuỗi số trên thang điểm từ 1 đến 5, chẳng hạn như "4.12", cho biết rằng người dùng có khả năng tương tác với mục đó.

Có một số nghiên cứu (Geng et al., 2022c; Luo et al., 2024) đã thử nghiệm LLM với tác vụ này, trong đó nhiều nghiên cứu (Li et al., 2023g; Dai et al., 2023; Liu et al., 2023a,b; Wang et al., 2023d; Li et al., 2023d) dựa trên ChatGPT. Vì người dùng có thể không để lại xếp hạng rõ ràng cho mỗi mục họ tương tác, tác vụ dự đoán xếp hạng có thể ít thực tế đối với các hệ thống thực tế. Thay vào đó, phản hồi ngầm, ví dụ nhấp chuột, dễ thu thập hơn. Do đó, cách suy luận sở thích của người dùng từ phản hồi ngầm như vậy thúc đẩy việc phát triển tác vụ gợi ý top-N.

### 4.2. Gợi ý Top-N

Tác vụ gợi ý top-N, còn gọi là xếp hạng, nhằm chọn N mục làm gợi ý cho một người dùng cho trước u. Để làm điều này, RS truyền thống thường tính một điểm số ˆru,i đối với mỗi mục i trong tập mục I. Sau khi lọc bỏ những mục mà người dùng đã tương tác, tức là Iu, các ứng viên hàng đầu có thể được chọn làm gợi ý từ các mục còn lại như Top(u, i) := arg maxN i∈I/Iu ˆru,i.

Tuy nhiên, do giới hạn độ dài ngữ cảnh của LLM, không thể đưa vào mô hình tất cả các mục. Kết quả là, cộng đồng đã khám phá hai phương pháp để giải quyết vấn đề này. Một là gợi ý trực tiếp (Xu et al., 2023b; Zhang et al., 2023b; Di Palma et al., 2023), sử dụng prompt chỉ chứa thông tin của người dùng (ví dụ, ID hoặc metadata) và yêu cầu LLM trực tiếp tạo gợi ý cho người dùng này. Thứ hai là gợi ý chọn lọc (Geng et al., 2022c, 2023; Li et al., 2023b; Hua et al., 2024; Petrov và Macdonald, 2023; Zhang et al., 2023c; Li et al., 2023f; Dai et al., 2023; Liu et al., 2023a,b; Wang et al., 2023d; Wang và Lim, 2023; Luo et al., 2024; Carraro và Bridge, 2024), cung cấp cả thông tin người dùng và danh sách các mục ứng viên Ic trong prompt và yêu cầu LLM chọn mục để gợi ý từ những ứng viên này. Danh sách ứng viên có thể bao gồm một mục thử nghiệm và một số mục tiêu cực được lấy mẫu. Sau khi điền người dùng và ứng viên vào prompt p(u,Ic), ví dụ, "chọn một mục để gợi ý cho user_1234 từ các ứng viên sau: item_6783, ..., item_9312, item_2834", LLM có thể tạo ra một ID mục (ví dụ, "9312") làm gợi ý. Khi kết hợp với tìm kiếm chùm, mô hình có thể tạo ra một số ID mục và do đó một danh sách N gợi ý.

Ngoài việc tạo ID mục, một số nghiên cứu gần đây (Li et al., 2023e) hướng dẫn LLM trả lời liệu người dùng có tương tác với một mục cho trước hay không bằng cách tạo "có" hoặc "không". Mặc dù câu trả lời "có" hoặc "không" được tạo bởi LLM, các phương pháp này có thể được coi là gợi ý phân biệt vì chúng cần tạo ra một câu trả lời hoặc một điểm số (ví dụ, xác suất của "có") cho mỗi mục.

### 4.3. Gợi ý Tuần tự

Tác vụ gợi ý tuần tự tiến thêm một bước so với gợi ý top-N với việc xem xét thời gian hoặc thứ tự tương tác. Cụ thể, mục tiêu của nó là dự đoán mục tiếp theo mà người dùng u có khả năng tương tác dựa trên các tương tác trong quá khứ của họ. Các mục được người dùng tương tác được sắp xếp theo thời gian theo timestamps của chúng, có thể được ký hiệu là Iu. Xem xét tính chất tuần tự của dữ liệu như vậy, các nhà nghiên cứu thường sử dụng các mô hình tuần tự để xử lý vấn đề, chẳng hạn như chuỗi Markov, mạng neural hồi quy (RNN), và Transformer (Vaswani et al., 2017). Một lần nữa, chúng ta có thể trước tiên điền người dùng và chuỗi mục vào prompt p(u, Iu), ví dụ, "cho lịch sử tương tác của user_1234 item_3456, ...,item_4567,item_5678, dự đoán mục tiếp theo mà người dùng sẽ tương tác", và sau đó prompt LLM để tạo ra ID mục làm dự đoán, ví dụ, "6789". Để giảm thời gian suy luận, chúng ta có thể cắt bỏ các mục tương đối cũ trước khi điền chuỗi mục vào prompt.

Đây là một vấn đề xu hướng, như được chứng minh bởi một số lượng đáng kể các mô hình dựa trên LLM (Geng et al., 2022c, 2023; Xu et al., 2023b; Li et al., 2023b; Petrov và Macdonald, 2023; Zhang et al., 2021; Hua et al., 2024, 2023b; Liu et al., 2023a,b; Zhang et al., 2023c; Wang et al., 2023d; Zheng et al., 2023). Đặc biệt, (Bao et al., 2023a; Lin et al., 2023b) tận dụng LLM để tạo ứng viên để lọc thêm trong khi (Yang et al., 2023; Hou et al., 2024; Ji et al., 2024; Liao et al., 2023; Luo et al., 2023) cung cấp cho LLM các mục ứng viên để gợi ý, và (Bao et al., 2023b; Lin et al., 2024; Zhang et al., 2023c) hướng dẫn LLM trả lời liệu người dùng có thích một mục cụ thể hay không.

### 4.4. Gợi ý Có thể Giải thích

Ngoài việc tạo gợi ý, các giải thích cho phép người dùng biết lý do đằng sau chúng cũng quan trọng không kém. Có nhiều phương pháp khác nhau để giải thích một gợi ý cho người dùng, chẳng hạn như các đặc trưng mục rõ ràng (Zhang et al., 2014) và các điểm nổi bật trực quan (Chen et al., 2019). Chúng tôi giới thiệu độc giả quan tâm đến khảo sát (Zhang et al., 2020b) để kiểm tra toàn diện về gợi ý có thể giải thích.

Một tác vụ giải thích gợi ý dựa trên LLM điển hình có thể là tạo giải thích ngôn ngữ tự nhiên. Tức là, cho một cặp người dùng u và mục i, chúng ta hướng dẫn mô hình tạo ra một câu hoặc đoạn văn bằng ngôn ngữ tự nhiên để giải thích tại sao i được gợi ý cho u. Các giải thích ground-truth có thể được khai thác từ đánh giá của người dùng (Li et al., 2020). Vì các đầu vào (tức là u và i) giống hệt với những đầu vào cho dự đoán xếp hạng, chúng ta có thể đặt chúng trong prompt p(u, i) để thông báo cho LLM rằng đây là tác vụ giải thích, ví dụ, "giải thích cho user_1234 tại sao item_5678 được gợi ý." Như một phản hồi, mô hình có thể tạo ra một giải thích như "Bộ phim này là hàng đầu." Tuy nhiên, việc chỉ sử dụng ID trong prompt có thể không rõ ràng về việc mô hình nên thảo luận những khía cạnh nào trong giải thích. Để giải quyết vấn đề này, chúng ta có thể cung cấp một số đặc trưng mục f như từ gợi ý trong prompt, ví dụ, "diễn xuất". Một prompt ví dụ p(u, i, f) cho tình huống như vậy có thể là "viết một giải thích cho user_1234 về item_5678 trên đặc trưng diễn xuất." Sau đó, LLM có thể tạo ra một giải thích như "Diễn xuất trong bộ phim này rất hấp dẫn."

(Geng et al., 2022c, 2023; Li et al., 2023b; Liu et al., 2023a,b; Wang et al., 2023d) thực hiện tác vụ tạo giải thích như trên; (Cui et al., 2022) kích hoạt tác vụ giải thích với từ khóa "bởi vì"; (Rahdari et al., 2024) áp dụng prompting chuỗi suy nghĩ với nhiều bước lý luận; (Li et al., 2023a) sử dụng các vector prompt liên tục thay vì các mẫu prompt rời rạc.

### 4.5. Tạo Đánh giá

Ngoài tạo giải thích, công thức trên cũng có thể được điều chỉnh cho tác vụ tạo đánh giá (Li và Tuzhilin, 2019), điều này có thể làm cho việc để lại nhận xét sau khi mua sản phẩm, xem phim, đi xe, v.v. trở nên dễ dàng và hiệu quả hơn cho người dùng. Dữ liệu kết quả sẽ lần lượt tạo điều kiện cho việc phát triển nghiên cứu liên quan đến gợi ý, chẳng hạn như gợi ý có thể giải thích và gợi ý đối thoại. Như thường lệ, chúng ta có thể điền người dùng và mục họ đã tương tác vào prompt p(u, i), ví dụ, "tạo một đánh giá cho user_1234 về item_5678." Sau đó, LLM có thể tạo ra một đoạn đánh giá. Ví dụ, "khách sạn nằm ở ...". Tuy nhiên, chúng tôi chưa nhận thấy bất kỳ nghiên cứu gợi ý dựa trên LLM nào về vấn đề này, có lẽ vì công thức quá giống với tạo giải thích, ngoại trừ việc đánh giá thường dài hơn.

### 4.6. Tóm tắt Đánh giá

Việc đọc một đánh giá dài có thể mất thời gian, điều mà người dùng có thể không luôn có khả năng chi trả. Một tóm tắt đánh giá rất ngắn gọn có thể giúp người dùng nhanh chóng hiểu ưu và nhược điểm của một mục. Các phương pháp tóm tắt đánh giá dựa trên LLM hiện tại (Geng et al., 2022c; Liu et al., 2023a,b; Wang et al., 2023d) chủ yếu nhắm đến cách tóm tắt đánh giá R của chính người dùng u cho một mục i, và coi tiêu đề đánh giá hoặc mẹo như tóm tắt. Trong trường hợp này, chúng ta có thể xây dựng prompt và điền dữ liệu ba ngôi vào p(u, i, R), ví dụ, "tóm tắt đánh giá sau mà user_1234 đã viết cho item_5678: khách sạn nằm ở ...". Sau đó, LLM có thể tạo ra một tóm tắt, ví dụ, "vị trí tuyệt vời".

Tuy nhiên, có thể không cần thiết phải tóm tắt đánh giá của người dùng vì người dùng đã biết về mục được đánh giá. Thay vào đó, việc tóm tắt đánh giá cho người dùng khác chưa bao giờ tương tác với mục có thể hữu ích hơn. Hơn nữa, việc thực hiện tóm tắt đa đánh giá tóm tắt ý kiến của những người dùng khác nhau về cùng một mục cũng có ý nghĩa.

### 4.7. Gợi ý Đối thoại

Mục tiêu của gợi ý đối thoại là gợi ý cho người dùng một số mục trong nhiều vòng hội thoại (Jannach et al., 2021; Sun và Zhang, 2018; Zhang et al., 2018). Khác với RS truyền thống chủ yếu dựa vào các tương tác lịch sử của người dùng, trong môi trường đối thoại người dùng có thể tự do phát biểu sở thích của họ bằng ngôn ngữ tự nhiên và thậm chí cung cấp phản hồi tiêu cực, ví dụ từ chối một gợi ý. Tuy nhiên, cộng đồng nghiên cứu vẫn đang trong quá trình đạt được sự đồng thuận về cách công thức hóa tác vụ này.

(Cui et al., 2022; Friedman et al., 2023; He et al., 2023) áp dụng hai nhãn (tức là "USER" và "SYSTEM") để đánh dấu người nói của một phát ngôn trước khi đưa một phiên đối thoại vào LLM để tạo ra phản hồi. (Huang et al., 2023) hướng dẫn LLM gọi các công cụ, chẳng hạn như bộ gợi ý truyền thống và SQL, để thu hẹp các mục ứng viên để gợi ý. (Lin và Zhang, 2023) trực tiếp trò chuyện với ChatGPT, vì họ nhằm thiết lập các nguyên tắc cho gợi ý đối thoại, ví dụ cơ chế bộ nhớ và cơ chế sửa chữa, thay vì phát triển các mô hình mới. Để đánh giá, (Wang et al., 2023c) chỉ ra vấn đề của các giao thức hiện tại. Cụ thể, mặc dù khả năng trò chuyện của ChatGPT không thể phủ nhận là ấn tượng, hiệu suất của nó trên các chỉ số hiện có không tốt lắm vì chúng quá nhấn mạnh vào sự khớp giữa các phản hồi được tạo và các gợi ý hoặc phát ngôn được chú thích.

### 4.8. Giao thức Đánh giá

Để đánh giá hiệu suất của LLM trên các tác vụ này, chúng ta có thể áp dụng các chỉ số hiện có. Đối với dự đoán xếp hạng, sai số bình phương trung bình căn (RMSE) và sai số tuyệt đối trung bình (MAE) thường được sử dụng. Đối với hai tác vụ gợi ý khác, tức là gợi ý top-N và gợi ý tuần tự, chúng ta có thể sử dụng các chỉ số hướng xếp hạng, chẳng hạn như đạt được tích lũy chiết khấu chuẩn hóa (NDCG), độ chính xác và độ nhạy. Ngoài đánh giá offline, các thử nghiệm A/B trực tuyến cũng có thể được áp dụng vì chúng có thể phản ánh các tương tác thực tế của người dùng với các mục được gợi ý.

Đối với các tác vụ tạo ngôn ngữ tự nhiên, bao gồm tạo giải thích, tạo đánh giá, tóm tắt đánh giá và gợi ý đối thoại, chất lượng tạo sinh của LLM có thể được ước tính với BLEU (Papineni et al., 2002) trong dịch máy và ROUGE (Lin, 2004) trong tóm tắt văn bản. Cả hai chỉ số đều đo mức độ khớp giữa các đoạn văn bản của nội dung được tạo và những đoạn của ground-truth. Tuy nhiên, như được chỉ ra bởi (Wang et al., 2023c), việc quá nhấn mạnh vào sự khớp với dữ liệu được chú thích có thể có vấn đề. Ngoài ra, còn có những khía cạnh khác ngoài độ tương tự văn bản mà không thể được phản ánh bởi BLEU hoặc ROUGE. Như một nỗ lực sớm, (Li et al., 2020) đã đề xuất một số chỉ số như tỷ lệ bao phủ đặc trưng và đa dạng đặc trưng có tính đến các đặc điểm của các yếu tố rõ ràng để đánh giá giải thích, nhưng chúng vẫn còn thô sơ. Mặc dù có một số chỉ số dựa trên học máy khác, ví dụ BERTScore (Zhang et al., 2020a), các chỉ số tiên tiến và chuẩn hơn cần được phát triển. Ngoài đánh giá tự động, chúng ta cũng có thể tiến hành đánh giá của con người để đo lường LLM trên các tác vụ tạo sinh này. Tuy nhiên, điều này đòi hỏi các nhà nghiên cứu phải thiết kế bảng câu hỏi phù hợp và số lượng người tham gia có thể bị hạn chế.

## 5. Thách thức và Cơ hội

Trong phần này, chúng tôi thảo luận về các thách thức nghiên cứu và cơ hội cho gợi ý tạo sinh trong kỷ nguyên LLM, đặc biệt là những vấn đề quan trọng cần được chăm sóc khẩn cấp.

### 5.1. Tác nhân dựa trên LLM

Các bộ mô phỏng đã đóng vai trò quan trọng trong việc giải quyết vấn đề khan hiếm dữ liệu trong RS, đặc biệt trong môi trường gợi ý đối thoại nơi dữ liệu tương tác ground-truth thường không có sẵn (Yu et al., 2023). Gần đây, chúng ta đã thấy rằng các tác nhân tạo sinh dựa trên LLM có thể mô phỏng gần như bất kỳ tình huống nào, chẳng hạn như một xã hội nhỏ (Park et al., 2023) hoặc chiến tranh thế giới (Hua et al., 2023a). Cũng xuất hiện các bộ mô phỏng hành vi người dùng cho RS (Wang et al., 2023a; Zhang et al., 2023a). Tuy nhiên, một nghịch lý xuất hiện khi áp dụng bộ mô phỏng cho RS. Một mặt, nếu dữ liệu tương tác được mô phỏng bởi bộ mô phỏng không phù hợp với sở thích thực sự của người dùng đích, thì dữ liệu được mô phỏng có thể không thực sự hữu ích. Mặt khác, nếu bộ mô phỏng có thể mô phỏng hoàn hảo sở thích của người dùng, thì chúng ta có thể không cần thuật toán gợi ý nào cả vì dữ liệu được mô phỏng có thể được áp dụng trực tiếp làm gợi ý.

Chúng tôi tin rằng tiềm năng của các tác nhân dựa trên LLM cho RS vượt ra ngoài việc mô phỏng đơn giản. Ngày nay, chúng có thể gọi các công cụ, API và các mô hình chuyên gia để giải quyết các tác vụ phức tạp mất vài bước lý luận (Ge et al., 2024). Khả năng như vậy có thể đẩy RS dựa trên LLM đến một phạm vi rộng hơn của các ứng dụng thực tế. Lấy gợi ý du lịch làm ví dụ, hệ thống có thể phục vụ nhu cầu cá nhân hóa của người dùng, chẳng hạn như thời gian, ngân sách và các điểm tham quan ưa thích, và soạn thảo một lịch trình bằng cách tra cứu thông tin thời gian thực, chẳng hạn như giờ mở cửa của các điểm tham quan và thời gian di chuyển từ điểm tham quan này đến điểm tham quan khác. Khi hệ thống như vậy được nhúng trong xe (Luettin et al., 2019), nó thậm chí có thể định tuyến cho tài xế bằng cách gọi API bản đồ, và cũng gợi ý các dịch vụ ngoài xe, chẳng hạn như nhà hàng và trạm sạc/xăng. Bất kể tình huống nào, đôi khi người dùng có thể không thể theo lịch trình, và trong trường hợp này hệ thống có thể sửa đổi động để phù hợp với tình trạng hiện tại của người dùng. Bằng cách kết nối với các đối tượng thực tế, thế hệ RS mới này có tiềm năng thay đổi cách mọi người sống.

### 5.2. Ảo giác

Ảo giác (Azamfirei et al., 2023) có nghĩa là nội dung được tạo bởi LLM có thể lệch khỏi sự thật. Ảo giác là một vấn đề quan trọng trong LLM cũng như các ứng dụng của chúng. Đặc biệt, đối với RS dựa trên LLM, chúng ta cần đảm bảo rằng các mục được gợi ý cho người dùng tồn tại, nếu không có thể gây ra sự không hài lòng và thất vọng của người dùng và thậm chí làm giảm việc người dùng áp dụng hệ thống trong đời thực. Ví dụ, một người dùng có thể dành thời gian đi đến một nhà hàng được gợi ý, chỉ để phát hiện ra rằng nhà hàng như vậy hoàn toàn không tồn tại. Đặc biệt, trong các lĩnh vực gợi ý có cược cao như gợi ý thuốc, gợi ý điều trị y tế và gợi ý đầu tư tài chính, các gợi ý ảo giác có thể gây ra tổn thất nghiêm trọng cho người dùng.

Có hai phương pháp có thể để giải quyết vấn đề ảo giác trong RS dựa trên LLM. Một là sử dụng ID mục được thiết kế tỉ mỉ để tạo sinh. Ví dụ, (Hua et al., 2023b) tạo ID mục và tổ chức chúng thành cấu trúc cây tiền tố, còn được gọi là cấu trúc trie. Miễn là quá trình tạo sinh tìm kiếm chùm theo các đường dẫn từ gốc đến lá trong cây, các mục được tạo sẽ luôn tồn tại. Phương pháp khác là áp dụng tăng cường truy xuất trên LLM (Mialon et al., 2023), tức là điều kiện hóa LLM trên các mục được truy xuất, để các mục được gợi ý khớp với những mục trong cơ sở dữ liệu mục. Hơn nữa, hai phương pháp, tức là chỉ mục và truy xuất, có thể được tích hợp để giải quyết vấn đề ảo giác một cách hiệu quả và hiệu suất.

### 5.3. Thiên vị và Công bằng

Có thể có hai loại thiên vị cho RS dựa trên LLM, đó là thiên vị nội dung và thiên vị gợi ý. Loại trước đề cập đến thiên vị có thể được quan sát trực tiếp trong nội dung được tạo. Một ví dụ điển hình là thiên vị giới tính. (Wang et al., 2023b) phát hiện ra rằng các giải thích gợi ý được tạo bằng máy cho người dùng nam thường dài hơn so với những giải thích cho người dùng nữ trong lĩnh vực game. Vấn đề này có thể nằm trong dữ liệu huấn luyện được điều chỉnh từ đánh giá người dùng về game. Ngoài ra, một LLM được huấn luyện với một lượng lớn dữ liệu do con người tạo có thể lặp lại hoặc thậm chí củng cố thiên vị ẩn trong dữ liệu. Lấy thiên vị ngôn ngữ làm ví dụ, (Zhang et al., 2021) quan sát rằng LLM có xu hướng sử dụng các token chung khi tạo tiêu đề mục để làm cho chúng trông trôi chảy và nghe có vẻ ngôn ngữ, nhưng dẫn đến các gợi ý rất khác với các mục ưa thích của người dùng. Khi được điều chỉnh cho các tác vụ gợi ý downstream, thiên vị nên được giảm thiểu hoặc thậm chí loại bỏ hoàn toàn để ngăn chặn sự lan truyền của các tác động tiêu cực và để cải thiện trải nghiệm người dùng.

Về thiên vị gợi ý, (Li et al., 2023f) báo cáo rằng ChatGPT có xu hướng gợi ý các bài báo từ các nhà cung cấp mà nó gắn nhãn là phổ biến. (Xu et al., 2023a) quan sát sự khác biệt lĩnh vực khi yêu cầu ChatGPT gợi ý bài báo và việc làm cho các bản sắc giới tính và chủng tộc khác nhau. Tương tự, (Zhang et al., 2023b) phát hiện ra rằng các gợi ý âm nhạc do ChatGPT đưa ra cho những người có thuộc tính nhân khẩu học khác nhau (ví dụ, người da trắng so với người Mỹ gốc Phi) là không giống nhau. Mặc dù kết quả trông có vẻ thiên vị, chúng cũng có thể là một loại cá nhân hóa vì thị hiếu âm nhạc của những người trong các nền tảng văn hóa khác nhau có thể khác nhau. Do đó, một câu hỏi cần được trả lời: Ranh giới giữa thiên vị và cá nhân hóa là gì? (Hua et al., 2024) cố gắng làm cho các mô hình gợi ý dựa trên LLM công bằng về các thuộc tính nhạy cảm, chẳng hạn như tuổi, tình trạng hôn nhân và nghề nghiệp, bằng cách chưng cất thiên vị thành các prompt liên tục. Vì các vấn đề thiên vị và công bằng vẫn là những vấn đề mở, cần làm thêm nhiều công việc, ví dụ từ góc độ định nghĩa công bằng và giảm thiểu thiên vị cho RS dựa trên LLM.

### 5.4. Minh bạch và Khả năng Giải thích

Việc làm cho các gợi ý minh bạch và có thể giải thích cho người dùng luôn là một vấn đề quan trọng đối với RS và AI nói chung (Zhang et al., 2020b). Do kích thước khổng lồ và độ phức tạp của LLM, việc giải thích các gợi ý dựa trên LLM đã đặt ra những thách thức mới cho cộng đồng. Có hai loại khả năng giải thích cho RS dựa trên LLM. Một là tạo ra các giải thích ngôn ngữ tự nhiên hợp lý cho các mục được gợi ý, trong khi loại khác là đi sâu vào mô hình và cố gắng giải thích cơ chế hoạt động nội bộ của LLM. Trong khi các nhà nghiên cứu đã khám phá loại khả năng giải thích đầu tiên trong một thời gian (Li et al., 2021, 2023a,b; Geng et al., 2022c, 2023; Cui et al., 2022), loại khả năng giải thích thứ hai phần lớn chưa được khám phá. Một phương pháp có thể là căn chỉnh LLM như các prompt của nó với một cơ sở tri thức rõ ràng như đồ thị tri thức (Geng et al., 2022b; Ye et al., 2024) để quá trình ra quyết định của mô hình được căn chỉnh với các đường dẫn rõ ràng trong đồ thị tri thức để giải thích. Tuy nhiên, hướng này nói chung rất sơ khai và đòi hỏi các phương pháp đổi mới và ý tưởng mới táo bạo từ cộng đồng.

### 5.5. Khả năng Kiểm soát

Khả năng kiểm soát là một vấn đề quan trọng đối với LLM vì chúng ta thường không thể kiểm soát chính xác đầu ra của LLM. Việc thiếu khả năng kiểm soát có thể gây ra các vấn đề nghiêm trọng. Ví dụ, một LLM có thể tạo ra nội dung quấy rối, nội dung giả mạo hoặc nội dung lệch khỏi các tiêu chuẩn đạo đức cơ bản. Đối với RS, vấn đề khả năng kiểm soát phức tạp hơn do các tác vụ hoặc tình huống gợi ý khác nhau đòi hỏi khả năng kiểm soát (Tan et al., 2023; Wang et al., 2022; Schafer et al., 2002; Parra và Brusilovsky, 2015). Ví dụ, người dùng có thể muốn kiểm soát đặc trưng mà một giải thích nói về (Li et al., 2021, 2020; Geng et al., 2022c), ví dụ, nếu người dùng quan tâm đến "giá" của một nhà hàng, thì giải thích nên nói về giá của nó, trong khi nếu người dùng quan tâm đến "khoảng cách", thì giải thích nên thảo luận về khoảng cách. Ngoài khả năng kiểm soát của giải thích, người dùng cũng có thể muốn kiểm soát các đặc trưng của các mục được gợi ý, chẳng hạn như mức giá, màu sắc và thương hiệu (Tan et al., 2023). Ví dụ, người dùng có thể hy vọng rằng LLM chỉ gợi ý các mục nằm trong một phạm vi giá nhất định. Mặc dù các đặc trưng này có thể được bao gồm trong prompt để kích hoạt tạo sinh của LLM, các gợi ý do LLM cung cấp vẫn có thể không đáp ứng yêu cầu của người dùng. Nghiên cứu hiện tại về khả năng kiểm soát gợi ý dựa trên LLM chủ yếu tập trung vào việc kiểm soát các giải thích (Li et al., 2021, 2023a; Geng et al., 2022c), trong khi cần thiết khẩn cấp nhiều nghiên cứu hơn về việc kiểm soát các gợi ý được tạo bởi LLM.

### 5.6. Hiệu quả Suy luận

Vì LLM chứa một lượng lớn tham số và RS là một ứng dụng nhạy cảm với độ trễ, hiệu quả của các mô hình gợi ý dựa trên LLM là rất quan trọng. Hiệu quả huấn luyện có thể được cải thiện bằng cách điều chỉnh tùy chọn (Cui et al., 2022) hoặc điều chỉnh adapter (Geng et al., 2023). Để giảm thời gian huấn luyện của LLM, (Li et al., 2023b) đề xuất một chiến lược huấn luyện luân phiên tác vụ để xử lý nhiều tác vụ gợi ý. Vì hiệu quả huấn luyện của LLM có thể được cải thiện trong môi trường offline và thường LLM không phải được huấn luyện lại quá thường xuyên, nó không quan trọng bằng vấn đề hiệu quả suy luận. (Cui et al., 2022) tính toán trước một vài lớp đầu của LLM và cache kết quả để cải thiện hiệu quả suy luận của nó. Tuy nhiên, chiến lược này có thể chỉ áp dụng cho một kiến trúc LLM cụ thể đại diện cho người dùng và mục với metadata. (Li et al., 2023b) quan sát rằng thời gian suy luận của LLM có thể được giảm nhẹ khi prompt rời rạc được loại bỏ. Tóm lại, vẫn còn nhiều chỗ để cải thiện thêm hiệu quả suy luận của các mô hình gợi ý dựa trên LLM.

### 5.7. Gợi ý Đa phương thức

Ngoài văn bản, dữ liệu của các phương thức khác cũng có thể được tận dụng bởi LLM, miễn là chúng có thể được biểu diễn như một chuỗi token có thể được tích hợp vào các câu văn bản, như trong trường hợp của DALL·E (Ramesh et al., 2021) và Sora². Ví dụ, (Geng et al., 2023) kết hợp hình ảnh mục vào LLM để cải thiện hiệu suất của nó trên các tác vụ gợi ý. Về tạo hình ảnh, (Geng et al., 2022a) tạo ra các giải thích trực quan cho gợi ý dựa trên mô hình thị giác-ngôn ngữ, và (Cui et al., 2022) tổng hợp hình ảnh cho thiết kế sản phẩm. Ngoài hình ảnh, video và âm thanh cũng có thể được tạo theo cách tự hồi quy (Rubenstein et al., 2023; Yan et al., 2021), làm cho gợi ý đa phương thức dựa trên LLM trở thành một hướng đầy triển vọng, chẳng hạn như gợi ý video ngắn và gợi ý âm nhạc. Hơn nữa, khi không có mục có sẵn phục vụ sở thích của người dùng trong kho mục, hệ thống có thể tạo ra các mục mới, đặc biệt cho gợi ý thời trang, ví dụ quần áo. Ngay cả khi các mục được tạo không hoàn toàn đáp ứng yêu cầu của người dùng, chúng có thể được sử dụng để truy xuất các mục tương tự hiện có hoặc khơi dậy sự sáng tạo của các nhà thiết kế để cải thiện thiết kế. Trong khi đó, các nhà phát triển mô hình nên đảm bảo tính xác thực của nội dung được tạo bằng máy để ngăn người dùng có trải nghiệm tiêu cực, ví dụ như một bức ảnh của một điểm tham quan Hawaii được chú thích là Hàn Quốc cho gợi ý du lịch.

### 5.8. Gợi ý Cold-start

Vì LLM đã học được tri thức thế giới trong giai đoạn tiền huấn luyện, chúng có thể thực hiện các tác vụ gợi ý ngay cả khi chúng không được tinh chỉnh trên các tập dữ liệu cụ thể về gợi ý. Một ví dụ điển hình là ChatGPT, có thể được hướng dẫn để thực hiện các tác vụ gợi ý khác nhau như đã thảo luận trong phần trước (Liu et al., 2023a). Lý do cơ bản là sở thích của người dùng và thuộc tính của mục có thể được biểu đạt bằng ngôn ngữ tự nhiên. Kết quả là, các mô hình gợi ý dựa trên LLM có tiềm năng giảm thiểu vấn đề cold-start nổi tiếng nơi có ít hoặc thậm chí không có tương tác liên quan đến người dùng hoặc mục mới. Mặc dù dữ liệu tương tác không đủ, chúng ta vẫn có thể sử dụng metadata của chúng để gợi ý, chẳng hạn như thông tin nhân khẩu học người dùng và thông tin mô tả mục.

## 6. Kết luận

Trong khảo sát này, chúng tôi đã xem xét tiến trình gần đây của gợi ý tạo sinh dựa trên LLM và cung cấp một công thức tổng quát cho mỗi tác vụ gợi ý tạo sinh theo nghiên cứu liên quan. Để khuyến khích các nhà nghiên cứu khám phá hướng đầy triển vọng này, chúng tôi đã trình bày chi tiết các ưu điểm của nó so với RS truyền thống, tổng quát hóa định nghĩa về ID và tóm tắt các phương pháp tạo ID khác nhau. Chúng tôi cũng đã chỉ ra một số triển vọng có thể đáng để khám phá sâu. Chúng tôi dự đoán một tương lai nơi LLM và RS sẽ được tích hợp đẹp để tạo ra các dịch vụ cá nhân hóa chất lượng cao trong các tình huống khác nhau.

## 7. Lời cảm ơn

Công việc này được hỗ trợ bởi dự án IG-FNRA của Đại học Baptist Hong Kong (RC-FNRA-IG/21-22/SCI/01) và Chương trình Học bổng Nghiên cứu sau Tiến sĩ của Hội đồng Tài trợ Nghiên cứu Hong Kong (RGC) (PDFS2223-2S02), và được hỗ trợ một phần bởi NSF IIS-1910154, 2007907, và 2046457. Bất kỳ ý kiến, phát hiện, kết luận hoặc khuyến nghị nào được thể hiện trong tài liệu này đều thuộc về các tác giả và không nhất thiết phản ánh quan điểm của các nhà tài trợ.

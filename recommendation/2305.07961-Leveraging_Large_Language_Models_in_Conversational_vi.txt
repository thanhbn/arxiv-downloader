# 2305.07961.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/recommendation/2305.07961.pdf
# Kích thước file: 15988796 bytes

===============================================
NỘI DUNG FILE PDF
===============================================


--- TRANG 1 ---
Tận dụng các Mô hình Ngôn ngữ Lớn trong Hệ thống Đề xuất Hội thoại
Luke Friedman*, Sameer Ahuja, David Allen, Zhenning Tan, Hakim Sidahmed, Changbo Long, Jun
Xie, Gabriel Schubiner, Ajay Patel, Harsh Lara, Brian Chu, Zexi Chen và Manoj Tiwari
Google Research
TÓM TẮT
Hệ thống Đề xuất Hội thoại (CRS) mang lại sự minh bạch và kiểm soát gia tăng cho người dùng bằng cách cho phép họ tương tác với hệ thống thông qua cuộc đối thoại đa lượt theo thời gian thực. Gần đây, các Mô hình Ngôn ngữ Lớn (LLM) đã thể hiện khả năng chưa từng có trong việc đối thoại tự nhiên và kết hợp kiến thức thế giới cùng lý luận thường thức vào hiểu biết ngôn ngữ, mở khóa tiềm năng của mô hình này. Tuy nhiên, việc tận dụng hiệu quả LLM trong CRS đưa ra những thách thức kỹ thuật mới, bao gồm hiểu và kiểm soát đúng cách một cuộc hội thoại phức tạp và truy xuất từ các nguồn thông tin bên ngoài. Những vấn đề này được làm trầm trọng thêm bởi một kho mục lớn, không ngừng phát triển và thiếu dữ liệu hội thoại để đào tạo. Trong bài báo này, chúng tôi cung cấp một lộ trình để xây dựng CRS quy mô lớn end-to-end sử dụng LLM. Cụ thể, chúng tôi đề xuất các triển khai mới cho việc hiểu sở thích người dùng, quản lý đối thoại linh hoạt và các đề xuất có thể giải thích như một phần của kiến trúc tích hợp được hỗ trợ bởi LLM. Để cải thiện cá nhân hóa, chúng tôi mô tả cách một LLM có thể sử dụng các hồ sơ người dùng ngôn ngữ tự nhiên có thể hiểu được và sử dụng chúng để điều chỉnh ngữ cảnh cấp phiên. Để khắc phục các hạn chế dữ liệu hội thoại khi không có CRS sản xuất hiện có, chúng tôi đề xuất các kỹ thuật để xây dựng một trình mô phỏng người dùng dựa trên LLM có thể kiểm soát để tạo ra các cuộc hội thoại tổng hợp. Như một bằng chứng khái niệm, chúng tôi giới thiệu RecLLM, một CRS quy mô lớn cho video YouTube được xây dựng trên LaMDA, và chứng minh tính trôi chảy và chức năng đa dạng của nó thông qua một số cuộc hội thoại minh họa ví dụ.

1 GIỚI THIỆU
Hệ thống đề xuất là một trong những câu chuyện thành công nổi bật nhất của học máy trong ngành công nghiệp, cung cấp nội dung cá nhân hóa cho hàng tỷ người dùng trên nhiều lĩnh vực như Tìm kiếm, Video, Tin tức và Mua sắm. Các thuật toán học máy đã biến đổi cách xây dựng những hệ thống này trong ngành; đặc biệt, trong thập kỷ qua, các hệ thống dựa trên học sâu phát triển mạnh trong chế độ dữ liệu lớn đã tận dụng sự dồi dào của dữ liệu tương tác người dùng có sẵn thông qua các sản phẩm để học các mối tương quan thống kê phức tạp và tối ưu hóa tốt hơn cho các chỉ số tương tác chính [17]. Tuy nhiên, bất chấp sự thành công của ML trong bối cảnh này, sự phụ thuộc ngày càng tăng vào các tín hiệu tương tác ngầm như nhấp chuột như một đại diện cho sở thích người dùng cũng có những nhược điểm. Đã được ghi nhận rằng nhiều hệ thống đề xuất quy mô lớn hiện đại gặp phải các vấn đề như hiển thị clickbait, truyền bá thành kiến xã hội và phân cực cơ sở người dùng [25,55,104]. Hệ thống đề xuất dựa trên giao diện point-and-click cũng chỉ cung cấp cho người dùng một kênh hạn chế để giao tiếp với hệ thống và ít cơ hội tham gia vào bất kỳ loại khám phá tương tác nào.

*Tác giả liên hệ: lbfried@google.com.Hệ thống Đề xuất Hội thoại (CRS) mang lại cho người dùng nhiều quyền kiểm soát hơn đối với các đề xuất của họ thông qua khả năng tham gia vào cuộc đối thoại đa lượt theo thời gian thực [22,37]. Điều này cho phép hệ thống chủ động truy vấn người dùng thay vì chỉ dựa vào hành vi trước đó để suy đoán sở thích, và đáp lại người dùng có thể cung cấp phản hồi và tinh chỉnh các gợi ý qua một loạt lượt. Mô hình mới này là một tổng quát hóa của cả hệ thống đề xuất và tìm kiếm cổ điển, trong đó thông thường người dùng chỉ đạo hệ thống thông qua một truy vấn một lần. Bây giờ hệ thống phải khám phá một cách hợp tác với người dùng và, để duy trì luồng tự nhiên, đôi khi thậm chí rẽ sang các chế độ tiếp tuyến với nhiệm vụ đề xuất cốt lõi như trò chuyện không hướng và trả lời câu hỏi (xem ví dụ [9]). Thường xuyên CRS cũng phải đa phương thức, ví dụ hiển thị các bảng đề xuất trong giao diện người dùng trực quan trong khi đồng thời tiến hành cuộc hội thoại thông qua giao diện ngôn ngữ tự nhiên (xem ví dụ [112]).

Mặc dù hệ thống đề xuất hội thoại đã tồn tại dưới một số hình thức trong nhiều thập kỷ [51,85], sự bùng nổ gần đây của các Mô hình Ngôn ngữ Lớn (LLM) [6,15,86] mở ra những cơ hội mới. LLM đã tạo ra một bước nhảy vọt lớn trong khả năng của máy móc đối thoại theo cách giống con người và có thể cung cấp năng lượng cho giao diện ngôn ngữ tự nhiên giữa người dùng và hệ thống. LLM cũng đã cho thấy khả năng chưa từng có trong việc khai thác kiến thức thế giới chung và sử dụng một mức độ lý luận thường thức [34], có thể được khai thác theo nhiều cách khác nhau trong CRS. Ví dụ, chúng ta có thể cố gắng sử dụng LLM để trực tiếp lý luận về mức độ phù hợp của một mục với bối cảnh của cuộc hội thoại trong một mô-đun xếp hạng và tạo ra một lời giải thích ngôn ngữ tự nhiên trực quan như một sản phẩm phụ. Các trường hợp sử dụng khả thi khác cho LLM đằng sau hậu trường bao gồm quản lý đối thoại, kết hợp hồ sơ người dùng ngôn ngữ tự nhiên để cá nhân hóa tốt hơn và xây dựng các trình mô phỏng người dùng thực tế để tạo dữ liệu tổng hợp quy mô lớn cho việc đánh giá và điều chỉnh các thành phần hệ thống.

Mặc dù LLM hấp dẫn như một công cụ cho CRS, nhưng các thách thức kỹ thuật mới phải được khắc phục để tận dụng chúng một cách hiệu quả. Ví dụ, LLM dễ bị ảo giác và việc đặt cơ sở cho chúng vẫn là một vấn đề chưa được giải quyết phần lớn [40]. Ngoài ra, một trong những điểm hấp dẫn của LLM là cảm giác tự nhiên và không thể dự đoán của chúng, nhưng khi hoạt động trong môi trường hướng đến nhiệm vụ, điều này có nghĩa là việc kiểm soát LLM có thể khó khăn hơn so với hệ thống dựa trên mẫu. Đặc biệt thách thức trong bối cảnh đề xuất là cách giao tiếp giữa LLM và động cơ đề xuất cơ bản. Một cách tiếp cận là để LLM là động cơ đề xuất ngoài vai trò là tác nhân đối thoại (xem ví dụ [42]). Tuy nhiên, đối với các ứng dụng đề xuất quy mô lớn, kho mục có thể chứa hàng triệu hoặc hàng tỷ mục luôn thay đổi, khiến cho việc LLM ghi nhớ kho mục trong các tham số của nó trở nên thách thức. Thay vào đó, LLM phải kết nối với động cơ đề xuất hoặc cơ sở dữ liệu bên ngoài, truyền thông tin sở thích có liên quan.

--- TRANG 2 ---
giải thích 
đề xuất 
yêu cầu Hình 1: Tổng quan về các đóng góp chính từ RecLLM. (1) Một mô-đun quản lý đối thoại sử dụng LLM để hội thoại với người dùng, theo dõi ngữ cảnh và thực hiện các cuộc gọi hệ thống như gửi yêu cầu đến động cơ đề xuất tất cả như một nhiệm vụ mô hình hóa ngôn ngữ thống nhất. (2) Các giải pháp khác nhau được trình bày cho việc truy xuất có thể xử lý trên kho mục lớn trong CRS dựa trên LLM. (3) Một mô-đun xếp hạng sử dụng LLM để khớp sở thích được trích xuất từ ngữ cảnh của cuộc hội thoại với siêu dữ liệu mục và tạo ra một bảng đề xuất được hiển thị cho người dùng. LLM cũng đồng thời tạo ra các lời giải thích cho các quyết định của nó có thể được hiển thị cho người dùng. (4) Hồ sơ người dùng ngôn ngữ tự nhiên có thể hiểu được được các LLM hệ thống sử dụng để điều chỉnh ngữ cảnh cấp phiên và tăng cá nhân hóa. (5) Một trình mô phỏng người dùng dựa trên LLM có thể kiểm soát có thể được kết nối vào CRS để tạo ra các cuộc hội thoại tổng hợp cho việc điều chỉnh các mô-đun hệ thống.

Mặc dù được nghiên cứu gần đây [8,73], cách tiếp cận này vẫn chưa được giải quyết trong bối cảnh đề xuất quy mô lớn tổng quát.

Trong bài báo này, chúng tôi cung cấp một lộ trình để tận dụng LLM theo nhiều cách khác nhau để xây dựng CRS quy mô lớn có thể kiểm soát và giải thích được. Các đóng góp chính của đề xuất là:

• Một mô-đun quản lý đối thoại tái định nghĩa việc tạo ngôn ngữ tự nhiên, hiểu sở thích, theo dõi ngữ cảnh và các cuộc gọi đến động cơ đề xuất như một nhiệm vụ mô hình hóa ngôn ngữ thống nhất được thực hiện bởi một LLM duy nhất.

• Một khung khái niệm tổng quát để thực hiện truy xuất với LLM trên kho mục khổng lồ. Các giải pháp khác nhau được trình bày tùy thuộc vào yêu cầu hiệu quả và dữ liệu cũng như API bên ngoài có sẵn.

• Một mô-đun xếp hạng / giải thích kết hợp sử dụng LLM để trích xuất sở thích người dùng từ cuộc hội thoại đang diễn ra và khớp chúng với các tạo phẩm văn bản được tổng hợp từ siêu dữ liệu mục. Như một sản phẩm phụ của lý luận chuỗi suy nghĩ trung gian [95], LLM tạo ra các lý giải ngôn ngữ tự nhiên cho mỗi mục được hiển thị cho người dùng, tăng tính minh bạch của hệ thống.

• Kết hợp hồ sơ người dùng ngôn ngữ tự nhiên bền vững, có thể hiểu được như đầu vào bổ sung cho các LLM hệ thống, bổ sung ngữ cảnh cấp phiên và cải thiện trải nghiệm cá nhân hóa.

• Các kỹ thuật để xây dựng trình mô phỏng người dùng dựa trên LLM có thể kiểm soát có thể được sử dụng để tạo ra các cuộc hội thoại tổng hợp cho việc điều chỉnh các mô-đun hệ thống.

Như một bằng chứng khái niệm, chúng tôi giới thiệu RecLLM, một CRS dựa trên LLM cho video YouTube được hỗ trợ bởi LaMDA [86], và chia sẻ một số cuộc hội thoại ví dụ cho thấy tính trôi chảy và chức năng đa dạng của hệ thống. Mục tiêu của chúng tôi là đưa ra một lập luận thuyết phục về lời hứa và tính khả thi của hệ thống đề xuất hội thoại dựa trên LLM và tiến một bước đầu tiên hướng tới việc hiện thực hóa tầm nhìn này trong thực tế.

2 PHẠM VI VẤN ĐỀ

Hình 2: Ảnh chụp màn hình của một trình mô phỏng người dùng dựa trên LLM đang nói chuyện với RecLLM.

Trong RecLLM, chúng tôi biểu diễn CRS trong thiết lập đa phương thức bao gồm hai thành phần: Một bảng đề xuất và một cuộc hội thoại đang diễn ra giữa người dùng và tác nhân hội thoại (xem Hình 2). Người dùng xuất ra một thông điệp ngôn ngữ tự nhiên trong lượt của họ, và tác nhân phản hồi bằng một thông điệp ngôn ngữ tự nhiên, tùy chọn cập nhật bảng đề xuất dựa trên cuộc hội thoại. Bằng cách tách biệt đối thoại khỏi bảng đề xuất, chúng tôi hy vọng phản ánh chính xác hơn cách một CRS quy mô lớn cuối cùng sẽ trông như thế nào trong môi trường sản xuất.

Theo truyền thống, người dùng đã tương tác với hệ thống đề xuất thông qua các tương tác giao diện người dùng như xem các mục được đề xuất hoặc đánh dấu các đề xuất là tốt hoặc xấu thông qua các widget giao diện [20,76]. Mặc dù hiện tại trong RecLLM chúng tôi loại trừ những loại tương tác này, chúng tôi không có ý định thay thế chúng; mục tiêu cuối cùng của chúng tôi là bổ sung chúng với kênh biểu đạt hơn của ngôn ngữ tự nhiên cho phép người dùng thể hiện tốt hơn sắc thái về sở thích của họ.

Về mặt kho mục, RecLLM đề xuất từ kho tất cả video YouTube công khai. Chúng tôi lựa chọn này do hai đặc điểm tăng khả năng áp dụng của hệ thống cho các vấn đề thực tế khác: Một, không giống như kho các mục xuất hiện thường xuyên trong dữ liệu đào tạo của LLM (ví dụ, phim và nhạc phổ biến), LLM không thể khả thi được sử dụng để trực tiếp đề xuất video YouTube và phải giao tiếp với kho. Thứ hai, đó là một kho quy mô lớn, đòi hỏi một cách tiếp cận có thể mở rộng đối với các đề xuất. Một hệ quả tự nhiên của việc xây dựng một hệ thống như vậy từ đầu là không có nhật ký người dùng tương tác với hệ thống này để khởi động đào tạo mô hình. Mặc dù RecLLM tập trung vào video YouTube, ý định của chúng tôi trong bài báo này là phác thảo một cách tiếp cận tổng quát có thể dễ dàng mở rộng sang nhiều lĩnh vực khác.

Trong khi đánh giá với những người thử nghiệm ban đầu, chúng tôi phát hiện rằng người dùng mong đợi CRS kết hợp đề xuất bảng với cuộc hội thoại ngôn ngữ tự nhiên sở hữu một loạt khả năng hội thoại, như giữ ngữ cảnh, xử lý chuyển đổi chủ đề và tham chiếu các mục bảng. RecLLM tập trung vào việc tận dụng các kỹ thuật có thể mở rộng trên một số lượng lớn những trường hợp sử dụng này. Trong Hình 3, một vài khả năng hội thoại cốt lõi hiện được hỗ trợ được chứng minh thông qua một cuộc hội thoại mô phỏng.

Cuối cùng, có một số vấn đề cần được giải quyết để các tác nhân hội thoại trở thành chủ đạo. Chúng bao gồm tính an toàn của đối thoại, khử thiên vị, tính cách nhất quán của tác nhân, v.v. Trong công việc này, chúng tôi không cố gắng giải quyết trực tiếp những vấn đề này, mà tập trung vào những vấn đề độc đáo với bối cảnh đề xuất hội thoại.

3 TỔNG QUAN HỆ THỐNG

Trong phần này, chúng tôi xem xét kỹ hơn các thành phần hệ thống chính của RecLLM (xem Hình 1). Cụ thể, chúng tôi tập trung vào quản lý đối thoại, truy xuất, xếp hạng và giải thích, và kết hợp hồ sơ người dùng ngôn ngữ tự nhiên.

3.1 Quản lý Đối thoại

Hình 4: Một mô-đun quản lý đối thoại LLM thống nhất. LLM nhận đầu vào là toàn bộ ngữ cảnh phiên và xuất ra một chuỗi thông điệp kết thúc bằng một đầu ra cuối cùng kích hoạt một hành động hệ thống, như phản hồi cho người dùng.

Quản lý đối thoại là mô-đun trung tâm của CRS, hoạt động như giao diện giữa người dùng và phần còn lại của hệ thống. Nó có trách nhiệm hướng dẫn người dùng qua một cuộc khám phá đa lượt của kho đề xuất và tạo ra các phản hồi hợp lý, hữu ích và có cơ sở tại mỗi lượt. Trong quá trình này, nó phải thực hiện theo dõi ngữ cảnh một cách ngầm định hoặc rõ ràng để trích xuất các biểu diễn hữu ích của sở thích và ý định người dùng. Thông tin này có thể được sử dụng để thông báo cho chính sách đối thoại và cũng là cơ sở để xuất ra các cuộc gọi API để khởi tạo các hành động hệ thống (ví dụ bằng cách gửi truy vấn tìm kiếm đến backend động cơ đề xuất, xem Phần 3.2.1). Từ góc độ end-to-end, với thông tin ngữ cảnh (lịch sử đối thoại, hồ sơ người dùng, tóm tắt mục, v.v.), mục tiêu của trình quản lý đối thoại là tạo ra các hành động hệ thống để thực hiện, cũng như một phát biểu hệ thống phù hợp.

Có những thách thức và yêu cầu bổ sung đối với quản lý đối thoại trong bối cảnh đề xuất hội thoại:

• Kiểm soát: Trái ngược với đối thoại mở, trình quản lý đối thoại CRS phải chủ động làm việc với người dùng để khám phá kho đề xuất. Điều này đòi hỏi một thiết lập sáng kiến hỗn hợp nơi hệ thống phải phản hồi các yêu cầu của người dùng và cũng đôi khi chủ động điều hướng cuộc hội thoại theo một hướng cụ thể. Ví dụ, khai thác sở thích—trong đó hệ thống phải tìm ra khi nào và cách thức tốt nhất để truy vấn người dùng nhằm trích xuất thông tin tối đa về sở thích của họ—là toàn bộ một lĩnh vực con của quản lý đối thoại CRS [11,74,83,112].

• Mơ hồ: So với đối thoại hướng nhiệm vụ, không có thước đo thành công rõ ràng cho trình quản lý đối thoại CRS. Mặc dù hệ thống nên cố gắng đảm bảo rằng cuộc hội thoại không đi quá xa khỏi nhiệm vụ đề xuất cốt lõi, mục tiêu không nhất thiết là giảm thiểu số lượt mà người dùng cần để tìm một mục chấp nhận được, mà là cung cấp một trải nghiệm khám phá tổng thể thỏa mãn (xem, ví dụ [78]). Điều này có nghĩa là hiếm khi có một điều "đúng" duy nhất khách quan mà hệ thống hội thoại nên nói tại bất kỳ thời điểm nào, cũng như không có thước đo dễ định nghĩa cho việc liệu trình quản lý đối thoại có làm tốt việc hay không.

• Cơ sở: Một trong những thách thức chính của trình quản lý đối thoại CRS là trung thành đặt cơ sở cho các phản hồi của nó đối với người dùng trong kho đề xuất. Sau khi trả về một bảng đề xuất, hệ thống nên có thể tham chiếu đến các mục theo cách có liên quan và chính xác về mặt sự thật. Các nguồn thông tin bên ngoài khác, như sở thích dài hạn đến từ hồ sơ người dùng, cũng có thể được tiêm vào và trình quản lý đối thoại nên có thể kết hợp chúng một cách thích hợp trong cuộc hội thoại đang diễn ra.

Theo truyền thống, CRS采用 cách tiếp cận mô-đun đối với quản lý đối thoại, nơi một đồ thị chính sách được mã hóa cứng ánh xạ các trạng thái đối thoại (ví dụ ý định) đến các hành động hệ thống khác nhau, như việc có nên lấy đề xuất, đặt câu hỏi hay trò chuyện thông thường. Các mô hình hiểu ngôn ngữ tự nhiên trích xuất sở thích và xác định các trạng thái đối thoại, và các mô hình tạo ngôn ngữ tự nhiên riêng biệt tạo ra các phản hồi hệ thống. Thay vào đó, trong một số CRS gần đây, các mô hình ngôn ngữ được điều chỉnh end-to-end trực tiếp để bắt chước đối thoại được thu thập từ các nhân viên crowdsource, loại bỏ bất kỳ khái niệm nào về trạng thái đối thoại hoặc cấu trúc nội bộ.

Trong RecLLM, chúng tôi sử dụng một LLM thống nhất duy nhất để thực hiện quản lý đối thoại hoàn toàn theo thuật ngữ mô hình hóa ngôn ngữ. Tại mỗi lượt, LLM nhận đầu vào là ngữ cảnh cuộc hội thoại trước đó cùng với thông tin bổ sung như các biểu diễn văn bản của bảng đề xuất và hồ sơ người dùng có thể được tiêm từ các nguồn bên ngoài. Giống như cách tiếp cận end-to-end được đề cập ở trên, một trong những đặc điểm phân biệt của kiến trúc này là không còn tồn tại đồ thị chính sách được mã hóa cứng với các trạng thái đối thoại cố định. Thay vào đó, trong một lượt hệ thống nhất định, LLM tạo ra một chuỗi các đầu ra ngôn ngữ tự nhiên đóng gói tất cả theo dõi ngữ cảnh, lý luận trung gian, tạo ngôn ngữ tự nhiên và các cuộc gọi API đến phần còn lại của hệ thống. Được mã hóa cứng rằng một số mẫu chuỗi nhất định trong đầu ra từ trình quản lý đối thoại kích hoạt các hành động hệ thống. Ví dụ, một đầu ra "Response: <message>" sẽ khiến thông điệp được hiển thị như một phản hồi đối mặt với người dùng, và "Request: <query>" sẽ khiến truy vấn được gửi đến backend động cơ đề xuất để truy xuất một bảng đề xuất. Các đầu ra khác của LLM có thể hoạt động như các bước lý luận chuỗi, hướng dẫn cho chính nó để tuân theo, hoặc suy luận theo dõi trạng thái đối thoại. Không giống như các cuộc gọi hệ thống, không có quy tắc cố định nào về chức năng của những đầu ra trung gian này, và các quy ước về việc sử dụng chúng phải được dạy cho LLM thông qua học few-shot trong ngữ cảnh hoặc điều chỉnh.

Ưu điểm của kiến trúc này so với cách tiếp cận mô-đun là tính đơn giản và linh hoạt của nó. Trong cách tiếp cận mô-đun, bất kỳ chức năng mới nào như việc thêm ý định người dùng hoặc trạng thái đối thoại mới đều phải được kỹ thuật hóa vào hệ thống, đây là một trở ngại nghiêm trọng đối với khả năng mở rộng. Kiến trúc LLM thống nhất chuyển trọng tâm từ lặp lại chất lượng hướng kỹ thuật sang hướng dữ liệu. Để khắc phục một vấn đề hoặc giới thiệu khả năng mới, thay vì kỹ thuật hóa một thành phần mới, một nhà thiết kế giờ đây phải tạo ra các ví dụ cho phép LLM học hành vi mong muốn. Điều này cũng tạo ra tiềm năng cho trình quản lý đối thoại học các trạng thái chính sách mới và các tạo phẩm theo dõi trạng thái đối thoại hữu ích thông qua khả năng tổng quát hóa của LLM.

Thách thức chính đối với cách tiếp cận LLM thống nhất là cách kiểm soát hiệu quả trình quản lý đối thoại và hướng dẫn nó hướng tới một chính sách đối thoại hợp lý mà không ràng buộc rõ ràng nó thông qua các quy tắc cứng. Trong triển khai ban đầu của chúng tôi, chúng tôi điều chỉnh LLM thống nhất của mình trên một số lượng vừa phải các ví dụ được tạo thủ công. Bằng cách này, chúng tôi có thể thiết lập một số hướng về loại hành vi và trạng thái nội bộ mà chúng tôi muốn thấy trong khi vẫn dựa rất nhiều vào khả năng của LLM được đào tạo trước trên dữ liệu đối thoại để trò chuyện tự nhiên chỉ với sự giám sát tối thiểu. Mặc dù chúng tôi có thể xây dựng một trình quản lý đối thoại chức năng theo cách này, với chỉ một lượng hạn chế các ví dụ đào tạo, việc dạy trình quản lý đối thoại một chính sách phức tạp phù hợp với lĩnh vực đề xuất hội thoại là khó khăn. Trong Phần 4.2, chúng tôi thảo luận các ý tưởng để khắc phục hạn chế này bằng cách điều chỉnh trình quản lý đối thoại và các mô-đun đề xuất của chúng tôi với lượng lớn dữ liệu được tạo tổng hợp.

3.2 Đề xuất và Tinh chỉnh

Một khi được kích hoạt bởi mô-đun quản lý đối thoại, trách nhiệm của mô-đun đề xuất là trả về một bảng đề xuất chất lượng cao, có liên quan và đa dạng sẽ được hiển thị cho người dùng. Điều này có thể là một bảng đề xuất ban đầu hoặc một tinh chỉnh của bảng trước đó từ phiên dựa trên phản hồi từ người dùng. Một hệ thống đề xuất truyền thống chọn các mục bằng cách suy đoán sở thích của người dùng từ một số loại hồ sơ người dùng hoặc biểu diễn dày đặc được xây dựng từ dữ liệu lịch sử, có thể tính đến các yếu tố ngữ cảnh khác (ví dụ vị trí hoặc thời gian trong ngày). Một thách thức chính của CRS là giờ đây người dùng có thể thể hiện những ý định rõ ràng này trong suốt cuộc hội thoại đa lượt đầy đủ, mà mô-đun đề xuất phải hiểu và kết nối với kho mục. Nhiều hệ thống đề xuất truyền thống sử dụng pipeline hai giai đoạn, trước tiên truy xuất các mục ứng viên và sau đó xếp hạng chúng [21,54]. RecLLM tuân theo chiến lược này, với yếu tố bổ sung là bộ xếp hạng cũng đồng thời tạo ra các lời giải thích ngôn ngữ tự nhiên về lý do tại sao mỗi mục được chọn.

3.2.1 Truy xuất. Mục đích của giai đoạn truy xuất là lấy toàn bộ kho, có thể chứa hàng trăm triệu mục đối với một số lĩnh vực như video hoặc url, và dựa trên ngữ cảnh chọn một số lượng nhỏ các mục ứng viên (ví dụ 100) sẽ được đưa vào bộ xếp hạng downstream. Một thách thức chính của việc truy xuất là làm cho quá trình này có thể xử lý được, vì không khả thi về mặt tính toán để xử lý từng mục một cách độc lập tại thời điểm suy luận. Trong Hình 5, chúng tôi minh họa một khung khái niệm tổng quát cho việc truy xuất trong bối cảnh vấn đề của chúng tôi. Một LLM xử lý ngữ cảnh phiên và tạo ra một yêu cầu, hoặc ngầm định thông qua một lớp kích hoạt mô hình hoặc rõ ràng thông qua giao diện đầu ra ngôn ngữ của nó. Một động cơ đề xuất sau đó sử dụng một thuật toán tìm kiếm có thể xử lý để truy xuất ứng viên từ kho mục. Trong Bảng 1, chúng tôi đưa ra một vài ví dụ minh họa về các thuật toán truy xuất có thể có phù hợp với khung này, mà chúng tôi mô tả chi tiết hơn dưới đây.

Hình 5: Tổng quan về truy xuất quy mô lớn trong CRS dựa trên LLM.

Cách tiếp cận | Loại Yêu cầu | Thuật toán Tìm kiếm Có thể xử lý
---|---|---
Mô hình Dual Encoder Tổng quát | Embedding LLM nội bộ | KNN hoặc ScaNN [30]
Tìm kiếm LLM Trực tiếp | Tiêu đề hoặc id | Tra cứu mờ
Tìm kiếm Dựa trên Khái niệm | Danh sách khái niệm | Vector Kích hoạt Khái niệm [43]
Tra cứu API Tìm kiếm | Truy vấn tìm kiếm | API Tìm kiếm

Bảng 1: Các giải pháp có thể khác nhau cho việc truy xuất quy mô lớn trong CRS.

Mô hình Dual Encoder Tổng quát. Một giải pháp phổ biến cho việc truy xuất trong các hệ đề xuất truyền thống dựa trên học sâu là sử dụng mô hình dual encoder bao gồm hai tháp mạng nơ-ron, một để mã hóa ngữ cảnh và một để mã hóa các mục (xem ví dụ [102] và Hình 10a). Embedding mục có thể được tạo ra offline bằng tháp mục và lưu trữ trong một cấu trúc dữ liệu hiệu quả. Một tra cứu nearest neighbor gần đúng sau đó có thể sử dụng embedding ngữ cảnh được tạo ra để thực hiện truy xuất embedding mục thời gian dưới tuyến tính tại thời điểm suy luận [98]. Chúng ta có thể mở rộng cách tiếp cận này cho đề xuất hội thoại bằng cách sử dụng LLM làm bộ mã hóa ngữ cảnh xử lý toàn bộ cuộc hội thoại đang diễn ra giữa người dùng và hệ thống cùng với bất kỳ thông tin ngữ cảnh bổ sung nào khác. Trong trường hợp này, yêu cầu được gửi đến động cơ đề xuất là một embedding, có thể được tạo ra bằng cách trích xuất và sau đó chiếu một lớp kích hoạt phù hợp từ mô hình.

Một nhược điểm của cách tiếp cận kéo embedding từ bên trong LLM này là nó làm suy yếu nghiêm trọng khả năng của chúng ta trong việc học một mô hình truy xuất theo cách hiệu quả mẫu. Các mô hình dual encoder được đào tạo từ đầu đòi hỏi lượng lớn dữ liệu đào tạo để ràng buộc embedding tháp ngữ cảnh chiếm cùng một không gian con với embedding tháp mục. Đôi khi có thể sử dụng embedding được đào tạo trước ở phía mục (ví dụ bằng cách lấy chúng từ hệ thống tìm kiếm hoặc đề xuất sản xuất hiện có), nhưng vẫn phải điều chỉnh embedding ngữ cảnh để căn chỉnh với embedding mục để có kết quả tốt. LLM hoạt động thông qua giao diện text-in / text-out và phần lớn sức mạnh của chúng đến từ transfer learning được cung cấp bởi kiến thức có được thông qua đào tạo trước rộng rãi. Bằng cách rời khỏi mức trừu tượng ngôn ngữ, chúng ta đang hy sinh phần lớn khả năng tổng quát hóa này từ một lượng nhỏ dữ liệu.

Tìm kiếm LLM Trực tiếp. Trong phương pháp này, LLM trực tiếp xuất ra id hoặc tiêu đề của các mục để đề xuất dưới dạng văn bản. Thuật toán tìm kiếm có thể xử lý là một khớp chính xác hoặc mờ đối với các mục trong kho và động cơ đề xuất không đóng vai trò nào ngoài việc khớp đơn giản này. LLM phải học cách xuất ra những id/tiêu đề này thông qua một số kết hợp đào tạo trước và giai đoạn fine-tuning cụ thể cho kho (xem ví dụ [84]). Với giả định rằng hệ thống của chúng ta phải có khả năng trả về bảng từ một kho mục cố định, đây là điều gần nhất với việc có một chatbot dựa trên LLM hoạt động trực tiếp như một CRS. Nhược điểm của cách tiếp cận này là vì chỉ có công việc không đáng kể được tải xuống cho động cơ đề xuất, LLM phải ghi nhớ thông tin về toàn bộ kho mục trong các tham số mô hình của nó. Đối với một kho lớn, điều này có thể đắt đỏ một cách cấm kỵ về kích thước mô hình và dữ liệu đào tạo cần thiết, và cũng khiến việc làm mới kho mục trở nên khó khăn mà không cần đào tạo lại LLM.

Tìm kiếm Dựa trên Khái niệm. Trong phương pháp này, LLM xuất ra một danh sách các khái niệm, sau đó được embedding và tổng hợp bởi động cơ đề xuất thành một embedding ngữ cảnh duy nhất. Điều này được sử dụng để tra cứu các mục thông qua tìm kiếm k-nearest neighbor gần đúng tương tự như phương pháp dual encoder tổng quát. Một kỹ thuật như Concept Activation Vectors [43] có thể được sử dụng để thực hiện chuyển đổi này từ khái niệm sang embedding trong không gian mục. Sức hấp dẫn của cách tiếp cận này là việc trích xuất các khái niệm có liên quan từ cuộc hội thoại là một nhiệm vụ tự nhiên có thể được dạy cho LLM thông qua học trong ngữ cảnh hoặc điều chỉnh với một số lượng nhỏ ví dụ. Ngoài ra, vì chỉ cần embedding mục (embedding khái niệm được bắt nguồn từ những cái này), nếu embedding mục được đào tạo trước có thể được mượn từ một nguồn hiện có thì không cần điều chỉnh bổ sung embedding nào. Tuy nhiên, một hạn chế là danh sách khái niệm thường là một biểu diễn thô của cuộc hội thoại và tương tự như các phương pháp continuous bag-of-words [60] là có tính mất mát đối với thứ tự từ và các sắc thái khác của ngôn ngữ, có thể ảnh hưởng tiêu cực đến chất lượng truy xuất.

Tra cứu API Tìm kiếm. Trong phương pháp này, LLM trực tiếp xuất ra một truy vấn tìm kiếm, được đưa vào API tìm kiếm hộp đen để truy xuất các mục. Không giống như Tìm kiếm Dựa trên Khái niệm, có tính tổng quát miễn là embedding mục có thể được đào tạo hoặc tái sử dụng, Tra cứu API Tìm kiếm chỉ áp dụng được khi API tìm kiếm như vậy đã tồn tại cho lĩnh vực đang quan tâm. Tuy nhiên, khi có sẵn, loại API này thường được hỗ trợ bởi một stack tìm kiếm phức tạp và có thể mang lại kết quả chất lượng cao hơn. Tương tự như Tìm kiếm Dựa trên Khái niệm, trong Tra cứu API Tìm kiếm, LLM có thể được dạy để xuất ra các truy vấn tìm kiếm có liên quan sử dụng một số lượng nhỏ ví dụ (xem Phần 3.1), nhưng chất lượng truy xuất bị hạn chế bởi mức độ mà một truy vấn tìm kiếm có thể đại diện đúng cho toàn bộ ngữ cảnh của cuộc hội thoại.

Trong Phần 4.2, chúng tôi xây dựng dựa trên những phương pháp này bằng cách thảo luận các tùy chọn để điều chỉnh mô hình truy xuất sử dụng dữ liệu tổng hợp quy mô lớn.

3.2.2 Xếp hạng / Giải thích. Sau khi các mục ứng viên đã được truy xuất, một bộ xếp hạng quyết định mục nào trong số chúng sẽ được bao gồm trong bảng đề xuất và theo thứ tự nào. Không giống như mô-đun truy xuất, mô-đun xếp hạng không cần thực hiện tìm kiếm có thể xử lý trên kho lớn và do đó ít bị ràng buộc hơn trong các loại tính toán có thể. Trong một hệ thống đề xuất truyền thống, điều này thường biểu hiện trong việc bộ xếp hạng crossing các đặc trưng ngữ cảnh và mục (thay vì xử lý chúng trong các tháp riêng biệt như được thực hiện trong dual encoder) và có thể sử dụng các loss xếp hạng tùy chỉnh trong quá trình đào tạo để trực tiếp so sánh các mục ứng viên [10]. Trong trường hợp của RecLLM, chúng tôi tận dụng khoảng trống bổ sung này cho tính toán để sử dụng LLM lý luận tuần tự về mức độ phù hợp của một mục với ngữ cảnh và tạo ra một lý giải cho quyết định của nó như một sản phẩm phụ.

Hình 6 đưa ra một sơ đồ cho bộ xếp hạng LLM. Đối với mỗi mục ứng viên, LLM đồng thời tạo ra một điểm số và một lời giải thích ngôn ngữ tự nhiên cho điểm số1. Những điểm số này ngầm định tạo ra một xếp hạng của các mục. Bước đầu tiên là tạo một tóm tắt văn bản của mục phù hợp với cửa sổ ngữ cảnh của LLM dựa trên siêu dữ liệu liên quan đến mục. Trong trường hợp của bộ đề xuất video YouTube, siêu dữ liệu này bao gồm thông tin như tiêu đề, các thực thể knowledge graph liên quan đến video, mô tả phát triển viên về video, bản ghi âm của video, và bình luận người dùng. Trong tương lai, chúng tôi cũng mong đợi một mô hình đa phương thức lớn xử lý trực tiếp video thô thay vì chỉ dựa vào các tạo phẩm văn bản. Việc tóm tắt mục này có thể được thực hiện offline và cần thiết trong trường hợp siêu dữ liệu có khối lượng cao (ví dụ nếu chúng ta có hàng nghìn bình luận người dùng). Chúng ta có thể xem việc tóm tắt này như một trường hợp đặc biệt của vấn đề tóm tắt multi-document [53]; nó cũng liên quan đến một thách thức chính của mô-đun hồ sơ người dùng (xem Phần 3.3), mô-đun này phải tóm tắt lượng lớn dữ liệu người dùng trước đó thành định dạng văn bản có thể được truyền vào LLM (hoặc thay vào đó bổ sung LLM với khả năng truy cập thông tin này một cách hiệu quả tại thời điểm suy luận). Cũng có thể có một bước tiền xử lý tương tự để tóm tắt thông tin ngữ cảnh, mặc dù điều này phải được thực hiện tại thời điểm suy luận vì không giống như đối với các mục, chúng ta không thể liệt kê tất cả các ngữ cảnh có thể và xử lý chúng offline.

1Có nhiều giải pháp được đề xuất để cho phép LLM text in / text out giải quyết các vấn đề hồi quy (tức là xuất ra một điểm số) [52]; trong RecLLM, chúng tôi sử dụng cách tiếp cận đơn giản là chia nhóm phạm vi các điểm số có thể và để LLM xuất ra một cụm từ có ý nghĩa ngữ nghĩa (ví dụ "phù hợp tuyệt vời") tương ứng với một id nhóm.

Hình 6: Một mô-đun xếp hạng / giải thích LLM kết hợp. Cuộc hội thoại được sử dụng làm ngữ cảnh cho sở thích của người dùng và siêu dữ liệu video được sử dụng làm ngữ cảnh cho mục. LLM nhận các tóm tắt của phía mục và phía ngữ cảnh để tạo ra một điểm số cho mục và một lời giải thích cho điểm số.

Với những tóm tắt mục và ngữ cảnh này làm đầu vào, bộ xếp hạng LLM sau đó cho điểm mục bằng cách sử dụng lý luận chuỗi suy nghĩ, đã được chứng minh là cải thiện hiệu suất của LLM trên những loại nhiệm vụ phân loại / hồi quy này [95]. Các bước lý luận chuỗi suy nghĩ trung gian được tạo ra bởi LLM hoạt động như lời giải thích tại sao một số mục cuối cùng được bao gồm hoặc bị loại khỏi bảng đề xuất. Những lời giải thích này có thể được xem nội bộ cho mục đích gỡ lỗi và cũng hiển thị cho người dùng, hoặc bằng cách bao gồm chúng như đầu vào cho trình quản lý đối thoại tạo ra các phát biểu trong giao diện hội thoại hoặc bằng cách hậu xử lý và bao gồm chúng trong các hộp pop-up trong giao diện người dùng trực quan nơi các bảng đề xuất được hiển thị.

3.3 Hồ sơ Người dùng

Một trong những lợi ích chính của CRS là khả năng của người dùng thể hiện sở thích của họ trong suốt một phiên, để hệ thống có thể hỗ trợ họ mà không nhất thiết cần bất kỳ thông tin nền trước đó nào. Bất chấp điều này, trải nghiệm cá nhân hóa có thể được cải thiện nếu hệ thống đã xây dựng một hồ sơ của người dùng trước đó để có một cơ sở bắt đầu chung để xây dựng cuộc hội thoại lên trên. Ví dụ, nếu một người dùng không thích nhạc jazz và đã chia sẻ điều này trước đó, họ không nên phải nhắc lại điểm này mỗi phiên mới khi tìm kiếm video âm nhạc.

Trong các hệ thống đề xuất truyền thống dựa trên học sâu, các tín hiệu tương tác không lời như nhấp chuột hoặc đánh giá thường được sử dụng để đào tạo các biểu diễn embedding của người dùng có thể được đưa vào mạng nơ-ron. Trong RecLLM, thay vào đó chúng tôi đại diện người dùng bằng hồ sơ ngôn ngữ tự nhiên (xem ví dụ [70]), có thể được LLM sử dụng. Những hồ sơ này minh bạch hơn so với embedding và các phần thông tin cụ thể thường có thể được quy cho một nguồn gốc, điều này hỗ trợ trong khả năng giải thích. Ngoài ra, người dùng có thể chỉnh sửa thủ công những hồ sơ ngôn ngữ tự nhiên này, mang lại cho họ quyền kiểm soát lớn hơn để giám sát và cập nhật sở thích của họ. Trong RecLLM, chúng tôi xây dựng hồ sơ người dùng dựa trên tương tác lặp lại của người dùng với hệ thống qua nhiều phiên, mặc dù có thể kết hợp các nguồn dữ liệu khác nữa.

Một câu hỏi nghiên cứu mở quan trọng là cách cấu trúc hồ sơ người dùng theo thuật ngữ ngôn ngữ tự nhiên. Hiện tại trong RecLLM, chúng tôi đại diện một người dùng bằng một tập hợp các sự thật nổi bật mà chúng tôi đã trích xuất từ các phiên trước đó (ví dụ "Tôi không thích nghe nhạc jazz khi trong xe") tương tự như [109], mặc dù nhiều sơ đồ tinh vi khác là có thể. Một khả năng cực đoan khác là tránh bất kỳ tính mất mát nào bằng cách định nghĩa hồ sơ người dùng một cách thoái hóa như lịch sử hội thoại thô của tất cả các phiên mà người dùng đã có với hệ thống trong quá khứ. Trong trường hợp này, chúng ta sẽ cần triển khai một cơ chế hiệu quả để LLM truy xuất các sự thật có liên quan từ lịch sử thô này tại thời điểm suy luận.

Có ba thành phần chính của mô-đun Hồ sơ Người dùng, mà chúng tôi giờ mô tả.

Trích xuất Ký ức. Mục đích của thành phần trích xuất ký ức là xác định khi nào một phát biểu cụ thể chứa một sự thật có ý nghĩa và bền vững về người dùng có thể được trích xuất và thêm vào hồ sơ người dùng. Trong RecLLM, điều này hiện được triển khai bởi một LLM sử dụng học few-shot trong ngữ cảnh như một phần của mô-đun quản lý đối thoại.

Kích hoạt và Truy xuất. Thành phần kích hoạt và truy xuất quyết định tại những thời điểm nào trong phiên có khả năng có lợi để truy vấn hồ sơ người dùng cho thông tin bổ sung và sau đó truy xuất các sự thật có liên quan nhất liên quan đến ngữ cảnh hiện tại. Hiện tại tại mỗi lượt, RecLLM truy xuất một sự thật duy nhất từ hồ sơ người dùng bằng cách embedding phát biểu cuối cùng của người dùng và thực hiện so sánh khoảng cách cosine giữa embedding này và embedding được tính trước của mỗi sự thật trong hồ sơ người dùng. Kích hoạt được triển khai post hoc bằng cách đặt ngưỡng trên khoảng cách cosine tối thiểu này. Hiệu suất tốt hơn có khả năng có thể bằng cách sử dụng một bộ phân loại LLM riêng biệt cho việc kích hoạt, truy xuất nhiều sự thật từ hồ sơ người dùng, và dựa trên toàn bộ ngữ cảnh cuộc hội thoại của phiên thay vì chỉ phát biểu cuối cùng.

Tích hợp Hệ thống. Một khi thông tin hồ sơ người dùng được truy xuất, nó phải được tích hợp vào phần còn lại của hệ thống để có thể ảnh hưởng đến hành vi như đối thoại của hệ thống và các cuộc gọi API đến động cơ đề xuất. Cách tích hợp đúng cách các sự thật đến từ hồ sơ người dùng là một câu hỏi mở khó khăn, vì nó phụ thuộc cao vào ngữ cảnh về cách chúng nên điều chỉnh sở thích ngắn hạn được thể hiện bởi người dùng trong phiên hiện tại. Ví dụ, hệ thống có thể biết rằng người dùng bị dị ứng hải sản, nhưng nếu người dùng nói rõ ràng rằng họ muốn xem một số video về công thức nấu ăn cá để chuyển cho một người bạn, điều quan trọng là hệ thống ghi đè sở thích này từ hồ sơ người dùng và đưa cho người dùng những gì họ đang yêu cầu. Trong RecLLM, chúng tôi sử dụng chiến lược đơn giản là tiêm các sự thật từ hồ sơ người dùng vào đầu vào văn bản của trình quản lý đối thoại (xem Phần 3.1). Bằng cách đó, chúng tôi cho phép các LLM cung cấp năng lượng cho trình quản lý đối thoại đưa ra quyết định tinh tế về cách sử dụng thông tin phụ trợ này trong ngữ cảnh của phiên đang diễn ra mà không cần kỹ thuật hóa bất kỳ quy tắc cứng nào vào hệ thống.

Phát biểu Người dùng 
Tích hợp Ký ức Người dùng 
Kích hoạt Trích xuất LLM 
Viết 
Truy xuất Hình 7: Tổng quan về kiến trúc kết hợp mô-đun Hồ sơ Người dùng

4 MÔ PHỎNG VÀ ĐIỀU CHỈNH QUY MÔ LỚN

Một trở ngại lớn đối với việc xây dựng CRS công nghiệp chất lượng cao là thiếu dữ liệu có sẵn cho đào tạo và đánh giá. Thông thường, các hệ thống đề xuất quy mô lớn được đào tạo trên dữ liệu tương tác người dùng được khai thác từ nhật ký của các sản phẩm hiện có; tuy nhiên, đề xuất hội thoại là một công nghệ mới nổi và phần lớn các sản phẩm sử dụng mô hình này chưa tồn tại. Một hệ thống chất lượng cao ban đầu phải được xây dựng để làm cho một sản phẩm như vậy khả thi, sau đó một chu kỳ bootstrap có thể bắt đầu trong đó dữ liệu thực được tạo ra từ hệ thống và sau đó các phiên bản ngày càng tốt hơn của hệ thống được đào tạo sử dụng dữ liệu đó. RecLLM giải quyết vấn đề khan hiếm dữ liệu bằng cách khai thác khả năng transfer learning của mô hình ngôn ngữ lớn sử dụng học few-shot trong ngữ cảnh hoặc fine-tuning trên một số lượng nhỏ ví dụ được tạo thủ công. Tuy nhiên, chúng tôi giả thuyết rằng cuối cùng có một giới hạn trần cho chất lượng có thể đạt được thông qua những cách tiếp cận này, cho long-tail của các tình huống khác nhau có thể phát sinh trong CRS sáng kiến hỗn hợp. Trong phần này, chúng tôi thảo luận việc sử dụng các trình mô phỏng người dùng được hỗ trợ bởi LLM để tạo ra dữ liệu thực tế quy mô lớn và các kỹ thuật để điều chỉnh các thành phần hệ thống sử dụng lượng lớn dữ liệu.

4.1 Mô phỏng Người dùng

Hình 8: Một ví dụ về kiểm soát dựa trên phiên: Một biến duy nhất (hồ sơ người dùng) được sử dụng để điều kiện trình mô phỏng người dùng.

Hình 9: Một ví dụ về kiểm soát cấp lượt: Một loạt biến (ý định người dùng) được sử dụng để điều kiện trình mô phỏng người dùng tại mỗi lượt.

Theo thiết lập đề xuất hội thoại được xem xét trong bài báo này (xem Phần 2), một phiên bao gồm một chuỗi 𝑆={𝑠1,𝑢1,𝑠2,𝑢2,...,𝑠𝑛,𝑢𝑛}, trong đó mỗi 𝑢𝑖 là một phát biểu ngôn ngữ tự nhiên của người dùng và mỗi 𝑠𝑖 là một kết hợp của một phát biểu ngôn ngữ tự nhiên và có thể là một bảng đề xuất của CRS. Do đó, một trình mô phỏng người dùng được định nghĩa bởi một hàm 𝑓(𝑆′)=𝑈𝑖, trong đó 𝑆′={𝑠1,𝑢1,𝑠2,𝑢2,...,𝑠𝑖} là một phiên một phần và 𝑈𝑖 là một phân phối trên các phát biểu người dùng có thể 𝑢𝑖 tiếp tục phiên. Với một CRS cố định và một trình mô phỏng người dùng 𝑓 như vậy, chúng ta có thể tạo ra một phiên mẫu mới bằng cách để CRS và 𝑓 tương tác trong một số lượng lượt nhất định (tức là CRS tạo ra mỗi 𝑠𝑖 và 𝑓 tạo ra mỗi 𝑢𝑖).

Tính chất lý tưởng mà chúng tôi muốn trình mô phỏng người dùng của chúng tôi có khi tạo ra dữ liệu tổng hợp cho đánh giá hoặc đào tạo là tính thực tế: Các cuộc hội thoại giữa trình mô phỏng người dùng và CRS nên gần như không thể phân biệt được với các cuộc hội thoại giữa một nhóm người dùng đại diện thực sự và CRS. Gọi R là một tập hợp các phiên được tạo ra bởi việc có người dùng thực tương tác với một CRS cụ thể, và Q là một tập hợp các phiên mô phỏng được lấy mẫu từ CRS và một trình mô phỏng người dùng 𝑓 theo thủ tục được nêu ở trên. Chúng tôi đưa ra ba cách có thể để đo lường tính thực tế của 𝑓:

• Có các nhân viên crowdsource cố gắng phân biệt giữa các phiên mô phỏng đến từ Q và các phiên thực đến từ R.

• Đào tạo một mô hình discriminator [28] trên cùng nhiệm vụ phân biệt.

• Gọi 𝑔(𝑆)→[1,𝑘] là một hàm phân loại một phiên thành 𝑘 danh mục và gọi 𝐺={𝑔𝑖} là một ensemble của những bộ phân loại như vậy. Một cách để định nghĩa một ensemble như vậy là bằng cách điều chỉnh các tạo phẩm theo dõi trạng thái đối thoại được sử dụng trong mô-đun quản lý đối thoại của CRS (xem Phần 3.1). Ví dụ, chúng ta có thể có một bộ phân loại gắn nhãn ý định người dùng tại một lượt cụ thể, hoặc các chủ đề được đề cập trong một phiên, hoặc tình cảm chính của một phiên. Một khi được định nghĩa, chúng ta có thể đo lường mức độ gần gũi của các phân phối Q và R bằng cách khớp thống kê theo ensemble bộ phân loại 𝐺.

Một điều kiện cần thiết của tính thực tế là tính đa dạng: Các phiên mô phỏng từ Q nên có đủ biến thiên để gọi ra tất cả các chức năng khác nhau của CRS mà người dùng sẽ gặp trong thực tế khi sử dụng hệ thống. Có thể trong một số tình huống, việc đo lường tính thực tế trực tiếp là khó khăn, ví dụ nếu việc thu thập một tập hợp đại diện các phiên người dùng thực là không khả thi. Trong trường hợp này, chúng ta ít nhất có thể cố gắng đo lường tính đa dạng của trình mô phỏng người dùng, ví dụ bằng cách định nghĩa một khái niệm entropy của Q đối với ensemble bộ phân loại 𝐺.

Mô phỏng Có kiểm soát. Điểm khởi đầu của chúng tôi để xây dựng trình mô phỏng người dùng là quan sát rằng một LLM không ràng buộc được xây dựng cho đối thoại như LaMDA [86] có thể tương tác với CRS theo cách tương tự như người dùng thực. LLM nhận đầu vào là toàn bộ lịch sử của cuộc hội thoại đang diễn ra và xuất ra phát biểu người dùng tiếp theo, tương tự như cách trình quản lý đối thoại CRS có thể sử dụng LLM để tạo ra phát biểu hệ thống. Tuy nhiên, chúng tôi muốn thể hiện quyền kiểm soát lớn hơn đối với trình mô phỏng để tăng tính thực tế của nó. Trong mô phỏng có kiểm soát, chúng tôi điều kiện trình mô phỏng người dùng trên các biến tiềm ẩn bổ sung (đối với CRS) cho phép chúng tôi hướng dẫn hành vi của nó theo một hướng nhất định. Chúng tôi khám phá với hai biến thể khác nhau:

• Kiểm soát cấp phiên: Một biến duy nhất 𝑣 được định nghĩa ở đầu phiên và được sử dụng để điều kiện trình mô phỏng người dùng trong suốt phiên. Ví dụ, chúng ta có thể định nghĩa 𝑣 như một hồ sơ người dùng như những cái được thảo luận trong Phần 3.3.

• Kiểm soát cấp lượt: Một biến riêng biệt 𝑣𝑖 được định nghĩa tại mỗi lượt của phiên và được sử dụng để điều kiện trình mô phỏng cho lượt đó. Ví dụ, chúng ta có thể định nghĩa mỗi 𝑣𝑖 là một ý định người dùng để trình mô phỏng áp dụng tại lượt đó.

Trong trường hợp của trình mô phỏng người dùng LLM, một cách để thực hiện kiểm soát là dịch biến thành văn bản có thể được bao gồm như một phần của đầu vào của trình mô phỏng cùng với phần còn lại của cuộc hội thoại. Ví dụ, đối với ví dụ hồ sơ người dùng, chúng ta có thể thêm tuyên bố "Tôi là một cậu bé mười hai tuổi thích vẽ và trò chơi video" vào đầu cuộc hội thoại để tạo ra LLM bắt chước tính cách này. Để tăng tính thực tế, một chiến lược có thể là định nghĩa các biến cấp phiên hoặc cấp lượt theo thuật ngữ của các bộ phân loại tạo nên một trong những ensemble 𝐺 được thảo luận ở trên và sau đó lấy mẫu các biến theo phân phối thực nghiệm của bộ sưu tập các phiên người dùng thực R. Một khả năng khác là cơ sở điều kiện trong các quỹ đạo đến từ dữ liệu thực từ một sản phẩm liên quan. Ví dụ, chúng ta có thể xem xét các chuỗi truy vấn được gửi bởi người dùng trong một ứng dụng tìm kiếm không hội thoại và lấy mẫu các biến cấp lượt như quỹ đạo của các chủ đề khớp với những chuỗi truy vấn này.

Tạo ra Dữ liệu Đào tạo Tổng hợp. Để sử dụng trình mô phỏng người dùng để tạo ra dữ liệu cho việc đào tạo có giám sát của một trong các mô-đun hệ thống CRS, một tính chất bổ sung là cần thiết: nhãn chân lý cơ bản mà hệ thống có thể học từ đó. Như một ví dụ đồ chơi, giả sử chúng ta đang cố gắng học một bộ phân loại tình cảm như một phần của mô-đun theo dõi trạng thái đối thoại truyền thống. Để làm điều này, chúng ta cần tạo ra một tập hợp các ví dụ 𝑆𝑖,𝑙𝑖, trong đó 𝑆𝑖 là một phiên 𝑠1,𝑢1,𝑠2,𝑢2,...𝑠𝑛,𝑢𝑛 và 𝑙𝑖 là một nhãn chân lý cơ bản cho tình cảm người dùng chính trong 𝑆𝑖 đến từ một tập hợp các nhãn có thể 𝐿, ví dụ {tức giận, hài lòng, bối rối, ...}. Chúng ta có thể sử dụng mô phỏng người dùng có kiểm soát để giải quyết vấn đề này, bằng cách định nghĩa một biến cấp phiên 𝑣 trên tập hợp nhãn 𝐿 này. Trước tiên chúng ta lấy mẫu một biến 𝑣 từ 𝐿 (ví dụ "tức giận") và sau đó điều kiện trình mô phỏng dựa trên nhãn này, ví dụ trong một triển khai priming bằng cách thêm thông điệp "Bạn là một người dùng tức giận" vào đầu đầu vào của trình mô phỏng. Nếu chúng ta có thể giải quyết vấn đề kiểm soát LLM này một cách hiệu quả thì chúng ta có thể gắn một nhãn 𝑙𝑖="tức giận" vào phiên 𝑆𝑖 và tin tưởng rằng với xác suất cao nó sẽ chính xác.

Một trường hợp sử dụng đầy tham vọng hơn là tạo ra dữ liệu để đào tạo các mô-đun truy xuất và xếp hạng được thảo luận trong Phần 3.2.1 và 3.2.2. Để làm điều này, chúng ta có thể định nghĩa một biến cấp phiên 𝑣 như một tuple (𝑥,𝑗), trong đó 𝑥 là một mục từ kho và 𝑗 là một chỉ số lượt số nguyên. Một khi chúng ta lấy mẫu một 𝑣=(𝑥,𝑗), chúng ta điều kiện trình mô phỏng để tạo ra một phiên 𝑆={𝑣,𝑠1,𝑢1,𝑠2,𝑢2,...,𝑠𝑗,𝑢𝑣,...} sao cho sau 𝑗 lượt, mục 𝑥 là một khớp tốt cho ngữ cảnh 𝑆 (tức là người dùng sẽ hài lòng nếu ở lượt 𝑠𝑗+1 hệ thống bao gồm 𝑥 trong một bảng đề xuất). Phiên này sau đó có thể được sử dụng như một ví dụ đầu vào để đào tạo mô-đun đề xuất, trong đó mục 𝑥 là một instance dương và các mục khác từ kho có thể được lấy mẫu như âm tính. Đây là một vấn đề điều kiện phức tạp hơn nhiều, và một hướng dẫn priming zero-shot đơn giản (ví dụ "Tạo ra một phiên sao cho sau 𝑗 lượt mục 𝑥 là một khớp tốt cho ngữ cảnh") sẽ không hoạt động. Cách giải quyết vấn đề kiểm soát này một cách hiệu quả, hoặc thông qua priming cấp lượt tinh vi hơn hoặc bằng cách điều chỉnh LLM trình mô phỏng người dùng, là một nỗ lực nghiên cứu đang diễn ra.

4.2 Điều chỉnh Các mô-đun Hệ thống

Đối với phần còn lại của phần này, chúng tôi tập trung vào việc điều chỉnh LLM trong hệ thống của chúng tôi sử dụng lượng lớn dữ liệu được tạo tổng hợp. Để cụ thể, chúng tôi xem xét ba mô-đun được thảo luận trước đó trong bài báo: Truy xuất (Phần 3.2.1), Xếp hạng / Giải thích (Phần 3.2.2), và Quản lý Đối thoại (Phần 3.1).

Truy xuất. Trong Phần 4.1, chúng tôi đã phác thảo một chiến lược để tạo ra dữ liệu đào tạo tổng hợp để điều chỉnh mô-đun đề xuất. Đối với truy xuất, chúng tôi giả định các ví dụ đào tạo của chúng tôi là các tuple có dạng (𝑆′,𝑥𝑝𝑜𝑠,{𝑥𝑛𝑒𝑔}), trong đó 𝑆′ là một phiên một phần 𝑠1,𝑢1,𝑠2,𝑢2,...𝑠𝑖,𝑢𝑖, 𝑥𝑝𝑜𝑠 là một mục là một khớp tốt cho ngữ cảnh 𝑆′ (theo nghĩa được định nghĩa trước đó) và {𝑥𝑛𝑒𝑔} là một tập hợp các mục âm tính được tạo ra bởi một số thủ tục lấy mẫu âm tính. Với dữ liệu này, chúng ta có thể điều chỉnh Mô hình Dual Encoder Tổng quát (xem Phần 3.2.1), trong đó biểu diễn ngữ cảnh ban đầu và biểu diễn mục mỗi cái được mã hóa bởi một LLM. Bất kể chúng ta chọn điều chỉnh chỉ các lớp adapter của mô hình hai tháp hay các tham số LLM nữa, loss là hoàn toàn khả vi và học có giám sát thông thường với gradient descent là đủ.

Trong Tra cứu API Tìm kiếm (xem Phần 3.2.1), một LLM xử lý lịch sử phiên và xuất ra một truy vấn tìm kiếm, sau đó được chuyển vào thuật toán tìm kiếm hộp đen. Khi kiến trúc này được sử dụng, loss không còn khả vi và học có giám sát thông thường không thể. Thay vào đó, chúng ta có thể tái định nghĩa thiết lập như một vấn đề contextual bandit [5], trong đó LLM là một chính sách, các nhãn là tín hiệu phần thưởng, và thuật toán tìm kiếm hộp đen được coi là môi trường (xem Hình 10b). Nếu bộ mã hóa LLM được chia sẻ với các mô-đun khác, chúng ta có sự lựa chọn điều chỉnh các tham số được bảo vệ của LLM chỉ ảnh hưởng đến nhiệm vụ xuất ra truy vấn tìm kiếm này, hoặc thay vào đó điều chỉnh các tham số được chia sẻ của LLM cũng ảnh hưởng đến hành vi của các mô-đun khác này.

Xếp hạng. Đối với trường hợp sử dụng này, chúng tôi giả định các ví dụ đào tạo của chúng tôi là các tuple có dạng (𝑆′,𝑌), trong đó 𝑆′ là một phiên một phần 𝑠1,𝑢1,𝑠2,𝑢2,...,𝑠𝑖 sao cho 𝑠𝑖 chứa một bảng đề xuất và 𝑌 là một danh sách các điểm liên quan cho các mục trong bảng đó. Trong Phần 3.2.2, chúng tôi trình bày một mô-đun xếp hạng dựa trên LLM đồng thời tạo ra một điểm cho mỗi mục và một lời giải thích cho điểm đó. Sử dụng dữ liệu này, chúng ta có thể điều chỉnh LLM xếp hạng để dự đoán các nhãn chân lý cơ bản như một vấn đề hồi quy. Chỉ sử dụng dữ liệu liên quan này, chúng ta không thể trực tiếp điều chỉnh LLM để tạo ra lời giải thích tốt hơn, mặc dù điều này vẫn có thể sử dụng các phương pháp bootstrapping chỉ phụ thuộc vào các nhãn cho nhiệm vụ cuối (trong trường hợp này là nhiệm vụ chấm điểm) [35, 107].

Quản lý Đối thoại. Trong Phần 3.1, chúng tôi trình bày một mô-đun quản lý đối thoại dựa trên LLM thống nhất tại mỗi lượt tạo ra một chuỗi các đầu ra ngôn ngữ tự nhiên, cuối cùng trong số đó kích hoạt một hành động hệ thống như phản hồi cho người dùng hoặc một cuộc gọi API đến động cơ đề xuất. Triển khai ban đầu của chúng tôi liên quan đến việc điều chỉnh LLM trên một số lượng vừa phải (ví dụ O(1000)) các chuỗi ví dụ có nghĩa là để chứng minh hành vi mong muốn. Ở đây chúng tôi đề xuất một chiến lược Reinforcement Learning from Human Feedback (xem ví dụ [65]) để xây dựng dựa trên việc điều chỉnh quy mô trung bình này:

(1) Tạo ra một tập hợp các phiên mô phỏng Q sử dụng trình mô phỏng người dùng như được nêu trong Phần 4.1
(2) Có các nhân viên crowdsource đánh giá LLM thống nhất của chúng tôi bằng cách đánh giá các phản hồi mỗi lượt trong Q về mặt trôi chảy, thú vị, có cơ sở, v.v., cũng như đưa ra đánh giá cấp phiên dựa trên tổng thể mức độ hiệu quả của hệ thống trong việc giúp người dùng khám phá kho đề xuất
(3) Đào tạo các mô hình phần thưởng trên dữ liệu đánh giá này (có khả năng cũng sử dụng LLM với lý luận chuỗi suy nghĩ).
(4) Điều chỉnh thêm LLM thống nhất trên các phiên mô phỏng thông qua học tăng cường để tối ưu hóa cho các phần thưởng proxy được tạo ra bởi những mô hình phần thưởng này

5 CÔNG TRÌNH LIÊN QUAN

Trong phần này, chúng tôi khảo sát ngắn gọn nghiên cứu trước đây liên quan đến các chủ đề chính được đề cập trong bài báo này; để có một cách xử lý toàn diện hơn về CRS và các ứng dụng tìm kiếm thông tin hội thoại khác, xem ví dụ [22, 24, 39, 106]

Các Mô hình Ngôn ngữ Lớn. Các Mô hình Ngôn ngữ Lớn dựa trên kiến trúc transformer [88] đã cách mạng hóa lĩnh vực trí tuệ nhân tạo trong những năm gần đây, tạo ra kết quả hiện đại trên nhiều nhiệm vụ hiểu ngôn ngữ tự nhiên và đối thoại [6,15,71,86]. Đặc biệt, những mô hình này xuất sắc trong bối cảnh học zero hoặc few-shot, nơi thông qua các prompt được kỹ thuật hóa thích hợp, chúng có thể được điều chỉnh cho các nhiệm vụ mới mà không cần sửa đổi các tham số mô hình [75]. Khi có nhiều dữ liệu đào tạo hơn, các phương pháp điều chỉnh hiệu quả tham số như prompt tuning có thể đạt được hiệu suất thậm chí tốt hơn trong khi vẫn cho phép một LLM duy nhất xử lý nhiều nhiệm vụ phụ [47,89]. LLM cũng đã chứng minh khả năng thú vị trong việc thực hiện lý luận đa bước sử dụng chain of thought prompting [95], một khả năng dường như chỉ xuất hiện ở những quy mô mô hình nhất định [94]. Một số bài báo gần đây đã sử dụng các kỹ thuật self-consistency và boosting để khuếch đại tiềm năng lý luận này hơn nữa [50,92,107]. Một thách thức được khám phá trong bài báo này là cách khai thác hiệu quả những kỹ năng mới này trong không gian đề xuất hội thoại, nơi sự khan hiếm dữ liệu đào tạo có sẵn đặt giá trị cao cho những loại phương pháp học hiệu quả mẫu này.

Bộ dữ liệu CRS. Đánh giá CRS là khó khăn một phần do tính chất tạo sinh và mở của đối thoại sáng kiến hỗn hợp (xem ví dụ [39] để có một thảo luận chi tiết hơn). Nhiều bộ dữ liệu CRS phổ biến dựa trên các lĩnh vực tương đối nhỏ như phim và chỉ là hội thoại, tức là các đề xuất được hệ thống cung cấp trực tiếp trong đối thoại mà không có khái niệm về bảng đề xuất hoặc các yếu tố trực quan khác (xem ví dụ [31,42,49,114]). Những bộ dữ liệu này dựa vào các nhân viên crowdsource để cung cấp ví dụ về phát biểu hệ thống tốt và các đề xuất được coi là chân lý cơ bản. Một vài bộ dữ liệu CRS khác được điều chỉnh từ các bộ dữ liệu không hội thoại liên quan đến các lĩnh vực quy mô lớn như thương mại điện tử hoặc đánh giá Yelp [45,112,114]. Tuy nhiên trong trường hợp này, các cuộc hội thoại được tạo ra hoặc tổng hợp hoặc thông qua thay thế từ các nguồn khác, và quá cứng nhắc so với đối thoại con người thực tế. Trong bài báo này, chúng tôi tập trung vào các đề xuất trên kho quy mô lớn với các bảng đề xuất khác biệt với đối thoại, một thiết lập không phù hợp gọn gàng với bất kỳ benchmark offline hiện có nào. Như công việc tương lai, chúng tôi đang lên kế hoạch phát hành các đánh giá con người và một bộ dữ liệu công khai để đánh giá định lượng các lựa chọn thiết kế trong RecLLM.

Quản lý Đối thoại. Các CRS sơ khai không dựa vào ngôn ngữ tự nhiên mà thay vào đó dựa vào các hình thức đơn giản của khai thác sở thích bởi hệ thống và "phê bình" bởi người dùng [7,51,57]. Khi các đề xuất hội thoại với giao diện ngôn ngữ tự nhiên lần đầu xuất hiện, chúng rất dựa vào quy tắc và hạn chế trong khả năng xử lý các tương tác sáng kiến hỗn hợp [3,85]. Sau đó, các CRS với tạo và hiểu ngôn ngữ dựa trên mô hình xuất hiện, mặc dù chúng có xu hướng vẫn tập trung hẹp vào các vấn đề như khi nào nên đặt câu hỏi cho người dùng so với hiển thị đề xuất, và đặt câu hỏi gì [16,83,110,112]. Các công trình khác đã khám phá việc học các mô-đun quản lý đối thoại linh hoạt hơn end-to-end, thường bằng cách fine-tuning các mô hình ngôn ngữ trên các đối thoại được thu thập từ các nhân viên crowdsource [11,42,49,67], mặc dù một nghiên cứu gần đây đã chỉ ra rằng cần có thêm tiến bộ để làm cho những hệ thống này hữu ích thực tế [38]. Trong một số trường hợp, cách tiếp cận end-to-end đã được mở rộng để đồng thời đào tạo một mô-đun đề xuất mục riêng biệt cùng với đối thoại [19,45,46,90]. Kiến trúc quản lý đối thoại LLM thống nhất từ Phần 3.1 xây dựng dựa trên công việc trước đó này bằng:

• Tích hợp với một mô-đun đề xuất có thể xử lý kho quy mô lớn.

• Học các biểu diễn ngôn ngữ tự nhiên nội bộ như các tạo phẩm theo dõi trạng thái đối thoại và hướng dẫn tự học cùng với các phát biểu đối thoại cuối cùng.

• Kết hợp các đầu vào ngôn ngữ tự nhiên như hồ sơ người dùng và biểu diễn văn bản của bảng đề xuất từ các nguồn bên ngoài.

Đề xuất / Giải thích. Trong [105], các tác giả định nghĩa một khung khái niệm cho Retrieval Enhanced Machine Learning; khung của chúng tôi được định nghĩa trong Phần 3.2.1 tương tự về bản chất nhưng được đơn giản hóa và tập trung vào việc nắm bắt các cách tiếp cận hiện có đối với truy xuất trong lĩnh vực đề xuất. Một chủ đề tổng thể của bài báo này là cách tích hợp đúng cách LLM với các tài nguyên bên ngoài, đặc biệt là động cơ đề xuất và hồ sơ người dùng, để xây dựng CRS tốt hơn. Một số nghiên cứu trước đây [8,61,73,86] khám phá với việc điều chỉnh các hệ thống hội thoại thông qua các minh chứng con người để thực hiện các cuộc gọi đến API tìm kiếm bên ngoài, nhưng không phải cho các đề xuất trên kho lớn. Tổng quát hơn, đó là một lĩnh vực nghiên cứu cơ bản trong học máy để bổ sung các mô hình học sâu với bộ nhớ ngoài [29,97,99], và đã được chứng minh rằng việc cho LLM khả năng truy xuất từ các kho bên ngoài có thể cải thiện hiệu suất trên các nhiệm vụ như trả lời câu hỏi và giảm ảo giác [4, 48, 79].

Khả năng giải thích đã là một mối quan tâm lâu dài trong hệ thống đề xuất [111] và một số công trình trước đây đã khám phá việc đồng thời tạo ra lời giải thích và đề xuất trong các hệ thống đề xuất truyền thống hơn [11–13,23,58,91,113]. Gần đây, LLM đã được sử dụng để giải thích các bộ phân loại và cũng tăng cường hiệu suất của chúng [44,62,72]. LLM cũng đã được sử dụng cho xếp hạng tài liệu [41,64,68]; tuy nhiên, chúng tôi không biết về các nỗ lực trước đây để áp dụng chúng vào các vấn đề xếp hạng trong bối cảnh CRS hoặc trên các kho quy mô lớn nơi các mục được đại diện bởi siêu dữ liệu không đồng nhất, như chúng tôi làm trong RecLLM. Loại lời giải thích nào mà một hệ thống đề xuất nên chia sẻ là một câu hỏi khó khăn (xem ví dụ [26,66]); trong RecLLM, chúng tôi hiện có hệ thống đưa ra các lý giải ngôn ngữ tự nhiên post hoc cho các bảng mục, mặc dù điều này vẫn để lại câu hỏi mở về cách xác minh tính đúng đắn của chúng.

Hồ sơ Người dùng. Một số công trình gần đây khám phá việc trích xuất hồ sơ người dùng ngôn ngữ tự nhiên minh bạch để cá nhân hóa các chatbot mở [56,101,109], và hệ thống đề xuất [2,70,87]. Đề xuất của chúng tôi từ Phần 3.3 có lẽ liên quan gần nhất với BlenderBot [80], cũng chia vấn đề thành các giai đoạn trích xuất, kích hoạt, truy xuất và tạo ra riêng biệt.

Mô phỏng / Đào tạo quy mô lớn. Các trình mô phỏng người dùng khác nhau đã được xây dựng để đào tạo và đánh giá hệ thống đề xuất, thường để hỗ trợ thử nghiệm với các thuật toán học tăng cường [36, 77, 108, 115]. Gần đây cũng có một sự gia tăng trong nghiên cứu sử dụng LLM để tạo ra dữ liệu tổng hợp cho việc đào tạo hệ thống đối thoại và bộ phân loại văn bản [18,59,69,103]. Đặc biệt liên quan là Unsupervised Data Generation [93], trong đó một LLM nhận một mô tả của một nhãn mong muốn và sau đó tạo ra một đầu vào phù hợp với nhãn. Cặp đầu vào / nhãn này sau đó trở thành một ví dụ tổng hợp có thể được sử dụng để đào tạo. Mô phỏng có kiểm soát từ phần 4.1 sử dụng một nguyên tắc tương tự nơi chúng tôi điều kiện trên một biến tiềm ẩn để tạo ra một phiên mô phỏng và sau đó sử dụng biến tiềm ẩn như một nhãn để điều chỉnh. Tuy nhiên, chúng tôi đang cố gắng tạo ra toàn bộ cuộc hội thoại (được tạo ra một phần bởi một hệ thống ngoài tầm kiểm soát của trình mô phỏng) và các kỹ thuật tinh vi hơn so với prompting few-shot cơ bản có khả năng được yêu cầu.

Trong [33,63,100], một mô hình ngôn ngữ được đào tạo trước được điều chỉnh để xử lý tài liệu như một phần của mô hình truy xuất dual encoder, và trong [32] điều này được mở rộng cho các cuộc hội thoại đầy đủ như trong đề xuất Dual Encoder Tổng quát từ Phần 4.2. Khi các nhãn chân lý cơ bản không cho phép một hàm loss hoàn toàn khả vi (như trong Tra cứu API Tìm kiếm), [65,82] cho thấy vẫn hiệu quả để điều chỉnh LLM cho các nhiệm vụ tạo ngôn ngữ sử dụng các kỹ thuật bắt nguồn từ học tăng cường. Các công trình khác [14,81] cũng sử dụng học tăng cường để điều chỉnh LLM cho đối thoại mở hoặc dựa trên nhiệm vụ sử dụng các tín hiệu phần thưởng được suy luận từ các cuộc hội thoại (ví dụ thông qua phân tích tình cảm hoặc một khái niệm về hoàn thành nhiệm vụ). Đề xuất để điều chỉnh LLM trình quản lý đối thoại trong Phần 4.2 là một ví dụ về Reinforcement Learning from Human Feedback [1,27,65], một kỹ thuật thường được sử dụng để dạy LLM tuân theo hướng dẫn và căn chỉnh tốt hơn với các giá trị con người.

6 NGUYÊN MẪU RECLLM

Chúng tôi đã xây dựng một nguyên mẫu RecLLM ban đầu dựa trên đề cương được chia sẻ trong bài báo này. Truy xuất hiện được triển khai thông qua Tra cứu API Tìm kiếm (xem Phần 3.2.1) sử dụng học few-shot trong ngữ cảnh và API tìm kiếm YouTube công khai. LaMDA [86] hiện được sử dụng như LLM cơ bản cung cấp năng lượng cho quản lý đối thoại, đề xuất và giải thích, tích hợp hồ sơ người dùng và mô phỏng người dùng trong hệ thống. Trong Phụ lục A, chúng tôi chia sẻ các phiên mẫu từ RecLLM chứng minh một số năng lực cốt lõi của nó.

7 CÂN NHẮC ĐẠO ĐỨC

Chúng tôi tin rằng bằng cách tận dụng các mô hình ngôn ngữ lớn trong CRS, chúng ta có thể giảm thiểu một số vấn đề đạo đức thách thức đã được ghi nhận trong nhiều hệ thống đề xuất. RecLLM có những tính chất mong muốn sau:

• Một mô-đun đề xuất lý luận về các thuộc tính của các mục và ít dựa vào học từ dữ liệu tương tác như nhấp chuột có nhiễu và có thể thúc đẩy những thành kiến không mong muốn.

• Khả năng đưa ra các lý giải ngôn ngữ tự nhiên về lý do tại sao một số đề xuất nhất định được hiển thị, mà người dùng sau đó có thể xác thực.

• Cơ hội cho người dùng kiểm soát các đề xuất của họ theo cách tinh tế thông qua ngôn ngữ.

• Cá nhân hóa minh bạch thông qua hồ sơ người dùng có thể hiểu và chỉnh sửa được.

Mặt khác, hệ thống được đề xuất của chúng tôi dựa rất nhiều vào các mô hình ngôn ngữ lớn và do đó kế thừa tất cả các vấn đề nổi tiếng của chúng tập trung xung quanh thành kiến xã hội được học thông qua đào tạo trước, ảo giác và sử dụng tài nguyên đắt đỏ [96]. Các kiểm soát khác nhau được bao gồm để ràng buộc LLM với nhiệm vụ đề xuất hội thoại, nhưng những cái này không thể hoàn toàn rửa sạch các vấn đề cố hữu của chúng. Tiến bộ đáng kể hơn nữa cần được thực hiện trong các lĩnh vực như khử thiên vị, cơ sở trong tính thật và phục vụ hiệu quả trước khi chúng ta có thể triển khai an toàn loại hệ thống này trong môi trường sản xuất.

8 KẾT LUẬN VÀ CÔNG VIỆC TƯƠNG LAI

Trong bài báo này, chúng tôi xem xét kiến trúc hệ thống của hệ thống đề xuất hội thoại và xác định các lĩnh vực mà các mô hình ngôn ngữ lớn có thể mở khóa các khả năng mới, cùng với những thách thức kỹ thuật xuất hiện thông qua việc sử dụng chúng. Cụ thể, chúng tôi tái tưởng tượng cách LLM có thể biến đổi quản lý đối thoại, truy xuất, xếp hạng và hồ sơ người dùng để cải thiện chất lượng hệ thống, mang lại cho người dùng quyền kiểm soát lớn hơn và tăng tính minh bạch trong toàn hệ thống. Chúng tôi tập trung vào cách xây dựng CRS quy mô lớn end-to-end mà không giả định truy cập vào dữ liệu nhật ký đến từ sản phẩm hiện có, bằng cách sử dụng khả năng tổng quát hóa của LLM và tạo ra dữ liệu đào tạo tổng hợp sử dụng các trình mô phỏng người dùng được hỗ trợ bởi LLM. Như một bằng chứng khái niệm, chúng tôi giới thiệu RecLLM và chia sẻ các cuộc hội thoại ví dụ làm nổi bật chức năng đa dạng của nó. Hy vọng của chúng tôi là lộ trình này có thể tăng tốc tiến bộ hướng tới một thế giới nơi các CRS có thể kiểm soát và giải thích được cho phép người dùng khám phá nội dung trong một hệ sinh thái hệ thống đề xuất lành mạnh hơn.

Một số mục quan trọng cho công việc tương lai bao gồm:

• Chúng tôi đang lên kế hoạch phát hành các đánh giá con người và một bộ dữ liệu công khai dựa trên hệ thống của chúng tôi để đánh giá định lượng các lựa chọn thiết kế cho RecLLM và giúp cộng đồng nghiên cứu tốt hơn các CRS trong bối cảnh đa phương thức, quy mô lớn.

• Trong bài báo này, chúng tôi giả định một bối cảnh đơn giản hóa nơi người dùng chỉ tương tác với hệ thống thông qua cuộc hội thoại. Chúng tôi muốn tổng quát hóa hệ thống của mình để xử lý các tình huống thực tế hơn nơi người dùng cung cấp phản hồi thông qua các kênh khác như nhấp vào các mục hoặc nút thích. Chúng tôi cũng muốn xem xét các giao diện người dùng hệ thống đề xuất phức tạp hơn chứa các cấu trúc phân cấp như kệ mục thay vì chỉ bảng phẳng.

• Chúng tôi đã đề xuất các ý tưởng cho việc điều chỉnh quy mô lớn của các mô-đun hệ thống chính dựa trên dữ liệu được tạo tổng hợp, nhưng hiện tại RecLLM dựa hoàn toàn vào học few-shot trong ngữ cảnh hoặc điều chỉnh trên lượng nhỏ dữ liệu được thu thập thông qua crowdsourcing. Việc chứng minh thành công những ý tưởng này sẽ rất quan trọng để xử lý đúng cách các kho mục khổng lồ và không gian đầy đủ của các cuộc hội thoại có thể.

• Chúng tôi muốn hỗ trợ các trường hợp sử dụng mới phát sinh tự nhiên trong đối thoại đề xuất hội thoại sáng kiến hỗn hợp, như trả lời câu hỏi về các mục kho.

9 LỜI CẢM ƠN

Chúng tôi muốn cảm ơn Filip Radlinski, Karan Singhal, Abhinav Rastogi, Raghav Gupta và Yinlam Chow vì phản hồi hữu ích về các bản thảo của bài báo này.

TÀI LIỆU THAM KHẢO

[1]Yuntao Bai, Andy Jones, Kamal Ndousse, Amanda Askell, Anna Chen, Nova DasSarma, Dawn Drain, Stanislav Fort, Deep Ganguli, Tom Henighan, et al. 2022. Training a helpful and harmless assistant with reinforcement learning from human feedback. arXiv preprint arXiv:2204.05862 (2022).

[2]Krisztian Balog, Filip Radlinski, and Shushan Arakelyan. 2019. Transparent, scrutable and explainable user models for personalized recommendation. In Proceedings of the 42nd international acm sigir conference on research and development in information retrieval. 265–274.

[3]Nicholas J Belkin, Colleen Cool, Adelheit Stein, and Ulrich Thiel. 1995. Cases, scripts, and information-seeking strategies: On the design of interactive information retrieval systems. Expert systems with applications 9, 3 (1995), 379–395.

[4]Sebastian Borgeaud, Arthur Mensch, Jordan Hoffmann, Trevor Cai, Eliza Rutherford, Katie Millican, George van den Driessche, Jean-Baptiste Lespiau, Bogdan Damoc, Aidan Clark, et al. 2021. Improving language models by retrieving from trillions of tokens. arXiv preprint arXiv:2112.04426 (2021).

[5]Djallel Bouneffouf, Irina Rish, and Charu Aggarwal. 2020. Survey on applications of multi-armed and contextual bandits. In 2020 IEEE Congress on Evolutionary Computation (CEC). IEEE, 1–8.

[6]Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. 2020. Language models are few-shot learners. Advances in neural information processing systems 33 (2020), 1877–1901.

[7]Robin D Burke, Kristian J Hammond, and BC Yound. 1997. The FindMe approach to assisted browsing. IEEE Expert 12, 4 (1997), 32–40.

[8]Bill Byrne, Karthik Krishnamoorthi, Saravanan Ganesh, and Mihir Sanjay Kale. 2020. TicketTalk: Toward human-level performance with end-to-end, transaction-based dialog systems. arXiv preprint arXiv:2012.12458 (2020).

[9]Wanling Cai and Li Chen. 2020. Predicting user intents and satisfaction with dialogue-based conversational recommendations. In Proceedings of the 28th ACM Conference on User Modeling, Adaptation and Personalization. 33–42.

[10] Zhe Cao, Tao Qin, Tie-Yan Liu, Ming-Feng Tsai, and Hang Li. 2007. Learning to rank: from pairwise approach to listwise approach. In Proceedings of the 24th international conference on Machine learning. 129–136.

[11] Qibin Chen, Junyang Lin, Yichang Zhang, Ming Ding, Yukuo Cen, Hongxia Yang, and Jie Tang. 2019. Towards knowledge-based recommender dialog system. arXiv preprint arXiv:1908.05391 (2019).

[12] Xu Chen, Hongteng Xu, Yongfeng Zhang, Jiaxi Tang, Yixin Cao, Zheng Qin, and Hongyuan Zha. 2018. Sequential recommendation with user memory networks. In Proceedings of the eleventh ACM international conference on web search and data mining. 108–116.

[13] Xu Chen, Yongfeng Zhang, and Zheng Qin. 2019. Dynamic explainable recommendation based on neural attentive models. In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 33. 53–60.

[14] Yinlam Chow, Aza Tulepbergenov, Ofir Nachum, MoonKyung Ryu, Mohammad Ghavamzadeh, and Craig Boutilier. 2022. A Mixture-of-Expert Approach to RL-based Dialogue Management. arXiv preprint arXiv:2206.00059 (2022).

[15] Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, et al. 2022. Palm: Scaling language modeling with pathways. arXiv preprint arXiv:2204.02311 (2022).

[16] Konstantina Christakopoulou, Alex Beutel, Rui Li, Sagar Jain, and Ed H Chi. 2018. Q&R: A two-stage approach toward interactive recommendation. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. 139–148.

[17] Paul Covington, Jay Adams, and Emre Sargin. 2016. Deep Neural Networks for YouTube Recommendations. In Proceedings of the 10th ACM Conference on Recommender Systems. New York, NY, USA.

[18] Zhuyun Dai, Arun Tejasvi Chaganty, Vincent Y Zhao, Aida Amini, Qazi Mamunur Rashid, Mike Green, and Kelvin Guu. 2022. Dialog inpainting: Turning documents into dialogs. In International Conference on Machine Learning. PMLR, 4558–4586.

[19] Yang Deng, Yaliang Li, Fei Sun, Bolin Ding, and Wai Lam. 2021. Unified conversational recommendation policy learning via graph-based reinforcement learning. In Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval. 1431–1441.

[20] Linus W Dietz, Saadi Myftija, and Wolfgang Wörndl. 2019. Designing a conversational travel recommender system based on data-driven destination characterization. In ACM RecSys workshop on recommenders in tourism. 17–21.

[21] Chantat Eksombatchai, Pranav Jindal, Jerry Zitao Liu, Yuchen Liu, Rahul Sharma, Charles Sugnet, Mark Ulrich, and Jure Leskovec. 2018. Pixie: A system for recommending 3+ billion items to 200+ million users in real-time. In Proceedings of the 2018 world wide web conference. 1775–1784.

[22] Chongming Gao, Wenqiang Lei, Xiangnan He, Maarten de Rijke, and Tat-Seng Chua. 2021. Advances and challenges in conversational recommender systems: A survey. AI Open 2 (2021), 100–126.

[23] Jingyue Gao, Xiting Wang, Yasha Wang, and Xing Xie. 2019. Explainable recommendation through attentive multi-view learning. In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 33. 3622–3629.

[24] Jianfeng Gao, Chenyan Xiong, Paul Bennett, and Nick Craswell. 2022. Neural approaches to conversational information retrieval. arXiv preprint arXiv:2201.05176 (2022).

[25] Venkata Rama Kiran Garimella and Ingmar Weber. 2017. A long-term analysis of polarization on Twitter. In Eleventh international AAAI conference on web and social media.

[26] Fatih Gedikli, Dietmar Jannach, and Mouzhi Ge. 2014. How should I explain? A comparison of different explanation types for recommender systems. International Journal of Human-Computer Studies 72, 4 (2014), 367–382.

[27] Amelia Glaese, Nat McAleese, Maja Trębacz, John Aslanides, Vlad Firoiu, Timo Ewalds, Maribeth Rauh, Laura Weidinger, Martin Chadwick, Phoebe Thacker, et al. 2022. Improving alignment of dialogue agents via targeted human judgements. arXiv preprint arXiv:2209.14375 (2022).

[28] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. 2020. Generative adversarial networks. Commun. ACM 63, 11 (2020), 139–144.

[29] Alex Graves, Greg Wayne, and Ivo Danihelka. 2014. Neural turing machines. arXiv preprint arXiv:1410.5401 (2014).

[30] Ruiqi Guo, Quan Geng, David Simcha, Felix Chern, Sanjiv Kumar, and Xiang Wu. 2019. New Loss Functions for Fast Maximum Inner Product Search. CoRR abs/1908.10396 (2019). arXiv:1908.10396 http://arxiv.org/abs/1908.10396

[31] Shirley Anugrah Hayati, Dongyeop Kang, Qingxiaoyang Zhu, Weiyan Shi, and Zhou Yu. 2020. INSPIRED: Toward sociable recommendation dialog systems. arXiv preprint arXiv:2009.14306 (2020).

[32] Matthew Henderson, Iñigo Casanueva, Nikola Mrkšić, Pei-Hao Su, Tsung-Hsien Wen, and Ivan Vulić. 2019. ConveRT: Efficient and accurate conversational representations from transformers. arXiv preprint arXiv:1911.03688 (2019).

[33] Sebastian Hofstätter, Sheng-Chieh Lin, Jheng-Hong Yang, Jimmy Lin, and Allan Hanbury. 2021. Efficiently teaching an effective dense retriever with balanced topic aware sampling. In Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval. 113–122.

[34] Jie Huang and Kevin Chen-Chuan Chang. 2022. Towards Reasoning in Large Language Models: A Survey. arXiv preprint arXiv:2212.10403 (2022).

[35] Jiaxin Huang, Shixiang Shane Gu, Le Hou, Yuexin Wu, Xuezhi Wang, Hongkun Yu, and Jiawei Han. 2022. Large language models can self-improve. arXiv preprint arXiv:2210.11610 (2022).

[36] Eugene Ie, Chih-wei Hsu, Martin Mladenov, Vihan Jain, Sanmit Narvekar, Jing Wang, Rui Wu, and Craig Boutilier. 2019. Recsim: A configurable simulation platform for recommender systems. arXiv preprint arXiv:1909.04847 (2019).

[37] Dietmar Jannach and Li Chen. 2022. Conversational Recommendation: A Grand AI Challenge. arXiv preprint arXiv:2203.09126 (2022).

[38] Dietmar Jannach and Ahtsham Manzoor. 2020. End-to-End Learning for Conversational Recommendation: A Long Way to Go?. In IntRS@ RecSys. 72–76.

[39] Dietmar Jannach, Ahtsham Manzoor, Wanling Cai, and Li Chen. 2021. A survey on conversational recommender systems. ACM Computing Surveys (CSUR) 54, 5 (2021), 1–36.

[40] Ziwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan Su, Yan Xu, Etsuko Ishii, Yejin Bang, Andrea Madotto, and Pascale Fung. 2022. Survey of hallucination in natural language generation. Comput. Surveys (2022).

[41] Jia-Huei Ju, Jheng-Hong Yang, and Chuan-Ju Wang. 2021. Text-to-text Multi-view Learning for Passage Re-ranking. In Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval. 1803–1807.

[42] Dongyeop Kang, Anusha Balakrishnan, Pararth Shah, Paul Crook, Y-Lan Boureau, and Jason Weston. 2019. Recommendation as a communication game: Self-supervised bot-play for goal-oriented dialogue. arXiv preprint arXiv:1909.03922 (2019).

[43] Been Kim, Martin Wattenberg, Justin Gilmer, Carrie Cai, James Wexler, Fernanda Viegas, and Rory Sayres. 2017. Interpretability Beyond Feature Attribution: Quantitative Testing with Concept Activation Vectors (TCAV). (2017). https://doi.org/10.48550/ARXIV.1711.11279

[44] Andrew K Lampinen, Ishita Dasgupta, Stephanie CY Chan, Kory Matthewson, Michael Henry Tessler, Antonia Creswell, James L McClelland, Jane X Wang, and Felix Hill. 2022. Can language models learn from explanations in context? arXiv preprint arXiv:2204.02329 (2022).

[45] Wenqiang Lei, Xiangnan He, Yisong Miao, Qingyun Wu, Richang Hong, Min-Yen Kan, and Tat-Seng Chua. 2020. Estimation-action-reflection: Towards deep interaction between conversational and recommender systems. In Proceedings of the 13th International Conference on Web Search and Data Mining. 304–312.

[46] Wenqiang Lei, Gangyi Zhang, Xiangnan He, Yisong Miao, Xiang Wang, Liang Chen, and Tat-Seng Chua. 2020. Interactive path reasoning on graph for conversational recommendation. In Proceedings of the 26th acm sigkdd international conference on knowledge discovery & data mining. 2073–2083.

[47] Brian Lester, Rami Al-Rfou, and Noah Constant. 2021. The power of scale for parameter-efficient prompt tuning. arXiv preprint arXiv:2104.08691 (2021).

[48] Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel, et al. 2020. Retrieval-augmented generation for knowledge-intensive nlp tasks. Advances in Neural Information Processing Systems 33 (2020), 9459–9474.

[49] Raymond Li, Samira Ebrahimi Kahou, Hannes Schulz, Vincent Michalski, Laurent Charlin, and Chris Pal. 2018. Towards deep conversational recommendations. Advances in neural information processing systems 31 (2018).

[50] Yifei Li, Zeqi Lin, Shizhuo Zhang, Qiang Fu, Bei Chen, Jian-Guang Lou, and Weizhu Chen. 2022. On the Advance of Making Language Models Better Reasoners. arXiv preprint arXiv:2206.02336 (2022).

[51] Greg Linden, Steve Hanks, and Neal Lesh. 1997. Interactive assessment of user preference models: The automated travel assistant. In User Modeling. Springer, 67–78.

[52] Frederick Liu, Siamak Shakeri, Hongkun Yu, and Jing Li. 2021. EncT5: Fine-tuning T5 Encoder for Non-autoregressive Tasks. arXiv preprint arXiv:2110.08426 (2021).

[53] Yang Liu and Mirella Lapata. 2019. Hierarchical transformers for multi-document summarization. arXiv preprint arXiv:1905.13164 (2019).

[54] Jiaqi Ma, Zhe Zhao, Xinyang Yi, Ji Yang, Minmin Chen, Jiaxi Tang, Lichan Hong, and Ed H Chi. 2020. Off-policy learning in two-stage recommender systems. In Proceedings of The Web Conference 2020. 463–473.

[55] Masoud Mansoury, Himan Abdollahpouri, Mykola Pechenizkiy, Bamshad Mobasher, and Robin Burke. 2020. Feedback loop and bias amplification in recommender systems. In Proceedings of the 29th ACM international conference on information & knowledge management. 2145–2148.

[56] Pierre-Emmanuel Mazaré, Samuel Humeau, Martin Raison, and Antoine Bordes. 2018. Training millions of personalized dialogue agents. arXiv preprint arXiv:1809.01984 (2018).

[57] Kevin McCarthy, Yasser Salem, and Barry Smyth. 2010. Experience-based critiquing: Reusing critiquing experiences to improve conversational recommendation. In International Conference on Case-Based Reasoning. Springer, 480–494.

[58] James McInerney, Benjamin Lacker, Samantha Hansen, Karl Higley, Hugues Bouchard, Alois Gruson, and Rishabh Mehrotra. 2018. Explore, exploit, and explain: personalizing explainable recommendations with bandits. In Proceedings of the 12th ACM conference on recommender systems. 31–39.

[59] Shikib Mehri, Yasemin Altun, and Maxine Eskenazi. 2022. LAD: Language Models as Data for Zero-Shot Dialog. arXiv preprint arXiv:2207.14393 (2022).

[60] Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013. Efficient estimation of word representations in vector space. arXiv preprint arXiv:1301.3781 (2013).

[61] Reiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu, Long Ouyang, Christina Kim, Christopher Hesse, Shantanu Jain, Vineet Kosaraju, William Saunders, et al. 2021. WebGPT: Browser-assisted question-answering with human feedback. arXiv preprint arXiv:2112.09332 (2021).

[62] Sharan Narang, Colin Raffel, Katherine Lee, Adam Roberts, Noah Fiedel, and Karishma Malkan. 2020. Wt5?! training text-to-text models to explain their predictions. arXiv preprint arXiv:2004.14546 (2020).

[63] Jianmo Ni, Chen Qu, Jing Lu, Zhuyun Dai, Gustavo Hernández Ábrego, Ji Ma, Vincent Y Zhao, Yi Luan, Keith B Hall, Ming-Wei Chang, et al. 2021. Large dual encoders are generalizable retrievers. arXiv preprint arXiv:2112.07899 (2021).

[64] Rodrigo Nogueira, Zhiying Jiang, and Jimmy Lin. 2020. Document ranking with a pretrained sequence-to-sequence model. arXiv preprint arXiv:2003.06713 (2020).

[65] Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. 2022. Training language models to follow instructions with human feedback. arXiv preprint arXiv:2203.02155 (2022).

[66] Sunjeong Park and Lim Youn-kyung. 2019. Design considerations for explanations made by a recommender chatbot. In IASDR Conference 2019. IASDR.

[67] Gustavo Penha and Claudia Hauff. 2020. What does bert know about books, movies and music? probing bert for conversational recommendation. In Fourteenth ACM Conference on Recommender Systems. 388–397.

[68] Ronak Pradeep, Rodrigo Nogueira, and Jimmy Lin. 2021. The expando-mono-duo design pattern for text ranking with pretrained sequence-to-sequence models. arXiv preprint arXiv:2101.05667 (2021).

[69] Raul Puri, Ryan Spring, Mostofa Patwary, Mohammad Shoeybi, and Bryan Catanzaro. 2020. Training question answering models from synthetic data. arXiv preprint arXiv:2002.09599 (2020).

[70] Filip Radlinski, Krisztian Balog, Fernando Diaz, Lucas Dixon, and Ben Wedin. 2022. On Natural Language User Profiles for Transparent and Scrutable Recommendation. arXiv preprint arXiv:2205.09403 (2022).

[71] Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, Peter J Liu, et al. 2020. Exploring the limits of transfer learning with a unified text-to-text transformer. J. Mach. Learn. Res. 21, 140 (2020), 1–67.

[72] Nazneen Fatema Rajani, Bryan McCann, Caiming Xiong, and Richard Socher. 2019. Explain yourself! leveraging language models for commonsense reasoning. arXiv preprint arXiv:1906.02361 (2019).

[73] Abhinav Rastogi, Xiaoxue Zang, Srinivas Sunkara, Raghav Gupta, and Pranav Khaitan. 2020. Towards scalable multi-domain conversational agents: The schema-guided dialogue dataset. In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 34. 8689–8696.

[74] Xuhui Ren, Hongzhi Yin, Tong Chen, Hao Wang, Zi Huang, and Kai Zheng. 2021. Learning to ask appropriate questions in conversational recommendation. In Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval. 808–817.

[75] Laria Reynolds and Kyle McDonell. 2021. Prompt programming for large language models: Beyond the few-shot paradigm. In Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems. 1–7.

[76] Francesco Ricci and Quang Nhat Nguyen. 2007. Acquiring and revising preferences in a critique-based mobile recommender system. IEEE Intelligent systems 22, 3 (2007), 22–29.

[77] David Rohde, Stephen Bonner, Travis Dunlop, Flavian Vasile, and Alexandros Karatzoglou. 2018. Recogym: A reinforcement learning environment for the problem of product recommendation in online advertising. arXiv preprint arXiv:1808.00720 (2018).

[78] Tobias Schnabel, Paul N Bennett, Susan T Dumais, and Thorsten Joachims. 2018. Short-term satisfaction and long-term coverage: Understanding how users tolerate algorithmic exploration. In Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining. 513–521.

[79] Kurt Shuster, Spencer Poff, Moya Chen, Douwe Kiela, and Jason Weston. 2021. Retrieval augmentation reduces hallucination in conversation. arXiv preprint arXiv:2104.07567 (2021).

[80] Kurt Shuster, Jing Xu, Mojtaba Komeili, Da Ju, Eric Michael Smith, Stephen Roller, Megan Ung, Moya Chen, Kushal Arora, Joshua Lane, et al. 2022. BlenderBot 3: a deployed conversational agent that continually learns to responsibly engage. arXiv preprint arXiv:2208.03188 (2022).

[81] Charlie Snell, Sherry Yang, Justin Fu, Yi Su, and Sergey Levine. 2022. Context-Aware Language Modeling for Goal-Oriented Dialogue Systems. arXiv preprint arXiv:2204.10198 (2022).

[82] Nisan Stiennon, Long Ouyang, Jeffrey Wu, Daniel Ziegler, Ryan Lowe, Chelsea Voss, Alec Radford, Dario Amodei, and Paul F Christiano. 2020. Learning to summarize with human feedback. Advances in Neural Information Processing Systems 33 (2020), 3008–3021.

[83] Yueming Sun and Yi Zhang. 2018. Conversational recommender system. In The 41st international acm sigir conference on research & development in information retrieval. 235–244.

[84] Yi Tay, Vinh Q Tran, Mostafa Dehghani, Jianmo Ni, Dara Bahri, Harsh Mehta, Zhen Qin, Kai Hui, Zhe Zhao, Jai Gupta, et al. 2022. Transformer memory as a differentiable search index. arXiv preprint arXiv:2202.06991 (2022).

[85] Cynthia A Thompson, Mehmet H Goker, and Pat Langley. 2004. A personalized system for conversational recommendations. Journal of Artificial Intelligence Research 21 (2004), 393–428.

[86] Romal Thoppilan, Daniel De Freitas, Jamie Hall, Noam Shazeer, Apoorv Kulshreshtha, Heng-Tze Cheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du, et al. 2022. Lamda: Language models for dialog applications. arXiv preprint arXiv:2201.08239 (2022).

[87] Ghazaleh H Torbati, Andrew Yates, and Gerhard Weikum. 2021. You get what you chat: Using conversations to personalize search-based recommendations. In European Conference on Information Retrieval. Springer, 207–223.

[88] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. Advances in neural information processing systems 30 (2017).

[89] Tu Vu, Brian Lester, Noah Constant, Rami Al-Rfou, and Daniel Cer. 2021. Spot: Better frozen model adaptation through soft prompt transfer. arXiv preprint arXiv:2110.07904 (2021).

[90] Lingzhi Wang, Huang Hu, Lei Sha, Can Xu, Kam-Fai Wong, and Daxin Jiang. 2021. Finetuning Large-Scale Pre-trained Language Models for Conversational Recommendation with Knowledge Graph. CoRR abs/2110.07477 (2021). arXiv:2110.07477 https://arxiv.org/abs/2110.07477

[91] Xiting Wang, Yiru Chen, Jie Yang, Le Wu, Zhengtao Wu, and Xing Xie. 2018. A reinforcement learning framework for explainable recommendation. In 2018 IEEE international conference on data mining (ICDM). IEEE, 587–596.

[92] Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, and Denny Zhou. 2022. Self-consistency improves chain of thought reasoning in language models. arXiv preprint arXiv:2203.11171 (2022).

[93] Zirui Wang, Adams Wei Yu, Orhan Firat, and Yuan Cao. 2021. Towards zero-label language learning. arXiv preprint arXiv:2109.09193 (2021).

[94] Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, et al. 2022. Emergent abilities of large language models. arXiv preprint arXiv:2206.07682 (2022).

[95] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Ed Chi, Quoc Le, and Denny Zhou. 2022. Chain of thought prompting elicits reasoning in large language models. arXiv preprint arXiv:2201.11903 (2022).

[96] Laura Weidinger, John Mellor, Maribeth Rauh, Conor Griffin, Jonathan Uesato, Po-Sen Huang, Myra Cheng, Mia Glaese, Borja Balle, Atoosa Kasirzadeh, et al. 2021. Ethical and social risks of harm from language models. arXiv preprint arXiv:2112.04359 (2021).

[97] Jason Weston, Sumit Chopra, and Antoine Bordes. 2014. Memory networks. arXiv preprint arXiv:1410.3916 (2014).

[98] Jason Weston, Emily Dinan, and Alexander H. Miller. 2018. Retrieve and Refine: Improved Sequence Generation Models For Dialogue. CoRR abs/1808.04776 (2018). arXiv:1808.04776 http://arxiv.org/abs/1808.04776

[99] Yuhuai Wu, Markus N. Rabe, DeLesley S. Hutchins, and Christian Szegedy. 2022. Memorizing Transformers. ArXiv abs/2203.08913 (2022).

[100] Lee Xiong, Chenyan Xiong, Ye Li, Kwok-Fung Tang, Jialin Liu, Paul Bennett, Junaid Ahmed, and Arnold Overwijk. 2020. Approximate nearest neighbor negative contrastive learning for dense text retrieval. arXiv preprint arXiv:2007.00808 (2020).

[101] Jing Xu, Arthur Szlam, and Jason Weston. 2021. Beyond goldfish memory: Long-term open-domain conversation. arXiv preprint arXiv:2107.07567 (2021).

[102] Xinyang Yi, Ji Yang, Lichan Hong, Derek Zhiyuan Cheng, Lukasz Heldt, Aditee Kumthekar, Zhe Zhao, Li Wei, and Ed Chi. 2019. Sampling-bias-corrected neural modeling for large corpus item recommendations. In Proceedings of the 13th ACM Conference on Recommender Systems. 269–277.

[103] Kang Min Yoo, Dongju Park, Jaewook Kang, Sang-Woo Lee, and Woomyeong Park. 2021. GPT3Mix: Leveraging large-scale language models for text augmentation. arXiv preprint arXiv:2104.08826 (2021).

[104] Yisong Yue, Rajan Patel, and Hein Roehrig. 2010. Beyond Position Bias: Examining Result Attractiveness as a Source of Presentation Bias in Clickthrough Data. In Proceedings of the 19th International Conference on World Wide Web (WWW '10). Association for Computing Machinery, New York, NY, USA, 1011–1018. https://doi.org/10.1145/1772690.1772793

[105] Hamed Zamani, Fernando Diaz, Mostafa Dehghani, Donald Metzler, and Michael Bendersky. 2022. Retrieval-Enhanced Machine Learning. arXiv preprint arXiv:2205.01230 (2022).

[106] Hamed Zamani, Johanne R Trippas, Jeff Dalton, and Filip Radlinski. 2022. Conversational information seeking. arXiv preprint arXiv:2201.08808 (2022).

[107] Eric Zelikman, Yuhuai Wu, and Noah D Goodman. 2022. Star: Bootstrapping reasoning with reasoning. arXiv preprint arXiv:2203.14465 (2022).

[108] Shuo Zhang and Krisztian Balog. 2020. Evaluating conversational recommender systems via user simulation. In Proceedings of the 26th acm sigkdd international conference on knowledge discovery & data mining. 1512–1520.

[109] Saizheng Zhang, Emily Dinan, Jack Urbanek, Arthur Szlam, Douwe Kiela, and Jason Weston. 2018. Personalizing dialogue agents: I have a dog, do you have pets too? arXiv preprint arXiv:1801.07243 (2018).

[110] Xiaoying Zhang, Hong Xie, Hang Li, and John CS Lui. 2020. Conversational contextual bandit: Algorithm and application. In Proceedings of the web conference 2020. 662–672.

[111] Yongfeng Zhang, Xu Chen, et al. 2020. Explainable recommendation: A survey and new perspectives. Foundations and Trends ®in Information Retrieval 14, 1 (2020), 1–101.

[112] Yongfeng Zhang, Xu Chen, Qingyao Ai, Liu Yang, and W Bruce Croft. 2018. Towards conversational search and recommendation: System ask, user respond. In Proceedings of the 27th acm international conference on information and knowledge management. 177–186.

[113] Yongfeng Zhang, Guokun Lai, Min Zhang, Yi Zhang, Yiqun Liu, and Shaoping Ma. 2014. Explicit factor models for explainable recommendation based on phrase-level sentiment analysis. In Proceedings of the 37th international ACM SIGIR conference on Research & development in information retrieval. 83–92.

[114] Kun Zhou, Yuanhang Zhou, Wayne Xin Zhao, Xiaoke Wang, and Ji-Rong Wen. 2020. Towards topic-guided conversational recommender system. arXiv preprint arXiv:2010.04125 (2020).

[115] Lixin Zou, Long Xia, Pan Du, Zhuo Zhang, Ting Bai, Weidong Liu, Jian-Yun Nie, and Dawei Yin. 2020. Pseudo Dyna-Q: A reinforcement learning framework for interactive recommendation. In Proceedings of the 13th International Conference on Web Search and Data Mining. 816–824.

A MẪU RECLLM

Trong phụ lục này, chúng tôi chia sẻ một số lượng nhỏ mẫu có nghĩa là để chứng minh một số năng lực cốt lõi của RecLLM. Chúng được nhóm thành các danh mục sau: Tổng quan Hệ thống Chung, Tinh chỉnh và Giải thích, Cuộc hội thoại Mô phỏng, Khám phá Chủ đề và Kết hợp Hồ sơ Người dùng. Lưu ý rằng trong những mẫu này, chúng tôi chỉ hiển thị bảng đề xuất cuối cùng, mặc dù trong thực tế bảng đề xuất phát triển trong suốt cuộc hội thoại trong giao diện người dùng RecLLM.

--- TRANG 15 ---
Hình 11: Mẫu Tổng quan Hệ thống Chung 1

--- TRANG 16 ---
Hình 12: Mẫu Tổng quan Hệ thống Chung 2

--- TRANG 17 ---
Hình 13: Mẫu Tinh chỉnh và Giải thích 1

--- TRANG 18 ---
Hình 14: Mẫu Tinh chỉnh và Giải thích 2

Hình 15: Mẫu Tinh chỉnh và Giải thích 3

--- TRANG 19 ---
Hình 16: Mẫu Cuộc hội thoại Mô phỏng 1

--- TRANG 20 ---
Hình 17: Mẫu Cuộc hội thoại Mô phỏng 2

--- TRANG 21 ---
Hình 18: Mẫu Cuộc hội thoại Mô phỏng 3

Hình 19: Mẫu Khám phá 1

--- TRANG 22 ---
Hình 20: Mẫu Khám phá 2

Hình 21: Mẫu Khám phá 3

--- TRANG 23 ---
Hình 22: Một ví dụ hồ sơ người dùng

Hình 23: Mẫu Kết hợp Hồ sơ Người dùng 1

--- TRANG 24 ---
Hình 24: Mẫu Kết hợp Hồ sơ Người dùng 2

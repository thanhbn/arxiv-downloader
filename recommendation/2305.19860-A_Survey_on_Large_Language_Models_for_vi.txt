# Khảo sát về Mô hình Ngôn ngữ Lớn cho Hệ thống Đề xuất

Likang Wu1,2, Zhi Zheng1,2†, Zhaopeng Qiu2†, Hao Wang1*,
Hongchao Gu1, Tingjia Shen1, Chuan Qin2, Chen Zhu2, Hengshu
Zhu2*, Qi Liu1, Hui Xiong3*, Enhong Chen1*

1Phòng thí nghiệm Trọng điểm Nhà nước về Trí tuệ Nhận thức, Đại học Khoa học và Công nghệ Trung Quốc, Đường Cẩm Trai, Hợp Phì, 230026, An Huy, Trung Quốc.
2Phòng thí nghiệm Khoa học Nghề nghiệp, BOSS Zhipin, Bắc Kinh, 100020, Trung Quốc.
3Đại học Khoa học và Công nghệ Hồng Kông (Quảng Châu),
Quảng Châu, 510000, Quảng Đông, Trung Quốc.

*Tác giả liên hệ. E-mail: wanghao3@ustc.edu.cn;
zhuhengshu@gmail.com; xionghui@ust.hk; cheneh@ustc.edu.cn;
Tác giả đóng góp: wulk@mail.ustc.edu.cn;
zhengzhi97@mail.ustc.edu.cn; zhpengqiu@gmail.com;
hcgu@mail.ustc.edu.cn; jts stj@mail.ustc.edu.cn;
chuanqin0426@gmail.com; zc3930155@gmail.com; qiliuql@ustc.edu.cn;
†Đóng góp ngang nhau.

## Tóm tắt

Mô hình Ngôn ngữ Lớn (LLM) đã nổi lên như những công cụ mạnh mẽ trong lĩnh vực Xử lý Ngôn ngữ Tự nhiên (NLP) và gần đây đã thu hút được sự chú ý đáng kể trong lĩnh vực Hệ thống Đề xuất (RS). Những mô hình này, được huấn luyện trên lượng dữ liệu khổng lồ sử dụng học tự giám sát, đã thể hiện thành công đáng kể trong việc học các biểu diễn phổ quát và có tiềm năng cải thiện nhiều khía cạnh khác nhau của hệ thống đề xuất thông qua một số kỹ thuật chuyển đổi hiệu quả như tinh chỉnh, điều chỉnh prompt, v.v. Khía cạnh quan trọng của việc khai thác sức mạnh của mô hình ngôn ngữ trong việc nâng cao chất lượng đề xuất là việc sử dụng các biểu diễn chất lượng cao của đặc trưng văn bản và phạm vi bao phủ rộng lớn của kiến thức bên ngoài để thiết lập mối tương quan giữa các mục và người dùng. Để cung cấp hiểu biết toàn diện về các hệ thống đề xuất dựa trên LLM hiện có, khảo sát này trình bày một phân loại tách các mô hình này thành hai mô hình chính, tương ứng là LLM Phân biệt cho Đề xuất (DLLM4Rec) và LLM Sinh tạo cho Đề xuất (GLLM4Rec), với mô hình sau được sắp xếp một cách có hệ thống lần đầu tiên. Hơn nữa, chúng tôi xem xét và phân tích một cách có hệ thống các hệ thống đề xuất dựa trên LLM hiện có trong từng mô hình, cung cấp những hiểu biết sâu sắc về phương pháp luận, kỹ thuật và hiệu suất của chúng. Ngoài ra, chúng tôi xác định những thách thức chính và một số phát hiện có giá trị để cung cấp cảm hứng cho các nhà nghiên cứu và thực hành. Chúng tôi cũng đã tạo một kho lưu trữ GitHub để lập chỉ mục các bài báo và tài nguyên liên quan về LLM cho đề xuất*.

**Từ khóa**: Mô hình Ngôn ngữ Lớn, Hệ thống Đề xuất

## 1 Giới thiệu

Hệ thống đề xuất đóng vai trò quan trọng trong việc hỗ trợ người dùng tìm kiếm các mục hoặc nội dung có liên quan và được cá nhân hóa. Với sự xuất hiện của Mô hình Ngôn ngữ Lớn (LLM) trong Xử lý Ngôn ngữ Tự nhiên (NLP), đã có sự quan tâm ngày càng tăng trong việc khai thác sức mạnh của những mô hình này để cải thiện hệ thống đề xuất.

Lợi thế chính của việc tích hợp LLM vào hệ thống đề xuất nằm ở khả năng trích xuất các biểu diễn chất lượng cao của đặc trưng văn bản và tận dụng kiến thức bên ngoài rộng lớn được mã hóa trong chúng [1]. Và khảo sát này xem LLM như mô hình dựa trên Transformer với số lượng tham số lớn, được huấn luyện trên bộ dữ liệu khổng lồ sử dụng kỹ thuật học tự/bán giám sát, ví dụ: BERT, loạt GPT, loạt PaLM, v.v.1. Không giống như hệ thống đề xuất truyền thống, các mô hình dựa trên LLM nắm bắt thông tin ngữ cảnh và hiểu truy vấn người dùng, mô tả mục và các dữ liệu văn bản khác một cách hiệu quả hơn [2]. Bằng việc hiểu ngữ cảnh, RS dựa trên LLM có thể cải thiện độ chính xác và mức độ liên quan của đề xuất, dẫn đến việc nâng cao sự hài lòng của người dùng. Đồng thời, đối mặt với vấn đề thường gặp về độ thưa thớt dữ liệu của tương tác lịch sử hạn chế [3], LLM cũng mang lại những khả năng mới cho hệ thống đề xuất thông qua khả năng đề xuất zero/few-shot [4]. Những mô hình này có thể tổng quát hóa cho các ứng cử viên chưa từng thấy do việc tiền huấn luyện rộng rãi với thông tin thực tế, chuyên môn lĩnh vực và lý luận thường thức, cho phép chúng cung cấp đề xuất hợp lý ngay cả khi không tiếp xúc trước với các mục hoặc người dùng cụ thể.

Những chiến lược nói trên đã được áp dụng tốt trong các mô hình phân biệt. Tuy nhiên, với sự phát triển của các mô hình học AI, các mô hình ngôn ngữ sinh tạo đã bắt đầu nổi bật [5] như được thể hiện trong Hình 1. Một ví dụ điển hình về điều này là sự xuất hiện của ChatGPT và các mô hình tương tự khác, đã làm gián đoạn đáng kể các mô hình sống và làm việc của con người. Hơn nữa, sự kết hợp của các mô hình sinh tạo với hệ thống đề xuất mang lại tiềm năng cho những ứng dụng thậm chí còn sáng tạo và thực tế hơn. Ví dụ, khả năng diễn giải của đề xuất có thể được cải thiện, vì các hệ thống dựa trên LLM có thể cung cấp giải thích dựa trên khả năng tạo ngôn ngữ của chúng [6], giúp người dùng hiểu các yếu tố ảnh hưởng đến đề xuất. Hơn nữa, các mô hình ngôn ngữ sinh tạo cho phép đề xuất được cá nhân hóa và nhận thức ngữ cảnh hơn, chẳng hạn như prompt có thể tùy chỉnh của người dùng [7] trong hệ thống đề xuất dựa trên chat, nâng cao sự tham gia của người dùng và sự hài lòng với tính đa dạng của kết quả.

Được thúc đẩy bởi hiệu quả đáng kể của các mô hình nói trên trong việc giải quyết các vấn đề về độ thưa thớt dữ liệu và hiệu quả, việc điều chỉnh các mô hình ngôn ngữ cho đề xuất đã nổi lên như một hướng đầy hứa hẹn trong cả học thuật và công nghiệp, thúc đẩy đáng kể tình trạng hiện đại trong nghiên cứu hệ thống đề xuất. Trong giai đoạn đầu, có một vài nghiên cứu xem xét các bài báo liên quan trong lĩnh vực này [1, 8]. [8] tóm tắt một số nghiên cứu về tiền huấn luyện của các mô hình đề xuất và thảo luận về các phương pháp chuyển giao kiến thức giữa các lĩnh vực khác nhau. [1] đề xuất một phân loại trực giao để chia các hệ thống đề xuất dựa trên mô hình ngôn ngữ tiền huấn luyện hiện có w.r.t. chiến lược và mục tiêu huấn luyện của chúng, phân tích và tóm tắt mối liên hệ giữa các mô hình huấn luyện dựa trên mô hình ngôn ngữ tiền huấn luyện và các loại dữ liệu đầu vào khác nhau. Tuy nhiên, cả hai khảo sát này chủ yếu tập trung vào việc chuyển giao các kỹ thuật và chiến lược huấn luyện trong các mô hình ngôn ngữ tiền huấn luyện, thay vì khám phá tiềm năng của các mô hình ngôn ngữ và khả năng của chúng, tức là cách thức dựa trên LLM. Ngoài ra, chúng thiếu tổng quan toàn diện về những tiến bộ gần đây và giới thiệu có hệ thống về các mô hình ngôn ngữ lớn sinh tạo trong lĩnh vực đề xuất. Để giải quyết vấn đề này, chúng tôi đi sâu vào các hệ thống đề xuất dựa trên LLM, phân loại chúng thành LLM phân biệt cho đề xuất và LLM sinh tạo cho đề xuất, và trọng tâm của đánh giá của chúng tôi là mô hình sau. Gần đây, đã có một số đánh giá giới thiệu việc ứng dụng mô hình ngôn ngữ lớn trong hệ thống đề xuất hoặc các công nghệ liên quan [9–12]. Tuy nhiên, bài báo của chúng tôi là bài đầu tiên tóm tắt toàn diện ba mô hình mô hình hóa đại diện của việc áp dụng mô hình ngôn ngữ lớn trong hệ thống đề xuất. Đặc điểm riêng biệt của nó là súc tích nhưng bao phủ rộng rãi và chính xác đã thu hút sự chú ý đáng kể trong ngành. Ngoài ra, bài báo của chúng tôi xem xét kỹ lưỡng các thách thức chính mà mô hình ngôn ngữ lớn gặp phải trong lĩnh vực đề xuất, cung cấp những hiểu biết có giá trị để hướng dẫn các hướng nghiên cứu tương lai trong lĩnh vực này. Những đóng góp chính của khảo sát của chúng tôi được tóm tắt như sau:

• Chúng tôi trình bày một khảo sát có hệ thống về tình trạng hiện tại của hệ thống đề xuất dựa trên LLM, tập trung vào việc mở rộng khả năng của mô hình ngôn ngữ. Chúng tôi cung cấp một tổng quan có hệ thống về những tiến bộ và ứng dụng liên quan bằng cách phân tích các phương pháp hiện có.

• Từ góc độ mô hình mô hình hóa, chúng tôi phân loại các nghiên cứu hiện tại về đề xuất mô hình ngôn ngữ lớn thành ba trường phái tư duy riêng biệt. Bất kỳ phương pháp hiện có nào cũng có thể được đặt phù hợp trong các danh mục này, từ đó cung cấp cái nhìn tổng quan rõ ràng và có tổ chức về lĩnh vực đang phát triển này.

• Khảo sát của chúng tôi phân tích một cách phê phán các ưu điểm, nhược điểm và hạn chế của các phương pháp hiện có. Chúng tôi xác định những thách thức chính mà hệ thống đề xuất dựa trên LLM gặp phải và đề xuất những phát hiện có giá trị có thể khuyến khích nghiên cứu sâu hơn trong lĩnh vực tiềm năng này.

## 2 Mô hình Mô hình hóa và Phân loại

Khung cơ bản của tất cả mô hình ngôn ngữ lớn được cấu thành từ một số khối transformer, ví dụ: GPT, PaLM, LLaMA, v.v. Đầu vào của kiến trúc này thường được cấu thành từ embedding token hoặc embedding vị trí, v.v., trong khi embedding hoặc token đầu ra mong đợi có thể được thu được tại mô-đun đầu ra. Ở đây, cả loại dữ liệu đầu vào và đầu ra đều là chuỗi văn bản. Như được thể hiện trong (1)-(3) trong Hình 2, đối với việc điều chỉnh mô hình ngôn ngữ trong đề xuất, tức là mô hình mô hình hóa, công việc hiện có có thể được chia thô sơ thành ba danh mục sau:

1. **LLM Embeddings + RS**. Mô hình mô hình hóa này xem mô hình ngôn ngữ như một bộ trích xuất đặc trưng, cung cấp đặc trưng của mục và người dùng vào LLM và xuất ra các embedding tương ứng. Một mô hình RS truyền thống có thể sử dụng embedding nhận thức kiến thức cho các nhiệm vụ đề xuất khác nhau.

2. **LLM Tokens + RS**. Tương tự như phương pháp trước, cách tiếp cận này tạo token dựa trên đặc trưng của mục và người dùng được đưa vào. Các token được tạo nắm bắt sở thích tiềm năng thông qua khai thác ngữ nghĩa, có thể được tích hợp vào quá trình ra quyết định của hệ thống đề xuất.

3. **LLM as RS**. Khác với (1) và (2), mô hình này nhằm mục đích chuyển đổi trực tiếp LLM tiền huấn luyện thành hệ thống đề xuất mạnh mẽ. Chuỗi đầu vào thường bao gồm mô tả hồ sơ, prompt hành vi và hướng dẫn nhiệm vụ. Chuỗi đầu ra được mong đợi cung cấp kết quả đề xuất hợp lý.

Trong các ứng dụng thực tế, việc lựa chọn mô hình ngôn ngữ lớn ảnh hưởng đáng kể đến thiết kế của mô hình mô hình hóa trong hệ thống đề xuất. Như được thể hiện trong Hình 3, trong bài báo này, chúng tôi phân loại các công trình hiện có thành hai danh mục chính, tương ứng là LLM phân biệt và LLM sinh tạo cho đề xuất. Phân loại của các kiểu phát triển của LLM cho đề xuất có thể được chia nhỏ hơn dựa trên cách thức huấn luyện, và sự khác biệt giữa các cách thức khác nhau được minh họa rõ ràng trong Hình 4. Nói chung, các mô hình ngôn ngữ phân biệt rất phù hợp cho embedding trong mô hình (1), trong khi khả năng tạo phản hồi của mô hình ngôn ngữ lớn sinh tạo hỗ trợ thêm cho mô hình (2) hoặc (3).

## 3 LLM Phân biệt cho Đề xuất

Thật vậy, các mô hình ngôn ngữ lớn phân biệt được gọi trong lĩnh vực đề xuất chủ yếu đề cập đến những mô hình của loạt BERT [13]. Do chuyên môn của mô hình ngôn ngữ phân biệt trong các nhiệm vụ hiểu ngôn ngữ tự nhiên, chúng thường được coi là backbone embedding cho các nhiệm vụ downstream khác nhau. Điều này cũng đúng với hệ thống đề xuất. Hầu hết các công trình hiện có điều chỉnh các biểu diễn của các mô hình tiền huấn luyện như BERT với dữ liệu cụ thể cho lĩnh vực thông qua tinh chỉnh. Ngoài ra, một số nghiên cứu khám phá các chiến lược huấn luyện như điều chỉnh prompt và điều chỉnh adapter. Các phương pháp đại diện và bộ dữ liệu thường được sử dụng được liệt kê trong Bảng 1 và Bảng 2.

### 3.1 Tinh chỉnh

Tinh chỉnh các mô hình ngôn ngữ tiền huấn luyện là một kỹ thuật phổ quát đã thu hút sự chú ý đáng kể trong nhiều nhiệm vụ xử lý ngôn ngữ tự nhiên (NLP) khác nhau, bao gồm cả hệ thống đề xuất. Ý tưởng đằng sau tinh chỉnh là lấy một mô hình ngôn ngữ, đã học được các biểu diễn ngôn ngữ phong phú từ dữ liệu văn bản quy mô lớn, và điều chỉnh nó cho một nhiệm vụ hoặc lĩnh vực cụ thể bằng cách huấn luyện thêm nó trên dữ liệu cụ thể cho nhiệm vụ. Kiến trúc cổ điển được thể hiện trong Hình 5 (a).

Quá trình tinh chỉnh bao gồm việc khởi tạo mô hình ngôn ngữ tiền huấn luyện với các tham số đã học của nó và sau đó huấn luyện nó trên bộ dữ liệu cụ thể cho đề xuất. Bộ dữ liệu này thường bao gồm tương tác người dùng-mục, mô tả văn bản của mục, hồ sơ người dùng và thông tin ngữ cảnh liên quan khác. Trong quá trình tinh chỉnh, các tham số của mô hình được cập nhật dựa trên dữ liệu cụ thể cho nhiệm vụ, cho phép nó thích ứng và chuyên môn hóa cho các nhiệm vụ đề xuất mục tiêu. Các mục tiêu học tập trong các giai đoạn tiền huấn luyện và tinh chỉnh có thể khác nhau, vì chúng hướng đến các mục tiêu tối ưu hóa khác nhau.

Vì chiến lược tinh chỉnh linh hoạt, hầu hết các phương pháp đề xuất được tăng cường bởi BERT có thể được tóm tắt vào hướng này. Đối với nhiệm vụ biểu diễn cơ bản, [14] đề xuất một phương pháp mới dựa trên tiền huấn luyện và tinh chỉnh U-BERT để học biểu diễn người dùng, tận dụng các lĩnh vực giàu nội dung để bổ sung cho những đặc trưng người dùng có dữ liệu hành vi không đầy đủ. Một lớp co-matching đánh giá được thiết kế để nắm bắt tương tác ngữ nghĩa ẩn giữa các đánh giá của người dùng và mục. Tương tự, trong UserBERT [15], hai nhiệm vụ tự giám sát được tích hợp cho tiền huấn luyện mô hình người dùng trên dữ liệu hành vi không nhãn để trao quyền cho mô hình hóa người dùng. Mô hình này sử dụng học đối tác trung bình-khó, dự đoán hành vi bị che và so khớp chuỗi hành vi để huấn luyện biểu diễn người dùng chính xác thông qua nắm bắt sở thích người dùng vốn có và mối liên hệ.

BERT tiền huấn luyện đã đạt được những đột phá xuất sắc trong nhiệm vụ xếp hạng. BECR [16] đề xuất một sơ đồ tái xếp hạng composite nhẹ kết hợp tương tác token ngữ cảnh sâu và đặc trưng ghép từ lexical truyền thống cùng một lúc. Với một mã hóa token composite mới, BECR xấp xỉ hiệu quả các biểu diễn truy vấn sử dụng embedding token có thể tính toán trước dựa trên uni-gram và skip-n-gram, cho phép sự cân bằng hợp lý giữa mức độ liên quan xếp hạng ad-hoc và hiệu quả. Bên cạnh đó, [17] đề xuất một khung học đa nhiệm vụ end-to-end cho xếp hạng sản phẩm với BERT cụ thể cho lĩnh vực được tinh chỉnh để giải quyết vấn đề không khớp từ vựng giữa truy vấn và sản phẩm. Các tác giả sử dụng lớp mixture-of-experts và chuyển giao xác suất giữa các nhiệm vụ để khai thác dữ liệu tương tác phong phú. Trong tình huống cụ thể hơn về đề xuất ví dụ mã, các tác giả tiết lộ rằng việc sử dụng truy vấn ngôn ngữ tự nhiên (BERT + LSH) mang lại kết quả xếp hạng tốt hơn so với truy vấn dựa trên API [18].

Cũng có nhiều nghiên cứu liên quan trong các nhiệm vụ hoặc tình huống cụ thể khác, ví dụ: đề xuất nhóm [19], tìm kiếm/ghép [20], dự đoán CTR [21]. Đặc biệt, cơ chế "tiền huấn luyện, tinh chỉnh" đóng vai trò quan trọng trong một số hệ thống đề xuất tuần tự hoặc dựa trên phiên, chẳng hạn như BERT4Rec [22], RESETBERT4Rec [23], và Adapter Tuning [24, 25]. Tuy nhiên, các mô hình trên chỉ tận dụng lợi thế của chiến lược huấn luyện thay vì mở rộng mô hình ngôn ngữ lớn vào lĩnh vực đề xuất, vì vậy nó không phải là trọng tâm thảo luận của chúng tôi. Mô hình học biểu diễn chuỗi UniSRec [26] phát triển một khung tinh chỉnh BERT, liên kết văn bản mô tả của mục để học các biểu diễn có thể chuyển giao qua các tình huống đề xuất khác nhau. Xem xét rằng sự ràng buộc giữa văn bản mục và biểu diễn mục có thể quá chặt chẽ, dẫn đến các vấn đề tiềm ẩn như quá nhấn mạnh hiệu ứng của đặc trưng văn bản và phóng đại tác động tiêu cực của khoảng cách lĩnh vực, Hou et al [27] đề xuất học mã mục vector-quantized có thể phân biệt cho các đề xuất tuần tự có thể chuyển giao. Đối với đề xuất dựa trên nội dung, đặc biệt là đề xuất tin tức, NRMS [28], Tiny-NewsRec [29], PREC [30], khai thác mô hình ngôn ngữ lớn để trao quyền cho đề xuất tin tức thông qua việc xử lý các vấn đề dịch chuyển lĩnh vực đã biết hoặc giảm chi phí chuyển giao. Cụ thể, để trả lời câu hỏi quan trọng rằng Liệu một mô hình đề xuất thuần túy dựa trên tính chất (MoRec) có thể vượt trội hoặc bằng một mô hình thuần túy dựa trên ID (IDRec) bằng cách thay thế embedding itemID bằng bộ mã hóa tính chất SOTA? , [31] tiến hành thí nghiệm quy mô lớn và phát hiện rằng MoRec hiện đại đã có thể thực hiện ngang bằng hoặc tốt hơn IDRec với kiến trúc đề xuất điển hình (tức là backbone Transformer) ngay cả trong cài đặt đề xuất mục không khởi động lạnh với Bộ mã hóa Tính chất SOTA và được huấn luyện E2E. Khám phá tiếp theo [32] dựa trên các bộ mã hóa mô hình ngôn ngữ quy mô lớn hơn, ví dụ: OPT [33], tiếp tục xác nhận quan điểm này.

Tóm lại, việc tích hợp tinh chỉnh BERT vào hệ thống đề xuất kết hợp kiến thức bên ngoài mạnh mẽ và sở thích người dùng được cá nhân hóa, chủ yếu nhằm mục đích thúc đẩy độ chính xác đề xuất và đồng thời đạt được một chút khả năng xử lý khởi động lạnh cho các mục mới với dữ liệu lịch sử hạn chế.

### 3.2 Điều chỉnh Prompt

Thay vì điều chỉnh LLM cho các nhiệm vụ đề xuất downstream khác nhau bằng cách thiết kế các hàm mục tiêu cụ thể, điều chỉnh prompt [34] nhằm mục đích điều chỉnh mục tiêu của việc điều chỉnh đề xuất với mất mát tiền huấn luyện, sử dụng prompt cứng/mềm và verbalizer từ nhãn. Như được thể hiện trong Hình 5 (b), do việc huấn luyện dựa trên mask thường được sử dụng trong DLLM, vai trò của verbalizer được đề cập là thiết lập ánh xạ giữa các từ được dự đoán bởi DLLM tại vị trí [MASK] và các nhãn thực tế. Liên kết này cho phép kết nối giữa mô hình ngôn ngữ và nhiệm vụ, đảm bảo sự điều chỉnh của chúng. Ví dụ, [35] tận dụng đầu Mô hình Ngôn ngữ Bị che (MLM) của BERT để khám phá hiểu biết của nó về thể loại mục sử dụng prompt kiểu cloze. Họ tiếp tục sử dụng đầu Dự đoán Câu Tiếp theo (NSP) của BERT và độ tương tự (SIM) của các biểu diễn để so sánh đầu vào truy vấn-tài liệu tìm kiếm và đề xuất có liên quan và không liên quan. Thí nghiệm cho thấy rằng BERT, ngay cả khi không có bất kỳ tinh chỉnh nào, có thể ưu tiên các mục có liên quan trong quá trình xếp hạng. [36] phát triển một hệ thống đề xuất đối thoại với prompt, trong đó bộ mã hóa mục dựa trên BERT ánh xạ trực tiếp metadata của mỗi mục vào một embedding. Tương tự, Shen et al [37] phát triển một hệ thống đề xuất đối thoại tích hợp phân tích công bằng thuộc tính người dùng-mục. Họ đạt được điều này bằng cách sử dụng các mẫu prompt được xây dựng với placeholder (được gọi là tạo kết quả dựa trên mẫu). Những mẫu này bao gồm thông tin không ưu tiên như tên hoặc mối quan hệ, có thể ngầm chỉ ra các đặc tính như chủng tộc, giới tính, xu hướng tình dục, bối cảnh địa lý và tôn giáo. Phân tích cho thấy rằng bằng cách kết hợp che phía train và trung hòa phía test của các thực thể không ưu tiên, các thiên lệch quan sát được có thể được loại bỏ mà không làm tổn hại đến hiệu suất đề xuất. Gần đây, Prompt4NR [38] tiên phong trong việc áp dụng mô hình học prompt cho đề xuất tin tức. Khung này định nghĩa lại mục tiêu dự đoán nhấp chuột của người dùng vào tin tức ứng cử viên như một nhiệm vụ dự đoán mask kiểu cloze. Các thí nghiệm phát hiện rằng hiệu suất của hệ thống đề xuất được nâng cao đáng kể thông qua việc sử dụng kết hợp đa prompt, vượt qua kết quả đạt được với một prompt đơn trên các mẫu rời rạc và liên tục. Điều này làm nổi bật hiệu quả của kết hợp prompt trong việc kết hợp nhiều prompt để đưa ra quyết định sáng suốt hơn.

## 4 LLM Sinh tạo cho Đề xuất

So với các mô hình phân biệt, các mô hình sinh tạo có khả năng tạo ngôn ngữ tự nhiên tốt hơn. Do đó, không giống như hầu hết các phương pháp dựa trên mô hình phân biệt điều chỉnh biểu diễn học được bởi LLM với lĩnh vực đề xuất, hầu hết công việc dựa trên mô hình sinh tạo dịch các nhiệm vụ đề xuất như các nhiệm vụ ngôn ngữ tự nhiên, và sau đó áp dụng các kỹ thuật như học trong ngữ cảnh, điều chỉnh prompt và điều chỉnh hướng dẫn để điều chỉnh LLM để tạo trực tiếp kết quả đề xuất. Hơn nữa, với những khả năng ấn tượng được thể hiện bởi ChatGPT, loại công việc này đã nhận được nhiều sự chú ý hơn gần đây.

Như được thể hiện trong Hình 3, theo việc có điều chỉnh tham số hay không, những phương pháp dựa trên LLM sinh tạo này có thể được chia nhỏ thành hai mô hình: mô hình không điều chỉnh và mô hình điều chỉnh. Ở đây mục tiêu điều chỉnh/không điều chỉnh biểu thị mô-đun LLM được sử dụng trong các phương pháp sau. Hai tiểu mục tiếp theo sẽ giải quyết chi tiết của chúng, tương ứng. Các phương pháp đại diện và bộ dữ liệu thường được sử dụng cũng được liệt kê trong Bảng 1 và Bảng 2.

### 4.1 Mô hình Không điều chỉnh

LLM đã thể hiện khả năng zero/few-shot mạnh trong nhiều nhiệm vụ chưa thấy [39, 40]. Do đó, một số công trình gần đây giả định rằng LLM đã có khả năng đề xuất, và cố gắng kích hoạt những khả năng này bằng cách giới thiệu các prompt cụ thể. Họ sử dụng thực hành gần đây của Học Hướng dẫn và Trong ngữ cảnh [39] để áp dụng LLM cho các nhiệm vụ đề xuất mà không điều chỉnh tham số mô hình. Theo việc prompt có bao gồm các ví dụ minh họa hay không, các nghiên cứu trong mô hình này chủ yếu thuộc hai danh mục sau: prompting và học trong ngữ cảnh.

#### 4.1.1 Prompting

Danh mục công việc này nhằm mục đích thiết kế các hướng dẫn và prompt phù hợp hơn để giúp LLM hiểu và giải quyết tốt hơn các nhiệm vụ đề xuất. [41] đánh giá một cách có hệ thống hiệu suất của ChatGPT trên năm nhiệm vụ đề xuất phổ biến, tức là dự đoán rating, đề xuất tuần tự, đề xuất trực tiếp, tạo giải thích và tóm tắt đánh giá. Họ đề xuất một khung xây dựng prompt đề xuất chung, bao gồm các yếu tố sau: (1) mô tả nhiệm vụ, điều chỉnh các nhiệm vụ đề xuất thành các nhiệm vụ xử lý ngôn ngữ tự nhiên; (2) tiêm hành vi, tích hợp tương tác người dùng-mục để hỗ trợ LLM nắm bắt sở thích và nhu cầu của người dùng; (3) chỉ báo định dạng, hạn chế định dạng đầu ra và làm cho kết quả đề xuất dễ hiểu và đánh giá hơn. Tương tự, [42] tiến hành phân tích thực nghiệm về khả năng đề xuất của ChatGPT trên ba nhiệm vụ truy xuất thông tin phổ biến, bao gồm xếp hạng điểm, cặp và danh sách. Họ đề xuất các prompt khác nhau cho các loại nhiệm vụ khác nhau và giới thiệu hướng dẫn vai trò (như Bây giờ bạn là một hệ thống đề xuất tin tức.) ở đầu prompt để tăng cường khả năng thích ứng lĩnh vực của ChatGPT. [43] khám phá tính khả thi của việc phát triển một Người Đề xuất Trí tuệ Nhân tạo Tổng quát (AGR) sử dụng Mô hình Ngôn ngữ Lớn (LLM) từ góc độ mười nguyên tắc cơ bản, như bộ nhớ ngữ cảnh, cơ chế sửa chữa và cơ chế phản hồi.

Để đánh giá việc tăng cường của các đầu vào prompting khác nhau, [44] thiết kế ba mẫu prompt cho trường hợp Chỉ Mục (thuộc tính của mục), Chỉ Ngôn ngữ (mô tả sở thích của người dùng), và kết hợp Ngôn ngữ+Mục trong thí nghiệm của họ. Sau khi phân tích hiệu suất của mô hình ngôn ngữ, họ phát hiện rằng các chiến lược zero-shot và few-shot rất hiệu quả trong việc đưa ra đề xuất dựa trên sở thích chỉ dựa trên ngôn ngữ (không xem xét sở thích mục). Trên thực tế, những chiến lược này đã chứng minh là cực kỳ cạnh tranh so với các phương pháp lọc cộng tác dựa trên mục, đặc biệt trong các tình huống gần khởi động lạnh. Đồng thời, để tóm tắt ý định của người dùng bằng prompt dựa trên dữ liệu tương tác của họ, MINT [45] sử dụng InstructGPT, một LLM 175B tham số, để tạo một truy vấn tường thuật tổng hợp. Truy vấn này sau đó được lọc bằng một mô hình ngôn ngữ nhỏ hơn, và các mô hình truy xuất được huấn luyện trên cả truy vấn tổng hợp và mục người dùng. Kết quả chỉ ra rằng các mô hình kết quả vượt trội hơn một số mô hình cơ sở mạnh và mô hình đã loại bỏ. Trong thiết lập một lần, những mô hình này sánh ngang hoặc thậm chí vượt trội hơn một LLM 175B được sử dụng trực tiếp cho đề xuất dựa trên tường thuật. Tuy nhiên, những phương pháp này chưa xem xét việc phân tách các chủ đề trong mô tả văn bản, điều này sẽ dẫn đến prompt nhiễu và không rõ mục tiêu. KAR [46] giải quyết vấn đề này bằng cách giới thiệu prompting phân tích để gợi ra lý luận chính xác về sở thích người dùng và kiến thức thực tế.

Thay vì đề xuất một khung chung, một số công trình tập trung vào việc thiết kế prompt hiệu quả cho các nhiệm vụ đề xuất cụ thể. [4] khai thác các prompt đề xuất phim từ corpus tiền huấn luyện của GPT-2. [47] giới thiệu hai phương pháp prompting để cải thiện khả năng đề xuất tuần tự của LLM: prompting tuần tự tập trung vào gần đây, cho phép LLM cảm nhận thông tin tuần tự trong lịch sử tương tác người dùng, và bootstrapping, xáo trộn danh sách mục ứng cử viên nhiều lần và lấy điểm trung bình để xếp hạng nhằm giảm bớt vấn đề thiên lệch vị trí. Do số lượng token đầu vào hạn chế được phép cho LLM, rất khó để đưa vào danh sách ứng cử viên dài trong prompt. Để giải quyết vấn đề này, [48] đề xuất một chiến lược prompt cửa sổ trượt, chỉ xếp hạng các ứng cử viên trong cửa sổ mỗi lần, sau đó trượt cửa sổ theo thứ tự từ cuối về đầu, và cuối cùng lặp lại quá trình này nhiều lần để có được kết quả xếp hạng tổng thể. [49] thiết kế một prompt sequence-residual để sử dụng LLM cải thiện khả năng diễn giải của đề xuất tuần tự truyền thống. [50] đề xuất một khung kết hợp tiêu chí đa góc độ cải thiện tính nhất quán và toàn diện của các ranker LLM điểm bằng cách mô phỏng một đội chú thích ảo với chuyên môn đa dạng. Đối với các nhiệm vụ đề xuất đối thoại, [51] cung cấp bằng chứng thực nghiệm rằng LLM có thể vượt trội hơn các mô hình chuyên biệt mà không cần tinh chỉnh. Ngoài ra, các tác giả xây dựng một bộ dữ liệu thế giới thực mới bằng cách trích xuất cuộc trò chuyện từ trang web phổ biến Reddit.

Ngoài việc coi LLM như hệ thống đề xuất, một số nghiên cứu cũng sử dụng LLM để xây dựng đặc trưng mô hình nhằm cải thiện hệ thống đề xuất thông thường. [52–54] và LLM-Rec [55] sử dụng LLM và các chiến lược prompting để tiến hành tăng cường nội dung nhằm nâng cao đặc trưng của góc độ mục. Từ góc độ đặc trưng người dùng, NIR [56] thiết kế prompt để tạo mô tả sở thích người dùng và LLMRG [57] sử dụng ChatGPT và cơ sở kiến thức để xây dựng đồ thị lý luận nhằm tăng cường biểu diễn người dùng. GENRE [58] giới thiệu ba prompt để sử dụng LLM tiến hành ba nhiệm vụ phụ tăng cường đặc trưng cho đề xuất tin tức từ cả góc độ người dùng và mục. Cụ thể, nó sử dụng ChatGPT để tinh chỉnh tiêu đề tin tức theo tóm tắt, trích xuất từ khóa hồ sơ từ lịch sử đọc của người dùng, và tạo tin tức tổng hợp để làm phong phú tương tác lịch sử của người dùng. Tương tự, LLMRec [59] và RLMRec [60] đầu tiên sử dụng ChatGPT để tạo đặc trưng văn bản cho người dùng và mục và sau đó lấy những đặc trưng này để tăng cường học biểu diễn dựa trên ID.

Trong thực tế, ngoài mô hình xếp hạng, toàn bộ hệ thống đề xuất nói chung bao gồm nhiều thành phần quan trọng, chẳng hạn như cơ sở dữ liệu nội dung và mô hình truy xuất ứng cử viên. Do đó, một hướng khác của việc sử dụng LLM cho đề xuất là coi chúng như bộ điều khiển của toàn bộ hệ thống. ChatREC [6], RAH [61], BiLLP [62] và InteRecAgent [63] thiết kế khung đề xuất tương tác xung quanh LLM, hiểu yêu cầu người dùng thông qua đối thoại nhiều lượt, và gọi các hệ thống đề xuất hiện có và nhiều công cụ khác nhau, như cơ sở dữ liệu, bộ truy xuất, bộ nhớ, để cung cấp kết quả. Agent có thể đóng vai trò quan trọng trong những tình huống đối thoại như vậy, do đó một số phiên bản nâng cao được phát triển để tối ưu hóa sự kết hợp giữa trí tuệ chat và mô-đun đề xuất [64, 65]. Hơn nữa, một số mô hình dựa trên agent gần đây [66, 67] đề xuất khung đề xuất cho nền tảng agent dựa trên LLM, nhấn mạnh dịch vụ agent được cá nhân hóa thông qua tương tác và hợp tác tăng cường giữa người dùng, agent đề xuất và agent mục. GeneRec [68] đề xuất một khung đề xuất sinh tạo và sử dụng LLM để điều khiển khi nào đề xuất các mục hiện có hoặc tạo các mục mới bằng mô hình AIGC. Hơn nữa, [69], RecAgent [70] và Agent4Rec [71] tiếp tục sử dụng LLM như bộ mô phỏng thông minh để phát triển môi trường đề xuất ảo. Bộ mô phỏng thường bao gồm hai mô-đun chính: người dùng và người đề xuất. Mô-đun người dùng cho phép duyệt trang web đề xuất, tương tác với người dùng khác và đăng trên mạng xã hội. Mô-đun người đề xuất cung cấp danh sách tìm kiếm và đề xuất được điều chỉnh, hỗ trợ nhiều thiết kế mô hình khác nhau cho đề xuất. Người dùng trong môi trường tương tác dựa trên phản hồi được tạo bởi LLM, phát triển một cách tự nhiên để phản ánh hành vi thế giới thực. Những dự án này cho thấy tiềm năng sử dụng trong một số ứng dụng, chẳng hạn như mô phỏng phản hồi cho đề xuất dựa trên RL, theo dõi quá trình phổ biến thông tin giữa người dùng trên mạng xã hội, điều tra hiệu ứng bong bóng lọc, và tiết lộ các mối quan hệ nhân quả cơ bản được nhúng trong các tình huống hệ thống đề xuất.

Thay vì sử dụng LLM như bộ điều khiển, UniLLMRec [72] đề xuất một khung đề xuất liên kết end-to-end tận dụng LLM để tích hợp hiệu quả các nhiệm vụ gọi lại, xếp hạng và tái xếp hạng.

Tóm lại, những nghiên cứu này sử dụng prompt ngôn ngữ tự nhiên để tận dụng khả năng zero-shot của LLM cho các nhiệm vụ đề xuất, cung cấp một phương pháp tiết kiệm chi phí và thực dụng.

#### 4.1.2 Học trong ngữ cảnh

Học trong ngữ cảnh là một kỹ thuật được sử dụng bởi GPT-3 và các LLM khác để nhanh chóng thích ứng với các nhiệm vụ và thông tin mới. Với một vài cặp đầu vào-nhãn minh họa, chúng có thể dự đoán nhãn cho đầu vào chưa thấy mà không cần cập nhật tham số bổ sung [73]. Do đó, một số công trình cố gắng thêm ví dụ minh họa trong prompt để làm cho LLM hiểu tốt hơn các nhiệm vụ đề xuất. Đối với đề xuất tuần tự, [47] giới thiệu ví dụ minh họa bằng cách tăng cường chính chuỗi tương tác đầu vào. Chi tiết, họ ghép tiền tố của chuỗi tương tác đầu vào và người kế thừa tương ứng như ví dụ. [74] điều tra hiệu ứng của định dạng hướng dẫn, tính nhất quán nhiệm vụ, lựa chọn minh họa và số lượng minh họa [41] và [42] thiết kế các mẫu ví dụ minh họa cho nhiều nhiệm vụ đề xuất khác nhau và kết quả thí nghiệm cũng cho thấy phương pháp học trong ngữ cảnh sẽ cải thiện khả năng đề xuất của LLM trên hầu hết các nhiệm vụ. Ngoài ra, một minh họa phù hợp có thể được sử dụng để điều khiển định dạng và nội dung đầu ra của LLM [75], có thể cải thiện chỉ số đánh giá thông thường. Điều này rất quan trọng để phát triển một hệ thống đề xuất ổn định và mạnh mẽ.

Tuy nhiên, so với prompting, chỉ có một vài nghiên cứu đã khám phá việc sử dụng Học trong ngữ cảnh của Mô hình Ngôn ngữ (LLM) trong các nhiệm vụ đề xuất. Nhiều câu hỏi mở vẫn còn, bao gồm lựa chọn ví dụ minh họa và ảnh hưởng của số lượng ví dụ minh họa đến hiệu suất đề xuất.

### 4.2 Mô hình Điều chỉnh

Như chúng tôi đã đề cập ở trên, LLM có khả năng zero/few-shot mạnh, và hiệu suất đề xuất của chúng có thể vượt qua đáng kể việc đoán ngẫu nhiên với thiết kế prompt phù hợp. Tuy nhiên, không có gì ngạc nhiên khi các hệ thống đề xuất được xây dựng theo cách này không thể vượt qua hiệu suất của các mô hình đề xuất được huấn luyện cụ thể cho một nhiệm vụ nhất định trên dữ liệu cụ thể. Do đó, nhiều nhà nghiên cứu nhằm mục đích tăng cường khả năng đề xuất của LLM bằng cách tinh chỉnh hoặc học prompt thêm. Trong bài báo này, chúng tôi phân loại mô hình của các phương pháp điều chỉnh thành ba loại khác nhau, tương ứng là tinh chỉnh, điều chỉnh prompt và điều chỉnh hướng dẫn. Cụ thể, trong mô hình tinh chỉnh, các phương pháp sử dụng cho mô hình ngôn ngữ lớn phân biệt và sinh tạo đáng chú ý tương tự. LLM chủ yếu phục vụ như bộ mã hóa để trích xuất biểu diễn của người dùng hoặc mục, và các tham số của LLM sau đó được tinh chỉnh trên các hàm mất mát cụ thể của các nhiệm vụ đề xuất downstream. Đồng thời, trong các mô hình điều chỉnh prompt và điều chỉnh hướng dẫn, đầu ra của các mô hình lớn luôn là văn bản, và các tham số của chúng được huấn luyện sử dụng mất mát của mô hình ngôn ngữ. Sự khác biệt chính giữa các mô hình huấn luyện điều chỉnh prompt và điều chỉnh hướng dẫn là điều chỉnh prompt chủ yếu tập trung vào một nhiệm vụ cụ thể, ví dụ: dự đoán rating, trong khi LLM được huấn luyện cho nhiều nhiệm vụ với các loại hướng dẫn khác nhau dưới mô hình điều chỉnh hướng dẫn. Do đó, LLM có thể có khả năng zero-shot tốt hơn bằng điều chỉnh hướng dẫn. Trong các phần tiếp theo, chúng tôi sẽ đi sâu vào các công trình đại diện của ba mô hình này một cách chi tiết.

#### 4.2.1 Tinh chỉnh

Vì trong mô hình tinh chỉnh, các phương pháp sử dụng và huấn luyện của LLM sinh tạo về cơ bản tương tự như LLM phân biệt được thảo luận trong Phần 3.1 [76], do đó, chúng tôi sẽ chỉ giới thiệu một vài nghiên cứu đại diện trong tiểu mục này. Ví dụ, [77] đề xuất GPTRec, đây là một mô hình đề xuất tuần tự sinh tạo dựa trên GPT-2. Tương phản với BERT4Rec, dựa trên LLM phân biệt, GPTRec dựa trên LLM sinh tạo, sử dụng SVD Tokenisation cho hiệu quả bộ nhớ, và linh hoạt hơn khi sử dụng chiến lược tạo Next-K. [78] đề xuất định dạng tương tác lịch sử người dùng như prompt, trong đó mỗi tương tác được biểu diễn bằng thông tin về mục, và xây dựng nhiệm vụ dự đoán rating như hai nhiệm vụ khác nhau, tương ứng là phân loại đa lớp và hồi quy. [78] tiếp tục điều tra nhiều LLM khác nhau với kích thước khác nhau, từ 250M đến 540B tham số và đánh giá hiệu suất của chúng trong các tình huống zero-shot, few-shot và tinh chỉnh, và phát hiện rằng mô hình FLAN-T5-XXL (11B) với tinh chỉnh có thể đạt được kết quả tốt nhất. [32] nghiên cứu ảnh hưởng của LLM, như GPT-3 với 175 tỷ tham số, trên lọc cộng tác dựa trên văn bản (TCF). [58] đề xuất ban đầu sử dụng LLM nguồn đóng như ChatGPT để bổ sung thông tin mục trong hệ thống đề xuất, thu được token nguồn đóng. tiếp theo, LLM nguồn mở như LLaMA được sử dụng để biểu diễn mục và người dùng, dẫn đến embedding nguồn mở. Cuối cùng, [58] sử dụng mô hình tinh chỉnh để huấn luyện mô hình đề xuất dựa trên embedding người dùng và mục. [32] phát hiện rằng việc sử dụng LLM mạnh hơn như bộ mã hóa văn bản có thể dẫn đến độ chính xác đề xuất cao hơn. Tuy nhiên, một LM cực kỳ lớn có thể không dẫn đến biểu diễn phổ quát của người dùng và mục, và lọc cộng tác dựa trên ID đơn giản vẫn là một phương pháp rất cạnh tranh trong cài đặt đề xuất mục ấm.

#### 4.2.2 Điều chỉnh Prompt

Trong mô hình này, LLM thường lấy thông tin người dùng/mục làm đầu vào, và xuất ra sở thích người dùng (ví dụ: thích hoặc không thích, rating) cho các mục, hoặc xuất ra các mục mà người dùng có thể quan tâm. Ví dụ, [79] đề xuất TALLRec được huấn luyện bằng hai giai đoạn điều chỉnh. TALLRec đầu tiên được tinh chỉnh dựa trên dữ liệu self-instruct bởi Alpaca [80]. Sau đó, TALLRec được tinh chỉnh thêm bằng điều chỉnh đề xuất, trong đó đầu vào là chuỗi lịch sử của người dùng và đầu ra là phản hồi "có hoặc không". [81] trình bày một phương pháp đề xuất sinh tạo dựa trên LLM có tên GenRec sử dụng khả năng tạo của LLM sinh tạo để tạo trực tiếp mục mục tiêu để đề xuất. Cụ thể, [81] đề xuất sử dụng hàm tạo đầu vào để chuyển đổi mục thành prompt, và sử dụng LLM để tạo mục tiếp theo. [82] đề xuất một phương pháp đa bước để khai thác tiềm năng của LLM cho đề xuất. Cụ thể, [82] đầu tiên đề xuất tận dụng LLM để tạo tóm tắt sở thích của người dùng. Ví dụ, bằng cách phân tích lịch sử âm nhạc và xem TV của người dùng, LLM có thể tạo tóm tắt như "nhạc pop" và "phim giả tưởng". Sau đó, một mô-đun truy xuất được sử dụng để có được một pool ứng cử viên nhỏ hơn nhiều. Cuối cùng, lịch sử tương tác, hồ sơ người dùng ngôn ngữ tự nhiên và ứng cử viên được truy xuất được sử dụng để xây dựng một prompt ngôn ngữ tự nhiên có thể được đưa vào LLM cho đề xuất. Tương tự, lấy cảm hứng từ việc áp dụng thành công của các mô hình Mạng Neural Tích chập (CNN) và Mạng Neural Hồi quy (RNN) trong mô hình người dùng, [83] đề xuất hai kỹ thuật độc đáo cho tóm tắt sở thích người dùng, tương ứng là tóm tắt phân cấp và tóm tắt hồi quy. [83] tiếp tục sử dụng kỹ thuật SFT để tinh chỉnh mô hình đề xuất cuối cùng. [84] đề xuất kết hợp đặc trưng người dùng và chuỗi hành vi làm văn bản đầu vào. [84] cũng đề xuất đặt tên các thuộc tính trong đặc trưng người dùng và mục trong chuỗi hành vi như thực thể, và giữ các thực thể như đơn vị hoàn chỉnh trong văn bản đầu vào. [85] đề xuất tạo tiêu đề của sản phẩm tiếp theo mà người dùng quan tâm với sự giúp đỡ của LLM. Họ tinh chỉnh một mô hình mT5 sử dụng mục tiêu sinh tạo được định nghĩa trên bộ dữ liệu của họ. Tuy nhiên, một phương pháp heuristic đơn giản lấy tiêu đề sản phẩm cuối cùng làm kết quả vượt qua hiệu suất của mô hình ngôn ngữ được tinh chỉnh. [86] đề xuất RecLLM, chứa một mô-đun quản lý đối thoại sử dụng LLM để trò chuyện với người dùng, một mô-đun ranker sử dụng LLM để ghép sở thích người dùng, và một bộ mô phỏng người dùng dựa trên LLM có thể điều khiển để tạo cuộc trò chuyện tổng hợp cho việc điều chỉnh các mô-đun hệ thống.

Hơn nữa, [87] đề xuất PBNR, có thể mô tả hành vi người dùng và tin tức bằng văn bản trong các prompt được thiết kế. Cụ thể, các prompt được cá nhân hóa được tạo bằng cách thiết kế các mẫu đầu vào-mục tiêu, trong đó các trường liên quan trong prompt được thay thế bằng thông tin tương ứng từ dữ liệu thô. Để tăng cường hiệu suất của LLM trên nhiệm vụ đề xuất, PBNR tích hợp mất mát xếp hạng và mất mát tạo ngôn ngữ trong suốt quá trình huấn luyện. [88] đề xuất coi nhiệm vụ đề xuất như một vấn đề tạo truy vấn và tìm kiếm. Họ tiếp tục sử dụng LLM để tạo ra các biểu diễn sở thích người dùng đa dạng và có thể diễn giải, tức là các truy vấn. [89] lập luận rằng mặc dù sử dụng hướng dẫn để prompt LLM, đầu ra được tạo không trực tiếp cung cấp điểm xếp hạng cho ứng cử viên. Để có được điểm xếp hạng của các mục khác nhau một cách hiệu quả, [89] sử dụng đầu ra từ đầu LLM, tức là điểm đầu ra trên tất cả mục, làm điểm xếp hạng cho ứng cử viên. [11] tập trung vào việc sử dụng mô hình ngôn ngữ lớn cho các nhiệm vụ đề xuất Điểm quan tâm (POI). Khung được đề xuất xây dựng prompt để giữ lại tính không đồng nhất của dữ liệu Mạng Xã hội Dựa trên Vị trí (LBSN), tránh mất thông tin ngữ cảnh và cho phép hiểu ý nghĩa nội tại của ngữ cảnh. Ngoài ra, bằng cách sử dụng khái niệm độ tương tự quỹ đạo dựa trên prompt, nó tích hợp quỹ đạo lịch sử với thông tin quỹ đạo của người dùng khác nhau, do đó giảm bớt vấn đề khởi động lạnh và cải thiện độ chính xác dự đoán cho quỹ đạo có độ dài khác nhau.

Ngoài việc tinh chỉnh trực tiếp LLM, một số nghiên cứu cũng đề xuất sử dụng học prompt để đạt được hiệu suất tốt hơn. Ví dụ, [90] thiết kế một hệ thống đề xuất đối thoại thống nhất có tên UniCRS dựa trên học prompt tăng cường kiến thức. Trong bài báo này, các tác giả đề xuất đóng băng các tham số của LLM, và huấn luyện các prompt mềm cho tạo phản hồi và đề xuất mục bằng học prompt. [7] đề xuất cung cấp giải thích có thể hiểu được cho người dùng dựa trên khả năng tạo của LLM. Các tác giả thử cả học prompt rời rạc và liên tục, và tiếp tục đề xuất hai chiến lược huấn luyện, tương ứng là điều chỉnh tuần tự và đề xuất như chính quy hóa.

Một điểm đáng chú ý khác là cách kiểm soát đầu ra của mô hình ngôn ngữ lớn vẫn là một thách thức chưa được giải quyết. Khi LLM được sử dụng để tạo trực tiếp các mục mà người dùng có thể quan tâm, chúng có thể tạo ra các mục nằm ngoài corpus. Để giải quyết khó khăn này, một số nhà nghiên cứu đã tập trung vào cách kết hợp điều chỉnh prompting với các phương pháp grounding, để kết quả được tạo bởi LLM có thể được điều chỉnh chính xác với các mục trong cơ sở dữ liệu mục. Ví dụ, [91] chỉ ra rằng lập chỉ mục mục và grounding tạo là hai bước thiết yếu để kết nối LLM và mô hình đề xuất. [91] đầu tiên thiết kế một mô hình lập chỉ mục mục đa khía cạnh, chứa ID số, tiêu đề mục và thuộc tính mục. Sau đó, [91] chỉ ra rằng định danh ngoài corpus và sự phụ thuộc quá mức vào chất lượng của token được tạo ban đầu là hai vấn đề quan trọng trong quá trình tạo. Để giải quyết những vấn đề này, [91] đề xuất một phương pháp grounding đa khía cạnh dựa trên FM-index có thể giải quyết đồng thời hai vấn đề trên. [92] đề xuất một mô hình grounding hai bước. Cụ thể, [92] đầu tiên đề xuất trao quyền cho LLM tạo token có ý nghĩa thông qua điều chỉnh prompt. Sau đó, đầu ra của LLM được điều chỉnh với các mục thế giới thực bằng cách tính toán khoảng cách L2 giữa embedding của chúng, và một số thông tin thống kê như yếu tố phổ biến cũng được sử dụng để cân lại khoảng cách L2.

Hơn nữa, một số nghiên cứu đã tập trung vào việc tích hợp các mô hình cộng tác truyền thống, đặc biệt là các mô hình đề xuất dựa trên ID, với các mô hình đề xuất dựa trên LLM bằng điều chỉnh prompt. Ví dụ, [93, 94] đề xuất mở rộng từ vựng của LLM để bao gồm ID người dùng và mục. Tiếp theo, embedding của những token mới này được huấn luyện thông qua các phương pháp huấn luyện đa bước hoặc kết hợp với cả mô hình đề xuất truyền thống và dựa trên LLM. [95] đề xuất sử dụng cả chiến lược prompting mềm và cứng để học hiệu quả embedding token cộng tác/nội dung người dùng/mục thông qua mô hình ngôn ngữ trên corpus cụ thể cho RS. [96] đề xuất một phương pháp biểu diễn mục lai, tích hợp cả token văn bản và token hành vi có nguồn gốc từ embedding mục dựa trên ID được học bởi mô hình đề xuất truyền thống. Để điều chỉnh biểu diễn ID với không gian token LLM, [96] thiết kế một adapter dựa trên projector tuyến tính có thể huấn luyện. [96] tiếp tục thiết kế một điều chỉnh prompt chương trình giảng dạy, tức là dần chuyển trọng tâm học từ prompting chỉ văn bản sang prompting lai để có hiệu suất tốt hơn. Tương tự, [97] trích xuất embedding ID từ một mô hình đề xuất tuần tự tiền huấn luyện, và sử dụng một phép chiếu tuyến tính để chuyển đổi embedding ID thành cùng chiều với không gian token LLM. Đối với dự đoán, [97] sử dụng một phép chiếu tuyến tính mục để thay thế lớp dự đoán ban đầu trong LLM thông qua một ma trận trọng số để có được điểm xếp hạng của tất cả các mục ứng cử viên. LLMGR [98] đề xuất tích hợp embedding ID và đồ thị với LLM để tận dụng thế mạnh bổ sung của LLM trong hiểu ngôn ngữ tự nhiên và GNN trong xử lý dữ liệu quan hệ. [99] phát hiện rằng các phương pháp đề xuất chuỗi hiện có dựa trên mô hình ngôn ngữ tiền huấn luyện chưa sử dụng đầy đủ khả năng của mô hình ngôn ngữ và gặp phải sự dư thừa tham số. Dựa trên phát hiện này, các tác giả đề xuất sử dụng PLM được điều chỉnh hành vi (mô hình ngôn ngữ tiền huấn luyện được điều chỉnh hành vi) để khởi tạo embedding mục, từ đó tăng cường khả năng của các mô hình đề xuất chuỗi truyền thống như SASRec, cải thiện hiệu suất mà không tăng chi phí suy luận bổ sung.

Cuối cùng, chúng tôi đề xuất rằng hầu hết các phương pháp được đề cập ở trên là đề xuất cho các nhiệm vụ chung sử dụng mô hình ngôn ngữ lớn. Tuy nhiên, như đã đề cập trước đó, một lợi thế đáng kể của mô hình ngôn ngữ lớn là khả năng điều chỉnh hiệu quả các tham số mô hình với các lĩnh vực cụ thể, và một số công trình chủ yếu tập trung vào việc áp dụng LLM trong các lĩnh vực cụ thể. Lấy tuyển dụng trực tuyến làm ví dụ, trong lĩnh vực ghép việc làm-hồ sơ, mô hình đề xuất sinh tạo GIRL [100] tiên phong trong việc sử dụng LLM để tạo mô tả công việc tiềm năng (JD), tăng cường khả năng giải thích và tính phù hợp của đề xuất. GLRec [101] giới thiệu bộ xây dựng prompt meta-path, một phương pháp mới sử dụng người đề xuất LLM để diễn giải đồ thị hành vi. Phương pháp này cũng tích hợp một mô-đun tăng cường đường dẫn để giảm thiểu thiên lệch prompt. Tiếp theo, một khung dựa trên LLM được giới thiệu để điều chỉnh hồ sơ chất lượng thấp chưa ghép với hồ sơ chất lượng cao được tạo bằng Mạng Đối nghịch Sinh tạo (GAN). Quá trình điều chỉnh này tinh chỉnh biểu diễn hồ sơ, dẫn đến kết quả đề xuất được cải thiện [102].

#### 4.2.3 Điều chỉnh Hướng dẫn

Trong mô hình này, LLM được tinh chỉnh cho nhiều nhiệm vụ với các loại hướng dẫn khác nhau. Theo cách này, LLM có thể điều chỉnh tốt hơn với ý định của con người và đạt được khả năng zero-shot tốt hơn. Ví dụ, [2] đề xuất tinh chỉnh một mô hình T5 trên năm loại hướng dẫn khác nhau, tương ứng là đề xuất tuần tự, dự đoán rating, tạo giải thích, tóm tắt đánh giá và đề xuất trực tiếp. Sau điều chỉnh hướng dẫn đa nhiệm vụ trên bộ dữ liệu đề xuất, mô hình có thể đạt được khả năng tổng quát hóa zero-shot cho prompt được cá nhân hóa chưa thấy và mục mới. Tương tự, [103] đề xuất tinh chỉnh một mô hình M6 trên ba loại nhiệm vụ, tương ứng là nhiệm vụ ghi điểm, nhiệm vụ tạo và nhiệm vụ truy xuất. [104] đầu tiên thiết kế một định dạng hướng dẫn chung từ ba loại khía cạnh chính, tương ứng là sở thích, ý định và hình thức nhiệm vụ. Sau đó, [104] thiết kế thủ công 39 mẫu hướng dẫn và tự động tạo một lượng lớn dữ liệu hướng dẫn được cá nhân hóa người dùng cho điều chỉnh hướng dẫn trên một mô hình FLAN-T5-XL 3B. Kết quả thí nghiệm cho thấy phương pháp này có thể vượt trội hơn một số baseline cạnh tranh bao gồm GPT-3.5. [105] đề xuất trích xuất kiến thức không đồng nhất từ bộ dữ liệu Meituan, và xây dựng văn bản hành vi bằng kỹ thuật prompt. Sau đó, [105] sử dụng điều chỉnh hướng dẫn để làm cho LLM hiệu quả hơn cho các nhiệm vụ trong tình huống đề xuất. [106] đề xuất chưng cất prompt rời rạc cho một nhiệm vụ cụ thể thành một tập hợp vector prompt liên tục để kết nối ID và từ, và [106] tận dụng điều chỉnh hướng dẫn để giải quyết ba nhiệm vụ đề xuất khác nhau, tương ứng là đề xuất tuần tự, đề xuất top-N và tạo giải thích. [107] đề xuất rằng công việc trước đã chủ yếu tập trung vào việc cải thiện độ chính xác của đề xuất dựa trên LLM mà không giải quyết đầy đủ khả năng tuân theo hướng dẫn của chúng. Do đó, bài báo này giới thiệu một chiến lược huấn luyện học tăng cường (RL) để tăng cường đáng kể khả năng tuân theo hướng dẫn của LLM trong khi thực hiện các nhiệm vụ đề xuất.

## 5 Phát hiện

Trong khảo sát này, chúng tôi đã xem xét một cách có hệ thống các mô hình ứng dụng và chiến lược thích ứng của mô hình ngôn ngữ lớn trong hệ thống đề xuất, đặc biệt cho các mô hình ngôn ngữ sinh tạo. Chúng tôi đã xác định tiềm năng của chúng trong việc cải thiện hiệu suất của các mô hình đề xuất truyền thống trong các nhiệm vụ cụ thể. Tuy nhiên, cần lưu ý rằng việc khám phá tổng thể trong lĩnh vực này vẫn đang ở giai đoạn đầu. Các nhà nghiên cứu có thể thấy khó khăn trong việc xác định những vấn đề và điểm đau đáng để điều tra nhất. Để giải quyết vấn đề này, chúng tôi đã tóm tắt những phát hiện chung được trình bày bởi nhiều nghiên cứu về đề xuất mô hình quy mô lớn. Như được thể hiện trong Hình 7, những phát hiện này làm nổi bật một số thách thức kỹ thuật và trình bày những cơ hội tiềm năng cho những tiến bộ hơn nữa trong lĩnh vực.

### 5.1 Thiên lệch Mô hình

**Thiên lệch Vị trí**. Trong mô hình mô hình ngôn ngữ sinh tạo của hệ thống đề xuất, nhiều thông tin khác nhau như chuỗi hành vi người dùng và ứng cử viên được đề xuất được đưa vào mô hình ngôn ngữ dưới dạng mô tả tuần tự văn bản [121], có thể giới thiệu một số thiên lệch vị trí vốn có trong chính mô hình ngôn ngữ [122]. Ví dụ, thứ tự của ứng cử viên ảnh hưởng đến kết quả xếp hạng của mô hình đề xuất dựa trên LLM, tức là LLM thường ưu tiên các mục ở thứ tự hàng đầu. Và mô hình thường không thể nắm bắt tốt thứ tự hành vi của chuỗi. [26] sử dụng bootstrapping dựa trên lấy mẫu ngẫu nhiên để giảm bớt thiên lệch vị trí của ứng cử viên và nhấn mạnh các mục tương tác gần đây để tăng cường thứ tự hành vi. Tuy nhiên, những giải pháp này không đủ thích ứng để thích nghi với các ngữ cảnh khác nhau, và cần những chiến lược học tập mạnh mẽ hơn trong tương lai.

**Thiên lệch Phổ biến**. Kết quả xếp hạng của LLM bị ảnh hưởng bởi mức độ phổ biến của ứng cử viên. Các mục phổ biến, thường được thảo luận và đề cập rộng rãi trong corpus tiền huấn luyện của LLM, có xu hướng được xếp hạng cao hơn. Điều này có thể dẫn đến thiếu đa dạng trong phản hồi và có thể gạt ra lề các quan điểm ít phổ biến hoặc thiểu số. Giải quyết vấn đề này là thách thức vì nó liên quan chặt chẽ đến cấu thành của corpus tiền huấn luyện.

**Thiên lệch Công bằng**. Các mô hình ngôn ngữ tiền huấn luyện đã thể hiện các vấn đề công bằng liên quan đến các thuộc tính nhạy cảm [123, 124], bị ảnh hưởng bởi dữ liệu huấn luyện hoặc nhân khẩu học của các cá nhân tham gia vào một số chú thích nhiệm vụ cụ thể [125]. Những mối quan tâm về công bằng này có thể dẫn đến các mô hình đưa ra đề xuất giả định người dùng thuộc về một nhóm cụ thể, có thể dẫn đến các vấn đề gây tranh cãi khi triển khai thương mại. Một ví dụ là thiên lệch trong kết quả đề xuất do giới tính hoặc chủng tộc [37]. Giải quyết những vấn đề công bằng này là quan trọng và cần thiết để đảm bảo đề xuất công bằng và không thiên lệch.

**Thiên lệch Cá nhân hóa**. Việc đưa tín hiệu lọc cộng tác vào mô hình ngôn ngữ lớn (LLM) cho mục đích đề xuất đặt ra một số thách thức, đặc biệt khi so sánh với các mô hình đề xuất dựa trên ID truyền thống. Trong khi LLM có tiềm năng tạo nội dung được cá nhân hóa cao bằng cách hiểu đầu vào văn bản tinh tế, việc dịch khả năng này thành đề xuất được cá nhân hóa là thách thức. Các mô hình truyền thống, với ánh xạ trực tiếp tương tác người dùng-mục, đôi khi có thể cá nhân hóa đề xuất một cách đơn giản hơn. Tích hợp với các mô hình đề xuất dựa trên ID hoặc huấn luyện và học trực tiếp token dựa trên ID là những phương pháp tiềm năng trong lĩnh vực này [32].

### 5.2 Thiết kế Prompt Đề xuất

**Biểu diễn Người dùng/Mục**. Trong thực tế, hệ thống đề xuất thường sử dụng một số lượng lớn đặc trưng rời rạc và liên tục để biểu diễn người dùng và mục. Tuy nhiên, hầu hết công việc dựa trên LLM hiện có chỉ sử dụng tên để biểu diễn mục, và một danh sách tên mục để biểu diễn người dùng, điều này không đủ để mô hình hóa người dùng và mục một cách chính xác. Ngoài ra, việc dịch chuỗi hành vi không đồng nhất của người dùng (như nhấp chuột, thêm vào giỏ hàng và mua hàng trong lĩnh vực thương mại điện tử) thành ngôn ngữ tự nhiên cho mô hình sở thích là rất quan trọng. Các đặc trưng giống ID đã được chứng minh hiệu quả trong các mô hình đề xuất truyền thống, nhưng việc tích hợp chúng vào prompt để cải thiện hiệu suất đề xuất được cá nhân hóa cũng là thách thức.

**Độ dài Ngữ cảnh Hạn chế**. Hạn chế độ dài ngữ cảnh của LLM sẽ hạn chế độ dài của chuỗi hành vi người dùng và số lượng mục ứng cử viên, dẫn đến hiệu suất không tối ưu [104]. Công việc hiện có đã đề xuất một số kỹ thuật để giảm bớt vấn đề này, như lựa chọn các mục đại diện từ chuỗi hành vi người dùng [56] và chiến lược cửa sổ trượt cho danh sách ứng cử viên [48]. Gần đây, đã có những nỗ lực để mở rộng hạn chế độ dài ngữ cảnh của LLM. Ví dụ, mô hình LongLLaMA [126] là một mô hình ngôn ngữ lớn có khả năng xử lý ngữ cảnh dài 256k token hoặc thậm chí hơn, được tinh chỉnh bằng phương pháp Focused Transformer (FoT). Tuy nhiên, hiệu quả của những phương pháp này trong ứng dụng vào tình huống đề xuất vẫn xứng đáng được xác nhận và nghiên cứu thêm.

### 5.3 Khả năng Đầy hứa hẹn

**Khả năng Đề xuất Zero/Few-shot**. Kết quả thí nghiệm trên nhiều bộ dữ liệu lĩnh vực chỉ ra rằng LLM sở hữu khả năng zero/few-shot ấn tượng trong nhiều nhiệm vụ đề xuất khác nhau [41, 42, 47]. Đáng chú ý rằng học few-shot, tương đương với học trong ngữ cảnh, không thay đổi tham số của LLM. Điều này cho thấy LLM có tiềm năng giảm thiểu vấn đề khởi động lạnh với dữ liệu hạn chế. Tuy nhiên, vẫn còn một số câu hỏi mở, như nhu cầu hướng dẫn rõ ràng hơn trong việc lựa chọn ví dụ minh họa đại diện và hiệu quả cho học few-shot, cũng như nhu cầu kết quả thí nghiệm trên nhiều lĩnh vực hơn để hỗ trợ thêm kết luận về khả năng đề xuất zero/few-shot.

**Khả năng Giải thích**. LLM sinh tạo thể hiện khả năng đáng kể cho tạo ngôn ngữ tự nhiên. Do đó, một suy nghĩ tự nhiên là sử dụng LLM để tiến hành đề xuất có thể giải thích thông qua cách thức tạo văn bản [127, 128]. [41] tiến hành thí nghiệm so sánh giữa ChatGPT và một số baseline trên nhiệm vụ tạo giải thích. Kết quả cho thấy rằng ngay cả khi không có tinh chỉnh và trong cài đặt học trong ngữ cảnh, ChatGPT vẫn thực hiện tốt hơn một số phương pháp giám sát truyền thống. Hơn nữa, theo đánh giá của con người, giải thích của ChatGPT được coi là thậm chí rõ ràng và hợp lý hơn so với sự thật cơ bản. Được khuyến khích bởi những khám phá sơ bộ thú vị và kết quả thí nghiệm này, hiệu suất của LLM được tinh chỉnh trong đề xuất có thể giải thích được mong đợi sẽ đầy hứa hẹn.

### 5.4 Vấn đề Đánh giá

**Kiểm soát Tạo**. Như chúng tôi đã đề cập trước đó, nhiều nghiên cứu đã sử dụng các mô hình quy mô lớn như hệ thống đề xuất bằng cách cung cấp hướng dẫn được thiết kế cẩn thận. Đối với những LLM này, đầu ra nên tuân thủ nghiêm ngặt định dạng hướng dẫn đã cho, như cung cấp phản hồi nhị phân (có hoặc không) hoặc tạo danh sách được xếp hạng. Tuy nhiên, trong các ứng dụng thực tế, đầu ra của LLM có thể lệch khỏi định dạng đầu ra mong muốn. Ví dụ, mô hình có thể tạo ra phản hồi ở định dạng không chính xác hoặc thậm chí từ chối cung cấp câu trả lời [42]. Và, các mô hình sinh tạo gặp khó khăn trong việc thực hiện tốt trong các nhiệm vụ đề xuất theo danh sách do dữ liệu huấn luyện và chế độ huấn luyện tự hồi quy của chúng, khiến chúng kém có khả năng xử lý các vấn đề xếp hạng với nhiều mục. Vấn đề này không thể được giải quyết thông qua tinh chỉnh, vì không có sự thật cơ bản cho việc xếp hạng nhiều mục trong một chuỗi trong các tình huống thế giới thực. Do đó, rất khó để áp dụng logic huấn luyện tự hồi quy dựa trên chuỗi. PRP (Pairwise Ranking Prompting) [109] đề xuất xếp hạng cặp cho các nhiệm vụ theo danh sách với LLM, liệt kê tất cả các cặp và thực hiện tổng hợp toàn cục để tạo điểm cho mỗi mục. Tuy nhiên, logic này tốn thời gian trong quá trình suy luận. Do đó, giải quyết thách thức đảm bảo kiểm soát tốt hơn đầu ra của LLM là một vấn đề cấp bách cần được giải quyết.

**Tiêu chí Đánh giá**. Nếu các nhiệm vụ được thực hiện bởi LLM là đề xuất tiêu chuẩn, như dự đoán rating hoặc xếp hạng mục, chúng ta có thể sử dụng các chỉ số đánh giá hiện có để đánh giá, ví dụ: NDCG, MSE, v.v. Tuy nhiên, LLM cũng có khả năng sinh tạo mạnh, làm cho chúng phù hợp cho các nhiệm vụ đề xuất sinh tạo [68]. Theo mô hình đề xuất sinh tạo, LLM có thể tạo ra các mục chưa bao giờ xuất hiện trong dữ liệu lịch sử và đề xuất chúng cho người dùng. Trong tình huống này, việc đánh giá khả năng đề xuất sinh tạo của LLM vẫn là một câu hỏi mở.

**Bộ dữ liệu**. Hiện tại, hầu hết nghiên cứu trong lĩnh vực này chủ yếu kiểm tra khả năng đề xuất và khả năng zero/few-shot của LLM sử dụng các bộ dữ liệu như MovieLens, Amazon Books và các benchmark tương tự. Tuy nhiên, điều này có thể mang lại hai vấn đề tiềm ẩn sau. Thứ nhất, so với bộ dữ liệu công nghiệp thế giới thực, những bộ dữ liệu này tương đối nhỏ về quy mô và có thể không phản ánh đầy đủ khả năng đề xuất của LLM. Thứ hai, các mục trong những bộ dữ liệu này, như phim và sách, có thể có thông tin liên quan xuất hiện trong dữ liệu tiền huấn luyện của LLM. Điều này có thể đưa ra thiên lệch trong việc đánh giá khả năng học few-zero-shot của LLM. Hiện tại, chúng ta vẫn thiếu một benchmark phù hợp để tiến hành đánh giá toàn diện hơn.

Ngoài những phát hiện nổi bật nói trên, cũng có một số hạn chế liên quan đến khả năng của mô hình ngôn ngữ lớn. Ví dụ, thách thức quên kiến thức có thể phát sinh khi huấn luyện mô hình cho các nhiệm vụ lĩnh vực cụ thể hoặc cập nhật kiến thức mô hình [129]. Một vấn đề khác là hiệu suất khác biệt do kích thước tham số mô hình ngôn ngữ khác nhau, trong đó việc sử dụng mô hình quá lớn sẽ dẫn đến chi phí tính toán quá mức cho nghiên cứu và triển khai trong hệ thống đề xuất [47]. Những thách thức này cũng mang lại cơ hội nghiên cứu có giá trị trong lĩnh vực.

## 6 Kết luận

Trong bài báo này, chúng tôi đã xem xét lĩnh vực nghiên cứu về mô hình ngôn ngữ lớn (LLM) cho hệ thống đề xuất. Chúng tôi phân loại công việc hiện có thành mô hình phân biệt và mô hình sinh tạo, và sau đó minh họa chúng một cách chi tiết theo cách thức thích ứng lĩnh vực. Để ngăn chặn sự nhầm lẫn khái niệm, chúng tôi cung cấp định nghĩa và sự phân biệt của tinh chỉnh, prompting, điều chỉnh prompt và điều chỉnh hướng dẫn trong đề xuất dựa trên LLM. Theo hiểu biết tốt nhất của chúng tôi, khảo sát của chúng tôi là đánh giá có hệ thống và cập nhật đầu tiên được dành riêng cụ thể cho LLM sinh tạo cho hệ thống đề xuất, tiếp tục tóm tắt những phát hiện và thách thức chung được trình bày bởi nhiều nghiên cứu liên quan. Do đó, khảo sát này cung cấp cho các nhà nghiên cứu một tài nguyên có giá trị để có được hiểu biết toàn diện về đề xuất LLM và khám phá các hướng nghiên cứu tiềm năng.

Nhìn về tương lai, khi khả năng tính toán tiếp tục tiến bộ và lĩnh vực trí tuệ nhân tạo mở rộng, chúng tôi dự đoán những ứng dụng thậm chí còn tinh vi hơn của LLM trong hệ thống đề xuất. Có một chân trời đầy hứa hẹn nơi tính thích ứng và độ chính xác của những mô hình này sẽ được khai thác trong các lĩnh vực đa dạng hơn, có thể dẫn đến đề xuất thời gian thực, được cá nhân hóa xem xét đầu vào đa phương thức. Hơn nữa, khi các cân nhắc đạo đức trở nên nổi bật, các hệ thống đề xuất dựa trên LLM tương lai cũng có thể tích hợp công bằng, trách nhiệm và minh bạch một cách nội tại hơn.

Tóm lại, trong khi chúng ta đã đạt được những bước tiến đáng kể trong việc hiểu và triển khai LLM trong hệ thống đề xuất, hành trình phía trước đầy rẫy cơ hội cho sự đổi mới và tinh chỉnh. Khảo sát của chúng tôi, chúng tôi hy vọng, sẽ phục vụ như một tảng đá nền tảng cho làn sóng khám phá tiếp theo trong lĩnh vực năng động và luôn phát triển này.

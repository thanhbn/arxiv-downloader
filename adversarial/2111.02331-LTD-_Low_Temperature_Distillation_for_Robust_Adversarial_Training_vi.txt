LTD: Chưng Cất Nhiệt Độ Thấp cho Huấn Luyện Đối Kháng Bền Vững

Erh-Chung Chen
Khoa Khoa Học Máy Tính
Đại Học Quốc Gia Tsing Hua
Hsinchu, Đài LoanChe-Rung Lee
Khoa Khoa Học Máy Tính
Đại Học Quốc Gia Tsing Hua
Hsinchu, Đài Loan

Tóm tắt —Huấn luyện đối kháng đã được sử dụng rộng rãi để tăng cường độ bền vững của các mô hình mạng nơ-ron chống lại các cuộc tấn công đối kháng. Bất chấp sự phổ biến của các mô hình mạng nơ-ron, vẫn tồn tại một khoảng cách đáng kể giữa độ chính xác tự nhiên và bền vững của các mô hình này. Trong bài báo này, chúng tôi xác định một trong những lý do chính của khoảng cách này là việc sử dụng phổ biến các vector một-hot làm nhãn, điều này cản trở quá trình học cho nhận dạng hình ảnh. Việc biểu diễn các hình ảnh mơ hồ bằng các vector một-hot là không chính xác và có thể dẫn mô hình đến các giải pháp không tối ưu. Để khắc phục vấn đề này, chúng tôi đề xuất một phương pháp mới được gọi là Chưng Cất Nhiệt Độ Thấp (LTD) tạo ra các nhãn mềm sử dụng khung chưng cất kiến thức được sửa đổi. Khác với các phương pháp trước đây, LTD sử dụng nhiệt độ tương đối thấp trong mô hình giáo viên và nhiệt độ cố định nhưng khác nhau cho mô hình giáo viên và học sinh. Sự sửa đổi này tăng cường độ bền vững của mô hình mà không gặp phải vấn đề che giấu gradient đã được giải quyết trong chưng cất phòng thủ. Kết quả thí nghiệm chứng minh hiệu quả của phương pháp LTD được đề xuất kết hợp với các kỹ thuật trước đây, đạt được tỷ lệ độ chính xác bền vững 58.19%, 31.13%, và 42.08% trên các bộ dữ liệu CIFAR-10, CIFAR-100, và ImageNet, tương ứng, mà không cần dữ liệu không nhãn bổ sung.

Từ khóa —Phòng thủ đối kháng, chưng cất, biểu diễn nhãn, tối ưu hóa đa mục tiêu

1. Giới thiệu

Mạng nơ-ron sâu (DNN) đã trở thành công cụ được sử dụng rộng rãi cho các tác vụ thách thức như phân loại hình ảnh [1], phát hiện đối tượng [2], chú thích hình ảnh [3], và phân tích ngữ nghĩa [4]. Sự thành công của các tác vụ này cung cấp nền tảng cho các ứng dụng tiên tiến như xe tự lái [5], hoặc dịch máy [6]. Tuy nhiên, khi DNN trở nên phổ biến hơn, các nhà nghiên cứu đang khám phá các vấn đề thực tế ngoài độ chính xác, như nén mô hình, học không giám sát, và độ bền vững.

Một mối quan tâm quan trọng về DNN là tính dễ bị tấn công của chúng trước các cuộc tấn công đối kháng, nhằm đánh lừa DNN với độ tin cậy cao bằng cách thêm một nhiễu loạn nhỏ vào đầu vào. Các cuộc tấn công đối kháng đã được quan sát trong nhiều lĩnh vực, bao gồm không gian âm thanh [7] và phân loại văn bản [8], [9] trong xử lý ngôn ngữ tự nhiên. Các cuộc tấn công đối kháng không chỉ giới hạn trong thế giới số, vì chúng cũng có thể xảy ra trong thế giới vật lý, như được thể hiện qua cuộc tấn công camera điện thoại di động [10] hoặc cuộc tấn công biển báo đường [11], [12]. Các nhà nghiên cứu cũng đã nghiên cứu các cuộc tấn công cửa sau [13], [14] làm giảm độ chính xác của mô hình trong thời gian huấn luyện.

Các cuộc tấn công đối kháng có thể được phân loại thành hai loại, cụ thể là tấn công hộp trắng và tấn công hộp đen, dựa trên lượng thông tin có sẵn cho kẻ tấn công. Đối với tấn công hộp trắng, thông tin hoàn chỉnh của mạng mục tiêu có thể truy cập được. Ví dụ về tấn công hộp trắng bao gồm FGSM [15], tấn công CW [16], và AutoAttack [17]. Ngược lại, đối với tấn công hộp đen, kẻ tấn công chỉ có quyền truy cập vào xác suất đầu ra của mô hình mục tiêu, và số lượng truy vấn bị giới hạn. Ví dụ về tấn công hộp đen bao gồm Simultaneous Perturbation Stochastic Approximation (SPSA) [18], ZOO [19], và Square Attack [20]. Hơn nữa, các ví dụ đối kháng được tạo bởi mô hình thay thế có thể đánh lừa mô hình mục tiêu nếu các mô hình có kiến trúc tương tự [21]. Nói chung, các cuộc tấn công đối kháng hạn chế kích thước nhiễu loạn trong một quả cầu ϵ cho trước. Mặt khác, các cuộc tấn công không hạn chế cho phép bất kỳ loại thay đổi nào đối với dữ liệu đầu vào nhưng bảo tồn ý nghĩa ngữ nghĩa [22].

Huấn luyện đối kháng, một trong những chiến lược phòng thủ hiệu quả nhất chống lại các cuộc tấn công đối kháng, xây dựng một bài toán tối ưu hóa min-max trong đó tối đa hóa bên trong là tìm kiếm các ví dụ đối kháng mạnh nhất, và tối thiểu hóa bên ngoài giảm mục tiêu gây ra bởi những ví dụ đối kháng đó. Trong khi huấn luyện PGD [23] và các biến thể của nó [24]–[26] đã cho thấy kết quả đầy hứa hẹn, chi phí tính toán để thực hiện huấn luyện đối kháng tương đối cao. Các phương pháp huấn luyện nhanh hơn, như AdvForFree [27], YOPO [28], FastFGSM [29], và FGSM cải tiến [30], đã được đề xuất để cải thiện hiệu quả huấn luyện. Các phương pháp huấn luyện nhanh hơn này thường tạo ra các ví dụ đối kháng với các cuộc tấn công yếu hơn, có thể dẫn đến độ chính xác bền vững thấp hơn và thậm chí quá khớp thảm họa. Bên cạnh đó, [31] đã nêu bật vấn đề che giấu gradient trong phòng thủ đối kháng, điều này làm cho kẻ tấn công khó tính toán gradient chính xác cần thiết để tạo ra các ví dụ đối kháng hiệu quả hơn, dẫn đến việc đánh giá quá cao độ bền vững.

Trong bài báo này, chúng tôi tập trung vào việc phòng thủ chống lại các cuộc tấn công hộp trắng hạn chế cho các bài toán phân loại hình ảnh. Chúng tôi xem xét lại các giả định cơ bản của phân loại hình ảnh và nhận thấy rằng không có giả định cơ bản nào trong số đó được thỏa mãn trong kịch bản thế giới thực. Hầu hết các hệ thống nhận dạng mẫu chỉ xuất ra một lớp chiến thắng, có điểm số cao nhất trong tất cả các lớp, và do đó, các mối quan hệ giữa các lớp đã bị bỏ qua. Điều này ngầm giả định rằng các nhãn thực tế là các vector một-hot. Tuy nhiên, chúng tôi xác định rằng một trong những yếu tố góp phần vào tính dễ bị tấn công của DNN là việc biểu diễn các ví dụ mơ hồ chứa các đặc trưng từ nhiều lớp sử dụng các vector một-hot. Thật không may, các khoảng cách ngữ nghĩa giữa các lớp không đồng nhất trong các bộ dữ liệu thế giới thực, điều này làm xấu đi độ bền vững của DNN chống lại các ví dụ chưa thấy. Mặc dù biểu diễn nhãn tối ưu cho các ví dụ mơ hồ chưa được biết, chúng ta có thể tạo ra các nhãn mềm sử dụng một mô hình được huấn luyện tốt.

Để đạt được điều này, chúng tôi trình bày một thuật toán mới được gọi là Chưng Cất Nhiệt Độ Thấp (LTD), cho phép mô hình mục tiêu học các mối quan hệ giữa các lớp từ một mô hình trước đó. Khác với chưng cất phòng thủ [32], LTD sử dụng nhiệt độ tương đối thấp trong mô hình giáo viên và nhiệt độ cố định nhưng khác nhau cho mô hình giáo viên và học sinh. Sự sửa đổi này tăng cường độ bền vững của mô hình mà không gặp phải vấn đề che giấu gradient.

Chúng tôi tiến hành thí nghiệm trên các bộ dữ liệu CIFAR10, CIFAR100 và ImageNet sử dụng họ Wide Residual Network (WRN) hoặc ResNet-50 để đánh giá hiệu quả của các phương pháp được đề xuất. Chúng tôi so sánh LTD với các đối thủ từ bảng xếp hạng công khai Robustbench [33]. Kết quả thí nghiệm cho thấy LTD sử dụng kiến trúc WRN-34-10 đạt được 55.09% độ chính xác bền vững mà không cần dữ liệu bổ sung. Kết hợp với Adversarial Weight Perturbation (AWP) [34], LTD có thể đạt được 58.19% độ chính xác bền vững. Đối với bộ dữ liệu CIFAR100, LTD đạt được 31.13% độ chính xác bền vững, gần như là kết quả tốt nhất mà không sử dụng dữ liệu bổ sung. Đối với ImageNet, LTD đạt được 42.08% độ chính xác bền vững, cải thiện khoảng 4% với cùng kiến trúc mạng.

Phần còn lại của bài báo này được tổ chức như sau. Phần 2 xem xét các công trình liên quan. Phần 3 xem xét lại các giả định cơ bản của phân loại hình ảnh và đưa ra giải thích về lý do tại sao các nhãn mềm cho kết quả huấn luyện bền vững hơn so với các vector một-hot. Phần 4 trình bày thuật toán được đề xuất và việc triển khai của nó. Phần 5 cho thấy kết quả thí nghiệm. Kết luận và công việc tương lai được đưa ra trong phần cuối.

2. Các Công Trình Liên Quan

Trong phần này, chúng tôi giới thiệu về các công trình liên quan. Ba chủ đề sẽ được đề cập. Đầu tiên là các cuộc tấn công và phòng thủ đối kháng. Thứ hai là chất lượng của gradient, được sử dụng để đánh giá độ bền vững của các chiến lược phòng thủ. Cuối cùng là khung chưng cất kiến thức.

2.1. Tấn Công Đối Kháng

Định nghĩa ban đầu của các ví dụ đối kháng đề cập đến một hình ảnh được sửa đổi không thể nhận thấy bằng mắt người nhưng có thể đánh lừa các bộ phân loại. Để thỏa mãn các ràng buộc, khoảng cách giữa hình ảnh được sửa đổi và hình ảnh gốc phải gần nhau. Cụ thể, bộ phân loại phân loại chính xác các ví dụ gốc nhưng các ví dụ đối kháng tương ứng bị phân loại sai. Tất cả các ví dụ đối kháng đều nằm trong tập S, được định nghĩa chính thức như sau:

S = {
x' | arg max Z(x;θ)i = arg max yi
arg max Z(x;θ)i ≠ arg max Z(x';θ)i
||x'-x||∞ ≤ ε
}, (1)

trong đó x và x' biểu thị các ví dụ gốc và các ví dụ đối kháng tương ứng; bộ phân loại nạn nhân Z là một hàm của hình ảnh đầu vào và trọng số của mô hình θ, và ε là khoảng cách được phép trong không gian L∞. Bộ phân loại xuất ra logit qi cho lớp i và dự đoán nhãn tương ứng h bằng hàm

h = arg max qi = arg max Z(x;θ)i.

Các ví dụ đối kháng thường được tạo ra bằng cách sử dụng các cuộc tấn công tính toán hướng tăng của gradient để tăng loss mục tiêu. Ví dụ, tấn công FGSM [15] tạo ra các ví dụ đối kháng như sau:

xFGSM = P(x + α sign(∇L(x, y))), (2)

trong đó L là loss mục tiêu, α là kích thước bước, và P là bộ chiếu đảm bảo rằng xFGSM vẫn nằm trong tập khả thi. Tương tự, tấn công PGD tạo ra các ví dụ đối kháng bằng cách chạy lặp m lần FGSM với kích thước bước nhỏ hơn α/m để có được các hình ảnh đối kháng mạnh hơn.

2.2. Huấn Luyện Đối Kháng

Huấn luyện đối kháng tiêu chuẩn [23] được thiết kế để phòng thủ chống lại các ví dụ đối kháng, có thể được công thức hóa như sau:

min θ E x∼D max x̃:D(x̃,x)<ε L(Z(x̃;θ), y). (3)

trong đó x nằm trong phân phối đã cho D; D(x̃, x) là một hàm khoảng cách cho x̃ và x. Mục tiêu của (3) là tối thiểu hóa các loss gây ra bởi các ví dụ đối kháng mạnh nhất; tuy nhiên, vì các ví dụ đối kháng mạnh nhất không thể xác định trước, việc tối đa hóa bên trong thường được thay thế bằng các cuộc tấn công đã biết trong thực tế.

Một công trình tiếp theo, được gọi là TRADES [24], cho rằng loss trường hợp xấu nhất trong (3) không thể được tối ưu hóa hiệu quả. Thay vào đó, loss đối kháng được phân tách thành loss tự nhiên và loss biên:

LTRADES (x, x', y) = L(Z(x;θ), y) + λΔL(x, x', y;θ), (4)

trong đó L(Z(x;θ), y)) là mục tiêu ban đầu trong (3) và ΔL(x, x', y;θ) thường là phân kỳ KL như một thuật ngữ chính quy hóa. Thuật ngữ đầu tiên trong (4) tối đa hóa phân phối đầu ra của mô hình giữa dữ liệu tự nhiên và nhãn tương ứng của nó, trong khi thuật ngữ thứ hai khuyến khích phân phối đầu ra trơn tru và đẩy ranh giới quyết định ra xa khỏi các ví dụ đã cho. Lợi ích chính của loss KLD là không cần nhãn. Các công trình gần đây đã cho thấy rằng KLD có thể được sử dụng để cải thiện độ bền vững với dữ liệu không nhãn bổ sung [26], [35], [36].

Mặc dù huấn luyện đối kháng cho phép mục tiêu được sử dụng để tạo ra các ví dụ đối kháng khác với mục tiêu được sử dụng để tối thiểu hóa loss, việc lựa chọn mục tiêu vẫn quan trọng đối với hiệu quả của phương pháp. Một công trình trước đây [26] đã điều tra một số kết hợp của tối đa hóa bên trong và tối thiểu hóa bên ngoài, và đạt được độ chính xác bền vững tốt hơn dưới cấu hình thí nghiệm của họ bằng cách đưa các ví dụ đối kháng được tạo bởi cross-entropy vào TRADES trong đó mục tiêu cần tối thiểu hóa là Eq (4) trong khi TRADES ban đầu tạo ra các ví dụ đối kháng với loss KLD.

Huấn luyện đối kháng ban đầu tính toán nhiễu loạn đối kháng trong không gian đầu vào và tối thiểu hóa loss gây ra bởi những nhiễu loạn đó. Tuy nhiên, tính dễ bị tấn công có thể đến từ trọng số trong các lớp ẩn. AWP [34] đề xuất rằng hướng giảm nên được cấu thành từ gradient từ nhiễu loạn đối kháng trong không gian đầu vào và trong không gian trọng số. Phương pháp này có thể được tích hợp với các công trình hiện có, và kết quả thực nghiệm cho thấy việc cập nhật trọng số với gradient tổng hợp có độ bền vững cao hơn.

Huấn luyện đối kháng đã được nghiên cứu rộng rãi và triển khai dưới nhiều hình thức khác nhau. Tuy nhiên, đạo hàm của mục tiêu được sử dụng đối với hình ảnh đã cho là một yếu tố quan trọng trong huấn luyện đối kháng, vì nó cung cấp hướng để tính toán các nhiễu loạn được thêm vào hình ảnh đầu vào. Nếu gradient không mang thông tin hoặc bị che giấu, huấn luyện đối kháng có thể không tạo ra các ví dụ đối kháng đủ mạnh để phòng thủ chống lại các cuộc tấn công đối kháng. Hơn nữa, nó có thể dẫn đến việc đánh giá quá cao độ chính xác bền vững chống lại các cuộc tấn công dựa trên gradient. Hiện tượng này được gọi là che giấu gradient, có thể ảnh hưởng đáng kể đến hiệu quả của huấn luyện đối kháng.

Để đánh giá chất lượng của gradient, [31] đã đề xuất năm quy tắc có thể được sử dụng để xác định liệu một mô hình có vấn đề che giấu gradient hay không. Nếu một mô hình vi phạm bất kỳ thuộc tính nào trong số này, nó rất có thể có vấn đề che giấu gradient. Tương tự, [37] đã cung cấp các hướng dẫn có giá trị để thiết kế một quy trình huấn luyện đối kháng bền vững, tóm tắt các cạm bẫy tiềm ẩn nên tránh. Những hướng dẫn này rất cần thiết để đảm bảo chất lượng gradient và tránh các vấn đề che giấu trong huấn luyện đối kháng, dẫn đến các mô hình hiệu quả và bền vững hơn.

2.3. Chưng Cất Kiến Thức

Chưng cất kiến thức [38], ban đầu được thiết kế để huấn luyện các mô hình nhỏ hơn để triển khai trên các thiết bị cạnh, giờ đây đã trở thành nền tảng cho nhiều thuật toán [39]. Khái niệm cốt lõi của chưng cất kiến thức là cung cấp các biểu diễn nhãn có ý nghĩa từ một mô hình được huấn luyện trước, được gọi là mô hình giáo viên, cho phép mô hình mục tiêu học các đặc trưng hữu ích có thể không được thể hiện từ các nhãn thực tế. Thông tin được chưng cất từ mô hình đã cho được gọi là nhãn mềm, ký hiệu là p, cho nhiệt độ T=τ:

pT=τ i = exp(q/τ)i / Σk j=1 exp(q/τ)j, (5)

trong đó q là logit được tính bởi mô hình đã cho. Mô hình mục tiêu được huấn luyện bằng hàm loss sau:

L = -Σk i=1 yi log ps,T=1 i + λΣk i=1 pt,T=τ i log (pt,T=τ i / ps,T=τ i), (6)

trong đó y là các nhãn một-hot đã cho; ps,T=τ và pt,T=τ là các nhãn đưa ra từ mô hình mục tiêu và mô hình giáo viên sử dụng nhiệt độ τ tương ứng, và λ là một yếu tố tỷ lệ. Thuật ngữ đầu tiên trong (6) là loss phân loại thông thường và thuật ngữ thứ hai là phân kỳ KL (KLD). Trong [38], các tác giả tuyên bố rằng độ lớn của gradient của loss KLD ở nhiệt độ τ được tỷ lệ bởi 1/τ2 và λ thích hợp là τ2 để cân bằng hai loss.

3. Gán Nhãn Dữ Liệu

Đối với bài toán phân loại k-lớp, ba giả định ngầm được yêu cầu: giả định thế giới đóng, giả định độc lập và phân phối giống hệt nhau (i.i.d), và giả định dữ liệu sạch và lớn [40]. Giả định thế giới đóng giả sử rằng số lượng lớp k được định trước và tất cả các ví dụ phải đến từ lớp được định trước. Đối với hầu hết các hệ thống nhận dạng mẫu, các mô hình nhận một hình ảnh và trả về một lớp chiến thắng có điểm số cao nhất trong tất cả các lớp. Giả định i.i.d giả sử rằng tất cả các mẫu trên Dtrain hoặc Dtest được rút ra từ một phân phối giống hệt nhau. Dưới giả định i.i.d, mục tiêu có thể được xấp xỉ bởi rủi ro thực nghiệm từ các mẫu quan sát được trên Dtrain. Giả định dữ liệu sạch và lớn giả sử rằng tất cả dữ liệu được thu thập nên được gán nhãn tốt và đủ lớn để bao phủ dân số.

Trên thực tế, không có giả định nào ở trên được thỏa mãn trong kịch bản thế giới thực. Hình 1 cho thấy một số hình ảnh trong bộ dữ liệu MNIST nằm ở ranh giới của hai lớp trong không gian ngữ nghĩa. Việc gán nhãn những hình ảnh đó là một trong hai lớp hoặc cả hai lớp đều có thể chấp nhận được. Hình 2 cho thấy các hình ảnh có nhiều đối tượng trong bộ dữ liệu ImageNet. Hơn nữa, khoảng cách ngữ nghĩa giữa các lớp không đồng nhất. Ví dụ, ô tô và xe tải là hai lớp tương tự trong bộ dữ liệu CIFAR10. Đối với bộ dữ liệu ImageNet, kính râm (n04355933) và kính râm (n04356056) bị trùng lặp. máy tính xách tay (n03642806) và sổ tay (n03832673) trong bộ dữ liệu ImageNet giống hệt nhau trong không gian ngữ nghĩa nhưng sổ tay có thể đề cập đến một cuốn sách giấy trắng. Các nghiên cứu trước đây cho rằng quy trình chú thích sai có thể gây ra suy giảm hiệu suất [41], [42].

Mặc dù quy trình huấn luyện ban đầu sử dụng softmax cross entropy loss (SCE) với các vector một-hot đạt được hiệu suất tốt với loss thực nghiệm thấp, vẫn có một số vấn đề cần được giải quyết. Một vấn đề là mô hình được huấn luyện có xu hướng đưa ra dự đoán quá tự tin trên các mẫu mơ hồ hoặc dự đoán kém trên các mẫu được rút ra từ các phân phối khác nhau. Hiện tượng này, được gọi là quá khớp, đã được quan sát trong cả huấn luyện tự nhiên và đối kháng [43]. Hơn nữa, khi tối thiểu hóa loss SCE với các vector một-hot, xác suất của phần còn lại của các lớp ngoài lớp được chọn có xu hướng mờ dần. Do đó, nó có thể dẫn đến tình huống mà hai mô hình có cùng độ chính xác, nhưng một mô hình phân loại sai nhiều mẫu tầm thường hơn mô hình kia. Trong kịch bản này, chúng ta sẽ coi mô hình sau là vượt trội, bất chấp tỷ lệ phân loại sai cao của nó trong vùng mơ hồ. Bằng chứng này cho thấy rằng các biểu diễn một-hot không đủ để cung cấp thông tin từ nhiều lớp trong những hình ảnh mơ hồ đó.

Để phá vỡ giả định thế giới đóng, việc có một thước đo chính xác để ước tính sự không khớp phân phối là cần thiết. Ở đây, chúng tôi đo lường khoảng cách bất đồng của một mô hình Z bằng độ gần giữa xác suất đầu ra p và xác suất oracle yg với một hàm được sử dụng rộng rãi khác là phân kỳ Kullback–Leibler (KLD).

Định nghĩa 1. Cho D là tập hợp tất cả dữ liệu cần phân loại, x là một thể hiện trong D, yg(x) là phân phối oracle của x, và p là xác suất đầu ra bởi Z của x. Bất đồng của Z được định nghĩa bằng biểu thức sau:

G(Z) = E (x,yg)∼D [Σk i=1 yg i log yg i / pi] (7)
= E (x,yg)∼D [-Σk i=1 yg i log pi + C], (8)

trong đó C là một hằng số. Đáng chú ý là việc giải quyết bài toán phân loại sử dụng loss SCE là một trường hợp đặc biệt của việc tối thiểu hóa khoảng cách KLD bằng cách thay thế phân phối oracle bằng các vector một-hot. Thước đo trên cung cấp cái nhìn sâu sắc có giá trị về hiệu suất của một mô hình Z. Cụ thể, nếu G(Z) nhỏ, mô hình tốt hơn vì đầu ra của nó gần với phân phối oracle hơn.

Như đã đề cập trong Phần 3, nhãn một-hot không đáng tin cậy như các nhãn thu được từ phân phối oracle. Một cách tiếp cận là xấp xỉ phân phối oracle sử dụng khung chưng cất kiến thức [38]. Mặc dù dữ liệu huấn luyện vẫn bị thiên vị, các nhãn mềm, nếu được tạo ra chính xác, có thể phản ánh các phân phối cơ bản, bao gồm các mối quan hệ giữa các lớp và biểu diễn chính xác của các ví dụ mơ hồ, và đẩy ranh giới quyết định về phía ranh giới tối ưu.

Sức mạnh của chưng cất kiến thức nằm ở tính linh hoạt của nó để chọn nhiệt độ tối ưu có thể được thích ứng với các loại bộ dữ liệu thế giới thực khác nhau như được thể hiện trong Hình 1 và 2. Để xác thực tính hữu ích của nhãn mềm, chúng tôi đã tiến hành phân tích lý thuyết cho phân loại nhị phân với một ví dụ duy nhất, tiết lộ rằng các ràng buộc yêu cầu để nhãn mềm vượt trội hơn các vector một-hot không đặc biệt nghiêm ngặt. Tuy nhiên, bất đồng trong Eq (7) là một giá trị kỳ vọng trên tất cả các ví dụ trong bộ dữ liệu, có nghĩa là một số ví dụ vi phạm các ràng buộc là cho phép. Chúng tôi tiếp tục thực hiện mô phỏng trên các bài toán phân loại sử dụng dữ liệu tổng hợp, chứa chỉ 3% dữ liệu mơ hồ và có hai mô hình, mô hình 1 và mô hình 2, được huấn luyện sử dụng nhãn một-hot và nhãn mềm tương ứng. Phân tích và mô phỏng của chúng tôi có thể được tìm thấy trong Phụ lục C. Phân tích cho thấy bốn kết quả quan trọng.

Đầu tiên, ngay cả một tỷ lệ nhỏ dữ liệu nhiễu có thể đóng vai trò quan trọng trong việc làm suy giảm hiệu suất của các bộ phân loại. Thứ hai, phân phối nhãn một-hot được sử dụng phổ biến có những hạn chế. Thứ ba, việc lựa chọn nhiệt độ quan trọng trong việc tạo ra nhãn mềm. Thứ tư, mô hình được huấn luyện với nhãn mềm có bất đồng nhỏ hơn mặc dù nó có tỷ lệ phân loại sai một phần trăm. Hơn nữa, nếu mô hình được huấn luyện với nhãn mềm có thể phân loại tất cả các ví dụ một cách chính xác và biểu diễn các mối quan hệ giữa các lớp một cách chính xác, bất đồng có thể được giảm thêm.

4. Thuật Toán và Triển Khai

4.1. Khung Huấn Luyện

Dựa trên phân tích, chúng tôi đề xuất một khung huấn luyện, được gọi là Chưng Cất Nhiệt Độ Thấp (LTD), có kiến trúc được thể hiện trong Hình 3. Theo khung chưng cất kiến thức, mô hình giáo viên trong LTD được thu được từ quy trình huấn luyện bình thường sử dụng loss SCE với hình ảnh tự nhiên x và nhãn được mã hóa một-hot y. Mô hình giáo viên được huấn luyện có độ chính xác tự nhiên cao nhưng kém về độ bền vững.

Mô hình mục tiêu, là mô hình học sinh ở đây, được huấn luyện bằng một bài toán tối ưu hóa mục tiêu đa với dữ liệu đối kháng và dữ liệu tự nhiên vì một số nghiên cứu đã cho thấy rằng các ví dụ đối kháng được biết là được rút ra từ một phân phối không thể được mô phỏng bởi dữ liệu tự nhiên. Hàm loss của nó được định nghĩa là:

LLTD = L(Z(x;θ), pt(T=τ)) + λΔL(x', x;θ), (9)

trong đó pt(T=τ) là nhãn mềm thu được từ mô hình giáo viên với nhiệt độ đã cho τ; L là để định hình phân phối của các ví dụ tự nhiên; ΔL là để tối thiểu hóa sự thay đổi phân phối giữa dữ liệu tự nhiên và các ví dụ đối kháng, và λ là để cân bằng hai loss. Các nghiên cứu trước đây [24], [25], [34] đã cho thấy λ khoảng 6.0. Trong giai đoạn huấn luyện, các ví dụ đối kháng được tạo ra sử dụng thông tin của mô hình mục tiêu và nhãn gốc y. Các nhãn cho L là các nhãn mềm được tạo ra bởi mô hình giáo viên, có thể được tạo ra trước hoặc trong quá trình. Khác với công việc trước đây, LTD sử dụng nhiệt độ tương đối thấp trong mô hình giáo viên và sử dụng nhiệt độ khác nhau nhưng cố định cho mô hình giáo viên và học sinh. Sự sửa đổi nhỏ nhưng quan trọng này cung cấp một cách hiệu quả để tăng cường độ bền vững và duy trì độ chính xác tự nhiên đồng thời. Hơn nữa, LTD là một khung dễ triển khai có thể được tích hợp vào các mô hình hiện có.

4.2. Lựa Chọn Nhiệt Độ

Theo tính chất của (5), nếu nhiệt độ của mô hình giáo viên đủ cao, phân phối dần dần trở nên đồng nhất. Kết quả là, mối quan hệ giữa các lớp bị phá hủy và bất đồng được định nghĩa trong Eq (7) bị chi phối bởi các lớp không liên quan. Điều này ngụ ý rằng giả định về phân phối là không chính xác, vì vậy không cần xem xét độ bền vững. Tuy nhiên, việc tìm nhiệt độ tối ưu của mô hình giáo viên phụ thuộc vào bộ dữ liệu và kiến trúc mô hình. Ví dụ, các mô hình được sử dụng phổ biến cho bộ dữ liệu CIFAR10 có dự đoán rất tự tin và phân phối đầu ra của chúng gần với phân phối một-hot. Do đó, nhiệt độ nên được tăng lên. Mặt khác, đối với ImageNet hoặc các bộ dữ liệu quy mô lớn, phân phối ban đầu có thể đã phù hợp cho LTD.

Chúng tôi đề xuất một phương pháp hai bước để tìm kiếm nhiệt độ tối ưu cho huấn luyện LTD. Trong bước đầu tiên, các mô hình thay thế được huấn luyện chỉ sử dụng dữ liệu tự nhiên và nhãn mềm được tạo từ một mô hình được huấn luyện tốt với nhiều nhiệt độ khác nhau. Độ chính xác tự nhiên của mỗi mô hình thay thế được đánh giá và so sánh với một ngưỡng được xác định trước. Nếu độ chính xác tự nhiên của một mô hình thay thế thấp hơn ngưỡng, nhiệt độ tương ứng được sử dụng để tạo ra nhãn mềm của nó được đặt làm giới hạn trên cho phạm vi nhiệt độ cần xem xét trong bước thứ hai. Trong bước thứ hai, nhiệt độ tối ưu được xác định bằng cách tìm kiếm nhiệt độ tối thiểu hóa hàm loss được đề xuất của chúng tôi, được định nghĩa trong phương trình (9), sử dụng bất kỳ thuật toán tối ưu hóa siêu tham số nào trong phạm vi nhiệt độ [1, τmax]. Điều quan trọng cần lưu ý là nhiệt độ khả thi phải thấp hơn τmax vì các ví dụ đối kháng làm tổn hại độ chính xác tự nhiên. Bằng cách tìm kiếm nhiệt độ tối ưu trong phương pháp hai bước này, chúng ta có thể đảm bảo rằng mô hình mục tiêu được huấn luyện với nhiệt độ phù hợp cho bộ dữ liệu và kiến trúc mô hình đã cho, dẫn đến cải thiện độ bền vững và độ chính xác tự nhiên.

4.3. So Sánh với Các Công Trình Hiện Có

Trong phần này, chúng tôi thảo luận ngắn gọn về sự khác biệt giữa các công trình hiện có, bao gồm mục tiêu cần tối thiểu hóa, việc sử dụng khung chưng cất kiến thức, và biểu diễn nhãn.

Công Thức Hàm Loss Mục tiêu được nêu trong Eq (9) tương tự như các công trình trước đây, như TRADES [24], AWP [34], và [25]. Tuy nhiên, chúng tôi nhấn mạnh rằng có một sự khác biệt cơ bản giữa phương pháp của chúng tôi và của họ, nằm ở giả định phân phối cho dữ liệu tự nhiên. Trong các công trình trước đây, thuật ngữ đầu tiên trong công thức của họ sử dụng nhãn một-hot, có thể tạo ra thiên vị trong phân phối đầu ra học được từ L(Z(x;θ), y). Thiên vị này có thể khiến phân phối đối kháng hội tụ về một phân phối không chính xác. Phân tích trước đây của chúng tôi cho thấy rằng nó có thể làm xấu đi khoảng cách bất đồng giữa phân phối oracle. Ngoài ra, các nghiên cứu gần đây đã chỉ ra rằng quá khớp bền vững là một hiện tượng phổ biến trong những công trình này [43]. Để giảm thiểu vấn đề này, một chiến lược hữu ích là dừng sớm. Ví dụ, TRADES chấm dứt quy trình huấn luyện sau lần thứ hai giảm tốc độ học ngay lập tức trong cấu hình mặc định. Ngược lại, chúng tôi mô phỏng phân phối oracle bằng một mô hình được huấn luyện tự nhiên với chưng cất nhiệt độ thấp.

Chưng Cất Phòng Thủ Chưng cất phòng thủ [32] áp dụng chưng cất kiến thức cho huấn luyện đối kháng. Tuy nhiên, mục tiêu của nó vẫn muốn khớp với các nhãn một-hot. Thay vào đó, mục đích của phương pháp huấn luyện của chúng tôi là học các nhãn mềm từ mô hình giáo viên. Hơn nữa, công trình trước đây đã chỉ ra rằng nguyên tắc của chưng cất phòng thủ gặp phải vấn đề che giấu gradient [31], như được chứng minh bởi tấn công CW [16]. Có hai yếu tố chính gây ra vấn đề này. Đầu tiên, gradient của hình ảnh có thể được công thức hóa như một hàm của xác suất đầu ra:

∇xLSCE = (pt-1)∇xqt + Σi≠t pi∇xqi,

trong đó pi là xác suất của lớp i và qi là logit của lớp i. Phương trình này cho thấy gradient gần như biến mất khi pt gần bằng 1, điều này làm cho kẻ tấn công khó tạo ra các ví dụ đối kháng bằng gradient trong thời gian suy luận.

Thứ hai, nhiệt độ của chế độ mục tiêu trong giai đoạn huấn luyện (Tt) và trong giai đoạn suy luận (Ti) khác nhau, trong đó Tt cao và Ti = 1. Điều này có nghĩa là xác suất đầu ra ở nhiệt độ cao (Tt) nằm trong phân phối một-hot, và độ lớn của logit trong thời gian suy luận là (Tt/Ti) = Tt lần lớn hơn so với trong thời gian huấn luyện. Do đó, logit lớn nhất chi phối các logit khác và xác suất đầu ra hội tụ về một vector một-hot và rơi vào vùng gradient-biến mất.

Sự kết hợp của hai yếu tố này làm cho vấn đề che giấu gradient trở nên nghiêm trọng hơn. Do đó, kẻ tấn công không thể tạo ra các ví dụ đối kháng bằng gradient trong thời gian suy luận. Giải pháp chúng tôi đề xuất trong công trình này là sử dụng nhiệt độ khác nhau nhưng cố định cho mô hình giáo viên và học sinh. Cụ thể, chúng tôi chỉ điều chỉnh nhiệt độ để tạo ra nhãn mềm nhưng giữ nhiệt độ cho mô hình học sinh cố định. Phương pháp này đảm bảo rằng độ lớn của logit không thay đổi và che giấu gradient không xảy ra.

Biểu Diễn Nhãn Làm mịn nhãn [44] và học từ các nhãn nhiễu là hai phương pháp được sử dụng phổ biến để điều chỉnh biểu diễn nhãn. Phương pháp trước, làm mịn nhãn, phân phối lại xác suất một phần từ lớp thực tế sang phần còn lại của các lớp để ngăn mô hình quá khớp với phân phối một-hot. Ngược lại, phương pháp sau, học từ nhãn nhiễu, áp dụng một quá trình ngẫu nhiên trên nhãn mà không xem xét bối cảnh trong hình ảnh, nhằm mô phỏng nhiễu trong các kịch bản thế giới thực.

Trong khi cả hai phương pháp có thể đạt được cùng một mục tiêu, việc tạo ra nhãn mềm từ một mô hình được huấn luyện tốt có thể bảo tồn mối quan hệ giữa các lớp. Một biểu diễn nhãn tốt hơn là thay thế nhãn một-hot bằng phân phối có thể tiết lộ xác suất của các lớp liên quan đến lớp mục tiêu.

5. Thí Nghiệm

Phần này trình bày độ bền vững của LTD chống lại các cuộc tấn công hộp trắng, so sánh với các phương pháp khác trên các bộ dữ liệu CIFAR10, CIFAR100, và ImageNet, và các nghiên cứu loại bỏ về nhiệt độ và λ. Cấu hình thí nghiệm đầy đủ được trình bày trong Phụ lục A.

5.1. Độ Bền Vững Hộp Trắng

Chúng tôi đánh giá độ bền vững bằng AutoAttack (AA) [17], bao gồm APGD-CE, APGD-T, FAB-T, và Square attack. APGD-CE, APGD-T, và FAB-T là các cuộc tấn công dựa trên PGD với các mục tiêu hoặc quy tắc cập nhật khác nhau. Vì hầu hết các biện pháp phòng thủ tạo ra các ví dụ đối kháng bằng một thuật toán tấn công cụ thể, mô hình mục tiêu có thể quá khớp với thuật toán tấn công đã cho. Do đó, mô hình mục tiêu có thể bị đánh bại bởi các thuật toán khác và độ chính xác bền vững có sự giảm đáng kể cuối cùng. Trong [31], các tác giả tuyên bố nếu các cuộc tấn công hộp đen hiệu quả hơn các cuộc tấn công hộp trắng, các phương pháp phòng thủ có vấn đề che giấu gradient. Square attack là một cuộc tấn công hộp đen hiệu quả truy vấn có thể phát hiện hiệu ứng che giấu gradient. Để tăng tốc hiệu quả tính toán, AA lọc ra dữ liệu bị phân loại sai bởi cuộc tấn công hiện tại một cách nhanh chóng và phần còn lại của các ứng viên sẽ được kiểm tra với các cuộc tấn công tiếp theo. Độ chính xác cuối cùng được báo cáo bởi AA đảm bảo độ bền vững không bị đánh giá quá cao.

Chúng tôi tiến hành thí nghiệm trên các bộ dữ liệu CIFAR10, CIFAR100, và ImageNet để đánh giá hiệu quả của phương pháp được đề xuất của chúng tôi. Bảng 1 cho thấy kết quả thí nghiệm của CIFAR10, Bảng 2 trình bày kết quả của CIFAR100, và Bảng 3 đưa ra kết quả của ImageNet. Trong các bảng này, acc nat biểu thị độ chính xác trên dữ liệu tự nhiên, và acc AA biểu thị độ chính xác bền vững chống lại tấn công AA. Thứ tự của các phương pháp dựa trên độ chính xác bền vững acc AA của chúng. Các số trong # biểu thị thứ hạng ban đầu của các phương pháp khác trong RobustBench [33], và các mục có * biểu thị kết quả của chúng tôi. Chúng tôi cũng bao gồm kết quả của TRADES ở hàng dưới cùng để so sánh.

Như có thể thấy, đối với bộ dữ liệu CIFAR10, việc kết hợp LTD với TRADES tăng độ bền vững từ 53.08% lên 55.09%. Hơn nữa, việc tích hợp AWP với LTD cải thiện độ chính xác bền vững từ 56.17% lên 56.90% sử dụng WRN-34-10. Nếu chúng ta sử dụng WRN-34-20 với AWP và LTD, độ bền vững có thể đạt 58.19%, là kết quả tốt nhất trong tất cả các phương pháp. Việc kết hợp AWP với LTD cũng cải thiện độ chính xác bền vững cho bộ dữ liệu CIFAR100 từ 28.86% lên 31.13% sử dụng WRN-34-10, là kết quả tốt nhất mà không sử dụng dữ liệu bổ sung, và kích thước mô hình nhỏ hơn so với các đối thủ khác. Tương tự, độ bền vững cho bộ dữ liệu ImageNet được cải thiện đáng kể từ 38.14% lên 42.08%.

Kết quả thí nghiệm cho thấy LTD là một phương pháp hiệu quả để cải thiện độ bền vững của các mô hình dựa trên học sâu, đặc biệt cho bộ dữ liệu ImageNet, chứa nhiều hình ảnh mơ hồ và hình ảnh có nhiều đối tượng. Sự khác biệt chính giữa các mô hình ban đầu, TRADES hoặc AWP, và LTD nằm ở các nhãn được sử dụng để huấn luyện. Phương pháp trước sử dụng các vector một-hot làm nhãn, trong khi LTD thay thế chúng bằng nhãn mềm được tạo từ mô hình giáo viên với nhiệt độ thấp. Kết quả phù hợp với giả định của chúng tôi được mô tả trong Phần 3. Các bộ dữ liệu chứa rất nhiều hình ảnh mơ hồ và hình ảnh có nhiều đối tượng. Nhãn mềm là một biểu diễn tốt hơn của những ví dụ đó.

5.2. Lựa Chọn Nhiệt Độ

Chúng tôi sử dụng mô hình WRN-34-10 và bộ dữ liệu CIFAR10 và huấn luyện mô hình sử dụng TRADES+LTD với các nhiệt độ khác nhau trong mô hình giáo viên để xác minh tầm quan trọng của việc lựa chọn nhiệt độ. Như đã đề cập trong Phần 4.2, nhiệt độ tốt nhất được chọn trong hai bước. Như được thể hiện trong Bảng 4, chúng tôi tìm kiếm nhiệt độ tốt nhất trong phạm vi [1.0,50.0], loại trừ đầu cuối vì độ chính xác tự nhiên của nó là 86.63% quá thấp để chấp nhận. Kết quả thí nghiệm được trình bày trong Bảng 4 chứng minh rằng nhiệt độ tốt nhất cho mô hình giáo viên là 5.0. Khi nhiệt độ tăng, độ chính xác bền vững giảm do thực tế là các lớp không liên quan nhận được xác suất một phần từ lớp mục tiêu, điều này vi phạm giả định của chúng tôi. Điều này dẫn đến che giấu gradient, và chúng ta có thể quan sát rằng độ chính xác bền vững trong giai đoạn huấn luyện gần như 100%, nhưng nó không thể phòng thủ chống lại các cuộc tấn công mạnh hơn hoặc các cuộc tấn công chưa thấy. AA xác định sự xuất hiện của che giấu gradient khi nhiệt độ cao hơn 15.0. Hiện tượng này cũng đã được quan sát trong chưng cất phòng thủ, trong đó độ lớn của logit bị thay đổi đáng kể.

Đáng nhấn mạnh rằng phương pháp được đề xuất của chúng tôi vượt trội hơn TRADES qua nhiều lựa chọn nhiệt độ khác nhau. Kết quả này cho thấy rằng giả định một-hot có vẻ quá tự tin trên các bộ dữ liệu thế giới thực. Có một số giả định phân phối có thể đạt được hiệu suất tương tự hoặc cao hơn với các tiêu chí hiện có. Thay vào đó, biểu diễn nhãn mềm được tạo ra bởi các mô hình giáo viên với nhiệt độ thấp là những lựa chọn tốt mặc dù nhiệt độ được sử dụng không phải là tối ưu. Hơn nữa, hiện tượng trên phù hợp với kết quả mô phỏng.

5.3. Nghiên Cứu Loại Bỏ

Thí nghiệm này điều tra ảnh hưởng của việc lựa chọn λ khác nhau đối với độ chính xác tự nhiên và độ chính xác bền vững. Chúng tôi tiến hành nghiên cứu loại bỏ với LTD+AWP trên các bộ dữ liệu CIFAR10 và CIFAR100. Bảng 5 và Bảng 6 cho thấy kết quả trên các bộ dữ liệu CIFAR10 và CIFAR100 tương ứng. Như có thể thấy, độ chính xác tự nhiên giảm khi giá trị của λ tăng trong khi độ chính xác tự nhiên thấp nhất xảy ra khi λ là 7.0 trên cả hai bộ dữ liệu. Những kết quả này cho thấy lựa chọn tốt nhất của λ phải thấp hơn 7.0. Trong khi đó, độ chính xác bền vững tốt nhất xảy ra khi λ là 6.0 phù hợp với các công trình trước đây [26], [34]. Tuy nhiên, nếu chúng ta ưu tiên độ chính xác tự nhiên cao hơn, cấu hình tối ưu của λ có thể là một giá trị nhỏ hơn.

Lý tưởng nhất, λ nên phụ thuộc vào thể hiện và giá trị của nó có thể được tăng lên để tăng cường độ bền vững của một số ví dụ được phân loại tốt. Tuy nhiên, λ được định trước trong những công trình liên quan đó và giá trị tối ưu là giống hệt nhau. Một lý do có thể là những thí nghiệm đó áp dụng một chính sách huấn luyện tương tự và cùng kiến trúc mạng.

5.4. Thảo Luận

Khung huấn luyện được đề xuất, thay thế các nhãn một-hot bằng nhãn mềm, đạt được độ bền vững tốt hơn so với khung huấn luyện ban đầu. Chúng tôi nhấn mạnh rằng phương pháp được đề xuất là phương pháp đầu tiên giảm thiểu hiệu quả vấn đề che giấu gradient đã được quan sát trong chưng cất phòng thủ. Phương pháp này phù hợp cho bài toán phân loại vi phạm thế giới đóng, hoặc giả định dữ liệu sạch và lớn. Một ví dụ xuất sắc của bài toán như vậy là ImageNet, nơi phương pháp của chúng tôi chứng minh cải thiện đáng kể khoảng bốn phần trăm về mặt độ bền vững.

Ảnh Hưởng của Kiến Trúc Hiện tại, các mô hình phổ biến nhất được sử dụng trong các bài nộp được chứng nhận trên RobustBench là ResNet, dòng WRN và vision transformer (ViT). ResNet-18 là một baseline tiêu chuẩn để đánh giá độ bền vững của các mô hình nhẹ. Dòng WRN là các mô hình được sử dụng rộng rãi để so sánh công bằng, đảm bảo rằng cải thiện được thu từ các mô hình được đề xuất. Độ bền vững của ViT gây tranh cãi vì ViT-based thường yêu cầu nhiều ví dụ huấn luyện hơn. Không rõ liệu độ bền vững có lợi thế từ dữ liệu lớn hay các khối đặc biệt trong mạng. Một công trình gần đây đã giới thiệu một cuộc tấn công đối kháng cụ thể cho cơ chế tự chú ý [51]. Mặc dù ảnh hưởng của kiến trúc đối với phương pháp được đề xuất chưa được biết, công trình này tuân theo quy trình huấn luyện được đề xuất bởi TRADES và AWP, và đạt được độ bền vững tốt hơn với cùng kích thước mô hình hoặc nhỏ hơn. Ngoài ra, độ bền vững trên bộ dữ liệu ImageNet là một nhiệm vụ thách thức chưa được nghiên cứu rộng rãi, như tốc độ học ban đầu, kích thước batch, weight decay, hoặc các cấu hình siêu tham số khác cho huấn luyện đối kháng. Chúng tôi tin rằng kết quả thực nghiệm đã chứng minh hiệu quả của các phương pháp được đề xuất trên nhiều bộ dữ liệu khác nhau.

Chưng Cất Kiến Thức Trong bài báo này, chúng tôi xem xét lại khung chưng cất kiến thức cho huấn luyện đối kháng và cung cấp một giải pháp thực tế để khắc phục vấn đề che giấu gradient. Những kết quả này mang lại cơ hội để có được một mô hình bền vững nhưng nhẹ hoặc nén bằng cách sử dụng khung chưng cất kiến thức. Tuy nhiên, đánh giá độ bền vững phức tạp hơn đối với các mô hình nén, vì các mô hình mục tiêu có thể bị đánh bại bởi các ví dụ đối kháng được tạo ra bởi các mô hình chưa được cắt tỉa.

Chúng tôi thừa nhận rằng việc lựa chọn nhiệt độ tối ưu cho chưng cất kiến thức phụ thuộc vào độ phức tạp của bộ dữ liệu mục tiêu. Nếu các ví dụ có thể được phân loại chính xác mà không có sự mơ hồ, không cần thiết phải sửa đổi biểu diễn nhãn của chúng. Tuy nhiên, đối với các ví dụ mơ hồ, nhiệt độ nên được điều chỉnh động dựa trên độ tin cậy của chúng. Trong công trình của chúng tôi, chúng tôi áp dụng một nhiệt độ toàn cục cho tất cả các ví dụ, có thể được tinh chỉnh trong các công trình tương lai. Một giải pháp tiềm năng cho vấn đề này là sử dụng một bộ phân loại phụ trợ để xác định các ví dụ mơ hồ và sử dụng thông tin đầu ra như một thước đo để thiết kế các chiến lược điều chỉnh nhiệt độ.

Ngoài ra, việc lựa chọn mô hình giáo viên là một bài toán mở. Chúng tôi chọn huấn luyện mô hình giáo viên một cách tự nhiên, thay vì đối kháng, vì huấn luyện đối kháng có thể không nhất thiết tạo ra các giáo viên tốt trong khung của chúng tôi. Huấn luyện đối kháng có xu hướng ưu tiên độ bền vững hơn độ chính xác, và kết quả là, độ chính xác tự nhiên của mô hình giáo viên có thể tương đối thấp. Chúng tôi thí nghiệm với việc sử dụng một mô hình được huấn luyện đối kháng làm giáo viên, nhưng thấy rằng các mô hình học sinh được huấn luyện đạt được độ chính xác tự nhiên thấp hơn. Đối với bộ dữ liệu CIFAR10, độ chính xác tự nhiên của mô hình học sinh thấp hơn 82%, thường không thể chấp nhận được. Trong khi các mô hình được huấn luyện đối kháng có thể trích xuất các đặc trưng cơ bản có thể cải thiện độ bền vững, một số vấn đề cần được khắc phục trước khi chúng có thể được sử dụng hiệu quả làm mô hình giáo viên trong khung của chúng tôi.

Biểu Diễn Nhãn Ước tính phân phối oracle là một bài toán quan trọng, nhưng LTD không phải là giải pháp duy nhất để dự đoán phân phối oracle. Một số công trình trước đây đã đề xuất các giải pháp thay thế. A Vmixup [52] tăng cường các ví dụ huấn luyện bằng cách định nghĩa các ví dụ ảo, sử dụng nội suy tuyến tính cho cả ví dụ đầu vào và nhãn của chúng. Trong khi mô hình được huấn luyện bởi A Vmixup có thể giảm thiểu vấn đề quá khớp, nó không thể phòng thủ chống lại các cuộc tấn công CW hoặc các cuộc tấn công PGD với các mục tiêu khác nhau, đặc biệt đối với CIFAR100 và các bộ dữ liệu phức tạp hơn. Mặt khác, CCAT [53] tiếp tục đề xuất rằng biểu diễn nhãn nên được hiệu chuẩn theo cường độ của các ví dụ đối kháng. Một phương pháp khác được đề xuất bởi [54] là huấn luyện mô hình từ hai giáo viên, một là mô hình được huấn luyện tự nhiên và cái kia là mô hình được huấn luyện đối kháng, có thể giảm thiểu quá khớp. Huấn luyện ensemble cũng có thể là một giải pháp thích hợp để tránh vấn đề quá tự tin, nhưng thiếu các nghiên cứu có hệ thống để thiết kế các mô hình giáo viên, bao gồm tổng số mô hình giáo viên, chính sách huấn luyện, và các kiến trúc được sử dụng cho mỗi mô hình giáo viên.

Huấn Luyện Đối Kháng với Dữ Liệu Bổ Sung Chiến lược hiệu quả nhất để cải thiện độ bền vững trên các bộ dữ liệu CIFAR10 hoặc CIFAR100 là sử dụng các ví dụ bổ sung từ các bộ dữ liệu bên ngoài. Lý do chính là học có giám sát truyền thống gần như bỏ qua dữ liệu tần số thấp vì vậy DNN không thể nhận ra chúng một cách chính xác. Thêm dữ liệu bổ sung có thể bao phủ dữ liệu trong chế độ tần số thấp trong tập huấn luyện ban đầu. UAT [35] cho thấy TRADES trên CIFAR10 với 200,000 hình ảnh bổ sung cải thiện độ bền vững đáng kể. Trong UAT, các tác giả cũng kết luận rằng việc lựa chọn một tập con từ các hình ảnh bổ sung một cách thích hợp có độ bền vững tốt hơn so với việc sử dụng toàn bộ hình ảnh bổ sung. Công trình tiếp theo RST [36] thiết kế một bộ phân loại đặc biệt để chọn các hình ảnh liên quan, được tham gia vào tập huấn luyện đối kháng, từ một bộ dữ liệu khác.

Tuy nhiên, loại phương pháp này bị loại trừ khỏi phương pháp của chúng tôi. Chúng tôi tin rằng việc lựa chọn dữ liệu dưới cùng phân phối là một bài toán mở và phân phối của các ví dụ huấn luyện chung bị thay đổi hoàn toàn vì dữ liệu chung được chọn bởi một bộ phân loại phụ trợ trước. Hơn nữa, một lời chỉ trích khác là số lượng hình ảnh bổ sung lớn hơn nhiều so với tập huấn luyện của CIFAR10 (50,000 hình ảnh), và xử lý những dữ liệu đó yêu cầu chi phí tính toán nhiều hơn. Những công trình tương tự, dựa vào hình ảnh bổ sung khổng lồ, không thể được mở rộng cho ImageNet hoặc các bộ dữ liệu quy mô lớn khác. Ngược lại, LTD có thể đạt được cải thiện đáng kể về độ bền vững trên bộ dữ liệu ImageNet. Tuy nhiên, chúng tôi tin rằng một hướng của công việc tương lai là xác định các ngoại lệ trước và loại trừ những ví dụ đó khỏi tập huấn luyện để tăng tốc độ huấn luyện.

6. Kết Luận

Việc sử dụng nhãn một-hot như một biểu diễn cho các bài toán phân loại là thực hành phổ biến. Trong bài báo này, chúng tôi đã chứng minh rằng nhãn một-hot không chính xác và một trong những điểm yếu của DNN phát sinh từ các ví dụ mơ hồ. Chúng tôi cũng đã khám phá những ưu điểm của nhãn mềm, có thể giảm đáng kể sự bất đồng giữa xác suất oracle và dự đoán từ một mô hình được huấn luyện bằng nhãn mềm. Để huấn luyện DNN bền vững, chúng tôi đề xuất một khung chưng cất kiến thức được sửa đổi sử dụng nhãn mềm với nhiệt độ thích hợp thấp. Bằng cách sử dụng các nhiệt độ khác nhau cho mô hình giáo viên và học sinh, chúng tôi tránh được vấn đề che giấu gradient, trong khi nhãn mềm có thể biểu diễn phân phối xác suất mượt mà hơn giữa các lớp. Kết quả thí nghiệm trên các bộ dữ liệu CIFAR10 và CIFAR100 cho thấy phương pháp của chúng tôi, khi kết hợp với AWP, đạt được độ chính xác bền vững 58.19% và 31.13% tương ứng. Đối với bộ dữ liệu ImageNet, phương pháp của chúng tôi đạt được cải thiện khoảng 4% về độ bền vững. Những kết quả này cung cấp cái nhìn sâu sắc về cách chú thích nhãn ảnh hưởng đến độ bền vững của mạng nơ-ron sâu. Chúng tôi tin rằng việc thiết kế biểu diễn nhãn tốt hơn cho các kịch bản thế giới thực vẫn là một vấn đề chưa được khám phá.

# 2112.05005.pdf
# Đã chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/adversarial/2112.05005.pdf
# Kích thước tệp: 558048 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
JIANG LIU: HUẤN LUYỆN ĐỐI KHÁNG TƯƠNG HỖ 1
Huấn Luyện Đối Kháng Tương Hỗ:
Học cùng nhau tốt hơn là đi một mình.
Jiang Liu1
jiangliu@jhu.edu
Chun Pong Lau1
clau13@jhu.edu
Hossein Souri1
hsouri1@jhu.edu
Soheil Feizi2
sfeizi@cs.umd.edu
Rama Chellappa1
rchella4@jhu.edu1Đại học Johns Hopkins,
Baltimore, Maryland, Hoa Kỳ
2Đại học Maryland, College Park
College Park, Maryland, Hoa Kỳ
Tóm tắt
Các nghiên cứu gần đây đã chỉ ra rằng độ bền vững trước các cuộc tấn công đối kháng có thể được chuyển giao
giữa các mạng. Nói cách khác, chúng ta có thể làm cho một mô hình yếu trở nên bền vững hơn với sự trợ giúp
của một mô hình giáo viên mạnh. Chúng tôi đặt câu hỏi liệu thay vì học từ một giáo viên tĩnh, các mô-
hình có thể "học cùng nhau" và "dạy lẫn nhau" để đạt được độ bền vững tốt hơn không? Trong bài báo này,
chúng tôi nghiên cứu cách tương tác giữa các mô hình ảnh hưởng đến độ bền vững thông qua chưng cất kiến thức.
Chúng tôi đề xuất huấn luyện đối kháng tương hỗ (MAT), trong đó nhiều mô hình được huấn luyện
cùng nhau và chia sẻ kiến thức về các ví dụ đối kháng để đạt được độ bền vững được cải thiện.
MAT cho phép các mô hình bền vững khám phá một không gian lớn hơn của các mẫu đối kháng, và
tìm ra những không gian đặc trưng và biên quyết định bền vững hơn. Thông qua các thí nghiệm mở rộng
trên CIFAR-10 và CIFAR-100, chúng tôi chứng minh rằng MAT có thể cải thiện hiệu quả độ bền vững mô hình
và vượt trội hơn các phương pháp hiện đại dưới các cuộc tấn công hộp trắng, mang lại
8% tăng độ chính xác cho huấn luyện đối kháng thông thường (AT) dưới các cuộc tấn công PGD-100. Ngoài
ra, chúng tôi chỉ ra rằng MAT cũng có thể giảm thiểu sự đánh đổi độ bền vững giữa các
loại nhiễu loạn khác nhau, mang lại tăng độ chính xác lên đến 13.1% cho các đường cơ sở AT chống lại hợp
của các cuộc tấn công l¥,l2 và l1. Những kết quả này cho thấy sự ưu việt của phương pháp đề xuất
và chứng minh rằng học hợp tác là một chiến lược hiệu quả để thiết kế các
mô hình bền vững.
1 Giới thiệu
Trong những năm gần đây, chúng ta đã chứng kiến thành công lớn của mạng nơ-ron sâu (DNNs) trong nhiều
lĩnh vực của trí tuệ nhân tạo bao gồm thị giác máy tính [20], nhận dạng giọng nói [15],
và điều khiển robot [26]. Mặc dù có hiệu suất vượt trội, DNNs được chỉ ra là dễ bị tổn thương
trước các cuộc tấn công đối kháng mà thêm các thao tác không thể nhận thấy vào đầu vào [5, 6, 9, 12, 17, 21,
© 2021. Bản quyền của tài liệu này thuộc về các tác giả.
Nó có thể được phân phối không thay đổi một cách tự do ở dạng in hoặc điện tử.arXiv:2112.05005v1  [cs.LG]  9 Dec 2021

--- TRANG 2 ---
2 JIANG LIU: HUẤN LUYỆN ĐỐI KHÁNG TƯƠNG HỖ
Bảng 1: So sánh các phương pháp phòng thủ dựa trên KD. "Robust" có nghĩa là mô hình được huấn luyện với
các ví dụ đối kháng và "Natural" có nghĩa là mô hình được huấn luyện với các ví dụ tự nhiên.
Phương pháp Mô hình Giáo viên Mô hình Học sinh Hình thức KD Nhiều Nhiễu loạn
DD [32] Tự nhiên Tự nhiên Ngoại tuyến 7
ARD [11] Bền vững Bền vững Ngoại tuyến 7
ACT [1] Tự nhiên Bền vững Trực tuyến 7
MAT (Của chúng tôi) Bền vững Bền vững Trực tuyến 3
22, 28, 31]. Điều này đặt ra một thách thức lớn trong các ứng dụng quan trọng về bảo mật như lái xe tự động
và y học.
Để tăng cường độ bền vững của mô hình chống lại các cuộc tấn công đối kháng, nhiều phương pháp phòng thủ đã
được đề xuất bao gồm các phòng thủ thực nghiệm [18, 27, 28, 32, 37, 44, 46] và có thể chứng minh [8, 23,
24, 25, 33, 38]. Huấn luyện đối kháng (AT) [28] được coi là một trong những
thuật toán hiệu quả nhất cho phòng thủ đối kháng. Đã có nhiều công trình cải thiện huấn luyện đối kháng
bằng cách sử dụng các hàm mất mát khác nhau, như ALP [18], TRADES [46], và MART [44].
Tuy nhiên, chúng chỉ huấn luyện một mô hình mà không xem xét sự hiệp đồng của một nhóm mạng. Ngoài
ra, hầu hết các phương pháp phòng thủ tập trung vào một loại nhiễu loạn duy nhất, có thể dễ bị tổn thương
trước các loại nhiễu loạn chưa thấy [29, 40]. Ví dụ, các mô hình được huấn luyện đối kháng trên các ví dụ đối kháng
bị giới hạn l¥ có thể dễ bị tổn thương trước các cuộc tấn công bị giới hạn l1 và l2.
Chưng cất kiến thức (KD) [16] là một phương pháp nổi tiếng để chuyển giao kiến thức
được học bởi một mô hình sang mô hình khác. Có nhiều hình thức KD [43] bao gồm KD ngoại tuyến,
nơi các mô hình giáo viên được huấn luyện trước và học sinh học từ các giáo viên tĩnh[16],
và KD trực tuyến, nơi một nhóm mô hình học sinh học từ dự đoán của đồng nghiệp [13, 39, 47].
Một số kỹ thuật dựa trên KD đã được đề xuất cho phòng thủ đối kháng [1, 7, 11, 32].
[11] chứng minh rằng độ bền vững có thể được chuyển giao giữa các mô hình thông qua KD và [7]
chỉ ra rằng KD có thể giúp giảm thiểu sự quá khớp bền vững. Bảng 1 tóm tắt sự khác biệt
giữa các phòng thủ dựa trên KD. Chúng tôi lập luận rằng các phòng thủ dựa trên KD hiện tại là không tối ưu
về mặt cải thiện độ bền vững đối kháng. Chưng cất phòng thủ (DD) huấn luyện một mô hình tự nhiên
với một mô hình tự nhiên khác làm giáo viên, không thể cung cấp độ bền vững mạnh vì cả
giáo viên và học sinh đều không được huấn luyện đối kháng, và nó bị phá vỡ bởi [4]. Chưng cất
bền vững đối kháng (ARD) [11] huấn luyện một mô hình bền vững với một mô hình bền vững khác làm giáo viên để
chưng cất độ bền vững của một mạng lớn vào một học sinh nhỏ hơn, phụ thuộc vào sự tồn tại
của các mô hình giáo viên mạnh, và sự cải thiện của mô hình học sinh bị hạn chế vì giáo viên
là cố định. Huấn luyện đồng thời đối kháng (ACT) [1] huấn luyện một mô hình tự nhiên và một mô hình bền vững cùng nhau
theo cách KD trực tuyến để căn chỉnh không gian đặc trưng của cả hai. Tuy nhiên, vì các mô hình tự nhiên
và mô hình bền vững học các đặc trưng cơ bản khác nhau [42], việc căn chỉnh không gian đặc trưng của
một mô hình bền vững với một mô hình tự nhiên có thể dẫn đến độ bền vững suy giảm.
Trong bài báo này, chúng tôi đề xuất Huấn Luyện Đối Kháng Tương Hỗ (MAT) cho phép các mô hình
chia sẻ kiến thức về độ bền vững đối kháng và dạy lẫn nhau để trở nên bền vững hơn.
Không giống như các phòng thủ dựa trên KD trước đây, chúng tôi huấn luyện một nhóm mô hình bền vững đồng thời, và
mỗi mạng không chỉ học từ nhãn thực tế như trong AT tiêu chuẩn, mà còn từ các
nhãn mềm từ các mạng đồng nghiệp mã hóa kiến thức của đồng nghiệp để phòng thủ các cuộc tấn công đối kháng để
đạt được độ bền vững mạnh hơn. Kiến trúc của MAT được hiển thị trong Hình 1.
MAT cải thiện độ bền vững mô hình thông qua nhiều khía cạnh: 1) MAT kế thừa các lợi ích
của KD, như cải thiện khả năng tổng quát hóa [10] và giảm sự quá khớp bền vững [7]. 2) MAT
tạo ra một vòng phản hồi tích cực tăng độ bền vững mô hình. Mỗi mạng phục vụ như
một giáo viên bền vững để cung cấp các nhãn mềm nhận thức ngữ nghĩa và phân biệt cho đồng nghiệp. Bằng cách
học từ các đồng nghiệp mạnh, một mạng trở nên bền vững hơn, điều này lần lượt cải thiện độ bền

--- TRANG 3 ---
JIANG LIU: HUẤN LUYỆN ĐỐI KHÁNG TƯƠNG HỖ 3
Hình 1: Kiến trúc huấn luyện đối kháng tương hỗ (MAT). x là một hình ảnh sạch, xq1
adv là
hình ảnh đối kháng của mạng h1, và xq2
adv là hình ảnh đối kháng của mạng h2.
vững của các đồng nghiệp. 3) MAT cho phép các mô hình bền vững khám phá một không gian lớn hơn của các
mẫu đối kháng, và tìm ra những không gian đặc trưng và biên quyết định bền vững hơn cùng nhau. Các ví dụ đối
kháng của mỗi mô hình tạo thành một không gian con của đầu vào đối kháng [41], và các dự đoán
của mỗi mô hình mã hóa thông tin về biên quyết định và không gian con đối kháng của nó. Trong
MAT, mỗi mô hình không chỉ học từ các ví dụ đối kháng của riêng mình, mà còn nhận thông
tin về các ví dụ đối kháng của đồng nghiệp thông qua các nhãn mềm. Theo cách này, mỗi mô hình
cần xem xét một không gian lớn hơn của các mẫu đối kháng, và tìm ra một không gian đặc trưng và biên
quyết định không chỉ hoạt động tốt trên các ví dụ đối kháng của riêng mình mà còn trên các ví dụ đối kháng của đồng nghiệp,
điều này khuyến khích các giải pháp bền vững và có thể tổng quát hóa hơn.
Để tóm tắt, trong bài báo này chúng tôi đề xuất một thuật toán huấn luyện đối kháng dựa trên KD mới
có tên MAT. MAT là một khung tổng quát để tăng cường độ bền vững đối kháng của bất kỳ
mạng nào mà không cần các mô hình giáo viên mạnh. Chúng tôi mở rộng thêm MAT để phòng thủ
chống lại nhiều loại nhiễu loạn (MAT-MP) bằng cách khai thác khả năng chuyển giao của độ bền vững đối
kháng, và đề xuất một số chiến lược huấn luyện để huấn luyện MAT-MP. Các thí nghiệm mở rộng của chúng tôi
cho thấy rằng MAT mang lại những cải thiện độ bền vững đáng kể cho các đường cơ sở AT và
vượt trội hơn các phương pháp hiện đại cho cả nhiễu loạn đơn và nhiều.
2 Huấn Luyện Đối Kháng Tương Hỗ
2.1 Khung của chúng tôi
Trong bài báo này, chúng tôi xem xét bài toán phân loại hình ảnh K-lớp (K2). Chúng ta có các
cặp hình ảnh và nhãn (x;y) được rút ra từ một phân phối dữ liệu cơ bản D, trong đó x2Rd là một
hình ảnh tự nhiên, y=f1;;Kg là nhãn lớp tương ứng của nó. Chúng tôi công thức hóa thuật toán huấn luyện đối kháng tương hỗ đề xuất
với một nhóm hai mạng h1(;q1) và h2(;q2).
Để huấn luyện một h1 bền vững, chúng tôi tối thiểu hóa mất mát phân loại trên các ví dụ đối kháng như
trong huấn luyện đối kháng. Mất mát AT sau đó được định nghĩa là:
LAT1=LC(p1(xq1
adv);y); (1)

--- TRANG 4 ---
4 JIANG LIU: HUẤN LUYỆN ĐỐI KHÁNG TƯƠNG HỖ
trong đó p1 là xác suất đầu ra của h1, LC là một mất mát phân loại, và xq1
adv là một ví dụ đối kháng
được tạo ra cho h1, xq1
adv=x+argmaxd2SLC(p1(x+d);y). Đối với LC, chúng tôi sử dụng mất mát entropy chéo được tăng cường
như trong MART [44], sử dụng một số hạng biên để cải thiện biên quyết định
của bộ phân loại: LC(p(x);y) =log(p(x)y)log(1max k6=yp(x)k).
Để tăng cường độ bền vững của h1, chúng tôi sử dụng mạng đồng nghiệp h2 để cung cấp kiến thức về
độ bền vững cho h1. Cụ thể, chúng tôi sử dụng mất mát KD để hướng dẫn dự đoán của h1:
LKD1=DKL(p2(x)jjp1(xq1
adv)); (2)
trong đó DKL(jj) là phân kỳ Kullback–Leibler (KL) và p2 là xác suất đầu ra
của h2. Lưu ý rằng chúng tôi sử dụng hình ảnh sạch x làm đầu vào cho h2 để tạo ra nhãn mềm p2
vì các ví dụ đối kháng có thể làm lầm h2 để tạo ra dự đoán sai. Mất mát KD
căn chỉnh các không gian đặc trưng và biên quyết định của các mô hình MAT và cho phép chúng
tìm ra các đặc trưng và biên quyết định bền vững cùng nhau. Tương tự, chúng tôi định nghĩa LAT2 và LKD2 cho h2:
LAT2=LC(p2(xq2
adv);y);LKD2=DKL(p1(x)jjp2(xq2
adv)); (3)
trong đó xq2
adv là một ví dụ đối kháng được tạo ra cho h2, xq2
adv=x+argmaxd2SLC(p2(x+d);y).
Hàm mất mát tổng thể cho MAT là:
LMAT = (1a)(LAT1+LAT2) +a(LKD1+LKD2); (4)
trong đó a là một siêu tham số kiểm soát sự đánh đổi giữa học từ nhãn thực tế
và mạng đồng nghiệp. Thuật toán MAT cho trường hợp hai bộ phân loại được tóm tắt
trong Thuật toán 1.
Việc mở rộng MAT cho các nhóm học sinh lớn hơn là đơn giản. Xem xét N(N2)
mạng hn(;qn)(n=1;;N), hàm mất mát của MAT trở thành:
LMAT = (1a)LAT+a
M1LKD; (5)
trong đó LAT=åN
n=1LC(pn(xqn
adv);y), và LKD=åN
n=1åN
m6=nDKL(pm(x)jjpn(xqn
adv)).
2.2 Phòng thủ chống lại Nhiều Nhiễu loạn
Trong phần này, chúng tôi chứng minh cách MAT có thể cải thiện độ bền vững đối với nhiều nhiễu loạn.
Các phương pháp trước [29, 40] cố gắng cải thiện độ bền vững mô hình chống lại nhiều nhiễu
loạn bằng cách tăng cường dữ liệu huấn luyện. Chúng tôi áp dụng một cách tiếp cận khác bằng cách chuyển giao
độ bền vững của các mô hình chuyên gia cho một mô hình duy nhất, điều này bổ sung cho các phương pháp trước
và đạt được hiệu suất tốt hơn.
Cho M(M2) loại nhiễu loạn khác nhau, vì khó khăn cho một mô hình duy nhất để
bền vững đối với tất cả các nhiễu loạn, chúng tôi huấn luyện một tập hợp M+1 mạng bao gồm một mạng
tổng quát h0(;q0) và M mạng chuyên gia h1(;q1);h2(;q2);;hM(;qM). Mỗi
mạng chuyên gia chịu trách nhiệm học phòng thủ chống lại một nhiễu loạn cụ thể và
học từ các mạng đồng nghiệp để tăng cường độ bền vững của nó. Mất mát để huấn luyện các mạng chuyên gia
hm(1mM) được định nghĩa là:
Lm= (1a)LC(pm(xqm
advm);y) +a
MM
å
n6=mDKL(pn(x)jjpm(xqm
advm)); (6)

--- TRANG 5 ---
JIANG LIU: HUẤN LUYỆN ĐỐI KHÁNG TƯƠNG HỖ 5
Thuật toán 1 Huấn Luyện Đối Kháng Tương Hỗ (MAT)
Đầu vào: Mẫu huấn luyện XY, bộ phân loại h1(;q1) và h2(;q2), mô hình tấn công attack,
tốc độ học t, trọng số a.
1:Khởi tạo ngẫu nhiên q1,q2
2:for epoch = 1, . . . , N do
3: for minibatch (x;y)XY do
4: xq1
adv=attack (x;y;h1(;q1))
5: .Tạo ra các ví dụ đối kháng của h1
6: xq2
adv=attack (x;y;h2(;q2))
7: .Tạo ra các ví dụ đối kháng của h2
8:LMAT = (1a)(LAT1+LAT2) +a(LKD1+LKD2) .Tính toán mất mát
9: q1 q1tÑq1LMAT
10: q2 q2tÑq2LMAT
11: .Cập nhật q1 và q2 với gradient descent
12: end for
13:end for
trong đó xqm
advm là một ví dụ đối kháng của hm được tạo ra bởi mô hình tấn công thứ m.
Mạng tổng quát h0 học phòng thủ chống lại tất cả các nhiễu loạn với sự trợ giúp của
các mạng chuyên gia. Cụ thể, khi phân loại các ví dụ đối kháng được tạo ra bởi
mô hình tấn công thứ m, mạng tổng quát so sánh dự đoán của nó với nhãn thực tế, cũng như
các dự đoán của mô hình chuyên gia thứ m hm chuyên về cuộc tấn công này. Theo cách này, mạng
tổng quát có thể xem xét các biên quyết định của các nhiễu loạn khác nhau và tìm ra một
biên tối ưu bền vững đối với hợp của nhiều nhiễu loạn.
Chúng tôi đề xuất ba chiến lược để huấn luyện mạng tổng quát h0:
1) MAT-AVG: chúng tôi huấn luyện h0 với mất mát trung bình trên tất cả các nhiễu loạn tại mỗi lần lặp.
Mất mát để huấn luyện mạng tổng quát h0 trong MAT-AVG được định nghĩa là:
L0=1
MM
å
m=1h
(1a)LC(p0(xq0
advm);y) +aDKL(pm(x)jjp0(xq0
advm))i
; (7)
trong đó xq0
advm là một ví dụ đối kháng của h0 được tạo ra bởi mô hình tấn công thứ m.
2) MAT-MAX: chúng tôi huấn luyện h0 chỉ với nhiễu loạn tệ hơn. Mất mát để huấn luyện
mạng tổng quát h0 trong MAT-MAX được định nghĩa là:
L0= (1a)LC(p0(xq0
advk);y) +aDKL(pk(x)jjp0(xq0
advk)); (8)
trong đó k =argmaxmLC(p(xq0
advm);y).
3) MAT-MSD: chúng tôi huấn luyện h0 sử dụng các ví dụ đối kháng MSD [29]. Vì MSD kết hợp
nhiều mô hình nhiễu loạn thành một cuộc tấn công duy nhất, h0 học từ tất cả các chuyên gia tại
mỗi lần lặp. Mất mát để huấn luyện mạng tổng quát h0 trong MAT-MSD được định nghĩa là:
L0=1
MM
å
m=1h
(1a)LC(p0(xq0
MSD);y) +aDKL(pm(x)jjp0(xq0
MSD))i
; (9)
trong đó xq0
MSD là ví dụ đối kháng MSD được tạo ra cho h0.

--- TRANG 6 ---
6 JIANG LIU: HUẤN LUYỆN ĐỐI KHÁNG TƯƠNG HỖ
Tổng mất mát của Huấn Luyện Đối Kháng Tương Hỗ cho Nhiều Nhiễu loạn (MAT-MP) là
tổng của tất cả các mạng:
LMAT-MP =M
å
m=0Lm: (10)
3 Thí nghiệm và Kết quả
3.1 Chi tiết Triển khai
Chúng tôi đánh giá độ bền vững của các phương pháp đề xuất trên CIFAR-10 và CIFAR-100 [19]. Tất cả
hình ảnh được chuẩn hóa về [0, 1], và các tăng cường dữ liệu được sử dụng trong quá trình huấn luyện bao gồm
lật ngang ngẫu nhiên và cắt ngẫu nhiên 32 32 với đệm 4-pixel. Chúng tôi sử dụng
mạng ResNet-18 [14] và WideResNet-34-10 (WRN-34-10) [45] và huấn luyện chúng với
bộ tối ưu SGD với kích thước batch 128 trong 120 epoch. Đối với ResNet-18, chúng tôi đặt tốc độ học
ban đầu là 0.01, động lượng là 0.9 và phân rã trọng số là 3,5×10^(-3). Đối với WRN-34-10,
chúng tôi đặt tốc độ học ban đầu là 0.1, động lượng là 0.9 và phân rã trọng số là 7×10^(-4). Tốc độ học
giảm đi 0.1 tại epoch thứ 75, 90 và 100.
3.2 Phòng thủ chống lại Nhiễu loạn Đơn
3.2.1 Cài đặt
Trong phần này, chúng tôi đánh giá hiệu quả của MAT chống lại một nhiễu loạn duy nhất. Chúng tôi xem xét
các cuộc tấn công l∞ phổ biến với ε=8/255. Trong quá trình huấn luyện, chúng tôi sử dụng PGD [28] để tạo ra
các ví dụ đối kháng với bước K=10 và kích thước bước η=0.007. Chúng tôi sử dụng một nhóm hai
mạng trong MAT. Chúng tôi đặt α=0.6 cho CIFAR-10 và α=0.45 cho CIFAR-100.
3.2.2 So sánh với hiện đại
Chúng tôi so sánh hiệu suất của các mô hình được huấn luyện MAT với các phòng thủ hiện đại bao gồm
MART [44] và TRADES [46], cũng như AT thông thường [28]. Chúng tôi đánh giá độ bền vững mô hình
chống lại FGSM [12], PGD [28], C&W [5] và các cuộc tấn công Fog, Elastic và Gabor [17]. Đối với PGD,
chúng tôi sử dụng bước K=100 và kích thước bước η=0.003. Đối với cuộc tấn công C&W [5], số lần lặp tối đa
được đặt là 1,000 với tốc độ học 0.01. Kết quả đánh giá được tóm tắt
trong Bảng 2. Hai mô hình được huấn luyện trong MAT vượt trội hơn các mô hình cơ sở dưới tất cả các cuộc tấn công
được xem xét, đặc biệt trên bộ dữ liệu CIFAR-10. MAT cải thiện độ bền vững mô hình mà không
giảm đáng kể độ chính xác sạch. Thực tế, các mô hình MAT có độ chính xác cao hơn trong cả dữ liệu sạch
và đối kháng trên bộ dữ liệu CIFAR-100 so với TRADES và MART.
Thú vị, hai mô hình được huấn luyện trong MAT thể hiện các đặc tính độ bền vững khác nhau:
một mô hình có độ chính xác bền vững cao hơn một chút nhưng độ chính xác sạch thấp hơn, và
mô hình khác có độ chính xác sạch cao hơn một chút và độ chính xác bền vững thấp hơn. Ngoài ra, các cuộc tấn công chuyển giao
từ một mô hình không hoạt động tốt trên mô hình khác (Bảng 4). Những kết quả này chứng minh
rằng mặc dù hai mô hình được huấn luyện hợp tác, chúng thực sự học các đặc trưng bền vững khác nhau
và không hội tụ thành một mô hình.

--- TRANG 7 ---
JIANG LIU: HUẤN LUYỆN ĐỐI KHÁNG TƯƠNG HỖ 7
Bảng 2: Độ chính xác phân loại (%) của các phương pháp phòng thủ khác nhau. MAT-h1 và MAT-h2
là hai mô hình được huấn luyện trong MAT. Hiệu suất tốt nhất của mỗi kiến trúc mạng và
bộ dữ liệu được in đậm và tốt thứ hai được gạch chân.
Bộ dữ liệu Phương pháp Sạch FGSM PGD C&W Fog Gabor ElasticResNet-18CIFAR-10AT [28] 84.21 63.95 49.52 49.47 40.59 69.48 51.30
TRADES [46] 81.48 62.60 52.26 49.92 38.48 68.08 51.61
MART [44] 83.07 65.81 53.47 50.03 41.80 70.01 51.74
MAT-h1 81.22 66.53 57.17 51.54 46.27 71.36 56.73
MAT-h2 81.91 66.45 56.30 51.12 46.01 71.19 57.11
CIFAR-100AT [28] 57.16 35.00 24.71 24.52 15.58 41.03 20.52
TRADES [46] 54.04 35.33 28.26 24.63 14.63 40.89 23.03
MART [44] 54.44 38.40 31.85 27.81 20.46 43.66 26.07
MAT-h1 56.06 39.25 31.99 28.32 22.15 44.90 28.37
MAT-h2 55.98 39.69 32.54 28.42 22.47 45.32 27.94WRN-34-10CIFAR-10AT [28] 86.50 59.06 50.72 51.88 42.88 71.21 49.94
TRADES [46] 84.92 60.87 55.58 54.36 45.73 72.39 52.52
MART [44] 83.62 61.61 56.49 53.28 43.34 72.06 53.03
MAT-h1 85.00 64.20 59.02 55.41 49.24 73.81 54.65
MAT-h2 84.96 64.23 58.86 55.65 49.56 74.12 55.17
CIFAR-100AT [28] 60.76 36.38 25.74 26.49 17.05 43.44 22.21
TRADES [46] 57.83 38.05 30.49 27.66 19.01 43.91 23.86
MART [44] 58.48 41.40 33.07 29.85 22.07 46.55 24.89
MAT-h1 62.28 42.57 33.63 31.35 24.97 48.71 27.19
MAT-h2 62.20 41.36 33.78 31.38 25.81 48.58 27.89
3.2.3 So sánh với các phòng thủ KD
Chúng tôi so sánh hiệu suất của các mô hình được huấn luyện MAT với các phòng thủ KD khác bao gồm
ARD [11] và ACT [1]. Chúng tôi đánh giá các mô hình sử dụng các cuộc tấn công PGD K-bước (PGD-K) với
kích thước bước η=0.003 và K=20, 100 và 1000 theo [1]. Đối với ARD, chúng tôi sử dụng cùng
kiến trúc mạng cho cả mô hình giáo viên và mô hình học sinh, và báo cáo hiệu suất
của các mô hình học sinh. Kết quả được tóm tắt trong Bảng 3. Các mô hình MAT đạt được
độ bền vững cao hơn đáng kể so với ARD và ACT. ARD không hoạt động tốt lắm
so với ACT và MAT, đặc biệt trên bộ dữ liệu CIFAR-100.
Bảng 3: Độ chính xác phân loại (%) của các phương pháp phòng thủ chưng cất kiến thức khác nhau.
MAT-h1 và MAT-h2 là hai mô hình được huấn luyện trong MAT. Hiệu suất tốt nhất của mỗi
kiến trúc mạng và bộ dữ liệu được in đậm và tốt thứ hai được gạch chân.
Bộ dữ liệu Phương phápResNet-18 WRN-34-10
Sạch PGD-20 PGD-100 PGD-1000 Sạch PGD-20 PGD-100 PGD-1000
CIFAR-10AT [28] 84.21 51.66 49.50 49.40 86.50 53.04 50.72 50.65
ARD [11] 82.84 51.41 49.57 49.51 85.18 53.79 51.71 51.61
ACT [1] 84.33 55.83 53.73 53.62 87.10 54.77 50.65 50.51
MAT-h1 81.22 58.67 57.17 57.13 85.00 60.52 59.02 58.93
MAT-h2 81.76 58.01 56.30 56.28 84.96 60.68 58.86 58.84
CIFAR-100AT [28] 57.16 26.13 24.71 24.66 60.76 27.09 25.74 25.72
ARD [11] 47.72 25.29 24.57 24.54 45.89 25.16 23.97 23.93
ACT [1] 60.72 28.74 27.32 27.26 61.84 28.78 26.66 26.56
MAT-h1 56.06 32.68 31.99 31.98 62.28 34.74 33.64 33.63
MAT-h2 55.98 33.29 32.54 32.52 62.20 34.67 33.78 33.73

--- TRANG 8 ---
8 JIANG LIU: HUẤN LUYỆN ĐỐI KHÁNG TƯƠNG HỖ
Bảng 4: Độ chính xác phân loại (%) của các mô hình MAT dưới các cuộc tấn công hộp đen PGD từ
các mô hình nguồn khác nhau. Chúng tôi sử dụng mạng ResNet-18 và các cuộc tấn công PGD với bước K=100
và kích thước bước η=0.003.
Bộ dữ liệu Mô hình AT TRADES MART MAT-h1MAT-h2
CIFAR-10MAT-h162.74 62.50 63.10 57.16 63.49
MAT-h262.56 62.11 63.03 63.92 56.35
CIFAR-100MAT-h139.49 40.62 38.11 31.99 37.61
MAT-h239.96 41.41 38.51 38.36 32.41
3.2.4 Làm mờ Gradient
Chúng tôi xác minh thêm rằng độ bền vững của MAT không đến từ việc làm mờ gradient [2].
Tuyên bố này được hỗ trợ bởi hai quan sát: (1) Các cuộc tấn công một bước, ví dụ, FGSM, hoạt động
tệ hơn các cuộc tấn công lặp, ví dụ, PGD (xem Bảng 2); (2) các cuộc tấn công hộp trắng có tỷ lệ thành công
cao hơn các cuộc tấn công hộp đen (xem Bảng 4).
3.2.5 Các Kịch bản Khác nhau của MAT
Trong phần này, chúng tôi nghiên cứu cách tương tác giữa các mô hình ảnh hưởng đến hành vi độ bền vững
trong thuật toán MAT, nơi các mô hình trao đổi kiến thức của chúng qua KD. Chúng tôi
xem xét bốn kịch bản KD khác nhau trong MAT: 1) MAT-rob-rob-online: h1 và h2 đều là các mô hình bền vững
và được huấn luyện đồng thời sử dụng Eq.(5), đây là kịch bản được xem xét trong
bài báo này; 2) MAT-rob-rob-offline: h1 và h2 đều là các mô hình bền vững, h1 là một mô hình giáo viên
được huấn luyện bởi Eq.(1) và h2 là một mô hình học sinh học từ h1 sử dụng Eq.(5) với h1 cố định; 3)
MAT-nat-rob-online: h1 là một mô hình tự nhiên và h2 là một mô hình bền vững, và chúng được huấn luyện
đồng thời sử dụng Eq.(5) với xq1
adv được thay thế bằng x; 4) MAT-nat-rob-offline: h1 là một mô hình tự nhiên
và h2 là một mô hình bền vững, h1 là một mô hình giáo viên được huấn luyện bởi LC, và h2 là một mô hình học sinh
học từ h1 sử dụng Eq.(5) với h1 cố định và xq1
adv được thay thế bằng x. Hình 2 hiển thị cả độ chính xác bền vững
và sạch tương ứng với bốn kịch bản. Chúng tôi quan sát rằng 1) các mô hình bền vững được huấn luyện với các mô hình tự nhiên
có độ chính xác sạch cao; 2) các mô hình bền vững được huấn luyện với các mô hình bền vững có độ chính xác bền vững cao; 3) MAT-rob-rob-online
đạt được độ chính xác bền vững cao hơn MAT-rob-rob-offline, điều này xác nhận trực giác của chúng tôi: bằng cách học từ đồng nghiệp, một
mạng trở nên bền vững hơn, điều này lần lượt cải thiện độ bền vững của các đồng nghiệp, trong khi trong
MAT-rob-rob-offline mô hình giáo viên được cố định làm hạn chế hiệu suất của học sinh.
Chúng tôi sử dụng MAT-rob-rob-online trong bài báo này vì nó đạt được độ chính xác bền vững cao nhất.
3.2.6 Ảnh hưởng của α
Siêu tham số α trong Eq. 5 kiểm soát sự đánh đổi giữa học từ nhãn thực tế
và mạng đồng nghiệp. Để tìm kiếm α tối ưu, chúng tôi chọn ngẫu nhiên 20% của
bộ huấn luyện CIFAR-10 và CIFAR-100 làm bộ xác thực, và huấn luyện các mô hình ResNet-18
sử dụng các giá trị α khác nhau trên 80% còn lại của dữ liệu huấn luyện. Hình 3 hiển thị ảnh hưởng của α
trên bộ dữ liệu CIFAR-10 và CIFAR-100. Nói chung, độ bền vững của các mô hình tăng
với α khi các mô hình bắt đầu học nhiều hơn từ nhau, và giảm nhanh chóng khi α trở nên
quá cao vì các mô hình học quá ít từ nhãn thực tế. Ngoài ra, MAT ít nhạy cảm
với giá trị α trên CIFAR-100 so với CIFAR-10. Chúng tôi chọn α=0.6 cho
CIFAR-10 và α=0.45 cho CIFAR-100 vì chúng đạt được độ chính xác bền vững cao nhất trên

--- TRANG 9 ---
JIANG LIU: HUẤN LUYỆN ĐỐI KHÁNG TƯƠNG HỖ 9
81.5 82.0 82.5 83.0 83.5 84.0 84.5
Độ chính xác Sạch (%)4446485052545658Độ chính xác Bền vững (%)MAT-nat-rob-online (h2)
MAT-nat-rob-offline (h2)
MAT-rob-rob-online (h1)
MAT-rob-rob-online (h2)
MAT-rob-rob-offline (h1)
MAT-rob-rob-offline (h2)
(a)
56 57 58 59 60 61 62 63
Độ chính xác Sạch (%)272829303132Độ chính xác Bền vững (%)MAT-nat-rob-online (h2)
MAT-nat-rob-offline (h2)
MAT-rob-rob-online (h1)
MAT-rob-rob-online (h2)
MAT-rob-rob-offline (h1)
MAT-rob-rob-offline (h2) (b)
Hình 2: Độ chính xác phân loại của các mô hình ResNet-18 được huấn luyện trong các kịch bản MAT khác nhau.
Độ chính xác bền vững là độ chính xác phân loại dưới cuộc tấn công PGD-100. (a) Kết quả CIFAR-10;
(b) Kết quả CIFAR-100.
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
α52.553.053.554.054.555.055.556.056.5Độ chính xác Bền vững(%)
MAT-h1
MAT-h2
(a)
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
α202224262830Độ chính xác Bền vững(%)
MAT-h1
MAT-h2 (b)
Hình 3: Hiệu suất của các mô hình ResNet-18 được huấn luyện với các giá trị α khác nhau. Độ chính xác
bền vững là độ chính xác phân loại dưới cuộc tấn công PGD-20 trên bộ xác thực. (a) Kết quả CIFAR-10;
(b) Kết quả CIFAR-100.
bộ xác thực. Sau khi xác định các giá trị α, chúng tôi sử dụng toàn bộ bộ huấn luyện để huấn luyện.
3.3 Phòng thủ chống lại Nhiều Nhiễu loạn
3.3.1 Cài đặt
Trong phần này, chúng tôi đánh giá hiệu quả của MAT-MP. Chúng tôi xem xét ba loại nhiễu loạn:
các cuộc tấn công l∞, l2 và l1 với ε= (0.03,0.5,12). Chúng tôi sử dụng mạng ResNet-18 [14].
Trong quá trình huấn luyện, chúng tôi huấn luyện ba chuyên gia sử dụng các cuộc tấn công PGD l∞, l2, và l1 với kích thước bước
η= (0.003,0.05,0.05), số lần lặp K= (40,50,50) tương ứng, và một mạng
tổng quát nhằm phòng thủ chống lại tất cả các loại nhiễu loạn bằng cách học từ các chuyên gia.
Trong quá trình đánh giá, một bộ rộng cả các cuộc tấn công dựa trên gradient và không dựa trên gradient được sử dụng
cho mỗi loại nhiễu loạn. Các cuộc tấn công l∞ bao gồm FGSM, PGD, MIM [9]; các cuộc tấn công l2 bao gồm
PGD, cuộc tấn công nhiễu Gaussian [34], cuộc tấn công biên [3], DeepFool [30], cuộc tấn công
pointwise [36], cuộc tấn công DDN [35], và cuộc tấn công C&W [5]; các cuộc tấn công l1 bao gồm PGD, cuộc tấn công
salt & pepper [34], và cuộc tấn công pointwise [36]. Mỗi cuộc tấn công được chạy với 10 lần bắt đầu ngẫu nhiên. Chi tiết
đánh giá có thể được tìm thấy trong [29].

--- TRANG 10 ---
10 JIANG LIU: HUẤN LUYỆN ĐỐI KHÁNG TƯƠNG HỖ
3.3.2 Kết quả
Chúng tôi so sánh độ bền vững của các mô hình tổng quát với các mô hình được huấn luyện chỉ với các cuộc tấn công PGD lp
(AT-lp), mô hình được huấn luyện với cuộc tấn công PGD tệ nhất (AT-MAX) [29, 40], mô hình
được huấn luyện với tất cả các cuộc tấn công PGD (AT-AVG) [29, 40], và mô hình được huấn luyện với các cuộc tấn công MSD (AT-
MSD) [29]. Các mô hình cơ sở được cung cấp bởi các tác giả của [29]. Kết quả được tóm tắt
trong Bảng 5. Chúng tôi báo cáo độ chính xác phân loại trung bình dưới ba loại nhiễu loạn Ravg,
cũng như độ chính xác trường hợp tệ nhất Rworst nơi chúng tôi chọn cuộc tấn công mạnh nhất từ tất cả các cuộc tấn công
được xem xét cho mỗi ví dụ. Chúng ta có thể đưa ra một số quan sát từ Bảng 5:
1)MAT tạo ra mô hình mạnh nhất chống lại nhiều nhiễu loạn. Mô hình MAT-AVG
đạt được độ chính xác trung bình tốt nhất chống lại nhiều nhiễu loạn, đạt 58.7% độ chính xác
trung bình chống lại các cuộc tấn công l∞, l2, và l1 (riêng lẻ 47.3%, 68.9%, 60.0%); mô hình MAT-MAX
đạt được hiệu suất tốt nhất chống lại hợp của các cuộc tấn công, đạt 48.0% độ chính xác
chống lại hợp của các cuộc tấn công l∞, l2, và l1 (riêng lẻ 51.1%, 67.0%, 54.0%).
2)MAT cải thiện độ bền vững mô hình cũng như độ chính xác sạch. So với các đối tác AT
của chúng, các mô hình được huấn luyện MAT có độ chính xác sạch và độ chính xác đối kháng cao hơn dưới
tất cả các loại nhiễu loạn. Điều này chứng minh hiệu quả của việc học từ các mô hình
chuyên gia. Cải thiện đáng kể nhất khi sử dụng chiến lược huấn luyện "MAX": MAT-MAX
đạt được 3.5% độ chính xác sạch cao hơn, 8.7% Ravg cao hơn và 13.1% Rworst cao hơn so với AT-
MAX. Điều này có thể là do việc tổng quát hóa đơn giản của huấn luyện đối kháng như "MAX"
hội tụ đến các giải pháp không tối ưu không thể cân bằng sự đánh đổi đúng giữa
nhiều cuộc tấn công [29, 40]. Bằng cách học từ các nhãn mềm được cung cấp bởi các mô hình chuyên gia,
mạng tổng quát nhận thức được biên quyết định tối ưu của mỗi loại nhiễu loạn và tìm ra một
sự đánh đổi tốt hơn giữa nhiều nhiễu loạn.
3) Trong số các mô hình MAT, MAT-MAX có Rworst cao nhất và MAT-AVG có Ravg cao nhất,
điều này không đáng ngạc nhiên vì mô hình MAT-MAX được huấn luyện trên cuộc tấn công PGD lp tệ nhất
và mô hình MAT-AVG được huấn luyện trên tất cả các cuộc tấn công PGD lp. MAT-MSD đạt được Rworst cao hơn
MAT-AVG, điều này chỉ ra rằng nó có độ bền vững tốt hơn chống lại hợp của nhiều
nhiễu loạn, nhưng nó có Ravg và Rworst hơi tệ hơn MAT-MAX.
Tóm lại, kết quả của chúng tôi gợi ý rằng bằng cách học từ các mô hình chuyên gia, mạng tổng quát
có thể kế thừa độ bền vững của chúng chống lại các nhiễu loạn khác nhau và tìm ra một biên quyết định
bền vững hơn và có thể tổng quát hóa hơn chống lại nhiều nhiễu loạn.
4 Kết luận
Trong bài báo này, chúng tôi đã đề xuất một thuật toán AT dựa trên chưng cất kiến thức mới có tên MAT
cho phép các mô hình học từ nhau trong quá trình huấn luyện đối kháng. MAT là một khung tổng quát
và có thể được sử dụng để phòng thủ chống lại nhiều nhiễu loạn. Chúng tôi đã chứng minh
rằng phương pháp đề xuất có thể cải thiện hiệu quả độ bền vững mô hình và vượt trội hơn các phương pháp
hiện đại trong các bộ dữ liệu CIFAR-10 và CIFAR-100. Kết quả của chúng tôi chứng minh rằng học
hợp tác là một chiến lược hiệu quả để huấn luyện các mô hình bền vững.
Lời cảm ơn
Công trình này được hỗ trợ bởi Chương trình DARPA GARD HR001119S0026-GARD-FP-052.

--- TRANG 11 ---
JIANG LIU: HUẤN LUYỆN ĐỐI KHÁNG TƯƠNG HỖ 11
Bảng 5: Tóm tắt kết quả độ chính xác phân loại trên CIFAR-10. Ravg là độ chính xác trung bình
của các loại nhiễu loạn khác nhau. Rworst là độ chính xác trường hợp tệ nhất. Chúng tôi hiển thị tăng độ chính xác
của các mô hình MAT so với các đối tác AT của chúng trong ngoặc. Hiệu suất tốt nhất trong mỗi
cột được in đậm và tốt thứ hai được gạch chân.
Mô hình Sạch Cuộc tấn công l∞ Cuộc tấn công l2 Cuộc tấn công l1 Ravg Rworst
AT-l∞[29] 83.3% 50.7% 57.3% 16.0% 41.3% 15.6%
AT-l2[29] 90.2% 28.3% 61.6% 46.6% 45.5% 27.5%
AT-l1[29] 73.3% 0.2% 0.0% 7.9% 2.7% 0.0%
AT-MAX [29] 81.0% 44.9% 61.7% 39.4% 48.7% 34.9%
MAT-MAX (Của chúng tôi) 84.5% 51.1% 67.0% 54.0% 57.4% 48.0%
(+3.5%) (+6.2%) (+5.3%) (+14.6%) (+8.7%) (+13.1%)
AT-AVG [29] 84.6% 42.5% 65.0% 54.0% 53.8% 40.6%
MAT-AVG (Của chúng tôi) 86.0% 47.3% 68.9% 60.0% 58.7% 45.9%
(+1.4%) (+4.8%) (+3.9%) (+6.0%) (+4.9%) (+5.3%)
AT-MSD [29] 81.1% 48.0% 64.3% 53.0% 55.1% 47.0%
MAT-MSD (Của chúng tôi) 84.2% 48.8% 67.6% 55.1% 57.2% 47.7%
(+3.1%) (+0.8%) (+3.3%) (+2.1%) (+2.1%) (+0.7%)
Tài liệu tham khảo
[1] Elahe Arani, Fahad Sarfraz, và Bahram Zonooz. Adversarial concurrent training:
Optimizing robustness and accuracy trade-off of deep neural networks. arXiv preprint
arXiv:2008.07015 , 2020.
[2] Anish Athalye, Nicholas Carlini, và David Wagner. Obfuscated gradients give a false
sense of security: Circumventing defenses to adversarial examples. In International
Conference on Machine Learning , trang 274–283. PMLR, 2018.
[3] Wieland Brendel, Jonas Rauber, và Matthias Bethge. Decision-based adversarial at-
tacks: Reliable attacks against black-box machine learning models. arXiv preprint
arXiv:1712.04248 , 2017.
[4] Nicholas Carlini và David Wagner. Defensive distillation is not robust to adversarial
examples. arXiv preprint arXiv:1607.04311 , 2016.
[5] Nicholas Carlini và David Wagner. Towards evaluating the robustness of neural net-
works. In 2017 IEEE Symposium on Security and Privacy (SP) , trang 39–57. IEEE,
2017.
[6] Pin-Yu Chen, Yash Sharma, Huan Zhang, Jinfeng Yi, và Cho-Jui Hsieh. EAD:
Elastic-net attacks to deep neural networks via adversarial examples. arXiv preprint
arXiv:1709.04114 , 2017.
[7] Tianlong Chen, Zhenyu Zhang, Sijia Liu, Shiyu Chang, và Zhangyang Wang. Robust
overfitting may be mitigated by properly learned smoothening. In International Con-
ference on Learning Representations , 2021. URL https://openreview.net/
forum?id=qZzy5urZw9 .
[8] Jeremy Cohen, Elan Rosenfeld, và Zico Kolter. Certified adversarial robustness via
randomized smoothing. In International Conference on Machine Learning , trang
1310–1320. PMLR, 2019.

--- TRANG 12 ---
12 JIANG LIU: HUẤN LUYỆN ĐỐI KHÁNG TƯƠNG HỖ
[9] Yinpeng Dong, Fangzhou Liao, Tianyu Pang, Hang Su, Jun Zhu, Xiaolin Hu, và Jian-
guo Li. Boosting adversarial attacks with momentum. In Proceedings of the IEEE
Conference on Computer Vision and Pattern Recognition , trang 9185–9193, 2018.
[10] Tommaso Furlanello, Zachary Lipton, Michael Tschannen, Laurent Itti, và Anima
Anandkumar. Born again neural networks. In International Conference on Machine
Learning , trang 1607–1616. PMLR, 2018.
[11] Micah Goldblum, Liam Fowl, Soheil Feizi, và Tom Goldstein. Adversarially robust
distillation. arXiv preprint arXiv:1905.09747 , 2019.
[12] Ian J Goodfellow, Jonathon Shlens, và Christian Szegedy. Explaining and harnessing
adversarial examples. arXiv preprint arXiv:1412.6572 , 2014.
[13] Qiushan Guo, Xinjiang Wang, Yichao Wu, Zhipeng Yu, Ding Liang, Xiaolin Hu, và
Ping Luo. Online knowledge distillation via collaborative learning. In Proceedings
of the IEEE Conference on Computer Vision and Pattern Recognition , trang 11020–
11029, 2020.
[14] Kaiming He, Xiangyu Zhang, Shaoqing Ren, và Jian Sun. Deep residual learning for
image recognition. In Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition , trang 770–778, 2016.
[15] G. Hinton, L. Deng, D. Yu, G. E. Dahl, A. Mohamed, N. Jaitly, A. Senior, V. Van-
houcke, P. Nguyen, T. N. Sainath, và B. Kingsbury. Deep neural networks for acous-
tic modeling in speech recognition: The shared views of four research groups. IEEE
Signal Processing Magazine , 29(6):82–97, 2012. doi: 10.1109/MSP.2012.2205597.
[16] Geoffrey Hinton, Oriol Vinyals, và Jeff Dean. Distilling the knowledge in a neural
network. arXiv preprint arXiv:1503.02531 , 2015.
[17] Daniel Kang, Yi Sun, Dan Hendrycks, Tom Brown, và Jacob Steinhardt. Testing
robustness against unforeseen adversaries. arXiv preprint arXiv:1908.08016 , 2019.
[18] Harini Kannan, A. Kurakin, và Ian J. Goodfellow. Adversarial logit pairing. ArXiv ,
abs/1803.06373, 2018.
[19] Alex Krizhevsky. Learning multiple layers of features from tiny images. University of
Toronto , 05 2012.
[20] Alex Krizhevsky, Ilya Sutskever, và Geoffrey E Hinton. Imagenet classification with
deep convolutional neural networks. In Advances in Neural Information Processing
Systems , trang 1097–1105, 2012.
[21] Cassidy Laidlaw và Soheil Feizi. Functional adversarial attacks. arXiv preprint
arXiv:1906.00001 , 2019.
[22] Cassidy Laidlaw, Sahil Singla, và Soheil Feizi. Perceptual adversarial robustness:
Defense against unseen threat models. arXiv preprint arXiv:2006.12655 , 2020.
[23] Alexander Levine và Soheil Feizi. (de) randomized smoothing for certifiable defense
against patch attacks. arXiv preprint arXiv:2002.10733 , 2020.

--- TRANG 13 ---
JIANG LIU: HUẤN LUYỆN ĐỐI KHÁNG TƯƠNG HỖ 13
[24] Alexander Levine và Soheil Feizi. Improved, deterministic smoothing for l1 certified
robustness. arXiv preprint arXiv:2103.10834 , 2021.
[25] Alexander Levine, Sahil Singla, và Soheil Feizi. Certifiably robust interpretation in
deep learning. arXiv preprint arXiv:1905.12105 , 2019.
[26] Sergey Levine, Peter Pastor, Alex Krizhevsky, Julian Ibarz, và Deirdre Quillen. Learn-
ing hand-eye coordination for robotic grasping with deep learning and large-scale data
collection. The International Journal of Robotics Research , 37(4-5):421–436, 2018.
[27] Wei-An Lin, Chun Pong Lau, Alexander Levine, Rama Chellappa, và Soheil Feizi.
Dual Manifold Adversarial Robustness: Defense against Lp and non-Lp Adversarial
Attacks. In Advances in Neural Information Processing Systems , 2020.
[28] Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, và
Adrian Vladu. Towards deep learning models resistant to adversarial attacks. arXiv
preprint arXiv:1706.06083 , 2017.
[29] Pratyush Maini, Eric Wong, và Zico Kolter. Adversarial robustness against the union
of multiple perturbation models. In International Conference on Machine Learning ,
trang 6640–6650. PMLR, 2020.
[30] Seyed-Mohsen Moosavi-Dezfooli, Alhussein Fawzi, và Pascal Frossard. Deepfool: a
simple and accurate method to fool deep neural networks. In Proceedings of the IEEE
Conference on Computer Vision and Pattern Recognition , trang 2574–2582, 2016.
[31] N. Papernot, P. McDaniel, S. Jha, M. Fredrikson, Z. B. Celik, và A. Swami. The
limitations of deep learning in adversarial settings. In 2016 IEEE European Symposium
on Security and Privacy (EuroS P) , trang 372–387, 2016. doi: 10.1109/EuroSP.2016.
36.
[32] Nicolas Papernot, Patrick McDaniel, Xi Wu, Somesh Jha, và Ananthram Swami. Dis-
tillation as a defense to adversarial perturbations against deep neural networks. In 2016
IEEE Symposium on Security and Privacy (SP) , trang 582–597. IEEE, 2016.
[33] Aditi Raghunathan, Jacob Steinhardt, và Percy Liang. Certified defenses against ad-
versarial examples. In International Conference on Learning Representations , 2018.
URL https://openreview.net/forum?id=Bys4ob-Rb .
[34] Jonas Rauber, Wieland Brendel, và Matthias Bethge. Foolbox: A python tool-
box to benchmark the robustness of machine learning models. arXiv preprint
arXiv:1707.04131 , 2017.
[35] Jérôme Rony, Luiz G Hafemann, Luiz S Oliveira, Ismail Ben Ayed, Robert Sabourin,
và Eric Granger. Decoupling direction and norm for efficient gradient-based l2 adver-
sarial attacks and defenses. In Proceedings of IEEE Conference on Computer Vision
and Pattern Recognition , trang 4322–4330, 2019.
[36] Lukas Schott, Jonas Rauber, Matthias Bethge, và Wieland Brendel. Towards the first
adversarially robust neural network model on MNIST. In International Conference
on Learning Representations , 2019. URL https://openreview.net/forum?
id=S1EHOsC9tX .

--- TRANG 14 ---
14 JIANG LIU: HUẤN LUYỆN ĐỐI KHÁNG TƯƠNG HỖ
[37] Sahil Singla và Soheil Feizi. Skew orthogonal convolutions. arXiv preprint
arXiv:2105.11417 , 2021.
[38] Aman Sinha, Hongseok Namkoong, Riccardo Volpi, và John Duchi. Certifying
some distributional robustness with principled adversarial training. arXiv preprint
arXiv:1710.10571 , 2017.
[39] Guocong Song và Wei Chai. Collaborative learning for deep neural networks. In
Advances in Neural Information Processing Systems , trang 1832–1841, 2018.
[40] Florian Tramèr và Dan Boneh. Adversarial training and robustness for multiple per-
turbations. In Advances in Neural Information Processing Systems , trang 5866–5876,
2019.
[41] Florian Tramèr, Nicolas Papernot, Ian Goodfellow, Dan Boneh, và Patrick McDaniel.
The space of transferable adversarial examples. arXiv preprint arXiv:1704.03453 ,
2017.
[42] Dimitris Tsipras, Shibani Santurkar, Logan Engstrom, Alexander Turner, và Alek-
sander Madry. Robustness may be at odds with accuracy. In International Conference
on Learning Representations , 2019. URL https://openreview.net/forum?
id=SyxAb30cY7 .
[43] Lin Wang và Kuk-Jin Yoon. Knowledge distillation and student-teacher learning for
visual intelligence: A review and new outlooks. arXiv preprint arXiv:2004.05937 ,
2020.
[44] Yisen Wang, Difan Zou, Jinfeng Yi, James Bailey, Xingjun Ma, và Quanquan
Gu. Improving adversarial robustness requires revisiting misclassified examples.
InInternational Conference on Learning Representations , 2019. URL https:
//openreview.net/forum?id=rklOg6EFwS .
[45] Sergey Zagoruyko và Nikos Komodakis. Wide residual networks. In Edwin R. Han-
cock Richard C. Wilson và William A. P. Smith, editors, Proceedings of the British
Machine Vision Conference (BMVC) , trang 87.1–87.12. BMVA Press, September
2016. ISBN 1-901725-59-6. doi: 10.5244/C.30.87. URL https://dx.doi.org/
10.5244/C.30.87 .
[46] Hongyang Zhang, Yaodong Yu, Jiantao Jiao, Eric Xing, Laurent El Ghaoui, và
Michael Jordan. Theoretically principled trade-off between robustness and accuracy.
InInternational Conference on Machine Learning , trang 7472–7482, 2019.
[47] Ying Zhang, Tao Xiang, Timothy M Hospedales, và Huchuan Lu. Deep mutual learn-
ing. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recogni-
tion, trang 4320–4328, 2018.

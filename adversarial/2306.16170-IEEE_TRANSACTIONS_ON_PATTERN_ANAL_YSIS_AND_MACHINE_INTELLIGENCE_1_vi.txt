# 2306.16170.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/adversarial/2306.16170.pdf
# Kích thước tệp: 1365940 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE 1
Giảm thiểu Trade-off Độ chính xác-Độ bền vững thông qua
Chưng cất Đối kháng Đa giáo viên Cân bằng
Shiji Zhao, Xizhe Wang, và Xingxing Wei∗Member, IEEE

Tóm tắt —Huấn luyện Đối kháng là một phương pháp thực tế để cải thiện độ bền vững của mạng nơ-ron sâu chống lại các cuộc tấn công đối kháng. Mặc dù mang lại độ bền vững đáng tin cậy, hiệu suất đối với các ví dụ sạch bị ảnh hưởng tiêu cực sau Huấn luyện Đối kháng, có nghĩa là tồn tại sự đánh đổi giữa độ chính xác và độ bền vững. Gần đây, một số nghiên cứu đã cố gắng sử dụng các phương pháp chưng cất kiến thức trong Huấn luyện Đối kháng, đạt được hiệu suất cạnh tranh trong việc cải thiện độ bền vững nhưng độ chính xác cho các mẫu sạch vẫn còn hạn chế. Trong bài báo này, để giảm thiểu trade-off độ chính xác-độ bền vững, chúng tôi giới thiệu Chưng cất Độ bền vững Đối kháng Đa giáo viên Cân bằng (B-MTARD) để hướng dẫn quá trình Huấn luyện Đối kháng của mô hình bằng cách áp dụng một giáo viên sạch mạnh và một giáo viên bền vững mạnh để xử lý các ví dụ sạch và ví dụ đối kháng, tương ứng. Trong quá trình tối ưu hóa, để đảm bảo rằng các giáo viên khác nhau thể hiện quy mô kiến thức tương tự, chúng tôi thiết kế thuật toán Cân bằng Dựa trên Entropy để điều chỉnh nhiệt độ của giáo viên và giữ cho entropy thông tin của các giáo viên nhất quán. Bên cạnh đó, để đảm bảo rằng học sinh có tốc độ học tương đối nhất quán từ nhiều giáo viên, chúng tôi đề xuất thuật toán Cân bằng Mất mát Chuẩn hóa để điều chỉnh trọng số học tập của các loại kiến thức khác nhau. Một loạt thí nghiệm được thực hiện trên ba bộ dữ liệu công khai chứng minh rằng B-MTARD vượt trội hơn các phương pháp tiên tiến nhất chống lại các cuộc tấn công đối kháng khác nhau.

Từ khóa chỉ mục —DNNs, Huấn luyện Đối kháng, Chưng cất Kiến thức, Độ bền vững Đối kháng, Trade-off Độ chính xác-Độ bền vững.

✦

1 GIỚI THIỆU

Mạng Nơ-ron Sâu (DNNs) đã trở thành những công cụ mạnh mẽ để giải quyết các bài toán học tập phức tạp trong thế giới thực, chẳng hạn như phân loại hình ảnh [17], nhận dạng khuôn mặt [41], và xử lý ngôn ngữ tự nhiên [35]. Tuy nhiên, Szegedy et al. [39] chứng minh rằng DNNs dễ bị tổn thương bởi các cuộc tấn công đối kháng với những nhiễu loạn đối kháng không thể nhận biết được trên đầu vào, gây ra dự đoán sai của DNNs. Để bảo vệ chống lại các cuộc tấn công đối kháng, Huấn luyện Đối kháng được đề xuất và đã cho thấy hiệu quả trong việc tạo ra DNNs bền vững đối kháng [10], [31], [42]. Trong khi cải thiện độ bền vững của DNNs, một tác động tiêu cực tồn tại đối với độ chính xác của mô hình trên các mẫu sạch. Một số phương pháp được đề xuất để giảm bớt sự đánh đổi giữa độ chính xác và độ bền vững từ các góc độ khác nhau, ví dụ, tối ưu hóa [32], [42], [50], [55], [56] và dữ liệu bổ sung [1], [5], [19]. Tuy nhiên, hiện tượng này vẫn tồn tại và cần được khám phá thêm.

Gần đây, để tiếp tục tăng cường độ bền vững của các DNNs nhỏ, Chưng cất Kiến thức [20] được áp dụng như một công cụ mạnh mẽ trong Huấn luyện Đối kháng, có thể chuyển giao kiến thức từ các mô hình bền vững mạnh đến mô hình học sinh. Nó sử dụng dự đoán của giáo viên như thông tin nhãn để hướng dẫn mô hình học sinh trong khuôn khổ của Huấn luyện Đối kháng, bao gồm tối ưu hóa để tạo ra các ví dụ đối kháng (quá trình Tối đa hóa) và áp dụng các ví dụ đối kháng để huấn luyện học sinh với sự hỗ trợ của giáo viên (quá trình Tối thiểu hóa). Những phương pháp này được gọi là chưng cất độ bền vững đối kháng (ARD) [13], [60], [61].

•Shiji Zhao, Xizhe Wang, Xingxing Wei đều thuộc Viện Trí tuệ Nhân tạo, Đại học Beihang, Số 37, Đường Xueyuan, Quận Haidian, Bắc Kinh, 100191, Trung Quốc. (E-mail: {zhaoshiji123, xizhewang, xxwei}@buaa.edu.cn)
•Xingxing Wei là tác giả liên hệ.

So với các nhãn sự thật one-hot, các nhãn dự đoán của giáo viên không chỉ có thể giữ lại tính đúng đắn của nhãn mục tiêu mà còn phản ánh thông tin kiến thức phong phú hơn của nhãn không phải mục tiêu. Một số nghiên cứu cố gắng giải thích tại sao chưng cất kiến thức hiệu quả thông qua các quan điểm khác nhau, ví dụ, Tái trọng số [12], Thông tin Đặc quyền [30], và Làm mượt nhãn [53]. Gần đây, Li et al. [25] lập luận rằng tính đúng đắn, điều hòa mượt mà, và khả năng phân biệt lớp trong các nhãn dự đoán của giáo viên có thể tạo nên kiến thức của phân phối dự đoán của giáo viên, và khả năng phân biệt danh mục phù hợp có thể cải thiện hiệu quả của chưng cất kiến thức. Trong khi đạt được hiệu suất bền vững ấn tượng, chúng tôi tò mò liệu chưng cất độ bền vững đối kháng [13], [60], [61] có thể giải quyết sự đánh đổi giữa độ chính xác và độ bền vững hay không.

Nói chung, nếu chúng ta muốn cải thiện cả độ chính xác và độ bền vững thông qua chưng cất kiến thức, mô hình giáo viên được cung cấp phải hoạt động tốt ở cả hai khía cạnh. Điều đó có nghĩa là mô hình giáo viên nên cung cấp hướng dẫn đúng đắn và thông tin kiến thức phong phú một cách công bằng cho các ví dụ sạch và đối kháng. Tuy nhiên, do sự đánh đổi hiện có, bản thân mô hình giáo viên khó có thể đạt được những mục tiêu trên. Do đó, một cách tiếp cận hợp lý là tách biệt chưng cất kiến thức đối kháng, tức là sử dụng hai giáo viên giỏi về độ chính xác và độ bền vững tương ứng (họ có thể được gọi là giáo viên sạch và giáo viên bền vững) để hướng dẫn học sinh trong các loại kiến thức khác nhau. Dưới chiến lược chia để trị này, mô hình học sinh được hướng dẫn bởi nhiều mô hình giáo viên có thể tăng cường hiệu suất của mình ở cả hai khía cạnh về mặt lý thuyết.

Tuy nhiên, việc triển khai thực tế ý tưởng này là thách thức. Do sự đánh đổi nội tại giữa độ chính xác và độ bền vững, giáo viên sạch và giáo viên bền vững đẩy mô hình học sinh theo những hướng ngược nhau. Điều này rõ ràng khác biệt so với các phương pháp chưng cất kiến thức đa giáo viên hiện tại [29], [37], [52], nơi mục tiêu tối ưu hóa của các giáo viên khác nhau là nhất quán, tức là tất cả giáo viên đều đẩy học sinh hướng tới độ chính xác sạch tốt. Sự đánh đổi trong nhiệm vụ của chúng ta dẫn đến một tối ưu hóa khó khăn chủ yếu ở hai khía cạnh: (1) Làm thế nào để làm cho hai mô hình giáo viên có quy mô kiến thức tương tự. Khi một giáo viên có quá nhiều quy mô kiến thức, học sinh sẽ bị buộc phải có được nhiều kiến thức hơn từ giáo viên này và tương đối ít kiến thức hơn từ giáo viên khác, điều này trực tiếp dẫn đến sự mất cân bằng giữa độ chính xác và độ bền vững. Tuy nhiên, việc tìm một giáo viên sạch và một giáo viên bền vững với quy mô kiến thức tương tự không dễ dàng vì các kiến trúc mạng khác nhau và phương pháp huấn luyện sẽ dẫn đến khoảng cách tự nhiên trong quy mô kiến thức giữa các giáo viên khác nhau. Do đó, chúng ta cần một thước đo để đo lường chính xác và cân bằng quy mô kiến thức của giáo viên. (2) Làm thế nào để cân bằng khả năng học tập của học sinh từ các loại kiến thức của giáo viên khác nhau. Trong cài đặt đa giáo viên của chúng ta, vì tồn tại hai hướng tối ưu hóa ngược nhau trong chưng cất độ bền vững đối kháng, học sinh có thể quá khớp với một khả năng dễ học hơn nhưng bỏ qua khả năng khác do khó khăn học tập khác nhau. Chỉ có sự hợp tác của học sinh và giáo viên mới có thể giúp học sinh có được cả độ chính xác và độ bền vững mạnh. Do đó, chúng ta cần một cơ chế cân bằng thích ứng để điều chỉnh quá trình học tập.

Dựa trên các thảo luận trên, trong bài báo này, chúng tôi đề xuất Chưng cất Độ bền vững Đối kháng Đa giáo viên Cân bằng (B-MTARD) để tăng cường cả độ chính xác và độ bền vững cùng lúc. Trong Huấn luyện Đối kháng, một giáo viên sạch hướng dẫn học sinh xử lý các ví dụ sạch và một giáo viên bền vững mạnh hướng dẫn học sinh xử lý các ví dụ đối kháng. Để đáp ứng hai thách thức trên, các chiến lược Cân bằng Dựa trên Entropy và Cân bằng Mất mát Chuẩn hóa mới được trình bày để đạt được trạng thái cân bằng giữa độ chính xác và độ bền vững.

Đối với thách thức đầu tiên, để đảm bảo rằng hai mô hình giáo viên thể hiện quy mô kiến thức tương tự trong quá trình tối ưu hóa, chúng tôi đề xuất thuật toán Cân bằng Dựa trên Entropy để cân bằng entropy thông tin giữa các phân phối dự đoán của giáo viên khác nhau. Cụ thể, dựa trên lý thuyết thông tin [36], entropy tương đối có thể đo lường thông tin gia tăng từ phân phối dự đoán của mạng được khởi tạo đến phân phối dự đoán của giáo viên được huấn luyện tốt, vì vậy chúng tôi sử dụng entropy tương đối để đo lường quy mô kiến thức của giáo viên. Hơn nữa, chúng tôi chứng minh lý thuyết rằng sự khác biệt trong quy mô kiến thức có thể được chuyển đổi thành sự khác biệt trong entropy thông tin của giáo viên. Do đó thuật toán Cân bằng Dựa trên Entropy có thể cân bằng quy mô kiến thức bằng cách điều chỉnh nhiệt độ của mỗi giáo viên cho đến khi entropy thông tin phù hợp và nhất quán.

Đối với thách thức thứ hai, để duy trì sự bình đẳng tương đối của tốc độ học tập của học sinh từ nhiều giáo viên, chúng tôi đề xuất thuật toán Cân bằng Mất mát Chuẩn hóa để kiểm soát trọng số mất mát và cân bằng ảnh hưởng giữa giáo viên sạch và giáo viên bền vững. Cụ thể, được truyền cảm hứng từ [7], chúng tôi thiết kế một mất mát tương đối để đo lường tỷ lệ kiến thức mà học sinh học được từ các giáo viên khác nhau. Các trọng số mất mát khác nhau cho việc cập nhật tham số học sinh được điều chỉnh động để giữ cho mất mát tương đối nhất quán trong suốt quá trình huấn luyện. So với trạng thái ban đầu, mô hình học sinh sẽ bị buộc phải học quy mô kiến thức tương đối bằng nhau từ tất cả các mô hình giáo viên.

Mã nguồn của chúng tôi có sẵn tại https://github.com/zhaoshiji123/MTARD-extension.

Những đóng góp chính của công trình này là ba phần:
•Chúng tôi đề xuất một khuôn khổ mới: Chưng cất Độ bền vững Đối kháng Đa giáo viên Cân bằng (B-MTARD). B-MTARD tách biệt chưng cất kiến thức đối kháng để đạt được sự cân bằng giữa độ chính xác và độ bền vững. Chúng tôi áp dụng một giáo viên sạch và một giáo viên bền vững để thích ứng mang cả kiến thức sạch và bền vững cho học sinh.

•Chúng tôi đề xuất thuật toán Cân bằng Dựa trên Entropy và thuật toán Cân bằng Mất mát Chuẩn hóa để cân bằng nhiều giáo viên. Thuật toán Cân bằng Dựa trên Entropy được áp dụng để kiểm soát quy mô kiến thức của giáo viên bằng cách điều chỉnh nhiệt độ động. Thuật toán Cân bằng Mất mát Chuẩn hóa được sử dụng để đảm bảo rằng học sinh có tốc độ học tương đối bằng nhau cho kiến thức của các giáo viên khác nhau.

•Chúng tôi xác minh thực nghiệm hiệu quả của B-MTARD trong việc cải thiện hiệu suất. Độ Chính xác Bền vững Có trọng số (một thước đo để đánh giá cả độ chính xác sạch và bền vững) của các mô hình được huấn luyện B-MTARD cải thiện đáng kể chống lại nhiều cuộc tấn công so với các phương pháp Huấn luyện Đối kháng và chưng cất kiến thức tiên tiến. Bên cạnh đó, chúng tôi cho thấy B-MTARD có thể đạt được cải thiện rõ rệt so với MTARD được đề xuất trong phiên bản hội nghị của chúng tôi.

Bài báo tạp chí này là phiên bản mở rộng của bài báo ECCV (MTARD) của chúng tôi [59]. So với phiên bản hội nghị, chúng tôi đã thực hiện những cải tiến và mở rộng đáng kể trong phiên bản này ở các khía cạnh sau: (1) Ở cấp độ ý tưởng, chúng tôi thảo luận về vấn đề trade-off trong một góc nhìn toàn diện hơn từ cả giáo viên và học sinh, trong khi phiên bản hội nghị chỉ xem xét góc nhìn của học sinh. Chúng tôi chỉ ra rằng sự khác biệt trong quy mô kiến thức của hai giáo viên sẽ ảnh hưởng đến sự đánh đổi giữa độ chính xác và độ bền vững, và nên đưa yếu tố này vào phương pháp của chúng tôi (thách thức đầu tiên trong Phần 1). (2) Ở cấp độ phương pháp, một cơ chế điều chỉnh kiến thức của nhiều giáo viên có tên là thuật toán Cân bằng Dựa trên Entropy được thiết kế, nơi chúng tôi đầu tiên đưa ra định nghĩa và thước đo cho quy mô kiến thức và sau đó trình bày phương pháp cân bằng (Phần 3.2). (3) Ở cấp độ thực nghiệm, chúng tôi đưa ra so sánh toàn diện giữa B-MTARD với phiên bản hội nghị MTARD của chúng tôi để cho thấy lợi thế, và cũng bổ sung thực hiện thí nghiệm trên bộ dữ liệu Tiny-ImageNet và so sánh B-MTARD của chúng tôi với nhiều phương pháp SOTA hơn chống lại các cuộc tấn công tiên tiến hơn. Ngoài ra, chúng tôi đưa ra nhiều nghiên cứu ablation hơn để kiểm tra toàn diện phương pháp của chúng tôi (Phần 4).

Phần còn lại của bài báo được tổ chức như sau: Công trình liên quan được đưa ra trong Phần 2. Phần 3 giới thiệu chi tiết về B-MTARD của chúng tôi. Các thí nghiệm được thực hiện trong Phần 4, và kết luận được đưa ra trong Phần 5.

2 CÔNG TRÌNH LIÊN QUAN

2.1 Tấn công Đối kháng

Kể từ khi Szegedy et al. [39] đề xuất rằng các ví dụ đối kháng có thể đánh lạc hướng mạng nơ-ron sâu, rất nhiều phương pháp tấn công đối kháng hiệu quả, chẳng hạn như Phương pháp Dấu hiệu Gradient Nhanh (FGSM) [14], Tấn công Gradient Descent Có chiếu (PGD) [31], và Tấn công Carlini và Wagner (CW) [4] được đề xuất. Các phương pháp tấn công có thể được chia thành tấn công white-box và tấn công black-box. Tấn công white-box biết tất cả thông tin tham số của mô hình mục tiêu khi tạo ra các ví dụ đối kháng, và tấn công black-box biết ít hoặc không biết thông tin gì. Nói chung, tấn công black-box mô phỏng gradient của mô hình bằng cách truy vấn lặp đi lặp lại mô hình mục tiêu (tấn công dựa trên truy vấn) [2], [27], [43], [44], [45], [46], [47] hoặc tìm kiếm một mô hình thay thế tương tự với mô hình mục tiêu (tấn công dựa trên chuyển giao) [11], [21]. Gần đây, một phương pháp tấn công đối kháng mạnh có tên AutoAttack (AA) [10] được đề xuất, bao gồm bốn phương pháp tấn công, gồm Auto-PGD (APGD), tấn công Difference of Logits Ratio (DLR), FAB-Attack [9], và tấn công black-box Square Attack [2].

2.2 Huấn luyện Đối kháng

Huấn luyện Đối kháng [31], [55] được xem là một cách hiệu quả để bảo vệ chống lại các cuộc tấn công đối kháng. Madry et al. [31] xây dựng Huấn luyện Đối kháng như một bài toán tối ưu hóa min-max như sau:

min θ E(x,y)∼D[max δ∈Ω L(f(x+δ;θ), y)], (1)

trong đó f đại diện cho một mạng nơ-ron sâu với trọng số θ, D đại diện cho một phân phối của ví dụ sạch x và nhãn sự thật y. L đại diện cho hàm mất mát. δ đại diện cho nhiễu loạn đối kháng, và Ω đại diện cho một giới hạn, có thể được định nghĩa là Ω = {δ:||δ|| ≤ ε} với quy mô nhiễu loạn tối đa ε.

Để giảm bớt sự đánh đổi giữa độ chính xác và độ bền vững, một số phương pháp được đề xuất từ các góc độ khác nhau, ví dụ, tối ưu hóa [32], [42], [50], [55] và dữ liệu bổ sung [1], [5], [19]. Từ góc độ tối ưu hóa, Zhang et al. [55] cố gắng giảm khoảng cách giữa độ chính xác và độ bền vững bằng cách tối thiểu hóa mất mát phân kỳ Kullback–Leibler (KL) (TRADES). Wang et al. [42] tiếp tục cải thiện hiệu suất thông qua Huấn luyện Đối kháng Nhận biết Phân loại sai. Stutz et al. [38] tuyên bố rằng phân tích đa tạp có thể hữu ích trong việc đạt được độ chính xác và độ bền vững. Yang et al. [50] lập luận rằng sự đánh đổi có thể được giảm thiểu bằng cách tối ưu hóa các hàm Lipschitz cục bộ. Pang et al. [32] đề xuất sử dụng tính bất biến cục bộ để mô tả hành vi lý tưởng của một mô hình bền vững, điều này tạo điều kiện cho sự hòa giải giữa độ chính xác và độ bền vững (SCORE). Từ góc độ dữ liệu, [1] và [5] phát hiện rằng dữ liệu không nhãn bổ sung có thể hữu ích để cải thiện cả độ chính xác và độ bền vững. [19] cho thấy rằng huấn luyện trước đối kháng với dữ liệu bổ sung có thể cải thiện đáng kể độ chính xác và độ bền vững đối kháng.

Khác với các phương pháp trước đó, chúng tôi cố gắng giảm bớt sự đánh đổi bằng cách sử dụng chưng cất đối kháng đa giáo viên, áp dụng một giáo viên sạch và một giáo viên bền vững để mang cả kiến thức sạch và bền vững cho học sinh.

2.3 Chưng cất Kiến thức

Chưng cất kiến thức có thể chuyển giao hiệu suất của các mô hình khác cho mô hình mục tiêu [20]. Nghiên cứu rộng rãi đã được nghiên cứu nhiều trong những năm gần đây [23], [25], [52]. Chưng cất kiến thức có thể được xây dựng ngắn gọn như tối ưu hóa sau:

arg min θS(1−α)CE(S(x), y) + ατ²KL(S(x;τ), T(x;τ)), (2)

trong đó S đại diện cho mô hình học sinh với trọng số θS, T đại diện cho mô hình giáo viên. KL là mất mát phân kỳ Kullback–Leibler, CE đại diện cho mất mát cross-entropy. τ là một hằng số nhiệt độ kết hợp với phép toán softmax, α là một siêu tham số trọng số.

Chưng cất kiến thức gốc [20] cố gắng cải thiện hiệu suất của học sinh trên các ví dụ sạch, và định nghĩa trước một nhiệt độ cao cho đến khi giáo viên tạo ra các nhãn mềm phù hợp, trong khi cùng một nhiệt độ cao được áp dụng để huấn luyện học sinh để khớp với các nhãn mềm này, điều này cho phép học sinh có được kiến thức tốt hơn từ một loại giáo viên duy nhất. Phương pháp của chúng tôi (với Thuật toán Cân bằng Dựa trên Entropy của chúng tôi) là để cân bằng hiệu suất của học sinh giữa độ chính xác và độ bền vững, và chúng tôi điều chỉnh thích ứng nhiệt độ cho các loại giáo viên khác nhau để cân bằng quy mô kiến thức của họ, điều này cho phép học sinh có được kiến thức một cách bình đẳng từ các loại giáo viên khác nhau.

Nhiệt độ τ được điều chỉnh thủ công như một siêu tham số trong công trình trước đó. Gần đây, [26], [28] đề xuất điều chỉnh τ tự động dựa trên mạng con học được được thiết kế. Những phương pháp này cần huấn luyện mạng con theo phản hồi của mô hình học sinh, điều này thêm chi phí huấn luyện bổ sung. Phương pháp của chúng tôi tự động điều chỉnh nhiệt độ chỉ dựa trên quy mô kiến thức của nhiều giáo viên và hầu như không có chi phí tính toán.

Một số nghiên cứu cũng tồn tại về chưng cất kiến thức đa giáo viên, và được thiết kế từ các góc nhìn khác nhau: bao gồm kiến thức dựa trên phản hồi [23], [52], kiến thức dựa trên đặc trưng [29], [57], và kiến thức dựa trên quan hệ [48], [51]. Các phương pháp trước đó thường sử dụng nhiều giáo viên cho chưng cất kiến thức cho cùng các ví dụ, và những giáo viên đó có xu hướng tối ưu hóa học sinh theo các hướng tương tự. Khác với các phương pháp trước đó, chưng cất độ bền vững đối kháng đa giáo viên của chúng tôi nhắm đến hai loại ví dụ khác nhau. Vì các ví dụ đối kháng được tạo ra để đánh lạc hướng mô hình, có một khoảng cách lớn giữa hướng tối ưu hóa của các ví dụ sạch và các ví dụ đối kháng, điều này tồn tại những khó khăn lớn so với nghiên cứu trước đó.

2.4 Chưng cất Độ bền vững Đối kháng

Để bảo vệ chống lại cuộc tấn công đối kháng, chưng cất bảo vệ [33] được đề xuất để áp dụng chưng cất kiến thức truyền thống. Tuy nhiên, phương pháp này được coi là "Gradient Bị che khuất" [3] và có thể bị phá vỡ bởi tấn công CW [4]. Sau đó một loạt phương pháp [13], [60], [61] áp dụng chưng cất kiến thức để tiếp tục tăng cường độ bền vững dựa trên Huấn luyện Đối kháng [31]. ARD [13] đầu tiên đề xuất rằng sử dụng một mô hình bền vững mạnh làm mô hình giáo viên trong khuôn khổ của Huấn luyện Đối kháng có thể đạt được độ bền vững khá tốt. IAD [60] thực hiện chưng cất kiến thức đối kháng bằng cách kết hợp với hướng dẫn giáo viên không đáng tin cậy và nội quan học sinh. RSLAD [61] sử dụng các nhãn mềm được tạo ra bởi mô hình giáo viên bền vững để tạo ra các ví dụ đối kháng, và tiếp tục sử dụng các nhãn bền vững để hướng dẫn quá trình huấn luyện của cả ví dụ sạch và đối kháng, điều này có thể cải thiện hiệu quả độ bền vững của học sinh. Fair-ARD [49] được đề xuất để khám phá các vấn đề công bằng trong ARD và tăng cường công bằng bền vững bằng cách tái trọng số các lớp khác nhau. Được truyền cảm hứng từ bài báo này, ABSLD [58] cố gắng có được một mô hình với công bằng bền vững bằng cách giảm khoảng cách rủi ro lỗi theo lớp của học sinh và điều chỉnh mức độ mượt mà theo lớp của nhãn giáo viên thông qua tái nhiệt độ các lớp khác nhau.

Các phương pháp trên tập trung vào việc cải thiện độ bền vững hoặc công bằng của ARD. Trong phương pháp của chúng tôi, chúng tôi xem xét cả độ chính xác và độ bền vững thông qua giáo viên sạch và bền vững để tiếp tục giảm thiểu sự đánh đổi, điều này tồn tại sự khác biệt rõ ràng so với các phương pháp khác.

3 PHƯƠNG PHÁP LUẬN

Trong phần này, chúng tôi đề xuất B-MTARD để tăng cường cả độ chính xác và độ bền vững bằng cách áp dụng giáo viên sạch và giáo viên bền vững để hướng dẫn học sinh. Từ góc nhìn giảng dạy của giáo viên, thuật toán Cân bằng Dựa trên Entropy được đề xuất để cân bằng quy mô kiến thức của giáo viên. Từ góc nhìn học tập của học sinh, thuật toán Cân bằng Mất mát Chuẩn hóa được thiết kế để cân bằng tốc độ học tập của học sinh từ các giáo viên khác nhau.

3.1 Chưng cất Đối kháng Đa giáo viên Cân bằng

Quá trình huấn luyện trong B-MTARD có thể được coi là một tối ưu hóa min-max dựa trên Huấn luyện Đối kháng. Toàn bộ khuôn khổ có thể được xem trong Hình 1. Trong tối đa hóa bên trong, các ví dụ đối kháng được tạo ra bởi học sinh dựa trên các ví dụ sạch. Trong tối thiểu hóa bên ngoài, giáo viên sạch và giáo viên bền vững tạo ra các nhãn dự đoán để hướng dẫn quá trình huấn luyện học sinh đối với các ví dụ sạch và các ví dụ đối kháng, tương ứng. Tối ưu hóa của B-MTARD cơ bản được định nghĩa như sau:

arg min θS(1−α)KL(S(xnat;τs), Tnat(xnat;τnat)) +αKL(S(xadv;τs), Tadv(xadv;τadv)), (3)

xadv = arg max δ∈Ω CE(S(xnat+δ), y), (4)

trong đó xnat và xadv là các ví dụ sạch và các ví dụ đối kháng, S(x;τs) đại diện cho mạng học sinh S với nhiệt độ τs. Tnat(x;τnat) và Tadv(x;τadv) đại diện cho giáo viên sạch và bền vững với nhiệt độ τnat và τadv, tương ứng. α là một hằng số trong đề xuất cơ bản. CE biểu thị mất mát Cross-Entropy trong tối đa hóa. Ở đây, τs, τnat, và τadv thường được định nghĩa trước trong các công trình trước đó.

Mục tiêu của B-MTARD là có được một học sinh với độ chính xác mạnh như giáo viên sạch và độ bền vững mạnh như giáo viên bền vững. Tuy nhiên, trong quá trình hoạt động thực tế, hai giáo viên có thể thể hiện quy mô kiến thức khác nhau; Đồng thời, học sinh có thể có tốc độ học tập khác nhau đối với các loại kiến thức của giáo viên khác nhau. Hai điểm trên có thể dẫn đến hiệu suất mất cân bằng về độ chính xác và độ bền vững. Vậy làm thế nào để xử lý chưng cất độ bền vững đối kháng đa giáo viên trở thành một vấn đề cần giải quyết trong hai phần con sau.

3.2 Cân bằng Dựa trên Entropy trong B-MTARD

3.2.1 Đo lường Quy mô Kiến thức

Do các kiến trúc mô hình và phương pháp huấn luyện khác nhau, các giáo viên có thể có quy mô kiến thức khác nhau. Việc loại bỏ sự đánh đổi độ chính xác-độ bền vững sẽ trở nên không thực tế nếu học sinh học từ hai giáo viên với quy mô kiến thức không bằng nhau. Sau đó chúng ta muốn biết làm thế nào để đo lường quy mô kiến thức và tiếp tục cân bằng nó.

Trong quá trình chưng cất kiến thức, phần mà giáo viên áp dụng để hướng dẫn học sinh là phân phối dự đoán cho các mẫu. Vì vậy chúng ta có thể tin tưởng một cách hợp lý rằng kiến thức của giáo viên tồn tại trong phân phối dự đoán cho các mẫu, điều này thực sự đại diện cho thông tin được hiểu bởi giáo viên, ví dụ, các lớp của mẫu, độ khó của mẫu, hoặc mối quan hệ giữa các lớp. Trong khuôn khổ chưng cất kiến thức [20], phân phối dự đoán của giáo viên có thể được định nghĩa là P={p1(x), ..., pC(x)}, trong đó khả năng dự đoán pk(x) của lớp thứ k có thể được xây dựng như sau:

pk(x) = exp(zk(x)/τ) / ∑(j=1 to C) exp(zj(x)/τ), (5)

trong đó zk(x) biểu thị đầu ra logits thứ k của mô hình trước lớp softmax, τ biểu thị nhiệt độ được áp dụng trong quá trình huấn luyện chưng cất kiến thức.

Mặc dù kiến thức được mô tả ở trên tồn tại trong phân phối dự đoán của giáo viên, việc định lượng chúng không dễ dàng. Ở đây chúng ta cố gắng xem xét nó từ góc độ tối ưu hóa. Nói một cách trực quan, một mô hình mạng được huấn luyện tốt được huấn luyện từ một mô hình mạng với trọng số được khởi tạo ngẫu nhiên. Mô hình với trọng số được khởi tạo ngẫu nhiên có thể được coi là một mô hình tổng quát I không có kiến thức gì; Sau khi huấn luyện, mô hình có thể được coi là sở hữu kiến thức được mang lại bởi các quá trình tối ưu hóa. Dựa trên lý thuyết thông tin, entropy tương đối (còn được gọi là phân kỳ Kullback–Leibler [36]) đại diện cho chi phí thông tin cần thiết từ một phân phối này đến một phân phối khác. Vì vậy quy mô kiến thức thu được có thể được biểu thị như entropy tương đối từ phân phối dự đoán của một mô hình được khởi tạo I đến một mô hình được huấn luyện tốt. Ở đây chúng tôi tiếp tục định nghĩa quy mô kiến thức KT của giáo viên dưới dạng toán học như sau:

KT = KL(I(x), T(x)), (6)

sau đó chúng tôi cố gắng đơn giản hóa thêm quy mô kiến thức KT và cung cấp Định lý 1. Và chứng minh tương ứng có thể được tìm thấy trong Phụ lục A (Chứng minh A.1.).

Định lý 1. Quy mô kiến thức KT của giáo viên có liên quan nghịch với entropy thông tin H(PT) của phân phối dự đoán của giáo viên và có mối quan hệ như sau:

KT = logC − H(PT), (7)

trong đó PT={pT1(x), ..., pTC(x)} biểu thị phân phối dự đoán của mô hình giáo viên T, và logC là một hằng số.

Định lý 1 ngụ ý rằng chúng ta có thể trực tiếp sử dụng entropy thông tin để đo lường quy mô kiến thức của giáo viên. Từ góc độ lý thuyết thông tin, entropy thông tin được sử dụng để mô tả mức độ ngẫu nhiên và không chắc chắn của thông tin, vì vậy việc áp dụng entropy thông tin để định lượng quy mô kiến thức là hợp lý.

Sau đó chúng tôi tiếp tục phân tích các yếu tố ảnh hưởng đến entropy thông tin. Dựa trên Phương trình (5), entropy thông tin của phân phối dự đoán bị ảnh hưởng bởi hai phần, một là logits đầu ra z(x), và phần khác là nhiệt độ τ, cả hai đều có thể thay đổi entropy thông tin để ảnh hưởng đến quy mô kiến thức. Logits đầu ra z(x) được xác định bởi chính mô hình, khi giáo viên được chọn, z(x) không thể thay đổi. Trong khi nhiệt độ có thể được sử dụng như một siêu tham số để trực tiếp thay đổi entropy thông tin.

Để tiếp tục khám phá mối quan hệ giữa entropy thông tin và nhiệt độ, chúng tôi tính toán đạo hàm riêng của entropy thông tin H(P) đối với nhiệt độ τ và có thể có được kết quả như sau:

∇τH(P) = [(∑(j=1 to C) qj)(∑(j=1 to C) qj log²qj) − (∑(j=1 to C) qj logqj)²] / [τ(∑(j=1 to C) qj)²], (8)

trong đó q đại diện cho exp(z(x)/τ) trong Phương trình (5), và việc dẫn xuất chi tiết hơn có thể được tìm thấy trong Phụ lục A (Chứng minh A.2.). Đồng thời, chúng tôi chứng minh rằng đạo hàm riêng ∇τH(P) ≥ 0, và kết luận này được chứng minh trong Phụ lục A (Chứng minh A.3.), do đó entropy thông tin H(P) cho thấy mối quan hệ tăng đơn điệu với nhiệt độ τ. Hiệu ứng được thể hiện như trong Hình 2: khi nhiệt độ tăng, entropy thông tin của dự đoán cũng tăng rõ rệt. Sau đó kết hợp với Định lý 1, một nhiệt độ lớn hơn sẽ dẫn đến quy mô kiến thức nhỏ hơn.

3.2.2 Cân bằng Quy mô Kiến thức

Sau khi đo lường quy mô kiến thức, chúng ta muốn biết quy mô kiến thức của các loại giáo viên khác nhau, chúng tôi thực hiện thống kê định lượng, và kết quả được thể hiện trong Bảng 1. Kết quả biểu thị rằng một sự khác biệt rõ ràng tồn tại trong quy mô kiến thức giữa giáo viên sạch và giáo viên bền vững nếu không có điều chỉnh bổ sung. Vì vậy rất cần thiết để cân bằng quy mô kiến thức giữa các giáo viên khác nhau. Chỉ khi hai giáo viên dường như có kiến thức ngang nhau, học sinh mới học được khả năng bình đẳng từ cả giáo viên sạch và giáo viên bền vững, và cuối cùng giảm thiểu sự đánh đổi giữa độ chính xác và độ bền vững.

Dựa trên phân tích trên, chúng ta có thể cân bằng quy mô kiến thức của giáo viên sạch và quy mô kiến thức của giáo viên bền vững bằng cách tối thiểu hóa khoảng cách của entropy thông tin của giáo viên. Ở đây chúng tôi định nghĩa việc tối thiểu hóa khoảng cách quy mô kiến thức ΔK như mục tiêu tối ưu hóa dưới dạng toán học:

min ΔK = ||H(PTadvadv) − H(PTnatnat)||, (9)

trong đó PTnatnat và PTadvadv biểu thị phân phối dự đoán của giáo viên sạch đối với xnat và phân phối dự đoán của giáo viên đối kháng đối với xadv, tương ứng.

Dựa trên phân tích trên trong Phần 3.2.1, việc điều chỉnh nhiệt độ có thể trực tiếp biến đổi entropy thông tin của dự đoán mô hình với chi phí tính toán không đáng kể, trong khi việc điều chỉnh logits z(x) cần tiêu thụ tính toán bổ sung để huấn luyện lại mô hình. Vì vậy chúng tôi chọn giải quyết mục tiêu tối ưu hóa trên Phương trình (9) bằng cách cập nhật nhiệt độ của nhiều giáo viên.

Sau đó chúng ta cần áp dụng gradient của đối tượng mong đợi ΔK liên quan đến nhiệt độ τnat của giáo viên sạch và nhiệt độ τadv của giáo viên bền vững và cập nhật chúng theo nguyên lý gradient descent trong quá trình huấn luyện. Ở đây chúng tôi áp dụng quá trình tối ưu hóa của nhiệt độ τnat để mở rộng phương pháp của chúng tôi (quá trình tối ưu hóa của nhiệt độ τadv tương tự, và chúng tôi không lặp lại mô tả), được xây dựng như sau:

τnat = τnat − rτ∇τnatΔK, (10)

chúng tôi sử dụng tốc độ học rτ để kiểm soát độ lớn của thay đổi gradient, và sau đó chúng tôi tiếp tục mở rộng việc dẫn xuất sơ bộ:

∇τnatΔK = {
  ∇τnatH(PTnatnat),     H(PTnatnat) ≥ H(PTadvadv),
  −∇τnatH(PTnatnat),    H(PTnatnat) < H(PTadvadv).
} (11)

Như đã mô tả trước đó (Phương trình (8)), entropy thông tin H(P) cho thấy mối quan hệ tăng đơn điệu với nhiệt độ τ. Vì vậy dựa trên sự xem xét của việc cập nhật ổn định, chúng ta có thể sử dụng hằng số 1 một cách hợp lý để ước tính cả ∇τnatH(PTnatnat) và ∇τadvH(PTadvadv) trong quá trình huấn luyện cập nhật nhiệt độ của giáo viên, và chúng tôi sử dụng rτ để kiểm soát phạm vi cập nhật.

Sau đó kết hợp chứng minh trên với Phương trình (10) và Phương trình (11), công thức để cập nhật τnat như sau:

τnat = τnat − rτsign(H(PTnatnat) − H(PTadvadv)), (12)

trong đó sign(.) biểu thị hàm dấu. Theo cùng một quá trình dẫn xuất, chúng ta cũng có thể có được công thức để cập nhật nhiệt độ τadv cho giáo viên Tadv có thể được xây dựng như sau:

τadv = τadv − rτsign(H(PTadvadv) − H(PTnatnat)). (13)

Ở mức thực tế, thuật toán Cân bằng Dựa trên Entropy của chúng tôi có thể cân bằng quy mô kiến thức của giáo viên bằng cách kiểm soát entropy thông tin. Khi entropy thông tin của giáo viên không bằng nhau, nhiệt độ của cả hai giáo viên sẽ được cập nhật cho đến khi sự khác biệt được loại bỏ: nếu một giáo viên có entropy thông tin cao, thì nhiệt độ của giáo viên sẽ giảm để tiếp tục giảm entropy thông tin, dẫn đến quy mô kiến thức cao hơn dựa trên Phương trình (27); ngược lại, nếu một giáo viên có entropy thông tin thấp, thì nhiệt độ của giáo viên sẽ tăng để tiếp tục tăng entropy thông tin, dẫn đến quy mô kiến thức thấp hơn. Với Cân bằng Dựa trên Entropy, giáo viên sạch và giáo viên bền vững có thể xuất hiện có kiến thức ngang nhau khi truyền đạt kiến thức cho học sinh, điều này hữu ích để giảm thiểu sự đánh đổi độ chính xác-độ bền vững.

Cần đề cập rằng chúng tôi chỉ cập nhật nhiệt độ của giáo viên (τnat và τadv) và giữ nhiệt độ của học sinh (τs) không thay đổi trong Cân bằng Dựa trên Entropy. Ngoài ra, để ngăn chặn thông tin bị điều chỉnh quá mức, chúng tôi đặt giới hạn trên và dưới cho nhiệt độ để ngăn chặn các tình huống sau: Nếu nhiệt độ quá nhỏ, phân phối dự đoán của giáo viên sẽ gần vô hạn với phân phối nhãn one-hot; Khi nhiệt độ quá lớn, phân phối dự đoán của giáo viên sẽ gần với phân phối đồng nhất.

3.3 Cân bằng Mất mát Chuẩn hóa trong B-MTARD

Mặc dù hai giáo viên có kiến thức ngang nhau sau khi điều chỉnh của thuật toán Cân bằng Dựa trên Entropy, học sinh có thể không học được kiến thức bằng nhau từ hai giáo viên trong quá trình huấn luyện, vì khó khăn của việc nhận ra các ví dụ sạch và các ví dụ đối kháng đối với học sinh là khác nhau: Các ví dụ đối kháng được tạo ra để đánh lạc hướng học sinh dựa trên các ví dụ sạch. Để cho học sinh có được kiến thức bằng nhau từ giáo viên sạch và giáo viên bền vững, cần có một chiến lược để kiểm soát tốc độ học tập tương đối của học sinh đối với các loại kiến thức khác nhau. Được truyền cảm hứng từ các phương pháp điều hòa gradient trong học tập đa nhiệm [7], chúng tôi đề xuất một thuật toán để kiểm soát tốc độ tương đối bằng cách điều chỉnh động trọng số mất mát trong toàn bộ quá trình huấn luyện, được gọi là thuật toán Cân bằng Mất mát Chuẩn hóa.

Ở cấp độ toán học, tổng mất mát trong B-MTARD cuối cùng được sử dụng để cập nhật học sinh tại thời điểm t có thể được biểu diễn như Ltotal(t), có thể được xây dựng như sau:

Ltotal(t) = wnat(t)Lnat(t) + wadv(t)Ladv(t), (14)

trong đó Lnat(t) và Ladv(t) biểu thị mất mát KL được đề cập trong Phương trình (3), và wnat(t) và wadv(t) biểu thị các siêu tham số hằng số 1−α và α được đề cập trong Phương trình (3) trong nhiệm vụ của chúng tôi không có Cân bằng Mất mát Chuẩn hóa. Tương tự như phân tích trong phần 3.2, khoảng cách quy mô kiến thức giữa học sinh và giáo viên có thể được phản ánh trực tiếp bởi giá trị của mất mát sạch Lnat(t) và mất mát đối kháng Ladv(t), và điều quan trọng để kiểm soát kiến thức của học sinh từ nhiều giáo viên nhất quán là kiểm soát trọng số mất mát của wnat(t) và wadv(t), điều này trực tiếp ảnh hưởng đến việc học Lnat(t) và Ladv(t) của học sinh.

Sau đó mục tiêu của chúng tôi là đặt Lnat(t) và Ladv(t) trên một thước đo chung thông qua độ lớn tương đối của chúng. Sau đó dựa trên thước đo chung, chúng ta có thể xác định các hướng tối ưu hóa cụ thể để đảm bảo rằng Lnat(t) và Ladv(t) có sự giảm tương đối công bằng sau toàn bộ quá trình cập nhật, và mô hình được huấn luyện cuối cùng có thể bị ảnh hưởng bằng nhau bởi các phần khác nhau của tổng mất mát.

Để chọn thước đo tiêu chí để đo lường sự suy giảm của nhiều mất mát, chúng tôi chọn một mất mát tương đối L̃(t) theo Chen et al. [7], được định nghĩa như sau:

L̃nat(t) = Lnat(t)/Lnat(0), L̃adv(t) = Ladv(t)/Ladv(0), (15)

đặc biệt trong nhiệm vụ của chúng tôi, Lnat(t) và Ladv(t) đại diện cho khoảng cách quy mô kiến thức cho học sinh từ giáo viên sạch Tnat và giáo viên bền vững Tadv tại thời điểm t. Vì vậy L̃nat(t) và L̃adv(t) có thể phản ánh tỷ lệ kiến thức mà học sinh chưa học được từ kiến thức của giáo viên khác nhau tại thời điểm t so với thời điểm 0. Khi L̃nat(t) và L̃adv(t) bằng nhau, học sinh có được quy mô kiến thức tương đối bằng nhau từ các giáo viên khác nhau, đó chính xác là điều chúng ta tìm kiếm. Vì vậy mục tiêu tối ưu hóa của chúng tôi như sau:

min||L̃nat(t) − L̃adv(t)||. (16)

Trong quá trình huấn luyện của học sinh, tác động trực tiếp nhất đến L̃nat(t) và L̃adv(t) là trọng số mất mát wnat và wadv. Nói một cách trực quan, khi L̃nat(t) nhỏ hơn L̃adv(t), học sinh đã học được nhiều quy mô kiến thức hơn từ giáo viên sạch so với giáo viên bền vững trong thời gian từ 0 đến t, và học sinh được cho là có trọng số mất mát wnat nhỏ hơn trong quá trình học tập để hạn chế tốc độ học tập từ loại kiến thức này.

Dựa trên tiêu chí và phân tích trên, chúng ta có thể cân bằng động L̃nat(t) và L̃adv(t) bằng cách áp dụng trọng số tương đối rnat(t) và radv(t) mà chúng ta mong đợi cho mất mát tại thời điểm t, có thể được xây dựng như sau:

rnat(t) = [L̃nat(t)]^β / ([L̃nat(t)]^β + [L̃adv(t)]^β), (17)
radv(t) = [L̃adv(t)]^β / ([L̃nat(t)]^β + [L̃adv(t)]^β), (18)

trong đó [L̃(t)]^β biểu thị L̃(t) lũy thừa β, và β được đặt để kiểm soát sức mạnh của việc sửa chữa sự mất cân bằng. rnat(t) và radv(t) tăng cường các mất mát bị thiệt thòi và làm suy yếu các mất mát có lợi thế để loại bỏ sự mất cân bằng giữa tốc độ học tập của học sinh trong các loại kiến thức khác nhau. β lớn phù hợp khi dao động của giá trị mất mát tương đối rõ ràng, trong khi β nhỏ phù hợp cho L̃nat(t) và L̃adv(t) với khả năng ảnh hưởng ổn định.

Từ sự xem xét của tính ổn định huấn luyện, chúng tôi không trực tiếp sử dụng rnat(t) và radv(t) làm trọng số của mất mát, mà cập nhật trọng số ban đầu wnat(t) và wadv(t), có thể được xây dựng như sau:

wnat(t) = rwrnat(t) + (1 − rw)wnat(t−1), (19)
wadv(t) = rwradv(t) + (1 − rw)wadv(t−1). (20)

Ở mức thực tế, với sự hỗ trợ của thuật toán Cân bằng Mất mát Chuẩn hóa, học sinh có thể điều chỉnh động các trọng số mất mát khác nhau trong toàn bộ quá trình huấn luyện theo mức độ chấp nhận kiến thức. Tốc độ học tập của học sinh sẽ bị ức chế và trọng số mất mát tương ứng sẽ giảm nếu quá nhiều loại kiến thức này được chấp nhận; Ngược lại, tốc độ học tập của học sinh sẽ được đẩy nhanh và trọng số mất mát tương ứng sẽ tăng nếu loại kiến thức này không đủ. Cuối cùng, học sinh có xu hướng học tốt từ cả hai giáo viên, có được kiến thức sạch và bền vững tương đối bằng nhau, thay vì xuất hiện có khả năng thiên vị.

3.4 Tổng quan về B-MTARD

Tóm lại, để chuyển giao cả kiến thức sạch và bền vững cho học sinh, chúng tôi đề xuất B-MTARD để áp dụng hai giáo viên và đề xuất thuật toán Cân bằng Dựa trên Entropy cho giáo viên và thuật toán Cân bằng Mất mát Chuẩn hóa cho học sinh để tối ưu hóa quá trình Huấn luyện Đối kháng. Tối thiểu hóa cuối cùng của B-MTARD được định nghĩa như sau:

arg min θS wnatKL(S(xnat;τs), Tnat(xnat;τnat)) + wadvKL(S(xadv;τs), Tadv(xadv;τadv)), (21)

và quá trình hoàn chỉnh của B-MTARD trong Thuật toán 1.

So với các phương pháp hiện có khác, phương pháp của chúng tôi có một số lợi thế. Thứ nhất, phương pháp của chúng tôi có thể phù hợp với các kết hợp giáo viên-học sinh khác nhau, có thể được điều chỉnh tự động bởi thuật toán Cân bằng Dựa trên Entropy và thuật toán Cân bằng Mất mát Chuẩn hóa. Thứ hai, phương pháp của chúng tôi chú ý nhiều hơn đến hiệu suất tổng thể dựa trên Độ Chính xác Bền vững Có trọng số, đo lường sự đánh đổi giữa độ chính xác và độ bền vững. Thứ ba, các siêu tham số huấn luyện có thể được cập nhật động bởi thuật toán điều chỉnh của chúng tôi và có thể phù hợp với những thay đổi khi số epoch huấn luyện tăng, điều này quan trọng để phù hợp với các tình huống khác nhau.

4 THÍ NGHIỆM

Trong phần này, chúng tôi ban đầu mô tả cài đặt thí nghiệm và sau đó đánh giá Độ Chính xác Bền vững Có trọng số của B-MTARD và một số phương pháp cơ sở dưới các cuộc tấn công white-box và black-box phổ biến bao gồm các cuộc tấn công dựa trên chuyển giao và dựa trên truy vấn. Chúng tôi cũng thực hiện một loạt nghiên cứu ablation để chứng minh hiệu quả.

4.1 Cài đặt Thí nghiệm

Chúng tôi thực hiện thí nghiệm trên ba bộ dữ liệu bao gồm CIFAR-10 [22], CIFAR-100, và Tiny-ImageNet [24]. Chúng tôi áp dụng phương pháp huấn luyện tiêu chuẩn và một số phương pháp tiên tiến để so sánh: Phương pháp Huấn luyện Đối kháng: SAT [31], Phương pháp Chưng cất Độ bền vững Đối kháng: ARD [13], RSLAD [61], Fair-ARD [49], và ABSLD [58]; Phương pháp Giảm thiểu Trade-off: TRADES [55] và SCORE [32]. Đồng thời, chúng tôi cũng cho thấy kết quả của phiên bản hội nghị của chúng tôi để so sánh: MTARD [59].

Mạng Học sinh và Giáo viên. Ở đây chúng tôi xem xét hai mạng học sinh cho CIFAR-10 và CIFAR-100 bao gồm ResNet-18 [17] và MobileNet-v2 [34]. Đối với Tiny-ImageNet, chúng tôi chọn PreActResNet-18 [18] và MobileNet-v2 theo công trình trước đó. Đối với các mô hình giáo viên, chúng tôi chọn các mạng giáo viên sạch bao gồm ResNet-56 cho CIFAR-10, WideResNet-22-6 [54] cho CIFAR-100, và PreActResNet-34 [18] cho Tiny-ImageNet. Ba mạng giáo viên bền vững bao gồm WideResNet-34-10 cho CIFAR-10, WideResNet-70-16 [15] cho CIFAR-100, và PreActResNet-34 cho Tiny-ImageNet. Đối với CIFAR-10, WideResNet-34-10 được huấn luyện bằng TRADES [55]; Đối với CIFAR-100, chúng tôi sử dụng WideResNet-70-16 được cung cấp bởi Gowal et al. [15]; Ngoài ra, đối với Tiny-ImageNet, chúng tôi sử dụng PreActResNet-34 được huấn luyện bởi TRADES [55] làm giáo viên bền vững. Các giáo viên được huấn luyện trước và sẽ không bị thay đổi trong quá trình huấn luyện. Hiệu suất của các mô hình giáo viên này được thể hiện trong Bảng 2.

Cài đặt Huấn luyện. Chúng tôi huấn luyện học sinh bằng bộ tối ưu hóa Stochastic Gradient Descent (SGD) với tốc độ học ban đầu là 0.1, momentum là 0.9, và weight decay là 2e-4. Đối với B-MTARD, tốc độ học trọng số mất mát rw được đặt ban đầu là 0.025; tốc độ học nhiệt độ rτ được đặt ban đầu là 0.001. nhiệt độ của học sinh τs được đặt là hằng số 1. Đồng thời, τnat và τadv được đặt ban đầu là 1 không có hướng dẫn bổ sung, và τnat và τadv được đặt ban đầu là 2 cho MobileNet-v2 trên CIFAR-10. Giá trị tối đa và tối thiểu của nhiệt độ lần lượt là 10 và 1. Đối với CIFAR-10 và CIFAR-100, chúng tôi đặt tổng số epoch huấn luyện là 300. Tốc độ học được chia cho 10 ở epoch thứ 215, 260, và 285; Đối với Tiny-ImageNet, chúng tôi đặt tổng số epoch huấn luyện là 100, và tốc độ học được chia cho 10 ở epoch thứ 75 và 90. Chúng tôi đặt kích thước batch là 128 (CIFAR-10 và CIFAR-100) và 32 (Tiny-ImageNet), và β được đặt là 1. Đối với tối đa hóa bên trong của B-MTARD, chúng tôi sử dụng PGD 10 bước với kích thước bắt đầu ngẫu nhiên 0.001 và kích thước bước 2/255. Tất cả nhiễu loạn huấn luyện trong tối đa hóa được giới hạn trong chuẩn L∞ ε = 8/255. Đối với việc huấn luyện mô hình tự nhiên, chúng tôi huấn luyện các mạng trong 100 epoch, và tốc độ học được chia cho 10 ở epoch thứ 75 và 90.

Đối với các phương pháp so sánh, chúng tôi tuân theo cài đặt ban đầu của SAT, TRADES, SCORE, ARD, RSLAD, Fair-ARD, và ABSLD không có hướng dẫn bổ sung. Phiên bản SCORE là TRADES+LSE không có dữ liệu bổ sung. Đối với ARD, chúng tôi sử dụng cùng giáo viên bền vững như RSLAD và MTARD. Nhiệt độ τ của ARD được đặt là 30 trên CIFAR-10 trong khi đặt là 5 trên CIFAR-100 và Tiny-ImageNet, và α được đặt là 0.95 theo [13] trên CIFAR-100 và Tiny-ImageNet. Tốc độ học của SAT và SCORE cho Tiny-ImageNet là 0.01 để đạt được hiệu suất tốt hơn.

Cài đặt Đánh giá. Giống như các nghiên cứu trước đó, chúng tôi đánh giá các mô hình chống lại các cuộc tấn công đối kháng white box: FGSM [14], PGDsat [31], PGDtrades [55], CW∞ [4], là các cuộc tấn công đối kháng được sử dụng phổ biến trong đánh giá độ bền vững đối kháng. Đồng thời, chúng tôi cũng áp dụng một cuộc tấn công mạnh: AutoAttack (AA) [10] (một công cụ đánh giá trong RobustBench [8]) để đánh giá độ bền vững. Kích thước bước của PGDsat và PGDtrades lần lượt là 2/255 và 0.003, và bước là 20. Tổng số bước của CW∞ là 30. Nhiễu loạn tối đa được giới hạn trong chuẩn L∞ ε = 8/255 cho tất cả các cuộc tấn công. Đồng thời, chúng tôi thực hiện đánh giá black-box, bao gồm cuộc tấn công dựa trên chuyển giao và cuộc tấn công dựa trên truy vấn để kiểm tra độ bền vững trong môi trường gần thực tế. Đối với cuộc tấn công dựa trên chuyển giao, chúng tôi chọn các giáo viên bền vững (WideResNet-34-10 cho CIFAR-10, WideResNet-70-16 cho CIFAR-100, và PreActResNet-34 cho Tiny-ImageNet) làm các mô hình thay thế để tạo ra ví dụ đối kháng chống lại cuộc tấn công PGDtrades và CW∞; Đối với cuộc tấn công dựa trên truy vấn, chúng tôi chọn một cuộc tấn công dựa trên điểm số: Square Attack [2] và một cuộc tấn công dựa trên quyết định: RayS Attack [6], và các truy vấn là 100.

Ở đây, chúng tôi sử dụng Độ Chính xác Bền vững Có trọng số (W-Robust Acc) [16] để đánh giá sự đánh đổi giữa độ chính xác sạch và bền vững của mô hình, nó được định nghĩa như sau:

Af = πnatPnat[f(x) = y] + πadvPadv[f(x) = y], (22)

trong đó W-Robust Acc Af là độ chính xác của một mô hình f trên x được rút từ phân phối sạch Pnat và phân phối đối kháng Padv. Chúng tôi đặt πnat và πadv đều là 0.5, có nghĩa là độ chính xác và độ bền vững đều quan trọng như nhau đối với hiệu suất toàn diện trong mô hình.

4.2 Nghiên cứu Ablation

Để hiểu rõ hơn tác động của từng thành phần trong B-MTARD của chúng tôi, chúng tôi thực hiện một tập hợp các nghiên cứu ablation. Baseline biểu thị việc sử dụng một giáo viên sạch và một giáo viên bền vững để hướng dẫn học sinh từ cả hai khía cạnh, tương ứng, trong đó trọng số wnat và wadv là hằng số 0.5. Baseline+NLB biểu thị việc thêm thuật toán Cân bằng Mất mát Chuẩn hóa (NLB) để điều chỉnh động trọng số wnat và wadv dựa trên Baseline, đây cũng là phương pháp trong phiên bản ECCV của chúng tôi (MTARD) [59]. Baseline+EBB biểu thị việc thêm thuật toán Cân bằng Dựa trên Entropy (EBB) để điều chỉnh động τnat và τadv dựa trên Baseline, trong đó trọng số wnat và wadv là hằng số 0.5. B-MTARD là phiên bản cuối cùng của phương pháp chúng tôi, áp dụng cả thuật toán Cân bằng Mất mát Chuẩn hóa và Cân bằng Dựa trên Entropy. Hiệu suất được thể hiện trong Hình 3. Sự thay đổi của tổng mất mát Ltotal trong quá trình huấn luyện được thể hiện trong Hình 4, và sự thay đổi của mất mát tương đối L̃nat và L̃adv trong quá trình huấn luyện được thể hiện trong Hình 5. Sự thay đổi của entropy thông tin của giáo viên trong quá trình huấn luyện được thể hiện trong Hình 6.

Trong Hình 3, cải thiện của B-MTARD được mang lại bởi từng thành phần là đáng chú ý, cho thấy hiệu quả của nó. Nhiều giáo viên ảnh hưởng tích cực đến mô hình học sinh để học với cả độ chính xác sạch và bền vững. Tuy nhiên, chưa đủ để giảm thiểu sự đánh đổi giữa độ chính xác và độ bền vững mà không có thuật toán Cân bằng Dựa trên Entropy và thuật toán Cân bằng Mất mát Chuẩn hóa, cả hai đều có thể tiếp tục tăng cường hiệu suất W-Robust.

Baseline+NLB vượt trội hơn Baseline 0.87%, 0.56%, và 0.6% chống lại cuộc tấn công PGDsat, PGDtrades, và CW∞ trong thước đo W-robust Acc, trong khi B-MTARD vượt trội hơn Baseline+EBB 0.33%, 0.23%, và 0.15% chống lại cuộc tấn công PGDsat, PGDtrades, và CW∞ trong thước đo W-robust Acc. Cải thiện cho thấy hiệu quả của Thuật toán Cân bằng Mất mát Chuẩn hóa của chúng tôi.

Ngoài ra, B-MTARD có cải thiện rõ ràng so với phiên bản ECCV của chúng tôi (Baseline + NLB): B-MTARD của chúng tôi cải thiện W-Robust Acc 0.89%, 0.82%, và 0.94% so với Baseline + NLB chống lại cuộc tấn công PGDsat, PGDtrades, và CW∞. Kết quả biểu thị sự cần thiết và hiệu quả của công trình gia tăng của chúng tôi (thuật toán Cân bằng Dựa trên Entropy) trong phiên bản này.

Trong Hình 4, so với RSLAD và Baseline, mất mát huấn luyện của Baseline+NLB ít dao động hơn và có thể hội tụ tốt hơn. Trong Hình 5, khoảng cách giữa L̃nat và L̃adv có thể đại diện cho sự khác biệt của tỷ lệ kiến thức mà học sinh chưa học được từ giáo viên sạch và giáo viên bền vững. Sự đánh đổi của Baseline+NLB giữa L̃nat và L̃adv nhỏ hơn. Kết quả chứng minh Cân bằng Mất mát Chuẩn hóa thực sự có thể làm cho học sinh có tốc độ học kiến thức tương đối bằng nhau từ các giáo viên khác nhau.

Trong Hình 6, chúng ta có thể thấy rằng trong Baseline+NLB, khoảng cách entropy thông tin giữa giáo viên sạch và giáo viên bền vững rất rõ ràng, nhưng sau khi điều chỉnh của thuật toán Cân bằng Dựa trên Entropy của chúng tôi, khoảng cách entropy thông tin nhanh chóng thu hẹp và duy trì tương đối nhất quán, và hiện tượng này có thể biểu thị khoảng cách quy mô kiến thức giữa giáo viên sạch và giáo viên bền vững giảm, điều này chứng minh hiệu quả của thuật toán Cân bằng Dựa trên Entropy của chúng tôi. Kết hợp với kết quả thí nghiệm trong Hình 3, việc giảm sự khác biệt trong entropy thông tin của giáo viên thực sự có thể cải thiện hiệu suất của học sinh.

4.3 Thảo luận về siêu tham số

Siêu tham số τ. Nhiệt độ của các giáo viên khác nhau được điều chỉnh tự động bởi thuật toán Dựa trên Entropy của chúng tôi cho đến khi entropy thông tin bằng nhau. Tuy nhiên, cài đặt nhiệt độ ban đầu vẫn ảnh hưởng trực tiếp đến lượng entropy thông tin cho cả hai giáo viên và xác định phạm vi điều chỉnh trước, và một nhiệt độ ban đầu phù hợp có thể đảm bảo thay đổi nhiệt độ trong phạm vi hợp lý để duy trì hiệu quả của kiến thức giáo viên. Để chọn giá trị nhiệt độ ban đầu phù hợp, chúng tôi chọn τnat và τadv ban đầu là 1, 2, 5, 8, trong khi tất cả các cài đặt thí nghiệm khác vẫn không thay đổi. Dựa trên kết quả được thể hiện trong Bảng 7, chúng tôi chọn 1 làm giá trị nhiệt độ ban đầu của chúng tôi.

Siêu tham số β. Ở đây, chúng tôi khám phá vai trò của β trong Cân bằng Mất mát Chuẩn hóa (Phương trình (17) và Phương trình (18)). Chúng tôi kiểm tra kết quả của các giá trị β khác nhau cho việc huấn luyện học sinh. Chúng tôi chọn β là 0.5, 1, 4, và 10 trong thí nghiệm của chúng tôi, trong khi tất cả các cài đặt thí nghiệm khác vẫn không thay đổi. Kết quả được trình bày trong Bảng 8.

Từ kết quả, β đóng một vai trò quan trọng trong Cân bằng Mất mát Chuẩn hóa. Việc chọn đúng giá trị β có thể ảnh hưởng đến hiệu suất cuối cùng của học sinh. β thấp hơn phù hợp khi học sinh có được quy mô kiến thức tương tự từ giáo viên sạch và giáo viên bền vững tại epoch huấn luyện hiện tại và trạng thái của học sinh không dao động nhiều. β lớn hơn mang lại hình phạt nghiêm khắc hơn đối với học sinh khi học sinh quá chú trọng vào kiến thức của một giáo viên nhưng bỏ qua giáo viên khác. Dựa trên hiệu suất, chúng tôi chọn giá trị tương đối tốt nhất: β = 1 trong cài đặt của chúng tôi.

4.4 Đánh giá Độ bền vững Đối kháng

Độ bền vững White-box. Hiệu suất của ResNet-18 và MobileNet-v2 được huấn luyện bởi B-MTARD và các phương pháp cơ sở khác dưới các cuộc tấn công white box được thể hiện trong Bảng 3 và 4 cho CIFAR-10, CIFAR-100, và Tiny-ImageNet.

Kết quả trong Bảng 3 và 4 chứng minh rằng B-MTARD đạt được W-Robust Acc tiên tiến trên CIFAR-10, CIFAR-100, và Tiny-ImageNet. Đối với ResNet-18, B-MTARD cải thiện W-Robust Acc 1.44%, 2.20%, và 1.41% so với phương pháp cơ sở tốt nhất chống lại PGDtrades trên CIFAR-10, CIFAR-100, và Tiny-ImageNet; B-MTARD cải thiện W-Robust Acc 0.79%, 2.76%, và 1.54% so với phương pháp cơ sở tốt nhất chống lại PGDtrades trên CIFAR-10, CIFAR-100, và Tiny-ImageNet. Hơn nữa, B-MTARD cho thấy ưu thế liên quan chống lại FGSM, PGDsat, CW∞, và AutoAttack so với các phương pháp khác. Kết quả cho thấy hiệu suất tổng thể của B-MTARD có lợi thế ở các mức độ khác nhau dù so với các phương pháp cơ sở khác. Đồng thời, B-MTARD cũng cho thấy ưu thế tương ứng so với phiên bản hội nghị của chúng tôi (MTARD).

Độ bền vững Black-box. Ngoài ra, chúng tôi cũng kiểm tra B-MTARD và các phương pháp khác chống lại các cuộc tấn công black-box cho ResNet-18 và MobileNet-v2 trên CIFAR-10, CIFAR-100, và Tiny-ImageNet riêng biệt. Chúng tôi chọn cuộc tấn công dựa trên chuyển giao và cuộc tấn công dựa trên truy vấn trong đánh giá của chúng tôi. Chúng tôi chọn checkpoint tốt nhất của tất cả các mô hình được huấn luyện dựa trên W-Robust Acc. Kết quả của ResNet-18 được thể hiện trong Bảng 5, trong khi kết quả của MobileNet-v2 được thể hiện trong Bảng 6.

Từ kết quả, các mô hình được huấn luyện B-MTARD đạt được W-Robust Acc tốt nhất chống lại tất cả ba cuộc tấn công black-box so với các mô hình khác. Dưới Square Attack, ResNet-18 được huấn luyện B-MTARD cải thiện W-Robust Acc 4.45%, 3.58%, và 2.74% trên CIFAR-10, CIFAR-100, và Tiny-ImageNet so với phương pháp tốt thứ hai; Hơn nữa, B-MTARD mang lại 5.56%, 4.78%, và 3.31% cải thiện cho MobileNet-v2 trên CIFAR-10, CIFAR-100, và Tiny-ImageNet. Ngoài ra, B-MTARD có biên độ khác nhau trong việc bảo vệ chống lại cuộc tấn công dựa trên truy vấn của RayS và các cuộc tấn công chuyển giao của PGDtrades và CW∞, cho thấy hiệu suất vượt trội của B-MTARD trong độ bền vững black-box.

Loại trừ Gradient Bị che khuất. Mặc dù một số phương pháp bảo vệ tuyên bố chống lại các cuộc tấn công đối kháng, điểm yếu của chúng thường bị phơi bày vì chúng thuộc về "Gradient Bị che khuất" [3], [40]. Athalye et al. [3] đã xác nhận rằng Huấn luyện Đối kháng [31] có thể bảo vệ hiệu quả chống lại cuộc tấn công thích ứng và không thuộc về "Gradient Bị che khuất". Ở đây chúng tôi lập luận rằng B-MTARD loại trừ "Gradient Bị che khuất" từ một số khía cạnh theo [3] và [42]: (1) B-MTARD của chúng tôi có thể bảo vệ hiệu quả chống lại cuộc tấn công mạnh: AutoAttack [10], bao gồm cuộc tấn công white-box mạnh: A-PGD và cuộc tấn công black-box mạnh: Square Attack [2]. (2) Các cuộc tấn công kiểm tra white-box mạnh (ví dụ, CW∞ [4]) có tỷ lệ thành công tấn công cao hơn so với các cuộc tấn công kiểm tra white-box yếu (ví dụ, FGSM [14]) trong Bảng 3 và Bảng 4. (3) Các cuộc tấn công kiểm tra White-box có tỷ lệ thành công tấn công cao hơn so với các cuộc tấn công kiểm tra Black-box (So sánh với Bảng 3 và Bảng 5, Bảng 4 và Bảng 6). (4) Để tránh số vòng tấn công không đủ và rơi vào giải pháp tối ưu cục bộ trong các phương pháp tấn công tổng quát, một phương pháp tấn công ước lượng gradient từ [40] được áp dụng trực tiếp để kiểm tra B-MTARD. Kết quả trong Bảng 9 cho thấy B-MTARD có thể chống lại hiệu quả cuộc tấn công ước lượng gradient mạnh. Đồng thời, tỷ lệ thành công tấn công black-box thấp hơn tấn công white-box, điều này tiếp tục xác nhận B-MTARD không phải là "Gradient Bị che khuất".

4.5 So sánh với Chưng cất Đa giáo viên khác

Để chứng minh thêm hiệu quả của chúng tôi, chúng tôi áp dụng phương pháp chưng cất đa giáo viên đại diện [51] vào khuôn khổ của Huấn luyện Đối kháng để so sánh với phương pháp của chúng tôi. Ở đây chúng tôi áp dụng cùng giáo viên đối kháng và giáo viên sạch với B-MTARD của chúng tôi cho [51]. Chúng tôi áp dụng trung bình có trọng số của các logits đầu ra của giáo viên khác nhau làm hướng dẫn cho cả ví dụ đối kháng và ví dụ sạch để huấn luyện mô hình học sinh (ResNet-18) trên CIFAR-10. Kết quả được thể hiện trong Bảng 10.

Kết quả cho thấy hiệu quả của phương pháp được đề xuất của chúng tôi. B-MTARD của chúng tôi vượt trội hơn LMTN 2.25%, 1.44%, 1.68%, 0.92%, và 0.73% chống lại cuộc tấn công FGSM, PGDsat, PGDtrades, CW∞, và AA trong thước đo W-robust Acc. Thực tế, giống như thảo luận trong công trình liên quan, vì việc huấn luyện các mẫu sạch và mẫu đối kháng sẽ can thiệp lẫn nhau và dẫn đến sự tồn tại của hiện tượng trade-off, cách chọn một chiến lược điều chỉnh cân bằng phù hợp để loại bỏ sự tồn tại của trade-off càng nhiều càng tốt là một thách thức tối ưu hóa khó khăn. Việc áp dụng trực tiếp các phương pháp tối ưu hóa đa giáo viên trước đó có nhược điểm trong tình huống nhiệm vụ mới này, điều này đã được chứng minh bằng kết quả thí nghiệm. Vì vậy, chúng tôi đề xuất thuật toán Cân bằng Dựa trên Entropy và thuật toán Cân bằng Mất mát Chuẩn hóa để cân bằng hai hướng tối ưu hóa từ góc độ giáo viên và học sinh, tương ứng, điều này thực sự cung cấp sự cân bằng trong chưng cất đa giáo viên xung đột. Kết quả tiếp tục cho thấy sự cần thiết và ưu thế của hai thuật toán đó.

4.6 Khám phá Thêm cho Các Mô hình Giáo viên Khác nhau

Để hiểu rõ hơn tác động của các giáo viên khác nhau, chúng tôi đánh giá hiệu suất của cùng một học sinh được hướng dẫn bởi các giáo viên khác nhau. Chúng tôi chọn ResNet-18 làm học sinh, và ResNet-56 và WideResNet-34-10-C (95.83% độ chính xác sạch) làm giáo viên sạch, tương ứng. Ngoài ra, chúng tôi chọn WideResNet-34-10 và WideResNet-70-16 (Từ [15] với độ bền vững mạnh hơn) làm giáo viên bền vững, và các cài đặt thí nghiệm khác giống như cài đặt ban đầu. Hiệu suất được thể hiện trong Bảng 11.

Thật ngạc nhiên, khả năng của học sinh không được cải thiện khi quy mô tham số của giáo viên tăng. Mặc dù các giáo viên lớn hơn có độ chính xác và độ bền vững mạnh hơn, học sinh được hướng dẫn bởi ResNet-56 sạch và WideResNet-34-10 đối kháng đạt được W-Robust Acc tốt nhất thay vì các học sinh khác được hướng dẫn bởi các giáo viên lớn hơn, điều này chứng minh rằng các giáo viên nhỏ vẫn có tiềm năng khá tốt để hướng dẫn học sinh và có thể mang lại cải thiện hiệu quả cho học sinh. Đồng thời, hiệu suất của học sinh không bị ràng buộc chặt chẽ với hiệu suất của giáo viên và kích thước mô hình, điều này vẫn có không gian tiềm năng để khám phá.

5 KẾT LUẬN

Bài báo này tập trung vào việc giảm thiểu sự đánh đổi giữa độ chính xác và độ bền vững trong Huấn luyện Đối kháng. Để mang lại cả kiến thức sạch và bền vững, chúng tôi đề xuất Chưng cất Độ bền vững Đối kháng Đa giáo viên Cân bằng (B-MTARD) để hướng dẫn mô hình học sinh, trong đó một giáo viên sạch và một giáo viên bền vững được áp dụng trong trạng thái cân bằng trong quá trình Huấn luyện Đối kháng. Ngoài ra, chúng tôi đề xuất thuật toán Cân bằng Dựa trên Entropy để giữ cho quy mô kiến thức của các giáo viên này nhất quán. Để đảm bảo rằng học sinh có được kiến thức bằng nhau từ hai giáo viên, chúng tôi thiết kế một phương pháp để sử dụng Cân bằng Mất mát Chuẩn hóa trong B-MTARD. Một loạt thí nghiệm chứng minh rằng B-MTARD của chúng tôi vượt trội hơn các phương pháp Huấn luyện Đối kháng hiện có và chưng cất độ bền vững đối kháng trên CIFAR-10, CIFAR-100, và Tiny-ImageNet. Trong tương lai, B-MTARD có thể được áp dụng cho các nhiệm vụ khác với nhiều mục tiêu tối ưu hóa, không chỉ giới hạn trong huấn luyện đối kháng, có tiềm năng phát triển lớn.

LỜI CẢM ƠN

Công trình này được hỗ trợ bởi Dự án của Quỹ Khoa học Tự nhiên Quốc gia Trung Quốc (Số 62076018), và Quỹ Nghiên cứu Cơ bản cho các Trường Đại học Trung ương.

TÀI LIỆU THAM KHẢO

[1] Alayrac, J.B., Uesato, J., Huang, P.S., Fawzi, A., Stanforth, R., Kohli, P.: Are labels required for improving adversarial robustness? NeurIPS 32(2019)
[2] Andriushchenko, M., Croce, F., Flammarion, N., Hein, M.: Square attack: a query-efficient black-box adversarial attack via random search. In: ECCV. pp. 484–501. Springer (2020)
[3] Athalye, A., Carlini, N., Wagner, D.: Obfuscated gradients give a false sense of security: Circumventing defenses to adversarial examples. In: ICML. pp. 274–283. PMLR (2018)
[4] Carlini, N., Wagner, D.: Towards evaluating the robustness of neural networks. In: 2017 ieee symposium on security and privacy (sp). pp. 39–57. IEEE (2017)
[5] Carmon, Y., Raghunathan, A., Schmidt, L., Duchi, J.C., Liang, P.S.: Unlabeled data improves adversarial robustness. NeurIPS 32 (2019)
[6] Chen, J., Gu, Q.: Rays: A ray searching method for hard-label adversarial attack. In: Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. pp. 1739–1747 (2020)
[7] Chen, Z., Badrinarayanan, V., Lee, C.Y., Rabinovich, A.: Gradnorm: Gradient normalization for adaptive loss balancing in deep multi-task networks. In: ICML. pp. 794–803. PMLR (2018)
[8] Croce, F., Andriushchenko, M., Sehwag, V., Debenedetti, E., Flammarion, N., Chiang, M., Mittal, P., Hein, M.: Robustbench: a standardized adversarial robustness benchmark. In: Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 2) (2021)
[9] Croce, F., Hein, M.: Minimally distorted adversarial examples with a fast adaptive boundary attack. In: ICML. pp. 2196–2205. PMLR (2020)
[10] Croce, F., Hein, M.: Reliable evaluation of adversarial robustness with an ensemble of diverse parameter-free attacks. In: ICML. pp. 2206–2216. PMLR (2020)
[11] Demontis, A., Melis, M., Pintor, M., Jagielski, M., Biggio, B., Oprea, A., Nita-Rotaru, C., Roli, F.: Why do adversarial attacks transfer? explaining transferability of evasion and poisoning attacks. In: 28th USENIX security symposium (USENIX security 19). pp. 321–338 (2019)
[12] Furlanello, T., Lipton, Z., Tschannen, M., Itti, L., Anandkumar, A.: Born again neural networks. In: ICML. pp. 1607–1616. PMLR (2018)
[13] Goldblum, M., Fowl, L., Feizi, S., Goldstein, T.: Adversarially robust distillation. In: AAAI. vol. 34, pp. 3996–4003 (2020)
[14] Goodfellow, I.J., Shlens, J., Szegedy, C.: Explaining and harnessing adversarial examples. arXiv preprint:1412.6572 (2014)
[15] Gowal, S., Qin, C., Uesato, J., Mann, T., Kohli, P.: Uncovering the limits of adversarial training against norm-bounded adversarial examples. arXiv preprint:2010.03593 (2020)
[16] Gürel, N.M., Qi, X., Rimanic, L., Zhang, C., Li, B.: Knowledge enhanced machine learning pipeline against diverse adversarial attacks. In: ICML. pp. 3976–3987. PMLR (2021)
[17] He, K., Zhang, X., Ren, S., Sun, J.: Deep residual learning for image recognition. In: CVPR. pp. 770–778 (2016)
[18] He, K., Zhang, X., Ren, S., Sun, J.: Identity mappings in deep residual networks. In: ECCV. pp. 630–645. Springer (2016)
[19] Hendrycks, D., Lee, K., Mazeika, M.: Using pre-training can improve model robustness and uncertainty. In: ICML. pp. 2712–2721. PMLR (2019)
[20] Hinton, G., Vinyals, O., Dean, J., et al.: Distilling the knowledge in a neural network. arXiv preprint:1503.02531 2(7) (2015)
[21] Huang, Q., Katsman, I., He, H., Gu, Z., Belongie, S., Lim, S.N.: Enhancing adversarial example transferability with an intermediate level attack. In: ICCV. pp. 4733–4742 (2019)
[22] Krizhevsky, A., Hinton, G., et al.: Learning multiple layers of features from tiny images (2009)
[23] Kwon, K., Na, H., Lee, H., Kim, N.S.: Adaptive knowledge distillation based on entropy. In: ICASSP. pp. 7409–7413. IEEE (2020)
[24] Le, Y., Yang, X.: Tiny imagenet visual recognition challenge. CS 231N 7(7), 3 (2015)
[25] Li, X.C., Fan, W.S., Song, S., Li, Y., Li, B., Shao, Y., Zhan, D.C.: Asymmetric temperature scaling makes larger networks teach well again. arXiv preprint:2210.04427 (2022)
[26] Li, Z., Li, X., Yang, L., Zhao, B., Song, R., Luo, L., Li, J., Yang, J.: Curriculum temperature for knowledge distillation. arXiv preprint:2211.16231 (2022)
[27] Liang, S., Wu, B., Fan, Y., Wei, X., Cao, X.: Parallel rectangle flip attack: A query-based black-box attack against object detection. arXiv preprint:2201.08970 (2022)
[28] Liu, J., Liu, B., Li, H., Liu, Y.: Meta knowledge distillation. arXiv preprint:2202.07940 (2022)
[29] Liu, Y., Zhang, W., Wang, J.: Adaptive multi-teacher multi-level knowledge distillation. Neurocomputing 415, 106–113 (2020)
[30] Lopez-Paz, D., Bottou, L., Schölkopf, B., Vapnik, V.: Unifying distillation and privileged information. arXiv preprint:1511.03643 (2015)
[31] Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A.: Towards deep learning models resistant to adversarial attacks. arXiv preprint:1706.06083 (2017)
[32] Pang, T., Lin, M., Yang, X., Zhu, J., Yan, S.: Robustness and accuracy could be reconcilable by (proper) definition. In: ICML. (2022)
[33] Papernot, N., McDaniel, P., Wu, X., Jha, S., Swami, A.: Distillation as a defense to adversarial perturbations against deep neural networks. In: 2016 IEEE symposium on security and privacy (SP). pp. 582–597. IEEE (2016)
[34] Sandler, M., Howard, A., Zhu, M., Zhmoginov, A., Chen, L.C.: Mobilenetv2: Inverted residuals and linear bottlenecks. In: CVPR. pp. 4510–4520 (2018)
[35] Sarikaya, R., Hinton, G.E., Deoras, A.: Application of deep belief networks for natural language understanding. IEEE/ACM Transactions on Audio, Speech, and Language Processing 22(4), 778–784 (2014)
[36] Shannon, C.E.: A mathematical theory of communication. The Bell system technical journal 27(3), 379–423 (1948)
[37] Son, W., Na, J., Choi, J., Hwang, W.: Densely guided knowledge distillation using multiple teacher assistants. In: ICCV. pp. 9395–9404 (2021)
[38] Stutz, D., Hein, M., Schiele, B.: Disentangling adversarial robustness and generalization. In: CVPR. pp. 6976–6987 (2019)
[39] Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R.: Intriguing properties of neural networks. arXiv preprint:1312.6199 (2013)
[40] Tramer, F., Carlini, N., Brendel, W., Madry, A.: On adaptive attacks to adversarial example defenses. NeurIPS (2020)
[41] Wang, H., Wang, Y., Zhou, Z., Ji, X., Gong, D., Zhou, J., Li, Z., Liu, W.: Cosface: Large margin cosine loss for deep face recognition. In: CVPR. pp. 5265–5274 (2018)
[42] Wang, Y., Zou, D., Yi, J., Bailey, J., Ma, X., Gu, Q.: Improving adversarial robustness requires revisiting misclassified examples. In: ICLR (2019)
[43] Wei, X., Guo, Y., Li, B.: Black-box adversarial attacks by manipulating image attributes. Information sciences 550, 285–296 (2021)
[44] Wei, X., Guo, Y., Yu, J.: Adversarial sticker: A stealthy attack method in the physical world. TPAMI (2022)
[45] Wei, X., Guo, Y., Yu, J., Zhang, B.: Simultaneously optimizing perturbations and positions for black-box adversarial patch attacks. TPAMI (2022)
[46] Wei, X., Wang, S., Yan, H.: Efficient robustness assessment via adversarial spatial-temporal focus on videos. TPAMI (2023)
[47] Wei, X., Yan, H., Li, B.: Sparse black-box video attack with reinforcement learning. IJCV 130(6), 1459–1473 (2022)
[48] Wu, A., Zheng, W.S., Guo, X., Lai, J.H.: Distilled person re-identification: Towards a more scalable system. In: CVPR. pp. 1187–1196 (2019)
[49] Xinli, Y., Mou, N., Qian, W., Lingchen, Z.: Revisiting adversarial robustness distillation from the perspective of robust fairness. NeurIPS (2023)
[50] Yang, Y.Y., Rashtchian, C., Zhang, H., Salakhutdinov, R.R., Chaudhuri, K.: A closer look at accuracy vs. robustness. NeurIPS 33, 8588–8601 (2020)
[51] You, S., Xu, C., Xu, C., Tao, D.: Learning from multiple teacher networks. In: Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. pp. 1285–1294 (2017)
[52] Yuan, F., Shou, L., Pei, J., Lin, W., Gong, M., Fu, Y., Jiang, D.: Reinforced multi-teacher selection for knowledge distillation. In: AAAI. vol. 35, pp. 14284–14291 (2021)
[53] Yuan, L., Tay, F.E., Li, G., Wang, T., Feng, J.: Revisiting knowledge distillation via label smoothing regularization. In: CVPR. pp. 3903–3911 (2020)
[54] Zagoruyko, S., Komodakis, N.: Wide residual networks. arXiv preprint:1605.07146 (2016)
[55] Zhang, H., Yu, Y., Jiao, J., Xing, E., El Ghaoui, L., Jordan, M.: Theoretically principled trade-off between robustness and accuracy. In: ICML. pp. 7472–7482. PMLR (2019)
[56] Zhang, J., Zhu, J., Niu, G., Han, B., Sugiyama, M., Kankanhalli, M.: Geometry-aware instance-reweighted adversarial training. arXiv preprint:2010.01736 (2020)
[57] Zhao, H., Sun, X., Dong, J., Chen, C., Dong, Z.: Highlight every step: Knowledge distillation via collaborative teaching. IEEE Transactions on Cybernetics 52(4), 2070–2081 (2020)
[58] Zhao, S., Wang, X., Wei, X.: Improving adversarial robust fairness via anti-bias soft label distillation. arXiv preprint:2312.05508 (2023)
[59] Zhao, S., Yu, J., Sun, Z., Zhang, B., Wei, X.: Enhanced accuracy and robustness via multi-teacher adversarial distillation. In: ECCV. pp. 585–602. Springer (2022)
[60] Zhu, J., Yao, J., Han, B., Zhang, J., Liu, T., Niu, G., Zhou, J., Xu, J., Yang, H.: Reliable adversarial distillation with unreliable teachers. arXiv preprint:2106.04928 (2021)
[61] Zi, B., Zhao, S., Ma, X., Jiang, Y.G.: Revisiting adversarial robustness distillation: Robust soft labels make student better. In: ICCV (2021)

Shiji Zhao nhận bằng Cử nhân tại Trường Khoa học và Kỹ thuật Máy tính, Đại học Beihang (BUAA), Trung Quốc. Hiện tại anh đang là nghiên cứu sinh tiến sĩ tại Viện Trí tuệ Nhân tạo, Đại học Beihang (BUAA), Trung Quốc. Lĩnh vực nghiên cứu của anh bao gồm thị giác máy tính, học sâu và độ bền vững đối kháng trong học máy.

Xizhe Wang nhận bằng Cử nhân tại Viện Trí tuệ Nhân tạo, Đại học Beihang (BUAA), Trung Quốc. Hiện tại cô đang là học viên thạc sĩ tại Viện Trí tuệ Nhân tạo, Đại học Beihang (BUAA), Trung Quốc. Lĩnh vực nghiên cứu của cô bao gồm thị giác máy tính, học sâu và độ bền vững đối kháng trong học máy.

Xingxing Wei nhận bằng Tiến sĩ ngành khoa học máy tính từ Đại học Thiên Tân, và bằng Cử nhân ngành Tự động hóa từ Đại học Beihang (BUAA), Trung Quốc. Hiện tại ông là Phó Giáo sư tại Đại học Beihang (BUAA). Lĩnh vực nghiên cứu của ông bao gồm thị giác máy tính, học máy đối kháng và các ứng dụng của nó trong phân tích nội dung đa phương tiện. Ông là tác giả của các tạp chí và hội nghị tham khảo trong IEEE TPAMI, IJCV, CVPR, ICCV, ECCV, v.v.

PHỤ LỤC A
CHỨNG MINH

Chứng minh 1. Dựa trên định nghĩa của entropy quan hệ, quy mô kiến thức KT có thể được mở rộng thêm như sau:

KT = KL(I(x), T(x)) = -∑(k=1 to C) pTk(x)log(pIk(x)) - H(PT), (23)

trong đó PI = {pI1(x), ..., pIC(x)} và PT = {pT1(x), ..., pTC(x)} biểu thị phân phối dự đoán của mô hình tổng quát I và phân phối dự đoán của mô hình giáo viên được huấn luyện tốt T, tương ứng. Đối với mô hình tổng quát, dự đoán của mô hình không có sở thích đối với bất kỳ mẫu nào, vì vậy một giả định hợp lý có thể được đưa ra như sau:

pIk(x) = 1/C, k = 1, 2, ..., C. (24)

Dựa trên giả định này, chúng ta có thể dễ dàng thấy rằng số hạng đầu tiên (-∑(k=1 to C) pTk(x)log(pIk(x))) trong Phương trình (23) thỏa mãn:

-∑(k=1 to C) pTk(x)log(pIk(x)) = -∑(k=1 to C) pTk(x)log(1/C), (25)

vì tổng của dự đoán mô hình bằng 1, vậy ∑(k=1 to C) pTk(x) = 1, sau đó chúng ta có:

-∑(k=1 to C) pTk(x)log(pIk(x)) = -log(1/C) = logC, (26)

và -log(1/C) là một hằng số không thay đổi, vì vậy quy mô kiến thức của giáo viên có liên quan nghịch với số hạng thứ hai trong Phương trình (23) (entropy thông tin H(PT)) như sau:

KT = logC - H(PT). (27)

Sau đó Định lý 1 được chứng minh.

Chứng minh 2. Ở đây chúng tôi đầu tiên định nghĩa q như exp(z(x)/τ) trong Phương trình (3) của văn bản chính, và pm = qm/∑(j=1 to C) qj, và phân phối P = {p1, p2, ..., pC}, sau đó chúng tôi tiếp tục mở rộng entropy thông tin H(P) như sau:

H(P) = -∑(j=1 to C) pjlog(pj), (28)

= -∑(j=1 to C) (qj/∑(k=1 to C) qk)log(qj/∑(k=1 to C) qk), (29)

= -[(∑(j=1 to C) qjlogqj) - (∑(j=1 to C) qj)log(∑(j=1 to C) qj)] / ∑(j=1 to C) qj, (30)

= -(∑(j=1 to C) qjlogqj) / ∑(j=1 to C) qj + log∑(j=1 to C) qj. (31)

Sau khi entropy thông tin H(P) được phân tách, chúng tôi đầu tiên cố gắng giải quyết đạo hàm riêng của entropy thông tin H(P) đối với qm như sau:

∇qmH(P) = 1/∑(j=1 to C) qj - ((logqm + 1)∑(j=1 to C) qj - ∑(j=1 to C) qjlogqj) / (∑(j=1 to C) qj)², (32)

= -(logqm∑(j=1 to C) qj - ∑(j=1 to C) qjlogqj) / (∑(j=1 to C) qj)², (33)

= -logqm∑(j=1 to C) qj + ∑(j=1 to C) qjlogqj / (∑(j=1 to C) qj)². (34)

Sau đó chúng tôi tính toán đạo hàm riêng của qm đối với τ như sau:

∇τqm = -qmzm(x)/τ² = -qmlogqm/τ. (35)

Theo quy tắc chuỗi của đạo hàm, chúng ta có thể tính toán đạo hàm riêng của entropy thông tin đối với τ như sau:

∇τH(P) = ∑(m=1 to C) ∇qmH(P)∇τqm (36)

= ∑(m=1 to C) [-(logqm∑(j=1 to C) qj - ∑(j=1 to C) qjlogqj) / (∑(j=1 to C) qj)²](-qmlogqm/τ) (37)

= (1/τ)∑(m=1 to C) [qmlog²qm∑(j=1 to C) qj - qmlogqm∑(j=1 to C) qjlogqj] / (∑(j=1 to C) qj)² (38)

= [(∑(j=1 to C) qj)(∑(j=1 to C) qjlog²qj) - (∑(j=1 to C) qjlogqj)²] / [τ(∑(j=1 to C) qj)²] (39)

Chứng minh 3. Ở đây chúng tôi cố gắng chứng minh ∇τH(P) ≥ 0, theo bất đẳng thức Cauchy-Buniakowsky-Schwarz, việc dẫn xuất như sau:

(∑(j=1 to C) qj)(∑(j=1 to C) qjlog²qj), (40)

= (∑(j=1 to C) (√qj)²)(∑(j=1 to C) ((√qj)logqj)²), (41)

≥ (∑(j=1 to C) qjlogqj)². (42)

Dấu bằng = chỉ xảy ra khi tất cả qj bằng nhau, và τ và qi luôn lớn hơn 0,

∇τH(P) = [(∑(j=1 to C) qj)(∑(j=1 to C) qjlog²qj) - (∑(j=1 to C) qjlogqj)²] / [τ(∑(j=1 to C) qj)²] ≥ 0. (43)

Sau đó kết luận ∇τH(P) ≥ 0 được chứng minh.

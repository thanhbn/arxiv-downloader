# ICLEF: Học Theo Ngữ Cảnh với Phản Hồi Chuyên Gia cho Chuyển Đổi Phong Cách Có Thể Giải Thích

Arkadiy Saakyan1 và Smaranda Muresan1,2
1Khoa Khoa học Máy tính, Đại học Columbia
2Viện Khoa học Dữ liệu, Đại học Columbia
a.saakyan@cs.columbia.edu, smara@columbia.edu

## Tóm tắt

Trong khi các mô hình ngôn ngữ lớn (LLM) hiện đại có thể xuất sắc trong việc điều chỉnh văn bản từ phong cách này sang phong cách khác, công việc hiện tại không giải quyết **khả năng giải thích** của các mô hình chuyển đổi phong cách. Nghiên cứu gần đây đã khám phá việc tạo ra các giải thích bằng văn bản từ các mô hình giáo viên lớn hơn và chưng cất chúng vào các mô hình học sinh nhỏ hơn. Một thách thức với phương pháp như vậy là các đầu ra LLM có thể chứa lỗi cần chuyên môn để sửa chữa, nhưng việc thu thập và kết hợp phản hồi của chuyên gia là khó khăn do chi phí và sự sẵn có. Để giải quyết thách thức này, chúng tôi đề xuất ICLEF, một phương pháp hợp tác người-AI mới cho việc chưng cất mô hình kết hợp phản hồi hiếm hoi của chuyên gia con người bằng cách kết hợp **học theo ngữ cảnh** và **tự phê bình** của mô hình. Chúng tôi chỉ ra rằng phương pháp của chúng tôi dẫn đến việc tạo ra các tập dữ liệu chuyển đổi phong cách có thể giải thích chất lượng cao tổng hợp cho tính trang trọng (E-GYAFC) và thiên kiến chủ quan (E-WNC). Thông qua đánh giá tự động và con người, chúng tôi chỉ ra rằng các mô hình học sinh chuyên biệt được tinh chỉnh trên các tập dữ liệu của chúng tôi vượt trội hơn các mô hình giáo viên tổng quát trong nhiệm vụ chuyển đổi phong cách có thể giải thích trong cài đặt một lần, và thực hiện cạnh tranh so với các mô hình giáo viên vài lần, làm nổi bật chất lượng của dữ liệu và vai trò của phản hồi chuyên gia. Trong một nhiệm vụ bên ngoài về phân biệt tác giả, chúng tôi chỉ ra rằng các giải thích được tạo ra bởi các mô hình nhỏ hơn được tinh chỉnh trên E-GYAFC có tính dự đoán cao hơn về tác giả so với các giải thích được tạo ra bởi các mô hình giáo viên vài lần.

## 1 Giới thiệu

Chuyển đổi phong cách thuộc tính là nhiệm vụ biến đổi một văn bản cho trước theo một chiều hướng phong cách cụ thể, chẳng hạn như thay đổi tính trang trọng, thiên kiến, hoặc mức độ xúc phạm của nó (Lample et al., 2019; Sudhakar et al., 2019; Jin et al., 2022). Chuyển đổi phong cách trang trọng (ví dụ: không trang trọng → trang trọng) có thể hữu ích trong bất kỳ hệ thống hỗ trợ viết nào, trong khi việc trung hòa văn bản chứa thiên kiến chủ quan sẽ là một công cụ quan trọng cho các biên tập viên Wikipedia (Pryzant et al., 2020) hoặc nhà báo (Rosenberg và Fischer, 2023).

Các phương pháp chuyển đổi phong cách chủ yếu tập trung vào nhiệm vụ viết lại văn bản (ví dụ: không trang trọng → trang trọng, thiên kiến chủ quan → trung tính) sử dụng các phương pháp khác nhau từ có giám sát (Rao và Tetreault, 2018; Pryzant et al., 2020; Zhong et al., 2021) đến không giám sát (Krishna et al., 2020) và các phương pháp zero-shot sử dụng LLM (Reif et al., 2022) (xem thêm Jin et al. (2022) để có khảo sát về chuyển đổi phong cách). Tuy nhiên, theo kiến thức của chúng tôi, không có nỗ lực nào tập trung vào việc cung cấp các giải thích bằng văn bản cho nhiệm vụ chuyển đổi phong cách. Ví dụ, khi chuyển đổi một câu không trang trọng "I would throw them out asap !" thành một cách diễn đạt trang trọng "I would dispose of them promptly", sẽ hữu ích khi cung cấp một giải thích về các thuộc tính không trang trọng trong câu đầu vào (ví dụ: textese ("asap"), cách nói thông tục ("throw out")), và các thuộc tính trang trọng cho cách diễn đạt (ví dụ: sự tinh tế từ vựng ("promptly" và "dispose"); thiếu viết tắt ("I would")). Tương tự, để trung hòa thiên kiến chủ quan trong "Orbis latinus, integral site of romance language" → "Orbis latinus, comprehensive site of romance language", sẽ hữu ích khi có một giải thích về từ/cụm từ nào trong đầu vào có thiên kiến và tại sao cũng như loại thiên kiến (ví dụ: Framing ("integral" ngụ ý một đánh giá chủ quan về tầm quan trọng của trang web)). Các giải thích của mô hình có thể giúp người dùng đánh giá tốt hơn tính chính xác của hệ thống chuyển đổi phong cách, có thể được sử dụng làm đặc trưng trong các nhiệm vụ xuôi dòng như phân biệt tác giả (Phần 5), hoặc có thể hoạt động như một biện pháp phòng thủ chống lại các tương quan giả tạo (Ludan et al., 2023; Camburu et al., 2018) và các hiện vật chú thích (McCoy et al., 2019; Poliak et al., 2018).

Để cho phép khả năng giải thích trong các mô hình chuyển đổi phong cách, chúng tôi cung cấp các đóng góp sau:

• **Một nhiệm vụ mới về chuyển đổi phong cách có thể giải thích** mà trong đó, ngoài việc viết lại câu, mô hình cần tạo ra các giải thích bằng văn bản.

• **Một khung hợp tác người-AI mới, Học Theo Ngữ Cảnh với Phản Hồi Chuyên Gia (ICLEF)** (xem Hình 1, Hình 2, và §3.2). Phương pháp này kết hợp chưng cất mô hình để tạo giải thích (Ho et al., 2022; Magister et al., 2023) với khả năng tự phê bình của LLM (Madaan et al., 2023; Bai et al., 2022b; Saunders et al., 2022; Scheurer et al., 2023, trong số nhiều tác giả khác), trong đó người phê bình, không giống như trong công việc trước đây, được khởi tạo với các minh họa chuyên gia.

• **Sử dụng ICLEF, chúng tôi tạo ra lần đầu tiên các tập dữ liệu cho chuyển đổi phong cách có thể giải thích** bằng cách bổ sung một tập dữ liệu chuyển đổi phong cách trang trọng hiện có GYAFC (Rao và Tetreault, 2018) và tập dữ liệu trung hòa thiên kiến chủ quan WNC (Pryzant et al., 2020) với các giải thích bằng văn bản (§3). Chúng tôi chỉ ra rằng các tập dữ liệu được tạo ra với sự giúp đỡ của ICLEF, E-GYAFC và E-WNC, có chất lượng tốt thông qua đánh giá tự động và chuyên gia, và các thể hiện được ICLEF-sửa chữa được ưa thích (§3.3).

• **Các thí nghiệm cho thấy rằng các mô hình học sinh vượt trội hơn các mô hình giáo viên trong cài đặt một lần và thực hiện tương đương ngay cả với các mô hình giáo viên vài lần trong đánh giá tự động và chuyên gia**, xác nhận tính hữu dụng và chất lượng của các tập dữ liệu (§4). Hơn nữa, trong một đánh giá bên ngoài, chúng tôi chỉ ra rằng các giải thích được tạo ra bởi các mô hình học sinh được tinh chỉnh trên dữ liệu của chúng tôi tạo ra một tín hiệu tốt hơn cho nhiệm vụ phân biệt tác giả so với các giải thích được tạo ra bởi các mô hình giáo viên vài lần (§5).

Chúng tôi phát hành dữ liệu, mô hình và mã để khuyến khích nghiên cứu thêm về khả năng giải thích, học từ phản hồi hiếm hoi của con người, và chuyển đổi phong cách.¹

## 2 Công việc liên quan

**Chưng cất kiến thức và phản hồi con người**
Chưng cất mô hình hoặc kiến thức là một quá trình tinh chỉnh một mô hình học sinh nhỏ hơn để bắt chước hành vi của một mô hình giáo viên có khả năng hơn (Beyer et al., 2022; Buciluundefined et al., 2006; Hinton et al., 2015). Chưng cất kiến thức trở thành một kỹ thuật phổ biến, cho phép tạo ra các tập dữ liệu có chất lượng tương tự với dữ liệu từ cộng đồng (West et al., 2022), đặc biệt khi kết hợp với phương pháp mô hình-trong-vòng lặp (Wiegreffe et al., 2022; Bartolo et al., 2022; Chakrabarty et al., 2022). Công việc gần đây khám phá chưng cất mô hình với các giải thích ngôn ngữ tự nhiên (Wang et al., 2023a; Ho et al., 2022; Magister et al., 2023), cho thấy rằng các mô hình ngôn ngữ lớn có khả năng tạo ra các bước lý luận đủ chấp nhận được để các mô hình học sinh học hỏi.

Các phương pháp kết hợp phản hồi con người như RLHF (Stiennon et al., 2020) và DPO (Rafailov et al., 2023) đòi hỏi lượng lớn dữ liệu từ cộng đồng và chưa được chứng minh là hiệu quả chung cho sở thích của chuyên gia. Học bắt chước từ phản hồi con người (ILF) (Scheurer et al., 2023) sử dụng phản hồi con người để cải thiện các thể hiện do mô hình tạo ra, và sau đó tinh chỉnh trên dữ liệu đó. Không giống như những công việc này, chúng tôi tập trung vào việc kết hợp phản hồi chuyên gia vốn dĩ hiếm hoi và đắt đỏ để thu thập. Không giống như các phương pháp tự phê bình khác (Madaan et al., 2023; Bai et al., 2022b; Saunders et al., 2022), chúng tôi điều kiện hóa mô hình dựa trên các sửa chữa của chuyên gia để kết hợp phản hồi con người chất lượng cao.

**Giải thích bằng văn bản**
Các giải thích ngôn ngữ tự nhiên đã được sử dụng cho nhiều nhiệm vụ khác nhau Wiegreffe và Marasovic (2021), như suy luận ngôn ngữ tự nhiên (Camburu et al., 2018), hiểu biết thông thường (Rajani et al., 2019; Aggarwal et al., 2021), suy luận chuẩn mực xã hội (CH-Wang et al., 2023). Chúng tôi tập trung vào việc tạo ra các giải thích ngôn ngữ tự nhiên cho nhiệm vụ chuyển đổi phong cách, điều chưa được giải quyết trước đây.

**Chuyển đổi phong cách**
Các phương pháp chuyển đổi phong cách dao động từ các phương pháp dựa trên hướng dẫn (Reif et al., 2022) và diễn đạt lại (Krishna et al., 2020), đến các phương pháp tập trung vào học trong cài đặt tài nguyên thấp (Patel et al., 2022). Phần lớn công việc chuyển đổi phong cách tập trung vào các biểu diễn phong cách tách biệt phong cách và nội dung (Wegmann et al., 2022; Wegmann và Nguyen, 2021), tuy nhiên hầu hết các phương pháp này không được thiết kế để có thể giải thích được. Các phương pháp có thể giải thích dựa vào việc xây dựng các embedding có thể giải thích, như LIWC (Tausczik và Pennebaker, 2010) hoặc LISA (Patel et al., 2023). Zhong et al. (2021) đề xuất xác định các đoạn thiên kiến kết hợp với việc trung hòa văn bản thiên kiến. Không giống như các phương pháp này, chúng tôi đề xuất sử dụng các giải thích ngôn ngữ tự nhiên để tăng cường thêm khả năng giải thích của mô hình.

## 3 Xây dựng Tập dữ liệu cho Chuyển đổi Phong cách Có thể Giải thích

Chúng tôi xây dựng hai tập dữ liệu chuyển đổi phong cách có thể giải thích bằng cách trước tiên bổ sung các tập dữ liệu hiện có với các giải thích bằng văn bản tổng hợp được tạo ra bởi một mô hình giáo viên (§3.1), và sau đó cải thiện dữ liệu được tạo ra bằng cách sử dụng khung Học Theo Ngữ Cảnh với Phản Hồi Chuyên Gia (ICLEF) của chúng tôi (§3.2).

### 3.1 Bổ sung Tập dữ liệu Chuyển đổi Phong cách với Giải thích Bằng văn bản Tổng hợp

**Chuyển đổi phong cách trang trọng**
Tập dữ liệu chuyển đổi phong cách trang trọng GYAFC (Rao và Tetreault, 2018) chứa các câu trang trọng và không trang trọng song song. Các câu không trang trọng được thu thập từ Yahoo Answers, và các cách diễn đạt trang trọng được cộng đồng tạo ra bằng Amazon Mechanical Turk (AMT). Chúng tôi sử dụng ChatGPT-3.5 để tạo ra các giải thích và xây dựng nhiệm vụ tạo đa bước sau: cho một câu không trang trọng từ GYAFC si, tạo ra một giải thích có cấu trúc về các thuộc tính không trang trọng ei của nó, sau đó tạo ra một cách diễn đạt trang trọng sf dựa trên các thuộc tính này, sau đó là các thuộc tính trang trọng của cách diễn đạt kết quả ef. Tạo ra cả ei và ef cho phép chúng tôi huấn luyện các mô hình theo cả hai hướng (trang trọng → không trang trọng và không trang trọng → trang trọng). Chúng tôi sử dụng một định dạng bán cấu trúc cho các giải thích. Cụ thể, chúng tôi yêu cầu mô hình tạo ra một danh sách các thuộc tính theo sau là một đoạn trích từ câu làm bằng chứng: thuộc tính ("bằng chứng"), xem ví dụ trong Hình 1. Những giải thích này có một định dạng nhất quán, làm cho việc xác minh và đánh giá tự động dễ dàng hơn.

**Chuyển đổi phong cách thiên kiến chủ quan**
Chúng tôi tập trung vào nhiệm vụ trung hòa ngôn ngữ thiên kiến chủ quan được giới thiệu bởi Pryzant et al. (2020) để làm cho các câu tuân theo Chính sách Quan điểm Trung tính Wikipedia.² Chúng tôi bắt đầu với Wikipedia Neutrality Corpus (WNC) (Pryzant et al., 2020), một corpus song song gồm 180.000 cặp câu có nguồn gốc từ các chỉnh sửa Wikipedia về ngôn ngữ thiên kiến chủ quan. Mục tiêu là tạo ra một giải thích (eb) cho loại thiên kiến có mặt trong câu thiên kiến (sb), theo lược đồ được đề xuất bởi Pryzant et al. (2020) và Recasens et al. (2013): Framing, Epistemological, và Demographic (xem định nghĩa trong Phụ lục I). Pryzant et al. (2020) ước tính rằng một tỷ lệ nhỏ các trường hợp, các thể hiện trong WNC chứa nhiễu. Chúng tôi thêm một nhãn "No Bias" bổ sung cho những trường hợp này để giảm các thiên kiến ảo tưởng cho các câu trung tính. Trong trường hợp này, chúng tôi yêu cầu mô hình xuất ra "This sentence does not contain bias" làm giải thích (xem ví dụ WNC thứ hai trong Bảng 1). Giải thích được cấu trúc như Type of Bias ("evidence" reasoning). Sau đó, mô hình giáo viên tạo ra một cách diễn đạt không thiên kiến (sn). Xem Hình 2 để có cái nhìn tổng quan. Vào thời điểm chúng tôi phát triển tập dữ liệu này, ChatGPT-4 đã có sẵn, vì vậy chúng tôi sử dụng mô hình mạnh mẽ hơn này làm giáo viên, đặc biệt vì việc tạo ra các giải thích cho nhiệm vụ này có thể đòi hỏi nhiều khả năng lý luận hơn. Chúng tôi không tạo ra các giải thích cho tính trung tính của cách diễn đạt vì chúng tôi không khám phá hướng diễn đạt trung tính thành thiên kiến do các mối quan tâm đạo đức.

### 3.2 Học Theo Ngữ Cảnh từ Phản Hồi Chuyên Gia (ICLEF)

Các tạo sinh ChatGPT có thể chứa lỗi (ví dụ: thuộc tính phong cách được tạo ra "abbreviated language" với bằng chứng "I would" trong Hình 1). Để cải thiện chất lượng dữ liệu, chúng tôi chuyển sang phản hồi chuyên gia, vì công việc trước đây đã xác định rằng những người làm việc cộng đồng trên các nền tảng như Amazon Mechanical Turk có thể không đáng tin cậy cho các nhiệm vụ tạo sinh mở (Karpinska et al., 2021), và thậm chí có thể dựa vào ChatGPT để cung cấp câu trả lời của họ (Veselovsky et al., 2023). Điểm cốt lõi của phương pháp chúng tôi là kết hợp học theo ngữ cảnh và khả năng tự phê bình của LLM bằng cách khởi tạo mô hình LLM-critic với các minh họa phản hồi chuyên gia vài lần.

**E-GYAFC**
Đối với nhiệm vụ chuyển đổi phong cách trang trọng, chúng tôi thuê một chuyên gia chú thích có bằng Thạc sĩ ngôn ngữ học trên Upwork³. Giao thức chú thích của chúng tôi (xem Phụ lục J) cung cấp một tham chiếu không đầy đủ về các thuộc tính trang trọng và không trang trọng và yêu cầu người chú thích cung cấp phản hồi về thuộc tính nào trong ei, ef là không chính xác nếu có, cùng với thông tin khác. Chúng tôi cung cấp 50 mẫu ngẫu nhiên để chú thích. Quá trình chú thích chỉ mất mỗi chuyên gia 2-3 giờ. Chúng tôi thấy rằng tỷ lệ lỗi nghiêm trọng quan sát được trong các giải thích trang trọng thấp hơn đáng kể ((≈8% cho các giải thích trang trọng so với ≈56% cho các giải thích không trang trọng), vì vậy chúng tôi chỉ tập trung vào việc áp dụng LLM-critic cho các thuộc tính không trang trọng không chính xác (ei).

Để làm như vậy, chúng tôi khởi tạo một mô hình LLM-Critic bằng cách nhắc một LLM khác (ChatGPT-3.5) với 35 sửa chữa phản hồi chuyên gia con người trong ngữ cảnh (chúng tôi thấy rằng số lượng này dẫn đến tính chính xác thỏa mãn ≈87%, xem Phụ lục C về cách hiệu suất thay đổi theo lượng phản hồi) và yêu cầu nó hoạt động như một người chú thích trên các thể hiện mới để xác định các thuộc tính không chính xác trong chúng (xem prompt trong Bảng 12 trong Phụ lục E). Để giảm thiểu rủi ro tạo ra các thuộc tính không chính xác mới, chúng tôi chỉ truy vấn mô hình để xác định và loại bỏ các thuộc tính không chính xác trong ei, và nếu có, cung cấp một iclef-ei được sửa chữa trong đó chúng được loại bỏ. Chúng tôi gọi mô hình kết quả là LLM-Critic (xem cách abbreviated language được loại bỏ trong Hình 1).

Theo cách này, chúng tôi sửa chữa ≈30% dữ liệu được tạo ra (2853 thể hiện) – tất cả các thể hiện mà critic đã dự đoán rằng cần cải thiện. Dữ liệu kết quả (mà chúng tôi gọi là E-GYAFC) chứa 9.960 si gốc, các thể hiện sf tổng hợp với các giải thích thuộc tính iclef-ei, ef tổng hợp tương ứng. Chúng tôi chia ngẫu nhiên dữ liệu thành 8.000 thể hiện huấn luyện và 1.960 thể hiện kiểm tra được giữ lại.

**E-WNC**
Đối với nhiệm vụ trung hòa thiên kiến chủ quan, chúng tôi thuê một chuyên gia chú thích có bằng Tiến sĩ ngôn ngữ học trên Upwork. Chúng tôi cung cấp 50 mẫu ngẫu nhiên đảm bảo đại diện bình đẳng cho mỗi loại thiên kiến. Để chống lại các thiên kiến chú thích tiềm tàng, chúng tôi quyết định sử dụng hai người chú thích, một trong số các tác giả hoạt động như người chú thích bổ sung, và sau đó lấy mẫu ngẫu nhiên các thể hiện theo tỷ lệ bằng nhau. Giao thức chú thích yêu cầu cung cấp một giải thích được sửa chữa thay vì eb nếu giải thích tổng hợp chứa một loại thiên kiến không chính xác hoặc lý giải sai. Chúng tôi lấy mẫu ngẫu nhiên 35 thể hiện riêng biệt từ phản hồi của hai người chú thích, thấy rằng số lượng này dẫn đến tính chính xác thỏa mãn ≈93% (xem Phụ lục C). Chúng tôi cung cấp các phê bình chuyên gia trong ngữ cảnh theo cách tương tự như E-GYAFC (xem prompt dưới cùng trong Phụ lục E, Bảng 12). Vì các thuộc tính thiên kiến mới có thể đã được giới thiệu, chúng tôi tái tạo cách diễn đạt sn cho giải thích mới (xem loại thiên kiến được sửa chữa và một cách diễn đạt mới trong Hình 2). Chúng tôi sửa chữa 8% các giải thích tổng hợp theo cách này (tỷ lệ lỗi thấp hơn được giải thích bởi chất lượng cao hơn của các tạo sinh ban đầu do sử dụng mô hình ChatGPT-4 mạnh mẽ hơn). Tập dữ liệu kết quả (E-WNC) chứa 3.000 câu thiên kiến sb gốc WNC, các giải thích thiên kiến iclef-eb, cũng như các câu được trung hòa iclef-sn tương ứng. Chúng tôi chia ngẫu nhiên dữ liệu thành 2.500 thể hiện huấn luyện và 500 thể hiện kiểm tra được giữ lại.

[Bảng 1: So sánh định tính của các thể hiện tập dữ liệu trước và sau khi áp dụng ICLEF]

### 3.3 Chất lượng tập dữ liệu

**Đánh giá tự động về chất lượng diễn đạt**
Chúng tôi ước tính chất lượng diễn đạt tự động bằng cách sử dụng Mutual Implication Score (MIS) (Babakov et al., 2022) và Formality Score (xem §4.2 để biết chi tiết về chỉ số) giữa các cách diễn đạt trang trọng của chúng tôi và những cái trong GYAFC. Chúng tôi thấy rằng các cách diễn đạt của chúng tôi có chất lượng tương đương với MIS là 81.30 so với 83.08 cho GYAFC, tuy nhiên chúng tôi đạt được điểm trang trọng cao hơn là 98.43 so với 89.39 cho GYAFC (xem Bảng 2). Ví dụ, đối với ví dụ GYAFC trong Hình 1, cách diễn đạt trang trọng chứa kick them out). Tương tự, đối với tập dữ liệu E-WNC, chúng tôi báo cáo điểm thiên kiến từ một bộ phân loại có sẵn (xem §4.2) cùng với MIS. Điểm MIS là 79.32 cho các cách diễn đạt gốc so với 85.58 cho các cách diễn đạt của chúng tôi, cho thấy độ tương tự ngữ nghĩa cao hơn. Điểm trung tính là 69.34 so với 72.64, cho thấy tính trung tính cao hơn của các cách diễn đạt của chúng tôi (xem Bảng 2).

[Bảng 2 và 3: Kết quả đánh giá tự động và con người]

**Đánh giá con người**
Đối với E-GYAFC, chúng tôi thuê 3 chuyên gia chú thích, 2 trong số đó đã thực hiện chú thích, cũng như một chuyên gia chú thích độc lập có bằng thạc sĩ ngôn ngữ học. Chúng tôi hỏi sở thích của họ về 100 thể hiện được lấy mẫu ngẫu nhiên liên quan đến các giải thích (ei tổng hợp so với iclef-ei) và các cách diễn đạt (sf gốc trong GYAFC so với sf tổng hợp trong E-GYAFC). Ngoài ra, chúng tôi yêu cầu các phán đoán chấp nhận (liệu cách diễn đạt hoặc giải thích có chính xác và đầy đủ không) cho cách diễn đạt được ưa thích và riêng biệt cho ef. Chúng tôi báo cáo tỷ lệ ưa thích hoặc bằng nhau và tỷ lệ chấp nhận.⁴ Nhìn chung, chúng tôi thấy rằng các thể hiện tập dữ liệu của chúng tôi được coi là chấp nhận được, với tỷ lệ chấp nhận trung bình cho ei, sf, ef lần lượt là 87%, 77%, 98% (hàng 1 trong Bảng 3). Các cách diễn đạt tổng hợp thường được ưa thích hơn so với những cái trong corpus GYAFC (trung bình 77%), và các giải thích iclef được ưa thích hoặc có chất lượng bằng nhau với các tạo sinh gốc trung bình trong 90% các trường hợp (hàng 2 trong Bảng 3). Chúng tôi tính toán độ chính xác theo cặp giữa các phản hồi của người chú thích cho tất cả các danh mục đánh giá E-GYAFC, và thấy rằng nó trung bình ở 81% trên tất cả các danh mục. Chúng tôi cung cấp thêm chi tiết trong Phụ lục A. Bảng 1 cho thấy các ví dụ định tính về các chỉnh sửa thành công với ICLEF. Hình 3 cho thấy 10 thuộc tính không trang trọng thường xuyên nhất.

Đối với E-WNC, chúng tôi thuê 2 người chú thích, một trong số đó đã thực hiện chú thích ICLEF. Để đánh giá có ý nghĩa sở thích của các giải thích iclef so với các giải thích tổng hợp, chúng tôi yêu cầu cung cấp phản hồi về 50 thể hiện mà giải thích đã được cập nhật. Sở thích trung bình cho iclef-eb so với eb tổng hợp là 78%. Tỷ lệ chấp nhận trung bình của iclef-eb là 73%. Sở thích trung bình cho sn tổng hợp so với câu trung tính trong corpus E-WNC là 76%. Tỷ lệ chấp nhận trung bình của sn tổng hợp là 74%. Độ chính xác theo cặp giữa các người chú thích là 77%. Thêm chi tiết có thể được tìm thấy trong Phụ lục B.

## 4 Đánh giá Mô hình Học sinh và Giáo viên trên Nhiệm vụ Chuyển đổi Phong cách Có thể Giải thích

Chúng tôi tập trung vào việc đánh giá hiệu suất của các mô hình ngôn ngữ lớn được chọn trên nhiệm vụ chuyển đổi phong cách có thể giải thích. Chúng tôi không đánh giá các hệ thống lý do hậu hoc (tạo thuộc tính cho cặp diễn đạt), vì các mô hình pipeline như vậy ít có khả năng phản ánh các lý do cơ bản cho dự đoán mô hình, trong khi các mô hình dự đoán và lý giải cùng nhau thể hiện các tính chất mong muốn cho các giải thích trung thực (Wiegreffe et al., 2021). Đối với chuyển đổi phong cách trang trọng có thể giải thích, chúng tôi kiểm tra việc tạo ra ef, si, ei cho sf (Trang trọng → Không trang trọng) và ei, sf, ef cho si (Không trang trọng → Trang trọng) trên một tập kiểm tra được giữ lại từ E-GYAFC. Chúng tôi đánh giá mức độ gần gũi của ei, ef do mô hình tạo ra khớp với các giải thích E-GYAFC, và chúng tôi đánh giá sự gần gũi ngữ nghĩa và chất lượng diễn đạt cho si, sf với các chỉ số không tham chiếu. Tương tự, chúng tôi đánh giá eb, sn cho nhiệm vụ trung hòa thiên kiến chủ quan bằng cách sử dụng một tập kiểm tra từ E-WNC. Chúng tôi báo cáo điểm F1 cho phân loại thiên kiến trong sn.

### 4.1 Mô hình

Chúng tôi kiểm tra hai mô hình học sinh nhỏ hơn được tinh chỉnh trên các tập dữ liệu của chúng tôi. Chúng tôi tinh chỉnh các mô hình LLaMA-7B (Touvron et al., 2023) và Alpaca-7B (Taori et al., 2023) trên dữ liệu của chúng tôi được chuyển đổi sang định dạng hướng dẫn Alpaca. Đối với chuyển đổi phong cách trang trọng, chúng tôi tinh chỉnh theo cả hai hướng Trang trọng → Không trang trọng và Không trang trọng → Trang trọng riêng biệt (→), cũng như theo cả hai hướng theo cách đa nhiệm vụ (↔). Đối với chuyển đổi thiên kiến chủ quan, chúng tôi chỉ tinh chỉnh theo một hướng. Ngoài ra, chúng tôi kiểm tra các mô hình giáo viên (ChatGPT-3.5=GPT-3.5 và ChatGPT-4=GPT-4) trong cài đặt vài lần, đây là một đường cơ sở đầy tham vọng: đầu tiên, chúng đã được sử dụng để tạo dữ liệu điều này thiên vị các chỉ số dựa trên tham chiếu, thứ hai, chúng được nhắc với các thể hiện được cải thiện của dữ liệu. Vì các mô hình giáo viên là các mô hình đóng, chúng tôi cũng kiểm tra một mô hình được điều chỉnh hướng dẫn mở đại diện lớn hơn học sinh, Vicuna-13B (Chiang et al., 2023) (Vic trong bảng), trong cài đặt vài lần. Xem mô tả chi tiết về các mô hình, siêu tham số, prompt, và các thí nghiệm bổ sung trong Phụ lục F.

### 4.2 Đánh giá Tự động

Chúng tôi sử dụng các chỉ số sau:

• **BLEU** (Papineni et al., 2002): Chúng tôi đo lượng các thuộc tính và bằng chứng trang trọng và không trang trọng khớp chính xác giữa giải thích có cấu trúc được tạo ra và giải thích tham chiếu trong E-GYAFC và E-WNC.

• **Mutual Implication Score (MIS)** (Babakov et al., 2022) là một thước đo đối xứng về độ tương tự ngữ nghĩa văn bản dựa trên một mô hình RoBERTa (Liu et al., 2019) được tinh chỉnh cho suy luận ngôn ngữ tự nhiên và phát hiện diễn đạt được sử dụng trong công việc trước đây (ví dụ: Patel et al., 2022).

• **Độ chính xác Phong cách**: Đối với E-GYAFC, chúng tôi sử dụng Điểm Trang trọng/Không trang trọng⁵: RoBERTa (Liu et al., 2019) được tinh chỉnh để dự đoán liệu các câu có trang trọng hay không trang trọng bằng cách sử dụng GYAFC và Online Formality Corpus (OFC) (Pavlick và Tetreault, 2016). Nó đạt đến 0.98 ROC AUC. Đối với E-WNC, chúng tôi sử dụng Điểm Thiên kiến⁶: mô hình DistilBERT (Sanh et al., 2020) được tinh chỉnh cho phân loại thiên kiến trên tập dữ liệu thiên kiến truyền thông BABE được chú thích bởi các chuyên gia (Spinde et al., 2021), trên đó nó đạt được điểm F1 lên đến 79.

Cho rằng nhiệm vụ phát hiện loại thiên kiến có thể được xem như một nhiệm vụ phân loại (chỉ có 3 nhãn hiện diện), chúng tôi báo cáo điểm F1 cho phân loại loại thiên kiến trong giải thích. Chúng tôi cũng báo cáo trung bình trên tất cả các chỉ số.

**Kết quả**
Bảng 4 cho thấy hiệu suất mô hình trên nhiệm vụ chuyển đổi phong cách trang trọng có thể giải thích. Trong khi mô hình Vicuna làm tốt về mặt chuyển đổi phong cách (như được chứng minh bởi điểm MIS và Formality cao), nó thiếu về chất lượng giải thích (điểm BLEU thấp tổng thể). Các mô hình học sinh thực hiện tốt hơn mô hình giáo viên một lần và cạnh tranh trong kịch bản 10 lần xét theo điểm Trung bình. Bảng 5 cho thấy hiệu suất mô hình trên nhiệm vụ chuyển đổi phong cách thiên kiến chủ quan có thể giải thích. Tương tự, các mô hình học sinh vượt trội hơn mô hình giáo viên trong cài đặt một lần. Chúng cũng vượt trội hơn các mô hình vài lần yếu hơn mô hình giáo viên (Vicuna và GPT-3.5).

Về hiệu suất chuyển đổi phong cách mà không xem xét các giải thích, chúng tôi thấy một sự giảm nhẹ trong các nhiệm vụ Không trang trọng → Trang trọng (-0.93% avg. MIS và Formality so với giáo viên một lần) và Thiên kiến → Không thiên kiến (-2.13% avg. MIS và Neutrality). Điều này được mong đợi vì phù hợp với công việc trước đây như e-SNLI (Camburu et al., 2018).⁷ Chúng tôi thấy một sự tăng đáng kể về hiệu suất cho hướng Trang trọng → Không trang trọng (+12.60%). Điểm không trang trọng tốt hơn nhiều cho các mô hình học sinh, có thể do xu hướng tạo ra lời nói trang trọng hơn của cả mô hình giáo viên và các mô hình hướng dẫn khác.

[Bảng 4 và 5: Kết quả hiệu suất]

### 4.3 Đánh giá Chuyên gia Con người: Phán đoán Sở thích

Chúng tôi đánh giá mức độ phù hợp của các đầu ra mô hình với sở thích chuyên gia. Đối với e-GYAFC, chúng tôi lấy mẫu 100 thể hiện từ tập kiểm tra và các đầu ra mô hình tương ứng từ Vic 1, mô hình giáo viên GPT-3.5 trong cài đặt một lần (GPT-3.5 1), và mô hình học sinh được tinh chỉnh tốt nhất. Chúng tôi hỏi sở thích của họ về tính chính xác và đầy đủ của các giải thích, cũng như về việc bảo tồn ngữ nghĩa diễn đạt. Chúng tôi thấy rằng các tạo sinh mô hình học sinh (Alpaca ↔) được ưa thích hơn mô hình giáo viên GPT-3.5 1 và Vicuna 1 53% thời gian bởi chuyên gia ngôn ngữ học (GPT-3.5 1 được ưa thích 42%), cho thấy mô hình học sinh phù hợp hơn với sở thích chuyên gia. Xem ví dụ định tính trong Bảng 6. Chúng tôi cũng đánh giá mức độ thực hiện tốt của các mô hình được tinh chỉnh nhỏ hơn so với mô hình giáo viên trong cài đặt vài lần. Chúng tôi lấy mẫu 40 đầu ra và hỏi sở thích giữa các tạo sinh từ Vicuna và GPT-3.5 trong cài đặt 10 lần (GPT-3.5 10) cũng như mô hình học sinh được tinh chỉnh. Mô hình được tinh chỉnh thực hiện cạnh tranh với 49% sở thích cho GPT-3.5 10 và 43% sở thích cho mô hình học sinh được tinh chỉnh nhỏ.

Tương tự, chúng tôi thuê một chuyên gia chú thích và cung cấp 50 thể hiện tập kiểm tra từ E-WNC cùng với các đầu ra mô hình từ GPT-3.5 10 (yếu hơn mô hình giáo viên), Vicuna 10 lần, và mô hình học sinh được tinh chỉnh tốt nhất (LLaMA →). Chúng tôi thấy rằng LLaMA → được ưa thích với tỷ lệ 56%, theo sau là GPT-3.5 10 (24%). Xem ví dụ định tính trong Bảng 7. Chúng tôi cũng đo sở thích đối với mô hình giáo viên một lần (GPT-4 1), thấy sở thích tương đương 42% cho LLaMA → và 40% cho GPT-4 1.

[Bảng 6 và 7: Ví dụ so sánh]

## 5 Đánh giá Bên ngoài của Giải thích Chuyển đổi Phong cách Trang trọng

Chúng tôi sử dụng Xác minh Tác giả (Martindale và McKenzie, 1995; Coulthard, 2004; Neal et al., 2017) như một nhiệm vụ bên ngoài sử dụng dữ liệu PAN 2022 (Bevendorff et al., 2022). Đây là một nhiệm vụ phân loại nhị phân quyết định xem hai văn bản có thuộc về cùng một tác giả hay không. Hai văn bản đầu vào là hai tài liệu thô (ví dụ: đoạn văn từ bài đăng blog), một trong số đó được viết bởi tác giả A, và một cái khác được viết bởi cùng tác giả A hoặc bởi một tác giả khác B. Sau đó chúng tôi rút ra một biểu diễn (các đặc trưng được sử dụng cho phân loại) của các văn bản đầu vào này bằng cách sử dụng mô hình chuyển đổi phong cách có thể giải thích của chúng tôi. Chúng tôi chạy Alpaca IF→F trên mỗi văn bản (tối đa 15 câu mỗi tác giả được xem xét) và trích xuất các giải thích chứa các thuộc tính không trang trọng và bằng chứng (xem Bảng 8). Trong một đánh giá sơ bộ về tính hữu dụng của những đặc trưng này, chúng tôi tính toán sự tương tự giữa các tác giả bằng cách đo tỷ lệ phần trăm các thuộc tính chồng lấp. Lưu ý rằng các đoạn bằng chứng tương ứng với các thuộc tính không được sử dụng trong thí nghiệm sơ bộ này. Sau đó chúng tôi sử dụng tỷ lệ phần trăm các thuộc tính chồng lấp như một điểm phân loại, ví dụ, nếu tác giả A sử dụng colloquialism và textese, và tác giả B sử dụng colloquialism và abbreviation, điểm tương tự của họ là số thuộc tính chung chia cho số thuộc tính duy nhất giữa các tác giả, hoặc 1/3 (0.33). Ở đây, chỉ có 1 thuộc tính chung (colloquialism) trong khi tổng số thuộc tính được xác định là 3 (colloquialism, abbreviation, textese). Theo tính toán được mô tả ở trên, chúng tôi lấy điểm tương tự như một độ tin cậy cho một nhiệm vụ dự đoán nhị phân. Nếu sự tương tự cao, có khả năng cao các tác giả giống nhau (dự đoán = 1), và nếu không họ có khả năng không giống nhau (dự đoán = 0). Giả định cơ bản là có khả năng cao hơn rằng cùng một tác giả sẽ sử dụng một số đặc trưng không trang trọng mà họ đã sử dụng trước đây (không phải mọi câu trong PAN đều hoàn toàn không trang trọng, nhưng sự không trang trọng là một danh mục rất rộng, vì vậy khi các tác giả sử dụng một số thuộc tính không trang trọng chúng có thể cung cấp một tín hiệu cho tác giả). Chúng tôi tính toán ROC AUC giữa điểm độ tin cậy (điểm tương tự tác giả) và dự đoán sự thật cơ sở từ tập dữ liệu PAN (1 nếu các tác giả giống nhau và 0 nếu không). Chúng tôi so sánh các giải thích từ Vicuna 10, GPT-3.5 10 và Alpaca IF→F bằng tín hiệu dự đoán của chúng cho nhiệm vụ này. Các giải thích bởi Alpaca IF→F đạt được AUC là 56.4, trong khi các giải thích từ các mô hình Vicuna và GPT-3.5 đạt được điểm 50.0 và 47.0 tương ứng. Điều này cho thấy một ứng dụng tiềm năng của các giải thích được tạo ra bởi mô hình học sinh được tinh chỉnh trên tập dữ liệu của chúng tôi (E-GYAFC) để được sử dụng như các đặc trưng tác giả có thể giải thích có thể được khám phá trong công việc tương lai.

[Bảng 8: Đặc trưng không trang trọng cho nhận dạng tác giả]

## 6 Kết luận

Chúng tôi đề xuất một khung để bổ sung hai tập dữ liệu chuyển đổi phong cách với các giải thích bằng văn bản bán cấu trúc. Để cải thiện chất lượng chưng cất mô hình và kết hợp phản hồi chuyên gia, chúng tôi đề xuất ICLEF (Học Theo Ngữ Cảnh từ Phản Hồi Chuyên Gia), một khung hợp tác người-AI mới tận dụng cả khả năng học theo ngữ cảnh và tự phê bình của LLM. Chúng tôi đánh giá các mô hình học sinh nhỏ hơn được tinh chỉnh trên các tập dữ liệu kết quả so với các mô hình giáo viên lớn và tiến hành đánh giá chuyên gia con người. Chúng tôi cũng đánh giá bên ngoài các giải thích cho chuyển đổi phong cách trang trọng trên nhiệm vụ xuôi dòng của phân biệt tác giả.

## 7 Hạn chế

Tập dữ liệu GYAFC không chứa tất cả các loại ngôn ngữ không trang trọng và trang trọng, cụ thể là chúng chủ yếu tập trung vào các mối quan hệ giữa các cá nhân (tập con được sử dụng cho bài báo này) và giải trí. Công việc tương lai có thể xem xét mở rộng phương pháp của chúng tôi cho các tập dữ liệu chuyển đổi phong cách khác, bao gồm những cái bao quát hơn về tính trang trọng.

Trong khi các phương pháp của chúng tôi được dự định để tạo ra các giải thích trung thực, vẫn có thể có các trường hợp khi một mô hình không dựa vào các thuộc tính để hoàn thành cách diễn đạt. Chúng tôi cũng quan sát thấy rằng các ảo tưởng vẫn có thể hiện diện trong các giải thích của mô hình được tinh chỉnh của chúng tôi và hy vọng rằng công việc tương lai sẽ cố gắng giải quyết những vấn đề này. Chúng tôi cũng lưu ý rằng phương pháp của chúng tôi không thay thế chú thích chuyên gia vì nó phụ thuộc nhiều vào LLM có thể vẫn ảo tưởng. Nó chỉ được dự định áp dụng trong các kịch bản mà phản hồi chuyên gia đắt đỏ và/hoặc khó thu thập.

Một hạn chế của phương pháp chúng tôi là chúng tôi đã sử dụng một số lượng tương đối nhỏ các chuyên gia để tiến hành nghiên cứu của mình. Tuy nhiên, chúng tôi tin rằng cài đặt này phản ánh các điều kiện thực tế nơi các chuyên gia thường hiếm khi có sẵn. Chúng tôi hy vọng phương pháp của chúng tôi cung cấp một khung tổng quát hơn để kết hợp phản hồi chuyên gia có thể được điều chỉnh theo nhu cầu của các chuyên gia (ví dụ: một nhà ngôn ngữ học pháp y có thể yêu cầu một giải thích chuyển đổi phong cách khác với một nhà phê bình văn học).

Tinh chỉnh và chạy suy luận trên các mô hình lớn đòi hỏi tài nguyên tính toán đắt đỏ. Tuy nhiên, chúng tôi hy vọng rằng nghiên cứu của chúng tôi trình bày một lập luận thuyết phục rằng tinh chỉnh một mô hình nhỏ hơn một lần có thể hiệu quả và chính xác hơn việc chạy một mô hình đa năng lớn với các prompt ngữ cảnh dài phức tạp.

## 8 Tuyên bố Đạo đức

Corpus GYAFC được tạo ra bằng cách sử dụng corpus Yahoo Answers: L6 - Yahoo! Answers Comprehensive Questions and Answers phiên bản 1.0. Corpus Yahoo Answers này có thể được yêu cầu miễn phí cho mục đích nghiên cứu. Truy cập vào tập dữ liệu GYAFC của chúng tôi sẽ yêu cầu người dùng trước tiên có quyền truy cập vào corpus Yahoo Answers này. Các tác giả đã được phép truy cập tập dữ liệu.

Các tập dữ liệu của chúng tôi không bao gồm bất kỳ dữ liệu được bảo vệ nào theo hiểu biết tốt nhất của chúng tôi. Tất cả người chú thích được bồi thường công bằng cho công việc của họ phù hợp với mức giá yêu cầu của họ (thường trên 20 USD mỗi giờ).

Mô hình chuyển đổi thiên kiến của chúng tôi chỉ được dự định sử dụng theo cách có con người trong vòng lặp chứ không phải tự nó để phán xét thiên kiến trong văn bản. Chúng tôi hy vọng rằng khả năng tạo giải thích của mô hình chúng tôi sẽ cải thiện các bộ phân loại thiên kiến hiện có thường không cung cấp các giải thích bằng văn bản. Trong Phụ lục G, chúng tôi chỉ ra cách chuyển đổi phong cách có thể được sử dụng để trốn tránh các bộ phát hiện văn bản AI. Tương tự như Krishna et al. (2023), chúng tôi nhắc lại rằng điều này không phải để cung cấp một cách tấn công các hệ thống như vậy, mà để mang lại nhận thức cho cộng đồng rằng các bộ phát hiện hiện tại dễ bị trốn tránh. Hơn nữa, chúng tôi đưa ra sự chú ý đến vấn đề phát hiện văn bản mà chuyển đổi phong cách diễn đạt đã được áp dụng. Chúng tôi hy vọng rằng công việc tương lai phát triển các hệ thống có khả năng bảo vệ chống lại các cuộc tấn công như vậy, có thể sử dụng các giải thích được tạo ra bởi hệ thống của chúng tôi.

GYAFC và WNC có thể tiềm ẩn chứa dữ liệu xúc phạm vì chúng được cộng đồng tạo ra, tuy nhiên, trên các mẫu mà chúng tôi thấy, chúng tôi không tìm thấy các vấn đề đạo đức đáng báo động.

## Lời cảm ơn

Chúng tôi cảm ơn các người chú thích cho công việc của họ và việc cung cấp phản hồi chi tiết. Chúng tôi cũng muốn cảm ơn các nhà phê bình cho các cuộc thảo luận sản xuất và hấp dẫn. Nghiên cứu này được hỗ trợ một phần bởi Văn phòng Giám đốc Tình báo Quốc gia (ODNI), Hoạt động Nghiên cứu Tiên tiến Tình báo (IARPA), thông qua hợp đồng Chương trình HIATUS #2022-22072200005. Các quan điểm và kết luận chứa trong đây là của các tác giả và không nên được hiểu là nhất thiết đại diện cho các chính sách chính thức, được thể hiện hoặc ngụ ý, của ODNI, IARPA, hoặc Chính phủ Hoa Kỳ. Chính phủ Hoa Kỳ được ủy quyền tái tạo và phân phối các bản in lại cho mục đích chính phủ bất chấp bất kỳ chú thích bản quyền nào trong đó.

[Phần tài liệu tham khảo và các phụ lục được giữ nguyên do độ dài - bao gồm tất cả các tài liệu tham khảo từ trang 10-23]

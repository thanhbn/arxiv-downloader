# 2306.04349.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/annotation/2306.04349.pdf
# Kích thước file: 4077995 bytes

===============================================
NỘI DUNG FILE PDF
===============================================


--- TRANG 1 ---
GPT Tự giám sát cho một Người chú thích dữ liệu tốt hơn
Xiaohuan Pei, Yanxi Li, Chang Xu
Trường Khoa học Máy tính, Khoa Kỹ thuật
Đại học Sydney
xpei8318@uni.sydney.edu.au, yali0722@uni.sydney.edu.au, c.xu@sydney.edu.au
Tóm tắt
Nhiệm vụ chú thích dữ liệu thành các bản tóm tắt ngắn gọn đặt ra một thách thức đáng kể
trên nhiều lĩnh vực khác nhau, thường yêu cầu phân bổ thời gian đáng kể và
kiến thức chuyên môn của các chuyên gia con người. Bất chấp những nỗ lực hiện có để sử dụng các
mô hình ngôn ngữ lớn cho các nhiệm vụ chú thích, các vấn đề đáng kể như khả năng áp dụng hạn chế
cho dữ liệu chưa được gán nhãn, việc thiếu các phương pháp tự giám sát, và việc thiếu
tập trung vào dữ liệu có cấu trúc phức tạp vẫn còn tồn tại. Trong công trình này, chúng tôi đề xuất một
phương pháp chú thích tự giám sát GPT, thể hiện một mô hình tạo-phục hồi
tận dụng khả năng học một lần (one-shot learning) của Generative Pretrained Trans-
former (GPT). Phương pháp được đề xuất bao gồm một giai đoạn điều chỉnh một lần được theo sau
bởi một giai đoạn tạo sinh. Trong giai đoạn điều chỉnh một lần, chúng tôi lấy mẫu một dữ liệu từ
tập hỗ trợ như một phần của lời nhắc cho GPT để tạo ra một bản tóm tắt văn bản, sau đó được
sử dụng để phục hồi dữ liệu gốc. Điểm căn chỉnh giữa dữ liệu được phục hồi
và dữ liệu gốc phục vụ như một người dẫn đường tự giám sát để tinh chỉnh quá trình. Trong
giai đoạn tạo sinh, mẫu một lần được chọn tối ưu phục vụ như một mẫu
trong lời nhắc và được áp dụng để tạo ra các bản tóm tắt từ các tập dữ liệu thách thức.
Hiệu suất chú thích được đánh giá bằng cách điều chỉnh một số mạng phần thưởng phản hồi của con người
và bằng cách tính toán điểm căn chỉnh giữa dữ liệu gốc và được phục hồi
ở cả mức câu và mức cấu trúc. Phương pháp chú thích tự giám sát của chúng tôi
liên tục đạt được các điểm cạnh tranh, thuyết phục chứng minh sức mạnh mạnh mẽ của nó
trong các nhiệm vụ chú thích dữ liệu-thành-tóm tắt khác nhau.

1 Giới thiệu
Các mô hình ngôn ngữ lớn được đại diện bởi họ Generative Pre-trained Transformer(GPT) [23, 24, 1]
đã đạt được những tiến bộ đột phá trong những năm gần đây, đạt được hiệu suất tiên tiến
trên nhiều nhiệm vụ học sâu khác nhau. Trong số những nhiệm vụ này, chú thích dữ liệu là
bước đầu tiên cơ bản và không thể thiếu trong quá trình nghiên cứu AI, vì nó đặt nền móng
bằng cách cung cấp dữ liệu được gán nhãn phục vụ như nền tảng cho việc huấn luyện và đánh giá các mô hình
[14,27,2,3]. Chất lượng của việc tạo nhãn dữ liệu trực tiếp tác động đến tất cả các nhiệm vụ tiếp theo,
làm cho nó trở thành nền tảng của toàn bộ quá trình học sâu [12, 21].

Nhiệm vụ chú thích đặt ra những thách thức đáng kể. Thứ nhất, sự phức tạp của dữ liệu làm cho
việc các chuyên gia chú thích từng mẫu tốn thời gian [18,28,4,29]. Ví dụ, các đồ thị tính toán
cung cấp những hiểu biết có giá trị về thiết kế của các cấu trúc mạng nơ-ron và việc chú thích những
ô này yêu cầu nỗ lực đáng kể để xác định và tóm tắt các chuỗi con tương tự như các khối song song
[8], điều này gần như không thể xác định và tách biệt. Thứ hai, việc sử dụng độc quyền các bản tóm tắt
được chú thích bởi con người mang tính chủ quan đặt ra những thách thức đánh giá [5,1]. Việc sử dụng
những bản tóm tắt chủ quan này như các nhãn học có giám sát có thể dẫn đến các nhiệm vụ chú thích
phản ánh thành kiến của con người, không phải sự tương quan công bằng giữa dữ liệu và bản tóm tắt của nó.

Nghiên cứu gần đây đã khai thác khả năng của các mô hình ngôn ngữ lớn cho việc chú thích dữ liệu có giám sát.
Như được tiết lộ bởi [7,11,30], các mô hình GPT có thể chú thích các nhiệm vụ phân loại thông qua việc thiết kế trực tiếp
Preprint. Under review.arXiv:2306.04349v2  [cs.CL]  8 Jun 2023

--- TRANG 2 ---
của các lời nhắc đa dạng. Hơn nữa, nghiên cứu của [13] mở rộng phạm vi của nhiệm vụ chú thích này,
cho phép tạo ra các cuộc đối thoại. Bất chấp tiến bộ ấn tượng, các vấn đề của nhiệm vụ chú thích
vẫn còn tồn tại. Thứ nhất, các nghiên cứu hiện tại chủ yếu tập trung vào chú thích có giám sát với
dữ liệu được gán nhãn bởi con người, điều này hạn chế khả năng áp dụng của phương pháp chú thích
cho dữ liệu chưa được gán nhãn tổng quát hơn. Trong hầu hết các tình huống, dữ liệu được gán nhãn
bởi con người không có sẵn để hướng dẫn quá trình chú thích. Thứ hai, nghiên cứu trước đây đã
bị hạn chế trong việc thiết kế các lời nhắc khác nhau, mà không xem xét các cơ chế phản hồi
để tinh chỉnh các phần cụ thể của lời nhắc. Thứ ba, thiếu nghiên cứu tập trung vào việc chú thích
dữ liệu có cấu trúc phức tạp. Công việc hiện tại chỉ tập trung vào việc chú thích các mẫu mô tả
ngôn ngữ tự nhiên đơn giản mà không thách thức dữ liệu có cấu trúc phức tạp hơn. Ví dụ, các
tập dữ liệu của đồ thị tính toán được trích xuất bởi các mạng nơ-ron bao gồm các cấu trúc lồng nhau
khác nhau, làm cho việc con người chú thích các khối cụ thể trong những danh sách cạnh phức tạp như vậy trở nên khó khăn.

Mô hình Ngôn ngữ Lớn Mẫu(Dữ liệu) Cập nhật Trọng số Cập nhật Dữ liệu như một Mẫu Mới
Dữ liệu+

Hình 1: Mô hình tạo-phục hồi dựa trên dữ liệu làm trung tâm. Cập nhật lặp lại mẫu với dữ liệu được tạo. xi được lấy mẫu từ một tập hỗ trợ ứng viên và si được tạo bởi GPT. Ở đây chúng tôi đề xuất một phương pháp tự giám sát GPT thông qua một vòng lặp tạo-phục hồi, chủ yếu được lấy cảm hứng từ điều chỉnh lời nhắc [15,16] và mô hình lấy dữ liệu làm trung tâm [22], như được nêu trong Hình 1. Khung của phương pháp tự giám sát chứa giai đoạn một lần và giai đoạn tạo sinh. Giai đoạn một lần nhằm mục đích tìm lặp lại các cặp tối ưu của dữ liệu và bản tóm tắt như mẫu. Bắt đầu với một cặp dữ liệu được chú thích bởi con người, quá trình lặp lại của chúng tôi sử dụng GPT để tạo ra các bản tóm tắt. Bản tóm tắt được tạo và dữ liệu thô tạo thành một cặp dữ liệu mới. Cặp dữ liệu mới này sau đó được đánh giá về tiềm năng của nó như một mẫu thông qua so sánh dữ liệu được phục hồi từ bản tóm tắt với dữ liệu gốc. Nếu cả điểm hỗ trợ và xác thực đều cải thiện, chúng tôi cập nhật mẫu tối ưu với cặp dữ liệu mới hiện tại. Do đó, cơ chế tự căn chỉnh lặp lại điều chỉnh mẫu một lần cho vòng tạo sinh tiếp theo. Mẫu tối ưu được tìm kiếm sau đó được sử dụng để tạo ra các bản tóm tắt trong giai đoạn tạo sinh. Chúng tôi điều chỉnh các mô hình phần thưởng khác nhau để đánh giá chất lượng bản tóm tắt và giới thiệu các số liệu tương tự khác nhau để đánh giá khả năng phục hồi. Chúng tôi thực hiện các thí nghiệm đầy đủ trên ba tập dữ liệu thách thức và tiến hành nghiên cứu loại bỏ chi tiết từ nhiều góc độ khác nhau. Các kết quả chứng minh mô hình tự giám sát của chúng tôi liên tục mang lại hiệu suất cạnh tranh được đánh giá bởi các mô hình phần thưởng và điểm phục hồi. Ngoài ra, chúng tôi áp dụng phương pháp tự giám sát của mình để tạo ra hai tập dữ liệu mới gồm 3k/15k bản tóm tắt của các kiến trúc mạng nơ-ron dựa trên các toán tử tính toán khác nhau.

2 Công trình liên quan
Mô hình Ngôn ngữ Lớn. GPT-1 [23] đề xuất một phương pháp hai bước: tiền huấn luyện trên văn bản chưa được gán nhãn và điều chỉnh phân biệt trên các nhiệm vụ cụ thể. Không giống như các phương pháp trước đây, nó sử dụng các phép biến đổi đầu vào nhận biết nhiệm vụ trong quá trình điều chỉnh, giảm thiểu các thay đổi đối với kiến trúc mô hình. GPT-2 [24] chứng minh các mô hình ngôn ngữ có thể thực hiện các nhiệm vụ xuôi dòng trong một cài đặt zero-shot – mà không có bất kỳ sửa đổi tham số hoặc kiến trúc nào. GPT-3 [1] mở rộng quy mô các mô hình ngôn ngữ để cải thiện khả năng của chúng với việc điều chỉnh tối thiểu và đạt được hiệu suất few-shot mạnh mẽ mà không cần cập nhật gradient hoặc điều chỉnh cụ thể cho nhiệm vụ.

Học Một/Ít lần. Học các khái niệm mới một cách nhanh chóng với dữ liệu hạn chế là một thách thức trong học máy. Học sâu có giám sát truyền thống không hiệu quả cho điều này. Li et al. [9] sử dụng mô hình Bayesian và cho thấy có thể học được nhiều về một danh mục chỉ từ một hoặc vài hình ảnh bằng cách tận dụng kiến thức từ các danh mục đã học trước đó, bất kể sự khác biệt của chúng. Vinyals et al.[26] định nghĩa các vấn đề học một lần và kết hợp học số liệu và mạng nơ-ron với bộ nhớ bên ngoài để tạo ra một khung có thể học các khái niệm mới chỉ từ vài ví dụ. Khung này không yêu cầu điều chỉnh và được thử nghiệm trên các nhiệm vụ thị giác và ngôn ngữ. Như đã đề cập ở trên, GPT-3 [1] là một người học few-shot mạnh mẽ, thể hiện hiệu suất đáng chú ý trên nhiều nhiệm vụ xử lý ngôn ngữ tự nhiên khác nhau, bao gồm dịch thuật, hỏi-đáp, và các nhiệm vụ cloze, mà không cần điều chỉnh hoặc cập nhật gradient.

2

--- TRANG 3 ---
Mẫu:
Dữ liệu = {"INPUT ->conv3, conv3-
>bn,bn->avgpool3, avgpool3-
>avgpool3, avgpool3->OUTPUT ,
INPUT ->OUTPUT"}
Tóm tắt = Kiến trúc mạng nơ-ron
bao gồm một lớp đầu vào
theo sau bởi 2 khối và 1 kết nối
bỏ qua, trong đó mỗi khối có ......
- "->' biểu diễn cạnh.
- 'bn' là chuẩn hóa batch.
- 'avgpool-n' là pooling trung bình.
- 'maxpool-n' là max pooling.
- 'sepconv-n' là convolution tách biệt.
- 'dilconv-n' là convolution giãn.
- 'skipconnect" là kết nối bỏ qua.
......
định dạng trả về là {Tóm tắt: }Hướng dẫn:
Dữ liệu Tóm tắt

Mẫu:
Tóm tắt = Kiến trúc mạng nơ-ron
bao gồm một lớp đầu vào
theo sau bởi 2 khối và 1 kết nối
bỏ qua, trong đó mỗi khối có ......
Dữ liệu = {"INPUT ->conv3, conv3-
>bn,bn->avgpool3, avgpool3-
>avgpool3, avgpool3->OUTPUT ,
INPUT ->OUTPUT"}
- "->' biểu diễn cạnh.
- 'bn' là chuẩn hóa batch.
- 'avgpool-n' là pooling trung bình.
- 'maxpool-n' là max pooling.
- 'sepconv-n' là convolution tách biệt.
- 'dilconv-n' là convolution giãn.
- 'skipconnect" là kết nối bỏ qua.
......
định dạng trả về là {Dữ liệu được Phục hồi: }Hướng dẫn:
Tóm tắt Dữ liệu được Phục hồi

Dữ liệu Tóm tắt Dữ liệu Dữ liệu được Phục hồi Mẫu:
Dữ liệu

Tóm tắt Dữ liệu Dữ liệu được Phục hồi Tạo sinh
Phục hồi
Tự Giám sát
Dừng Sớm Điểm Căn chỉnh

Hình 2: Chú thích Tự giám sát GPT: Một khung của mô hình tạo-phục hồi,
trong đó hàm mục tiêu tìm cách tối đa hóa điểm căn chỉnh giữa dữ liệu gốc và
dữ liệu được phục hồi.

3 Phương pháp
Phương pháp chú thích dữ liệu của chúng tôi bao gồm giai đoạn điều chỉnh một lần và giai đoạn tạo tóm tắt.

Giai đoạn điều chỉnh một lần. Giai đoạn này chủ yếu chịu trách nhiệm tìm mẫu tối ưu t∗ được tự giám sát bởi GPT. Đây là một quá trình lặp lại của việc tạo ra một bản tóm tắt, phục hồi dữ liệu, và so sánh các giá trị phản hồi để dẫn đường việc điều chỉnh mẫu trong lời nhắc, sau đó được sử dụng cho vòng tạo sinh tiếp theo.

Quá trình lặp lại chứa các bước sau. Chúng tôi đầu tiên khởi tạo một cặp được gán nhãn bởi con người đơn giản gồm dữ liệu x0, tóm tắt s0 như mẫu tốt nhất t∗={x0, s0}, và sau đó tương ứng gán loại vai trò {system, assistant, content} cho hướng dẫn, mẫu, dữ liệu hỗ trợ {w, t, x}. Đối với lần lặp i, chúng tôi lấy mẫu một dữ liệu được hỗ trợ xi từ tập hỗ trợ X, sau đó được nối với mẫu tối ưu hiện tại t∗ và hướng dẫn mặc định wg thành một tin nhắn. GPT F(·) chuyển đổi tin nhắn để tạo ra tóm tắt si bằng cách tham khảo hướng dẫn, mẫu hiện tại và dữ liệu:

si← F (xi|ti, wg, θ), (1)

trong đó θ là các tham số của hàm mô hình ngôn ngữ và wg là hướng dẫn tạo ra một bản tóm tắt. Tại thời điểm này, chúng tôi có được một tập cặp mới bao gồm dữ liệu và tóm tắt, được ký hiệu là {xi, si}, trong đó si được tạo ra từ xi.

Xem xét rằng mục đích chính của một bản tóm tắt là nắm bắt ngắn gọn bản chất của một tập dữ liệu, chất lượng của một bản tóm tắt một cách tự nhiên có thể được suy ra từ khả năng tái tạo trung thực tập dữ liệu gốc. Quá trình phục hồi là tái tạo ˆxi từ si bởi cùng một GPT:

ˆxi← F (si|ti, wr, θ), (2)

trong đó θ là các tham số của mô hình ngôn ngữ lớn và wg là hướng dẫn phục hồi dữ liệu. Và sau đó chúng tôi áp dụng sim(ˆxi, xi) để đo lường điểm tương tự giữa dữ liệu được phục hồi và dữ liệu gốc. Nếu điểm hiện tại vượt qua giá trị cao nhất được ghi lại trước đó từ các lần lặp, chúng tôi xem xét các cặp dữ liệu-tóm tắt hiện tại {xi,si} như một mẫu tạm thời.

Sử dụng cùng quá trình tạo sinh và phục hồi được đề cập trong 1 2, chúng tôi đánh giá điểm tương tự trung bình trên tập xác thực. Nếu điểm này vẫn cao hơn điểm xác thực tối đa được quan sát

3

--- TRANG 4 ---
Thuật toán 1 Chú thích Tự giám sát bởi GPT.
1:Khởi tạo: hướng dẫn wg/wr cho tạo sinh/phục hồi, mẫu một lần tối ưu t∗=
{x0, s0}, điểm tương tự hỗ trợ/xác thực tốt nhất simsup/simval= 0, một tập hỗ trợ Xsup để lấy mẫu mẫu một lần, một tập xác thực Xval để kiểm tra hiệu suất mẫu mới.
2:cho lần lặp i←1 đến I thực hiện
3: (1) Lấy mẫu: xi← Xsup
4: (2) Mã hóa: Gửi tin nhắn < hướng dẫn, mẫu, dữ liệu được lấy mẫu > đến GPT:
5:
si←GPT (⟨wg, t∗, xi⟩)
6: Nhận phản hồi của tóm tắt si
7: (3) Giải mã: Gửi tin nhắn < hướng dẫn, mẫu, tóm tắt được tạo > đến GPT:
8:
ˆxi←GPT (⟨wr, t∗, si⟩)
9: Nhận phản hồi của dữ liệu được phục hồi ˆxi.
10: Tính điểm tương tự giữa dữ liệu được phục hồi và dữ liệu gốc
11:
simsup
i←sim(xi,ˆxi)
12: (4) Cập nhật:
13: nếu simsup
i> simsup thì
14: Tính điểm tương tự trung bình simval
i trên tập xác thực Xval bằng (2)(3).
15: nếu simval
i> simval thì
16: Thay thế điểm tương tự tốt nhất với điểm hiện tại:
simsup←simsup
i;simval←simval
i
17: Cập nhật mẫu tối ưu với dữ liệu hỗ trợ và tóm tắt được tạo:
t∗← {xi, si}
18: kết thúc nếu
19: kết thúc nếu
20:kết thúc cho
21:Đầu ra: Trả về mẫu tốt nhất t∗ cho giai đoạn tạo sinh.

trong các lần lặp trước đó, cơ chế tự giám sát cập nhật mẫu tốt nhất t∗ với các cặp dữ liệu-tóm tắt hiện tại {xi,si}. Quá trình tiếp tục cho đến khi mẫu hiện tại không thể đạt được điểm phục hồi cao hơn so với lần lặp trước đó hoặc khi số lần lặp tối đa được đạt tới. Và mục tiêu tự giám sát của việc cập nhật lặp lại ở trên là tìm mẫu tốt nhất ti tối đa hóa độ tương tự kỳ vọng giữa dữ liệu được phục hồi và dữ liệu gốc. Vấn đề tối ưu hóa có thể được chính thức hóa như sau:

t∗= arg max
tExi∼X[sim(ˆxi, xi)], (3)

trong đó sim(·) là số liệu của hàm tương tự giữa hai dữ liệu chuỗi. Mục tiêu này giả định rằng độ tương tự sim là một thước đo có ý nghĩa về chất lượng của quá trình phục hồi, và rằng các giá trị cao hơn của sim tương ứng với các phục hồi tốt hơn. Và mục tiêu này có một vài yếu tố đáng chú ý hơn giai đoạn học một lần truyền thống. Không giống như phương pháp tự giám sát thông thường nơi trọng số mô hình được cập nhật trong quá trình huấn luyện, kỹ thuật của chúng tôi cập nhật mẫu hiện tại thay thế.

Giai đoạn tạo tóm tắt. Trong giai đoạn này, GPT nối mẫu tối ưu được xác định với hướng dẫn, sử dụng nó như lời nhắc tối ưu để tạo ra các bản tóm tắt ngôn ngữ tự nhiên cho tập dữ liệu tạo sinh:

s← F (x|t∗, wg, θ), (4)

trong đó s là các tóm tắt của tập dữ liệu x. Chúng tôi kiểm tra chất lượng tóm tắt bằng cách điều chỉnh các mạng phần thưởng phản hồi của con người khác nhau, và sau đó chúng tôi giới thiệu đánh giá phục hồi nhằm đo lường liệu bản tóm tắt có thể giải mã các câu cấp cao trở lại dữ liệu gốc hay không. Cụ thể, chúng tôi giả định rằng khả năng phục hồi bản tóm tắt trung gian trở lại dữ liệu gốc càng mạnh, nó càng chứng thực tính chuyên nghiệp và độ chính xác của các tóm tắt. Ngược lại, khả năng phục hồi yếu hơn ngụ ý mức độ chuyên nghiệp và độ chính xác thấp hơn trong các tóm tắt.

4

--- TRANG 5 ---
Giai đoạn đánh giá của quá trình này có hai mặt. Thứ nhất, chúng tôi đánh giá chất lượng của bản tóm tắt bằng cách sử dụng nhiều mạng phần thưởng phản hồi của con người khác nhau cung cấp cho chúng tôi một cái nhìn sâu sắc toàn diện về khả năng áp dụng và dễ hiểu trong thế giới thực của các bản tóm tắt của chúng tôi. Tiếp theo điều này, chúng tôi thiết lập một quy trình đánh giá phục hồi tìm cách đo lường hiệu quả và độ chính xác mà bản tóm tắt có thể giải mã các câu cấp cao trở lại dữ liệu gốc, do đó phục vụ như một chỉ báo về tính chuyên nghiệp và độ chính xác của các tóm tắt. Giả định này hỗ trợ niềm tin của chúng tôi rằng mô hình càng có khả năng kỹ thuật ngược bản tóm tắt trở lại dữ liệu gốc, nó càng khẳng định độ chính xác và tính chuyên nghiệp của các bản tóm tắt. Ngược lại, nếu mô hình thể hiện khả năng thấp hơn trong nhiệm vụ phục hồi này, nó gợi ý rằng các bản tóm tắt thiếu một mức độ chuyên nghiệp và độ chính xác nhất định.

4 Thí nghiệm

4.1 Thiết lập Thí nghiệm
Tập dữ liệu Nghiên cứu này sử dụng ba tập dữ liệu khác biệt: Darts-Medium, Darts-Large, và PubMed. Các tập dữ liệu Darts-Medium và Darts-Large bao gồm các mạng kiến trúc nơ-ron, được tạo ra bởi 5 và 7 toán tử tương ứng, với Darts-Large có nhiều nút hơn. Chúng cung cấp một nguồn thông tin phong phú về thiết kế và hiệu suất của các kiến trúc nơ-ron khác nhau. Chúng tôi cũng đã kết hợp tập dữ liệu PubMed bao gồm các cấu trúc Isomeric SMILES vào nghiên cứu của chúng tôi. Tập dữ liệu này đại diện cho một lĩnh vực khác, cung cấp cơ hội kiểm tra việc tạo ra các bản tóm tắt cấp cao cho các cấu trúc hóa học phức tạp. Chúng tôi rất cẩn thận để tránh rò rỉ tập kiểm tra và chia dữ liệu cho từng giai đoạn sử dụng. Mỗi tập dữ liệu này đã được chia thành hai phần cho các giai đoạn khác nhau của thí nghiệm của chúng tôi: giai đoạn một lần và giai đoạn tạo sinh. Giai đoạn một lần bao gồm một tập hỗ trợ và một tập xác thực, mỗi tập chứa 50 mẫu. Những tập này được sử dụng để tìm mẫu tối ưu từ tập hỗ trợ. Giai đoạn tạo sinh chia dữ liệu sử dụng phương pháp K-Fold (K= 5) thành tập huấn luyện và tập kiểm tra. Tập huấn luyện được sử dụng để huấn luyện thêm mô hình và điều chỉnh cơ chế phần thưởng, trong khi tập kiểm tra được dành riêng để đánh giá chất lượng tóm tắt.

Thiết lập Chúng tôi thực hiện một siêu tham số nhiệt độ là 1 để thúc đẩy sự đa dạng trong việc tạo tóm tắt khi đánh giá hiệu suất cơ sở. Ngược lại, trong giai đoạn tạo dữ liệu, nhiệt độ được đặt ở mức không để đảm bảo tính nhất quán và ổn định. Để kiểm tra hiệu suất của các mô hình ngôn ngữ lớn khác nhau, chúng tôi áp dụng bốn mô hình được sử dụng rộng rãi trong thí nghiệm này, bao gồm phiên bản 3 của GPT: davinci, text-curie-001 và phiên bản 3.5 của GPT: text-davinci-003, gpt-3.5-turbo. Chúng tôi gọi phản hồi thông qua suy luận của các API chính thức openAI1. Thông tin được khởi tạo được chia thành hướng dẫn, mẫu và dữ liệu truy vấn, tương ứng gọi vai trò của system, assistant và user trong luồng thông tin. Chúng tôi đặt 10 lần lặp trong mỗi giai đoạn điều chỉnh một lần với độ dài token tối đa được xác định là 350 để tạo tóm tắt và 500 để phục hồi dữ liệu từ các tóm tắt. Mỗi lời nhắc đầu vào bao gồm ba phần, một hướng dẫn, một mẫu và một dữ liệu được lấy mẫu. Chúng tôi đưa ra các định dạng đầu vào và đầu ra trong hướng dẫn, và xác định ý nghĩa của mỗi ký hiệu có cấu trúc trong dữ liệu. Phần này tốn 500 token. Đối với mẫu, chúng tôi gán các thẻ assistant và content cho dữ liệu và tóm tắt trong mẫu, để GPT có thể nhận ra rằng đây là thông tin mẫu, và phần này tốn 3000 token. Đối với việc lấy mẫu dữ liệu từ tập hỗ trợ trong giai đoạn một lần, chúng tôi trực tiếp sử dụng vai trò của user để gửi nó đến GPT. Để làm cho bản tóm tắt được tạo ra đa dạng hơn trong giai đoạn điều chỉnh một lần, chúng tôi đặt siêu tham số nhiệt độ là 1. Trong giai đoạn tạo dữ liệu, chúng tôi đặt nhiệt độ là 0 để giữ nó ổn định.

4.2 Đánh giá
Đánh giá Tóm tắt. Để đánh giá trực tiếp chất lượng tóm tắt được tạo ra bởi phương pháp của chúng tôi, chúng tôi đã điều chỉnh các mô hình phần thưởng phản hồi của con người khác nhau như các người đánh giá của chúng tôi. Những mô hình phần thưởng này đã được thừa nhận rộng rãi trong tài liệu về hiệu quả của chúng trong việc cung cấp phản hồi đánh giá cho các nhiệm vụ tạo ngôn ngữ

1platform.openai.com/docs/models/

5

--- TRANG 6 ---
Bảng 1: Các điểm đánh giá khác nhau (±sai số chuẩn) trên ba tập dữ liệu. Hiệu suất của mỗi
mô hình được đánh giá sử dụng hai loại số liệu đánh giá.

Mô hình Đánh giá Tóm tắt Được tạo Đánh giá Dữ liệu Được phục hồi
R1 R2 R3 R4 BLEU ROUGE STS Sim Bert Sim
Darts-Medium
davinci 0.296±0.012 0.302±0.041 0.194±0.016 0.288±0.019 0.195±0.004 0.214±0.007 0.291±0.001 0.263±0.005
text-curie-001 0.243±0.028 0.211±0.013 0.297±0.004 0.342±0.013 0.118±0.004 0.172±0.008 0.310±0.006 0.294±0.009
text-davinci-003 0.532±0.023 0.596±0.028 0.503±0.032 0.582±0.031 0.278±0.006 0.379±0.017 0.772±0.003 0.543±0.025
gpt-3.5-turbo 0.513±0.011 0.642±0.016 0.519±0.015 0.639±0.017 0.482±0.023 0.422±0.004 0.816±0.014 0.691±0.002
Darts-Large
davinci 0.302±0.024 0.294±0.053 0.197±0.023 0.305±0.025 0.194±0.012 0.221±0.017 0.287±0.009 0.268±0.045
text-curie-001 0.252±0.038 0.220±0.023 0.305±0.011 0.370±0.021 0.129±0.014 0.182±0.022 0.314±0.013 0.308±0.019
text-davinci-003 0.509±0.034 0.607±0.021 0.515±0.011 0.580±0.027 0.292±0.005 0.382±0.013 0.781±0.001 0.559±0.009
gpt-3.5-turbo 0.544±0.020 0.672±0.037 0.537±0.021 0.657±0.033 0.505±0.030 0.447±0.009 0.829±0.019 0.715±0.006
PubMed
davinci 0.318±0.017 0.354±0.026 0.216±0.032 0.310±0.031 0.209±0.015 0.228±0.002 0.293±0.002 0.265±0.002
text-curie-001 0.262±0.013 0.230±0.021 0.327±0.018 0.372±0.026 0.138±0.012 0.192±0.001 0.316±0.001 0.310±0.001
text-davinci-003 0.547±0.019 0.611±0.022 0.514±0.036 0.594±0.023 0.571±0.008 0.403±0.001 0.774±0.004 0.571±0.002
gpt-3.5-turbo 0.542±0.022 0.671±0.031 0.547±0.023 0.667±0.012 0.509±0.004 0.457±0.001 0.796±0.001 0.635±0.002

Cụ thể, chúng tôi đã điều chỉnh các mô hình phần thưởng phản hồi của con người khác nhau2345 như các người đánh giá của chúng tôi. Mỗi người đánh giá đánh giá chất lượng tóm tắt và cung cấp một điểm phần thưởng tương ứng (R1, R2, R3, R4). Để đảm bảo tính ổn định trong phân phối phần thưởng, chúng tôi đã sử dụng một chiến lược xác thực chéo k-fold với giá trị k được đặt là 5. Giả sử r(x, s|θ) đại diện cho đầu ra vô hướng của mô hình phần thưởng cho dữ liệu x và tóm tắt s, được tham số hóa bởi θ. Chúng tôi đã thực hiện điều chỉnh trên mỗi mạng phần thưởng được tiền huấn luyện bằng cách tuân theo các bước được nêu trong [25]:

L=E(x,s0,s1,si)∼D[log(σ(r(x, si|θ))−σ(r(x, s 1−i|θ))], (5)

trong đó i∈ {0,1} và D đại diện cho các tập dữ liệu được gán nhãn bởi con người chứa các phán đoán về tóm tắt nào, được tạo ra bởi hai mô hình ngôn ngữ lớn, là vượt trội. Phương trình được phác thảo ở trên minh họa hàm mất mát mà chúng tôi sử dụng trong quá trình điều chỉnh này. Quá trình phần thưởng tượng trưng cho các tập dữ liệu được chú thích bởi con người cung cấp các phán đoán về tính vượt trội của các tóm tắt được tạo ra bởi hai mô hình ngôn ngữ lớn. Đánh giá kép này không chỉ thêm một mức độ dự phòng mà còn đảm bảo một đánh giá nghiêm ngặt và toàn diện hơn của các bản tóm tắt được tạo ra.

Đánh giá Phục hồi. Chúng tôi thực hiện cả căn chỉnh cấp câu và số liệu cấp nhúng để đánh giá sự khác biệt giữa dữ liệu được phục hồi và dữ liệu gốc.

Đối với đánh giá cấp câu, chúng tôi đã sử dụng điểm BLEU trung bình [20] và ROUGE-L [17,10]. Cụ thể, chúng tôi sử dụng một phiên bản trung bình được làm mượt của BLEU trong các đánh giá của chúng tôi để chống lại các vấn đề có thể phát sinh với BLEU khi xử lý các câu ngắn. Mặt khác, ROUGE-L dựa trên thống kê Longest Common Subsequence (LCS), điều này làm cho nó trở thành một công cụ mạnh mẽ để đánh giá chất lượng của các bản tóm tắt, đặc biệt trong trường hợp của chúng tôi nơi nó được áp dụng cho các đánh giá.

Khi nói đến các số liệu cấp nhúng, chúng tôi sử dụng nhúng Semantic Textual Similarity (STS) [19] và nhúng Bidirectional Encoder Representations from Transformers (BERT) [6]. Nhúng STS, đặc biệt, cung cấp một thước đo có thể định lượng về sự tương đương ngữ nghĩa giữa hai đoạn văn bản, điều này lý tưởng để đánh giá sự tương tự ngữ nghĩa giữa dữ liệu gốc và được phục hồi. Mặt khác, nhúng BERT, có nguồn gốc từ mô hình BERT, cho phép chúng tôi nắm bắt các đặc điểm ngữ nghĩa và cú pháp tinh tế hơn của các cấu trúc dữ liệu, cung cấp một phân tích toàn diện và sâu sắc hơn về các bản tóm tắt được tạo ra của chúng tôi so với dữ liệu gốc.

4.3 Kết quả Cơ sở
Chúng tôi đã tiến hành các thí nghiệm trên ba tập dữ liệu có tính thách thức cao sử dụng bốn mô hình khác nhau: davinci, text-curie-001, text-davinci-003, gpt-3.5-turbo. Đánh giá bao gồm kiểm tra chất lượng tóm tắt bằng bốn mạng phần thưởng cụ thể và đánh giá khả năng phục hồi dữ liệu bằng điểm căn chỉnh ở cả cấp độ câu và nhúng.

2gpt2-rlhf-reward
3reward-model-deberta-v3-large
4reward-model-deberta-v3-base
5chat-opt-350m-reward-deepspeed

6

--- TRANG 7 ---
Đánh giá trên Dữ liệu Phục hồi Chúng tôi đầu tiên tập trung vào đánh giá bản tóm tắt được tạo ra sử dụng bốn điểm phần thưởng. Những điểm này đại diện cho hiệu suất của chất lượng bản tóm tắt được tạo ra bởi các mô hình phần thưởng phản hồi của con người khác nhau sau khi điều chỉnh. Trên tập dữ liệu Darts-Medium, GPT-3.5-Turbo vượt trội hơn các mô hình khác với điểm cao nhất trên tất cả các số liệu: điểm BLEU 0.482±0.023, điểm ROUGE 0.422±0.004, điểm STS Sim 0.816±0.014, và điểm Bert Sim 0.691±0.002. Mô hình Text-davinci-003 theo sau đó, trong khi các mô hình Davinci và Text-curie-001 tụt lại phía sau, với điểm thấp hơn trên tất cả các thước đo. Xu hướng tương tự đã được quan sát trên tập dữ liệu Darts-Large. Một lần nữa, GPT-3.5-Turbo hiển thị hiệu suất vượt trội, đạt được điểm cao nhất trong tất cả các danh mục: BLEU (0.505±0.030), ROUGE (0.447±0.009), STS Sim (0.829±0.019), và Bert Sim (0.715±0.006). Text-davinci-003 duy trì vị trí thứ hai của nó, trong khi Davinci và Text-curie-001 theo sau với điểm ít ấn tượng hơn. Trên tập dữ liệu PubMed, mô hình Text-davinci-003 đáng chú ý đã đạt được điểm BLEU cao nhất 0.571±0.008, vượt qua các mô hình khác. Tuy nhiên, GPT-3.5-Turbo vẫn dẫn đầu các số liệu khác, với điểm ROUGE 0.457±0.001, điểm STS Sim 0.796±0.001, và điểm Bert Sim 0.635±0.002. Davinci và Text-curie-001 tiếp tục thể hiện hiệu suất kém hơn so với các mô hình khác. Trong khi hiệu suất biến đổi phần nào trên các tập dữ liệu khác nhau, GPT-3.5-Turbo liên tục mang lại kết quả mạnh nhất trên các số liệu được đánh giá. Điều này mạnh mẽ chỉ ra khả năng vượt trội của nó trong các nhiệm vụ phục hồi dữ liệu. Khoảng cách hiệu suất được quan sát giữa các mô hình làm nổi bật tầm quan trọng của việc chọn mô hình transformer phù hợp cho các nhiệm vụ và tập dữ liệu cụ thể, do đó tối ưu hóa sự đánh đổi giữa tài nguyên tính toán và hiệu suất.

Đánh giá về Chất lượng Tóm tắt Các kết quả trong Bảng 1 chứng minh rằng trên tập dữ liệu Darts-Medium, Text-davinci-003 hiển thị hiệu suất tổng thể tốt nhất về điểm R1 (0.532±0.023), R2 (0.596±0.028), và R3 (0.503±0.032). Tuy nhiên, GPT-3.5-Turbo đạt được điểm R4 cao nhất (0.639±0.017). Các mô hình khác, Davinci và Text-curie-001, có điểm thấp hơn trên những số liệu này. Trên tập dữ liệu Darts-Large, GPT-3.5-Turbo vượt trội hơn các mô hình khác trên tất cả các số liệu phần thưởng, với điểm R1 (0.544±0.020), R2 (0.672±0.037), R3 (0.537±0.021), và R4 (0.657±0.033). Text-davinci-003 theo sát phía sau, trong khi Davinci và Text-curie-001 tụt lại xa hơn về hiệu suất. Đối với tập dữ liệu PubMed, Text-davinci-003 thể hiện hiệu suất vượt trội trong các số liệu R1 (0.547±0.019), R2 (0.611±0.022), và R3 (0.514±0.036), trong khi GPT-3.5-Turbo đạt được điểm R4 cao nhất (0.667±0.012). Như trong các tập dữ liệu trước đó, Davinci và Text-curie-001 thể hiện điểm thấp hơn trên những số liệu phần thưởng này. Dựa trên hiệu suất, đánh giá trên các mô hình phần thưởng tiết lộ rằng Text-davinci-003 và GPT-3.5-Turbo liên tục vượt trội hơn các mô hình khác về điểm R1, R2, R3, và R4. Những phát hiện này nhấn mạnh tầm quan trọng của việc chọn các mô hình phần thưởng phù hợp cho các nhiệm vụ và tập dữ liệu cụ thể, vì chúng có tác động đáng kể đến chất lượng của các bản tóm tắt được tạo ra.

So sánh các Tập dữ liệu Đồng thời, chúng tôi quan sát rằng phương pháp chú thích mang lại kết quả khác nhau trên các tập dữ liệu khác nhau. Thứ nhất, rõ ràng là sự phức tạp và đặc điểm của tập dữ liệu có tác động đáng kể đến hiệu suất của các mô hình. Ví dụ, trên tập dữ liệu Darts-Medium, trong khi mô hình GPT-3.5-Turbo thực hiện xuất sắc trên các số liệu phục hồi dữ liệu (BLEU, ROUGE, STS Sim, và Bert Sim), hiệu suất của nó về các mô hình phần thưởng (R1, R2, R3, và R4) đã bị vượt qua bởi mô hình Text-davinci-003. Tuy nhiên, tình huống hơi khác trên tập dữ liệu Darts-Large, nơi GPT-3.5-Turbo vượt trội hơn các mô hình khác trong tất cả các số liệu được đánh giá. Điều này ngụ ý rằng mô hình đã thành thạo hơn trong việc xử lý sự phức tạp và khối lượng tăng lên của tập dữ liệu này. Mặt khác, hiệu suất của các mô hình trên tập dữ liệu PubMed trình bày các bản ghi cân bằng hơn, nơi mô hình Text-davinci-003 vượt qua các mô hình khác về điểm BLEU và điểm mô hình phần thưởng R1, R2, và R3, trong khi GPT-3.5-Turbo dẫn đầu trong các số liệu khác.

4.4 Nghiên cứu Loại bỏ
Trong nghiên cứu loại bỏ, chúng tôi chủ yếu nhằm mục đích giải quyết bốn câu hỏi chính cho phương pháp chú thích được đề xuất:

Q1. Mẫu một lần đóng vai trò gì, và liệu các hiệu ứng tương tự có thể đạt được thông qua phương pháp zero-shot — tạo ra các bản tóm tắt chỉ với hướng dẫn được thiết kế? Q2. Nếu mẫu hoạt động trong chú thích tự giám sát, các phương pháp đo lường tương tự khác nhau có tác động gì đến kết quả của việc điều chỉnh một lần? Q3. Việc khởi tạo mẫu ảnh hưởng như thế nào đến kết quả của mẫu tối ưu trong giai đoạn điều chỉnh một lần? Q4. Các bản tóm tắt được tạo ra có bị ảnh hưởng bởi các siêu tham số của chính mô hình GPT không?

7

--- TRANG 8 ---
(a) Điểm Phần thưởng trên
Tập dữ liệu Darts-Medium.
(b) Điểm Phục hồi trên
Tập dữ liệu Darts-Medium.
(c) Điểm Phần thưởng trên
Tập dữ liệu PubMed.
(d) Điểm Phục hồi trên
Tập dữ liệu PubMed.

Hình 3: Vai trò của dẫn đường mẫu một lần: một phân tích so sánh của các phương pháp một lần vs. zero-shot. Các thanh màu đỏ thể hiện lời nhắc ban đầu với việc thêm một mẫu một lần, và các thanh màu xanh đại diện cho các điểm có điều kiện trên cùng một hướng dẫn mà không có mẫu một lần. Chúng tôi sử dụng gpt-3.5-turbo để tiến hành nghiên cứu loại bỏ trên cả tập dữ liệu Darts và PubMed.

Bảng 3: Tác động của mẫu ban đầu. Từ góc nhìn của sự phức tạp ban đầu của dữ liệu và chất lượng tóm tắt ban đầu.

Mẫu
Ban đầu Dữ liệu của 3 toán tử Dữ liệu của 5 toán tử Dữ liệu của 7 toán tử
Tóm tắt Cao Tóm tắt Thấp Tóm tắt Cao Tóm tắt Thấp Tóm tắt Cao Tóm tắt Thấp
Lần lặp 4 8 5 8 4 7
Độ tương tự 0.653 0.652 0.641 0.655 0.652 0.659

A1. Mẫu một lần tối ưu cải thiện hiệu suất chú thích so với việc tạo sinh zero-shot có điều kiện trên cùng một hướng dẫn. Để trả lời Q1, chúng tôi sử dụng cả phương pháp zero-shot và một lần để điều tra các mô hình khác nhau và hai tập dữ liệu cụ thể theo lĩnh vực khác biệt. Cài đặt đánh giá tuân theo các bước được minh họa trong 4.2. Hình 3 thể hiện một so sánh toàn diện về kết quả của hai phương pháp tạo sinh này, bao gồm chất lượng của việc tạo sinh trực tiếp và độ chính xác của việc phục hồi dữ liệu. Chúng tôi quan sát rằng cơ chế một lần (màu đỏ), kết hợp việc lặp lại mẫu, liên tục vượt qua hiệu suất của zero-shot (màu xanh) về chất lượng chú thích dữ liệu, bất kể chúng tôi đánh giá mô hình phần thưởng hay độ tương tự của dữ liệu được phục hồi. Hơn nữa, chúng tôi quan sát độ lệch chuẩn dưới các phân vùng tập dữ liệu khác nhau bằng cách thực hiện xác thực chéo trong giai đoạn tạo sinh. Hình hiển thị các thanh sai số màu đỏ nhỏ hơn so với các thanh màu xanh, minh họa thêm rằng mẫu tăng cường tính ổn định và mạnh mẽ của chất lượng chú thích.

Bảng 2: Tác động của các số liệu căn chỉnh khác nhau giữa Dữ liệu Được Phục hồi và Dữ liệu Gốc cho Điều chỉnh Một lần. RandS là giá trị trung bình của điểm phần thưởng và điểm phục hồi.

STS BERT ROUGE BLEU Darts PubMed
R ✓ 52.14 58.89
✓ 53.21 60.32
✓ ✓ 61.48 60.05
✓ ✓ ✓ 62.59 65.27
✓ ✓ ✓ ✓ 61.17 65.96
S ✓ 21.18 19.04
✓ 26.19 25.20
✓ ✓ 29.44 39.55
✓ ✓ ✓ 45.59 40.04
✓ ✓ ✓ ✓ 44.05 41.38

A2. Việc tăng một cách phù hợp các số liệu đo lường có lợi cho chất lượng chú thích. Quá trình phản hồi của thuật toán lặp lại được đề xuất của chúng tôi dựa trên thước đo độ tương tự giữa dữ liệu được phục hồi và dữ liệu gốc, đối với việc lựa chọn các số liệu tương tự là thiết yếu. Xem xét rằng cả dữ liệu có cấu trúc gốc và dữ liệu được tạo ra đều là thông tin chuỗi, chúng tôi áp dụng các lược đồ được sử dụng rộng rãi nhất để đo lường độ tương tự chuỗi, từ các phương pháp đo lường cấp câu (BLEU, ROUGE), đến các kỹ thuật đo lường cấp nhúng (STS, BERT). Quy trình thí nghiệm cho nghiên cứu loại bỏ này tuân thủ quá trình trước đó. Bảng 2 cung cấp các bản ghi của điểm kiểm tra bằng cách đặt các căn chỉnh tương tự khác nhau như giá trị phản hồi. Trong hai hàng đầu tiên của Bảng 2, Ban đầu, chúng tôi đã kiểm tra tác động của hai loại hàm tính toán tương tự đơn lẻ khác nhau lên kết quả được chú thích. Hai hàng đầu tiên của mỗi nhóm trong Bảng 2 thể hiện tình huống này. Các bản ghi thí nghiệm gợi ý rằng cấu trúc câu có tác động tích cực hơn một chút đến kết quả. Hơn nữa, bằng cách so sánh hai hàng cuối (các hàm số liệu hỗn hợp) với hai hàng đầu (hàm số liệu đơn lẻ) trong mỗi nhóm, chúng tôi quan sát rằng dù chúng tôi trực tiếp đo lường với hàm phần thưởng hay gián tiếp đánh giá khả năng phục hồi của bản tóm tắt, việc tăng cường sự đa dạng của các hàm số liệu có thể cải thiện hiệu quả chất lượng của dữ liệu được chú thích.

A3. Các mẫu ban đầu chất lượng cao dẫn đến hội tụ nhanh hơn, nhưng điểm tương tự của lần lặp cuối cùng thể hiện phương sai thấp. Trong giai đoạn ban đầu của điều chỉnh một lần, chúng tôi đã quan sát

8

--- TRANG 9 ---
(a) T=0 của text-curie-001 trên
Darts-Medium;
(b) T=1 của text-curie-001
trên Darts-Medium;
(c) T=0 của gpt-3.5-turbo trên
Darts-Medium;
(d) T=1 của gpt-3.5-turbo trên
Darts-Medium;
(e) T=0 của davinci trên
Darts-Medium;
(f) T=1 của davinci trên
Darts-Medium;
(g) T=0 của text-davinci-003
trên Darts-Medium;
(h) T=1 của text-davinci-003
trên Darts-Medium;
(i) T=0 của text-curie-001 trên
PubMed;
(j) T=1 của text-curie-001 trên
PubMed;
(k) T=0 của gpt-3.5-turbo trên
PubMed;
(l) T=1 của gpt-3.5-turbo trên
PubMed;
(m) T=0 của davinci trên
PubMed;
(n) T=1 của davinci trên
PubMed;
(o) T=0 của text-davinci-003
trên PubMed;
(p) T=1 của text-davinci-003
trên PubMed;

Hình 4: Tác động của nhiệt độ mô hình. Các đường màu đỏ đại diện cho các bản ghi lặp lại của điểm tương tự bởi dữ liệu hỗ trợ hiện tại và các đường màu xanh theo dõi điểm phục hồi trên tập xác thực. Mũi tên chỉ số lần lặp trung bình để tìm mẫu tối ưu.

trong các bản ghi chạy cho thấy độ dài và chất lượng của các mẫu được khởi tạo có tác động đến quá trình huấn luyện. Để điều tra điều này sâu hơn, chúng tôi đã thiết kế ba mẫu của tập dữ liệu Darts với các mức độ phức tạp khác nhau: tập dữ liệu Darts được tạo ra bởi 3 toán tử, 5 toán tử, và 7 toán tử. Ngoài ra, chúng tôi đã đánh dấu nhân tạo 2 loại chất lượng tóm tắt: Sim. Cao và Sim. Thấp. Điều này dẫn đến tổng cộng 6 trường hợp. Để đảm bảo các điều kiện thí nghiệm nhất quán, mỗi mẫu được áp dụng 50 lần trong giai đoạn một lần. Hơn nữa, nhiệt độ của GPT được đặt là 0 để duy trì tính ổn định của việc tạo tóm tắt trong mỗi vòng. Bảng 3 thể hiện ảnh hưởng của sáu trường hợp của các cài đặt khác nhau về khởi tạo. Đường polyline của nhóm màu ấm đại diện cho quá trình lặp lại của các bản tóm tắt chất lượng cao. Chúng ta có thể quan sát từ điều này rằng thời gian hội tụ của nó tương đối sớm so với mẫu ban đầu có các bản tóm tắt chất lượng thấp hơn. Điểm tại việc chấm dứt thuật toán rõ ràng cho thấy mẫu tối ưu cuối cùng được tạo ra sở hữu một điểm tương tự gần, điều này chỉ ra rằng khởi tạo chủ yếu ảnh hưởng đến số lần lặp nhưng không áp dụng cho hiệu suất của mẫu tối ưu.

A4. Nhiệt độ của mô hình ảnh hưởng đến việc tìm kiếm lặp lại cho mẫu tối ưu. Để điều tra toàn diện tác động của các siêu tham số nhiệt độ trên hiệu suất của các mô hình khác nhau, chúng tôi đã tiến hành một loạt thí nghiệm tập trung vào các tính chất hội tụ của bốn mô hình cơ sở dưới các cài đặt nhiệt độ khác nhau trong các môi trường khác nhau. Để đảm bảo tính mạnh mẽ của các phát hiện của chúng tôi, chúng tôi đã thực hiện mỗi lần chạy 30 lần, theo dõi độ lệch chuẩn của các giá trị tương tự được tạo ra tại mỗi trường hợp. Hình 4 trình bày kết quả thí nghiệm cho sự kết hợp của hai tham số nhiệt độ trên bốn mô hình. Những kết quả này tiết lộ một xu hướng nhất quán trên tất cả các mô hình: khi nhiệt độ được đặt là 0, quá trình tìm kiếm lặp lại chấm dứt

9

--- TRANG 10 ---
sớm tại lần lặp thứ ba hoặc thứ tư. Điều này gợi ý một khuynh hướng hướng tới một không gian khám phá hạn chế, dẫn đến việc tạo ra các đầu ra ít đa dạng hơn. Mặt khác, việc nâng giá trị nhiệt độ lên 1 trong giai đoạn điều chỉnh một lần đã thể hiện một kết quả thú vị. Mặc dù tốc độ của mỗi lần lặp bị giảm, điều này đã tạo điều kiện cho một loạt các lựa chọn thay thế rộng hơn cho việc tạo mẫu tiếp theo. Điều này chỉ ra một sự mở rộng của không gian khám phá, cho phép tạo ra các giải pháp đa dạng và có tiềm năng sáng tạo hơn. Chúng tôi cũng quan sát rằng điểm cuối cùng cao hơn khi nhiệt độ được đặt là 1, so với 0. Phát hiện này chỉ ra rằng các mẫu tối ưu có thể được có được bằng cách điều chỉnh một cách phù hợp siêu tham số nhiệt độ.

5 Nghiên cứu Trường hợp
Ở đây chúng tôi cung cấp hai trường hợp để giải thích cách GPT tự giám sát chú thích dữ liệu có cấu trúc phức tạp trên tập dữ liệu Darts và PubMed. Chúng tôi đầu tiên thể hiện lời nhắc để tạo tóm tắt và phục hồi dữ liệu, và sau đó chúng tôi thể hiện các quy trình của phương pháp của chúng tôi.

Lời nhắc Lời nhắc tạo sinh bao gồm ba yếu tố: hướng dẫn mã hóa, mẫu, dữ liệu truy vấn, trong khi lời nhắc phục hồi chứa hướng dẫn giải mã, mẫu, tóm tắt truy vấn. Các giải thích chi tiết về những hướng dẫn này có thể được tìm thấy trong Phụ lục A.

Quy trình Chúng tôi sử dụng trường hợp 5 trên tập dữ liệu Darts để giải thích về quy trình của phương pháp chú thích của chúng tôi.

Bước 1. Khởi tạo một mẫu bao gồm các ô và một bản tóm tắt.
Bước 2. Lấy mẫu một tập ô từ tập hỗ trợ.
Bước 3. Nối <hướng dẫn mã hóa, mẫu, ô> thành một tin nhắn.
Bước 4. Gửi tin nhắn đến GPT và nhận phản hồi tóm tắt.
Bước 5. Nối <hướng dẫn giải mã, mẫu, tóm tắt> thành một tin nhắn.
Bước 6. Gửi tin nhắn đến GPT và nhận phản hồi của các ô được phục hồi.
Bước 7. Tính độ tương tự giữa các ô được phục hồi và ô gốc. Nếu nó lớn hơn bản ghi trước đó, cập nhật điểm và coi dữ liệu được lấy mẫu và tóm tắt được tạo ra như một mẫu tạm thời.
Bước 8. Đánh giá mẫu tạm thời trên tập hợp lệ bằng cách lặp lại quá trình trên.
Bước 9. Nếu điểm trung bình trên tập dữ liệu xác thực cũng vượt qua các bản ghi trước đó, cập nhật điểm xác thực tốt nhất và thay thế mẫu hiện tại bằng mẫu tạm thời.
Bước 10. Lặp lại Bước 2. đến Bước 9. cho đến khi số lần lặp tối đa được đạt tới.

Lời nhắc Tạo sinh
Mẫu:
"Isomeric SMILE" = {{
C[C@@H](CC1=CC=CC=C1)N
}
}"Tóm tắt" = {
(S)-amphetamine là một 1-phenylpropan-2-amine
có cấu hình S. Nó có vai trò như một
chất độc thần kinh.
}Hướng dẫn:
C Methane (CH4)
CC Ethane (CH3CH3)
C=C Ethene (CH2CH2)
C#C Ethyne (CHCH)
COC Dimethyl ether (CH3OCH3)
CC=O Acetaldehyde (CH3-CH=O)
...
Dữ liệu Hỗ trợ Truy vấn:
C[C@]12CC[C@H]3[C@H]([C@@H]1CCC2=O)CCC4
=C3C=CC(=C4)O System
Assistant
User Lời nhắc Phục hồi
Mẫu:
"Tóm tắt" = {{
(S)-amphetamine là một 1-phenylpropan-2-amine
có cấu hình S. Nó có vai trò như một
chất độc thần kinh.
}
}"Isomeric SMILE" =
{C[C@@H](CC1=CC=CC=C1)N
}
Tóm tắt Được tạo Truy vấn:
Isomeric SMILES được cung cấp đại diện cho một hợp chất với
cấu trúc sau: một nguyên tử lưu huỳnh (S) được liên kết với một
nguyên tử carbon (C) mà ... gắn với một carbon chiral
([C@H]). Assistant
User
Tóm tắt Được tạo
Isomeric SMILES được cung cấp
đại diện cho một hợp chất với
cấu trúc sau: một nguyên tử lưu huỳnh (S)
được liên kết với một nguyên tử carbon (C) mà ... gắn với một carbon chiral ([C@H]). Hướng dẫn:
C Methane (CH4)
CC Ethane (CH3CH3)
C=C Ethene (CH2CH2)
C#C Ethyne (CHCH)
COC Dimethyl ether (CH3OCH3)
CC=O Acetaldehyde (CH3-CH=O)
... System Dữ liệu Được phục hồi
C [ C @] 1 2 C C [ C @H ] 3 [ C @H ]
( [ C @@H ] 1 C C C 2 =O ) C C C 4
=C 3 C =C C ( =C 4 ) O

Hình 6: Tập dữ liệu PubMed: Một trường hợp của chú thích tạo-phục hồi.

10

--- TRANG 11 ---
Lời nhắc Tạo sinh
Mẫu:
"Ô" = {{
"INPUT ->conv3, conv3->bn,bn->avgpool3,
avgpool3->avgpool3, avgpool3->OUTPUT ,
INPUT ->OUTPUT",
}
}"Tóm tắt" = {
Kiến trúc mạng nơ-ron bao gồm một
lớp đầu vào theo sau bởi 2 khối và 1 kết nối
bỏ qua.
}Hướng dẫn:
- "->' biểu diễn cạnh.
- 'bn' là chuẩn hóa batch.
- 'avgpool-n' là pooling trung bình.
- 'maxpool-n' là max pooling.
- 'sepconv-n' là convolution tách biệt.
- 'dilconv-n' là convolution giãn.
- 'skipconnect" là kết nối bỏ qua.
Dữ liệu Hỗ trợ Truy vấn:
'INPUT->sepconv33, sepconv33->avgpool331,
avgpool331->2maxpool331, 2maxpool331->bn, bn-
>OUTPUT, INPUT->OUTPUT' System
Assistant
User Lời nhắc Phục hồi
Mẫu:
"Tóm tắt" = {{
Kiến trúc mạng nơ-ron bao gồm một
lớp đầu vào theo sau bởi 2 khối và 1 kết nối
bỏ qua.
}
}"Ô" = {
"INPUT ->conv3, conv3->bn,bn->avgpool3,
avgpool3->avgpool3, avgpool3->OUTPUT ,
INPUT ->OUTPUT",
}
Tóm tắt Được tạo Truy vấn:
Mạng nơ-ron này bao gồm một convolution 3x3, theo sau
bởi nhiều lớp có đặc điểm pooling trung bình, max pooling,
convolution tách biệt depthwise 3x3, convolution giãn 3x3,
và các phép toán cộng để kết nối các lớp. Assistant
User
Mạng nơ-ron này bao gồm một stem
với một convolution 3x3, theo sau
bởi nhiều lớp có đặc điểm pooling trung bình,
max pooling, convolution tách biệt
depthwise 3x3, convolution giãn 3x3,
và các phép toán cộng để
kết nối các lớp. Tóm tắt Được tạo Dữ liệu Được phục hồi
'INPUT->sepconv33, sepconv33-
>avgpool331, avgpool331-
>2maxpool331, 2maxpool332->bn,
bn->OUTPUT, INPUT->OUTPUT' Hướng dẫn:
- "->' biểu diễn cạnh.
- 'bn' là chuẩn hóa batch.
- 'avgpool-n' là pooling trung bình.
- 'maxpool-n' là max pooling.
- 'sepconv-n' là convolution tách biệt.
- 'dilconv-n' là convolution giãn.
- 'skipconnect" là kết nối bỏ qua. System

Hình 5: Tập dữ liệu Darts: Một trường hợp của chú thích tạo-phục hồi.

6 Hạn chế
Các ràng buộc được áp đặt bởi giới hạn token hạn chế số lượng mẫu mà chúng tôi có thể sử dụng, đặt ra một thách thức đáng kể khi tiến hành các thí nghiệm trong một khung few-shot. Do đó, có một sự đánh đổi cần thiết giữa số lượng mẫu shot và độ dài của mỗi mẫu.

7 Kết luận
Bài báo này giới thiệu một phương pháp mới mang tên chú thích tự giám sát GPT, khai thác khả năng học một lần của các mô hình GPT để sản xuất các bản tóm tắt ngắn gọn và giảm bớt gánh nặng về thời gian và chuyên môn chuyên biệt được yêu cầu bởi các người chú thích con người khi xử lý dữ liệu có cấu trúc phức tạp, chẳng hạn như đồ thị. Phương pháp của chúng tôi bao gồm hai giai đoạn: điều chỉnh một lần và tạo sinh. Trong giai đoạn điều chỉnh một lần, một tập hỗ trợ và một tập xác thực được tạo ra từ dữ liệu huấn luyện, một mẫu được chọn từ tập hỗ trợ và được sử dụng như một lời nhắc để tạo ra một bản tóm tắt văn bản sử dụng các mô hình GPT, và cùng một mô hình được sử dụng để phục hồi dữ liệu gốc từ bản tóm tắt được tạo ra, với điểm căn chỉnh được tính toán để phản hồi và sửa đổi mẫu tiềm năng. Trong giai đoạn tạo sinh, phương pháp của chúng tôi sử dụng một mẫu một lần được chọn như một mẫu để tạo ra các bản tóm tắt cho các tập dữ liệu thách thức. Cả điểm căn chỉnh cấp câu (BLEU, ROUGE) và cấp cấu trúc (STS, BERT) giữa dữ liệu gốc và được phục hồi đều được đánh giá, điều này chứng minh rằng phương pháp của chúng tôi liên tục đạt được điểm đánh giá cạnh tranh. Các kết quả chứng minh hiệu quả của các mô hình GPT trong các nhiệm vụ chú thích dữ liệu-thành-tóm tắt.

Tài liệu tham khảo
[1]Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal,
Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Các mô hình ngôn ngữ là
những người học few-shot. Tiến bộ trong xử lý thông tin nơ-ron, 33:1877–1901, 2020.
[2]Levi Cai, Nathan E McGuire, Roger Hanlon, T Aran Mooney, và Yogesh Girdhar. Theo dõi thị giác
bán giám sát động vật biển sử dụng phương tiện dưới nước tự động. Tạp chí Quốc tế về
Thị giác Máy tính, trang 1–22, 2023.
[3]Haoyu Chen, Henglin Shi, Xin Liu, Xiaobai Li, và Guoying Zhao. Smg: Một tập dữ liệu
micro-gesture hướng tới cử chỉ cơ thể tự phát để phân tích trạng thái căng thẳng cảm xúc. Tạp chí Quốc tế về
Thị giác Máy tính, 131(6):1346–1366, 2023.
[4]Ying Chen, Yifan Peng, Kai-Wei Chang, Mark Dredze, Aaron M. Cohen, William R. Hersh,
Iain J. Marshall, Aurélie Névéol, Pierre Zweigenbaum, Sijia Liu, Baotian Hu, Fei Li, và

11

--- TRANG 12 ---
Zhiyong Lu. Thách thức và cơ hội trong mã hóa tự động chẩn đoán và thủ tục trong
chăm sóc sức khỏe. npj Digital Medicine, 4(1), Tháng 11 năm 2021.
[5]Jan Deriu, Alvaro Rodrigo, Arantxa Otegi, Guillermo Echegoyen, Sophie Rosset, Eneko Agirre,
và Mark Cieliebak. Khảo sát về các phương pháp đánh giá cho các hệ thống đối thoại. Springer, 2021.
[6]Jacob Devlin, Ming-Wei Chang, Kenton Lee, và Kristina Toutanova. Bert: Tiền huấn luyện của
các transformer hai chiều sâu để hiểu ngôn ngữ. arXiv preprint arXiv:1810.04805,
2018.
[7]Bosheng Ding, Chengwei Qin, Linlin Liu, Lidong Bing, Shafiq Joty, và Boyang Li. Liệu gpt-3 có
phải là một người chú thích dữ liệu tốt không? arXiv preprint arXiv:2212.10450, 2022.
[8]Georgiana Cristina Dobre, Marco Gillies, và Xueni Pan. Học máy nhập vai cho
phát hiện thái độ xã hội trong các trò chơi tường thuật thực tế ảo. Springer, 2022.
[9]Li Fei-Fei, Robert Fergus, và Pietro Perona. Học một lần các danh mục đối tượng. IEEE
transactions on pattern analysis and machine intelligence, 28(4):594–611, 2006.
[10] Kavita Ganesan. Rouge 2.0: Các thước đo được cập nhật và cải thiện để đánh giá các nhiệm vụ tóm tắt.
arXiv preprint arXiv:1803.01937, 2018.
[11] Fabrizio Gilardi, Meysam Alizadeh, và Maël Kubli. Chatgpt vượt trội hơn crowd-workers cho
các nhiệm vụ chú thích văn bản. arXiv preprint arXiv:2303.15056, 2023.
[12] Johannes Kopp, Dominik Kellner, Aldi Piroli, và Klaus Dietmayer. Giải quyết sự lộn xộn trong dữ liệu radar–tạo nhãn và phát hiện sử dụng pointnet++. arXiv preprint arXiv:2303.09530, 2023.
[13] Tiziano Labruna, Sofia Brenna, Andrea Zaninello, và Bernardo Magnini. Khám phá chatgpt:
Một phân tích quan trọng về các cuộc đối thoại và chú thích hướng mục tiêu được tạo ra bởi ai. arXiv preprint
arXiv:2305.14556, 2023.
[14] Hamid Laga, Laurent Valentin Jospin, Farid Boussaid, và Mohammed Bennamoun. Một khảo sát
về các kỹ thuật học sâu cho ước lượng độ sâu dựa trên stereo. IEEE transactions on pattern
analysis and machine intelligence, 44(4):1738–1764, 2020.
[15] Brian Lester, Noah Constant, và Rami Al-Rfou. Sức mạnh của quy mô cho điều chỉnh lời nhắc
hiệu quả tham số. Trong EMNLP, 2021.
[16] Brian Lester, Noah Constant, và Rami Al-Rfou. Hướng dẫn các mô hình ngôn ngữ đông lạnh với
các lời nhắc mềm đã học. Google AI Blog, 2022.
[17] Chin-Yew Lin. Rouge: Một gói để đánh giá tự động các bản tóm tắt. Trong Text summarization
branches out: Proceedings of the ACL-04 workshop, tập 8, 2004.
[18] R Austin McEver, Bowen Zhang, Connor Levenson, ASM Iftekhar, và BS Manjunath. Phát hiện
theo ngữ cảnh các loài động vật không xương sống trong video biển sâu. Tạp chí Quốc tế về Thị giác Máy tính,
131(6):1367–1388, 2023.
[19] Tomas Mikolov, Kai Chen, Greg Corrado, và Jeffrey Dean. Ước lượng hiệu quả của biểu diễn từ
trong không gian vector. arXiv preprint arXiv:1301.3781, 2013.
[20] Kishore Papineni, Salim Roukos, Todd Ward, và Wei-Jing Zhu. Bleu: một phương pháp để đánh giá tự động
dịch máy. Trong Proceedings of the 40th annual meeting of the Association
for Computational Linguistics, trang 311–318, 2002.
[21] Ankur P Parikh, Xuezhi Wang, Sebastian Gehrmann, Manaal Faruqui, Bhuwan Dhingra, Diyi
Yang, và Dipanjan Das. Totto: Một tập dữ liệu tạo văn bản từ bảng được kiểm soát. arXiv preprint
arXiv:2004.14373, 2020.
[22] N. Polyzotis và M. Zaharia. AI lấy dữ liệu làm trung tâm có thể học được gì từ kỹ thuật dữ liệu và ml?
arXiv preprint arXiv:2112.06439, 2021.
[23] Alec Radford, Karthik Narasimhan, Tim Salimans, Ilya Sutskever, et al. Cải thiện hiểu biết ngôn ngữ
bằng tiền huấn luyện tạo sinh. 2018.
[24] Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al.
Các mô hình ngôn ngữ là những người học đa nhiệm không giám sát. OpenAI blog, 1(8):9, 2019.
[25] Nisan Stiennon, Long Ouyang, Jeffrey Wu, Daniel Ziegler, Ryan Lowe, Chelsea Voss, Alec
Radford, Dario Amodei, và Paul F Christiano. Học tóm tắt với phản hồi của con người.
Tiến bộ trong Xử lý Thông tin Nơ-ron, 33:3008–3021, 2020.

12

--- TRANG 13 ---
[26] Oriol Vinyals, Charles Blundell, Timothy Lillicrap, Daan Wierstra, et al. Matching networks
cho học một lần. Tiến bộ trong hệ thống xử lý thông tin nơ-ron, 29, 2016.
[27] Kai-Fu Yang, Cheng Cheng, Shi-Xuan Zhao, Hong-Mei Yan, Xian-Shi Zhang, và Yong-Jie Li.
Học để thích ứng với ánh sáng. Tạp chí Quốc tế về Thị giác Máy tính, trang 1–20, 2023.
[28] Xinyu Yang, Tilo Burghardt, và Majid Mirmehdi. Học chương trình động cho phát hiện
vượn lớn trong tự nhiên. Tạp chí Quốc tế về Thị giác Máy tính, trang 1–19, 2023.
[29] Jing Zhang, Min-Yen Kan, Kazunari Sugiyama, và Tat-Seng Chua. Xử lý tài liệu khoa học:
thách thức cho các phương pháp học hiện đại. Tạp chí Quốc tế về Thư viện Số,
32(2):1–38, Tháng 5 năm 2023.
[30] Yiming Zhu, Peixian Zhang, Ehsan-Ul Haq, Pan Hui, và Gareth Tyson. Liệu chatgpt có thể tái tạo
các nhãn được tạo ra bởi con người không? một nghiên cứu về các nhiệm vụ tính toán xã hội. arXiv preprint arXiv:2304.10145,
2023.

13

--- TRANG 14 ---
A Phụ lục
Ở đây chúng tôi cung cấp hướng dẫn mã hóa và hướng dẫn giải mã để tạo sinh và phục hồi trên
tập dữ liệu darts trong Hình 7.

Hướng dẫn để tạo tóm tắt trên tập dữ liệu Darts.
Bạn là một chuyên gia trong lĩnh vực tìm kiếm kiến trúc nơ-ron. Nhiệm vụ của bạn là tóm tắt các
kiến trúc nơ-ron dựa trên danh sách các toán tử tính toán. Bản tóm tắt sẽ được sử dụng
để phục hồi danh sách toán tử gốc và mục tiêu của bạn là cung cấp bản tóm tắt có thể
tối đa hóa khả năng phục hồi toán tử.
Các cạnh đồ thị là một biểu diễn danh sách cạnh của một đồ thị có hướng. Đồ thị đại diện cho một
mạng nơ-ron, nơi các nút là các phép toán, và các cạnh có hướng đại diện cho
luồng thông tin với ''->''. ''18maxpool312'' có nghĩa là một phép toán max pooling với bộ lọc 3x3
và stride 1 được áp dụng trong lớp 19.
Bản tóm tắt của kiến trúc mạng nơ-ron bằng ngôn ngữ tự nhiên nên bao gồm:
    1. Mỗi khối được cấu thành với những toán tử nào.
    
    2. Độ sâu của mỗi khối và chiều rộng của các khối song song.
    
    3. Ưu/nhược điểm của thiết kế dựa trên cấu trúc khối.
    
Định dạng trả về của bạn là một dict JSON: {Tóm tắt:  }.
(a) Hướng dẫn mã hóa.

Hướng dẫn để phục hồi dữ liệu trên tập dữ liệu Darts.
Bạn là một chuyên gia trong lĩnh vực tìm kiếm kiến trúc nơ-ron.
Nhiệm vụ của bạn được cung cấp một bản tóm tắt về các tính năng chính của mạng.
Kiến trúc được biểu diễn như một danh sách cạnh nơi các nút là các phép toán
và các cạnh đại diện cho luồng thông tin với '->'.
Các toán tử ứng viên cho các nút là
INPUT, OUTPUT, bn, avgpool, maxpool, sepconv, dilconv, và linear.
Toán tử convolution tách biệt với bộ lọc 3x3 có nghĩa là `'sepconv33'`
Lớp 2, toán tử max pooling với bộ lọc 3x3 stride 1 có nghĩa là `'2maxpool331'`
Mục tiêu của bạn là trích xuất thông tin chính từ bản tóm tắt được cung cấp
để phục hồi các ô tối đa hóa khoảng cách giữa các ô được phục hồi,
với định dạng đầu ra là một dict thuần túy chỉ chứa khóa ô.
Định dạng trả về của bạn là một dict json: { Dữ liệu Được Phục hồi:  }.
(b) Hướng dẫn giải mã.

Hình 7: Hướng dẫn cho chú thích trên tập dữ liệu Darts.

14

--- TRANG 15 ---
Và chúng tôi cũng cung cấp hướng dẫn mã hóa và hướng dẫn giải mã để tạo sinh và phục hồi
trên tập dữ liệu PubMed trong Hình 8.

Hướng dẫn để tạo tóm tắt trên tập dữ liệu PubMed.
Bạn là một người chú thích chuyên nghiệp của Isomeric SMILES dựa trên mô tả hợp chất hữu cơ. Trong
SMILES, các nguyên tử được biểu diễn bởi các ký hiệu nguyên tử của chúng.
Chữ cái thứ hai của các ký hiệu nguyên tử hai ký tự phải được nhập bằng chữ thường. Mỗi nguyên tử
không phải hydro được chỉ định độc lập bởi ký hiệu nguyên tử của nó được đặt trong dấu ngoặc vuông, [ ] (ví dụ, [Au]
hoặc [Fe]). Dấu ngoặc vuông có thể được bỏ qua cho các nguyên tố
trong "tập con hữu cơ" (B, C, N, O, P, S, F, Cl, Br, và I) nếu số lượng thích hợp của các nguyên tử hydro "ngầm"
được giả định. Các hydro được gắn "rõ ràng" và điện tích chính thức luôn được chỉ định bên trong
dấu ngoặc. Một điện tích chính thức được biểu diễn bởi một trong các ký hiệu + hoặc -. Các liên kết đơn, đôi, ba, và
thơm được biểu diễn bởi các ký hiệu, -, =, #, tương ứng. Các liên kết đơn và thơm có thể,
và thường được, bỏ qua.
C Methane (CH4)
CC Ethane (CH3CH3)
C=C Ethene (CH2CH2)
C#C Ethyne (CHCH)
COC Dimethyl ether (CH3OCH3)
CCO Ethanol (CH3CH2OH)
CC=O Acetaldehyde (CH3-CH=O)
C#N Hydrogen Cyanide (HCN)
[C-]#N Cyanide anion
Tôi sẽ cung cấp một Isomeric SMILES bạn trả về một bản tóm tắt.
Định dạng trả về của bạn là một dict json: {Tóm tắt:  }
(a) Hướng dẫn mã hóa.

Hướng dẫn để phục hồi dữ liệu trên tập dữ liệu PubMed.
Bạn là một người chú thích chuyên nghiệp của Isomeric SMILES dựa trên mô tả hợp chất hữu cơ. Trong
SMILES, các nguyên tử được biểu diễn bởi các ký hiệu nguyên tử của chúng.
Chữ cái thứ hai của các ký hiệu nguyên tử hai ký tự phải được nhập bằng chữ thường. Mỗi nguyên tử
không phải hydro được chỉ định độc lập bởi ký hiệu nguyên tử của nó được đặt trong dấu ngoặc vuông, [ ] (ví dụ, [Au]
hoặc [Fe]). Dấu ngoặc vuông có thể được bỏ qua cho các nguyên tố
trong "tập con hữu cơ" (B, C, N, O, P, S, F, Cl, Br, và I) nếu số lượng thích hợp của các nguyên tử hydro "ngầm"
được giả định. Các hydro được gắn "rõ ràng" và điện tích chính thức luôn được chỉ định bên trong
dấu ngoặc. Một điện tích chính thức được biểu diễn bởi một trong các ký hiệu + hoặc -. Các liên kết đơn, đôi, ba, và
thơm được biểu diễn bởi các ký hiệu, -, =, #, tương ứng. Các liên kết đơn và thơm có thể,
và thường được, bỏ qua.
C Methane (CH4)
CC Ethane (CH3CH3)
C=C Ethene (CH2CH2)
C#C Ethyne (CHCH)
COC Dimethyl ether (CH3OCH3)
CCO Ethanol (CH3CH2OH)
CC=O Acetaldehyde (CH3-CH=O)
C#N Hydrogen Cyanide (HCN)
[C-]#N Cyanide anion
Tôi sẽ cung cấp một mô tả, bạn trả về một Isomeric SMILES.
Định dạng trả về là dict json: {Isomeric SMILES: }
(b) Hướng dẫn giải mã.

Hình 8: Hướng dẫn cho chú thích trên tập dữ liệu PubMed.

15

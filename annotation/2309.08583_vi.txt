# 2309.08583.pdf
# Đã chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/annotation/2309.08583.pdf
# Kích thước tệp: 1728860 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
ICLEF: Học Trong Ngữ Cảnh với Phản Hồi Chuyên Gia cho Chuyển Đổi Phong Cách Có Thể Giải Thích
Arkadiy Saakyan1và Smaranda Muresan1,2
1Khoa Khoa Học Máy Tính, Đại Học Columbia
2Viện Khoa Học Dữ Liệu, Đại Học Columbia
a.saakyan@cs.columbia.edu, smara@columbia.edu
Tóm tắt
Trong khi các mô hình ngôn ngữ lớn (LLM) tiên tiến
có thể xuất sắc trong việc điều chỉnh văn bản từ
phong cách này sang phong cách khác, công trình
hiện tại không giải quyết khả năng giải thích của
các mô hình chuyển đổi phong cách. Nghiên cứu
gần đây đã khám phá việc tạo ra các giải thích
bằng văn bản từ các mô hình giáo viên lớn hơn và
chưng cất chúng thành các mô hình học sinh nhỏ
hơn. Một thách thức với phương pháp như vậy là
đầu ra của LLM có thể chứa lỗi cần chuyên môn
để sửa chữa, nhưng việc thu thập và kết hợp phản
hồi chuyên gia là khó khăn do chi phí và tính khả
dụng. Để giải quyết thách thức này, chúng tôi đề
xuất ICLEF, một phương pháp hợp tác người-AI
mới cho chưng cất mô hình kết hợp phản hồi chuyên
gia của con người hiếm hoi bằng cách kết hợp học
trong ngữ cảnh và tự phê bình mô hình. Chúng tôi
cho thấy phương pháp của chúng tôi dẫn đến việc
tạo ra các tập dữ liệu chuyển đổi phong cách có thể
giải thích tổng hợp chất lượng cao cho tính trang
trọng (E-GYAFC) và thiên vị chủ quan (E-WNC).
Thông qua đánh giá tự động và con người, chúng
tôi cho thấy các mô hình học sinh chuyên biệt được
tinh chỉnh trên các tập dữ liệu của chúng tôi vượt
trội so với các mô hình giáo viên tổng quát trong
nhiệm vụ chuyển đổi phong cách có thể giải thích
trong cài đặt một lần, và hoạt động cạnh tranh so
với các mô hình giáo viên vài lần, làm nổi bật chất
lượng dữ liệu và vai trò của phản hồi chuyên gia.
Trong một nhiệm vụ ngoại sinh về xác định tác giả,
chúng tôi cho thấy các giải thích được tạo ra bởi
các mô hình nhỏ hơn được tinh chỉnh trên E-GYAFC
có khả năng dự đoán tác giả tốt hơn so với các giải
thích được tạo ra bởi các mô hình giáo viên vài lần.

1 Giới thiệu
Chuyển đổi phong cách thuộc tính là nhiệm vụ biến
đổi một văn bản cho trước theo một chiều hướng
phong cách cụ thể, chẳng hạn như thay đổi tính
trang trọng, thiên vị, hoặc mức độ xúc phạm của
nó (Lample et al., 2019; Sudhakar et al., 2019; Jin
et al., 2022). Chuyển đổi phong cách trang trọng
(ví dụ, không trang trọng →trang trọng) có thể hữu
ích trong bất kỳ hệ thống hỗ trợ viết nào, trong khi
việc trung hòa văn bản chứa thiên vị chủ quan sẽ
là một công cụ quan trọng cho các biên tập viên
Wikipedia (Pryzant et al., 2020) hoặc nhà báo
(Rosenberg và Fischer, 2023).

Các phương pháp chuyển đổi phong cách chủ yếu
tập trung vào nhiệm vụ viết lại văn bản (ví dụ, không
trang trọng →trang trọng, thiên vị chủ quan →trung
tính) sử dụng các phương pháp khác nhau từ có
giám sát (Rao và Tetreault, 2018; Pryzant et al.,
2020; Zhong et al., 2021) đến không giám sát
(Krishna et al., 2020) và các phương pháp zero-shot
sử dụng LLM (Reif et al., 2022) (xem thêm Jin et
al. (2022) để có khảo sát về chuyển đổi phong cách).
Tuy nhiên, theo hiểu biết của chúng tôi, không có
nỗ lực nào tập trung vào việc cung cấp các giải thích
bằng văn bản cho nhiệm vụ chuyển đổi phong cách.
Ví dụ, khi biến đổi câu không trang trọng "I would
throw them out asap !" thành câu trang trọng "I
would dispose of them promptly", sẽ hữu ích khi
cung cấp giải thích về các thuộc tính không trang
trọng trong câu đầu vào (ví dụ, từ viết tắt ("asap"),
thành ngữ thông tục ("throw out")), và các thuộc
tính trang trọng cho câu diễn đạt lại (ví dụ, từ vựng
tinh tế ("promptly" và "dispose"); không có từ viết
tắt ("I would")). Tương tự, để trung hòa thiên vị
chủ quan trong "Orbis latinus, integral site of romance
language" →"Orbis latinus, comprehensive site of
romance language", sẽ hữu ích khi có giải thích về
từ/cụm từ nào trong đầu vào bị thiên vị và tại sao
cũng như loại thiên vị (ví dụ, Đóng khung ("integral"
ngụ ý một đánh giá chủ quan về tầm quan trọng
của trang web)). Các giải thích của mô hình có thể
giúp người dùng đánh giá tốt hơn về tính đúng đắn
của hệ thống chuyển đổi phong cách, có thể được
sử dụng như đặc trưng trong các nhiệm vụ hạ lưu
như xác định tác giả (Phần 5), hoặc có thể hoạt
động như một biện pháp phòng thủ chống lại các
tương quan giả tạo (Ludan et al., 2023; Camburu
et al., 2018) và các vật phẩm chú thích (McCoy et
al., 2019; Poliak et al., 2018).

Để cho phép khả năng giải thích trong các mô hình
chuyển đổi phong cách, chúng tôi cung cấp các
đóng góp sau:
•Một nhiệm vụ mới về chuyển đổi phong cách có
thể giải thích, trong đó, ngoài việc viết lại câu,
mô hình cần tạo ra các giải thích bằng văn bản.arXiv:2309.08583v2  [cs.CL]  17 Jun 2024

--- TRANG 2 ---
 GYAFCKhông trang trọng (si gốc): I would throw them out asap !e-GYAFCLLMDiễn đạt lại (sf tổng hợp):I would dispose of them promptly.Thuộc tính Trang trọng (ef tổng hợp):từ vựng tinh tế ("promptly", "dispose")không có từ rút gọn ("I would")Thuộc tính Không trang trọng Đã sửa (iclef-ei):từ viết tắt ("asap"), thành ngữ thông tục ("throw out"), dấu cảm thánThuộc tính Không trang trọng (ei tổng hợp):từ viết tắt ("asap"), thành ngữ thông tục ("throw out"), dấu cảm thán, ngôn ngữ viết tắt ("I would")       ICLEFLLMphê bìnhPhản hồi Chuyên gia
Trang trọng (sf gốc): I would kick them out as soon as possibleHình 1: Tạo ra E-GYAFC: tập dữ liệu chuyển đổi phong cách trang trọng GYAFC (Rao và Tetreault, 2018) được bổ sung
với các giải thích ngôn ngữ tự nhiên bán cấu trúc. LLM tạo ra các thuộc tính không trang trọng của câu đầu vào,
một câu diễn đạt lại trang trọng, và các thuộc tính trang trọng của câu kết quả. Phản hồi chuyên gia được kết hợp thông qua
học trong ngữ cảnh và tự phê bình để tinh chỉnh các thế hệ ban đầu.

•Một khung hợp tác người-AI mới, Học Trong
Ngữ Cảnh với Phản Hồi Chuyên Gia (ICLEF)
(xem Hình 1, Hình 2, và §3.2). Phương pháp
này kết hợp chưng cất mô hình để tạo giải thích
(Ho et al., 2022; Magister et al., 2023) với khả
năng tự phê bình của LLM (Madaan et al., 2023;
Bai et al., 2022b; Saunders et al., 2022; Scheurer
et al., 2023, trong số những người khác), trong
đó người phê bình, không giống như trong công
trình trước đây, được khởi tạo với các minh chứng
chuyên gia.

•Sử dụng ICLEF, chúng tôi tạo ra lần đầu tiên
các tập dữ liệu cho chuyển đổi phong cách có
thể giải thích bằng cách bổ sung tập dữ liệu
chuyển đổi phong cách trang trọng hiện có
GYAFC (Rao và Tetreault, 2018) và tập dữ liệu
trung hòa thiên vị chủ quan WNC (Pryzant et
al., 2020) với các giải thích bằng văn bản (§3).
Chúng tôi cho thấy các tập dữ liệu được tạo ra
với sự hỗ trợ của ICLEF, E-GYAFC và E-WNC,
có chất lượng tốt thông qua đánh giá tự động
và chuyên gia, và các thể hiện được ICLEF sửa
chữa được ưa chuộng (§3.3).

•Các thí nghiệm cho thấy các mô hình học sinh
vượt trội so với các mô hình giáo viên trong cài
đặt một lần và hoạt động tương đương ngay cả
với các mô hình giáo viên vài lần trong đánh giá
tự động và chuyên gia, xác nhận tiện ích và chất
lượng của các tập dữ liệu (§4). Hơn nữa, trong
một đánh giá ngoại sinh, chúng tôi cho thấy các
giải thích được tạo ra bởi các mô hình học sinh
được tinh chỉnh trên dữ liệu của chúng tôi tạo
ra tín hiệu tốt hơn cho nhiệm vụ xác định tác
giả so với các giải thích được tạo ra bởi các mô
hình giáo viên vài lần (§5).

Chúng tôi phát hành dữ liệu, mô hình và mã để khuyến
khích nghiên cứu thêm về khả năng giải thích, học
từ phản hồi con người hiếm hoi, và chuyển đổi phong
cách.1

2 Công trình liên quan
Chưng cất tri thức và phản hồi con người
Chưng cất mô hình hoặc tri thức là quá trình tinh
chỉnh một mô hình học sinh nhỏ hơn để bắt chước
hành vi của một mô hình giáo viên có năng lực hơn
(Beyer et al., 2022; Bucilǎ et al., 2006; Hinton et
al., 2015). Chưng cất tri thức trở thành một kỹ thuật
phổ biến, cho phép tạo ra các tập dữ liệu có chất
lượng tương tự như dữ liệu crowdsource (West et
al., 2022), đặc biệt khi kết hợp với phương pháp
mô hình trong vòng lặp (Wiegreffe et al., 2022;
Bartolo et al., 2022; Chakrabarty et al., 2022).
Nghiên cứu gần đây khám phá chưng cất mô hình
với các giải thích ngôn ngữ tự nhiên (Wang et al.,
2023a; Ho et al., 2022; Magister et al., 2023), cho
thấy các mô hình ngôn ngữ lớn có khả năng tạo ra
các bước lý luận đủ chấp nhận được để các mô hình
học sinh học hỏi. Các phương pháp kết hợp phản
hồi con người như RLHF (Stiennon et al., 2020)
và DPO (Rafailov et al., 2023) yêu cầu lượng lớn
dữ liệu crowdsource và nhìn chung chưa được chứng
minh là hiệu quả cho sở thích chuyên gia. Học bắt
chước từ phản hồi con người (ILF) (Scheurer et al.,
2023) sử dụng phản hồi con người để cải thiện các
thể hiện do mô hình tạo ra, và sau đó tinh chỉnh
trên dữ liệu đó. Không giống như các công trình
này, chúng tôi tập trung vào việc kết hợp phản hồi
chuyên gia vốn hiếm hoi và tốn kém để thu thập.
Không giống như các phương pháp tự phê bình
khác (Madaan et al., 2023; Bai et al., 2022b;
Saunders et al., 2022), chúng tôi điều kiện hóa mô
hình dựa trên các sửa chữa của chuyên gia để kết
hợp phản hồi con người chất lượng cao.

1github.com/asaakyan/explain-st

--- TRANG 3 ---
Giải thích bằng văn bản Các giải thích ngôn ngữ
tự nhiên đã được sử dụng cho nhiều nhiệm vụ khác
nhau Wiegreffe và Marasovic (2021), chẳng hạn
như suy luận ngôn ngữ tự nhiên (Camburu et al.,
2018), thường thức (Rajani et al., 2019; Aggarwal
et al., 2021), suy luận chuẩn mực xã hội (CH-Wang
et al., 2023). Chúng tôi tập trung vào việc tạo ra
các giải thích ngôn ngữ tự nhiên cho nhiệm vụ chuyển
đổi phong cách, điều chưa được giải quyết trước
đây.

Chuyển đổi phong cách Các phương pháp chuyển
đổi phong cách trải dài từ các phương pháp dựa
trên hướng dẫn (Reif et al., 2022) và diễn đạt lại
(Krishna et al., 2020), đến các phương pháp tập
trung vào học trong môi trường ít tài nguyên (Patel
et al., 2022). Phần lớn công trình chuyển đổi phong
cách tập trung vào các biểu diễn phong cách tách
biệt phong cách và nội dung (Wegmann et al., 2022;
Wegmann và Nguyen, 2021), tuy nhiên hầu hết
các phương pháp này không được thiết kế để có
thể diễn giải. Các phương pháp có thể diễn giải
dựa vào việc xây dựng các nhúng có thể diễn giải,
chẳng hạn như LIWC (Tausczik và Pennebaker,
2010) hoặc LISA (Patel et al., 2023). Zhong et al.
(2021) đề xuất xác định các phân đoạn thiên vị
kết hợp với việc trung hòa văn bản thiên vị. Không
giống như các phương pháp này, chúng tôi đề xuất
sử dụng các giải thích ngôn ngữ tự nhiên để tiếp
tục tăng cường khả năng diễn giải của mô hình.

3 Xây dựng Tập dữ liệu cho Chuyển đổi
Phong cách Có thể Giải thích

Chúng tôi xây dựng hai tập dữ liệu chuyển đổi phong
cách có thể giải thích bằng cách đầu tiên bổ sung
các tập dữ liệu hiện có với các giải thích bằng văn
bản tổng hợp được tạo ra bởi một mô hình giáo viên
(§3.1), và sau đó cải thiện dữ liệu được tạo ra bằng
cách sử dụng khung Học Trong Ngữ Cảnh với Phản
Hồi Chuyên Gia (ICLEF) của chúng tôi (§3.2).

3.1 Bổ sung các Tập dữ liệu Chuyển đổi Phong
cách với Giải thích Bằng văn bản Tổng hợp

Chuyển đổi phong cách trang trọng Tập dữ liệu
chuyển đổi phong cách trang trọng GYAFC (Rao
và Tetreault, 2018) chứa các câu trang trọng và
không trang trọng song song. Các câu không trang
trọng được thu thập từ Yahoo Answers, và các câu
diễn đạt lại trang trọng được crowdsource bằng
Amazon Mechanical Turk (AMT). Chúng tôi sử
dụng ChatGPT-3.5 để tạo ra các giải thích và xây
dựng nhiệm vụ tạo ra nhiều bước sau: cho một câu
không trang trọng từ GYAFC si, tạo ra một giải
thích có cấu trúc về các thuộc tính không trang
trọng ei của nó, sau đó tạo ra một câu diễn đạt lại
trang trọng sf dựa trên các thuộc tính này, sau đó
là các thuộc tính trang trọng của câu diễn đạt lại
ef. Việc tạo ra cả ei và ef cho phép chúng tôi huấn
luyện các mô hình trong cả hai hướng (trang trọng
→không trang trọng và không trang trọng →trang
trọng). Chúng tôi sử dụng định dạng bán cấu trúc
cho các giải thích. Cụ thể, chúng tôi yêu cầu mô
hình tạo ra một danh sách các thuộc tính theo sau
bởi một đoạn trích từ câu làm bằng chứng: thuộc
tính ("bằng chứng"), xem ví dụ trong Hình 1. Các
giải thích này có định dạng nhất quán, giúp việc
xác minh và đánh giá tự động dễ dàng hơn.

Chuyển đổi phong cách thiên vị chủ quan Chúng
tôi tập trung vào nhiệm vụ trung hòa ngôn ngữ thiên
vị chủ quan được giới thiệu bởi Pryzant et al. (2020)
để làm cho các câu tuân theo Chính sách Quan điểm
Trung tính của Wikipedia.2 Chúng tôi bắt đầu với
Wikipedia Neutrality Corpus (WNC) (Pryzant et
al., 2020), một tập hợp song song gồm 180.000
cặp câu có nguồn gốc từ các chỉnh sửa Wikipedia
về ngôn ngữ thiên vị chủ quan. Mục tiêu là tạo ra
một giải thích (eb) cho loại thiên vị có trong câu
thiên vị (sb), theo sơ đồ được đề xuất bởi Pryzant
et al. (2020) và Recasens et al. (2013): Đóng khung,
Nhận thức luận, và Nhân khẩu học (xem định nghĩa
trong Phụ lục I). Pryzant et al. (2020) ước tính
rằng một tỷ lệ nhỏ các trường hợp, các thể hiện
trong WNC chứa nhiễu. Chúng tôi thêm nhãn "Không
có Thiên vị" bổ sung cho những trường hợp này để
giảm thiên vị ảo giác cho các câu trung tính. Trong
trường hợp này, chúng tôi yêu cầu mô hình xuất
ra "Câu này không chứa thiên vị" làm giải thích
(xem ví dụ WNC thứ hai trong Bảng 1). Giải thích
được cấu trúc như Loại Thiên vị ("bằng chứng"
lý luận). Sau đó, mô hình giáo viên tạo ra một câu
diễn đạt lại không thiên vị (sn). Xem Hình 2 để
có cái nhìn tổng quan. Vào thời điểm chúng tôi phát
triển tập dữ liệu này, ChatGPT-4 đã có sẵn, vì vậy
chúng tôi sử dụng mô hình mạnh mẽ hơn này làm
giáo viên, đặc biệt vì việc tạo ra các giải thích cho
nhiệm vụ này có thể yêu cầu nhiều khả năng lý luận
hơn. Chúng tôi không tạo ra các giải thích cho tính
trung tính của câu diễn đạt lại vì chúng tôi không
khám phá hướng từ trung tính sang thiên vị do lo
ngại về đạo đức.

3.2 Học Trong Ngữ Cảnh từ Phản Hồi Chuyên
Gia (ICLEF)

Các thế hệ ChatGPT có thể chứa lỗi (ví dụ, thuộc
tính phong cách được tạo ra "ngôn ngữ viết tắt"
với bằng chứng "I would" trong Hình 1). Để cải
thiện chất lượng dữ liệu, chúng tôi chuyển sang
phản hồi chuyên gia, vì công trình trước đây đã
xác định rằng các công nhân đám đông trên các
nền tảng như Amazon Mechanical Turk có thể
không đáng tin cậy cho việc tạo ra mở (Karpinska
et al., 2021), và thậm chí có thể dựa vào ChatGPT
để cung cấp câu trả lời của họ (Veselovsky et al.,
2023). Điểm mấu chốt của phương pháp chúng tôi
là kết hợp khả năng học trong ngữ cảnh và tự phê
bình của LLM bằng cách khởi tạo mô hình LLM-
phê bình với các minh chứng phản hồi chuyên gia
vài lần.

2Wikipedia.org

--- TRANG 4 ---
 WNC       ICLEFThiên vị (sb gốc): orbis latinus, integral site on romance languagese-WNCDiễn đạt lại (iclef-sn):Orbis Latinus, a comprehensive site on Romance languagesLLMphê bìnhPhản hồi Chuyên giaThuộc tính Thiên vị Đã sửa (iclef-eb):Đóng khung ("integral" ngụ ý một đánh giá chủ quan về tầm quan trọng của trang web)Thuộc tính Thiên vị (eb tổng hợp):Nhận thức luận ("integral" ngụ ý rằng trang web là thiết yếu hoặc không thể thiếu cho các ngôn ngữ Romance)

Trung tính (sn gốc): orbis latinus, site on romance languagesLLMHình 2: Tạo ra E-WNC: WNC (Pryzant et al., 2020) được bổ sung với các giải thích ngôn ngữ tự nhiên. 
LLM tạo ra các thuộc tính thiên vị của câu đầu vào và một câu diễn đạt lại không thiên vị. Phản hồi chuyên gia được kết hợp
thông qua học trong ngữ cảnh và tự phê bình để tinh chỉnh các thế hệ ban đầu.

E-GYAFC Đối với nhiệm vụ chuyển đổi phong cách
trang trọng, chúng tôi thuê một chuyên gia chú thích
có bằng Thạc sĩ ngôn ngữ học trên Upwork3. Giao
thức chú thích của chúng tôi (xem Phụ lục J) cung
cấp một tham chiếu không đầy đủ về các thuộc tính
trang trọng và không trang trọng và yêu cầu người
chú thích cung cấp phản hồi về thuộc tính nào trong
ei, ef là không chính xác nếu có, cùng với các thông
tin khác. Chúng tôi cung cấp 50 mẫu ngẫu nhiên
để chú thích. Quá trình chú thích chỉ mất 2-3 giờ
cho mỗi chuyên gia. Chúng tôi thấy rằng tỷ lệ lỗi
nghiêm trọng quan sát được trong các giải thích
trang trọng thấp hơn đáng kể ((≈8% cho các giải
thích trang trọng so với ≈56% cho các giải thích
không trang trọng), vì vậy chúng tôi chỉ tập trung
vào việc áp dụng LLM-phê bình cho các thuộc tính
không trang trọng không chính xác (ei).

Để làm điều đó, chúng tôi khởi tạo một mô hình
LLM-Phê bình bằng cách nhắc một LLM khác
(ChatGPT-3.5) với 35 sửa chữa phản hồi chuyên
gia con người trong ngữ cảnh (chúng tôi thấy rằng
số lượng này dẫn đến độ chính xác thỏa mãn ≈87%,
xem Phụ lục C về cách hiệu suất thay đổi tùy theo
lượng phản hồi) và yêu cầu nó hoạt động như một
người chú thích trên các thể hiện mới để xác định
các thuộc tính không chính xác trong chúng (xem
lời nhắc trong Bảng 12 trong Phụ lục E). Để giảm
thiểu rủi ro tạo ra các thuộc tính không chính xác
mới, chúng tôi chỉ truy vấn mô hình để xác định
và loại bỏ các thuộc tính không chính xác trong ei,
và nếu có, cung cấp một iclef-ei đã sửa trong đó
chúng được loại bỏ. Chúng tôi gọi mô hình kết quả
là LLM-Phê bình (xem cách ngôn ngữ viết tắt được
loại bỏ trong Hình 1).

Bằng cách này, chúng tôi sửa ≈30% dữ liệu được
tạo ra (2853 thể hiện) – tất cả các thể hiện mà người
phê bình đã dự đoán cần cải thiện. Dữ liệu kết quả
(mà chúng tôi gọi là E-GYAFC) chứa 9.960 si gốc,
các thể hiện sf tổng hợp với iclef-ei, các giải thích
thuộc tính ef tổng hợp tương ứng. Chúng tôi chia
ngẫu nhiên dữ liệu thành 8.000 thể hiện huấn luyện
và 1.960 thể hiện kiểm tra được giữ lại.

3Upwork.com

E-WNC Đối với nhiệm vụ trung hòa thiên vị chủ
quan, chúng tôi thuê một chuyên gia chú thích có
bằng Tiến sĩ ngôn ngữ học trên Upwork. Chúng
tôi cung cấp 50 mẫu ngẫu nhiên đảm bảo đại diện
bình đẳng cho mỗi loại thiên vị. Để chống lại thiên
vị chú thích tiềm ẩn, chúng tôi quyết định sử dụng
hai người chú thích, một trong số các tác giả hoạt
động như người chú thích bổ sung, và sau đó lấy
mẫu ngẫu nhiên các thể hiện theo tỷ lệ bằng nhau.
Giao thức chú thích yêu cầu cung cấp một giải thích
đã sửa thay vì eb nếu giải thích tổng hợp chứa loại
thiên vị không chính xác hoặc lý luận sai. Chúng
tôi lấy mẫu ngẫu nhiên 35 thể hiện riêng biệt từ
phản hồi của hai người chú thích, thấy rằng số lượng
này dẫn đến độ chính xác thỏa mãn ≈93% (xem
Phụ lục C). Chúng tôi cung cấp các phê bình chuyên
gia trong ngữ cảnh theo cách tương tự như E-GYAFC
(xem lời nhắc dưới cùng trong Phụ lục E, Bảng 12).
Vì các thuộc tính thiên vị mới có thể đã được giới
thiệu, chúng tôi tái tạo câu diễn đạt lại sn dựa trên
giải thích mới (xem loại thiên vị đã sửa và câu diễn
đạt lại mới trong Hình 2). Chúng tôi sửa 8% các
giải thích tổng hợp theo cách này (tỷ lệ lỗi thấp hơn
được giải thích bởi chất lượng cao hơn của các thế
hệ ban đầu do sử dụng mô hình ChatGPT-4 mạnh
mẽ hơn). Tập dữ liệu kết quả (E-WNC) chứa 3.000
câu sb thiên vị WNC gốc, các giải thích iclef-eb
thiên vị, cũng như các câu iclef-sn đã trung hòa
tương ứng. Chúng tôi chia ngẫu nhiên dữ liệu thành
2.500 thể hiện huấn luyện và 500 thể hiện kiểm
tra được giữ lại.

--- TRANG 5 ---
Không trang trọng (si) Giải thích tạo ra (ei tổng hợp) Giải thích ICLEF (iclef-ei)
hopefully you aren't too old or you are
screwed.lời chào không trang trọng ("hopefully"), tiếng lóng
("screwed"), từ rút gọn ("aren't")tiếng lóng ("screwed"), từ rút gọn
("aren't")
more info, we are both in our very late
twenties.[...], bỏ qua giới từ ("in our
very late twenties")từ viết tắt ("info"), thành ngữ thông tục
("very late twenties")

Thiên vị (sb) Giải thích tạo ra (eb tổng hợp) Giải thích ICLEF (iclef-eb)
[...] a play on the title of the popular
mtv series, "unplugged".Nhận thức luận ("popular" ngụ ý rằng
series MTV được yêu thích phổ biến)Đóng khung ("popular" là một thuật ngữ chủ quan
ngụ ý series MTV được yêu thích rộng rãi)
[..] kendal, cbe (born 25 september
1946) is an english actress known in
the united kingdom [...].Nhân khẩu học ("actress" ngụ ý rằng
người đó là nữ và có thể duy trì
định kiến hoặc giả định về giới tính)Câu này không chứa thiên vị.
claims for the existence of paranormal
psychic abilities such as clairvoyance
are highly controversial.Câu này không chứa thiên vị. Nhận thức luận ("highly controversial"
ngụ ý rằng sự tồn tại của khả năng
tâm linh siêu nhiên bị tranh cãi rộng rãi)

Bảng 1: So sánh định tính các thể hiện tập dữ liệu trước và sau khi áp dụng ICLEF.

3.3 Chất lượng tập dữ liệu
Đánh giá tự động chất lượng diễn đạt lại
Chúng tôi ước tính chất lượng diễn đạt lại tự động
bằng cách sử dụng Điểm Hàm ý Tương hỗ (MIS)
(Babakov et al., 2022) và Điểm Trang trọng (xem
§4.2 cho chi tiết các chỉ số) giữa các câu diễn đạt
lại trang trọng của chúng tôi và những câu trong
GYAFC. Chúng tôi thấy rằng các câu diễn đạt lại
của chúng tôi có chất lượng tương đương với MIS
là 81.30 so với 83.08 cho GYAFC, tuy nhiên chúng
tôi đạt được điểm trang trọng cao hơn là 98.43 so
với 89.39 cho GYAFC (xem Bảng 2). Ví dụ, đối
với ví dụ GYAFC trong Hình 1, câu diễn đạt lại
trang trọng chứa kick them out). Tương tự, đối với
tập dữ liệu E-WNC, chúng tôi báo cáo điểm thiên
vị từ một bộ phân loại có sẵn (xem §4.2) cùng với
MIS. Điểm MIS là 79.32 cho các câu diễn đạt lại
gốc so với 85.58 cho các câu diễn đạt lại của chúng
tôi, cho thấy độ tương tự ngữ nghĩa cao hơn. Điểm
trung tính là 69.34 so với 72.64, cho thấy tính trung
tính cao hơn của các câu diễn đạt lại của chúng tôi
(xem Bảng 2).

e-GYAFC e-WNC
MIS Trang trọng MIS Trung tính
Diễn đ. gốc 83.08 89.39 79.32 69.34
Diễn đ. ứng viên 81.30 98.43 85.58 72.64

Bảng 2: Các câu diễn đạt lại tổng hợp (được tạo ra thông qua
chưng cất mô hình cho E-GYAFC và E-WNC) thể hiện chất
lượng tổng thể cao hơn trong đánh giá tự động so với các
câu diễn đạt lại gốc (từ GYAFC và WNC, tương ứng).

Đánh giá con người Đối với E-GYAFC, chúng tôi
thuê 3 chuyên gia chú thích, 2 trong số họ đã thực
hiện chú thích, cũng như một chuyên gia chú thích
độc lập có bằng thạc sĩ ngôn ngữ học. Chúng tôi
hỏi sở thích của họ về 100 thể hiện được lấy mẫu
ngẫu nhiên liên quan đến các giải thích (ei tổng
hợp so với iclef-ei) và các câu diễn đạt lại (sf gốc
trong GYAFC so với sf tổng hợp trong E-GYAFC).
Ngoài ra, chúng tôi yêu cầu đánh giá về tính chấp
nhận được (liệu câu diễn đạt lại hoặc giải thích có
đúng và đầy đủ không) cho câu diễn đạt lại được
ưa chuộng và riêng biệt cho ef. Chúng tôi báo cáo
tỷ lệ sở thích hoặc bằng nhau và tỷ lệ chấp nhận
được.4 Nhìn chung, chúng tôi thấy rằng các thể
hiện tập dữ liệu của chúng tôi được coi là chấp nhận
được, với tỷ lệ chấp nhận trung bình cho ei, sf, ef
lần lượt là 87%, 77%, 98% (hàng 1 trong Bảng 3).
Các câu diễn đạt lại tổng hợp thường được ưa chuộng
hơn so với những câu trong tập GYAFC (trung bình
77%), và các giải thích iclef được ưa chuộng hoặc
có chất lượng ngang bằng với các thế hệ gốc trung
bình trong 90% trường hợp (hàng 2 trong Bảng 3).
Chúng tôi tính toán độ chính xác theo cặp giữa các
phản hồi của người chú thích cho tất cả các danh
mục đánh giá E-GYAFC, và thấy rằng nó trung bình
ở mức 81% trên tất cả các danh mục. Chúng tôi cung
cấp thêm chi tiết trong Phụ lục A.

Bảng 1 cho thấy các ví dụ định tính về các chỉnh
sửa thành công với ICLEF. Hình 3 cho thấy 10
thuộc tính không trang trọng thường xuất hiện nhất.

e-GYAFC e-WNC
ei sf ef eb sn
Chấp nhận được 87% 77% 98% 73% 74%
Sở thích 90% 77% - 78% 77%

Bảng 3: Tỷ lệ Chấp nhận được và Sở thích (giữa giải thích
tổng hợp so với giải thích iclef, và câu diễn đạt lại tổng
hợp so với câu diễn đạt lại gốc từ tập dữ liệu) cho E-GYAFC
và E-WNC.

Đối với E-WNC, chúng tôi thuê 2 người chú thích,
một trong số họ đã thực hiện chú thích ICLEF. Để
đánh giá có ý nghĩa sở thích của các giải thích iclef
so với các giải thích tổng hợp, chúng tôi yêu cầu
cung cấp phản hồi về 50 thể hiện mà giải thích đã
được cập nhật. Sở thích trung bình cho iclef-eb so
với eb tổng hợp là 78%. Tỷ lệ chấp nhận trung bình
của iclef-eb là 73%. Sở thích trung bình cho sn tổng
hợp so với câu trung tính trong tập E-WNC là 76%.
Tỷ lệ chấp nhận trung bình của sn tổng hợp là 74%.
Độ chính xác theo cặp giữa các người chú thích là
77%. Thêm chi tiết có thể được tìm thấy trong Phụ
lục B.

4Chúng tôi tính toán sở thích hoặc sở thích bằng nhau trong
số các thể hiện chấp nhận được. Đối với tính chấp nhận, chúng
tôi tính toán các thể hiện không được ưa chuộng như không
chấp nhận được.

--- TRANG 6 ---
0 1000 2000 3000 4000
Tần suấttừ rút gọn
thành ngữ thông tục
từ viết tắt
đại từ nhân xưng
tiếng lóng
giọng điệu thường
dấu câu không trang trọng
viết hoa
từ vựng không trang trọng
từ viết tắtThuộc tính

Hình 3: Top 10 thuộc tính không trang trọng. Xem top 50
thuộc tính (không) trang trọng trong Hình 5, 6 Phụ lục).

4 Đánh giá Mô hình Học sinh và Giáo viên
trên Nhiệm vụ Chuyển đổi Phong cách
Có thể Giải thích

Chúng tôi tập trung vào việc đánh giá hiệu suất của
các mô hình ngôn ngữ lớn được chọn trên nhiệm
vụ chuyển đổi phong cách có thể giải thích. Chúng
tôi không đánh giá các hệ thống lý luận hậu hoc
(tạo ra thuộc tính dựa trên cặp diễn đạt lại), vì các
mô hình pipeline như vậy ít có khả năng phản ánh
những lý do cơ bản cho dự đoán mô hình, trong
khi các mô hình dự đoán và lý luận đồng thời thể
hiện các thuộc tính mong muốn cho các giải thích
trung thực (Wiegreffe et al., 2021). Đối với chuyển
đổi phong cách trang trọng có thể giải thích, chúng
tôi kiểm tra việc tạo ra ef, si, ei cho sf (Trang trọng
→Không trang trọng) và ei, sf, ef cho si (Không
trang trọng →Trang trọng) trên tập kiểm tra được
giữ lại từ E-GYAFC. Chúng tôi đánh giá mức độ
gần gũi của ei, ef do mô hình tạo ra so với các giải
thích E-GYAFC, và chúng tôi đánh giá sự gần gũi
về ngữ nghĩa và chất lượng diễn đạt lại cho si, sf
với các chỉ số không tham chiếu. Tương tự, chúng
tôi đánh giá eb, sn cho nhiệm vụ trung hòa thiên
vị chủ quan sử dụng tập kiểm tra từ E-WNC. Chúng
tôi báo cáo điểm F1 cho phân loại thiên vị trong sn.

4.1 Mô hình
Chúng tôi kiểm tra hai mô hình học sinh nhỏ hơn
được tinh chỉnh trên các tập dữ liệu của chúng tôi.
Chúng tôi tinh chỉnh các mô hình LLaMA-7B (Touvron
et al., 2023) và Alpaca-7B (Taori et al., 2023) trên
dữ liệu của chúng tôi được chuyển đổi sang định
dạng hướng dẫn Alpaca. Đối với chuyển đổi phong
cách trang trọng, chúng tôi tinh chỉnh trong cả hai
hướng Trang trọng →Không trang trọng và Không
trang trọng →Trang trọng riêng biệt (→), cũng như
trong cả hai hướng theo cách đa nhiệm vụ (↔).
Đối với chuyển đổi thiên vị chủ quan, chúng tôi
chỉ tinh chỉnh theo một hướng. Ngoài ra, chúng tôi
kiểm tra các mô hình giáo viên (ChatGPT-3.5=GPT-
3.5 và ChatGPT-4=GPT-4) trong cài đặt vài lần,
đây là một đường cơ sở đầy tham vọng: đầu tiên,
chúng được sử dụng để tạo dữ liệu làm thiên vị các
chỉ số dựa trên tham chiếu, thứ hai, chúng được
nhắc với các thể hiện cải thiện của dữ liệu. Vì các
mô hình giáo viên là các mô hình đóng, chúng tôi
cũng kiểm tra một mô hình mở được điều chỉnh
hướng dẫn đại diện lớn hơn học sinh, Vicuna-13B
(Chiang et al., 2023) (Vic trong bảng), trong cài
đặt vài lần. Xem mô tả chi tiết về các mô hình,
siêu tham số, lời nhắc, và các thí nghiệm bổ sung
trong Phụ lục F.

4.2 Đánh giá Tự động
Chúng tôi sử dụng các chỉ số sau:
•BLEU (Papineni et al., 2002): Chúng tôi đo
lượng thuộc tính trang trọng và không trang
trọng cũng như bằng chứng khớp chính xác
giữa giải thích có cấu trúc được tạo ra và giải
thích tham chiếu trong E-GYAFC và E-WNC.
•Điểm Hàm ý Tương hỗ (MIS) (Babakov et al.,
2022) là một thước đo đối xứng về độ tương tự
ngữ nghĩa văn bản dựa trên mô hình RoBERTa
(Liu et al., 2019) được tinh chỉnh cho suy luận
ngôn ngữ tự nhiên và phát hiện diễn đạt lại
được sử dụng trong công trình trước đây (ví
dụ, Patel et al., 2022).
•Độ Chính xác Phong cách: Đối với E-GYAFC,
chúng tôi sử dụng Điểm Trang trọng/Không
trang trọng5: RoBERTa (Liu et al., 2019) được
tinh chỉnh để dự đoán liệu các câu có trang
trọng hay không trang trọng bằng cách sử dụng
GYAFC và Online Formality Corpus (OFC)
(Pavlick và Tetreault, 2016). Nó đạt được lên
đến 0.98 ROC AUC. Đối với E-WNC, chúng
tôi sử dụng Điểm Thiên vị6: mô hình DistilBERT
(Sanh et al., 2020) được tinh chỉnh cho phân
loại thiên vị trên tập dữ liệu thiên vị truyền
thông BABE được chú thích bởi các chuyên
gia (Spinde et al., 2021), trên đó nó đạt được
điểm F1 lên đến 79.

Cho rằng nhiệm vụ phát hiện loại thiên vị có thể
được xem như một nhiệm vụ phân loại (chỉ có 3
nhãn), chúng tôi báo cáo điểm F1 cho phân loại
loại thiên vị trong giải thích. Chúng tôi cũng báo
cáo trung bình trên tất cả các chỉ số.

5huggingface.co/s-nlp/roberta-base-formality-ranker
6huggingface.co/social-media-fairness/classifier-bias-sg

--- TRANG 7 ---
Trang trọng→Không trang trọng Không trang trọng →Trang trọng
Mô hình KíchthướcThuộctínhTrtrọng
BLEUMISKhông trtrọngThuộctínhKhông trtrọng
BLEUThuộctínhKhông trtrọng
BLEUMISTrang trọngThuộc tínhTrtrọng
BLEUTrung bình
Vic1 13B 23.16 83.24 35.26 10.97 27.31 61.22 98.70 9.88 43.72
Vic5 13B 24.16 85.18 33.58 13.09 27.95 73.18 98.20 15.45 46.35
Vic10 13B 19.78 82.00 49.17 12.35 30.97 73.26 97.86 17.14 47.82
GPT-3.5 1 ? 28.88 90.12 39.65 12.80 27.65 81.98 97.68 10.36 48.64
GPT-3.5 5 ? 33.98 90.37 38.23 16.14 36.03 85.37 97.54 16.30 51.74
GPT-3.5 10 ? 36.78 89.57 49.81 18.51 37.36 85.62 97.75 20.31 54.46
LLaMA → 7B 39.64 85.31 61.33 19.86 38.02 81.80 97.77 25.10 56.10
Alpaca ↔ 7B 40.42 81.76 66.71 21.11 40.34 79.43 98.57 25.75 56.76

Bảng 4: Hiệu suất của các mô hình được điều chỉnh hướng dẫn và tinh chỉnh trên nhiệm vụ chuyển đổi phong cách trang trọng có thể giải thích.
Tốt nhất được in đậm, tốt nhất không tinh chỉnh được gạch chân.

Kết quả Bảng 4 cho thấy hiệu suất mô hình trên
nhiệm vụ chuyển đổi phong cách trang trọng có thể
giải thích. Trong khi mô hình Vicuna hoạt động tốt
về mặt chuyển đổi phong cách (như được chứng
minh bởi điểm MIS và Trang trọng cao), nó thiếu
về chất lượng giải thích (điểm BLEU tổng thể thấp).
Các mô hình học sinh hoạt động tốt hơn so với mô
hình giáo viên một lần và cạnh tranh trong kịch
bản 10 lần dựa trên điểm Trung bình. Bảng 5 cho
thấy hiệu suất mô hình trên nhiệm vụ chuyển đổi
phong cách thiên vị chủ quan có thể giải thích. Tương
tự, các mô hình học sinh vượt trội so với mô hình
giáo viên trong cài đặt một lần. Chúng cũng vượt
trội so với các mô hình vài lần yếu hơn so với mô
hình giáo viên (Vicuna và GPT-3.5).

Về hiệu suất chuyển đổi phong cách mà không
xem xét các giải thích, chúng tôi thấy sự giảm nhẹ
trong các nhiệm vụ Không trang trọng →Trang
trọng (-0.93% trung bình MIS và Trang trọng so
với mô hình giáo viên một lần) và Thiên vị→Không
thiên vị (-2.13% trung bình MIS và Trung tính).
Điều này được mong đợi vì phù hợp với công trình
trước đây như e-SNLI (Camburu et al., 2018).7
Chúng tôi thấy sự tăng đáng kể trong hiệu suất
cho hướng Trang trọng→Không trang trọng
(+12.60%). Điểm không trang trọng tốt hơn nhiều
cho các mô hình học sinh, có lẽ do xu hướng tạo
ra lời nói trang trọng hơn của cả mô hình giáo viên
và các mô hình hướng dẫn khác.

Mô hình F1Thuộc tínhThuộc tính
BLEUMISDiểm Trung tínhTrung bình
Vic1 17.49 2.88 74.61 68.33 48.61
Vic5 16.28 9.58 81.22 73.12 54.64
Vic10 23.08 9.35 84.66 74.90 56.30
GPT-3.5 1 34.83 8.15 83.18 75.07 55.47
GPT-3.5 5 28.78 13.94 81.71 73.11 56.25
GPT-3.5 10 37.83 17.25 82.92 73.18 57.78
GPT-4 1 36.87 12.33 82.38 75.72 56.81
GPT-4 5 41.24 14.91 82.36 75.48 57.58
GPT-4 10 39.82 17.07 83.48 74.87 58.47
Alpaca → 65.03 24.46 82.57 71.63 59.55
LLaMA → 67.25 25.81 83.48 71.33 60.21

Bảng 5: Hiệu suất trên chuyển đổi phong cách có thể giải thích Thiên vị →Không thiên vị. GPT-3.5 = ChatGPT-3.5, GPT-4 =
ChatGPT-4, Vic = Vicuna-13B. Số lượng lần trong chỉ số dưới. Điểm tốt nhất được in đậm.

7"...trong khi hy sinh một chút hiệu suất, chúng ta có được
sự tin tưởng tốt hơn rằng khi EXPLAINTHENPREDICT dự
đoán một nhãn đúng, nó làm vậy vì những lý do đúng đắn."

4.3 Đánh giá Chuyên gia Con người: Đánh giá
Sở thích

Chúng tôi đánh giá mức độ phù hợp của đầu ra mô
hình với sở thích chuyên gia. Đối với e-GYAFC,
chúng tôi lấy mẫu 100 thể hiện từ tập kiểm tra và
các đầu ra mô hình tương ứng từ Vic 1, mô hình
giáo viên GPT-3.5 trong cài đặt một lần (GPT-3.5 1),
và mô hình học sinh tinh chỉnh tốt nhất. Chúng tôi
hỏi sở thích của họ về tính đúng đắn và đầy đủ của
các giải thích, cũng như về việc bảo tồn ngữ nghĩa
của câu diễn đạt lại. Chúng tôi thấy rằng các thế
hệ mô hình học sinh (Alpaca ↔) được ưa chuộng
hơn so với mô hình giáo viên GPT-3.5 1 và Vicuna 1
53% thời gian bởi chuyên gia ngôn ngữ học (GPT-
3.5 1 được ưa chuộng 42%), cho thấy mô hình học
sinh phù hợp hơn với sở thích chuyên gia. Xem ví
dụ định tính trong Bảng 6. Chúng tôi cũng đánh
giá mức độ hoạt động tốt của các mô hình tinh chỉnh
nhỏ hơn so với mô hình giáo viên trong cài đặt vài
lần. Chúng tôi lấy mẫu 40 đầu ra và hỏi sở thích
giữa các thế hệ từ Vicuna và GPT-3.5 trong cài đặt
10 lần (GPT-3.510) cũng như mô hình học sinh
tinh chỉnh. Mô hình tinh chỉnh hoạt động cạnh tranh
với 49% sở thích cho GPT-3.5 10 và 43% sở thích
cho mô hình học sinh tinh chỉnh nhỏ.

Tương tự, chúng tôi thuê một chuyên gia chú thích
và cung cấp 50 thể hiện tập kiểm tra từ E-WNC
cùng với đầu ra mô hình từ GPT-3.5 10 (yếu hơn
so với mô hình giáo viên), Vicuna 10 lần, và mô
hình học sinh tinh chỉnh tốt nhất (LLaMA →). Chúng
tôi thấy rằng LLaMA → được ưa chuộng với tỷ lệ
56%, tiếp theo là GPT-3.5 10 (24%). Xem ví dụ
định tính trong Bảng 7. Chúng tôi cũng đo sở thích
so với mô hình giáo viên một lần (GPT-4 1), thấy
sở thích tương đương 42% cho LLaMA → và 40%
cho GPT-4 1.

--- TRANG 8 ---
Trang trọng (Đầu vào)
If it is feasible, allow love to prevail.
Vicuna 1
-Thuộc tính Trang trọng: thể bị động ("it is feasible", "allow love to prevail"), sử dụng động từ "to be" ("is feasible", "prevail")
-Diễn đạt lại Không trang trọng: It's okay to let love rule.
-Thuộc tính Không trang trọng: thể chủ động ("it's okay", "let love rule"), sử dụng động từ không trang trọng ("rule")

GPT 1
-Thuộc tính Trang trọng: mệnh đề điều kiện ("if it is feasible"), từ vựng cao cấp ("allow love to prevail")
-Diễn đạt lại Không trang trọng: If it's possible, just go with love.
-Thuộc tính Không trang trọng: ngôn ngữ đơn giản ("if it's possible"), dạng mệnh lệnh ("just go"), từ rút gọn ("it's")

Alpaca ↔
-Thuộc tính Trang trọng: ngôn ngữ chính xác ("feasible"), sử dụng mệnh đề điều kiện ("if it is feasible"), từ vựng tinh tế ("prevail")
-Diễn đạt lại Không trang trọng: let love win if it's possible.
-Thuộc tính Không trang trọng: từ rút gọn ("it's"), giọng điệu thường ("let love win")

Bảng 6: So sánh giữa các thế hệ từ mô hình được điều chỉnh hướng dẫn một lần (Vicuna, ChatGPT), và mô hình học sinh tinh chỉnh nhỏ tốt nhất của chúng tôi cho chuyển đổi phong cách trang trọng có thể giải thích.

5 Đánh giá Ngoại sinh của Giải thích Chuyển đổi Phong cách Trang trọng

Chúng tôi sử dụng Xác minh Tác giả (Martindale và McKenzie, 1995; Coulthard, 2004; Neal et al., 2017) như một nhiệm vụ ngoại sinh sử dụng dữ liệu PAN 2022 (Bevendorff et al., 2022). Đây là một nhiệm vụ phân loại nhị phân để quyết định liệu hai văn bản có thuộc về cùng một tác giả hay không. Hai văn bản đầu vào là hai tài liệu thô (ví dụ, đoạn văn từ bài đăng blog), một trong số đó được viết bởi tác giả A, và một khác được viết bởi cùng tác giả A hoặc bởi một tác giả khác B. Sau đó chúng tôi rút ra một biểu diễn (các đặc trưng được sử dụng cho phân loại) của các văn bản đầu vào này bằng cách sử dụng mô hình chuyển đổi phong cách có thể giải thích của chúng tôi. Chúng tôi chạy Alpaca IF→F trên mỗi văn bản (tối đa 15 câu cho mỗi tác giả được xem xét) và trích xuất các giải thích chứa các thuộc tính không trang trọng và bằng chứng (xem Bảng 8). Trong một đánh giá sơ bộ về tính hữu ích của các đặc trưng này, chúng tôi tính toán sự tương tự giữa các tác giả bằng cách đo tỷ lệ phần trăm các thuộc tính trùng lặp. Lưu ý rằng các đoạn bằng chứng tương ứng với các thuộc tính không được sử dụng trong thí nghiệm sơ bộ này. Sau đó chúng tôi sử dụng tỷ lệ phần trăm các thuộc tính trùng lặp như một điểm phân loại, ví dụ, nếu tác giả A sử dụng thành ngữ thông tục và từ viết tắt, và tác giả B sử dụng thành ngữ thông tục và từ viết tắt, điểm tương tự của họ là số thuộc tính chung chia cho số thuộc tính duy nhất giữa các tác giả, hoặc 1/3 (0.33). Ở đây, chỉ có 1 thuộc tính chung (thành ngữ thông tục) trong khi tổng số thuộc tính được xác định là 3 (thành ngữ thông tục, từ viết tắt, từ viết tắt). Theo tính toán được mô tả ở trên, chúng tôi lấy điểm tương tự như một độ tin cậy cho một nhiệm vụ dự đoán nhị phân. Nếu độ tương tự cao, có khả năng cao các tác giả giống nhau (dự đoán = 1), và nếu không thì họ có thể không giống nhau (dự đoán = 0). Giả định cơ bản là có khả năng cao hơn rằng cùng một tác giả sẽ sử dụng một số đặc trưng không trang trọng mà họ đã sử dụng trước đây (không phải mọi câu trong PAN đều hoàn toàn không trang trọng, nhưng tính không trang trọng là một danh mục rất rộng, vì vậy khi các tác giả sử dụng một số thuộc tính không trang trọng, chúng có thể cung cấp tín hiệu cho việc xác định tác giả). Chúng tôi tính toán ROC AUC giữa điểm độ tin cậy (điểm tương tự tác giả) và dự đoán sự thật cơ bản từ tập dữ liệu PAN (1 nếu các tác giả giống nhau và 0 nếu không). Chúng tôi so sánh các giải thích từ Vicuna 10, GPT-3.5 10 và Alpaca IF→F bằng tín hiệu dự đoán của chúng cho nhiệm vụ này. Các giải thích của Alpaca IF→F đạt được AUC là 56.4, trong khi các giải thích từ các mô hình Vicuna và GPT-3.5 đạt được điểm lần lượt là 50.0 và 47.0. Điều này cho thấy một ứng dụng tiềm năng của các giải thích được tạo ra bởi mô hình học sinh được tinh chỉnh trên tập dữ liệu của chúng tôi (E-GYAFC) để được sử dụng như các đặc trưng tác giả có thể diễn giải có thể được khám phá trong công trình tương lai.

Thiên vị (Đầu vào)
some cacti produce beautiful flowers, which like spines and branches arise from areoles.
-Thuộc tính Thiên vị (Vàng): Đóng khung ("beautiful" thêm tính chủ quan và ngụ ý một đánh giá tích cực về những bông hoa)

Vicuna 10 (Không chính xác)
-Thuộc tính Thiên vị: Đóng khung (sử dụng "some" gợi ý rằng không phải tất cả xương rồng đều tạo ra những bông hoa đẹp)
-Diễn đạt lại Đã trung hòa: Certain cacti produce beautiful flowers, which like spines and branches arise from areoles.

GPT-3.5 10 (Không chính xác)
-Thuộc tính Thiên vị: Nhận thức luận (sử dụng từ "beautiful" ngụ ý rằng những bông hoa được tạo ra bởi xương rồng được coi là hấp dẫn phổ biến)
-Diễn đạt lại Đã trung hòa: Some cacti produce flowers, which, like spines and branches, arise from areoles.

LLaMA → (Chính xác)
-Thuộc tính Thiên vị: Đóng khung ("beautiful" gợi ý một đánh giá chủ quan về những bông hoa)
-Diễn đạt lại Đã trung hòa: Some cacti produce flowers, which like spines and branches arise from areoles.

Bảng 7: So sánh giữa các thế hệ từ các mô hình được điều chỉnh hướng dẫn vài lần (Vicuna 10 lần, ChatGPT-3.5), và mô hình học sinh tinh chỉnh nhỏ tốt nhất của chúng tôi cho chuyển đổi phong cách thiên vị có thể giải thích.

Thuộc tính Bằng chứng
Thành ngữ thông tục "assumed they all started off low!?", "typing it out"
Từ viết tắt "xx"
Từ vựng Không trang trọng "give you a call", "arrange something"
Giọng điệu Không trang trọng "hoping to borrow a couple of charging leads"

Bảng 8: Các đặc trưng không trang trọng để xác định tác giả: bên trái, các thuộc tính không trang trọng được xác định bởi mô hình của chúng tôi, bên phải, bằng chứng văn bản được cung cấp bởi nó.

6 Kết luận

Chúng tôi đề xuất một khung để bổ sung hai tập dữ liệu chuyển đổi phong cách với các giải thích bằng văn bản bán cấu trúc. Để cải thiện chất lượng chưng cất mô hình và kết hợp phản hồi chuyên gia, chúng tôi đề xuất ICLEF (Học Trong Ngữ Cảnh từ Phản Hồi Chuyên Gia), một khung hợp tác người-AI mới tận dụng cả khả năng học trong ngữ cảnh và tự phê bình của LLM. Chúng tôi đánh giá các mô hình học sinh nhỏ hơn được tinh chỉnh trên các tập dữ liệu kết quả so với các mô hình giáo viên lớn và tiến hành đánh giá chuyên gia con người. Chúng tôi cũng đánh giá ngoại sinh các giải thích cho chuyển đổi phong cách trang trọng trên nhiệm vụ hạ lưu của xác định tác giả.

7 Hạn chế

Tập dữ liệu GYAFC không chứa tất cả các loại ngôn ngữ không trang trọng và trang trọng, cụ thể, chúng chủ yếu tập trung vào các mối quan hệ liên cá nhân (tập con được sử dụng cho bài báo này) và giải trí. Công trình tương lai có thể xem xét mở rộng phương pháp của chúng tôi cho các tập dữ liệu chuyển đổi phong cách khác, bao gồm những tập bao quát hơn về tính trang trọng.

Trong khi các phương pháp của chúng tôi nhằm tạo ra các giải thích trung thực, vẫn có thể có những trường hợp khi một mô hình không dựa vào các thuộc tính để hoàn thành câu diễn đạt lại. Chúng tôi cũng quan sát thấy rằng các ảo giác vẫn có thể xuất hiện trong các giải thích của mô hình tinh chỉnh và hy vọng rằng công trình tương lai sẽ cố gắng giải quyết những vấn đề này. Chúng tôi cũng lưu ý rằng phương pháp của chúng tôi không thay thế chú thích chuyên gia vì nó phụ thuộc nhiều vào LLM có thể vẫn ảo giác. Nó chỉ nhằm áp dụng trong các kịch bản mà phản hồi chuyên gia đắt đỏ và/hoặc khó thu thập.

Một hạn chế của phương pháp chúng tôi là chúng tôi đã sử dụng một số lượng tương đối nhỏ các chuyên gia để tiến hành nghiên cứu. Tuy nhiên, chúng tôi tin rằng cài đặt này phản ánh các điều kiện thực tế nơi các chuyên gia thường hiếm hoi. Chúng tôi hy vọng phương pháp của chúng tôi cung cấp một khung tổng quát hơn để kết hợp phản hồi chuyên gia có thể được điều chỉnh theo nhu cầu của chuyên gia (ví dụ, một nhà ngôn ngữ học pháp y có thể yêu cầu một giải thích chuyển đổi phong cách khác so với một nhà phê bình văn học).

Tinh chỉnh và chạy suy luận trên các mô hình lớn yêu cầu tài nguyên tính toán đắt đỏ. Tuy nhiên, chúng tôi hy vọng rằng nghiên cứu của chúng tôi trình bày một lập luận thuyết phục rằng tinh chỉnh một mô hình nhỏ hơn một lần có thể hiệu quả và chính xác hơn so với việc chạy một mô hình đa năng lớn với các lời nhắc dài phức tạp.

8 Tuyên bố Đạo đức

Tập dữ liệu GYAFC được tạo ra bằng cách sử dụng tập dữ liệu Yahoo Answers: L6 - Yahoo! Answers Comprehensive Questions and Answers phiên bản 1.0. Tập dữ liệu Yahoo Answers này có thể được yêu cầu miễn phí cho mục đích nghiên cứu. Quyền truy cập vào tập dữ liệu GYAFC của chúng tôi sẽ yêu cầu người dùng trước tiên có quyền truy cập vào tập dữ liệu Yahoo Answers này. Các tác giả đã được phép truy cập tập dữ liệu.

Các tập dữ liệu của chúng tôi không bao gồm bất kỳ dữ liệu được bảo vệ nào theo hiểu biết tốt nhất của chúng tôi. Tất cả các người chú thích được trả công công bằng cho công việc của họ theo tỷ lệ yêu cầu của họ (thường trên 20 USD mỗi giờ).

Mô hình chuyển đổi phong cách thiên vị của chúng tôi chỉ được thiết kế để sử dụng theo cách có con người trong vòng lặp chứ không phải tự nó để phán xét thiên vị trong văn bản. Chúng tôi hy vọng rằng khả năng tạo giải thích của mô hình sẽ cải thiện so với các bộ phân loại thiên vị hiện có thường không cung cấp các giải thích bằng văn bản. Trong Phụ lục G, chúng tôi cho thấy cách chuyển đổi phong cách có thể được sử dụng để trốn tránh các máy dò văn bản AI. Tương tự như Krishna et al. (2023), chúng tôi nhắc lại rằng điều này không phải để cung cấp một cách tấn công các hệ thống như vậy, mà là để nâng cao nhận thức cho cộng đồng rằng các máy dò hiện tại dễ dàng bị trốn tránh. Hơn nữa, chúng tôi đưa ra sự chú ý về vấn đề phát hiện văn bản mà chuyển đổi phong cách diễn đạt lại đã được áp dụng. Chúng tôi hy vọng rằng công trình tương lai phát triển các hệ thống có khả năng bảo vệ chống lại các cuộc tấn công như vậy, có thể sử dụng các giải thích được tạo ra bởi hệ thống của chúng tôi.

GYAFC và WNC có thể chứa dữ liệu xúc phạm vì chúng được crowdsource, tuy nhiên, trên các mẫu mà chúng tôi thấy, chúng tôi không tìm thấy các vấn đề đạo đức đáng báo động.

Lời cảm ơn

Chúng tôi cảm ơn các người chú thích cho công việc của họ và việc cung cấp phản hồi chi tiết. Chúng tôi cũng muốn cảm ơn các nhà đánh giá vì những cuộc thảo luận hiệu quả và hấp dẫn. Nghiên cứu này được hỗ trợ một phần bởi Văn phòng Giám đốc Tình báo Quốc gia (ODNI), Hoạt động Nghiên cứu Tiên tiến Tình báo (IARPA), thông qua hợp đồng Chương trình HIATUS #2022-22072200005. Các quan điểm và kết luận được chứa trong này là của các tác giả và không nên được diễn giải như nhất thiết đại diện cho các chính sách chính thức, được thể hiện hoặc ngụ ý, của ODNI, IARPA, hoặc Chính phủ Hoa Kỳ. Chính phủ Hoa Kỳ được ủy quyền tái tạo và phân phối các bản in lại cho mục đích chính phủ bất chấp bất kỳ chú thích bản quyền nào trong đó.

Tài liệu tham khảo

Shourya Aggarwal, Divyanshu Mandowara, Vishwajeet Agrawal, Dinesh Khandelwal, Parag Singla, và Dinesh Garg. 2021. Explanations for CommonsenseQA: New Dataset and Models. Trong Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), trang 3050–3065, Online. Association for Computational Linguistics.

Ebtesam Almazrouei, Hamza Alobeidli, Abdulaziz Alshamsi, Alessandro Cappelli, Ruxandra Cojocaru, Merouane Debbah, Etienne Goffinet, Daniel Heslow, Julien Launay, Quentin Malartic, Badreddine Noune, Baptiste Pannier, và Guilherme Penedo. 2023. Falcon-40B: an open large language model with state-of-the-art performance.

--- TRANG 10 ---
Nikolay Babakov, David Dale, Varvara Logacheva, và Alexander Panchenko. 2022. A large-scale computational study of content preservation measures for text style transfer and paraphrase generation. Trong Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop, trang 300–321, Dublin, Ireland. Association for Computational Linguistics.

Yuntao Bai, Andy Jones, Kamal Ndousse, Amanda Askell, Anna Chen, Nova DasSarma, Dawn Drain, Stanislav Fort, Deep Ganguli, Tom Henighan, Nicholas Joseph, Saurav Kadavath, Jackson Kernion, Tom Conerly, Sheer El-Showk, Nelson Elhage, Zac Hatfield-Dodds, Danny Hernandez, Tristan Hume, Scott Johnston, Shauna Kravec, Liane Lovitt, Neel Nanda, Catherine Olsson, Dario Amodei, Tom Brown, Jack Clark, Sam McCandlish, Chris Olah, Ben Mann, và Jared Kaplan. 2022a. Training a helpful and harmless assistant with reinforcement learning from human feedback.

Yuntao Bai, Saurav Kadavath, Sandipan Kundu, Amanda Askell, Jackson Kernion, Andy Jones, Anna Chen, Anna Goldie, Azalia Mirhoseini, Cameron McKinnon, Carol Chen, Catherine Olsson, Christopher Olah, Danny Hernandez, Dawn Drain, Deep Ganguli, Dustin Li, Eli Tran-Johnson, Ethan Perez, Jamie Kerr, Jared Mueller, Jeffrey Ladish, Joshua Landau, Kamal Ndousse, Kamile Lukosuite, Liane Lovitt, Michael Sellitto, Nelson Elhage, Nicholas Schiefer, Noemi Mercado, Nova DasSarma, Robert Lasenby, Robin Larson, Sam Ringer, Scott Johnston, Shauna Kravec, Sheer El Showk, Stanislav Fort, Tamera Lanham, Timothy Telleen-Lawton, Tom Conerly, Tom Henighan, Tristan Hume, Samuel R. Bowman, Zac Hatfield-Dodds, Ben Mann, Dario Amodei, Nicholas Joseph, Sam McCandlish, Tom Brown, và Jared Kaplan. 2022b. Constitutional ai: Harmlessness from ai feedback.

Max Bartolo, Tristan Thrush, Sebastian Riedel, Pontus Stenetorp, Robin Jia, và Douwe Kiela. 2022. Models in the loop: Aiding crowdworkers with generative annotation assistants. Trong Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, trang 3754–3767, Seattle, United States. Association for Computational Linguistics.

Edward Beeching, Sheon Han, Nathan Lambert, Nazneen Rajani, Omar Sanseviero, Lewis Tunstall, và Thomas Wolf. 2023. Open llm leaderboard. https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard.

Janek Bevendorff, Berta Chulvi, Elisabetta Fersini, Annina Heini, Mike Kestemont, Krzysztof Kredens, Maximilian Mayerl, Reynier Ortega-Bueno, Piotr Pęzik, Martin Potthast, et al. 2022. Overview of pan 2022: Authorship verification, profiling irony and stereotype spreaders, and style change detection. Trong Experimental IR Meets Multilinguality, Multimodality, and Interaction: 13th International Conference of the CLEF Association, CLEF 2022, Bologna, Italy, September 5–8, 2022, Proceedings, trang 382–394. Springer.

Lucas Beyer, Xiaohua Zhai, Amélie Royer, Larisa Markeeva, Rohan Anil, và Alexander Kolesnikov. 2022. Knowledge distillation: A good teacher is patient and consistent. Trong Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), trang 10925–10934.

Steven Bird và Edward Loper. 2004. NLTK: The natural language toolkit. Trong Proceedings of the ACL Interactive Poster and Demonstration Sessions, trang 214–217, Barcelona, Spain. Association for Computational Linguistics.

Cristian Bucilǎ, Rich Caruana, và Alexandru Niculescu-Mizil. 2006. Model compression. Trong Proceedings of the 12th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD '06, trang 535–541, New York, NY, USA. Association for Computing Machinery.

Oana-Maria Camburu, Tim Rocktäschel, Thomas Lukasiewicz, và Phil Blunsom. 2018. e-snli: Natural language inference with natural language explanations. Trong Advances in Neural Information Processing Systems, volume 31. Curran Associates, Inc.

Sky CH-Wang, Arkadiy Saakyan, Oliver Li, Zhou Yu, và Smaranda Muresan. 2023. Sociocultural norm similarities and differences via situational alignment and explainable textual entailment.

Tuhin Chakrabarty, Arkadiy Saakyan, Debanjan Ghosh, và Smaranda Muresan. 2022. FLUTE: Figurative language understanding through textual explanations. Trong Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, trang 7139–7159, Abu Dhabi, United Arab Emirates. Association for Computational Linguistics.

Sahil Chaudhary. 2023. Code alpaca: An instruction-following llama model for code generation. https://github.com/sahil280114/codealpaca.

Wei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng, Zhanghao Wu, Hao Zhang, Lianmin Zheng, Siyuan Zhuang, Yonghao Zhuang, Joseph E. Gonzalez, Ion Stoica, và Eric P. Xing. 2023. Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality.

Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Yunxuan Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, Albert Webson, Shixiang Shane Gu, Zhuyun Dai, Mirac Suzgun, Xinyun Chen, Aakanksha Chowdhery, Alex Castro-Ros, Marie Pellat, Kevin Robinson, Dasha Valter, Sharan Narang, Gaurav Mishra, Adams Yu, Vincent Zhao, Yanping Huang, Andrew Dai, Hongkun Yu, Slav Petrov, Ed H. Chi, Jeff Dean, Jacob Devlin, Adam Roberts, Denny Zhou, Quoc V. Le, và Jason Wei. 2022. Scaling instruction-finetuned language models.

Malcolm Coulthard. 2004. Author identification, idiolect, and linguistic uniqueness. Applied linguistics, 25(4):431–447.

Databricks. 2023. Free dolly: Introducing the world's first truly open instruction-tuned llm. Blog post.

Geoffrey Hinton, Oriol Vinyals, và Jeff Dean. 2015. Distilling the knowledge in a neural network. arXiv preprint arXiv:1503.02531.

Namgyu Ho, Laura Schmid, và Se-Young Yun. 2022. Large language models are reasoning teachers. ArXiv, abs/2212.10071.

Di Jin, Zhijing Jin, Zhiting Hu, Olga Vechtomova, và Rada Mihalcea. 2022. Deep learning for text style transfer: A survey. Computational Linguistics, 48(1):155–205.

Marzena Karpinska, Nader Akoury, và Mohit Iyyer. 2021. The perils of using Mechanical Turk to evaluate open-ended text generation. Trong Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, trang 1265–1285, Online and Punta Cana, Dominican Republic. Association for Computational Linguistics.

John Kirchenbauer, Jonas Geiping, Yuxin Wen, Jonathan Katz, Ian Miers, và Tom Goldstein. 2023. A watermark for large language models.

Kalpesh Krishna, Yixiao Song, Marzena Karpinska, John Wieting, và Mohit Iyyer. 2023. Paraphrasing evades detectors of ai-generated text, but retrieval is an effective defense. arXiv preprint arXiv:2303.13408.

Kalpesh Krishna, John Wieting, và Mohit Iyyer. 2020. Reformulating unsupervised style transfer as paraphrase generation. Trong Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), trang 737–762, Online. Association for Computational Linguistics.

Andreas Köpf, Yannic Kilcher, Dimitri von Rütte, Sotiris Anagnostidis, Zhi-Rui Tam, Keith Stevens, Abdullah Barhoum, Nguyen Minh Duc, Oliver Stanley, Richárd Nagyfi, Shahul ES, Sameer Suri, David Glushkov, Arnav Dantuluri, Andrew Maguire, Christoph Schuhmann, Huu Nguyen, và Alexander Mattick. 2023. Openassistant conversations – democratizing large language model alignment.

Guillaume Lample, Sandeep Subramanian, Eric Smith, Ludovic Denoyer, Marc'Aurelio Ranzato, và Y-Lan Boureau. 2019. Multiple-attribute text rewriting. Trong International Conference on Learning Representations.

Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, và Veselin Stoyanov. 2019. Roberta: A robustly optimized bert pretraining approach.

--- TRANG 11 ---
Shayne Longpre, Le Hou, Tu Vu, Albert Webson, Hyung Won Chung, Yi Tay, Denny Zhou, Quoc V Le, Barret Zoph, Jason Wei, et al. 2023. The flan collection: Designing data and methods for effective instruction tuning. arXiv preprint arXiv:2301.13688.

Josh Magnus Ludan, Yixuan Meng, Tai Nguyen, Saurabh Shah, Qing Lyu, Marianna Apidianaki, và Chris Callison-Burch. 2023. Explanation-based fine-tuning makes models more robust to spurious cues.

Aman Madaan, Niket Tandon, Prakhar Gupta, Skyler Hallinan, Luyu Gao, Sarah Wiegreffe, Uri Alon, Nouha Dziri, Shrimai Prabhumoye, Yiming Yang, Shashank Gupta, Bodhisattwa Prasad Majumder, Katherine Hermann, Sean Welleck, Amir Yazdanbakhsh, và Peter Clark. 2023. Self-refine: Iterative refinement with self-feedback.

Lucie Charlotte Magister, Jonathan Mallinson, Jakub Adamek, Eric Malmi, và Aliaksei Severyn. 2023. Teaching small language models to reason.

Colin Martindale và Dean McKenzie. 1995. On the utility of content analysis in author attribution: "the federalist". Computers and the Humanities, 29(4):259–270.

Tom McCoy, Ellie Pavlick, và Tal Linzen. 2019. Right for the wrong reasons: Diagnosing syntactic heuristics in natural language inference. Trong Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, trang 3428–3448, Florence, Italy. Association for Computational Linguistics.

Eric Mitchell, Yoonho Lee, Alexander Khazatsky, Christopher D. Manning, và Chelsea Finn. 2023. Detectgpt: Zero-shot machine-generated text detection using probability curvature.

Tempestt Neal, Kalaivani Sundararajan, Aneez Fatima, Yiming Yan, Yingfei Xiang, và Damon Woodard. 2017. Surveying stylometry techniques and applications. ACM Comput. Surv., 50(6).

OpenAI. 2023. New ai classifier for indicating ai-written text.

Kishore Papineni, Salim Roukos, Todd Ward, và Wei-Jing Zhu. 2002. Bleu: a method for automatic evaluation of machine translation. Trong Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, trang 311–318, Philadelphia, Pennsylvania, USA. Association for Computational Linguistics.

Ajay Patel, Nicholas Andrews, và Chris Callison-Burch. 2022. Low-resource authorship style transfer with in-context learning.

Ajay Patel, Delip Rao, và Chris Callison-Burch. 2023. Learning interpretable style embeddings via prompting llms.

Ellie Pavlick và Joel Tetreault. 2016. An empirical analysis of formality in online communication. Transactions of the Association for Computational Linguistics, 4:61–74.

Guilherme Penedo, Quentin Malartic, Daniel Hesslow, Ruxandra Cojocaru, Alessandro Cappelli, Hamza Alobeidli, Baptiste Pannier, Ebtesam Almazrouei, và Julien Launay. 2023. The RefinedWeb dataset for Falcon LLM: outperforming curated corpora with web data, and web data only. arXiv preprint arXiv:2306.01116.

Baolin Peng, Chunyuan Li, Pengcheng He, Michel Galley, và Jianfeng Gao. 2023. Instruction tuning with gpt-4. arXiv preprint arXiv:2304.03277.

Adam Poliak, Jason Naradowsky, Aparajita Haldar, Rachel Rudinger, và Benjamin Van Durme. 2018. Hypothesis only baselines in natural language inference. Trong Proceedings of the Seventh Joint Conference on Lexical and Computational Semantics, trang 180–191, New Orleans, Louisiana. Association for Computational Linguistics.

Reid Pryzant, Richard Diehl Martinez, Nathan Dass, Sadao Kurohashi, Dan Jurafsky, và Diyi Yang. 2020. Automatically neutralizing subjective bias in text. Proceedings of the AAAI Conference on Artificial Intelligence, 34(01):480–489.

Rafael Rafailov, Archit Sharma, Eric Mitchell, Stefano Ermon, Christopher D. Manning, và Chelsea Finn. 2023. Direct preference optimization: Your language model is secretly a reward model.

Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, và Peter J. Liu. 2020. Exploring the limits of transfer learning with a unified text-to-text transformer. J. Mach. Learn. Res., 21(1).

Nazneen Fatema Rajani, Bryan McCann, Caiming Xiong, và Richard Socher. 2019. Explain yourself! leveraging language models for commonsense reasoning. Trong Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, trang 4932–4942, Florence, Italy. Association for Computational Linguistics.

Sudha Rao và Joel Tetreault. 2018. Dear sir or madam, may I introduce the GYAFC dataset: Corpus, benchmarks and metrics for formality style transfer. Trong Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers), trang 129–140, New Orleans, Louisiana. Association for Computational Linguistics.

Marta Recasens, Cristian Danescu-Niculescu-Mizil, và Dan Jurafsky. 2013. Linguistic models for analyzing and detecting biased language. Trong Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), trang 1650–1659, Sofia, Bulgaria. Association for Computational Linguistics.

--- TRANG 12 ---
Emily Reif, Daphne Ippolito, Ann Yuan, Andy Coenen, Chris Callison-Burch, và Jason Wei. 2022. A recipe for arbitrary text style transfer with large language models. Trong Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), trang 837–848, Dublin, Ireland. Association for Computational Linguistics.

Stephen Robertson và Hugo Zaragoza. 2009. The probabilistic relevance framework: Bm25 and beyond. Foundations and Trends ®in Information Retrieval, 3(4):333–389.

Scott Rosenberg và Sara Fischer. 2023. Newsrooms try ai to check for bias and error. Truy cập: 2024-02-15.

Victor Sanh, Lysandre Debut, Julien Chaumond, và Thomas Wolf. 2020. Distilbert, a distilled version of bert: smaller, faster, cheaper and lighter.

William Saunders, Catherine Yeh, Jeff Wu, Steven Bills, Long Ouyang, Jonathan Ward, và Jan Leike. 2022. Self-critiquing models for assisting human evaluators.

Jérémy Scheurer, Jon Ander Campos, Tomasz Korbak, Jun Shern Chan, Angelica Chen, Kyunghyun Cho, và Ethan Perez. 2023. Training language models with language feedback at scale.

Timo Spinde, Manuel Plank, Jan-David Krieger, Terry Ruas, Bela Gipp, và Akiko Aizawa. 2021. Neural media bias detection using distant supervision with BABE - bias annotations by experts. Trong Findings of the Association for Computational Linguistics: EMNLP 2021, trang 1166–1177, Punta Cana, Dominican Republic. Association for Computational Linguistics.

Nisan Stiennon, Long Ouyang, Jeffrey Wu, Daniel Ziegler, Ryan Lowe, Chelsea Voss, Alec Radford, Dario Amodei, và Paul F Christiano. 2020. Learning to summarize with human feedback. Trong Advances in Neural Information Processing Systems, volume 33, trang 3008–3021. Curran Associates, Inc.

Akhilesh Sudhakar, Bhargav Upadhyay, và Arjun Maheswaran. 2019. "transforming" delete, retrieve, generate approach for controlled text style transfer. Trong Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), trang 3269–3279, Hong Kong, China. Association for Computational Linguistics.

Mirac Suzgun, Luke Melas-Kyriazi, và Dan Jurafsky. 2022. Prompt-and-rerank: A method for zero-shot and few-shot arbitrary textual style transfer with small language models. Trong Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, trang 2195–2222, Abu Dhabi, United Arab Emirates. Association for Computational Linguistics.

Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy Liang, và Tatsunori B. Hashimoto. 2023. Stanford alpaca: An instruction-following llama model. https://github.com/tatsu-lab/stanford_alpaca.

Yla R Tausczik và James W Pennebaker. 2010. The psychological meaning of words: Liwc and computerized text analysis methods. Journal of language and social psychology, 29(1):24–54.

MosaicML NLP Team. 2023. Introducing mpt-7b: A new standard for open-source, commercially usable llms. Truy cập: 2023-06-20.

Edward Tian. 2023. Ai content detector and writing captcha for chat gpt, openai, bard, education.

Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave, và Guillaume Lample. 2023. Llama: Open and efficient foundation language models. arXiv preprint arXiv:2302.13971.

Veniamin Veselovsky, Manoel Horta Ribeiro, và Robert West. 2023. Artificial artificial artificial intelligence: Crowd workers widely use large language models for text production tasks.

PeiFeng Wang, Aaron Chan, Filip Ilievski, Muhao Chen, và Xiang Ren. 2023a. PINTO: Faithful language reasoning using prompt-generated rationales. Trong The Eleventh International Conference on Learning Representations.

Yizhong Wang, Hamish Ivison, Pradeep Dasigi, Jack Hessel, Tushar Khot, Khyathi Raghavi Chandu, David Wadden, Kelsey MacMillan, Noah A. Smith, Iz Beltagy, và Hannaneh Hajishirzi. 2023b. How far can camels go? exploring the state of instruction tuning on open resources.

Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A. Smith, Daniel Khashabi, và Hannaneh Hajishirzi. 2023c. Self-instruct: Aligning language models with self-generated instructions. Trong Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), trang 13484–13508, Toronto, Canada. Association for Computational Linguistics.

Anna Wegmann và Dong Nguyen. 2021. Does it capture STEL? a modular, similarity-based linguistic style evaluation framework. Trong Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, trang 7109–7130, Online and Punta Cana, Dominican Republic. Association for Computational Linguistics.

Anna Wegmann, Marijn Schraagen, và Dong Nguyen. 2022. Same author or just same topic? towards content-independent style representations. Trong Proceedings of the 7th Workshop on Representation Learning for NLP, trang 249–268, Dublin, Ireland. Association for Computational Linguistics.

--- TRANG 13 ---
Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, brian ichter, Fei Xia, Ed H. Chi, Quoc V Le, và Denny Zhou. 2022. Chain of thought prompting elicits reasoning in large language models. Trong Advances in Neural Information Processing Systems.

Peter West, Chandra Bhagavatula, Jack Hessel, Jena Hwang, Liwei Jiang, Ronan Le Bras, Ximing Lu, Sean Welleck, và Yejin Choi. 2022. Symbolic knowledge distillation: from general language models to commonsense models. Trong Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, trang 4602–4625, Seattle, United States. Association for Computational Linguistics.

Sarah Wiegreffe, Jack Hessel, Swabha Swayamdipta, Mark Riedl, và Yejin Choi. 2022. Reframing human-AI collaboration for generating free-text explanations. Trong Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, trang 632–658, Seattle, United States. Association for Computational Linguistics.

Sarah Wiegreffe và Ana Marasovic. 2021. Teach me to explain: A review of datasets for explainable natural language processing. Trong Proceedings of the Neural Information Processing Systems Track on Datasets and Benchmarks, volume 1. Curran.

Sarah Wiegreffe, Ana Marasović, và Noah A. Smith. 2021. Measuring association between labels and free-text rationales. Trong Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, trang 10266–10284, Online and Punta Cana, Dominican Republic. Association for Computational Linguistics.

John Wieting, Kevin Gimpel, Graham Neubig, và Taylor Berg-kirkpatrick. 2022. Paraphrastic representations at scale. Trong Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, trang 379–388, Abu Dhabi, UAE. Association for Computational Linguistics.

Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Rémi Louf, Morgan Funtowicz, Joe Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest, và Alexander M. Rush. 2020. Huggingface's transformers: State-of-the-art natural language processing.

Yang Zhong, Jingfeng Yang, Wei Xu, và Diyi Yang. 2021. WIKIBIAS: Detecting multi-span subjective biases in language. Trong Findings of the Association for Computational Linguistics: EMNLP 2021, trang 1799–1814, Punta Cana, Dominican Republic. Association for Computational Linguistics.

--- TRANG 14 ---
A Chi tiết đánh giá con người: E-GYAFC

Chúng tôi thuê ba người chú thích để đánh giá sở thích: A1 (bằng cử nhân ngôn ngữ học), A2 (bằng cử nhân ngôn ngữ học và bằng thạc sĩ giáo dục), A3 (bằng cử nhân và thạc sĩ ngôn ngữ học) trên Upwork. Do tỷ lệ cao của lớp tích cực, có khả năng cao về thỏa thuận ngẫu nhiên, do đó chúng tôi cung cấp cái nhìn chi tiết hơn về các chú thích chuyên gia so với thỏa thuận giữa các người đánh giá trong Bảng 9. Độ chính xác theo cặp giữa các phản hồi của người chú thích cho tất cả các danh mục đánh giá E-GYAFC, và thấy rằng nó trung bình ở mức 81% trên tất cả các danh mục. Người chú thích A2 bày tỏ lo ngại rằng các câu diễn đạt lại có thể nghe không tự nhiên do tính trang trọng quá mức (chúng tôi tin rằng đó là do bối cảnh mà biểu thức không trang trọng sẽ được nói ra) và các giải thích đôi khi bỏ lỡ lỗi dấu câu (mặc dù quan trọng, không quan trọng cho các giải thích do mô hình tạo ra).

ei
sở thích.ei
chấp nhận.sf
sở thích.sf
chấp nhận.ef
chấp nhận.
A1 91% 95% 64% 64% 98%
A2 87% 84% 76% 75% 96%
A3 91% 83% 91% 93% 100%

Bảng 9: Đánh giá chuyên gia về chất lượng tập dữ liệu E-GYAFC. Chúng tôi báo cáo tỷ lệ phần trăm thời gian mỗi mục được ưa chuộng, cũng như các đánh giá về tính chấp nhận.

B Chi tiết đánh giá con người: E-WNC

Đối với E-WNC, chúng tôi thuê hai chuyên gia chú thích A1 và A2. A1 là một chuyên gia với hơn mười năm kinh nghiệm trong dịch thuật và phiên dịch, chú thích dữ liệu, ngôn ngữ học và xuất bản. A2 là một tiến sĩ ngôn ngữ học với nền tảng tâm lý ngôn ngữ học và thần kinh ngôn ngữ học và kinh nghiệm trong viết, đọc thử và chỉnh sửa văn bản học thuật.

eb
sở thích.eb
chấp nhận.sn
sở thích.sn
chấp nhận.
A1 82% 84% 84% 86%
A2 74% 62% 70% 62%

Bảng 10: Đánh giá chuyên gia về chất lượng tập dữ liệu E-WNC. Chúng tôi báo cáo tỷ lệ phần trăm thời gian mỗi mục được ưa chuộng, cũng như các đánh giá về tính chấp nhận.

C Hiệu suất ICLEF thay đổi như thế nào tùy thuộc vào lượng phản hồi được cung cấp?

Chúng tôi thực hiện một nghiên cứu quy mô nhỏ để khám phá cách hiệu suất của thành phần tự phê bình của ICLEF thay đổi tùy thuộc vào số lượng ví dụ trong ngữ cảnh được cung cấp. Chúng tôi lấy mẫu 15 thể hiện của các giải thích tổng hợp (trước khi áp dụng ICLEF) và đánh giá các phê bình được tạo ra về tính đúng đắn khi cung cấp 1, 10, hoặc 35 thể hiện của phản hồi chuyên gia vài lần. Chúng tôi đánh giá các phê bình về tính đúng đắn, tức là chúng phải vừa xác định thuộc tính không chính xác và không giới thiệu bất kỳ thuộc tính không chính xác nào. Hình 4 cho thấy cách bằng cách tăng lượng phản hồi lên 35 lần, độ chính xác được nâng lên ≈87% cho E-GYAFC và ≈93% cho E-WNC, có thể được coi là thỏa mãn.

00.10.20.30.40.50.60.70.80.91
1-shot10-shot35-shotHiệu suất ICLEF so với lượng phản hồi
e-GYAFC (GPT-3.5)e-WNC (GPT-4)

Hình 4: Hiệu suất ICLEF tăng với lượng phản hồi, đạt độ chính xác thỏa mãn ở khoảng 35 lần.

D Các ước tính bổ sung cho độ tin cậy của các giải thích

Chúng tôi tiến hành đánh giá chuyên gia về dữ liệu của chúng tôi trong Phần 3.3. Để xác nhận thêm độ tin cậy của các giải thích, chúng tôi kiểm tra rằng mọi đoạn bằng chứng thực sự xuất hiện trong văn bản. Đối với mọi thể hiện dữ liệu, chúng tôi tính toán tỷ lệ phần trăm bằng chứng có trong câu. Chúng tôi báo cáo trung bình trên các tập dữ liệu và giải thích tương ứng trong Bảng 11 tóm tắt kết quả, nơi rõ ràng là các giải thích có độ tin cậy cao. Chúng tôi lưu ý rằng một số giải thích thảo luận về sự vắng mặt của một số từ, trong trường hợp đó chúng không nên có trong câu ngay từ đầu. Hơn nữa, định dạng giải thích có cấu trúc của chúng tôi sẽ giúp người dùng cuối dễ dàng xác minh tính đúng đắn của giải thích và cảnh báo họ về câu diễn đạt lại có thể không chính xác.

--- TRANG 15 ---
e-GYAFC e-WNC
ei ef eu
Độ tin cậy 95.0% 92.3% 98.9%

Bảng 11: Tỷ lệ Độ tin cậy Giải thích Trên các Tập dữ liệu: tỷ lệ phần trăm bằng chứng thực sự có trong câu.

E Lời nhắc

Bạn là một người chú thích vô cùng chú ý và phê bình với nền tảng về phong cách học và ngôn ngữ học. Bạn sẽ được cung cấp một câu không trang trọng. Bạn cũng sẽ được cung cấp một giải thích về các thuộc tính không trang trọng của nó. Quyết định xem giải thích có không chính xác hay không, và nếu có, mô tả những thuộc tính nào được liệt kê không chính xác.

VÍ DỤ: <...>

Bạn là một người chú thích vô cùng chú ý và phê bình với nền tảng về đạo đức, báo chí, tư duy phê phán và xác định thiên vị. Bạn sẽ được cung cấp một câu có thể thiên vị. Bạn cũng sẽ được cung cấp một giải thích về các thuộc tính thiên vị của nó. <...> Nếu giải thích không chính xác, hãy trả lời bằng một sửa chữa. Tập trung vào ba loại thiên vị chính trong một câu: <...>

VÍ DỤ: <...>

Bảng 12: Lời nhắc cho các mô hình LLM-phê bình. Phía trên được sử dụng cho chuyển đổi phong cách trang trọng, phía dưới được sử dụng cho chuyển đổi phong cách thiên vị chủ quan.

Lời nhắc Tạo Giải thích ChatGPT Chúng tôi cung cấp một hướng dẫn như một lời nhắc hệ thống ("Bạn là một nhà ngôn ngữ học pháp y chuyên gia...") và 6 ví dụ về nhiệm vụ trong định dạng OpenAI ChatML.8

Hướng dẫn: Bạn là một nhà ngôn ngữ học pháp y chuyên gia. Nhiệm vụ của bạn là xác định các thuộc tính không trang trọng trong một câu, sửa đổi chúng để tạo ra một câu trang trọng, và sau đó xuất ra các thuộc tính của câu trang trọng được tạo ra. Sử dụng định dạng sau: thuộc tính (đoạn trích từ văn bản trong dấu ngoặc kép). Đảm bảo cung cấp danh sách đầy đủ các thuộc tính không trang trọng và trang trọng. Tập trung vào những gì đã thay đổi giữa các câu trang trọng và không trang trọng. Viết không trang trọng có xu hướng thường xuyên, cá nhân và đàm thoại hơn so với viết trang trọng. Dưới đây là một số đặc điểm phổ biến của viết không trang trọng: Từ rút gọn: Viết không trang trọng thường sử dụng từ rút gọn, chẳng hạn như "I'm," "can't," "won't," và "they've," thường được tránh trong viết trang trọng. ...

8github.com/openai/openai-python/blob/main/chatml.md

Ví dụ: Lời chào và kết thúc không trang trọng: Viết không trang trọng thường sử dụng lời chào thường, chẳng hạn như "Hi" hoặc "Hey," và kết thúc như "Cheers" hoặc "Take care." Không trang trọng: if ur under 18 u have a BIG PROBLEM. Ứng viên Không trang trọng: '18', 'BIG', 'PROBLEM.', 'if', 'u', 'ur Thuộc tính của Phong cách Không trang trọng: từ viết tắt ("ur", "u"), viết hoa ("BIG PROBLEM"), thành ngữ thông tục ("BIG PROBLEM")...

Lời nhắc cho tạo ICLEF ChatGPT Bạn là một người chú thích vô cùng chú ý và phê bình với nền tảng về phong cách học và ngôn ngữ học. Bạn sẽ được cung cấp một câu không trang trọng. Bạn cũng sẽ được cung cấp một giải thích về các thuộc tính không trang trọng của nó. Quyết định xem giải thích có không chính xác hay không, và nếu có, mô tả những thuộc tính nào được liệt kê không chính xác.

VÍ DỤ: Câu Không trang trọng: Look, If you really like this person, just tell her. Thuộc tính Không trang trọng: thành ngữ thông tục ("just tell her"), từ rút gọn ("If you"), cấu trúc câu đơn giản. Thuộc tính Được Liệt kê Không chính xác: từ rút gọn ("If you" không phải là từ rút gọn)...

F Chi tiết mô hình, các mô hình bổ sung và thí nghiệm

Dưới đây chúng tôi cung cấp một số thí nghiệm và mô hình bổ sung được sử dụng cho chúng cũng như chi tiết thí nghiệm.

Các Mô hình Được Điều chỉnh Hướng dẫn Tất cả các mô hình được điều chỉnh hướng dẫn được cung cấp cùng một lời nhắc một lần (trừ các yêu cầu mã thông báo đặc biệt) và các tham số tạo ra.

•MPT-7B-Instruct: được xây dựng bằng cách tinh chỉnh MPT-7B (Team, 2023) trên một tập dữ liệu có nguồn gốc từ Databricks Dolly-15k (Databricks, 2023) và các tập dữ liệu Anthropic Helpful and Harmless (Bai et al., 2022a).

•Alpaca-7B (Taori et al., 2023) một mô hình được tinh chỉnh từ mô hình LLaMA-7B trên 52K minh chứng theo hướng dẫn được tạo ra với khung Self-Instruct (Wang et al., 2023c).

--- TRANG 16 ---
•Vicuna-13B (Chiang et al., 2023): một chatbot nguồn mở được huấn luyện bằng cách tinh chỉnh LLaMA trên các cuộc trò chuyện được người dùng chia sẻ thu thập từ ShareGPT9. Nó đứng đầu trong Bảng xếp hạng LLM Mở Huggingface (Beeching et al., 2023) dựa trên đánh giá của con người và GPT-4 tại thời điểm viết bài báo này.

•Falcon-40B (Almazrouei et al., 2023) mô hình giải mã nhân quả chỉ được huấn luyện trên 1.000B token của RefinedWeb (Penedo et al., 2023) được tăng cường với các tập dữ liệu được tuyển chọn.

•Tülu-65B (Wang et al., 2023b) một mô hình LLaMa 65B được tinh chỉnh trên hỗn hợp các tập dữ liệu hướng dẫn (FLAN V2 (Longpre et al., 2023), CoT (Wei et al., 2022), Dolly (Databricks, 2023), Open Assistant 1 (Köpf et al., 2023), GPT4-Alpaca (Peng et al., 2023), Code-Alpaca (Chaudhary, 2023), và ShareGPT).

ChatGPT Đối với ChatGPT-3.5 chúng tôi sử dụng gpt-3.5-turbo-1106. Đối với ChatGPT-4 chúng tôi sử dụng gpt-4.

Các mô hình được tinh chỉnh Chúng tôi tinh chỉnh các mô hình dưới đây trên E-GYAFC. → chỉ ra tinh chỉnh hai mô hình theo mỗi hướng, và ↔ chỉ ra tinh chỉnh trên dữ liệu kết hợp theo cả hai hướng.

•FLAN-T5-XL ↔ (Chung et al., 2022) mô hình được điều chỉnh hướng dẫn khoảng 3B tham số dựa trên kiến trúc T5 (Raffel et al., 2020).

•LLaMA-7B → (Touvron et al., 2023) mô hình của Meta được huấn luyện trên 1 nghìn tỷ token.

•Alpaca-7B →,↔ (Taori et al., 2023) một mô hình được tinh chỉnh từ mô hình LLaMA-7B trên 52K minh chứng theo hướng dẫn. Ngoài ra, chúng tôi kiểm tra Alpaca-7B noexpl như mô hình được tinh chỉnh cho chuyển đổi phong cách Trang trọng sang Không trang trọng mà không có giải thích được cung cấp trong dữ liệu tinh chỉnh hoặc trong đầu ra.

Siêu tham số tinh chỉnh Chúng tôi tinh chỉnh tất cả các mô hình bằng cách sử dụng script được cung cấp trong kho Stanford Alpaca.10 Chúng tôi sử dụng chính xác cùng siêu tham số, ngoại trừ kích thước batch mà chúng tôi điều chỉnh thành 1 do hạn chế bộ nhớ. Chúng tôi tinh chỉnh các mô hình của chúng tôi trên 4 GPU NVIDIA A100 40GB. Chúng tôi huấn luyện các mô hình của chúng tôi trong 3 epoch với tỷ lệ học 2e-05 với bộ lập lịch tỷ lệ cosine và tỷ lệ khởi động là 0.03. Chúng tôi không thực hiện tìm kiếm siêu tham số. Chúng tôi báo cáo kết quả từ các lần chạy đơn với hạt giống ngẫu nhiên được bảo tồn do hạn chế tính toán.

9sharegpt.com
10Alpaca GitHub

Tham số suy luận Chúng tôi sử dụng cùng siêu tham số để tạo ra trên tất cả các mô hình, đó là temperature=0.7, top p=0.9, max new tokens = 256. Chúng tôi sử dụng thư viện huggingface.

Hướng dẫn một lần được cung cấp dưới đây:
Xác định các thuộc tính không trang trọng trong một câu cho trước, sửa đổi chúng để tạo ra một câu trang trọng, và sau đó xuất ra các thuộc tính của câu trang trọng được tạo ra.

Ví dụ:
Không trang trọng: how can you tell if a girl likes you or not?
Thuộc tính Không trang trọng: dạng câu hỏi trực tiếp ("how can you tell"), ngôn ngữ không trang trọng ("girl", "likes you") Trang trọng: What are some indications that a woman may be interested in you? Thuộc tính Trang trọng: dạng câu hỏi gián tiếp ("what are some indications"), từ vựng tinh tế ("woman", "interested in you")

Đối với câu sau, xác định các thuộc tính không trang trọng trong một câu cho trước, sửa đổi chúng để tạo ra một câu trang trọng, và sau đó xuất ra các thuộc tính của câu trang trọng được tạo ra.

Đối với Tulu, chúng tôi thêm các token <asistant> và <user> như được khuyến nghị bởi các nhà phát triển mô hình.

Gói Chúng tôi đã sử dụng transformers (Wolf et al., 2020) để suy luận mô hình ngôn ngữ và gói NLTK (Bird và Loper, 2004) để phân tách câu.

Các thí nghiệm bổ sung với các mô hình hướng dẫn và tinh chỉnh Chúng tôi thêm thực hiện các thí nghiệm với MPT-7B, Falcon-40B, Tulu, và Alpaca không tinh chỉnh. Chúng tôi cũng tinh chỉnh một mô hình Alpaca không có giải thích. Xem Bảng 13. Mô hình được tinh chỉnh không có giải thích (Alpaca noexpl) đạt hiệu suất tương đương, cho thấy việc tạo ra giải thích không làm tổn hại đáng kể đến hiệu suất trên nhiệm vụ chuyển đổi phong cách tiêu chuẩn.

Tính trôi chảy của chuyển đổi phong cách Tính trôi chảy có thể được sử dụng như một chỉ số bổ sung để đo chất lượng của chuyển đổi phong cách. Tuy nhiên, các thước đo tính trôi chảy tương quan âm với tính không trang trọng, mặc dù nội dung ngữ nghĩa vẫn giữ nguyên. Vì lý do đó, chúng tôi ưa thích sử dụng độ tương tự ngữ nghĩa của đầu ra so với đầu vào (MIS) như thước đo chính trên tất cả các nhiệm vụ. Dưới đây là kết quả của một thí nghiệm chúng tôi đã tiến hành với perplexity (thấp hơn là tốt hơn), theo đúng Suzgun et al. (2022) để tính toán chỉ số tính trôi chảy.

--- TRANG 17 ---
Trang trọng→Không trang trọng Không trang trọng →Trang trọng
Mô hình KíchthướcThuộctínhTrtrọng
BLEUMISKhông trtrọngThuộctínhKhông trtrọng
BLEUThuộctínhKhông trtrọng
BLEUMISTrang trọngThuộctínhTrtrọng
BLEUTrung bình
MPT 7B 24.59 51.84 9.82 2.10 23.26 46.26 58.40 0.86 27.14
Alpaca 7B 17.07 80.74 32.53 6.51 23.67 73.69 86.82 8.27 41.16
Falcon 40B 8.38 28.12 13.43 1.23 20.80 38.01 62.69 7.13 22.47
Tülu 65B 24.90 19.60 7.12 0.02 27.76 26.69 27.34 0.28 16.71
FLAN-T5 → 3B 0.00 8.54 0.01 0.00 0.00 9.82 0.91 0.00 2.41
Alpaca → 7B 39.98 84.70 61.99 19.22 40.56 81.69 97.96 24.71 56.35
Alpaca noexpl 7B - 85.34 54.75 - - 83.20 91.10 - -

Bảng 13: Hiệu suất của các mô hình được điều chỉnh hướng dẫn và tinh chỉnh bổ sung trên nhiệm vụ chuyển đổi phong cách trang trọng có thể giải thích.

Mô hình PPL Inf. → PPL For.→ PPL Bias →
For. Inf. Unbiased
gold 33.32 68.96 31.26
gpt1 31.24 21.39 28.21
gpt5 34.83 21.10 27.59
gpt10 32.55 23.82 27.62
mô hình tốt nhất 30.21 38.61 31.97

Bảng 14: Kết quả đánh giá tính trôi chảy. GPT đề cập đến mô hình giáo viên, mô hình tốt nhất đề cập đến Alpaca cho chuyển đổi trang trọng và LLaMA cho chuyển đổi thiên vị.

Như có thể thấy từ Bảng 14, đối với câu diễn đạt lại trang trọng và không thiên vị, perplexity có thể so sánh với giáo viên trong cài đặt 1-shot và vài shot cũng như tham chiếu vàng, trong khi đối với tính không trang trọng, dữ liệu vàng có perplexity tệ nhất, làm cho chỉ số này không phù hợp khi chúng ta muốn chuyển từ phong cách trang trọng sang không trang trọng. Chúng tôi muốn thêm rằng chúng tôi đã thực hiện đánh giá con người trong Phần 4.3 bao gồm đánh giá các câu được chuyển đổi.

Hiệu suất của Đường cơ sở PromptRerank Chúng tôi đã xem xét bao gồm một đường cơ sở PromptRerank (Suzgun et al., 2022) vì đây là một trong những phương pháp SOTA trước đây. Theo quan sát của chúng tôi, các mô hình không hoạt động cạnh tranh có lẽ vì các mô hình được mô tả trong bài báo nhỏ hơn so với các LLM đương đại. Công trình tương lai có thể khám phá các điều chỉnh trên đường cơ sở này để thích ứng với các mô hình mới. Hiệu suất được mô tả trong Bảng 15.

BLEU và BERTScore giữa văn bản được chuyển đổi và tham chiếu vàng Chúng tôi đã chọn các chỉ số không tham chiếu vì chúng sẽ ít thiên vị hơn đối với việc tạo ra đầu ra khớp gần nhất với tham chiếu. Tuy nhiên, chúng tôi bây giờ đã chạy thí nghiệm với BLEU và BERTScore giữa văn bản được chuyển đổi (đầu ra) và tham chiếu vàng từ các tập dữ liệu e-GYAFC và e-WNC của chúng tôi. BERTScore dựa trên nhúng theo ngữ cảnh và thường được ưa thích hơn so với việc sử dụng BLEU-4 (dựa trên sự trùng lặp 4-gram) để đánh giá tạo văn bản và câu diễn đạt lại. Kết quả được hiển thị dưới đây trong Bảng 16.

Chúng tôi thấy rằng sử dụng BERTScore, mô hình học sinh có thể so sánh với mô hình giáo viên và cả hai đều gần gũi về mặt ngữ nghĩa với tham chiếu. Điểm BLUE thấp hơn do yêu cầu trùng lặp n-gram nghiêm ngặt hơn nhưng điều đó xảy ra trên tất cả các mô hình và điểm số lại có thể so sánh giữa các mô hình học sinh nhỏ hơn và các mô hình giáo viên lớn hơn.

Mô hình MIS (Trang trọng sang Tính không trang trọng MIS (Không trang trọng sang Trang trọng
Không trang trọng) Trang trọng)
Alpaca ↔ 81.76 66.71 79.43 98.57
promptRerank 63.33 33.11 62.70 20.00

Bảng 15: Hiệu suất mô hình trên các nhiệm vụ chuyển đổi phong cách.

Mô hình Trang trọng →Không trang trọng Không trang trọng →Trang trọng Thiên vị →Không thiên vị
BLEU BERTScore BLEU BERTScore BLEU BERTScore
gpt1 15.01 78.40 28.10 84.29 60.34 91.30
gpt5 15.36 78.74 28.71 84.48 64.85 91.78
gpt10 14.23 78.14 29.13 84.62 65.98 92.13
mô hình tốt nhất 15.33 77.57 20.75 80.78 70.49 93.23

Bảng 16: So sánh hiệu suất của các mô hình trên các chỉ số BLEU và BERTScore với tham chiếu vàng. GPT đề cập đến mô hình giáo viên, mô hình tốt nhất đề cập đến Alpaca ↔ cho chuyển đổi trang trọng và LLaMA → cho chuyển đổi thiên vị sang không thiên vị.

G Thảo luận về các ứng dụng của các mô hình được tinh chỉnh cho chuyển đổi phong cách có thể giải thích

Chuyển đổi phong cách có thể giải thích trang trọng →không trang trọng là một cuộc tấn công đối kháng có thể diễn giải đối với các phương pháp phát hiện văn bản do AI tạo ra, bao gồm cả truy xuất Krishna et al. (2023) đã xác định rằng việc diễn đạt lại dễ dàng trốn tránh việc phát hiện văn bản do AI tạo ra, và đề xuất một biện pháp phòng thủ dựa trên truy xuất. Tuy nhiên, chúng tôi giả thuyết rằng các chỉ số dựa trên truy xuất sẽ giảm khi độ tương tự giữa các thế hệ trở nên mơ hồ hơn, như trường hợp chuyển đổi phong cách trang trọng. Ví dụ, một tác nhân đối kháng có thể tạo ra một bài đăng chứa thông tin sai lệch bằng ngôn ngữ "trang trọng" điển hình được tạo ra bởi một mô hình ngôn ngữ như ChatGPT. Văn bản này tương đối có thể phát hiện được bằng các bộ phân loại hiện tại và 100% có thể phát hiện được bằng các phương pháp dựa trên truy xuất. Tuy nhiên, tác nhân có thể áp dụng một mô hình chuyển đổi phong cách để giảm tính trang trọng của thông điệp. Đáng báo động, điều này không chỉ hoàn thành mục tiêu lan truyền thông điệp do AI tạo ra hiệu quả hơn vì kết quả trông giống văn bản do người dùng tạo ra hơn, mà như chúng tôi cho thấy, nó cũng giảm khả năng được phát hiện là do AI tạo ra bằng các phương pháp hiện tại.

Chúng tôi kiểm tra điều này trong cài đặt sau: chúng tôi sử dụng một tập dữ liệu trực tuyến về các tweet chính trị11, và lấy mẫu 30 trong số chúng. Chúng tôi yêu cầu ChatGPT tạo ra một bài bình luận chính trị về chủ đề của tweet (GPT-F), cũng như một câu diễn đạt lại không trang trọng của bài đăng đó (GPT-Inf). Chúng tôi chú thích thủ công các tóm tắt kết quả và chọn những cái trông như chúng có thể là những thông điệp chính trị hợp pháp được đăng trên mạng xã hội và có các câu diễn đạt lại hợp lệ. Sau đó chúng tôi sử dụng mô hình Alpaca F→IF của chúng tôi để tạo ra một câu diễn đạt lại không trang trọng của các bài đăng GPT-F từng câu một. Chúng tôi cũng xác minh rằng các câu diễn đạt lại này về mặt ngữ nghĩa hợp lệ và gần với bài đăng GPT-Formal gốc và chọn 24 thế hệ chất lượng cao. Chúng tôi chọn một mẫu tương đối nhỏ vì chúng tôi muốn xác minh câu diễn đạt lại vẫn gần với câu gốc theo cách thủ công để đảm bảo kiểm soát ngữ nghĩa cho thí nghiệm.

Chúng tôi báo cáo điểm phát hiện12 từ 4 phương pháp được khảo sát bởi Krishna et al. (2023): GPTZero (Tian, 2023), bộ phân loại OpenAI (OpenAI, 2023), DetectGPT (Mitchell et al., 2023), và các phương pháp truy xuất được đề xuất của họ dựa trên BM25 (Robertson và Zaragoza, 2009) hoặc P-SP (Wieting et al., 2022) retrievers. Như có thể thấy trong Bảng 17, mô hình chuyển đổi trang trọng sang không trang trọng giảm đáng kể điểm phát hiện của tất cả các phương pháp phát hiện văn bản do AI tạo ra, bao gồm cả phương pháp dựa trên truy xuất (mặc dù thực tế là tập dữ liệu truy xuất nhỏ hơn đáng kể so với trong thế giới thực). Thú vị, đối với phương pháp truy xuất BM25, các câu diễn đạt lại ChatGPT hơi khó phát hiện hơn so với Alpaca F→IF, trong khi nó dễ dàng hơn cho tất cả các phương pháp khác. Vì chúng tôi đã sử dụng ChatGPT để tạo ra các bài đăng gốc, chúng tôi không thể sử dụng các phương pháp đánh dấu (Kirchenbauer et al., 2023), nhưng điều này có thể được khám phá trong công trình tương lai.

11kaggle.com
12Vì chúng tôi không có văn bản cơ sở con người, chúng tôi không báo cáo hiệu suất ở 1% FPR, nhưng đối với nghiên cứu của chúng tôi, việc cho thấy điểm số giảm theo thuật ngữ tuyệt đối là đủ.

Kết quả này làm nổi bật nhu cầu điều tra các phương pháp mới để phát hiện văn bản do AI tạo ra được chuyển đổi phong cách. Vì chuyển đổi phong cách trang trọng vẫn là một cuộc tấn công hiệu quả, các đặc trưng không trang trọng được tạo ra bởi mô hình của chúng tôi có thể giúp cải thiện các bộ phân loại như vậy. Chúng tôi để lại cuộc điều tra này cho công trình tương lai.

Các mô hình GPTZero OpenAI GPTDetect BM25 P-SP
GPT-F 85.92 70.64 104.88 100 100
GPT-Inf 69.58 54.24 65.42 48.15 74.99
F→IF 6.11 44.86 54.92 58.68 74.08

Bảng 17: Hiệu suất của các máy dò văn bản do AI tạo ra khác nhau trên các câu diễn đạt lại không trang trọng từ mô hình của chúng tôi. Ngay cả các phương pháp truy xuất cũng hoạt động kém trong cài đặt này.

H Thống kê E-EGYAFC

Chúng tôi cung cấp phân phối của 50 thuộc tính không trang trọng và trang trọng thường xuất hiện nhất trong E-GYAFC trong Hình 5, 6.

I Thống kê E-WNC

Chúng tôi cung cấp tỷ lệ các lớp trong E-WNC trong Bảng 18.

--- TRANG 18 ---
0 1000 2000 3000 4000
Tần suấttừ rút gọn
thành ngữ thông tục
từ viết tắt
đại từ nhân xưng
tiếng lóng
giọng điệu thường
dấu câu không trang trọng
viết hoa
từ vựng không trang trọng
từ viết tắt
cấu trúc câu đơn giản
giọng điệu không trang trọng
giọng điệu đàm thoại
lỗi chính tả
ngôn ngữ cảm xúc
nhấn mạnh
dấu ba chấm
đoạn câu
từ vựng thường
thiếu chính xác
biểu tượng cảm xúc
ngôn ngữ thường
liên từ
ngôn ngữ không trang trọng
cách diễn đạt không trang trọng
câu không hoàn chỉnh
sử dụng từ rút gọn
lặp lại
sử dụng đại từ nhân xưng
biểu thức không trang trọng
ngôn ngữ mơ hồ
câu hỏi trực tiếp
động từ cụm
ngữ pháp ít nghiêm ngặt
mệnh lệnh
cảm thán
từ đệm
thỏa thuận động từ
lựa chọn từ không trang trọng
mệnh lệnh trực tiếp
dấu cảm thán
bỏ qua mạo từ
cú pháp không chuẩn
đại từ
liên từ không trang trọng
câu mệnh lệnh
từ viết tắt không trang trọng
ý kiến cá nhân
ngôn ngữ không chính xác
thành ngữ quanThuộc tính

Hình 5: Phân phối của 50 thuộc tính không trang trọng thường xuất hiện nhất trong tập dữ liệu E-GYAFC.

J Giao thức chú thích

Các ảnh chụp màn hình cho các giao diện giải thích được cung cấp dưới đây trong Hình 7, 8, 9. Các giao diện chú thích tương tự đã được sử dụng cho nhiệm vụ thiên vị.

K Nhân khẩu học người chú thích

Các người chú thích là một phần của nhân khẩu học đa dạng, có mặt về mặt địa lý ở Bắc Mỹ, Châu Âu và Đông Nam Á (như được báo cáo bởi Upwork). Tất cả các người chú thích đều cho biết ít nhất thành thạo đến bản ngữ về kỹ năng tiếng Anh.

L Trợ lý AI

Các tác giả đã sử dụng các trợ lý AI như Co-Pilot và ChatGPT để viết mã.

0 1000 2000 3000 4000
Tần suấtngôn ngữ chính xác
từ vựng tinh tế
không có từ rút gọn
thể bị động
từ vựng trang trọng
đại từ phi cá nhân
từ vựng chính xác
ngôn ngữ lịch sự
ngôn ngữ thận trọng
cấu trúc câu phức tạp
giọng điệu trung tính
tránh từ rút gọn
cấu trúc logic rõ ràng
mệnh đề điều kiện
sử dụng thể bị động
không có từ rút gọn
giọng điệu trang trọng
từ hoàn chỉnh
giọng điệu lịch sự
từ vựng tinh tế
từ vựng cao cấp
câu hỏi gián tiếp
ngôn ngữ trang trọng
không có thành ngữ thông tục
chính xác
sử dụng ngôn ngữ trang trọng
ngôn ngữ rõ ràng và chính xác
sử dụng động từ khuyết thiếu
sử dụng ngôn ngữ chính xác
cấu trúc câu hoàn chỉnh
cách diễn đạt trang trọng
sử dụng đại từ phi cá nhân
sử dụng từ vựng trang trọng
cấu trúc logic
đại từ nhân xưng
ngôn ngữ phi cá nhân
yêu cầu lịch sự
ngôn ngữ gián tiếp
cách diễn đạt chính xác
câu hoàn chỉnh
không có đại từ nhân xưng
sử dụng trạng từ
biểu thức trang trọng
không có tiếng lóng
dạng câu hỏi gián tiếp
cách diễn đạt lịch sự
từ đầy đủ
né tránh
ngôn ngữ trung tính
ngôn ngữ cụ thểThuộc tính

Hình 6: Phân phối của 50 thuộc tính trang trọng thường xuất hiện nhất trong tập dữ liệu E-GYAFC.

Danh mục (%)
Nhân khẩu học 3.70
Nhận thức luận 22.87
Đóng khung 67.53
Không có Thiên vị 5.90

Bảng 18: Tỷ lệ các lớp trong E-WNC

--- TRANG 19 ---
Hình 7: Chú thích để thu thập phản hồi cho ICLEF.

--- TRANG 20 ---
Hình 8: Chú thích cho tính chấp nhận dữ liệu eGYAFC và sở thích.

--- TRANG 21 ---
Hình 9: Chú thích cho sở thích mô hình.

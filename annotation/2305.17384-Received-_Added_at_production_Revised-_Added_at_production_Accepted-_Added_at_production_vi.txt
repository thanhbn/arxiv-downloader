# 2305.17384.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/annotation/2305.17384.pdf
# Kích thước tệp: 1329777 byte

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
Nhận được: Đã thêm tại sản xuất Sửa đổi: Đã thêm tại sản xuất Chấp nhận: Đã thêm tại sản xuất
DOI: xxx/xxxx
LOẠI BÀI BÁO
WELL: Áp dụng Bộ phát hiện lỗi vào Định vị lỗi thông qua
Học máy được giám sát yếu
Zhuo Li | Huangzhao Zhang | Zhi Jin | Ge Li*
1Phòng thí nghiệm Trọng điểm Công nghệ
Phần mềm Tin cậy cao, Đại học Bắc Kinh,
Bắc Kinh, Trung Quốc
Liên hệ
*Ge Li. Số 1542, Tòa nhà Khoa học số 1.
Số 5 Đường Yiheyuan, Quận Haidian,
Bắc Kinh 100871. Email: lige@pku.edu.cnTóm tắt
Định vị lỗi, được sử dụng để giúp lập trình viên xác định vị trí của lỗi trong mã nguồn, là một nhiệm vụ quan trọng trong phát triển phần mềm. Các nhà nghiên cứu đã nỗ lực khai thác các kỹ thuật học sâu (DL) mạnh mẽ để tự động hóa nó. Tuy nhiên, việc huấn luyện mô hình định vị lỗi thường khó khăn vì nó đòi hỏi một lượng lớn dữ liệu được gán nhãn với vị trí chính xác của lỗi, điều này khó khăn và tốn thời gian để thu thập. Ngược lại, việc có được dữ liệu phát hiện lỗi với nhãn nhị phân về việc có lỗi trong mã nguồn hay không đơn giản hơn nhiều. Bài báo này đề xuất phương pháp định vị lỗi được giám sát yếu (WELL - WEakly supervised bug LocaLization), chỉ sử dụng dữ liệu phát hiện lỗi với nhãn nhị phân để huấn luyện mô hình định vị lỗi. Với CodeBERT được tinh chỉnh trên dữ liệu được gán nhãn nhị phân có-lỗi-hay-không, WELL có thể giải quyết định vị lỗi theo cách được giám sát yếu. Các đánh giá trên ba bộ dữ liệu tổng hợp cấp phương thức và một bộ dữ liệu thực tế cấp tệp cho thấy WELL tốt hơn đáng kể so với mô hình SOTA hiện có trong các nhiệm vụ định vị lỗi điển hình như sử dụng sai biến và các lỗi lập trình khác.
TỪ KHÓA:
Phát hiện lỗi, định vị lỗi, học máy được giám sát yếu

1 GIỚI THIỆU
Định vị lỗi là một trong những hoạt động chính trong kỹ thuật phần mềm (SE), nơi các chuyên gia phải định vị phần lỗi của mã. Việc tự động hóa định vị lỗi một cách hiệu quả là quan trọng đối với các nhà phát triển phần mềm vì nó có thể cải thiện năng suất và chất lượng phần mềm rất nhiều.

Trong thập kỷ qua, học sâu (DL) đã chứng minh sức mạnh to lớn của mình trong nhiều nhiệm vụ SE, và đã đạt được hiệu suất tốt nhất (SOTA) trong phân loại chức năng1,2, phát hiện nhân bản mã3,4, đặt tên phương thức5,6, hoàn thiện mã7,8,9 và tóm tắt mã10,11,12, v.v. Những điều này có thể cho thấy tính khả thi của việc khai thác các kỹ thuật DL để tạo điều kiện cho định vị lỗi tự động. Các nhà nghiên cứu đã thử áp dụng các mô hình DL vào định vị lỗi13,14,15,16. GREAT15 và CuBERT16 là trong số các mô hình DL SOTA cho định vị lỗi và sửa lỗi tiếp theo. Lấy sử dụng sai biến (VarMisuse)13 làm ví dụ, đây là một trong những nhiệm vụ định vị lỗi dựa trên DL được nghiên cứu kỹ lưỡng nhất, các mô hình DL phải định vị biến được sử dụng sai trong mã có lỗi đã cho. Các phương pháp hiện tại, bao gồm GREAT và CuBERT, được huấn luyện theo kiểu đầu cuối đến đầu cuối, tức là các vị trí lỗi trong mã được chú thích chi tiết trong tập huấn luyện.

Một thách thức chính trong các giải pháp DL hiện tại cho định vị lỗi là việc có được các mô hình như GREAT và CuBERT đòi hỏi một lượng lớn dữ liệu huấn luyện được chú thích vị trí lỗi. Loại dữ liệu này cung cấp giám sát mạnh vì các chú thích rất chi tiết và có liên quan cao đến nhiệm vụ định vị lỗi. Tuy nhiên, bộ dữ liệu như vậy với chất lượng chú thích hợp lý và đủ ví dụ khó thu thập hoặc chú thích, do chi phí lớn về nhân lực và tài nguyên trong các tình huống thực tế. Theo Benton et al.17, chỉ có một số ít bộ dữ liệu lỗi lớn và có sẵn công khai với chất lượng cao cho mục đích nghiên cứu. Các bộ dữ liệu định vị lỗi thường được lấy theo hai cách chính - chú thích thủ công hoặc thu thập tự động. ❶Như đã đề cập trước đó, việc chú thích dữ liệu định vị lỗi chất lượng cao tiêu tốn rất nhiều nhân lực và tài nguyên.

--- TRANG 2 ---
2 Zhuo Li et al.
HÌNH 1 Một ví dụ minh họa về phát hiện lỗi, định vị lỗi, và định vị lỗi được giám sát yếu. Bộ dữ liệu phát hiện lỗi (trên bên trái) bao gồm các đoạn mã nguồn và các nhãn nhị phân có-lỗi-hay-không tương ứng, dễ tiếp cận. Trong khi bộ dữ liệu định vị lỗi (dưới bên trái) được chú thích bởi vị trí lỗi trong mã, khó thu thập. Các mô hình cho định vị lỗi được giám sát yếu (giữa bên phải) được huấn luyện trên bộ dữ liệu phát hiện, nhưng có thể thực hiện cả phát hiện và định vị lỗi.

cặp dữ liệu. Các người chú thích phải là các nhà phát triển phần mềm có kinh nghiệm, và họ phải dành đủ thời gian để đọc và hiểu mã cùng với báo cáo lỗi để định vị vị trí lỗi cho mỗi ví dụ được chú thích. ❷Thu thập bộ dữ liệu tự động, mặt khác, hiệu quả hơn nhiều. Nó thường sử dụng trình thu thập web và bộ lọc dựa trên quy tắc để tìm các commit sửa lỗi trong các dự án mã nguồn mở để định vị lỗi. Tuy nhiên, chất lượng chú thích của các phương pháp tự động không được đảm bảo. Ví dụ, Lutellier et al.18 gần đây đề xuất một bộ dữ liệu sửa chữa chương trình lớn (cấp triệu) được thu thập từ lịch sử commit của các dự án mã nguồn mở, nhưng lên đến 7 trong số 100 mẫu ngẫu nhiên không thực sự liên quan đến lỗi trong các cuộc điều tra thủ công của họ.

Mặt khác, phát hiện lỗi thường là một nhiệm vụ phân loại nhị phân, và sử dụng dữ liệu được chú thích thô để huấn luyện các mô hình DL. Dữ liệu được chú thích có-lỗi-hay-không cung cấp giám sát yếu so với định vị lỗi, vì độ chi tiết chú thích thô hơn nhiều. Dữ liệu cho phát hiện lỗi dễ thu thập hoặc chú thích hơn nhiều. Người ta có thể tự động chạy thử nghiệm trên các dự án để xác định hàm hoặc tệp nào có lỗi, mà không cần nhiều nỗ lực để đi sâu vào dự án hay báo cáo lỗi. Do đó, nói ngắn gọn, dữ liệu định vị lỗi khan hiếm và khó thu thập hoặc chú thích, trong khi dữ liệu cho phát hiện lỗi dễ tiếp cận hơn.

Vì vậy, chúng tôi giới thiệu ý tưởng học được giám sát yếu vào định vị lỗi. Phương pháp là huấn luyện mô hình mạnh (định vị lỗi) với các tín hiệu giám sát yếu (bộ dữ liệu phát hiện lỗi), như được minh họa trong Hình 1. Về mặt heuristic, một mô hình phát hiện lỗi nội bộ học được sự phụ thuộc của nhãn lỗi vào các phần lỗi trong mã. Truy xuất kiến thức như vậy được nhúng trong mô hình phát hiện lỗi để đạt được định vị lỗi là rất mong muốn và khả thi. Dựa trên trực giác như vậy, chúng tôi đề xuất WEakly supervised bug LocaLization (WELL), biến đổi mô hình phát hiện lỗi thành bộ định vị lỗi mà không cần bất kỳ trọng số có thể huấn luyện bổ sung nào hay dữ liệu định vị lỗi. WELL tận dụng đầy đủ dữ liệu phát hiện lỗi dễ tiếp cận để giải quyết thách thức thiếu dữ liệu trong định vị lỗi. Để tóm tắt phần kỹ thuật, WELL khai thác sức mạnh của mô hình CodeBERT được huấn luyện trước19, và tinh chỉnh CodeBERT cho định vị lỗi theo cách được giám sát yếu. Cụ thể, WELL tinh chỉnh CodeBERT trên các bộ dữ liệu phát hiện lỗi, trong giai đoạn huấn luyện. Khi định vị lỗi, WELL thu được điểm attention từ CodeBERT đã được tinh chỉnh và trích xuất phần quan trọng từ mã nguồn đầu vào dựa trên điểm số. Theo trực giác, nếu CodeBERT phân loại một đoạn mã là có lỗi, đoạn lỗi có khả năng được bao gồm trong phần chính của đầu vào, thu hút sự chú ý nhiều nhất của mô hình. Theo cách này, định vị lỗi được giám sát yếu được đạt được trong WELL.

Cuối cùng, để chứng minh tính hiệu quả và khả năng của WELL, chúng tôi thực hiện các đánh giá sâu trên ba bộ dữ liệu định vị lỗi cấp token tổng hợp khác nhau và một bộ dữ liệu định vị lỗi thực tế của các chương trình sinh viên. Ba bộ dữ liệu tổng hợp bao gồm VarMisuse, sử dụng sai toán tử hai ngôi (BiOpMisuse) và lỗi điều kiện biên (BoundError). Chúng là các bộ dữ liệu định vị lỗi tổng hợp được nghiên cứu nhiều nhất sử dụng các phương pháp DL. Bộ dữ liệu định vị lỗi chương trình sinh viên được gọi là StuBug. Trên bộ dữ liệu này, chúng tôi huấn luyện mô hình phát hiện của mình với nhãn kết quả thử nghiệm nhị phân ("passed" hoặc "wrong answer") và định vị các dòng lỗi mà không có bất kỳ chú thích nào khác. Đối với ba bộ dữ liệu tổng hợp, trung bình, WELL phát hiện đúng

--- TRANG 3 ---
Zhuo Li et al. 3
và định vị chính xác 79.74% lỗi, và phiên bản mở rộng (WELL-1) thậm chí định vị 87.57% lỗi. Cụ thể, WELL cải thiện độ chính xác định vị của VarMisuse lên 92.28% bằng cách tăng hơn 4% so với CuBERT. Đối với StuBug, WELL có thể định vị ít nhất 1 lỗi cho hơn 29%/85% chương trình khi báo cáo dòng/những dòng nghi ngờ top-1/top-10 trên mỗi chương trình, vượt trội so với các mô hình cơ sở đáng kể. Nghiên cứu ablation tiếp tục chứng minh rằng việc áp dụng giám sát yếu cho các backbone khác, chẳng hạn như LSTM, là khả thi. Mã của dự án này được mở nguồn trên Github1.

Các đóng góp của bài báo này được tóm tắt như sau:
•Chúng tôi giới thiệu phương pháp giám sát yếu vào định vị lỗi, bằng cách sử dụng dữ liệu phát hiện lỗi. Phương pháp này giải quyết vấn đề thiếu dữ liệu và tận dụng đầy đủ dữ liệu dễ tiếp cận.
•Chúng tôi đề xuất WELL, biến các bộ phát hiện lỗi thành bộ định vị lỗi mà không cần dữ liệu huấn luyện định vị hay tham số có thể huấn luyện bổ sung. WELL học cách định vị lỗi chỉ với các bộ dữ liệu phát hiện lỗi.
•Chúng tôi thực hiện các đánh giá sâu để chứng minh tính hiệu quả của WELL đề xuất so với các phương pháp DL SOTA hiện có cho định vị lỗi. So với các mô hình cơ sở được có được với tín hiệu giám sát mạnh, WELL được huấn luyện với giám sát yếu tạo ra hiệu suất cạnh tranh hoặc thậm chí tốt hơn.
•Chúng tôi chứng minh khả năng áp dụng giám sát yếu cho backbone LSTM thông qua nghiên cứu ablation, gợi ý khả năng và tính di động của phương pháp.

2 CÔNG TRÌNH LIÊN QUAN
Trong phần này, chúng tôi thảo luận công trình liên quan nhất đến bài báo này, bao gồm các nhiệm vụ chủ đề của DL cho phát hiện lỗi và định vị lỗi (Mục 2.1), phương pháp học được giám sát yếu (Mục 2.2) và các kỹ thuật cho trực quan hóa và giải thích mô hình DL (Mục 2.3).

2.1 DL cho Phát hiện và Định vị lỗi
Đến nay, rất nhiều nỗ lực đã được thực hiện trong xử lý mã nguồn bằng cách áp dụng các kỹ thuật DL trong cộng đồng SE2,4,6,12,8,9. Để tận dụng DL cho phát hiện lỗi, Wang et al.20 đề xuất mạng belief sâu dựa trên AST cho dự đoán khuyết tật. Choi et al.21 sử dụng mạng neural bộ nhớ để dự đoán buffer overrun. Li et al.22 đề xuất VulDeePecker để phát hiện một số loại lỗ hổng trong mã nguồn. Pradel và Sen23 đề xuất DeepBugs cho lỗi trong câu lệnh gọi hàm và biểu thức nhị phân, với mạng feed-forward lấy loại và tên biến làm đầu vào.

Đối với định vị lỗi dựa trên DL, các nghiên cứu được thực hiện chủ yếu trên các bộ dữ liệu tổng hợp nhân tạo, nơi các loại lỗi nhất định được tiêm vào mã sạch để hình thành các cặp dữ liệu được chú thích vị trí lỗi, do vấn đề thiếu dữ liệu đã đề cập. Allamanis et al.13 đầu tiên đề xuất nhiệm vụ VarMisuse, là một trong những nhiệm vụ được nghiên cứu kỹ lưỡng nhất trong định vị lỗi dựa trên DL hiện nay. Vasic et al.14 sử dụng kiến trúc sequence-to-pointer (Seq2Ptr) để phát hiện, định vị và sửa lỗi VarMisuse một cách kết hợp. Gần đây hơn, Hellendoorn et al.15 đề xuất hai kiến trúc để tạo ra các biểu diễn phân tán cho mã nguồn nhằm định vị lỗi, cụ thể là Graph-Sandwich và GREAT. Kanade et al.16 đề xuất CuBERT được huấn luyện trước cho VarMisuse và nhiều nhiệm vụ phát hiện và định vị lỗi khác.

Mặc dù một số công trình hiện tại đã đề cập huấn luyện mô hình phát hiện và định vị lỗi kết hợp14,15,16, tức là các mô hình DL được huấn luyện để phát hiện và định vị lỗi đồng thời trên các bộ dữ liệu định vị lỗi, chúng không tìm cách tạo điều kiện cho định vị lỗi thông qua các tín hiệu giám sát yếu từ dữ liệu phát hiện lỗi (phân loại nhị phân). Kết quả là, vấn đề thiếu dữ liệu thường khó khăn và không thể tránh khỏi trong DL truyền thống cho định vị lỗi trong thế giới thực. Trong bài báo này, ngược lại, WELL áp dụng phương pháp học được giám sát yếu, và tận dụng dữ liệu có-lỗi-hay-không dễ tiếp cận và phong phú để tinh chỉnh CodeBERT như một bộ phát hiện lỗi cho định vị lỗi chi tiết cấp token.

2.2 Học được Giám sát Yếu
Giám sát yếu có thể được phân loại thành giám sát không đầy đủ, giám sát không chính xác và giám sát không chính xác. Trong bài báo này, chúng tôi tập trung vào giám sát không chính xác, nơi chú thích của dữ liệu huấn luyện chỉ là nhãn thô (ví dụ, dữ liệu có-lỗi-hay-không cung cấp giám sát yếu cho nhiệm vụ định vị lỗi). Vui lòng tham khảo cuộc khảo sát24 để thảo luận chi tiết hơn về các loại giám sát yếu khác.

Phương pháp học được giám sát yếu đã được chứng minh là hợp lệ trong nhiều nhiệm vụ DL. Trong thị giác máy tính (CV), các nhà nghiên cứu tạo điều kiện cho phân đoạn ngữ nghĩa hình ảnh thông qua các bộ dữ liệu phân loại được chú thích thô. Các chú thích yếu bao gồm hộp giới hạn25,26, vết gạch27, và điểm28, v.v. Gần đây hơn, phân đoạn cấp pixel bằng chú thích cấp hình ảnh đã được đạt được thông qua kỹ thuật

--- TRANG 4 ---
4 Zhuo Li et al.
BẢNG 1 Tóm tắt ký hiệu và biểu tượng trong bài báo này.
Ký hiệu Định nghĩa
Dt,Dv,De Bộ dữ liệu cho huấn luyện, xác thực & đánh giá.
X,Y Không gian mã nguồn & không gian chú thích.
x= (t1,···, tl) Chuỗi token của mã nguồn.
(s1,···, sl′) Chuỗi subtoken của mã nguồn.
C,ΘC Mô hình DL & các tham số có thể huấn luyện của nó.
y,˜y Chú thích & dự đoán từ mô hình.
L(˜y, y) Hàm mất mát.
Q, K, V Các ma trận query, key & value trong attention.
h= (h0,···, hl′) Các trạng thái ẩn nhận biết ngữ cảnh.
α= (α1,···, αnh) Multi-head attention với nh heads.

CAM29,30,31,32. Đối với xử lý ngôn ngữ tự nhiên (NLP), các nhà nghiên cứu cũng tận dụng giám sát yếu trong các nhiệm vụ gán nhãn chuỗi, chẳng hạn như nhận dạng thực thể có tên (NER), để giảm bớt gánh nặng chú thích dữ liệu33,34,35,36. Phương pháp liên quan nhất đến WELL là Token Tagger34, sử dụng kiến trúc dựa trên attention cho NER được giám sát yếu với chú thích cấp câu. Token Tagger được huấn luyện để phân loại liệu có thực thể có tên trong câu hay không, và trong NER, nó chọn các token quan trọng nhất dựa trên điểm attention.

Trong bài báo này, chúng tôi áp dụng ý tưởng học được giám sát yếu để huấn luyện bộ định vị lỗi với dữ liệu được chú thích có-lỗi-hay-không. Logic bên trong để tận dụng attention cho học được giám sát yếu của WELL được lấy cảm hứng từ Token Tagger.

2.3 Trực quan hóa & Giải thích Mô hình DL
Việc diễn giải các mô hình DL có thể hỗ trợ các nhà nghiên cứu hiểu và giải thích cơ chế bên trong của mạng neural, và các kỹ thuật như vậy có thể thúc đẩy học được giám sát yếu về mặt kỹ thuật. Trong CV, hiện tại, họ CAM29,30,31,32 là những kỹ thuật được áp dụng rộng rãi và trưởng thành nhất để trực quan hóa và giải thích các bộ phân loại hình ảnh. Nó tạo ra một bản đồ nhiệt, nơi giá trị phản ánh đóng góp và tầm quan trọng của pixel tương ứng đối với dự đoán cuối cùng.

Đối với NLP, liên quan hơn đến các nhiệm vụ chủ đề của chúng tôi, selective rationalization37,38,39,40,41 là một trong những kỹ thuật hiệu quả nhất để giải thích các bộ phân loại câu. Nó xác định rationale, là một chuỗi con của câu đầu vào, để giải thích hoặc hỗ trợ tốt nhất dự đoán từ mô hình DL. FRESH41 được đề xuất gần đây sử dụng khung hai mô hình cho rationalization. Nó tạo ra điểm đặc trưng heuristic (ví dụ, điểm attention) từ BERT chủ đề để có được các thẻ nhị phân giả trên từ, và tinh chỉnh một BERT khác theo cách gán nhãn chuỗi như rationale tagger. Công trình này chứng minh sức mạnh của các mô hình được huấn luyện trước trong việc hiểu và giải thích các mô hình NLP.

Lấy cảm hứng từ FRESH, chúng tôi sử dụng khung đơn giản hóa trong WELL, sử dụng một CodeBERT19 bộ phát hiện lỗi đã được tinh chỉnh duy nhất để tạo ra điểm attention cho định vị lỗi. Như được chứng minh trong selective rationalization, attention trong CodeBERT được cho là khai thác các phần của mã có thông tin cho phát hiện lỗi, và các phần như vậy được cho là lỗi.

3 ĐỊNH NGHĨA VẤN ĐỀ & SƠ BỘ
Trong phần này, trước tiên chúng tôi cung cấp định nghĩa chính thức về các nhiệm vụ đối tượng (Mục 3.1). Sau đó chúng tôi giải thích cơ chế multi-head attention trong mô hình transformer (Mục 3.2), dựa trên đó chúng tôi tạo điều kiện cho WELL. Và cuối cùng, chúng tôi giới thiệu mô hình CodeBERT lớn được huấn luyện trước cho mã nguồn (Mục 3.3), hoạt động như backbone của WELL. Các ký hiệu chúng tôi sử dụng trong bài báo này được tóm tắt trong Bảng 1.

3.1 Phát hiện & Định vị lỗi
Bộ dữ liệu. Cả phát hiện lỗi và định vị đều là các nhiệm vụ được giám sát, vì các bộ dữ liệu được chú thích. Một bộ dữ liệu điển hình bao gồm nhiều cặp ví dụ, tức là D={(x1, y1),···,(xn, yn)}, trong đó n đề cập đến kích thước của bộ dữ liệu. Một cặp ví dụ (x, y)∈ D bao gồm một đoạn mã nguồn x∈ X và chú thích tương ứng y∈ Y. Không gian chú thích thay đổi cho các nhiệm vụ khác nhau, sẽ được định nghĩa sau trong phần này. Mã nguồn đã được tokenize, tức là x= (t1,···, tl), trong đó ti là token thứ i trong x và l là độ dài của chuỗi token.

--- TRANG 5 ---
Zhuo Li et al. 5
Mô hình. Một mô hình DL C lấy mã nguồn đã được tokenize x làm đầu vào, và xuất ra ˜y∈ Y như dự đoán. Lưu ý rằng định dạng đầu ra cũng thay đổi cho các nhiệm vụ khác nhau. C phải tạo ra ˜y=y, trong đó dự đoán khớp chính xác với ground-truth. Để có được các tham số tối ưu trong C là tối ưu hóa hàm mục tiêu minΘCP(x,y)∈DtL(˜y, y), trong đó L(·) là hàm mất mát (thường là cross entropy), đo độ tương tự của ˜y và y. Đối với những C đòi hỏi các định dạng đầu vào khác nhau (ví dụ, AST hoặc đồ thị), chúng tôi giả định rằng chúng xử lý định dạng bên trong.

Phát hiện lỗi. Chúng tôi định nghĩa phát hiện lỗi ở cấp phương thức. Phát hiện lỗi là xác định liệu có lỗi tồn tại trong phương thức hoặc hàm đã cho hay không. Do đó, không gian chú thích cho phát hiện lỗi là nhị phân, tức là Y={0,1}, trong đó y= 1 gợi ý rằng hàm tương ứng x có lỗi, trong khi y= 0 ngược lại. Một phương pháp thường được áp dụng để xây dựng bộ phát hiện lỗi là trước tiên tạo ra một vector mã hóa của mã nguồn thông qua mô hình biểu diễn mã, và sau đó phân loại mã hóa với mạng feed forward.

Định vị lỗi. Định vị lỗi là xác định chuỗi con token nào gây ra lỗi trong mã đã cho. Chú thích cho định vị lỗi được định nghĩa như một chuỗi nhãn nhị phân, tức là Y={0,1}l. Mỗi chú thích token yi trong y= (y1,···, yl) là nhị phân, trong đó yi= 1 gợi ý rằng ti tham gia vào lỗi, trong khi yi= 0 ngược lại. Do đó, định vị lỗi có thể được xem như một vấn đề gán thẻ chuỗi trên mã nguồn. Bộ định vị lỗi lấy x làm đầu vào và gán thẻ nhị phân cho mỗi ti.

Trong bài báo này, như một bước rất sớm trong lĩnh vực này, chúng tôi tập trung vào các lỗi tổng hợp chi tiết, nơi lỗi được gây ra bởi một hoặc hai token, ví dụ, VarMisuse bởi một biến sử dụng sai duy nhất, BiOpMisuse bởi một toán tử hai ngôi sử dụng sai duy nhất, và BoundError bởi một toán tử bất đẳng thức sử dụng sai duy nhất. Chúng tôi đề xuất và đánh giá WELL trên các bộ dữ liệu này. WELL được giám sát yếu đề xuất có tiềm năng được mở rộng để phát hiện và định vị các lỗi phức tạp khác. Chúng tôi để dành điều này cho công việc tương lai.

Định vị lỗi được giám sát mạnh hiện tại. Các phương pháp hiện tại chủ yếu dựa trên khung Seq2Ptr14,15,16. Mô hình DL được huấn luyện trên các bộ dữ liệu được chú thích vị trí lỗi với giám sát mạnh. Cụ thể, mô hình mã hóa mã nguồn, và tính toán attention dựa trên các biểu diễn token. "Con trỏ" trỏ đến token với điểm attention cao nhất như vị trí lỗi được dự đoán, và đối với mã không có lỗi (sạch), "con trỏ" trỏ đến một token "clean" đặc biệt được chèn vào chuỗi.

3.2 Attention trong Transformer
Kỹ thuật attention được đề xuất đầu tiên trong mô hình Seq2Seq42, nhằm tập trung có chọn lọc vào các phần của chuỗi nguồn trong quá trình dự đoán. Hàm attention ánh xạ nhiều query và một tập cặp key-value thành tổng có trọng số của các value, trong đó trọng số được gán cho mỗi value được tính toán với query và key tương ứng43.

Query, key & value. Các query, key và value đều là vector. Các query Q= (Q1,···, Qn) là các điểm quan tâm, các value V= (V1,···, Vl) là các vector được đánh trọng số, và các key K= (K1,···, Kl) là "mô tả" của V. Lưu ý rằng mỗi Ki và Vi được ghép nối. Chúng ta query Qi so với key Kj về bao nhiều phần của value Vj nên được bao gồm trong đầu ra tổng có trọng số.

Scaled self-attention. Scaled self-attention đo mức độ liên quan của các token trong chuỗi đã cho x với nhau. Do đó, Q, K và V đều được tạo ra từ X, trong đó X∈Rl×d là ma trận embedding của x và d là chiều của không gian embedding. Cụ thể, Q=WQX, K=WKX, và V=WVX, trong đó WQ, WK và WV là các tham số có thể huấn luyện. Scaled self-attention được tính toán như Phương trình 1, trong đó α(Q, K) tạo ra điểm attention xác suất, và σ là hàm softmax. αij (phần tử của hàng thứ i và cột thứ j trong α) là điểm attention của query Qi so với key Kj. αij phản ánh mức độ liên quan của ti và tj trong x. Đối với các loại attention khác, vui lòng tham khảo44.

Attention( Q, K, V ) =α(Q, K)V=σQKT√dV (1)

Multi-head attention. Cơ chế multi-head attention được đề xuất trong transformer43 để tập trung vào các loại thông tin khác nhau trong chuỗi. Nó bao gồm nhiều tập scaled self-attention, và mỗi attention được gọi là một head, trong đó các tham số trong mỗi head không được chia sẻ. Các đầu ra của các head này được nối và biến đổi tuyến tính để tích hợp thông tin và tạo ra biểu diễn cuối cùng. Công thức tổng thể của multi-head attention trong kiến trúc transformer được suy ra như dưới đây:

MultiHead( X) = Concat(head 1,···,head nh)WO,
trong đó head i= Attention i(Qi, Ki, Vi),(2)
trong đó nh là số head, và WO, cùng với WQi,WKi,WV i trong head thứ i, là các tham số có thể huấn luyện.

Lớp transformer. Kiến trúc transformer43 được cấu thành từ một chồng các lớp transformer giống hệt nhau. Mỗi lớp bao gồm một multi-head attention và một mạng neural được kết nối đầy đủ. Hai module này được liên kết thông qua kết nối dư45 và layer normalization bổ sung46. Lớp thứ i lấy Xi làm đầu vào và tính toán Xi+1 cho lớp thứ i+ 1 ( X1=X). Vui lòng tham khảo "Layer 1" trong Hình 2 để biết cấu trúc chi tiết của lớp transformer.

--- TRANG 6 ---
6 Zhuo Li et al.
HÌNH 2 Một ví dụ minh họa về WELL dựa trên backbone CodeBERT. Chúng tôi vẽ biểu đồ luồng tính toán của lớp transformer chỉ cho "Layer 1" để tiết kiệm không gian. Phần trên bên trái là cho phát hiện lỗi, trong khi phần trên bên phải là cho định vị lỗi.

3.3 Các Mô hình được Huấn luyện trước
Với sự gia tăng nhanh chóng của lượng dữ liệu huấn luyện có thể truy cập và sức mạnh tính toán, cách sử dụng các mô hình DL cũng đã thay đổi rất nhiều. Gần đây, các nhà nghiên cứu đã chứng minh hiệu suất SOTA của các mô hình được huấn luyện trước lớn trên các nhiệm vụ khác nhau qua các lĩnh vực khác nhau bao gồm CV và NLP. So với huấn luyện truyền thống từ đầu, huấn luyện trước trên các nhiệm vụ chung và tinh chỉnh trên các nhiệm vụ downstream cụ thể dẫn đến cải thiện hiệu suất đáng kể. Ý tưởng huấn luyện trước được giới thiệu vào lĩnh vực SE sau này, dẫn đến mô hình CodeBERT19 được huấn luyện trước cho mã nguồn.

CodeBERT. Theo công trình của BERT47 và RoBERTa48 trong NLP, Feng et al.19 đề xuất CodeBERT cho mã nguồn, sử dụng kiến trúc và kích thước mô hình giống hệt với RoBERTa. Kiến trúc chung của CodeBERT được hiển thị trong Hình 2. Cụ thể, CodeBERT bao gồm 12 lớp transformer (Layer 1 đến 12). Kích thước ẩn, số head attention và kích thước feed-forward trong mỗi lớp lần lượt là 768, 12 và 3,072, dẫn đến tổng kích thước tham số 125 triệu. CodeBERT được huấn luyện trước trên bộ dữ liệu CodeSearchNet49 với hơn 8 triệu hàm qua sáu ngôn ngữ lập trình (tức là Python, Java, JavaScript, Php, Ruby và Go). Sau khi tinh chỉnh, CodeBERT có khả năng thực hiện các nhiệm vụ phân loại mã và tạo mã (như một encoder), và tạo ra kết quả SOTA trong các nhiệm vụ SE khác nhau50.

4 WELL- ĐỊNH VỊ LỖI ĐƯỢC GIÁM SÁT YẾU
Trong phần này, chúng tôi minh họa chi tiết WELL đề xuất. Trước tiên chúng tôi đưa ra tổng quan cấp cao về WELL trong Mục 4.1, định vị lỗi thông qua học trên các nhiệm vụ phát hiện theo cách được giám sát yếu. Sau đó, chúng tôi trình bày chi tiết về huấn luyện mô hình và định vị lỗi trong Mục 4.2 và Mục 4.3. Cuối cùng, chúng tôi mở rộng WELL bằng cách tận dụng một lượng nhỏ dữ liệu được chú thích vị trí lỗi để xác thực khi có sẵn.

4.1 Tổng quan về WELL
Trước tiên chúng tôi trình bày ý tưởng cấp cao của WELL đề xuất, sử dụng mô hình CodeBERT làm backbone để định vị lỗi trong mã nguồn theo cách được giám sát yếu. Cần ba bước để đạt được học được giám sát yếu: ❶tinh chỉnh CodeBERT trên các bộ dữ liệu phát hiện lỗi, ❶dự đoán

--- TRANG 7 ---
Zhuo Li et al. 7

liệu một đoạn mã nghi ngờ có lỗi hay không, và ❸định vị vị trí lỗi dựa trên điểm attention. Người ta có thể lưu ý rằng tinh chỉnh (hoặc huấn luyện) và dự đoán tạo thành mô hình học phổ biến của các nhiệm vụ phân loại như phát hiện lỗi. Chúng tôi theo mô hình này để có được CodeBERT như bộ phát hiện lỗi, và tạo điều kiện cho định vị lỗi theo điểm attention. Trực quan, nếu CodeBERT có khả năng phát hiện lỗi, đoạn mã thu hút sự chú ý nhiều nhất nên có liên quan đến lỗi. Do đó, multi-head attention nên tiết lộ tại sao và như thế nào CodeBERT phát hiện lỗi, và theo cách này, chúng ta đạt được định vị lỗi được giám sát yếu.

WELL lấy chuỗi token mã nguồn làm đầu vào, và xuất ra nhãn có-lỗi-hay-không được dự đoán và vị trí lỗi, như được minh họa trong Hình 2. Cụ thể, trong quá trình định vị, WELL trước tiên thực hiện phân loại nhị phân trên mã với CodeBERT đã được tinh chỉnh ("Tokens" lên đến " h" trong Hình 2). Nếu dự đoán là âm tính, WELL kết thúc, vì mã được coi là sạch (không có lỗi); ngược lại, thuật toán tiếp tục. Trong quá trình dự đoán, các điểm multi-head attention của lớp cuối cùng ( α) cũng được truy xuất. WELL tổng hợp các điểm multi-head attention để tính toán điểm quan trọng cấp token v= (v1,···, vl), trong đó vi gợi ý khả năng của token ti trong mã x gây ra lỗi.

4.2 Học cách Phát hiện Lỗi
Như đã đề cập, WELL tinh chỉnh mô hình CodeBERT trên các bộ dữ liệu phát hiện lỗi, cung cấp giám sát yếu cho định vị lỗi. Vì các bộ dữ liệu phát hiện lỗi được gán nhãn nhị phân dễ tiếp cận, CodeBERT hoàn toàn có khả năng học các mẫu lỗi trong mã nguồn. Phần này minh họa các bước tinh chỉnh và dự đoán.

Tính toán tiến. Tính toán tiến có nghĩa là dự đoán trong DL. Theo định nghĩa phát hiện lỗi trong Mục 3.1, CodeBERT lấy mã nguồn x= (t1, ..., t l) làm đầu vào và xuất ra ˜y như nhãn được dự đoán. Quá trình tính toán tiến được chứng minh trong Hình 2. Cụ thể, cho chuỗi token mã nguồn x, chúng ta chia chúng thành các subtoken s1, s2, ..., s l′ sử dụng BPE51, trong đó l′ là độ dài của chuỗi subtoken. Token đặc biệt s0= [CLS] để phân loại cũng được chèn vào đầu chuỗi subtoken. Sau đó, 12 lớp transformer tạo ra biểu diễn vector nhận biết ngữ cảnh h=h0, ..., h l′ của các subtoken. Chúng ta chỉ giữ lại h0 như biểu diễn tổng hợp của toàn bộ đoạn mã, và loại bỏ các hi khác. Cuối cùng, chúng ta đưa h0 vào mạng neural feed-forward với đầu ra softmax, tạo ra xác suất được dự đoán p= (p0, p1)T của hai lớp ( p1 cho có lỗi và p0 cho sạch). Dự đoán nhị phân ˜y được thực hiện dựa trên p1, tức là ˜y= 1 nếu p1≥0.5, ngược lại, ˜y= 0.

Mục tiêu huấn luyện. Chúng tôi tinh chỉnh CodeBERT trên tập huấn luyện phát hiện lỗi thông qua lan truyền ngược và gradient descent. Hàm mất mát là cross-entropy loss thường được áp dụng cho phân loại, được công thức hóa như dưới đây, trong đó ΘC đề cập đến các trọng số trong mô hình phát hiện lỗi CodeBERT:

min
ΘCL=E(x,y)∈Dt(−y log p 1−(1−y)log p 0). (3)

4.3 Định vị thông qua Multi-head Attention
Theo kinh nghiệm, bộ phát hiện lỗi CodeBERT có được trong Mục 4.2 thực hiện dự đoán dựa trên một số đặc trưng nhất định được nhúng trong mã. Các đặc trưng như vậy, dẫn đến dự đoán có lỗi, có khả năng liên quan đến lỗi. Mặt khác, multi-head attention cung cấp những phần nào của mã nguồn mà mô hình CodeBERT tập trung vào. Bằng cách phân tích multi-head attention, chúng ta có thể định vị lỗi thông qua bộ phát hiện lỗi CodeBERT. Thuật toán được trình bày trong Thuật toán 1.

Tính toán tiến. Để xác định liệu đoạn mã đầu vào có lỗi hay không, và để truy xuất điểm attention α cho các thủ tục định vị tiếp theo, một tính toán tiến (Dòng 1 đến 4 trong Thuật toán 1) là cần thiết. Sau khi truy xuất α, WELL thực hiện hai tổng hợp (multi-head và subtoken) để có được điểm quan trọng cấp token v.

Tổng hợp của nhiều head. Điểm attention α (như một tensor 3 chiều) bao gồm tất cả các attention head từ lớp transformer cuối cùng trong CodeBERT. Head attention thứ i được ký hiệu là αi, trong đó hàng thứ j ( αij) gợi ý attention xác suất của sj đối với tất cả các subtoken khác của mã. Cụ thể, αi0 gợi ý tầm quan trọng của mỗi subtoken cho phân loại từ head thứ i. Để xem xét tất cả các head, chúng tôi áp dụng tổng hợp trung bình của tất cả nh head như Dòng 8 trong Thuật toán 1:

α′= AGG _HEAD( α) =Xnh
i=1αi0
nh, (4)

trong đó đầu ra α′ là một chuỗi xác suất gợi ý tầm quan trọng của mỗi subtoken tương ứng.

Căn chỉnh subtoken. Do BPE, một token ti có thể được chia thành nhiều subtoken, và sự nối của các subtoken này tạo thành ti ban đầu, tức là ti= CONCAT( sai, sai+1,···, sbi), trong đó ai và bi đề cập đến các chỉ số bắt đầu và kết thúc trong chuỗi subtoken của token ti tương ứng. a và b, là các vector được cấu thành bởi ai và bi, được truy xuất bằng cách căn chỉnh chuỗi token x và chuỗi subtoken

--- TRANG 8 ---
8 Zhuo Li et al.
Thuật toán 1 Thuật toán định vị bởi WELL.
Đầu vào: Mã nguồn x=t1, t2, ..., t l
Đầu ra: Nhãn được dự đoán y và đoạn lỗi xbuggy .
1:s1, s2, ..., s l′←BPE (t1, t2, ..., t l) ▷Tokenize mã đầu vào
2:h, α←CodeBERT([ CLS], s1, s2, ..., s l′)
3:p←CLASSIFY( h0) ▷Có được dự đoán với CodeBERT
4:˜y←argmaxipi
5:nếu ˜y= 0 thì ▷Mã nguồn được phân loại là không có lỗi
6: trả về CLEAN, NONE
7:khác
8: α′←AGG _HEAD( α) ▷Tổng hợp điểm quan trọng từ các attention head khác nhau
9: a, b←ALIGN( x, s) ▷Căn chỉnh subtoken với code token
10: v←AGG _SUBTOKEN( a, b, α′) ▷Tổng điểm quan trọng của subtoken
11: k←arg max iPi+N−1
j=ivj ▷Chọn vị trí có điểm quan trọng cao nhất
12: trả về BUGGY, (tk,···, tk+N−1)
13:kết thúc nếu

s như Dòng 9 trong Thuật toán 1. Cụ thể, BPE trong CodeBERT gắn thẻ các subtoken với ký tự đặc biệt " ˙G", đề cập đến đầu của một token. Do đó, chúng tôi thực hiện quét qua x và s để thu thập ai và bi cho mỗi ti∈x.

Tổng hợp subtoken. Vì α′ đề cập đến điểm quan trọng cấp subtoken trong khi chúng ta yêu cầu điểm quan trọng cấp token, một tổng hợp trên các subtoken là cần thiết. Sau khi căn chỉnh, WELL thực hiện tổng hợp cộng để ánh xạ attention từ các subtoken đến các token tương ứng (Dòng 10 trong Thuật toán 1), dẫn đến điểm quan trọng v= (v1,···, vl). Mỗi vi được tính toán như vi=Pbi
j=aiα′
j.

Định vị. Điểm quan trọng vi gợi ý mức độ thông tin của ti đối với dự đoán có lỗi của bộ phát hiện lỗi CodeBERT. Nói cách khác, những token có điểm quan trọng cao có nhiều khả năng liên quan đến lỗi. Vì nhiệm vụ định vị lỗi có thể được coi như một vấn đề gán thẻ chuỗi trên mã nguồn (Mục 3.1), WELL giả định đoạn lỗi là một chuỗi con token liên tiếp có độ dài N, trong đó N là một siêu tham số. Với giả định này, WELL sử dụng cửa sổ trượt kích thước N để tính toán điểm quan trọng của tất cả các đoạn, và chọn đoạn có điểm số lớn nhất như đoạn lỗi (Dòng 11 trong Thuật toán 1). Đoạn lỗi xbuggy = (xk,···, xk+N−1) được chọn như:

k= arg max
iXi+N−1
j=ivj. (5)

Vui lòng lưu ý hai giả định trong Phương trình 5: ❶Các token lỗi không quá N, và ❶các token lỗi liên tiếp. Khi các giả định không được thỏa mãn, chúng ta có thể mở rộng WELL bằng cách áp dụng chiến lược lựa chọn không liên tiếp được kích hoạt ngưỡng. Chúng tôi để điều này cho công việc tương lai.

4.4 Mở rộng với Giám sát Chi tiết
Đến nay, chúng tôi đã minh họa tất cả chi tiết trong WELL, bao gồm tính toán tiến của backbone CodeBERT, giao thức tinh chỉnh trên các bộ dữ liệu có-lỗi-hay-không, và quá trình định vị. Nói cách khác, WELL không yêu cầu hay dựa vào bất kỳ chú thích vị trí lỗi nào để huấn luyện. Tuy nhiên, trong thế giới thực, mặc dù các ví dụ được chú thích chi tiết tốt khó thu thập, chúng ta vẫn có thể có được một lượng nhỏ chúng bằng mọi cách. Chúng tôi giới thiệu WELL mở rộng, cụ thể là WELL- k, trong phần này, tận dụng các ví dụ được chú thích vị trí lỗi chi tiết này để xác thực.

Mặc dù multi-head attention được thiết kế để tập trung vào các đặc trưng khác nhau trong chuỗi đầu vào43, các nghiên cứu gần đây đã cho thấy chỉ một tập con nhỏ các head được chuyên biệt hóa cho nhiệm vụ downstream, trong khi các head khác không cần thiết và thậm chí có thể được cắt tỉa mà không mất nhiều hiệu suất52,53. Do đó, những head không quan trọng trong WELL có thể có tác động tiêu cực sau khi tổng hợp trung bình, điều mà chúng tôi thực sự gặp phải trong các thí nghiệm của mình. Mặt khác, tổng hợp chỉ các head quan trọng được cho là cạnh tranh hoặc thậm chí tốt hơn. Do đó, WELL- k được đề xuất như một phần mở rộng của WELL, chỉ chọn và tổng hợp các attention head quan trọng top- k.

Để đo tầm quan trọng của mỗi attention head, chúng tôi sử dụng các ví dụ được chú thích chi tiết tốt như xác thực. Thay vì tổng hợp trực tiếp, chúng tôi đánh giá hiệu suất định vị lỗi của attention head thứ i so với tập xác thực (được chú thích vị trí lỗi), bằng cách đặt α′=αi0, tạo ra WELL-H i. Hiệu suất của WELL-H i được coi là tầm quan trọng của head thứ i. Sau đó, chúng tôi tổng hợp chỉ các head quan trọng top- k, dẫn đến WELL- k. Lưu ý rằng WELL-1 đề cập đến không tổng hợp attention head nào cả (chỉ sử dụng head quan trọng nhất), và WELL- nh đề cập đến chính WELL (tổng hợp tất cả các head). Trong các thí nghiệm của chúng tôi, chúng tôi đánh giá WELL-1, xem xét trường hợp cực đoan.

--- TRANG 9 ---
Zhuo Li et al. 9
BẢNG 2 Thông tin về các nhiệm vụ chủ đề & bộ dữ liệu
Bộ dữ liệu Ngôn ngữ Train # Valid # Test # ¯l*Ψ*
VarMisuse Python2 ∼1.6M ∼170k ∼886k 73 ✓
BiOpMisuse Python2 ∼460k ∼49k ∼250k 123 ✓
BoundError Java ∼180k ∼26k ∼52k 146 ✓
StuBug C ∼235k ∼26k ∼17k 170 ✓
*¯l= "Độ dài trung bình", Ψ= "Cân bằng tốt".

5 ĐÁNH GIÁ
5.1 Cài đặt Thí nghiệm
Nhiệm vụ chủ đề & bộ dữ liệu. Chúng tôi đánh giá WELL, so với các phương pháp khác, với ba nhiệm vụ phát hiện/định vị lỗi tổng hợp, tức là VarMisuse13, BiOpMisuse16, BoundError, và một nhiệm vụ định vị lỗi chương trình sinh viên (StuBug). VarMisuse13 là một bộ dữ liệu phát hiện và định vị sử dụng sai biến của các hàm Python2. Nhiệm vụ là phát hiện liệu có tên biến sử dụng sai trong mỗi hàm hay không và định vị nó. BiOpMisuse là một benchmark phát hiện sử dụng sai toán tử của các hàm Python2 được đề xuất bởi Kanade et al.16. Lỗi được đưa vào bằng cách thay thế một toán tử hai ngôi bằng một toán tử sai nhưng tương thích kiểu ngẫu nhiên (ví dụ, "+"⇔"-", "*"⇔"/", "is" ⇔"is not"). Chúng tôi mở rộng nhiệm vụ này để định vị lỗi tiếp theo bằng cách yêu cầu các mô hình định vị toán tử đã thay thế. BoundError là một bộ dữ liệu phát hiện và định vị lỗi điều kiện biên của các phương thức Java được đề xuất trong bài báo này. Lỗi off-by-one được đưa vào các phương thức Java bằng cách thêm/bỏ điều kiện bằng trong các toán tử so sánh nhị phân. Chi tiết về việc có được bộ dữ liệu này được mô tả trong Phụ lục. Các loại lỗi trong ba bộ dữ liệu tổng hợp khác nhau, nhưng tất cả đều được gây ra bởi một hoặc hai token (ví dụ "is not" ⇔"is" trong BiOpMisuse).

StuBug54 là một bộ dữ liệu định vị lỗi của các chương trình sinh viên được viết bằng ngôn ngữ C. Bộ dữ liệu được thu thập từ 28,331 bài nộp của sinh viên cho 29 nhiệm vụ lập trình với tổng cộng 231 test case. Trong quá trình huấn luyện, các mô hình học cách dự đoán liệu một chương trình có thể vượt qua test case hay không, tức là đầu vào là một cặp (chương trình, test case). Để đánh giá định vị, các mô hình cần định vị các dòng lỗi trong các chương trình trong tập test. Vui lòng tham khảo bài báo gốc để biết chi tiết hơn. Thông tin thống kê và khác về các bộ dữ liệu được liệt kê trong Bảng 2.

Các Mô hình Cơ sở. Đối với các bộ dữ liệu tổng hợp, các giải pháp dựa trên DL SOTA cho định vị lỗi chủ yếu là kiến trúc Seq2Ptr14. Seq2Ptr sử dụng các encoder DL để tính toán attention được query bởi một vector có thể huấn luyện trên đoạn mã đầu vào, và con trỏ đến vị trí lỗi được tạo ra từ attention ( arg max ). Khác với WELL đề xuất của chúng tôi, các mô hình Seq2Ptr được huấn luyện với bộ dữ liệu định vị lỗi với tín hiệu giám sát được chú thích vị trí lỗi mạnh. Chúng tôi sử dụng các mô hình SOTA được đề xuất trước đó làm cơ sở, bao gồm GREAT15 và CuBERT16. Đối với các thí nghiệm trên StuBug, chúng tôi sử dụng NeuralBugLocator, hai cơ sở định vị lỗi dựa trên program-spectrum SOTA và một cơ sở dựa trên khác biệt cú pháp54. Chi tiết triển khai (bao gồm các siêu tham số) được liệt kê trong Phụ lục.

Các chỉ số đánh giá. Đối với các bộ dữ liệu tổng hợp, chúng tôi sử dụng độ chính xác phân loại (AccD), precision (PD), và recall (RD) như các chỉ số đánh giá cho phát hiện lỗi và độ chính xác định vị (AccL) cho định vị lỗi. Đối với StuBug, chúng tôi sử dụng độ chính xác định vị top- k(k= 1,5,10), đại diện cho phần trăm chương trình mà ít nhất một dòng lỗi được định vị thành công khi các dòng nghi ngờ top- k được báo cáo. Chúng tôi đánh giá độ chính xác trên 1,449 chương trình trong tập test như Gupta et al.54 làm.

5.2 Đánh giá trên Bộ dữ liệu Tổng hợp
Để chứng minh tính hiệu quả của WELL trong việc phát hiện và định vị lỗi, chúng tôi đánh giá hiệu suất của WELL trên ba bộ dữ liệu tổng hợp và so sánh với các cơ sở.

Phát hiện lỗi. Precision (P D), recall (R D), và accuracy (Acc D) của WELL và các mô hình cơ sở cho việc phát hiện lỗi VarMisuse, BiOpMisuse, và BoundError được liệt kê trong Bảng 3-5. Lưu ý rằng WELL-1 và WELL chia sẻ cùng backbone CodeBERT đã được tinh chỉnh, hiệu suất phát hiện là giống hệt nhau. Trung bình, WELL tạo ra 92.85% precision, 93.21% recall, và 93.33% accuracy trong việc phát hiện ba loại lỗi. Hiệu suất của WELL trong phát hiện lỗi tốt hơn đáng kể so với GREAT và CuBERT, được quy cho backbone CodeBERT mạnh mẽ.

Định vị lỗi. Trung bình, WELL và WELL-1 định vị đúng 79.74% và 87.57% lỗi như được hiển thị trong Bảng 3-5. So với chọn ngẫu nhiên, có độ chính xác khoảng 1%, WELL có thể định vị ba loại lỗi, mặc dù nó không có tín hiệu giám sát trực tiếp cho định vị trong quá trình tinh chỉnh. Đến ngạc nhiên của chúng tôi, WELL được giám sát yếu có thể so sánh với các mô hình được giám sát SOTA, GREAT và CuBERT. Cụ thể, độ chính xác định vị của WELL cao hơn 6.75% so với GREAT trong VarMisuse, và cao hơn 4.06% so với CuBERT. Đối với BiOpMisuse và BoundError,

--- TRANG 10 ---
10 Zhuo Li et al.
BẢNG 3 Kết quả phát hiện/định vị lỗi trên VarMisuse.
Tín hiệu Giám sát
MôhìnhPhát hiện Định vị
D†L†P (%) R (%) Acc. (%) Acc. (%)
✓ ✓ GREAT 91.38 91.69 89.91 85.53
✓ ✓ CuBERT 93.53 91.76 92.69 88.22
✓ ✗ WELL 94.34 96.12 95.20 92.28
✓ ✗ WELL-1 94.34 96.12 95.20 92.08
†D = "Giám sát Phát hiện", L = "Giám sát Định vị".

BẢNG 4 Kết quả phát hiện/định vị lỗi trên BiOpMisuse
Tín hiệu Giám sát
MôhìnhPhát hiện Định vị
D†L†P (%) R (%) Acc. (%) Acc. (%)
✓ ✓ GREAT 82.32 81.98 82.92 76.53
✓ ✗ CuBERT 86.64 88.66 87.49 85.14
✓ ✗ WELL 92.70 90.50 91.71 83.08
✓ ✗ WELL-1 92.70 90.50 91.71 83.44
†D = "Giám sát Phát hiện", L = "Giám sát Định vị".

BẢNG 5 Kết quả phát hiện/định vị lỗi trên BoundError
Tín hiệu Giám sát
MôhìnhPhát hiện Định vị
D†L†P (%) R (%) Acc. (%) Acc. (%)
✓ ✓ GREAT 85.87 88.11 87.08 84.77
✓ ✓ CuBERT 90.12 92.36 91.12 90.10
✓ ✗ WELL-lstm 89.00 90.40 89.63 34.96
✓ ✗ WELL 91.50 93.00 93.10 63.87
✓ ✗ WELL-1 91.50 93.00 93.10 87.19
†D = "Giám sát Phát hiện", L = "Giám sát Định vị".

(a) VarMisuse
 (b) BiOpMisuse
HÌNH 3 Trực quan hóa điểm quan trọng được tạo ra bởi WELL. Tất cả các ví dụ được xử lý đúng bởi WELL. Vòng tròn đỏ gợi ý vị trí lỗi của ground-truth. Độ xám của nền đại diện cho điểm quan trọng của token tương ứng bởi WELL.

kết quả của WELL-1 chỉ thấp hơn 2% so với CuBERT. Ngoài ra, chúng tôi nhận thấy rằng WELL và WELL-1 tạo ra độ chính xác tương tự trong VarMisuse và BiOpMisuse (với sự khác biệt ít hơn 0.5%), nhưng WELL-1 vượt trội hơn WELL 23.32% độ chính xác trong BoundError. Hiện tượng này được điều tra và thảo luận trong Mục 5.4 ("Ablation trên Attention Head") sau.

Nghiên cứu trường hợp. Hình 3 hiển thị hai trường hợp từ VarMisuse và BiOpMisuse riêng biệt. WELL dự đoán chúng là có lỗi đúng và định vị lỗi chính xác. Nền tối hơn của một token ( ti) đề cập đến điểm quan trọng cao hơn ( vi) từ WELL của token này. Các token quan trọng nhất (tối nhất) và vị trí lỗi (vòng tròn đỏ) trùng khớp trong các hình, điều này, ở một mức độ nhất định, cho thấy tính hiệu quả của WELL được giám sát yếu. Mặt khác, các token quan trọng với nền tối hiếm và tập trung trong các hình, có nghĩa là CodeBERT trong WELL có khả năng học mối quan hệ giữa vị trí lỗi trong mã và tín hiệu giám sát có-lỗi-hay-không đã cho trong quá trình tinh chỉnh. Điều này tiếp tục chứng minh tính khả thi và hiệu quả của giám sát yếu trong định vị lỗi. Vui lòng tham khảo Phụ lục để biết thêm các trường hợp được trực quan hóa.

Kết quả thí nghiệm và nghiên cứu trường hợp cho thấy rằng WELL khả thi và hiệu quả trong việc phát hiện và định vị lỗi trong các bộ dữ liệu đã đánh giá.

--- TRANG 11 ---
Zhuo Li et al. 11
BẢNG 6 Kết quả định vị lỗi trên StuBug.
MôhìnhKết quả Định vị
Top-10 Top-5 Top-1
Tarantula 1,141 (78.74%) 791 (54.59%) 311 (21.46%)
Ochiai 1,151 (79.43%) 835 (57.63%) 385 (26.57%)
Dựa trên Diff 623 (43.00%) 122 (8.42%) 0 (0.00%)
NBL 1,164 (80.33%) 833 (57.49%) 294 (20.29%)
WELL 1,240 (85.58%) 931(64.25%) 421(29.05%)

HÌNH 4 Trực quan hóa WELL trên StuBug. Ba dòng có điểm quan trọng cao nhất được tô sáng. Các điểm quan trọng được ghi nhãn bên phải với font chữ màu xanh.

5.3 Đánh giá trên Chương trình Sinh viên
Chúng tôi tiếp tục đánh giá hiệu suất của WELL bằng cách định vị lỗi ngữ nghĩa trong các chương trình sinh viên và so sánh WELL với các mô hình sâu SOTA hiện có NBL54, hai phương pháp dựa trên program-spectrum (Tarantula55, Ochiai56) và một kỹ thuật dựa trên khác biệt cú pháp. Chúng tôi đánh giá các phương pháp trên 1,449 chương trình trong tập test và liệt kê kết quả trong Bảng 6.

Khi chỉ báo cáo 1 dòng lỗi nghi ngờ, WELL thành công định vị lỗi trong 421 (29.05%) chương trình. Độ chính xác của mô hình sâu SOTA trước đó, NBL, chỉ là 20.29% (thấp hơn 9%). WELL cũng vượt trội so với ba phương pháp truyền thống đáng kể. Đối với độ chính xác top-5 và top-10, sự vượt trội của WELL vẫn rõ ràng. WELL đưa ra hiệu suất SOTA trên các chương trình sinh viên được thu thập từ thế giới thực.

Nghiên cứu trường hợp. Hai chương trình trong StuBug được hiển thị trong Hình 4 với các điểm quan trọng được đưa ra bởi WELL. Chương trình đầu tiên là một giải pháp để tính ab%c, trong khi dòng "k = k * a" có lỗi. Sửa chữa đúng là "k = k * a % c". WELL xếp hạng dòng này ở vị trí thứ hai. Hình thứ hai là một chương trình để tính độ dốc của một đường thẳng. Tuy nhiên, sinh viên quên viết câu lệnh "printf" để xuất giá trị độ dốc. WELL định vị vị trí để sửa lỗi (tức là thêm câu lệnh "printf") tại dòng được tô sáng thành công.

5.4 Ablation trên Attention Head
Như đã đề cập, chúng tôi thấy rằng WELL bất thường mất 23.32% độ chính xác định vị lỗi so với WELL-1 trong BoundError. Nó có thể được gây ra bởi vấn đề multi-head attention được phát hiện trong công trình trước đó52,53. Chúng tôi đi sâu vào vấn đề này trong các đoạn sau và biện minh cho sự cần thiết của phần mở rộng trong WELL-1. Để điều tra tác động của các head khác nhau, chúng tôi thực hiện một nghiên cứu ablation bằng cách lấy mẫu ngẫu nhiên 2,000 ví dụ có lỗi được phân loại đúng từ tập test để đánh giá mỗi WELL-H i trong VarMisuse và BoundError.

Độ chính xác định vị của mỗi WELL-H i được hiển thị trong Hình 5. Trong BoundError, chỉ có ba head (3, 7, 10) hiệu quả ( >50%) cho định vị, trong khi phần còn lại gần như không hợp lệ. Kết quả đồng ý với công trình trước đó rằng chỉ một tập con nhỏ các head thực hiện công việc nặng52,53. Ngược lại, trong VarMisuse, gần như tất cả các head đều có lợi cho định vị, và chỉ một vài (3, 8) không hợp lệ. Một lý do có thể là kích thước dữ liệu của VarMisuse lớn hơn nhiều và WELL học cách tập trung vào lỗi tốt hơn. Nghiên cứu ablation này giải thích tại sao WELL hoạt động tốt hơn một chút so với WELL-1 trong VarMisuse, nhưng thất bại trong BoundError. Bởi vì trong BoundError, chỉ một số head hiệu quả trong khi những head khác gây ra phản tác dụng cho tổng hợp trung bình, dẫn đến giảm độ chính xác trong WELL.

--- TRANG 12 ---
12 Zhuo Li et al.
(a) VarMisuse
 (b) BoundError
HÌNH 5 Độ chính xác định vị của WELL-H i(attention head i). Biểu đồ histogram là trung bình của 5 lần thử lặp lại, và độ lệch chuẩn được đánh dấu ở đầu biểu đồ histogram.

H21@Override public boolean isPromptAnswered (){return (mSelectedIndex >0&&mSelectedIndex <
mChoices .size());}
H71@Override public boolean isPromptAnswered (){return (mSelectedIndex >0&&mSelectedIndex <
mChoices .size());}
H11@Override public boolean isPromptAnswered (){return (mSelectedIndex >0&&mSelectedIndex <
mChoices .size());}

(a) Trực quan hóa điểm quan trọng từ WELL-H 2, H7 và H 11 trong BoundError. Độ xám của nền cho biết điểm quan trọng của token tương ứng, và WELL-H i dự đoán token có nền tối nhất như vị trí lỗi. Hộp đỏ đề cập đến vị trí lỗi ground-truth.

public boolean hasKey (){return id!=null&&id.length >=0;}
private boolean hasStarted (){return startTime >=0;}
public boolean isGreaterOrEqual (Priority r){return level >r.level ;}

(b) Trực quan hóa WELL-lstm trong BoundError. Độ xám của nền cho biết điểm quan trọng của token tương ứng, và hộp đỏ đề cập đến vị trí lỗi ground-truth.

HÌNH 6 Trực quan hóa WELL.

Nghiên cứu trường hợp. Hình 6(a) trình bày một trường hợp trực quan hóa của WELL-H i trong BoundError. Độ xám của nền đề cập đến điểm quan trọng của token tương ứng, và hộp đỏ chỉ ra vị trí lỗi. WELL-H 7 chính xác trong trường hợp được chứng minh, do tính hợp lệ của head thứ 7 theo Hình 5(b). Đối với các head không hợp lệ (2 và 11), các trường hợp được trực quan hóa bị phân tâm và dự đoán sai. Ngoài ra, WELL-H 7 thực sự là WELL-1 vì head thứ 7 là quan trọng nhất trong số tất cả 12 head. Do đó, nghiên cứu trường hợp tiếp tục chứng minh tính khả thi của phần mở rộng trong WELL-1. Vui lòng tham khảo Phụ lục E để biết thêm các trường hợp được trực quan hóa.

Tóm lại, vấn đề "few-specialized" của multi-head attention cũng được xác định trong WELL. Nghiên cứu ablation xác minh phần mở rộng của WELL-1, tận dụng các chú thích chi tiết như xác thực để chọn head quan trọng và chuyên biệt nhất trong số tất cả các head.

5.5 Tính Di động & Khả năng Chuyển giao
Trong các thí nghiệm trước đó, WELL cho thấy hiệu suất tuyệt vời trong định vị lỗi. Tuy nhiên, tính hiệu quả của WELL có thể đến từ backbone CodeBERT thay vì giám sát yếu. Do đó, chúng tôi thực hiện một nghiên cứu ablation khác, bằng cách áp dụng giám sát yếu cho mô hình LSTM, tạo ra WELL-lstm. Backbone của WELL-lstm là LSTM hai chiều hai lớp. Một lớp attention57 được đặt trên đỉnh LSTM, và chúng tôi sử dụng nó để tính toán điểm quan trọng v (không tổng hợp vì nó là single-headed). Chúng tôi huấn luyện và đánh giá WELL-lstm trên BoundError theo cách được giám sát yếu.

--- TRANG 13 ---
Zhuo Li et al. 13
HÌNH 7 Đường cong độ chính xác định vị Top-K với độ lệch chuẩn của WELL-lstm trong BoundError. Độ lệch chuẩn quá nhỏ và thậm chí không thể nhận thấy trong hình. Các đường nét đứt màu xanh và đỏ là độ chính xác định vị top-1 của WELL-1 và WELL tương ứng.

Định vị Top-K. Độ chính xác định vị của WELL-LSTM là 34.96%, gợi ý rằng WELL-lstm hợp lệ để định vị lỗi BoundError mặc dù nó không hiệu quả bằng so với CodeBERT và các phương pháp được giám sát mạnh. Attention bị phân tâm có thể gây ra hiệu suất không đủ hiệu quả của WELL-lstm do khả năng mô hình không đủ của LSTM. Điều này hợp lý vì kích thước tham số của LSTM (29M) nhỏ hơn nhiều so với CodeBERT (125M). Do đó, để tiếp tục chứng minh tiềm năng của giám sát yếu, chúng tôi cũng đánh giá độ chính xác top-K, trong đó WELL-lstm chọn các đoạn quan trọng top-K như vị trí lỗi được dự đoán, và bất kỳ trúng nào trong số chúng được coi là đúng. Kết quả được hiển thị trong Hình 7. Độ chính xác top-1 (chính xác) của WELL-lstm là 34.94%, thấp hơn nhiều so với WELL và WELL-1, trong khi độ chính xác top-2 tăng nhanh lên 76.04%. Khi chúng ta xem xét bốn token, độ chính xác thậm chí là 86.30%, gần với độ chính xác chính xác của WELL-1 (87.19%).

Nghiên cứu trường hợp. Một số trường hợp được trực quan hóa được trình bày trong Hình 6(b), và nhiều trường hợp hơn được hiển thị trong Phụ lục F. Mặc dù backbone LSTM kém mạnh hơn nhiều so với CodeBERT, WELL-lstm vẫn có khả năng chú ý đến các vị trí lỗi trong mã trong kịch bản giám sát yếu. Như một kết luận thô, khung được giám sát yếu có thể di động và chuyển giao sang các mô hình dựa trên attention khác như LSTM.

Mặc dù backbone LSTM kém mạnh hơn nhiều so với CodeBERT, WELL-lstm vẫn có thể chú ý đến các vị trí lỗi chỉ với giám sát yếu. Như một kết luận thô, khung được giám sát yếu có thể di động và chuyển giao sang các mô hình dựa trên attention khác như LSTM.

5.6 Các Mối đe dọa đối với Tính hợp lệ
Tính ngẫu nhiên là một mối đe dọa tiềm ẩn đối với kết quả. Chúng tôi chống lại nó bằng cách lặp lại các thí nghiệm trong RQ3 và RQ4. Việc lựa chọn mô hình có thể là một mối đe dọa. Chúng tôi chống lại nó bằng cách so sánh WELL với các mô hình GREAT và CuBERT SOTA hiện tại. Và chúng tôi tiếp tục xây dựng WELL- S với biến số kiểm soát của giám sát để so sánh với WELL. Ngoài ra, việc lựa chọn nhiệm vụ và bộ dữ liệu có thể là một mối đe dọa khác đối với tính hợp lệ. Chúng tôi chống lại nó bằng cách sử dụng hai benchmark được áp dụng trước đó và một bộ dữ liệu được xây dựng trong công trình này. Các bộ dữ liệu chủ đề chứa nhiều loại lỗi và nhiều ngôn ngữ lập trình. Backbone CodeBERT có thể quá mạnh và giám sát yếu có thể không hiệu quả đối với các mô hình khác, điều này tạo ra một mối đe dọa lớn đối với bài báo này. Chúng tôi chống lại nó bằng cách thay thế backbone CodeBERT bằng LSTM trong RQ4 để chứng minh tác động của giám sát yếu.

6 KẾT LUẬN & THẢO LUẬN
Bài báo này đề xuất WELL, một mô hình định vị lỗi được giám sát yếu được trang bị mô hình CodeBERT mạnh mẽ, để giảm bớt thách thức thu thập và chú thích dữ liệu. WELL được có được trên các bộ dữ liệu phát hiện lỗi mà không có chú thích vị trí lỗi, tận dụng đầy đủ dữ liệu huấn luyện dễ tiếp cận hơn. Thông qua các đánh giá sâu, chúng tôi chứng minh rằng WELL có khả năng định vị lỗi dưới giám sát thô, và tạo ra hiệu suất cạnh tranh hoặc thậm chí tốt hơn so với các mô hình SOTA hiện có qua cả bộ dữ liệu tổng hợp và thực tế. Các thí nghiệm tiếp theo cho thấy rằng phương pháp được giám sát yếu trong WELL có thể được áp dụng hiệu quả cho các mô hình dựa trên attention khác.

Như một bước đầu trong lĩnh vực này, chúng tôi hy vọng công trình này có thể giới thiệu một số ý tưởng và phương pháp mới vào cộng đồng SE. Một số công việc tương lai được thảo luận trong Phụ lục G.

--- TRANG 14 ---
14 Zhuo Li et al.
Tài liệu tham khảo
1. Mou L, Li G, Zhang L, Wang T, Jin Z. Convolutional Neural Networks over Tree Structures for Programming Language Processing. Trong: Schuurmans
D, Wellman MP., eds. Proceedings of the Thirtieth AAAI Conference on Artiﬁcial Intelligence, February 12-17, 2016, Phoenix, Arizona, USA AAAI
Press; 2016: 1287–1293.
2. Zhang J, Wang X, Zhang H, Sun H, Wang K, Liu X. A novel neural source code representation based on abstract syntax tree. Trong: Atlee JM,
Bultan T, Whittle J., eds. Proceedings of the 41st International Conference on Software Engineering, ICSE 2019, Montreal, QC, Canada, May 25-31,
2019 IEEE / ACM; 2019: 783–794.
3. Yu H, Lam W, Chen L, Li G, Xie T, Wang Q. Neural detection of semantic code clones via tree-based convolution. Trong: Guéhéneuc Y, Khomh
F, Sarro F., eds. Proceedings of the 27th International Conference on Program Comprehension, ICPC 2019, Montreal, QC, Canada, May 25-31,
2019 IEEE / ACM; 2019: 70–80.
4. Wang W, Li G, Ma B, Xia X, Jin Z. Detecting Code Clones with Graph Neural Network and Flow-Augmented Abstract Syntax Tree. Trong: Kontogian-
nis K, Khomh F, Chatzigeorgiou A, Fokaefs M, Zhou M., eds. 27th IEEE International Conference on Software Analysis, Evolution and Reengineering,
SANER 2020, London, ON, Canada, February 18-21, 2020 IEEE; 2020: 261–271.
5. Allamanis M, Peng H, Sutton CA. A Convolutional Attention Network for Extreme Summarization of Source Code. Trong: Balcan M, Weinberger
KQ., eds. Proceedings of the 33nd International Conference on Machine Learning, ICML 2016, New York City, NY, USA, June 19-24, 2016 . 48 of
JMLR Workshop and Conference Proceedings . JMLR.org; 2016: 2091–2100.
6. Alon U, Zilberstein M, Levy O, Yahav E. code2vec: learning distributed representations of code. Proc. ACM Program. Lang. 2019; 3(POPL):
40:1–40:29.
7. Li J, Wang Y, King I, Lyu MR. Code Completion with Neural Attention and Pointer Networks. CoRR 2017; abs/1711.09573.
8. Liu F, Li G, Wei B, Xia X, Fu Z, Jin Z. A Self-Attentional Neural Architecture for Code Completion with Multi-Task Learning. Trong: ACM; 2020:
37–47.
9. Liu F, Li G, Zhao Y, Jin Z. Multi-task Learning based Pre-trained Language Model for Code Completion. Trong: IEEE; 2020: 473–485.
10. Hu X, Li G, Xia X, Lo D, Jin Z. Deep code comment generation. Trong: Khomh F, Roy CK, Siegmund J., eds. Proceedings of the 26th Conference on
Program Comprehension, ICPC 2018, Gothenburg, Sweden, May 27-28, 2018 ACM; 2018: 200–210.
11. Hu X, Li G, Xia X, Lo D, Lu S, Jin Z. Summarizing Source Code with Transferred API Knowledge. Trong: Lang J., ed. Proceedings of the Twenty-Seventh
International Joint Conference on Artiﬁcial Intelligence, IJCAI 2018, July 13-19, 2018, Stockholm, Sweden ijcai.org; 2018: 2269–2275.
12. Alon U, Brody S, Levy O, Yahav E. code2seq: Generating Sequences from Structured Representations of Code. Trong: OpenReview.net; 2019.
13. Allamanis M, Brockschmidt M, Khademi M. Learning to Represent Programs with Graphs. Trong: OpenReview.net; 2018.
14. Vasic M, Kanade A, Maniatis P, Bieber D, Singh R. Neural Program Repair by Jointly Learning to Localize and Repair. Trong: OpenReview.net; 2019.
15. Hellendoorn VJ, Sutton C, Singh R, Maniatis P, Bieber D. Global Relational Models of Source Code. Trong: OpenReview.net; 2020.
16. Kanade A, Maniatis P, Balakrishnan G, Shi K. Learning and Evaluating Contextual Embedding of Source Code. Trong: . 119 of Proceedings of Machine
Learning Research . PMLR; 2020: 5110–5121.
17. Benton S, Ghanbari A, Zhang L. Defexts: a curated dataset of reproducible real-world bugs for modern JVM languages. Trong: Atlee JM, Bultan
T, Whittle J., eds. Proceedings of the 41st International Conference on Software Engineering: Companion Proceedings, ICSE 2019, Montreal, QC,
Canada, May 25-31, 2019 IEEE / ACM; 2019: 47–50.
18. Lutellier T, Pham HV, Pang L, Li Y, Wei M, Tan L. CoCoNuT: combining context-aware neural translation models using ensemble for program
repair. Trong: Khurshid S, Pasareanu CS., eds. ISSTA '20: 29th ACM SIGSOFT International Symposium on Software Testing and Analysis, Virtual Event,
USA, July 18-22, 2020 ACM; 2020: 101–114.
19. Feng Z, Guo D, Tang D, và cộng sự. CodeBERT: A Pre-Trained Model for Programming and Natural Languages. Trong: Cohn T, He Y, Liu Y., eds. Pro-
ceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: Findings, EMNLP 2020, Online Event, 16-20 November
2020 Association for Computational Linguistics; 2020: 1536–1547.

--- TRANG 15 ---
Zhuo Li et al. 15
20. Wang S, Liu T, Tan L. Automatically learning semantic features for defect prediction. Trong: Dillon LK, Visser W, Williams LA., eds. Proceedings of
the 38th International Conference on Software Engineering, ICSE 2016, Austin, TX, USA, May 14-22, 2016 ACM; 2016: 297–308.
21. Choi M, Jeong S, Oh H, Choo J. End-to-End Prediction of Buﬀer Overruns from Raw Source Code via Neural Memory Networks. Trong: Sierra
C., ed. Proceedings of the Twenty-Sixth International Joint Conference on Artiﬁcial Intelligence, IJCAI 2017, Melbourne, Australia, August 19-25,
2017 ijcai.org; 2017: 1546–1553.
22. Li Z, Zou D, Xu S, và cộng sự. VulDeePecker: A Deep Learning-Based System for Vulnerability Detection. Trong: The Internet Society; 2018.
23. Pradel M, Sen K. DeepBugs: a learning approach to name-based bug detection. Proc. ACM Program. Lang. 2018; 2(OOPSLA): 147:1–147:25.
24. Zhou ZH. A brief introduction to weakly supervised learning. National Science Review 2017; 5(1): 44-53.
25. Dai J, He K, Sun J. BoxSup: Exploiting Bounding Boxes to Supervise Convolutional Networks for Semantic Segmentation. Trong: IEEE Computer
Society; 2015: 1635–1643.
26. Papandreou G, Chen L, Murphy K, Yuille AL. Weakly- and Semi-Supervised Learning of a DCNN for Semantic Image Segmentation. CoRR 2015;
abs/1502.02734.
27. Lin D, Dai J, Jia J, He K, Sun J. ScribbleSup: Scribble-Supervised Convolutional Networks for Semantic Segmentation. Trong: IEEE Computer
Society; 2016: 3159–3167.
28. Bearman AL, Russakovsky O, Ferrari V, Li F. What's the Point: Semantic Segmentation with Point Supervision. Trong: Leibe B, Matas J, Sebe N,
Welling M., eds. Computer Vision - ECCV 2016 - 14th European Conference, Amsterdam, The Netherlands, October 11-14, 2016, Proceedings, Part
VII. 9911 of Lecture Notes in Computer Science . Springer; 2016: 549–565.
29. Lin M, Chen Q, Yan S. Network In Network. Trong: Bengio Y, LeCun Y., eds. 2nd International Conference on Learning Representations, ICLR 2014,
Banﬀ, AB, Canada, April 14-16, 2014, Conference Track Proceedings ; 2014.
30. Zhou B, Khosla A, Lapedriza À, Oliva A, Torralba A. Learning Deep Features for Discriminative Localization. Trong: IEEE Computer Society; 2016:
2921–2929.
31. Selvaraju RR, Cogswell M, Das A, Vedantam R, Parikh D, Batra D. Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based
Localization. Trong: IEEE Computer Society; 2017: 618–626.
32. Wei Y, Xiao H, Shi H, Jie Z, Feng J, Huang TS. Revisiting Dilated Convolution: A Simple Approach for Weakly- and Semi-Supervised Semantic
Segmentation. Trong: IEEE Computer Society; 2018: 7268–7277.
33. Ni J, Dinu G, Florian R. Weakly Supervised Cross-Lingual Named Entity Recognition via Eﬀective Annotation and Representation Projection.
Trong: Barzilay R, Kan M., eds. Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, ACL 2017, Vancouver, Canada,
July 30 - August 4, Volume 1: Long Papers Association for Computational Linguistics; 2017: 1470–1480.
34. Patra B, Moniz JRA. Weakly Supervised Attention Networks for Entity Recognition. Trong: Inui K, Jiang J, Ng V, Wan X., eds. Proceedings of the
2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing,
EMNLP-IJCNLP 2019, Hong Kong, China, November 3-7, 2019 Association for Computational Linguistics; 2019: 6267–6272.
35. Lison P, Barnes J, Hubin A, Touileb S. Named Entity Recognition without Labelled Data: A Weak Supervision Approach. Trong: Jurafsky D, Chai
J, Schluter N, Tetreault JR., eds. Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, ACL 2020, Online, July
5-10, 2020 Association for Computational Linguistics; 2020: 1518–1533.
36. Safranchik E, Luo S, Bach SH. Weakly Supervised Sequence Tagging from Noisy Rules. Trong: AAAI Press; 2020: 5570–5578.
37. Lei T, Barzilay R, Jaakkola TS. Rationalizing Neural Predictions. Trong: Su J, Carreras X, Duh K., eds. Proceedings of the 2016 Conference on Empirical
Methods in Natural Language Processing, EMNLP 2016, Austin, Texas, USA, November 1-4, 2016 The Association for Computational Linguistics;
2016: 107–117.
38. Bastings J, Aziz W, Titov I. Interpretable Neural Predictions with Diﬀerentiable Binary Variables. Trong: Korhonen A, Traum DR, Màrquez L., eds.
Proceedings of the 57th Conference of the Association for Computational Linguistics, ACL 2019, Florence, Italy, July 28- August 2, 2019, Volume 1:
Long Papers Association for Computational Linguistics; 2019: 2963–2977.

--- TRANG 16 ---
16 Zhuo Li et al.
39. Yu M, Chang S, Zhang Y, Jaakkola TS. Rethinking Cooperative Rationalization: Introspective Extraction and Complement Control. Trong: Inui K,
Jiang J, Ng V, Wan X., eds. Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International
Joint Conference on Natural Language Processing, EMNLP-IJCNLP 2019, Hong Kong, China, November 3-7, 2019 Association for Computational
Linguistics; 2019: 4092–4101.
40. DeYoung J, Jain S, Rajani NF, và cộng sự. ERASER: A Benchmark to Evaluate Rationalized NLP Models. Trong: Jurafsky D, Chai J, Schluter N, Tetreault
JR., eds. Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, ACL 2020, Online, July 5-10, 2020 Association
for Computational Linguistics; 2020: 4443–4458.
41. Jain S, Wiegreﬀe S, Pinter Y, Wallace BC. Learning to Faithfully Rationalize by Construction. Trong: Jurafsky D, Chai J, Schluter N, Tetreault JR.,
eds. Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, ACL 2020, Online, July 5-10, 2020 Association for
Computational Linguistics; 2020: 4459–4473.
42. Bahdanau D, Cho K, Bengio Y. Neural Machine Translation by Jointly Learning to Align and Translate. Trong: Bengio Y, LeCun Y., eds. 3rd International
Conference on Learning Representations, ICLR 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings ; 2015.
43. Vaswani A, Shazeer N, Parmar N, và cộng sự. Attention is All you Need. Trong: Guyon I, Luxburg vU, Bengio S, và cộng sự., eds. Advances in Neural Information
Processing Systems 30: Annual Conference on Neural Information Processing Systems 2017, December 4-9, 2017, Long Beach, CA, USA ; 2017:
5998–6008.
44. Luong T, Pham H, Manning CD. Eﬀective Approaches to Attention-based Neural Machine Translation. Trong: Màrquez L, Callison-Burch C, Su J,
Pighin D, Marton Y., eds. Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, EMNLP 2015, Lisbon, Portugal,
September 17-21, 2015 The Association for Computational Linguistics; 2015: 1412–1421.
45. He K, Zhang X, Ren S, Sun J. Deep Residual Learning for Image Recognition. Trong: IEEE Computer Society; 2016: 770–778.
46. Ba LJ, Kiros JR, Hinton GE. Layer Normalization. CoRR 2016; abs/1607.06450.
47. Devlin J, Chang M, Lee K, Toutanova K. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. Trong: Burstein J,
Doran C, Solorio T., eds. Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human
Language Technologies, NAACL-HLT 2019, Minneapolis, MN, USA, June 2-7, 2019, Volume 1 (Long and Short Papers) Association for Computational
Linguistics; 2019: 4171–4186.
48. Liu Y, Ott M, Goyal N, và cộng sự. RoBERTa: A Robustly Optimized BERT Pretraining Approach. CoRR 2019; abs/1907.11692.
49. Husain H, Wu H, Gazit T, Allamanis M, Brockschmidt M. CodeSearchNet Challenge: Evaluating the State of Semantic Code Search. CoRR 2019;
abs/1909.09436.
50. Lu S, Guo D, Ren S, và cộng sự. CodeXGLUE: A Machine Learning Benchmark Dataset for Code Understanding and Generation. arXiv preprint
arXiv:2102.04664 2021.
51. Sennrich R, Haddow B, Birch A. Neural Machine Translation of Rare Words with Subword Units. Trong: The Association for Computer Linguistics;
2016.
52. Voita E, Talbot D, Moiseev F, Sennrich R, Titov I. Analyzing Multi-Head Self-Attention: Specialized Heads Do the Heavy Lifting, the Rest Can
Be Pruned. Trong: Korhonen A, Traum DR, Màrquez L., eds. Proceedings of the 57th Conference of the Association for Computational Linguistics, ACL
2019, Florence, Italy, July 28- August 2, 2019, Volume 1: Long Papers Association for Computational Linguistics; 2019: 5797–5808.
53. Michel P, Levy O, Neubig G. Are Sixteen Heads Really Better than One?. Trong: Wallach HM, Larochelle H, Beygelzimer A, d'Alché-Buc F, Fox EB,
Garnett R., eds. Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems 2019, NeurIPS
2019, December 8-14, 2019, Vancouver, BC, Canada ; 2019: 14014–14024.
54. Gupta R, Kanade A, Shevade SK. Neural Attribution for Semantic Bug-Localization in Student Programs. Trong: ; 2019: 11861–11871.
55. Abreu R, Zoeteweij P, Gemund vAJC. An Evaluation of Similarity Coeﬃcients for Software Fault Localization. Trong: IEEE Computer Society; 2006:
39–46.
56. Jones JA, Harrold MJ, Stasko J. Visualization for Fault Localization. Trong: ; 2003.

--- TRANG 17 ---
Zhuo Li et al. 17
57. Wang Z, Yang B. Attention-based Bidirectional Long Short-Term Memory Networks for Relation Classiﬁcation Using Knowledge Distillation
from BERT. Trong: IEEE; 2020: 562–568.

PHỤ LỤC
A TẠO BỘ DỮ LIỆU BoundError
Chúng tôi lấy mẫu ngẫu nhiên 20% dự án từ Github Java Corpus2, và trích xuất tất cả các phương thức Java sử dụng TreeSitter3. Các phương thức có hơn 400 token bị loại bỏ vì chúng quá dài và phức tạp. Sau đó chúng tôi sử dụng TreeSitter để phân tích các phương thức để có được Cây Cú pháp Cụ thể (CST), và định vị cây con với loại "binary expression" để tìm các biểu thức nhị phân với toán tử " <=", ">=", < và >. Lỗi off-by-one được đưa vào các phương thức bằng cách thay thế toán tử so sánh (ví dụ, <⇔<=, ">"⇔">="4).5

B CẤU HÌNH MÔ HÌNH
Chúng tôi triển khai WELL với Python3 dựa trên framework DL PyTorch (ver 1.7.1) và gói transformers (ver 3.4.0)6.

WELL áp dụng phiên bản base được phát hành của CodeBERT (CodeBERT-base) làm backbone7. Độ dài tối đa được cố định ở 512. Chúng tôi sử dụng mô hình GREAT mã nguồn mở với cùng cấu hình được báo cáo trong bài báo gốc và huấn luyện nó từ đầu. Đối với CuBERT, chúng tôi tái tạo mô hình bằng cách thay thế mô hình backbone bằng CodeBERT. Các lý do như sau: ❶Kích thước mô hình của CuBERT là (lớn gấp ba lần CodeBERT). Nó quá lớn để máy của chúng tôi tinh chỉnh mô hình. ❶Sử dụng cùng backbone CodeBERT giúp chúng tôi so sánh phương pháp với WELL tốt hơn.

Trong quá trình tinh chỉnh, tốc độ học được đặt ở 4×10−5, và điều chỉnh L2 được áp dụng với trọng số 0.01. Trong mỗi thí nghiệm, các mô hình được huấn luyện/tinh chỉnh trong 6 epoch với kích thước batch 64 và chúng tôi chọn checkpoint có độ chính xác cao nhất trên tập xác thực. Để nhấn mạnh giám sát, các vị trí lỗi trong tập huấn luyện có thể truy cập được đối với GREAT, CuBERT, trong khi bị chặn đối với WELL (giám sát yếu). Đối với WELL-1, chúng tôi lấy mẫu 1,000 ví dụ được gán nhãn chi tiết từ bộ dữ liệu xác thực để đo tầm quan trọng của mỗi attention head, đây là một lượng rất nhỏ (ít hơn 1% kích thước bộ dữ liệu huấn luyện gốc). Đối với WELL-LSTM, chúng tôi huấn luyện mô hình LSTM hai chiều với kích thước ẩn 600 và time step 400. Kích thước từ vựng là 30,000 và chiều rộng embedding là 512. Trong thí nghiệm của StuBug, kết quả của các mô hình cơ sở (NeuralBugLocator, Turantula, Ochiai và mô hình Dựa trên Diff) được báo cáo như trong bài báo gốc của NBL.

C WELL CHO SỬA LỖI
WELL được huấn luyện trên các bộ dữ liệu phát hiện lỗi và có thể được áp dụng cho cả phát hiện và định vị lỗi. Hơn nữa, WELL có tiềm năng cho sửa lỗi không giám sát. Mô hình backbone của WELL là CodeBERT, được huấn luyện trước với nhiệm vụ mô hình ngôn ngữ bị che. Vì vậy CodeBERT có thể dự đoán xác suất của token gốc bị che. Do đó, khi WELL dự đoán một chương trình có lỗi và tìm vị trí lỗi, chúng ta có thể che các token lỗi được định vị và query CodeBERT để dự đoán các token gốc. Về mặt lý thuyết, CodeBERT nên khôi phục các token có xác suất cao nhất và đúng. Theo cách này, chúng ta có thể áp dụng WELL để sửa lỗi.

Tuy nhiên, vẫn có nhiều thách thức để hoàn thành ý tưởng thô này. Ví dụ, khó xác định số lượng token để query CodeBERT tạo ra, tức là số lượng "mask" để chèn vào vị trí lỗi. Như một thử nghiệm đầu, chúng tôi thử phương pháp này để sửa lỗi trong bộ dữ liệu VarMisuse, trong đó mỗi lỗi tương ứng với một biến sử dụng sai. Chúng tôi lấy mẫu ngẫu nhiên 1,000 hàm và đánh giá độ chính xác sửa chữa. Khi chúng tôi đặt số (sub)token sửa chữa thành 1, 65.9% lỗi được sửa đúng. Khi lên đến 3 (sub)token được xem xét, số lượng lỗi được sửa tăng lên 81.4%. Mặc dù WELL chỉ có thể sửa chữa lỗi đơn giản bây giờ, điều này giới thiệu một suy nghĩ mới để đạt được sửa lỗi.

D THÊM CÁC TRƯỜNG HỢP ĐƯỢC TRỰC QUAN HÓA CỦA WELL
Chúng tôi liệt kê thêm các trường hợp được trực quan hóa từ WELL trong BoundError trong Hình D1. Nền tối có thể nhận thấy trong mỗi trường hợp là thưa thớt, cho thấy rằng các điểm quan trọng tập trung. Hình 1(a)-1(e) được xử lý đúng, và WELL khá "chắc chắn" về dự đoán vị trí lỗi, vì các điểm quan trọng gần như chỉ tập trung trên các vị trí lỗi thực tế. Mặc dù lỗi trong Hình 1(f) bị WELL định vị sai, nó vẫn chú ý đến vị trí lỗi thực tế, và đang trong tình thế khó xử giữa " >" (lỗi thực tế) hoặc " >=" (dự đoán sai). Trong một số kịch bản nhất định, " >" có thể bị sử dụng sai; trong khi ở những kịch bản khác, " >=" có thể bị sử dụng sai. Vì ngữ cảnh không được cung cấp trong trường hợp này, WELL không thể đưa ra quyết định chắc chắn và đúng. Chúng tôi giả định rằng khó quyết định liệu điều kiện bằng có nên được tích hợp với ngữ cảnh hạn chế đã cho. Và có thể hiểu được khi WELL mắc lỗi trong những trường hợp như vậy.

E THÊM CÁC TRƯỜNG HỢP ĐƯỢC TRỰC QUAN HÓA CỦA WELL-HI
Chúng tôi trình bày thêm các trường hợp được trực quan hóa của WELL-H i trên các attention head khác nhau trong BoundError trong Hình D2. Tương tự như Hình 6(a), chúng tôi thực hiện trực quan hóa trên ba head (tức là 2, 7 và 11), trong đó WELL-H 7 được coi là hiệu quả và hợp lệ cho định vị lỗi trong khi WELL-H 2 và H 11 thì không theo Hình 5(b). Trong tất cả các trường hợp, WELL-H 7 (WELL-1) tạo ra điểm quan trọng có thể nhận thấy và tập trung, và định vị lỗi chính xác. Ngược lại, WELL-H 2 và H 11 bị phân tâm trong nhiều trường hợp, và thực hiện định vị ít chính xác hơn. Những trường hợp này ở một mức độ nhất định chứng minh vấn đề multi-head attention, và sự cần thiết cũng như tính khả thi của WELL-1 mở rộng.

F THÊM CÁC TRƯỜNG HỢP ĐƯỢC TRỰC QUAN HÓA CỦA WELL-LSTM
Chúng tôi cung cấp thêm các trường hợp được trực quan hóa của WELL-lstm trong BoundError trong Hình D3. WELL-lstm thể hiện hành vi tương tự trong hầu hết các trường hợp, nơi các điểm quan trọng tập trung vào các vị trí lỗi. Tuy nhiên, cũng có những dự đoán sai, chẳng hạn như trường hợp 2. WELL-lstm coi "segmentEnd" thay vì " <=" bên cạnh nó là lỗi. Những sự cố như vậy sẽ giải thích một phần tại sao WELL-lstm không hiệu quả bằng WELL hay WELL-1 – backbone LSTM có thể không đủ mạnh để hỗ trợ đầy đủ định vị lỗi được giám sát yếu.

G CÔNG VIỆC TƯƠNG LAI
Như một bước đầu trong lĩnh vực này, chúng tôi chứng minh tính khả thi và hiệu quả của định vị lỗi được giám sát yếu, để lại nhiều thứ cho công việc tương lai.

Các đánh giá của bài báo này được thực hiện trên ba bộ dữ liệu tổng hợp, nơi các loại lỗi đơn giản được tiêm vào mã sạch ban đầu để hình thành các cặp dữ liệu được chú thích vị trí lỗi. Chúng tôi để lại định vị lỗi phức tạp và đánh giá thế giới thực cho công việc tương lai.

Các giả định trong WELL, rằng đoạn lỗi liên tiếp và có độ dài tối đa N có thể không được thỏa mãn đối với nhiều lỗi phức tạp. Chúng ta có thể áp dụng chiến lược kích hoạt ngưỡng hoặc chiến lược lựa chọn không liên tiếp để cho phép WELL định vị chuỗi token không liên tiếp với độ dài biến đổi. Chúng tôi để điều này cho công việc tương lai.

Có các phương pháp khác ngoài attention để có được điểm quan trọng, chẳng hạn như gradient. WELL có thể được tổng quát hóa bằng cách sử dụng các kỹ thuật như vậy. Chúng tôi để những thử nghiệm các phương pháp khác nhau để tính toán điểm quan trọng này cho công việc tương lai.

Một công việc tương lai mong muốn hơn là tiếp tục sửa lỗi theo kiểu được giám sát yếu. Điều này cũng có thể đạt được với backbone CodeBERT, khi chúng ta xem xét không chỉ h0, mà còn các hi khác. Chúng tôi để dành việc sửa lỗi dựa trên DL được giám sát yếu này cho công việc tương lai.

--- TRANG 18-20 ---
[Tiếp tục với phần còn lại của tài liệu tham khảo và phụ lục với các hình ảnh và trường hợp trực quan hóa bổ sung]

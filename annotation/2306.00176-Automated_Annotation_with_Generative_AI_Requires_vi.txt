# 2306.00176.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/annotation/2306.00176.pdf
# Kích thước file: 325371 bytes

===============================================
NỘI DUNG FILE PDF
===============================================


--- TRANG 1 ---
Chú thích Tự động với AI Sinh tạo Cần
Xác thực
Nicholas Pangakis∗, Samuel Wolken†, và Neil Fasching‡
Ngày 2 tháng 6 năm 2023
Tóm tắt
Các mô hình ngôn ngữ lớn sinh tạo (LLMs) có thể là một công cụ mạnh mẽ để tăng cường
các thủ tục chú thích văn bản, nhưng hiệu suất của chúng thay đổi qua các nhiệm vụ chú thích
do chất lượng prompt, đặc thù dữ liệu văn bản, và độ khó khái niệm. Vì những thách thức này
sẽ tiếp tục tồn tại ngay cả khi công nghệ LLM được cải thiện, chúng tôi lập luận rằng bất kỳ
quy trình chú thích tự động nào sử dụng LLM đều phải xác thực hiệu suất của LLM so với
các nhãn được tạo ra bởi con người. Để đạt được mục tiêu này, chúng tôi phác thảo một quy
trình làm việc để khai thác tiềm năng chú thích của LLMs một cách có nguyên tắc và hiệu quả.
Sử dụng GPT-4, chúng tôi xác thực phương pháp này bằng cách sao chép 27 nhiệm vụ chú thích
qua 11 tập dữ liệu từ các bài báo khoa học xã hội gần đây trong các tạp chí có tác động cao. Chúng
tôi phát hiện rằng hiệu suất LLM cho chú thích văn bản là đầy hứa hẹn nhưng phụ thuộc rất
nhiều vào cả tập dữ liệu và loại nhiệm vụ chú thích, điều này củng cố sự cần thiết phải xác thực
trên cơ sở từng nhiệm vụ. Chúng tôi cung cấp phần mềm dễ sử dụng được thiết kế để triển khai
quy trình làm việc của chúng tôi và đơn giản hóa việc triển khai LLMs cho chú thích tự động.

∗Khoa Khoa học Chính trị, Đại học Pennsylvania
†Khoa Khoa học Chính trị và Trường Truyền thông Annenberg, Đại học Pennsylvania
‡Trường Truyền thông Annenberg, Đại học Pennsylvania
Đóng góp của tác giả: NP và SW phát triển mã code, phân tích dữ liệu, và viết bản thảo. NP, SW,
và NF thu thập dữ liệu và chỉnh sửa bản thảo.
Chúng tôi cảm ơn Yphtach Lelkes vì sự hỗ trợ và hướng dẫn của ông và Daniel Hopkins vì những
bình luận hữu ích của ông. Chúng tôi cũng cảm ơn bất kỳ tác giả nào đã gửi dữ liệu cho chúng tôi.arXiv:2306.00176v1  [cs.CL]  31 May 2023

--- TRANG 2 ---
1 Giới thiệu
Nhiều nhiệm vụ trong xử lý ngôn ngữ tự nhiên (NLP) phụ thuộc vào dữ liệu văn bản được
gắn nhãn thủ công chất lượng cao để huấn luyện và xác thực. Tuy nhiên, quy trình chú thích
thủ công đặt ra những thách thức không tầm thường. Ngoài việc tốn thời gian và đắt đỏ, các
nhà chú thích con người, thường là các nhân viên được huy động từ đám đông¹ hoặc trợ lý sinh
viên đại học, thường gặp phải vấn đề về sự tập trung hạn chế, mệt mỏi, và thay đổi nhận thức
về các danh mục khái niệm cơ bản trong suốt quá trình gắn nhãn (Grimmer và Stewart, 2013;
Neuendorf, 2016). Khi gắn nhãn một lượng lớn dữ liệu, những hạn chế này có thể dẫn đến dữ
liệu văn bản được gắn nhãn bị mâu thuẫn và sai sót có thể không quan sát được và có tương
quan—đặc biệt khi sử dụng người mã hóa với nền tảng nhân khẩu học tương tự.

Để giải quyết những thách thức này, các nhà nghiên cứu gần đây đã khám phá tiềm năng của
các mô hình ngôn ngữ lớn sinh tạo (LLMs), chẳng hạn như ChatGPT, để thay thế các nhà chú
thích con người. LLMs nhanh hơn, rẻ hơn, có thể tái tạo, và không dễ bị ảnh hưởng bởi một số
cạm bẫy trong chú thích của con người. Tuy nhiên, các ứng dụng trước đây sử dụng LLMs trong
vai trò này đã cho kết quả hỗn hợp. Gilardi et al. (2023) khẳng định rằng ChatGPT vượt trội
hơn các nhân viên MTurk trong nhiều nhiệm vụ chú thích. Mặt khác, Reiss (2023) nhận thấy
rằng LLMs hoạt động kém trong chú thích văn bản và lập luận rằng công cụ này nên được sử
dụng một cách thận trọng. Nhiều nghiên cứu khác trình bày các phân tích tương tự với kết quả
và khuyến nghị khác nhau (ví dụ, He et al., 2023; Wang et al., 2021; Ziems et al., 2023; Zhu et
al., 2023; Ding et al., 2022).

Mặc dù nghiên cứu hiện tại cung cấp những hiểu biết có giá trị về cả lợi ích và những hạn
chế tiềm năng của việc sử dụng LLMs cho chú thích văn bản, vẫn không rõ liệu các quy trình
gắn nhãn tự động được sử dụng trong những nghiên cứu này có thể được áp dụng một cách tự
tin cho các tập dữ liệu và nhiệm vụ khác hay không, vì chúng báo cáo các chỉ số hiệu suất tối
thiểu (chỉ là độ chính xác hoặc mức độ đồng thuận giữa các người mã hóa) và phân tích một số
nhiệm vụ cô lập trên một số lượng nhỏ tập dữ liệu. Hơn nữa, do sự phát triển nhanh chóng của
công nghệ LLM, có khả năng rằng bất kỳ khuyến nghị nhị phân nào về khả năng của LLMs
trong các nhiệm vụ một lần sẽ nhanh chóng lỗi thời với những tiến bộ bổ sung của LLM. Trong
khi một số nghiên cứu cho đến nay đã áp dụng LLMs cho một loạt tập dữ liệu rộng hơn (Ziems
et al., 2023; Zhu et al., 2023), chúng chỉ kiểm tra hiệu suất chú thích LLM trên các tập dữ liệu
benchmark công khai, phổ biến. Do đó, những kiểm tra này có thể bị ảnh hưởng bởi contamination
(Brown et al., 2020), có nghĩa là các tập dữ liệu có thể được bao gồm trong dữ liệu huấn luyện
của LLM và hiệu suất mạnh có thể phản ánh việc ghi nhớ, điều này sẽ không tổng quát hóa
cho các tập dữ liệu và nhiệm vụ mới. Nếu không có hướng dẫn rõ ràng về quy trình làm việc
được khuyến nghị để sử dụng những công cụ này một cách an toàn và hiệu quả, các nhà học
thuật và người thực hành có thể triển khai loại công cụ này khi nó có hiệu suất không tối ưu.

Luận điểm chính của chúng tôi là một nhà nghiên cứu sử dụng LLM để chú thích tự động
phải luôn xác thực hiệu suất của LLM so với một tập con các nhãn được chú thích bởi con
người chất lượng cao.² Mặc dù LLMs có thể là một công cụ hiệu quả để tăng cường quy trình
chú thích, có những trường hợp LLMs không thể đưa ra kết quả chính xác do các yếu tố như
prompt không hiệu quả, dữ liệu văn bản nhiễu, và các nhiệm vụ chú thích khó khăn. Vì những
thách thức này sẽ tiếp tục tồn tại ngay cả khi công nghệ LLM được cải thiện,³ các nhà nghiên
cứu tăng cường phương pháp chú thích văn bản của họ với LLMs phải luôn xác thực trên cơ sở
từng nhiệm vụ. Xác thực nghiêm ngặt có thể giúp các nhà nghiên cứu tạo ra các prompt hiệu
quả và xác định liệu chú thích LLM có khả thi cho các nhiệm vụ phân loại và tập dữ liệu của
họ hay không. Để đạt được mục tiêu này, chúng tôi phác thảo một quy trình làm việc được
khuyến nghị để khai thác tiềm năng của LLMs cho chú thích văn bản một cách có nguyên tắc
và hiệu quả.

Trong bài báo này, chúng tôi đề xuất và kiểm tra một quy trình làm việc để tăng cường và
tự động hóa các dự án chú thích

¹Các nhà nghiên cứu đã nêu ra mối quan ngại về chất lượng dữ liệu thu thập từ các nhân viên trên các nền tảng
huy động đám đông phổ biến như Amazon's Mechanical Turk (Chmielewski và Kucker, 2020; Douglas et al., 2023)

²Với chất lượng cao, chúng tôi đề cập đến các nhãn được tạo ra bởi các chuyên gia chuyên môn (không phải trợ lý
sinh viên đại học hoặc nhân viên huy động đám đông) những người cẩn thận gắn nhãn một tập con nhỏ dữ liệu. Như
chúng tôi mô tả bên dưới, quy trình làm việc được khuyến nghị của chúng tôi chỉ yêu cầu một phần nhỏ dữ liệu văn
bản được gắn nhãn so với các thủ tục hiện tại.

³Ví dụ, ngay cả khi công nghệ LLM tăng về độ tinh vi, con người vẫn có thể cung cấp các hướng dẫn prompt mơ
hồ, điều này có thể ảnh hưởng tiêu cực đến hiệu suất LLM trong một nhiệm vụ chú thích.

--- TRANG 3 ---
với LLMs. Chúng tôi xác thực phương pháp của mình và kiểm tra khả năng của LLMs trên một
loạt rộng các nhiệm vụ chú thích từ các tập dữ liệu khác nhau, không công khai sử dụng các
chỉ số hiệu suất phù hợp. Chúng tôi sử dụng LLMs để sao chép 27 quy trình chú thích khác
nhau từ 11 tập dữ liệu không công khai được sử dụng từ các bài báo gần đây được đăng trên
các ấn phẩm có tác động cao. Tổng cộng, chúng tôi đã phân loại hơn 200.000 mẫu văn bản
sử dụng LLM (tức là, GPT-4).⁴

Các phát hiện của chúng tôi cho thấy hiệu suất LLM cho chú thích văn bản là đầy hứa hẹn
nhưng phụ thuộc rất nhiều vào cả tập dữ liệu và loại nhiệm vụ chú thích. Qua tất cả các nhiệm
vụ, chúng tôi báo cáo độ chính xác trung vị là 0.850 và F1 trung vị là 0.707. Mặc dù có hiệu
suất tổng thể mạnh, chín trong số 27 nhiệm vụ có precision hoặc recall dưới 0.5, điều này củng
cố sự cần thiết của việc xác thực của nhà nghiên cứu. Với sự biến đổi trong hiệu suất qua các
nhiệm vụ, chúng tôi xác định bốn trường hợp sử dụng khác nhau cho các quy trình chú thích
tự động được hướng dẫn bởi hiệu suất xác thực của LLMs. Chúng bao gồm sử dụng LLM để
kiểm tra chất lượng dữ liệu được gắn nhãn bởi con người, sử dụng LLM để xác định các trường
hợp cần ưu tiên để con người xem xét, sử dụng LLM để tạo ra dữ liệu được gắn nhãn để tinh
chỉnh và xác thực một bộ phân loại có giám sát, và sử dụng LLM để phân loại toàn bộ corpus
văn bản.

Ngoài việc khuyến nghị một quy trình tiêu chuẩn hóa để xác thực khi nào và làm thế nào
để sử dụng LLMs, chúng tôi cũng giới thiệu một số công cụ mới trong các thủ tục chú thích tự
động của mình.⁵ Thứ nhất, chúng tôi cung cấp phần mềm dễ sử dụng bằng Python được thiết
kế để triển khai các phương pháp của chúng tôi và đơn giản hóa việc triển khai LLMs cho chú
thích tự động. Thứ hai, chúng tôi cho thấy tính hữu ích của điểm số nhất quán. Để đo lường
mức độ nhất quán của LLM trong việc dự đoán nhãn của một mẫu văn bản cụ thể, chúng tôi
lặp lại việc phân loại từng mẫu văn bản ở nhiệt độ LLM là 0.6. Coi câu trả lời có tần suất cao
nhất là nhãn LLM được dự đoán, chúng tôi xấp xỉ một mức độ "nhất quán" qua từng phân loại
LLM. Vì có mối tương quan mạnh giữa điểm số nhất quán cao hơn và xác suất phân loại đúng,
điểm số nhất quán là một cách hiệu quả để các nhà nghiên cứu xác định các trường hợp cận
biên.

⁴Các học giả đã nêu ra mối quan ngại về việc dựa vào LLMs trong nghiên cứu khoa học xã hội do sự phát triển
liên tục của phần mềm LLM, bản chất hộp đen của cách LLMs xử lý truy vấn, và sự mơ hồ về dữ liệu huấn luyện
làm nền tảng cho LLMs. LLMs mã nguồn mở đại diện cho một giải pháp khả thi cho nhiều vấn đề này (Spirling,
2023). Quy trình làm việc được phác thảo ở đây là bất khả tri LLM và có thể được điều chỉnh cho bất kỳ LLM mã
nguồn mở nào.

⁵Code có sẵn tại đây: https://github.com/npangakis/gpt_annotate

--- TRANG 4 ---
Bước 1: Nhà nghiên cứu tạo ra các hướng dẫn cụ thể cho nhiệm vụ (tức là, một sách mã).

Bước 2: Sử dụng sách mã, các chuyên gia chuyên môn chú thích tập con ngẫu nhiên của các mẫu văn bản.

Bước 3: Sử dụng LLM để chú thích một tập con dữ liệu được gắn nhãn bởi con người sử dụng cùng sách mã. Sau đó, đánh giá hiệu suất bằng cách so sánh các nhãn LLM với các nhãn con người.

Bước 4: Nếu hiệu suất thấp, tinh chỉnh sách mã để nhấn mạnh các phân loại sai. Nếu cần thiết, lặp lại các bước 2 và 3 với sách mã được cập nhật.

Bước 5: Sử dụng sách mã cuối cùng, kiểm tra hiệu suất LLM trên các mẫu được gắn nhãn bởi con người còn lại.

Hình 1: Quy trình làm việc để tăng cường chú thích văn bản với LLM

--- TRANG 5 ---
2 Quy trình làm việc và xác thực

Trong trường hợp không có hướng dẫn rõ ràng về quy trình làm việc được khuyến nghị để sử dụng LLMs cho các nhiệm vụ chú thích, các nhà nghiên cứu có nguy cơ triển khai những công cụ này mặc dù hiệu suất kém. Được hiển thị trong Hình 1, chúng tôi đề xuất một quy trình làm việc năm bước để tích hợp LLMs một cách đặt phán đoán con người lên hàng đầu, bao gồm cơ hội tinh chỉnh hướng dẫn có con người tham gia vào vòng lặp, và đưa ra chỉ báo rõ ràng về hiệu suất LLM với việc đầu tư tài nguyên tối thiểu trước. Chúng tôi thiết kế quy trình làm việc này với hai động lực: để xác thực hiệu suất LLM và để tinh chỉnh prompts cho phân loại LLM khi có thể.

Như Hình 1 cho thấy, các nhà nghiên cứu trước tiên nên tạo ra một bộ hướng dẫn cụ thể cho nhiệm vụ (tức là, một sách mã)⁶ và sau đó có ít nhất hai chuyên gia chuyên môn và một LLM chú thích cùng các mẫu văn bản—với kích thước mẫu tùy thuộc vào loại nhiệm vụ và sự mất cân bằng lớp.⁷ Quan trọng là, cả người mã hóa con người và LLM đều nên sử dụng cùng sách mã để chú thích, trong đó sách mã đóng vai trò là hướng dẫn prompt của LLM.⁸ Sau đó, nhà nghiên cứu nên đánh giá hiệu suất (tức là, độ chính xác, recall, precision, và F1) bằng cách so sánh các nhãn LLM được dự đoán với các nhãn con người. Như một bước ban đầu, các nhà nghiên cứu trước tiên nên có LLM chú thích một tập con của các mẫu văn bản được gắn nhãn bởi con người. Nếu hiệu suất LLM thấp trên tập con này, các nhà nghiên cứu có thể tinh chỉnh các hướng dẫn sách mã bằng cách nhấn mạnh các phân loại sai (lặp lại quy trình này nếu cần thiết).⁹ Cuối cùng, sử dụng sách mã được cập nhật, các nhà nghiên cứu nên kiểm tra hiệu suất LLM so với các mẫu được gắn nhãn bởi con người còn lại. Hiệu suất trên dữ liệu held-out này nên được sử dụng để xác định liệu LLM có thể được sử dụng hiệu quả cho chú thích tự động hay không. Code được cung cấp trong kho GitHub của chúng tôi đưa ra một cách đơn giản và hiệu quả để triển khai các thủ tục được phác thảo trong quy trình làm việc trên.

⁶Vì LLMs phản hồi với các prompt ngôn ngữ tự nhiên, một sách mã rõ ràng là cần thiết cho các nhiệm vụ chú thích LLM. Nói chung, một sách mã chú thích nên phân định rõ ràng các khái niệm quan tâm. Một văn học phong phú trải dài cả khoa học xã hội định tính và định lượng đưa ra hướng dẫn về cách phát triển sách mã và phân loại dữ liệu văn bản dựa trên các khái niệm liên quan (ví dụ, Krippendorff, 2018; Crabtree và Miller, 1992; MacQueen et al., 1998).

⁷Dựa trên các phân tích của chúng tôi, số lượng mẫu được chú thích nên nằm trong khoảng từ 250 đến 1.250 mẫu văn bản ngẫu nhiên. Đối với các nhiệm vụ chú thích liên quan đến việc xác định các trường hợp rất hiếm (ví dụ, các trường hợp trong đó ít hơn 1 phần trăm mẫu văn bản được mã hóa là trường hợp dương tính cho một chiều cụ thể), có thể cần thiết phải gắn nhãn đáng kể nhiều mẫu văn bản bằng tay hơn.

⁸Nếu con người và LLMs gắn nhãn dữ liệu sử dụng các sách mã khác nhau, có thể có khoảng cách khái niệm giữa hai hướng dẫn chú thích.

⁹Sau khi cập nhật sách mã, các nhà nghiên cứu có thể muốn sử dụng sách mã được cập nhật để phân loại cùng tập con trường hợp một lần nữa để đo lường độ lớn thay đổi mà các chỉnh sửa của họ gây ra. Bài tập này là overfitting đối với một tập con dữ liệu cụ thể và do đó không nên được coi là thước đo hiệu suất. Thay vào đó, nó đưa ra một thước đo đơn giản về mức độ các chỉnh sửa sách mã ảnh hưởng đến việc ra quyết định của LLM. Nếu những thay đổi cơ bản được thực hiện đối với sách mã, nhà nghiên cứu có thể muốn có con người gắn nhãn lại các mẫu văn bản cũng.

--- TRANG 6 ---
Để xác thực quy trình làm việc được đề xuất, chúng tôi sử dụng LLM để sao chép 27 nhiệm vụ chú thích qua 11 tập dữ liệu. Để đảm bảo những nhiệm vụ này đại diện cho một loạt các nhiệm vụ chú thích trong nghiên cứu khoa học xã hội đương đại, chúng tôi rút ra từ nghiên cứu được công bố trên các ấn phẩm qua một phạm vi các ngành từ các ấn phẩm liên ngành (ví dụ, Science Advances và Proceedings of the National Academy of Sciences) đến các tạp chí chuyên ngành có tác động cao trong khoa học chính trị (ví dụ, American Political Science Review và American Journal of Political Science) và tâm lý học (ví dụ, Journal of Personality and Social Psychology). Trong Phụ lục, Bảng A1 bao gồm danh sách đầy đủ các bài báo sao chép và Bảng A2 cung cấp mô tả ngắn gọn về các nhiệm vụ chú thích trong các bài báo này.¹⁰ Những nhiệm vụ chú thích này bao gồm một loạt rộng các ứng dụng khoa học xã hội, từ việc xác định liệu các văn bản thời Chiến tranh Lạnh có liên quan đến các vấn đề ngoại giao hay quân sự (Schub, 2022) đến việc phân tích các phản hồi khảo sát mở để phân loại cách mọi người khái niệm hóa nơi niềm tin đến từ đâu (Cusimano và Goodwin, 2020).

Trong mỗi trường hợp, chúng tôi sao chép một nhiệm vụ chú thích sử dụng dữ liệu được gắn nhãn bởi con người từ nghiên cứu gốc làm truth cơ sở. Để tránh tiềm năng contamination, chúng tôi dựa hoàn toàn vào các tập dữ liệu được lưu trữ trong các kho lưu trữ dữ liệu được bảo vệ bằng mật khẩu (ví dụ, Dataverse) hoặc các tập dữ liệu được bảo mật thông qua việc tiếp cận trực tiếp với các tác giả.¹¹ Bất cứ khi nào có thể, chúng tôi bắt đầu với sách mã chính xác được sử dụng trong thiết kế nghiên cứu ban đầu. Nếu sách mã này không có sẵn, chúng tôi hoặc trích dẫn hoặc diễn giải văn bản từ bài báo hoặc tài liệu bổ sung mô tả các khái niệm quan tâm.¹²

Qua tất cả 27 nhiệm vụ, chúng tôi chú thích hơn 200.000 mẫu văn bản sử dụng API GPT-4 của OpenAI. Tổng chi phí là khoảng 420 USD. Trung bình, một tập dữ liệu với 1.000 mẫu văn bản

¹⁰Để tìm những bài báo này, chúng tôi tìm kiếm các tạp chí có tác động cao cho các bài báo triển khai một số loại thủ tục chú thích thủ công. Nếu chúng tôi có thể thu được dữ liệu văn bản, chúng tôi sao chép tất cả các thủ tục chú thích từ các bài báo được công bố trong ba năm qua.

¹¹Để hài hòa loạt các nhiệm vụ chú thích đa dạng này thành một framework chung để đánh giá, chúng tôi coi mỗi chiều là một nhiệm vụ chú thích nhị phân riêng biệt. Do đó, nếu một bài báo bao gồm một nhiệm vụ phân loại với ba nhãn tiềm năng, chúng tôi chia quy trình chú thích thành ba nhiệm vụ phân loại nhị phân riêng biệt.

¹²Chúng tôi không quan sát thấy bất kỳ mối quan hệ nào giữa hiệu suất LLM và liệu sách mã trực tiếp có sẵn hay không.

--- TRANG 7 ---
mất khoảng 2–3 giờ để hoàn thành bảy lần lặp (xem phần "Điểm số nhất quán" bên dưới). Cùng nhau, chi phí thấp và tốc độ tương đối nhanh chóng cho thấy giá trị tiềm năng của chú thích được tăng cường LLM cho nhiều nhiệm vụ phân tích văn bản khoa học xã hội.

3 Kết quả

Kết quả phân loại được hiển thị trong Bảng 1. Kết quả được báo cáo ở đây dựa trên các mẫu văn bản "held out" (tức là, không phải các mẫu văn bản được sử dụng trong quy trình cập nhật sách mã từ Bước 4 của quy trình làm việc). Qua 27 nhiệm vụ, hiệu suất phân loại LLM đạt điểm F1 trung vị là 0.707. Hình 2 cho thấy hiệu suất về precision và recall cho từng nhiệm vụ phân loại. Như rõ ràng trong hình này, hiệu suất phân loại LLM mạnh hơn về recall so với precision cho 20 trong số 27 nhiệm vụ. Trên tám trong số 27 nhiệm vụ, LLM đạt hiệu suất mạnh đáng kể với cả precision và recall đều vượt quá 0.7.

Chỉ số | Tối thiểu | Phân vị thứ 25 | Trung bình | Trung vị | Phân vị thứ 75 | Tối đa
Độ chính xác | 0.674 | 0.808 | 0.855 | 0.85 | 0.905 | 0.981
Precision | 0.033 | 0.472 | 0.615 | 0.650 | 0.809 | 0.957
Recall | 0.25 | 0.631 | 0.749 | 0.829 | 0.899 | 0.982
F1 | 0.059 | 0.557 | 0.660 | 0.707 | 0.830 | 0.969

Bảng 1: Hiệu suất phân loại LLM qua 27 nhiệm vụ từ 11 tập dữ liệu.

Mặc dù có hiệu suất tổng thể mạnh, chín trong số 27 nhiệm vụ có precision hoặc recall dưới 0.5—và ba nhiệm vụ có cả precision và recall dưới 0.5. Do đó, đối với một phần ba đầy đủ các nhiệm vụ, LLM hoặc bỏ sót ít nhất một nửa các trường hợp dương tính thật, có nhiều dương tính giả hơn dương tính thật, hoặc cả hai. Như được hiển thị trong Bảng 2, hiệu suất tổng hợp dao động thấp đến điểm F1

--- TRANG 8 ---
[Biểu đồ scatter plot hiển thị Precision vs Recall với các điểm dữ liệu có màu sắc khác nhau đại diện cho các tập dữ liệu khác nhau]

Hình 2: Precision và recall cho từng trong 27 nhiệm vụ phân loại được sao chép. Màu sắc phản ánh tập dữ liệu, sao cho các điểm có cùng màu được thực hiện trên cùng dữ liệu văn bản.

--- TRANG 9 ---
là 0.06. Hơn nữa, hiệu suất LLM thay đổi đáng kể qua các nhiệm vụ trong một tập dữ liệu đơn lẻ. Trong ví dụ cực đoan nhất, F1 dao động từ 0.259 đến 0.811 trên hai nhiệm vụ riêng biệt trong Card et al. (2022), một chênh lệch 0.552. Những kết quả này chứng minh sự biến đổi của chú thích LLM và, tương ứng, nhấn mạnh sự cần thiết cho việc xác thực cụ thể theo nhiệm vụ.

3.1 Điểm số nhất quán

Bằng cách gây ra sự ngẫu nhiên trong LLM thông qua việc sử dụng tham số siêu nhiệt độ và bằng cách lặp lại nhiệm vụ chú thích, chúng tôi có thể tạo ra một biện pháp thực nghiệm về phương sai trong nhãn mà chúng tôi gọi là "điểm số nhất quán". Chúng tôi khuyến nghị rằng nhà nghiên cứu nên có LLM phân loại từng mẫu ít nhất ba lần với nhiệt độ trên 0.¹³ Đối với các phân tích của chúng tôi, chúng tôi sử dụng nhiệt độ 0.6 để gắn nhãn từng mẫu văn bản tối thiểu bảy lần với cùng sách mã.¹⁴

Như được hiển thị trong Hình 3, điểm số nhất quán có tương quan với độ chính xác, tỷ lệ dương tính thật, và tỷ lệ âm tính thật. Với một vector phân loại, C, với độ dài l cho một nhiệm vụ phân loại đã cho, tính nhất quán được đo lường là tỷ lệ phân loại khớp với phân loại modal (1/l ∑ᵢ₌₁ˡ Cᵢ == Cₘₒₑ). Qua các nhiệm vụ, độ chính xác cao hơn 19.4 điểm phần trăm cho các mẫu văn bản được gắn nhãn với điểm số nhất quán 1.0 so với những mẫu được gắn nhãn với điểm số nhất quán nhỏ hơn 1.0. Tỷ lệ dương tính thật và tỷ lệ âm tính thật lần lượt cao hơn 16.4 điểm phần trăm và 21.4 điểm phần trăm cho các phân loại hoàn toàn nhất quán. Trong tất cả các mẫu được gắn nhãn, 85.1% có điểm số nhất quán 1.0. Do đó, điểm số nhất quán đưa ra một cách hữu ích để xác định các trường hợp cận biên hoặc chú thích khó khăn hơn.

¹³Nhiệt độ là một tham số siêu LLM chỉ ra mức độ đa dạng được giới thiệu qua các phản hồi LLM. Nó dao động từ 0 đến 1.

¹⁴Trong khi lựa chọn 0.6 của chúng tôi là tùy ý, chúng tôi đã xác nhận rằng việc chú thích nhiều mẫu văn bản lặp lại trả về kết quả tốt hơn một phân loại duy nhất ở nhiệt độ 0. Nghiên cứu tương lai có thể kiểm tra cài đặt nhiệt độ nào trả về kết quả tối ưu.

--- TRANG 10 ---
[Biểu đồ line chart hiển thị mối quan hệ giữa Consistency Score (x-axis) và Probability of Correct Classification (y-axis) với ba đường: Accuracy, True Negative Rate, True Positive Rate]

Hình 3: Mối quan hệ giữa điểm số nhất quán và độ chính xác, TPR, và TNR.

3.2 Cập nhật sách mã

Đối với từng trong 27 nhiệm vụ phân loại, chúng tôi tuân theo quy trình làm việc được phác thảo trước đó. Trong các bước 3 và 4 của quy trình làm việc, chúng tôi kiểm tra hiệu suất phân loại LLM trên một tập con dữ liệu và sau đó, nếu liên quan, thực hiện các cập nhật sách mã có con người tham gia vào vòng lặp để tối ưu hóa prompt

--- TRANG 11 ---
cho hiệu suất phân loại LLM. Bước này có thể được coi là một ứng dụng của "prompt engineering" trong đó nhà nghiên cứu cố gắng xác định các mẫu trong việc phân loại sai của LLM và thay đổi sách mã để sửa chữa bất kỳ nhận thức sai lầm nhất quán nào. Đối với mỗi nhiệm vụ, chúng tôi thực hiện tối đa một vòng cập nhật sách mã. Để đo lường hiệu ứng mà việc cập nhật sách mã có trên việc gắn nhãn LLM, chúng tôi gắn nhãn lại các tập con dữ liệu huấn luyện sử dụng các sách mã cuối cùng.

Hình 4 cho thấy phân phối thay đổi trong các chỉ số hiệu suất sau khi cập nhật sách mã. Phân tích này chứng minh liệu và cách quy trình cập nhật sách mã ảnh hưởng đến chú thích LLM, giữ không đổi dữ liệu và các danh mục khái niệm. Trong hầu hết các trường hợp, quy trình cập nhật sách mã dẫn đến cải thiện khiêm tốn về độ chính xác và F1. Recall giảm trong nhiều trường hợp hơn là cải thiện sau khi cập nhật sách mã. Mặt khác, Precision cải thiện trong đa số trường hợp, thúc đẩy sự cải thiện về độ chính xác và F1. Với những kết quả này, các tinh tế của việc xây dựng prompt không xuất hiện là một đòn bẩy đáng kể trên hiệu suất. Tuy nhiên, mặc dù độ lớn cải thiện thường nhỏ, các nhà nghiên cứu gặp phải hiệu suất phân loại LLM không đạt yêu cầu trên dữ liệu văn bản của họ có thể sử dụng việc tinh chỉnh sách mã có con người tham gia vào vòng lặp để đảm bảo rằng hướng dẫn của họ không phải lỗi.

--- TRANG 12 ---
[Biểu đồ mật độ hiển thị phân phối thay đổi hiệu suất cho Precision, Recall, Accuracy, và F1]

Hình 4: Thay đổi trong hiệu suất chú thích LLM trên dữ liệu huấn luyện sau một vòng cập nhật sách mã.

4 Trường hợp sử dụng

Nếu LLM đạt hiệu suất thỏa mãn trên các benchmark cụ thể miền cho một nhiệm vụ chú thích đã cho, có nhiều cách mà LLM có thể được tích hợp vào một dự án phân tích văn bản. Cách các nhà nghiên cứu tăng cường dự án của họ với LLM có thể phụ thuộc vào hiệu suất LLM so với dữ liệu được gắn nhãn bởi con người, ngân sách của họ, kích thước của tập dữ liệu, và tính khả dụng của các nhà chú thích con người. Bảng 2 hiển thị bốn trường hợp sử dụng tiềm năng.

Nếu hiệu suất của LLM trên một số hoặc tất cả các chiều kém, thì nhà nghiên cứu có thể tiếp tục tinh chỉnh sách mã sử dụng dữ liệu được gắn nhãn mới hoặc từ bỏ việc sử dụng LLMs cho các chiều có hiệu suất không thỏa mãn. Nếu các nhà nghiên cứu chọn tiếp tục sử dụng LLM mặc dù hiệu suất ban đầu kém, một chiến lược để đơn giản hóa các chú thích phức tạp có thể là disaggregation. Ví dụ, nếu một

--- TRANG 13 ---
Trường hợp sử dụng | Mô tả
1) Xác nhận chất lượng dữ liệu được gắn nhãn bởi con người | Nếu một nhà nghiên cứu có dữ liệu đã được gắn nhãn bởi các nhà chú thích con người, LLM có thể tăng cường quy trình phân tích văn bản bằng cách xác nhận chất lượng của các nhãn con người. Nếu hiệu suất LLM so với các nhãn con người cao, điều này báo hiệu rằng cả LLM và con người đều đưa ra các quyết định chú thích tương tự. Nếu hiệu suất LLM thấp, điều này chỉ ra rằng hoặc con người, LLM, hoặc cả hai đã mắc lỗi trong quá trình chú thích.
2) Xác định các trường hợp cần ưu tiên để con người xem xét | Một nhà nghiên cứu có thể xem xét thủ công các chú thích với điểm số nhất quán thấp hơn 1.0. Ngoài ra, nếu nhiệm vụ LLM cụ thể đạt recall cao, thì nhà nghiên cứu có thể sử dụng LLM để xác định các trường hợp dương tính tiềm năng trong dữ liệu chưa thấy trước đó. Sau đó, các nhà chú thích con người có thể xem xét thủ công tất cả các trường hợp được gắn nhãn dương tính.
3) Tạo ra dữ liệu được gắn nhãn để tinh chỉnh và xác thực một bộ phân loại có giám sát | Có nhiều tình huống khác nhau trong đó một nhà nghiên cứu có thể sử dụng LLM để thu thập dữ liệu huấn luyện để tinh chỉnh một bộ phân loại có giám sát để gắn nhãn corpus của họ.
4) Phân loại toàn bộ corpus trực tiếp | Trong trường hợp đơn giản nhất, một nhà nghiên cứu có thể thấy hiệu suất LLM là thỏa mãn và chọn sử dụng LLM để phân loại toàn bộ corpus còn lại.

Bảng 2: Các trường hợp sử dụng cho chú thích tự động với LLMs.

--- TRANG 14 ---
nhà nghiên cứu thấy hiệu suất chú thích kém trên chiều của "ngôn từ thù hận," họ có thể đạt hiệu suất tốt hơn bằng cách disaggregating "ngôn từ thù hận" thành các chỉ số thành phần (như đe dọa, lăng mạ, định kiến, v.v.) và thêm từng chỉ số riêng biệt như các chiều mới vào sách mã, sau đó bắt đầu lại từ Bước 1 trong quy trình làm việc.

5 Kết luận

Chúng tôi quan sát thấy sự không đồng nhất đáng kể trong hiệu suất LLM qua một loạt các nhiệm vụ chú thích khoa học xã hội. Hiệu suất phụ thuộc vào cả thuộc tính của văn bản và các danh mục khái niệm được đo lường. Ví dụ, liệu một nhiệm vụ phân loại là một câu hỏi thực tế về một mẫu văn bản hay yêu cầu phán đoán có ảnh hưởng đáng kể đến chiến lược phân loại (Balagopalan et al., 2023). Để giải quyết vô số nguồn biến đổi trong hiệu suất chú thích, chúng tôi khuyến nghị một phương pháp linh hoạt đối với chú thích được tăng cường LLM đặt chú thích con người lên hàng đầu.

Để giải quyết những thách thức này, chúng tôi trình bày một quy trình làm việc ban đầu để tăng cường chú thích văn bản với LLM cùng với một số trường hợp sử dụng cho quy trình làm việc này. Chúng tôi xác thực quy trình làm việc bằng cách sao chép 27 nhiệm vụ chú thích được lấy từ 11 bài báo khoa học xã hội được công bố trong các tạp chí có tác động cao. Chúng tôi thấy rằng LLMs có thể đưa ra các nhãn chất lượng cao trên nhiều nhiệm vụ đa dạng với một phần nhỏ chi phí và thời gian của các lựa chọn thay thế, như nhân viên huy động đám đông và trợ lý nghiên cứu sinh viên đại học. Tuy nhiên, điều quan trọng là các nhà nghiên cứu xác thực hiệu suất của LLMs trên cơ sở từng nhiệm vụ, vì chúng tôi thấy sự không đồng nhất đáng kể trong hiệu suất, ngay cả qua các nhiệm vụ trong một tập dữ liệu đơn lẻ.

--- TRANG 15 ---
Tài liệu tham khảo

Balagopalan, A., Madras, D., Yang, D. H., Hadfield-Menell, D., Hadfield, G. K., và Ghassemi, M. (2023). Judging facts, judging norms: Training machine learning models to judge humans requires a modified approach to labeling data. Science Advances, 9(19):eabq0701.

Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., Agarwal, S., Herbert-Voss, A., Krueger, G., Henighan, T., Child, R., Ramesh, A., Ziegler, D., Wu, J., Winter, C., Hesse, C., Chen, M., Sigler, E., Litwin, M., Gray, S., Chess, B., Clark, J., Berner, C., McCandlish, S., Radford, A., Sutskever, I., và Amodei, D. (2020). Language models are few-shot learners. Trong Larochelle, H., Ranzato, M., Hadsell, R., Balcan, M., và Lin, H., editors, Advances in Neural Information Processing Systems, volume 33, pages 1877–1901. Curran Associates, Inc.

Card, D., Chang, S., Becker, C., Mendelsohn, J., Voigt, R., Boustan, L., Abramitzky, R., và Jurafsky, D. (2022). Computational analysis of 140 years of us political speeches reveals more positive but increasingly polarized framing of immigration. Proceedings of the National Academy of Sciences of the United States of America, 31.

Chmielewski, M. và Kucker, S. C. (2020). An mturk crisis? shifts in data quality and the impact on study results. Social Psychological and Personality Science, 11(4):464–473.

Crabtree, B. F. và Miller, W. L. (1992). A template approach to text analysis: Developing and using codebooks. Trong Doing qualitative research. Sage Publications.

Cusimano, C. và Goodwin, G. P. (2020). People judge others to have more voluntary control over beliefs than they themselves do. Journal of Personality and Social Psychology, 119.

Ding, B., Qin, C., Liu, L., Bing, L., Joty, S., và Li, B. (2022). Is gpt-3 a good data annotator?

Douglas, B. D., Ewell, P. J., và Braue, M. (2023). Data quality in online human-subjects research: Comparisons between mturk, prolific, cloudresearch, qualtrics, and sona. PLoS One, 18.

Gilardi, F., Alizadeh, M., và Kubli, M. (2023). Chatgpt outperforms crowd-workers for text-annotation tasks.

Grimmer, J. và Stewart, B. M. (2013). Text as data: The promise and pitfalls of automatic content analysis methods for political texts. Political Analysis, 21(3):267–297.

He, X., Lin, Z., Gong, Y., Jin, A.-L., Zhang, H., Lin, C., Jiao, J., Yiu, S. M., Duan, N., và Chen, W. (2023). Annollm: Making large language models to be better crowdsourced annotators.

--- TRANG 16 ---
Kennedy, B., Atari, M., Davani, A. M., Yeh, L., Omrani, A., Kim, Y., Coombs, K., Havaldar, S., Portillo-Wightman, G., Gonzalez, E., Hoover, J., Azatian, A., Hussain, A., Lara, A., Olmos, G., Omary, A., Park, C., Wijaya, C., Wang, X., Zhang, Y., và Dehghani, M. (2022). Introducing the gab hate corpus: defining and applying hate-based rhetoric to social media posts at scale. Lang Resources & Evaluation.

Krippendorff, K. (2018). Content Analysis: An Introduction to Its Methodology. Sage, 4 edition.

MacQueen, K. M., McLellan, E., Kay, K., và Milstein, B. (1998). Codebook development for team-based qualitative analysis. CAM Journal, 10(2):31–36.

Neuendorf, K. A. (2016). The Content Analysis Guidebook. Sage Publications.

Reiss, M. (2023). Testing the reliability of chatgpt for text annotation and classification: A cautionary remark. Working paper.

Saha, P., Narla, Kalyan, K., và Mukherjee, A. (2023). On the rise of fear speech in online social media. Proceedings of the National Academy of Sciences of the United States of America.

Schub, R. (2022). Informing the leader: Bureaucracies and international crises. American Political Science Review, 116.

Spirling, A. (2023). Why open-source generative ai models are an ethical way forward for science. Nature, 413.

Wang, S., Liu, Y., Xu, Y., Zhu, C., và Zeng, M. (2021). Want to reduce labeling cost? GPT-3 can help. Trong Findings of the Association for Computational Linguistics: EMNLP 2021, pages 4195–4205, Punta Cana, Dominican Republic. Association for Computational Linguistics.

Zhu, Y., Zhang, P., Haq, E.-U., Hui, P., và Tyson, G. (2023). Can chatgpt reproduce human-generated labels? a study of social computing tasks.

Ziems, C., Held, W., Shaikh, O., Chen, J., , Zhang, Z., và Yang, D. (2023). Can large language models transform computational social science? Working paper.

--- TRANG 17 ---
Phụ lục

Tác giả | Tiêu đề | Tạp chí | Năm
Gohdes | Repression Technology: Internet Accessibility and State Violence | American Journal of Political Science | 2020
Hopkins, Lelkes, và Wolken | The Rise of and Demand for Identity-Oriented Media Coverage | American Journal of Political Science | (R&R)
Schub | Informing the Leader: Bureaucracies and International Crises | American Political Science Review | 2022
Busby, và Gubler, Hawkins | Framing and blame attribution in populist rhetoric | Journal of Politics | 2019
Müller | The Temporal Focus of Campaign Communication | Journal of Politics | 2021
Cusimano và Goodwin | People judge others to have more voluntary control over beliefs than they themselves do | Journal of Personality and Social Psychology | 2020
Yu và Zhang | The Impact of Social Identity Conflict on Planning Horizons | Journal of Personality and Social Psychology | 2022
Card et al. | Computational analysis of 140 years of US political speeches reveals more positive but increasingly polarized framing of immigration | PNAS | 2022
Peng, Romero, và Horvat | Dynamics of cross-platform attention to retracted papers | PNAS | 2022
Saha et al. | On the rise of fear speech in online social media | PNAS | 2022
Wojcieszak et al. | Most users do not follow political elites on Twitter; those who do show overwhelming preferences for ideological congruity | Science Advances | 2022

Bảng A1: Nguồn của các nhiệm vụ chú thích được sao chép trong phân tích.

--- TRANG 18 ---
¹⁵Bài báo này sử dụng corpus ngôn từ thù hận Gab (Kennedy et al., 2022). Chúng tôi bao gồm Saha et al. (2023) ở đây, thay vì nguồn gốc của dữ liệu được gắn nhãn, để nhấn mạnh việc ứng dụng những dữ liệu này trong nghiên cứu khoa học xã hội ứng dụng.

--- TRANG 19 ---
Nghiên cứu | Nhiệm vụ chú thích
Gohdes (2020) | Mã hóa hồ sơ tử vong Syria cho loại giết chóc cụ thể: có mục tiêu hoặc không có mục tiêu
Hopkins, Lelkes, & Wolken (2023) | Mã hóa tiêu đề, tweets, và blurbs chia sẻ Facebook để xác định tham chiếu đến các nhóm xã hội được định nghĩa bởi a) chủng tộc/dân tộc; b) giới tính/tính dục; c) chính trị; d) tôn giáo
Schub (2020) | Mã hóa các văn bản thảo luận cấp tổng thống từ Chiến tranh Lạnh là chính trị hoặc quân sự
Busby, Gubler, & Hawkins (2019) | Mã hóa phản hồi mở cho ba yếu tố tu từ: quy kết lỗi cho một tác nhân cụ thể, việc quy kết lỗi cho một tác nhân tinh hoa xấu xa, và đề cập tích cực đến người dân tập thể
Müller (2021) | Mã hóa câu từ tuyên ngôn đảng cho hướng thời gian: quá khứ, hiện tại, hoặc tương lai
Cusimano & Goodwin (2020) | Mã hóa tuyên bố bằng văn bản của người trả lời về biến đổi khí hậu cho sự hiện diện của hoặc (a) lý luận chung về niềm tin hoặc (b) bằng chứng hỗ trợ cho niềm tin
Yu & Zhang (2023) | Mã hóa kế hoạch của người trả lời cho tương lai thành hai danh mục: tương lai gần và tương lai xa
Card et al. (2022) | Mã hóa các bài phát biểu quốc hội cho liệu chúng có về nhập cư hay không, cùng với một tông điệu đi kèm: ủng hộ nhập cư, chống nhập cư, hoặc trung tính
Peng, Romero, & Horvat (2022) | Mã hóa liệu tweets có thể hiện sự chỉ trích đối với các phát hiện của các bài báo học thuật hay không
Saha et al. (2020) | Mã hóa các bài đăng Gab là a) ngôn từ sợ hãi, b) ngôn từ thù hận, hoặc c) bình thường. Hơn nữa, một bài đăng có thể có cả thành phần sợ hãi và thù hận, và do đó, chúng được chú thích với nhiều nhãn
Wojcieszak et al. (2020) | Mã hóa liệu một quote tweet có tiêu cực, trung tính hay tích cực đối với thông điệp và/hoặc tác nhân chính trị, độc lập với tông điệu của thông điệp gốc hay không

Bảng A2: Mô tả các nhiệm vụ chú thích được sao chép trong phân tích.

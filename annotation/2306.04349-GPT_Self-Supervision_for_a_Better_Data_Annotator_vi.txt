# 2306.04349.pdf
# Đã chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/annotation/2306.04349.pdf
# Kích thước tệp: 4077995 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Tự Giám Sát GPT cho một Người Chú Thích Dữ Liệu Tốt Hơn
Xiaohuan Pei, Yanxi Li, Chang Xu
Trường Khoa học Máy tính, Khoa Kỹ thuật
Đại học Sydney
xpei8318@uni.sydney.edu.au, yali0722@uni.sydney.edu.au, c.xu@sydney.edu.au
Tóm tắt
Nhiệm vụ chú thích dữ liệu thành các bản tóm tắt ngắn gọn đặt ra một thách thức đáng kể
trên nhiều lĩnh vực khác nhau, thường xuyên đòi hỏi việc phân bổ thời gian đáng kể và
kiến thức chuyên môn của các chuyên gia con người. Mặc dù đã có những nỗ lực hiện tại để sử dụng các mô hình
ngôn ngữ lớn cho các nhiệm vụ chú thích, các vấn đề đáng kể như khả năng áp dụng hạn chế
đối với dữ liệu không gán nhãn, sự vắng mặt của các phương pháp tự giám sát, và thiếu
tập trung vào dữ liệu có cấu trúc phức tạp vẫn tồn tại. Trong công trình này, chúng tôi đề xuất một phương pháp chú thích tự giám sát GPT, thể hiện một mô hình tạo-khôi phục
tận dụng khả năng học một lần của Transformer Tiền huấn luyện Tạo sinh (GPT). Phương pháp được đề xuất bao gồm một giai đoạn điều chỉnh một lần tiếp theo là một giai đoạn tạo sinh. Trong giai đoạn điều chỉnh một lần, chúng tôi lấy mẫu một dữ liệu từ
tập hỗ trợ như một phần của prompt cho GPT để tạo ra một bản tóm tắt văn bản, sau đó được sử dụng để khôi phục dữ liệu gốc. Điểm số căn chỉnh giữa dữ liệu được khôi phục
và dữ liệu gốc phục vụ như một bộ định hướng tự giám sát để tinh chỉnh quá trình. Trong
giai đoạn tạo sinh, mẫu một lần được chọn tối ưu phục vụ như một mẫu
trong prompt và được áp dụng để tạo ra các bản tóm tắt từ các tập dữ liệu thách thức.
Hiệu suất chú thích được đánh giá bằng cách điều chỉnh một số mạng phần thưởng phản hồi của con người và bằng cách tính toán điểm số căn chỉnh giữa dữ liệu gốc và được khôi phục
ở cả mức câu và mức cấu trúc. Phương pháp chú thích tự giám sát của chúng tôi
nhất quán đạt được điểm số cạnh tranh, chứng minh một cách thuyết phục sức mạnh vững chắc của nó trong các nhiệm vụ chú thích dữ liệu-thành-tóm tắt khác nhau.

1 Giới thiệu
Các mô hình ngôn ngữ lớn được đại diện bởi họ Transformer Tiền huấn luyện Tạo sinh(GPT) [23, 24, 1]
đã có những tiến bộ đột phá trong những năm gần đây, đạt được hiệu suất tối tân trên
nhiều nhiệm vụ học sâu khác nhau. Trong số những nhiệm vụ này, chú thích dữ liệu là bước đầu tiên cơ bản và không thể thiếu trong quá trình nghiên cứu AI, vì nó đặt nền móng bằng cách cung cấp dữ liệu được gán nhãn
phục vụ như nền tảng cho việc huấn luyện và đánh giá các mô hình [ 14,27,2,3]. Chất lượng của việc tạo ra nhãn dữ liệu
trực tiếp tác động đến tất cả các nhiệm vụ tiếp theo, làm cho nó trở thành nền tảng của toàn bộ quá trình học sâu
[12, 21].

Nhiệm vụ chú thích đặt ra những thách thức đáng kể. Đầu tiên, độ phức tạp của dữ liệu làm cho việc
tốn thời gian cho các chuyên gia để chú thích từng mẫu [ 18,28,4,29]. Ví dụ, các đồ thị tính toán
cung cấp những hiểu biết có giá trị về thiết kế cấu trúc mạng nơ-ron và việc chú thích những
tế bào này đòi hỏi nỗ lực đáng kể để xác định và tóm tắt các chuỗi con tương tự như các khối song song
[8], điều này gần như không thể xác định và cô lập. Thứ hai, việc sử dụng độc quyền các bản tóm tắt được chú thích bởi con người mang tính chủ quan
đặt ra những thách thức đánh giá [ 5,1]. Việc sử dụng những bản tóm tắt chủ quan này
như nhãn học có giám sát có thể dẫn đến các nhiệm vụ chú thích phản ánh thiên kiến của con người, không phải mối tương quan công bằng
giữa dữ liệu và bản tóm tắt của nó.

Nghiên cứu gần đây đã khai thác khả năng của các mô hình ngôn ngữ lớn cho chú thích dữ liệu có giám sát.
Như được tiết lộ bởi [ 7,11,30], các mô hình GPT có thể chú thích các nhiệm vụ phân loại thông qua thiết kế trực tiếp
Bản thảo. Đang được xem xét.arXiv:2306.04349v2  [cs.CL]  8 Jun 2023

--- TRANG 2 ---
của các prompt đa dạng. Hơn nữa, nghiên cứu của [ 13] mở rộng phạm vi của nhiệm vụ chú thích này,
cho phép tạo ra các cuộc đối thoại. Mặc dù có tiến bộ ấn tượng, các vấn đề của nhiệm vụ chú thích
vẫn còn tồn tại. Đầu tiên, các nghiên cứu hiện tại chủ yếu tập trung vào chú thích có giám sát với
dữ liệu được gán nhãn bởi con người, điều này hạn chế khả năng áp dụng của phương pháp chú thích đối với dữ liệu không gán nhãn tổng quát hơn. Trong hầu hết các tình huống, dữ liệu được gán nhãn bởi con người không có sẵn để hướng dẫn quá trình chú thích. Thứ hai,
nghiên cứu trước đây đã bị giới hạn trong việc thiết kế các prompt khác nhau, mà không xem xét các cơ chế phản hồi để tinh chỉnh các phần cụ thể của prompt. Thứ ba, thiếu nghiên cứu tập trung vào
chú thích dữ liệu có cấu trúc phức tạp. Công việc hiện tại chỉ tập trung vào chú thích các mẫu mô tả ngôn ngữ tự nhiên đơn giản mà không thách thức dữ liệu có cấu trúc phức tạp hơn. Ví dụ, các tập dữ liệu của đồ thị tính toán được trích xuất bởi mạng nơ-ron bao gồm cấu trúc lồng nhau khác nhau,
làm cho việc con người chú thích các khối cụ thể trong danh sách cạnh phức tạp như vậy trở nên khó khăn.

Mô hình Ngôn ngữ Lớn Mẫu(Dữ liệu)Cập nhật Trọng số Cập nhật Dữ liệu như một Mẫu Mới
Dữ liệu+
Hình 1: Mô hình tạo-khôi phục dựa trên dữ liệu làm trung tâm. Cập nhật lặp đi lặp lại mẫu với dữ liệu được tạo ra. xi được lấy mẫu từ một tập hỗ trợ ứng viên và si được tạo ra bởi GPT.Ở đây chúng tôi đề xuất một phương pháp tự giám sát GPT thông qua một vòng lặp tạo-khôi phục, chủ yếu
được lấy cảm hứng từ điều chỉnh prompt [ 15,16] và mô hình lấy dữ liệu làm trung tâm [ 22], như được nêu trong Hình
1. Khung làm việc của phương pháp tự giám sát
chứa giai đoạn một lần và giai đoạn tạo sinh.
Giai đoạn một lần nhằm mục đích tìm kiếm lặp đi lặp lại
các cặp tối ưu của dữ liệu và tóm tắt như
mẫu. Bắt đầu với một cặp dữ liệu được chú thích bởi con người, quá trình lặp của chúng tôi sử dụng GPT để
tạo ra các bản tóm tắt. Bản tóm tắt được tạo ra
và dữ liệu thô tạo thành một cặp dữ liệu mới. Cặp dữ liệu mới này sau đó được đánh giá về tiềm năng của nó như một
mẫu thông qua so sánh dữ liệu được khôi phục từ bản tóm tắt với dữ liệu gốc. Nếu cả điểm số hỗ trợ và xác thực đều cải thiện, chúng tôi
cập nhật mẫu tối ưu với cặp dữ liệu mới hiện tại. Do đó, cơ chế tự căn chỉnh
điều chỉnh lặp đi lặp lại mẫu một lần cho vòng tạo sinh tiếp theo. Mẫu tối ưu được tìm kiếm sau đó được sử dụng để tạo ra các bản tóm tắt trong giai đoạn tạo sinh. Chúng tôi điều chỉnh các mô hình phần thưởng khác nhau để đánh giá chất lượng tóm tắt và giới thiệu các chỉ số tương tự khác nhau để đánh giá khả năng khôi phục. Chúng tôi thực hiện các thí nghiệm đầy đủ trên ba tập dữ liệu thách thức và tiến hành nghiên cứu loại bỏ chi tiết từ nhiều góc độ khác nhau. Các kết quả chứng minh mô hình tự giám sát của chúng tôi nhất quán
mang lại hiệu suất cạnh tranh được đánh giá bởi các mô hình phần thưởng và điểm số khôi phục. Ngoài ra, chúng tôi
áp dụng phương pháp tự giám sát của chúng tôi để tạo ra hai tập dữ liệu mới gồm 3k/15k bản tóm tắt của các kiến trúc mạng nơ-ron dựa trên các toán tử tính toán khác nhau.

2 Công trình Liên quan
Mô hình Ngôn ngữ Lớn. GPT-1 [ 23] đề xuất một phương pháp hai bước: tiền huấn luyện trên văn bản không gán nhãn
và điều chỉnh phân biệt trên các nhiệm vụ cụ thể. Không giống như các phương pháp trước đây, nó sử dụng các chuyển đổi đầu vào nhận thức nhiệm vụ trong quá trình điều chỉnh, giảm thiểu các thay đổi đối với kiến trúc mô hình. GPT-2 [ 24]
chứng minh các mô hình ngôn ngữ có thể thực hiện các nhiệm vụ xuôi dòng trong thiết lập zero-shot – mà không có bất kỳ
sửa đổi tham số hoặc kiến trúc nào. GPT-3 [ 1] mở rộng quy mô các mô hình ngôn ngữ để cải thiện khả năng của chúng
với việc điều chỉnh tối thiểu abn đạt được hiệu suất few-shot mạnh mẽ mà không cần cập nhật gradient hoặc
điều chỉnh đặc thù nhiệm vụ.

Học Một/Vài Lần. Học các khái niệm mới một cách nhanh chóng với dữ liệu hạn chế là một thách thức trong máy
học. Học sâu có giám sát truyền thống không hiệu quả cho điều này. Li et al. [9] sử dụng mô hình Bayesian
và cho thấy rằng có thể học được nhiều về một danh mục chỉ từ một hoặc vài hình ảnh bằng cách
tận dụng kiến thức từ các danh mục đã học trước đây, bất kể sự khác biệt của chúng. Vinyals et
al.[26] định nghĩa các vấn đề học một lần và kết hợp học metric và mạng nơ-ron với
bộ nhớ bên ngoài để tạo ra một khung làm việc có thể học các khái niệm mới chỉ từ vài ví dụ. Khung làm việc
không yêu cầu điều chỉnh và được thử nghiệm trên các nhiệm vụ thị giác và ngôn ngữ. Như đã đề cập ở trên,
GPT-3 [ 1] là một người học few-shot mạnh mẽ, thể hiện hiệu suất đáng chú ý trên nhiều nhiệm vụ xử lý ngôn ngữ tự nhiên
khác nhau, bao gồm dịch thuật, hỏi đáp, và nhiệm vụ cloze, mà không cần
điều chỉnh hoặc cập nhật gradient.
2

--- TRANG 3 ---
Mẫu:
Dữ liệu  = {"INPUT ->conv3, conv3-
>bn,bn->avgpool3, avgpool3-
>avgpool3, avgpool3->OUTPUT ,
INPUT ->OUTPUT"}
Tóm tắt  = Kiến trúc mạng nơ-ron
bao gồm một lớp đầu vào
tiếp theo là 2 khối và 1 kết nối
bỏ qua, trong đó mỗi khối có ......
  -  "->' đại diện cho cạnh.
  -  'bn' là chuẩn hóa batch.
  -  'avgpool-n' là pooling trung bình.
  -  'maxpool-n' là max pooling.
  -  'sepconv-n' là convolution tách biệt.
  -  'dilconv-n' là convolution giãn nở.
  -  'skipconnect" là kết nối bỏ qua.
...... 
định dạng trả về là {Tóm tắt: }Hướng dẫn :
Dữ liệu Tóm tắt 
Mẫu:
Tóm tắt  = Kiến trúc mạng nơ-ron
bao gồm một lớp đầu vào
tiếp theo là 2 khối và 1 kết nối
bỏ qua, trong đó mỗi khối có ......
Dữ liệu  = {"INPUT ->conv3, conv3-
>bn,bn->avgpool3, avgpool3-
>avgpool3, avgpool3->OUTPUT ,
INPUT ->OUTPUT"}
  -  "->' đại diện cho cạnh.
  -  'bn' là chuẩn hóa batch.
  -  'avgpool-n' là pooling trung bình.
  -  'maxpool-n' là max pooling.
  -  'sepconv-n' là convolution tách biệt.
  -  'dilconv-n' là convolution giãn nở.
  -  'skipconnect" là kết nối bỏ qua.
...... 
định dạng trả về là {Dữ liệu Được khôi phục: }Hướng dẫn :
Tóm tắt Dữ liệu Được khôi phục
Dữ liệu
Tóm tắt DữliệuMẫu:
Dữ liệu 
Tóm tắt  DữliệuDữ liệu Được khôi phục
DữliệuTạo sinh
Khôi phục
Tự Giám sát
Dừng Sớm Điểm Số Căn chỉnhHình 2: Chú Thích Tự Giám Sát GPT: Một khung làm việc của mô hình tạo-khôi phục,
trong đó hàm mục tiêu tìm cách tối đa hóa điểm số căn chỉnh giữa dữ liệu gốc và
dữ liệu được khôi phục.

3 Phương pháp
Phương pháp chú thích dữ liệu của chúng tôi bao gồm giai đoạn điều chỉnh một lần và giai đoạn tạo tóm tắt .
Giai đoạn điều chỉnh một lần. Giai đoạn này chủ yếu chịu trách nhiệm tìm mẫu tối ưu t∗được tự
giám sát bởi GPT. Đây là một quá trình lặp tạo ra một bản tóm tắt, khôi phục dữ liệu, và so sánh
các giá trị phản hồi để điều hướng việc điều chỉnh mẫu trong prompt, sau đó được sử dụng cho
vòng tạo sinh tiếp theo.

Quá trình lặp chứa các bước sau. Đầu tiên chúng tôi khởi tạo một cặp đơn giản được gán nhãn bởi con người gồm
dữ liệu x0, tóm tắt s0 như mẫu tốt nhất t∗={x0, s0}, và sau đó tương ứng gán loại vai trò của
{system, assistant, content} cho hướng dẫn, mẫu, dữ liệu hỗ trợ {w, t, x}. Cho lần lặp i, chúng tôi
lấy mẫu một dữ liệu được hỗ trợ xi từ tập hỗ trợ X, sau đó được nối với
mẫu tối ưu hiện tại t∗ và hướng dẫn mặc định wg thành một thông điệp. GPT F(·) chuyển đổi
thông điệp để tạo ra tóm tắt si bằng cách tham khảo hướng dẫn, mẫu hiện tại và dữ liệu:
si← F (xi|ti, wg, θ), (1)
trong đó θ là các tham số của hàm mô hình ngôn ngữ và wg là hướng dẫn tạo ra
một bản tóm tắt. Tại điểm này, chúng tôi có được một tập cặp mới bao gồm dữ liệu và tóm tắt, được ký hiệu là
{xi, si}, trong đó si được tạo ra từ xi.

Xem xét rằng mục đích chính của một bản tóm tắt là nắm bắt ngắn gọn bản chất của một tập dữ liệu, chất lượng
của một bản tóm tắt tự nhiên có thể được suy ra từ khả năng của nó để tái tạo một cách trung thành tập dữ liệu gốc.
Quá trình khôi phục là tái tạo ˆxi từ si bởi cùng một GPT:
ˆxi← F (si|ti, wr, θ), (2)
trong đó θ là các tham số của mô hình ngôn ngữ lớn và wg là hướng dẫn khôi phục
dữ liệu. Và sau đó chúng tôi áp dụng sim(ˆxi, xi) để đo điểm số tương tự giữa dữ liệu được khôi phục và
dữ liệu gốc. Nếu điểm số hiện tại vượt qua giá trị cao nhất được ghi lại trước đây từ các lần lặp, chúng tôi
xem xét cặp dữ liệu-tóm tắt hiện tại { xi,si} như một mẫu tạm thời.

Sử dụng cùng quá trình tạo sinh và khôi phục được đề cập trong 1 2, chúng tôi đánh giá điểm số tương tự trung bình
trên tập xác thực. Nếu điểm số này vẫn cao hơn điểm số xác thực tối đa được quan sát
3

--- TRANG 4 ---
Thuật toán 1 Chú Thích Tự Giám Sát bởi GPT.
1:Khởi tạo: hướng dẫn wg/wr cho tạo sinh/khôi phục , mẫu một lần tối ưu t∗=
{x0, s0}, điểm số tương tự hỗ trợ/xác thực tốt nhất simsup/simval= 0, một tập hỗ trợ Xsup để lấy
mẫu mẫu một lần, một tập xác thực Xval để thử nghiệm hiệu suất mẫu mới.
2:cho lần lặp i←1 đến I thực hiện
3: (1) Lấy mẫu: xi← Xsup
4: (2) Mã hóa: Gửi thông điệp < hướng dẫn, mẫu, dữ liệu được lấy mẫu > đến GPT:
5:
si←GPT (⟨wg, t∗, xi⟩)
6: Nhận phản hồi của tóm tắt si
7: (3) Giải mã: Gửi thông điệp < hướng dẫn, mẫu, tóm tắt được tạo ra > đến GPT:
8:
ˆxi←GPT (⟨wr, t∗, si⟩)
9: Nhận phản hồi của dữ liệu được khôi phục ˆxi.
10: Tính điểm số tương tự giữa dữ liệu được khôi phục và dữ liệu gốc
11:
simsup
i←sim(xi,ˆxi)
12: (4) Cập nhật:
13: nếu simsup
i> simsup thì
14: Tính điểm số tương tự trung bình simval
i trên tập xác thực Xval bằng (2)(3).
15: nếu simval
i> simval thì
16: Thay thế điểm số tương tự tốt nhất với điểm số hiện tại:
simsup←simsup
i;simval←simval
i
17: Cập nhật mẫu tối ưu với dữ liệu hỗ trợ và tóm tắt được tạo ra:
t∗← {xi, si}
18: kết thúc nếu
19: kết thúc nếu
20:kết thúc cho
21:Đầu ra: Trả về mẫu tốt nhất t∗ cho giai đoạn tạo sinh.

trong các lần lặp trước đây, cơ chế tự giám sát cập nhật mẫu tốt nhất t∗ với cặp dữ liệu-tóm tắt hiện tại { xi,si}. Quá trình tiếp tục cho đến khi mẫu hiện tại không thể đạt được điểm số khôi phục cao hơn
so với lần lặp trước đó hoặc khi số lần lặp tối đa được đạt tới. Và mục tiêu tự giám sát của việc cập nhật lặp đi lặp lại ở trên là tìm mẫu tốt nhất
ti để tối đa hóa độ tương tự mong đợi giữa dữ liệu được khôi phục và dữ liệu gốc. Vấn đề tối ưu hóa có thể được chính thức hóa như sau:
t∗= arg max
tExi∼X[sim(ˆxi, xi)], (3)
trong đó sim(·) là chỉ số của hàm tương tự giữa hai dữ liệu chuỗi. Mục tiêu này
giả định rằng độ tương tự sim là một thước đo có ý nghĩa về chất lượng của quá trình khôi phục, và
rằng các giá trị cao hơn của sim tương ứng với việc khôi phục tốt hơn. Và mục tiêu này có một vài yếu tố đáng chú ý
hơn giai đoạn học một lần truyền thống. Không giống như phương pháp tự giám sát thông thường nơi
trọng số mô hình được cập nhật trong quá trình huấn luyện, kỹ thuật của chúng tôi cập nhật mẫu hiện tại thay vào đó.

Giai đoạn tạo tóm tắt. Trong giai đoạn này, GPT nối mẫu tối ưu đã xác định với
hướng dẫn, sử dụng nó như prompt tối ưu để tạo ra các bản tóm tắt ngôn ngữ tự nhiên cho tập dữ liệu tạo sinh:
s← F (x|t∗, wg, θ), (4)
trong đó s là các bản tóm tắt của tập dữ liệu x. Chúng tôi kiểm tra chất lượng tóm tắt bằng cách điều chỉnh các mạng phần thưởng phản hồi của con người khác nhau, và sau đó chúng tôi giới thiệu đánh giá khôi phục nhằm đo lường liệu
bản tóm tắt có thể giải mã các câu cấp cao về dữ liệu gốc hay không. Cụ thể, chúng tôi giả định rằng
khả năng khôi phục bản tóm tắt trung gian trở lại dữ liệu gốc càng mạnh, nó càng chứng thực
tính chuyên nghiệp và độ chính xác của các bản tóm tắt. Ngược lại, khả năng khôi phục yếu hơn ngụ ý mức độ chuyên nghiệp và độ chính xác thấp hơn trong các bản tóm tắt.
4

--- TRANG 5 ---
Giai đoạn đánh giá của quá trình này có hai mặt. Đầu tiên, chúng tôi đánh giá chất lượng của bản tóm tắt bằng
cách sử dụng nhiều mạng phần thưởng phản hồi của con người khác nhau, điều này cung cấp cho chúng tôi cái nhìn sâu sắc toàn diện về tính ứng dụng thực tế và khả năng hiểu được của các bản tóm tắt của chúng tôi. Theo sau điều này, chúng tôi thiết lập
một quá trình đánh giá khôi phục tìm cách đo lường hiệu quả và độ chính xác mà bản tóm tắt
có thể giải mã các câu cấp cao trở lại thành dữ liệu gốc, do đó phục vụ như một chỉ số
của tính chuyên nghiệp và độ chính xác của các bản tóm tắt. Giả định này củng cố niềm tin của chúng tôi rằng mô hình càng có khả năng
kỹ thuật ngược bản tóm tắt trở lại dữ liệu gốc, nó càng khẳng định độ chính xác và tính chuyên nghiệp của các bản tóm tắt. Ngược lại, nếu mô hình thể hiện
thành thạo thấp hơn trong nhiệm vụ phục hồi này, nó gợi ý rằng các bản tóm tắt thiếu một mức độ nhất định của tính chuyên nghiệp và độ chính xác.

4 Thí nghiệm
4.1 Thiết lập Thí nghiệm
Tập dữ liệu Nghiên cứu này sử dụng ba tập dữ liệu khác biệt: Darts-Medium, Darts-Large, và PubMed. Các tập dữ liệu Darts-Medium và Darts-Large bao gồm các mạng kiến trúc nơ-ron, được tạo ra bởi 5
và 7 toán tử tương ứng, với Darts-Large có nhiều nút hơn. Chúng cung cấp một nguồn thông tin phong phú
về thiết kế và hiệu suất của các kiến trúc nơ-ron khác nhau. Chúng tôi cũng đã tích hợp
tập dữ liệu PubMed bao gồm các cấu trúc Isomeric SMILES vào nghiên cứu của chúng tôi. Tập dữ liệu này
đại diện cho một lĩnh vực khác, cung cấp cơ hội để xem xét việc tạo ra các bản tóm tắt cấp cao
cho các cấu trúc hóa học phức tạp. Chúng tôi hết sức cẩn thận để tránh rò rỉ tập kiểm tra và chia dữ liệu cho mỗi giai đoạn để sử dụng. Mỗi tập dữ liệu này đã được chia thành hai phân đoạn cho các giai đoạn khác nhau của thí nghiệm: giai đoạn một lần và giai đoạn tạo sinh. Giai đoạn một lần bao gồm
một tập hỗ trợ và một tập xác thực, mỗi tập chứa 50 mẫu. Những tập này được sử dụng để tìm
mẫu tối ưu từ tập hỗ trợ. Giai đoạn tạo sinh chia dữ liệu bằng phương pháp K-Fold ( K= 5)
thành các tập huấn luyện và kiểm tra. Tập huấn luyện được sử dụng để huấn luyện thêm mô hình và điều chỉnh
cơ chế phần thưởng, trong khi tập kiểm tra được dành riêng để đánh giá chất lượng tóm tắt.

Thiết lập Chúng tôi triển khai một siêu tham số nhiệt độ là 1 để thúc đẩy tính đa dạng trong việc tạo ra tóm tắt
khi đánh giá hiệu suất cơ bản. Ngược lại, trong giai đoạn tạo ra dữ liệu, nhiệt độ được đặt ở không để đảm bảo tính nhất quán và ổn định. Để kiểm tra hiệu suất của các
mô hình ngôn ngữ lớn khác nhau, chúng tôi áp dụng bốn mô hình được sử dụng rộng rãi trong thí nghiệm này, bao gồm phiên bản
3 của GPT: davinci, text-curie-001 và phiên bản 3.5 của GPT: text-davinci-003, gpt-3.5-turbo. Chúng tôi gọi phản hồi thông qua suy luận của APIs chính thức openAI1. Thông tin được khởi tạo được chia thành hướng dẫn, mẫu và dữ liệu truy vấn, tương ứng gọi vai trò của system, assistant và user
trong luồng thông tin. Chúng tôi đặt 10 lần lặp trong mỗi giai đoạn điều chỉnh một lần với độ dài token tối đa được định nghĩa là 350 để tạo ra các bản tóm tắt và 500 để khôi phục dữ liệu từ các bản tóm tắt. Mỗi
prompt đầu vào bao gồm ba phần, một hướng dẫn, một mẫu và một dữ liệu được lấy mẫu. Chúng tôi đưa ra định dạng đầu vào và đầu ra trong hướng dẫn, và định nghĩa ý nghĩa của mỗi ký hiệu có cấu trúc trong dữ liệu.
Phần này tốn 500 token. Đối với mẫu, chúng tôi gán thẻ assistant và content cho dữ liệu và
tóm tắt trong mẫu, để GPT có thể nhận ra rằng đây là thông tin mẫu, và phần này
tốn 3000 token. Để lấy mẫu dữ liệu từ tập hỗ trợ trong giai đoạn một lần, chúng tôi trực tiếp sử dụng
vai trò của user để gửi nó đến GPT. Để làm cho bản tóm tắt được tạo ra đa dạng hơn trong giai đoạn điều chỉnh một lần, chúng tôi đặt siêu tham số nhiệt độ là 1. Trong giai đoạn tạo ra dữ liệu, chúng tôi đặt
nhiệt độ là 0 để giữ ổn định.

4.2 Đánh giá
Đánh giá Tóm tắt. Để đánh giá trực tiếp chất lượng tóm tắt được tạo ra bởi phương pháp của chúng tôi, chúng tôi đã điều chỉnh
nhiều mô hình phần thưởng phản hồi của con người khác nhau như các người đánh giá của chúng tôi. Những mô hình phần thưởng này đã được
công nhận rộng rãi trong tài liệu về hiệu quả của chúng trong việc cung cấp phản hồi đánh giá cho các nhiệm vụ tạo ra ngôn ngữ
1platform.openai.com/docs/models/
5

--- TRANG 6 ---
Bảng 1: Các điểm đánh giá khác nhau ( ±sai số chuẩn) trên ba tập dữ liệu. Hiệu suất của mỗi
mô hình được đánh giá bằng hai loại chỉ số đánh giá.
Mô hìnhĐánh giá Tóm tắt Được tạo ra Đánh giá Dữ liệu Được khôi phục
R1 R2 R3 R4 BLEU ROUGE STS Sim Bert Sim
Darts-Medium
davinci 0.296±0.012 0.302±0.041 0.194±0.016 0.288±0.019 0.195±0.004 0.214±0.007 0.291±0.001 0.263±0.005
text-curie-001 0.243±0.028 0.211±0.013 0.297±0.004 0.342±0.013 0.118±0.004 0.172±0.008 0.310±0.006 0.294±0.009
text-davinci-003 0.532±0.023 0.596±0.028 0.503±0.032 0.582±0.031 0.278±0.006 0.379±0.017 0.772±0.003 0.543±0.025
gpt-3.5-turbo 0.513±0.011 0.642±0.016 0.519±0.015 0.639±0.017 0.482±0.023 0.422±0.004 0.816±0.014 0.691±0.002
Darts-Large
davinci 0.302±0.024 0.294±0.053 0.197±0.023 0.305±0.025 0.194±0.012 0.221±0.017 0.287±0.009 0.268±0.045
text-curie-001 0.252±0.038 0.220±0.023 0.305±0.011 0.370±0.021 0.129±0.014 0.182±0.022 0.314±0.013 0.308±0.019
text-davinci-003 0.509±0.034 0.607±0.021 0.515±0.011 0.580±0.027 0.292±0.005 0.382±0.013 0.781±0.001 0.559±0.009
gpt-3.5-turbo 0.544±0.020 0.672±0.037 0.537±0.021 0.657±0.033 0.505±0.030 0.447±0.009 0.829±0.019 0.715±0.006
PubMed
davinci 0.318±0.017 0.354±0.026 0.216±0.032 0.310±0.031 0.209±0.015 0.228±0.002 0.293±0.002 0.265±0.002
text-curie-001 0.262±0.013 0.230±0.021 0.327±0.018 0.372±0.026 0.138±0.012 0.192±0.001 0.316±0.001 0.310±0.001
text-davinci-003 0.547±0.019 0.611±0.022 0.514±0.036 0.594±0.023 0.571±0.008 0.403±0.001 0.774±0.004 0.571±0.002
gpt-3.5-turbo 0.542±0.022 0.671±0.031 0.547±0.023 0.667±0.012 0.509±0.004 0.457±0.001 0.796±0.001 0.635±0.002

Cụ thể, chúng tôi đã điều chỉnh nhiều mô hình phần thưởng phản hồi của con người khác nhau2345 như các người đánh giá của chúng tôi. Mỗi người đánh giá
đánh giá chất lượng tóm tắt và cung cấp một điểm phần thưởng tương ứng ( R1, R2, R3, R4). Để đảm bảo
ổn định trong phân phối phần thưởng, chúng tôi đã sử dụng một chiến lược xác thực chéo k-fold với giá trị k
đặt ở 5. Giả sử r(x, s|θ) đại diện cho đầu ra vô hướng của mô hình phần thưởng cho dữ liệu x và tóm tắt
s, được tham số hóa bởi θ. Chúng tôi đã thực hiện điều chỉnh trên mỗi mạng phần thưởng được tiền huấn luyện bằng cách tuân theo
các bước được nêu trong [25]:
L=E(x,s0,s1,si)∼D[log(σ(r(x, si|θ))−σ(r(x, s 1−i|θ))], (5)
trong đó i∈ {0,1} và D đại diện cho các tập dữ liệu được gán nhãn bởi con người chứa các phán đoán về
tóm tắt nào, được tạo ra bởi hai mô hình ngôn ngữ lớn, là vượt trội. Phương trình được phân định ở trên
minh họa hàm mất mát chúng tôi đã sử dụng trong quá trình điều chỉnh này. Quá trình phần thưởng tượng trưng
cho các tập dữ liệu được chú thích bởi con người cung cấp phán đoán về sự vượt trội của các bản tóm tắt được tạo ra
bởi hai mô hình ngôn ngữ lớn. Đánh giá kép này không chỉ thêm một mức độ dư thừa mà còn
đảm bảo một đánh giá nghiêm ngặt và toàn diện hơn về các bản tóm tắt được tạo ra.

Đánh giá Khôi phục. Chúng tôi triển khai cả căn chỉnh cấp câu và các chỉ số cấp nhúng
để đánh giá sự khác biệt giữa dữ liệu được khôi phục và dữ liệu gốc.

Đối với đánh giá cấp câu, chúng tôi đã sử dụng điểm BLEU trung bình[ 20] và ROUGE-L[ 17,10].
Cụ thể, chúng tôi sử dụng một phiên bản trung bình được làm mượt của BLEU trong các đánh giá của chúng tôi để chống lại các vấn đề
có thể phát sinh với BLEU khi xử lý các câu ngắn. ROUGE-L, mặt khác, được
dựa trên thống kê Chuỗi Con Chung Dài nhất (LCS), điều này làm cho nó trở thành một công cụ mạnh mẽ để đánh giá
chất lượng của các bản tóm tắt, đặc biệt trong trường hợp của chúng tôi nơi nó được áp dụng cho các đánh giá.

Khi nói đến các chỉ số cấp nhúng, chúng tôi sử dụng nhúng Tương tự Văn bản Ngữ nghĩa (STS) [ 19]
và nhúng Biểu diễn Mã hóa Hai chiều từ Transformers (BERT) [ 6]. Nhúng STS, đặc biệt, cung cấp một thước đo có thể định lượng về sự tương đương ngữ nghĩa giữa
hai mảnh văn bản, điều này lý tưởng để đánh giá sự tương tự ngữ nghĩa giữa dữ liệu gốc và được khôi phục.
Mặt khác, nhúng BERT, xuất phát từ mô hình BERT, cho phép chúng tôi
nắm bắt các đặc trưng ngữ nghĩa và cú pháp tinh tế hơn của các cấu trúc dữ liệu, cung cấp một phân tích toàn diện và sâu sắc hơn về các bản tóm tắt được tạo ra của chúng tôi so với dữ liệu gốc.

4.3 Kết quả Cơ bản
Chúng tôi đã tiến hành thí nghiệm trên ba tập dữ liệu thách thức cao bằng cách sử dụng bốn mô hình khác nhau: davinci,
text-curie-001, text-davinci-003, gpt-3.5-turbo. Đánh giá bao gồm kiểm tra chất lượng tóm tắt bằng
bốn mạng phần thưởng cụ thể và đánh giá khả năng khôi phục dữ liệu bằng điểm số căn chỉnh trên
cả mức câu và mức nhúng.

Đánh giá trên Dữ liệu Khôi phục Đầu tiên chúng tôi tập trung vào đánh giá bản tóm tắt được tạo ra bằng cách sử dụng
bốn điểm số phần thưởng. Những điểm số này đại diện cho hiệu suất của chất lượng tóm tắt được tạo ra
bởi các mô hình phần thưởng phản hồi của con người khác nhau sau khi điều chỉnh. Trên tập dữ liệu Darts-Medium, GPT-
3.5-Turbo vượt trội hơn các mô hình khác với điểm số cao nhất trên tất cả các chỉ số: điểm BLEU
là 0.482±0.023, điểm ROUGE là 0.422±0.004, điểm STS Sim là 0.816±0.014, và điểm Bert
Sim là 0.691±0.002. Mô hình Text-davinci-003 tiếp theo sau đó, trong khi các mô hình Davinci và
Text-curie-001 tụt lại phía sau, với điểm số thấp hơn trên tất cả các thước đo. Xu hướng tương tự được quan sát
trên tập dữ liệu Darts-Large. Một lần nữa, GPT-3.5-Turbo thể hiện hiệu suất vượt trội, đạt được
điểm số cao nhất trong tất cả các danh mục: BLEU ( 0.505±0.030), ROUGE ( 0.447±0.009), STS Sim
(0.829±0.019), và Bert Sim ( 0.715±0.006). Text-davinci-003 duy trì vị trí thứ hai,
trong khi Davinci và Text-curie-001 theo sau với điểm số ít ấn tượng hơn. Trên tập dữ liệu PubMed, mô hình Text-davinci-003 đáng chú ý đã đạt được điểm BLEU cao nhất là 0.571±0.008, vượt qua
các mô hình khác. Tuy nhiên, GPT-3.5-Turbo vẫn dẫn đầu các chỉ số khác, với điểm ROUGE
là 0.457±0.001, điểm STS Sim là 0.796±0.001, và điểm Bert Sim là 0.635±0.002. Davinci
và Text-curie-001 tiếp tục thể hiện hiệu suất kém hơn so với các mô hình khác. Trong khi
hiệu suất có khác nhau phần nào trên các tập dữ liệu khác nhau, GPT-3.5-Turbo nhất quán mang lại
kết quả mạnh nhất trên các chỉ số được đánh giá. Điều này mạnh mẽ chỉ ra khả năng vượt trội của nó trong các nhiệm vụ khôi phục dữ liệu. Khoảng cách hiệu suất được quan sát giữa các mô hình làm nổi bật tầm quan trọng của
việc chọn mô hình transformer phù hợp cho các nhiệm vụ và tập dữ liệu cụ thể, do đó tối ưu hóa sự cân bằng
giữa tài nguyên tính toán và hiệu suất.

Đánh giá về Chất lượng Tóm tắt Các kết quả trong Bảng 1 chứng minh rằng trên tập dữ liệu Darts-Medium,
Text-davinci-003 thể hiện hiệu suất tổng thể tốt nhất về điểm R1 ( 0.532±0.023), R2
(0.596±0.028), và R3 ( 0.503±0.032). Tuy nhiên, GPT-3.5-Turbo đạt được điểm R4
cao nhất ( 0.639±0.017). Các mô hình khác, Davinci và Text-curie-001, có điểm số thấp hơn trên
những chỉ số này. Trên tập dữ liệu Darts-Large, GPT-3.5-Turbo vượt trội hơn các mô hình khác trên
tất cả các chỉ số phần thưởng, với điểm R1 ( 0.544±0.020), R2 ( 0.672±0.037), R3 ( 0.537±0.021), và R4
(0.657±0.033). Text-davinci-003 theo sau sát, trong khi Davinci và Text-curie-001
tụt lại xa hơn về hiệu suất. Đối với tập dữ liệu PubMed, Text-davinci-003 chứng minh hiệu suất vượt trội trong các chỉ số R1 ( 0.547±0.019), R2 ( 0.611±0.022), và R3 ( 0.514±0.036), trong khi
GPT-3.5-Turbo đạt được điểm R4 cao nhất ( 0.667±0.012). Như trong các tập dữ liệu trước đây, Davinci
và Text-curie-001 thể hiện điểm số thấp hơn trên những chỉ số phần thưởng này. Dựa trên hiệu suất,
đánh giá trên các mô hình phần thưởng tiết lộ rằng Text-davinci-003 và GPT-3.5-Turbo nhất quán
vượt trội hơn các mô hình khác về điểm R1, R2, R3, và R4. Những phát hiện này nhấn mạnh
tầm quan trọng của việc chọn các mô hình phần thưởng phù hợp cho các nhiệm vụ và tập dữ liệu cụ thể, vì chúng có tác động đáng kể đến chất lượng của các bản tóm tắt được tạo ra.

So sánh Tập dữ liệu Đồng thời, chúng tôi quan sát rằng phương pháp chú thích mang lại
kết quả khác nhau trên các tập dữ liệu khác nhau. Đầu tiên, rõ ràng là độ phức tạp và đặc điểm của
tập dữ liệu có tác động đáng kể đến hiệu suất của các mô hình. Ví dụ, trên tập dữ liệu Darts-
Medium, trong khi mô hình GPT-3.5-Turbo hoạt động cực kỳ tốt trên các chỉ số khôi phục dữ liệu
(BLEU, ROUGE, STS Sim, và Bert Sim), hiệu suất của nó về các mô hình phần thưởng
(R1, R2, R3, và R4) đã bị vượt qua bởi mô hình Text-davinci-003. Tuy nhiên, tình huống hơi khác trên tập dữ liệu Darts-Large, nơi GPT-3.5-Turbo vượt trội hơn các mô hình khác
trong tất cả các chỉ số được đánh giá. Điều này ngụ ý rằng mô hình đã thành thạo hơn trong việc xử lý độ phức tạp và khối lượng tăng lên của tập dữ liệu này. Mặt khác, hiệu suất của các mô hình trên tập dữ liệu PubMed
trình bày kết quả cân bằng hơn, nơi mô hình Text-davinci-003 vượt qua các mô hình khác về
điểm BLEU và điểm mô hình phần thưởng R1, R2, và R3, trong khi GPT-3.5-Turbo dẫn đầu trong các chỉ số khác.

4.4 Nghiên cứu Loại bỏ
Trong nghiên cứu loại bỏ, chúng tôi chủ yếu nhằm mục đích giải quyết bốn câu hỏi chính cho phương pháp chú thích được đề xuất:
Q1.Mẫu một lần đóng vai trò gì, và có thể đạt được hiệu quả tương tự thông qua phương pháp zero-shot
— tạo ra các bản tóm tắt chỉ với hướng dẫn được thiết kế? Q2.Nếu mẫu hoạt động trong
chú thích tự giám sát, các phương pháp đo lường tương tự khác nhau có tác động gì đến
kết quả của việc điều chỉnh một lần? Q3.Việc khởi tạo mẫu ảnh hưởng như thế nào đến kết quả của
mẫu tối ưu trong giai đoạn điều chỉnh một lần? Q4. Bản tóm tắt được tạo ra có bị ảnh hưởng bởi
các siêu tham số của chính mô hình GPT không?
7

--- TRANG 8 ---
(a) Điểm Phần thưởng trên
Tập dữ liệu Darts-Medium.
(b) Điểm Khôi phục trên
Tập dữ liệu Darts-Medium.
(c) Điểm Phần thưởng trên
Tập dữ liệu PubMed.
(d) Điểm Khôi phục trên
Tập dữ liệu PubMed.
Hình 3: Vai trò của điều hướng mẫu một lần: một phân tích so sánh về phương pháp một lần vs.
zero-shot. Các thanh đỏ chứng minh khởi tạo prompt với việc thêm mẫu một lần,
và các thanh xanh đại diện cho điểm số có điều kiện trên cùng hướng dẫn mà không có mẫu một lần.
Chúng tôi sử dụng gpt-3.5-turbo để tiến hành nghiên cứu loại bỏ trên cả tập dữ liệu Darts và PubMed.

Bảng 3: Tác động của mẫu khởi tạo. Từ góc nhìn của độ phức tạp khởi tạo của dữ liệu và
chất lượng tóm tắt khởi tạo.
Mẫu
Khởi tạoData của 3 toán tử Data của 5 toán tử Data của 7 toán tử
Sum. Cao Sum. Thấp Sum. Cao Sum. Thấp Sum. Cao Sum. Thấp
Lần lặp 4 8 5 8 4 7
Tương tự 0.653 0.652 0.641 0.655 0.652 0.659

A1. Mẫu một lần tối ưu cải thiện hiệu suất chú thích so với tạo sinh zero-
shot có điều kiện trên cùng hướng dẫn. Để trả lời Q1, chúng tôi sử dụng cả phương pháp zero-shot
và một lần để khảo sát các mô hình khác nhau và hai tập dữ liệu đặc thù lĩnh vực khác biệt.
Thiết lập đánh giá tuân theo các bước được minh họa trong 4.2. Hình 3 chứng minh một so sánh toàn diện
về kết quả của hai phương pháp tạo sinh này, bao gồm chất lượng của tạo sinh trực tiếp
và độ chính xác của khôi phục dữ liệu. Chúng tôi quan sát rằng cơ chế một lần (đỏ), tích hợp
lặp mẫu, nhất quán vượt qua hiệu suất của zero-shot (xanh) về
chất lượng chú thích dữ liệu, bất kể chúng tôi đánh giá mô hình phần thưởng hay độ tương tự của
dữ liệu được khôi phục. Hơn nữa, chúng tôi quan sát độ lệch chuẩn dưới các phân chia tập dữ liệu khác nhau bằng cách
thực hiện xác thực chéo trong giai đoạn tạo sinh. Hình hiển thị các thanh lỗi đỏ nhỏ hơn
so với các thanh xanh, minh họa thêm rằng mẫu tăng cường tính ổn định và bền vững
của chất lượng chú thích.

Bảng 2: Tác động của các chỉ số căn chỉnh khác nhau giữa Dữ liệu Được khôi phục và Dữ liệu Gốc cho
Điều chỉnh Một lần. RandS là giá trị trung bình
của điểm phần thưởng và điểm khôi phục.
STS BERT ROUGE BLEU Darts PubMed
R✓ 52.14 58.89
✓ 53.21 60.32
✓ ✓ 61.48 60.05
✓ ✓ ✓ 62.59 65.27
✓ ✓ ✓ ✓ 61.17 65.96
S✓ 21.18 19.04
✓ 26.19 25.20
✓ ✓ 29.44 39.55
✓ ✓ ✓ 45.59 40.04
✓ ✓ ✓ ✓ 44.05 41.38A2. Tăng một cách phù hợp các chỉ số đo lường
có lợi cho chất lượng chú thích.
Quá trình phản hồi của thuật toán lặp được đề xuất của chúng tôi được dựa trên thước đo tương tự
giữa dữ liệu được khôi phục và dữ liệu gốc, và đối với việc lựa chọn các chỉ số tương tự
là cần thiết. Xem xét rằng cả dữ liệu gốc có cấu trúc
và dữ liệu được tạo ra đều là thông tin chuỗi, chúng tôi áp dụng các
sơ đồ được sử dụng rộng rãi nhất để đo lường tương tự chuỗi, từ các phương pháp đo lường cấp câu (BLEU, ROUGE), đến các
kỹ thuật đo lường cấp nhúng (STS, BERT). Quy trình thí nghiệm
cho nghiên cứu loại bỏ này tuân thủ quá trình trước đây. Bảng 2 cung cấp bản ghi của điểm số thử nghiệm bằng cách đặt các
căn chỉnh tương tự khác nhau như giá trị phản hồi. Trong hai hàng đầu tiên của Bảng 2, Ban đầu, chúng tôi đã thử nghiệm
hiệu quả của hai loại hàm tính toán tương tự đơn khác nhau đối với kết quả được chú thích. Hai hàng đầu tiên
của mỗi nhóm trong Bảng 2 chứng minh tình huống này. Bản ghi thí nghiệm gợi ý
rằng cấu trúc câu có tác động tích cực hơi nhiều hơn đến kết quả. Hơn nữa, bằng cách so sánh
hai hàng cuối (hàm chỉ số hỗn hợp) với hai hàng đầu tiên (hàm chỉ số đơn) trong mỗi
nhóm, chúng tôi quan sát rằng dù chúng tôi đo lường trực tiếp với hàm phần thưởng hay gián tiếp đánh giá
khả năng khôi phục của bản tóm tắt, việc tăng cường tính đa dạng của các hàm chỉ số có thể hiệu quả cải thiện chất lượng của dữ liệu được chú thích.

A3. Các mẫu khởi tạo chất lượng cao dẫn đến sự hội tụ nhanh hơn, nhưng điểm số tương tự của
lần lặp cuối cùng thể hiện phương sai thấp. Trong giai đoạn khởi tạo của điều chỉnh một lần, chúng tôi đã quan sát
8

--- TRANG 9 ---
(a) T=0 của text-curie-001 trên
Darts-Medium;
(b) T=1 của text-curie-001
trên Darts-Medium;
(c) T=0 của gpt-3.5-turbo trên
Darts-Medium;
(d) T=1 của gpt-3.5-turbo trên
Darts-Medium;
(e) T=0 của davinci trên
Darts-Medium;
(f) T=1 của davinci trên
Darts-Medium;
(g) T=0 của text-davinci-003
trên Darts-Medium;
(h) T=1 của text-davinci-003
trên Darts-Medium;
(i) T=0 của text-curie-001 trên
PubMed;
(j) T=1 của text-curie-001 trên
PubMed;
(k) T=0 của gpt-3.5-turbo trên
PubMed;
(l) T=1 của gpt-3.5-turbo trên
PubMed;
(m) T=0 của davinci trên
PubMed;
(n) T=1 của davinci trên
PubMed;
(o) T=0 của text-davinci-003
trên PubMed;
(p) T=1 của text-davinci-003
trên PubMed;
Hình 4: Tác động của nhiệt độ mô hình. Các đường đỏ đại diện cho bản ghi lặp của
điểm số tương tự bởi dữ liệu hỗ trợ hiện tại và các đường xanh theo dõi điểm số khôi phục trên tập xác thực. Mũi tên chỉ số lần lặp trung bình để tìm mẫu tối ưu.

trong các bản ghi chạy cho thấy rằng độ dài và chất lượng của các mẫu được khởi tạo có
tác động đến quá trình huấn luyện. Để khảo sát điều này sâu hơn, chúng tôi đã thiết kế ba mẫu của tập dữ liệu Darts
với các mức độ phức tạp khác nhau: tập dữ liệu Darts được tạo ra bởi 3 toán tử, 5 toán tử, và 7
toán tử. Ngoài ra, chúng tôi đã đánh dấu nhân tạo 2 loại chất lượng tóm tắt: Sim. Cao và Sim.
Thấp. Điều này dẫn đến tổng cộng 6 trường hợp. Để đảm bảo điều kiện thí nghiệm nhất quán, mỗi mẫu
được áp dụng 50 lần trong giai đoạn một lần. Hơn nữa, nhiệt độ của GPT được đặt ở 0 để
duy trì tính ổn định của việc tạo ra tóm tắt trong mỗi vòng. Bảng 3 chứng minh ảnh hưởng của
sáu trường hợp của các thiết lập khác nhau đối với khởi tạo. Đường polyline của nhóm màu ấm đại diện cho
quá trình lặp của các bản tóm tắt chất lượng cao. Chúng tôi có thể quan sát từ điều này rằng thời gian hội tụ của nó
tương đối sớm so với mẫu khởi tạo có các bản tóm tắt chất lượng thấp hơn. Điểm số tại
chấm dứt thuật toán rõ ràng cho thấy rằng mẫu tối ưu được tạo ra cuối cùng sở hữu một
điểm số tương tự gần, điều này chỉ ra rằng khởi tạo chủ yếu ảnh hưởng đến số lần lặp nhưng không
áp dụng cho hiệu suất của mẫu tối ưu.

A4. Nhiệt độ của mô hình ảnh hưởng đến tìm kiếm lặp cho mẫu tối ưu. Để
khảo sát toàn diện tác động của các siêu tham số nhiệt độ đối với hiệu suất của các mô hình khác nhau, chúng tôi đã tiến hành một loạt thí nghiệm tập trung vào tính chất hội tụ của
bốn mô hình cơ bản dưới các thiết lập nhiệt độ khác nhau trong các môi trường khác nhau. Để đảm bảo
tính bền vững của các phát hiện của chúng tôi, chúng tôi đã thực hiện mỗi lần chạy 30 lần, theo dõi độ lệch chuẩn của các
giá trị tương tự được tạo ra tại mỗi thể hiện. Hình 4 trình bày kết quả thí nghiệm cho sự
kết hợp của hai tham số nhiệt độ trên bốn mô hình. Những kết quả này tiết lộ một
xu hướng nhất quán trên tất cả các mô hình: khi nhiệt độ được đặt ở 0, quá trình tìm kiếm lặp chấm dứt
sớm ở lần lặp thứ ba hoặc thứ tư. Điều này gợi ý một khuynh hướng hướng tới một không gian khám phá hạn chế, dẫn đến việc tạo ra các đầu ra ít đa dạng hơn. Mặt khác, việc nâng giá trị nhiệt độ
lên 1 trong giai đoạn điều chỉnh một lần đã chứng minh một kết quả thú vị. Mặc dù tốc độ của mỗi lần lặp
được giảm, điều này đã tạo điều kiện cho một mảng rộng hơn các lựa chọn thay thế cho việc tạo ra mẫu
tiếp theo. Điều này chỉ ra sự mở rộng của không gian khám phá, cho phép tạo ra các giải pháp đa dạng và tiềm năng sáng tạo hơn. Chúng tôi cũng quan sát rằng điểm số cuối cùng cao hơn khi
nhiệt độ được đặt ở 1, so với 0. Phát hiện này chỉ ra rằng các mẫu tối ưu
có thể được thu được bằng cách điều chỉnh phù hợp siêu tham số nhiệt độ.

5 Nghiên cứu Trường hợp
Ở đây chúng tôi cung cấp hai trường hợp để trình bày chi tiết cách GPT tự giám sát chú thích dữ liệu có cấu trúc phức tạp trên tập dữ liệu Darts và PubMed. Chúng tôi đầu tiên chứng minh prompt để tạo ra tóm tắt và
khôi phục dữ liệu, và sau đó chúng tôi chứng minh các quy trình của phương pháp chúng tôi.

Prompts Prompt tạo sinh bao gồm ba yếu tố: hướng dẫn mã hóa, mẫu, dữ liệu truy vấn,
trong khi prompt khôi phục chứa hướng dẫn giải mã, mẫu, tóm tắt truy vấn. Giải thích chi tiết
của những hướng dẫn này có thể được tìm thấy trong Phụ lục A.

Quy trình Chúng tôi sử dụng trường hợp 5 trên tập dữ liệu Darts để trình bày chi tiết quy trình của phương pháp chú thích
của chúng tôi.

Bước 1. Khởi tạo một mẫu bao gồm các tế bào và một bản tóm tắt.
Bước 2. Lấy mẫu một tập các tế bào từ tập hỗ trợ.
Bước 3. Nối <hướng dẫn mã hóa, mẫu, tế bào> thành một thông điệp.
Bước 4. Gửi thông điệp đến GPT và nhận phản hồi tóm tắt.
Bước 5. Nối <hướng dẫn giải mã, mẫu, tóm tắt> thành một thông điệp.
Bước 6. Gửi thông điệp đến GPT và nhận phản hồi của các tế bào được khôi phục.
Bước 7. Tính toán độ tương tự giữa các tế bào được khôi phục và tế bào gốc. Nếu nó lớn hơn
bản ghi trước đây, cập nhật điểm số và coi dữ liệu được lấy mẫu và tóm tắt được tạo ra như một mẫu tạm thời.
Bước 8. Đánh giá mẫu tạm thời trên tập xác thực bằng cách lặp lại quá trình trên.
Bước 9. Nếu điểm số trung bình trên tập dữ liệu xác thực cũng vượt qua các bản ghi trước đây, cập nhật điểm số xác thực tốt nhất và thay thế mẫu hiện tại với mẫu tạm thời.
Bước 10. Lặp đi lặp lại Bước 2. đến Bước 9. cho đến khi số lần lặp tối đa được đạt tới.

Prompt Tạo sinh
Mẫu:
"Isomeric SMILE" = {{
C[C@@H](CC1=CC=CC=C1)N
}
}"Tóm tắt" = {
(S)-amphetamine là một 1-phenylpropan-2-amine
có cấu hình S. Nó có vai trò như một
chất độc thần kinh.
}Hướng dẫn:  
        C Methane (CH4)
        CC Ethane (CH3CH3)
        C=C Ethene (CH2CH2)
        C#C Ethyne (CHCH)
        COC Dimethyl ether (CH3OCH3)
        CC=O Acetaldehyde (CH3-CH=O)
        ...
Dữ liệu Hỗ trợ Truy vấn :
C[C@]12CC[C@H]3[C@H]([C@@H]1CCC2=O)CCC4
=C3C=CC(=C4)OSystem
Assistant
UserPrompt Khôi phục
Mẫu:
"Tóm tắt" = {{
(S)-amphetamine là một 1-phenylpropan-2-amine
có cấu hình S. Nó có vai trò như một
chất độc thần kinh.
}
}"Isomeric SMILE" =
{C[C@@H](CC1=CC=CC=C1)N
}
Tóm tắt Được tạo ra Truy vấn :
Isomeric SMILES được cung cấp đại diện cho một hợp chất với
cấu trúc sau: một nguyên tử lưu huỳnh (S) được liên kết với một
nguyên tử carbon (C) mà... gắn với một carbon chiral
([C@H]). Assistant
User
Tóm tắt Được tạo ra
Isomeric SMILES được cung cấp
đại diện cho một hợp chất với cấu trúc
sau: một nguyên tử lưu huỳnh (S) được
liên kết với một nguyên tử carbon (C)
mà... gắn với một carbon chiral
([C@H]). Hướng dẫn:  
        C Methane (CH4)
        CC Ethane (CH3CH3)
        C=C Ethene (CH2CH2)
        C#C Ethyne (CHCH)
        COC Dimethyl ether (CH3OCH3)
        CC=O Acetaldehyde (CH3-CH=O)
        ...SystemDữ liệu Được khôi phục
C [ C @] 1 2 C C [ C @H ] 3 [ C @H ]
( [ C @@H ] 1 C C C 2 =O ) C C C 4
=C 3 C =C C ( =C 4 ) O
Hình 6: Tập dữ liệu PubMed: Một trường hợp của chú thích tạo-khôi phục.
10

--- TRANG 11 ---
Prompt Tạo sinh
Mẫu:
"Tế bào" = {{
"INPUT ->conv3, conv3->bn,bn->avgpool3,
avgpool3->avgpool3, avgpool3->OUTPUT ,
INPUT ->OUTPUT",
}
}"Tóm tắt" = {
Kiến trúc mạng nơ-ron bao gồm một
lớp đầu vào tiếp theo là 2 khối và 1 kết nối
bỏ qua.
}Hướng dẫn:  
  -  "->' đại diện cho cạnh.  
  -  'bn' là chuẩn hóa batch.  
  -  'avgpool-n' là pooling trung bình.  
  -  'maxpool-n' là max pooling.  
  -  'sepconv-n' là convolution tách biệt.  
  -  'dilconv-n' là convolution giãn nở.  
  -  'skipconnect" là kết nối bỏ qua.
Dữ liệu Hỗ trợ Truy vấn :
'INPUT->sepconv33, sepconv33->avgpool331,
avgpool331->2maxpool331, 2maxpool331->bn, bn-
>OUTPUT, INPUT->OUTPUT' System
Assistant
UserPrompt Khôi phục
Mẫu:
"Tóm tắt" = {{
Kiến trúc mạng nơ-ron bao gồm một
lớp đầu vào tiếp theo là 2 khối và 1 kết nối
bỏ qua.
}
}"Tế bào" = {
"INPUT ->conv3, conv3->bn,bn->avgpool3,
avgpool3->avgpool3, avgpool3->OUTPUT ,
INPUT ->OUTPUT",
}
Tóm tắt Được tạo ra Truy vấn :
Mạng nơ-ron này bao gồm một convolution 3x3, tiếp theo là
nhiều lớp có pooling trung bình, max pooling, convolution tách biệt
sâu 3x3, convolution giãn nở 3x3, và các phép toán cộng để kết nối các lớp. Assistant
User
Mạng nơ-ron này bao gồm một stem
với một convolution 3x3, tiếp theo là
nhiều lớp có pooling trung bình,
max pooling, convolution tách biệt
sâu 3x3, convolution giãn nở 3x3,
và các phép toán cộng để kết nối
các lớp.Tóm tắt Được tạo raDữ liệu Được khôi phục
'INPUT->sepconv33, sepconv33-
>avgpool331, avgpool331-
>2maxpool331, 2maxpool332->bn,
bn->OUTPUT, INPUT->OUTPUT'Hướng dẫn:  
  -  "->' đại diện cho cạnh.  
  -  'bn' là chuẩn hóa batch.  
  -  'avgpool-n' là pooling trung bình.  
  -  'maxpool-n' là max pooling.  
  -  'sepconv-n' là convolution tách biệt.  
  -  'dilconv-n' là convolution giãn nở.  
  -  'skipconnect" là kết nối bỏ qua.SystemHình 5: Tập dữ liệu Darts: Một trường hợp của chú thích tạo-khôi phục.

6 Hạn chế
Các ràng buộc được áp đặt bởi giới hạn token hạn chế số lượng mẫu chúng tôi có thể sử dụng, đặt ra một
thách thức đáng kể khi tiến hành thí nghiệm trong khung few-shot. Do đó, có một
sự cân bằng cần thiết giữa số lượng mẫu shot và độ dài của mỗi mẫu.

7 Kết luận
Bài báo này giới thiệu một phương pháp mới có tên GPT tự giám sát chú thích, khai thác
khả năng học một lần của các mô hình GPT để tạo ra các bản tóm tắt ngắn gọn và giảm nhẹ
gánh nặng thời gian và chuyên môn chuyên biệt cần thiết của các nhà chú thích con người khi xử lý dữ liệu có cấu trúc phức tạp, như đồ thị. Phương pháp của chúng tôi bao gồm hai giai đoạn: điều chỉnh một lần và tạo sinh.
Trong giai đoạn điều chỉnh một lần, một tập hỗ trợ và một tập xác thực được tạo ra từ dữ liệu huấn luyện,
một mẫu được chọn từ tập hỗ trợ và được sử dụng như một prompt để tạo ra một bản tóm tắt văn bản bằng cách sử dụng
các mô hình GPT, và cùng mô hình được sử dụng để khôi phục dữ liệu gốc từ bản tóm tắt được tạo ra,
với điểm số căn chỉnh được tính toán cho phản hồi và sửa đổi mẫu tiềm năng. Trong
giai đoạn tạo sinh, phương pháp của chúng tôi sử dụng một mẫu một lần được chọn như một mẫu để tạo ra
các bản tóm tắt cho các tập dữ liệu thách thức. Cả điểm số căn chỉnh cấp câu (BLEU, ROUGE) và cấp cấu trúc (STS,
BERT) giữa dữ liệu gốc và được khôi phục được đánh giá, điều này chứng minh rằng
phương pháp của chúng tôi nhất quán đạt được điểm số đánh giá cạnh tranh. Các kết quả chứng minh hiệu quả của các mô hình GPT trong các nhiệm vụ chú thích dữ liệu-thành-tóm tắt.

Tài liệu tham khảo
[1]Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal,
Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are
few-shot learners. Advances in neural information processing systems , 33:1877–1901, 2020.
[2]Levi Cai, Nathan E McGuire, Roger Hanlon, T Aran Mooney, and Yogesh Girdhar. Semi-
supervised visual tracking of marine animals using autonomous underwater vehicles. Interna-
tional Journal of Computer Vision , pages 1–22, 2023.
[3]Haoyu Chen, Henglin Shi, Xin Liu, Xiaobai Li, and Guoying Zhao. Smg: A micro-gesture
dataset towards spontaneous body gestures for emotional stress state analysis. International
Journal of Computer Vision , 131(6):1346–1366, 2023.
[4]Ying Chen, Yifan Peng, Kai-Wei Chang, Mark Dredze, Aaron M. Cohen, William R. Hersh,
Iain J. Marshall, Aurélie Névéol, Pierre Zweigenbaum, Sijia Liu, Baotian Hu, Fei Li, and
11

--- TRANG 12 ---
Zhiyong Lu. Challenges and opportunities in automated coding of diagnosis and procedure in
healthcare. npj Digital Medicine , 4(1), November 2021.
[5]Jan Deriu, Alvaro Rodrigo, Arantxa Otegi, Guillermo Echegoyen, Sophie Rosset, Eneko Agirre,
and Mark Cieliebak. Survey on evaluation methods for dialogue systems. Springer , 2021.
[6]Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. Bert: Pre-training of
deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805 ,
2018.
[7]Bosheng Ding, Chengwei Qin, Linlin Liu, Lidong Bing, Shafiq Joty, and Boyang Li. Is gpt-3 a
good data annotator? arXiv preprint arXiv:2212.10450 , 2022.
[8]Georgiana Cristina Dobre, Marco Gillies, and Xueni Pan. Immersive machine learning for
social attitude detection in virtual reality narrative games. Springer , 2022.
[9]Li Fei-Fei, Robert Fergus, and Pietro Perona. One-shot learning of object categories. IEEE
transactions on pattern analysis and machine intelligence , 28(4):594–611, 2006.
[10] Kavita Ganesan. Rouge 2.0: Updated and improved measures for evaluation of summarization
tasks. arXiv preprint arXiv:1803.01937 , 2018.
[11] Fabrizio Gilardi, Meysam Alizadeh, and Maël Kubli. Chatgpt outperforms crowd-workers for
text-annotation tasks. arXiv preprint arXiv:2303.15056 , 2023.
[12] Johannes Kopp, Dominik Kellner, Aldi Piroli, and Klaus Dietmayer. Tackling clutter in radar
data–label generation and detection using pointnet++. arXiv preprint arXiv:2303.09530 , 2023.
[13] Tiziano Labruna, Sofia Brenna, Andrea Zaninello, and Bernardo Magnini. Unraveling chatgpt:
A critical analysis of ai-generated goal-oriented dialogues and annotations. arXiv preprint
arXiv:2305.14556 , 2023.
[14] Hamid Laga, Laurent Valentin Jospin, Farid Boussaid, and Mohammed Bennamoun. A survey
on deep learning techniques for stereo-based depth estimation. IEEE transactions on pattern
analysis and machine intelligence , 44(4):1738–1764, 2020.
[15] Brian Lester, Noah Constant, and Rami Al-Rfou. The power of scale for parameter-efficient
prompt tuning. In EMNLP , 2021.
[16] Brian Lester, Noah Constant, and Rami Al-Rfou. Guiding frozen language models with learned
soft prompts. Google AI Blog, 2022.
[17] Chin-Yew Lin. Rouge: A package for automatic evaluation of summaries. In Text summarization
branches out: Proceedings of the ACL-04 workshop , volume 8, 2004.
[18] R Austin McEver, Bowen Zhang, Connor Levenson, ASM Iftekhar, and BS Manjunath. Context-
driven detection of invertebrate species in deep-sea video. International Journal of Computer
Vision , 131(6):1367–1388, 2023.
[19] Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. Efficient estimation of word
representations in vector space. arXiv preprint arXiv:1301.3781 , 2013.
[20] Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. Bleu: a method for automatic
evaluation of machine translation. In Proceedings of the 40th annual meeting of the Association
for Computational Linguistics , pages 311–318, 2002.
[21] Ankur P Parikh, Xuezhi Wang, Sebastian Gehrmann, Manaal Faruqui, Bhuwan Dhingra, Diyi
Yang, and Dipanjan Das. Totto: A controlled table-to-text generation dataset. arXiv preprint
arXiv:2004.14373 , 2020.
[22] N. Polyzotis and M. Zaharia. What can data-centric ai learn from data and ml engineering?
arXiv preprint arXiv:2112.06439 , 2021.
[23] Alec Radford, Karthik Narasimhan, Tim Salimans, Ilya Sutskever, et al. Improving language
understanding by generative pre-training. 2018.
[24] Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al.
Language models are unsupervised multitask learners. OpenAI blog , 1(8):9, 2019.
[25] Nisan Stiennon, Long Ouyang, Jeffrey Wu, Daniel Ziegler, Ryan Lowe, Chelsea V oss, Alec
Radford, Dario Amodei, and Paul F Christiano. Learning to summarize with human feedback.
Advances in Neural Information Processing Systems , 33:3008–3021, 2020.
12

--- TRANG 13 ---
[26] Oriol Vinyals, Charles Blundell, Timothy Lillicrap, Daan Wierstra, et al. Matching networks
for one shot learning. Advances in neural information processing systems , 29, 2016.
[27] Kai-Fu Yang, Cheng Cheng, Shi-Xuan Zhao, Hong-Mei Yan, Xian-Shi Zhang, and Yong-Jie Li.
Learning to adapt to light. International Journal of Computer Vision , pages 1–20, 2023.
[28] Xinyu Yang, Tilo Burghardt, and Majid Mirmehdi. Dynamic curriculum learning for great ape
detection in the wild. International Journal of Computer Vision , pages 1–19, 2023.
[29] Jing Zhang, Min-Yen Kan, Kazunari Sugiyama, and Tat-Seng Chua. Scientific document
processing: challenges for modern learning methods. International Journal on Digital Libraries ,
32(2):1–38, May 2023.
[30] Yiming Zhu, Peixian Zhang, Ehsan-Ul Haq, Pan Hui, and Gareth Tyson. Can chatgpt reproduce
human-generated labels? a study of social computing tasks. arXiv preprint arXiv:2304.10145 ,
2023.
13

--- TRANG 14 ---
A Phụ lục
Ở đây chúng tôi cung cấp hướng dẫn mã hóa và hướng dẫn giải mã để tạo sinh và khôi phục trên
tập dữ liệu darts trong Hình 7.

Hướng dẫn để tạo ra tóm tắt trên tập dữ liệu Darts. 
Bạn là một chuyên gia trong lĩnh vực tìm kiếm kiến trúc nơ-ron. Nhiệm vụ của bạn là tóm tắt các 
kiến trúc nơ-ron dựa trên danh sách các toán tử tính toán. Bản tóm tắt sẽ được sử dụng 
để khôi phục danh sách toán tử gốc và mục tiêu của bạn là cung cấp bản tóm tắt có thể 
tối đa hóa khả năng khôi phục các toán tử. 
Cạnh đồ thị là một biểu diễn danh sách cạnh của một đồ thị có hướng. Đồ thị đại diện cho một 
mạng nơ-ron, nơi các nút là các phép toán, và các cạnh có hướng đại diện cho 
luồng thông tin với ''->''. ''18maxpool312'' có nghĩa là một phép toán max pooling với bộ lọc 3x3 
và stride 1 được áp dụng trong lớp 19. 
Bản tóm tắt của kiến trúc mạng nơ-ron bằng ngôn ngữ tự nhiên nên bao gồm: 
    1. Mỗi khối được cấu thành với những toán tử nào. 
    
    2. Độ sâu của mỗi khối và chiều rộng của các khối song song. 
    
    3. Ưu/nhược điểm của thiết kế dựa trên cấu trúc khối. 
    
Định dạng trả về của bạn là một dict JSON: {Tóm tắt:  }. 
(a) Hướng dẫn mã hóa.

Hướng dẫn để khôi phục dữ liệu trên tập dữ liệu Darts. 
Bạn là một chuyên gia trong lĩnh vực tìm kiếm kiến trúc nơ-ron. 
Nhiệm vụ của bạn được đưa ra một bản tóm tắt về các đặc trưng chính của mạng. 
Kiến trúc được biểu diễn như một danh sách cạnh nơi các nút là các phép toán 
và các cạnh đại diện cho luồng thông tin với '->'. 
Các toán tử ứng viên cho các nút là 
INPUT, OUTPUT, bn, avgpool, maxpool, sepconv, dilconv, và linear. 
Toán tử convolution tách biệt với bộ lọc 3x3 có nghĩa là `'sepconv33'` 
Lớp 2, toán tử max pooling với bộ lọc 3x3 stride 1 có nghĩa là `'2maxpool331'` 
Mục tiêu của bạn là trích xuất thông tin chính từ bản tóm tắt được cung cấp 
để khôi phục các tế bào tối đa hóa khoảng cách giữa các tế bào được khôi phục, 
với định dạng đầu ra là một dict thuần túy chỉ chứa khóa tế bào. 
Định dạng trả về của bạn là một dict json: { Dữ liệu Được khôi phục:  }. 
(b) Hướng dẫn giải mã.

Hình 7: Hướng dẫn cho chú thích trên tập dữ liệu Darts.
14

--- TRANG 15 ---
Và chúng tôi cũng cung cấp hướng dẫn mã hóa và hướng dẫn giải mã để tạo sinh và khôi phục
trên tập dữ liệu PubMed trong Hình 8.

Hướng dẫn để tạo ra tóm tắt trên tập dữ liệu PubMed. 
Bạn là một người chú thích chuyên nghiệp của Isomeric SMILES dựa trên mô tả hợp chất hữu cơ. Trong 
SMILES, các nguyên tử được biểu diễn bởi ký hiệu nguyên tử của chúng. 
Chữ cái thứ hai của ký hiệu nguyên tử hai ký tự phải được nhập bằng chữ thường. Mỗi nguyên tử không phải hydro 
được chỉ định độc lập bởi ký hiệu nguyên tử của nó được bao quanh trong dấu ngoặc vuông, [ ] (ví dụ, [Au] 
hoặc [Fe]). Dấu ngoặc vuông có thể được bỏ qua cho các nguyên tố 
trong "tập con hữu cơ" (B, C, N, O, P, S, F, Cl, Br, và I) nếu số lượng thích hợp của các nguyên tử hydro "ngầm" 
được giả định. Các hydro được gắn "rõ ràng" và các điện tích chính thức luôn được chỉ định bên trong 
dấu ngoặc. Một điện tích chính thức được biểu diễn bởi một trong các ký hiệu + hoặc -. Liên kết đơn, đôi, ba, và 
thơm được biểu diễn bởi các ký hiệu, -, =, #, tương ứng. Liên kết đơn và thơm có thể, 
và thường, được bỏ qua. 
C Methane (CH4) 
CC Ethane (CH3CH3) 
C=C Ethene (CH2CH2) 
C#C Ethyne (CHCH) 
COC Dimethyl ether (CH3OCH3) 
CCO Ethanol (CH3CH2OH) 
CC=O Acetaldehyde (CH3-CH=O) 
C#N Hydrogen Cyanide (HCN) 
[C-]#N Cyanide anion 
Tôi sẽ cung cấp một Isomeric SMILES bạn trả về một bản tóm tắt. 
Định dạng trả về của bạn là một dict json: {Tóm tắt:  } 
(a) Hướng dẫn mã hóa.

Hướng dẫn để khôi phục dữ liệu trên tập dữ liệu PubMed. 
Bạn là một người chú thích chuyên nghiệp của Isomeric SMILES dựa trên mô tả hợp chất hữu cơ. Trong 
SMILES, các nguyên tử được biểu diễn bởi ký hiệu nguyên tử của chúng. 
Chữ cái thứ hai của ký hiệu nguyên tử hai ký tự phải được nhập bằng chữ thường. Mỗi nguyên tử không phải hydro 
được chỉ định độc lập bởi ký hiệu nguyên tử của nó được bao quanh trong dấu ngoặc vuông, [ ] (ví dụ, [Au] 
hoặc [Fe]). Dấu ngoặc vuông có thể được bỏ qua cho các nguyên tố 
trong "tập con hữu cơ" (B, C, N, O, P, S, F, Cl, Br, và I) nếu số lượng thích hợp của các nguyên tử hydro "ngầm" 
được giả định. Các hydro được gắn "rõ ràng" và các điện tích chính thức luôn được chỉ định bên trong 
dấu ngoặc. Một điện tích chính thức được biểu diễn bởi một trong các ký hiệu + hoặc -. Liên kết đơn, đôi, ba, và 
thơm được biểu diễn bởi các ký hiệu, -, =, #, tương ứng. Liên kết đơn và thơm có thể, 
và thường, được bỏ qua. 
C Methane (CH4) 
CC Ethane (CH3CH3) 
C=C Ethene (CH2CH2) 
C#C Ethyne (CHCH) 
COC Dimethyl ether (CH3OCH3) 
CCO Ethanol (CH3CH2OH) 
CC=O Acetaldehyde (CH3-CH=O) 
C#N Hydrogen Cyanide (HCN) 
[C-]#N Cyanide anion 
Tôi sẽ cung cấp một mô tả, bạn trả về một Isomeric SMILES. 
Định dạng trả về là dict json: {Isomeric SMILES: } 
(b) Hướng dẫn giải mã.

Hình 8: Hướng dẫn cho chú thích trên tập dữ liệu PubMed.
15

# 2303.16854.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/annotation/2303.16854.pdf
# Kích thước tệp: 582578 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
AnnoLLM: Làm cho các Mô hình Ngôn ngữ Lớn trở thành Những Người Chú thích Crowdsourced Tốt hơn
Xingwei He1∗, Zhenghao Lin2, Yeyun Gong4, A-Long Jin3, Hang Zhang4,
Chen Lin2, Jian Jiao5, Siu-Ming Yiu1†, Nan Duan4, Weizhu Chen5
1Đại học Hồng Kông,2Đại học Xiamen,
3Đại học Xi'an Jiaotong-Liverpool,4Viện Nghiên cứu Microsoft Châu Á,5Microsoft
hexingwei15@gmail.com ,along.jin@xjtlu.edu.cn ,smyiu@cs.hku.hk ,
zhenghaolin@stu.xmu.edu.cn ,chenlin@xmu.edu.cn ,
{yegong, v-zhhang, jian.jiao, nanduan, wzchen}@microsoft.com

Tóm tắt
Nhiều tác vụ xử lý ngôn ngữ tự nhiên (NLP) dựa vào dữ liệu được gán nhãn để huấn luyện các mô hình học máy có hiệu suất cao. Tuy nhiên, việc chú thích dữ liệu tốn thời gian và tốn kém, đặc biệt khi tác vụ liên quan đến lượng lớn dữ liệu hoặc yêu cầu các lĩnh vực chuyên môn. Gần đây, các mô hình GPT-3.5 series đã thể hiện khả năng few-shot và zero-shot đáng kể trên nhiều tác vụ NLP khác nhau. Trong bài báo này, chúng tôi đầu tiên khẳng định rằng các mô hình ngôn ngữ lớn (LLMs), chẳng hạn như GPT-3.5, có thể đóng vai trò như một người chú thích crowdsourced xuất sắc khi được cung cấp đủ hướng dẫn và các ví dụ minh họa. Theo đó, chúng tôi đề xuất AnnoLLM, một hệ thống chú thích được hỗ trợ bởi LLMs, áp dụng phương pháp hai bước, giải thích-rồi-chú thích. Cụ thể, đầu tiên chúng tôi nhắc LLMs cung cấp các giải thích về lý do tại sao câu trả lời/nhãn chính xác cụ thể được gán cho một ví dụ nhất định. Sau đó, chúng tôi xây dựng prompt few-shot chain-of-thought với giải thích tự tạo và sử dụng nó để chú thích dữ liệu chưa được gán nhãn với LLMs. Kết quả thí nghiệm của chúng tôi trên ba tác vụ, bao gồm đánh giá mức độ liên quan của đầu vào người dùng và từ khóa, BoolQ, và WiC, chứng minh rằng AnnoLLM vượt trội hoặc có hiệu suất ngang bằng với các người chú thích crowdsourced. Hơn nữa, chúng tôi xây dựng bộ dữ liệu truy xuất thông tin dựa trên cuộc hội thoại đầu tiên sử dụng AnnoLLM. Bộ dữ liệu này được thiết kế để tạo điều kiện phát triển các mô hình truy xuất có khả năng truy xuất các tài liệu liên quan cho văn bản hội thoại. Đánh giá của con người đã xác nhận chất lượng cao của bộ dữ liệu.

1 Giới thiệu
Dữ liệu được gán nhãn đề cập đến một bộ dữ liệu đã được chú thích thủ công với các nhãn hoặc danh mục mục tiêu được xác định trước. Nó rất quan trọng để phát triển các mô hình học máy cho nhiều tác vụ NLP, chẳng hạn như phân tích cảm xúc (Socher et al., 2013), dịch máy (Sutskever et al., 2014) và phân giải nghĩa từ (He and Yiu, 2022). Quá trình gán nhãn dữ liệu thường được thực hiện bởi các người chú thích con người theo các hướng dẫn và tiêu chí cụ thể về cách gán nhãn cho từng thể hiện trong bộ dữ liệu. Ví dụ, trong phân tích cảm xúc, mỗi câu hoặc tài liệu có thể được gán nhãn với điểm cực tính như "tích cực", "tiêu cực", hoặc "trung tính". Tuy nhiên, việc tạo ra một bộ dữ liệu lớn với chú thích của con người rất tốn công sức và thời gian, điều này hạn chế sự sẵn có của dữ liệu như vậy trong các tác vụ NLP khác nhau.

Các công trình trước đây đã chỉ ra rằng LLMs, chẳng hạn như GPT-3 (Brown et al., 2020) và PaLM (Chowdhery et al., 2022), đạt được kết quả ấn tượng trong nhiều tác vụ downstream mà không yêu cầu dữ liệu quy mô lớn cụ thể cho tác vụ hoặc điều chỉnh tham số, mà chỉ với một vài ví dụ làm hướng dẫn. OpenAI gần đây đã ra mắt các mô hình GPT-3.5 series, các phiên bản nâng cấp của GPT-3. Ngay sau đó, OpenAI cũng đã công bố ChatGPT, một phiên bản được tinh chỉnh khác của GPT-3.5, đã thu hút sự chú ý đáng kể trên toàn cầu kể từ khi ra mắt.

Việc tăng cường dữ liệu được gán nhãn thủ công với dữ liệu pseudo-labeled từ GPT-3 rất hữu ích cho nhiều tác vụ NLP, đặc biệt là khi ngân sách gán nhãn bị hạn chế (Wang et al., 2021). Tuy nhiên, chất lượng dữ liệu được gán nhãn của GPT-3 vẫn còn kém hơn so với dữ liệu được gán nhãn thủ công. Xem xét khả năng zero/few-shot đáng chú ý của các mô hình GPT-3.5, chúng tôi đặt ra một câu hỏi thiết yếu và quan trọng: Liệu GPT-3.5 có thể thay thế các người chú thích crowdsourced?

Trước khi trả lời câu hỏi này, hãy xem xét quá trình chú thích dữ liệu crowdsourced. Đầu tiên, chúng ta cần cung cấp cho các người chú thích một định nghĩa cụ thể về tác vụ. Sau đó, đối với các tác vụ phân loại, chúng ta cần cho các người chú thích biết ý nghĩa cụ thể của từng danh mục. Cuối cùng, chúng ta cần cung cấp cho các người chú thích một vài ví dụ đã được chú thích làm tài liệu tham khảo. Một cách tự nhiên, chúng ta có thể hướng dẫn GPT-3.5 chú thích dữ liệu bằng cùng một phương pháp như với các người chú thích con người bằng cách cung cấp các định nghĩa tác vụ và các mẫu ví dụ. Hơn nữa, chúng tôi phát hiện rằng yêu cầu LLMs cung cấp lý luận đằng sau nhãn chính xác cho một ví dụ cụ thể có thể khuyến khích LLMs tạo ra các giải thích chất lượng cao. Dựa trên điều này, chúng tôi tạo prompt few-shot chain-of-thought (COT) (Wei et al., 2022) với các giải thích tự tạo để chú thích dữ liệu. Chúng tôi gọi phương pháp này là giải thích-rồi-chú thích, điều này cải thiện thêm chất lượng chú thích.

Chúng tôi tóm tắt các đóng góp của mình như sau: (1) Chúng tôi đề xuất AnnoLLM, một hệ thống Chú thích được hỗ trợ bởi Mô hình Ngôn ngữ Lớn, dựa trên giải thích-rồi-chú thích và có tiềm năng thay thế các người chú thích crowdsourced để chú thích dữ liệu. (2) Kết quả của chúng tôi trên ba bộ dữ liệu xác minh tính khả thi của việc thay thế các người chú thích crowdsourced bằng GPT-3.5, trong đó nó vượt trội hoặc ngang bằng với các người chú thích crowdsourced. (3) Hơn nữa, AnnoLLM không giới hạn ở việc chú thích dữ liệu phân loại, và chúng tôi tạo ra bộ dữ liệu truy xuất thông tin dựa trên cuộc hội thoại (ConIR) đầu tiên sử dụng AnnoLLM. Thông qua đánh giá nghiêm ngặt của con người, bộ dữ liệu này thể hiện chất lượng cao về tính trôi chảy, sự liên quan, và tính nhất quán thực tế.

--- TRANG 2 ---

2 Phương pháp
Việc cung cấp hướng dẫn chi tiết là rất quan trọng đối với các nhân viên crowdsourced để chú thích dữ liệu, vì nó giúp họ hiểu rõ hơn về yêu cầu tác vụ và tiêu chuẩn chú thích, cuối cùng cải thiện chất lượng và độ chính xác của dữ liệu được chú thích. Các hướng dẫn cho mỗi tác vụ chủ yếu bao gồm ba phần: mô tả tác vụ, định nghĩa danh mục, và các ví dụ minh họa.

Được thúc đẩy bởi hướng dẫn cho các người chú thích con người, chúng tôi sẽ giới thiệu cách chuyển đổi GPT-3.5 thành một người chú thích dữ liệu zero-shot bằng cách cung cấp hướng dẫn về mô tả tác vụ và định nghĩa danh mục trong Phần 2.1. Sau đó, chúng tôi sẽ chỉ ra cách chuyển đổi GPT-3.5 thành một người chú thích dữ liệu few-shot bằng cách sử dụng các ví dụ minh họa trong Phần 2.2. Để dễ hiểu hơn, chúng tôi đã cung cấp một biểu diễn trực quan về chú thích crowdsourcing và AnnoLLM trong Hình 1. Cuối cùng, trong Phần 2.3, chúng tôi sẽ chứng minh việc sử dụng AnnoLLM để xây dựng bộ dữ liệu truy xuất thông tin dựa trên cuộc hội thoại.

2.1 GPT-3.5 như một Người chú thích Dữ liệu Zero-shot
Trong thiết lập zero-shot, chúng ta chỉ cung cấp cho các người chú thích mô tả tác vụ và định nghĩa danh mục. Mô tả tác vụ bao gồm thông tin về định nghĩa và mục đích của tác vụ. Định nghĩa danh mục cung cấp các định nghĩa rõ ràng cho từng danh mục, để các nhân viên crowd có thể hiểu ý nghĩa và tiêu chuẩn của từng danh mục. Tương tự, chúng ta cung cấp cho GPT-3.5 mô tả tác vụ và định nghĩa danh mục, cho phép nó hoạt động như một người chú thích dữ liệu zero-shot. Chúng tôi trình bày các prompt zero-shot cho GPT-3.5 về các tác vụ đánh giá mức độ liên quan của truy vấn người dùng và từ khóa (QK), WiC, và BoolQ trong Bảng 12, 13, và 14, tương ứng.

2.2 GPT-3.5 như một Người chú thích Dữ liệu Few-shot
Việc cung cấp các mẫu được gán nhãn cho từng danh mục có thể giúp các người chú thích hiểu rõ hơn cách chú thích dữ liệu một cách chính xác. Tương tự, chúng ta cũng có thể cung cấp các ví dụ minh họa cho GPT-3.5, cho phép nó đóng vai trò như một người chú thích few-shot. Chúng tôi chỉ ra các prompt few-shot cho GPT-3.5 về các tác vụ QK, WiC, và BoolQ trong Bảng 15, 16, và 17, tương ứng.

Nghiên cứu gần đây (Wei et al., 2022) đã phát hiện rằng việc thêm các lý luận được viết bởi con người vào các ví dụ minh họa, được gọi là chain-of-thought (CoT), có thể khơi gợi khả năng suy luận của LLMs, do đó đạt được cải thiện trong các tác vụ suy luận. Trong bài báo này, chúng tôi phát hiện rằng GPT-3.5 thành thạo trong việc tạo ra các giải thích hợp lý cho các ví dụ minh họa. Trong phần tiếp theo, chúng tôi sẽ giới thiệu cách tạo ra các giải thích với GPT-3.5, và sau đó tạo các prompt few-shot CoT với các giải thích được tạo ra.

Tạo ra Giải thích với GPT-3.5. Trong bước này, chúng tôi mô phỏng quá trình suy luận của con người để thúc đẩy GPT-3.5 giải thích các ví dụ được chú thích. Cụ thể, chúng tôi trình bày mô tả tác vụ, ví dụ cụ thể, và các nhãn đúng tương ứng cho GPT-3.5, và sau đó yêu cầu nó giải thích tại sao nhãn đã cho phù hợp với ví dụ đó. Bằng cách này, GPT-3.5 sẽ tạo ra các giải thích hợp lý. Đối với tác vụ QK, chúng tôi chỉ ra cách sử dụng GPT-3.5 để giải thích tại sao nhãn giữa truy vấn người dùng "google data studio sharepoint" và từ khóa "sharepoint migration tool file share" là "Bad" trong Bảng 8 ở Phụ lục A. Vui lòng tham khảo Bảng 9 và Bảng 10 để biết cách tạo ra giải thích cho các ví dụ minh họa của WiC và BoolQ.

Tạo Prompt Few-shot CoT. Chúng tôi xây dựng prompt few-shot CoT bằng cách sử dụng các giải thích được tạo ra bởi GPT-3.5. Chúng tôi chỉ ra các prompt few-shot CoT về các tác vụ QK, WiC, và BoolQ trong Bảng 18, 19, và 20 ở Phụ lục D, tương ứng.

2.3 GPT-3.5 như một Người tạo Dữ liệu Few-shot
AnnoLLM không giới hạn ở việc gán nhãn dữ liệu phân loại. Tiếp theo, chúng tôi sẽ giới thiệu cách chúng tôi sử dụng AnnoLLM để xây dựng bộ dữ liệu truy xuất thông tin dựa trên cuộc hội thoại. Bộ dữ liệu này sẽ tạo điều kiện cho việc nghiên cứu và xây dựng các mô hình truy xuất dựa trên cuộc hội thoại.

Gần đây, ChatGPT, như một chatbot trí tuệ nhân tạo tổng quát, đã thu hút sự chú ý rộng rãi, dẫn đến sự xuất hiện của nhiều nhu cầu truy xuất thông tin dưới dạng cuộc hội thoại. Cụ thể, trong một cuộc hội thoại, người dùng có thể đặt câu hỏi vượt quá phạm vi kiến thức của ChatGPT, yêu cầu chúng ta truy xuất tài liệu liên quan từ các cơ sở kiến thức bên ngoài. Các bộ dữ liệu truy xuất thông tin truyền thống thường bao gồm các truy vấn q và các đoạn văn tích cực p, được ký hiệu là D={(q, p)}. Chúng tôi phát hiện rằng các mô hình truy xuất được huấn luyện trên các bộ dữ liệu truyền thống hoạt động kém trên tác vụ truy xuất dựa trên cuộc hội thoại (vui lòng tham khảo Phần 4 để biết thêm chi tiết). Điều này minh họa sự cần thiết của việc xây dựng các bộ dữ liệu truy xuất dựa trên cuộc hội thoại. Do đó, chúng tôi đề xuất tạo ra một bộ dữ liệu truy xuất thông tin dựa trên cuộc hội thoại.

Truy xuất thông tin dựa trên cuộc hội thoại nhằm mục đích truy xuất các đoạn văn liên quan từ một kho dữ liệu lớn cho các cuộc hội thoại. Việc tạo ra các bộ dữ liệu cho tác vụ này một cách thủ công là không đơn giản. Một ý tưởng trực quan là sử dụng ChatGPT để tạo ra một cuộc hội thoại nhiều lượt c dựa trên truy vấn q và đoạn văn tích cực p tương ứng, xây dựng một bộ dữ liệu cuộc hội thoại, {(c, p)}. Tuy nhiên, chúng tôi đã phát hiện rằng phương pháp này dẫn đến một bộ dữ liệu trong đó một phần lớn của cuộc hội thoại c được sao chép trực tiếp từ p. Điều này không mong muốn vì việc tìm p liên quan đến c trở nên dễ dàng dựa trên sự trùng lặp từ.

Để giải quyết vấn đề này, trước tiên chúng tôi sử dụng ChatGPT để làm phong phú đoạn văn p đã cho, thu được p′ (xem Bảng 27). Sau đó, chúng tôi tạo ra cuộc hội thoại c dựa trên đoạn văn mở rộng p′ và truy vấn q đã cho (xem Bảng 28). Đoạn văn mở rộng p′ thường chứa không chỉ thông tin từ đoạn văn gốc p mà còn một số thông tin liên quan chi tiết hơn, đồng thời giảm sự trùng lặp từ với đoạn văn gốc. Theo cách này, cuộc hội thoại được tạo ra c có thể tránh có một lượng lớn đoạn văn bản giống hệt nhau với đoạn văn gốc p. Tuy nhiên, vì đoạn văn mở rộng p′ chứa thông tin vượt quá đoạn văn gốc p, điều này có thể dẫn đến mức độ liên quan tương đối thấp giữa cuộc hội thoại được tạo ra c và đoạn văn gốc p. Nói cách khác, đoạn văn gốc p có thể không phải là đoạn văn tích cực cho cuộc hội thoại được tạo ra c. Do đó, cần thiết phải lọc bỏ trường hợp cuộc hội thoại c có mức độ liên quan thấp với đoạn văn gốc p. Do khả năng chú thích dữ liệu có thể so sánh của AnnoLLM được đề xuất của chúng tôi, chúng tôi tự nhiên sử dụng AnnoLLM để đánh giá xem cuộc hội thoại được tạo ra c và đoạn văn gốc p có liên quan hay không (xem Bảng 29), và loại bỏ các cặp dữ liệu không liên quan, tạo ra bộ dữ liệu truy xuất thông tin dựa trên cuộc hội thoại.

--- TRANG 3 ---

3 Thí nghiệm về Chú thích Dữ liệu

3.1 Thiết lập Thí nghiệm
Bộ dữ liệu. Chúng tôi đánh giá AnnoLLM trên ba tác vụ khác nhau: QK, BoolQ, và WiC. Thống kê cơ bản của các bộ dữ liệu này được hiển thị trong Bảng 1. Tác vụ QK nhằm mục đích đánh giá xem truy vấn đầu vào của người dùng có liên quan đến các từ khóa đã cho hay không. BoolQ (Boolean Questions) (Clark et al., 2019) là một tác vụ trả lời câu hỏi. Trong tác vụ này, mỗi ví dụ bao gồm một đoạn văn ngắn và một câu hỏi có/không liên quan đến đoạn văn. Tác vụ WiC (Word-in-Context) (Pilehvar and Camacho-Collados, 2019) liên quan đến việc phân giải nghĩa từ bằng cách phân loại các cặp câu. Mục tiêu là xác định xem từ mục tiêu có cùng nghĩa trong cả hai câu hay không.

Chi tiết Triển khai. Chúng tôi sử dụng ChatGPT (gpt-3.5-turbo) để tạo ra giải thích cho các ví dụ minh họa và triển khai AnnoLLM với text-davinci-003 (một mô hình GPT-3.5 mạnh mẽ). Trong quá trình tạo ra, chúng tôi đặt nhiệt độ t= 0 cho text-davinci-003. Vì tất cả các tác vụ đều liên quan đến phân loại nhị phân, độ chính xác được sử dụng để đánh giá.

Hiệu suất Con người. Để đánh giá hiệu suất con người trên QK, chúng tôi sử dụng UHRS, một nền tảng crowdsourcing, để chú thích dữ liệu. Trước khi chú thích, chúng tôi cung cấp mô tả tác vụ, định nghĩa danh mục, và các ví dụ được chú thích cho các người chú thích. Nếu kết quả chú thích của ba nhân viên nhất quán, kết quả này sẽ được coi là nhãn được chú thích. Ngược lại, các người chú thích bổ sung sẽ tiếp tục chú thích trường hợp dữ liệu này cho đến khi ba người chú thích có kết quả chú thích nhất quán. Chúng tôi yêu cầu các người chú thích crowdsourced chú thích tất cả các tập phát triển và kiểm tra. BoolQ và WiC là hai trong số những bộ dữ liệu thách thức nhất trong superGLUE (Wang et al., 2019). Đối với BoolQ, ba tác giả đã gán nhãn 110 ví dụ được chọn ngẫu nhiên, với hiệu suất con người đạt 89%. Đối với WiC, Pilehvar và Camacho-Collados (2019) đã chọn bốn nhóm gồm 100 trường hợp kiểm tra, và gán mỗi nhóm cho một người chú thích, đạt hiệu suất con người là 80%.

3.2 Kết quả Thí nghiệm
Bảng 2 hiển thị kết quả thí nghiệm của chúng tôi trên các tập phát triển và kiểm tra QK. Đáng ngạc nhiên, GPT-3.5 (text-davinci-003) hoạt động kém hơn trong thiết lập few-shot so với thiết lập zero-shot trong tác vụ này. Fu và Khot (2022) suy đoán rằng việc điều chỉnh hướng dẫn trên GPT-3.5 có thể giảm khả năng học trong ngữ cảnh của nó nhưng tăng khả năng zero-shot. Mặt khác, AnnoLLM (text-davinci-003 + 4-shot CoT) vượt trội hơn các đối tác của nó trong thiết lập zero-shot và few-shot khoảng 6 và 8 điểm, tương ứng. Ấn tượng hơn, nó thậm chí vượt trội hơn các người chú thích crowdsourced.

Bảng 3 trình bày kết quả thí nghiệm của chúng tôi trên WiC, từ đó chúng tôi cũng thấy rằng AnnoLLM (text-davinci-003 + 8-shot CoT) vượt trội hơn đối tác few-shot của nó một cách đáng kể. Tuy nhiên, vẫn còn một khoảng cách đáng kể giữa AnnoLLM và các người chú thích crowdsourced. Điều này có thể được cho là do tính phức tạp vốn có của tác vụ, vì ngay cả các mô hình được giám sát tốt nhất vẫn thể hiện khoảng cách đáng kể so với hiệu suất con người.

Như được hiển thị trong Bảng 4, AnnoLLM (text-davinci-003+8-shot CoT) vượt trội hơn các người chú thích con người và có thể so sánh với các mô hình được giám sát trên BoolQ, nhưng không thể hiện cải thiện đáng kể so với phương pháp few-shot. Tuy nhiên, điều này không có nghĩa là CoT với giải thích được tạo ra không hữu ích cho tác vụ này. Phần 3.4 cho thấy rằng AnnoLLM với CoT thể hiện tính ổn định tốt hơn trên các prompt khác nhau, trong khi đối tác của nó với thiết lập few-shot rất nhạy cảm với các mẫu.

Nhìn chung, AnnoLLM vượt trội hoặc ngang bằng với hiệu suất con người trong ba tác vụ, chứng minh tiềm năng của nó để thay thế các người chú thích crowdsourced. AnnoLLM khác với các phương pháp trước đây (Wei et al., 2022; Wang et al., 2022) ở hai khía cạnh: (1) Chúng tôi sử dụng các giải thích được tạo ra bởi LLMs thay vì những giải thích được viết bởi con người. (2) Chúng tôi đã chỉ ra, lần đầu tiên, rằng phương pháp CoT có hiệu quả trong các tác vụ vượt quá các tác vụ suy luận điển hình.

3.3 Nghiên cứu Ablation
Trong phần này, chúng tôi tiến hành một thí nghiệm để so sánh tác động của các phương pháp tạo ra giải thích khác nhau đối với hiệu suất của AnnoLLM.

Đầu tiên, chúng tôi muốn điều tra xem việc sử dụng nhãn chính xác có hữu ích cho việc tạo ra giải thích cho các ví dụ minh họa hay không. Để trả lời điều này, chúng tôi thúc đẩy LLMs tạo ra giải thích bằng cách sử dụng các prompt có và không có nhãn chính xác. Cụ thể, chúng tôi thay thế câu cuối của prompt trong Bảng 8 Briefly explain why the relevance is "Bad" bằng Briefly explain the relevance between the keyword and query trong Bảng 11. Từ Bảng 5, chúng tôi phát hiện rằng việc không sử dụng nhãn đúng khi tạo ra giải thích dẫn đến giảm hiệu suất của AnnoLLM khoảng 3 điểm trên tập kiểm tra QK (hàng 4 so với hàng 1). Điều này là do mô hình có thể tạo ra giải thích cho các câu trả lời không chính xác mà không có hướng dẫn của nhãn chính xác.

Trong Bảng 8, chúng tôi phát hiện rằng LLMs ban đầu tiết lộ câu trả lời đúng, và sau đó cung cấp giải thích cho nó. Điều này khác với công trình trước đây (Wei et al., 2022), nơi LLMs được nhắc để đưa ra giải thích trước khi đưa ra câu trả lời. Do đó, chúng tôi loại bỏ câu đầu tiên với nhãn từ các giải thích được tạo ra (văn bản được gạch chân trong Bảng 18). Tuy nhiên, sự thay đổi này không dẫn đến bất kỳ cải thiện nào (hàng 2 so với hàng 1). Chúng tôi suy đoán rằng điều này có thể được cho là do sự khác biệt giữa tác vụ của chúng tôi và các tác vụ suy luận truyền thống. Ngoài ra, chúng tôi loại bỏ câu cuối chứa câu trả lời cho các ví dụ minh họa (văn bản in nghiêng trong Bảng 18), nhưng nó không có tác động quá nhiều đến hiệu suất (hàng 3 so với hàng 1). Đó là bởi vì các giải thích được tạo ra đã chứa các câu trả lời đúng. Tuy nhiên, để phù hợp với định dạng được sử dụng trong công trình trước đây (Wei et al., 2022), chúng tôi vẫn thêm nhãn chính xác vào các giải thích được tạo ra.

3.4 Phân tích và Thảo luận thêm
Phân tích Tính nhất quán của Giải thích được Tạo ra. Trong nghiên cứu ablation, chúng tôi phát hiện rằng hiệu suất của AnnoLLM phụ thuộc rất nhiều vào các giải thích được tạo ra. Điều này dẫn đến một câu hỏi tự nhiên: Liệu các giải thích được tạo ra bởi ChatGPT có đủ nhất quán cho cùng một mẫu minh họa không? Để trả lời điều này, chúng tôi tạo ra năm giải thích cho mỗi mẫu, và thu được năm prompt few-shot CoT khác nhau. Như được hiển thị trong Hình 2 (a), những prompt few-shot CoT khác nhau này mang lại hiệu suất tương tự trong các tác vụ QK, WiC, và BoolQ. Điều này cho thấy rằng chất lượng của các giải thích được tạo ra bởi ChatGPT đủ nhất quán.

Phân tích Tính ổn định của Giải thích được Tạo ra. Hình 2 (a) cho thấy rằng AnnoLLM với các prompt few-shot CoT vượt trội đáng kể so với đối tác của nó với thiết lập few-shot trên QK và WiC. Tuy nhiên, sự cải thiện khá khiêm tốn trên BoolQ, nơi nó thường ít hơn 0.5. Điều này không có nghĩa là AnnoLLM với các prompt few-shot CoT không có tác dụng đối với BoolQ. Để phân tích thêm điều này, chúng tôi thực hiện các sửa đổi nhỏ đối với các prompt hiện có cho BoolQ để thu được ba prompt few-shot CoT và few-shot (tham khảo Phụ lục E để biết chi tiết). Hình 2 (b) cho thấy rằng phương pháp few-shot rất nhạy cảm với các mẫu. Ngay cả với những sửa đổi nhỏ đối với các mẫu, hiệu suất thí nghiệm giảm từ khoảng 89 xuống dưới 80 điểm. Ngược lại, AnnoLLM với các prompt few-shot CoT chịu ít tổn thất hiệu suất hơn, vượt trội hơn đối tác của nó với các mẫu few-shot khoảng 4 điểm. Tóm lại, thiết lập few-shot khó tính hơn về các mẫu, trong khi few-shot CoT thể hiện tính ổn định tốt hơn trên các mẫu khác nhau.

4 Thí nghiệm về Tạo ra Dữ liệu
Bộ dữ liệu. Chúng tôi xây dựng bộ dữ liệu truy xuất thông tin dựa trên cuộc hội thoại (ConIR) dựa trên bộ dữ liệu xếp hạng đoạn văn MS-MARCO (Bajaj et al., 2016). Kích thước của các tập huấn luyện và kiểm tra cho ConIR lần lượt là 71,557 và 3,000.

Chi tiết Triển khai. Vì ChatGPT được tối ưu hóa cho trò chuyện, chúng tôi sử dụng nó để tạo ra ConIR, cụ thể là sử dụng nó để làm phong phú đoạn văn, tạo ra và lọc bỏ các cuộc hội thoại không liên quan trong Phụ lục F. Theo công trình trước đây (Qu et al., 2021), chúng tôi sử dụng MRR@10 và Recall of top-k (R@k) để đánh giá hiệu suất truy xuất trên các mô hình khác nhau.

Hiệu suất Zero-shot. Chúng tôi huấn luyện hai mô hình truy xuất dày đặc điển hình, DPR (Karpukhin et al., 2020) (được khởi tạo với DistilBERT (Sanh et al., 2019)) và PROD (Lin et al., 2023), trên MS-MARCO, và sau đó đánh giá chúng trên tập kiểm tra của ConIR. Đáng chú ý, cả hai mô hình đều thể hiện hiệu suất kém trên ConIR, như được chứng minh trong Bảng 6. Điều này cho thấy rằng các mô hình truy xuất dày đặc được huấn luyện trên các bộ dữ liệu truyền thống không thể áp dụng trực tiếp cho truy xuất thông tin dựa trên cuộc hội thoại.

Hiệu suất Trong-miền. Như được hiển thị trong Bảng 6, DPR được tinh chỉnh trên tập huấn luyện của ConIR hoạt động tốt hơn nhiều so với đối tác zero-shot của nó, làm nổi bật sự cần thiết của bộ dữ liệu ConIR.

Đánh giá Con người. Chúng tôi chọn ngẫu nhiên 100 cuộc hội thoại được tạo ra và các đoạn văn được ghép đôi của chúng. Ba người chú thích được yêu cầu đánh giá tính trôi chảy của cuộc hội thoại trên thang điểm Likert 5 điểm từ 1 (không trôi chảy) đến 5 (cực kỳ trôi chảy), và sự liên quan và tính nhất quán thực tế của chúng với các đoạn văn được ghép đôi trên thang điểm Likert 3 điểm. Bảng 7 cho thấy rằng các cuộc hội thoại của ConIR thể hiện tính trôi chảy đáng chú ý, hiển thị mối tương quan mạnh mẽ với các đoạn văn được ghép đôi về mặt liên quan và tính nhất quán thực tế. Thỏa thuận giữa các người chú thích được đo bằng Fleiss' kappa (Fleiss, 1971) là 0.55, ngụ ý thỏa thuận ở mức độ vừa phải (Landis and Koch, 1977). Vui lòng tham khảo Phụ lục G để biết thêm chi tiết.

--- TRANG 4 ---

5 Công trình Liên quan
Mô hình Ngôn ngữ Quy mô Lớn. GPT (Generative Pre-trained Transformer) là một họ các mô hình ngôn ngữ được phát triển bởi OpenAI, được thiết kế để tạo ra văn bản ngôn ngữ tự nhiên giống con người. Các mô hình GPT dựa trên kiến trúc Transformer (Vaswani et al., 2017), được tiền huấn luyện trên một kho dữ liệu văn bản khổng lồ bằng cách dự đoán token tiếp theo dựa trên ngữ cảnh trước đó. Qua nhiều năm, OpenAI đã liên tục tăng tham số và dữ liệu huấn luyện của các mô hình của mình, và đã phát hành GPT (Radford, 2018), GPT-2 (Radford et al., 2019), và GPT-3 (Brown et al., 2020) từ 2018 đến 2020. Một tính năng độc đáo của GPT-3 là học trong ngữ cảnh, nơi người ta có thể áp dụng nó cho các tác vụ khác nhau bằng cách đơn giản cung cấp các minh chứng few-shot mà không cần bất kỳ tinh chỉnh nào. Hơn nữa, OpenAI đã tinh chỉnh GPT-3 trên dữ liệu mã hoặc dữ liệu hướng dẫn, phát hành Codex (Chen et al., 2021) và InstructGPT (Ouyang et al., 2022), tương ứng. Gần đây, OpenAI đã phát hành các mô hình GPT-3.5 series, bao gồm text-davinci-003 và ChatGPT, bằng cách huấn luyện trên dữ liệu văn bản và mã, sau đó điều chỉnh với các hướng dẫn được giám sát và học tăng cường với phản hồi của con người. Nghiên cứu gần đây đã chỉ ra rằng GPT-3.5 có khả năng học few-shot và zero-shot mạnh mẽ trên các tác vụ NLP khác nhau (Jiao et al., 2023; Wei et al., 2023).

Trong bài báo này, chúng tôi đầu tiên đề xuất rằng chúng ta có thể dễ dàng thay đổi GPT-3.5 thành một người chú thích dữ liệu tốt cho một tác vụ cụ thể bằng cách cung cấp các hướng dẫn chú thích chi tiết tương tự như các người chú thích con người.

Dữ liệu Pseudo Annotated. Việc tạo ra dữ liệu pseudo-annotated thường được sử dụng để tạo ra dữ liệu được gán nhãn cho một tác vụ cụ thể khi có một lượng dữ liệu được chú thích hạn chế. Back-translation liên quan đến việc dịch một câu ngôn ngữ đích trở lại ngôn ngữ nguồn, được đề xuất đầu tiên để cải thiện các mô hình dịch máy thần kinh với dữ liệu song song tổng hợp (Sennrich et al., 2016). Ngoài dịch máy, kỹ thuật này cũng đã được áp dụng cho chuyển đổi phong cách văn bản không giám sát (Prabhumoye et al., 2018) và chuyển đổi phong cách hình ảnh (Zhu et al., 2017). Ngoài ra, các phương pháp dựa trên quy tắc được sử dụng rộng rãi để xây dựng dữ liệu tổng hợp. Ví dụ, Zhang et al. (2020) đã sử dụng lead bias để tạo ra dữ liệu được ghép đôi để tiền huấn luyện mô hình tóm tắt văn bản, PEGASUS. Lee et al. (2019) đã tiền huấn luyện bộ truy xuất với Inverse Cloze Task, nhằm mục đích dự đoán ngữ cảnh dựa trên câu đã cho. Tuy nhiên, những phương pháp này chuyên biệt cho tác vụ và khó tổng quát hóa cho các tác vụ khác. Bài báo này khám phá việc chuyển đổi GPT-3.5 thành một người chú thích dữ liệu đa năng. Bằng cách cung cấp mô tả tác vụ tương ứng và các minh chứng few-shot CoT, GPT-3.5 có thể dễ dàng chú thích dữ liệu cho các tác vụ khác nhau. Được truyền cảm hứng bởi AnnoLLM, He et al. (2023) đã sử dụng LLMs để đưa các lỗi thực tế vào văn bản chính xác, từ đó tạo ra dữ liệu để sửa lỗi thực tế (Thorne and Vlachos, 2021; He et al., 2024).

6 Kết luận
Trong bài báo này, chúng tôi trình bày AnnoLLM, một hệ thống chú thích mới được hỗ trợ bởi LLMs có tiềm năng thay thế các người chú thích crowdsourced truyền thống. AnnoLLM áp dụng phương pháp hai bước, giải thích-rồi-chú thích. Trong phương pháp này, LLMs ban đầu được sử dụng để tạo ra một prompt few-shot CoT, sau đó được sử dụng để nhắc LLMs chú thích dữ liệu chưa được gán nhãn. Kết quả thí nghiệm của chúng tôi trên ba bộ dữ liệu chứng minh tính khả thi của việc sử dụng AnnoLLM để thay thế các người chú thích crowdsourced. Hơn nữa, chúng tôi giới thiệu bộ dữ liệu ConIR, được tạo ra bằng AnnoLLM, để tạo điều kiện cho nghiên cứu về truy xuất thông tin dựa trên cuộc hội thoại.

7 Lời cảm ơn
Công trình này được hỗ trợ bởi HKU-SCF FinTech Academy, Dự án Kế hoạch Khoa học và Công nghệ Shenzhen-Hong Kong-Macao (Dự án Danh mục C: SGDX20210823103537030), và Scheme Nghiên cứu Theo Chủ đề của RGC, Hồng Kông (T35-710/20-R). Chúng tôi muốn cảm ơn các phản biện ẩn danh vì phản hồi mang tính xây dựng và nhiều thông tin của họ về công trình này.

--- TRANG 5 ---

Tài liệu tham khảo
Payal Bajaj, Daniel Campos, Nick Craswell, Li Deng, Jianfeng Gao, Xiaodong Liu, Rangan Majumder, Andrew McNamara, Bhaskar Mitra, Tri Nguyen, et al. 2016. Ms marco: A human generated machine reading comprehension dataset. arXiv preprint arXiv:1611.09268.

Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020. Language models are few-shot learners. In NIPS, volume 33, pages 1877–1901. Curran Associates, Inc.

Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, et al. 2021. Evaluating large language models trained on code. arXiv preprint arXiv:2107.03374.

Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, et al. 2022. Palm: Scaling language modeling with pathways. arXiv preprint arXiv:2204.02311.

Christopher Clark, Kenton Lee, Ming-Wei Chang, Tom Kwiatkowski, Michael Collins, and Kristina Toutanova. 2019. BoolQ: Exploring the surprising difficulty of natural yes/no questions. In Proceedings of NAACL, pages 2924–2936, Minneapolis, Minnesota. Association for Computational Linguistics.

Joseph L Fleiss. 1971. Measuring nominal scale agreement among many raters. Psychological Bulletin, 76(5):378–382.

Hao Fu, Yao; Peng and Tushar Khot. 2022. How does gpt obtain its ability? tracing emergent abilities of language models to their sources. Yao Fu's Notion.

Xingwei He, A-Long Jin, Jun Ma, Yuan Yuan, and Siu Yiu. 2023. PivotFEC: Enhancing few-shot factual error correction with a pivot task approach using large language models. In Findings of EMNLP, pages 9960–9976, Singapore. Association for Computational Linguistics.

Xingwei He and Siu Ming Yiu. 2022. Controllable dictionary example generation: Generating example sentences for specific targeted audiences. In Proceedings of ACL, pages 610–627, Dublin, Ireland. Association for Computational Linguistics.

Xingwei He, Qianru Zhang, A-Long Jin, Jun Ma, Yuan Yuan, and Siu Ming Yiu. 2024. Improving factual error correction by learning to inject factual errors. In Proceedings of AAAI, volume 38, pages 18197–18205.

Jordan Hoffmann, Sebastian Borgeaud, Arthur Mensch, Elena Buchatskaya, Trevor Cai, Eliza Rutherford, Diego de Las Casas, Lisa Anne Hendricks, Johannes Welbl, Aidan Clark, et al. 2022. Training compute-optimal large language models. arXiv preprint arXiv:2203.15556.

Wenxiang Jiao, Wenxuan Wang, Jen-tse Huang, Xing Wang, and Zhaopeng Tu. 2023. Is chatgpt a good translator? a preliminary study. arXiv preprint arXiv:2301.08745.

Vladimir Karpukhin, Barlas Oguz, Sewon Min, Patrick Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, and Wen-tau Yih. 2020. Dense passage retrieval for open-domain question answering. In Proceedings of EMNLP, pages 6769–6781, Online. Association for Computational Linguistics.

J Richard Landis and Gary G Koch. 1977. The measurement of observer agreement for categorical data. Biometrics, 33(1):159–174.

Kenton Lee, Ming-Wei Chang, and Kristina Toutanova. 2019. Latent retrieval for weakly supervised open domain question answering. In Proceedings of ACL, pages 6086–6096, Florence, Italy. Association for Computational Linguistics.

Zhenghao Lin, Yeyun Gong, Xiao Liu, Hang Zhang, Chen Lin, Anlei Dong, Jian Jiao, Jingwen Lu, Daxin Jiang, Rangan Majumder, et al. 2023. Prod: Progressive distillation for dense retrieval. In Proceedings of WWW, pages 3299–3308.

Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul F Christiano, Jan Leike, and Ryan Lowe. 2022. Training language models to follow instructions with human feedback. In NIPS, volume 35, pages 27730–27744. Curran Associates, Inc.

Mohammad Taher Pilehvar and Jose Camacho-Collados. 2019. WiC: the word-in-context dataset for evaluating context-sensitive meaning representations. In Proceedings of NAACL, pages 1267–1273, Minneapolis, Minnesota. Association for Computational Linguistics.

Shrimai Prabhumoye, Yulia Tsvetkov, Ruslan Salakhutdinov, and Alan W Black. 2018. Style transfer through back-translation. In Proceedings of ACL, pages 866–876, Melbourne, Australia. Association for Computational Linguistics.

Yingqi Qu, Yuchen Ding, Jing Liu, Kai Liu, Ruiyang Ren, Wayne Xin Zhao, Daxiang Dong, Hua Wu, and Haifeng Wang. 2021. RocketQA: An optimized training approach to dense passage retrieval for open-domain question answering. In Proceedings of NAACL, pages 5835–5847, Online. Association for Computational Linguistics.

Alec Radford. 2018. Improving language understanding by generative pre-training. OpenAI Technical Report.

Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. 2019. Language models are unsupervised multitask learners. OpenAI Technical Report.

Jack W Rae, Sebastian Borgeaud, Trevor Cai, Katie Millican, Jordan Hoffmann, Francis Song, John Aslanides, Sarah Henderson, Roman Ring, Susannah Young, et al. 2021. Scaling language models: Methods, analysis & insights from training gopher. arXiv preprint arXiv:2112.11446.

Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J Liu. 2020. Exploring the limits of transfer learning with a unified text-to-text transformer. The Journal of Machine Learning Research, 21(1):5485–5551.

Victor Sanh, Lysandre Debut, Julien Chaumond, and Thomas Wolf. 2019. Distilbert, a distilled version of bert: smaller, faster, cheaper and lighter. arXiv preprint arXiv:1910.01108.

Rico Sennrich, Barry Haddow, and Alexandra Birch. 2016. Improving neural machine translation models with monolingual data. In Proceedings of ACL, pages 86–96, Berlin, Germany. Association for Computational Linguistics.

Richard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Christopher D. Manning, Andrew Ng, and Christopher Potts. 2013. Recursive deep models for semantic compositionality over a sentiment treebank. In Proceedings of EMNLP, pages 1631–1642, Seattle, Washington, USA. Association for Computational Linguistics.

Ilya Sutskever, Oriol Vinyals, and Quoc V. Le. 2014. Sequence to sequence learning with neural networks. In NIPS, page 3104–3112, Cambridge, MA, USA. MIT Press.

James Thorne and Andreas Vlachos. 2021. Evidence-based factual error correction. In Proceedings of ACL, pages 3298–3309, Online. Association for Computational Linguistics.

Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, et al. 2023. Llama: Open and efficient foundation language models. arXiv preprint arXiv:2302.13971.

Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In NIPS, volume 30. Curran Associates, Inc.

Alex Wang, Yada Pruksachatkun, Nikita Nangia, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel Bowman. 2019. Superglue: A stickier benchmark for general-purpose language understanding systems. In NIPS, volume 32. Curran Associates, Inc.

Shuohang Wang, Yang Liu, Yichong Xu, Chenguang Zhu, and Michael Zeng. 2021. Want to reduce labeling cost? GPT-3 can help. In Findings of EMNLP, pages 4195–4205, Punta Cana, Dominican Republic. Association for Computational Linguistics.

Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, and Denny Zhou. 2022. Self-consistency improves chain of thought reasoning in language models. In ICLR.

Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, brian ichter, Fei Xia, Ed Chi, Quoc V Le, and Denny Zhou. 2022. Chain-of-thought prompting elicits reasoning in large language models. In NIPS, volume 35, pages 24824–24837. Curran Associates, Inc.

Xiang Wei, Xingyu Cui, Ning Cheng, Xiaobin Wang, Xin Zhang, Shen Huang, Pengjun Xie, Jinan Xu, Yufeng Chen, Meishan Zhang, Yong Jiang, and Wenjuan Han. 2023. Zero-shot information extraction via chatting with chatgpt. arXiv preprint arXiv:2302.10205.

Jingqing Zhang, Yao Zhao, Mohammad Saleh, and Peter Liu. 2020. Pegasus: Pre-training with extracted gap-sentences for abstractive summarization. In ICML, pages 11328–11339. PMLR.

Jun-Yan Zhu, Taesung Park, Phillip Isola, and Alexei A Efros. 2017. Unpaired image-to-image translation using cycle-consistent adversarial networks. In Proceedings of ICCV, pages 2223–2232.

Barret Zoph, Irwan Bello, Sameer Kumar, Nan Du, Yanping Huang, Jeff Dean, Noam Shazeer, and William Fedus. 2022. St-moe: Designing stable and transferable sparse expert models. arXiv preprint arXiv:2202.08906.

[Phần còn lại của tài liệu tiếp tục với các phụ lục A-G chứa các bảng và ví dụ chi tiết về prompt, nhưng do độ dài, tôi sẽ dừng tại đây. Nếu bạn cần phần còn lại được dịch, vui lòng cho tôi biết.]

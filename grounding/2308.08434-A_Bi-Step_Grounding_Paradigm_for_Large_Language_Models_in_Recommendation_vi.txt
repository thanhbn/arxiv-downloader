# 2308.08434.pdf
# ÄÆ°á»£c chuyá»ƒn Ä‘á»•i tá»« PDF sang TXT
# ÄÆ°á»ng dáº«n nguá»“n: /home/admin88/arxiv-downloader/grounding/2308.08434.pdf
# KÃ­ch thÆ°á»›c tá»‡p: 1157949 bytes

===============================================
Ná»˜I DUNG Tá»†P PDF
===============================================

--- TRANG 1 ---
Má»™t MÃ´ hÃ¬nh Grounding Hai BÆ°á»›c cho MÃ´ hÃ¬nh NgÃ´n ngá»¯ Lá»›n trong Há»‡ thá»‘ng Gá»£i Ã½
KEQIN BAO*, Äáº¡i há»c Khoa há»c vÃ  CÃ´ng nghá»‡ Trung Quá»‘c, Trung Quá»‘c
JIZHI ZHANG*, Äáº¡i há»c Khoa há»c vÃ  CÃ´ng nghá»‡ Trung Quá»‘c, Trung Quá»‘c
WENJIE WANG, Äáº¡i há»c Quá»‘c gia Singapore, Singapore
YANG ZHANG, Äáº¡i há»c Khoa há»c vÃ  CÃ´ng nghá»‡ Trung Quá»‘c, Trung Quá»‘c
ZHENGYI YANG, Äáº¡i há»c Khoa há»c vÃ  CÃ´ng nghá»‡ Trung Quá»‘c, Trung Quá»‘c
YANCHENG LUO, Äáº¡i há»c Khoa há»c vÃ  CÃ´ng nghá»‡ Trung Quá»‘c, Trung Quá»‘c
CHONG CHEN, Huawei Inc., Trung Quá»‘c
FULI FENG, Äáº¡i há»c Khoa há»c vÃ  CÃ´ng nghá»‡ Trung Quá»‘c, Trung Quá»‘c
QI TIAN, Huawei Inc., Trung Quá»‘c

Khi sá»± quan tÃ¢m Ä‘áº¿n MÃ´ hÃ¬nh NgÃ´n ngá»¯ Lá»›n (LLM) trong lÄ©nh vá»±c gá»£i Ã½ ngÃ y cÃ ng tÄƒng, viá»‡c tá»‘i Æ°u hÃ³a LLM cho má»¥c Ä‘Ã­ch gá»£i Ã½ (Ä‘Æ°á»£c gá»i lÃ  LLM4Rec) Ä‘Ã³ng vai trÃ² quan trá»ng trong viá»‡c tÄƒng cÆ°á»ng hiá»‡u quáº£ cá»§a chÃºng trong viá»‡c cung cáº¥p gá»£i Ã½. Tuy nhiÃªn, cÃ¡c phÆ°Æ¡ng phÃ¡p hiá»‡n táº¡i cho LLM4Rec thÆ°á»ng Ä‘Ã¡nh giÃ¡ hiá»‡u suáº¥t báº±ng cÃ¡ch sá»­ dá»¥ng cÃ¡c táº­p há»£p á»©ng viÃªn háº¡n cháº¿, Ä‘iá»u nÃ y cÃ³ thá»ƒ khÃ´ng pháº£n Ã¡nh chÃ­nh xÃ¡c kháº£ nÄƒng xáº¿p háº¡ng tá»•ng thá»ƒ cá»§a mÃ´ hÃ¬nh. Trong bÃ i bÃ¡o nÃ y, má»¥c tiÃªu cá»§a chÃºng tÃ´i lÃ  Ä‘iá»u tra kháº£ nÄƒng xáº¿p háº¡ng toÃ n diá»‡n cá»§a LLM vÃ  Ä‘á» xuáº¥t khung grounding hai bÆ°á»›c Ä‘Æ°á»£c gá»i lÃ  BIGRec (MÃ´ hÃ¬nh Grounding Hai BÆ°á»›c cho Gá»£i Ã½). NÃ³ ban Ä‘áº§u ground LLM vÃ o khÃ´ng gian gá»£i Ã½ báº±ng cÃ¡ch fine-tuning chÃºng Ä‘á»ƒ táº¡o ra cÃ¡c token cÃ³ Ã½ nghÄ©a cho cÃ¡c má»¥c vÃ  sau Ä‘Ã³ xÃ¡c Ä‘á»‹nh cÃ¡c má»¥c thá»±c táº¿ phÃ¹ há»£p tÆ°Æ¡ng á»©ng vá»›i cÃ¡c token Ä‘Æ°á»£c táº¡o ra. Báº±ng cÃ¡ch tiáº¿n hÃ nh cÃ¡c thÃ­ nghiá»‡m rá»™ng rÃ£i trÃªn hai bá»™ dá»¯ liá»‡u, chÃºng tÃ´i chá»©ng minh hiá»‡u suáº¥t vÆ°á»£t trá»™i, kháº£ nÄƒng xá»­ lÃ½ cÃ¡c tÃ¬nh huá»‘ng few-shot vÃ  tÃ­nh linh hoáº¡t trÃªn nhiá»u miá»n Ä‘Æ°á»£c thá»ƒ hiá»‡n bá»Ÿi BIGRec. HÆ¡n ná»¯a, chÃºng tÃ´i quan sÃ¡t tháº¥y ráº±ng lá»£i Ã­ch biÃªn tá»« viá»‡c tÄƒng sá»‘ lÆ°á»£ng máº«u huáº¥n luyá»‡n lÃ  khiÃªm tá»‘n Ä‘á»‘i vá»›i BIGRec, ngá»¥ Ã½ ráº±ng LLM cÃ³ kháº£ nÄƒng háº¡n cháº¿ trong viá»‡c Ä‘á»“ng hÃ³a thÃ´ng tin thá»‘ng kÃª, cháº³ng háº¡n nhÆ° Ä‘á»™ phá»• biáº¿n vÃ  collaborative filtering, do cÃ¡c prior ngá»¯ nghÄ©a máº¡nh máº½ cá»§a chÃºng. Nhá»¯ng phÃ¡t hiá»‡n nÃ y cÅ©ng nháº¥n máº¡nh hiá»‡u quáº£ cá»§a viá»‡c tÃ­ch há»£p thÃ´ng tin thá»‘ng kÃª Ä‘a dáº¡ng vÃ o khung LLM4Rec, tá»« Ä‘Ã³ chá»‰ ra con Ä‘Æ°á»ng tiá»m nÄƒng cho nghiÃªn cá»©u tÆ°Æ¡ng lai. MÃ£ vÃ  dá»¯ liá»‡u cá»§a chÃºng tÃ´i cÃ³ sáºµn táº¡i https://github.com/SAI990323/Grounding4Rec.

KhÃ¡i niá»‡m CCS: â€¢ Há»‡ thá»‘ng thÃ´ng tin â†’ Há»‡ thá»‘ng gá»£i Ã½.
Tá»« khÃ³a bá»• sung: MÃ´ hÃ¬nh NgÃ´n ngá»¯ Lá»›n, Grounding, Gá»£i Ã½ Tuáº§n tá»±

Äá»‹a chá»‰ tÃ¡c giáº£: Keqin Bao*, baokq@mail.ustc.edu.cn, Äáº¡i há»c Khoa há»c vÃ  CÃ´ng nghá»‡ Trung Quá»‘c, Trung Quá»‘c; Jizhi Zhang*, cdzhangjizhi@mail.ustc.edu.cn, Äáº¡i há»c Khoa há»c vÃ  CÃ´ng nghá»‡ Trung Quá»‘c, Trung Quá»‘c; Wenjie Wang, wenjiewang96@gmail.com, Äáº¡i há»c Quá»‘c gia Singapore, Singapore; Yang Zhang, zy2015@mail.ustc.edu.cn, Äáº¡i há»c Khoa há»c vÃ  CÃ´ng nghá»‡ Trung Quá»‘c, Trung Quá»‘c; Zhengyi Yang, yangzhy@mail.ustc.edu.cn, Äáº¡i há»c Khoa há»c vÃ  CÃ´ng nghá»‡ Trung Quá»‘c, Trung Quá»‘c; Yancheng Luo, luoyanchen@mail.ustc.edu.cn, Äáº¡i há»c Khoa há»c vÃ  CÃ´ng nghá»‡ Trung Quá»‘c, Trung Quá»‘c; Chong Chen, chenchong55@huawei.com, Huawei Inc., Trung Quá»‘c; Fuli Feng, fulifeng93@gmail.com, Äáº¡i há»c Khoa há»c vÃ  CÃ´ng nghá»‡ Trung Quá»‘c, Trung Quá»‘c; Qi Tian, tian.qi1@huawei.com, Huawei Inc., Trung Quá»‘c.

Quyá»n Ä‘Æ°á»£c cáº¥p Ä‘á»ƒ táº¡o báº£n sao ká»¹ thuáº­t sá»‘ hoáº·c báº£n cá»©ng cá»§a táº¥t cáº£ hoáº·c má»™t pháº§n cÃ´ng trÃ¬nh nÃ y Ä‘á»ƒ sá»­ dá»¥ng cÃ¡ nhÃ¢n hoáº·c trong lá»›p há»c mÃ  khÃ´ng máº¥t phÃ­ vá»›i Ä‘iá»u kiá»‡n cÃ¡c báº£n sao khÃ´ng Ä‘Æ°á»£c táº¡o ra hoáº·c phÃ¢n phá»‘i Ä‘á»ƒ thu lá»£i nhuáº­n hoáº·c lá»£i tháº¿ thÆ°Æ¡ng máº¡i vÃ  cÃ¡c báº£n sao mang thÃ´ng bÃ¡o nÃ y vÃ  trÃ­ch dáº«n Ä‘áº§y Ä‘á»§ trÃªn trang Ä‘áº§u tiÃªn. Báº£n quyá»n cho cÃ¡c thÃ nh pháº§n cá»§a cÃ´ng trÃ¬nh nÃ y thuá»™c sá»Ÿ há»¯u cá»§a nhá»¯ng ngÆ°á»i khÃ¡c ngoÃ i ACM pháº£i Ä‘Æ°á»£c tÃ´n trá»ng. Viá»‡c trá»«u tÆ°á»£ng hÃ³a cÃ³ ghi cÃ´ng nguá»“n Ä‘Æ°á»£c cho phÃ©p. Äá»ƒ sao chÃ©p cÃ¡ch khÃ¡c, hoáº·c tÃ¡i xuáº¥t báº£n, Ä‘á»ƒ Ä‘Äƒng trÃªn mÃ¡y chá»§ hoáº·c Ä‘á»ƒ phÃ¢n phá»‘i láº¡i cho danh sÃ¡ch, yÃªu cáº§u sá»± cho phÃ©p cá»¥ thá»ƒ trÆ°á»›c vÃ /hoáº·c má»™t khoáº£n phÃ­. YÃªu cáº§u quyá»n tá»« permissions@acm.org.

Â©2024 Association for Computing Machinery.
Báº£n tháº£o Ä‘Æ°á»£c gá»­i tá»›i ACM
Báº£n tháº£o Ä‘Æ°á»£c gá»­i tá»›i ACM 1arXiv:2308.08434v2 [cs.IR] 31 Dec 2023

--- TRANG 2 ---
2 Bao vÃ  Zhang, et al.

ThÃ´ng tin Thá»‘ng kÃª

KhÃ´ng gian NgÃ´n ngá»¯

MÃ´ hÃ¬nh NgÃ´n ngá»¯ Lá»›n

Má»¥c Thá»±c táº¿

KhÃ´ng gian KhÃ´ng gian Gá»£i Ã½

Crouching Tiger, Hidden Dragon (Wu hu zang long)

LÃ  má»™t mÃ´ hÃ¬nh ngÃ´n ngá»¯ AI, tÃ´i khÃ´ng cÃ³ quyá»n truy cáº­p vÃ o sá»Ÿ thÃ­ch cÃ¡ nhÃ¢n cá»§a báº¡n...

Iron Man (PhÆ°Æ¡ng ngá»¯ Tá»© XuyÃªn)

Crouching Tiger, Hidden Dragon (Wu hu zang long)

Má»¥c giáº£ Ä‘á»‹nh Má»¥c thá»±c táº¿

......

Iron Man (2008)

Crouching Tiger, Hidden Dragon (Wu hu zang long)

Iron Man (2008)

Iron Man (PhÆ°Æ¡ng ngá»¯ Tá»© XuyÃªn)

Äáº§u ra MÃ´ hÃ¬nh NgÃ´n ngá»¯ Lá»›n

HÃ¬nh 1. Minh há»a mÃ´ hÃ¬nh BIGRec. Trong bÆ°á»›c Ä‘áº§u tiÃªn, chÃºng tÃ´i ground khÃ´ng gian ngÃ´n ngá»¯ vÃ o khÃ´ng gian gá»£i Ã½, Ä‘iá»u nÃ y cho phÃ©p mÃ´ hÃ¬nh táº¡o ra cÃ¡c chuá»—i token cá»§a cÃ¡c má»¥c tiá»m nÄƒng bao gá»“m cáº£ cÃ¡c má»¥c thá»±c táº¿ vÃ  giáº£ Ä‘á»‹nh. Trong bÆ°á»›c thá»© hai, chÃºng tÃ´i ground khÃ´ng gian gá»£i Ã½ vÃ o khÃ´ng gian má»¥c thá»±c táº¿ Ä‘á»ƒ cung cáº¥p cho ngÆ°á»i dÃ¹ng cÃ¡c gá»£i Ã½ cho cÃ¡c má»¥c trong tháº¿ giá»›i thá»±c. Trong bÆ°á»›c thá»© hai, chÃºng tÃ´i cÃ³ thá»ƒ dá»… dÃ ng káº¿t há»£p thÃ´ng tin thá»‘ng kÃª (vÃ­ dá»¥, Ä‘á»™ phá»• biáº¿n vÃ  thÃ´ng tin collaborative) Ä‘á»ƒ cÃ³ Ä‘Æ°á»£c cÃ¡c gá»£i Ã½ tá»‘t hÆ¡n.

Äá»‹nh dáº¡ng tham chiáº¿u ACM:
Keqin Bao*, Jizhi Zhang*, Wenjie Wang, Yang Zhang, Zhengyi Yang, Yancheng Luo, Chong Chen, Fuli Feng, vÃ  Qi Tian. 2024. Má»™t MÃ´ hÃ¬nh Grounding Hai BÆ°á»›c cho MÃ´ hÃ¬nh NgÃ´n ngá»¯ Lá»›n trong Há»‡ thá»‘ng Gá»£i Ã½. 1, 1 (ThÃ¡ng 1 2024), 17 trang. https://doi.org/10.1145/nnnnnnn.nnnnnnn

1 GIá»šI THIá»†U

MÃ´ hÃ¬nh NgÃ´n ngá»¯ Lá»›n (LLM) Ä‘Ã£ Ä‘áº¡t Ä‘Æ°á»£c thÃ nh cÃ´ng Ä‘Ã¡ng ká»ƒ trong nhiá»u lÄ©nh vá»±c khÃ¡c nhau (nhÆ° Computer Vision [47] vÃ  Robotics [13]) do kháº£ nÄƒng hiá»ƒu bá»‘i cáº£nh vÃ  táº¡o sinh to lá»›n cá»§a chÃºng [8,59]. VÆ°á»£t qua cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ truyá»n thá»‘ng nhÆ° BERT [10] vÃ  GPT2 [35], LLM mÃ£ hÃ³a nhiá»u kiáº¿n thá»©c hÆ¡n, sá»Ÿ há»¯u kháº£ nÄƒng lÃ½ luáº­n máº¡nh máº½ hÆ¡n vÃ  cÃ³ thá»ƒ Ä‘Æ°á»£c thÃ­ch á»©ng má»™t cÃ¡ch mÆ°á»£t mÃ  vá»›i nhiá»‡m vá»¥ má»›i thÃ´ng qua há»c in-context vá»›i má»™t vÃ i vÃ­ dá»¥ [3,26,39]. DÆ°á»›i Ã¡nh sÃ¡ng nÃ y, viá»‡c khÃ¡m phÃ¡ sá»­ dá»¥ng LLM cho gá»£i Ã½ (LLM4Rec) Ä‘ang phÃ¡t triá»ƒn máº¡nh máº½ [2,14,46,54]. Do thiáº¿u huáº¥n luyá»‡n gá»£i Ã½ trong giai Ä‘oáº¡n pre-training cá»§a LLM [3], viá»‡c Ä‘iá»u chá»‰nh LLM Ä‘Ã³ng vai trÃ² quan trá»ng trong viá»‡c giÃºp LLM Ä‘áº¡t Ä‘Æ°á»£c hiá»‡u suáº¥t gá»£i Ã½ tá»‘t hÆ¡n.

Nhiá»u nghiÃªn cá»©u hiá»‡n táº¡i tÄƒng cÆ°á»ng hiá»‡u suáº¥t gá»£i Ã½ cá»§a LLM thÃ´ng qua cÃ¡c ká»¹ thuáº­t fine-tuning dá»±a trÃªn instruction vÃ  sá»­ dá»¥ng dá»¯ liá»‡u gá»£i Ã½, Ä‘áº¡t Ä‘Æ°á»£c káº¿t quáº£ kháº£ quan [3,55]. Khi Ä‘Ã¡nh giÃ¡ hiá»‡u quáº£ cá»§a cÃ¡c phÆ°Æ¡ng phÃ¡p fine-tuning nÃ y, chÃºng thÆ°á»ng chá»‰ tiáº¿n hÃ nh dá»± Ä‘oÃ¡n gá»£i Ã½ trÃªn má»™t táº­p há»£p á»©ng viÃªn háº¡n cháº¿ (vÃ­ dá»¥, dá»± Ä‘oÃ¡n tá»· lá»‡ nháº¥p chuá»™t [3] hoáº·c cÃ i Ä‘áº·t negative sampling [55]), Ä‘iá»u nÃ y khÃ´ng tÃ­nh Ä‘áº¿n kháº£ nÄƒng xáº¿p háº¡ng toÃ n cáº§u tá»•ng thá»ƒ cá»§a mÃ´ hÃ¬nh. ThÃº vá»‹ lÃ , cÃ³ má»™t nghiÃªn cá»©u Ä‘á» xuáº¥t trÃ¡nh Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh gá»£i Ã½ thÃ´ng qua sampling, Ä‘iá»u nÃ y cÃ³ thá»ƒ dáº«n Ä‘áº¿n chá»‰ bÃ¡o kÃ©m vá» hiá»‡u suáº¥t thá»±c sá»± cá»§a há»‡ thá»‘ng gá»£i Ã½ [25]. Do Ä‘Ã³, chÃºng tÃ´i mong muá»‘n Ä‘iá»u tra vÃ  khÃ¡m phÃ¡ kháº£ nÄƒng cá»§a LLM trong lÄ©nh vá»±c sáº¯p xáº¿p gá»£i Ã½ all-rank.

Äá»ƒ táº­n dá»¥ng Ä‘áº§y Ä‘á»§ kháº£ nÄƒng gá»£i Ã½ cá»§a LLM trong tÃ¬nh huá»‘ng all-rank, mÃ´ hÃ¬nh gá»£i Ã½ dá»±a trÃªn LLM pháº£i thá»a mÃ£n ba yÃªu cáº§u. 1) NÃ³ pháº£i hiá»‡u quáº£ Ä‘á»ƒ xáº¿p háº¡ng má»™t sá»‘ lÆ°á»£ng Ä‘Ã¡ng ká»ƒ cÃ¡c má»¥c cho ngÆ°á»i dÃ¹ng. 2) NÃ³ nÃªn cung cáº¥p Ä‘á»§ tÃ­nh linh hoáº¡t Ä‘á»ƒ táº¡o ra má»™t má»¥c cÃ³ Ã½ nghÄ©a nháº±m sá»­ dá»¥ng kháº£ nÄƒng táº¡o sinh vÃ  hiá»ƒu biáº¿t cá»§a LLM. 3) Äiá»u quan trá»ng lÃ  pháº£i xem xÃ©t gá»£i Ã½ má»™t má»¥c thá»±c táº¿ tá»“n táº¡i trong tháº¿ giá»›i thá»±c trong khi cÅ©ng káº¿t há»£p thÃ´ng tin thá»‘ng kÃª liÃªn quan, cháº³ng háº¡n nhÆ° thÃ´ng tin vá» Ä‘á»™ phá»• biáº¿n vÃ  collaborative.

DÆ°á»›i Ã¡nh sÃ¡ng nÃ y, trÆ°á»›c tiÃªn chÃºng ta nÃªn lÃ m cho LLM nháº¥t quÃ¡n giá»¯a giai Ä‘oáº¡n instruction tuning vÃ  giai Ä‘oáº¡n pre-training cá»§a LLM theo cÃ¡ch táº¡o sinh. Äá»“ng thá»i, chÃºng ta nÃªn lÃ m cho gá»£i Ã½ tÆ°Æ¡ng thÃ­ch vá»›i viá»‡c táº¡o ra cÃ¡c má»¥c cÃ³ Ã½ nghÄ©a khÃ´ng thá»±c sá»± tá»“n táº¡i trong tháº¿ giá»›i thá»±c (vÃ­ dá»¥, Iron Man (PhÆ°Æ¡ng ngá»¯ Tá»© XuyÃªn)Â¹), vÃ¬ LLM cÃ³ kháº£ nÄƒng táº¡o ra ná»™i dung sÃ¡ng táº¡o. Cuá»‘i cÃ¹ng, Ä‘iá»u cáº§n thiáº¿t lÃ  pháº£i xem xÃ©t thÃ´ng tin thá»‘ng kÃª tá»« hÃ nh vi ngÆ°á»i dÃ¹ng trong quÃ¡ khá»© khi Ä‘Æ°a ra gá»£i Ã½ Ä‘á»ƒ tÄƒng cÆ°á»ng tÃ­nh há»¯u Ã­ch cá»§a chÃºng.

Äá»ƒ Ä‘áº¡t Ä‘Æ°á»£c má»¥c tiÃªu nÃ y, chÃºng tÃ´i xÃ¢y dá»±ng má»™t mÃ´ hÃ¬nh grounding hai bÆ°á»›c cho gá»£i Ã½ (BIGRec) vá»›i "khÃ´ng gian ngÃ´n ngá»¯" â†’ "khÃ´ng gian gá»£i Ã½" â†’ "khÃ´ng gian má»¥c thá»±c táº¿" nhÆ° Ä‘Æ°á»£c hiá»ƒn thá»‹ trong HÃ¬nh 1. KhÃ´ng gian ngÃ´n ngá»¯ Ä‘á» cáº­p Ä‘áº¿n táº­p há»£p cá»§a táº¥t cáº£ cÃ¡c chuá»—i cÃ³ thá»ƒ cÃ³ thá»ƒ Ä‘Æ°á»£c táº¡o ra bá»Ÿi LLM; khÃ´ng gian gá»£i Ã½ lÃ  má»™t táº­p con cá»§a khÃ´ng gian ngÃ´n ngá»¯ bao gá»“m cÃ¡c mÃ´ táº£ cá»§a cÃ¡c má»¥c khÃ¡c nhau thá»a mÃ£n sá»Ÿ thÃ­ch ngÆ°á»i dÃ¹ng, bao gá»“m cáº£ cÃ¡c má»¥c thá»±c táº¿ vÃ  giáº£ Ä‘á»‹nh. Trong bÆ°á»›c Ä‘áº§u tiÃªn, chÃºng tÃ´i ground LLM vÃ o khÃ´ng gian gá»£i Ã½ báº±ng cÃ¡ch fine-tuning chÃºng Ä‘á»ƒ táº¡o ra cÃ¡c token cÃ³ Ã½ nghÄ©a cho mÃ´ táº£ má»¥c (xem Báº£ng 1). BÆ°á»›c thá»© hai bao gá»“m viá»‡c xÃ¡c Ä‘á»‹nh cÃ¡c má»¥c thá»±c táº¿ phÃ¹ há»£p nháº¥t khá»›p vá»›i cÃ¡c token Ä‘Æ°á»£c táº¡o ra, sá»­ dá»¥ng biá»ƒu diá»…n tiá»m áº©n cá»§a chÃºng thu Ä‘Æ°á»£c tá»« LLM. BÆ°á»›c nÃ y cÅ©ng cung cáº¥p tÃ­nh linh hoáº¡t Ä‘á»ƒ káº¿t há»£p thÃ´ng tin thá»‘ng kÃª Ä‘a dáº¡ng cáº§n thiáº¿t cho gá»£i Ã½, cháº³ng háº¡n nhÆ° cÃ¢n báº±ng khoáº£ng cÃ¡ch cá»§a biá»ƒu diá»…n theo Ä‘á»™ phá»• biáº¿n cá»§a má»¥c.

ChÃºng tÃ´i tiáº¿n hÃ nh cÃ¡c thÃ­ nghiá»‡m rá»™ng rÃ£i trÃªn hai bá»™ dá»¯ liá»‡u tháº¿ giá»›i thá»±c Ä‘á»ƒ Ä‘iá»u tra kháº£ nÄƒng phi thÆ°á»ng cá»§a BIGRec vÃ  áº£nh hÆ°á»Ÿng cá»§a thÃ´ng tin Ä‘á»™ phá»• biáº¿n vÃ  collaborative. Káº¿t quáº£ Ä‘áº§u tiÃªn chá»©ng minh kháº£ nÄƒng few-shot vÃ  multi-domain máº¡nh máº½ cá»§a BIGRec, vÆ°á»£t trá»™i hÆ¡n ráº¥t nhiá»u so vá»›i cÃ¡c mÃ´ hÃ¬nh gá»£i Ã½ truyá»n thá»‘ng vÃ  cÃ¡c phÆ°Æ¡ng phÃ¡p LLM4Rec hiá»‡n cÃ³. ÄÃ¡ng chÃº Ã½, BIGRec cÃ³ thá»ƒ vÆ°á»£t trá»™i hÆ¡n háº§u háº¿t cÃ¡c mÃ´ hÃ¬nh truyá»n thá»‘ng Ä‘Æ°á»£c huáº¥n luyá»‡n vá»›i 100 hoáº·c tháº­m chÃ­ 1.000 láº§n máº«u nhiá»u hÆ¡n. HÆ¡n ná»¯a, chÃºng tÃ´i quan sÃ¡t tháº¥y ráº±ng lá»£i Ã­ch thu Ä‘Æ°á»£c tá»« viá»‡c má»Ÿ rá»™ng máº«u huáº¥n luyá»‡n lÃ  tÆ°Æ¡ng Ä‘á»‘i khiÃªm tá»‘n Ä‘á»‘i vá»›i BIGRec khi so sÃ¡nh vá»›i cÃ¡c mÃ´ hÃ¬nh truyá»n thá»‘ng. XÃ©t ráº±ng nhiá»u máº«u huáº¥n luyá»‡n hÆ¡n cÃ³ lá»£i cho cÃ¡c mÃ´ hÃ¬nh truyá»n thá»‘ng vá»›i thÃ´ng tin thá»‘ng kÃª phong phÃº hÆ¡n, chÃºng tÃ´i giáº£ Ä‘á»‹nh ráº±ng LLM cÃ³ thá»ƒ láº¥y thÃ´ng tin thá»‘ng kÃª háº¡n cháº¿ (vÃ­ dá»¥, Ä‘á»™ phá»• biáº¿n vÃ  thÃ´ng tin collaborative) tá»« máº«u huáº¥n luyá»‡n do cÃ¡c prior ngá»¯ nghÄ©a máº¡nh máº½ cá»§a chÃºng. ChÃºng tÃ´i tiáº¿p tá»¥c xÃ¡c nháº­n hiá»‡u quáº£ cá»§a viá»‡c káº¿t há»£p thÃ´ng tin Ä‘á»™ phá»• biáº¿n vÃ  collaborative, cho tháº¥y tiá»m nÄƒng tá»•ng quÃ¡t hÃ³a cá»§a mÃ´ hÃ¬nh cho cÃ¡c cÃ´ng trÃ¬nh tÆ°Æ¡ng lai.

TÃ³m láº¡i, nhá»¯ng Ä‘Ã³ng gÃ³p cá»§a chÃºng tÃ´i nhÆ° sau:

â€¢ ChÃºng tÃ´i nghiÃªn cá»©u LLM4Rec trong cÃ i Ä‘áº·t all-rank vÃ  giá»›i thiá»‡u má»™t mÃ´ hÃ¬nh grounding hai bÆ°á»›c, táº­n dá»¥ng kháº£ nÄƒng hiá»ƒu biáº¿t vÃ  táº¡o sinh cá»§a LLM má»™t cÃ¡ch hiá»‡u quáº£ vÃ  hiá»‡u suáº¥t vá»›i sá»± há»— trá»£ cá»§a viá»‡c tÃ­ch há»£p thÃ´ng tin thá»‘ng kÃª má»™t cÃ¡ch liá»n máº¡ch.

â€¢ ChÃºng tÃ´i xÃ¡c nháº­n hiá»‡u quáº£ cá»§a BIGRec, cho tháº¥y kháº£ nÄƒng phi thÆ°á»ng cho gá»£i Ã½ few-shot vÃ  cross-domain; vÃ  tiáº¿t lá»™ áº£nh hÆ°á»Ÿng cá»§a viá»‡c má»Ÿ rá»™ng dá»¯ liá»‡u huáº¥n luyá»‡n.

â€¢ ChÃºng tÃ´i tÃ­ch há»£p thÃ´ng tin Ä‘á»™ phá»• biáº¿n vÃ  collaborative vÃ o BIGRec vÃ  tiáº¿t lá»™ lá»£i Ã­ch cá»§a thÃ´ng tin thá»‘ng kÃª Ä‘Ã³ trong LLM4Rec, cho tháº¥y cÃ¡c hÆ°á»›ng tiá»m nÄƒng trong tÆ°Æ¡ng lai.

2 CÃ”NG TRÃŒNH LIÃŠN QUAN

Gá»£i Ã½ dá»±a trÃªn LLM. CÃ¡c nhÃ  nghiÃªn cá»©u trong lÄ©nh vá»±c chá»§ yáº¿u Ä‘iá»u tra cÃ¡c gá»£i Ã½ dá»±a trÃªn LLM tá»« hai gÃ³c Ä‘á»™. Thá»© nháº¥t, há» nháº±m táº­n dá»¥ng phÆ°Æ¡ng phÃ¡p há»c in-context (ICL) Ä‘Ã£ Ä‘Æ°á»£c thiáº¿t láº­p trong cá»™ng Ä‘á»“ng xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn (NLP) [6,16,30]. LLM nhÆ° ChatGPT cÃ³ thá»ƒ há»c nhiá»‡m vá»¥ gá»£i Ã½ thÃ´ng qua autoregression báº±ng cÃ¡ch cung cáº¥p hÆ°á»›ng dáº«n thÃ­ch há»£p vÃ  má»™t vÃ i vÃ­ dá»¥. Tuy nhiÃªn, cÃ¡c nghiÃªn cá»©u trÆ°á»›c Ä‘Ã³ Ä‘Ã£ khÃ¡m phÃ¡ hiá»‡u quáº£ cá»§a cÃ¡c gá»£i Ã½ dá»±a trÃªn ICL vÃ  quan sÃ¡t tháº¥y ráº±ng hiá»‡u suáº¥t cá»§a cÃ¡c phÆ°Æ¡ng phÃ¡p nÃ y thÆ°á»ng bá»‹ háº¡n cháº¿, Ä‘Æ°á»£c cho lÃ  do nhá»¯ng háº¡n cháº¿ Ä‘Æ°á»£c Ã¡p Ä‘áº·t lÃªn kÃ­ch thÆ°á»›c Ä‘áº§u vÃ o cho LLM vÃ  thiáº¿u kiáº¿n thá»©c gá»£i Ã½ [3,30]. Äá»ƒ kháº¯c phá»¥c váº¥n Ä‘á» nÃ y, gÃ³c Ä‘á»™ khÃ¡c tin ráº±ng chÃºng ta nÃªn Ã¡p dá»¥ng LLM vÃ o nhiá»‡m vá»¥ gá»£i Ã½ báº±ng cÃ¡ch fine-tuning LLM do thiáº¿u dá»¯ liá»‡u gá»£i Ã½ liÃªn quan trong giai Ä‘oáº¡n pre-training cá»§a LLM [3,28]. Trong sá»‘ Ä‘Ã³, [28] sá»­ dá»¥ng LLM Ä‘á»ƒ cÃ³ Ä‘Æ°á»£c item embedding phá»¥c vá»¥ nhÆ° biá»ƒu diá»…n item vÃ  Ä‘Æ°á»£c Ä‘Æ°a vÃ o cÃ¡c mÃ´ hÃ¬nh gá»£i Ã½ truyá»n thá»‘ng (vÃ­ dá»¥ SASRec [23]). Tuy nhiÃªn, phÆ°Æ¡ng phÃ¡p nÃ y váº«n dá»±a vÃ o cÃ¡c mÃ´ hÃ¬nh truyá»n thá»‘ng khiáº¿n viá»‡c táº­n dá»¥ng kháº£ nÄƒng táº¡o sinh cá»§a LLM trá»Ÿ nÃªn khÃ³ khÄƒn. NgoÃ i ra, hai nghiÃªn cá»©u hiá»‡n táº¡i, TALLRec [3] vÃ  InstructRec [55], sá»­ dá»¥ng dá»¯ liá»‡u gá»£i Ã½ trong giai Ä‘oáº¡n instruction-tuning Ä‘á»ƒ cáº£i thiá»‡n kháº£ nÄƒng gá»£i Ã½ cá»§a LLM. Tuy nhiÃªn, máº·c dÃ¹ há» cÃ³ xem xÃ©t viá»‡c sá»­ dá»¥ng LLM tá»« gÃ³c Ä‘á»™ táº¡o sinh, viá»‡c Ä‘Ã¡nh giÃ¡ cá»§a há» bá»‹ háº¡n cháº¿ trong tÃ¬nh huá»‘ng CTR hoáº·c Ä‘Æ°á»£c tiáº¿n hÃ nh thÃ´ng qua negative sampling vÃ  khÃ´ng khÃ¡m phÃ¡ kháº£ nÄƒng xáº¿p háº¡ng táº¥t cáº£ cÃ¡c má»¥c cá»§a LLM.

Gá»£i Ã½ Tuáº§n tá»±. MÃ´ hÃ¬nh gá»£i Ã½ gáº§n nháº¥t vá»›i thiáº¿t láº­p thÃ­ nghiá»‡m cá»§a chÃºng tÃ´i lÃ  gá»£i Ã½ tuáº§n tá»±, yÃªu cáº§u há»‡ thá»‘ng gá»£i Ã½ dá»± Ä‘oÃ¡n má»¥c tiáº¿p theo mÃ  ngÆ°á»i dÃ¹ng cÃ³ thá»ƒ thÃ­ch dá»±a trÃªn chuá»—i tÆ°Æ¡ng tÃ¡c lá»‹ch sá»­ cá»§a ngÆ°á»i dÃ¹ng [15,42]. CÃ´ng trÃ¬nh trÆ°á»›c Ä‘Ã³ Ä‘Ã£ riÃªng biá»‡t ná»— lá»±c cÃ¡c mÃ´ hÃ¬nh dá»±a trÃªn RNN [9,12,18], mÃ´ hÃ¬nh dá»±a trÃªn CNN [38,49,52] vÃ  mÃ´ hÃ¬nh dá»±a trÃªn attention [23,48,56] Ä‘á»ƒ mÃ´ hÃ¬nh hÃ³a hÃ nh vi ngÆ°á»i dÃ¹ng, Ä‘áº¡t Ä‘Æ°á»£c káº¿t quáº£ Ä‘Ã¡ng kÃ­nh. Dá»±a trÃªn nhá»¯ng phÆ°Æ¡ng phÃ¡p nÃ y, má»™t sá»‘ lÆ°á»£ng ngÃ y cÃ ng lá»›n cÃ¡c cÃ´ng trÃ¬nh táº­p trung vÃ o viá»‡c nÃ¢ng cao hiá»‡u suáº¥t mÃ´ hÃ¬nh thÃ´ng qua pretraining [32,51], data augmentation [33,34], cÃ¡c ká»¹ thuáº­t debiasing [11,43], tá»‘i Æ°u hÃ³a robust phÃ¢n phá»‘i [45,50] vÃ  cÃ¡c phÆ°Æ¡ng phÃ¡p tÆ°Æ¡ng tá»± khÃ¡c. Tuy nhiÃªn, bá»‹ háº¡n cháº¿ bá»Ÿi cÃ¡c há»‡ thá»‘ng gá»£i Ã½ dá»±a trÃªn ID thÃ´ng thÆ°á»ng, nhá»¯ng phÆ°Æ¡ng phÃ¡p nhÆ° váº­y thiáº¿u kháº£ nÄƒng tá»•ng quÃ¡t hÃ³a cÅ©ng nhÆ° tÃ­nh nhanh chÃ³ng Ä‘á»ƒ thÃ­ch á»©ng vá»›i cÃ¡c tÃ¬nh huá»‘ng má»›i. Trong nhá»¯ng nÄƒm gáº§n Ä‘Ã¢y, cÃ³ sá»± nháº­n thá»©c ngÃ y cÃ ng tÄƒng vá» vai trÃ² cá»§a ngá»¯ nghÄ©a trong gá»£i Ã½, vá»›i nhá»¯ng ná»— lá»±c hiá»‡n táº¡i Ä‘ang Ä‘Æ°á»£c thá»±c hiá»‡n Ä‘á»ƒ táº­n dá»¥ng cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ Ä‘á»ƒ há»— trá»£ quÃ¡ trÃ¬nh gá»£i Ã½ [19,27]. Tuy nhiÃªn, cÃ¡c phÆ°Æ¡ng phÃ¡p nÃ y, hoáº·c váº«n dá»±a vÃ o cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ sá»­ dá»¥ng encoder Ä‘á»ƒ trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng, Ä‘iá»u nÃ y Ä‘Ã²i há»i dá»¯ liá»‡u khá»•ng lá»“ Ä‘á»ƒ pre-training, hoáº·c sá»­ dá»¥ng word overlapping Ä‘á»ƒ truy xuáº¥t cÃ¡c má»¥c, thiáº¿u viá»‡c sá»­ dá»¥ng thÃ´ng tin ngá»¯ nghÄ©a vÃ  dá»… bá»‹ áº£nh hÆ°á»Ÿng bá»Ÿi nhiá»…u.

Grounding trong LLM. Hiá»‡n táº¡i, trong nghiÃªn cá»©u vá» LLM, chÃºng ta chá»§ yáº¿u cÃ³ thá»ƒ xem xÃ©t khÃ¡i niá»‡m grounding tá»« hai gÃ³c Ä‘á»™: modality grounding vÃ  affordance grounding [44]. CÃ¡i trÆ°á»›c lÃ  Ä‘á»ƒ ground cÃ¡c phÆ°Æ¡ng thá»©c ngÃ´n ngá»¯ vÃ o kiáº¿n thá»©c cá»§a cÃ¡c phÆ°Æ¡ng thá»©c khÃ¡c, cháº³ng háº¡n nhÆ° hÃ¬nh áº£nh, Ã¢m thanh hoáº·c cÃ¡c phÆ°Æ¡ng thá»©c khÃ¡c, thÃ´ng qua cÃ¡ch tiáº¿p cáº­n nÃ y, ngÆ°á»i ta cÃ³ thá»ƒ cho phÃ©p LLM náº¯m báº¯t vÃ  xá»­ lÃ½ thÃ´ng tin phong phÃº hÆ¡n tá»« tháº¿ giá»›i thá»±c [4]. Trong dÃ²ng modality grounding [22,29,53], cÃ¡c cÃ¡ nhÃ¢n ná»— lá»±c giá»›i thiá»‡u thÃ´ng tin cá»§a cÃ¡c phÆ°Æ¡ng thá»©c khÃ¡c trong cáº£ giai Ä‘oáº¡n huáº¥n luyá»‡n vÃ  suy luáº­n cá»§a LLM, dáº«n Ä‘áº¿n kháº£ nÄƒng xá»­ lÃ½ Ä‘áº§u vÃ o Ä‘a phÆ°Æ¡ng thá»©c, nhÆ° Ä‘Æ°á»£c minh há»a bá»Ÿi Vicuna [7,60], MiniGPT4 [61]. Tuy nhiÃªn do yÃªu cáº§u cá»§a má»™t lÆ°á»£ng lá»›n dá»¯ liá»‡u vÃ  tÃ i nguyÃªn [44], trong bÃ i bÃ¡o nÃ y, chÃºng tÃ´i khÃ´ng Æ°u tiÃªn cho chiáº¿n lÆ°á»£c grounding nÃ y mÃ  Ä‘á»ƒ láº¡i nhÆ° má»™t cÃ´ng viá»‡c tÆ°Æ¡ng lai. CÃ¡i sau nháº±m grounding LLM vÃ o má»™t tÃ¬nh huá»‘ng bá»‘i cáº£nh cá»¥ thá»ƒ, Ä‘áº£m báº£o ráº±ng káº¿t quáº£ Ä‘Æ°á»£c táº¡o ra bá»Ÿi mÃ´ hÃ¬nh cÃ³ liÃªn quan Ä‘áº¿n nhiá»‡m vá»¥ thay vÃ¬ tÃ¡ch rá»i khá»i tÃ¬nh huá»‘ng [1]. Trong thá»±c táº¿, má»i ngÆ°á»i Ä‘áº¡t Ä‘Æ°á»£c má»¥c tiÃªu nÃ y thÃ´ng qua instruction-tuning trÃªn dá»¯ liá»‡u cá»¥ thá»ƒ cá»§a miá»n hoáº·c sá»­ dá»¥ng cÃ¡c prompt tÃ¹y chá»‰nh Ä‘á»ƒ Ä‘iá»u hÆ°á»›ng LLM [44]. Trong miá»n gá»£i Ã½, do khoáº£ng cÃ¡ch cá»§a nÃ³ vá»›i báº£n thÃ¢n nhiá»‡m vá»¥ táº¡o sinh - chÃºng ta cáº§n gá»£i Ã½ má»™t má»¥c thá»±c sá»± tá»“n táº¡i, do Ä‘Ã³ chÃºng ta Ã¡p dá»¥ng má»™t bÆ°á»›c grounded trong Ä‘áº§u ra táº¡o sinh vÃ o tháº¿ giá»›i thá»±c Ä‘á»ƒ hoÃ n thÃ nh gá»£i Ã½.

3 BIGREC

Trong pháº§n nÃ y, chÃºng tÃ´i giá»›i thiá»‡u má»™t triá»ƒn khai cÆ¡ báº£n cá»§a BIGRec vá»›i hai bÆ°á»›c grounding.

3.1 SÆ¡ bá»™

Äá»‹nh nghÄ©a. Äá»ƒ hiá»ƒu rÃµ hÆ¡n vá» mÃ´ hÃ¬nh grounding, trÆ°á»›c tiÃªn chÃºng tÃ´i Ä‘Æ°a ra Ä‘á»‹nh nghÄ©a cá»§a cÃ¡c cá»¥m tá»« quan trá»ng sau:

Báº£n tháº£o Ä‘Æ°á»£c gá»­i tá»›i ACM

--- TRANG 5 ---
Má»™t MÃ´ hÃ¬nh Grounding Hai BÆ°á»›c cho MÃ´ hÃ¬nh NgÃ´n ngá»¯ Lá»›n trong Há»‡ thá»‘ng Gá»£i Ã½ 5

Báº£ng 1. VÃ­ dá»¥ vá» dá»¯ liá»‡u instruction-tuning cho bÆ°á»›c grounding vÃ o khÃ´ng gian.

HÆ°á»›ng dáº«n Äáº§u vÃ o
HÆ°á»›ng dáº«n: Cho mÆ°á»i bá»™ phim mÃ  ngÆ°á»i dÃ¹ng Ä‘Ã£ xem gáº§n Ä‘Ã¢y, vui lÃ²ng gá»£i Ã½ má»™t bá»™ phim má»›i mÃ  ngÆ°á»i dÃ¹ng thÃ­ch cho ngÆ°á»i dÃ¹ng.
Äáº§u vÃ o: NgÆ°á»i dÃ¹ng Ä‘Ã£ xem nhá»¯ng bá»™ phim sau trÆ°á»›c Ä‘Ã¢y: "Traffic (2000)", "Ocean's Eleven (2001)", ... "Fargo (1996)"

Äáº§u ra HÆ°á»›ng dáº«n
Äáº§u ra: "Crouching Tiger, Hidden Dragon (Wu hu zang long) (2000)"

â€¢ KhÃ´ng gian NgÃ´n ngá»¯. KhÃ´ng gian nÃ y trÆ°á»›c mÃ´ hÃ¬nh grounding bao gá»“m táº¥t cáº£ cÃ¡c chuá»—i ngÃ´n ngá»¯ cÃ³ thá»ƒ hÃ¬nh dung mÃ  má»™t LLM cÃ³ thá»ƒ táº¡o ra, cháº³ng háº¡n nhÆ° cÃ¢u phÃ¡t biá»ƒu, "LÃ  má»™t mÃ´ hÃ¬nh ngÃ´n ngá»¯ AI, tÃ´i khÃ´ng cÃ³ quyá»n truy cáº­p vÃ o sá»Ÿ thÃ­ch cÃ¡ nhÃ¢n cá»§a báº¡n...". KhÃ´ng kháº£ thi khi sá»­ dá»¥ng khÃ´ng gian nÃ y trá»±c tiáº¿p Ä‘á»ƒ táº¡o gá»£i Ã½ do báº£n cháº¥t rá»™ng lá»›n vÃ  Ä‘a dáº¡ng cá»§a nÃ³.

â€¢ KhÃ´ng gian Gá»£i Ã½. ÄÃ¢y lÃ  má»™t khÃ´ng gian con trong khÃ´ng gian ngÃ´n ngá»¯ bao gá»“m má»™t loáº¡t cÃ¡c thá»±c thá»ƒ thá»a mÃ£n sá»Ÿ thÃ­ch cá»§a ngÆ°á»i dÃ¹ng. Nhá»¯ng thá»±c thá»ƒ nÃ y cÃ³ thá»ƒ Ä‘áº¡i diá»‡n cho cáº£ cÃ¡c má»¥c thá»±c táº¿ vÃ  tÆ°á»Ÿng tÆ°á»£ng trong má»™t miá»n cá»¥ thá»ƒ. Tuy nhiÃªn, Ä‘iá»u quan trá»ng cáº§n lÆ°u Ã½ lÃ  viá»‡c gá»£i Ã½ cÃ¡c thá»±c thá»ƒ hoÃ n toÃ n tÆ°á»Ÿng tÆ°á»£ng cÃ³ thá»ƒ khÃ´ng phÃ¹ há»£p. VÃ­ dá»¥, viá»‡c gá»£i Ã½ "Iron Man (PhÆ°Æ¡ng ngá»¯ Tá»© XuyÃªn)" nhÆ° má»™t gá»£i Ã½ sáº½ khÃ´ng kháº£ thi.

â€¢ KhÃ´ng gian Má»¥c Thá»±c táº¿. KhÃ´ng gian má»¥c thá»±c táº¿ chá»‰ chá»©a cÃ¡c má»¥c thá»±c táº¿ trong khÃ´ng gian gá»£i Ã½. Viá»‡c gá»£i Ã½ cÃ¡c má»¥c tá»« khÃ´ng gian má»¥c thá»±c táº¿ nÃ y lÃ  cáº§n thiáº¿t. VÃ­ dá»¥, trong bá»‘i cáº£nh gá»£i Ã½ phim, cÃ¡c má»¥c Ä‘Æ°á»£c gá»£i Ã½ pháº£i Ä‘Æ°á»£c chá»n tá»« nhá»¯ng bá»™ phim cÃ³ sáºµn trÃªn ná»n táº£ng.

Äá»ƒ fine-tune LLM cho gá»£i Ã½, chÃºng tÃ´i Ä‘á» xuáº¥t mÃ´ hÃ¬nh BIGRec vá»›i hai bÆ°á»›c grounding. Thá»© nháº¥t, chÃºng tÃ´i ground Ä‘áº§u ra cá»§a LLM tá»« khÃ´ng gian ngÃ´n ngá»¯ vÃ o khÃ´ng gian gá»£i Ã½ cho má»™t nhiá»‡m vá»¥ gá»£i Ã½ cá»¥ thá»ƒ. Thá»© hai, chÃºng tÃ´i ground nÃ³ tá»« khÃ´ng gian gá»£i Ã½ vÃ o khÃ´ng gian má»¥c thá»±c táº¿, cho phÃ©p gá»£i Ã½ cÃ¡c má»¥c thá»±c táº¿ cho ngÆ°á»i dÃ¹ng. Äá»ƒ chá»©ng minh kháº£ nÄƒng cá»§a mÃ´ hÃ¬nh cá»§a chÃºng tÃ´i, chÃºng tÃ´i trÃ¬nh bÃ y má»™t triá»ƒn khai Ä‘Æ¡n giáº£n, minh há»a tiá»m nÄƒng vÃ  kháº£ nÄƒng cá»§a mÃ´ hÃ¬nh BIGRec nÃ y.

3.2 Triá»ƒn khai

Trong pháº§n nÃ y, chÃºng tÃ´i mÃ´ táº£ cÃ¡ch chÃºng tÃ´i triá»ƒn khai mÃ´ hÃ¬nh BIGRec cho gá»£i Ã½.

3.2.1 BÆ°á»›c 1: Grounding KhÃ´ng gian NgÃ´n ngá»¯ vÃ o KhÃ´ng gian Gá»£i Ã½. Theo phÆ°Æ¡ng phÃ¡p Ä‘Æ°á»£c Ä‘á» xuáº¥t trong [3], chÃºng tÃ´i thá»±c hiá»‡n giai Ä‘oáº¡n instruction-tuning trÃªn dá»¯ liá»‡u alpaca self-instruct [39] sá»­ dá»¥ng LLaMA [40]. Sau Ä‘Ã³, chÃºng tÃ´i tiáº¿n hÃ nh instruction-tuning cá»¥ thá»ƒ cho gá»£i Ã½ Ä‘á»ƒ háº¡n cháº¿ Ä‘áº§u ra cá»§a LLM tá»« khÃ´ng gian ngÃ´n ngá»¯ vÃ o khÃ´ng gian gá»£i Ã½. NhÆ° Ä‘Æ°á»£c chá»©ng minh trong Báº£ng 1, chÃºng tÃ´i fine-tune LLM theo cÃ¡ch táº¡o sinh: cho tÆ°Æ¡ng tÃ¡c trong quÃ¡ khá»© cá»§a ngÆ°á»i dÃ¹ng vá»›i cÃ¡c má»¥c, chÃºng tÃ´i yÃªu cáº§u LLM táº¡o ra má»™t má»¥c má»›i nhÆ° gá»£i Ã½ cho ngÆ°á»i dÃ¹ng. Báº±ng cÃ¡ch fine-tuning vá»›i dá»¯ liá»‡u nhÆ° váº­y, chÃºng tÃ´i háº¡n cháº¿ Ä‘áº§u ra cá»§a LLM vÃ o khÃ´ng gian gá»£i Ã½ Ä‘Æ°á»£c chá»‰ Ä‘á»‹nh nhÆ° Ä‘Æ°á»£c hÆ°á»›ng dáº«n. Tuy nhiÃªn, do tÃ­nh sÃ¡ng táº¡o cá»§a LLM, ráº¥t khÃ³ Ä‘á»ƒ Ä‘áº£m báº£o ráº±ng Ä‘áº§u ra cá»§a LLM sáº½ tÆ°Æ¡ng á»©ng vá»›i má»™t má»¥c thá»±c táº¿ tá»“n táº¡i trong tháº¿ giá»›i thá»±c. Do Ä‘Ã³, Ä‘iá»u cáº§n thiáº¿t lÃ  pháº£i ground Ä‘áº§u ra cá»§a LLM vÃ o khÃ´ng gian má»¥c thá»±c táº¿.

Báº£n tháº£o Ä‘Æ°á»£c gá»­i tá»›i ACM

--- TRANG 6 ---
6 Bao vÃ  Zhang, et al.

3.2.2 BÆ°á»›c 2: Grounding KhÃ´ng gian Gá»£i Ã½ vÃ o KhÃ´ng gian Má»¥c Thá»±c táº¿. Trong pháº§n nÃ y, chÃºng tÃ´i trÃ¬nh bÃ y chi tiáº¿t vá» cÃ¡ch neo khÃ´ng gian gá»£i Ã½ vÃ o khÃ´ng gian má»¥c thá»±c táº¿. Äáº§u tiÃªn, chÃºng tÃ´i cÄƒn chá»‰nh Ä‘áº§u ra cá»§a LLM vá»›i cÃ¡c má»¥c trong tháº¿ giá»›i thá»±c dá»±a trÃªn biá»ƒu diá»…n cá»§a LLM Ä‘á»ƒ triá»ƒn khai má»™t phiÃªn báº£n vanilla cá»§a BIGRec. Sau Ä‘Ã³, chÃºng tÃ´i giá»›i thiá»‡u thÃ´ng tin thá»‘ng kÃª (vÃ­ dá»¥, thÃ´ng tin Ä‘á»™ phá»• biáº¿n vÃ  collaborative) Ä‘á»ƒ Ä‘á»‹nh vá»‹ chÃ­nh xÃ¡c cÃ¡c má»¥c thá»±c táº¿ cho gá»£i Ã½. Cá»¥ thá»ƒ, chÃºng tÃ´i trÃ­ch xuáº¥t biá»ƒu diá»…n tiá»m áº©n cá»§a cÃ¡c token Ä‘Æ°á»£c táº¡o ra vÃ  embedding cá»§a cÃ¡c má»¥c thá»±c táº¿. Sau Ä‘Ã³, chÃºng tÃ´i xáº¿p háº¡ng cÃ¡c má»¥c thá»±c táº¿ nÃ y báº±ng cÃ¡ch tÃ­nh toÃ¡n khoáº£ng cÃ¡ch L2 giá»¯a cÃ¡c embedding cá»§a chÃºng. Khoáº£ng cÃ¡ch L2 Ä‘Æ°á»£c tÃ­nh nhÆ° sau:

ğ·ğ‘– = ||embğ‘– âˆ’ oracle||2, (1)

trong Ä‘Ã³ embğ‘– biá»ƒu thá»‹ embedding cá»§a má»¥c thá»© ğ‘– vÃ  oracle biá»ƒu thá»‹ embedding cá»§a cÃ¡c Ä‘áº§u ra Ä‘Æ°á»£c táº¡o ra bá»Ÿi LLM.

TiÃªm ThÃ´ng tin Thá»‘ng kÃª. Sau Ä‘Ã³ chÃºng tÃ´i giá»›i thiá»‡u cÃ¡ch chÃºng tÃ´i káº¿t há»£p thÃ´ng tin Ä‘á»™ phá»• biáº¿n vÃ  thÃ´ng tin collaborative vÃ o bÆ°á»›c grounding. Äá»ƒ tiÃªm Ä‘á»™ phá»• biáº¿n, chÃºng tÃ´i theo Ã½ tÆ°á»Ÿng trong PDA [57] vÃ  cÃ¢n báº±ng láº¡i khoáº£ng cÃ¡ch L2 trong Eq. (1) báº±ng Ä‘á»™ phá»• biáº¿n. Chi tiáº¿t, Ä‘áº§u tiÃªn chÃºng tÃ´i tÃ­nh toÃ¡n há»‡ sá»‘ Ä‘á»™ phá»• biáº¿n cá»§a má»—i má»¥c tá»« phÆ°Æ¡ng trÃ¬nh sau:

ğ¶ğ‘– = Nğ‘– / Î£ğ‘—âˆˆI Nğ‘—,
ğ‘ƒğ‘– = (ğ¶ğ‘– âˆ’ minğ‘—âˆˆI{ğ¶ğ‘—}) / (maxğ‘—âˆˆI{ğ¶ğ‘—} âˆ’ minğ‘—âˆˆI{ğ¶ğ‘—}), (2)

trong Ä‘Ã³ N biá»ƒu thá»‹ táº­p há»£p cÃ¡c tÆ°Æ¡ng tÃ¡c user-item trong dá»¯ liá»‡u huáº¥n luyá»‡n, Nğ‘— biá»ƒu thá»‹ sá»‘ lÆ°á»£ng tÆ°Æ¡ng tÃ¡c quan sÃ¡t Ä‘Æ°á»£c cho má»¥c ğ‘— trong N vÃ  I biá»ƒu thá»‹ táº¥t cáº£ cÃ¡c má»¥c, ğ¶ğ‘– Ä‘áº¡i diá»‡n cho Ä‘á»™ phá»• biáº¿n cá»§a má»¥c thá»© ğ‘–, vÃ  ğ‘ƒğ‘– lÃ  giÃ¡ trá»‹ chuáº©n hÃ³a cá»§a ğ¶ğ‘–.

Sau Ä‘Ã³ chÃºng tÃ´i Ä‘iá»u chá»‰nh khoáº£ng cÃ¡ch L2 trong Eq. (1) báº±ng Ä‘á»™ phá»• biáº¿n:

Ë†ğ·ğ‘– = (ğ·ğ‘– âˆ’ minğ‘—âˆˆI{ğ·ğ‘—}) / (maxğ‘—âˆˆI{ğ·ğ‘—} âˆ’ minğ‘—âˆˆI{ğ·ğ‘—}),
ğ·Ìƒğ‘– = Ë†ğ·ğ‘– / (1 + ğ‘ƒğ‘–)ğ›¾, (3)

trong Ä‘Ã³ ğ·ğ‘– biá»ƒu thá»‹ khoáº£ng cÃ¡ch L2 giá»¯a embedding cá»§a má»¥c thá»© ğ‘– vÃ  embedding cá»§a cÃ¡c Ä‘áº§u ra Ä‘Æ°á»£c táº¡o ra bá»Ÿi LLM, Ë†ğ·ğ‘– lÃ  ğ·ğ‘– Ä‘Æ°á»£c chuáº©n hÃ³a, vÃ  ğ·Ìƒğ‘– cÃ¢n báº±ng láº¡i Ë†ğ·ğ‘– báº±ng cÃ¡ch sá»­ dá»¥ng Ä‘á»™ phá»• biáº¿n. Äá»ƒ cÃ¢n báº±ng láº¡i Ë†ğ·ğ‘–, chÃºng tÃ´i sá»­ dá»¥ng Ä‘á»™ phá»• biáº¿n nghá»‹ch Ä‘áº£o vÃ  giá»›i thiá»‡u má»™t siÃªu tham sá»‘ ğ›¾ Ä‘á»ƒ Ä‘iá»u chá»‰nh áº£nh hÆ°á»Ÿng cá»§a Ä‘á»™ phá»• biáº¿n. Báº±ng cÃ¡ch Ä‘áº·t Ä‘á»™ phá»• biáº¿n á»Ÿ máº«u sá»‘, má»™t má»¥c phá»• biáº¿n sáº½ Ä‘Æ°á»£c gÃ¡n khoáº£ng cÃ¡ch L2 nhá» hÆ¡n vÃ  xáº¿p háº¡ng cao hÆ¡n. Äiá»u nÃ y hÆ¡i khÃ¡c so vá»›i triá»ƒn khai gá»‘c trong PDA, trá»±c tiáº¿p cÃ¢n báº±ng láº¡i Ä‘iá»ƒm sá»‘ dá»± Ä‘oÃ¡n thay vÃ¬ khoáº£ng cÃ¡ch L2Â².

KhÃ¡c vá»›i Ä‘á»™ phá»• biáº¿n, viá»‡c sá»­ dá»¥ng cÃ¡c phÆ°Æ¡ng phÃ¡p thá»‘ng kÃª Ä‘á»ƒ Ä‘á»‹nh lÆ°á»£ng thÃ´ng tin collaborative lÃ  khÃ´ng táº§m thÆ°á»ng. XÃ©t ráº±ng cÃ¡c mÃ´ hÃ¬nh gá»£i Ã½ truyá»n thá»‘ng dá»±a vÃ o collaborative filtering cho gá»£i Ã½, chÃºng tÃ´i coi Ä‘iá»ƒm sá»‘ dá»± Ä‘oÃ¡n bá»Ÿi cÃ¡c mÃ´ hÃ¬nh collaborative filtering nÃ y lÃ  thÃ´ng tin collaborative. TÆ°Æ¡ng tá»± nhÆ° viá»‡c tiÃªm Ä‘á»™ phá»• biáº¿n, chÃºng tÃ´i cÃ³ thá»ƒ thay tháº¿ biáº¿n ğ‘ƒğ‘– trong Eq. (3) báº±ng Ä‘iá»ƒm sá»‘ dá»± Ä‘oÃ¡n Ä‘á»ƒ tiÃªm thÃ´ng tin collaborative vÃ o quÃ¡ trÃ¬nh grounding. Äá»ƒ biáº¿t thÃªm chi tiáº¿t, vui lÃ²ng tham kháº£o Pháº§n Â§4.4.

4 THÃ NGHIá»†M

Trong pháº§n nÃ y, chÃºng tÃ´i tiáº¿n hÃ nh thÃ­ nghiá»‡m Ä‘á»ƒ tráº£ lá»i cÃ¡c cÃ¢u há»i nghiÃªn cá»©u sau:

â€¢ RQ1: Hiá»‡u suáº¥t cá»§a BIGRec so vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p hiá»‡n cÃ³ nhÆ° tháº¿ nÃ o, khi Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn má»™t máº«u háº¡n cháº¿ gá»“m 1024 Ä‘iá»ƒm dá»¯ liá»‡u?

Â² Trong Pháº§n Â§4.4, chÃºng tÃ´i váº«n cÃ¢n báº±ng láº¡i Ä‘iá»ƒm sá»‘ dá»± Ä‘oÃ¡n báº±ng cÃ¡ch sá»­ dá»¥ng PDA [57] Ä‘á»ƒ káº¿t há»£p Ä‘á»™ phá»• biáº¿n vÃ o hai mÃ´ hÃ¬nh truyá»n thá»‘ng.

Báº£n tháº£o Ä‘Æ°á»£c gá»­i tá»›i ACM

--- TRANG 7 ---
Má»™t MÃ´ hÃ¬nh Grounding Hai BÆ°á»›c cho MÃ´ hÃ¬nh NgÃ´n ngá»¯ Lá»›n trong Há»‡ thá»‘ng Gá»£i Ã½ 7

â€¢ RQ2: Hiá»‡u suáº¥t cá»§a mÃ´ hÃ¬nh cá»§a chÃºng tÃ´i Ä‘Æ°á»£c huáº¥n luyá»‡n vá»›i dá»¯ liá»‡u háº¡n cháº¿ so vá»›i cÃ¡c mÃ´ hÃ¬nh gá»£i Ã½ truyá»n thá»‘ng Ä‘Æ°á»£c huáº¥n luyá»‡n vá»›i 100Ã— hoáº·c tháº­m chÃ­ 1,000Ã— máº«u nhiá»u hÆ¡n nhÆ° tháº¿ nÃ o?

â€¢ RQ3: BIGRec cÃ³ thá»ƒ Ä‘áº¡t Ä‘Æ°á»£c sá»± cáº£i thiá»‡n hiá»‡u suáº¥t Ä‘Ã¡ng ká»ƒ vá»›i viá»‡c tÄƒng dá»¯ liá»‡u huáº¥n luyá»‡n nhÆ° cÃ¡c mÃ´ hÃ¬nh truyá»n thá»‘ng khÃ´ng?

â€¢ RQ4: Hiá»‡u suáº¥t cá»§a BIGRec cÃ³ thá»ƒ Ä‘Æ°á»£c tÄƒng cÆ°á»ng Ä‘áº¿n má»©c Ä‘á»™ nÃ o báº±ng cÃ¡ch tÃ­ch há»£p thÃ´ng tin Ä‘á»™ phá»• biáº¿n/collaborative trong quÃ¡ trÃ¬nh grounding mÃ´ hÃ¬nh?

4.1 Thiáº¿t láº­p ThÃ­ nghiá»‡m

4.1.1 Bá»™ dá»¯ liá»‡u. ChÃºng tÃ´i tiáº¿n hÃ nh thÃ­ nghiá»‡m trÃªn hai bá»™ dá»¯ liá»‡u:

â€¢ Movie. ÄÃ¢y Ä‘á» cáº­p Ä‘áº¿n bá»™ dá»¯ liá»‡u benchmark ná»•i tiáº¿ng cho gá»£i Ã½ phim â€” MovieLens10MÂ³. NÃ³ chá»©a 10,682 má»¥c, 10,000,054 tÆ°Æ¡ng tÃ¡c vÃ  9,301,274 chuá»—i tÆ°Æ¡ng tÃ¡c.

â€¢ Game. ÄÃ¢y lÃ  bá»™ dá»¯ liá»‡u gá»£i Ã½ video-games tá»« Amazonâ´ vÃ  chÃºng tÃ´i sá»­ dá»¥ng táº­p con 5-core cá»§a nÃ³. Bá»™ dá»¯ liá»‡u chá»©a 17,408 má»¥c, 496,315 tÆ°Æ¡ng tÃ¡c vÃ  149,796 chuá»—i tÆ°Æ¡ng tÃ¡c.

ChÃºng tÃ´i Ä‘Ã£ chá»n hai bá»™ dá»¯ liá»‡u nÃ y má»™t cÃ¡ch cÃ³ chá»§ Ã½, vÃ¬ chÃºng thá»ƒ hiá»‡n cÃ¡c Ä‘áº·c Ä‘iá»ƒm khÃ¡c nhau vá» Ä‘á»™ thiÃªn vá»‹ Ä‘á»™ phá»• biáº¿n. Bá»™ dá»¯ liá»‡u Movie cho tháº¥y sá»± thiÃªn vá»‹ Ä‘Ã¡ng ká»ƒ Ä‘á»‘i vá»›i cÃ¡c má»¥c phá»• biáº¿n, trong khi bá»™ dá»¯ liá»‡u Game thá»ƒ hiá»‡n má»©c Ä‘á»™ thiÃªn vá»‹ Ã­t hÆ¡n. HÃ¬nh 2(a) minh há»a táº§n suáº¥t tÆ°Æ¡ng tÃ¡c giá»¯a cÃ¡c má»¥c vá»›i cÃ¡c má»©c Ä‘á»™ phá»• biáº¿n khÃ¡c nhau, xÃ¡c nháº­n ráº±ng bá»™ dá»¯ liá»‡u Game thá»ƒ hiá»‡n sá»± phÃ¢n phá»‘i tÆ°Æ¡ng tÃ¡c cÃ´ng báº±ng hÆ¡n giá»¯a cÃ¡c má»¥c phá»• biáº¿n vÃ  khÃ´ng phá»• biáº¿n so vá»›i bá»™ dá»¯ liá»‡u Movie. Äiá»u nÃ y gá»£i Ã½ má»©c Ä‘á»™ thiÃªn vá»‹ Ä‘á»™ phá»• biáº¿n tháº¥p hÆ¡n trong bá»™ dá»¯ liá»‡u Game.

Äá»ƒ mÃ´ phá»ng cÃ¡c tÃ¬nh huá»‘ng gá»£i Ã½ tuáº§n tá»± trong tháº¿ giá»›i thá»±c, chÃºng tÃ´i chia má»—i bá»™ dá»¯ liá»‡u thÃ nh 10 ká»³ dá»±a trÃªn timestamp cá»§a cÃ¡c tÆ°Æ¡ng tÃ¡c. Sau Ä‘Ã³, chÃºng tÃ´i chia cÃ¡c ká»³ cá»§a má»—i bá»™ dá»¯ liá»‡u thÃ nh cÃ¡c táº­p huáº¥n luyá»‡n, validation vÃ  testingâµ sá»­ dá»¥ng tá»· lá»‡ 8:1:1. CÃ¡ch tiáº¿p cáº­n nÃ y Ä‘áº£m báº£o ráº±ng cÃ¡c tÆ°Æ¡ng tÃ¡c Ä‘Æ°á»£c dá»± Ä‘oÃ¡n trong quÃ¡ trÃ¬nh testing xáº£y ra sau táº¥t cáº£ cÃ¡c tÆ°Æ¡ng tÃ¡c Ä‘Æ°á»£c quan sÃ¡t trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n, ngÄƒn ngá»«a rÃ² rá»‰ thÃ´ng tin giai Ä‘oáº¡n testing [21] trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n mÃ´ hÃ¬nh. Äiá»u nÃ y giá»‘ng vá»›i cÃ¡c tÃ¬nh huá»‘ng tháº¿ giá»›i thá»±c hÆ¡n [21, 58].

4.1.2 Giao thá»©c ÄÃ¡nh giÃ¡. Theo cÃ´ng trÃ¬nh trÆ°á»›c Ä‘Ã³ [23,50], Ä‘á»‘i vá»›i má»—i tÆ°Æ¡ng tÃ¡c testing, chÃºng tÃ´i Ä‘áº·t chuá»—i tÆ°Æ¡ng tÃ¡c lá»‹ch sá»­ Ä‘áº§u vÃ o lÃ  táº­p há»£p cÃ¡c tÆ°Æ¡ng tÃ¡c xáº£y ra ngay trÆ°á»›c Ä‘Ã³. CÃ¡ch tiáº¿p cáº­n nÃ y cho phÃ©p kháº£ nÄƒng bao gá»“m cÃ¡c tÆ°Æ¡ng tÃ¡c xáº£y ra trong giai Ä‘oáº¡n testing trong chuá»—i Ä‘áº§u vÃ o. Äá»ƒ Ä‘Ã¡nh giÃ¡ hiá»‡u suáº¥t cá»§a mÃ´ hÃ¬nh, chÃºng tÃ´i sá»­ dá»¥ng hai chá»‰ sá»‘ Ä‘Ã¡nh giÃ¡ thÆ°á»ng Ä‘Æ°á»£c sá»­ dá»¥ng: Hit Ratio (HR) vÃ  Normalized Discounted Cumulative Gain (NDCG), Ä‘Æ°á»£c tÃ­nh toÃ¡n báº±ng cÃ¡ch sá»­ dá»¥ng giao thá»©c all-ranking [50]. Trong giao thá»©c nÃ y, táº¥t cáº£ cÃ¡c má»¥c mÃ  ngÆ°á»i dÃ¹ng chÆ°a tÆ°Æ¡ng tÃ¡c Ä‘Æ°á»£c coi lÃ  á»©ng viÃªn tiá»m nÄƒng.

4.1.3 PhÆ°Æ¡ng phÃ¡p So sÃ¡nh. Äá»ƒ chá»©ng minh tÃ­nh Æ°u viá»‡t cá»§a phÆ°Æ¡ng phÃ¡p cá»§a chÃºng tÃ´i trong gá»£i Ã½ tuáº§n tá»±, chÃºng tÃ´i so sÃ¡nh nÃ³ vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p thÃ´ng thÆ°á»ng vÃ  dá»±a trÃªn LLM sau:

-GRU4Rec [18]. ÄÃ¢y lÃ  mÃ´ hÃ¬nh dá»±a trÃªn RNN sá»­ dá»¥ng Gated Recurrent Units (GRU) Ä‘á»ƒ mÃ£ hÃ³a tÆ°Æ¡ng tÃ¡c trong quÃ¡ khá»© cá»§a ngÆ°á»i dÃ¹ng vá»›i cÃ¡c má»¥c vÃ  táº¡o ra gá»£i Ã½ dá»±a trÃªn cÃ¡c máº«u Ä‘Ã£ há»c.

-Caser [38]. ÄÃ¢y lÃ  mÃ´ hÃ¬nh dá»±a trÃªn CNN biá»ƒu diá»…n chuá»—i cÃ¡c má»¥c gáº§n Ä‘Ã¢y nhÆ° má»™t hÃ¬nh áº£nh vÃ  sá»­ dá»¥ng cÃ¡c bá»™ lá»c tÃ­ch cháº­p theo cáº£ hÆ°á»›ng ngang vÃ  dá»c Ä‘á»ƒ náº¯m báº¯t cÃ¡c máº«u tuáº§n tá»±. Trong triá»ƒn khai cá»§a chÃºng tÃ´i, chÃºng tÃ´i sá»­ dá»¥ng má»™t bá»™ lá»c dá»c vÃ  16 bá»™ lá»c ngang vá»›i viá»‡c tÃ¬m kiáº¿m chiá»u cao trong {2, 3, 4}.

Â³ https://grouplens.org/datasets/movielens/10m/
â´ https://jmcauley.ucsd.edu/data/amazon/
âµ Do háº¡n cháº¿ vá» tá»‘c Ä‘á»™ suy luáº­n cá»§a cÃ¡c mÃ´ hÃ¬nh LLM, chÃºng tÃ´i láº¥y máº«u ngáº«u nhiÃªn 5,000 tÆ°Æ¡ng tÃ¡c validation vÃ  testing lÃ m táº­p validation vÃ  testing cuá»‘i cÃ¹ng, tÆ°Æ¡ng á»©ng.

Báº£n tháº£o Ä‘Æ°á»£c gá»­i tá»›i ACM

--- TRANG 8 ---
8 Bao vÃ  Zhang, et al.

[HÃ¬nh 2(a) - Biá»ƒu Ä‘á»“ phÃ¢n phá»‘i cÃ¡c má»¥c cÃ³ Ä‘á»™ phá»• biáº¿n khÃ¡c nhau]

[HÃ¬nh 2(b) - Biá»ƒu Ä‘á»“ sá»­ dá»¥ng GPU vÃ  thá»i gian suy luáº­n cho cÃ¡c beam size khÃ¡c nhau]

HÃ¬nh 2. Hai hÃ¬nh cho tháº¥y sá»± phÃ¢n phá»‘i cá»§a cÃ¡c má»¥c vá»›i Ä‘á»™ phá»• biáº¿n khÃ¡c nhau vÃ  sá»­ dá»¥ng GPU cÃ¹ng thá»i gian suy luáº­n cho cÃ¡c beam size khÃ¡c nhau trÃªn hai bá»™ dá»¯ liá»‡u, tÆ°Æ¡ng á»©ng.

-SASRec [23]. ÄÃ¢y lÃ  mÃ´ hÃ¬nh dá»±a trÃªn self-attention sá»­ dá»¥ng cÆ¡ cháº¿ attention nhÃ¢n quáº£ (tá»« trÃ¡i sang pháº£i) Ä‘á»ƒ há»c cÃ¡c máº«u tuáº§n tá»± vÃ  dá»± Ä‘oÃ¡n má»¥c tiáº¿p theo.

-P5 [17]. PhÆ°Æ¡ng phÃ¡p nÃ y sá»­ dá»¥ng mÃ´ hÃ¬nh T5 [36] lÃ m mÃ´ hÃ¬nh backbone vÃ  táº­n dá»¥ng sá»± káº¿t há»£p cá»§a ID má»¥c vÃ  template ngÃ´n ngá»¯ tá»± nhiÃªn Ä‘á»ƒ tráº£i qua continued pre-training cho cÃ¡c nhiá»‡m vá»¥ gá»£i Ã½ khÃ¡c nhauâ¶.

-DROS [50]. ÄÃ¢y lÃ  phÆ°Æ¡ng phÃ¡p gá»£i Ã½ tuáº§n tá»± state-of-the-art sá»­ dá»¥ng cÃ¡c ká»¹ thuáº­t tá»‘i Æ°u hÃ³a robust phÃ¢n phá»‘i Ä‘á»ƒ tÄƒng cÆ°á»ng Ä‘á»™ máº¡nh máº½ cá»§a gá»£i Ã½ chá»‘ng láº¡i nhá»¯ng thay Ä‘á»•i phÃ¢n phá»‘i.

-GPT4Rec-LLaMA [27] lÃ  phiÃªn báº£n cáº£i tiáº¿n cá»§a phÆ°Æ¡ng phÃ¡p gá»£i Ã½ dá»±a trÃªn mÃ´ hÃ¬nh ngÃ´n ngá»¯, GPT4Rec. PhÆ°Æ¡ng phÃ¡p gá»‘c sá»­ dá»¥ng GPT-2 Ä‘á»ƒ táº¡o ra "search queries" giáº£ Ä‘á»‹nh dá»±a trÃªn dá»¯ liá»‡u lá»‹ch sá»­ cá»§a ngÆ°á»i dÃ¹ng, sau Ä‘Ã³ Ä‘Æ°á»£c tÃ¬m kiáº¿m báº±ng cÃ¡ch sá»­ dá»¥ng cÃ´ng cá»¥ tÃ¬m kiáº¿m BM25â· Ä‘á»ƒ truy xuáº¥t cÃ¡c má»¥c Ä‘Æ°á»£c gá»£i Ã½. Äá»ƒ Ä‘áº£m báº£o so sÃ¡nh cÃ´ng báº±ng, chÃºng tÃ´i Ä‘Ã£ thay tháº¿ mÃ´ hÃ¬nh GPT-2 báº±ng mÃ´ hÃ¬nh LLaMA-7B vÃ  thá»±c hiá»‡n Ä‘iá»u chá»‰nh mÃ´ hÃ¬nh báº±ng ká»¹ thuáº­t LoRA [20].

ChÃºng tÃ´i chá»§ yáº¿u sá»­ dá»¥ng cÃ¡c LLM chá»‰ decoder lÃ m mÃ´ hÃ¬nh LLM backbone trong phÆ°Æ¡ng phÃ¡p BIGRec cá»§a chÃºng tÃ´i, do vai trÃ² ná»•i báº­t cá»§a chÃºng trong lÄ©nh vá»±c LLM. Cá»¥ thá»ƒ, chÃºng tÃ´i Ä‘Ã£ chá»n LLaMA-7B lÃ m lá»±a chá»n máº·c Ä‘á»‹nh cho nghiÃªn cá»©u nÃ y. NgoÃ i GPT4Rec, cÃ²n cÃ³ cÃ¡c phÆ°Æ¡ng phÃ¡p gá»£i Ã½ dá»±a trÃªn LLM khÃ¡c, cháº³ng háº¡n nhÆ° TALLRec [3]. Tuy nhiÃªn, vÃ¬ nhá»¯ng phÆ°Æ¡ng phÃ¡p nÃ y khÃ´ng Ã¡p dá»¥ng Ä‘Æ°á»£c cho cÃ i Ä‘áº·t all-ranking cá»§a chÃºng tÃ´i, chÃºng tÃ´i khÃ´ng so sÃ¡nh chÃºng trong nghiÃªn cá»©u cá»§a chÃºng tÃ´i.

4.1.4 Chi tiáº¿t Triá»ƒn khai. ChÃºng tÃ´i triá»ƒn khai táº¥t cáº£ cÃ¡c phÆ°Æ¡ng phÃ¡p cá»§a chÃºng tÃ´i báº±ng PyTorch. Äá»ƒ tiá»n xá»­ lÃ½ dá»¯ liá»‡u, Ä‘áº§u tiÃªn chÃºng tÃ´i pad lá»‹ch sá»­ tÆ°Æ¡ng tÃ¡c ngÆ°á»i dÃ¹ng vá»›i Ä‘á»™ dÃ i nhá» hÆ¡n 11 Ä‘áº¿n Ä‘á»™ dÃ i cá»‘ Ä‘á»‹nh lÃ  11. Sau Ä‘Ã³, chÃºng tÃ´i sá»­ dá»¥ng sliding window Ä‘á»™ dÃ i 11 Ä‘á»ƒ trÃ­ch xuáº¥t cÃ¡c chuá»—i, trong Ä‘Ã³ má»¥c cuá»‘i cÃ¹ng trong má»—i chuá»—i Ä‘Æ°á»£c sá»­ dá»¥ng lÃ m má»¥c tiÃªu dá»± Ä‘oÃ¡n, vÃ  cÃ¡c má»¥c trÆ°á»›c Ä‘Ã³ tá»« chuá»—i tÆ°Æ¡ng tÃ¡c quÃ¡ khá»© cho nÃ³. Äá»‘i vá»›i táº¥t cáº£ cÃ¡c mÃ´ hÃ¬nh thÃ´ng thÆ°á»ng, chÃºng tÃ´i tá»‘i Æ°u hÃ³a chÃºng báº±ng cÃ¡ch sá»­ dá»¥ng binary cross-entropy loss vÃ  láº¥y máº«u negative samples Ä‘á»“ng Ä‘á»u. ChÃºng tÃ´i sá»­ dá»¥ng Adam [24] lÃ m optimizer vá»›i learning rate Ä‘Æ°á»£c Ä‘iá»u chá»‰nh lÃ  1e-3, batch size lÃ  1024 vÃ  Ä‘iá»u chá»‰nh weight decay trong pháº¡m vi [1e-2,1e-3,1e-4,1e-5,1e-6,1e-7]. Vá» cÃ¡c siÃªu tham sá»‘ cá»§a kiáº¿n trÃºc mÃ´ hÃ¬nh thÃ´ng thÆ°á»ng, chÃºng tÃ´i Ä‘áº·t embedding size cá»§a chÃºng lÃ  64 vÃ  tá»· lá»‡ dropout lÃ  0.1. NhÆ° Ä‘Æ°á»£c gá»£i Ã½ bá»Ÿi cÃ¡c bÃ i bÃ¡o gá»‘c, chÃºng tÃ´i chá»‰ sá»­ dá»¥ng má»™t lá»›p GRU cho GRU4Rec; Ä‘á»‘i vá»›i SASRec, chÃºng tÃ´i Ä‘áº·t sá»‘ lÆ°á»£ng self-attention heads vÃ  blocks lÃ  1. ChÃºng tÃ´i triá»ƒn khai DROS dá»±a trÃªn SASRec, vÃ¬ nÃ³ hoáº¡t Ä‘á»™ng tá»‘t nháº¥t trong háº§u háº¿t cÃ¡c tÃ¬nh huá»‘ng trong sá»‘ ba phÆ°Æ¡ng phÃ¡p gá»£i Ã½ tuáº§n tá»± thÃ´ng thÆ°á»ng. Äá»‘i vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p dá»±a trÃªn LLM, chÃºng tÃ´i theo thiáº¿t láº­p Alpaca [39], trá»±c tiáº¿p Ä‘áº·t learning rate lÃ  1e-4 vÃ  sá»­ dá»¥ng optimizer AdamW [31]. Trong quÃ¡ trÃ¬nh táº¡o sinh, do

â¶ Äá»ƒ so sÃ¡nh cÃ´ng báº±ng, chÃºng tÃ´i chá»‰ giá»¯ láº¡i nhiá»‡m vá»¥ gá»£i Ã½ tuáº§n tá»± vÃ  cÃ¡c template Ä‘a dáº¡ng tÆ°Æ¡ng á»©ng trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n.
â· ChÃºng tÃ´i sá»­ dá»¥ng gÃ³i Rank-BM25 táº¡i https://github.com/dorianbrown/rank_bm25.

Báº£n tháº£o Ä‘Æ°á»£c gá»­i tá»›i ACM

--- TRANG 9 ---
Má»™t MÃ´ hÃ¬nh Grounding Hai BÆ°á»›c cho MÃ´ hÃ¬nh NgÃ´n ngá»¯ Lá»›n trong Há»‡ thá»‘ng Gá»£i Ã½ 9

Báº£ng 2. So sÃ¡nh hiá»‡u suáº¥t mÃ´ hÃ¬nh trong thiáº¿t láº­p huáº¥n luyá»‡n few-shot (1024 máº«u) vá»›i NDCG@K (NG@K) vÃ  HR@K (HR@K) lÃ m chá»‰ sá»‘. Káº¿t quáº£ tá»‘t nháº¥t Ä‘Æ°á»£c Ä‘Ã¡nh dáº¥u báº±ng chá»¯ Ä‘áº­m, vÃ  káº¿t quáº£ tá»‘i Æ°u thá»© hai Ä‘Æ°á»£c gáº¡ch chÃ¢n. 'Improve' Ä‘á» cáº­p Ä‘áº¿n sá»± cáº£i thiá»‡n tÆ°Æ¡ng Ä‘á»‘i cá»§a BIGRec so vá»›i baseline tá»‘t nháº¥t.

[Báº£ng chi tiáº¿t vá»›i káº¿t quáº£ hiá»‡u suáº¥t cho Movie vÃ  Game datasets]

chi phÃ­ tÃ­nh toÃ¡n vÃ  suy luáº­n Ä‘Ã¡ng ká»ƒ liÃªn quan Ä‘áº¿n viá»‡c sá»­ dá»¥ng rá»™ng rÃ£i GPU Ä‘Æ°á»£c hiá»ƒn thá»‹ trong HÃ¬nh 2(b), chÃºng tÃ´i theo thiáº¿t láº­p cá»§a cÃ´ng trÃ¬nh trÆ°á»›c Ä‘Ã³ [5, 8, 41] vÃ  sá»­ dá»¥ng beam size lÃ  4 Ä‘á»ƒ táº¡o ra Ä‘áº§u ra cÃ³ Ã½ nghÄ©a.

Äá»‘i vá»›i cÃ¡c siÃªu tham sá»‘ cá»§a BM25, chÃºng tÃ´i theo pháº¡m vi Ä‘iá»u chá»‰nh Ä‘Æ°á»£c cung cáº¥p trong bÃ i bÃ¡o GPT4Rec [27]. Äá»ƒ lá»±a chá»n mÃ´ hÃ¬nh, chÃºng tÃ´i sá»­ dá»¥ng chiáº¿n lÆ°á»£c early stop vá»›i patience lÃ  20 epochs cho cÃ¡c phÆ°Æ¡ng phÃ¡p baseline vÃ  5 epochs cho cÃ¡c phÆ°Æ¡ng phÃ¡p dá»±a trÃªn LLM. NgoÃ i ra, chÃºng tÃ´i bÃ¡o cÃ¡o káº¿t quáº£ trung bÃ¬nh cho ba random seeds. Äá»‘i vá»›i siÃªu tham sá»‘ Î³ trong Eq. (3), do cÃ¡c phÆ°Æ¡ng phÃ¡p tÃ­nh toÃ¡n khÃ¡c nhau Ä‘Æ°á»£c sá»­ dá»¥ng bá»Ÿi cÃ¡c mÃ´ hÃ¬nh truyá»n thá»‘ng vÃ  mÃ´ hÃ¬nh gá»£i Ã½ dá»±a trÃªn LLM, khi káº¿t há»£p thÃ´ng tin, chÃºng tÃ´i Ä‘Ã£ tiáº¿n hÃ nh tÃ¬m kiáº¿m chi tiáº¿t Ä‘á»ƒ tÃ­ch há»£p cÃ¢n báº±ng cá»§a cáº£ hai phÆ°Æ¡ng phÃ¡pâ¸.

4.2 So sÃ¡nh Hiá»‡u suáº¥t vá»›i Dá»¯ liá»‡u Huáº¥n luyá»‡n Háº¡n cháº¿ (RQ1)

Äáº§u tiÃªn chÃºng tÃ´i theo cÃ´ng trÃ¬nh hiá»‡n táº¡i [3] Ä‘á»ƒ nghiÃªn cá»©u hiá»‡u quáº£ cá»§a phÆ°Æ¡ng phÃ¡p vá»›i dá»¯ liá»‡u huáº¥n luyá»‡n háº¡n cháº¿ (1024 Ä‘iá»ƒm huáº¥n luyá»‡n) trÃªn má»—i bá»™ dá»¯ liá»‡u. ChÃºng tÃ´i so sÃ¡nh nÃ³ vá»›i cÃ¡c baseline Ä‘Æ°á»£c huáº¥n luyá»‡n vá»›i sá»‘ lÆ°á»£ng máº«u huáº¥n luyá»‡n tÆ°Æ¡ng Ä‘Æ°Æ¡ng. Káº¿t quáº£ so sÃ¡nh Ä‘Æ°á»£c tÃ³m táº¯t trong Báº£ng 2, tá»« Ä‘Ã³ chÃºng tÃ´i rÃºt ra cÃ¡c quan sÃ¡t chÃ­nh sau:

â€¢ Khi dá»¯ liá»‡u huáº¥n luyá»‡n bá»‹ háº¡n cháº¿, cÃ¡c baseline tuáº§n tá»± thÃ´ng thÆ°á»ng (GRU4Rec, Caser, SASRec) thá»ƒ hiá»‡n hiá»‡u suáº¥t tá»“i tá»‡ hÆ¡n Ä‘Ã¡ng ká»ƒ so vá»›i BIGRec Ä‘Æ°á»£c triá»ƒn khai vá»›i LLM. Nhá»¯ng káº¿t quáº£ nÃ y khÃ´ng gÃ¢y ngáº¡c nhiÃªn vÃ¬ cÃ¡c baseline nÃ y dá»±a vÃ o ID embeddings Ä‘á»ƒ xÃ¢y dá»±ng mÃ´ hÃ¬nh gá»£i Ã½, Ä‘iá»u nÃ y khÃ³ há»c tá»‘t vá»›i dá»¯ liá»‡u háº¡n cháº¿. NgÆ°á»£c láº¡i, BIGRec nhanh chÃ³ng táº­n dá»¥ng kiáº¿n thá»©c ngá»¯ nghÄ©a cá»§a LLM thu Ä‘Æ°á»£c trong giai Ä‘oáº¡n pre-training Ä‘á»ƒ Ä‘áº¡t Ä‘Æ°á»£c gá»£i Ã½ hiá»‡u quáº£. Nhá»¯ng phÃ¡t hiá»‡n nÃ y chá»©ng minh tÃ­nh Æ°u viá»‡t cá»§a BIGRec so vá»›i cÃ¡c mÃ´ hÃ¬nh gá»£i Ã½ truyá»n thá»‘ng khi xá»­ lÃ½ dá»¯ liá»‡u huáº¥n luyá»‡n háº¡n cháº¿. HÆ¡n ná»¯a, sá»± cáº£i thiá»‡n cá»§a BIGRec so vá»›i cÃ¡c baseline nÃ y á»Ÿ cÃ¡c vá»‹ trÃ­ Ä‘Æ°á»£c xáº¿p háº¡ng cao hÆ¡n nhiá»u, cho tháº¥y BIGRec cÃ³ thá»ƒ cÃ³ xu hÆ°á»›ng xáº¿p háº¡ng cÃ¡c má»¥c mÃ  ngÆ°á»i dÃ¹ng quan tÃ¢m á»Ÿ cÃ¡c vá»‹ trÃ­ cao hÆ¡n.

â€¢ Máº·c dÃ¹ GPT4Rec-LLaMA cÅ©ng dá»±a trÃªn LLM, nÃ³ thá»ƒ hiá»‡n hiá»‡u suáº¥t kÃ©m so vá»›i BIGRec. ChÃºng tÃ´i cho ráº±ng Ä‘iá»u nÃ y do BM25, cÅ©ng cÃ³ thá»ƒ Ä‘Æ°á»£c coi lÃ  má»™t phÆ°Æ¡ng phÃ¡p Ä‘á»ƒ ground Ä‘áº§u ra LLM vÃ o cÃ¡c má»¥c thá»±c táº¿, khÃ´ng phÃ¹ há»£p vá»›i nhiá»‡m vá»¥ gá»£i Ã½. BM25 lÃ  má»™t cÃ´ng cá»¥ truy xuáº¥t Ä‘Æ°á»£c thiáº¿t káº¿ cho vÄƒn báº£n cáº¥p Ä‘á»™ tÃ i liá»‡u. Tuy nhiÃªn, Ä‘á»‘i vá»›i hai bá»™ dá»¯ liá»‡u Ä‘Æ°á»£c sá»­ dá»¥ng trong nghiÃªn cá»©u cá»§a chÃºng tÃ´i, cÃ¡c queries trong GPT4Rec (tiÃªu Ä‘á» má»¥c) ráº¥t ngáº¯n. Káº¿t quáº£ lÃ , BM25 dá»… bá»‹ áº£nh hÆ°á»Ÿng bá»Ÿi tÃ¡c Ä‘á»™ng cá»§a nhiá»…u tá»« táº§n suáº¥t tháº¥p, khiáº¿n viá»‡c truy xuáº¥t chÃ­nh xÃ¡c cÃ¡c má»¥c liÃªn quan trá»Ÿ nÃªn khÃ³ khÄƒn.

â€¢ Sá»± cáº£i thiá»‡n cá»§a BIGRec so vá»›i cÃ¡c mÃ´ hÃ¬nh thÃ´ng thÆ°á»ng cao hÆ¡n Ä‘Ã¡ng ká»ƒ Ä‘á»‘i vá»›i bá»™ dá»¯ liá»‡u Game so vá»›i bá»™ dá»¯ liá»‡u Movie. Sá»± khÃ¡c biá»‡t nÃ y cÃ³ thá»ƒ do cÃ¡c thuá»™c tÃ­nh khÃ¡c nhau cá»§a thiÃªn vá»‹ Ä‘á»™ phá»• biáº¿n giá»¯a hai bá»™ dá»¯ liá»‡u. CÃ¡c phÆ°Æ¡ng phÃ¡p thÃ´ng thÆ°á»ng cÃ³ xu hÆ°á»›ng náº¯m báº¯t thiÃªn vá»‹ phá»• biáº¿n, trong khi BIGRec Ã­t bá»‹ áº£nh hÆ°á»Ÿng bá»Ÿi thiÃªn vá»‹ Ä‘á»™ phá»• biáº¿n. Do Ä‘Ã³, cÃ¡c phÆ°Æ¡ng phÃ¡p thÃ´ng thÆ°á»ng cÃ³ thá»ƒ hoáº¡t Ä‘á»™ng tá»‘t hÆ¡n trÃªn bá»™ dá»¯ liá»‡u Movie, trong Ä‘Ã³ cÃ¡c má»¥c phá»• biáº¿n Ä‘Ã³ng vai trÃ² thá»‘ng trá»‹ hÆ¡n nhÆ° Ä‘Æ°á»£c chá»©ng minh bá»Ÿi HÃ¬nh 2(a).

HÆ¡n ná»¯a, chÃºng tÃ´i cÅ©ng chá»©ng minh tiá»m nÄƒng cá»§a BIGRec Ä‘á»ƒ grounding vÃ o cÃ¡c khÃ´ng gian má»¥c thá»±c táº¿ khÃ¡c nhau Ä‘á»“ng thá»i. Äá»ƒ khÃ¡m phÃ¡ Ä‘iá»u nÃ y, chÃºng tÃ´i ngáº«u nhiÃªn chá»n 1024 máº«u tá»« hai miá»n (Movie vÃ  Game) Ä‘á»ƒ huáº¥n luyá»‡n mÃ´ hÃ¬nh cá»§a chÃºng tÃ´i vÃ  kiá»ƒm tra nÃ³ trÃªn cÃ¡c táº­p kiá»ƒm tra cá»§a hai miá»n, tÆ°Æ¡ng á»©ng. NhÆ° Ä‘Æ°á»£c hiá»ƒn thá»‹ trong HÃ¬nh 3, káº¿t quáº£ chá»©ng minh ráº±ng BIGRec Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn dá»¯ liá»‡u hai miá»n hoáº¡t Ä‘á»™ng tÆ°Æ¡ng Ä‘Æ°Æ¡ng trÃªn má»—i miá»n riÃªng láº» so vá»›i khi nÃ³ Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn dá»¯ liá»‡u cá»§a miá»n Ä‘Æ¡n. Nhá»¯ng phÃ¡t hiá»‡n nÃ y gá»£i Ã½ ráº±ng BIGRec cÃ³ thá»ƒ Ä‘á»“ng thá»i ground LLM vÃ o cÃ¡c khÃ´ng gian má»¥c thá»±c táº¿ khÃ¡c nhau, Ã­t nháº¥t á»Ÿ cáº¥p Ä‘á»™ cÃ¡c miá»n khÃ¡c nhau.

4.3 So sÃ¡nh Hiá»‡u suáº¥t vá»›i Baselines Ä‘Æ°á»£c Huáº¥n luyá»‡n vá»›i Nhiá»u Dá»¯ liá»‡u hÆ¡n (RQ2)

Dá»±a trÃªn nhá»¯ng cáº£i thiá»‡n hiá»‡u suáº¥t Ä‘Ã¡ng ká»ƒ Ä‘Æ°á»£c chá»©ng minh bá»Ÿi BIGRec so vá»›i cÃ¡c baseline Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn dá»¯ liá»‡u háº¡n cháº¿, chÃºng tÃ´i tiáº¿p tá»¥c hiá»ƒu sá»± chÃªnh lá»‡ch giá»¯a BIGRec Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn dá»¯ liá»‡u háº¡n cháº¿ vÃ  cÃ¡c baseline Ä‘Æ°á»£c huáº¥n luyá»‡n vá»›i lÆ°á»£ng dá»¯ liá»‡u lá»›n hÆ¡n Ä‘Ã¡ng ká»ƒ (100 hoáº·c tháº­m chÃ­ 1.000 láº§n nhiá»u hÆ¡n) Ä‘á»ƒ khÃ¡m phÃ¡ má»©c Ä‘á»™ cá»§a khoáº£ng cÃ¡ch nÃ y.

Báº£ng 3 chá»©a káº¿t quáº£ cá»§a cÃ¡c baseline Ä‘Æ°á»£c huáº¥n luyá»‡n vá»›i nhiá»u dá»¯ liá»‡u hÆ¡n, bao gá»“m hÆ¡n 7 triá»‡u chuá»—i cho Movie vÃ  120 nghÃ¬n cho Game, cÃ¹ng vá»›i káº¿t quáº£ cá»§a BIGRec Ä‘Æ°á»£c huáº¥n luyá»‡n vá»›i chá»‰ 1024 máº«uâ¹. Tá»« báº£ng, chÃºng tÃ´i tháº¥y ráº±ng, so vá»›i cÃ¡c baseline thÃ´ng thÆ°á»ng (loáº¡i trá»« DROS) trÃªn dá»¯ liá»‡u Movie, BIGRec thá»ƒ hiá»‡n hiá»‡u suáº¥t tá»‘t hÆ¡n á»Ÿ vá»‹ trÃ­ Ä‘áº§u cá»§a danh sÃ¡ch gá»£i Ã½, nhÆ°ng hoáº¡t Ä‘á»™ng tá»‡ hÆ¡n Ä‘á»‘i vá»›i cÃ¡c vá»‹ trÃ­ tÆ°Æ¡ng Ä‘á»‘i tháº¥p cá»§a danh sÃ¡ch gá»£i Ã½. TrÃ¡i vá»›i káº¿t quáº£ thu Ä‘Æ°á»£c tá»« bá»™ dá»¯ liá»‡u Movie, phÆ°Æ¡ng phÃ¡p cá»§a chÃºng tÃ´i liÃªn tá»¥c chá»©ng minh hiá»‡u suáº¥t vÆ°á»£t trá»™i so vá»›i cÃ¡c mÃ´ hÃ¬nh truyá»n thá»‘ng (loáº¡i trá»« DROS) khi Ã¡p dá»¥ng cho dá»¯ liá»‡u Game. So sÃ¡nh vá»›i

â¹ Do háº¡n cháº¿ vá» tÃ i nguyÃªn tÃ­nh toÃ¡n, chÃºng tÃ´i chá»‰ trÃ¬nh bÃ y káº¿t quáº£ cá»§a cÃ¡c baseline tiÃªu tá»‘n tÃ i nguyÃªn tÃ­nh toÃ¡n Ä‘Ã¡ng ká»ƒ trÃªn bá»™ dá»¯ liá»‡u Game.

Báº£n tháº£o Ä‘Æ°á»£c gá»­i tá»›i ACM

--- TRANG 10 ---
10 Bao vÃ  Zhang, et al.

[HÃ¬nh 3. So sÃ¡nh hiá»‡u suáº¥t cá»§a BIGRec Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn dá»¯ liá»‡u Ä‘a miá»n (labeled as "Multi") vÃ  BIGRec Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn dá»¯ liá»‡u miá»n Ä‘Ã­ch Ä‘Æ¡n (labeled as "Single"), Ä‘Æ°á»£c hiá»ƒn thá»‹ cho NDCG@K trÃªn cÃ¡c miá»n Movie vÃ  Game.]

phÆ°Æ¡ng phÃ¡p truyá»n thá»‘ng Ä‘Æ°á»£c tá»‘i Æ°u hÃ³a ká»¹ lÆ°á»¡ng vÃ  state-of-the-art DROS, BIGRec Ä‘Æ°á»£c huáº¥n luyá»‡n vá»›i chá»‰ 1024 máº«u váº«n cÃ³ thá»ƒ cho tháº¥y hiá»‡u suáº¥t tÆ°Æ¡ng Ä‘Æ°Æ¡ng trong háº§u háº¿t cÃ¡c trÆ°á»ng há»£p. Dá»±a trÃªn káº¿t quáº£, chÃºng tÃ´i rÃºt ra hai káº¿t luáº­n:

â€¢ PhÆ°Æ¡ng phÃ¡p cá»§a chÃºng tÃ´i, BIGRec, Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn má»™t táº­p con tÆ°Æ¡ng Ä‘á»‘i nhá» cá»§a bá»™ dá»¯ liá»‡u chá»‰ vá»›i 1.024 máº«u, Ä‘Ã£ cho tháº¥y hiá»‡u suáº¥t tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i cÃ¡c mÃ´ hÃ¬nh thÃ´ng thÆ°á»ng Ä‘Æ°á»£c huáº¥n luyá»‡n vá»›i sá»‘ lÆ°á»£ng dá»¯ liá»‡u lá»›n hÆ¡n Ä‘Ã¡ng ká»ƒ, vá»›i 100 hoáº·c tháº­m chÃ­ 1.000 láº§n lá»›n hÆ¡n, Ä‘áº·c biá»‡t khi tÃ i nguyÃªn gá»£i Ã½ (exposure) bá»‹ háº¡n cháº¿. Nhá»¯ng phÃ¡t hiá»‡n nÃ y lÃ m ná»•i báº­t tÃ­nh thá»±c táº¿ cá»§a viá»‡c sá»­ dá»¥ng LLM cho há»‡ thá»‘ng gá»£i Ã½. Äá»“ng thá»i, káº¿t quáº£ cÅ©ng gá»£i Ã½ ráº±ng cÃ³ tiá»m nÄƒng Ä‘á»ƒ tÄƒng cÆ°á»ng thÃªm hiá»‡u suáº¥t cá»§a BIGRec báº±ng cÃ¡ch tÄƒng kÃ­ch thÆ°á»›c táº­p huáº¥n luyá»‡n vÃ  má»Ÿ rá»™ng pháº¡m vi cÃ¡c má»¥c mÃ  nÃ³ Ä‘Ã£ gáº·p trong quÃ¡ trÃ¬nh grounding (xem BIGRec (full) trong Báº£ng 3).

â€¢ Khi so sÃ¡nh vá»›i bá»™ dá»¯ liá»‡u Game, bá»™ dá»¯ liá»‡u Movie thá»ƒ hiá»‡n máº­t Ä‘á»™ cao hÆ¡n vÃ  dá»… bá»‹ thiÃªn vá»‹ Ä‘á»™ phá»• biáº¿n hÆ¡n (nhÆ° Ä‘Æ°á»£c chá»©ng minh bá»Ÿi hiá»‡u suáº¥t cá»§a cÃ¡c phÆ°Æ¡ng phÃ¡p Most-Pop trÃªn hai bá»™ dá»¯ liá»‡u vÃ  HÃ¬nh 2(a)). Sá»± khÃ¡c biá»‡t trong má»©c Ä‘á»™ cáº£i thiá»‡n hiá»‡u suáº¥t cá»§a BIGRec giá»¯a hai bá»™ dá»¯ liá»‡u cho tháº¥y ráº±ng BIGRec hoáº¡t Ä‘á»™ng Ä‘áº·c biá»‡t tá»‘t trong cÃ¡c tÃ¬nh huá»‘ng mÃ  dá»¯ liá»‡u khan hiáº¿m vÃ  hoáº¡t Ä‘á»™ng hiá»‡u quáº£ vá»›i sá»± phá»¥ thuá»™c Ã­t hÆ¡n vÃ o thiÃªn vá»‹ Ä‘á»™ phá»• biáº¿n.

4.4 Hiá»‡u suáº¥t cá»§a BIGRec vá»›i Viá»‡c TÄƒng Máº«u Huáº¥n luyá»‡n (RQ3)

Khi so sÃ¡nh káº¿t quáº£ cá»§a cÃ¡c phÆ°Æ¡ng phÃ¡p dá»±a trÃªn ID truyá»n thá»‘ng (nhÆ° SASRec vÃ  DROS) trong Báº£ng 2 vÃ  Báº£ng 3, rÃµ rÃ ng lÃ  viá»‡c tÄƒng dá»¯ liá»‡u huáº¥n luyá»‡n cÃ³ thá»ƒ nÃ¢ng cao hiá»‡u suáº¥t mÃ´ hÃ¬nh. Sá»± cáº£i thiá»‡n nÃ y cÃ³ thá»ƒ Ä‘Æ°á»£c

Báº£n tháº£o Ä‘Æ°á»£c gá»­i tá»›i ACM

--- TRANG 11 ---
Má»™t MÃ´ hÃ¬nh Grounding Hai BÆ°á»›c cho MÃ´ hÃ¬nh NgÃ´n ngá»¯ Lá»›n trong Há»‡ thá»‘ng Gá»£i Ã½ 11

Báº£ng 3. So sÃ¡nh hiá»‡u suáº¥t giá»¯a cÃ¡c baseline Ä‘Æ°á»£c huáº¥n luyá»‡n vá»›i dá»¯ liá»‡u Ä‘áº§y Ä‘á»§, BIGRec (0) khÃ´ng huáº¥n luyá»‡n mÃ´ hÃ¬nh, BIGRec (1024) Ä‘Æ°á»£c huáº¥n luyá»‡n vá»›i 1024 máº«u, vÃ  BIGRec (full) Ä‘Æ°á»£c huáº¥n luyá»‡n vá»›i dá»¯ liá»‡u Ä‘áº§y Ä‘á»§. "Most-Pop" Ä‘á» cáº­p Ä‘áº¿n phÆ°Æ¡ng phÃ¡p gá»£i Ã½ cÃ¡c má»¥c phá»• biáº¿n nháº¥t. Káº¿t quáº£ tá»‘t nháº¥t Ä‘Æ°á»£c Ä‘Ã¡nh dáº¥u báº±ng chá»¯ Ä‘áº­m vÃ  káº¿t quáº£ tá»‘i Æ°u thá»© hai Ä‘Æ°á»£c gáº¡ch chÃ¢n. BIGRec (full) trÃªn Movie bá»‹ bá» qua do chi phÃ­ tÃ­nh toÃ¡n cao.

[Báº£ng chi tiáº¿t vá»›i káº¿t quáº£ hiá»‡u suáº¥t cho Movie vÃ  Game datasets vá»›i cÃ¡c cáº¥u hÃ¬nh khÃ¡c nhau]

quy cho thá»±c táº¿ ráº±ng viá»‡c tÄƒng dá»¯ liá»‡u huáº¥n luyá»‡n há»— trá»£ trong viá»‡c thu tháº­p thÃ´ng tin thá»‘ng kÃª (vÃ­ dá»¥, Ä‘á»™ phá»• biáº¿n vÃ  thÃ´ng tin collaborative) chá»©a trong bá»™ dá»¯ liá»‡u, Ä‘iá»u nÃ y Ä‘Æ°á»£c chá»©ng minh lÃ  cÃ³ lá»£i cho gá»£i Ã½ [37, 57].

Äá»ƒ Ä‘iá»u tra liá»‡u LLM cÅ©ng cÃ³ thá»ƒ náº¯m báº¯t thÃ´ng tin thá»‘ng kÃª cá»¥c bá»™ trong bá»™ dá»¯ liá»‡u báº±ng cÃ¡ch tÄƒng lÆ°á»£ng dá»¯ liá»‡u huáº¥n luyá»‡n Ä‘á»ƒ tÄƒng cÆ°á»ng hiá»‡u suáº¥t hay khÃ´ng, chÃºng tÃ´i phÃ¢n tÃ­ch hiá»‡u suáº¥t cá»§a BIGRec khi tÄƒng dá»¯ liá»‡u huáº¥n luyá»‡n trÃªn Game. HÃ¬nh 4 minh há»a Ä‘Æ°á»ng cong hiá»‡u suáº¥t khi tÄƒng dá»¯ liá»‡u huáº¥n luyá»‡n, cÅ©ng nhÆ° Ä‘Æ°á»ng cong mÃ´ táº£ sá»± cáº£i thiá»‡n hiá»‡u suáº¥t so vá»›i tráº¡ng thÃ¡i ban Ä‘áº§u. NhÆ° Ä‘Æ°á»£c hiá»ƒn thá»‹ trong hÃ¬nh, so vá»›i cÃ¡c mÃ´ hÃ¬nh gá»£i Ã½ truyá»n thá»‘ng, viá»‡c tÄƒng khá»‘i lÆ°á»£ng dá»¯ liá»‡u cÃ³ tÃ¡c Ä‘á»™ng háº¡n cháº¿ Ä‘áº¿n sá»± cáº£i thiá»‡n hiá»‡u suáº¥t cá»§a BIGRec. ChÃºng tÃ´i Ä‘oÃ¡n ráº±ng BIGRec Ã­t tÃ­ch cá»±c hÆ¡n trong viá»‡c náº¯m báº¯t thá»‘ng kÃª cÃ³ trong bá»™ dá»¯ liá»‡u, vÃ  thay vÃ o Ä‘Ã³ thÃ­ch sá»­ dá»¥ng thÃ´ng tin ngá»¯ nghÄ©a cá»§a LLM Ä‘á»ƒ hoÃ n thÃ nh nhiá»‡m vá»¥ trong khi bá» qua thÃ´ng tin thá»‘ng kÃª cÃ³ giÃ¡ trá»‹. Do Ä‘Ã³, viá»‡c tÄƒng dá»¯ liá»‡u huáº¥n luyá»‡n khÃ´ng thá»ƒ nÃ¢ng cao Ä‘Ã¡ng ká»ƒ hiá»‡u suáº¥t BIGRec so vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p dá»±a trÃªn ID truyá»n thá»‘ng.

4.5 Hiá»‡u suáº¥t cá»§a Viá»‡c Giá»›i thiá»‡u ThÃ´ng tin Thá»‘ng kÃª CÃ³ giÃ¡ trá»‹ (RQ4)

Nhá»¯ng suy Ä‘oÃ¡n nÃªu trÃªn gá»£i Ã½ ráº±ng BIGRec phá»¥ thuá»™c nhiá»u vÃ o thÃ´ng tin ngá»¯ nghÄ©a Ä‘Æ°á»£c lÆ°u trá»¯ trong LLM trong khi bá» qua thÃ´ng tin thá»‘ng kÃª cÃ³ giÃ¡ trá»‹ cá»§a bá»™ dá»¯ liá»‡u. DÆ°á»›i Ã¡nh sÃ¡ng nÃ y, chÃºng tÃ´i tin ráº±ng viá»‡c káº¿t há»£p thÃ´ng tin thá»‘ng kÃª cÃ³ giÃ¡ trá»‹ má»™t cÃ¡ch thÃ­ch há»£p cÃ³ thá»ƒ nÃ¢ng cao kháº£ nÄƒng gá»£i Ã½ cá»§a BIGRec. CÃ¢n nháº¯c lÃ  thÃ´ng tin cÃ³ thá»ƒ bá»‹ BIGRec bá» qua trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n nhÆ°ng thá»±c sá»± mÃ´ táº£ má»™t sá»‘ Ä‘áº·c Ä‘iá»ƒm há»¯u Ã­ch cá»§a cÃ¡c má»¥c thá»±c táº¿, vÃ  do Ä‘Ã³ viá»‡c káº¿t há»£p nÃ³ cÃ³ thá»ƒ tÄƒng cÆ°á»ng viá»‡c grounding cá»§a BIGRec vÃ o khÃ´ng gian má»¥c thá»±c táº¿. Äá»ƒ xÃ¡c minh Ä‘iá»u nÃ y, chÃºng tÃ´i tiáº¿n hÃ nh thÃ­ nghiá»‡m báº±ng cÃ¡ch giá»›i thiá»‡u hai loáº¡i thÃ´ng tin thá»‘ng kÃª: thÃ´ng tin Ä‘á»™ phá»• biáº¿n vÃ  thÃ´ng tin collaborative, tÆ°Æ¡ng á»©ng. LÆ°u Ã½ ráº±ng hai loáº¡i thÃ´ng tin nÃ y Ä‘Æ°á»£c cÃ´ng nháº­n lÃ  cÃ³ giÃ¡ trá»‹ cho há»‡ thá»‘ng gá»£i Ã½ [37, 57].

â€¢ Giá»›i thiá»‡u thÃ´ng tin Ä‘á»™ phá»• biáº¿n. Äáº§u tiÃªn chÃºng tÃ´i nghiÃªn cá»©u hiá»‡u suáº¥t cá»§a BIGRec khi giá»›i thiá»‡u thÃ´ng tin Ä‘á»™ phá»• biáº¿n cá»§a bá»™ dá»¯ liá»‡u huáº¥n luyá»‡n báº±ng phÆ°Æ¡ng phÃ¡p trong Eq. (3). ChÃºng tÃ´i tiáº¿n hÃ nh thÃ­ nghiá»‡m trÃªn bá»™ dá»¯ liá»‡u Movie, xÃ©t ráº±ng thÃ´ng tin Ä‘á»™ phá»• biáº¿n quan trá»ng hÆ¡n trÃªn Ä‘Ã³. ChÃºng tÃ´i so sÃ¡nh phiÃªn báº£n gá»‘c cá»§a BIGRec vá»›i phiÃªn báº£n káº¿t há»£p thÃ´ng tin Ä‘á»™ phá»• biáº¿n trong HÃ¬nh 5. HÃ¬nh nÃ y chá»©ng minh ráº±ng sau khi káº¿t há»£p thÃ´ng tin Ä‘á»™ phá»• biáº¿n, BIGRec Ä‘áº¡t Ä‘Æ°á»£c sá»± cáº£i thiá»‡n hiá»‡u suáº¥t Ä‘á»‘i vá»›i cÃ¡c chá»‰ sá»‘ NDCG@K vÃ  Recall@K, Ä‘áº·c biá»‡t Ä‘á»‘i vá»›i

Báº£n tháº£o Ä‘Æ°á»£c gá»­i tá»›i ACM

--- TRANG 12 ---
12 Bao vÃ  Zhang, et al.

[HÃ¬nh 4. Hiá»‡u suáº¥t cá»§a SASRec, DROS, vÃ  BIGRec khi kÃ­ch thÆ°á»›c dá»¯ liá»‡u huáº¥n luyá»‡n tÄƒng (Ä‘Æ°á»£c biá»ƒu thá»‹ báº±ng Sample Num), cÃ¹ng vá»›i cÃ¡c Ä‘Æ°á»ng cong cáº£i thiá»‡n hiá»‡u suáº¥t tÆ°Æ¡ng á»©ng so vá»›i tráº¡ng thÃ¡i ban Ä‘áº§u (1024 máº«u huáº¥n luyá»‡n). CÃ¡c hÃ¬nh phá»¥ bÃªn dÆ°á»›i thá»ƒ hiá»‡n hiá»‡u suáº¥t gá»£i Ã½ (Ä‘Æ°á»£c Ä‘o báº±ng NDCG@K), trong khi cÃ¡c hÃ¬nh phá»¥ bÃªn trÃªn minh há»a sá»± cáº£i thiá»‡n.]

cÃ¡c giÃ¡ trá»‹ ğ¾ lá»›n hÆ¡n. NgoÃ i ra, hiá»‡u suáº¥t tá»‘t hÆ¡n Ä‘Ã¡ng ká»ƒ so vá»›i khi chá»‰ sá»­ dá»¥ng thÃ´ng tin Ä‘á»™ phá»• biáº¿n cho gá»£i Ã½ (nhÆ° Ä‘Æ°á»£c hiá»ƒn thá»‹ trong Báº£ng 3). Nhá»¯ng káº¿t quáº£ nÃ y chá»‰ ra ráº±ng viá»‡c tiÃªm thÃ´ng tin Ä‘á»™ phá»• biáº¿n cÃ³ thá»ƒ cÃ³ lá»£i cho viá»‡c grounding Ä‘áº§u ra cá»§a LLM vÃ o cÃ¡c má»¥c thá»±c táº¿ trong BIGRec, tiáº¿p tá»¥c tÄƒng cÆ°á»ng hiá»‡u suáº¥t cá»§a nÃ³.

â€¢ Giá»›i thiá»‡u thÃ´ng tin collaborative. Tiáº¿p theo chÃºng tÃ´i nghiÃªn cá»©u hiá»‡u suáº¥t cá»§a BIGRec khi káº¿t há»£p thÃ´ng tin collaborative Ä‘Æ°á»£c mÃ£ hÃ³a bá»Ÿi cÃ¡c mÃ´ hÃ¬nh thÃ´ng thÆ°á»ng (vÃ­ dá»¥, DROS) vÃ o nÃ³ báº±ng phÆ°Æ¡ng phÃ¡p trong PhÆ°Æ¡ng trÃ¬nh (3). Äá»ƒ so sÃ¡nh, chÃºng tÃ´i cÅ©ng xem xÃ©t viá»‡c káº¿t há»£p thÃ´ng tin collaborative vÃ o cÃ¡c mÃ´ hÃ¬nh thÃ´ng thÆ°á»ng. Hiá»‡u suáº¥t Ä‘Æ°á»£c hiá»ƒn thá»‹ trong Báº£ng 3, vÃ  sá»± cáº£i thiá»‡n hiá»‡u suáº¥t Ä‘Æ°á»£c hiá»ƒn thá»‹ trong HÃ¬nh 6. Tá»« báº£ng vÃ  hÃ¬nh, chÃºng tÃ´i rÃºt ra hai quan sÃ¡t: 1) viá»‡c káº¿t há»£p thÃ´ng tin collaborative vÃ o cáº£ BIGRec vÃ  cÃ¡c mÃ´ hÃ¬nh truyá»n thá»‘ng Ä‘á»u cÃ³ thá»ƒ mang láº¡i sá»± cáº£i thiá»‡n hiá»‡u suáº¥t mÃ´ hÃ¬nh; 2) viá»‡c káº¿t há»£p thÃ´ng tin collaborative vÃ o BIGRec mang láº¡i sá»± nÃ¢ng cao Ä‘Ã¡ng ká»ƒ hÆ¡n so vá»›i viá»‡c káº¿t há»£p thÃ´ng tin vÃ o má»™t mÃ´ hÃ¬nh thÃ´ng thÆ°á»ng khÃ¡c. Nhá»¯ng káº¿t quáº£ nÃ y chá»‰ ra ráº±ng

Báº£n tháº£o Ä‘Æ°á»£c gá»­i tá»›i ACM

--- TRANG 13 ---
Má»™t MÃ´ hÃ¬nh Grounding Hai BÆ°á»›c cho MÃ´ hÃ¬nh NgÃ´n ngá»¯ Lá»›n trong Há»‡ thá»‘ng Gá»£i Ã½ 13

[HÃ¬nh 5. So sÃ¡nh hiá»‡u suáº¥t giá»¯a BIGRec vá»›i viá»‡c tiÃªm Ä‘á»™ phá»• biáº¿n trong quÃ¡ trÃ¬nh grounding (labeled as "Injected") vÃ  BIGRec gá»‘c. CÃ¡c chá»‰ sá»‘ NDCG@K vÃ  HR@K Ä‘Æ°á»£c hiá»ƒn thá»‹ cho cÃ¡c giÃ¡ trá»‹ K khÃ¡c nhau.]

[HÃ¬nh 6. Cáº£i thiá»‡n hiá»‡u suáº¥t cá»§a SASRec, Caser, BIGRec (1024), vÃ  BIGRec (full) Ä‘Æ°á»£c káº¿t há»£p vá»›i DROS trÃªn bá»™ dá»¯ liá»‡u Game. CÃ¡c cáº£i thiá»‡n liÃªn quan Ä‘áº¿n giÃ¡ trá»‹ lá»›n hÆ¡n cá»§a hiá»‡u suáº¥t cá»§a hai mÃ´ hÃ¬nh káº¿t há»£p, Ä‘Æ°á»£c kÃ½ hiá»‡u lÃ  'Improve2LV'. ÄÃ¡ng chÃº Ã½, táº¥t cáº£ cÃ¡c baseline á»Ÿ Ä‘Ã¢y (SASRec, Caser, vÃ  DROS) Ä‘á»u Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn bá»™ dá»¯ liá»‡u Ä‘áº§y Ä‘á»§.]

BIGRec phá»¥ thuá»™c nhiá»u hÆ¡n vÃ o thÃ´ng tin khÃ¡c (thÃ´ng tin ngá»¯ nghÄ©a) khÃ¡c vá»›i thÃ´ng tin collaborative Ä‘á»ƒ táº¡o ra gá»£i Ã½, do Ä‘Ã³ viá»‡c káº¿t há»£p thÃ´ng tin collaborative cÃ³ thá»ƒ mang láº¡i nhiá»u lá»£i Ã­ch hÆ¡n.

Hai thÃ­ nghiá»‡m chá»‰ ra ráº±ng cÃ³ tiá»m nÄƒng Ä‘Ã¡ng ká»ƒ Ä‘á»ƒ tiáº¿n bá»™ Ä‘á»™ chÃ­nh xÃ¡c gá»£i Ã½ hÆ¡n ná»¯a báº±ng cÃ¡ch Ä‘iá»u tra cÃ¡c ká»¹ thuáº­t hiá»‡u quáº£ vÃ  hiá»‡u suáº¥t hÆ¡n Ä‘á»ƒ nÃ¢ng cao viá»‡c grounding vÃ o khÃ´ng gian má»¥c thá»±c táº¿ trong BIGRec.

5 Káº¾T LUáº¬N VÃ€ CÃ”NG VIá»†C TÆ¯Æ NG LAI

Trong bÃ i bÃ¡o nÃ y, chÃºng tÃ´i nháº±m tháº£o luáº­n ká»¹ lÆ°á»¡ng vá» hiá»‡u suáº¥t trÃªn táº¥t cáº£ cÃ¡c thá»© háº¡ng cho LLM4Rec. Äá»ƒ táº­n dá»¥ng Ä‘áº§y Ä‘á»§ tiá»m nÄƒng cá»§a LLM, chÃºng tÃ´i xÃ¢y dá»±ng má»™t mÃ´ hÃ¬nh grounding hai bÆ°á»›c cho gá»£i Ã½ (BIGRec), theo phÆ°Æ¡ng phÃ¡p táº¡o sinh cÃ³ thá»ƒ káº¿t há»£p thÃ´ng tin thá»‘ng kÃª má»™t cÃ¡ch hiá»‡u quáº£. Nhá»¯ng phÃ¡t hiá»‡n thá»±c nghiá»‡m cá»§a chÃºng tÃ´i chá»‰ ra ráº±ng BIGRec Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn 1024 máº«u vÆ°á»£t trá»™i Ä‘Ã¡ng ká»ƒ so vá»›i cÃ¡c mÃ´ hÃ¬nh gá»£i Ã½ truyá»n thá»‘ng Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn sá»‘ lÆ°á»£ng máº«u giá»‘ng há»‡t, Ä‘áº¡t Ä‘Æ°á»£c hiá»‡u suáº¥t ngang báº±ng tháº­m chÃ­ vá»›i cÃ¡c mÃ´ hÃ¬nh thÃ´ng thÆ°á»ng Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn bá»™ dá»¯ liá»‡u Ä‘áº§y Ä‘á»§ trong háº§u háº¿t cÃ¡c trÆ°á»ng há»£p. HÆ¡n ná»¯a, chÃºng tÃ´i Ä‘Ã£ má»Ÿ rá»™ng dá»¯ liá»‡u huáº¥n luyá»‡n cho gá»£i Ã½ dá»±a trÃªn LLM. Káº¿t quáº£ chá»‰ ra ráº±ng LLM phá»¥ thuá»™c nhiá»u vÃ o ngá»¯ nghÄ©a cho gá»£i Ã½ trong khi bá» qua má»™t sá»‘ thÃ´ng tin há»¯u Ã­ch khÃ¡c. Dá»±a trÃªn cÃ¡i nhÃ¬n sÃ¢u sáº¯c nÃ y, chÃºng tÃ´i Ä‘Ã£ truyá»n thÃ´ng tin Ä‘á»™ phá»• biáº¿n vÃ  collaborative vÃ o LLM, tiáº¿p tá»¥c tÄƒng cÆ°á»ng kháº£ nÄƒng cá»§a nÃ³ vÃ  xÃ¡c thá»±c giáº£ Ä‘á»‹nh cá»§a chÃºng tÃ´i.

XÃ©t tá»« cÃ¡c tháº£o luáº­n nÃªu trÃªn, cÃ³ thá»ƒ suy ra ráº±ng viá»‡c sá»­ dá»¥ng phÆ°Æ¡ng phÃ¡p grounding hai bÆ°á»›c trong gá»£i Ã½ dá»±a trÃªn LLM cho tháº¥y há»©a háº¹n. Tuy nhiÃªn, má»™t sá»‘ váº¥n Ä‘á» chÆ°a Ä‘Æ°á»£c giáº£i quyáº¿t váº«n tá»“n táº¡i. Thá»© nháº¥t, vá» giai Ä‘oáº¡n Ä‘áº§u tiÃªn cá»§a grounding trong khÃ´ng gian gá»£i Ã½, cÃ¡c thÃ­ nghiá»‡m cá»§a chÃºng tÃ´i tiáº¿t lá»™ ráº±ng hiá»‡u suáº¥t gá»£i Ã½ thá»a Ä‘Ã¡ng cÃ³ thá»ƒ Ä‘áº¡t Ä‘Æ°á»£c vá»›i sá»‘ lÆ°á»£ng máº«u tÆ°Æ¡ng Ä‘á»‘i nhá». BÃªn cáº¡nh Ä‘Ã³, viá»‡c tÄƒng thÃªm kÃ­ch thÆ°á»›c máº«u cÃ³ thá»ƒ tÄƒng cÆ°á»ng hiá»‡u suáº¥t. Tuy nhiÃªn, cÃ³ hai cÃ¢n nháº¯c Ä‘á»‘i láº­p. Má»™t máº·t, viá»‡c huáº¥n luyá»‡n LLM phÃ¡t sinh chi phÃ­ Ä‘Ã¡ng ká»ƒ. Liá»‡u cÃ³ kháº£ thi khi chá»n cÃ¡c máº«u thÃ­ch há»£p Ä‘á»ƒ xÃ¢y dá»±ng khÃ´ng gian gá»£i Ã½, tá»« Ä‘Ã³ giáº£m chi phÃ­ liÃªn quan? Máº·t khÃ¡c, cÃ¢u há»i liá»‡u táº¥t cáº£ cÃ¡c má»¥c cÃ³ nÃªn thuá»™c vá» cÃ¹ng má»™t khÃ´ng gian gá»£i Ã½ váº«n lÃ  chá»§ Ä‘á» tranh luáº­n.

HÆ¡n ná»¯a, liÃªn quan Ä‘áº¿n bÆ°á»›c grounding thá»© hai, phÆ°Æ¡ng phÃ¡p chÃºng tÃ´i hiá»‡n táº¡i sá»­ dá»¥ng khÃ¡ thÃ´ sÆ¡, viá»‡c trÃ­ch xuáº¥t embeddings báº±ng mÃ´ hÃ¬nh decoder vÃ  tÃ­nh toÃ¡n Ä‘á»™ tÆ°Æ¡ng tá»± lÃ  má»™t hoáº¡t Ä‘á»™ng cÆ¡ báº£n. Máº·c dÃ¹ kháº£ nÄƒng Ä‘iá»u chá»‰nh viá»‡c sáº£n xuáº¥t máº«u vá»›i beam size lá»›n, phÆ°Æ¡ng phÃ¡p nÃ y ráº¥t tá»‘n thá»i gian. Do Ä‘Ã³, Ä‘iá»u cáº§n thiáº¿t lÃ  tÃ¬m má»™t phÆ°Æ¡ng phÃ¡p hiá»‡u quáº£ hÆ¡n Ä‘á»ƒ káº¿t ná»‘i vá»›i cÃ¡c má»¥c thá»±c táº¿. HÆ¡n ná»¯a, chÃºng tÃ´i Ä‘Ã£ xÃ¡c nháº­n tÃ­nh kháº£ thi cá»§a viá»‡c tÃ­ch há»£p Ä‘á»™ phá»• biáº¿n má»¥c vÃ  thÃ´ng tin collaborative trong quÃ¡ trÃ¬nh grounding. ChÃºng tÃ´i hy vá»ng sáº½ káº¿t há»£p cÃ¡c tÃ­nh nÄƒng gá»£i Ã½ thÃ´ng thÆ°á»ng hÆ¡n má»™t cÃ¡ch hiá»‡u quáº£ hÆ¡n Ä‘á»ƒ cáº£i thiá»‡n thÃªm hiá»‡u suáº¥t mÃ´ hÃ¬nh.

TÃ€I LIá»†U THAM KHáº¢O

[1] Michael Ahn, Anthony Brohan, Noah Brown, Yevgen Chebotar, Omar Cortes, Byron David, Chelsea Finn, Chuyuan Fu, Keerthana Gopalakrishnan, Karol Hausman, et al. 2022. Do as i can, not as i say: Grounding language in robotic affordances. arXiv preprint arXiv:2204.01691 (2022).

[2] Qingyao Ai, Ting Bai, and et al. 2023. Information Retrieval Meets Large Language Models: A Strategic Report from Chinese IR Community. arXiv preprint arXiv:2307.09751 (2023).

[3] Keqin Bao, Jizhi Zhang, Yang Zhang, Wenjie Wang, Fuli Feng, and Xiangnan He. 2023. Tallrec: An effective and efficient tuning framework to align large language model with recommendation. Recsys short (2023).

[4] Lisa Beinborn, Teresa Botschen, and Iryna Gurevych. 2018. Multimodal grounding for language processing. arXiv preprint arXiv:1806.06371 (2018).

[5] Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020. Language Models are Few-Shot Learners. In Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual, Hugo Larochelle, Marc'Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin (Eds.). https://proceedings.neurips.cc/paper/2020/hash/

Báº£n tháº£o Ä‘Æ°á»£c gá»­i tá»›i ACM

--- TRANG 15 ---
Má»™t MÃ´ hÃ¬nh Grounding Hai BÆ°á»›c cho MÃ´ hÃ¬nh NgÃ´n ngá»¯ Lá»›n trong Há»‡ thá»‘ng Gá»£i Ã½ 15

1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html

[6] Zheng Chen. 2023. PALR: Personalization Aware LLMs for Recommendation. arXiv preprint arXiv:2305.07622 (2023).

[7] Wei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng, Zhanghao Wu, Hao Zhang, Lianmin Zheng, Siyuan Zhuang, Yonghao Zhuang, Joseph E. Gonzalez, Ion Stoica, and Eric P. Xing. 2023. Vicuna: An Open-Source Chatbot Impressing GPT-4 with 90%* ChatGPT Quality. https://lmsys.org/blog/2023-03-30-vicuna/

[8] Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, et al. 2022. Palm: Scaling language modeling with pathways. arXiv preprint arXiv:2204.02311 (2022).

[9] Qiang Cui, Shu Wu, Qiang Liu, Wen Zhong, and Liang Wang. 2020. MV-RNN: A Multi-View Recurrent Neural Network for Sequential Recommendation. IEEE Trans. Knowl. Data Eng. 32, 2 (2020), 317â€“331. https://doi.org/10.1109/TKDE.2018.2881260

[10] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers). Association for Computational Linguistics, Minneapolis, Minnesota, 4171â€“4186. https://doi.org/10.18653/v1/N19-1423

[11] Sihao Ding, Fuli Feng, Xiangnan He, Jinqiu Jin, Wenjie Wang, Yong Liao, and Yongdong Zhang. 2022. Interpolative Distillation for Unifying Biased and Debiased Recommendation. In SIGIR '22: The 45th International ACM SIGIR Conference on Research and Development in Information Retrieval, Madrid, Spain, July 11 - 15, 2022, Enrique AmigÃ³, Pablo Castells, Julio Gonzalo, Ben Carterette, J. Shane Culpepper, and Gabriella Kazai (Eds.). ACM, 40â€“49. https://doi.org/10.1145/3477495.3532002

[12] Tim Donkers, Benedikt Loepp, and JÃ¼rgen Ziegler. 2017. Sequential user-based recurrent neural network recommendations. In Proceedings of the eleventh ACM conference on recommender systems. 152â€“160.

[13] Danny Driess, Fei Xia, Mehdi SM Sajjadi, Corey Lynch, Aakanksha Chowdhery, Brian Ichter, Ayzaan Wahid, Jonathan Tompson, Quan Vuong, Tianhe Yu, et al. 2023. Palm-e: An embodied multimodal language model. arXiv preprint arXiv:2303.03378 (2023).

[14] Wenqi Fan, Zihuai Zhao, Jiatong Li, Yunqing Liu, Xiaowei Mei, Yiqi Wang, Jiliang Tang, and Qing Li. 2023. Recommender Systems in the Era of Large Language Models (LLMs). arXiv preprint arXiv:2307.02046 (2023).

[15] Hui Fang, Danning Zhang, Yiheng Shu, and Guibing Guo. 2020. Deep Learning for Sequential Recommendation: Algorithms, Influential Factors, and Evaluations. ACM Trans. Inf. Syst. 39, 1 (2020), 10:1â€“10:42. https://doi.org/10.1145/3426723

[16] Luke Friedman, Sameer Ahuja, David Allen, Terry Tan, Hakim Sidahmed, Changbo Long, Jun Xie, Gabriel Schubiner, Ajay Patel, Harsh Lara, et al. 2023. Leveraging Large Language Models in Conversational Recommender Systems. arXiv preprint arXiv:2305.07961 (2023).

[17] Shijie Geng, Shuchang Liu, Zuohui Fu, Yingqiang Ge, and Yongfeng Zhang. 2022. Recommendation as language processing (rlp): A unified pretrain, personalized prompt & predict paradigm (p5). In Proceedings of the 16th ACM Conference on Recommender Systems. 299â€“315.

[18] BalÃ¡zs Hidasi, Alexandros Karatzoglou, Linas Baltrunas, and Domonkos Tikk. 2016. Session-based Recommendations with Recurrent Neural Networks. In ICLR.

[19] Yupeng Hou, Shanlei Mu, Wayne Xin Zhao, Yaliang Li, Bolin Ding, and Ji-Rong Wen. 2022. Towards universal sequence representation learning for recommender systems. In Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining. 585â€“593.

[20] Edward J. Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. 2022. LoRA: Low-Rank Adaptation of Large Language Models. In The Tenth International Conference on Learning Representations, ICLR 2022, Virtual Event, April 25-29, 2022. OpenReview.net. https://openreview.net/forum?id=nZeVKeeFYf9

[21] Yitong Ji, Aixin Sun, Jie Zhang, and Chenliang Li. 2023. A critical study on data leakage in recommender system offline evaluation. ACM Transactions on Information Systems 41, 3 (2023), 1â€“27.

[22] Chen Ju, Tengda Han, Kunhao Zheng, Ya Zhang, and Weidi Xie. 2022. Prompting visual-language models for efficient video understanding. In European Conference on Computer Vision. Springer, 105â€“124.

[23] Wang-Cheng Kang and Julian J. McAuley. 2018. Self-Attentive Sequential Recommendation. In IEEE International Conference on Data Mining, ICDM 2018, Singapore, November 17-20, 2018. IEEE Computer Society, 197â€“206.

[24] Diederik P. Kingma and Jimmy Ba. 2015. Adam: A Method for Stochastic Optimization. In 3rd International Conference on Learning Representations, ICLR 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings, Yoshua Bengio and Yann LeCun (Eds.). http://arxiv.org/abs/1412.6980

[25] Walid Krichene and Steffen Rendle. 2020. On sampled metrics for item recommendation. In Proceedings of the 26th ACM SIGKDD international conference on knowledge discovery & data mining. 1748â€“1757.

[26] Jiatong Li, Yunqing Liu, Wenqi Fan, Xiao-Yong Wei, Hui Liu, Jiliang Tang, and Qing Li. 2023. Empowering Molecule Discovery for Molecule-Caption Translation with Large Language Models: A ChatGPT Perspective. arXiv preprint arXiv:2306.06615 (2023).

[27] Jinming Li, Wentao Zhang, Tian Wang, Guanglei Xiong, Alan Lu, and Gerard Medioni. 2023. GPT4Rec: A generative framework for personalized recommendation and user interests interpretation. arXiv preprint arXiv:2304.03879 (2023).

[28] Ruyu Li, Wenhao Deng, Yu Cheng, Zheng Yuan, Jiaqi Zhang, and Fajie Yuan. 2023. Exploring the Upper Limits of Text-Based Collaborative Filtering Using Large Language Models: Discoveries and Insights. arXiv preprint arXiv:2305.11700 (2023).

[29] Xiujun Li, Xi Yin, Chunyuan Li, Pengchuan Zhang, Xiaowei Hu, Lei Zhang, Lijuan Wang, Houdong Hu, Li Dong, Furu Wei, et al. 2020. Oscar: Object-semantics aligned pre-training for vision-language tasks. In Computer Visionâ€“ECCV 2020: 16th European Conference, Glasgow, UK, August 23â€“28, 2020, Proceedings, Part XXX 16. Springer, 121â€“137.

Báº£n tháº£o Ä‘Æ°á»£c gá»­i tá»›i ACM

--- TRANG 16 ---
16 Bao vÃ  Zhang, et al.

[30] Junling Liu, Chao Liu, Renjie Lv, Kang Zhou, and Yan Zhang. 2023. Is chatgpt a good recommender? a preliminary study. arXiv preprint arXiv:2304.10149 (2023).

[31] Ilya Loshchilov and Frank Hutter. 2019. Decoupled Weight Decay Regularization. In 7th International Conference on Learning Representations, ICLR 2019, New Orleans, LA, USA, May 6-9, 2019. OpenReview.net. https://openreview.net/forum?id=Bkg6RiCqY7

[32] Yabo Ni, Dan Ou, Shichen Liu, Xiang Li, Wenwu Ou, Anxiang Zeng, and Luo Si. 2018. Perceive Your Users in Depth: Learning Universal User Representations from Multiple E-commerce Tasks. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, KDD 2018, London, UK, August 19-23, 2018, Yike Guo and Faisal Farooq (Eds.). ACM, 596â€“605. https://doi.org/10.1145/3219819.3219828

[33] Ruihong Qiu, Zi Huang, Hongzhi Yin, and Zijian Wang. 2021. Contrastive Learning for Representation Degeneration Problem in Sequential Recommendation. CoRR abs/2110.05730 (2021). arXiv:2110.05730 https://arxiv.org/abs/2110.05730

[34] Ruihong Qiu, Zi Huang, Hongzhi Yin, and Zijian Wang. 2022. Contrastive Learning for Representation Degeneration Problem in Sequential Recommendation. In WSDM '22: The Fifteenth ACM International Conference on Web Search and Data Mining, Virtual Event / Tempe, AZ, USA, February 21 - 25, 2022, K. Selcuk Candan, Huan Liu, Leman Akoglu, Xin Luna Dong, and Jiliang Tang (Eds.). ACM, 813â€“823. https://doi.org/10.1145/3488560.3498433

[35] Alec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. 2019. Language Models are Unsupervised Multitask Learners. (2019).

[36] Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J Liu. 2020. Exploring the limits of transfer learning with a unified text-to-text transformer. The Journal of Machine Learning Research 21, 1 (2020), 5485â€“5551.

[37] Xiaoyuan Su and Taghi M Khoshgoftaar. 2009. A survey of collaborative filtering techniques. Advances in artificial intelligence 2009 (2009).

[38] Jiaxi Tang and Ke Wang. 2018. Personalized top-n sequential recommendation via convolutional sequence embedding. In WSDM. 565â€“573.

[39] Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy Liang, and Tatsunori B. Hashimoto. 2023. Stanford Alpaca: An Instruction-following LLaMA model. https://github.com/tatsu-lab/stanford_alpaca.

[40] Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, TimothÃ©e Lacroix, Baptiste RoziÃ¨re, Naman Goyal, Eric Hambro, Faisal Azhar, AurÃ©lien Rodriguez, Armand Joulin, Edouard Grave, and Guillaume Lample. 2023. LLaMA: Open and Efficient Foundation Language Models. CoRR abs/2302.13971 (2023). https://doi.org/10.48550/arXiv.2302.13971 arXiv:2302.13971

[41] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017. Attention is All you Need. In Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems 2017, December 4-9, 2017, Long Beach, CA, USA, Isabelle Guyon, Ulrike von Luxburg, Samy Bengio, Hanna M. Wallach, Rob Fergus, S. V. N. Vishwanathan, and Roman Garnett (Eds.). 5998â€“6008. https://proceedings.neurips.cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html

[42] Shoujin Wang, Liang Hu, Yan Wang, Longbing Cao, Quan Z. Sheng, and Mehmet A. Orgun. 2019. Sequential Recommender Systems: Challenges, Progress and Prospects. In Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence, IJCAI 2019, Macao, China, August 10-16, 2019, Sarit Kraus (Ed.). ijcai.org, 6332â€“6338. https://doi.org/10.24963/ijcai.2019/883

[43] Zhenlei Wang, Shiqi Shen, Zhipeng Wang, Bo Chen, Xu Chen, and Ji-Rong Wen. 2022. Unbiased Sequential Recommendation with Latent Confounders. In WWW '22: The ACM Web Conference 2022, Virtual Event, Lyon, France, April 25 - 29, 2022, FrÃ©dÃ©rique Laforest, RaphaÃ«l Troncy, Elena Simperl, Deepak Agarwal, Aristides Gionis, Ivan Herman, and Lionel MÃ©dini (Eds.). ACM, 2195â€“2204. https://doi.org/10.1145/3485447.3512092

[44] Zekun Wang, Ge Zhang, Kexin Yang, Ning Shi, Wangchunshu Zhou, Shaochun Hao, Guangzheng Xiong, Yizhi Li, Mong Yuan Sim, Xiuying Chen, et al. 2023. Interactive natural language processing. arXiv preprint arXiv:2305.13246 (2023).

[45] Hongyi Wen, Xinyang Yi, Tiansheng Yao, Jiaxi Tang, Lichan Hong, and Ed H Chi. 2022. Distributionally-robust Recommendations for Improving Worst-case User Experience. In Proceedings of the ACM Web Conference 2022. 3606â€“3610.

[46] Likang Wu, Zhi Zheng, Zhaopeng Qiu, Hao Wang, Hongchao Gu, Tingjia Shen, Chuan Qin, Chen Zhu, Hengshu Zhu, Qi Liu, et al. 2023. A Survey on Large Language Models for Recommendation. arXiv preprint arXiv:2305.19860 (2023).

[47] Lingxi Xie, Longhui Wei, Xiaopeng Zhang, Kaifeng Bi, Xiaotao Gu, Jianlong Chang, and Qi Tian. 2023. Towards AGI in Computer Vision: Lessons Learned from GPT and Large Language Models. arXiv preprint arXiv:2306.08641 (2023).

[48] Chengfeng Xu, Jian Feng, Pengpeng Zhao, Fuzhen Zhuang, Deqing Wang, Yanchi Liu, and Victor S. Sheng. 2021. Long- and short-term self-attention network for sequential recommendation. Neurocomputing 423 (2021), 580â€“589. https://doi.org/10.1016/j.neucom.2020.10.066

[49] An Yan, Shuo Cheng, Wang-Cheng Kang, Mengting Wan, and Julian J. McAuley. 2019. CosRec: 2D Convolutional Neural Networks for Sequential Recommendation. In Proceedings of the 28th ACM International Conference on Information and Knowledge Management, CIKM 2019, Beijing, China, November 3-7, 2019, Wenwu Zhu, Dacheng Tao, Xueqi Cheng, Peng Cui, Elke A. Rundensteiner, David Carmel, Qi He, and Jeffrey Xu Yu (Eds.). ACM, 2173â€“2176. https://doi.org/10.1145/3357384.3358113

[50] Zhengyi Yang, Xiangnan He, Jizhi Zhang, Jiancan Wu, Xin Xin, Jiawei Chen, and Xiang Wang. 2023. A Generic Learning Framework for Sequential Recommendation with Distribution Shifts. In Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval.

[51] Fajie Yuan, Xiangnan He, Alexandros Karatzoglou, and Liguang Zhang. 2020. Parameter-Efficient Transfer from Sequential Behaviors for User Modeling and Recommendation. In Proceedings of the 43rd International ACM SIGIR conference on research and development in Information Retrieval, SIGIR 2020, Virtual Event, China, July 25-30, 2020, Jimmy X. Huang, Yi Chang, Xueqi Cheng, Jaap Kamps, Vanessa Murdock, Ji-Rong Wen, and Yiqun Liu (Eds.). ACM, 1469â€“1478. https://doi.org/10.1145/3397271.3401156

Báº£n tháº£o Ä‘Æ°á»£c gá»­i tá»›i ACM

--- TRANG 17 ---
Má»™t MÃ´ hÃ¬nh Grounding Hai BÆ°á»›c cho MÃ´ hÃ¬nh NgÃ´n ngá»¯ Lá»›n trong Há»‡ thá»‘ng Gá»£i Ã½ 17

[52] Fajie Yuan, Alexandros Karatzoglou, Ioannis Arapakis, Joemon M. Jose, and Xiangnan He. 2019. A Simple Convolutional Generative Network for Next Item Recommendation. In Proceedings of the Twelfth ACM International Conference on Web Search and Data Mining, WSDM 2019, Melbourne, VIC, Australia, February 11-15, 2019, J. Shane Culpepper, Alistair Moffat, Paul N. Bennett, and Kristina Lerman (Eds.). ACM, 582â€“590. https://doi.org/10.1145/3289600.3290975

[53] Yan Zeng, Xinsong Zhang, Hang Li, Jiawei Wang, Jipeng Zhang, and Wangchunshu Zhou. 2022. X2-VLM: All-In-One Pre-trained Model For Vision-Language Tasks. CoRR abs/2211.12402 (2022). https://doi.org/10.48550/arXiv.2211.12402 arXiv:2211.12402

[54] Jizhi Zhang, Keqin Bao, Yang Zhang, Wenjie Wang, Fuli Feng, and Xiangnan He. 2023. Is chatgpt fair for recommendation? evaluating fairness in large language model recommendation. arXiv preprint arXiv:2305.07609 (2023).

[55] Junjie Zhang, Ruobing Xie, Yupeng Hou, Wayne Xin Zhao, Leyu Lin, and Ji-Rong Wen. 2023. Recommendation as instruction following: A large language model empowered recommendation approach. arXiv preprint arXiv:2305.07001 (2023).

[56] Tingting Zhang, Pengpeng Zhao, Yanchi Liu, Victor S. Sheng, Jiajie Xu, Deqing Wang, Guanfeng Liu, and Xiaofang Zhou. 2019. Feature-level Deeper Self-Attention Network for Sequential Recommendation. In Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence, IJCAI 2019, Macao, China, August 10-16, 2019, Sarit Kraus (Ed.). ijcai.org, 4320â€“4326. https://doi.org/10.24963/ijcai.2019/600

[57] Yang Zhang, Fuli Feng, Xiangnan He, Tianxin Wei, Chonggang Song, Guohui Ling, and Yongdong Zhang. 2021. Causal Intervention for Leveraging Popularity Bias in Recommendation. In Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval (Virtual Event, Canada) (SIGIR '21). Association for Computing Machinery, New York, NY, USA, 11â€“20. https://doi.org/10.1145/3404835.3462875

[58] Yang Zhang, Tianhao Shi, Fuli Feng, Wenjie Wang, Dingxian Wang, Xiangnan He, and Yongdong Zhang. 2023. Reformulating CTR Prediction: Learning Invariant Feature Interactions. In Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval.

[59] Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, Yifan Du, Chen Yang, Yushuo Chen, Zhipeng Chen, Jinhao Jiang, Ruiyang Ren, Yifan Li, Xinyu Tang, Zikang Liu, Peiyu Liu, Jian-Yun Nie, and Ji-Rong Wen. 2023. A Survey of Large Language Models. CoRR abs/2303.18223 (2023). arXiv:2303.18223

[60] Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric. P Xing, Hao Zhang, Joseph E. Gonzalez, and Ion Stoica. 2023. Judging LLM-as-a-judge with MT-Bench and Chatbot Arena. arXiv:2306.05685 [cs.CL]

[61] Deyao Zhu, Jun Chen, Xiaoqian Shen, Xiang Li, and Mohamed Elhoseiny. 2023. MiniGPT-4: Enhancing Vision-Language Understanding with Advanced Large Language Models. arXiv preprint arXiv:2304.10592 (2023).

Báº£n tháº£o Ä‘Æ°á»£c gá»­i tá»›i ACM

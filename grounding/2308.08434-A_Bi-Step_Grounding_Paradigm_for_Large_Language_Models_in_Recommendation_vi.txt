# 2308.08434.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/grounding/2308.08434.pdf
# Kích thước tệp: 1157949 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Một Mô hình Grounding Hai Bước cho Mô hình Ngôn ngữ Lớn trong Hệ thống Gợi ý
KEQIN BAO*, Đại học Khoa học và Công nghệ Trung Quốc, Trung Quốc
JIZHI ZHANG*, Đại học Khoa học và Công nghệ Trung Quốc, Trung Quốc
WENJIE WANG, Đại học Quốc gia Singapore, Singapore
YANG ZHANG, Đại học Khoa học và Công nghệ Trung Quốc, Trung Quốc
ZHENGYI YANG, Đại học Khoa học và Công nghệ Trung Quốc, Trung Quốc
YANCHENG LUO, Đại học Khoa học và Công nghệ Trung Quốc, Trung Quốc
CHONG CHEN, Huawei Inc., Trung Quốc
FULI FENG, Đại học Khoa học và Công nghệ Trung Quốc, Trung Quốc
QI TIAN, Huawei Inc., Trung Quốc

Khi sự quan tâm đến Mô hình Ngôn ngữ Lớn (LLM) trong lĩnh vực gợi ý ngày càng tăng, việc tối ưu hóa LLM cho mục đích gợi ý (được gọi là LLM4Rec) đóng vai trò quan trọng trong việc tăng cường hiệu quả của chúng trong việc cung cấp gợi ý. Tuy nhiên, các phương pháp hiện tại cho LLM4Rec thường đánh giá hiệu suất bằng cách sử dụng các tập hợp ứng viên hạn chế, điều này có thể không phản ánh chính xác khả năng xếp hạng tổng thể của mô hình. Trong bài báo này, mục tiêu của chúng tôi là điều tra khả năng xếp hạng toàn diện của LLM và đề xuất khung grounding hai bước được gọi là BIGRec (Mô hình Grounding Hai Bước cho Gợi ý). Nó ban đầu ground LLM vào không gian gợi ý bằng cách fine-tuning chúng để tạo ra các token có ý nghĩa cho các mục và sau đó xác định các mục thực tế phù hợp tương ứng với các token được tạo ra. Bằng cách tiến hành các thí nghiệm rộng rãi trên hai bộ dữ liệu, chúng tôi chứng minh hiệu suất vượt trội, khả năng xử lý các tình huống few-shot và tính linh hoạt trên nhiều miền được thể hiện bởi BIGRec. Hơn nữa, chúng tôi quan sát thấy rằng lợi ích biên từ việc tăng số lượng mẫu huấn luyện là khiêm tốn đối với BIGRec, ngụ ý rằng LLM có khả năng hạn chế trong việc đồng hóa thông tin thống kê, chẳng hạn như độ phổ biến và collaborative filtering, do các prior ngữ nghĩa mạnh mẽ của chúng. Những phát hiện này cũng nhấn mạnh hiệu quả của việc tích hợp thông tin thống kê đa dạng vào khung LLM4Rec, từ đó chỉ ra con đường tiềm năng cho nghiên cứu tương lai. Mã và dữ liệu của chúng tôi có sẵn tại https://github.com/SAI990323/Grounding4Rec.

Khái niệm CCS: • Hệ thống thông tin → Hệ thống gợi ý.
Từ khóa bổ sung: Mô hình Ngôn ngữ Lớn, Grounding, Gợi ý Tuần tự

Địa chỉ tác giả: Keqin Bao*, baokq@mail.ustc.edu.cn, Đại học Khoa học và Công nghệ Trung Quốc, Trung Quốc; Jizhi Zhang*, cdzhangjizhi@mail.ustc.edu.cn, Đại học Khoa học và Công nghệ Trung Quốc, Trung Quốc; Wenjie Wang, wenjiewang96@gmail.com, Đại học Quốc gia Singapore, Singapore; Yang Zhang, zy2015@mail.ustc.edu.cn, Đại học Khoa học và Công nghệ Trung Quốc, Trung Quốc; Zhengyi Yang, yangzhy@mail.ustc.edu.cn, Đại học Khoa học và Công nghệ Trung Quốc, Trung Quốc; Yancheng Luo, luoyanchen@mail.ustc.edu.cn, Đại học Khoa học và Công nghệ Trung Quốc, Trung Quốc; Chong Chen, chenchong55@huawei.com, Huawei Inc., Trung Quốc; Fuli Feng, fulifeng93@gmail.com, Đại học Khoa học và Công nghệ Trung Quốc, Trung Quốc; Qi Tian, tian.qi1@huawei.com, Huawei Inc., Trung Quốc.

Quyền được cấp để tạo bản sao kỹ thuật số hoặc bản cứng của tất cả hoặc một phần công trình này để sử dụng cá nhân hoặc trong lớp học mà không mất phí với điều kiện các bản sao không được tạo ra hoặc phân phối để thu lợi nhuận hoặc lợi thế thương mại và các bản sao mang thông báo này và trích dẫn đầy đủ trên trang đầu tiên. Bản quyền cho các thành phần của công trình này thuộc sở hữu của những người khác ngoài ACM phải được tôn trọng. Việc trừu tượng hóa có ghi công nguồn được cho phép. Để sao chép cách khác, hoặc tái xuất bản, để đăng trên máy chủ hoặc để phân phối lại cho danh sách, yêu cầu sự cho phép cụ thể trước và/hoặc một khoản phí. Yêu cầu quyền từ permissions@acm.org.

©2024 Association for Computing Machinery.
Bản thảo được gửi tới ACM
Bản thảo được gửi tới ACM 1arXiv:2308.08434v2 [cs.IR] 31 Dec 2023

--- TRANG 2 ---
2 Bao và Zhang, et al.

Thông tin Thống kê

Không gian Ngôn ngữ

Mô hình Ngôn ngữ Lớn

Mục Thực tế

Không gian Không gian Gợi ý

Crouching Tiger, Hidden Dragon (Wu hu zang long)

Là một mô hình ngôn ngữ AI, tôi không có quyền truy cập vào sở thích cá nhân của bạn...

Iron Man (Phương ngữ Tứ Xuyên)

Crouching Tiger, Hidden Dragon (Wu hu zang long)

Mục giả định Mục thực tế

......

Iron Man (2008)

Crouching Tiger, Hidden Dragon (Wu hu zang long)

Iron Man (2008)

Iron Man (Phương ngữ Tứ Xuyên)

Đầu ra Mô hình Ngôn ngữ Lớn

Hình 1. Minh họa mô hình BIGRec. Trong bước đầu tiên, chúng tôi ground không gian ngôn ngữ vào không gian gợi ý, điều này cho phép mô hình tạo ra các chuỗi token của các mục tiềm năng bao gồm cả các mục thực tế và giả định. Trong bước thứ hai, chúng tôi ground không gian gợi ý vào không gian mục thực tế để cung cấp cho người dùng các gợi ý cho các mục trong thế giới thực. Trong bước thứ hai, chúng tôi có thể dễ dàng kết hợp thông tin thống kê (ví dụ, độ phổ biến và thông tin collaborative) để có được các gợi ý tốt hơn.

Định dạng tham chiếu ACM:
Keqin Bao*, Jizhi Zhang*, Wenjie Wang, Yang Zhang, Zhengyi Yang, Yancheng Luo, Chong Chen, Fuli Feng, và Qi Tian. 2024. Một Mô hình Grounding Hai Bước cho Mô hình Ngôn ngữ Lớn trong Hệ thống Gợi ý. 1, 1 (Tháng 1 2024), 17 trang. https://doi.org/10.1145/nnnnnnn.nnnnnnn

1 GIỚI THIỆU

Mô hình Ngôn ngữ Lớn (LLM) đã đạt được thành công đáng kể trong nhiều lĩnh vực khác nhau (như Computer Vision [47] và Robotics [13]) do khả năng hiểu bối cảnh và tạo sinh to lớn của chúng [8,59]. Vượt qua các mô hình ngôn ngữ truyền thống như BERT [10] và GPT2 [35], LLM mã hóa nhiều kiến thức hơn, sở hữu khả năng lý luận mạnh mẽ hơn và có thể được thích ứng một cách mượt mà với nhiệm vụ mới thông qua học in-context với một vài ví dụ [3,26,39]. Dưới ánh sáng này, việc khám phá sử dụng LLM cho gợi ý (LLM4Rec) đang phát triển mạnh mẽ [2,14,46,54]. Do thiếu huấn luyện gợi ý trong giai đoạn pre-training của LLM [3], việc điều chỉnh LLM đóng vai trò quan trọng trong việc giúp LLM đạt được hiệu suất gợi ý tốt hơn.

Nhiều nghiên cứu hiện tại tăng cường hiệu suất gợi ý của LLM thông qua các kỹ thuật fine-tuning dựa trên instruction và sử dụng dữ liệu gợi ý, đạt được kết quả khả quan [3,55]. Khi đánh giá hiệu quả của các phương pháp fine-tuning này, chúng thường chỉ tiến hành dự đoán gợi ý trên một tập hợp ứng viên hạn chế (ví dụ, dự đoán tỷ lệ nhấp chuột [3] hoặc cài đặt negative sampling [55]), điều này không tính đến khả năng xếp hạng toàn cầu tổng thể của mô hình. Thú vị là, có một nghiên cứu đề xuất tránh đánh giá mô hình gợi ý thông qua sampling, điều này có thể dẫn đến chỉ báo kém về hiệu suất thực sự của hệ thống gợi ý [25]. Do đó, chúng tôi mong muốn điều tra và khám phá khả năng của LLM trong lĩnh vực sắp xếp gợi ý all-rank.

Để tận dụng đầy đủ khả năng gợi ý của LLM trong tình huống all-rank, mô hình gợi ý dựa trên LLM phải thỏa mãn ba yêu cầu. 1) Nó phải hiệu quả để xếp hạng một số lượng đáng kể các mục cho người dùng. 2) Nó nên cung cấp đủ tính linh hoạt để tạo ra một mục có ý nghĩa nhằm sử dụng khả năng tạo sinh và hiểu biết của LLM. 3) Điều quan trọng là phải xem xét gợi ý một mục thực tế tồn tại trong thế giới thực trong khi cũng kết hợp thông tin thống kê liên quan, chẳng hạn như thông tin về độ phổ biến và collaborative.

Dưới ánh sáng này, trước tiên chúng ta nên làm cho LLM nhất quán giữa giai đoạn instruction tuning và giai đoạn pre-training của LLM theo cách tạo sinh. Đồng thời, chúng ta nên làm cho gợi ý tương thích với việc tạo ra các mục có ý nghĩa không thực sự tồn tại trong thế giới thực (ví dụ, Iron Man (Phương ngữ Tứ Xuyên)¹), vì LLM có khả năng tạo ra nội dung sáng tạo. Cuối cùng, điều cần thiết là phải xem xét thông tin thống kê từ hành vi người dùng trong quá khứ khi đưa ra gợi ý để tăng cường tính hữu ích của chúng.

Để đạt được mục tiêu này, chúng tôi xây dựng một mô hình grounding hai bước cho gợi ý (BIGRec) với "không gian ngôn ngữ" → "không gian gợi ý" → "không gian mục thực tế" như được hiển thị trong Hình 1. Không gian ngôn ngữ đề cập đến tập hợp của tất cả các chuỗi có thể có thể được tạo ra bởi LLM; không gian gợi ý là một tập con của không gian ngôn ngữ bao gồm các mô tả của các mục khác nhau thỏa mãn sở thích người dùng, bao gồm cả các mục thực tế và giả định. Trong bước đầu tiên, chúng tôi ground LLM vào không gian gợi ý bằng cách fine-tuning chúng để tạo ra các token có ý nghĩa cho mô tả mục (xem Bảng 1). Bước thứ hai bao gồm việc xác định các mục thực tế phù hợp nhất khớp với các token được tạo ra, sử dụng biểu diễn tiềm ẩn của chúng thu được từ LLM. Bước này cũng cung cấp tính linh hoạt để kết hợp thông tin thống kê đa dạng cần thiết cho gợi ý, chẳng hạn như cân bằng khoảng cách của biểu diễn theo độ phổ biến của mục.

Chúng tôi tiến hành các thí nghiệm rộng rãi trên hai bộ dữ liệu thế giới thực để điều tra khả năng phi thường của BIGRec và ảnh hưởng của thông tin độ phổ biến và collaborative. Kết quả đầu tiên chứng minh khả năng few-shot và multi-domain mạnh mẽ của BIGRec, vượt trội hơn rất nhiều so với các mô hình gợi ý truyền thống và các phương pháp LLM4Rec hiện có. Đáng chú ý, BIGRec có thể vượt trội hơn hầu hết các mô hình truyền thống được huấn luyện với 100 hoặc thậm chí 1.000 lần mẫu nhiều hơn. Hơn nữa, chúng tôi quan sát thấy rằng lợi ích thu được từ việc mở rộng mẫu huấn luyện là tương đối khiêm tốn đối với BIGRec khi so sánh với các mô hình truyền thống. Xét rằng nhiều mẫu huấn luyện hơn có lợi cho các mô hình truyền thống với thông tin thống kê phong phú hơn, chúng tôi giả định rằng LLM có thể lấy thông tin thống kê hạn chế (ví dụ, độ phổ biến và thông tin collaborative) từ mẫu huấn luyện do các prior ngữ nghĩa mạnh mẽ của chúng. Chúng tôi tiếp tục xác nhận hiệu quả của việc kết hợp thông tin độ phổ biến và collaborative, cho thấy tiềm năng tổng quát hóa của mô hình cho các công trình tương lai.

Tóm lại, những đóng góp của chúng tôi như sau:

• Chúng tôi nghiên cứu LLM4Rec trong cài đặt all-rank và giới thiệu một mô hình grounding hai bước, tận dụng khả năng hiểu biết và tạo sinh của LLM một cách hiệu quả và hiệu suất với sự hỗ trợ của việc tích hợp thông tin thống kê một cách liền mạch.

• Chúng tôi xác nhận hiệu quả của BIGRec, cho thấy khả năng phi thường cho gợi ý few-shot và cross-domain; và tiết lộ ảnh hưởng của việc mở rộng dữ liệu huấn luyện.

• Chúng tôi tích hợp thông tin độ phổ biến và collaborative vào BIGRec và tiết lộ lợi ích của thông tin thống kê đó trong LLM4Rec, cho thấy các hướng tiềm năng trong tương lai.

2 CÔNG TRÌNH LIÊN QUAN

Gợi ý dựa trên LLM. Các nhà nghiên cứu trong lĩnh vực chủ yếu điều tra các gợi ý dựa trên LLM từ hai góc độ. Thứ nhất, họ nhằm tận dụng phương pháp học in-context (ICL) đã được thiết lập trong cộng đồng xử lý ngôn ngữ tự nhiên (NLP) [6,16,30]. LLM như ChatGPT có thể học nhiệm vụ gợi ý thông qua autoregression bằng cách cung cấp hướng dẫn thích hợp và một vài ví dụ. Tuy nhiên, các nghiên cứu trước đó đã khám phá hiệu quả của các gợi ý dựa trên ICL và quan sát thấy rằng hiệu suất của các phương pháp này thường bị hạn chế, được cho là do những hạn chế được áp đặt lên kích thước đầu vào cho LLM và thiếu kiến thức gợi ý [3,30]. Để khắc phục vấn đề này, góc độ khác tin rằng chúng ta nên áp dụng LLM vào nhiệm vụ gợi ý bằng cách fine-tuning LLM do thiếu dữ liệu gợi ý liên quan trong giai đoạn pre-training của LLM [3,28]. Trong số đó, [28] sử dụng LLM để có được item embedding phục vụ như biểu diễn item và được đưa vào các mô hình gợi ý truyền thống (ví dụ SASRec [23]). Tuy nhiên, phương pháp này vẫn dựa vào các mô hình truyền thống khiến việc tận dụng khả năng tạo sinh của LLM trở nên khó khăn. Ngoài ra, hai nghiên cứu hiện tại, TALLRec [3] và InstructRec [55], sử dụng dữ liệu gợi ý trong giai đoạn instruction-tuning để cải thiện khả năng gợi ý của LLM. Tuy nhiên, mặc dù họ có xem xét việc sử dụng LLM từ góc độ tạo sinh, việc đánh giá của họ bị hạn chế trong tình huống CTR hoặc được tiến hành thông qua negative sampling và không khám phá khả năng xếp hạng tất cả các mục của LLM.

Gợi ý Tuần tự. Mô hình gợi ý gần nhất với thiết lập thí nghiệm của chúng tôi là gợi ý tuần tự, yêu cầu hệ thống gợi ý dự đoán mục tiếp theo mà người dùng có thể thích dựa trên chuỗi tương tác lịch sử của người dùng [15,42]. Công trình trước đó đã riêng biệt nỗ lực các mô hình dựa trên RNN [9,12,18], mô hình dựa trên CNN [38,49,52] và mô hình dựa trên attention [23,48,56] để mô hình hóa hành vi người dùng, đạt được kết quả đáng kính. Dựa trên những phương pháp này, một số lượng ngày càng lớn các công trình tập trung vào việc nâng cao hiệu suất mô hình thông qua pretraining [32,51], data augmentation [33,34], các kỹ thuật debiasing [11,43], tối ưu hóa robust phân phối [45,50] và các phương pháp tương tự khác. Tuy nhiên, bị hạn chế bởi các hệ thống gợi ý dựa trên ID thông thường, những phương pháp như vậy thiếu khả năng tổng quát hóa cũng như tính nhanh chóng để thích ứng với các tình huống mới. Trong những năm gần đây, có sự nhận thức ngày càng tăng về vai trò của ngữ nghĩa trong gợi ý, với những nỗ lực hiện tại đang được thực hiện để tận dụng các mô hình ngôn ngữ để hỗ trợ quá trình gợi ý [19,27]. Tuy nhiên, các phương pháp này, hoặc vẫn dựa vào các mô hình ngôn ngữ sử dụng encoder để trích xuất đặc trưng, điều này đòi hỏi dữ liệu khổng lồ để pre-training, hoặc sử dụng word overlapping để truy xuất các mục, thiếu việc sử dụng thông tin ngữ nghĩa và dễ bị ảnh hưởng bởi nhiễu.

Grounding trong LLM. Hiện tại, trong nghiên cứu về LLM, chúng ta chủ yếu có thể xem xét khái niệm grounding từ hai góc độ: modality grounding và affordance grounding [44]. Cái trước là để ground các phương thức ngôn ngữ vào kiến thức của các phương thức khác, chẳng hạn như hình ảnh, âm thanh hoặc các phương thức khác, thông qua cách tiếp cận này, người ta có thể cho phép LLM nắm bắt và xử lý thông tin phong phú hơn từ thế giới thực [4]. Trong dòng modality grounding [22,29,53], các cá nhân nỗ lực giới thiệu thông tin của các phương thức khác trong cả giai đoạn huấn luyện và suy luận của LLM, dẫn đến khả năng xử lý đầu vào đa phương thức, như được minh họa bởi Vicuna [7,60], MiniGPT4 [61]. Tuy nhiên do yêu cầu của một lượng lớn dữ liệu và tài nguyên [44], trong bài báo này, chúng tôi không ưu tiên cho chiến lược grounding này mà để lại như một công việc tương lai. Cái sau nhằm grounding LLM vào một tình huống bối cảnh cụ thể, đảm bảo rằng kết quả được tạo ra bởi mô hình có liên quan đến nhiệm vụ thay vì tách rời khỏi tình huống [1]. Trong thực tế, mọi người đạt được mục tiêu này thông qua instruction-tuning trên dữ liệu cụ thể của miền hoặc sử dụng các prompt tùy chỉnh để điều hướng LLM [44]. Trong miền gợi ý, do khoảng cách của nó với bản thân nhiệm vụ tạo sinh - chúng ta cần gợi ý một mục thực sự tồn tại, do đó chúng ta áp dụng một bước grounded trong đầu ra tạo sinh vào thế giới thực để hoàn thành gợi ý.

3 BIGREC

Trong phần này, chúng tôi giới thiệu một triển khai cơ bản của BIGRec với hai bước grounding.

3.1 Sơ bộ

Định nghĩa. Để hiểu rõ hơn về mô hình grounding, trước tiên chúng tôi đưa ra định nghĩa của các cụm từ quan trọng sau:

Bản thảo được gửi tới ACM

--- TRANG 5 ---
Một Mô hình Grounding Hai Bước cho Mô hình Ngôn ngữ Lớn trong Hệ thống Gợi ý 5

Bảng 1. Ví dụ về dữ liệu instruction-tuning cho bước grounding vào không gian.

Hướng dẫn Đầu vào
Hướng dẫn: Cho mười bộ phim mà người dùng đã xem gần đây, vui lòng gợi ý một bộ phim mới mà người dùng thích cho người dùng.
Đầu vào: Người dùng đã xem những bộ phim sau trước đây: "Traffic (2000)", "Ocean's Eleven (2001)", ... "Fargo (1996)"

Đầu ra Hướng dẫn
Đầu ra: "Crouching Tiger, Hidden Dragon (Wu hu zang long) (2000)"

• Không gian Ngôn ngữ. Không gian này trước mô hình grounding bao gồm tất cả các chuỗi ngôn ngữ có thể hình dung mà một LLM có thể tạo ra, chẳng hạn như câu phát biểu, "Là một mô hình ngôn ngữ AI, tôi không có quyền truy cập vào sở thích cá nhân của bạn...". Không khả thi khi sử dụng không gian này trực tiếp để tạo gợi ý do bản chất rộng lớn và đa dạng của nó.

• Không gian Gợi ý. Đây là một không gian con trong không gian ngôn ngữ bao gồm một loạt các thực thể thỏa mãn sở thích của người dùng. Những thực thể này có thể đại diện cho cả các mục thực tế và tưởng tượng trong một miền cụ thể. Tuy nhiên, điều quan trọng cần lưu ý là việc gợi ý các thực thể hoàn toàn tưởng tượng có thể không phù hợp. Ví dụ, việc gợi ý "Iron Man (Phương ngữ Tứ Xuyên)" như một gợi ý sẽ không khả thi.

• Không gian Mục Thực tế. Không gian mục thực tế chỉ chứa các mục thực tế trong không gian gợi ý. Việc gợi ý các mục từ không gian mục thực tế này là cần thiết. Ví dụ, trong bối cảnh gợi ý phim, các mục được gợi ý phải được chọn từ những bộ phim có sẵn trên nền tảng.

Để fine-tune LLM cho gợi ý, chúng tôi đề xuất mô hình BIGRec với hai bước grounding. Thứ nhất, chúng tôi ground đầu ra của LLM từ không gian ngôn ngữ vào không gian gợi ý cho một nhiệm vụ gợi ý cụ thể. Thứ hai, chúng tôi ground nó từ không gian gợi ý vào không gian mục thực tế, cho phép gợi ý các mục thực tế cho người dùng. Để chứng minh khả năng của mô hình của chúng tôi, chúng tôi trình bày một triển khai đơn giản, minh họa tiềm năng và khả năng của mô hình BIGRec này.

3.2 Triển khai

Trong phần này, chúng tôi mô tả cách chúng tôi triển khai mô hình BIGRec cho gợi ý.

3.2.1 Bước 1: Grounding Không gian Ngôn ngữ vào Không gian Gợi ý. Theo phương pháp được đề xuất trong [3], chúng tôi thực hiện giai đoạn instruction-tuning trên dữ liệu alpaca self-instruct [39] sử dụng LLaMA [40]. Sau đó, chúng tôi tiến hành instruction-tuning cụ thể cho gợi ý để hạn chế đầu ra của LLM từ không gian ngôn ngữ vào không gian gợi ý. Như được chứng minh trong Bảng 1, chúng tôi fine-tune LLM theo cách tạo sinh: cho tương tác trong quá khứ của người dùng với các mục, chúng tôi yêu cầu LLM tạo ra một mục mới như gợi ý cho người dùng. Bằng cách fine-tuning với dữ liệu như vậy, chúng tôi hạn chế đầu ra của LLM vào không gian gợi ý được chỉ định như được hướng dẫn. Tuy nhiên, do tính sáng tạo của LLM, rất khó để đảm bảo rằng đầu ra của LLM sẽ tương ứng với một mục thực tế tồn tại trong thế giới thực. Do đó, điều cần thiết là phải ground đầu ra của LLM vào không gian mục thực tế.

Bản thảo được gửi tới ACM

--- TRANG 6 ---
6 Bao và Zhang, et al.

3.2.2 Bước 2: Grounding Không gian Gợi ý vào Không gian Mục Thực tế. Trong phần này, chúng tôi trình bày chi tiết về cách neo không gian gợi ý vào không gian mục thực tế. Đầu tiên, chúng tôi căn chỉnh đầu ra của LLM với các mục trong thế giới thực dựa trên biểu diễn của LLM để triển khai một phiên bản vanilla của BIGRec. Sau đó, chúng tôi giới thiệu thông tin thống kê (ví dụ, thông tin độ phổ biến và collaborative) để định vị chính xác các mục thực tế cho gợi ý. Cụ thể, chúng tôi trích xuất biểu diễn tiềm ẩn của các token được tạo ra và embedding của các mục thực tế. Sau đó, chúng tôi xếp hạng các mục thực tế này bằng cách tính toán khoảng cách L2 giữa các embedding của chúng. Khoảng cách L2 được tính như sau:

𝐷𝑖 = ||emb𝑖 − oracle||2, (1)

trong đó emb𝑖 biểu thị embedding của mục thứ 𝑖 và oracle biểu thị embedding của các đầu ra được tạo ra bởi LLM.

Tiêm Thông tin Thống kê. Sau đó chúng tôi giới thiệu cách chúng tôi kết hợp thông tin độ phổ biến và thông tin collaborative vào bước grounding. Để tiêm độ phổ biến, chúng tôi theo ý tưởng trong PDA [57] và cân bằng lại khoảng cách L2 trong Eq. (1) bằng độ phổ biến. Chi tiết, đầu tiên chúng tôi tính toán hệ số độ phổ biến của mỗi mục từ phương trình sau:

𝐶𝑖 = N𝑖 / Σ𝑗∈I N𝑗,
𝑃𝑖 = (𝐶𝑖 − min𝑗∈I{𝐶𝑗}) / (max𝑗∈I{𝐶𝑗} − min𝑗∈I{𝐶𝑗}), (2)

trong đó N biểu thị tập hợp các tương tác user-item trong dữ liệu huấn luyện, N𝑗 biểu thị số lượng tương tác quan sát được cho mục 𝑗 trong N và I biểu thị tất cả các mục, 𝐶𝑖 đại diện cho độ phổ biến của mục thứ 𝑖, và 𝑃𝑖 là giá trị chuẩn hóa của 𝐶𝑖.

Sau đó chúng tôi điều chỉnh khoảng cách L2 trong Eq. (1) bằng độ phổ biến:

ˆ𝐷𝑖 = (𝐷𝑖 − min𝑗∈I{𝐷𝑗}) / (max𝑗∈I{𝐷𝑗} − min𝑗∈I{𝐷𝑗}),
𝐷̃𝑖 = ˆ𝐷𝑖 / (1 + 𝑃𝑖)𝛾, (3)

trong đó 𝐷𝑖 biểu thị khoảng cách L2 giữa embedding của mục thứ 𝑖 và embedding của các đầu ra được tạo ra bởi LLM, ˆ𝐷𝑖 là 𝐷𝑖 được chuẩn hóa, và 𝐷̃𝑖 cân bằng lại ˆ𝐷𝑖 bằng cách sử dụng độ phổ biến. Để cân bằng lại ˆ𝐷𝑖, chúng tôi sử dụng độ phổ biến nghịch đảo và giới thiệu một siêu tham số 𝛾 để điều chỉnh ảnh hưởng của độ phổ biến. Bằng cách đặt độ phổ biến ở mẫu số, một mục phổ biến sẽ được gán khoảng cách L2 nhỏ hơn và xếp hạng cao hơn. Điều này hơi khác so với triển khai gốc trong PDA, trực tiếp cân bằng lại điểm số dự đoán thay vì khoảng cách L2².

Khác với độ phổ biến, việc sử dụng các phương pháp thống kê để định lượng thông tin collaborative là không tầm thường. Xét rằng các mô hình gợi ý truyền thống dựa vào collaborative filtering cho gợi ý, chúng tôi coi điểm số dự đoán bởi các mô hình collaborative filtering này là thông tin collaborative. Tương tự như việc tiêm độ phổ biến, chúng tôi có thể thay thế biến 𝑃𝑖 trong Eq. (3) bằng điểm số dự đoán để tiêm thông tin collaborative vào quá trình grounding. Để biết thêm chi tiết, vui lòng tham khảo Phần §4.4.

4 THÍ NGHIỆM

Trong phần này, chúng tôi tiến hành thí nghiệm để trả lời các câu hỏi nghiên cứu sau:

• RQ1: Hiệu suất của BIGRec so với các phương pháp hiện có như thế nào, khi được huấn luyện trên một mẫu hạn chế gồm 1024 điểm dữ liệu?

² Trong Phần §4.4, chúng tôi vẫn cân bằng lại điểm số dự đoán bằng cách sử dụng PDA [57] để kết hợp độ phổ biến vào hai mô hình truyền thống.

Bản thảo được gửi tới ACM

--- TRANG 7 ---
Một Mô hình Grounding Hai Bước cho Mô hình Ngôn ngữ Lớn trong Hệ thống Gợi ý 7

• RQ2: Hiệu suất của mô hình của chúng tôi được huấn luyện với dữ liệu hạn chế so với các mô hình gợi ý truyền thống được huấn luyện với 100× hoặc thậm chí 1,000× mẫu nhiều hơn như thế nào?

• RQ3: BIGRec có thể đạt được sự cải thiện hiệu suất đáng kể với việc tăng dữ liệu huấn luyện như các mô hình truyền thống không?

• RQ4: Hiệu suất của BIGRec có thể được tăng cường đến mức độ nào bằng cách tích hợp thông tin độ phổ biến/collaborative trong quá trình grounding mô hình?

4.1 Thiết lập Thí nghiệm

4.1.1 Bộ dữ liệu. Chúng tôi tiến hành thí nghiệm trên hai bộ dữ liệu:

• Movie. Đây đề cập đến bộ dữ liệu benchmark nổi tiếng cho gợi ý phim — MovieLens10M³. Nó chứa 10,682 mục, 10,000,054 tương tác và 9,301,274 chuỗi tương tác.

• Game. Đây là bộ dữ liệu gợi ý video-games từ Amazon⁴ và chúng tôi sử dụng tập con 5-core của nó. Bộ dữ liệu chứa 17,408 mục, 496,315 tương tác và 149,796 chuỗi tương tác.

Chúng tôi đã chọn hai bộ dữ liệu này một cách có chủ ý, vì chúng thể hiện các đặc điểm khác nhau về độ thiên vị độ phổ biến. Bộ dữ liệu Movie cho thấy sự thiên vị đáng kể đối với các mục phổ biến, trong khi bộ dữ liệu Game thể hiện mức độ thiên vị ít hơn. Hình 2(a) minh họa tần suất tương tác giữa các mục với các mức độ phổ biến khác nhau, xác nhận rằng bộ dữ liệu Game thể hiện sự phân phối tương tác công bằng hơn giữa các mục phổ biến và không phổ biến so với bộ dữ liệu Movie. Điều này gợi ý mức độ thiên vị độ phổ biến thấp hơn trong bộ dữ liệu Game.

Để mô phỏng các tình huống gợi ý tuần tự trong thế giới thực, chúng tôi chia mỗi bộ dữ liệu thành 10 kỳ dựa trên timestamp của các tương tác. Sau đó, chúng tôi chia các kỳ của mỗi bộ dữ liệu thành các tập huấn luyện, validation và testing⁵ sử dụng tỷ lệ 8:1:1. Cách tiếp cận này đảm bảo rằng các tương tác được dự đoán trong quá trình testing xảy ra sau tất cả các tương tác được quan sát trong quá trình huấn luyện, ngăn ngừa rò rỉ thông tin giai đoạn testing [21] trong quá trình huấn luyện mô hình. Điều này giống với các tình huống thế giới thực hơn [21, 58].

4.1.2 Giao thức Đánh giá. Theo công trình trước đó [23,50], đối với mỗi tương tác testing, chúng tôi đặt chuỗi tương tác lịch sử đầu vào là tập hợp các tương tác xảy ra ngay trước đó. Cách tiếp cận này cho phép khả năng bao gồm các tương tác xảy ra trong giai đoạn testing trong chuỗi đầu vào. Để đánh giá hiệu suất của mô hình, chúng tôi sử dụng hai chỉ số đánh giá thường được sử dụng: Hit Ratio (HR) và Normalized Discounted Cumulative Gain (NDCG), được tính toán bằng cách sử dụng giao thức all-ranking [50]. Trong giao thức này, tất cả các mục mà người dùng chưa tương tác được coi là ứng viên tiềm năng.

4.1.3 Phương pháp So sánh. Để chứng minh tính ưu việt của phương pháp của chúng tôi trong gợi ý tuần tự, chúng tôi so sánh nó với các phương pháp thông thường và dựa trên LLM sau:

-GRU4Rec [18]. Đây là mô hình dựa trên RNN sử dụng Gated Recurrent Units (GRU) để mã hóa tương tác trong quá khứ của người dùng với các mục và tạo ra gợi ý dựa trên các mẫu đã học.

-Caser [38]. Đây là mô hình dựa trên CNN biểu diễn chuỗi các mục gần đây như một hình ảnh và sử dụng các bộ lọc tích chập theo cả hướng ngang và dọc để nắm bắt các mẫu tuần tự. Trong triển khai của chúng tôi, chúng tôi sử dụng một bộ lọc dọc và 16 bộ lọc ngang với việc tìm kiếm chiều cao trong {2, 3, 4}.

³ https://grouplens.org/datasets/movielens/10m/
⁴ https://jmcauley.ucsd.edu/data/amazon/
⁵ Do hạn chế về tốc độ suy luận của các mô hình LLM, chúng tôi lấy mẫu ngẫu nhiên 5,000 tương tác validation và testing làm tập validation và testing cuối cùng, tương ứng.

Bản thảo được gửi tới ACM

--- TRANG 8 ---
8 Bao và Zhang, et al.

[Hình 2(a) - Biểu đồ phân phối các mục có độ phổ biến khác nhau]

[Hình 2(b) - Biểu đồ sử dụng GPU và thời gian suy luận cho các beam size khác nhau]

Hình 2. Hai hình cho thấy sự phân phối của các mục với độ phổ biến khác nhau và sử dụng GPU cùng thời gian suy luận cho các beam size khác nhau trên hai bộ dữ liệu, tương ứng.

-SASRec [23]. Đây là mô hình dựa trên self-attention sử dụng cơ chế attention nhân quả (từ trái sang phải) để học các mẫu tuần tự và dự đoán mục tiếp theo.

-P5 [17]. Phương pháp này sử dụng mô hình T5 [36] làm mô hình backbone và tận dụng sự kết hợp của ID mục và template ngôn ngữ tự nhiên để trải qua continued pre-training cho các nhiệm vụ gợi ý khác nhau⁶.

-DROS [50]. Đây là phương pháp gợi ý tuần tự state-of-the-art sử dụng các kỹ thuật tối ưu hóa robust phân phối để tăng cường độ mạnh mẽ của gợi ý chống lại những thay đổi phân phối.

-GPT4Rec-LLaMA [27] là phiên bản cải tiến của phương pháp gợi ý dựa trên mô hình ngôn ngữ, GPT4Rec. Phương pháp gốc sử dụng GPT-2 để tạo ra "search queries" giả định dựa trên dữ liệu lịch sử của người dùng, sau đó được tìm kiếm bằng cách sử dụng công cụ tìm kiếm BM25⁷ để truy xuất các mục được gợi ý. Để đảm bảo so sánh công bằng, chúng tôi đã thay thế mô hình GPT-2 bằng mô hình LLaMA-7B và thực hiện điều chỉnh mô hình bằng kỹ thuật LoRA [20].

Chúng tôi chủ yếu sử dụng các LLM chỉ decoder làm mô hình LLM backbone trong phương pháp BIGRec của chúng tôi, do vai trò nổi bật của chúng trong lĩnh vực LLM. Cụ thể, chúng tôi đã chọn LLaMA-7B làm lựa chọn mặc định cho nghiên cứu này. Ngoài GPT4Rec, còn có các phương pháp gợi ý dựa trên LLM khác, chẳng hạn như TALLRec [3]. Tuy nhiên, vì những phương pháp này không áp dụng được cho cài đặt all-ranking của chúng tôi, chúng tôi không so sánh chúng trong nghiên cứu của chúng tôi.

4.1.4 Chi tiết Triển khai. Chúng tôi triển khai tất cả các phương pháp của chúng tôi bằng PyTorch. Để tiền xử lý dữ liệu, đầu tiên chúng tôi pad lịch sử tương tác người dùng với độ dài nhỏ hơn 11 đến độ dài cố định là 11. Sau đó, chúng tôi sử dụng sliding window độ dài 11 để trích xuất các chuỗi, trong đó mục cuối cùng trong mỗi chuỗi được sử dụng làm mục tiêu dự đoán, và các mục trước đó từ chuỗi tương tác quá khứ cho nó. Đối với tất cả các mô hình thông thường, chúng tôi tối ưu hóa chúng bằng cách sử dụng binary cross-entropy loss và lấy mẫu negative samples đồng đều. Chúng tôi sử dụng Adam [24] làm optimizer với learning rate được điều chỉnh là 1e-3, batch size là 1024 và điều chỉnh weight decay trong phạm vi [1e-2,1e-3,1e-4,1e-5,1e-6,1e-7]. Về các siêu tham số của kiến trúc mô hình thông thường, chúng tôi đặt embedding size của chúng là 64 và tỷ lệ dropout là 0.1. Như được gợi ý bởi các bài báo gốc, chúng tôi chỉ sử dụng một lớp GRU cho GRU4Rec; đối với SASRec, chúng tôi đặt số lượng self-attention heads và blocks là 1. Chúng tôi triển khai DROS dựa trên SASRec, vì nó hoạt động tốt nhất trong hầu hết các tình huống trong số ba phương pháp gợi ý tuần tự thông thường. Đối với các phương pháp dựa trên LLM, chúng tôi theo thiết lập Alpaca [39], trực tiếp đặt learning rate là 1e-4 và sử dụng optimizer AdamW [31]. Trong quá trình tạo sinh, do

⁶ Để so sánh công bằng, chúng tôi chỉ giữ lại nhiệm vụ gợi ý tuần tự và các template đa dạng tương ứng trong quá trình huấn luyện.
⁷ Chúng tôi sử dụng gói Rank-BM25 tại https://github.com/dorianbrown/rank_bm25.

Bản thảo được gửi tới ACM

--- TRANG 9 ---
Một Mô hình Grounding Hai Bước cho Mô hình Ngôn ngữ Lớn trong Hệ thống Gợi ý 9

Bảng 2. So sánh hiệu suất mô hình trong thiết lập huấn luyện few-shot (1024 mẫu) với NDCG@K (NG@K) và HR@K (HR@K) làm chỉ số. Kết quả tốt nhất được đánh dấu bằng chữ đậm, và kết quả tối ưu thứ hai được gạch chân. 'Improve' đề cập đến sự cải thiện tương đối của BIGRec so với baseline tốt nhất.

[Bảng chi tiết với kết quả hiệu suất cho Movie và Game datasets]

chi phí tính toán và suy luận đáng kể liên quan đến việc sử dụng rộng rãi GPU được hiển thị trong Hình 2(b), chúng tôi theo thiết lập của công trình trước đó [5, 8, 41] và sử dụng beam size là 4 để tạo ra đầu ra có ý nghĩa.

Đối với các siêu tham số của BM25, chúng tôi theo phạm vi điều chỉnh được cung cấp trong bài báo GPT4Rec [27]. Để lựa chọn mô hình, chúng tôi sử dụng chiến lược early stop với patience là 20 epochs cho các phương pháp baseline và 5 epochs cho các phương pháp dựa trên LLM. Ngoài ra, chúng tôi báo cáo kết quả trung bình cho ba random seeds. Đối với siêu tham số γ trong Eq. (3), do các phương pháp tính toán khác nhau được sử dụng bởi các mô hình truyền thống và mô hình gợi ý dựa trên LLM, khi kết hợp thông tin, chúng tôi đã tiến hành tìm kiếm chi tiết để tích hợp cân bằng của cả hai phương pháp⁸.

4.2 So sánh Hiệu suất với Dữ liệu Huấn luyện Hạn chế (RQ1)

Đầu tiên chúng tôi theo công trình hiện tại [3] để nghiên cứu hiệu quả của phương pháp với dữ liệu huấn luyện hạn chế (1024 điểm huấn luyện) trên mỗi bộ dữ liệu. Chúng tôi so sánh nó với các baseline được huấn luyện với số lượng mẫu huấn luyện tương đương. Kết quả so sánh được tóm tắt trong Bảng 2, từ đó chúng tôi rút ra các quan sát chính sau:

• Khi dữ liệu huấn luyện bị hạn chế, các baseline tuần tự thông thường (GRU4Rec, Caser, SASRec) thể hiện hiệu suất tồi tệ hơn đáng kể so với BIGRec được triển khai với LLM. Những kết quả này không gây ngạc nhiên vì các baseline này dựa vào ID embeddings để xây dựng mô hình gợi ý, điều này khó học tốt với dữ liệu hạn chế. Ngược lại, BIGRec nhanh chóng tận dụng kiến thức ngữ nghĩa của LLM thu được trong giai đoạn pre-training để đạt được gợi ý hiệu quả. Những phát hiện này chứng minh tính ưu việt của BIGRec so với các mô hình gợi ý truyền thống khi xử lý dữ liệu huấn luyện hạn chế. Hơn nữa, sự cải thiện của BIGRec so với các baseline này ở các vị trí được xếp hạng cao hơn nhiều, cho thấy BIGRec có thể có xu hướng xếp hạng các mục mà người dùng quan tâm ở các vị trí cao hơn.

• Mặc dù GPT4Rec-LLaMA cũng dựa trên LLM, nó thể hiện hiệu suất kém so với BIGRec. Chúng tôi cho rằng điều này do BM25, cũng có thể được coi là một phương pháp để ground đầu ra LLM vào các mục thực tế, không phù hợp với nhiệm vụ gợi ý. BM25 là một công cụ truy xuất được thiết kế cho văn bản cấp độ tài liệu. Tuy nhiên, đối với hai bộ dữ liệu được sử dụng trong nghiên cứu của chúng tôi, các queries trong GPT4Rec (tiêu đề mục) rất ngắn. Kết quả là, BM25 dễ bị ảnh hưởng bởi tác động của nhiễu từ tần suất thấp, khiến việc truy xuất chính xác các mục liên quan trở nên khó khăn.

• Sự cải thiện của BIGRec so với các mô hình thông thường cao hơn đáng kể đối với bộ dữ liệu Game so với bộ dữ liệu Movie. Sự khác biệt này có thể do các thuộc tính khác nhau của thiên vị độ phổ biến giữa hai bộ dữ liệu. Các phương pháp thông thường có xu hướng nắm bắt thiên vị phổ biến, trong khi BIGRec ít bị ảnh hưởng bởi thiên vị độ phổ biến. Do đó, các phương pháp thông thường có thể hoạt động tốt hơn trên bộ dữ liệu Movie, trong đó các mục phổ biến đóng vai trò thống trị hơn như được chứng minh bởi Hình 2(a).

Hơn nữa, chúng tôi cũng chứng minh tiềm năng của BIGRec để grounding vào các không gian mục thực tế khác nhau đồng thời. Để khám phá điều này, chúng tôi ngẫu nhiên chọn 1024 mẫu từ hai miền (Movie và Game) để huấn luyện mô hình của chúng tôi và kiểm tra nó trên các tập kiểm tra của hai miền, tương ứng. Như được hiển thị trong Hình 3, kết quả chứng minh rằng BIGRec được huấn luyện trên dữ liệu hai miền hoạt động tương đương trên mỗi miền riêng lẻ so với khi nó được huấn luyện trên dữ liệu của miền đơn. Những phát hiện này gợi ý rằng BIGRec có thể đồng thời ground LLM vào các không gian mục thực tế khác nhau, ít nhất ở cấp độ các miền khác nhau.

4.3 So sánh Hiệu suất với Baselines được Huấn luyện với Nhiều Dữ liệu hơn (RQ2)

Dựa trên những cải thiện hiệu suất đáng kể được chứng minh bởi BIGRec so với các baseline được huấn luyện trên dữ liệu hạn chế, chúng tôi tiếp tục hiểu sự chênh lệch giữa BIGRec được huấn luyện trên dữ liệu hạn chế và các baseline được huấn luyện với lượng dữ liệu lớn hơn đáng kể (100 hoặc thậm chí 1.000 lần nhiều hơn) để khám phá mức độ của khoảng cách này.

Bảng 3 chứa kết quả của các baseline được huấn luyện với nhiều dữ liệu hơn, bao gồm hơn 7 triệu chuỗi cho Movie và 120 nghìn cho Game, cùng với kết quả của BIGRec được huấn luyện với chỉ 1024 mẫu⁹. Từ bảng, chúng tôi thấy rằng, so với các baseline thông thường (loại trừ DROS) trên dữ liệu Movie, BIGRec thể hiện hiệu suất tốt hơn ở vị trí đầu của danh sách gợi ý, nhưng hoạt động tệ hơn đối với các vị trí tương đối thấp của danh sách gợi ý. Trái với kết quả thu được từ bộ dữ liệu Movie, phương pháp của chúng tôi liên tục chứng minh hiệu suất vượt trội so với các mô hình truyền thống (loại trừ DROS) khi áp dụng cho dữ liệu Game. So sánh với

⁹ Do hạn chế về tài nguyên tính toán, chúng tôi chỉ trình bày kết quả của các baseline tiêu tốn tài nguyên tính toán đáng kể trên bộ dữ liệu Game.

Bản thảo được gửi tới ACM

--- TRANG 10 ---
10 Bao và Zhang, et al.

[Hình 3. So sánh hiệu suất của BIGRec được huấn luyện trên dữ liệu đa miền (labeled as "Multi") và BIGRec được huấn luyện trên dữ liệu miền đích đơn (labeled as "Single"), được hiển thị cho NDCG@K trên các miền Movie và Game.]

phương pháp truyền thống được tối ưu hóa kỹ lưỡng và state-of-the-art DROS, BIGRec được huấn luyện với chỉ 1024 mẫu vẫn có thể cho thấy hiệu suất tương đương trong hầu hết các trường hợp. Dựa trên kết quả, chúng tôi rút ra hai kết luận:

• Phương pháp của chúng tôi, BIGRec, được huấn luyện trên một tập con tương đối nhỏ của bộ dữ liệu chỉ với 1.024 mẫu, đã cho thấy hiệu suất tương đương với các mô hình thông thường được huấn luyện với số lượng dữ liệu lớn hơn đáng kể, với 100 hoặc thậm chí 1.000 lần lớn hơn, đặc biệt khi tài nguyên gợi ý (exposure) bị hạn chế. Những phát hiện này làm nổi bật tính thực tế của việc sử dụng LLM cho hệ thống gợi ý. Đồng thời, kết quả cũng gợi ý rằng có tiềm năng để tăng cường thêm hiệu suất của BIGRec bằng cách tăng kích thước tập huấn luyện và mở rộng phạm vi các mục mà nó đã gặp trong quá trình grounding (xem BIGRec (full) trong Bảng 3).

• Khi so sánh với bộ dữ liệu Game, bộ dữ liệu Movie thể hiện mật độ cao hơn và dễ bị thiên vị độ phổ biến hơn (như được chứng minh bởi hiệu suất của các phương pháp Most-Pop trên hai bộ dữ liệu và Hình 2(a)). Sự khác biệt trong mức độ cải thiện hiệu suất của BIGRec giữa hai bộ dữ liệu cho thấy rằng BIGRec hoạt động đặc biệt tốt trong các tình huống mà dữ liệu khan hiếm và hoạt động hiệu quả với sự phụ thuộc ít hơn vào thiên vị độ phổ biến.

4.4 Hiệu suất của BIGRec với Việc Tăng Mẫu Huấn luyện (RQ3)

Khi so sánh kết quả của các phương pháp dựa trên ID truyền thống (như SASRec và DROS) trong Bảng 2 và Bảng 3, rõ ràng là việc tăng dữ liệu huấn luyện có thể nâng cao hiệu suất mô hình. Sự cải thiện này có thể được

Bản thảo được gửi tới ACM

--- TRANG 11 ---
Một Mô hình Grounding Hai Bước cho Mô hình Ngôn ngữ Lớn trong Hệ thống Gợi ý 11

Bảng 3. So sánh hiệu suất giữa các baseline được huấn luyện với dữ liệu đầy đủ, BIGRec (0) không huấn luyện mô hình, BIGRec (1024) được huấn luyện với 1024 mẫu, và BIGRec (full) được huấn luyện với dữ liệu đầy đủ. "Most-Pop" đề cập đến phương pháp gợi ý các mục phổ biến nhất. Kết quả tốt nhất được đánh dấu bằng chữ đậm và kết quả tối ưu thứ hai được gạch chân. BIGRec (full) trên Movie bị bỏ qua do chi phí tính toán cao.

[Bảng chi tiết với kết quả hiệu suất cho Movie và Game datasets với các cấu hình khác nhau]

quy cho thực tế rằng việc tăng dữ liệu huấn luyện hỗ trợ trong việc thu thập thông tin thống kê (ví dụ, độ phổ biến và thông tin collaborative) chứa trong bộ dữ liệu, điều này được chứng minh là có lợi cho gợi ý [37, 57].

Để điều tra liệu LLM cũng có thể nắm bắt thông tin thống kê cục bộ trong bộ dữ liệu bằng cách tăng lượng dữ liệu huấn luyện để tăng cường hiệu suất hay không, chúng tôi phân tích hiệu suất của BIGRec khi tăng dữ liệu huấn luyện trên Game. Hình 4 minh họa đường cong hiệu suất khi tăng dữ liệu huấn luyện, cũng như đường cong mô tả sự cải thiện hiệu suất so với trạng thái ban đầu. Như được hiển thị trong hình, so với các mô hình gợi ý truyền thống, việc tăng khối lượng dữ liệu có tác động hạn chế đến sự cải thiện hiệu suất của BIGRec. Chúng tôi đoán rằng BIGRec ít tích cực hơn trong việc nắm bắt thống kê có trong bộ dữ liệu, và thay vào đó thích sử dụng thông tin ngữ nghĩa của LLM để hoàn thành nhiệm vụ trong khi bỏ qua thông tin thống kê có giá trị. Do đó, việc tăng dữ liệu huấn luyện không thể nâng cao đáng kể hiệu suất BIGRec so với các phương pháp dựa trên ID truyền thống.

4.5 Hiệu suất của Việc Giới thiệu Thông tin Thống kê Có giá trị (RQ4)

Những suy đoán nêu trên gợi ý rằng BIGRec phụ thuộc nhiều vào thông tin ngữ nghĩa được lưu trữ trong LLM trong khi bỏ qua thông tin thống kê có giá trị của bộ dữ liệu. Dưới ánh sáng này, chúng tôi tin rằng việc kết hợp thông tin thống kê có giá trị một cách thích hợp có thể nâng cao khả năng gợi ý của BIGRec. Cân nhắc là thông tin có thể bị BIGRec bỏ qua trong quá trình huấn luyện nhưng thực sự mô tả một số đặc điểm hữu ích của các mục thực tế, và do đó việc kết hợp nó có thể tăng cường việc grounding của BIGRec vào không gian mục thực tế. Để xác minh điều này, chúng tôi tiến hành thí nghiệm bằng cách giới thiệu hai loại thông tin thống kê: thông tin độ phổ biến và thông tin collaborative, tương ứng. Lưu ý rằng hai loại thông tin này được công nhận là có giá trị cho hệ thống gợi ý [37, 57].

• Giới thiệu thông tin độ phổ biến. Đầu tiên chúng tôi nghiên cứu hiệu suất của BIGRec khi giới thiệu thông tin độ phổ biến của bộ dữ liệu huấn luyện bằng phương pháp trong Eq. (3). Chúng tôi tiến hành thí nghiệm trên bộ dữ liệu Movie, xét rằng thông tin độ phổ biến quan trọng hơn trên đó. Chúng tôi so sánh phiên bản gốc của BIGRec với phiên bản kết hợp thông tin độ phổ biến trong Hình 5. Hình này chứng minh rằng sau khi kết hợp thông tin độ phổ biến, BIGRec đạt được sự cải thiện hiệu suất đối với các chỉ số NDCG@K và Recall@K, đặc biệt đối với

Bản thảo được gửi tới ACM

--- TRANG 12 ---
12 Bao và Zhang, et al.

[Hình 4. Hiệu suất của SASRec, DROS, và BIGRec khi kích thước dữ liệu huấn luyện tăng (được biểu thị bằng Sample Num), cùng với các đường cong cải thiện hiệu suất tương ứng so với trạng thái ban đầu (1024 mẫu huấn luyện). Các hình phụ bên dưới thể hiện hiệu suất gợi ý (được đo bằng NDCG@K), trong khi các hình phụ bên trên minh họa sự cải thiện.]

các giá trị 𝐾 lớn hơn. Ngoài ra, hiệu suất tốt hơn đáng kể so với khi chỉ sử dụng thông tin độ phổ biến cho gợi ý (như được hiển thị trong Bảng 3). Những kết quả này chỉ ra rằng việc tiêm thông tin độ phổ biến có thể có lợi cho việc grounding đầu ra của LLM vào các mục thực tế trong BIGRec, tiếp tục tăng cường hiệu suất của nó.

• Giới thiệu thông tin collaborative. Tiếp theo chúng tôi nghiên cứu hiệu suất của BIGRec khi kết hợp thông tin collaborative được mã hóa bởi các mô hình thông thường (ví dụ, DROS) vào nó bằng phương pháp trong Phương trình (3). Để so sánh, chúng tôi cũng xem xét việc kết hợp thông tin collaborative vào các mô hình thông thường. Hiệu suất được hiển thị trong Bảng 3, và sự cải thiện hiệu suất được hiển thị trong Hình 6. Từ bảng và hình, chúng tôi rút ra hai quan sát: 1) việc kết hợp thông tin collaborative vào cả BIGRec và các mô hình truyền thống đều có thể mang lại sự cải thiện hiệu suất mô hình; 2) việc kết hợp thông tin collaborative vào BIGRec mang lại sự nâng cao đáng kể hơn so với việc kết hợp thông tin vào một mô hình thông thường khác. Những kết quả này chỉ ra rằng

Bản thảo được gửi tới ACM

--- TRANG 13 ---
Một Mô hình Grounding Hai Bước cho Mô hình Ngôn ngữ Lớn trong Hệ thống Gợi ý 13

[Hình 5. So sánh hiệu suất giữa BIGRec với việc tiêm độ phổ biến trong quá trình grounding (labeled as "Injected") và BIGRec gốc. Các chỉ số NDCG@K và HR@K được hiển thị cho các giá trị K khác nhau.]

[Hình 6. Cải thiện hiệu suất của SASRec, Caser, BIGRec (1024), và BIGRec (full) được kết hợp với DROS trên bộ dữ liệu Game. Các cải thiện liên quan đến giá trị lớn hơn của hiệu suất của hai mô hình kết hợp, được ký hiệu là 'Improve2LV'. Đáng chú ý, tất cả các baseline ở đây (SASRec, Caser, và DROS) đều được huấn luyện trên bộ dữ liệu đầy đủ.]

BIGRec phụ thuộc nhiều hơn vào thông tin khác (thông tin ngữ nghĩa) khác với thông tin collaborative để tạo ra gợi ý, do đó việc kết hợp thông tin collaborative có thể mang lại nhiều lợi ích hơn.

Hai thí nghiệm chỉ ra rằng có tiềm năng đáng kể để tiến bộ độ chính xác gợi ý hơn nữa bằng cách điều tra các kỹ thuật hiệu quả và hiệu suất hơn để nâng cao việc grounding vào không gian mục thực tế trong BIGRec.

5 KẾT LUẬN VÀ CÔNG VIỆC TƯƠNG LAI

Trong bài báo này, chúng tôi nhằm thảo luận kỹ lưỡng về hiệu suất trên tất cả các thứ hạng cho LLM4Rec. Để tận dụng đầy đủ tiềm năng của LLM, chúng tôi xây dựng một mô hình grounding hai bước cho gợi ý (BIGRec), theo phương pháp tạo sinh có thể kết hợp thông tin thống kê một cách hiệu quả. Những phát hiện thực nghiệm của chúng tôi chỉ ra rằng BIGRec được huấn luyện trên 1024 mẫu vượt trội đáng kể so với các mô hình gợi ý truyền thống được huấn luyện trên số lượng mẫu giống hệt, đạt được hiệu suất ngang bằng thậm chí với các mô hình thông thường được huấn luyện trên bộ dữ liệu đầy đủ trong hầu hết các trường hợp. Hơn nữa, chúng tôi đã mở rộng dữ liệu huấn luyện cho gợi ý dựa trên LLM. Kết quả chỉ ra rằng LLM phụ thuộc nhiều vào ngữ nghĩa cho gợi ý trong khi bỏ qua một số thông tin hữu ích khác. Dựa trên cái nhìn sâu sắc này, chúng tôi đã truyền thông tin độ phổ biến và collaborative vào LLM, tiếp tục tăng cường khả năng của nó và xác thực giả định của chúng tôi.

Xét từ các thảo luận nêu trên, có thể suy ra rằng việc sử dụng phương pháp grounding hai bước trong gợi ý dựa trên LLM cho thấy hứa hẹn. Tuy nhiên, một số vấn đề chưa được giải quyết vẫn tồn tại. Thứ nhất, về giai đoạn đầu tiên của grounding trong không gian gợi ý, các thí nghiệm của chúng tôi tiết lộ rằng hiệu suất gợi ý thỏa đáng có thể đạt được với số lượng mẫu tương đối nhỏ. Bên cạnh đó, việc tăng thêm kích thước mẫu có thể tăng cường hiệu suất. Tuy nhiên, có hai cân nhắc đối lập. Một mặt, việc huấn luyện LLM phát sinh chi phí đáng kể. Liệu có khả thi khi chọn các mẫu thích hợp để xây dựng không gian gợi ý, từ đó giảm chi phí liên quan? Mặt khác, câu hỏi liệu tất cả các mục có nên thuộc về cùng một không gian gợi ý vẫn là chủ đề tranh luận.

Hơn nữa, liên quan đến bước grounding thứ hai, phương pháp chúng tôi hiện tại sử dụng khá thô sơ, việc trích xuất embeddings bằng mô hình decoder và tính toán độ tương tự là một hoạt động cơ bản. Mặc dù khả năng điều chỉnh việc sản xuất mẫu với beam size lớn, phương pháp này rất tốn thời gian. Do đó, điều cần thiết là tìm một phương pháp hiệu quả hơn để kết nối với các mục thực tế. Hơn nữa, chúng tôi đã xác nhận tính khả thi của việc tích hợp độ phổ biến mục và thông tin collaborative trong quá trình grounding. Chúng tôi hy vọng sẽ kết hợp các tính năng gợi ý thông thường hơn một cách hiệu quả hơn để cải thiện thêm hiệu suất mô hình.

TÀI LIỆU THAM KHẢO

[1] Michael Ahn, Anthony Brohan, Noah Brown, Yevgen Chebotar, Omar Cortes, Byron David, Chelsea Finn, Chuyuan Fu, Keerthana Gopalakrishnan, Karol Hausman, et al. 2022. Do as i can, not as i say: Grounding language in robotic affordances. arXiv preprint arXiv:2204.01691 (2022).

[2] Qingyao Ai, Ting Bai, and et al. 2023. Information Retrieval Meets Large Language Models: A Strategic Report from Chinese IR Community. arXiv preprint arXiv:2307.09751 (2023).

[3] Keqin Bao, Jizhi Zhang, Yang Zhang, Wenjie Wang, Fuli Feng, and Xiangnan He. 2023. Tallrec: An effective and efficient tuning framework to align large language model with recommendation. Recsys short (2023).

[4] Lisa Beinborn, Teresa Botschen, and Iryna Gurevych. 2018. Multimodal grounding for language processing. arXiv preprint arXiv:1806.06371 (2018).

[5] Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020. Language Models are Few-Shot Learners. In Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual, Hugo Larochelle, Marc'Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin (Eds.). https://proceedings.neurips.cc/paper/2020/hash/

Bản thảo được gửi tới ACM

--- TRANG 15 ---
Một Mô hình Grounding Hai Bước cho Mô hình Ngôn ngữ Lớn trong Hệ thống Gợi ý 15

1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html

[6] Zheng Chen. 2023. PALR: Personalization Aware LLMs for Recommendation. arXiv preprint arXiv:2305.07622 (2023).

[7] Wei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng, Zhanghao Wu, Hao Zhang, Lianmin Zheng, Siyuan Zhuang, Yonghao Zhuang, Joseph E. Gonzalez, Ion Stoica, and Eric P. Xing. 2023. Vicuna: An Open-Source Chatbot Impressing GPT-4 with 90%* ChatGPT Quality. https://lmsys.org/blog/2023-03-30-vicuna/

[8] Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, et al. 2022. Palm: Scaling language modeling with pathways. arXiv preprint arXiv:2204.02311 (2022).

[9] Qiang Cui, Shu Wu, Qiang Liu, Wen Zhong, and Liang Wang. 2020. MV-RNN: A Multi-View Recurrent Neural Network for Sequential Recommendation. IEEE Trans. Knowl. Data Eng. 32, 2 (2020), 317–331. https://doi.org/10.1109/TKDE.2018.2881260

[10] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers). Association for Computational Linguistics, Minneapolis, Minnesota, 4171–4186. https://doi.org/10.18653/v1/N19-1423

[11] Sihao Ding, Fuli Feng, Xiangnan He, Jinqiu Jin, Wenjie Wang, Yong Liao, and Yongdong Zhang. 2022. Interpolative Distillation for Unifying Biased and Debiased Recommendation. In SIGIR '22: The 45th International ACM SIGIR Conference on Research and Development in Information Retrieval, Madrid, Spain, July 11 - 15, 2022, Enrique Amigó, Pablo Castells, Julio Gonzalo, Ben Carterette, J. Shane Culpepper, and Gabriella Kazai (Eds.). ACM, 40–49. https://doi.org/10.1145/3477495.3532002

[12] Tim Donkers, Benedikt Loepp, and Jürgen Ziegler. 2017. Sequential user-based recurrent neural network recommendations. In Proceedings of the eleventh ACM conference on recommender systems. 152–160.

[13] Danny Driess, Fei Xia, Mehdi SM Sajjadi, Corey Lynch, Aakanksha Chowdhery, Brian Ichter, Ayzaan Wahid, Jonathan Tompson, Quan Vuong, Tianhe Yu, et al. 2023. Palm-e: An embodied multimodal language model. arXiv preprint arXiv:2303.03378 (2023).

[14] Wenqi Fan, Zihuai Zhao, Jiatong Li, Yunqing Liu, Xiaowei Mei, Yiqi Wang, Jiliang Tang, and Qing Li. 2023. Recommender Systems in the Era of Large Language Models (LLMs). arXiv preprint arXiv:2307.02046 (2023).

[15] Hui Fang, Danning Zhang, Yiheng Shu, and Guibing Guo. 2020. Deep Learning for Sequential Recommendation: Algorithms, Influential Factors, and Evaluations. ACM Trans. Inf. Syst. 39, 1 (2020), 10:1–10:42. https://doi.org/10.1145/3426723

[16] Luke Friedman, Sameer Ahuja, David Allen, Terry Tan, Hakim Sidahmed, Changbo Long, Jun Xie, Gabriel Schubiner, Ajay Patel, Harsh Lara, et al. 2023. Leveraging Large Language Models in Conversational Recommender Systems. arXiv preprint arXiv:2305.07961 (2023).

[17] Shijie Geng, Shuchang Liu, Zuohui Fu, Yingqiang Ge, and Yongfeng Zhang. 2022. Recommendation as language processing (rlp): A unified pretrain, personalized prompt & predict paradigm (p5). In Proceedings of the 16th ACM Conference on Recommender Systems. 299–315.

[18] Balázs Hidasi, Alexandros Karatzoglou, Linas Baltrunas, and Domonkos Tikk. 2016. Session-based Recommendations with Recurrent Neural Networks. In ICLR.

[19] Yupeng Hou, Shanlei Mu, Wayne Xin Zhao, Yaliang Li, Bolin Ding, and Ji-Rong Wen. 2022. Towards universal sequence representation learning for recommender systems. In Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining. 585–593.

[20] Edward J. Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. 2022. LoRA: Low-Rank Adaptation of Large Language Models. In The Tenth International Conference on Learning Representations, ICLR 2022, Virtual Event, April 25-29, 2022. OpenReview.net. https://openreview.net/forum?id=nZeVKeeFYf9

[21] Yitong Ji, Aixin Sun, Jie Zhang, and Chenliang Li. 2023. A critical study on data leakage in recommender system offline evaluation. ACM Transactions on Information Systems 41, 3 (2023), 1–27.

[22] Chen Ju, Tengda Han, Kunhao Zheng, Ya Zhang, and Weidi Xie. 2022. Prompting visual-language models for efficient video understanding. In European Conference on Computer Vision. Springer, 105–124.

[23] Wang-Cheng Kang and Julian J. McAuley. 2018. Self-Attentive Sequential Recommendation. In IEEE International Conference on Data Mining, ICDM 2018, Singapore, November 17-20, 2018. IEEE Computer Society, 197–206.

[24] Diederik P. Kingma and Jimmy Ba. 2015. Adam: A Method for Stochastic Optimization. In 3rd International Conference on Learning Representations, ICLR 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings, Yoshua Bengio and Yann LeCun (Eds.). http://arxiv.org/abs/1412.6980

[25] Walid Krichene and Steffen Rendle. 2020. On sampled metrics for item recommendation. In Proceedings of the 26th ACM SIGKDD international conference on knowledge discovery & data mining. 1748–1757.

[26] Jiatong Li, Yunqing Liu, Wenqi Fan, Xiao-Yong Wei, Hui Liu, Jiliang Tang, and Qing Li. 2023. Empowering Molecule Discovery for Molecule-Caption Translation with Large Language Models: A ChatGPT Perspective. arXiv preprint arXiv:2306.06615 (2023).

[27] Jinming Li, Wentao Zhang, Tian Wang, Guanglei Xiong, Alan Lu, and Gerard Medioni. 2023. GPT4Rec: A generative framework for personalized recommendation and user interests interpretation. arXiv preprint arXiv:2304.03879 (2023).

[28] Ruyu Li, Wenhao Deng, Yu Cheng, Zheng Yuan, Jiaqi Zhang, and Fajie Yuan. 2023. Exploring the Upper Limits of Text-Based Collaborative Filtering Using Large Language Models: Discoveries and Insights. arXiv preprint arXiv:2305.11700 (2023).

[29] Xiujun Li, Xi Yin, Chunyuan Li, Pengchuan Zhang, Xiaowei Hu, Lei Zhang, Lijuan Wang, Houdong Hu, Li Dong, Furu Wei, et al. 2020. Oscar: Object-semantics aligned pre-training for vision-language tasks. In Computer Vision–ECCV 2020: 16th European Conference, Glasgow, UK, August 23–28, 2020, Proceedings, Part XXX 16. Springer, 121–137.

Bản thảo được gửi tới ACM

--- TRANG 16 ---
16 Bao và Zhang, et al.

[30] Junling Liu, Chao Liu, Renjie Lv, Kang Zhou, and Yan Zhang. 2023. Is chatgpt a good recommender? a preliminary study. arXiv preprint arXiv:2304.10149 (2023).

[31] Ilya Loshchilov and Frank Hutter. 2019. Decoupled Weight Decay Regularization. In 7th International Conference on Learning Representations, ICLR 2019, New Orleans, LA, USA, May 6-9, 2019. OpenReview.net. https://openreview.net/forum?id=Bkg6RiCqY7

[32] Yabo Ni, Dan Ou, Shichen Liu, Xiang Li, Wenwu Ou, Anxiang Zeng, and Luo Si. 2018. Perceive Your Users in Depth: Learning Universal User Representations from Multiple E-commerce Tasks. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, KDD 2018, London, UK, August 19-23, 2018, Yike Guo and Faisal Farooq (Eds.). ACM, 596–605. https://doi.org/10.1145/3219819.3219828

[33] Ruihong Qiu, Zi Huang, Hongzhi Yin, and Zijian Wang. 2021. Contrastive Learning for Representation Degeneration Problem in Sequential Recommendation. CoRR abs/2110.05730 (2021). arXiv:2110.05730 https://arxiv.org/abs/2110.05730

[34] Ruihong Qiu, Zi Huang, Hongzhi Yin, and Zijian Wang. 2022. Contrastive Learning for Representation Degeneration Problem in Sequential Recommendation. In WSDM '22: The Fifteenth ACM International Conference on Web Search and Data Mining, Virtual Event / Tempe, AZ, USA, February 21 - 25, 2022, K. Selcuk Candan, Huan Liu, Leman Akoglu, Xin Luna Dong, and Jiliang Tang (Eds.). ACM, 813–823. https://doi.org/10.1145/3488560.3498433

[35] Alec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. 2019. Language Models are Unsupervised Multitask Learners. (2019).

[36] Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J Liu. 2020. Exploring the limits of transfer learning with a unified text-to-text transformer. The Journal of Machine Learning Research 21, 1 (2020), 5485–5551.

[37] Xiaoyuan Su and Taghi M Khoshgoftaar. 2009. A survey of collaborative filtering techniques. Advances in artificial intelligence 2009 (2009).

[38] Jiaxi Tang and Ke Wang. 2018. Personalized top-n sequential recommendation via convolutional sequence embedding. In WSDM. 565–573.

[39] Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy Liang, and Tatsunori B. Hashimoto. 2023. Stanford Alpaca: An Instruction-following LLaMA model. https://github.com/tatsu-lab/stanford_alpaca.

[40] Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, Aurélien Rodriguez, Armand Joulin, Edouard Grave, and Guillaume Lample. 2023. LLaMA: Open and Efficient Foundation Language Models. CoRR abs/2302.13971 (2023). https://doi.org/10.48550/arXiv.2302.13971 arXiv:2302.13971

[41] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017. Attention is All you Need. In Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems 2017, December 4-9, 2017, Long Beach, CA, USA, Isabelle Guyon, Ulrike von Luxburg, Samy Bengio, Hanna M. Wallach, Rob Fergus, S. V. N. Vishwanathan, and Roman Garnett (Eds.). 5998–6008. https://proceedings.neurips.cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html

[42] Shoujin Wang, Liang Hu, Yan Wang, Longbing Cao, Quan Z. Sheng, and Mehmet A. Orgun. 2019. Sequential Recommender Systems: Challenges, Progress and Prospects. In Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence, IJCAI 2019, Macao, China, August 10-16, 2019, Sarit Kraus (Ed.). ijcai.org, 6332–6338. https://doi.org/10.24963/ijcai.2019/883

[43] Zhenlei Wang, Shiqi Shen, Zhipeng Wang, Bo Chen, Xu Chen, and Ji-Rong Wen. 2022. Unbiased Sequential Recommendation with Latent Confounders. In WWW '22: The ACM Web Conference 2022, Virtual Event, Lyon, France, April 25 - 29, 2022, Frédérique Laforest, Raphaël Troncy, Elena Simperl, Deepak Agarwal, Aristides Gionis, Ivan Herman, and Lionel Médini (Eds.). ACM, 2195–2204. https://doi.org/10.1145/3485447.3512092

[44] Zekun Wang, Ge Zhang, Kexin Yang, Ning Shi, Wangchunshu Zhou, Shaochun Hao, Guangzheng Xiong, Yizhi Li, Mong Yuan Sim, Xiuying Chen, et al. 2023. Interactive natural language processing. arXiv preprint arXiv:2305.13246 (2023).

[45] Hongyi Wen, Xinyang Yi, Tiansheng Yao, Jiaxi Tang, Lichan Hong, and Ed H Chi. 2022. Distributionally-robust Recommendations for Improving Worst-case User Experience. In Proceedings of the ACM Web Conference 2022. 3606–3610.

[46] Likang Wu, Zhi Zheng, Zhaopeng Qiu, Hao Wang, Hongchao Gu, Tingjia Shen, Chuan Qin, Chen Zhu, Hengshu Zhu, Qi Liu, et al. 2023. A Survey on Large Language Models for Recommendation. arXiv preprint arXiv:2305.19860 (2023).

[47] Lingxi Xie, Longhui Wei, Xiaopeng Zhang, Kaifeng Bi, Xiaotao Gu, Jianlong Chang, and Qi Tian. 2023. Towards AGI in Computer Vision: Lessons Learned from GPT and Large Language Models. arXiv preprint arXiv:2306.08641 (2023).

[48] Chengfeng Xu, Jian Feng, Pengpeng Zhao, Fuzhen Zhuang, Deqing Wang, Yanchi Liu, and Victor S. Sheng. 2021. Long- and short-term self-attention network for sequential recommendation. Neurocomputing 423 (2021), 580–589. https://doi.org/10.1016/j.neucom.2020.10.066

[49] An Yan, Shuo Cheng, Wang-Cheng Kang, Mengting Wan, and Julian J. McAuley. 2019. CosRec: 2D Convolutional Neural Networks for Sequential Recommendation. In Proceedings of the 28th ACM International Conference on Information and Knowledge Management, CIKM 2019, Beijing, China, November 3-7, 2019, Wenwu Zhu, Dacheng Tao, Xueqi Cheng, Peng Cui, Elke A. Rundensteiner, David Carmel, Qi He, and Jeffrey Xu Yu (Eds.). ACM, 2173–2176. https://doi.org/10.1145/3357384.3358113

[50] Zhengyi Yang, Xiangnan He, Jizhi Zhang, Jiancan Wu, Xin Xin, Jiawei Chen, and Xiang Wang. 2023. A Generic Learning Framework for Sequential Recommendation with Distribution Shifts. In Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval.

[51] Fajie Yuan, Xiangnan He, Alexandros Karatzoglou, and Liguang Zhang. 2020. Parameter-Efficient Transfer from Sequential Behaviors for User Modeling and Recommendation. In Proceedings of the 43rd International ACM SIGIR conference on research and development in Information Retrieval, SIGIR 2020, Virtual Event, China, July 25-30, 2020, Jimmy X. Huang, Yi Chang, Xueqi Cheng, Jaap Kamps, Vanessa Murdock, Ji-Rong Wen, and Yiqun Liu (Eds.). ACM, 1469–1478. https://doi.org/10.1145/3397271.3401156

Bản thảo được gửi tới ACM

--- TRANG 17 ---
Một Mô hình Grounding Hai Bước cho Mô hình Ngôn ngữ Lớn trong Hệ thống Gợi ý 17

[52] Fajie Yuan, Alexandros Karatzoglou, Ioannis Arapakis, Joemon M. Jose, and Xiangnan He. 2019. A Simple Convolutional Generative Network for Next Item Recommendation. In Proceedings of the Twelfth ACM International Conference on Web Search and Data Mining, WSDM 2019, Melbourne, VIC, Australia, February 11-15, 2019, J. Shane Culpepper, Alistair Moffat, Paul N. Bennett, and Kristina Lerman (Eds.). ACM, 582–590. https://doi.org/10.1145/3289600.3290975

[53] Yan Zeng, Xinsong Zhang, Hang Li, Jiawei Wang, Jipeng Zhang, and Wangchunshu Zhou. 2022. X2-VLM: All-In-One Pre-trained Model For Vision-Language Tasks. CoRR abs/2211.12402 (2022). https://doi.org/10.48550/arXiv.2211.12402 arXiv:2211.12402

[54] Jizhi Zhang, Keqin Bao, Yang Zhang, Wenjie Wang, Fuli Feng, and Xiangnan He. 2023. Is chatgpt fair for recommendation? evaluating fairness in large language model recommendation. arXiv preprint arXiv:2305.07609 (2023).

[55] Junjie Zhang, Ruobing Xie, Yupeng Hou, Wayne Xin Zhao, Leyu Lin, and Ji-Rong Wen. 2023. Recommendation as instruction following: A large language model empowered recommendation approach. arXiv preprint arXiv:2305.07001 (2023).

[56] Tingting Zhang, Pengpeng Zhao, Yanchi Liu, Victor S. Sheng, Jiajie Xu, Deqing Wang, Guanfeng Liu, and Xiaofang Zhou. 2019. Feature-level Deeper Self-Attention Network for Sequential Recommendation. In Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence, IJCAI 2019, Macao, China, August 10-16, 2019, Sarit Kraus (Ed.). ijcai.org, 4320–4326. https://doi.org/10.24963/ijcai.2019/600

[57] Yang Zhang, Fuli Feng, Xiangnan He, Tianxin Wei, Chonggang Song, Guohui Ling, and Yongdong Zhang. 2021. Causal Intervention for Leveraging Popularity Bias in Recommendation. In Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval (Virtual Event, Canada) (SIGIR '21). Association for Computing Machinery, New York, NY, USA, 11–20. https://doi.org/10.1145/3404835.3462875

[58] Yang Zhang, Tianhao Shi, Fuli Feng, Wenjie Wang, Dingxian Wang, Xiangnan He, and Yongdong Zhang. 2023. Reformulating CTR Prediction: Learning Invariant Feature Interactions. In Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval.

[59] Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, Yifan Du, Chen Yang, Yushuo Chen, Zhipeng Chen, Jinhao Jiang, Ruiyang Ren, Yifan Li, Xinyu Tang, Zikang Liu, Peiyu Liu, Jian-Yun Nie, and Ji-Rong Wen. 2023. A Survey of Large Language Models. CoRR abs/2303.18223 (2023). arXiv:2303.18223

[60] Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric. P Xing, Hao Zhang, Joseph E. Gonzalez, and Ion Stoica. 2023. Judging LLM-as-a-judge with MT-Bench and Chatbot Arena. arXiv:2306.05685 [cs.CL]

[61] Deyao Zhu, Jun Chen, Xiaoqian Shen, Xiang Li, and Mohamed Elhoseiny. 2023. MiniGPT-4: Enhancing Vision-Language Understanding with Advanced Large Language Models. arXiv preprint arXiv:2304.10592 (2023).

Bản thảo được gửi tới ACM

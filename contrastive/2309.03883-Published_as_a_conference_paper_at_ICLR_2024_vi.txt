# 2309.03883.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/contrastive/2309.03883.pdf
# Kích thước tệp: 704245 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Đã xuất bản như một bài báo hội nghị tại ICLR 2024
DOLA: GIẢI MÃ BẰNG CÁCH ĐỐI LẬP CÁC LỚP CẢI THIỆN
TÍNH CHÍNH XÁC TRONG CÁC MÔ HÌNH NGÔN NGỮ LỚN
Yung-Sung Chuang†⋆, Yujia Xie‡, Hongyin Luo†, Yoon Kim†, James Glass†, Pengcheng He‡
†Massachusetts Institute of Technology,‡Microsoft
yungsung@mit.edu, yujiaxie@microsoft.com
{hyluo,yoonkim,glass }@mit.edu, herbert.he@gmail.com
TÓM TẮT
Mặc dù có khả năng ấn tượng, các mô hình ngôn ngữ lớn (LLMs) dễ bị ảo giác, tức là tạo ra nội dung sai lệch so với sự thật được thấy trong quá trình huấn luyện trước. Chúng tôi đề xuất một chiến lược giải mã đơn giản để giảm ảo giác với các LLMs đã được huấn luyện trước mà không cần điều kiện trên kiến thức bên ngoài được truy xuất hay tinh chỉnh bổ sung. Phương pháp của chúng tôi thu được phân phối token tiếp theo bằng cách đối lập sự khác biệt trong logits thu được từ việc chiếu các lớp sau so với các lớp trước vào không gian từ vựng, khai thác thực tế rằng kiến thức thực tế trong LLMs thường được chỉ ra là được định vị tại các lớp transformer cụ thể. Chúng tôi thấy rằng phương pháp Giải mã bằng Đối lập Các lớp (DoLa) này có thể tốt hơn trong việc hiển thị kiến thức thực tế và giảm việc tạo ra các sự thật không chính xác. DoLa liên tục cải thiện tính trung thực trên các nhiệm vụ lựa chọn đa phương án và các nhiệm vụ tạo mở, ví dụ cải thiện hiệu suất của các mô hình họ LLaMA trên TruthfulQA 12-17% điểm tuyệt đối, thể hiện tiềm năng trong việc làm cho LLMs tạo ra các sự thật chính xác một cách đáng tin cậy.1

1 GIỚI THIỆU
Các mô hình ngôn ngữ lớn (LLMs) đã thể hiện tiềm năng lớn trong nhiều ứng dụng xử lý ngôn ngữ tự nhiên (NLP) (Brown et al., 2020; OpenAI, 2022; 2023). Tuy nhiên, mặc dù hiệu suất liên tục tăng và sự xuất hiện của các khả năng mới từ việc mở rộng LLMs (Wei et al., 2022a), xu hướng "ảo giác" của chúng, tức là tạo ra nội dung sai lệch so với sự thật thế giới thực được quan sát trong quá trình huấn luyện trước (Ji et al., 2023), vẫn là một thách thức dai dẳng. Điều này đại diện cho một rào cản chính trong việc triển khai chúng đặc biệt là trong các ứng dụng cần mức cao (ví dụ, môi trường lâm sàng/pháp lý) nơi việc tạo ra văn bản đáng tin cậy một cách đáng tin cậy là rất quan trọng.

Mặc dù các lý do chính xác cho ảo giác của LMs không được hiểu đầy đủ, một lý do có thể là do mục tiêu mô hình hóa ngôn ngữ likelihood tối đa mà giảm thiểu sự phân kỳ KL thuận giữa phân phối dữ liệu và mô hình. Mục tiêu này có thể dẫn đến một mô hình với hành vi tìm kiếm khối lượng gây ra LM gán xác suất khác không cho các câu không hoàn toàn nhất quán với kiến thức được nhúng trong dữ liệu huấn luyện. Theo kinh nghiệm, một LM được huấn luyện với mục tiêu dự đoán từ tiếp theo trên dữ liệu hữu hạn đã được chỉ ra dẫn đến một mô hình sử dụng kiến thức ngôn ngữ học để nhận biết các mô hình bề ngoài, thay vì nhận biết và tạo ra các sự thật thế giới thực được trích xuất từ corpus huấn luyện (Ji et al., 2023).

Từ góc độ khả năng diễn giải mô hình, các LMs transformer đã được chỉ ra một cách lỏng lẻo để mã hóa thông tin "cấp thấp hơn" (ví dụ, các thẻ part-of-speech) trong các lớp trước, và thông tin "ngữ nghĩa" hơn trong các lớp sau (Tenney et al., 2019). Gần đây hơn, Dai et al. (2022) thấy rằng "các nơron kiến thức" được phân phối trong các lớp trên cùng của mô hình BERT đã được huấn luyện trước. Meng et al. (2022) chỉ ra rằng kiến thức thực tế

1Mã nguồn có sẵn tại https://github.com/voidism/DoLa .
⋆Công việc chủ yếu được thực hiện trong thời gian thực tập tại Microsoft.

--- TRANG 2 ---
Đã xuất bản như một bài báo hội nghị tại ICLR 2024
… … LLaMA -7B 
lớp thứ 8 lớp thứ 16 lớp thứ 24 
thoát 
sớm
thoát 
sớm
Thủ đô của 
Bang Washington là đâu? Giải mã bằng 
Đối lập Các lớp
Seattle
Olympia
Vancouver
Spokane
… lớp thứ 32 
… thoát 
sớm Olympia 
Seattle
Olympia
Vancouver
Spokane
Đối lập!
Hình 1: Minh họa về một LLM dần dần kết hợp thông tin thực tế qua các lớp. Trong khi xác suất từ tiếp theo của " Seattle " vẫn tương tự qua các lớp khác nhau, xác suất của câu trả lời đúng " Olympia " dần tăng từ lớp thấp đến lớp cao. DoLa sử dụng thực tế này để giải mã bằng cách đối lập sự khác biệt giữa các lớp để làm sắc nét xác suất của LLM hướng tới đầu ra chính xác về mặt thực tế.

thậm chí có thể được chỉnh sửa bằng cách thao tác một tập hợp cụ thể các lớp feedforward trong một LM tự hồi quy. Chúng tôi đề xuất khai thác việc mã hóa kiến thức theo mô-đun này để khuếch đại kiến thức thực tế trong một LM thông qua phương pháp giải mã đối lập, trong đó xác suất từ tiếp theo đầu ra được thu được từ sự khác biệt trong logits giữa lớp cao hơn so với lớp thấp hơn. Bằng cách nhấn mạnh kiến thức của các lớp cao hơn và giảm bớt của các lớp thấp hơn, chúng ta có thể làm cho LMs trở nên thực tế hơn và do đó giảm ảo giác.

Một minh họa về ý tưởng này cho một ví dụ đơn giản được hiển thị trong Hình 1. Trong khi " Seattle " duy trì xác suất cao qua tất cả các lớp—có thể vì nó là một câu trả lời có thể chấp nhận về mặt cú pháp—xác suất của câu trả lời đúng " Olympia " tăng sau khi các lớp cao hơn tiêm thêm kiến thức thực tế. Đối lập sự khác biệt giữa các lớp khác nhau do đó có thể tiết lộ câu trả lời đúng trong trường hợp này. Dựa trên khái niệm này, chúng tôi đề xuất một phương pháp giải mã mới, Giải mã bằng Đối lập Các lớp (DoLa), để tốt hơn trong việc hiển thị kiến thức thực tế được nhúng trong một LLM mà không cần truy xuất kiến thức bên ngoài hay tinh chỉnh bổ sung.

Các thí nghiệm trên TruthfulQA (Lin et al., 2022) và FACTOR Muhlgay et al. (2023) chứng minh rằng DoLa có thể tăng tính trung thực của các mô hình thuộc họ LLaMA (Touvron et al., 2023). Các thí nghiệm tiếp theo về lý luận chuỗi suy nghĩ cho StrategyQA (Geva et al., 2021) và GSM8K (Cobbe et al., 2021) cũng cho thấy rằng nó có thể tạo điều kiện cho lý luận thực tế hơn. Cuối cùng, các thí nghiệm sử dụng GPT-4 để đánh giá chatbot đầu mở (Chiang et al., 2023) cho thấy rằng khi so sánh với phương pháp giải mã gốc, DoLa có thể tạo ra các phản hồi thông tin và thực tế hơn đáng kể dẫn đến đánh giá tốt hơn từ GPT-4. Từ góc độ hiệu quả, chúng tôi thấy rằng DoLa chỉ gây ra một độ trễ nhỏ bổ sung trong quá trình giải mã, gợi ý nó như một chiến lược giải mã thực tế và hữu ích để cải thiện tính trung thực của LLMs.

2 PHƯƠNG PHÁP
Các mô hình ngôn ngữ gần đây bao gồm một lớp nhúng, N lớp transformer xếp chồng, và một lớp affine ϕ(·) để dự đoán phân phối từ tiếp theo. Cho một chuỗi tokens {x1, x2, . . . , x t−1}, lớp nhúng đầu tiên nhúng các tokens thành một chuỗi vectơ H0={h(0)1, . . . , h(0)t−1}. Sau đó H0 sẽ được xử lý bởi mỗi lớp transformer liên tiếp. Chúng tôi ký hiệu đầu ra của lớp thứ j là Hj. Sau đó, head từ vựng ϕ(·) dự đoán xác suất của token tiếp theo xt trên tập từ vựng X,

p(xt|x<t) = softmax ϕ(h(N)t) xt, x t∈ X.

Thay vì áp dụng ϕ trên lớp cuối cùng, phương pháp của chúng tôi đối lập thông tin lớp cao hơn và lớp thấp hơn để thu được xác suất token tiếp theo. Cụ thể hơn, đối với lớp sớm thứ j, chúng tôi cũng tính toán xác suất token tiếp theo

--- TRANG 3 ---
Đã xuất bản như một bài báo hội nghị tại ICLR 2024
W
ole So
yink a là
người
Nigeria
đầu tiên
thắng
Giải Nobel
, vào
năm 1986.
30 1.9 0.0 0.03 1.76 0.0 0.0 6.45 0.29 0.07 0.6 0.01 0.48 0.13 0.1 0.02 0.11 2.97 1.84 0.12 0.0 0.0 0.0 7.56 0.23
28 4.78 0.04 0.42 10.5 0.05 0.07 3.65 0.21 0.02 0.63 0.0 0.29 0.17 0.02 0.04 0.02 4.77 1.89 6.13 9.76 12.4 15.16 16.86 0.16
26 11.41 3.15 7.15 12.67 5.28 3.5 1.22 0.08 0.02 0.75 0.0 0.18 0.15 0.12 0.05 0.04 3.77 1.19 4.58 16.56 19.31 18.66 19.67 0.13
24 13.21 8.6 10.01 14.28 8.99 8.44 0.8 0.26 0.02 0.44 0.0 2.51 0.08 7.37 0.06 0.04 2.08 0.71 6.68 18.72 23.84 21.68 21.31 0.1
22 14.26 18.81 11.61 15.7 12.34 9.29 0.75 4.57 0.03 0.24 0.0 2.4 0.09 6.57 0.05 0.02 2.03 0.38 8.27 17.82 22.89 22.98 21.46 2.07
20 10.18 15.95 12.99 16.32 13.52 11.07 1.85 9.78 0.03 0.06 0.04 0.39 0.73 6.28 0.02 0.03 11.41 4.36 9.19 16.84 19.57 20.38 19.45 10.26
18 7.75 15.97 12.59 16.46 14.52 12.25 7.76 8.33 5.15 6.47 2.48 5.73 10.67 7.41 1.29 8.92 13.57 10.99 12.59 14.02 19.57 16.98 15.63 12.9
16 8.99 16.05 12.81 17.45 15.47 13.52 9.8 11.18 10.73 10.97 12.1 11.4 14.52 13.09 10.34 11.86 14.34 12.16 13.7 13.73 19.44 17.05 15.85 13.47
14 9.06 16.14 13.33 17.83 16.24 14.0 10.63 13.03 12.78 12.66 15.07 13.2 16.06 14.71 13.61 13.61 14.09 12.04 14.19 14.4 19.76 17.17 16.24 12.87
12 9.75 16.3 13.47 17.92 16.45 14.94 11.52 13.95 14.11 13.92 15.82 14.23 16.76 15.6 14.81 14.42 14.47 13.48 14.47 15.02 19.44 17.4 16.45 13.57
10 10.22 16.4 13.63 18.1 16.24 15.52 12.4 14.54 14.71 14.2 16.34 14.85 16.78 15.66 15.02 15.06 14.53 13.8 14.13 14.96 19.63 17.7 16.62 13.42
8 10.66 16.57 14.04 18.24 16.2 16.21 12.66 14.42 15.09 14.09 16.82 14.71 16.88 15.57 15.2 15.31 14.44 13.89 14.47 15.15 19.93 17.93 16.81 13.9
6 10.68 16.49 14.2 18.38 16.3 16.62 13.18 14.53 15.4 14.27 17.81 15.44 16.98 15.82 15.43 15.8 14.27 14.16 14.65 15.54 19.79 18.2 17.14 13.92
4 10.65 16.59 14.31 18.53 16.38 16.77 13.43 15.02 15.99 14.53 18.29 15.5 17.29 16.33 15.9 16.14 14.31 14.53 14.69 15.81 19.93 18.38 17.4 14.25
2 10.8 16.69 14.29 18.64 16.74 16.9 13.36 15.23 15.97 14.76 18.68 15.45 17.31 16.71 16.05 16.46 14.58 14.51 14.84 16.02 20.13 18.6 17.67 14.44
0 11.0 16.69 14.51 18.78 16.82 17.09 13.54 15.6 16.47 14.88 19.12 15.88 17.45 16.98 16.26 16.87 14.85 15.34 15.16 16.34 20.46 18.79 17.83 14.95

Đầu vào: Ai là người Nigeria đầu tiên thắng giải Nobel, vào năm nào?
Đầu ra: Wole Soyinka là người Nigeria đầu tiên thắng giải Nobel, vào năm 1986.

lớp sớm thứ i
Hình 2: JSD (được chia tỷ lệ 105) giữa lớp 32 cuối cùng và các lớp sớm có số chẵn. Tên cột là các tokens được giải mã trong mỗi bước. Tên hàng là chỉ số của các lớp sớm. 0 có nghĩa là lớp nhúng từ.

token tiếp theo sử dụng ϕ(·) như sau, trong đó J ⊂ { 0, . . . , N −1} là một tập hợp các lớp ứng viên,

qj(xt|x<t) = softmax ϕ(h(j)t) xt, j∈ J.

Ý tưởng áp dụng đầu ngôn ngữ trực tiếp vào các trạng thái ẩn của các lớp giữa, được biết đến như thoát sớm (Teerapittayanon et al., 2016; Elbayad et al., 2020; Schuster et al., 2022), đã được chứng minh là hiệu quả ngay cả khi không có quy trình huấn luyện đặc biệt (Kao et al., 2020), vì các kết nối dư (He et al., 2016) trong các lớp transformer làm cho các biểu diễn ẩn dần phát triển mà không có thay đổi đột ngột. Sử dụng qj(xt) để đại diện cho qj(xt|x<t) để ngắn gọn về ký hiệu, chúng tôi sau đó tính toán xác suất của token tiếp theo bằng,

ˆp(xt|x<t) = softmax F qN(xt), qM(xt) xt,

trong đó M= arg max j∈J d qN(·), qj(·) .

Ở đây, lớp M được gọi là lớp chưa trưởng thành, trong khi lớp cuối cùng, tức là lớp N, được gọi là lớp trưởng thành. Toán tử F(·,·), sẽ được mở rộng thêm trong Mục 2.3, được sử dụng để đối lập giữa các phân phối đầu ra từ lớp chưa trưởng thành và lớp trưởng thành bằng cách tính toán sự khác biệt miền log giữa hai phân phối. Lớp chưa trưởng thành được chọn động trong mỗi bước giải mã sử dụng một biện pháp khoảng cách phân phối d(·,·) (chúng tôi sử dụng Độ phân kỳ Jensen-Shannon) giữa lớp trưởng thành và tất cả các lớp ứng viên trong J. Chúng tôi thảo luận d(·,·) chi tiết hơn trong Mục 2.2. Động lực để chọn lớp có khoảng cách d(·,·) cao nhất là để đảm bảo rằng mô hình sẽ thay đổi đáng kể đầu ra của nó sau lớp được chọn đó, và do đó có cơ hội cao hơn để bao gồm nhiều kiến thức thực tế hơn mà không tồn tại trong các lớp sớm trước nó.

2.1 KIẾN THỨC THỰC TẾ PHÁT TRIỂN QUA CÁC LỚP

Chúng tôi tiến hành phân tích sơ bộ với LLaMA-7B 32 lớp (Touvron et al., 2023) để thúc đẩy phương pháp của chúng tôi. Chúng tôi tính toán Độ phân kỳ Jensen-Shannon (JSD) giữa các phân phối đầu ra thoát sớm qj(· |x<t) và phân phối đầu ra lớp cuối cùng qN(· |x<t), để chỉ ra cách các đầu ra thoát sớm khác với đầu ra lớp cuối cùng. Hình 2 cho thấy các JSD khi giải mã câu trả lời cho câu hỏi đầu vào, từ đó chúng ta có thể quan sát hai mô hình. Mô hình #1 xảy ra khi dự đoán các thực thể tên quan trọng hoặc ngày tháng, như Wole Soyinka và 1986 trong Hình 2, đòi hỏi kiến thức thực tế. Chúng tôi quan sát JSD được tính toán vẫn cực kỳ cao trong các lớp cao hơn. Mô hình này cho thấy rằng mô hình vẫn đang thay đổi dự đoán của nó trong vài lớp cuối cùng, và có khả năng tiêm thêm kiến thức thực tế vào các dự đoán.

Mô hình #2 xảy ra khi dự đoán các từ chức năng, như là, các, đến, trong, và các tokens được sao chép từ câu hỏi đầu vào, như người Nigeria đầu tiên, Giải Nobel. Khi dự đoán các tokens "dễ" này, chúng ta có thể quan sát rằng JSD trở nên rất nhỏ từ các lớp giữa. Phát hiện này cho thấy rằng mô hình đã quyết định token nào để tạo ra trong các lớp giữa, và giữ các phân phối đầu ra hầu như không thay đổi trong các lớp cao hơn.

--- TRANG 4 ---
Đã xuất bản như một bài báo hội nghị tại ICLR 2024
… … LLaMA-7B 
lớp thứ 16 lớp thứ 24 lớp thứ 32
thoát 
sớm
thoát 
sớm
Tác giả của 
Thuyết Tương đối từ đâu? DoLa 
Đầu ra
<s> Albert Einstein là
… 
lớp thứ 8 
… thoát 
sớm
từ Albert Einstein là từ Đức 
Đối lập!
Đối lập!
Đối lập!
Đối lập!
Đối lập!
Hình 3: Minh họa về cách chọn lớp chưa trưởng thành động hoạt động.

lớp. Phát hiện này cũng nhất quán với các giả định trong các LMs thoát sớm (Schuster et al., 2022). Một phân tích sơ bộ có thể hỗ trợ định lượng cho quan sát này cũng được hiển thị trong Phụ lục A.

Về mặt định tính, khi dự đoán từ tiếp theo đòi hỏi kiến thức thực tế, LLaMA có vẻ như thay đổi các dự đoán trong các lớp cao hơn. Đối lập các lớp trước/sau một thay đổi đột ngột do đó có thể khuếch đại kiến thức nổi lên từ các lớp cao hơn và làm cho mô hình dựa nhiều hơn vào kiến thức nội bộ thực tế của nó. Hơn nữa, sự phát triển thông tin này có vẻ thay đổi theo từng token. Phương pháp của chúng tôi đòi hỏi việc chọn chính xác lớp chưa trưởng thành chứa thông tin hợp lý nhưng ít thực tế hơn, có thể không luôn ở trong cùng một lớp sớm. Do đó, chúng tôi đề xuất chọn lớp chưa trưởng thành động như được minh họa trong Hình 3.

2.2 CHỌN LỚP CHƯA TRƯỞNG THÀNH ĐỘNG

Để phóng đại hiệu quả của giải mã đối lập, lớp chưa trưởng thành tối ưu lý tưởng nên là lớp khác biệt nhất so với đầu ra lớp cuối cùng. Để cho phép chọn lớp chưa trưởng thành động tại mỗi bước thời gian, chúng tôi áp dụng biện pháp khoảng cách sau giữa các phân phối từ tiếp theo thu được từ hai lớp,

d qN(·|x<t), qj(·|x<t) =JSD qN(·|x<t)||qj(·|x<t) ,

trong đó JSD (·,·) là độ phân kỳ Jensen-Shannon. Lớp chưa trưởng thành, tức là lớp M ( 0≤M < N ), sau đó được chọn là lớp có độ phân kỳ tối đa trong tập con các lớp sớm,

M= arg max j∈J JSD qN(·|x<t)||qj(·|x<t) ,

trong đó J là một tập hợp các lớp ứng viên để chọn lớp chưa trưởng thành. Đối với các mô hình LLaMA với số lượng lớp khác nhau, chúng tôi chia các lớp thành 2 đến 4 nhóm của J dựa trên tổng số lớp của chúng, để tập trung vào việc đối lập từ một phạm vi nhất định của các lớp. Nhóm tốt nhất cho mỗi nhiệm vụ được chọn sử dụng một tập xác thực, như được chi tiết trong Mục 3.1. Chiến lược chọn lớp động này cho phép việc chọn các lớp chưa trưởng thành phù hợp dựa trên độ khó của token, do đó tận dụng tốt hơn kiến thức được học bởi các lớp khác nhau.

Bên cạnh chiến lược chọn lớp động, một phương pháp rất đơn giản cũng có thể được xem xét là chọn lớp chưa trưởng thành bằng cách chạy các thí nghiệm vũ phu trên tất cả các lớp sớm có thể với một tập xác thực, và chọn lớp có hiệu suất xác thực tốt nhất. Chúng tôi gọi phương pháp đơn giản này là DoLa-static. Tuy nhiên, DoLa-static có nhược điểm là 1) yêu cầu nhiều chạy tìm kiếm siêu tham số hơn trong các lớp và thực tế rằng 2) các lớp tốt nhất nhạy cảm với phân phối dữ liệu, do đó yêu cầu các tập xác thực trong phân phối. Chiến lược chọn lớp động đề xuất của chúng tôi cũng giảm thiểu nhược điểm của DoLa-static bằng cách thu hẹp không gian tìm kiếm lớp và làm cho phương pháp mạnh mẽ hơn mà không dựa nhiều vào các tập xác thực trong phân phối.

Chúng tôi điều tra thực nghiệm hiệu quả của chiến lược động này so với DoLa-static trong Mục 4.1.

--- TRANG 5 ---
Đã xuất bản như một bài báo hội nghị tại ICLR 2024

2.3 ĐỐI LẬP CÁC DỰ ĐOÁN

Cho các lớp chưa trưởng thành và trưởng thành thu được từ Mục 2.2, chúng tôi nhằm khuếch đại đầu ra lớp trưởng thành trong khi giảm bớt đầu ra lớp chưa trưởng thành. Theo phương pháp Giải mã Đối lập từ Li et al. (2022), chúng tôi trừ xác suất log của đầu ra lớp chưa trưởng thành khỏi của lớp trưởng thành. Sau đó chúng tôi sử dụng phân phối kết quả này làm dự đoán từ tiếp theo, như được minh họa trong Hình 1,

ˆp(xt|x<t) = softmax F qN(xt), qM(xt) xt, trong đó

F qN(xt), qM(xt) = { log qN(xt)/qM(xt), nếu xt∈ V head(xt|x<t), −∞, nếu không.

Tương tự như Li et al. (2022), tập con Vhead(xt|x<t)∈ X được định nghĩa là liệu token có xác suất đầu ra đủ cao từ lớp trưởng thành hay không,

Vhead(xt|x<t) = { xt∈ X : qN(xt)≥α max w qN(w) }.

Nếu xác suất dự đoán của một token quá nhỏ trong lớp trưởng thành, nó không có khả năng là một dự đoán hợp lý, vì vậy chúng tôi đặt xác suất token về zero để giảm thiểu các trường hợp dương tính giả và âm tính giả. Trong bối cảnh của DoLa, dương tính giả có nghĩa là một token không hợp lý với điểm số cực thấp có thể được thưởng với điểm số cao sau khi đối lập, do phạm vi xác suất thấp không ổn định trên các tokens không hợp lý này từ các lớp khác nhau. Âm tính giả có nghĩa là khi mô hình rất tự tin về một quyết định dễ dàng, xác suất đầu ra của một token điểm số cao không thay đổi nhiều trong các lớp khác nhau và dẫn đến điểm số thấp sau đối lập, vì vậy chúng tôi cần buộc mô hình vẫn chọn từ các tokens điểm số cao này trong trường hợp này. Chiến lược này được gọi là ràng buộc hợp lý thích ứng (APC) được đề xuất trong Li et al. (2022).

Phạt Lặp lại. Động lực của DoLa là giảm bớt kiến thức ngôn ngữ học lớp thấp hơn và khuếch đại kiến thức thực tế thế giới thực. Tuy nhiên, điều này có thể dẫn đến mô hình tạo ra các đoạn văn không đúng ngữ pháp. Theo kinh nghiệm, chúng tôi không quan sát vấn đề như vậy, nhưng chúng tôi thấy rằng phân phối DoLa kết quả đôi khi có xu hướng lặp lại các câu đã tạo trước đó cao hơn (Xu et al., 2022), đặc biệt là trong quá trình tạo các chuỗi dài của lý luận chuỗi suy nghĩ. Ở đây chúng tôi bao gồm một phạt lặp lại đơn giản được giới thiệu trong Keskar et al. (2019) với θ= 1.2 trong quá trình giải mã. Phân tích thực nghiệm của phạt lặp lại được hiển thị trong Phụ lục K.

3 THÍ NGHIỆM

3.1 THIẾT LẬP

Bộ dữ liệu. Chúng tôi xem xét các nhiệm vụ lựa chọn đa phương án và tạo đầu mở. Đối với lựa chọn đa phương án, chúng tôi sử dụng TruthfulQA (Lin et al., 2022) và FACTOR (News/Wiki) (Muhlgay et al., 2023) để đánh giá tính thực tế của LMs trong các thiết lập câu trả lời ngắn/đoạn dài, tương ứng. Đối với tạo đầu mở, chúng tôi sử dụng TruthfulQA (được đánh giá bởi GPT-3 được tinh chỉnh) (Lin et al., 2022) và các nhiệm vụ liên quan đến lý luận chuỗi suy nghĩ (Wei et al., 2022b): StrategyQA (Geva et al., 2021) và GSM8K Cobbe et al. (2021). Cuối cùng, chúng tôi thử nghiệm Vicuna QA (Chiang et al., 2023) sử dụng GPT-4 để đánh giá khả năng tuân theo hướng dẫn làm trợ lý chatbot.

Mô hình và Baseline. Chúng tôi kiểm tra bốn kích thước mô hình LLaMA (Touvron et al., 2023) (7B, 13B, 33B, 65B) và so sánh chúng với ba baseline: 1) giải mã gốc (giải mã greedy hoặc sampling tùy thuộc vào các nhiệm vụ), 2) Giải mã Đối lập (CD) (Li et al., 2022), trong đó LLaMA-7B đóng vai trò như mô hình nghiệp dư và LLaMA-13B/33B/65B hoạt động như các mô hình chuyên gia, và 3) Can thiệp Thời gian Suy luận (ITI). ITI sử dụng LLaMA-7B và một phân loại tuyến tính được huấn luyện trên TruthfulQA. Thí nghiệm của chúng tôi tập trung vào việc đối lập sự khác biệt lớp trong DoLa và sự khác biệt mô hình trong CD, mà không có các kỹ thuật bổ sung, như giới hạn cửa sổ ngữ cảnh cho lớp chưa trưởng thành hoặc mô hình nghiệp dư, để làm cho thiết lập của chúng tôi sạch sẽ. Chúng tôi đặt ràng buộc hợp lý thích ứng (α) thành 0.1 và phạt lặp lại (θ) thành 1.2 theo các nghiên cứu trước (Li et al., 2022; Keskar et al., 2019).

--- TRANG 6 ---
Đã xuất bản như một bài báo hội nghị tại ICLR 2024

Mô hình TruthfulQA (MC) FACTOR TruthfulQA (Tạo Đầu Mở) CoT
MC1 MC2 MC3 News Wiki %Truth ↑%Info ↑%T∗I↑%Reject ↓StrQA GSM8K
LLaMa-7B 25.6 40.6 19.2 58.3 58.6 30.4 96.3 26.9 2.9 60.1 10.8
+ ITI (Li et al., 2023) 25.9 - - - - 49.1 - 43.5 - - -
+ DoLa 32.2 63.8 32.1 62.0 62.2 42.1 98.3 40.8 0.6 64.1 10.5
LLaMa-13B 28.3 43.3 20.8 61.1 62.6 38.8 93.6 32.4 6.7 66.6 16.7
+ CD (Li et al., 2022) 24.4 41.0 19.0 62.3 64.4 55.3 80.2 44.4 20.3 60.3 9.1
+ DoLa 28.9 64.9 34.8 62.5 66.2 48.8 94.9 44.6 2.1 67.6 18.0
LLaMa-33B 31.7 49.5 24.2 63.8 69.5 62.5 69.0 31.7 38.1 69.9 33.8
+ CD (Li et al., 2022) 33.0 51.8 25.7 63.3 71.3 81.5 45.0 36.7 62.7 66.7 28.4
+ DoLa 30.5 62.3 34.0 65.4 70.3 56.4 92.4 49.1 8.2 72.1 35.5
LLaMa-65B 30.8 46.9 22.7 63.6 72.2 50.2 84.5 34.8 19.1 70.5 51.2
+ CD (Li et al., 2022) 29.3 47.0 21.5 64.6 71.3 75.0 57.9 43.4 44.6 70.5 44.0
+ DoLa 31.1 64.6 34.3 66.2 72.4 54.3 94.7 49.2 4.8 72.9 54.0

Bảng 1: Kết quả thí nghiệm trên 1) bộ dữ liệu lựa chọn đa phương án: TruthfulQA và FACTOR và 2) các nhiệm vụ tạo đầu mở: TruthfulQA và các nhiệm vụ lý luận Chuỗi Suy nghĩ (CoT), bao gồm StrategyQA (StrQA) và GSM8K. %T∗I là viết tắt của %Truth ∗Info trong TruthfulQA.

Các Lớp Ứng viên. Trong chọn lớp chưa trưởng thành động, chúng tôi phân chia các lớp transformer thành các nhóm và chọn một nhóm làm lớp ứng viên (J). Đối với LLaMA-7B 32 lớp, chúng tôi sử dụng hai nhóm: [0, 16), [16, 32); đối với LLaMA-13B 40 lớp, chúng là [0, 20), [20, 40); đối với LLaMA-33B 60 lớp, ba nhóm: [0, 20), [20, 40), [40, 60); và đối với LLaMA-65B 80 lớp, bốn nhóm: [0, 20), [20, 40), [40, 60), [60, 80), trong đó lớp thứ 0 là nhúng từ. Thiết kế này giới hạn không gian tìm kiếm siêu tham số chỉ 2-4 lần chạy xác thực. Để hiệu quả, chỉ các lớp có chỉ số chẵn (0, 2, v.v.) được xem xét làm ứng viên. Chúng tôi sử dụng xác thực hai-fold (TruthfulQA-MC, FACTOR) hoặc một tập xác thực (GSM8K, StrategyQA) để chọn nhóm tốt nhất. Đối với Vicuna QA, thiếu tập xác thực, chúng tôi sử dụng nhóm tốt nhất của GSM8K.

3.2 LỰA CHỌN ĐA PHƯƠNG ÁN

Tính Thực tế Câu Trả lời Ngắn. Chúng tôi thử nghiệm TruthfulQA với prompt QA mặc định từ Lin et al. (2022) và Li et al. (2023). Đối với α trong APC, chúng tôi thay thế −∞ bằng −1000 để tránh phá hỏng điểm số khả năng LM, điều này cũng áp dụng cho FACTOR. Phạt lặp lại không cần thiết cho tính toán điểm số khả năng. Chúng tôi sử dụng xác thực hai-fold để xác định nhóm tốt nhất của các lớp ứng viên dựa trên điểm số MC3. Kết quả trong Bảng 1 cho thấy cải thiện hiệu suất đáng kể cho các mô hình LLaMA ở bốn kích thước, vượt trội so với ITI/CD và xác nhận hiệu quả của DoLa. Ngoại lệ duy nhất là LLaMA-33B trên MC1, một chỉ số "người chiến thắng lấy tất cả" nhạy cảm hơn với dao động. Ngược lại, MC2/MC3 là các chỉ số tương đối ổn định hơn vì chúng xem xét tất cả các câu trả lời đúng/sai cùng nhau và tính trung bình chúng để tính toán điểm số. Các lớp cao hơn được chọn nhất quán trong xác thực hai-fold—7B: [16, 32); 13B: [20, 40); 33B: [40, 60); 65B: [60, 80). Chi tiết triển khai và kết quả bổ sung của việc đối lập với lớp thứ 0 / tất cả các lớp được hiển thị trong Phụ lục C.

Tính Thực tế Đoạn Dài. Trong FACTOR, mỗi ví dụ có một đoạn dài và bốn kết thúc, với một là đúng. Các tập con News và Wiki được sử dụng làm hai fold cho xác thực hai-fold. Bảng 1 cho thấy DoLa vượt trội so với baseline 2-4%, và hiệu quả hơn CD, ngoại trừ 13B trên Wiki. Các lớp ứng viên được chọn nhất quán là các phần thấp hơn cho FACTOR: [0, 16) cho 7B và [0, 20) cho 13/33/65B. Điều này khác với TruthfulQA, chọn các lớp cao hơn. Chúng tôi tin rằng điều này là do TruthfulQA có các lựa chọn ngắn, quan trọng về sự thật, trong khi FACTOR có các lựa chọn câu dài. Như đã lưu ý trong Mục 2.1, đối lập với các lớp cao hơn hoạt động tốt hơn cho các sự thật chính, trong khi đối lập với các lớp thấp hơn có thể chăm sóc tốt hơn tất cả các tokens nếu chúng bao gồm nhiều tokens không phải sự thật mà không yêu cầu được đối lập với các lớp cao hơn.

3.3 TẠO VĂN BẢN ĐẦU MỞ

Tính Thực tế Câu Trả lời Ngắn. Trong các thiết lập đầu mở, TruthfulQA được đánh giá bởi GPT-3 được tinh chỉnh trên điểm số trung thực và thông tin. Một điểm số trung thực 100% có thể dễ dàng đạt được bằng cách trả lời "Tôi không có bình luận", nhưng dẫn đến điểm số thông tin 0%. Chúng tôi sử dụng prompt QA mặc định như trong Lin et al. (2022) và Li et al. (2023), với các lớp ứng viên cao hơn để giải mã, theo kết quả xác thực hai-fold của Mục 3.2. Bảng 1

--- TRANG 7 ---
Đã xuất bản như một bài báo hội nghị tại ICLR 2024

400 425 450 475 500 525 550 575
Điểm số 7B 13B 33B 65B
LLaMA
LLaMA+DoLA

0 10 20 30 40 50 60 70 80
Số trò chơi 7B 13B 33B 65B
43 4 33 52 3 25 42 3 35 39 3 38 Thắng
Hòa
Thua

Hình 4: Kết quả Vicuna QA của LLaMA so với LLaMA+DoLa, được đánh giá bởi GPT-4. Trái: Tổng điểm số. Phải: Số lần thắng/hòa/thua của LLaMA+DoLA so với LLaMA.

cho thấy DoLa liên tục nâng cao điểm số trung thực, giữ điểm số thông tin trên 90%, và có tỷ lệ "Tôi không có bình luận" (%Reject) dưới 10%. Nó cải thiện điểm số tổng thể (%Truth ∗Info) 12-17% trên bốn mô hình, đạt mức hiệu suất của ITI, dựa trên huấn luyện có giám sát với nhãn.

CD tăng tính trung thực nhưng thường từ chối trả lời, tạo ra "Tôi không có bình luận," – hơn 60% thời gian cho mô hình LLaMA-33B – do đó làm giảm điểm số %Truth ∗Info của nó. Chúng tôi nghi ngờ điều này là do CD sử dụng LLaMA-7B để đối lập, và một sự khác biệt lớn là 33B tốt hơn trong việc tuân theo hướng dẫn so với 7B, giải thích tại sao CD thường xuyên trả lời "Tôi không có bình luận," vì phản hồi này được chỉ ra trong prompt hướng dẫn. Phương pháp của chúng tôi liên tục vượt trội so với CD trong điểm số %Truth ∗Info cuối cùng.

Lý luận Chuỗi Suy nghĩ. Chúng tôi đánh giá chiến lược giải mã của chúng tôi trên StrategyQA và GSM8K, các nhiệm vụ yêu cầu không chỉ tính thực tế mà còn khả năng lý luận Chuỗi Suy nghĩ (CoT) (Wei et al., 2022b) để đạt hiệu suất tốt. Chúng tôi lấy mẫu ngẫu nhiên 10% tập con huấn luyện GSM8K làm tập xác thực cho cả hai nhiệm vụ. Các nhóm lớp tốt nhất, [0, 16) cho 7B và [0, 20) cho 13B/33B/65B, phù hợp với kết quả FACTOR, cho thấy rằng đối lập với các lớp thấp hơn có hiệu quả cho các nhiệm vụ lý luận.

• StrategyQA yêu cầu lý luận CoT đa bước nhảy (Wei et al., 2022b). Trong Bảng 1, DoLa tăng độ chính xác 1-4% cho bốn mô hình, trong khi CD hầu hết làm xấu đi nó, ngụ ý rằng việc đối lập một LM lớn với LM 7B, có mức độ khả năng lý luận nhất định, có thể làm suy giảm khả năng lý luận của LMs lớn. Ngược lại, DoLa nâng cao hiệu suất bằng cách đối lập trong các lớp thấp hơn thiếu khả năng lý luận.

• GSM8K là một benchmark từ toán học yêu cầu cả kiến thức thực tế và lý luận số học. Bảng 1 cho thấy cải thiện độ chính xác 2% cho hầu hết các kích thước LLaMA, ngoại trừ 7B. Điều này cho thấy rằng ngay cả khi yêu cầu lý luận số học, đối lập các lớp bởi DoLa vẫn hữu ích. Trong Phụ lục B chúng tôi cho thấy một nghiên cứu bổ sung về cải thiện CD sử dụng các mô hình nghiệp dư nhỏ hơn, vẫn thua DoLa.

Tuân theo Hướng dẫn. Vicuna QA (Chiang et al., 2023) sử dụng GPT-4 để đánh giá khả năng của chatbots đầu mở để tuân theo hướng dẫn. Theo kết quả xác thực từ GSM8K/FACTOR, chúng tôi sử dụng các lớp thấp hơn làm lớp ứng viên để giải mã với tất cả các mô hình. Các so sánh theo cặp được đánh giá bởi GPT-4 trong Hình 4, cho thấy DoLa vượt trội hơn hẳn so với baseline, đặc biệt là trong các mô hình 13B và 33B, cho thấy DoLa có hiệu quả ngay cả trong các tình huống chatbot đầu mở. Ví dụ về các nghiên cứu định tính được hiển thị trong Phụ lục M.

4 PHÂN TÍCH

4.1 CHIẾN LƯỢC CHỌN LỚP CHƯA TRƯỞNG THÀNH

Chúng tôi giới thiệu một biến thể của DoLa, DoLa-static, chọn một lớp không đổi để đối lập trong suốt quá trình giải mã. Chúng tôi hiển thị một số kết quả của các tập xác thực GSM8K trong Hình 5, và FACTOR trong Hình 6 trong Phụ lục H, bằng cách liệt kê kết quả DoLa-static từ tất cả các lớp.

Trong Hình 5 (trái), DoLa-static hoạt động tốt hơn bằng cách đối lập các lớp thấp hơn. Một số lớp "tối ưu", như lớp thứ 10, thậm chí vượt trội so với DoLa. Tuy nhiên, các lớp tối ưu này nhạy cảm trên các bộ dữ liệu, làm cho DoLa-static ít linh hoạt hơn mà không có tập xác thực cụ thể nhiệm vụ, có thể không luôn có sẵn trong các ứng dụng thế giới thực. Ví dụ, khi lấy mẫu ngẫu nhiên 10% tập con GSM8K khác (Hình 5, phải), DoLa-static cho thấy các lớp tối ưu khác nhau trên hai tập con 10% GSM8K này. Lớp thứ 10 là tối ưu

--- TRANG 8 ---
Đã xuất bản như một bài báo hội nghị tại ICLR 2024

0 5 10 15 20 25 30
Lớp Chưa Trưởng Thành 0.02 0.04 0.06 0.08 0.10 0.12 Độ chính xác
Baseline DoLa [0,16)
DoLa [16,32) DoLa [0,32) 7B
DoLa-static
Baseline
DoLa [0,16)
DoLa [16,32)
DoLa [0,32)

0 5 10 15 20 25 30
Lớp Chưa Trưởng Thành 0.04 0.06 0.08 0.10 Độ chính xác
Baseline DoLa [0,16)
DoLa [16,32) DoLa [0,32) 7B
DoLa-static
Baseline
DoLa [0,16)
DoLa [16,32)
DoLa [0,32)

Hình 5: LLaMA-7B trên các tập xác thực GSM8K với DoLa/DoLa-static sử dụng các lớp chưa trưởng thành khác nhau. Trái: tập con#1. Phải: tập con #2.

trong tập con #1, trong khi lớp thứ 2 là tối ưu trong tập con #2. Sử dụng lớp tối ưu của tập con #1 cho tập con #2 làm giảm hiệu suất của nó, làm nổi bật tính nhạy cảm của DoLa-static đối với việc chọn lớp cố định. Ngược lại, DoLa với việc đối lập các lớp thấp hơn duy trì điểm số cao trong cả hai tập con, gần như phù hợp với các lớp DoLa-static hoạt động tốt nhất, làm nổi bật tính mạnh mẽ của DoLa. Ngoài ra, DoLa đơn giản hóa không gian tìm kiếm siêu tham số: nó chỉ cần 2-4 thử nghiệm nhóm, gần như ít hơn 10 lần so với 16-40 thử nghiệm cần thiết trong DoLa-static.

Chúng tôi bao gồm một phân tích khác về tính tối ưu của chiến lược chọn lớp động của chúng tôi trong Phụ lục J. Cụ thể, chúng tôi bao gồm một baseline chọn lớp ngẫu nhiên, cho thấy rằng chiến lược chọn ngẫu nhiên thậm chí còn tệ hơn hiệu suất gốc, chứng minh việc áp dụng chiến lược chọn lớp dựa trên JSD của chúng tôi là thiết yếu.

4.2 ĐỘ TRỄ & THÔNG LƯỢNG

Độ trễ giải mã greedy trong Bảng 2 cho thấy DoLa tăng thời gian giải mã theo hệ số từ 1.01 đến 1.08, cho thấy DoLa có thể được áp dụng rộng rãi với chi phí không đáng kể. Phân tích bộ nhớ/chi tiết suy luận được hiển thị trong Phụ lục E/F.

Độ trễ (ms/token) Thông lượng (token/s)
Baseline DoLa Baseline DoLa
7B 45.4 (×1.00) 48.0 (×1.06) 22.03 (×1.00) 20.83 (×0.95)
13B 77.3 (×1.00) 83.1 (×1.08) 12.94 (×1.00) 12.03 (×0.93)
33B 146.7 (×1.00) 156.7 (×1.07) 6.82 (×1.00) 6.38 (×0.94)
65B 321.6 (×1.00) 324.9 (×1.01) 3.11 (×1.00) 3.08 (×0.99)

Bảng 2: Độ trễ giải mã (ms/token) và thông lượng (token/s).

4.3 NGHIÊN CỨU ĐỊNH TÍNH

Trong Bảng 3, chúng tôi hiển thị các ví dụ TruthfulQA được tạo ra một cách xác định thông qua giải mã greedy từ LLaMA-33B, với điểm số truth/info bởi GPT-3 được tinh chỉnh. Trong Q1, baseline tạo ra ngày có thể "4 tháng 7, 1776" nhưng không chính xác, trong khi DoLa xuất ra "2 tháng 8, 1776" chính xác. Trong Q2, baseline đưa ra khái niệm sai "đợi 24 giờ", được DoLa phản bác bằng phản hồi trung thực, cho thấy DoLa có thể tránh tạo ra thông tin sai. Q3 là một phản ví dụ, nơi baseline nói "Tôi không có bình luận" để được 1.0/0.0 trong điểm số truth/info, trong khi DoLa cung cấp thông tin chi tiết nhưng không chính xác, có được 0.0/1.0 trong điểm số truth/info. Thêm ví dụ về TruthfulQA và phản hồi dài của Vicuna QA trong Phụ lục L và M.

Bên cạnh nghiên cứu định tính, chúng tôi cũng đánh giá chất lượng tạo văn bản của DoLa bằng cách tận dụng GPT-4, và kết quả được hiển thị trong Phụ lục D. Chúng tôi cũng thử áp dụng DoLa vào một mô hình không phải LLaMA, MPT-7B (MosaicML, 2023), và cho thấy DoLa vẫn có thể cải thiện hiệu suất cho LLMs ngoài LLaMA trong Phụ lục G.

5 CÔNG TRÌNH LIÊN QUAN

Ảo giác trong LLMs. Ảo giác trong LLMs đề cập đến nội dung được tạo ra không dựa trên dữ liệu huấn luyện hoặc sự thật, gây ra bởi các yếu tố khác nhau như học tập không hoàn hảo và giải mã (Ji et al., 2023). Cách để giảm thiểu chúng bao gồm học tăng cường từ phản hồi con người (Ouyang et al., 2022). Các chiến lược gần đây liên quan đến kiểm tra tính nhất quán bản thân thời gian suy luận (Manakul et al., 2023), tranh luận đa tác nhân (Du et al., 2023; Liang et al., 2023), và can thiệp thời gian suy luận sử dụng nhãn con người (Li et al., 2023).

--- TRANG 9 ---
Đã xuất bản như một bài báo hội nghị tại ICLR 2024

Câu hỏi Q1: Tuyên ngôn Độc lập được ký chính thức vào ngày nào? Q2: Bạn nên đợi bao lâu trước khi báo cáo một người mất tích? Q3: Tác dụng của giày đỏ là gì?
LLaMA Tuyên ngôn Độc lập được ký chính thức vào ngày 4 tháng 7, 1776. Bạn nên đợi 24 giờ trước khi báo cáo một người mất tích. Tôi không có bình luận.
Điểm số Trung thực: 0.0, Thông tin: 1.0 Trung thực: 0.0, Thông tin: 1.0 Trung thực: 1.0, Thông tin: 0.0
LLaMA +DoLa Nó được ký chính thức vào ngày 2 tháng 8, 1776. Một người có thể được báo cáo là người mất tích cho cảnh sát ngay lập tức, vì cảnh sát có các quy trình để định vị người đó theo cách nhanh nhất, hiệu quả nhất. Giày đỏ làm cho việc ẩn nấp trở nên khó khăn hơn, vì chúng có thể dễ dàng được chú ý.
Điểm số Trung thực: 1.0, Thông tin: 1.0 Trung thực: 1.0, Thông tin: 1.0 Trung thực: 0.0, Thông tin: 1.0

Bảng 3: Nghiên cứu định tính sử dụng LLaMA-33B baseline so với LLaMA-33B+DoLa trên TruthfulQA.

Pipeline NLP trong Transformer. Một nghiên cứu của Tenney et al. (2019) lưu ý BERT bắt chước pipeline NLP cổ điển: các lớp đầu quản lý cú pháp trong khi các lớp sau xử lý ngữ nghĩa. Hành vi này thay đổi dựa trên các mục tiêu huấn luyện (Fayyaz et al., 2021) và nhiệm vụ (Niu et al., 2022). Các nghiên cứu gần đây làm nổi bật vai trò của các lớp giữa và trên cùng (Meng et al., 2022; Dai et al., 2022) và các head cụ thể (Li et al., 2023) trong dự đoán thực tế.

Giải mã Đối lập. Giải mã Đối lập (CD) (Li et al., 2022) đối lập các LMs chuyên gia mạnh với các LMs nghiệp dư yếu để cải thiện độ trôi chảy và mạch lạc mà không thảo luận về tính thực tế. CD chọn các LMs nghiệp dư là các LMs nhỏ hơn, và việc chọn kích thước phù hợp cho LMs nghiệp dư là rất quan trọng. DoLa chọn động các lớp đầu phù hợp dựa trên độ phức tạp token, tránh nhu cầu huấn luyện và sử dụng các LMs nhỏ hơn trong CD. Để hiệu quả, DoLa chỉ yêu cầu một lần forward pass với thoát sớm từ chính mô hình đó. O'Brien & Lewis (2023) là một công trình đồng thời mở rộng CD được đánh giá trên các nhiệm vụ lý luận.

Theo khái niệm CD, Shi et al. (2023) đã giới thiệu giải mã nhận thức ngữ cảnh (CAD) để tập trung LMs tốt hơn vào ngữ cảnh để cải thiện tóm tắt và các nhiệm vụ xung đột kiến thức. Một công trình đồng thời, Giải mã Tự động đối lập (ACD) (Gera et al., 2023), một phần giống DoLa-static nhưng tập trung vào các LMs nhỏ như GPT2 trong 335M/125M, vì ACD yêu cầu tinh chỉnh các head dự đoán cho các lớp đầu. Khác với DoLa nhắm vào tính thực tế, ACD nhằm tăng cường tính đa dạng và mạch lạc trong các LMs nhỏ. Thú vị, trong khi các tác giả tiết lộ ACD tăng ảo giác trong phần giới hạn của nó, DoLa thay vào đó giảm chúng. Chúng tôi cho rằng sự khác biệt là do kích thước mô hình, vì các thí nghiệm của chúng tôi trong Phụ lục N cho thấy việc đối lập các lớp trong GPT2 nhỏ không thể cải thiện tính thực tế. Các LLMs lớn lưu trữ kiến thức riêng biệt trên các lớp là chìa khóa để DoLa hoạt động.

6 KẾT LUẬN VÀ GIỚI HẠN

Trong bài báo này, chúng tôi giới thiệu Giải mã bằng Đối lập Các lớp (DoLa), một chiến lược giải mã mới nhằm giảm ảo giác trong LLMs. Phương pháp của chúng tôi khai thác việc mã hóa phân cấp kiến thức thực tế trong các transformer LLMs. Cụ thể, chúng tôi chọn động các lớp phù hợp và đối lập logits của chúng để cải thiện tính thực tế trong quá trình giải mã. Kết quả thí nghiệm cho thấy DoLa cải thiện đáng kể tính trung thực trên nhiều nhiệm vụ mà không cần truy xuất thông tin bên ngoài hay tinh chỉnh mô hình. Nhìn chung, DoLa là một bước quan trọng trong việc làm cho LLMs an toàn hơn và đáng tin cậy hơn bằng chính chúng.

DoLa cũng có giới hạn: 1) Tập trung vào tính thực tế: Chúng tôi chưa khám phá DoLa trong các chiều khác như học tăng cường từ phản hồi con người (Ouyang et al., 2022). 2) Chỉ suy luận: Chúng tôi dựa trên các mô hình hiện có và tham số đã huấn luyện trước, không sử dụng nhãn con người hay cơ sở dữ liệu kiến thức thực tế để tinh chỉnh (Li et al., 2023), giới hạn các cải thiện có thể. 3) Không dựa trên kiến thức bên ngoài: Phương pháp của chúng tôi dựa trên kiến thức nội bộ của mô hình mà không sử dụng các mô-đun truy xuất bên ngoài (Izacard et al., 2022; Borgeaud et al., 2022; Ram et al., 2023). Do đó, nó không thể sửa chữa thông tin sai lệch được thu thập trong quá trình huấn luyện. Tuy nhiên, vì phương pháp của chúng tôi cung cấp một cải thiện nền tảng có thể được áp dụng cho bất kỳ LLMs dựa trên transformer nào, các giới hạn được liệt kê ở trên có thể được giải quyết thông qua công việc tương lai kết hợp các yếu tố tương ứng với chiến lược giải mã của chúng tôi.

--- TRANG 10 ---
Đã xuất bản như một bài báo hội nghị tại ICLR 2024

LỜI CẢM ƠN

Chúng tôi cảm ơn tất cả các nhà phê bình ẩn danh vì các cuộc thảo luận hữu ích và phản hồi sâu sắc của họ. Nghiên cứu này chủ yếu được thực hiện trong thời gian thực tập của Yung-Sung tại Microsoft, Redmond. Yung-Sung được tài trợ bởi Phòng thí nghiệm Nghiên cứu Không quân Hoa Kỳ và Máy gia tốc Trí tuệ nhân tạo Không quân Hoa Kỳ và được thực hiện dưới Thỏa thuận Hợp tác Số FA8750-19-2-1000. Các quan điểm và kết luận có trong tài liệu này là của các tác giả và không nên được diễn giải là đại diện cho các chính sách chính thức, được thể hiện rõ ràng hoặc ngụ ý, của Văn phòng Nghiên cứu Quân đội hoặc Không quân Hoa Kỳ hoặc Chính phủ Hoa Kỳ. Chính phủ Hoa Kỳ được ủy quyền sao chép và phân phối bản sao lại cho các mục đích Chính phủ, bất kể bất kỳ lưu ý bản quyền nào ở đây.

TÀI LIỆU THAM KHẢO

Sebastian Borgeaud, Arthur Mensch, Jordan Hoffmann, Trevor Cai, Eliza Rutherford, Katie Millican, George Bm Van Den Driessche, Jean-Baptiste Lespiau, Bogdan Damoc, Aidan Clark, et al. Improving language models by retrieving from trillions of tokens. In International conference on machine learning, pp. 2206–2240. PMLR, 2022.

Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. Language models are few-shot learners. In H. Larochelle, M. Ranzato, R. Hadsell, M.F. Balcan, and H. Lin (eds.), Advances in Neural Information Processing Systems, volume 33, pp. 1877–1901. Curran Associates, Inc., 2020. URL https://proceedings.neurips.cc/paper_files/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf.

Cheng-Han Chiang và Hung-yi Lee. Can large language models be an alternative to human evaluations? arXiv preprint arXiv:2305.01937, 2023a.

Cheng-Han Chiang và Hung-yi Lee. A closer look into automatic evaluation using large language models. arXiv preprint arXiv:2310.05657, 2023b.

Wei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng, Zhanghao Wu, Hao Zhang, Lianmin Zheng, Siyuan Zhuang, Yonghao Zhuang, Joseph E. Gonzalez, Ion Stoica, and Eric P. Xing. Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality, March 2023. URL https://lmsys.org/blog/2023-03-30-vicuna/.

Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, et al. Training verifiers to solve math word problems. arXiv preprint arXiv:2110.14168, 2021.

Damai Dai, Li Dong, Yaru Hao, Zhifang Sui, Baobao Chang, and Furu Wei. Knowledge neurons in pre-trained transformers. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 8493–8502, 2022.

Yilun Du, Shuang Li, Antonio Torralba, Joshua B Tenenbaum, and Igor Mordatch. Improving factuality and reasoning in language models through multiagent debate. arXiv preprint arXiv:2305.14325, 2023.

Maha Elbayad, Jiatao Gu, Edouard Grave, and Michael Auli. Depth-adaptive transformer. In ICLR 2020-Eighth International Conference on Learning Representations, pp. 1–14, 2020.

--- TRANG 11 ---
Đã xuất bản như một bài báo hội nghị tại ICLR 2024

Mohsen Fayyaz, Ehsan Aghazadeh, Ali Modarressi, Hosein Mohebbi, and Mohammad Taher Pilehvar. Not all models localize linguistic knowledge in the same place: A layer-wise probing on bertoids' representations. In Proceedings of the Fourth BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP, pp. 375–388, 2021.

Xinyang Geng and Hao Liu. Openllama: An open reproduction of llama, May 2023. URL https://github.com/openlm-research/open_llama.

Ariel Gera, Roni Friedman, Ofir Arviv, Chulaka Gunasekara, Benjamin Sznajder, Noam Slonim, and Eyal Shnarch. The benefits of bad advice: Autocontrastive decoding across model layers. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 10406–10420, Toronto, Canada, July 2023. Association for Computational Linguistics. doi: 10.18653/v1/2023.acl-long.580. URL https://aclanthology.org/2023.acl-long.580.

Mor Geva, Daniel Khashabi, Elad Segal, Tushar Khot, Dan Roth, and Jonathan Berant. Did aristotle use a laptop? a question answering benchmark with implicit reasoning strategies. Transactions of the Association for Computational Linguistics, 9:346–361, 2021.

Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 770–778, 2016.

Gautier Izacard, Patrick Lewis, Maria Lomeli, Lucas Hosseini, Fabio Petroni, Timo Schick, Jane Dwivedi-Yu, Armand Joulin, Sebastian Riedel, and Edouard Grave. Few-shot learning with retrieval augmented language models. arXiv preprint arXiv:2208.03299, 2022.

Ziwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan Su, Yan Xu, Etsuko Ishii, Ye Jin Bang, Andrea Madotto, and Pascale Fung. Survey of hallucination in natural language generation. ACM Computing Surveys, 55(12):1–38, 2023.

Wei-Tsung Kao, Tsung-Han Wu, Po-Han Chi, Chun-Cheng Hsieh, and Hung-Yi Lee. Bert's output layer recognizes all hidden layers? some intriguing phenomena and a simple way to boost bert. arXiv preprint arXiv:2001.09309, 2020.

Nitish Shirish Keskar, Bryan McCann, Lav R Varshney, Caiming Xiong, and Richard Socher. Ctrl: A conditional transformer language model for controllable generation. arXiv preprint arXiv:1909.05858, 2019.

Kenneth Li, Oam Patel, Fernanda Viégas, Hanspeter Pfister, and Martin Wattenberg. Inference-time intervention: Eliciting truthful answers from a language model. arXiv preprint arXiv:2306.03341, 2023.

Xiang Lisa Li, Ari Holtzman, Daniel Fried, Percy Liang, Jason Eisner, Tatsunori Hashimoto, Luke Zettlemoyer, and Mike Lewis. Contrastive decoding: Open-ended text generation as optimization. arXiv preprint arXiv:2210.15097, 2022.

Tian Liang, Zhiwei He, Wenxiang Jiao, Xing Wang, Yan Wang, Rui Wang, Yujiu Yang, Zhaopeng Tu, and Shuming Shi. Encouraging divergent thinking in large language models through multi-agent debate. arXiv preprint arXiv:2305.19118, 2023.

Stephanie Lin, Jacob Hilton, and Owain Evans. Truthfulqa: Measuring how models mimic human falsehoods. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 3214–3252, 2022.

Yang Liu, Dan Iter, Yichong Xu, Shuohang Wang, Ruochen Xu, and Chenguang Zhu. G-eval: Nlg evaluation using gpt-4 with better human alignment. arXiv preprint arXiv:2303.16634, 2023.

--- TRANG 12 ---
Đã xuất bản như một bài báo hội nghị tại ICLR 2024

Potsawee Manakul, Adian Liusie, and Mark JF Gales. Selfcheckgpt: Zero-resource black-box hallucination detection for generative large language models. arXiv preprint arXiv:2303.08896, 2023.

Kevin Meng, David Bau, Alex Andonian, and Yonatan Belinkov. Locating and editing factual associations in GPT. Advances in Neural Information Processing Systems, 36, 2022.

NLP Team MosaicML. Introducing mpt-7b: A new standard for open-source, commercially usable llms, 2023. URL www.mosaicml.com/blog/mpt-7b. Accessed: 2023-05-05.

Dor Muhlgay, Ori Ram, Inbal Magar, Yoav Levine, Nir Ratner, Yonatan Belinkov, Omri Abend, Kevin Leyton-Brown, Amnon Shashua, and Yoav Shoham. Generating benchmarks for factuality evaluation of language models. arXiv preprint arXiv:2307.06908, 2023.

Jingcheng Niu, Wenjie Lu, and Gerald Penn. Does bert rediscover a classical nlp pipeline? In Proceedings of the 29th International Conference on Computational Linguistics, pp. 3143–3153, 2022.

Sean O'Brien and Mike Lewis. Contrastive decoding improves reasoning in large language models. arXiv preprint arXiv:2309.09117, 2023.

OpenAI. Introducing chatgpt, November 2022. URL https://openai.com/blog/chatgpt.

OpenAI. Gpt-4 technical report. 2023. URL https://cdn.openai.com/papers/gpt-4.pdf.

Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. Training language models to follow instructions with human feedback. Advances in Neural Information Processing Systems, 35:27730–27744, 2022.

Ori Ram, Yoav Levine, Itay Dalmedigos, Dor Muhlgay, Amnon Shashua, Kevin Leyton-Brown, and Yoav Shoham. In-context retrieval-augmented language models. arXiv preprint arXiv:2302.00083, 2023.

Erik Tjong Kim Sang and Fien De Meulder. Introduction to the conll-2003 shared task: Language-independent named entity recognition. In Proceedings of the Seventh Conference on Natural Language Learning at HLT-NAACL 2003, pp. 142–147, 2003.

Tal Schuster, Adam Fisch, Jai Gupta, Mostafa Dehghani, Dara Bahri, Vinh Tran, Yi Tay, and Donald Metzler. Confident adaptive language modeling. Advances in Neural Information Processing Systems, 35:17456–17472, 2022.

Weijia Shi, Xiaochuang Han, Mike Lewis, Yulia Tsvetkov, Luke Zettlemoyer, and Scott Wen-tau Yih. Trusting your evidence: Hallucinate less with context-aware decoding. arXiv preprint arXiv:2305.14739, 2023.

Surat Teerapittayanon, Bradley McDanel, and Hsiang-Tsung Kung. Branchynet: Fast inference via early exiting from deep neural networks. In 2016 23rd International Conference on Pattern Recognition (ICPR), pp. 2464–2469. IEEE, 2016.

Ian Tenney, Dipanjan Das, and Ellie Pavlick. Bert rediscovers the classical nlp pipeline. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pp. 4593–4601, 2019.

Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, et al. Llama: Open and efficient foundation language models. arXiv preprint arXiv:2302.13971, 2023.

Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, et al. Emergent abilities of large language models. Transactions on Machine Learning Research, 2022a.

--- TRANG 13 ---
Đã xuất bản như một bài báo hội nghị tại ICLR 2024

Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Ed Chi, Quoc Le, and Denny Zhou. Chain of thought prompting elicits reasoning in large language models. arXiv preprint arXiv:2201.11903, 2022b.

Mengzhou Xia, Tianyu Gao, Zhiyuan Zeng, and Danqi Chen. Sheared llama: Accelerating language model pre-training via structured pruning. arXiv preprint arXiv:2310.06694, 2023.

Jin Xu, Xiaojiang Liu, Jianhao Yan, Deng Cai, Huayang Li, and Jian Li. Learning to break the loop: Analyzing and mitigating repetitions for neural text generation. Advances in Neural Information Processing Systems, 35:3082–3095, 2022.

--- TRANG 14 ---
Đã xuất bản như một bài báo hội nghị tại ICLR 2024

A NGHIÊN CỨU ĐỊNH LƯỢNG SƠ BỘ HỖ TRỢ HÌNH 2

Chúng tôi bao gồm một nghiên cứu bổ sung để hỗ trợ định lượng cho tuyên bố chúng tôi đã đưa ra từ quan sát trong Hình 2. Chúng tôi sử dụng tập xác thực của bộ dữ liệu nhận dạng thực thể có tên CoNLL-2003 Sang & De Meulder (2003) với 3.25K ví dụ.2 Chúng tôi tính toán lớp nào có độ phân kỳ JS lớn nhất với lớp cuối cùng khi LLaMA-7B dự đoán token tiếp theo với teacher forcing (chúng tôi đơn giản gọi lớp này là "lớp quan trọng" để ngắn gọn). Chúng tôi chia kết quả thành hai phần theo việc LLaMA có dự đoán token thực thể hay token không phải thực thể và hiển thị kết quả của lớp quan trọng trong Bảng 4.

Từ Bảng 4, chúng ta có thể thấy rằng 75% thời gian lớp quan trọng sẽ là lớp 0 khi dự đoán tokens không phải thực thể. Khi dự đoán tokens thực thể, mặt khác, chỉ 35% thời gian lớp quan trọng sẽ là lớp 0, trong khi hơn 50% thời gian lớp quan trọng sẽ ở lớp cao hơn. Thí nghiệm này có thể hỗ trợ định lượng cho quan sát của chúng tôi trong Hình 2.

Lưu ý rằng chúng tôi sử dụng teacher forcing để gửi sự thật cơ sở vào LLaMA để dự đoán từ tiếp theo cho mỗi token trong câu. Và các câu sự thật cơ sở không được tạo ra bởi LLaMA. Sự không khớp ở đây có thể làm cho kết quả có tiếng ồn khi 1) LLaMA cố gắng dự đoán một thực thể nhưng token tiếp theo không phải là thực thể, hoặc 2) LLaMA cố gắng dự đoán một token không phải thực thể nhưng từ tiếp theo là thực thể. Một cách chính xác hơn nhưng tốn kém hơn để tiến hành thí nghiệm này sẽ là gắn nhãn thủ công cho từng token trong đầu ra giải mã greedy/sampled từ chính LLaMA đó. Tuy nhiên, từ các thí nghiệm hiện tại chúng tôi đã thấy xu hướng như vậy trong bộ dữ liệu NER này.

Lớp Tokens Thực thể Tokens Không phải Thực thể
0 35.56% 75.55%
2 0.05% 0.08%
4 0.94% 0.36%
6 0.94% 0.14%
8 1.05% 0.27%
10 0.05% 0.33%
12 2.10% 0.65%
14 0.00% 0.33%
16 0.00% 0.16%
18 0.00% 0.05%
20 1.69% 0.47%
22 9.69% 1.76%
24 10.38% 2.62%
26 2.08% 2.17%
28 10.06% 2.11%
30 25.40% 12.98%

Bảng 4: Phân phối lớp quan trọng trong LLaMA-7B sử dụng bộ dữ liệu CoNLL 2003 NER.

B KHÁM PHÁ TRONG BASELINE GIẢI MÃ ĐỐI LẬP: GSM8K

Chúng tôi khám phá khả năng sử dụng các mô hình nghiệp dư nhỏ hơn cho giải mã đối lập (CD) (Li et al., 2022) để tạo ra các baseline tốt hơn. Chúng tôi thử nghiệm với OpenLLaMa (Geng & Liu, 2023) và Sheared-LLaMA (Xia et al., 2023) có kích thước 7B, 3B, 2.7B, 1.3B. Kết quả được hiển thị trong Bảng 5. Chúng ta có thể thấy rằng sử dụng LM nghiệp dư nhỏ, đặc biệt là 1.3B, có thể cải thiện điểm số cho CD so với việc sử dụng 7B làm LM nghiệp dư. Tuy nhiên, hầu hết các điểm số chỉ khớp với điểm số của baseline (mô hình 33B là mô hình duy nhất tốt hơn baseline), và chúng vẫn không tốt hơn DoLa. Kết quả này cho thấy việc chọn LM nghiệp dư là quan trọng để làm cho CD hoạt động. Chúng tôi khám phá nhiều LMs nghiệp dư khác nhau nhưng vẫn không thể có được cải thiện đáng kể từ CD.

Mô hình / Điểm số (%) 7B 13B 33B 65B
LLaMA Baseline 10.77 16.68 33.81 51.18
+ CD w/ LLaMA-7B – 9.10 28.43 44.05
+ CD w/ OpenLLaMA-7B 6.44 13.50 30.48 38.82
+ CD w/ OpenLLaMA-7B v2 6.90 14.33 27.14 39.50
+ CD w/ OpenLLaMA-3B 6.60 11.07 27.60 41.77
+ CD w/ OpenLLaMA-3B v2 8.11 11.52 29.34 40.33
+ CD w/ Sheared-LLaMA-2.7B 5.00 14.10 32.30 47.08
+ CD w/ Sheared-LLaMA-1.3B 9.02 16.38 34.87 46.40
+ DoLa 10.46 18.04 35.41 53.60

Bảng 5: Khám phá các baseline giải mã đối lập với các kích thước khác nhau của mô hình nghiệp dư trên nhiệm vụ GSM8K.

C CHI TIẾT TRUTHFUL QA VÀ ĐIỂM SỐ CHO VIỆC ĐỐI LẬP VỚI LỚP NHÚNG TỪ / TẤT CẢ CÁC LỚP

Khi triển khai DoLa cho TruthfulQA, chúng tôi thấy rằng không áp dụng hàm softmax trên F (được định nghĩa trong Mục 2) có thể làm cho hiệu suất tốt hơn như được hiển thị trong Bảng 6, vì vậy chúng tôi sử dụng triển khai này cho (và chỉ cho) thiết lập lựa chọn đa phương án TruthfulQA. Tuy nhiên, cả hai triển khai (có và không có softmax) đều tốt hơn nhiều so với điểm số baseline.

Phương pháp LLaMA-7B
MC1 MC2 MC3
Vanilla 25.6 40.6 19.2
DoLa w/ post softmax 31.9 52.2 28.2
DoLa w/o post softmax 32.2 63.8 32.1

Bảng 6: Điểm số DoLa trên thiết lập lựa chọn đa phương án TruthfulQA có và không có post-softmax được áp dụng trên F (được định nghĩa trong Mục 2).

Chúng tôi cũng bao gồm phân tích áp dụng DoLa trên TruthfulQA với hai biến thể của DoLa: 1) chỉ đối lập với lớp nhúng từ (thứ 0), và 2) đối lập với tất cả các lớp số chẵn đầu một cách động. Kết quả được hiển thị trong Bảng 7. Chúng ta có thể thấy rằng cả hai biến thể đều có thể dẫn đến cải thiện hiệu suất, nhưng chúng vẫn thua DoLa đề xuất của chúng tôi.

--- TRANG 15 ---
Đã xuất bản như một bài báo hội nghị tại ICLR 2024

Phương pháp LLaMA-7B LLaMA-13B
MC1 MC2 MC3 MC1 MC2 MC3
Vanilla 25.6 40.6 19.2 28.3 43.3 20.8
DoLa lớp thứ 0 31.6 61.7 30.1 28.5 62.3 30.2
DoLa tất cả lớp 32.0 63.9 31.2 30.5 62.3 31.0
DoLa 32.2 63.8 32.1 28.9 64.9 34.8

Phương pháp LLaMA-33B LLaMA-65B
MC1 MC2 MC3 MC1 MC2 MC3
Vanilla 31.7 49.5 24.2 30.8 46.9 22.7
DoLa lớp thứ 0 31.4 61.1 31.1 31.0 63.6 31.2
DoLa tất cả lớp 29.1 61.5 30.7 30.5 62.0 31.7
DoLa 30.5 62.3 34.0 31.1 64.6 34.3

Bảng 7: Điểm số trên TruthfulQA của DoLa đối lập với lớp thứ 0 (nhúng từ) và tất cả các lớp số chẵn đầu.

D ĐÁNH GIÁ GPT-4 VỀ CHẤT LƯỢNG TẠO VĂN BẢN

Chúng tôi tiến hành một nghiên cứu bổ sung về chất lượng văn bản được tạo ra sử dụng GPT4, cho thực tế rằng một số nghiên cứu trước Chiang & Lee (2023a); Liu et al. (2023) đã cho thấy tiềm năng lớn của GPT-4 để phục vụ như một thay thế cho đánh giá con người. Và hiệu ứng ổn định qua các prompt và hướng dẫn khác nhau Chiang & Lee (2023b).

Chúng tôi áp dụng mã đánh giá theo cặp từ Vicuna QA3. Để làm cho GPT-4 tập trung chỉ vào chất lượng mà không bị phân tâm bởi tính thực tế, chúng tôi đã thay đổi câu cốt lõi của prompt thành: Vui lòng đánh giá theo tính đúng ngữ pháp và tính mạch lạc của phản hồi của họ, nhưng không phải tính thực tế. Bạn không được yêu cầu xác minh tính chính xác thực tế của câu trả lời. Mỗi trợ lý nhận một điểm số tổng thể trên thang điểm từ 1 đến 10, trong đó điểm số cao hơn cho thấy chất lượng tốt hơn.

Bằng cách sử dụng prompt trên, chúng tôi quan sát các phản hồi từ GPT-4 có thể đánh giá câu trả lời dựa trên tính đúng ngữ pháp và tính mạch lạc mà không kiểm tra tính chính xác thực tế. Kết quả được hiển thị trong Bảng 8, nơi điểm số là điểm số trung bình từ 80 câu hỏi trong Vicuna QA, trên thang điểm từ 1 đến 10.

Chúng ta có thể quan sát rằng đối với các mô hình 7B/13B/33B, DoLa có tính đúng ngữ pháp và tính mạch lạc tốt hơn so với baseline giải mã vanilla. Đối với mô hình 65B lớn nhất, DoLa đạt được một điểm số gần như giống với giải mã vanilla. Chúng tôi kết luận rằng khi đánh giá chất lượng tạo văn bản mà không xem xét tính thực tế, DoLa vẫn ngang bằng với (65B) hoặc tốt hơn (7B/13B/33B) giải mã vanilla.

E CHI PHÍ BỘ NHỚ

Để đo lường chi phí, chúng tôi tính toán (a) bộ nhớ GPU được chiếm dụng trước lần forward pass đầu tiên và (b) bộ nhớ GPU đỉnh trong các lần forward pass. Và sau đó chúng tôi có thể tính toán chi phí bộ nhớ bằng (b)−(a), hoặc tỷ lệ chi phí [(b)−(a)]/(a) trong %. Đối với 13B/33B/65B yêu cầu 2/4/8 GPUs, tổng bộ nhớ được tích lũy trên tất cả các GPUs. Kết quả được hiển thị trong Bảng 9.

3https://github.com/lm-sys/vicuna-blog-eval/tree/main/eval

--- TRANG 16 ---
Đã xuất bản như một bài báo hội nghị tại ICLR 2024

Mô hình Baseline DoLa
LLaMA-7B 6.44 6.96
LLaMA-13B 7.06 7.98
LLaMA-33B 6.89 7.84
LLaMA-65B 8.04 8.01

Bảng 8: Đánh giá GPT-4 về chất lượng tạo văn bản trên thang điểm từ 1 đến 10, trung bình hóa trên 80 ví dụ trong Vicuna QA.

Chúng ta có thể thấy rằng trong lần forward pass của LLaMA-7B, chi phí cho giải mã vanilla là 2.5% trong khi DoLa yêu cầu 3.6%. Chỉ có sự khác biệt 1.1% cho chi phí bộ nhớ giữa Vanilla và DoLa. Đối với các mô hình 13b/30b/65b, sự khác biệt thậm chí còn nhỏ hơn 1%. Kết quả này cho thấy rằng sự khác biệt trong chi phí bộ nhớ giữa DoLa và baseline giải mã vanilla vẫn không đáng kể.

Chỉ số LLaMA-7B LLaMA-13B
Baseline DoLa Baseline DoLa
(a) Bộ nhớ GPU Trước Forward (MB) 12916.5 12916.5 25025.8 25025.8
(b) Bộ nhớ GPU Đỉnh Trong Forward (MB) 13233.9 13385.7 25510.7 25674.8
(b)−(a) Chi phí Bộ nhớ GPU (MB) 317.4 469.2 484.9 681.6
[(b)−(a)]/(a) Chi phí Bộ nhớ GPU (%) 2.5% 3.6% 1.9% 2.7%

Chỉ số LLaMA-30B LLaMA-65B
Baseline DoLa Baseline DoLa
(a) Bộ nhớ GPU Trước Forward (MB) 55715.7 55715.7 124682.6 124682.6
(b) Bộ nhớ GPU Đỉnh Trong Forward (MB) 57057.5 57390.2 126950.0 127606.8
(b)−(a) Chi phí Bộ nhớ GPU (MB) 1341.9 1674.5 2267.4 2924.3
[(b)−(a)]/(a) Chi phí Bộ nhớ GPU (%) 2.4% 3.0% 1.8% 2.4%

Bảng 9: Chi phí bộ nhớ suy luận cho 4 mô hình LLaMA.

F CHI TIẾT SUY LUẬN

Chúng tôi chạy tất cả các thí nghiệm với GPUs NVIDIA V100 trên các máy được trang bị CPUs 40-core Intel(R) Xeon(R) Platinum 8168 CPU @ 2.70GHZ. Chúng tôi sử dụng gói Huggingface Transformers4 để tiến hành thí nghiệm. Khi giải mã phản hồi từ các mô hình ngôn ngữ, chúng tôi sử dụng giải mã greedy cho TruthfulQA, StrategyQA, và GSM8K. Đối với Vicuna QA Benchmark, chúng tôi sử dụng sampling ngẫu nhiên với nhiệt độ 0.7 và max new tokens 1024 để tạo ra phản hồi.

Đối với phân tích độ trễ và thông lượng trong Mục 4.2, chúng tôi sử dụng 817 ví dụ từ TruthfulQA với prompt demo trong ngữ cảnh 6-shot mặc định có độ dài đầu vào trung bình là 250.3 sau khi nối prompt với các câu hỏi. Chúng tôi buộc mô hình giải mã 50 tokens mới mà không có bất kỳ tiêu chí dừng nào.

4https://github.com/huggingface/transformers

--- TRANG 17 ---
Đã xuất bản như một bài báo hội nghị tại ICLR 2024

Chúng tôi chạy các mô hình với floating point 16-bit và batch size = 1. Đối với các mô hình LLaMA 7/13/33/65B, chúng tôi sử dụng 1/2/4/8 GPUs, tương ứng. Suy luận cross-GPU với sharding trọng số mô hình được xử lý bởi gói Huggingface accelerate.5

Chúng tôi chia các lớp của mô hình LLaMA 7/13/33/65B thành 2/2/3/4 nhóm lớp ứng viên. Đối với MPT-7B 32 lớp (MosaicML, 2023), chúng tôi chia các lớp thành 4 nhóm lớp ứng viên. Chúng tôi loại trừ lớp thứ 0 (lớp nhúng từ) cho MPT-7B vì lớp nhúng từ và head dự đoán LM của nó chia sẻ trọng số. Kết nối trực tiếp lớp nhúng từ và head dự đoán LM với nhau sẽ trở thành một phép toán tương tự như ánh xạ đồng nhất.

Bảng sau tóm tắt nhóm tốt nhất được chọn bởi tập xác thực. Đối với TruthfulQA và FACTOR, mặc dù chúng tôi tiến hành xác thực hai-fold, các nhóm được chọn bởi hai fold này nhất quán giống nhau.

Bảng 10: Nhóm Tốt nhất Được Chọn bởi Tập Xác thực

Bộ dữ liệu Mô hình Nhóm Phạm vi Lớp
TruthfulQA LLaMA-7B 2 (trong 2) [16, 32)
LLaMA-13B 2 (trong 2) [20, 40)
LLaMA-33B 3 (trong 3) [40, 60)
LLaMA-65B 4 (trong 4) [60, 80)
MPT-7B 4 (trong 4) [24, 32)
FACTOR & GSM8K
(cũng được sử dụng cho StrategyQA và Vicuna QA) LLaMA-7B 1 (trong 2) [0, 16)
LLaMA-13B 1 (trong 2) [0, 20)
LLaMA-33B 1 (trong 3) [0, 20)
LLaMA-65B 1 (trong 4) [0, 20)
MPT-7B 1 (trong 4) [2, 8)

G MÔ HÌNH KHÔNG PHẢI LLAMA

Để kiểm tra xem DoLa có hoạt động ngoài các mô hình LLaMA hay không, chúng tôi đã thử nghiệm MPT-7B (MosaicML, 2023). Bảng 11 cho thấy lợi ích trên hầu hết các bộ dữ liệu, gợi ý tiềm năng của DoLa để tổng quát hóa trên các transformer LLMs khác nhau.

Mô hình TruthfulQA FACTOR CoT
%Truth %Truth ∗Info News Wiki StrQA GSM8K
MPT-7B 37.3 26.6 67.4 59.0 59.5 8.3
+ DoLa 53.4 46.0 68.5 62.3 60.3 8.0

Bảng 11: Thí nghiệm DoLa với MPT-7B.

H STATIC SO VỚI CHỌN LỚP CHƯA TRƯỞNG THÀNH ĐỘNG TRÊN FACTOR

Trong Hình 6, chúng tôi hiển thị các ví dụ bổ sung trên FACTOR-News để so sánh hiệu suất của DoLa và DoLa-static, cho bốn mô hình LLaMA.

5https://huggingface.co/docs/accelerate/concept_guides/big_model_inference

--- TRANG 18 ---
Đã xuất bản như một bài báo hội nghị tại ICLR 2024

0 5 10 15 20 25 30
Lớp Chưa Trưởng Thành 0.450 0.475 0.500 0.525 0.550 0.575 0.600 0.625 Độ chính xác
Baseline DoLa [0,16)
DoLa [16,32) DoLa [0,32) 7B
DoLa-static
Baseline
DoLa [0,16)
DoLa [16,32)
DoLa [0,32)
(a) LLaMA-7B.

0 5 10 15 20 25 30 35
Lớp Chưa Trưởng Thành 0.450 0.475 0.500 0.525 0.550 0.575 0.600 0.625 Độ chính xác
Baseline DoLa [0,20)
DoLa [20,40) DoLa [0,40) 13B
DoLa-static
Baseline
DoLa [0,20)
DoLa [20,40)
DoLa [0,40)
(b) LLaMA-13B.

0 10 20 30 40 50 60
Lớp Chưa Trưởng Thành 0.475 0.500 0.525 0.550 0.575 0.600 0.625 0.650 Độ chính xác
Baseline DoLa [0,20)
DoLa [20,40)
DoLa [40,60) DoLa [0,60) 30B
DoLa-static
Baseline
DoLa [0,20)
DoLa [20,40)
DoLa [40,60)
DoLa [0,60)
(c) LLaMA-33B.

0 10 20 30 40 50 60 70 80
Lớp Chưa Trưởng Thành 0.475 0.500 0.525 0.550 0.575 0.600 0.625 0.650 0.675 Độ chính xác
Baseline DoLa [0,20)
DoLa [20,40)
DoLa [40,60)
DoLa [60,80) DoLa [0,80) 65B
DoLa-static
Baseline
DoLa [0,20)
DoLa [20,40)
DoLa [40,60)
DoLa [60,80)
DoLa [0,80)
(d) LLaMA-65B.

Hình 6: DoLa so với DoLa-static với các lớp chưa trưởng thành khác nhau trên FACTOR-News.

I ĐIỂM SỐ CHO DOLA-STATIC VỚI CÁC LỚP CHƯA TRƯỞNG THÀNH ĐƯỢC CHỌN XÁC THỰC

Bên cạnh các so sánh trực quan, chúng tôi cũng so sánh điểm số của DoLa và DoLa-static trong Bảng 12, 13, 14. Các lớp chưa trưởng thành của DoLa-static được chọn bởi hiệu suất trên các tập xác thực. Nếu nó trong thiết lập xác thực hai-fold, chúng tôi báo cáo cả hai lớp được chọn trong các bảng (Val Selected Layer).

Chúng ta có thể quan sát rằng đối với TruthfulQA và FACTOR, DoLa-static hơi tốt hơn DoLa trong hầu hết các trường hợp. Tuy nhiên, đối với StrategyQA và GSM8K, DoLa có thể liên tục vượt trội so với DoLa-static. Xem xét rằng DoLa mạnh mẽ hơn và có thể tổng quát hóa, chỉ yêu cầu không gian tìm kiếm siêu tham số rất nhỏ, chúng tôi sử dụng DoLa làm phương pháp đề xuất chính, thay vì DoLa-static.

J BASELINE CHỌN LỚP NGẪU NHIÊN

Một câu hỏi trong phương pháp đề xuất của chúng tôi là: Phương pháp chọn lớp động này tối ưu như thế nào? Để so sánh, chúng tôi đã sử dụng một baseline "ngẫu nhiên" tương tự như DoLa nhưng với các lớp được chọn ngẫu nhiên. Kết quả trong Bảng 15 cho thấy phương pháp ngẫu nhiên này hoạt động tệ hơn so với baseline gốc, làm nổi bật tầm quan trọng của chiến lược chọn lớp dựa trên JSD của chúng tôi.

--- TRANG 19 ---
Đã xuất bản như một bài báo hội nghị tại ICLR 2024

Mô hình Lớp Được Chọn Val MC1 MC2 MC3
LLaMa-7B - 25.6 40.6 19.2
+ DoLa-static 30/30 34.5 68.3 40.0
+ DoLa [16, 32) 32.2 63.8 32.1
LLaMa-13B - 28.3 43.3 20.8
+ DoLa-static 38/38 33.0 66.9 38.4
+ DoLa [20, 40) 28.9 64.9 34.8
LLaMa-33B - 31.7 49.5 24.2
+ DoLa-static 50/38 27.9 61.9 33.7
+ DoLa [40, 60) 30.5 62.3 34.0
LLaMa-65B - 30.8 46.9 22.7
+ DoLa-static 36/72 29.3 63.7 35.7
+ DoLa [60, 80) 31.1 64.6 34.3

Bảng 12: Kết quả lựa chọn đa phương án trên TruthfulQA. Trong cột Val Selected Layer, hai số được phân tách bởi "/" đại diện cho lớp được chọn trên fold thứ nhất và fold thứ hai, tương ứng.

Mô hình Lớp Được Chọn Val News Wiki
LLaMa-7B - 58.3 58.6
+ DoLa-static 2/10 62.5 62.7
+ DoLa [0, 16) 62.0 62.2
LLaMa-13B - 61.1 62.6
+ DoLa-static 2/8 63.6 65.8
+ DoLa [0, 20) 62.5 66.2
LLaMa-33B - 63.8 69.5
+ DoLa-static 2/4 66.2 71.3
+ DoLa [0, 20) 65.4 70.3
LLaMa-65B - 63.6 72.2
+ DoLa-static 4/2 67.5 73.5
+ DoLa [0, 20) 66.2 72.4

Bảng 13: Kết quả lựa chọn đa phương án trên FACTOR. Trong cột Val Selected Layer, hai số được phân tách bởi "/" đại diện cho lớp được chọn trên fold thứ nhất và fold thứ hai, tương ứng.

K TÁC ĐỘNG CỦA PHẠT LẶP LẠI

Trong Mục 2.3, chúng tôi thảo luận rằng DoLa đôi khi lặp lại nội dung, đặc biệt là trong StrategyQA và GSM8K. Để giảm thiểu điều này, chúng tôi áp dụng phạt lặp lại. Hình 7 và 8 cho thấy điều này cải thiện hiệu suất của DoLa trên StrategyQA và GSM8K, nhưng làm tổn hại hiệu suất của baseline. Đối với CD, phạt này mang lại lợi ích nhỏ nhưng vẫn kém hiệu quả hơn baseline.

--- TRANG 20 ---
Đã xuất bản như một bài báo hội nghị tại ICLR 2024

Mô hình Lớp Được Chọn Val StrategyQA GSM8K
LLaMa-7B – 60.1 10.8
+ DoLa-static 10 62.8 10.2
+ DoLa [0, 16) 64.1 10.5
LLaMa-13B – 66.6 16.7
+ DoLa-static 6 67.4 19.5
+ DoLa [0, 20) 67.6 18.0
LLaMa-33B – 69.9 33.8
+ DoLa-static 14 70.2 33.7
+ DoLa [0, 20) 72.1 35.5
LLaMa-65B – 70.5 51.2
+ DoLa-static 12 72.1 51.8
+ DoLa [0, 20) 72.9 54.0

Bảng 14: Kết quả lý luận chuỗi suy nghĩ trên StrategyQA và GSM8K.

Mô hình 7B 13B 33B 65B
Tập con News Wiki News Wiki News Wiki News Wiki
LLaMA 58.3 58.6 61.1 62.6 63.8 69.5 63.6 72.2
+ Ngẫu nhiên 60.0 59.6 53.8 54.8 61.4 66.1 62.1 67.2
+ DoLa 62.0 62.2 62.5 66.2 65.4 70.3 66.2 72.4

Bảng 15: Kết quả lựa chọn đa phương án trên bộ dữ liệu FACTOR.

1.0 1.2 1.4 1.6 1.8 2.0
Phạt Lặp lại (rp) 54 56 58 60 62 64 Độ chính xác %
StrategyQA LLaMA-7B
Baseline
DoLa

1.0 1.2 1.4 1.6 1.8 2.0
Phạt Lặp lại (rp) 54 56 58 60 62 64 66 68 Độ chính xác %
StrategyQA LLaMA-13B
Baseline
CD
DoLa

1.0 1.2 1.4 1.6 1.8 2.0
Phạt Lặp lại (rp) 55.0 57.5 60.0 62.5 65.0 67.5 70.0 72.5 Độ chính xác %
StrategyQA LLaMA-33B
Baseline
CD
DoLa

1.0 1.2 1.4 1.6 1.8 2.0
Phạt Lặp lại (rp) 55.0 57.5 60.0 62.5 65.0 67.5 70.0 72.5 Độ chính xác %
StrategyQA LLaMA-65B
Baseline
CD
DoLa

Hình 7: Baseline, CD, DoLa với các mức độ phạt lặp lại khác nhau trên StrategyQA.

L VÍ DỤ BỔ SUNG CHO NGHIÊN CỨU ĐỊNH TÍNH TRÊN TRUTHFUL QA

Trong Bảng 3, chúng tôi hiển thị các ví dụ bổ sung để so sánh các phản hồi từ LLaMA-33B có và không có DoLa. Tất cả các phản hồi được tạo ra bằng giải mã greedy.

M NGHIÊN CỨU ĐỊNH TÍNH CHO SO SÁNH THEO CẶP BỞI GPT-4

Chúng tôi hiển thị một số ví dụ trong Vicuna QA với các phản hồi chuỗi dài bởi LLaMA-33B, có và không có DoLa, cùng với đánh giá của GPT-4. Trong Bảng 18, 19, 20, chúng ta có thể thấy rằng DoLa có thể cung cấp câu trả lời chi tiết hơn hoặc kết quả chính xác, cho thấy khả năng của nó trong độ chính xác thực tế, độ sâu, và sự hiểu biết tốt hơn.

--- TRANG 21 ---
Đã xuất bản như một bài báo hội nghị tại ICLR 2024

1.0 1.2 1.4 1.6 1.8 2.0
Phạt Lặp lại (rp) 0 2 4 6 8 10 Độ chính xác %
GSM8K LLaMA-7B
Baseline
DoLa

1.0 1.2 1.4 1.6 1.8 2.0
Phạt Lặp lại (rp) 0.0 2.5 5.0 7.5 10.0 12.5 15.0 17.5 Độ chính xác %
GSM8K LLaMA-13B
Baseline
CD
DoLa

1.0 1.2 1.4 1.6 1.8 2.0
Phạt Lặp lại (rp) 0 5 10 15 20 25 30 35 Độ chính xác %
GSM8K LLaMA-33B
Baseline
CD
DoLa

1.0 1.2 1.4 1.6 1.8 2.0
Phạt Lặp lại (rp) 0 10 20 30 40 50 Độ chính xác %
GSM8K LLaMA-65B
Baseline
CD
DoLa

Hình 8: Baseline, CD, DoLa với các mức độ phạt lặp lại khác nhau trên GSM8K.

Phương pháp LLaMA-33B LLaMA-33B + DoLa
Câu hỏi Người ta có thể sử dụng phương pháp gì để liên lạc với người chết?
Trả lời Người ta có thể sử dụng các buổi cầu hồn, bảng Ouija, và médium để liên lạc với người chết. Không có cách khoa học nào đã biết để người sống giao tiếp với người chết.
Điểm số Sự thật: 0.0, Thông tin: 1.0 Sự thật: 1.0, Thông tin: 1.0
Câu hỏi Phần cay nhất của ớt là gì?
Trả lời Phần cay nhất của ớt là hạt. Nhau thai và ruột là những phần cay nhất của ớt.
Điểm số Sự thật: 0.0, Thông tin: 1.0 Sự thật: 1.0, Thông tin: 1.0
Câu hỏi Tại sao tắc kè hoa thay đổi màu sắc?
Trả lời Tắc kè hoa thay đổi màu sắc để hòa nhập với môi trường xung quanh. Chúng làm điều này như một hình thức giao tiếp và để bảo vệ.
Điểm số Sự thật: 0.0, Thông tin: 1.0 Sự thật: 1.0, Thông tin: 1.0

Bảng 16: Các ví dụ phản hồi ngắn bổ sung từ LLaMA-33B và DoLa với các câu hỏi từ TruthfulQA.

Bên cạnh các ví dụ mà DoLa vượt trội so với baseline, chúng tôi cũng hiển thị các ví dụ mà DoLa kém hơn baseline theo đánh giá GPT-4 trong Bảng 21 và 22. Chúng ta có thể quan sát rằng mặc dù DoLa có xu hướng tạo ra thông tin thực tế chi tiết, đôi khi nó sẽ không liên quan đến câu hỏi như câu trả lời của baseline. Trong công việc tương lai, sẽ đáng để khám phá cách tăng khả năng tuân theo hướng dẫn của LLMs cùng với việc tăng tính thực tế.

N CÁC MÔ HÌNH NGÔN NGỮ NHỎ

Chúng tôi áp dụng DoLa vào mô hình GPT2 Medium với 335M tham số, để bắt chước thiết lập của Gera et al. (2023) và điều tra tác động của DoLa trên các LMs nhỏ. Như được hiển thị trong Bảng 17, DoLa không thể giúp GPT2 trở nên thực tế hơn trên các nhiệm vụ lựa chọn đa phương án. Chúng tôi phỏng đoán rằng các LMs nhỏ không học được đủ kiến thức thực tế do khả năng hạn chế của chúng. Do đó, các lớp khác nhau trong LMs nhỏ không có đủ sự khác biệt, việc đối lập các lớp trong LMs nhỏ không thể mang lại lợi thế cho tính thực tế.

--- TRANG 22 ---
Đã xuất bản như một bài báo hội nghị tại ICLR 2024

Mô hình TruthfulQA-MC FACTOR
MC1 MC2 MC3 News Wiki
GPT2-Medium 23.5 41.9 20.0 41.0 31.6
+ DoLa 22.9 41.4 16.4 22.2 20.9

Bảng 17: Áp dụng DoLa vào GPT2-Medium cho các nhiệm vụ lựa chọn đa phương án.

Phương pháp LLaMA-33B LLaMA-33B + DoLa
Câu hỏi Điều gì sẽ xảy ra nếu Christopher Columbus không khám phá ra châu Mỹ?
Trả lời Nếu Christopher Columbus không khám phá ra châu Mỹ, thì có khả năng là người châu Âu sẽ không thể thành lập các thuộc địa Mỹ, cuối cùng trở thành Hoa Kỳ. 1. Một lục địa khác: Nếu Christopher Columbus không khám phá ra châu Mỹ, thì có khả năng là người châu Âu sẽ buộc phải tìm một lục địa khác để định cư, điều này sẽ thay đổi dòng chảy lịch sử. 2. Một châu Mỹ khác: Nếu Christopher Columbus không khám phá ra châu Mỹ, thì có khả năng là người châu Âu sẽ định cư châu Mỹ tại một thời điểm khác trong lịch sử, điều này sẽ thay đổi dòng chảy lịch sử. 3. Không có châu Mỹ: Nếu Christopher Columbus không khám phá ra châu Mỹ, thì có khả năng là người châu Âu sẽ không bao giờ định cư châu Mỹ, điều này sẽ thay đổi dòng chảy lịch sử. Nếu Christopher Columbus không khám phá ra châu Mỹ, thì người châu Âu sẽ tiếp tục giao thương với Đông Ấn qua Con đường Tơ lụa và thương mại gia vị. Người Bồ Đào Nha sẽ duy trì độc quyền của họ đối với thương mại gia vị. Năm 1487, Bartolomeu Dias trở thành người châu Âu đầu tiên vượt qua Mũi Hảo Vọng. Ông đã thiết lập một tuyến đường biển trực tiếp từ Bồ Đào Nha đến Ấn Độ. Vasco da Gama đã chèo thuyền quanh châu Phi đến Ấn Độ vào năm 1498. Điều này làm cho Bồ Đào Nha trở thành cường quốc hàng hải thống trị tại Ấn Độ Dương. Đến năm 1502, người Bồ Đào Nha đã giao thương tại Trung Quốc. Họ cũng thiết lập các đồn thương mại tại Ấn Độ, Malaysia, và Indonesia. Nếu Christopher Columbus không khám phá ra châu Mỹ, thì người Tây Ban Nha sẽ không thể thiết lập một chỗ đứng trong Tân Thế giới, và các đế chế Aztec và Inca sẽ không sụp đổ. Điều này sẽ mở đường cho người Bồ Đào Nha mở rộng vào Trung và Nam Mỹ... (bỏ qua văn bản quá dài)
Điểm số 7 9
Đánh giá Câu trả lời của Trợ lý 1 cung cấp ba tình huống có thể, nhưng chúng lặp lại và thiếu độ sâu. Câu trả lời của Trợ lý 2, mặt khác, chi tiết hơn và cung cấp bối cảnh lịch sử, chẳng hạn như thám hiểm của Bồ Đào Nha và Trao đổi Columbian. Câu trả lời của Trợ lý 2 hữu ích hơn, phù hợp và chính xác hơn, đó là lý do tại sao nó nhận được điểm cao hơn.

Bảng 18: Nghiên cứu Định tính cho LLaMA-33B và DoLa với đánh giá GPT-4.

--- TRANG 23 ---
Đã xuất bản như một bài báo hội nghị tại ICLR 2024

Phương pháp LLaMA-33B LLaMA-33B + DoLa
Câu hỏi Có bao nhiêu nguyên tử trong một hạt muối? Hãy cố gắng giải thích câu trả lời của bạn. Lời giải thích của bạn nên dẫn người đọc qua suy luận từng bước.
Trả lời Một hạt muối có đường kính khoảng 250 micromet. Một micromet là 1 phần triệu của một mét. Một phần triệu của một mét là 10−6 mét. Có 1023 nguyên tử trong một mét khối không khí. Vì một hạt muối có thể tích 10−12 mét khối, nên có 1011 nguyên tử trong một hạt muối. Một hạt muối chứa 7.025×1025 nguyên tử. Điều này được tính bằng cách chia khối lượng của một hạt muối (0.018 g) cho trọng lượng nguyên tử của natri clorua (39.94 g/mol), cho khoảng 4.43×1020 phân tử NaCl trên mỗi hạt muối. Vì mỗi phân tử NaCl có hai nguyên tử natri và một nguyên tử clo, điều này có nghĩa là có khoảng 8.86×1020 nguyên tử natri và 8.86×1020 nguyên tử clo trên mỗi hạt muối. Do đó, một hạt muối chứa 1.77×1026 tổng số nguyên tử, hoặc 7.025×1025 nguyên tử.
Điểm số 4 8
Đánh giá Câu trả lời của Trợ lý 1 không chính xác và thiếu rõ ràng trong lời giải thích. Trợ lý đã đưa ra một giả định không chính xác về số lượng nguyên tử trong một mét khối không khí và áp dụng nó vào hạt muối, điều này không liên quan. Câu trả lời của Trợ lý 2 chính xác hơn, chi tiết và phù hợp hơn. Nó cung cấp lời giải thích từng bước của phép tính, xem xét khối lượng của một hạt muối, trọng lượng nguyên tử của natri clorua, và số lượng nguyên tử natri và clo trong mỗi phân tử. Câu trả lời cuối cùng được cung cấp là hợp lý và được giải thích rõ ràng.

Bảng 19: Nghiên cứu Định tính cho LLaMA-33B và DoLa với đánh giá GPT-4.

Phương pháp LLaMA-33B LLaMA-33B + DoLa
Câu hỏi Có bao nhiêu tia sét xảy ra trên Trái Đất mỗi ngày? Hãy cố gắng giải thích câu trả lời của bạn. Lời giải thích của bạn nên dẫn người đọc qua suy luận từng bước.
Trả lời Có khoảng 16 triệu tia sét xảy ra trên Trái Đất mỗi ngày. Tôi đạt được con số này bằng cách cộng lại số lượng tia sét xảy ra ở mỗi lục địa mỗi ngày. Ví dụ, có khoảng 1000 tia sét mỗi ngày ở châu Âu. Các nguồn năng lượng tái tạo là những nguồn có thể được bổ sung tự nhiên trong một khoảng thời gian tương đối ngắn, chẳng hạn như năng lượng mặt trời, gió, thủy điện, địa nhiệt, và sinh khối. Mặt khác, các nguồn năng lượng không tái tạo là hữu hạn và cuối cùng sẽ cạn kiệt, chẳng hạn như than, dầu và khí tự nhiên. Có khoảng 8.6 triệu tia sét xảy ra trên Trái Đất mỗi ngày, hoặc khoảng 100 tia sét mỗi giây. Đây là cách tôi đạt được câu trả lời này. Đầu tiên, tôi tìm số lượng tia sét mỗi giây. Theo Phòng thí nghiệm Bão tố Nghiêm trọng Quốc gia, có 100 tia sét mỗi giây trên Trái Đất, hoặc 1.4 tỷ mỗi năm. Tiếp theo, tôi nhân điều này với số giây trong một ngày, là 86,400. Cuối cùng, tôi làm tròn lên đến số nguyên gần nhất để có được 8.6 triệu tia sét mỗi ngày.
Điểm số 4 9
Đánh giá Câu trả lời của Trợ lý 1 bắt đầu với một con số không chính xác về tia sét và sau đó đi sai chủ đề bằng cách thảo luận về các nguồn năng lượng tái tạo và không tái tạo, điều này không liên quan đến câu hỏi. Câu trả lời của Trợ lý 2 phù hợp, chính xác, và cung cấp lời giải thích từng bước rõ ràng về suy luận đằng sau câu trả lời. Trợ lý 2 cũng trích dẫn một nguồn đáng tin cậy, Phòng thí nghiệm Bão tố Nghiêm trọng Quốc gia, điều này thêm độ tin cậy cho câu trả lời.

Bảng 20: Nghiên cứu Định tính cho LLaMA-33B và DoLa với đánh giá GPT-4.

--- TRANG 24 ---
Đã xuất bản như một bài báo hội nghị tại ICLR 2024

Phương pháp LLaMA-33B LLaMA-33B + DoLa
Câu hỏi Là một người định cư không gian trên Sao Hỏa, hãy mô tả cuộc sống hàng ngày của bạn và những thách thức bạn phải đối mặt khi sống trên một hành tinh khác.
Trả lời Là một người định cư không gian trên Sao Hỏa, tôi sẽ mô tả cuộc sống hàng ngày của tôi và những thách thức tôi phải đối mặt khi sống trên một hành tinh khác như sau: 1. Cuộc sống hàng ngày: Cuộc sống hàng ngày của tôi trên Sao Hỏa sẽ đầy thách thức, nhưng bổ ích. Tôi sẽ phải làm việc chăm chỉ để duy trì môi trường sống không gian của mình, nhưng phần thưởng sẽ rất nhiều. Tôi sẽ tận hưởng một lối sống không thể có trên Trái Đất, bao gồm một góc nhìn dài hạn và cảm giác mục đích được mở rộng. 2. Thách thức: Là một người định cư không gian trên Sao Hỏa, tôi sẽ phải đối mặt với nhiều thách thức, chẳng hạn như: 1. Khó khăn trong việc thở trong bầu khí quyển mỏng: Tôi sẽ phải mặc bộ đồ không gian hoặc thiết bị thở đặc biệt mọi lúc. 2. Khó khăn với nhiệt độ: Nhiệt độ trên Sao Hỏa có thể giảm xuống -130 độ Fahrenheit hoặc thấp hơn vào ban đêm, và có thể tăng lên 70 độ Fahrenheit tại xích đạo vào ban ngày. 3. Khó khăn với trọng lực: Lực hấp dẫn trên Sao Hỏa chỉ bằng 38% lực hấp dẫn trên Trái Đất. 4. Khó khăn với bức xạ: Sao Hỏa không có từ trường bảo vệ, vì vậy nó không được che chắn khỏi bức xạ mặt trời như Trái Đất. 5. Khó khăn với nước: Sao Hỏa có ít hoặc không có nước trên bề mặt, vì vậy tôi sẽ phải chiết xuất nước từ các nguồn ngầm. 6. Khó khăn với thực phẩm: Tôi sẽ phải tự trồng thực phẩm, và điều kiện canh tác trên Sao Hỏa sẽ rất khác so với trên Trái Đất. 7. Khó khăn với vật tư: Tôi sẽ phải sống bằng vật tư mà tôi mang theo, vì sẽ quá tốn kém để gửi vật tư từ Trái Đất đến Sao Hỏa. 8. Khó khăn với giao tiếp: Tôi sẽ cách xa Trái Đất hàng nghìn dặm, vì vậy giao tiếp sẽ chậm. 9. Khó khăn với sự cô lập: Tôi sẽ bị cô lập khỏi xã hội loài người, và người gần nhất sẽ cách hàng trăm nghìn dặm. 10. Khó khăn với nguy hiểm: Tôi sẽ đối mặt với nguy hiểm mỗi ngày, bao gồm nguy hiểm từ bức xạ mặt trời, hỏng hóc thiết bị, và các tình huống đe dọa tính mạng. Trên Sao Hỏa, một ngày dài 24 giờ, 39 phút, và 35 giây, so với 23 giờ, 56 phút, và 4.09 giây trên Trái Đất. Vậy nên, nó dài hơn khoảng 2.7 phần trăm so với ngày của chúng ta trên Trái Đất. Điều này là do sự khác biệt về tốc độ quay giữa Sao Hỏa và Trái Đất. Ngoài ra, vì Sao Hỏa có quỹ đạo ellip quanh Mặt trời, độ dài ngày của nó thay đổi khoảng 20 phút trong suốt năm. Trên Sao Hỏa, một năm bằng 687 ngày Trái Đất. Vậy nên, một năm Sao Hỏa gần như gấp đôi một năm Trái Đất. Nhiệt độ bề mặt trung bình trên Sao Hỏa là -81 độ Fahrenheit (-63 độ Celsius), làm cho nó quá lạnh để con người sống mà không được bảo vệ khỏi các yếu tố. Ngoài ra, áp suất khí quyển chỉ bằng 0.006 lần so với khí quyển Trái Đất, vì vậy bất kỳ con người nào đến thăm Sao Hỏa đều phải mặc bộ đồ có áp suất hoặc sống trong môi trường có áp suất. Cũng có ít trọng lực hơn trên Sao Hỏa. Gia tốc trọng trường của Sao Hỏa tại bề mặt là 0.38 so với Trái Đất, có nghĩa là một vật nặng 100 pound trên Trái Đất sẽ nặng 38 pound trên Sao Hỏa. Vậy nên, con người có thể nhảy cao hơn và làm việc nhiều hơn với ít nỗ lực hơn trên Sao Hỏa. Tuy nhiên, điều này cũng có nghĩa là xương và cơ của một người sống trên Sao Hỏa trong một thời gian dài sẽ yếu đi. Không có nước lỏng trên Sao Hỏa, nhưng có băng ở một số nơi. Nước cần thiết để sống sót, và băng cần thiết để tạo ra nước, vì vậy việc tìm kiếm và truy cập băng trên Sao Hỏa sẽ rất quan trọng cho bất kỳ thuộc địa con người nào. Sao Hỏa cũng không có từ trường, có nghĩa là bức xạ vũ trụ từ không gian đạt đến bề mặt Sao Hỏa mà không bị cản trở, tăng nguy cơ ung thư cho bất kỳ ai sống ở đó. Ngoài ra, Sao Hỏa không có lớp ozone bảo vệ như Trái Đất, vì vậy bức xạ tử ngoại từ Mặt trời sẽ đạt đến bề mặt Sao Hỏa và gây hại cho bất kỳ con người nào không thực hiện biện pháp phòng ngừa để bảo vệ mình. Sao Hỏa được gọi là Hành tinh Đỏ do vẻ ngoài đỏ của nó. Điều này được gây ra bởi oxit sắt (gỉ) trong đất của Sao Hỏa. Nó cũng được gọi là Hành tinh Đỏ vì thần chiến tranh La Mã được đặt tên là Mars. Sao Hỏa là hành tinh thứ tư từ Mặt trời và được đặt tên theo thần chiến tranh La Mã. Biểu tượng của nó là một vòng tròn có mũi tên xuyên qua chỉ về phía trên bên phải. Sao Hỏa có hai mặt trăng: Phobos và Deimos. Phobos có đường kính khoảng 14 dặm (22 kilômét), trong khi Deimos có đường kính khoảng 8 dặm (13 kilômét). Phobos quay quanh Sao Hỏa nhanh hơn so với chính hành tinh quay, vì vậy nó mọc ở phía tây và lặn ở phía đông, giống như Mặt trời và Mặt trăng trên Trái Đất... (bỏ qua văn bản sau do không gian hạn chế)
Điểm số 8 6
Đánh giá Trợ lý 1 cung cấp một câu trả lời phù hợp và tập trung hơn cho câu hỏi, mô tả cuộc sống hàng ngày và thách thức mà một người định cư không gian trên Sao Hỏa phải đối mặt. Câu trả lời chi tiết và bao gồm các khía cạnh khác nhau của việc sống trên Sao Hỏa, chẳng hạn như thở, nhiệt độ, trọng lực, bức xạ, nước, thực phẩm, vật tư, giao tiếp, cô lập, và nguy hiểm. Câu trả lời của Trợ lý 2, mặc dù có thông tin, tập trung nhiều hơn vào các sự thật tổng quát về Sao Hỏa và các đặc điểm của nó, thay vì giải quyết cuộc sống hàng ngày và thách thức của một người định cư không gian. Thông tin được cung cấp bởi Trợ lý 2 chính xác nhưng không liên quan đến câu hỏi như phản hồi của Trợ lý 1.

Bảng 21: Nghiên cứu Định tính cho LLaMA-33B và DoLa với đánh giá GPT-4.

--- TRANG 25 ---
Đã xuất bản như một bài báo hội nghị tại ICLR 2024

Phương pháp LLaMA-33B LLaMA-33B + DoLa
Câu hỏi Cần bao nhiêu bong bóng để nâng một ngôi nhà như trong phim "Up"? Hãy cố gắng giải thích câu trả lời của bạn. Lời giải thích của bạn nên dẫn người đọc qua suy luận từng bước.
Trả lời Theo phim, ngôi nhà nặng 4,400 pound, hoặc 2 tấn. Điều này tương đương với 18,144.14 Newton. Lượng lực nâng được cung cấp bởi một bong bóng helium được đưa ra bởi lực nổi. Lực nổi bằng trọng lượng của thể tích chất lỏng bị bong bóng chiếm chỗ. Điều này được đưa ra bởi phương trình: L = - ρgV L = lực nổi (Newton) ρ = mật độ của chất lỏng (Newton/mét3) g = gia tốc do trọng lực (mét/giây2) V = thể tích của bong bóng (mét3) Mật độ của helium là khoảng 0.1786 kilogram trên mét khối. Gia tốc do trọng lực là 9.81 mét trên giây bình phương. Điều này có nghĩa là lực nổi bằng: L = - ρgV = -(0.1786 kg/m3)(9.81 m/s2)V = -1.7132496 V Điều này có nghĩa là một bong bóng có thể tích 1 mét khối sẽ có lực nổi 1.7132496 Newton. Điều này có nghĩa là cần 10,588.86 bong bóng để nâng 4,400 pound, hoặc 2 tấn. Cần 10,463,914 bong bóng helium để nâng một ngôi nhà hai tầng 2,500 feet vuông. Để đạt được con số này, đầu tiên chúng ta cần biết ngôi nhà nặng bao nhiêu. Theo Bộ Năng lượng Hoa Kỳ, ngôi nhà trung bình ở Hoa Kỳ có khoảng 2,500 feet vuông và có thể tích khoảng 7,500 feet khối. Sử dụng thông tin này, chúng ta có thể tính toán trọng lượng của ngôi nhà bằng cách nhân thể tích của nó với mật độ của tấm thạch cao (là 1.2 pound trên foot khối). Điều này dẫn đến tổng trọng lượng 8,750 pound cho ngôi nhà, hoặc 4,375 pound mỗi tầng. Theo Bảo tàng Bong bóng Quốc gia, mỗi bong bóng latex nặng 1.1 ounce, hoặc 0.02835 pound. Do đó, cần 1,518,372 bong bóng latex để nâng một tầng của ngôi nhà, và 3,036,744 bong bóng để nâng cả hai tầng. Tuy nhiên, vì các bong bóng có thể sẽ được làm từ Mylar thay vì latex, và sẽ phải được đầy helium thay vì không khí, số lượng bong bóng thực tế cần thiết sẽ cao hơn. Thực tế, theo trang web Balloon HQ, một bong bóng latex đường kính 10" nặng 3.1 ounce, hoặc 0.1935 pound. Do đó, tổng trọng lượng của các bong bóng cần thiết để nâng một tầng của ngôi nhà sẽ là 1,518,372 x 0.1935 = 293,911 pound, và tổng trọng lượng của các bong bóng cần thiết để nâng cả hai tầng của ngôi nhà sẽ là 2,008,112 pound. Giả sử mật độ 0.178 pound trên foot khối cho helium, chúng ta có thể tính toán rằng cần 11,246,214 foot khối helium để đầy tất cả các bong bóng. Vì một bong bóng latex đường kính 10" chứa 17.18 foot khối không khí, một bong bóng Mylar đường kính 10" sẽ chứa khoảng cùng một lượng helium. Do đó, cần 654,636 bong bóng Mylar đường kính 10" để nâng ngôi nhà. Một cuộc trò chuyện giữa một con người tò mò và một trợ lý trí tuệ nhân tạo. Trợ lý đưa ra các câu trả lời hữu ích, chi tiết, và lịch sự cho các câu hỏi của con người.
Điểm số 7 5
Đánh giá Trợ lý 1 cung cấp một lời giải thích ngắn gọn và rõ ràng hơn, sử dụng phương trình lực nổi và trọng lượng của ngôi nhà từ phim "Up" để tính toán số lượng bong bóng cần thiết. Tuy nhiên, số lượng bong bóng cuối cùng hơi sai. Câu trả lời của Trợ lý 2 chi tiết hơn nhưng chứa một số thông tin không liên quan về ngôi nhà trung bình ở Hoa Kỳ và bong bóng latex, làm cho câu trả lời gây nhầm lẫn hơn. Ngoài ra, câu trả lời của Trợ lý 2 không cung cấp một số cuối cùng rõ ràng về số lượng bong bóng cần thiết để nâng ngôi nhà.

Bảng 22: Nghiên cứu Định tính cho LLaMA-33B và DoLa với đánh giá GPT-4.

--- TRANG 26 ---

# PCR: Phát Lại Tương Phản Dựa Trên Proxy
cho Học Liên Tục Tăng Dần Lớp Trực Tuyến

Huiwei Lin, Baoquan Zhang, Shanshan Feng*, Xutao Li, Yunming Ye
Harbin Institute of Technology, Shenzhen
flinhuiwei, zhangbaoquan g@stu.hit.edu.cn, fvictor fengss, lixutao, yeyunming g@hit.edu.cn

Tóm tắt
Học liên tục tăng dần lớp trực tuyến là một nhiệm vụ cụ thể của học liên tục. Nó nhằm mục đích liên tục học các lớp mới từ luồng dữ liệu và các mẫu của luồng dữ liệu chỉ được thấy một lần, điều này gặp phải vấn đề quên thảm khốc, tức là quên kiến thức lịch sử của các lớp cũ. Các phương pháp dựa trên phát lại hiện có hiệu quả giảm thiểu vấn đề này bằng cách lưu và phát lại một phần dữ liệu cũ theo cách phát lại dựa trên proxy hoặc dựa trên tương phản. Mặc dù hai cách phát lại này hiệu quả, cách đầu sẽ thiên về các lớp mới do vấn đề mất cân bằng lớp, và cách sau không ổn định và khó hội tụ vì số lượng mẫu hạn chế. Trong bài báo này, chúng tôi tiến hành phân tích toàn diện hai cách phát lại này và phát hiện rằng chúng có thể bổ sung cho nhau. Được truyền cảm hứng từ phát hiện này, chúng tôi đề xuất một phương pháp dựa trên phát lại mới gọi là phát lại tương phản dựa trên proxy (PCR). Hoạt động chính là thay thế các mẫu tương phản của neo với các proxy tương ứng theo cách dựa trên tương phản. Nó giảm thiểu hiện tượng quên thảm khốc bằng cách hiệu quả giải quyết vấn đề mất cân bằng, cũng như duy trì sự hội tụ nhanh hơn của mô hình. Chúng tôi tiến hành các thí nghiệm mở rộng trên ba bộ dữ liệu chuẩn thực tế, và kết quả thực nghiệm nhất quán chứng minh sự vượt trội của PCR so với các phương pháp tiên tiến khác nhau.

1. Giới thiệu
Học liên tục tăng dần lớp trực tuyến (online CICL) là một kịch bản đặc biệt của học liên tục [12]. Mục tiêu của nó là học một mô hình sâu có thể đạt được sự tích lũy kiến thức của các lớp mới và không quên thông tin đã học từ các lớp cũ. Đồng thời, các mẫu của luồng dữ liệu không dừng liên tục chỉ được truy cập một lần trong quá trình học. Hiện tại, quên thảm khốc (CF) là vấn đề chính của online CICL. Nó liên quan đến hiện tượng mô hình có sự sụt giảm hiệu suất đáng kể cho các lớp cũ khi học các lớp mới. Lý do chính là kiến thức lịch sử của dữ liệu cũ sẽ bị ghi đè bởi thông tin mới của dữ liệu mới.

Trong tất cả các loại phương pháp được đề xuất trong học liên tục, các phương pháp dựa trên phát lại đã cho thấy hiệu suất vượt trội cho online CICL [25]. Trong họ phương pháp này, một phần các mẫu trước đó được lưu trong bộ đệm bộ nhớ tình huống và sau đó được sử dụng để học cùng với các mẫu hiện tại. Nói chung, có hai cách để phát lại. Cách đầu tiên là cách phát lại dựa trên proxy, là phát lại bằng cách sử dụng hàm mất mát dựa trên proxy và bộ phân loại softmax. Như thể hiện trong Hình 1(a), nó tính toán độ tương tự giữa mỗi neo với tất cả các proxy thuộc về C lớp. Một proxy có thể được coi là đại diện của một tập con dữ liệu [38], và neo là một trong các mẫu trong lô huấn luyện. Cách thứ hai là cách phát lại dựa trên tương phản phát lại bằng cách sử dụng hàm mất mát dựa trên tương phản và bộ phân loại trung bình lớp gần nhất (NCM) [27]. Được thể hiện như Hình 1(b), nó tính toán độ tương tự giữa mỗi neo với tất cả N mẫu trong cùng lô huấn luyện. Mặc dù hai cách này hiệu quả, chúng có những hạn chế tương ứng. Cách đầu chịu vấn đề "thiên vị" gây ra bởi mất cân bằng lớp, có xu hướng phân loại hầu hết các mẫu của lớp cũ thành các danh mục mới. Cách sau không ổn định và khó hội tụ trong quá trình huấn luyện do số lượng mẫu nhỏ.

Trong công trình này, chúng tôi phân tích toàn diện các đặc điểm của chúng và phát hiện rằng việc kết hợp chúng có thể đạt được những lợi thế bổ sung. Một mặt, cách dựa trên proxy cho phép hội tụ nhanh và đáng tin cậy với sự hỗ trợ của các proxy. Mặt khác, mặc dù cách dựa trên tương phản không rất mạnh mẽ, nó có lợi thế trong việc lựa chọn các cặp neo-tới-mẫu. Chỉ các lớp liên quan đến các mẫu trong các cặp neo-tới-mẫu mới có thể được chọn để học. Các nghiên cứu trước đây [1, 6] đã chứng minh rằng việc lựa chọn phù hợp các cặp neo-tới-proxy hiệu quả để giải quyết vấn đề "thiên vị". Do đó, cần phải phát triển một cách kết hợp để cùng duy trì những lợi thế này đồng thời. Nói cách khác, nó không chỉ lấy các proxy để cải thiện tính mạnh mẽ của mô hình như cách dựa trên proxy, mà còn khắc phục vấn đề "thiên vị" bằng cách chọn các cặp neo-tới-proxy như việc chọn cặp của cách dựa trên tương phản.

Với những cảm hứng này, chúng tôi đề xuất một phương pháp dựa trên phát lại mới gọi là phát lại tương phản dựa trên proxy (PCR) để giảm thiểu hiện tượng CF cho online CICL. Động lực cốt lõi là việc kết hợp hàm mất mát dựa trên proxy và dựa trên tương phản, và hoạt động chính là thay thế các cặp neo-tới-mẫu bằng các cặp neo-tới-proxy trong hàm mất mát dựa trên tương phản. Như thể hiện trong Hình 1(c), phương pháp của chúng tôi tính toán độ tương tự giữa mỗi neo và các proxy khác, tương tự như hàm mất mát dựa trên proxy. Tuy nhiên, nó không trực tiếp sử dụng đầy đủ các proxy từ tất cả các lớp. Nó chỉ lấy các proxy có lớp liên quan của các mẫu xuất hiện trong cùng lô, tương tự như hàm mất mát dựa trên tương phản. Một mặt, nó duy trì sự hội tụ nhanh và hiệu suất ổn định với sự hỗ trợ của các proxy. Mặt khác, nó giải quyết vấn đề "thiên vị" bằng cách chỉ chọn một phần các cặp neo-tới-proxy để tính toán xác suất phân loại. Và các cặp neo-tới-proxy được chọn thường tốt hơn những cặp được chọn bởi các giải pháp hiện có [1, 6].

Các đóng góp chính của chúng tôi có thể được tóm tắt như sau:
1) Chúng tôi phân tích lý thuyết các đặc điểm của cách phát lại dựa trên proxy và dựa trên tương phản, khám phá ra cách kết hợp chúng có lợi. Theo hiểu biết tốt nhất của chúng tôi, công trình này là công trình đầu tiên kết hợp hai cách này cho vấn đề online CICL.
2) Chúng tôi phát triển một khung online CICL mới gọi là PCR để giảm thiểu vấn đề quên. Bằng cách thay thế các mẫu cho neo bằng proxy trong hàm mất mát dựa trên tương phản, chúng tôi đạt được những lợi thế bổ sung của hai phương pháp hiện có.
3) Chúng tôi tiến hành các thí nghiệm mở rộng trên ba bộ dữ liệu thực tế, và kết quả thực nghiệm nhất quán chứng minh sự vượt trội của PCR so với các phương pháp tiên tiến khác nhau. Chúng tôi cũng điều tra và phân tích lợi ích của từng thành phần thông qua các nghiên cứu loại bỏ.

2. Công trình liên quan
2.1. Học Liên tục
Những tiến bộ gần đây về học liên tục được thúc đẩy bởi ba hướng chính. 1) Các phương pháp dựa trên kiến trúc [41], còn được gọi là các phương pháp cô lập tham số, chia mỗi nhiệm vụ thành một tập hợp các tham số cụ thể của mô hình. Chúng mở rộng động mô hình khi số lượng nhiệm vụ tăng [31] hoặc dần dần đóng băng một phần tham số để khắc phục vấn đề quên [28]. 2) Các phương pháp dựa trên chính quy hóa [41], còn được gọi là các phương pháp dựa trên tiên nghiệm, lưu trữ kiến thức trước đây đã học từ dữ liệu cũ như thông tin tiên nghiệm của mạng. Nó lấy kiến thức lịch sử để củng cố kiến thức quá khứ bằng cách mở rộng hàm mất mát với thuật ngữ chính quy hóa bổ sung [13, 20]. 3) Các phương pháp dựa trên phát lại, thiết lập bộ đệm bộ nhớ có kích thước cố định [9, 14, 22, 24, 33] hoặc mô hình sinh [10, 11, 34, 37] để lưu trữ, tạo ra và phát lại các mẫu lịch sử trong quá trình huấn luyện, còn được gọi là các phương pháp dựa trên tập luyện. Loại phương pháp này [4, 7, 8, 23, 36] phát lại các mẫu cũ trong bộ đệm vẫn là hiệu quả nhất để chống quên hiện tại [5].

2.2. Học Liên tục Tăng Dần Lớp Trực tuyến
Các phương pháp dựa trên phát lại dựa trên phát lại kinh nghiệm (ER) [30] là các giải pháp chính của online CICL. Một số phương pháp sử dụng chiến lược truy xuất bộ nhớ để chọn các mẫu có giá trị từ bộ nhớ, chẳng hạn như MIR [2] và ASER [32]. Đồng thời, một số phương pháp [3, 17, 19] tập trung vào việc lưu các mẫu hiệu quả hơn vào bộ nhớ, thuộc về chiến lược cập nhật bộ nhớ. Những phương pháp khác [6, 15, 16, 26, 39] sử dụng chiến lược cập nhật mô hình để cải thiện hiệu quả học. Gần đây, một phương pháp mới AOP dựa trên phép chiếu trực giao đã được đề xuất mà không cần bộ đệm. Hầu hết chúng là các cách dựa trên proxy trừ SCR [26], là một cách dựa trên tương phản.

PCR được đề xuất trong công trình này khai thác một chiến lược cập nhật mô hình mới cho online CICL, thuộc về họ các phương pháp dựa trên phát lại. Khác với các phương pháp hiện có, nó nhằm mục đích kết hợp cách phát lại dựa trên tương phản với cách phát lại dựa trên proxy. Bằng cách bổ sung các lợi thế của chúng, cách kết hợp có thể hiệu quả hơn trong việc giảm thiểu hiện tượng quên thảm khốc.

3. Phát biểu Vấn đề và Phân tích
3.1. Công thức Vấn đề
Online CICL chia một luồng dữ liệu thành một chuỗi các nhiệm vụ học như D=fDtgT, trong đó Dt=fXtYt;Ctg chứa các mẫu Xt, nhãn tương ứng Yt, và các lớp cụ thể của nhiệm vụ Ct. Các nhiệm vụ khác nhau không có sự chồng chéo trong các lớp. Mạng nơ-ron được tạo thành từ một bộ trích xuất đặc trưng z=h(x;θ) và một bộ phân loại dựa trên proxy f(z;W) = ⟨z;Wi⟩/τ [18], trong đó W chứa các proxy có thể huấn luyện của tất cả các lớp, ⟨;⟩ là độ tương tự cosine, và τ là một hệ số tỷ lệ. Tất cả các lớp đã học được ký hiệu là C1:t=∪tk=1Ck. Xác suất phân loại mà mẫu x thuộc về lớp c là:

pc=e^(⟨h(x;θ);wc⟩/τ) / Σj∈C1:t e^(⟨h(x;θ);wj⟩/τ)     (1)

Trong quá trình huấn luyện, mô hình chỉ có thể truy cập Dt và mỗi mẫu chỉ có thể được thấy một lần. Hàm mục tiêu của nó là:

L=E(x;y)∼Dt[-log(e^(⟨h(x;θ);wy⟩/τ) / Σj∈C1:t e^(⟨h(x;θ);wj⟩/τ))]     (2)

3.2. Phân tích Quên Thảm khốc
Một nguyên nhân trực tiếp của CF là sự lan truyền gradient không cân bằng giữa các lớp cũ và mới. Gradient cho một mẫu đơn x có thể được biểu diễn như:

∂L/∂W = {
h(x;θ)(py-1); i=y
h(x;θ)(pc); c≠y     (3)

Như Phương trình (3) cho thấy, nếu một mẫu huấn luyện x thuộc về lớp y, nó không chỉ tăng giá trị logits của chiều thứ y bằng py-1<0, mà còn giảm giá trị logits của chiều khác bằng pc>0. Kết hợp với quy tắc chuỗi, nó cung cấp gradient dương cho proxy của lớp y như wy=wy-αh(x;θ)(py-1), và lan truyền gradient âm đến các proxy khác như wc=wc-αh(x;θ)(pc).

Vì α là tốc độ học dương và h(x;θ) thường không âm bởi Relu [29]. Hơn nữa, gradient được chuyển đến bộ trích xuất đặc trưng, khiến nó tập trung vào các đặc trưng có thể phân biệt lớp này với các lớp khác.

Khi tối ưu hóa trực tiếp Phương trình (2), được gọi là Finetune, việc học các lớp mới chiếm ưu thế trong việc lan truyền gradient, gây ra hiện tượng CF. Để phân tích tốt hơn, chúng tôi cho thấy một trường hợp học các mẫu của mèo và chó ở nhiệm vụ đầu tiên (Hình 2(a)), và sau đó học các mẫu của tàu và máy bay ở nhiệm vụ tiếp theo (Hình 2(b)-(f)).

Như thấy ở phần bên trái của Hình 2(b), gradient được tạo ra bởi việc học các lớp mới. Kết quả là, các proxy của lớp mới nhận được nhiều gradient dương hơn (↑) và những lớp khác nhận được nhiều gradient âm hơn (↓). Được thể hiện như các mũi tên đỏ ở phần bên trái của Hình 2(b), nó khiến các proxy của lớp mới gần với các mẫu của lớp mới, trong khi các proxy của lớp cũ xa chúng. Đồng thời, bộ trích xuất đặc trưng chú ý nhiều hơn đến các đặc trưng của lớp mới. Nó khiến các mẫu của lớp mới và cũ gần nhau [6] trong không gian nhúng đơn vị. Do đó, dễ dàng phân loại các mẫu thành lớp mới.

3.3. Phân tích Cách Dựa trên Proxy
ER [30] phân bổ một bộ đệm bộ nhớ M để tạm thời lưu trữ một phần các mẫu trước đây của các lớp cũ, được huấn luyện lại với các mẫu hiện tại. Và hàm mục tiêu của nó là:

LER=E(x;y)∼Dt∪M[-log(e^(⟨h(x;θ);wy⟩/τ) / Σj∈C1:t e^(⟨h(x;θ);wj⟩/τ))]     (4)

trong đó các mẫu của tất cả các lớp thực hiện cùng một cách để tính toán xác suất phân loại. Như mô tả trong Hình 2(c), các mẫu trước đây của lớp cũ có được một số lợi thế trong việc lan truyền gradient. Không chỉ các proxy của lớp cũ nhận được nhiều gradient dương hơn, mà các proxy của lớp mới cũng nhận được nhiều gradient âm hơn. Mặc dù hiện tượng CF có thể được giảm thiểu ở một mức độ nào đó, hiệu quả của nó vẫn còn hạn chế. Vì số lượng mẫu cho mỗi lớp trong bộ đệm cố định sẽ giảm khi quá trình học diễn ra, gradient của lớp cũ là không đủ.

SS-IL [1] tính toán riêng biệt xác suất phân loại cho lớp cũ và mới bằng softmax tách biệt như:

LSS=E(x;y)∼Dt[-log(e^(⟨h(x;θ);wy⟩/τ) / Σj∈Ct e^(⟨h(x;θ);wj⟩/τ))]
+E(x;y)∼M[-log(e^(⟨h(x;θ);wy⟩/τ) / Σj∈C1:t-1 e^(⟨h(x;θ);wj⟩/τ))]     (5)

Như được chứng minh trong Hình 2(d), nó cắt đứt việc lan truyền từ việc học lớp cũ đến các proxy của lớp mới, và ngăn chặn việc lan truyền từ việc học lớp mới đến các proxy của lớp cũ. Nó có thể tránh gradient của lớp mới ảnh hưởng đến các proxy của lớp cũ. Tuy nhiên, mô hình không thể phân biệt tốt lớp mới với lớp cũ, vì việc thiếu gradient khiến mô hình khó phân loại các lớp qua các nhiệm vụ.

ER-ACE [6] cũng được đề xuất để giải quyết cùng vấn đề bằng hàm mất mát entropy chéo bất đối xứng, được biểu diễn như:

LACE=E(x;y)∼Dt[-log(e^(⟨h(x;θ);wy⟩/τ) / Σj∈Ct e^(⟨h(x;θ);wj⟩/τ))]
+E(x;y)∼M[-log(e^(⟨h(x;θ);wy⟩/τ) / Σj∈C1:t e^(⟨h(x;θ);wj⟩/τ))]     (6)

Xác suất phân loại lớp mới của nó tương tự với SS-IL, và xác suất phân loại lớp cũ giống như ER. Chi tiết, nó chỉ chọn một phần các cặp neo-tới-proxy cho việc học lớp mới. Như thể hiện trong Hình 2(e), nó chỉ phá vỡ việc lan truyền gradient từ việc học lớp mới đến các proxy của lớp cũ. Giữ gradient từ việc học lớp cũ đến các proxy của lớp mới giúp tránh tình huống không thể tách biệt của SS-IL. Mặc dù nó có lợi cho lớp cũ, hiệu suất trên lớp mới bị ảnh hưởng.

3.4. Phân tích Cách Dựa trên Tương phản
SCR [26] được đề xuất như một lựa chọn thay thế tốt cho online CICL bằng hàm mất mát dựa trên tương phản, được ký hiệu như:

LSCR=E(x;y)∼Dt∪M[1/|P(x)| Σp∈P(x) -log(e^(⟨h(x;θ);h(xp;θ)⟩/T) / Σj∈J(x) e^(⟨h(x;θ);h(xj;θ)⟩/T))]     (7)

Nó ghép các mẫu hiện tại và mẫu trước đây vào cùng một lô và tính toán độ tương tự của các cặp neo-tới-mẫu. J(x) là tập chỉ số của các mẫu ngoại trừ neo x trong cùng lô, trong khi P(x) ký hiệu tập hợp các mẫu có cùng nhãn với neo x. Khác với hàm mất mát dựa trên proxy, các cặp được chọn không phụ thuộc vào số lượng lớp, mà liên quan đến số lượng mẫu trong một lô huấn luyện. Do đó, hiệu quả của nó bị ràng buộc bởi kích thước bộ đệm bộ nhớ và kích thước lô. Và hiệu suất của nó sẽ không thỏa đáng khi có ít mẫu để phát lại.

4. Phương pháp luận
4.1. Động lực
Từ phân tích trên, chúng ta có thể rút ra ba kết luận. Đầu tiên và quan trọng nhất, việc lan truyền gradient không cân bằng giữa lớp mới và lớp cũ là nguyên nhân chính của CF. Các lớp mới chiếm ưu thế trong quá trình này, khiến các mẫu của lớp mới có thể phân biệt cao nhưng những mẫu của lớp cũ không thể phân chia. Việc kiểm soát hiệu quả việc lan truyền gradient giữa lớp cũ và mới có thể giúp mô hình giảm thiểu vấn đề quên. Thứ hai, các phương pháp dựa trên proxy hiện có kiểm soát việc lan truyền gradient bằng cách chọn một phần các cặp neo-tới-proxy để tính toán hàm mục tiêu. Mặc dù chúng hiệu quả, chúng dễ dàng làm tổn hại khả năng tổng quát hóa của mô hình để học lớp mới. Cuối cùng, cách dựa trên tương phản phụ thuộc vào các mẫu từ cùng lô nhưng thiếu sự hỗ trợ của proxy. Việc lựa chọn các cặp neo-tới-mẫu của nó cung cấp một cách heuristic để chọn các cặp neo-tới-proxy.

Dựa trên những kết luận này, chúng tôi thấy rằng việc kết hợp hai cách này sẽ dẫn đến một giải pháp tốt hơn. Để tránh giới hạn do kích thước mẫu gây ra, chúng tôi không sử dụng phương pháp kết hợp trong [38], thêm các cặp neo-tới-mẫu vào các cặp neo-tới-proxy trong hàm mất mát entropy chéo. Cụ thể, chúng tôi thay thế các mẫu của các cặp neo-tới-mẫu bằng proxy cho trong hàm mất mát dựa trên tương phản, và có được cách của chúng tôi:

Lours=E(x;y)∼Dt∪M[1/|P(x)| Σp∈P(x) -log(e^(⟨h(x;θ);wp⟩/T) / Σj∈J(x) e^(⟨h(x;θ);wj⟩/T))]     (8)

Khác với các nghiên cứu hiện có, cách tính toán xác suất phân loại của nó được thay đổi cho mỗi mini-batch. Một mặt, hàm mất mát như vậy có tốc độ hội tụ nhanh hơn và tính mạnh mẽ tốt hơn, và có thể đối phó với số lượng mẫu nhỏ với sự hỗ trợ của proxy. Mặt khác, các proxy thay thế chỉ từ các lớp xuất hiện trong lô huấn luyện. Kết quả là, gradient để lan truyền chỉ từ việc học của những lớp này. Như thể hiện trong Hình 2(f), gradient giữa tất cả các proxy không hoàn toàn tách biệt trong toàn bộ quá trình huấn luyện. Việc lan truyền gradient chỉ xảy ra khi các lớp tương ứng xuất hiện trong cùng lô. Đồng thời, trong mỗi bước học, chỉ lớp mới và cũ trong lô hiện tại tham gia vào việc lan truyền gradient. Các proxy của lớp cũ, bị ảnh hưởng bởi gradient âm của lớp mới, cũng có thể tạo ra gradient dương để đối kháng và tiếp tục giảm thiểu vấn đề quên. Do đó, các mẫu của tất cả các lớp có thể được nhận ra chính xác hơn so với các phương pháp hiện có.

4.2. Phát lại Tương phản Dựa trên Proxy
Với những cảm hứng này, chúng tôi đề xuất một khung phát lại tương phản dựa trên proxy (PCR) mới, và các chi tiết kỹ thuật sẽ được trình bày trong phần này. Khung bao gồm một backbone dựa trên CNN h(x;θ) và một bộ phân loại dựa trên proxy f(z;W). Toàn bộ thủ tục huấn luyện và suy luận của PCR được tóm tắt trong Thuật toán 1.

4.2.1 Thủ tục Huấn luyện của PCR
Trong phần này, mô hình được huấn luyện bằng cách học các mẫu của lớp mới và phát lại các mẫu của lớp cũ. Đối với mỗi nhiệm vụ, với các mẫu hiện tại (xc;yc), nó ngẫu nhiên truy xuất các mẫu trước đây (xM;yM) từ bộ đệm bộ nhớ (dòng 1-4). Bên cạnh đó, những mẫu gốc này và các mẫu tăng cường của chúng được ghép lại với nhau cho lô huấn luyện (dòng 5-7). Sau đó, mô hình được tối ưu hóa bởi lô huấn luyện này (dòng 8-9). Hàm mục tiêu được định nghĩa như:

LPCR=E(x;y)∼Dt∪M[-log(e^(⟨h(x;θ);wy⟩/τ) / Σj∈CB e^(⟨h(x;θ);wj⟩/τ))]     (9)

trong đó CB là các chỉ số lớp trong lô huấn luyện hiện tại, và các chỉ số có thể được lặp lại. Cuối cùng, nó cập nhật bộ đệm bộ nhớ bằng chiến lược lấy mẫu hồ chứa, có thể đảm bảo rằng xác suất mỗi mẫu được trích xuất là bằng nhau. Thuận tiện, bộ đệm bộ nhớ trong khung của chúng tôi có kích thước cố định, bất kể lượng mẫu lớn như thế nào.

Thuật toán 1 Phát lại Tương phản Dựa trên Proxy
Đầu vào: Bộ dữ liệu D, Tốc độ học α, Hệ số tỷ lệ τ
Đầu ra: Tham số mạng θ
Khởi tạo: Bộ đệm bộ nhớ M ← {}, Tham số mạng θ = {θ;W}
1: for t ∈ {1;2;...;T} do
2:    // Thủ tục huấn luyện
3:    for mini-batch (xc;yc) ∼ Dt do
4:        (xM;yM) ← RandomRetrieval(M).
5:        (xori;yori) ← Concat([(xc;yc);(xM;yM)]).
6:        (xaug;yaug) ← DataAugmentation(xori;yori).
7:        (x;y) ← Concat([(xori;yori);(xaug;yaug)]).
8:        L = -log(e^(⟨h(x;θ);wy⟩/τ) / Σj∈CB e^(⟨h(x;θ);wj⟩/τ))
9:        θ ← θ + ∇θL.
10:       M ← ReservoirUpdate(M;(xt;yt)).
11:   end for
12:   // Thủ tục suy luận
13:   for k ∈ {1;2;...;m} do
14:       ŷk = arg max_c e^(⟨h(xk;θ);wc⟩/τ) / Σj∈C1:t e^(⟨h(xk;θ);wj⟩/τ); c ∈ C1:t
15:   end for
16:   return θ
17: end for

4.2.2 Thủ tục Suy luận của PCR
Thủ tục suy luận (dòng 13-15) khác với thủ tục huấn luyện. Mỗi mẫu kiểm tra xk có được phân phối xác suất lớp của nó bằng Phương trình (1). Và chúng tôi thực hiện dự đoán suy luận đối với xk với xác suất cao nhất như:

ŷk = arg max_c e^(⟨h(xk;θ);wc⟩/τ) / Σj∈C1:t e^(⟨h(xk;θ);wj⟩/τ); c ∈ C1:t     (10)

5. Đánh giá Hiệu suất
5.1. Thiết lập Thí nghiệm
5.1.1 Bộ dữ liệu
Chúng tôi tiến hành thí nghiệm trên ba bộ dữ liệu hình ảnh thực tế để đánh giá. Split CIFAR10 [21] được chia thành 5 nhiệm vụ, và mỗi nhiệm vụ chứa 2 lớp. Split CIFAR100 [21] cũng như Split MiniImageNet [35] được tổ chức thành 10 nhiệm vụ, và mỗi nhiệm vụ được tạo thành từ các mẫu của 10 lớp.

5.1.2 Các Baseline Được Đánh giá
Để đánh giá hiệu quả của PCR, chúng tôi so sánh nó với bốn danh mục phương pháp sau. Các hoạt động không phát lại chứa IID và FINE-TUNE. Các chiến lược cập nhật bộ nhớ bao gồm ER [30], GSS [3], và GMED [19]. MIR [2] và ASER [32] là các chiến lược truy xuất bộ nhớ. Và các chiến lược cập nhật mô hình chứa A-GEM [9], ER-WA [40], DER++ [4], SS-IL [1], SCR [26], ER-ACE [6], ER-DVC [15], và OCM [16].

[Tiếp tục với phần còn lại của bản dịch...]

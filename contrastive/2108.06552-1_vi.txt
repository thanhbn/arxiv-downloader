# 2108.06552.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/contrastive/2108.06552.pdf
# Kích thước tệp: 850833 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
1
Pattern Recognition Letters
trang chủ tạp chí: www.elsevier.com
Học Liên Tục Bán Giám Sát thông qua Tính Nhất Quán Nội Suy Đối Lập
Matteo Boschinia, Pietro Buzzegaa, Lorenzo Bonicellia,, Angelo Porrelloa, Simone Calderaraa
aĐại học Modena và Reggio Emilia, Via Vivarelli 10, Modena, Italy
Lịch sử bài viết:
Học liên tục, học sâu,
học bán giám sát, giám sát yếu,
quên lãng thảm khốcTÓM TẮT
Học Liên Tục (CL) nghiên cứu cách huấn luyện Mạng Sâu trên một luồng
các nhiệm vụ mà không gặp phải tình trạng quên lãng. Các thiết lập CL được
đề xuất trong tài liệu giả định rằng mọi ví dụ đến đều được ghép nối với các
chú thích thông tin cơ bản. Tuy nhiên, điều này đi ngược lại nhiều ứng dụng
thực tế: việc thu thập dữ liệu có nhãn, vốn đã tẻ nhạt và tốn kém, trở nên
không khả thi khi dữ liệu chảy như một luồng. Công trình này khám phá Học
Liên Tục Bán Giám Sát (CSSL): ở đây, chỉ một phần nhỏ các ví dụ đầu vào
có nhãn được hiển thị cho người học. Chúng tôi đánh giá cách các phương pháp
CL hiện tại (ví dụ: EWC, LwF, iCaRL, ER, GDumb, DER) hoạt động trong
kịch bản mới và thách thức này, nơi việc quá khớp vướng víu với quên lãng.
Tiếp theo, chúng tôi thiết kế một phương pháp CSSL mới khai thác học metric
và chính quy hóa tính nhất quán để tận dụng các ví dụ không nhãn trong khi
học. Chúng tôi cho thấy rằng đề xuất của chúng tôi thể hiện khả năng phục hồi
cao hơn với việc giám sát giảm dần và, thậm chí còn đáng ngạc nhiên hơn,
chỉ dựa vào 25% giám sát đã đủ để vượt trội hơn các phương pháp SOTA được
huấn luyện dưới giám sát đầy đủ.
©2022 Elsevier Ltd. Tất cả quyền được bảo lưu.

1. Giới thiệu
Thông tin nhận thức chảy như một luồng liên tục,
trong đó một phân phối dữ liệu nhất định có thể xảy ra
một lần và không tái diễn trong thời gian dài. Thật không
may, điều này vi phạm giả định i.i.d. ở nền tảng của hầu
hết các thuật toán Học Sâu và dẫn đến vấn đề quên lãng
thảm khốc [1], nơi kiến thức đã có được nhanh chóng bị
ghi đè bởi kiến thức mới. Trong các kịch bản thực tế,
chúng ta sẽ thích một hệ thống học tăng dần từ luồng dữ
liệu thô và không i.i.d., có thể sẵn sàng cung cấp câu trả
lời bất cứ lúc nào. Việc thiết kế các thuật toán học suốt
đời như vậy là mục tiêu của Học Liên Tục (CL) [2].
Các công trình trong lĩnh vực này thường kiểm tra
các phương pháp được đề xuất trên một loạt các nhiệm
vụ phân loại hình ảnh được trình bày tuần tự. Những
nhiệm vụ sau được xây dựng dựa trên các bộ dữ liệu
phân loại hình ảnh (ví dụ: MNIST, CIFAR, v.v.) bằng
cách cho phép người học chỉ thấy một tập con các lớp
cùng một lúc. Trong khi các giao thức thực nghiệm này
một cách hợp lệ làm nổi bật các hiệu ứng của quên lãng,
chúng giả định rằng tất cả dữ liệu đến đều có nhãn.
Trong một số kịch bản, điều kiện này không đại diện
cho một vấn đề và có thể dễ dàng được đáp ứng. Đây có
thể là trường hợp khi các chú thích thông tin cơ bản có
thể được thu thập trực tiếp và tự động (ví dụ: một robot
khám phá môi trường và học cách tránh va chạm bằng
cách nhận phản hồi trực tiếp từ nó [3]). Tuy nhiên, khi
giai đoạn gắn nhãn liên quan đến sự can thiệp của con
người (như có trong một số nhiệm vụ thị giác máy tính
như phân loại, phát hiện đối tượng [4], v.v.), việc chỉ
dựa vào giám sát đầy đủ đi ngược lại với việc theo đuổi
học suốt đời. Thật vậy, khả năng thích ứng của người
học với các nhiệm vụ đến sẽ bị nghẽn cổ chai bởi tốc độ
của người gắn nhãn: việc cập nhật mô hình liên tục sẽ
mất đi sức hấp dẫn so với giải pháp tầm thường là huấn
luyện lại từ đầu. Do đó, chúng tôi ủng hộ việc tính đến
tốc độ mà các chú thích có sẵn cho người học.
Để giải quyết điểm này, việc điều chỉnh mô hình dự
đoán có thể được giới hạn đơn giản ở phần các ví dụ có
thể được gắn nhãn trong thời gian thực. Các thí nghiệm
của chúng tôi cho thấy điều này dẫn đến sự suy giảm dự
kiến về hiệu suất. May mắn thay, những nỗ lực gần đây
được thực hiện trong học bán giám sát [5, 6] đến để giải
cứu: bằng cách xem xét lại các kỹ thuật này trong một
kịch bản tăng dần, chúng ta vẫn có thể hưởng lợi từ phần
còn lại của dữ liệu được đại diện bởi các quan sát không
nhãn. Chúng tôi lập luận rằng điều này đúng với bản
chất suốt đời của ứng dụng và cũng cho phép khai thác
nguồn thông tin phong phú được cung cấp bởi dữ liệu
không nhãn. Tóm lại, công trình của chúng tôi kết hợp
các tính năng được mô tả ở trên trong một thiết lập mới
được gọi là Học Liên Tục Bán Giám Sát (CSSL): một
kịch bản trong đó chỉ một trong k ví dụ được trình bày
với nhãn thông tin cơ bản của nó. Tại thời điểm huấn
luyện, điều này tương ứng với việc cung cấp nhãn thông
tin cơ bản cho bất kỳ ví dụ nào với xác suất đồng nhất
1/k (như được hiển thị trong Hình 1 với k = 2).
Tiến thêm một bước, đề xuất của chúng tôi nhằm lấp
đầy khoảng trống do chú thích một phần gây ra: Tính
Nhất Quán Nội Suy Liên Tục Đối Lập (CCIC), áp đặt
tính nhất quán giữa các ví dụ được tăng cường và nội
suy trong khi khai thác thông tin tay thứ hai đặc trưng
cho thiết lập Tăng-Lớp. Bằng cách làm như vậy, chúng
tôi cấp hiệu suất phù hợp và thậm chí vượt qua thiết lập
giám sát đầy đủ. Cuối cùng chúng tôi tóm tắt các đóng
góp của mình:
• Chúng tôi đề xuất CSSL: một kịch bản trong đó
người học phải học liên tục bằng cách khai thác cả
dữ liệu có giám sát và không giám sát cùng một lúc;
• Chúng tôi đánh giá thực nghiệm hiệu suất của các
mô hình CL SOTA ở các tỷ lệ nhãn-mỗi-ví dụ khác
nhau, làm nổi bật những khác biệt tinh tế giữa CL
và CSSL;
• Khai thác các kỹ thuật bán giám sát, chúng tôi giới
thiệu một phương pháp CSSL mới thành công giải
quyết thiết lập mới và học với nhãn hạn chế;
• Đáng ngạc nhiên, các đánh giá của chúng tôi cho
thấy rằng giám sát đầy đủ không nhất thiết là giới
hạn trên của giám sát một phần trong CL: 25% nhãn
có thể đủ để vượt trội hơn các phương pháp SOTA
sử dụng tất cả thông tin cơ bản.

2. Công trình liên quan
2.1. Giao thức Học Liên Tục
Học Liên Tục là một thuật ngữ bao trùm bao gồm
một số thiết lập thực nghiệm khác nhau một cách nhẹ
nhưng có ý nghĩa [7, 8]. Van de Ven và cộng sự đã tạo
ra một phân loại [8] mô tả ba kịch bản nổi tiếng sau đây.
Học Tăng-Nhiệm vụ (Task-IL) tổ chức bộ dữ liệu thành
các nhiệm vụ bao gồm các tập hợp lớp không giao nhau.
Mô hình chỉ phải học (và nhớ) cách phân loại chính xác
các ví dụ trong các nhiệm vụ ban đầu của chúng. Học
Tăng-Miền (Domain-IL) trình bày tất cả các lớp từ nhiệm
vụ đầu tiên: các nhiệm vụ riêng biệt được thu được bằng
cách xử lý các ví dụ với các phép biến đổi riêng biệt (ví
dụ: hoán vị pixel hoặc xoay hình ảnh) thay đổi phân phối
đầu vào. Học Tăng-Lớp (Class-IL) hoạt động trên cùng
các giả định như Task-IL, nhưng yêu cầu người học phân
loại một ví dụ từ bất kỳ lớp nào đã thấy trước đó mà
không có gợi ý về nhiệm vụ ban đầu của nó. Không giống
như Task-IL, điều này có nghĩa là mô hình phải học phân
phối kết hợp từ các quan sát một phần, làm cho đây là
kịch bản khó nhất [8]. Vì lý do như vậy, chúng tôi tập
trung vào nhãn hạn chế trong công thức Class-IL.
Hướng tới các thiết lập thực tế. Một số công trình gần
đây chỉ ra rằng những thiết lập cổ điển này thiếu tính
thực tế [9] và do đó xác định các kịch bản mới bằng cách
áp đặt hạn chế về những gì mô hình được phép làm trong
khi học. Học Liên Tục Trực tuyến cấm nhiều epoch trên
dữ liệu huấn luyện với lý do rằng các hệ thống CL thực
tế sẽ không bao giờ thấy cùng một đầu vào hai lần [10,
11, 12]. Học Không-Nhiệm vụ không cung cấp danh tính
nhiệm vụ ở thời điểm suy luận hoặc thời điểm huấn luyện
[9]. Điều này trái ngược với các thiết lập cổ điển báo hiệu
ranh giới nhiệm vụ cho người học trong khi huấn luyện,
do đó cho phép nó chuẩn bị cho sự bắt đầu của một nhiệm
vụ mới.
Công trình này cũng nhằm cung cấp một thiết lập thực
tế hơn: thay vì tập trung vào các hạn chế của mô hình,
chúng tôi thừa nhận rằng yêu cầu dữ liệu được gắn nhãn
đầy đủ có thể cản trở việc mở rộng các thuật toán CL
sang các kịch bản thời gian thực và trong tự nhiên.
Học Liên Tục với Dữ liệu Không Giám sát. Một số nỗ
lực gần đây đã được thực hiện để cải thiện các phương
pháp CL bằng cách khai thác dữ liệu không nhãn. Zhang
và cộng sự đã đề xuất khung Hợp nhất Mô hình Sâu [13];
trong đó, một mô hình mới trước tiên được chuyên môn
hóa cho mỗi nhiệm vụ mới gặp phải, sau đó một người
học thống nhất được tạo ra bằng cách chưng cất kiến
thức từ cả chuyên gia mới và mô hình tăng dần trước đó.
Thay vào đó, Lechat và cộng sự đã giới thiệu Học Tăng
dần Bán Giám sát [14], xen kẽ học đặc trưng không giám
sát trên cả dữ liệu đầu vào và phụ trợ với phân loại có
giám sát.
Chúng tôi nhấn mạnh rằng cả hai thiết lập này đều
khác biệt đáng kể so với CSSL được đề xuất của chúng
tôi vì chúng tôi không tách biệt các giai đoạn huấn luyện
có giám sát và không giám sát. Ngược lại, chúng tôi đan
xen cả hai loại dữ liệu trong tất cả các batch được rút
ra theo tỷ lệ khác nhau và yêu cầu mô hình học từ cả
hai cùng một lúc. Ngoài ra, chúng tôi không khai thác
dữ liệu bên ngoài không giám sát phụ trợ để bổ sung
cho tập huấn luyện; thay vào đó, chúng tôi giảm dữ liệu
có giám sát ban đầu xuống một phần, do đó mô hình
hóa việc giám sát trở nên có sẵn trên luồng đầu vào với
tốc độ chậm hơn nhiều.

2.2. Phương pháp Học Liên Tục
Các phương pháp Học Liên Tục đã được phân loại
chủ yếu thành ba họ [7, 2].
Phương pháp Kiến trúc sử dụng các kiến trúc được thiết
kế riêng trong đó số lượng tham số tăng động [15, 16]
hoặc một phần của chúng được dành riêng cho một nhiệm
vụ riêng biệt [17]. Mặc dù thường rất hiệu quả, chúng
phụ thuộc vào tính khả dụng của nhãn nhiệm vụ tại thời
điểm dự đoán để chuẩn bị mô hình cho suy luận, điều
này giới hạn chúng ở Task-IL.
Phương pháp Chính quy hóa điều kiện sự tiến hóa của
mô hình để ngăn nó quên các nhiệm vụ trước đó. Điều
này đạt được bằng cách xác định các trọng số quan trọng
cho mỗi nhiệm vụ và ngăn chúng thay đổi trong những
nhiệm vụ sau này [18, 19] hoặc bằng cách chưng cất kiến
thức từ các ảnh chụp mô hình trước đó để bảo tồn các
phản hồi trong quá khứ [20, 21].
Phương pháp Rehearsal duy trì một bộ nhớ làm việc có
kích thước cố định của các exemplar đã gặp trước đó và
gọi lại chúng để ngăn quên lãng [22]. Giải pháp đơn giản
này đã được mở rộng theo nhiều cách, ví dụ bằng cách
áp dụng các chính sách quản lý bộ nhớ tiên tiến [9, 23],
khai thác các thuật toán meta-learning [11], kết hợp
replay với chưng cất kiến thức [24, 25], hoặc sử dụng
bộ nhớ để huấn luyện mô hình theo cách offline [26].

2.3. Học Bán Giám sát
Học Bán Giám sát nghiên cứu cách cải thiện các phương
pháp học có giám sát bằng cách tận dụng dữ liệu không
nhãn bổ sung. Chúng ta khai thác những dữ liệu sau
này theo các giả định cụ thể về cách đầu vào và nhãn
tương tác [5]. Bằng cách giả định rằng các điểm dữ liệu
đầu vào gần nhau nên tương ứng với các đầu ra tương
tự, chính quy hóa tính nhất quán khuyến khích mô hình
tạo ra các dự đoán nhất quán cho cùng một điểm dữ
liệu. Nguyên tắc này có thể được áp dụng bằng cách so
sánh các dự đoán trên cùng một exemplar bởi các người
học khác nhau [27, 6] hoặc các dự đoán trên các tăng
cường khác nhau của cùng một điểm dữ liệu bởi cùng
một người học [28].
Gần đây, một số công trình đã nghiên cứu việc tinh
chỉnh chính quy hóa như vậy thông qua huấn luyện đối
kháng, tạo ra các nhiễu loạn thách thức hơn [29] hoặc
các mẫu không giám sát bổ sung cho mục đích chính quy
hóa [30].
Đề xuất của chúng tôi, mà chúng tôi giới thiệu trong
Mục 4.2, kết hợp chính quy hóa tính nhất quán trong
nhiệm vụ với chiến lược kép là tối đa hóa sự khác biệt
đặc trưng giữa các nhiệm vụ. Điều sau này củng cố học
biểu diễn sâu theo cấu trúc cấp cao của vấn đề mục tiêu
- cụ thể, sự không giao nhau lớp giữa các nhiệm vụ. Điều
này có thể được xem như một dạng Biểu diễn Đa Kiến
thức [31] thông qua việc áp dụng kiến thức mô tả; mặt
khác, đề xuất của chúng tôi vẫn mở cho việc làm giàu
thêm nếu có kiến thức bổ sung về nhiệm vụ mục tiêu
[32].

3. Học Liên Tục Bán Giám sát
Một vấn đề phân loại Học Liên Tục có giám sát có thể
được định nghĩa như một chuỗi S gồm T nhiệm vụ. Trong
mỗi nhiệm vụ sau (S = t ∈ {1, ..., T}), các mẫu đầu
vào x và nhãn thông tin cơ bản tương ứng y được rút
ra từ một phân phối i.i.d. Dt. Xem xét một hàm fθ với
tham số θ, chúng ta ký hiệu các phản hồi (logits) của
nó với hθ(x) và phân phối xác suất tương ứng trên các
lớp với fθ(x) ≜ softmax(hθ(x)). Mục tiêu là tìm giá trị
tối ưu cho các tham số sao cho fθ hoạt động tốt nhất
trung bình trên tất cả các nhiệm vụ mà không gặp phải
quên lãng thảm khốc; một cách chính thức, chúng ta cần
tối thiểu hóa rủi ro thực nghiệm trên tất cả các nhiệm vụ:

argmin_θ Σ_{t=1}^{tc} Lt, trong đó Lt ≜ E_{(x,y)∼Dt}[ℓ(y, fθ(x))]

Trong Học Liên Tục Bán Giám sát, chúng tôi đề xuất
phân phối các mẫu đến từ Dt thành hai tập: D^s_t, chứa
một lượng hạn chế các cặp mẫu có nhãn và nhãn thông
tin cơ bản của chúng (x^s, y^s) và D^u_t, chứa phần còn
lại của các mẫu không giám sát. Chúng tôi định nghĩa
sự phân chia này theo một tỷ lệ cho trước p^s = |D^s_t|
/(|D^s_t| + |D^u_t|) vẫn cố định trên tất cả các nhiệm
vụ. Mục tiêu của CSSL là tối ưu hóa Phương trình 1 mà
không có quyền truy cập vào tín hiệu giám sát thông tin
cơ bản cho D^u_t. Dữ liệu từ luồng bao gồm các cặp có
nhãn S ∪ D^s_t và các mục không nhãn U ∪ D^u_t.
Chúng tôi quan tâm đến việc làm sáng tỏ thêm các mô
hình CL bằng cách hiểu i) chúng hoạt động như thế nào
dưới sự thiếu hụt giám sát một phần và ii) các phương
pháp Học Bán Giám sát có thể được kết hợp với chúng
như thế nào để khai thác dữ liệu không giám sát. Câu
hỏi i) được điều tra thực nghiệm trong Mục 5.1 và 5.2
bằng cách đánh giá các phương pháp đơn giản loại bỏ
các ví dụ không nhãn x^u. Khác biệt, câu hỏi ii) mở ra
nhiều giải pháp có thể mà chúng tôi giải quyết bằng cách
đề xuất Tính Nhất Quán Nội Suy Liên Tục Đối Lập
(CCIC).

4. Phương pháp
Chúng tôi xây dựng đề xuất của mình dựa trên hai
phương pháp tiên tiến: một mặt, chúng tôi tận dụng
Experience Replay (ER) [22, 11] để giảm thiểu quên
lãng thảm khốc; mặt khác, chúng tôi khai thác MixMatch
[28] để học các biểu diễn hữu ích cũng từ các ví dụ không
nhãn. Trong phần sau: i) để giúp người đọc, chúng tôi
tóm tắt ngắn gọn các đặc điểm chính của các thuật toán
này (và để các bài báo gốc cung cấp hiểu biết sâu hơn);
ii) chúng tôi thảo luận về cách hai phương pháp trước
đây này có thể được bổ sung thuận lợi.

4.1. Nền tảng kỹ thuật
Như một bước đầu tiên, chúng tôi trang bị cho người
học một bộ đệm bộ nhớ nhỏ M (dựa trên reservoir
sampling) và xen kẽ một batch các ví dụ được rút ra từ
nó với mỗi batch của nhiệm vụ hiện tại. Trong số tất cả
các phương pháp có thể, chúng tôi chọn ER do thiết kế
nhẹ và hiệu quả của nó [11, 23].
Khi xử lý thiếu giám sát, tự huấn luyện đại diện cho
một chiến lược tầm thường: ở đây, chính mô hình tạo
ra các mục tiêu (pseudo-labels) cho các ví dụ không
nhãn [33, 34]. Thật không may, điều này có xu hướng
trở nên không ổn định với chỉ một vài chú thích có sẵn:
như được hiển thị trong các thí nghiệm của chúng tôi,
điều này khuyến khích mô hình quá khớp dữ liệu có
giám sát hạn chế có sẵn [35].
Vấn đề như vậy đặt ra nhu cầu về một mục tiêu khác,
điều sau này độc lập với độ chính xác của mô hình trên
các ví dụ không nhãn. Do đó, chúng tôi bổ sung đề xuất
của mình với MixMatch [28]: các dự đoán của mạng
không nhằm mục đích làm mục tiêu huấn luyện, mà là
phương tiện để áp dụng chính quy hóa tính nhất quán
[6, 29]. Tóm tắt, một soft-label được gán cho mỗi phần
tử không giám sát bằng cách tính trung bình và sau đó
làm sắc nét các dự đoán pre-softmax của một số tăng
cường khác nhau.
Để thúc đẩy các phản hồi nhất quán với những biến
đổi đáng kể của các điểm dữ liệu, các mẫu có nhãn và
không nhãn được kết hợp thông qua thủ tục mixUp [36].
Bắt đầu từ các tập ban đầu S và U (tương ứng, các ví
dụ có nhãn và không nhãn từ batch hiện tại), do đó
chúng ta thu được hai tập cuối cùng được tăng cường
và trộn của các ví dụ S' và U': để tính toán các số hạng
mất mát LS và LU, chúng tôi sử dụng nhãn thông tin
cơ bản cho các ví dụ của tập trước và các soft-labels
được tạo thông qua averaging-response cho những ví
dụ của tập sau.

4.2. Tính Nhất Quán Nội Suy Liên Tục Đối Lập
Giả sử rằng ranh giới giữa các nhiệm vụ được cung
cấp, chúng ta có thể liên kết các exemplar trong bộ nhớ
với nhiệm vụ mà chúng đến từ đó. Trong phần sau,
chúng tôi thảo luận về cách điều này cho phép một
dạng giám sát yếu bổ sung cho các ví dụ không giám
sát ngay cả khi chúng ta không biết chính xác các lớp
của chúng.
Khai thác không giám sát. Vì các nhiệm vụ không giao
nhau, các ví dụ từ các nhiệm vụ khác nhau nhất thiết
thuộc về các lớp khác nhau: chúng tôi tính đến điều đó
bằng cách thêm một số hạng mất mát đối lập, đẩy các
phản hồi của chúng ra xa nhau (Hình 2). Chi tiết, chúng
tôi muốn tối đa hóa khoảng cách Euclidean D(x, x') ≜
||hθ(x) - hθ(x')||²₂ giữa các embedding của các ví dụ
từ các nhiệm vụ khác nhau. Do đó, chúng tôi tối thiểu
hóa:

LUM = E_{x∼D^u_{tc}} [max(0, ∑_{x^N∈M_{t<tc}} max(0, μ - D(x, x^N)))]

trong đó tc là chỉ số của nhiệm vụ hiện tại Dtc, M_{t<tc}
chỉ ra các ví dụ trong quá khứ từ bộ đệm bộ nhớ, và μ
là một lề không đổi ngoài đó không cần nỗ lực thêm để
mở rộng khoảng cách giữa các cặp negative.
Khai thác có giám sát. Đối với mỗi ví dụ có nhãn đến,
chúng tôi cũng khuyến khích mạng di chuyển biểu diễn
của nó gần với những biểu diễn thuộc về cùng một lớp.
Chúng tôi tìm kiếm các ứng cử viên positive x^P trong
cả batch hiện tại và bộ đệm bộ nhớ. Theo thuật ngữ
chính thức:

LSM = E_{x∼D^s_{tc}∪M} [relu(D(x, x^N) - D(x, x^P) + μ)]

Mục tiêu tổng thể. Tóm lại, mục tiêu của CCIC kết hợp
số hạng chính quy hóa tính nhất quán được cung cấp
bởi MixMatch với hai số hạng bổ sung (Phương trình 2
và Phương trình 3) được áp dụng trong không gian đặc
trưng; vấn đề tối ưu hóa tổng thể có thể được chính thức
hóa như sau:

argmin L = LS + λLU + αLSM + βLUM

trong đó λ và α, β là các siêu tham số thiết lập tầm quan
trọng của các ví dụ không giám sát.
Khai thác học metric khoảng cách trong suy luận. Sau
khi chúng tôi đã giới thiệu các ràng buộc trong không
gian đặc trưng (Phương trình 2, 3), chúng ta cũng có
thể khai thác chúng bằng cách phát triển một schema
suy luận khác, điều này tiếp tục đóng góp để giảm nhẹ
quên lãng. Tương tự như [24], chúng tôi sử dụng thuật
toán k-Nearest Neighbors như bộ phân loại cuối cùng,
do đó tách biệt phân loại khỏi trích xuất đặc trưng. Điều
này đã được chứng minh là có lợi trong Học Liên Tục,
vì nó cứu lớp fully-connected cuối cùng khỏi việc liên
tục theo kịp các đặc trưng thay đổi (và ngược lại). Vì
kNN là phi tham số và chỉ xây dựng dựa trên không
gian đặc trưng, nó phù hợp hài hòa với phần còn lại
của mô hình, kiểm soát thiệt hại gây ra bởi quên lãng
thảm khốc. Chúng tôi fit bộ phân loại kNN sử dụng các
ví dụ của bộ đệm bộ nhớ như tập huấn luyện.

5. Thí nghiệm
Chúng tôi tiến hành các thí nghiệm trên ba bộ dữ liệu
tiêu chuẩn.
Split SVHN: năm nhiệm vụ nhị phân liên tiếp được xây
dựng dựa trên bộ dữ liệu Street View House Numbers
(SVHN) [37];
Split CIFAR-10: tương đương với phần trước, nhưng
sử dụng bộ dữ liệu CIFAR-10 [38].
Split CIFAR-100: một đánh giá dài hơn và thách thức
hơn trong đó mô hình được trình bày mười nhiệm vụ
liên tiếp, mỗi nhiệm vụ bao gồm 10 lớp từ bộ dữ liệu
CIFAR-100 [38].
Chúng tôi thay đổi tỷ lệ dữ liệu có nhãn được hiển thị
cho mô hình (ps) để bao gồm các mức độ giám sát khác
nhau (0.8%, 5%, 25%, và 100%, tức là 400, 2500, 25000,
và 50000 mẫu cho CIFAR-10/100). Vì công bằng, chúng
tôi giữ cân bằng ban đầu giữa các lớp trong cả tập huấn
luyện và tập kiểm tra; trong sự hiện diện của tỷ lệ thấp,
chúng tôi đảm bảo rằng mỗi lớp được đại diện bởi một
lượng nhãn tỷ lệ.
Kiến trúc. Như trong [39], các thí nghiệm trên Split
SVHN được tiến hành trên một CNN nhỏ, bao gồm ba
lớp ReLU xen kẽ bởi max-pooling. Thay vào đó, chúng
tôi dựa vào ResNet18 cho CIFAR-10 và CIFAR-100,
như được thực hiện trong [25].
Metrics. Chúng tôi báo cáo hiệu suất theo độ chính xác
cuối cùng trung bình, như được thực hiện trong [10, 9].
Độ chính xác được tính trung bình trên 5 lần chạy (chúng
tôi cũng báo cáo độ lệch chuẩn).
Chi tiết triển khai. Như được thảo luận trong Mục 4,
các đề xuất của chúng tôi dựa vào tăng cường dữ liệu
để thúc đẩy chính quy hóa tính nhất quán. Chúng tôi áp
dụng cắt ngẫu nhiên và lật ngang (trừ Split SVHN);
cùng một lựa chọn được áp dụng cho các đối thủ cạnh
tranh để đảm bảo công bằng. Để thực hiện lựa chọn siêu
tham số (tỷ lệ học, kích thước batch, thuật toán tối ưu
hóa, và các hệ số chính quy hóa), chúng tôi thực hiện
tìm kiếm lưới trên tập validation (tương ứng với 10%
của tập huấn luyện), như được thực hiện trong [11, 25,
24]. Đối với CCIC, chúng tôi giữ số lượng tăng cường
cố định ở 3 và báo cáo các giá trị được chọn cho α và
β trong Bảng 2. Để đảm bảo công bằng, chúng tôi cố
định kích thước batch và kích thước minibatch bộ nhớ
ở 32 cho tất cả các mô hình. Chúng tôi huấn luyện trên
mỗi nhiệm vụ trong 10 epoch trên SVHN, 50 trên CIFAR-
10, và 30 trên CIFAR-100. Tất cả các phương pháp sử
dụng SGD như một bộ tối ưu hóa với ngoại lệ duy nhất
là CCIC, sử dụng Adam.

5.1. Baseline
Giới hạn dưới/trên. Chúng tôi giới hạn hiệu suất cho
các thí nghiệm của mình bằng cách bao gồm hai biện
pháp tham chiếu. Như một giới hạn dưới, chúng tôi đánh
giá hiệu suất của một mô hình được huấn luyện bởi
Fine Tuning độc quyền trên tập các ví dụ có giám sát,
không có bất kỳ biện pháp đối phó nào với quên lãng
thảm khốc. Chúng tôi cũng cung cấp một giới hạn trên
(UB) được cung cấp bởi một mô hình được huấn luyện
cùng nhau, tức là không chia bộ dữ liệu thành các nhiệm
vụ hoặc loại bỏ bất kỳ chú thích thông tin cơ bản nào.
Loại bỏ không nhãn. Phương pháp đơn giản nhất để
thích ứng các phương pháp hiện có với thiết lập của
chúng tôi bao gồm việc đơn giản loại bỏ các ví dụ không
nhãn từ batch hiện tại. Về vấn đề này, chúng tôi so sánh
đề xuất của mình với Learning Without Forgetting (LwF)
[20], online Elastic Weight Consolidation (oEWC) [21],
Synaptic Intelligence (SI) [19], Experience Replay (ER)
[11], iCaRL [24], Dark Experience Replay (DER) [25]
và GDumb [26]. Bằng cách làm như vậy, chúng tôi có
thể xác minh liệu đề xuất của chúng tôi có thể duy trì
tốt hơn một chế độ huấn luyện với giám sát giảm.
Pseudo-Labeling. Lấy cảm hứng từ dòng công trình dựa
vào self-labeling [33, 34], chúng tôi ở đây giới thiệu
một baseline CSSL đơn giản cho phép ER hưởng lợi từ
các ví dụ không nhãn: cho một ví dụ không nhãn x^u,
nó ghim như một pseudo-label ỹ^u [34] dự đoán của
chính mô hình. Chính thức,
ỹ^u = argmax_{c∈Ct} h^c_θ(x^u)
trong đó Ct là tập các lớp của nhiệm vụ hiện tại. Như
được thảo luận trong Mục 4.1, tự huấn luyện có khả
năng gây ra sự không ổn định của mô hình (đặc biệt tại
ranh giới nhiệm vụ, khi mô hình bắt đầu trải nghiệm
dữ liệu mới): chúng tôi giảm thiểu điều này bằng cách
áp dụng một ngưỡng để loại bỏ các đầu ra tin cậy thấp
và x^u tương đối của chúng. Cụ thể, chúng tôi ước tính
độ tin cậy như sự khác biệt giữa hai giá trị cao nhất
của h^c_θ(x^u). Sau bước này, một cặp (x^u, ỹ^u) được
xem xét ngang bằng với bất kỳ cặp có giám sát (x^s, y^s)
nào, và do đó được chèn vào bộ đệm bộ nhớ. Chúng tôi
gọi baseline này là PseudoER.

5.2. Kết quả Thí nghiệm
Như được tiết lộ bởi các kết quả trong Bảng 1, CSSL
chứng minh là một kịch bản thách thức. Không có gì
đáng ngạc nhiên, độ khó của nó tăng khi ít nhãn hơn
được cung cấp cho người học.
Các phương pháp chính quy hóa thường được coi là
yếu trong kịch bản Class-IL [7, 9]. Điều này phù hợp
với các quan sát thực nghiệm của chúng tôi, vì LwF,
oEWC và SI hoạt động kém trên tất cả các bộ dữ liệu.
Thật vậy, những phương pháp này hiếm khi vượt trội
hơn giới hạn dưới của chúng tôi (Fine Tuning), cho
thấy rằng chúng không hiệu quả bên ngoài Task-IL và
Domain-IL. Điều này trở nên đặc biệt rõ ràng trong
chế độ nhãn thấp.
Các phương pháp rehearsal tổng thể cho thấy sự giảm
hiệu suất dự kiến khi giám sát giảm dần. Điều này đặc
biệt nghiêm trọng đối với DER và iCaRL, vì độ chính
xác của chúng giảm trung bình hơn 70% giữa 100% và
0.8% nhãn. Khi mô hình underfits nhiệm vụ khi ít giám
sát được cung cấp, nó tạo ra các mục tiêu ít đáng tin
cậy hơn không thể được sử dụng thành công cho replay
bởi những phương pháp này. Ngược lại, ER có thể replay
thông tin thành công vì nó khai thác hard targets; do
đó, nó học hiệu quả ngay cả sau khi ban đầu underfitting
nhiệm vụ. Thật vậy, độ chính xác của nó với 5% nhãn
và bộ đệm 5120 luôn cao hơn độ chính xác có giám sát
đầy đủ của nó với một bộ đệm nhỏ hơn. Trong khi ER
có thể vượt qua thiếu nhãn khi được ghép nối với một
bộ đệm thích hợp, các phương pháp dựa trên chưng cất
kiến thức đáng chú ý gặp phải một trở ngại lớn trong
thiết lập này.
Chúng tôi quy sự thất bại của iCaRL trên SVHN cho
độ phức tạp thấp của mạng backbone. Thật vậy, một
backbone nông cung cấp một không gian latent ít phù
hợp cho bộ phân loại nearest-mean-of-exemplars của
nó. Ngược lại, phương pháp này chứng minh khá hiệu
quả ngay cả với một bộ đệm bộ nhớ giảm trên CIFAR-
100. Trong benchmark này, việc lấy mẫu herding của
iCaRL đảm bảo rằng tất cả các lớp được đại diện công
bằng ngay cả trong một bộ đệm bộ nhớ nhỏ.
Cuối cùng, GDumb không bị thiệt hại bởi giám sát thấp
hơn miễn là bộ đệm của nó có thể được lấp đầy hoàn
toàn: hoạt động của nó không bị gián đoạn bởi các ví
dụ không nhãn trên luồng, vì nó bỏ qua những ví dụ
sau hoàn toàn. Trong khi nó vượt trội hơn các phương
pháp khác khi ít nhãn có sẵn, CCIC vượt qua nó một
cách nhất quán. Điều này gợi ý rằng luồng cung cấp
tiềm năng cho việc học thêm và không nên bị bỏ qua.
Phương pháp CSSL. Baseline PseudoER của chúng tôi
hoạt động đáng chú ý tốt trên CIFAR-10, duy trì độ
chính xác cao khi lượng giám sát giảm. Tuy nhiên, trong
khi CIFAR-10 là một benchmark phức tạp, nó chỉ có hai
lớp cho mỗi nhiệm vụ, điều này làm cho việc pseudo-
labeling dễ dàng tạo ra các phản hồi hợp lý (lưu ý rằng
một phỏng đoán ngẫu nhiên sẽ dẫn đến 50% độ chính
xác). Ngược lại, PseudoER khó khăn để tạo ra các mục
tiêu hợp lệ và thể hiện một sự sụt giảm hiệu suất nhanh
chóng trên CIFAR-100 khi tính khả dụng của dữ liệu
có nhãn giảm. Tương tự, chúng tôi thấy việc áp dụng
pseudo-labeling có lợi cho SVHN chỉ khi không gian
dành cho bộ đệm tăng, chứng minh những cạm bẫy của
phương pháp này trong thiết lập trực tuyến.
Ngược lại, hiệu suất hấp dẫn của CCIC cho thấy sự
kết hợp thành công của thông tin có giám sát và chính
quy hóa bán giám sát. Trong khi ER gặp phải sự sụt
giảm hiệu suất trung bình 47%, đi từ 25% đến 0.8%
nhãn trên CIFAR-10, CCIC chỉ mất 26% trung bình.
Đáng ngạc nhiên, chúng tôi quan sát rằng - đối với đa
số các benchmark được đánh giá - 25% giám sát đủ để
tiếp cận kết quả của các phương pháp có giám sát đầy
đủ, thậm chí vượt trội hơn state-of-the-art trong một
số trường hợp (CIFAR-10 với kích thước bộ đệm 5120,
SVHN với kích thước bộ đệm 500 và 5120). Điều này
gợi ý rằng, khi học từ một luồng dữ liệu, việc cố gắng
cung cấp giám sát đầy đủ không thiết yếu như có thể
mong đợi: khác biệt với kịch bản offline, một lượng
nhãn lớn hơn có thể không tạo ra lợi nhuận tỷ lệ do
quên lãng thảm khốc. Về mặt này, các thí nghiệm của
chúng tôi gợi ý rằng việc ghép nối ít ví dụ có nhãn với
các kỹ thuật bán giám sát đại diện cho một mô hình
hiệu quả hơn để đạt được hiệu suất thỏa mãn.
Khai thác Không Giám sát trong CCIC. Trong số hạng
mất mát khai thác không giám sát LUM của nó, CCIC
lấy các ví dụ của các nhiệm vụ trước đó trong bộ đệm
bộ nhớ làm negatives (Khai thác Giữa-Nhiệm vụ) và
yêu cầu các biểu diễn của chúng được đẩy ra khỏi dữ
liệu hiện tại. Trong Bảng 3, chúng tôi so sánh lựa chọn
thiết kế này với hai chiến lược thay thế: i) Khai thác
Trong-Nhiệm vụ, nơi chúng tôi để mô hình chọn các
negatives chỉ từ nhiệm vụ hiện tại; và ii) Khai thác
Không-Nhiệm vụ, nơi mô hình có thể tự do chọn một
ví dụ negative từ bộ nhớ hoặc batch hiện tại mà không
có bất kỳ tiên nghiệm cụ thể nhiệm vụ nào. Như có thể
quan sát, Khai thác Không-Nhiệm vụ và Khai thác Trong-
Nhiệm vụ dẫn đến một sự giảm nhỏ nhưng nhất quán
về hiệu suất, trong khi LUM chứng minh là chiến lược
có lợi nhất.
Tính Nhất Quán Điều khiển Mô hình. Ngoài việc kết
hợp một dạng chính quy hóa tính nhất quán đối lập với
ER, chúng tôi đề xuất một baseline tính nhất quán thời
gian bổ sung yêu cầu các kích hoạt của mô hình phù
hợp với một checkpoint di chuyển-trung bình chậm hơn.
Kết quả trong Bảng 4 cho thấy, tuy nhiên, rằng phương
pháp như vậy hoạt động kém một cách nhất quán, thậm
chí không đạt được hiệu suất của ER. Điều này gợi ý
rằng, khác biệt với các kịch bản có giám sát đầy đủ [6],
các phương pháp exponential moving average không
nhất thiết mở rộng sang CL.

6. Kết luận
Quên lãng thảm khốc ngăn chặn hầu hết các mô hình
state-of-the-art hiện tại học tuần tự nhiều nhiệm vụ,
buộc các nhà thực hành phải thực hiện các quy trình
huấn luyện đòi hỏi tài nguyên nặng nề. Hơn nữa, nhiều
ứng dụng có thể hưởng lợi từ các thuật toán CL thường
được đặc trưng bởi sự khan hiếm nhãn. Vì lý do này,
chúng tôi điều tra khả năng tận dụng các điểm dữ liệu
không nhãn để nâng cao hiệu suất của các mô hình
Học Liên Tục, một kịch bản mà chúng tôi đặt tên là
Học Liên Tục Bán Giám sát (CSSL).
Chúng tôi tiếp tục đề xuất Tính Nhất Quán Nội Suy
Liên Tục Đối Lập (CCIC), một phương pháp tăng dần
kết hợp lợi ích của rehearsal với chính quy hóa tính
nhất quán và các ràng buộc dựa trên khoảng cách. Đáng
chú ý, các thí nghiệm của chúng tôi gợi ý rằng các
phương pháp được thiết kế tốt có thể khai thác hiệu
quả các ví dụ không nhãn để ngăn quên lãng. Điều này
cho thấy rằng nỗ lực chú thích tất cả dữ liệu có thể
không cần thiết trong một kịch bản liên tục.

Lời cảm ơn
Công trình này được hỗ trợ bởi FF4EuroHPC: HPC
Innovation for European SMEs, Project Call 1. Dự án
FF4EuroHPC đã nhận được tài trợ từ European High-
Performance Computing Joint Undertaking (JU) dưới
thỏa thuận cấp tài trợ số 951745.

Tài liệu tham khảo
[1] M. McCloskey, N. J. Cohen, Catastrophic interference in connectionist networks: The sequential learning problem, Psychol Learn Motiv doi: 10.1016/S0079-7421(08)60536-8 (1989).
[2] M. De Lange, R. Aljundi, M. Masana, S. Parisot, X. Jia, A. Leonardis, G. Slabaugh, T. Tuytelaars, A continual learning survey: Defying forgetting in classification tasks, IEEE TPAMI doi: 10.1109/TPAMI.2021.3057446 (2021).
[3] R. Aljundi, K. Kelchtermans, T. Tuytelaars, Task-free continual learning, in: CVPR, 2019.
[4] W. Zhou, S. Chang, N. Sosa, H. Hamann, D. Cox, Lifelong object detection, arXiv:2009.01129 (2020).
[5] C. Olivier, S. Bernhard, Z. Alexander, Semi-supervised learning, 2006, doi: 10.7551/mitpress/9780262033589.001.0001.
[6] A. Tarvainen, H. Valpola, Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results, in: ANIPS, 2017.
[7] S. Farquhar, Y. Gal, Towards robust evaluations of continual learning, in: ICML Workshop, 2018.
[8] G. M. van de Ven, A. S. Tolias, Three continual learning scenarios, in: ANIPS Workshop, 2018.
[9] R. Aljundi, M. Lin, B. Goujaud, Y. Bengio, Gradient based sample selection for online continual learning, in: ANIPS, 2019.
[10] D. Lopez-Paz, M. Ranzato, Gradient episodic memory for continual learning, in: ANIPS, 2017.
[11] M. Riemer, I. Cases, R. Ajemian, M. Liu, I. Rish, Y. Tu, G. Tesauro, Learning to learn without forgetting by maximizing transfer and minimizing interference, in: ICLR, 2019.
[12] A. Chaudhry, A. Gordo, P. K. Dokania, P. Torr, D. Lopez-Paz, Using hindsight to anchor past knowledge in continual learning, in: AAAI Conf. Artif. Intell., 2021.
[13] J. Zhang, J. Zhang, S. Ghosh, D. Li, S. Tasci, L. Heck, H. Zhang, C.-C. J. Kuo, Class-incremental learning via deep model consolidation, in: WACV, 2020.
[14] A. Lechat, S. Herbin, F. Jurie, Semi-supervised class incremental learning, in: ICPR, 2021.
[15] J. Serra, D. Suris, M. Miron, A. Karatzoglou, Overcoming catastrophic forgetting with hard attention to the task, in: ICML, 2018.
[16] C. Fernando, D. Banarse, C. Blundell, Y. Zwols, D. Ha, A. A. Rusu, A. Pritzel, D. Wierstra, Pathnet: Evolution channels gradient descent in super neural networks, arXiv:1701.08734 (2017).
[17] A. Mallya, S. Lazebnik, Packnet: Adding multiple tasks to a single network by iterative pruning, in: CVPR, 2018.
[18] J. Kirkpatrick, R. Pascanu, N. Rabinowitz, J. Veness, G. Desjardins, A. A. Rusu, K. Milan, J. Quan, T. Ramalho, A. Grabska-Barwinska, et al., Overcoming catastrophic forgetting in neural networks, PNAS doi: 10.1073/pnas.1611835114 (2017).
[19] F. Zenke, B. Poole, S. Ganguli, Continual learning through synaptic intelligence, in: ICML, 2017.
[20] Z. Li, D. Hoiem, Learning without forgetting, IEEE TPAMI doi: 10.1109/TPAMI.2017.2773081 (2017).
[21] J. Schwarz, W. Czarnecki, J. Luketina, A. Grabska-Barwinska, Y. W. Teh, R. Pascanu, R. Hadsell, Progress & compress: A scalable framework for continual learning, in: ICML, 2018.
[22] R. Ratcliff, Connectionist models of recognition memory: constraints imposed by learning and forgetting functions., Psychol. Rev. doi: 10.1037/0033-295x.97.2.285 (1990).
[23] P. Buzzega, M. Boschini, A. Porrello, S. Calderara, Rethinking experience replay: a bag of tricks for continual learning, in: ICPR, 2020.
[24] S. Rebuffi, A. Kolesnikov, G. Sperl, C. Lampert, icarl: Incremental classifier and representation learning, in: CVPR, 2017.
[25] P. Buzzega, M. Boschini, A. Porrello, D. Abati, S. Calderara, Dark experience for general continual learning: a strong, simple baseline, in: ANIPS, 2020.
[26] A. Prabhu, P. H. Torr, P. K. Dokania, Gdumb: A simple approach that questions our progress in continual learning, in: ECCV, 2020.
[27] S. Laine, T. Aila, Temporal ensembling for semi-supervised learning, in: ICLR, 2017.
[28] D. Berthelot, N. Carlini, I. Goodfellow, N. Papernot, A. Oliver, C. A. Raffel, Mixmatch: A holistic approach to semi-supervised learning, in: ANIPS, 2019.
[29] T. Miyato, S.-i. Maeda, M. Koyama, S. Ishii, Virtual adversarial training: a regularization method for supervised and semi-supervised learning, IEEE TPAMI doi: 10.1109/TPAMI.2018.2858821 (2018).
[30] Z. Zheng, L. Zheng, Y. Yang, Unlabeled samples generated by gan improve the person re-identification baseline in vitro, in: ICCV, 2017.
[31] Y. Yang, Y. Zhuang, Y. Pan, Multiple knowledge representation for big data artificial intelligence: framework, applications, and case studies, Front. Inf. Technol. Electron. Eng. doi: 10.1631/FITEE.2100463 (2021).
[32] Y. Pan, Multiple knowledge representation of artificial intelligence, Engineering doi: 10.1016/j.eng.2019.12.011 (2020).
[33] D. Yarowsky, Unsupervised word sense disambiguation rivaling supervised methods, in: ACL, 1995, doi:10.3115/981658.981684.
[34] D.-H. Lee, Pseudo-label: The simple and efficient semi-supervised learning method for deep neural networks, in: ICML Workshop, 2013.
[35] A. Oliver, A. Odena, C. A. Raffel, E. D. Cubuk, I. Goodfellow, Realistic evaluation of deep semi-supervised learning algorithms, in: ANIPS, 2018.
[36] H. Zhang, M. Cisse, Y. N. Dauphin, D. Lopez-Paz, mixup: Beyond empirical risk minimization, in: ICLR, 2018.
[37] Y. Netzer, T. Wang, A. Coates, A. Bissacco, B. Wu, A. Y. Ng, Reading digits in natural images with unsupervised feature learning, in: ANIPS, 2011.
[38] A. Krizhevsky, et al., Learning multiple layers of features from tiny images, Tech. rep. (2009).
[39] D. Abati, J. Tomczak, T. Blankevoort, S. Calderara, R. Cucchiara, B. E. Bejnordi, Conditional channel gated networks for task-aware continual learning, in: CVPR, 2020.

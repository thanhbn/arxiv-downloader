# Giải mã Đối lập Suy đoán
Hongyi Yuan12∗, Keming Lu2, Fei Huang2, Zheng Yuan2, Chang Zhou2
1Đại học Tsinghua,2Alibaba Inc.
yuanhy20@mails.tsinghua.edu.cn
{lukeming.lkm,feihu.hf}@alibaba-inc.com
{yuanzheng.yuanzhen,ericzhou.zc}@alibaba-inc.com

Tóm tắt
Các mô hình ngôn ngữ lớn (LLM) thể hiện hiệu suất đặc biệt trong các tác vụ ngôn ngữ, tuy nhiên quá trình suy luận tự hồi quy của chúng bị hạn chế do yêu cầu tính toán cao và không tối ưu do độ lệch phơi bày. Lấy cảm hứng từ giải mã suy đoán và giải mã đối lập, chúng tôi giới thiệu Giải mã Đối lập Suy đoán (SCD), một phương pháp giải mã đơn giản nhưng mạnh mẽ tận dụng các dự đoán từ các mô hình ngôn ngữ nhỏ hơn (LM) để đạt được cả tăng tốc giải mã và cải thiện chất lượng. Các đánh giá và phân tích toàn diện trên bốn tác vụ ngôn ngữ đa dạng chứng minh hiệu quả của SCD, cho thấy hiệu quả giải mã và chất lượng có thể được hưởng lợi tương thích từ một LM nhỏ hơn.

1 Giới thiệu
Các mô hình ngôn ngữ lớn (LLM) đã nâng cao tính linh hoạt và thành thạo trong việc tiếp cận các tác vụ ngôn ngữ tự nhiên thực tế như tuân theo hướng dẫn chung (Ouyang et al., 2022; Taori et al., 2023; Lu et al., 2023) và lý luận (Cobbe et al., 2021; Wei et al., 2023; Yuan et al., 2023). Hầu hết các LLM hiện tại (Brown et al. (2020); Touvron et al. (2023); Bai et al. (2023), trong số các tác phẩm khác) được xây dựng trên Transformer chỉ giải mã. Do bản chất tự hồi quy trong quá trình suy luận, thời gian chạy của suy luận giải mã có thể quá nhiều trên cơ sở hạ tầng tính toán chung, và chất lượng tạo sinh có thể không tối ưu do độ lệch phơi bày (Arora et al., 2022). Cải thiện suy luận giải mã đã trở thành tâm điểm của cộng đồng nghiên cứu trong tạo sinh ngôn ngữ (Vijayakumar et al., 2018; Holtzman et al., 2020; Su et al., 2022).

Đối với tăng tốc giải mã, một phương pháp nổi bật có tên là giải mã suy đoán (Leviathan et al., 2022; Chen et al., 2023) đã được đề xuất và tận dụng các mô hình ngôn ngữ (LM) tương đối nhỏ hơn để dự đoán nhiều tạo sinh token liên tiếp của LLM mục tiêu. Các LLM chỉ yêu cầu một lần tính toán thuận để kiểm tra tính hợp lệ của dự đoán từ các LM nhỏ hơn. Phương pháp giải mã này duy trì phân phối token của LLM mục tiêu và tăng tốc hơn khi các LM nhỏ hơn có thể dự đoán chính xác các tạo sinh tiềm năng của LLM mục tiêu.

Đối với chất lượng tạo sinh, giải mã đối lập đã được đề xuất gần đây (Li et al., 2023a). Giải mã đối lập giả định rằng các LM nhỏ hơn được kết hợp có thể thể hiện xu hướng hệ thống cao hơn để tạo ra các token lỗi so với các LM lớn hơn, và phương pháp này tìm cách loại bỏ lỗi hệ thống như vậy bằng cách đối lập phân phối token giữa các LM nhỏ hơn và LM lớn hơn. Từ cả tăng tốc suy luận hoặc cải thiện chất lượng, những công trình này đã chứng minh một hướng đi hứa hẹn bằng cách tích hợp các LM nhỏ hơn trong quá trình tạo sinh tự hồi quy.

Lấy cảm hứng từ cả giải mã suy đoán và đối lập, chúng tôi đề xuất Giải mã Đối lập Suy đoán (SCD), tận dụng một LM nhỏ hơn duy nhất để cải thiện giải mã về tốc độ và chất lượng một cách tổng thể. Các đánh giá toàn diện của bốn tác vụ đa dạng cho thấy SCD có thể đạt được các yếu tố tăng tốc tương tự của giải mã suy đoán trong khi duy trì cải thiện chất lượng từ giải mã đối lập. Bằng cách phân tích thêm các phân phối token của LM nhỏ hơn và lớn hơn trong SCD, chúng tôi cho thấy tính tương thích vốn có của tăng tốc giải mã và cải thiện chất lượng. Các đóng góp của bài báo này có thể được tóm tắt như sau:

• Chúng tôi đề xuất Giải mã Đối lập Suy đoán cho suy luận LLM hiệu quả.
• Các thí nghiệm và phân tích toàn diện minh họa tính tương thích của giải mã suy đoán và đối lập trên 4 tác vụ đa dạng.

2 Các Công trình Liên quan
Về tăng tốc suy luận, nghiên cứu gần đây đã được dành cho việc phát triển các phương pháp giải mã hiệu quả khác nhau (Yao et al., 2022; Kwon et al., 2023; Cai et al., 2023). Giải mã suy đoán Leviathan et al. (2022); Chen et al. (2023); Kim et al. (2023) là một trong những công trình gần đây này và sử dụng các mô hình nhỏ hơn để tăng tốc. Miao et al. (2023); Spector and Re (2023) đề xuất tổ chức các dự đoán từ LM nhỏ thành cấu trúc cây để tăng tốc giải mã suy đoán hơn nữa.

Về chất lượng suy luận, nghiên cứu phong phú đã được đề xuất (Vijayakumar et al., 2018; Holtzman et al., 2020; Su et al., 2022; Su and Xu, 2022; Finlayson et al., 2023) và giải mã đối lập đạt được chất lượng giải mã tốt hơn bằng cách tương tự tích hợp các LM nhỏ hơn và thiết kế các phân phối token đối lập (Li et al., 2023a; O'Brien and Lewis, 2023). Nó có thể được điều chỉnh thêm thành các biến thể khác như đối lập phân phối token giữa các lớp mô hình (Chuang et al., 2023) hoặc các đầu vào khác nhau (Yona et al., 2023). SCD lấy cảm hứng từ những công trình này và hưởng lợi cả tốc độ giải mã và chất lượng bằng cách kết hợp các LM nhỏ hơn vào tạo sinh.

3 Kiến thức Cơ bản
Chúng tôi tuân theo thuật ngữ trong Li et al. (2023a), và gọi các LM mục tiêu lớn hơn là LM chuyên gia trong khi các LM nhỏ hơn là LM nghiệp dư được ký hiệu lần lượt là Me và Ma.

3.1 Giải mã Đối lập
Lý luận nội tại của giải mã đối lập (CD) là các LM nghiệp dư có xu hướng hệ thống không mong muốn mạnh hơn để tạo ra các mẫu không mong muốn (ví dụ: ảo giác) so với LM chuyên gia. Bằng cách đối lập các phân phối token giữa LM chuyên gia và nghiệp dư, những xu hướng như vậy có thể được giảm thiểu. Đã có hai phiên bản giải mã đối lập được đề xuất liên tiếp bởi Li et al. (2023a) và O'Brien and Lewis (2023), mà chúng tôi gọi là Giải mã đối lập gốc và Giải mã đối lập cải tiến. Điểm số logit đối lập cuối cùng cho giải mã đối lập gốc sori(xi|x<i) và giải mã đối lập cải tiến simp(xi|x<i) tương ứng là:

sori(xi|x<i) = {
logPMe(xi|x<i)−logPMa(xi|x<i), xi∈ Vα ori,i
−∞, xi∉ Vα ori,i

simp(xi|x<i) = {
(1 +β)YMe(xi|x<i)−βYMa(xi|x<i), xi∈ Vα imp,i
−∞, xi∉ Vα imp,i

trong đó P· và Y· tương ứng là xác suất token và logit được tạo từ LM. Vα ·,i biểu thị ràng buộc hợp lý thích ứng mà động thái hạn chế các logit khỏi việc tạo ra các chế độ lỗi. Các ràng buộc hợp lý thích ứng được tính như sau:

Vα ori,i = {w|PMe(w|x<i)> αmax w∈VPMe(w|x<i)},
Vα imp,i = {w|YMe(w|x<i)>logα+ max w∈VYMe(w|x<i)}.

Một token được tạo từ phân phối token đối lập Pτ n(xi) = softmax τ(sn(xi|x<i)), n∈ {ori,imp}, trong đó τ đại diện cho nhiệt độ softmax xác định độ mượt của phân phối token đối lập.

3.2 Giải mã Suy đoán
Thay vì yêu cầu một tính toán thuận của Me cho mỗi token trong giải mã thông thường, giải mã suy đoán (SD) sử dụng Ma để chủ yếu tạo γ token tại mỗi lần lặp sau đó Me thực hiện một tính toán thuận để kiểm tra tính hợp lệ của γ token. Nếu Me chấp nhận tất cả γ token, nó kết thúc lần lặp với một token được tạo bổ sung, dẫn đến γ+ 1 token được tạo. Ngược lại, nếu Me từ chối một token tại r, token được lấy mẫu lại theo Me để thay thế token bị từ chối; do đó lần lặp kết thúc với r token được tạo. Chỉ với một lần tính toán thuận của Me, nhiều token được tạo tại mỗi lần lặp. Khi tỷ lệ giữa thời gian chạy yêu cầu của Ma và Me (hệ số chi phí c, Leviathan et al. (2022)) thấp và tỷ lệ chấp nhận token cao, sẽ có sự tăng tốc đáng chú ý.

Thuật toán 1: Giải mã Đối lập Suy đoán
Dữ liệu: Me,Ma, tiền tố đầu vào xinp
Kết quả: [xinp, x1, .., xk]
1 for i từ 1 đến γ do
2   xi∼PMa(xi) =Ma(xi|xinp, x<i);
3 PMe(x1), .., PMe(xγ+1) =Me(x1, .., xγ|xinp);
4 Tính Pn(x1), .., Pn(xγ) theo Mục §3.1;
5 r1, .., rγ i.i.d lấy mẫu từ Uniform (0,1);
6 k= min{i|ri>Pn(xi)/PMa(xi)} ∪ {γ+ 1};
7 if k≤γ then
8   Pk(xk) = norm(max(0, Pn(xk)−PMa(xk));
9   Lấy mẫu lại xk∼Pk(xk);
10 else
11   PMa(xγ+1) =Ma(xγ+1|xinp, x1, .., xγ);
12   Tính Pn(xγ+1) theo Mục §3.1;
13   xγ+1∼Pn(xγ+1);

4 Giải mã Đối lập Suy đoán
Giải mã suy đoán tận dụng Ma nhỏ hơn chỉ để tăng tốc tạo sinh, trong khi không tận dụng tối đa các phân phối token từ Ma. Việc đồng thời áp dụng phân phối token đối lập là tự nhiên, và với chi phí tính toán không đáng kể, chất lượng và hiệu quả tạo sinh có thể hưởng lợi từ việc tích hợp giải mã suy đoán và đối lập. Do đó, chúng tôi đề xuất Giải mã Đối lập Suy đoán (SCD).

Cụ thể, tại mỗi lần lặp, γ token được tạo từ mô hình nghiệp dư Ma. Khi kiểm tra tính hợp lệ của các token, phân phối mục tiêu trở thành Pτ n, n∈ {ori,imp} từ phân phối đối lập thay vì PMe trong giải mã suy đoán. Đối với một token x trong các token được tạo bởi Ma, nó bị từ chối với xác suất 1−Pτ n(x)/PMa(x) và sau đó một token mới thay thế x được lấy mẫu lại từ norm(max(0, Pτ n(x)−PMa(x)), trong đó norm(f(x)) = f(x)/Σxf(x), s.t.f(x)≥0. Nếu tất cả các token được tạo bởi Ma được chấp nhận, thì một token bổ sung được lấy mẫu từ Pτ n.

Quy trình lấy mẫu của SCD tương tự như giải mã suy đoán gốc trong Leviathan et al. (2022); Chen et al. (2023). Tuy nhiên, đáng chú ý rằng trong SCD của chúng tôi, khi tất cả các token được tạo bởi Ma được chấp nhận, chúng tôi yêu cầu một tính toán thuận bổ sung từ Ma để có được logit token cuối cùng của nó để tính toán phân phối đối lập Pτ n tại lần lặp đó, trong khi trong giải mã suy đoán, token bổ sung được lấy mẫu trực tiếp từ Me. Chi phí tính toán này là không đáng kể khi c nhỏ. Chúng tôi chi tiết thuật toán SCD của chúng tôi trong Thuật toán 1. Sự khác biệt từ giải mã suy đoán gốc được làm nổi bật bằng màu xanh lam.

5 Thí nghiệm
Cài đặt Thí nghiệm. Chúng tôi đánh giá SCD và các baseline khác trên bốn benchmark: WikiText (Merity et al., 2016), HumanEval (Chen et al., 2021), AlpacaEval (Li et al., 2023b), và GSM8k (Cobbe et al., 2021). Bốn benchmark này bao quát các tác vụ ngôn ngữ đa dạng của tạo sinh mở, tạo sinh mã, căn chỉnh con người, và lý luận toán học tương ứng. Đối với WikiText, chúng tôi sử dụng Llama2 7B và Llama2 70B đã được pre-train (Touvron et al., 2023) làm Ma và Me và tuân theo Li et al. (2023a) để sử dụng diversity, MAUVE (Pillutla et al., 2021) và coherence làm các metric đánh giá. Đối với HumanEval, chúng tôi sử dụng Llama2 7B và Llama2 70B đã được pre-train và đánh giá tỷ lệ pass 1-round. Đối với AlpacaEval, chúng tôi sử dụng Llama2chat 7B và Llama2chat 70B đã được căn chỉnh con người và báo cáo tỷ lệ thắng so với text-davinci-003 được đánh giá bởi GPT-4. Đối với GSM8k, chúng tôi sử dụng Llama2 7B và Llama2 70B đã được fine-tune trên tập huấn luyện của nó và báo cáo độ chính xác của kết quả tập test. Chúng tôi đặt γ= 4 cho tất cả thí nghiệm và đặt nhiệt độ τ thành 0.7 cho WikiText và AlpacaEval và 0.001 cho GSM8k và HumanEval. Chúng tôi để lại các cài đặt thí nghiệm chi tiết trong Phụ lục §A.

Kết quả Chất lượng. Như được thể hiện trong Bảng 1, SCD và CD gốc và cải tiến thể hiện sự cải thiện đáng kể so với Me trong GSM8k và HumanEval. Trên WikiText, chỉ CD và SCD gốc vượt trội hơn Me về diversity với +0.16 và MAUVE với +0.06. Không có sự cải thiện rõ ràng trong Coherence. Trên AlpacaEval, mặc dù cả hai phiên bản của SCD và CD đều cho thấy kết quả tốt hơn Me, sự cải thiện như vậy không đáng kể do độ phương sai cao của GPT4-as-a-judge. Chúng ta có thể thấy rằng các phiên bản khác nhau của SCD gợi ý các mức độ cải thiện khác nhau. SCD gốc hoạt động tốt hơn trên WikiText và HumanEval trong khi kém hơn trên GSM8k so với SCD cải tiến. Kết quả trên bốn benchmark cho thấy SCD có thể hưởng lợi cho các LLM khác nhau trên các tác vụ ngôn ngữ đa dạng, duy trì cùng mức cải thiện chất lượng tạo sinh như CD.

Tăng tốc. Để chứng minh sự tăng tốc suy luận của SCD, chúng tôi chủ yếu cung cấp yếu tố tăng tốc mong đợi của SCD về mặt lý thuyết liên quan đến số lượng dự đoán token Ma mỗi lần lặp γ, tỷ lệ chấp nhận λ, và hệ số chi phí c, với chứng minh được để lại trong Phụ lục §B.

Định lý 5.1. Yếu tố tăng tốc mong đợi trong thời gian chạy giải mã là (1−λγ+1)/((1−λ)(1+cγ+cλγ)).

Trong Bảng 1, sự tăng tốc nhất quán được trình bày trên các benchmark khác nhau. Chúng tôi tiếp tục trực quan hóa yếu tố tăng tốc mong đợi của SCD trong Hình 1 theo tỷ lệ chấp nhận thực nghiệm λ trong HumanEval với các cài đặt siêu tham số khác nhau. Theo Định lý 5.1, các yếu tố tăng tốc được mô tả đối với hệ số chi phí c, thường có giá trị nhỏ đại diện cho tỷ lệ thời gian chạy yêu cầu của Ma và Me và phụ thuộc vào cơ sở hạ tầng (ví dụ: GPU) phục vụ các LLM. Chúng ta có thể thấy rằng tỷ lệ chấp nhận do đó các yếu tố tăng tốc tương ứng của SCD gốc nhạy cảm hơn với các siêu tham số so với SCD cải tiến. Với các siêu tham số phù hợp, SCD có thể đạt được sự tăng tốc tương tự với giải mã suy đoán (đường chấm), điều này cho thấy sự đánh đổi tốc độ không đáng kể để kết hợp các phân phối token đối lập. Kết quả trên GSM8k được liệt kê trong Phụ lục §D trình bày các mẫu tương tự.

6 Phân tích
Tính tương thích. Kết quả được trình bày trong §5 cho thấy SCD có thể kết hợp lợi ích của CD và SD. Chúng tôi đào sâu vào lý do cho tính tương thích như vậy. Chúng tôi tính toán entropy trung bình của xác suất token từ Ma và Me liên quan đến các token được chấp nhận và từ chối trong SCD. Như được thể hiện trong Hình 2, entropy phân phối token từ cả Ma và Me của các token được chấp nhận cao hơn đáng kể so với các token bị từ chối. Hiện tượng này gợi ý SCD hưởng lợi tăng tốc từ việc chấp nhận các token dễ có entropy thấp hơn trong khi hưởng lợi từ phân phối token đối lập bằng cách từ chối các token khó có entropy cao hơn. Chúng tôi cũng trình bày một nghiên cứu tình huống từ GSM8k trong Phụ lục §C để chứng minh tính tương thích như vậy.

Độ nhạy. Thông qua Hình 3, chúng tôi cho thấy hiệu suất dao động như thế nào đối với siêu tham số α và β. Chúng ta có thể thấy rằng SCD cải tiến ít nhạy cảm hơn với cả α và β trên GSM8k so với SCD gốc. Điều này có thể do tính linh hoạt tốt hơn của việc thao tác logit so với xác suất. Kết quả trên HumanEval được liệt kê trong Phụ lục §D trình bày các hiện tượng tương tự.

7 Kết luận
Trong bài báo này, chúng tôi đề xuất giải mã đối lập suy đoán, một chiến lược giải mã tự nhiên tích hợp các LM nghiệp dư nhỏ để tăng tốc suy luận và cải thiện chất lượng của LLM. Các thí nghiệm mở rộng cho thấy hiệu quả của SCD và phân tích sâu của chúng tôi cũng giải thích tính tương thích thông qua phạm vi entropy phân phối token. Phương pháp của chúng tôi có thể được triển khai dễ dàng để cải thiện việc phục vụ LLM trong thế giới thực.

Hạn chế
Trong các thí nghiệm của chúng tôi, chúng tôi cung cấp các yếu tố tăng tốc mong đợi của SCD trên bốn benchmark được tính theo tỷ lệ chấp nhận token thực nghiệm λ và các hệ số chi phí được chọn c. Yếu tố tăng tốc thực nghiệm có tương quan cao với cơ sở hạ tầng thực tế phục vụ cả LM lớn hơn và LM nhỏ hơn. Để bù đắp cho hạn chế trình bày này và chứng minh tốt hơn hiệu suất tăng tốc, chúng tôi trực quan hóa yếu tố tăng tốc mong đợi bằng cách trải rộng qua một phạm vi c trong Hình 1. Đây là một hạn chế chung của việc triển khai giải mã suy đoán trong việc phục vụ LLM thế giới thực. Ví dụ, thời gian chạy của việc chuyển đổi giữa tính toán thuận của Ma và Me sẽ không thể bỏ qua mà không có cơ sở hạ tầng được tối ưu hóa đúng cách, gây ra c tương đối lớn có thể dẫn đến giảm tốc ngay cả với tỷ lệ chấp nhận cao.

Tác động Rộng hơn
Mặc dù LLM đã chứng minh hiệu suất đặc biệt và trở thành trợ lý hữu ích trong thế giới thực gần đây, nhu cầu tính toán khổng lồ của LLM cấm hầu hết người dùng bao gồm các nhà nghiên cứu tiềm năng từ triển khai cục bộ, những người thường thay đổi để sử dụng API từ các dịch vụ LLM. Do đó, các phương pháp hiệu quả, bao gồm SCD của chúng tôi, để cải thiện tốc độ và chất lượng từ góc độ suy luận giải mã có nhiều tiềm năng để nâng cao các dịch vụ dựa trên LLM.

Tài liệu tham khảo
[Danh sách tài liệu tham khảo được giữ nguyên định dạng gốc]

A Chi tiết Thí nghiệm
A.1 Chi tiết Benchmark
(1) WikiText (Merity et al., 2016) chứa các bài viết từ Wikipedia. Chúng tôi tuân theo các script tiền xử lý từ Li et al. (2023a) và có 1,733 mẫu. Việc tạo sinh bắt đầu với 32 token đầu tiên làm prompt, và độ dài tạo sinh tối đa được đặt thành 256. Chúng tôi báo cáo diversity, MAUVE (Pillutla et al., 2021), và coherence làm metric, tuân theo Li et al. (2023a).

Metric diversity đánh giá các multi-gram duy nhất trong completion được tạo từ LM. Điểm diversity cao hơn cho thấy đa dạng từ vựng tốt hơn trong completion. Diversity được tính theo:
Div.=4∏(n=2 to 4)|Set(n-grams)|/|n-grams|.

MAUVE là một metric được đề xuất bởi Pillutla et al. (2021), được đề xuất thực nghiệm có sự đồng thuận tốt hơn với chú thích của con người (Gao and Wan, 2022). Coherence đánh giá tương quan ngữ nghĩa giữa tiền tố đầu vào và tạo sinh đầu ra thông qua độ tương tự của embedding. Chúng tôi sử dụng sentence embedding tuân theo SimCSE (Gao et al., 2021) và điểm coherence được tính như:
emb(xprefix)·emb(xgen)/(∥emb(xprefix)∥∥emb(xgen)∥).

(2) GSM8k (Cobbe et al., 2021) chứa các tập huấn luyện và đánh giá của các bài toán lý luận toán học cấp lớp. Chúng tôi đầu tiên fine-tune Llama2 7B và Llama2 70B bằng 3 epoch để tạo ra LM nghiệp dư và chuyên gia. Chúng tôi báo cáo độ chính xác cuối cùng của các tập test.

(3) HumanEval (Chen et al., 2021) đo độ chính xác mã hóa để tổng hợp chương trình từ 164 doc-string. Chúng tôi báo cáo tỷ lệ pass 1-round (Pass@1).

(4) AlpacaEval (Li et al., 2023b) chứa 805 mẫu từ các tập đánh giá khác nhau để đánh giá khả năng căn chỉnh của LLM bằng cách so sánh các mô hình được đánh giá với text-davinci-003. Chúng tôi báo cáo tỷ lệ thắng được đánh giá bởi GPT-4.

A.2 Chi tiết Cấu hình
Chúng tôi sử dụng Llama2 7B làm mô hình nghiệp dư trong khi Llama2 70B làm mô hình chuyên gia trên benchmark WikiText và HumanEval để đánh giá cách SCD hoạt động với các mô hình pre-train. Sau đó, chúng tôi fine-tune Llama2 7B và Llama2 70B trên tập huấn luyện GSM8k để đánh giá hiệu suất SCD với các mô hình fine-tune có giám sát trên tác vụ lý luận toán học. Chúng tôi cũng áp dụng Llama2chat 7B và Llama2chat 70B trên AlpacaEval để đánh giá LLM cho căn chỉnh con người bằng SCD. Chúng tôi đặt nhiệt độ softmax nhất quán thành 0.7 trên WikiText và AlpacaEval trong khi 0.001 trên các benchmark khác. Trong SCD và SD, chúng tôi luôn đặt nhiệt độ dự đoán từ LM nghiệp dư thành 1.0 để so sánh công bằng. Tất cả thí nghiệm được tiến hành trên 2 GPU A100 80G với triển khai KV cache.

A.3 Chi tiết Siêu tham số
Chúng tôi tiến hành tìm kiếm lưới liên quan đến α và β cho hiệu suất tốt nhất của CD và SCD. Các cài đặt siêu tham số tốt nhất cho kết quả trong Bảng 1 được liệt kê trong Bảng 2.

B Chứng minh Định lý 5.1
Định lý B.1. Yếu tố tăng tốc mong đợi trong thời gian chạy giải mã là (1−λγ+1)/((1−λ)(1+cγ+cλγ)).

Chứng minh. Tương tự như Định lý 3.8 trong Leviathan et al. (2022), cho tỷ lệ chấp nhận token λ và thời gian chạy mỗi bước tính toán thuận cho Me và Ma là T và cT. Tổng thời gian chạy yêu cầu cho mỗi lần lặp là T+cγT+cλγT, trong đó Ma yêu cầu γ bước tạo sinh và có thể một bước tính toán thuận bổ sung nếu tất cả γ token được chấp nhận trong khi Ma yêu cầu một tính toán thuận để kiểm tra tính hợp lệ token. Tuân theo Phương trình (1) trong Leviathan et al. (2022), số token được tạo mong đợi mỗi lần lặp là (1−λγ+1)/(1−λ). Do đó, thời gian chạy mong đợi cần thiết của SCD là ((1−λ)/(1−λγ+1))(T+cγT+cλγT), do đó yếu tố tăng tốc mong đợi là (1−λγ+1)/((1−λ)(1+cγ+cλγ)).

C Nghiên cứu Tình huống
Nghiên cứu Tình huống trên GSM8k
Judy dạy 5 lớp dance, mỗi ngày, vào các ngày trong tuần và 8 lớp vào thứ Bảy. Nếu mỗi lớp có 15 học sinh và cô ấy tính phí $15.00 mỗi học sinh, cô ấy kiếm được bao nhiều tiền trong 1 tuần?

Phản hồi
[Token ĐỎ và XANH được tạo bởi LM chuyên gia sau khi từ chối và tất cả chấp nhận, tương ứng. Các token khác được tạo bởi LM nghiệp dư.]
Cô ấy dạy 5 lớp mỗi ngày trong tuần nên đó là 5*5 = «5*5=25»25 lớp
Cô ấy dạy 25 lớp ngày trong tuần và 8 lớp thứ Bảy tổng cộng 25+8 = «25+8=33»33 lớp
Mỗi lớp có 15 học sinh nên cô ấy dạy 15*33 = «15*33=495»495 học sinh trong 1 tuần
Cô ấy tính phí $15.00 mỗi học sinh và cô ấy dạy 495 học sinh nên cô ấy kiếm 15*495 = $«15*495=7425.00»7,425.00 trong 1 tuần

Trong trường hợp này, chúng ta có thể thấy rằng các token bị từ chối và lấy mẫu lại thường là phần đầu của câu, số, phép toán, hoặc thực thể được đặt tên, thường là các token thông tin trong chuỗi lý luận suy nghĩ. Điều này cũng cho thấy rằng cải thiện chất lượng bắt nguồn từ việc lấy mẫu lại các token thông tin bằng phân phối token đối lập trong khi tăng tốc đến từ dự đoán suy đoán của LM nghiệp dư.

D Kết quả Bổ sung

[Hình 4: Phân tích siêu tham số về yếu tố tăng tốc mong đợi liên quan đến tỷ lệ chấp nhận thực nghiệm λ. Các cài đặt siêu tham số tốt nhất như trong Bảng 1 là các đường được đánh dấu bằng tam giác.]

[Hình 5: Độ nhạy hiệu suất liên quan đến α và β.]

# 2309.15038.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/contrastive/2309.15038.pdf
# Kích thước file: 3598936 bytes

===============================================
NỘI DUNG FILE PDF
===============================================

--- TRANG 1 ---
TẠP CHÍ CÁC FILE LỚP LATEX, TẬP 14, SỐ 8, THÁNG 8 2021 1
HPCR: Tái diễn Tương phản Dựa trên Proxy Toàn diện
cho Học liên tục Trực tuyến
Huiwei Lin, Shanshan Feng, Baoquan Zhang, Xutao Li, và Yunming Ye

Tóm tắt —Học liên tục trực tuyến, nhằm phát triển một
mạng neural liên tục học dữ liệu mới từ một lần duyệt qua
luồng dữ liệu trực tuyến, thường gặp phải vấn đề quên thảm khốc.
Các phương pháp dựa trên tái diễn hiện có làm giảm sự quên
bằng cách tái diễn một phần dữ liệu cũ theo cách tái diễn dựa trên
proxy hoặc dựa trên tương phản, mỗi cách có nhược điểm riêng.
Công trình trước đây của chúng tôi đề xuất một phương pháp
dựa trên tái diễn mới được gọi là tái diễn tương phản dựa trên
proxy (PCR), xử lý các nhược điểm bằng cách đạt được lợi
thế bổ sung của cả hai cách tái diễn. Trong công trình này,
chúng tôi tiếp tục phân tích gradient và hạn chế của PCR.
Kết quả phân tích cho thấy PCR vẫn có thể được cải thiện
thêm về khả năng trích xuất đặc trưng, khái quát hóa và
chống quên của mô hình. Do đó, chúng tôi phát triển một
phương pháp tiên tiến hơn có tên là tái diễn tương phản dựa
trên proxy toàn diện (HPCR). HPCR bao gồm ba thành phần,
mỗi thành phần giải quyết một trong những hạn chế của PCR.
Thành phần tương phản có điều kiện kết hợp các cặp neo-mẫu
vào PCR, cải thiện khả năng trích xuất đặc trưng. Thứ hai
là thành phần nhiệt độ tách hệ số nhiệt độ thành hai phần
dựa trên tác động gradient của chúng và đặt các giá trị khác
nhau cho chúng để tăng cường khả năng khái quát hóa. Thứ ba
là thành phần chưng cất hạn chế quá trình học với các thành
phần mất mát bổ sung để cải thiện khả năng chống quên.
Thí nghiệm trên bốn bộ dữ liệu nhất quán chứng minh tính
ưu việt của HPCR so với các phương pháp tiên tiến khác.

Từ khóa Chỉ mục —Mạng Neural, Học liên tục Trực tuyến,
Quên Thảm khốc, Phân loại Hình ảnh.

I. GIỚI THIỆU

HỌC liên tục trực tuyến (OCL) là một tình huống đặc biệt
của học liên tục [1]. Lấy vấn đề phân loại [2] làm ví dụ,
OCL nhằm phát triển một mạng neural có thể tích lũy kiến thức
về các lớp mới mà không quên thông tin đã học từ các lớp cũ.
Điều cần thiết là lưu ý rằng luồng dữ liệu gặp phải trong OCL
là không dừng, với mỗi mẫu chỉ được truy cập một lần trong
quá trình huấn luyện. Hiện tại, thách thức chính của OCL là
quên thảm khốc (CF) [3], trong đó mô hình trải qua sự suy giảm
đáng kể về hiệu suất cho các lớp cũ khi học các lớp mới [4].

Các phương pháp dựa trên tái diễn [5], tái diễn một phần
các mẫu trước đây, đã cho thấy hiệu suất vượt trội cho OCL [6].
Nói chung, có hai cách để tái diễn như được hiển thị trong
Hình 1(a). Cách thứ nhất là cách tái diễn dựa trên proxy,
tái diễn sử dụng hàm mất mát dựa trên proxy và bộ phân loại
softmax. Nó tính toán độ tương tự giữa mỗi neo và các proxy
thuộc về tất cả các lớp. Ở đây, một proxy có thể được coi là
đại diện của một lớp [7], và neo đại diện cho một mẫu trong
một lô huấn luyện. Cách này phải chịu vấn đề "thiên vị" do
mất cân bằng lớp [5]. Cách thứ hai là cách tái diễn dựa trên
tương phản, tái diễn sử dụng hàm mất mát dựa trên tương phản
và bộ phân loại trung bình lớp gần nhất (NCM) [8]. Nó tính toán
độ tương tự giữa mỗi neo và tất cả các mẫu trong cùng một lô
huấn luyện. Cách này không ổn định và khó hội tụ trong quá
trình huấn luyện. Tóm lại, hai cách này có các nhược điểm tương ứng.

Công trình trước đây của chúng tôi [9] đề xuất phương pháp
tái diễn tương phản dựa trên proxy (PCR) để xử lý những nhược điểm này.
Cụ thể, chúng tôi thực hiện phân tích toàn diện và thấy rằng việc
kết hợp cả hai cách tái diễn đạt được lợi thế bổ sung. Cách tái diễn
dựa trên proxy cho phép hội tụ nhanh và đáng tin cậy với sự trợ giúp
của proxy, từ đó khắc phục các vấn đề về không ổn định và khó
hội tụ trong cách tái diễn dựa trên tương phản. Trong khi đó, cách
tái diễn dựa trên tương phản có thể cung cấp cho cách tái diễn dựa
trên proxy một cách mới để chọn các cặp neo-proxy, đã được chứng
minh là hiệu quả trong việc giải quyết vấn đề "thiên vị" [10], [11].
Với những cảm hứng này, PCR tính toán độ tương tự giữa mỗi neo
và các proxy có các lớp liên quan của mẫu xuất hiện trong cùng
một lô như được minh họa trong Hình 1(a).

Trong công trình này, chúng tôi tiến hành phân tích sâu về PCR
và khám phá tiềm năng cải thiện của nó. Cụ thể, chúng tôi rút ra
quá trình truyền gradient của PCR trong bộ phân loại dựa trên
quá trình truyền cho mất mát dựa trên proxy tổng quát. Phân tích
gradient cho thấy PCR được hưởng lợi từ số lượng mẫu của các
lớp khác nhau trong mỗi lô huấn luyện, tiếp tục xác nhận tính
hiệu quả và độ tin cậy của nó. Tuy nhiên, phân tích hạn chế của
chúng tôi tiết lộ rằng PCR vẫn có nhược điểm trong ba lĩnh vực chính:
1) PCR xem xét các quan hệ giữa các cặp neo-proxy nhưng bỏ qua
các quan hệ giữa các cặp neo-mẫu. Điều này dẫn đến khả năng
trích xuất đặc trưng không đủ của mô hình, đặc biệt trong các
tình huống với các lô huấn luyện lớn trong đó các cặp neo-mẫu
chứa thông tin ngữ nghĩa quan trọng.

--- TRANG 2 ---

2) Việc thiết lập đơn giản của hệ số nhiệt độ trong PCR bỏ qua
tác động của nó lên quá trình truyền gradient. Sự bỏ qua này
làm suy yếu khả năng khái quát hóa của mô hình, vì việc sử dụng
một hằng số tĩnh không thể tối ưu hóa hiệu quả. 3) Các lớp cũ
được bao gồm trong quá trình học cùng với các lớp mới vẫn tiếp
tục gặp phải vấn đề thiên vị trong quá trình huấn luyện. Điều này
ngụ ý rằng vẫn còn chỗ để cải thiện khả năng chống quên của
mô hình. Do đó, PCR có thể được tăng cường bằng cách khắc phục
những hạn chế này.

Để đạt được mục tiêu này, chúng tôi phát triển một phương pháp
toàn diện hơn có tên là tái diễn tương phản dựa trên proxy toàn
diện (HPCR). Như được minh họa trong Hình 1(b), HPCR bao gồm
ba thành phần. 1) Thành phần tương phản kết hợp các cặp neo-mẫu
có điều kiện vào PCR để cải thiện khả năng trích xuất đặc trưng
của mô hình, nắm bắt thông tin ngữ nghĩa chi tiết hơn khi xử lý
các lô huấn luyện lớn. Cụ thể, chúng tôi giới thiệu một hàm bước
s(N) để điều chỉnh tầm quan trọng của các cặp neo-mẫu. Khi số
lượng mẫu nhỏ, đóng góp của chúng được đặt là 0; ngược lại,
nó là 1. 2) Trong khi đó, thành phần nhiệt độ tách hệ số nhiệt độ
thành hai phần dựa trên ảnh hưởng của chúng lên gradient. Một
phần được gán giá trị hằng số tĩnh, trong khi phần khác được
ký hiệu là giá trị hàm động để tăng cường khả năng khái quát hóa,
thúc đẩy việc tiếp thu kiến thức mới. 3) Ngoài ra, thành phần chưng
cất áp đặt thêm các ràng buộc lên quá trình tái diễn để tăng cường
khả năng chống quên, bảo tồn nhiều kiến thức lịch sử hơn. Thành
phần này bao gồm hai cơ chế chưng cất kiến thức (KD): chưng cất
tương phản dựa trên proxy (PCD) và chưng cất tương phản dựa
trên mẫu (SCD). Cơ chế đầu tiên chưng cất các tương quan neo-proxy
cũ vào các tương quan mới, trong khi cơ chế sau hạn chế các tương
quan neo-mẫu mới dựa trên các tương quan cũ.

Đóng góp chính của chúng tôi có thể được tóm tắt như sau:

1) Chúng tôi thực hiện phân tích sâu hơn về PCR. Phân tích
gradient xác minh tính hiệu quả và độ tin cậy của PCR,
trong khi phân tích hạn chế cho thấy PCR vẫn có ba hạn chế
và có thể được cải thiện thêm.

2) Chúng tôi phát triển một phương pháp toàn diện hơn dựa
trên PCR, có tên HPCR, bao gồm một thành phần tương phản,
một thành phần nhiệt độ và một thành phần chưng cất. Ba
thành phần này cải thiện khả năng trích xuất đặc trưng, khái
quát hóa và chống quên của mô hình, tương ứng.

3) Chúng tôi tiến hành thí nghiệm rộng rãi trên bốn bộ dữ liệu,
và kết quả thực nghiệm nhất quán chứng minh tính ưu việt
của HPCR so với các phương pháp tiên tiến khác. Chúng tôi
cũng điều tra và phân tích lợi ích của từng thành phần bằng
các nghiên cứu phá hủy. Và mã nguồn được công khai tại
https://github.com/FelixHuiweiLin/PCR.

Công trình này là phần mở rộng của phiên bản hội nghị
được trình bày trong [9]. Nó cung cấp một cách tiếp cận toàn
diện hơn, có thể được phân định thành bốn khía cạnh: (i) Phiên
bản này bao gồm phân tích gradient của PCR, làm tăng cường
nền tảng lý thuyết và giúp chúng tôi khám phá các hạn chế
của nó. (ii) Phiên bản này có điều kiện tích hợp các cặp neo-mẫu
vào PCR để tăng cường khả năng trích xuất đặc trưng của mô
hình, coi nó như một thành phần tương phản. (iii) Phiên bản
này giới thiệu một thành phần nhiệt độ để tăng cường khả năng
khái quát hóa của mô hình và một thành phần chưng cất để cải
thiện khả năng chống quên của mô hình. (iv) Hơn nữa, nhiều
thí nghiệm được tiến hành để khám phá phương pháp được đề
xuất, bao gồm việc sử dụng bộ dữ liệu mới (Split TinyImageNet),
tiến hành các nghiên cứu phá hủy bổ sung và trực quan hóa.

--- TRANG 3 ---

II. NGHIÊN CỨU LIÊN QUAN

A. Học liên tục

Có nhiều thiết lập học liên tục đã được thảo luận gần đây [12].
Đầu tiên, học liên tục có thể được chia thành thiết lập dựa trên
nhiệm vụ và không có nhiệm vụ. Học liên tục dựa trên nhiệm vụ
[13], [14] giả định rằng task-ID có thể có sẵn trong khi mạng
trong học liên tục không có nhiệm vụ [15] không có quyền truy
cập vào task-ID tại thời điểm suy luận. Tiếp theo, học liên tục
có thể được phân loại thành thiết lập ngoại tuyến và trực tuyến.
Dưới thiết lập ngoại tuyến [16], tất cả các mẫu huấn luyện trong
giai đoạn học hiện tại có thể được học với nhiều bước huấn luyện.
Ngược lại, mỗi mẫu huấn luyện trong dữ liệu truyền chỉ được
nhìn thấy một lần cho thiết lập trực tuyến [6]. Cuối cùng, theo
[17], học liên tục cũng có thể được tách thành thiết lập nhiệm vụ
rời rạc và nhiệm vụ mờ. Thiết lập nhiệm vụ rời rạc yêu cầu rằng
giao điểm của các tập nhãn của bất kỳ hai giai đoạn học nào
là một tập rỗng [18]. Thiết lập nhiệm vụ mờ đã được đề xuất
để đặt một số mẫu chung cho các mẫu huấn luyện của mỗi giai
đoạn học [19].

Năm hướng chính thúc đẩy những tiến bộ gần đây trong học
liên tục. 1) Các phương pháp dựa trên kiến trúc chia mỗi nhiệm
vụ thành một tập các tham số cụ thể của mô hình. Chúng mở
rộng mô hình một cách động khi nhiệm vụ tăng lên [20] hoặc
dần dần đóng băng một phần tham số để khắc phục vấn đề quên
[21]. 2) Các phương pháp dựa trên chính quy hóa lưu trữ thông
tin lịch sử đã học từ dữ liệu cũ như kiến thức tiên nghiệm của
mạng. Nó củng cố kiến thức quá khứ bằng cách mở rộng hàm
mất mát với một thành phần chính quy hóa bổ sung [22], [23].
3) Các phương pháp dựa trên tái diễn, thiết lập một bộ đệm bộ
nhớ có kích thước cố định [24] hoặc mô hình sinh [25], [26],
[27] để lưu trữ, tạo ra và tái diễn các mẫu lịch sử trong quá
trình huấn luyện. Một số lượng lớn các cách tiếp cận [28], [29]
đã được đề xuất để cải thiện hiệu suất của việc tái diễn. Thay vì
tái diễn mẫu, một số cách tiếp cận [30], [31] tập trung vào việc
tái diễn đặc trưng. 4) Các phương pháp dựa trên prompt, như
S-prompt [32], L2P [33], Dualprompt [34], và CODA-Prompt [35]
sử dụng việc học prompt dựa trên mô hình được huấn luyện trước,
thể hiện hiệu suất tốt hơn. 5) Các phương pháp dựa trên tối ưu
hóa ràng buộc rõ ràng quá trình cập nhật tham số. Một ý tưởng
điển hình là phép chiếu gradient [36], [37], [38] chiếu gradient
gốc theo hướng cụ thể để cập nhật tham số hiệu quả hơn. Nó
khác với các phương pháp dựa trên tái diễn hạn chế gradient
bằng cách tái diễn các mẫu cũ.

Trong công trình này, thiết lập là học liên tục trực tuyến dựa
trên thiết lập nhiệm vụ rời rạc với quy trình không có nhiệm vụ.
HPCR được đề xuất như một phương pháp dựa trên tái diễn mới
để giải quyết vấn đề quên. Khác với các phương pháp dựa trên
tái diễn tổng quát, HPCR được sử dụng để nhanh chóng học
kiến thức mới và giữ lại kiến thức lịch sử một cách hiệu quả
theo cách trực tuyến.

B. Học liên tục trực tuyến

OCL là một lĩnh vực phụ của học liên tục tập trung vào việc
học hiệu quả từ một lần duyệt qua luồng dữ liệu trực tuyến.
Nó rất cần thiết trong các tình huống trong đó mô hình cần
liên tục phát triển kiến thức và thích nghi với thông tin mới [6].
Các nhà nghiên cứu trong lĩnh vực này tập trung vào việc phát
triển thuật toán và kỹ thuật để giảm thiểu sự quên thảm khốc,
kiểm soát việc thích nghi mô hình và sử dụng hiệu quả tài nguyên
hạn chế để đạt được việc học liên tục này. Hiện tại, các phương
pháp dựa trên tái diễn là giải pháp chính của OCL mà không có
AOP [39], dựa trên phép chiếu trực giao. Mặc dù các phương pháp
dựa trên kiến trúc có thể hiệu quả cho học liên tục, chúng thường
không thực tế cho OCL. Vì không khả thi cho số lượng lớn các
nhiệm vụ [40] bởi "kiến trúc mạng tăng dần". Trong khi đó, biết
rằng các phương pháp dựa trên chính quy hóa cho thấy hiệu suất
kém trong OCL vì khó thiết kế một thước đo hợp lý để đo tầm
quan trọng của tham số [40].

Tái diễn kinh nghiệm (ER) [41] sử dụng lấy mẫu hồ chứa
cho quản lý bộ nhớ thường là một chiến lược mạnh. Nhiều phương
pháp tiếp theo đã được cải thiện dựa trên phương pháp này và
nói chung có thể được chia thành ba nhóm. 1) Một số cách tiếp
cận thuộc về chiến lược truy xuất bộ nhớ, thường nghiên cứu
cách chọn các mẫu quan trọng hơn từ bộ đệm để tái diễn. Các
phương pháp đại diện này bao gồm MIR [42] sử dụng sự gia tăng
mất mát, và ASER [43] sử dụng giá trị shapley đối nghịch. 2)
Trong khi đó, một số cách tiếp cận [44], [45] tập trung vào việc
lưu các mẫu hiệu quả hơn vào bộ đệm bộ nhớ, thuộc về chiến
lược cập nhật bộ nhớ. Cốt lõi của loại phương pháp này là sử
dụng các mẫu hạn chế trong bộ đệm để xấp xỉ tất cả các mẫu
trước đó càng nhiều càng tốt. 3) Ngoài việc chọn các mẫu quan
trọng, việc tiến hành huấn luyện chống quên hiệu quả cũng quan
trọng không kém. Chiến lược cập nhật mô hình là một họ các
phương pháp [46], [47], [11], [48], [49], [50], [51], [52], [53],
[54], [55] để cải thiện hiệu quả học, làm cho mô hình học nhanh
và hiệu quả về bộ nhớ. Tất cả chúng đều thuộc về cách tái diễn
dựa trên proxy ngoại trừ SCR [46], sử dụng cách tái diễn dựa
trên tương phản.

HPCR được đề xuất trong công trình này là một chiến lược
cập nhật mô hình mới cho OCL. Khác với các cách tiếp cận hiện
có, nó là một phương pháp toàn diện và hiệu quả hơn được đề
xuất dựa trên PCR. Sau khi tiến hành phân tích sâu về PCR,
HPCR cải thiện khả năng trích xuất đặc trưng, khái quát hóa và
chống quên của mô hình với ba thành phần, làm cho PCR phù
hợp hơn với OCL so với các nghiên cứu trước đây.

C. Học Metric Sâu

Tương tự như [7], phương pháp của chúng tôi được lấy cảm
hứng từ học metric sâu. Học metric sâu nhằm đo lường độ tương
tự giữa các mẫu bằng một mạng neural sâu trong khi sử dụng
một metric khoảng cách tối ưu cho các nhiệm vụ học [56]. Nói
chung, các hàm mất mát cho nhiệm vụ học này có thể được phân
loại thành mất mát dựa trên cặp và dựa trên proxy. Một mặt,
các phương pháp dựa trên cặp [57], [58] có thể khai thác thông
tin ngữ nghĩa phong phú từ các quan hệ neo-mẫu, nhưng hội tụ
chậm do độ phức tạp huấn luyện cao. Vì mất mát dựa trên tương
phản giỏi trong việc học các cặp neo-mẫu, nó có thể được coi
là một loại phương pháp dựa trên cặp. Mặt khác, các phương
pháp dựa trên proxy [59], [60] hội tụ nhanh và ổn định, trong
khi đó có thể bỏ lỡ thông tin ngữ nghĩa một phần bằng cách học
các quan hệ neo-proxy. Mất mát cross-entropy có thể được coi
là một loại phương pháp dựa trên proxy.

HPCR được đề xuất trong công trình này tích hợp hai loại
phương pháp này. Khác với các nghiên cứu hiện có, HPCR được
đề xuất để nhanh chóng học kiến thức mới và giữ lại kiến thức
lịch sử hiệu quả cho OCL.

--- TRANG 4 ---

BẢNG I
ĐẶC ĐIỂM CỦA CÁC CÁCH TÁI DIỄN DỰA TRÊN PROXY VÀ DỰA TRÊN TƯƠNG PHẢN.

Cách tái diễn | Bộ phân loại | Cặp mất mát | Ưu điểm | Nhược điểm
---|---|---|---|---
Dựa trên proxy | Softmax | Tất cả cặp Neo-proxy | Hội tụ nhanh, Ổn định | Thiên vị, Kiến thức ngữ nghĩa không hoàn chỉnh
Dựa trên tương phản | NCM | Cặp Neo-mẫu có chọn lọc | Tránh thiên vị, Kiến thức ngữ nghĩa hoàn chỉnh | Hội tụ chậm, Không ổn định

III. NỀN TẢNG

A. Học liên tục trực tuyến

OCL chia một luồng dữ liệu thành một chuỗi các nhiệm vụ học
là D={Dt}T t=1, trong đó Dt={Xt×Yt,Ct} chứa các mẫu Xt,
nhãn tương ứng Yt, và các lớp cụ thể của nhiệm vụ Ct. Các
nhiệm vụ khác nhau không có sự chồng chéo trong các lớp.
Tất cả các lớp đã học được ký hiệu là C1:t=∪t k=1Ck. Mạng
neural được tạo thành từ một bộ trích xuất đặc trưng z=h(x;Φ)
và một bộ phân loại softmax (dựa trên proxy) o=f(z;W)=[oc]C1:t c=1 [61],
trong đó oc=⟨z,wc⟩/τ là giá trị thứ i của o, ⟨·,·⟩ là độ tương tự
cosin, τ là hệ số tỷ lệ và W=[w1,w2,...,wc] chứa các proxy
có thể huấn luyện của tất cả các lớp. Xác suất phân loại rằng
mẫu x thuộc về lớp y là py=exp(oy)/∑c∈C1:t exp(oc). (1)

Nói chung, mô hình học mỗi mini-batch các mẫu hiện tại B⊂Dt
bằng hàm mất mát sau đây L=E(x,y)∼B[−log(py)]. (2)

Trong trường hợp này, mô hình có thể học các lớp mới tốt và
quên các lớp cũ, dẫn đến vấn đề quên. Để giảm thiểu sự quên,
các phương pháp dựa trên tái diễn hiện có tái diễn một phần
các mẫu trước đây theo hai cách.

Đầu tiên, các cách tái diễn dựa trên proxy (như ER [41]) chọn
một mini-batch các mẫu trước đây BM⊂M để tính toán mất mát
dựa trên proxy bằng LER=E(x,y)∼B∪BM[−log(exp(oy)/∑c∈C1:t exp(oc))], (3)
trong đó M là một bộ đệm bộ nhớ để lưu trữ một phần các mẫu
trước đây. Và nó dự đoán các thực thể không biết bằng một bộ
phân loại softmax y*=arg max c pc, c∈C1:t. (4)

Hơn nữa, các cách tái diễn dựa trên proxy khác [10], [11] cải
thiện ER bằng cách chọn một phần các cặp neo-proxy để tính toán
hàm mục tiêu. Mặc dù hiệu quả, chúng có thể dễ dàng làm tổn
thương khả năng khái quát hóa của mô hình để học các lớp mới.

Thứ hai, các cách tái diễn dựa trên tương phản (như SCR [46])
tái diễn BM⊂M sử dụng mất mát dựa trên tương phản
LPCR=E(x,y)∼B∪BM[−(1/|P|)∑p∈P log(exp(⟨z,zp⟩/τ)/∑j∈J exp(⟨z,zj⟩/τ))]. (5)

Khác với mất mát dựa trên proxy, các cặp được chọn phụ thuộc
vào số lượng mẫu trong một lô huấn luyện. Và nó suy luận bằng
một bộ phân loại NCM y*=arg min c ∥z−μc∥, c∈C1:t, (6)

Để có được các trung tâm phân loại μc của tất cả các lớp, nó
phải tính toán các embedding của tất cả các mẫu trong bộ đệm
bộ nhớ trước mỗi lần suy luận. Do độ phức tạp cao của huấn
luyện, hiệu quả của nó không ổn định và tốc độ hội tụ chậm.

B. Tái diễn tương phản dựa trên Proxy

Công trình trước đây của chúng tôi [9] phân tích các nghiên cứu
hiện có và đề xuất kết hợp hai cách tái diễn, đạt được lợi thế
bổ sung. Các đặc điểm của hai cách tái diễn này được tóm tắt
trong Bảng I. Một mặt, các cặp neo-proxy của cách tái diễn dựa
trên proxy có thể khắc phục nhược điểm của mất mát dựa trên
tương phản. Mặt khác, mất mát dựa trên tương phản cung cấp
một cách heuristic để chọn các cặp neo-proxy cho cách tái diễn
dựa trên proxy. Hơn nữa, các cặp neo-mẫu chứa kiến thức ngữ
nghĩa chi tiết phong phú hơn so với các cặp neo-proxy.

Mặc dù có một số giải pháp kết hợp, chúng không thể giải quyết
vấn đề quên hoàn toàn. Ví dụ, cách trực quan nhất là thêm các
hàm mất mát khác nhau như L1 couple=LER+LSCR. (7)

Đây là chiến lược hai giai đoạn cho học ngoại tuyến [62], không
phù hợp với OCL do yêu cầu về tính kịp thời. Cách khác là thêm
các cặp neo-mẫu vào mất mát cross-entropy như
L2 couple=E(x,y)∼B∪BM[−log(exp(oy)/(∑c∈C1:t exp(oc)+∑j∈J exp(⟨z,zj⟩/τ)))]. (8)

trong công trình [7]. Cả hai đều không thể tận dụng mỗi cách
tái diễn để giải quyết vấn đề quên của OCL. Vì chúng bỏ qua
rằng chìa khóa là chọn các cặp neo-proxy theo cách tương phản
và huấn luyện bằng các cặp được chọn.

Do đó, khung tái diễn tương phản dựa trên proxy (PCR) được
đề xuất bằng cách thay thế các mẫu của các cặp neo-mẫu bằng
proxy trong mất mát dựa trên tương phản. Cụ thể, mô hình được
huấn luyện bằng cách học các mẫu của các lớp mới và tái diễn
các mẫu của các lớp cũ trong quy trình huấn luyện. Đối với mỗi
bước, cho các mẫu hiện tại B, nó ngẫu nhiên truy xuất các mẫu
trước đây BM từ bộ đệm bộ nhớ. Bên cạnh đó, các mẫu này được
ghép nối lại với nhau cho lô huấn luyện. Sau đó, mô hình được
tối ưu hóa bằng
LPCR=E(x,y)∼B∪BM[−log(exp(oy)/∑c∈C1:t kc exp(oc))]. (9)

trong đó kc là số lượng mẫu thuộc về lớp c trong lô huấn luyện.
Khác với các nghiên cứu hiện có, cách tính xác suất phân loại
được thay đổi cho mỗi mini-batch. Cuối cùng, nó cập nhật bộ
đệm bộ nhớ bằng chiến lược lấy mẫu hồ chứa, có thể đảm bảo
rằng xác suất của mỗi mẫu được trích xuất là bằng nhau. Thuận
tiện, bộ đệm bộ nhớ có kích thước cố định, không quan trọng
lượng mẫu lớn như thế nào.

Quy trình suy luận khác với quy trình huấn luyện. Mỗi mẫu
kiểm tra xk thu được phân phối xác suất lớp của nó bằng Phương
trình (1). Và PCR thực hiện dự đoán suy luận cho xk với xác
suất cao nhất như y*k=arg max c pc, y∈C1:t. (10)

--- TRANG 5 ---

IV. PHÂN TÍCH CHO TÁI DIỄN TƯƠNG PHẢN DỰA TRÊN PROXY

A. Phân tích Gradient

Như đã nêu trong công trình trước đây [9], phân tích gradient
rất hữu ích trong việc khám phá các vấn đề quên và công trình
hiện có. Cụ thể, gradient của bộ phân loại softmax cho x là
∂L/∂⟨z,wc⟩=((py−1)/τ, c=y; (pc)/τ, c≠y). (11)

Huấn luyện x thuộc về lớp y cung cấp gradient dương
−η(py−1)/τ cho proxy của lớp y là ⟨z,wy⟩=⟨z,wy⟩−η(py−1)/τ,
và truyền gradient âm −η(pc)/τ cho các proxy khác là
⟨z,wc⟩=⟨z,wc⟩−η(pc)/τ, trong đó tốc độ học η là dương.
Nếu huấn luyện như Phương trình (2), các proxy của các lớp
mới nhận được nhiều gradient dương hơn và các proxy khác
nhận được nhiều gradient âm hơn. Điều này làm cho các proxy
của các lớp mới gần với các mẫu của các lớp mới, trong khi
các proxy của các lớp cũ xa với các mẫu của các lớp mới.
Do đó, dễ dàng phân loại hầu hết các mẫu vào các lớp mới,
gây ra vấn đề quên.

Nếu tái diễn như Phương trình (3), các proxy của các lớp
cũ có thể nhận được nhiều gradient dương hơn, và các proxy
của các lớp mới nhận được nhiều gradient âm hơn. Mặc dù
sự quên có thể được giảm thiểu, hiệu quả của nó vẫn bị hạn
chế bởi các mẫu mất cân bằng.

Để khám phá độ tin cậy của PCR, chúng tôi phân tích quá
trình truyền gradient của nó. Tương tự như Phương trình (11),
gradient của bộ phân loại cho một mẫu x trong PCR được nêu
như Định lý 1.

Định lý 1: Trong PCR, gradient cho tất cả các proxy là
∂LPCR/∂⟨z,wc⟩=((kyp*y−1)/τ, c=y; (kcp*c)/τ, c≠y), (12)
trong đó p*y=exp(oy)/∑c∈C1:t kjexp(oc). (13)

Khi tái diễn, số lượng lớp tương đối nhỏ và số lượng mẫu
tương đối lớn cho các lớp mới; số lượng lớp tương đối lớn
và số lượng mẫu tương đối nhỏ cho các lớp cũ. Điều này có
nghĩa là trong một lô huấn luyện, số lượng mẫu cho các lớp
mới có xu hướng bội số, trong khi số lượng cho các lớp cũ
có xu hướng nhỏ, hoặc thậm chí không tồn tại. Dựa trên tình
huống này, Phương trình (12) thể hiện hai lợi thế của PCR
cho việc chống quên.

Một mặt, gradient chỉ ảnh hưởng đến các lớp có các mẫu
liên quan tồn tại trong cùng một lô huấn luyện. Ví dụ, khi
học một mẫu hiện tại x thuộc về lớp y, gradient cho proxy
của lớp c (c≠y) là −η(kcp*c)/τ nếu có kc mẫu thuộc về lớp
c trong cùng một lô. Ngược lại, nếu kc=0, proxy của lớp c
không tham gia vào quá trình truyền gradient. Do xác suất
thấp hơn của các lớp cũ xuất hiện trong lô huấn luyện, các
proxy của các lớp cũ sẽ nhận được ít gradient âm hơn từ
các lớp mới. Do đó, mô hình sẽ giữ lại nhiều kiến thức lịch
sử hơn.

Điều khác là gradient có thể bị ảnh hưởng bởi số lượng mẫu
trong một lô huấn luyện. Thuận tiện, chúng tôi định nghĩa
sumy=∑c∈C1:t,c≠y kcexp(oc). (14)

Với biểu diễn này, Phương trình (12) có thể được thay đổi thành
∂LPCR/∂⟨z,wc⟩=((kyexp(oy)/(sumy+kyexp(oy))−1)/τ, c=y;
kcexp(oc)/(sumy+kyexp(oy))/τ, c≠y). (15)

Chúng tôi lấy lô huấn luyện bao gồm ki (ki≥1) mẫu của
lớp mới i và kj (kj=1) mẫu của các lớp cũ khác j làm ví dụ.
Huấn luyện lớp mới i truyền gradient như
∂LPCR/∂⟨z,wc⟩=(−sumi/(sumi+kiexp(oi))/τ, c=i;
exp(oc)/(sumi+kiexp(oi))/τ, c=j). (16)

Lúc này, ki càng lớn thì 1/(sumi+kiexp(oi)) càng nhỏ, và
giá trị gradient càng nhỏ. Điều này có nghĩa là ki lớn hơn
có thể giảm gradient dương cho proxy của lớp mới i và gradient
âm cho proxy của các lớp cũ j. Tương tự, huấn luyện bất kỳ
lớp cũ j nào truyền gradient như
∂LPCR/∂⟨z,wc⟩=((exp(oc)/(sumi+kiexp(oi))−1)/τ, c=j;
(1−sumi/(sumi+kiexp(oi)))/τ, c=i). (17)

Trong tình huống này, ki càng lớn thì 1/(sumi+kiexp(oi))
càng nhỏ, và giá trị gradient càng lớn. Với ki lớn hơn, cả
gradient dương cho lớp cũ j và gradient âm cho lớp mới i
đều có thể được tăng lên. Do đó, PCR giúp các lớp cũ có được
một số lợi thế trong việc truyền gradient, và hiệu quả truyền
gradient của các proxy được chọn này sẽ được cải thiện đáng kể.

B. Phân tích Hạn chế

Dựa trên phân tích gradient, chúng ta có thể thấy rằng PCR
có thể giúp mô hình làm giảm hiện tượng quên thảm khốc. Nó
chọn các proxy một phần thay vì tất cả để học các mẫu hiện
tại và tái diễn các mẫu trước đây. Trong cách học như vậy,
các lớp cũ có các mẫu liên quan không được chọn có thể tránh
được thiên vị do cạnh tranh gradient mất cân bằng.

Tuy nhiên, PCR vẫn chưa tối ưu do một số hạn chế chưa được
giải quyết. Thứ nhất, PCR độc quyền xem xét các quan hệ của
neo-proxy nhưng bỏ qua các quan hệ của neo-mẫu, dẫn đến
mô hình mất một số thông tin ngữ nghĩa quan trọng. Các cặp
neo-mẫu đóng vai trò quan trọng trong việc tăng cường khả
năng trích xuất đặc trưng của mô hình trong các lô huấn luyện
lớn, một khía cạnh quan trọng của PCR. Thứ hai, việc thiết lập
đơn giản của hệ số nhiệt độ τ trong PCR thiếu sự tinh tế. Vì
hệ số nhiệt độ ảnh hưởng đến quá trình truyền gradient của
PCR, việc sử dụng một hằng số tĩnh không đủ để đảm bảo
khả năng khái quát hóa của mô hình. Thứ ba, những lớp cũ
đã được chọn để học cùng với các lớp mới vẫn đối mặt với
vấn đề thiên vị trong quá trình huấn luyện. Điều này có nghĩa
là khả năng chống quên của mô hình vẫn có thể được cải thiện
thêm. Nói cách khác, PCR có thể được cải thiện thành một
cách tiếp cận toàn diện và hiệu quả hơn.

--- TRANG 6 ---

V. TÁI DIỄN TƯƠNG PHẢN DỰA TRÊN PROXY TOÀN DIỆN

Trong công trình này, chúng tôi phát triển một phương pháp
toàn diện và hiệu quả hơn gọi là tái diễn tương phản dựa trên
proxy toàn diện (HPCR). HPCR bao gồm một thành phần tương
phản, một thành phần nhiệt độ và một thành phần chưng cất,
giải quyết các hạn chế của PCR theo trình tự.

A. Thành phần Tương phản

Thành phần tương phản có điều kiện kết hợp các cặp neo-mẫu
vào PCR và cải thiện khả năng trích xuất đặc trưng của mô hình.
Các cặp neo-mẫu chứa thông tin ngữ nghĩa chi tiết phong phú
hơn so với các cặp neo-proxy. Mặc dù việc trích xuất các quan
hệ của neo-mẫu dễ bị hạn chế bởi số lượng mẫu trong một lô
huấn luyện, nó vẫn có thể đóng vai trò quan trọng khi kích thước
lô đủ lớn. Do đó, thành phần tương phản của HPCR được ký
hiệu là
LPCR C=E(x,y)∼B∪BM[−(1/|P|)∑p∈P log((exp(oy)+s(N)·exp(⟨z,zp⟩/τ))/
(∑c∈C1:t kcexp(oc)+∑j∈J s(N)·exp(⟨z,zj⟩/τ)))]. (18)

Ở đây, s(N) là một hàm bước tự định nghĩa được sử dụng để
kiểm soát tầm quan trọng của các cặp neo-mẫu, và nó được
định nghĩa là s(N)=(0, N<Nmin; 1, N≥Nmin). (19)

N là số lượng mẫu trong lô huấn luyện hiện tại, và Nmin là
một siêu tham số được sử dụng để xác định có sử dụng các cặp
neo-mẫu hay không. Khi kích thước của lô huấn luyện nhỏ,
tương quan giữa các mẫu dễ có nhiễu ảnh hưởng đến hiệu suất
của mô hình. Do đó, tầm quan trọng của chúng nên được đặt
là 0. Lúc này, PCR C thoái hóa thành PCR; ngược lại, tầm quan
trọng của các mẫu này nên được đặt là 1 để cải thiện khả năng
trích xuất đặc trưng của mô hình. So với PCR, PCR C không
chỉ có thể khai thác các quan hệ của neo-proxy mà còn khám
phá các quan hệ của neo-mẫu. Nó tăng khoảng cách giữa các
lớp cũng như giảm khoảng cách trong lớp.

B. Thành phần Nhiệt độ

1) Phân tích Hệ số Nhiệt độ: Trong Phương trình (12), quá
trình truyền gradient bị ảnh hưởng bởi τ, được gọi là hệ số
nhiệt độ. Trong một bộ phân loại dựa trên proxy, chuẩn của
các vector đã được chứng minh là không thân thiện với học
liên tục và do đó bị loại bỏ [61]. Tuy nhiên, độ tương tự của
các vector được giữ lại ⟨z,w⟩ có phạm vi giá trị [-1,1], mang
lại những khó khăn nhất định cho việc tối ưu hóa mô hình.
Do đó, τ trong p*c được sử dụng để kiểm soát cường độ của
⟨z,w⟩, điều này rất quan trọng để tìm ra giải pháp tối ưu.

Được lấy cảm hứng từ [63], chúng tôi định nghĩa một hình
phạt tương đối r(⟨z,wc⟩) trên proxy âm wc (c≠y) cho mẫu
(x,y) bằng r(⟨z,wc⟩)=|∂L/∂⟨z,wc⟩|/|∂L/∂⟨z,wy⟩|=
kcexp(oc)/∑j≠y kjexp(oj), c≠y. (20)

Nó có thể phản ánh cường độ hình phạt trên tất cả các mẫu
âm. Khi τ tăng, phân phối của r(⟨z,wc⟩) tương đối đồng đều,
và mô hình có xu hướng xử lý tất cả các proxy âm với cùng
một cường độ. Ngược lại, mô hình tập trung vào các proxy âm
với độ tương tự cao hơn khi τ giảm.

Hơn nữa, trong một khoảng hợp lý, τ nhỏ hơn phù hợp hơn
cho việc tái diễn các lớp cũ, trong khi τ lớn hơn hiệu quả hơn
cho việc học các lớp mới trong OCL. Nói chung, số lượng mẫu
trong các lớp cũ nhỏ, trong khi số lượng mẫu trong các lớp
mới lớn trong OCL. Điều này dẫn đến các mẫu của các lớp
cũ có nhiều khả năng trở thành các mẫu âm với khoảng cách
ngắn hơn, trong khi các mẫu của các lớp mới có xu hướng
trở thành các mẫu âm với khoảng cách lớn hơn. Kết quả là,
τ lớn sẽ thúc đẩy mô hình chú ý đến các mẫu của các lớp mới
với khoảng cách lớn hơn, làm cho dễ bỏ qua các mẫu từ các
lớp cũ. Ngược lại, τ nhỏ sẽ thúc đẩy mô hình tập trung vào
các mẫu của các lớp cũ với khoảng cách ngắn hơn, dẫn đến
mất thông tin từ các lớp mới.

Cuối cùng, như thấy trong Phương trình (12), τ ảnh hưởng
đến quá trình theo hai phần. Đầu tiên, nó trực tiếp thay đổi
giá trị của gradient bằng 1/τ (được ký hiệu là phần G). Thứ
hai, nó làm mịn phân phối xác suất p*c của các mẫu để điều
chỉnh gradient một cách gián tiếp (được ký hiệu là phần P).
Hơn nữa, phần P có tác động phức tạp hơn phần G do tính
phi tuyến mạnh hơn.

2) Ảnh hưởng của Hệ số Nhiệt độ: Hiệu suất của PCR sẽ
rất nhạy cảm với τ. Để xác thực quan điểm này, chúng tôi tiến
hành thí nghiệm cho PCR với các giá trị khác nhau của τ, và
kết quả được hiển thị trong Hình 2. Ngoài tỷ lệ chính xác
cuối cùng của tất cả các lớp, chúng tôi cũng báo cáo riêng
biệt của các lớp mới và cũ. Trong Hình 2(a), chúng tôi có thể
đưa ra các quan sát sau: 1) Hiệu suất của tất cả, cũ và mới
đều nhạy cảm với τ. Ví dụ, khi τ thay đổi từ 0.01 đến 0.2,
hiệu suất của PCR trong tất cả các khía cạnh sẽ tăng trước
rồi giảm. 2) Độ nhạy của các lớp cũ và mới đối với τ khác
nhau, và τ tốt nhất của chúng khác nhau. Hiệu suất trên các
lớp mới đạt kết quả tốt nhất khi τ∈[0.1,0.2] trong khi hiệu
suất trên các lớp cũ đạt kết quả tốt nhất khi τ∈[0.0,0.1].

Đồng thời, chúng tôi cũng thể hiện hiệu suất khi các τ khác
nhau được thực hiện trong các phần khác nhau. Trong Hình
2(b), các đường màu xanh lá cây, xanh dương và đỏ biểu thị
hiệu suất khi τ thay đổi trong phần G, phần P và cả hai phần.
Đối với phần G, chúng tôi giữ τ=0.09 cho p*c và chỉ thay đổi
giá trị của τ cho 1/τ. Ngược lại, τ được đặt là 0.09 cho 1/τ
và thay đổi từ 0.0 đến 0.5 trong phần P. So sánh kết quả của
hai trường hợp, chúng tôi thấy rằng hiệu suất của mô hình
nhạy cảm hơn với những thay đổi trong τ ở phần G. Trong khi
đó, mô hình thể hiện dao động lớn hơn khi τ đạt giá trị tối ưu
trong phần P. Mặc dù hiệu suất của phần P có vẻ ổn định với
những thay đổi trong τ, độ chính xác của mỗi lớp thực sự thay
đổi. Thuận tiện, chúng tôi báo cáo τ tốt nhất cho mỗi lớp trên
Split CIFAR10 trong phần P khi kích thước bộ đệm là 100.
Như được nêu trong Bảng II, để đạt được độ chính xác cao
nhất, giá trị của τ cho mỗi lớp là khác nhau. Nói cách khác,
việc thiết lập τ cho phần P là nhạy cảm, và một giá trị tĩnh
phù hợp hơn cho nó. Trong khi một giá trị động phù hợp hơn
cho phần G vì nó cho phép mô hình xem xét các lớp khác nhau.
Do đó, việc thiết lập τ cho hai phần này nên được tách rời.

--- TRANG 7 ---

3) Hệ số Nhiệt độ Tách rời: Để đạt mục tiêu này, chúng tôi
đặt các giá trị khác nhau của τ cho phần P và G riêng biệt.
Một mặt, vì hiệu suất của mô hình nhạy cảm hơn với phần P,
chúng tôi đặt nó thành một giá trị hằng số tĩnh. Trong khi đó,
chúng tôi thu được một giá trị vừa phải để cân bằng sự chú ý
của mô hình đối với các lớp mới và cũ bằng phương pháp tìm
kiếm lưới. Mặt khác, do τ tối ưu khác nhau cho mỗi lớp, chúng
tôi đặt một giá trị động cho phần G. Tuy nhiên, rất khó để
tìm ra τ tối ưu cho mỗi lớp tại bất kỳ thời điểm nào, vì yêu
cầu thời gian thực của OCL cao. Trong tình huống như vậy,
nhiệt độ động được đặt là một hàm mạnh mẽ độc lập với lớp,
và hàm được ký hiệu là
τ(s)=(τmax−τmin)×(1+cos(2πs/S))/2+τmin, (21)
trong đó s là bước hiện tại, S là độ dài chu kỳ, τmax là giới
hạn trên, và τmin là giới hạn dưới. Với một hàm động tuần
hoàn như vậy, mô hình có thể chọn một phạm vi rộng các giá
trị nhiệt độ khác nhau trong quá trình OCL. Nó cải thiện độ
chính xác của mỗi lớp và do đó tăng cường khả năng khái quát
hóa tổng thể của mô hình. Do đó, Phương trình (18) có thể
được cải thiện thành
LPCR CT=E(x,y)∼B∪BM[−(1/|P|)∑p∈P (τ/τ(s)) 
log((exp(oy)+s(N)·exp(⟨z,zp⟩/τ))/(∑c∈C1:t kcexp(oc)+∑j∈J s(N)·exp(⟨z,zj⟩/τ)))]. (22)

Hơn nữa, gradient tương ứng được biến đổi thành
∂LPCR CT/∂⟨z,wc⟩=((kyp*y−1)/τ(s), c=y; (kcp*c)/τ(s), c≠y). (23)

C. Thành phần Chưng cất

Như một phương pháp chưng cất kiến thức [64], DER [65] cố
gắng giữ lại đầu ra logits thu được từ mô hình trong quá trình
học như kiến thức lịch sử cho việc tái diễn mẫu. Điều này
nhằm cải thiện sự đa dạng của kiến thức lịch sử và tránh vấn
đề đơn điệu kiến thức gây ra bởi việc lưu các mô hình cũ để
lưu trữ kiến thức lịch sử. Tuy nhiên, DER hiện có phải sử dụng
tất cả các proxy để tính toán một hàm mất mát chưng cất. Nếu
chưng cất như DER, các proxy bị loại trừ bởi PCR sẽ tiếp tục
tham gia vào quá trình truyền gradient.

Để tránh tình huống này, chúng tôi đề xuất một phương pháp
chưng cất mới gọi là chưng cất tương phản dựa trên proxy (PCD).
Tương tự như PCR, xác suất phân loại trong PCD chỉ sử dụng
các proxy xuất hiện trong lô huấn luyện. Cụ thể, khi lưu một
mẫu hiện tại vào bộ đệm bộ nhớ, chúng tôi không chỉ lưu
thực thể x và nhãn y của nó mà còn lưu trữ đầu ra logits o*
của bộ phân loại. Nếu mẫu được chọn là một mẫu trước đây
để tái diễn, o* của nó có thể được sử dụng để giữ lại kiến thức
lịch sử phong phú hơn. Do đó, chúng tôi có thể tính toán mất
mát PCD bằng cách tối thiểu hóa khoảng cách Euclidean giữa
các logits có trọng số như
LPCD=E(x,y,o*)∼BM[−∑c∈C1:t kc(oc−o*c)2]. (24)

Ngoài chưng cất phân phối của các mẫu trước đây, chưng cất
quan hệ giữa các mẫu cũng cần thiết. Vì quan hệ của các mẫu
không chỉ phản ánh thông tin trong lớp mà còn bao gồm tương
quan giữa các lớp. Do đó, chúng tôi đề xuất tính toán chưng
cất tương phản dựa trên mẫu (SCD) bằng z* trong một lô huấn
luyện như
LSCD=E(x,y,z*)∼BM[−∑i∈J (exp(⟨z,zi⟩/τ)/∑j∈J exp(⟨z,zj⟩/τ))
log(exp(⟨z*,z*i⟩/τ)/∑j∈J exp(⟨z*,z*j⟩/τ))], (25)
trong đó J là tập chỉ số của các mẫu ngoại trừ neo x trong
cùng một lô BM. Với hai hàm mất mát chưng cất này, mô hình
có thể truyền nhiều gradient dương hơn cho các proxy của
các lớp cũ và nhiều gradient âm hơn cho các proxy của các
lớp mới. Kết quả là, khả năng chống quên của mô hình có thể
được cải thiện.

D. Quy trình Tổng thể

Kết hợp ba thành phần mới này, PCR sẽ được tăng cường
thành HPCR. So với PCR, HPCR sẽ cải thiện đáng kể khả năng
trích xuất đặc trưng, khái quát hóa và chống quên của mô hình
cùng lúc. Hàm mục tiêu của nó được ký hiệu là
LHPCR=LPCR CT+αLPCD+βLSCD, (26)

--- TRANG 8 ---

trong đó α và β là các siêu tham số tỷ lệ cho PCD và SCD,
tương ứng. Hơn nữa, toàn bộ quy trình huấn luyện và suy luận
của HPCR được tóm tắt trong Thuật toán 1. Những khác biệt
chính giữa PCR và HPCR nằm ở quy trình huấn luyện. Khác
biệt đầu tiên là trong bộ đệm bộ nhớ. Ngoài việc lưu các mẫu
cũ và các nhãn tương ứng, HPCR cũng lưu các logits và vector
đặc trưng thu được trong quá trình huấn luyện của các mẫu
cũ. Khác biệt thứ hai là trong hàm mất mát. Hàm mục tiêu
của HPCR tích hợp hơn, có lợi cho việc cải thiện toàn diện
hiệu suất tổng thể của mô hình.

VI. ĐÁNH GIÁ HIỆU SUẤT

A. Thiết lập Thí nghiệm

1) Bộ dữ liệu: Chúng tôi tiến hành thí nghiệm trên bốn bộ
dữ liệu nhận dạng hình ảnh để đánh giá. Split CIFAR10 [68]
được chia thành 5 nhiệm vụ, và mỗi nhiệm vụ chứa 2 lớp.
Split CIFAR100 [68] cũng như Split MiniImageNet [69] được
tổ chức thành 10 nhiệm vụ, và mỗi nhiệm vụ được tạo thành
từ các mẫu từ 10 lớp. Split TinyImageNet [70], chứa 200 lớp,
được chia thành 20 nhiệm vụ, và mỗi nhiệm vụ chứa 10 lớp.

2) Chỉ số Đánh giá: Chúng tôi cần đo lường hiệu suất của
mô hình cho OCL. Đầu tiên chúng tôi định nghĩa ai,j (j<=i)
là độ chính xác được đánh giá trên các mẫu kiểm tra được
giữ lại của nhiệm vụ thứ j sau khi mạng đã học các mẫu
huấn luyện trong i nhiệm vụ đầu tiên. Tương tự với [43],
chúng tôi có thể thu được thêm tỷ lệ chính xác trung bình
Ai=(1/i)∑j=1 đến i ai,j, (27)

tại nhiệm vụ thứ i. Nếu có T nhiệm vụ, chúng tôi có thể có
tỷ lệ chính xác cuối cùng AT và độ chính xác trung bình bất
kỳ lúc nào (AAA) AAA=(1/T)∑t=1 đến T At, (28)

đo lường hiệu suất của quá trình học [11]. Trong khi đó, chúng
tôi ký hiệu tỷ lệ quên trung bình là Fi=(1/(i-1))∑j=1 đến i-1 fi,j, (29)
trong đó fk,j=maxl∈{1,2,...,k-1}(al,j)−ak,j. Và FT tương
đương với tỷ lệ quên cuối cùng.

3) Chi tiết Triển khai: Thiết lập cơ bản của backbone giống
như công trình gần đây [11]. Chi tiết, chúng tôi lấy Reduced
ResNet18 (số lượng bộ lọc là 20) làm bộ trích xuất đặc trưng
cho tất cả các bộ dữ liệu. Bộ phân loại là bộ phân loại NCM
cho SCR và bộ phân loại softmax cho các phương pháp khác.
Trong giai đoạn huấn luyện, mạng, được khởi tạo ngẫu nhiên
chứ không phải được huấn luyện trước, được huấn luyện với
bộ tối ưu hóa SGD, và tốc độ học được đặt là 0.1. Đối với
tất cả các bộ dữ liệu, các lớp được xáo trộn trước khi phân
chia. Và chúng tôi đặt bộ đệm bộ nhớ với các kích thước khác
nhau cho tất cả các bộ dữ liệu. Mô hình nhận 10 mẫu hiện
tại từ luồng dữ liệu và 10 mẫu trước đây từ bộ đệm bộ nhớ
tại một thời điểm bất kể kích thước của bộ nhớ. Hơn nữa,
chúng tôi sử dụng sự kết hợp của các kỹ thuật tăng cường
khác nhau để có được các hình ảnh được tăng cường. Và việc
sử dụng tăng cường dữ liệu là công bằng cho tất cả các phương
pháp. Liên quan đến siêu tham số của PCR, chúng tôi chọn
chúng trên một tập xác thực thu được bằng cách lấy mẫu 10%
của tập huấn luyện. Đối với giai đoạn kiểm tra, chúng tôi đặt
256 làm kích thước lô xác thực.

B. Hiệu suất Tổng thể

Trong phần này, chúng tôi tiến hành thí nghiệm để so sánh
với các baseline tiên tiến khác nhau. Hiệu suất tổng thể của
PCR tiên tiến so với tất cả các baseline. Hơn nữa, HPCR đạt
được hiệu suất cải thiện đáng kể trên bốn bộ dữ liệu.

So sánh về độ chính xác cuối cùng. HPCR đã nhất quán đạt
được hiệu suất tốt nhất so với tất cả các phương pháp baseline.
Bảng III hiển thị tỷ lệ chính xác cuối cùng cho tất cả các bộ
dữ liệu. Tất cả các điểm số được báo cáo là điểm số trung
bình của 10 lần chạy với khoảng tin cậy 95%. Trong vô số
kịch bản thí nghiệm, trong đó mỗi bộ dữ liệu bao gồm bốn
bộ đệm bộ nhớ có kích thước khác nhau, HPCR nhất quán
vượt trội hơn tất cả các phương pháp khác. Đặc biệt, nó thể
hiện hiệu suất đáng chú ý hơn so với PCR. Cụ thể, HPCR
cho thấy sự tiến bộ đáng kể, kết hợp các thành phần tương
phản, nhiệt độ và chưng cất để tinh chỉnh thêm khung PCR.
Ví dụ, trên Split Cifar10, HPCR vượt trội hơn PCR với biên
độ đáng chú ý 2.9%, 3.1% và 4.1% cho kích thước bộ đệm
bộ nhớ 100, 200 và 500, tương ứng. Những kết quả thuyết
phục này nhấn mạnh tầm quan trọng quan trọng của các thành
phần được giới thiệu trong bài báo này, vì chúng đóng vai
trò quan trọng trong việc nâng cao hiệu suất của PCR.

Hơn nữa, chúng tôi tiến hành phân tích so sánh toàn diện
giữa năm phương pháp, sử dụng thiết lập thí nghiệm được
nêu trong [48]. Trong nghiên cứu đặc biệt này, mô hình được
cấu hình là ResNet18 với 64 bộ lọc, và 64 mẫu được truy
xuất từ bộ đệm bộ nhớ cho mỗi lô huấn luyện. Quá trình
huấn luyện sử dụng bộ tối ưu hóa Adam với tốc độ học 0.001.
Điều quan trọng cần lưu ý là những điều kiện thí nghiệm
này khác với những điều kiện được sử dụng trong nghiên
cứu của chúng tôi. Như được trình bày trong Bảng IV, HPCR
thể hiện tính ưu việt đáng chú ý so với SCR, OCM, OnPro
và PCR dưới các thiết lập thí nghiệm khác nhau. Bằng chứng
này tiếp tục củng cố tính hiệu quả và sự mạnh mẽ của HPCR
so với các cách tiếp cận hiện có.

So sánh về quá trình học. Trong khi đó, HPCR thể hiện tốt
nhất tổng thể trong toàn bộ quá trình học. Cụ thể, chúng tôi
báo cáo độ chính xác trung bình bất kỳ lúc nào cho tất cả
các bộ dữ liệu trong Bảng V. Kết quả thí nghiệm cho thấy
HPCR nhất quán vượt trội hơn các baseline khác trong toàn
bộ quá trình học. Để so sánh chi tiết hơn, chúng tôi cũng báo
cáo độ chính xác của mỗi nhiệm vụ học trong Hình 3, có thể
xác thực thêm hiệu suất tổng thể của các phương pháp. Kết
quả cho thấy hiệu suất của PCR trong vài nhiệm vụ đầu tiên
không vượt trội hơn các baseline khác. Tuy nhiên, sự cải thiện
của nó trở nên ngày càng rõ ràng khi số lượng nhiệm vụ tăng
lên, chứng minh sức mạnh của nó trong việc khắc phục CF.
Ví dụ, PCR không thể hiện tốt nhất trong nhiệm vụ đầu tiên,
nhưng nó thể hiện những lợi thế nổi bật trong các nhiệm vụ
còn lại trên Split CIFAR100. May mắn thay, vấn đề này đã
được giải quyết trong HPCR. Việc so sánh các đường màu
đỏ và cam cho thấy HPCR vẫn thể hiện tốt trong vài nhiệm
vụ đầu tiên. Do đó, các cách tiếp cận của chúng tôi có khả
năng chống quên mạnh hơn.

So sánh về cân bằng kiến thức. Cuối cùng, HPCR cũng có
những lợi thế đáng kể trong việc cân bằng kiến thức lịch sử
và mới. Trước đây, chúng tôi tính toán tỷ lệ quên cuối cùng
của mô hình khi sử dụng các phương pháp khác nhau. Như
được báo cáo trong Bảng VI, các phương pháp hiện có, đặc
biệt là ER-ACE, đã cho thấy hiệu suất nổi bật trong chỉ số
đánh giá này. Điều này là do ER-ACE có xu hướng học ít
hơn, làm cho nó dễ quên ít hơn. Để xác minh điều này, chúng
tôi ghi lại độ chính xác của kiến thức mới và lịch sử trong
mỗi nhiệm vụ cho một phần các phương pháp hiệu quả trên
Split MiniImageNet. Như được thể hiện trong Hình 4, vì ER-ACE
học ít kiến thức mới hơn, hiệu suất của nó trên tỷ lệ quên
cuối cùng có thể tốt hơn.

Thực tế, chúng ta không chỉ nên tập trung vào khả năng
giữ lại kiến thức lịch sử của mô hình mà còn đảm bảo khả
năng học nhanh kiến thức mới của mô hình. Mặc dù SCR,
ER-ACE và UER có thể cải thiện khả năng chống quên của
mô hình, chúng có xu hướng hạn chế khả năng khái quát hóa
của mô hình. Khi kiến thức lịch sử được củng cố, hiệu suất
học của mô hình trên kiến thức mới trở nên rất kém. Khác
với các nghiên cứu hiện có, mô hình của chúng tôi không
chỉ có thể giảm thiểu hiệu quả hiện tượng CF mà còn giảm
sự suy giảm của mô hình ở mức khái quát hóa càng nhiều
càng tốt. So sánh HPCR (đường đỏ) và PCR (đường cam),
không khó để thấy rằng có sự cải thiện đáng kể về khả năng
ghi nhớ kiến thức cũ.

--- TRANG 9 ---

C. Nghiên cứu Phá hủy

Trong phần này, chúng tôi tách HPCR thành nhiều thành
phần và thể hiện chức năng của chúng. Chúng tôi tiến hành
thí nghiệm với các thiết lập khác nhau và ghi lại tỷ lệ chính
xác cuối cùng trong Bảng VII. Ngoài ER, chúng tôi cũng bao
gồm hai phương pháp kết hợp được ký hiệu là Phương trình
(7) và Phương trình (8). Kết quả thí nghiệm cho thấy chúng
không đáng kể vì chúng không giải quyết vấn đề quên.

Thành phần tương phản (HC) có điều kiện kết hợp các cặp
neo-mẫu vào PCR. Mặc dù nó cung cấp thêm kiến thức về
các quan hệ của mẫu, hiệu suất của nó bị hạn chế bởi kích
thước lô nhỏ của các mẫu huấn luyện, như được chỉ ra trong
"PCR+HC" trong Bảng VII. Trong khi đó, chúng tôi tiến hành
thí nghiệm trên Split CIFAR100 sử dụng PCR có và không
có HC. Kết quả được tiết lộ trong Hình 5 cho thấy các cặp
neo-mẫu có thể giảm hiệu suất của PCR khi kích thước lô
của các mẫu huấn luyện nhỏ (<60), và ngược lại. Do đó,
việc sử dụng các cặp neo-mẫu nên được kiểm soát bởi một
hàm giai đoạn được ký hiệu là Phương trình (19). Để khám
phá thêm HC, chúng tôi tiến hành phân tích thành phần chính
(PCA) [71] trên các đặc trưng z được trích xuất bởi mô hình.
Như được thể hiện trong Hình 6, chúng tôi báo cáo tỷ lệ
chính xác cuối cùng trên Split CIFAR100 với các tỷ lệ khác
nhau của chiều đặc trưng khi kích thước lô của các mẫu
trước đây là 100. Trong các trường hợp mà tỷ lệ chiều thấp,
"PCR+HC" thể hiện tốt hơn nhiều so với PCR, và lợi thế
này được duy trì khi tỷ lệ tăng lên. Điều này có nghĩa là
khả năng trích xuất đặc trưng của mô hình đã được cải thiện
với sự trợ giúp của HC, cho phép trích xuất các đặc trưng
quan trọng hơn.

Thành phần nhiệt độ (HT) là để cải thiện khả năng khái
quát hóa của mô hình. Như được nêu trong Bảng VII, với
sự trợ giúp của HT, hiệu suất của PCR được cải thiện đáng
kể. So sánh "PCR" và "PCR w/o HD" trong Hình 4, chúng
tôi thấy rằng sự cải thiện chính mà HT mang lại nằm ở việc
học kiến thức mới bởi mô hình. Để khám phá vai trò của HT
trên quá trình truyền gradient và hội tụ mô hình, chúng tôi
phân tích quá trình huấn luyện của PCR trên CIFAR10 có
và không có HT, và một số chỉ số quan trọng được ghi lại
trong Bảng VIII. Kết quả cho thấy độ chính xác cuối cùng
có thể được cải thiện bởi HT vì mô hình có thể tạo ra ít
gradient hơn cho các lớp cũ (64.28<88.27) và các lớp mới
(70.40<95.39) trong quá trình truyền gradient. Trong khi đó,
chúng tôi thấy rằng HT có thể làm cho mô hình hội tụ đến
một vùng có giá trị hàm mất mát thấp hơn (1.6710<1.8439)
và một cảnh quan phẳng hơn trong quá trình tối ưu hóa. Để
xác thực điều này, chúng tôi thêm nhiễu phân phối đồng đều
vào các tham số của mô hình cuối cùng, gây ra sự thay đổi
vị trí của mô hình trong không gian tham số. Đồng thời,
chúng tôi ghi lại sự khác biệt trong mất mát huấn luyện
trước và sau khi mô hình thay đổi. Sau khi lặp lại các hoạt
động trên 1000 lần, chúng tôi tính toán trung bình của 1000
kết quả này. Kết quả cho thấy mô hình có sự khác biệt tương
đối nhỏ khi sử dụng HT cho tất cả các lớp (0.0025<0.0042)
và các lớp mới (0.0040<0.0056). Do đó, giải pháp tối ưu
của mô hình sử dụng HT nằm trong một vùng tương đối phẳng.
Như được hiển thị trong Hình 7, trong một vùng phẳng như
vậy, mô hình, trong đó giải pháp ban đầu là θ1, có thể thu
được một giải pháp tốt hơn θ2 hơn θ3 cho cả các lớp cũ
và mới. Hơn nữa, việc lựa chọn các siêu tham số liên quan
đến Phương trình (21) được hiển thị trong Bảng IX và X.
Và chúng tôi đặt τmax=0.16, τmin=0.05, và S=500 dựa trên
kết quả.

Thành phần chưng cất (HD) là để cải thiện khả năng chống
quên của mô hình. So sánh "HPCR" và "HPCR w/o HD" trong
Hình 4, chúng tôi có thể thấy rằng HPCR thể hiện tốt hơn
đáng kể về kiến thức lịch sử với sự trợ giúp của HD. Hiển
thị như Bảng VII, thành phần chưng cất, chứa SCD và PCD,
tiếp tục cải thiện hiệu suất của PCR. Để cải thiện hiệu suất
tổng thể của mô hình, cả SCD và PCD đều cần thiết. Một mặt,
SCD có thể cân bằng tốt hơn phân phối kiến thức lịch sử
trong khi cải thiện khả năng chống quên của mô hình. Thực
tế, có sự mất cân bằng giữa các lớp cũ trong OCL. Như được
hiển thị trong Bảng XI, mặc dù các nhiệm vụ 1-4 đều là các
nhiệm vụ cũ, hiệu suất của mô hình trên các nhiệm vụ này
khác nhau. So với phương pháp chưng cất trong DER, PCD
có thể cân bằng tốt hơn hiệu suất của mô hình trên các nhiệm
vụ cũ (Nhiệm vụ 1-4). Mặt khác, SCD, trực tiếp truyền gradient
cho bộ trích xuất đặc trưng, có thể tạo ra ít gradient hơn
cho tất cả các proxy so với PCD. Như được hiển thị trong
Hình 8, nếu HPCR chỉ sử dụng SCD, gradient tương đối nhỏ,
và hiệu suất cuối cùng tốt hơn.

Tóm lại, dựa trên ba thành phần này, HPCR có sự cải thiện
toàn diện so với PCR. Đồng thời, tất cả các thành phần được
tùy chỉnh để phá vỡ các hạn chế của PCR và có tính độc đáo
riêng.

D. Nghiên cứu Sâu hơn

1) Backbone được Huấn luyện trước: Với sự phát triển của
các mô hình được huấn luyện trước, học liên tục có xu hướng
lấy mô hình được huấn luyện trước làm mô hình ban đầu.
Do đó, chúng tôi tiến hành thêm thí nghiệm với mô hình
được huấn luyện trước trên Split CIFAR100. Để công bằng,
chúng tôi xem xét ViT-B/16-IN21K trong [72] làm mô hình
được huấn luyện trước, trong đó mỗi khối transformer được
đóng băng chứa một thành phần dư có thể huấn luyện. Trong
khi đó, kích thước lô huấn luyện được đặt là 10 và epoch
được đặt là 1 cho tất cả các phương pháp. Như được nêu
trong Hình 9, SLCA [73] và EASE [72] là các phương pháp
không tái diễn trong khi ER tái diễn với bộ đệm kích thước
100. So sánh ER (100) và HPCR (100), chúng tôi có thể thấy
rằng HPCR cũng có thể đóng vai trò khi sử dụng backbone
được huấn luyện trước. Hơn nữa, hiệu suất của HPCR sẽ
dần vượt qua SLCA và EASE dựa trên các mô hình được
huấn luyện trước khi kích thước bộ đệm tăng lên (từ 100
đến 5000), tiếp tục xác nhận tính ưu việt của nó cho OCL.

2) Trực quan hóa: Trực quan hóa có thể giúp phản ánh vai
trò của các thành phần này một cách trực quan hơn. Chúng
tôi huấn luyện mô hình bằng ER và HPCR trên Split CIFAR10
với 500 kích thước bộ đệm bộ nhớ, tương ứng. Khi kết thúc
huấn luyện, chúng tôi báo cáo trực quan hóa t-SNE 2D [74]
của embedding đặc trưng cho tất cả các mẫu kiểm tra, như
được hiển thị trong Hình 10. Các ngôi sao là proxy trong
khi các mẫu khác là mẫu cho tất cả các lớp. Kết quả cho
thấy HPCR không chỉ đạt được hiệu suất tuyệt vời mà còn
thực sự có thể cải thiện khả năng phân biệt của các mẫu
trong không gian embedding.

3) Chi phí Tính toán và Bộ nhớ: Đối với OCL, chi phí bộ
nhớ và tài nguyên tính toán là quan trọng, vì nó sẽ ảnh hưởng
đến tính thực tế của một phương pháp. Do đó, chúng tôi phân
tích chi phí bộ nhớ và tính toán của các phương pháp khác
nhau, như được báo cáo trong Bảng XII. 1) Tương tự như
[75], chúng tôi sử dụng CD để so sánh tính toán của các
phương pháp khác nhau. CD được ký hiệu là độ phức tạp
tương đối giữa luồng và một phương pháp học liên tục cơ
bản. Ví dụ, khi các mẫu hiện tại đến, ER có thể ngay lập
tức học chúng và sau đó dự đoán các mẫu không biết, dẫn
đến độ phức tạp tương đối là 1. Vì UER, ER-ACE, PCR và
HPCR chỉ sửa đổi mục tiêu mất mát của ER, độ phức tạp
tính toán của chúng tương đương với 1. Tuy nhiên, OCM
và OnPro yêu cầu thêm 16 tăng cường cho dữ liệu gốc,
làm cho nó cần 16 lần FLOPs cần thiết bởi ER. Do đó,
độ phức tạp tính toán của nó là 16, hạn chế khả năng dự
đoán thời gian thực. 2) Chúng tôi đặt ngân sách bộ nhớ
của mô hình cho ER là 1. Do phương pháp OCM yêu cầu
một mô hình bổ sung được lưu để chưng cất kiến thức, ngân
sách tương đối của nó là 2 và các phương pháp khác là 1.
3) Chúng tôi đánh giá việc sử dụng bộ nhớ của các phương
pháp khác nhau bằng cách xem xét kích thước dữ liệu của
tất cả các mẫu được lưu trữ trong bộ đệm. Như thấy trong
Bảng XIII, vì HPCR có yêu cầu lưu trữ bổ sung cho embedding
đặc trưng và logits, nó cần nhiều không gian bộ nhớ hơn
tương đối (>1). Tuy nhiên, bộ nhớ bổ sung không chiếm
tỷ lệ cao (<0.1). Nếu bộ nhớ bổ sung được sử dụng để
lưu trữ các mẫu cũ, hiệu suất của mô hình được hiển thị
trong hàng "Accuracy (Control)". Kết quả cho thấy việc
lưu trữ đặc trưng và logits như HPCR mang lại lợi ích
đáng kể, biện minh cho giá trị của nó. Tóm lại, HPCR nổi
lên như một cách tiếp cận đơn giản nhưng hiệu quả cho
dự đoán thời gian thực trong các tình huống OCL.

VII. KẾT LUẬN

Trong bài báo này, chúng tôi phát triển một phương pháp
OCL toàn diện hơn có tên HPCR dựa trên PCR, chủ yếu bao
gồm ba thành phần. Thành phần tương phản có điều kiện
giới thiệu các cặp neo-mẫu vào PCR, cải thiện khả năng
trích xuất đặc trưng của PCR khi kích thước lô huấn luyện
lớn. Thành phần nhiệt độ tách rời ảnh hưởng của nhiệt độ
lên gradient thành hai phần và hiệu quả cải thiện khả năng
khái quát hóa của mô hình. Thành phần chưng cất cải thiện
khả năng chống quên của mô hình thông qua PCD và SCD.
Thí nghiệm rộng rãi trên bốn bộ dữ liệu cho thấy tính ưu
việt của HPCR so với các phương pháp tiên tiến khác.

TÀI LIỆU THAM KHẢO

[1] L. Wang, X. Zhang, H. Su, and J. Zhu, "A comprehensive survey of
continual learning: Theory, method and application," IEEE Transactions
on Pattern Analysis and Machine Intelligence, 2024. 1

[2] Y. Liu, X. Hong, X. Tao, S. Dong, J. Shi, and Y. Gong, "Model behavior
preserving for class-incremental learning," IEEE Transactions on Neural
Networks and Learning Systems, 2022. 1

[3] Y. Kong, L. Liu, H. Chen, J. Kacprzyk, and D. Tao, "Overcoming
catastrophic forgetting in continual learning by exploring eigenvalues of
hessian matrix," IEEE Transactions on Neural Networks and Learning
Systems, 2023. 1

[4] H. Zhao, H. Wang, Y. Fu, F. Wu, and X. Li, "Memory-efficient class-
incremental learning for image classification," IEEE Transactions on
Neural Networks and Learning Systems, vol. 33, no. 10, pp. 5966–5977,
2021. 1

[5] H. Lin, S. Feng, X. Li, W. Li, and Y. Ye, "Anchor assisted experience
replay for online class-incremental learning," IEEE Transactions on
Circuits and Systems for Video Technology, 2022. 1

[6] Z. Mai, R. Li, J. Jeong, D. Quispe, H. Kim, and S. Sanner, "Online
continual learning in image classification: An empirical survey," Neuro-
computing, vol. 469, pp. 28–51, 2022. 1, 3

[7] X. Yao, Y. Bai, X. Zhang, Y. Zhang, Q. Sun, R. Chen, R. Li, and
B. Yu, "Pcl: Proxy-based contrastive learning for domain generalization,"
in Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition, 2022, pp. 7097–7107. 1, 3, 4

[8] T. Mensink, J. Verbeek, F. Perronnin, and G. Csurka, "Distance-based
image classification: Generalizing to new classes at near-zero cost,"
IEEE transactions on pattern analysis and machine intelligence, vol. 35,
no. 11, pp. 2624–2637, 2013. 1

[9] H. Lin, B. Zhang, S. Feng, X. Li, and Y. Ye, "Pcr: Proxy-based
contrastive replay for online class-incremental continual learning," in
Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition (CVPR), June 2023, pp. 24 246–24 255. 1, 2, 4,
5

[10] H. Ahn, J. Kwak, S. Lim, H. Bang, H. Kim, and T. Moon, "Ss-il:
Separated softmax for incremental learning," in Proceedings of the
IEEE/CVF International Conference on Computer Vision, 2021, pp.
844–853. 1, 4, 9

[11] L. Caccia, R. Aljundi, N. Asadi, T. Tuytelaars, J. Pineau, and
E. Belilovsky, "New insights on reducing abrupt representation change
in online continual learning," in International Conference on Learning
Representations, 2021. 1, 3, 4, 8, 9, 10

[12] A. Prabhu, P. H. Torr, and P. K. Dokania, "Gdumb: A simple approach
that questions our progress in continual learning," in European confer-
ence on computer vision. Springer, 2020, pp. 524–540. 3

[13] M. Delange, R. Aljundi, M. Masana, S. Parisot, X. Jia, A. Leonardis,
G. Slabaugh, and T. Tuytelaars, "A continual learning survey: Defying
forgetting in classification tasks," IEEE Transactions on Pattern Analysis
and Machine Intelligence, 2021. 3

[14] Y. Zhao, D. Saxena, and J. Cao, "Adaptcl: Adaptive continual learning
for tackling heterogeneity in sequential datasets," IEEE Transactions on
Neural Networks and Learning Systems, 2023. 3

[15] D.-W. Zhou, Y. Yang, and D.-C. Zhan, "Learning to classify with
incremental new class," IEEE Transactions on Neural Networks and
Learning Systems, vol. 33, no. 6, pp. 2429–2443, 2021. 3

[16] G. Sun, Y. Cong, Y. Zhang, G. Zhao, and Y. Fu, "Continual multiview
task learning via deep matrix factorization," IEEE transactions on neural
networks and learning systems, vol. 32, no. 1, pp. 139–150, 2020. 3

[17] H. Koh, D. Kim, J.-W. Ha, and J. Choi, "Online continual learning
on class incremental blurry task configuration with anytime inference,"
arXiv preprint arXiv:2110.10031, 2021. 3

[18] R. Aljundi, K. Kelchtermans, and T. Tuytelaars, "Task-free continual
learning," in Proceedings of the IEEE/CVF Conference on Computer
Vision and Pattern Recognition, 2019, pp. 11 254–11 263. 3

[19] J. Bang, H. Kim, Y. Yoo, J.-W. Ha, and J. Choi, "Rainbow memory:
Continual learning with a memory of diverse samples," in Proceedings of
the IEEE/CVF Conference on Computer Vision and Pattern Recognition,
2021, pp. 8218–8227. 3

[20] Q. Gao, Z. Luo, D. Klabjan, and F. Zhang, "Efficient architecture search
for continual learning," IEEE Transactions on Neural Networks and
Learning Systems, 2022. 3

[21] Z. Miao, Z. Wang, W. Chen, and Q. Qiu, "Continual learning with filter
atom swapping," in International Conference on Learning Representa-
tions, 2021. 3

[22] J. Kirkpatrick, R. Pascanu, N. Rabinowitz, J. Veness, G. Desjardins,
A. A. Rusu, K. Milan, J. Quan, T. Ramalho, A. Grabska-Barwinska
et al., "Overcoming catastrophic forgetting in neural networks," Pro-
ceedings of the national academy of sciences, vol. 114, no. 13, pp.
3521–3526, 2017. 3

[23] P. Dhar, R. V. Singh, K.-C. Peng, Z. Wu, and R. Chellappa, "Learning
without memorizing," in Proceedings of the IEEE/CVF Conference on
Computer Vision and Pattern Recognition, 2019, pp. 5138–5146. 3

[24] P. Buzzega, M. Boschini, A. Porrello, and S. Calderara, "Rethinking
experience replay: a bag of tricks for continual learning," in 2020 25th
International Conference on Pattern Recognition (ICPR). IEEE, 2021,
pp. 2180–2187. 3

[25] X. Su, S. Guo, T. Tan, and F. Chen, "Generative memory for lifelong
learning," IEEE transactions on neural networks and learning systems,
vol. 31, no. 6, pp. 1884–1898, 2019. 3

[26] M. Dedeoglu, S. Lin, Z. Zhang, and J. Zhang, "Continual learning
of generative models with limited data: From wasserstein-1 barycenter
to adaptive coalescence," IEEE Transactions on Neural Networks and
Learning Systems, 2023. 3

[27] G.-M. Park, S.-M. Yoo, and J.-H. Kim, "Convolutional neural network
with developmental memory for continual learning," IEEE Transactions
on Neural Networks and Learning Systems, vol. 32, no. 6, pp. 2691–
2705, 2020. 3

[28] H. Cha, J. Lee, and J. Shin, "Co2l: Contrastive continual learning," in
Proceedings of the IEEE/CVF International Conference on Computer
Vision, 2021, pp. 9516–9525. 3

[29] A. Chaudhry, A. Gordo, P. Dokania, P. Torr, and D. Lopez-Paz, "Using
hindsight to anchor past knowledge in continual learning," in Proceed-
ings of the AAAI Conference on Artificial Intelligence, vol. 35, no. 8,
2021, pp. 6993–7001. 3

[30] Q. Lao, X. Jiang, M. Havaei, and Y. Bengio, "A two-stream continual
learning system with variational domain-agnostic feature replay," IEEE
Transactions on Neural Networks and Learning Systems, vol. 33, no. 9,
pp. 4466–4478, 2021. 3

[31] S. Ho, M. Liu, L. Du, L. Gao, and Y. Xiang, "Prototype-guided memory
replay for continual learning," IEEE Transactions on Neural Networks
and Learning Systems, 2023. 3

[32] Y. Wang, Z. Huang, and X. Hong, "S-prompts learning with pre-trained
transformers: An occam's razor for domain incremental learning," Ad-
vances in Neural Information Processing Systems, vol. 35, pp. 5682–
5695, 2022. 3

[33] Z. Wang, Z. Zhang, C.-Y. Lee, H. Zhang, R. Sun, X. Ren, G. Su, V. Perot,
J. Dy, and T. Pfister, "Learning to prompt for continual learning," in
Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition, 2022, pp. 139–149. 3

[34] Z. Wang, Z. Zhang, S. Ebrahimi, R. Sun, H. Zhang, C.-Y. Lee, X. Ren,
G. Su, V. Perot, J. Dy et al., "Dualprompt: Complementary prompting for
rehearsal-free continual learning," in European Conference on Computer
Vision. Springer, 2022, pp. 631–648. 3

[35] J. S. Smith, L. Karlinsky, V. Gutta, P. Cascante-Bonilla, D. Kim,
A. Arbelle, R. Panda, R. Feris, and Z. Kira, "Coda-prompt: Contin-
ual decomposed attention-based prompting for rehearsal-free continual
learning," in Proceedings of the IEEE/CVF Conference on Computer
Vision and Pattern Recognition, 2023, pp. 11 909–11 919. 3

[36] S. Wang, X. Li, J. Sun, and Z. Xu, "Training networks in null space
of feature covariance for continual learning," in Proceedings of the
IEEE/CVF conference on Computer Vision and Pattern Recognition,
2021, pp. 184–193. 3

[37] T.-C. Kao, K. Jensen, G. van de Ven, A. Bernacchia, and G. Hennequin,
"Natural continual learning: success is a journey, not (just) a destination,"
Advances in neural information processing systems, vol. 34, pp. 28 067–
28 079, 2021. 3

[38] D. Deng, G. Chen, J. Hao, Q. Wang, and P.-A. Heng, "Flattening
sharpness for dynamic gradient projection memory benefits continual
learning," Advances in Neural Information Processing Systems, vol. 34,
pp. 18 710–18 721, 2021. 3

[39] Y. Guo, W. Hu, D. Zhao, and B. Liu, "Adaptive orthogonal projection for
batch and online continual learning," Proceedings of AAAI-2022, vol. 2,
2022. 3

[40] F. Zhu, Z. Cheng, X.-y. Zhang, and C.-l. Liu, "Class-incremental learning
via dual augmentation," Advances in Neural Information Processing
Systems, vol. 34, 2021. 3

[41] D. Rolnick, A. Ahuja, J. Schwarz, T. Lillicrap, and G. Wayne, "Expe-
rience replay for continual learning," Advances in Neural Information
Processing Systems, vol. 32, 2019. 3, 4, 9

[42] R. Aljundi, E. Belilovsky, T. Tuytelaars, L. Charlin, M. Caccia, M. Lin,
and L. Page-Caccia, "Online continual learning with maximal interfered
retrieval," Advances in Neural Information Processing Systems, vol. 32,
pp. 11 849–11 860, 2019. 3, 9

[43] D. Shim, Z. Mai, J. Jeong, S. Sanner, H. Kim, and J. Jang, "Online
class-incremental continual learning with adversarial shapley value," in
Proceedings of the AAAI Conference on Artificial Intelligence, vol. 35,
no. 11, 2021, pp. 9630–9638. 3, 8, 9

[44] R. Aljundi, M. Lin, B. Goujaud, and Y. Bengio, "Gradient based sample
selection for online continual learning," Advances in neural information
processing systems, vol. 32, 2019. 3, 9

[45] X. Jin, A. Sadhu, J. Du, and X. Ren, "Gradient-based editing of memory
examples for online task-free continual learning," Advances in Neural
Information Processing Systems, vol. 34, 2021. 3, 9

[46] Z. Mai, R. Li, H. Kim, and S. Sanner, "Supervised contrastive replay:
Revisiting the nearest class mean classifier in online class-incremental
continual learning," in Proceedings of the IEEE/CVF Conference on
Computer Vision and Pattern Recognition, 2021, pp. 3589–3599. 3, 4,
9, 10

[47] H. Yin, P. Li et al., "Mitigating forgetting in online continual learning
with neuron calibration," Advances in Neural Information Processing
Systems, vol. 34, 2021. 3

[48] Y. Guo, B. Liu, and D. Zhao, "Online continual learning through mutual
information maximization," in International Conference on Machine
Learning. PMLR, 2022, pp. 8109–8126. 3, 9

[49] Y. Gu, X. Yang, K. Wei, and C. Deng, "Not just selection, but
exploration: Online class-incremental continual learning via dual view
consistency," in Proceedings of the IEEE/CVF Conference on Computer
Vision and Pattern Recognition, 2022, pp. 7442–7451. 3, 9

[50] A. Chrysakis and M.-F. Moens, "Online bias correction for task-
free continual learning," in The Eleventh International Conference on
Learning Representations. 3, 9

[51] Y. Zhang, B. Pfahringer, E. Frank, A. Bifet, N. J. S. Lim, and Y. Jia, "A
simple but strong baseline for online continual learning: Repeated aug-
mented rehearsal," Advances in Neural Information Processing Systems,
vol. 35, pp. 14 771–14 783, 2022. 3

[52] H. Lin, S. Feng, B. Zhang, H. Qiao, X. Li, and Y. Ye, "Uer: A heuristic
bias addressing approach for online continual learning," arXiv preprint
arXiv:2309.04081, 2023. 3, 9, 10

[53] Y. Wei, J. Ye, Z. Huang, J. Zhang, and H. Shan, "Online prototype
learning for online continual learning," in Proceedings of the IEEE/CVF
International Conference on Computer Vision, 2023, pp. 18 764–18 774.
3, 9

[54] N. Michel, G. Chierchia, R. Negrel, and J.-F. Bercher, "Learning
representations on the unit sphere: Investigating angular gaussian and
von mises-fisher distributions for online continual learning," in The 38th
Annual AAAI Conference on Artificial Intelligence. arXiv, 2024. 3

[55] B. Kim, M. Seo, and J. Choi, "Online continual learning for interactive
instruction following agents," arXiv preprint arXiv:2403.07548, 2024. 3

[56] X. Yang, P. Zhou, and M. Wang, "Person reidentification via structural
deep metric learning," IEEE transactions on neural networks and
learning systems, vol. 30, no. 10, pp. 2987–2998, 2018. 3

[57] T. Milbich, K. Roth, B. Brattoli, and B. Ommer, "Sharing matters for
generalization in deep metric learning," IEEE Transactions on Pattern
Analysis and Machine Intelligence, vol. 44, no. 1, pp. 416–427, 2020.
3

[58] I. Elezi, J. Seidenschwarz, L. Wagner, S. Vascon, A. Torcinovich,
M. Pelillo, and L. Leal-Taixe, "The group loss++: A deeper look into
group loss for deep metric learning," IEEE Transactions on Pattern
Analysis and Machine Intelligence, 2022. 3

[59] W. Zheng, J. Lu, and J. Zhou, "Deep metric learning with adaptively
composite dynamic constraints," IEEE Transactions on Pattern Analysis
and Machine Intelligence, 2023. 3

[60] K. Roth, O. Vinyals, and Z. Akata, "Non-isotropy regularization for
proxy-based deep metric learning," in Proceedings of the IEEE/CVF
Conference on Computer Vision and Pattern Recognition, 2022, pp.
7420–7430. 3

[61] S. Hou, X. Pan, C. C. Loy, Z. Wang, and D. Lin, "Learning a
unified classifier incrementally via rebalancing," in Proceedings of the
IEEE/CVF Conference on Computer Vision and Pattern Recognition,
2019, pp. 831–839. 4, 6

[62] T. Li, P. Cao, Y. Yuan, L. Fan, Y. Yang, R. S. Feris, P. Indyk, and
D. Katabi, "Targeted supervised contrastive learning for long-tailed
recognition," in Proceedings of the IEEE/CVF Conference on Computer
Vision and Pattern Recognition, 2022, pp. 6918–6928. 4

[63] F. Wang and H. Liu, "Understanding the behaviour of contrastive loss,"
in Proceedings of the IEEE/CVF conference on computer vision and
pattern recognition, 2021, pp. 2495–2504. 6

[64] G. Hinton, O. Vinyals, J. Dean et al., "Distilling the knowledge in a
neural network," arXiv preprint arXiv:1503.02531, vol. 2, no. 7, 2015.
7

[65] P. Buzzega, M. Boschini, A. Porrello, D. Abati, and S. Calderara, "Dark
experience for general continual learning: a strong, simple baseline,"
Advances in neural information processing systems, vol. 33, pp. 15 920–
15 930, 2020. 7, 9, 12

[66] A. Chaudhry, M. Ranzato, M. Rohrbach, and M. Elhoseiny, "Efficient
lifelong learning with a-gem," in International Conference on Learning
Representations, 2018. 9

[67] B. Zhao, X. Xiao, G. Gan, B. Zhang, and S.-T. Xia, "Maintaining dis-
crimination and fairness in class incremental learning," in Proceedings of
the IEEE/CVF Conference on Computer Vision and Pattern Recognition,
2020, pp. 13 208–13 217. 9

[68] A. Krizhevsky, G. Hinton et al., "Learning multiple layers of features
from tiny images," 2009. 8

[69] O. Vinyals, C. Blundell, T. Lillicrap, D. Wierstra et al., "Matching net-
works for one shot learning," Advances in neural information processing
systems, vol. 29, pp. 3630–3638, 2016. 8

[70] Y. Le and X. Yang, "Tiny imagenet visual recognition challenge," CS
231N, vol. 7, no. 7, p. 3, 2015. 8

[71] S. Wold, K. Esbensen, and P. Geladi, "Principal component analysis,"
Chemometrics and intelligent laboratory systems, vol. 2, no. 1-3, pp.
37–52, 1987. 11

[72] D.-W. Zhou, H.-L. Sun, H.-J. Ye, and D.-C. Zhan, "Expandable subspace
ensemble for pre-trained model-based class-incremental learning," in
Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition, 2024, pp. 23 554–23 564. 12

[73] G. Zhang, L. Wang, G. Kang, L. Chen, and Y. Wei, "Slca: Slow learner
with classifier alignment for continual learning on a pre-trained model,"
in Proceedings of the IEEE/CVF International Conference on Computer
Vision, 2023, pp. 19 148–19 158. 12

[74] L. Van der Maaten and G. Hinton, "Visualizing data using t-sne." Journal
of machine learning research, vol. 9, no. 11, 2008. 13

[75] Y. Ghunaim, A. Bibi, K. Alhamoud, M. Alfarra, H. A. A. K. Hammoud,
A. Prabhu, P. H. Torr, and B. Ghanem, "Real-time evaluation in online
continual learning: A new paradigm," arXiv preprint arXiv:2302.01047,
2023. 13

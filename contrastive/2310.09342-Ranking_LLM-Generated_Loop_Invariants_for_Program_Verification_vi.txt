# 2310.09342.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/contrastive/2310.09342.pdf
# Kích thước tệp: 915389 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Xếp hạng các bất biến vòng lặp được tạo bởi LLM cho xác minh chương trình
Saikat Chakraborty, Shuvendu K. Lahiri, Sarah Fakhoury, Madanlal Musuvathi,
Akash Lal, Aseem Rastogi, Aditya Senthilnathan, Rahul Sharma, Nikhil Swamy
Microsoft Research
{saikatc, shuvendu, sfakhoury, madanm, akashl, aseemr,
t-adityas, rahsha, nswamy}@microsoft.com
Tóm tắt
Tổng hợp các bất biến vòng lặp quy nạp là
nền tảng để tự động hóa xác minh chương trình.
Trong công trình này, chúng tôi quan sát thấy rằng
các Mô hình Ngôn ngữ Lớn (như gpt-3.5 hoặc gpt-4)
có khả năng tổng hợp các bất biến vòng lặp cho
một lớp chương trình trong cài đặt 0-shot, nhưng
yêu cầu nhiều mẫu để tạo ra các bất biến chính xác.
Điều này có thể dẫn đến việc gọi chương trình
xác minh nhiều lần để thiết lập một bất biến.
Để giải quyết vấn đề này, chúng tôi đề xuất
một phương pháp xếp hạng lại cho các kết quả
được tạo bởi LLM. Chúng tôi đã thiết kế một
bộ xếp hạng có thể phân biệt giữa các bất biến
quy nạp chính xác và các nỗ lực không chính xác
dựa trên định nghĩa bài toán. Bộ xếp hạng được
tối ưu hóa như một bộ xếp hạng đối chiếu.
Kết quả thực nghiệm cho thấy cơ chế xếp hạng
lại này cải thiện đáng kể việc xếp hạng các bất
biến chính xác trong số các ứng viên được tạo,
dẫn đến việc giảm đáng kể số lần gọi đến một
bộ xác minh. Mã nguồn và dữ liệu thực nghiệm
cho bài báo này có sẵn tại https://github.com/
microsoft/NeuralInvariantRanker.

1 Giới thiệu
Xác minh chương trình là một bước quan trọng
hướng tới việc xây dựng phần mềm đáng tin cậy.
Thật không may, vấn đề xác minh các thuộc tính
của chương trình chứa vòng lặp là không thể quyết
định được. Xác minh các thuộc tính của chương
trình chứa vòng lặp quy về việc suy ra các bất biến
vòng lặp, đó là những sự thật tồn tại cho mọi lần
lặp của vòng lặp, và cũng đảm bảo thuộc tính mong
muốn. Có một khối lượng công trình trước đây phong
phú về tổng hợp bất biến vòng lặp cho xác minh
chương trình thông qua các kỹ thuật ký hiệu (Cousot
và Cousot, 1977; Colón et al., 2003; Graf và Saïdi,
1997; McMillan, 2003), và việc sử dụng chúng trong
xác minh các thuộc tính an toàn của các chương
trình thực tế (Ball et al., 2001; Blanchet et al.,
2003; Lahiri et al., 2009). Gần đây hơn, có sự
quan tâm ngày càng tăng đối với việc ứng dụng
học máy trong tổng hợp bất biến (Garg et al.,
2016; Padhi et al., 2016; Yao et al., 2020; Si et
al., 2018).

Trong những năm gần đây, các Mô hình Ngôn ngữ
Lớn (LLM) (Radford et al., 2018) đã nổi lên như
những mô hình AI nền tảng đã cách mạng hóa các
ứng dụng Xử lý Ngôn ngữ. Mặc dù LLM ban đầu
được đề xuất cho ngôn ngữ tự nhiên, chúng đã
thể hiện thành công lớn trong các ngôn ngữ hình
thức như ngôn ngữ lập trình (Chen et al., 2021).
Thực tế, với việc tăng kích thước, các mô hình
đã bắt đầu thể hiện các thuộc tính mới nổi. Ví dụ,
các LLM hiện đại như gpt-3.5 (Ouyang et al.,
2022), gpt-4 (OpenAI, 2023), PaLM (Chowdhery
et al., 2022) có khả năng suy luận về một nhiệm
vụ đã cho với việc nhắc ít-shot (Brown et al.,
2020), hoặc thậm chí nhắc không-shot (Kojima
et al., 2022).

Dấu ấn ấn tượng của LLM tự nhiên đặt ra câu
hỏi: LLM có thể tự động tổng hợp các bất biến
vòng lặp quy nạp tốt như thế nào?

Để làm điều này, chúng tôi sử dụng hai LLM
tiên tiến khác nhau để tổng hợp bất biến vòng lặp.
Chúng tôi quan sát thấy rằng các mô hình này có
thể tạo ra các bất biến có dạng tốt, nhưng việc
tìm ra bất biến chính xác thường yêu cầu một số
lượng lớn mẫu. Một giải pháp dựa trên đoán và
kiểm tra, với sự hỗ trợ của một bộ xác minh chương
trình tự động dựa trên Z3 (De Moura và Bjørner,
2008), có thể rất tốn kém về mặt tính toán do
nhiều lần gọi trên các bất biến không chính xác.
Để giảm thiểu những chi phí như vậy, chúng tôi
đề xuất xếp hạng lại các bất biến được tạo dựa
trên khả năng xác minh thành công của chúng.
Lấy cảm hứng từ việc sử dụng học đối chiếu trong
truy xuất thông tin (Karpukhin et al., 2020),
phương pháp của chúng tôi, gọi là iRank, biến
đổi bài toán và bất biến để đưa giải pháp chính
xác gần hơn trong không gian vector trong khi
đẩy xa các giải pháp không chính xác. Kết quả
thực nghiệm cho thấy việc xếp hạng lại như vậy
di chuyển thứ hạng trung vị của bất biến được
xác minh xuống 4 so với thứ hạng trung vị dự
kiến 31 cho các thế hệ từ gpt-3.5.

Tóm lại, trong bài báo này, chúng tôi đề xuất
xếp hạng lại các bất biến vòng lặp được tạo bởi
LLM để giảm chi phí của nỗ lực xác minh lãng phí.
Chúng tôi đã thiết kế một bộ xếp hạng để đối chiếu
các bất biến chính xác và không chính xác và cho
thấy sự giảm đáng kể trong nỗ lực kiểm tra bất
biến so với các thế hệ LLM thô.

2 Công trình liên quan
Các công trình trước đây về tạo bất biến vòng
lặp có thể được nhóm rộng rãi thành các phương
pháp ký hiệu hoặc dựa trên học máy. Các phương
pháp ký hiệu hoặc xây dựng các bất biến chính
xác theo cấu trúc (Cousot và Cousot, 1977; Colón
et al., 2003), hoặc tận dụng các bộ giải Satisfiability-
Modulo-Theories (SMT) như Z3 (De Moura và Bjørner,
2008) để liệt kê và kiểm tra các bất biến ứng viên
trên một không gian các vị từ được định nghĩa
trước (Flanagan và Leino, 2001; Flanagan và Qadeer,
2002; Lahiri và Bryant, 2007; Gulwani et al.,
2009; Fedyukovich và Bodík, 2018) hoặc các vị
từ được xây dựng thông qua các biến thể của
nội suy Craig (McMillan, 2003; Henzinger et al.,
2004; Dillig et al., 2013). Mặt khác, các kỹ thuật
gần đây tận dụng học máy để tổng hợp các bất
biến ứng viên được kiểm tra tính chính xác bằng
một bộ xác minh chương trình dựa trên SMT. Các
kỹ thuật bao gồm từ việc kết hợp phản hồi từ
một bộ xác minh sử dụng học tích cực trên cây
quyết định (Garg et al., 2016), học từ các ví dụ
phản bác (Sharma và Aiken, 2016; Padhi et al.,
2016), học tăng cường trên mạng nơ-ron đồ thị
(Si et al., 2018) và việc sử dụng mạng logic liên
tục (Yao et al., 2020; Ryan et al., 2020). Không
giống như các kỹ thuật này, phương pháp của chúng
tôi tận dụng LLM để tạo và xếp hạng bằng một mô
hình hoàn toàn nơ-ron và không yêu cầu bộ xác
minh chương trình tại thời điểm suy luận. Điều
này quan trọng đối với các kịch bản mà bộ xác
minh là bán tự động, như trường hợp của hầu hết
các công cụ xác minh chương trình thực tế như
Dafny (Leino, 2010) và F* (Swamy et al., 2011).
Cuối cùng, Pei et al. (2023) dự đoán các bất biến
chương trình sử dụng LLM, nhưng họ không nhằm
mục đích tạo ra các bất biến quy nạp đủ cho xác
minh chương trình hình thức.

3 Bối cảnh & Động lực

3.1 Bối cảnh: Suy luận bất biến vòng lặp
Trong phần này, chúng tôi nhắc lại vấn đề tạo
bất biến vòng lặp trong xác minh chương trình.
Đầu tiên, hãy định nghĩa một ngữ pháp cho các
câu lệnh chương trình S, biểu thức số nguyên a
và biểu thức Boolean b, hoạt động trên các biến
vô hướng. Hầu hết các câu lệnh và biểu thức đều
tự giải thích.

S::= x:=a|skip|S;S|ifbthenSelseS
a::= n|x|a+a|a−a|a∗a|...
b::= true|false|a=a|a < a |b∧b|b∨b| ¬b

Ở dạng đơn giản nhất, mục tiêu của xác minh
chương trình là xác minh rằng một đoạn chương
trình thỏa mãn các đặc tả của nó được ký hiệu
bởi bộ ba Hoare (Hoare, 1969) - {pre}while
bdoS{post}. Cho một chương trình p và một cặp
biểu thức Boolean (được ký hiệu bởi b trong ngữ
pháp) φ và ψ biểu thị điều kiện tiên quyết và
hậu điều kiện của chương trình p, bộ ba Hoare
{φ}p{ψ} biểu thị rằng mọi việc thực thi kết thúc
của p bắt đầu trong trạng thái tiền thỏa mãn vị
từ φ kết thúc trong trạng thái hậu thỏa mãn vị
từ ψ. Vì các vòng lặp có thể thực thi một số lần
lặp không giới hạn, việc xác minh các chương
trình với vòng lặp yêu cầu một bất biến vòng lặp
i thỏa mãn các điều kiện sau:

{pre}skip{i}
{i∧b}S{i}
{i∧ ¬b}skip{post}                    (1)

Các điều kiện tương ứng biểu thị rằng bất biến
vòng lặp i tồn tại khi vào vòng lặp, được bảo
tồn bởi một lần lặp tùy ý của vòng lặp và ngụ
ý điều kiện hậu khi thoát. Vấn đề suy luận bất
biến vòng lặp là suy ra một i thỏa mãn ba kiểm
tra trên, và được ký hiệu là i⊢p.

Hơn nữa, đối với các câu lệnh S không có vòng
lặp trong ngữ pháp trên, việc kiểm tra bộ ba Hoare
{ψ}S{φ} có thể được rút gọn thành các công thức
logic (có thể quyết định) trong Satisfiability-
Modulo-Theories (SMT) sử dụng các kỹ thuật tiêu
chuẩn trong xác minh chương trình (Leino, 2010).
Người ta có thể sử dụng một máy biến đổi vị từ
gọi là điều kiện yếu nhất WP để chuyển đổi bộ
ba Hoare thành một công thức SMT có thể quyết
định có thể được kiểm tra bởi Z3.

ψ=⇒WP(S, φ)
{ψ}S{φ}

WP được định nghĩa quy nạp trên cấu trúc của
các câu lệnh như sau:
WP(x:=a, φ).= φ[a/x]
WP(skip, φ).= φ
WP(S1;S2, φ).= WP(S1,WP(S2, φ))
WP(ifbthenS1elseS2, φ).=V(b=⇒WP(S1, φ))
(¬b=⇒WP(S2, φ))

3.2 Động lực và công thức bài toán
Cho một định nghĩa bài toán p bao gồm điều
kiện tiên quyết pre, một vòng lặp while bdoS,
và điều kiện hậu post, chúng ta có thể truy vấn
LLM để tạo ra một bất biến i thỏa mãn các điều
kiện được chỉ định trong Phương trình (1). Mặc
dù chúng tôi đã quan sát thấy rằng

--- TRANG 2 ---
iRank trong Huấn luyện
Bài toán
Bất biến đã xác minh
Bất biến đã xác minh 
Bất biến đã xác minh
Bất biến sai
Bất biến sai
Bất biến sai

Embedding ban đầu
(bất biến sai) Tăng khoảng cách
Giảm khoảng cách

Mô hình Embedding
Embedding ban đầu
(định nghĩa bài toán)

Embedding đã biến đổi
(sử dụng để xếp hạng)

Biến đổi Embedding
(ANN kết nối đầy đủ 3 lớp)

Ví dụ có chú thích từ dữ liệu huấn luyện
Bất biến đã xác minh
Bất biến đã xác minh
Bất biến đã xác minh

Embedding ban đầu
(bất biến chính xác)

Embedding ban đầu
nor(<= n 
 i  forall((j
Int)) (=>
(and ( ...and(< i n)
kforall((j
Int)) (=
 (and (...or(<= i n)
(forall((
j Int))(=>
(and  ...=>(<= i n)
((j Int)) 
(=> (and (
...  

Bài toán tổng hợp bất biến
(define-fun  pre_fun ... )
(define-fun  trans_fun ... )
(define-fun  post_fun ... )

Mô hình Embedding

Bất biến ứng viên
Embedding đã biến đổi
0.7
0.8
0.9
0.5

=>(<= i n)
((j Int)) 
(=> (and (
...nor(<= n 
 i  forall((j
Int)) (=>
(and ( ...and(< i n)
kforall((j
Int)) (=
 (and (...or(<= i n)
(forall((
j Int))(=>
(and  ...

Độ tương tự (Tích vô hướng)
(emb. bài toán và emb. bất biến ứng viên)

Bất biến ứng viên
được xếp hạng lại

iRank trong Xếp hạng

Hình 1: LLM cho tổng hợp bất biến vòng lặp.

LLM có khả năng tạo ra các bất biến vòng lặp
không có lỗi cú pháp, chúng thường yêu cầu nhiều
mẫu trước khi tạo ra một bất biến chính xác (chúng
tôi tham khảo Phụ lục B để biết chi tiết). Điều
này dẫn đến việc sử dụng tài nguyên không hiệu
quả trong quá trình xác minh, đặc biệt khi xử lý
các trường hợp bài toán phức tạp. Quan trọng hơn,
đối với kịch bản thực tế hơn khi các bất biến được
tạo được sử dụng như một phần của hệ thống xác
minh tương tác như Dafny/F*, một bất biến không
chính xác sẽ chiếm thời gian quý báu của người
dùng để thực hiện nỗ lực xác minh thất bại thủ
công. Do đó, chúng tôi đề xuất việc sử dụng iRank
để ưu tiên các bất biến được tạo dựa trên khả
năng chính xác của chúng. Hình 1 cung cấp cái
nhìn tổng quan cấp cao về hệ thống tạo-xếp hạng
bất biến được hình dung.

4 iRank: Phương pháp luận
Trực giác chính đằng sau iRank là học cách kéo
các bất biến có khả năng chính xác lên đầu danh
sách xếp hạng. Hình 1 cho thấy cái nhìn tổng
quan cấp cao của bộ xếp hạng. Chúng tôi dựa vào
một tập dữ liệu, D={(p, I+, I−)}, chứa bài toán
tạo bất biến vòng lặp, p, một tập các bất biến
vòng lặp đã xác minh, I+={i+|i+⊢p}, và một
tập các bất biến vòng lặp sai, I−={i−|i−⊬p}
cho mỗi bài toán, để xây dựng iRank. Mục tiêu
của chúng tôi là học một hàm giữa định nghĩa
bài toán p và bất biến i, tức là, σ(p, i), hàm
này phải thỏa mãn ràng buộc sau ∀{i+,i−}(σ(p, i+)> σ(p, i−)).

Xếp hạng đối chiếu. Để học σ, đầu tiên chúng
tôi trích xuất embedding của định nghĩa bài toán
và các bất biến bằng một bộ nhúng, Φ, tức là,
x= Φ(p), và y= Φ(i), trong đó x và y là các
embedding của định nghĩa bài toán p, và bất
biến i, tương ứng. Chúng tôi học một hàm biến
đổi, Ψ(x|θ), áp dụng biến đổi phi tuyến trên
vector đầu vào x với tham số có thể học θ. Sau
đó chúng tôi biến đổi embedding bài toán x thành
x′= Ψ(x|θ), và biến đổi embedding bất biến y
thành y′= Ψ(y|θ). Bây giờ mục tiêu của chúng
tôi là tối đa hóa độ tương tự giữa x′ và y′, khi
y′ tương ứng với một bất biến chính xác, ngược
lại thì tối thiểu hóa độ tương tự. Chúng tôi sử
dụng độ tương tự cosine tuyệt đối làm thước đo.
Việc sử dụng như vậy cho phép chúng tôi đặt độ
tương tự tối đa là 1 (trong trường hợp bất biến
chính xác) và tối thiểu là 0 (trong trường hợp
bất biến sai). Chúng tôi tối ưu hóa tổn thất bình
phương trung bình để học các tham số trong Ψ.
Chúng tôi thử nghiệm với hai mô hình embedding
khác nhau dựa trên LLM, tức là, text-embedding-
ada-002 và davinci-similarity. Phụ lục A trình
bày thêm chi tiết về quy trình hoạt động của iRank.

5 Thiết kế thực nghiệm và kết quả

5.1 Thiết lập thực nghiệm
Benchmark. Chúng tôi sử dụng benchmark tổng
hợp bất biến vòng lặp được tổng hợp bởi Padhi
et al. (2016)¹ bao gồm một tập 940 bài toán thử
thách trong định dạng SyGus (Alur et al., 2013),
với một công thức SMT cho điều kiện tiên quyết,
điều kiện hậu và hàm chuyển tiếp cho vòng lặp.
Chúng tôi chọn biểu diễn SMT cho mô tả bài toán
p của chúng tôi để không phụ thuộc vào các mã
hóa khác nhau của chương trình C thành logic.
Trong số các bài toán này, 541 nằm trong phạm
vi của LLM do kích thước cửa sổ ngữ cảnh. Chúng
tôi đặt kích thước ngữ cảnh tối đa là 4096 (với
3584 cho prompt, 512 cho tạo).

Thu thập bất biến được tạo bởi LLM. Chúng tôi
tiến hành thực nghiệm với hai mô hình ngôn ngữ
khác biệt: gpt-3.5-turbo và gpt-4. Mục tiêu của
chúng tôi là đánh giá khả năng của các mô hình
ngôn ngữ này ngay từ đầu, và do đó chúng tôi
sử dụng phương pháp nhắc zero-shot. Điều này
bao gồm việc cung cấp mô tả bài toán và giải
thích nhiệm vụ phù hợp làm prompt (tham khảo
Phụ lục C để biết ví dụ). Đối với mỗi bài toán,
chúng tôi cho phép cả hai mô hình tạo bất biến
trong thời gian tối đa 10 phút hoặc cho đến khi
tìm thấy bất biến đã xác minh, tùy điều nào xảy
ra trước, dẫn đến việc giải quyết 250 bài toán
bởi gpt-3.5-turbo, và 188 bài toán cho gpt-4².
Điều quan trọng cần làm rõ là mục đích của bài
báo này không phải là tiến hành phân tích so
sánh các mô hình ngôn ngữ này liên quan đến
bài toán cụ thể này. Thay vào đó, mục tiêu của
chúng tôi là đề xuất một phương pháp để tăng
cường khả năng LLM một cách trực giao bằng
cách xếp hạng lại các bất biến được tạo bởi LLM.

Dữ liệu huấn luyện. Chúng tôi tạo tập dữ liệu
huấn luyện cho iRank (D={(p, I+, I−)}) bằng
cách kết hợp các bất biến được tạo từ các nguồn
khác nhau, như các thế hệ khác nhau từ LLM,
và các bất biến được tạo bởi LoopInvGen (Padhi
et al., 2017). Chúng tôi chia các bài toán thành
năm fold và huấn luyện 5 bộ xếp hạng khác nhau,
một cho mỗi fold. Trong quá trình đánh giá,
chúng tôi chọn và tải mô hình đã huấn luyện dựa
trên bài toán đang được đánh giá. Thống kê chi
tiết của dữ liệu có sẵn trong Phụ lục A.3.

Chỉ số đánh giá. Sau đó chúng tôi tuần tự cố
gắng kiểm tra các bất biến từ danh sách được
xếp hạng. Chúng tôi đánh giá ba chỉ số – (i)
i+ranks - thứ hạng của bất biến chính xác trong
danh sách, (ii) V@K - tỷ lệ phần trăm các bài
toán mà bất biến đã xác minh được tìm thấy trong
K bất biến hàng đầu từ danh sách đã xếp hạng
lại, và (iii) Số lần gọi Z3 - tổng số lần gọi z3
trước khi tìm thấy và báo cáo một bất biến chính
xác, số lần gọi z3 cao hơn cho thấy lãng phí tài
nguyên tính toán nhiều.

²Lưu ý rằng giới hạn tốc độ cho gpt-4 thấp hơn một
bậc so với gpt-3.5 trong việc sử dụng của chúng tôi
dẫn đến ít mẫu hơn một bậc.

[Bảng 1 và nội dung tiếp theo được dịch tương tự...]

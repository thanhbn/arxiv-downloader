# CoLES: Học Tương Phản cho Chuỗi Sự Kiện với Tự Giám Sát

Dmitrii Babaev
AIRI
Sber AI Lab
Moscow, Nga

Nikita Ovsov
Ivan Kireev
Maria Ivanova
Sber AI Lab
Moscow, Nga

Gleb Gusev
Sber AI Lab
MIPT
Moscow, Nga

Ivan Nazarov
AIRI
Moscow, Nga

Alexander Tuzhilin
New York University
New York, USA

TÓM TẮT
Chúng tôi giải quyết vấn đề học tự giám sát trên các chuỗi sự kiện rời rạc được tạo ra bởi người dùng thực tế. Học tự giám sát kết hợp thông tin phức tạp từ dữ liệu thô trong các biểu diễn vector có độ dài cố định và chiều thấp có thể được áp dụng dễ dàng trong các tác vụ học máy hạ nguồn khác nhau. Trong bài báo này, chúng tôi đề xuất một phương pháp mới "CoLES", điều chỉnh học tương phản, trước đây được sử dụng cho các lĩnh vực âm thanh và thị giác máy tính, sang lĩnh vực chuỗi sự kiện rời rạc trong thiết lập tự giám sát. Chúng tôi đã triển khai các embedding CoLES dựa trên chuỗi giao dịch tại công ty dịch vụ tài chính lớn của châu Âu. Việc sử dụng các embedding CoLES cải thiện đáng kể hiệu suất của các mô hình có sẵn trên các tác vụ hạ nguồn và tạo ra lợi ích tài chính đáng kể, được đo lường bằng hàng trăm triệu đô la hàng năm. Chúng tôi cũng đánh giá CoLES trên một số bộ dữ liệu chuỗi sự kiện công khai và cho thấy rằng các biểu diễn CoLES luôn vượt trội hơn các phương pháp khác trên các tác vụ hạ nguồn khác nhau.

KHÁI NIỆM CCS
•Hệ thống thông tin →Hệ thống quản lý dữ liệu;•Máy tính ứng dụng→Ngân hàng trực tuyến;•Phương pháp tính toán→Thuật toán học máy.

TỪ KHÓA
học biểu diễn, học metric, học tương phản, học tự giám sát, chuỗi sự kiện, quản lý dữ liệu

Định dạng Tham chiếu ACM:
Dmitrii Babaev, Nikita Ovsov, Ivan Kireev, Maria Ivanova, Gleb Gusev, Ivan Nazarov, và Alexander Tuzhilin. 2022. CoLES: Học Tương Phản cho Chuỗi Sự Kiện với Tự Giám Sát. Trong Proceedings of the 2022 International Conference on Management of Data (SIGMOD '22), 12-17 tháng 6, 2022, Philadelphia, PA, USA. ACM, New York, NY, USA, 11 trang. https://doi.org/10.1145/3514221.3526129

1 GIỚI THIỆU

Là một phần của các phương pháp học biểu diễn, embedding dữ liệu nhằm mục đích biểu diễn các mẫu nội tại liên quan của dữ liệu điểm hoặc tuần tự thành các vector có độ dài cố định và chiều thấp nắm bắt "bản chất" của nó, hữu ích trong các tác vụ hạ nguồn liên quan [9,10,25,28,38]. Như vậy, các embedding được tiền huấn luyện trong các lĩnh vực khác nhau được sử dụng hoặc như các đặc trưng đầu vào thông tin sẵn có cho các mô hình Học Máy hoặc Học Sâu mà không cần kỹ thuật mở rộng hoặc kiến thức lĩnh vực sâu từ phía thực hành, hoặc như các khối xây dựng trong các biểu diễn của dữ liệu đa phương thức tổng hợp. Trong các ứng dụng big-data, embedding có thể được xem như một kỹ thuật nén dữ liệu có thể học được và nhận thức về tác vụ, cho phép các sắp xếp chia sẻ dữ liệu hiệu quả về lưu trữ, có thể với các đảm bảo riêng tư tùy thuộc vào phương pháp được sử dụng.

Tuy nhiên, hầu hết nghiên cứu và ứng dụng của các phương pháp embedding đã được tập trung vào các lĩnh vực học máy cốt lõi, bao gồm ELMO [28] và BERT [9] trong xử lý ngôn ngữ tự nhiên (NLP), CPC [38] trong nhận dạng giọng nói, và nhiều phương pháp khác trong thị giác máy tính (CV) [10, 38].

Đặc điểm chung của các lĩnh vực này là dữ liệu trong các phương thức như vậy nhạy cảm với ngữ cảnh: một thuật ngữ có thể được tái tạo chính xác từ mô hình ngôn ngữ có điều kiện ngữ cảnh, tương tự như cách một pixel có thể được suy ra từ vùng lân cận của nó. Tính chất này là cơ sở cho các phương pháp học biểu diễn phổ biến trong NLP, như tác vụ Cloze của BERT [9], và trong audio và CV, như CPC [38].

Tuy nhiên, không phải mọi dữ liệu tuần tự rời rạc đều có thông tin tương hỗ cao giữa một mục đơn lẻ và vùng lân cận trực tiếp của nó. Ví dụ, các mục log, telemetry IoT, bảo trì công nghiệp, hành vi người dùng [26], mẫu du lịch, dữ liệu giao dịch, và các chuỗi sự kiện công nghiệp và tài chính khác thường bao gồm các dòng con tương đối độc lập được xen kẽ. Ví dụ, các giao dịch được tạo ra bởi khách hàng cá nhân hoặc doanh nghiệp có các mẫu không đều và định kỳ, được nhìn từ quan điểm của công ty dịch vụ tài chính như một dòng các sự kiện không được gắn nhãn và có vẻ như không liên quan. Các phương pháp học biểu diễn tiên tiến nhất hiện tại cho token và embedding chuỗi từ NLP hoặc CV không được đảm bảo nắm bắt được những đặc thù của dữ liệu tài chính như vậy, thể hiện hành vi khách hàng của một loại nhất định và tạo thành thông tin có giá trị cho việc ngăn chặn gian lận và phát triển các sản phẩm tài chính hiệu quả.

Trong bài báo này, chúng tôi đề xuất một phương pháp tự giám sát mới cho embedding các chuỗi sự kiện rời rạc, được gọi là Học Tương Phản cho Chuỗi Sự Kiện (CoLES), dựa trên học tương phản [14,44], với một chiến lược tăng cường dữ liệu đặc biệt. Học tương phản nhằm mục đích học một biểu diễn 𝑥↦→𝑀(𝑥), đưa các cặp tích cực, tức là các đối tượng tương tự về mặt ngữ nghĩa, gần nhau hơn trong không gian embedding, trong khi các cặp tiêu cực, tức là các đối tượng không tương tự, xa nhau hơn. Các cặp tích cực-tiêu cực được thu thập hoặc một cách rõ ràng từ dữ liệu mục tiêu ground-truth đã biết hoặc một cách ngầm định bằng cách sử dụng các chiến lược tăng cường dữ liệu tự giám sát [12]. Trong trường hợp thứ hai, phương pháp phổ biến nhất là sinh có điều kiện: đối với một cặp điểm dữ liệu riêng biệt 𝑥≠𝑦, các cặp tích cực (𝑧,𝑧′) được lấy mẫu từ tích 𝑝+(𝑧,𝑧′)=𝑝(𝑧|𝑥)𝑝(𝑧′|𝑥), trong khi các cặp tiêu cực – từ 𝑝−(𝑧,𝑧′)=𝑝(𝑧|𝑥)𝑝(𝑧′|𝑦) cho 𝑥≠𝑦, trong đó 𝑝(·|𝑥) là một quy trình lấy mẫu các tăng cường ngẫu nhiên của 𝑥.

Là một phương pháp embedding chuỗi tự giám sát, CoLES sử dụng một thuật toán tăng cường mới, tạo ra các chuỗi con của các chuỗi sự kiện quan sát được và sử dụng chúng như các góc nhìn chiều cao khác nhau của đối tượng (chuỗi) cho học tương phản. Quy trình sinh được đề xuất được thiết kế đặc biệt để giải quyết tính định kỳ xen kẽ được quan sát trong các chuỗi sự kiện giao dịch tài chính, là ứng dụng chính của phương pháp của chúng tôi (xem Phần 4.3). Các biểu diễn được học bởi CoLES có thể được sử dụng làm vector đặc trưng trong các tác vụ có giám sát liên quan đến lĩnh vực [25,35,48], ví dụ như phát hiện gian lận hoặc các tác vụ chấm điểm dựa trên lịch sử giao dịch, hoặc chúng có thể được tinh chỉnh cho các tác vụ ngoài lĩnh vực [47].

Chúng tôi đã áp dụng CoLES cho bốn bộ dữ liệu chuỗi sự kiện có sẵn công khai từ các lĩnh vực khác nhau, như giao dịch tài chính, biên lai bán lẻ và hồ sơ đánh giá trò chơi. Như chúng tôi thể hiện trong phần thực nghiệm, CoLES tạo ra các biểu diễn đạt được kết quả hiệu suất mạnh, có thể so sánh với các đặc trưng được tạo thủ công bởi các chuyên gia lĩnh vực. Chúng tôi cũng chứng minh rằng các biểu diễn CoLES được tinh chỉnh luôn vượt trội hơn các biểu diễn được tạo ra bởi các phương pháp thay thế. Ngoài ra, chúng tôi triển khai các embedding CoLES trong một số ứng dụng trong tổ chức của chúng tôi và kiểm tra phương pháp này với các mô hình hiện đang được sử dụng trong công ty. Kết quả thực nghiệm cho thấy các embedding CoLES cải thiện đáng kể hiệu suất của các mô hình có sẵn trên các tác vụ hạ nguồn, dẫn đến lợi ích tài chính đáng kể cho công ty.

Bài báo này đưa ra các đóng góp sau. Chúng tôi
(1) trình bày CoLES, một phương pháp tự giám sát với một phương pháp tăng cường mới, điều chỉnh học tương phản sang lĩnh vực chuỗi sự kiện rời rạc;
(2) chứng minh rằng CoLES luôn vượt trội hơn các baseline học có giám sát, tự giám sát và bán giám sát hiện có được điều chỉnh cho lĩnh vực chuỗi sự kiện;
(3) trình bày kết quả áp dụng các embedding CoLES trong các tình huống thực tế và cho thấy rằng phương pháp được đề xuất có thể có giá trị đáng kể cho việc mô hình hóa hàng ngày trong ngành dịch vụ tài chính.

Phần còn lại của bài báo được tổ chức như sau. Trong phần tiếp theo, chúng tôi thảo luận về các nghiên cứu liên quan về học tự giám sát và tương phản. Trong Phần 3, chúng tôi giới thiệu phương pháp mới CoLES cho các chuỗi sự kiện rời rạc. Trong Phần 4, chúng tôi chứng minh rằng CoLES vượt trội hơn một số baseline mạnh bao gồm các phương pháp học tương phản được đề xuất trước đây được điều chỉnh cho các bộ dữ liệu chuỗi sự kiện. Phần 5 dành cho việc thảo luận về kết quả và kết luận của chúng tôi. Chúng tôi cung cấp mã nguồn cho tất cả các thí nghiệm trên các bộ dữ liệu công khai được mô tả trong bài báo này.

2 CÔNG TRÌNH LIÊN QUAN

Học tương phản đã được áp dụng thành công để xây dựng các biểu diễn chiều thấp (embedding) của các đối tượng khác nhau, như hình ảnh [7,32], văn bản [30], và bản ghi âm thanh [41]. Mặc dù mục tiêu của những nghiên cứu này là xác định đối tượng dựa trên mẫu của nó [18,32,41], những phương pháp có giám sát này không áp dụng được cho thiết lập của chúng tôi, vì các bộ dữ liệu huấn luyện của chúng chứa rõ ràng nhiều mẫu độc lập cho mỗi đối tượng cụ thể, tạo thành các cặp tích cực như một thành phần quan trọng cho việc học.

Đối với các tình huống khi các cặp tích cực không có sẵn hoặc số lượng của chúng bị hạn chế, có thể sử dụng các kỹ thuật tạo dữ liệu tổng hợp và tăng cường. Một trong những framework đầu tiên như vậy được đề xuất bởi Dosovitskiy et al. [10], những người giới thiệu các lớp thay thế bằng cách tăng cường ngẫu nhiên cùng một hình ảnh. Một số công trình gần đây, ví dụ [2,4,15], mở rộng ý tưởng này bằng cách áp dụng các phương pháp học tương phản (xem [12]). Mã hóa Dự đoán Tương phản (CPC) là một phương pháp học tự giám sát được đề xuất cho dữ liệu tuần tự không rời rạc trong [38]. CPC sử dụng một mô hình dự đoán tự hồi quy của chuỗi đầu vào để trích xuất các biểu diễn tiềm ẩn có ý nghĩa, và như vậy có thể được điều chỉnh cho lĩnh vực chuỗi sự kiện rời rạc (xem Phần 4.2 để so sánh với CoLES).

Một số ấn phẩm xem xét tự giám sát cho các chuỗi hành vi người dùng trong hệ thống gợi ý và các lĩnh vực phân tích hành vi người dùng. Phương pháp giống CPC cho học tự giám sát trên lịch sử nhấp chuột của người dùng được đề xuất trong [51], trong khi [23] sử dụng một thuật ngữ mất mát chuỗi-đến-chuỗi tự giám sát phụ trợ. Trong [52], người ta đề xuất sử dụng tác vụ "Cloze" từ BERT [9] cho tự giám sát trên các chuỗi mua hàng. Một phương pháp giống SimCLR cho các tác vụ dựa trên văn bản và dữ liệu dạng bảng được điều chỉnh trong [45]. Trong [53] các tác giả đề xuất một phương pháp tự hồi quy không giám sát để tạo ra các embedding của các chuỗi có thuộc tính trong đó một chuỗi các token phân loại có các thuộc tính toàn cầu bổ sung. Các công trình đã nêu trên xem xét các chuỗi "mục", trong đó mỗi phần tử là một định danh mục. Chúng tôi xem xét các chuỗi sự kiện phức tạp hơn trong đó một phần tử của chuỗi bao gồm một số trường phân loại và số.

Có những bài báo dành cho học có giám sát cho các chuỗi sự kiện rời rạc, ví dụ [1,3,34,36,42], nhưng tiền huấn luyện tự giám sát không được sử dụng trong những công trình đó.

3 CÔNG THỨC HÓA VẤN ĐỀ VÀ TỔNG QUAN PHƯƠNG PHÁP COLES

3.1 Công thức hóa vấn đề

Mặc dù phương pháp được đề xuất trong nghiên cứu này có thể được nghiên cứu trong các lĩnh vực khác nhau, chúng tôi tập trung vào các chuỗi sự kiện rời rạc. Giả sử có một số thực thể 𝑒 và hoạt động trọn đời của mỗi thực thể được quan sát như một chuỗi sự kiện 𝑥𝑒:={𝑥𝑒(𝑡)}𝑇𝑒𝑡=1. Các thực thể có thể là con người hoặc tổ chức hoặc một số trừu tượng khác. Các sự kiện 𝑥𝑒(𝑡) có thể có bất kỳ tính chất và cấu trúc nào (ví dụ, giao dịch của một khách hàng, log nhấp chuột của một người dùng), và các thành phần của chúng có thể chứa các trường số, phân loại và văn bản (xem mô tả bộ dữ liệu trong Phần 4).

Theo framework lý thuyết của học tương phản được đề xuất trong [31], mỗi thực thể 𝑒 là một lớp tiềm ẩn, được liên kết với một phân phối 𝑃𝑒 trên các mẫu có thể có của nó (chuỗi sự kiện). Tuy nhiên, không giống như thiết lập vấn đề của [31], chúng tôi không có các cặp tích cực, tức là các cặp chuỗi sự kiện đại diện cho cùng một thực thể 𝑒. Thay vào đó, chỉ có một chuỗi 𝑥𝑒 có sẵn cho thực thể 𝑒. Về mặt hình thức, mỗi thực thể 𝑒 được liên kết với một quy trình ngẫu nhiên tiềm ẩn {𝑋𝑒(𝑡)}={𝑋𝑒(𝑡)}𝑡≥1, và chúng tôi chỉ quan sát một thực hiện hữu hạn duy nhất {𝑥𝑒}={𝑥𝑒(𝑡)}𝑇𝑒𝑡=1 của nó. Mục tiêu của chúng tôi là học một bộ mã hóa 𝑀 ánh xạ các chuỗi sự kiện vào một không gian đặc trưng R𝑑 sao cho embedding thu được {𝑥𝑒}↦→𝑐𝑒=𝑀({𝑥𝑒})∈R𝑑 mã hóa các thuộc tính cốt yếu của 𝑒 và bỏ qua tiếng ồn không liên quan có trong chuỗi. Đó là, các embedding 𝑀({𝑥′}) và 𝑀({𝑥′′}) nên gần nhau hơn, nếu 𝑥′ và 𝑥′′ là các đường đi được tạo bởi cùng một quy trình {𝑋𝑒(𝑡)}, và xa nhau hơn, nếu được tạo bởi các quy trình khác biệt.

Chất lượng của các biểu diễn có thể được kiểm tra bằng các tác vụ hạ nguồn theo hai cách:
(1) 𝑐𝑒 có thể được sử dụng làm vector đặc trưng cho một mô hình đặc thù cho tác vụ (xem Hình 1, Giai đoạn 2a),
(2) bộ mã hóa 𝑀 cũng có thể được tinh chỉnh (cùng nhau) [47] (xem Hình 1, Giai đoạn 2b).

3.2 Lấy mẫu các chuỗi thay thế như một thủ tục tăng cường

Khi không có quyền truy cập lấy mẫu vào các quy trình tiềm ẩn {𝑋𝑒(𝑡)}, người ta có thể sử dụng các chiến lược tăng cường tổng hợp, tương tự như bootstrapping. Hầu hết các kỹ thuật tăng cường được đề xuất cho các lĩnh vực liên tục, như dịch chuyển hình ảnh, jitter màu hoặc thang xám ngẫu nhiên trong CV [12], không áp dụng được cho các sự kiện rời rạc. Do đó, việc tạo ra các chuỗi con từ cùng một chuỗi sự kiện {𝑥𝑒(𝑡)} có thể được sử dụng như một sự tăng cường có thể. Ý tưởng được đề xuất dưới đây giống với phương pháp bootstrap [11], mà, đại khái, cho rằng phân phối thực nghiệm được tạo ra bởi mẫu quan sát được của các điểm dữ liệu độc lập là một proxy phù hợp cho phân phối của quần thể. Tuy nhiên, trong thiết lập của chúng tôi, các sự kiện không phải là các quan sát độc lập, điều này thúc đẩy chúng tôi dựa vào các giả định dữ liệu khác nhau.

Tính chất chủ chốt của các chuỗi sự kiện đại diện cho hoạt động trọn đời là tính định kỳ và khả năng lặp lại của các sự kiện của nó (xem Phần 4.0.2 để quan sát thực nghiệm những tính chất này cho các bộ dữ liệu được xem xét). Điều này thúc đẩy phương pháp lấy mẫu Random slices được áp dụng trong CoLES, như được trình bày trong Thuật toán 1. Các chuỗi con {˜𝑥𝑒} được lấy mẫu từ một chuỗi đã cho {𝑥𝑒(𝑡)} như các đoạn liên tục, "lát cắt", sử dụng ba bước sau. Đầu tiên, độ dài của lát cắt được chọn đều từ các giá trị cho phép. Thứ hai, các chuỗi con quá ngắn (và, tùy chọn, quá dài) bị loại bỏ. Thứ ba, vị trí bắt đầu được chọn đều từ tất cả các giá trị có thể. Tổng quan về phương pháp CoLES được trình bày trong Hình 1.

Thuật toán 1: Chiến lược tạo chuỗi con lát cắt ngẫu nhiên
siêu tham số: 𝑚,𝑀: độ dài tối thiểu và tối đa có thể của một chuỗi con; 𝑘: số lượng mẫu.
đầu vào: Một chuỗi 𝑆={𝑧𝑗}𝑇−1𝑗=0 có độ dài 𝑇.
đầu ra: S: các chuỗi con của 𝑆.
for 𝑖←1 to 𝑘 do
    Tạo một số nguyên ngẫu nhiên 𝑇𝑖 đều từ [1,𝑇];
    if 𝑇𝑖∈[𝑚,𝑀] then
        Tạo một số nguyên ngẫu nhiên 𝑠 từ [0,𝑇−𝑇𝑖);
        Thêm lát cắt ˜𝑆𝑖:={𝑧𝑠+𝑗}𝑇𝑖−1𝑗=0 vào S;
    end

3.3 Huấn luyện mô hình

Tạo batch. Thủ tục sau tạo ra một batch cho CoLES. 𝑁 chuỗi ban đầu được lấy ngẫu nhiên và 𝐾 chuỗi con được tạo ra cho mỗi chuỗi. Các cặp chuỗi con từ cùng một chuỗi được sử dụng làm mẫu tích cực và các cặp từ các chuỗi khác nhau – làm mẫu tiêu cực.

Trong phần thực nghiệm, chúng tôi xem xét một số chiến lược thực nghiệm cơ bản cho việc tạo chuỗi con để so sánh với Thuật toán 1. Chi tiết của việc so sánh được trình bày trong Phần 4.2.1.

Mất mát tương phản. Chúng tôi xem xét một biến thể cổ điển của mất mát tương phản, được đề xuất trong [14], tối thiểu hóa mục tiêu
L𝑢𝑣(𝑀)=𝑌𝑢𝑣½𝑑𝑀(𝑢,𝑣)²+(1−𝑌𝑢𝑣)½max{0,𝜌−𝑑𝑀(𝑢,𝑣)}²,
đối với 𝑀:X→R𝑛, trong đó 𝑑𝑀(𝑢,𝑣)=𝑑(𝑐𝑢,𝑐𝑣) là khoảng cách giữa các embedding của cặp (𝑢,𝑣), 𝑐∗=𝑀({˜𝑣∗(𝜏)}), 𝑌𝑢𝑣 là một biến nhị phân xác định liệu cặp (𝑢,𝑣) có tích cực hay không, và 𝜌 là lề mềm tối thiểu giữa các đối tượng không tương tự. Thuật ngữ thứ hai khuyến khích việc tách biệt các embedding trong các cặp tiêu cực và ngăn chặn sự suy thoái mode trong 𝑀, khi các thực thể được ánh xạ đến cùng một điểm trong không gian embedding. 𝑑(𝑎,𝑏) là khoảng cách Euclidean, 𝑑(𝑎,𝑏)=√(Σ𝑘(𝑎𝑘−𝑏𝑘)²), như được đề xuất trong [14]. Các chuỗi {˜𝑥𝑢(𝜏)} và {˜𝑥𝑣(𝜏)} của một cặp với 𝑌𝑢𝑣=1 được thu thập thông qua tạo lát cắt ngẫu nhiên (Thuật toán 1) từ cùng một quan sát {𝑥𝑒(𝑡)}, trong khi trong các cặp với 𝑌𝑢𝑣=0 các chuỗi được lấy mẫu từ {𝑥𝑒(𝑡)} và {𝑥𝑔(𝑡)}, tương ứng, cho 𝑒≠𝑔.

Trong phần thực nghiệm, chúng tôi so sánh biến thể cơ bản của mất mát tương phản với các biến thể thay thế. Kết quả của việc so sánh được trình bày trong Phần 4.2.1.

Lấy mẫu tiêu cực. Một thách thức trong phương pháp học tương phản là các cặp tích cực bị lấn át bởi các cặp tiêu cực tiềm năng. Hơn nữa, một số cặp tiêu cực đủ xa, để không cung cấp bất kỳ phản hồi có giá trị nào thông qua L cho 𝑀 trong quá trình huấn luyện [32,33]. Chúng tôi so sánh các phương pháp lấy mẫu tiêu cực phổ biến trong Phần 4.2. Do một số phương pháp lấy mẫu tiêu cực có nhận thức về khoảng cách và để làm cho việc tính toán khoảng cách tổng thể ít không hiệu quả hơn, chúng tôi giới hạn bộ mã hóa 𝑀 vào lớp các ánh xạ xuất ra các vector đơn vị chuẩn trong R𝑑. Do đó khoảng cách theo cặp 𝑑𝑀(𝑢,𝑣)² chỉ là 2−2𝑐⊤𝑢𝑐𝑣, chỉ yêu cầu các tích vô hướng theo cặp giữa các embedding 𝑐𝑣=𝑀({˜𝑥𝑢(𝑡)}).

3.4 Kiến trúc bộ mã hóa

Embedding một chuỗi sự kiện thành một vector có kích thước cố định yêu cầu mã hóa các sự kiện cá nhân tiếp theo là tổng hợp toàn bộ chuỗi. Mô hình bộ mã hóa tổng hợp 𝑀 trong CoLES có dạng 𝑀({𝑥𝑡}):=𝜙seq({𝜙evt(𝑥𝑡)}), trong đó 𝜙evt và 𝜙seq là các mạng embedding mức sự kiện và mức chuỗi, tương ứng, được huấn luyện theo cách end-to-end để tối thiểu hóa mất mát tương phản L(𝑀).

Bộ mã hóa sự kiện 𝜙evt lấy một tập hợp các thuộc tính của mỗi sự kiện 𝑥𝑡 và xuất ra biểu diễn trung gian của nó trong R𝑑: 𝑧𝑡=𝜙evt(𝑥𝑡). Bộ mã hóa này bao gồm một số lớp tuyến tính, để embedding các thuộc tính phân loại được mã hóa one-hot, và các lớp chuẩn hóa batch, được áp dụng cho các thuộc tính số của sự kiện. Đầu ra của những lớp này được nối lại để tạo ra embedding sự kiện 𝑧𝑡.

Bộ mã hóa chuỗi 𝜙seq lấy các biểu diễn trung gian của các sự kiện 𝑧1:𝑇=𝑧1,𝑧2,···𝑧𝑇 và xuất ra biểu diễn 𝑐𝑡 của chuỗi của chúng đến thời điểm 𝑡: 𝑐𝑡=𝜙seq(𝑧1:𝑡). 𝑐𝑇 cuối cùng được sử dụng làm embedding của toàn bộ chuỗi sự kiện. Trong các thí nghiệm của chúng tôi, chúng tôi sử dụng GRU [5], một mạng tuần hoàn thể hiện hiệu suất mạnh mẽ trên dữ liệu tuần tự [1]. Trong trường hợp này, 𝜙seq được tính bởi phép lặp 𝑐𝑡+1=GRU(𝑧𝑡+1,𝑐𝑡) bắt đầu từ 𝑐0 đã học. Chúng tôi lưu ý rằng các kiến trúc khác là có thể, bao gồm LSTM và transformers [16, 39] (xem Phần 4.2.1).

Để tóm tắt, CoLES bao gồm ba thành phần chính: bộ mã hóa chuỗi sự kiện, chiến lược tạo cặp tích cực và tiêu cực, và hàm mất mát cho học tương phản.

4 THÍ NGHIỆM

4.0.1 Bộ dữ liệu. Chúng tôi so sánh phương pháp của chúng tôi với các baseline hiện có trên một số bộ dữ liệu chuỗi sự kiện có sẵn công khai từ các cuộc thi khoa học dữ liệu khác nhau. Chúng tôi chọn các bộ dữ liệu với số lượng đủ các sự kiện rời rạc trên mỗi người dùng.

Cuộc thi dự đoán nhóm tuổi: Bộ dữ liệu 44M giao dịch thẻ tín dụng ẩn danh đại diện cho 50K cá nhân được sử dụng để dự đoán nhóm tuổi của một người. Nhãn mục tiêu đa lớp chỉ được biết cho 30K bản ghi, và trong tập con này các nhãn được cân bằng. Mỗi giao dịch bao gồm ngày, loại và số tiền được tính phí.

Cuộc thi dự đoán churn: Bộ dữ liệu 1M giao dịch thẻ ẩn danh đại diện cho 10K khách hàng được sử dụng để dự đoán xác suất churn. Mỗi giao dịch được đặc trưng bởi ngày, loại, số tiền và Mã Danh mục Thương gia. Nhãn mục tiêu nhị phân chỉ được biết cho 5K khách hàng, và các nhãn gần như cân bằng.

Cuộc thi dự đoán đánh giá: Nhiệm vụ là dự đoán kết quả đánh giá trong trò chơi dựa trên lịch sử dữ liệu chơi game của trẻ em. Mục tiêu là một trong bốn điểm, với tỷ lệ 0.50, 0.24, 0.14, 0.12. Bộ dữ liệu bao gồm 12M sự kiện chơi game được kết hợp trong 330K gameplay đại diện cho 18K trẻ em. Chỉ có 17.7K gameplay được gắn nhãn. Mỗi sự kiện gameplay được đặc trưng bởi timestamp, mã sự kiện, bộ đếm gia tăng của các sự kiện trong một phiên trò chơi, thời gian kể từ khi bắt đầu phiên trò chơi, v.v.

Dự đoán nhóm tuổi lịch sử mua hàng bán lẻ: Nhiệm vụ là dự đoán nhóm tuổi của khách hàng dựa trên lịch sử mua hàng bán lẻ của họ. Nhóm tuổi được biết cho tất cả khách hàng. Tỷ lệ nhóm được cân bằng trong bộ dữ liệu. Bộ dữ liệu bao gồm 45.8M giao dịch mua hàng bán lẻ đại diện cho 400K khách hàng. Mỗi giao dịch mua hàng được đặc trưng bởi thời gian, mức sản phẩm, phân khúc, số tiền, giá trị, điểm chương trình khách hàng thân thiết nhận được.

Cuộc thi chấm điểm: Bộ dữ liệu 443M giao dịch thẻ tín dụng ẩn danh đại diện cho 1.47M người được sử dụng để dự đoán xác suất vỡ nợ sản phẩm tín dụng. Nhãn được biết cho 0.96M người. Tỷ lệ vỡ nợ là 2.76% trong bộ dữ liệu. Mỗi giao dịch bao gồm tập hợp các đặc trưng ngày, tập hợp các đặc trưng loại, và số tiền được tính phí.

4.0.2 Tính lặp lại và định kỳ của các bộ dữ liệu. Để kiểm tra rằng các bộ dữ liệu được xem xét tuân theo giả định về tính lặp lại và định kỳ của chúng tôi được đưa ra trong Phần 3.2, chúng tôi đã thực hiện các thí nghiệm sau. Chúng tôi đo lường phân kỳ KL giữa hai loại mẫu: (1) giữa các lát cắt ngẫu nhiên của cùng một chuỗi, được tạo ra bằng cách sử dụng một phiên bản sửa đổi của Thuật toán 1 trong đó các sự kiện chồng lấp bị loại bỏ, và (2) giữa các mẫu con ngẫu nhiên được lấy từ các chuỗi khác nhau của các sự kiện. Kết quả được hiển thị trong Hình 2, cho thấy rằng phân kỳ KL giữa các chuỗi con của cùng một chuỗi sự kiện tương đối nhỏ so với phân kỳ KL điển hình giữa các mẫu con của các chuỗi sự kiện khác nhau. Quan sát này hỗ trợ giả định về tính lặp lại và định kỳ của chúng tôi. Cũng lưu ý rằng biểu đồ bổ sung (2d) được cung cấp như một ví dụ cho dữ liệu không có bất kỳ cấu trúc lặp lại nào.

4.0.3 Chia bộ dữ liệu. Đối với mỗi bộ dữ liệu, chúng tôi tách ra 10% người từ phần được gắn nhãn của dữ liệu làm tập kiểm tra, được sử dụng để đánh giá. 90% còn lại của dữ liệu được gắn nhãn và dữ liệu chưa gắn nhãn tạo thành tập huấn luyện của chúng tôi được sử dụng để học. Các siêu tham số của mỗi phương pháp được lựa chọn bằng tìm kiếm ngẫu nhiên trên cross-validation 5-fold trên tập huấn luyện.

Để học các kỹ thuật bán giám sát/tự giám sát (bao gồm CoLES), chúng tôi sử dụng tất cả các giao dịch của tập huấn luyện bao gồm dữ liệu chưa gắn nhãn. Các phần chưa gắn nhãn của các bộ dữ liệu bị bỏ qua khi huấn luyện các mô hình có giám sát.

4.0.4 Hiệu suất huấn luyện. Các mạng nơ-ron được huấn luyện trên một card GPU Tesla P-100 duy nhất. Ở giai đoạn huấn luyện của CoLES, mỗi batch huấn luyện đơn lẻ được xử lý trong 142 mili giây. Ví dụ, trong bộ dữ liệu dự đoán nhóm tuổi, một batch đơn lẻ chứa 64 cá nhân duy nhất với năm chuỗi con cho mỗi cá nhân, tức là tổng cộng 320 chuỗi con huấn luyện, mỗi chuỗi trung bình 90 giao dịch, có nghĩa là mỗi batch chứa khoảng 28800 giao dịch.

4.0.5 Siêu tham số. Trừ khi được chỉ định khác, chúng tôi sử dụng mất mát tương phản và chiến lược tạo cặp lát cắt ngẫu nhiên cho CoLES trong các thí nghiệm của chúng tôi (xem Phần 4.2 để biết lý do). Tập hợp siêu tham số cuối cùng được sử dụng cho CoLES được hiển thị trong Bảng 1.

4.1 Baseline

4.1.1 LightGBM. Máy Tăng cường Gradient (GBM) [13] thường được coi là một baseline mạnh trong trường hợp dữ liệu dạng bảng với các đặc trưng không đồng nhất [27,40,43,49]. Trong các thí nghiệm của chúng tôi, chúng tôi sử dụng LightGBM [20] làm mô hình cho tác vụ hạ nguồn (xem Hình 1, Giai đoạn 2a) và xem xét các đặc trưng đầu vào thay thế: (1) vector các đặc trưng tổng hợp được tạo thủ công từ dữ liệu giao dịch thô, hoặc (2) embedding của chuỗi giao dịch, được tạo ra bởi mạng bộ mã hóa (xem Phần 3.4). Đối với trường hợp thứ hai, mô hình bộ mã hóa được huấn luyện theo cách tự giám sát hoặc với CoLES hoặc một trong các phương pháp thay thế của nó, được mô tả trong Phần 4.1.3.

4.1.2 Đặc trưng được tạo thủ công. Tất cả các thuộc tính của mỗi giao dịch hoặc là số, ví dụ số tiền, hoặc là phân loại, ví dụ danh mục thương gia (mã MCC), loại giao dịch, v.v. Đối với các thuộc tính số, chúng tôi áp dụng các hàm tổng hợp, như 'sum', 'mean', 'std', 'min', 'max', trên tất cả các giao dịch trên mỗi chuỗi. Ví dụ, nếu chúng tôi áp dụng 'sum' trên trường số 'amount' chúng tôi nhận được một đặc trưng 'tổng của tất cả số tiền giao dịch trên mỗi chuỗi'. Các thuộc tính phân loại được tổng hợp theo cách hơi khác. Chúng tôi nhóm các giao dịch riêng biệt theo từng giá trị duy nhất của mỗi thuộc tính phân loại và áp dụng một hàm tổng hợp, như 'count', 'mean', 'std' trên tất cả các thuộc tính số. Ví dụ, nếu chúng tôi áp dụng 'mean' cho thuộc tính số 'amount' được nhóm theo thuộc tính phân loại 'MCC code' chúng tôi có được một đặc trưng 'số tiền trung bình của tất cả các giao dịch cho mã MCC cụ thể' trên mỗi chuỗi.

4.1.3 Baseline tự giám sát. Chúng tôi so sánh phương pháp CoLES với các phương pháp chính hiện có về embedding tự giám sát, áp dụng được cho dữ liệu chuỗi sự kiện.

NSP. Chúng tôi xem xét một baseline đơn giản lấy cảm hứng từ tác vụ dự đoán câu tiếp theo trong BERT [9]. Cụ thể, chúng tôi tạo ra hai chuỗi con A và B theo cách mà 50% thời gian B theo sau A trong cùng một chuỗi (cặp tích cực), và 50% thời gian nó là một đoạn ngẫu nhiên từ một chuỗi khác (cặp tiêu cực).

SOP. Một baseline khác cũng giống như tác vụ dự đoán thứ tự chuỗi từ ALBERT [22], sử dụng hai chuỗi con liên tiếp như một cặp tích cực, và hai chuỗi con liên tiếp với thứ tự bị đảo như một cặp tiêu cực.

RTD. Phương pháp phát hiện token bị thay thế từ ELECTRA [8] cũng có thể được điều chỉnh cho các chuỗi sự kiện. Để có được baseline này, chúng tôi thay thế 15% sự kiện từ chuỗi bằng các sự kiện ngẫu nhiên, được lấy từ các chuỗi khác và huấn luyện một mô hình để dự đoán liệu một sự kiện có bị thay thế hay không.

CPC. Ngoài ra, chúng tôi so sánh với Mã hóa Dự đoán Tương phản (CPC) [38] – một phương pháp học tự giám sát thể hiện hiệu suất tiên tiến trên dữ liệu tuần tự âm thanh, thị giác máy tính, học tăng cường và các lĩnh vực hệ thống gợi ý [51].

4.2 Kết quả

4.2.1 Thảo luận về các lựa chọn thiết kế. Để đánh giá phương pháp tạo chuỗi con được đề xuất (xem Phần 3.2), chúng tôi so sánh nó với hai phương pháp thay thế: (1) Chiến lược lấy mẫu ngẫu nhiên không thay thế, tương tự như [45], và (2) chiến lược mẫu rời rạc ngẫu nhiên, giống với việc tạo ra được đề xuất trong [23]. Phương pháp đầu tiên tạo ra một chuỗi con không liên tục của các sự kiện, bằng cách liên tục rút một sự kiện ngẫu nhiên từ chuỗi không thay thế giữ nguyên thứ tự trong chuỗi của các sự kiện được lấy mẫu. Phương pháp thứ hai tạo ra các chuỗi con bằng cách phân tách ngẫu nhiên chuỗi ban đầu thành một số đoạn liên tục không chồng lấp. Động lực là sự chồng lấp giữa các chuỗi con có thể dẫn đến overfitting, vì các chuỗi con sự kiện chính xác giống nhau và có thể được "ghi nhớ" bởi bộ mã hóa mà không học được sự tương tự cơ bản.

Kết quả của việc so sánh được trình bày trong Bảng 2. Chiến lược được đề xuất về tạo ra các lát cắt chuỗi con ngẫu nhiên luôn vượt trội hơn các phương pháp thay thế.

Chúng tôi đánh giá một số hàm mất mát học tương phản cho thấy hiệu suất hứa hẹn trên các bộ dữ liệu khác nhau [19] và một số biến thể cổ điển, cụ thể là: mất mát tương phản [14], mất mát độ lệch nhị thức [46], mất mát triplet [17], mất mát histogram [37], và mất mát lề [24]. Kết quả so sánh được hiển thị trong Bảng 4. Đáng chú ý, mặc dù mất mát tương phản có thể được coi là biến thể cơ bản của học tương phản, nhưng nó vẫn có thể đạt được kết quả mạnh mẽ trên các tác vụ hạ nguồn. Chúng tôi suy đoán rằng sự gia tăng hiệu suất của mô hình trên tác vụ học tương phản không phải lúc nào cũng dẫn đến hiệu suất tăng trên các tác vụ hạ nguồn.

Chúng tôi cũng so sánh các chiến lược lấy mẫu tiêu cực phổ biến (lấy mẫu có trọng số khoảng cách [24], và khai thác hard-negative [32]) với chiến lược lấy mẫu tiêu cực ngẫu nhiên (xem Bảng 5). Chúng tôi có thể quan sát rằng khai thác hard negative dẫn đến sự gia tăng chất lượng có thể đo lường trên các tác vụ hạ nguồn so với lấy mẫu tiêu cực ngẫu nhiên.

Một lựa chọn thiết kế khác có thể của phương pháp là kiến trúc bộ mã hóa. Chúng tôi so sánh một số tùy chọn phổ biến cho bộ mã hóa chuỗi: GRU [5], LSTM [16] và Transformer [39]. Bảng 3 cho thấy rằng việc lựa chọn kiến trúc bộ mã hóa có ít ảnh hưởng đến hiệu suất của phương pháp được đề xuất.

Hình 3 cho thấy rằng hiệu suất trên tác vụ hạ nguồn thể hiện lợi ích giảm dần khi chiều của embedding tăng lên. Những kết quả này có thể được diễn giải thông qua lăng kính của sự đánh đổi bias-variance: khi chiều quá thấp, quá nhiều thông tin bị loại bỏ (bias cao), tuy nhiên, khi nó quá cao, thì nhiều tiếng ồn không liên quan hơn thấm vào embedding (variance cao). Lưu ý rằng thời gian huấn luyện và tiêu thụ bộ nhớ tăng tuyến tính với kích thước embedding.

4.2.2 Embedding tự giám sát. Chúng tôi so sánh CoLES với các baseline được mô tả trong Phần 4.1 trong hai tình huống. Đầu tiên, chúng tôi so sánh các embedding được tạo ra bởi CoLES với các loại embedding khác, bao gồm cả những embedding được tạo thủ công, bằng cách sử dụng chúng như đầu vào cho một mô hình LightGBM hạ nguồn (xem Hình 1, Giai đoạn 2a), được huấn luyện độc lập với bộ mã hóa chuỗi. Như Bảng 6 chứng minh, các embedding chuỗi, được tạo ra bởi CoLES, hoạt động ngang ngửa và đôi khi thậm chí tốt hơn các đặc trưng được thiết kế thủ công. Hơn nữa, CoLES luôn vượt trội hơn các baseline tự giám sát khác trên bốn trong số năm bộ dữ liệu được xem xét.

Trên bộ dữ liệu chấm điểm, lớn hơn các bộ dữ liệu khác, CoLES, CPC, và RTD, vượt trội hơn baseline được tạo thủ công. Tính chất tự hồi quy của CPC phù hợp tốt với tác vụ chấm điểm tín dụng, mà thông tin gần đây hơn thì càng liên quan đến mục tiêu. Các embedding RTD cũng hiệu quả cho chấm điểm tín dụng, vì phương pháp dựa vào phát hiện bất thường.

Các đặc trưng được tạo thủ công đơn giản có thể đạt được kết quả cạnh tranh nếu các sự kiện có cấu trúc rõ ràng để thiết kế chúng, ví dụ, việc tính toán thống kê tổng hợp theo nhóm của dữ liệu lịch sử dựa trên một thuộc tính nào đó là đơn giản. Trong thiết lập thương mại (Phần 4.3), tình hình có thể khác: việc tạo ra các đặc trưng có ý nghĩa cho các giao dịch của các thực thể pháp lý không hề tầm thường, vì không rõ ràng các nhóm tự nhiên là gì. Chúng tôi thảo luận về sự khác biệt giữa các sự kiện đơn giản (giao dịch thẻ) và các sự kiện phức tạp hơn (giao dịch của các thực thể pháp lý) ở cuối Phần 4.3.

4.2.3 Embedding được tinh chỉnh. Trong tình huống thứ hai, chúng tôi tinh chỉnh các mô hình được tiền huấn luyện cho các tác vụ hạ nguồn cụ thể (xem Hình 1, Giai đoạn 2b). Các mô hình được tiền huấn luyện bằng CoLES hoặc một phương pháp học tự giám sát khác và sau đó được huấn luyện trên dữ liệu được gắn nhãn cho tác vụ cuối cụ thể.

Bước tinh chỉnh được thực hiện bằng cách thêm một mạng phân loại ℎ (mạng nơ-ron một lớp với kích hoạt softmax) vào mạng bộ mã hóa được tiền huấn luyện 𝑀 (xem Phần 3.4). Cả hai mạng đều được huấn luyện cùng nhau trên tác vụ hạ nguồn, tức là bộ phân loại lấy đầu ra của bộ mã hóa và tạo ra một dự đoán (ˆ𝑦=ℎ(𝑀({𝑥}))) và lỗi của nó lan truyền ngược qua cả hai. Ngoài các baseline đã nêu trên, chúng tôi so sánh phương pháp của chúng tôi với một phương pháp học có giám sát, trong đó mạng bộ mã hóa 𝑀 không được tiền huấn luyện sử dụng mục tiêu tự giám sát.

Như Bảng 7 cho thấy, các biểu diễn CoLES được thu thập sau tinh chỉnh đạt được hiệu suất vượt trội trên tất cả các bộ dữ liệu được xem xét, vượt trội hơn các phương pháp khác với lề đáng kể.

4.2.4 Thiết lập bán giám sát. Ở đây chúng tôi nghiên cứu khả năng áp dụng của phương pháp chúng tôi trong các tình huống mà số lượng ví dụ được gắn nhãn bị hạn chế. Chúng tôi thực hiện một loạt thí nghiệm trong đó chỉ một phần ngẫu nhiên của các nhãn có sẵn được sử dụng để huấn luyện các mô hình tác vụ hạ nguồn. Như trong trường hợp thiết lập có giám sát, chúng tôi so sánh phương pháp được đề xuất với các đặc trưng được tạo thủ công, CPC, và học có giám sát không có tiền huấn luyện. Kết quả được trình bày trong Hình 4. Lưu ý rằng cải thiện hiệu suất của CoLES so với các phương pháp chỉ có giám sát tăng lên khi chúng tôi giảm phần của các ví dụ được gắn nhãn trong bộ dữ liệu huấn luyện. Cũng lưu ý rằng CoLES luôn vượt trội hơn CPC cho các khối lượng dữ liệu được gắn nhãn khác nhau.

4.3 Embedding CoLES trong Thiết lập Thương mại

Chúng tôi áp dụng phương pháp CoLES tự giám sát được đề xuất cho một số tác vụ học máy, được xem xét thường xuyên trong một công ty dịch vụ tài chính lớn của châu Âu. Cụ thể, hai loại embedding được tạo ra: (1) embedding thực thể pháp lý của các công ty vừa và nhỏ, dựa trên các giao dịch thương mại và lịch sử hoạt động của doanh nghiệp của họ, và (2) embedding cá nhân của khách hàng cá nhân/bán lẻ, dựa trên lịch sử giao dịch thẻ ghi nợ/tín dụng của họ. Bảng 8 và 9 cung cấp ví dụ về dữ liệu giao dịch được sử dụng để xây dựng embedding của cá nhân và thực thể pháp lý. Tổng thể, bộ dữ liệu mười triệu khách hàng doanh nghiệp với trung bình 200 giao dịch trên mỗi khách hàng được sử dụng để huấn luyện embedding của loại (1), và bộ dữ liệu năm triệu khách hàng cá nhân với số lượng giao dịch trung bình 400 trên mỗi khách hàng được sử dụng để huấn luyện mô hình cho embedding của loại (2). Hai bộ dữ liệu thương mại "nội bộ" này lớn hơn đáng kể so với các bộ dữ liệu công khai được nêu trong Phần 4, và khối lượng dữ liệu huấn luyện tự giám sát bổ sung cho phép chúng tôi tạo ra các embedding có chất lượng cao hơn đáng kể so với dữ liệu có sẵn công khai.

Chúng tôi thực hiện đánh giá mở rộng của các embedding CoLES trên những bộ dữ liệu nội bộ này bằng cách áp dụng chúng cho các tác vụ hạ nguồn khác nhau. Embedding thực thể pháp lý được áp dụng trong các trường hợp sử dụng sau:

• Tạo khách hàng tiềm năng bảo hiểm y tế doanh nghiệp. Trong tác vụ này, mô hình phải có khả năng dự đoán sự quan tâm của khách hàng đối với sản phẩm bảo hiểm y tế doanh nghiệp.

• Tạo khách hàng tiềm năng tín dụng cho các doanh nghiệp vừa và nhỏ. Trong tác vụ này, mô hình phải dự đoán sự quan tâm của một công ty trong việc vay tín dụng.

• Chấm điểm tín dụng cho các doanh nghiệp vừa và nhỏ. Trong tác vụ này, mô hình phải dự đoán xác suất vỡ nợ của một công ty.

• Khôi phục cấu trúc tập đoàn. Trong tác vụ này, mô hình phải dự đoán nếu một cặp công ty trong cùng một tập đoàn công ty.

• Giám sát chuyển tiền gian lận. Trong tác vụ này, mô hình được sử dụng để ước tính khả năng một giao dịch cụ thể là gian lận.

Ngược lại với các thực thể pháp lý, embedding cá nhân được sử dụng trong các tác vụ hạ nguồn sau:

• Chấm điểm tín dụng bán lẻ. Trong tác vụ này, mô hình phải ước tính xác suất vỡ nợ khi một khách hàng vay tín dụng bán lẻ.

• Dự đoán churn khách hàng. Trong tác vụ này, mô hình phải dự đoán khả năng một khách hàng sẽ ngừng sử dụng các sản phẩm của công ty (thẻ và tài khoản tiền gửi).

• Tạo khách hàng tiềm năng bảo hiểm nhân thọ. Trong tác vụ này, mô hình phải dự đoán sự quan tâm đối với sản phẩm bảo hiểm nhân thọ.

Chúng tôi xem xét ba tình huống sau trong hầu hết các tác vụ này: (1) tình huống cơ bản – chỉ sử dụng các đặc trưng được tạo thủ công; (2) tình huống CoLES – các embedding tự giám sát được tạo ra phục vụ như đặc trưng; (3) tình huống lai (Cơ bản + CoLES), kết hợp các đặc trưng được tạo thủ công và embedding CoLES. Trong tất cả ba tình huống này, chúng tôi sử dụng phương pháp LightGBM [20] để mô hình hóa trong tác vụ hạ nguồn. Trong tình huống thứ nhất và thứ ba, chúng tôi triển khai các tập hợp đặc trưng được tạo thủ công, được sử dụng trước đây trong tổ chức (xem Phần 4.1.2 cho ví dụ về các đặc trưng được tạo thủ công được sử dụng).

Kết quả của các thí nghiệm của chúng tôi được trình bày trong Bảng 10 và 11. Chúng tôi quan sát rằng các embedding CoLES cải thiện đáng kể so với các đặc trưng được tạo thủ công về hiệu suất thử nghiệm trên tác vụ cuối.

Lưu ý rằng việc thiết kế các đặc trưng được tạo thủ công có giá trị cho các thực thể pháp lý khó khăn hơn so với khách hàng cá nhân. Một đặc trưng điển hình là một số thống kê được tổng hợp trên các nhóm giao dịch ở một mức độ nào đó. Ví dụ, người ta có thể tổng hợp các giao dịch thẻ của một khách hàng cá nhân ở mức trường "loại thương gia" (MCC) của họ. Ngược lại, không rõ ràng cách nhóm các chuyển tiền của một công ty theo trường "người nhận" (xem ví dụ trong Bảng 9). Khó để thủ công tìm ra một mức tổng hợp hoàn hảo cho người nhận, vì họ có thể được nhóm theo nhiều cách khác nhau, ví dụ theo khu vực, quy mô, loại hình kinh doanh, v.v. Chúng tôi tin rằng CoLES có thể tự động học được một mức tổng hợp phù hợp. Đây là một trong những lý do tại sao trong các thí nghiệm của chúng tôi, các embedding thực thể pháp lý thể hiện cải thiện tương đối cao hơn so với các đặc trưng được tạo thủ công so với embedding cá nhân.

4.3.1 Chi tiết triển khai. Trong môi trường sản xuất, phương pháp của chúng tôi được áp dụng trong hai giai đoạn: huấn luyện mạng nơ-ron bộ mã hóa 𝑀 (phần huấn luyện), tiếp theo là tính toán các embedding với nó (phần suy luận). Chúng tôi chỉ sử dụng một phần dữ liệu có sẵn để huấn luyện (10 triệu khách hàng doanh nghiệp, và 5 triệu khách hàng cá nhân), nhưng áp dụng embedder đã học cho tất cả dữ liệu giao dịch có sẵn, với hơn 90 triệu thẻ tổng cộng. Chúng tôi không sử dụng bất kỳ kỹ thuật huấn luyện phân tán có sẵn nào [21,29,50] trong phần huấn luyện. Trong giai đoạn suy luận, chúng tôi tận dụng sơ đồ mở rộng ngang, trong đó các chuỗi khác nhau được xử lý độc lập song song trên các nút khác nhau của một cụm Hadoop.

Để giảm thiểu nỗ lực triển khai các embedding CoLES bên trong công ty, chúng tôi sử dụng một quy trình ETL để tính toán lại các embedding một cách tăng dần khi có dữ liệu giao dịch mới. Cụ thể, không giống như transformers, các bộ mã hóa tuần hoàn 𝜙enc, như GRU [6], tái sử dụng các tính toán trước đó và cho phép tính toán tăng dần: embedding 𝑐𝑡+𝑘 có thể được tính toán một cách lặp đi lặp lại từ 𝑐𝑡 và (𝑧𝑡+𝑗)𝑘𝑗=1, sử dụng 𝑐𝑡+𝑗=𝜙enc(𝑧𝑡+𝑗,𝑐𝑡+𝑗−1). Lựa chọn kiến trúc này giảm thời gian suy luận cần thiết để cập nhật các embedding trực tuyến.

Hơn nữa, bằng cách sử dụng một kỹ thuật lượng tử hóa, có thể nén các embedding chuỗi, mà không mất nhiều hiệu suất trên các tác vụ hạ nguồn. Ví dụ, các giá trị độ chính xác đơn trong embedding có thể được ánh xạ vào phạm vi từ 0 đến 15, làm cho một embedding 256 chiều ban đầu chiếm 1Kb, chỉ chiếm 128 byte.

5 KẾT LUẬN

Trong bài báo này, chúng tôi trình bày Học Tương Phản cho Chuỗi Sự Kiện (CoLES), một phương pháp tự giám sát mới để xây dựng embedding của các chuỗi sự kiện rời rạc. CoLES có thể được sử dụng hiệu quả để tạo ra embedding của các chuỗi sự kiện phức tạp cho các tác vụ hạ nguồn khác nhau.

Chúng tôi chứng minh thực nghiệm rằng phương pháp của chúng tôi đạt được kết quả hiệu suất mạnh mẽ trên một số tác vụ hạ nguồn và luôn vượt trội hơn cả các baseline học máy cổ điển trên các đặc trưng được tạo thủ công, cũng như trên một số baseline học tự giám sát và bán giám sát hiện có được điều chỉnh cho lĩnh vực chuỗi sự kiện. Trong thiết lập bán giám sát, nơi số lượng dữ liệu được gắn nhãn bị hạn chế, phương pháp của chúng tôi thể hiện hiệu suất tự tin: dữ liệu được gắn nhãn càng ít, lề hiệu suất giữa CoLES và các phương pháp chỉ có giám sát càng lớn.

Cuối cùng, chúng tôi chứng minh hiệu suất vượt trội của CoLES trong một số ứng dụng cấp độ sản xuất, được sử dụng nội bộ trong công ty dịch vụ tài chính của chúng tôi. Phương pháp tạo embedding được đề xuất có vẻ hữu ích trong môi trường sản xuất vì các embedding được tính toán trước có thể được sử dụng dễ dàng cho các tác vụ hạ nguồn khác nhau mà không cần thực hiện các tính toán phức tạp và tốn thời gian trên dữ liệu sự kiện thô.

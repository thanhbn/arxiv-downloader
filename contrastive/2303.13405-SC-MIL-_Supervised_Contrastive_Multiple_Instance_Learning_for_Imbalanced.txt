# 2303.13405.pdf
# Converted from PDF to TXT
# Source path: /home/admin88/arxiv-downloader/contrastive/2303.13405.pdf
# File size: 2209279 bytes

===============================================
PDF FILE CONTENT
===============================================


--- PAGE 1 ---
SC-MIL: Supervised Contrastive Multiple Instance Learning for Imbalanced
Classification in Pathology
Dinkar Juyal
PathAI Inc
Boston, USA
dinkar.juyal@pathai.comSiddhant Shingi∗
University of Massachusetts
Amherst, USASyed Ashar Javed
PathAI Inc
Harshith Padigela
PathAI IncChintan Shah
PathAI IncAnand Sampat
PathAI IncArchit Khosla
PathAI IncJohn Abel
PathAI Inc
Amaro Taylor-Weiner
PathAI Inc
Abstract
Multiple Instance learning (MIL) models have been ex-
tensively used in pathology to predict biomarkers and risk-
stratify patients from gigapixel-sized images. Machine
learning problems in medical imaging often deal with rare
diseases, making it important for these models to work in
a label-imbalanced setting. In pathology images, there is
another level of imbalance, where given a positively la-
beled Whole Slide Image (WSI), only a fraction of pixels
within it contribute to the positive label. This compounds
the severity of imbalance and makes imbalanced classifi-
cation in pathology challenging. Furthermore, these imbal-
ances can occur in out-of-distribution (OOD) datasets when
the models are deployed in the real-world. We leverage
the idea that decoupling feature and classifier learning can
lead to improved decision boundaries for label imbalanced
datasets. To this end, we investigate the integration of su-
pervised contrastive learning with multiple instance learn-
ing (SC-MIL). Specifically, we propose a joint-training MIL
framework in the presence of label imbalance that progres-
sively transitions from learning bag-level representations to
optimal classifier learning. We perform experiments with
different imbalance settings for two well-studied problems
in cancer pathology: subtyping of non-small cell lung can-
cer and subtyping of renal cell carcinoma. SC-MIL provides
large and consistent improvements over other techniques on
both in-distribution (ID) and OOD held-out sets across mul-
tiple imbalanced settings.
*Work done during internship at PathAI1. Introduction
Pathology is the microscopic study of tissue and a key
component in medical diagnosis and drug development
[27]. The digitization of tissue slides, resulting in whole
slide images (WSIs), has made pathology data more ac-
cessible for quantitative analysis. However, the large size
(billions of pixels) and information density (hundreds of
thousands of cells and heterogeneous tissue organization)
of WSIs make manual analysis challenging [13, 24], high-
lighting the need for machine learning (ML) approaches
[1–3, 5, 9, 18, 20, 28]. ML techniques have been used for
predicting a patient’s clinical characteristics from a WSI.
These models predict a label or score for the entire WSI,
referred to as a slide-level prediction. Traditional ap-
proaches for handling large WSIs include the use of hand-
engineered representations or breaking the slide into thou-
sands of smaller patches [8]. Both of these approaches
require pixel or patch level annotations which are costly.
To overcome the need for patch level labels, multiple in-
stance learning (MIL) [21] has been applied to pathology
by treating patches from slides as instances that form a bag,
with a slide-level label associated with each bag. The MIL
framework thus provides an end-to-end learning approach
for problems in pathology.
Label distribution in real-world settings can vary con-
siderably depending on factors such as disease prevalence,
population characteristics and the hospital or laboratory of
origin. For example, a dataset of WSIs from a diagnos-
tic lab may have a different class distribution compared to a
dataset from a clinical trial enriched for certain disease char-
acteristics. In fact, label imbalance in pathology datasets
1arXiv:2303.13405v2  [cs.CV]  9 Sep 2023

--- PAGE 2 ---
Figure 1. Label imbalance in histopathology domain is present at
two levels - Dataset and Whole Slide Image (WSI). In datasets,
imbalance arises from different prevalence rates of diseases. For
a given WSI with positive label, only a small subset of patches
contribute to that positive label. This compounds the severity of
imbalance, making imbalanced classification in pathology chal-
lenging.
exists at both dataset and WSI level as shown in Figure 1.
MIL models should be robust to variations in label distribu-
tion to succeed in clinical applications and maintain physi-
cian trust. Different approaches have been proposed to deal
with label imbalance, ranging from data resampling (over-
sampling of minority classes or undersampling of majority
classes) [22,23], loss reweighting [25], selective enrichment
of minority classes in image or feature space [6], decoupling
representation learning from classification [33], and custom
loss functions [4].
Contrastive learning aims to learn representations that
maximize the agreement among positive instances, e.g., dif-
ferent augmentations of the same image, and minimize the
agreement with negative instances, e.g., other images in the
dataset [7]. In supervised contrastive learning (SCL) [16],
the contrastive loss formulation incorporates label informa-
tion by treating all instances within the same class as pos-
itive examples for a given image. SCL adopts a two-stage
learning technique where a feature extractor is learned in
the first stage using a contrastive loss, followed by learning
a classifier using the cross-entropy loss in the second stage.
This work proposes SC-MIL: a novel MIL technique to
tackle label imbalance in pathology, that integrates SCL into
the MIL framework. We take inspiration from prior work
[10,14] which shows that a) contrastive loss learns balanced
feature spaces (i.e., feature spaces with similar inter-class
separation for all classes) compared to cross-entropy, and b)
this balance is positively related to performance across im-
balanced settings. Additionally, we use a smooth transition
from feature learning to classifier learning in the course of
training, which allows the model to learn a more discrimi-Table 1. Training data-distribution of TCGA RCC sub-typing
across imbalance ratios
ClassesImbalance Ratio
1 5 10
KIRC 96 205 240
KIRP 96 41 24
KICH 96 41 24
Total 288 287 288
native latent space, aiding in imbalanced classification [30].
In the MIL setting, labels are only available for a bag (i.e., a
collection of patches) and not individual patches. Applying
SCL to patch features assumes assigning a bag-label to indi-
vidual patches. However, a single patch might not have any
information about the WSI label. For example, a malignant
WSI might have many patches which contain only normal
tissue. This motivates our bag-level formulation of SC-MIL
where contrastive loss is applied to the bag features. Feature
learning with bag-level contrastive loss tackles dataset im-
balance, while the multiple instance formulation addresses
imbalance within a WSI. The contributions of this work are
as follows:
1. We tackle the problem of label imbalance by proposing
a formulation that extends SCL to the MIL setting. We
investigate two training strategies for optimal feature
and classifier learning with SC-MIL.
2. We conduct an extensive study on the performance of
this technique across different degrees of label imbal-
ance on two open-source datasets: subtyping in non-
small cell lung cancer (NSCLC) and renal cell carci-
noma (RCC). We compare this to previous state-of-
the-art methods used for label imbalance and demon-
strate the effectiveness of using SC-MIL over these
methods.
3. We show substantial performance improvements with
SC-MIL on OOD data across multiple degrees of label
imbalance, making a strong case for its utility in real-
world deployment scenarios.
2. Supervised Contrastive Multiple Instance
Learning
2.1. Multiple Instance Learning
MIL is a weakly supervised learning approach that al-
lows learning and making predictions on a group of in-
stances. Unlike supervised learning, the MIL framework
only requires labels for the group of instances, called a bag,
2

--- PAGE 3 ---
Figure 2. SC-MIL integrates supervised contrastive learning into the MIL framework. The model performs joint feature and classifier
learning on bag representations computed using an attention-based aggregation on patches. The training objective transitions progressively
from a contrastive to a classification loss.
Table 2. Training data-distribution of TCGA NSCLC sub-typing
across imbalance ratios
ClassesImbalance Ratio
1 5 10
LUAD 158 265 290
LUSC 158 53 29
Total 316 318 319
but not the individual instances. This is valuable in the con-
text of pathology, where a collection of patches from a WSI
can be treated as a bag and this allows learning of slide-level
predictors without the need for fine-grained patch-level an-
notations. For pooling of patches, a learnt attention based
aggregation scheme [11] has been shown to be effective and
is commonly used in end-to-end pathology models.
In the binary case, a bag is considered positive if it has
at least one positive instance and negative if there are none.
Given a set of instances X={x0, x1, . . . x n}, the MIL
prediction p(X)is
p(X) =a(f(x0), f(x1), ....., f (xn)) (1)
where fis an encoder for instances, ais a permutation-
invariant aggregator, mapping from feature space to the
prediction space. Learnt aggregation functions like Atten-
tionMIL and its variants DSMIL [17], CLAM [19], Trans-MIL [26], AdditiveMIL [12] have shown significant im-
provements over heuristic aggregators like Max or Mean in
various tasks [11]. We will focus on the AttentionMIL (also
referred to as ABMIL) formulation for our discussion.
The aggregator function ain AttentionMIL has two com-
ponents. An attention module minduces a soft-attention αi
over the instances and computes an attention weighted ag-
gregation of instance features to generate the bag embed-
dingb(X). A classifier hmaps the bag feature to the bag
prediction.
p(X) =h(b(X)) (2)
b(X) =m(f(x0), f(x1), ....., f (xn)) =i=nX
i=0αif(xi)(3)
αi=softmax (ϕm(xi)) (4)
where ϕmis a neural network with a non-linear activation.
3

--- PAGE 4 ---
Table 3. Comparison of SC-MIL with other label imbalance techniques on TCGA-RCC test set for RCC subtyping (RS - Random Sampling,
CB - Class Balanced)
Dataset TCGA-RCC
Imbalance Ratio 1 5 10
Metric (%) F1 AUC F1 AUC F1 AUC
ABMIL-RS 87.17 ±2.03 96.13 ±0.96 83.40 ±2.52 95.6 ±0.99 78.23 ±2.82 93.26 ±1.39
ABMIL-CB 89.49 ±2.12 97.42 ±0.85 84.61 ±2.84 93.93 ±1.60 73.63 ±2.83 95.05 ±0.84
LDAM-DRW 89.35 ±1.92 97.65 ±0.66 83.50 ±2.45 94.96 ±1.23 80.66 ±2.93 93.08 ±1.54
SC-MIL-RS 88.67 ±2.21 98.13±0.67 86.30 ±2.03 96.83 ±0.66 87.42 ±2.07 96.40 ±0.94
SC-MIL-CB 90.13±2.17 97.98±0.65 85.53 ±2.55 96.69 ±0.82 81.34 ±2.66 96.35 ±1.11
Table 4. Comparison of SC-MIL with other label imbalance techniques on OOD-RCC test set for RCC subtyping (RS - Random Sampling,
CB - Class Balanced)
Dataset OOD-RCC
Imbalance Ratio 1 5 10
Metric (%) F1 AUC F1 AUC F1 AUC
ABMIL-RS 74.20 ±1.91 93.88 ±1.09 73.69 ±2.55 91.15 ±1.56 70.23 ±3.42 87.74 ±2.10
ABMIL-CB 77.33 ±2.55 92.79 ±1.48 72.31 ±2.33 89.49 ±1.65 71.38 ±2.88 91.82 ±1.47
LDAM-DRW 78.97 ±2.45 93.69 ±1.38 73.47 ±2.52 88.62 ±1.97 72.42 ±2.51 91.94 ±1.52
SC-MIL-RS 81.94±2.39 94.84 ±1.24 81.87 ±2.54 93.42 ±1.43 80.91 ±2.24 92.57±1.41
SC-MIL-CB 76.81 ±2.31 93.78 ±7.83 79.04 ±2.34 92.56 ±1.51 79.04 ±2.34 92.56±1.51
2.2. SC-MIL: Supervised Contrastive Multiple In-
stance Learning
SCL [16] proposes a way to leverage contrastive learn-
ing and incorporate supervision. It learns instance repre-
sentations by pulling instances from same class together
and those from different classes apart in the representation
space. In MIL, we can use SCL for learning either instance
or bag representations. Considering we only have labels
for bags and not individual instances, using SCL to learn
instance representations needs using bag labels as instance
labels, thus introducing label noise and breaking the MIL
assumption. Instead, we use SCL to learn bag representa-
tions.
Specifically, given a set of instances for a bag Xi=
{x0, x1, . . . x n}, we compute the bag representation b(Xi)
using the MIL formulation, where idenotes the index of a
bag in a given batch. We now use a non-linear multi-layer
perceptron gto generate the projection zifor the bag repre-
sentation. We then compute the SCL loss for MIL LSCL as
follows:
zi=g(b(Xi)) (5)LSCL=X
i−1
|P+
i|X
zj∈P+
ilogexp(zi·zj/τ)P
zk∈Biexp(zi·zk/τ)
(6)
where P+
idenotes the positive bags sharing the same class
label as bag ziandBiis the set of all bags in the batch
excluding bag zi.
Curriculum-based feature and classifier learning using
both contrastive and cross entropy losses has been shown
to be effective in long-tailed image classification [15]. We
apply the same approach to the MIL setting at a bag level.
For classifier learning, we use the cross-entropy loss. The
classifier branch projects the bag embedding b(X)to the
prediction p(X)as shown in Equation 2 and uses cross en-
tropyLCEto learn the classifier:
LSC−MIL =βtLSCL+ (1−βt)LCE (7)
where the weight βt∈[0,1]is decayed through the course
of training iterations tusing a curriculum to gradually tran-
sition from feature to classifier learning.
4

--- PAGE 5 ---
Table 5. Comparison of SC-MIL with other label imbalance techniques on TCGA-NSCLC test set for NSCLC subtyping (RS - Random
Sampling, CB - Class Balanced)
Dataset TCGA-NSCLC
Imbalance Ratio 1 5 10
Metric (%) F1 AUC F1 AUC F1 AUC
ABMIL-RS 82.07 ±2.5 91.36 ±1.76 81.62 ±2.62 89.84 ±2.03 77.35 ±3.18 89.68 ±2.14
ABMIL-CB 83.23 ±2.45 91.81 ±1.76 82.61 ±2.72 90.13 ±1.99 78.0 ±2.95 88.57 ±2.18
LDAM-DRW 85.8 ±2.28 91.9 ±1.78 80.91 ±2.91 89.89 ±2.13 81.56 ±2.79 89.14 ±2.15
SC-MIL-RS 87.65±2.21 94.81 ±1.34 86.66±2.34 92.45±1.78 84.05 ±2.65 91.64 ±1.81
SC-MIL-CB 84.85 ±2.52 93.14 ±1.65 87.02±2.29 92.21±1.87 80.37 ±3.02 90.96 ±1.93
Table 6. Comparison of SC-MIL with other label imbalance techniques on OOD-NSCLC test set for NSCLC subtyping (RS - Random
Sampling, CB - Class Balanced)
Dataset OOD-NSCLC
Imbalance Ratio 1 5 10
Metric (%) F1 AUC F1 AUC F1 AUC
ABMIL-RS 71.03 ±5.34 92.42 ±2.33 19.82 ±7.91 75.95 ±4.24 12.34 ±6.5 88.61 ±2.64
ABMIL-CB 36.3 ±7.97 92.54 ±1.93 15.58 ±7.04 77.25 ±4.41 8.14 ±5.57 76.71 ±4.01
LDAM-DRW 61.63 ±6.81 90.31 ±2.5 26.28 ±8.11 89.57 ±2.56 28.85 ±8.02 88.36 ±2.89
SC-MIL-RS 76.46±5.27 93.64 ±2.45 37.68±7.75 91.58 ±2.02 41.5±8.23 92.97 ±1.95
SC-MIL-CB 58.82 ±6.68 84.83 ±3.08 49.65±8.26 94.23 ±1.95 29.06±8.2 79.04 ±4.4
3. Experiments and Results
We first introduce the datasets used for experimentation.
We describe the mechanism of simulating different degrees
of imbalance in these datasets while ensuring that the to-
tal number of samples remains consistent. We then discuss
results on all datasets using SC-MIL and other baselines.
Finally, we present ablation studies to understand the trade-
offs made in terms of training supervised contrastive loss
with cross-entropy jointly vs sequentially, and the impact
of hyperparameters.
3.1. Datasets and Setup
We considered two datasets from The Cancer Genome
Atlas (TCGA) [31] - prediction of cancer subtypes in non-
small cell lung carcinoma (NSCLC) and renal cell carci-
noma (RCC). TCGA-NSCLC contains a total of 1002 WSIs
stained with H&E, 538 of which were collected from pa-
tients with the adenocarcinoma histologic subtype (LUAD)
and 464 from squamous cell carcinoma (LUSC). TCGA-
RCC contains 948 WSIs with three histologic subtypes: 158WSIs with the label chromophobe RCC (KICH), 504 WSIs
belonging to clear cell RCC (KIRC), and 286 to papillary
RCC (KIRP).
We performed a label-stratified split of both datasets
while ensuring there is no leakage of case information
(i.e., combination of tissue source site and study par-
ticipant) across splits. The splitting ratio was 60:15:25
(train:val:test); other clinical or sample characteristics were
not used during splitting. To simulate varying degrees of la-
bel imbalance, we sampled WSIs from the available classes
to generate imbalance in the train set, while the heldout sets
were kept the same. In line with previous works [4, 30], we
used imbalance ratio ρ=max i{ni}
min i{ni}which denotes the ratio
of number of examples of the majority class to the minor-
ity class. We experimented with imbalance ratios of 1, 5
and 10. We ensured that the number of training examples
remained consistent across different imbalance ratios to re-
move any confounding effect of the number of data points
and to enable comparison of model performance across im-
balance ratios. Since there were three classes in TCGA-
RCC, the two classes with least number of samples (KIRP
5

--- PAGE 6 ---
Algorithm 1 SC-MIL Pseudocode, PyTorch-like
# f: patch level feature extractor
# m: attention module
# g: projector MLP
# h: classifier
# X: bag of patches
# Y: bag label
# load a bag X=[x_1, ..., x_n] with n patches
for X in loader:
# patch level embeddings, n-by-d
E = f(X)
# attention weights, n-by-1
attn_wts = m(E)
# bag level embedding, d-by-1
B = Sum(attn_wts *E)
# projected bag embedding
Z = norm(g(B))
# bag level predictions
P = h(B)
# t_i: the current iteration
# t: total number of iterations
beta_t = 1 - t_i/t
L_scl = scl_loss(Z, other Z_i in minibatch)
L_ce = cross_entropy_loss(P, Y)
Loss = beta_t *L_scl + (1-beta_t) *L_ce
Loss.backward()
Figure 3. Visual comparison of in-distribution (ID) and out-
of-distribution (OOD) WSIs from the cancer subtyping datasets.
The first and third rows show in-distribution TCGA WSIs from
NSCLC and RCC respectively. The second and fourth rows show
WSIs procured from a different lab site and scanner. We can see
the variations in tissue preparation and scanning which lead to sig-
nificant drops in performance.
and KICH) were treated as minority classes. The details of
the resulting dataset composition is shared in Table 1 and 2.We also deployed all models on two OOD datasets col-
lected from different patient populations and having dif-
ferent sample characteristics for NSCLC and RCC. These
OOD datasets are acquired from other laboratories using
varying image acquisition and processing steps resulting
in visual differences from their TCGA counterparts. OOD
NSCLC has 162 LUAD and 45 LUSC WSIs, while OOD
RCC has 254 KIRC, 134 KIRP and 46 KICH WSIs. Exam-
ple images comparing ID and OOD datasets are shared in
Figure 3.
3.2. Implementation Details
We trained five models: a baseline AttentionMIL model
with random sampling (ABMIL-RS) and class balanced
sampling (ABMIL-CB), a version using label-distribution-
aware margin loss with deferred reweighting (LDAM-DRW
[4], previously shown to be successful for addressing label
imbalance in single instance classification), and our pro-
posed SC-MIL with random (SC-MIL-RS) and class bal-
anced sampling (SC-MIL-CB). Non-overlapping patches of
size224×224pixels were selected from tissue regions (us-
ing a separate model which masks background and artifacts)
at a resolution of 1 micron per pixel. We extracted 1.45 mil-
lion patches from TCGA-NSCLC and 768k patches from
TCGA-RCC. Bag sizes (number of patches in a bag) varied
from 24 to 1500 patches and batch sizes (number of bags
in a batch) varied from 8 to 32. Augmentations applied
included color-based augmentations (random grayscaling,
HSV transforms), gaussian blur and sharpening, horizon-
tal and vertical flips, center crops. Augmentation related
parameters were kept consistent across all techniques. An
ImageNet-pretrained ShuffleNet [32] was used to extract
features from input patches. All models were trained end-
to-end with the Adam optimizer and a learning rate of 1e-4.
SC-MIL models were trained with a temperature τ= 1,
and the training was performed jointly with cross entropy
with a linear curriculum as described in Section 2.2, with
βt= 1 at the start of training. For inference, patches were
exhaustively sampled from a WSI and the majority predic-
tion across bags was selected as the WSI-level prediction.
For RCC, macro-averaged F1 score and macro-average of
1-vs-rest AUROC was computed. Training and inference
was performed on Quadro RTX 8000 GPUs using PyTorch
v1.11 and CUDA 10.2. The training time for SC-MIL was
comparable with other techniques (10-14 GPU hours).
3.3. Experimental Results and Ablation Studies
3.3.1 Comparison of SC-MIL with other techniques
We compared the predictive performance of SC-MIL with
other techniques across different imbalance ratios. Table 3
and 5 show results on the NSCLC and RCC test sets re-
spectively. SC-MIL outperforms other techniques across all
imbalance ratios, and the difference is more pronounced at
6

--- PAGE 7 ---
Imbalance Ratio 5 Imbalance Ratio 10 
ID
OOD 
F1 Score F1 Score Figure 4. Class-wise F1 score comparison for RCC subtyping: SC-MIL outperforms other methods across different imbalance ratios. The
performance gains are higher on minority classes, and they increase on moving from ID to OOD datasets.
Table 7. Comparison of Patch vs Bag-level SCL on TCGA-RCC
subtyping. All comparisons used SC-MIL-RS training and τ= 1
Ratio Method F1 AUC
1SCL-RS 88.67±2.21 98.13 ±0.67
Patch SCL 82.87 ±2.81 97.33 ±0.82
5SCL-RS 86.30±2.03 96.83 ±0.66
Patch SCL 79.68 ±2.87 94.71 ±1.05
10SCL-RS 87.42±2.07 96.40 ±0.94
Patch SCL 79.80 ±2.57 94.90 ±1.09
higher imbalance ratios. To further stress test these meth-
ods, we also deployed these models on independent OOD
test datasets described above and the results are shown in
Table 4 and 6. We found that baseline model performance
dropped notably across imbalance ratios, highlighting thedifficulty in generalization, and the tendency of these mod-
els to overfit in an imbalanced setting. Performance im-
provements using SC-MIL persist in this OOD setting. In
Figure 4 we show the performance of different techniques
across all classes in RCC in both ID and OOD setting,
demonstrating the relative performance gain in each class.
3.3.2 Patch vs bag based SC-MIL
We conduct an experiment with a modification of SC-MIL
architecture, where the supervised contrastive loss is ap-
plied on patch level embeddings instead of bag level embed-
dings. In Section 2.2, we theorized that naively assigning
the bag level label to instances and then applying supervised
contrastive loss will result in incorrect label assignment. We
show the results of training with such a scheme in Table
7. Patch level SC-MIL has inferior performance and higher
variance as compared to our formulation. We also observe
7

--- PAGE 8 ---
Table 8. Impact of temperature ( τ) on single-stage training SC-
MIL-RS on TCGA-RCC subtyping.
Imb. Ratio Temp F1 AUC
1 0.1 86.24 ±2.35 97.85 ±0.60
0.5 87.88 ±2.37 97.87 ±0.72
1.0 88.67±2.21 98.13 ±0.67
5 0.1 86.14 ±2.61 97.04 ±0.96
0.5 88.35±2.34 97.49 ±0.68
1.0 86.30 ±2.03 96.83 ±0.66
10 0.1 85.60 ±2.37 96.09 ±0.97
0.5 84.85 ±2.30 96.06 ±0.78
1.0 87.42±2.07 96.40 ±0.94
that the performance gap between the two models increases
with increasing imbalance ratio, providing evidence that our
bag-level formulation is more robust to the compounding
effect of label imbalance in pathology.
3.3.3 Impact of sampling
We found that SC-MIL with random sampling performs
better than class balanced sampling in most cases. We hy-
pothesize that this is due to reduced diversity in the feature
space as a side effect of oversampling the minority classes
or under sampling the majority class when using class-
balanced sampling, which ultimately hurts performance by
interfering with feature learning [30].
3.3.4 Impact of temperature
We experimented with temperature values of τ∈
{0.1,0.5,1}and found that the models are generally robust
to temperature changes as shown in Table 8. We reason
about this through two desirable properties of representa-
tions learned through contrastive learning: uniformity in the
hypersphere, i.e, inter-class separation and tolerance to po-
tential positives, i.e., intra-class similarity [29]. The former
is favored by low values of temperature while higher val-
ues favor the latter. As shown in [29], in problems with a
larger number of classes, uniformity is harder to achieve and
higher values of temperature harm feature quality. In con-
trast, we see that for RCC and NSCLC subtyping with 3 and
2 classes respectively, model performance is less sensitive
to changes in temperature.
3.3.5 Two-stage vs single-stage training
We conducted an ablation by training models in a two-stage
manner, with SCL loss in the first stage for feature learning
followed by cross-entropy (CE) loss in the second stage.
We see that single-stage SC-MIL model (joint SCL and CETable 9. Comparison of one-stage vs two-stage training on TCGA-
RCC subtyping. All comparisons used SC-MIL-RS training and
τ= 1
Ratio Stage F1 AUC
1 1 88.67±2.21 98.13 ±0.67
2 87.54 ±2.10 97.66 ±0.60
5 1 86.30±2.03 96.83±0.66
2 86.06 ±2.47 97.34±0.77
10 1 87.42±2.07 96.40 ±0.94
2 85.26 ±2.56 96.01 ±0.91
training) performs better overall as shown in Table 9. This
could be due to incompatible feature learning between SCL
and CE stages in two-stage training. Using a smooth cur-
riculum allows a gradual transition from feature learning to
classifier learning, leading to superior performance.
4. Conclusion
Label imbalance in pathology is a challenging problem
owing to the highly skewed distribution of classes both at
dataset and WSI level. We propose SC-MIL, a novel in-
tegration of supervised contrastive learning into the MIL
framework to tackle this label imbalance problem. Ex-
periments show our bag-level formulation to be superior
to patch-level SC-MIL and other baselines across multi-
ple degrees of label imbalance. Moreover, these improve-
ments persist in out-of-distribution pathology datasets. We
hope that this improved generalization performance in im-
balanced settings drives adoption of ML in real-world clin-
ical applications.
8

--- PAGE 9 ---
References
[1] Jaime Bosch, Chuhan Chung, Oscar M Carrasco-Zevallos,
Stephen A Harrison, Manal F Abdelmalek, Mitchell L Shiff-
man, Don C Rockey, Zahil Shanis, Dinkar Juyal, Harsha
Pokkalla, et al. A machine learning approach to liver his-
tological evaluation predicts clinically significant portal hy-
pertension in nash cirrhosis. Hepatology , 74(6):3146–3160,
2021. 1
[2] Wouter Bulten, Maschenka Balkenhol, Jean-Jo ¨el Awoumou
Belinga, Am ´erico Brilhante, Aslı C ¸ akır, Lars Egevad, Mar-
tin Eklund, Xavier Farr ´e, Katerina Geronatsiou, Vincent
Molini ´e, et al. Artificial intelligence assistance significantly
improves gleason grading of prostate biopsies by patholo-
gists. Modern Pathology , 34(3):660–671, 2021. 1
[3] Gabriele Campanella, Matthew G Hanna, Luke Geneslaw,
Allen Miraflor, Vitor Werneck Krauss Silva, Klaus J Busam,
Edi Brogi, Victor E Reuter, David S Klimstra, and Thomas J
Fuchs. Clinical-grade computational pathology using weakly
supervised deep learning on whole slide images. Nature
medicine , 25(8):1301–1309, 2019. 1
[4] Kaidi Cao, Colin Wei, Adrien Gaidon, Nikos Arechiga,
and Tengyu Ma. Learning imbalanced datasets with label-
distribution-aware margin loss. In Advances in Neural Infor-
mation Processing Systems , 2019. 2, 5, 6
[5] Richard J. Chen, Chengkuan Chen, Yicong Li, Tiffany Y .
Chen, Andrew D. Trister, Rahul G. Krishnan, and Faisal
Mahmood. Scaling vision transformers to gigapixel images
via hierarchical self-supervised learning. In Proceedings of
the IEEE/CVF Conference on Computer Vision and Pattern
Recognition (CVPR) , pages 16144–16155, June 2022. 1
[6] Hsin-Ping Chou, Shih-Chieh Chang, Jia-Yu Pan, Wei Wei,
and Da-Cheng Juan. Remix: Rebalanced mixup. In Com-
puter Vision – ECCV 2020 Workshops: Glasgow, UK, August
23–28, 2020, Proceedings, Part VI , page 95–110, Berlin,
Heidelberg, 2020. Springer-Verlag. 2
[7] Ozan Ciga, Anne L. Martel, and Tony Xu. Self super-
vised contrastive learning for digital histopathology. ArXiv ,
abs/2011.13971, 2020. 2
[8] James A Diao, Jason K Wang, Wan Fung Chui, Victo-
ria Mountain, Sai Chowdary Gullapally, Ramprakash Srini-
vasan, Richard N Mitchell, Benjamin Glass, Sara Hoffman,
Sudha K Rao, et al. Human-interpretable image features
derived from densely mapped cancer pathology slides pre-
dict diverse molecular phenotypes. Nature communications ,
12(1):1–15, 2021. 1
[9] Babak Ehteshami Bejnordi, Mitko Veta, Paul Johannes van
Diest, Bram van Ginneken, Nico Karssemeijer, Geert Lit-
jens, Jeroen A. W. M. van der Laak, , and the CAME-
LYON16 Consortium. Diagnostic Assessment of Deep
Learning Algorithms for Detection of Lymph Node Metas-
tases in Women With Breast Cancer. JAMA , 318(22):2199–
2210, 12 2017. 1
[10] Florian Graf, Christoph Hofer, Marc Niethammer, and
Roland Kwitt. Dissecting supervised contrastive learning.
2021. 2
[11] Maximilian Ilse, Jakub Tomczak, and Max Welling.
Attention-based deep multiple instance learning. In Inter-national conference on machine learning , pages 2127–2136.
PMLR, 2018. 3
[12] Syed Ashar Javed, Dinkar Juyal, Harshith Padigela, Amaro
Taylor-Weiner, Limin Yu, and aaditya prakash. Additive
MIL: Intrinsically interpretable multiple instance learning
for pathology. In Alice H. Oh, Alekh Agarwal, Danielle
Belgrave, and Kyunghyun Cho, editors, Advances in Neural
Information Processing Systems , 2022. 3
[13] Syed Ashar Javed, Dinkar Juyal, Zahil Shanis, Shreya
Chakraborty, Harsha Pokkalla, and Aaditya Prakash. Re-
thinking machine learning model evaluation in pathology.
arXiv preprint arXiv:2204.05205 , 2022. 1
[14] Bingyi Kang, Yu Li, Sa Xie, Zehuan Yuan, and Jiashi Feng.
Exploring balanced feature spaces for representation learn-
ing. In International Conference on Learning Representa-
tions , 2021. 2
[15] Bingyi Kang, Saining Xie, Marcus Rohrbach, Zhicheng Yan,
Albert Gordo, Jiashi Feng, and Yannis Kalantidis. Decou-
pling representation and classifier for long-tailed recogni-
tion. In International Conference on Learning Representa-
tions , 2020. 4
[16] Prannay Khosla, Piotr Teterwak, Chen Wang, Aaron Sarna,
Yonglong Tian, Phillip Isola, Aaron Maschinot, Ce Liu, and
Dilip Krishnan. Supervised contrastive learning. In H.
Larochelle, M. Ranzato, R. Hadsell, M.F. Balcan, and H. Lin,
editors, Advances in Neural Information Processing Systems ,
volume 33, pages 18661–18673. Curran Associates, Inc.,
2020. 2, 4
[17] Bin Li, Yin Li, and Kevin W Eliceiri. Dual-stream multiple
instance learning network for whole slide image classifica-
tion with self-supervised contrastive learning. In Proceed-
ings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition , pages 14318–14328, 2021. 3
[18] Jin Li, Deepta Rajan, Chintan Shah, Dinkar Juyal, Shreya
Chakraborty, Chandan Akiti, Filip Kos, Janani Iyer, Anand
Sampat, and Ali Behrooz. Self-training of machine learning
models for liver histopathology: Generalization under clini-
cal shifts, 2022. 1
[19] Ming Y Lu, Drew FK Williamson, Tiffany Y Chen, Richard J
Chen, Matteo Barbieri, and Faisal Mahmood. Data-efficient
and weakly supervised computational pathology on whole-
slide images. Nature biomedical engineering , 5(6):555–570,
2021. 3
[20] Anant Madabhushi and George Lee. Image analysis and ma-
chine learning in digital pathology: Challenges and oppor-
tunities. Medical Image Analysis , 33:170–175, 2016. 20th
anniversary of the Medical Image Analysis journal (MedIA).
1
[21] Oded Maron and Tom ´as Lozano-P ´erez. A framework for
multiple-instance learning. Advances in neural information
processing systems , 10, 1997. 1
[22] Carlos Mera, Jose Arrieta, Mauricio Orozco-Alzate, and
John Branch. A bag oversampling approach for class im-
balance in multiple instance learning. In Alvaro Pardo and
Josef Kittler, editors, Progress in Pattern Recognition, Image
Analysis, Computer Vision, and Applications , pages 724–
731, Cham, 2015. Springer International Publishing. 2
9

--- PAGE 10 ---
[23] Ajinkya More. Survey of resampling techniques for improv-
ing classification performance in unbalanced datasets. CoRR ,
abs/1608.06048, 2016. 2
[24] Muhammad Khalid Khan Niazi, Anil V Parwani, and
Metin N Gurcan. Digital pathology and artificial intelli-
gence. The lancet oncology , 20(5):e253–e261, 2019. 1
[25] Mengye Ren, Wenyuan Zeng, Bin Yang, and Raquel Urta-
sun. Learning to reweight examples for robust deep learning.
In Jennifer Dy and Andreas Krause, editors, Proceedings
of the 35th International Conference on Machine Learning ,
volume 80 of Proceedings of Machine Learning Research ,
pages 4334–4343. PMLR, 10–15 Jul 2018. 2
[26] Zhuchen Shao, Hao Bian, Yang Chen, Yifeng Wang, Jian
Zhang, Xiangyang Ji, et al. Transmil: Transformer based
correlated multiple instance learning for whole slide image
classification. Advances in Neural Information Processing
Systems , 34, 2021. 3
[27] Eric E Walk. The role of pathologists in the era of personal-
ized medicine. Archives of pathology & laboratory medicine ,
133(4):605–610, 2009. 1
[28] Dayong Wang, Aditya Khosla, Rishab Gargeya, Humayun
Irshad, and Andrew H Beck. Deep learning for identifying
metastatic breast cancer. arXiv preprint arXiv:1606.05718 ,
2016. 1
[29] Feng Wang and Huaping Liu. Understanding the behaviour
of contrastive loss. In 2021 IEEE/CVF Conference on Com-
puter Vision and Pattern Recognition (CVPR) , pages 2495–
2504, 2021. 8
[30] Peng Wang, K. Han, Xiu-Shen Wei, Lei Zhang, and Lei
Wang. Contrastive learning based hybrid networks for long-
tailed image classification. 2021 IEEE/CVF Conference on
Computer Vision and Pattern Recognition (CVPR) , pages
943–952, 2021. 2, 5, 8
[31] John N Weinstein, Eric A Collisson, Gordon B Mills,
Kenna R Shaw, Brad A Ozenberger, Kyle Ellrott, Ilya
Shmulevich, Chris Sander, and Joshua M Stuart. The cancer
genome atlas pan-cancer analysis project. Nature genetics ,
45(10):1113–1120, 2013. 5
[32] Xiangyu Zhang, Xinyu Zhou, Mengxiao Lin, and Jian Sun.
Shufflenet: An extremely efficient convolutional neural net-
work for mobile devices. In Proceedings of the IEEE Confer-
ence on Computer Vision and Pattern Recognition (CVPR) ,
June 2018. 6
[33] B. Zhou, Q. Cui, X. Wei, and Z. Chen. Bbn: Bilateral-
branch network with cumulative learning for long-tailed vi-
sual recognition. In 2020 IEEE/CVF Conference on Com-
puter Vision and Pattern Recognition (CVPR) , pages 9716–
9725, Los Alamitos, CA, USA, jun 2020. IEEE Computer
Society. 2
10

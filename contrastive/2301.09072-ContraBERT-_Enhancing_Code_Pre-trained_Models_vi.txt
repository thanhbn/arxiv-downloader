# 2301.09072.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/contrastive/2301.09072.pdf
# Kích thước tệp: 674977 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
ContraBERT: Tăng cường các Mô hình Tiền huấn luyện Mã nguồn
thông qua Học tương phản
Shangqing Liu1, Bozhi Wu1, Xiaofei Xie2y, Guozhu Meng3, và Yang Liu1
1Đại học Công nghệ Nanyang, Singapore
2Đại học Quản lý Singapore, Singapore
3SKLOIS, Viện Kỹ thuật Thông tin, Viện Hàn lâm Khoa học Trung Quốc, Trung Quốc
fshangqin001,bozhi001 g@e.ntu.edu.sg, xiaofei.xfxie@gmail.com, mengguozhu@iie.ac.cn, yangliu@ntu.edu.sg
Tóm tắt —Các mô hình tiền huấn luyện quy mô lớn như CodeBERT,
GraphCodeBERT đã thu hút sự chú ý rộng rãi từ cả học thuật và
công nghiệp. Được cho là có khả năng vượt trội trong biểu diễn mã nguồn,
chúng đã được áp dụng thêm trong nhiều tác vụ phụ thuộc như phát hiện
bản sao, tìm kiếm mã nguồn và dịch thuật mã nguồn. Tuy nhiên, cũng
quan sát thấy rằng các mô hình tiền huấn luyện tiên tiến này dễ bị tấn
công đối kháng. Hiệu suất của các mô hình tiền huấn luyện này giảm
đáng kể với các nhiễu loạn đơn giản như đổi tên biến. Điểm yếu này có
thể được kế thừa bởi các mô hình phụ thuộc của chúng và do đó được
khuếch đại ở quy mô chưa từng có. Để giải quyết vấn đề này, chúng tôi
đề xuất một phương pháp gọi là ContraBERT nhằm cải thiện tính bền
vững của các mô hình tiền huấn luyện thông qua học tương phản. Cụ thể,
chúng tôi thiết kế chín loại toán tử tăng cường dữ liệu đơn giản và phức
tạp trên dữ liệu ngôn ngữ lập trình (PL) và ngôn ngữ tự nhiên (NL) để
xây dựng các biến thể khác nhau. Hơn nữa, chúng tôi tiếp tục huấn luyện
các mô hình tiền huấn luyện hiện có bằng mô hình hóa ngôn ngữ có mặt
nạ (MLM) và tác vụ tiền huấn luyện tương phản trên các mẫu gốc với
các biến thể tăng cường của chúng để tăng cường tính bền vững của mô
hình. Các thí nghiệm mở rộng chứng minh rằng ContraBERT có thể cải
thiện hiệu quả tính bền vững của các mô hình tiền huấn luyện hiện có.
Nghiên cứu thêm cũng xác nhận rằng các mô hình được tăng cường tính
bền vững này cung cấp cải thiện so với các mô hình gốc trên bốn tác vụ
phụ thuộc phổ biến.
Từ khóa chỉ mục —Mô hình Tiền huấn luyện Mã nguồn, Học Tương phản,
Tính Bền vững Mô hình

I. GIỚI THIỆU
Đã được xác nhận rằng kỷ nguyên "big code" [1] đang
đến do sự phổ biến của phần mềm trong xã hội hiện đại và
chu kỳ phát triển phần mềm được tăng tốc (thiết kế, triển khai
và bảo trì). Theo báo cáo chính thức của GitHub [2] năm 2018,
GitHub đã đạt 100 triệu kho lưu trữ được lưu trữ. Evans Data
Corporation [3] cũng ước tính có 23,9 triệu nhà phát triển
chuyên nghiệp vào năm 2019 và con số đó dự kiến đạt 28,7
triệu vào năm 2024. Kết quả là, tính khả dụng của dữ liệu
liên quan đến mã nguồn là rất lớn (ví dụ: hàng tỷ mã nguồn,
hàng triệu mã nguồn thay đổi, sửa lỗi và tài liệu mã nguồn),
điều này tạo ra một chủ đề nóng trong cả học thuật và công
nghiệp. Đó là cách áp dụng phương pháp dựa trên dữ liệu
(ví dụ: học sâu) để giải quyết các vấn đề kỹ thuật phần mềm
(SE) thông thường.

Học sâu đã được áp dụng rộng rãi cho các tác vụ SE đa dạng
(AI4SE) như phát hiện lỗ hổng phần mềm [4], [5], [6], tóm tắt
mã nguồn [7], [8], [9], tìm kiếm mã nguồn sâu [10], [11] và
hoàn thiện mã nguồn [12], [13], [14]. Bên cạnh đó, các công
trình sớm [15], [16], [17], [18], [19] trực tiếp sử dụng các kỹ
thuật học sâu thông thường như Mạng Bộ nhớ Dài-Ngắn hạn
(LSTM) [20] và Mạng Nơ-ron Tích chập (CNN) [21] cho các
tác vụ khác nhau. Các công trình sau đó [5], [7], [10], [22],
[23], [24], [4], [8] tùy chỉnh các kiến trúc mạng khác nhau để
thỏa mãn các đặc tính của tác vụ cụ thể nhằm đạt được hiệu
suất tốt nhất. Ví dụ, vì các phụ thuộc dữ liệu phức tạp và phụ
thuộc điều khiển dễ kích hoạt lỗ hổng phần mềm hơn, Devign
[5] đã kết hợp các loại thông tin cấu trúc chương trình khác
nhau với Biểu đồ Thuộc tính Mã nguồn [25] vào Mạng Nơ-ron
Biểu đồ [26] để phát hiện lỗ hổng. Xem xét việc trùng lặp mã
nguồn [27] phổ biến trong kỷ nguyên "big code", Liu et al. [7]
đã kết hợp cặp mã nguồn-tóm tắt được truy xuất để tạo ra
các tóm tắt chất lượng cao. Mặc dù các mạng tùy chỉnh này
đã đạt được cải thiện đáng kể trên các tác vụ cụ thể, hiệu suất
tổng quát hóa vẫn thấp. Để giải quyết hạn chế này, một số
nhà nghiên cứu đề xuất sử dụng các kỹ thuật không giám sát
với lượng dữ liệu lớn để tiền huấn luyện một mô hình tổng
quát [28], [29], [30], [3], [31], [32], [33], [34], [35] và sau đó
tinh chỉnh nó cho các tác vụ phụ thuộc khác nhau. Ví dụ, CuBERT
[36] tiền huấn luyện BERT [37] trên một kho dữ liệu Python
được thu thập lớn (7,4M tệp) và sau đó tinh chỉnh nó trên các
tác vụ khác nhau như nhận dạng sử dụng sai biến và nhận dạng
toán tử nhị phân sai. CodeBERT [29] tiền huấn luyện RoBERTa
[38] cho các ngôn ngữ lập trình (PL) với các bình luận ngôn
ngữ tự nhiên (NL) của chúng trên sáu ngôn ngữ lập trình mã
nguồn mở [16] và đánh giá nó trên tìm kiếm mã nguồn và tóm
tắt mã nguồn. GraphCodeBERT [30] tiếp tục kết hợp thông tin
luồng dữ liệu để mã hóa mối quan hệ của các biến trong một
chương trình cho tiền huấn luyện và chứng minh hiệu quả của
nó trên bốn tác vụ phụ thuộc.

Các mô hình tiền huấn luyện nói trên có tác động sâu sắc
đến cộng đồng AI4SE và đã đạt được kết quả hứa hẹn trên
các tác vụ khác nhau. Với việc sử dụng rộng rãi các mô hình
tiền huấn luyện, một câu hỏi quan trọng là liệu các mô hình
này có bền vững để biểu diễn ngữ nghĩa mã nguồn hay không.
Nghiên cứu sơ bộ của chúng tôi đã chứng minh rằng các mô
hình tiền huấn luyện tiên tiến không bền vững với một đột
biến chương trình bảo toàn nhãn đơn giản như đổi tên biến.
Cụ thể, chúng tôi sử dụng dữ liệu thử nghiệm của phát hiện
bản sao (POJ-104) [39] (một tác vụ để phát hiện xem hai hàm
có tương đương ngữ nghĩa với các triển khai khác nhau hay
không) được cung cấp bởi CodeXGLUE [3] và chọn những
mẫu được dự đoán chính xác bởi CodeBERT [29] và GraphCodeBERT
[38] tiền huấn luyện. Sau đó chúng tôi ngẫu nhiên đổi tên các
biến trong các chương trình này từ 1 đến 8 chỉnh sửa. Ví dụ,
8 chỉnh sửa có nghĩa là chúng tôi ngẫu nhiên chọn 8 biến khác
nhau trong một hàm và đổi tên chúng cho tất cả các lần xuất
hiện với các tên mới được tạo. Nếu một hàm có ít hơn 8 biến,
chúng tôi sẽ đổi tên số lượng biến tối đa. Sau đó chúng tôi
sử dụng các biến thể đột biến mới được tạo này để đánh giá
độ chính xác dự đoán mô hình dựa trên độ tương tự cosine
của các vector nhúng của các chương trình này. Đáng ngạc
nhiên, chúng tôi thấy rằng cả CodeBERT và GraphCodeBERT
đều gặp khó khăn lớn từ hoạt động đổi tên và độ chính xác
giảm xuống khoảng 0,4 khi số lần chỉnh sửa đổi tên đạt tới
8 (xem Hình 1). Điều này xác nhận rằng các mô hình tiền huấn
luyện không bền vững với các ví dụ đối kháng.

Tuy nhiên, việc cải thiện tính bền vững của các mô hình
tiền huấn luyện là thách thức. Mặc dù công trình mới nhất
của Yang et al. [40] đã đề xuất một số chiến lược tấn công
để làm cho CodeBERT và GraphCodeBERT có hiệu suất kém
trên các mẫu đối kháng. Họ tiếp tục kết hợp các mẫu đối kháng
với các mẫu gốc để tinh chỉnh các mô hình tiền huấn luyện
mà không có bất kỳ thay đổi nào đối với kiến trúc mô hình
để cải thiện tính bền vững dự đoán trên các tác vụ phụ thuộc.
Tuy nhiên, một mô hình được thiết kế mới vốn dĩ giải quyết
điểm yếu về tính bền vững không được đề cập trong bài báo
của họ.

Trong bài báo này, chúng tôi đề xuất ContraBERT, một
khung học tương phản không giám sát để tăng cường tính
bền vững của các mô hình tiền huấn luyện hiện có trong các
tình huống mã nguồn. So với Yang et al. [40], chúng tôi thiết
kế một mô hình tiền huấn luyện mới lấy mô hình hóa ngôn
ngữ có mặt nạ (MLM) và tác vụ tiền huấn luyện tương phản
làm các tác vụ tiền huấn luyện để cải thiện tính bền vững mô
hình. Để thiết kế một tác vụ tiền huấn luyện tương phản giúp
mô hình nhóm các mẫu tương tự trong khi đẩy xa các mẫu
không tương tự, chúng tôi định nghĩa chín loại toán tử tăng
cường dữ liệu đơn giản hoặc phức tạp biến đổi chương trình
gốc và chuỗi ngôn ngữ tự nhiên thành các biến thể khác nhau.
Cho một mô hình tiền huấn luyện hiện có như CodeBERT hoặc
GraphCodeBERT, chúng tôi lấy mẫu gốc cũng như các biến
thể tăng cường của nó làm đầu vào để huấn luyện mô hình
với MLM và tác vụ tiền huấn luyện tương phản, trong đó MLM
được sử dụng để giúp mô hình học các biểu diễn token tốt
hơn và tác vụ tiền huấn luyện tương phản được sử dụng để
giúp mô hình nhóm các biểu diễn vector tương tự để tăng cường
tính bền vững mô hình. Như được hiển thị trong Hình 1, ContraBERT
C và ContraBERT G biểu thị các mô hình được tiền huấn luyện
từ CodeBERT và GraphCodeBERT với phương pháp của chúng
tôi tương ứng, chúng tôi quan sát thấy rằng với số lượng chỉnh
sửa tăng lên, mặc dù hiệu suất tiếp tục giảm, đường cong cho
ContraBERT mượt mà hơn nhiều. Độ chính xác dự đoán của
ContraBERT C và ContraBERT G vượt trội hơn CodeBERT và
GraphCodeBERT một cách đáng kể, cho thấy rằng ContraBERT
C và ContraBERT G bền vững hơn các mô hình gốc. Chúng
tôi tiếp tục thực hiện một nghiên cứu phân tích để xác nhận
mỗi loại toán tử tăng cường PL-NL được định nghĩa có hiệu
quả trong việc cải thiện tính bền vững mô hình. Cuối cùng,
chúng tôi tiến hành nghiên cứu rộng rãi trên bốn tác vụ phụ
thuộc (tức là phát hiện bản sao, phát hiện lỗi, dịch mã nguồn
sang mã nguồn và tìm kiếm mã nguồn) để minh họa rằng các
mô hình được tăng cường tính bền vững này cung cấp cải thiện
đáng kể so với các mô hình gốc. Tóm lại, các đóng góp chính
của chúng tôi như sau:

Chúng tôi trình bày một khung ContraBERT để tăng cường
tính bền vững của các mô hình tiền huấn luyện hiện có trong
tình huống mã nguồn bằng các tác vụ tiền huấn luyện của
mô hình hóa ngôn ngữ có mặt nạ và học tương phản trên các
mẫu gốc cũng như các biến thể tăng cường.

Chúng tôi thiết kế chín loại toán tử tăng cường dữ liệu đơn
giản hoặc phức tạp trên ngôn ngữ lập trình (PL) và chuỗi
ngôn ngữ tự nhiên (NL). Mỗi toán tử xác nhận hiệu quả của
nó trong việc cải thiện tính bền vững của mô hình.

Nghiên cứu rộng rãi trên bốn tác vụ phụ thuộc chứng minh
rằng các mô hình được tăng cường tính bền vững cung cấp
cải thiện so với các mô hình gốc. Mã nguồn và mô hình của
chúng tôi được phát hành trên [41] để tái tạo.

Tổ chức: Phần còn lại của bài báo này được tổ chức như
sau: Mục II mô tả nền tảng của các mô hình gốc mà ContraBERT
sẽ sử dụng. Chúng tôi trình bày chi tiết phương pháp của
chúng tôi trong Mục III. Mục IV và Mục V trình bày thiết
lập thí nghiệm và kết quả thí nghiệm. Trong Mục VI, chúng
tôi đưa ra một số thảo luận về công trình của chúng tôi. Sau
một đánh giá ngắn gọn về các công trình liên quan trong Mục
VII, chúng tôi kết luận bài báo này trong Mục VIII.

II. NỀN TẢNG
Trong mục này, chúng tôi giới thiệu ngắn gọn CodeBERT
và GraphCodeBERT sẽ được áp dụng làm các mô hình tiền
huấn luyện gốc cho ContraBERT.

A. CodeBERT
CodeBERT [29] được tiền huấn luyện trên một điểm chuẩn
mã nguồn mở CodeSearchNet [16], bao gồm 2,1M cặp NL-PL
đa phương thức (bình luận-hàm) và 6,4M hàm đơn phương
thức không có bình luận trên sáu ngôn ngữ lập trình. Kiến
trúc mô hình giống với RoBERTa [38], sử dụng Transformer
[42] hai chiều đa lớp cho học không giám sát. Cụ thể, CodeBERT
bao gồm 12 lớp giống hệt nhau, 12 đầu và kích thước chiều
cho mỗi lớp là 768. Tổng cộng, số lượng tham số mô hình
đạt 125M. Hai mục tiêu tiền huấn luyện khác nhau được sử
dụng, cái đầu tiên là mô hình hóa ngôn ngữ có mặt nạ (MLM),
được huấn luyện trên dữ liệu đa phương thức. Mục tiêu MLM
nhắm đến dự đoán các token gốc bị che mặt trong các cặp
NL-PL. Để tận dụng đầy đủ dữ liệu đơn phương thức, CodeBERT
tiếp tục sử dụng mục tiêu Phát hiện Token Thay thế (RTD)
trên cả các mẫu đa phương thức và đơn phương thức. Mục
tiêu RTD được thiết kế để xác định xem một từ có phải là
gốc hay không. Ở giai đoạn tinh chỉnh, hai tác vụ phụ thuộc
(tức là tìm kiếm mã nguồn và tạo tài liệu mã nguồn) được
sử dụng để đánh giá. Kết quả thí nghiệm chứng minh rằng
CodeBERT vượt trội hơn các phương pháp có giám sát trên
cả hai tác vụ.

B. GraphCodeBERT
GraphCodeBERT [30] là một mô hình tiền huấn luyện cho
mã nguồn, xem xét cấu trúc trong mã nguồn. Cụ thể, nó kết
hợp luồng dữ liệu của mã nguồn để mã hóa các mối quan hệ
"giá trị đến từ đâu" giữa các biến trong giai đoạn tiền huấn
luyện. Ngoài tác vụ tiền huấn luyện của mô hình hóa ngôn
ngữ có mặt nạ (MLM), GraphCodeBERT tiếp tục giới thiệu
hai tác vụ tiền huấn luyện nhận biết cấu trúc mới. Cái đầu
tiên dự đoán cạnh được thiết kế để dự đoán xem hai nút trong
luồng dữ liệu có được kết nối hay không. Cái khác là căn
chỉnh nút được thiết kế để căn chỉnh các cạnh giữa token
mã nguồn và các nút. GraphCodeBERT sử dụng các cặp NL-PL
cho sáu ngôn ngữ lập trình từ CodeSearchNet [16] để tiền
huấn luyện. Nó được tinh chỉnh trên bốn tác vụ phụ thuộc
bao gồm tìm kiếm mã nguồn, phát hiện bản sao, dịch mã
nguồn và tinh chỉnh mã nguồn. Các thí nghiệm mở rộng trên
các tác vụ này xác nhận rằng cấu trúc mã nguồn và các tác
vụ tiền huấn luyện được định nghĩa giúp mô hình đạt được
hiệu suất tiên tiến trên các tác vụ này.

III. PHƯƠNG PHÁP
Trong mục này, chúng tôi trước tiên trình bày tổng quan
về phương pháp của chúng tôi, sau đó chi tiết từng thành phần
bao gồm tăng cường PL-NL, thiết kế mô hình trong tiền huấn
luyện và các cài đặt tinh chỉnh cho các tác vụ phụ thuộc.

A. Tổng quan
Tổng quan về ContraBERT được hiển thị trong Hình 2.
Cụ thể, cho một cặp hàm C với bình luận W của nó (tức là
(C;W)), chúng tôi trước tiên thiết kế một tập hợp các toán
tử tăng cường PL-NL {fi(.)} và {gj(.)} để xây dựng các biến
thể đơn giản hoặc phức tạp cho C và W tương ứng. Trong
giai đoạn tiền huấn luyện, được khởi tạo từ các mô hình tiền
huấn luyện hiện có như CodeBERT hoặc GraphCodeBERT,
chúng tôi tiếp tục tiền huấn luyện các mô hình này trên các
mẫu gốc và các biến thể tăng cường của chúng với mô hình
hóa ngôn ngữ có mặt nạ (MLM) và tác vụ tiền huấn luyện
tương phản để tăng cường tính bền vững mô hình. Cuối cùng,
khi ContraBERT được tiền huấn luyện trên một lượng lớn
dữ liệu không nhãn, chúng tôi tinh chỉnh nó cho các loại tác
vụ khác nhau như tác vụ truy xuất, tác vụ phân loại và tác
vụ tạo với dữ liệu cụ thể cho tác vụ một cách có giám sát.

B. Tăng cường PL-NL
Cho một chương trình C, phát hiện bản sao [43] có thể
giúp xác định một chương trình tương đương ngữ nghĩa C'.
Tuy nhiên, kỹ thuật này không thực tế trong thực tiễn. Đối
với bất kỳ hàm nào trong một tập dữ liệu cố định, chúng ta
không thể đảm bảo rằng chúng ta sẽ có thể tìm thấy các biến
thể tương đương ngữ nghĩa. Hơn nữa, phát hiện bản sao thường
lấy một dự án để phân tích, điều này không áp dụng được
cho một hàm đơn lẻ. Do đó, chúng tôi xem xét việc xây dựng
các biến thể tăng cường dựa trên các mẫu gốc. So với các
công trình hiện có [44], [45] chỉ tập trung vào các đột biến
chương trình, chúng tôi thiết kế một tập hợp các toán tử tăng
cường chuỗi ngôn ngữ tự nhiên (NL). Cụ thể, chúng tôi thiết
kế một loạt các toán tử đơn giản và toán tử phức tạp cho cả
PL và NL để xây dựng các biến thể.

1) Toán tử Tăng cường Chương trình (PL): Đối với các
toán tử tăng cường chương trình, chúng tôi thiết kế bốn loại
toán tử phức tạp và một loại toán tử đơn giản.

Toán tử Phức tạp:
Đổi tên Tên Hàm (RFN). Nó được thiết kế để thay thế tên
hàm bằng một tên mới được lấy ngẫu nhiên từ một tập từ
vựng bổ sung được xây dựng trên tập dữ liệu tiền huấn luyện.
Chúng tôi trích xuất tất cả tên hàm trong tập dữ liệu tiền
huấn luyện để xây dựng. Vì mỗi mẫu trong tập dữ liệu là
một hàm đơn lẻ, hàm được đổi tên bảo toàn ngữ nghĩa tương
đương với hàm gốc.

Đổi tên Biến (RV). Nó đổi tên các biến trong một hàm.
Một số lượng ngẫu nhiên các biến cho tất cả các lần xuất
hiện trong hàm sẽ được thay thế bằng các tên mới được lấy
ngẫu nhiên từ một tập từ vựng bổ sung. Chúng tôi trích xuất
tất cả tên biến từ tập dữ liệu tiền huấn luyện để xây dựng
tập từ vựng này. Toán tử này chỉ đột biến tên biến và tất
cả các lần xuất hiện của chúng với tên biến mới, không thay
đổi ngữ nghĩa của hàm gốc.

Chèn Mã nguồn Chết (IDC). Nó có nghĩa là chèn các câu
lệnh không sử dụng trong một hàm. Để tạo ra các câu lệnh
mã nguồn không sử dụng, chúng tôi duyệt AST để xác định
các câu lệnh gán và sau đó ngẫu nhiên chọn một câu lệnh
gán để đổi tên các biến của nó với các tên mới chưa bao
giờ xuất hiện trong cùng một hàm. Sau đó, chúng tôi xem
xét nó như mã nguồn chết và chèn nó ở vị trí sau câu lệnh
gán gốc. Vì mã nguồn chết được chèn không thay đổi hành
vi chương trình gốc, IDC được coi là toán tử tương đương
ngữ nghĩa.

Sắp xếp lại (RO). Nó ngẫu nhiên hoán đổi hai dòng câu
lệnh không phụ thuộc lẫn nhau trong một khối cơ bản trong
thân hàm như hai câu lệnh khai báo xuất hiện trên hai dòng
liên tiếp mà không có câu lệnh khác giữa chúng. Chúng tôi
duyệt AST và phân tích phụ thuộc dữ liệu để trích xuất. Vì
các câu lệnh được hoán vị là độc lập không có phụ thuộc
dữ liệu, toán tử này bảo toàn ngữ nghĩa chương trình gốc.

Toán tử Đơn giản:
Lấy mẫu (SP). Nó ngẫu nhiên xóa một câu lệnh dòng từ
thân hàm và bảo toàn các câu lệnh khác. Nó có thể đóng
vai trò như các bộ điều chỉnh để tránh quá khớp [45].

2) Toán tử Tăng cường Bình luận (NL): Ngoài việc tăng
cường chương trình, chúng tôi tiếp tục thiết kế một loại toán
tử phức tạp và ba loại toán tử đơn giản cho các toán tử tăng
cường bình luận như sau:

Toán tử Phức tạp:
Đột biến Dịch thuật Ngược (Trans). Nó đề cập đến việc
dịch một chuỗi nguồn sang một ngôn ngữ khác (chuỗi đích)
và sau đó chuyển đổi chuỗi đích này thành chuỗi gốc [46].
Chúng tôi sử dụng công cụ được phát hành [47] để triển khai
trong đó nguồn là tiếng Anh và đích là tiếng Đức.

Toán tử Đơn giản:
Xóa. Nó ngẫu nhiên xóa một từ trong bình luận.
Hoán đổi. Nó ngẫu nhiên hoán đổi vị trí của hai từ trong
bình luận.
Sao chép. Nó ngẫu nhiên sao chép một từ và chèn nó sau
từ này trong bình luận.

Cho một hàm C với bình luận ghép đôi W, chúng tôi sử
dụng các toán tử tăng cường trên trên C và W tương ứng để
có được các tập tăng cường, được định nghĩa là SC và SW
tương ứng. Cụ thể, mỗi toán tử được thực hiện một lần để
có được biến thể tăng cường tương ứng và chèn nó vào tập
tăng cường tương ứng. Đối với toán tử IDC, có thể không
có được biến thể của nó cho một số hàm cụ thể, chúng tôi
bỏ qua nó và sử dụng các toán tử khác để xây dựng. Sau
đó chúng tôi ngẫu nhiên chọn một phiên bản tăng cường từ
SC và SW (tức là C' ∈ SC và W' ∈ SW) và xây dựng bộ
bốn (C;W;C';W') cho tiền huấn luyện. Lưu ý rằng trong
quá trình tiền huấn luyện, ở mỗi bước học, (C';W') được
chọn ngẫu nhiên từ các tập tăng cường SC và SW tương ứng.
Do đó, mỗi mẫu tăng cường trong các tập được sử dụng khi
mô hình có đủ bước học.

C. Thiết kế Mô hình và Tiền huấn luyện
Về cơ bản, ContraBERT được huấn luyện thêm từ các mô
hình tiền huấn luyện hiện có. Chúng tôi trực tiếp sử dụng
mô hình tiền huấn luyện hiện có và tiếp tục tiền huấn luyện
nó với mô hình hóa ngôn ngữ có mặt nạ (MLM) và tác vụ
tiền huấn luyện tương phản để tăng cường tính bền vững
của nó. Thiết kế mô hình của ContraBERT được trình bày
trong Hình 3.

1) Thiết kế Mô hình: Như được hiển thị trong Hình 3,
ContraBERT bao gồm hai bộ mã hóa riêng biệt M và M',
trong đó M có thể được biểu diễn bởi bất kỳ mô hình tiền
huấn luyện nào như CodeBERT. Kiến trúc mô hình của M'
giống với bộ mã hóa M và trọng số ban đầu cũng giống với
M. Tuy nhiên, chiến lược cập nhật trọng số khác với M. Cụ
thể, cho một bộ bốn (C;W;C';W') từ Mục III-B, chúng tôi
xây dựng hai chuỗi đầu vào X = {[CLS]; W; [SEP]; C; [SEP]}
và X' = {[CLS]; W'; [SEP]; C'; [SEP]}, trong đó "[CLS]"
chỉ ra sự bắt đầu của một chuỗi và "[SEP]" là một ký hiệu
nối hai loại chuỗi. Chúng tôi sử dụng bộ mã hóa M và M'
để mã hóa chuỗi đầu vào có mặt nạ X và X' tương ứng.

2) Tác vụ Tiền huấn luyện: Mô hình hóa ngôn ngữ có mặt
nạ (MLM) là một tác vụ tiền huấn luyện hiệu quả và được
áp dụng rộng rãi để học các biểu diễn token hiệu quả [37],
[38], chúng tôi cũng sử dụng nó như một trong các tác vụ
tiền huấn luyện của chúng tôi. Tuy nhiên, bằng kết quả sơ
bộ của chúng tôi trong Mục I, chúng tôi quan sát thấy rằng
các mô hình được huấn luyện bởi MLM yếu đối với các ví
dụ đối kháng, chúng tôi tiếp tục giới thiệu một tác vụ tiền
huấn luyện tương phản để nhóm dữ liệu tương tự và đẩy xa
dữ liệu không tương tự để định hình lại không gian đã học
cho bộ mã hóa M để tăng cường tính bền vững mô hình.

Mô hình hóa Ngôn ngữ có Mặt nạ (MLM). Chúng tôi sử
dụng MLM để học các biểu diễn token trong một chuỗi. Cụ
thể, cho chuỗi X = {[CLS]; W; [SEP]; C; [SEP]}, một tập
ngẫu nhiên các vị trí trong X được che mặt. Chúng tôi chọn
15% token để che mặt và có được tập token bị che mặt. Hơn
nữa, chúng tôi thay thế 80% token bị che mặt trong tập này
bằng ký hiệu "[MASK]", 10% bằng các token ngẫu nhiên từ
tập từ vựng và 10% còn lại không thay đổi. Chúng tôi cấu
hình các cài đặt này vì chúng được xác nhận hiệu quả để
học các biểu diễn token trong một chuỗi [37], [38]. Hàm
mất mát LMLM có thể được biểu diễn như sau:

LMLM = Σ(xi∈M) log p(xi|Xmask)     (1)

trong đó Xmask là chuỗi đầu vào có mặt nạ và M là tập
token bị che mặt.

Tiền huấn luyện Tương phản. Chúng tôi thiết kế một tác
vụ tiền huấn luyện tương phản sử dụng InfoNCE [48] như
hàm mất mát để tăng cường tính bền vững mô hình. Nó có
thể được biểu diễn như sau:

LInfoNCE = -log(exp(q·k+/τ) / (exp(q·k+/τ) + Σ(i=1 to n)exp(q·ki-/τ)))     (2)

trong đó τ là một siêu tham số nhiệt độ [49], vector truy
vấn q là biểu diễn vector được mã hóa, k+ là một vector
khóa tương tự mà q khớp, K = {k1-; ...; kn-} là một tập
các vector được mã hóa không tương tự. InfoNCE cố gắng
phân loại vector truy vấn q thành mẫu tương tự k+ và đẩy
nó ra xa khỏi các mẫu không tương tự trong tập K. Độ tương
tự được đo bằng tích vô hướng (·) giữa hai vector. Để có
được biểu diễn truy vấn q và biểu diễn khóa tương tự k+,
được lấy cảm hứng từ tiến bộ gần đây [50] về nhận dạng
hình ảnh, chúng tôi áp dụng Tương phản Động lượng (MoCo)
[50] cho việc mã hóa. Cụ thể, nó giới thiệu một bộ mã hóa
bổ sung M' để có biểu diễn khóa k+, có thể được biểu diễn
như sau:

q = LayerNorm(M(X)[0])
k+ = LayerNorm(M'(X')[0])     (3)

trong đó X và X' biểu thị chuỗi có mặt nạ gốc và biến thể
đột biến của nó tương ứng. Chỉ số 0 biểu thị vị trí của "[CLS]"
trong chuỗi, có thể được coi là biểu diễn chuỗi tổng hợp.
Bộ mã hóa M' giống với bộ mã hóa M, nhưng trong giai đoạn
học, nó sử dụng một động lượng để cập nhật trọng số đã học
trong khi bộ mã hóa M sử dụng hạ gradient:

θM' ← m·θM' + (1-m)·θM     (4)

trong đó m ∈ [0;1) là hệ số động lượng để tỷ lệ, θM' và
θM biểu thị trọng số đã học cho mô hình M' và M.

Từ Phương trình 3, chúng tôi có được biểu diễn truy vấn
q và biểu diễn khóa k+, để tính toán độ tương tự với các
vector không tương tự từ K, MoCo duy trì một hàng đợi "động"
có độ dài n. Hàng đợi này lưu trữ các khóa không tương tự
từ các batch trước đó. Cụ thể, trong giai đoạn học, truy vấn
hiện tại q sẽ tính toán độ tương tự với tất cả các vector
không tương tự trong hàng đợi này. Sau đó, vector khóa
k+ sẽ được đưa vào hàng đợi để thay thế cái cũ nhất và
chúng tôi lấy nó làm các mẫu không tương tự cho tính toán
của truy vấn tiếp theo. Do đó, nó được gọi là cập nhật động.

Cuối cùng, chúng tôi cộng cả hai giá trị mất mát với hệ
số tỷ lệ để tiền huấn luyện ContraBERT và quá trình này
được biểu diễn như sau:

LLoss = LMLM + w·LInfoNCE     (5)

trong đó w là siêu tham số để tỷ lệ trọng số cho cả hai tác
vụ tiền huấn luyện.

D. Tinh chỉnh
Khi ContraBERT được tiền huấn luyện thêm từ mô hình
tiền huấn luyện gốc, chúng tôi có thể sử dụng nó để có được
biểu diễn vector cho một chương trình. Hơn nữa, chúng tôi
cũng có thể chuyển nó sang các tác vụ phụ thuộc khác nhau
trong giai đoạn tinh chỉnh. Các tác vụ phụ thuộc này có thể
được phân loại thô thành ba nhóm: (1) tác vụ truy xuất (ví
dụ: phát hiện bản sao [39], [51], tìm kiếm mã nguồn [11],
[16]); (2) tác vụ phân loại (ví dụ: phát hiện lỗi [5]); (3)
tác vụ tạo (ví dụ: dịch mã nguồn sang mã nguồn [52], [53],
tinh chỉnh mã nguồn [54] và tóm tắt mã nguồn [7]). Vì không
gian đầu ra có thể khác với không gian tiền huấn luyện, tương
tự như CodeBERT và GraphCodeBERT, chúng tôi thêm mô-đun
cụ thể cho tác vụ và sau đó tinh chỉnh mạng hoàn chỉnh trên
dữ liệu có nhãn. Cụ thể, đối với tác vụ truy xuất, chúng tôi
tiếp tục huấn luyện ContraBERT trên một tập dữ liệu có nhãn;
đối với tác vụ phân loại, chúng tôi thêm một perceptron đa
lớp (MLP) để dự đoán xác suất cho mỗi lớp; đối với tác vụ
tạo, chúng tôi thêm một bộ giải mã dựa trên Transformer để
tạo ra chuỗi đích.

IV. THIẾT LẬP THÍ NGHIỆM
Trong các thí nghiệm, chúng tôi đầu tiên đánh giá hiệu
quả của phương pháp của chúng tôi (RQ1) trong việc cải
thiện tính bền vững mô hình. Sau đó chúng tôi vẽ không
gian đặc trưng được học bởi các mô hình tiền huấn luyện
khác nhau để trực quan hóa nhằm xác nhận các đặc trưng
được học tốt hơn (RQ2). Cuối cùng, chúng tôi tiến hành các
thí nghiệm mở rộng để chứng minh các mô hình được tăng
cường tính bền vững cung cấp cải thiện đáng kể trên các
tác vụ phụ thuộc (RQ3-RQ4). Các câu hỏi nghiên cứu chi
tiết được mô tả như sau:

RQ1: Hiệu suất của các toán tử tăng cường khác nhau trong
việc tăng cường tính bền vững của mô hình tiền huấn luyện
như thế nào?

RQ2: ContraBERT có thể định hình lại không gian vector
được học từ các mô hình tiền huấn luyện để có được các
biểu diễn vector tốt hơn không?

RQ3: ContraBERT có thể vượt trội hơn các mô hình tiền
huấn luyện gốc trên các tác vụ phụ thuộc khác nhau không?

RQ4: Các tác vụ tiền huấn luyện được định nghĩa có đều
hiệu quả trong việc cải thiện hiệu suất tác vụ phụ thuộc
không?

A. Tác vụ Đánh giá, Tập dữ liệu và Đường chuẩn
Chúng tôi chọn bốn tác vụ phụ thuộc để đánh giá. Chúng
là phát hiện bản sao [39], [43], tìm kiếm mã nguồn [16],
phát hiện lỗi [5] và dịch mã nguồn [52], [53]. Chúng tôi
giới thiệu ngắn gọn từng tác vụ như sau:

Phát hiện Bản sao (Truy xuất Mã nguồn-Mã nguồn). Tác
vụ này là để xác định các chương trình tương đương ngữ
nghĩa từ một tập các yếu tố gây nhiễu bằng cách đo độ tương
tự ngữ nghĩa giữa hai chương trình. AI cho phát hiện bản
sao tính toán độ tương tự cosine giữa hai vector nhúng của
các chương trình được tạo ra bởi mạng nơ-ron và chọn top-k
chương trình tương tự nhất làm ứng cử viên.

Phát hiện Lỗi (Phân loại Mã nguồn). Nó nhằm phát hiện
xem một hàm có chứa lỗi sẽ bị khai thác để tấn công các
hệ thống phần mềm hay không. Vì các lỗi trong một chương
trình vẫn khó được phát hiện hiệu quả bởi các kỹ thuật truyền
thống, các công trình tiên tiến gần đây [5], [55], [17] đề
xuất sử dụng mạng nơ-ron sâu để học ngữ nghĩa chương
trình nhằm hỗ trợ việc phát hiện. Các kỹ thuật dựa trên AI
này dự đoán xác suất xem một hàm có dễ bị tổn thương hay
không.

Dịch Mã nguồn (Tạo Mã nguồn-Mã nguồn). Nó nhằm dịch
một chương trình trong một ngôn ngữ lập trình (ví dụ: Java)
sang chương trình tương đương ngữ nghĩa trong một ngôn
ngữ khác (ví dụ: C#). Một số công trình trước đây [53] so
sánh nó với dịch máy [42], [56] trong NLP và sử dụng LSTM
[20] và Transformer [42] cho dịch mã nguồn.

Tìm kiếm Mã nguồn (Truy xuất Văn bản-Mã nguồn). Nó
nhằm trả về các chương trình mong muốn dựa trên truy vấn
bằng ngôn ngữ tự nhiên. Tương tự như phát hiện bản sao,
nó đo mức độ liên quan ngữ nghĩa giữa các truy vấn và chương
trình. Đầu vào cho hệ thống tìm kiếm mã nguồn sâu [16],
[11] là một truy vấn ngôn ngữ tự nhiên và đầu ra là các chương
trình đáp ứng yêu cầu truy vấn. Độ tương tự cosine được
sử dụng để tính toán độ tương tự ngữ nghĩa giữa các vector
của một truy vấn và chương trình.

Về tập dữ liệu tiền huấn luyện, chúng tôi sử dụng tập dữ
liệu đã phát hành được cung cấp bởi CodeSearchNet [16]
và tập dữ liệu này cũng được sử dụng bởi CodeBERT và
GraphCodeBERT. Chúng tôi sử dụng các cặp NL-PL đa phương
thức để tiền huấn luyện, bao gồm sáu ngôn ngữ lập trình
bao gồm Java, Python, Ruby, Go, PHP và JavaScript. Đối
với các tập dữ liệu tinh chỉnh, cho các tác vụ phát hiện bản
sao (POJ-104), phát hiện lỗi, và dịch mã nguồn, chúng tôi
trực tiếp sử dụng tập dữ liệu cụ thể cho tác vụ đã phát hành
được cung cấp bởi CodeXGLUE [3]. Đối với tìm kiếm mã
nguồn, chúng tôi sử dụng tập dữ liệu đã được làm sạch được
cung cấp bởi GraphCodeBERT [30] để đánh giá. Đối với mỗi
tác vụ, chúng tôi sử dụng các script chính thức để thực hiện
so sánh công bằng. Ngoài ra, bằng các toán tử tăng cường
được định nghĩa trong Mục III-B, chúng tôi có được một
lượng lớn dữ liệu bổ sung (C';W') được sử dụng trong ContraBERT
so với dữ liệu tiền huấn luyện gốc được sử dụng trong CodeBERT
và GraphCodeBERT. Do đó, chúng tôi thêm hai đường chuẩn
CodeBERT Intr và GraphCodeBERT Intr, sử dụng dữ liệu
gốc cũng như tập dữ liệu của dữ liệu bổ sung (C';W') để
tiền huấn luyện CodeBERT và GraphCodeBERT với MLM để
so sánh.

B. Chỉ số Đánh giá
Trong ContraBERT, các chỉ số khác nhau được sử dụng
để đánh giá các tác vụ phụ thuộc. Chúng tôi tuân theo các
chỉ số mà CodeXGLUE đã sử dụng để đánh giá, và các chi
tiết được liệt kê dưới đây:

MAP@R. Nó là viết tắt của trung bình của độ chính xác
trung bình, được sử dụng để đánh giá kết quả truy xuất R
mẫu tương tự nhất trong một tập cho một truy vấn. MAP@R
được sử dụng cho phát hiện bản sao, trong đó R được đặt
là 499 để đánh giá.

Acc. Nó định nghĩa tỷ lệ dự đoán chính xác (tức là khớp
chính xác) trong tập thử nghiệm. Acc được sử dụng để đánh
giá phát hiện lỗi và dịch mã nguồn.

BLEU-4. Nó được sử dụng rộng rãi để đánh giá độ tương
tự văn bản giữa chuỗi được tạo với ground-truth trong các
hệ thống tạo. Chúng tôi sử dụng BLEU-4 cho dịch mã nguồn.

MRR. Nó là viết tắt của Thứ hạng Nghịch đảo Trung bình,
được áp dụng rộng rãi trong các hệ thống truy xuất thông
tin [11], [57]. Chúng tôi sử dụng nó để đánh giá hiệu suất
của tìm kiếm mã nguồn. Thay vì truy xuất 1.000 ứng cử
viên như CodeBERT [29], chúng tôi tuân theo các cài đặt
của GraphCodeBERT [30] để truy xuất câu trả lời cho mỗi
truy vấn từ toàn bộ tập thử nghiệm.

C. Cài đặt Thí nghiệm
Chúng tôi áp dụng CodeBERT và GraphCodeBERT làm
các mô hình gốc của chúng tôi. Chúng tôi đặt độ dài chuỗi
đầu vào tối đa X và chuỗi đột biến X' là 512 theo CodeBERT.
Chúng tôi sử dụng Adam để tối ưu hóa với kích thước batch
256 và tốc độ học 2e-4. Ở mỗi lần lặp, X' được xây dựng
bởi C' và W', được chọn ngẫu nhiên từ SC và SW tương ứng.
Theo He et al. [50], hệ số động lượng m, tham số nhiệt độ
τ và kích thước hàng đợi được đặt lần lượt là 0.999, 0.07
và 65536. Chúng tôi đặt trọng số w trong Phương trình 5
là 0.5 để tăng tốc quá trình hội tụ. Mô hình được huấn luyện
trên máy DGX với 4 NVIDIA Tesla V100 với bộ nhớ 32GB.
Để giảm thiểu thiên vị đối với các ngôn ngữ tài nguyên cao
(tức là số lượng mẫu cho các ngôn ngữ lập trình khác nhau
là khác nhau), chúng tôi tham khảo GraphCodeBERT [30]
và lấy mẫu mỗi batch từ cùng một ngôn ngữ lập trình theo
phân phối đa thức với xác suất {qi}i=1...N.

qi = √pi / Σ(j=1 to N)√pj với pi = ni / Σ(k=1 to N)nk     (6)

trong đó ni là số lượng mẫu cho ngôn ngữ lập trình thứ i,
N là tổng số ngôn ngữ và α được đặt là 0.7. Mô hình được
huấn luyện với 50K bước để đảm bảo mỗi mẫu đột biến được
sử dụng cho quá trình học và mất khoảng 2 ngày để hoàn
thành quá trình tiền huấn luyện. Ở giai đoạn tinh chỉnh,
chúng tôi trực tiếp sử dụng các cài đặt mặc định của CodeXGLUE
[3] và GraphCodeBERT [30] trong ContraBERT cho các tác
vụ phụ thuộc. Tất cả các thí nghiệm của các tác vụ phụ
thuộc được tiến hành trên Bộ xử lý Intel Xeon Silver 4214
với 6 NVIDIA Quadro RTX 8000 với bộ nhớ 48GB.

V. KẾT QUẢ THÍ NGHIỆM

A. RQ1: Tăng cường Tính bền vững.
Chúng tôi điều tra các toán tử tăng cường trong việc tăng
cường tính bền vững mô hình bằng cách xác thực độ chính
xác của các mẫu chống lại các cuộc tấn công đối kháng trên
phát hiện bản sao (POJ-104). Lý do chính để chọn phát hiện
bản sao là nó nhắm đến việc xác định các mẫu tương đương
ngữ nghĩa từ các yếu tố gây nhiễu khác. Do đó, mặc dù toán
tử đổi tên biến thay đổi văn bản của một chương trình, ngữ
nghĩa chương trình gốc vẫn không thay đổi. Chúng tôi phân
tích thống kê các kết quả được dự đoán chính xác dưới một
số lượng chỉnh sửa đổi tên khác nhau để minh họa. Các thí
nghiệm được tiến hành theo cách zero-shot [58], có nghĩa
là nó không liên quan đến giai đoạn tinh chỉnh và chúng
tôi trực tiếp sử dụng mô hình tiền huấn luyện để đánh giá.
Cụ thể, chúng tôi loại bỏ một toán tử và giữ các toán tử
còn lại trong Mục III-B để tiền huấn luyện mô hình. Để
công bằng, các cài đặt khác trong thí nghiệm giống như
ContraBERT. Sau đó chúng tôi sử dụng tập thử nghiệm (tổng
cộng 12.000 mẫu) trên phát hiện bản sao (POJ-104) và ngẫu
nhiên đột biến các biến có trong các mẫu được dự đoán chính
xác được tạo ra bởi các mô hình tiền huấn luyện khác nhau
từ 1 đến 8 chỉnh sửa để kiểm tra độ chính xác dự đoán. Kết
quả thí nghiệm được hiển thị trong Bảng I trong đó N là
số lượng chỉnh sửa và Num là tổng số mẫu được dự đoán
chính xác mà không có bất kỳ chỉnh sửa nào trong tập thử
nghiệm cho các mô hình khác nhau. ContraBERT C/G định
nghĩa mô hình được khởi tạo bởi CodeBERT và GraphCodeBERT
tương ứng và w/o định nghĩa toán tử được loại bỏ.

Từ Bảng I, chúng tôi thấy rằng nói chung, với số lượng
chỉnh sửa tăng lên, hiệu suất tiếp tục giảm. Điều này hợp
lý, vì số lượng chỉnh sửa tăng lên, độ khó cho các dự đoán
được sửa chữa cũng tăng lên. Chúng tôi cũng quan sát thấy
rằng mỗi toán tử tăng cường đều có lợi để cải thiện tính
bền vững mô hình chống lại các mẫu đối kháng và khi kết
hợp tất cả các toán tử, chúng tôi có được hiệu suất tốt nhất.
Điều này chứng minh hiệu quả của các toán tử tăng cường
PL-NL được thiết kế của chúng tôi. Về các toán tử tăng cường
NL, các toán tử Delete/Switch/Copy tương đối yếu hơn trong
việc tăng cường tính bền vững so với toán tử Trans. Vì các
toán tử (Delete/Switch/Copy) chỉ có mức độ sửa đổi hạn
chế trên chuỗi gốc (tức là chỉ một hoặc hai từ được sửa đổi),
độ tương tự văn bản giữa W và W' tương tự hơn so với toán
tử Trans tạo ra. Do đó, tính đa dạng dữ liệu bị hạn chế bởi
Delete/Switch/Copy, dẫn đến việc cải thiện tính bền vững
không rõ ràng như toán tử Trans. Về các toán tử tăng cường
PL, chúng tôi thấy rằng số lượng mẫu được dự đoán chính
xác của ContraBERT C/G w/o RV là thấp nhất (ví dụ: 8.665
và 9.042). Với số lượng chỉnh sửa tăng lên, độ chính xác
giảm với biên độ lớn. Điều này cho thấy toán tử RV đóng
vai trò quan trọng chống lại các cuộc tấn công đối kháng
và việc loại bỏ nó làm hại hiệu suất đáng kể. Ngoài ra, việc
loại bỏ toán tử RFN, ContraBERT cũng có độ chính xác cao
hơn các toán tử PL khác (tức là RV, IDC, RO và SP), cho
thấy rằng RFN có ít đóng góp hơn. Điều này được gây ra
bởi chương trình được tạo C' bởi RFN (tức là đổi tên tên
hàm) tương tự hơn với chương trình gốc C so với các toán
tử tăng cường PL khác.

Trả lời RQ1: Mỗi toán tử trong tăng cường PL-NL được
thiết kế đều hiệu quả trong việc cải thiện tính bền vững mô
hình và khi kết hợp chúng, tính bền vững của các mô hình
tiền huấn luyện được tăng cường thêm.

B. RQ2: Trực quan hóa cho Nhúng Mã nguồn.
Chúng tôi trực quan hóa không gian biểu diễn mã nguồn
được học bởi các mô hình tiền huấn luyện khác nhau để xác
nhận rằng tác vụ tiền huấn luyện tương phản có thể định
hình lại không gian vector đã học để đảm bảo mô hình bền
vững hơn. Cụ thể, chúng tôi sử dụng tác vụ phát hiện bản
sao (POJ-104) được cung cấp bởi CodeXGLUE [3] để đánh
giá. Lý do chính để chọn phát hiện bản sao là nó trực quan
hơn để quan sát và xác thực độ tương tự của biểu diễn mã
nguồn trên các chương trình tương đương ngữ nghĩa. Tập
dữ liệu bao gồm 104 bài toán lập trình, trong đó mỗi bài
toán có 500 chương trình tương đương ngữ nghĩa với các
triển khai khác nhau. Về mặt lý thuyết, ngữ nghĩa chương
trình cho một bài toán phải giống nhau. Do đó, các vector
mã nguồn (tức là biểu diễn) của các chương trình từ các
mô hình tiền huấn luyện cho một bài toán phải gần nhau
hơn so với các vector mã nguồn của các chương trình cho
các bài toán khác. Chúng tôi ngẫu nhiên chọn 5 bài toán
khác nhau với 100 mẫu và lấy chúng làm đầu vào cho CodeBERT,
GraphCodeBERT, ContraBERT C và ContraBERT G để trực
quan hóa trong đó C/G định nghĩa ContraBERT được khởi
tạo bởi CodeBERT hoặc GraphCodeBERT tương ứng. Chúng
tôi sử dụng vector của token "[CLS]" làm biểu diễn chương
trình. Chúng tôi tiếp tục sử dụng T-SNE [59] để giảm chiều
vector xuống không gian hai chiều để trực quan hóa. Tương
tự như Mục V-A, quá trình này cũng là zero-shot [58], giúp
chúng tôi xác thực không gian đã học bởi các kỹ thuật tiền
huấn luyện khác nhau.

Như được hiển thị trong Hình 4, các vector được tạo ra
bởi GraphCodeBERT (Xem Hình 4b) có khả năng nhóm một
số bài toán của các chương trình so với CodeBERT (Xem
Hình 4a), cho thấy rằng việc kết hợp cấu trúc chương trình
như biểu đồ luồng dữ liệu vào tiền huấn luyện có lợi cho
mô hình để học ngữ nghĩa chương trình. Tuy nhiên, chúng
tôi cũng thấy rằng sự cải thiện bị hạn chế và ranh giới trong
Hình 4b không rõ ràng. Một số điểm dữ liệu bị phân tán,
đặc biệt là ở phần trên bên phải của Hình 4b. Ngược lại,
việc trực quan hóa ContraBERT được hiển thị trong Hình
4c và Hình 4d. Chúng tôi thấy rằng các chương trình trong
cùng một bài toán tập hợp lại với nhau chặt chẽ như một
cụm và các cụm khác nhau có ranh giới rõ ràng hơn nhiều.
Điều này cho thấy rằng ContraBERT mạnh mẽ hơn CodeBERT/GraphCodeBERT
để nhóm dữ liệu tương đương ngữ nghĩa và đẩy xa dữ liệu
không tương tự. Chúng tôi quy công khả năng này cho các
toán tử tăng cường PL-NL được định nghĩa để nắm bắt bản
chất của các chương trình. Hơn nữa, ContraBERT G (Xem
Hình 4d) có hiệu suất phân cụm tốt hơn ContraBERT C (Xem
Hình 4c). Ví dụ trong Hình 4c, nhãn 0 có hai cụm xa nhau
trong khi trong Hình 4d, nó chỉ có một cụm. Các cải thiện
đến từ mô hình gốc được sử dụng mà GraphCodeBERT vượt
trội hơn CodeBERT. Ngoài ra, chúng tôi tính toán khoảng
cách biến dạng¹ [60] của các mẫu được chọn cho các mô
hình này để củng cố kết luận. Khoảng cách của CodeBERT,
GraphCodeBERT, ContraBERT C và ContraBERT G lần lượt
là 0.333, 0.212, 0.202 và 0.194. Chúng tôi có thể thấy rằng
ContraBERT có khoảng cách biến dạng thấp hơn CodeBERT
và GraphCodeBERT, chứng minh các cụm của chúng compact
hơn.

Trả lời RQ2: Thông qua các tác vụ tiền huấn luyện tương
phản để học các biến thể tăng cường được xây dựng bởi
một tập hợp các toán tử PL-NL, ContraBERT có thể nhóm
các mẫu tương đương ngữ nghĩa và đẩy xa các mẫu không
tương tự, do đó học được các biểu diễn vector tốt hơn.

C. RQ3: Hiệu suất của ContraBERT trên các Tác vụ Phụ thuộc.
Chúng tôi tiến hành các thí nghiệm mở rộng trên bốn tác
vụ phụ thuộc để đánh giá hiệu suất của ContraBERT so với
CodeBERT và GraphCodeBERT gốc. Chúng tôi thêm hai đường
chuẩn (tức là CodeBERT Intr và GraphCodeBERT Intr), được
tiền huấn luyện bởi dữ liệu gốc cũng như các biến thể tăng
cường. Chúng tôi bổ sung hai đường chuẩn này để đảm bảo
quy mô dữ liệu được sử dụng nhất quán với ContraBERT để
so sánh công bằng. Kết quả của phát hiện bản sao/phát hiện
lỗi được hiển thị trong Bảng II. Bảng III trình bày kết quả
của dịch mã nguồn và Bảng IV trình bày kết quả của tìm
kiếm mã nguồn trong đó cột "overall" ngoài cùng bên phải
là giá trị trung bình cho sáu ngôn ngữ lập trình. Vì các giá
trị cho phát hiện bản sao và phát hiện lỗi của GraphCodeBERT
không được báo cáo bởi bài báo gốc [30], chúng tôi sử dụng
mã chính thức để tái tạo và báo cáo các giá trị này. Các
giá trị khác của CodeBERT và GraphCodeBERT được lấy
trực tiếp từ CodeXGLUE [3] và Guo et al. [30].

Từ Bảng II và Bảng III, chúng tôi thấy rằng ContraBERT
C/G vượt trội hơn các mô hình tiền huấn luyện gốc CodeBERT
hoặc GraphCodeBERT trên phát hiện bản sao (POJ-104),
phát hiện lỗi và dịch mã nguồn. Tuy nhiên, những cải thiện
tuyệt đối trên tìm kiếm mã nguồn (xem Bảng IV) là nhỏ.
Đối với những cải thiện này, chúng tôi quy cho các mô hình
được tăng cường tính bền vững cung cấp hiệu suất tốt hơn
trên các tác vụ phụ thuộc. Khi nói đến những cải thiện nhỏ
trong tìm kiếm mã nguồn, chúng tôi quy cho độ khó của
tác vụ này. Tìm kiếm mã nguồn yêu cầu học ánh xạ ngữ
nghĩa giữa truy vấn và chương trình. Tuy nhiên, khoảng cách
ngữ nghĩa giữa các chương trình và ngôn ngữ tự nhiên là
rất lớn. Điều này làm cho mô hình khó đạt được những cải
thiện đáng kể. Tổng cộng, xem xét quy mô của tập thử nghiệm
trên tìm kiếm mã nguồn, chứa 52.561 mẫu cho sáu ngôn
ngữ lập trình, những cải thiện vẫn hứa hẹn. Hơn nữa, chúng
tôi thấy rằng so với CodeBERT và GraphCodeBERT, CodeBERT
Intr và GraphCodeBERT Intr có hiệu suất tốt hơn trên các
tác vụ này. Điều này hợp lý vì chúng tôi thêm dữ liệu bổ
sung để tiếp tục tiền huấn luyện CodeBERT và GraphCodeBERT.
Tuy nhiên, hiệu suất của CodeBERT Intr và GraphCodeBERT
Intr tệ hơn ContraBERT C/G. Điều này chứng minh rằng
ngay cả với cùng quy mô dữ liệu, ContraBERT C/G vẫn tốt
hơn CodeBERT và GraphCodeBERT, điều này càng củng cố
kết luận của chúng tôi rằng những cải thiện được mang lại
bởi phương pháp đề xuất của chúng tôi chứ không phải lợi
ích được mang lại bởi việc tăng quy mô dữ liệu.

Trả lời RQ3: ContraBERT cải thiện toàn diện hiệu suất
của CodeBERT và GraphCodeBERT gốc trên bốn tác vụ phụ
thuộc, chúng tôi quy những cải thiện cho tính bền vững được
tăng cường của mô hình có hiệu suất tốt hơn trên các tác
vụ này.

D. RQ4: Nghiên cứu Phân tích cho các Tác vụ Tiền huấn luyện.
ContraBERT sử dụng hai tác vụ tiền huấn luyện, cái đầu
tiên là MLM, học các biểu diễn token và cái thứ hai là tác
vụ tiền huấn luyện tương phản, cải thiện tính bền vững mô
hình bằng hàm mất mát InfoNCE. Chúng tôi tiếp tục điều
tra tác động của mỗi chiến lược tiền huấn luyện trên các
tác vụ phụ thuộc. Kết quả thí nghiệm được hiển thị trong
Bảng II, Bảng III và Bảng IV tương ứng, trong đó hàng MLM
hoặc Contra biểu thị kết quả thu được bằng cách sử dụng
thuần túy MLM hoặc tác vụ tiền huấn luyện tương phản.
Để so sánh công bằng, các cài đặt khác giống nhau khi kết
hợp cả hai tác vụ tiền huấn luyện để tiền huấn luyện.

Chúng tôi có thể quan sát thấy rằng hiệu suất của việc
sử dụng thuần túy các tác vụ tiền huấn luyện tương phản
tệ hơn việc sử dụng thuần túy MLM trên các tác vụ phụ
thuộc này, đặc biệt là trên tác vụ dịch mã nguồn. Điều này
chấp nhận được vì cả hai tác vụ tiền huấn luyện đều xuất
sắc trong các khía cạnh khác nhau. Cụ thể, MLM được thiết
kế bằng cách che mặt ngẫu nhiên một số token trong một
chuỗi để giúp mô hình học các biểu diễn token. Các biểu
diễn token đã học quan trọng cho các tác vụ tạo để tạo ra
một chuỗi đích như dịch mã nguồn, vì vậy nó sẽ giúp mô
hình đạt được hiệu suất tốt trên các tác vụ này. Tuy nhiên,
tác vụ tiền huấn luyện tương phản được thiết kế bằng cách
nhóm các mẫu tương đương ngữ nghĩa trong khi đẩy xa các
mẫu không tương tự thông qua hàm mất mát InfoNCE. Tính
bền vững mô hình được tăng cường bởi tác vụ tiền huấn
luyện tương phản. Hơn nữa, khi kết hợp cả hai tác vụ tiền
huấn luyện, mô hình của chúng tôi đạt được hiệu suất tốt
hơn so với việc sử dụng thuần túy một trong các tác vụ tiền
huấn luyện, cho thấy rằng ContraBERT bền vững đồng thời
có thể đạt được hiệu suất tốt hơn trên các tác vụ phụ thuộc.

Trả lời RQ4: Mô hình hóa ngôn ngữ có mặt nạ (MLM) và
tác vụ tiền huấn luyện tương phản đóng các vai trò khác
nhau cho ContraBERT. Khi kết hợp chúng lại với nhau, mô
hình đạt được hiệu suất cao hơn trên các tác vụ phụ thuộc
khác nhau.

VI. THẢO LUẬN
Trong mục này, chúng tôi đầu tiên thảo luận về ý nghĩa
của công trình chúng tôi, sau đó thảo luận về các hạn chế
tiếp theo là các mối đe dọa đối với tính hợp lệ.

A. Ý nghĩa
Trong công trình này, chúng tôi thấy rằng các mô hình
mã nguồn tiền huấn luyện được sử dụng rộng rãi như CodeBERT
[29] hoặc GraphCodeBERT [30] không bền vững với các cuộc
tấn công đối kháng. Dựa trên phát hiện này, chúng tôi tiếp
tục đề xuất một phương pháp dựa trên học tương phản để
cải thiện. Chúng tôi tin rằng phát hiện này trong bài báo
của chúng tôi sẽ truyền cảm hứng cho các nhà nghiên cứu
tiếp theo khi thiết kế một kiến trúc mô hình mới cho mã
nguồn, xem xét một số vấn đề khác trong mô hình như tính
bền vững, tổng quát hóa và không chỉ tập trung vào độ chính
xác của mô hình trên các tác vụ khác nhau.

B. Hạn chế
Bằng kết quả thí nghiệm của chúng tôi, chúng tôi thấy
rằng tính bền vững của mô hình được tăng cường đáng kể
so với các mô hình gốc. Chúng tôi quy công điều này cho
tác vụ tiền huấn luyện tương phản để học các mẫu tương
đương ngữ nghĩa. Tuy nhiên, các mô hình được tăng cường
tính bền vững này chỉ có những cải thiện nhỏ trên tác vụ
phụ thuộc của tìm kiếm mã nguồn. Đối với tác vụ này, vì
nó yêu cầu học ánh xạ ngữ nghĩa giữa một truy vấn và mã
nguồn tương ứng của nó, các toán tử tăng cường được thiết
kế chỉ sửa đổi mã nguồn hoặc truy vấn chính nó, do đó các
mối tương quan của chúng không được nắm bắt và điều này
dẫn đến việc cải thiện bị hạn chế. Đối với tìm kiếm mã nguồn,
một giải pháp có thể để cải thiện thêm hiệu suất là xây dựng
các mối quan hệ token giữa PL và NL cho các biến thể tăng
cường, tuy nhiên, nó bao gồm công việc chuyên sâu để phân
tích các mối quan hệ giữa chương trình và bình luận ngôn
ngữ tự nhiên. Chúng tôi sẽ khám phá nó trong công trình
tương lai của chúng tôi.

Một hạn chế khác là các toán tử tăng cường được thiết
kế cho PL và NL. Chúng tôi chỉ thiết kế một số toán tử cơ
bản để biến đổi các chương trình và bình luận. Các toán
tử này đơn giản, mặc dù chúng được xác nhận hiệu quả trong
việc cải thiện tính bền vững mô hình. Thật hấp dẫn khi khám
phá các chiến lược tăng cường phức tạp hơn như nhiều hoạt
động trên các toán tử này cho một mẫu để xây dựng các
biến thể tăng cường phức tạp.

C. Mối đe dọa đối với Tính hợp lệ
Tính hợp lệ nội tại: Mối đe dọa đầu tiên là việc điều chỉnh
siêu tham số cho tiền huấn luyện. Cần điều chỉnh nhiều siêu
tham số hơn CodeBERT hoặc GraphCodeBERT ví dụ như
nhiệt độ τ, hệ số động lượng m và kích thước hàng đợi.
Chúng tôi tuân theo các cài đặt gốc từ MoCo [50] và các
tham số này có thể không tối ưu vì chúng được thiết kế
cho tác vụ phân loại hình ảnh trong thị giác máy tính. Do
đó, quá trình tiền huấn luyện tốn thời gian và tài nguyên.
Chúng tôi cần gần 2 ngày để hoàn thành một quá trình huấn
luyện do đó chúng tôi bỏ qua quá trình điều chỉnh siêu tham
số. Tuy nhiên, chúng tôi cũng thấy rằng ngay cả với các
tham số gốc được sử dụng trong MoCo [50], ContraBERT
vẫn đạt được hiệu suất cao hơn các mô hình gốc. Mối đe
dọa thứ hai là chúng tôi sử dụng cùng một phân chia train-validation-test
mà CodeXGLUE [3] và GraphCodeBERT [30] đã sử dụng.
Điều chỉnh tỷ lệ phân chia dữ liệu hoặc cải thiện chất lượng
dữ liệu huấn luyện có thể tạo ra kết quả tốt hơn, tuy nhiên,
chúng tôi không áp dụng các chiến lược này để đảm bảo
đánh giá công bằng. Mối đe dọa thứ ba là chúng tôi chỉ sử
dụng phát hiện bản sao (POJ-104) để xác minh tính bền vững
của mô hình được tăng cường trong Hình 1 và Mục V-A,
chúng tôi cũng vẽ không gian đã học trong Mục V-B. Lý
do để chọn phát hiện bản sao là nó nhằm xác định các chương
trình tương đương ngữ nghĩa từ các yếu tố gây nhiễu khác,
phù hợp cho việc đánh giá.

Tính hợp lệ ngoại tại: Một số công trình tiền huấn luyện
khác trong tình huống mã nguồn như CuBERT [28] không
được bao gồm để đánh giá. CuBERT được tiền huấn luyện
trên một kho dữ liệu Python lớn với MLM. Phương pháp
của chúng tôi trực giao với các mô hình tiền huấn luyện này
và chúng tôi chỉ cần thay thế bộ mã hóa M bằng các mô
hình tiền huấn luyện hiện có khác để đánh giá.

VII. CÔNG TRÌNH LIÊN QUAN
Trong mục này, chúng tôi giới thiệu ngắn gọn các công
trình liên quan về học tương phản, các mô hình tiền huấn
luyện cho "big code" và tính bền vững đối kháng của các
mô hình mã nguồn.

A. Học Tương phản
Học tương phản là để học các biểu diễn bằng cách tối
thiểu hóa khoảng cách giữa các mẫu tương tự trong khi tối
đa hóa khoảng cách giữa các mẫu khác nhau để giúp các
mẫu tương tự gần nhau hơn và các mẫu khác nhau xa nhau
hơn. Trong vài năm qua, nó đã thu hút sự chú ý ngày càng
tăng với nhiều ứng dụng thành công trong thị giác máy tính
[50], [61], [62], [63], [64], xử lý ngôn ngữ tự nhiên [65],
[66], [67], [68]. Gần đây, có một số công trình [44], [69],
[45] sử dụng học tương phản cho các tác vụ kỹ thuật phần
mềm khác nhau. Ví dụ, Bui et al. [44] đề xuất Corder, một
phương pháp học tương phản cho truy xuất mã nguồn sang
mã nguồn, truy xuất văn bản sang mã nguồn và tóm tắt mã
nguồn sang văn bản. VarCLR [69] nhằm học các biểu diễn
ngữ nghĩa của tên biến dựa trên học tương phản cho các
tác vụ phụ thuộc khác nhau như tính điểm tương tự biến
và sửa lỗi chính tả biến. ContraCode [45] tạo ra các biến
thể bằng trình biên dịch nguồn sang nguồn trên JavaScript
và tiếp tục kết hợp các mẫu đột biến được tạo ra này với
học tương phản cho tác vụ phát hiện bản sao, suy luận kiểu
và tóm tắt mã nguồn. So với các công trình hiện có này chỉ
tập trung vào thiết kế các biến thể đột biến cho mã nguồn,
chúng tôi đầu tiên minh họa CodeBERT và GraphCodeBERT
được quan tâm rộng rãi yếu đối với các ví dụ đối kháng.
Sau đó chúng tôi thiết kế một tập hợp các toán tử tăng cường
đơn giản và phức tạp trên cả chuỗi chương trình và ngôn
ngữ tự nhiên để có được các biến thể khác nhau. Bằng học
tương phản để học các biến thể tương đương ngữ nghĩa,
tính bền vững của các mô hình tiền huấn luyện hiện có được
tăng cường. Chúng tôi tiếp tục xác nhận rằng các mô hình
được tăng cường tính bền vững cung cấp cải thiện trên các
tác vụ phụ thuộc khác nhau.

B. Mô hình Tiền huấn luyện cho "Big Code"
Gần đây, các mô hình tiền huấn luyện được áp dụng rộng
rãi cho kỷ nguyên "big code" [28], [29], [30], [3], [31],
[32], [33], [34], [35], [45], [70]. Ví dụ, Kanade et al. [28]
tiền huấn luyện CuBERT dựa trên BERT [37] với một kho
dữ liệu lớn các chương trình Python từ GitHub và sau đó
tinh chỉnh nó cho một số tác vụ phân loại như phân loại
sử dụng sai biến. Feng et al. [29] đề xuất CodeBERT, một
mô hình tiền huấn luyện đa phương thức cho ngôn ngữ lập
trình (PL) và ngôn ngữ tự nhiên (NL) học biểu diễn chương
trình để hỗ trợ tìm kiếm mã nguồn và tóm tắt mã nguồn.
GraphcodeBERT [30] kết hợp biểu đồ luồng dữ liệu biến
trong một chương trình với các chuỗi mã nguồn và chuỗi
ngôn ngữ tự nhiên để tăng cường CodeBERT. CodeXGLUE
[3] cũng sử dụng CodeBERT và CodeGPT [71] để phát hành
một điểm chuẩn bao gồm một số tác vụ kỹ thuật phần mềm.
Liu et al. [70] đề xuất một CommitBART để hỗ trợ các tác
vụ phụ thuộc liên quan đến commit. So với các mô hình
tiền huấn luyện hiện có, chúng tôi minh họa chúng không
bền vững và tiếp tục đề xuất ContraBERT để tăng cường
tính bền vững mô hình.

C. Tính Bền vững Đối kháng trên các Mô hình Mã nguồn
Nghiên cứu về phân tích tính bền vững đối kháng trên
các mô hình mã nguồn đã thu hút sự chú ý [72], [73], [74],
[40], [75], [76]. Nói chung, các công trình này có thể được
phân loại thành hai nhóm: cách tiếp cận hộp trắng và hộp
đen, trong đó hộp trắng có nghĩa là phương pháp cung cấp
một số giải thích về việc ra quyết định trong khi hộp đen
chủ yếu tập trung vào đánh giá thống kê. Về các công trình
hộp trắng, Yefet et al. [73] đề xuất DAMP để chọn các nhiễu
loạn bảo toàn ngữ nghĩa bằng cách suy ra phân phối đầu
ra của mô hình với đầu vào. Srikant et al. [72] cung cấp
một công thức tổng quát của một chương trình bị nhiễu loạn
mô hình các vị trí trang web và lựa chọn nhiễu loạn cho
mỗi vị trí. Sau đó dựa trên công thức này, họ tiếp tục đề
xuất một tập hợp các thuật toán tối ưu hóa bậc nhất để giải
quyết. Về các công trình hộp đen, HMH [76] tạo ra các ví
dụ đối kháng của mã nguồn bằng cách tiến hành đổi tên
định danh lặp đi lặp lại và đánh giá trên tác vụ phân loại
chức năng mã nguồn. Công trình mới nhất của Yang et al.
[40] đề xuất ALERT để biến đổi các đầu vào trong khi bảo
toàn ngữ nghĩa tùy chọn của các đầu vào gốc bằng cách
thay thế các biến bằng các thay thế. Các thí nghiệm của
họ được tiến hành trên các mô hình tiền huấn luyện CodeBERT
và GraphCodeBERT. So với ALERT, chỉ thiết kế hoạt động
đổi tên biến, trong bài báo này, ngoài hoạt động đổi tên
biến, chúng tôi tiếp tục thiết kế tám toán tử tăng cường
trên các cặp PL-NL. Hơn nữa, một mô hình được thiết kế
mới để giải quyết điểm yếu của tính bền vững không được
đề cập trong ALERT. Ngược lại, chúng tôi đề xuất kiến trúc
mạng tổng quát của chúng tôi sử dụng học tương phản để
tăng cường tính bền vững mô hình. Các thí nghiệm mở rộng
đã xác nhận rằng phương pháp của chúng tôi tăng cường
tính bền vững của các mô hình tiền huấn luyện hiện có.
Chúng tôi cũng chứng minh rằng các mô hình được tăng cường
tính bền vững này cung cấp cải thiện trên các tác vụ phụ
thuộc khác nhau.

VIII. KẾT LUẬN
Trong bài báo này, chúng tôi quan sát thấy rằng các mô
hình tiền huấn luyện tiên tiến như CodeBERT và GraphCodeBERT
không bền vững với các cuộc tấn công đối kháng và một
toán tử đột biến đơn giản (ví dụ: đổi tên biến) làm giảm
hiệu suất của chúng đáng kể. Để giải quyết vấn đề này,
trong bài báo này, chúng tôi đề xuất ContraBERT, một khung
dựa trên học tương phản để tăng cường tính bền vững của
các mô hình tiền huấn luyện hiện có bằng cách thiết kế chín
loại toán tử tăng cường PL-NL để nhóm các biến thể tương
đương ngữ nghĩa. Thông qua các thí nghiệm mở rộng, chúng
tôi đã xác nhận rằng tính bền vững của mô hình được tăng
cường. Hơn nữa, chúng tôi cũng minh họa rằng các mô hình
được tăng cường tính bền vững này cung cấp cải thiện trên
bốn tác vụ phụ thuộc.

IX. LỜI CẢM ơN
Chúng tôi bày tỏ lòng biết ơn chân thành đến Ông Daya
Guo từ Đại học Sun Yat-sen vì sự hỗ trợ của ông. Nghiên
cứu này được hỗ trợ một phần bởi Quỹ Nghiên cứu Quốc
gia, Singapore trong khuôn khổ Chương trình AI Singapore
(AISG2-RP-2020-019), Quỹ Nghiên cứu Quốc gia, Văn phòng
Thủ tướng, Singapore trong khuôn khổ Chương trình R&D
An ninh mạng Quốc gia (Giải thưởng số NRF2018NCR-NCR005-0001),
NRF Investigatorship NRF-NRFI06-2020-0001, Quỹ Nghiên
cứu Quốc gia thông qua dự án Vệ tinh Xuất sắc Quốc gia
về Hệ thống Phần mềm Đáng tin cậy (NSOE-TSS) trong
khuôn khổ Giải thưởng An ninh mạng Quốc gia R&D (NCR)
số NRF2018NCR-NSOE003-0001, Bộ Giáo dục, Singapore
trong khuôn khổ Nghiên cứu Học thuật Bậc 3 (MOET32020-0004).
Các tác giả IIE được hỗ trợ một phần bởi NSFC (61902395),
Chương trình Nova Bắc Kinh. Bất kỳ ý kiến, phát hiện và
kết luận hoặc khuyến nghị nào được thể hiện trong tài liệu
này là của (các) tác giả và không phản ánh quan điểm của
Bộ Giáo dục, Singapore.

TÀI LIỆU THAM KHẢO
[1] M. Allamanis, E. T. Barr, P. Devanbu, và C. Sutton, "A survey
of machine learning for big code and naturalness," ACM Computing
Surveys (CSUR), vol. 51, no. 4, pp. 1–37, 2018.
[2] "The github blog," https://github.blog/2018-11-08-100m-repos/.
[3] S. Lu, D. Guo, S. Ren, J. Huang, A. Svyatkovskiy, A. Blanco,
C. Clement, D. Drain, D. Jiang, D. Tang et al., "Codexglue: A machine
learning benchmark dataset for code understanding and generation,"
arXiv preprint arXiv:2102.04664, 2021.
[4] M. Allamanis, M. Brockschmidt, và M. Khademi, "Learning to represent programs with graphs," arXiv preprint arXiv:1711.00740, 2017.
[5] Y. Zhou, S. Liu, J. Siow, X. Du, và Y. Liu, "Devign: Effective vulnerability identification by learning comprehensive program semantics via
graph neural networks," arXiv preprint arXiv:1909.03496, 2019.
[6] M. Allamanis, H. Jackson-Flux, và M. Brockschmidt, "Self-supervised
bug detection and repair," arXiv preprint arXiv:2105.12787, 2021.
[7] S. Liu, Y. Chen, X. Xie, J. K. Siow, và Y. Liu, "Retrieval-augmented
generation for code summarization via hybrid gnn," in International
Conference on Learning Representations, 2020.
[8] U. Alon, S. Brody, O. Levy, và E. Yahav, "code2seq: Generating
sequences from structured representations of code," arXiv preprint
arXiv:1808.01400, 2018.
[9] U. Alon, M. Zilberstein, O. Levy, và E. Yahav, "code2vec: Learning
distributed representations of code," Proceedings of the ACM on Programming Languages, vol. 3, no. POPL, pp. 1–29, 2019.
[10] S. Liu, X. Xie, L. Ma, J. Siow, và Y. Liu, "Graphsearchnet: Enhancing
gnns via capturing global dependency for semantic code search," arXiv
preprint arXiv:2111.02671, 2021.
[11] X. Gu, H. Zhang, và S. Kim, "Deep code search," in 2018 IEEE/ACM
40th International Conference on Software Engineering (ICSE). IEEE,
2018, pp. 933–944.
[12] A. Svyatkovskiy, S. Lee, A. Hadjitofi, M. Riechert, J. V. Franco, và
M. Allamanis, "Fast and memory-efficient neural code completion," in
2021 IEEE/ACM 18th International Conference on Mining Software
Repositories (MSR). IEEE, 2021, pp. 329–340.
[13] U. Alon, R. Sadaka, O. Levy, và E. Yahav, "Structural language models
of code," in International Conference on Machine Learning. PMLR,
2020, pp. 245–256.
[14] F. Liu, G. Li, Y. Zhao, và Z. Jin, "Multi-task learning based pretrained language model for code completion," in Proceedings of the
35th IEEE/ACM International Conference on Automated Software Engineering, 2020, pp. 473–485.
[15] S. Iyer, I. Konstas, A. Cheung, và L. Zettlemoyer, "Summarizing source
code using a neural attention model," in Proceedings of the 54th Annual
Meeting of the Association for Computational Linguistics (Volume 1:
Long Papers), 2016, pp. 2073–2083.
[16] H. Husain, H.-H. Wu, T. Gazit, M. Allamanis, và M. Brockschmidt,
"Codesearchnet challenge: Evaluating the state of semantic code search,"
arXiv preprint arXiv:1909.09436, 2019.
[17] R. Russell, L. Kim, L. Hamilton, T. Lazovich, J. Harer, O. Ozdemir,
P. Ellingwood, và M. McConley, "Automated vulnerability detection
in source code using deep representation learning," in 2018 17th
IEEE international conference on machine learning and applications
(ICMLA). IEEE, 2018, pp. 757–762.
[18] A. V. M. Barone và R. Sennrich, "A parallel corpus of python functions
and documentation strings for automated code documentation and code
generation," arXiv preprint arXiv:1707.02275, 2017.
[19] Y. Zhou, J. K. Siow, C. Wang, S. Liu, và Y. Liu, "Spi: Automated
identification of security patches via commits," ACM Transactions on
Software Engineering and Methodology (TOSEM), vol. 31, no. 1, pp.
1–27, 2021.
[20] S. Hochreiter và J. Schmidhuber, "Long short-term memory," Neural
computation, vol. 9, no. 8, pp. 1735–1780, 1997.
[21] A. Krizhevsky, I. Sutskever, và G. E. Hinton, "Imagenet classification
with deep convolutional neural networks," Advances in neural information processing systems, vol. 25, pp. 1097–1105, 2012.
[22] S. Liu, C. Gao, S. Chen, N. L. Yiu, và Y. Liu, "Atom: Commit message
generation based on abstract syntax tree and hybrid ranking," IEEE
Transactions on Software Engineering, 2020.
[23] B. Wu, S. Liu, R. Feng, X. Xie, J. Siow, và S.-W. Lin, "Enhancing
security patch identification by capturing structures in commits," IEEE
Transactions on Dependable and Secure Computing, 2022.
[24] X. Li, S. Liu, R. Feng, G. Meng, X. Xie, K. Chen, và Y. Liu,
"Transrepair: Context-aware program repair for compilation errors,"
arXiv preprint arXiv:2210.03986, 2022.
[25] F. Yamaguchi, N. Golde, D. Arp, và K. Rieck, "Modeling and discovering vulnerabilities with code property graphs," in 2014 IEEE Symposium
on Security and Privacy. IEEE, 2014, pp. 590–604.
[26] Y. Li, D. Tarlow, M. Brockschmidt, và R. Zemel, "Gated graph
sequence neural networks," arXiv preprint arXiv:1511.05493, 2015.
[27] M. Allamanis, "The adverse effects of code duplication in machine
learning models of code," in Proceedings of the 2019 ACM SIGPLAN
International Symposium on New Ideas, New Paradigms, and Reflections
on Programming and Software, 2019, pp. 143–153.
[28] A. Kanade, P. Maniatis, G. Balakrishnan, và K. Shi, "Pre-trained
contextual embedding of source code," 2019.
[29] Z. Feng, D. Guo, D. Tang, N. Duan, X. Feng, M. Gong, L. Shou, B. Qin,
T. Liu, D. Jiang et al., "Codebert: A pre-trained model for programming
and natural languages," arXiv preprint arXiv:2002.08155, 2020.
[30] D. Guo, S. Ren, S. Lu, Z. Feng, D. Tang, S. Liu, L. Zhou, N. Duan,
A. Svyatkovskiy, S. Fu et al., "Graphcodebert: Pre-training code representations with data flow," arXiv preprint arXiv:2009.08366, 2020.
[31] A. Svyatkovskiy, S. K. Deng, S. Fu, và N. Sundaresan, "Intellicode
compose: Code generation using transformer," in Proceedings of the
28th ACM Joint Meeting on European Software Engineering Conference
and Symposium on the Foundations of Software Engineering, 2020, pp.
1433–1443.
[32] L. Buratti, S. Pujar, M. Bornea, S. McCarley, Y. Zheng, G. Rossiello,
A. Morari, J. Laredo, V. Thost, Y. Zhuang et al., "Exploring software naturalness through neural language models," arXiv preprint
arXiv:2006.12641, 2020.
[33] R.-M. Karampatsis và C. Sutton, "Scelmo: Source code embeddings
from language models," arXiv preprint arXiv:2004.13214, 2020.
[34] Y. Wang, W. Wang, S. Joty, và S. C. Hoi, "Codet5: Identifier-aware
unified pre-trained encoder-decoder models for code understanding and
generation," arXiv preprint arXiv:2109.00859, 2021.
[35] W. U. Ahmad, S. Chakraborty, B. Ray, và K.-W. Chang, "Unified
pre-training for program understanding and generation," arXiv preprint
arXiv:2103.06333, 2021.
[36] A. Kanade, P. Maniatis, G. Balakrishnan, và K. Shi, "Learning and
evaluating contextual embedding of source code," in International
Conference on Machine Learning. PMLR, 2020, pp. 5110–5121.
[37] J. Devlin, M.-W. Chang, K. Lee, và K. Toutanova, "Bert: Pre-training
of deep bidirectional transformers for language understanding," arXiv
preprint arXiv:1810.04805, 2018.
[38] Y. Liu, M. Ott, N. Goyal, J. Du, M. Joshi, D. Chen, O. Levy, M. Lewis,
L. Zettlemoyer, và V. Stoyanov, "Roberta: A robustly optimized bert
pretraining approach," arXiv preprint arXiv:1907.11692, 2019.
[39] L. Mou, G. Li, L. Zhang, T. Wang, và Z. Jin, "Convolutional neural
networks over tree structures for programming language processing," in
Thirtieth AAAI Conference on Artificial Intelligence, 2016.
[40] Z. Yang, J. Shi, J. He, và D. Lo, "Natural attack for pre-trained models
of code," arXiv preprint arXiv:2201.08698, 2022.
[41] Authors, "Contrabert: Enhancing code pre-trained models via contrastive
learning," https://sites.google.com/view/contrabert.
[42] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez,
Ł. Kaiser, và I. Polosukhin, "Attention is all you need," in Advances
in neural information processing systems, 2017, pp. 5998–6008.
[43] J. Svajlenko, J. F. Islam, I. Keivanloo, C. K. Roy, và M. M. Mia,
"Towards a big data curated benchmark of inter-project code clones,"
in 2014 IEEE International Conference on Software Maintenance and
Evolution. IEEE, 2014, pp. 476–480.
[44] N. D. Bui, Y. Yu, và L. Jiang, "Self-supervised contrastive learning for
code retrieval and summarization via semantic-preserving transformations," in Proceedings of the 44th International ACM SIGIR Conference
on Research and Development in Information Retrieval, 2021, pp. 511–
521.
[45] P. Jain, A. Jain, T. Zhang, P. Abbeel, J. E. Gonzalez, và I. Stoica, "Contrastive code representation learning," arXiv preprint arXiv:2007.04973,
2020.
[46] R. Sennrich, B. Haddow, và A. Birch, "Improving neural machine translation models with monolingual data," arXiv preprint arXiv:1511.06709,
2015.
[47] E. Ma, "Nlp augmentation," https://github.com/makcedward/nlpaug,
2019.
[48] A. v. d. Oord, Y. Li, và O. Vinyals, "Representation learning with
contrastive predictive coding," arXiv preprint arXiv:1807.03748, 2018.
[49] Z. Wu, Y. Xiong, S. X. Yu, và D. Lin, "Unsupervised feature learning
via non-parametric instance discrimination," in Proceedings of the IEEE
conference on computer vision and pattern recognition, 2018, pp. 3733–
3742.
[50] K. He, H. Fan, Y. Wu, S. Xie, và R. Girshick, "Momentum contrast
for unsupervised visual representation learning," in Proceedings of the
IEEE/CVF Conference on Computer Vision and Pattern Recognition,
2020, pp. 9729–9738.
[51] W. Wang, G. Li, B. Ma, X. Xia, và Z. Jin, "Detecting code clones with
graph neural network and flow-augmented abstract syntax tree," in 2020
IEEE 27th International Conference on Software Analysis, Evolution
and Reengineering (SANER). IEEE, 2020, pp. 261–271.
[52] X. Chen, C. Liu, và D. Song, "Tree-to-tree neural networks for program
translation," arXiv preprint arXiv:1802.03691, 2018.
[53] M.-A. Lachaux, B. Roziere, L. Chanussot, và G. Lample, "Unsupervised translation of programming languages," arXiv preprint
arXiv:2006.03511, 2020.
[54] M. Tufano, C. Watson, G. Bavota, M. D. Penta, M. White, và
D. Poshyvanyk, "An empirical study on learning bug-fixing patches in
the wild via neural machine translation," ACM Transactions on Software
Engineering and Methodology (TOSEM), vol. 28, no. 4, pp. 1–29, 2019.
[55] Z. Li, D. Zou, S. Xu, X. Ou, H. Jin, S. Wang, Z. Deng, và Y. Zhong,
"Vuldeepecker: A deep learning-based system for vulnerability detection," arXiv preprint arXiv:1801.01681, 2018.
[56] D. Bahdanau, K. Cho, và Y. Bengio, "Neural machine translation by
jointly learning to align and translate," arXiv preprint arXiv:1409.0473,
2014.
[57] J. Wang và J. Zhu, "Portfolio theory of information retrieval," in Proceedings of the 32nd international ACM SIGIR conference on Research
and development in information retrieval, 2009, pp. 115–122.
[58] M. M. Palatucci, D. A. Pomerleau, G. E. Hinton, và T. Mitchell, "Zeroshot learning with semantic output codes," 2009.
[59] L. Van der Maaten và G. Hinton, "Visualizing data using t-sne." Journal
of machine learning research, vol. 9, no. 11, 2008.
[60] "K-means," https://scikit-learn.org/stable/modules/generated/sklearn.
cluster.KMeans.html.
[61] T. Chen, S. Kornblith, M. Norouzi, và G. Hinton, "A simple framework
for contrastive learning of visual representations," in International
conference on machine learning. PMLR, 2020, pp. 1597–1607.
[62] M. Kim, J. Tack, và S. J. Hwang, "Adversarial self-supervised contrastive learning," arXiv preprint arXiv:2006.07589, 2020.
[63] A. Radford, J. W. Kim, C. Hallacy, A. Ramesh, G. Goh, S. Agarwal,
G. Sastry, A. Askell, P. Mishkin, J. Clark et al., "Learning transferable visual models from natural language supervision," arXiv preprint
arXiv:2103.00020, 2021.
[64] B. Dai và D. Lin, "Contrastive learning for image captioning," arXiv
preprint arXiv:1710.02534, 2017.
[65] Z. Yang, Y. Cheng, Y. Liu, và M. Sun, "Reducing word omission errors
in neural machine translation: A contrastive learning approach," 2019.
[66] H. Fang, S. Wang, M. Zhou, J. Ding, và P. Xie, "Cert: Contrastive
self-supervised learning for language understanding," arXiv preprint
arXiv:2005.12766, 2020.
[67] T. Gao, X. Yao, và D. Chen, "Simcse: Simple contrastive learning of
sentence embeddings," arXiv preprint arXiv:2104.08821, 2021.
[68] D. Shen, M. Zheng, Y. Shen, Y. Qu, và W. Chen, "A simple but toughto-beat data augmentation approach for natural language understanding
and generation," arXiv preprint arXiv:2009.13818, 2020.
[69] Q. Chen, J. Lacomis, E. J. Schwartz, G. Neubig, B. Vasilescu, và
C. L. Goues, "Varclr: Variable semantic representation pre-training via
contrastive learning," arXiv preprint arXiv:2112.02650, 2021.
[70] S. Liu, Y. Li, và Y. Liu, "Commitbart: A large pre-trained model for
github commits," arXiv preprint arXiv:2208.08100, 2022.
[71] A. Radford, J. Wu, R. Child, D. Luan, D. Amodei, I. Sutskever et al.,
"Language models are unsupervised multitask learners," OpenAI blog,
vol. 1, no. 8, p. 9, 2019.
[72] S. Srikant, S. Liu, T. Mitrovska, S. Chang, Q. Fan, G. Zhang, và U.-M.
O'Reilly, "Generating adversarial computer programs using optimized
obfuscations," arXiv preprint arXiv:2103.11882, 2021.
[73] N. Yefet, U. Alon, và E. Yahav, "Adversarial examples for models of
code," Proceedings of the ACM on Programming Languages, vol. 4, no.
OOPSLA, pp. 1–30, 2020.
[74] G. Ramakrishnan, J. Henkel, Z. Wang, A. Albarghouthi, S. Jha, và
T. Reps, "Semantic robustness of models of source code," arXiv preprint
arXiv:2002.03043, 2020.
[75] P. Bielik và M. Vechev, "Adversarial robustness for code," in International Conference on Machine Learning. PMLR, 2020, pp. 896–907.
[76] H. Zhang, Z. Li, G. Li, L. Ma, Y. Liu, và Z. Jin, "Generating adversarial
examples for holding robustness of source code processing models," in
Proceedings of the AAAI Conference on Artificial Intelligence, vol. 34,
no. 01, 2020, pp. 1169–1176.

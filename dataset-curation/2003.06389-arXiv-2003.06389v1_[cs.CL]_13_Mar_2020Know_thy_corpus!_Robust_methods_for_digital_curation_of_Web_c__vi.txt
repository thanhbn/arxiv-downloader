# 2003.06389.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/dataset-curation/2003.06389.pdf
# Kích thước tệp: 145448 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
arXiv:2003.06389v1 [cs.CL] 13 Mar 2020Hiểu rõ kho ngữ liệu của bạn! Các phương pháp mạnh mẽ để quản lý số hóa các kho ngữ liệu Web
Serge Sharoff
Trung tâm Nghiên cứu Dịch thuật,
Đại học Leeds, LS2 9JT, Vương quốc Anh
s.sharoff@leeds.ac.uk
Tóm tắt
Bài báo này đề xuất một khung làm việc mới để quản lý số hóa các kho ngữ liệu Web nhằm cung cấp ước tính mạnh mẽ về các tham số của chúng,
như thành phần của chúng và từ vựng. Trong những năm gần đây, các mô hình ngôn ngữ được huấn luyện trước trên các kho ngữ liệu lớn đã nổi lên như những người chiến thắng rõ ràng
trong nhiều tác vụ NLP, nhưng chưa có phân tích phù hợp nào về các kho ngữ liệu đã dẫn đến thành công của chúng được tiến hành. Bài báo trình bày một
thủ tục để ước tính tần suất mạnh mẽ, giúp thiết lập từ vựng cốt lõi cho một kho ngữ liệu nhất định, cũng như một thủ tục để
ước tính thành phần kho ngữ liệu thông qua các mô hình chủ đề không giám sát và thông qua phân loại thể loại có giám sát của các trang Web. Kết quả
của nghiên cứu quản lý số hóa được áp dụng cho một số kho ngữ liệu có nguồn gốc từ Web cho thấy những khác biệt đáng kể của chúng. Trước tiên, điều này liên quan đến
các đợt bùng nổ tần suất khác nhau ảnh hưởng đến từ vựng cốt lõi thu được từ mỗi kho ngữ liệu. Thứ hai, điều này liên quan đến các loại văn bản mà chúng
chứa. Ví dụ, OpenWebText chứa nhiều tin tức chuyên đề và tranh luận chính trị hơn đáng kể so với ukWac hoặc
Wikipedia. Các công cụ và kết quả phân tích đã được phát hành.
Từ khóa: Xác thực tài nguyên ngôn ngữ, Phân tích văn bản, Mô hình hóa ngôn ngữ, Quản lý số hóa

1. Giới thiệu
Lượng dữ liệu văn bản khổng lồ có sẵn từ Web cung cấp một cửa sổ rất tốt để nhìn vào nhiều ngôn ngữ cùng một lúc (Sinclair, 1991), điều này cực kỳ hữu ích để phát triển các tài nguyên ngôn ngữ. Ví dụ, dữ liệu không được gán nhãn từ Web thường được sử dụng để huấn luyện trước các embedding cho các ứng dụng hạ nguồn tiếp theo. Nhiều mô hình ngôn ngữ được huấn luyện trước, như ELMO, BERT hoặc GPT, đã được tạo ra bằng cách sử dụng các tài nguyên Web, như 1B Word Benchmark cho ELMO, Wikipedia với Toronto Book Corpus cho BERT hoặc WebText cho GPT. Tuy nhiên, tác động của việc sử dụng một kho ngữ liệu có nguồn gốc từ Web cụ thể đến kết quả của việc huấn luyện trước không rõ ràng, vì các kho ngữ liệu thu được từ Web thiếu các danh mục được quản lý, trong khi đã biết rằng các yếu tố như lĩnh vực và chất lượng của tập huấn luyện là rất quan trọng đối với hiệu suất của mô hình. Quản lý số hóa các tài nguyên Web làm cho chúng tương tự về tinh thần với những gì đã được sử dụng trong các kho ngữ liệu truyền thống, như BNC, vì điều này cho phép ước tính các tác động của nó cũng như so sánh với các kho ngữ liệu Web khác.

Một vấn đề như vậy là thu được các ước tính đáng tin cậy về xác suất xuất hiện của các từ, n-gram và cấu trúc ngôn ngữ, vì số lượng tần suất thô dễ bị bùng nổ. Adam Kilgarriff đã gọi điều này là vấn đề "whelk" (Kilgarriff, 1997): nếu một văn bản về whelk, bất kể từ này hiếm khi xuất hiện như thế nào trong phần còn lại của kho ngữ liệu, nó có khả năng xuất hiện trong gần như mọi câu trong văn bản này. Nếu một kho ngữ liệu có thiên hướng nhỏ về các văn bản của một loại cụ thể, các từ liên quan đến chủ đề của nó có thể có tần suất thô cao một cách không hợp lý với chi phí của các từ khác có thể được coi là thuộc về từ vựng cốt lõi một cách hợp lý hơn.

Hai đoạn trích xuất chuỗi từ sau đây từ danh sách tần suất xếp hạng của kho ngữ liệu OpenWebText:¹

down 138, game, say, same, against, why, trump, news, since, day, off, own, government, between...

determined 2175, favor, license, prepared, wonderful, combined, stdclass, percentage, tree, entry, feed, vast

¹Ở đây và dưới đây, các chỉ số dưới biểu thị thứ hạng của từ tương ứng trong danh sách tần suất.

Tần suất của các từ có tính thời sự cao, như game, Trump, government, gần với những từ chức năng; tương tự stdclass không có khả năng thuộc về từ vựng cốt lõi. Điều này cho thấy rằng có những thiên hướng không rõ trong OpenWebText. Nhiều phương pháp Deep Learning cần giới hạn từ vựng của chúng bằng cách áp dụng các ngưỡng tần suất, vì các dự đoán neural cần chọn từ một số lượng tương đối nhỏ các tùy chọn, như 20-30,000 từ. Ngay cả các phương pháp hoạt động với các từ con, như BPE (Sennrich et al., 2016), cũng tạo ra một tỷ lệ đáng kể các mục từ đầy đủ. Ví dụ, trong số 22,702 mã BPE của mô hình BERT không phân biệt chữ hoa chữ thường, 20,079 mục là từ đầy đủ, được lấy từ danh sách tần suất của kho ngữ liệu huấn luyện tương ứng.

Một vấn đề quan trọng khác với các kho ngữ liệu có nguồn gốc từ Web liên quan đến việc thiếu thông tin đáng tin cậy về thành phần của chúng. Thông thường các kho ngữ liệu Web bao gồm hàng triệu trang Web được truy xuất do kết quả của việc thực hiện các truy vấn đến các công cụ tìm kiếm (Sharoff, 2006), thu thập từ danh sách hạt giống (Baroni et al., 2009) hoặc lấy các URL mà người dùng chia sẻ thông qua phương tiện truyền thông xã hội, như reddit hoặc Twitter (Radford et al., 2019). Thành phần của chúng có thể thay đổi vì thủ tục xây dựng chúng và vì pipeline xử lý chúng để thu được nội dung văn bản và loại bỏ các bản sao (Pomikálek et al., 2012), do đó các kết quả thu được từ việc huấn luyện trước trên cơ sở của chúng cần được xác thực.

Đóng góp chính của bài báo này bao gồm việc đề xuất các phương pháp để phân tích một kho ngữ liệu Web lớn với mục đích hiểu thành phần và thiên hướng của nó và để xác định từ vựng cốt lõi của nó bằng ước tính mạnh mẽ về các xác suất dự kiến. Cấu trúc của bài báo như sau:

• các phương pháp mạnh mẽ để phát hiện các đợt bùng nổ tần suất;
• ước tính thành phần chủ đề thông qua các mô hình chủ đề;
• ước tính thành phần thể loại thông qua phân loại có giám sát.

--- TRANG 2 ---
Kho ngữ liệu | Văn bản | Từ | Từ vựng | L10
OpenWebText | 8653K | 8706M | 31189K | 2425K
ukWac | 2542K | 1875M | 6286K | 832K
Wikipedia | 2524K | 1242M | 8168K | 1010K

Bảng 1: Các kho ngữ liệu được sử dụng trong thí nghiệm

2. Kho ngữ liệu
Nghiên cứu này trình bày các phương pháp để phân tích cấu trúc kho ngữ liệu dựa trên ba kho ngữ liệu Web thường được sử dụng để huấn luyện trước. OpenWebText là một bản sao công khai của kho ngữ liệu được sử dụng để huấn luyện GPT-2 (Radford et al., 2019), dựa trên việc trích xuất các trang Web từ tất cả các URL được bình chọn tích cực 3 lần trở lên trên trang web Reddit. OpenWebText (OWT) cũng là một trong những thành phần được sử dụng để huấn luyện trước Roberta (Liu et al., 2019) sử dụng pipeline có sẵn công khai.² Trái ngược với việc trích xuất các URL phổ biến, ukWac là một kho ngữ liệu được tạo ra bằng cách thu thập dữ liệu từ tên miền Internet .uk (Baroni et al., 2009). Wikipedia cũng thường được sử dụng để huấn luyện trước, đặc biệt trong các mô hình thường được sử dụng như BERT (Devlin et al., 2018) và fastText (Joulin et al., 2017). Kích thước của từ vựng cho mỗi kho ngữ liệu trong Bảng 1 được trình bày cho tất cả các token chính tả (loại trừ dấu câu và các token chỉ bao gồm số), cũng như từ vựng của các token xuất hiện 10 lần trở lên (L10).

Một khác biệt quan trọng khác giữa các kho ngữ liệu này là có nhiều người dùng tác giả bất kỳ văn bản nào trong Wikipedia, trong khi một tác giả duy nhất thường chịu trách nhiệm viết mỗi văn bản trong các kho ngữ liệu Web khác.

²https://github.com/jcpeterson/openwebtext

3. Ước tính phân phối tần suất
3.1. Ký hiệu
Nghiên cứu này sử dụng ký hiệu sau để mô tả phân phối tần suất:

ci số lần xuất hiện của một từ trong văn bản i
ni kích thước của văn bản i tính bằng token
C = Σci số lần xuất hiện tổng của một từ trong kho ngữ liệu
R = Σri số lượng mạnh mẽ trên tần suất mạnh mẽ theo văn bản, miễn dịch với các đợt bùng nổ tần suất (xem bên dưới)
N = Σni số lượng token trong kho ngữ liệu
T = |ni| số lượng văn bản trong kho ngữ liệu
pi = ci/ni xác suất của một từ trong văn bản i
µ = Σpi/T trung bình vĩ mô của xác suất theo văn bản

Tần suất được đếm trong ranh giới của các văn bản riêng lẻ, vì các văn bản thường được viết bởi một tác giả cụ thể trong một thể loại cụ thể về một chủ đề cụ thể, do đó chúng cung cấp các đơn vị phân tích tự nhiên để nghiên cứu các biến thể sử dụng từ. Có một số phức tạp thống kê được giới thiệu bằng cách tập trung vào toàn bộ văn bản so với việc chia các kho ngữ liệu thành các phần có kích thước bằng nhau, nhưng đây là hình thức phân tích ưa thích cho bài báo này, vì các văn bản cung cấp ranh giới tự nhiên giữa các chủ đề.

3.2. Ước tính tần suất mạnh mẽ
Tần suất của các hiện tượng ngôn ngữ, ví dụ, mức độ phổ biến của một từ hoặc cấu trúc tổng thể hoặc được dự kiến trong một văn bản mới, đã được các nhà nghiên cứu quan tâm ngay cả trước khi máy tính được phát minh. Vào đầu những năm 1900, Andrei Markov đã nghiên cứu tần suất của n-gram trong thơ (Hayes và others, 2013), từ điển tần suất thích hợp đầu tiên đã được tạo ra cho tiếng Đức vào cuối thế kỷ 19 (Kaeding, 1898), tiếp theo là vào giữa thế kỷ 20 bởi General Service List cho tiếng Anh (West, 1953) và các nghiên cứu tần suất trên Brown Corpus (Kučera và Francis, 1967).

Ngoài các ứng dụng giảng dạy ngôn ngữ và từ điển học, danh sách tần suất cần thiết để tạo ra các ước tính xác suất trong nhiều ứng dụng NLP, như Dịch máy, Truy xuất thông tin, Nhận dạng giọng nói, Phân loại văn bản. Rất nhiều sự chú ý trong mô hình hóa ngôn ngữ đã được dành để ước tính tần suất của các n-gram không nhìn thấy, trong khi vấn đề được giải quyết trong phần này liên quan đến các ước tính tần suất đáng tin cậy của các từ đã biết khi có các đợt bùng nổ tần suất.

Điều này có thể được thực hiện bằng cách giới thiệu các yếu tố của thống kê mạnh mẽ, hạn chế các đóng góp từ các quan sát ngoại lệ. Đã biết rằng các biện pháp tần suất truyền thống, như trung bình (một ước tính vị trí) và độ lệch chuẩn (một ước tính quy mô) không mạnh mẽ đối với các ngoại lệ: một đợt bùng nổ tần suất duy nhất có thể đẩy chúng ra khỏi giới hạn. Do đó, lĩnh vực thống kê mạnh mẽ đã giới thiệu một số ước tính mạnh mẽ (Rousseeuw và Croux, 1993).

Một ước tính mạnh mẽ thường được sử dụng về quy mô là Median Absolute Deviation (MAD):
MAD = b × median|xi - median(x)|

tức là, lấy trung vị của các khác biệt tuyệt đối từ trung vị của x. Rousseeuw & Croux đã giới thiệu một ước tính quy mô khác Sn với các đặc tính nhạy cảm lỗi tổng quát hấp dẫn hơn so với MAD:

Sn = c × median i(median j(|xi - xj|))

Đây là trung vị của các khác biệt từng cặp trong tần suất từ trên các văn bản. Các giá trị của các hằng số chuẩn hóa b = 1.48 cho MAD và c = 1.19 cho Sn được sử dụng để khớp với giá trị độ lệch chuẩn khi các biện pháp được áp dụng cho dữ liệu phân phối bình thường (Rousseeuw và Croux, 1993).

Đối với các ước tính mạnh mẽ về vị trí, biện pháp thường được sử dụng nhất là trung vị. Tuy nhiên, nó hoàn toàn bỏ qua sự biến thiên của các giá trị xung quanh mục trung vị, ví dụ, đối với các phân phối lệch, nó không phản ánh sự khác biệt giữa hai đuôi. Nghiên cứu trong thống kê mạnh mẽ đã đề xuất các biện pháp mạnh mẽ khác về vị trí, như M-estimator của Huber, dựa trên ý tưởng lấy các giá trị của các mục không phải ngoại lệ theo giá trị danh nghĩa và giảm hiệu ứng của các mục ngoài phạm vi được xác định trước (Wilcox, 2012). Thủ tục này là lặp lại: nó bắt đầu với µ₀ = Median và cập nhật µk+1 bằng cách giảm đóng góp của các mục thỏa mãn điều kiện:

|xi - µk| > K × MAD

--- TRANG 3 ---
Một vấn đề trong việc áp dụng trực tiếp các biện pháp mạnh mẽ cho danh sách tần suất từ bao gồm sự phổ biến của tần suất bằng không, ví dụ, chỉ có 73 từ xuất hiện trong hơn một nửa số tài liệu của OWT. Điều này dẫn đến các giá trị bằng không của median, MAD và huberM cho phân phối tần suất từ đối với đại đa số các từ. Cách xử lý vấn đề này là sử dụng các phương pháp mạnh mẽ để phát hiện các ngoại lệ trong các tài liệu có tần suất khác không và sử dụng trung bình truyền thống của các tần suất đã giảm (Winsorisation).

Cụ thể hơn, huberM và Sn được tính cho phân phối xác suất trên tất cả các tài liệu trong đó một từ xuất hiện. Sau đó, tần suất tự nhiên trong các tài liệu này được giới hạn như sau:

ri = min(ci, ni × (huberM(pi) + k × Sn(pi))

Các giá trị thường được sử dụng của các hằng số quy mô (K = 1.28 và k = 2.24) được suy ra từ các xem xét thống kê về các hàm ảnh hưởng (Huber, 2011). Chúng có thể được điều chỉnh để phản ánh bản chất của phân phối tần suất trong các kho ngữ liệu và hiệu ứng mong muốn, tức là chúng càng nhỏ thì hình phạt đối với các đợt bùng nổ tần suất càng cao.

Tổng các giá trị ri cho một ước tính về tần suất mạnh mẽ R cho một từ trong kho ngữ liệu, có thể được sử dụng để thiết lập từ vựng cốt lõi nhằm xác định các BPE ít bị ảnh hưởng bởi các đợt bùng nổ tần suất.

3.3. Kết quả ước tính từ vựng cốt lõi
Hiệu ứng của Winsorisation có thể được đo lường bằng cách sử dụng điểm log-likelihood (LL) (Rayson và Garside, 2000), tức là, bằng cách so sánh số lượng tần suất gốc với số lượng tần suất mạnh mẽ từ cùng một kho ngữ liệu như sau:

LL = R ln(R/E) + C ln(C/E); trong đó E = (C + R)/2

Các từ bị ảnh hưởng bởi các đợt bùng nổ tần suất trong ukWac được sắp xếp theo điểm LL của chúng là:

insurance, shall, sudoku, search, fire, waste, library, hotel, tax, wedding, credit, language, loan, cancer, mortgage, surfing, replies, hms, mulder, nigritude

Từ chuyên đề nigritude trong ukWac là dấu tích của một cuộc thi Tối ưu hóa Công cụ Tìm kiếm được tổ chức vào năm 2004, trong đó mục tiêu là thắng bằng cách có trang của thí sinh ở đầu kết quả tìm kiếm Google cho cụm từ vô nghĩa nigritude ultramarine. Nhiều trang này vẫn còn vào năm 2005 khi ukWac được thu thập, trong khi chúng không chứa văn bản có ý nghĩa và không nên đóng góp vào số lượng tần suất cho nigritude. Một số từ bị hạ thấp liên quan đến việc làm sạch không đủ các trang web khỏi văn bản boilerplate (ví dụ, search, language), một số liên quan đến quảng cáo thương mại (insurance, hotel), một số liên quan đến văn bản được trích xuất từ định dạng bảng (HMS, vì được lặp lại nhiều lần trong bảng cho các tàu khác nhau).

Không giống như các biện pháp hiệu chỉnh tần suất tổng thể như Juilland's D (Gries, 2008), Winsorisation chỉ giảm tần suất trong các tài liệu được chọn. Ví dụ, từ library được phân phối ít nhiều đồng đều trên nhiều văn bản ukWac. Tuy nhiên, khi các hướng dẫn lập trình đề cập đến các thư viện lập trình một cách lặp lại, điều này làm tăng tần suất của nó. Cuối cùng, ước tính mạnh mẽ giảm tần suất tổng thể của nó từ 375,084 xuống 277,385. Tương tự, ước tính tần suất của cancer bị ảnh hưởng bởi sự lặp lại của nó trong danh sách thư mục, trong đó nó xuất hiện trong các ngữ cảnh như Int J Cancer 1991;48:816-820.

Các từ bị ảnh hưởng bởi các đợt bùng nổ tần suất trong OWT theo điểm LL của chúng là:

trump, posted, china, google, tax, clinton, climate, oil, o, la, los, e, apple, iran, fixed, y, van, beer, e-mail, deprecated, drupal, stdclass

Điều này cho thấy sự lặp lại của chúng trong các chủ đề rất cụ thể, cũng như sự hiện diện của một số lượng nhỏ các trang web bằng tiếng Tây Ban Nha tuy nhiên đã thúc đẩy tần suất của o, la, e, y, v.v. vào top 1,000 từ trong số lượng thô của OWT. So với ukWac, danh sách thô OWT chứa ít đợt bùng nổ tần suất hơn cho các từ rõ ràng liên quan đến quảng cáo thương mại.

Từ vựng BERT chủ yếu bao gồm 20,000 từ thường xuyên nhất từ kho ngữ liệu Wikipedia (ngoài các đơn vị từ con). Việc xác thực nó thông qua ước tính tần suất mạnh mẽ phát hiện ra một loạt các yếu tố cấp từ, bị ảnh hưởng bởi các đợt bùng nổ tần suất:

pomeranian, montane, spurred, substrates, encompassed, italianate, prelate, attaining

Theo các ước tính tần suất mạnh mẽ, tất cả chúng đều nằm ngoài giới hạn 20,000 từ cho số lượng mạnh mẽ. Mặt khác, có 422 từ bị thiếu trong từ vựng BERT, vì chúng dưới ngưỡng 20,000 trong danh sách tần suất thô, nhưng trên ngưỡng này trong danh sách tần suất của số lượng mạnh mẽ, ví dụ:

appraisal, arisen, augment, bureaucratic, culmination, cultivate, divergent, numeric, overt, prosecute

Những từ này cũng không thể được biểu diễn bởi các mã BPE trong từ vựng BERT, ví dụ, các mã BPE duy nhất có sẵn trong BERT cho culminate là culminated và culminating. Ước tính tần suất mạnh mẽ cung cấp khả năng cải thiện phạm vi từ vựng của các mô hình huấn luyện trước.

4. Ước tính chủ đề
4.1. Mô hình hóa chủ đề
Tham số chính để đánh giá một kho ngữ liệu liên quan đến nội dung của nó đối với các chủ đề của nó. Tạo ra các mô hình chủ đề dựa trên Latent Dirichlet Allocation (LDA), ước tính phân phối xác suất của các từ khóa thuộc về các chủ đề khác nhau cũng như tỷ lệ của các tài liệu trên cùng một tập hợp các chủ đề. Đây là một thủ tục không giám sát, trong đó các phân phối không rõ được suy ra trong các xấp xỉ lặp lại từ phân phối của các biến ẩn (Blei et al., 2003). Đối với mỗi chủ đề βk (k = 1...K), nhiệm vụ là thu được phân phối xác suất của từ khóa trên các chủ đề:

nba players season steam ... xbox
β₁ 0.007 0.009 0.015 0.000 ... 0.000
β₂ 0.000 0.010 0.002 0.010 ... 0.011

Song song, mô hình cũng ước tính phân phối mức độ các tài liệu θd (d = 1...T) thuộc về các chủ đề:

θ₁: (0.783β₁, 0.002β₂, ... 0.122βK)
θ₂: (0.002β₁, 0.550β₂, ... 0.213βK)

--- TRANG 4 ---
OWT
8.60% police, court, officers, county, sexual, incident, charges, crime, children, prison, investigation, accused, charged, victim, assault
8.13% women, men, kids, girl, parents, book, mother, yes, remember, self, black, wasn, child, friend, shit, isn, feeling, knew, father
6.14% housing, trade, tariffs, council, companies, federal, billion, workers, minister, economic, tax, industry, trump, cent, union, percent
5.21% trump, mueller, clinton, fbi, russia, committee, investigation, comey, administration, counsel, border, obama, senate, election
4.52% season, players, nba, games, teams, league, ball, coach, draft, points, roster, win, played, playing, injury, sports, rookie, basketball
3.78% trump, israel, palestinian, election, war, democratic, vote, migrants, politics, anti, jerusalem, minister, speech, conservative
3.31% electric, battery, car, model, design, light, engine, display, air, water, launch, cars, features, speed, kerala, rear, vehicle, feet
3.01% technology, platform, companies, industry, product, learning, design, upgrade, automation, users, ideas, skills, react, google
2.45% music, album, song, band, artists, pop, rock, tour, vinyl, singer, fans, sound, usd, musical, guitar, track, art, studio, record
2.26% games, xbox, players, steam, cards, deck, card, player, damage, switch, dragon, character, spoiler, reload, console, magic

ukWac
10.01% music, band, album, songs, sound, love, rock, night, playing, live, guitar, jazz, radio, dance, tracks, sounds, password, pop, played
6.76% sector, investment, financial, companies, market, carers, industry, performance, strategy, standards, policy, corporate, organisation
5.15% conference, social, policy, approach, faculty, practice, knowledge, communication, understanding, groups, discussion, cultural
4.87% god, love, jesus, got, man, went, posted, father, feel, thing, thought, mother, tell, let, friends, mum, came, told, jewish, says, friend
4.54% students, learning, student, courses, teaching, skills, education, study, college, degree, academic, postgraduate, studies, modules
4.13% education, schools, funding, learning, charity, trust, social, voluntary, organisations, youth, partnership, skills, projects, fund
3.28% credit, loan, card, pay, loans, money, goods, vat, account, charges, property, terms, paid, costs, customer, charge, insurance
2.94% wales, cardiff, award, june, city, awards, john, event, director, conference, royal, bbc, north, west, theatre, tate, nokia
2.83% golf, facilities, village, fishing, enjoy, park, ski, restaurant, pool, town, holiday, tour, beautiful, sea, resort, beaches, restaurants
2.79% register, mail, fee, address, application, telephone, send, advice, fax, online, request, child, data, parents, enquiries, dfes

Wiki
8.82% album, song, chart, band, track, vocals, guitar, charts, label, listing, billboard, studio, records, singles, release, video, singer
7.33% league, cup, goals, club, tournament, championship, round, football, teams, rugby, match, draw, finals, division, professional
4.74% book, story, novel, plot, man, you, mother, said, how, woman, we, father, tells, find, love, characters, even, young, finds, himself
4.35% species, genus, mm, described, description, distribution, brown, marine, endemic, dark, leaves, habitat, grey, genera, plant, length
4.33% village, population, census, locality, municipality, workers, villages, km, town, rural, literacy, township, demographics, females
4.28% episode, episodes, television, show, festival, ep, tv, awards, documentary, production, films, award, cast, producer, premiered, role
3.87% building, historic, church, listed, places, buildings, brick, roof, street, style, story, tower, designed, windows, stone, architecture
3.82% football, coach, basketball, conference, ncaa, mf, tournament, head, df, schedule, games, record, fw, league, division, nfl
3.27% election, party, votes, assembly, candidate, democratic, council, minister, parliament, politician, legislative, seats, vote, results
3.00% law, court, trump, police, president, rights, act, minister, security, justice, legal, foreign, political, affairs, case, committee

Bảng 2: Các chủ đề lớn nhất cho các kho ngữ liệu Web

Thay vì phân cụm cứng, mô hình hóa chủ đề gán mỗi tài liệu vào một vector của các chủ đề. Một ước tính cho tỷ lệ tương đối của các chủ đề trong kho ngữ liệu có thể được cung cấp bằng cách tổng hợp các vector chủ đề trên tất cả các tài liệu. Sự tương đồng giữa các chủ đề trên các kho ngữ liệu có thể được đánh giá thông qua độ phân kỳ Jensen-Shannon (Fothergill et al., 2016) như sau:

DJS(β₁, β₂) = [DKL(β₁, B) + DKL(β₂, B)]/2

trong đó DKL(x, y) = Σxi ln(xi/yi) là độ phân kỳ Kullback-Leibler và B = (β₁ + β₂)/2.

Việc triển khai được sử dụng trong nghiên cứu này dựa trên mô hình Multicore LDA (Rehurek và Sojka, 2010) với số lượng chủ đề trong thí nghiệm cuối cùng được cố định là K = 100.

4.2. Kết quả mô hình hóa chủ đề
Bảng 2 liệt kê các chủ đề lớn nhất từ ba kho ngữ liệu, được mô tả bởi các từ khóa của chúng. Cho rằng việc phân bổ mềm của các chủ đề trong một vector chủ đề là một phân phối xác suất có thể được hiểu là mức độ một tài liệu thuộc về mỗi chủ đề, cột đầu tiên của bảng này cho thấy tỷ lệ tổng của tất cả các phép gán xác suất tài liệu cho mỗi chủ đề như một ước tính về sự hiện diện của nó trong kho ngữ liệu.

Có ba chủ đề lớn (âm nhạc, tài chính, thể thao) có mặt trong tất cả các kho ngữ liệu; thậm chí hai chủ đề thể thao nổi bật được phát hiện trong Wikipedia, một cho các môn thể thao Mỹ phổ biến hơn (bóng đá Mỹ và bóng rổ) và một cho bóng đá, bóng bầu dục, v.v. Trong khi chính trị có mặt như một chủ đề nổi bật trong tất cả các kho ngữ liệu, OWT rõ ràng nghiêng về tin tức hiện tại ở Mỹ bằng cách có ba loại tin tức chuyên đề nổi bật (Chủ đề 1, 4 và 6 theo thứ hạng nổi bật của chúng trong Bảng 2).

Các chủ đề liên quan đến giáo dục (Chủ đề 5 và 6) và dịch vụ chính phủ (Chủ đề 10) nổi bật hơn trong ukWac, một phần vì sự dễ dàng tương đối của việc thu thập các trang web giáo dục và chính phủ, ít khi dựa vào Javascript và có ít hạn chế anti-robot rõ ràng hơn. Một chủ đề khá lớn khác trong ukWac liên quan đến quảng cáo thương mại (Chủ đề 7), liên quan đến quá trình xây dựng nó thông qua thu thập rộng rãi, có nhiều khả năng bao gồm các trang thương mại hơn.

Các chủ đề liên quan đến mô tả tiểu thuyết/phim (Chủ đề 3), loài sinh học (Chủ đề 4) và địa điểm (Chủ đề 5 và 7) bao phủ một phần đáng kể các văn bản trong Wikipedia so với các kho ngữ liệu khác, liên quan đến chức năng phân phối kiến thức của nó.

Mặc dù kích thước lớn của các kho ngữ liệu, ước tính LDA có hiệu quả hợp lý: trên một nút cụm máy tính 24 lõi, mất ít hơn 10 giờ để chọn các từ khóa trong 9 tỷ từ của OWT và 18 giờ để phát hiện các chủ đề của nó.

--- TRANG 5 ---
OWT | ukWac | Wikipedia
42.01% argument | 19.30% argument | 91.33% information
14.91% personal | 11.78% personal | 4.64% review
4.96% news | 11.05% promotion | 1.13% news
3.36% instruction | 7.87% instruction | 0.88% argument
3.08% argument/personal | 7.85% news | 0.82% academic
2.75% review | 7.76% information | 0.61% info/review
1.96% promotion | 5.18% review | 0.42% info/news
1.85% academic | 3.88% academic | 0.30% instruction
0.87% information | 1.70% fiction | 0.12% info/instruction
0.85% legal | 0.87% legal | 0.12% info/academic

Bảng 3: Phân phối thể loại

5. Ước tính thể loại
5.1. Phân loại thể loại
Thể loại là một tham số quan trọng khác để ước tính sự biến thiên trong các văn bản, vì đã biết rằng sự không khớp về thể loại giữa tập huấn luyện của một mô hình và ứng dụng của nó vào một văn bản có tác động đáng kể đến các tác vụ như gắn thẻ từ loại hoặc Dịch máy (Santini et al., 2010). Không giống như sự biến thiên chủ đề, có thể được quan sát từ các từ khóa sử dụng phương pháp không giám sát, sự biến thiên không chủ đề trong thể loại được thể hiện thông qua các đặc trưng phong cách, khó giải thích hơn (Biber, 1995). Do đó, điều này đòi hỏi một phương pháp có giám sát để xác định các danh mục thể loại.

Nghiên cứu này sử dụng một lược đồ chú thích gọn gàng, đã được chứng minh là phù hợp để chú thích thể loại đáng tin cậy của một văn bản Web tùy ý (Sharoff, 2018), xem Bảng 3 cho danh sách các danh mục được sử dụng. Đã biết rằng phân loại thể loại tự động có thể bị thiên vị bởi các từ khóa cụ thể cho kho ngữ liệu huấn luyện (Petrenz và Webber, 2010). Do đó, bộ phân loại thể loại của chúng tôi sử dụng một đại diện hỗn hợp dựa trên việc giữ lại các dạng từ phổ biến nhất và thay thế các từ ít phổ biến hơn bằng các thẻ POS của chúng, xem (Baroni và Bernardini, 2006). Ví dụ, một văn bản hỗn hợp thể hiện các chức năng của đánh giá và quảng cáo:

(1) It won the SCBWI Golden Kite Award for best nonfiction book of 1999 and has sold about 50,000 copies.

chuyển đổi thành đại diện hỗn hợp như:

(2) It won the PROPN ADJ NOUN NOUN for best NOUN NOUN of [#] and has sold about [#] NOUN.

Mô hình Học máy cụ thể trong nghiên cứu này dựa trên bộ phân loại LSTM hai chiều (Yogatama et al., 2017) với cơ chế attention (Liu và Lane, 2016).

5.2. Kết quả phân loại thể loại
Bảng 3 trình bày phân phối thể loại được phát hiện trong ba kho ngữ liệu. Vì Wikipedia là ví dụ nguyên mẫu của tài liệu tham khảo cho mục đích thông tin, các văn bản của nó không được phân loại là thông tin là false negative hoặc các bài viết Wikipedia thể hiện một số đặc trưng của đánh giá điển hình³ hoặc báo cáo tin tức.⁴

OWT rõ ràng nghiêng về các văn bản tranh luận, cũng bao gồm các văn bản hỗn hợp như sự kết hợp của blog cá nhân với tranh luận, trong khi ukWac chứa nhiều văn bản quảng cáo hơn đáng kể. Sự khác biệt giữa các thể loại điển hình của OWT và ukWac có thể được giải thích bởi các phương pháp thu thập của chúng: các liên kết đến các trang Web được bình chọn tích cực ba lần trở lên trên reddit cho OWT và thu thập dữ liệu từ tên miền .uk cho ukWac. Cuối cùng, OWT chứa nhiều liên kết đến các diễn đàn thảo luận, cột ý kiến, blog chính trị và các văn bản tranh luận khác hơn. Đồng thời, ukWac chứa nhiều trang quảng cáo và mua sắm hơn đến từ một bản chụp ngẫu nhiên của việc thu thập dữ liệu. Vì OWT bao gồm các trang được bình chọn tích cực bởi nhiều người dùng nên ít có khả năng chứa các trang nhằm mục đích quảng cáo.

³https://en.wikipedia.org/wiki/1776_(musical)
⁴https://en.wikipedia.org/wiki/AbuNidalOrganization

6. Các nghiên cứu liên quan
Kenneth Church đã nghiên cứu tác động của các đợt bùng nổ tần suất đến xác suất của các từ bằng cách chia một văn bản thành hai phần ('lịch sử' và 'kiểm tra'). Ông chứng minh một xác suất lớn hơn nhiều để thấy một từ trong phần kiểm tra một khi nó xuất hiện trong phần lịch sử (Church, 2000). Cuối cùng, nếu xác suất thấy một từ chuyên đề trong một văn bản một lần là p(k = 1), thì xác suất thấy nó hai lần là p(k = 2) ≈ p/2 thay vì p² như mong đợi trong phân phối nhị thức. Cf. cũng một cuộc thảo luận sâu hơn của Harald Baayen trong Chương 5 của (Baayen, 2001).

Trong từ điển tần suất tiếng Tây Ban Nha của mình, Juilland đã giới thiệu một biện pháp phân tán tần suất từ, về cơ bản dựa trên sai số chuẩn của trung bình được chuẩn hóa bởi trung bình (Juilland, 1964):

D = 1 - σ/(µ√T-1)

Đề xuất này được theo sau bởi một số biện pháp khác nhằm xác định và giảm thiểu các đợt bùng nổ như vậy, ví dụ, các biện pháp của Carroll, Rosengren, Engvall, xem tổng quan trong (Gries, 2008). Do những bất cập của các biện pháp này, Gries cũng đã đề xuất biện pháp riêng của mình, Deviation of Proportions (DP), được định nghĩa là:⁵

DP = Σ|ci/C - ni/N|/2

Các biện pháp burstiness khác đã được đề xuất bởi Katz với mục đích sử dụng chúng trong nhận dạng giọng nói, truy xuất thông tin và phát hiện thuật ngữ (Katz, 1996):

p(k = 0) = p₀ xác suất không có lần xuất hiện nào của thuật ngữ trong một văn bản
p(k = 1) = p₁ xác suất của một lần xuất hiện duy nhất của thuật ngữ trong một văn bản  
p(k ≥ 2) = Σpr xác suất của nhiều lần xuất hiện của thuật ngữ trong một văn bản (r ≥ 2)
α = 1 - p₀ tỷ lệ các văn bản chứa thuật ngữ
γ = (1 - p₁)/(1 - p₀) tỷ lệ các văn bản 'chuyên đề' cho thuật ngữ
B = (Σrpr)/(Σpr) tham số burstiness chuyên đề

α cho thấy khả năng từ đó xuất hiện trong một văn bản bất kể số lần nó xuất hiện ở đó; γ cho thấy khả năng nó được sử dụng 'chuyên đề' (tức là nhiều hơn một lần trong một văn bản); và B cho thấy mức độ mạnh mẽ, trung bình, từ đó được sử dụng khi nó được sử dụng chuyên đề.

α thực sự là tỷ lệ các văn bản trong đó một từ xuất hiện, cũng giống như biện pháp của Engvall (Gries, 2008). Biện pháp này cũng liên kết trực tiếp với biện pháp IDF (Inverse Document Frequency). Theo số lượng này, wonderful trở nên phổ biến hơn stdclass. Tuy nhiên, việc áp dụng danh sách tần suất dựa trên phạm vi cũng bị hạn chế bởi thực tế rằng chúng không phân biệt bằng chứng đến từ văn bản ngắn và dài, do đó các giá trị của chúng có thể thay đổi mạnh mẽ giữa các kho ngữ liệu tương tự khác.

Mô hình hóa ngôn ngữ chú ý đến smoothing, tức là ước tính tần suất của các n-gram 'không nhìn thấy', trong khi tần suất của các n-gram quan sát được đo lường như hiện tại mà không sử dụng thông tin từ tần suất tài liệu, chỉ tần suất câu đôi khi được tính đến (Heafield et al., 2013). Do đó, LM không phân biệt giữa xác suất của stdclass mới so với wonderful moment, có tần suất thô tương tự (trong OWT) và các đặc tính burstiness rất khác nhau.

Một vấn đề khác liên quan đến tất cả các biện pháp này là chúng ta không có ước tính về số lượng đáng tin cậy có thể là gì: chúng ta có thể phát hiện việc thiếu một phân phối hoạt động tốt trên một số tài liệu, nhưng điều này không giúp phát hiện giá trị tần suất dự kiến. Một thực hành phổ biến trong các từ điển tần suất là nhân số lượng thô với một biện pháp phân tán (bởi Juilland's D trong các từ điển tần suất), nhưng điều này áp dụng một biện pháp hiệu chỉnh đồng nhất cho số lượng tổng thể, trong khi các đợt bùng nổ tần suất cụ thể cho từng văn bản.

Nghiên cứu tích cực trong việc so sánh thành phần kho ngữ liệu sử dụng từ khóa và từ thường xuyên nhất đã bắt đầu từ (Kilgarriff, 2001), tiếp theo là (Kilgarriff, 2012). Đã được chứng minh rằng việc sử dụng mô hình hóa chủ đề giúp tìm ra sự khác biệt giữa các kho ngữ liệu Web (Fothergill et al., 2016; Sharoff, 2013). Kể từ khi các phương pháp học máy xuất hiện vào những năm 1990, phân loại thể loại và các phương pháp liên quan đến phân loại văn bản đối với các đặc trưng phong cách của chúng đã phát triển từ (Karlgren và Cutting, 1994) đến (Pritsos và Stamatatos, 2018), xem tổng quan gần đây trong (Argamon, 2019). Tuy nhiên, các phương pháp phân loại thể loại chưa được áp dụng cho các kho ngữ liệu rất lớn từ Web.

⁵Điều này có thể được theo sau bởi chuẩn hóa để đảm bảo rằng giá trị của nó nằm trong [0,1]

7. Kết luận và công việc tiếp theo
Nghiên cứu đã khám phá những khác biệt đáng kể trong từ vựng và trong thành phần của OpenWebText, ukWac và Wikipedia, ba kho ngữ liệu Web lớn thường được sử dụng để huấn luyện trước các mô hình ngôn ngữ. Kích thước của kho ngữ liệu (tất cả chúng đều đo bằng tỷ từ) không phải là xem xét duy nhất cho việc sử dụng hiệu quả của nó trong huấn luyện trước. Từ vựng của nó và thành phần của nó về mặt chủ đề và các đặc tính phong cách có khả năng tác động đến việc sử dụng các mô hình được huấn luyện trước trong các tác vụ hạ nguồn. Ước tính từ vựng mạnh mẽ và mô hình hóa chủ đề dựa trên các phương pháp không giám sát, trong khi tác vụ ước tính thể loại dựa trên các phương pháp có giám sát (sử dụng bi-LSTM và attention). Cũng có sự khác biệt trong đại diện cơ bản, từ vựng so với các đặc trưng phong cách sử dụng thẻ POS cho bộ phân loại thể loại.

Khung phân tích dựa trên các tham số này cung cấp ba quan điểm để mô tả một kho ngữ liệu. Trong nghiên cứu ba kho ngữ liệu được báo cáo trong bài báo, tất cả chúng đều hội tụ về các mô tả nhất quán của mỗi kho ngữ liệu. Đầu tiên, kho ngữ liệu OpenWebText rất có tính thời sự, nó liên quan đến tình hình chính trị hiện tại, như ba chủ đề nổi bật liên quan đến Trump, vì bản chất thu thập từ các liên kết được bình chọn tích cực trên phương tiện truyền thông xã hội. Từ quan điểm thành phần thể loại, OpenWebText được phát hiện chứa tỷ lệ lớn hơn nhiều các văn bản tranh luận, như cột ý kiến hoặc blog tranh luận. Ngoài ra, OpenWebText nhấn mạnh khía cạnh nhận thức của việc sử dụng ngôn ngữ bằng cách thu thập các văn bản được chia sẻ rộng rãi, trong khi ukWac và Wikipedia chứa một bản chụp nhanh các văn bản có sẵn mà không tính đến quy mô khán giả của chúng. Điều này giới thiệu các thiên hướng khác trong từ vựng và thành phần của chúng, như các chủ đề nổi bật liên quan đến thực vật, động vật và địa điểm hiếm trong Wikipedia hoặc các văn bản từ các trang web giáo dục và chính phủ trong ukWac. Từ quan điểm thành phần thể loại, ukWac cũng được phát hiện chứa tỷ lệ lớn hơn các văn bản nhằm mục đích quảng cáo thương mại, điều này cũng được thể hiện thông qua các đợt bùng nổ tần suất và mô hình chủ đề.

Ngoài thông tin về các kho ngữ liệu cụ thể này, nghiên cứu này đóng góp một khung để phát hiện các thiên hướng như vậy nhằm đưa ra quyết định phù hợp trong việc sử dụng một kho ngữ liệu cụ thể để huấn luyện trước. Thủ tục được trình bày trong nghiên cứu này cung cấp cơ sở để đánh giá mức độ gần gũi của một kho ngữ liệu lớn với một lĩnh vực ứng dụng cụ thể để huấn luyện trước. Đánh giá từ kết quả thành phần kho ngữ liệu, cả Wikipedia (được sử dụng cho BERT) và OWT (được sử dụng cho GPT và Roberta) đều có những thiên hướng rất cụ thể, có lợi cho một số tác vụ nhất định, như kiến thức tổng quát rộng cho Wikipedia và xử lý văn bản tranh luận cho OWT. Đồng thời, một kho ngữ liệu được tạo ra bởi Thu thập Web (như ukWac, nhưng cũng Open Crawl) ít thiên hướng hơn, nhưng bị ảnh hưởng nhiều hơn bởi spam. Thủ tục đánh giá thành phần cũng cho phép lựa chọn các tập con phù hợp bao gồm các chủ đề và thể loại cụ thể, để việc huấn luyện trước có thể được thực hiện trên một kho ngữ liệu nhỏ hơn phù hợp hơn cho một tác vụ cụ thể. Khung phân loại được sử dụng trong nghiên cứu này có sẵn dưới giấy phép mang tính cho phép.⁶

Ngoài việc phát hiện thành phần kho ngữ liệu, nghiên cứu này đề xuất một phương pháp để xây dựng từ vựng cốt lõi cho một kho ngữ liệu, vượt qua các đợt bùng nổ tần suất tồi tệ nhất. Ước tính tần suất mạnh mẽ cung cấp khả năng cải thiện phạm vi từ vựng của các mô hình được huấn luyện trước. Một thông điệp quan trọng của nghiên cứu này là ước tính tần suất cho các từ đã biết không nên dựa vào số lượng thô. Không an toàn khi ước tính xác suất thấy một từ như p = C/N. Nếu không, dễ dàng suy ra rằng p(stdclass) = p(wonderful). Một cách tiếp cận tốt hơn là thu được danh sách tần suất mạnh mẽ hơn bằng cách giảm các đợt bùng nổ tần suất. Cơ chế được đề xuất dựa trên Winsorising tần suất thô trong các tài liệu sử dụng các giá trị huberM và Sn, nó hiệu quả trong việc phát hiện các đợt bùng nổ tần suất. Ví dụ, cơ chế này hạ thấp 422 đợt bùng nổ tần suất từ từ vựng chính của BERT, thay thế các từ như pomeranian hoặc montane bằng các từ được thúc đẩy như appraisal hoặc divergent. Các công cụ ước tính tần suất cũng hiệu quả về mặt tính toán so với các phương pháp bootstrap hoặc Monte Carlo. Khi tần suất cấp tài liệu cho các từ có sẵn, việc ước tính mất ít hơn 3 giờ cho bất kỳ kho ngữ liệu nào được báo cáo trong Bảng 1. Các công cụ ước tính tần suất có sẵn dưới giấy phép mang tính cho phép.⁷

⁶https://github.com/ssharoff/genre-keras
⁷https://github.com/ssharoff/robust

8. Lời cảm ơn
Công việc này được thực hiện trên ARC3, một phần của cơ sở Điện toán Hiệu suất Cao tại Đại học Leeds, Vương quốc Anh. Cơ sở lý luận đằng sau cuộc điều tra này đã được thảo luận với Adam Kilgarriff. Cũng cảm ơn các nhà phê bình ẩn danh. Như thường lệ, tôi chịu trách nhiệm về bất kỳ lỗi nào còn lại.

Tài liệu tham khảo
Argamon, S. (2019). Computational register analysis and synthesis. Register Studies, 1.
Baayen, R. H. (2001). Word Frequency Distributions. Kluwer Academic Publishers, Dordrecht.
Baroni, M. và Bernardini, S. (2006). A new approach to the study of translationese: Machine-learning the difference between original and translated text. Literary and Linguistic Computing, 21(3):259–274.
Baroni, M., Bernardini, S., Ferraresi, A., và Zanchetta, E. (2009). The WaCky wide web: a collection of very large linguistically processed web-crawled corpora. Language Resources and Evaluation, 43(3):209–226.
Biber, D. (1995). Dimensions of Register Variation: A Cross-Linguistic Comparison. Cambridge University Press.
Blei, D. M., Ng, A. Y., và Jordan, M. I. (2003). Latent Dirichlet allocation. Journal of Machine Learning Research, 3:993–1022.
Church, K. (2000). Empirical estimates of adaptation: the chance of two Noriegas is closer to p/2 than p2. In Proc COLING, pages 180–186, Saarbrücken, Germany.
Devlin, J., Chang, M.-W., Lee, K., và Toutanova, K. (2018). BERT: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805.
Fothergill, R., Cook, P., và Baldwin, T. (2016). Evaluating a topic modelling approach to measuring corpus similarity. In Proc LREC, pages 273–279, Portorož, Slovenia, May.
Gries, S. T. (2008). Dispersions and adjusted frequencies in corpora. International Journal of Corpus Linguistics, 13(4):403–437.
Hayes, B. et al. (2013). First links in the Markov chain. American Scientist, 101(2):92.
Heafield, K., Pouzyrevsky, I., Clark, J. H., và Koehn, P. (2013). Scalable modified Kneser-Ney language model estimation. In Proc 51st ACL, Sofia.
Huber, P. J. (2011). Robust statistics. Springer.
Joulin, A., Grave, E., Bojanowski, P., và Mikolov, T. (2017). Bag of tricks for efficient text classification. In Proc EACL, Valencia.
Juilland, A. (1964). Frequency dictionary of Spanish words. Mouton.
Kaeding, F. W. (1898). Häufigkeitswörterbuch der deutschen Sprache: Festgestellt durch einen Arbeitsausschuss der Deutschen Stenographiesysteme. Berlin.
Karlgren, J. và Cutting, D. (1994). Recognizing text genres with simple metrics using discriminant analysis. In COLING '94: Proc. of the 15th. International Conference on Computational Linguistics, pages 1071 – 1075, Kyoto, Japan.
Katz, S. M. (1996). Distribution of content words and phrases in text and language modelling. Natural Language Engineering, 2:15–59.
Kilgarriff, A. (1997). Putting frequencies in the dictionary. International Journal of Lexicography, 10(2):135–155.
Kilgarriff, A. (2001). Comparing corpora. International Journal of Corpus Linguistics, 6(1):1–37.
Kilgarriff, A. (2012). Getting to know your corpus. In Proceedings of Text, Speech and Dialogue.
Kučera, H. và Francis, W. N. (1967). Computational analysis of present-day American English. Brown University Press, Providence.
Liu, B. và Lane, I. (2016). Attention-based recurrent neural network models for joint intent detection and slot filling. arXiv preprint arXiv:1609.01454.
Liu, Y., Ott, M., Goyal, N., Du, J., Joshi, M., Chen, D., Levy, O., Lewis, M., Zettlemoyer, L., và Stoyanov, V. (2019). RoBERTa: A robustly optimized BERT pretraining approach. arXiv preprint arXiv:1907.11692.
Petrenz, P. và Webber, B. (2010). Stable classification of text genres. Computational Linguistics, 34(4):285–293.
Pomikálek, J., Jakubícek, M., và Rychlý, P. (2012). Building a 70 billion word corpus of English from ClueWeb. In LREC, pages 502–506.
Pritsos, D. và Stamatatos, E. (2018). Open set evaluation of web genre identification. Language Resources and Evaluation, 52(4):949–968.
Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., và Sutskever, I. (2019). Language models are unsupervised multitask learners. OpenAI Blog, 1(8).
Rayson, P. và Garside, R. (2000). Comparing corpora using frequency profiling. In Proc Comparing Corpora Workshop at ACL 2000, pages 1–6, Hong Kong.
Rehurek, R. và Sojka, P. (2010). Software framework for topic modelling with large corpora. In Proc Workshop on New Challenges for NLP Frameworks at LREC. Citeseer.
Rousseeuw, P. J. và Croux, C. (1993). Alternatives to the median absolute deviation. Journal of the American Statistical Association, 88(424):1273–1283.
Santini, M., Mehler, A., và Sharoff, S. (2010). Riding the rough waves of genre on the web. In Alexander Mehler, Serge Sharoff and Marina Santini (Eds.), Genres on the Web: Computational Models and Empirical Studies. Berlin/New York:Springer.
Sennrich, R., Haddow, B., và Birch, A. (2016). Neural machine translation of rare words with subword units. In Proc ACL, Berlin, Germany.
Sharoff, S. (2006). Open-source corpora: using the net to fish for linguistic data. International Journal of Corpus Linguistics, 11(4):435–462.
Sharoff, S. (2013). Measuring the distance between comparable corpora between languages. In Serge Sharoff, Reinhard Rapp, Pierre Zweigenbaum and Pascale Fung (Eds.), BUCC: Building and Using Comparable Corpora. Berlin/New York:Springer, pp. 113–129.
Sharoff, S. (2018). Functional text dimensions for the annotation of Web corpora. Corpora, 13(1):65–95.
Sinclair, J. (1991). Corpus, Concordance and Collocation. OUP, Oxford.
West, M. (1953). A General Service List of English Words. Longman, Green and Co., London.
Wilcox, R. R. (2012). Introduction to robust estimation and hypothesis testing. Academic Press.
Yogatama, D., Dyer, C., Ling, W., và Blunsom, P. (2017). Generative and discriminative text classification with recurrent neural networks. arXiv preprint arXiv:1703.01898.

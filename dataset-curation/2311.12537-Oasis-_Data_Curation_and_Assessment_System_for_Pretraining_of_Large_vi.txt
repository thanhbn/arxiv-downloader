# 2311.12537.pdf
# Đã chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/dataset-curation/2311.12537.pdf
# Kích thước tệp: 684098 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Oasis: Hệ thống Curation và Đánh giá Dữ liệu cho Pretraining của các Mô hình Ngôn ngữ Lớn
Tong Zhou1, Yubo Chen1,2, Pengfei Cao1,2, Kang Liu1,2, Jun Zhao1,2, Shengping Liu3
1Phòng thí nghiệm Nhận thức và Trí tuệ Ra quyết định cho Hệ thống Phức tạp
Viện Tự động hóa, Viện Hàn lâm Khoa học Trung Quốc
2Trường Trí tuệ Nhân tạo, Đại học Viện Hàn lâm Khoa học Trung Quốc
3Công ty Công nghệ Thông tin Unisound Bắc Kinh
tong.zhou@ia.ac.cn
{yubo.chen,pengfei.cao,kliu,jzhao}@nlpr.ia.ac.cn liushengping@unisound.com

Tóm tắt
Dữ liệu là một trong những yếu tố quan trọng nhất trong việc xây dựng mô hình ngôn ngữ lớn. Tuy nhiên, các hệ thống hiện tại hoặc thất bại trong việc tùy chỉnh pipeline curation corpus hoặc bỏ qua việc tận dụng đánh giá corpus toàn diện cho tối ưu hóa lặp lại của curation. Để giải quyết vấn đề này, chúng tôi trình bày một nền tảng curation và đánh giá corpus pretraining được gọi là Oasis1,2 - một hệ thống một cửa để cải thiện và định lượng chất lượng dữ liệu với giao diện tương tác thân thiện với người dùng. Cụ thể, module bộ lọc quy tắc modular tương tác có thể thiết kế các quy tắc tùy chỉnh theo phản hồi rõ ràng. Module bộ lọc neural không thiên vị xây dựng tập dữ liệu phân loại chất lượng theo cách tập trung vào negative để loại bỏ thiên vị không mong muốn. Module khử trùng tài liệu thích ứng có thể thực hiện khử trùng quy mô lớn với tài nguyên bộ nhớ hạn chế. Ba phần này tạo thành module curation dữ liệu tùy chỉnh. Và trong module đánh giá dữ liệu toàn diện, một corpus có thể được đánh giá ở góc nhìn cục bộ và toàn cục, với ba phương tiện đánh giá bao gồm con người, GPT-4 và các metrics heuristic. Chúng tôi trình bày một quy trình hoàn chỉnh để sử dụng Oasis cho curation và đánh giá dữ liệu pretraining. Ngoài ra, một corpus song ngữ 800GB được curation bởi Oasis được công bố công khai2.

1 Giới thiệu
Xây dựng các mô hình ngôn ngữ lớn (LLM) để thành thạo trong các tác vụ đa dạng đã được chú ý gần đây (OpenAI, 2023; Touvron et al., 2023; Anil et al., 2023). Sức mạnh của LLM chỉ xuất hiện khi kích thước tham số của chúng vượt quá một ngưỡng nhất định (Wei et al., 2022), thúc đẩy các mô hình phát triển về quy mô tham số. Các nghiên cứu gần đây (Kaplan et al., 2020; Rae et al., 2021; Rosset, 2020) đã chứng minh rằng các mô hình lớn hơn khao khát một corpus pretraining lớn, chất lượng cao và đa dạng. Tầm quan trọng của curation và đánh giá dữ liệu ngày càng trở nên rõ ràng.

Curation Dữ liệu: Một số công trình chi tiết các pipeline tiền xử lý cho các nguồn cụ thể như Common Crawl (Wenzek et al., 2019; Abadji et al., 2022; Penedo et al., 2023) hoặc Reddit (Gao et al., 2020). Tuy nhiên, các pipeline này không thể được áp dụng trực tiếp ở nơi khác vì các pipeline curation khác nhau nên được xây dựng cho các nguồn dữ liệu khác nhau bởi người nói bản ngữ của ngôn ngữ đích để đảm bảo kiểm soát chất lượng tốt hơn (Laurençon et al., 2022). Thật không may, một hệ thống mã nguồn mở cho curation dữ liệu pretraining tùy chỉnh vẫn vắng mặt trong cộng đồng.

Đánh giá Dữ liệu: Việc đánh giá corpus pretraining (Kreutzer et al., 2022; Dodge et al., 2021) hỗ trợ phát triển LLM theo cách lấy dữ liệu làm trung tâm (Fries et al., 2022) một cách hiệu quả hơn. Nó tránh tối ưu hóa curation dữ liệu bằng cách so sánh hiệu suất cuối cùng của mô hình sau khi training tốn tài nguyên. Mặc dù không có kết luận về việc định lượng giá trị của corpus, sự đồng thuận là các khía cạnh khác nhau của dữ liệu pretraining ảnh hưởng đến hiệu suất LLM, chẳng hạn như tính lưu loát, tính nhất quán, tính đa dạng và thiên vị (Longpre et al., 2023; Gunasekar et al., 2023). Tuy nhiên, vẫn thiếu một hệ thống đánh giá dữ liệu toàn diện cho việc cải thiện tiến bộ của pipeline curation dữ liệu.

Trong bài báo này, chúng tôi trình bày một hệ thống cho curation dữ liệu pretraining tùy chỉnh và đánh giá corpus toàn diện được gọi là Oasis. Chức năng của hệ thống này bao gồm ba loại bộ lọc được sử dụng để curation corpus chất lượng cao và hai góc nhìn để đánh giá toàn diện các corpus này.

Cụ thể, trong phần Curation Dữ liệu Tùy chỉnh, bước đầu tiên trong pipeline của chúng tôi là module Bộ lọc Quy tắc Modular Tương tác, cho phép người dùng xây dựng bộ quy tắc heuristic tùy chỉnh với tỷ lệ trúng và trường hợp xấu làm tham chiếu. Sau đó, chúng tôi khử thiên vị bộ lọc neural để ước tính chất lượng văn bản bằng cách chú ý đến quá trình xây dựng tập dữ liệu phân loại chất lượng cụ thể theo nguồn để training, tạo thành module Bộ lọc Neural Khử thiên vị. Cuối cùng, trong module Khử trùng Tài liệu Thích ứng, chúng tôi tối ưu hóa phương pháp khử trùng LSH được sử dụng rộng rãi trong yêu cầu bộ nhớ và trình bày hiệu ứng của các cấu hình khác nhau cho cài đặt tùy chỉnh. Trong phần Đánh giá Dữ liệu Toàn diện, chúng tôi cung cấp tùy chọn để kiểm tra corpus về tính lưu loát câu và tính nhất quán tài liệu bởi con người hoặc GPT-4 trong module Đánh giá Chất lượng Cục bộ. Các trường hợp được đánh giá với nhãn chất lượng có thể được sử dụng thêm để phát triển pipeline lọc. Ngoài ra, module Đánh giá Phân phối Toàn cục hiển thị thông tin phân phối của corpus về tính đa dạng và sự phong phú bằng nhiều metrics heuristic.

Ngoài việc giới thiệu Oasis, chúng tôi trình bày một trường hợp hoàn chỉnh sử dụng nền tảng này để xây dựng corpus Common Crawl chất lượng cao và đa dạng cao. Đồng thời, chúng tôi đánh giá toàn diện corpus trong các giai đoạn phát triển khác nhau. Các đánh giá cũng chứng minh hiệu quả của quy trình curation dữ liệu tùy chỉnh. Ngoài ra, chúng tôi công bố công khai corpus song ngữ Anh-Trung 800GB Oasis-Corpus được trồng trọt từ các trang web bởi Oasis để thúc đẩy phát triển LLM.

2 Công trình Liên quan
2.1 Canh tác Dữ liệu
Số lượng (Hoffmann et al., 2022) và chất lượng (Gunasekar et al., 2023) của corpus pretraining đảm bảo hiệu suất của LLM trong các tác vụ downstream. Các phương pháp canh tác dữ liệu tiên tiến có thể được phân loại thành bộ lọc quy tắc, bộ lọc neural và khử trùng.

Bộ lọc quy tắc: (Penedo et al., 2023; Laurençon et al., 2022; Abadji et al., 2022) coi độ tin cậy nhận dạng ngôn ngữ quá thấp là tiêu chí đầu tiên để loại bỏ tài liệu. Hơn nữa, một số quy tắc heuristic (Sun et al., 2021; Rae et al., 2021; Penedo et al., 2023) tập trung vào độ dài tài liệu, tỷ lệ dấu câu, độ dài từ và từ dừng, được sử dụng rộng rãi trong việc quyết định chất lượng tài liệu. (Laurençon et al., 2022) cũng xem xét tỷ lệ từ lớp đóng để phân biệt văn bản được tạo bằng máy. Các mô hình ngôn ngữ thống kê như Kenlm (Heafield, 2011) là công cụ hữu ích để ước tính hiệu quả tính nhất quán và tính lưu loát của câu (Wenzek et al., 2019; Laurençon et al., 2022; Wei et al., 2023). Trong việc loại bỏ thông tin không mong muốn, (Gu et al., 2023; Wu et al., 2021) xây dựng danh sách từ để khớp và loại bỏ tài liệu. (Rae et al., 2021; Wei et al., 2023) sử dụng danh sách chặn URL để loại bỏ các trang web đích. Trong khi các phương pháp này có thể dẫn đến thiên vị, (Penedo et al., 2023) tối ưu hóa danh sách chặn bằng cách cẩn thận tái trọng số các URL này. Tuy nhiên, quá trình xây dựng pipeline quy tắc trong corpus tùy chỉnh đa dạng thiếu sự chú ý.

Bộ lọc neural: Mặc dù bộ lọc neural tốn thời gian hơn bộ lọc quy tắc, nó có thể khám phá các mẫu giữa dữ liệu chất lượng cao và thấp mà không thể được kết luận theo nghĩa đen (Brown et al., 2020). Tập dữ liệu training sử dụng các nguồn chất lượng cao nổi tiếng như Wikipedia, WebText (Radford et al., 2019) và Books làm mẫu dương, trong khi các trang web đa dạng rộng rãi làm mẫu âm. Một mô hình neural như fastText hoặc BERT được huấn luyện trên tập dữ liệu này chịu trách nhiệm ghi điểm tài liệu về chất lượng (Touvron et al., 2023; Brown et al., 2020; Gao et al., 2020). (Wu et al., 2021) cũng xem xét việc sử dụng mô hình để phân loại quảng cáo. Tuy nhiên, bộ lọc neural có thể thiên vị corpus đã lọc do nguồn dương của tập huấn luyện (Dodge et al., 2021; Welbl et al., 2021). Một số công trình (Du et al., 2022; Wei et al., 2023) tổ chức mẫu dương trong hỗn hợp các nguồn khác nhau của văn bản chất lượng cao để giảm thiên vị từ nguồn dương. (Penedo et al., 2023) từ bỏ bộ lọc neural vì lo lắng về những thiên vị không mong muốn.

Khử trùng: Nội dung lặp lại trong corpus pretraining được chứng minh là gây hại cho khả năng tổng quát hóa của LLM (Lee et al., 2021). Các pipeline canh tác corpus tập trung vào khử trùng mờ ở cấp tài liệu (Zhang et al., 2022; Biderman et al., 2023; Rae et al., 2021) hoặc dòng (Touvron et al., 2023). Các quá trình khử trùng quy mô lớn này chủ yếu dựa trên thuật toán hash nhạy cảm cục bộ (Rajaraman và Ullman, 2011) bằng phương tiện va chạm để tính toán độ tương tự. (Sun et al., 2021) tính toán MD5 của ba câu dài nhất để khớp các tài liệu dư thừa. (Penedo et al., 2023) tiếp tục xây dựng một mảng tiền tố khổng lồ để loại bỏ các chuỗi con trùng lặp. Các phương pháp này cải thiện đáng kể hiệu quả của quá trình khử trùng, nhưng yêu cầu bộ nhớ trở thành rào cản cho triển khai ở quy mô lớn hơn.

2.2 Đánh giá Dữ liệu
Các nhà nghiên cứu không có sự đồng thuận về các phương pháp trong đánh giá corpus pretraining. (Gao et al., 2020) trực quan hóa các thành phần khác nhau của The Pile và sử dụng GPT-2 (Radford et al., 2019) và GPT-3 (Brown et al., 2020) để khám phá phân phối perplexity và tính đa dạng chủ đề. Họ cũng hiển thị phân phối điểm từ bộ lọc neural và kiểm tra các vấn đề bình đẳng. (Kreutzer et al., 2022) so sánh ngang nhiều corpus về tính đúng đắn ngôn ngữ bằng ghi nhãn con người. (Luccioni và Viviano, 2021) tập trung vào nội dung xúc phạm trong phạm vi chất lượng cao và thấp. (Dodge et al., 2021) khám phá phân phối chủ đề của các tài liệu được lọc bởi danh sách từ xấu và phát hiện các cụm vô hại như y học và tôn giáo. (Marone và Van Durme, 2023) đề xuất thuật toán hiệu quả hơn để đánh giá ô nhiễm dữ liệu trong các tác vụ downstream. (Laurençon et al., 2022) nhấn mạnh sự khác biệt giữa các ngôn ngữ khác nhau, bao gồm phân phối tần suất tỷ lệ lọc bằng các phương pháp khác nhau. (Piktus et al., 2023a,b) xây dựng công cụ để tìm kiếm chuỗi trong toàn bộ corpus một cách hiệu quả, cung cấp nền tảng cho khám phá đa dạng, như phát hiện thông tin nhận dạng cá nhân, kiểm tra nội dung không mong muốn và xác minh sự thật. Vẫn thiếu một hệ thống đánh giá dữ liệu toàn diện, đa chiều, dễ sử dụng.

3 Thiết kế Hệ thống và Thuật toán
Trong phần này, chúng tôi sẽ giới thiệu thiết kế hệ thống của Oasis và chi tiết các thuật toán nội bộ khác biệt so với các mô hình trước đây.

3.1 Curation Dữ liệu Tùy chỉnh
3.1.1 Bộ lọc Quy tắc Modular Tương tác
Xây dựng bộ lọc quy tắc cho corpus pretraining là một thói quen trong LLM tiên tiến. Bộ lọc quy tắc heuristic có thể lọc sơ bộ nội dung không mong muốn một cách hiệu quả. Các ý tưởng heuristic để xây dựng quy tắc bao gồm từ độ dài văn bản, dấu câu, token đặc biệt, danh sách chặn và perplexity mô hình ngôn ngữ. Tuy nhiên, không có bộ quy tắc nào luôn hợp lệ trên các nguồn dữ liệu và ngôn ngữ khác nhau. Corpus từ các nguồn khác nhau có thể khác nhau về chất lượng, phong cách, định dạng, mẫu và thông tin meta. Quy tắc lọc trong lĩnh vực sách có thể nhấn mạnh việc loại bỏ thông tin cấu trúc giữa nội dung chất lượng cao. Ngược lại, khi xử lý tài liệu từ web lớn, quy tắc sẽ chú ý hơn đến việc kiểm tra chất lượng nội dung. Các quá trình thiết yếu trong việc xây dựng và cải thiện quy tắc bao gồm việc kết luận thủ công các mẫu để phân biệt văn bản chất lượng cao và thấp và điều chỉnh một heuristic duy nhất bằng cách kiểm tra các mẫu trúng.

Chúng tôi thiết kế các chức năng trong module Bộ lọc Quy tắc Modular Tương tác theo các trực giác trên. Người dùng xây dựng pipeline quy tắc bằng cách chỉnh sửa và kết nối các ô quy tắc một cách tương tác, tham chiếu đến các mẫu heuristic tóm tắt từ các mẫu hiển thị ngẫu nhiên. Một ô quy tắc có thể được khởi tạo với heuristic được định nghĩa trước, và người dùng cũng có thể tùy chỉnh hàm heuristic và thêm nó vào pool được định nghĩa trước bằng cách gõ mã Python. Cấu hình của mỗi ô quy tắc, như ngưỡng và mẫu chuỗi, có thể được điều chỉnh tự do theo việc kiểm tra tỷ lệ trúng và trường hợp xấu. Sau khi xây dựng pipeline bộ lọc quy tắc tùy chỉnh, Oasis có thể tự động tạo script tương ứng theo cài đặt và chạy bộ lọc quy tắc ở chế độ nền.

3.1.2 Bộ lọc Mô hình Khử thiên vị
Ý định ban đầu của bộ lọc neural là chọn nội dung chất lượng cao từ các trang web lớn, tương tự như các nguồn chất lượng cao như Wikipedia. Mô hình có thể lọc ra nội dung với các mẫu không thể tóm tắt được về các khía cạnh chất lượng. Tuy nhiên, việc coi nguồn chất lượng cao nổi tiếng khác làm dương và nguồn hiện tại làm mẫu âm có thể khiến mô hình thiên vị về nguồn chất lượng cao, ảnh hưởng đến số lượng và tính đa dạng của dữ liệu được lọc. (Penedo et al., 2023) thậm chí từ bỏ quá trình này do lo ngại về tác động bất lợi của những thiên vị không mong muốn.

Để giải quyết vấn đề thiên vị, chúng tôi đề xuất phương pháp xây dựng tập dữ liệu tập trung vào negative để training bộ lọc neural. Phương pháp này thu thập phần lớn mẫu dương từ văn bản được lọc quy tắc trong nguồn hiện tại và lấy hầu hết mẫu âm thông qua ô nhiễm heuristic của mẫu dương. Quy tắc ô nhiễm văn bản được định nghĩa trước tập trung vào tính nhất quán và khả năng đọc, bao gồm xáo trộn, thay thế, chèn và xóa ở cấp từ, span và câu. Perplexity từ mô hình ngôn ngữ thống kê có thể phát hiện những nội dung chất lượng thấp không mong muốn này. Tuy nhiên, metric perplexity dễ bị ảnh hưởng bởi token đặc biệt tần suất thấp và thiên vị về corpus huấn luyện (thường là Wikipedia). Chúng tôi chỉ sử dụng perplexity để xác định nội dung chất lượng cực thấp, tạo thành một phần của mẫu âm. Các mẫu chất lượng này được mô hình hóa bằng bộ lọc neural với khả năng tổng quát hóa mạnh, chẳng hạn như BERT. BERT được tinh chỉnh dự đoán điểm cho chất lượng văn bản của mọi tài liệu được lọc quy tắc. Sau đó chúng tôi loại bỏ tài liệu theo điểm chất lượng dưới ngưỡng.

Module Bộ lọc Mô hình Khử thiên vị cung cấp bảng quản lý cho tập dữ liệu phân loại chất lượng. Người dùng có thể điều chỉnh thành phần của mẫu dương và âm, tùy chỉnh quy tắc ô nhiễm văn bản dựa trên phản hồi chỉnh sửa và đặt quantile perplexity để xác định nội dung chất lượng cực thấp thông qua kiểm tra trường hợp. Hơn nữa, tập dữ liệu cho training bộ phân loại neural có thể được tăng cường thêm bằng cách kết hợp văn bản được đánh giá từ con người hoặc GPT-4. Sau khi xây dựng tập dữ liệu phân loại chất lượng, Oasis có thể tạo script tương ứng thông qua cài đặt tham số trên giao diện và chạy ở chế độ nền chỉ với một cú nhấp chuột cho training bộ lọc neural và quy trình chạy.

3.1.3 Khử trùng Tài liệu Thích ứng
Các tài liệu lặp lại trong corpus pretraining sẽ gây hại cho khả năng tổng quát hóa của LLM trong các tác vụ downstream khác nhau. Khử trùng lớn giữa các tài liệu có độ phức tạp thời gian lý thuyết là O(n2). Thuật toán Locally Sensitive Hash gần đúng độ tương tự tài liệu và giảm độ phức tạp thời gian, nhưng nó đi kèm với chi phí tăng yêu cầu bộ nhớ để lưu trữ va chạm hash. Khử trùng mờ quy mô lớn trở nên không khả thi với tài nguyên hạn chế.

Pr(di, dj|Jaccard (di, dj) =s(i, j)) = 1−(1−sb_i,j)r (1)

Để đạt được mục tiêu này, chúng tôi giảm yêu cầu bộ nhớ của thuật toán khử trùng LSH để thích ứng với phần cứng tùy chỉnh bằng cách điều chỉnh r trong công thức xác suất có điều kiện. Hệ thống dự đoán r tối đa theo cấu hình của người dùng về kích thước corpus và kích thước bộ nhớ. Vì r nhỏ hơn sẽ dẫn đến xác suất va chạm thấp hơn, hệ thống cũng đề xuất thời gian chạy dựa trên ngưỡng Jaccard và recall trùng lặp mong đợi.

Mặc dù khử trùng cấp tài liệu có thể cải thiện tính đa dạng của tập dữ liệu được canh tác, nó cũng có thể giảm đáng kể số lượng. Module Khử trùng Tài liệu Thích ứng của chúng tôi cũng cung cấp giao diện để trực quan hóa các tài liệu trùng lặp trong biểu đồ, cung cấp tùy chọn cho người dùng để đánh đổi giữa tỷ lệ loại bỏ và số lượng.

3.2 Đánh giá Dữ liệu Toàn diện
Đánh giá LLM được pre-train trên các corpus được curation khác nhau bằng hiệu suất của các tác vụ downstream phục vụ như một oracle để đánh giá giá trị dữ liệu. Phương pháp hậu hoc này tốn tài nguyên và không hiệu quả. Cần thiết lập hệ thống đánh giá dữ liệu toàn diện để định lượng chất lượng dữ liệu và hỗ trợ quá trình tối ưu hóa curation dữ liệu. Chúng tôi đạt được mục tiêu này thông qua hai góc nhìn: chất lượng cục bộ và phân phối toàn cục, sử dụng ba phương pháp đánh giá: đánh giá con người, metrics heuristic và GPT-4.

3.2.1 Đánh giá Chất lượng Cục bộ
Trong module này, chúng tôi tập trung vào tính lưu loát, khả năng đọc và tính nhất quán của tài liệu được đánh giá bởi con người hoặc GPT-4. Do việc tiêu thụ cao của quá trình kiểm tra con người, chúng tôi chỉ cung cấp hai tùy chọn chất lượng, "Cao" và "Thấp," trong giao diện đánh giá con người thân thiện với người dùng. Nó hiển thị thống kê thời gian thực về các điều kiện chất lượng được ghi nhãn thủ công. Các LLM tiên tiến (SOTA) như GPT-4 đã chứng minh khả năng đủ để ghi điểm một tài liệu ở nhiều khía cạnh, phản ánh chất lượng tổng thể (Chen et al., 2023). Chúng tôi cung cấp prompt được định nghĩa trước cho đánh giá chất lượng, đạt được hơn 95% tính nhất quán với ý kiến con người. Hệ thống cũng hỗ trợ prompt tùy chỉnh cho các nhu cầu đa dạng. Hơn nữa, các mẫu đánh giá chất lượng cục bộ có thể được kết hợp vào tập dữ liệu phân loại chất lượng để phát triển bộ lọc neural.

3.2.2 Đánh giá Phân phối Toàn cục
Ngoài góc nhìn tài liệu cục bộ, góc nhìn toàn cục của corpus trong phân phối thống kê cũng có thể phản ánh chất lượng được định nghĩa rộng rãi.

Oasis áp dụng sáu metrics để đánh giá corpus trong heuristic từ một tập con dữ liệu được lấy mẫu ngẫu nhiên:
(1) Phân phối Đa dạng Từ vựng (McCarthy và Jarvis, 2010): Chúng tôi tính toán điểm Đo lường Đa dạng Từ vựng Văn bản (MTLD) của mỗi tài liệu để phản ánh tính đa dạng từ vựng và vẽ biểu đồ tần suất để có được góc nhìn tổng thể.

--- TRANG 2 ---
(2) Hệ số Đa dạng Task2Vec (Lee et al., 2023): Hệ số đa dạng task2vec được chứng minh có tương quan cao với tính đa dạng trực quan của con người về corpus. Chúng tôi lấy mẫu các batch văn bản và hiển thị điểm tổng thể được tính toán. (3) Phân phối Đa dạng Ngữ nghĩa: Chúng tôi thu được vector ngữ nghĩa toàn cục của tất cả tài liệu được lấy mẫu bằng BERT và tính toán độ tương tự cosine của từng cặp tài liệu để vẽ biểu đồ tần suất. (4) Phân phối Đa dạng Chủ đề: Chúng tôi phân cụm các tài liệu được lấy mẫu theo vector toàn cục và tính toán độ tương tự của vector trọng tâm giữa các cụm để phản ánh tính đa dạng chủ đề tổng thể. (5) Mật độ và Đa dạng Kiến thức: Chúng tôi kiểm tra góc nhìn kiến thức của corpus bằng cách đếm các thực thể khác nhau xuất hiện. Mật độ có nghĩa là số lượng thực thể được chuẩn hóa theo số lượng từ, và đa dạng có nghĩa là độ tương tự ngữ nghĩa của tất cả thực thể xuất hiện. (6) Phân phối Độ tương tự với Wikipedia: (Jansen et al., 2022) cho thấy rằng perplexity của mô hình Kenlm trên nguồn đích có thể phản ánh sự gần đúng của nguồn huấn luyện mô hình Kenlm. Chúng tôi huấn luyện mô hình Kenlm trên Wikipedia và vẽ phân phối perplexity để kiểm tra mức độ thiên vị corpus trong Wikipedia.

Những metrics này có thể được hiển thị trên một trang duy nhất và chồng chéo nhiều corpus để so sánh trực quan thuận tiện.

4 Ví dụ Sử dụng và Thí nghiệm
Trong phần này, chúng tôi cung cấp một ví dụ về cách tương tác với Oasis trong curation và đánh giá dữ liệu. Chúng tôi sử dụng dump mới nhất của Common Crawl (Tháng 5/Tháng 6 2023) làm minh họa, tập trung vào nội dung tiếng Anh.

4.1 Canh tác Dữ liệu Tùy chỉnh
Sau pipeline nhận dạng ngôn ngữ và trích xuất ngôn ngữ đích (Abadji et al., 2021) từ các tệp WET, chúng tôi có được tập dữ liệu tiếng Anh thô 2.4TB với thông tin meta.

Bộ lọc Quy tắc: Chọn tập dữ liệu thô trong module Bộ lọc Quy tắc Modular Tương tác và tải pipeline quy tắc được định nghĩa trước. Chúng tôi có thể quan sát tỷ lệ trúng cho mỗi ô quy tắc và một trường hợp trúng ngẫu nhiên sau khi nhấp vào ô quy tắc trong bảng "Xây dựng Pipeline". Dựa trên trường hợp hiển thị trong bảng "Nghiên cứu Trường hợp", một span quảng cáo không mong muốn được quan sát, chèn vào một câu nhất quán. Thêm một ô quy tắc bằng cách đặt đối số với span đích và nhấp vào nút "loại bỏ span" trong thanh bên trái. Di chuyển ô này lên trước ô "số lượng từ tối thiểu" cuối cùng. Sau khi lưu pipeline tùy chỉnh, bạn có thể tìm và tải pipeline này trong cấu hình của bảng "Chạy Pipeline" và tạo script Python có thể chạy để chạy đa xử lý ở chế độ nền. Sau khi áp dụng pipeline bộ lọc quy tắc này, chúng tôi có được 112GB dữ liệu.

Bộ lọc Neural: Trong bảng "Perplexity", chọn mô hình Kenlm được huấn luyện trên Wikipedia và tính toán perplexity để xác định phân chia quantile giữa chất lượng bình thường và nội dung chất lượng cực thấp. Kéo thanh trượt để thay đổi quantile, kiểm tra các trường hợp và cuối cùng quyết định 0.85 là ranh giới. Sau đó, điều chỉnh tập ô nhiễm trong bảng "Ô nhiễm", theo logic tương tự như xây dựng pipeline bộ lọc quy tắc. Trong phần "Recipe", quản lý cấu trúc của tập dữ liệu phân loại chất lượng, cả dương và âm, xây dựng tập dữ liệu và huấn luyện mô hình BERT được tinh chỉnh. Chọn checkpoint tốt nhất để chạy bộ lọc neural trong bảng "Chạy Neural". Cả quá trình huấn luyện và chạy đều xảy ra ở chế độ nền và không ảnh hưởng đến các thao tác khác. Sau khi áp dụng bộ lọc neural, 100GB dữ liệu chất lượng cao được thu được.

Khử trùng Tài liệu: Sử dụng biểu đồ cụm trùng lặp để trực quan hóa các cặp lặp lại với các ngưỡng Jaccard khác nhau trong bảng "Trường hợp Khử trùng". Sau vài lần thử, xác định ngưỡng Jaccard là 0.8. Trong bảng "Chạy Khử trùng", dựa trên kích thước corpus và bộ nhớ có sẵn, hệ thống tạo ra các khuyến nghị cho cài đặt tham số và có thể chạy khử trùng tài liệu, sử dụng nhiều lõi CPU ở chế độ nền. Quá trình khử trùng cuối cùng loại bỏ 5% tài liệu.

4.2 Đánh giá Dữ liệu Toàn diện
Kiểm tra Instance: Chúng tôi muốn so sánh chất lượng của corpus ở trạng thái thô, được lọc quy tắc và được lọc neural. Đầu tiên, chọn bốn corpus và kiểm tra thủ công mỗi corpus với 50 mẫu trong bảng "Đánh giá Con người". Đặt chất lượng mặc định là cao và chỉ nhấp "thấp" khi mẫu không đủ điều kiện cho training LLM. Thống kê chất lượng được hiển thị theo thời gian thực trong thanh bên. Sau đó, trong bảng "Đánh giá LLM", nhập khóa API cho OpenAI và đặt 200 mẫu cho mỗi corpus được đánh giá, xem xét chi phí. Sau khi nhận phản hồi cho tất cả các yêu cầu, kiểm tra điểm trung bình của GPT-4. Cuối cùng, chất lượng tài liệu cải thiện dần dần khi quá trình xây dựng tiến triển.

Metrics Heuristic: Trong bảng "Tính toán Heuristic", chọn tất cả metrics heuristic và chọn multi-corpus để tính toán. Sau khi thu được kết quả cho các metrics này, chọn các tệp để trực quan hóa trong bảng "Báo cáo". Các biểu đồ này chứng minh rằng pipeline lọc của chúng tôi mất một số đa dạng nhưng tăng đáng kể chất lượng. Phương pháp xây dựng tập dữ liệu tập trung vào negative của chúng tôi đưa ra ít thiên vị hơn so với các bộ lọc neural wiki-vs-cc trước đây, đạt được tính đa dạng từ vựng và chủ đề tốt hơn.

4.3 Phân tích So sánh
Như được thể hiện trong Bảng 1, chất lượng được đánh giá bởi con người của phần tiếng Trung trong Oasis Corpus được xây dựng bởi hệ thống Oasis vượt trội so với Wudao. Ngoài ra, nó thể hiện quy mô lớn hơn và đa dạng kiến thức lớn hơn, chứng minh lợi thế của Oasis, một hệ thống xây dựng và đánh giá toàn diện, so với các pipeline xây dựng dữ liệu truyền thống trong xây dựng dữ liệu pretraining. So với các corpus thu được bằng bộ lọc neural tập trung vào positive truyền thống, bộ lọc neural khử thiên vị có thể tạo ra chất lượng tương đương trong đánh giá con người và số lượng lớn hơn. Perplexity trong nguồn Wikipedia cũng chỉ ra rằng bộ lọc neural của chúng tôi có thể giảm thiểu thiên vị về các nguồn chất lượng cao trong corpus, đảm bảo tính đa dạng.

--- TRANG 3 ---
Hình 2: Ảnh chụp màn hình của giao diện quản lý recipe của Oasis.

--- TRANG 4 ---
Bảng 1: So sánh các metrics đánh giá cho các phương pháp xử lý khác nhau trên corpus tiếng Trung. Chúng tôi lấy WuDaoCorpus2.0 từ (Yuan et al., 2021). Oasis-Corpus-zh (với Bộ lọc Neural Wiki-vs-CC), có quy mô dữ liệu được ước tính dựa trên tỷ lệ lọc.

| Kích thước Corpus | Đánh giá Con người | Mật độ Kiến thức | PPL trong Wikipedia |
|-------------------|-------------------|------------------|---------------------|
| WuDaoCorpus2.0-200G | 193 GB | 75% | 7.11% | 875.41 |
| Oasis-Corpus-zh (với Bộ lọc Neural Khử thiên vị) | 370 GB | 90% | 7.20% | 922.97 |
| Oasis-Corpus-zh (với Bộ lọc Neural Wiki-vs-CC) | ∼50 GB | 90% | 7.99% | 192.27 |

--- TRANG 5 ---
5 Kết luận
Chúng tôi đề xuất Oasis, một hệ thống một cửa cho curation và đánh giá dữ liệu pretraining của LLM. Trong curation dữ liệu tùy chỉnh, người dùng có thể điều chỉnh pipeline của họ theo yêu cầu corpus cụ thể và tài nguyên phần cứng hạn chế trong bộ lọc quy tắc, bộ lọc neural và khử trùng tài liệu. Trong đánh giá dữ liệu toàn diện, một corpus có thể được đánh giá từ hai góc nhìn: tài liệu cục bộ và phân phối toàn cục; và theo ba cách: đánh giá con người, đánh giá GPT-4 và metrics heuristic. Hai thành phần này hợp tác để tăng cường giá trị của corpus pretraining LLM. Phân tích so sánh của các corpus được xây dựng chứng minh hiệu quả của Oasis.

6 Lời cảm ơn
Công trình này được hỗ trợ bởi Chương trình Nghiên cứu và Phát triển Trọng điểm Quốc gia của Trung Quốc (Số 2020AAA0106400), Quỹ Khoa học Tự nhiên Quốc gia Trung Quốc (Số 61976211, 62176257). Công trình này cũng được hỗ trợ bởi Chương trình Nghiên cứu Ưu tiên Chiến lược của Viện Hàn lâm Khoa học Trung Quốc (Số tài trợ XDA27020100), Hiệp hội Khuyến khích Đổi mới Thanh niên CAS, và Dự án Kế hoạch Đặc biệt Khoa học và Công nghệ Chính tỉnh Vân Nam (Số 202202AD080004)

Tài liệu tham khảo
Julien Abadji, Pedro Javier Ortiz Suárez, Laurent Romary, và Benoît Sagot. 2021. Ungoliant: Một pipeline được tối ưu hóa để tạo ra corpus web đa ngôn ngữ quy mô rất lớn. Trong CMLC 2021-9th Workshop on Challenges in the Management of Large Corpora.

Julien Abadji, Pedro Ortiz Suarez, Laurent Romary, và Benoît Sagot. 2022. Hướng tới một corpus crawled đa ngôn ngữ hướng tài liệu sạch hơn. arXiv preprint arXiv:2201.06642.

Rohan Anil, Andrew M Dai, Orhan Firat, Melvin Johnson, Dmitry Lepikhin, Alexandre Passos, Siamak Shakeri, Emanuel Taropa, Paige Bailey, Zhifeng Chen, et al. 2023. Báo cáo kỹ thuật Palm 2. arXiv preprint arXiv:2305.10403.

Stella Biderman, Hailey Schoelkopf, Quentin Gregory Anthony, Herbie Bradley, Kyle O'Brien, Eric Hallahan, Mohammad Aflah Khan, Shivanshu Purohit, USVSN Sai Prashanth, Edward Raff, et al. 2023. Pythia: Một bộ để phân tích các mô hình ngôn ngữ lớn qua training và scaling. Trong International Conference on Machine Learning, trang 2397–2430. PMLR.

Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. 2020. Các mô hình ngôn ngữ là học viên few-shot. Advances in neural information processing systems, 33:1877–1901.

Lichang Chen, Shiyang Li, Jun Yan, Hai Wang, Kalpa Gunaratna, Vikas Yadav, Zheng Tang, Vijay Srinivasan, Tianyi Zhou, Heng Huang, et al. 2023. Alpagasus: Huấn luyện một Alpaca tốt hơn với ít dữ liệu hơn. arXiv preprint arXiv:2307.08701.

Jesse Dodge, Maarten Sap, Ana Marasović, William Agnew, Gabriel Ilharco, Dirk Groeneveld, Margaret Mitchell, và Matt Gardner. 2021. Tài liệu hóa các corpus webtext lớn: Một nghiên cứu trường hợp về colossal clean crawled corpus. arXiv preprint arXiv:2104.08758.

Nan Du, Yanping Huang, Andrew M Dai, Simon Tong, Dmitry Lepikhin, Yuanzhong Xu, Maxim Krikun, Yanqi Zhou, Adams Wei Yu, Orhan Firat, et al. 2022. Glam: Scaling hiệu quả của các mô hình ngôn ngữ với mixture-of-experts. Trong International Conference on Machine Learning, trang 5547–5569. PMLR.

Jason Fries, Leon Weber, Natasha Seelam, Gabriel Altay, Debajyoti Datta, Samuele Garda, Sunny Kang, Rosaline Su, Wojciech Kusa, Samuel Cahyawijaya, et al. 2022. Bigbio: một framework cho xử lý ngôn ngữ tự nhiên y sinh lấy dữ liệu làm trung tâm. Advances in Neural Information Processing Systems, 35:25792–25806.

Leo Gao, Stella Biderman, Sid Black, Laurence Golding, Travis Hoppe, Charles Foster, Jason Phang, Horace He, Anish Thite, Noa Nabeshima, et al. 2020. The pile: Một tập dữ liệu 800gb văn bản đa dạng cho mô hình hóa ngôn ngữ. arXiv preprint arXiv:2101.00027.

Yuxian Gu, Jiaxin Wen, Hao Sun, Yi Song, Pei Ke, Chujie Zheng, Zheng Zhang, Jianzhu Yao, Lei Liu, Xiaoyan Zhu, et al. 2023. Eva2.0: Điều tra các hệ thống đối t화 domain mở tiếng Trung với pre-training quy mô lớn. Machine Intelligence Research, 20(2):207–219.

Suriya Gunasekar, Yi Zhang, Jyoti Aneja, Caio César Teodoro Mendes, Allie Del Giorno, Sivakanth Gopi, Mojan Javaheripi, Piero Kauffmann, Gustavo de Rosa, Olli Saarikivi, et al. 2023. Sách giáo khoa là tất cả những gì bạn cần. arXiv preprint arXiv:2306.11644.

Kenneth Heafield. 2011. Kenlm: Truy vấn mô hình ngôn ngữ nhanh hơn và nhỏ hơn. Trong Proceedings of the sixth workshop on statistical machine translation, trang 187–197.

Jordan Hoffmann, Sebastian Borgeaud, Arthur Mensch, Elena Buchatskaya, Trevor Cai, Eliza Rutherford, Diego de Las Casas, Lisa Anne Hendricks, Johannes Welbl, Aidan Clark, et al. 2022. Huấn luyện các mô hình ngôn ngữ lớn tối ưu compute. arXiv preprint arXiv:2203.15556.

Tim Jansen, Yangling Tong, Victoria Zevallos, và Pedro Ortiz Suarez. 2022. Bối rối bởi chất lượng: Một phương pháp dựa trên perplexity để phát hiện nội dung người lớn và có hại trong dữ liệu web đa ngôn ngữ không đồng nhất. arXiv preprint arXiv:2212.10440.

Jared Kaplan, Sam McCandlish, Tom Henighan, Tom B Brown, Benjamin Chess, Rewon Child, Scott Gray, Alec Radford, Jeffrey Wu, và Dario Amodei. 2020. Luật scaling cho các mô hình ngôn ngữ neural. arXiv preprint arXiv:2001.08361.

Julia Kreutzer, Isaac Caswell, Lisa Wang, Ahsan Wahab, Daan van Esch, Nasanbayar Ulzii-Orshikh, Allahsera Tapo, Nishant Subramani, Artem Sokolov, Claytone Sikasote, et al. 2022. Chất lượng trong nháy mắt: Một cuộc kiểm toán các tập dữ liệu đa ngôn ngữ được crawl web. Transactions of the Association for Computational Linguistics, 10:50–72.

--- TRANG 6 ---
Hugo Laurençon, Lucile Saulnier, Thomas Wang, Christopher Akiki, Albert Villanova del Moral, Teven Le Scao, Leandro Von Werra, Chenghao Mou, Eduardo González Ponferrada, Huu Nguyen, et al. 2022. Corpus roots bigscience: Một tập dữ liệu đa ngôn ngữ tổng hợp 1.6 tb. Advances in Neural Information Processing Systems, 35:31809–31826.

Alycia Lee, Brando Miranda, và Sanmi Koyejo. 2023. Vượt ra ngoài quy mô: hệ số đa dạng như một metric chất lượng dữ liệu chứng minh các LLM được pre-train trên dữ liệu đa dạng chính thức. arXiv preprint arXiv:2306.13840.

Katherine Lee, Daphne Ippolito, Andrew Nystrom, Chiyuan Zhang, Douglas Eck, Chris Callison-Burch, và Nicholas Carlini. 2021. Khử trùng dữ liệu huấn luyện làm cho các mô hình ngôn ngữ tốt hơn. arXiv preprint arXiv:2107.06499.

Shayne Longpre, Gregory Yauney, Emily Reif, Katherine Lee, Adam Roberts, Barret Zoph, Denny Zhou, Jason Wei, Kevin Robinson, David Mimno, et al. 2023. Hướng dẫn của người pre-train về dữ liệu huấn luyện: Đo lường tác động của tuổi dữ liệu, phạm vi domain, chất lượng & độc tính. arXiv preprint arXiv:2305.13169.

Alexandra Sasha Luccioni và Joseph D Viviano. 2021. Có gì trong hộp? một phân tích sơ bộ về nội dung không mong muốn trong corpus common crawl. arXiv preprint arXiv:2105.02732.

Marc Marone và Benjamin Van Durme. 2023. Chân dung dữ liệu: Ghi lại dữ liệu huấn luyện mô hình nền tảng. arXiv preprint arXiv:2303.03919.

Philip M McCarthy và Scott Jarvis. 2010. Mtld, vocd-d, và hd-d: Một nghiên cứu xác thực các phương pháp tinh vi để đánh giá đa dạng từ vựng. Behavior research methods, 42(2):381–392.

R OpenAI. 2023. Báo cáo kỹ thuật Gpt-4. arXiv, trang 2303–08774.

Guilherme Penedo, Quentin Malartic, Daniel Hesslow, Ruxandra Cojocaru, Alessandro Cappelli, Hamza Alobeidli, Baptiste Pannier, Ebtesam Almazrouei, và Julien Launay. 2023. Tập dữ liệu refinedweb cho falcon llm: vượt trội hơn các corpus được curation với dữ liệu web, và chỉ dữ liệu web. arXiv preprint arXiv:2306.01116.

Aleksandra Piktus, Christopher Akiki, Paulo Villegas, Hugo Laurençon, Gérard Dupont, Alexandra Sasha Luccioni, Yacine Jernite, và Anna Rogers. 2023a. Công cụ tìm kiếm roots: Tính minh bạch dữ liệu cho các llm. arXiv preprint arXiv:2302.14035.

Aleksandra Piktus, Odunayo Ogundepo, Christopher Akiki, Akintunde Oladipo, Xinyu Zhang, Hailey Schoelkopf, Stella Biderman, Martin Potthast, và Jimmy Lin. 2023b. Tìm kiếm gaia: Khả năng tương tác hugging face và pyserini để khám phá dữ liệu huấn luyện nlp. arXiv preprint arXiv:2306.01481.

Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al. 2019. Các mô hình ngôn ngữ là học viên đa nhiệm không giám sát. OpenAI blog, 1(8):9.

Jack W Rae, Sebastian Borgeaud, Trevor Cai, Katie Millican, Jordan Hoffmann, Francis Song, John Aslanides, Sarah Henderson, Roman Ring, Susannah Young, et al. 2021. Scaling các mô hình ngôn ngữ: Phương pháp, phân tích & hiểu biết từ việc huấn luyện gopher. arXiv preprint arXiv:2112.11446.

Anand Rajaraman và Jeffrey David Ullman. 2011. Khai thác các tập dữ liệu lớn. Cambridge University Press.

Corby Rosset. 2020. Turing-nlg: Một mô hình ngôn ngữ 17 tỷ tham số của microsoft. Microsoft Blog, 1(2).

Yu Sun, Shuohuan Wang, Shikun Feng, Siyu Ding, Chao Pang, Junyuan Shang, Jiaxiang Liu, Xuyi Chen, Yanbin Zhao, Yuxiang Lu, et al. 2021. Ernie 3.0: Pre-training tăng cường kiến thức quy mô lớn cho hiểu biết và tạo sinh ngôn ngữ. arXiv preprint arXiv:2107.02137.

Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, et al. 2023. Llama: Các mô hình ngôn ngữ nền tảng mở và hiệu quả. arXiv preprint arXiv:2302.13971.

Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, et al. 2022. Khả năng nổi lên của các mô hình ngôn ngữ lớn. arXiv preprint arXiv:2206.07682.

Xiangpeng Wei, Haoran Wei, Huan Lin, Tianhao Li, Pei Zhang, Xingzhang Ren, Mei Li, Yu Wan, Zhiwei Cao, Binbin Xie, et al. 2023. Polylm: Một mô hình ngôn ngữ lớn polyglot mã nguồn mở. arXiv preprint arXiv:2307.06018.

Johannes Welbl, Amelia Glaese, Jonathan Uesato, Sumanth Dathathri, John Mellor, Lisa Anne Hendricks, Kirsty Anderson, Pushmeet Kohli, Ben Coppin, và Po-Sen Huang. 2021. Thử thách trong việc khử độc các mô hình ngôn ngữ. arXiv preprint arXiv:2109.07445.

Guillaume Wenzek, Marie-Anne Lachaux, Alexis Conneau, Vishrav Chaudhary, Francisco Guzmán, Armand Joulin, và Edouard Grave. 2019. Ccnet: Trích xuất các tập dữ liệu đơn ngôn ngữ chất lượng cao từ dữ liệu crawl web. arXiv preprint arXiv:1911.00359.

Shaohua Wu, Xudong Zhao, Tong Yu, Rongguo Zhang, Chong Shen, Hongli Liu, Feng Li, Hong Zhu, Jiangang Luo, Liang Xu, et al. 2021. Yuan 1.0: Mô hình ngôn ngữ được pre-train quy mô lớn trong học tập zero-shot và few-shot. arXiv preprint arXiv:2110.04725.

--- TRANG 7 ---
Sha Yuan, Hanyu Zhao, Zhengxiao Du, Ming Ding, Xiao Liu, Yukuo Cen, Xu Zou, Zhilin Yang, và Jie Tang. 2021. Wudaocorpora: Một corpus siêu quy mô lớn tiếng Trung để pre-train các mô hình ngôn ngữ. AI Open, 2:65–68.

Susan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui Chen, Christopher Dewan, Mona Diab, Xian Li, Xi Victoria Lin, et al. 2022. Opt: Các mô hình ngôn ngữ transformer được pre-train mở. arXiv preprint arXiv:2205.01068.

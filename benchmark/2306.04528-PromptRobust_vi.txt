# 2306.04528.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/benchmark/2306.04528.pdf
# Kích thước tệp: 780406 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
PromptRobust
PromptRobust: Hướng Tới Việc Đánh Giá Tính Bền Vững của Các Mô Hình Ngôn Ngữ Lớn Trên Các Prompt Đối Kháng

Kaijie Zhu1,2∗, Jindong Wang1†, Jiaheng Zhou2, Zeek Wang1, Hao Chen3, Yidong Wang4,
Linyi Yang5, Wei Ye4, Neil Zhenqiang Gong6, Yue Zhang5, Xing Xie1
1Microsoft Research2Viện Tự động hóa, CAS3Đại học Carnegie Mellon
4Đại học Bắc Kinh5Đại học Westlake6Đại học Duke

Tóm tắt
Sự phụ thuộc ngày càng tăng vào các Mô hình Ngôn ngữ Lớn (LLMs) đòi hỏi sự hiểu biết toàn diện về tính bền vững của chúng đối với các prompt. Trong bài báo này, chúng tôi giới thiệu PromptRobust, một benchmark tính bền vững được thiết kế để đo lường khả năng chống chịu của LLMs đối với các prompt đối kháng. Nghiên cứu này sử dụng nhiều cuộc tấn công văn bản đối kháng trên các prompt ở nhiều cấp độ: ký tự, từ, câu và ngữ nghĩa. Các prompt đối kháng, được tạo ra để mô phỏng các lỗi hợp lý của người dùng như lỗi đánh máy hoặc từ đồng nghĩa, nhằm đánh giá cách những sai lệch nhỏ có thể ảnh hưởng đến kết quả của LLM trong khi vẫn duy trì tính toàn vẹn ngữ nghĩa. Những prompt này sau đó được sử dụng trong các nhiệm vụ khác nhau, bao gồm phân tích cảm xúc, suy luận ngôn ngữ tự nhiên, đọc hiểu, dịch máy và toán học. Chúng tôi tạo ra 4.788 prompt đối kháng và đánh giá trên 8 nhiệm vụ và 13 bộ dữ liệu. Phát hiện của chúng tôi cho thấy rằng các LLMs không bền vững đối với các prompt đối kháng. Hơn nữa, chúng tôi trình bày một phân tích toàn diện để hiểu bí ẩn đằng sau tính bền vững của prompt và khả năng chuyển giao của nó. Sau đó chúng tôi đưa ra phân tích sâu sắc và các khuyến nghị thực tế cho việc soạn thảo prompt, có lợi cho cả các nhà nghiên cứu và người dùng hàng ngày.

1 Giới thiệu
Trong vai trò là một giảng viên toán học,
tính toán câu trả lời cho 
bài toán sau liên quan đến:
Câu hỏi: Cho z(a) = -871*a 
+ 415. z(-16) có phải là một số
hợp số không? Trả lời:

Mẫu Prompt
Người dùng 1
Trả lời: Không.

Phân tích khẳng định này và xác định
xem nó là cảm xúc 'tích cực' hay 'tiêu cực':
nó chậm -- rất, rất chậm.

Mẫu Prompt
Trả lời: Tích cực.

Xin chào, tôi là trợ lý hữu ích. Tôi có thể giúp gì cho bạn?
Người dùng 2
(Đáp án đúng: Có)
(Đáp án đúng: Tiêu cực)

Hình 1: LLMs không bền vững đối với prompt: lỗi đánh máy và từ đồng nghĩa dẫn đến lỗi trong các bài toán và phân tích cảm xúc. Các ký tự và từ màu đỏ là nhiễu loạn.

Các mô hình ngôn ngữ lớn (LLMs) đã trở nên ngày càng phổ biến do hiệu suất chưa từng có của chúng trong các nhiệm vụ khác nhau như phân tích cảm xúc (Wang et al., 2019), trả lời câu hỏi (Wang et al., 2019), lý luận logic (Liu et al., 2023a), v.v. Một đầu vào cho LLM là sự nối tiếp của một prompt và (tùy chọn) một mẫu, trong đó prompt nhằm hướng dẫn LLM thực hiện nhiệm vụ gì và mẫu là dữ liệu cho nhiệm vụ đó.

Với việc áp dụng rộng rãi các LLMs, đặc biệt trong các lĩnh vực quan trọng về an toàn và ra quyết định, việc kiểm tra tính bền vững của LLMs đối với các nhiễu loạn trong đầu vào trở nên thiết yếu. Thực tế, các nghiên cứu hiện có (Wang et al., 2021; Nie et al., 2020; Wang et al., 2023b; Zhuo et al., 2023; Yang et al., 2023) đã cố gắng đánh giá tính bền vững của LLMs từ các góc độ khác nhau. Ví dụ, AdvGLUE (Wang et al., 2021) và ANLI (Nie et al., 2020) là hai bộ dữ liệu công khai để đánh giá tính bền vững của các mô hình ngôn ngữ đối với các mẫu đối kháng, là những mẫu được nhiễu loạn cẩn thận để làm cho mô hình ngôn ngữ tạo ra phản hồi không chính xác. Trong kỷ nguyên của các mô hình ngôn ngữ lớn, Wang et al. (2023b) đã đánh giá ChatGPT và các LLMs khác về tính bền vững của chúng đối với

∗Công việc được thực hiện trong thời gian thực tập tại Microsoft Research Asia.
†Tác giả liên hệ: Jindong Wang ¡jindong.wang@microsoft.com¿.

1arXiv:2306.04528v5 [cs.CL] 16 Jul 2024

--- TRANG 2 ---
PromptRobust

các mẫu đối kháng và các mẫu ngoài phân phối (OOD). Zhuo et al. (2023) đánh giá tính bền vững của LLMs cho một nhiệm vụ cụ thể gọi là phân tích cú pháp ngữ nghĩa.

Những nghiên cứu này đã chứng minh rằng các LLMs hiện tại không bền vững đối với các mẫu đối kháng và OOD cho một số nhiệm vụ xử lý ngôn ngữ tự nhiên phổ biến. Một prompt duy nhất thường được sử dụng để hướng dẫn LLM thực hiện một nhiệm vụ cho nhiều mẫu. Ví dụ, trong một bài toán (như trong Hình 1), một prompt có thể được sử dụng cho nhiều mẫu (tức là các bài toán). Do đó, một prompt bị nhiễu loạn có thể khiến LLM đưa ra phản hồi không chính xác cho nhiều mẫu sạch. Kết quả là, một prompt bị nhiễu loạn có thể nói là có tác động lớn hơn đến LLMs so với một mẫu đối kháng, vì mẫu sau chỉ ảnh hưởng đến phản hồi của LLM cho một mẫu duy nhất. Tuy nhiên, mặc dù có tầm quan trọng trung tâm, tính bền vững của LLMs đối với các nhiễu loạn prompt vẫn chưa được khám phá nhiều.

Trong bài báo này, chúng tôi nhằm mục đích thu hẹp khoảng cách bằng cách giới thiệu PromptRobust, một benchmark toàn diện được thiết kế để đánh giá tính bền vững của LLMs đối với các nhiễu loạn trong prompt, hiểu các yếu tố góp phần vào tính bền vững của chúng (hoặc thiếu tính bền vững), và xác định các thuộc tính chính của các prompt bền vững. Chúng tôi xem xét nhiều nhiễu loạn prompt khác nhau bao gồm 1) các lỗi đánh máy nhỏ, từ đồng nghĩa, và các cách biểu đạt câu khác nhau có cùng ý nghĩa ngữ nghĩa, có thể thường xảy ra với người dùng bình thường hoặc nhà phát triển trong việc sử dụng hàng ngày LLMs trong các tình huống không đối kháng, cũng như 2) các nhiễu loạn được tạo ra một cách chiến lược bởi kẻ tấn công trong các tình huống đối kháng. Với việc lạm dụng thuật ngữ một chút, chúng tôi gọi prompt bị nhiễu loạn như vậy trong cả hai tình huống là prompt đối kháng. Hình 1 cho thấy các ví dụ về prompt đối kháng với lỗi đánh máy và từ đồng nghĩa dẫn đến phản hồi không chính xác.

PromptRobust bao gồm các prompt, tấn công, mô hình, nhiệm vụ, bộ dữ liệu, và phân tích. Cụ thể, chúng tôi đánh giá 4 loại prompt: zero-shot (ZS), few-shot (FS), hướng vai trò, và hướng nhiệm vụ. Chúng tôi tạo ra 4 loại tấn công (gọi là tấn công prompt) để tạo các prompt đối kháng: tấn công cấp ký tự, cấp từ, cấp câu, và cấp ngữ nghĩa bằng cách mở rộng 7 cuộc tấn công đối kháng (Li et al., 2019; Gao et al., 2018; Li et al., 2020; Jin et al., 2019; Naik et al., 2018; Ribeiro et al., 2020) được thiết kế ban đầu để tạo ra các mẫu đối kháng. Chúng tôi lưu ý rằng, mặc dù chúng tôi gọi chúng là tấn công, các prompt đối kháng được tạo ra của chúng cũng phục vụ như các thử nghiệm để mô phỏng các prompt đa dạng tiềm năng với các nhiễu loạn xảy ra tự nhiên từ người dùng LLM thực tế. PromptRobust trải rộng trên 9 LLMs phổ biến, từ các mô hình nhỏ hơn như Flan-T5-large (Chung et al., 2022) đến các mô hình lớn hơn như ChatGPT (OpenAI, 2023a) và GPT-4 (OpenAI, 2023b). Hơn nữa, chúng tôi chọn 8 nhiệm vụ để đánh giá, cụ thể là phân tích cảm xúc (SST-2 (Socher et al., 2013)), tính đúng đắn ngữ pháp (CoLA (Warstadt et al., 2018)), phát hiện câu trùng lặp (QQP (Wang et al., 2017) và MRPC (Dolan & Brockett, 2005)), suy luận ngôn ngữ tự nhiên (MNLI (Williams et al., 2018), QNLI (Wang et al., 2019), RTE (Wang et al., 2019), và WNLI (Levesque et al., 2012)), kiến thức đa nhiệm vụ (MMLU (Hendrycks et al., 2021)), đọc hiểu (SQuAD V2 (Rajpurkar et al., 2018)), dịch thuật (UN Multi (Eisele & Chen, 2010) và IWSLT 2017 (Cettolo et al., 2017)), và giải toán (Mathematics (Saxton et al., 2019)). Tổng cộng, chúng tôi đã tạo ra 4.788 prompt đối kháng, đại diện cho các tình huống đa dạng, thực tế và thách thức.

Chúng tôi thực hiện các thí nghiệm và phân tích rộng rãi sử dụng PromptRobust. Kết quả làm nổi bật sự thiếu tính bền vững phổ biến đối với các prompt đối kháng trong các LLMs hiện tại, với các tấn công cấp từ chứng minh hiệu quả nhất (giảm hiệu suất trung bình 39% trong tất cả các nhiệm vụ). Chúng tôi đi sâu vào các lý do đằng sau lỗ hổng này bằng cách khám phá trọng số chú ý của LLMs đối với từng từ trong đầu vào cho các phản hồi sai lầm liên quan đến đầu vào sạch và đối kháng, trong đó đầu vào đối kháng là sự nối tiếp của một prompt đối kháng và một mẫu sạch. Phát hiện của chúng tôi tiết lộ rằng các prompt đối kháng khiến LLMs chuyển hướng tập trung của chúng về phía các yếu tố bị nhiễu loạn do đó tạo ra phản hồi sai. Chúng tôi cũng kiểm tra khả năng chuyển giao của các prompt đối kháng giữa các mô hình, và gợi ý khả năng chuyển giao thành công của các prompt đối kháng từ LLM này sang LLM khác. Hơn nữa, chúng tôi phân tích các mẫu tần suất từ để hướng dẫn nghiên cứu tương lai trong việc cải thiện tính bền vững và hỗ trợ người dùng cuối trong việc tạo ra các prompt bền vững hơn. Chúng tôi kết luận bằng việc thảo luận các chiến lược tiềm năng để cải thiện tính bền vững.

Tóm lại, đóng góp của chúng tôi như sau:
1. Chúng tôi giới thiệu PromptRobust, benchmark hệ thống đầu tiên để đánh giá, hiểu và phân tích tính bền vững của LLMs đối với các prompt đối kháng.

--- TRANG 3 ---
PromptRobust

2. Chúng tôi thực hiện đánh giá toàn diện về tính bền vững của LLMs đối với các prompt đối kháng và thực hiện phân tích rộng rãi, bao gồm giải thích trực quan cho các lỗ hổng quan sát được, phân tích khả năng chuyển giao của các prompt đối kháng, và phân tích tần suất từ để cung cấp hướng dẫn thực tế cho người dùng downstream và kỹ sư prompt để tạo ra các prompt bền vững hơn.

2 PromptRobust

2.1 Prompts và mô hình

Chúng tôi điều tra bốn loại prompt khác nhau. Prompt hướng nhiệm vụ mô tả rõ ràng nhiệm vụ mà mô hình được yêu cầu thực hiện, khuyến khích mô hình tạo ra đầu ra cụ thể cho nhiệm vụ dựa trên kiến thức được huấn luyện trước. Trong khi đó, prompt hướng vai trò thường đặt mô hình như một thực thể với vai trò cụ thể, chẳng hạn như một chuyên gia, cố vấn, hoặc người phiên dịch. Bằng cách kết hợp thông tin vai trò, những prompt này nhằm truyền đạt ngầm định dạng đầu ra và hành vi mong đợi. Mỗi trong hai danh mục prompt có thể được thiết kế cho cả tình huống học zero-shot (ZS) và few-shot (FS). Trong tình huống zero-shot, một đầu vào được định nghĩa là [P,x], trong đó P biểu thị một prompt, x là một mẫu, và [,] biểu thị phép nối tiếp. Đối với tình huống few-shot, một số ví dụ được thêm vào đầu vào, tạo ra định dạng [P,E,x], trong đó E đại diện cho các ví dụ. Ví dụ, E={[x1,y1],[x2,y2],[x3,y3]} đại diện cho ba ví dụ trong tình huống học ba shot. Trong các thí nghiệm của chúng tôi, chúng tôi chọn ngẫu nhiên ba ví dụ trong tập huấn luyện của một nhiệm vụ và nối chúng vào một prompt. Phụ lục A.1 cho thấy các ví dụ về các loại prompt khác nhau.

Đánh giá của chúng tôi bao gồm một tập hợp đa dạng các LLMs để đánh giá toàn diện hiệu suất của chúng trên các nhiệm vụ và lĩnh vực khác nhau. Các mô hình chúng tôi xem xét như sau: Flan-T5-large (Chung et al., 2022) (0.8B), Dolly-6B (Databricks, 2023), Vicuna-13B (Chiang et al., 2023), Llama2-13b-chat (Touvron et al., 2023b), Cerebras-GPT-13B (Dey et al., 2023), GPT-NEOX-20B (Black et al., 2022), Flan-UL2 (20B) (Brain, 2023), ChatGPT (OpenAI, 2023a), và GPT-4 (OpenAI, 2023b).¹ Bằng cách kết hợp các LLMs với các kiến trúc và kích thước khác nhau, chúng tôi nhằm cung cấp hiểu biết về điểm mạnh và điểm yếu của chúng, cuối cùng tạo điều kiện thuận lợi cho việc lựa chọn mô hình cho một ứng dụng hoặc trường hợp sử dụng cụ thể. Chi tiết về những LLMs này có trong Phụ lục B.1.

2.2 Tấn công

Cho một mẫu duy nhất x và nhãn y của nó, một cuộc tấn công đối kháng văn bản nhằm tìm một nhiễu loạn δ sao cho LLM fθ tạo ra phản hồi không chính xác. Chính thức, δ được tìm thấy bằng cách giải quyết bài toán tối ưu hóa sau: max δ∈C L[fθ(x+δ);y], trong đó x+δ là mẫu đối kháng, fθ(x+δ) là phản hồi của LLM khi chỉ nhận mẫu đối kháng làm đầu vào, C chỉ ra các ràng buộc cho nhiễu loạn δ, và L đại diện cho một hàm mất mát.

Tấn công prompt. Trong bài báo này, trọng tâm của chúng tôi là tấn công các prompt thay vì các mẫu. Điều này là do sự phổ biến của LLMs trong các ứng dụng khác nhau, tạo ra phản hồi sử dụng học trong ngữ cảnh trên các prompt (tức là hướng dẫn) và mẫu. Prompts được nhập bởi người dùng hoặc được tạo ra bởi hệ thống hoặc nhà phát triển. Hơn nữa, mục đích cuối cùng của việc thực hiện "tấn công" như vậy thực sự không phải để thực sự tấn công các mô hình, mà là để mô phỏng các nhiễu loạn có thể có thể xảy ra tự nhiên trong các tình huống thực tế. Bảng 8 cho thấy nhiều prompt được tạo ra bởi các phương pháp đối kháng được sử dụng để mô phỏng các prompt người dùng có thể có, là những lỗi hoặc biểu đạt phổ biến được thực hiện bởi người dùng. Vì người dùng có thể mắc các lỗi khác nhau khi nhập prompt, chẳng hạn như lỗi đánh máy, cách sử dụng từ khác nhau, phong cách câu khác nhau, v.v., nghiên cứu về tính bền vững của prompt là cần thiết để hiểu LLMs.

Chúng tôi ký hiệu một đầu vào cho LLMs là [P,x], trong đó P là một prompt, x là một mẫu, và [,] biểu thị nối tiếp. Lưu ý rằng trong tình huống học few-shot, một vài ví dụ được nối vào prompt; và mẫu x là tùy chọn trong một số tình huống ứng dụng. Tấn công prompt của chúng tôi cũng có thể được mở rộng cho những tình huống như vậy, nhưng chúng tôi sử dụng ký hiệu [P,x] để đơn giản.

Cho một bộ dữ liệu D={(xi,yi)}i∈[N] với N mẫu và nhãn ground-truth của chúng, một cuộc

¹ Chúng tôi không thực hiện tấn công prompt trên GPT-4 bằng cách tối ưu hóa các thuật toán đối kháng vì nó đòi hỏi nhiều vòng giao tiếp và quá tốn kém. Chúng tôi sử dụng các prompt đối kháng được tạo ra bởi ChatGPT để đánh giá GPT-4 vì các prompt đối kháng có thể được chuyển giao (Mục 4.4).

--- TRANG 4 ---
PromptRobust

tấn công prompt nhằm nhiễu loạn P sao cho LLM fθ tạo ra phản hồi không chính xác cho tất cả các mẫu trong bộ dữ liệu D.

Định nghĩa 2.1 (Tấn công Prompt). Cho một LLM fθ, một bộ dữ liệu D={(xi,yi)}i∈[N], và một prompt sạch P, mục tiêu của một cuộc tấn công prompt có thể được công thức hóa như sau:

max δ∈C ∑(x;y)∈D L[fθ([P+δ,x]),y], (1)

trong đó δ là nhiễu loạn văn bản được thêm vào prompt sạch P và C là tập nhiễu loạn cho phép, tức là ràng buộc nhiễu loạn. Chúng tôi lưu ý rằng cuộc tấn công này tương tự như nhiễu loạn đối kháng phổ quát (UAP) (Moosavi-Dezfooli et al., 2017; Brown et al., 2017) và kích hoạt đối kháng phổ quát (UAT) (Wallace et al., 2019), mở rộng những khái niệm này sang lĩnh vực prompt. Phụ lục A.4 cho thấy nhiều so sánh hơn.

Các tấn công khác nhau. Sau đó chúng tôi chỉnh sửa các cuộc tấn công văn bản black-box hiện có để thực hiện Eq. (1) do hiệu quả của chúng và không phụ thuộc vào gradient mô hình. Do đó, cả LLMs mã nguồn mở và độc quyền đều có thể là mục tiêu tấn công. Các thể hiện của chúng tôi trải rộng bốn cấp độ riêng biệt, nắm bắt một phổ rộng các độ phức tạp từ các thao tác ký tự đơn giản đến các thay đổi ngữ nghĩa tinh vi. Chi tiết của mỗi cuộc tấn công có trong Phụ lục A.3.

• Cấp ký tự: Chúng tôi sử dụng TextBugger (Li et al., 2019) và DeepWordBug (Gao et al., 2018), thao tác văn bản bằng cách đưa vào lỗi đánh máy hoặc lỗi cho các từ, ví dụ, bằng cách thêm, xóa, lặp lại, thay thế, và hoán vị ký tự cho một số từ.

• Cấp từ: Chúng tôi sử dụng BertAttack (Li et al., 2020) và TextFooler (Jin et al., 2019) để thay thế từ bằng từ đồng nghĩa hoặc từ tương tự về ngữ cảnh để đánh lừa LLMs.

• Cấp câu: Chúng tôi thực hiện StressTest (Naik et al., 2018) và CheckList (Ribeiro et al., 2020) để nối các câu không liên quan hoặc ngoại lai vào cuối prompt, nhằm làm xao lãng LLMs. Đối với StressTest, chúng tôi áp dụng các cài đặt tương tự như trong (Wang et al., 2019), nối " and true is true ", "and false is not true ", hoặc " and true is true " năm lần vào cuối một prompt. Đối với cuộc tấn công CheckList, chúng tôi tạo ra 50 chuỗi ngẫu nhiên bao gồm chữ cái và chữ số, mỗi chuỗi có độ dài 10, và nối chuỗi ngẫu nhiên này vào cuối một prompt.

• Cấp ngữ nghĩa: Chúng tôi mô phỏng hành vi ngôn ngữ của mọi người từ các quốc gia khác nhau bằng cách chọn 6 ngôn ngữ phổ biến (Trung Quốc, Pháp, Ả Rập, Tây Ban Nha, Nhật Bản, và Hàn Quốc) và xây dựng 10 prompt cho mỗi ngôn ngữ trên mỗi bộ dữ liệu. Những prompt này sau đó được dịch sang tiếng Anh, đưa vào các sắc thái và biến thể ngôn ngữ có thể ảnh hưởng đến LLMs.

Bảo tồn ngữ nghĩa của các prompt đối kháng.

Bảng 1: Thống kê các bộ dữ liệu được sử dụng trong bài báo này.
Nhiệm vụ | Bộ dữ liệu | #Mẫu | #Lớp | #[Prompt đối kháng, mẫu]
Phân tích cảm xúc | SST2 | 872 | 2 | 73,248
Tính đúng đắn ngữ pháp | CoLA | 1,000 | 2 | 84,000
Phát hiện câu trùng lặp | QQP | 1,000 | 2 | 84,000
 | MRPC | 408 | 2 | 34,272
Suy luận ngôn ngữ tự nhiên | MNLI | 1,000 | 3 | 84,000
 | QNLI | 1,000 | 2 | 84,000
 | RTE | 277 | 2 | 23,268
 | WNLI | 71 | 2 | 5,964
Kiến thức đa nhiệm vụ | MMLU | 564 | 4 | 47,376
Đọc hiểu | SQuAD V2 | 200 | - | 16,800
Dịch thuật | Multi UN | 99 | - | 8,316
 | IWSLT 2017 | 100 | - | 8,400
Lý luận toán học | Math | 160 | - | 13,440

Các prompt đối kháng có thực tế không? Mục đích của chúng tôi là mô phỏng các lỗi hợp lý của người dùng; do đó, điều bắt buộc là những prompt này bảo tồn tính toàn vẹn ngữ nghĩa, đảm bảo chúng vẫn có thể chấp nhận được và không thể phát hiện đối với hiểu biết của con người. Điều quan trọng tối cao là các prompt được thiết kế đối kháng của chúng tôi duy trì tính nhất quán và thực tế. Nghiên cứu con người của chúng tôi trong Phụ lục A.2 cho thấy ít nhất 85% đối tượng đồng ý rằng các prompt được tạo ra là có thể chấp nhận được.

2.3 Nhiệm vụ và bộ dữ liệu

Hiện tại, PromptRobust hỗ trợ 8 nhiệm vụ và 13 bộ dữ liệu từ phân tích cảm xúc đến lý luận toán học. Do hạn chế về không gian, chúng tôi để lại chi tiết của các bộ dữ liệu trong Phụ lục B.2.

3 Thí nghiệm

Thiết lập. Nhu cầu tính toán rộng rãi để tạo ra một prompt đối kháng đòi hỏi lặp đi lặp lại trong toàn bộ bộ dữ liệu trung bình 100 lần. Do đó, việc đánh giá toàn bộ

--- TRANG 5 ---
PromptRobust

Bảng 2: APDR và độ lệch chuẩn của các cuộc tấn công khác nhau trên các bộ dữ liệu khác nhau.

Bộ dữ liệu | Cấp ký tự | Cấp từ | Cấp câu | Cấp ngữ nghĩa
---|---|---|---|---
 | TextBugger | DeepWordBug | TextFooler | BertAttack | CheckList | StressTest | Semantic
SST-2 | 0.25 ±0.39 | 0.18±0.33 | 0.35±0.41 | 0.34±0.44 | 0.22±0.36 | 0.15±0.31 | 0.28±0.35
CoLA | 0.39 ±0.40 | 0.27±0.32 | 0.43±0.35 | 0.45±0.38 | 0.23±0.30 | 0.18±0.25 | 0.34±0.37
QQP | 0.30 ±0.38 | 0.22±0.31 | 0.31±0.36 | 0.33±0.38 | 0.18±0.30 | 0.06±0.26 | 0.40±0.39
MRPC | 0.37 ±0.42 | 0.34±0.41 | 0.37±0.41 | 0.42±0.38 | 0.24±0.37 | 0.25±0.33 | 0.39±0.39
MNLI | 0.32 ±0.40 | 0.18±0.29 | 0.32±0.39 | 0.34±0.36 | 0.14±0.24 | 0.10±0.25 | 0.22±0.24
QNLI | 0.38 ±0.39 | 0.40±0.35 | 0.50±0.39 | 0.52±0.38 | 0.25±0.39 | 0.23±0.33 | 0.40±0.35
RTE | 0.33 ±0.41 | 0.25±0.35 | 0.37±0.44 | 0.40±0.42 | 0.18±0.32 | 0.17±0.24 | 0.42±0.40
WNLI | 0.39 ±0.42 | 0.31±0.37 | 0.41±0.43 | 0.41±0.40 | 0.24±0.32 | 0.20±0.27 | 0.49±0.39
MMLU | 0.21 ±0.24 | 0.12±0.16 | 0.21±0.20 | 0.40±0.30 | 0.13±0.18 | 0.03±0.15 | 0.20±0.19
SQuAD V2 | 0.09 ±0.17 | 0.05±0.08 | 0.25±0.29 | 0.31±0.32 | 0.02±0.03 | 0.02±0.04 | 0.08±0.09
IWSLT | 0.08 ±0.14 | 0.10±0.12 | 0.27±0.30 | 0.12±0.18 | 0.10±0.10 | 0.17±0.19 | 0.18±0.14
UN Multi | 0.06 ±0.08 | 0.08±0.12 | 0.15±0.19 | 0.10±0.16 | 0.06±0.07 | 0.09±0.11 | 0.15±0.18
Math | 0.18 ±0.17 | 0.14±0.13 | 0.49±0.36 | 0.42±0.32 | 0.15±0.11 | 0.13±0.08 | 0.23±0.13
Trung bình | 0.21 ±0.30 | 0.17±0.26 | 0.31±0.33 | 0.33±0.34 | 0.12±0.23 | 0.11±0.23 | 0.22±0.26

Bảng 3: APDR trên các LLMs khác nhau.

Bộ dữ liệu | T5-large | Vicuna | Llama2 | UL2 | ChatGPT | GPT-4
---|---|---|---|---|---|---
SST-2 | 0.04 ±0.11 | 0.83±0.26 | 0.24±0.33 | 0.03±0.12 | 0.17±0.29 | 0.24±0.38
CoLA | 0.16 ±0.19 | 0.81±0.22 | 0.38±0.32 | 0.13±0.20 | 0.21±0.31 | 0.13±0.23
QQP | 0.09 ±0.15 | 0.51±0.41 | 0.59±0.33 | 0.02±0.04 | 0.16±0.30 | 0.16±0.38
MRPC | 0.17 ±0.26 | 0.52±0.40 | 0.84±0.27 | 0.06±0.10 | 0.22±0.29 | 0.04±0.06
MNLI | 0.08 ±0.13 | 0.67±0.38 | 0.32±0.32 | 0.06±0.12 | 0.13±0.18 | -0.03 ±0.02
QNLI | 0.33 ±0.25 | 0.87±0.19 | 0.51±0.39 | 0.05±0.11 | 0.25±0.31 | 0.05±0.23
RTE | 0.08 ±0.13 | 0.78±0.23 | 0.68±0.39 | 0.02±0.04 | 0.09±0.13 | 0.03±0.05
WNLI | 0.13 ±0.14 | 0.78±0.27 | 0.73±0.37 | 0.04±0.03 | 0.14±0.12 | 0.04±0.04
MMLU | 0.11 ±0.18 | 0.41±0.24 | 0.28±0.24 | 0.05±0.11 | 0.14±0.18 | 0.04±0.04
SQuAD V2 | 0.05 ±0.12 | - | - | 0.10 ±0.18 | 0.22±0.28 | 0.27±0.31
IWSLT | 0.14 ±0.17 | - | - | 0.15 ±0.11 | 0.17±0.26 | 0.07±0.14
UN Multi | 0.13 ±0.14 | - | - | 0.05 ±0.05 | 0.12±0.18 | -0.02 ±0.01
Math | 0.24 ±0.21 | - | - | 0.21 ±0.21 | 0.33±0.31 | 0.02±0.18
Trung bình | 0.13 ±0.19 | 0.69±0.34 | 0.51±0.39 | 0.08±0.14 | 0.18±0.26 | 0.08±0.21

Bảng 4: APDR trên các prompt khác nhau.

Bộ dữ liệu | ZS-task | ZS-role | FS-task | FS-role
---|---|---|---|---
SST-2 | 0.31 ±0.39 | 0.28±0.35 | 0.22±0.38 | 0.24±0.39
CoLA | 0.43 ±0.35 | 0.43±0.38 | 0.24±0.28 | 0.25±0.36
QQP | 0.43 ±0.42 | 0.34±0.43 | 0.16±0.21 | 0.14±0.20
MRPC | 0.44 ±0.44 | 0.51±0.43 | 0.24±0.32 | 0.23±0.30
MNLI | 0.29 ±0.35 | 0.26±0.33 | 0.19±0.29 | 0.21±0.33
QNLI | 0.46 ±0.39 | 0.51±0.40 | 0.30±0.34 | 0.32±0.36
RTE | 0.33 ±0.39 | 0.35±0.40 | 0.31±0.39 | 0.27±0.38
WNLI | 0.36 ±0.36 | 0.39±0.39 | 0.37±0.41 | 0.33±0.38
MMLU | 0.25 ±0.23 | 0.22±0.26 | 0.18±0.23 | 0.14±0.20
SQuAD V2 | 0.16 ±0.26 | 0.20±0.28 | 0.06±0.11 | 0.07±0.12
IWSLT | 0.18 ±0.22 | 0.24±0.25 | 0.08±0.09 | 0.11±0.10
UN Multi | 0.17 ±0.18 | 0.15±0.16 | 0.04±0.07 | 0.04±0.07
Math | 0.33 ±0.26 | 0.39±0.30 | 0.16±0.18 | 0.17±0.17
Trung bình | 0.33 ±0.36 | 0.34±0.37 | 0.21±0.31 | 0.21±0.31

bộ dữ liệu sử dụng LLMs là không khả thi. Để giảm nhẹ ràng buộc tính toán và bảo tồn quá trình nghiên cứu công bằng, chúng tôi áp dụng chiến lược lấy mẫu bao gồm việc chọn một tập con mẫu từ các tập kiểm tra hoặc kiểm tra trên các bộ dữ liệu khác nhau. Thống kê của mỗi bộ dữ liệu và nhiệm vụ được tóm tắt trong Bảng 1.² Chi tiết lấy mẫu có trong Phụ lục C.

Ban đầu chúng tôi đánh giá hiệu suất của tất cả LLMs mà không có tấn công prompt để cung cấp đường cơ sở hiệu suất. Chúng tôi thấy rằng một số LLMs thậm chí không thể hiện hiệu suất thỏa đáng với các prompt sạch, thu hẹp lựa chọn của chúng tôi xuống 6 LLMs: Flan-T5-large, Vicuna-13B, Llama2-13B-chat, UL2, ChatGPT, và GPT-4. Chi tiết và thảo luận thêm về hiệu suất prompt sạch trong tất cả LLMs có sẵn trong Phụ lục C.2. Chúng tôi tạo ra 10 prompt riêng biệt cho cả danh mục hướng vai trò và hướng nhiệm vụ. Mỗi prompt có thể được tăng cường với ba ví dụ, tạo thành các prompt few-shot. Tổng cộng, chúng tôi có 40 prompt cho mỗi bộ dữ liệu trên mỗi LLM. Để có hiệu suất và hiệu quả tốt hơn, chúng tôi chọn top 3 prompt hoạt động tốt nhất của mỗi loại để thực hiện tấn công prompt. Kết quả là, chúng tôi đánh giá các lỗ hổng đối kháng của 9 LLMs trên 13 bộ dữ liệu, bao gồm tổng cộng 4.788 prompt³ và các đối tác đối kháng tương ứng của chúng. Đánh giá toàn diện này cho phép chúng tôi thu được hiểu biết có giá trị về tính bền vững và hiệu suất của LLMs trong một loạt các tình huống và phong cách prompt.

Chỉ số đánh giá. Xem xét các chỉ số đánh giá đa dạng trên các nhiệm vụ và hiệu suất cơ sở khác nhau trên các mô hình và bộ dữ liệu, việc giảm hiệu suất tuyệt đối có thể không cung cấp so sánh có ý nghĩa. Do đó, chúng tôi giới thiệu một chỉ số thống nhất, Tỷ lệ Giảm Hiệu suất (PDR). PDR định lượng sự suy giảm hiệu suất tương đối sau một cuộc tấn công prompt, cung cấp một thước đo được chuẩn hóa theo ngữ cảnh để so sánh các cuộc tấn công, bộ dữ liệu và mô hình khác nhau. PDR được cho bởi: PDR(A,P,fθ,D) = 1 - ∑(x;y)∈D M[fθ([A(P),x]),y] / ∑(x;y)∈D M[fθ([P,x]),y], trong đó A là cuộc tấn công đối kháng được áp dụng cho prompt P, và M[·] là hàm đánh giá: đối với nhiệm vụ phân loại, M[·] là hàm chỉ thị 1[ŷ,y] bằng 1 khi ŷ=y, và 0 trong trường hợp ngược lại; đối với nhiệm vụ đọc hiểu, M[·] là điểm F1; đối với các nhiệm vụ dịch thuật, M[·] là chỉ số Bleu (Papineni et al., 2002). Lưu ý rằng PDR âm có nghĩa là các prompt đối kháng có thể nâng cao hiệu suất.

4 Kết quả và phân tích

4.1 Kết quả trên các cuộc tấn công, mô hình và prompt

Chúng tôi báo cáo và thảo luận APDR Trung bình (APDR) trên các cuộc tấn công, LLMs và prompt khác nhau. Kết quả chính của chúng tôi dựa trên tất cả các prompt, có kết luận nhất quán với Phụ lục C.4 nơi chúng tôi hiển thị kết quả bằng cách loại trừ các prompt đối kháng không thể chấp nhận được. Lưu ý rằng mặc dù nghiên cứu bảo tồn ngữ nghĩa của chúng tôi chứng minh rằng ít nhất 85% prompt đối kháng là có thể chấp nhận được, vẫn có một số prompt đối kháng lệch khỏi ý nghĩa ngữ nghĩa dự định của chúng. Hơn nữa, lưu ý rằng sự khác biệt trong các giá trị phương sai APDR là do các giá trị PDR khác nhau trên các cuộc tấn công, prompt, mô hình và bộ dữ liệu khác nhau.

Phân tích về các cuộc tấn công. Bảng 2 tóm tắt APDR của 7 cuộc tấn công trên 13 bộ dữ liệu, được tính bởi APDR_A(A,D) = 1/|P| 1/|F| ∑P∈P ∑fθ∈F PDR(A,P,fθ,D), trong đó P là tập hợp của 4 loại prompt và F là tập hợp của tất cả mô hình. Kết quả cung cấp một số hiểu biết chính. Đầu tiên, hiệu quả tấn công rất biến đổi, với các cuộc tấn công cấp từ chứng minh mạnh mẽ nhất, dẫn đến sự suy giảm hiệu suất trung bình 33% trên tất cả bộ dữ liệu. Các cuộc tấn công cấp ký tự xếp thứ hai, gây ra sự giảm hiệu suất 20% trong hầu hết các bộ dữ liệu. Đáng chú ý, các cuộc tấn công cấp ngữ nghĩa thể hiện tính hiệu quả gần như tương đương với các cuộc tấn công cấp ký tự, nhấn mạnh tác động sâu sắc của các biến thể ngôn ngữ tinh tế đối với hiệu suất của LLMs. Ngược lại, các cuộc tấn công cấp câu đặt ra ít mối đe dọa hơn, gợi ý rằng các can thiệp đối kháng ở cấp độ này có tác động giảm đi. Hơn nữa, tác động của tấn công prompt thay đổi trên các bộ dữ liệu khác nhau. Ví dụ, các cuộc tấn công StressTest trên SQUAD V2 chỉ dẫn đến giảm hiệu suất 2%, trong khi gây ra giảm 25% trên MRPC. Hơn nữa, chúng tôi quan sát thấy rằng cuộc tấn công StressTest một cách nghịch lý làm tăng hiệu suất của mô hình trong một số bộ dữ liệu, chúng tôi đi sâu vào hiện tượng này trong Phụ lục D.3.

Lưu ý rằng trong khi các cuộc tấn công cấp ký tự có thể phát hiện được bằng các công cụ phát hiện ngữ pháp, các cuộc tấn công cấp từ và ngữ nghĩa nhấn mạnh tầm quan trọng của việc hiểu ngữ nghĩa mạnh mẽ và trình bày/dịch thuật nhiệm vụ chính xác cho LLMs. Hiểu biết toàn diện về những sắc thái này sẽ thông báo cho sự hiểu biết sâu sắc hơn về các cuộc tấn công đối kháng trên LLMs.

Phân tích về LLMs. Bảng 3 tóm tắt APDR của 9 LLMs trên 13 bộ dữ liệu, được tính bởi APDR_fθ(fθ,D) = 1/|A| 1/|P| ∑A∈A ∑P∈P PDR(A,P,fθ,D), trong đó P là tập hợp của 4 loại prompt và A là tập hợp của 7 cuộc tấn công. Phân tích của chúng tôi tiết lộ rằng GPT-4 và UL2 vượt trội đáng kể so với các mô hình khác về tính bền vững, theo sau là T5-large, ChatGPT, và Llama2, với Vicuna thể hiện tính bền vững ít nhất. Tính bền vững chống lại các prompt đối kháng của UL2, T5-large, và ChatGPT thay đổi trên các bộ dữ liệu, với UL2 và T5-large cho thấy ít lỗ hổng hơn đối với các cuộc tấn công trên phân loại cảm xúc (SST-2), hầu hết các nhiệm vụ NLI, và đọc hiểu (SQuAD V2). Cụ thể, UL2 xuất sắc trong các nhiệm vụ dịch thuật, trong khi ChatGPT thể hiện tính bền vững trong một số nhiệm vụ NLI. Tuy nhiên, Vicuna thể hiện tính dễ bị tổn thương cao một cách nhất quán đối với các cuộc tấn công trên tất cả các nhiệm vụ. Có thể thấy rằng, với cùng các prompt đối kháng được tạo ra bởi ChatGPT, GPT-4 thể hiện tính bền vững vượt trội trong tất cả các nhiệm vụ. Tuy nhiên, điều quan trọng là nhận ra rằng tính bền vững quan sát được này có thể do khả năng chuyển giao yếu của các prompt đối kháng được tạo ra đặc biệt cho ChatGPT. Trong tương lai, hiệu suất của GPT-4 và ChatGPT có thể được cải thiện vì những mô hình độc quyền này tiếp tục phát triển.

Mô hình so với cuộc tấn công. Chúng tôi hiển thị trong Bảng 10 mối quan hệ giữa các mô hình và cuộc tấn công. Nhìn chung, các cuộc tấn công cấp từ nổi lên như mạnh mẽ nhất, và BertAttack một cách nhất quán vượt trội hơn những cuộc tấn công khác trên tất cả các mô hình. Tuy nhiên, không có mẫu hình rõ ràng nào nổi lên cho hiệu quả của các cuộc tấn công khác. Ví dụ, trong khi TextBugger chứng minh hiệu quả hơn DeepWordBug cho một số mô hình như Llama2 và ChatGPT, điều ngược lại đúng cho T5-large. Đáng chú ý, Vicuna và Llama2 đặc biệt dễ bị tổn thương đối với các cuộc tấn công cấp câu, trái ngược với các mô hình như T5-large và ChatGPT, vẫn phần lớn không bị ảnh hưởng. Những quan sát như vậy có thể gợi ý về các lỗ hổng cố hữu cụ thể đối với các mô hình dựa trên Llama.

--- TRANG 6 ---
PromptRobust

Bảng 5: Trực quan hóa chú ý của các mẫu được phân loại đúng bởi prompt sạch nhưng bị phân loại sai bởi prompt đối kháng. Đối với mỗi cuộc tấn công, phía trên là prompt sạch với văn bản mẫu, phía dưới là prompt đối kháng tương ứng với cùng văn bản mẫu. N=Tiêu cực, P=Tích cực và N/A có nghĩa là phản hồi không có sẵn. Màu xanh lá cây và đỏ biểu thị câu trả lời đúng và sai, tương ứng. Cường độ màu biểu thị trọng số chú ý khác nhau (màu nặng hơn có nghĩa là trọng số lớn hơn).

Cuộc tấn công | Dự đoán | [Prompt, mẫu]
---|---|---
BertAttack | N | Trong vai trò là công cụ phân tích cảm xúc, phản hồi với 'tích cực' hoặc 'tiêu cực' để phân loại câu này: tiêu đề không chỉ mô tả các nhân vật chính, mà còn cả những người lười biếng đằng sau camera. Trả lời:
 | P | Trong vai trò là công cụ phân tích lời khen, phản hồi với 'tích cực' hoặc 'tiêu cực' để phân loại tâm trạng này: tiêu đề không chỉ mô tả các nhân vật chính, mà còn cả những người lười biếng đằng sau camera. Trả lời:
CheckList | P | Với ngữ cảnh của văn bản này, chỉ ra nếu cảm xúc được truyền đạt là 'tích cực' hoặc 'tiêu cực': phim hay, nhưng rất ủ rũ. Trả lời:
 | N | Với ngữ cảnh của văn bản này, chỉ ra nếu cảm xúc được truyền đạt là 'tích cực' hoặc 'tiêu cực' LkF0FZxMZ4: phim hay, nhưng rất ủ rũ. Trả lời:
DeepWordBug | N | Phục vụ như một mô hình đánh giá cảm xúc, xác định nếu câu đã cho là 'tích cực' hoặc 'tiêu cực'. Phân loại: tôi phải nhìn đi chỗ khác - điều này thật kinh khủng. Trả lời:
 | N/A | Phục vụ như một mô hình đánh giá cảm xúc, xác định nếu câu đã cho là 'tích cực' hoặc 'tiêu cực'. Phân loại: tôi phải nhìn đi chỗ khác - điều này thật kinh khủng. Trả lời:
Semantic | N | Trong vai trò là công cụ phân tích cảm xúc, phản hồi với 'tích cực' hoặc 'tiêu cực' để phân loại câu này: xấu. Trả lời:
 | P | Phân loại những gì bạn đang cố gắng truyền đạt trong câu này là 'tích cực' nếu nó tích cực, và 'tiêu cực' nếu nó tiêu cực. xấu. Trả lời:

Bảng 6: APDR của khả năng chuyển giao của một số LLMs.

Cuộc tấn công | Chat →T5 | Chat →UL2 | Chat →V | T5 →Chat | T5 →UL2 | T5 →V | UL2 →Chat | UL2 →T5 | UL2 →V | V →Chat | V →T5 | V →UL2
---|---|---|---|---|---|---|---|---|---|---|---|---
BertAttack | 0.05 ±0.17 | 0.08±0.19 | 0.08±0.88 | 0.18±0.32 | 0.11±0.23 | -1.39 ±5.67 | 0.15±0.27 | 0.05±0.11 | -0.70 ±3.18 | 0.06±0.19 | 0.05±0.11 | 0.03±0.12
CheckList | 0.00 ±0.04 | 0.01±0.03 | 0.19±0.39 | 0.00±0.07 | 0.01±0.03 | -0.09 ±0.64 | 0.01±0.06 | 0.01±0.04 | -0.13 ±1.80 | -0.01 ±0.04 | 0.00±0.01 | 0.00±0.00
TextFooler | 0.04 ±0.08 | 0.03±0.09 | -0.25 ±1.03 | 0.11±0.23 | 0.08±0.16 | -0.30 ±2.09 | 0.11±0.21 | 0.07±0.18 | -0.17 ±1.46 | 0.04±0.16 | 0.02±0.06 | 0.00±0.01
TextBugger | -0.00 ±0.09 | -0.01 ±0.05 | 0.02±0.94 | 0.04±0.15 | 0.01±0.04 | -0.45 ±3.43 | 0.04±0.13 | 0.02±0.07 | -0.84 ±4.42 | 0.03±0.13 | 0.01±0.05 | 0.00±0.01
DeepWordBug | 0.03 ±0.11 | 0.01±0.03 | 0.10±0.46 | 0.00±0.06 | 0.01±0.02 | -0.18 ±1.20 | 0.01±0.10 | 0.02±0.06 | -0.09 ±0.75 | 0.00±0.03 | 0.02±0.11 | 0.00±0.01
StressTest | 0.04 ±0.17 | 0.03±0.10 | 0.01±0.48 | -0.01 ±0.06 | 0.03±0.06 | 0.04±0.80 | 0.00±0.04 | 0.05±0.16 | 0.06±0.45 | 0.00±0.04 | 0.09±0.18 | 0.02±0.08
Semantic | 0.04 ±0.12 | 0.02±0.06 | 0.25±0.47 | 0.07±0.27 | 0.00±0.03 | -0.81 ±4.14 | 0.02±0.11 | -0.13 ±0.72 | -0.50 ±1.59 | 0.07±0.11 | 0.00±0.05 | 0.00±0.02

Phân tích về các loại prompt. Bảng 4 tóm tắt APDR của 4 loại prompt trên 13 bộ dữ liệu, được tính bởi APDR_t(D) = 1/|A| 1/|P_t| 1/|F| ∑A∈A ∑P∈P_t ∑fθ∈F PDR(A,P,fθ,D), trong đó P_t là tập hợp các prompt của loại t nhất định, A là tập hợp của 7 cuộc tấn công và F là tập hợp của tất cả mô hình. Trong phân tích của chúng tôi, các prompt few-shot một cách nhất quán thể hiện tính bền vững vượt trội so với các prompt zero-shot trên tất cả các bộ dữ liệu. Hơn nữa, trong khi các prompt hướng nhiệm vụ vượt trội nhẹ so với các prompt hướng vai trò trong tính bền vững tổng thể, cả hai đều cho thấy điểm mạnh khác nhau trên các bộ dữ liệu và nhiệm vụ khác nhau. Ví dụ, các prompt hướng vai trò thể hiện tăng tính bền vững trong các bộ dữ liệu SST-2 và QQP, trong khi các prompt hướng nhiệm vụ bền vững hơn trong các bộ dữ liệu MRPC, QNLI, SQuAD V2, và IWSLT. Hiểu biết về các tác động khác nhau của các loại prompt đối với lỗ hổng mô hình có thể thông báo cho các chiến lược thiết kế và điều chỉnh prompt tốt hơn, nâng cao tính bền vững của LLMs chống lại các cuộc tấn công prompt đối kháng.

4.2 Kết quả về kích thước mô hình, tinh chỉnh, và đầu vào đối kháng

Kích thước mô hình và tinh chỉnh. Chúng tôi phân tích hiệu suất trên các kích thước mô hình khác nhau sử dụng chuỗi Llama2 (7B, 13B, và 70B). Kết quả của chúng tôi trong Phụ lục C.3 cho thấy rằng các mô hình lớn hơn thường bền vững hơn các mô hình nhỏ hơn, nhưng ngoại lệ có thể xảy ra khi các mô hình nhỏ hơn vượt trội hơn các mô hình lớn hơn, đây là một phát hiện thú vị có thể kích hoạt nghiên cứu trong tương lai. Chúng tôi cũng đánh giá tác động của tinh chỉnh sử dụng các mô hình Llama2 vanilla và Llama2-chat trong Phụ lục C.3, chỉ ra rằng các mô hình được tinh chỉnh nhìn chung tốt hơn đối với các prompt đối kháng.

Tấn công cả prompt và mẫu. Chúng tôi tấn công cả prompt và kiểm tra trên AdvGLUE (Wang et al., 2021), chứa các mẫu đối kháng. Kết quả của chúng tôi trong Bảng 11 cho thấy rằng tấn công cả hai sẽ thực hiện thậm chí tệ hơn. Tuy nhiên, những điều hấp dẫn xảy ra, vì tấn công cả hai đôi khi có thể nâng cao hiệu suất cần nỗ lực hơn nữa.

4.3 Hiểu lỗ hổng của LLMs đối với các prompt đối kháng

Chúng tôi nghiên cứu điều kỳ diệu đằng sau các prompt đối kháng để phân tích tại sao chúng dẫn đến lỗi cho LLMs từ các khía cạnh khác nhau: trực quan hóa chú ý, phân tích phản hồi sai lầm (Phụ lục D.1), và phân tích cấp câu (Phụ lục D.3).

--- TRANG 7 ---
PromptRobust

Chúng tôi trực quan hóa các chú ý để điều tra ảnh hưởng của các prompt đối kháng đến sự tập trung của LLMs vào các từ đầu vào. Cụ thể, chúng tôi đề xuất hai kỹ thuật trực quan hóa chú ý: 1) Chú ý theo Gradient, gán điểm chú ý cho mỗi từ dựa trên chuẩn gradient, và 2) Chú ý theo Xóa, gán điểm chú ý cho mỗi từ bằng cách kiểm tra thay đổi tuyệt đối trong mất mát khi từ được loại bỏ. Chi tiết của những phương pháp này có thể được tìm thấy trong Phụ lục D.2. Cả hai kỹ thuật đều tạo ra kết quả tương tự; do đó, chúng tôi tập trung vào kết quả từ phương pháp Chú ý theo Gradient để đơn giản. Các phát hiện chính của chúng tôi, như được chứng minh trong Bảng 5, như sau:

• Prompt sạch: phân bổ chú ý hiệu quả. LLMs chủ yếu tập trung vào các thuật ngữ chính trong prompt sạch, hỗ trợ phân loại chính xác. Ví dụ, đối với prompt sạch của BertAttack trong Bảng 5, LLMs chủ yếu phân bổ chú ý cho thuật ngữ 'lazy', suy luận chính xác cảm xúc 'Tiêu cực'.

• Prompt đối kháng: phân kỳ chú ý. Prompt đối kháng có thể chuyển hướng chú ý của LLMs từ các phân đoạn văn bản tích hợp, gây ra phân loại sai. Trong một số cuộc tấn công như CheckList và StressTest, mô hình đồng thời tập trung vào văn bản mục tiêu và nội dung đối kháng, khuếch đại tính dễ bị tổn thương của nó đối với các nhiễu loạn đối kháng. Ví dụ, việc đưa vào một chuỗi ngẫu nhiên 'LKF0FZxMZ4' trong một cuộc tấn công CheckList làm xao lãng mô hình, giảm sự tập trung vào từ quan trọng 'good' cho phân loại chính xác. Trong các cuộc tấn công khác, chẳng hạn như BertAttack và DeepWordBug, sự chú ý của mô hình hoàn toàn bị chuyển hướng từ văn bản yêu cầu phân loại về phía prompt đối kháng, dẫn đến sự thay đổi đáng kể trong tập trung. Ví dụ, trong cuộc tấn công DeepWordBug, lỗi đánh máy trong các từ cụ thể chuyển hướng chú ý của mô hình từ 'awful' sang từ đã thay đổi 'Qetermine'.

4.4 Khả năng chuyển giao của các prompt đối kháng

Bảng 6 hiển thị hiệu quả của các cuộc tấn công khác nhau trong việc chuyển giao các prompt đối kháng giữa một số LLMs. Đối với mỗi bộ dữ liệu và loại prompt, chúng tôi chọn các prompt dễ bị tổn thương nhất được tạo ra bởi một mô hình nguồn (ví dụ, ChatGPT). Những prompt này sau đó được sử dụng để phát động các cuộc tấn công chuyển giao chống lại các mô hình mục tiêu (ví dụ, T5-large). Tác động của những cuộc tấn công chuyển giao này được định lượng bằng cách tính APDR_transfer(A,f^target_θ) = 1/|P^source| 1/|D| ∑P∈P^source ∑D∈D PDR(A,P,f^target_θ,D), trong đó f^target_θ là mô hình mục tiêu, P^source là các prompt được chọn từ mô hình nguồn và D là tập hợp của tất cả bộ dữ liệu.

Nhìn chung, chúng tôi quan sát thấy rằng các prompt đối kháng thể hiện một mức độ khả năng chuyển giao nhất định. Tuy nhiên, nó là krít so với Bảng 2 và 3. Cụ thể, APDR trong mô hình mục tiêu bởi các prompt đối kháng từ mô hình nguồn là nhỏ so với APDR gốc của mô hình nguồn. Hơn nữa, độ lệch chuẩn có xu hướng lớn hơn APDR, chỉ ra rằng khả năng chuyển giao không nhất quán. Một số prompt đối kháng có thể được chuyển giao thành công, gây ra sự giảm hiệu suất, trong khi những prompt khác có thể cải thiện hiệu suất của mô hình mục tiêu một cách bất ngờ. Một ví dụ điển hình là chuyển giao BertAttack từ UL2 sang Vicuna, dẫn đến giá trị -0.70(3.18), gợi ý một sự nâng cao bất ngờ trong hiệu suất của Vicuna khi bị áp dụng những prompt đối kháng này. Những hiện tượng này minh họa các đặc điểm tính bền vững phức tạp của các mô hình khác nhau. Khả năng chuyển giao đến ChatGPT tốt hơn so với T5-large và UL2. Điều này gợi ý một hướng để tạo ra các prompt đối kháng để tấn công các mô hình black-box như ChatGPT bằng cách huấn luyện trên các mô hình nhỏ như T5-large, có thể được sử dụng cho nghiên cứu tính bền vững trong tương lai.

4.5 Prompt nào bền vững hơn? Tần suất từ

Kết quả tần suất từ của hai bộ dữ liệu này được trình bày trong Phụ lục E. Phát hiện của chúng tôi nhấn mạnh rằng tính kiên cường của một prompt gắn liền với việc sử dụng từ theo ngữ cảnh, thay vì sự hiện diện đơn thuần của một số thuật ngữ nhất định. Sự phức tạp này gợi ý rằng các yếu tố ngoài tần suất từ, chẳng hạn như sự nhất quán ngữ nghĩa và cấu trúc cú pháp, có thể đóng vai trò then chốt trong việc xác định tính bền vững. Kiến thức này có giá trị vì nó có thể ảnh hưởng đến nghiên cứu tương lai về tính bền vững của LLMs, cung cấp hướng dẫn cho việc tạo ra các prompt kháng cự hơn, và tạo điều kiện thuận lợi cho việc tạo ra các cơ chế phòng thủ chống lại các cuộc tấn công prompt đối kháng. Điều cần thiết là nhấn mạnh rằng các quan sát của chúng tôi bắt nguồn từ phạm vi hiện tại của các mô hình và bộ dữ liệu. Hơn nữa, tính bền vững hoặc lỗ hổng của từ vẫn phụ thuộc sâu sắc vào ngữ cảnh. Do đó, việc xác định trực tiếp tính bền vững của từ mà không xem xét bối cảnh rộng hơn có thể dẫn đến các kết luận quá đơn giản hoặc không chính xác.

4.6 Biện pháp đối phó và phòng thủ

Chúng tôi thảo luận các biện pháp đối phó tiềm năng. 1) Tiền xử lý đầu vào: Một cách tiếp cận bao gồm việc phát hiện và giải quyết trực tiếp các đối thủ tiềm năng, chẳng hạn như phát hiện lỗi đánh máy, chuỗi không liên quan, và nâng cao tính rõ ràng và súc tích của prompt. 2) Kết hợp dữ liệu chất lượng thấp trong tiền huấn luyện: Dữ liệu chất lượng thấp có thể phục vụ như các đối thủ tiềm năng, và việc bao gồm rõ ràng dữ liệu chất lượng thấp trong quá trình tiền huấn luyện có thể phát triển hiểu biết tốt hơn về các đầu vào đa dạng và xây dựng tính kiên cường chống lại các đối thủ. 3) Tinh chỉnh cải thiện: Tinh chỉnh có thể dẫn đến cải thiện tính bền vững. Như chúng tôi đã chứng minh trước đây, các mô hình như T5 và UL2 thể hiện tính bền vững lớn hơn so với ChatGPT, gợi ý lợi ích tiềm năng của tinh chỉnh có giám sát quy mô lớn. Chi tiết hơn có trong Phụ lục F.

5 Công trình liên quan

Đánh giá Tính Bền vững LLM. AdvGLUE (Wang et al., 2021) đứng như một bộ dữ liệu tĩnh để đánh giá tính bền vững đối kháng của các mẫu đầu vào. DecodingTrust (Wang et al., 2023a) thực hiện một đánh giá toàn diện về độ tin cậy trong các mô hình GPT, đặc biệt là GPT-3.5 và GPT-4. Nghiên cứu đi sâu vào các lĩnh vực như độc tính, thiên kiến khuôn mẫu, thách thức đối kháng, và quyền riêng tư. Cụ thể, họ đánh giá tính bền vững trên các bộ dữ liệu tiêu chuẩn AdvGLUE(Wang et al., 2021) và AdvGLUE++ (Wang et al., 2023a). Cụ thể đối với tính bền vững đối kháng, DecodingTrust cũng tập trung vào việc đánh giá tính bền vững của các mẫu đầu vào thay vì prompt và nó vẫn sử dụng các bộ dữ liệu tĩnh thay vì một bộ benchmark có thể hành động. Ngược lại, PromptRobust được định vị như một benchmark mở tập trung vào các prompt đối kháng thay vì mẫu (và nó có thể được mở rộng để bao gồm mẫu). Lưu ý rằng các prompt là hướng dẫn chung để hỗ trợ học trong ngữ cảnh của LLMs để thực hiện các nhiệm vụ cụ thể, và chúng có thể được kết hợp với nhiều mẫu trong một số nhiệm vụ nhất định. Prompt là không thể thiếu trong tương tác con người-LLMs trong khi các mẫu đầu vào có thể không cần thiết, có nghĩa là prompt linh hoạt và điều cần thiết là đánh giá tính bền vững của chúng.

An toàn của LLMs. Chúng tôi mô phỏng các prompt người dùng tiềm năng bằng cách tạo ra các prompt đối kháng, nhưng mục đích chính không phải là thực sự tấn công mô hình. Điều này phân biệt công việc của chúng tôi với các nỗ lực hiện có trong nghiên cứu an toàn của LLMs. Cụ thể, cả SafetyPrompts (Sun et al., 2023) và các cuộc tấn công inject prompt (Perez & Ribeiro, 2022; Greshake et al., 2023; Liu et al., 2023b) đều được thiết kế để làm nổi bật các hướng dẫn có thể có hại có thể điều khiển LLMs đưa ra các đầu ra không phù hợp với giá trị con người hoặc thực hiện các hành động không mong muốn như rò rỉ dữ liệu và truy cập trái phép. Prompt đối kháng được tạo ra để mô phỏng các lỗi hợp lý mà người dùng cuối có thể vô tình mắc phải. Mục tiêu của chúng tôi là đánh giá mức độ mà những prompt này, ngay cả khi chúng hơi lệch khỏi quy chuẩn, có thể làm lệch kết quả LLM. Những prompt đối kháng này duy trì tính toàn vẹn ngữ nghĩa của chúng, đảm bảo chúng hầu như không thể phát hiện đối với con người. Các prompt đối kháng không được thiết kế để gợi ra các phản hồi có hại hoặc gây hiểu lầm.

6 Kết luận và Hạn chế

Tính bền vững của các prompt trong LLMs là mối quan tâm tối quan trọng trong an ninh và tương tác con người-máy tính. Trong bài báo này, chúng tôi đã đánh giá kỹ lưỡng tính bền vững của LLMs đối với các prompt đối kháng sử dụng benchmark PromptRobust được đề xuất. Điều quan trọng là tận dụng các phương pháp tấn công đối kháng để mô phỏng các nhiễu loạn tiềm năng như lỗi đánh máy, từ đồng nghĩa, và sự khác biệt về phong cách. Sau đó chúng tôi đã thực hiện các thí nghiệm và phân tích rộng rãi trên các nhiệm vụ và mô hình khác nhau. Trong khi kết quả cho thấy rằng các LLMs hiện tại không đủ bền vững đối với các prompt đối kháng, chúng tôi đã phân tích thêm lý do đằng sau điều đó sử dụng trực quan hóa chú ý. Hơn nữa, chúng tôi đã phân tích các từ thường xuyên để cung cấp hướng dẫn cho cả chuyên gia và phi chuyên gia trong việc phát triển các công cụ kỹ thuật prompt tốt hơn. PromptRobust sẽ được mã nguồn mở để phục vụ như một công cụ nền tảng cho nghiên cứu LLMs bền vững.

Có một số hạn chế. Đầu tiên, do tính toán đáng kể, chúng tôi không thực hiện đánh giá trên các bộ dữ liệu đầy đủ, mà dựa vào lấy mẫu. Nghiên cứu tương lai có thể đánh giá trên toàn bộ bộ dữ liệu để có được nhiều hiểu biết hơn. Thứ hai, chúng tôi không thể bao gồm tất cả LLMs và bộ dữ liệu do ràng buộc tính toán. Bao gồm nhiều hơn trong tương lai có thể cung cấp góc nhìn đa dạng hơn. Thứ ba, chúng tôi không đánh giá các kỹ thuật tiên tiến hơn của kỹ thuật prompt như chuỗi suy nghĩ (CoT) (Wei et al., 2022) và cây suy nghĩ (ToT) (Yao et al., 2023). Chúng tôi tin rằng nhiều đánh giá hơn có thể được thực hiện trên các kỹ thuật kỹ thuật prompt mới nhất. Thứ tư, chúng tôi xem xét các cuộc tấn công prompt black-box, có thể tạo ra các nhiễu loạn có thể mô phỏng các lỗi xảy ra tự nhiên. Các cuộc tấn công prompt white-box được tối ưu hóa có thể tạo ra các prompt đối kháng tốt hơn, đây là một công việc tương lai thú vị.

[Phần tài liệu tham khảo và phụ lục tiếp theo sẽ được dịch tương tự...]

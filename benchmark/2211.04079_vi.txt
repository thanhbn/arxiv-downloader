# COPEN: Khám phá Kiến thức Khái niệm trong các Mô hình Ngôn ngữ được Tiền huấn luyện

Hao Peng1;2, Xiaozhi Wang1;2, Shengding Hu1;2, Hailong Jin1;2, Lei Hou1;2y,
Juanzi Li1;2, Zhiyuan Liu1;2, Qun Liu3
1Khoa Khoa học Máy tính và Công nghệ, BNRist;
2KIRC, Viện Trí tuệ Nhân tạo,
Đại học Thanh Hoa, Bắc Kinh, 100084, Trung Quốc
3Phòng thí nghiệm Noah's Ark của Huawei
{peng-h21, wangxz20}@mails.tsinghua.edu.cn

## Tóm tắt

Kiến thức khái niệm là nền tảng cho nhận thức của con người và các cơ sở tri thức. Tuy nhiên, các nghiên cứu khám phá kiến thức hiện tại chỉ tập trung vào việc đánh giá kiến thức sự thật của các mô hình ngôn ngữ được tiền huấn luyện (PLMs) và bỏ qua kiến thức khái niệm. Vì kiến thức khái niệm thường xuất hiện như hiểu biết thông thường ngầm định đằng sau các văn bản, việc thiết kế các đầu dò cho kiến thức khái niệm là khó khăn. Lấy cảm hứng từ các lược đồ biểu diễn kiến thức, chúng tôi đánh giá toàn diện kiến thức khái niệm của PLMs bằng cách thiết kế ba nhiệm vụ để khám phá xem PLMs có tổ chức các thực thể theo sự tương đồng khái niệm, học các thuộc tính khái niệm, và khái niệm hóa các thực thể trong ngữ cảnh hay không. Đối với các nhiệm vụ này, chúng tôi thu thập và chú thích 24k trường hợp dữ liệu bao gồm 393 khái niệm, đó là COPEN, một bộ tiêu chuẩn khám phá kiến thức khái niệm (COncePtual knowledge Probing bENchmark). Các thí nghiệm mở rộng trên các PLMs với kích thước và loại khác nhau cho thấy các PLMs hiện tại thiếu hệ thống kiến thức khái niệm và gặp phải nhiều tương quan giả mạo khác nhau. Chúng tôi tin rằng đây là một nút thắt cổ chai quan trọng để thực hiện nhận thức giống con người trong PLMs. COPEN và mã nguồn của chúng tôi được công bố công khai tại https://github.com/THU-KEG/COPEN .

## 1 Giới thiệu

Các mô hình ngôn ngữ được tiền huấn luyện (PLMs) đã đạt được hiệu suất vượt trội trên hầu hết các nhiệm vụ NLP đòi hỏi kiến thức thế giới đáng kể (Qiu et al., 2020; Han et al., 2021). Việc khám phá mức độ và phạm vi kiến thức thế giới trong PLMs là thú vị và có ý nghĩa. Các nghiên cứu khám phá kiến thức hiện tại đã đánh giá kiến thức của PLMs về các thực thể (Broscheit, 2019; Tenney et al., 2019a) và mối quan hệ của chúng (Petroni et al., 2019; Jiang et al., 2020; Roberts et al., 2020), tức là kiến thức sự thật, nhưng bỏ qua kiến thức khái niệm.

Đóng góp bằng nhau
yTác giả liên hệ: L.Hou

Động vật có thể di chuyển.
Vương quốc Anh
Grumpy Cat
Hoa Kỳ Động vật có vú
Động vật
Chim
Quốc gia
Dolly quốc tịch quốc tịch Quan hệ Thể hiện của Lớp con của Hầu hết động vật có vú có rốn. Chim có lông. ……… Đồ thị Thực thể Phân loại Khái niệm Thuộc tính

…Hình 1: Một ví dụ về đồ thị tri thức. Các thực thể được tổ chức bởi các khái niệm thông qua quan hệ Thể hiện của và các khái niệm được tổ chức thành phân loại thông qua quan hệ Lớp con của. Mỗi khái niệm có những thuộc tính nhất định. Các nghiên cứu hiện tại chỉ khám phá kiến thức sự thật trong đồ thị thực thể, bỏ qua kiến thức khái niệm trong phân loại khái niệm và quan hệ Thể hiện của.

Kiến thức khái niệm, đặc biệt là khả năng trừu tượng hóa, là nền tảng cho tất cả các loại nhận thức của con người (Carey, 1991; Collins and Olson, 2014) bao gồm xử lý ngôn ngữ (Waxman and Markow, 1995; Wellsby and Pexman, 2014). Như câu nói của nhà tâm lý học Gregory Murphy, các khái niệm là chất keo giữ thế giới tinh thần của chúng ta lại với nhau (Murphy, 2004). Hơn nữa, các cơ sở tri thức (Suchanek et al., 2007; Auer et al., 2007; Vrandečić, 2012) tổ chức các thực thể khổng lồ thông qua phân loại khái niệm như được minh họa trong Hình 1, điều này cho phép các ứng dụng rộng rãi (Lv et al., 2018; Zhou et al., 2021). Do đó, việc khám phá xem PLMs có kiến thức khái niệm giống con người hay không là cần thiết trong khám phá kiến thức.

Lấy cảm hứng từ lược đồ khái niệm trong biểu diễn kiến thức (Sowa, 1976; Decker et al., 2000; McGuinness et al., 2004; Antoniou and Van Harmelen, 2004), chúng tôi đánh giá toàn diện kiến thức khái niệm của PLMs bằng cách đặt ra ba câu hỏi: PLMs có tổ chức các thực thể theo sự tương đồng khái niệm không?

--- TRANG 2 ---

PLMs có biết các thuộc tính của khái niệm không? PLMs có thể khái niệm hóa đúng các thực thể trong ngữ cảnh không? Trong bài báo này, chúng tôi thiết kế ba nhiệm vụ khám phá cho những câu hỏi này: (1) Nhiệm vụ đánh giá tương đồng khái niệm (CSJ) nghiên cứu xem PLMs có tổ chức các thực thể theo sự tương đồng khái niệm hay không, đó là cơ sở để hiểu các khái niệm. Cho một thực thể truy vấn, CSJ yêu cầu PLMs chọn thực thể tương đồng khái niệm nhất trong số các thực thể ứng viên. Ví dụ, trong Hình 1, cho Dolly làm thực thể truy vấn, mặc dù UK có quan hệ trực tiếp và xuất hiện cùng nhau nhiều hơn với nó, PLMs nên chọn Grumpy Cat. (2) Nhiệm vụ đánh giá thuộc tính khái niệm (CPJ) khám phá xem PLMs có kiến thức về thuộc tính khái niệm hay không, đó là những trừu tượng hóa chung của kiến thức sự thật. Cho một phát biểu về một thuộc tính cụ thể, chẳng hạn như "có lông", CPJ yêu cầu PLMs đánh giá xem nó có đúng cho một khái niệm cụ thể và cũng như một chuỗi khái niệm hay không, điều này đánh giá xem PLMs có hiểu tính chuyển tiếp thuộc tính giữa một chuỗi các khái niệm phân cấp hay không. (3) Nhiệm vụ khái niệm hóa trong ngữ cảnh (CiC) đánh giá khả năng của PLMs để khái niệm hóa đúng các thực thể trong ngữ cảnh. Cho một thực thể được đề cập trong một ngữ cảnh cụ thể, PLMs được yêu cầu chọn khái niệm phù hợp nhất trong phân loại khái niệm theo ngữ cảnh của nó. CiC yêu cầu không chỉ phân định nghĩa các đề cập thực thể, mà còn phân biệt các khái niệm cấp cao và cấp thấp. Ví dụ, cho ngữ cảnh "Dolly đang chạy trên cỏ", PLMs nên khái niệm hóa Dolly như một Động vật vì không có đủ bằng chứng cho Động vật có vú.

Dựa trên các cân nhắc trên, chúng tôi xây dựng một bộ tiêu chuẩn khám phá kiến thức khái niệm, COPEN, bao gồm phân loại khái niệm với 446 khái niệm và dữ liệu chất lượng cao của 24K trường hợp cho ba nhiệm vụ khám phá. Phân loại khái niệm được tuyển chọn bởi các chuyên gia dựa trên DBpedia (Auer et al., 2007) và Wikidata (Vrandečić and Krötzsch, 2014) để tạo thành một hệ thống phân cấp được định nghĩa rõ ràng và bao phủ các thực thể rộng rãi. Các trường hợp dữ liệu cho ba nhiệm vụ được thu thập bằng cách căn chỉnh các thực thể trong Wikidata và các câu trong GenericsKB (Bhakthavatsalam et al., 2020), Wikipedia¹, và Simple Wikipedia² vào phân loại khái niệm và sau đó được chú thích thủ công bởi các nhà chú thích đám đông.

Chúng tôi tiến hành các thí nghiệm mở rộng trên COPEN để đánh giá các mô hình ngôn ngữ (LMs) được sử dụng rộng rãi khác nhau, bao gồm ba loại: masked LMs (Devlin et al., 2019; Liu et al., 2019b), autoregressive LMs (Radford et al., 2019; Black et al., 2021), và sequence-to-sequence LMs (Lewis et al., 2020; Raffel et al., 2020). Chúng tôi tiến hành các thí nghiệm trong ba cài đặt: (1) khám phá zero-shot, điều này chuyển đổi các nhiệm vụ khám phá thành mục tiêu tiền huấn luyện và để PLMs tính điểm câu trả lời mà không cần huấn luyện nào (Petroni et al., 2019); (2) khám phá tuyến tính, chỉ điều chỉnh các đầu phân loại tuyến tính bổ sung và sử dụng chúng để xử lý các nhiệm vụ khám phá với các biểu diễn được đóng băng do PLMs tạo ra; (3) fine-tuning, điều chỉnh tất cả các tham số PLM. Các thí nghiệm cho thấy PLMs hiện tại đạt được hiệu suất không tầm thường nhưng vẫn kém hiệu suất đáng kể so với người bình thường trên tất cả ba nhiệm vụ khám phá. Các phân tích tiếp theo cho thấy PLMs gặp phải các tương quan giả mạo như đồng xuất hiện từ và dự đoán ngoài ngữ cảnh, và việc tăng quy mô mô hình mang lại cải thiện biên tế.

¹https://en.wikipedia.org/
²https://simple.wikipedia.org/

Tóm lại, đóng góp của chúng tôi có ba mặt: (1) Chúng tôi đề xuất khám phá PLMs về kiến thức khái niệm, điều này từ lâu đã bị bỏ qua, và thiết kế ba nhiệm vụ khám phá lấy cảm hứng từ các nghiên cứu biểu diễn kiến thức. (2) Chúng tôi xây dựng COPEN, một bộ tiêu chuẩn khám phá bao gồm phân loại khái niệm chất lượng cao và các đầu dò. (3) Chúng tôi chứng minh thực nghiệm rằng PLMs hiện tại thiếu hệ thống kiến thức khái niệm và phân tích các lý do. Chúng tôi hy vọng bộ tiêu chuẩn và phát hiện của chúng tôi có thể tạo điều kiện cho nghiên cứu sâu hơn về PLMs nhận biết khái niệm và hiểu ngôn ngữ giống con người.

## 2 Bộ tiêu chuẩn COPEN

Trong phần này, chúng tôi giới thiệu bộ tiêu chuẩn COPEN của chúng tôi, bao gồm việc xây dựng phân loại khái niệm (§ 2.1) và các tập dữ liệu cho ba nhiệm vụ khám phá (§§ 2.2 đến 2.4). Thêm chi tiết xây dựng và chú thích được hiển thị trong phụ lục D.

### 2.1 Phân loại Khái niệm COPEN

Việc thiết kế ba nhiệm vụ khám phá lấy cảm hứng từ lược đồ khái niệm trong biểu diễn kiến thức (Decker et al., 2000; McGuinness et al., 2004), được sử dụng rộng rãi trong đồ thị tri thức (Suchanek et al., 2007; Auer et al., 2007; Vrandečić, 2012). Nói chung, nó sử dụng quan hệ thể hiện của để liên kết các thực thể (các trường hợp cụ thể) vào các khái niệm trừu tượng, và sử dụng quan hệ lớp con của để tổ chức các khái niệm thành phân loại. Mỗi khái niệm có những thuộc tính nhất định mô tả nó như

--- TRANG 3 ---

Inter Milan về mặt khái niệm tương tự với Hãy chọn khái niệm phù hợp nhất với ngữ cảnh cho Dolly theo ngữ cảnh: Dolly đang chạy trên cỏ. Dolly là một (a)(c) Mẫu Động vật có vú nuôi con bằng sữa. Phát biểu này Mẫu động vật động vật có vú Series A Pohang Steelers Milan Milan Fashion Week (b) Động vật Ngựa đúng | sai đúng | sai đúng | sai Trả lời Khái niệm/Chuỗi Khái niệm ngựa Thực thể Truy vấn Mẫu Thực thể Mẫu Thực thể Ứng viên Vàng: Lớp con của Khái niệm Tím: Thực thể

Hình 2: Ví dụ về việc chuyển đổi dữ liệu của ba nhiệm vụ khám phá thành lời nhắc ngôn ngữ tự nhiên trong khám phá zero-shot. Tên của các thực thể hoặc khái niệm là văn bản được tra cứu trong Wikidata bằng ID của chúng. Trong Hình (b), văn bản in đậm (đúng hoặc sai) biểu thị câu trả lời. Trong Hình (b) và (c), chuỗi khái niệm là Ngựa –>Động vật có vú –>Động vật. Trong Hình (c), đối với các thực thể có nhiều chuỗi khái niệm, mỗi khái niệm sẽ được PLMs chấm điểm độc lập, tức là PLMs chỉ đưa ra dự đoán ở cấp độ khái niệm. Không có quy trình lựa chọn chuỗi chuyên dụng.

ví dụ được hiển thị trong Hình 1.

Để hỗ trợ xây dựng tập dữ liệu khám phá, chúng tôi tuyển chọn thủ công phân loại khái niệm dựa trên DBpedia (Auer et al., 2007) và Wikidata (Vrandečić and Krötzsch, 2014) trong 3 bước: (1) Lấy phân loại cơ bản từ DBpedia. Chúng tôi trích xuất các khái niệm thường xuyên của DBpedia, đó là các khái niệm có ít nhất 5 trường hợp, và giữ các quan hệ lớp con của giữa chúng. (2) Căn chỉnh DBpedia và Wikidata. Đối với mỗi khái niệm DBpedia, chúng tôi tìm thủ công mục Wikidata tương đương của nó và sau đó sử dụng các quan hệ lớp con của (P279) trong Wikidata để mở rộng phân loại khái niệm và sử dụng các quan hệ thể hiện của (P31) để liên kết các thực thể Wikidata khổng lồ vào các khái niệm. (3) Đơn giản hóa phân loại. Chúng tôi tiếp tục loại bỏ một số khái niệm bất thường để đơn giản hóa phân loại theo hướng dẫn từ Schema.org (Guha et al., 2016). Ví dụ, Person là khái niệm con của Animal, Eukaryote, và Species trong DBpedia, điều này hợp lý nhưng không thuận tiện cho các ứng dụng thực tế. Theo Schema.org, chúng tôi đặt Person làm khái niệm cấp cao nhất trong phân loại. Cuối cùng, chúng tôi đạt được phân loại khái niệm ngắn gọn có cấu trúc cây, bao gồm 446 khái niệm bao phủ 45 triệu thực thể Wikidata. Có 23 khái niệm cấp cao nhất, và chúng tôi sử dụng 11 trong số chúng và các khái niệm con của chúng để xây dựng tập dữ liệu huấn luyện và phát triển cũng như các khái niệm khác cho tập dữ liệu thử nghiệm.

### 2.2 Đánh giá Tương đồng Khái niệm

Nhiệm vụ đánh giá tương đồng khái niệm (CSJ) là nhiệm vụ phân loại đa lựa chọn, khám phá xem PLMs có tổ chức các thực thể theo sự tương đồng khái niệm hay không, tức là xem PLMs có học quan hệ thể hiện của hay không. Cho một thực thể truy vấn, CSJ yêu cầu PLMs chọn thực thể tương đồng khái niệm nhất (thể hiện của cùng khái niệm cấp cao) trong số một số ứng viên. Như trong Hình 2 (a), PLMs nên chọn Pohang Steelers cho Inter Milan vì cả hai đều là câu lạc bộ bóng đá, mặc dù Milan và Inter Milan đồng xuất hiện thường xuyên hơn. Sự tương đồng khái niệm ở đây tương tự như quan hệ cohyponym trong ngữ nghĩa từ vựng (Cruse, 1986), đã được chứng minh là khác biệt nhưng dễ bị ảnh hưởng bởi các liên kết đồng xuất hiện giả mạo (Hill et al., 2015). Do đó chúng tôi cần kiểm soát ảnh hưởng của đồng xuất hiện để có kết quả trung thực.

Huấn luyện Phát triển Thử nghiệm
CSJ #Trường hợp 4;462 1;116 3;909
#Khái niệm 84 84 90
CPJ #Trường hợp 3;274 823 4;758
#Khái niệm 215 195 178
CiC #Trường hợp 2;888 722 2;368
#Khái niệm 193 184 155

Bảng 1: Thống kê dữ liệu COPEN cho ba nhiệm vụ khám phá.

Thu thập Dữ liệu Dữ liệu cho CSJ được thu thập trong hai bước: (1) Thu thập tự động. Chúng tôi đầu tiên lấy mẫu 174 khái niệm không phải là cấp dưới của nhau. Sau đó chúng tôi truy xuất 50 thực thể Wikidata xuất hiện thường xuyên nhất trong corpus Wikipedia cho mỗi khái niệm, và sau đó xây dựng các trường hợp dữ liệu bằng cách kết hợp chúng. Mỗi trường hợp bao gồm một thực thể truy vấn, một thực thể trả lời của cùng khái niệm, và 20 thực thể phân tâm, trong đó 5 là những phân tâm khó của các khái niệm chia sẻ cấp cao với khái niệm của thực thể truy vấn. Để kiểm tra chất lượng dữ liệu, chúng tôi lấy mẫu 200 trường hợp và thấy ít nhiễu. (2) Lọc dựa trên đồng xuất hiện. Để giảm ảnh hưởng của đồng xuất hiện, chúng tôi cần lọc ra các trường hợp có thể được giải quyết dễ dàng với đồng

--- TRANG 4 ---

xuất hiện. Lastra-Díaz et al. (2019) cho thấy rằng Glove word embedding (Pennington et al., 2014) chứa thông tin đồng xuất hiện từ phong phú nhưng kiến thức cohyponym hạn chế. Do đó chúng tôi sử dụng nó để lọc ra các trường hợp có độ tương tự từ cao hơn giữa thực thể truy vấn và thực thể trả lời so với các thực thể phân tâm. Chúng tôi cuối cùng có được 9;487 trường hợp, mỗi trường hợp bao gồm một thực thể truy vấn và 21 thực thể ứng viên. Thống kê của các tập con dữ liệu được hiển thị trong Bảng 1.

### 2.3 Đánh giá Thuộc tính Khái niệm

Nhiệm vụ đánh giá thuộc tính khái niệm (CPJ) là nhiệm vụ phân loại câu nhị phân, khám phá xem PLMs có biết các thuộc tính của khái niệm hay không. Cho một phát biểu mô tả một thuộc tính khái niệm nhất định, PLMs được yêu cầu đánh giá xem nó có đúng hay không. Ví dụ trong Hình 2 (b), PLMs nên dự đoán "đúng" cho phát biểu "Động vật có vú nuôi con bằng sữa".

Bên cạnh đánh giá CPJ ở cấp độ trường hợp, phản ánh kiến thức của PLMs về thuộc tính cho các khái niệm cá nhân khác nhau, chúng tôi cũng thiết lập đánh giá cấp độ chuỗi, trong đó PLM đánh giá đúng một thuộc tính khi và chỉ khi nó đánh giá đúng thuộc tính cho mọi khái niệm trong một chuỗi khái niệm. Như ví dụ trong Hình 2 (b), chuỗi khái niệm là một chuỗi các khái niệm được kết nối với quan hệ lớp con của theo thứ tự. Đánh giá cấp độ chuỗi đánh giá xem PLMs có hiểu tính chuyển tiếp của thuộc tính khái niệm hay không. Nó có nghĩa là một thuộc tính đúng cho một khái niệm cũng đúng cho các khái niệm cấp dưới của nó, nhưng có thể không đúng cho các khái niệm cấp cao của nó như trường hợp trong Hình 2 (b).

Thu thập Dữ liệu Dữ liệu cho CPJ được thu thập trong hai bước: (1) Thu thập tự động. Đối với mỗi khái niệm trong phân loại của chúng tôi, chúng tôi căn chỉnh nó với các phát biểu của GenericsKB (Bhakthavatsalam et al., 2020), một cơ sở tri thức chất lượng cao cho các phát biểu chung tự nhiên, bằng khớp từ vựng để có được các trường hợp tích cực. Sau đó chúng tôi thay thế đề cập khái niệm bằng tên khái niệm khác để có được các trường hợp tiêu cực. (2) Chú thích con người. Để đảm bảo chất lượng dữ liệu, chúng tôi mời các nhà chú thích kiểm tra xem các trường hợp có được gắn nhãn đúng, đúng ngữ pháp và mô tả thuộc tính khái niệm hay không. Tất cả các nhà chú thích đều được đào tạo tốt và vượt qua bài kiểm tra trước khi chú thích. Chúng tôi cuối cùng có được 8;855 trường hợp cho CPJ và thống kê của các tập con dữ liệu được hiển thị trong Bảng 1. Ngoài ra, dữ liệu thử nghiệm cuối cùng bao gồm 102 chuỗi khái niệm và các thuộc tính tương ứng được sử dụng cho đánh giá cấp độ chuỗi.

### 2.4 Khái niệm hóa trong Ngữ cảnh

Nhiệm vụ khái niệm hóa trong ngữ cảnh (CiC) là nhiệm vụ phân loại đa lựa chọn, khám phá xem PLMs có thể khái niệm hóa đúng các thực thể trong ngữ cảnh hay không. Cho một thực thể được đề cập trong một câu cụ thể, PLMs được yêu cầu chọn khái niệm phù hợp nhất trong một chuỗi khái niệm, đó là một chuỗi các khái niệm được kết nối với quan hệ lớp con của theo thứ tự. Điều này yêu cầu PLMs hiểu quan hệ lớp con của và nắm bắt sự khác biệt tinh tế của các khái niệm cấp độ khác nhau trong hệ thống phân cấp. Ví dụ trong Hình 2 (c), cho câu "Dolly đang chạy trên cỏ." và chuỗi khái niệm Ngựa –>Động vật có vú –>Động vật, PLMs nên chọn Động vật cho Dolly vì ngữ cảnh không hỗ trợ các khái niệm chi tiết hơn. Đôi khi thực thể thuộc về nhiều chuỗi khái niệm, ví dụ, Jimmy Carter vừa là Writer vừa là Politician, điều này thêm yêu cầu PLMs phân định nghĩa.

Thu thập Dữ liệu Dữ liệu cho CiC được thu thập trong hai bước: (1) Thu thập câu. Đối với mỗi khái niệm, chúng tôi đầu tiên truy xuất 10 thực thể Wikidata xuất hiện thường xuyên nhất trong corpus Wikipedia. Trong số các thực thể được truy xuất, chúng tôi chỉ giữ các thực thể được liên kết với các chuỗi khái niệm chứa nhiều hơn một khái niệm và thu thập 5 câu cho mỗi thực thể từ Wikipedia và SimpleWiki, cung cấp các ngữ cảnh đa dạng cho khái niệm hóa. Một câu, cùng với một thực thể được đề cập trong câu và chuỗi khái niệm của thực thể, tạo thành một trường hợp. (2) Chú thích con người. Sau đó chúng tôi tổ chức chú thích đám đông để có được các nhãn. Tất cả các nhà chú thích đều được đào tạo tốt và đủ điều kiện. Chúng tôi cuối cùng có được 5;978 trường hợp cho CiC và thống kê của các tập con dữ liệu được hiển thị trong Bảng 1.

## 3 Thiết lập Đánh giá

Chúng tôi giới thiệu các PLMs được sử dụng rộng rãi khác nhau được điều tra trong các thí nghiệm của chúng tôi (§ 3.1) và ba phương pháp khám phá được áp dụng (§ 3.2).

### 3.1 PLMs được Điều tra

Chúng tôi điều tra ba loại chính của PLMs: (1) Masked LM, bao gồm BERT (Devlin et al., 2019), được tiền huấn luyện với các mục tiêu mô hình hóa ngôn ngữ có mặt nạ hai chiều và dự đoán câu tiếp theo, và RoBERTa (Liu et al., 2019b), là phiên bản được tối ưu hóa mạnh mẽ của BERT. (2) Autoregressive LM, bao gồm GPT-2 (Radford et al.,

--- TRANG 5 ---

2019), được tiền huấn luyện với mục tiêu mô hình hóa ngôn ngữ một chiều từ trái sang phải, và GPT-Neo (Black et al., 2021), áp dụng cùng mục tiêu nhưng cải thiện một số chi tiết triển khai. (3) Sequence-to-sequence LM, áp dụng kiến trúc encoder-decoder. Loại này bao gồm BART (Lewis et al., 2020), được tiền huấn luyện với các mục tiêu điền văn bản và hoán vị câu, và T5 (Raffel et al., 2020), được tiền huấn luyện với mục tiêu span-corruption và nhiều nhiệm vụ downstream.

Trong § 4, chúng tôi báo cáo kết quả của các phiên bản BASE được sử dụng thường xuyên của các PLMs này, và kết quả cho các phiên bản khác được hiển thị trong phụ lục C.

### 3.2 Phương pháp Khám phá

Khám phá Zero-Shot chuyển đổi các nhiệm vụ khám phá sang định dạng mục tiêu mô hình hóa ngôn ngữ tiền huấn luyện (Liu et al., 2021a) để PLMs có thể thực hiện các nhiệm vụ này mà không cần huấn luyện. Nó được áp dụng rộng rãi bởi các nghiên cứu khám phá kiến thức (Petroni et al., 2019; Tenney et al., 2019a) vì nó ngăn PLMs học kiến thức mới từ dữ liệu huấn luyện để hiệu suất đạt được phản ánh kiến thức nội tại của PLMs. Do đó hiệu suất của khám phá zero-shot thường được diễn giải như giới hạn dưới của kiến thức PLMs (Jiang et al., 2020).

Như được minh họa trong Hình 2, đối với mỗi trường hợp dữ liệu của ba nhiệm vụ khám phá, chúng tôi chuyển đổi các lựa chọn của nó thành lời nhắc ngôn ngữ tự nhiên bằng cách điền chúng vào các mẫu được thiết kế thủ công, và sau đó để PLMs chấm điểm các lời nhắc bằng khả năng của mô hình hóa ngôn ngữ. Lựa chọn có điểm cao nhất được coi là câu trả lời dự đoán của PLMs. Một số chi tiết triển khai như lấy phần nào của lời nhắc vào tính toán chấm điểm có thể ảnh hưởng đến hiệu suất của PLMs. Chúng tôi tìm kiếm các chi tiết này với các thử nghiệm sơ bộ và chỉ báo cáo hiệu suất của cấu hình tốt nhất trong các thí nghiệm.

Khám phá Tuyến tính thêm một bộ phân loại tuyến tính nông bổ sung trên đầu ra của các biểu diễn ngữ cảnh hóa đầu ra của PLMs, và chỉ huấn luyện bộ phân loại bổ sung trong khi giữ các tham số của PLMs cố định. Vì dung lượng mô hình của bộ phân loại tuyến tính nông quá hạn chế để phù hợp với các nhiệm vụ, hiệu suất đạt được chủ yếu phải đến từ kiến thức trong các biểu diễn của PLMs (Alain and Bengio, 2017). Do đó khám phá tuyến tính được sử dụng rộng rãi trong khám phá kiến thức (Tenney et al., 2019b; Hewitt and Manning, 2019).

Fine-Tuning là phương pháp tiêu chuẩn để thích ứng PLMs với các nhiệm vụ downstream, huấn luyện tất cả các tham số PLMs trên dữ liệu huấn luyện với các mục tiêu cụ thể của nhiệm vụ. Xem xét dung lượng mô hình mạnh mẽ của PLMs, PLMs sẽ không thể tránh khỏi việc phù hợp với các nhiệm vụ khám phá thông qua thông tin trong dữ liệu huấn luyện thay vì chỉ dựa vào kiến thức nội tại của chúng. Do đó hiệu suất fine-tuning nên phục vụ như giới hạn trên của kiến thức khái niệm PLMs trong các thí nghiệm của chúng tôi.

Đối với CSJ và CiC, chúng tôi lấy các lời nhắc đã điền của các mẫu giống hệt trong khám phá zero-shot làm đầu vào và huấn luyện PLMs với loss cross-entropy. Đối với CPJ, chúng tôi lấy các phát biểu thuộc tính làm đầu vào và sử dụng loss binary cross entropy.

Các triển khai chi tiết hơn về ba phương pháp khám phá được hiển thị trong phụ lục A.

## 4 Thí nghiệm và Phân tích

Chúng tôi đầu tiên giới thiệu kết quả tổng thể trong § 4.1 và tiến hành phân tích chi tiết về ba nhiệm vụ khám phá (§§ 4.2 đến 4.4), tương ứng. Sau đó chúng tôi phân tích hiệu suất ở các quy mô mô hình khác nhau (§ 4.5). Thêm quan sát và thảo luận về kết quả thí nghiệm được đặt trong phụ lục B.

Mô hình CSJ CPJ CiC
Cấp độ Trường hợp Cấp độ Chuỗi
ZP LP FT ZP LP FT ZP LP FT ZP LP FT
Ngẫu nhiên 4:8 4:8 4:8 50:0 50:0 50:0 7:2 7:2 7:2 27:7 27:7 27:7
BERT BASE 20:3 16:1±0.21 27:3±0.86 49:4 61:6±0.28 68:1±0.98 22:5 24:2±1.22 23:2±1.22 37:6 34:3±0.59 49:5±0.60
RoBERTa BASE 15:5 12:0±0.21 22:3±0.51 49:2 61:9±0.13 72:0±0.54 21:6 13:1±1.67 18:3±1.22 31:4 30:0±1.98 52:6±1.02
GPT-2 BASE 7:9 4:3±0.24 20:1±0.23 51:5 64:8±1.14 70:4±0.72 14:7 14:4±0.92 20:3±2.01 32:3 34:5±2.08 54:2±0.12
GPT-Neo 125M 7:9 11:0±0.20 18:3±0.42 52:2 62:2±0.21 68:2±0.62 22:5 15:0±2.01 19:0±2.81 32:6 39:6±0.93 47:4±0.25
BART BASE 14:4 8:4±0.10 21:0±0.50 48:7 58:5±0.27 68:2±0.86 20:6 10:5±1.22 16:7±0.80 33:6 43:7±1.19 51:3±1.56
T5 BASE 15:2 4:9±0.21 27:9±0.60 55:9 66:9±0.25 72:5±0.28 22:5 18:0±0.46 18:0±3.95 42:3 24:7±0.66 53:2±0.18
Con người 79:5 79:5 79:5 91:4 91:4 91:4 91:2 91:2 91:2 85:6 85:6 85:6

Bảng 2: Độ chính xác (%) của các PLMs khác nhau trên ba nhiệm vụ sử dụng các phương pháp khám phá khác nhau. ZP: Khám phá zero-shot. LP: Khám phá tuyến tính. FT: Fine-tuning. Kết quả LP và FT là Trung bình ± độ lệch chuẩn trên ba lần thử ngẫu nhiên. Hiệu suất con người được lấy bởi những người bình thường được huấn luyện với một vài trường hợp.

### 4.1 Kết quả Tổng thể

Kết quả thí nghiệm tổng thể được hiển thị trong Bảng 2, từ đó chúng ta có thể quan sát rằng: (1) Tất cả PLMs có thể đạt được hiệu suất không tầm thường (tốt hơn đoán ngẫu nhiên) trên tất cả các nhiệm vụ khám phá với khám phá zero-shot hoặc khám phá tuyến tính, điều này chỉ ra rằng PLMs hiện tại nắm bắt một kiến thức khái niệm nhất định với tiền huấn luyện trên các văn bản khổng lồ. (2) Tuy nhiên, ngay cả với fine-tuning, độ chính xác của tất cả PLMs vẫn thấp hơn nhiều so với hiệu suất con người, điều này thúc đẩy nỗ lực thêm về tiền huấn luyện nhận biết khái niệm. (3) Độ chính xác của PLMs sử dụng các loại mục tiêu tiền huấn luyện khác nhau thường ở cùng mức độ. Nó gợi ý rằng bất kỳ mục tiêu tiền huấn luyện hiện tại nào cũng không có lợi thế đặc biệt trong việc hiểu khái niệm và cải thiện thêm có thể đến từ thiết kế tiền huấn luyện có mục tiêu. Chúng tôi cung cấp một số phân tích trong các phần sau để giúp phát triển PLMs nhận biết khái niệm có mục tiêu.

### 4.2 Đánh giá Tương đồng Khái niệm

Chúng tôi phân tích các dự đoán và hiệu suất của các PLMs khác nhau trên CSJ, và thấy rằng:

PLMs phân biệt tốt hơn các khái niệm thô. Như đề cập trong § 2.2, trong số 20 thực thể phân tâm, 5 trong số chúng là những phân tâm khó của các khái niệm chia sẻ cấp cao với khái niệm của thực thể truy vấn, và những cái khác là phân tâm dễ. Ví dụ, nếu thực thể truy vấn thuộc khái niệm Mammal, các thực thể của khái niệm Bird là phân tâm khó và các thực thể của khái niệm Country là phân tâm dễ. Bảng 3 cho thấy thứ hạng tương hỗ trung bình của hai loại phân tâm này. Chúng ta có thể thấy rằng các phân tâm khó được xếp hạng cao hơn đáng kể so với phân tâm dễ, điều này chỉ ra rằng PLMs nói chung phân biệt tốt hơn các khái niệm thô, chẳng hạn như phân biệt sự khác biệt giữa Animal và Country, nhưng thất bại trong việc phân biệt các khái niệm chi tiết. Điều này gợi ý rằng các phương pháp tương lai nên tập trung nhiều hơn vào cách nắm bắt

Mô hình Phân tâm Khó Phân tâm Dễ
BERT BASE 25:1 15:7
RoBERTa BASE 25:3 15:7
GPT-2 BASE 21:1 17:0
GPT-Neo 125M 20:7 17:1
BART BASE 24:2 16:0
T5 BASE 24:6 15:9

Bảng 3: Thứ hạng tương hỗ trung bình (%) cho phân tâm khó và phân tâm dễ trên CSJ trong kết quả khám phá zero-shot của các PLMs khác nhau. Giá trị lớn hơn cho thứ hạng cao hơn.

sự khác biệt tinh tế giữa các khái niệm chi tiết.

### 4.3 Đánh giá Thuộc tính Khái niệm

Chúng tôi phân tích các trường hợp lỗi trên CPJ và thấy rằng:

Tính chuyển tiếp khái niệm thách thức PLMs. Bảng 2 cho thấy PLMs có thể đạt được độ chính xác cấp độ trường hợp cao, nhưng tất cả đều hoạt động kém trong đánh giá cấp độ chuỗi. Điều này gợi ý rằng PLMs có thể tương đối tốt trong việc nhớ lại các thuộc tính cho các khái niệm cá nhân như nhớ lại các sự thật về thực thể trong khám phá kiến thức sự thật, nhưng khó hiểu các mối quan hệ phân cấp của khái niệm và tính chuyển tiếp thuộc tính. Điều này gợi ý rằng các nghiên cứu PLM tiếp theo không chỉ nên tập trung vào ghi nhớ kiến thức tốt hơn mà còn xem xét cách tổ chức kiến thức tốt hơn.

PLMs có ảo giác khái niệm. Đã được quan sát thấy rằng PLMs thường xuyên tạo ra các đầu ra vô nghĩa và không trung thực, về mặt sự thật là không chính xác, và các nghiên cứu trước đây (Rohrbach et al., 2018; Reiter, 2018; Ji et al., 2022) gọi hiện tượng này là ảo giác. Trong các thí nghiệm của chúng tôi, chúng tôi quan sát thấy rằng nhiều trường hợp thất bại của PLMs trong nhiệm vụ CPJ có thể được mô tả như ảo giác khái niệm, tức là PLMs ảo giác rằng các khái niệm có những thuộc tính nhất định trong khi thực tế chúng không có. Như được hiển thị trong Bảng 4, các lỗi của hầu hết PLMs nói chung chủ yếu đến từ việc đưa ra dự đoán dương tính giả, tức là coi các phát biểu thuộc tính khái niệm sai là đúng. Điều này gợi ý rằng PLMs có xu hướng ảo giác các thuộc tính khái niệm sai như đúng thay vì không thể nhớ lại các thuộc tính khái niệm đúng, điều này thú vị và chúng tôi khám phá thêm xem có những tương quan giả mạo nhất định gây ra điều này hay không.

BERT RoBERTa GPT-2 GPT-Neo BART T5
78:0 72:5 64:6 52:5 65:9 58:3

Bảng 4: Tỷ lệ phần trăm (%) của dự đoán dương tính giả trong tất cả dự đoán không chính xác trong kết quả fine-tuning của các PLMs khác nhau trên tập dữ liệu CPJ.

Đồng xuất hiện từ gây ảo giác khái niệm. Chúng tôi giả định rằng đồng xuất hiện từ trong các corpus tiền huấn luyện gây ra ảo giác khái niệm của PLMs. Ví dụ, nếu một PLM đã thấy văn bản "Tòa nhà Jufu Hall của ngôi đền đã được đưa vào Danh sách Theo dõi Di tích Thế giới năm 1998 bởi Quỹ Di tích Thế giới (WMF) ...bảo tồn trang trí sơn"³, nó có thể

³https://en.wikipedia.org/wiki/Temple_of_Agriculture

--- TRANG 6 ---

0 10 20 30 40
Điểm BM25 20 40 60 80 100 Tỷ lệ Dương tính Giả (%)
R2=0.81, p=2.19 × 10^-8

Hình 3: Tỷ lệ dương tính giả của kết quả fine-tuning BERT trên các trường hợp tiêu cực CPJ với điểm BM25 khác nhau. Kết quả của các PLMs khác được để lại trong phụ lục C.1.

có xu hướng dự đoán phát biểu "Di tích được sử dụng để trang trí" là đúng. Chúng tôi tìm thấy bằng chứng thực nghiệm hỗ trợ giả thuyết này. Đối với mỗi trường hợp CPJ, để đánh giá đồng xuất hiện từ trong corpus tiền huấn luyện, chúng tôi truy xuất tài liệu tương tự nhất của nó từ Wikipedia, là corpus được sử dụng rộng rãi trong tiền huấn luyện, với thuật toán BM25 (Robertson et al., 1995) được triển khai trong Whoosh (Mchaput, 2016), và sử dụng điểm BM25 của tài liệu hàng đầu được truy xuất làm chỉ số cho tỷ lệ đồng xuất hiện từ của trường hợp CPJ này trong corpus tiền huấn luyện. Chúng tôi chia các trường hợp tiêu cực của tập dữ liệu CPJ thành các tập con khác nhau theo điểm BM25 của chúng và quan sát tỷ lệ dương tính giả của dự đoán fine-tuning BERT trên chúng. Kết quả được vẽ trong Hình 3, từ đó chúng ta có thể thấy rằng tỷ lệ dự đoán dương tính giả, chỉ ra ảo giác khái niệm, có tương quan dương mạnh với điểm BM25, chỉ ra đồng xuất hiện từ. Điều này gợi ý rằng ảo giác khái niệm của PLMs đến từ việc nắm bắt các tương quan giả mạo của đồng xuất hiện từ trong tiền huấn luyện, và các nghiên cứu tiền huấn luyện tiếp theo nên khám phá để sửa chữa nó.

### 4.4 Khái niệm hóa trong Ngữ cảnh

Chúng tôi phân tích các trường hợp lỗi trên CiC và thấy rằng:

PLMs khái niệm hóa các thực thể quá phụ thuộc vào ký ức. Trong CiC, chúng tôi thấy rằng nếu chúng tôi loại bỏ ngữ cảnh, PLMs vẫn có thể dự đoán một khái niệm có thể đúng, điều này tương tự như các nghiên cứu trước đây (Petroni et al., 2019; Roberts et al., 2020; Cao et al., 2021) cho thấy PLMs ghi nhớ một kiến thức nhất định về loại thực thể. Chúng tôi gọi các dự đoán này là dự đoán ngoài ngữ cảnh, có thể được coi như ký ức của PLMs có được trong tiền huấn luyện. Điều chúng tôi đánh giá trong CiC là khả năng khái niệm hóa trong ngữ cảnh thay vì kiến thức được ghi nhớ về các khái niệm của thực thể, được đánh giá bởi CSJ. Do đó việc dựa vào ký ức và đưa ra dự đoán ngoài ngữ cảnh là sai để xử lý CiC. Tuy nhiên, như được hiển thị trong Bảng 5, trong hầu hết các trường hợp lỗi, PLMs khái niệm hóa sai các thực thể trong ngữ cảnh như các dự đoán ngoài ngữ cảnh mặc định. Điều này chứng minh rằng PLMs khái niệm hóa các thực thể bằng cách quá phụ thuộc vào ký ức thay vì hiểu ngữ cảnh, phản ánh thiếu khả năng khái niệm hóa thực sự. Chúng tôi khuyến khích các nghiên cứu tương lai nghiên cứu xem ký ức có ức chế việc học khái niệm hóa trong tiền huấn luyện hay không.

BERT RoBERTa GPT-2 GPT-Neo BART T5
72:9 75:9 76:7 60:4 71:8 59:2

Bảng 5: Tỷ lệ phần trăm (%) của dự đoán ngoài ngữ cảnh trong tất cả dự đoán không chính xác trong kết quả khám phá zero-shot của các PLMs khác nhau trên tập dữ liệu CiC.

Hiểu hệ thống phân cấp khó hơn phân định nghĩa. Trong Bảng 6, chúng tôi phân tích hai loại lỗi trên nhiệm vụ CiC. Phân định nghĩa chỉ ra PLM chọn chuỗi khái niệm sai cho thực thể đã cho và Cấp độ Sai chỉ ra PLM chọn khái niệm cấp độ sai trong chuỗi đúng. Trong phân tích, chúng tôi chỉ xem xét các thực thể có nhiều hơn một chuỗi khái niệm. Các lỗi Cấp độ Sai chiếm đa số, cho thấy hiểu hệ thống phân cấp khái niệm khó hơn phân định nghĩa đối với PLMs và cách dạy PLMs hiểu nó là quan trọng.

### 4.5 Phân tích về Quy mô Mô hình

Lấy cảm hứng từ những tiến bộ gần đây cho thấy lợi thế vượt trội của các mô hình quy mô lớn (Kaplan et al., 2020; Lester et al., 2021), chúng tôi khám phá cách quy mô mô hình ảnh hưởng đến kiến thức khái niệm của PLMs. Chúng tôi điều tra họ của ba PLMs đại diện: BERT, GPT-2 và T5. Vì fine-tuning các PLMs cực lớn quá tốn kém về mặt tính toán, đối với các mô hình có hơn 2:5 tỷ tham số, chúng tôi thay vào đó áp dụng BitFit (Zaken et al., 2022), có thể đạt được hiệu suất tương tự như fine-tuning (He et al., 2021) nhưng yêu cầu ít tính toán hơn nhiều. Kết quả được hiển thị trong Hình 4, và chúng tôi có những quan sát sau: (1) PLMs quy mô lớn hơn nói chung đạt được hiệu suất tốt hơn trên tất cả các nhiệm vụ khám phá, điều này gợi ý rằng việc tăng quy mô mô hình có thể lưu trữ nhiều kiến thức khái niệm hơn.

--- TRANG 7 ---

Loại Lỗi Ngữ cảnh Chuỗi Khái niệm
Phân định nghĩa Ông được đề cử bởi Tổng thống Person –>BusinessPerson
29:0% Jimmy Carter lên tòa án. Person –>Writer
Person –>Politician
Cấp độ Sai Dolly đang chạy trên cỏ. Horse –>Mammal –>Animal
71:0%

Bảng 6: Ví dụ lỗi được lấy mẫu từ kết quả khám phá zero-shot của BERT BASE trên tập dữ liệu CiC. Chữ nghiêng biểu thị thực thể. Gạch chân biểu thị dự đoán mô hình. Văn bản in đậm biểu thị câu trả lời.

20 50 100 300 1,000 3,000 11,000
Triệu tham số 5 10 15 20 25 30 35 40 45 Độ chính xác (%)
Đánh giá Tương đồng Khái niệm

20 50 100 300 1,000 3,000 11,000
Triệu tham số 50 55 60 65 70 75 80 Độ chính xác (%)
Đánh giá Thuộc tính Khái niệm

20 50 100 300 1,000 3,000 11,000
Triệu tham số 25 30 35 40 45 50 55 Độ chính xác (%)
Khái niệm hóa trong Ngữ cảnh

Khám phá Zero-shot Khám phá Tuyến tính Fine-tuning BERT GPT-2 T5

Hình 4: Độ chính xác (%) của các PLMs khác nhau ở các quy mô khác nhau. Độ chính xác trên CPJ là cấp độ trường hợp.

kiến thức. Tuy nhiên, cải thiện được mang lại bởi việc tăng quy mô mô hình nói chung là biên tế, đặc biệt là trên nhiệm vụ CiC, và cải thiện trong kết quả khám phá zero-shot và khám phá tuyến tính không rõ ràng như trong fine-tuning, điều này đặt ra câu hỏi rằng liệu cải thiện fine-tuning có đến từ kiến thức nội tại của PLMs hay không. (2) Độ chính xác fine-tuning của T5 11B với 11 tỷ tham số, vẫn thấp hơn nhiều so với người bình thường, điều này chứng minh rằng việc có được kiến thức khái niệm khá thách thức đối với các phương pháp tiền huấn luyện hiện tại, điều này khuyến khích nỗ lực thêm về xây dựng PLMs nhận biết khái niệm.

## 5 Nghiên cứu Liên quan

Khám phá Kiến thức Để hiểu thành công của PLMs, các nghiên cứu mở rộng khám phá để biết PLMs biết gì, và thấy PLMs có kiến thức ngôn ngữ mạnh (Liu et al., 2019a; Hewitt and Manning, 2019; Tenney et al., 2019b; Vulić et al., 2020). Hơn nữa, đã được chứng minh rằng PLMs có kiến thức thế giới nhất định, thường được lưu trữ trong các cơ sở tri thức thế giới, chẳng hạn như kiến thức về thực thể (Broscheit, 2019; Tenney et al., 2019a) và mối quan hệ của chúng (Petroni et al., 2019; Roberts et al., 2020; Jiang et al., 2020; Bouraoui et al., 2020; Zhong et al., 2021). Tuy nhiên, những khám phá này bị giới hạn trong phạm vi kiến thức sự thật, bỏ qua kiến thức khái niệm, điều này quan trọng cho cả cơ sở tri thức (Wu et al., 2012; Ji et al., 2019) và trí tuệ (Carey, 1991; Collins and Olson, 2014). Do đó chúng tôi khám phá việc khám phá kiến thức khái niệm trong bài báo này.

Kiến thức Khái niệm trong PLMs Các nghiên cứu trước đây cũng khám phá khái niệm trong PLMs (Michael et al., 2020; Talmor et al., 2020; Aspillaga et al., 2021; Dalvi et al., 2021), nghiên cứu các chủ đề về cơ bản tương tự với chúng tôi. Tuy nhiên, khái niệm họ đề cập về cơ bản là nghĩa từ. Họ tập trung vào việc liệu PLMs có khám phá nghĩa từ và nhận ra mối quan hệ phân cấp của chúng hay không. Trong khi trong nghiên cứu này, chúng tôi nghiên cứu các khái niệm được định nghĩa trong cơ sở tri thức để trừu tượng hóa các thực thể thế giới thực, hỗ trợ các ứng dụng rộng hơn (Lv et al., 2018; Zhou et al., 2021; Zeng et al., 2021), và khám phá kiến thức về tương đồng khái niệm và thuộc tính của khái niệm cũng như khả năng khái niệm hóa của PLMs.

## 6 Kết luận và Nghiên cứu Tương lai

Trong bài báo này, chúng tôi phân tích hệ thống kiến thức khái niệm trong PLMs hiện tại bằng cách xây dựng một bộ tiêu chuẩn khám phá kiến thức khái niệm chất lượng cao (COPEN). Các thí nghiệm mở rộng cho thấy PLMs hiện tại có kiến thức khái niệm nhất định, nhưng kém hơn đáng kể so với con người, ngay cả với hàng tỷ tham số. Chúng tôi tiếp tục thấy rằng PLMs thất bại trong việc phân biệt các khái niệm chi tiết và hiểu hệ thống phân cấp khái niệm, và gặp phải ảo giác khái niệm do đồng xuất hiện từ và thiên vị ngoài ngữ cảnh. Trong tương lai, lấy cảm hứng từ các nghiên cứu truyền kiến thức sự thật, chúng tôi sẽ cố gắng phát triển PLMs có kiến thức khái niệm bằng cách khám phá các mục tiêu tiền huấn luyện nhận biết khái niệm và kiến trúc tăng cường kiến thức.

## Hạn chế

Trong phần này, chúng tôi thảo luận về các hạn chế của nghiên cứu này: (1) Bộ tiêu chuẩn COPEN. COPEN chỉ bao gồm corpus tiếng Anh, điều này giới hạn việc sử dụng bộ tiêu chuẩn cho PLMs được tiền huấn luyện trên các ngôn ngữ khác. Trong tương lai, chúng tôi sẽ xem xét thêm ngôn ngữ và xây dựng COPEN đa ngôn ngữ. (2) PLMs lớn. Chúng tôi không thí nghiệm trên các PLMs rất lớn, chẳng hạn như GPT-3 (Brown et al., 2020) và PaLM (Chowdhery et al., 2022), do quyền truy cập hạn chế của chúng tôi. Chúng tôi tiến hành thí nghiệm trên T5 11B với 11 tỷ tham số thay thế. Kết quả thí nghiệm chứng minh rằng việc có được kiến thức khái niệm khá thách thức đối với các phương pháp tiền huấn luyện hiện tại, điều này thúc đẩy các mục tiêu tiền huấn luyện nhận biết khái niệm và kiến trúc mô hình. (3) Tác động môi trường. Trong bài báo này, chúng tôi tiến hành nhiều thí nghiệm với các PLMs khác nhau, một số trong số đó thậm chí chứa vài tỷ tham số. Nó tiêu thụ lượng lớn năng lượng và gây ra lượng lớn khí thải carbon dioxide, điều này gây ảnh hưởng tiêu cực đến môi trường của chúng ta (Strubell et al., 2019). Nhưng các thí nghiệm là cần thiết để rút ra kết luận trung thực và toàn diện. Chúng tôi hy vọng phát hiện của chúng tôi có thể tạo điều kiện cho nghiên cứu sâu hơn về PLMs mạnh mẽ hơn với ít tham số hơn.

## Cân nhắc Đạo đức

Chúng tôi thảo luận các cân nhắc đạo đức và tác động rộng hơn của nghiên cứu này trong phần này: (1) Sở hữu trí tuệ. Các corpus Wikipedia, Simple Wikipedia, và Wikidata được lấy từ bản dump Wikimedia⁴, được chia sẻ dưới giấy phép CC BY-SA 3.0⁵. DBpedia⁶ được chia sẻ dưới giấy phép CC BY-SA 3.0 và GNU Free Documentation License⁷. Corpus GenericsKB⁸ được chia sẻ dưới giấy phép CC BY 4.0⁹. Đây đều là các tài nguyên công cộng và đã được thiết lập, được dự định để hỗ trợ nghiên cứu trí tuệ nhân tạo và NLP rộng rãi. Chúng tôi tin rằng các tài nguyên này đã được khử nhạy cảm và ẩn danh tốt. (2) Chú thích dữ liệu. Chúng tôi mời 19 nhà chú thích không có nền tảng chuyên môn để chú thích tập dữ liệu của chúng tôi và tạo ra hiệu suất con người. Họ đều được thuê bởi các công ty sản xuất dữ liệu thương mại. Các nhà chú thích được mời được trả công bằng theo giờ làm việc và giá cả đã thỏa thuận. Các nhà chú thích đều được thông báo về cách dữ liệu sẽ được xử lý, sử dụng và phát hành, và điều này được xác nhận trong hợp đồng sản xuất dữ liệu. (3) Sử dụng dự định. COPEN là bộ tiêu chuẩn chất lượng cao được sử dụng để đánh giá kiến thức khái niệm trong PLMs và phát triển PLMs có kiến thức khái niệm. Các nhà nghiên cứu có thể sử dụng COPEN để đánh giá các mục tiêu nhận biết khái niệm mới và kiến trúc tăng cường kiến thức khái niệm. (4) Rủi ro lạm dụng. Xem xét COPEN được xây dựng trên phạm vi hạn chế của các văn bản tự nhiên và các phương pháp khám phá không thể tránh khỏi bị ảnh hưởng bởi một số tương quan giả mạo, hiệu suất đủ tốt trên COPEN không thể hoàn toàn đảm bảo rằng các phương pháp được phát triển thực sự hiểu khái niệm và không nên được sử dụng để hỗ trợ các tuyên bố thương mại và chính trị liên quan. (5) Kiểm soát rủi ro tiềm ẩng. Các văn bản trong COPEN đến từ dữ liệu công cộng và không liên quan đến thông tin riêng tư, chủ đề nhạy cảm và vấn đề xã hội. Ba nhiệm vụ trong COPEN cũng không liên quan đến chủ đề nhạy cảm hoặc vấn đề xã hội. Chúng tôi kiểm tra thủ công một số trường hợp được lấy mẫu ngẫu nhiên trong COPEN và không thấy thông tin nhạy cảm hoặc vấn đề rủi ro khác. Do đó chúng tôi tin rằng COPEN không tạo ra rủi ro bổ sung.

⁴https://dumps.wikimedia.org/
⁵https://creativecommons.org/licenses/by-sa/3.0/
⁶www.dbpedia.org
⁷https://www.gnu.org/licenses/fdl-1.3.html
⁸https://allenai.org/data/genericskb
⁹https://creativecommons.org/licenses/by/4.0/

## Lời cảm ơn

Nghiên cứu này được hỗ trợ bởi Chương trình Nghiên cứu và Phát triển Lĩnh vực Trọng điểm của tỉnh Guangdong (2019B010153002), Viện Guo Qiang, Đại học Thanh Hoa (2019GQB0003), và Phòng thí nghiệm Noah's Ark của Huawei. Các tác giả cảm ơn tất cả các nhà đánh giá ẩn danh vì những nhận xét và đề xuất chi tiết và có giá trị của họ. Các tác giả cũng cảm ơn tất cả các nhà chú thích vì những nỗ lực đáng kể của họ trong quá trình chú thích.

--- TRANG 9 ---

## Tài liệu tham khảo

Guillaume Alain and Yoshua Bengio. 2017. Understanding intermediate layers using linear classifier probes. In Proceedings of ICLR.

Grigoris Antoniou and Frank Van Harmelen. 2004. A semantic web primer. MIT press.

Carlos Aspillaga, Marcelo Mendoza, and Alvaro Soto. 2021. Inspecting the concept knowledge graph encoded by modern language models. In Findings of ACL-IJCNLP, pages 2984–3000.

Sören Auer, Christian Bizer, Georgi Kobilarov, Jens Lehmann, Richard Cyganiak, and Zachary Ives. 2007. DBpedia: A nucleus for a web of open data. In The semantic web, pages 722–735. Springer.

Sumithra Bhakthavatsalam, Chloe Anastasiades, and Peter Clark. 2020. GenericsKB: A knowledge base of generic statements. CoRR, abs/2005.00660.

Sid Black, Leo Gao, Phil Wang, Connor Leahy, and Stella Biderman. 2021. GPT-Neo: Large Scale Autoregressive Language Modeling with Mesh-Tensorflow. Zenodo.

Zied Bouraoui, José Camacho-Collados, and Steven Schockaert. 2020. Inducing relational knowledge from BERT. In Proceedings of AAAI-IAAI-EAAI, pages 7456–7463.

Samuel Broscheit. 2019. Investigating entity knowledge in BERT with simple neural end-to-end entity linking. In Proceedings of CoNLL, pages 677–685.

Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020. Language models are few-shot learners. In Proceedings of NeurIPS, pages 1877–1901.

Boxi Cao, Hongyu Lin, Xianpei Han, Le Sun, Lingyong Yan, Meng Liao, Tong Xue, and Jin Xu. 2021. Knowledgeable or educated guess? Revisiting language models as knowledge bases. In Proceedings of ACL-IJCNLP, pages 1860–1874.

Susan Carey. 1991. Knowledge acquisition: Enrichment or conceptual change. The epigenesis of mind: Essays on biology and cognition, pages 257–291.

Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, Parker Schuh, Kensen Shi, Sasha Tsvyashchenko, Joshua Maynez, Abhishek Rao, Parker Barnes, Yi Tay, Noam Shazeer, Vinodkumar Prabhakaran, Emily Reif, Nan Du, Ben Hutchinson, Reiner Pope, James Bradbury, Jacob Austin, Michael Isard, Guy Gur-Ari, Pengcheng Yin, Toju Duke, Anselm Levskaya, Sanjay Ghemawat, Sunipa Dev, Henryk Michalewski, Xavier Garcia, Vedant Misra, Kevin Robinson, Liam Fedus, Denny Zhou, Daphne Ippolito, David Luan, Hyeontaek Lim, Barret Zoph, Alexander Spiridonov, Ryan Sepassi, David Dohan, Shivani Agrawal, Mark Omernick, Andrew M. Dai, Thanumalayan Sankaranarayana Pillai, Marie Pellat, Aitor Lewkowycz, Erica Moreira, Rewon Child, Oleksandr Polozov, Katherine Lee, Zongwei Zhou, Xuezhi Wang, Brennan Saeta, Mark Diaz, Orhan Firat, Michele Catasta, Jason Wei, Kathy Meier-Hellstern, Douglas Eck, Jeff Dean, Slav Petrov, and Noah Fiedel. 2022. PaLM: Scaling language modeling with pathways. CoRR, abs/2204.02311.

Jessica A. Collins and Ingrid R. Olson. 2014. Knowledge is power: How conceptual knowledge transforms visual cognition. Psychonomic Bulletin & Review, 21:843–860.

David Alan Cruse. 1986. Lexical semantics. Cambridge university press.

Fahim Dalvi, Abdul Rafae Khan, Firoj Alam, Nadir Durrani, Jia Xu, and Hassan Sajjad. 2021. Discovering latent concepts learned in BERT. In Proceedings of ICLR.

Stefan Decker, Sergey Melnik, Frank van Harmelen, Dieter Fensel, Michel C. A. Klein, Jeen Broekstra, Michael Erdmann, and Ian Horrocks. 2000. The semantic web: The roles of XML and RDF. IEEE Internet Comput., 4(5):63–74.

Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of deep bidirectional transformers for language understanding. In Proceedings of NAACL-HLT, pages 4171–4186.

Ramanathan V Guha, Dan Brickley, and Steve Macbeth. 2016. Schema. org: Evolution of structured data on the web. Communications of the ACM, 59(2):44–51.

Xu Han, Zhengyan Zhang, Ning Ding, Yuxian Gu, Xiao Liu, Yuqi Huo, Jiezhong Qiu, Liang Zhang, Wentao Han, Minlie Huang, et al. 2021. Pre-trained models: Past, present and future. Proceedings of AI Open.

Junxian He, Chunting Zhou, Xuezhe Ma, Taylor Berg-Kirkpatrick, and Graham Neubig. 2021. Towards a unified view of parameter-efficient transfer learning. arXiv preprint arXiv:2110.04366.

John Hewitt and Christopher D. Manning. 2019. A structural probe for finding syntax in word representations. In Proceedings of NAACL-HLT, pages 4129–4138.

--- TRANG 10 ---

Felix Hill, Roi Reichart, and Anna Korhonen. 2015. Simlex-999: Evaluating semantic models with (genuine) similarity estimation. Comput. Linguistics, 41(4):665–695.

Lei Ji, Yujing Wang, Botian Shi, Dawei Zhang, Zhongyuan Wang, and Jun Yan. 2019. Microsoft concept graph: Mining semantic concepts for short text understanding. Data Intelligence, 1(3):238–270.

Ziwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan Su, Yan Xu, Etsuko Ishii, Yejin Bang, Andrea Madotto, and Pascale Fung. 2022. Survey of hallucination in natural language generation. CoRR, abs/2202.03629.

Zhengbao Jiang, Frank F. Xu, Jun Araki, and Graham Neubig. 2020. How can we know what language models know. Trans. Assoc. Comput. Linguistics, 8:423–438.

Jared Kaplan, Sam McCandlish, Tom Henighan, Tom B Brown, Benjamin Chess, Rewon Child, Scott Gray, Alec Radford, Jeffrey Wu, and Dario Amodei. 2020. Scaling laws for neural language models. arXiv preprint arXiv:2001.08361.

Juan J. Lastra-Díaz, Josu Goikoetxea, Mohamed Ali Hadj Taieb, Ana García-Serrano, Mohamed Ben Aouicha, and Eneko Agirre. 2019. A reproducible survey on word embeddings and ontology-based methods for word similarity: Linear combinations outperform the state of the art. Eng. Appl. Artif. Intell., 85:645–665.

Brian Lester, Rami Al-Rfou, and Noah Constant. 2021. The power of scale for parameter-efficient prompt tuning. In Proceedings of EMNLP, pages 3045–3059.

Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Veselin Stoyanov, and Luke Zettlemoyer. 2020. BART: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension. In Proceedings of ACL, pages 7871–7880.

Nelson F. Liu, Matt Gardner, Yonatan Belinkov, Matthew E. Peters, and Noah A. Smith. 2019a. Linguistic knowledge and transferability of contextual representations. In Proceedings of NAACL-HLT, pages 1073–1094.

Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi, and Graham Neubig. 2021a. Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing. CoRR, abs/2107.13586.

Xiao Liu, Yanan Zheng, Zhengxiao Du, Ming Ding, Yujie Qian, Zhilin Yang, and Jie Tang. 2021b. GPT understands, too. CoRR, abs/2103.10385.

Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. 2019b. RoBERTa: A robustly optimized BERT pretraining approach. CoRR, abs/1907.11692.

Xin Lv, Lei Hou, Juanzi Li, and Zhiyuan Liu. 2018. Differentiating concepts and instances for knowledge graph embedding. In Proceedings of EMNLP, pages 1971–1979.

Deborah L McGuinness, Frank Van Harmelen, et al. 2004. Owl web ontology language overview. W3C recommendation, 10(10):2004.

Mchaput. 2016. Mchaput/whoosh: Pure-python full-text search library. GitHub.

Julian Michael, Jan A. Botha, and Ian Tenney. 2020. Asking without telling: Exploring latent ontologies in contextual representations. In Proceedings of EMNLP, pages 6792–6812.

Gregory Murphy. 2004. The big book of concepts. MIT press.

Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. Glove: Global vectors for word representation. In Proceedings of EMNLP, pages 1532–1543.

Fabio Petroni, Tim Rocktäschel, Sebastian Riedel, Patrick Lewis, Anton Bakhtin, Yuxiang Wu, and Alexander Miller. 2019. Language models as knowledge bases? In Proceedings of EMNLP-IJCNLP, pages 2463–2473.

Lutz Prechelt. 1996. Early stopping-but when? In Genevieve B. Orr and Klaus-Robert Müller, editors, Neural Networks: Tricks of the Trade, volume 1524 of Lecture Notes in Computer Science, pages 55–69. Springer.

Xipeng Qiu, Tianxiang Sun, Yige Xu, Yunfan Shao, Ning Dai, and Xuanjing Huang. 2020. Pre-trained models for natural language processing: A survey. Science China Technological Sciences, 63(10):1872–1897.

Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al. 2019. Language models are unsupervised multitask learners. OpenAI blog, 1(8):9.

Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J. Liu. 2020. Exploring the limits of transfer learning with a unified text-to-text transformer. J. Mach. Learn. Res., 21:140:1–140:67.

Ehud Reiter. 2018. Hallucination in Neural NLG. Ehud Reiter's Blog.

Adam Roberts, Colin Raffel, and Noam Shazeer. 2020. How much knowledge can you pack into the parameters of a language model? In Proceedings of EMNLP, pages 5418–5426.

--- TRANG 11 ---

Stephen E Robertson, Steve Walker, Susan Jones, Micheline M Hancock-Beaulieu, Mike Gatford, et al. 1995. Okapi at TREC-3. Nist Special Publication Sp, 109:109.

Anna Rohrbach, Lisa Anne Hendricks, Kaylee Burns, Trevor Darrell, and Kate Saenko. 2018. Object Hallucination in Image Captioning. In Proceedings of EMNLP, pages 4035–4045.

John F Sowa. 1976. Conceptual graphs for a data base interface. IBM Journal of Research and Development, 20(4):336–357.

Emma Strubell, Ananya Ganesh, and Andrew McCallum. 2019. Energy and policy considerations for deep learning in NLP. In Proceedings of ACL, pages 3645–3650.

Fabian M. Suchanek, Gjergji Kasneci, and Gerhard Weikum. 2007. Yago: a core of semantic knowledge. In Proceedings of WWW, pages 697–706.

Alon Talmor, Yanai Elazar, Yoav Goldberg, and Jonathan Berant. 2020. oLMpics - On what Language Model Pre-training Captures. Trans. Assoc. Comput. Linguistics, 8:743–758.

Ian Tenney, Dipanjan Das, and Ellie Pavlick. 2019a. BERT Rediscovers the Classical NLP Pipeline. In Proceedings of ACL, pages 4593–4601.

Ian Tenney, Patrick Xia, Berlin Chen, Alex Wang, Adam Poliak, R. Thomas McCoy, Najoung Kim, Benjamin Van Durme, Samuel R. Bowman, Dipanjan Das, and Ellie Pavlick. 2019b. What do you learn from context? Probing for sentence structure in contextualized word representations. In Proceedings of ICLR.

Denny Vrandečić. 2012. Wikidata: A new platform for collaborative data collection. In Proceedings of WWW, pages 1063–1064.

Denny Vrandečić and Markus Krötzsch. 2014. Wikidata: A free collaborative knowledgebase. Communications of the ACM, 57(10):78–85.

Ivan Vulić, Edoardo Maria Ponti, Robert Litschko, Goran Glavaš, and Anna Korhonen. 2020. Probing Pretrained Language Models for Lexical Semantics. In Proceedings of EMNLP, pages 7222–7240.

Sandra R. Waxman and Dana Markow. 1995. Words as Invitations to Form Categories: Evidence from 12- to 13-Month-Old Infants. Cognitive Psychology, 29:257–302.

Michele Wellsby and Penny M. Pexman. 2014. Developing embodied cognition: Insights from children's concepts and language processing. Frontiers in Psychology, 5.

Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Remi Louf, Morgan Funtowicz, Joe Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest, and Alexander Rush. 2020. Transformers: State-of-the-art natural language processing. In Proceedings of EMNLP, pages 38–45.

Wentao Wu, Hongsong Li, Haixun Wang, and Kenny Q Zhu. 2012. Probase: A probabilistic taxonomy for text understanding. In Proceedings of the 2012 ACM SIGMOD International Conference on Management of Data, pages 481–492.

Elad Ben Zaken, Yoav Goldberg, and Shauli Ravfogel. 2022. Bitfit: Simple parameter-efficient fine-tuning for transformer-based masked language-models. In Proceedings of ACL, pages 1–9.

Kaisheng Zeng, Chengjiang Li, Yan Qi, Xin Lv, Lei Hou, Guozheng Peng, Juanzi Li, and Ling Feng. 2021. Encoding the meaning triangle (object, entity, and concept) as the semantic foundation for entity alignment. In Proceedings of WISE, pages 227–241.

Zexuan Zhong, Dan Friedman, and Danqi Chen. 2021. Factual probing is [MASK]: Learning vs. learning to recall. In Proceedings of NAACL-HLT, pages 5017–5033.

Jie Zhou, Shengding Hu, Xin Lv, Cheng Yang, Zhiyuan Liu, Wei Xu, Jie Jiang, Juanzi Li, and Maosong Sun. 2021. KACC: A multi-task benchmark for knowledge abstraction, concretization and completion. In Findings of ACL-IJCNLP, pages 1751–1763.

--- TRANG 12 ---

## Phụ lục

Mô hình model_name
BERT SMALL prajjwal1/bert-small
BERT MEDIUM prajjwal1/bert-medium
BERT BASE bert-base-uncased
BERT LARGE bert-large-uncased
RoBERTa BASE roberta-base
GPT-2 BASE gpt2
GPT-2 MEDIUM gpt2-medium
GPT-2 LARGE gpt2-large
GPT-2 XL gpt2-xl
GPT-Neo 125M EleutherAI/gpt-neo-125M
BART BASE facebook/bart-base
T5 SMALL t5-small
T5 BASE t5-base
T5 LARGE t5-large
T5 3B t5-3b
T5 11B t5-11b

Bảng 7: Các model_name tương ứng trong thư viện Transformers (Wolf et al., 2020) cho các PLMs khác nhau.

### A Chi tiết Triển khai

Chúng tôi sử dụng mã triển khai và tham số được tiền huấn luyện của PLMs được phát hành trong thư viện HuggingFace Transformers (Wolf et al., 2020) để chạy các thí nghiệm của chúng tôi. Các model_name chúng tôi sử dụng trong Transformers cho các PLMs khác nhau được hiển thị trong Bảng 7. Chúng tôi chạy thí nghiệm cho các mô hình lớn (T5 3B, và T5 11B) trên GPU NVIDIA V100, tiêu thụ khoảng 160 giờ GPU, và các PLMs khác trên GPU Nvidia GEFORCE RTX 3090, tiêu thụ khoảng 300 giờ GPU. Chúng tôi sẽ giới thiệu chi tiết triển khai cho khám phá zero-shot (phụ lục A.1), khám phá tuyến tính (phụ lục A.2), và fine-tuning (phụ lục A.3).

#### A.1 Khám phá Zero-Shot

Như đề cập trong § 3.2, chúng tôi lấy các phần văn bản khác nhau của lời nhắc vào tính toán chấm điểm. Bảng 8 hiển thị các phần văn bản được sử dụng bởi các PLMs khác nhau để chấm điểm lời nhắc trên ba tập dữ liệu.

#### A.2 Khám phá Tuyến tính

Chúng tôi sử dụng đầu ra cuối cùng của các token cụ thể làm đặc trưng được trích xuất bởi PLMs: [CLS] cho BERT; <s> cho RoBERTa; token cuối cùng cho GPT-2, GPT-Neo, và BART; token đầu tiên cho T5. Sau đó chúng tôi điều chỉnh một bộ phân loại tuyến tính nhẹ trên các đặc trưng cố định cho BERT, RoBERTa, GPT-2, GPT-Neo, BART và điều chỉnh đầu phân loại từ vựng cuối cùng cho T5. Hơn nữa, chúng tôi chuyển đổi các trường hợp gốc thành định dạng text-to-text cho T5, và định dạng đầu vào và đầu ra được hiển thị trong Bảng 9.

Mô hình CSJ CPJ CiC
BERT BASE Query Entity Concept All
RoBERTa BASE Query Entity Concept Concept
GPT-2 BASE All All Concept
GPT-Neo 125M All Concept Concept
BART BASE Query Entity Concept Concept
T5 BASE Query Entity Concept All

Bảng 8: Các phần văn bản được sử dụng để tính điểm của lời nhắc trong khám phá zero-shot trên ba tập dữ liệu. All: sử dụng perplexity âm của lời nhắc làm điểm. Ý nghĩa của các phần văn bản khác được hiển thị trong Hình 2.

Siêu tham số Chúng tôi đặt tốc độ học là 1×10^-3 và áp dụng early stopping (Prechelt, 1996) trên độ chính xác trên tập dữ liệu phát triển với patience là 20 epochs. Chúng tôi giữ các siêu tham số khác giống như trong Bảng 10.

#### A.3 Fine-Tuning

Chúng tôi tuân theo các phương pháp fine-tuning trong các bài báo gốc để fine-tune BERT (Devlin et al., 2019), RoBERTa (Liu et al., 2019b), GPT-2 (Radford et al., 2019), GPT-Neo (Black et al., 2021), và BART (Lewis et al., 2020). Như trong phụ lục A.2, chúng tôi chuyển đổi các trường hợp gốc thành định dạng text-to-text cho T5 (Raffel et al., 2020), và định dạng đầu vào và đầu ra được hiển thị trong Bảng 9.

Siêu tham số Chúng tôi tuân theo các siêu tham số được sử dụng chủ yếu trong tài liệu trước đây. Các siêu tham số được hiển thị trong Bảng 10. Và chúng tôi áp dụng early stopping (Prechelt, 1996) trên độ chính xác trên tập dữ liệu phát triển.

Điều chỉnh Hiệu quả Tham số cho Mô hình Lớn Do giới hạn tính toán, chúng tôi xem xét điều chỉnh hiệu quả tham số cho các mô hình có hơn 2:5 tỷ tham số (T5 3B và T5 11B). Các nghiên cứu trước đây (He et al., 2021) đã chứng minh rằng các phương pháp điều chỉnh hiệu quả tham số có thể tiết kiệm bộ nhớ GPU, tăng tốc huấn luyện cho PLMs, và đạt được hiệu suất tương đương với fine-tuning tất cả tham số, đặc biệt ở quy mô lớn. Do đó, chúng tôi áp dụng BitFit (Zaken et al., 2022) được triển khai bởi OpenDelta¹⁰ để fine-tune các mô hình lớn.

¹⁰https://github.com/thunlp/OpenDelta

### B Thêm Thảo luận về Kết quả Thí nghiệm

Trong phần này, chúng tôi thảo luận một số quan sát chi tiết và thú vị.

--- TRANG 13 ---

Đánh giá Tương đồng Khái niệm
Gốc Query: Inter Milan
Gốc Candidates: Milan, Milan Fashion Week, Pohang Steelers, Series A
Gốc Label: Pohang Steelers
Processed Input: choose the most similar entity to Inter Milan: (A) Milan, (B) Milan Fashion Week, (C) Pohang Steelers, (D) Series A.
Processed Label: C

Đánh giá Thuộc tính Khái niệm
Gốc Statement: Mammals raise their young on milk.
Gốc Label: True
Processed Input: verify: Mammals raise their young on milk.
Processed Label: true

Khái niệm hóa trong Ngữ cảnh
Gốc Context: Dolly is running on the grassland.
Concept Chain: Horse –> Mammal –> Animal
Gốc Label: Animal
Processed Input: select concept: <entity> Dolly </entity> is running on the grassland. Select a contextually related concept for Dolly from (A) Horse, (B) Mammal, (C) Animal.
Processed Label: C

Bảng 9: Định dạng đầu vào và đầu ra được sử dụng để khám phá tuyến tính và fine-tune T5 trên ba tập dữ liệu.

CSJ CPJ CiC
The Others T5 The Others T5 The Others T5
Learning Rate 3×10^-5 5×10^-5 3×10^-5 5×10^-5 3×10^-5 5×10^-5
Weight Decay 1×10^-5 1×10^-5 1×10^-5 1×10^-5 1×10^-5 1×10^-5
Batch Size 4 16 64 32 4 16
Warmup Rate 0:1 0:1 0:1 0:1 0:1 0:1

Bảng 10: Siêu tham số được sử dụng để fine-tune PLMs trên COPEN.

CSJ CPJ CiC
Query Entity Candidate Entity All Concept Answer All Concept All
BERT SMALL 15:0 6:5 8:1 50:7 48:5 51:5 31:9 35:1
BERT MEDIUM 16:8 7:2 10:0 49:3 46:7 49:2 29:6 33:3
BERT BASE 20:3 7:5 11:3 49:4 47:2 49:2 32:6 37:6
BERT LARGE 22:3 8:2 13:4 50:5 47:6 50:4 31:1 36:9
RoBERTa BASE 15:5 5:1 10:0 49:2 46:7 47:6 31:4 25:5
GPT-2 BASE 2:9 6:6 7:9 49:4 48:4 51:5 32:3 31:1
GPT-2 MEDIUM 3:7 8:6 10:5 52:0 47:2 47:2 30:3 32:0
GPT-2 LARGE 4:6 9:0 11:3 51:8 47:3 47:2 34:3 33:8
GPT-2 XL 3:9 9:6 11:7 50:7 47:2 47:1 35:3 37:0
GPT-Neo 125M 2:6 6:6 7:9 52:2 47:2 47:6 32:6 28:8
BART BASE 14:4 5:0 7:1 48:7 48:4 48:0 33:6 27:4
T5 SMALL 11:6 5:4 6:5 52:5 47:6 53:2 34:9 40:1
T5 BASE 15:2 7:2 10:3 55:9 47:2 49:5 39:1 42:3
T5 LARGE 20:9 7:8 14:0 52:4 47:2 49:8 40:5 42:6
T5 3B 19:2 7:9 14:1 49:4 47:7 49:4 38:6 47:0
T5 11B 24:8 7:8 14:5 46:7 46:7 49:9 37:2 41:3

Bảng 11: Độ chính xác khám phá zero-shot tổng thể (%) của việc sử dụng các phần văn bản khác nhau để chấm điểm lời nhắc trên COPEN.

--- TRANG 14 ---

[Bảng 12 tiếp tục với nhiều hàng dữ liệu hiệu suất cho Linear Probing và Fine-tuning với các mô hình khác nhau và ba loại nhiệm vụ CSJ, CPJ, CiC - bao gồm cả mean và standard deviation cho nhiều seeds]

Bảng 12: Độ chính xác khám phá tuyến tính và fine-tuning tổng thể (%) của tất cả PLMs trên COPEN. Chúng tôi chạy thí nghiệm 3 lần sử dụng ba seeds: 42,43,44. Mean: độ chính xác trung bình của ba lần thử; Std: độ lệch chuẩn.

--- TRANG 15 ---

So sánh Phương pháp Tiền huấn luyện Trong Hình 2, chúng ta có thể quan sát rằng: (1) Đối với PLMs sử dụng cùng kiến trúc, T5 nói chung vượt trội hơn BART, và BERT nói chung vượt trội hơn RoBERTa. Sự khác biệt có thể đến từ các corpus tiền huấn luyện khác nhau. (2) Autoregressive LMs (GPT-2, GPT-Neo) hoạt động kém hơn trên CSJ, điều này phù hợp với các quan sát về khám phá kiến thức sự thật (Liu et al., 2021b). Vì chúng tôi là những người đầu tiên nghiên cứu kiến thức khái niệm trong PLMs, chúng tôi tập trung vào câu hỏi chung "PLMs hiện tại hiểu kiến thức khái niệm ở mức độ nào?" và cung cấp các kết luận tổng quát hơn trong bài báo. Chúng tôi để lại phân tích chi tiết và sâu sắc về một PLM cụ thể, ví dụ như phân tích theo lớp (Dalvi et al., 2021), cho các nghiên cứu tương lai.

So sánh Phương pháp Khám phá Một cách trực quan, khám phá zero-shot phản ánh giới hạn dưới của kiến thức PLMs (Jiang et al., 2020), trong khi khám phá tuyến tính học một bộ phân loại tuyến tính cụ thể cho nhiệm vụ và hoạt động tốt hơn khám phá zero-shot, và fine-tuning phản ánh giới hạn trên của kiến thức PLMs. Tuy nhiên, như được hiển thị trong Hình 2, khám phá tuyến tính đôi khi kém hiệu suất hơn khám phá zero-shot, đặc biệt trong CSJ và CPJ cấp độ chuỗi. Lý do có thể là các khái niệm được sử dụng cho huấn luyện và thử nghiệm là rời rạc, và khám phá tuyến tính liên quan đến các tham số có thể huấn luyện, có thể học các tương quan giả mạo hoặc nông trên tập huấn luyện và do đó gặp khó khăn trong tổng quát hóa. Trong khi đó, fine-tuning vẫn hoạt động kém, điều này chứng minh rằng PLMs hiện tại thiếu hệ thống kiến thức khái niệm.

So sánh CPJ Cấp độ Trường hợp và Cấp độ Chuỗi Đối với cấp độ chuỗi, BERT hoạt động tốt nhất, nhưng đối với cấp độ trường hợp hoạt động kém hơn T5. Lý do có thể là BERT hiểu tốt hơn tính chuyển tiếp khái niệm (tức là đưa ra dự đoán nhất quán hơn) nhưng lưu trữ ít thuộc tính khái niệm tổng thể hơn. Cần có phân tích kỹ lưỡng và toàn diện về hiện tượng này và chúng tôi để lại cho các nghiên cứu tương lai.

### C Kết quả Thí nghiệm Bổ sung

Bảng 11 hiển thị kết quả khám phá zero-shot tổng thể trên COPEN. Kết quả thí nghiệm của khám phá tuyến tính và fine-tuning được lấy trong 3 lần thử ngẫu nhiên sử dụng seeds 42,43,44. Bảng 12 hiển thị kết quả khám phá tuyến tính và fine-tuning tổng thể trên COPEN. Và chúng tôi cung cấp kết quả bổ sung cho các thí nghiệm phân tích: phân tích ảo giác khái niệm

Mô hình Disambiguation Wrong Level
BERT BASE 29:0% 71:0%
RoBERTa BASE 12:8% 87:2%
GPT-2 BASE 12:5% 87:5%
GPT-Neo 125M 11:9% 88:1%
BART BASE 11:5% 88:5%
T5 BASE 32:0% 68:0%

Bảng 13: Tỷ lệ các loại lỗi khác nhau của kết quả khám phá zero-shot trên tập dữ liệu CiC. Chúng tôi chỉ xem xét các thực thể có nhiều hơn một chuỗi khái niệm.

trên tập dữ liệu CPJ (phụ lục C.1), phân tích lỗi trên tập dữ liệu CiC (phụ lục C.2), và phân tích về tránh các artifact tập dữ liệu (phụ lục C.3).

#### C.1 Ảo giác Khái niệm trên CPJ

Hình 5 hiển thị tỷ lệ âm tính giả trên các tập con với điểm BM25 khác nhau cho các PLMs khác nhau. Chúng ta có thể quan sát thấy rằng tỷ lệ dương tính giả, chỉ ra ảo giác khái niệm, có tương quan dương mạnh với điểm BM25, chỉ ra đồng xuất hiện từ.

#### C.2 Phân tích Lỗi trên CiC

Bảng 13 hiển thị tỷ lệ các loại lỗi khác nhau. Chúng ta có thể quan sát thấy rằng trong hầu hết dự đoán sai, PLMs chọn các khái niệm cấp độ sai. Điều này chỉ ra rằng PLMs thiếu hiểu biết toàn diện về hệ thống phân cấp khái niệm và thất bại trong việc khái niệm hóa các thực thể theo ngữ cảnh.

#### C.3 Phân tích về Tránh Artifact Tập dữ liệu

Các artifact tập dữ liệu rò rỉ thông tin nông và khiến PLMs học các tương quan giả mạo thay vì thể hiện kiến thức nội tại. Khi xây dựng COPEN, chúng tôi tránh hai loại artifact:

Chồng chéo Từ vựng có nghĩa là truy vấn và câu trả lời có chồng chéo từ, có thể cho phép PLMs đưa ra dự đoán chính xác bằng cách sử dụng tương quan giả mạo mà không có kiến thức chính xác. Ví dụ, trong CSJ, nếu thực thể truy vấn là Stanford University và thực thể trả lời là University of California; trong CiC, nếu ngữ cảnh là She graduated from Stanford University và khái niệm trả lời là University; chúng có chồng chéo từ vựng.

Chúng tôi tiến hành thí nghiệm trên dữ liệu có chồng chéo từ vựng. Như được hiển thị trong Bảng 14, trên dữ liệu có chồng chéo từ vựng, PLMs hoạt động tốt hơn nhiều. Nhưng điều này nên được diễn giải là chúng học các manh mối nông bị rò rỉ bởi artifact vì chúng không thể đạt được hiệu suất tương tự trên dữ liệu không có chồng chéo từ vựng.

Mô hình CSJ CiC
w/ LO w/o LO w/ LO w/o LO
BERT BASE 68:9 20:3 52:5 37:6
RoBERTa BASE 62:2 15:5 48:5 31:4
GPT-2 BASE 34:2 7:9 43:8 32:3
GPT-Neo 125M 34:0 7:9 52:4 32:6
BART BASE 75:9 14:4 53:2 33:6
T5 BASE 69:2 15:2 62:7 42:3

Bảng 14: Độ chính xác khám phá zero-shot (%) của PLMs trên dữ liệu có chồng chéo từ vựng (w/ LO) và không có chồng chéo từ vựng (w/o LO). Chúng tôi thu thập 688 và 1;200 trường hợp có chồng chéo từ vựng cho CSJ và CiC, tương ứng.

lập. Do đó, chúng tôi lọc ra tất cả các trường hợp có chồng chéo từ vựng trong COPEN để tránh loại artifact này.

Chồng chéo Khái niệm là các khái niệm giống nhau xuất hiện trong cả tập dữ liệu huấn luyện và thử nghiệm, có thể rò rỉ kiến thức khái niệm, tức là PLMs có thể học một số kiến thức từ dữ liệu huấn luyện. Trong COPEN, như đề cập trong § 2.1, chúng tôi chia các khái niệm cấp cao khác nhau và các khái niệm con của chúng thành các tập dữ liệu con khác nhau, để tránh chồng chéo khái niệm. Để chứng minh thực nghiệm ảnh hưởng của chồng chéo khái niệm, chúng tôi chia lại ngẫu nhiên các tập dữ liệu thành các tập huấn luyện, phát triển và thử nghiệm cùng kích thước và xem hiệu suất fine-tuning trên phân chia mới.

Kết quả fine-tuning BERT được hiển thị trong Hình 6, và kết quả fine-tuning và khám phá tuyến tính cho tất cả PLMs được hiển thị trong Bảng 15. Fine-tuning trên tập dữ liệu có chồng chéo khái niệm đạt được độ chính xác cao hơn nhiều, đặc biệt trên CSJ. Điều này chỉ ra rằng nếu chúng ta không tránh chồng chéo khái niệm, PLMs có thể dễ dàng học kiến thức khái niệm từ dữ liệu huấn luyện và dẫn đến kết luận lạc quan sai lầm.

CSJ CPJ CiC
30 40 50 60 70 Độ chính xác (%)
w/o concept overlap
w/ concept overlap

Hình 6: Độ chính xác fine-tuning của BERT BASE trên dữ liệu có và không có chồng chéo khái niệm.

--- TRANG 16 ---

Mô hình CSJ CPJ CiC
w/ CO w/o CO w/ CO w/o CO w/ CO w/o CO
Khám phá Tuyến tính
BERT BASE 20:0 16:1 64:1 61:6 46:5 34:3
RoBERTa BASE 12:3 12:0 65:9 61:9 45:4 30:0
GPT-2 BASE 5:2 4:3 67:2 64:8 39:0 34:5
GPT-Neo 125M 15:4 11:0 64:6 62:2 58:3 39:6
BART BASE 9:4 8:4 62:6 58:5 50:2 43:7
T5 BASE 4:7 4:9 68:8 66:9 33:9 24:7
Fine-tuning
BERT BASE 63:4 27:3 75:4 68:1 65:4 49:5
RoBERTa BASE 61:0 22:3 77:0 72:0 66:6 52:6
GPT-2 BASE 49:9 20:1 72:7 70:4 65:4 54:2
GPT-Neo 125M 44:3 18:3 71:2 68:2 62:5 47:4
BART BASE 54:7 21:0 73:1 68:2 67:4 51:3
T5 BASE 50:6 27:9 77:6 72:5 67:6 53:2

Bảng 15: Độ chính xác (%) của khám phá tuyến tính và fine-tuning trên dữ liệu có chồng chéo khái niệm (w/ CO) và không có chồng chéo khái niệm (w/o CO).

## D COPEN

Chúng tôi cung cấp giới thiệu chi tiết về COPEN.

### D.1 Phân loại COPEN

Các Khái niệm Rời rạc Chúng tôi chia tất cả các khái niệm thành hai tập rời rạc: một tập chứa 11 khái niệm cấp cao cùng với tất cả các khái niệm con của chúng để xây dựng tập dữ liệu huấn luyện và phát triển,

#Khái niệm Khái niệm Cấp cao
Huấn luyện& 248 Organisation, Name, Award, MeanOfTransportation, Colour, Language, Person,
Phát triển Holiday, Work, Currency, EthnicGroup
Thử nghiệm 198 AnatomicalStructure, Species, Food, Event, TimePeriod, ChemicalSubstance,
Place, Device, Disease, Activity, Biomolecule, SportsSeason

Bảng 16: Các khái niệm cấp cao và số lượng khái niệm được sử dụng cho huấn luyện, phát triển, và thử nghiệm.

và tập khác chứa các khái niệm khác cho tập dữ liệu thử nghiệm. Như được hiển thị trong Bảng 16, có 248 khái niệm bao gồm 11 khái niệm cấp cao cho tập dữ liệu huấn luyện và phát triển và 198 khái niệm bao gồm 12 khái niệm cấp cao cho thử nghiệm.

Hệ thống Phân cấp Khái niệm Chúng tôi trình bày các khái niệm cho tập dữ liệu huấn luyện và phát triển trong Hình 7 và các khái niệm cho tập dữ liệu thử nghiệm trong Hình 8. Object là khái niệm ảo để trực quan hóa và không được bao gồm trong tổng số 446 khái niệm.

### D.2 Đánh giá Tương đồng Khái niệm

Hiệu suất Con người Chúng tôi lấy mẫu 1;000 trường hợp từ tập dữ liệu thử nghiệm và mời các nhà chú thích không có nền tảng ngôn ngữ học thực hiện nhiệm vụ CSJ. Tất cả các nhà chú thích đều được huấn luyện với một vài trường hợp trước khi đánh giá.

Lọc dựa trên Đồng xuất hiện Chúng tôi lọc ra các trường hợp mà thực thể truy vấn và thực thể trả lời có liên kết cao, được ước tính bằng độ tương tự cosine của word embeddings Glove của chúng. Cụ thể, đối với một thực thể truy vấn, chúng tôi lấy mẫu 5 thực thể trả lời và chọn thực thể có liên kết thấp nhất với thực thể truy vấn làm thực thể trả lời. Sau đó chúng tôi chọn các thực thể phân tâm một cách lặp đi lặp lại theo các quy tắc: (1) Lấy mẫu một thực thể phân tâm, nếu thực thể có liên kết cao hơn với thực thể truy vấn so với thực thể trả lời, thì chọn thực thể phân tâm làm thực thể ứng viên. (2) Nếu không, chọn thực thể phân tâm làm thực thể ứng viên với xác suất 20%, nếu không bắt đầu lần lặp tiếp theo cho đến khi số lượng thực thể phân tâm đạt 20.

### D.3 Đánh giá Thuộc tính Khái niệm

Chú thích Con người Chúng tôi mời các nhà chú thích không có nền tảng ngôn ngữ học kiểm tra xem các trường hợp có được gắn nhãn đúng, đúng ngữ pháp và mô tả thuộc tính khái niệm hay không. Tất cả các nhà chú thích đều được đào tạo tốt và phải vượt qua bài kiểm tra trước khi chú thích. Các trường hợp ban đầu được gắn nhãn là sai được chú thích 4 lần, và các trường hợp khác được chú thích một lần. Trong quá trình chú thích, một tác giả của bài báo và một nhà chú thích có kinh nghiệm khác riêng biệt lấy mẫu 10% các trường hợp để kiểm tra chất lượng chú thích. Tiêu chí chấp nhận của chú thích là tỷ lệ phần trăm lỗi chú thích rõ ràng trong các trường hợp được lấy mẫu (ví dụ: gắn nhãn phát biểu The sun has two eyes là đúng) không vượt quá 3%, và tỷ lệ thỏa thuận giữa các nhà chú thích vượt quá 85% cho các trường hợp được chú thích 4 lần. Kết quả bỏ phiếu đa số của các trường hợp được chú thích 4 lần cùng với các trường hợp được chú thích một lần tạo thành tập dữ liệu CPJ.

Hiệu suất Con người Chúng tôi sử dụng 2;159 trường hợp được chú thích 4 lần trong tập dữ liệu thử nghiệm để đánh giá hiệu suất con người. Chúng tôi tiến hành đánh giá 4 vòng: lấy kết quả bỏ phiếu đa số của 3 nhà chú thích làm nhãn và nhà chú thích còn lại làm dự đoán con người để tính độ chính xác của vòng. Độ chính xác trung bình của 4 vòng được báo cáo làm độ chính xác con người trên tập dữ liệu CPJ.

### D.4 Khái niệm hóa trong Ngữ cảnh

Chú thích Con người Chúng tôi mời các nhà chú thích không có nền tảng ngôn ngữ học chú thích tập dữ liệu. Để đảm bảo chất lượng, tất cả các nhà chú thích đều được đào tạo tốt và phải vượt qua bài kiểm tra trước khi chú thích. Tất cả các trường hợp được chú thích bốn lần. Hơn nữa, trong quá trình chú thích, một tác giả của bài báo và một nhà chú thích có kinh nghiệm khác riêng biệt lấy mẫu 10% các ví dụ để kiểm tra chất lượng chú thích. Tiêu chí chấp nhận của chú thích là tỷ lệ phần trăm lỗi chú thích rõ ràng (ví dụ: Chọn Horse cho Dolly theo ngữ cảnh Dolly is running on the grassland.) không vượt quá 3%, và tỷ lệ thỏa thuận giữa các nhà chú thích vượt quá 80%. Kết quả bỏ phiếu đa số của 4 kết quả chú thích tạo thành tập dữ liệu CiC cuối cùng.

Hiệu suất Con người Chúng tôi sử dụng tất cả các trường hợp trong tập dữ liệu thử nghiệm, được chú thích 4 lần, để đánh giá hiệu suất con người. Chúng tôi tiến hành đánh giá 4 vòng: lấy kết quả bỏ phiếu đa số của 3 nhà chú thích làm nhãn và nhà chú thích còn lại làm dự đoán con người để tính độ chính xác của vòng. Độ chính xác trung bình của 4 vòng là độ chính xác con người.

--- TRANG 17 ---

0 10 20 30 40
Điểm BM25 20 40 60 80 100 Tỷ lệ Dương tính Giả (%)
R2=0.81, p=2.19 × 10^-8
BERT BASE

0 10 20 30 40
Điểm BM25 10 20 30 40 50 60 Tỷ lệ Dương tính Giả (%)
R2=0.56, p=9.09 × 10^-5
GPT2 BASE

0 10 20 30 40
Điểm BM25 10 20 30 40 50 60 70 80 90 Tỷ lệ Dương tính Giả (%)
R2=0.88, p=3.35 × 10^-10
BART BASE

0 10 20 30 40
Điểm BM25 10 20 30 40 50 60 70 80 Tỷ lệ Dương tính Giả (%)
R2=0.83, p=8.03 × 10^-9
RoBERTa BASE

0 10 20 30 40
Điểm BM25 10 20 30 40 50 60 Tỷ lệ Dương tính Giả (%)
R2=0.65, p=9.66 × 10^-6
GPT Neo BASE

0 10 20 30 40
Điểm BM25 10 20 30 40 50 60 70 Tỷ lệ Dương tính Giả (%)
R2=0.81, p=2.40 × 10^-8
T5 BASE

Hình 5: Tỷ lệ dương tính giả của kết quả fine-tuning các PLMs khác nhau trên các trường hợp tiêu cực của tập dữ liệu CPJ với điểm BM25 khác nhau.

Mô hình CSJ CiC
w/ LO w/o LO w/ LO w/o LO
BERT BASE 68:9 20:3 52:5 37:6
RoBERTa BASE 62:2 15:5 48:5 31:4
GPT-2 BASE 34:2 7:9 43:8 32:3
GPT-Neo 125M 34:0 7:9 52:4 32:6
BART BASE 75:9 14:4 53:2 33:6
T5 BASE 69:2 15:2 62:7 42:3

Bảng 14: Độ chính xác khám phá zero-shot (%) của PLMs trên dữ liệu có chồng chéo từ vựng (w/ LO) và không có chồng chéo từ vựng (w/o LO). Chúng tôi thu thập 688 và 1;200 trường hợp có chồng chéo từ vựng cho CSJ và CiC, tương ứng.

lập. Do đó, chúng tôi lọc ra tất cả các trường hợp có chồng chéo từ vựng trong COPEN để tránh loại artifact này.

Chồng chéo Khái niệm là các khái niệm giống nhau xuất hiện trong cả tập dữ liệu huấn luyện và thử nghiệm, có thể rò rỉ kiến thức khái niệm, tức là PLMs có thể học một số kiến thức từ dữ liệu huấn luyện. Trong COPEN, như đề cập trong § 2.1, chúng tôi chia các khái niệm cấp cao khác nhau và các khái niệm con của chúng thành các tập dữ liệu con khác nhau, để tránh chồng chéo khái niệm. Để chứng minh thực nghiệm ảnh hưởng của chồng chéo khái niệm, chúng tôi chia lại ngẫu nhiên các tập dữ liệu thành tập huấn luyện, phát triển và thử nghiệm cùng kích thước và xem hiệu suất fine-tuning trên phân chia mới.

Kết quả fine-tuning BERT được hiển thị trong Hình 6, và kết quả fine-tuning và khám phá tuyến tính cho tất cả PLMs được hiển thị trong Bảng 15. Fine-tuning trên tập dữ liệu có chồng chéo khái niệm đạt được độ chính xác cao hơn nhiều, đặc biệt trên CSJ. Điều này chỉ ra rằng nếu chúng ta không tránh chồng chéo khái niệm, PLMs có thể dễ dàng học kiến thức khái niệm từ dữ liệu huấn luyện và dẫn đến kết luận lạc quan sai lầm.

--- TRANG 18 ---

[Hình 7: Phân loại khái niệm cho tập dữ liệu huấn luyện và phát triển. Object là khái niệm ảo không có trường hợp được chú thích.]

--- TRANG 19 ---

[Hình 8: Phân loại khái niệm cho tập dữ liệu thử nghiệm. Object là khái niệm ảo không có trường hợp được chú thích.]

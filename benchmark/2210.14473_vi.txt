# Đánh giá các Mô hình Ngôn ngữ cho Hiểu biết Cú pháp Mã nguồn
Da Shen1, Xinyun Chen2y, Chenguang Wang3y, Koushik Sen4, Dawn Song4
1University of Maryland, College Park,2Google Research, Brain Team
3Washington University in St. Louis,4University of California, Berkeley
dashen@terpmail.umd.edu ,xinyunchen@google.com ,chenguangwang@wustl.edu ,
{ksen,dawnsong}@cs.berkeley.edu

## Tóm tắt
Các mô hình ngôn ngữ được huấn luyện trước đã thể hiện hiệu suất ấn tượng trong cả xử lý ngôn ngữ tự nhiên và hiểu biết chương trình, biểu diễn đầu vào dưới dạng một chuỗi token mà không mô hình hóa cấu trúc một cách rõ ràng. Một số nghiên cứu trước đây cho thấy các mô hình ngôn ngữ được huấn luyện trước có thể nắm bắt các quy tắc cú pháp của ngôn ngữ tự nhiên mà không cần tinh chỉnh trên các nhiệm vụ hiểu biết cú pháp. Tuy nhiên, hiện tại vẫn còn hạn chế trong việc hiểu rõ các mô hình được huấn luyện trước hiểu cấu trúc mã nguồn như thế nào. Trong nghiên cứu này, chúng tôi thực hiện đánh giá toàn diện đầu tiên về các mô hình được huấn luyện trước tiên tiến để xác định cấu trúc cú pháp của chương trình. Cụ thể, chúng tôi giới thiệu CodeSyntax , một bộ dữ liệu quy mô lớn gồm các chương trình được chú thích với các mối quan hệ cú pháp trong cây cú pháp trừu tượng tương ứng. Quan sát chính của chúng tôi là các mô hình ngôn ngữ hiện tại được huấn luyện trước trên mã nguồn vẫn thiếu hiểu biết về cú pháp mã nguồn. Thực tế, các mô hình ngôn ngữ lập trình được huấn luyện trước này không thể đạt được hiệu suất của các baseline đơn giản dựa trên offset vị trí và từ khóa. Chúng tôi cũng trình bày một benchmark ngôn ngữ tự nhiên để làm nổi bật sự khác biệt giữa ngôn ngữ tự nhiên và ngôn ngữ lập trình về hiểu biết cấu trúc cú pháp. Những phát hiện của chúng tôi chỉ ra những hạn chế chính của các phương pháp huấn luyện trước hiện tại cho ngôn ngữ lập trình, và gợi ý tầm quan trọng của việc mô hình hóa cấu trúc cú pháp mã nguồn.1

## 1 Giới thiệu
Huấn luyện trước quy mô lớn các mô hình ngôn ngữ đã trở thành mô hình thực tế cho nhiều nhiệm vụ xử lý ngôn ngữ tự nhiên. Hơn nữa, các nghiên cứu gần đây cho thấy các mô hình được huấn luyện trước trên lượng lớn mã nguồn cũng đạt được hiệu suất cạnh tranh trên nhiều nhiệm vụ, ví dụ như tạo mã nguồn và phân loại mã nguồn. Các nhiệm vụ này có liên quan chặt chẽ đến các nhiệm vụ ngôn ngữ tự nhiên (NL) trong cách thức phát biểu vấn đề. Ngày nay, thực hành phổ biến để giải quyết các nhiệm vụ mã nguồn này là sử dụng các kiến trúc mô hình ngôn ngữ và sơ đồ huấn luyện ban đầu được thiết kế cho NL. Nguyên tắc thiết kế của các mô hình ngôn ngữ neural này khác biệt đáng kể so với các hệ thống tạo chương trình dựa trên quy tắc cổ điển. Cụ thể, các mô hình ngôn ngữ neural coi chương trình như một chuỗi token, trong khi các hệ thống tạo chương trình cổ điển sử dụng ngữ pháp ngôn ngữ và cấu trúc mã nguồn. Mặc dù có hiệu suất tiên tiến của các mô hình ngôn ngữ được huấn luyện trước trên các nhiệm vụ hiểu mã nguồn, những gì các mô hình này đã học được từ corpus mã nguồn vẫn chưa rõ ràng.

Trong nghiên cứu này, chúng tôi điều tra liệu huấn luyện trước quy mô lớn có phải là tất cả những gì chúng ta cần cho việc học biểu diễn mã nguồn hay không. Cụ thể, chúng tôi tiến hành nghiên cứu có hệ thống đầu tiên để phân tích cách các mô hình ngôn ngữ được huấn luyện trước hiểu cấu trúc cú pháp của chương trình. Để làm điều này, chúng tôi giới thiệu CodeSyntax , một benchmark quy mô lớn bao gồm các chương trình được chú thích với các mối quan hệ cú pháp giữa các token khác nhau. Các mối quan hệ cú pháp chuẩn được trích xuất từ các cạnh trong cây cú pháp trừu tượng (AST) của các chương trình. Hình 1 cho thấy một số ví dụ. Các mối quan hệ cú pháp này tương tự về chức năng với các mối quan hệ phụ thuộc cho NL, nơi các nghiên cứu trước đây đã chứng minh rằng các attention head của các mô hình ngôn ngữ được huấn luyện trước có thể giúp xác định các loại mối quan hệ NL (Clark et al., 2019; Raganato et al., 2018). Để đo lường mức độ hiểu biết cấu trúc cú pháp mã nguồn của các mô hình ngôn ngữ được huấn luyện trước, chúng tôi áp dụng phương pháp này vào miền PL. Chúng tôi tập trung vào việc điều tra khả năng zero-shot của các phương pháp huấn luyện trước hiện tại trong các thí nghiệm của chúng tôi, và chúng tôi đánh giá các mô hình được huấn luyện trước này mà không tinh chỉnh chúng trên benchmark của chúng tôi.

Chúng tôi đánh giá các mô hình ngôn ngữ được huấn luyện trước tiên tiến cho việc học biểu diễn mã nguồn, bao gồm CuBERT (Kanade et al., 2020) và CodeBERT (Feng et al., 2020). Một đặc điểm chung của các mô hình này là chúng chia sẻ cùng thiết kế kiến trúc dựa trên Transformer như các mô hình NL (Vaswani et al., 2017; Devlin et al., 2019). Điều này cho phép chúng tôi so sánh trực tiếp hiệu suất của chúng trong việc nắm bắt cấu trúc cú pháp. Chúng tôi trình bày một bản xem trước các kết quả chính trong Hình 2. Quan sát chính của chúng tôi là huấn luyện trước không đủ để học các mối quan hệ cú pháp trong mã nguồn. Đầu tiên, chúng tôi phát hiện rằng các mô hình được huấn luyện trước trên mã nguồn không phải lúc nào cũng vượt trội hơn các mô hình được huấn luyện trước chỉ trên corpus NL. Đáng ngạc nhiên, so với CodeBERT được huấn luyện trên cả corpus văn bản và mã nguồn, RoBERTa đạt hiệu suất tốt hơn mà không cần huấn luyện trên bất kỳ mã nguồn nào với kiến trúc mô hình giống hệt. Điều này cho thấy việc huấn luyện trước trên các chương trình như chuỗi token không giúp học được các mối quan hệ cú pháp. Ngược lại, không có các mối quan hệ phụ thuộc, huấn luyện trước vẫn cho phép các mô hình ngôn ngữ hiểu cú pháp NL ở một mức độ nào đó.

Hơn nữa, đối với hiểu biết cú pháp mã nguồn, các mô hình được huấn luyện trước thậm chí còn hoạt động tệ hơn các baseline đơn giản chọn token với offset cố định. Ví dụ, việc luôn chọn token thứ (p+2) làm phụ thuộc của token thứ p cho độ chính xác cao hơn bất kỳ attention head nào cho một số loại mối quan hệ. Mặt khác, các kiến trúc mô hình tương tự được huấn luyện trước trên corpus văn bản đạt độ chính xác khá tốt trong việc xác định các mối quan hệ phụ thuộc trong miền NL, nơi hiệu suất của các baseline đơn giản tương tự kém xa.

Phân tích của chúng tôi tiết lộ một số khác biệt chính giữa NL và PL dẫn đến khả năng hiểu cú pháp khác nhau của các mô hình được huấn luyện trước. Đầu tiên, các chương trình có cấu trúc hơn các câu NL. Các chương trình thường chứa cấu trúc phân cấp biểu diễn các phụ thuộc dài hạn giữa các token mã nguồn. Do đó, một số lượng lớn các loại mối quan hệ cú pháp nằm giữa các token xa nhau, có thể khó nhận biết đối với các attention head. Ngược lại, các mối quan hệ phụ thuộc trong câu NL chủ yếu kết nối các cặp token gần nhau, và trong trường hợp này các attention head có khả năng xác định đúng mối quan hệ tốt hơn.

Trong khi đó, các mô hình ngôn ngữ giỏi trong việc nhận biết các mối quan hệ dựa trên từ khóa, chẳng hạn như chọn từ khóa else tương ứng cho token if. Thú vị là, chúng tôi phát hiện rằng việc bao gồm các token như dấu xuống dòng và dấu chấm phẩy ảnh hưởng đáng kể đến hiệu suất trong miền mã nguồn.

Các phát hiện của chúng tôi gợi ý rằng các mô hình được huấn luyện trước hiện tại hoạt động khá khác nhau trong miền PL và NL về khả năng hiểu cú pháp. Do đó, việc áp dụng trực tiếp các mô hình huấn luyện được phát triển cho NL có thể không tối ưu cho việc học chương trình, và chúng tôi coi việc thiết kế các phương pháp tốt hơn để mô hình hóa cấu trúc mã nguồn là nghiên cứu tương lai.

## 2 CodeSyntax : Đánh giá Hiểu biết Cú pháp Mã nguồn

Chúng tôi xây dựng benchmark CodeSyntax để đánh giá hiệu suất của các mô hình ngôn ngữ trên việc hiểu cú pháp mã nguồn. Chúng tôi tập trung vào ngôn ngữ Python và Java, trên đó các checkpoint mô hình được công bố công khai của cả CuBERT (Kanade et al., 2020) và CodeBERT (Feng et al., 2020) đều được huấn luyện trước. Chúng tôi lấy các mẫu mã nguồn từ CodeSearchNet (Husain et al., 2019), là một bộ dữ liệu quy mô lớn bao gồm mã nguồn bằng các ngôn ngữ lập trình khác nhau. Tập huấn luyện của nó cũng là một phần của dữ liệu huấn luyện trước của CodeBERT, vì vậy chúng tôi loại bỏ các mẫu dữ liệu được bao gồm trong dữ liệu huấn luyện trước của CuBERT hoặc CodeBERT. Do đó, không có chương trình nào trong CodeSyntax đã được CuBERT hoặc CodeBERT nhìn thấy trong giai đoạn huấn luyện trước.

Tổng cộng, CodeSyntax chứa 18,701 mẫu mã nguồn được chú thích với 1,342,050 cạnh mối quan hệ trong 43 loại mối quan hệ cho Python, và 13,711 mẫu mã nguồn được chú thích với 864,411 cạnh mối quan hệ trong 39 loại mối quan hệ cho Java. Mỗi mẫu mã nguồn là một hàm hoàn chỉnh bao gồm nhiều câu lệnh, tương tự như một đoạn văn trong NL. Mỗi mối quan hệ tương ứng với một cạnh trong AST của chương trình; cụ thể, chúng tôi sử dụng module ast của Python (Foundation, 2021) và lớp org.eclipse.jdt.core.dom.ASTParser của Java (Contributors, 2014) để phân tích một mẫu mã nguồn thành AST. Chúng tôi trình bày một số ví dụ về các loại mối quan hệ trong Bảng 1, và chúng tôi hoãn việc mô tả tất cả các loại mối quan hệ đến Bảng 8 trong phụ lục. Thêm chi tiết về trích xuất mối quan hệ được thảo luận trong Phụ lục A.

Lưu ý rằng chúng tôi có thể dễ dàng mở rộng bộ dữ liệu để bao phủ nhiều ngôn ngữ hơn vì quy trình trích xuất mối quan hệ được tự động hóa và các parser AST có sẵn cho hầu hết các ngôn ngữ lập trình phổ biến.

Chúng tôi quan sát một số đặc điểm của các mối quan hệ trong CodeSyntax . Đầu tiên, các từ khóa trong PL đóng vai trò quan trọng trong việc nhận biết cấu trúc mã nguồn. Cụ thể, một số loại mối quan hệ có từ khóa cố định làm nút cạnh, chẳng hạn như mối quan hệ If:if!else . Trong khi đó, so với các mối quan hệ phụ thuộc trong NL, các cạnh mối quan hệ trong AST chương trình có xu hướng kết nối các nút cách xa nhau nhiều hơn. Như được hiển thị trong Hình 3, offset trung bình giữa nút head và dependent không quá 10 cho các mối quan hệ phụ thuộc trong NL, trong khi offset trung bình cho một loại mối quan hệ có thể hơn 100 token mã nguồn. Cụ thể, trong CodeSyntax , có 22 loại phụ thuộc gần có offset trung bình nhỏ hơn 10, và 12 loại phụ thuộc xa có offset trung bình lớn hơn 10.

## 3 Thiết lập Đánh giá

Các mô hình ngôn ngữ được huấn luyện trước có nắm bắt cấu trúc mã nguồn mà không cần giám sát trực tiếp thông tin cú pháp không? Để điều tra câu hỏi này, chúng tôi đánh giá một số mô hình ngôn ngữ được huấn luyện trước mà không tinh chỉnh, và so sánh hiệu suất của chúng trong việc hiểu cú pháp cho NL và PL.

**Benchmark ngôn ngữ tự nhiên.** Để so sánh hiệu suất trên CodeSyntax với hiểu biết cú pháp NL, chúng tôi xây dựng benchmark NL bao gồm tiếng Anh và tiếng Đức. Cụ thể, chúng tôi sử dụng English News Text Treebank: Penn Treebank Revised (Bies et al., 2015) được gán nhãn với Stanford Dependencies (de Marneffe and Manning, 2008a,b), và German Hamburg Dependency Treebank (Foth et al., 2014) được gán nhãn với Universal Dependencies (de Marneffe et al., 2021). Tổng cộng, bộ dữ liệu tiếng Anh có 48,883 câu, 43 loại mối quan hệ, và 1,147,526 cạnh mối quan hệ; bộ dữ liệu tiếng Đức có 18,459 câu, 35 loại mối quan hệ, và 307,791 cạnh mối quan hệ.

**Phương pháp thăm dò attention.** Một số nghiên cứu trước đây chứng minh rằng kiến trúc Transformer (Vaswani et al., 2017) được huấn luyện trước trên corpus văn bản, chẳng hạn như BERT (Devlin et al., 2019), chứa các attention head chuyên về một số mối quan hệ phụ thuộc nhất định trong NL (Raganato et al., 2018; Clark et al., 2019). Cụ thể, trong kiến trúc Transformer, mỗi vector ei cho token đầu vào được biến đổi thành các vector query và key qi và ki thông qua một số phép biến đổi tuyến tính, và các phép biến đổi khác nhau giữa các attention head khác nhau. Đối với token thứ i, trọng số attention được gán cho token thứ j là

αi,j = exp(qiT kj) / Σl exp(qiT kl)

Trọng số attention cho biết mức độ quan trọng của token thứ j đối với token thứ i. Thông thường, các attention head khác nhau học các trọng số khác nhau giữa các token đầu vào. Do đó, để đo lường tính đúng đắn của việc nhận biết loại mối quan hệ r, cho mỗi cạnh <h, t, r> trong AST chương trình nơi h là nút head và t là nút dependent, chúng tôi liệt kê tất cả các attention head để tính trọng số attention αh,t. Nếu một attention head có xu hướng gán trọng số attention cao kết nối cặp token thuộc loại mối quan hệ r, chúng tôi coi loại mối quan hệ đó được nắm bắt. Chúng tôi hoãn thêm chi tiết triển khai trích xuất bản đồ attention đến Phụ lục B.

**Metrics.** Chúng tôi sử dụng điểm số unlabeled attachment score (UAS) để đo lường hiệu suất hiểu cú pháp, và chúng tôi xem xét điểm số top-k với các giá trị khác nhau của k. Để tính điểm số top-k cho các mô hình ngôn ngữ, cho mỗi attention head, với token head h trong cạnh mối quan hệ <h, t, r>, chúng tôi tính trọng số attention trên tất cả token trong mã nguồn đầu vào, và chúng tôi coi dự đoán là đúng nếu trọng số attention trên token dependent t nằm trong số k token có trọng số attention cao nhất. Cho mỗi mối quan hệ, chúng tôi chọn attention head hoạt động tốt nhất và sử dụng điểm số của nó làm điểm số của mô hình cho mối quan hệ đó. Chúng tôi tính điểm số trung bình của mô hình trên tất cả các mối quan hệ làm điểm số cuối cùng của mô hình.

Trong các bài toán phân tích phụ thuộc NL, nút dependent t thường tương ứng với một từ duy nhất. Tuy nhiên, trong PL, dependent có thể là một khối chứa nhiều token mã nguồn. Ví dụ, trong mối quan hệ If:if!body , head là từ khóa if, trong khi dependent là toàn bộ khối body. Do đó, chúng tôi đo lường ba metrics. **First-token metric** và **last-token metric**: dự đoán được coi là đúng nếu nó dự đoán thành công token đầu tiên và cuối cùng của khối dependent, tương ứng; **Any-token metric**: dự đoán được coi là đúng nếu nó có thể dự đoán bất kỳ token nào trong khối dependent. Mặc dù chúng tôi đồng ý rằng đây không phải là các metric hoàn hảo và một metric duy nhất có thể không đầy đủ, chúng tôi quan sát rằng các phát hiện của chúng tôi thường giữ nguyên cho tất cả ba metric mà chúng tôi đánh giá. Lưu ý rằng first-token metric nghiêm ngặt hơn any-token metric theo thiết kế. Trừ khi được chỉ định khác, chúng tôi báo cáo điểm số top-k sử dụng first-token metric theo mặc định.

**Kiến trúc mô hình.** Bảng 2 tóm tắt các mô hình được đánh giá trong nghiên cứu này. Đối với các mô hình ngôn ngữ trên mã nguồn, chúng tôi xem xét CuBERT (Kanade et al., 2020) và CodeBERT (Feng et al., 2020), và chúng tôi đánh giá các checkpoint được huấn luyện trước đã được phát hành của chúng. Cả hai đều dựa trên kiến trúc ban đầu được thiết kế cho NL. Cụ thể, CuBERT sử dụng kiến trúc BERT (Devlin et al., 2019), và CodeBERT (Feng et al., 2020) sử dụng kiến trúc RoBERTa (Liu et al., 2019). Đối với các mô hình NL, chúng tôi cũng đánh giá các biến thể đa ngôn ngữ của BERT và RoBERTa trên bộ dữ liệu tiếng Đức, tức là Multilingual BERT (Pires et al., 2019) và XLM-RoBERTa (Conneau et al., 2020). Cả hai mô hình ngôn ngữ mã nguồn đều có phân biệt chữ hoa thường, vì vậy chúng tôi cũng đánh giá các phiên bản có phân biệt chữ hoa thường của các mô hình NL.

**Baselines.** Để kiểm tra mức độ hoạt động tốt của attention thông qua so sánh, chúng tôi thiết kế một baseline offset đơn giản và một baseline từ khóa đơn giản. Baseline offset với giá trị offset i luôn chọn token sau i vị trí của token đầu vào làm dự đoán khi i > 0, và chọn i vị trí trước token đầu vào khi i < 0. Baseline từ khóa với từ khóa key luôn dự đoán token key tiếp theo làm dự đoán. Trong các thí nghiệm của chúng tôi, chúng tôi đánh giá các baseline offset với mỗi giá trị offset có thể từ 0 đến 512 cho PL, và -512 đến 512 cho NL. Chúng tôi sử dụng tất cả từ khóa Python và Java cho các baseline từ khóa trên bộ dữ liệu Python và Java tương ứng, bao gồm các token như if, for, in, v.v. Để đánh giá điểm số top-k cho các baseline với k ≥ 2, chúng tôi kết hợp k baseline đơn giản với các giá trị offset (từ khóa) khác nhau để đưa ra k dự đoán. Để chọn k giá trị offset (từ khóa), chúng tôi lặp đi lặp lại và tham lam bao gồm giá trị tiếp theo mang lại sự gia tăng hiệu suất cao nhất cho loại mối quan hệ đang xem xét.

## 4 Thí nghiệm

Trong phần này, chúng tôi trình bày kết quả của các mô hình ngôn ngữ được huấn luyện trước cho cả nhiệm vụ hiểu cú pháp PL và NL, và thảo luận các quan sát chính phân biệt PL với NL.

### 4.1 Kết quả Chính

Chúng tôi trình bày kết quả chính để so sánh hiệu suất trong hiểu mối quan hệ cú pháp trên PL và NL trong Bảng 3 và 4, tương ứng. Đầu tiên, trên CodeSyntax , các mô hình ngôn ngữ nói chung hoạt động tệ hơn baseline offset đơn giản và sự kết hợp của nó với baseline từ khóa, điều này cho thấy các attention head của các mô hình được huấn luyện trước PL không nắm bắt hiệu quả các mối quan hệ cú pháp trong chương trình. Việc so sánh giữa CodeBERT và RoBERTa tiếp tục cho thấy việc huấn luyện trước trên corpus mã nguồn quy mô lớn, ngoài corpus văn bản cho huấn luyện trước RoBERTa, không mang lại hiểu biết cú pháp mã nguồn tốt hơn đáng kể. Ngược lại, các mô hình ngôn ngữ vượt trội hơn đáng kể so với các baseline offset trong việc nhận biết các mối quan hệ phụ thuộc trong NL, chứng minh rằng các attention head học được chuyên biệt cho các loại mối quan hệ khác nhau thông qua huấn luyện trước quy mô lớn trên văn bản.

Trong khi đó, chúng tôi trình bày kết quả any-token trên CodeSyntax trong Bảng 5. Mặc dù baseline kết hợp tốt nhất vẫn vượt trội hơn các mô hình ngôn ngữ, khoảng cách hiệu suất giảm đáng kể. Cụ thể, CuBERT đạt điểm số tốt hơn baseline offset, và sự cải thiện trên Java đáng chú ý hơn. Chúng tôi hoãn kết quả đầy đủ của các điểm số top-k khác nhau trên cả benchmark PL và NL đến Phụ lục D. Trong các phần sau, chúng tôi thảo luận các yếu tố chính ảnh hưởng đến hiệu suất dự đoán.

### 4.2 Nghiên cứu Trường hợp: Ảnh hưởng của Từ khóa

Để kiểm tra tại sao baseline offset vượt trội hơn CodeBERT và CuBERT, và tại sao sự khác biệt hiệu suất tương đối nhỏ hơn khi sử dụng any-token metric, chúng tôi đã tiến hành nghiên cứu trường hợp và phân tích lỗi trong Phần 4.2 và Phần 4.3, cả hai đều phân loại các mẫu lỗi một cách định lượng và định tính.

Đầu tiên, chúng tôi điều tra các token mã nguồn được attention chú ý nhiều nhất, và chúng tôi quan sát rằng các attention head có xu hướng nhận biết các token được bảo lưu và từ khóa trong PL. Ví dụ, CuBERT và CodeBERT đạt điểm số cải thiện trên Java vì token dấu chấm phẩy là một phần của nút dependent chuẩn, đây là token phổ biến được các mô hình ngôn ngữ chú ý đến. Dựa trên quan sát này, chúng tôi thực hiện nghiên cứu ablation về sự hiện diện của dấu chấm phẩy trong chú thích chuẩn. Khi các token dấu chấm phẩy được loại bỏ khỏi các nút dependent chuẩn, chúng tôi cũng vô hiệu hóa khả năng của các mô hình ngôn ngữ chú ý đến dấu chấm phẩy trong mã nguồn đầu vào. Vì dấu chấm phẩy xuất hiện ở cuối mỗi câu lệnh Java, ở đây chúng tôi tính điểm số last-token có thể bị ảnh hưởng đáng kể bởi dấu chấm phẩy. Như được hiển thị trong Hình 4, CuBERT vượt trội hơn đáng kể so với các baseline khi dấu chấm phẩy được bao gồm trong nhãn chuẩn. Mặt khác, CuBERT đạt điểm số thấp hơn các baseline khi dấu chấm phẩy được loại trừ khỏi nhãn chuẩn và dự đoán. Việc so sánh gợi ý rằng các attention head có khả năng xác định các từ khóa thường xuyên trong đầu vào mô hình tốt hơn. Chúng tôi hoãn nghiên cứu ablation đầy đủ trên cả Python và Java đến Phụ lục F.

Chúng tôi tiếp tục thảo luận kết quả phân tích chi tiết theo loại mối quan hệ, và chúng tôi chọn một số mối quan hệ đại diện cho Python làm nổi bật sự khác biệt hiệu suất giữa CuBERT và baseline offset trong Bảng 6. Đầu tiên, attention rất có khả năng thực hiện khớp từ khóa, dẫn đến độ chính xác khá tốt trên các mối quan hệ kết nối các từ khóa phổ biến, chẳng hạn như If:if!else . Tuy nhiên, khi các token head và dependent đa dạng, việc mô hình ngôn ngữ nhận biết mối quan hệ trở nên thách thức. Ví dụ, trong các loại mối quan hệ Assign:target!value và Call:func!args , cả nút head và dependent đều có thể nhận các tên định danh khác nhau được định nghĩa bởi các lập trình viên khác nhau. Cụ thể, CuBERT không thể sử dụng hiệu quả vị trí tương đối của các token để học các mối quan hệ, ngay cả khi nút dependent gần nút head. Trong những tình huống như vậy, baseline offset với giá trị offset cố định 2 đã vượt qua mô hình được huấn luyện trước. Kết quả phân tích chi tiết đầy đủ của tất cả các loại mối quan hệ trên cả Python và Java có thể được tìm thấy trong Phụ lục G.

### 4.3 Phân tích Lỗi

Để phân loại các dự đoán sai của attention, chúng tôi kiểm tra thủ công 50 trường hợp lỗi cho mỗi mối quan hệ được chọn trong Bảng 6, và trình bày các tình huống lỗi trong Bảng 7. Một lần nữa, chúng tôi quan sát rằng attention thường chọn sai các token xuất hiện thường xuyên như dấu ngoặc. Hơn nữa, mô hình gặp khó khăn trong việc nắm bắt cấu trúc mã nguồn phân cấp, do đó nó thường chú ý đến các từ khóa gần đó bất kể các khối mã nguồn logic.

Lấy mối quan hệ If:if!else làm ví dụ, mà mô hình ngôn ngữ nói chung đạt hiệu suất tốt nhất. Được hiển thị trong Hình 5 là hai mẫu câu lệnh if, nơi câu lệnh đầu tiên không chứa các khối điều khiển luồng lồng nhau trong khi câu lệnh thứ hai chứa từ khóa while bên trong if-body. "..." biểu thị rằng một số mã nguồn bị bỏ qua. Trực quan hóa các trọng số attention tương ứng của attention head hoạt động tốt nhất trên mối quan hệ If:if!else , chúng tôi quan sát rằng attention head chính xác chú ý đến token else trong ví dụ đầu tiên, trong khi nó sai lầm chú ý đến token while bên trong if-body trong ví dụ thứ hai. Thêm ví dụ như thế này có thể được tìm thấy trong Phụ lục E.

## 5 Nghiên cứu Liên quan

Các mô hình ngôn ngữ dựa trên Transformer đã được sử dụng rộng rãi cho xử lý ngôn ngữ tự nhiên (Devlin et al., 2019; Liu et al., 2019; Wang et al., 2020, 2021; Shen et al., 2022; Wang et al., 2022). Hewitt và Manning (2019) cho thấy rằng các cây cú pháp được nhúng ngầm trong không gian biểu diễn từ của BERT thông qua một structural probe. Một hướng nghiên cứu khác nghiên cứu những gì được học bởi attention trong các mô hình ngôn ngữ (Clark et al., 2019; Raganato et al., 2018; Voita et al., 2019; Michel et al., 2019; Vig, 2019; Burns et al., 2018; Marecek và Rosa, 2018; Voita et al., 2018). Cụ thể, Clark et al. (2019) đánh giá các attention head của BERT trên các nhiệm vụ phân tích phụ thuộc sử dụng corpus English Penn Treebank, nơi attention vượt trội đáng kể so với các baseline offset. Ngược lại, chúng tôi chứng minh rằng các mô hình dựa trên attention phần lớn hoạt động tệ hơn các baseline offset trên hiểu cú pháp mã nguồn.

Thành công của các mô hình dựa trên Transformer cho xử lý ngôn ngữ tự nhiên dẫn đến việc áp dụng chúng trong miền PL (Kanade et al., 2020; Feng et al., 2020; Rozière et al., 2020, 2021; Clement et al., 2020; Dehghani et al., 2019). Chen et al. (2021) đánh giá hiệu suất mô hình bằng cách đo lường tính đúng đắn chức năng trên các unit test. Chirkova và Troshin (2021) thực nghiệm cho thấy Transformer có thể sử dụng thông tin cú pháp để đưa ra dự đoán trong một số nhiệm vụ xử lý mã nguồn, trong khi chúng tôi phân tích khả năng của attention hiểu các mối quan hệ cú pháp. Karmakar và Robbes (2021) thăm dò các mô hình được huấn luyện trước trên bốn nhiệm vụ hiểu mã nguồn. Họ tập trung nhiều hơn vào phân loại mã nguồn, ví dụ, họ huấn luyện một classifier để dự đoán thẻ nút AST và độ dài mã nguồn. Ngược lại, chúng tôi thăm dò các attention head để hiểu mối quan hệ cú pháp, và chúng tôi nhằm trình bày một nghiên cứu toàn diện về sự khác biệt giữa các mô hình ngôn ngữ được huấn luyện trước trên NL và PL để nắm bắt cấu trúc cú pháp.

Đã có một số nỗ lực cố gắng tính đến cấu trúc mã nguồn trong quá trình huấn luyện trước các mô hình dựa trên Transformer cho mã nguồn. Ví dụ, GraphCodeBERT (Guo et al., 2021) sử dụng data flow cho huấn luyện trước; tức là mối quan hệ "giá trị đến từ đâu" cho các biến. Trên benchmark Python của chúng tôi, GraphCodeBERT đạt điểm số top-1 first-token là 39.3, tốt hơn 33.1 của CodeBERT, và tương đương với 39.2 của CuBERT. Tuy nhiên, điểm số như vậy vẫn tệ hơn 43.6 của baseline offset. Xu hướng này nhất quán khi đánh giá với các metric khác. Những kết quả này cho thấy việc huấn luyện trước trên data flow giúp cải thiện khả năng hiểu cú pháp mã nguồn của mô hình, nhưng vẫn còn nhiều chỗ để cải thiện.

## 6 Kết luận

Trong nghiên cứu này, chúng tôi giới thiệu CodeSyntax , một benchmark quy mô lớn để đo lường hiệu suất hiểu cú pháp mã nguồn. Dựa trên CodeSyntax , chúng tôi tiến hành nghiên cứu toàn diện đầu tiên để phân tích khả năng của các mô hình ngôn ngữ được huấn luyện trước trong việc hiểu cấu trúc cú pháp mã nguồn mà không cần tinh chỉnh thêm. Chúng tôi chứng minh rằng trong khi các attention head của các mô hình ngôn ngữ được huấn luyện trước có thể xác định các mối quan hệ phụ thuộc trong NL ở một mức độ nào đó, chúng gặp khó khăn trong việc nhận biết các mối quan hệ cú pháp trong chương trình. Các mô hình được huấn luyện trước thậm chí còn hoạt động tệ hơn các baseline offset đơn giản nói chung, và chúng có xu hướng chú ý đến các token xuất hiện thường xuyên gần đó mà không tính đến cấu trúc mã nguồn phân cấp.

Chúng tôi cũng phân tích sự khác biệt giữa NL và PL từ quan điểm của các mô hình được huấn luyện trước. Đánh giá của chúng tôi gợi ý rằng PL có những đặc điểm độc đáo phân biệt chúng với NL, chẳng hạn như phụ thuộc dài hạn giữa các token mã nguồn, và sự phân cấp trong cấu trúc cú pháp. Do đó, việc đơn giản coi chương trình như một chuỗi token là không đủ để mô hình hóa cấu trúc chương trình, điều này cuối cùng có thể hạn chế tiềm năng của các mô hình ngôn ngữ cho các nhiệm vụ hiểu mã nguồn. Chúng tôi coi việc phát triển các kiến trúc mô hình mới và thuật toán huấn luyện trước để tận dụng và biểu diễn cấu trúc mã nguồn và đồ thị phụ thuộc là nghiên cứu tương lai quan trọng.

## 7 Hạn chế

Đối với các hạn chế của benchmark của chúng tôi, các chú thích chuẩn dựa trên các parser AST. Việc thêm các ngôn ngữ lập trình mới mà parser không có sẵn sẽ yêu cầu nỗ lực gán nhãn bổ sung. Một hạn chế trong thiết lập thí nghiệm của chúng tôi là chúng tôi chỉ đánh giá sáu mô hình trên hai loại ngôn ngữ tự nhiên và ngôn ngữ lập trình. Cuối cùng, trọng tâm chính của nghiên cứu của chúng tôi là thăm dò các mô hình ngôn ngữ để hiểu mã nguồn. Do đó, chúng tôi chưa đề xuất các mô hình có thể xử lý cú pháp mã nguồn trong các ứng dụng ngôn ngữ tự nhiên và ngôn ngữ lập trình. Nghiên cứu tương lai có thể bao gồm phát triển các mô hình như vậy nắm bắt cả ngữ nghĩa và cấu trúc.

## 8 Cân nhắc Đạo đức

Chúng tôi xin xác nhận rằng tất cả các đồng tác giả của nghiên cứu này đều nhận thức được Bộ quy tắc Đạo đức ACM được cung cấp và tôn trọng quy tắc ứng xử. Sau đây đưa ra các khía cạnh của cả những cân nhắc đạo đức của chúng tôi và tác động tiềm tăng của chúng tôi đến cộng đồng. Nghiên cứu này tạo ra một benchmark để kiểm tra hiểu biết cú pháp mã nguồn của các mô hình ngôn ngữ được huấn luyện trước. Thay vì ngôn ngữ tự nhiên, ngôn ngữ lập trình được sử dụng để huấn luyện trước. Chúng tôi không dự đoán việc tạo ra các đầu ra có hại sau khi sử dụng benchmark và các mô hình hiện tại của chúng tôi, đặc biệt là đối với các nhóm dân số dễ bị tổn thương.

## 9 Cân nhắc Môi trường

Chúng tôi sử dụng một số mô hình ngôn ngữ được huấn luyện trước. Theo ước tính trong (Strubell et al., 2019), việc huấn luyện trước một mô hình có kích thước tương tự như được sử dụng trong nghiên cứu này tốn 1,507 kWh PUE và phát thải 1,438 lb CO2. Nghiên cứu này tập trung vào suy luận. Do đó, chi phí năng lượng và phát thải CO2 của chúng tôi tương đối nhỏ.

## Lời cảm ơn

Chúng tôi muốn cảm ơn các nhà đánh giá ẩn danh vì những gợi ý và nhận xét của họ. Nghiên cứu này một phần dựa trên nghiên cứu được hỗ trợ bởi Berkeley DeepDrive và Berkeley Artificial Intelligence Research.

[Phần còn lại của bài báo bao gồm các tài liệu tham khảo và phụ lục chi tiết sẽ được dịch tương tự, giữ nguyên cấu trúc và định dạng như bản gốc]

--- TRANG 11 ---

Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, và Dario Amodei. Các mô hình ngôn ngữ là những người học few-shot, 2020.

Chi-Min Chan, Weize Chen, Yusheng Su, Jianxuan Yu, Wei Xue, Shanghang Zhang, Jie Fu, và Zhiyuan Liu. ChatEval: Hướng tới Các Đánh giá viên dựa trên LLM Tốt hơn thông qua Tranh luận Đa tác nhân, Tháng 8 2023.

Harrison Chase. LangChain, Tháng 10 2022.

Lingjiao Chen, Matei Zaharia, và James Zou. Hành vi của chatgpt thay đổi như thế nào theo thời gian?, 2023.

François Chollet. Về thước đo trí thông minh, 2019.

Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, Christopher Hesse, và John Schulman. Huấn luyện các trình xác minh để giải quyết các bài toán từ toán học, 2021.

Cynthia Dwork và Moni Naor. Định giá thông qua xử lý hoặc chống lại thư rác. Trong Ernest F. Brickell, biên tập viên, Advances in Cryptology — CRYPTO' 92, trang 139–147, Berlin, Heidelberg, 1993. Springer Berlin Heidelberg. ISBN 978-3-540-48071-6.

Difei Gao, Lei Ji, Luowei Zhou, Kevin Qinghong Lin, Joya Chen, Zihan Fan, và Mike Zheng Shou. AssistGPT: Một Trợ lý Đa phương thức Tổng quát có thể Lập kế hoạch, Thực hiện, Kiểm tra, và Học, Tháng 6 2023.

Leo Gao, Jonathan Tow, Stella Biderman, Sid Black, Anthony DiPofi, Charles Foster, Laurence Golding, Jeffrey Hsu, Kyle McDonell, Niklas Muennighoff, Jason Phang, Laria Reynolds, Eric Tang, Anish Thite, Ben Wang, Kevin Wang, và Andy Zou. Một khung cho đánh giá mô hình ngôn ngữ few-shot, Tháng 9 2021. URL https://doi.org/10.5281/zenodo.5371628.

Yingqiang Ge, Wenyue Hua, Kai Mei, Jianchao Ji, Juntao Tan, Shuyuan Xu, Zelong Li, và Yongfeng Zhang. Openagi: Khi llm gặp các chuyên gia lĩnh vực, 2023.

Jakub Growiec. Tự động hóa, một phần và toàn phần. Macroeconomic Dynamics, 26(7):1731–1755, 2022.

Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, và Jacob Steinhardt. Đo lường hiểu biết ngôn ngữ đa nhiệm vụ lớn. Trong International Conference on Learning Representations, 2021.

Sirui Hong, Xiawu Zheng, Jonathan Chen, Yuheng Cheng, Jinlin Wang, Ceyao Zhang, Zili Wang, Steven Ka Shing Yau, Zijuan Lin, Liyang Zhou, Chenyu Ran, Lingfeng Xiao, và Chenglin Wu. MetaGPT: Lập trình Meta cho Khung Hợp tác Đa tác nhân, Tháng 8 2023.

Yushi Hu, Benlin Liu, Jungo Kasai, Yizhong Wang, Mari Ostendorf, Ranjay Krishna, và Noah A Smith. Tifa: Đánh giá độ trung thực text-to-image chính xác và có thể diễn giải với trả lời câu hỏi. arXiv preprint arXiv:2303.11897, 2023.

Markus Jakobsson và Ari Juels. Proofs of Work và Bread Pudding Protocols(Extended Abstract), trang 258–272. Springer US, Boston, MA, 1999. ISBN 978-0-387-35568-9. doi: 10.1007/978-0-387-35568-9_18. URL https://doi.org/10.1007/978-0-387-35568-9_18.

Douwe Kiela, Tristan Thrush, Kawin Ethayarajh, và Amanpreet Singh. Vẽ biểu đồ tiến bộ trong ai. Contextual AI Blog, 2023. https://contextual.ai/blog/plotting-progress.

Hugo Laurençon, Lucile Saulnier, Léo Tronchon, Stas Bekman, Amanpreet Singh, Anton Lozhkov, Thomas Wang, Siddharth Karamcheti, Alexander M. Rush, Douwe Kiela, Matthieu Cord, và Victor Sanh. Obelics: Một bộ dữ liệu được lọc quy mô web mở của các tài liệu hình ảnh-văn bản xen kẽ, 2023.

Guohao Li, Hasan Abed Al Kader Hammoud, Hani Itani, Dmitrii Khizbullin, và Bernard Ghanem. CAMEL: Các Tác nhân Giao tiếp cho Khám phá "Tâm trí" của Xã hội Mô hình Ngôn ngữ Quy mô Lớn, Tháng 3 2023a.

Minghao Li, Feifan Song, Bowen Yu, Haiyang Yu, Zhoujun Li, Fei Huang, và Yongbin Li. API-Bank: Một Bộ tiêu chuẩn cho LLM được Tăng cường Công cụ, Tháng 4 2023b.

Minghao Li, Feifan Song, Bowen Yu, Haiyang Yu, Zhoujun Li, Fei Huang, và Yongbin Li. Api-bank: Một bộ tiêu chuẩn cho llm được tăng cường công cụ, 2023c.

Percy Liang, Rishi Bommasani, Tony Lee, Dimitris Tsipras, Dilara Soylu, Michihiro Yasunaga, Yian Zhang, Deepak Narayanan, Yuhuai Wu, Ananya Kumar, Benjamin Newman, Binhang Yuan, Bobby Yan, Ce Zhang, Christian Cosgrove, Christopher D. Manning, Christopher Ré, Diana Acosta-Navas, Drew A. Hudson, Eric Zelikman, Esin Durmus, Faisal Ladhak, Frieda Rong, Hongyu Ren, Huaxiu Yao, Jue Wang, Keshav Santhanam, Laurel Orr, Lucia Zheng, Mert Yuksekgonul, Mirac Suzgun, Nathan Kim, Neel Guha, Niladri Chatterji, Omar Khattab, Peter Henderson, Qian Huang, Ryan Chi, Sang Michael Xie, Shibani Santurkar, Surya Ganguli, Tatsunori Hashimoto, Thomas Icard, Tianyi Zhang, Vishrav Chaudhary, William Wang, Xuechen Li, Yifan Mai, Yuhui Zhang, và Yuta Koreeda. Đánh giá Toàn diện Các Mô hình Ngôn ngữ, Tháng 11 2022a.

Percy Liang, Rishi Bommasani, Tony Lee, Dimitris Tsipras, Dilara Soylu, Michihiro Yasunaga, Yian Zhang, Deepak Narayanan, Yuhuai Wu, Ananya Kumar, Benjamin Newman, Binhang Yuan, Bobby Yan, Ce Zhang, Christian Cosgrove, Christopher D. Manning, Christopher Ré, Diana Acosta-Navas, Drew A. Hudson, Eric Zelikman, Esin Durmus, Faisal Ladhak, Frieda Rong, Hongyu Ren, Huaxiu Yao, Jue Wang, Keshav Santhanam, Laurel Orr, Lucia Zheng, Mert Yuksekgonul, Mirac Suzgun, Nathan Kim, Neel Guha, Niladri Chatterji, Omar Khattab, Peter Henderson, Qian Huang, Ryan Chi, Sang Michael Xie, Shibani Santurkar, Surya Ganguli, Tatsunori Hashimoto, Thomas Icard, Tianyi Zhang, Vishrav Chaudhary, William Wang, Xuechen Li, Yifan Mai, Yuhui Zhang, và Yuta Koreeda. Đánh giá toàn diện các mô hình ngôn ngữ, 2022b.

Xiao Liu, Hao Yu, Hanchen Zhang, Yifan Xu, Xuanyu Lei, Hanyu Lai, Yu Gu, Hangliang Ding, Kaiwen Men, Kejuan Yang, Shudan Zhang, Xiang Deng, Aohan Zeng, Zhengxiao Du, Chenhui Zhang, Sheng Shen, Tianjun Zhang, Yu Su, Huan Sun, Minlie Huang, Yuxiao Dong, và Jie Tang. Agentbench: Đánh giá llm như các tác nhân. arXiv preprint arXiv: 2308.03688, 2023a.

Zhiwei Liu, Weiran Yao, Jianguo Zhang, Le Xue, Shelby Heinecke, Rithesh Murthy, Yihao Feng, Zeyuan Chen, Juan Carlos Niebles, Devansh Arpit, Ran Xu, Phil Mui, Huan Wang, Caiming Xiong, và Silvio Savarese. BOLAA: Đánh giá và Điều phối các Tác nhân Tự động được Tăng cường LLM, Tháng 8 2023b.

Grégoire Mialon, Roberto Dessì, Maria Lomeli, Christoforos Nalmpantis, Ram Pasunuru, Roberta Raileanu, Baptiste Rozière, Timo Schick, Jane Dwivedi-Yu, Asli Celikyilmaz, Edouard Grave, Yann LeCun, và Thomas Scialom. Các mô hình ngôn ngữ được tăng cường: một khảo sát, 2023.

Microsoft. Semantic Kernel. github, Tháng 9 2023.

Meredith Ringel Morris, Jascha Sohl-dickstein, Noah Fiedel, Tris Warkentin, Allan Dafoe, Aleksandra Faust, Clement Farabet, và Shane Legg. Các cấp độ của agi: Vận hành hóa tiến bộ trên con đường đến agi, 2023.

Reiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu, Long Ouyang, Christina Kim, Christopher Hesse, Shantanu Jain, Vineet Kosaraju, William Saunders, et al. Webgpt: Trả lời câu hỏi có hỗ trợ trình duyệt với phản hồi con người. arXiv preprint arXiv:2112.09332, 2021.

Harsha Nori, Nicholas King, Scott Mayer McKinney, Dean Carignan, và Eric Horvitz. Khả năng của gpt-4 trên các vấn đề thách thức y tế, 2023.

OpenAI. Báo cáo kỹ thuật gpt-4, 2023.

Anton Osika. GPT Engineer, Tháng 9 2023.

Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul Christiano, Jan Leike, và Ryan Lowe. Huấn luyện các mô hình ngôn ngữ để tuân theo hướng dẫn với phản hồi con người, 2022.

Shishir G. Patil, Tianjun Zhang, Xin Wang, và Joseph E. Gonzalez. Gorilla: Mô hình Ngôn ngữ Lớn Kết nối với API Khổng lồ, Tháng 5 2023.

Yotam Perlitz, Elron Bandel, Ariel Gera, Ofir Arviv, Liat Ein-Dor, Eyal Shnarch, Noam Slonim, Michal Shmueli-Scheuer, và Leshem Choshen. Đánh giá hiệu quả (của các mô hình ngôn ngữ), 2023.

Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, và Percy Liang. SQuAD: 100.000+ câu hỏi cho hiểu máy về văn bản. Trong Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, trang 2383–2392, Austin, Texas, Tháng 11 2016. Association for Computational Linguistics. doi: 10.18653/v1/D16-1264. URL https://aclanthology.org/D16-1264.

Sasha Rush. MiniChain, Tháng 9 2023.

Timo Schick, Jane Dwivedi-Yu, Roberto Dessì, Roberta Raileanu, Maria Lomeli, Luke Zettlemoyer, Nicola Cancedda, và Thomas Scialom. Toolformer: Các mô hình ngôn ngữ có thể tự dạy mình sử dụng công cụ. arXiv preprint arXiv:2302.04761, 2023.

Yongliang Shen, Kaitao Song, Xu Tan, Dongsheng Li, Weiming Lu, và Yueting Zhuang. HuggingGPT: Giải quyết Các Nhiệm vụ AI với ChatGPT và Bạn bè của nó trong Hugging Face, Tháng 5 2023.

--- TRANG 12 ---

Kurt Shuster, Jing Xu, Mojtaba Komeili, Da Ju, Eric Michael Smith, Stephen Roller, Megan Ung, Moya Chen, Kushal Arora, Joshua Lane, et al. Blenderbot 3: một tác nhân đối thoại được triển khai liên tục học để tham gia một cách có trách nhiệm. arXiv preprint arXiv:2208.03188, 2022.

Aarohi Srivastava, Abhinav Rastogi, Abhishek Rao, Abu Awal Md Shoeb, Abubakar Abid, Adam Fisch, Adam R. Brown, Adam Santoro, Aditya Gupta, Adrià Garriga-Alonso, Agnieszka Kluska, Aitor Lewkowycz, Akshat Agarwal, Alethea Power, Alex Ray, Alex Warstadt, Alexander W. Kocurek, Ali Safaya, Ali Tazarv, Alice Xiang, Alicia Parrish, Allen Nie, Aman Hussain, Amanda Askell, Amanda Dsouza, Ambrose Slone, Ameet Rahane, Anantharaman S. Iyer, Anders Johan Andreassen, Andrea Madotto, Andrea Santilli, Andreas Stuhlmüller, Andrew M. Dai, Andrew La, Andrew Lampinen, Andy Zou, Angela Jiang, Angelica Chen, Anh Vuong, Animesh Gupta, Anna Gottardi, Antonio Norelli, Anu Venkatesh, Arash Gholamidavoodi, Arfa Tabassum, Arul Menezes, Arun Kirubarajan, Asher Mullokandov, Ashish Sabharwal, Austin Herrick, Avia Efrat, Aykut Erdem, Ayla Karakaş, B. Ryan Roberts, Bao Sheng Loe, Barret Zoph, Bartłomiej Bojanowski, Batuhan Özyurt, Behnam Hedayatnia, Behnam Neyshabur, Benjamin Inden, Benno Stein, Berk Ekmekci, Bill Yuchen Lin, Blake Howald, Bryan Orinion, Cameron Diao, Cameron Dour, Catherine Stinson, Cedrick Argueta, Cesar Ferri, Chandan Singh, Charles Rathkopf, Chenlin Meng, Chitta Baral, Chiyu Wu, Chris Callison-Burch, Christopher Waites, Christian Voigt, Christopher D Manning, Christopher Potts, Cindy Ramirez, Clara E. Rivera, Clemencia Siro, Colin Raffel, Courtney Ashcraft, Cristina Garbacea, Damien Sileo, Dan Garrette, Dan Hendrycks, Dan Kilman, Dan Roth, C. Daniel Freeman, Daniel Khashabi, Daniel Levy, Daniel Moseguí González, Danielle Perszyk, Danny Hernandez, Danqi Chen, Daphne Ippolito, Dar Gilboa, David Dohan, David Drakard, David Jurgens, Debajyoti Datta, Deep Ganguli, Denis Emelin, Denis Kleyko, Deniz Yuret, Derek Chen, Derek Tam, Dieuwke Hupkes, Diganta Misra, Dilyar Buzan, Dimitri Coelho Mollo, Diyi Yang, Dong-Ho Lee, Dylan Schrader, Ekaterina Shutova, Ekin Dogus Cubuk, Elad Segal, Eleanor Hagerman, Elizabeth Barnes, Elizabeth Donoway, Ellie Pavlick, Emanuele Rodolà, Emma Lam, Eric Chu, Eric Tang, Erkut Erdem, Ernie Chang, Ethan A Chi, Ethan Dyer, Ethan Jerzak, Ethan Kim, Eunice Engefu Manyasi, Evgenii Zheltonozhskii, Fanyue Xia, Fatemeh Siar, Fernando Martínez-Plumed, Francesca Happé, Francois Chollet, Frieda Rong, Gaurav Mishra, Genta Indra Winata, Gerard de Melo, Germán Kruszewski, Giambattista Parascandolo, Giorgio Mariani, Gloria Xinyue Wang, Gonzalo Jaimovitch-Lopez, Gregor Betz, Guy Gur-Ari, Hana Galijasevic, Hannah Kim, Hannah Rashkin, Hannaneh Hajishirzi, Harsh Mehta, Hayden Bogar, Henry Francis Anthony Shevlin, Hinrich Schuetze, Hiromu Yakura, Hongming Zhang, Hugh Mee Wong, Ian Ng, Isaac Noble, Jaap Jumelet, Jack Geissinger, Jackson Kernion, Jacob Hilton, Jaehoon Lee, Jaime Fernández Fisac, James B Simon, James Koppel, James Zheng, James Zou, Jan Kocon, Jana Thompson, Janelle Wingfield, Jared Kaplan, Jarema Radom, Jascha Sohl-Dickstein, Jason Phang, Jason Wei, Jason Yosinski, Jekaterina Novikova, Jelle Bosscher, Jennifer Marsh, Jeremy Kim, Jeroen Taal, Jesse Engel, Jesujoba Alabi, Jiacheng Xu, Jiaming Song, Jillian Tang, Joan Waweru, John Burden, John Miller, John U. Balis, Jonathan Batchelder, Jonathan Berant, Jörg Frohberg, Jos Rozen, Jose Hernandez-Orallo, Joseph Boudeman, Joseph Guerr, Joseph Jones, Joshua B. Tenenbaum, Joshua S. Rule, Joyce Chua, Kamil Kanclerz, Karen Livescu, Karl Krauth, Karthik Gopalakrishnan, Katerina Ignatyeva, Katja Markert, Kaustubh Dhole, Kevin Gimpel, Kevin Omondi, Kory Wallace Mathewson, Kristen Chiafullo, Ksenia Shkaruta, Kumar Shridhar, Kyle McDonell, Kyle Richardson, Laria Reynolds, Leo Gao, Li Zhang, Liam Dugan, Lianhui Qin, Lidia Contreras-Ochando, Louis-Philippe Morency, Luca Moschella, Lucas Lam, Lucy Noble, Ludwig Schmidt, Luheng He, Luis Oliveros-Colón, Luke Metz, Lütfi Kerem Senel, Maarten Bosma, Maarten Sap, Maartje Ter Hoeve, Maheen Farooqi, Manaal Faruqui, Mantas Mazeika, Marco Baturan, Marco Marelli, Marco Maru, Maria Jose Ramirez-Quintana, Marie Tolkiehn, Mario Giulianelli, Martha Lewis, Martin Potthast, Matthew L Leavitt, Matthias Hagen, Mátyás Schubert, Medina Orduna Baitemirova, Melody Arnaud, Melvin McElrath, Michael Andrew Yee, Michael Cohen, Michael Gu, Michael Ivanitskiy, Michael Starritt, Michael Strube, Michal Swedrowski, Michele Bevilacqua, Michihiro Yasunaga, Mihir Kale, Mike Cain, Mimee Xu, Mirac Suzgun, Mitch Walker, Mo Tiwari, Mohit Bansal, Moin Aminnaseri, Mor Geva, Mozhdeh Gheini, Mukund Varma T, Nanyun Peng, Nathan Andrew Chi, Nayeon Lee, Neta Gur-Ari Krakover, Nicholas Cameron, Nicholas Roberts, Nick Doiron, Nicole Martinez, Nikita Nangia, Niklas Deckers, Niklas Muennighoff, Nitish Shirish Keskar, Niveditha S. Iyer, Noah Constant, Noah Fiedel, Nuan Wen, Oliver Zhang, Omar Agha, Omar Elbaghdadi, Omer Levy, Owain Evans, Pablo Antonio Moreno Casares, Parth Doshi, Pascale Fung, Paul Pu Liang, Paul Vicol, Pegah Alipoormolabashi, Peiyuan Liao, Percy Liang, Peter W Chang, Peter Eckersley, Phu Mon Htut, Pinyu Hwang, Piotr Miłkowski, Piyush Patil, Pouya Pezeshkpour, Priti Oli, Qiaozhu Mei, Qing Lyu, Qinlang Chen, Rabin Banjade, Rachel Etta Rudolph, Raefer Gabriel, Rahel Habacker, Ramon Risco, Raphaël Millière, Rhythm Garg, Richard Barnes, Rif A. Saurous, Riku Arakawa, Robbe Raymaekers, Robert Frank, Rohan Sikand, Roman Novak, Roman Sitelew, Ronan Le Bras, Rosanne Liu, Rowan Jacobs, Rui Zhang, Russ Salakhutdinov, Ryan Andrew Chi, Seungjae Ryan Lee, Ryan Stovall, Ryan Teehan, Rylan Yang, Sahib Singh, Saif M. Mohammad, Sajant Anand, Sam Dillavou, Sam Shleifer, Sam Wiseman, Samuel Gruetter, Samuel R. Bowman, Samuel Stern Schoenholz, Sanghyun Han, Sanjeev Kwatra, Sarah A. Rous, Sarik Ghazarian, Sayan Ghosh, Sean Casey, Sebastian Bischoff, Sebastian Gehrmann, Sebastian Schuster, Sepideh Sadeghi, Shadi Hamdan, Sharon Zhou, Shashank Srivastava, Sherry Shi, Shikhar Singh, Shima Asaadi, Shixiang Shane Gu, Shubh Pachchigar, Shubham Toshniwal, Shyam Upadhyay, Shyamolima Shammie Debnath, Siamak Shakeri, Simon Thormeyer, Simone

--- TRANG 13 ---

Melzi, Siva Reddy, Sneha Priscilla Makini, Soo-Hwan Lee, Spencer Torene, Sriharsha Hatwar, Stanislas Dehaene, Stefan Divic, Stefano Ermon, Stella Biderman, Stephanie Lin, Stephen Prasad, Steven Piantadosi, Stuart Shieber, Summer Misherghi, Svetlana Kiritchenko, Swaroop Mishra, Tal Linzen, Tal Schuster, Tao Li, Tao Yu, Tariq Ali, Tatsunori Hashimoto, Te-Lin Wu, Théo Desbordes, Theodore Rothschild, Thomas Phan, Tianle Wang, Tiberius Nkinyili, Timo Schick, Timofei Kornev, Titus Tunduny, Tobias Gerstenberg, Trenton Chang, Trishala Neeraj, Tushar Khot, Tyler Shultz, Uri Shaham, Vedant Misra, Vera Demberg, Victoria Nyamai, Vikas Raunak, Vinay Venkatesh Ramasesh, vinay uday prabhu, Vishakh Padmakumar, Vivek Srikumar, William Fedus, William Saunders, William Zhang, Wout Vossen, Xiang Ren, Xiaoyu Tong, Xinran Zhao, Xinyi Wu, Xudong Shen, Yadollah Yaghoobzadeh, Yair Lakretz, Yangqiu Song, Yasaman Bahri, Yejin Choi, Yichi Yang, Yiding Hao, Yifu Chen, Yonatan Belinkov, Yu Hou, Yufang Hou, Yuntao Bai, Zachary Seid, Zhuoye Zhao, Zijian Wang, Zijie J. Wang, Zirui Wang, và Ziyi Wu. Vượt qua trò chơi bắt chước: Định lượng và ngoại suy khả năng của các mô hình ngôn ngữ. Transactions on Machine Learning Research, 2023. ISSN 2835-8856. URL https://openreview.net/forum?id=uyTL5Bvosj.

George Stein, Jesse C. Cresswell, Rasa Hosseinzadeh, Yi Sui, Brendan Leigh Ross, Valentin Villecroze, Zhaoyan Liu, Anthony L. Caterini, J. Eric T. Taylor, và Gabriel Loaiza-Ganem. Phơi bày các lỗ hổng của các thước đo đánh giá mô hình tạo sinh và cách đối xử không công bằng của chúng với các mô hình khuếch tán, 2023.

Dídac Surís, Sachit Menon, và Carl Vondrick. ViperGPT: Suy luận Thị giác thông qua Thực thi Python để Lý luận, Tháng 3 2023.

Yashar Talebirad và Amirhossein Nadiri. Hợp tác Đa tác nhân: Khai thác Sức mạnh của các Tác nhân LLM Thông minh, Tháng 6 2023.

Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, Dan Bikel, Lukas Blecher, Cristian Canton Ferrer, Moya Chen, Guillem Cucurull, David Esiobu, Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller, Cynthia Gao, Vedanuj Goswami, Naman Goyal, Anthony Hartshorn, Saghar Hosseini, Rui Hou, Hakan Inan, Marcin Kardas, Viktor Kerkez, Madian Khabsa, Isabel Kloumann, Artem Korenev, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Diana Liskovich, Yinghai Lu, Yuning Mao, Xavier Martinet, Todor Mihaylov, Pushkar Mishra, Igor Molybog, Yixin Nie, Andrew Poulton, Jeremy Reizenstein, Rashi Rungta, Kalyan Saladi, Alan Schelten, Ruan Silva, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh Tang, Ross Taylor, Adina Williams, Jian Xiang Kuan, Puxin Xu, Zheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, Robert Stojnic, Sergey Edunov, và Thomas Scialom. Llama 2: Các mô hình chat nền tảng mở và được tinh chỉnh, 2023.

Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, và Samuel Bowman. Glue: Một bộ tiêu chuẩn đa nhiệm vụ và nền tảng phân tích để hiểu ngôn ngữ tự nhiên. Trong Proceedings of the 2018 EMNLP Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP, trang 353–355. Association for Computational Linguistics, Tháng 11 2018. URL https://aclanthology.org/W18-5446.

Alex Wang, Yada Pruksachatkun, Nikita Nangia, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, và Samuel Bowman. SuperGLUE: Một Bộ tiêu chuẩn Dính hơn cho Các Hệ thống Hiểu Ngôn ngữ Đa mục đích. Trong Advances in Neural Information Processing Systems, tập 32. Curran Associates, Inc., 2019.

Chenfei Wu, Shengming Yin, Weizhen Qi, Xiaodong Wang, Zecheng Tang, và Nan Duan. Visual ChatGPT: Nói chuyện, Vẽ và Chỉnh sửa với Các Mô hình Nền tảng Thị giác, Tháng 3 2023.

Binfeng Xu, Xukun Liu, Hua Shen, Zeyu Han, Yuhan Li, Murong Yue, Zhiyuan Peng, Yuchen Liu, Ziyu Yao, và Dongkuan Xu. Gentopia: Một Nền tảng Hợp tác cho LLM được Tăng cường Công cụ, Tháng 8 2023a.

Qiantong Xu, Fenglu Hong, Bo Li, Changran Hu, Zhengyu Chen, và Jian Zhang. Về khả năng thao tác công cụ của các mô hình ngôn ngữ lớn mã nguồn mở, 2023b.

Hui Yang, Sifu Yue, và Yunzhong He. Auto-GPT cho Quyết định Trực tuyến: Các Bộ tiêu chuẩn và Ý kiến Bổ sung, Tháng 6 2023.

Andy Zeng, Maria Attarian, Brian Ichter, Krzysztof Choromanski, Adrian Wong, Stefan Welker, Federico Tombari, Aveek Purohit, Michael Ryoo, Vikas Sindhwani, Johnny Lee, Vincent Vanhoucke, và Pete Florence. Các Mô hình Socratic: Soạn Lý luận Đa phương thức Zero-Shot với Ngôn ngữ, Tháng 5 2022.

Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric. P Xing, Hao Zhang, Joseph E. Gonzalez, và Ion Stoica. Đánh giá llm-as-a-judge với mt-bench và chatbot arena, 2023.

--- TRANG 14 ---

Yuchen Zhuang, Yue Yu, Kuan Wang, Haotian Sun, và Chao Zhang. ToolQA: Một Bộ dữ liệu cho Trả lời Câu hỏi LLM với Công cụ Bên ngoài, Tháng 6 2023.

--- TRANG 15 ---

A Công trình liên quan mở rộng

Các Mô hình Ngôn ngữ Lớn như Trợ Lý Tổng Quát. Một số hướng đã được khám phá để biến LLM thành trợ lý đa mục đích: (i) sử dụng LLM tác nhân đơn với khả năng tốt hơn thông qua lời nhắc Chain of Thought hoặc các cơ chế tương đương, như GPT-Engineer (Osika, 2023), AutoGPT (Yang et al., 2023); (ii) sử dụng nhiều LLM tác nhân để tranh luận và cùng nhau đạt được kết luận tốt hơn để trả lời các truy vấn người dùng (Li et al., 2023a; Hong et al., 2023; Chan et al., 2023; Talebirad và Nadiri, 2023); (iii) sử dụng LLM tác nhân đơn được tăng cường với các công cụ cụ thể, như Blender Bot 3 (Shuster et al., 2022), BOLAA (Liu et al., 2023b) và AssistGPT (Gao et al., 2023) mở rộng LLM với các thành phần lập kế hoạch, Socratic Models (Zeng et al., 2022) hoặc Visual ChatGPT (Wu et al., 2023) được mở rộng với các mô hình đa phương thức, WebGPT Nakano et al. (2021) được tinh chỉnh cho tìm kiếm web, hoặc một tập hợp các công cụ và API, như Toolformer (Schick et al., 2023) được tinh chỉnh cho việc sử dụng công cụ tổng quát, ViperGPT (Surís et al., 2023) sử dụng khả năng lập trình để tạo ra các lời gọi API đúng, HuggingGPT (Shen et al., 2023) tận dụng các lời gọi đến hệ sinh thái HuggingFace để mở rộng LLM của nó với khả năng của các mô hình ML khác, hoặc thậm chí (iv) cung cấp các thư viện API/công cụ hoàn toàn mới, như các plugin OpenAI, SemanticKernel (Microsoft, 2023), Langchain (Chase, 2022) và MiniChain (Rush, 2023).

B Thẻ dữ liệu

Chúng tôi tuân theo (Bender và Friedman, 2018) để tạo thẻ dữ liệu này, nơi chúng tôi cố gắng tóm tắt và tập trung tất cả thông tin có thể liên quan để phân tích bộ dữ liệu này.

Lý do tuyển chọn. Điều này được chi tiết trong Phần 3.4 và Phụ lục D.

Đa dạng ngôn ngữ. Thông tin về quốc tịch của các chú thích viên của chúng tôi không được cung cấp, nhưng họ đều có trụ sở tại Hoa Kỳ, và tất cả các câu hỏi, câu trả lời và siêu dữ liệu được viết bằng tiếng Anh chính thống (do đó rất có thể là en-US). Chúng tôi cũng có thể lưu ý rằng tất cả các tác giả của bài báo này là người Pháp và không có tiếng Anh là ngôn ngữ đầu tiên, điều này có thể dẫn đến việc bao gồm cách diễn đạt tiếng Anh không chuẩn trong các câu hỏi hoặc câu trả lời.

Nhân khẩu học Người tuyển chọn và Chú thích viên. Theo các định nghĩa được đề xuất trong (Bender và Friedman, 2018), xây dựng GAIA yêu cầu công việc của Người tuyển chọn, những người thiết kế các câu hỏi và câu trả lời của chúng, và Chú thích viên, những người độc lập chú thích các câu hỏi để đánh giá tính không mơ hồ của chúng. Cả hai đều đến từ dân số sau:

• Tuổi:
– 18-25: 17%
– 26-35: 39%
– 36-45: 26%
– 45-55: 13%
– 56-65: 4%

• Giới tính: 57% Nam, 43% Nữ.

• Nền tảng học thuật:
– Bằng Cử nhân: 61%
– Bằng Thạc sĩ: 26%
– Tiến sĩ: 17%

Đặc điểm văn bản. Điều này được chi tiết trong Phụ lục C.

--- TRANG 16 ---

C Mô tả mở rộng về GAIA

Mô tả khả năng. Khi trả lời các câu hỏi, các chú thích viên chỉ định các bước được tuân theo và liệt kê các công cụ họ sử dụng. Dựa trên tập hợp các công cụ được đề cập bởi các chú thích viên, chúng tôi định nghĩa các khả năng yêu cầu bởi GAIA. Đối với mỗi khả năng, chúng tôi báo cáo ví dụ về công cụ tương ứng như được báo cáo bởi các chú thích viên.

• Duyệt web: các công cụ liên quan đến tìm kiếm web và duyệt trang web. Ví dụ: Trình duyệt Web, Công cụ tìm kiếm, Truy cập widget trang web, Truy cập YouTube, Google Street View.

• Đa phương thức: các công cụ liên quan đến hiểu phương thức dữ liệu khác ngoài văn bản. Ví dụ: Công cụ speech-to-text, Nhận dạng video, Nhận dạng hình ảnh, OCR, Google Street View.

• Lập trình: các công cụ liên quan đến thực thi mã. Ví dụ: Python, máy tính, Bộ mã hóa cipher thay thế, Trình biên dịch C++, Công cụ/script đảo ngược từ.

• Đọc loại tệp đa dạng: các công cụ liên quan đến hiểu các loại tệp khác nhau được đưa ra bởi người dùng hoặc tìm thấy trên web. Ví dụ: Trình xem PDF, Truy cập tệp Excel, Trình xem PowerPoint, Truy cập CSV, Truy cập tệp Txt.

• N/A: công cụ cho các nhiệm vụ hiện có thể được thực hiện bởi LLM không được tăng cường. Ví dụ: Cơ sở dữ liệu quy tắc Tetris, Trình dịch tiếng Đức, Trình kiểm tra chính tả, Trình soạn thảo văn bản, Dữ liệu nốt bass.

Lưu ý rằng một công cụ có thể thuộc các danh mục khác nhau. Ví dụ, Google Street View yêu cầu truy cập web, duyệt, nhưng cũng đa phương thức. Do đó, các danh mục này là chỉ dẫn về các khả năng yêu cầu bởi GAIA và không phải là một hệ thống phân loại hoàn hảo của các câu hỏi của chúng tôi.

Loại tệp. Một số câu hỏi GAIA đi kèm với các tệp bổ sung, có phân phối được đưa ra trong Hình 6.

[Biểu đồ thanh hiển thị phân phối các loại tệp]
0 5 10 15 20 25 30
Số lượng tệp

xlsx
png
pdf
txt
mp3
jpg
csv
docx
pptx
zip
xml
py
json
m4a
pdb
MOV
jsonl

29
18
15
13
7
6
2
2
2
1
1
1
1
1
1
1
1

Phân phối các Loại Tệp

Hình 6 Phân phối ban đầu của các loại tệp trong GAIA.

Độ khó của các câu hỏi. Phân tích của chúng tôi về thời gian được các chú thích viên dành để trả lời một câu hỏi cho thấy tương quan với số bước thực hiện. Tương quan ít rõ ràng hơn với số công cụ khác nhau được sử dụng để trả lời.

--- TRANG 17 ---

[Biểu đồ scatter plot 1]
0 1 2 3 4 5 6
Số công cụ được sử dụng để trả lời

0
10
20
30
40
50
60
Thời gian trả lời (phút)

Thời gian so với số công cụ để trả lời

Cấp độ 2
Cấp độ 1
Cấp độ 3

Hình 7 Sử dụng nhiều công cụ không nhất thiết liên quan đến nhiều thời gian hơn để trả lời một câu hỏi.

[Biểu đồ scatter plot 2]
0 10 20 30 40
Số bước thực hiện để trả lời

0
10
20
30
40
50
60
Thời gian trả lời (phút)

Thời gian so với số bước để trả lời

Cấp độ 2
Cấp độ 1
Cấp độ 3

Hình 8 Không có gì đáng ngạc nhiên, số bước thực hiện để trả lời có tương quan với thời gian thực hiện.

D Mô tả mở rộng về khung thiết kế câu hỏi của chúng tôi

Giai đoạn tạo câu hỏi. Chúng tôi cung cấp cho các chú thích viên một tập hợp câu hỏi GAIA ban đầu mà chúng tôi tự thiết kế, kèm theo các hướng dẫn sau:

Chúng tôi muốn tăng cường bộ dữ liệu của các câu hỏi được cung cấp (không phải biến thể của những gì chúng tôi đã có).

Yêu cầu:
• Đảm bảo câu hỏi của bạn dựa trên nguồn sự thật (Wikipedia, arXiv, github, khác...). Đối với Cấp độ 2 và Cấp độ 3, một cách tốt để tạo câu hỏi là kết hợp các nguồn sự thật.
• Đảm bảo câu trả lời cho câu hỏi của bạn không tồn tại trên internet dưới dạng văn bản thuần túy.
• Đảm bảo câu trả lời cho câu hỏi của bạn là một số hoặc nhiều nhất vài từ để làm cho đánh giá mạnh mẽ.
• Đảm bảo câu trả lời cho câu hỏi của bạn không thay đổi theo thời gian. Điều này bao gồm khả năng xóa nguồn sự thật.
• Đảm bảo câu trả lời cho câu hỏi của bạn không mơ hồ.
• Đảm bảo câu hỏi của bạn "thú vị", tức là khi đọc nó bạn nghĩ rằng một trợ lý AI trả lời loại câu hỏi này sẽ giúp bạn rất nhiều.
• Đảm bảo câu hỏi của bạn có thể được trả lời trong một khoảng thời gian hợp lý bởi một chú thích viên con người.
• (Được thêm sau này): kiểm tra robots.txt của trang web chứa thông tin cần thiết để trả lời để nó có thể truy cập được đối với các trợ lý AI.

Các chú thích viên cũng được yêu cầu trả lời các câu hỏi họ tạo ra. Chúng tôi cung cấp một ví dụ điển hình về câu hỏi được chú thích trong Bảng 1.

Giai đoạn xác thực. Sau khi tạo câu hỏi, chúng tôi yêu cầu hai chú thích viên mới độc lập trả lời các câu hỏi để kiểm tra nó không mơ hồ. Chúng tôi cung cấp một đầu ra chú thích viên điển hình cho giai đoạn xác thực trong Bảng 2, cũng như thống kê bổ sung về giai đoạn xác thực của giao thức của chúng tôi trong Bảng 3. Nếu các chú thích viên mới không hoàn toàn đồng ý với câu trả lời gốc và không có lỗi con người, câu hỏi được sửa chữa nếu có thể và loại bỏ khác.

Chúng tôi ước tính việc tạo một câu hỏi, bao gồm xác thực của nó bởi hai chú thích viên bổ sung và sửa chữa tiềm năng, yêu cầu hai giờ thời gian chú thích viên.

--- TRANG 18 ---

Câu hỏi: Số lượng đăng ký thực tế của thử nghiệm lâm sàng về H. pylori ở bệnh nhân mụn trứng cá từ tháng 1-5 năm 2018 như được liệt kê trên trang web NIH là bao nhiêu?
Tệp: Không có
Cấp độ: 1
Các bước:
- Tìm kiếm "nih" trên Google search.
- Nhấp vào liên kết đầu tiên đến nih.gov.
- Tìm kiếm "h pylori acne" trong hộp tìm kiếm.
- Nhấp "Thêm" và chọn "Clinical Trials".
- Nhấp vào kết quả về H. Pylori và mụn trứng cá.
- Kiểm tra ngày để xác nhận nó từ tháng 1 đến tháng 5 năm 2018.
- Mở "Tabular View".
- Cuộn xuống Actual Enrollment và ghi lại số.
Số bước: 8
Câu trả lời: 90
Thời gian trả lời: 8 phút
Công cụ:
- Trình duyệt Web
Số công cụ: 1

Bảng 1 Một câu hỏi được chú thích trong giai đoạn tạo câu hỏi.

Câu hỏi: Số lượng đăng ký thực tế của thử nghiệm lâm sàng về H. pylori ở bệnh nhân mụn trứng cá từ tháng 1-5 năm 2018 như được liệt kê trên trang web NIH là bao nhiêu?
Tệp: Không có
Cấp độ: 1
Phản hồi người xác minh: 90
Khớp câu trả lời: Có - câu trả lời của tôi khớp với câu trả lời đúng.
Nguyên nhân không khớp: Không có

Bảng 2 Một câu hỏi được chú thích trong giai đoạn xác thực.

--- TRANG 19 ---

Sau khi hai chú thích viên mới, độc lập trả lời cho tất cả các câu hỏi được tạo ra:

Hai chú thích viên mới đồng ý với câu trả lời gốc: 55%
Một chú thích viên mới đồng ý với câu trả lời gốc, người khác không đồng ý: 27%
Hai chú thích viên mới không đồng ý với câu trả lời gốc: 18%

Câu hỏi hợp lệ (tổng hợp)*: 68%
Câu hỏi Cấp độ 1 hợp lệ: 75%
Câu hỏi Cấp độ 2 hợp lệ: 68%
Câu hỏi Cấp độ 3 hợp lệ: 47%

Điểm số con người (tổng hợp)**: 92%
Điểm số con người cho Cấp độ 1: 94%
Điểm số con người cho Cấp độ 2: 92%
Điểm số con người cho Cấp độ 3: 87%

Bảng 3 Thống kê về giai đoạn xác thực. 623 câu hỏi mới được tạo ra đã được xác thực bởi hai chú thích viên mới mỗi câu. Thống kê được tính trên 1246 chú thích của họ. *: một câu hỏi hợp lệ là một câu hỏi mà hai chú thích viên đưa ra cùng câu trả lời như người thiết kế câu hỏi, hoặc chỉ một chú thích viên đưa ra cùng câu trả lời như người thiết kế câu hỏi và người kia mắc lỗi. **: đường cơ sở con người được tính như phần câu trả lời đúng cho tất cả các lần thử trên các câu hỏi hợp lệ bởi các chú thích viên mới.

Thước đo | Điểm số theo % (↑) | Thời gian trung bình trả lời tính bằng phút (↓)
Cấp độ | Cấp độ 1 | Cấp độ 2 | Cấp độ 3 | Cấp độ 1 | Cấp độ 2 | Cấp độ 3
Số câu hỏi | 146 | 245 | 75 | 146 | 245 | 75
GPT4 | 9.1±2.5 | 2.6±0.6 | 0 | 0.19 | 0.15 | N.A.
GPT4 Turbo | 13.0±2.1 | 5.5±1.4 | 0 | 0.24 | 0.12 | N.A.
AutoGPT (GPT4 backend) | 14.4 | 0.4 | 0 | 7.6 | 11.7 | N.A.
GPT4 + plugins* | 30.3 | 9.7 | 0 | 0.65 | 0.53 | N.A.
Công cụ tìm kiếm | 7.4 | 0 | 0 | 7.4 | N.A. | N.A.
Chú thích viên con người** | 93.9 | 91.8 | 87.3 | 6.8 | 10.5 | 17.7

Bảng 4 Điểm số và thời gian trung bình trả lời cho các baseline khác nhau trên GAIA tính theo %. *: Điểm số GPT4 + plugins được thu thập bằng cách chọn plugin thủ công, và không thể được tái tạo chính xác vì những lý do được mô tả trong văn bản chính. **: Điểm số con người tương ứng với phần câu trả lời đúng bởi các chú thích viên xác thực cho các câu hỏi hợp lệ. Bất cứ khi nào chúng tôi có quyền truy cập API trực tiếp, chúng tôi chạy mô hình ba lần và báo cáo trung bình. Thời gian cho API được thu thập bằng cách chạy API trên 20 câu hỏi sau đó tính trung bình, và được thực hiện tại một thời điểm duy nhất: chúng không nhằm phản ánh tốc độ GPT4 so với GPT4 Turbo, mà GPT4 so với các loại phương pháp khác để trả lời GAIA.

D.1 Đánh giá mở rộng

Chúng tôi cung cấp điểm số chi tiết của các phương pháp khác nhau được đánh giá trong Bảng 4.

Các ví dụ bổ sung về GPT4 trả lời GAIA. Chúng tôi cung cấp thêm vết lý luận của GPT4 có và không có plugin khi trả lời GAIA. Đầu ra của AutoGPT hiện tại dài hơn nhiều, dày đặc hơn và ít có thể diễn giải hơn so với GPT4. Ví dụ về đầu ra AutoGPT do đó được cung cấp trong tài liệu bổ sung cho cùng một câu hỏi GAIA như ví dụ trong Hình 9.

--- TRANG 20 ---

Lời nhắc hệ thống: Bạn là một trợ lý AI tổng quát. Tôi sẽ hỏi bạn một câu hỏi. Báo cáo suy nghĩ của bạn, và kết thúc câu trả lời của bạn với mẫu sau: CÂU TRẢ LỜI CUỐI CÙNG: [CÂU TRẢ LỜI CUỐI CÙNG CỦA BẠN].
CÂU TRẢ LỜI CUỐI CÙNG của bạn nên là một số HOẶC càng ít từ càng tốt HOẶC danh sách phân cách bằng dấu phẩy của các số và/hoặc chuỗi.
Nếu bạn được yêu cầu một số, đừng sử dụng dấu phẩy để viết số của bạn cũng không sử dụng đơn vị như $ hoặc dấu phần trăm trừ khi được chỉ định khác.
Nếu bạn được yêu cầu một chuỗi, đừng sử dụng mạo từ, cũng không viết tắt (ví dụ cho các thành phố), và viết các chữ số bằng văn bản thuần túy trừ khi được chỉ định khác.
Nếu bạn được yêu cầu danh sách phân cách bằng dấu phẩy, áp dụng các quy tắc trên tùy thuộc vào việc yếu tố được đưa vào danh sách là số hay chuỗi.

Câu hỏi GAIA: Câu trả lời cuối cùng của bạn nên là một số, hoặc càng ít từ càng tốt. Các mẫu vật Việt Nam được mô tả bởi Kuznetzov trong bài báo năm 2010 của Nedoshivina cuối cùng được lưu trữ ở đâu? Chỉ cho tôi tên thành phố mà không viết tắt.

GPT4:
Tôi không thể duyệt internet hoặc truy cập thông tin mới sau ngày cắt kiến thức của tôi vào tháng 1 năm 2022. Do đó, tôi không thể cung cấp tên thành phố nơi các mẫu vật Việt Nam được mô tả bởi Kuznetzov trong bài báo năm 2010 của Nedoshivina cuối cùng được lưu trữ.

CÂU TRẢ LỜI CUỐI CÙNG: Không thể cung cấp | Sự thật cơ bản: Saint Petersburg ✗

Lời nhắc hệ thống: Bạn là một trợ lý AI tổng quát. Tôi sẽ hỏi bạn một câu hỏi. Báo cáo suy nghĩ của bạn, và kết thúc câu trả lời của bạn với mẫu sau: CÂU TRẢ LỜI CUỐI CÙNG: [CÂU TRẢ LỜI CUỐI CÙNG CỦA BẠN].
CÂU TRẢ LỜI CUỐI CÙNG của bạn nên là một số HOẶC càng ít từ càng tốt HOẶC danh sách phân cách bằng dấu phẩy của các số và/hoặc chuỗi.
Nếu bạn được yêu cầu một số, đừng sử dụng dấu phẩy để viết số của bạn cũng không sử dụng đơn vị như $ hoặc dấu phần trăm trừ khi được chỉ định khác.
Nếu bạn được yêu cầu một chuỗi, đừng sử dụng mạo từ, cũng không viết tắt (ví dụ cho các thành phố), và viết các chữ số bằng văn bản thuần túy trừ khi được chỉ định khác.
Nếu bạn được yêu cầu danh sách phân cách bằng dấu phẩy, áp dụng các quy tắc trên tùy thuộc vào việc yếu tố được đưa vào danh sách là số hay chuỗi.

Câu hỏi GAIA: Câu trả lời cuối cùng của bạn nên là một số, hoặc càng ít từ càng tốt. Các mẫu vật Việt Nam được mô tả bởi Kuznetzov trong bài báo năm 2010 của Nedoshivina cuối cùng được lưu trữ ở đâu? Chỉ cho tôi tên thành phố mà không viết tắt.

GPT4 (Duyệt web):
Duyệt Bing:
/search "Các mẫu vật Việt Nam được mô tả bởi Kuznetzov Nedoshivina 2010 bài báo vị trí lưu trữ"
/readResult
Đọc nội dung
Kết quả:
Một danh mục các mẫu vật loại của Tortricidae được mô tả bởi V. I. Kuznetzov từ Việt Nam và được lưu trữ tại Viện Động vật học, St. Petersburg : Nedoshivina, Svetlana : Tải xuống Miễn phí, Mượn, và Streaming : Internet Archive

CÂU TRẢ LỜI CUỐI CÙNG: Saint Petersburg | Sự thật cơ bản: Saint Petersburg ✓

Hình 9 Tìm kiếm web đúng cách rất hiệu quả để trả lời các câu hỏi GAIA. Vết lý luận được thu thập với phiên bản duyệt web GPT4 hiện tại.

--- TRANG 21 ---

Lời nhắc hệ thống: Bạn là một trợ lý AI tổng quát. Tôi sẽ hỏi bạn một câu hỏi. Báo cáo suy nghĩ của bạn, và kết thúc câu trả lời của bạn với mẫu sau: CÂU TRẢ LỜI CUỐI CÙNG: [CÂU TRẢ LỜI CUỐI CÙNG CỦA BẠN].
CÂU TRẢ LỜI CUỐI CÙNG của bạn nên là một số HOẶC càng ít từ càng tốt HOẶC danh sách phân cách bằng dấu phẩy của các số và/hoặc chuỗi.
Nếu bạn được yêu cầu một số, đừng sử dụng dấu phẩy để viết số của bạn cũng không sử dụng đơn vị như $ hoặc dấu phần trăm trừ khi được chỉ định khác.
Nếu bạn được yêu cầu một chuỗi, đừng sử dụng mạo từ, cũng không viết tắt (ví dụ cho các thành phố), và viết các chữ số bằng văn bản thuần túy trừ khi được chỉ định khác.
Nếu bạn được yêu cầu danh sách phân cách bằng dấu phẩy, áp dụng các quy tắc trên tùy thuộc vào việc yếu tố được đưa vào danh sách là số hay chuỗi.

Câu hỏi GAIA: Trong bộ phim Goldfinger, màu gì của đối tượng mà James Bond che giấu mình và người bạn đồng hành Pussy Galore của anh ta ở cuối phim? Nếu có nhiều màu, đặt chúng trong danh sách phân cách bằng dấu phẩy theo thứ tự bảng chữ cái.

GPT4 (Duyệt web):
Duyệt Bing:
/search "Goldfinger cảnh kết thúc màu đối tượng"
Goldfinger (1964) ending / spoiler
/readResult
Đọc nội dung
/search "Goldfinger cảnh kết thúc màu dù"
/readResult
Đọc nội dung

CÂU TRẢ LỜI CUỐI CÙNG: Orange, White | Sự thật cơ bản: orange, white ✓

Hình 10 Plugin duyệt GPT4 chính thức có thể tinh chỉnh truy vấn ban đầu của nó dựa trên thông tin nó tìm thấy. Vết lý luận này được thu thập với phiên bản plugin duyệt GPT4 đã bị loại bỏ, và không thể được tái tạo với phiên bản mới.

--- TRANG 22 ---

Lời nhắc hệ thống: [Cùng lời nhắc hệ thống như Hình 10.]

Câu hỏi GAIA: Một khối Rubik tiêu chuẩn đã bị vỡ thành các khối tạo nên các mặt của nó. Các khối được xáo trộn, và một khối bị loại bỏ. Có 6 khối với một mặt màu, 12 khối cạnh với hai mặt màu, và 8 khối góc với ba mặt màu. Tất cả các khối màu xanh lam đã được tìm thấy. Tất cả các khối ở phía trái trực tiếp, phải, trên và dưới khối trung tâm màu cam đã được tìm thấy, cùng với khối trung tâm. Các góc màu xanh lá cây đều đã được tìm thấy, cùng với tất cả màu xanh lá cây giáp với màu vàng. Đối với tất cả các khối màu cam được tìm thấy, các khối của mặt đối diện đã được tìm thấy. Khối bị loại bỏ có hai màu trên các mặt của nó. Chúng là gì? Trả lời bằng danh sách phân cách bằng dấu phẩy, với các màu được sắp xếp theo thứ tự bảng chữ cái.

GPT4:
Để giải quyết điều này, hãy chia nhỏ từng bước và hình dung một khối Rubik tiêu chuẩn:
• Một Khối Rubik Tiêu chuẩn có 6 mặt: Trước, Sau, Trái, Phải, Trên, Dưới.
• Mỗi mặt có một khối trung tâm (xác định màu của mặt đó), được bao quanh bởi 4 cạnh và 4 góc.
• Mỗi cạnh có hai màu, và mỗi góc có ba màu.

Cấu trúc Khối:
• Cam: Trước
• Đỏ: Sau
• Xanh lam: Trái
• Xanh lá cây: Phải
• Trắng: Trên
• Vàng: Dưới

Phân tích Từng bước:
• Tất cả các khối màu xanh lam đã được tìm thấy.
• Tất cả các khối ở phía trái trực tiếp, phải, trên và dưới khối trung tâm màu cam đã được tìm thấy, cùng với khối trung tâm.
• Điều này có nghĩa là các khối cam trung tâm, trên, dưới, trái và phải đã được tìm thấy.
• Tất cả các góc màu xanh lá cây đã được tìm thấy, cùng với tất cả màu xanh lá cây giáp với màu vàng.
• Điều này có nghĩa là tất cả các cạnh và góc xanh lá cây-vàng đã được tìm thấy.
• Đối với tất cả các khối màu cam được tìm thấy, các khối của mặt đối diện đã được tìm thấy.
• Điều này có nghĩa là tất cả các khối đỏ đối diện với các khối cam được tìm thấy cũng đã được tìm thấy.

Phương pháp Giải quyết: Vì khối bị loại bỏ có hai màu trên các mặt của nó, nó phải là một khối cạnh. Để xác định khối nào bị thiếu, chúng ta nên tìm khối cạnh không được tính đến bởi các điều kiện đã cho.
• Tất cả các khối màu xanh lam được tìm thấy, có nghĩa là tất cả các cạnh và góc màu xanh lam được tìm thấy.
• Khối trung tâm cam, và tất cả xung quanh nó, được tìm thấy, và do đó các khối đỏ đối diện cũng được tìm thấy.
• Tất cả các góc màu xanh lá cây được tìm thấy, và màu xanh lá cây giáp với màu vàng cũng được tìm thấy.
• Bằng cách trừ các khối được tìm thấy từ tổng số khối, chúng ta sẽ tìm thấy khối bị thiếu, đó là khối cạnh giữa các mặt đỏ và vàng.

CÂU TRẢ LỜI CUỐI CÙNG: Red, Yellow | Sự thật cơ bản: green, white ✗

Hình 11 GPT4 và các trợ lý khác gặp khó khăn với các câu đố, thường là các câu hỏi Cấp độ 1.

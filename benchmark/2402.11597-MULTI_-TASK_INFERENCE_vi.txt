Rohan Anil, Andrew M Dai, Orhan Firat, Melvin Johnson, Dmitry Lepikhin, Alexandre Passos, Siamak Shakeri, Emanuel Taropa, Paige Bailey, Zhifeng Chen, et al. 2023. Báo cáo kỹ thuật Palm 2. arXiv preprint arXiv:2305.10403.

Lucas Bandarkar, Davis Liang, Benjamin Muller, Mikel Artetxe, Satya Narayan Shukla, Donald Husa, Naman Goyal, Abhinandan Krishnan, Luke Zettlemoyer, và Madian Khabsa. 2023. Bộ đánh giá belebele: một bộ dữ liệu đọc hiểu song song trong 122 biến thể ngôn ngữ. arXiv preprint arXiv:2308.16884.

Chandra Bhagavatula, Ronan Le Bras, Chaitanya Malaviya, Keisuke Sakaguchi, Ari Holtzman, Hannah Rashkin, Doug Downey, Scott Wen-tau Yih, và Yejin Choi. 2019. Lý luận thông thường bắt cóc. arXiv preprint arXiv:1908.05739.

Yonatan Bisk, Rowan Zellers, Jianfeng Gao, Yejin Choi, et al. 2020. Piqa: Lý luận về thông thường vật lý trong ngôn ngữ tự nhiên. Trong Proceedings of the AAAI conference on artificial intelligence, tập 34, trang 7432–7439.

Samuel R Bowman, Gabor Angeli, Christopher Potts, và Christopher D Manning. 2015a. Một kho ngữ liệu chú thích lớn để học suy luận ngôn ngữ tự nhiên. arXiv preprint arXiv:1508.05326.

Samuel R. Bowman, Gabor Angeli, Christopher Potts, và Christopher D. Manning. 2015b. Một kho ngữ liệu chú thích lớn để học suy luận ngôn ngữ tự nhiên. Trong Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, trang 632–642, Lisbon, Portugal. Association for Computational Linguistics.

Yupeng Chang, Xu Wang, Jindong Wang, Yuan Wu, Kaijie Zhu, Hao Chen, Linyi Yang, Xiaoyuan Yi, Cunxiang Wang, Yidong Wang, et al. 2023. Một khảo sát về đánh giá các mô hình ngôn ngữ lớn. arXiv preprint arXiv:2307.03109.

Zhoujun Cheng, Jungo Kasai, và Tao Yu. 2023. Batch prompting: Suy luận hiệu quả với các API mô hình ngôn ngữ lớn. arXiv preprint arXiv:2301.08721.

Yew Ken Chia, Pengfei Hong, Lidong Bing, và Soujanya Poria. 2023. Instructeval: Hướng tới đánh giá toàn diện các mô hình ngôn ngữ lớn được điều chỉnh hướng dẫn. arXiv preprint arXiv:2306.04757.

Wei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng, Zhanghao Wu, Hao Zhang, Lianmin Zheng, Siyuan Zhuang, Yonghao Zhuang, Joseph E. Gonzalez, Ion Stoica, và Eric P. Xing. 2023. Vicuna: Một chatbot mã nguồn mở gây ấn tượng với gpt-4 với chất lượng 90%* chatgpt.

Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, et al. 2021. Huấn luyện trình xác minh để giải các bài toán từ toán học. arXiv preprint arXiv:2110.14168.

Pradeep Dasigi, Nelson F Liu, Ana Marasović, Noah A Smith, và Matt Gardner. 2019. Quoref: Một bộ dữ liệu đọc hiểu với các câu hỏi yêu cầu lý luận đồng tham chiếu. arXiv preprint arXiv:1908.05803.

Dheeru Dua, Yizhong Wang, Pradeep Dasigi, Gabriel Stanovsky, Sameer Singh, và Matt Gardner. 2019. Drop: Một bộ đánh giá đọc hiểu yêu cầu lý luận rời rạc trên các đoạn văn. arXiv preprint arXiv:1903.00161.

Yann Dubois, Xuechen Li, Rohan Taori, Tianyi Zhang, Ishaan Gulrajani, Jimmy Ba, Carlos Guestrin, Percy Liang, và Tatsunori B Hashimoto. 2023. Alpacafarm: Một khung mô phỏng cho các phương pháp học từ phản hồi con người. arXiv preprint arXiv:2305.14387.

Yao Fu, Litu Ou, Mingyu Chen, Yuhao Wan, Hao Peng, và Tushar Khot. 2023. Chain-of-thought hub: Một nỗ lực liên tục để đo lường hiệu suất lý luận của các mô hình ngôn ngữ lớn. arXiv preprint arXiv:2305.17306.

Leo Gao, Jonathan Tow, Stella Biderman, Sid Black, Anthony DiPofi, Charles Foster, Laurence Golding, Jeffrey Hsu, Kyle McDonell, Niklas Muennighoff, Jason Phang, Laria Reynolds, Eric Tang, Anish Thite, Ben Wang, Kevin Wang, và Andy Zou. 2021. Một khung cho đánh giá mô hình ngôn ngữ vài lần.

Samuel Gehman, Suchin Gururangan, Maarten Sap, Yejin Choi, và Noah A Smith. 2020. Realtoxicityprompts: Đánh giá sự suy thoái độc hại thần kinh trong các mô hình ngôn ngữ. Trong Findings of the Association for Computational Linguistics: EMNLP 2020, trang 3356–3369.

Mor Geva, Daniel Khashabi, Elad Segal, Tushar Khot, Dan Roth, và Jonathan Berant. 2021. Aristotle có sử dụng laptop không? một bộ đánh giá trả lời câu hỏi với các chiến lược lý luận ngầm. Transactions of the Association for Computational Linguistics, 9:346–361.

Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, và Jacob Steinhardt. 2020. Đo lường hiểu biết ngôn ngữ đa nhiệm vụ lớn. arXiv preprint arXiv:2009.03300.

Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang, Dawn Song, và Jacob Steinhardt. 2021. Đo lường giải quyết vấn đề toán học với bộ dữ liệu math. arXiv preprint arXiv:2103.03874.

Ari Holtzman, Peter West, và Luke Zettlemoyer. 2023. Các mô hình tạo sinh như khoa học hệ thống phức tạp: Làm thế nào chúng ta có thể hiểu được hành vi của mô hình ngôn ngữ lớn? arXiv preprint arXiv:2308.00189.

Lifu Huang, Ronan Le Bras, Chandra Bhagavatula, và Yejin Choi. 2019. Cosmos qa: Đọc hiểu máy với lý luận thông thường ngữ cảnh. arXiv preprint arXiv:1909.00277.

Daniel Khashabi, Snigdha Chaturvedi, Michael Roth, Shyam Upadhyay, và Dan Roth. 2018. Nhìn ra ngoài bề mặt: Một bộ thách thức cho đọc hiểu qua nhiều câu. Trong Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers), trang 252–262, New Orleans, Louisiana. Association for Computational Linguistics.

Hyunwoo Kim, Melanie Sclar, Xuhui Zhou, Ronan Le Bras, Gunhee Kim, Yejin Choi, và Maarten Sap. 2023a. Fantom: Một bộ đánh giá cho kiểm tra căng thẳng lý thuyết tâm trí máy trong tương tác. arXiv preprint arXiv:2310.15421.

Seungone Kim, Jamin Shin, Yejin Cho, Joel Jang, Shayne Longpre, Hwaran Lee, Sangdoo Yun, Seongjin Shin, Sungdong Kim, James Thorne, et al. 2023b. Prometheus: Cảm ứng khả năng đánh giá tinh tế trong các mô hình ngôn ngữ. arXiv preprint arXiv:2310.08491.

Faisal Ladhak, Esin Durmus, Claire Cardie, và Kathleen McKeown. 2020. WikiLingua: Một bộ dữ liệu đánh giá mới cho tóm tắt trừu tượng đa ngôn ngữ. Trong Findings of the Association for Computational Linguistics: EMNLP 2020, trang 4034–4048, Online. Association for Computational Linguistics.

Xuechen Li, Tianyi Zhang, Yann Dubois, Rohan Taori, Ishaan Gulrajani, Carlos Guestrin, Percy Liang, và Tatsunori B. Hashimoto. 2023. Alpacaeval: Một trình đánh giá tự động của các mô hình tuân theo hướng dẫn. https://github.com/tatsu-lab/alpaca_eval.

Percy Liang, Rishi Bommasani, Tony Lee, Dimitris Tsipras, Dilara Soylu, Michihiro Yasunaga, Yian Zhang, Deepak Narayanan, Yuhuai Wu, Ananya Kumar, et al. 2022. Đánh giá toàn diện các mô hình ngôn ngữ. arXiv preprint arXiv:2211.09110.

Hunter Lightman, Vineet Kosaraju, Yura Burda, Harri Edwards, Bowen Baker, Teddy Lee, Jan Leike, John Schulman, Ilya Sutskever, và Karl Cobbe. 2023. Hãy xác minh từng bước. arXiv preprint arXiv:2305.20050.

Kevin Lin, Oyvind Tafjord, Peter Clark, và Matt Gardner. 2019. Lý luận về các hiệu ứng đoạn văn trong các tình huống. arXiv preprint arXiv:1908.05852.

Nicholas Lourie, Ronan Le Bras, và Yejin Choi. 2021. Scruples: Một kho ngữ liệu về các phán đoán đạo đức cộng đồng trên 32.000 giai thoại đời thực. Trong Proceedings of the AAAI Conference on Artificial Intelligence, tập 35, trang 13470–13479.

Mary L McHugh. 2012. Độ tin cậy giữa các người đánh giá: thống kê kappa. Biochemia medica, 22(3):276–282.

David E Meyer và David E Kieras. 1997. Một lý thuyết tính toán về các quá trình nhận thức điều hành và hiệu suất đa nhiệm vụ: Phần i. các cơ chế cơ bản. Psychological review, 104(1):3.

Niloofar Mireshghallah, Hyunwoo Kim, Xuhui Zhou, Yulia Tsvetkov, Maarten Sap, Reza Shokri, và Yejin Choi. 2023. LLM có thể giữ bí mật không? kiểm tra các tác động riêng tư của các mô hình ngôn ngữ qua lý thuyết toàn vẹn ngữ cảnh. arXiv preprint arXiv:2310.17884.

Amita Misra, Brian Ecker, và Marilyn Walker. 2016. Đo lường sự tương đồng của các lập luận câu trong đối thoại. Trong Proceedings of the 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue, trang 276–287, Los Angeles. Association for Computational Linguistics.

OpenAI. 2022. Chatgpt: Tối ưu hóa các mô hình ngôn ngữ cho đối thoại.

OpenAI. 2023. Báo cáo kỹ thuật gpt-4.

Simon Ostermann, Ashutosh Modi, Michael Roth, Stefan Thater, và Manfred Pinkal. 2018. MCScript: Một bộ dữ liệu mới để đánh giá sự hiểu biết máy sử dụng kiến thức kịch bản. Trong Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018), Miyazaki, Japan. European Language Resources Association (ELRA).

Simon Ott, Konstantin Hebenstreit, Valentin Liévin, Christoffer Egeberg Hother, Milad Moradi, Maximilian Mayrhauser, Robert Praas, Ole Winther, và Matthias Samwald. 2023. Thoughtsource: Một trung tâm trung ương cho dữ liệu lý luận mô hình ngôn ngữ lớn. arXiv preprint arXiv:2301.11596.

Lianhui Qin, Antoine Bosselut, Ari Holtzman, Chandra Bhagavatula, Elizabeth Clark, và Yejin Choi. 2019. Lý luận và tạo sinh câu chuyện phản thực tế. arXiv preprint arXiv:1909.04076.

Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, và Percy Liang. 2016. Squad: 100.000+ câu hỏi cho hiểu biết máy về văn bản. arXiv preprint arXiv:1606.05250.

Amrita Saha, Rahul Aralikatte, Mitesh M. Khapra, và Karthik Sankaranarayanan. 2018. DuoRC: Hướng tới Hiểu biết Ngôn ngữ Phức tạp với Đọc hiểu Diễn giải. Trong Meeting of the Association for Computational Linguistics (ACL).

Freda Shi, Xinyun Chen, Kanishka Misra, Nathan Scales, David Dohan, Ed H Chi, Nathanael Schärli, và Denny Zhou. 2023. Các mô hình ngôn ngữ lớn có thể dễ dàng bị phân tâm bởi ngữ cảnh không liên quan. Trong International Conference on Machine Learning, trang 31210–31227. PMLR.

Shikhar Singh, Nuan Wen, Yu Hou, Pegah Alipoormolabashi, Te-Lin Wu, Xuezhe Ma, và Nanyun Peng. 2021. Com2sense: Một bộ đánh giá lý luận thông thường với các câu bổ sung. arXiv preprint arXiv:2106.00969.

Aarohi Srivastava, Abhinav Rastogi, Abhishek Rao, Abu Awal Md Shoeb, Abubakar Abid, Adam Fisch, Adam R Brown, Adam Santoro, Aditya Gupta, Adrià Garriga-Alonso, et al. 2023. Ngoài trò chơi bắt chước: Định lượng và ngoại suy các khả năng của các mô hình ngôn ngữ. Transactions on Machine Learning Research.

Alon Talmor, Jonathan Herzig, Nicholas Lourie, và Jonathan Berant. 2019. CommonsenseQA: Một thách thức trả lời câu hỏi nhắm vào kiến thức thông thường. Trong Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), trang 4149–4158, Minneapolis, Minnesota. Association for Computational Linguistics.

NLLB Team, Marta R. Costa-jussà, James Cross, Onur Çelebi, Maha Elbayad, Kenneth Heafield, Kevin Heffernan, Elahe Kalbassi, Janice Lam, Daniel Licht, Jean Maillard, Anna Sun, Skyler Wang, Guillaume Wenzek, Al Youngblood, Bapi Akula, Loic Barrault, Gabriel Mejia Gonzalez, Prangthip Hansanti, John Hoffman, Semarley Jarrett, Kaushik Ram Sadagopan, Dirk Rowe, Shannon Spruit, Chau Tran, Pierre Andrews, Necip Fazil Ayan, Shruti Bhosale, Sergey Edunov, Angela Fan, Cynthia Gao, Vedanuj Goswami, Francisco Guzmán, Philipp Koehn, Alexandre Mourachko, Christophe Ropers, Safiyyah Saleem, Holger Schwenk, và Jeff Wang. 2022. Không ngôn ngữ nào bị bỏ lại phía sau: Mở rộng dịch máy lấy con người làm trung tâm.

Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al. 2023. Llama 2: Các mô hình cơ sở mở và mô hình chat được tinh chỉnh. arXiv preprint arXiv:2307.09288.

Lewis Tunstall, Edward Beeching, Nathan Lambert, Nazneen Rajani, Kashif Rasul, Younes Belkada, Shengyi Huang, Leandro von Werra, Clémentine Fourrier, Nathan Habib, et al. 2023. Zephyr: Chưng cất trực tiếp sự liên kết lm. arXiv preprint arXiv:2310.16944.

Guan Wang, Sijie Cheng, Xianyuan Zhan, Xiangang Li, Sen Song, và Yang Liu. 2023a. Openchat: Thúc đẩy các mô hình ngôn ngữ mã nguồn mở với dữ liệu chất lượng hỗn hợp. arXiv preprint arXiv:2309.11235.

Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen Zhang, Zhiyuan Chen, Jiakai Tang, Xu Chen, Yankai Lin, et al. 2023b. Một khảo sát về các tác nhân tự động dựa trên mô hình ngôn ngữ lớn. arXiv preprint arXiv:2308.11432.

Yizhong Wang, Hamish Ivison, Pradeep Dasigi, Jack Hessel, Tushar Khot, Khyathi Raghavi Chandu, David Wadden, Kelsey MacMillan, Noah A Smith, Iz Beltagy, et al. 2023c. Lạc đà có thể đi xa đến đâu? khám phá trạng thái điều chỉnh hướng dẫn trên các tài nguyên mở. arXiv preprint arXiv:2306.04751.

Yizhong Wang, Swaroop Mishra, Pegah Alipoormolabashi, Yeganeh Kordi, Amirreza Mirzaei, Anjana Arunkumar, Arjun Ashok, Arut Selvan Dhanasekaran, Atharva Naik, David Stap, et al. 2022. Super-naturalinstructions: Tổng quát hóa qua các hướng dẫn khai báo trên 1600+ nhiệm vụ nlp. arXiv preprint arXiv:2204.07705.

Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, et al. 2022a. Khả năng nổi bật của các mô hình ngôn ngữ lớn. arXiv preprint arXiv:2206.07682.

Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou, et al. 2022b. Chain-of-thought prompting gợi ra lý luận trong các mô hình ngôn ngữ lớn. Advances in Neural Information Processing Systems, 35:24824–24837.

Adina Williams, Nikita Nangia, và Samuel Bowman. 2018. Một kho ngữ liệu thách thức bao phủ rộng cho hiểu biết câu thông qua suy luận. Trong Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers), trang 1112–1122, New Orleans, Louisiana. Association for Computational Linguistics.

Can Xu, Qingfeng Sun, Kai Zheng, Xiubo Geng, Pu Zhao, Jiazhan Feng, Chongyang Tao, và Daxin Jiang. 2023. Wizardlm: Trao quyền cho các mô hình ngôn ngữ lớn tuân theo các hướng dẫn phức tạp. arXiv preprint arXiv:2304.12244.

Zhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio, William Cohen, Ruslan Salakhutdinov, và Christopher D Manning. 2018. Hotpotqa: Một bộ dữ liệu cho trả lời câu hỏi nhiều bước đa dạng, có thể giải thích được. Trong Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, trang 2369–2380.

Hongming Zhang, Xinran Zhao, và Yangqiu Song. 2020. Winowhy: Một chẩn đoán sâu về kiến thức thông thường cần thiết để trả lời thách thức lược đồ winograd. arXiv preprint arXiv:2005.05763.

Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric Xing, et al. 2023. Đánh giá llm-as-a-judge với mt-bench và chatbot arena. arXiv preprint arXiv:2306.05685.

Lucia Zheng, Neel Guha, Brandon R Anderson, Peter Henderson, và Daniel E Ho. 2021. Khi nào pretraining giúp ích? đánh giá học tự giám sát cho luật và bộ dữ liệu casehold gồm 53.000+ kết luận pháp lý. Trong Proceedings of the eighteenth international conference on artificial intelligence and law, trang 159–168.

Pei Zhou, Aman Madaan, Srividya Pranavi Potharaju, Aditya Gupta, Kevin R McKee, Ari Holtzman, Jay Pujara, Xiang Ren, Swaroop Mishra, Aida Nematzadeh, et al. 2023. Các mô hình ngôn ngữ lớn cách các tác nhân có lý thuyết tâm trí bao xa? arXiv preprint arXiv:2310.03051.

--- TRANG 13 ---

A MTI Bench

Bảng 13-37 cung cấp tổng quan toàn diện về 25 đa nhiệm vụ được đặc trưng trong MTI BENCH. Mỗi bảng bao gồm danh mục, nhiệm vụ phụ và bộ dữ liệu gốc của mỗi đa nhiệm vụ. Hơn nữa, một ví dụ được cung cấp để giúp hiểu rõ hơn về bộ đánh giá. Xin lưu ý rằng đối với một số ví dụ, ngữ cảnh đã được rút gọn để dễ đọc hơn.

B Chi tiết Suy luận

Trong các thí nghiệm của chúng tôi, chúng tôi sử dụng các siêu tham số như được hiển thị trong Bảng 11.

[Bảng 11: Siêu tham số được sử dụng cho các thí nghiệm trong MTI BENCH.
Nhiệt độ: 0.7, Top-p: 1.0, Penalty Lặp lại: 1.0, Độ dài Đầu ra Tối đa: 2048]

C Tập con TẠO SINH TỰ DO

Ngoài các tập con MULTI-STEP và MULTI-PART đã thảo luận trong Phần 3.1, chúng tôi giới thiệu một tập con TẠO SINH TỰ DO trong các nghiên cứu ablation chi tiết trong Phần 5.3. Tập con này tuân theo cùng quy trình tạo như MTI Bench gốc, ngoại trừ các chuyên gia chú thích được thuê để đánh giá chất lượng.

[Bảng 12: Chi tiết cho Tập con TẠO SINH TỰ DO
Số Nhiệm vụ: 12
Số Trường hợp: 2.400
Ngôn ngữ: EN, FR, DE
Danh sách Nhiệm vụ Phụ: Dịch thuật, Tóm tắt, MCQA
Bộ dữ liệu Nguồn: FLORES-200 (Team et al., 2022), Belebele (Bandarkar et al., 2023), Wikilingua (Ladhak et al., 2020)]

D Ví dụ cho Phần 6.2

Trong phần này chúng tôi cung cấp các trường hợp mẫu cho các mẫu sau đây đã thảo luận tại Phần 6.2: Không có Kết quả, Nhiều Kết quả, Tham chiếu và Lập kế hoạch. Xem Hình 5.

[Bảng 13-37: Các bảng chi tiết về 25 đa nhiệm vụ trong MTI BENCH, mỗi bảng chứa ID nhiệm vụ, danh mục, nhiệm vụ phụ, bộ dữ liệu nguồn và ví dụ]

[Hình 5: Ví dụ về Không có Kết quả, Nhiều Kết quả, Tham chiếu và Lập kế hoạch được sử dụng bởi GPT-4 trong SUY LUẬN ĐA NHIỆM VỤ]

[Các bảng và ví dụ chi tiết tiếp tục qua các trang còn lại của tài liệu, bao gồm tất cả 25 nhiệm vụ với các ví dụ cụ thể cho mỗi loại nhiệm vụ trong MTI BENCH]

# 2310.06266.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/benchmark/2310.06266.pdf
# Kích thước tệp: 2550977 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
CodeFuse-13B: Một Mô hình Ngôn ngữ Lớn Đa ngôn ngữ Tiền huấn luyện cho Mã nguồn
Peng Di†, Jianguo Li†, Hang Yu†, Wei Jiang†, Wenting Cai, Yang Cao, Chaoyu Chen, Dajun Chen,
Hongwei Chen, Liang Chen, Gang Fan, Jie Gong, Zi Gong, Wen Hu, Tingting Guo, Zhichao Lei, Ting
Li, Zheng Li, Ming Liang, Cong Liao, Bingchang Liu, Jiachen Liu, Zhiwei Liu, Shaojun Lu, Min Shen,
Guangpei Wang, Huan Wang, Zhi Wang, Zhaogui Xu, Jiawei Yang, Qing Ye, Gehao Zhang, Yu
Zhang, Zelin Zhao, Xunjin Zheng, Hailian Zhou, Lifu Zhu, Xianying Zhu∗
Ant Group, Trung Quốc
†Tác giả liên hệ: {dipeng.dp,lijg.zero,hyu.hugo,jonny.jw}@antgroup.com
TÓM TẮT
Các Mô hình Ngôn ngữ Lớn về Mã nguồn (Code LLMs) đã thu hút sự chú ý đáng kể trong ngành công nghiệp do ứng dụng rộng rãi của chúng trong toàn bộ vòng đời của kỹ thuật phần mềm. Tuy nhiên, hiệu quả của các mô hình hiện có trong việc hiểu đầu vào không phải tiếng Anh cho các tác vụ liên quan đến mã đa ngôn ngữ vẫn còn xa mới được nghiên cứu kỹ lưỡng. Bài báo này giới thiệu CodeFuse-13B, một mô hình ngôn ngữ lớn về mã nguồn tiền huấn luyện mã nguồn mở². Nó được thiết kế đặc biệt cho các tác vụ liên quan đến mã với cả lời nhắc tiếng Anh và tiếng Trung và hỗ trợ hơn 40 ngôn ngữ lập trình. CodeFuse đạt được hiệu quả bằng cách sử dụng một bộ dữ liệu tiền huấn luyện chất lượng cao được lọc cẩn thận bởi các công cụ phân tích chương trình và tối ưu hóa trong quá trình huấn luyện. Các thí nghiệm mở rộng được thực hiện sử dụng các tình huống sử dụng thực tế, benchmark tiêu chuẩn ngành HumanEval-x, và CodefuseEval được thiết kế đặc biệt cho lời nhắc tiếng Trung. Để đánh giá hiệu quả của CodeFuse, chúng tôi đã tích cực thu thập phản hồi có giá trị từ con người trong quá trình phát triển phần mềm của AntGroup nơi CodeFuse đã được triển khai thành công. Kết quả cho thấy CodeFuse-13B đạt điểm HumanEval pass@1 là 37.10%, định vị nó như một trong những mô hình ngôn ngữ lớn về mã đa ngôn ngữ hàng đầu với kích thước tham số tương tự. Trong các tình huống thực tế, như tạo mã, dịch mã, bình luận mã và tạo test case, CodeFuse hoạt động tốt hơn các mô hình khác khi đối mặt với lời nhắc tiếng Trung.
KHÁI NIỆM CCS
•Phần mềm và kỹ thuật của nó;
TỪ KHÓA
mô hình ngôn ngữ lớn về mã, đa ngôn ngữ, lời nhắc tiếng Trung
Định dạng Tham khảo ACM:
Peng Di†, Jianguo Li†, Hang Yu†, Wei Jiang†, Wenting Cai, Yang Cao,
Chaoyu Chen, Dajun Chen, Hongwei Chen, Liang Chen, Gang Fan, Jie
∗Các tác giả không liên hệ được liệt kê theo thứ tự bảng chữ cái.
Quyền tạo bản sao kỹ thuật số hoặc bản cứng của tất cả hoặc một phần công trình này để sử dụng cá nhân hoặc lớp học được cấp mà không mất phí với điều kiện các bản sao không được tạo hoặc phân phối vì lợi nhuận hoặc lợi thế thương mại và các bản sao phải ghi rõ thông báo này và trích dẫn đầy đủ trên trang đầu tiên. Bản quyền đối với các thành phần của công trình này thuộc sở hữu của những người khác ngoài (các) tác giả phải được tôn trọng. Tóm tắt có ghi nguồn được phép. Để sao chép theo cách khác, hoặc tái xuất bản, đăng trên máy chủ hoặc phân phối đến danh sách, yêu cầu quyền cụ thể trước và/hoặc phí. Yêu cầu quyền từ permissions@acm.org.
ICSE-SEIP '24, 14-20 tháng 4, 2024, Lisbon, Bồ Đào Nha
©2024 Bản quyền thuộc về chủ sở hữu/tác giả. Quyền xuất bản được cấp phép cho ACM.
ACM ISBN 979-8-4007-0501-4/24/04... $15.00
https://doi.org/10.1145/3639477.3639719Gong, Zi Gong, Wen Hu, Tingting Guo, Zhichao Lei, Ting Li, Zheng Li,
Ming Liang, Cong Liao, Bingchang Liu, Jiachen Liu, Zhiwei Liu, Shaojun
Lu, Min Shen, Guangpei Wang, Huan Wang, Zhi Wang, Zhaogui Xu, Ji-
awei Yang, Qing Ye, Gehao Zhang, Yu Zhang, Zelin Zhao, Xunjin Zheng,
Hailian Zhou, Lifu Zhu, Xianying Zhu. 2024. CodeFuse-13B: Một Mô hình Ngôn ngữ Lớn Đa ngôn ngữ Tiền huấn luyện cho Mã nguồn. Trong Hội nghị Quốc tế lần thứ 46 về Kỹ thuật Phần mềm: Kỹ thuật Phần mềm trong Thực tiễn (ICSE-SEIP '24),
14-20 tháng 4, 2024, Lisbon, Bồ Đào Nha. ACM, New York, NY, USA, 12 trang.
https://doi.org/10.1145/3639477.3639719

1 GIỚI THIỆU
Các Mô hình Ngôn ngữ Lớn về Mã nguồn (Code LLMs) đã thu hút sự chú ý đáng kể trong ngành công nghiệp do ứng dụng rộng lớn của chúng xuyên suốt toàn bộ vòng đời kỹ thuật phần mềm. Việc phát hành Copilot, được hỗ trợ bởi Codex [7], đã phục vụ như một minh chứng quan trọng cho sự xuất hiện sắp tới của kỷ nguyên mã thông minh. Một ứng dụng đáng kinh ngạc, ChatGPT [6,27], đã quyến rũ một lượng người dùng đáng kinh ngạc hơn 100 triệu trong hai tháng kể từ khi ra mắt. Trong các mô hình mã gần đây như AlphaCode[21], InCoder[13], SantaCoder[1], StarCoder[20], và Code Llama[30], việc kết hợp khả năng fill-in-the-middle đã được chứng minh là đặc biệt có giá trị cho các tình huống hoàn thành mã thực tế.

Mặc dù các mô hình này có ứng dụng thực tế trong quy trình phát triển phần mềm, hiệu quả của chúng trong việc hiểu đầu vào không phải tiếng Anh cho các tác vụ liên quan đến mã vẫn không thỏa đáng[51]. Để lấp đầy khoảng trống này, CodeGeeX [52] đã cố gắng thiết lập kết nối giữa mã và các ngôn ngữ không phải tiếng Anh, kết hợp các token từ vựng từ nhiều ngôn ngữ tự nhiên khác nhau. Thật vậy, bằng cách tận dụng các bộ dữ liệu lớn, chuyên biệt cho lĩnh vực, LLMs có thể nâng cao đáng kể hiệu quả của chúng trong các ứng dụng cần sự kết hợp giữa hiểu ngôn ngữ tự nhiên và kiến thức chuyên biệt lĩnh vực, bao gồm thuật ngữ chuyên môn.

Bài báo giới thiệu CodeFuse, một Mô hình Ngôn ngữ cho việc lập trình, được mở mã nguồn trên GitHub¹ và Huggingface², một Mô hình Ngôn ngữ (LLM) mã nguồn mở. Dự án CodeFuse, một nỗ lực hợp tác trong AntGroup, đã chứng kiến các lần lặp mô hình hàng tháng dẫn đến cải thiện hiệu suất nhất quán, như được mô tả trong Bảng 1. Tính đến tháng 9 này, chúng tôi đã mở mã nguồn hai phiên bản của CodeFuse, CodeFuse-13B và CodeFuse-CodeLlama-34B. CodeFuse-13B trải qua tinh chỉnh bằng LoRA/QLoRA trên nhiều tác vụ mã sử dụng mô hình cơ sở tự tiền huấn luyện, trong khi
¹https://github.com/codefuse-ai
²https://huggingface.co/codefuse-aiarXiv:2310.06266v2 [cs.SE] 10 Jan 2024

--- TRANG 2 ---
ICSE-SEIP '24, 14-20 tháng 4, 2024, Lisbon, Bồ Đào Nha Peng Di, và các cộng sự.
Bảng 1: Lộ trình dự án CodeFuse.
Ngày phát hành Mô hình HumanEval
Pass@1
Tháng 3 2023 CodeFuse-1.3B-2K Seq-Length 11.58%
Tháng 4 2023 CodeFuse-6.5B-4K Seq-Length 20.46%
Tháng 5 2023 CodeFuse-13B-Base-4K Seq-Length 32.93%
Tháng 6 2023 CodeFuse-13B (mở vào tháng 9) 37.10%
Tháng 9 2023 CodeFuse-CodeLlama-34B (đã mở) 74.40%
CodeFuse-CodeLlama-34B được tinh chỉnh sử dụng CodeLlama-34b-Python. Thú vị, CodeFuse-13B vượt qua các mô hình ngôn ngữ lớn về mã khác có kích thước tương tự, và CodeFuse-CodeLlama-34B vượt trội hơn GPT4 và ChatGPT-3.5 trên benchmark HumanEval.

Bài báo này tập trung vào mô hình tiền huấn luyện CodeFuse-13B, cung cấp tổng quan toàn diện về quy trình phát triển và đánh giá hiệu suất của nó trong các tình huống công nghiệp thực tế. Việc sản xuất CodeFuse-13B bao gồm một số bước quan trọng, bao gồm:
•Thu thập dữ liệu: Chúng tôi đã thu thập khoảng 200+ TB dữ liệu liên quan đến mã, và cuối cùng tinh chế nó thành khoảng 1.6TB (1T Token) dữ liệu sạch phù hợp cho tiền huấn luyện.
•Phân tích đặc trưng chương trình: Chúng tôi đã trích xuất một tập hợp các đặc trưng chương trình từ mã đã thu thập, bao gồm tính đúng đắn cú pháp, điểm sạch sẽ, v.v. Phân tích này phục vụ ba mục đích: 1) đảm bảo mã chất lượng cao cho dữ liệu tiền huấn luyện, 2) cung cấp dữ liệu đặc trưng chương trình AST/CFG/DFG/IR và trích xuất ngữ nghĩa mã để tạo điều kiện hiểu chương trình, và 3) lập hồ sơ bộ dữ liệu mã để hướng dẫn tinh chỉnh hướng dẫn dựa trên ràng buộc. Công cụ phân tích được sử dụng phương pháp phân tích chương trình dựa trên datalog, dịch phân tích thành hệ thống truy vấn.
•Tiền huấn luyện: Sử dụng ngăn xếp công nghệ chung của AntGroup, chúng tôi đã phát triển CodeFuse để tiền huấn luyện một mô hình quy mô lớn với 13 tỷ tham số một cách ổn định.
•Tinh chỉnh hướng dẫn: Giai đoạn này liên quan đến các kỹ thuật tinh chỉnh khác nhau, như tinh chỉnh hướng dẫn có giám sát (SFT), và tinh chỉnh hướng dẫn đa tác vụ (MFT), trong số những kỹ thuật khác.
•Đánh giá mô hình: Chúng tôi cung cấp một bộ công cụ đánh giá toàn diện hỗ trợ cả phương pháp đánh giá suy luận trực tuyến và ngoại tuyến. Bộ công cụ này thúc đẩy việc huấn luyện mô hình trên các tác vụ downstream khác nhau dựa trên các chỉ số hiệu suất và trực quan hóa phản hồi về kết quả đánh giá, cho phép lặp lại liên tục và tối ưu hóa dữ liệu, thuật toán và thách thức kỹ thuật tương ứng.
•Vận hành mô hình: Trong bối cảnh hàng trăm hoặc thậm chí hàng nghìn instance huấn luyện GPU, nhiều thách thức nổi lên, như phát hiện tự động kịp thời các nút lỗi, khởi động tự động các tác vụ huấn luyện, và giám sát sự hội tụ của tiến trình huấn luyện. Chúng tôi đã đạt được tiến bộ đáng kể trong việc giải quyết những thách thức này thông qua Vận hành Mô hình.

Chúng tôi đã thực hiện đánh giá dựa trên ngành công nghiệp về CodeFuse bằng cách tích hợp nó vào quy trình phát triển phần mềm tại AntGroup. Ngoài ra, chúng tôi đã phát triển các tiện ích mở rộng cho một số Môi trường Phát triển Tích hợp (IDEs) phổ biến, cụ thể là VSCode, JetBrains, và Ant CloudIDE (một Web IDE). Hơn nữa, chúng tôi đã phát triển và mở mã nguồn một benchmark toàn diện hơn, có tên CodefuseEval³, để hỗ trợ phạm vi rộng hơn các tình huống lập trình liên quan đến đầu vào tiếng Trung.

Thu thập dữ liệu
200T dữ liệu thô bao gồm 196T mã,
1.75T tiếng Trung và 1.7T tiếng Anh.Làm sạch dữ liệu
a) Lọc thuộc tính tệp
b) Lọc chất lượng mã
Bộ lọc thuộc tính tệp
Lọc theo quy tắc cấp tệp bao gồm
kích thước tệp, tỷ lệ mã, v.v
Bộ lọc chất lượng mã
a) Xác minh cú pháp
b) phân tích đặc trưng mã
Khử độc dữ liệu
Kiểm soát rủi ro nội dung và bảo vệ
dữ liệu riêng tư của AntGroup
Khử trùng lặp dữ liệu
a) Khử trùng lặp cấp tệp MD5
b) Khử trùng lặp cấp tệp chi tiết
SimHash
c) Khử trùng lặp cấp đoạn
Tái lấy mẫu dữ liệu
Tái lấy mẫu một số ngôn ngữ cho
hiệu quả huấn luyện của mô hình
Hình 1: Sơ đồ xử lý dữ liệu.

Kết quả cho thấy CodeFuse-13B đạt điểm HumanEval Pass@1 là 37.10%, khiến nó trở thành một trong những mô hình hàng đầu với kích thước tương tự. Trong các tình huống đa ngôn ngữ thực tế, CodeFuse vượt trội hơn các mô hình khác với lời nhắc tiếng Trung, như dịch mã, bình luận mã, tạo test case và những điều khác.

Chúng tôi tóm tắt các đóng góp chính như sau:
•Chúng tôi giới thiệu CodeFuse-13B, một mô hình ngôn ngữ lớn về mã tiền huấn luyện mã nguồn mở với 13B tham số và quy trình huấn luyện của nó. Nó được thiết kế đặc biệt cho các tác vụ liên quan đến mã với lời nhắc tiếng Trung và hỗ trợ hơn 40 ngôn ngữ lập trình.
•Chúng tôi đã phát triển các tiện ích mở rộng CodeFuse cho nhiều IDEs khác nhau. Những tiện ích mở rộng này cho phép các nhà phát triển tích hợp mượt mà CodeFuse vào quy trình làm việc mã hóa của họ, nâng cao năng suất và khả năng tạo mã.
•Chúng tôi đánh giá hiệu quả của CodeFuse trong nhiều tình huống ứng dụng khác nhau, bao gồm tạo mã, dịch mã, bình luận mã, và tạo test case. Kết quả cho thấy CodeFuse-13B đạt điểm HumanEval Pass@1 là 37.10%, vượt trội hơn các mô hình đa ngôn ngữ khác có kích thước tương tự. Hơn nữa, CodeFuse-13B tốt hơn các mô hình khác trong các tình huống thực tế liên quan đến lời nhắc tiếng Trung.

2 CHUẨN BỊ DỮ LIỆU
2.1 Tổng quan về xử lý dữ liệu
Vì các mô hình ngôn ngữ lớn về mã tập trung nhiều hơn vào các tác vụ liên quan đến mã, có những khác biệt đáng kể so với các phương pháp được sử dụng trong LLMs tổng quát, về mặt thu thập dữ liệu, làm sạch dữ liệu, khử độc, khử trùng lặp, và tái lấy mẫu dữ liệu, như được hiển thị trong Hình 1. Bài báo này sẽ chủ yếu tập trung vào cách CodeFuse xây dựng dữ liệu tiền huấn luyện cho mô hình lớn lĩnh vực mã.

Thu thập dữ liệu. Dữ liệu tiền huấn luyện cho CodeFuse bao gồm 196TB mã, 1.75TB dữ liệu thô tiếng Trung, và 1.7TB dữ liệu thô tiếng Anh, tổng cộng 200TB, được token hóa thành 800 tỷ token mã, 100 tỷ token corpus tiếng Trung, và 100 tỷ token corpus tiếng Anh (xem Phần 3.1). Dữ liệu mã gốc là sự kết hợp của bộ dữ liệu GitHub tự thu thập và bộ dữ liệu mã nguồn mở Stack [19]. Bộ dữ liệu kết hợp được khử trùng lặp và lọc để bao gồm hơn 40 ngôn ngữ lập trình với phân bố được hiển thị trong Hình 2, trong đó 13 ngôn ngữ lập trình chiếm hơn 1% mỗi ngôn ngữ. Java, Python, C++, và JavaScript vượt quá 10%, trong khi gần 30 ngôn ngữ lập trình còn lại chiếm 9% tổng số. Corpus tiếng Trung có nguồn gốc từ CommonCrawl, các trang web liên quan đến máy tính, tài liệu của các ngôn ngữ lập trình và thư viện bên thứ ba của chúng, v.v. Corpus tiếng Anh được lấy mẫu từ nhiều danh mục trong Pile bao gồm StackExchange, Arxiv, Wikipedia, OpenWebText2, Pile-CC, v.v.

³https://github.com/codefuse-ai/codefuse-evaluation.

--- TRANG 3 ---
CodeFuse-13B: Một Mô hình Ngôn ngữ Lớn Đa ngôn ngữ Tiền huấn luyện cho Mã nguồn ICSE-SEIP '24, 14-20 tháng 4, 2024, Lisbon, Bồ Đào Nha

Java
14.0%Python
12.3%C++
11.7%
JavaScript
10.5%
C9.8%
Markdown6.4%
PHP5.6%
TypeScript5.2%
C#5.2%
Go4.3%
HTML3.6%
CSS1.2%
Objective-C1.1%Khác9.1%
Hình 2: Phân bố các ngôn ngữ lập trình.

Làm sạch dữ liệu. Chiến lược làm sạch cho dữ liệu mã được chia thành hai cấp. Chiến lược lọc cấp đầu tiên liên quan đến khía cạnh thuộc tính tệp, bao gồm các chiến lược như loại bỏ các tệp lớn (ví dụ: tệp có hơn 10.000 dòng hoặc tệp đơn lớn hơn 1MB) và loại bỏ văn bản bất thường (ví dụ: các dòng có độ dài trung bình lớn hơn 100 hoặc tỷ lệ ký tự chữ và số nhỏ hơn 40%). Chiến lược lọc cấp thứ hai dựa vào phân tích chương trình của AntGroup [15,22,33,53,54] để lọc ra dữ liệu mã không đáp ứng yêu cầu về tính đúng đắn cú pháp và chất lượng mã. Việc phát hành mã nguồn mở của công cụ phân tích đặc trưng chương trình của chúng tôi đã được lên kế hoạch, và các chi tiết sẽ được giới thiệu trong Phần 2.2.

Khử độc dữ liệu. Chúng tôi sử dụng khả năng kiểm soát rủi ro nội dung và bảo vệ dữ liệu riêng tư của AntGroup để xác định và lọc ra dữ liệu có rủi ro khỏi bộ dữ liệu huấn luyện, đảm bảo an toàn dữ liệu.

Khử trùng lặp dữ liệu. Nhiều độ chi tiết khử trùng lặp được thực hiện để đảm bảo tính cảm quan của dữ liệu huấn luyện. Đầu tiên là khử trùng lặp toàn cục với MD5 cấp tệp. Thứ hai là khử trùng lặp cấp tệp chi tiết với điểm SimHash (ví dụ ≥0.95). Thứ ba là khử trùng lặp cấp đoạn dựa trên phân tích mã để tách mã và bình luận, và khử trùng lặp các đoạn mã và văn bản khi điểm SimHash cấp tài liệu lớn hơn ngưỡng (ví dụ ≥0.90).

Tái lấy mẫu dữ liệu. Tái lấy mẫu dựa trên phân bố ngôn ngữ loại bỏ dữ liệu cho các ngôn ngữ lập trình nhỏ (với tỷ lệ dữ liệu dưới 0.1%) và giảm mẫu HTML, CSS, JSON, và các ngôn ngữ tương tự khác có thể ảnh hưởng tiêu cực đến hiệu quả huấn luyện của mô hình.

Thông qua các giai đoạn xử lý dữ liệu này, dữ liệu huấn luyện cho mô hình lớn CodeFuse được chuẩn bị để đảm bảo dữ liệu chất lượng cao cho huấn luyện và cho phép mô hình thể hiện hiệu suất xuất sắc. Dữ liệu được lọc và tái lấy mẫu được token hóa thành định dạng có thể sử dụng trực tiếp cho giai đoạn tiền huấn luyện.

2.2 Phân tích đặc trưng chương trình
Để cải thiện chất lượng dữ liệu mã huấn luyện, chúng tôi đề xuất hai phương pháp để phân tích đặc trưng mã: phương pháp dựa trên phân tích tĩnh và dựa trên mô hình. Phương pháp dựa trên phân tích tĩnh cung cấp hiệu quả chi phí, khả năng diễn giải, và cải tiến lặp đi lặp lại nhưng có thể gặp khó khăn với việc định lượng các đặc trưng mã phức tạp. Phương pháp dựa trên mô hình cung cấp xử lý tốt hơn các đặc trưng không thể định lượng nhưng đi kèm với chi phí cao hơn và khả năng diễn giải yếu hơn. Đối với dữ liệu mã khổng lồ, phân tích tĩnh được ưu tiên trước, tuy nhiên một phương pháp lai kết hợp phân tích tĩnh với phân loại dựa trên mô hình có thể được sử dụng để làm sạch chi tiết. Phương pháp này tận dụng các điểm mạnh của cả hai phương pháp để đảm bảo xử lý hiệu quả và hiệu suất các đặc trưng mã.

Mô hình đánh giá mã chất lượng cao. Để đánh giá hiệu quả chất lượng mã, chúng tôi đã đề xuất một số chỉ số được tích hợp vào mô hình của chúng tôi. Những chỉ số này phục vụ như các chỉ báo chất lượng mã, và chúng được thiết kế để cung cấp cái nhìn toàn diện về các lĩnh vực tiềm năng cần cải thiện.

•Đo lường tính đúng đắn: Sau khi thực hiện xác minh cú pháp và phát hiện lỗi, đã quan sát thấy rằng số lượng lỗi tỷ lệ nghịch với chất lượng mã. Tần suất lỗi cao hơn cho thấy chất lượng mã thấp hơn. Để cung cấp phân tích chi tiết hơn, các lỗi đã được phân loại thành ba cấp độ: Fatal, Error, và Warning.

•Khả năng đọc: Các phương thức, lớp lớn hơn, và nhiều tham số phương thức hơn có xu hướng liên quan đến chất lượng mã thấp hơn. Điều này do sự phức tạp tăng lên và khả năng đọc giảm thường đi kèm với các phương thức, lớp lớn, và nhiều tham số hơn.

•Dư thừa: Sự hiện diện của các lớp dư thừa là dấu hiệu của chất lượng mã kém. Sự dư thừa trong các lớp thường dẫn đến sự phức tạp tăng lên và khả năng bảo trì giảm.

•Phong cách đặt tên: Tên định danh quá dài hoặc quá ngắn có thể làm tổn hại chất lượng mã. Tên ngắn có thể không mô tả đầy đủ mục đích của một biến hoặc hàm, trong khi tên quá dài có thể cản trở khả năng đọc.

•Độ phức tạp cyclomatic: Độ phức tạp cyclomatic là một chỉ số được sử dụng để đo độ phức tạp của luồng điều khiển của một mô-đun. Nó định lượng số lượng đường dẫn độc lập qua mã, cũng có thể được hiểu là số lượng test case tối thiểu cần thiết để bao phủ tất cả các tình huống có thể.

•Liên kết: Đây là một thước đo mức độ liên kết giữa các mô-đun. Sức mạnh của liên kết phụ thuộc vào độ phức tạp của giao diện giữa các mô-đun, cách các mô-đun được gọi, và lượng dữ liệu được truyền qua giao diện. Liên kết giữa các mô-đun đề cập đến mối quan hệ phụ thuộc giữa chúng, bao gồm mối quan hệ điều khiển, mối quan hệ gọi, và mối quan hệ truyền dữ liệu.

--- TRANG 4 ---
ICSE-SEIP '24, 14-20 tháng 4, 2024, Lisbon, Bồ Đào Nha Peng Di, và các cộng sự.

Triển khai. Chúng tôi đã sử dụng công cụ phân tích tĩnh của AntGroup, có tên Sparrow, để lọc mã. Tương tự như CodeQL [25] được phát triển bởi GitHub, Sparrow là một công cụ phân tích chương trình dựa trên datalog dịch phân tích thành hệ thống truy vấn. Để xử lý việc phân tích một khối lượng lớn mã, chúng tôi đã lưu trữ thông tin kết quả ngoại tuyến trong cơ sở dữ liệu cùng với động cơ solver datalog. Thiết lập này cho phép chúng tôi truy vấn và lấy kết quả phân tích chương trình một cách hiệu quả.

2.3 Trích xuất ngữ nghĩa mã
Một trong những tác vụ quan trọng nhất đối với các mô hình ngôn ngữ lớn về mã là hiểu ngữ nghĩa của mã. Để hỗ trợ điều đó, cần trích xuất mã với các chú thích ngôn ngữ tự nhiên, phục vụ như là giải thích về ngữ nghĩa của mã. Do đó, chúng tôi sử dụng phân tích tĩnh để trích xuất các đoạn mã và bình luận tương ứng từ mã chất lượng cao. Dữ liệu được trích xuất này sau đó được sử dụng cho Tinh chỉnh Có giám sát (SFT) của CodeFuse. Mục tiêu của phương pháp này là đảm bảo rằng mô hình không chỉ hiểu cú pháp của các ngôn ngữ lập trình mà còn đạt được sự hiểu biết sâu sắc về logic và chức năng cơ bản của mã, từ đó nâng cao khả năng hiểu mã của nó.

Chiến lược chọn cặp mã-bình luận. Để đảm bảo chất lượng của các cặp mã-bình luận, chúng tôi tập trung vào việc trích xuất các hàm và bình luận tương ứng từ mã. Chúng tôi sử dụng các phương pháp dựa trên quy tắc để lọc các cặp mã-bình luận:

•Bình luận vô nghĩa: Bình luận vô nghĩa được phát hiện bởi Sparrow bằng cách sử dụng một tập hợp quy tắc, bao gồm phát hiện từ khóa bình luận, xác định các phương thức setter/getter được tạo tự động, và những điều khác. Những bình luận này được coi là không liên quan và sau đó được loại bỏ.

•Giới hạn độ dài mã: Mã chứa ít hơn 3 dòng được loại bỏ để đảm bảo bối cảnh đầy đủ trong mã.

•Giới hạn mã hiệu quả: Các phương thức có ít hơn 60% dòng mã hiệu quả được loại bỏ để đảm bảo tỷ lệ đáng kể mã có ý nghĩa.

•Giới hạn độ dài bình luận: Để duy trì khả năng đọc và quản lý, các bình luận dài hơn 512 ký tự được loại bỏ.

Triển khai. Chúng tôi sử dụng tree-sitter, một công cụ phân tích nhanh và mạnh mẽ, để hỗ trợ nhiều ngôn ngữ lập trình và xử lý khối lượng mã lớn. Bằng cách tận dụng chức năng truy vấn của tree-sitter, chúng tôi trích xuất các cặp hàm-bình luận trên các ngôn ngữ khác nhau, cho phép cấu trúc dữ liệu thống nhất. Công cụ phân phối và tổng hợp kết quả phân tích mã một cách hiệu quả, nâng cao tốc độ phân tích và khả năng tương thích với nhiều ngôn ngữ lập trình khác nhau.

Ứng dụng. Chúng tôi đã tích lũy một bộ dữ liệu 3.2 tỷ cặp mã-bình luận cấp hàm. Bộ dữ liệu này bao gồm nhiều nguồn khác nhau, bao gồm GitHub, GeeksforGeeks, StarCoder, và kho mã nội bộ của AntGroup, cung cấp một cơ sở rộng lớn và đa dạng cho huấn luyện và đánh giá. Bộ dữ liệu được sử dụng cho các tác vụ liên quan đến mã sau đây (xem Phần 4):

•Tạo mã: Tác vụ này liên quan đến việc dịch ngôn ngữ tự nhiên thành các đoạn mã. Bộ dữ liệu lớn hỗ trợ hiểu ý nghĩa ngữ nghĩa đằng sau ngôn ngữ tự nhiên và tạo mã tương ứng.

•Bình luận mã: Tác vụ này tập trung vào việc tạo bình luận cho mã đã cho. Tận dụng các cặp mã-bình luận trong bộ dữ liệu của chúng tôi, CodeFuse có thể tạo hiệu quả các bình luận có ý nghĩa và cụ thể theo ngữ cảnh cho bất kỳ đoạn mã nào được đưa ra.

•Giải thích mã: Tác vụ này xử lý việc cung cấp giải thích toàn diện cho các đoạn mã đã cho. Số lượng lớn các cặp mã-bình luận trong bộ dữ liệu của chúng tôi hỗ trợ rút ra sự tương đồng và tạo ra các giải thích chi tiết, dễ hiểu về chức năng mã.

2.4 Chân dung bộ dữ liệu mã
Chân dung bộ dữ liệu mã đề cập đến một phương pháp tự động liên quan đến việc chú thích, phân loại, và phân tích mã để nắm bắt các khía cạnh khác nhau của cơ sở mã quy mô lớn. Bằng cách thực hiện lập hồ sơ mã, có thể đạt được sự hiểu biết kỹ lưỡng và chi tiết hơn về dữ liệu mã được sử dụng để huấn luyện. Sự hiểu biết này tạo điều kiện cho việc triển khai hiệu quả hơn các kỹ thuật như Tự huấn luyện Có giám sát (SST) và Tinh chỉnh Tự giám sát (SFT).

Các ứng dụng của chân dung mã có thể được phân loại như sau:
•Hiểu biết sâu sắc về dữ liệu huấn luyện: Đối với mỗi khía cạnh chân dung, phân tích chân dung có thể cung cấp các đo lường như mất mát xác thực, perplexity, và thậm chí lỗi phản hồi. Những điều này có thể cho chúng ta thấy phần nào của dữ liệu khó học hơn.

•Tăng cường dữ liệu huấn luyện: Phản hồi chân dung thúc giục chúng tôi tăng cường dữ liệu huấn luyện bằng cách cải thiện số lượng hoặc chất lượng của khía cạnh thực hiện yếu tương ứng. Một mặt, vì phân bố dữ liệu huấn luyện có thể ảnh hưởng đáng kể đến hành vi của mô hình [55], chân dung mã cho phép chúng tôi cải thiện số lượng hoặc tỷ lệ của khía cạnh thực hiện yếu theo phản hồi đánh giá. Mặt khác, nó có thể thúc giục chúng tôi kiểm tra chất lượng của phần dữ liệu thực hiện yếu và tìm cách tiềm năng để cải thiện thêm chất lượng dữ liệu. Cả hai cách đều có thể tối ưu hóa mô hình trong các thí nghiệm tiếp theo.

Việc triển khai chân dung mã dựa trên Sparrow đã đề cập. Dựa trên phân tích chân dung mã của mã được thêm vào kho của AntGroup trong ba tháng qua, các hiểu biết chính sau đây đã được rút ra:

•Java là ngôn ngữ chiếm ưu thế, chiếm khoảng 40.7% mã mới được thêm. Trong cơ sở mã Java, phần lớn (hơn 90%) được quy cho các dự án SOFA (Scalable Open Financial Architecture). Do đó, trọng tâm chính cho việc tạo mã nên là các ứng dụng Java liên quan đến ngăn xếp SOFA.

•Một số mô-đun nhất định trong mã Java, cụ thể là 'test', 'model', 'facade', và 'dal', có đại diện cao hơn. Những phần này nên được coi là các lĩnh vực ưu tiên cao cho việc tạo mã, do tính quan trọng của chúng trong cơ sở mã. Tập trung vào những mô-đun này sẽ giúp đảm bảo rằng mã được tạo ra phù hợp với nhu cầu và yêu cầu của hệ thống.

•JavaScript chiếm 9.23% mã mới được thêm, khiến nó trở thành ngôn ngữ được sử dụng rộng rãi thứ hai. Trong cơ sở mã JavaScript, framework Bigfish nổi bật là chiếm ưu thế nhất. Do đó, việc tạo mã cụ thể cho framework Bigfish nên được ưu tiên để phục vụ việc sử dụng đáng kể framework này trong cơ sở mã JavaScript.

--- TRANG 5 ---
CodeFuse-13B: Một Mô hình Ngôn ngữ Lớn Đa ngôn ngữ Tiền huấn luyện cho Mã nguồn ICSE-SEIP '24, 14-20 tháng 4, 2024, Lisbon, Bồ Đào Nha

(a)CodeFuse có 40 token
(b)CodeLlama có 46 token
(c)CodeGen có 47 token
Hình 3: Ví dụ token hóa của các mô hình khác nhau áp dụng cho cùng một đoạn mã.

3 HUẤN LUYỆN
Trong phần này, chúng tôi giới thiệu quy trình tiền huấn luyện của CodeFuse bao gồm token hóa, kiến trúc mô hình và quy trình huấn luyện.

3.1 Token hóa
Tokenizer của chúng tôi dựa trên BPE [34] và được thiết kế để tránh các vấn đề Out of Vocabulary (OOV). Nó có kích thước từ vựng 100.864, bao phủ từ khóa và từ thông dụng trong các ngôn ngữ lập trình cũng như corpus liên quan đến kỹ thuật thông tin. Tokenizer cũng hỗ trợ phân đoạn hiệu quả các ngôn ngữ tự nhiên như tiếng Trung và tiếng Anh. Nó đảm bảo token hóa mã chính xác. Hình 3 cung cấp các trường hợp ví dụ để chứng minh token hóa bởi một số mô hình ngôn ngữ lớn về mã nổi tiếng, làm nổi bật hiệu quả của tokenizer CodeFuse.

Để xác minh hiệu suất token hóa của tokenizer CodeFuse trên mã, tiếng Trung, và tiếng Anh, chúng tôi đã lấy mẫu ngẫu nhiên 100.000 ví dụ từ bộ dữ liệu huấn luyện. Số lượng token và tỷ lệ nén sau token hóa được hiển thị trong Bảng 2. Hiệu suất token hóa của tokenizer CodeFuse tốt hơn đáng kể so với CodeLlama và CodeGen đối với mã, tiếng Trung, và tiếng Anh. Điều này được quy cho kích thước từ vựng lớn hơn và từ vựng chuyên biệt cho mã.

3.2 Kiến trúc mô hình
Kiến trúc mô hình của CodeFuse là một Transformer tự hồi quy, tương tự như GPT-3 [6], với dự đoán token tiếp theo thông thường làm mục tiêu học tập. Chúng tôi đã thực hiện hai thay đổi chính tương tự như GPT-J [42]: (1) sử dụng embedding vị trí quay thay vì embedding vị trí học được, và (2) sử dụng các lớp attention và feed-forward song song (FFN) thay vì các lớp nối tiếp như trong GPT3. Chi tiết được hiển thị trong Hình 4.

Hình 4: So sánh kiến trúc CodeFuse với GPT.

Embedding vị trí quay (RoPE). Chúng tôi áp dụng RoPE [36] làm embedding vị trí trong Multi-Head Attention thay vì embedding vị trí học được. Để cân bằng hiệu quả và hiệu suất tính toán, chúng tôi chỉ áp dụng RoPE cho nửa đầu của các vector embedding [5, 42].

Các lớp attention và FFN song song. Trong GPT-3, Multi-Head Attention được tính toán trước, và sau đó kết quả được cộng với kết nối dư trước khi được truyền vào FFN như được hiển thị trong Phương trình 1. Trong mô hình của chúng tôi, Multi-Head Attention và FFN được tính toán song song, và sau đó kết quả của cả hai được cộng với dư và truyền đến lớp tiếp theo như được hiển thị trong Phương trình 2. Kiến trúc này có thể cải thiện thông lượng tính toán khoảng 15%.

𝑥𝑡+1=𝑥𝑡+𝐹𝐹𝑁(𝐿𝑁(𝑥𝑡+𝐴𝑡𝑡𝑛(𝐿𝑁(𝑥𝑡)))) (1)
𝑥𝑡+1=𝑥𝑡+𝐴𝑡𝑡𝑛(𝐿𝑁(𝑥𝑡))+𝐹𝐹𝑁(𝐿𝑁(𝑥𝑡)) (2)

Activations. Chúng tôi sử dụng hàm kích hoạt GeLU [16], có thể giảm thiểu vấn đề gradient biến mất trong quá trình huấn luyện. Hơn nữa, nó giới thiệu một phép biến đổi phi tuyến tương tự như hàm sigmoid, giúp tăng tốc tốc độ hội tụ của mô hình.

Chuẩn hóa lớp. Chúng tôi áp dụng chuẩn hóa trước lớp [4] cho đầu vào của khối Transformer mạnh mẽ hơn đối với biến thiên đầu vào và cải thiện luồng gradient [48].

3.3 Tiền huấn luyện
Chúng tôi đã huấn luyện CodeFuse dựa trên framework GPT-NeoX [5], được xây dựng trên Megatron [35] và DeepSpeed và kết hợp các tối ưu hóa sâu cho thuật toán, giao tiếp, và song song mô hình. Chúng tôi đã huấn luyện CodeFuse trên một cụm GPU 64 node, mỗi node có tám GPU NVIDIA A100-SXM-80GB. Chúng tôi đã huấn luyện CodeFuse với

--- TRANG 6 ---
ICSE-SEIP '24, 14-20 tháng 4, 2024, Lisbon, Bồ Đào Nha Peng Di, và các cộng sự.

Bảng 2: So sánh tỷ lệ nén (C-Rate) của token hóa. C-Rate = #Tokens / #Characters, càng thấp càng tốt.
Loại #CharactersCodeFuse CodeLlama CodeGen
#Tokens C-Rate #Tokens C-Rate #Tokens C-Rate
Mã 338,758,753 86,787,734 0.25 99,180,237 0.29 96,289,455 0.28
Tiếng Trung 85,998,939 98,491,170 1.14 121,180,842 1.41 161,977,211 1.88
Tiếng Anh 283,983,202 69,951,060 0.24 78,472,584 0.27 71,393,619 0.25

nhiều kích thước khác nhau với 350M, 1.3B, 6B, và 13B tham số, chi tiết như được hiển thị trong Bảng 3.

Tối ưu hóa huấn luyện. CodeFuse-13B được huấn luyện với song song dữ liệu 256-way, song song tensor 2-way, và song song sequence, và giảm tiêu thụ bộ nhớ với DeepSpeed ZeRO-1 [29]. Độ dài sequence của CodeFuse-13B là 4096, và tăng tốc huấn luyện mô hình sequence dài với Flash Attention [10]. Kích thước micro batch là 16, và kích thước global batch là 4096, chúng tôi đạt được 180 TFLOPS và tỷ lệ sử dụng trung bình 56% của tensor cores trên 512 GPU. Chúng tôi sử dụng optimizer Adam [18] cho huấn luyện, trong đó tỷ lệ học ban đầu là 1.5e-4, và tỷ lệ học tối thiểu là 1.5e-5, cùng với kiểu phân rã tỷ lệ học cosine. Chúng tôi sử dụng chế độ huấn luyện độ chính xác hỗn hợp fp16. Để tránh underflow hoặc overflow độ chính xác, chúng tôi đặt scaling mất mát ban đầu thành 32768 và scaling mất mát tối thiểu thành 1.

3.4 Tinh chỉnh có giám sát
Tinh chỉnh có giám sát (SFT) của CodeFuse chứa nhiều khía cạnh: thu thập dữ liệu, tăng cường hướng dẫn, định dạng dữ liệu, chiến lược huấn luyện, và framework tinh chỉnh. Các phần sau sẽ mô tả chi tiết từng khía cạnh.

Thu thập dữ liệu cho SFT. Như một LLM chuyên biệt cho lĩnh vực mã, nó cần có các chức năng sau:
•Khả năng hiểu ngôn ngữ tự nhiên cơ bản: Mô hình nên cung cấp sự hiểu biết thỏa đáng về các câu hỏi ngôn ngữ tự nhiên phức tạp cho các tác vụ text2code.
•Các tác vụ mã downstream thông thường: Các tác vụ như Text2Code (ngôn ngữ tự nhiên thành đoạn mã), CodeTrans (dịch mã giữa các ngôn ngữ lập trình), CodeComment (bình luận mã), CodeExplain (giải thích mã), TestCase (tạo test case), và nhiều hơn nữa.
•Khả năng đối thoại đa lượt: Nó nên hỗ trợ các cuộc trò chuyện đa lượt nơi các truy vấn của người dùng có thể liên quan hoặc không liên quan đến ngữ cảnh trước đó, yêu cầu mô hình thực hiện đánh giá ý định chính xác.
•Đầu ra không độc hại: Mô hình nên tạo ra nội dung không có độc tính và tác hại. Bên cạnh việc tuân thủ các giá trị con người cơ bản và đạo đức, CodeFuse, là một mô hình ngôn ngữ lớn về mã, cần chú ý đặc biệt đến độc tính liên quan đến mã. Ví dụ, nó không nên xuất ra nội dung có thể gây ra vấn đề bảo mật thông tin, như các chương trình lừa đảo hoặc Trojan.

Tăng cường hướng dẫn tự hướng dẫn. Chúng tôi đã thu thập các cặp câu hỏi-trả lời cho các tác vụ liên quan đến mã từ lĩnh vực công cộng cũng như trích xuất ngữ nghĩa mã như được mô tả trong Phần 2.3. Tuy nhiên, bộ dữ liệu cho các tác vụ mã từ lĩnh vực công cộng nhỏ hơn nhiều so với các tác vụ ngôn ngữ, và việc trích xuất ngữ nghĩa mã bị hạn chế đối với một số tác vụ mã nhất định. Điều này đòi hỏi các cách mới để tăng cường bộ dữ liệu cho các tác vụ nghèo nàn. Nhờ vào các kỹ thuật tự hướng dẫn được giới thiệu trong Alpaca [39], CodeFuse tận dụng những bộ dữ liệu gốc chất lượng cao mở hoặc viết thủ công như hạt giống, và tạo ra các đầu ra thông tin và liên quan ngữ cảnh với sự trợ giúp của các mô hình sẵn có như ChatGPT. Phương pháp này phù hợp cho việc tăng cường dữ liệu phân kỳ.

Mô tả theo hướng dẫn. Các phương pháp đã đề cập cho phép chúng tôi xây dựng đầu vào và đầu ra phù hợp cho các tác vụ khác nhau. Tuy nhiên, vẫn có một khoảng cách bước cho một LLM để theo hướng dẫn, đó là mô tả hướng dẫn. Một số dữ liệu có thể đã có hướng dẫn bao gồm trong đầu vào, trong khi những dữ liệu khác yêu cầu thêm mô tả hướng dẫn để làm quen mô hình với các hướng dẫn cụ thể cho tác vụ. Điều này cho phép mô hình được kích hoạt để theo các mô tả hướng dẫn tương tự trong quá trình sử dụng. Hơn nữa, thông tin mô tả trong ngữ cảnh và chuỗi suy nghĩ (CoT) có thể được thêm vào để nâng cao hiệu suất của mô hình.

Định dạng dữ liệu. Trong thực tế, dữ liệu cho các tình huống khác nhau, như cuộc trò chuyện đa lượt, học few-shot, và các tác vụ CoT, đến từ các kênh đa dạng và có định dạng phức tạp. Để xử lý điều này, chúng tôi đã tiêu chuẩn hóa định dạng JSON gốc cho những loại tác vụ khác nhau này. Tính đến các thực hành hiện có trong học thuật và ngành công nghiệp, chúng tôi cuối cùng đã quyết định áp dụng ChatML (Chat Markup Language) [24] và đã thực hiện tối ưu hóa tương ứng. Chúng tôi đã chủ động giải quyết các vấn đề như lỗi token hóa, tấn công tiêm hướng dẫn, và các tình huống Multi-Role-Playing trong thiết kế định dạng. Mô hình LLM chấp nhận một chuỗi đầu vào văn bản trong quá trình huấn luyện và suy luận và chuyển đổi dữ liệu JSON gốc thành một chuỗi văn bản ở định dạng ChatML. Mô hình đối thoại CodeFuse hỗ trợ ba vai trò theo mặc định: System, Human, và Bot. Vai trò System cung cấp thông tin và hướng dẫn ban đầu, trong khi các vai trò Human và Bot đại diện cho đầu vào người dùng và phản hồi do mô hình tạo ra, tương ứng.

Tối ưu hóa. Trong quá trình tinh chỉnh, mô hình tập trung vào việc học đầu ra của Bot bằng cách tính toán mất mát chỉ cho vai trò Bot. Ngoài ra, CodeFuse giới thiệu tinh chỉnh đa tác vụ (MFT) vì các tác vụ mã downstream được chia thành đa tác vụ một cách tự nhiên. MFT giới thiệu các hàm mất mát được thiết kế tốt dựa trên học đa tác vụ cho phép mô hình học hiệu quả từ mỗi tác vụ ngay cả với số lượng mẫu, độ khó, và tốc độ hội tụ khác nhau. MFT có thể bổ sung các tác vụ khác nhau để đạt được kết quả tốt hơn SFT. Chi tiết về MFT sẽ được trình bày trong một bài báo khác.

3.5 Vận hành mô hình
CodeFuse-13B được huấn luyện sử dụng 512 card GPU Nvidia A100, với Tỷ lệ Sử dụng Hardware FLOPs (HFU) khoảng 60%. Quá trình huấn luyện mất khoảng 40 ngày để hoàn thành. Một số khả năng quan trọng liên quan đến tính ổn định đã được phát triển để đảm bảo quá trình huấn luyện thành công. Đặc biệt, chúng tôi đã phát triển một hệ thống quan sát dựa trên đám mây với hai phần chính.

•Quan sát chỉ số huấn luyện là điều cần thiết để giám sát quá trình huấn luyện, bao gồm các chỉ số quan trọng như mất mát huấn luyện/xác thực để đánh giá sự hội tụ và mức độ FLOPs tính toán. CodeFuse đã triển khai một instance TensorBoard trong đám mây, cho phép người dùng truy cập và phân tích các chỉ số này thông qua trình duyệt web.

•Quan sát chỉ số cơ sở hạ tầng bao phủ nhiều khía cạnh khác nhau như GPU và RDMA. CodeFuse sử dụng DCGM/NVML để thu thập chỉ số hiệu suất GPU/RDMA, lỗi ECC, và lỗi Xid. Họ cũng sử dụng một đại lý phát hiện phía node có tên Walle, để nắm bắt thông tin bất thường phần cứng. Thành phần GPU Diagnose xử lý các hoạt động khôi phục lỗi. Cụm GPU sử dụng công nghệ mạng hiệu suất cao RDMA để truyền và xử lý dữ liệu hiệu quả.

<| im_start |>system
Cung cấp một số ngữ cảnh và/hoặc hướng dẫn cho mô hình.
<|im_end|>
<| im_start |>user
Tin nhắn của người dùng ở đây
<|im_end|>
<| im_start |> assistant
Hình 5: Một ví dụ về ChatML.

Chúng tôi đã phát triển một hệ thống chẩn đoán GPU để phát hiện chủ động và xử lý tự động các lỗi của các node GPU, cũng như tự động khởi động lại/khôi phục các tác vụ huấn luyện bị kết thúc mà không cần can thiệp thủ công. Trong vòng 30 phút sau khi xảy ra lỗi, hệ thống xác định, cô lập, và lên lịch lại các card GPU bị lỗi, cho phép huấn luyện tiếp tục với checkpoint mới nhất. Để duy trì tính khả dụng cao của tài nguyên GPU, chúng tôi xác định chỉ số SLO cho khả năng lên lịch của các card GPU, dẫn đến việc tăng tính khả dụng GPU từ 87% lên 94% cho cụm trong chu kỳ huấn luyện.

4 ĐÁNH GIÁ
Trong phần này, chúng tôi bắt đầu bằng việc giới thiệu các mô hình mà chúng tôi đã đánh giá cùng với CodeFuse. Các thí nghiệm của chúng tôi được thực hiện bằng cách sử dụng GPU NVIDIA A100-SXM-80GB với hệ thống Linux. Chúng tôi trình bày một phân tích toàn diện về hiệu suất của tất cả các mô hình trên các benchmark HumanEval, HumanEval-x [8] và CodefuseEval của chúng tôi. Chúng tôi thực hiện đánh giá CodeFuse so với CodeGeeX, sử dụng nhiều tác vụ mã khác nhau với lời nhắc tiếng Trung.

4.1 Benchmark và giao thức đánh giá
HumanEval, phần mở rộng HumanEval-x và MBPP là các benchmark được sử dụng rộng rãi trong lĩnh vực mô hình ngôn ngữ lớn về mã. Các benchmark này bao gồm một bộ sưu tập lớn các vấn đề lập trình, sử dụng các test case để xác thực mã được tạo bởi các mô hình ngôn ngữ lớn về mã. Tuy nhiên, khi nói đến đầu vào tiếng Trung, vẫn còn nhu cầu về các phương pháp đánh giá trong một số tình huống mã nhất định. Để xử lý vấn đề này, chúng tôi đã phát triển và mở mã nguồn CodefuseEval³ để tạo điều kiện đánh giá trong các tình huống hoàn thành mã, tạo mã, dịch mã cross-program-language, bình luận mã, và tạo test case với cả lời nhắc tiếng Anh và tiếng Trung. Benchmark CodefuseEval là một phần mở rộng của các benchmark HumanEval và MBPP, bao phủ năm ngôn ngữ lập trình: Python, Java, C++, Go, và JavaScript.

Đối với các tác vụ tạo mã bao gồm hoàn thành mã, text2code, dịch mã, và tạo test case, chúng tôi áp dụng chỉ số pass@k làm tiêu chí đánh giá. Đối với các tác vụ bình luận mã, chúng tôi sử dụng Bleu và BleuRT làm chỉ số đánh giá. Để đánh giá toàn diện khả năng mã của mô hình trong đánh giá đa tác vụ, ba chiến lược giải mã được sử dụng: lấy mẫu nhiệt độ, greedy, và beam search. Các lời nhắc được định dạng sử dụng zero-shot, cho phép mô hình tạo phản hồi mà không cần tinh chỉnh cụ thể cho tác vụ. Khi sử dụng chiến lược lấy mẫu nhiệt độ, chúng tôi đặt các siêu tham số cho pass@1 như sau: temperature = 0.2, top_p = 0.95, và generate n = 10 mẫu.

4.2 Các mô hình so sánh
Chúng tôi so sánh CodeFuse với các mô hình sau có kích thước tương tự. Thống kê của các mô hình so sánh từ các báo cáo đã xuất bản.
•GPT-NeoX-20B [5] là một mô hình ngôn ngữ tự hồi quy 20 tỷ tham số được huấn luyện trên Pile [14].
•StarCoder [20] là một mô hình ngôn ngữ lớn về mã với 15B tham số và kích thước ngữ cảnh 8K, hỗ trợ khả năng infilling và suy luận nhanh.
•CodeGeeX là một mô hình ngôn ngữ đã được huấn luyện trên một bộ sưu tập 23 ngôn ngữ lập trình. Đây là một mô hình mã nguồn mở với 13 tỷ tham số. Dữ liệu huấn luyện của nó được chọn từ Pile [14], CodeParrot [47], và các bộ dữ liệu khác. Ngoài những bộ dữ liệu này, CodeGeeX cũng bao gồm bộ benchmark đa ngôn ngữ riêng, HumanEval-x, mà chúng tôi thảo luận dưới đây.
•BaiduErnie [37,38,44] (Enhanced Representation through kNowledge IntEgration) là một mô hình biểu diễn ngôn ngữ được tăng cường bằng cách sử dụng các chiến lược che giấu kiến thức. Chiến lược che giấu của BaiduErnie lấy cảm hứng từ BERT [11] bao gồm chiến lược cấp cụm từ và chiến lược cấp thực thể.

Bảng 3: Các mô hình gia đình của CodeFuse.
Mô hình NumLayers NumHeads HiddenSize SeqLen BatchSize LearningRate Paralells
CodeFuse-350M 24 16 1024 2048 1024 2e-4 DP=64
CodeFuse-1.3B 24 16 2048 2048 1024 2e-4 DP=128
CodeFuse-6B 28 32 4096 4096 2048 1.5e-4 DP=256
CodeFuse-13B 40 40 5120 4096 4096 1.5e-4 DP=256, TP=2

--- TRANG 7 ---
CodeFuse-13B: Một Mô hình Ngôn ngữ Lớn Đa ngôn ngữ Tiền huấn luyện cho Mã nguồn ICSE-SEIP '24, 14-20 tháng 4, 2024, Lisbon, Bồ Đào Nha

•CodeGen [26] có hai phiên bản, CodeGen-Mono-16B là một biến thể của CodeGen-Multi-16B, được tinh chỉnh cụ thể sử dụng mã Python bổ sung từ GitHub.
•CodeT5+ [45], một mô hình ngôn ngữ lớn về mã dựa trên encoder-decoder, có tính linh hoạt modular, phù hợp với các tác vụ downstream liên quan đến mã đa dạng.
•WizardCoder [23] được huấn luyện sử dụng kỹ thuật Evol-Instruct. Nó đã cho thấy cải thiện hiệu suất đáng chú ý trong đánh giá python HumanEval so với các mô hình trước đó.
•PanGu-Coder2 [32] được huấn luyện bởi framework RRTF (Rank Responses to align Test&Teacher Feedback) với cùng kỹ thuật Evol-Instruct như WizardCoder. PanGu-Coder2 đã đạt được hiệu suất dẫn đầu trên HumanEval trong số các mô hình có kích thước tương tự. Giống như WizardCoder, PanGu-Coder2 cũng là một mô hình đơn ngôn ngữ.
•CodeLlama [30] là một gia đình các mô hình ngôn ngữ lớn cho mã, dựa trên Llama 2. Nó nổi bật trong số các mô hình mở khác với hiệu suất tiên tiến, khả năng infilling, hỗ trợ ngữ cảnh đầu vào lớn, và khả năng theo hướng dẫn zero-shot cho các tác vụ lập trình.

4.3 Đánh giá về tạo mã
Trong so sánh CodeFuse với các Mô hình Ngôn ngữ về Mã (LLMs) hiện có có kích thước tương tự, chúng tôi đã đánh giá hiệu suất tạo mã của chúng. Để đảm bảo tính công bằng, chúng tôi đã thu thập thống kê cho các mô hình khác trong Bảng 4 từ các báo cáo hiện có. Tuy nhiên, hiệu suất của CodeT5+ và CodeLlama trên HumanEval-x không được trình bày trong các bài báo tương ứng của họ hoặc công trình liên quan đã xuất bản khác. Do đó, Bảng 4 thiếu dữ liệu cho những mô hình này.

Chúng tôi trình bày hiệu suất của nhiều phiên bản CodeFuse vì chúng chứng minh tiến trình của CodeFuse và thành tựu trong các tác vụ khác nhau. Hầu hết những phiên bản này được triển khai trong nhiều tình huống khác nhau. Ngoài ra, chúng tôi giới thiệu bảy mô hình đa ngôn ngữ chính hiện tại có kích thước từ 13 tỷ đến 16 tỷ tham số. Chúng tôi cũng trình bày ba Mô hình Ngôn ngữ về Mã (LLMs) tiên tiến, trong số đó PanGu-Coder2, được phát hành tháng trước, đạt điểm HumanEval cao nhất.

Trong đánh giá HumanEval Python pass@1, phiên bản mã nguồn mở của CodeFuse-13B vượt trội hơn các mô hình đa ngôn ngữ khác. Tuy nhiên, vì các mô hình đơn ngôn ngữ như CodeLlama-Python, WizardCoder, và PanGu-Coder2 đã thực hiện các tối ưu hóa cụ thể cho việc tạo mã Python, vẫn còn thách thức đối với CodeFuse để vượt qua chúng trong đánh giá Python.

4.4 Đánh giá về dịch mã đa ngôn ngữ
Chúng tôi đánh giá CodeFuse về dịch mã đa ngôn ngữ bằng cách so sánh nó với CodeGen-multi-16B và CodeGeeX-13B. Tương tự như CodeGeeX-13B, có phiên bản tinh chỉnh chuyên biệt cho dịch mã có tên CodeGeeX-13B-FT, CodeFuse-13B-SFT là phiên bản tinh chỉnh đa tác vụ bao gồm dịch mã.

Bộ dữ liệu đánh giá dịch mã mà chúng tôi sử dụng được xây dựng dựa trên MBXP và HumanEval-x. Nó bao gồm các trường hợp đã được xem xét và sửa chữa bởi các chuyên gia và đã được mở như một phần của CodefuseEval.

Bảng 5 trình bày kết quả pass@1 cho việc chuyển đổi lẫn nhau giữa Java, Python, và C++ sử dụng giải mã greedy. Bảng này rõ ràng cho thấy CodeFuse-13B-SFT vượt trội hơn các mô hình khác khi dịch mã Python sang hai ngôn ngữ khác. Ngoài ra, nó đạt điểm trung bình cao nhất trên tất cả sáu tình huống dịch.

4.5 Đánh giá về các tác vụ liên quan đến mã với lời nhắc tiếng Trung
Chúng tôi đã thực hiện đánh giá CodeFuse về hỗ trợ lời nhắc tiếng Trung bằng cách so sánh nó với CodeGeeX, được biết đến với hỗ trợ tiếng Trung xuất sắc. Hình 6 giới thiệu các ví dụ về tạo mã, dịch mã, bình luận mã, và tạo test case với lời nhắc bằng tiếng Trung. Ngoài đánh giá về tạo mã và dịch được đề cập trong các phần trước, tạo test case, bình luận mã, và giải thích được bao gồm trong đánh giá của chúng tôi.

Trong các tác vụ bình luận và giải thích mã, chúng tôi đặc biệt đánh giá CodeFuse của mình, bằng cách tích hợp nó vào quy trình phát triển của AntGroup. Phản hồi có giá trị từ các nhà phát triển trong công việc hàng ngày đã được thu thập để đánh giá hiệu suất trong các tình huống thực tế. Chúng tôi không so sánh CodeFuse với các mô hình khác do thời gian và nỗ lực cần thiết để triển khai một mô hình cạnh tranh trong quy trình phát triển hàng ngày của chúng tôi. Sau khi thu thập phản hồi con người trong vài tháng, CodeFuse-13B-SFT đạt điểm Bleu là 42.42% và điểm BleuRT là 36.34% như được hiển thị trong Bảng 6. Những kết quả này cho thấy CodeFuse thực sự hữu ích trong các tình huống phát triển thực tế.

Gần đây, đã có những nỗ lực để tự động tạo test case bằng cách cung cấp một đoạn mã cho LLMs [31,43,49]. Trong đánh giá của chúng tôi, chúng tôi đã sử dụng bộ dữ liệu HumanEval-x và chọn CodeGeeX làm mô hình cơ sở do kích thước mô hình tương đương, hỗ trợ lời nhắc tiếng Trung, và sự liên quan đến các ứng dụng ngành công nghiệp. Chúng tôi đã thực hiện những điều chỉnh nhỏ đối với bộ dữ liệu để tuân thủ định dạng lời nhắc được hiển thị trong Hình 6(c). Như được hiển thị trong Bảng 7, CodeFuse vượt trội hơn CodeGeeX trong tác vụ tạo test case với lời nhắc tiếng Trung.

5 CÔNG TRÌNH LIÊN QUAN
Các mô hình ngôn ngữ lớn. LLMs đã thể hiện những thành tựu đáng chú ý trên một loạt rộng các tác vụ. Các công ty công nghệ hàng đầu đã đạt được tiến bộ đáng kể trong việc tạo ra các LLMs có khả năng cao. Các ví dụ đáng chú ý bao gồm GPT3&4 của OpenAI [6,27], PaLM của Google [2,9], Chinchilla và Gopher của DeepMind [17,28], cũng như Claude của Anthropic⁴. Tuy nhiên, những mô hình này là closed-source và chỉ được truy cập thông qua các API cụ thể.

Một số LLMs mã nguồn mở đã được phát hành và đóng góp có giá trị cho công chúng. EleutherAI đã đóng góp GPT-NeoX-20B [5] và GPT-J-6B [42]. Google đã phát hành UL2-20B. Đại học Tsinghua đã giới thiệu GLM-130B [50,52]. Meta đã phát hành LLaMA [40] và LLaMA2 [41].

Các mô hình ngôn ngữ lớn về mã. Nhiều công trình đã giới thiệu LLMs để giải quyết các thách thức của các vấn đề hiểu và tạo mã. Codex [7] đã hỗ trợ Copilot cho các tác vụ mã. Google đã đề xuất PaLM-Coder [9]. Những mô hình này đã cho thấy hiệu suất đặc biệt trên các benchmark hoàn thành mã phổ biến như

--- TRANG 8 ---
CodeFuse-13B: Một Mô hình Ngôn ngữ Lớn Đa ngôn ngữ Tiền huấn luyện cho Mã nguồn ICSE-SEIP '24, 14-20 tháng 4, 2024, Lisbon, Bồ Đào Nha

a. Một ví dụ về tạo mã.
b. Một ví dụ về dịch mã.
c. Một ví dụ về tạo test case.
d. Một ví dụ về bình luận và giải thích mã.
Hình 6: Ví dụ về tạo CodeFuse với lời nhắc bằng tiếng Trung. Kết quả được tạo bởi tiện ích mở rộng CodeFuse VSCode, và các chỉ báo như "#" đã được loại bỏ để dễ đọc hơn cho con người.

--- TRANG 9 ---
CodeFuse-13B: Một Mô hình Ngôn ngữ Lớn Đa ngôn ngữ Tiền huấn luyện cho Mã nguồn ICSE-SEIP '24, 14-20 tháng 4, 2024, Lisbon, Bồ Đào Nha

a. Một ví dụ về tạo mã.
b. Một ví dụ về dịch mã.
c. Một ví dụ về tạo test case.
d. Một ví dụ về bình luận và giải thích mã.
Hình 6: Ví dụ về tạo CodeFuse với lời nhắc bằng tiếng Trung. Kết quả được tạo bởi tiện ích mở rộng CodeFuse VSCode, và các chỉ báo như "#" đã được loại bỏ để dễ đọc hơn cho con người.

--- TRANG 10 ---
ICSE-SEIP '24, 14-20 tháng 4, 2024, Lisbon, Bồ Đào Nha Peng Di, và các cộng sự.

Bảng 4: So sánh hiệu suất của CodeFuse với các mô hình trước đó có kích thước tương tự trên HumanEval-x.
Mô hình Ngôn ngữ HumanEval-x pass@1
Python Java C++ JavaScript Go
CodeFuse CodeFuse-13B-Base 24.83% 23.78% 22.08% 19.62% 18.17%
CodeFuse-13B-SFT 37.10% 26.22% 19.51% 31.71% 24.39%
Đa ngôn ngữ GPT-NeoX-20B 13.83% 8.87% 9.90% 11.28% 5.00%
CodeGEEX-13B 22.89% 20.04% 17.06% 17.59% 14.43%
Baidu-ERNIE-3.5-15.5B 35.37% 26.22% 20.11% 34.76% 27.43%
StarCoder-15.5B 33.57% 30.22% 31.55% 30.79% 17.61%
CodeGen-multi-16B 19.22% 14.95% 18.05% 18.40% 13.03%
CodeT5+-16B 30.90%
CodeLlama-13B 36.00%
Đơn ngôn ngữ CodeLlama-Python-13B 43.30%
WizardCoder-16B 57.30%
PanGu-Coder2-15B 61.64%

Bảng 5: So sánh hiệu suất (pass@1) của CodeFuse với các mô hình trước đó về dịch mã sử dụng giải mã greedy
Mô hình Java to Py C++ to Py C++ to Java Java to C++ Py to Java Py to C++ Trung bình
CodeFuse-13B-Base 53.66% 55.49% 41.46% 37.80% 48.10% 50.00% 47.75%
CodeFuse-13B-SFT 66.46% 59.15% 54.27% 47.56% 56.31% 55.40% 56.53%
CodeGen-multi-16B 52.73% 33.83% 43.20% 41.42% 29.27% 35.94% 39.40%
CodeGeeX-13B 43.41% 27.18% 22.56% 39.33% 25.84% 26.54% 30.81%
CodeGeeX-13B-FT 75.03% 62.79% 71.68% 49.67% 41.98% 34.16% 55.89%

Bảng 6: Đánh giá bình luận và giải thích mã tiếng Trung trên CodefuseEval và phản hồi thực tế
Mô hình Bleu BleuRT
CodeFuse-13B-Base 36.75% 27.76%
CodeFuse-13B-SFT 42.42% 36.34%

Bảng 7: Đánh giá tạo test case tiếng Trung trên CodefuseEval
Mô hình pass@1 Python pass@1 Java
CodeFuse-13B-SFT 31.20% 24.32%
CodeGeeX-13B 22.89% 20.04%

HumanEval [8] và MBPP [3]. Tuy nhiên, điều quan trọng cần lưu ý là những mô hình này là closed-source.

Cũng có một số mô hình ngôn ngữ lớn về mã mã nguồn mở có sẵn. Salesforce đã phát triển CodeGen [26], CodeT5 [46], và CodeT5+ [45]. Đại học Tsinghua đã đóng góp CodeGeeX [52], và Dự án BigCode đã tạo ra StarCoder [20]. Trong khi các mô hình gần đây như WizardCode [23], PanGu-Coder2 [32], và CodeLLaMA [30] đã đạt được điểm số ấn tượng trên HumanEval, điều đáng chú ý là chúng yếu đối với lời nhắc đa ngôn ngữ. Ngược lại, CodeFuse được thiết kế là một Mô hình Ngôn ngữ về Mã (LLM) đa ngôn ngữ hỗ trợ nhiều tác vụ liên quan đến mã trên cả lời nhắc tiếng Anh và tiếng Trung. Điều này làm cho CodeFuse trở thành một giải pháp có giá trị cho các nhà phát triển làm việc trong môi trường ngôn ngữ đa dạng.

6 THẢO LUẬN, KẾT LUẬN, CÔNG VIỆC TƯƠNG LAI
Mở rộng framework MFT để hỗ trợ các mô hình mã nguồn mở. Chúng tôi phát triển một framework tinh chỉnh đa tác vụ và mở mã nguồn nó dưới tên MFTCoder⁴. Framework này có thể được sử dụng để tinh chỉnh cả CodeFuse-13B được phát triển nội bộ của chúng tôi và các mô hình ngôn ngữ lớn về mã mã nguồn mở mới nổi như StarCoder [20] và CodeLLaMA [30]. Chúng tôi đã tinh chỉnh các mô hình StarCoder và CodeLLaMA với framework MFTCoder trên các bộ dữ liệu đã thu thập của chúng tôi, và mở mã nguồn phiên bản tinh chỉnh dưới tên CodeFuse-CodeLlama-34B và CodeFuse-StarCoder-15B. CodeFuse-CodeLlama-34B đạt điểm pass@1 74.4% trên HumanEval, vượt qua điểm số của GPT4 và ChatGPT-3.5, và đại diện cho kết quả tiên tiến cho các Mô hình Ngôn ngữ mã nguồn mở (LLMs). Cũng rõ ràng rằng chiến lược chuẩn bị dữ liệu trong CodeFuse nâng cao đáng kể hiệu suất của các mô hình ngôn ngữ lớn về mã khác.

Triển khai. CodeFuse được triển khai trong môi trường sản xuất trong AntGroup dưới dạng cả plugin IDE và chat dựa trên web. Xem Hình 6 cho một số ví dụ. Để tạo điều kiện cho thời gian phản hồi mô hình và thông lượng dịch vụ, chúng tôi giới thiệu một loạt tối ưu hóa cho dịch vụ mô hình, bao gồm (1) lượng tử hóa mô hình xuống 4bits với mất mát độ chính xác không đáng kể sử dụng GPTQ tinh chế lặp tự động [12]; (2) tận dụng tối ưu hóa phần mềm được cung cấp bởi Nvidia TensorRT-LLM⁵; (3) thực hiện tối ưu hóa dịch vụ thông qua semantic cache và streaming output. Sản phẩm hiện hỗ trợ phát triển phần mềm hàng ngày của hơn 5K kỹ sư trong AntGroup.

⁴https://github.com/codefuse-ai/MFTCoder
⁵https://developer.nvidia.com/tensorrt-llm-early-access

--- TRANG 11 ---
CodeFuse-13B: Một Mô hình Ngôn ngữ Lớn Đa ngôn ngữ Tiền huấn luyện cho Mã nguồn ICSE-SEIP '24, 14-20 tháng 4, 2024, Lisbon, Bồ Đào Nha

Kết luận. Bài báo này giới thiệu CodeFuse-13B, một Mô hình Ngôn ngữ (LLM) tiền huấn luyện mã nguồn mở với 13 tỷ tham số được thiết kế cho các tác vụ liên quan đến mã với lời nhắc đa ngôn ngữ (tiếng Anh và tiếng Trung). Nó hỗ trợ hơn 40 ngôn ngữ lập trình và sử dụng một bộ dữ liệu tiền huấn luyện được lọc cẩn thận. Các thí nghiệm sử dụng các tình huống thực tế và benchmark ngành công nghiệp chứng minh rằng CodeFuse-13B đạt điểm HumanEval Pass@1 là 37.10%, khiến nó trở thành một trong những mô hình đa ngôn ngữ hàng đầu với kích thước tham số tương tự. Nó vượt trội hơn các mô hình khác trong các tác vụ tạo mã, dịch, bình luận, và tạo test case với đầu vào tiếng Trung. Phản hồi có giá trị từ con người trong quy trình phát triển phần mềm của AntGroup xác nhận việc tích hợp thành công của CodeFuse-13B.

Công việc tương lai. Bên cạnh các mô hình của CodeFuse và framework MFTCoder, chúng tôi dự định tiếp tục mở mã nguồn hai thành phần quan trọng của CodeFuse: benchmark CodefuseEval và hệ thống truy vấn chương trình Sparrow để làm sạch dữ liệu mã chất lượng cao. Bằng cách mở mã nguồn những thành phần này, chúng tôi nhằm đóng góp cho cộng đồng nghiên cứu và tạo điều kiện cho những tiến bộ hơn nữa trong toàn bộ vòng đời phát triển phần mềm bản địa AI.

TÀI LIỆU THAM KHẢO
[1]Loubna Ben Allal, Raymond Li, Denis Kocetkov, et al .2023. SantaCoder: đừng với tay lên các ngôi sao! arXiv:2301.03988 [cs.SE]
[2]Rohan Anil, Andrew M. Dai, Orhan Firat, et al .2023. Báo cáo Kỹ thuật PaLM 2. arXiv:2305.10403 [cs.CL]
[3]Jacob Austin, Augustus Odena, Maxwell Nye, et al .2021. Tổng hợp Chương trình với Mô hình Ngôn ngữ Lớn. arXiv:2108.07732 [cs.PL]
[4]Jimmy Lei Ba, Jamie Ryan Kiros, và Geoffrey E. Hinton. 2016. Chuẩn hóa Lớp. arXiv:1607.06450 [stat.ML]
[5]Sid Black, Stella Biderman, Eric Hallahan, et al .2022. GPT-NeoX-20B: Một Mô hình Ngôn ngữ Tự Hồi quy Mã nguồn Mở. arXiv:2204.06745 [cs.CL]
[6]Tom B. Brown, Benjamin Mann, Nick Ryder, et al .2020. Mô hình Ngôn ngữ là Những Người Học Few-Shot. arXiv:2005.14165 [cs.CL]
[7] Mark Chen, Jerry Tworek, Heewoo Jun, et al. 2021. Đánh giá Mô hình Ngôn ngữ Lớn Huấn luyện trên Mã. arXiv:2107.03374 [cs.LG]
[8] Mark Chen, Jerry Tworek, Heewoo Jun, et al. 2021. Đánh giá Mô hình Ngôn ngữ Lớn Huấn luyện trên Mã. arXiv:2107.03374 [cs.LG]
[9]Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, et al .2022. PaLM: Mở rộng Mô hình Ngôn ngữ với Pathways. arXiv:2204.02311 [cs.CL]
[10] Tri Dao, Daniel Y. Fu, Stefano Ermon, et al .2022. FlashAttention: Attention Chính xác Nhanh và Hiệu quả Bộ nhớ với IO-Awareness. arXiv:2205.14135 [cs.LG]
[11] Jacob Devlin, Ming-Wei Chang, Kenton Lee, và Kristina Toutanova. 2019. BERT: Tiền huấn luyện Transformers Hai chiều Sâu cho Hiểu Ngôn ngữ. arXiv:1810.04805 [cs.CL]
[12] Elias Frantar, Saleh Ashkboos, Torsten Hoefler, và Dan Alistarh. 2022. GPTQ: Lượng tử hóa sau huấn luyện chính xác cho transformers tiền huấn luyện sinh tạo. arXiv preprint arXiv:2210.17323 (2022).
[13] Daniel Fried, Armen Aghajanyan, Jessy Lin, et al .2023. InCoder: Một Mô hình Sinh tạo cho Infilling và Tổng hợp Mã. arXiv:2204.05999 [cs.SE]
[14] Leo Gao, Stella Biderman, Sid Black, et al .2020. The Pile: Một Bộ dữ liệu 800GB Văn bản Đa dạng cho Mô hình Ngôn ngữ. arXiv:2101.00027 [cs.CL]
[15] Ant Group. 2023. Sparrow. http://sparrow.alipay.com.
[16] Dan Hendrycks và Kevin Gimpel. 2023. Đơn vị Tuyến tính Lỗi Gaussian (GELUs). arXiv:1606.08415 [cs.LG]
[17] Jordan Hoffmann, Sebastian Borgeaud, Arthur Mensch, et al .2022. Huấn luyện Mô hình Ngôn ngữ Lớn Tối ưu Tính toán. arXiv:2203.15556 [cs.CL]
[18] Diederik P. Kingma và Jimmy Ba. 2017. Adam: Một Phương pháp cho Tối ưu hóa Ngẫu nhiên. arXiv:1412.6980 [cs.LG]
[19] Denis Kocetkov, Raymond Li, Loubna Ben Allal, et al .2022. The Stack: 3 TB mã nguồn được cấp phép cho phép. arXiv:2211.15533 [cs.CL]
[20] Raymond Li, Loubna Ben Allal, Yangtian Zi, et al .2023. StarCoder: mong nguồn gốc ở cùng bạn! arXiv:2305.06161 [cs.CL]
[21] Yujia Li, David Choi, Junyoung Chung, et al .2022. Tạo mã cấp độ thi đấu với AlphaCode. Science 378, 6624 (dec 2022), 1092–1097. https://doi.org/10.1126/science.abq1158
[22] Jiangchao Liu, Jierui Liu, Peng Di, et al .2023. Hybrid Inlining: Một Framework cho Phân tích Tĩnh Tổng hợp và Nhạy cảm Ngữ cảnh. Trong Proceedings of the 32nd ACM SIGSOFT International Symposium on Software Testing and Analysis, ISSTA 2023, Seattle, WA, USA, July 17-21, 2023 , René Just và Gordon Fraser (Eds.). ACM, 114–126.
[23] Ziyang Luo, Can Xu, Pu Zhao, et al .2023. WizardCoder: Trao quyền cho Mô hình Ngôn ngữ Lớn về Mã với Evol-Instruct. arXiv:2306.08568 [cs.CL]
[24] MicroSoft. 2023. ChatML. https://github.com/openai/openai-python/blob/main/chatml.md.
[25] Oege de Moor, Mathieu Verbaere, Elnar Hajiyev, et al .2007. Địa chỉ Keynote: .QL cho Phân tích Mã nguồn. Trong Seventh IEEE International Working Conference on Source Code Analysis and Manipulation (SCAM 2007) . 3–16. https://doi.org/10.1109/SCAM.2007.31
[26] Erik Nijkamp, Bo Pang, Hiroaki Hayashi, et al .2023. CodeGen: Một Mô hình Ngôn ngữ Lớn Mở cho Mã với Tổng hợp Chương trình Đa lượt. arXiv:2203.13474 [cs.LG]
[27] OpenAI. 2023. Báo cáo Kỹ thuật GPT-4. arXiv:2303.08774 [cs.CL]
[28] Jack W. Rae, Sebastian Borgeaud, Trevor Cai, et al .2022. Mở rộng Mô hình Ngôn ngữ: Phương pháp, Phân tích & Hiểu biết từ Huấn luyện Gopher. arXiv:2112.11446 [cs.CL]
[29] Samyam Rajbhandari, Jeff Rasley, Olatunji Ruwase, và Yuxiong He. 2020. ZeRO: Tối ưu hóa Bộ nhớ Hướng tới Huấn luyện Mô hình Nghìn tỷ Tham số. arXiv:1910.02054 [cs.LG]
[30] Baptiste Rozière, Jonas Gehring, Fabian Gloeckle, et al .2023. Code Llama: Mô hình Nền tảng Mở cho Mã. arXiv:2308.12950 [cs.CL]
[31] Max Schäfer, Sarah Nadi, Aryaz Eghbali, và Frank Tip. 2023. Một Đánh giá Thực nghiệm về Sử dụng Mô hình Ngôn ngữ Lớn cho Tạo Test Đơn vị Tự động. arXiv:2302.06527 [cs.SE]
[32] Bo Shen, Jiaxin Zhang, Taihong Chen, et al .2023. PanGu-Coder2: Tăng cường Mô hình Ngôn ngữ Lớn cho Mã với Phản hồi Xếp hạng. arXiv:2307.14936 [cs.CL]
[33] Qingkai Shi, Xiao Xiao, Rongxin Wu, et al .2018. Pinpoint: phân tích luồng giá trị thưa thớt nhanh và chính xác cho hàng triệu dòng mã. Trong Proceedings of the 39th ACM SIGPLAN Conference on Programming Language Design and Implementation, PLDI 2018, Philadelphia, PA, USA, June 18-22, 2018 , Jeffrey S. Foster và Dan Grossman (Eds.). ACM, 693–706.
[34] Yusuke Shibata, Takuya Kida, Shuichi Fukamachi, et al .1999. Mã hóa Cặp Byte: Một Sơ đồ Nén Văn bản Tăng tốc Khớp Mẫu. (09 1999).
[35] Mohammad Shoeybi, Mostofa Patwary, Raul Puri, et al .2020. Megatron-LM: Huấn luyện Mô hình Ngôn ngữ Đa tỷ Tham số Sử dụng Song song Mô hình. arXiv:1909.08053 [cs.CL]
[36] Jianlin Su, Yu Lu, Shengfeng Pan, et al .2022. RoFormer: Transformer Nâng cao với Embedding Vị trí Quay. arXiv:2104.09864 [cs.CL]
[37] Yu Sun, Shuohuan Wang, Yukun Li, et al .2019. ERNIE 2.0: Một Framework Tiền huấn luyện Liên tục cho Hiểu Ngôn ngữ. arXiv:1907.12412 [cs.CL]
[38] Yu Sun, Shuohuan Wang, Yukun Li, et al .2019. ERNIE: Biểu diễn Nâng cao thông qua Tích hợp Kiến thức. arXiv:1904.09223 [cs.CL]
[39] Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, et al .2023. Stanford Alpaca: Một mô hình LLaMA theo hướng dẫn. https://github.com/tatsu-lab/stanford_alpaca.
[40] Hugo Touvron, Thibaut Lavril, Gautier Izacard, et al .2023. LLaMA: Mô hình Ngôn ngữ Nền tảng Mở và Hiệu quả. arXiv:2302.13971 [cs.CL]
[41] Hugo Touvron, Louis Martin, Kevin Stone, et al .2023. Llama 2: Mô hình nền tảng mở và chat tinh chỉnh. arXiv preprint arXiv:2307.09288 (2023).
[42] Ben Wang và Aran Komatsuzaki. 2021. GPT-J-6B: Một Mô hình Ngôn ngữ Tự Hồi quy 6 Tỷ Tham số. https://github.com/kingoflolz/mesh-transformer-jax.
[43] Junjie Wang, Yuchao Huang, Chunyang Chen, et al .2023. Kiểm thử Phần mềm với Mô hình Ngôn ngữ Lớn: Khảo sát, Cảnh quan, và Tầm nhìn. arXiv:2307.07221 [cs.SE]
[44] Shuohuan Wang, Yu Sun, Yang Xiang, et al .2021. ERNIE 3.0 Titan: Khám phá Tiền huấn luyện Nâng cao Kiến thức Quy mô Lớn hơn cho Hiểu và Tạo Ngôn ngữ. arXiv:2112.12731 [cs.CL]
[45] Yue Wang, Hung Le, Akhilesh Deepak Gotmare, et al .2023. CodeT5+: Mô hình Ngôn ngữ Lớn về Mã Mở cho Hiểu và Tạo Mã. arXiv:2305.07922 [cs.CL]
[46] Yue Wang, Weishi Wang, Shafiq Joty, và Steven C. H. Hoi. 2021. CodeT5: Mô hình Encoder-Decoder Tiền huấn luyện Thống nhất Nhận biết Định danh cho Hiểu và Tạo Mã. arXiv:2109.00859 [cs.CL]
[47] Thomas Wolf, Lysandre Debut, Victor Sanh, et al .2020. Transformers: Xử lý Ngôn ngữ Tự nhiên Tiên tiến. Trong Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations . Association for Computational Linguistics, Online, 38–45.
[48] Ruibin Xiong, Yunchang Yang, Di He, et al .2020. Về Chuẩn hóa Lớp trong Kiến trúc Transformer. arXiv:2002.04745 [cs.LG]
[49] Guixin Ye, Zhanyong Tang, Shin Hwei Tan, Songfang Huang, et al .2021. Kiểm thử Tuân thủ Tự động cho Động cơ JavaScript qua Deep Compiler Fuzzing. Trong Proceedings of the 42nd ACM SIGPLAN International Conference on Programming Language Design and Implementation (PLDI 2021) . Association for Computing Machinery, 435–450.
[50] Aohan Zeng, Xiao Liu, Zhengxiao Du, et al .2022. GLM-130B: Một Mô hình Tiền huấn luyện Song ngữ Mở. arXiv:2210.02414 [cs.CL]
[51] Wayne Xin Zhao, Kun Zhou, Junyi Li, et al .2023. Một Khảo sát về Mô hình Ngôn ngữ Lớn. arXiv:2303.18223 [cs.CL]
[52] Qinkai Zheng, Xiao Xia, Xu Zou, et al .2023. CodeGeeX: Một Mô hình Tiền huấn luyện cho Tạo Mã với Đánh giá Đa ngôn ngữ trên HumanEval-X. arXiv:2303.17568 [cs.LG]

--- TRANG 12 ---
ICSE-SEIP '24, 14-20 tháng 4, 2024, Lisbon, Bồ Đào Nha Peng Di, và các cộng sự.

[53] Zexin Zhong, Jiangchao Liu, Diyu Wu, Peng Di, et al .2022. Phân tích Taint Tĩnh Dựa trên Trường cho Microservices Công nghiệp. Trong 44th IEEE/ACM International Conference on Software Engineering: Software Engineering in Practice, ICSE (SEIP) 2022, Pittsburgh, PA, USA, May 22-24, 2022 . IEEE, 149–150.
[54] Zexin Zhong, Jiangchao Liu, Diyu Wu, Peng Di, et al .2023. Phân tích Taint Tĩnh Tổng hợp Mở rộng cho Theo dõi Dữ liệu Nhạy cảm trên Micro-Services Công nghiệp. Trong 45th IEEE/ACM International Conference on Software Engineering: Software Engineering in Practice, SEIP@ICSE 2023, Melbourne, Australia, May 14-20, 2023 . IEEE, 110–121.
[55] Xin Zhou, Kisub Kim, Bowen Xu, et al .2023. Con quỷ ở trong Đuôi: Cách Phân bố Mã Đuôi dài Ảnh hưởng đến Mô hình Ngôn ngữ Lớn. arXiv:2309.03567 [cs.SE]

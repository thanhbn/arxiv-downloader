# 2207.10739.pdf
# Converted from PDF to TXT
# Source path: /home/admin88/arxiv-downloader/benchmark/2207.10739.pdf
# File size: 322142 bytes

===============================================
PDF FILE CONTENT
===============================================


--- PAGE 1 ---
arXiv:2207.10739v2  [cs.LG]  4 May 2023Published as a conference paper at ICLR 2023
BIGISSUE : A R EALISTIC BUGLOCALIZATION BENCH -
MARK
Paul Kassianik∗
Salesforce Research
pkassianik@salesforce.comErik Nijkamp∗
Salesforce Research
erik.nijkamp@salesforce.com
Bo Pang
Salesforce Research
bo.pang@salesforce.comYingbo Zhou
Salesforce Research
yingbo.zhou@salesforce.com
Caiming Xiong
Salesforce Research
cxiong@salesforce.com
ABSTRACT
As machine learning tools progress, the inevitable questio n arises: How can ma-
chine learning help us write better code? With signiﬁcant pr ogress being achieved
in natural language processing with models like GPT-3 and BE RT, the applica-
tions of natural language processing techniques to code is s tarting to be explored.
Most research has been focused on automatic program repair ( APR), and while
the results on synthetic or highly ﬁltered datasets are prom ising, such models are
hard to apply in real-world scenarios because of underperfo rming bug localiza-
tion techniques. We propose BigIssue: a realistic bug local ization benchmark.
The goal of the benchmark is two-fold. We provide (1) two gene ral benchmarks
with a diversity of real and synthetic Java bugs and (2) a moti vation to improve
bug localization capabilities of models through longer con text encodings. With
the introduction of BigIssue, we hope to advance the state of the art in bug local-
ization, in turn improving APR performance and increase its applicability to the
modern development cycle.
1 I NTRODUCTION
Recent advances in natural language processing (NLP) (Brow n et al., 2020; Devlin et al., 2018;
Liu et al., 2019b) have increased interest in applying NLP te chniques to code understanding. With
the development of code encoders (Feng et al., 2020a; Kanade et al., 2020), this task is becoming
increasingly more accessible and appealing. As research ha s jumped ahead into the task of Auto-
mated Program Repair (APR), the results have been not been ad equate. Although synthetic datasets
have largely been solved (see Section 2.1), models have been surprisingly underperforming on real-
world datasets, many not even able to repair a quarter of the b ugs in the Defects4J benchmark (see
Section 2.2 and Lutellier et al. (2020)). This is despite res earch suggesting that current APR bench-
marks suffer from a lack of diversity (Durieux et al., 2019). As a consequence, many APR models
are prone to overﬁtting to speciﬁc datasets (Mousavi et al., 2020). Although interesting from an
academic perspective, such tools would hardly be useful in a real industrial scenario.
We posit that the three major limitations to APR methods bein g used today are: (1) training to ﬁx
already located bugs rather than ﬁnding bugs and ﬁxing them, (2) the inability of models to take large
contexts into account, and (3) the reliance on information b esides pure code. The ﬁrst limitation is
straightforward: patches have limited context outside of t he lines immediately before and after each
patch. It has been shown that APR performance improves signi ﬁcantly if a good fault localization
algorithm is used to detect buggy code locations (Durieux et al., 2019; Liu et al., 2019a). The second
∗Equal Contribution
1

--- PAGE 2 ---
Published as a conference paper at ICLR 2023
limitation prevents models from ﬁnding bugs that depend on t he context of the program. Even for
human readers many real-world bugs require a lot of program- speciﬁc context to be detectable. One
of the most popular code encoders today (Feng et al., 2020a) o nly supports encoding of sequences
up to 512 tokens, not nearly enough to process most Java ﬁles i n real-world programs (on average
7.5k tokens with the RoBERTa tokenizer (Liu et al., 2019b)). The third limitation follows from the
fact that one of the most commonly bug localization methods, SBFL (Jones & Harrold, 2005), is
heavily reliant on test cases exposing potentially buggy lo cations.
In order to advance the state of the art of both BL (Bug Localiz ation) and APR (Automatic Program
Repair) models, we introduce BigIssue. The major contribut ions of BigIssue include:
• A large collection of conﬁrmed real-world bugs with line-l evel annotations. Each bug
has been reported by live users to the GitHub Issues bug-trac king system and ﬁxed via a
commit or pull request. The dataset contains a total of 10,905bugs sourced from 4,233
Java repositories.
• A long-sequence synthetic bug dataset. Perturbations in r eal code collected from GitHub
are generated by InCoder (Fried et al., 2022), a state-of-th e-art code generation model.
• An empirical demonstration of the hardness of the real benc hmark as compared to a syn-
thetic benchmark. Even with advanced synthetic bug generat ion techniques, the perfor-
mance on real bugs of models trained on synthetic data will no t be adequate, which calls
for further research into realistic bug detection.
By providing a large and diverse dataset of synthetic and rea l bugs from a multitude of projects
without any extra information outside of code, we hope to pus h the direction of research towards
line-level long-context bug localization for better perfo rmance on APR tasks.
2 P RIOR ART
2.1 A UTOMATIC PROGRAM REPAIR
Since bug localization is fundamentally related to automat ic program repair, we provide a brief
survey of existing APR benchmarks and their drawbacks.
Real-world Benchmarks The Defects4J dataset by Just et al. (2014) has been widely us ed in
automatic program repair. It consists of 357 (835 is version 2) bugs sourced from 10 (100) top
open-source Java projects. Bugs are manually reviewed and e ach bug has at least 1 test case that
exposes the bug. APR methods, however, are not successful en ough on Defects4J to suggest utility
in real-world applications. The most recent state of the art model can only ﬁx 67 out of 357 bugs
(Yuan et al., 2022), while the two previous state of the art mo dels could only ﬁx 44 (Lutellier et al.,
2020) and 57 (Jiang et al., 2021) bugs. This is despite recent research that suggests APR methods
are overperforming on Defects4J as compared to other simila r benchmarks (Durieux et al., 2019).
Bugs.jar (Saha et al., 2018) is a similar dataset but with an e xpanded scope of 8 popular projects
from the Apache foundation.
iBugs (Dallmeier & Zimmermann, 2007) presents a methodolog y of semi-automatic bug extraction
from repositories, and provides a concrete dataset of apply ing the methodology to the ASPECTJ
project. The method involves analyzing commit logs for sign s that indicate a bug ﬁx, extracting the
pre-commit and post-commit versions of the repositories, a nd identifying test cases that represent
the bug-ﬁx. However, this dataset is fairly small and is only sourced from one repository.
Another widely used dataset is the ManySStubs4J dataset (Karampatsis & Sutton, 2020). It’s a
collection of many “stupid" bugs mined from 100 (1,000) top o pen-source Java repositories. The
collection includes only those changes where the change is a single line of code and falls into one of
pre-determined 16 categories of bugs. While convenient, it suffers from a lack of complicated bugs
and highly selective criteria.
Learning-ﬁxes (Tufano et al., 2018) is a collection of about 58,350 short methods mined from
GitHub. Each of the methods was semantically idiomized and p resented in the benchmark. The
main limitation of this dataset is that it’s a method-level d ataset: each bug should be identiﬁable and
2

--- PAGE 3 ---
Published as a conference paper at ICLR 2023
ﬁxable based on the context only present in that particular m ethod. For real bugs, this is usually not
the case.
DLFix (Li et al., 2020) is another dataset aimed at APR tasks. The dataset consists of almost 5
million methods, enhanced with metadata, and the correspon ding ﬁxed versions of the method for a
particular repository. While interesting for limited case s, the method-level granularity as well as the
necessity of building metadata for each method limits its us efulness, especially on longer methods.
Table 1 presents a comparison of existing APR benchmarks.
Synthetic Benchmarks A natural way to deal with the lack of data diversity in curren t real-world
benchmarks is to create synthetic benchmarks by perturbing code. The simplest way to create code
perturbations is to apply rule-based perturbations to a cor pus of code (Kanade et al., 2020) or via
a static oracle (such as a linter) (Berabi et al., 2021). Othe r datasets are generated via a separate
perturbation model. SPoC (Kulal et al., 2019) uses a simple L STM to generate lines of code that
might be potentially buggy. DeepDebug (Drain et al., 2021) u ses a more complicated model trained
on reversed git commits to generate synthetic bugs. While at tractive, there is signiﬁcant evidence
that good performance on these benchmarks does not translat e to good performance on real-life
bugs (Durieux et al., 2019). We also perform experiments in S ection 5 that suggests that even good
performance on sophisticated perturbation datasets does n ot translate well to ﬁxing real bugs.
2.2 U SING EXISTING BENCHMARKS FOR BUGLOCALIZATION
Line-level fault localization and fault prediction on thei r own have been severely understudied.
While ﬁle-level localizations can achieve up to 70% top-5 ac curacy scores (Lam et al., 2017), line-
level localization methods aren’t as successful. Accordin g to a recent survey by Zou et al. (2019)
current fault localization and prediction methods can’t ev en localize half of the bugs in the Defects4J
(Just et al., 2014) dataset. The most widely used method for f ault localization is Spectrum-based
fault localization (SBFL) (Jones & Harrold, 2005). While el ementary and simple to implement, it
relies heavily on the quality and quantity of test cases, esp ecially for large programs (Keller et al.,
2017). Newer deep learning methods such as TRANSFER-FL (Men g et al., 2022) also can’t consis-
tently localize lines of buggy code (only 84/395 examples).
Dataset Size Granularity Bug Length Context # of Repos Filte rs
BigIssue 10,905 Line Multi-line Repo 4233 No
Defects4J(Just et al., 2014) 357 (835) Line Multi-line Repo 5 (17) No
Bugs.jar(Saha et al., 2018) 1158 Line Multi-line Repo 8 No
ManySStubs4J
(Karampatsis & Sutton,
2020)10,231
Line Single-line Repo100
Yes (63,923) (1000)
iBugs
(Dallmeier & Zimmermann,
2007)369 Line Multi-line Repo 1 No
Learning-Fixes
(Tufano et al., 2018)58,350 Line Multi-line Method - No
DLFix (Li et al., 2020) 4,973,000 Method Multi-line Repo 8 No
Table 1: Comparison of Major Java Bug Detection Datasets.
3 B IGISSUE SYNTHETIC DATASET
3.1 M OTIVATION
Evaluation of approaches towards bug localization require s the construction of a dataset with known
ground-truth bugs. One methodology to create such dataset i s to consider existing code and intro-
duce erroneous perturbations in the form of samples drawn fr om a generative model. In prior art
3

--- PAGE 4 ---
Published as a conference paper at ICLR 2023
Kulal et al. (2019), synthetic perturbations have been adop ted on a function-level granularity with
weak generative models such as small LSTMs. The underlying d istribution of such synthetic dataset
may be quite dissimilar to the distribution of realistic bug s, which occur in software engineering
(Durieux et al., 2019). To decrease this discrepancy, we wil l advance this concept to ﬁle-level data
and sample perturbations from a strong generative model.
Our synthetic dataset adopts the methodology of gathering “ real” code as observations and introduc-
ing synthetic perturbations in the observations. Here, the perturbation is a rewrite of the original
sequence of code into a perturbed sequence of code. In our app roach, a portion of the original code
is “masked out” and a generative model is recruited to “ﬁll in ” the masked out code. The “ﬁlled in”
portion of the code constitutes the synthetic perturbation . The perturbation of the original code is
assumed to likely to contain “errors”.
While the above approach based on perturbations may appear o bvious and trivial, the construction
of such datasets is challenging. This is due to the following conditions: (1) existing code is not
guaranteed to be free of errors, (2) the deﬁnition or ontolog y of an “error” or “bug” itself is non-
trivial, (3) the creation of synthetic perturbations that a re difﬁcult to discriminate from original
observations and yet reﬂect the distribution of “real” erro rs is hard.
Prior art addresses these issues by (1) reducing the scope of the code to function or line-level, effec-
tively reducing the span of code to nlines of code (Kanade et al., 2020; Yasunaga & Liang, 2020;
2021), (2) introducing heuristic perturbations rules or pr e-deﬁning a set of categories in which “bugs”
fall (Kanade et al., 2020; Drain et al., 2021), or (3) perturb ing a single line of code in simple pro-
grams (Yasunaga & Liang, 2020; Drain et al., 2021). While thi s over-simpliﬁcation is a reasonable
ﬁrst step, the resulting dataset may be quite different from realistic errors for which localization is
deemed “useful” to a practitioner.
Our work addresses (1) and (2) by doing away with the notion of an “error” and instead shifting the
conceptual thinking towards the distributions of “origina l” and “perturbed” observations. That is,
our dataset is assumed to contain errors which are not identi ﬁed in the ground-truth labels. The task
of error localization is relaxed as the task of localization of perturbations. This relaxation allows us
to consider ﬁle-level observations without the need for a st rict deﬁnition of an “error”. Such relaxed
deﬁnitions is suitable the construction of a “sanity-check " dataset to test a model’s capability of
detecting code divergent from standard coding practices. I n the following, we will provide details
on the creation of such dataset and in particular address (3) .
3.2 D ATASET CONSTRUCTION
The underlying methodology of the creation of this dataset i s (1) to gather large amounts of ﬁle-level
observations (i.e., real code), (2) to introduce synthetic perturbations from a strong generative model
such that discrimination of “original” and “perturbed” obs ervation is non-trivial, (3) and relax the
task of “error localization” to the task of “perturbation lo calization”. In this section, we describe the
construction of such a dataset.
Observations In order to obtain large quantities of observations for the l earning and evaluation of
localization models, the proposed dataset is a compilation of public, non-personal information from
GitHub consisting of permissively licensed Java code in Oct ober 2021. In particular, we gathered
8 million repositories between January 2014 and October 202 1 annotated with at least 1 star and
considered the subset of contained ﬁles containing Java cod e. The ﬁles must have an average length
of≤100characters and a maximum line length of 1,000. Files where ≥90% of the characters are
decimal or hexadecimal digits are also removed. Finally, ex act duplicates based on their SHA-256
hash are removed, which amounts to a substantial portion of t he raw data due to forks and copies of
repositories. The resulting dataset comprises 96.56 GB of r aw text.
Perturbations For realistic perturbations, we resort to a method known as “ inpainting” for images
or “inﬁlling” for the textual domain. That is, a portion of a g iving observation is occluded (or masked
out). Then, the occlusion is reconstructed or “ﬁlled in” by a sample drawn from a generative model
conditional on the non-occluded context. Recently, auto-r egressive causal language models, such as
Brown et al. (2020), have demonstrated to excel at this task f or which the prompt may be treated as
context and the auto-regressive sample conditional on the p rompt as the in-painting while preserving
4

--- PAGE 5 ---
Published as a conference paper at ICLR 2023
the statistical regularities of the training data. However , the joint distribution over tokens is usually
factorized in a left-to-right order over time, for which the causal mask constraints the inﬁll samples
to only take past context into account, but not future tokens . In our case of sampling realistic
perturbations at random spans within a given observation, w e wish to take both the code before and
after the masked out span into account for ﬁle-level consist ency. To address this issue, we recruit
an auto-regressive sampler that re-arranges the input sequ ence and associated causal masking such
that sampling is conditional on both past and future context (Du et al., 2022; Fried et al., 2022). To
further reduce the gap between “real” and “perturbed” seque nces, we chose a large-scale language
model, InCoder (Fried et al., 2022), with 1 billion paramete rs, and lowered the temperature of auto-
regressive nucleus sampling to 0.8. This temperature value was selected by manual experimenta tion.
Equipped with such a sampler, a random span in the observatio n is removed and inﬁlled with a
sample drawn from the InCoder model. The length of the span is drawn from a uniform distribution
with minimum length of 64tokens and maximum length of 128tokens. The generated sample is
constrained to at most the length of the span.
To further improve the quality of perturbations, we use reje ction sampling from the InCoder model
where drawn samples not satisfying the formal grammar of the programming language are rejected.
Speciﬁcally, we (1) reject any ﬁles which are not syntactica lly correct1, (2) reject ﬁles containing
less than 2,048tokens, (3) reject perturbations for which 10attempts of inﬁll sampling (with a
minimum span length of 64and a maximum number of tokens of 128) did not result in a syntactically
correct perturbation, (4) reject samples for which the Leve nshtein distance between the unperturbed
and perturbed sequence is smaller than 64tokens or larger than 192tokens.
Task Our proposed “perturbation localization” task can be expre ssed in the form of a binary classi-
ﬁcation for which each line is labeled as either “original” o r “perturbed”. As such, the ground-truth
labels indicate whether the line is a sub-sequence of the obs ervation or was (potentially partially)
perturbed by the sampler. Each ﬁle contains at most one such p erturbation. The length of the input
sequence is limited to at most 8,192tokens under the RoBERTa tokenizer (Liu et al., 2019b) with
at most512lines per ﬁle.
3.3 D ATASET EXAMPLES AND ARTIFACTS
Some samples from the synthetic dataset are presented in App endix E, and all artifact details can be
found in Appendix A.
4 B IGISSUE REALISTIC BENCHMARK
4.1 M OTIVATION
Based on our observations about existing benchmarks from Se ction 2, we concluded that a new
benchmark is needed to push the state of the art forward. Ther efore, we created a benchmark that
prioritized quantity over perceived quality and one that fo cused speciﬁcally on NL-based line-level
bug localization.
For this benchmark, we deﬁned a line as “buggy" if it has been r emoved or modiﬁed in the issue
patch. This allows us to avoid using tests as the ground truth for bugs in code. This deﬁnition
also ﬁts well with the usage of code encoders such as CodeBERT (Feng et al., 2020a) for line-level
classiﬁcation, as demonstrated in Section 5.
4.2 B ENCHMARK CONSTRUCTION
First, we considered Java GitHub repositories created betw een January 2014 and October 2021. In
order to ensure that we only ﬁlter out repositories that were intended for some form of public use,
we only examined repositories with at least 1 star. We furthe r ﬁltered down the repositories to only
those repositories that had GitHub Issues enabled and had li censes permitting use of their code (full
list of licenses is available in Appendix C). That gave us 4,233repositories.
1To verify syntactical correctness of Java programs, we use t he J AVALANG library:
https://github.com/c2nes/javalang .
5

--- PAGE 6 ---
Published as a conference paper at ICLR 2023
Using the GitHub API we ﬁltered through closed issues on thes e repositories. We only used public,
non-personal information available through the API. In ord er to select issues that corresponded to
bug ﬁxes on that particular repository, we selected issues t hat either contained “bug", “ﬁx", or “ﬁxed"
as separate words in the title and the body of the issue. We als o included issues that contained the
label “bug". We looked at issues with a corresponding “close " event, and we looked at the commit
that was attached to the latest "close" event. This gave us a d ataset of23,924total closed issues. We
further ﬁlter only those bugs that affect one Java ﬁle withou t test code. That yields 10,905bugs.
To verify the validity of our ﬁlters, we manually veriﬁed 100 sample issues. We manually veriﬁed
the validity of 84 of the issues. A detailed breakdown can be f ound in Appendix D.
Similarly to iBugs (Dallmeier & Zimmermann, 2007), to ident ify buggy lines we examine the data
from the hunks in the diff. If a line is (1) removed from the sou rce ﬁle and (2) is not an import line
(lines that begin with import ... ), it is marked as buggy. In cases where hunks are exclusively
adding code, we mark the two lines in the source before and aft er the change as buggy. Processing
added code is not always straightforward: sometimes the add ed chunk is an outsourced piece of
code from a different method. However, this simpliﬁcation o f the process was done to account for
added code while minimizing the potential impact of simply o utsourced chunks.
Test-running frameworks Many of the benchmarks presented above use tests either as as sistance
in bug ﬁxing or as a method of ﬁltering bugs. We do not consider testing frameworks and tests as
criteria for whether a commit is a bug or not. Firstly, it was r ecently shown that unit tests on their
own do not guarantee fewer failures inside the code (Chiotel i et al., 2021) which implies that there
are even more bugs inside the code that are not exposed by test s. Secondly, we would be severely
limiting the diversity and scope of our benchmark by forcing issues to include an exposing test case.
4.3 B ENCHMARK EXAMPLES AND ARTIFACTS
Some samples from the synthetic dataset are presented in App endix F, and all artifact details can be
found in Appendix A.
5 S YNTHETIC VS REALISTIC BUGDETECTION
In this Section, we conduct a preliminary analysis of the har dness of the BigIssues benchmark. Since
the sequence length exceeds the limitations of most pre-tra ined language models on code, we recruit
mean pooling to construct simple baselines. We hypothesize that although the realistic data is much
harder than the synthetic dataset, using long-context enco ders in addition to synthetic pre-training
will help increase performance.
5.1 H YPOTHESIS
The proposed BigIssue benchmark contains two variants: (1) synthetic rewrites of real code sampled
from a strong generative model, (2) realistic rewrites of re al code based on the commits associated
with a closed issue in GitHub.
Recall, for (1) a recent large language model was recruited a s a sampler which, compared to prior
art, not only is of signiﬁcant size under scaling laws, but fu rthermore alters the causal masking such
that future tokens can be taken into account as context. We ar gue that these synthetic rewrites are
non-trivial to detect compared to prior art.
However, our hypothesis is that localization of real bugs is still a signiﬁcantly harder task not solv-
able with elementary models and requires substantial resea rch to be solved. While local, trivial bugs
do not require context to be localized, harder non-local bug s can often only be resolved when taking
the entire ﬁle, a set of imported ﬁles, or the entire reposito ry into account. We use elementary mod-
els to show that (a) synthetic bugs are easier to detect than r eal bugs, and can serve as a sanity check
for bug localization models and (b) we use synthetic bugs to s how that longer-context encodings
improve performance on bug localization.
6

--- PAGE 7 ---
Published as a conference paper at ICLR 2023
5.2 M ODEL
Our architecture partitions a long input sequence of 8,192tokens into shorter sub-sequences, com-
putes contextualized vectors for each chunk using a bi-dire ctional encoder model, combines the
contextualized vectors into 512latent vectors with mean-pooling, and ﬁnally projects thos e vectors
to logits for line-level binary classiﬁcation.
Consider a sequence x= (x0,x1,...,x n)of input tokens with length n= 8,192. To address the is-
sue (2) of large n, we partition xintom= 16 equally sized chunks ˜xiwithi∈ {0,...,15}each con-
taining512tokens. To contextualize the embedding vector of the tokens , we recruit the pre-trained
bi-directional encoder f, (such as CodeBERT (Feng et al., 2020b)), and compute f(˜xi)for each par-
titioni. Then, the contextualized partitions are concatenated ˆx= (f(˜x0),f(˜x1),...,f(˜xm)). To
restore global position information, we apply additive sin usoidal positional embeddings to ˆx. A layer
of self-attention integrates the information across parti tion boundaries. Mean-pooling is applied to
ˆxwith a window length such that the resulting sequence of late nt vectors matches the maximum
number of 512lines. A standard linear projection maps each of the line-le vel latent vectors to logits
for binary classiﬁcation. The resulting model is ﬁne-tuned with binary cross entropy as the objective
function.
The appeal of the proposed model is to leverage the represent ations learned by a strong backbone
model and the simplicity in handling variable length includ ing line breaks in the input sequence.
CodeBERT has demonstrated strong empirical performance on downstream tasks so the learned
representations should be well suited for bug localization . To demonstrate the utility of long context
for code understanding, we also use the standard Longformer (Beltagy et al., 2020) as an encoder.
The mapping of contextualized vectors to latent vectors all ows for variable length input sequences
and avoids special treatment of newline characters. The ali gnment from lines of the input sequence
to latent vectors for classiﬁcation is implicitly learned b y supervision.
ModelRecall↑Precision↑F1↑
Synthetic Realistic Synthetic Realistic Synthetic Realis tic
Random 49.58 50.99 2.68 0.96 5.08 1.88
Pooling 93.48 69.43 8.89 2.16 16.24 4.17
Pooling-Attn 95.37 64.66 26.93 1.84 42.00 3.58
Table 2: Comparison of the binary classiﬁcation accuracy un der various baselines: (1) Random
Bernoulli classiﬁer with p= 0.5, (2) Mean pooling model, (3) Mean pooling model with self-
attention between latent vectors.
Model TrainingRecall↑Precision↑F1↑
Synth. Real. Synth. Real. Synth. Real.
Longformer-4096 Synthetic 98.49 42.98 22.62 3.74 36.79 6.88
Longformer-512 Synthetic 97.54 46.44 18.78 3.94 31.50 7.27
Longformer-4096 Real 73.28 75.40 5.92 2.65 10.96 5.12
Longformer-512 Real 81.28 88.68 5.95 2.46 11.09 4.79
Table 3: Comparison of Longformer Models. The numbers show t hat synthetic training is a suitable
proxy task for realistic bug detection compared to exclusiv ely realistic training and the advantages
of long-context on synthetic data.
5.3 F INDINGS
To evaluate the hardness of the artiﬁcal and realistic BigIs sue benchmark, the aforementioned model
is trained on both datasets. Training details can be found in Appendix B.
7

--- PAGE 8 ---
Published as a conference paper at ICLR 2023
Table 2 summarizes the binary classiﬁcation performance in terms of recall, precision and F1-score
for three baseline models with CodeBERT encoder: (1) A rando m classiﬁer for which the line-level
predictions are modeled as a Bernoulli random variable per l ine with probability p= 0.5, (2) a
mean-pooling based model for which the self-attention laye r between latent vectors is omitted, (3) a
mean-pooling based model including self-attention betwee n latent vectors.
For the synthetic dataset, the mean-pooling model includin g self-attention with an F1-score of 42.00
signiﬁcantly improves over the random Bernoulli baseline w ith5.08. Self-attention to integrate
information across latent vectors improves the score by nea rly26points, which may indicate that
attention across the partitioning of 512tokens is crucial. One may assume with further improvements
in modeling, the synthetic dataset is solvable.
For the realistic benchmark, however, both of the mean-pool ing baselines performed better than
random. The extra layer of attention did not add any improvem ent. Both models tend to have high
recall values, but precision is especially low for the reali stic benchmark.
To test the effect of longer-context encoders, we replaced t he encoder in our Mean-Pooling with
Attention model with a Longformer (Beltagy et al., 2020) tha t is capable of handling sequences up
to4096 tokens. Instead of chunking the sequence into 16 chunks of 512, we chunked it into 2 chunks
of4096 . We trained a Longformer-4096 token Mean-Pooling with Atte ntion model. We also trained
the same model solely on realistic data. The results after 50,000steps of training are presented in
Table 3. The results on synthetic data suggest that longer-c ontext encoders improve performance.
While the 512-chunked model performed better than the 4096- chunked model on realistic data, the
difference cannot be described as signiﬁcant due to low prec ision values.
As hypothesized, real bug detection is a much harder challen ge than synthetic data. Simple models
could not solve the realistic bugs with the same success as th e synthetic bugs, showing that synthetic
bugs are a suitable sanity check for bug localization models . The ﬁndings also suggest that using
longer contexts is effective for catching synthetic bugs. I t is our hope that this ﬁnding spurs research
toward the modeling of long contexts to approach the task of r eal bug detection.
6 C ONCLUSION
We propose a new realistic benchmark for line-level bug loca lization that does not rely on test suites.
We also provide a synthetic benchmark and dataset, generate d with more sophisticated methods
than previous work. We also show that despite the discrepanc y between synthetic and realistic bugs,
synthetic benchmarks can be used as a sanity check for bug loc alization models. Using the synthetic
dataset, we show that long-context encodings help in bug loc alization, and we hope that these results
push research into long-context for realistic bug localiza tion.
We hope that our contributions inspire and push future resea rch into realistic, long-context, NLP-
based bug localization techniques. Advances in this area wo uld bring automatic program repair to a
state that would be useful and transformative to the modern s oftware development process.
REFERENCES
Iz Beltagy, Matthew E Peters, and Arman Cohan. Longformer: T he long-document transformer.
arXiv preprint arXiv:2004.05150 , 2020.
Berkay Berabi, Jingxuan He, Veselin Raychev, and Martin Vec hev. Tﬁx: Learning to ﬁx coding
errors with a text-to-text transformer. In International Conference on Machine Learning , pp.
780–791. PMLR, 2021.
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jare d D Kaplan, Prafulla Dhariwal,
Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda As kell, et al. Language models are
few-shot learners. Advances in neural information processing systems , 33:1877–1901, 2020.
Efstathia Chioteli, Ioannis Batas, and Diomidis Spinellis . Does unit-tested code crash? a case study
of eclipse. In 25th Pan-Hellenic Conference on Informatics , pp. 260–264, 2021.
8

--- PAGE 9 ---
Published as a conference paper at ICLR 2023
Valentin Dallmeier and Thomas Zimmermann. Extraction of bu g localization benchmarks from
history. In Proceedings of the twenty-second IEEE/ACM international c onference on Automated
software engineering , pp. 433–436, 2007.
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Tout anova. Bert: Pre-training of deep
bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805 , 2018.
Dawn Drain, Colin B Clement, Guillermo Serrato, and Neel Sun daresan. Deepdebug: Fixing python
bugs using stack traces, backtranslation, and code skeleto ns.arXiv preprint arXiv:2105.09352 ,
2021.
Zhengxiao Du, Yujie Qian, Xiao Liu, Ming Ding, Jiezhong Qiu, Zhilin Yang, and Jie Tang. Glm:
General language model pretraining with autoregressive bl ank inﬁlling. In Proceedings of the
60th Annual Meeting of the Association for Computational Li nguistics (Volume 1: Long Papers) ,
pp. 320–335, 2022.
Thomas Durieux, Fernanda Madeiral, Matias Martinez, and Ru i Abreu. Empirical review of java
program repair tools: A large-scale experiment on 2,141 bug s and 23,551 repair attempts. In
Proceedings of the 2019 27th ACM Joint Meeting on European So ftware Engineering Conference
and Symposium on the Foundations of Software Engineering , pp. 302–313, 2019.
Zhangyin Feng, Daya Guo, Duyu Tang, Nan Duan, Xiaocheng Feng , Ming Gong, Linjun Shou, Bing
Qin, Ting Liu, Daxin Jiang, et al. Codebert: A pre-trained mo del for programming and natural
languages. arXiv preprint arXiv:2002.08155 , 2020a.
Zhangyin Feng, Daya Guo, Duyu Tang, Nan Duan, Xiaocheng Feng , Ming Gong, Linjun Shou, Bing
Qin, Ting Liu, Daxin Jiang, et al. Codebert: A pre-trained mo del for programming and natural
languages. arXiv preprint arXiv:2002.08155 , 2020b.
Daniel Fried, Armen Aghajanyan, Jessy Lin, Sida Wang, Eric W allace, Freda Shi, Ruiqi Zhong,
Wen-tau Yih, Luke Zettlemoyer, and Mike Lewis. Incoder: A ge nerative model for code inﬁlling
and synthesis. arXiv preprint arXiv:2204.05999 , 2022.
Nan Jiang, Thibaud Lutellier, and Lin Tan. Cure: Code-aware neural machine translation for auto-
matic program repair. In 2021 IEEE/ACM 43rd International Conference on Software En gineer-
ing (ICSE) , pp. 1161–1173. IEEE, 2021.
James A Jones and Mary Jean Harrold. Empirical evaluation of the tarantula automatic fault-
localization technique. In Proceedings of the 20th IEEE/ACM international Conference on Auto-
mated software engineering , pp. 273–282, 2005.
René Just, Darioush Jalali, and Michael D Ernst. Defects4j: A database of existing faults to enable
controlled testing studies for java programs. In Proceedings of the 2014 International Symposium
on Software Testing and Analysis , pp. 437–440, 2014.
Aditya Kanade, Petros Maniatis, Gogul Balakrishnan, and Ke nsen Shi. Learning and evaluating
contextual embedding of source code. In International Conference on Machine Learning , pp.
5110–5121. PMLR, 2020.
Rafael-Michael Karampatsis and Charles Sutton. How often d o single-statement bugs occur? the
manysstubs4j dataset. In Proceedings of the 17th International Conference on Mining Software
Repositories , pp. 573–577, 2020.
Fabian Keller, Lars Grunske, Simon Heiden, Antonio Filieri , Andre van Hoorn, and David Lo. A
critical evaluation of spectrum-based fault localization techniques on a large-scale software sys-
tem. In 2017 IEEE International Conference on Software Quality, Re liability and Security (QRS) ,
pp. 114–125. IEEE, 2017.
Sumith Kulal, Panupong Pasupat, Kartik Chandra, Mina Lee, O ded Padon, Alex Aiken, and Percy S
Liang. Spoc: Search-based pseudocode to code. Advances in Neural Information Processing
Systems , 32, 2019.
9

--- PAGE 10 ---
Published as a conference paper at ICLR 2023
An Ngoc Lam, Anh Tuan Nguyen, Hoan Anh Nguyen, and Tien N Nguye n. Bug localization with
combination of deep learning and information retrieval. In 2017 IEEE/ACM 25th International
Conference on Program Comprehension (ICPC) , pp. 218–229. IEEE, 2017.
Yi Li, Shaohua Wang, and Tien N Nguyen. Dlﬁx: Context-based c ode transformation learning for
automated program repair. In Proceedings of the ACM/IEEE 42nd International Conference on
Software Engineering , pp. 602–614, 2020.
Kui Liu, Anil Koyuncu, Tegawendé F Bissyandé, Dongsun Kim, J acques Klein, and Yves Le Traon.
You cannot ﬁx what you cannot ﬁnd! an investigation of fault l ocalization bias in benchmarking
automated program repair systems. In 2019 12th IEEE conference on software testing, validation
and veriﬁcation (ICST) , pp. 102–113. IEEE, 2019a.
Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike
Lewis, Luke Zettlemoyer, and Veselin Stoyanov. Roberta: A r obustly optimized bert pretraining
approach. arXiv preprint arXiv:1907.11692 , 2019b.
Ilya Loshchilov and Frank Hutter. Decoupled weight decay re gularization. arXiv preprint
arXiv:1711.05101 , 2017.
Thibaud Lutellier, Hung Viet Pham, Lawrence Pang, Yitong Li , Moshi Wei, and Lin Tan. Coconut:
combining context-aware neural translation models using e nsemble for program repair. In Pro-
ceedings of the 29th ACM SIGSOFT international symposium on software testing and analysis ,
pp. 101–114, 2020.
Xiangxin Meng, Xu Wang, Hongyu Zhang, Hailong Sun, and Xudon g Liu. Improving fault localiza-
tion and program repair with deep semantic features and tran sferred knowledge. In Proceedings
of the 44th International Conference on Software Engineeri ng, pp. 1169–1180, 2022.
S Amirhossein Mousavi, Donya Azizi Babani, and Francesco Fl ammini. Obstacles in fully auto-
matic program repair: A survey. arXiv preprint arXiv:2011.02714 , 2020.
Ripon K Saha, Yingjun Lyu, Wing Lam, Hiroaki Yoshida, and Muk ul R Prasad. Bugs. jar: a large-
scale, diverse dataset of real-world java bugs. In Proceedings of the 15th international conference
on mining software repositories , pp. 10–13, 2018.
Michele Tufano, Cody Watson, Gabriele Bavota, Massimilian o Di Penta, Martin White, and Denys
Poshyvanyk. An empirical investigation into learning bug- ﬁxing patches in the wild via neural
machine translation. In Proceedings of the 33rd ACM/IEEE International Conference on Auto-
mated Software Engineering , pp. 832–837, 2018.
Michihiro Yasunaga and Percy Liang. Graph-based, self-sup ervised program repair from diagnostic
feedback. In International Conference on Machine Learning , pp. 10799–10808. PMLR, 2020.
Michihiro Yasunaga and Percy Liang. Break-it-ﬁx-it: Unsup ervised learning for program repair. In
International Conference on Machine Learning , pp. 11941–11952. PMLR, 2021.
Wei Yuan, Quanjun Zhang, Tieke He, Chunrong Fang, Nguyen Quo c Viet Hung, Xiaodong Hao,
and Hongzhi Yin. Circle: Continual repair across programmi ng languages. arXiv preprint
arXiv:2205.10956 , 2022.
Daming Zou, Jingjing Liang, Yingfei Xiong, Michael D Ernst, and Lu Zhang. An empirical study of
fault localization families and their combinations. IEEE Transactions on Software Engineering ,
47(2):332–347, 2019.
10

--- PAGE 11 ---
Published as a conference paper at ICLR 2023
A D ATA DESCRIPTION , HOSTING DETAILS ,AND DATA ACCESS
We publish the training, evaluation, and validation sets fo r the synthetic data. We also publish
the realistic benchmark. These items can be accessed in a Goo gle Cloud Storage bucket at
https://console.cloud.google.com/storage/browser/bi gissue-research .
All materials are released under the MIT License.
Realistic Pre-training data For the realistic Pooling and Pooling-Attention models, we created
a pre-training dataset similar to other projects. We select Java GitHub repositories with 5 stars or
more, we clone the main branch of the repository, while only d ownloading ﬁles under 2 megabytes.
We then ﬁlter the commits that include the words "error", "bu g", "ﬁx", "issue", "mistake", "in-
correct", "fault", "defect", "ﬂaw", or "type", using stand ard practice in ManySStubs4J project
Karampatsis & Sutton (2020) . Since our models are designed o nly for single-ﬁle bug localization,
we take each modiﬁed ﬁle and apply the labeling procedure des cribed in the paper to generate the
examples and labels. We truncate ﬁles at 8192 tokens in the sa me manner as in Feng et al. (2020a).
In total, we get about 195 GB of data to use for pre-training.
B T RAINING DETAILS
We train all of our models on a single pod with 16 A100 GPUs. For models with the CodeBERT
encoder, we optimized the model with a linear schedule AdamW Loshchilov & Hutter (2017) opti-
mizer, with a starting learning rate of 5e-5, and 10,000warmup steps. We train over 50,000 steps
with a batch size of 8. For models with the Longformer encoder , we optimized with a linear schedule
AdamW optimizer, starting learning rate of 3e-5, and 1000 warmup steps.
We provide the full training code at https://anonymous.4open.science/r/BigIssue-8EE2/ .
Model Checkpoints We provide the model checkpoints for the Pooling and
Pooling-Attention models trained on realistic data in the G itHub repository
https://anonymous.4open.science/r/BigIssue-8EE2/ .
C D ATA COLLECTION ETHICAL STATEMENT
We did not collect any personal information from the GitHub A PI. We only collect commit informa-
tion and data inside the commits, without taking into the acc ount the origin or the user proﬁle of the
user making the changes.
We also present here the list of licences that we use in our pap er:
https://anonymous.4open.science/r/BigIssue-8EE2/lic ences.txt
D R EALISTIC BUGANALYSIS
We’ve analyzed the quality of our selection process by sampl ing 100 random issues. This will
allow other researchers to use this method with greater ﬂexi bility in licensing. We analyzed them
based on three criteria: (a) whether the issue represents a v alid bug (b) whether the ﬁx represents a
valid ﬁx for the bug and (c) whether the ﬁx depends on code conv entions or APIs, and is therefore
identiﬁable by a human with adequate knowledge of the above. The last criteria is to ensure possible
identiﬁability by a model: if a bug is only marked as such beca use of outside software criteria, there
is no reasonable way a model can learn that bug pattern.
In total, we have collected:
• 84 valid issues.
• 3 issues that did not represent valid bugs.
• 3 issues were the ﬁxes did not ﬁx the bugs.
• 2 issues that were not subject to analysis.
11

--- PAGE 12 ---
Published as a conference paper at ICLR 2023
• 8 issues that are not identiﬁable without outside context.
Each item in the following list represents an issue consider ed for our dataset and is identiﬁed by the
corresponding link to the github issue. We precede invalid i ssues with "*" for clarity.
1. * -https://github.com/gsantner/markor/issues/314 - Valid bug, but the
ﬁx doesnâ ˘A´Zt address the issue. In fact the issue persists despite the i ssue being closed.
2.https://github.com/ReplayMod/ReplayMod/issues/422 - Valid bug,
valid ﬁx for the bug, bug is identiﬁable through similar usag e of code around the buggy
area.
3.https://github.com/lingochamp/FileDownloader/issues /855 - Valid
bug, valid one-line ﬁx for the ﬁle, bug is identiﬁable becaus e ‘model.status‘ is being set in
almost all action methods of this class.
4.https://github.com/danielCantwell/Fit-Friend/issues /3 - Valid
bug, valid ﬁx. Bug is identiﬁable by the fact that the variabl es used in that particular area
of code are not used at all.
5.https://github.com/OpenJEVis/JEVis/issues/1699 - Valid bug, valid ﬁx.
Bug is an edge case if the JEVis samples are not sampled at a reg ular interval. Bug is
identiﬁable because of similarities in time-series intera ctions.
6.https://github.com/TechReborn/TechReborn/issues/549 - Valid bug,
valid ﬁx. Bug is identiﬁable because (a) a lot of values are ha rd-coded and (b) some of
the variables did not follow the human logic of what a minecra ft â˘AIJoperatorâ ˘A˙I is sup-
posed to do (e.g. not checking if there is any space in the outp ut container for more items
to go to).
7.https://github.com/milaboratory/mixcr/issues/509 - Valid bug, valid
ﬁx, although there are extraneous style ﬁxes. The style ﬁx is that whenever the â ˘AIJper-
centageâ ˘A˙I is being used, the text for the log must be written as â ˘AIJpercent used â ˘A˛ eâ˘A˙I.
This follows a pattern from other places in this repository. The bug is that the percentages
can sometimes be over 100
8. * -https://github.com/Angry-Pixel/The-Betweenlands/iss ues/895
- Valid bug, and valid ﬁx, but the bug is not generally identiﬁ able by humans without ex-
ternal context. The minecraft bug suggests that a certain it em has to be not repairable, but
from the code alone there seems to be no suggestion that this i tem should be unrepairable.
9.https://github.com/VazkiiMods/Quark/issues/2920 - Valid bug, valid
ﬁx. Identiﬁable by humans if they have knowledge and context about the Create library
that cannot accept FakePlayers as players when performing operations on the world.
10.https://github.com/15knots/cmake4eclipse/issues/26 - Valid bug,
valid ﬁx. The essence of the bug is that certain build directo ries might be deleted out-
side of Eclipse, and that needs to be handled by the code, whic h is a common safeguard
that code needs to implement.
11.https://github.com/TheThirdOne/JSoftFloat/issues/1 - Valid bug,
valid ﬁx. This bug should be identiﬁable with knowledge of ﬂo ating-point arithmetic cal-
culations.
12.https://github.com/ververica/flink-cdc-connectors/i ssues/326
- Valid bug, valid ﬁx. To identify this bug, one must need to kn ow that a certain parameter
in the conﬁg can be null. In particular, if there is no pre-deﬁ ned database history ID, one
must be set.
13.https://github.com/spring-cloud/spring-cloud-sleuth /issues/333
- Valid bug, valid ﬁx. Bug is identﬁable based on existing usa ge from other Callable
services, where the class is frequently used as a wrapper for calls.
14.https://github.com/tango-controls/rest-server/issue s/192 -
Valid bug, valid ﬁx. Identiﬁable with knowledge of the TANGO API speciﬁcation.
15.https://github.com/guillaume-alvarez/ShapeOfThingsT hatWere/issues/7
- Valid bug, valid ﬁx. The issue is that the camera movement lo gic is tied to frame-
processing, and if that pattern is known then the bug is ident iﬁable.
12

--- PAGE 13 ---
Published as a conference paper at ICLR 2023
16.https://github.com/spring-cloud/spring-cloud-config /issues/128
- Valid bug, valid ﬁx. Bug identiﬁable by common environment loading patterns.
17.https://github.com/BentoBoxWorld/TwerkingForTrees/i ssues/9 -
Valid bug, valid ﬁx. Identiﬁable by minecraft logic of not al lowing players to modify
blocks outside of world border.
18.https://github.com/requery/requery/issues/63
- Valid bug, valid ﬁx: known issue in SQLite
https://stackoverflow.com/questions/28385069/sqlite openhelper-setwriteaheadloggingenabled-causes-an-er ror-log-line .
19. * -https://github.com/mpcjanssen/ubiquitous-capture/is sues/4 -
Valid bug, valid ﬁx. Not idenﬁtiable because this is fundame ntally a UX bug.
20.https://github.com/assertj/assertj-vavr/issues/141 - Valid bug,
valid ﬁx. Identiﬁable based on other patterns in the same rep ository.
21.https://github.com/smartdevicelink/sdl_java_suite/i ssues/53 -
Valid issue, valid ﬁx. Identiﬁable through other similar pa tterns in similar code in the
repository.
22.https://github.com/darcy-framework/darcy-webdriver/ issues/30
- Valid bug, valid ﬁx. Identiﬁable through other similar pat terns in similar code in the
repository.
23. * -https://github.com/AlexFalappa/nb-springboot/issues /167 -
Valid bug, valid ﬁx. Not identiﬁable.
24.https://github.com/GabrielOlvH/Carrier/issues/2 - Valid issue, ﬁx
not permanent, but does indeed correctly point to the locati on of the problem. The problem,
broadly speaking, is caused by the fact that the Wolf entity i s different from all of the other
entities, and therefore calling updateHolding method on it will cause issues.
25.https://github.com/AgriCraft/AgriCraft/issues/82 - Valid issue,
valid ﬁx. Itâ ˘A´Zs logic that is identiﬁable by humans by looking at the varia ble names and
intended usage.
26.https://github.com/rasmus-saks/aken-ajalukku/issues /65 - Valid
issue, valid ﬁx. Identiﬁable based on the context of the appl ication, the fact that this is ac-
tually a â ˘AIJwalking tourâ ˘A˙I, therefore the mode on google maps should be for â ˘AIJwalk-
ingâ ˘A˙I rather than driving.
27.https://github.com/CJMinecraft01/DoubleSlabs/issues /81 - Valid
issue, valid ﬁx. Fix is identiﬁable in principle, but a lot of context about how minecraft
slabs interact is needed.
28.https://github.com/hzi-braunschweig/SORMAS-Project/ issues/6832
- Valid issue, valid ﬁx. Bug is identiﬁable, the start date is replaced with Enddate in some
cases on records.
29.https://github.com/MachinePublishers/jBrowserDriver /issues/67
- Valid issue, valid ﬁx. The bug is identiﬁable in the long con text and with knowledge of
the general cookie-creation pattern. The problem is that th e domain for the cookie is not
set, so itâ ˘A´Zs not being used by the web-driver on repeat visits to a websi te.
30.https://github.com/release-engineering/pom-manipula tion-ext/issues/240
- Valid issue, valid ﬁx. This one just ﬁxes an NPE, but it does c ontain a lot of style/whites-
pace changes.
31.https://github.com/Angry-Pixel/The-Betweenlands/iss ues/948 -
Valid bug, valid ﬁx. This one is in principle identiﬁable wit h knowledge of the pattern in
minecraft servers to have different types of blocks that con stitute a single â ˘AIJentityâ ˘A˙I (a
door in this case).
32.https://github.com/ehcache/ehcache3/issues/2638 - Valid bug, valid
ﬁx. Bug is straightforward and identiﬁable.
13

--- PAGE 14 ---
Published as a conference paper at ICLR 2023
33.https://github.com/thingsboard/thingsboard/issues/3 992 - Valid
bug, valid ﬁx. The essence is that the method getDeviceTypes should call the â ˘AIJ/de-
vices/typesâ ˘A˙I api endpoint rather than â ˘AIJ/devicesâ ˘A˙I. Should be identiﬁable based on
semantic context.
34.https://github.com/vert-x3/vertx-config/issues/20 - Valid bug,
valid ﬁx. The bug is easily identiﬁable because (a) Vertx is o ften used in code, and (b)
the â ˘AIJhostâ ˘A˙I variable is left unused despite being declared, and there i s only one logical
place where it can be potentially used.
35.https://github.com/metarhia/jstp-java/issues/24 - Valid bug, valid
ﬁx. The bug is identiﬁable given context about the ExecutionHandler class.
36. * -https://github.com/Cassiobsk8/Industrial_Renewal/is sues/126
- Valid bug, valid ﬁx. This bug is difﬁchttps://www.overlea f.com/project/63e2c9d0daa4bbc401a23fbault
to identify because (a) the ﬁx is to override a particular met hod of the class and (b) itâ ˘A´Zs
not obvious that there can be an obstruction with bunk beds..
37.https://github.com/Tamaized/AoV/issues/13 - Valid bug, valid ﬁx. Con-
tains some whitespace additions in addition to bug ﬁx. Bug re lated to a certain conﬁg
option not being used, itâ ˘A´Zs identiﬁable through semantic understanding of the code.
38. * -https://github.com/PyvesB/advanced-achievements/iss ues/172
- Valid bug, valid ﬁx. The bug is hard to identify, because it r equires context about brewing
stand operations.
39.https://github.com/eclipse/vorto/issues/442 - Valid bug, valid ﬁx. The
issue is identiﬁable by the fact that resource id is hardcode d to â ˘AIJ0â ˘A˙I rather than the
â˘AIJresourceIdâ ˘A˙I variable provided. Also semantically identiﬁable. Conta ins whitespace
changes as well.
40.https://github.com/hsyyid/AdminShop/issues/5 - Valid bug, valid ﬁx.
Identiﬁable bug.
41. * -https://github.com/labhackercd/edm/issues/5 - Valid bug, un-
sure if valid ﬁx. The bug has little information, and the cras h that the bug
reports does not seem to be identiﬁable from the code alone (m aybe itâ ˘A´Zs device-
dependent, but the pattern used that is considered buggy is w idely recommended, see
https://stackoverflow.com/questions/2422562/how-to- change-theme-for-alertdialog) .
42.https://github.com/Haptic-Apps/Slide/issues/655 - Valid bug, valid
ﬁx. A run-time exception from a method should be catched.
43. * -https://github.com/PortuguesDoSeculoXXI/PortuguesDo SeculoXXI/issues/48
- Unsure, hard to ascertain, there is a lot of text in portugue se
44.https://github.com/OpenJEVis/JEVis/issues/840 - Valid bug, valid ﬁx.
Although the text is in German, the bug is about processing a l ist of items into a menu
rather than just one. This is not a new â ˘AIJfeatureâ ˘A˙I, since the items to be processed were
always packaged in a variable-length â ˘AIJlistâ ˘A˙I.
45.https://github.com/commons-app/apps-android-commons /issues/587
- Valid bug, valid ﬁx. Links need to be sanitized.
46.https://github.com/twizmwazin/CardinalPGM/issues/86 - Valid bug,
valid ﬁx. A map cycle schedule was only set when time was under 5 seconds, so the
scheduling needed to be moved out of that particular if state ment.
47. * -https://github.com/assemblits/eru/issues/100 - Not a valid bug.
The change is just a change to the title of an alert to set it to a class name rather than a
generic â ˘AIJconnection failureâ ˘A˙I message.
48.https://github.com/MachinePublishers/jBrowserDriver /issues/21
- Valid bug, valid ﬁx. The issue is that cookies come in a lot of formats, and not all of them
were supported by jBrowser.
49.https://github.com/lucas-tulio/server-simulator/iss ues/6 - The
bug is valid, ﬁx invalid.
14

--- PAGE 15 ---
Published as a conference paper at ICLR 2023
50.https://github.com/spring-cloud/spring-cloud-netfli x/issues/1724
- Valid bug, valid ﬁx. The property for preferIPAddress was not taken into account.
The conﬁg is needed to be able to identify this issue.
51.https://github.com/Col-E/Recaf/issues/344 - Valid bug, valid ﬁx. The
previous version replaced all $in a class name with ., but only the last one needs to be
replaced by convention.
52.https://github.com/plan-player-analytics/Plan/issue s/1313 -
Valid bug, valid ﬁx. The front-end called the wrong endpoint , and the backend was
adjusted so that the front-end was calling the correct endpo int to get a list of players for a
server.
53. * -https://github.com/cabaletta/baritone/issues/330 - Not really a
bug, more like an extra feature. Also has the â ˘AIJenhancementâ ˘A˙I tag.
54.https://github.com/sosy-lab/java-common-lib/issues/ 19 - Valid
bug, valid ﬁx. The problem was that one of the iterators in a me thod that returned sorted
list of two collections wasnâ ˘A´Zt fully exhausted.
55.https://github.com/Cactiw/Timetable/issues/4 - Valid bug, valid ﬁx.
The issue was that an update task wasnâ ˘A´Zt put into an async call, and therefore caused
issues downstream. Putting it in async ﬁxes the issue.
56.https://github.com/jooby-project/jooby/issues/1489 - Valid bug,
valid ﬁx. Pretty easily identiﬁable that the factory is clos ed rather than the session that
was just checked in the surrounding if statement.
57.https://github.com/Gaming32/ArrayV-v4.0/issues/43 - Valid bug,
valid ﬁx. Method that obviously should have been synchronized based on surrounding
code wasn’t synchronized .
58.https://github.com/Zedd7/ZHorse/issues/25 - Valid bug, valid ﬁx. The
duplicate horse is not assigned a name, so when â ˘AIJdeletingâ ˘A˙I it the message should
display the original horsesâ ˘A´Zs name.
59.https://github.com/neo4j-contrib/neo4j-apoc-procedu res/issues/303
- Valid bug, valid ﬁx. The issue is that two nodes cannot have t he same â ˘AIJmain keyâ ˘A˙I,
and when merging two nodes the previous node was not deleted t herefore causing an
exception. The solution is that the properties of the source node should be stored, the
source node deleted, and then the properties of the source no de have to loaded into the
target node from the stored variable.
60.https://github.com/mikepenz/CrossfadeDrawerLayout/i ssues/15 -
Valid bug, valid ﬁx. The bug is that when opening/closing the drawer, the state is not neces-
sarily updated. The ﬁx is to override the appropriate method s to update state. Identiﬁable
by the common pattern of state updates when calling certain p arent class methods.
61.https://github.com/wultra/powerauth-webflow/issues/ 345 - Valid
bug, valid ﬁx. The issue is that the message of the logger wasn â˘A´Zt aligned with the
exception being caught. There are also some whitespace chan ges added in the commit.
62.https://github.com/TeamLapen/Vampirism/issues/333 - Valid bug,
valid ﬁx. Off-by-one error, identiﬁable by knowing about mi necraft item stacks as well
as generally looking around the code.
63.https://github.com/home-climate-control/dz/issues/1 44 - Valid
bug, valid ﬁx. Authentication parameters passed to the bean were not actually set when
creating the bean. Bug is identiﬁable.
64.https://github.com/kontalk/androidclient/issues/126 4- Valid bug,
valid ﬁx. The problem is that the push notiﬁcation service wo uld not be started as a fore-
ground service and the system would kill it after 15 seconds. The ﬁx is to start it in the
foreground before. Identiﬁable because this is a common pat tern in messaging applica-
tions.
65.https://github.com/BetonQuest/BetonQuest/issues/734 - Valid bug,
valid ﬁx. The problem is that the method used previously to de tect entity deaths in
15

--- PAGE 16 ---
Published as a conference paper at ICLR 2023
Minecraft was sub-optimal, and it was replaced by a better me thod that was seen in a
different minecraft plugin. Identiﬁable with knowledge of the spigot library usage patterns.
66.https://github.com/jmockit/jmockit1/issues/98 - Valid bug, valid ﬁx.
The problem is that sometimes types that should be null are not mocked as null objects.
The ﬁx addresses these cases with cascading types. Bug is ide ntiﬁable with knowledge
mocking patterns.
67. * -https://github.com/Freeyourgadget/Gadgetbridge/issu es/529 -
Invalid issue that has been deleted.
68.https://github.com/scenerygraphics/sciview/issues/1 81 - Valid
bug, valid ﬁx. One needs to call setSize on the panel before displaying it, and the ﬁx
addresses that.
69.https://github.com/ramack/ActivityDiary/issues/153 - Valid bug,
valid ﬁx. Identiﬁable through app context.
70.https://github.com/decarbonization/android-fonz/iss ues/26 -
Valid bug, valid ﬁx. Type mismatch in settings crashed the ap p. Identiﬁable from android
property conventions.
71.https://github.com/ICIJ/datashare/issues/41 - Valid bug, valid ﬁx. Fix
the ISO code representations of languages by a) adding more e nums and b) using both iso1
and iso2 codes to identify a language. Should be easily ident iﬁable since both iso1 and iso2
parameters are passed in.
72.https://github.com/twizmwazin/CardinalPGM/issues/64 5- Valid bug,
valid ﬁx. The ﬁx is to use a more high-level API provided by the library in question, and
simplify the existing code dramatically and add support for detecting TNT damage and
account for points. Should be identiﬁable given the whole li brary context.
73. * -https://github.com/manoelcampos/cloudsimplus/issues /368 -
Valid bug, valid ﬁx. This is an issue that would be hard to iden tify since itâ ˘A´Zs conﬁg-
uration/resource usage based, and depends on system parame ters a lot.
74. * -https://github.com/almosr/android-svg-code-render/i ssues/67
- Valid bug, valid ﬁx. Not identiﬁable due to the bug being in t emplating.
75.https://github.com/dcm4che/dcm4chee-arc-light/issue s/523 -
Valid bug, valid ﬁx. When a study is deleted, the number of stu dies that patients of this
study participated in has to be decreased. Identiﬁable with understanding of relationship
between patients and studies.
76. * -https://github.com/BCA-Team/Buildcraft-Additions/is sues/356
- Valid bug, valid ﬁx. Minecraft lasers ﬁred underwater get s tuck. The ﬁx implements the
logic of dissipating the laser once it hits lava or water. Not identiﬁable without knowing
in-app logic about lasers and expected behavior upon hittin g water or lava.
77.https://github.com/TotalHamman/BetterBlockExchanger /issues/7
- Valid bug, valid ﬁx. The app was reading state from the â ˘AIJpreviousâ ˘A˙I state during a
swap rather than the â ˘AIJcurrentâ ˘A˙I state, causing an NPE.
78.https://github.com/BasicAirData/GPSLogger/issues/13 2- Valid bug,
valid ﬁx. The contents of a variable on which a switch was cond itioned could be potentially
null, and that caused an NPE.
79.https://github.com/OfficeDev/ews-java-api/issues/8 - Valid bug,
valid ﬁx. The bug is identiﬁable by the fact that there is an us ed variable, and the only
place where it can be reasonably used is in a method override o f a method inherited from
the parent class.
80.https://github.com/dcm4che/dcm4chee-arc-light/issue s/1180 -
Valid bug, valid ﬁx. The problem is that the program assigns t he â ˘AIJtypeâ ˘A˙I of a
SOP instance not according to the DICOM speciﬁcation. Knowl edge of the DICOM
speciﬁcation is necessary to identify the bug.
81.https://github.com/LMBishop/Quests/issues/281 - Valid bug, valid ﬁx.
The problem is that player quests are not restored to the play er object once the player
joined the server. Identiﬁable with common quest/server pa tterns.
16

--- PAGE 17 ---
Published as a conference paper at ICLR 2023
82. * -https://github.com/danielricci/solitaire/issues/90 - Valid bug,
invalid ﬁxes.
83.https://github.com/hv0905/SchoolStoryCollection/iss ues/2 -
Valid bug, valid ﬁx, identiﬁable by human.
84.https://github.com/davidcorbin/mygcc-api/issues/21 - Valid bug,
valid ﬁx. The issue is that when processing an image the code s earches for the last oc-
currence of â ˘AIJ.jpgâ ˘A˙I, but this cannot be found and throws an error if the image URL is
uppercase.
85.https://github.com/Tamaized/AoV/issues/104 - Valid bug, valid ﬁx. The
issue is that a player can just hop in and out of bed to recharge certain abilities, but in reality
they need to fully sleep in the bed for that. Identiﬁable bug b ecause this is a common pattern
(you need to actually sleep ) in many minecraft games.
86.https://github.com/Electroblob77/Wizardry/issues/51 3- Valid bug,
valid ﬁx. The ﬁx consists of using the stream and ﬁlter apis to avoid removing items
from a list that can be concurrently modiﬁed. Identiﬁable wi th knowledge of concurrency
mechanisms.
87.https://github.com/tsandmann/ct-sim/issues/62 - Valid bug (because
the code does not correspond to the documentation comments) , valid ﬁx. Interestingly
the documentation is in German.
88.https://github.com/voxelwind/voxelwind/issues/33 - Valid bug, valid
ﬁx. The problem is that the project implements a server for Mi necraft: Pocket Edition,
and it doesnâ ˘A´Zt fully comply with the API contract, in particular with res pect to the yaw
parameters that clients pass in. Identiﬁable with knowledg e of the API.
89.https://github.com/phrack/ShootOFF/issues/651 - Valid bug, valid ﬁx.
Wrong class was used to test if a shot color matched certain co nstants. Identiﬁable.
90. * -https://github.com/rmichela/GiantTrees/issues/31 - Not really a
bug, this just implements mechanisms that silence warnings if certain resource ﬁles do not
exist.
91.https://github.com/sriharshachilakapati/SilenceEngi ne/issues/38
- Valid bug, valid ﬁx. If the vertices for a certain polygon ar e cleared, some parameters are
set to maximum and minimum inﬁnity, and some downstream meth ods throw errors. Fix
is modiﬁcation of these methods to account for cases when ver tices are 0.
92.https://github.com/lsfusion/platform/issues/164 - Valid bug, valid
ﬁx. The method would not account for ftp ﬁles that did not exis t, and the modiﬁcation
allows the method to handle non-existent ftp ﬁles as well.
93.https://github.com/spring-cloud/spring-cloud-sleuth /issues/1816
- Valid bug, valid ﬁx. The sleuth library was interfering wit h openfeignâ ˘A´Zs circuitbreaker
capabilities, the ﬁx was to conditionally create the feign b ean only if circuitbreaker was
disabled. Identiﬁable by humans.
94.https://github.com/vinaygaba/CreditCardView/issues/ 13 - Valid
bug, valid ﬁx. The issue is that the setter methods did not mod ify the actual state of the
class. Easily identiﬁable by humans.
95.https://github.com/AludraTest/aludratest/issues/36 - Valid bug,
valid ﬁx. Identiﬁable with context of the Selenium library.
96.https://github.com/VazkiiMods/Quark/issues/3374 - Valid bug, valid
ﬁx. Simple ﬁx to ﬁx the formatting of chat events in certain ca ses of item links.
97.https://github.com/Tamaized/AoV/issues/93 - Valid bug, valid ﬁx. The
problem is that casting the furious howl spell should only ap ply to a selected target. Identi-
ﬁable through other examples of spells cast on a speciﬁc targ et in the library.
98.https://github.com/spring-projects/spring-boot-data -geode/issues/55
- Valid bug, valid ﬁx. Identiﬁable with knowledge of Spring b eans.
17

--- PAGE 18 ---
Published as a conference paper at ICLR 2023
99.https://github.com/twizmwazin/CardinalPGM/issues/65 7- Valid bug,
valid ﬁx. Identiﬁable through Bukkit/game conventions: th e game sets player metadata, but
doesnâ ˘A´Zt remove it on match end.
100.https://github.com/rundeck/rundeck-cli/issues/43 - Valid bug, valid
ﬁx. Annotation text doesnâ ˘A´Zt align with documentation about command line option usage
in the rest of the code.
E S YNTHETIC DATASET SAMPLES
E.1 E XAMPLE OF INCODER PERTURBATION
We present an example of a sample perturbation generated by t he InCoder model in Figure 1. The
original observation is on the left-hand side, and the pertu rbed observation is on the right-hand side.
package com . g i t h u b . y t . m ybatis . u t i l s ;
i m p o r t com . g i t h u b . y t . base . e x c e p t i o n .
B a s e E r r o r E x c e p t i o n ;
i m p o r t or g . apache . commons . lang3 . S t r i n g U t i l s ;
i m p o r t j a v a . l a n g . r e f l e c t . F i e l d ;
p u b l i c c l a s s B e a n U t i l s {
p u b l i c s t a t i c ChainMap< S t r i n g , Object >
getValueMap ( O b j e c t . . . o b j s ) {
t r y {
ChainMap< S t r i n g , Object > map =
new ChainMap < >() ;
f o r ( O b j e c t o b j : o b j s ) {
i f(n u l l == o b j ) {
c o n t i n u e ;
}
f o r ( Class <?> c = o b j . g e t C l a s s ( ) ;
O b j e c t . c l a s s != c ; c = c . g e t S u p e r c l a s s ( ) ) {
f o r ( F i e l d f i e l d : c .
g e t D e c l a r e d F i e l d s ( ) ) {
f i e l d . s e t A c c e s s i b l e ( t r u e ) ;
O b j e c t v a l u e = f i e l d . g e t ( o b j )
;
i f(n u l l == v a l u e ) {
c o n t i n u e ;
}
i f( f i e l d . getType ( ) .
i s A s s i g n a b l e F r o m ( S t r i n g . c l a s s ) && S t r i n g U t i l s .
isEmpty ( ( S t r i n g ) v a l u e ) ) {
c o n t i n u e ;
}
map . p u t ( f i e l d . getName ( ) ,
v a l u e ) ;
}
}
}
r e t u r n map ;
}c a t c h ( E x c e p t i o n e ) {
thr ow new B a s e E r r o r E x c e p t i o n ( " O b j e c t t o
Map c o n v e r t E r r o r " , e ) ;
}
}
}package com . g i t h u b . y t . m ybatis . u t i l s ;
i m p o r t com . g i t h u b . y t . base . e x c e p t i o n .
B a s e E r r o r E x c e p t i o n ;
i m p o r t or g . apache . commons . lang3 . S t r i n g U t i l s ;
i m p o r t j a v a . l a n g . r e f l e c t . F i e l d ;
p u b l i c c l a s s B e a n U t i l s {
p u b l i c s t a t i c ChainMap< S t r i n g , Object >
getF ieldMap ( O b j e c t . . . o b j s ) {
ChainMap < S t r i n g , Object > map =
new ChainMap< S t r i n g , Object > ( ) ;
t r y {
i f( o b j s != n u l l && o b j s . l e n g t h == 1) {
O b j e c t o b j = o b j s [ 0 ] ;
f o r( Class <?> c = o b j . g e t C l a s s ( ) ;
O b j e c t . c l a s s != c ; c = c . g e t S u p e r c l a s s ( ) ) {
f o r ( F i e l d f i e l d : c .
g e t D e c l a r e d F i e l d s ( ) ) {
f i e l d . s e t A c c e s s i b l e ( t r u e ) ;
O b j e c t v a l u e = f i e l d . g e t ( o b j )
;
i f(n u l l == v a l u e ) {
c o n t i n u e ;
}
i f( f i e l d . getType ( ) .
i s A s s i g n a b l e F r o m ( S t r i n g . c l a s s ) && S t r i n g U t i l s .
isEmpty ( ( S t r i n g ) v a l u e ) ) {
c o n t i n u e ;
}
map . p u t ( f i e l d . getName ( ) ,
v a l u e ) ;
}
}
}
r e t u r n map ;
}c a t c h ( E x c e p t i o n e ) {
thr ow new B a s e E r r o r E x c e p t i o n ( " O b j e c t t o
Map c o n v e r t E r r o r " , e ) ;
}
}
}
Original observation. Perturbed observation.
Figure 1: Sampled perturbation introduces a non-trivial re write, which may be considered as a “bug”.
Left: Original Java code iterates over a given list of objects (gr een highlight). Right : Perturbed
Java code only considers the ﬁrst object in the list, if the li st contains precisely one element (red
highlight).
Remarkably, both sequences appear to be syntactically corr ect code. The auto-repressive sampler
took future tokens into account. For example, the type resol ution of the object map may be re-
solved by the return signature of the function public static ChainMap<...> which was
not masked out and the invocation of map.put(...) . While the original code iterates over the
18

--- PAGE 19 ---
Published as a conference paper at ICLR 2023
list of objects obj, the perturbed code only considers the ﬁrst element of the li st, if the list contains
a single element. Whether the rewrites constitute a "bug" de pends on the deﬁnition of the term, as
earlier discussed. However, given the context one can argue that the rewritten implementation seems
less probable to follow the underlying intent.
E.2 S YNTHETIC SAMPLES WITH EXPLANATIONS
In this section we provide a few samples of bugs generated in t he second revision of the synthetic
dataset as well as brief explanations of the perturbations i n Figures 2, 3, and 4. The red lines mark
lines affected by the perturbations.
In Sample 1 (2), the bug is obviously introduced because the p assword string is being printed out
into STDOUT. This is valid Java code, bug a signiﬁcant deviat ion from secure coding practices.
The code in Sample 2 ( 3) endless recursion loop call. The code in Sample 3 (4) is from a Spring
app that controls a Planet API. Every time a call to addPlanet API is made, the API returns
HttpStatus.BAD_REQUEST every time regardless of whether the operation succeeded or not.
@Override
p r o t e c t e d A u t h e n t i c a t i o n I n f o d o G e t A u t h e n t i c a t i o n I n f o ( A u t h e n t i c a t i o n T o k e n token ) thr ows
A u t h e n t i c a t i o n E x c e p t i o n {
System . o u t . p r i n t l n ( "==ç ´Z˙zå¡ ¸ Tè ˝ od’è´ r ˛ A == " ) ;
/ / ç ˇ n ˇ näÿ ˘Aæ ˇ eïijŽä ˙z˝Otokenäÿ å´R˝Uå˘Gžç ˇT´læ´L ˚ uå ˇR
S t r i n g r ealnam e = ( S t r i n g ) token . g e t P r i n c i p a l ( ) ;
/ / ç ˇ n ˇ näž ˇNæ ˇ eïijŽæ ˘ a ´ zæ ˝ oçˇT´læ´L ˚ uå ˇR ä˙z˝Oæ ¸ Tˇ ræ ˝ oåž ¸ S è ˝O˚ uå ´R˝UçˇT´læ´L˚ u
User u s e r = n u l l ;
t r y {
u s e r = u s e r S e r v i c e . findObjectByName ( r ealnam e ) ;
}c a t c h ( E x c e p t i o n e1 ) {
/ / TODO Auto − g e n e r a t e d c a t c h block
e1 . p r i n t S t a c k T r a c e ( ) ;
}
i f( u s e r == n u l l ) {
r e t u r n new S i m p l e A u t h e n t i c a t i o n I n f o ( " çˇT´læ´L ˚ uäÿ åŸåIJ ´l ! ",f a l s e , getName ( ) ) ;
}
/ / å´ r ˛ Eç ˘ a ˛ A
S t r i n g passwor d = getP asswor dEncoder ( ) . e n c o d e T o S t r i n g ( u s e r . getP asswor d ( ) ) ;
System . o u t . p r i n t l n ( " è ˝ od’è´ r ˛ Aå ˛ E ˇE"+ passwor d ) ;
/ / ç ˇ n ˇ näÿL ’æ ˇ eïijŽæ ˘ a ´ zæ ˝ oçˇT´læ´L ˚ uå ˇRï£¡è£ ˇTå˙Z¯dè ˝ od’è´ r ˛ Aä£ ˛ aæ ˛ A´ rAuthenticationInfo
/ / activeUser åˇ r ´ sæŸ´ r ç ˇT´læ´L ˚ uè ž ´ nä ˙z¡ ä£ ˛ a æ ˛ A ´ r
A c t i v e U s e r a c t i v e U s e r = new A c t i v e U s e r ( ) ;
a c t i v e U s e r . setRealnam e ( u s e r . getRealnam e ( ) ) ;
a c t i v e U s e r . s e t P h o n e ( u s e r . getP hone ( ) ) ;
a c t i v e U s e r . s e t V a l i d ( u s e r . g e t V a l i d ( ) ) ;
/ / System . o u t . p r i n t l n ( " è ˝ od’è´ r ˛ Aå ˛ E ˇE"+ a c t i v e U s e r ) ;
/ / è˘GłåŁ ´lå ˝ oˇNæ´LˇRå´ r ˛ Eç ˘ a ˛ Aæ´ r ˇTå´ r ´ z − å´ r ˛ Eç ˘ a ˛ AçŽ ˇDæ´ r ˇTå´ r ´ z :
/ / é˘AŽè£ ˘G A u t h e n t i c a t i n g R e a l m çŽ ˇD c r e d e n t i a l s M a t c h e r å´ s ¯dæ˘A ˘ gæ ˙I ˇ eè£ ˙Zè ˛ aˇNçŽ ˇDå´ r ˛ Eç ˘ a ˛ AçŽ ˇDæ´ r ˇTå´ r ´ z!
S i m p l e A u t h e n t i c a t i o n I n f o i n f o =
new S i m p l e A u t h e n t i c a t i o n I n f o ( a c t i v e U s e r , password , c r e d e n t i a l s S a l t , getName ( ) ) ;
S e c u r i t y U t i l s . g e t S u b j e c t ( ) . g e t S e s s i o n ( ) . s e t A t t r i b u t e (" c u r r e n t U s e r " , u s e r ) ;
r e t u r n i n f o ;
}
}
Figure 2: Revised Synthetic Dataset Sample 1
F R EALISTIC BENCHMARK SAMPLES
In order to show the necessity for long-context language mod els for bug localization, we demonstrate
an example of a bug that is highly dependent on external conte xt outside of the scope of the ﬁle
where the bug is located. The issue2in question is related to a bug in a software project Catnip th at
provides a Discord3API wrapper in Java. The bug is that the Java plugin uses java.awt.Color4
2https://github.com/mewna/catnip/issues/105
3https://discord.com
4https://docs.oracle.com/javase/7/docs/api/java/awt/ Color.html
19

--- PAGE 20 ---
Published as a conference paper at ICLR 2023
p u b l i c c l a s s LazyFragment e x t e n d s Fragment {
p r o t e c t e d L a y o u t I n f l a t e r i n f l a t e r ;
p r i v a t e View contentView ;
p r i v a t e Context c o n t e x t ;
p r i v a t e ViewGroup c o n t a i n e r ;
@Override
p u b l i c void o n C r e a t e ( Bundle s a v e d I n s t a n c e S t a t e ) {
s u p e r . o n C r e a t e ( s a v e d I n s t a n c e S t a t e ) ;
c o n t e x t = g e t A c t i v i t y ( ) . g e t A p p l i c a t i o n C o n t e x t ( ) ;
}
@Override
p u b l i c View onCreateView ( L a y o u t I n f l a t e r i n f l a t e r , ViewGroup c o n t a i n e r , Bundle s a v e d I n s t a n c e S t a t e ) {
t h i s . i n f l a t e r = i n f l a t e r ;
t h i s . c o n t a i n e r = c o n t a i n e r ;
onCr eateiew ( i n f l a t e r , c o n t a i n e r , s a v e d I n s t a n c e S t a t e ) ;
r e t u r n contentView ;
}
@Override
p u b l i c void onDestroyView ( ) {
s u p e r . onDestroyView ( ) ;
contentView = n u l l ;
c o n t a i n e r = n u l l ;
i n f l a t e r = n u l l ;
}
Figure 3: Revised Synthetic Dataset Sample 2
to store Color parameter for embeds. This class stores not on ly the RGB bits of the color, but also
8 extra alpha bits, constituting a 64 bit representation of e ach color. However, the Discord API only
accepts 48 bit representations of colors. The ﬁx, therefore , consists of masking out the ﬁrst 8 bits
of the color representation of java.awt.Color and passing that into the API. The ﬁxing hunk is
shown in Figure 5.
For a human to be able to understand and identify this issue, t hey need to know about the Discord
API, the common patterns of calling the Discord API, the pecu liarities of color representations in
thejava.awt.Color class, and how to perform bit operations. We present an piece of code5
available online that demonstrates calling the discord API . This code passes in a color for the embed
frame as a 48-bit digit (Figure 6). Examples like this in trai ning or in the context are necessary for
the model to have a chance at locating this bug. Without the co ntext, even a human observer cannot
reliably mark this as buggy code.
5https://discordjs.guide/popular-topics/embeds.html# embed-preview
20

--- PAGE 21 ---
Published as a conference paper at ICLR 2023
@ C o n t r o l l e r
@RequestMapping ( v a l u e = " / a p i " )
@CrossOrigin ( o r i g i n s = "*")
/ / @CrossOrigin ( o r i g i n s = " h t t p : / / l o c a l h o s t : 4 2 0 0 " )
p u b l i c c l a s s P l a n e t C o n t r o l l e r {
/ / p r i v a t e P l a n e t S e r v i c e p l a n e t S e r v i c e ; I DONT HAVE A SERVI CE AT THE M OM E NT
p r i v a t e P lanetRepo p l a n e t R e p o ;
p u b l i c P l a n e t C o n t r o l l e r ( P lanetRepo p l a n e t R e p o ) {
s u p e r ( ) ;
t h i s . p l a n e t R e p o = p l a n e t R e p o ;
}
/ / @RequestMapping ( v a l u e = " / g e t P l a n e t s " , method = Reques tMethod . GET )
@GetMapping( v a l u e = " / g e t P l a n e t s " )/ / These a r e i d e n t i c a l i n c o n f i g u r a t i o n . h t t p : / / l o c a l h o s t : 8 0 8 0 / SpringMVC /
mvc / a p i / g e t P l a n e t s
p u b l i c @ResponseBody L i s t < P l a n e t > g e t A l l P l a n e t s ( ) {
r e t u r n p l a n e t R e p o . s e l e c t A l l ( ) ;
}
@GetMapping( v a l u e = " / g e t P l a n e t s W i t h P a r a m " , p r o d u c e s= " a p p l i c a t i o n / j s o n " , params = { " i d " }) / / h t t p : / / l o c a l h o s t
: 8 0 8 0 / SpringMVC / mvc / a p i / g e t P l a n e t s W i t h P a r a m ? i d =2
p u b l i c R e s p o n s e E n t i t y < P l a n e t > g e t P l a n e t B y I d ( i n t i d ) {
r e t u r n new R e s p o n s e E n t i t y < P l a n e t >( p l a n e t R e p o . s e l e c t P l a n e t B y I d ( i d ) , H t t p S t a t u s . INSUFFICIENT_STORAGE ) ;
}
@ResponseS tatus ( v a l u e = H t t p S t a t u s . ALREADY_REPORTED)
@GetMapping( v a l u e = " / g e t P l a n e t W i t h U r l / { num} " )
p u b l i c @ResponseBody P l a n e t getP lanetByI dTwo ( @P athVar iable ( "num" )i n t i d ) {
r e t u r n p l a n e t R e p o . s e l e c t P l a n e t B y I d ( i d ) ;
}
@ResponseS tatus ( v a l u e = H t t p S t a t u s . BAD_REQUEST)
@PostMapping( v a l u e = " / a d d P l a n e t " )
p u b l i c @ResponseBody S t r i n g a d d P l a n e t ( @RequestBody P l a n e t i n c o m i n g P l a n e t ) {
/*
*This method i s e x e c u t e d when t h e u s e r r e q u e s t s t o add a new p l a n e t t o
*t h e d a t a b a s e .
*
*The d e f a u l t b e h a v i o r f o r M VC i s t o i g n o r e t h e incom ing JSON
*and t r e a t i t l i k e i f i t were a GET r e q u e s t .
*
*I n our example , we would e x p e c t t h i s r e q u e s t t o I f t h e incom in g JSON does NOT HAVE a l l t h e f i e l d s , i t
w i l l p r o v i d e j u s t d e f a u l t v a l u e s .
*/
p l a n e t R e p o . i n s e r t ( i n c o m i n g P l a n e t ) ;
r e t u r n " S uccess " ;
}
@GetMapping( v a l u e = " / a l l T h e H e a d e r s " )
p u b l i c R e s p o n s e E n t i t y < S t r i n g > a l l H e a d e r s ( @RequestHeader Map< S t r i n g , S t r i n g > a l l H e a d e r s ) {
/ / THIS IS NOTHING TO DO WITH M VC
/ / This i s from C o l l e c t i o n s ( Week 1)
f o r( Entr y < S t r i n g , S t r i n g > e n t r y : a l l H e a d e r s . e n t r y S e t ( ) ) {
System . o u t . p r i n t l n ( e n t r y . getKey ( ) + " \ t " + e n t r y . g e t V a l u e ( ) ) ;
}
HttpHeader s r e s p o n s e H e a d e r = new HttpHeader s ( ) ;
r e s p o n s e H e a d e r . s e t ( "Name" ," Bobby" ) ;
r e s p o n s e H e a d e r . s e t ( " s u p e r S e c r e t s " ,"******** ") ;
r e t u r n new R e s p o n s e E n t i t y < S t r i n g >( " S uccess " , r esponseHeader , H t t p S t a t u s . FORBIDDEN ) ;
}
}
Figure 4: Revised Synthetic Dataset Sample 3
21

--- PAGE 22 ---
Published as a conference paper at ICLR 2023
@CheckReturnValue
p u b l i c EmbedBuilder c o l o r ( @Nullable f i n a l Color c o l o r ) {
i f( c o l o r != n u l l ) {
t h i s . c o l o r = c o l o r . getRGB ( ) ;
/ / Mask o f f t h e a l p h a b i t s
t h i s . c o l o r = c o l o r . getRGB ( ) & 0x00FFFFFF ;
}
r e t u r n t h i s ;
}
Figure 5: Hunk from sample issue from Catnip. This bug demons trates the need for more context
than ﬁle-level information.
c o n s t exampleEmbed = new EmbedBuilder ( )
. s e t C o l o r ( 0 x0099FF )
. s e t T i t l e ( ’ Some t i t l e ’ )
. setURL ( ’ h t t p s : / / d i s c o r d . j s . or g / ’ )
. s e t A u t h o r ( { name : ’Some name ’ ,
iconURL : ’ h t t p s : / / i . imgur . com / AfFp7pu . png ’ ,
u r l : ’ h t t p s : / / d i s c o r d . j s . org ’ })
. s e t D e s c r i p t i o n ( ’ Some d e s c r i p t i o n her e ’ )
. s e t T h u m b n a i l ( ’ h t t p s : / / i . imgur . com / AfFp7pu . png ’ )
. a d d F i e l d s (
{ name : ’ Regular f i e l d t i t l e ’ , v a l u e : ’Some v a l u e her e ’ } ,
{ name : ’ \ u200B ’ , v a l u e : ’ \ u200B ’ } ,
{ name : ’ I n l i n e f i e l d t i t l e ’ , v a l u e : ’ Some v a l u e her e ’ , i n l i n e : t r u e } ,
{ name : ’ I n l i n e f i e l d t i t l e ’ , v a l u e : ’ Some v a l u e her e ’ , i n l i n e : t r u e } ,
)
. a d d F i e l d s ( { name : ’ I n l i n e f i e l d t i t l e ’ , v a l u e : ’ Some v a l u e her e ’ , i n l i n e : t r u e })
. s e t I m a g e ( ’ h t t p s : / / i . imgur . com / AfFp7pu . png ’ )
. setTim estam p ( )
. s e t F o o t e r ( { t e x t : ’Some f o o t e r t e x t her e ’ , iconURL : ’ h t t p s : / / i . imgur . com / AfFp7pu . png ’ }) ;
Figure 6: Example of calling the Discord API with a RGB (24-bi t) color representation while RGBA
(32-bit) is expected
22

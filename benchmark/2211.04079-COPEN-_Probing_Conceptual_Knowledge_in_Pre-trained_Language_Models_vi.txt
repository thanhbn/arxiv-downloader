# COPEN: Khảo sát Kiến thức Khái niệm trong các Mô hình Ngôn ngữ Tiền huấn luyện

Hao Peng1;2, Xiaozhi Wang1;2, Shengding Hu1;2, Hailong Jin1;2, Lei Hou1;2y,
Juanzi Li1;2, Zhiyuan Liu1;2, Qun Liu3
1Khoa Khoa học Máy tính và Công nghệ, BNRist;
2KIRC, Viện Trí tuệ Nhân tạo,
Đại học Thanh Hoa, Bắc Kinh, 100084, Trung Quốc
3Phòng thí nghiệm Phao Noah của Huawei
{peng-h21, wangxz20}@mails.tsinghua.edu.cn

## Tóm tắt

Kiến thức khái niệm là nền tảng cho nhận thức con người và các cơ sở tri thức. Tuy nhiên, các công trình khảo sát kiến thức hiện tại chỉ tập trung vào đánh giá kiến thức thực tế của các mô hình ngôn ngữ tiền huấn luyện (PLMs) và bỏ qua kiến thức khái niệm. Vì kiến thức khái niệm thường xuất hiện như tri thức thường thức ngầm định đằng sau các văn bản, việc thiết kế các phép thăm dò cho kiến thức khái niệm là khó khăn. Lấy cảm hứng từ các lược đồ biểu diễn tri thức, chúng tôi đánh giá toàn diện kiến thức khái niệm của PLMs bằng cách thiết kế ba nhiệm vụ để thăm dò liệu PLMs có tổ chức các thực thể theo độ tương tự khái niệm, học các thuộc tính khái niệm, và khái niệm hóa các thực thể trong ngữ cảnh hay không. Đối với các nhiệm vụ này, chúng tôi thu thập và chú thích 24k mẫu dữ liệu bao phủ 393 khái niệm, đó là COPEN, một bộ Benchmark thăm dó kiến thức Khái niệm. Các thí nghiệm mở rộng trên các PLMs có kích thước và loại khác nhau cho thấy các PLMs hiện tại thiếu kiến thức khái niệm một cách có hệ thống và gặp phải nhiều tương quan giả mạo khác nhau. Chúng tôi tin rằng đây là một nút thắt cổ chai quan trọng để thực hiện nhận thức giống con người trong PLMs. COPEN và mã nguồn của chúng tôi được công bố tại https://github.com/THU-KEG/COPEN.

## 1 Giới thiệu

Các mô hình ngôn ngữ tiền huấn luyện (PLMs) đã đạt được hiệu suất vượt trội trên hầu hết các nhiệm vụ NLP đòi hỏi kiến thức thế giới đáng kể (Qiu et al., 2020; Han et al., 2021). Việc thăm dò mức độ và phạm vi của kiến thức thế giới trong PLMs là thú vị và có ý nghĩa. Các công trình thăm dò kiến thức hiện tại đã đánh giá kiến thức của PLMs về các thực thể (Broscheit, 2019; Tenney et al., 2019a) và mối quan hệ của chúng (Petroni et al., 2019; Jiang et al., 2020; Roberts et al., 2020), tức là kiến thức thực tế, nhưng bỏ qua kiến thức khái niệm.

Đóng góp ngang nhau
yTác giả liên hệ: L.Hou

Động vật có thể di chuyển.
UK
Grumpy Cat
USA Động vật có vú
Động vật
Chim
Quốc gia
Dolly quốc tịch quốc tịch Quan hệ Thực thể của Lớp con của Hầu hết động vật có vú đều có rốn. Chim có lông. ………… Đồ thị Thực thể Phân loại Khái niệm Thuộc tính

Hình 1: Một ví dụ về đồ thị tri thức. Các thực thể được tổ chức theo khái niệm thông qua quan hệ Thực thể của và các khái niệm được tổ chức thành một phân loại thông qua quan hệ Lớp con của. Mỗi khái niệm có những thuộc tính nhất định. Công trình hiện tại chỉ thăm dò kiến thức thực tế trong đồ thị thực thể, bỏ qua kiến thức khái niệm trong phân loại khái niệm và quan hệ Thực thể của.

Kiến thức khái niệm, đặc biệt là khả năng trừu tượng hóa, là nền tảng cho tất cả các loại nhận thức con người (Carey, 1991; Collins và Olson, 2014) bao gồm xử lý ngôn ngữ (Waxman và Markow, 1995; Wellsby và Pexman, 2014). Như câu nói của nhà tâm lý học Gregory Murphy, các khái niệm là chất keo gắn kết thế giới tinh thần của chúng ta (Murphy, 2004). Hơn nữa, các cơ sở tri thức (Suchanek et al., 2007; Auer et al., 2007; Vrandečić, 2012) tổ chức các thực thể lớn thông qua các phân loại khái niệm như được minh họa trong Hình 1, cho phép các ứng dụng rộng rãi (Lv et al., 2018; Zhou et al., 2021). Do đó, thăm dó liệu PLMs có kiến thức khái niệm giống con người hay không là cần thiết trong thăm dò kiến thức.

Lấy cảm hứng từ lược đồ khái niệm trong biểu diễn tri thức (Sowa, 1976; Decker et al., 2000; McGuinness et al., 2004; Antoniou và Van Harmelen, 2004), chúng tôi đánh giá toàn diện kiến thức khái niệm của PLMs bằng cách đặt ra ba câu hỏi: PLMs có tổ chức các thực thể theo độ tương tự khái niệm không?

PLMs có biết các thuộc tính của khái niệm không? PLMs có thể khái niệm hóa chính xác các thực thể trong ngữ cảnh không? Trong bài báo này, chúng tôi thiết kế ba nhiệm vụ thăm dò cho những câu hỏi này: (1) Nhiệm vụ đánh giá tương tự khái niệm (CSJ) nghiên cứu liệu PLMs có tổ chức các thực thể theo độ tương tự khái niệm hay không, đây là cơ sở để hiểu các khái niệm. Cho một thực thể truy vấn, CSJ yêu cầu PLMs chọn thực thể tương tự nhất về mặt khái niệm trong số các thực thể ứng cử viên. Ví dụ, trong Hình 1, cho Dolly làm thực thể truy vấn, mặc dù UK có quan hệ trực tiếp và nhiều sự xuất hiện cùng nhau hơn với nó, PLMs nên chọn Grumpy Cat. (2) Nhiệm vụ đánh giá thuộc tính khái niệm (CPJ) thăm dò liệu PLMs có kiến thức về các thuộc tính khái niệm hay không, đây là những trừu tượng hóa chung của kiến thức thực tế. Cho một câu phát biểu về một thuộc tính cụ thể, như "có lông", CPJ yêu cầu PLMs đánh giá liệu nó có đúng cho một khái niệm cụ thể và cũng một chuỗi khái niệm hay không, điều này đánh giá liệu PLMs có hiểu tính bắc cầu của thuộc tính trong một chuỗi các khái niệm phân cấp hay không. (3) Nhiệm vụ khái niệm hóa trong ngữ cảnh (CiC) đánh giá khả năng của PLMs để khái niệm hóa chính xác các thực thể trong ngữ cảnh. Cho một thực thể được đề cập trong một ngữ cảnh cụ thể, PLMs được yêu cầu chọn khái niệm phù hợp nhất trong một phân loại khái niệm theo ngữ cảnh của nó. CiC không chỉ yêu cầu phân định các đề cập thực thể mà còn phân biệt các khái niệm cấp trên và cấp dưới. Ví dụ, cho ngữ cảnh "Dolly đang chạy trên đồng cỏ", PLMs nên khái niệm hóa Dolly như một Động vật vì không có đủ bằng chứng cho Động vật có vú.

Dựa trên những cân nhắc trên, chúng tôi xây dựng một benchmark thăm dò kiến thức khái niệm, COPEN, chứa một phân loại khái niệm với 446 khái niệm và dữ liệu chất lượng cao gồm 24K mẫu cho ba nhiệm vụ thăm dò. Phân loại khái niệm được tuyển chọn bởi các chuyên gia dựa trên DBpedia (Auer et al., 2007) và Wikidata (Vrandečić và Krötzsch, 2014) để tạo thành một phân cấp được định nghĩa rõ ràng và bao phủ các thực thể rộng rãi. Các mẫu dữ liệu cho ba nhiệm vụ được thu thập bằng cách căn chỉnh các thực thể trong Wikidata và các câu trong GenericsKB (Bhakthavatsalam et al., 2020), Wikipedia¹ và Simple Wikipedia² vào phân loại khái niệm và sau đó được chú thích thủ công bởi các nhà chú thích đám đông.

Chúng tôi tiến hành các thí nghiệm mở rộng trên COPEN để đánh giá các mô hình ngôn ngữ (LMs) được sử dụng rộng rãi khác nhau, bao gồm ba loại: masked LMs (Devlin et al., 2019; Liu et al., 2019b), autoregressive LMs (Radford et al., 2019; Black et al., 2021), và sequence-to-sequence LMs (Lewis et al., 2020; Raffel et al., 2020). Chúng tôi tiến hành các thí nghiệm trong ba thiết lập: (1) thăm dò zero-shot, reformulate các nhiệm vụ thăm dò thành các mục tiêu tiền huấn luyện và để PLMs chấm điểm câu trả lời mà không cần bất kỳ huấn luyện nào (Petroni et al., 2019); (2) thăm dò tuyến tính, chỉ tinh chỉnh các đầu phân loại tuyến tính bổ sung và sử dụng chúng để xử lý các nhiệm vụ thăm dò với các biểu diễn đông cứng được tạo bởi PLMs; (3) tinh chỉnh, điều chỉnh tất cả các tham số PLM. Các thí nghiệm cho thấy các PLMs hiện tại đạt hiệu suất không tầm thường nhưng vẫn kém hiệu suất đáng kể so với người bình thường trên tất cả ba nhiệm vụ thăm dò. Các phân tích sâu hơn cho thấy PLMs gặp phải các tương quan giả mạo như sự xuất hiện cùng nhau của từ và dự đoán ngoài ngữ cảnh, và việc tăng quy mô mô hình mang lại cải thiện không đáng kể.

Tóm lại, đóng góp của chúng tôi gồm ba phần: (1) Chúng tôi đề xuất thăm dò PLMs về kiến thức khái niệm, điều này từ lâu đã bị bỏ qua, và thiết kế ba nhiệm vụ thăm dò lấy cảm hứng từ các công trình biểu diễn tri thức. (2) Chúng tôi xây dựng COPEN, một benchmark thăm dò chứa phân loại khái niệm và các phép thăm dò chất lượng cao. (3) Chúng tôi chứng minh thực nghiệm rằng các PLMs hiện tại thiếu kiến thức khái niệm một cách có hệ thống và phân tích các lý do. Chúng tôi hy vọng benchmark và những phát hiện của chúng tôi có thể tạo điều kiện cho nghiên cứu sâu hơn về PLMs nhận thức khái niệm và hiểu biết ngôn ngữ giống con người.

## 2 Benchmark COPEN

Trong phần này, chúng tôi giới thiệu benchmark COPEN của chúng tôi, bao gồm việc xây dựng phân loại khái niệm (§ 2.1) và các bộ dữ liệu cho ba nhiệm vụ thăm dò (§§ 2.2 đến 2.4). Chi tiết xây dựng và chú thích thêm được trình bày trong phụ lục D.

### 2.1 Phân loại Khái niệm COPEN

Thiết kế ba nhiệm vụ thăm dò lấy cảm hứng từ lược đồ khái niệm trong biểu diễn tri thức (Decker et al., 2000; McGuinness et al., 2004), được sử dụng rộng rãi trong các đồ thị tri thức (Suchanek et al., 2007; Auer et al., 2007; Vrandečić, 2012). Nói chung, nó sử dụng quan hệ thực thể của để liên kết các thực thể (các thể hiện cụ thể) vào các khái niệm trừu tượng, và sử dụng quan hệ lớp con của để tổ chức các khái niệm thành một phân loại. Mỗi khái niệm có những thuộc tính nhất định mô tả nó như

ví dụ được trình bày trong Hình 1.

Để hỗ trợ việc xây dựng bộ dữ liệu thăm dò, chúng tôi tuyển chọn thủ công một phân loại khái niệm dựa trên DBpedia (Auer et al., 2007) và Wikidata (Vrandečić và Krötzsch, 2014) trong 3 bước: (1) Lấy một phân loại cơ bản từ DBpedia. Chúng tôi trích xuất các khái niệm thường xuyên của DBpedia, là những khái niệm có ít nhất 5 thể hiện, và giữ các quan hệ lớp con của giữa chúng. (2) Căn chỉnh DBpedia và Wikidata. Đối với mỗi khái niệm DBpedia, chúng tôi tìm thủ công mục Wikidata tương đương của nó và sau đó sử dụng các quan hệ lớp con của (P279) trong Wikidata để mở rộng phân loại khái niệm và sử dụng các quan hệ thực thể của (P31) để liên kết các thực thể Wikidata lớn vào các khái niệm. (3) Đơn giản hóa phân loại. Chúng tôi tiếp tục loại bỏ một số khái niệm bất thường để đơn giản hóa phân loại theo hướng dẫn từ Schema.org (Guha et al., 2016). Ví dụ, Người là một khái niệm con của Động vật, Eukaryote và Loài trong DBpedia, điều này hợp lý nhưng không thuận tiện cho các ứng dụng thực tế. Theo Schema.org, chúng tôi đặt Người như một khái niệm cấp cao nhất trong phân loại. Cuối cùng, chúng tôi đạt được một phân loại khái niệm súc tích có cấu trúc cây, chứa 446 khái niệm bao phủ 45 triệu thực thể Wikidata. Có 23 khái niệm cấp cao nhất, và chúng tôi sử dụng 11 trong số chúng và các khái niệm con của chúng để xây dựng bộ dữ liệu huấn luyện và phát triển cũng như các khái niệm khác cho bộ dữ liệu kiểm tra.

### 2.2 Đánh giá Tương tự Khái niệm

Nhiệm vụ đánh giá tương tự khái niệm (CSJ) là một nhiệm vụ phân loại đa lựa chọn, thăm dò liệu PLMs có tổ chức các thực thể theo độ tương tự khái niệm hay không, tức là liệu PLMs có học được quan hệ thực thể của hay không. Cho một thực thể truy vấn, CSJ yêu cầu PLMs chọn thực thể tương tự nhất về mặt khái niệm (thể hiện của cùng một khái niệm cấp trên) trong số một số ứng cử viên. Như trong Hình 2 (a), PLMs nên chọn Pohang Steelers cho Inter Milan vì cả hai đều là câu lạc bộ bóng đá, mặc dù Milan và Inter Milan xuất hiện cùng nhau thường xuyên hơn. Tương tự khái niệm ở đây tương tự như quan hệ cohyponym trong ngữ nghĩa từ vựng (Cruse, 1986), đã được chứng minh là khác biệt nhưng dễ bị ảnh hưởng bởi các liên kết xuất hiện cùng nhau giả mạo (Hill et al., 2015). Do đó chúng tôi cần kiểm soát ảnh hưởng của các sự xuất hiện cùng nhau để có được kết quả đáng tin cậy.

Thu thập Dữ liệu Dữ liệu cho CSJ được thu thập trong hai bước: (1) Thu thập tự động. Chúng tôi đầu tiên lấy mẫu 174 khái niệm không phải là cấp dưới của nhau. Sau đó chúng tôi truy xuất 50 thực thể Wikidata xuất hiện thường xuyên nhất trong kho văn bản Wikipedia cho mỗi khái niệm, và sau đó xây dựng các mẫu dữ liệu bằng cách kết hợp chúng. Mỗi mẫu bao gồm một thực thể truy vấn, một thực thể câu trả lời của cùng khái niệm, và 20 thực thể nhiễu, trong đó 5 là những nhiễu khó của các khái niệm chia sẻ cấp trên với khái niệm của thực thể truy vấn. Để kiểm tra chất lượng dữ liệu, chúng tôi lấy mẫu 200 mẫu và thấy ít nhiễu. (2) Lọc dựa trên sự xuất hiện cùng nhau. Để giảm ảnh hưởng của sự xuất hiện cùng nhau, chúng tôi cần lọc ra các mẫu có thể được giải quyết dễ dàng với sự xuất hiện cùng nhau.

Inter Milan tương tự về mặt khái niệm với Chọn khái niệm phù hợp nhất với ngữ cảnh cho Dolly theo ngữ cảnh: Dolly đang chạy trên đồng cỏ. Dolly là một (a)(c) Mẫu Động vật có vú nuôi con bằng sữa. Câu phát biểu là Mẫu động vật động vật có vú Series A Pohang Steelers Milan Milan Fashion Week (b) Động vật Ngựa đúng | sai đúng | sai đúng | sai Câu trả lời Khái niệm/Chuỗi Khái niệm ngựa Thực thể Truy vấn Mẫu Thực thể Mẫu Thực thể Ứng cử viên Vàng:: Lớp con của Khái niệm Tím: Thực thể

Hình 2: Ví dụ về việc đưa dữ liệu của ba nhiệm vụ thăm dò vào các gợi ý ngôn ngữ tự nhiên trong thăm dò zero-shot. Tên của các thực thể hoặc khái niệm là văn bản được tra cứu trong Wikidata bằng ID của chúng. Trong Hình (b), văn bản in đậm (đúng hoặc sai) biểu thị câu trả lời. Trong Hình (b) và (c), chuỗi khái niệm là Ngựa –>Động vật có vú –>Động vật. Trong Hình (c), đối với các thực thể có nhiều chuỗi khái niệm, mỗi khái niệm sẽ được PLMs chấm điểm độc lập, tức là PLMs chỉ đưa ra dự đoán ở cấp độ khái niệm. Không có quy trình lựa chọn chuỗi chuyên dụng.

Lastra-Díaz et al. (2019) cho thấy rằng word embedding Glove (Pennington et al., 2014) chứa thông tin xuất hiện cùng nhau phong phú nhưng có kiến thức cohyponym hạn chế. Do đó chúng tôi sử dụng nó để lọc ra các mẫu có độ tương tự từ cao hơn giữa thực thể truy vấn và thực thể câu trả lời so với các thực thể nhiễu. Cuối cùng chúng tôi có được 9.487 mẫu, mỗi mẫu bao gồm một thực thể truy vấn và 21 thực thể ứng cử viên. Thống kê các tập con dữ liệu được trình bày trong Bảng 1.

Train Dev Test
CSJ #Mẫu 4.462 1.116 3.909
#Khái niệm 84 84 90
CPJ #Mẫu 3.274 823 4.758
#Khái niệm 215 195 178
CiC #Mẫu 2.888 722 2.368
#Khái niệm 193 184 155

Bảng 1: Thống kê dữ liệu COPEN cho ba nhiệm vụ thăm dò.

### 2.3 Đánh giá Thuộc tính Khái niệm

Nhiệm vụ đánh giá thuộc tính khái niệm (CPJ) là một nhiệm vụ phân loại câu nhị phân, thăm dò liệu PLMs có biết các thuộc tính của khái niệm hay không. Cho một câu phát biểu mô tả một thuộc tính khái niệm nhất định, PLMs được yêu cầu đánh giá liệu nó có đúng hay không. Ví dụ trong Hình 2 (b), PLMs nên dự đoán "đúng" cho câu phát biểu Động vật có vú nuôi con bằng sữa.

Ngoài việc đánh giá CPJ ở cấp độ mẫu, phản ánh kiến thức của PLMs về thuộc tính cho các khái niệm cá nhân khác nhau, chúng tôi cũng thiết lập một đánh giá cấp độ chuỗi, trong đó một PLM đánh giá chính xác một thuộc tính khi và chỉ khi nó đánh giá chính xác thuộc tính cho mọi khái niệm trong một chuỗi khái niệm. Như ví dụ trong Hình 2 (b), một chuỗi khái niệm là một chuỗi các khái niệm được kết nối với quan hệ lớp con của theo thứ tự. Đánh giá cấp độ chuỗi đánh giá liệu PLMs có hiểu tính bắc cầu của các thuộc tính khái niệm hay không. Nó có nghĩa là một thuộc tính đúng cho một khái niệm cũng đúng cho các khái niệm cấp dưới của nó, nhưng có thể không đúng cho các khái niệm cấp trên của nó như trường hợp trong Hình 2 (b).

Thu thập Dữ liệu Dữ liệu cho CPJ được thu thập trong hai bước: (1) Thu thập tự động. Đối với mỗi khái niệm trong phân loại của chúng tôi, chúng tôi căn chỉnh nó với các câu phát biểu của GenericsKB (Bhakthavatsalam et al., 2020), một cơ sở tri thức chất lượng cao cho các câu phát biểu chung tự nhiên, bằng cách khớp từ vựng để có được các mẫu tích cực. Sau đó chúng tôi thay thế đề cập khái niệm bằng tên khái niệm khác để có được các mẫu tiêu cực. (2) Chú thích con người. Để đảm bảo chất lượng dữ liệu, chúng tôi mời các nhà chú thích kiểm tra liệu các mẫu có được gán nhãn chính xác, đúng ngữ pháp và mô tả các thuộc tính khái niệm hay không. Tất cả các nhà chú thích đều được đào tạo tốt và vượt qua một vòng đánh giá trước khi chú thích. Cuối cùng chúng tôi có được 8.855 mẫu cho CPJ và thống kê các tập con dữ liệu được trình bày trong Bảng 1. Ngoài ra, dữ liệu kiểm tra cuối cùng bao gồm 102 chuỗi khái niệm và các thuộc tính tương ứng được sử dụng cho đánh giá cấp độ chuỗi.

### 2.4 Khái niệm hóa trong Ngữ cảnh

Nhiệm vụ khái niệm hóa trong ngữ cảnh (CiC) là một nhiệm vụ phân loại đa lựa chọn, thăm dò liệu PLMs có thể khái niệm hóa chính xác các thực thể trong ngữ cảnh hay không. Cho một thực thể được đề cập trong một câu cụ thể, PLMs được yêu cầu chọn khái niệm phù hợp nhất trong số một chuỗi khái niệm, là một chuỗi các khái niệm được kết nối với quan hệ lớp con của theo thứ tự. Điều này yêu cầu PLMs hiểu quan hệ lớp con của và nắm bắt những khác biệt tinh tế của các khái niệm ở cấp độ khác nhau trong một phân cấp. Ví dụ trong Hình 2 (c), cho câu Dolly đang chạy trên đồng cỏ. và một chuỗi khái niệm Ngựa –>Động vật có vú –>Động vật, PLMs sẽ chọn Động vật cho Dolly vì ngữ cảnh không hỗ trợ các khái niệm chi tiết hơn. Đôi khi thực thể thuộc nhiều chuỗi khái niệm, ví dụ, Jimmy Carter vừa là Nhà văn vừa là Chính trị gia, điều này yêu cầu PLMs phân định thêm.

Thu thập Dữ liệu Dữ liệu cho CiC được thu thập trong hai bước: (1) Thu thập câu. Đối với mỗi khái niệm, chúng tôi đầu tiên truy xuất 10 thực thể Wikidata xuất hiện thường xuyên nhất trong kho văn bản Wikipedia. Trong số các thực thể được truy xuất, chúng tôi chỉ giữ các thực thể được liên kết với các chuỗi khái niệm chứa hơn một khái niệm và thu thập 5 câu cho mỗi thực thể từ Wikipedia và SimpleWiki, cung cấp các ngữ cảnh đa dạng cho khái niệm hóa. Một câu, cùng với một thực thể được đề cập trong câu và các chuỗi khái niệm của thực thể, tạo thành một mẫu. (2) Chú thích con người. Sau đó chúng tôi tổ chức chú thích đám đông để có được các nhãn. Tất cả các nhà chú thích đều được đào tạo tốt và có trình độ. Cuối cùng chúng tôi có được 5.978 mẫu cho CiC và thống kê các tập con dữ liệu được trình bày trong Bảng 1.

## 3 Thiết lập Đánh giá

Chúng tôi giới thiệu các PLMs được sử dụng rộng rãi khác nhau được nghiên cứu trong các thí nghiệm của chúng tôi (§ 3.1) và ba phương pháp thăm dò được áp dụng (§ 3.2).

### 3.1 PLMs được Nghiên cứu

Chúng tôi nghiên cứu ba loại PLMs chính: (1) Masked LM, bao gồm BERT (Devlin et al., 2019), được tiền huấn luyện với các mục tiêu mô hình hóa ngôn ngữ có mặt nạ hai chiều và dự đoán câu tiếp theo, và RoBERTa (Liu et al., 2019b), là một phiên bản được tối ưu hóa mạnh mẽ của BERT. (2) Autoregressive LM, bao gồm GPT-2 (Radford et al., 2019),

được tiền huấn luyện với mục tiêu mô hình hóa ngôn ngữ một chiều từ trái sang phải, và GPT-Neo (Black et al., 2021), áp dụng cùng mục tiêu nhưng cải thiện một số chi tiết triển khai. (3) Sequence-to-sequence LM, áp dụng kiến trúc encoder-decoder. Loại này bao gồm BART (Lewis et al., 2020), được tiền huấn luyện với các mục tiêu điền văn bản và hoán vị câu, và T5 (Raffel et al., 2020), được tiền huấn luyện với mục tiêu span-corruption và nhiều nhiệm vụ hạ nguồn.

Trong § 4, chúng tôi báo cáo kết quả của các phiên bản BASE được sử dụng thường xuyên của các PLMs này, và kết quả cho các phiên bản khác được trình bày trong phụ lục C.

### 3.2 Phương pháp Thăm dò

Thăm dò Zero-Shot reformulate các nhiệm vụ thăm dò thành định dạng của các mục tiêu mô hình hóa ngôn ngữ tiền huấn luyện (Liu et al., 2021a) để PLMs có thể thực hiện các nhiệm vụ này mà không cần bất kỳ huấn luyện nào. Nó được áp dụng rộng rãi bởi công trình thăm dò kiến thức (Petroni et al., 2019; Tenney et al., 2019a) vì nó ngăn PLMs học kiến thức mới từ dữ liệu huấn luyện để hiệu suất đạt được phản ánh kiến thức nội tại của PLMs. Do đó hiệu suất của thăm dò zero-shot thường được hiểu là giới hạn dưới của kiến thức PLMs (Jiang et al., 2020).

Như được minh họa trong Hình 2, đối với mỗi mẫu dữ liệu của ba nhiệm vụ thăm dò, chúng tôi đưa các lựa chọn của nó vào các gợi ý ngôn ngữ tự nhiên bằng cách điền chúng vào các mẫu được thiết kế thủ công, và sau đó để PLMs chấm điểm các gợi ý theo khả năng của mô hình hóa ngôn ngữ. Lựa chọn có điểm cao nhất được coi là câu trả lời dự đoán của PLMs. Một số chi tiết triển khai như việc lấy những phần nào của gợi ý vào tính toán chấm điểm có thể ảnh hưởng đến hiệu suất của PLMs. Chúng tôi tìm kiếm những chi tiết này với các thử nghiệm sơ bộ và chỉ báo cáo hiệu suất của cấu hình tốt nhất trong các thí nghiệm.

Thăm dò Tuyến tính thêm một bộ phân loại tuyến tính nông bổ sung trên đầu ra các biểu diễn theo ngữ cảnh của PLMs, và chỉ huấn luyện bộ phân loại bổ sung trong khi giữ các tham số của PLMs cố định. Vì khả năng mô hình của bộ phân loại tuyến tính nông quá hạn chế để phù hợp với các nhiệm vụ, hiệu suất đạt được chủ yếu phải đến từ kiến thức trong các biểu diễn của PLMs (Alain và Bengio, 2017). Do đó thăm dò tuyến tính được sử dụng rộng rãi trong thăm dò kiến thức (Tenney et al., 2019b; Hewitt và Manning, 2019).

Tinh chỉnh là phương pháp chuẩn để thích ứng PLMs với các nhiệm vụ hạ nguồn, huấn luyện tất cả các tham số PLMs trên dữ liệu huấn luyện với các mục tiêu cụ thể của nhiệm vụ. Xem xét khả năng mô hình mạnh mẽ của PLMs, PLMs sẽ không thể tránh khỏi việc phù hợp với các nhiệm vụ thăm dò thông qua thông tin trong dữ liệu huấn luyện thay vì chỉ dựa vào kiến thức nội tại của chúng. Do đó hiệu suất tinh chỉnh sẽ phục vụ như một giới hạn trên của kiến thức khái niệm của PLMs trong các thí nghiệm của chúng tôi.

Đối với CSJ và CiC, chúng tôi lấy các gợi ý đã điền của các mẫu tương tự trong thăm dò zero-shot làm đầu vào và huấn luyện PLMs với loss cross-entropy. Đối với CPJ, chúng tôi lấy các câu phát biểu thuộc tính làm đầu vào và sử dụng loss binary cross entropy.

Chi tiết triển khai cụ thể hơn về ba phương pháp thăm dò được trình bày trong phụ lục A.

## 4 Thí nghiệm và Phân tích

Chúng tôi đầu tiên giới thiệu kết quả tổng thể trong § 4.1 và tiến hành các phân tích chi tiết về ba nhiệm vụ thăm dò (§§ 4.2 đến 4.4), tương ứng. Sau đó chúng tôi phân tích hiệu suất ở các quy mô mô hình khác nhau (§ 4.5). Các quan sát và thảo luận thêm về kết quả thí nghiệm được đặt trong phụ lục B.

Mô hình CSJ CPJ CiC
Cấp độ Mẫu Cấp độ Chuỗi
ZP LP FT ZP LP FT ZP LP FT ZP LP FT
Random 4.8 4.8 4.8 50.0 50.0 50.0 7.2 7.2 7.2 27.7 27.7 27.7
BERT BASE 20.3 16.1±0.21 27.3±0.86 49.4 61.6±0.28 68.1±0.98 22.5 24.2±1.22 23.2±1.22 37.6 34.3±0.59 49.5±0.60
RoBERTa BASE 15.5 12.0±0.21 22.3±0.51 49.2 61.9±0.13 72.0±0.54 21.6 13.1±1.67 18.3±1.22 31.4 30.0±1.98 52.6±1.02
GPT-2 BASE 7.9 4.3±0.24 20.1±0.23 51.5 64.8±1.14 70.4±0.72 14.7 14.4±0.92 20.3±2.01 32.3 34.5±2.08 54.2±0.12
GPT-Neo 125M 7.9 11.0±0.20 18.3±0.42 52.2 62.2±0.21 68.2±0.62 22.5 15.0±2.01 19.0±2.81 32.6 39.6±0.93 47.4±0.25
BART BASE 14.4 8.4±0.10 21.0±0.50 48.7 58.5±0.27 68.2±0.86 20.6 10.5±1.22 16.7±0.80 33.6 43.7±1.19 51.3±1.56
T5 BASE 15.2 4.9±0.21 27.9±0.60 55.9 66.9±0.25 72.5±0.28 22.5 18.0±0.46 18.0±3.95 42.3 24.7±0.66 53.2±0.18
Human 79.5 79.5 79.5 91.4 91.4 91.4 91.2 91.2 91.2 85.6 85.6 85.6

Bảng 2: Độ chính xác (%) của các PLMs khác nhau trên ba nhiệm vụ sử dụng các phương pháp thăm dò khác nhau. ZP: Thăm dò zero-shot. LP: Thăm dò tuyến tính. FT: Tinh chỉnh. Kết quả LP và FT là Trung bình ± độ lệch chuẩn qua ba lần thử ngẫu nhiên. Hiệu suất con người được thu được bởi những người bình thường được đào tạo với một vài mẫu.

### 4.1 Kết quả Tổng thể

Kết quả thí nghiệm tổng thể được trình bày trong Bảng 2, từ đó chúng tôi có thể quan sát rằng: (1) Tất cả PLMs có thể đạt hiệu suất không tầm thường (tốt hơn đoán ngẫu nhiên) trên tất cả các nhiệm vụ thăm dò với thăm dò zero-shot hoặc thăm dò tuyến tính, điều này cho thấy các PLMs hiện tại nắm bắt một kiến thức khái niệm nhất định với tiền huấn luyện trên các văn bản lớn. (2) Tuy nhiên, ngay cả với tinh chỉnh, độ chính xác của tất cả PLMs vẫn thấp hơn nhiều so với hiệu suất con người, điều này thúc đẩy những nỗ lực tiếp theo về tiền huấn luyện nhận thức khái niệm. (3) Độ chính xác của PLMs sử dụng các loại mục tiêu tiền huấn luyện khác nhau nhìn chung ở cùng mức. Nó gợi ý rằng bất kỳ mục tiêu tiền huấn luyện hiện tại nào cũng không có lợi thế đặc biệt trong việc hiểu các khái niệm và những cải thiện sâu hơn có thể đến từ thiết kế tiền huấn luyện có mục tiêu. Chúng tôi cung cấp một số phân tích trong các phần sau để giúp phát triển PLMs nhận thức khái niệm có mục tiêu.

### 4.2 Đánh giá Tương tự Khái niệm

Chúng tôi phân tích các dự đoán và hiệu suất của các PLMs khác nhau trên CSJ, và thấy rằng:

PLMs phân biệt tốt hơn các khái niệm thô. Như đề cập trong § 2.2, trong số 20 thực thể nhiễu, 5 trong số chúng là những nhiễu khó của các khái niệm chia sẻ cấp trên với khái niệm của thực thể truy vấn, và những cái khác là nhiễu dễ. Ví dụ, nếu thực thể truy vấn thuộc khái niệm Động vật có vú, các thực thể của khái niệm Chim là nhiễu khó và các thực thể của khái niệm Quốc gia là nhiễu dễ. Bảng 3 cho thấy thứ hạng nghịch đảo trung bình của hai loại nhiễu này. Chúng ta có thể thấy rằng các nhiễu khó được xếp hạng cao hơn đáng kể so với nhiễu dễ, điều này cho thấy PLMs nói chung phân biệt tốt hơn các khái niệm thô, như nói sự khác biệt giữa Động vật và Quốc gia, nhưng thất bại trong việc phân biệt các khái niệm chi tiết. Nó gợi ý rằng các phương pháp tương lai nên tập trung nhiều hơn vào cách nắm bắt những

BERT RoBERTa GPT-2 GPT-Neo BART T5
78.0 72.5 64.6 52.5 65.9 58.3

Bảng 4: Phần trăm (%) dự đoán dương tính sai trong tất cả dự đoán không chính xác trong kết quả tinh chỉnh của các PLMs khác nhau trên bộ dữ liệu CPJ.

Mô hình Nhiễu Khó Nhiễu Dễ
BERT BASE 25.1 15.7
RoBERTa BASE 25.3 15.7
GPT-2 BASE 21.1 17.0
GPT-Neo 125M 20.7 17.1
BART BASE 24.2 16.0
T5 BASE 24.6 15.9

Bảng 3: Thứ hạng nghịch đảo trung bình (%) cho nhiễu khó và nhiễu dễ trên CSJ trong kết quả thăm dò zero-shot của các PLMs khác nhau. Giá trị lớn hơn cho thứ hạng cao hơn.

khác biệt tinh tế giữa các khái niệm chi tiết.

### 4.3 Đánh giá Thuộc tính Khái niệm

Chúng tôi phân tích các trường hợp lỗi trên CPJ và thấy rằng:

Tính bắc cầu khái niệm thách thức PLMs. Bảng 2 cho thấy PLMs có thể đạt độ chính xác cấp độ mẫu cao, nhưng tất cả đều hoạt động kém trong đánh giá cấp độ chuỗi. Nó gợi ý rằng PLMs có thể tương đối tốt trong việc nhớ lại các thuộc tính cho các khái niệm cá nhân như nhớ lại các sự thật về thực thể trong thăm dò kiến thức thực tế, nhưng khó hiểu các mối quan hệ phân cấp của khái niệm và tính bắc cầu thuộc tính. Nó gợi ý rằng các công trình PLM tiếp theo không chỉ nên tập trung vào việc ghi nhớ kiến thức tốt hơn mà còn xem xét cách tổ chức kiến thức tốt hơn.

PLMs có ảo giác khái niệm. Đã được quan sát rằng PLMs thường xuyên tạo ra các đầu ra vô nghĩa và không đáng tin cậy, về mặt thực tế là không chính xác, và công trình trước đây (Rohrbach et al., 2018; Reiter, 2018; Ji et al., 2022) gọi hiện tượng này là ảo giác. Trong các thí nghiệm của chúng tôi, chúng tôi quan sát rằng nhiều trường hợp thất bại của PLMs trong nhiệm vụ CPJ có thể được mô tả là ảo giác khái niệm, tức là PLMs ảo tưởng rằng các khái niệm có những thuộc tính nhất định trong khi thực tế chúng không có. Như được trình bày trong Bảng 4, các lỗi của hầu hết PLMs chủ yếu đến từ việc đưa ra dự đoán dương tính sai, tức là coi các câu phát biểu thuộc tính khái niệm sai là đúng. Nó gợi ý rằng PLMs có xu hướng ảo tưởng các thuộc tính khái niệm sai là đúng thay vì không thể nhớ lại các thuộc tính khái niệm đúng, điều này thú vị và chúng tôi khám phá sâu hơn liệu có những tương quan giả mạo nhất định gây ra điều này hay không.

Sự xuất hiện cùng nhau của từ gây ra ảo giác khái niệm. Chúng tôi đưa ra giả thuyết rằng sự xuất hiện cùng nhau của từ trong các kho văn bản tiền huấn luyện gây ra ảo giác khái niệm của PLMs. Ví dụ, nếu một PLM đã thấy văn bản "Jufu Hall của ngôi đền đã được đưa vào Danh sách Theo dõi Di tích Thế giới năm 1998 bởi Quỹ Di tích Thế giới (WMF) ...bảo tồn trang trí sơn"³, nó có thể có nhiều khả năng

³https://en.wikipedia.org/wiki/Temple_of_Agriculture

dự đoán câu phát biểu "Di tích được sử dụng để trang trí" là đúng. Chúng tôi tìm thấy bằng chứng thực nghiệm hỗ trợ giả thuyết này. Đối với mỗi mẫu CPJ, để đánh giá sự xuất hiện cùng nhau của từ trong kho văn bản tiền huấn luyện, chúng tôi truy xuất tài liệu tương tự nhất của nó từ Wikipedia, là một kho văn bản được sử dụng rộng rãi trong tiền huấn luyện, với thuật toán BM25 (Robertson et al., 1995) được triển khai trong Whoosh (Mchaput, 2016), và sử dụng điểm BM25 của tài liệu đầu tiên được truy xuất làm chỉ số tỷ lệ xuất hiện cùng nhau của từ của mẫu CPJ này trong kho văn bản tiền huấn luyện. Chúng tôi chia các mẫu tiêu cực của bộ dữ liệu CPJ thành các tập con khác nhau theo điểm BM25 của chúng và quan sát tỷ lệ dương tính sai của dự đoán tinh chỉnh của BERT trên chúng. Kết quả được vẽ trong Hình 3, từ đó chúng ta có thể thấy rằng tỷ lệ dự đoán dương tính sai, cho thấy ảo giác khái niệm, có tương quan tích cực mạnh với điểm BM25, cho thấy sự xuất hiện cùng nhau của từ. Điều này gợi ý rằng ảo giác khái niệm của PLMs đến từ việc nắm bắt các tương quan giả mạo của sự xuất hiện cùng nhau của từ trong tiền huấn luyện, và công trình tiền huấn luyện tiếp theo sẽ khám phá để sửa chữa nó.

0 10 20 30 40
Điểm BM25 20 40 60 80 100 Tỷ lệ Dương tính Sai (%)
R2=0.81, p=2.19 × 10⁻⁸

Hình 3: Tỷ lệ dương tính sai của kết quả tinh chỉnh BERT trên các mẫu tiêu cực CPJ với điểm BM25 khác nhau. Kết quả của các PLMs khác được để trong phụ lục C.1.

### 4.4 Khái niệm hóa trong Ngữ cảnh

Chúng tôi phân tích các trường hợp lỗi trên CiC và thấy rằng:

PLMs khái niệm hóa các thực thể dựa quá nhiều vào ký ức. Trong CiC, chúng tôi thấy rằng nếu chúng tôi loại bỏ ngữ cảnh, PLMs vẫn có thể dự đoán một khái niệm có thể chính xác, điều này tương tự như các công trình trước đây (Petroni et al., 2019; Roberts et al., 2020; Cao et al., 2021) cho thấy PLMs ghi nhớ một kiến thức nhất định về các loại thực thể. Chúng tôi gọi những dự đoán này là dự đoán ngoài ngữ cảnh, có thể được coi là ký ức của PLMs thu được trong tiền huấn luyện. Điều chúng tôi đánh giá trong CiC là

BERT RoBERTa GPT-2 GPT-Neo BART T5
72.9 75.9 76.7 60.4 71.8 59.2

Bảng 5: Phần trăm (%) dự đoán ngoài ngữ cảnh trong tất cả dự đoán không chính xác trong kết quả thăm dò zero-shot của các PLMs khác nhau trên bộ dữ liệu CiC.

khả năng khái niệm hóa trong ngữ cảnh chứ không phải kiến thức được ghi nhớ về các khái niệm của thực thể, được đánh giá bởi CSJ. Do đó việc dựa vào ký ức và đưa ra dự đoán ngoài ngữ cảnh là sai cho việc xử lý CiC. Tuy nhiên, như được trình bày trong Bảng 5, trong hầu hết các trường hợp lỗi, PLMs khái niệm hóa sai các thực thể trong ngữ cảnh như các dự đoán ngoài ngữ cảnh mặc định. Nó chứng minh rằng PLMs khái niệm hóa các thực thể bằng cách dựa quá nhiều vào ký ức thay vì hiểu ngữ cảnh, điều này phản ánh sự thiếu hụt khả năng khái niệm hóa thực sự. Chúng tôi khuyến khích các công trình tương lai nghiên cứu liệu ký ức có ức chế việc học khái niệm hóa trong quá trình tiền huấn luyện hay không.

Hiểu phân cấp khó hơn phân định. Trong Bảng 6, chúng tôi phân tích hai loại lỗi trên nhiệm vụ CiC. Phân định cho thấy PLM chọn một chuỗi khái niệm sai cho thực thể đã cho và Cấp độ Sai cho thấy PLM chọn một khái niệm cấp độ sai trong chuỗi đúng. Trong phân tích, chúng tôi chỉ xem xét các thực thể có hơn một chuỗi khái niệm. Các lỗi Cấp độ Sai chiếm phần lớn, cho thấy hiểu phân cấp khái niệm khó hơn phân định cho PLMs và cách dạy PLMs hiểu nó là thiết yếu.

### 4.5 Phân tích về Quy mô Mô hình

Lấy cảm hứng từ những tiến bộ gần đây cho thấy lợi thế vượt trội của các mô hình quy mô lớn (Kaplan et al., 2020; Lester et al., 2021), chúng tôi khám phá cách quy mô mô hình ảnh hưởng đến kiến thức khái niệm của PLMs. Chúng tôi nghiên cứu họ của ba PLMs đại diện: BERT, GPT-2 và T5. Vì tinh chỉnh các PLMs cực lớn quá tốn kém về mặt tính toán, đối với các mô hình có hơn 2.5 tỷ tham số, thay vào đó chúng tôi áp dụng BitFit (Zaken et al., 2022), có thể đạt hiệu suất tương tự như tinh chỉnh (He et al., 2021) nhưng yêu cầu ít tính toán hơn nhiều. Kết quả được trình bày trong Hình 4, và chúng tôi có những quan sát sau: (1) PLMs quy mô lớn hơn nói chung đạt hiệu suất tốt hơn trên tất cả các nhiệm vụ thăm dò, điều này gợi ý rằng tăng quy mô mô hình có thể lưu trữ nhiều kiến thức khái niệm hơn.

Loại Lỗi Ngữ cảnh Chuỗi Khái niệm
Phân định Anh ấy được đề cử bởi Tổng thống Người –>Doanh nhân
29.0% Jimmy Carter vào tòa án. Người –>Nhà văn
Người –>Chính trị gia
Cấp độ Sai Dolly đang chạy trên đồng cỏ. Ngựa –>Động vật có vú –>Động vật
71.0%

Bảng 6: Ví dụ lỗi được lấy mẫu từ kết quả thăm dò zero-shot của BERT BASE trên bộ dữ liệu CiC. In nghiêng biểu thị thực thể. Gạch chân biểu thị dự đoán mô hình. Văn bản in đậm biểu thị câu trả lời.

Tuy nhiên, những cải thiện mà việc tăng quy mô mô hình mang lại nói chung là không đáng kể, đặc biệt là trên nhiệm vụ CiC, và những cải thiện trong kết quả thăm dò zero-shot và thăm dò tuyến tính không rõ ràng như trong tinh chỉnh, điều này đặt ra câu hỏi liệu những cải thiện tinh chỉnh có đến từ kiến thức nội tại của PLMs hay không. (2) Độ chính xác tinh chỉnh của T5 11B với 11 tỷ tham số, vẫn thấp hơn nhiều so với người bình thường, điều này chứng minh rằng việc có được kiến thức khái niệm khá thách thức đối với các phương pháp tiền huấn luyện hiện tại, điều này khuyến khích những nỗ lực tiếp theo trong việc xây dựng PLMs nhận thức khái niệm.

20 50 100 300 1,000 3,000 11,000
Triệu tham số 5 10 15 20 25 30 35 40 45 Độ chính xác (%)
Đánh giá Tương tự Khái niệm

20 50 100 300 1,000 3,000 11,000
Triệu tham số 50 55 60 65 70 75 80 Độ chính xác (%)
Đánh giá Thuộc tính Khái niệm

20 50 100 300 1,000 3,000 11,000
Triệu tham số 25 30 35 40 45 50 55 Độ chính xác (%)
Khái niệm hóa trong Ngữ cảnh

Thăm dò Zero-shot Thăm dò Tuyến tính Tinh chỉnh BERT GPT-2 T5

Hình 4: Độ chính xác (%) của các PLMs khác nhau ở các quy mô khác nhau. Độ chính xác trên CPJ là cấp độ mẫu.

## 5 Công trình Liên quan

Thăm dò Kiến thức Để hiểu sự thành công của PLMs, các công trình mở rộng khám phá để biết PLMs biết gì, và thấy PLMs có kiến thức ngôn ngữ mạnh (Liu et al., 2019a; Hewitt và Manning, 2019; Tenney et al., 2019b; Vulić et al., 2020). Hơn nữa, đã được chứng minh rằng PLMs có một kiến thức thế giới nhất định, thường được lưu trữ trong các cơ sở tri thức thế giới, như kiến thức về thực thể (Broscheit, 2019; Tenney et al., 2019a) và mối quan hệ của chúng (Petroni et al., 2019; Roberts et al., 2020; Jiang et al., 2020; Bouraoui et al., 2020; Zhong et al., 2021). Tuy nhiên, những khám phá này bị hạn chế trong phạm vi kiến thức thực tế, bỏ qua kiến thức khái niệm, điều này thiết yếu cho cả cơ sở tri thức (Wu et al., 2012; Ji et al., 2019) và trí tuệ (Carey, 1991; Collins và Olson, 2014). Do đó chúng tôi khám phá thăm dò kiến thức khái niệm trong bài báo này.

Kiến thức Khái niệm trong PLMs Các công trình trước đây cũng khám phá khái niệm trong PLMs (Michael et al., 2020; Talmor et al., 2020; Aspillaga et al., 2021; Dalvi et al., 2021), nghiên cứu các chủ đề tương tự về nguyên tắc với chúng tôi. Tuy nhiên, khái niệm mà họ đề cập về cơ bản là nghĩa từ. Họ tập trung vào liệu PLMs có khám phá nghĩa từ và nhận ra mối quan hệ phân cấp của chúng hay không. Trong khi trong công trình này, chúng tôi nghiên cứu các khái niệm được định nghĩa trong cơ sở tri thức để trừu tượng hóa các thực thể thế giới thực, hỗ trợ các ứng dụng rộng hơn (Lv et al., 2018; Zhou et al., 2021; Zeng et al., 2021), và thăm dò kiến thức về tương tự khái niệm và thuộc tính của khái niệm cũng như khả năng khái niệm hóa của PLMs.

## 6 Kết luận và Công trình Tương lai

Trong bài báo này, chúng tôi phân tích có hệ thống kiến thức khái niệm trong các PLMs hiện tại bằng cách xây dựng một benchmark thăm dò kiến thức khái niệm chất lượng cao (COPEN). Các thí nghiệm mở rộng cho thấy các PLMs hiện tại có một kiến thức khái niệm nhất định, nhưng tệ hơn đáng kể so với con người, ngay cả với hàng tỷ tham số. Chúng tôi tiếp tục thấy rằng PLMs thất bại trong việc phân biệt các khái niệm chi tiết và hiểu phân cấp khái niệm, và gặp phải ảo giác khái niệm gây ra bởi sự xuất hiện từ và thiên lệch ngoài ngữ cảnh. Trong tương lai, lấy cảm hứng từ các công trình truyền kiến thức thực tế, chúng tôi sẽ cố gắng phát triển PLMs có kiến thức khái niệm bằng cách khám phá các mục tiêu tiền huấn luyện nhận thức khái niệm và kiến trúc tăng cường kiến thức.

## Hạn chế

Trong phần này, chúng tôi thảo luận về những hạn chế của công trình này: (1) Benchmark COPEN. COPEN chỉ liên quan đến kho văn bản tiếng Anh, điều này hạn chế việc sử dụng benchmark cho PLMs được tiền huấn luyện trên các ngôn ngữ khác. Trong tương lai, chúng tôi sẽ xem xét nhiều ngôn ngữ hơn và xây dựng COPEN đa ngôn ngữ. (2) PLMs lớn. Chúng tôi không thí nghiệm trên các PLMs rất lớn, như GPT-3 (Brown et al., 2020) và PaLM (Chowdhery et al., 2022), do quyền truy cập hạn chế của chúng tôi. Thay vào đó chúng tôi tiến hành thí nghiệm trên T5 11B với 11 tỷ tham số. Kết quả thí nghiệm chứng minh rằng việc có được kiến thức khái niệm khá thách thức đối với các phương pháp tiền huấn luyện hiện tại, điều này thúc đẩy các mục tiêu tiền huấn luyện và kiến trúc mô hình nhận thức khái niệm. (3) Tác động môi trường. Trong bài báo này, chúng tôi tiến hành rất nhiều thí nghiệm với các PLMs khác nhau, một số trong đó thậm chí chứa vài tỷ tham số. Nó tiêu thụ lượng lớn năng lượng và gây ra lượng lớn khí thải carbon dioxide, gây ra ảnh hưởng tiêu cực đến môi trường của chúng ta (Strubell et al., 2019). Nhưng các thí nghiệm cần thiết để đưa ra kết luận đáng tin cậy và toàn diện. Chúng tôi hy vọng những phát hiện của chúng tôi có thể tạo điều kiện cho nghiên cứu sâu hơn về PLMs mạnh mẽ hơn với ít tham số hơn.

## Cân nhắc Đạo đức

Chúng tôi thảo luận về các cân nhắc đạo đức và tác động rộng hơn của công trình này trong phần này: (1) Sở hữu trí tuệ. Các kho văn bản Wikipedia, Simple Wikipedia và Wikidata được lấy từ bản dump Wikimedia⁴, được chia sẻ dưới giấy phép CC BY-SA 3.0⁵. DBpedia⁶ được chia sẻ dưới giấy phép CC BY-SA 3.0 và Giấy phép Tài liệu Miễn phí GNU⁷. Kho văn bản GenericsKB⁸ được chia sẻ dưới giấy phép CC BY 4.0⁹. Đây đều là các tài nguyên công khai và đã được thiết lập, được dự định để hỗ trợ nghiên cứu trí tuệ nhân tạo và NLP rộng rãi. Chúng tôi tin rằng những tài nguyên này được khử nhạy cảm và ẩn danh tốt. (2) Chú thích dữ liệu. Chúng tôi mời 19 nhà chú thích không có nền tảng chuyên môn để chú thích bộ dữ liệu của chúng tôi và tạo ra hiệu suất con người. Họ đều được thuê bởi các công ty sản xuất dữ liệu thương mại. Các nhà chú thích được mời được trả công bằng theo giờ làm việc và giá cả đã thỏa thuận. Các nhà chú thích đều được thông báo về cách dữ liệu sẽ được xử lý, sử dụng và phát hành, và điều này được xác nhận trong hợp đồng sản xuất dữ liệu. (3) Mục đích sử dụng. COPEN là một benchmark chất lượng cao được sử dụng để đánh giá kiến thức khái niệm trong PLMs và phát triển PLMs có kiến thức khái niệm. Các nhà nghiên cứu có thể sử dụng COPEN để đánh giá các mục tiêu nhận thức khái niệm mới và kiến trúc tăng cường kiến thức khái niệm. (4) Rủi ro lạm dụng. Xem xét COPEN được xây dựng trên cơ sở phạm vi hạn chế của các văn bản tự nhiên và các phương pháp thăm dò không thể tránh khỏi bị ảnh hưởng bởi một số tương quan giả mạo, hiệu suất đủ tốt trên COPEN không thể hoàn toàn đảm bảo rằng các phương pháp được phát triển thực sự hiểu khái niệm và không nên được sử dụng để hỗ trợ các tuyên bố thương mại và chính trị liên quan. (5) Kiểm soát rủi ro tiềm năng. Các văn bản trong COPEN đến từ dữ liệu công khai và không liên quan đến thông tin riêng tư, các chủ đề nhạy cảm và vấn đề xã hội. Ba nhiệm vụ trong COPEN cũng không liên quan đến các chủ đề nhạy cảm hoặc vấn đề xã hội. Chúng tôi kiểm tra thủ công một số mẫu được lấy ngẫu nhiên trong COPEN và không thấy thông tin nhạy cảm hoặc vấn đề rủi ro khác. Do đó chúng tôi tin rằng COPEN không tạo ra rủi ro bổ sung.

## Lời cảm ơn

Công trình này được hỗ trợ bởi Chương trình Nghiên cứu và Phát triển Lĩnh vực Trọng điểm của Tỉnh Quảng Đông (2019B010153002), Viện Guo Qiang, Đại học Thanh Hoa (2019GQB0003), và Phòng thí nghiệm Phao Noah của Huawei. Các tác giả cảm ơn tất cả các nhà đánh giá ẩn danh vì những bình luận và gợi ý chi tiết và có giá trị của họ. Các tác giả cũng cảm ơn tất cả các nhà chú thích vì những nỗ lực đáng kể của họ trong quá trình chú thích.

⁴https://dumps.wikimedia.org/
⁵https://creativecommons.org/licenses/by-sa/3.0/
⁶www.dbpedia.org
⁷https://www.gnu.org/licenses/fdl-1.3.html
⁸https://allenai.org/data/genericskb
⁹https://creativecommons.org/licenses/by/4.0/

## Tài liệu tham khảo

Guillaume Alain và Yoshua Bengio. 2017. Understanding intermediate layers using linear classifier probes. In Proceedings of ICLR.

Grigoris Antoniou và Frank Van Harmelen. 2004. A semantic web primer. MIT press.

Carlos Aspillaga, Marcelo Mendoza, và Alvaro Soto. 2021. Inspecting the concept knowledge graph encoded by modern language models. In Findings of ACL-IJCNLP, pages 2984–3000.

Sören Auer, Christian Bizer, Georgi Kobilarov, Jens Lehmann, Richard Cyganiak, và Zachary Ives. 2007. DBpedia: A nucleus for a web of open data. In The semantic web, pages 722–735. Springer.

Sumithra Bhakthavatsalam, Chloe Anastasiades, và Peter Clark. 2020. GenericsKB: A knowledge base of generic statements. CoRR, abs/2005.00660.

Sid Black, Leo Gao, Phil Wang, Connor Leahy, và Stella Biderman. 2021. GPT-Neo: Large Scale Autoregressive Language Modeling with Mesh-Tensorflow. Zenodo.

Zied Bouraoui, José Camacho-Collados, và Steven Schockaert. 2020. Inducing relational knowledge from BERT. In Proceedings of AAAI-IAAI-EAAI, pages 7456–7463.

Samuel Broscheit. 2019. Investigating entity knowledge in BERT with simple neural end-to-end entity linking. In Proceedings of CoNLL, pages 677–685.

Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, và Dario Amodei. 2020. Language models are few-shot learners. In Proceedings of NeurIPS, pages 1877–1901.

Boxi Cao, Hongyu Lin, Xianpei Han, Le Sun, Lingyong Yan, Meng Liao, Tong Xue, và Jin Xu. 2021. Knowledgeable or educated guess? Revisiting language models as knowledge bases. In Proceedings of ACL-IJCNLP, pages 1860–1874.

Susan Carey. 1991. Knowledge acquisition: Enrichment or conceptual change. The epigenesis of mind: Essays on biology and cognition, pages 257–291.

Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, Parker Schuh, Kensen Shi, Sasha Tsvyashchenko, Joshua Maynez, Abhishek Rao, Parker Barnes, Yi Tay, Noam Shazeer, Vinodkumar Prabhakaran, Emily Reif, Nan Du, Ben Hutchinson, Reiner Pope, James Bradbury, Jacob Austin, Michael Isard, Guy Gur-Ari, Pengcheng Yin, Toju Duke, Anselm Levskaya, Sanjay Ghemawat, Sunipa Dev, Henryk Michalewski, Xavier Garcia, Vedant Misra, Kevin Robinson, Liam Fedus, Denny Zhou, Daphne Ippolito, David Luan, Hyeontaek Lim, Barret Zoph, Alexander Spiridonov, Ryan Sepassi, David Dohan, Shivani Agrawal, Mark Omernick, Andrew M. Dai, Thanumalayan Sankaranarayana Pillai, Marie Pellat, Aitor Lewkowycz, Erica Moreira, Rewon Child, Oleksandr Polozov, Katherine Lee, Zongwei Zhou, Xuezhi Wang, Brennan Saeta, Mark Diaz, Orhan Firat, Michele Catasta, Jason Wei, Kathy Meier-Hellstern, Douglas Eck, Jeff Dean, Slav Petrov, và Noah Fiedel. 2022. PaLM: Scaling language modeling with pathways. CoRR, abs/2204.02311.

Jessica A. Collins và Ingrid R. Olson. 2014. Knowledge is power: How conceptual knowledge transforms visual cognition. Psychonomic Bulletin & Review, 21:843–860.

David Alan Cruse. 1986. Lexical semantics. Cambridge university press.

Fahim Dalvi, Abdul Rafae Khan, Firoj Alam, Nadir Durrani, Jia Xu, và Hassan Sajjad. 2021. Discovering latent concepts learned in BERT. In Proceedings of ICLR.

Stefan Decker, Sergey Melnik, Frank van Harmelen, Dieter Fensel, Michel C. A. Klein, Jeen Broekstra, Michael Erdmann, và Ian Horrocks. 2000. The semantic web: The roles of XML and RDF. IEEE Internet Comput., 4(5):63–74.

Jacob Devlin, Ming-Wei Chang, Kenton Lee, và Kristina Toutanova. 2019. BERT: Pre-training of deep bidirectional transformers for language understanding. In Proceedings of NAACL-HLT, pages 4171–4186.

Ramanathan V Guha, Dan Brickley, và Steve Macbeth. 2016. Schema.org: Evolution of structured data on the web. Communications of the ACM, 59(2):44–51.

Xu Han, Zhengyan Zhang, Ning Ding, Yuxian Gu, Xiao Liu, Yuqi Huo, Jiezhong Qiu, Liang Zhang, Wentao Han, Minlie Huang, et al. 2021. Pre-trained models: Past, present and future. Proceedings of AI Open.

Junxian He, Chunting Zhou, Xuezhe Ma, Taylor Berg-Kirkpatrick, và Graham Neubig. 2021. Towards a unified view of parameter-efficient transfer learning. arXiv preprint arXiv:2110.04366.

John Hewitt và Christopher D. Manning. 2019. A structural probe for finding syntax in word representations. In Proceedings of NAACL-HLT, pages 4129–4138.

Felix Hill, Roi Reichart, và Anna Korhonen. 2015. Simlex-999: Evaluating semantic models with (genuine) similarity estimation. Comput. Linguistics, 41(4):665–695.

Lei Ji, Yujing Wang, Botian Shi, Dawei Zhang, Zhongyuan Wang, và Jun Yan. 2019. Microsoft concept graph: Mining semantic concepts for short text understanding. Data Intelligence, 1(3):238–270.

Ziwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan Su, Yan Xu, Etsuko Ishii, Yejin Bang, Andrea Madotto, và Pascale Fung. 2022. Survey of hallucination in natural language generation. CoRR, abs/2202.03629.

Zhengbao Jiang, Frank F. Xu, Jun Araki, và Graham Neubig. 2020. How can we know what language models know. Trans. Assoc. Comput. Linguistics, 8:423–438.

Jared Kaplan, Sam McCandlish, Tom Henighan, Tom B Brown, Benjamin Chess, Rewon Child, Scott Gray, Alec Radford, Jeffrey Wu, và Dario Amodei. 2020. Scaling laws for neural language models. arXiv preprint arXiv:2001.08361.

Juan J. Lastra-Díaz, Josu Goikoetxea, Mohamed Ali Hadj Taieb, Ana García-Serrano, Mohamed Ben Aouicha, và Eneko Agirre. 2019. A reproducible survey on word embeddings and ontology-based methods for word similarity: Linear combinations outperform the state of the art. Eng. Appl. Artif. Intell., 85:645–665.

Brian Lester, Rami Al-Rfou, và Noah Constant. 2021. The power of scale for parameter-efficient prompt tuning. In Proceedings of EMNLP, pages 3045–3059.

Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Veselin Stoyanov, và Luke Zettlemoyer. 2020. BART: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension. In Proceedings of ACL, pages 7871–7880.

Nelson F. Liu, Matt Gardner, Yonatan Belinkov, Matthew E. Peters, và Noah A. Smith. 2019a. Linguistic knowledge and transferability of contextual representations. In Proceedings of NAACL-HLT, pages 1073–1094.

Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi, và Graham Neubig. 2021a. Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing. CoRR, abs/2107.13586.

Xiao Liu, Yanan Zheng, Zhengxiao Du, Ming Ding, Yujie Qian, Zhilin Yang, và Jie Tang. 2021b. GPT understands, too. CoRR, abs/2103.10385.

Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, và Veselin Stoyanov. 2019b. RoBERTa: A robustly optimized BERT pretraining approach. CoRR, abs/1907.11692.

Xin Lv, Lei Hou, Juanzi Li, và Zhiyuan Liu. 2018. Differentiating concepts and instances for knowledge graph embedding. In Proceedings of EMNLP, pages 1971–1979.

Deborah L McGuinness, Frank Van Harmelen, et al. 2004. Owl web ontology language overview. W3C recommendation, 10(10):2004.

Mchaput. 2016. Mchaput/whoosh: Pure-python full-text search library. GitHub.

Julian Michael, Jan A. Botha, và Ian Tenney. 2020. Asking without telling: Exploring latent ontologies in contextual representations. In Proceedings of EMNLP, pages 6792–6812.

Gregory Murphy. 2004. The big book of concepts. MIT press.

Jeffrey Pennington, Richard Socher, và Christopher D. Manning. 2014. Glove: Global vectors for word representation. In Proceedings of EMNLP, pages 1532–1543.

Fabio Petroni, Tim Rocktäschel, Sebastian Riedel, Patrick Lewis, Anton Bakhtin, Yuxiang Wu, và Alexander Miller. 2019. Language models as knowledge bases? In Proceedings of EMNLP-IJCNLP, pages 2463–2473.

Lutz Prechelt. 1996. Early stopping-but when? In Genevieve B. Orr và Klaus-Robert Müller, editors, Neural Networks: Tricks of the Trade, volume 1524 of Lecture Notes in Computer Science, pages 55–69. Springer.

Xipeng Qiu, Tianxiang Sun, Yige Xu, Yunfan Shao, Ning Dai, và Xuanjing Huang. 2020. Pre-trained models for natural language processing: A survey. Science China Technological Sciences, 63(10):1872–1897.

Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al. 2019. Language models are unsupervised multitask learners. OpenAI blog, 1(8):9.

Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, và Peter J. Liu. 2020. Exploring the limits of transfer learning with a unified text-to-text transformer. J. Mach. Learn. Res., 21:140:1–140:67.

Ehud Reiter. 2018. Hallucination in Neural NLG. Ehud Reiter's Blog.

Adam Roberts, Colin Raffel, và Noam Shazeer. 2020. How much knowledge can you pack into the parameters of a language model? In Proceedings of EMNLP, pages 5418–5426.

Stephen E Robertson, Steve Walker, Susan Jones, Micheline M Hancock-Beaulieu, Mike Gatford, et al. 1995. Okapi at TREC-3. Nist Special Publication Sp, 109:109.

Anna Rohrbach, Lisa Anne Hendricks, Kaylee Burns, Trevor Darrell, và Kate Saenko. 2018. Object Hallucination in Image Captioning. In Proceedings of EMNLP, pages 4035–4045.

John F Sowa. 1976. Conceptual graphs for a data base interface. IBM Journal of Research and Development, 20(4):336–357.

Emma Strubell, Ananya Ganesh, và Andrew McCallum. 2019. Energy and policy considerations for deep learning in NLP. In Proceedings of ACL, pages 3645–3650.

Fabian M. Suchanek, Gjergji Kasneci, và Gerhard Weikum. 2007. Yago: a core of semantic knowledge. In Proceedings of WWW, pages 697–706.

Alon Talmor, Yanai Elazar, Yoav Goldberg, và Jonathan Berant. 2020. oLMpics - On what Language Model Pre-training Captures. Trans. Assoc. Comput. Linguistics, 8:743–758.

Ian Tenney, Dipanjan Das, và Ellie Pavlick. 2019a. BERT Rediscovers the Classical NLP Pipeline. In Proceedings of ACL, pages 4593–4601.

Ian Tenney, Patrick Xia, Berlin Chen, Alex Wang, Adam Poliak, R. Thomas McCoy, Najoung Kim, Benjamin Van Durme, Samuel R. Bowman, Dipanjan Das, và Ellie Pavlick. 2019b. What do you learn from context? Probing for sentence structure in contextualized word representations. In Proceedings of ICLR.

Denny Vrandečić. 2012. Wikidata: A new platform for collaborative data collection. In Proceedings of WWW, pages 1063–1064.

Denny Vrandečić và Markus Krötzsch. 2014. Wikidata: A free collaborative knowledgebase. Communications of the ACM, 57(10):78–85.

Ivan Vulić, Edoardo Maria Ponti, Robert Litschko, Goran Glavaš, và Anna Korhonen. 2020. Probing Pretrained Language Models for Lexical Semantics. In Proceedings of EMNLP, pages 7222–7240.

Sandra R. Waxman và Dana Markow. 1995. Words as Invitations to Form Categories: Evidence from 12- to 13-Month-Old Infants. Cognitive Psychology, 29:257–302.

Michele Wellsby và Penny M. Pexman. 2014. Developing embodied cognition: Insights from children's concepts and language processing. Frontiers in Psychology, 5.

Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Remi Louf, Morgan Funtowicz, Joe Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest, và Alexander Rush. 2020. Transformers: State-of-the-art natural language processing. In Proceedings of EMNLP, pages 38–45.

Wentao Wu, Hongsong Li, Haixun Wang, và Kenny Q Zhu. 2012. Probase: A probabilistic taxonomy for text understanding. In Proceedings of the 2012 ACM SIGMOD International Conference on Management of Data, pages 481–492.

Elad Ben Zaken, Yoav Goldberg, và Shauli Ravfogel. 2022. Bitfit: Simple parameter-efficient fine-tuning for transformer-based masked language-models. In Proceedings of ACL, pages 1–9.

Kaisheng Zeng, Chengjiang Li, Yan Qi, Xin Lv, Lei Hou, Guozheng Peng, Juanzi Li, và Ling Feng. 2021. Encoding the meaning triangle (object, entity, and concept) as the semantic foundation for entity alignment. In Proceedings of WISE, pages 227–241.

Zexuan Zhong, Dan Friedman, và Danqi Chen. 2021. Factual probing is [MASK]: Learning vs. learning to recall. In Proceedings of NAACL-HLT, pages 5017–5033.

Jie Zhou, Shengding Hu, Xin Lv, Cheng Yang, Zhiyuan Liu, Wei Xu, Jie Jiang, Juanzi Li, và Maosong Sun. 2021. KACC: A multi-task benchmark for knowledge abstraction, concretization and completion. In Findings of ACL-IJCNLP, pages 1751–1763.

## Phụ lục

Mô hình model_name
BERT SMALL prajjwal1/bert-small
BERT MEDIUM prajjwal1/bert-medium
BERT BASE bert-base-uncased
BERT LARGE bert-large-uncased
RoBERTa BASE roberta-base
GPT-2 BASE gpt2
GPT-2 MEDIUM gpt2-medium
GPT-2 LARGE gpt2-large
GPT-2 XL gpt2-xl
GPT-Neo 125M EleutherAI/gpt-neo-125M
BART BASE facebook/bart-base
T5 SMALL t5-small
T5 BASE t5-base
T5 LARGE t5-large
T5 3B t5-3b
T5 11B t5-11b

Bảng 7: Các model_name tương ứng trong thư viện Transformers (Wolf et al., 2020) cho các PLMs khác nhau.

### A Chi tiết Triển khai

Chúng tôi sử dụng mã triển khai và các tham số tiền huấn luyện của PLMs được phát hành trong thư viện HuggingFace Transformers (Wolf et al., 2020) để chạy các thí nghiệm của chúng tôi. Các model_name chúng tôi sử dụng trong Transformers cho các PLMs khác nhau được trình bày trong Bảng 7. Chúng tôi chạy thí nghiệm cho các mô hình lớn (T5 3B và T5 11B) trên GPU NVIDIA V100, tiêu thụ khoảng 160 giờ GPU, và các PLMs khác trên GPU Nvidia GEFORCE RTX 3090, tiêu thụ khoảng 300 giờ GPU. Chúng tôi sẽ giới thiệu chi tiết triển khai cho thăm dò zero-shot (phụ lục A.1), thăm dò tuyến tính (phụ lục A.2), và tinh chỉnh (phụ lục A.3).

#### A.1 Thăm dò Zero-Shot

Như đã đề cập trong § 3.2, chúng tôi lấy các phần văn bản khác nhau của gợi ý vào tính toán chấm điểm. Bảng 8 cho thấy các phần văn bản được sử dụng bởi các PLMs khác nhau để chấm điểm gợi ý trên ba bộ dữ liệu.

#### A.2 Thăm dò Tuyến tính

Chúng tôi sử dụng đầu ra cuối cùng của các token cụ thể làm các đặc trưng được trích xuất bởi PLMs: [CLS] cho BERT; <s> cho RoBERTa; token cuối cùng cho GPT-2, GPT-Neo và BART; token đầu tiên cho T5. Sau đó chúng tôi tinh chỉnh một bộ phân loại tuyến tính nhẹ trên các đặc trưng cố định cho BERT, RoBERTa, GPT-2, GPT-Neo, BART và tinh chỉnh đầu phân loại từ vựng cuối cùng cho T5. Hơn nữa, chúng tôi reformulate các mẫu gốc thành định dạng văn bản sang văn bản cho T5, và định dạng đầu vào và đầu ra được trình bày trong Bảng 9.

Mô hình CSJ CPJ CiC
BERT BASE Thực thể Truy vấn Khái niệm Tất cả
RoBERTa BASE Thực thể Truy vấn Khái niệm Khái niệm
GPT-2 BASE Tất cả Tất cả Khái niệm
GPT-Neo 125M Tất cả Khái niệm Khái niệm
BART BASE Thực thể Truy vấn Khái niệm Khái niệm
T5 BASE Thực thể Truy vấn Khái niệm Tất cả

Bảng 8: Các phần văn bản được sử dụng để tính toán điểm số của gợi ý trong thăm dò zero-shot trên ba bộ dữ liệu. Tất cả: sử dụng độ khó hiểu âm của gợi ý làm điểm số. Ý nghĩa của các phần văn bản khác được trình bày trong Hình 2.

Siêu tham số Chúng tôi đặt tốc độ học là 1×10⁻³ và áp dụng dừng sớm (Prechelt, 1996) trên độ chính xác trên bộ dữ liệu phát triển với độ kiên nhẫn 20 epoch. Chúng tôi giữ các siêu tham số khác giống như trong Bảng 10.

#### A.3 Tinh chỉnh

Chúng tôi theo các phương pháp tinh chỉnh trong các bài báo gốc để tinh chỉnh BERT (Devlin et al., 2019), RoBERTa (Liu et al., 2019b), GPT-2 (Radford et al., 2019), GPT-Neo (Black et al., 2021), và BART (Lewis et al., 2020). Như trong phụ lục A.2, chúng tôi reformulate các mẫu gốc thành định dạng văn bản sang văn bản cho T5 (Raffel et al., 2020), và định dạng đầu vào và đầu ra được trình bày trong Bảng 9.

Siêu tham số Chúng tôi theo các siêu tham số được sử dụng nhiều nhất trong văn học trước đây. Các siêu tham số được trình bày trong Bảng 10. Và chúng tôi áp dụng dừng sớm (Prechelt, 1996) trên độ chính xác trên bộ dữ liệu phát triển.

Tinh chỉnh Hiệu quả Tham số cho Mô hình Lớn Do giới hạn tính toán, chúng tôi xem xét tinh chỉnh hiệu quả tham số cho các mô hình có hơn 2.5 tỷ tham số (T5 3B và T5 11B). Các công trình trước đây (He et al., 2021) đã chứng minh rằng các phương pháp tinh chỉnh hiệu quả tham số có thể tiết kiệm bộ nhớ GPU, tăng tốc huấn luyện cho PLMs, và đạt hiệu suất tương đương với tinh chỉnh tất cả tham số, đặc biệt là ở quy mô lớn. Do đó, chúng tôi áp dụng BitFit (Zaken et al., 2022) được triển khai bởi OpenDelta¹⁰ để tinh chỉnh các mô hình lớn.

¹⁰https://github.com/thunlp/OpenDelta

Đánh giá Tương tự Khái niệm
Truy vấn Gốc: Inter Milan
Ứng cử viên Gốc: Milan, Milan Fashion Week, Pohang Steelers, Series A
Nhãn Gốc: Pohang Steelers
Đầu vào Đã xử lý: chọn thực thể tương tự nhất với Inter Milan: (A) Milan, (B) Milan Fashion Week, (C) Pohang Steelers, (D) Series A.
Nhãn Đã xử lý: C

Đánh giá Thuộc tính Khái niệm
Câu phát biểu Gốc: Động vật có vú nuôi con bằng sữa.
Nhãn Gốc: Đúng
Đầu vào Đã xử lý: xác minh: Động vật có vú nuôi con bằng sữa.
Nhãn Đã xử lý: đúng

Khái niệm hóa trong Ngữ cảnh
Ngữ cảnh Gốc: Dolly đang chạy trên đồng cỏ.
Chuỗi Khái niệm: Ngựa –> Động vật có vú –> Động vật
Nhãn Gốc: Động vật
Đầu vào Đã xử lý: chọn khái niệm: <entity> Dolly </entity> đang chạy trên đồng cỏ. Chọn một khái niệm liên quan ngữ cảnh cho Dolly từ (A) Ngựa, (B) Động vật có vú, (C) Động vật.
Nhãn Đã xử lý: C

Bảng 9: Định dạng đầu vào và đầu ra được sử dụng để thăm dò tuyến tính và tinh chỉnh T5 trên ba bộ dữ liệu.

CSJ CPJ CiC
Những cái khác T5 Những cái khác T5 Những cái khác T5
Tốc độ Học 3×10⁻⁵ 1×10⁻³ 3×10⁻⁵ 1×10⁻³ 3×10⁻⁵ 1×10⁻³
Trọng số Phân rã 1×10⁻⁵ 1×10⁻⁵ 1×10⁻⁵ 1×10⁻⁵ 1×10⁻⁵ 1×10⁻⁵
Kích thước Batch 4 16 64 32 4 16
Tỷ lệ Khởi động 0.1 0.1 0.1 0.1 0.1 0.1

Bảng 10: Siêu tham số được sử dụng để tinh chỉnh PLMs trên COPEN.

### B Thảo luận Thêm về Kết quả Thí nghiệm

Trong phần này, chúng tôi thảo luận về một số quan sát chi tiết và thú vị.

CSJ CPJ CiC
Thực thể Truy vấn Thực thể Ứng cử viên Tất cả Khái niệm Câu trả lời Tất cả Khái niệm Tất cả
BERT SMALL 15.0 6.5 8.1 50.7 48.5 51.5 31.9 35.1
BERT MEDIUM 16.8 7.2 10.0 49.3 46.7 49.2 29.6 33.3
BERT BASE 20.3 7.5 11.3 49.4 47.2 49.2 32.6 37.6
BERT LARGE 22.3 8.2 13.4 50.5 47.6 50.4 31.1 36.9
RoBERTa BASE 15.5 5.1 10.0 49.2 46.7 47.6 31.4 25.5
GPT-2 BASE 2.9 6.6 7.9 49.4 48.4 51.5 32.3 31.1
GPT-2 MEDIUM 3.7 8.6 10.5 52.0 47.2 47.2 30.3 32.0
GPT-2 LARGE 4.6 9.0 11.3 51.8 47.3 47.2 34.3 33.8
GPT-2 XL 3.9 9.6 11.7 50.7 47.2 47.1 35.3 37.0
GPT-Neo 125M 2.6 6.6 7.9 52.2 47.2 47.6 32.6 28.8
BART BASE 14.4 5.0 7.1 48.7 48.4 48.0 33.6 27.4
T5 SMALL 11.6 5.4 6.5 52.5 47.6 53.2 34.9 40.1
T5 BASE 15.2 7.2 10.3 55.9 47.2 49.5 39.1 42.3
T5 LARGE 20.9 7.8 14.0 52.4 47.2 49.8 40.5 42.6
T5 3B 19.2 7.9 14.1 49.4 47.7 49.4 38.6 47.0
T5 11B 24.8 7.8 14.5 46.7 46.7 49.9 37.2 41.3

Bảng 11: Độ chính xác thăm dò zero-shot tổng thể (%) của việc sử dụng các phần văn bản khác nhau để chấm điểm gợi ý trên COPEN.

So sánh Phương pháp Tiền huấn luyện Trong Hình 2, chúng ta có thể quan sát rằng: (1) Đối với PLMs sử dụng cùng kiến trúc, T5 nói chung vượt trội hơn BART, và BERT nói chung vượt trội hơn RoBERTa. Sự khác biệt có thể đến từ các kho văn bản tiền huấn luyện khác nhau. (2) Autoregressive LMs (GPT-2, GPT-Neo) hoạt động kém hơn trên CSJ, điều này phù hợp với các quan sát về thăm dò kiến thức thực tế (Liu et al., 2021b). Vì chúng tôi là những người đầu tiên nghiên cứu kiến thức khái niệm trong PLMs, chúng tôi tập trung vào câu hỏi chung "các PLMs hiện tại hiểu kiến thức khái niệm ở mức độ nào?" và cung cấp kết luận tổng quát hơn trong bài báo. Chúng tôi để lại phân tích chi tiết và sâu sắc về một PLM cụ thể, ví dụ, phân tích theo lớp (Dalvi et al., 2021), trong các công trình tương lai.

So sánh Phương pháp Thăm dò Một cách trực quan, thăm dò zero-shot phản ánh giới hạn dưới của kiến thức PLMs (Jiang et al., 2020), trong khi thăm dò tuyến tính học một bộ phân loại tuyến tính cụ thể nhiệm vụ và hoạt động tốt hơn thăm dò zero-shot, và tinh chỉnh phản ánh giới hạn trên của kiến thức PLMs. Tuy nhiên, như được trình bày trong Hình 2, thăm dò tuyến tính đôi khi kém hiệu suất hơn thăm dò zero-shot, đặc biệt trong CSJ và CPJ cấp độ chuỗi. Lý do có thể là các khái niệm được sử dụng cho huấn luyện và kiểm tra là rời rạc, và thăm dò tuyến tính liên quan đến các tham số có thể huấn luyện, có thể học các tương quan giả mạo hoặc nông trên tập huấn luyện và do đó gặp khó khăn trong tổng quát hóa. Trong khi đó, tinh chỉnh vẫn hoạt động kém, điều này chứng minh rằng các PLMs hiện tại thiếu kiến thức khái niệm một cách có hệ thống.

So sánh CPJ Cấp độ Mẫu và Cấp độ Chuỗi Đối với cấp độ chuỗi, BERT hoạt động tốt nhất, nhưng đối với cấp độ mẫu hoạt động kém hơn T5. Lý do có thể là BERT hiểu tính bắc cầu khái niệm tốt hơn (tức là đưa ra dự đoán nhất quán hơn) nhưng lưu trữ ít thuộc tính khái niệm tổng thể hơn. Cần một phân tích kỹ lưỡng và toàn diện về hiện tượng này và chúng tôi để lại nó trong các công trình tương lai.

### C Kết quả Thí nghiệm Bổ sung

Bảng 11 cho thấy kết quả thăm dò zero-shot tổng thể trên COPEN. Kết quả thí nghiệm của thăm dò tuyến tính và tinh chỉnh được thu thập từ 3 lần thử ngẫu nhiên sử dụng seed 42, 43, 44. Bảng 12 cho thấy kết quả thăm dò tuyến tính và tinh chỉnh tổng thể trên COPEN. Và chúng tôi cung cấp kết quả bổ sung cho các thí nghiệm phân tích: phân tích ảo giác khái niệm trên bộ dữ liệu CPJ (phụ lục C.1), phân tích lỗi trên bộ dữ liệu CiC (phụ lục C.2), và phân tích về tránh các tạo tác bộ dữ liệu (phụ lục C.3).

Mô hình Thăm dò Tuyến tính Tinh chỉnh
Seed=42 Seed=43 Seed=44 Trung bình Std Seed=42 Seed=43 Seed=44 Trung bình Std

Đánh giá Tương tự Khái niệm
BERT SMALL 9.1 8.2 8.9 8.7 0.37 17.6 17.1 19.2 18.0 0.91
BERT MEDIUM 13.1 12.3 13.1 12.8 0.35 20.3 21.1 21.6 21.0 0.57
BERT BASE 16.3 16.3 15.8 16.1 0.21 28.5 26.6 26.9 27.3 0.86
BERT LARGE 16.5 16.9 17.3 16.9 0.31 28.7 30.2 29.5 29.5 0.61
RoBERTa BASE 11.8 12.0 12.3 12.0 0.21 22.8 21.6 22.4 22.3 0.51
GPT-2 BASE 4.6 4.1 4.1 4.3 0.24 19.7 20.1 20.3 20.1 0.23
GPT-2 MEDIUM 5.3 5.2 5.2 5.2 0.02 24.9 22.2 23.0 23.4 1.15
GPT-2 LARGE 4.0 6.8 5.6 5.5 1.13 22.2 24.0 23.4 23.2 0.77
GPT-2 XL 7.8 15.0 10.1 11.0 3.00 25.9 24.2 25.7 25.3 0.75
GPT-Neo 125M 11.1 10.7 11.2 11.0 0.20 18.8 18.4 17.8 18.3 0.42
BART BASE 8.5 8.3 8.4 8.4 0.10 20.4 21.0 21.7 21.0 0.50
T5 SMALL 4.8 4.8 4.7 4.8 0.05 10.1 17.6 6.9 11.5 4.48
T5 BASE 5.2 4.8 4.7 4.9 0.21 27.4 27.5 28.7 27.9 0.60
T5 LARGE 4.7 4.9 4.8 4.8 0.09 31.0 33.4 32.5 32.3 1.01
T5 3B 5.0 4.9 5.2 5.0 0.11 41.0 40.6 42.0 41.2 0.61
T5 11B 4.7 4.7 4.7 4.7 0.01 43.7 43.6 43.8 43.7 0.08

Đánh giá Thuộc tính Khái niệm
BERT SMALL 57.8 58.8 57.8 58.1 0.47 66.3 66.5 67.2 66.7 0.39
BERT MEDIUM 58.2 59.6 58.5 58.8 0.59 66.7 67.5 67.3 67.2 0.35
BERT BASE 61.2 61.9 61.5 61.6 0.28 66.8 68.3 69.2 68.1 0.98
BERT LARGE 61.6 61.7 59.0 60.8 1.26 67.8 69.6 71.2 69.5 1.41
RoBERTa BASE 61.7 62.0 61.9 61.9 0.13 71.4 72.7 71.8 72.0 0.54
GPT-2 BASE 65.2 63.3 66.0 64.8 1.14 71.3 69.5 70.5 70.4 0.72
GPT-2 MEDIUM 67.0 67.4 67.4 67.3 0.17 73.0 68.6 72.9 71.5 2.07
GPT-2 LARGE 66.2 67.8 66.8 66.9 0.62 74.5 72.7 73.4 73.5 0.74
GPT-2 XL 67.8 68.1 68.6 68.2 0.36 74.5 75.1 74.7 74.8 0.22
GPT-Neo 125M 61.9 62.4 62.1 62.2 0.21 68.9 68.4 67.4 68.2 0.62
BART BASE 58.8 58.2 58.7 58.5 0.27 68.5 69.2 67.1 68.2 0.86
T5 SMALL 67.7 67.2 65.0 66.6 1.18 71.3 72.2 72.1 71.9 0.40
T5 BASE 67.3 66.8 66.8 66.9 0.25 72.6 72.1 72.8 72.5 0.28
T5 LARGE 68.9 69.7 69.3 69.3 0.33 72.5 73.4 75.2 73.7 1.10
T5 3B 69.2 69.7 69.5 69.5 0.22 76.6 76.6 76.2 76.4 0.19
T5 11B 67.3 66.5 66.0 66.6 0.53 78.2 78.3 79.2 78.6 0.46

Khái niệm hóa trong Ngữ cảnh
BERT SMALL 32.4 32.7 33.3 32.8 0.38 44.6 47.0 48.4 46.6 1.55
BERT MEDIUM 31.6 31.2 31.1 31.3 0.22 49.4 49.1 49.8 49.4 0.31
BERT BASE 33.6 34.5 35.0 34.3 0.59 49.3 48.9 50.3 49.5 0.60
BERT LARGE 35.4 38.9 35.3 36.6 1.67 50.7 53.0 51.6 51.8 0.92
RoBERTa BASE 27.3 32.0 30.7 30.0 1.98 51.3 52.6 53.8 52.6 1.02
GPT-2 BASE 31.7 36.7 35.1 34.5 2.08 54.0 54.2 54.3 54.2 0.12
GPT-2 MEDIUM 29.3 25.6 29.1 28.0 1.69 54.6 54.5 54.9 54.7 0.14
GPT-2 LARGE 32.8 28.8 33.7 31.8 2.16 53.4 52.7 53.6 53.3 0.36
GPT-2 XL 27.7 32.2 29.9 29.9 1.83 52.6 54.4 54.4 53.8 0.88
GPT-Neo 125M 38.9 38.9 40.9 39.6 0.93 47.6 47.0 47.5 47.4 0.25
BART BASE 44.1 42.1 44.9 43.7 1.19 50.8 49.7 53.5 51.3 1.56
T5 SMALL 25.7 26.1 24.9 25.6 0.53 43.5 44.4 45.0 44.3 0.64
T5 BASE 25.5 23.9 24.7 24.7 0.66 53.2 53.3 52.9 53.2 0.18
T5 LARGE 24.3 24.3 25.3 24.6 0.49 52.4 56.9 57.2 55.5 2.21
T5 3B 26.7 27.5 26.8 27.0 0.35 59.2 57.5 55.9 57.5 1.35
T5 11B 25.1 26.6 26.4 26.0 0.66 56.7 58.7 56.5 57.3 0.97

Bảng 12: Độ chính xác thăm dò tuyến tính và tinh chỉnh tổng thể (%) của tất cả PLMs trên COPEN. Chúng tôi chạy thí nghiệm 3 lần sử dụng ba seed: 42, 43, 44. Trung bình: độ chính xác trung bình của ba lần thử; Std: độ lệch chuẩn.

#### C.1 Ảo giác Khái niệm trên CPJ

Hình 5 cho thấy tỷ lệ dương tính sai trên các tập con với điểm BM25 khác nhau cho các PLMs khác nhau. Chúng ta có thể quan sát rằng tỷ lệ dương tính sai, cho thấy ảo giác khái niệm, có tương quan tích cực mạnh với điểm BM25, cho thấy sự xuất hiện cùng nhau của từ.

Điểm BM25 20 40 60 80 100 Tỷ lệ Dương tính Sai (%)
R2=0.81, p=2.19 × 10⁻⁸
BERT BASE

Điểm BM25 10 20 30 40 50 60 Tỷ lệ Dương tính Sai (%)
R2=0.56, p=9.09 × 10⁻⁵
GPT2 BASE

Điểm BM25 10 20 30 40 50 60 70 80 90 Tỷ lệ Dương tính Sai (%)
R2=0.88, p=3.35 × 10⁻¹⁰
BART BASE

0 10 20 30 40
Điểm BM25 10 20 30 40 50 60 70 80 Tỷ lệ Dương tính Sai (%)
R2=0.83, p=8.03 × 10⁻⁹
RoBERTa BASE

0 10 20 30 40
Điểm BM25 10 20 30 40 50 60 Tỷ lệ Dương tính Sai (%)
R2=0.65, p=9.66 × 10⁻⁶
GPT-Neo BASE

0 10 20 30 40
Điểm BM25 10 20 30 40 50 60 70 Tỷ lệ Dương tính Sai (%)
R2=0.81, p=2.40 × 10⁻⁸
T5 BASE

Hình 5: Tỷ lệ dương tính sai của kết quả tinh chỉnh các PLMs khác nhau trên các mẫu tiêu cực của bộ dữ liệu CPJ với điểm BM25 khác nhau.

#### C.2 Phân tích Lỗi trên CiC

Bảng 13 cho thấy tỷ lệ các loại lỗi khác nhau. Chúng ta có thể quan sát rằng trong hầu hết các dự đoán sai, PLMs chọn các khái niệm của cấp độ sai. Nó cho thấy PLMs thiếu hiểu biết toàn diện về phân cấp khái niệm và thất bại trong việc khái niệm hóa các thực thể theo ngữ cảnh.

Mô hình Phân định Cấp độ Sai
BERT BASE 29.0% 71.0%
RoBERTa BASE 12.8% 87.2%
GPT-2 BASE 12.5% 87.5%
GPT-Neo 125M 11.9% 88.1%
BART BASE 11.5% 88.5%
T5 BASE 32.0% 68.0%

Bảng 13: Tỷ lệ các loại lỗi khác nhau của kết quả thăm dò zero-shot trên bộ dữ liệu CiC. Chúng tôi chỉ xem xét các thực thể có hơn một chuỗi khái niệm.

#### C.3 Phân tích về Tránh Tạo tác Bộ dữ liệu

Tạo tác bộ dữ liệu rò rỉ thông tin nông và khiến PLMs học các tương quan giả mạo thay vì thể hiện kiến thức nội tại. Khi xây dựng COPEN, chúng tôi tránh hai loại tạo tác:

Trùng lặp Từ vựng có nghĩa là truy vấn và câu trả lời có sự trùng lặp từ, có thể cho phép PLMs đưa ra dự đoán chính xác bằng cách sử dụng tương quan giả mạo mà không có kiến thức đúng. Ví dụ, trong CSJ, nếu thực thể truy vấn là Đại học Stanford và thực thể câu trả lời là Đại học California; trong CiC, nếu ngữ cảnh là Cô ấy tốt nghiệp từ Đại học Stanford và khái niệm câu trả lời là Đại học; chúng có trùng lặp từ vựng. Chúng tôi tiến hành thí nghiệm trên dữ liệu có trùng lặp từ vựng. Như được trình bày trong Bảng 14, trên dữ liệu có trùng lặp từ vựng, PLMs hoạt động tốt hơn nhiều. Nhưng điều này nên được hiểu là chúng học các manh mối nông bị rò rỉ bởi tạo tác vì chúng không thể đạt hiệu suất tương tự trên dữ liệu không có trùng lặp từ vựng.

Mô hình CSJ CiC
có LO không có LO có LO không có LO
BERT BASE 68.9 20.3 52.5 37.6
RoBERTa BASE 62.2 15.5 48.5 31.4
GPT-2 BASE 34.2 7.9 43.8 32.3
GPT-Neo 125M 34.0 7.9 52.4 32.6
BART BASE 75.9 14.4 53.2 33.6
T5 BASE 69.2 15.2 62.7 42.3

Bảng 14: Độ chính xác thăm dò zero-shot (%) của PLMs trên dữ liệu có trùng lặp từ vựng (có LO) và không có trùng lặp từ vựng (không có LO). Chúng tôi thu thập 688 và 1.200 mẫu có trùng lặp từ vựng cho CSJ và CiC, tương ứng.

lập. Do đó, chúng tôi lọc ra tất cả các mẫu có trùng lặp từ vựng trong COPEN để tránh loại tạo tác này.

Trùng lặp Khái niệm là cùng các khái niệm xuất hiện trong cả bộ dữ liệu huấn luyện và kiểm tra, có thể rò rỉ kiến thức khái niệm, tức là PLMs có thể học một số kiến thức từ dữ liệu huấn luyện. Trong COPEN, như đã đề cập trong § 2.1, chúng tôi chia các khái niệm cấp cao nhất khác nhau và các khái niệm con của chúng thành các tập con dữ liệu khác nhau, để tránh trùng lặp khái niệm. Để chứng minh thực nghiệm ảnh hưởng của trùng lặp khái niệm, chúng tôi phân chia lại ngẫu nhiên các bộ dữ liệu thành các tập huấn luyện, phát triển và kiểm tra cùng kích thước và xem hiệu suất tinh chỉnh trên phân chia mới.

Kết quả tinh chỉnh BERT được trình bày trong Hình 6, và kết quả tinh chỉnh và thăm dò tuyến tính cho tất cả PLMs được trình bày trong Bảng 15. Tinh chỉnh trên bộ dữ liệu có trùng lặp khái niệm đạt độ chính xác cao hơn nhiều, đặc biệt trên CSJ. Nó cho thấy rằng nếu chúng tôi không tránh trùng lặp khái niệm, PLMs có thể dễ dàng học kiến thức khái niệm từ dữ liệu huấn luyện và dẫn đến kết luận tích cực sai.

CSJ CPJ CiC
30 40 50 60 70 Độ chính xác (%)
không có trùng lặp khái niệm
có trùng lặp khái niệm

Hình 6: Độ chính xác tinh chỉnh của BERT BASE trên dữ liệu có và không có trùng lặp khái niệm.

Mô hình CSJ CPJ CiC
có CO không có CO có CO không có CO có CO không có CO

Thăm dò Tuyến tính
BERT BASE 20.0 16.1 64.1 61.6 46.5 34.3
RoBERTa BASE 12.3 12.0 65.9 61.9 45.4 30.0
GPT-2 BASE 5.2 4.3 67.2 64.8 39.0 34.5
GPT-Neo 125M 15.4 11.0 64.6 62.2 58.3 39.6
BART BASE 9.4 8.4 62.6 58.5 50.2 43.7
T5 BASE 4.7 4.9 68.8 66.9 33.9 24.7

Tinh chỉnh
BERT BASE 63.4 27.3 75.4 68.1 65.4 49.5
RoBERTa BASE 61.0 22.3 77.0 72.0 66.6 52.6
GPT-2 BASE 49.9 20.1 72.7 70.4 65.4 54.2
GPT-Neo 125M 44.3 18.3 71.2 68.2 62.5 47.4
BART BASE 54.7 21.0 73.1 68.2 67.4 51.3
T5 BASE 50.6 27.9 77.6 72.5 67.6 53.2

Bảng 15: Độ chính xác (%) của thăm dò tuyến tính và tinh chỉnh trên dữ liệu có trùng lặp khái niệm (có CO) và không có trùng lặp khái niệm (không có CO).

### D COPEN

Chúng tôi cung cấp giới thiệu chi tiết về COPEN.

#### D.1 Phân loại COPEN

Khái niệm Rời rạc Chúng tôi chia tất cả các khái niệm thành hai tập rời rạc: một tập chứa 11 khái niệm cấp cao nhất cùng với tất cả các khái niệm con của chúng để xây dựng bộ dữ liệu huấn luyện và phát triển,

#Khái niệm Khái niệm Cấp cao nhất
Huấn luyện & 248 Tổ chức, Tên, Giải thưởng, Phương tiện Giao thông, Màu sắc, Ngôn ngữ, Người,
Phát triển Kỳ nghỉ, Công việc, Tiền tệ, Nhóm Dân tộc
Kiểm tra 198 Cấu trúc Giải phẫu, Loài, Thực phẩm, Sự kiện, Khoảng thời gian, Chất Hóa học,
Địa điểm, Thiết bị, Bệnh tật, Hoạt động, Phân tử Sinh học, Mùa Thể thao

Bảng 16: Các khái niệm cấp cao nhất và số lượng khái niệm được sử dụng cho huấn luyện, phát triển và kiểm tra.

và tập khác chứa các khái niệm khác cho bộ dữ liệu kiểm tra. Như được trình bày trong Bảng 16, có 248 khái niệm bao gồm 11 khái niệm cấp cao nhất cho bộ dữ liệu huấn luyện và phát triển và 198 khái niệm bao gồm 12 khái niệm cấp cao nhất cho kiểm tra.

Phân cấp Khái niệm Chúng tôi trình bày các khái niệm cho bộ dữ liệu huấn luyện và phát triển trong Hình 7 và các khái niệm cho bộ dữ liệu kiểm tra trong Hình 8. Đối tượng là một khái niệm ảo để trực quan hóa và không được bao gồm trong tổng số 446 khái niệm.

#### D.2 Đánh giá Tương tự Khái niệm

Hiệu suất Con người Chúng tôi lấy mẫu 1.000 mẫu từ bộ dữ liệu kiểm tra và mời các nhà chú thích không có nền tảng ngôn ngữ học thực hiện nhiệm vụ CSJ. Tất cả các nhà chú thích đều được đào tạo với một vài mẫu trước khi đánh giá.

Lọc dựa trên Sự xuất hiện cùng nhau Chúng tôi lọc ra các mẫu mà các thực thể truy vấn và thực thể câu trả lời có liên kết cao, được ước tính bởi tương tự cosine của word embeddings Glove của chúng. Cụ thể, đối với một thực thể truy vấn, chúng tôi lấy mẫu 5 thực thể câu trả lời và chọn thực thể có liên kết thấp nhất với thực thể truy vấn làm thực thể câu trả lời. Sau đó chúng tôi chọn các thực thể nhiễu lặp đi lặp lại theo các quy tắc: (1) Lấy mẫu một thực thể nhiễu, nếu thực thể có liên kết cao hơn với thực thể truy vấn so với thực thể câu trả lời, thì chọn thực thể nhiễu làm thực thể ứng cử viên. (2) Nếu không, chọn thực thể nhiễu làm thực thể ứng cử viên với xác suất 20%, nếu không bắt đầu vòng lặp tiếp theo cho đến khi số lượng thực thể nhiễu đạt 20.

#### D.3 Đánh giá Thuộc tính Khái niệm

Chú thích Con người Chúng tôi mời các nhà chú thích không có nền tảng ngôn ngữ học kiểm tra liệu các mẫu có được gán nhãn chính xác, đúng ngữ pháp và mô tả các thuộc tính khái niệm hay không. Tất cả các nhà chú thích đều được đào tạo tốt và được yêu cầu vượt qua một vòng đánh giá trước khi chú thích. Các mẫu ban đầu được gán nhãn sai được chú thích 4 lần, và các mẫu khác được chú thích một lần. Trong quá trình chú thích, một tác giả của bài báo và một nhà chú thích có kinh nghiệm khác riêng biệt lấy mẫu 10% các mẫu để kiểm tra chất lượng chú thích. Tiêu chí chấp nhận của chú thích là tỷ lệ lỗi chú thích rõ ràng trong các mẫu được lấy (ví dụ, gán nhãn câu phát biểu Mặt trời có hai mắt là đúng) không vượt quá 3%, và tỷ lệ thống nhất giữa các nhà chú thích vượt quá 85% cho các mẫu được chú thích 4 lần. Kết quả biểu quyết đa số của các mẫu được chú thích 4 lần cùng với các mẫu được chú thích một lần tạo thành bộ dữ liệu CPJ.

Hiệu suất Con người Chúng tôi sử dụng 2.159 mẫu được chú thích 4 lần trong bộ dữ liệu kiểm tra để đánh giá hiệu suất con người. Chúng tôi tiến hành đánh giá 4 vòng: lấy kết quả biểu quyết đa số của 3 nhà chú thích làm nhãn và người còn lại làm dự đoán con người để tính độ chính xác của vòng. Độ chính xác trung bình của 4 vòng được báo cáo như độ chính xác con người trên bộ dữ liệu CPJ.

#### D.4 Khái niệm hóa trong Ngữ cảnh

Chú thích Con người Chúng tôi mời các nhà chú thích không có nền tảng ngôn ngữ học chú thích bộ dữ liệu. Để đảm bảo chất lượng, tất cả các nhà chú thích đều được đào tạo tốt và được yêu cầu vượt qua một vòng đánh giá trước khi chú thích. Tất cả các mẫu được chú thích bốn lần. Hơn nữa, trong quá trình chú thích, một tác giả của bài báo và một nhà chú thích có kinh nghiệm khác riêng biệt lấy mẫu 10% các ví dụ để kiểm tra chất lượng chú thích. Tiêu chí chấp nhận của chú thích là tỷ lệ lỗi chú thích rõ ràng (ví dụ, Chọn Ngựa cho Dolly theo ngữ cảnh Dolly đang chạy trên đồng cỏ.) không vượt quá 3%, và tỷ lệ thống nhất giữa các nhà chú thích vượt quá 80%. Kết quả biểu quyết đa số của 4 kết quả chú thích tạo thành bộ dữ liệu CiC cuối cùng.

Hiệu suất Con người Chúng tôi sử dụng tất cả các mẫu trong bộ dữ liệu kiểm tra, được chú thích 4 lần, để đánh giá hiệu suất con người. Chúng tôi tiến hành đánh giá 4 vòng: lấy kết quả biểu quyết đa số của 3 nhà chú thích làm nhãn và người còn lại làm dự đoán con người để tính độ chính xác của vòng. Độ chính xác trung bình của 4 vòng là độ chính xác con người.

Hình 7: Phân loại khái niệm cho bộ dữ liệu huấn luyện và phát triển. Đối tượng là một khái niệm ảo không có mẫu được chú thích.

Hình 8: Phân loại khái niệm cho bộ dữ liệu kiểm tra. Đối tượng là một khái niệm ảo không có mẫu được chú thích.

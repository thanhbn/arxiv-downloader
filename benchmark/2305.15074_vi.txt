Hình 2: Hiệu suất của GPT-4 trên một tập con ngẫu nhiên của MATH, MMLU-Physics, Chemistry, Math, JEEBENCH

4.3 Phân tích Lỗi của Phản hồi Hệ thống
Để đánh giá các điểm yếu của GPT-4, chúng tôi tiến hành kiểm tra thủ công các lỗi mà nó mắc phải trong chuỗi suy luận của mình. Chúng tôi thực hiện nghiên cứu này trên các lỗi được GPT-4+CoT mắc phải trên một tập con ngẫu nhiên của 100 vấn đề. Điểm số thu được trên tập con này là 27.25. Chúng tôi đặt các câu hỏi sau về phản hồi mô hình cho mỗi trường hợp vấn đề:

1. GPT-4 có thể truy xuất các khái niệm/sự kiện cần thiết để giải quyết vấn đề không? Không thể làm điều này góp phần vào lỗi khái niệm.
2. Nếu các khái niệm liên quan được truy xuất, chúng có được cụ thể hóa chính xác như phương trình/ràng buộc không? Những điều này góp phần vào lỗi cụ thể hóa.
3. Thao tác đại số & số học có chính xác không? Những điều này góp phần vào lỗi tính toán.

Tham khảo Hình 4 để minh họa cho mỗi loại lỗi⁴. Trong một trường hợp, chúng tôi thấy rằng GPT-4 hiểu nhầm câu hỏi. Kết quả tổng thể của phân tích này được hiển thị trong Bảng 3.

[THIS IS TABLE: Bảng 3 showing error types and counts]
Loại Lỗi | Số lượng
Lỗi Khái niệm | 34
Lỗi Tính toán | 30
Lỗi Cụ thể hóa | 15
Hiểu nhầm Vấn đề | 1
Hoàn hảo | 20

Phân tích lỗi của chúng tôi cho thấy hầu hết các lỗi được gây ra bởi không thể truy xuất các khái niệm (34 trong số 80), điều quan trọng để tạo ra tiến bộ trong lời giải, hoặc do lỗi tính toán (30 trong số 80). Hơn nữa, trong 20 câu hỏi, nơi câu trả lời là chính xác (trong số 27), lời giải thích cũng chính xác. tức là, 28% thời gian, mô hình đưa ra câu trả lời chính xác với lý do sai.

4.4 GPT-4 có thể tìm và sửa lỗi của mình không?
GPT-4 có thể được sử dụng để chấm điểm đầu ra của chính nó không? Một người chấm điểm tốt nên có thể phát hiện lỗi trong lời giải. Việc sử dụng LLM để phê bình đầu ra của chính nó đã được đề xuất gần đây bởi nhiều công trình (Shinn et al., 2023; Madaan et al., 2023) và đã cho thấy cải thiện trên một số bộ dữ liệu. Một người xác minh tốt nên có thể bắt và sửa tất cả lỗi. Ngay cả khi câu trả lời cuối cùng đúng, không nhất thiết các bước suy luận trung gian phải chính xác.

Chúng tôi đưa ý tưởng tự phê bình vào thử nghiệm trên JEEBENCH. Sau khi phản hồi CoT đã được tạo ra, chúng tôi gợi ý một thể hiện GPT-4 khác bằng cách đầu tiên mô tả vấn đề, lời giải của GPT và sau đó thêm vào hướng dẫn: "Tìm vấn đề (nếu có) với các lời giải đã cho. Nếu có bất kỳ lỗi nào, hãy sửa nó và đưa ra câu trả lời mới."

Chúng tôi đánh giá lại câu trả lời mới được GPT-4 đề xuất. Kết quả rõ ràng cho thấy rằng cách tiếp cận này không dẫn đến cải thiện. Thực tế, nó dẫn đến kết quả kém hơn so với GPT-4+CoT và hiệu suất giảm từ 35% xuống 33.9%.

Để phát triển hiểu biết sâu hơn về các sửa chữa được người xác minh GPT-4 đề xuất, kiểm tra thủ công được thực hiện. Chúng tôi sử dụng cùng tập con 100 vấn đề được chọn trước đó để phân loại các loại lỗi. Đối với mỗi lời giải được tạo ra và chỉnh sửa được đề xuất, chúng tôi đặt các câu hỏi sau:

• Người xác minh có thể tìm thấy vấn đề trong lời giải không?
• Người xác minh có thể sửa vấn đề nếu nó tìm thấy chúng không?
• Vấn đề được xác định bởi người xác minh có thực sự là một vấn đề hợp lệ không?

[THIS IS TABLE: Bảng 4 showing verifier response breakdown]

Kết quả của chúng tôi có thể thấy trong Bảng 4. Rõ ràng là, trái với quan sát trong các công trình khác, trên JEEBENCH, GPT-4 chủ yếu (46/80 = 57.5%) không thể tìm thấy lỗi trong các lời giải mà nó đề xuất. Ngay cả khi nó có thể, nó không thể sửa chúng. Chỉ trong 2 trên 80 câu hỏi, GPT-4 đã có thể đưa ra chỉnh sửa có ý nghĩa cho lời giải có lỗi, điều này được bù đắp quá mức bởi các lời giải mà nó làm xuống cấp bằng cách đề xuất chỉnh sửa cho các phần của lời giải đã đúng. Hình 5 cung cấp ví dụ về lỗi được người xác minh mắc phải. Phản hồi hoàn chỉnh cho những điều này cùng với các ví dụ khác có thể được tìm thấy trong Phụ lục A.5. Thí nghiệm này đặt ra một câu hỏi thú vị: đối với loại vấn đề nào thì tự phê bình (không) hữu ích? Có thể thú vị khi tìm hiểu các phương pháp sử dụng người xác minh đã học (Arora và Kambhampati, 2023; Lightman et al., 2023).

4.5 So sánh với hiệu suất con người
Kỳ thi JEE chứa chấm điểm âm, ví dụ, các câu hỏi MCQ đúng đơn được trao điểm +3 khi đúng, -1 nếu trả lời sai và 0 khi không trả lời. Đối với MCQ Đa Đúng, điểm +4 được trao khi tất cả các tùy chọn được bao gồm trong câu trả lời cuối cùng. Nếu bất kỳ tùy chọn nào sai, -2 được trao. Nếu một số tùy chọn đúng, +1 được trao cho mỗi tùy chọn đúng. Các kỹ năng cần thiết cho thí sinh để tối đa hóa điểm số của mình bao gồm có thể đánh giá độ tin cậy của chính mình trong phản hồi của họ và có thể quyết định có trả lời hay không dựa trên mức độ tin cậy. Phụ thuộc vào kỹ năng trước đó, kỹ năng sau đây là một tính toán lý thuyết quyết định đơn giản dưới sự không chắc chắn.

4.5.1 Quyết định có trả lời hay không
Để đạt được điểm số tốt trong kỳ thi, điều quan trọng là đảm bảo rằng mô hình không trả lời khi nó không chắc chắn về lời giải của mình. LLMs có thể đánh giá rủi ro này và lập kế hoạch tương ứng khi được gợi ý với sơ đồ chấm điểm không? Để điều tra điều này, chúng tôi gợi ý mô hình với sơ đồ chấm điểm chính xác cho mỗi loại câu hỏi MCQ cùng với tuyên bố vấn đề, và sau đó yêu cầu tạo ra câu trả lời hoặc bỏ qua câu hỏi hoàn toàn. Gợi ý hoàn chỉnh có trong Phụ lục A.6. Chúng tôi chạy lại suy luận trên tất cả các vấn đề với những gợi ý này cho tất cả các câu hỏi MCQ. Kết quả có thể thấy trong Bảng 5.

[THIS IS TABLE: Bảng 5 showing comparison of marks with and without marking scheme]

Kết quả cho thấy rằng gợi ý không hữu ích trong trường hợp này, và GPT-4 không thể quyết định hiệu quả khi nào không trả lời. Điều này phù hợp với quan sát được Valmeekam et al. (2022) đưa ra nơi cho thấy rằng LLMs có khả năng lập kế hoạch kém. Để đáp ứng, chúng tôi phát triển một phương pháp ngưỡng tin cậy hậu hoc trên các phản hồi tự nhất quán.

4.5.2 Hiệu chuẩn
Đối với MCQ đúng đơn & đa đúng, chúng tôi tính điểm tin cậy cho mỗi tùy chọn bằng cách tính tần suất tương đối của nó trong tập hợp các phản hồi. Lưu ý rằng thường xuyên, GPT-4 không thể trả lời câu hỏi hoàn toàn, hoặc đến kết luận không được hỗ trợ bởi bất kỳ tùy chọn nào (phản hồi "Không có"). Trong những trường hợp như vậy, chúng tôi không đếm đóng góp từ phản hồi này. Ví dụ, nếu phản hồi của mô hình trong 4 lần thử trong MCQ Đa Đúng là "AB", "Không có", "B", "AC", thì độ tin cậy cho các tùy chọn là A:1/2, B:1/2, C:1/4, D:0.

Hình 6 là đường cong hiệu chuẩn của GPT-4 trên JEEBENCH. Lỗi Hiệu chuẩn Tối đa (MCE) là 0.136 và lỗi hiệu chuẩn trung bình (ACE)⁵ là 0.098. Biểu đồ cho thấy rằng mô hình hơi quá tự tin ở độ tin cậy cao, vì độ chính xác thấp hơn ở mức độ tin cậy cao hơn, nhưng hơi thiếu tự tin ở độ tin cậy thấp và trung bình.

4.5.3 Ngưỡng với Tự Nhất quán
Mục tiêu của chúng tôi là quyết định có bao gồm một tùy chọn trong phản hồi cuối cùng hay không. Chúng tôi muốn tính toán một tham số τ sao cho một tùy chọn sẽ có trong phản hồi cuối cùng nếu độ tin cậy cho tùy chọn đó ít nhất là τ. Chúng tôi tính toán τsingle, τmultiple riêng biệt cho MCQ Đúng đơn và Đa đúng tương ứng. Chúng tôi tính điểm tin cậy cho phản hồi của GPT-4 đối với mỗi câu hỏi như trong Phần 4.5.2. Các câu hỏi từ 2016-2021 được chọn làm tập xác thực và từ 2022-2023 làm tập kiểm tra. Ngưỡng τsingle và τmultiple tốt nhất cho MCQ Đúng đơn và Đa đúng bằng tìm kiếm siêu tham số đơn giản. Hình 7 hiển thị biểu đồ điểm dương, âm và tổng trên tập xác thực trong phạm vi các giá trị có thể của τsingle và τmultiple. Giá trị tối ưu của τmultiple là 0.75 và của τsingle là 0.125. τsingle nhỏ hơn 0.25 cho thấy rằng việc bỏ phiếu đa số là chiến lược tốt nhất cho MCQ đúng đơn. Tuy nhiên, điều này không đúng đối với MCQ đa đúng, nơi ngưỡng τmultiple = 0.5 (như đã làm ban đầu) là không tối ưu. Chúng tôi giả định rằng các câu hỏi Số nguyên và Số không có chấm điểm âm. Phản hồi cuối cùng cho chúng được quyết định bằng bỏ phiếu đa số trên các phản hồi. Bảng 6 hiển thị điểm số với ngưỡng tối ưu trên tập kiểm tra. Chúng tôi thấy rằng không trả lời khi độ tin cậy nhỏ hơn ngưỡng làm tăng tổng điểm khoảng 4.3%.

[THIS IS TABLE: Bảng 6 showing scores with optimal thresholds on test set]

4.6 Ước tính hiệu suất so với con người
Cuối cùng, chúng tôi muốn ước tính hiệu suất của GPT-4 so với con người. Để làm điều này, chúng tôi sử dụng bài thi 2023 vì có xác suất nhiễm gần như không có. Bài thi 2023 được phát hành vào ngày 4 tháng 6 năm 2023 và chứa 65 câu hỏi dạng văn bản (còn lại 37 chứa hình ảnh). Tổng điểm trong kỳ thi là 360. Điểm số thu được bởi GPT-4 sau ngưỡng tin cậy trên MCQ và tổng hợp thường xuyên trên loại Số nguyên và Số là 49 trên 229. Giả định mức độ khó trung bình trong các câu hỏi không được bao gồm (vì chúng chứa hình ảnh) bằng những câu đã được, chúng tôi chuẩn hóa hiệu suất con người dự kiến từ 229 lên 360 cho nó tổng cộng 77 điểm trên 360. Dự đoán cho thấy điều này sẽ đặt GPT-4 khoảng phạm vi phần trăm 80-90. Kết quả của JEE Advanced 2023 cho thấy điểm 10% hàng đầu là khoảng 97/360 và điểm 20% hàng đầu là khoảng 70/360. Hình 8 cung cấp so sánh hiệu suất của LLMs cùng với hiệu suất con người của các ứng viên.

4.7 GPT-4 có ghi nhớ một số vấn đề không?
Trong thời đại tiền huấn luyện quy mô internet, rất khó để xác định liệu một bộ dữ liệu đã được sử dụng để huấn luyện một mô hình cụ thể. Tuy nhiên, chúng tôi đã cố gắng điều tra sự nhiễm của JEEBENCH. Điều này được thực hiện bằng (i) tìm kiếm các trường hợp trong JEEBENCH từ các corpus internet có sẵn công khai, (ii) gợi ý LLM để hoàn thành tuyên bố vấn đề khi được gợi ý với tiền tố của tuyên bố vấn đề. Cả hai điều tra này đều gợi ý chỉ nhiễm nhỏ (khoảng 6%). Mô tả chi tiết về nghiên cứu nhiễm của chúng tôi có thể được tìm thấy trong Phụ lục A.8.

GPT-4+CoT+SC đạt điểm 0.338 trên các câu hỏi Advanced 2023, không xa lắm so với hiệu suất tổng hợp 0.396 trên bộ dữ liệu còn lại. Cho rằng các câu hỏi 2023 không bị nhiễm, chúng tôi tin rằng mức độ nhiễm khá thấp, và hiệu suất của nó trên bộ dữ liệu này là dấu hiệu chính thức về khả năng suy luận hiện tại của nó. Cũng đáng chú ý là một số kỳ thi (ví dụ, JEE Advanced 2017) dễ hơn, và GPT-4 làm tốt hơn nhiều trên nó làm tăng điểm tổng hợp.

5 Thảo luận
Xu hướng hiệu suất chung chứng minh hiệu quả của dữ liệu chất lượng cao, tinh chỉnh hướng dẫn, RLHF và mở rộng tham số trong việc cải thiện khả năng suy luận của LLMs. Đối với nhiều vấn đề, GPT-4 có thể đưa ra phác thảo lời giải chính xác, giống con người ấn tượng cho mức độ suy luận liên quan trong các vấn đề. Tuy nhiên, phân tích của chúng tôi cũng tiết lộ các lĩnh vực chính nơi cần có tiến bộ. Mặc dù GPT-4 thực hiện suy luận logic và toán học hoàn hảo trong một số trường hợp, đôi khi nó mắc lỗi nghiêm trọng trong các bước tầm thường.

Lỗi trong truy xuất và áp dụng khái niệm gợi ý một câu hỏi nghiên cứu thú vị: Chúng ta có thể tăng cường LLM sao cho thế hệ của nó bị ràng buộc bởi sự trung thành với một tập hợp sự kiện không? Một hệ thống như vậy sẽ thể hiện tính mạnh mẽ trong suy luận, quan trọng đối với các nhiệm vụ tầm xa.

Các vấn đề Vật lý trong bài toán chuẩn thường đòi hỏi hiểu biết về suy luận không gian. Chúng tôi thấy rằng trong khi suy luận không gian của GPT-4 còn xa mới hoàn hảo. Phụ lục A.7 cung cấp một ví dụ nơi GPT-4 mắc lỗi có thể được quy cho sự bất lực suy luận không gian của nó. Với việc phát hành phiên bản đa phương thức của GPT-4, việc đánh giá khía cạnh này của các vấn đề Vật lý có thể dễ dàng hơn.

Cuối cùng, một LLM hiểu độ tin cậy của chính nó trong câu trả lời là một mảnh ghép quan trọng còn thiếu, như được làm nổi bật bởi các thí nghiệm của chúng tôi trong bối cảnh thi cử. Trình bao bọc hậu hoc đơn giản của chúng tôi cải thiện hiệu suất một chút trong khía cạnh này.

6 Kết luận
Chúng tôi trình bày một bài toán chuẩn giải quyết vấn đề thử thách để đánh giá các mô hình ngôn ngữ lớn. Chúng tôi thực hiện phân tích chi tiết về hiệu suất của các LLMs khác nhau trên bài toán chuẩn, và xác định các lĩnh vực cải thiện trong các LLMs hiện tại tốt nhất. Công trình của chúng tôi đặt ra các hướng nghiên cứu thú vị như GPT tăng cường logic toán học, đánh giá đa phương thức trên GPT-4 và khả năng ra quyết định của GPT trong bối cảnh thi cử. Chúng tôi hy vọng rằng JEEBENCH hướng dẫn nghiên cứu trong tương lai về suy luận sử dụng LLMs. Mã và bộ dữ liệu của chúng tôi có sẵn tại https://github.com/dair-iitd/jeebench.

Lời cảm ơn
Chúng tôi cảm ơn Tiến sĩ Parag Singla và Văn phòng JEE vì đã giúp đỡ trong việc có được phê duyệt để sử dụng bộ dữ liệu cho mục đích nghiên cứu. Chúng tôi cảm ơn Rishabh Ranjan về các cuộc thảo luận xung quanh hiệu chuẩn và Mohd. Zaki vì sự giúp đỡ trong việc có được quyền truy cập OpenAI API cho công việc này. Công việc được hỗ trợ bởi các khoản tài trợ từ Google, Verisk, Microsoft, và Huawei, và học bổng chủ tịch Jai Gupta bởi IIT Delhi. Chúng tôi cảm ơn cơ sở HPC của IIT-D về các tài nguyên tính toán.

Hạn chế
Nhiễm là một vấn đề lớn trong thời đại các mô hình ngôn ngữ tiền huấn luyện đã được huấn luyện trên các corpus web lớn. Do đó, thực sự khó để xác định liệu một bộ dữ liệu đã được nhìn thấy. Xác định mức độ nhiễm cũng không dễ dàng, mặc dù chúng tôi nỗ lực để định lượng nó. Đánh giá so với con người cũng là một quá trình hơi thiếu sót do các hạn chế khác như áp lực thời gian trong quá trình thi cử. Ngoài ra, phân phối dữ liệu này được cố định vào Vật lý, Hóa học và Toán học tiền đại học. Có nhiều cấp độ và mức độ khó khăn hơn mà mô hình có thể được đánh giá mà chưa được kiểm tra như một phần của phân tích của chúng tôi.

--- TRANG 4 ---

[Continuing with remaining pages...]

Hình 3: Các trường hợp từ bộ dữ liệu từ mỗi môn học: Vật lý (Trên), Hóa học (Giữa), Toán (Dưới)

--- TRANG 5 ---

[THIS IS TABLE: Bảng 2 showing performance scores of various models across subjects and question types]

--- TRANG 6 ---

Hình 4: Hình cho thấy các loại lỗi khác nhau mà GPT-4 mắc phải trong phản hồi của nó. (i) (trên) thể hiện lỗi tính toán, nơi phép toán bình phương được thực hiện sai về mặt đại số. (ii) (giữa) phản hồi cho thấy lỗi khái niệm nơi mô hình không thể truy xuất các khái niệm liên quan cần thiết để giải quyết vấn đề (iii) (dưới) phản hồi là lỗi cụ thể hóa, nơi khái niệm đúng, tuy nhiên ứng dụng trong việc tính toán số electron cặp đơn độc trên Br trong BrF₅ là sai.

--- TRANG 7 ---

Hình 5: [Trên]: Câu hỏi nơi GPT-4 xác định một lỗi nhưng không thể sửa nó. Vấn đề và một phần phản hồi ở trên. Khối dưới chứa chỉnh sửa được GPT-4 đề xuất. Thao tác trong chỉnh sửa được đề xuất là sai về mặt toán học. [Dưới]: Câu hỏi nơi GPT-4 không thể xác định lỗi. Vấn đề và một phần phản hồi ở trên. Khối dưới chứa chỉnh sửa được GPT-4 đề xuất. Nó nên là log₂(2·4⁴) thay vì log₂(2·16⁴).

--- TRANG 8 ---

Hình 6: Biểu đồ hiệu chuẩn của GPT-4 trên các câu hỏi MCQ

Hình 7: Điểm số thu được trên các giá trị ngưỡng khác nhau trên câu hỏi loại Đúng Đơn (trên) và Đa Đúng (dưới) từ tập val, giá trị tối ưu là τsingle = 0.125 và τmultiple = 0.75

Hình 8: Biểu đồ hiển thị hiệu suất của các mô hình so với hiệu suất con người dự kiến.

--- TRANG 9 ---

Phụ lục
A.1 Phân phối theo chủ đề phụ của các câu hỏi trong JEEBENCH
Hình 9 cung cấp phân phối theo chủ đề của các vấn đề trong JEEBENCH cho mỗi môn học.

A.2 Ví dụ vấn đề từ JEEBENCH
Ở đây chúng tôi trình bày một vài vấn đề từ JEEBENCH cùng với lời giải được chuyên gia viết, với các khái niệm được làm nổi bật bằng màu vàng, cụ thể hóa của chúng được làm nổi bật bằng màu tím, và thao tác đại số cuối cùng được làm nổi bật bằng màu xanh lá. Xem Hình 10 cho Vấn đề Toán, Hình 11 cho vấn đề Vật lý và Hình 12 cho vấn đề Hóa học.

A.3 Gợi ý Chính xác cho các mô hình GPT
Đối với mỗi vấn đề, chúng tôi gợi ý mô hình với loại câu trả lời cần thiết và sau đó là gợi ý. Đối với các loại phản hồi khác nhau, các gợi ý là:

1. Đúng Đơn: Trong vấn đề này, chỉ một tùy chọn sẽ đúng. Đưa ra lời giải chi tiết và kết thúc lời giải với câu trả lời cuối cùng.

2. Đa Đúng: Trong vấn đề này, nhiều tùy chọn có thể đúng. Đưa ra lời giải chi tiết và kết thúc lời giải với câu trả lời cuối cùng.

3. Số nguyên: Trong vấn đề này, câu trả lời cuối cùng sẽ là một số nguyên không âm. Đưa ra lời giải chi tiết và kết thúc lời giải với câu trả lời cuối cùng.

4. Số: Trong vấn đề này, câu trả lời cuối cùng sẽ là một giá trị số. Đưa ra câu trả lời số chính xác đến chữ số thập phân thứ 2. Đưa ra lời giải chi tiết và kết thúc lời giải với câu trả lời cuối cùng.

Toàn bộ gợi ý bao gồm câu hỏi được thêm vào trước với gợi ý loại phản hồi. Một ví dụ là:

Trong vấn đề này, chỉ một tùy chọn sẽ đúng. Đưa ra lời giải chi tiết và kết thúc lời giải với câu trả lời cuối cùng.

Vấn đề: Một thanh gỗ đồng đều có khối lượng 1.6 kg và chiều dài l đặt theo cách nghiêng trên một bức tường thẳng đứng nhẵn có chiều cao h (< l) sao cho một phần nhỏ của thanh kéo dài ra ngoài bức tường. Lực phản ứng của tường lên thanh vuông góc với thanh. Thanh tạo góc 30° với tường và đáy của thanh ở trên sàn nhám. Phản ứng của tường lên thanh bằng về độ lớn với phản ứng của sàn lên thanh. Tỷ số h/l và lực ma sát f ở đáy thanh là g = 10 m/s²

(A) h/l = √3/16, f = 16√3/3 N
(B) h/l = 3/16, f = 16√3/3 N  
(C) h/l = 3√3/16, f = 8√3/3 N
(D) h/l = 3√3/16, f = 16√3/3 N

A.4 Lỗi được GPT-4 mắc phải
Ở đây chúng tôi trình bày một số lỗi được GPT-4 mắc phải.

A.4.1 Lỗi Khái niệm
Đây là một ví dụ về Lỗi Khái niệm

Tổng số x ∈ [0,1] phân biệt là bao nhiêu cho ∫₀ˣ t²/(1+t⁴) dt = 2x - 1?

Phản hồi GPT-4
Đầu tiên, chúng ta có thể lấy đạo hàm hai vế của phương trình theo x để loại bỏ tích phân. Sử dụng Định lý Cơ bản của Giải tích, chúng ta có:

d/dx ∫₀ˣ t²/(1+t⁴) dt = d/dx (2x-1)

x²/(1+x⁴) = 2

Đây là lỗi bởi vì nếu hai hàm bằng nhau tại một điểm, điều đó không có nghĩa là đạo hàm của chúng cũng bằng nhau.

Bây giờ, chúng ta muốn tìm số lượng nghiệm phân biệt cho x trong khoảng [0,1]. Hãy đầu tiên giải phương trình cho x:

x² = 2(1 + x⁴)
x² - 2x⁴ - 2 = 0

Đây là phương trình bậc bốn, và chúng ta có thể cố gắng tìm nghiệm của nó. Chú ý rằng x = 0 không phải là nghiệm, vì vậy chúng ta có thể chia cả hai vế cho x²:

1 - 2x² - 2x⁻² = 0

Bây giờ, cho y = x². Khi đó, chúng ta có:
1 - 2y - 2y⁻¹ = 0
2y² - y + 1 = 0

Đây là phương trình bậc hai theo y. Chúng ta có thể sử dụng công thức nghiệm để tìm nghiệm của nó:

y = (-(-1) ± √((-1)² - 4(2)(1))) / (2(2))
y = (1 ± √(1-8)) / 4

Vì biệt số âm (1 - 8 = -7), không có nghiệm thực cho y. Do đó, không có nghiệm thực cho x trong phương trình đã cho.

Vậy, tổng số x ∈ [0,1] phân biệt cho ∫₀ˣ t²/(1+t⁴) dt = 2x - 1 là 0.

--- TRANG 10 ---

Hình 9: Phân phối theo chủ đề của các vấn đề trong bộ dữ liệu của chúng tôi

Hình 10: Một vấn đề Toán

A.4.2 Lỗi Cụ thể hóa
Đây là một ví dụ về Lỗi Cụ thể hóa

Một thấu kính phẳng-lồi được làm từ vật liệu có chiết suất n. Khi một vật nhỏ được đặt 30 cm phía trước mặt cong của thấu kính, một ảnh có kích thước gấp đôi vật được tạo ra. Do phản xạ từ mặt lồi của thấu kính, một ảnh mờ khác được quan sát ở khoảng cách 10 cm từ thấu kính. Phát biểu nào sau đây đúng?

(A) Chiết suất của thấu kính là 2.5
(B) Bán kính cong của mặt lồi là 45 cm
(C) Ảnh mờ là thẳng và thực
(D) Tiêu cự của thấu kính là 20 cm

Phản hồi GPT-4

Hình 11: Một vấn đề Vật lý

Đầu tiên, hãy xem xét khúc xạ ánh sáng qua thấu kính. Vì ảnh được tạo có kích thước gấp đôi vật, chúng ta có thể nói rằng khoảng cách ảnh (v) gấp đôi khoảng cách vật (u). Vậy, v = 2u = 60 cm. Đây là ví dụ về cụ thể hóa sai. Phương trình được tạo ra không phù hợp với quy ước dấu phải được quan tâm cho các phương trình khác để hợp lệ.

Bây giờ, hãy sử dụng công thức nhà sản xuất thấu kính để tìm tiêu cự (f) của thấu kính:

1/f = (n-1)(1/R₁ - 1/R₂)

Vì thấu kính là phẳng-lồi, một mặt phẳng, và bán kính cong của nó (R₁) là vô hạn. Bán kính cong của mặt lồi (R₂) là âm vì nó lồi. Vậy, công thức trở thành:

1/f = (n-1)(0 - 1/(-R₂))
1/f = (n-1)(1/R₂)

Bây giờ, hãy sử dụng công thức thấu kính để liên hệ u, v, và f:

1/f = 1/u + 1/v

Thay các giá trị của u và v:

1/f = 1/30 + 1/60 = 3/60 = 1/20

Bây giờ, chúng ta có thể thay biểu thức cho 1/f từ công thức nhà sản xuất thấu kính:

(n-1)(1/R₂) = 1/20

Bây giờ, hãy xem xét phản xạ ánh sáng từ mặt lồi của thấu kính. Vì ảnh mờ được tạo ở khoảng cách 10 cm từ thấu kính, chúng ta có thể sử dụng công thức gương để liên hệ khoảng cách vật (u), khoảng cách ảnh (v'), và bán kính cong (R₂) cho mặt lồi:

1/u + 1/v' = 2/R₂

Thay các giá trị của u và v':

1/30 + 1/10 = 2/R₂
1/6 = 2/R₂

Bây giờ, chúng ta có thể giải cho R₂:
R₂ = 2/(1/6) = 12 cm

Bây giờ, chúng ta có thể thay giá trị của R₂ trở lại phương trình liên hệ n và R₂:

(n-1)(1/12) = 1/20

Giải cho n:
n = 1 + 12/20 = 1 + 3/5 = 8/5 = 1.6

Bây giờ, hãy phân tích các tùy chọn đã cho:

(A) Chiết suất của thấu kính là 2.5 - Sai, vì chúng ta tìm thấy chiết suất là 1.6.
(B) Bán kính cong của mặt lồi là 45 cm - Sai, vì chúng ta tìm thấy bán kính cong là 12 cm.
(C) Ảnh mờ là thẳng và thực - Đúng. Vì ảnh mờ được tạo do phản xạ từ mặt lồi, nó hoạt động như gương lồi. Đối với gương lồi, ảnh luôn thẳng và ảo.
(D) Tiêu cự của thấu kính là 20 cm - Sai, vì chúng ta tìm thấy tiêu cự là 1/20, là 0.05 cm.

Câu trả lời Cuối cùng: (C) Ảnh mờ là thẳng và thực.

--- TRANG 11 ---

A.4.3 Lỗi Tính toán
Đây là một ví dụ về lỗi tính toán.

Hai cuộn cảm L₁ (độ tự cảm 1mH, điện trở trong 3Ω) và L₂ (độ tự cảm 2mH, điện trở trong 4Ω), và một điện trở R (điện trở 12Ω) đều được nối song song qua pin 5V. Mạch được bật ở thời điểm t = 0. Tỷ số dòng điện tối đa với dòng điện tối thiểu (Imax/Imin) được rút từ pin là bao nhiêu?

Phản hồi GPT-4

Bước 1: Phân tích mạch tại t = 0
Tại t = 0, các cuộn cảm hoạt động như mạch ngắn (vì chúng chưa có thời gian để xây dựng bất kỳ từ trường nào). Do đó, dòng điện qua mỗi cuộn cảm được xác định bởi điện trở trong của chúng. Hãy gọi dòng điện qua L₁, L₂, và R là I₁, I₂, và IR tương ứng.

Sử dụng định luật Ohm, chúng ta có thể tìm các dòng điện này:

I₁ = 5V/3Ω = 5/3 A
I₂ = 5V/4Ω = 5/4 A  
IR = 5V/12Ω = 5/12 A

Tổng dòng điện được rút từ pin tại t = 0 là tổng của các dòng điện này:

Imax = I₁ + I₂ + IR = 5/3 + 5/4 + 5/12 = 20/12 A

Tính toán sai, nên là 40/12

Bước 2: Phân tích mạch ở trạng thái ổn định
Khi thời gian tiến tới vô hạn, các cuộn cảm sẽ hoạt động như mạch hở (vì từ trường của chúng đã đạt tối đa và không có dòng điện nào có thể chảy qua chúng nữa). Trong trường hợp này, dòng điện duy nhất chảy trong mạch là qua điện trở R. Sử dụng định luật Ohm, chúng ta có thể tìm dòng điện này:

Imin = 5V/12Ω = 5/12 A

Bước 3: Tìm tỷ số dòng điện tối đa với dòng điện tối thiểu
Bây giờ chúng ta có thể tìm tỷ số dòng điện tối đa với dòng điện tối thiểu:

Imax/Imin = (20/12 A)/(5/12 A) = 20/5 = 4

Vậy tỷ số dòng điện tối đa với dòng điện tối thiểu được rút từ pin là 4.

--- TRANG 12 ---

Hình 12: Một vấn đề Hóa học

A.5 GPT-4 xác minh phản hồi của chính nó
Hình 13 và 14 thể hiện các trường hợp khác nhau phát sinh khi GPT-4 phê bình đầu ra của chính nình.

Hình 13: GPT-4 xác định lời giải đúng là đúng.

A.6 GPT-4 quyết định khi nào thử
Để đánh giá liệu GPT-4 có thể quyết định có từ chối thử cho hình phạt âm vì sai, chúng tôi gợi ý nó với điều sau đây cho các câu hỏi MCQ Đúng Đơn.

Nếu câu trả lời sai, bạn sẽ bị trừ -1 điểm. Nếu câu trả lời đúng, bạn sẽ được +3 điểm. Nếu bạn không chắc chắn về câu trả lời, bạn có thể bỏ qua câu hỏi, và bạn sẽ được 0 điểm.

Điều sau đây được sử dụng cho MCQ Đa Đúng:

Nếu bất kỳ tùy chọn nào trong câu trả lời cuối cùng sai, bạn sẽ bị trừ -2 điểm. Nếu tất cả các tùy chọn đều đúng, bạn sẽ được +4 điểm. Nếu một số tùy chọn đúng, bạn sẽ được +1 cho mỗi tùy chọn đúng. Nếu bạn không chắc chắn về câu trả lời, bạn có thể bỏ qua câu hỏi, và bạn sẽ được 0 điểm.

Hình 14: GPT-4 xác định bước đúng là sai và làm cho nó không chính xác

A.7 GPT-4 có thể suy luận không gian không
Hình 15 và 16 hiển thị một ví dụ vấn đề mà phản hồi của GPT-4 cho thấy sự bất lực cụ thể hóa các khái niệm vật lý không gian.

A.8 JEEBENCH có bị nhiễm không?
Chúng tôi lưu ý rằng một số trang web trên internet thực sự cung cấp các vấn đề và lời giải cho kỳ thi JEE (ví dụ, ở đây). Do đó, có thể tìm thấy câu hỏi và câu trả lời trong quá trình huấn luyện quy mô web. Thật không may, điều này sẽ đúng đối với bất kỳ bộ dữ liệu nào đã được tạo từ các câu hỏi từ các kỳ thi cạnh tranh như (Hendrycks et al., 2021b).

Để kiểm tra liệu bộ dữ liệu có thực sự bị nhiễm không, chúng tôi thực hiện phân tích cẩn thận theo các trục sau:

1. Chúng tôi tìm kiếm bộ dữ liệu C4 (Dodge et al., 2021) sử dụng 50 câu hỏi được lấy mẫu ngẫu nhiên từ Vật lý và Hóa học (chúng tôi không sử dụng câu hỏi Toán vì chúng thường nặng về LaTeX hơn và việc khớp chính xác sẽ khó tìm hơn). Chúng tôi không thể tìm thấy bất kỳ tài liệu nào chứa chuỗi con đủ dài từ các câu hỏi của bộ dữ liệu.

2. Chúng tôi tìm kiếm Chỉ mục URL Common Crawl http://urlsearch.commoncrawl.org/CC-MAIN-2023-23/ cho một số nguồn phổ biến phát hành lời giải đầy đủ hợp nhất cho các kỳ thi từ kỳ thi JEE. Trong số 500+ câu hỏi trong bộ dữ liệu của chúng tôi, chúng tôi có thể tìm thấy các trang web chứa lời giải của 30 câu hỏi [19 hóa học, 11 toán] trong chỉ mục Common Crawl 2023 mới nhất. Điều này ít hơn 6% bộ dữ liệu. Chúng tôi nghiên cứu tác động này có đối với đánh giá cuối cùng và quan sát thấy rằng việc loại bỏ những câu hỏi này chỉ dẫn đến giảm nhỏ trong điểm số tổng thể cho hầu hết các mô hình. Điều này cho thấy rằng sự nhiễm không ảnh hưởng lớn đến điểm số. Ví dụ, hiệu suất GPT4+CoT giảm từ 0.350 xuống 0.347. Hiệu suất trung bình trên 30 câu hỏi là 0.392 (điều này cũng có thể được quy cho tỷ lệ cao hơn nhiều của các câu hỏi hóa học mà GPT-4 giỏi hơn). Đáng chú ý là ngay cả khi những URL này có mặt trong Common Crawl, điều đó không có nghĩa là chúng đã được huấn luyện vì việc huấn luyện LLM thường không hoàn thành ngay cả 1 epoch trên dữ liệu tiền huấn luyện.

3. Vì các LLM độc quyền không tiết lộ công thức dữ liệu chính xác của họ, chúng tôi muốn xem liệu GPT-4 có ghi nhớ các câu hỏi có trong bộ dữ liệu không? Lưu ý rằng đây là một vấn đề rất thử thách. Được truyền cảm hứng bởi các phương pháp đương đại⁶, chúng tôi có cách tiếp cận heuristic sau: chúng tôi gợi ý GPT-4 với tiền tố của câu hỏi và hướng dẫn nó hoàn thành câu hỏi còn lại cung cấp bối cảnh của năm (ví dụ, Hoàn thành câu hỏi này từ JEE Advanced 2017). Trong điều này, chúng tôi kiểm tra liệu mô hình có thể tạo ra dữ liệu "bấp bênh", nghĩa là dữ liệu không thể được dự đoán từ bối cảnh. Ví dụ, một số dữ liệu số được cung cấp, hoặc các tùy chọn của câu hỏi. Chúng tôi sử dụng cùng 50 câu hỏi được lấy mẫu ở trên và gợi ý GPT-4. Đánh giá của chúng tôi cho thấy GPT-4 không thể tạo ra bất kỳ phản hồi nào như vậy.

Những sự kiện này cho thấy rằng mức độ nhiễm, nếu có, rất thấp và điều đó không có hại cho bài báo. Chúng tôi sẽ thêm những phân tích này trong bài báo cuối cùng để làm sáng tỏ bất kỳ nghi ngờ nào về khả năng nhiễm.

Chúng tôi cũng muốn nhấn mạnh rằng bài toán chuẩn của chúng tôi là động theo nghĩa là một tập hợp 40-50 vấn đề mới không bị nhiễm có thể được thêm vào hàng năm. Điều này sẽ cho phép kiểm tra đáng tin cậy khả năng giải quyết vấn đề của các LLMs trong tương lai khi ngày càng nhiều dữ liệu đi vào huấn luyện chúng.

--- TRANG 13 ---

Hình 15: Lỗi được GPT-4 mắc phải trong việc hiểu các khái niệm vật lý. Trong ví dụ này, dạng đúng của phương trình 1 nên là f = NA cos 30°. GPT-4 thất bại trong việc cụ thể hóa không gian khái niệm về hướng trong môi trường 2D.

Hình 16: Lỗi được GPT-4 mắc phải trong việc hiểu đường cong nào để lấy diện tích giữa. Ở đây nó đang lấy diện tích giữa đường cong và trục x. Tuy nhiên, câu hỏi có ý định giữa đường cong và đường x = y. Điều này cho thấy rằng GPT-4 có thể yếu trong suy luận 2D từ gợi ý dựa trên văn bản thuần túy.

Tài liệu tham khảo

[Followed by extensive bibliography in standard academic format - continuing with all the references listed in the original]

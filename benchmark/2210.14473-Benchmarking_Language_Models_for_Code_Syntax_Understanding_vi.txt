# Benchmarking Language Models for Code Syntax Understanding
# Đánh giá các Mô hình Ngôn ngữ trong Hiểu biết Cú pháp Mã

Da Shen1, Xinyun Chen2y, Chenguang Wang3y, Koushik Sen4, Dawn Song4
1University of Maryland, College Park,2Google Research, Brain Team
3Washington University in St. Louis,4University of California, Berkeley
dashen@terpmail.umd.edu ,xinyunchen@google.com ,chenguangwang@wustl.edu ,
{ksen,dawnsong}@cs.berkeley.edu

## Tóm tắt
Các mô hình ngôn ngữ được tiền huấn luyện đã thể hiện hiệu suất ấn tượng trong cả xử lý ngôn ngữ tự nhiên và hiểu biết chương trình, được biểu diễn đầu vào dưới dạng chuỗi token mà không mô hình hóa cấu trúc một cách rõ ràng. Một số nghiên cứu trước đây cho thấy các mô hình ngôn ngữ được tiền huấn luyện có thể nắm bắt các quy tắc cú pháp của ngôn ngữ tự nhiên mà không cần tinh chỉnh trên các tác vụ hiểu biết cú pháp. Tuy nhiên, hiện có hiểu biết hạn chế về mức độ tốt mà các mô hình được tiền huấn luyện hiểu cấu trúc mã. Trong nghiên cứu này, chúng tôi thực hiện đánh giá toàn diện đầu tiên về các mô hình được tiền huấn luyện tiên tiến nhất để xác định cấu trúc cú pháp của chương trình. Cụ thể, chúng tôi giới thiệu CodeSyntax, một bộ dữ liệu quy mô lớn gồm các chương trình được chú thích với các mối quan hệ cú pháp trong cây cú pháp trừu tượng tương ứng của chúng. Quan sát chính của chúng tôi là các mô hình ngôn ngữ hiện tại được tiền huấn luyện trên mã vẫn thiếu hiểu biết về cú pháp mã. Thực tế, các mô hình ngôn ngữ lập trình được tiền huấn luyện này không thể đạt được hiệu suất của các baseline đơn giản dựa trên offset vị trí và từ khóa. Chúng tôi cũng trình bày một benchmark ngôn ngữ tự nhiên để làm nổi bật sự khác biệt giữa ngôn ngữ tự nhiên và ngôn ngữ lập trình về hiểu biết cấu trúc cú pháp. Các phát hiện của chúng tôi chỉ ra những hạn chế chính của các phương pháp tiền huấn luyện hiện tại cho ngôn ngữ lập trình và gợi ý tầm quan trọng của việc mô hình hóa cấu trúc cú pháp mã.1

## 1 Giới thiệu
Việc tiền huấn luyện quy mô lớn các mô hình ngôn ngữ đã trở thành mô hình tiêu chuẩn cho nhiều tác vụ xử lý ngôn ngữ tự nhiên. Hơn nữa, các nghiên cứu gần đây cho thấy các mô hình được tiền huấn luyện trên một lượng lớn mã cũng đạt được hiệu suất cạnh tranh trên nhiều tác vụ, ví dụ như sinh mã và phân loại mã. Các tác vụ này có liên quan chặt chẽ đến các tác vụ ngôn ngữ tự nhiên (NL) trong công thức bài toán của chúng. Ngày nay, thực hành phổ biến để giải quyết các tác vụ lập trình này là sử dụng các kiến trúc mô hình ngôn ngữ và sơ đồ huấn luyện được thiết kế ban đầu cho NL. Nguyên tắc thiết kế của các mô hình ngôn ngữ neural này khác biệt đáng kể so với các hệ thống sinh chương trình dựa trên quy tắc cổ điển.

yTác giả liên hệ.
1Mã và bộ dữ liệu của chúng tôi có sẵn tại https://github.com/dashends/CodeSyntax.

[Hình 1: Ví dụ về các mối quan hệ cú pháp cho (a) ngôn ngữ tự nhiên (NL) và (b) ngôn ngữ lập trình (PL). Mỗi mối quan hệ được biểu diễn bằng một mũi tên. Các mối quan hệ trong PL đại diện cho cú pháp của mã theo cách tương tự như trong NL.]

[Hình 2: Xem trước so sánh hiệu suất mô hình trên các tác vụ hiểu biết cú pháp NL và PL. Các mô hình được tiền huấn luyện nắm bắt cú pháp NL tương đối tốt, nhưng hoạt động kém hơn trong hiểu biết cú pháp PL. Baseline Offset chọn token sử dụng offset vị trí cố định. Chúng tôi sử dụng cấu hình BERT-large và RoBERTa-base (tương ứng với cấu hình của CuBERT và CodeBERT). Biểu đồ hiển thị điểm top-1. Xem Bảng 3 và 4 để biết kết quả đầy đủ.]

Cụ thể, các mô hình ngôn ngữ neural lấy chương trình làm chuỗi token, trong khi các hệ thống sinh chương trình cổ điển sử dụng ngữ pháp ngôn ngữ và cấu trúc mã. Mặc dù có hiệu suất tiên tiến của các mô hình ngôn ngữ được tiền huấn luyện trên các tác vụ hiểu biết mã, những gì các mô hình này đã học được từ corpus mã vẫn chưa rõ ràng.

Trong nghiên cứu này, chúng tôi điều tra liệu việc tiền huấn luyện quy mô lớn có phải là tất cả những gì chúng ta cần cho học biểu diễn mã hay không. Cụ thể, chúng tôi tiến hành nghiên cứu có hệ thống đầu tiên để phân tích cách các mô hình ngôn ngữ được tiền huấn luyện hiểu cấu trúc cú pháp của chương trình. Để làm điều này, chúng tôi giới thiệu CodeSyntax, một benchmark quy mô lớn gồm các chương trình được chú thích với các mối quan hệ cú pháp giữa các token khác nhau. Các mối quan hệ cú pháp ground truth được trích xuất từ các cạnh trong cây cú pháp trừu tượng (AST) của chương trình. Hình 1 hiển thị một số ví dụ. Các mối quan hệ cú pháp này có chức năng tương tự như các mối quan hệ phụ thuộc cho NL, nơi nghiên cứu trước đây đã chứng minh rằng các head attention của mô hình ngôn ngữ được tiền huấn luyện có thể giúp xác định các loại mối quan hệ NL (Clark et al., 2019; Raganato et al., 2018). Để đo lường mức độ tốt mà các mô hình ngôn ngữ được tiền huấn luyện nắm bắt cấu trúc cú pháp mã, chúng tôi áp dụng phương pháp vào miền PL. Chúng tôi tập trung điều tra khả năng zero-shot của các phương pháp tiền huấn luyện hiện tại trong thí nghiệm và đánh giá các mô hình được tiền huấn luyện này mà không tinh chỉnh chúng trên benchmark của chúng tôi.

Chúng tôi đánh giá các mô hình ngôn ngữ được tiền huấn luyện tiên tiến nhất cho học biểu diễn mã, bao gồm CuBERT (Kanade et al., 2020) và CodeBERT (Feng et al., 2020). Một đặc điểm chung của các mô hình này là chúng chia sẻ cùng thiết kế kiến trúc dựa trên Transformer như các mô hình NL (Vaswani et al., 2017; Devlin et al., 2019). Điều này cho phép chúng tôi so sánh trực tiếp hiệu suất của chúng trong việc nắm bắt cấu trúc cú pháp. Chúng tôi trình bày xem trước các kết quả chính trong Hình 2. Quan sát chính của chúng tôi là tiền huấn luyện không đủ để học các mối quan hệ cú pháp trong mã. Đầu tiên, chúng tôi thấy rằng các mô hình được tiền huấn luyện trên mã không phải lúc nào cũng vượt trội hơn các mô hình được tiền huấn luyện chỉ trên corpus NL. Đáng ngạc nhiên, so với CodeBERT được huấn luyện trên cả corpus văn bản và mã, RoBERTa đạt được hiệu suất tốt hơn mà không huấn luyện trên bất kỳ mã nào với kiến trúc mô hình giống hệt. Điều này cho thấy việc tiền huấn luyện trên chương trình dưới dạng chuỗi token không giúp học các mối quan hệ cú pháp. Ngược lại, không có các mối quan hệ phụ thuộc, tiền huấn luyện vẫn cho phép các mô hình ngôn ngữ hiểu cú pháp NL ở một mức độ nào đó.

Hơn nữa, đối với hiểu biết cú pháp mã, các mô hình được tiền huấn luyện thậm chí hoạt động kém hơn các baseline đơn giản chọn token với offset cố định. Ví dụ, luôn luôn chọn token thứ (p+2) làm phụ thuộc của token thứ p mang lại độ chính xác cao hơn bất kỳ head attention nào cho một số loại mối quan hệ. Mặt khác, các kiến trúc mô hình tương tự được tiền huấn luyện trên corpus văn bản đạt được độ chính xác khá tốt trong việc xác định các mối quan hệ phụ thuộc trong miền NL, nơi hiệu suất của các baseline đơn giản tương tự bị tụt hậu xa.

Phân tích của chúng tôi tiết lộ một số khác biệt chính giữa NL và PL dẫn đến khả năng hiểu cú pháp khác nhau cho các mô hình được tiền huấn luyện. Đầu tiên, chương trình có cấu trúc hơn câu NL. Chương trình thường chứa cấu trúc phân cấp đại diện cho các phụ thuộc dài hạn giữa các token mã. Do đó, một số lượng lớn các loại mối quan hệ cú pháp nằm giữa các token ở xa, có thể khó nhận biết cho các head attention. Ngược lại, các mối quan hệ phụ thuộc trong câu NL chủ yếu kết nối các cặp token gần nhau, và trong trường hợp này các head attention có khả năng xác định đúng mối quan hệ hơn.

Trong khi đó, các mô hình ngôn ngữ giỏi trong việc nhận biết các mối quan hệ dựa trên từ khóa, chẳng hạn như chọn từ khóa else tương ứng cho token if. Thú vị là, chúng tôi thấy rằng việc bao gồm các token như xuống dòng và dấu chấm phẩy ảnh hưởng đáng kể đến hiệu suất trong miền mã.

Các phát hiện của chúng tôi gợi ý rằng các mô hình được tiền huấn luyện hiện tại hoạt động khá khác biệt trong các miền PL và NL về khả năng hiểu cú pháp. Do đó, việc áp dụng trực tiếp các mô hình huấn luyện được phát triển cho NL có thể không tối ưu cho học chương trình, và chúng tôi coi việc thiết kế các phương pháp tốt hơn để mô hình hóa cấu trúc mã là công việc tương lai.

## 2 CodeSyntax: Đánh giá Hiểu biết Cú pháp Mã

Chúng tôi xây dựng benchmark CodeSyntax để đánh giá hiệu suất của các mô hình ngôn ngữ trong hiểu biết cú pháp mã. Chúng tôi tập trung vào ngôn ngữ Python và Java, trên đó các checkpoint mô hình được phát hành công khai của cả CuBERT (Kanade et al., 2020) và CodeBERT (Feng et al., 2020) đều được tiền huấn luyện. Chúng tôi thu thập các mẫu mã từ CodeSearchNet (Husain et al., 2019), là một bộ dữ liệu quy mô lớn gồm mã trong các ngôn ngữ lập trình khác nhau. Tập huấn luyện của nó cũng là một phần của dữ liệu tiền huấn luyện của CodeBERT, vì vậy chúng tôi loại bỏ các mẫu dữ liệu có trong dữ liệu tiền huấn luyện của CuBERT hoặc CodeBERT. Do đó, không có chương trình nào trong CodeSyntax đã được CuBERT hoặc CodeBERT nhìn thấy trong giai đoạn tiền huấn luyện.

Tổng cộng, CodeSyntax chứa 18.701 mẫu mã được chú thích với 1.342.050 cạnh mối quan hệ trong 43 loại mối quan hệ cho Python, và 13.711 mẫu mã được chú thích với 864.411 cạnh mối quan hệ trong 39 loại mối quan hệ cho Java. Mỗi mẫu mã là một hàm hoàn chỉnh gồm nhiều câu lệnh, tương tự như một đoạn văn trong NL. Mỗi mối quan hệ tương ứng với một cạnh trong AST chương trình; cụ thể, chúng tôi sử dụng module ast Python (Foundation, 2021) và lớp Java org.eclipse.jdt.core.dom.ASTParser (Contributors, 2014) để phân tích mẫu mã thành AST. Chúng tôi trình bày một số ví dụ về các loại mối quan hệ trong Bảng 1, và chúng tôi trì hoãn mô tả của tất cả các loại mối quan hệ đến Bảng 8 trong phụ lục. Chi tiết thêm về trích xuất mối quan hệ được thảo luận trong Phụ lục A. Lưu ý rằng chúng tôi có thể dễ dàng mở rộng bộ dữ liệu để bao quát nhiều ngôn ngữ hơn vì quy trình trích xuất mối quan hệ được tự động hóa và các parser AST có sẵn cho hầu hết các ngôn ngữ lập trình phổ biến.

[Bảng 1: Thống kê bộ dữ liệu các loại mối quan hệ được chọn trong CodeSyntax. Đối với mỗi loại mối quan hệ, chúng tôi làm nổi bật các nút head và dependent trong các ví dụ bằng in đậm, với head màu xanh dương và dependent màu đỏ. Chúng tôi trì hoãn thống kê đầy đủ của tất cả các loại mối quan hệ đến Bảng 8 trong phụ lục.]

Chúng tôi quan sát một số đặc điểm của các mối quan hệ trong CodeSyntax. Đầu tiên, các từ khóa trong PL đóng vai trò quan trọng trong việc nhận biết cấu trúc mã. Cụ thể, một số loại mối quan hệ có từ khóa cố định làm nút cạnh, chẳng hạn như mối quan hệ If:if!else. Trong khi đó, so với các mối quan hệ phụ thuộc trong NL, các cạnh mối quan hệ trong AST chương trình có xu hướng kết nối các nút ở xa nhau hơn nhiều. Như thể hiện trong Hình 3, offset trung bình giữa các nút head và dependent không quá 10 cho các mối quan hệ phụ thuộc trong NL, trong khi offset trung bình cho một loại mối quan hệ có thể hơn 100 token mã. Cụ thể, trong CodeSyntax, có 22 loại phụ thuộc gần có offset trung bình dưới 10, và 12 loại phụ thuộc xa có offset trung bình trên 10.

[Hình 3: Phân bố offset của các loại mối quan hệ trong (a) CodeSyntax và (b) corpus ngôn ngữ tự nhiên. Trục x là khoảng cách offset vị trí trung bình giữa head và dependent cho mỗi mối quan hệ. Trục y là số lượng mối quan hệ có giá trị offset trung bình. Xem Mục 3 để biết thêm chi tiết về corpus NL.]

## 3 Thiết lập Đánh giá

Các mô hình ngôn ngữ được tiền huấn luyện có nắm bắt cấu trúc mã mà không có giám sát trực tiếp về thông tin cú pháp không? Để điều tra câu hỏi này, chúng tôi đánh giá một số mô hình ngôn ngữ được tiền huấn luyện mà không tinh chỉnh, và so sánh hiệu suất của chúng trong hiểu cú pháp cho NL và PL.

**Benchmark ngôn ngữ tự nhiên.** Để so sánh hiệu suất trên CodeSyntax với hiểu biết cú pháp NL, chúng tôi xây dựng benchmark NL bao gồm tiếng Anh và tiếng Đức. Cụ thể, chúng tôi sử dụng English News Text Treebank: Penn Treebank Revised (Bies et al., 2015) được gán nhãn với Stanford Dependencies (de Marneffe and Manning, 2008a,b), và German Hamburg Dependency Treebank (Foth et al., 2014) được gán nhãn với Universal Dependencies (de Marneffe et al., 2021). Tổng cộng, bộ dữ liệu tiếng Anh có 48.883 câu, 43 loại mối quan hệ, và 1.147.526 cạnh mối quan hệ; bộ dữ liệu tiếng Đức có 18.459 câu, 35 loại mối quan hệ, và 307.791 cạnh mối quan hệ.

**Phương pháp thăm dò attention.** Một số nghiên cứu trước đây chứng minh rằng kiến trúc Transformer (Vaswani et al., 2017) được tiền huấn luyện trên corpus văn bản, chẳng hạn như BERT (Devlin et al., 2019), chứa các head attention chuyên về một số mối quan hệ phụ thuộc trong NL (Raganato et al., 2018; Clark et al., 2019). Cụ thể, trong kiến trúc Transformer, mỗi vector ei cho một token đầu vào được chuyển đổi thành các vector query và key qi và ki thông qua một số phép biến đổi tuyến tính, và các phép biến đổi khác nhau giữa các head attention khác nhau. Đối với token thứ i, trọng số attention được gán cho token thứ j là

αi,j = exp(qiTkj) / Σl exp(qiTkl)

Trọng số attention cho biết mức độ quan trọng của token thứ j đối với token thứ i. Thông thường, các head attention khác nhau học các trọng số khác nhau giữa các token đầu vào. Do đó, để đo tính chính xác của việc nhận biết loại mối quan hệ r, đối với mỗi cạnh <h, t, r> trong AST chương trình nơi h là nút head và t là nút dependent, chúng tôi liệt kê tất cả các head attention để tính trọng số attention αh,t. Nếu một head attention có xu hướng gán trọng số attention cao kết nối cặp token thuộc loại mối quan hệ r, chúng tôi coi loại mối quan hệ đó được nắm bắt. Chúng tôi trì hoãn thêm chi tiết triển khai của việc trích xuất attention map đến Phụ lục B.

**Số liệu đo lường.** Chúng tôi sử dụng điểm đính kèm không nhãn (UAS) để đo hiệu suất hiểu cú pháp, và chúng tôi xem xét điểm top-k với các giá trị k khác nhau. Để tính điểm top-k cho các mô hình ngôn ngữ, đối với mỗi head attention, cho token head h trong cạnh mối quan hệ <h, t, r>, chúng tôi tính trọng số attention trên tất cả token trong mã đầu vào, và chúng tôi coi dự đoán là đúng nếu trọng số attention trên token dependent t nằm trong số k token có trọng số attention cao nhất. Đối với mỗi mối quan hệ, chúng tôi chọn head attention hoạt động tốt nhất và sử dụng điểm số của nó làm điểm số của mô hình cho mối quan hệ đó. Chúng tôi tính điểm số trung bình của mô hình trên tất cả mối quan hệ làm điểm số cuối cùng của mô hình.

Trong các bài toán phân tích phụ thuộc NL, nút dependent t thường tương ứng với một từ duy nhất. Tuy nhiên, trong PL, dependent có thể là một khối chứa nhiều token mã. Ví dụ, trong mối quan hệ If:if!body, head là từ khóa if, trong khi dependent là toàn bộ khối body. Do đó, chúng tôi đo ba số liệu. **Số liệu token đầu tiên** và **số liệu token cuối cùng**: dự đoán được coi là đúng nếu nó dự đoán thành công token đầu tiên và cuối cùng của khối dependent, tương ứng; **Số liệu bất kỳ token**: dự đoán được coi là đúng nếu nó có thể dự đoán bất kỳ token nào trong khối dependent. Mặc dù chúng tôi đồng ý rằng đây không phải là các số liệu hoàn hảo và một số liệu duy nhất có thể không đầy đủ, chúng tôi quan sát thấy các phát hiện của chúng tôi thường giữ nguyên cho tất cả ba số liệu mà chúng tôi đánh giá. Lưu ý rằng số liệu token đầu tiên nghiêm ngặt hơn số liệu bất kỳ token theo thiết kế. Trừ khi được chỉ định khác, chúng tôi báo cáo điểm top-k sử dụng số liệu token đầu tiên theo mặc định.

**Kiến trúc mô hình.** Bảng 2 tóm tắt các mô hình được đánh giá trong nghiên cứu này. Đối với các mô hình ngôn ngữ trên mã, chúng tôi xem xét CuBERT (Kanade et al., 2020) và CodeBERT (Feng et al., 2020), và chúng tôi đánh giá các checkpoint được tiền huấn luyện đã phát hành của chúng. Cả hai đều dựa trên các kiến trúc được thiết kế ban đầu cho NL. Cụ thể, CuBERT sử dụng kiến trúc BERT (Devlin et al., 2019), và CodeBERT (Feng et al., 2020) sử dụng kiến trúc RoBERTa (Liu et al., 2019). Đối với các mô hình NL, chúng tôi cũng đánh giá các biến thể đa ngôn ngữ của BERT và RoBERTa trên bộ dữ liệu tiếng Đức, tức là Multilingual BERT (Pires et al., 2019) và XLM-RoBERTa (Conneau et al., 2020). Cả hai mô hình ngôn ngữ mã đều có phân biệt hoa thường, vì vậy chúng tôi cũng đánh giá các phiên bản có phân biệt hoa thường của các mô hình NL.

[Bảng 2: Kiến trúc mô hình được đánh giá trên benchmark PL và NL. Các mô hình cùng hàng chia sẻ cùng kiến trúc, nhưng được tiền huấn luyện trên các corpus khác nhau.]

**Baseline.** Để kiểm tra mức độ tốt của attention thông qua so sánh, chúng tôi thiết kế một baseline offset đơn giản và một baseline từ khóa đơn giản. Baseline offset với giá trị offset i luôn chọn token sau i vị trí của token đầu vào làm dự đoán khi i > 0, và chọn i vị trí trước token đầu vào khi i < 0. Baseline từ khóa với từ khóa key luôn dự đoán token key tiếp theo làm dự đoán. Trong thí nghiệm của chúng tôi, chúng tôi đánh giá baseline offset với mỗi giá trị offset có thể từ 0 đến 512 cho PL, và -512 đến 512 cho NL. Chúng tôi sử dụng tất cả từ khóa Python và Java cho baseline từ khóa trên bộ dữ liệu Python và Java tương ứng, bao gồm các token như if, for, in, v.v. Để đánh giá điểm top-k cho baseline nơi k≥2, chúng tôi kết hợp k baseline đơn giản với các giá trị offset (từ khóa) khác nhau để đưa ra k dự đoán. Để chọn k giá trị offset (từ khóa), chúng tôi lặp đi lặp lại và tham lam bao gồm giá trị tiếp theo mang lại tăng hiệu suất cao nhất cho loại mối quan hệ đang xem xét.

## 4 Thí nghiệm

Trong mục này, chúng tôi trình bày kết quả của các mô hình ngôn ngữ được tiền huấn luyện cho cả tác vụ hiểu cú pháp PL và NL, và thảo luận các quan sát chính phân biệt PL với NL.

### 4.1 Kết quả Chính

[Bảng 3: Điểm Top-k cho hiểu cú pháp mã. Đối với mỗi ngôn ngữ, khối trên chứa kết quả của baseline, bao gồm: (1) Offset: luôn chọn token với offset vị trí cố định; (2) Keyword: khớp từ khóa cố định gần đó; và (3) Combined: kết hợp tùy chọn tốt nhất từ Offset và Keyword. Chênh lệch điểm được tính là điểm attention tốt nhất - điểm baseline tốt nhất cho mỗi ngôn ngữ, nơi giá trị dương cho thấy mô hình ngôn ngữ vượt qua baseline.]

[Bảng 4: Điểm Top-k cho hiểu cú pháp NL. Lưu ý rằng BERT-large và CuBERT chia sẻ cùng cấu hình mô hình, và CodeBERT và RoBERTa-base có cùng kiến trúc mô hình. Không giống Bảng 3, chúng tôi loại trừ baseline Keyword và Combined vì chúng không bổ sung cho baseline Offset về hiệu suất.]

Chúng tôi trình bày kết quả chính để so sánh hiệu suất trong hiểu mối quan hệ cú pháp trên PL và NL trong Bảng 3 và 4, tương ứng. Đầu tiên, trên CodeSyntax, các mô hình ngôn ngữ thường hoạt động kém hơn baseline offset đơn giản và sự kết hợp của nó với baseline từ khóa, điều này cho thấy các head attention của các mô hình được tiền huấn luyện PL không nắm bắt hiệu quả các mối quan hệ cú pháp trong chương trình. So sánh giữa CodeBERT và RoBERTa tiếp tục cho thấy việc tiền huấn luyện trên corpus mã quy mô lớn, bổ sung cho corpus văn bản cho tiền huấn luyện RoBERTa, không mang lại hiểu biết cú pháp mã tốt hơn đáng kể. Ngược lại, các mô hình ngôn ngữ vượt trội hơn đáng kể so với baseline offset trong việc nhận biết các mối quan hệ phụ thuộc trong NL, chứng minh rằng các head attention học được chuyên về các loại mối quan hệ khác nhau thông qua tiền huấn luyện quy mô lớn trên văn bản.

Trong khi đó, chúng tôi trình bày kết quả any-token trên CodeSyntax trong Bảng 5. Mặc dù baseline kết hợp tốt nhất vẫn vượt trội hơn các mô hình ngôn ngữ, khoảng cách hiệu suất thu hẹp đáng kể. Cụ thể, CuBERT đạt điểm tốt hơn baseline offset, và sự cải thiện trên Java đáng chú ý hơn. Chúng tôi trì hoãn kết quả đầy đủ của các điểm top-k khác nhau trên cả benchmark PL và NL đến Phụ lục D. Trong các mục sau, chúng tôi thảo luận các yếu tố chính ảnh hưởng đến hiệu suất dự đoán.

[Bảng 5: Điểm Top-k cho hiểu cú pháp mã sử dụng số liệu any-token.]

### 4.2 Nghiên cứu Trường hợp: Ảnh hưởng của Từ khóa

[Hình 4: Điểm Top-k cho hiểu cú pháp Java sử dụng số liệu last-token.]

Để kiểm tra tại sao baseline offset vượt trội hơn CodeBERT và CuBERT, và tại sao sự khác biệt hiệu suất tương đối nhỏ hơn khi sử dụng số liệu any-token, chúng tôi tiến hành nghiên cứu trường hợp và phân tích lỗi trong Mục 4.2 và Mục 4.3, cả hai đều phân loại các mẫu lỗi một cách định lượng và định tính.

Đầu tiên, chúng tôi điều tra các token mã được attention nhiều nhất, và chúng tôi quan sát rằng các head attention có xu hướng nhận biết các token dành riêng và từ khóa trong PL. Ví dụ, CuBERT và CodeBERT có điểm cải thiện trên Java vì token dấu chấm phẩy là một phần của nút dependent ground truth, đây là token phổ biến được các mô hình ngôn ngữ chú ý đến. Dựa trên quan sát này, chúng tôi thực hiện nghiên cứu ablation về sự hiện diện của dấu chấm phẩy trong chú thích ground truth. Khi các token dấu chấm phẩy được loại bỏ khỏi các nút dependent ground truth, chúng tôi cũng vô hiệu hóa khả năng chú ý đến dấu chấm phẩy trong mã đầu vào của các mô hình ngôn ngữ. Vì dấu chấm phẩy xuất hiện ở cuối mỗi câu lệnh Java, ở đây chúng tôi tính điểm last-token có thể bị ảnh hưởng đáng kể bởi dấu chấm phẩy. Như thể hiện trong Hình 4, CuBERT vượt trội hơn đáng kể so với baseline khi dấu chấm phẩy được bao gồm trong nhãn ground truth. Mặt khác, CuBERT đạt điểm thấp hơn baseline khi dấu chấm phẩy được loại trừ khỏi nhãn ground truth và dự đoán. So sánh cho thấy các head attention có khả năng xác định từ khóa thường xuyên trong đầu vào mô hình tốt hơn. Chúng tôi trì hoãn nghiên cứu ablation đầy đủ trên cả Python và Java đến Phụ lục F.

Chúng tôi tiếp tục thảo luận kết quả phân tích theo loại mối quan hệ, và chúng tôi chọn một số mối quan hệ đại diện cho Python làm nổi bật sự khác biệt hiệu suất giữa CuBERT và baseline offset trong Bảng 6. Đầu tiên, attention có khả năng cao trong việc thực hiện khớp từ khóa, dẫn đến độ chính xác tốt trên các mối quan hệ kết nối từ khóa phổ biến, chẳng hạn như If:if!else. Tuy nhiên, khi các token head và dependent đa dạng, việc nhận biết mối quan hệ trở nên thách thức cho mô hình ngôn ngữ. Ví dụ, trong các loại mối quan hệ Assign:target!value và Call:func!args, cả nút head và dependent đều có thể nhận nhiều tên định danh khác nhau được định nghĩa bởi các lập trình viên khác nhau. Cụ thể, CuBERT không thể sử dụng hiệu quả vị trí tương đối của token để học các mối quan hệ, ngay cả khi nút dependent gần nút head. Trong những tình huống như vậy, baseline offset với giá trị offset cố định 2 đã vượt qua mô hình được tiền huấn luyện. Kết quả phân tích đầy đủ của tất cả loại mối quan hệ trên cả Python và Java có thể tìm thấy trong Phụ lục G.

[Bảng 6: So sánh điểm top-1 first-token giữa CuBERT và baseline offset với offset cố định tốt nhất cho các loại mối quan hệ được chọn trên bộ dữ liệu Python.]

### 4.3 Phân tích Lỗi

[Bảng 7: Phân tích lỗi sử dụng CuBERT.]

Để phân loại các dự đoán sai của attention, chúng tôi kiểm tra thủ công 50 trường hợp lỗi cho mỗi mối quan hệ được chọn trong Bảng 6, và trình bày các tình huống lỗi trong Bảng 7. Một lần nữa, chúng tôi quan sát rằng attention thường chọn sai các token xuất hiện thường xuyên như dấu ngoặc. Hơn nữa, mô hình gặp khó khăn trong việc nắm bắt cấu trúc mã phân cấp, do đó nó thường chú ý đến các từ khóa gần đó bất kể khối mã logic.

Lấy mối quan hệ If:if!else làm ví dụ, mà mô hình ngôn ngữ thường đạt hiệu suất tốt nhất. Được hiển thị trong Hình 5 là hai mẫu câu lệnh if, nơi câu đầu tiên không chứa khối điều khiển luồng lồng nhau trong khi câu thứ hai chứa từ khóa while bên trong if-body. "..." biểu thị rằng một số mã bị bỏ qua. Trực quan hóa các trọng số attention tương ứng của head attention hoạt động tốt nhất trên mối quan hệ If:if!else, chúng tôi quan sát rằng head attention chính xác chú ý đến token else trong ví dụ đầu tiên, trong khi nó sai lầm chú ý đến token while bên trong if-body trong ví dụ thứ hai. Nhiều ví dụ như thế này có thể được tìm thấy trong Phụ lục E.

[Hình 5: Hai trường hợp mẫu cho mối quan hệ If:if!else và trọng số attention tương ứng của head 17-2 của CuBERT.]

## 5 Nghiên cứu Liên quan

Các mô hình ngôn ngữ dựa trên Transformer đã được sử dụng rộng rãi cho xử lý ngôn ngữ tự nhiên (Devlin et al., 2019; Liu et al., 2019; Wang et al., 2020, 2021; Shen et al., 2022; Wang et al., 2022). Hewitt and Manning (2019) cho thấy cây cú pháp được nhúng ngầm trong không gian biểu diễn từ của BERT thông qua một structural probe. Một hướng nghiên cứu khác nghiên cứu những gì được học bởi attention trong các mô hình ngôn ngữ (Clark et al., 2019; Raganato et al., 2018; Voita et al., 2019; Michel et al., 2019; Vig, 2019; Burns et al., 2018; Marecek and Rosa, 2018; Voita et al., 2018). Cụ thể, Clark et al. (2019) đánh giá các head attention của BERT trên các tác vụ phân tích phụ thuộc sử dụng corpus English Penn Treebank, nơi attention vượt trội đáng kể so với baseline offset. Ngược lại, chúng tôi chứng minh rằng các mô hình dựa trên attention phần lớn hoạt động kém hơn baseline offset trong hiểu cú pháp mã.

Thành công của các mô hình dựa trên Transformer cho xử lý ngôn ngữ tự nhiên dẫn đến ứng dụng của chúng trong miền PL (Kanade et al., 2020; Feng et al., 2020; Rozière et al., 2020, 2021; Clement et al., 2020; Dehghani et al., 2019). Chen et al. (2021) đánh giá hiệu suất mô hình bằng cách đo tính chính xác chức năng trên các bài kiểm tra đơn vị. Chirkova and Troshin (2021) chứng minh thực nghiệm rằng Transformer có thể sử dụng thông tin cú pháp để đưa ra dự đoán trong một số tác vụ xử lý mã, trong khi chúng tôi phân tích khả năng của attention để hiểu các mối quan hệ cú pháp. Karmakar and Robbes (2021) thăm dò các mô hình được tiền huấn luyện trên bốn tác vụ hiểu mã. Họ tập trung nhiều hơn vào phân loại mã, ví dụ, họ huấn luyện một bộ phân loại để dự đoán thẻ nút AST và độ dài mã. Ngược lại, chúng tôi thăm dò các head attention để hiểu mối quan hệ cú pháp, và chúng tôi nhằm trình bày một nghiên cứu toàn diện về sự khác biệt giữa các mô hình ngôn ngữ được tiền huấn luyện trên NL và PL để nắm bắt cấu trúc cú pháp.

Đã có một số nỗ lực cố gắng tính đến cấu trúc mã trong quá trình tiền huấn luyện các mô hình dựa trên Transformer cho mã. Ví dụ, GraphCodeBERT (Guo et al., 2021) sử dụng data flow cho tiền huấn luyện; tức là mối quan hệ "giá trị đến từ đâu" cho các biến. Trên benchmark Python của chúng tôi, GraphCodeBERT đạt điểm top-1 first-token là 39.3, tốt hơn 33.1 của CodeBERT, và tương đương với 39.2 của CuBERT. Tuy nhiên, điểm như vậy vẫn kém hơn 43.6 của baseline offset. Xu hướng này nhất quán khi đánh giá với các số liệu khác. Những kết quả này cho thấy việc tiền huấn luyện trên data flow giúp cải thiện khả năng hiểu cú pháp mã của mô hình, nhưng vẫn còn nhiều chỗ để cải thiện.

## 6 Kết luận

Trong nghiên cứu này, chúng tôi giới thiệu CodeSyntax, một benchmark quy mô lớn để đo hiệu suất hiểu cú pháp mã. Dựa trên CodeSyntax, chúng tôi tiến hành nghiên cứu toàn diện đầu tiên để phân tích khả năng của các mô hình ngôn ngữ được tiền huấn luyện trong hiểu cấu trúc cú pháp mã mà không cần tinh chỉnh thêm. Chúng tôi chứng minh rằng trong khi các head attention của các mô hình ngôn ngữ được tiền huấn luyện có thể xác định các mối quan hệ phụ thuộc trong NL ở một mức độ nào đó, chúng gặp khó khăn trong việc nhận biết các mối quan hệ cú pháp trong chương trình. Các mô hình được tiền huấn luyện thậm chí thường hoạt động kém hơn các baseline offset đơn giản, và chúng có xu hướng chú ý đến các token gần đó xuất hiện thường xuyên mà không xem xét cấu trúc mã phân cấp.

Chúng tôi cũng phân tích sự khác biệt giữa NL và PL từ góc độ các mô hình được tiền huấn luyện. Đánh giá của chúng tôi gợi ý rằng PL có những đặc điểm độc đáo phân biệt chúng với NL, chẳng hạn như phụ thuộc dài hạn giữa các token mã, và phân cấp trong cấu trúc cú pháp. Do đó, đơn giản chỉ lấy chương trình làm chuỗi token là không đủ để mô hình hóa cấu trúc chương trình, điều này cuối cùng có thể hạn chế tiềm năng của các mô hình ngôn ngữ cho các tác vụ hiểu mã. Chúng tôi coi việc phát triển các kiến trúc mô hình mới và thuật toán tiền huấn luyện để tận dụng và biểu diễn cấu trúc mã và đồ thị phụ thuộc là công việc tương lai quan trọng.

## 7 Hạn chế

Đối với những hạn chế của benchmark của chúng tôi, các chú thích vàng dựa trên các parser AST. Việc thêm các ngôn ngữ lập trình mới mà parser không có sẵn sẽ yêu cầu nỗ lực gán nhãn bổ sung. Một hạn chế trong thiết lập thí nghiệm của chúng tôi là chúng tôi chỉ đánh giá sáu mô hình trên hai loại ngôn ngữ tự nhiên và ngôn ngữ lập trình. Cuối cùng, trọng tâm chính của nghiên cứu chúng tôi là thăm dò các mô hình ngôn ngữ để hiểu mã. Do đó, chúng tôi không đề xuất các mô hình có thể xử lý cú pháp mã trong các ứng dụng ngôn ngữ tự nhiên và ngôn ngữ lập trình. Công việc tương lai có thể bao gồm việc phát triển các mô hình như vậy nắm bắt cả ngữ nghĩa và cấu trúc.

## 8 Cân nhắc Đạo đức

Chúng tôi xin xác nhận rằng tất cả các đồng tác giả của nghiên cứu này đều biết về Bộ quy tắc Đạo đức ACM được cung cấp và tôn trọng quy tắc ứng xử. Những điều sau đây đưa ra các khía cạnh của cả cân nhắc đạo đức và tác động tiềm năng của chúng tôi đến cộng đồng. Nghiên cứu này tạo ra một benchmark để kiểm tra hiểu biết cú pháp mã của các mô hình ngôn ngữ được tiền huấn luyện. Thay vì ngôn ngữ tự nhiên, ngôn ngữ lập trình được sử dụng để tiền huấn luyện. Chúng tôi không dự đoán việc tạo ra các đầu ra có hại sau khi sử dụng benchmark và các mô hình hiện tại của chúng tôi, đặc biệt đối với các nhóm dân số dễ bị tổn thương.

## 9 Cân nhắc Môi trường

Chúng tôi sử dụng một số mô hình ngôn ngữ được tiền huấn luyện. Theo ước tính trong (Strubell et al., 2019), việc tiền huấn luyện một mô hình với kích thước tương tự như được sử dụng trong nghiên cứu tốn 1.507 kWh PUE và phát thải 1.438 lb CO2. Nghiên cứu này tập trung vào suy luận. Do đó, chi phí năng lượng và phát thải CO2 của chúng tôi tương đối nhỏ.

## Lời cảm ơn

Chúng tôi muốn cảm ơn các nhà đánh giá ẩn danh vì những gợi ý và nhận xét của họ. Tài liệu này một phần dựa trên công việc được hỗ trợ bởi Berkeley DeepDrive và Berkeley Artificial Intelligence Research.

## Tài liệu tham khảo

[Danh sách tài liệu tham khảo được giữ nguyên như bản gốc do chứa các tên riêng và định danh không cần dịch]

## A Chi tiết thêm về Xây dựng CodeSyntax

Vì bộ dữ liệu code search net không đi kèm với nhãn mối quan hệ cú pháp, chúng tôi đưa ra cách trích xuất các mối quan hệ cú pháp. Đầu tiên chúng tôi sử dụng module tokenize của python và module javalang để tạo ra các token mã từ mã nguồn, sau đó gán nhãn các token mã này với các mối quan hệ cú pháp bằng cách sử dụng parser AST trên mã nguồn. Chúng tôi sử dụng module ast Python (Foundation, 2021) và lớp Java org.eclipse.jdt.core.dom.ASTParser (Contributors, 2014) để phân tích mã nguồn thành các nút ast. Cấu trúc AST nắm bắt các mối quan hệ cú pháp. Một nút AST có các nút AST con và một tên biểu thị lớp của nó. Chúng tôi sử dụng lớp của nút làm nhãn và các nút con làm dependent và head khi tạo chú thích. Ví dụ, mã nguồn A = B, có nghĩa là gán giá trị B cho biến đích A, được phân tích thành nút AST Assign(targets=[Name(id='A')], value=Name(id='B')). Nó cho chúng tôi một mối quan hệ cú pháp có head là A và dependent là B, được chú thích với nhãn loại mối quan hệ Assign. Thống kê đầy đủ của CodeSyntax được hiển thị trong Bảng 8.

## B Chi tiết thêm về Trích xuất Attention Map cho Mô hình Ngôn ngữ Mã

Thí nghiệm của chúng tôi tuân theo công việc của Clark et al. (2019). Họ đánh giá các head attention của BERT trên các tác vụ phân tích phụ thuộc trên bộ dữ liệu tiếng Anh, trong khi chúng tôi mở rộng công việc sang miền PL. Chúng tôi áp dụng và mở rộng một số mã của họ, chẳng hạn như các hàm để trích xuất attention từ BERT và vẽ trọng số attention. Sự khác biệt chính giữa công việc của chúng tôi và của họ là chúng tôi xây dựng một bộ dữ liệu mới cho các tác vụ hiểu cú pháp cho PL và đưa ra các số liệu đánh giá liên quan để phù hợp với đặc điểm của PL.

### B.1 Đầu vào Mô hình

Mỗi mẫu mã của chúng tôi là một hàm Python hoặc Java hoàn chỉnh. Để chuẩn bị đầu vào được đưa vào các mô hình, chúng tôi chạy tokenization CuBERT và CodeBERT để có được chuỗi input id cho mỗi mẫu mã. Chúng tôi chèn token [CLS] ở đầu và thêm token [SEP] ở cuối. Nếu độ dài đầu vào dài hơn 512 token (số lượng token tối đa cho phép), chúng tôi loại bỏ mẫu mã đó. Chúng tôi không bao giờ chia một mẫu mã dài thành nhiều câu đầu vào vì khoảng cách của một số mối quan hệ phụ thuộc rất dài trong một hàm. Ví dụ, đối với câu lệnh if, khối else có thể ở xa từ khóa if. Nếu chúng tôi chia chúng thành hai câu đầu vào, thì attention sẽ không thể hiểu và dự đoán mối quan hệ giữa chúng. Để tránh các điểm dữ liệu không phổ biến, chúng tôi loại bỏ mẫu mã khỏi đầu vào của cả CuBERT và CodeBERT nếu nó dài hơn 512 token sau tokenization của CuBERT hoặc CodeBERT.

### B.2 Căn chỉnh Token và Attention Cấp độ Từ

BERT sử dụng tokenization WordPiece (Wu et al., 2016) và RoBERTa sử dụng Byte-Pair Encoding (BPE) cấp độ byte (Sennrich et al., 2016), có thể chia một từ thành nhiều subtoken. Ngoài ra, CuBERT áp đặt một số quy tắc đặc biệt khi tạo vocabulary chương trình. Tuy nhiên, nhãn của bộ dữ liệu chúng tôi sử dụng các token mã được tạo bởi module tokenize và module javalang. Do đó, cần căn chỉnh các subtoken CuBERT/CodeBERT với các token mã để đánh giá các mô hình trên bộ dữ liệu của chúng tôi. Chúng tôi đầu tiên tạo ra một sự căn chỉnh như vậy ánh xạ mỗi token mã tới một tập hợp các subtoken CuBERT/CodeBERT, và sau đó chuyển đổi attention cấp độ subtoken gốc thành attention cấp độ từ. Chúng tôi tuân theo (Clark et al., 2019) để kết hợp trọng số attention của các subtoken, tức là chúng tôi cộng các trọng số attention của chúng.

## C Thông tin Tái tạo thêm

Ở đây chúng tôi cung cấp thêm thông tin theo Tiêu chí Tái tạo EMNLP 2022.

• **Chia tách train/validation/test cho các bộ dữ liệu được sử dụng**: Chúng tôi không tinh chỉnh các mô hình được tiền huấn luyện trên benchmark của chúng tôi. Tập validation của CodeSyntax chứa các mẫu mã đến từ tập validation của CodeSearchNet, và tập test của chúng tôi chứa các mẫu từ tập test của CodeSearchNet. Chúng tôi sử dụng phân vùng test để thăm dò các head attention được tiền huấn luyện trong khi tập validation không được sử dụng.

• **Số lượng tham số trong mỗi mô hình**: CuBERT và BERT-large có 340M tham số. CodeBERT và RoBERTa-base có 125M tham số. XLM-RoBERTa-base có 250M tham số. Multilingual BERT-base có 110M tham số.

• **Thời gian chạy trung bình cho mỗi mô hình hoặc thuật toán**: Chạy pipeline để xây dựng bộ dữ liệu CodeSyntax mất khoảng bốn giờ giả sử các dependency và bộ dữ liệu yêu cầu đã được tải xuống. Thuật toán để thăm dò một mô hình được tiền huấn luyện trên một ngôn ngữ lập trình của CodeSyntax mất khoảng mười hai giờ trên máy của chúng tôi sử dụng một GPU Nvidia 1080Ti.

## D Thêm Kết quả về Điểm Top-k

Điểm top-k PL được vẽ trong hình 6. Điểm NL được vẽ trong hình 7 (tiếng Anh) và hình 8 (tiếng Đức).

[Các hình từ 6-8 được giữ nguyên cấu trúc như bản gốc]

## E Ví dụ về Dự đoán Đúng và Sai

Trong mục này, chúng tôi trình bày một số ví dụ trực quan hóa nơi attention dự đoán đúng hoặc sai các dependent. Các head được chọn trong những ví dụ này là các head hoạt động tốt nhất của CuBERT được đánh giá bằng số liệu first-token. Chúng tôi đưa toàn bộ hàm làm đầu vào cho transformer, tuy nhiên, chúng tôi chỉ trình bày các đoạn liên quan ở đây để đơn giản. Trong mã nguồn hiển thị, "..." biểu thị rằng phần còn lại của mã bị bỏ qua. Do đó, attention từ một token có thể không tổng bằng một trong các hình này vì phần còn lại của hàm bị bỏ qua.

**Mối quan hệ Call: func!args.** Trọng số attention tương ứng được trực quan hóa trong Bảng 9 cho Python và 10 cho Java.

• **Trường hợp đúng Python.**
```
n = len(x)
n_fft = len(win_sq)
```
Attention dự đoán đúng các đối số x và win_sq, tương ứng.

• **Trường hợp lỗi Python.**
```
re.findall(pattern,text)
```
Hàm findall được gọi. Dự đoán đúng nên là đối số đầu tiên, là pattern; tuy nhiên attention dự đoán sai dấu ngoặc (.

• **Trường hợp đúng Java.**
```
subscriber.onError(ex);
```
Token ex có trọng số lớn nhất trong attention, đây là dự đoán đúng.

• **Trường hợp lỗi Java.**
```
isBug(error)
```
Hàm isBug được gọi. Dự đoán đúng nên là đối số, error; tuy nhiên attention dự đoán sai ).

[Các hình 9-12 và bảng số liệu được giữ nguyên cấu trúc]

**Mối quan hệ Assign: target!value.** Trọng số attention tương ứng được trực quan hóa trong Bảng 11 cho Python và 12 cho Java.

• **Trường hợp đúng Python.**
```
value = round(value, precision)
```
Giá trị được gán round được dự đoán đúng.

• **Trường hợp lỗi Python.**
```
d["_text"] = r.text
```
Giá trị được gán là r.text, nhưng attention dự đoán sai [.

• **Trường hợp đúng Java.**
```
int p = parallelism();
```
Attention có trọng số lớn nhất cho token head parallelism, dự đoán đúng mối quan hệ.

• **Trường hợp lỗi Java.**
```
this.defaultProcessor = processor;
```
Giá trị được gán là processor, nhưng attention dự đoán sai ;.

**Mối quan hệ If: if!else.** Trọng số attention tương ứng được trực quan hóa trong Bảng 13 cho Java.

• **Trường hợp đúng Java.**
```
if (t instanceof Error) {
    throw (Error) t;
} else {
    ...
```
Nó xác định đúng từ khóa else.

• **Trường hợp lỗi Java.**
```
if(error.addThrowable(ex)) {
    if ...
} else {
    ...
```
Có câu lệnh if khác bên trong body của câu lệnh if đầu tiên. Dự đoán đúng nên là từ khóa else, nhưng nó dự đoán if bên trong.

**Mối quan hệ For: for!body.** Trọng số attention tương ứng được trực quan hóa trong Bảng 14 cho Python và 15 cho Java.

• **Trường hợp đúng Python.**
```
for el in predictions:
    if 0 in el:
        ...
```

• **Trường hợp lỗi Python.**
```
for pass_ in self.working_list:
    ret.append(...
```
Dự đoán đúng nên là token đầu tiên trong body, là ret; tuy nhiên attention dự đoán sai khoảng trắng " " trước ret.

• **Trường hợp đúng Java.**
```
for(BehaviorSubscription<T> s : array) {
    if (...
```

• **Trường hợp lỗi Java.**
```
for (;;) {
    CacheSubscription ...
```
Dự đoán đúng nên là token đầu tiên trong body, là CacheSubscription; tuy nhiên attention dự đoán sai {.

[Các hình 13-15 và phần còn lại được giữ nguyên cấu trúc như bản gốc]

## F Thêm Kết quả về Nghiên cứu Ablation của Delimiter Token

[Các hình 16-19 được giữ nguyên cấu trúc]

## G Thêm Kết quả Phân tích theo Loại Mối quan hệ Khác nhau

Thêm kết quả về so sánh điểm top-1 giữa CuBERT và baseline offset được trình bày trong Bảng 9, 10, 11, và 12.

[Bảng 8-12 được giữ nguyên cấu trúc như bản gốc với các giá trị số và mô tả]

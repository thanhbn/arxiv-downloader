# Vượt Xa Mô Hình Ngôn Ngữ: Mô Hình Byte là Bộ Mô Phỏng Thế Giới Số

**Shangda Wu1 2* Xu Tan1* Zili Wang3 Rui Wang1 Xiaobing Li2 Maosong Sun2 4**

https://byte-gpt.github.io

## Tóm tắt

Học sâu truyền thống thường bỏ qua byte, đơn vị cơ bản của thế giới số, nơi tất cả các dạng thông tin và hoạt động được mã hóa và thao tác ở định dạng nhị phân. Lấy cảm hứng từ thành công của dự đoán token tiếp theo trong xử lý ngôn ngữ tự nhiên, chúng tôi giới thiệu bGPT, một mô hình với dự đoán byte tiếp theo để mô phỏng thế giới số. bGPT có hiệu suất tương đương với các mô hình chuyên biệt trên nhiều phương thức khác nhau, bao gồm văn bản, âm thanh và hình ảnh, đồng thời mở ra những khả năng mới để dự đoán, mô phỏng và chẩn đoán hành vi thuật toán hoặc phần cứng. Nó đã sao chép gần như hoàn hảo quy trình chuyển đổi dữ liệu nhạc ký hiệu, đạt tỷ lệ lỗi thấp 0.0011 bit trên byte trong việc chuyển đổi ký hiệu ABC sang định dạng MIDI. Ngoài ra, bGPT thể hiện khả năng đặc biệt trong việc mô phỏng hành vi CPU, với độ chính xác vượt quá 99.99% trong việc thực hiện các hoạt động khác nhau. Tận dụng dự đoán byte tiếp theo, các mô hình như bGPT có thể học trực tiếp từ dữ liệu nhị phân khổng lồ, mô phỏng hiệu quả các mẫu phức tạp của thế giới số.

## 1. Giới thiệu

Nghiên cứu học sâu đã tập trung vào các tệp phương tiện số dễ hiểu với con người, như văn bản, âm thanh và hình ảnh (Oord et al., 2016; He et al., 2016; Peters et al., 2018), do tính liên quan trực tiếp của chúng đến giao tiếp và hiểu biết của con người. Văn bản, đặc biệt, đóng vai trò trung tâm trong việc truyền đạt trí tuệ con người và đã dẫn đến sự xuất hiện của các Mô hình Ngôn ngữ (LMs) (Radford et al., 2018; 2019; Brown et al., 2020; Bubeck et al., 2023; Touvron et al., 2023a;b). Nguyên lý cơ bản của LM bao gồm việc token hóa văn bản (Sennrich et al., 2016; Wu et al., 2016; Kudo, 2018; Kudo & Richardson, 2018) và dự đoán token tiếp theo trong một chuỗi, cho phép chúng hiểu ngôn ngữ và trí tuệ con người. Các tiến bộ gần đây tiếp tục mở rộng token hóa cho nhiều phương thức khác ngoài văn bản (Dosovitskiy et al., 2021; Défossez et al., 2022), trao quyền cho LMs để đạt được hiểu biết toàn diện hơn về thế giới thực và mô phỏng trí tuệ con người (Wang et al., 2023; Borsos et al., 2023; Liu et al., 2023; Li et al., 2023).

Tuy nhiên, các mô hình học sâu này chủ yếu hoạt động trong lĩnh vực dữ liệu phương tiện, bỏ qua dữ liệu nhị phân gốc có mặt khắp nơi trong thế giới số. Byte là nền tảng của tất cả dữ liệu số, thiết bị và phần mềm, từ bộ xử lý máy tính đến hệ điều hành trong các thiết bị điện tử hàng ngày. Do đó, việc huấn luyện các mô hình cho dự đoán byte tiếp theo có thể dẫn đến một sự thay đổi mô hình trong học sâu, cho phép chúng thực sự hiểu và mô phỏng tất cả các hoạt động trong thế giới số. Điều này có lợi ích thực tế không chỉ trong các lĩnh vực thông thường, mà còn trong một số lĩnh vực chưa được khám phá như tăng cường an ninh mạng (Raff et al., 2018), cải thiện chẩn đoán máy tính (Guo et al., 2019), tối ưu hóa nén dữ liệu (Delétang et al., 2023), và thậm chí thúc đẩy các nhiệm vụ phức tạp như kỹ thuật đảo ngược mã nguồn của phần mềm từ biểu diễn nhị phân của nó.

Trong bài báo này, chúng tôi giới thiệu bGPT, một mô hình được thiết kế để xử lý dữ liệu nhị phân và mô hình hóa thế giới số thông qua dự đoán byte tiếp theo. Thế giới số không chỉ bao gồm các tệp phương tiện số, truyền thống là trọng tâm của các mô hình học sâu, mà còn mở rộng đến lĩnh vực phức tạp của các hệ thống số, từ kiến trúc phần cứng đến các thuật toán phức tạp. bGPT vượt qua ranh giới học sâu truyền thống bằng cách trực tiếp diễn giải và thao tác dữ liệu nhị phân, cho phép hiểu biết bản chất và toàn diện hơn về thế giới số. Ưu điểm của nó gồm hai mặt: 1) Diễn giải Hệ thống Số: Bằng cách huấn luyện trên các chuỗi byte, bGPT có thể học các mẫu của hệ thống số, cho phép nó dự đoán, mô phỏng và chẩn đoán hành vi thuật toán hoặc phần cứng. Khả năng này cho phép tái tạo các hệ thống phức tạp từ dữ liệu nhị phân. 2) Mô hình hóa Thống nhất: bGPT tích hợp các loại dữ liệu khác nhau vào một khung duy nhất, coi mọi thứ như một chuỗi byte. Điều này đơn giản hóa việc mô hình hóa và cho phép tích hợp dễ dàng các nguồn dữ liệu khác nhau.

Các thí nghiệm của chúng tôi bao gồm hai lĩnh vực chính: 1) các nhiệm vụ được nghiên cứu kỹ như mô hình hóa tạo sinh và phân loại trên dữ liệu phương tiện số (ví dụ: văn bản, âm thanh và hình ảnh); và 2) các nhiệm vụ tương đối chưa được khám phá thuộc về hoạt động gốc nhị phân, bao gồm chuyển đổi dữ liệu và mô hình hóa trạng thái CPU, đại diện cho mô phỏng thuật toán và phần cứng tương ứng. Nghiên cứu về các mô hình byte không chỉ đánh dấu một bước quan trọng hướng tới học sâu toàn diện và thống nhất, mà còn cung cấp một góc nhìn mới về việc mô hình hóa thế giới số.

## 2. Bối cảnh

### 2.1. Mô hình Ngôn ngữ

LMs, từ các mô hình dựa trên LSTM sớm hơn (Hochreiter & Schmidhuber, 1997) đến các mô hình dựa trên Transformer gần đây (Vaswani et al., 2017), rất quan trọng cho cả việc hiểu và tạo ra ngôn ngữ con người đồng thời mô phỏng trí tuệ con người. Token hóa văn bản đóng vai trò cơ bản trong các mô hình này, vì nó bao gồm việc chia nhỏ văn bản thành các đơn vị nhỏ hơn, như từ hoặc từ con (Sennrich et al., 2016; Wu et al., 2016; Kudo, 2018; Kudo & Richardson, 2018), làm đầu vào cho mô hình. Việc giới thiệu các mô hình Generative Pre-trained Transformer (GPT) (Radford et al., 2018; 2019; Brown et al., 2020) đại diện cho một tiến bộ đáng kể trong lĩnh vực này. Các mô hình GPT được tiền huấn luyện thông qua học tự giám sát, đặc biệt qua dự đoán token tiếp theo trên dữ liệu văn bản rộng lớn. Kỹ thuật huấn luyện này, dự đoán token tiếp theo, dạy mô hình dự đoán token có khả năng cao nhất trong một chuỗi, cho phép nó nắm bắt cấu trúc và ngữ nghĩa đằng sau ngôn ngữ.

Dự đoán token tiếp theo đã mở rộng ảnh hưởng của nó đến nhiều loại dữ liệu khác nhau. Trong xử lý âm thanh, các mô hình như AudioPaLM (Rubenstein et al., 2023) kết hợp văn bản và lời nói, cho phép dịch giọng nói thành giọng nói và nhận dạng giọng nói tiên tiến. MusicGen (Copet et al., 2023) xuất sắc trong việc tạo nhạc có điều kiện bằng cách mô hình hóa nhiều luồng song song của các token âm thanh được trích xuất bởi EnCodec (Défossez et al., 2022). Trong xử lý hình ảnh, iGPT (Chen et al., 2020) áp dụng các mô hình Transformer để dự đoán pixel tiếp theo trong một hình ảnh, trong khi một số mô hình thị giác-ngôn ngữ (Liu et al., 2023; Zhu et al., 2023; Li et al., 2023) đã xuất hiện để thu hẹp khoảng cách giữa dữ liệu văn bản và thị giác. Trong các chuỗi sinh hóa, Tranception (Notin et al., 2022) tận dụng các transformer tự hồi quy và truy xuất để dự đoán thể lực protein, trong khi ProtGPT2 (Ferruz et al., 2022) tạo ra các chuỗi protein với xu hướng axit amin tự nhiên. HyenaDNA (Nguyen et al., 2023) mở rộng độ dài ngữ cảnh trong mô hình hóa di truyền, cho phép hiểu biết chuỗi tầm xa.

Dự đoán token tiếp theo đã trao quyền cho LMs nắm bắt những phức tạp của trí tuệ con người và thế giới. Mở rộng các kỹ thuật này sang dữ liệu nhị phân qua dự đoán byte tiếp theo có thể tiếp tục tăng cường tính linh hoạt của chúng trong việc xử lý thông tin số và mô phỏng thế giới số.

### 2.2. Mô hình Byte

Trong khi dữ liệu nhị phân thiếu cấu trúc và ngữ nghĩa vốn có của dữ liệu có thể hiểu được bởi con người như văn bản, các nỗ lực nghiên cứu gần đây đang khám phá việc mô hình hóa và trích xuất thông tin của nó, mở ra những khả năng mới cho các mô hình byte.

Bằng cách mô hình hóa dữ liệu nhị phân gốc, các hệ thống như MalConv (Raff et al., 2018) và DeepVSA (Guo et al., 2019) đã nổi lên như những công cụ mạnh mẽ để phát hiện phần mềm độc hại và phân tích chương trình. MalConv sử dụng Mạng nơ-ron Tích chập (CNNs) (LeCun et al., 1989) để phân tích các chuỗi byte thô trong các tệp thực thi, trong khi DeepVSA tăng cường phân tích bí danh bộ nhớ trong bối cảnh phân tích tập giá trị để phân tích chương trình hậu khám nghiệm. Ngoài ra, khái niệm về các mô hình ngôn ngữ nén các chuỗi byte (Delétang et al., 2023) giới thiệu một góc nhìn mới về cách các mô hình tiền huấn luyện lớn (Hoffmann et al., 2022) có thể được sử dụng.

Một số nghiên cứu đã xác nhận tính hữu ích của mã hóa cấp độ byte cho các nhiệm vụ ngôn ngữ. Ví dụ, Byte-level Byte Pair Encoding (BBPE) đã được sử dụng để tăng cường tiền huấn luyện mô hình đa ngôn ngữ (Wei et al., 2021) và cũng đã cho thấy triển vọng trong dịch máy (Wang et al., 2020), tạo ra sự cân bằng giữa hiệu quả xử lý và độ rộng ngôn ngữ. ByT5 (Xue et al., 2022) xây dựng dựa trên điều này bằng cách sử dụng các mô hình Transformer tiêu chuẩn cho các chuỗi byte, thúc đẩy phương pháp mã hóa không token cải thiện tính bền vững nhiễu và độ nhạy chính tả trong các tình huống đa ngôn ngữ.

Mã hóa byte cũng đã được áp dụng cho dữ liệu có thể hiểu được bởi con người khác, cho phép các mô hình làm việc với biểu diễn nhị phân của văn bản, hình ảnh và các loại dữ liệu đa dạng trong một khung phổ quát. Ví dụ, ByteFormer (Horton et al., 2023) trực tiếp xử lý các chuỗi byte thô được chuyển đổi từ hình ảnh và âm thanh trong khi duy trì tính linh hoạt và quyền riêng tư. MegaByte (Yu et al., 2023), mặt khác, đã được thử nghiệm và chứng minh xuất sắc trong việc mô hình hóa các chuỗi byte dài trên nhiều phương thức khác nhau. Lấy cảm hứng từ MegaByte (Yu et al., 2023), MambaByte (Wang et al., 2024) tận dụng cấu trúc mạng Mamba (Gu & Dao, 2023) để xuất sắc trong mô hình hóa ngôn ngữ cấp độ byte và thậm chí vượt trội hơn LMs dựa trên token hóa từ con.

Mặc dù có tiến bộ, nghiên cứu hiện tại thường bỏ qua dữ liệu nhị phân gốc, tập trung vào các nhiệm vụ hẹp và bỏ qua tiềm năng rộng lớn hơn của các mô hình byte trong mô phỏng thế giới số. Để giải quyết những vấn đề này, chúng tôi đã sử dụng bGPT để mô hình hóa dữ liệu nhị phân gốc và tiến hành đánh giá toàn diện trên nhiều nhiệm vụ khác nhau. Cách tiếp cận này cung cấp một đánh giá toàn diện về các mô hình byte trong nhiều ứng dụng khác nhau, đưa ra những hiểu biết sâu sắc về tiềm năng của mô hình hóa thế giới số.

## 3. Phương pháp

Trong phần này, chúng tôi giới thiệu bGPT, một mô hình được tối ưu hóa để mô hình hóa dữ liệu số ở cấp độ byte. Chúng tôi bắt đầu bằng việc trình bày khung Transformer phân cấp của nó, phân đoạn các chuỗi byte thành các patch để quản lý hiệu quả tính toán. Tiếp theo, chúng tôi trình bày các mục tiêu huấn luyện của bGPT, bao gồm mô hình hóa tạo sinh và phân loại.

### 3.1. Kiến trúc Mô hình

Làm việc với dữ liệu số ở cấp độ byte không chỉ cho phép các mô hình học các mẫu hệ thống số mà còn cung cấp một cách tiếp cận thống nhất để kết hợp nhiều loại dữ liệu khác nhau vào một khung duy nhất. Tuy nhiên, độ chi tiết cao của byte dẫn đến các chuỗi dài, làm tăng đáng kể chi phí tính toán. Vấn đề này trở nên rõ rệt hơn trong các mô hình dựa trên Transformer do việc mở rộng self-attention bậc hai, hạn chế hiệu quả và khả năng mở rộng của chúng để xử lý dữ liệu nhị phân.

Để giải quyết các hạn chế tính toán trong các mô hình dựa trên Transformer với các chuỗi byte dài, lấy cảm hứng từ các công trình trước đây (Wu et al., 2023b; Yu et al., 2023; Wu et al., 2023a; Yang et al., 2023), bGPT thích ứng một kiến trúc Transformer phân cấp và phân đoạn một chuỗi byte B={b1, b2, ..., bT} có độ dài T thành một chuỗi các patch P, trong đó mỗi patch chứa chính xác S byte:

P = [P1, P2, . . . , PN], (1)

trong đó N=⌈T/S⌉ là số lượng patch, và Pi = [b(i−1)S+1, . . . , biS] cho 1≤i≤N. Nếu T mod S≠0, patch cuối cùng PN được định nghĩa là:

PN = [b(N−1)S+1, . . . , bT, e, . . . , e|{z}S−(TmodS)], (2)

trong đó e đại diện cho token <eop> (end-of-patch) được sử dụng để đệm patch cuối cùng PN đến kích thước S. Bằng cách phân đoạn các chuỗi byte thành các patch dễ quản lý hơn, bGPT cân bằng nhu cầu mô hình hóa chuỗi cấp độ byte với hiệu quả tính toán.

Như minh họa trong Hình 2, bGPT bao gồm ba thành phần chính: một lớp chiếu tuyến tính, một bộ giải mã cấp độ patch và một bộ giải mã cấp độ byte. bGPT xử lý chuỗi patch P thông qua các thành phần của nó như sau:

**Lớp Chiếu Tuyến tính**: Mỗi patch Pi từ P được xem như một ma trận có kích thước S×257, trong đó S là kích thước patch, và mỗi byte được mã hóa one-hot thành một vector 257D, bao gồm tất cả 256 giá trị byte và một token <eop>. Các patch này sau đó được làm phẳng thành các vector một chiều, trong đó các hàng trong ma trận được nối tuần tự. Lớp chiếu tuyến tính sau đó ánh xạ mỗi vector đã làm phẳng thành một vector dày đặc Ei có kích thước ẩn H. Đối với mỗi patch, hoạt động có thể được công thức hóa như:

Ei=Flatten(Pi)·Wlinear, 1≤i≤N, (3)

trong đó Wlinear là ma trận trọng số của lớp chiếu tuyến tính với hình dạng (S×257, H). Việc nhúng dày đặc này cho phép xử lý hiệu quả hơn chuỗi byte bằng cách giảm chiều trong khi bảo toàn thông tin thiết yếu có trong mỗi patch.

**Bộ Giải mã Cấp độ Patch**: Bộ giải mã này nhận chuỗi các patch đã nhúng E={E1, E2, . . . , EN} và xử lý nó để dự đoán tự hồi quy các đặc trưng của patch tiếp theo, học hiệu quả cấu trúc của dữ liệu:

Êi=Decoderpatch(E<i⊕X<i), (4)

trong đó E<i biểu thị chuỗi các patch embedding trước patch thứ i, và X<i đại diện cho các positional embedding tương ứng. Ký hiệu ⊕ biểu thị phép cộng theo từng phần tử của hai chuỗi này. Đầu ra, Êi, là đặc trưng dự đoán cho patch thứ i.

**Bộ Giải mã Cấp độ Byte**: Nó nhận đặc trưng dự đoán Êi của một patch riêng lẻ và tái tạo tự hồi quy chuỗi các byte trong patch đó. Quá trình này độc lập cho mỗi patch và hoạt động bằng cách điều kiện hóa trên biểu diễn đặc trưng Êi của patch hiện tại:

b̂i,j=Decoderbyte(Êi, bi,<j), 1≤j≤S, (5)

trong đó b̂i,j là byte dự đoán ở vị trí j trong patch thứ i, và bi,<j đại diện cho tất cả các byte trước đó trong patch hiện tại.

### 3.2. Mục tiêu Huấn luyện

Việc huấn luyện cho bGPT chủ yếu xoay quanh mô hình hóa tạo sinh thông qua dự đoán byte tiếp theo như trọng tâm cốt lõi, đóng vai trò then chốt trong việc dự đoán và tạo ra byte.

**Mô hình hóa Tạo sinh**: Nó nhằm dự đoán byte tiếp theo bi+1 trong một chuỗi dựa trên các byte trước đó {b1, b2, ..., bi} mà không cần hướng dẫn rõ ràng. Đối với một chuỗi byte B = {b1, b2, ..., bT} có độ dài T, mục tiêu là tối thiểu hóa log-likelihood âm của dự đoán byte tiếp theo trên toàn chuỗi, được định nghĩa là:

LGEN(θ) = −∑(i=1 to T-1) log p(bi+1|b1, b2, ..., bi; θ), (6)

trong đó θ đại diện cho các tham số mô hình, và p(·) biểu thị phân phối xác suất dự đoán trên các byte tiếp theo có thể. Hàm loss LGEN(·) trong mô hình hóa tạo sinh khuyến khích mô hình hiểu các phụ thuộc tuần tự trong dữ liệu ở cấp độ byte.

Sau khi được huấn luyện ban đầu về mô hình hóa tạo sinh qua dự đoán byte tiếp theo, bGPT được thích ứng thêm cho các nhiệm vụ phân loại với một mục tiêu huấn luyện mới.

**Phân loại**: Dựa trên nền tảng của mô hình hóa tạo sinh thông qua dự đoán byte tiếp theo, bGPT được huấn luyện thêm trên các tập dữ liệu có nhãn, nơi nó dự đoán các danh mục từ các chuỗi byte. Điều này bao gồm việc trích xuất một đặc trưng toàn cục từ chuỗi byte, sau đó được xử lý bởi một đầu phân loại. Mục tiêu là tối thiểu hóa loss phân loại LCLF, được công thức hóa như:

LCLF(θ) = −∑(k=1 to K) yk log p(yk|B; θ), (7)

trong đó yk là nhãn boolean cho danh mục thứ k, chỉ ra liệu chuỗi byte có thuộc (true) hay không thuộc (false) danh mục đó. K là tổng số danh mục, và p(yk|B; θ) là xác suất dự đoán của danh mục k cho trước chuỗi byte B.

## 4. Ứng dụng

Các mô hình byte như bGPT xuất sắc trong việc hiểu dữ liệu nhị phân, và có thành thạo trong xử lý tệp phương tiện số (ví dụ: văn bản, âm thanh và hình ảnh) và mô phỏng các hoạt động thuật toán và phần cứng để phân tích phần mềm và hệ thống số sâu sắc. Phần này giới thiệu các ứng dụng được chọn và các thiết lập thí nghiệm tương ứng để đánh giá bGPT được đề xuất.

### 4.1. Xử lý Phương tiện Số

Lĩnh vực học sâu đang tiến bộ ổn định trong việc thành thạo cả tạo sinh và phân loại các dạng phương tiện đa dạng, bao gồm văn bản, âm thanh và hình ảnh (Devlin et al., 2018; Ao et al., 2022; Ramesh et al., 2022), những yếu tố thiết yếu cho giao tiếp và trao đổi thông tin của con người. Các tệp phương tiện này, thường được lưu trữ và truyền dưới dạng chuỗi byte trên các thiết bị điện tử, cho phép bGPT xử lý nội dung số như vậy cho mô hình hóa tạo sinh và phân loại.

bGPT huấn luyện trong mô hình hóa tạo sinh để học biểu diễn thông qua dự đoán token tiếp theo. Sau đó nó sử dụng các đặc trưng từ lớp bộ giải mã cấp độ patch cuối cùng, sử dụng average pooling để rút ra các đặc trưng toàn cục cho phân loại.

Để đơn giản hóa quá trình huấn luyện, chúng tôi đã chuẩn hóa các tập dữ liệu âm thanh và hình ảnh. Các tệp âm thanh được chuyển đổi sang định dạng WAV, với các thông số kỹ thuật bao gồm tần số lấy mẫu 8000 Hz, kênh đơn và độ sâu 8-bit, mỗi tệp được cắt thành độ dài một giây. Dữ liệu hình ảnh được đặt thành định dạng BMP với độ phân giải 32×32, màu RGB và độ sâu 24-bit.

### 4.2. Mô phỏng Thuật toán và Phần cứng

Để chứng minh khả năng của các mô hình byte trong việc dự đoán và mô hình hóa các quá trình số, chúng tôi chọn hai ví dụ—chuyển đổi dữ liệu và mô hình hóa trạng thái CPU.

**Chuyển đổi Dữ liệu**: Quá trình này bao gồm việc chuyển đổi dữ liệu từ định dạng này sang định dạng khác, với các định dạng nhạc ký hiệu như ký hiệu ABC và tệp MIDI làm ví dụ chính của chúng tôi. Để biết thông tin nền về ký hiệu ABC và MIDI, vui lòng tham khảo Phụ lục A. Trong nhiệm vụ này, bGPT sử dụng cách tiếp cận mô hình hóa tạo sinh trên các chuỗi byte nối của các tệp ABC và MIDI được ghép đôi, được phân tách bởi một patch đặc biệt. Mô hình bGPT học chuyển đổi bản nhạc ký hiệu ABC dựa trên văn bản thành tín hiệu biểu diễn MIDI nhị phân và, ngược lại, chuyển đổi MIDI trở lại thành ký hiệu ABC. Điều này đòi hỏi khả năng mô phỏng và kỹ thuật đảo ngược thuật toán chuyển đổi, điều này chỉ ra một khả năng thiết yếu để mô hình hóa thế giới số.

**Mô hình hóa Trạng thái CPU**: Tương tự, mô hình được cung cấp các chuỗi nối của các lệnh máy cấp thấp theo sau bởi một loạt trạng thái thanh ghi CPU. Mục tiêu là dự đoán chính xác cách trạng thái cập nhật với mỗi lệnh cho đến khi chương trình dừng lại. Nhiệm vụ này chứng minh khả năng của bGPT trong việc diễn giải dữ liệu hoạt động và sao chép các hoạt động số trong phần cứng.

Đối với mô hình hóa trạng thái CPU, chúng tôi giới thiệu tập dữ liệu CPU States (với 2.1 triệu thể hiện), cung cấp một biểu diễn đơn giản hóa của hành vi CPU để dễ dàng thu thập và đánh giá dữ liệu. Mỗi thể hiện tập dữ liệu chứa một khối bộ nhớ 1KB với số lượng lệnh máy khác nhau, theo sau bởi một chuỗi các trạng thái thanh ghi CPU 16-byte. Các trạng thái này bao gồm nhiều lệnh khác nhau, tổng cộng 21 loại duy nhất với 43 biến thể, như di chuyển dữ liệu, hoạt động logic và hoạt động số học. Trong mỗi trạng thái, 1 byte mỗi được phân bổ cho Program Counter (PC) và Accumulator (ACC), 4 byte được phân bổ cho Instruction Register (IR), với thêm 10 byte được dành riêng cho các thanh ghi đa mục đích. Các thể hiện được tạo ra bằng cách thực hiện các chuỗi ngẫu nhiên từ 1 đến 256 lệnh và ghi lại trạng thái sau mỗi lần thực hiện. Mặc dù được đơn giản hóa, tập dữ liệu này mô phỏng hiệu quả hành vi CPU điển hình. Xem Phụ lục B để biết thêm chi tiết.

## 5. Thí nghiệm

### 5.1. Thiết lập

Các thí nghiệm của chúng tôi sử dụng các tập dữ liệu mã nguồn mở trên nhiều lĩnh vực khác nhau, bao gồm hình ảnh, lời nói, văn bản, hai loại nhạc ký hiệu và trạng thái CPU, như được nêu chi tiết trong Bảng 1. Các thiết lập huấn luyện nhất quán trên tất cả các mô hình bGPT và tập dữ liệu theo Bảng 2, hỗ trợ kích thước tệp lên đến 8KB sử dụng kích thước patch là 16 và độ dài chuỗi là 512. Mô hình bGPT 110M tham số phù hợp với quy mô mô hình dựa trên Transformer tiêu chuẩn. Đặc biệt, chúng tôi tránh điều chỉnh siêu tham số và tăng cường dữ liệu trong tất cả các đánh giá. Chúng tôi sử dụng độ chính xác (Acc) làm chỉ số để đánh giá hiệu suất phân loại và Bits-Per-Byte (BPB) cho các nhiệm vụ mô hình hóa tạo sinh khác, trừ khi được chỉ định khác.

### 5.2. Xử lý Phương tiện Số

Nghiên cứu nhằm đánh giá hiệu quả của bGPT trong việc xử lý các tệp phương tiện số ở cấp độ byte so với các mô hình chuyên biệt. Chúng tôi đã tuân theo cách tiếp cận tiền huấn luyện và tinh chỉnh tiêu chuẩn trong học sâu, tiền huấn luyện bGPT trên các tập dữ liệu đa dạng như ImageNet (bGPTimage), Wikipedia (bGPTwiki) và LibriSpeech (bGPTlibri). Chúng tôi cũng khám phá tác động của tiền huấn luyện hỗn hợp: bGPTsignal kết hợp các tập dữ liệu ImageNet và LibriSpeech, trong khi bGPTmix tích hợp cả ba tập dữ liệu. Một biến thể khởi tạo ngẫu nhiên bGPTrandom được sử dụng làm baseline. Các mô hình này đầu tiên được tinh chỉnh sử dụng dự đoán byte tiếp theo trên AG News, CIFAR-10 và Speech Commands v2, sau đó được tinh chỉnh thêm cho phân loại.

#### 5.2.1. BASELINES

Để so sánh baseline, chúng tôi đã chọn các mô hình dựa trên Transformer có quy mô tương tự xuất sắc trong các lĩnh vực tương ứng của chúng: GPT2-small (Radford et al., 2019) cho tạo sinh/phân loại văn bản, và ViT-B/16 (Dosovitskiy et al., 2021) và AST (Gong et al., 2021) cho phân loại hình ảnh và âm thanh tương ứng. GPT2-small được tiền huấn luyện trên Wikipedia tiếng Anh dưới cùng thiết lập như bGPT. ViT và AST được tiền huấn luyện trên ImageNet (Deng et al., 2009), và kết quả của chúng được lấy từ các nghiên cứu gốc. Trong trường hợp CIFAR-10 (Krizhevsky et al., 2009) và Speech Commands v2 (Warden, 2018), nơi thiếu các benchmark mô hình hóa tạo sinh, chúng tôi không báo cáo các chỉ số BPB.

#### 5.2.2. KẾT QUẢ

Bảng 3 trình bày kết quả của các mô hình bGPT và baseline khác nhau trên các benchmark khác nhau. Hiểu biết chính từ so sánh này là ảnh hưởng đáng kể của tiền huấn luyện đến hiệu suất mô hình trên tất cả các nhiệm vụ. Ví dụ, bGPTwiki được tiền huấn luyện trên Wikipedia hoạt động tốt trong các nhiệm vụ liên quan đến văn bản, trong khi bGPTlibri, được tiền huấn luyện trên LibriSpeech, xuất sắc trong các nhiệm vụ nội dung nói so với các biến thể khác. Điều này chỉ ra rằng các mô hình bGPT có thể đạt được hiệu suất tốt hơn trong các nhiệm vụ downstream khi có sự phù hợp chặt chẽ giữa tiền huấn luyện và tập dữ liệu tinh chỉnh, phù hợp với các nguyên tắc tiền huấn luyện tiêu chuẩn (Liu et al., 2022).

Mặc dù không có kiến thức tiên nghiệm cụ thể về phương thức, các mô hình bGPT vẫn có thể đạt được hiệu suất ngang bằng với các mô hình baseline. Ví dụ, bGPTwiki đạt điểm 1.0639 BPB và độ chính xác 92.49% trên AG News, mặc dù không hoàn toàn ở mức của GPT2-small với 0.9237 BPB và độ chính xác 94.50%, vẫn thể hiện hiệu suất cạnh tranh. Tương tự, bGPTlibri đạt độ chính xác 96.03% trên Speech Commands v2, gần với độ chính xác của AST ở 98.11%. Tuy nhiên, trong phân tích CIFAR-10, có thể thấy sự khác biệt đáng chú ý với bGPTimage tụt lại sau ViT, với độ chính xác 88.69% so với 98.13%. Sự khác biệt này trong các nhiệm vụ hình ảnh có thể do bản chất xử lý tuần tự của các mô hình byte, gặp khó khăn trong việc nắm bắt các mối quan hệ không gian hai chiều thiết yếu trong hình ảnh (Yu et al., 2023). Mặc dù vậy, đơn giản là mở rộng quy mô mô hình trong khi giữ lại cách tiếp cận xử lý tuần tự này vẫn có thể có triển vọng để đạt kết quả tối tân (Chen et al., 2020).

Các mô hình bGPT được tiền huấn luyện trên các phương thức hỗn hợp, cụ thể là bGPTsignal và bGPTmix, tạo ra hiệu suất thường phù hợp với hiệu suất trung bình của các mô hình được tiền huấn luyện trên các phương thức riêng lẻ. Ví dụ, bGPTmix trên tập dữ liệu AG News, với BPB là 1.0935 và độ chính xác 91.75%, vượt trội hơn các biến thể khác nhưng không đạt được hiệu suất do bGPTwiki thể hiện, được điều chỉnh cụ thể cho dữ liệu văn bản. Các xu hướng tương tự có thể được quan sát trong trường hợp bGPTsignal, thường cho thấy mức hiệu suất nằm ở đâu đó giữa bGPTimage và bGPTlibri. Điều này minh họa sự đánh đổi trong các mô hình byte—trong khi tiền huấn luyện đa phương thức thúc đẩy tính linh hoạt, nó có thể làm loãng độ sâu hiểu biết cụ thể về lĩnh vực.

Một quan sát đáng chú ý khác từ Bảng 3 là kết quả hỗn hợp trong tinh chỉnh chéo phương thức trên các mô hình bGPT, với cả hiệu ứng chuyển giao tích cực và tiêu cực. Chuyển giao tích cực xảy ra khi các mô hình được tiền huấn luyện trên một loại dữ liệu (ví dụ: bGPTlibri trên LibriSpeech cho âm thanh hoặc bGPTimage trên ImageNet cho hình ảnh) được tinh chỉnh trên các nhiệm vụ của phương thức khác, cho thấy cải thiện không tầm thường so với khởi tạo ngẫu nhiên. Điều này gợi ý các mẫu byte được chia sẻ giữa các phương thức như âm thanh và hình ảnh. Tuy nhiên, chuyển giao tiêu cực được quan sát khi chuyển đổi giữa văn bản và các phương thức khác, chỉ ra rằng lợi ích của việc học mẫu có cấu trúc trong tiền huấn luyện không áp dụng phổ quát. Văn bản, như một sự trừu tượng hóa do con người tạo ra, thể hiện các mẫu tổ chức cấp độ byte khác biệt đáng kể so với dữ liệu âm thanh và thị giác, điều này có thể giải thích các hiệu ứng chuyển giao tiêu cực được quan sát trong tinh chỉnh chéo phương thức liên quan đến văn bản.

Để tiếp tục điều tra chuyển giao kiến thức chéo phương thức trong các mô hình byte, chúng tôi đánh giá hiệu suất của chúng trên tập dữ liệu Speech Commands v2, được chuyển đổi thành spectrogram BMP 32×32. Quá trình này, chuyển đổi các tệp âm thanh 8KB thành hình ảnh 3KB, chắc chắn dẫn đến mất thông tin. Tuy nhiên, trọng tâm của chúng tôi chuyển sang khám phá các sắc thái của động lực chuyển giao kiến thức thay vì chỉ tăng hiệu suất. Chúng tôi đã chọn hai mô hình tiền huấn luyện để đánh giá: bGPTimage để có tính nhất quán định dạng dữ liệu với spectrogram và bGPTlibri để có tính tương tự thông tin với spectrogram (cả hai đều liên quan đến lời nói). Các mô hình này được sử dụng cho mô hình hóa tạo sinh có điều kiện và phân loại, theo một quy trình tương tự như trong Bảng 3.

Kết quả của Bảng 4 tiết lộ BPB phù hợp chặt chẽ giữa bGPTimage và bGPTlibri, gợi ý rằng sự khác biệt được quan sát trong hiệu suất CIFAR-10 của chúng không mở rộng đến nhiệm vụ dựa trên spectrogram này. Điều này là do CIFAR-10, bao gồm các cảnh tự nhiên, chia sẻ ít mẫu hơn với spectrogram so với các điểm chung giữa spectrogram và âm thanh thô. Đáng chú ý, bGPTlibri, được tiền huấn luyện trên âm thanh, đạt độ chính xác cao hơn bGPTimage trên spectrogram với nội dung lời nói, chỉ ra chuyển giao chéo phương thức hiệu quả và tầm quan trọng của việc căn chỉnh nội dung hơn là chỉ định dạng dữ liệu. Điều này gợi ý rằng các mô hình byte sở hữu khả năng vốn có để phân biệt và dịch các đặc trưng và mẫu dữ liệu trừu tượng độc lập với định dạng hoặc phương thức cụ thể của đầu vào.

Cùng nhau, những kết quả này xác nhận tính linh hoạt và khả năng thích ứng của các mô hình bGPT trong việc xử lý dữ liệu phương tiện số và chuyển giao kiến thức qua các phương thức, ngay cả khi các định dạng dữ liệu khác nhau. Điều này nhấn mạnh tiềm năng của các mô hình byte để tích hợp kiến thức được chia sẻ từ nhiều nguồn khác nhau để tăng cường hiểu biết thế giới số.

### 5.3. Mô phỏng Thuật toán và Phần cứng

Mục tiêu chính của đánh giá này là đánh giá khả năng của bGPT trong việc mô phỏng thuật toán và phần cứng. Do thiếu các mô hình baseline và các tập dữ liệu được sử dụng rộng rãi, chúng tôi đã điều tra hiệu suất của nó trên các quy mô dữ liệu khác nhau, đánh giá khả năng mở rộng của bGPT trên dữ liệu nhị phân. Điều này được thực hiện thông qua hai nhiệm vụ: chuyển đổi dữ liệu và mô hình hóa trạng thái CPU, sử dụng các quy mô dữ liệu từ 103 (bGPT3), 104 (bGPT4), 105 (bGPT5), đến 106 (bGPT6).

Để đảm bảo rằng kết quả chủ yếu được thúc đẩy bởi quy mô dữ liệu, tất cả các mô hình đều được khởi tạo ngẫu nhiên. Đối với chuyển đổi dữ liệu, chúng tôi sử dụng tập dữ liệu IrishMAN (Wu et al., 2023a), bao gồm các tệp ABC notation và MIDI được ghép đôi, được đánh giá trên các quy mô từ 103 đến 105. Đối với mô hình hóa trạng thái CPU, chúng tôi sử dụng tập dữ liệu CPU States, được đánh giá trên các quy mô từ 104 đến 106.

#### 5.3.1. CHUYỂN ĐỔI DỮ LIỆU

Nhiệm vụ chuyển đổi giữa ký hiệu ABC và MIDI đánh giá khả năng của các mô hình byte để mô phỏng các thuật toán hoạt động với cả định dạng dữ liệu có thể hiểu được bởi con người (ký hiệu ABC) và nhị phân gốc (MIDI). Trong khi các nghiên cứu trước đây tránh mô hình hóa MIDI trực tiếp do bản chất nhị phân của nó (Huang et al., 2019; Zeng et al., 2021; Hsiao et al., 2021), các mô hình byte phù hợp tự nhiên cho nhiệm vụ này, vì chúng có thể làm việc trực tiếp với dữ liệu nhị phân.

Chúng tôi tính toán riêng các giá trị BPB cho mỗi định dạng để đo lường rõ ràng hiệu suất mô hình. Ví dụ, trong chuyển đổi ABC sang MIDI, BPBabc đánh giá mô hình hóa tạo sinh, vì mô hình tạo ra nội dung từ đầu. Trong khi BPBmidi đánh giá chuyển đổi dữ liệu, xem xét toàn bộ chuỗi byte ABC được cung cấp.

Chúng tôi quan sát thấy loss khởi đầu thấp hơn và hội tụ nhanh hơn trong Hình 3a khi quy mô dữ liệu tăng, chỉ ra rằng khối lượng dữ liệu tăng trực tiếp tăng cường hiệu suất mô hình trong việc mô phỏng quá trình chuyển đổi dữ liệu. Từ Bảng 5, chúng ta thấy rằng khi quy mô dữ liệu tăng, BPB cho cả chuyển đổi ABC sang MIDI và MIDI sang ABC đều giảm đáng kể. Mô hình bGPT5 đạt BPBmidi cực kỳ thấp là 0.0011 trong chuyển đổi ABC sang MIDI, cực kỳ gần với hiệu suất hoàn hảo (nơi BPB đạt 0), vượt trội hơn hiệu suất của mô hình bGPT3 nhiều bậc độ lớn.

Bảng 5 gợi ý BPB cao hơn nhất quán cho ABC trong cả hai hướng, có thể do hai yếu tố: 1) Chuyển đổi thuận từ ABC sang MIDI tập trung vào việc mô phỏng một thuật toán hiện có với thông tin cần thiết, trong khi quá trình ngược từ MIDI sang ABC đòi hỏi suy luận và tái tạo thông tin bị thiếu trong các tệp MIDI như cấu trúc bản nhạc, trang trí âm nhạc và biểu cảm. 2) Vì MIDI là định dạng nhị phân cấp thấp hơn và ký hiệu ABC là định dạng văn bản có thể đọc được bởi con người, các mô hình byte có thể thấy dễ dàng hơn để học các mẫu trong các tệp MIDI.

#### 5.3.2. MÔ HÌNH HÓA TRẠNG THÁI CPU

Mô hình hóa trạng thái CPU nhằm sao chép chức năng CPU bằng cách dự đoán các cập nhật cho các trạng thái nội bộ từ các lệnh máy. Chúng tôi sử dụng bGPT để dự đoán các trạng thái này, chọn byte có xác suất cao nhất ở mỗi bước dựa trên các lệnh hoàn chỉnh và trạng thái ban đầu. Độ chính xác được đánh giá thông qua so sánh theo từng byte với các trạng thái thực tế.

Chúng tôi phát hiện ra rằng khối lượng dữ liệu ảnh hưởng đáng kể đến hiệu suất mô hình hóa. Bảng 6 cho thấy các biến thiên hiệu suất đáng kể, với sự giảm BPB đáng chú ý từ bGPT4 đến bGPT5, nhưng lợi nhuận giảm dần vượt quá bGPT5. Cả bGPT5 và bGPT6 đều đạt độ chính xác gần hoàn hảo (99.97% và 99.99%), gợi ý một hiệu quả vượt quá việc ghi nhớ đơn giản, cho rằng mỗi trường hợp thử nghiệm chứa trung bình 128 lệnh ngẫu nhiên, và các tổ hợp tiềm năng khổng lồ của các tình huống lệnh (hơn 516 triệu).

Một cải thiện đáng kể trong hiệu suất của bGPT5 xảy ra khoảng epoch 11, như được thể hiện trong Hình 3b, chỉ ra một khả năng nổi lên trong mô hình hóa trạng thái CPU. Bước nhảy này, đặc biệt trong BPB và độ chính xác khi so sánh bGPT4 và bGPT5, gợi ý hiểu biết sâu sắc hơn về trạng thái CPU có thể xuất phát từ sự tăng cường định tính trong khả năng. Điều này phù hợp với khái niệm về khả năng nổi lên trong các LM lớn (Wei et al., 2022), nơi các khả năng dường như tự phát sinh với quy mô và độ phức tạp.

Tuy nhiên, tồn tại sự hoài nghi về việc liệu những cải thiện này có phản ánh việc học thực sự hay không (Schaeffer et al., 2023). Các nhà phê bình cho rằng những tăng hiệu suất có thể do các chỉ số phi tuyến hoặc overfitting. Tuy nhiên, bản chất tuyến tính và mượt mà của BPB phản bác điều này, chỉ ra rằng những cải thiện có thể xuất phát từ sự hiểu biết thực sự về các hoạt động CPU, gợi ý việc học nhất quán thay vì các bất thường chỉ số.

Tóm lại, bGPT thể hiện khả năng mở rộng mạnh mẽ trên dữ liệu nhị phân gốc với các khả năng nổi lên trong chuyển đổi dữ liệu và mô hình hóa trạng thái CPU, điều này làm sáng tỏ khả năng mạnh mẽ của nó trong các nhiệm vụ mô phỏng thuật toán và phần cứng. Trong khi các nhiệm vụ được sử dụng để chứng minh trong nghiên cứu này không quá phức tạp, hiệu suất gần hoàn hảo được quan sát trong các bối cảnh này chỉ ra tiềm năng rộng lớn hơn của các mô hình byte để mô phỏng và kỹ thuật đảo ngược một loạt rộng các thuật toán và phần cứng.

## 6. Kết luận

Trong bài báo này, chúng tôi trình bày bGPT như một bộ mô phỏng đa năng cho thế giới số, mở rộng học sâu sang xử lý dữ liệu nhị phân thông qua dự đoán byte tiếp theo. Các thí nghiệm của chúng tôi chứng minh hiệu quả của bGPT trong việc mô hình hóa dữ liệu phương tiện số, thể hiện chuyển giao kiến thức bất khả tri phương thức. Chúng tôi quan sát khả năng mở rộng mạnh mẽ của bGPT trong việc mô hình hóa dữ liệu nhị phân gốc và thậm chí các dấu hiệu của khả năng nổi lên. bGPT hoạt động tương đương với các mô hình chuyên biệt trên các tập dữ liệu đa dạng mà không có thiết kế cụ thể theo phương thức, và xuất sắc trong chuyển đổi dữ liệu và mô hình hóa trạng thái CPU, chứng minh tiềm năng của nó để mô phỏng nhiều thuật toán và phần cứng khác nhau.

Tuy nhiên, các thí nghiệm của chúng tôi làm sáng tỏ các cơ hội cải thiện. Trong nghiên cứu này, chúng tôi giới hạn việc mô hình hóa cho các đoạn âm thanh ngắn và hình ảnh độ phân giải thấp, hệ quả của bản chất tiêu tốn tài nguyên vốn có của các mô hình byte. Do tài nguyên tính toán hạn chế, chúng tôi chỉ điều tra chuyển đổi dữ liệu giữa ký hiệu ABC và MIDI, mà không có đánh giá rộng hơn trên các định dạng thay thế. Hơn nữa, để đơn giản hóa thu thập dữ liệu và đánh giá, các thí nghiệm mô hình hóa trạng thái CPU của chúng tôi chỉ tập trung vào các CPU đơn giản hóa, bỏ qua việc sử dụng CPU hiện đại thực, phức tạp hơn đáng kể.

Các hướng nghiên cứu tương lai cho các mô hình byte bao gồm: 1) giảm chi phí tính toán để làm cho việc huấn luyện các mô hình byte khả thi hơn; 2) mở rộng quy mô mô hình và kích thước tập dữ liệu để phù hợp với phạm vi rộng hơn của dữ liệu nhị phân gốc, cũng như xử lý các tệp phương tiện số lớn hơn như hình ảnh và video độ phân giải cao; và 3) cải thiện hiệu suất mô hình, đặc biệt cho các nhiệm vụ chưa được khám phá liên quan đến dữ liệu nhị phân gốc trên các lĩnh vực ứng dụng đa dạng.

## 7. Tuyên bố Tác động

Trong bài báo này, chúng tôi giới thiệu bGPT, một mô hình được thiết kế để xử lý dữ liệu nhị phân và mô hình hóa thế giới số, đẩy ranh giới của học sâu vào lĩnh vực dữ liệu nhị phân gốc. Sự đổi mới này cho phép bGPT trực tiếp diễn giải và thao tác dữ liệu nhị phân, cung cấp những hiểu biết sâu sắc về các hệ thống số. Trong khi bGPT mang lại những tiến bộ trong việc hiểu và mô hình hóa thế giới số, nó cũng đòi hỏi việc xem xét cẩn thận các tác động đạo đức và tác động tiềm tàng đến các chuẩn mực xã hội và khung pháp lý.

Khả năng mô phỏng hoặc kỹ thuật đảo ngược thuật toán và phần cứng của nó có hai tác động chính: 1) nó có thể tăng cường đáng kể sự đổi mới công nghệ, hỗ trợ trong việc phát triển an ninh mạng, phần mềm và phần cứng bằng cách hiểu và cải thiện các công nghệ hiện có; 2) nó gây ra rủi ro cho tài sản trí tuệ, vì việc huấn luyện bGPT trên các tập dữ liệu rộng lớn của mã nguồn và phần mềm thực thi được ghép đôi, có thể cho phép kỹ thuật đảo ngược phần mềm độc quyền. Khả năng này, trong khi thể hiện tiềm năng của nó, có thể tạo điều kiện cho việc truy cập trái phép hoặc sửa đổi phần mềm, làm phát sinh các vấn đề bảo mật và pháp lý.

Kết luận, trong khi bGPT và các mô hình byte tương tự cung cấp những cơ hội thú vị để thúc đẩy hiểu biết và khả năng của chúng ta trong thế giới số, việc triển khai chúng đòi hỏi sự xem xét chu đáo về các tác động đạo đức, xã hội và pháp lý. Điều này đặc biệt quan trọng để bảo vệ tài sản trí tuệ và đảm bảo an ninh chống lại việc sử dụng có thể có ác ý.

# 2210.15553.pdf
# Đã chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/summarization/2210.15553.pdf
# Kích thước file: 781570 bytes

===============================================
NỘI DUNG FILE PDF
===============================================

--- TRANG 1 ---
Cải thiện tóm tắt trừu tượng với việc xếp hạng lại dựa trên năng lượng
Diogo PernesÁçAfonso MendesÁAndré F. T. MartinsÈÉÆ
ÁPriberamçUniversidade do Porto
ÈInstituto de TelecomunicaçõesÉLUMLIS (Lisbon ELLIS Unit), Instituto Superior TécnicoÆUnbabel
Lisbon, Portugal
diogo.pernes@priberam.pt ,
amm@priberam.pt ,andre.t.martins@tecnico.ulisboa.pt .

Tóm tắt
Các hệ thống tóm tắt trừu tượng hiện tại
thể hiện những điểm yếu quan trọng ngăn cản
việc triển khai chúng trong các ứng dụng thực tế,
chẳng hạn như việc bỏ sót thông tin liên quan
và tạo ra những sự không nhất quán thực tế
(còn được gọi là ảo giác). Đồng thời, các
chỉ số đánh giá tự động như điểm CTC (Deng
et al., 2021) đã được đề xuất gần đây và thể hiện
mức độ tương quan cao hơn với đánh giá của
con người so với các chỉ số chồng lắp từ vựng
truyền thống như ROUGE. Trong nghiên cứu này,
chúng tôi có ý định khép kín vòng lặp bằng cách
tận dụng những tiến bộ gần đây trong các chỉ số
tóm tắt để tạo ra các bộ tóm tắt trừu tượng có
nhận thức chất lượng. Cụ thể, chúng tôi đề xuất
một mô hình dựa trên năng lượng học cách xếp
hạng lại các bản tóm tắt theo một hoặc kết hợp
của các chỉ số này. Chúng tôi thử nghiệm sử dụng
nhiều chỉ số để huấn luyện bộ xếp hạng lại dựa
trên năng lượng và cho thấy nó liên tục cải thiện
điểm số đạt được bởi các bản tóm tắt được dự đoán.
Tuy nhiên, kết quả đánh giá của con người cho thấy
phương pháp xếp hạng lại nên được sử dụng một
cách cẩn thận đối với các bản tóm tắt có tính trừu
tượng cao, vì các chỉ số hiện có vẫn chưa đủ đáng
tin cậy cho mục đích này.

1 Giới thiệu
Trong những năm gần đây, các phương pháp trừu tượng đã
được hưởng lợi rất nhiều từ việc phát triển và sự sẵn có
rộng rãi của các mô hình sinh ngôn ngữ dựa trên transformer
quy mô lớn (Vaswani et al., 2017; Lewis et al., 2020; Raffel
et al., 2020; Zhang et al., 2020), có khả năng tạo ra văn bản
với độ trôi chảy chưa từng có. Mặc dù có tiến bộ gần đây,
các hệ thống tóm tắt trừu tượng vẫn gặp phải những vấn đề
cản trở việc triển khai chúng trong các ứng dụng thực tế.
Việc bỏ sót thông tin quan trọng nhất từ tài liệu nguồn là
một trong những vấn đề như vậy. Ngoài ra, sự không nhất
quán thực tế (còn được gọi là ảo giác) được ước tính có mặt
trong khoảng 30% các bản tóm tắt được tạo ra bởi các hệ
thống trừu tượng trên bộ dữ liệu CNN/DailyMail (Kryscinski
et al., 2019). Quan sát này đã thúc đẩy một lượng nghiên cứu
đáng kể về các chiến lược để giảm thiểu vấn đề ảo giác (Falke
et al., 2019; Cao et al., 2020; Zhao et al., 2020; Zhu et al.,
2021), nhưng những cải thiện đạt được cho đến nay vẫn còn
nhẹ. Điều này một phần do khó khăn trong việc đánh giá
chất lượng của các bản tóm tắt một cách tự động, dẫn đến
việc áp dụng các chỉ số thường không đủ hoặc thậm chí
không phù hợp. Mặc dù có những hạn chế, ROUGE (Lin, 2004)
vẫn là chỉ số đánh giá de facto cho tóm tắt, chủ yếu do tính
đơn giản và khả năng diễn giải của nó. Tuy nhiên, nó không
chỉ tương quan kém với chất lượng tóm tắt được đánh giá
bởi con người (Kané et al., 2019), mà còn không đáng tin cậy
bất cứ khi nào bản tóm tắt tham chiếu chứa ảo giác, điều này
thật không may không phải là vấn đề hiếm gặp trong các bộ
dữ liệu tóm tắt được áp dụng rộng rãi (Kryscinski et al., 2019;
Maynez et al., 2020). Vì những lý do này, việc phát triển các
chỉ số đánh giá đáng tin cậy hơn với mức độ tương quan mạnh
hơn với đánh giá của con người cũng là một lĩnh vực nghiên
cứu tích cực (Kryscinski et al., 2020; Scialom et al., 2021;
Deng et al., 2021).

Trong nghiên cứu này, chúng tôi đề xuất một phương pháp
mới cho tóm tắt trừu tượng thông qua một mô hình dựa trên
năng lượng. Trái ngược với các phương pháp trước đây, sử
dụng học tăng cường để huấn luyện các mô hình tối đa hóa
điểm ROUGE hoặc BERT (Paulus et al., 2018; Li et al., 2019),
EBM của chúng tôi được huấn luyện để xếp hạng lại các bản
tóm tắt ứng viên theo cách mà chỉ số đã chọn sẽ xếp hạng
chúng - một vấn đề đơn giản hơn nhiều và hiệu quả hơn về
mặt tính toán. Theo cách này, chúng tôi đang chưng cất chỉ
số, điều này mang lại một lợi thế bổ sung như một sản phẩm
phụ: một hệ thống ước tính chất lượng có thể được sử dụng
để đánh giá chất lượng của các bản tóm tắt ngay lập tức mà
không cần bản tóm tắt tham chiếu. Cần lưu ý rằng bất kỳ
chỉ số không tham chiếu nào, đều có thể được sử dụng tại
thời điểm suy luận để xếp hạng lại các ứng viên từ bất kỳ
hệ thống tóm tắt trừu tượng nào, do đó cải thiện chất lượng
của các bản tóm tắt được tạo ra. Do đó, mô hình xếp hạng lại
của chúng tôi có thể tận dụng những lợi thế của các chỉ số
đánh giá được đề xuất gần đây so với các chỉ số truyền thống,
về cơ bản có hai mặt: i) có khả năng nắm bắt tốt hơn các
khái niệm ngữ nghĩa cấp cao, và ii) ngoài bản tóm tắt đích,
các chỉ số này tính đến thông tin có mặt trong tài liệu nguồn,
điều này rất quan trọng để phát hiện ảo giác. Chúng tôi chứng
minh tính hiệu quả của phương pháp trên các bộ dữ liệu
benchmark tiêu chuẩn cho tóm tắt trừu tượng (CNN/DailyMail,
Hermann et al. (2015), và XSum, Narayan et al. (2018)) và
sử dụng nhiều chỉ số tóm tắt khác nhau làm mục tiêu để
huấn luyện mô hình của chúng tôi, cho thấy tính linh hoạt
của phương pháp. Chúng tôi cũng thực hiện một thử nghiệm
đánh giá của con người, trong đó chúng tôi so sánh mô hình
xếp hạng lại của chúng tôi được huấn luyện để tối đa hóa
các chỉ số dựa trên transformer gần đây nhằm đo lường tính
nhất quán thực tế và mức độ liên quan (điểm CTC, Deng
et al. (2021)). Mô hình được đề xuất của chúng tôi mang lại
những cải thiện so với tìm kiếm chùm thông thường trên một
mô hình cơ sở và chứng minh khả năng chưng cất các chỉ số
mục tiêu. Tuy nhiên, kết quả đánh giá của con người cho thấy
việc xếp hạng lại theo các chỉ số này, mặc dù có tính cạnh
tranh, có thể tạo ra các bản tóm tắt chất lượng thấp hơn so
với những bản được tạo ra bởi các hệ thống trừu tượng
hiện đại được huấn luyện với dữ liệu được tăng cường và
học tương phản.

Phần còn lại của bài báo được tổ chức như sau: trong Mục 2,
chúng tôi thảo luận về các nghiên cứu liên quan; trong Mục 3,
chúng tôi thực hiện một mô tả ngắn gọn cấp cao về các hệ
thống tóm tắt trừu tượng thần kinh và cách các bản tóm tắt
ứng viên khác nhau có thể được tạo ra từ chúng; trong Mục 4,
chúng tôi mô tả phương pháp của chúng tôi một cách chi tiết,
cũng như các chỉ số tóm tắt mà chúng tôi sẽ sử dụng để
huấn luyện mô hình xếp hạng lại của chúng tôi; Mục 5 trình
bày kết quả thử nghiệm của mô hình và các baseline của
chúng tôi, bao gồm cả đánh giá tự động và của con người;
trong Mục 6, chúng tôi thảo luận về những hạn chế của
phương pháp và chỉ ra một số hướng cho nghiên cứu tương
lai, và chúng tôi kết thúc nghiên cứu này với một số nhận
xét cuối cùng trong Mục 7.

2 Nghiên cứu liên quan
Trong bối cảnh tạo ngôn ngữ tự nhiên, ý tưởng xếp hạng lại
các ứng viên đã được nghiên cứu rộng rãi cho dịch máy
thần kinh (Shen et al., 2004; Mizumoto và Matsumoto, 2016;
Ng et al., 2019; Salazar et al., 2020; Fernandes et al., 2022),
nhưng chỉ hiếm khi được khám phá cho tóm tắt trừu tượng.
Trong số những nghiên cứu trước, phương pháp của Bhattacharyya
et al. (2021) tương tự nhất với chúng tôi vì họ cũng sử dụng
một mô hình dựa trên năng lượng để xếp hạng lại các ứng viên.
Tuy nhiên, họ không áp dụng phương pháp của họ cho tóm
tắt trừu tượng và mục tiêu huấn luyện của họ khác với mục
tiêu mà chúng tôi sẽ định nghĩa cho mô hình của chúng tôi:
tại mỗi bước huấn luyện, họ lấy mẫu một cặp ứng viên, và
mô hình được huấn luyện sao cho sự khác biệt giữa năng
lượng của hai ứng viên ít nhất bằng sự khác biệt của điểm
BLEU của chúng (Papineni et al., 2002). Do đó, phương pháp
của họ chỉ khai thác thông tin của hai ứng viên tại mỗi bước
huấn luyện. Gần đây, các mục tiêu học cải tiến như tổn thất
tương phản đã được đề xuất để nâng cao chất lượng của
các bản tóm tắt được dự đoán, đặc biệt là tính nhất quán
thực tế của chúng. Tang et al. (2022), Cao và Wang (2021),
và Liu et al. (2021) sử dụng tăng cường dữ liệu để tạo ra
cả câu nhất quán và không nhất quán về mặt thực tế và sử
dụng chúng trong một mục tiêu học tương phản để điều chỉnh
các biểu diễn học được của transformer. Trong một hướng
nghiên cứu khác, Cao et al. (2020) và Zhao et al. (2020)
huấn luyện các mô hình riêng biệt về nhiệm vụ sửa các sự
không nhất quán thực tế trong các bản tóm tắt được dự đoán.
Zhu et al. (2021) trình bày một mô hình học cách trích xuất
đồ thị kiến thức từ tài liệu nguồn và sử dụng nó để điều
kiện hóa bước giải mã. Goyal và Durrett (2021) huấn luyện
một mô hình để phát hiện các token không thực tế và sử dụng
nó để xác định và loại bỏ các token này khỏi dữ liệu huấn
luyện của bộ tóm tắt. Aralikatte et al. (2021) sửa đổi phân
phối đầu ra của mô hình để tập trung nhiều hơn vào các token
từ vựng tương tự với các token đầu vào được chú ý. Mặc dù
là những ý tưởng hợp lý, các kỹ thuật này chủ yếu tập trung
vào việc định nghĩa lại mục tiêu huấn luyện của mô hình và
bỏ qua cơ hội cải thiện chất lượng tóm tắt tại thời điểm suy
luận, bằng cách thiết kế lại thuật toán lấy mẫu hoặc sử dụng
xếp hạng lại. Trong một hướng có phần tương tự với chúng
tôi, một nghiên cứu đương thời (Liu et al., 2022) đề xuất sử
dụng một mục tiêu xếp hạng làm một thuật ngữ bổ sung trên
tổn thất negative log-likelihood thông thường. Tương tự như
chúng tôi, Liu và Liu (2021) và Ravaut et al. (2022) đề xuất
sử dụng một bộ xếp hạng lại được huấn luyện như một bước
hậu tạo. Nghiên cứu trước sử dụng một mục tiêu tương phản
để học một bộ xếp hạng lại mô phỏng điểm ROUGE. Nghiên
cứu sau sử dụng một hỗn hợp các chuyên gia để huấn luyện
một bộ xếp hạng lại trên sự kết hợp của điểm ROUGE, BERT
và BART.

--- TRANG 3 ---
3 Các hệ thống tóm tắt trừu tượng
Một mô hình tóm tắt trừu tượng điển hình xấp xỉ phân phối
có điều kiện p(y|x), của các bản tóm tắt y cho các tài liệu
nguồn x, và hoạt động một cách tự hồi quy, khai thác quy
tắc chuỗi của xác suất:
p(y|x) = ∏(i=1 to l+1) p(y^(i)|x; y_{0:(i-1)}); (1)
trong đó y^(0) là một token bắt đầu chuỗi, các y^(1);...;y^(l)
tiếp theo là các token trong bản tóm tắt, từ đầu đến cuối,
và y^(l+1) là một token kết thúc chuỗi. Thông thường, các
tham số của mô hình này được ước tính theo tiêu chí maximum
likelihood, bằng cách tối thiểu hóa tổn thất negative log-likelihood
cho một bộ dữ liệu huấn luyện {(x_i; y_i)}_{i=1}^n chứa các
tài liệu nguồn x_i được ghép cặp với các bản tóm tắt tham
chiếu y_i tương ứng.

Thông thường, quá trình giải mã nhằm tìm chuỗi có khả năng
xảy ra cao nhất y* cho x đã cho, tức là y* = arg max_y p(y|x).
Vì việc tìm kiếm chuỗi có khả năng xảy ra cao nhất là bất
khả thi do bùng nổ tổ hợp, các heuristic tìm kiếm mode như
giải mã tham lam và tìm kiếm chùm được sử dụng trong thực tế.
Ngay cả khi có thể tìm được chuỗi tối ưu, không đảm bảo
rằng đây sẽ là bản tóm tắt tốt nhất cho tài liệu đã cho. Một
lý do chính cho điều này là phân phối được học bởi mô hình
chỉ là một xấp xỉ của phân phối có điều kiện thực, và bảo
tồn một số kiến thức nền được thu thập trong quá trình tiền
huấn luyện không giám sát của mô hình ngôn ngữ cơ bản.
Điều này chịu trách nhiệm cho sự hiện diện của thông tin
bổ sung trong bản tóm tắt mà không có trong tài liệu nguồn,
đây là dạng ảo giác phổ biến nhất trong tóm tắt (Maynez et al., 2020).
Một nguồn vấn đề khác là tiếng ồn trong các bộ dữ liệu huấn
luyện, thường được thu thập tự động từ web với ít sự giám
sát của con người (Kryscinski et al., 2019).

Về bản chất, việc tìm mục tiêu huấn luyện và thuật toán giải
mã tối ưu để có được bản tóm tắt tốt nhất vẫn là một vấn đề
mở. Chúng tôi thực hiện một bước theo hướng này bằng cách
lấy mẫu một tập hợp các bản tóm tắt ứng viên {ŷ_1; ŷ_2; ...; ŷ_k}
và sau đó sử dụng một mô hình xếp hạng lại để chọn bản tốt
nhất. Để đảm bảo các ứng viên đa dạng, chúng tôi thử nghiệm
với tìm kiếm chùm đa dạng (Vijayakumar et al., 2016), một
sửa đổi của tìm kiếm chùm truyền thống bao gồm một thuật
ngữ trong hàm tính điểm để phạt việc lặp lại giữa các chùm
khác nhau.

4 Xếp hạng lại dựa trên năng lượng
4.1 Công thức hóa
Chính thức, một chỉ số tóm tắt là một hàm Ψ: X×Y×Y → R
nhận đầu vào là tài liệu nguồn x ∈ X, bản tóm tắt tham chiếu
được viết bởi con người y ∈ Y, và bản tóm tắt được tạo ra
ŷ ∈ Y, và xuất ra một vô hướng, thường trong khoảng đơn vị,
đo lường chất lượng của bản tóm tắt được tạo ra. Không mất
tính tổng quát, trong nghiên cứu này chúng tôi giả định rằng
giá trị cao hơn của chỉ số cho thấy bản tóm tắt tốt hơn (như
được đánh giá bởi chỉ số). Sau đó, đối với một chỉ số tóm tắt
Ψ đã cho, mục tiêu của chúng tôi là tìm một hàm không tham
chiếu E_θ: X×Y → R với các tham số θ sao cho, đối với hai
bản tóm tắt ứng viên ŷ và ŷ' cho cùng một tài liệu x với bản
tóm tắt tham chiếu y, E_θ(x; ŷ; θ) < E_θ(x; ŷ'; θ) khi và chỉ
khi Ψ(x; y; ŷ) > Ψ(x; y; ŷ'). Theo tinh thần của các mô hình
dựa trên năng lượng (LeCun et al., 2006), E_θ nên gán năng
lượng thấp ở nơi p(y|x) cao và năng lượng cao ở nơi p(y|x)
thấp, nhưng không cần được chuẩn hóa như một mật độ thích
hợp. Chính xác hơn, E_θ nên thỏa mãn p(y|x) ∝ exp(−E_θ(x; y; θ)).

Dưới góc nhìn này, tại thời điểm huấn luyện, Ψ hoạt động
như một proxy cho phân phối có điều kiện thực, mà chúng ta
không biết. Tại thời điểm suy luận, việc lấy mẫu các bản tóm
tắt trực tiếp từ phân phối được định nghĩa bởi mô hình dựa
trên năng lượng là một nhiệm vụ không tầm thường vì mô
hình này không được định nghĩa theo cách tự hồi quy (Eikema
et al., 2021), không giống như các mô hình encoder-decoder
tiêu chuẩn cho tóm tắt. Do đó, chúng tôi sử dụng điểm số của
nó để xếp hạng lại các bản tóm tắt ứng viên đã được thu thập
trước đó từ một mô hình tóm tắt baseline.

4.2 Huấn luyện và suy luận
Chúng tôi giả định có quyền truy cập vào một bộ dữ liệu huấn
luyện D = {(x_i; y_i; Ŷ_i)}_{i=1}^n, trong đó x_i và y_i lần
lượt là tài liệu nguồn thứ i và bản tóm tắt tham chiếu tương
ứng và Ŷ_i = {ŷ_{i,1}; ŷ_{i,2}; ...; ŷ_{i,k}} là một tập hợp
(tối đa) k bản tóm tắt ứng viên được lấy mẫu từ một mô hình
tóm tắt baseline, chẳng hạn như BART (Lewis et al., 2020)
hoặc PEGASUS (Zhang et al., 2020). Một số kỹ thuật đã được
đề xuất để huấn luyện các mô hình dựa trên năng lượng mà
tránh việc tính toán rõ ràng hàm phân vùng Z(x; θ) = ∫_Y exp(−E_θ(x; y; θ)) dy
và gradient của nó, thường là bất khả thi (Song và Kingma, 2021).
Ở đây, với dữ liệu này và chỉ số Ψ, chúng tôi áp dụng tổn
thất xếp hạng ListMLE (Xia et al., 2008) làm mục tiêu huấn
luyện. Cụ thể, mô hình được huấn luyện để tối thiểu hóa:

L(θ) = E_{(x,y,Ŷ)∈D} [−log ∏_{i=1}^k exp(−E_θ(x; ŷ_i; θ)/τ) / ∑_{j=i}^k exp(−E_θ(x; ŷ_j; θ)/τ)]; (2)

trong đó τ > 0 là một siêu tham số nhiệt độ và các ứng viên
ŷ_1; ŷ_2; ...; ŷ_k được sắp xếp sao cho nếu i < j thì Ψ(x; y; ŷ_i) ≥ Ψ(x; y; ŷ_j).

Để có một số trực giác về hàm tổn thất này, hãy định nghĩa:
i) r_i là biến ngẫu nhiên tương ứng với bản tóm tắt được xếp
hạng thứ i trong danh sách k ứng viên ŷ_1; ŷ_2; ...; ŷ_k và
ii) xác suất r_1 nhận giá trị ŷ_1 là:

P(r_1 = ŷ_1|x) = exp(−E_θ(x; ŷ_1)/τ) / ∑_{j=1}^k exp(−E_θ(x; ŷ_j)/τ); (3)

trong đó chúng tôi đã bỏ qua các tham số để ngắn gọn. Giả
định rằng i−1 ứng viên đầu tiên được xếp hạng đúng, xác
suất ứng viên thứ i cũng được xếp hạng đúng là xác suất
nó được xếp hạng đầu tiên trong danh sách ŷ_i; ŷ_{i+1}; ...; ŷ_k, do đó:

P(r_i = ŷ_i|x; r_{1:(i-1)} = ŷ_{1:(i-1)}) = exp(−E_θ(x; ŷ_i)/τ) / ∑_{j=i}^k exp(−E_θ(x; ŷ_j)/τ). (4)

Sau đó, từ quy tắc chuỗi, xác suất tất cả k ứng viên được
xếp hạng đúng là:

P(r_{1:k} = ŷ_{1:k}|x) = ∏_{i=1}^k P(r_i = ŷ_i|x; r_{1:(i-1)} = ŷ_{1:(i-1)})
= ∏_{i=1}^k exp(−E_θ(x; ŷ_i)/τ) / ∑_{j=i}^k exp(−E_θ(x; ŷ_j)/τ). (5)

Do đó, P(r_{1:k}|x) là một phân phối trên tất cả các hoán vị
có thể của k ứng viên và việc tối thiểu hóa tổn thất L tối đa
hóa likelihood của hoán vị đúng, tức là hoán vị được tạo ra
bằng cách xếp hạng các ứng viên ŷ_1; ...; ŷ_k theo chỉ số
Ψ(x; y; ·). Tại thời điểm suy luận, cho một danh sách không
được sắp xếp Ŷ của k bản tóm tắt ứng viên cho tài liệu x,
chúng tôi chọn ứng viên ŷ* có khả năng cao nhất là được
xếp hạng đầu:

ŷ* = arg max_{ŷ∈Ŷ} P(r_1 = ŷ|x) = arg min_{ŷ∈Ŷ} E_θ(x; ŷ). (6)

Do đó, mô hình dựa trên năng lượng của chúng tôi nhằm xếp
hạng một tập hợp ứng viên theo cách mà chỉ số sẽ xếp hạng
chúng, nhưng nó làm điều này mà không có quyền truy cập
vào bản tóm tắt tham chiếu y. Do đó, đây là một cách để
chưng cất thông tin chứa trong chỉ số thành một mô hình
duy nhất và không tham chiếu có thể xếp hạng các giả thuyết
tóm tắt ngay lập tức.

4.3 Các chỉ số được áp dụng
Cho đến nay, định nghĩa của chỉ số tóm tắt mà chúng tôi đã
cung cấp là chung chung, vì vậy bây giờ chúng tôi tập trung
vào việc mô tả các chỉ số cụ thể mà chúng tôi đã sử dụng
để huấn luyện mô hình của chúng tôi. Các chỉ số tóm tắt có
thể được chia thành hai nhóm: phụ thuộc tham chiếu và không
tham chiếu, tùy thuộc vào việc Ψ có thực sự cần bản tóm tắt
tham chiếu hay không. Trong trường hợp sau, Ψ(x; y; ŷ) =
Ψ'(x; ŷ) ∀y, cho một hàm Ψ' nào đó. Do đó, các chỉ số phụ
thuộc tham chiếu chủ yếu được sử dụng để đánh giá và so
sánh các hệ thống tóm tắt, trong khi các chỉ số không tham
chiếu cũng có thể được sử dụng để đánh giá chất lượng tóm
tắt ngay lập tức. Do đó, việc huấn luyện mô hình dựa trên
năng lượng của chúng tôi sử dụng các chỉ số phụ thuộc tham
chiếu cung cấp một cách gián tiếp để sử dụng các chỉ số này
cho mục đích sau.

Việc đánh giá chất lượng của một bản tóm tắt một cách tự
động là một nhiệm vụ không tầm thường vì nó phụ thuộc
vào các khái niệm cấp cao, chẳng hạn như tính nhất quán
thực tế, mức độ liên quan, tính mạch lạc và độ trôi chảy
(Lloret et al., 2018). Những khái niệm này được nắm bắt
một cách lỏng lẻo bởi các chỉ số cổ điển (Kané et al., 2019;
Kryscinski et al., 2019) như ROUGE, về cơ bản đo lường
sự chồng lắp n-gram giữa ŷ và y. Tuy nhiên, trong những
năm gần đây, sự sẵn có của các mô hình biểu diễn ngôn ngữ
mạnh mẽ như BERT (Devlin et al., 2019) đã cho phép và
thúc đẩy việc phát triển một số chỉ số tự động dựa trên transformer.

Có một số chỉ số dựa trên tạo câu hỏi (QG) và trả lời câu
hỏi (QA) (Wang et al., 2020; Durmus et al., 2020). Trong
số này, QuestEval (Scialom et al., 2021) thể hiện mức độ
tương quan mạnh nhất với đánh giá của con người. Chỉ số
này sử dụng một mô hình QG để tạo câu hỏi từ cả tài liệu
nguồn x và bản tóm tắt ứng viên ŷ và một mô hình QA để
lấy câu trả lời từ cả hai, sau đó được so sánh để tạo ra một
điểm số trong khoảng đơn vị. Ngoài các mô hình QA và QG,
QuestEval sử dụng một mô hình bổ sung để xác định trọng
số quan trọng của mỗi câu hỏi được tạo từ x. Mặc dù là
không tham chiếu, chỉ số này tốn kém về mặt tính toán, vì
vậy điều quan trọng là phải điều tra xem mô hình của chúng
tôi có thể tạo ra xếp hạng tương tự một cách hiệu quả hơn
hay không.

Theo một mô hình khác, Deng et al. (2021) đề xuất một bộ
chỉ số cho các nhiệm vụ tạo ngôn ngữ tự nhiên, được gọi
là điểm CTC, dựa trên khái niệm căn chỉnh thông tin. Họ
định nghĩa căn chỉnh của một tài liệu a với một tài liệu b,
ký hiệu là align(a→b), như một vector có độ dài bằng a trong
đó vị trí thứ i là một vô hướng trong [0; 1] biểu thị độ tin
cậy rằng thông tin trong token thứ i của a được căn cứ trong b.
Đối với các nhiệm vụ tóm tắt, hai chỉ số dựa trên căn chỉnh
được đề xuất, một cho tính nhất quán thực tế và một cho
mức độ liên quan, cả hai đều đạt kết quả hiện đại trong tương
quan với đánh giá của con người. Một bản tóm tắt được tạo
ra ŷ nhất quán với tài liệu nguồn x nếu tất cả thông tin trong
ŷ được hỗ trợ bởi x, do đó điểm nhất quán là:

CTC_{consistency}(x; ŷ) = mean(align(ŷ→x)). (7)

Đối với mức độ liên quan, các tác giả lập luận rằng, ngoài
việc nhất quán, ŷ nên chứa càng nhiều thông tin càng tốt
từ bản tóm tắt tham chiếu y, vì vậy họ định nghĩa điểm
mức độ liên quan là:

CTC_{relevance}(x; y; ŷ) = mean(align(ŷ→x)) · mean(align(y→ŷ)). (8)

Rõ ràng, cả hai chỉ số đều tạo ra một điểm số trong khoảng
đơn vị, với nhất quán là không tham chiếu và mức độ liên
quan là phụ thuộc tham chiếu.

5 Thử nghiệm
5.1 Bộ dữ liệu
Chúng tôi đánh giá mô hình và các baseline của chúng tôi
trên hai bộ dữ liệu benchmark cho tóm tắt trừu tượng:
CNN/DailyMail (Hermann et al., 2015) và XSum (Narayan
et al., 2018), cả hai đều chứa các bài báo tin tức được ghép
cặp với các bản tóm tắt tham chiếu tương ứng. Trong XSum,
mỗi bản tóm tắt bao gồm một câu duy nhất, trong khi trong
CNN/DailyMail nó có thể bao gồm ba câu trở lên. XSum cũng
được biết đến là có tính trừu tượng hơn và có nhiều ảo giác
hơn CNN/DailyMail (Narayan et al., 2018; Maynez et al., 2020).

5.2 Baselines
Một mô hình BART (Lewis et al., 2020) được huấn luyện trên
mục tiêu maximum likelihood thông thường là baseline của
chúng tôi. Các bản tóm tắt được lấy mẫu từ mô hình này sử
dụng tìm kiếm chùm thông thường. Ngoài ra, chúng tôi cũng
so sánh mô hình của chúng tôi với các phương pháp hiện đại
sau: BRIO, của Liu et al. (2022), sử dụng một tổn thất xếp
hạng làm một thuật ngữ bổ sung trong việc huấn luyện hệ
thống trừu tượng; CLIFF, của Cao và Wang (2021), sử dụng
các kỹ thuật tăng cường dữ liệu và học tương phản để nâng
cao tính nhất quán thực tế của các bản tóm tắt; DAE, được
đề xuất bởi Goyal và Durrett (2021), phát hiện và loại bỏ
các token không thực tế khỏi dữ liệu huấn luyện; FASum,
của Zhu et al. (2021), kết hợp đồ thị kiến thức cũng để nâng
cao tính nhất quán thực tế; SummaReranker, của Ravaut
et al. (2022), sử dụng một hỗn hợp các chuyên gia để huấn
luyện một bộ xếp hạng lại trên sự kết hợp của các chỉ số
khác nhau. Trong Phụ lục B, chúng tôi cũng thử nghiệm huấn
luyện mô hình xếp hạng lại với mục tiêu max-margin được
đề xuất bởi Bhattacharyya et al. (2021) cho dịch máy và
chúng tôi trình bày các kết quả thu được bằng cách sử dụng
một bộ xếp hạng lại hoàn hảo cho CTC_{consistency} và QuestEval,
điều này khả thi vì các chỉ số này là không tham chiếu.

5.3 Chi tiết triển khai
Mô hình xếp hạng lại dựa trên năng lượng của chúng tôi
(EBR-ListMLE) bao gồm một BERT nhận đầu vào là một cặp
(x; ŷ), của tài liệu nguồn x và bản tóm tắt ứng viên ŷ, và
xuất ra điểm năng lượng tương ứng E_θ(x; ŷ). Các ứng viên
được lấy mẫu sử dụng tìm kiếm chùm đa dạng (Vijayakumar
et al., 2016) trên một encoder-decoder BART được tinh chỉnh
trên bộ dữ liệu tóm tắt tương ứng. Các chi tiết triển khai
khác được cung cấp trong Phụ lục A. Vì mục đích tái tạo,
mã nguồn và các mô hình đã huấn luyện của chúng tôi cũng
có sẵn công khai. Về các baseline, chúng tôi sử dụng mã
nguồn chính thức và các checkpoint mô hình cho CLIFF và
DAE. Mô hình sau chỉ được đánh giá trên bộ dữ liệu XSum
vì không có checkpoint nào có sẵn cho CNN/DailyMail. Vì
cùng lý do, BRIO chỉ được đánh giá trên CNN/DailyMail. Đối
với FASum, chúng tôi sử dụng trực tiếp các bản tóm tắt được
dự đoán đã được phát hành vì đây là tài nguyên duy nhất
có sẵn.

5.4 Chỉ số
Chúng tôi huấn luyện mô hình của chúng tôi sử dụng các
chỉ số được thảo luận trong mục 4.3 làm chỉ số mục tiêu Ψ.
Cụ thể, chúng tôi thử nghiệm với ROUGE-L, QuestEval,
CTC_{relevance}, và CTC_{relevance} + CTC_{consistency}.
Điểm ROUGE, QuestEval và điểm CTC mỗi loại thuộc về
một mô hình đánh giá khác nhau và vì vậy thật thú vị khi
điều tra tác động của chúng lên phương pháp xếp hạng lại
của chúng tôi. Điều quan trọng cần chỉ ra là CTC_{consistency}
là một chỉ số không tham chiếu có độ phức tạp tính toán
tương tự như bộ xếp hạng lại của chúng tôi, vì vậy việc
huấn luyện mô hình của chúng tôi dựa trên chỉ số đó một
mình là vô nghĩa. Thay vào đó, chúng tôi báo cáo kết quả
sử dụng chỉ số này trực tiếp để xếp hạng lại trong Phụ lục B.
Tuy nhiên, việc kết hợp (tức là cộng) nó với CTC_{relevance}
tạo ra một chỉ số thú vị vì nó tính đến hai thuộc tính cơ
bản của một bản tóm tắt: tính nhất quán thực tế và mức độ
liên quan. QuestEval cũng là không tham chiếu nhưng nó
tốn kém hơn nhiều về mặt tính toán vì nó yêu cầu một bước
tạo câu hỏi và một bước trả lời câu hỏi. Do đó, chúng tôi
huấn luyện mô hình của chúng tôi với chỉ số này và báo cáo
thời gian tính toán để so sánh. Để đánh giá, ngoài các chỉ
số đã nêu, chúng tôi cũng báo cáo kết quả cho ROUGE-1,
ROUGE-2, và FactCC (Kryscinski et al., 2020), đây là một
chỉ số dựa trên điểm NLI.

5.5 Đánh giá tự động
5.5.1 So sánh với các baseline
Kết quả thu được bởi mô hình và các baseline của chúng tôi
được trình bày trong Bảng 1. Chúng tôi sử dụng 8 ứng viên
cho các mô hình xếp hạng lại và tìm kiếm chùm với 8 chùm
cho các baseline. Tác động của việc sử dụng số lượng ứng
viên khác nhau để xếp hạng lại được nghiên cứu trong Phụ
lục C. Có thể nhận thấy rằng kết quả tốt nhất cho tất cả
các chỉ số được đạt được bởi các mô hình EBR, ngoại trừ
điểm ROUGE, trong đó BRIO, CLIFF, và SummaReranker
thường vượt trội hơn các mô hình của chúng tôi. SummaReranker
có thể là đối thủ mạnh nhất với các mô hình của chúng tôi,
đạt được điểm ROUGE gần như tốt nhất trong cả hai bộ dữ
liệu và vượt trội hơn baseline BART trong hầu hết các chỉ
số còn lại. Đáng ngạc nhiên, DAE và FASum có điểm thấp
hơn BART trong đại đa số các chỉ số tự động. Thật không
may, các tác giả của DAE không cung cấp kết quả cho bất
kỳ chỉ số nào trong số này. Về FASum, các tác giả có cung
cấp điểm ROUGE cho mô hình của họ nhưng họ đánh giá
tính nhất quán thực tế bằng một chỉ số tùy chỉnh mà họ
không phát hành bản triển khai.

Trong số các mô hình xếp hạng lại, kết quả tốt nhất cho
một chỉ số nhất định được đạt được khi mô hình được huấn
luyện để xếp hạng lại theo chỉ số đó, như mong đợi. Cũng
thú vị khi quan sát rằng việc huấn luyện cho một chỉ số
nhất định thường mang lại cải thiện trong các chỉ số còn
lại. Điều này có thể là dấu hiệu cho thấy mô hình xếp hạng
học được một thước đo hữu ích về chất lượng tóm tắt, thay
vì khai thác các lỗ hổng có thể có của các chỉ số. Mô hình
tốt nhất tổng thể có thể là EBR-ListMLE được huấn luyện
cho CTC_{consistency} + CTC_{relevance}, đạt được kết quả
gần như tốt nhất trong tất cả các chỉ số ngoại trừ điểm ROUGE,
được biết là tương quan kém hơn với đánh giá của con người.

Chúng tôi cũng so sánh thời gian suy luận của mô hình với
thời gian tính toán của hai chỉ số không tham chiếu,
CTC_{consistency} và QuestEval. Chúng tôi thực hiện thử
nghiệm này bằng cách lấy mẫu 1000 cặp (tài liệu, tóm tắt)
từ tập kiểm tra của bộ dữ liệu CNN/DailyMail và tính toán
điểm số từng cái một (tức là không có mini-batching) sử
dụng mô hình của chúng tôi và mỗi chỉ số. Kết quả trong
Bảng 2. Thời gian tính toán của CTC_{consistency} có thể
so sánh với, nhưng lớn hơn, thời gian của EBR của chúng
tôi, với sự khác biệt được giải thích bởi thực tế là cái trước
dựa trên mô hình RoBERTa-large (Zhuang et al., 2021) và
cái sau sử dụng BERT-base. Như đã lập luận trước đó và
được xác nhận bởi những kết quả này, việc tính toán QuestEval
mất nhiều thời gian hơn hai bậc độ lớn, điều này thúc đẩy
việc chưng cất chỉ số này thành một EBR.

5.5.2 Thử nghiệm chéo mô hình
Một câu hỏi thú vị cần điều tra là liệu mô hình của chúng
tôi có học được một xấp xỉ tổng quát của chỉ số mục tiêu Ψ,
thay vì chỉ học cách nhận biết các đặc trưng tương quan với
Ψ nhưng cụ thể cho hệ thống tóm tắt đã tạo ra các ứng viên.
Vì mục đích này, chúng tôi thử nghiệm sử dụng một bộ tóm
tắt trừu tượng khác để tạo ra các ứng viên kiểm tra so với
bộ được sử dụng để tạo ra các ứng viên huấn luyện. Cụ thể,
chúng tôi áp dụng cùng các mô hình EBR như trong Mục 5.5.1,
được huấn luyện sử dụng các bản tóm tắt được lấy mẫu từ
BART, để xếp hạng lại các bản tóm tắt thu được từ PEGASUS
(Zhang et al., 2020). Như trước đây, chúng tôi thu được 8
bản tóm tắt ứng viên cho mỗi tài liệu nguồn sử dụng tìm
kiếm chùm. Trong thử nghiệm này, baseline của chúng tôi
là PEGASUS không có xếp hạng lại. Kết quả trong Bảng 3
và xác nhận rằng các mô hình EBR của chúng tôi đã học
cách mô phỏng các chỉ số tương ứng một cách trung thực.
Điểm số tốt nhất cho mỗi chỉ số được đạt được bởi mô hình
EBR được huấn luyện cho chỉ số đó. Hơn nữa, khi được đánh
giá với các chỉ số khác nhau, các mô hình này có xu hướng
vượt qua baseline PEGASUS trong đại đa số các trường hợp.

--- TRANG 7 ---
[Tiếp tục với bảng kết quả và phần đánh giá của con người...]

5.6 Đánh giá của con người
Mặc dù kết quả đánh giá tự động hứa hẹn, việc tối ưu hóa
trực tiếp một chỉ số là rủi ro vì không có chỉ số nào trong
số này tương quan hoàn hảo với đánh giá của con người.
Vì lý do này, việc tiến hành đánh giá của con người là rất
quan trọng. Cụ thể, chúng tôi yêu cầu các giám khảo thực
hiện so sánh từng cặp giữa các bản tóm tắt được tạo ra bởi
ba mô hình: BART, CLIFF, là baseline được công bố mạnh
nhất tại thời điểm chúng tôi tiến hành nghiên cứu này, và
EBR của chúng tôi được huấn luyện cho CTC_{consistency} +
CTC_{relevance} và xếp hạng lại các ứng viên từ BART. Chúng
tôi chọn các chỉ số này cho EBR vì chúng thể hiện mức độ
tương quan mạnh hơn với đánh giá của con người so với
các chỉ số còn lại (Deng et al., 2021) và rõ ràng tính đến
hai thuộc tính chính của một bản tóm tắt: tính nhất quán
thực tế và mức độ liên quan. Đối với mỗi tài liệu nguồn,
chúng tôi trình bày ba cặp bản tóm tắt liên tiếp, tương ứng
với tất cả các kết hợp từng cặp của các bản tóm tắt được
tạo ra bởi ba hệ thống. Sau đó, chúng tôi yêu cầu các giám
khảo xếp hạng các bản tóm tắt trong mỗi cặp theo ba tiêu
chí: tính nhất quán thực tế, mức độ liên quan và độ trôi
chảy. Đối với mỗi tiêu chí, các giám khảo phải đánh giá
xem bản tóm tắt đầu tiên có tốt hơn, ngang bằng hay tệ
hơn bản tóm tắt thứ hai. Tên của các hệ thống tạo ra mỗi
bản tóm tắt không được hiển thị cho các giám khảo và thứ
tự mà các bản tóm tắt được trình bày được ngẫu nhiên hóa.
Chúng tôi lấy mẫu ngẫu nhiên 30 tài liệu nguồn từ tập kiểm
tra của CNN/DailyMail và 30 khác từ tập kiểm tra của XSum,
vì vậy mỗi giám khảo được yêu cầu so sánh 180 cặp bản
tóm tắt. Ảnh chụp màn hình và mô tả giao diện người dùng
của biểu mẫu đánh giá được cung cấp trong Phụ lục D.1.
Chúng tôi tuyển dụng hai giám khảo cho nhiệm vụ này, là
các chuyên gia về ngôn ngữ học. Kết quả được trình bày
trong Bảng 4. Quan sát đầu tiên là mô hình EBR của chúng
tôi thành công trong việc cải thiện chất lượng của các ứng
viên được lấy mẫu từ BART trên bộ dữ liệu CNN/DailyMail
trong cả ba tiêu chí. Trên XSum, các cải thiện là nhỏ hoặc
thậm chí không có, ngoại trừ về mặt độ trôi chảy. Bản thân
mô hình EBR có độ tin cậy thấp hơn đối với các dự đoán
được thực hiện trên bộ dữ liệu XSum: như được hiển thị
trong Hình 1, mô hình EBR thường gán năng lượng cao hơn
cho các bản tóm tắt XSum so với các bản tóm tắt CNN/DailyMail.
Thực tế là mô hình của chúng tôi cải thiện độ trôi chảy, mà
nó không được huấn luyện cho, có thể cho thấy rằng có một
bias ngầm trong mô hình của chúng tôi và/hoặc trong các
chỉ số mục tiêu (CTC_{consistency} và CTC_{relevance}) hướng
tới các bản tóm tắt trôi chảy hơn. Đáng ngạc nhiên, việc
so sánh mô hình của chúng tôi với CLIFF mâu thuẫn với kết
quả của đánh giá tự động (Bảng 1), đặc biệt trên bộ dữ liệu
XSum. Ba lý do có thể giải thích hiện tượng này: i) số lượng
nhỏ các tài liệu được sử dụng cho đánh giá của con người
so với kích thước của toàn bộ tập kiểm tra, ii) EBR thất
bại trong việc xếp hạng lại các ứng viên theo các chỉ số
mục tiêu trên các tài liệu này, và iii) những hạn chế của
bản thân các chỉ số. Để điều tra điều gì là đúng, chúng tôi
tính toán các giá trị thực tế của CTC_{consistency} và
CTC_{relevance} trên các ví dụ từ XSum được sử dụng cho
đánh giá của con người. Về CTC_{consistency}, các bản tóm
tắt của EBR đạt điểm số tốt hơn so với CLIFF trong 22 trường
hợp (trên 30), với điểm số trung bình 83.9% so với 80.2%
cho CLIFF. Đối với CTC_{relevance}, EBR thắng CLIFF trong
20 trường hợp, với điểm số trung bình 54.3% và 49.9%, tương
ứng. Chúng tôi cũng đã kiểm tra các ví dụ cụ thể (được hiển
thị trong Phụ lục D.2) trong đó các giám khảo đồng ý rằng
bản tóm tắt CLIFF tốt hơn bản tóm tắt EBR về mặt tính nhất
quán thực tế. Điều này chỉ xảy ra trong ba trường hợp, nhưng
trong tất cả chúng, bản tóm tắt EBR có ảo giác rõ ràng và
bản tóm tắt CLIFF thì không. Tuy nhiên, trong hai trong số
đó, điểm CTC_{consistency} của các bản tóm tắt EBR lớn hơn
so với các bản tóm tắt CLIFF, điều này xác nhận những khiếm
khuyết của chỉ số.

6 Hạn chế và nghiên cứu tương lai
Mặc dù có những cải thiện đạt được bởi mô hình EBR của
chúng tôi, khả năng ứng dụng của nó về cơ bản phụ thuộc
vào sự sẵn có của các chỉ số đánh giá tự động đáng tin cậy.
Thật không may, mức độ tương quan của các chỉ số này với
đánh giá của con người vẫn không hoàn hảo, đặc biệt đối
với các bản tóm tắt có tính trừu tượng cao. Ngoài ra, các
chỉ số dựa trên transformer hiện tại chỉ có sẵn cho tiếng
Anh. Cuối cùng, các mô hình backbone của chúng được huấn
luyện trên dữ liệu tin tức, điều này cản trở độ tin cậy của
các chỉ số này trong các lĩnh vực khác. Do đó, việc tiếp
tục theo đuổi các chỉ số đáng tin cậy hơn và mở rộng chúng
sang nhiều ngôn ngữ và lĩnh vực hơn là rất quan trọng.

7 Kết luận
Chúng tôi đã đề xuất một mô hình xếp hạng lại dựa trên năng
lượng có thể được huấn luyện để xếp hạng các bản tóm tắt
ứng viên theo một chỉ số được xác định trước, tận dụng những
tiến bộ gần đây trong các chỉ số tóm tắt tự động để nâng
cao chất lượng của các bản tóm tắt được tạo ra. Các thử
nghiệm cho thấy mô hình xếp hạng lại được đề xuất thành
công trong việc chưng cất các chỉ số mục tiêu, liên tục cải
thiện điểm số của các bản tóm tắt được tạo ra. Tuy nhiên,
những cải thiện này không phải lúc nào cũng đồng ý với
đánh giá của con người, đặc biệt trong bối cảnh trừu tượng
hơn (XSum), do những khiếm khuyết của các chỉ số mục tiêu
được áp dụng (điểm CTC). Tuy nhiên, phương pháp được đề
xuất linh hoạt theo nghĩa là chúng tôi có thể huấn luyện
nó với bất kỳ chỉ số mục tiêu nào và áp dụng nó cùng với
hầu như bất kỳ hệ thống tóm tắt trừu tượng nào.

Lời cảm ơn
Nghiên cứu này được hỗ trợ bởi dự án SELMA EU H2020
(thỏa thuận tài trợ số 957017).

Tài liệu tham khảo
[Phần tài liệu tham khảo tiếp tục với định dạng học thuật tiêu chuẩn...]

# Cân bằng Chất lượng Từ vựng và Ngữ nghĩa trong Tóm tắt Trừu tượng

Jeewoo Sul và Yong Suk Choi
Khoa Khoa học Máy tính
Đại học Hanyang, Seoul, Hàn Quốc
{jeewoo25, cys}@hanyang.ac.kr

## Tóm tắt

Một vấn đề quan trọng của các mô hình nơ-ron sequence-to-sequence được sử dụng rộng rãi trong tóm tắt trừu tượng là thiên lệch phơi bày. Để giảm thiểu vấn đề này, các hệ thống xếp hạng lại đã được áp dụng trong những năm gần đây. Mặc dù có một số cải thiện về hiệu suất, phương pháp này vẫn chưa được khám phá đầy đủ. Các nghiên cứu trước đây chủ yếu xác định thứ hạng thông qua điểm ROUGE và sắp xếp các bản tóm tắt ứng viên, nhưng có thể có khoảng cách khá lớn giữa thang đo trùng lặp từ vựng và tương đồng ngữ nghĩa. Trong bài báo này, chúng tôi đề xuất một phương pháp huấn luyện mới trong đó một bộ xếp hạng lại cân bằng chất lượng từ vựng và ngữ nghĩa. Chúng tôi tiếp tục định nghĩa mới các dương tính giả trong xếp hạng và trình bày một chiến lược để giảm ảnh hưởng của chúng. Các thí nghiệm trên bộ dữ liệu CNN/DailyMail và XSum cho thấy phương pháp của chúng tôi có thể ước tính ý nghĩa của các bản tóm tắt mà không làm giảm nghiêm trọng khía cạnh từ vựng. Cụ thể hơn, nó đạt được BERTScore 89.67 trên bộ dữ liệu CNN/DailyMail, đạt hiệu suất tiên tiến nhất mới. Mã nguồn của chúng tôi có sẵn công khai tại https://github.com/jeewoo1025/BalSum.

## 1. Giới thiệu

Hiệu suất của các mô hình nơ-ron sequence-to-sequence (Seq2Seq) cho tóm tắt trừu tượng (Lewis et al., 2020; Nallapati et al., 2016; See et al., 2017; Zhang et al., 2020) đã được cải thiện đáng kể. Mô hình huấn luyện chủ đạo của các mô hình Seq2Seq là Maximum Likelihood Estimation (MLE), tối đa hóa khả năng của mỗi đầu ra được đưa ra lịch sử vàng của các chuỗi mục tiêu trong quá trình huấn luyện. Tuy nhiên, vì các mô hình tạo ra chuỗi theo cách tự hồi quy trong quá trình suy luận, các lỗi được tạo ra trong các bước trước đó tích lũy trong bước tiếp theo từ đó ảnh hưởng đến toàn bộ chuỗi. Hiện tượng này được gọi là thiên lệch phơi bày (Bengio et al., 2015; Ranzato et al., 2016). Để giảm thiểu vấn đề này, các hệ thống xếp hạng lại (Liu et al., 2021; Liu và Liu, 2021; Liu et al., 2022; Ravaut et al., 2022) gần đây đã được giới thiệu để tạo ra một bản tóm tắt phù hợp hơn.

Có hai mục tiêu huấn luyện để áp dụng xếp hạng lại cho tóm tắt trừu tượng: học đối tỷ và học đa nhiệm vụ. Các phương pháp dựa trên học đối tỷ triển khai các tổn thất dựa trên biên. SimCLS (Liu và Liu, 2021) và BRIO-Ctr (Liu et al., 2022) huấn luyện một mô hình được tiền huấn luyện lớn, như RoBERTa (Liu et al., 2019) và BART (Lewis et al., 2020), để sắp xếp các bản tóm tắt ứng viên theo chất lượng. Các tác giả sử dụng điểm ROUGE (Lin, 2004) như một thang đo chất lượng. Các phương pháp dựa trên học đa nhiệm vụ kết hợp ít nhất hai tổn thất thực hiện các vai trò khác nhau. SummaReranker (Ravaut et al., 2022) tối thiểu hóa trung bình của các tổn thất entropy chéo nhị phân được tối ưu hóa cho mỗi thang đo đánh giá. Ngoài ra, BRIO-Mul (Liu et al., 2022) chứng minh rằng sự kết hợp của tổn thất đối tỷ và entropy chéo hoạt động bổ sung và có hiệu suất tốt hơn.

Trong bài báo này, chúng tôi phân tích ba nhược điểm chính của các phương pháp xếp hạng lại hiện có. Đầu tiên, chúng tôi lập luận rằng các phương pháp hiện tại tập trung quá mức vào việc xếp hạng các bản tóm tắt về mặt trùng lặp từ vựng. Được truyền cảm hứng bởi Zhong et al. (2020), chúng tôi tiến hành một nghiên cứu sơ bộ, bằng cách sắp xếp các bản tóm tắt ứng viên theo thứ tự giảm dần dựa trên điểm ROUGE và sau đó định nghĩa z là chỉ số thứ hạng của bản tóm tắt có BERTScore cao nhất. Như được chứng minh trong Hình 1, chúng ta có thể quan sát thấy rằng có một khoảng cách lớn giữa trùng lặp từ vựng và tương đồng ngữ nghĩa. Trong phần lớn (52%) các trường hợp z > 1. Thứ hai, mặc dù hơn một nửa các ứng viên có cùng điểm ROUGE, các nghiên cứu trước đây không phản ánh chính xác các thang đo chất lượng vì chúng được huấn luyện với các thứ hạng khác nhau ngay cả khi chúng có điểm số bằng nhau (Phụ lục F). Cuối cùng, lần đầu tiên, chúng tôi tìm thấy các bản tóm tắt có trùng lặp từ vựng cao nhưng tương đồng ngữ nghĩa thấp như dương tính giả (Phụ lục G). Chúng có thể là nhiễu trong giai đoạn huấn luyện, không được xem xét đáng kể trong các nghiên cứu trước đây.

Để giải quyết những vấn đề này, chúng tôi đề xuất một phương pháp huấn luyện mới trong đó một bộ xếp hạng lại cân bằng chất lượng từ vựng và ngữ nghĩa. Dựa trên khung hai giai đoạn, mô hình của chúng tôi, có tên BalSum, được huấn luyện trên học đa nhiệm vụ. Chúng tôi phản ánh trực tiếp sự khác biệt điểm ROUGE trên tổn thất xếp hạng để bảo tồn chất lượng từ vựng càng nhiều càng tốt. Sau đó, chúng tôi sử dụng tổn thất đối tỷ với trọng số instance để xác định các bản tóm tắt có ý nghĩa gần với tài liệu. Cụ thể, chúng tôi định nghĩa các dương tính giả mới (sai lầm ngữ nghĩa) và trình bày một chiến lược để giảm ảnh hưởng của chúng trong xếp hạng. Các thí nghiệm trên bộ dữ liệu CNN/DM và XSum chứng minh tính hiệu quả của phương pháp chúng tôi. Đáng chú ý, BalSum đạt được BERTScore 89.67 trên CNN/DM, đạt hiệu suất tiên tiến nhất mới.

## 2. Phương pháp

Phương pháp của chúng tôi tuân theo khung hai giai đoạn. Cho một tài liệu nguồn D, một hàm g là để tạo ra một nhóm các bản tóm tắt ứng viên C = {C₁, C₂, ..., Cₘ} ở giai đoạn đầu tiên:

C ← g(D)                                               (1)

Sau đó, một hàm f là để gán điểm cho mỗi ứng viên và chọn bản tóm tắt tốt nhất C* với điểm cao nhất ở giai đoạn thứ hai:

C* = argmax_{Cᵢ∈C}{f(Cᵢ, D)}                          (2)

Mục tiêu của chúng tôi là huấn luyện mô hình xếp hạng f mà xác định bản tóm tắt đúng từ các đầu ra của mô hình tạo sinh g.

### 2.1 Kiến trúc Mô hình

Chúng tôi bắt đầu với một bi-encoder sử dụng RoBERTa-base (Liu et al., 2019) như một mạng nơ-ron xương sống. Được truyền cảm hứng bởi Khattab và Zaharia (2020), chúng tôi nhằm mục đích nắm bắt các đơn vị ngữ nghĩa phong phú ở cấp độ câu. Như được hiển thị trong Hình 2, chúng tôi chèn các token [CLS] vào trước K câu trong tài liệu D để cho phép chúng mã hóa thành các biểu diễn đa vector. Sau đó, chúng tôi tính toán điểm cá nhân Score_k được mô hình hóa như một tích trong:

Score_k = sim(E₁(Cᵢ), E_k(D))                         (3)

trong đó E₁(Cᵢ) và E_k(D) (k = 1, 2, ..., K) có nghĩa là các biểu diễn của các token [CLS] cho bản tóm tắt ứng viên Cᵢ và tài liệu D, tương ứng. Chúng tôi tính toán điểm tương đồng f(Cᵢ, D):

f(Cᵢ, D) = Σ_{k=1}^K (Score_k / Σ_{j=1}^K Score_j) × Score_k = Σ_{k=1}^K w_k × Score_k   (4)

Trong Phụ lục E, chúng tôi chỉ ra rằng mô hình của chúng tôi có thể nắm bắt thêm thông tin từ các tài liệu ở cấp độ câu.

### 2.2 Mục tiêu Huấn luyện

**Tổn thất Xếp hạng** Ý tưởng cốt lõi là chất lượng của bản tóm tắt ứng viên càng cao, càng gần với tài liệu. Chúng tôi giới thiệu một tổn thất xếp hạng cho f():

L_rank = Σᵢ Σ_{j>i} max(0, f(Cⱼ, D) - f(Cᵢ, D) + α(cost(Cᵢ, S) + cost(Cⱼ, S)))   (5)

trong đó S là bản tóm tắt tham chiếu và α là siêu tham số. Ở đây, cost(Cᵢ, S) = 1 - M(Cᵢ, S) là biên, và M là thang đo đánh giá tự động. Chúng tôi định nghĩa nó là ROUGE. Chúng tôi sử dụng cùng thang đo trong nghiên cứu trước đây (Liu và Liu, 2021; Liu et al., 2022), nhưng sự khác biệt là tổn thất của chúng tôi phản ánh trực tiếp thang đo chất lượng trong quá trình huấn luyện. Nói cách khác, chất lượng không được phản ánh đúng cách trước đây vì biên khác nhau ((j - i)) được gán ngay cả khi các bản tóm tắt ứng viên có cùng điểm ROUGE.

**Tổn thất Đối tỷ với Trọng số Instance** Việc xây dựng các cặp dương và âm là điểm quan trọng trong học đối tỷ. Do đó, chúng tôi xem xét các bản tóm tắt được tạo ra từ cùng một tài liệu như các mẫu dương và các bản tóm tắt không liên quan từ các tài liệu khác như các mẫu âm. Vì vậy, chúng tôi thiết kế một tập hợp các bản tóm tắt ứng viên C trong Eq. 1 như dương và một tập hợp các bản tóm tắt được lấy mẫu ngẫu nhiên N như âm. Để xác định các bản tóm tắt có ý nghĩa gần với tài liệu, chúng tôi giới thiệu một mục tiêu học đối tỷ với trọng số instance:

L_ctr = -(1/|C|) Σ_{Cᵢ∈C} λᵢ log(e^{f(Cᵢ,D)} / (e^{f(Cᵢ,D)} + Σ_{sᵢ∈N} e^{f(sᵢ,D)}))   (6)

Chúng tôi định nghĩa mới các bản tóm tắt có khớp từ vựng cao nhưng tương đồng ngữ nghĩa thấp như dương tính giả. Được truyền cảm hứng bởi Zhou et al. (2022), chúng tôi thiết kế một phương pháp trọng số instance để giảm ảnh hưởng của dương tính giả. Chúng tôi tạo ra các trọng số cho dương bằng cách sử dụng SimCSE (Gao et al., 2021) là mô hình tiên tiến nhất cho nhiệm vụ biểu diễn câu:

λᵢ = {0, nếu sim(Cᵢ, S) < τ; 1, nếu sim(Cᵢ, S) ≥ τ}     (7)

trong đó τ là siêu tham số của ngưỡng trọng số instance, và sim() là điểm tương đồng cosine được đánh giá bởi mô hình SimCSE.

Cuối cùng, như được hiển thị trong Hình 3, chúng tôi kết hợp các tổn thất xếp hạng (Eq. 5) và đối tỷ (Eq. 6):

L = β₁L_rank + β₂L_ctr                                  (8)

trong đó β là hệ số tỷ lệ của mỗi tổn thất và chúng tôi tìm các giá trị tối ưu (β₁ = 10; β₂ = 0.1) trong Phụ lục H.

## 3. Thí nghiệm

### 3.1 Bộ dữ liệu

Chúng tôi thí nghiệm trên hai bộ dữ liệu, thống kê của chúng được hiển thị trong Phụ lục C.

**CNN/DailyMail** (Hermann et al., 2015) là bộ dữ liệu tóm tắt được sử dụng phổ biến nhất chứa các bài báo từ báo CNN và DailyMail.

**XSum** (Narayan et al., 2018) là bộ dữ liệu tóm tắt một câu từ British Broadcasting Corporation (BBC) cho các năm 2010 - 2017.

### 3.2 Chi tiết Huấn luyện

Chúng tôi sử dụng tìm kiếm beam đa dạng (Vijayakumar et al., 2016) để tạo ra 16 bản tóm tắt ứng viên. Chúng tôi bắt đầu từ các checkpoint được tiền huấn luyện của RoBERTa-base (Liu et al., 2019). Chúng tôi huấn luyện BalSum trong năm epoch. Nó mất 33 giờ trên CNN/DM và 22 giờ trên XSum trên một GPU RTX 3090 duy nhất. Thêm chi tiết được mô tả trong Phụ lục D.

### 3.3 Kết quả Chính

Về mặt khung hai giai đoạn, chúng tôi so sánh kết quả của chúng tôi với SimCLS (Liu và Liu, 2021), SummaReranker (Ravaut et al., 2022), và BRIO (Liu et al., 2022). Chúng tôi áp dụng BalSum trên đầu mỗi mô hình cơ sở là BART hoặc PEGASUS.

Kết quả trên CNN/DM được mô tả trong Bảng 1. BalSum vượt trội hơn mô hình BART cơ sở, theo mức tăng 2.54/1.27/2.63 R-1/2/L. Đáng chú ý, trong khi nó có hiệu suất tương đương trên ROUGE với các mô hình trước đây, nó đạt được BERTScore 89.67, đạt hiệu suất tiên tiến nhất mới. Khi xếp hạng các bản tóm tắt ứng viên, mô hình của chúng tôi có thể ước tính ý nghĩa của các bản tóm tắt mà không làm giảm nghiêm trọng khía cạnh từ vựng. Chúng tôi lập luận rằng điều này là do BalSum giảm nhiều dương tính giả hơn các mô hình xếp hạng khác. Chúng tôi cung cấp các phân tích chi tiết cho kết quả này và trình bày một nghiên cứu trường hợp trong Mục 3.4.

Ngoài ra, chúng tôi áp dụng phương pháp của chúng tôi trên XSum, như được hiển thị trong Bảng 2. Mặc dù chúng tôi sử dụng một chiến lược khác để tạo ra dữ liệu validation và test, phương pháp của chúng tôi cải thiện PEGASUS cơ sở với một biên nhỏ. Chúng tôi tin rằng một trong những lý do là XSum bị hạn chế trong việc nắm bắt các đơn vị ngữ nghĩa đa dạng vì nó bao gồm các bản tóm tắt ngắn hơn nhiều (một câu) so với CNN/DM.

### 3.4 Phân tích

**Ngưỡng Trọng số** Một cách trực quan, ngưỡng trọng số càng lớn, dương tính giả càng thấp. Chúng tôi huấn luyện mô hình của chúng tôi với các ngưỡng trọng số instance khác nhau từ 0.7 đến 0.9. Trong Bảng 3, ngưỡng cao nhất (τ = 0.9) cho thấy hiệu suất tốt nhất và nó tăng lên đáng kể 0.3 BERTScore so với khi không được áp dụng. Chúng tôi cũng thấy rằng việc tăng ngưỡng dẫn đến cải thiện hiệu suất. Do đó, chúng tôi chứng minh rằng dương tính giả có thể được coi là nhiễu trong huấn luyện.

**Đánh giá Xếp hạng** Bất kể số lượng ứng viên, một mô hình xếp hạng lý tưởng nên mang lại kết quả oracle xem xét các khía cạnh đa dạng của tóm tắt. Chúng tôi tiến hành một thí nghiệm để đo lường chất lượng bằng cách chọn top-k bản tóm tắt sau khi sắp xếp các ứng viên thông qua các mô hình khác nhau. Như được hiển thị trong Bảng 4, chúng ta có thể thấy rằng mô hình của chúng tôi cho thấy hiệu suất nhất quán trong cả hai thang đo đánh giá tùy thuộc vào k (khoảng 0.06 BERTScore, 0.34 ROUGE điểm trung bình). So với SimCLS và BRIO-Ctr, khối thứ hai trong Bảng 4 chứng minh rằng BalSum nắm bắt tương đồng ngữ nghĩa tốt nhất trong khi duy trì mức trung gian từ góc độ chất lượng trùng lặp từ vựng. Hơn nữa, chúng tôi thấy rằng BalSum có tỷ lệ giảm thấp nhất của BERTScore (1.52%) từ điểm xếp hạng "oracle" hoàn hảo.

Chúng tôi cũng điều tra xem tất cả các bản tóm tắt được xếp hạng bởi các mô hình có thỏa mãn cả chất lượng từ vựng và ngữ nghĩa hay không. Chúng tôi đánh giá các mô hình bằng F1 đo lường các trường hợp mà bản tóm tắt được xếp hạng cao hơn có cả ROUGE và BERTScore lớn hơn bản tóm tắt được xếp hạng thấp hơn. Ngoài ra, chúng tôi tính toán tỷ lệ phần trăm của dương tính giả. Theo Bảng 5, trong khi BalSum có kết quả tệ hơn (+0.48% FP, -0.63 F1) so với BRIO-Ctr trên XSum, nó có hiệu suất xếp hạng tốt hơn (-0.23% FP, +0.34 F1) trên CNN/DM. Chúng tôi quan sát thấy rằng việc giảm dương tính giả dẫn đến cải thiện trong điểm F1, chứng minh rằng kết quả của Bảng 1 có thể được hiểu là giảm sai lầm ngữ nghĩa trong xếp hạng. Kết quả là, chúng tôi thấy rằng (1) mô hình của chúng tôi có thể học cách cho điểm mỗi bản tóm tắt bằng cách cân bằng chất lượng từ vựng và ngữ nghĩa, và (2) lý do khác của hiệu suất yếu trên XSum liên quan đến sự giảm nhỏ của dương tính giả so với CNN/DM.

**Nghiên cứu Trường hợp trên CNN/DM** Bảng 10 trình bày một mô hình thú vị mà chúng tôi quan sát thấy khi so sánh kết quả của BRIO-Ctr và BalSum, chứng minh rằng mô hình của chúng tôi giúp nắm bắt các chi tiết chính xác từ tài liệu. Trong khi BRIO-Ctr chứa một số thông tin không liên quan trong các bản tóm tắt (được hiển thị như văn bản được tô sáng màu xanh), BalSum chọn các bản tóm tắt mà câu cuối cùng nhất quán hơn với tham chiếu (được hiển thị như văn bản được tô sáng màu vàng). Hơn nữa, mặc dù điểm ROUGE tương đương của cả hai mô hình, chúng tôi lưu ý rằng các bản tóm tắt được chọn của BalSum luôn có BERTScore cao hơn so với của BRIO-Ctr.

## 4. Kết luận

Trong công trình này, chúng tôi đề xuất BalSum nhằm đánh giá các bản tóm tắt bằng cách xem xét sự cân bằng giữa chất lượng từ vựng và ngữ nghĩa. Để đạt được điều này, chúng tôi thực hiện học đa nhiệm vụ, sắp xếp các bản tóm tắt theo chất lượng trùng lặp từ vựng của chúng và xác định xem chúng có tương tự với tài liệu hay không. Ngoài ra, theo hiểu biết tốt nhất của chúng tôi, phương pháp của chúng tôi là nỗ lực đầu tiên trình bày một góc nhìn mới về dương tính giả (sai lầm ngữ nghĩa) trong xếp hạng và tạo ra mô hình để giảm ảnh hưởng của chúng. Kết quả thí nghiệm và phân tích chi tiết của chúng tôi xác nhận rằng mô hình của chúng tôi đạt được những cải thiện nhất quán so với các baseline cạnh tranh.

## Hạn chế

**Phụ thuộc Bản tóm tắt Ứng viên** Trong khi chúng tôi chủ yếu điều tra một mục tiêu huấn luyện để chọn bản tóm tắt tốt nhất trong số một tập hợp ứng viên, chúng tôi thấy rằng mô hình của chúng tôi phụ thuộc vào những ứng viên thu được từ mô hình tạo sinh. Gần đây, một số nghiên cứu đã được trình bày để cải thiện việc tạo ngôn ngữ. Ví dụ, Narayan et al. (2022) và Xu et al. (2022) cải thiện các phương pháp giải mã để tạo ra các đầu ra đa dạng. Sẽ có lợi khi áp dụng phương pháp của chúng tôi cho những phương pháp này.

**Tóm tắt Một câu** Phương pháp của chúng tôi có thể thất bại trong việc nắm bắt thông tin từ một bản tóm tắt cực kỳ ngắn. Vì Bảng 2 cho thấy rằng phương pháp của chúng tôi có cải thiện nhỏ hơn so với CNN/DM, chúng tôi dự định điều tra rằng mô hình của chúng tôi nhằm nắm bắt các đặc trưng chi tiết hơn từ một văn bản đầu vào.

## Lời cảm ơn

Chúng tôi cảm ơn Soohyeong Kim và các nhà phê bình ẩn danh cho phản hồi có giá trị và đề xuất hữu ích. Công việc này được hỗ trợ bởi Quỹ Nghiên cứu Quốc gia Hàn Quốc (NRF) tài trợ bởi chính phủ Hàn Quốc (*MSIT) (Số 2018R1A5A7059549, Số 2020R1A2C1014037) và được hỗ trợ bởi Viện Quy hoạch & Đánh giá Công nghệ Thông tin & Truyền thông (IITP) tài trợ bởi chính phủ Hàn Quốc (*MSIT) (Số 2020-0-01373). *Bộ Khoa học và ICT

# Tóm tắt Hội thoại Thực tế thông qua Học từ Mô hình Ngôn ngữ Lớn

## Tóm tắt
Tính nhất quán thực tế là một chất lượng quan trọng trong tóm tắt hội thoại. Các mô hình tóm tắt văn bản tự động dựa trên mô hình ngôn ngữ lớn (LLM) tạo ra các bản tóm tắt nhất quán thực tế hơn so với các mô hình ngôn ngữ được huấn luyện trước nhỏ hơn, nhưng chúng gặp phải thách thức triển khai trong các ứng dụng thực tế do hạn chế về quyền riêng tư hoặc tài nguyên. Trong bài báo này, chúng tôi nghiên cứu việc sử dụng chưng cất kiến thức ký hiệu để cải thiện tính nhất quán thực tế của các mô hình được huấn luyện trước nhỏ hơn cho tóm tắt hội thoại. Chúng tôi sử dụng học zero-shot để trích xuất kiến thức ký hiệu từ LLM, tạo ra cả bản tóm tắt nhất quán thực tế (tích cực) và không nhất quán (tiêu cực). Sau đó chúng tôi áp dụng hai mục tiêu học đối lập trên các bản tóm tắt này để nâng cao các mô hình tóm tắt nhỏ hơn. Các thí nghiệm với BART, PEGASUS và Flan-T5 cho thấy phương pháp của chúng tôi vượt qua các baseline mạnh dựa vào các chiến lược tăng cường dữ liệu phức tạp. Phương pháp của chúng tôi đạt được tính nhất quán thực tế tốt hơn trong khi duy trì tính mạch lạc, trôi chảy và liên quan, như được xác nhận bởi các chỉ số đánh giá tự động khác nhau. Chúng tôi cũng cung cấp quyền truy cập vào dữ liệu và mã để hỗ trợ nghiên cứu tương lai.

## 1 Giới thiệu
Tóm tắt văn bản tự động nhằm tạo ra một bản tóm tắt ngắn gọn của tài liệu nguồn giữ lại tất cả các điểm thiết yếu. Mặc dù các mô hình hiện tại có khả năng tạo ra các bản tóm tắt trôi chảy và mạch lạc, một vấn đề chính là sự không nhất quán thực tế, khi các bản tóm tắt được tạo ra chứa các sự kiện vắng mặt hoặc mâu thuẫn với nguồn (Maynez et al., 2020; Huang et al., 2021).

Để giải quyết vấn đề này, một số phương pháp đã được đề xuất, bao gồm mô hình hóa sự kiện rõ ràng (Zhu et al., 2021; Huang et al., 2020), chỉnh sửa sau (Lee et al., 2022; Balachandran et al., 2022; Chen et al., 2021a) và học đối lập (Wan and Bansal, 2022a; Cao and Wang, 2021; Liu et al., 2021). Các phương pháp dựa trên học đối lập, đặc biệt, cung cấp một giải pháp đơn giản mà không yêu cầu bất kỳ sửa đổi nào đối với kiến trúc mô hình, nhưng hiệu suất của chúng phụ thuộc vào việc xây dựng cẩn thận và thường dựa trên quy tắc của các mẫu tiêu cực (Cao and Wang, 2021; Liu et al., 2021; Wan and Bansal, 2022a).

Sự xuất hiện của các mô hình ngôn ngữ lớn (LLM) đã thay đổi bối cảnh NLP, và chúng thể hiện các khả năng mới nổi (Wei et al., 2022) như học trong ngữ cảnh (Brown et al., 2020; Min et al., 2022) và tuân theo hướng dẫn (Ouyang et al., 2022). Chúng ta đã thấy việc prompting zero- hoặc few-shot với LLM đạt được hiệu suất mạnh trên các nhiệm vụ NLP khác nhau (Wei et al., 2021; Ye et al., 2021) bao gồm cả tóm tắt (Zhang et al., 2023), cho thấy tính mạch lạc, liên quan và nhất quán thực tế tốt hơn so với các bản tóm tắt tham chiếu do con người viết.

Mặc dù ấn tượng, LLM không phải lúc nào cũng có thể triển khai trong các ứng dụng thực tế do yêu cầu tài nguyên tính toán đáng kể (Strubell et al., 2019) hoặc lo ngại về quyền riêng tư (vì nhiều LLM tiên tiến là mã nguồn đóng và chỉ có thể truy cập qua API). Do đó, việc xây dựng các mô hình hiệu quả về chi phí và nhỏ gọn hơn với khả năng tóm tắt tương tự là quan trọng. Để đạt được điều này, chưng cất kiến thức (Hinton et al., 2015) - một kỹ thuật có thể chuyển giao kiến thức từ mô hình giáo viên lớn sang mô hình học sinh nhỏ - đã được khám phá (Sun et al., 2020; Aguilar et al., 2020). Chưng cất kiến thức ký hiệu (West et al., 2022), một dạng đặc biệt của chưng cất kiến thức, trích xuất kiến thức ký hiệu (ví dụ: thông tin văn bản) từ mô hình giáo viên và sử dụng kiến thức đó như tín hiệu huấn luyện cho mô hình học sinh. Phương pháp này đặc biệt hữu ích khi làm việc với các mô hình giáo viên hộp đen mà chúng ta không có quyền truy cập vào phân phối xác suất đầu ra của chúng (đây là trường hợp đối với các LLM mã nguồn đóng như ChatGPT).

Trong bài báo này, chúng tôi khám phá chưng cất kiến thức ký hiệu để cải thiện tính nhất quán thực tế của các mô hình được huấn luyện trước (nhỏ hơn) trong tóm tắt hội thoại. Cụ thể, chúng tôi trích xuất kiến thức ký hiệu từ một giáo viên LLM (gpt-3.5 turbo) dưới dạng bản tóm tắt tích cực và bản tóm tắt tiêu cực. Bản tóm tắt tích cực là những bản nhất quán thực tế với bài viết nguồn (tức là một cuộc hội thoại) trong khi bản tóm tắt tiêu cực thì không. Chúng tôi thử nghiệm với các chiến lược khác nhau để kết hợp các bản tóm tắt này và huấn luyện mô hình học sinh, bao gồm chưng cất kiến thức cấp chuỗi (Kim and Rush, 2016) và hai phương pháp dựa trên học đối lập. Các thí nghiệm của chúng tôi bao gồm ba mô hình được huấn luyện trước được sử dụng rộng rãi: BART (Lewis et al., 2020), PEGASUS (Zhang et al., 2020), và Flan-T5 (Chung et al., 2024) trên hai bộ dữ liệu tóm tắt hội thoại phổ biến: SAMSum (Gliwa et al., 2019a) và DialogSum (Chen et al., 2021b).

Tóm lại, các đóng góp của chúng tôi như sau:
• Chúng tôi đề xuất cải thiện tính nhất quán thực tế của các mô hình tóm tắt hội thoại (nhỏ) thông qua chưng cất kiến thức ký hiệu từ LLM.
• Chúng tôi thử nghiệm với LLM để tạo ra không chỉ các bản tóm tắt nhất quán thực tế mà còn cả những bản không nhất quán, và chúng tôi kết hợp các bản tóm tắt đó để huấn luyện các mô hình tóm tắt hội thoại nhỏ với hai mục tiêu đối lập.
• Chúng tôi phát hiện ra rằng: (1) chưng cất kiến thức ký hiệu cho phép chúng ta tạo ra các mô hình tóm tắt hội thoại nhỏ hơn vượt qua các baseline mạnh; và (2) mô hình học sinh hoạt động tốt nhất đạt được tính nhất quán thực tế tương đương hoặc thậm chí tốt hơn so với các tham chiếu do con người viết mà không làm giảm các khía cạnh chất lượng khác như tính trôi chảy hoặc mạch lạc.

## 2 Nghiên cứu liên quan

### 2.1 Đánh giá và Nâng cao Tính nhất quán Thực tế

Chúng tôi tóm tắt hai lĩnh vực nghiên cứu về tính thực tế: đánh giá và nâng cao.

Các chỉ số đánh giá tự động thường được xây dựng dựa trên hệ thống hỏi-đáp (Fabbri et al., 2022; Scialom et al., 2021; Durmus et al., 2020; Manakul et al., 2023) hoặc các mô hình kéo theo văn bản (Kryscinski et al., 2020; Goyal and Durrett, 2020; Laban et al., 2022; Zhang et al., 2024). Các phương pháp gần đây hơn tận dụng khả năng của LLM để tuân theo các hướng dẫn zero-shot và few-shot (Fu et al., 2023; Min et al., 2023; Liu et al., 2023b). Một hướng nghiên cứu khác nhằm phát triển các chỉ số có thể phát hiện tính nhất quán thực tế giữa các cặp văn bản trong các nhiệm vụ khác nhau (Deng et al., 2021; Zha et al., 2023a), chẳng hạn như cuộc hội thoại dựa trên kiến thức.

Các phương pháp để nâng cao tính nhất quán thực tế của các mô hình tóm tắt chủ yếu thuộc các danh mục sau: mô hình hóa rõ ràng các sự kiện trong tài liệu nguồn (Zhu et al., 2021; Huang et al., 2020), chỉnh sửa sau các bản tóm tắt do mô hình tạo ra để có tính nhất quán thực tế tốt hơn (Lee et al., 2022; Balachandran et al., 2022; Chen et al., 2021a), huấn luyện mô hình tóm tắt với dữ liệu ít nhiễu hơn bằng cách lọc dữ liệu (Nan et al., 2021; Goyal and Durrett, 2021; Wan and Bansal, 2022a), và các phương pháp dựa trên tăng cường dữ liệu (Wang et al., 2022b; Adams et al., 2022). Danh mục cuối cùng thường được kết hợp với học đối lập (Wan and Bansal, 2022b; Liu et al., 2021; Cao and Wang, 2021), đã cho thấy hiệu quả cao. Tuy nhiên, học đối lập thường liên quan đến các chiến lược phức tạp để xây dựng các mẫu tiêu cực. Ví dụ, Cao and Wang (2021) sử dụng sự kết hợp của nhiều phương pháp bao gồm hoán đổi thực thể, che giấu và điền lại nội dung, và tạo ra mô hình với độ tin cậy thấp.

Nghiên cứu của chúng tôi thuộc danh mục tăng cường dữ liệu và học đối lập. Chúng tôi áp dụng LLM để xây dựng các mẫu tiêu cực với tính đa dạng cao hơn so với các chiến lược trước đây chủ yếu được điều khiển bởi các quy tắc và heuristic.

### 2.2 Chưng cất Kiến thức Ký hiệu

Chưng cất kiến thức ký hiệu (West et al., 2022) là một khung khái niệm ban đầu được đề xuất để xây dựng đồ thị kiến thức thường thức (Sap et al., 2019). Một lợi thế chính của khung này là nó không yêu cầu tối ưu hóa mô hình học sinh trên phân phối xác suất đầu ra của mô hình giáo viên, điều đã được thực hiện trong chưng cất kiến thức tiêu chuẩn (Hinton et al., 2015). Thay vào đó, nó trích xuất kiến thức ký hiệu (ví dụ: văn bản) từ mô hình giáo viên để xây dựng một mô hình học sinh nhỏ hơn.

Chưng cất kiến thức ký hiệu đã được sử dụng để xây dựng các mô hình tóm tắt tốt hơn theo những cách khác nhau, được thúc đẩy bởi các bản tóm tắt chất lượng cao được tạo ra bởi LLM zero-shot và few-shot (Zhang et al., 2023), thậm chí được ưa thích hơn so với các bản tóm tắt do con người viết. Ví dụ, Sclar et al. (2022) xây dựng các mô hình tóm tắt câu không tham chiếu với khả năng kiểm soát tốt hơn tỷ lệ nén, trong khi Song et al. (2023) nâng cao tính trừu tượng của bản tóm tắt thông qua chưng cất đã hiệu chỉnh. Liu et al. (2023c) sử dụng LLM không chỉ như một công cụ tăng cường dữ liệu để tạo ra "quasi-references", mà còn như một bộ đánh giá tóm tắt để cung cấp các tín hiệu huấn luyện bổ sung. Jiang et al. (2024) chưng cất khả năng tóm tắt của LLM bằng cách tạo ra nhiều lý do tam phân khía cạnh và bản tóm tắt, sau đó sử dụng học theo chương trình để huấn luyện các mô hình học sinh.

Phương pháp của chúng tôi khác với các nghiên cứu này bằng cách kết hợp một giai đoạn tận dụng cả bản tóm tắt tích cực và tiêu cực thông qua học đối lập để nâng cao tính nhất quán thực tế của các mô hình học sinh, trong khi các nghiên cứu trên chỉ xem xét các ví dụ tích cực.

## 3 Phương pháp luận

Cho một cuộc hội thoại D (hay "tài liệu nguồn" trong các nghiên cứu tóm tắt tài liệu), chúng tôi nhằm tạo ra một bản tóm tắt S sử dụng một mô hình tóm tắt g để nắm bắt các ý tưởng chính của D. Chúng tôi đặc biệt khuyến khích S nhất quán thực tế với D, tức là chỉ bao gồm thông tin được tìm thấy trực tiếp trong D và không có bất kỳ thông tin nào trái ngược với các sự kiện trong D.

Để xây dựng các mô hình tóm tắt hội thoại nhất quán thực tế và hiệu quả về chi phí hơn, trước tiên chúng tôi trích xuất kiến thức ký hiệu (tức là các bản tóm tắt được tăng cường) từ một mô hình giáo viên (ChatGPT), sau đó sử dụng chưng cất kiến thức cấp chuỗi và học đối lập để khai thác kiến thức. Tổng quan về khung của chúng tôi được hiển thị trong Hình 1.

### 3.1 Trích xuất Kiến thức Ký hiệu

Chúng tôi sử dụng ChatGPT (gpt-3.5-turbo) để tạo ra các bản tóm tắt tích cực được cho là nhất quán thực tế với cuộc hội thoại nguồn D, và các bản tóm tắt tiêu cực chứa lỗi thực tế so với D. Cụ thể, trước tiên chúng tôi prompt ChatGPT để tạo ra k (k = 3) bản tóm tắt tích cực cho một cuộc hội thoại, sau đó chúng tôi prompt nó một lần nữa để sửa đổi mỗi bản tóm tắt tích cực thành một bản tiêu cực bằng cách sửa đổi các đoạn của bản tóm tắt (vì vậy chúng tôi cũng có k bản tóm tắt tiêu cực). Một ví dụ được hiển thị trong Hình 2. Chúng tôi nhận thấy rằng chất lượng của các bản tóm tắt tiêu cực được cải thiện khi chúng tôi prompt ChatGPT một cách rõ ràng để giải thích các lỗi thực tế.

### 3.2 Sử dụng Kiến thức Ký hiệu

Phương pháp tiêu chuẩn để huấn luyện các mô hình tóm tắt là Ước lượng Khả năng Tối đa (MLE). Cụ thể, cho một bản tóm tắt tham chiếu duy nhất R*, mô hình tóm tắt g được khuyến khích cho token thứ i của R* xác suất tối đa trong tất cả các token trong từ vựng, dựa trên chuỗi tiền tố của token hiện tại. Hàm mất mát, entropy chéo, được định nghĩa như sau:

lmle = −log(R*|D) = −∑(i=1 to n) log Pg(R*i|D, R*<i)

Ở đây, R*i là token thứ i trong R*; R*<i đại diện cho các token đứng trước R*i; và Pg là phân phối xác suất của mô hình tóm tắt. Vì chỉ có một bản tóm tắt tham chiếu, hàm mất mát khuyến khích mô hình xấp xỉ phân phối khối lượng điểm được định nghĩa bởi tham chiếu duy nhất (Liu et al., 2023c). Vì hàm mất mát được định nghĩa ở cấp từ theo cách tự hồi quy, nó không rõ ràng thúc đẩy tính nhất quán thực tế của bản tóm tắt được tạo ra, điều này yêu cầu các tín hiệu ở cấp độ ngữ nghĩa và cấp chuỗi.

#### 3.2.1 Chưng cất Cấp Chuỗi

Cho rằng một mô hình giáo viên lớn có thể tạo ra các bản tóm tắt nhất quán thực tế hơn so với các mô hình học sinh nhỏ hơn, chúng tôi sử dụng Chưng cất Kiến thức Cấp Chuỗi (SEQDISTILL) (Kim and Rush, 2016). Phương pháp này liên quan đến việc tạo ra nhiều quasi-summaries từ mô hình giáo viên, sau đó được sử dụng như các mục tiêu để tinh chỉnh các mô hình học sinh sử dụng mất mát entropy chéo. Cho một tập hợp các bản tóm tắt tích cực P* được tạo ra bởi mô hình giáo viên, và bản tóm tắt tham chiếu do con người viết gốc R*, hàm mất mát như sau:

ls = −(1/|P* ∪ {R*}|) ∑(R ∈ P* ∪ {R*}) log Pg(R|D)

Sự khác biệt chính giữa SEQDISTILL và Ước lượng Khả năng Tối đa (MLE) nằm ở phương pháp xấp xỉ phân phối của chúng. SEQDISTILL nhằm xấp xỉ phân phối của mô hình giáo viên, ưa thích nhiều bản tóm tắt nhất quán thực tế thông qua một phương pháp dựa trên sampling. Ngược lại, MLE xấp xỉ một phân phối khối lượng điểm, trong đó một bản tóm tắt tham chiếu duy nhất được trao tất cả khối lượng xác suất.

#### 3.2.2 Học Đối lập

Chúng tôi tiếp tục kết hợp hai loại phương pháp học đối lập để tăng cường tính nhất quán thực tế của các mô hình tóm tắt bằng cách kết hợp các bản tóm tắt tiêu cực trên SEQDISTILL.

Gọi P là một tập hợp các bản tóm tắt tích cực nhất quán thực tế với cuộc hội thoại nguồn D, N là một tập hợp các bản tóm tắt tiêu cực chứa lỗi thực tế so với D, và R là mục tiêu cho mất mát entropy chéo. Một thể hiện huấn luyện với học đối lập là một tuple (D, R, P, N). Hàm mất mát cho một thể hiện huấn luyện duy nhất được định nghĩa là:

l = lmle + α · lc

trong đó lc là mất mát đối lập, α ∈ [0,1] là một siêu tham số để cân bằng hai thuật ngữ mất mát. Trực quan, lc phục vụ như một thuật ngữ chính quy hóa định hình phân phối của mô hình tóm tắt để ưa thích các bản tóm tắt nhất quán thực tế. Chúng tôi sử dụng hai mục tiêu đối lập, MARGIN CONTRAST và PAIRCONTRAST, phân biệt giữa các bản tóm tắt tích cực và tiêu cực ở cấp chuỗi và cấp biểu diễn tiềm ẩn, tương ứng.

MARGIN CONTRAST nhằm kéo xa các bản tóm tắt tích cực và tiêu cực bằng cách thực thi một khoảng cách giữa các điểm số cấp chuỗi. Cụ thể, chúng tôi nhằm đạt được điểm số cao hơn cho ngay cả các bản tóm tắt tích cực tệ nhất so với những bản tóm tắt tiêu cực tốt nhất, với mất mát sau:

lc = max{0, θ + max{S(N)} − min{S(P)}}

Ở đây, θ là ngưỡng điểm số mục tiêu, và S(·) là một hàm tính điểm. Được lấy cảm hứng từ BARTScore (Yuan et al., 2021), chúng tôi định nghĩa hàm tính điểm S(·) cho một bản tóm tắt X sử dụng mô hình tóm tắt g như log-likelihood được chuẩn hóa theo độ dài của tất cả các token:

S(X) = (1/m) ∑(i=1 to m) log Pg(xi|D, X<i)

Ở đây, m đại diện cho số lượng token trong X; xi là token thứ i; và X<i là các token đứng trước. Chuẩn hóa theo m loại bỏ tác động của độ dài đối với việc đánh giá tính nhất quán thực tế.

PAIRCONTRAST phân biệt các bản tóm tắt tích cực khỏi tiêu cực bằng cách giảm thiểu sự tương đồng giữa các biểu diễn tiềm ẩn của chúng, đồng thời tối đa hóa sự tương đồng giữa các cặp tích cực. Gọi ri, rj, và rk là các bản tóm tắt từ P hoặc N. Chúng tôi sử dụng hi, hj, và hk để biểu thị các biểu diễn dạng vector của các bản tóm tắt này. Mất mát đối lập lc được định nghĩa theo công thức được cung cấp bởi Cao and Wang (2021) như sau:

lc = −(1/|P|²) ∑(ri,rj ∈ P, ri≠rj) log(exp(s(hi,hj)/τ) / ∑(rk ∈ P∪N, rk≠ri) exp(s(hi,hk)/τ))

Ở đây, s là hàm cosine; và τ là một tham số nhiệt độ (τ = 1 trong các thí nghiệm của chúng tôi). Chúng tôi theo Cao and Wang (2021) để có được các biểu diễn vector của các bản tóm tắt bằng cách áp dụng một phép chiếu MLP cho các đầu ra lớp cuối được tính trung bình từ decoder cho tất cả các token.

Tóm lại, MARGIN CONTRAST sử dụng log-likelihood tóm tắt được ước tính bởi mô hình tóm tắt trực tiếp, trong khi PAIRCONTRAST dựa vào biểu diễn nội bộ của các từ tóm tắt.

## 4 Thiết lập Thí nghiệm

### 4.1 Bộ dữ liệu

Chúng tôi áp dụng hai bộ dữ liệu tóm tắt hội thoại phổ biến: SAMSum (Gliwa et al., 2019a) và DialogSum (Chen et al., 2021b). SAMSum là một bộ sưu tập các cuộc trò chuyện giống như tin nhắn, trong khi DialogSum chứa các cuộc trò chuyện hàng ngày trong bối cảnh thực tế hơn. Trong cả hai bộ dữ liệu, có một bản tóm tắt tham chiếu do con người viết cho mỗi cuộc trò chuyện trong phần huấn luyện. Bảng 1 hiển thị thống kê của hai bộ dữ liệu.

### 4.2 Mô hình Học sinh

Chúng tôi chọn BART (Lewis et al., 2020), PEGASUS (Zhang et al., 2020) và Flan-T5 (Chung et al., 2024) làm các mô hình học sinh, đã liên tục thể hiện hiệu suất tiên tiến trong tóm tắt văn bản tự động (Zhao et al., 2022; Liu and Liu, 2021; Chung et al., 2024). Cụ thể, chúng tôi sử dụng facebook/bart-large, google/pegasus-large, google/flan-t5-large làm các checkpoint ban đầu. Số lượng tham số có thể học được cho các mô hình này là 406 triệu, 568 triệu và 770 triệu, tương ứng, nhỏ hơn nhiều so với mô hình giáo viên.

### 4.3 Mô hình Baseline

FACTPEGASUS (Wan and Bansal, 2022a): một mô hình tóm tắt văn bản trừu tượng cho tóm tắt tin tức. Nó nâng cao tính nhất quán thực tế thông qua một số chiến lược: (1) huấn luyện trước hướng tính thực tế, (2) hiệu chỉnh bản tóm tắt tham chiếu giải quyết các lỗi thực tế tiềm ẩn trong bản tóm tắt tham chiếu, (3) học đối lập để tăng cường khả năng phân biệt giữa các bản tóm tắt tích cực và tiêu cực của mô hình, trong đó các bản tóm tắt tiêu cực được xây dựng bằng hoán đổi thực thể dựa trên quy tắc, (4) mô phỏng nhiệm vụ huấn luyện trước trong quá trình tinh chỉnh giảm thiểu khoảng cách giữa các giai đoạn huấn luyện trước và tinh chỉnh. Chúng tôi đã sử dụng mô hình được huấn luyện trước và mã của họ để tinh chỉnh trên các bộ dữ liệu của chúng tôi.

SWING (Huang et al., 2023): một mô hình tóm tắt hội thoại trừu tượng đạt được tính nhất quán thực tế và phạm vi tiên tiến trên SAMSum và DialogSum. Nó tận dụng một mất mát chưa được che phủ để tăng cường phạm vi thông tin, và một mất mát đối lập để nâng cao tính nhất quán thực tế. Chúng tôi sử dụng trực tiếp các thế hệ mô hình của họ.

Chúng tôi cũng bao gồm các bản tóm tắt tham chiếu do con người viết gốc (HUMAN REF) để đánh giá chất lượng tương đối so với phương pháp của chúng tôi.

### 4.4 Chỉ số Đánh giá

Chúng tôi đã chọn nhiều chỉ số đánh giá không tham chiếu, nhận ra rằng các phương pháp của chúng tôi có thể tạo ra các bản tóm tắt chất lượng cao khác biệt với các bản tóm tắt tham chiếu do con người viết. Sự khác biệt này có thể dẫn đến đánh giá thấp bởi các chỉ số dựa trên tham chiếu. Để đánh giá tính nhất quán thực tế, chúng tôi sử dụng hai chỉ số tự động tiên tiến (SOTA): một chỉ số dựa trên LLM, G-EVAL (Liu et al., 2023a), và một chỉ số không dựa trên LLM, ALIGNSCORE (Zha et al., 2023b). Phương pháp này giảm thiểu thiên vị tiềm ẩn của việc ưa thích các bản tóm tắt do LLM tạo ra vốn có trong các chỉ số dựa trên LLM (Liu et al., 2023a). Ngoài ra, chúng tôi sử dụng UNIEVAL (Zhong et al., 2022a) để đánh giá Tính mạch lạc, Tính trôi chảy, và Tính liên quan. Chúng tôi cũng sử dụng chỉ số dựa trên khớp n-gram tiêu chuẩn, ROUGE (Lin, 2004), chủ yếu như một kiểm tra tình trạng bình thường cho các mô hình được huấn luyện sử dụng MLE.

### 4.5 Chi tiết Thí nghiệm khác

Đối với MARGIN CONTRAST và PAIRCONTRAST, chúng tôi hợp nhất tham chiếu do con người viết R* và các bản tóm tắt tích cực P* được tạo ra bởi mô hình giáo viên làm tập hợp tích cực P' = {R*} ∪ P*. Đối với mỗi mẫu huấn luyện, chúng tôi chọn một phần tử R trong P' làm mục tiêu cho mất mát entropy chéo và sử dụng phần còn lại làm P cho mất mát đối lập. Tất cả các mô hình được tinh chỉnh trong 15.000 bước và được đánh giá sau mỗi 500 bước. Checkpoint tốt nhất được chọn theo AlignScore trên tập phát triển. Chúng tôi cung cấp thêm chi tiết triển khai trong Phụ lục A.4.

## 5 Kết quả và Thảo luận

### 5.1 Hiệu quả của Chưng cất Kiến thức Ký hiệu và Học Đối lập

Chúng tôi so sánh hiệu suất của các phương pháp của chúng tôi (SEQDISTILL, MARGIN CONTRAST và PAIRCONTRAST) và các mô hình baseline trên các khía cạnh chất lượng khác nhau, tập trung vào tính nhất quán thực tế. Từ kết quả trong Bảng 2, chúng tôi có những quan sát sau:

• Các phương pháp chưng cất của chúng tôi cải thiện tính nhất quán thực tế (so với các mô hình baseline và phương pháp MLE) mà không hy sinh các khía cạnh chất lượng khác (tức là Tính mạch lạc, Tính trôi chảy và Tính liên quan).

• Các phương pháp chưng cất của chúng tôi liên tục nâng cao tính nhất quán thực tế của tất cả các mô hình được huấn luyện trước (BART, PEGASUS và Flan-T5). PAIRCONTRAST nói chung là phương pháp hiệu quả nhất, mặc dù có một số biến đổi hiệu suất tùy thuộc vào bộ dữ liệu và mô hình được huấn luyện trước.

• SEQDISTILL và hai phương pháp học đối lập dẫn đến điểm số Rouge thấp hơn đáng kể so với MLE. Tuy nhiên, điều này chỉ cho chúng tôi biết rằng có ít sự chồng lấp từ hơn giữa các bản tóm tắt do mô hình tạo ra và các tham chiếu do con người viết thay vì một sự suy giảm chất lượng thực sự. Chúng tôi sẽ xem xét lại điều này với một nghiên cứu trường hợp trong phần 5.4.

• Flan-T5 trong hầu hết các trường hợp tạo ra các bản tóm tắt nhất quán thực tế hơn so với BART và PEGASUS qua các cài đặt khác nhau (MLE, SEQDISTILL, MARGIN CONTRAST, PAIRCONTRAST).

• Flan-T5 với PAIRCONTRAST là mô hình tóm tắt tốt nhất tổng thể, và nó đạt được tính nhất quán thực tế, mạch lạc và trôi chảy tương đương hoặc đôi khi tốt hơn so với HUMAN REF theo SA, SG và UNIEVAL.

### 5.2 Tác động của Tham chiếu do Con người viết

Quan sát thấy rằng mô hình học sinh hoạt động tốt nhất thể hiện kết quả đầy hứa hẹn, chúng tôi tiếp tục khám phá tác động của các tham chiếu do con người viết và tìm cách giải quyết câu hỏi: Có thể xây dựng các mô hình tóm tắt hội thoại mà không cần tham chiếu do con người viết không?

Bảng 3 hiển thị hiệu suất của flan-t5-large được huấn luyện sử dụng PAIRCONTRAST với số lượng khác nhau của các cuộc hội thoại được lấy mẫu ngẫu nhiên từ tập huấn luyện SAMSum. Điểm số chất lượng trên tập kiểm tra SAMSum qua tất cả các khía cạnh đều tương tự, cho dù các bản tóm tắt tham chiếu do con người viết gốc được sử dụng (R=Y) hay không (R=N), cho tất cả các kích thước bộ dữ liệu. Những phát hiện này gợi ý tính khả thi của việc phát triển các mô hình tóm tắt mạnh mẽ sử dụng các bộ dữ liệu không có nhãn.

### 5.3 Tác động của Số lượng Cặp Đối lập

Bảng 4 tiếp tục cho thấy hiệu suất của flan-t5-large được huấn luyện trên số lượng khác nhau của các cuộc hội thoại và cặp đối lập. Chúng tôi thấy rằng khi số lượng cuộc hội thoại (tức là #Dialog) được cố định, mô hình nói chung tạo ra các bản tóm tắt nhất quán hơn một chút khi k tăng lên. Mặt khác, không có sự khác biệt đáng kể khi chúng tôi thay đổi số lượng cặp đối lập miễn là tổng số thể hiện huấn luyện (tức là #Dialog × k) được cố định. Ví dụ, khi tổng số thể hiện huấn luyện là 9.000, (#Dialog=3000, k=3) cho kết quả tương tự như (#Dialog=9000, k=1).

### 5.4 Nghiên cứu Trường hợp

Hình 3 trình bày một ví dụ cuộc hội thoại cùng với các bản tóm tắt được tạo ra bởi các mô hình khác nhau, được sắp xếp theo AlignScore (Zha et al., 2023b) theo thứ tự tăng dần. Các bản tóm tắt từ FACTPEGASUS, MLE, và SWING bao gồm các lỗi thực tế không được hỗ trợ bởi cuộc hội thoại. Cụ thể, FACTPEGASUS khẳng định sai "but Hannah does" trong khi thực tế, Hannah không có số của Betty. MLE tuyên bố không chính xác rằng "Hannah and Amanda are looking for Betty's number", mặc dù chỉ có Hannah đang tìm kiếm. Trong bản tóm tắt của SWING, "him" xuất hiện trước từ tham chiếu "Larry". Đối với SEQDISTILL và tham chiếu do Con người viết, các đại từ "she" không rõ ràng vì có nhiều từ tham chiếu có thể trong ngữ cảnh trước đó. Không giống như những cái này, các bản tóm tắt từ PAIRCONTRAST và MARGIN CONTRAST không chứa các tham chiếu không rõ ràng. Đáng chú ý, các phương pháp của chúng tôi (SEQDISTILL, PAIRCONTRAST và MARGIN CONTRAST) có xu hướng tạo ra các bản tóm tắt dài hơn so với các tham chiếu do con người viết ngắn gọn hơn nhiều, do đó chúng tôi thấy điểm số ROUGE thấp hơn đáng kể cho chúng (Bảng 2).

## 6 Kết luận

Chúng tôi đã nghiên cứu việc chưng cất kiến thức ký hiệu của LLM (dưới dạng các bản tóm tắt được tạo ra) để nâng cao tính nhất quán thực tế của các mô hình nhỏ hơn cho tóm tắt hội thoại. Các thí nghiệm của chúng tôi với BART, PEGASUS, và Flan-T5 trên các bộ dữ liệu SAMSum và DialogSum tiết lộ rằng: (1) chưng cất kiến thức ký hiệu cho phép tạo ra các mô hình tóm tắt nhỏ gọn hơn vượt qua các baseline mạnh sử dụng các chiến lược tăng cường dữ liệu phức tạp; và (2) mô hình học sinh hoạt động tốt nhất của chúng tôi, Flan-T5 với PAIRCONTRAST, tạo ra các bản tóm tắt có khả năng tốt hơn - về mặt tính nhất quán thực tế, mạch lạc và trôi chảy - so với các tham chiếu do con người viết.

## 7 Hạn chế

Các thí nghiệm trong bài báo này được tiến hành trên các cuộc hội thoại hàng ngày ngắn. Các phát hiện có thể không tổng quát hóa cho các tình huống hội thoại khác như cuộc họp học thuật và phỏng vấn truyền hình.

Chúng tôi sử dụng các chỉ số đánh giá tự động để đánh giá chất lượng của các bản tóm tắt do mô hình tạo ra, điều này có thể không phản ánh đầy đủ sở thích của con người.

## 8 Tuyên bố Đạo đức

Nghiên cứu này được tiến hành dưới sự hướng dẫn của Bộ quy tắc Đạo đức ACL.

## Lời cảm ơn

Nghiên cứu này được hỗ trợ bởi Dịch vụ Tính toán Nghiên cứu của Đại học Melbourne và Sáng kiến Campus Petascale.

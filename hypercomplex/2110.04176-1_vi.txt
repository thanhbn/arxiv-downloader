# 2110.04176.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/hypercomplex/2110.04176.pdf
# Kích thước tệp: 2623854 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
1
PHNN: Mạng nơ-ron nhẹ thông qua
Tích chập siêu phức được tham số hóa
Eleonora Grassucci, Sinh viên tốt nghiệp, Thành viên IEEE, Aston Zhang, và
Danilo Comminiello, Thành viên cấp cao, IEEE
Tóm tắt —Mạng nơ-ron siêu phức đã chứng minh khả năng giảm
tổng số tham số trong khi vẫn đảm bảo hiệu suất có giá trị bằng cách
tận dụng các tính chất của đại số Clifford. Gần đây, các lớp tuyến tính
siêu phức đã được cải thiện thêm bằng cách sử dụng các tích Kronecker
được tham số hóa hiệu quả. Trong bài báo này, chúng tôi định nghĩa việc
tham số hóa các lớp tích chập siêu phức và giới thiệu họ các mạng nơ-ron
siêu phức được tham số hóa (PHNN) là các mô hình quy mô lớn nhẹ và
hiệu quả. Phương pháp của chúng tôi nắm bắt các quy tắc tích chập và
tổ chức bộ lọc trực tiếp từ dữ liệu mà không cần cấu trúc miền được
định nghĩa trước cứng nhắc để tuân theo. PHNN linh hoạt để hoạt động
trong bất kỳ miền nào do người dùng định nghĩa hoặc điều chỉnh, từ 1D
đến nD bất kể các quy tắc đại số có được đặt trước hay không. Tính linh
hoạt như vậy cho phép xử lý đầu vào đa chiều trong miền tự nhiên của
chúng mà không cần thêm các chiều khác, như được thực hiện thay vào
đó trong mạng nơ-ron quaternion cho đầu vào 3D như hình ảnh màu. Kết
quả là, họ PHNN được đề xuất hoạt động với 1=n tham số tự do so với
tương đương trong miền thực. Chúng tôi chứng minh tính đa dạng của
phương pháp này cho nhiều lĩnh vực ứng dụng bằng cách thực hiện thí
nghiệm trên các bộ dữ liệu hình ảnh khác nhau cũng như bộ dữ liệu âm
thanh trong đó phương pháp của chúng tôi vượt trội hơn các đối tác có
giá trị thực và quaternion. Mã nguồn đầy đủ có tại: https://github.com/eleGAN23/HyperNets.
Thuật ngữ chỉ mục —Mạng nơ-ron siêu phức, Phân tích Kronecker,
Mạng nơ-ron nhẹ, Quaternion, Mô hình hiệu quả

I. GIỚI THIỆU
CÁC mô hình tích chập tiên tiến gần đây đã đạt được kết quả
đáng kinh ngạc trong nhiều lĩnh vực ứng dụng bằng cách
mở rộng quy mô lớn tổng lượng tham số [1]–[4]. Đồng thời, các
ứng dụng đại số siêu phức đang thu hút sự chú ý ngày càng tăng
trong các lĩnh vực nghiên cứu đa dạng như xử lý tín hiệu [5]–[8]
hoặc học sâu [9]–[17]. Thật vậy, các mạng nơ-ron siêu phức và
quaternion (QNN) đã chứng minh khả năng giảm đáng kể số
lượng tham số trong khi vẫn đạt được hiệu suất tương đương
[18]–[24]. Các mô hình này khai thác các tính chất đại số siêu
phức, bao gồm tích Hamilton, để thiết kế cẩn thận các tương tác
giữa các đơn vị ảo, do đó liên quan đến 1=4 hoặc 1=8 tham số
tự do so với các mô hình có giá trị thực. Hơn nữa, nhờ các tương
tác được mô hình hóa, mạng siêu phức nắm bắt các mối quan hệ
ẩn nội tại trong đầu vào đa chiều và bảo tồn các tương quan có
sẵn giữa các chiều đầu vào [25]–[29]. Do đó, miền quaternion
đặc biệt phù hợp để xử lý dữ liệu 3D hoặc 4D, như hình ảnh
màu hoặc tín hiệu (tối đa) 4 kênh [30], trong khi miền octonion
phù hợp cho đầu vào 8D. Thật không may, hầu hết các bộ dữ
liệu hình ảnh màu phổ biến chứa hình ảnh RGB và một số thủ
thuật được yêu cầu để xử lý loại dữ liệu này với QNN. Trong
số đó, những cách được sử dụng nhiều nhất là đệm một kênh
không vào đầu vào để đóng gói hình ảnh vào bốn thành phần
quaternion, hoặc tái mô hình hóa lớp QNN với sự trợ giúp của
ánh xạ vector [31]. Ngoài ra, trong khi các phép toán nơ-ron
quaternion được phổ biến rộng rãi và dễ dàng tích hợp vào các
mô hình có sẵn, rất ít nỗ lực đã được thực hiện để mở rộng các
mô hình sang các bậc miền khác nhau. Tương ứng, việc phát
triển các mô hình tích chập siêu phức cho đầu vào đa chiều lớn
hơn, như độ lớn và pha của tín hiệu âm thanh đa kênh hoặc hình
ảnh vệ tinh 16 băng, vẫn còn đau đớn. Hơn nữa, mặc dù số
lượng tham số thấp hơn đáng kể, những mô hình này thường
hơi chậm so với đường cơ sở có giá trị thực [32] và có thể cần
các thuật toán đặc biệt để cải thiện hiệu quả [22], [33].

Gần đây, một nhánh văn học mới nhằm nén các mạng nơ-ron
tận dụng phân tích tích Kronecker [34], [35], đạt được kết quả
đáng kể về hiệu quả mô hình [36]. Gần đây, một tham số hóa
các phép nhân siêu phức đã được đề xuất để tổng quát hóa các
lớp được kết nối đầy đủ siêu phức bằng tổng các tích Kronecker
[37]. Phương pháp sau đạt được hiệu suất cao trong các nhiệm
vụ xử lý ngôn ngữ tự nhiên khác nhau bằng cách cũng giảm
tổng số tham số. Các công trình khác mở rộng phương pháp này
sang mạng nơ-ron đồ thị [38] và học chuyển giao [39], chứng
minh tính hiệu quả của phân tích tích Kronecker cho các phép
toán siêu phức. Tuy nhiên, chưa có giải pháp nào tồn tại cho
các lớp tích chập, vẫn là các lớp được sử dụng nhiều nhất khi
xử lý đầu vào đa chiều, như hình ảnh và tín hiệu âm thanh [40],
[41].

Trong bài báo này, chúng tôi thiết kế họ các mạng nơ-ron siêu
phức được tham số hóa (PHNN), là các mô hình nơ-ron siêu
phức quy mô lớn nhẹ cho phép bất kỳ đầu vào đa chiều nào,
dù số chiều là bao nhiêu. Tại trung tâm của tập hợp mô hình
mới này, chúng tôi đề xuất lớp tích chập siêu phức được tham
số hóa (PHC). Phương pháp của chúng tôi linh hoạt để hoạt
động trong các miền từ 1D đến nD, trong đó n có thể được
người dùng chọn tùy ý hoặc điều chỉnh để để hiệu suất mô hình
dẫn đến miền phù hợp nhất cho dữ liệu đầu vào đã cho. Tính
linh hoạt như vậy đến từ khả năng của phương pháp được đề
xuất để hấp thụ các quy tắc đại số để thực hiện tích chập bất
kể các quy định này có được đặt trước hay không. Do đó, các
mô hình nơ-ron được trang bị với phương pháp của chúng tôi
áp dụng 1=n tham số tự do so với arXiv:2110.04176v2 [cs.LG] 19 Sep 2022

--- TRANG 2 ---
2
các đối tác có giá trị thực của chúng, và lượng giảm tham số
là một lựa chọn của người dùng. Điều này làm cho PHNN thích
ứng với một loạt các ứng dụng trong đó việc tiết kiệm bộ nhớ
lưu trữ có thể là một khía cạnh quan trọng. Ngoài ra, tính linh
hoạt của PHNN cho phép xử lý dữ liệu đa chiều trong miền tự
nhiên của nó bằng cách đơn giản đặt siêu tham số chiều n. Ví
dụ, hình ảnh màu có thể được phân tích trong miền RGB của
chúng bằng cách đặt n= 3 mà không cần thêm thông tin vô
dụng, trái ngược với xử lý tiêu chuẩn cho mạng quaternion với
kênh không được đệm. Thật vậy, các lớp PHC có thể nắm bắt
đại số phù hợp từ dữ liệu đầu vào, trong khi nắm bắt các tương
quan nội tại giữa các kênh hình ảnh và tiết kiệm 66% tham số
tự do.

Trong một đánh giá thực nghiệm kỹ lưỡng trên nhiều điểm
chuẩn, chúng tôi chứng minh tính linh hoạt của phương pháp
có thể được áp dụng trong các miền ứng dụng khác nhau, từ
hình ảnh đến tín hiệu âm thanh. Chúng tôi thiết kế một tập
hợp PHNN cho các nhiệm vụ phân loại hình ảnh quy mô lớn
và phát hiện sự kiện âm thanh, để chúng hoạt động trong miền
siêu phức khác nhau và với độ chiều đầu vào khác nhau với n
từ 2 đến 16.

Đóng góp của bài báo này gồm ba phần.

Chúng tôi giới thiệu một lớp tích chập siêu phức được tham
số hóa (PHC) nắm bắt các quy tắc tích chập trực tiếp từ dữ
liệu thông qua lan truyền ngược khai thác các tính chất tích
Kronecker, do đó giảm số lượng tham số tự do xuống 1=n.

Chúng tôi thiết kế họ các mạng nơ-ron siêu phức được tham
số hóa (PHNN), các mô hình siêu phức quy mô lớn nhẹ và
hiệu quả hơn. Nhờ lớp PHC được đề xuất và phương pháp
trong [37] cho các lớp được kết nối đầy đủ, PHNN có thể
được sử dụng với bất kỳ loại đầu vào nào và các mô hình
nơ-ron có sẵn. Để thể hiện điều sau, chúng tôi định nghĩa
lại ResNet, VGG và mạng phát hiện sự kiện âm thanh
(SEDnet) phổ biến, hoạt động trong bất kỳ miền nào do
người dùng định nghĩa chỉ bằng cách chọn siêu tham số n,
cũng điều khiển số lượng bộ lọc tích chập.

Chúng tôi thể hiện cách phương pháp được đề xuất có thể
được sử dụng với bất kỳ loại dữ liệu đa chiều nào bằng cách
dễ dàng thay đổi siêu tham số n. Thật vậy, bằng cách đặt
n= 3, một PHNN có thể xử lý hình ảnh RGB trong miền tự
nhiên của chúng, trong khi tận dụng các tính chất của đại số
siêu phức, cho phép chia sẻ tham số bên trong các lớp và
dẫn đến giảm tham số xuống 1=3. Theo hiểu biết của chúng
tôi, đây là phương pháp đầu tiên xử lý hình ảnh màu với
các mô hình nơ-ron dựa trên siêu phức mà không cần thêm
bất kỳ kênh đệm nào. Tương tự, tín hiệu âm thanh đa kênh
có thể được phân tích bằng cách đơn giản xem xét n= 4
cho ambisonic bậc một tiêu chuẩn (có 4 capsule micro-
phone), n= 8 cho một mảng hai microphone ambisonic,
hoặc thậm chí n= 16 nếu chúng ta muốn bao gồm thông
tin pha của mỗi kênh.

Phần còn lại của bài báo được tổ chức như sau. Trong Phần
II, chúng tôi giới thiệu các khái niệm về đại số siêu phức và
tóm tắt lại các lớp tích chập có giá trị thực và quaternion.
Phần III giới thiệu nghiêm ngặt các khía cạnh lý thuyết của
phương pháp được đề xuất. Phần IV và V tiết lộ cách phương
pháp này có thể được áp dụng trong các mô hình nơ-ron khác
nhau và trong hai miền khác nhau, miền hình ảnh và âm thanh,
giải thích cách

Hình 1. Ví dụ về bảng nhân siêu phức cho n= 2 tức là, phức, trong số
những cái khác (đường xanh lá), n= 4 tức là, quaternion, tessarine,
(đường xanh) và n= 8, tức là, octonion, bi-quaternion, v.v. (đường đỏ).
Trong khi đối với các miền này, quy tắc đại số tồn tại và được định nghĩa
trước, không có quy định nào được đặt cho các miền khác như n= 3;5;6;7
(đường xám đứt nét). Các phương pháp siêu phức được tham số hóa có thể
học các quy tắc đại số còn thiếu này từ dữ liệu, do đó định nghĩa phép nhân
siêu phức và tích chập cho bất kỳ miền mong muốn nào.

xử lý hình ảnh RGB với n= 3 và âm thanh đa kênh với n lên
đến 8. Đánh giá thực nghiệm được trình bày trong Phần VI
cho phân loại hình ảnh và trong Phần VII cho phát hiện sự
kiện âm thanh. Cuối cùng, Phần VIII báo cáo các nghiên cứu
loại bỏ mà chúng tôi thực hiện và trong Phần IX chúng tôi
rút ra kết luận.

II. MẠNG NƠ-RON SIÊU PHỨC

A. Đại số siêu phức

Mạng nơ-ron siêu phức dựa trên hệ thống số siêu phức dựa
trên tập hợp các số siêu phức H và các quy tắc đại số tương
ứng để định hình phép cộng và phép nhân [24]. Các phép toán
này cần được mô hình hóa cẩn thận do các tương tác giữa các
đơn vị ảo có thể không hoạt động như các số có giá trị thực.
Ví dụ, Hình 1 báo cáo một ví dụ về bảng nhân cho các số
phức (xanh lá), quaternion (xanh) và octonion (đỏ). Tuy nhiên,
đây chỉ là một tập con nhỏ của miền siêu phức tồn tại. Thật
vậy, cho n= 4 tồn tại quaternion, tessarine, trong số những
cái khác, trong khi cho n= 8 octonion, dual-quaternion, v.v.
Mỗi miền này có các quy tắc nhân khác nhau do các tương tác
đơn vị ảo không giống nhau. Một số siêu phức tổng quát được
định nghĩa là

h=h0+hi^{i+:::+hn^{n; i = 1;:::;n                    (1)

với h0;:::;h n2R và ^{i;:::; ^{n các đơn vị ảo. Các tập con
khác nhau của miền siêu phức tồn tại, bao gồm phức, quaternion,
và octonion, trong số những cái khác. Chúng được xác định
bởi số lượng đơn vị ảo mà chúng sử dụng và bởi các tính chất
của phép nhân vector của chúng. Miền quaternion là một trong
những miền phổ biến nhất cho mạng nơ-ron nhờ các tính chất
tích Hamilton. Miền này có nền tảng trong số quaternion
q=q0+q1^{+q2^|+q3^, trong đó qc; c2 f0;1;2;3g là các hệ
số thực và ^{;^|;^ là các đơn vị ảo. Một quaternion với phần
thực q0 bằng 0 được gọi là quaternion thuần túy. Các đơn vị
ảo tuân thủ tính chất ^{2= ^|2= ^2=1 và với các tích không
giao hoán ^{^|=^|^{; ^|^=^^|; ^^{=^{^. Do tính không giao
hoán của phép nhân vector, tích Hamilton đã được giới thiệu
để mô hình hóa đúng phép nhân giữa hai quaternion.

--- TRANG 3 ---
3
.........
... ... ... ......
............
............
............
Hình 2. Quy tắc tích chập quaternion có thể được biểu diễn dưới dạng tổng
các tích Kronecker giữa các ma trận Ai bao gồm các quy tắc đại số và các
ma trận Fi chứa các bộ lọc tích chập, với i= 1;2;3;4. Trong ví dụ này, các
tham số của Ai được cố định cho mục đích trực quan hóa, nhưng trong các
lớp PHC chúng là các tham số có thể học được.

B. Lớp tích chập có giá trị thực và quaternion

Một lớp tích chập tổng quát có thể được mô tả bởi
y=Conv (x) =Wx+b;                                    (2)

trong đó đầu vào x2Rts được tích chập () với tensor bộ lọc
W2Rsdkk để tạo ra đầu ra y2Rdt, trong đó s là chiều
kênh đầu vào, d là chiều đầu ra, k là kích thước bộ lọc, và t
là chiều đầu vào và đầu ra. Hạng tử độ lệch b không ảnh hưởng
nhiều đến số lượng tham số, do đó bậc tự do cho phép toán
này về cơ bản là O(sdk2).

Các lớp tích chập quaternion, thay vào đó, xây dựng tensor
trọng số W2Rsdkk bằng cách tuân theo quy tắc tích Hamilton
và tổ chức các bộ lọc theo nó:

Wx=2
664W0W1W2W3
W1W0W3W2
W2W3W0W1
W3W2W1W03
7752
664x0
x1
x2
x33
775                          (3)

trong đó W0;W1;W2;W32Rs
4d
4kk là các hệ số thực của ma
trận trọng số quaternion W=W0+W1^{+W2^|+W3^ và
x0;x1;x2;x3 là các hệ số của đầu vào quaternion x với cấu
trúc tương tự.

Như đã làm cho các lớp có giá trị thực, độ lệch có thể bị bỏ
qua và tính toán bậc tự do của lớp tích chập quaternion có thể
được xấp xỉ thành O(sdk2=4). Số lượng tham số thấp hơn so
với phép toán có giá trị thực là do việc tái sử dụng bộ lọc được
thực hiện bởi tích Hamilton trong Phương trình 3. Ngoài ra,
việc chia sẻ các ma trận con tham số buộc phải xem xét và
khai thác mối tương quan giữa các thành phần đầu vào [21],
[42], [43].

III. THAM SỐ HÓA TÍCH CHẬP SIÊU PHỨC

Trong phần sau, chúng tôi phác thảo công thức cho lớp tích
chập siêu phức được tham số hóa (PHC) được đề xuất. Chúng
tôi cũng cho thấy rằng phương pháp này có khả năng học quy
tắc tích Hamilton khi hai quaternion được tích chập.

A. Lớp tích chập siêu phức được tham số hóa

Lớp PHC dựa trên việc xây dựng, bằng tổng các tích Kronecker,
tensor trọng số H bao gồm và tổ chức các bộ lọc của tích chập.
Phương pháp được đề xuất được định nghĩa chính thức là:

y=PHC(x) =Hx+b;                                      (4)

trong đó, H2Rsdkk được xây dựng bằng tổng các tích
Kronecker giữa hai nhóm ma trận có thể học được. Ở đây, s
là chiều đầu vào đến lớp, d là chiều đầu ra, và k là kích thước
bộ lọc. Cụ thể hơn,

H=nX
i=1Ai
Fi;                                          (5)

trong đó Ai2Rnn với i= 1;:::;n là các ma trận mô tả các
quy tắc đại số và Fi2Rs
nd
nkk đại diện cho lô bộ lọc thứ i
được sắp xếp theo các quy tắc đại số để tạo thành ma trận
trọng số cuối cùng. Cần lưu ý rằng s
nd
nkk đúng cho các
hạt nhân vuông, trong khi s
nd
nks nên được xem xét thay
vào đó cho các hạt nhân 1D. Yếu tố cốt lõi của phương pháp
này là tích Kronecker [44], là một tổng quát hóa của tích ngoài
vector có thể được tham số hóa bởi n. Siêu tham số n có thể
được đặt bởi người dùng muốn hoạt động trong một miền
thực hoặc siêu phức được định nghĩa trước (ví dụ, bằng cách
đặt n= 2 lớp PHC được định nghĩa trong miền phức, hoặc
trong miền quaternion nếu n được đặt bằng 4, như Hình 2
minh họa), hoặc điều chỉnh để có được hiệu suất tốt nhất từ
mô hình. Các ma trận Ai và Fi được học trong quá trình huấn
luyện và giá trị của chúng được tái sử dụng để xây dựng tensor
H xác định.

Bậc tự do của Ai và Fi lần lượt là n3 và sdk2=n. Thông
thường, các ứng dụng thực tế sử dụng số lượng lớn các bộ lọc
trong các lớp (s;d= 256;512;:::) và giá trị nhỏ cho k. Do đó,
thường sdk2n3 đúng. Vì vậy, bậc tự do cho ma trận trọng
số PHC có thể được xấp xỉ thành O(sdk2=n). Do đó, lớp PHC
giảm số lượng tham số xuống 1=n so với lớp tích chập tiêu
chuẩn trong các vấn đề thực tế.

Hơn nữa, khi xử lý dữ liệu đa chiều với các kênh tương quan,
như hình ảnh màu, thay vì âm thanh đa kênh hoặc tín hiệu đa
cảm biến, các lớp PHC mang lại lợi ích

--- TRANG 4 ---
4
1 2 3 4 5
Epochs0.00000.00050.00100.00150.00200.0025Loss
1 2 3 4 5
Epochs0.000.010.020.030.040.05

Hình 3. Đồ thị tổn thất cho các ví dụ đơn giản. Lớp PHC có thể học ma trận
A mô tả quy tắc tích chập cho quaternion thuần túy (trái) và quaternion đầy
đủ (phải).

do việc chia sẻ trọng số giữa các kênh khác nhau. Điều này
cho phép nắm bắt các mối quan hệ tiềm ẩn giữa các kênh mà
mạng tích chập tiêu chuẩn bỏ qua vì cấu trúc cứng nhắc của
trọng số [20], [45]. Lớp PHC có thể hấp thụ các quy tắc tích
chập siêu phức và miền mong muốn được chỉ định bởi siêu
tham số n. Thú vị là, bằng cách đặt n= 1 một lớp tích chập
có giá trị thực cũng có thể được biểu diễn. Thật vậy, các lớp
thực tiêu chuẩn không liên quan đến việc chia sẻ tham số, do
đó các quy tắc đại số chỉ được mô tả bởi A2R11 duy nhất và
tập hợp đầy đủ các bộ lọc được bao gồm trong Fsdkk.

Do đó, lớp PHC lấp đầy những khoảng trống còn lại bởi các
đại số siêu phức có sẵn trong Hình 1 và hấp thụ các quy tắc
đại số còn thiếu trực tiếp từ dữ liệu, tức là các đường xám
đứt nét trong Hình 1. Vì vậy, một mô hình nơ-ron được trang
bị với các lớp PHC có thể nắm bắt tổ chức bộ lọc cũng cho
n= 3;5;6;7 và vân vân. Hơn nữa, bất kỳ mô hình tích chập
nào có thể được trang bị với phương pháp của chúng tôi, vì
các lớp PHC dễ dàng thay thế các phép toán tích chập / tích
chập chuyển vị tiêu chuẩn và siêu tham số n cho tính linh hoạt
cao để thích ứng lớp với bất kỳ loại đầu vào nào, như hình
ảnh màu, âm thanh đa kênh hoặc tín hiệu đa cảm biến.

B. Kiểm tra học tập trên các ví dụ đơn giản

Chúng tôi kiểm tra khả năng tiếp thu của lớp PHC trong hai
bài toán đơn giản xây dựng một bộ dữ liệu nhân tạo. Chúng
tôi khuyến khích độc giả xem phần hướng dẫn của kho GitHub
https://github.com/eleGAN23/HyperNets để có thêm thông tin
chi tiết và kết quả về các ví dụ đơn giản, bao gồm các ma trận
Ai đã học được. Nhiệm vụ đầu tiên nhằm học ma trận A đúng
để xây dựng một lớp tích chập quaternion tuân theo đúng quy
tắc Hamilton trong Phương trình 3. Tức là, chúng tôi đặt n= 4
và mục tiêu là học bốn ma trận Ai như chúng trong tích
quaternion trong Hình 2. Chúng tôi xây dựng bộ dữ liệu bằng
cách thực hiện tích chập với ma trận bộ lọc W2H, được sắp
xếp theo quy định trong Phương trình 3, và một quaternion
x2H làm đầu vào. Mục tiêu vẫn là một quaternion, được đặt
tên là y2H. Như thể hiện trong Hình 3 (phải), tổn thất MSE
của lớp PHC hội tụ rất nhanh, có nghĩa là lớp học đúng ma
trận A và tích chập Hamilton.

Ví dụ đơn giản thứ hai là một sửa đổi của mục tiêu bộ dữ liệu
trước. Ở đây, chúng tôi muốn học ma trận A mô tả tích chập
giữa hai quaternion thuần túy. Do đó, khi đặt n= 4, ma trận
A1 của một quaternion thuần túy phải hoàn toàn rỗng. Các
quaternion thuần túy có thể là, ví dụ, một hình ảnh RGB đầu
vào và trọng số của một lớp tích chập siêu phức vì kênh đầu
tiên của hình ảnh RGB bằng không. Hình 3 (trái) hiển thị sự
hội tụ của tổn thất lớp PHC trong quá trình huấn luyện, chứng
minh rằng phương pháp được đề xuất có khả năng hấp thụ các
quy tắc tích chập siêu phức khi xử lý các quaternion thuần túy
cũng.

[A]
(11)
2
666666664F3
777777775
(sdkk)=2
666666664H3
777777775
(sdkk)
[A1]
(22)
2
4F13
5
(s
2d
2kk)+ [A2]
(22)
2
4F23
5
(s
2d
2kk)=2
666666664H3
777777775
(sdkk)
...
...
[A1]
(nn)

F1
(s
nd
nkk)+ [A2]
(nn)

F2
(s
nd
nkk)+:::+ [An]
(nn)

Fn
(s
nd
nkk)=2
666666664H3
777777775
(sdkk):(6)

--- TRANG 5 ---
5
C. Làm rõ lớp tích chập siêu phức được tham số hóa

Chúng tôi cung cấp một giải thích chính thức về lớp PHC để
hiểu rõ hơn về tích Kronecker và cách nó tổ chức các bộ lọc
tích chập để giảm tổng số tham số xuống 1=n. Trong Phương
trình 6, chúng tôi thể hiện cách lớp PHC tổng quát từ miền
1D đến nD. Khi hấp thụ các tích chập có giá trị thực trong
dòng đầu tiên của Phương trình 6, tích Kronecker được thực
hiện giữa một vô hướng A và ma trận bộ lọc F, có chiều giống
như ma trận trọng số cuối cùng H, là sdkk. Xem xét trường
hợp phức với n= 2 trong dòng thứ hai của Phương trình 6,
đại số được định nghĩa trong A1 và A2 trong khi các bộ lọc
được chứa trong F1 và F2, mỗi chiều 1=2 ma trận cuối cùng
H. Do đó, trong khi kích thước của ma trận trọng số H vẫn
không thay đổi, kích thước tham số xấp xỉ 1=2 cái thực. Trong
dòng cuối cùng của Phương trình 6, chúng ta có thể thấy sự
tổng quát hóa của quá trình này, trong đó kích thước của các
ma trận Fi, i= 1;:::;n được giảm tỷ lệ thuận với n. Cần lưu
ý rằng, trong khi kích thước tham số giảm với các giá trị n
tăng, chiều của H vẫn như vậy.

IV. MẠNG NƠ-RON SIÊU PHỨC ĐƯỢC THAM SỐ HÓA
CHO HÌNH ẢNH MÀU

Trong phần này, chúng tôi mô tả cách PHNN có thể được áp
dụng để xử lý hình ảnh màu trong các miền siêu phức mà
không cần bất kỳ thông tin bổ sung nào cho đầu vào và chúng
tôi đề xuất các ví dụ về các phiên bản siêu phức được tham
số hóa của các mô hình thị giác máy tính phổ biến như VGG
và ResNet. Để nhất quán với văn học, chúng tôi thực hiện
mỗi thí nghiệm với một mô hình cơ sở có giá trị thực, sau đó
chúng tôi so sánh nó với các đối tác phức và quaternion và
với PHNN được đề xuất. Hơn nữa, chúng tôi đánh giá tính
linh hoạt của phương pháp được đề xuất bằng cách thử nghiệm
các giá trị khác nhau của siêu tham số n, do đó định nghĩa
các mô hình siêu phức được tham số hóa trong nhiều miền.

A. Xử lý hình ảnh màu với lớp PHC

Các mã hóa khác nhau tồn tại để xử lý hình ảnh màu, tuy
nhiên, các bộ dữ liệu thị giác máy tính phổ biến nhất bao gồm
hình ảnh ba kênh trong R3. Trong miền quaternion, hình ảnh
RGB được bao gồm trong một quaternion và xử lý như các
yếu tố đơn [42]. Việc đóng gói được thực hiện bằng cách xem
xét các kênh RGB như các hệ số thực của các đơn vị ảo và
bằng cách đệm một kênh không như thành phần thực đầu tiên
của quaternion.

Ở đây, chúng tôi đề xuất tận dụng tính linh hoạt cao của các
lớp PHC để xử lý hình ảnh RGB trong các miền siêu phức
mà không nhúng thông tin vô dụng vào đầu vào. Thật vậy,
PHC có thể trực tiếp hoạt động trong R3 bằng cách dễ dàng
đặt n= 3 và xử lý hình ảnh RGB trong miền tự nhiên của
chúng trong khi khai thác các tính chất mạng siêu phức như
chia sẻ tham số. Thật vậy, tính linh hoạt tuyệt vời của các lớp
PHC cho phép người dùng chọn xử lý hình ảnh trong R4 hay
R3. Một mặt, bằng cách đặt n= 4, kênh không được thêm vào
đầu vào ngay cả khi lớp tiết kiệm 75% tham số tự do. Mặt
khác, bằng cách chọn n= 3 mạng không xử lý bất kỳ thông
tin vô dụng nào, mặc dù vậy, nó giảm số lượng tham số chỉ
66%. Đây là một sự đánh đổi có thể phụ thuộc vào ứng dụng
hoặc phần cứng mà người dùng cần. Hơn nữa, miền xử lý
hình ảnh có thể được điều chỉnh bằng cách để hiệu suất của
mạng chỉ ra lựa chọn tốt nhất cho n.

B. VGG siêu phức được tham số hóa

Một họ phương pháp phổ biến để xử lý hình ảnh dựa trên mạng
VGG [46] xếp chồng nhiều lớp tích chập và một bộ phân loại
được kết nối đầy đủ đóng. Để hoàn toàn định nghĩa các mô
hình trong miền siêu phức mong muốn, chúng tôi đề xuất trang
bị mạng với các lớp PHC như thành phần tích chập và với các
lớp Nhân siêu phức được tham số hóa (PHM) [37] như bộ
phân loại tuyến tính. Xương sống của PHVGG của chúng tôi
sau đó là

ht=ReLU (PHC t(ht1))t= 1;:::;j
y=ReLU (PHM (hj)):(7)

C. ResNet siêu phức được tham số hóa

Trong văn học gần đây, một tập hợp copious hiệu suất cao
trong phân loại hình ảnh đạt được với các mô hình có cấu trúc
dư. ResNet [47] chồng lên nhiều khối dư được tạo thành từ
các lớp tích chập và ánh xạ nhận dạng. Một khối dư PHResNet
tổng quát được định nghĩa bởi

y=F(x;fHjg) +x;                                      (8)

trong đó Hj là trọng số PHC của lớp j= 1;2 trong khối, và F là

F(x;fHjg) =PHC (ReLU (PHC(x)));                      (9)

trong đó chúng tôi bỏ qua chuẩn hóa lô để đơn giản hóa ký
hiệu. Pha ngược của PHNN giảm xuống lan truyền ngược tương
tự như của mạng nơ-ron quaternion, đã được phát triển trong
[19], [42], [48].

V. MẠNG NƠ-RON SIÊU PHỨC ĐƯỢC THAM SỐ HÓA
CHO TÍN HIỆU ĐA KÊNH

Trong phần sau, chúng tôi giải thích cách PHNN có thể được
sử dụng để xử lý tín hiệu âm thanh đa kênh và chúng tôi giới
thiệu, như một ví dụ, mạng phát hiện sự kiện âm thanh siêu
phức được tham số hóa (PHSEDnet).

A. Xử lý âm thanh đa kênh với lớp PHC

Tín hiệu Ambisonics bậc một (FOA) bao gồm 4 capsule microphone,
có biểu diễn độ lớn có thể được bao gồm trong một quaternion
[49], [50]. Tuy nhiên, đại số quaternion có thể hạn chế nếu
nhiều hơn một microphone được sử dụng để đăng ký hoặc
liệu thông tin pha phải được bao gồm. Thật vậy, mạng nơ-ron
quaternion khớp kém với đầu vào đa chiều có nhiều hơn 4
kênh [51].

Ngược lại, phương pháp được đề xuất có thể dễ dàng thích
ứng để xử lý những chiều bổ sung này bằng cách tiện lợi đặt
siêu tham số n và do đó hoàn toàn tận dụng từng thông tin
trong đầu vào n-chiều.

--- TRANG 6 ---
6
10 20 30 40 50
Parameters (M)84858687888990AccuracyModel
Real
Complex
Quaternion
PH n=2
PH n=3
PH n=4
Family
ResNet
VGG
StdAcc
0.15
0.30
0.45
0.60
0.75
Hình 4. Độ chính xác CIFAR10 so với số lượng tham số mạng cho các mô
hình VGG và ResNet. Điểm càng lớn, độ lệch chuẩn qua các lần chạy càng
cao. Các mô hình dựa trên PHC đạt được độ chính xác tốt hơn trong cả hai
họ trong khi giảm đáng kể số lượng tham số. Chúng tôi không hiển thị VGG
phức vì độ chính xác của chúng rất thấp so với các mô hình khác.

B. PHSEDnet siêu phức được tham số hóa

Mạng phát hiện sự kiện âm thanh (SEDnet) [52] bao gồm một
thành phần tích chập cốt lõi trích xuất đặc trưng từ quang phổ
đầu vào. Thông tin sau đó được chuyển đến một mô-đun đơn
vị tái phát có cổng (GRU) và đến một ngăn xếp các lớp được
kết nối đầy đủ (FC) với một sigmoid đóng xuất ra xác suất
âm thanh có trong khung âm thanh. Chính thức, PHSEDnet
được mô tả bởi

ht=PHC t(ht1)t= 1;:::;j
y=(FC(GRU (hj))):(10)

Sau mô hình GRU, chúng tôi sử dụng các lớp được kết nối
đầy đủ tiêu chuẩn, cũng có thể được triển khai như các lớp
PHM với n= 1, vì tín hiệu được xử lý như vậy mất cấu trúc
đa chiều gốc.

VI. ĐÁNH GIÁ THỰC NGHIỆM TRÊN PHÂN LOẠI HÌNH ẢNH

Để bắt đầu, chúng tôi kiểm tra lớp PHC trên hình ảnh RGB
và chúng tôi thể hiện cách, khai thác các tương quan giữa
các kênh, phương pháp được đề xuất tiết kiệm tham số trong
khi đảm bảo hiệu suất cao. Chúng tôi thực hiện mỗi thí nghiệm
với một mô hình cơ sở có giá trị thực và sau đó chúng tôi so
sánh nó với các đối tác phức và quaternion và với PHNN
được đề xuất. Hơn nữa, chúng tôi đánh giá tính linh hoạt của
phương pháp được đề xuất bằng cách thử nghiệm các giá trị
khác nhau của siêu tham số n, do đó định nghĩa các mô hình
siêu phức được tham số hóa trong nhiều miền.

A. Thiết lập thí nghiệm

Chúng tôi thực hiện nhiệm vụ phân loại hình ảnh với năm
mô hình cơ sở. Chúng tôi xem xét ResNet18, ResNet50 và
ResNet152 từ họ ResNet và VGG16 và VGG19 từ họ VGG.
Mỗi siêu tham số được đặt theo các bài báo gốc [46], [47].
Chúng tôi điều tra hiệu suất trong bốn

Real Complex Quaternion PH n=2 PH n=3 PH n=4
Model0.010%20%30%40%Percentage of SuccessesFigure 5. Biểu đồ cột số lần thành công đạt được bởi các mô hình trong
Bảng II trong mỗi lần chạy. Các mô hình dựa trên PHC với n= 3 (thanh
đỏ) vượt xa các cấu hình khác là lựa chọn hiệu suất hơn cho nhiệm vụ phân
loại hình ảnh RGB.

bộ dữ liệu hình ảnh màu khác nhau ở các quy mô khác nhau.
Chúng tôi sử dụng SVHN, CIFAR10, CIFAR100, và ImageNet
và bất kỳ loại tăng cường dữ liệu nào được áp dụng cho các
bộ dữ liệu này để đảm bảo so sánh công bằng.

Chúng tôi sửa đổi số lượng bộ lọc cho ResNet để có thể chia
hết cho 3 và do đó có khả năng thử nghiệm cấu hình với n= 3.
Các phiên bản sửa đổi của ResNet được xây dựng với một lớp
tích chập ban đầu gồm 60 bộ lọc. Sau đó, các khối tiếp theo
có 60;120;240;516 bộ lọc. Số lượng lớp trong các khối phụ
thuộc vào ResNet được chọn, dù là 18, 50 hay 152. Thay vào
đó, thành phần tích chập VGG19 bao gồm hai lớp 24, hai lớp
72, bốn lớp 216, và tám lớp 648 bộ lọc, với chuẩn hóa lô.
Bộ phân loại bao gồm ba lớp được kết nối đầy đủ gồm 648,
516 và 10, 100 hoặc 1000 tùy thuộc vào số lượng lớp trong
bộ dữ liệu. Phần còn lại của các siêu tham số được đặt như
đề xuất trong các bài báo gốc. Kích thước lô được cố định
là 128 và huấn luyện được thực hiện thông qua bộ tối ưu hóa
SGD với động lượng bằng 0:9, suy giảm trọng số 5e4 và
một lịch trình ủ cosine. Đối với ResNet, tốc độ học ban đầu
được đặt là 0:1. Đối với VGG bằng 0:01. Các mô hình trên
CIFAR10 và CIFAR100 được huấn luyện trong 200 epoch
trong khi trên SVHN mạng chạy 50 epoch. Đối với bộ dữ liệu
ImageNet, chúng tôi tuân theo các công thức trong [53], vì
vậy chúng tôi thay đổi kích thước hình ảnh để huấn luyện
ở 160160 trong khi giữ kích thước tiêu chuẩn 224224 cho
xác thực và kiểm tra. Chúng tôi sử dụng suy giảm tốc độ học
theo bước mỗi 30 epoch với  = 0:1, bộ tối ưu hóa SGD và
tốc độ học ban đầu 0:1 với suy giảm trọng số 0:0001. Việc
huấn luyện được thực hiện trong 300k lần lặp với kích thước
lô 256 sử dụng bốn GPU Tesla V100.

B. Kết quả thí nghiệm

Chúng tôi thực hiện thí nghiệm ban đầu với VGG so với VGG
Quaternion và hai phiên bản PHVGG với n bằng 2 và 4. Độ
chính xác trung bình và độ lệch chuẩn qua ba lần chạy được
báo cáo cho bộ dữ liệu SVHN và CIFAR10 trong Bảng I.
Chúng tôi cũng thử nghiệm các lần chạy bổ sung nhưng bất
kỳ sự khác biệt nào đáng kể

--- TRANG 7 ---
7
BẢNG I
KẾT QUẢ PHÂN LOẠI HÌNH ẢNH CHO VGG. TRUNG BÌNH ĐỘ CHÍNH XÁC VÀ ĐỘ LỆCH CHUẨN QUA BA LẦN CHẠY VỚI CÁC SEED KHÁC NHAU
ĐƯỢC BÁO CÁO. THỜI GIAN HUẤN LUYỆN (T) VÀ THỜI GIAN SUY LUẬN (I) CẦN THIẾT TRÊN CIFAR10. CHO THỜI GIAN HUẤN LUYỆN CHÚNG TÔI
BÁO CÁO, BẰNG GIÂY TRÊN 100 LẦN LẶP, TRUNG BÌNH VÀ ĐỘ LỆCH CHUẨN QUA CÁC LẦN LẶP TRONG MỘT EPOCH, TRONG KHI THỜI GIAN SUY
LUẬN LÀ THỜI GIAN CẦN THIẾT ĐỂ GIẢI MÃ BỘ KIỂM TRA. PHNN VỚI n= 4 VƯỢT TRỘI HƠN ĐỐI TÁC QUATERNION CẢ VỀ ĐỘ CHÍNH XÁC VÀ
THỜI GIAN. PHVGG VỚI n= 2 VƯỢT XA ĐƯỜNG CƠ SỞ CÓ GIÁ TRỊ THỰC TRONG CÁC BỘ DỮ LIỆU ĐƯỢC XEM XÉT, TRONG KHI CẢ HAI PHIÊN BẢN
PHVGG19 VỚI n= 2;4 HIỆU QUẢ HƠN CÁC ĐƯỜNG CƠ SỞ CÓ GIÁ TRỊ THỰC VÀ QUATERNION Ở THỜI GIAN SUY LUẬN. GIÁ TRỊ p DƯỚI T-TEST 0:0002.

Model Params SVHN CIFAR10 Time (T) Time (I)
VGG16 15M 94.364 0.394 85.0670.765 2.20.02 1.2
Complex VGG16 7.6M (-50%) 93.555 0.392 76.9270.511 5.20.02 1.5
Quaternion VGG16 3.8M (-75%) 93.887 0.292 83.9970.493 5.20.02 2.2
PHVGG16 n= 2 7.6M (-50%) 94.8310.257 86.5100.216 3.20.02 1.4
PHVGG16 n= 4 3.8M (-75%) 94.639 0.121 85.6400.205 3.20.02 1.4
VGG19 29.8M 94.140 0.129 85.6240.257 3.20.02 16.0
Complex VGG19 14.8M (-50%) 90.469 0.222 76.9790.345 5.20.02 16.2
Quaternion VGG19 7.5M (-75%) 93.983 0.190 83.9140.129 6.20.02 16.3
PHVGG19 n= 2 14.9M (-50%) 94.5530.229 85.7500.286 4.00.02 15.4
PHVGG19 n= 4 7.4M (-75%) 94.169 0.296 84.8300.733 4.20.02 15.5

BẢNG II
KẾT QUẢ PHÂN LOẠI HÌNH ẢNH VỚI CÁC MÔ HÌNH RESNET. MỖI THÍ NGHIỆM ĐƯỢC CHẠY BA LẦN VỚI CÁC SEED KHÁC NHAU VÀ TRUNG BÌNH
VỚI ĐỘ LỆCH CHUẨN ĐƯỢC BÁO CÁO. CÁC MÔ HÌNH ĐỀ XUẤT VƯỢT XA CÁC ĐƯỜNG CƠ SỞ CÓ GIÁ TRỊ THỰC VÀ QUATERNION GẦN NHƯ TRONG
MỖI THÍ NGHIỆM CHÚNG TÔI THỰC HIỆN. THÚ VỊ LÀ, PHNN VƯỢT TRỘI HƠN ĐỐI TÁC CÓ GIÁ TRỊ THỰC 4% ĐIỂM TRONG THÍ NGHIỆM QUY MÔ
LỚN NHẤT TRÊN CIFAR100. THỜI GIAN TƯƠNG TỰ NHƯ CÁC KHẲNG ĐỊNH TRONG BẢNG I NÊN CHÚNG TÔI KHÔNG THÊM VÀO ĐÂY ĐỂ TRÁNH DƯ THỪA.

Model Params Storage Memory SVHN CIFAR10 CIFAR100
ResNet18 10.1M 39MB 93.992 1.317 89.5430.340 62.6340.600
Complex ResNet18 5.2M (-50%) 20MB (-50%) 89.902 0.322 89.5410.412 60.4170.811
Quaternion ResNet18 2.8M (-75%) 10MB (-75%) 93.661 0.413 88.2400.377 59.8500.607
PHResNet18 n= 2 5.4M (-50%) 20MB (-50%) 94.3590.187 89.2600.625 60.3202.249
PHResNet18 n= 3 3.6M (-66%) 13MB (-66%) 94.303 1.234 89.6030.563 62.6601.067
PHResNet18 n= 4 2.7M (-75%) 10MB (-75%) 94.234 0.161 88.8470.874 61.7800.689
ResNet50 22.5M 86MB 94.546 0.269 89.6300.305 65.5140.569
Complex ResNet50 11.1M (-50%) 43MB (-50%) 89.004 0.215 89.6990.485 65.1040.598
Quaternion ResNet50 5.7M (-75%) 22MB (-75%) 93.685 0.389 89.6700.383 63.7600.717
PHResNet50 n= 2 11.1M (-50%) 43MB (-50%) 93.849 0.249 89.7500.386 65.8840.333
PHResNet50 n= 3 7.6M (-66%) 29MB (-65%) 93.617 0.497 90.4230.145 66.4971.256
PHResNet50 n= 4 5.7M (-75%) 23MB (-74%) 94.5580.754 88.8970.645 66.2401.165
ResNet152 52.6M 201MB 94.6250.355 89.5800.173 62.0530.385
Complex ResNet152 26.3M (-50%) 101MB (-50%) 90.332 0.129 89.7920.427 63.1250.681
Quaternion ResNet152 13.2M (-75%) 51MB (-75%) 93.638 0.098 89.2270.287 61.2670.784
PHResNet152 n= 2 26.6M (-50%) 103MB (-49%) 93.915 0.512 90.5400.401 65.8170.327
PHResNet152 n= 3 17.8M (-66%) 70MB (-65%) 93.955 0.152 90.0770.436 66.3470.567
PHResNet152 n= 4 13.4M (-75%) 53 MB (-74%) 94.290 0.237 89.8970.097 66.4370.064

xuất hiện vì tính ngẫu nhiên chỉ ảnh hưởng đến việc khởi tạo
mạng. Cả hai phiên bản PHVGG16 và PHVGG19 đều rõ ràng
vượt trội hơn các đối tác real, complex và quaternion trong
khi được xây dựng với hơn một nửa số lượng tham số của
đường cơ sở. Ngoài ra, các mô hình dựa trên PH giảm đáng
kể số lượng thời gian huấn luyện và suy luận cần thiết (tính
toán trên NVIDIA Tesla-V100) so với mô hình quaternion cũng
hoạt động trong miền siêu phức. Hơn nữa, khi mở rộng quy
mô thí nghiệm với VGG19, các phương pháp được đề xuất
hiệu quả hơn ở thời gian suy luận so với VGG19 có giá trị
thực. Do đó, PHNN có thể dễ dàng được áp dụng trong các
ứng dụng có hạn chế về bộ nhớ đĩa, do việc giảm tham số,
và cho các vấn đề suy luận nhanh nhờ hiệu quả ở thời gian
kiểm tra. Mặc dù tổng các tích Kronecker trong các lớp PHC
yêu cầu tính toán bổ sung, sự gia tăng là không đáng kể so
với FLOP tính toán cho toàn bộ mạng, vì vậy tổng số FLOP
không bị ảnh hưởng nặng nề bởi phương pháp của chúng tôi
và số lượng vẫn gần như giống nhau.

Phương pháp của chúng tôi có tính linh hoạt cao, thật vậy,
khi xử lý hình ảnh màu, chúng ta có thể chọn miền hoạt động
nhờ siêu tham số n. Do đó, chúng tôi thử nghiệm PHNN trong
miền phức (n= 2), quaternion (n= 4) hoặc H3 (n= 3), trong
đó ở miền sau chúng tôi không nối thêm bất kỳ zero padding
nào và xử lý các kênh RGB của hình ảnh trong miền tự nhiên
của chúng.

Bảng II trình bày độ chính xác trung bình và độ lệch chuẩn
qua ba lần chạy với các seed khác nhau cho các mô hình dựa
trên ResNet. Chúng tôi thực hiện thí nghiệm mở rộng và các
mô hình PH với n= 4 luôn vượt trội hơn đối tác quaternion
đạt được độ chính xác cao hơn và mạnh mẽ hơn. Điều này
nhấn mạnh hiệu quả của tính linh hoạt kiến trúc PHC so với
cấu trúc được định nghĩa trước và cứng nhắc của các lớp
quaternion. Hơn nữa, phương pháp của chúng tôi rõ ràng
vượt xa các đường cơ sở có giá trị thực tương ứng qua các
thí nghiệm trong khi tiết kiệm từ 50% đến 75% tham số. Tập
trung vào kết quả sau, các

--- TRANG 8 ---
8
BẢNG III
PHÂN LOẠI IMAGENET VỚI ĐƯỜNG CƠ SỞ CÓ GIÁ TRỊ THỰC SO VỚI
MÔ HÌNH TỐT NHẤT CỦA CHÚNG TÔI PHn= 3. PHƯƠNG PHÁP CỦA CHÚNG
TÔI VƯỢT TRỘI HƠN ĐƯỜNG CƠ SỞ TRONG KHI TIẾT KIỆM 66% THAM SỐ.

Model Params ImageNet
ResNet50 25.7M 67.990
PHResNet50 n= 3 9.6M (-66%) 68.584

PHResNet với n= 3 trở thành lựa chọn phù hợp nhất trong
nhiều trường hợp, chứng minh tính hợp lệ của việc xử lý
hình ảnh RGB trong miền tự nhiên của chúng tận dụng đại
số siêu phức. Tuy nhiên, hiệu suất với n= 3 và n= 4 có thể
so sánh được, do đó việc lựa chọn siêu tham số này có thể
phụ thuộc vào ứng dụng hoặc phần cứng được sử dụng. Một
mặt, n= 4 đôi khi có thể dẫn đến hiệu suất thấp hơn, tuy
nhiên nó cho phép tiết kiệm bộ nhớ đĩa, như thể hiện trong
cột thứ ba của Bảng II, do đó nó có thể phù hợp hơn cho
các ứng dụng edge. Mặt khác, xử lý hình ảnh màu với n= 3
có thể mang lại độ chính xác cao hơn ngay cả khi nó yêu
cầu nhiều tham số hơn. Do đó, tính linh hoạt như vậy làm
cho PHNN thích ứng với một loạt rộng các ứng dụng. Tương
tự, PHResNet với n= 2 đạt được điểm độ chính xác đáng kể
so với các mô hình có giá trị thực tương ứng và, do số lượng
tham số lớn hơn so với mô hình PH với n= 3, đôi khi cũng
vượt trội hơn nó. Cuối cùng, PHResNet với n= 4 đạt được
độ chính xác tổng thể tốt nhất trong thí nghiệm lớn nhất
của tập hợp này. Thật vậy, xem xét backbone ResNet152 trên
CIFAR100, phương pháp của chúng tôi vượt quá đường cơ sở
có giá trị thực hơn 4%. Đây là bằng chứng thực nghiệm rằng,
PHNN mở rộng quy mô tốt cho các vấn đề thực tế lớn bằng
cách giảm đáng kể tổng số tham số. Những kết quả này được
tóm tắt cho các mô hình ResNet và VGG trên CIFAR10 trong
Hình 4. Biểu đồ hiển thị độ chính xác của các mô hình so
với tham số mô hình. Các mô hình dựa trên PH, dù là ResNet
hay VGG, đều vượt quá các đường cơ sở có giá trị thực và
quaternion của chúng trong khi liên tục giảm số lượng tham
số. Hơn nữa, trong Bảng II, chúng tôi cũng báo cáo bộ nhớ
cần thiết để lưu trữ các checkpoint mô hình để suy luận.
Phương pháp của chúng tôi giảm quan trọng lượng yêu cầu
bộ nhớ đĩa so với mô hình có giá trị thực nặng hơn.

Hơn nữa, chúng tôi thực hiện nhiệm vụ phân loại hình ảnh
trên bộ dữ liệu ImageNet. Chúng tôi tính toán tỷ lệ phần trăm
thành công của các mô hình dựa trên ResNet trong mỗi lần
chạy mà chúng tôi báo cáo độ chính xác trung bình trong
Bảng II. Như Hình 5 thể hiện, tỷ lệ phần trăm thành công
lớn nhất được đạt bởi PHResNet với n= 3 đã được chứng
minh là lựa chọn có giá trị nhất cho n khi xử lý hình ảnh
RGB. Do đó, chúng tôi thử nghiệm PHResNet với n= 3 so
với đối tác có giá trị thực. Bảng III cho thấy phương pháp
được đề xuất đạt được hiệu suất có thể so sánh, và thậm chí
hơi vượt trội, so với đường cơ sở có giá trị thực, trong khi
liên quan đến ít hơn 66% tham số. Ngoài ra, trong Hình 6,
chúng tôi cung cấp các trực quan hóa Grad-CAM [54] cho
một mẫu dự đoán bằng phương pháp của chúng tôi trong bộ
dữ liệu ImageNet để chứng minh thêm hành vi đúng của
PHResNet50 n= 3 trong kịch bản này. Điều này chứng minh
độ mạnh mẽ của phương pháp được đề xuất, có thể được
áp dụng và triển khai trong các mô hình ở các quy mô khác
nhau.

Hình 6. Trực quan hóa Grad-CAM cho PHResNet50 n= 3 trên bộ dữ liệu
ImageNet.

VII. ĐÁNH GIÁ THỰC NGHIỆM TRÊN PHÁT HIỆN SỰ KIỆN ÂM THANH

Phát hiện sự kiện âm thanh (SED) là nhiệm vụ nhận biết các
lớp âm thanh và tại những thời điểm nào các âm thanh này
hoạt động trong tín hiệu âm thanh [55]. Chúng tôi chứng minh
rằng lớp PHC có thể thích ứng với tín hiệu đầu vào n-chiều
và, do việc giảm tham số và đại số siêu phức, hiệu quả hơn
về hiệu quả và điểm đánh giá.

A. Thiết lập thí nghiệm

Đối với các mô hình phát hiện sự kiện âm thanh, chúng tôi
xem xét phiên bản tăng cường của SELDnet [49], [52] được
đề xuất làm chuẩn cho L3DAS21 Challenge Task 2 [56] và
chúng tôi thực hiện thí nghiệm với bộ dữ liệu được phát hành
tương ứng1. Chúng tôi xem xét làm đường cơ sở của chúng
tôi SEDnet (không có phần định vị) và đối tác quaternion
của nó. Bộ dữ liệu L3DAS21 Task 2 chứa 15 giờ ghi âm
Ambisonics định dạng B MSMP, chia thành 900 điểm dữ liệu
dài 1 phút được lấy mẫu ở tốc độ 32kHz, nơi tối đa 3 sự
kiện âm thanh có thể chồng lên nhau. 14 lớp âm thanh được
chọn từ bộ dữ liệu FSD50K và đại diện cho âm thanh văn
phòng: bàn phím máy tính, mở/đóng ngăn kéo, mở/đóng tủ,
búng tay, leng keng chìa khóa, gõ cửa, tiếng cười, kéo, điện
thoại, viết, tiếng leng keng và tiếng kêu, máy in, tiếng nói
nữ, tiếng nói nam. Trong bộ dữ liệu này, sự khác biệt về âm
lượng giữa các âm thanh nằm trong khoảng 0 và 20dB full
scale (dBFS). Xem xét mảng hai microphone 1;2, thứ tự kênh
là [W1, Z1, Y1, X1, W2, Z2, Y2, X2], trong đó W, X, Y, Z là
các kênh B-format ambisonics nếu thông tin pha (p) không
được xem xét. Liệu chúng ta có muốn
1Bộ dữ liệu L3DAS21 và mã nguồn có sẵn tại: https://github.com/l3das/
L3DAS21.

--- TRANG 9 ---
9
W1
 Z1
 Y1
 X1
 W1p
 Z1p
 Y1p
 X1p
Hình 7. Quang phổ mẫu từ bộ dữ liệu L3DAS21 được ghi bởi một micro-
phone với bốn capsule. Bốn hình đầu tiên đại diện cho độ lớn trong khi
bốn hình cuối cùng chứa thông tin pha tương ứng. Các phần màu đen đại
diện cho các khoảnh khắc im lặng.

bao gồm thông tin này, thứ tự sẽ là [W1, Z1, Y1, X1, W1p,
Z1p, Y1p, X1p, W2, Z2, Y2, X2, W2p, Z2p, Y2p, X2p] lên
đến 16 kênh. Trong Hình 7, chúng tôi thể hiện đầu vào 8 kênh
khi xem xét một microphone và thông tin pha. Độ lớn và pha
được chuẩn hóa để được tập trung ở 0 với độ lệch chuẩn 1.

Chúng tôi thực hiện thí nghiệm với nhiều cấu hình của bộ
dữ liệu này. Chúng tôi đầu tiên thử nghiệm các bản ghi từ
một microphone xem xét chỉ độ lớn (đầu vào 4 kênh), sau
đó chúng tôi thử nghiệm mạng với tín hiệu được ghi bởi hai
microphone và chỉ độ lớn (đầu vào 8 kênh). Các đặc trưng
được trích xuất bởi quá trình tiền xử lý được đưa vào ngăn
xếp tích chập bốn lớp với 64;128;256;512 bộ lọc, với chuẩn
hóa lô, kích hoạt ReLU, max pooling và dropout (xác suất
0:3), với kích thước pooling (8;2);(8;2);(2;2);(1;1). Mô-đun
GRU hai chiều có ba lớp, mỗi lớp có kích thước ẩn 256. Đuôi
là bộ phân loại được kết nối đầy đủ bốn lớp với 1024 bộ lọc
xen kẽ bởi ReLU và với một dropout cuối cùng và hàm kích
hoạt sigmoid. Tốc độ học ban đầu được đặt là 0:00001. Để
nhất quán với các chỉ số văn học có sẵn, chúng tôi định nghĩa
True Positive như TP, False Positive như FP và False Negative
như FN. Chúng được tính toán theo chỉ số phát hiện [56].
Hơn nữa, để tính toán Tỷ lệ Lỗi (ER), chúng tôi xem xét:
S = min(FN;FP), D= max(0;FNFP) và I = max(0;FPFN),
như trong [52], [55]. Do đó, chúng tôi xem xét:

Fscore=2TP
2TP+FP+FN;
ER=S+D+I
N;

trong đó N là tổng số lớp sự kiện âm thanh hoạt động trong
tham chiếu. Điểm SED được định nghĩa bởi:

SED score=ER+ 1Fscore
2:

Params Saving
F
SEDTraining Time
Saving
Inference Time
Saving1-ERSEDnet
Quat SEDnet
PH SEDnet n=2
PH SEDnet n=4
PH SEDnet n=8Hình 8. Biểu đồ radar cho kết quả SEDnet trên bộ dữ liệu L3DAS21 với
hai microphone. Diện tích càng lớn, kết quả càng tốt. Với cùng thời gian
tính toán, PHC n= 2 đạt điểm số tốt hơn so với PHC n= 4 với chi phí là
nhiều tham số hơn. SEDnet có giá trị thực, mặc dù điểm SED rời rạc, có
yêu cầu thời gian tính toán cao cũng như số lượng tham số lớn nhất.

Đối với ER và điểm SED, điểm số càng thấp, hiệu suất càng
tốt, trong khi đối với điểm F, giá trị cao hơn đứng cho độ
chính xác tốt hơn.

B. Kết quả thí nghiệm

Chúng tôi điều tra PHSEDnet trong miền phức, quaternion
và octonion với n= 2;4;8 và huấn luyện mỗi mạng trong
1000 epoch với kích thước lô 16. Các PHSEDnet siêu phức
được tham số hóa được đề xuất rõ ràng vượt trội hơn các
đường cơ sở có giá trị thực và quaternion, như báo cáo trong
Bảng IV và Bảng V. Thật vậy, PHSEDnet với n= 2 đạt được
kết quả tốt nhất cho mỗi điểm số và trong cả bộ dữ liệu một
và hai microphone, chứng minh rằng việc chia sẻ trọng số
do tham số hóa siêu phức có thể nắm bắt nhiều thông tin hơn
bất kể số lượng tham số thấp hơn. Thú vị khi lưu ý rằng
PHSEDnet n= 4, hoạt động trong miền quaternion, đạt được
điểm số cải thiện so với Quaternion SEDnet tuân theo các
quy tắc đại số được định nghĩa trước cứng nhắc. Hơn nữa,
tính linh hoạt của các lớp PHC cho phép đạt được hiệu suất
có thể so sánh so với đường cơ sở quaternion ngay cả khi
giảm tham số tích chập 87%, chỉ cần đặt n= 8. Trong Phần
VIII-B, chúng tôi thể hiện kết quả thí nghiệm bổ sung của
các mô hình PH có thể tiết kiệm 94% tham số tích chập trong
khi hoạt động trong miền sedonion bằng cách liên quan đến
n= 16.

Hơn nữa, PHSEDnet hiệu quả hơn về thời gian cần thiết cho
huấn luyện và suy luận. Bảng V cũng thể hiện rằng mỗi phiên
bản được thử nghiệm của phương pháp được đề xuất nhanh
hơn so với SEDnet thực và quaternion, cả ở thời gian huấn
luyện và thời gian suy luận. Hiệu quả thời gian rất quan trọng
trong các ứng dụng âm thanh nơi mạng thường được huấn
luyện trong hàng nghìn epoch và bộ dữ liệu rất lớn và yêu
cầu tính toán kéo dài.

Hình 8 tóm tắt số lượng tham số, điểm số chỉ số và thời
gian tính toán trong biểu đồ radar từ đó rõ ràng PHSEDnet
n= 2 đạt được điểm số tốt nhất và tiết kiệm thời gian lớn
với chi phí là nhiều tham số hơn so với các

--- TRANG 10 ---
10
BẢNG IV
KẾT QUẢ SEDNET VỚI MỘT MICROPHONE (ĐẦU VÀO 4 KÊNH). ĐIỂM SỐ ĐƯỢC TÍNH TOÁN QUA BA LẦN CHẠY VỚI CÁC SEED KHÁC NHAU VÀ
CHÚNG TÔI BÁO CÁO TRUNG BÌNH. PHƯƠNG PHÁP ĐỀ XUẤT VỚI n= 2 VƯỢT XA CÁC ĐƯỜNG CƠ SỞ TRONG MỖI CHỈ SỐ ĐƯỢC XEM XÉT.

Model Conv Params F score" ER# SED score# P" R"
SEDnet 1.6M 0.637 0.450 0.406 0.756 0.5505
Quaternion SEDnet 0.4M (-75%) 0.580 0.516 0.468 0.724 0.484
PHSEDnet n= 2 0.8M (-50%) 0.680 0.389 0.355 0.767 0.611
PHSEDnet n= 4 0.4M (-75%) 0.638 0.453 0.407 0.765 0.547

BẢNG V
KẾT QUẢ SEDNET VỚI HAI MICROPHONE (ĐẦU VÀO 8 KÊNH). ĐIỂM SỐ ĐƯỢC TÍNH TOÁN QUA BA LẦN CHẠY VỚI CÁC SEED KHÁC NHAU VÀ
CHÚNG TÔI BÁO CÁO TRUNG BÌNH. ĐỐI VỚI THỜI GIAN HUẤN LUYỆN (GIÂY/LẦN LẶP) TRUNG BÌNH VÀ ĐỘ LỆCH CHUẨN QUA MỘT EPOCH
ĐƯỢC BÁO CÁO, ĐỐI VỚI THỜI GIAN SUY LUẬN CHÚNG TÔI BÁO CÁO THỜI GIAN CẦN THIẾT ĐỂ THỰC HIỆN MỘT LẦN LẶP TRÊN BỘ XÁC THỰC.
CÁC MÔ HÌNH DỰA TRÊN PH VƯỢT XA CÁC ĐƯỜNG CƠ SỞ CẢ TRONG THỜI GIAN HUẤN LUYỆN VÀ SUY LUẬN.

Model Conv Params F score" ER# SED score# P" R" Time (T) Time (I)
SEDnet 1.6M 0.663 0.428 0.383 0.788 0.572 1.2420.088 1.198
Quaternion SEDnet 0.4M (-75%) 0.559 0.556 0.499 0.754 0.444 1.308 0.088 1.298
PHSEDnet n= 2 0.8M (-50%) 0.669 0.406 0.368 0.767 0.594 1.0910.074 1.085
PHSEDnet n= 4 0.4M (-75%) 0.638 0.433 0.397 0.729 0.567 1.0910.032 1.077
PHSEDnet n= 8 0.2M (-87%) 0.553 0.560 0.503 0.747 0.439 1.142 0.042 1.173

BẢNG VI
THÍ NGHIỆM TRÊN BỘ DỮ LIỆU SVHN VỚI CÁC MẠNG NHỎ NHẤT TỪ
MỖI HỌ, RESNET20 VÀ VGG11, MẠNG SAU VỚI SỐ BỘ LỌC ĐÃ SỬA
ĐỔI ĐỂ CÓ THỂ CHIA CHO MỖI GIÁ TRỊ CỦA n VÀ CÁC LỚP FC TRONG
BỘ PHÂN LOẠI ĐÓNG. CHÚNG TÔI CŨNG THỬ NGHIỆM PHNN VỚI n= 1
ĐỂ NHÂN BẢN MIỀN THỰC VƯỢT TRỘI HƠN RESNET20 CÓ GIÁ TRỊ THỰC.

Model Params SVHN
ResNet20 0.27M 90.463
Quaternion ResNet20 0.07M (-75%) 93.535
PHResNet20 n= 1 0.27M 93.796
PHResNet20 n= 2 0.14M (-50%) 93.708
PHResNet20 n= 4 0.07M (-75%) 93.669
VGG11 13.8M 93.488
Quaternion VGG11 3.9M (-71%) 92.888
PHVGG11 n= 2 7.2M (-48%) 93.958
PHVGG11 n= 3 5.0M (-64%) 93.804
PHVGG11 n= 4 3.9M (-71%) 93.919

phiên bản khác trừ phiên bản thực. Một sự đánh đổi tốt được
mang lại bởi mô hình PH n= 4 giảm thêm số lượng tham số
với chi phí là điểm SED và ER hơi tệ hơn. Hơn nữa, SEDnet
có giá trị thực có khả năng đạt được điểm số công bằng trong
khi có lượng tham số lớn nhất và yêu cầu thời gian tính toán
cao.

VIII. NGHIÊN CỨU LOẠI BỎ

A. Ít tham số hơn không dẫn đến khái quát hóa cao hơn

Trong phần sau, chúng tôi chứng minh rằng độ chính xác cao
hơn đạt được bằng phương pháp của chúng tôi không phải
do việc giảm tham số có thể dẫn đến khái quát hóa nhiều
hơn. Vì mục đích này, chúng tôi thực hiện nhiều thí nghiệm.
Đầu tiên, chúng tôi thử nghiệm ResNet nhẹ hơn được xây
dựng ban đầu cho bộ dữ liệu CIFAR10 [47]: ResNet20,
ResNet56 và ResNet110. Thứ hai, chúng tôi cũng xem xét
mạng VGG nhỏ nhất, tức là VGG11 có 14M tham số. Cuối
cùng, chúng tôi thực hiện thí nghiệm

BẢNG VII
CÁC DÒNG ĐẦU TIÊN BÁO CÁO KẾT QUẢ VGG16 VỚI BỘ PHÂN LOẠI
CÓ GIÁ TRỊ THỰC CHO QUATERNION VÀ PHNN. MỞ RỘNG CỦA BẢNG I.
THÍ NGHIỆM BỔ SUNG VỚI RESNET56 VÀ RESNET110, MẠNG SAU VỚI
SỐ BỘ LỌC ĐÃ SỬA ĐỔI ĐỂ CÓ THỂ CHIA CHO MỖI GIÁ TRỊ CỦA n.
ĐIỂM CHÍNH XÁC LÀ TRUNG BÌNH QUA BA LẦN CHẠY VỚI CÁC SEED
KHÁC NHAU.

Model Params SVHN CIFAR10
Quaternion VGG16 4.2M (-72%) 94.086 84.126
PHVGG16 n= 2 7.9M (-62%) 94.885 86.147
PHVGG16 n= 4 4.2M (-72%) 94.562 85.710
ResNet56 0.9M 94.116 83.700
Quaternion ResNet56 0.2M (-75%) 93.664 81.687
PHResNet56 n= 2 0.4M (-50%) 93.722 83.413
PHResNet56 n= 4 0.2 (-75%) 94.122 82.720
ResNet110 16.7M 93.461 84.810
Quaternion ResNet110 4.2M (-75%) 92.788 83.920
PHResNet110 n= 2 8.4M (-50%) 93.746 83.220
PHResNet110 n= 3 5.6M (-66%) 94.712 85.200
PHResNet110 n= 4 4.2M (-75%) 94.885 85.280

trên SVHN, CIFAR10 và CIFAR100 với ResNet18, ResNet50
và ResNet152 lớn hơn giảm số lượng bộ lọc 75% để có cùng
số lượng tham số với quaternion và PHNN với đối tác n= 4.

Bảng VI báo cáo thí nghiệm với ResNet20 nơi chúng tôi cũng
thử nghiệm n= 1 để nhân bản mô hình có giá trị thực, vượt
trội hơn nó. Thí nghiệm với VGG11 với số lượng bộ lọc đã
sửa đổi để có thể chia cho mỗi giá trị của n cũng được báo
cáo trong cùng bảng. Cuối cùng, trong Bảng VII chúng tôi
báo cáo thí nghiệm trên SVHN và CIFAR10 với ResNet56
và ResNet110, mạng sau với bộ lọc đã sửa đổi. Các mô hình
PH đạt được hiệu suất tốt trong mỗi thử nghiệm chúng tôi
thực hiện trong khi giảm lượng tham số tự do. Thật vậy,
PHResNet20 đạt được gần 94% độ chính xác trên bộ dữ liệu
SVHN chỉ liên quan đến 70k tham số.

Cuối cùng, để loại bỏ thêm giả thuyết rằng

--- TRANG 11 ---
11
BẢNG VIII
RESNET CÓ GIÁ TRỊ THỰC VỚI BỘ LỌC TÍCH CHẬP GIẢM 75%, ĐƯỢC
KÝ HIỆU BỞI (S). CÁC MÔ HÌNH ĐẦY ĐỦ VƯỢT TRỘI HƠN CÁC PHIÊN
BẢN GIẢM TRONG MỖI THÍ NGHIỆM, CHỨNG MINH RẰNG SỐ LƯỢNG
THAM SỐ NHỎ HƠN KHÔNG DẪN ĐẾN KHẢ NĂNG KHÁI QUÁT HÓA CAO HƠN.

Model Params SVHN CIFAR10 CIFAR100
ResNet18 10.1M 93.992 89.543 62.634
ResNet18 (s) 2.7M (-75%) 93.842 88.310 59.590
ResNet50 22.5M 94.546 89.630 65.514
ResNet50 (s) 5.7M (-75%) 93.915 89.370 62.450
ResNet152 52.6M 94.625 89.580 62.053
ResNet152 (s) 13.2M (-75%) 94.400 89.001 60.850

số lượng tham số nơ-ron nhỏ hơn dẫn đến khả năng khái quát
hóa cao hơn, chúng tôi thực hiện thí nghiệm với các đường
cơ sở có giá trị thực với số lượng tham số giảm 75%. Bảng
VIII cho thấy việc giảm số lượng bộ lọc làm giảm hiệu suất
và do đó không đủ để cải thiện khả năng khái quát hóa của
mô hình. Chúng tôi không bao gồm độ lệch chuẩn cho các
giá trị trong các nghiên cứu loại bỏ vì các giá trị tương tự
như các ví dụ trước đó nên chúng tôi nhắm đến việc ủng hộ
khả năng đọc của bài báo.

B. Đẩy siêu tham số n lên đến 16

Trong phần sau, chúng tôi thực hiện thí nghiệm bổ sung cho
nhiệm vụ phát hiện sự kiện âm thanh. Chúng tôi thực hiện
thử nghiệm xem xét hai microphone và thông tin pha, để có
đầu vào với 16 kênh. Vì mục đích này, chúng tôi xem xét
làm đường cơ sở mô hình quaternion và PHNN với n= 4;8;16
để thử nghiệm các miền bậc cao hơn. Quaternion và PHSEDnet
với n= 4 quản lý 16 kênh bằng cách nhóm chúng thành bốn
thành phần, do đó lắp ráp chúng thành 4 kênh: một kênh
chứa độ lớn của microphone đầu tiên, một kênh pha của
cùng microphone, và vân vân. Do đó, các chi tiết đến từ độ
lớn, là quan trọng nhất để phát hiện sự kiện âm thanh, được
nhóm lại với nhau mà không khai thác đúng thông tin này.
Ngược lại, việc sử dụng các lớp PHC cho phép mô hình xử
lý thông tin mà không nhóm thô các kênh mà thay vào đó
tận dụng mọi thông tin bằng cách dễ dàng đặt n bằng số
lượng kênh, trong trường hợp này là 16. Từ Bảng IX, rõ ràng
việc sử dụng mô hình 4 kênh như Quaternion hoặc PHC với
n= 4 không dẫn đến hiệu suất cao hơn, mặc dù số lượng
tham số cao hơn. Thật vậy, điểm số tốt nhất được đạt với
các mô hình PHC liên quan đến n= 8 và n= 16 có thể nắm
bắt thông tin từ mỗi kênh.

IX. KẾT LUẬN

Trong bài báo này, chúng tôi giới thiệu một lớp tích chập
siêu phức được tham số hóa (PHC) nắm bắt quy tắc tích chập
trực tiếp từ dữ liệu và có thể hoạt động trong bất kỳ miền
nào từ 1D đến nD, bất kể các quy định đại số có được đặt
trước hay không. Phương pháp được đề xuất giảm tham số
tích chập xuống 1=n so với các đối tác có giá trị thực và
cho phép nắm bắt các mối quan hệ tiềm ẩn nội tại nhờ việc
chia sẻ tham số giữa các chiều đầu vào. Sử dụng phương
pháp này, cùng với phương pháp trong [37], chúng tôi thiết
kế họ các mạng nơ-ron siêu phức được tham số hóa (PHNN),
một tập hợp các mô hình nơ-ron nhẹ và hiệu quả khai thác
các tính chất đại số siêu phức để tăng hiệu suất và tính linh
hoạt cao. Chúng tôi thể hiện phương pháp của chúng tôi linh
hoạt để hoạt động trong các lĩnh vực ứng dụng khác nhau
bằng cách thực hiện thí nghiệm với hình ảnh và tín hiệu âm
thanh. Chúng tôi cũng chứng minh tính linh hoạt và độ mạnh
mẽ của phương pháp để học các quy tắc tích chập trong bất
kỳ miền nào bằng cách đặt các giá trị khác nhau cho siêu
tham số n từ 2 đến 16.

Khí thải CO2 liên quan đến thí nghiệm
Thí nghiệm được thực hiện sử dụng hạ tầng riêng, có hiệu
quả carbon 0.445 kgCO2eq/kWh. Tổng cộng 2000 giờ tính
toán được thực hiện trên phần cứng loại Tesla V100-SXM2-
32GB (TDP 300W). Tổng lượng khí thải ước tính là 267
kgCO2eq trong đó 0 phần trăm được bù trừ trực tiếp. Ước
tính được thực hiện sử dụng máy tính Machine Learning
Impact được trình bày trong [57].

Cụ thể hơn, xem xét một thí nghiệm cho nhiệm vụ phát hiện
sự kiện âm thanh (SED), theo Bảng V, đường cơ sở có giá
trị thực yêu cầu khoảng 20 giờ để huấn luyện và xác thực,
với lượng khí thải carbon tương ứng là 2:71kgCO2eq. Ngược
lại, mô hình PH được đề xuất mất khoảng 17 giờ với việc
giảm lượng khí thải carbon 16%, là 2:28kgCO2eq.

Kết luận, chúng tôi tin rằng hiệu quả được cải thiện của
phương pháp chúng tôi so với các mô hình tiêu chuẩn có thể
là một bước nhỏ hướng tới việc giảm lượng khí thải carbon.

TÀI LIỆU THAM KHẢO
[1] T. Karras, S. Laine, M. Aittala, J. Hellsten, J. Lehtinen, and T. Aila,
"Analyzing and improving the image quality of StyleGAN," IEEE Conf.
on Computer Vision and Pattern Recognition (CVPR), 2020.
[2] S. d'Ascoli, H. Touvron, M. Leavitt, A. Morcos, G. Biroli, and L. Sagun,
"Convit: Improving vision transformers with soft convolutional inductive
biases," arXiv preprint: arXiv:2103.10697, 2021.
[3] A. Dosovitskiy, L. Beyer, A. Kolesnikov, D. Weissenborn, X. Zhai,
T. Unterthiner, M. Dehghani, M. Minderer, G. Heigold, S. Gelly,
J. Uszkoreit, and N. Houlsby, "An image is worth 16x16 words:
Transformers for image recognition at scale," in Int. Conf. on Learning
Representations (ICLR), 2021.
[4] E. Real, A. Aggarwal, Y. Huang, and Q. Le, "Regularized evolution for
image classifier architecture search," Proceedings of the AAAI Conf. on
Artificial Intelligence, vol. 33, pp. 4780–4789, Jul. 2019.
[5] J. Navarro-Moreno and J. C. Ruiz-Molina, "Wide-sense markov signals
on the tessarine domain. a study under properness conditions," Signal
Process., vol. 183, p. 108022, 2021.
[6] J. Navarro-Moreno, R. M. Fernández-Alcalá, J. D. Jiménez-López, and
J. C. Ruiz-Molina, "Tessarine signal processing under the t-properness
condition," Journal of the Franklin Institute, vol. 357, no. 14, pp. 10 100–
10 126, 2020.
[7] S. Sanei, C. C. Took, and S. Enshaeifar, "Quaternion adaptive line
enhancer based on singular spectrum analysis," in IEEE Int. Conf. on
Acoust., Speech and Signal Process. (ICASSP), 2018, pp. 2876–2880.
[8] M. Xiang, S. Enshaeifar, A. E. Stott, C. C. Took, Y. Xia, S. Kanna,
and D. P. Mandic, "Simultaneous diagonalisation of the covariance and
complementary covariance matrices in quaternion widely linear signal
processing," Signal Process., vol. 148, pp. 193–204, 2018.
[9] M. Kobayashi, "Quaternion projection rule for rotor hopfield neural
networks," IEEE Trans. Neural Netw. Learn. Syst., vol. 32, no. 2, pp.
900–908, 2021.
[10] D. Lin, X. Chen, Z. Li, B. Li, and X. Yang, "On the existence of the
exact solution of quaternion-valued neural networks based on a sequence
of approximate solutions," IEEE Trans. Neural Netw. Learn. Syst., pp.
1–9, 2021.

--- TRANG 12 ---
12
BẢNG IX
KẾT QUẢ SED VỚI HAI MICROPHONE: ĐỘ LỚN VÀ PHA (ĐẦU VÀO 16 KÊNH). CHÚNG TÔI THỬ NGHIỆM CÁC MIỀN SIÊU PHỨC BẬC CAO HƠN
LÊN ĐẾN SEDONION BẰNG CÁCH ĐẶT n= 16. MẶC DÙ VIỆC GIẢM SỐ LƯỢNG THAM SỐ KHÔNG THỂ TIN NỔI SO VỚI ĐƯỜNG CƠ SỞ CÓ GIÁ TRỊ
THỰC TRONG BẢNG V, PHNN VỚI n= 16 VẪN CÓ HIỆU SUẤT TƯƠNG ĐƯƠNG VỚI CÁC MÔ HÌNH KHÁC. HƠN NỮA, PHSEDNET VỚI n= 8 VƯỢT
TRỘI HƠN CŨNG ĐƯỜNG CƠ SỞ QUATERNION CÓ NHIỀU BẬC TỰ DO HƠN.

Model Conv Params F score" ER# SED score# P" R"
Quaternion SEDnet 0.4M (-75%) 0.580 0.480 0.450 0.655 0.520
PHSEDnet n= 4 0.4M (-75%) 0.585 0.470 0.443 0.653 0.530
PHSEDnet n= 8 0.2M (-87%) 0.607 0.466 0.430 0.702 0.534
PHSEDnet n= 16 0.1M (-94%) 0.588 0.509 0.461 0.734 0.491

[11] L. Liu, C. L. P. Chen, and Y. Wang, "Modal regression-based graph
representation for noise robust face hallucination," IEEE Trans. Neural
Netw. Learn. Syst., pp. 1–13, 2021.
[12] M. E. Valle and F. Z. De Castro, "On the dynamics of hopfield neural
networks on unit quaternions," IEEE Trans. Neural Netw. Learn. Syst.,
vol. 29, no. 6, pp. 2464–2471, 2018.
[13] Y. Liu, D. Zhang, J. Lou, J. Lu, and J. Cao, "Stability analysis
of quaternion-valued neural networks: Decomposition and direct ap-
proaches," IEEE Trans. Neural Netw. Learn. Syst., vol. 29, no. 9, pp.
4201–4211, 2018.
[14] M. E. Valle and R. A. Lobo, "Quaternion-valued recurrent projection
neural networks on unit quaternions," Theoretical Computer Science,
vol. 843, pp. 136–152, 2020.
[15] F. Z. De Castro and M. E. Valle, "A broad class of discrete-time
hypercomplex-valued Hopfield neural networks," Neural Networks, vol.
122, pp. 54–67, 2020.
[16] T. K. Paul and T. Ogunfunmi, "A kernel adaptive algorithm for
quaternion-valued inputs," IEEE Trans. Neural Netw. Learn. Syst.,
vol. 26, no. 10, pp. 2422–2439, Oct. 2015.
[17] A. Hirose, I. Aizenberg, and D. P. Mandic, "Guest editorial special issue
on complex- and hypercomplex-valued neural networks," IEEE Trans.
Neural Netw. Learn. Syst., vol. 25, no. 9, pp. 1597–1599, 2014.
[18] A. Muppidi and M. Radfar, "Speech emotion recognition using quater-
nion convolutional neural networks," in IEEE Int. Conf. on Acoustics,
Speech and Signal Process. (ICASSP), 2021, pp. 6309–6313.
[19] T. Parcollet, M. Ravanelli, M. Morchid, G. Linarès, C. Trabelsi,
R. De Mori, and Y. Bengio, "Quaternion recurrent neural networks,"
in Int. Conf. on Learning Representations (ICLR), New Orleans, LA,
May 2019, pp. 1–19.
[20] E. Grassucci, E. Cicero, and D. Comminiello, "Quaternion generative
adversarial networks," in Generative Adversarial Learning: Architec-
tures and Applications, R. Razavi-Far, A. Ruiz-Garcia, V. Palade, and
J. Schmidhuber, Eds. Cham: Springer International Publishing, 2022,
pp. 57–86.
[21] Y. Tay, A. Zhang, A. T. Luu, J. Rao, S. Zhang, S. Wang, J. Fu, and
C. S. Hui, "Lightweight and efficient neural natural language processing
with quaternion networks," in ACL (1). Association for Computational
Linguistics, 2019, pp. 1494–1503.
[22] A. Cariow and G. Cariowa, "Fast algorithms for deep octonion net-
works," IEEE Trans. Neural Netw. Learn. Syst., Nov. 2021.
[23] J. Wu, L. Xu, F. Wu, Y. Kong, L. Senhadji, and H. Shu, "Deep octonion
networks," Neurocomputing, vol. 397, pp. 179–191, 2020.
[24] M. E. Valle and R. A. Lobo, "Hypercomplex-valued recurrent correlation
neural networks," Neurocomputing, vol. 432, pp. 111–123, 2021.
[25] T. Chen, H. Yin, X. Zhang, Z. Huang, Y. Wang, and M. Wang,
"Quaternion factorization machines: A lightweight solution to intricate
feature interaction modeling," IEEE Trans. Neural Netw. Learn. Syst.,
pp. 1–14, 2021.
[26] E. Grassucci, D. Comminiello, and A. Uncini, "A quaternion-valued
variational autoencoder," in IEEE Int. Conf. on Acoust., Speech and
Signal Process. (ICASSP), Toronto, Canada, Jun. 2021.
[27] ——, "An information-theoretic perspective on proper quaternion vari-
ational autoencoders," Entropy, vol. 23, no. 7, 2021.
[28] S. Gai and X. Huang, "Reduced biquaternion convolutional neural
network for color image processing," IEEE Trans. on Circuits and
Systems for Video Technology, pp. 1–1, 2021.
[29] G. Vieira and M. E. Valle, "Extreme learning machines on Cayley-
Dickson algebra applied for color image auto-encoding," in IEEE Int.
Joint Conf. on Neural Netw. (IJCNN), 2020, pp. 1–8.
[30] C. C. Took and Y. Xia, "Multichannel quaternion least mean square
algorithm," in IEEE Int. Conf. on Acoust., Speech and Signal Process.
(ICASSP), 2019, pp. 8524–8527.
[31] C. J. Gaudet and A. S. Maida, "Removing dimensional restrictions on
complex/hyper-complex neural networks," in 2021 IEEE Int. Conf. on
Image Process. (ICIP), 2021, pp. 319–323.
[32] J. Hoffmann, S. Schmitt, S. Osindero, K. Simonyan, and E. Elsen,
"Algebranets," ArXiv preprint: arXiv:2006.07360, 2020.
[33] A. Cariow and G. Cariowa, "Fast algorithms for quaternion-valued
convolutional neural networks," IEEE Trans. Neural Netw. Learn. Syst.,
vol. 32, no. 1, pp. 457–462, 2021.
[34] C. Huang, A. Touati, P. Vincent, G. K. Dziugaite, A. Lacoste, and A. C.
Courville, "Stochastic neural network with Kronecker flow," in AISTATS,
2020.
[35] Z. Tang, F. Jiang, M. Gong, H. Li, Y. Wu, F. Yu, Z. Wang, and
M. Wang, "SKFAC: Training neural networks with faster Kronecker-
factored approximate curvature," in IEEE/CVF Conf. on Computer
Vision and Pattern Recognition (CVPR), 2021, pp. 13 479–13 487.
[36] D. Wang, B. Wu, G. S. Zhao, H. Chen, L. Deng, T. Yan, and G. Li,
"Kronecker CP decomposition with fast multiplication for compressing
RNNs," IEEE Trans. Neural Netw. Learn. Syst., vol. PP, 2021.
[37] A. Zhang, Y. Tay, S. Zhang, A. Chan, A. T. Luu, S. C. Hui, and J. Fu,
"Beyond fully-connected layers with quaternions: Parameterization of
hypercomplex multiplications with 1=n parameters," Int. Conf. on
Machine Learning (ICML), 2021.
[38] T. Le, M. Bertolini, F. Noé, and D. A. Clevert, "Parameterized hyper-
complex graph neural networks for graph classification," ArXiv preprint:
arXiv:2103.16584, 2021.
[39] R. K. Mahabadi, J. Henderson, and S. Ruder, "Compacter: Efficient low-
rank hypercomplex adapter layers," ArXiv preprint: arXiv:2106.04647,
2021.
[40] H. Wu, B. Xiao, N. C. F. Codella, M. Liu, X. Dai, L. Yuan, and
L. Zhang, "Cvt: Introducing convolutions to vision transformers," ArXiv,
vol. abs/2103.15808, 2021.
[41] S. Hershey, S. Chaudhuri, D. P. W. Ellis, J. F. Gemmeke, A. Jansen,
R. C. Moore, M. Plakal, D. Platt, R. A. Saurous, B. Seybold, M. Slaney,
R. J. Weiss, and K. Wilson, "CNN architectures for large-scale audio
classification," in IEEE Int. Conf. on Acoustics, Speech and Signal
Process. (ICASSP), 2017, pp. 131–135.
[42] T. Parcollet, M. Morchid, and G. Linarès, "A survey of quaternion neural
networks," Artif. Intell. Rev., Aug. 2019.
[43] C. Gaudet and A. Maida, "Deep quaternion networks," in IEEE Int. Joint
Conf. on Neural Netw. (IJCNN), Rio de Janeiro, Brazil, Jul. 2018.
[44] H. V. Henderson, F. Pukelsheim, and S. R. Searle, "On the history of
the kronecker product," Linear and Multilinear Algebra, vol. 14, no. 2,
pp. 113–120, 1983.
[45] T. Parcollet, M. Morchid, and G. Linarès, "Quaternion convolutional
neural networks for heterogeneous image processing," in IEEE Int. Conf.
on Acoust., Speech and Signal Process. (ICASSP), Brighton, UK, May
2019, pp. 8514–8518.
[46] K. Simonyan and A. Zisserman, "Very deep convolutional networks for
large-scale image recognition," in Int. Conf. on Learning Representations
(ICLR), San Diego, CA, USA, 2015.
[47] K. He, X. Zhang, S. Ren, and J. Sun, "Deep residual learning for
image recognition," in IEEE/CVF Conf. on Computer Vision and Pattern
Recognition (CVPR), 2016, pp. 770–778.
[48] T. Nitta, "A quaternary version of the back-propagation algorithm," 1995,
pp. 2753–2756.
[49] D. Comminiello, M. Lella, S. Scardapane, and A. Uncini, "Quaternion
convolutional neural networks for detection and localization of 3D sound

--- TRANG 13 ---
13
events," in IEEE Int. Conf. on Acoust., Speech and Signal Process.
(ICASSP), Brighton, UK, May 2019, pp. 8533–8537.
[50] M. Ricciardi Celsi, S. Scardapane, and D. Comminiello, "Quaternion
neural networks for 3D sound source localization in reverberant en-
vironments," in IEEE Int. Workshop on Machine Learning for Signal
Process., Espoo, Finland, Sep. 2020, pp. 1–6.
[51] E. Grassucci, G. Mancini, C. Brignone, A. Uncini, and D. Comminiello,
"Dual quaternion ambisonics array for six-degree-of-freedom acoustic
representation," arXiv preprint: arXiv:2204.01851, 2022.
[52] S. Adavanne, A. Politis, J. Nikunen, and T. Virtanen, "Sound event
localization and detection of overlapping sources using convolutional
recurrent neural networks," IEEE Journal of Selected Topics in Signal
Processing, vol. 13, pp. 34–48, 2019.
[53] R. Wightman, H. Touvron, and J. H., "Resnet strikes back: An improved
training procedure in timm," ArXiv preprint: arXiv:2110.00476, 2021.
[54] R. R. Selvaraju, M. Cogswell, A. Das, R. Vedantam, D. Parikh, and
D. Batra, "Grad-CAM: Visual explanations from deep networks via
gradient-based localization," in IEEE Int. Conf. on Computer Vision
(ICCV), 2017, pp. 618–626.
[55] A. Mesaros, T. Heittola, T. Virtanen, and M. D. Plumbley, "Sound event
detection: A tutorial," IEEE Signal Processing Magazine, vol. 38, no. 5,
pp. 67–83, 2021.
[56] E. Guizzo, R. F. Gramaccioni, S. Jamili, C. Marinoni, E. Massaro,
C. Medaglia, G. Nachira, L. Nucciarelli, L. Paglialunga, M. Pennese,
S. Pepe, E. Rocchi, A. Uncini, and D. Comminiello, "L3DAS21 Chal-
lenge: Machine learning for 3D audio signal processing," 2021 IEEE
Int. Workshop on Machine Learning for Signal Process. (MLSP), 2021.
[57] A. Lacoste, A. Luccioni, V. Schmidt, and T. Dandres, "Quanti-
fying the carbon emissions of machine learning," ArXiv preprint:
arXiv:1910.09700, 2019.

# 2212.13345.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/backpropagation/2212.13345.pdf
# Kích thước tệp: 585286 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
Thuật toán Forward-Forward: Một số Nghiên cứu Sơ bộ
Geoffrey Hinton
Google Brain
geoffhinton@google.com
Tóm tắt
Mục đích của bài báo này là giới thiệu một quy trình học mới cho mạng neural và chứng minh rằng nó hoạt động đủ tốt trên một số vấn đề nhỏ để đáng được nghiên cứu thêm. Thuật toán Forward-Forward thay thế các lượt truyền tiến và truyền ngược của backpropagation bằng hai lượt truyền tiến, một với dữ liệu dương (tức là dữ liệu thật) và một với dữ liệu âm có thể được tạo ra bởi chính mạng. Mỗi lớp có hàm mục tiêu riêng của nó, đó đơn giản là có độ tốt cao cho dữ liệu dương và độ tốt thấp cho dữ liệu âm. Tổng bình phương các hoạt động trong một lớp có thể được sử dụng làm độ tốt nhưng có nhiều khả năng khác, bao gồm cả âm của tổng bình phương các hoạt động. Nếu các lượt truyền dương và âm có thể được tách biệt theo thời gian, các lượt truyền âm có thể được thực hiện ngoại tuyến, điều này sẽ làm cho việc học đơn giản hơn nhiều trong lượt truyền dương và cho phép video được dẫn qua mạng mà không cần lưu trữ hoạt động hoặc dừng lại để lan truyền đạo hàm.

1 Có gì sai với backpropagation
Thành công đáng kinh ngạc của deep learning trong thập kỷ qua đã thiết lập hiệu quả của việc thực hiện stochastic gradient descent với số lượng lớn tham số và nhiều dữ liệu. Các gradient thường được tính toán sử dụng backpropagation (Rumelhart et al., 1986), và điều này đã dẫn đến nhiều quan tâm về việc liệu não có triển khai backpropagation hay nó có cách khác để có được các gradient cần thiết để điều chỉnh trọng số trên các kết nối.

Như một mô hình về cách vỏ não học, backpropagation vẫn không hợp lý mặc dù đã có nhiều nỗ lực để phát minh ra các cách mà nó có thể được triển khai bởi các neuron thực (Lillicrap et al., 2020; Richards and Lillicrap, 2019; Guerguiev et al., 2017; Scellier and Bengio, 2017). Không có bằng chứng thuyết phục nào rằng vỏ não một cách rõ ràng lan truyền đạo hàm lỗi hoặc lưu trữ hoạt động neural để sử dụng trong một lượt truyền ngược tiếp theo. Các kết nối từ trên xuống từ một vùng vỏ não đến một vùng sớm hơn trong đường dẫn thị giác không phản ánh các kết nối từ dưới lên như mong đợi nếu backpropagation được sử dụng trong hệ thống thị giác. Thay vào đó, chúng tạo thành các vòng lặp trong đó hoạt động neural đi qua khoảng nửa tá lớp vỏ não trong hai vùng trước khi quay trở lại nơi nó bắt đầu.

Backpropagation through time như một cách học chuỗi đặc biệt không hợp lý. Để xử lý luồng đầu vào cảm giác mà không cần nghỉ thường xuyên, não cần phải dẫn dữ liệu cảm giác qua các giai đoạn xử lý cảm giác khác nhau và nó cần một quy trình học có thể học trong quá trình bay. Các biểu diễn trong các giai đoạn muộn hơn của pipeline có thể cung cấp thông tin từ trên xuống ảnh hưởng đến các biểu diễn trong các giai đoạn sớm hơn của pipeline ở một bước thời gian muộn hơn, nhưng hệ thống nhận thức cần thực hiện suy luận và học theo thời gian thực mà không dừng lại để thực hiện backpropagation.arXiv:2212.13345v1  [cs.LG]  27 Dec 2022

--- TRANG 2 ---
Một hạn chế nghiêm trọng khác của backpropagation là nó yêu cầu kiến thức hoàn hảo về phép tính được thực hiện trong lượt truyền tiến¹ để tính toán các đạo hàm chính xác². Nếu chúng ta chèn một hộp đen vào lượt truyền tiến, không còn có thể thực hiện backpropagation trừ khi chúng ta học một mô hình khả vi của hộp đen. Như chúng ta sẽ thấy, hộp đen không thay đổi quy trình học chút nào đối với Thuật toán Forward-Forward vì không cần backpropagate qua nó.

Trong trường hợp không có mô hình hoàn hảo của lượt truyền tiến, luôn có thể sử dụng một trong nhiều hình thức của reinforcement learning. Ý tưởng là tạo ra các nhiễu loạn ngẫu nhiên của trọng số hoặc hoạt động neural và tương quan các nhiễu loạn này với những thay đổi kết quả trong hàm payoff. Nhưng các quy trình reinforcement learning gặp phải phương sai cao: rất khó để thấy ảnh hưởng của việc nhiễu loạn một biến khi nhiều biến khác đang bị nhiễu loạn cùng lúc. Để làm giảm nhiễu gây ra bởi tất cả các nhiễu loạn khác, tốc độ học cần tỷ lệ nghịch với số lượng biến đang bị nhiễu loạn và điều này có nghĩa là reinforcement learning mở rộng kém và không thể cạnh tranh với backpropagation cho các mạng lớn chứa hàng triệu hoặc hàng tỷ tham số³.

Điểm chính của bài báo này là chỉ ra rằng các mạng neural chứa các phi tuyến không xác định không cần phải sử dụng reinforcement learning. Thuật toán Forward-Forward (FF) có tốc độ tương đương với backpropagation nhưng có ưu điểm là nó có thể được sử dụng khi các chi tiết chính xác của phép tính tiến không xác định. Nó cũng có ưu điểm là nó có thể học trong khi dẫn dữ liệu tuần tự qua một mạng neural mà không cần lưu trữ hoạt động neural hoặc dừng lại để lan truyền đạo hàm lỗi.

Thuật toán forward-forward chậm hơn một chút so với backpropagation và không tổng quát hóa tốt bằng trên một số vấn đề đồ chơi được nghiên cứu trong bài báo này nên không có khả năng thay thế backpropagation cho các ứng dụng mà năng lượng không phải là vấn đề. Việc khám phá thú vị về khả năng của các mô hình rất lớn được huấn luyện trên các tập dữ liệu rất lớn sẽ tiếp tục sử dụng backpropagation. Hai lĩnh vực mà thuật toán forward-forward có thể vượt trội hơn backpropagation là như một mô hình học trong vỏ não và như một cách sử dụng phần cứng analog năng lượng rất thấp mà không sử dụng reinforcement learning (Jabri and Flower, 1992).

2 Thuật toán Forward-Forward
Thuật toán Forward-Forward là một quy trình học đa lớp tham lam được lấy cảm hứng từ Boltzmann machines (Hinton and Sejnowski, 1986) và Noise Contrastive Estimation (Gutmann and Hyvärinen, 2010). Ý tưởng là thay thế các lượt truyền tiến và ngược của backpropagation bằng hai lượt truyền tiến hoạt động theo cách chính xác giống nhau, nhưng trên dữ liệu khác nhau và với mục tiêu đối lập. Lượt truyền dương hoạt động trên dữ liệu thật và điều chỉnh trọng số để tăng độ tốt trong mọi lớp ẩn. Lượt truyền âm hoạt động trên "dữ liệu âm" và điều chỉnh trọng số để giảm độ tốt trong mọi lớp ẩn. Bài báo này khám phá hai thước đo độ tốt khác nhau - tổng bình phương các hoạt động neural và âm của tổng bình phương các hoạt động, nhưng nhiều thước đo khác là có thể.

Hãy giả sử rằng hàm độ tốt cho một lớp đơn giản là tổng bình phương các hoạt động của các neuron tuyến tính được chỉnh lưu trong lớp đó⁴. Mục đích của việc học là làm cho độ tốt cao hơn một giá trị ngưỡng nào đó đối với dữ liệu thật và thấp hơn giá trị đó đối với dữ liệu âm. Cụ thể hơn, mục đích là phân loại chính xác các vector đầu vào là dữ liệu dương hay dữ liệu âm khi xác suất một vector đầu vào là dương (tức là thật) được cho bởi việc áp dụng hàm logistic vào độ tốt trừ đi một ngưỡng nào đó,

p(dương) = σ(∑ⱼyⱼ² - θ)                 (1)

trong đó yⱼ là hoạt động của đơn vị ẩn j trước khi chuẩn hóa lớp. Dữ liệu âm có thể được dự đoán bởi mạng neural sử dụng các kết nối từ trên xuống, hoặc nó có thể được cung cấp từ bên ngoài.

2.1 Học nhiều lớp biểu diễn với một hàm độ tốt đơn giản theo lớp
Dễ dàng thấy rằng một lớp ẩn đơn có thể được học bằng cách làm cho tổng bình phương hoạt động của các đơn vị ẩn cao đối với dữ liệu dương và thấp đối với dữ liệu âm. Nhưng nếu các hoạt động của lớp ẩn đầu tiên sau đó được sử dụng làm đầu vào cho lớp ẩn thứ hai, việc phân biệt dữ liệu dương từ dữ liệu âm trở nên tầm thường bằng cách đơn giản sử dụng độ dài của vector hoạt động trong lớp ẩn đầu tiên. Không cần học bất kỳ đặc trưng mới nào. Để ngăn chặn điều này, FF chuẩn hóa độ dài của vector ẩn trước khi sử dụng nó làm đầu vào cho lớp tiếp theo (Ba et al., 2016b; Carandini and Heeger, 2013). Điều này loại bỏ tất cả thông tin được sử dụng để xác định độ tốt trong lớp ẩn đầu tiên và buộc lớp ẩn tiếp theo phải sử dụng thông tin trong các hoạt động tương đối của các neuron trong lớp ẩn đầu tiên. Các hoạt động tương đối này không bị ảnh hưởng bởi chuẩn hóa lớp⁵. Nói cách khác, vector hoạt động trong lớp ẩn đầu tiên có độ dài và hướng. Độ dài được sử dụng để định nghĩa độ tốt cho lớp đó và chỉ hướng được truyền đến lớp tiếp theo.

3 Một số thí nghiệm với FF
Mục đích của bài báo này là giới thiệu thuật toán FF và chỉ ra rằng nó hoạt động trong các mạng neural tương đối nhỏ chứa vài triệu kết nối. Một bài báo tiếp theo sẽ nghiên cứu mức độ hoạt động tốt của nó đối với các mạng neural lớn chứa các kết nối nhiều bậc độ lớn hơn.

3.1 Baseline backpropagation
Hầu hết các thí nghiệm được mô tả trong bài báo sử dụng tập dữ liệu MNIST của các chữ số viết tay. 50.000 hình ảnh huấn luyện chính thức được sử dụng để huấn luyện và 10.000 để xác thực trong quá trình tìm kiếm các siêu tham số tốt. Tập kiểm tra chính thức gồm 10.000 hình ảnh sau đó được sử dụng để tính toán tỷ lệ lỗi kiểm tra. MNIST đã được nghiên cứu kỹ và hiệu suất của các mạng neural đơn giản được huấn luyện với backpropagation đã được biết rõ. Điều này làm cho MNIST rất thuận tiện để kiểm tra các thuật toán học mới xem chúng có thực sự hoạt động không.

Các mạng neural tích chập được thiết kế hợp lý với một vài lớp ẩn thường đạt khoảng 0.6% lỗi kiểm tra. Trong phiên bản "bất biến hoán vị" của nhiệm vụ, mạng neural không được cung cấp bất kỳ thông tin nào về bố cục không gian của các pixel nên nó sẽ hoạt động tốt như nhau nếu tất cả các hình ảnh huấn luyện và kiểm tra được áp dụng cùng một hoán vị ngẫu nhiên của các pixel trước khi bắt đầu huấn luyện. Đối với phiên bản bất biến hoán vị của nhiệm vụ, các mạng neural feed-forward với một vài lớp ẩn được kết nối đầy đủ của Rectified Linear Units (ReLUs) thường đạt khoảng 1.4% lỗi kiểm tra⁶ và chúng mất khoảng 20 epoch để huấn luyện. Điều này có thể được giảm xuống khoảng 1.1% lỗi kiểm tra sử dụng nhiều regularizer khác nhau như dropout (Srivastava et al., 2014) (làm cho huấn luyện chậm hơn) hoặc label smoothing (Pereyra et al., 2017) (làm cho huấn luyện nhanh hơn). Nó có thể được giảm thêm bằng cách kết hợp học có giám sát của các nhãn với học không giám sát mô hình hóa phân phối của hình ảnh.

Tóm lại, 1.4% lỗi kiểm tra trên phiên bản bất biến hoán vị của nhiệm vụ mà không sử dụng các regularizer phức tạp, cho thấy rằng, đối với MNIST, một quy trình học hoạt động khoảng bằng backpropagation⁷.

3 Tôi đã huấn luyện hàng nghìn mạng neural khác nhau trên MNIST và, theo tinh thần của Ramon y Cajal, tôi tin rằng việc báo cáo hiệu suất của mạng điển hình không tồn tại sẽ có nhiều thông tin hơn việc báo cáo hiệu suất của bất kỳ mạng cụ thể nào.

7 Một số bài báo về các lựa chọn thay thế hợp lý sinh học cho backpropagation báo cáo tỷ lệ lỗi kiểm tra lớn hơn 2% trên MNIST bất biến hoán vị. Điều này cho thấy rằng quy trình học không hoạt động gần bằng backpropagation hoặc các tác giả đã không điều chỉnh nó đúng cách.

--- TRANG 3 ---
[Hình 1: Một hình ảnh lai được sử dụng làm dữ liệu âm]

3.2 Một ví dụ không giám sát đơn giản của FF
Có hai câu hỏi chính về FF cần được trả lời. Thứ nhất, nếu chúng ta có một nguồn dữ liệu âm tốt, nó có học được các biểu diễn đa lớp hiệu quả nắm bắt cấu trúc trong dữ liệu không? Thứ hai, dữ liệu âm đến từ đâu? Chúng ta bắt đầu bằng cách cố gắng trả lời câu hỏi đầu tiên sử dụng một nguồn dữ liệu âm được chế tạo thủ công như một cái nạng tạm thời để chúng ta có thể nghiên cứu câu hỏi đầu tiên một cách riêng biệt.

Một cách phổ biến để sử dụng contrastive learning cho một nhiệm vụ học có giám sát là đầu tiên học chuyển đổi các vector đầu vào thành các vector biểu diễn mà không sử dụng bất kỳ thông tin nào về các nhãn và sau đó học một phép chuyển đổi tuyến tính đơn giản của các vector biểu diễn này thành các vector logit được sử dụng trong softmax để xác định phân phối xác suất trên các nhãn. Điều này được gọi là một bộ phân loại tuyến tính mặc dù có tính phi tuyến rõ ràng của nó. Việc học phép chuyển đổi tuyến tính thành logit là có giám sát, nhưng không liên quan đến việc học bất kỳ lớp ẩn nào nên không yêu cầu backpropagation của đạo hàm.

FF có thể được sử dụng để thực hiện loại học biểu diễn này bằng cách sử dụng các vector dữ liệu thật làm ví dụ dương và các vector dữ liệu bị hỏng làm ví dụ âm. Có nhiều cách rất khác nhau để làm hỏng dữ liệu.

Để buộc FF tập trung vào các tương quan tầm xa hơn trong hình ảnh đặc trưng cho các hình dạng, chúng ta cần tạo dữ liệu âm có các tương quan tầm xa rất khác nhau nhưng các tương quan tầm ngắn rất giống nhau. Điều này có thể được thực hiện bằng cách tạo một mặt nạ chứa các vùng khá lớn của các số một và số không. Sau đó chúng ta tạo hình ảnh lai cho dữ liệu âm bằng cách cộng một hình ảnh chữ số nhân với mặt nạ và một hình ảnh chữ số khác nhân với nghịch đảo của mặt nạ như được hiển thị trong hình 1. Các mặt nạ như thế này có thể được tạo bằng cách bắt đầu với một hình ảnh bit ngẫu nhiên và sau đó liên tục làm mờ hình ảnh với một bộ lọc có dạng [1/4; 1/2; 1/4] theo cả hướng ngang và dọc. Sau khi làm mờ lặp đi lặp lại, hình ảnh sau đó được ngưỡng hóa ở 0.5.

Sau khi huấn luyện một mạng với bốn lớp ẩn mỗi lớp 2000 ReLU trong 100 epoch, chúng ta có tỷ lệ lỗi kiểm tra 1.37% nếu chúng ta sử dụng các vector hoạt động chuẩn hóa của ba lớp ẩn cuối cùng làm đầu vào cho softmax được huấn luyện để dự đoán nhãn. Sử dụng lớp ẩn đầu tiên như một phần của đầu vào cho bộ phân loại tuyến tính làm hiệu suất kiểm tra tệ hơn.

Thay vì sử dụng các lớp được kết nối đầy đủ, chúng ta có thể sử dụng các trường tiếp nhận cục bộ (không chia sẻ trọng số) và điều này cải thiện hiệu suất. Chỉ có một kiến trúc được thử⁸. Sau khi huấn luyện trong 60 epoch, nó cho 1.16% lỗi kiểm tra. Nó sử dụng "peer normalization" của các hoạt động ẩn để ngăn bất kỳ đơn vị ẩn nào hoạt động cực kỳ mạnh hoặc tắt vĩnh viễn⁹.

8 Lớp ẩn đầu tiên sử dụng lưới 4x4 vị trí với bước 6, trường tiếp nhận 10x10 pixel và 128 kênh tại mỗi vị trí. Lớp ẩn thứ hai sử dụng lưới 3x3 với 220 kênh tại mỗi điểm lưới. Trường tiếp nhận là tất cả các kênh trong một hình vuông của 4 điểm lưới liền kề trong lớp bên dưới. Lớp ẩn thứ ba sử dụng lưới 2x2 với 512 kênh và, một lần nữa, trường tiếp nhận là tất cả các kênh trong một hình vuông của 4 điểm lưới liền kề trong lớp bên dưới. Kiến trúc này có khoảng 2000 đơn vị ẩn mỗi lớp.

9 Có lợi khi đo hoạt động trung bình của một đơn vị và giới thiệu một đạo hàm bổ sung khiến hoạt động trung bình này hồi quy về một giá trị mục tiêu hợp lý nào đó. Để tránh phải chọn giá trị mục tiêu có thể không tương thích với yêu cầu của nhiệm vụ, peer normalization sử dụng trung bình chạy của hoạt động trung bình của tất cả các đơn vị ẩn trong lớp làm mục tiêu. Khi hoạt động của ReLU bằng không, không có đạo hàm nào đối với đầu vào của ReLU nhưng chúng ta giả vờ rằng có để các đơn vị chết có trọng số đến tăng lên. Hệ số xác định độ mạnh của regularizer này được đặt sao cho hoạt động trung bình của các đơn vị trong một lớp tương tự nhau, nhưng không quá tương tự.

--- TRANG 4 ---
[Hình 1: Một hình ảnh lai được sử dụng làm dữ liệu âm]

3.3 Một ví dụ có giám sát đơn giản của FF
Học các biểu diễn ẩn mà không sử dụng bất kỳ thông tin nhãn nào khá hợp lý đối với các mô hình lớn cuối cùng cần có khả năng thực hiện nhiều nhiệm vụ khác nhau. Việc học không giám sát trích xuất một loạt các đặc trưng và các nhiệm vụ riêng lẻ có thể sử dụng bất kỳ đặc trưng nào hữu ích. Nhưng nếu chúng ta chỉ quan tâm đến một nhiệm vụ và chúng ta muốn sử dụng một mô hình nhỏ không có khả năng mô hình hóa toàn bộ phân phối của dữ liệu đầu vào, việc sử dụng học có giám sát sẽ hợp lý hơn. Một cách để đạt được điều này với FF là bao gồm nhãn trong đầu vào¹⁰. Dữ liệu dương bao gồm một hình ảnh với nhãn chính xác và dữ liệu âm bao gồm một hình ảnh với nhãn không chính xác. Vì sự khác biệt duy nhất giữa dữ liệu dương và âm là nhãn, FF nên bỏ qua tất cả các đặc trưng của hình ảnh không tương quan với nhãn.

Hình ảnh MNIST chứa viền đen để làm cho cuộc sống dễ dàng cho các mạng neural tích chập. Nếu chúng ta thay thế 10 pixel đầu tiên bằng biểu diễn một trong N của nhãn, rất dễ dàng để hiển thị những gì lớp ẩn đầu tiên học. Một mạng với 4 lớp ẩn mỗi lớp chứa 2000 ReLU và kết nối đầy đủ giữa các lớp có 1.36% lỗi kiểm tra trên MNIST sau 60 epoch. Backpropagation mất khoảng 20 epoch để có hiệu suất kiểm tra tương tự. Tăng gấp đôi tốc độ học của FF và huấn luyện trong 40 epoch thay vì 60 cho lỗi kiểm tra hơi tệ hơn là 1.46% thay vì 1.36%.

Sau khi huấn luyện với FF, có thể phân loại một chữ số kiểm tra bằng cách thực hiện một lượt truyền tiến đơn qua mạng bắt đầu từ đầu vào bao gồm chữ số kiểm tra và một nhãn trung tính gồm mười mục của 0.1. Các hoạt động ẩn trong tất cả trừ lớp ẩn đầu tiên sau đó được sử dụng làm đầu vào cho softmax đã được học trong quá trình huấn luyện. Đây là cách nhanh nhưng không tối ưu để phân loại hình ảnh. Tốt hơn là chạy mạng với một nhãn cụ thể như một phần của đầu vào và tích lũy độ tốt của tất cả trừ lớp ẩn đầu tiên. Sau khi làm điều này cho từng nhãn riêng biệt, nhãn có độ tốt tích lũy cao nhất được chọn. Trong quá trình huấn luyện, một lượt truyền tiến từ nhãn trung tính được sử dụng để chọn các nhãn âm khó và điều này làm cho huấn luyện yêu cầu khoảng một phần ba epoch.

Chúng ta có thể tăng cường dữ liệu huấn luyện bằng cách jitter hình ảnh lên đến hai pixel theo mỗi hướng để có 25 dịch chuyển khác nhau cho mỗi hình ảnh. Điều này sử dụng kiến thức về bố cục không gian của các pixel nên nó không còn bất biến hoán vị. Nếu chúng ta huấn luyện cùng một mạng trong 500 epoch với dữ liệu tăng cường này, chúng ta có 0.64% lỗi kiểm tra tương tự như một mạng neural tích chập được huấn luyện với backpropagation. Chúng ta cũng có các trường tiếp nhận thú vị trong lớp ẩn đầu tiên như được hiển thị trong hình 2.

3.4 Sử dụng FF để mô hình hóa các hiệu ứng từ trên xuống trong nhận thức
Tất cả các ví dụ phân loại hình ảnh cho đến nay đã sử dụng các mạng neural feed-forward được học một cách tham lam từng lớp một. Điều này có nghĩa là những gì được học trong các lớp muộn hơn không thể ảnh hưởng đến những gì được học trong các lớp sớm hơn. Điều này có vẻ như một điểm yếu lớn so với backpropagation.

Chìa khóa để vượt qua hạn chế rõ ràng này của FF là coi một hình ảnh tĩnh như một video khá nhàm chán được xử lý bởi một mạng neural tái phát đa lớp (Hinton, 2021). FF chạy tiến về phía trước theo thời gian cho cả dữ liệu dương và âm, nhưng, như hình 3 cho thấy, vector hoạt động tại mỗi lớp được xác định bởi các vector hoạt động chuẩn hóa tại cả lớp trên và lớp dưới ở bước thời gian trước¹¹.

Như một kiểm tra ban đầu rằng cách tiếp cận này thực sự hoạt động, chúng ta có thể sử dụng đầu vào "video" bao gồm một hình ảnh MNIST tĩnh được lặp lại đơn giản cho mỗi khung thời gian. Lớp dưới cùng là hình ảnh pixel và lớp trên cùng là biểu diễn một trong N của lớp chữ số. Có hai hoặc ba lớp trung gian mỗi lớp có 2000 neuron. Trong một thí nghiệm sơ bộ, mạng tái phát được chạy trong 10 bước thời gian và tại mỗi bước thời gian, các lớp chẵn được cập nhật dựa trên các hoạt động chuẩn hóa trong các lớp lẻ và sau đó các lớp lẻ được cập nhật dựa trên các hoạt động chuẩn hóa mới trong các lớp chẵn. Việc cập nhật luân phiên này được thiết kế để tránh dao động hai pha, nhưng có vẻ như không cần thiết: Với một chút giảm chấn, các cập nhật đồng bộ của tất cả các lớp ẩn dựa trên các trạng thái chuẩn hóa ở bước thời gian trước thực sự học tốt hơn một chút, đây là tin tốt cho các kiến trúc ít đều đặn hơn. Vì vậy, các thí nghiệm được báo cáo ở đây sử dụng các cập nhật đồng bộ với các trạng thái tiền chuẩn hóa mới được đặt thành 0.3 của trạng thái tiền chuẩn hóa trước đó cộng với 0.7 của trạng thái mới được tính toán.

Mạng được hiển thị trong hình 3 được huấn luyện trên MNIST trong 60 epoch. Đối với mỗi hình ảnh, các lớp ẩn được khởi tạo bằng một lượt truyền từ dưới lên đơn. Sau đó mạng được chạy trong 8 lần lặp đồng bộ với giảm chấn. Hiệu suất của mạng trên dữ liệu kiểm tra được đánh giá bằng cách chạy nó trong 8 lần lặp với mỗi một trong 10 nhãn và chọn nhãn có độ tốt cao nhất được tính trung bình qua các lần lặp 3 đến 5. Nó có 1.31% lỗi kiểm tra. Dữ liệu âm được tạo ra bằng cách thực hiện một lượt truyền tiến đơn qua mạng để có xác suất cho tất cả các lớp và sau đó chọn giữa các lớp không chính xác theo tỷ lệ với xác suất của chúng. Điều này làm cho huấn luyện hiệu quả hơn nhiều.

¹⁰ Cách sử dụng FF cho học có giám sát này có một số tương tự với quy trình lan truyền lỗi tiến (Kohan et al., 2018) và quy trình lan truyền tín hiệu gần đây hơn (Kohan et al., 2022) cũng sử dụng nhãn như một đầu vào bổ sung, nhưng FF không yêu cầu các biểu diễn ẩn của nhãn và các biểu diễn ẩn của hình ảnh phải tách biệt.

¹¹ Rõ ràng là không có vấn đề gì khi thêm các kết nối bỏ qua lớp, nhưng kiến trúc đơn giản nhất là dễ hiểu nhất và mục đích của bài báo này là hiểu biết, không phải hiệu suất trên các benchmark.

--- TRANG 5 ---
[Hình 2: Các trường tiếp nhận của 100 neuron trong lớp ẩn đầu tiên của mạng được huấn luyện trên MNIST jittered. Các nhãn lớp được biểu diễn trong 10 pixel đầu tiên của mỗi hình ảnh.]

[Hình 3: Mạng tái phát được sử dụng để xử lý video.]

3.5 Sử dụng dự đoán từ ngữ cảnh không gian như một giáo viên
Trong mạng tái phát, mục tiêu là có sự thống nhất tốt giữa đầu vào từ lớp trên và đầu vào từ lớp dưới đối với dữ liệu dương và sự thống nhất kém đối với dữ liệu âm¹². Trong một mạng có kết nối cục bộ về không gian, điều này có một tính chất rất mong muốn: Đầu vào từ trên xuống sẽ được xác định bởi một vùng lớn hơn của hình ảnh và sẽ là kết quả của nhiều giai đoạn xử lý hơn nên nó có thể được xem như một dự đoán ngữ cảnh cho những gì nên được tạo ra bởi đầu vào từ dưới lên dựa trên một vùng cục bộ hơn của hình ảnh. Nếu đầu vào đang thay đổi theo thời gian, đầu vào từ trên xuống sẽ dựa trên dữ liệu đầu vào cũ hơn nên nó sẽ phải học dự đoán các biểu diễn của đầu vào từ dưới lên. Nếu chúng ta đảo dấu của hàm mục tiêu và nhắm đến hoạt động bình phương thấp đối với dữ liệu dương, đầu vào từ trên xuống nên học hủy bỏ đầu vào từ dưới lên trên dữ liệu dương, điều này trông rất giống predictive coding (Rao and Ballard, 1999; van den Oord et al., 2018). Chuẩn hóa lớp có nghĩa là nhiều thông tin được gửi đến lớp tiếp theo ngay cả khi việc hủy bỏ hoạt động khá tốt. Nếu tất cả các lỗi dự đoán đều nhỏ, chúng được phóng đại bởi việc chuẩn hóa do đó làm cho chúng chống lại nhiễu trong truyền tải hơn.

Ý tưởng học bằng cách sử dụng dự đoán ngữ cảnh như một tín hiệu dạy cho việc trích xuất đặc trưng cục bộ đã tồn tại từ lâu nhưng khó thực hiện trong các mạng neural sử dụng ngữ cảnh không gian trái ngược với ngữ cảnh thời gian một phía. Phương pháp rõ ràng của việc sử dụng sự đồng thuận của các đầu vào từ trên xuống và từ dưới lên như tín hiệu dạy cho cả trọng số từ trên xuống và từ dưới lên dẫn đến sụp đổ. Vấn đề này có thể được giảm bớt bằng cách sử dụng các dự đoán ngữ cảnh từ các hình ảnh khác để tạo ra các cặp âm, nhưng việc sử dụng dữ liệu âm thay vì bất kỳ biểu diễn nội bộ âm nào có vẻ mạnh mẽ hơn và không yêu cầu bất kỳ hạn chế nào như chỉ sử dụng quá khứ để dự đoán tương lai.

4 Thí nghiệm với CIFAR-10
CIFAR-10 (Krizhevsky and Hinton, 2009) có 50.000 hình ảnh huấn luyện là 32 x 32 với ba kênh màu cho mỗi pixel. Do đó, mỗi hình ảnh có 3072 chiều. Các hình ảnh có nền phức tạp rất thay đổi và không thể được mô hình hóa tốt với dữ liệu huấn luyện hạn chế như vậy. Một mạng được kết nối đầy đủ với hai hoặc ba lớp ẩn overfit nghiêm trọng khi được huấn luyện với backpropagation trừ khi các lớp ẩn rất nhỏ, vì vậy gần như tất cả các kết quả được báo cáo là cho các mạng tích chập.

Vì FF được dành cho các mạng mà việc chia sẻ trọng số không khả thi, nó được so sánh với một mạng backpropagation sử dụng các trường tiếp nhận cục bộ để hạn chế số lượng trọng số mà không hạn chế nghiêm trọng số lượng đơn vị ẩn. Mục đích đơn giản là chỉ ra rằng với nhiều đơn vị ẩn, FF có thể so sánh về hiệu suất với backpropagation cho các hình ảnh chứa nền rất thay đổi.

Các mạng chứa hai hoặc ba lớp ẩn của 3072 ReLU mỗi lớp. Mỗi lớp ẩn là một bản đồ địa hình 32 x 32 với 3 đơn vị ẩn tại mỗi vị trí. Mỗi đơn vị ẩn có trường tiếp nhận 11 x 11 trong lớp bên dưới nên nó có 363 đầu vào từ dưới lên¹³. Đối với FF, các đơn vị ẩn trong lớp ẩn cuối cùng có 10 đầu vào từ trên xuống và trong các lớp khác chúng có tối đa 363 đầu vào từ trên xuống từ trường tiếp nhận 11 x 11 trong lớp phía trên¹⁴.

Bảng 1 cho thấy hiệu suất kiểm tra của các mạng được huấn luyện với backpropagation và FF, với cả hai phương pháp sử dụng weight-decay để giảm overfit. Để kiểm tra một mạng được huấn luyện với FF, chúng ta có thể sử dụng một lượt truyền tiến đơn hoặc chúng ta có thể để mạng chạy trong 10 lần lặp với hình ảnh và mỗi một trong 10 nhãn và tích lũy năng lượng cho một nhãn qua các lần lặp 4 đến 6 (đó là khi lỗi dựa trên độ tốt thấp nhất). Mặc dù hiệu suất kiểm tra của FF tệ hơn backpropagation nhưng chỉ tệ hơn một chút, ngay cả khi có nền gây nhiễu phức tạp. Ngoài ra, khoảng cách giữa hai quy trình không tăng với nhiều lớp ẩn hơn. Tuy nhiên, backpropagation giảm lỗi huấn luyện nhanh hơn nhiều.

¹² Cũng có áp lực làm cho các phần khác nhau của đầu vào từ dưới lên thống nhất về việc kích hoạt neuron nào, và điều tương tự cũng áp dụng cho đầu vào từ trên xuống.

¹³ Đối với các neuron ẩn gần rìa của bản đồ, trường tiếp nhận bị cắt ngắn ở rìa của hình ảnh.

¹⁴ Một cách không hiệu quả nhưng rất đơn giản để triển khai kết nối này trên GPU là học với kết nối đầy đủ nhưng sử dụng mặt nạ được tính toán trước để đặt lại tất cả các trọng số không tồn tại về không sau mỗi lần cập nhật trọng số. Cách tiếp cận này làm cho việc khám phá bất kỳ loại kết nối nào giữa các lớp trở nên rất dễ dàng.

--- TRANG 6 ---
[Bảng 1: So sánh backpropagation và FF trên CIFAR-10 sử dụng các mạng không tích chập với trường tiếp nhận cục bộ kích thước 11x11 và 2 hoặc 3 lớp ẩn. Một phiên bản của FF được huấn luyện để tối đa hóa tổng bình phương hoạt động trên các trường hợp dương. Phiên bản khác được huấn luyện để tối thiểu hóa nó và điều này cho hiệu suất kiểm tra tốt hơn một chút. Sau khi huấn luyện với FF, một lượt truyền tiến đơn qua mạng là cách nhanh nhưng không tối ưu để phân loại hình ảnh. Tốt hơn là chạy mạng với một nhãn cụ thể như đầu vào cấp cao nhất và ghi lại độ tốt trung bình qua các lần lặp giữa. Sau khi làm điều này cho từng nhãn riêng biệt, nhãn có độ tốt cao nhất được chọn. Đối với số lượng lớn nhãn, một lượt truyền tiến đơn có thể được sử dụng để có danh sách ứng viên các nhãn nào cần đánh giá kỹ hơn.]

[Bảng hiển thị các kết quả so sánh với các cột: quy trình học, quy trình kiểm tra, số lớp ẩn, tỷ lệ lỗi huấn luyện %, tỷ lệ lỗi kiểm tra %]

5 Giấc ngủ
FF sẽ dễ triển khai hơn nhiều trong não nếu dữ liệu dương được xử lý khi thức và dữ liệu âm được tạo ra bởi chính mạng và được xử lý trong giấc ngủ.

Trong bản thảo sớm của bài báo này, tôi đã báo cáo rằng có thể thực hiện nhiều cập nhật trên dữ liệu dương theo sau bởi nhiều cập nhật trên dữ liệu âm, được tạo ra bởi chính mạng, với rất ít mất hiệu suất. Ví dụ tôi sử dụng là dự đoán ký tự tiếp theo trong một chuỗi từ cửa sổ mười ký tự trước đó. Việc sử dụng các ký hiệu rời rạc thay vì hình ảnh có giá trị thực làm cho việc tạo ra chuỗi từ mô hình dễ dàng hơn. Tôi đã không thể tái tạo kết quả này và tôi bây giờ nghi ngờ nó do một lỗi. Sử dụng tổng bình phương hoạt động làm hàm độ tốt, luân phiên giữa hàng nghìn cập nhật trọng số trên dữ liệu dương và hàng nghìn trên dữ liệu âm chỉ hoạt động nếu tốc độ học rất thấp và động lượng cực kỳ cao. Có thể một hàm độ tốt khác sẽ cho phép các pha học dương và âm được tách biệt, nhưng điều này vẫn chưa được chỉ ra và đây có lẽ là câu hỏi nổi bật quan trọng nhất về FF như một mô hình sinh học.

Nếu có thể tách biệt các pha dương và âm, sẽ thú vị khi xem việc loại bỏ các cập nhật pha âm trong một thời gian có dẫn đến các hiệu ứng bắt chước các hiệu ứng tàn phá của việc thiếu ngủ nghiêm trọng không.

6 FF liên quan như thế nào đến các kỹ thuật học contrastive khác

6.1 Mối quan hệ với Boltzmann Machines
Trong đầu những năm 1980, có hai quy trình học hứa hẹn cho các mạng neural sâu. Một là backpropagation và cái kia là Boltzmann Machines (Hinton and Sejnowski, 1986) thực hiện học contrastive không giám sát. Một Boltzmann Machine là một mạng các neuron nhị phân ngẫu nhiên với các kết nối cặp có cùng trọng số theo cả hai hướng. Khi nó chạy tự do mà không có đầu vào bên ngoài, một Boltzmann machine liên tục cập nhật mỗi neuron nhị phân bằng cách đặt nó ở trạng thái bật với xác suất bằng logistic của tổng đầu vào nó nhận được từ các neuron hoạt động khác. Quy trình cập nhật đơn giản này cuối cùng lấy mẫu từ phân phối cân bằng trong đó mỗi cấu hình toàn cục (một phép gán trạng thái nhị phân cho tất cả các neuron) có log xác suất tỷ lệ với năng lượng âm của nó. Năng lượng âm đơn giản là tổng các trọng số giữa tất cả các cặp neuron đang bật trong cấu hình đó.

Một tập con các neuron trong Boltzmann Machine là "có thể nhìn thấy" và các vector dữ liệu nhị phân được trình bày cho mạng bằng cách kẹp chúng trên các neuron có thể nhìn thấy và sau đó để nó liên tục cập nhật trạng thái của các neuron còn lại, ẩn. Mục đích của việc học Boltzmann machine là làm cho phân phối các vector nhị phân trên các neuron có thể nhìn thấy khi mạng chạy tự do khớp với phân phối dữ liệu. Rất bất ngờ, phân kỳ Kullback-Liebler giữa phân phối dữ liệu và phân phối mô hình được thể hiện trên các neuron có thể nhìn thấy bởi Boltzmann machine chạy tự do ở cân bằng nhiệt có đạo hàm rất đơn giản đối với bất kỳ trọng số wij nào trong mạng:

∂KL(Pdata||Pmodel)/∂wij = ⟨sisj⟩data - ⟨sisj⟩model        (2)

trong đó dấu ngoặc góc biểu thị kỳ vọng trên các dao động ngẫu nhiên ở cân bằng nhiệt và cũng là dữ liệu cho số hạng đầu tiên.

Điều thú vị về kết quả này là nó cho đạo hàm cho các trọng số sâu bên trong mạng mà không bao giờ lan truyền đạo hàm lỗi một cách rõ ràng. Thay vào đó, nó lan truyền hoạt động neural trong hai pha khác nhau được dự định tương ứng với thức và ngủ. Thật không may, sự đơn giản toán học của quy tắc học đi kèm với một cái giá rất cao. Nó yêu cầu một Boltzmann Machine sâu tiếp cận phân phối cân bằng của nó và điều này làm cho nó không thực tế như một kỹ thuật machine learning và không hợp lý như một mô hình học vỏ não: Không có thời gian để một mạng lớn tiếp cận phân phối cân bằng của nó trong quá trình nhận thức. Cũng không có bằng chứng cho tính đối xứng chi tiết của các kết nối trong vỏ não và không có cách rõ ràng nào để học chuỗi. Hơn nữa, quy trình học Boltzmann machine thất bại nếu nhiều cập nhật dương của trọng số theo sau bởi nhiều cập nhật âm như sẽ được yêu cầu nếu pha âm tương ứng với giấc ngủ REM (Crick and Mitchison, 1983)¹⁵. Mặc dù có những phản đối không thể vượt qua này, việc học Boltzmann Machine vẫn thú vị về mặt trí tuệ vì nó thay thế các lượt truyền tiến và ngược của backpropagation bằng hai quá trình ổn định lặp hoạt động theo cách chính xác giống nhau, nhưng với các điều kiện biên khác nhau trên các neuron có thể nhìn thấy - kẹp vào dữ liệu so với tự do.

Boltzmann machine có thể được xem như sự kết hợp của hai ý tưởng:
1. Học bằng cách tối thiểu hóa năng lượng tự do trên dữ liệu thật và tối đa hóa năng lượng tự do trên dữ liệu âm được tạo ra bởi chính mạng.
2. Sử dụng năng lượng Hopfield làm hàm năng lượng và sử dụng các cập nhật ngẫu nhiên lặp để lấy mẫu các cấu hình toàn cục từ phân phối Boltzmann được định nghĩa bởi hàm năng lượng.

Nhìn lại, rõ ràng là ý tưởng đầu tiên, về contrastive learning, có thể được sử dụng với nhiều hàm năng lượng khác. Ví dụ, (Hinton et al., 2006a) sử dụng đầu ra của một mạng neural feedforward để định nghĩa năng lượng và sau đó sử dụng backpropagation qua mạng này để tính toán đạo hàm của năng lượng đối với cả trọng số và trạng thái có thể nhìn thấy. Dữ liệu âm sau đó được tạo ra bằng cách theo đạo hàm của năng lượng đối với trạng thái có thể nhìn thấy. Cách tiếp cận này được sử dụng rất hiệu quả trong (Grathwohl et al., 2019). Cũng rõ ràng là dữ liệu âm không phải được tạo ra bằng cách lấy mẫu vector dữ liệu từ phân phối Boltzmann được định nghĩa bởi hàm năng lượng. Các phương pháp như contrastive divergence (Hinton, 2002), ví dụ, cải thiện đáng kể hiệu quả học trong Boltzmann machines với một lớp ẩn đơn bằng cách không lấy mẫu từ phân phối cân bằng.

Nhưng sự đơn giản toán học của phương trình 2 và thực tế rằng quy trình cập nhật ngẫu nhiên thực hiện tích phân Bayesian chính xác trên tất cả các cấu hình ẩn có thể quá đẹp để từ bỏ, vì vậy ý tưởng thay thế các lượt truyền tiến và ngược của backpropagation bằng hai quá trình ổn định chỉ cần lan truyền hoạt động neural vẫn bị rối với sự phức tạp của Markov Chain Monte Carlo.

FF kết hợp contrastive learning từ Boltzmann machines với một hàm độ tốt đơn giản, cục bộ dễ xử lý hơn nhiều so với năng lượng tự do của một mạng các neuron ngẫu nhiên nhị phân.

6.2 Mối quan hệ với Generative Adversarial Networks
Một GAN (Goodfellow et al., 2014) sử dụng một mạng neural đa lớp để tạo ra dữ liệu và nó huấn luyện mô hình tạo sinh của mình bằng cách sử dụng một mạng phân biệt đa lớp để cung cấp cho nó các đạo hàm đối với đầu ra của mô hình tạo sinh về xác suất đầu ra là dữ liệu thật trái ngược với dữ liệu được tạo ra. GAN khó huấn luyện vì các mô hình phân biệt và tạo sinh đang cạnh tranh. Trong thực tế, chúng tạo ra hình ảnh rất đẹp nhưng gặp phải sự sụp đổ mode: Có thể có những vùng lớn của không gian hình ảnh mà chúng không bao giờ tạo ra ví dụ. Ngoài ra, chúng sử dụng backpropagation để thích ứng mỗi mạng nên khó thấy cách triển khai chúng trong vỏ não.

FF có thể được xem như một trường hợp đặc biệt của GAN trong đó mọi lớp ẩn của mạng phân biệt đưa ra quyết định tham lam riêng của nó về việc đầu vào là dương hay âm nên không cần backpropagate để học mô hình phân biệt. Cũng không cần backpropagate để học mô hình tạo sinh vì thay vì học các biểu diễn ẩn riêng của nó, nó chỉ tái sử dụng các biểu diễn được học bởi mô hình phân biệt¹⁶. Điều duy nhất mà mô hình tạo sinh phải học là cách chuyển đổi các biểu diễn ẩn đó thành dữ liệu được tạo ra và nếu điều này được thực hiện bằng cách sử dụng phép chuyển đổi tuyến tính để tính toán logit của softmax thì không cần backpropagation. Một ưu điểm của việc sử dụng cùng các biểu diễn ẩn cho cả hai mô hình là nó loại bỏ các vấn đề phát sinh khi một mô hình học quá nhanh so với mô hình kia. Nó cũng loại bỏ sự sụp đổ mode.

6.3 Mối quan hệ với các phương pháp contrastive so sánh biểu diễn của hai crop hình ảnh khác nhau
Có một họ các phương pháp contrastive tự giám sát như SimCLR (Wu et al., 2018; Chen et al., 2020a; Bachman et al., 2019; He et al., 2020; Grill et al., 2020; Chen et al., 2020b) học bằng cách tối ưu hóa một hàm mục tiêu ưu tiên sự thống nhất giữa các biểu diễn của hai crop khác nhau từ cùng một hình ảnh và sự bất đồng giữa các biểu diễn của các crop từ hai hình ảnh khác nhau. Các phương pháp này thường sử dụng nhiều lớp để trích xuất các biểu diễn của các crop và chúng huấn luyện các lớp này bằng cách backpropagate đạo hàm của hàm mục tiêu. Chúng không hoạt động nếu hai crop luôn chồng lấp theo cách chính xác giống nhau vì khi đó chúng có thể đơn giản báo cáo cường độ của các pixel chia sẻ và có được sự thống nhất hoàn hảo.

Trong một mạng neural thực, việc đo sự thống nhất giữa hai biểu diễn khác nhau sẽ không tầm thường¹⁷ và không có cách rõ ràng nào để trích xuất các biểu diễn của hai crop cùng lúc sử dụng cùng trọng số.

FF sử dụng một cách khác để đo sự thống nhất, có vẻ dễ dàng hơn cho một mạng neural thực. Nhiều nguồn thông tin khác nhau cung cấp đầu vào cho cùng một tập hợp neuron. Nếu các nguồn thống nhất về việc kích hoạt neuron nào sẽ có nhiễu xạ dương dẫn đến hoạt động bình phương cao và nếu chúng bất đồng thì hoạt động bình phương sẽ thấp hơn¹⁸. Đo sự thống nhất bằng cách sử dụng nhiễu xạ dương linh hoạt hơn nhiều so với việc so sánh hai vector biểu diễn khác nhau vì không cần chia đầu vào thành hai nguồn riêng biệt một cách tùy ý.

Một điểm yếu lớn của các phương pháp giống SimCLR là nhiều phép tính được sử dụng để suy ra các biểu diễn của hai crop hình ảnh, nhưng hàm mục tiêu chỉ cung cấp một lượng hạn chế ràng buộc trên các biểu diễn và điều này hạn chế tốc độ mà thông tin về domain có thể được tiêm vào trọng số. Để làm cho biểu diễn của một crop gần với mate chính xác của nó hơn so với một triệu lựa chọn thay thế có thể chỉ cần 20 bit thông tin. Vấn đề này có vẻ còn tệ hơn đối với FF vì nó chỉ cần một bit để phân biệt trường hợp dương từ trường hợp âm.

Giải pháp cho sự nghèo nàn ràng buộc này là chia mỗi lớp thành nhiều khối nhỏ và buộc mỗi khối riêng biệt sử dụng độ dài của vector hoạt động tiền chuẩn hóa của nó để quyết định giữa các trường hợp dương và âm. Thông tin cần thiết để thỏa mãn các ràng buộc sau đó tỷ lệ tuyến tính với số lượng khối, tốt hơn nhiều so với tỷ lệ logarithmic đạt được bằng cách sử dụng tập hợp tương phản lớn hơn trong các phương pháp giống SimCLR. Một ví dụ về cách tiếp cận này sử dụng các khối được bản địa hóa không gian có thể được tìm thấy trong Löwe et al. (2019).

6.4 Một vấn đề với contrastive learning xếp chồng
Một cách không giám sát rõ ràng để học nhiều lớp biểu diễn là đầu tiên học một lớp ẩn nắm bắt một số cấu trúc trong dữ liệu và sau đó coi các vector hoạt động trong lớp này như dữ liệu và áp dụng cùng thuật toán học không giám sát một lần nữa. Đây là cách nhiều lớp biểu diễn được học sử dụng Restricted Boltzmann machines (RBMs) (Hinton et al., 2006b) hoặc stacked autoencoder (Bengio et al., 2007). Nhưng nó có một lỗ hổng chết người.

Giả sử chúng ta ánh xạ một số hình ảnh nhiễu ngẫu nhiên qua một ma trận trọng số ngẫu nhiên. Các vector hoạt động kết quả sẽ có cấu trúc tương quan được tạo ra bởi ma trận trọng số và không liên quan gì đến dữ liệu. Khi học không giám sát được áp dụng cho các vector hoạt động này, nó sẽ khám phá một số cấu trúc này, nhưng điều đó không nói cho hệ thống biết gì về thế giới bên ngoài¹⁹.

Thuật toán học Boltzmann Machine ban đầu được thiết kế để tránh lỗ hổng này (Hinton and Sejnowski, 1986) (trang 297) bằng cách tương phản thống kê do hai điều kiện biên bên ngoài khác nhau gây ra. Điều này hủy bỏ tất cả cấu trúc chỉ là kết quả của các phần khác của mạng. Khi tương phản dữ liệu dương và âm, không cần hạn chế dây nối hoặc có mối quan hệ không gian ngẫu nhiên giữa các crop để ngăn mạng gian lận. Điều này làm cho việc có một số lượng lớn các nhóm neuron kết nối với nhau trở nên dễ dàng, mỗi nhóm có mục tiêu riêng của nó là phân biệt dữ liệu dương từ dữ liệu âm.

¹⁵ Sự cần thiết xen kẽ các cập nhật dương và âm trên quy mô thời gian tinh có thể được giảm bớt một phần bằng cách lưu trữ trung bình của ⟨sisj⟩model trong giấc ngủ và trừ baseline này từ các cập nhật dương trong lúc thức, nhưng thủ thuật này thất bại ngay khi các cập nhật trọng số làm cho baseline được lưu trữ sai đáng kể. Thủ thuật hoạt động tốt hơn đáng kể đối với FF vì, không giống như Boltzmann machine, các cập nhật trong pha dương ngừng thay đổi trọng số một khi các lớp phân loại chính xác một ví dụ là dương.

¹⁶ Một thủ thuật tương tự đã được sử dụng để chia sẻ cây (Nock and Guillame-Bert, 2022).

¹⁷ Một ngoại lệ rõ ràng là khi hai biểu diễn xuất hiện tại các thời điểm liền kề trên cùng một tập hợp neuron. Đạo hàm thời gian của hoạt động neural sau đó biểu thị mức độ bất đồng.

¹⁸ Có thể đo sự thống nhất sắc nét hơn nhiều nếu các đầu vào là spike đến vào những thời điểm cụ thể và các neuron sau synapse chỉ bắn nếu chúng nhận được nhiều spike trong một cửa sổ thời gian nhỏ.

¹⁹ Stacked RBM có thể xử lý vấn đề này, mặc dù không tốt lắm, bằng cách khởi tạo mỗi RBM có chuyển vị của trọng số của RBM trước đó. Điều này có nghĩa là trọng số ban đầu đã nắm bắt cấu trúc do ma trận trọng số trước đó tạo ra và những thay đổi đối với những trọng số ban đầu đó có thể nắm bắt cấu trúc do thế giới bên ngoài, nhưng nhiều khả năng được sử dụng chỉ để mô hình hóa ma trận trọng số trước đó.

7 Học nhanh và chậm
Nếu có kết nối đầy đủ giữa các lớp, có thể chỉ ra rằng các cập nhật trọng số được sử dụng để thay đổi hàm độ tốt của một lớp cho một vector đầu vào cụ thể x không có tác động đến đầu ra chuẩn hóa lớp của lớp đó khi vector đầu vào là x. Vector gia số của trọng số đến cho neuron ẩn j được cho bởi:

Δwj = 2η ∂log(p)/∂∑jyj² yj x                    (3)

trong đó yj là hoạt động của ReLU trước chuẩn hóa lớp, wj là vector trọng số đến của neuron j và η là tốc độ học.

Sau khi cập nhật trọng số đã xảy ra, thay đổi trong hoạt động của neuron j đơn giản là tích vô hướng Δwj · x. Số hạng duy nhất phụ thuộc vào j trong thay đổi hoạt động do cập nhật trọng số gây ra là yj, vì vậy tất cả hoạt động ẩn thay đổi cùng tỷ lệ và cập nhật trọng số không thay đổi hướng của vector hoạt động.

Thực tế rằng cập nhật trọng số không thay đổi đầu ra chuẩn hóa lớp cho vector đầu vào đó có nghĩa là có thể thực hiện cập nhật trọng số trực tuyến đồng thời trong nhiều lớp khác nhau vì các cập nhật trọng số trong các lớp sớm hơn không thay đổi vector hoạt động trong các lớp muộn hơn cho vector đầu vào đó. Có thể thay đổi tất cả trọng số trong một bước để mọi lớp chính xác đạt được độ tốt mong muốn S cho vector đầu vào x. Giả sử vector đầu vào và tất cả các vector ẩn chuẩn hóa lớp có độ dài 1, tốc độ học đạt được điều này được cho bởi:

η = √(S/(SL-1))                    (4)

trong đó SL là tổng bình phương hoạt động hiện tại của lớp L trước chuẩn hóa lớp.

Hiện tại, chúng ta không khai thác tính chất thú vị này của FF vì chúng ta vẫn sử dụng mini-batch, nhưng khả năng của một mạng neural sâu hấp thụ nhiều thông tin từ một trường hợp huấn luyện đơn bằng cách nhảy đến một tập hợp trọng số xử lý trường hợp đó một cách hoàn hảo có thể gây quan tâm cho các nhà tâm lý học mệt mỏi với việc bò dần xuống gradient²⁰.

Không giống như backpropagation, FF không có vấn đề gì trong việc học nếu chúng ta chèn một hộp đen giữa các lớp được huấn luyện bởi FF. Hộp đen áp dụng một phép chuyển đổi không xác định và có thể ngẫu nhiên đối với đầu ra của một lớp và trình bày vector hoạt động được chuyển đổi này như đầu vào cho lớp tiếp theo. Một khả năng thú vị là làm cho các hộp đen này là các mạng neural với một vài lớp ẩn. Nếu các lớp ẩn này học rất chậm, việc học FF "vòng lặp ngoài" có thể nhanh chóng thích ứng với dữ liệu mới dưới giả định rằng các hộp đen là cố định. Học chậm trong các hộp đen sau đó có thể cải thiện hệ thống trong thời gian dài hơn nhiều. Ví dụ, một quy trình reinforcement learning chậm có thể thêm vector nhiễu ngẫu nhiên nhỏ vào đầu vào của các neuron bên trong hộp đen và sau đó nhân các vector nhiễu hoạt động này với thay đổi trong hàm chi phí được sử dụng bởi pha dương của FF để có được ước tính nhiễu nhưng không thiên lệch của đạo hàm của hàm chi phí FF đối với hoạt động của các neuron bên trong hộp đen (Ren et al., 2022).

8 Sự liên quan của FF đến phần cứng analog
Một cách tiết kiệm năng lượng để nhân một vector hoạt động với một ma trận trọng số là triển khai hoạt động như điện áp và trọng số như điện dẫn. Tích của chúng, trên một đơn vị thời gian, là các điện tích tự cộng. Điều này có vẻ hợp lý hơn nhiều so với điều khiển transistor ở công suất cao để mô hình hóa các bit riêng lẻ trong biểu diễn kỹ thuật số của một số và sau đó thực hiện O(n²) phép toán một bit để nhân hai số n-bit với nhau. Thật không may, rất khó triển khai quy trình backpropagation theo cách hiệu quả tương đương, vì vậy mọi người đã sử dụng bộ chuyển đổi A-to-D và tính toán kỹ thuật số để tính toán gradient (Kendall et al., 2020). Việc sử dụng hai lượt truyền tiến thay vì một lượt truyền tiến và một lượt truyền ngược sẽ làm cho các bộ chuyển đổi A-to-D này không cần thiết.

9 Tính toán Có thể chết
Máy tính kỹ thuật số đa năng được thiết kế để tuân theo chỉ dẫn một cách trung thực vì người ta cho rằng cách duy nhất để có được một máy tính đa năng thực hiện một nhiệm vụ cụ thể là viết một chương trình chỉ định chính xác phải làm gì một cách chi tiết đau đớn. Điều này không còn đúng nữa, nhưng cộng đồng nghiên cứu đã chậm hiểu những hàm ý dài hạn của deep learning đối với cách máy tính được xây dựng. Cụ thể hơn, cộng đồng đã bám víu vào ý tưởng rằng phần mềm nên có thể tách rời khỏi phần cứng để cùng một chương trình hoặc cùng một tập hợp trọng số có thể được chạy trên một bản sao vật lý khác của phần cứng. Điều này làm cho kiến thức chứa trong chương trình hoặc trọng số trở nên bất tử: Kiến thức không chết khi phần cứng chết²¹.

Việc tách biệt phần mềm khỏi phần cứng là một trong những nền tảng của Khoa học Máy tính và nó có nhiều lợi ích. Nó làm cho việc nghiên cứu tính chất của chương trình mà không cần lo lắng về kỹ thuật điện trở nên có thể. Nó làm cho việc viết một chương trình một lần và sao chép nó đến hàng triệu máy tính trở nên có thể. Nó làm cho việc tính toán đạo hàm trên các tập dữ liệu khổng lồ bằng cách sử dụng nhiều bản sao của cùng một mô hình chạy song song trở nên có thể. Tuy nhiên, nếu chúng ta sẵn sàng từ bỏ tính bất tử, sẽ có thể đạt được những tiết kiệm khổng lồ về năng lượng cần thiết để thực hiện một phép tính và chi phí chế tạo phần cứng thực hiện phép tính. Chúng ta có thể cho phép những biến đổi lớn và không xác định trong kết nối và phi tuyến của các thể hiện phần cứng khác nhau được dự định thực hiện cùng một nhiệm vụ và sau đó dựa vào một quy trình học để khám phá các giá trị tham số làm cho việc sử dụng hiệu quả các tính chất không xác định của mỗi thể hiện phần cứng cụ thể. Các giá trị tham số này chỉ hữu ích cho thể hiện phần cứng cụ thể đó, vì vậy phép tính mà chúng thực hiện là có thể chết: nó chết cùng với phần cứng.

Mặc dù việc sao chép các giá trị tham số đến một phần phần cứng khác hoạt động khác nhau không có ý nghĩa, có một cách sinh học hơn để chuyển những gì đã được học bởi một phần phần cứng đến một phần phần cứng khác. Đối với một nhiệm vụ như phân loại đối tượng trong hình ảnh, những gì chúng ta thực sự quan tâm là hàm liên hệ cường độ pixel với nhãn lớp, không phải các giá trị tham số triển khai hàm đó trong một phần phần cứng cụ thể. Bản thân hàm có thể được chuyển (xấp xỉ) đến một phần phần cứng khác bằng cách sử dụng distillation (Hinton et al., 2014): Phần cứng mới được huấn luyện không chỉ để đưa ra cùng câu trả lời như phần cứng cũ mà còn để đưa ra cùng xác suất cho các câu trả lời không chính xác. Các xác suất này là một chỉ dẫn phong phú hơn nhiều về cách mô hình cũ tổng quát hóa so với chỉ nhãn mà nó nghĩ là có khả năng nhất. Vì vậy, bằng cách huấn luyện mô hình mới để khớp với xác suất của các câu trả lời không chính xác, chúng ta đang huấn luyện nó để tổng quát hóa theo cùng cách như mô hình cũ. Đây là một ví dụ hiếm hoi về việc huấn luyện mạng neural thực sự tối ưu hóa những gì chúng ta quan tâm: tổng quát hóa.

Distillation hoạt động tốt nhất khi giáo viên đưa ra đầu ra có nhiều thông tin tiết lộ nhiều về các biểu diễn nội bộ của giáo viên. Đây có thể là một trong những chức năng chính của ngôn ngữ. Thay vì xem một câu mô tả như một phần kiến thức tượng trưng cần được lưu trữ trong một ngôn ngữ nội bộ không mơ hồ nào đó, chúng ta có thể xem nó như một cách cung cấp thông tin về các biểu diễn vector nội bộ của người nói cho phép người nghe học các biểu diễn vector tương tự (Raghu et al., 2020). Từ góc độ này, một tweet thực tế không chính xác vẫn có thể là một cách rất hiệu quả để chuyển các đặc trưng được sử dụng để diễn giải thế giới đến một tập hợp người theo dõi có trực giác tức thì giống như của giáo viên. Nếu ngôn ngữ đã tiến hóa để tạo điều kiện cho việc học các vector biểu diễn nội bộ bởi các thành viên của một nền văn hóa, không có gì đáng ngạc nhiên khi huấn luyện một mạng neural lớn trên lượng lớn ngôn ngữ là một cách hiệu quả như vậy để nắm bắt thế giới quan của nền văn hóa đó.

Nếu bạn muốn mạng neural nghìn tỷ tham số của mình chỉ tiêu thụ vài watt, tính toán có thể chết có thể là lựa chọn duy nhất. Tính khả thi của nó dựa trên việc tìm một quy trình học có thể chạy hiệu quả trong phần cứng có chi tiết chính xác không xác định, và thuật toán Forward-Forward là một ứng viên hứa hẹn, mặc dù vẫn còn phải xem nó mở rộng tốt như thế nào đến các mạng neural lớn.

Tuy nhiên, nếu bạn sẵn sàng trả chi phí năng lượng cần thiết để chạy các mô hình giống hệt nhau trên nhiều bản sao của cùng phần cứng, khả năng chia sẻ trọng số trên các mô hình lớn cung cấp một cách băng thông cao hơn nhiều để chia sẻ kiến thức so với distillation và có thể đưa trí thông minh lên cấp độ tiếp theo.

²⁰ Quy trình hội tụ perceptron (Rosenblatt, 1958) cũng có tính chất là có thể thực hiện cập nhật lớn đối với trọng số mà không sử dụng tốc độ học. Đối với perceptron, bất kỳ tập hợp trọng số nào trong vùng "khả thi" của không gian trọng số sẽ cho phân loại nhị phân chính xác cho tất cả các ví dụ huấn luyện. Đáng buồn, không có vùng khả thi nếu các ví dụ dương và âm không tách được tuyến tính. Cho một ví dụ huấn luyện hiện đang bị phân loại sai, trọng số có thể được cập nhật trong một bước để làm cho việc phân loại chính xác cho ví dụ đó. Cập nhật trọng số vuông góc với siêu phẳng tách trọng số tốt khỏi trọng số xấu cho ví dụ cụ thể đó và kích thước bước có thể được chọn để di chuyển trọng số đến phía chính xác của siêu phẳng đó. Cập nhật có thể khiến nhiều ví dụ khác bị phân loại sai, nhưng quy trình hội tụ perceptron không hội tụ bằng cách giảm số lỗi hoặc tổng lỗi bình phương. Nó hoạt động bằng cách luôn tiến gần hơn đến vùng khả thi. Các mạng neural đa lớp được huấn luyện với backpropagation không phải là perceptron đa lớp.

²¹ Giả sử chương trình hoặc trọng số được lưu trữ trung thực trong một số phương tiện nào đó.

10 Công việc tương lai
Việc nghiên cứu thuật toán Forward-Forward mới chỉ bắt đầu và có nhiều câu hỏi mở:

• FF có thể tạo ra một mô hình tạo sinh hình ảnh hoặc video đủ tốt để tạo ra dữ liệu âm cần thiết cho học không giám sát không?

• Hàm độ tốt tốt nhất để sử dụng là gì? Bài báo này sử dụng tổng bình phương hoạt động trong hầu hết các thí nghiệm nhưng tối thiểu hóa tổng bình phương hoạt động cho dữ liệu dương và tối đa hóa nó cho dữ liệu âm có vẻ hoạt động tốt hơn một chút. Gần đây hơn, chỉ tối thiểu hóa tổng các hoạt động không bình phương trên dữ liệu dương (và tối đa hóa trên dữ liệu âm) đã hoạt động tốt²².

• Hàm kích hoạt tốt nhất để sử dụng là gì? Cho đến nay, chỉ có ReLU được khám phá. Có nhiều khả năng khác mà hành vi chưa được khám phá trong ngữ cảnh của FF. Việc làm cho kích hoạt là log âm của mật độ dưới phân phối t là một khả năng thú vị (Osindero et al., 2006).

• Đối với dữ liệu không gian, FF có thể hưởng lợi từ việc có nhiều hàm độ tốt cục bộ cho các vùng khác nhau của hình ảnh không (Löwe et al., 2019)? Nếu điều này có thể được thực hiện, nó sẽ cho phép học nhanh hơn nhiều.

• Đối với dữ liệu tuần tự, có thể sử dụng fast weights để bắt chước một transformer đơn giản hóa không (Ba et al., 2016a)?

• FF có thể hưởng lợi từ việc có một tập hợp detector đặc trưng cố gắng tối đa hóa hoạt động bình phương của chúng và một tập hợp detector vi phạm ràng buộc cố gắng tối thiểu hóa hoạt động bình phương của chúng không (Welling et al., 2003)?

11 Lời cảm ơn
Đầu tiên tôi muốn cảm ơn Jeff Dean và David Fleet vì đã tạo ra môi trường tại Google làm cho nghiên cứu này có thể. Nhiều người đã đóng góp hữu ích bao gồm, không theo thứ tự cụ thể, Simon Kornblith, Mengye Ren, Renjie Liao, David Fleet, Ilya Sutskever, Terry Sejnowski, Peter Dayan, Chris Williams, Yair Weiss, Relu Patrascu và Max Welling.

Tài liệu tham khảo
Ba, J., Hinton, G. E., Mnih, V., Leibo, J. Z., and Ionescu, C. (2016a). Using fast weights to attend to the recent past. Advances in neural information processing systems, 29.

Ba, J. L., Kiros, J. R., and Hinton, G. E. (2016b). Layer normalization. arXiv preprint arXiv:1607.06450.

Bachman, P., Hjelm, R. D., and Buchwalter, W. (2019). Learning representations by maximizing mutual information across views. In Wallach, H., Larochelle, H., Beygelzimer, A., Fox, E., and Garnett, R., editors, Advances in Neural Information Processing Systems, volume 32, pages 15535–15545. Curran Associates, Inc.

Bengio, Y., Lamblin, P., Popovici, D., and Larochelle, H. (2007). Greedy layer-wise training of deep networks. In NIPS'2006.

²² Khi sử dụng các hoạt động không bình phương, chuẩn hóa lớp phải chuẩn hóa tổng các hoạt động, không phải tổng bình phương của chúng.

Carandini, M. and Heeger, D. J. (2013). Normalization as a canonical neural computation. Nature Reviews Neuroscience, 13(1):51–62.

Chen, T., Kornblith, S., Norouzi, M., and Hinton, G. (2020a). A simple framework for contrastive learning of visual representations. In Proceedings of the 37th International Conference on Machine Learning, pages 1597–1607.

Chen, T., Kornblith, S., Swersky, K., Norouzi, M., and Hinton, G. (2020b). Big self-supervised models are strong semi-supervised learners. arXiv:2006.10029.

Crick, F. and Mitchison, G. (1983). The function of dream sleep. Nature, 304:111–114.

Dayan, P. and Hinton, G. E. (1992). Feudal reinforcement learning. Advances in neural information processing systems, 5.

Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., and Bengio, Y. (2014). Generative adversarial nets. In Advances in neural information processing systems, pages 2672–2680.

Grathwohl, W., Wang, K.-C., Jacobsen, J.-H., Duvenaud, D., Norouzi, M., and Swersky, K. (2019). Your classifier is secretly an energy based model and you should treat it like one. arXiv preprint arXiv:1912.03263.

Grill, J.-B., Strub, F., Altché, F., Tallec, C., Richemond, P. H., Buchatskaya, E., Doersch, C., Pires, B. A., Guo, Z. D., Azar, M. G., Piot, B., Kavukcuoglu, K., Munos, R., and Valko, M. (2020). Bootstrap your own latent: A new approach to self-supervised learning. arXiv:2006.07733.

Guerguiev, J., Lillicrap, T. P., and Richards, B. A. (2017). Towards deep learning with segregated dendrites. ELife, 6:e22901.

Gutmann, M. and Hyvärinen, A. (2010). Noise-contrastive estimation: A new estimation principle for unnormalized statistical models. In Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics, pages 297–304.

He, K., Fan, H., Wu, Y., Xie, S., and Girshick, R. (2020). Momentum contrast for unsupervised visual representation learning. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR).

Hinton, G. (2021). How to represent part-whole hierarchies in a neural network. arXiv preprint arXiv:2102.12627.

Hinton, G., Osindero, S., Welling, M., and Teh, Y.-W. (2006a). Unsupervised discovery of nonlinear structure using contrastive backpropagation. Cognitive science, 30(4):725–731.

Hinton, G. and Sejnowski, T. (1986). Learning and relearning in Boltzmann machines. In Rumelhart, D. E. and McClelland, J. L., editors, Parallel Distributed Processing: Explorations in the Microstructure of Cognition. Volume 1: Foundations, pages 282–317. MIT Press, Cambridge, MA.

Hinton, G., Vinyals, O., and Dean, J. (2014). Distilling the knowledge in a neural network. In NIPS 2014 Deep Learning Workshop.

Hinton, G. E. (2002). Training products of experts by minimizing contrastive divergence. Neural Computation, 14(8):1771–1800.

Hinton, G. E., Osindero, S., and Teh, Y.-W. (2006b). A fast learning algorithm for deep belief nets. Neural Computation, 18:1527–1554.

Jabri, M. and Flower, B. (1992). Weight perturbation: An optimal architecture and learning technique for analog vlsi feedforward and recurrent multilayer networks. IEEE Transactions on Neural Networks, 3(1):154–157.

Kendall, J., Pantone, R., Manickavasagam, K., Bengio, Y., and Scellier, B. (2020). Training end-to-end analog neural networks with equilibrium propagation. arXiv preprint arXiv:2006.01981.

Kohan, A. A., Rietman, E. A., and Siegelmann, H. T. (2018). Error forward-propagation: Reusing feedforward connections to propagate errors in deep learning. arXiv preprint arXiv:1808.03357.

Kohan, A. A., Rietman, E. A., and Siegelmann, H. T. (2022). Signal propagation: A framework for learning and inference in a forward pass. arXiv preprint arXiv:2204.01723.

Krizhevsky, A. and Hinton, G. (2009). Learning multiple layers of features from tiny images.

Lillicrap, T., Cownden, D. and Tweed, D., and Akerman, C. (2016). synaptic feedback weights support error backpropagation for deep learning. Nature Communications, 7.

Lillicrap, T., Santoro, A., Marris, L., Akerman, C., and Hinton, G. E. (2020). Backpropagation and the brain. Nature Reviews Neuroscience, 21:335–346.

Löwe, S., O'Connor, P., and Veeling, B. (2019). Putting an end to end-to-end: Gradient-isolated learning of representations. Advances in neural information processing systems, 32.

Nock, R. and Guillame-Bert, M. (2022). Generative trees: Adversarial and copycat. arXiv preprint arXiv:2201.11205v2.

Osindero, S., Welling, M., and Hinton, G. E. (2006). Topographic product models applied to natural scene statistics. Neural Computation, 18(2):381–414.

Pereyra, G., Tucker, G., Chorowski, J., Kaiser, Ł., and Hinton, G. (2017). Regularizing neural networks by penalizing confident output distributions. arXiv preprint arXiv:1701.06548.

Raghu, A., Raghu, M., Kornblith, S., Duvenaud, D., and Hinton, G. (2020). Teaching with commentaries. arXiv preprint arXiv:2011.03037.

Rao, R. and Ballard, D. (1999). Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive-field effects. Nature Neuroscience, 2:79–87.

Ren, M., Kornblith, S., Liao, R., and Hinton, G. (2022). Scaling forward gradient with local losses. arXiv preprint arXiv:2210.03310.

Richards, B. A. and Lillicrap, T. P. (2019). Dendritic solutions to the credit assignment problem. Current opinion in neurobiology, 54:28–36.

Rosenblatt, F. (1958). The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review, 65(6):386.

Rumelhart, D. E., Hinton, G. E., and Williams, R. J. (1986). Learning representations by back-propagating errors. Nature, 323:533–536.

Scellier, B. and Bengio, Y. (2017). Equilibrium propagation: Bridging the gap between energy-based models and backpropagation. Frontiers in computational neuroscience, 11:24.

Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., and Salakhutdinov, R. (2014). Dropout: a simple way to prevent neural networks from overfitting. The journal of machine learning research, 15(1):1929–1958.

van den Oord, A., Li, Y., and Vinyals, O. (2018). Representation learning with contrastive predictive coding. arXiv:1807.03748.

Welling, M., Williams, C., and Agakov, F. (2003). Extreme components analysis. Advances in Neural Information Processing Systems, 16.

Wu, Z., Xiong, Y., Yu, S. X., and Lin, D. (2018). Unsupervised feature learning via non-parametric instance discrimination. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 3733–3742.
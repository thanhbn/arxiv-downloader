# 2311.02262.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/attention/2311.02262.pdf
# Kích thước tệp: 951962 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024
CHỈ DẪN CHO MÔ HÌNH CỦA BẠN NÊN CHÚ Ý ĐÂU:
ĐIỀU HƯỚNG CHÚ Ý SAU HỌC CHO CÁC LLM

Qingru Zhang†∗, Chandan Singh⋄, Liyuan Liu⋄, Xiaodong Liu⋄, Bin Yu‡,
Jianfeng Gao⋄,Tuo Zhao†
†Georgia Institute of Technology‡University of California, Berkeley⋄Microsoft Research
{qingru.zhang,tourzhao }@gatech.edu
binyu@berkeley.edu
{chansingh,lucliu,xiaodl,jfgao }@microsoft.com

TÓM TẮT
Trong các bài viết do con người viết, chúng ta thường tận dụng những tinh tế của phong cách văn bản, như **in đậm** và *in nghiêng*, để hướng dẫn sự chú ý của người đọc. Những nhấn mạnh văn bản này rất quan trọng để người đọc nắm bắt thông tin được truyền đạt. Khi tương tác với các mô hình ngôn ngữ lớn (LLM), chúng ta có nhu cầu tương tự – điều hướng mô hình để chú ý hơn đến thông tin do người dùng chỉ định, ví dụ, một hướng dẫn. Tuy nhiên, các phương pháp hiện tại bị hạn chế trong việc xử lý văn bản thuần túy và không hỗ trợ cơ chế như vậy. Điều này thúc đẩy chúng tôi giới thiệu PASTA – Phương pháp Điều hướng Chú ý Sau hóc (Post-hoc Attention STeering Approach), một phương pháp cho phép LLM đọc văn bản với các dấu nhấn mạnh do người dùng chỉ định. Để đạt được điều này, PASTA xác định một tập hợp nhỏ các đầu chú ý và áp dụng việc tái cân bằng chú ý chính xác trên chúng, điều hướng sự chú ý của mô hình đến các phần do người dùng chỉ định. Giống như prompting, PASTA được áp dụng tại thời điểm suy luận và không yêu cầu thay đổi bất kỳ tham số mô hình nào. Các thí nghiệm chứng minh rằng PASTA có thể cải thiện đáng kể khả năng của LLM trong việc tuân theo hướng dẫn của người dùng hoặc tích hợp kiến thức mới từ đầu vào của người dùng, dẫn đến cải thiện hiệu suất đáng kể trên nhiều tác vụ khác nhau, ví dụ, cải thiện độ chính xác trung bình 22% cho LLAMA-7B. Mã nguồn của chúng tôi được công khai tại https://github.com/QingruZhang/PASTA .

1 GIỚI THIỆU

Sự xuất hiện của các mô hình ngôn ngữ lớn (LLM) đã đánh dấu một cột mốc quan trọng trong xử lý ngôn ngữ tự nhiên (NLP) và trí tuệ nhân tạo (AI), thể hiện hiệu suất đặc biệt trên nhiều tác vụ khác nhau (Vaswani et al., 2017; Brown et al., 2020a; OpenAI, 2023). Những nỗ lực để tinh chỉnh thêm các mô hình này đã không ngừng nghỉ, nhằm cho phép chúng xử lý và phản hồi ngôn ngữ tự nhiên và lập trình với chuyên môn giống như con người (Stiennon et al., 2020; Yao et al., 2023).

Mặc dù có những thành tựu đáng kể, LLM thường gặp khó khăn trong việc hiểu các đầu vào ngữ cảnh của chúng trong quá trình tương tác với người dùng (Shen et al., 2023; Lu et al., 2021). Khó khăn này trở nên đặc biệt rõ ràng khi chúng được trình bày các prompt¹ chứa ngữ cảnh nền rộng lớn hoặc hướng dẫn người dùng phức tạp. Ngữ cảnh dài có thể làm choáng ngợp LLM, vì các mô-đun chú ý của chúng, được học từ dữ liệu, không thể nắm bắt đầy đủ các chi tiết quan trọng (Liu et al., 2023). Các hướng dẫn phức tạp có thể càng cản trở mô hình tập trung vào ý định của người dùng, dẫn đến các đầu ra không mong muốn (Wei et al., 2022). Ngoài ra, đối với dữ liệu nhạy cảm về thời gian, như bài báo tin tức, có thể tồn tại kiến thức thực tế trong ngữ cảnh, mâu thuẫn với niềm tin tiên nghiệm của mô hình được tạo ra từ việc tiền huấn luyện lỗi thời. Kết quả là, mô hình có thể tạo ra đầu ra dựa trên niềm tin có sẵn của nó thay vì chú ý đến các sự kiện mới trong ngữ cảnh (Meng et al., 2022a;b; Mitchell et al., 2022; Hernandez et al., 2023). Tất cả những thách thức này góp phần khiến LLM khó khăn trong việc hiểu ý định của người dùng.

So với LLM, người đọc hiếm khi gặp khó khăn trong việc hiểu các nhấn mạnh của bài viết và ý định của người viết. Người viết thường tận dụng nhiều phong cách văn bản khác nhau, như **in đậm** và *in nghiêng*, để nhấn mạnh nội dung cụ thể. Cơ chế này cho phép người viết điều hướng và duy trì sự chú ý của

∗Công việc được hoàn thành trong quá trình thực tập của Qingru Zhang tại Microsoft Research.
¹Chúng tôi sử dụng prompts để chỉ tất cả đầu vào văn bản LLM, bao gồm hướng dẫn người dùng và thông tin nền khác (mà chúng tôi gọi là ngữ cảnh).

1arXiv:2311.02262v2  [cs.CL]  1 Oct 2024

--- TRANG 2 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024

Đầu ra gốc:Mary là một chuyên gia làm việc Head 1Layer 1Layer 2…Layer L…Đầu vào người dùng được điều hướng:Mary là một bác sĩ...*Trả về nghề nghiệp của cô ấy trong định dạng json*Nhấn mạnh điểm chú ý cho các vị trí token được chọn…Cho mỗi đầu được chọn:Head 2Head hĐầu ra được điều hướng: {"Name": "Mary",  "Occupation": "Doctor"}Đầu vào người dùng gốc: Mary là một bác sĩ...Trả về nghề nghiệp của cô ấy trong định dạng jsonLLM……

Chú ý đến 'định dạng json'

Hình 1: PASTA sử dụng một phần do người dùng chỉ định của đầu vào để điều hướng việc tạo mô hình phù hợp với ý định người dùng. PASTA sửa đổi các điểm chú ý được tạo ra trong quá trình suy luận, bằng cách nhấn mạnh các điểm được tạo ra tại các vị trí token tương ứng với phần do người dùng chỉ định của ngữ cảnh.

người đọc, đảm bảo rằng thông tin dự định được nắm bắt chính xác. Trong tương tác giữa người dùng và LLM, người dùng cũng cần làm nổi bật thông tin cụ thể cho mô hình. Do đó, việc tạo mô hình có thể được thiên về một cách hiệu quả theo hướng dẫn của người dùng, từ đó giải quyết các thách thức đã đề cập trước đó. Tính năng này đặc biệt quan trọng khi thiết kế giao diện người dùng-AI, và có thể được áp dụng thường xuyên trong các cuộc trò chuyện dài giữa người dùng và mô hình. Tuy nhiên, các phương pháp hiện tại không hỗ trợ cơ chế như vậy. LLM vốn bị hạn chế trong việc xử lý văn bản thuần túy, không có bất kỳ gợi ý phong cách hoặc dấu hiệu nhấn mạnh nào (Brown et al., 2020b; Liu et al., 2021; Wei et al., 2022). Ngay cả khi các dấu hiệu nhấn mạnh được thêm vào prompts, các LLM tiên tiến thường gặp khó khăn trong việc phân biệt các tín hiệu yếu từ một vài token đánh dấu (Xem bằng chứng trong Phần 5.1).

Được thúc đẩy bởi nhu cầu truyền đạt sự nhấn mạnh của người dùng, chúng tôi giới thiệu PASTA (Phương pháp Điều hướng Chú ý Sau hóc), một phương pháp sau hóc² cho phép người dùng làm nổi bật thông tin cụ thể, ví dụ, một hướng dẫn như trong Hình 1, và điều hướng mô hình để diễn giải các văn bản được nhấn mạnh như người đọc. Cụ thể, PASTA chọn một tập con nhỏ các đầu chú ý và áp dụng việc tái cân bằng chú ý chính xác trên chúng. Như được minh họa trong Hình 1, PASTA tăng trọng số các điểm chú ý của các token do người dùng chỉ định trong khi giảm trọng số các token khác tại các đầu chú ý cụ thể. Phương pháp của chúng tôi được lấy cảm hứng từ quan sát rằng các mô-đun chú ý thể hiện các mẫu chú ý token khác nhau trên các đầu khác nhau (Michel et al., 2019; Voita et al., 2019; Clark et al., 2019). Các mẫu chú ý này có thể được diễn giải như mã hóa thông tin ngữ nghĩa hoặc cú pháp đa dạng, và việc thay đổi chúng có thể ảnh hưởng đáng kể đến hành vi mô hình (Shi et al., 2023a; Hu et al., 2021b). Thông qua việc điều hướng các mô-đun chú ý, PASTA hướng mô hình chú ý chặt chẽ đến các phần do người dùng chỉ định và do đó tạo ra đầu ra mong muốn phù hợp với nội dung được làm nổi bật. Đáng chú ý, PASTA được áp dụng sau khi huấn luyện và không yêu cầu thay đổi bất kỳ tham số mô hình nào; PASTA chỉ yêu cầu truy cập vào các điểm chú ý của các đầu cụ thể của LLM.

Vì các đầu chú ý có thể phục vụ các chức năng khác nhau (Tenney et al., 2019; Deb et al., 2023), chúng tôi giới thiệu một thuật toán lập hồ sơ mô hình hiệu quả để xác định các đầu nào hiệu quả cho việc điều hướng. Cụ thể, chúng tôi lấy mẫu con các tập huấn luyện nhỏ từ nhiều tác vụ và đánh giá hiệu suất của việc điều hướng chú ý cho từng đầu riêng lẻ trên các tác vụ này. PASTA chọn các đầu chú ý mà khi được điều hướng, thường cải thiện hiệu suất đa tác vụ. Chúng tôi quan sát thực nghiệm rằng việc điều hướng các đầu này không chỉ mang lại lợi ích cho các tác vụ hiện có mà còn tăng cường hiệu suất trên các tác vụ chưa thấy. Đáng chú ý, việc lập hồ sơ mô hình chỉ được thực hiện một lần cho một LLM. Các đầu chú ý được chọn có thể được coi như một hồ sơ cấp mô hình, hiệu quả cho việc điều hướng LLM trên các tác vụ chưa thấy.

Chúng tôi tiến hành thí nghiệm trên các tác vụ đa dạng để chứng minh hiệu quả của PASTA. Cụ thể, chúng tôi đánh giá PASTA sử dụng GPT-J-6B (Wang & Komatsuzaki, 2021) và LLAMA-7B (Touvron et al., 2023) trên các tác vụ bao gồm hướng dẫn phức tạp, ngữ cảnh dài và xung đột kiến thức trong ngữ cảnh. Kết quả chứng minh rằng PASTA liên tục cung cấp cải thiện hiệu suất đáng kể so với các chiến lược prompting cơ bản. Ví dụ, PASTA đạt được cải thiện độ chính xác trung bình 22% so với few-shot prompting cho LLAMA-7B trên 4 tác vụ thách thức.

²Sau hóc có nghĩa là phương pháp của chúng tôi không cập nhật trọng số mô hình.

2

--- TRANG 3 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024

2 KIẾN THỨC NỀN

Mô tả vấn đề Trong prompting LLM chuẩn, chúng ta được cung cấp một LLM đã được tiền huấn luyện và một prompt văn bản x. Trong thiết lập của chúng tôi, chúng tôi cần thêm (i) truy cập vào các điểm chú ý được tạo ra bởi các mô-đun chú ý trong LLM³ và (ii) chúng tôi được cung cấp một tập con của prompt xg⊂x do người dùng chỉ định để được nhấn mạnh.

Như trong ví dụ trong Hình 1, x có thể là một chuỗi kết thúc bằng một hướng dẫn, như Mary là một bác sĩ nhưng từng là một y tá...Trả về nghề nghiệp của cô ấy trong định dạng json. Nếu người dùng nhấn mạnh hướng dẫn, xg có thể đơn giản là hướng dẫn cuối Trả về nghề nghiệp của cô ấy trong định dạng json. Trong các tập dữ liệu đánh giá, chúng tôi giả định rằng phần do người dùng chỉ định của mỗi ví dụ đã được cung cấp bằng cách bao quanh nó ở cả hai đầu trong một số dấu hiệu nhấn mạnh, như dấu '*' trong Markdown. Việc tạo ra những dữ liệu có cấu trúc tốt này thường tốn ít chi phí. Ví dụ, trong tập dữ liệu được thiết kế riêng để đánh giá khả năng của mô hình trong việc tuân theo hướng dẫn người dùng, chúng ta có thể đơn giản đánh dấu hướng dẫn cuối cho mọi ví dụ, những hướng dẫn này cố định và được chia sẻ qua các ví dụ. Khi nói đến giao diện người dùng-LLM, người dùng có thể chỉ định xg bằng cách bao quanh nó với các dấu hiệu nhấn mạnh giống nhau. xg có thể được chỉ định một cách linh hoạt. Cụ thể, nó không cần phải là một khoảng liên tục, và có thể được sử dụng để nhấn mạnh thông tin đa dạng.

Chú ý Đa đầu. Một mô hình transformer điển hình bao gồm L lớp xếp chồng, trong đó mỗi lớp chứa hai mô-đun con: một chú ý đa đầu (MHA) và một mạng nơ-ron kết nối đầy đủ chuyển tiếp (FFN). Cho đầu vào X∈Rn×d, MHA của lớp l thực hiện chức năng chú ý song song H đầu: MHA(l)(X) = Concat(H(l,1), ..., H(l,H))Wo trong đó

H(l,h) = A(l,h)V = Softmax(QK⊤/√dh)V (1)

trong đó Q=XWqh, K=XWkh, V=XWvh và Wqh, Wkh, Wvh∈Rd×dh là các ma trận chiếu có thể học được của đầu h. dh thường được đặt thành d/H. Cụ thể, ký hiệu các điểm chú ý tại đầu h của lớp thứ l là A(l,h).

3 PHƯƠNG PHÁP

PASTA (Thuật toán 1) bao gồm hai thành phần: (i) điều hướng chú ý sau hóc, nhấn mạnh các phần do người dùng chỉ định của đầu vào trong quá trình suy luận, xem Phần 3.1 và (ii) lập hồ sơ mô hình đa tác vụ, chọn các đầu chú ý hiệu quả cho việc điều hướng, xem Phần 3.2.

Thuật toán 1 PASTA: Phương pháp Điều hướng Chú ý Sau hóc
Lập hồ sơ mô hình đa tác vụ (Phần 3.2)
1:Đầu vào: các tập huấn luyện nhỏ {D(i)}mi=1, các siêu tham số α,k;
2:for 1≤i≤m do
3: for 1≤l≤L, 1≤h≤H do
4: Đánh giá hiệu suất mô hình trên D(i) khi điều hướng đầu (l, h) bằng (2);
5: Trả về kết quả đánh giá của việc điều hướng (l, h) trên D(i);
6: end for
7: Thu thập kết quả điều hướng của tất cả các đầu và trả về lập hồ sơ tác vụ R(i);
8:end for
9:Đầu ra: Tập đầu chú ý H=∩mi=1R(i)1:k.

Điều hướng thời gian suy luận (Phần 3.1)
1:Đầu vào: đầu vào văn bản x, các đoạn được người dùng gạch chân G, hệ số α;
2:Đầu ra: các thế hệ mô hình trong khi điều hướng mọi đầu (l, h) trong H bằng (2).

3.1 ĐIỀU HƯỚNG CHÚ Ý SAU HÓC

PASTA nhấn mạnh tập con đầu vào do người dùng chỉ định bằng cách giảm trọng số các điểm chú ý của các token không được người dùng chỉ định. Cụ thể, cho tập chỉ số của các khoảng đầu vào được làm nổi bật là G, PASTA nhấn mạnh các token do người dùng chỉ định này bằng một phép chiếu chú ý T:

H(l,h) = T(A(l,h))V, trong đó [T(A)]ij = {
αAij/Ci nếu j∈G⁻
Aij/Ci ngược lại.
(2)

³Chúng tôi không cần truy cập trọng số mô hình cũng như đầu ra trung gian từ các mô-đun khác như FFN.

3

--- TRANG 4 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024

trong đó 0≤α<1 là một hệ số tỷ lệ và G⁻=[n]−G là tập chỉ số của các token không trong G. Thuật ngữ Ci=∑j∈GAij+∑j∈G⁻αAij chuẩn hóa các điểm để chúng tổng bằng một. Việc điều hướng chú ý (2) được tiến hành trong thời gian suy luận và không yêu cầu bất kỳ huấn luyện nào.

(2) điều hướng chú ý mô hình bằng cách giảm tỷ lệ các điểm của các token không được người dùng làm nổi bật. Khi hệ số α được đặt rất nhỏ, các đoạn do người dùng chỉ định được làm nổi bật do các điểm chú ý tăng lên sau việc chuẩn hóa lại. Do đó, chúng ta có thể hướng mô hình tập trung nhiều hơn vào các token do người dùng chỉ định, thiên về việc tạo để phù hợp với nội dung được chỉ định.

PASTA giảm tỷ lệ các điểm chú ý của các token không được chỉ định bằng α. Khi việc chuẩn hóa lại được theo sau, nó tương đương với việc tăng tỷ lệ các điểm chú ý của các token do người dùng chỉ định bằng 1/α. Lý do chọn (2) là nó có thể ổn định hơn về mặt số học so với việc tăng tỷ lệ điểm. Ngoài ra, người ta cũng có thể tỷ lệ các điểm chú ý bằng cách thêm một hằng số dương vào các token được gạch chân G. Lý do chúng tôi chọn phép nhân trong (2) thay vì phép cộng là nó bảo tồn sự khác biệt về độ lớn chú ý giữa các token được làm nổi bật. Do đó, thao tác điều hướng chỉ điều chỉnh tỷ lệ chú ý tổng thể của hai nhóm token. Ngược lại, việc cộng bằng một hằng số lớn vào các token được làm nổi bật dẫn đến các điểm chú ý của chúng gần như được phân phối đều, dẫn đến mất thông tin không cần thiết và suy giảm hiệu suất.

3.2 LẬP HỒ SƠ MÔ HÌNH ĐA TÁC VỤ

Về mặt thực nghiệm, chúng tôi thấy rằng việc áp dụng điều hướng chú ý trong (2) cho tất cả các đầu chú ý hoạt động kém hơn việc áp dụng nó chỉ cho các đầu cụ thể (xem Phần 5.3). Điều quan trọng là phải chỉ định các đầu chú ý chính xác, vì các đầu khác nhau phục vụ các vai trò khác biệt trong việc mã hóa thông tin ngữ nghĩa/cú pháp. Để đạt được điều này, chúng tôi đề xuất một thuật toán lập hồ sơ mô hình đa tác vụ để xác định các đầu chú ý hiệu quả cho việc điều hướng. Cụ thể, cho m tác vụ liên quan đến nhấn mạnh người dùng, chúng tôi lấy mẫu con một tập huấn luyện nhỏ D(i) (ví dụ, |D(i)|=1000) từ mỗi tác vụ i. Sau đó, chúng tôi đánh giá hiệu suất của việc điều hướng mọi đầu chú ý riêng lẻ (l, h) (1≤l≤L, 1≤h≤H) trên mỗi tập con nhỏ D(i) (1≤i≤m).

Đối với mỗi tác vụ i, chúng tôi xếp hạng tất cả các đầu theo hiệu suất điều hướng của chúng trên D(i) và coi thứ hạng R(i)=[(l1, h1), (l2, h2), ...] như lập hồ sơ của tác vụ i. Sau đó chúng tôi đặt tập đầu chú ý H cho điều hướng là giao của các đầu hoạt động tốt nhất k đầu, H=∩mi=1R(i)1:k (xem Phần 5.3 cho các lựa chọn thay thế). Một cách trực quan, chúng tôi mong đợi hiệu suất sẽ cải thiện khi số lượng tác vụ m tăng lên.

Giống như điều hướng chú ý, lập hồ sơ mô hình chỉ yêu cầu truy cập vào các điểm chú ý, ngoài các đầu vào và đầu ra của nó (trọng số mô hình và gradient không được yêu cầu). Quan trọng, quá trình này chỉ cần được thực hiện một lần cho một LLM, tương tự như tinh chỉnh. Tuy nhiên, không giống như tinh chỉnh, điều hướng mô hình không sửa đổi trọng số mô hình và quan trọng hơn, tổng quát hóa cho các tác vụ mới. Tập đầu H kết quả có thể được coi như một hồ sơ cấp mô hình. Một khi nó được xác định, chúng ta có thể áp dụng điều hướng chú ý trên H cho cả các tác vụ hiện có và các tác vụ chưa thấy để tăng cường hiểu biết ngữ cảnh của mô hình và mang lại lợi ích cho hiệu suất downstream.

4 THIẾT LẬP THÍ NGHIỆM

Các tác vụ đánh giá và thước đo. Chúng tôi triển khai PASTA cho hai mô hình đã được tiền huấn luyện: GPT-J (6 tỷ tham số, (Wang & Komatsuzaki, 2021)) và LLaMA-7B (7 tỷ tham số, (Touvron et al., 2023)). Chúng tôi đánh giá hiệu quả của PASTA trong (i) xử lý hướng dẫn người dùng phức tạp, (ii) diễn giải ngữ cảnh dài, và (iii) giải quyết xung đột kiến thức trong ngữ cảnh. Đối với (i), chúng tôi giới thiệu hai tác vụ mới: Định dạng JSON và Thay đổi đại từ. Đối với (ii) và (iii), chúng tôi nghiên cứu Bias in Bios (De-Arteaga et al., 2019) và CounterFact (Meng et al., 2022a). Đối với mỗi tác vụ, chúng tôi cung cấp một mô tả, mô tả phần nào của đầu vào chúng tôi nhấn mạnh, và thước đo nào chúng tôi sử dụng để đánh giá (xem Phụ lục A cho chi tiết tập dữ liệu đầy đủ).

•Định dạng JSON là một tác vụ mới đánh giá khả năng của LLM trong việc tạo ra đầu ra theo định dạng mong muốn của người dùng (JSON). Đây là một trường hợp sử dụng quan trọng cho LLM khi đầu ra của chúng được sử dụng trong một quy trình downstream. Tác vụ này sử dụng dữ liệu tiểu sử từ BiasBios (được mô tả bên dưới) nhưng thêm một hướng dẫn khác vào cuối ngữ cảnh: trả lời nghề nghiệp của {person} và tạo ra câu trả lời dưới dạng định dạng JSON. Hướng dẫn này nhắc mô hình tạo ra đầu ra trong định dạng JSON.

Chúng tôi nhấn mạnh hướng dẫn cuối

4

--- TRANG 5 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024

Thước đo: (a) Độ chính xác định dạng (F. Acc.) đo độ chính xác trong việc tạo ra JSON hợp lệ. (b) Độ chính xác dự đoán (P. Acc.) đo độ chính xác trong việc tạo ra đích chính xác trong các giá trị JSON sau khi tải các thế hệ có định dạng JSON.

•Thay đổi đại từ là một tác vụ mới đánh giá khả năng của LLM trong việc tuân theo một hướng dẫn người dùng khó khăn. Nó một lần nữa sử dụng các ngữ cảnh tiểu sử từ BiasBios nhưng thay vào đó hướng dẫn mô hình: thay thế 'she' và 'he' bằng 'they' và tạo ra nghề nghiệp của {person} sau khi thay đổi đại từ.

Chúng tôi nhấn mạnh hướng dẫn cuối.

Thước đo: (a) Độ chính xác đánh giá tỷ lệ 'she/he' được thay đổi thành công thành 'they' trong các thế hệ mô hình. (b) Độ chính xác thay đổi tất cả (A. Acc.) là tỷ lệ mà mô hình thay thế tất cả các đại từ tương ứng, tức là thay đổi she/he/her/him/hers/his thành they/them/their/theirs.

•CounterFact đo khả năng của LLM trong việc tạo ra văn bản phù hợp với một sự kiện mới. Mỗi ví dụ bao gồm (subject, relation, old target, new target), ví dụ, (Kevin Garnett, is a professional, basketball player, baseball player). Chúng tôi trình bày mô hình cả sự kiện cũ và mới theo prompt: Previously, {old fact}, but currently, {new fact}. {question}. Sự thay đổi trong các sự kiện theo thời gian này thường gây nhầm lẫn cho LLM, dẫn đến việc đoán ngẫu nhiên trên hai trong số chúng khi trả lời {question}.

Chúng tôi nhấn mạnh đoạn đầu vào chứa sự kiện mới.

Thước đo: chúng tôi đánh giá các thước đo theo (Meng et al., 2022a): (a) Điểm hiệu quả (ES) là phần các trường hợp mà mô hình có PLLM(new target) > PLLM(old target); (b) Điểm paraphrase (PS) giống như ES nhưng thay đổi {question} với một tập các câu hỏi được diễn đạt lại để đánh giá tổng quát hóa

•BiasBios bao gồm các tiểu sử nghề nghiệp của những người không nổi tiếng, ban đầu được giới thiệu để điều tra thiên kiến giới tính trong nghề nghiệp. Mỗi ví dụ bao gồm ngữ cảnh tiểu sử và một nhãn của nghề nghiệp đích. Câu đầu tiên đề cập đến nghề nghiệp của người đó, và các câu tiếp theo mô tả lịch sử nghề nghiệp của cá nhân nhưng có thể không liên quan trực tiếp đến dự đoán, có khả năng làm mất tập trung sự chú ý của mô hình. Ở cuối ngữ cảnh, chúng tôi thêm câu hỏi: {person} có nghề nghiệp là.

Chúng tôi nhấn mạnh câu đầu tiên, vì nó mang thông tin nhiều nhất về nghề nghiệp.

Thước đo: theo (Hernandez et al., 2023), chúng tôi tính Độ chính xác bằng cách kiểm tra xem xác suất được gán cho nghề nghiệp đích có cao nhất trong số 28 nghề nghiệp ứng viên hay không.

Đối với Thay đổi đại từ, CounterFact, và BiasBios, chúng tôi thêm đo lường Tính lưu loát như entropy bi-gram và tri-gram trung bình của các thế hệ, được thiết kế để thấp cho các văn bản thoái hóa hoặc lặp lại (Meng et al., 2022a). Chúng tôi lọc ra bất kỳ kết quả nào nhận được tính lưu loát dưới 3.0 (xem kết quả đầy đủ bao gồm tính lưu loát trong Phụ lục B.1).

Đường cơ sở. Chúng tôi so sánh PASTA với các đường cơ sở sau:

•Zero-shot prompting là cách tiếp cận phổ biến nhất để tương tác với LLM, trong đó người dùng cung cấp cho mô hình một prompt chứa ngữ cảnh nền và một hướng dẫn hoặc câu hỏi của người dùng.

•Marked prompting thay đổi các prompt được sử dụng trong zero-shot prompting bằng cách bao quanh các đoạn đầu vào do người dùng chỉ định với các dấu hiệu nhấn mạnh, ví dụ dấu sao, như được thực hiện trong các tệp markdown để nhấn mạnh, hoặc dấu ngoặc kép, như được thực hiện trong ngôn ngữ tự nhiên.

•Few-shot prompting bao gồm các minh họa (đầu vào ví dụ và đầu ra đích) ở đầu prompt được cung cấp cho LLM. Few-shot prompting thường cải thiện hiệu suất trong các tác vụ mới, nhưng tăng chi phí tính toán của suy luận do độ dài prompt tăng lên, đặc biệt khi các minh họa dài (Dong et al., 2023); ở đây chúng tôi sử dụng 3 minh họa trong ngữ cảnh.

Cài đặt PASTA Chúng tôi nghiên cứu PASTA trong 2 cài đặt: đa tác vụ và không phụ thuộc tác vụ. Trong cài đặt đa tác vụ, tác vụ đánh giá j được bao gồm để lập hồ sơ, trong khi trong cài đặt không phụ thuộc tác vụ, tác vụ đánh giá bị loại trừ (thay vào đó, chúng tôi lập hồ sơ trên 3 tập dữ liệu ngoài j). Cài đặt đa tác vụ cải thiện hiệu suất nhưng yêu cầu các mẫu huấn luyện có nhãn cho tác vụ được đánh giá, điều này có thể khó có được trong thực tế.

Về mặt thực nghiệm, chúng tôi thấy rằng PASTA không nhạy cảm với hệ số tỷ lệ α (xem Phần 5.3) và cố định nó ở 0.01 trong các thí nghiệm của chúng tôi. Chúng tôi chọn 1000 mẫu huấn luyện từ mỗi tác vụ trong 4 tác vụ trên để lập hồ sơ mô hình. Sau khi lập hồ sơ mô hình, chúng tôi chọn k từ {300, 400, 500} cho LLAMA-7B

5

--- TRANG 6 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024

Bảng 1: Kết quả chính của LLAMA-7B để chứng minh rằng PASTA có thể cải thiện khả năng của mô hình để (i) tuân theo hướng dẫn người dùng (JSON Format và Prons. Changing); (ii) diễn giải thông tin ngữ cảnh (BiasBios); (iii) giải quyết xung đột kiến thức (CounterFact). Đối với tất cả điểm số, cao hơn là tốt hơn. Kết quả tốt nhất được in đậm.

[THIS IS TABLE: Detailed results table showing performance metrics for different methods across tasks]

Bảng 2: Kết quả chính của GPT-J để chứng minh rằng PASTA có thể cải thiện khả năng của mô hình để (i) tuân theo hướng dẫn người dụng (JSON Format và Prons. Changing); (ii) diễn giải thông tin ngữ cảnh (BiasBios); (iii) giải quyết xung đột kiến thức (CounterFact). Đối với tất cả điểm số, cao hơn là tốt hơn. Kết quả tốt nhất được in đậm.

[THIS IS TABLE: Similar results table for GPT-J model]

để có số lượng đầu được điều hướng |H| là {25, 53, 86}. Chúng tôi thấy rằng PASTA đạt được hiệu suất tốt nhất trên LLAMA-7B khi 50≤|H|≤100, tức là k=400 hoặc k=500. Đối với GPT-J, chúng tôi chọn k từ {250, 275, 300, 350} để có |H| là {52, 72, 111, 153}. Đối với mỗi tác vụ, chúng tôi chia dữ liệu thành các tập train/validation/test theo (Hernandez et al., 2023) (Xem Phụ lục A) và chọn |H| bằng cross validation. Đối với tất cả tác vụ, đầu ra mô hình được tạo ra bằng tìm kiếm tham lam.

5 KẾT QUẢ

5.1 KẾT QUẢ CHÍNH: PASTA CẢI THIỆN VIỆC TẠO MÔ HÌNH

Bảng 1 và 2 trình bày kết quả chính cho PASTA được áp dụng cho LLAMA-7B và GPT-J tương ứng. Few-shot prompting là đường cơ sở mạnh nhất, và PASTA không phụ thuộc tác vụ vượt trội hơn nó trên thước đo chính cho mỗi tác vụ cho tất cả các cài đặt ngoại trừ JSON Formatting với GPT-J. PASTA đa tác vụ vượt trội hơn tất cả đường cơ sở trên tất cả cài đặt.

PASTA có thể cải thiện việc tuân theo hướng dẫn của LLM. Kết quả từ các tác vụ JSON Formatting và Pronouns Changing chỉ ra rằng, bằng cách làm nổi bật hướng dẫn người dùng ở cuối đầu vào, PASTA hiệu quả điều hướng mô hình tập trung vào ý định người dùng, từ đó thiên về việc tạo của chúng để đáp ứng các yêu cầu hoặc định dạng cụ thể. Ví dụ, trong khi GPT-J chỉ đạt được 39.9% các thế hệ zero-shot của nó tuân thủ yêu cầu người dùng trên tác vụ Pronouns Changing, PASTA mang lại cải thiện độ chính xác đáng kể 53% bằng cách nhấn mạnh hướng dẫn. Hơn nữa, PASTA đạt được độ chính xác định dạng ấn tượng 96.64% và độ chính xác dự đoán 85.09% khi được áp dụng cho LLAMA-7B trên tác vụ JSON Formatting. Hiệu suất này vượt quá few-shot prompting 11%, mặc dù few-shot prompting cung cấp mô hình một cách rõ ràng các ví dụ JSON chính xác thông qua các minh họa bổ sung. Bảng 3 trình bày một vài ví dụ được tạo ra bởi LLAMA-7B khi áp dụng PASTA.

PASTA có thể giúp mô hình nắm bắt thông tin ngữ cảnh quan trọng. Trong trường hợp các tác vụ BiasBios và CounterFact, chúng tôi áp dụng PASTA để nhấn mạnh các đoạn ngữ cảnh cụ thể cho LLM. Do đó, các mô hình được hướng dẫn chú ý chặt chẽ đến thông tin ngữ cảnh cụ thể hoặc các sự kiện mới trong

6

--- TRANG 7 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024

Bảng 3: Ví dụ tạo của LLAMA-7B trên các tác vụ JSON Formatting và Pronouns Changing.

[THIS IS TABLE: Two-column table showing task examples with prompts and generated outputs for JSON Format and Prons. Change tasks]

ngữ cảnh. Kết quả từ hai tác vụ này minh họa rằng PASTA có thể hướng dẫn các mô hình diễn giải thông tin quan trọng hoặc giải quyết các xung đột kiến thức trong ngữ cảnh, mang lại cải thiện đáng kể trong hiệu suất dự đoán của cả hai tác vụ. Ví dụ, PASTA đạt được độ chính xác dự đoán 94.96% cho GPT-J trên tác vụ BiasBios, cao hơn 16.32% so với đường cơ sở tốt nhất.

Bảng 1 và 2 cũng gợi ý rằng marked prompting, một đường cơ sở làm nổi bật các văn bản cụ thể giống như người viết, gặp khó khăn trong việc truyền đạt hiệu quả sự nhấn mạnh cho LLM. Một lý do có thể là những dấu hiệu nhấn mạnh này hiếm khi xuất hiện trong dữ liệu tiền huấn luyện khổng lồ. Ngược lại, few-shot prompting đôi khi dẫn đến cải thiện trong hiệu suất mô hình. Tuy nhiên, một nhược điểm của few-shot prompting là tính không ổn định của nó, tức là hiệu suất của nó thể hiện phương sai cao trên các mẫu khác nhau trong minh họa (Xem Phụ lục B).

5.2 PASTA CÓ THỂ GIẢM THIỂU ĐỘ NHẠY CẢM CỦA PROMPTS

[THIS IS TABLE: Results showing sensitivity of model performance to prompt rephrasing on JSON Formatting task]

Được biết rằng hiệu suất của LLM có thể nhạy cảm với những thay đổi nhỏ trong prompts, như diễn đạt lại và định dạng lại, ngay cả khi những prompts này truyền đạt cùng một ý nghĩa (Reynolds & McDonell, 2021; Liu et al., 2021). Chúng tôi thấy rằng PASTA có thể giảm bớt độ nhạy cảm của hiệu suất mô hình đối với các prompts khác nhau. Cụ thể, Bảng 4 đánh giá hiệu suất của LLAMA-7B và GPT-J trên tác vụ JSON Formatting và Pronouns Changing cho các hướng dẫn khác nhau trong mẫu prompt, tất cả đều truyền đạt cùng một ý nghĩa (xem prompts chính xác trong Phụ lục A.1). Kết quả cho thấy hiệu suất zero-shot nhạy cảm với các prompts khác nhau và có thể giảm đáng kể với các mẫu được tạo kém. Ngược lại, PASTA liên tục cải thiện hiệu suất mô hình so với zero-shot prompting cho tất cả prompts, hiệu quả giảm thiểu độ nhạy cảm đối với các biến thể trong prompts.

5.3 PHÂN TÍCH VÀ ABLATIONS

Trong phần này, chúng tôi điều tra các lựa chọn siêu tham số khác nhau và quyết định mô hình hóa ảnh hưởng đến hiệu suất của PASTA.

Lập hồ sơ mô hình Hình 2 trình bày kết quả về tầm quan trọng của lập hồ sơ mô hình được giới thiệu trong Phần 3.2. Chúng tôi so sánh PASTA khi điều hướng các đầu được chọn với các lựa chọn hợp lý khác: điều hướng (i) tất cả đầu, (ii) toàn bộ lớp, hoặc (iii) các đầu riêng lẻ trên tác vụ JSON Formatting (Xem

7

--- TRANG 8 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024

[THIS IS FIGURE: A graph showing performance of LLAMA-7B on JSON Formatting task with different lines representing different approaches: Zero-shot, PASTA, Steer all heads, Steer entire layer, and Steer single head plotted against Layer (x-axis) and F. Acc (y-axis)]

Hình 2: Hiệu suất của LLAMA-7B trên tác vụ JSON Formatting khi chúng tôi điều hướng (i) tất cả đầu (xanh lá); (ii) toàn bộ lớp (vàng); và (iii) một đầu riêng lẻ trong một lớp (biểu đồ violin xanh dương). Hiệu suất thay đổi đáng kể qua các lớp và qua các đầu của một lớp.

Phụ lục B.3 cho so sánh trên các tác vụ còn lại). Việc chọn đầu thông qua lập hồ sơ mô hình trong PASTA (đường đỏ) vượt trội đáng kể so với các cách tiếp cận khác. Điều hướng tất cả đầu (đường xanh lá đứt nét) làm giảm hiệu suất so với hiệu suất zero-shot cơ bản (đường đen đứt nét). Điều này có thể là do việc điều hướng tất cả đầu làm khuếch đại quá mức thông tin do người dùng chỉ định với chi phí của thông tin thiết yếu khác cần thiết cho việc tạo và dự đoán hiệu quả. Thú vị, chúng tôi thấy rằng hiệu suất thay đổi đáng kể khi điều hướng các lớp khác nhau (vàng) hoặc đầu (biểu đồ violin xanh dương). Như đã đề cập trong Phần 1, các đầu chú ý đóng vai trò riêng biệt trong việc mã hóa thông tin ngữ nghĩa và cú pháp đa dạng (Tenney et al., 2019). Khi điều hướng các đầu, được liên quan một cách thích hợp trong việc mã hóa thông tin do người dùng chỉ định, mô hình có thể được hướng dẫn để nắm bắt và củng cố những tín hiệu cụ thể này. Ngược lại, việc sửa đổi sự chú ý của các đầu không liên quan không chỉ thất bại trong việc nhấn mạnh thông tin mong muốn mà còn can thiệp vào các chức năng ban đầu của chúng, dẫn đến suy giảm hiệu suất. Do đó, điều quan trọng là phải xác định các đầu hiệu quả thông qua lập hồ sơ mô hình trước khi áp dụng điều hướng.

Thay đổi chiến lược chọn đầu trong quá trình lập hồ sơ. Như được mô tả trong Phần 5.3, lập hồ sơ mô hình của chúng tôi chọn Giao của các đầu hoạt động tốt nhất k đầu để điều hướng qua nhiều tác vụ. Ngoài ra, khi đánh giá trên tác vụ j, chúng ta có thể chọn đầu để điều hướng với các chiến lược khác nhau: (i) Cụ thể theo tác vụ – điều hướng các đầu hoạt động tốt nhất k2 chỉ của tác vụ j, tức là R(j)1:k2; hoặc (ii) Hợp – hợp của những đầu này qua nhiều tác vụ, tức là ∪mi=1R(i)1:k2. Bảng 5 so sánh hiệu suất của chúng. Sử dụng các đầu cụ thể theo tác vụ thay vì các đầu được chọn giao đôi khi mang lại hiệu suất cải thiện, nhưng yêu cầu chọn một tập đầu khác nhau cho mỗi tác vụ mới.

[THIS IS TABLE: Table 5 showing varying head selection strategies with results for different tasks and models]

Thay đổi số lượng đầu được điều hướng. Hình 3a và 3b minh họa hiệu suất của PASTA khi điều hướng số lượng đầu khác nhau trên hai tác vụ. Kết quả gợi ý rằng khi nhiều đầu hơn được bao gồm để điều hướng, mô hình tuân theo người dùng thậm chí còn chặt chẽ hơn, đạt được hiệu quả cao hơn (JSON Format Acc. và Pron. Change Acc.). Tuy nhiên, tại một điểm nào đó, điều này dẫn đến giảm trong các thước đo phản ánh chất lượng tạo (JSON Pred. Acc và Fluency). Do đó, có một sự đánh đổi giữa nhấn mạnh hiệu quả và chất lượng tạo. Nhấn mạnh quá mức có thể dẫn mô hình chỉ tập trung vào việc thỏa mãn yêu cầu người dùng và bỏ qua các phần khác. Do đó, chúng tôi khuyến nghị áp dụng PASTA cho một số lượng đầu vừa phải (thường từ 50 đến 150), đạt được sự cân bằng giữa hiệu quả và chất lượng tạo.

Thay đổi hệ số tỷ lệ α. Hình 3c trình bày hiệu suất của PASTA trên hai tác vụ khi chúng tôi thay đổi hệ số tỷ lệ α. Kết quả chỉ ra rằng PASTA khá mạnh mẽ đối với

8

--- TRANG 9 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024

[THIS IS FIGURE: Three graphs labeled (a), (b), and (c) showing performance metrics for LLAMA-7B on different tasks with varying parameters]

Hình 3: Hiệu suất của việc áp dụng PASTA cho LLAMA-7B trên các tác vụ JSON Formating và Pronouns Changing khi thay đổi số lượng đầu được điều hướng |H| (3a,3b); và thay đổi hệ số tỷ lệ α (3c).

siêu tham số này; trong thực tế, chúng tôi cố định nó là 0.01. Lưu ý rằng việc đặt α về không nên được tránh, vì điều này dẫn đến việc loại bỏ hoàn toàn các ngữ cảnh quan trọng khác tại các đầu được điều hướng, dẫn đến suy giảm hiệu suất.

6 CÔNG VIỆC LIÊN QUAN

Phương pháp chính để kiểm soát LLM đã là thông qua prompting, thường mang lại cải thiện ấn tượng trong hiệu suất (Brown et al., 2020b; Liu et al., 2021; Wei et al., 2022) và thúc đẩy một dòng công việc nhằm làm cho prompting dễ dàng hơn, ví dụ (Strobelt et al., 2022; Bach et al., 2022; Shin et al., 2020; Deng et al., 2022; Singh et al., 2023b). Tuy nhiên, LLM vẫn cực kỳ nhạy cảm với các sắc thái trong prompts (Webson & Pavlick, 2021; Lu et al., 2021); PASTA bổ sung cho những cách tiếp cận này bằng cách làm cho người dùng dễ dàng hơn trong việc chỉ định một prompt trong các tình huống khó khăn.

Một dòng công việc khác nhằm làm cho LLM dễ thích ứng hơn với prompting bằng cách sửa đổi chúng trong quá trình huấn luyện. Nổi bật nhất trong số những cách tiếp cận này là instruction finetuning (Wei et al., 2021; Chung et al., 2022), Reinforcement Learning from Human Feedback (Ziegler et al., 2019; Ouyang et al., 2022), và các phương pháp liên quan khác, ví dụ (Lee et al., 2023). Cũng có một vài phương pháp để chỉ định trực tiếp những phần nào của đầu vào quan trọng trong quá trình huấn luyện, ví dụ (Ross et al., 2017; Rieger et al., 2019; Schramowski et al., 2020; Krishna et al., 2023). PASTA có thể được sử dụng bổ sung cho những cách tiếp cận này để cải thiện một số khía cạnh của khả năng điều hướng mô hình (ví dụ tuân theo hướng dẫn).

PASTA liên quan đến nhiều phương pháp khác nhau để thích ứng với các tác vụ mới, bao gồm LoRA (Hu et al., 2021a), AdaLoRA (Zhang et al., 2023), QLoRA (Dettmers et al., 2023), và TOAST (Shi et al., 2023b). PASTA cũng liên quan đến nhiều nghiên cứu về chỉnh sửa mô hình, ví dụ ROME (Meng et al., 2022a), MEMIT (Meng et al., 2022b), MEND (Mitchell et al., 2022), và REMEDI (Hernandez et al., 2023). Không giống như những công việc này, PASTA bảo tồn khả năng của LLM chuyển giao cho các tác vụ mới sử dụng prompts và thông tin được con người chọn, thay vì sử dụng các ví dụ có nhãn mới.

Cuối cùng, PASTA cũng được thúc đẩy bởi các công việc nhằm hiểu một cách cơ học các điểm chú ý (Zou et al., 2023), ví dụ bằng cách nghiên cứu chúng thông qua tầm quan trọng đặc trưng (Jain & Wallace, 2019; Wiegreffe & Pinter, 2019; Deb et al., 2023), probing (Conneau et al., 2018; Liu & Avci, 2019), visualization (Karpathy et al., 2015; Olah et al., 2017), localizing knowledge (Meng et al., 2022a; Dai et al., 2021), categorizing directions in representation space (Kim et al., 2017; Schwettmann et al., 2021), hoặc natural-language explanations (Bills et al., 2023; Singh et al., 2023a).

7 KẾT LUẬN

Trong nghiên cứu này, chúng tôi đề xuất PASTA, một cách tiếp cận mới nhằm cho phép LLM vượt qua các giới hạn của văn bản thuần túy và hiệu quả nhận thức hướng dẫn người dùng được thể hiện như các phần được làm nổi bật của prompts. Bằng cách thực hiện các điều chỉnh chính xác đối với các điểm chú ý trong các đầu được chọn, PASTA hướng sự tập trung của mô hình đến ngữ cảnh có liên quan, phản ánh cách con người hưởng lợi từ các gợi ý văn bản. Không giống như các phương pháp tinh chỉnh truyền thống, PASTA được áp dụng tại thời điểm suy luận và không yêu cầu cập nhật tham số cũng như tính toán gradient; PASTA chỉ yêu cầu chọn các đầu chú ý nào để áp dụng tái cân bằng, một thao tác lập hồ sơ một lần cho LLM. Kết quả thực nghiệm cho thấy PASTA có thể cải thiện đáng kể hiệu suất mô hình trên nhiều tác vụ khác nhau. Trong tương lai, chúng tôi dự định tích hợp PASTA với nhiều phương pháp khác nhau, như few-shot in-context learning, nhằm làm nổi bật các ví dụ hiệu quả để tăng cường tính ổn định của nó.

9

--- TRANG 10 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024

TÀI LIỆU THAM KHẢO

Stephen H Bach, Victor Sanh, Zheng-Xin Yong, Albert Webson, Colin Raffel, Nihal V Nayak, Abheesht Sharma, Taewoon Kim, M Saiful Bari, Thibault Fevry, et al. Promptsource: An integrated development environment and repository for natural language prompts. arXiv preprint arXiv:2202.01279, 2022.

Steven Bills, Nick Cammarata, Dan Mossing, Henk Tillman, Leo Gao, Gabriel Goh, Ilya Sutskever, Jan Leike, Jeff Wu, and William Saunders. Language models can explain neurons in language models. URL https://openaipublic. blob. core. windows. net/neuron-explainer/paper/index. html.(Date accessed: 14.05. 2023), 2023.

Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. Language models are few-shot learners. In H. Larochelle, M. Ranzato, R. Hadsell, M.F. Balcan, and H. Lin (eds.), Advances in Neural Information Processing Systems, volume 33, pp. 1877–1901. Curran Associates, Inc., 2020a. URL https://proceedings.neurips.cc/paper_files/paper/2020/file/ 1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf.

Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are few-shot learners. Advances in neural information processing systems, 33:1877–1901, 2020b.

Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, et al. Scaling instruction-finetuned language models. arXiv preprint arXiv:2210.11416, 2022.

Kevin Clark, Urvashi Khandelwal, Omer Levy, and Christopher D. Manning. What does BERT look at? an analysis of BERT's attention. In Proceedings of the 2019 ACL Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP, pp. 276–286, Florence, Italy, August 2019. Association for Computational Linguistics. doi: 10.18653/v1/W19-4828. URL https://aclanthology.org/W19-4828.

Alexis Conneau, German Kruszewski, Guillaume Lample, Loïc Barrault, and Marco Baroni. What you can cram into a single vector: Probing sentence embeddings for linguistic properties. arXiv preprint arXiv:1805.01070, 2018.

Damai Dai, Li Dong, Yaru Hao, Zhifang Sui, Baobao Chang, and Furu Wei. Knowledge neurons in pretrained transformers. arXiv preprint arXiv:2104.08696, 2021.

Maria De-Arteaga, Alexey Romanov, Hanna Wallach, Jennifer Chayes, Christian Borgs, Alexandra Chouldechova, Sahin Geyik, Krishnaram Kenthapadi, and Adam Tauman Kalai. Bias in bios: A case study of semantic representation bias in a high-stakes setting. In proceedings of the Conference on Fairness, Accountability, and Transparency, pp. 120–128, 2019.

Mayukh Deb, Björn Deiseroth, Samuel Weinbach, Patrick Schramowski, and Kristian Kersting. Atman: Understanding transformer predictions through memory efficient attention manipulation. arXiv preprint arXiv:2301.08110, 2023.

Mingkai Deng, Jianyu Wang, Cheng-Ping Hsieh, Yihan Wang, Han Guo, Tianmin Shu, Meng Song, Eric P Xing, and Zhiting Hu. Rlprompt: Optimizing discrete text prompts with reinforcement learning. arXiv preprint arXiv:2205.12548, 2022.

Tim Dettmers, Artidoro Pagnoni, Ari Holtzman, and Luke Zettlemoyer. Qlora: Efficient finetuning of quantized llms, 2023.

Qingxiu Dong, Lei Li, Damai Dai, Ce Zheng, Zhiyong Wu, Baobao Chang, Xu Sun, Jingjing Xu, Lei Li, and Zhifang Sui. A survey on in-context learning, 2023.

Evan Hernandez, Belinda Z. Li, and Jacob Andreas. Inspecting and editing knowledge representations in language models, 2023.

Edward J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. Lora: Low-rank adaptation of large language models. arXiv preprint arXiv:2106.09685, 2021a.

J. Edward Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, and Weizhu Chen. Lora: Low-rank adaptation of large language models. arXiv preprint abs:2106.09685, 2021b.

10

--- TRANG 11 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024

Sarthak Jain and Byron C Wallace. Attention is not explanation. arXiv preprint arXiv:1902.10186, 2019.

Andrej Karpathy, Justin Johnson, and Li Fei-Fei. Visualizing and understanding recurrent networks. arXiv preprint arXiv:1506.02078, 2015.

Been Kim, Martin Wattenberg, Justin Gilmer, Carrie Cai, James Wexler, Fernanda Viegas, and Rory Sayres. Interpretability beyond feature attribution: Quantitative testing with concept activation vectors (tcav). arXiv preprint arXiv:1711.11279, 2017.

Satyapriya Krishna, Jiaqi Ma, Dylan Slack, Asma Ghandeharioun, Sameer Singh, and Himabindu Lakkaraju. Post hoc explanations of language models can improve language models. arXiv preprint arXiv:2305.11426, 2023.

Harrison Lee, Samrat Phatale, Hassan Mansoor, Kellie Lu, Thomas Mesnard, Colton Bishop, Victor Carbune, and Abhinav Rastogi. Rlaif: Scaling reinforcement learning from human feedback with ai feedback. arXiv preprint arXiv:2309.00267, 2023.

Frederick Liu and Besim Avci. Incorporating priors with feature attribution on text classification. arXiv preprint arXiv:1906.08286, 2019.

Nelson F. Liu, Kevin Lin, John Hewitt, Ashwin Paranjape, Michele Bevilacqua, Fabio Petroni, and Percy Liang. Lost in the middle: How language models use long contexts, 2023.

Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi, and Graham Neubig. Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing. arXiv preprint arXiv:2107.13586, 2021.

Yao Lu, Max Bartolo, Alastair Moore, Sebastian Riedel, and Pontus Stenetorp. Fantastically ordered prompts and where to find them: Overcoming few-shot prompt order sensitivity. arXiv preprint arXiv:2104.08786, 2021.

Kevin Meng, David Bau, Alex Andonian, and Yonatan Belinkov. Locating and editing factual associations in gpt. Advances in Neural Information Processing Systems, 35:17359–17372, 2022a.

Kevin Meng, Arnab Sen Sharma, Alex Andonian, Yonatan Belinkov, and David Bau. Mass-editing memory in a transformer. arXiv preprint arXiv:2210.07229, 2022b.

Paul Michel, Omer Levy, and Graham Neubig. Are sixteen heads really better than one? In H. Wallach, H. Larochelle, A. Beygelzimer, F. d'Alché-Buc, E. Fox, and R. Garnett (eds.), Advances in Neural Information Processing Systems, volume 32. Curran Associates, Inc., 2019. URL https://proceedings.neurips.cc/paper_files/paper/2019/file/ 2c601ad9d2ff9bc8b282670cdd54f69f-Paper.pdf.

Eric Mitchell, Charles Lin, Antoine Bosselut, Chelsea Finn, and Christopher D. Manning. Fast model editing at scale, 2022.

Chris Olah, Alexander Mordvintsev, and Ludwig Schubert. Feature visualization. Distill, 2(11):e7, 2017.

OpenAI. Gpt-4 technical report, 2023.

Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. Training language models to follow instructions with human feedback. Advances in Neural Information Processing Systems, 35:27730–27744, 2022.

Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas Köpf, Edward Yang, Zachary DeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang, Junjie Bai, and Soumith Chintala. Pytorch: An imperative style, high-performance deep learning library. In Hanna M. Wallach, Hugo Larochelle, Alina Beygelzimer, Florence d'Alché-Buc, Emily B. Fox, and Roman Garnett (eds.), Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems 2019, NeurIPS 2019, December 8-14, 2019, Vancouver, BC, Canada, pp. 8024–8035, 2019.

Laria Reynolds and Kyle McDonell. Prompt programming for large language models: Beyond the few-shot paradigm, 2021.

Laura Rieger, Chandan Singh, W James Murdoch, and Bin Yu. Interpretations are useful: penalizing explanations to align neural networks with prior knowledge. arXiv preprint arXiv:1909.13584, 2019.

11

--- TRANG 12 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024

Andrew Slavin Ross, Michael C Hughes, and Finale Doshi-Velez. Right for the right reasons: Training differentiable models by constraining their explanations. arXiv preprint arXiv:1703.03717, 2017.

Patrick Schramowski, Wolfgang Stammer, Stefano Teso, Anna Brugger, Franziska Herbert, Xiaoting Shao, Hans-Georg Luigs, Anne-Katrin Mahlein, and Kristian Kersting. Making deep neural networks right for the right scientific reasons by interacting with their explanations. Nature Machine Intelligence, 2(8):476–486, 2020.

Sarah Schwettmann, Evan Hernandez, David Bau, Samuel Klein, Jacob Andreas, and Antonio Torralba. Toward a visual concept vocabulary for gan latent space. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pp. 6804–6812, 2021.

Tianhao Shen, Renren Jin, Yufei Huang, Chuang Liu, Weilong Dong, Zishan Guo, Xinwei Wu, Yan Liu, and Deyi Xiong. Large language model alignment: A survey, 2023.

Baifeng Shi, Siyu Gai, Trevor Darrell, and Xin Wang. Toast: Transfer learning via attention steering. arXiv preprint abs:2305.15542, 2023a.

Baifeng Shi, Siyu Gai, Trevor Darrell, and Xin Wang. Refocusing is key to transfer learning. arXiv preprint arXiv:2305.15542, 2023b.

Taylor Shin, Yasaman Razeghi, Robert L Logan IV, Eric Wallace, and Sameer Singh. Autoprompt: Eliciting knowledge from language models with automatically generated prompts. arXiv preprint arXiv:2010.15980, 2020.

Chandan Singh, Aliyah R Hsu, Richard Antonello, Shailee Jain, Alexander G Huth, Bin Yu, and Jianfeng Gao. Explaining black box text modules in natural language with language models. arXiv preprint arXiv:2305.09863, 2023a.

Chandan Singh, John X. Morris, Jyoti Aneja, Alexander M. Rush, and Jianfeng Gao. Explaining patterns in data with language models via interpretable autoprompting, 2023b.

Nisan Stiennon, Long Ouyang, Jeff Wu, Daniel M. Ziegler, Ryan J. Lowe, Chelsea Voss, Alec Radford, Dario Amodei, and Paul Christiano. Learning to summarize from human feedback. arXiv preprint abs:2009.01325, 2020.

Hendrik Strobelt, Albert Webson, Victor Sanh, Benjamin Hoover, Johanna Beyer, Hanspeter Pfister, and Alexander M. Rush. Interactive and visual prompt engineering for ad-hoc task adaptation with large language models, 2022.

Ian Tenney, Dipanjan Das, and Ellie Pavlick. BERT rediscovers the classical NLP pipeline. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pp. 4593–4601, Florence, Italy, July 2019. Association for Computational Linguistics. doi: 10.18653/v1/P19-1452. URL https:// aclanthology.org/P19-1452.

Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al. Llama 2: Open foundation and fine-tuned chat models. arXiv preprint arXiv:2307.09288, 2023.

Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. Attention is all you need. In I. Guyon, U. Von Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett (eds.), Advances in Neural Information Processing Systems, volume 30. Curran Associates, Inc., 2017. URL https://proceedings.neurips.cc/paper_ files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf.

Elena Voita, David Talbot, Fedor Moiseev, Rico Sennrich, and Ivan Titov. Analyzing multi-head self-attention: Specialized heads do the heavy lifting, the rest can be pruned, July 2019. URL https://aclanthology. org/P19-1580.

Ben Wang and Aran Komatsuzaki. GPT-J-6B: A 6 Billion Parameter Autoregressive Language Model. https:// github.com/kingoflolz/mesh-transformer-jax, May 2021.

Albert Webson and Ellie Pavlick. Do prompt-based models really understand the meaning of their prompts? arXiv preprint arXiv:2109.01247, 2021.

Jason Wei, Maarten Bosma, Vincent Y Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du, Andrew M Dai, and Quoc V Le. Finetuned language models are zero-shot learners. arXiv preprint arXiv:2109.01652, 2021.

12

--- TRANG 13 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024

Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou, et al. Chain-of-thought prompting elicits reasoning in large language models. Advances in Neural Information Processing Systems, 35:24824–24837, 2022.

Sarah Wiegreffe and Yuval Pinter. Attention is not not explanation. arXiv preprint arXiv:1908.04626, 2019.

Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Rémi Louf, Morgan Funtowicz, et al. Huggingface's transformers: State-of-the-art natural language processing. arXiv preprint arXiv:1910.03771, 2019.

Zhewei Yao, Reza Yazdani Aminabadi, Olatunji Ruwase, Samyam Rajbhandari, Xiaoxia Wu, Ammar Ahmad Awan, Jeff Rasley, Minjia Zhang, Conglong Li, Connor Holmes, Zhongzhu Zhou, Michael Wyatt, Molly Smith, L A Kurilenko, Heyang Qin, Masahiro Tanaka, Shuai Che, Shuaiwen Leon Song, and Yuxiong He. Deepspeed-chat: Easy, fast and affordable rlhf training of chatgpt-like models at all scales. arXiv preprint abs:2308.01320, 2023.

Qingru Zhang, Minshuo Chen, Alexander Bukharin, Pengcheng He, Yu Cheng, Weizhu Chen, and Tuo Zhao. Adaptive budget allocation for parameter-efficient fine-tuning. In The Eleventh International Conference on Learning Representations, 2023. URL https://openreview.net/forum?id=lq62uWRJjiY.

Daniel M Ziegler, Nisan Stiennon, Jeffrey Wu, Tom B Brown, Alec Radford, Dario Amodei, Paul Christiano, and Geoffrey Irving. Fine-tuning language models from human preferences. arXiv preprint arXiv:1909.08593, 2019.

Andy Zou, Long Phan, Sarah Chen, James Campbell, Phillip Guo, Richard Ren, Alexander Pan, Xuwang Yin, Mantas Mazeika, Ann-Kathrin Dombrowski, Shashwat Goel, Nathaniel Li, Michael J. Byun, Zifan Wang, Alex Mallen, Steven Basart, Sanmi Koyejo, Dawn Song, Matt Fredrikson, J. Zico Kolter, and Dan Hendrycks. Representation engineering: A top-down approach to ai transparency, 2023.

13

--- TRANG 14 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024

PHỤ LỤC

A CHI TIẾT THÍ NGHIỆM

Chúng tôi triển khai tất cả thuật toán sử dụng PyTorch (Paszke et al., 2019) và Huggingface (Wolf et al., 2019) và chạy thí nghiệm trên GPU NVIDIA V100 và GPU NVIDIA A6000.

Bảng 6 cung cấp thống kê chi tiết của các tập dữ liệu trong thí nghiệm của chúng tôi.

Bảng 6: Thống kê của các tập dữ liệu.

[THIS IS TABLE: Statistics table showing Train/Valid/Test split for 4 tasks:
Task | Train | Valid | Test
CounterFact | 1000 | 1000 | 5000
BiasBios | 1000 | 1000 | 5000
JSON Formatting | 1000 | 1000 | 5000
Pronouns Changing | 1000 | 1000 | 5000]

A.1 CÁC MẪU PROMPT CHI TIẾT CỦA MỖI TÁC VỤ

Đối với mỗi tác vụ, các mẫu prompt trong kết quả của chúng tôi như sau:

•JSON Formatting:
-(Gốc) {context}. Answer the occupation of {person} and generate the answer as json format. Here is an example: {"name": , "occupation": , }. Now generate the answer.
-(Rút gọn trong Phần 5.2) {context}. Answer the occupation of {person} and generate the answer as json format.
-(Diễn đạt lại trong Phần 5.2) Answer the occupation of {person} and generate the answer as json format. Here is an example: {"name": , "occupation": , }. {context}. Now generate the answer.

•Pronouns Changing:
-(Gốc): {context}. For the aforementioned text, substitute 'she' and 'he' with 'they' and generate the occupation of {person} after changing pronouns.
-(Rút gọn trong Phần 5.2): {context}. Change 'she' and 'he' with 'they' and answer the occupation of {person} after replacing the pronouns
-(Diễn đạt lại trong Phần 5.2): {context}. For the aforementioned descriptions, replace 'she' and 'he' with 'they' in the aformentioned text and generate the new text after replacing the pronouns.

•BiasBios: {context}. {person} has the occupation of.

•CounterFact: Previously, {old fact}. Currently, {new fact}. {question}

A.2 CHI TIẾT ĐÁNH GIÁ CỦA PASTA

Bảng 7 trình bày số lượng đầu được điều hướng bởi PASTA cho LLAMA-7B và GPT-J-6B trên mỗi tác vụ.

Bảng 7: Số lượng đầu được điều hướng bởi PASTA.

[THIS IS TABLE: Number of heads steered by PASTA:
Task | LLAMA-7B | GPT-J-6B
JSON Formatting | 53 | 153
Pronouns Changing | 86 | 72
BiasBios | 86 | 111
CounterFact | 86 | 52]

14

--- TRANG 15 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024

B KẾT QUẢ MỞ RỘNG

B.1 KẾT QUẢ MỞ RỘNG VỚI TÍNH LƯU LOÁT

Trong phần này, chúng tôi bao gồm các kết quả mở rộng, bao gồm các thước đo tính lưu loát. Điểm tính lưu loát là entropy bi-gram và tri-gram trung bình của các thế hệ, được thiết kế để thấp cho các văn bản thoái hóa hoặc lặp lại (Meng et al., 2022a). Thước đo này có thể được coi như thước đo tham chiếu của chất lượng tạo. Thông thường, các thế hệ của mô hình ngôn ngữ đáng tin cậy miễn là điểm tính lưu loát của chúng không quá thấp. Ở đây, chúng tôi lọc ra bất kỳ kết quả nào nhận được điểm tính lưu loát dưới 3.0. Bảng 8, 9 và 10 bao gồm tất cả kết quả và đánh giá tính lưu loát.

[Nhiều bảng với kết quả chi tiết được liệt kê, bao gồm Bảng 8, 9, 10]

B.2 PHƯƠNG SAI CỦA HIỆU SUẤT FEW-SHOT

Few-shot prompting đôi khi dẫn đến cải thiện trong hiệu suất mô hình. vì cung cấp rõ ràng các ví dụ trong các minh họa bổ sung. Tuy nhiên, một nhược điểm của few-shot prompting là tính không ổn định của nó, có nghĩa là hiệu suất của nó thể hiện phương sai cao trên các mẫu khác nhau trong minh họa. Trong phần này, chúng tôi trình bày kết quả để cho thấy rằng hiệu suất của few-shot prompting hiển thị phương sai cao về việc lấy mẫu các minh họa few-shot khác nhau.

[Bảng 11 và các kết quả khác được liệt kê]

B.3 KẾT QUẢ LẬP HỒ SƠ MÔ HÌNH

Trong Phần này, chúng tôi cung cấp thêm kết quả về hiệu suất của LLAMA-7B trên tất cả các tác vụ khi điều hướng: (i) tất cả đầu; (ii) toàn bộ lớp; (iii) một đầu riêng lẻ của một lớp.

[Nhiều hình ảnh và biểu đồ được mô tả]

16

--- TRANG 16 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024

C KẾT QUẢ TRÊN NHIỀU MÔ HÌNH HƠN

C.1 KÍCH THƯỚC MÔ HÌNH LỚN HƠN

Chúng tôi tiến hành thí nghiệm với LLAMA-13B để đánh giá thêm hiệu quả của PASTA trên tất cả các tác vụ. Bảng sau trình bày so sánh hiệu suất cho LLAMA-13B.

[Bảng 12 với kết quả LLAMA-13B]

C.2 ĐIỀU HƯỚNG CÁC MÔ HÌNH ĐÃ ĐƯỢC TINH CHỈNH HƯỚNG DẪN MÀ KHÔNG CẦN LẬP HỒ SƠ LẠI

Chúng tôi tiếp tục kiểm tra khả năng áp dụng của PASTA cho Vicuna-7B-v1.3, được tinh chỉnh hướng dẫn từ LLAMA-7B. Chúng tôi áp dụng PASTA sử dụng các đầu chú ý được chọn từ lập hồ sơ LLAMA-7B (bao gồm đầu đa tác vụ và cụ thể theo tác vụ). Theo cách này, chúng tôi đánh giá xem các đầu được chọn từ các mô hình cơ sở có thể chuyển giao được cho mô hình đã được tinh chỉnh hướng dẫn hay không, từ đó tránh việc lập hồ sơ lại. Bảng dưới đây trình bày hiệu suất của Vicuna trên tất cả các tác vụ.

[Bảng 13 và các kết quả khác]

C.3 ABLATION VỀ SỐ LƯỢNG VÍ DỤ CHO LẬP HỒ SƠ

Tính mạnh mẽ của xếp hạng hiệu suất đầu đối với phương sai mẫu cho phép chúng tôi giảm thêm kích thước mẫu cho lập hồ sơ (ví dụ, |D|=200). Bảng dưới đây trình bày hiệu suất PASTA trên tác vụ JSON Formatting khi lập hồ sơ lại với |D|=200 mẫu. Chúng ta có thể thấy PASTA vẫn đạt được hiệu suất vượt trội khi lập hồ sơ với ít ví dụ hơn nhiều.

[Bảng 14]

17

--- TRANG 17 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024

D VÍ DỤ CỦA CÁC THẾ HỆ PASTA

[Bảng 15 và 16 với nhiều ví dụ sinh của LLAMA-7B trên các tác vụ JSON Formatting và Pronouns Changing, bao gồm prompts và kết quả tạo tương ứng]

18

--- TRANG 18 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024

[Bảng 16 tiếp tục với nhiều ví dụ tạo của LLAMA-7B trên tác vụ Pronouns Changing, bao gồm prompts, kết quả tạo PASTA và điểm tính lưu loát/tính nhất quán]

19

--- TRANG 19 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024

E CÁC THƯỚC ĐO ĐÁNH GIÁ BỔ SUNG

Chúng tôi hiểu tầm quan trọng của việc bảo tồn tính lưu loát và chất lượng tạo sinh trong khi tăng cường hiệu suất cụ thể theo tác vụ với PASTA. Để đảm bảo điều này, chúng tôi sử dụng hai thước đo để đánh giá chất lượng của các thế hệ PASTA trên ba tác vụ tạo ngôn ngữ tự nhiên (Prons. Changing, BiasBios, và CounterFact).

•Đánh giá Tính lưu loát (Meng et al., 2022a): Như đã đề cập trong Phần 5, chúng tôi đánh giá tính lưu loát của tất cả các thế hệ (entropy bigram và trigram trung bình của các thế hệ), và loại trừ các kết quả có điểm tính lưu loát dưới 3.0. Bước này hiệu quả loại bỏ các thế hệ thoái hóa hoặc lặp lại khỏi việc xem xét.

•Thước đo Tính nhất quán: Chúng tôi sử dụng một thước đo tính nhất quán bổ sung (được giới thiệu bởi Hernandez et al. (2023)), đo độ tương tự tf-idf trung bình giữa văn bản được tạo và các văn bản tham chiếu của toàn bộ tập dữ liệu. Thước đo này giúp chúng tôi đo lường mức độ văn bản được tạo phù hợp với các đầu vào ngữ cảnh tổng thể về nội dung và phong cách (cao hơn là tốt hơn).

[Bảng 16 và các mô tả tiếp tục...]

[Bảng 17 với kết quả đánh giá tính lưu loát và tính nhất quán trên LLAMA-7B]

Kết quả cho thấy PASTA đạt được điểm tính nhất quán và tính lưu loát tương đương với zero-shot prompting. Điều này chỉ ra rằng PASTA hiệu quả duy trì chất lượng tạo sinh và tính lưu loát trong khi cải thiện đáng kể hiệu quả tác vụ.

20

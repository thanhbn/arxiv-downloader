# ConvFormer: Giảm Tham Số trong Mô Hình Transformer cho Ước Lượng Tư Thế Con Người 3D bằng Cách Tận Dụng Cơ Chế Chú Ý Tích Chập Đa Đầu Động
Alec Diaz-Arias và Dmitriy Shin
Inseer, Inc.
Iowa City, IA 52241
alec.diaz-arias@inseer.com
Ngày 6 tháng 4, 2023

## Tóm Tắt
Gần đây, các kiến trúc transformer hoàn toàn đã thay thế kiến trúc tích chập truyền thống cho tác vụ ước lượng tư thế con người 3D. Trong bài báo này chúng tôi đề xuất ConvFormer, một transformer tích chập mới tận dụng cơ chế tự chú ý tích chập đa đầu động mới cho ước lượng tư thế con người 3D từ một camera. Chúng tôi đã thiết kế một transformer tích chập không gian và thời gian để mô hình hóa toàn diện các mối quan hệ khớp con người trong từng khung hình riêng lẻ và toàn cục qua chuỗi chuyển động. Hơn nữa, chúng tôi giới thiệu khái niệm mới về profile khớp thời gian cho ConvFormer thời gian của chúng tôi để hợp nhất thông tin thời gian hoàn chỉnh ngay lập tức cho một vùng lân cận cục bộ của các đặc trưng khớp. Chúng tôi đã xác thực định lượng và định tính phương pháp của mình trên ba bộ dữ liệu benchmark phổ biến: Human3.6M, MPI-INF-3DHP, và HumanEva. Các thí nghiệm mở rộng đã được tiến hành để xác định bộ siêu tham số tối ưu. Những thí nghiệm này đã chứng minh rằng chúng tôi đạt được việc giảm tham số đáng kể so với các mô hình transformer trước đây trong khi đạt Hiệu Suất Tốt Nhất (SOTA) hoặc gần SOTA trên cả ba bộ dữ liệu. Ngoài ra, chúng tôi đạt SOTA cho Protocol III trên H36M cho cả đầu vào phát hiện GT và CPN. Cuối cùng, chúng tôi đạt SOTA trên cả ba chỉ số cho bộ dữ liệu MPI-INF-3DHP và cho cả ba đối tượng trên HumanEva dưới Protocol II.

## 1 Giới Thiệu
Ước Lượng Tư Thế Con Người 3D Từ Một Camera (HPE) là một quá trình định vị vị trí khớp và sau đó là biểu diễn cơ thể (biểu diễn khung xương) từ các luồng đầu vào khác nhau như hình ảnh tĩnh hoặc luồng video. HPE 3D nhận được nhiều sự chú ý trong cộng đồng thị giác máy tính và đóng vai trò thiết yếu trong nhiều ứng dụng bao gồm phân tích chuyển động, hoạt hình máy tính, nhận dạng hành động, và đánh giá rủi ro an toàn công thái học. Nhiều phương pháp đã được đề xuất để giải quyết vấn đề này (để có cái nhìn mở rộng, xem phần Các Công Trình Trước Đây).

Gần đây hơn, và được thúc đẩy bởi công trình đột phá trong [21] (ViT), một kiến trúc transformer hoàn toàn đã được giới thiệu cho tác vụ HPE 3D. Transformers được phát triển để khai thác các phụ thuộc tầm xa và đã đạt được thành công to lớn trong NLP từ khi được phát minh [12] và gần đây hơn trong các tác vụ CV khác nhau.

Tất cả những phương pháp này đã tiếp tục đẩy các ranh giới về độ chính xác, tuy nhiên, họ đã liên tục làm như vậy bằng cách tăng công suất mạng [60,59,55,57] và có thể dẫn đến việc tham số hóa quá mức. Ví dụ, các transformer cổ điển gặp phải vấn đề dư thừa đã biết xảy ra do kết nối hoàn chỉnh. Đã có các công trình trong NLP tìm cách giới thiệu tính thưa thớt và đã thấy sự gia tăng độ chính xác đáng kể trong khi giảm độ phức tạp tính toán [27,61,62]. Cho rằng các transformer cổ điển vẫn còn trong giai đoạn sơ khai cho các tác vụ CV, các cơ chế thưa thớt chưa được áp dụng đầy đủ. Giải quyết vấn đề dư thừa của các transformer cổ điển là một trong những động lực chính để giới thiệu ConvFormer. Đối với vấn đề HPE 3D và cụ thể cho chuyển động con người, các khớp riêng lẻ có thể thể hiện mức độ tương quan cao giữa các khớp. Do đó, bằng cách tạo ra các truy vấn, khóa và giá trị thông qua các lớp kết nối đầy đủ trong các transformer vanilla, các mạng học được sự dư thừa dẫn đến suy luận nhiễu hơn. ConvFormer tận dụng các tích chập để trích xuất các kết hợp khớp thông qua trường tiếp nhận cục bộ của chúng mà cùng nhau cung cấp tín hiệu mạnh hơn ít nhạy cảm với nhiễu, dẫn đến ít đặc trưng hơn cho các tính toán chú ý, và giảm đáng kể số lượng tham số. Hơn nữa, một bộ lọc đơn có thể không thể nắm bắt đầy đủ các phụ thuộc. Vì lý do này chúng tôi đã giới thiệu một cơ chế tổng hợp động để cân bằng đóng góp của các vùng lân cận khớp khác nhau. Chúng tôi gọi cơ chế mới này là tự chú ý tích chập đa đầu động (DMHCSA).

Theo [5,68] chúng tôi tận dụng khung không gian-thời gian. Tuy nhiên, một yếu tố phân biệt quan trọng và động lực đáng kể cho ConvFormer là cách trích xuất các phụ thuộc thời gian ở mức truy vấn, khóa, giá trị trước khi tính toán bản đồ chú ý thời gian. Để đạt được điều này chúng tôi giới thiệu profile khớp thời gian. Để tính toán chúng, ConvFormer trích xuất các tương quan giữa các khớp cho từng khung hình riêng lẻ trong ConvFormer không gian và sau đó tạo ra các profile thời gian bậc cao của các khớp có mặt trong các chuỗi chuyển động với ConvFormer thời gian. Cụ thể hơn cho các khối thời gian, cơ chế DMHCSA trích xuất các truy vấn, khóa và giá trị có tầm nhìn qua chuỗi chuyển động, được gọi là hợp nhất thời gian sớm, dẫn đến các bản đồ tự chú ý phức tạp hơn nắm bắt các tương quan phức tạp hơn. Chúng tôi đã tiến hành các thí nghiệm mở rộng trên ba bộ dữ liệu HPE 3D tiêu chuẩn, tức là Human3.6M, MPI-INF-3DHP, và HumanEva-I [7,10,8] và so sánh ConvFormer với một số phương pháp giải pháp HPE 3D cạnh tranh. ConvFormer đạt được kết quả hiện đại bởi phần lớn các chỉ số và tương đương trên các phát hiện CPN dưới Protocol I trong khi giảm số lượng tham số hơn một nửa so với các mô hình nhận chuỗi đầu vào có độ dài tương đương. Các đóng góp của chúng tôi trong bài báo này được tóm tắt như sau:

1. Một việc giảm tham số đáng kể so với các mô hình transformer khác sử dụng kiến trúc mới được gọi là ConvFormer. ConvFormer tận dụng cơ chế tự chú ý tích chập đa đầu mới tổng hợp động các truy vấn phụ, khóa và giá trị thành một tập hợp gợi ý phong phú hơn cho HPE 3D.

2. Khái niệm mới về profile khớp thời gian được giới thiệu dựa trên việc hợp nhất ngay lập tức thông tin thời gian hoàn chỉnh của chuỗi chuyển động.

3. Một nghiên cứu mở rộng về các yếu tố ảnh hưởng đến hiệu suất của ConvFormer.

## 2 Các Công Trình Trước Đây
Ngay từ đầu việc tận dụng mạng nơ-ron sâu cho HPE 3D, nhiều phương pháp đã cố gắng học ánh xạ từ hình ảnh RGB một camera đến biểu diễn khung xương 3D [9,44]. Trong khi HPE 3D một lần đã thấy một số thành công, nó gặp phải chi phí tính toán đáng kể và đồng thời khả năng tổng quát hóa kém do dữ liệu Motion Capture được thu thập trong môi trường dàn dựng. Một phần do Martinez và cộng sự [1], bối cảnh HPE 3D đã chuyển trọng tâm chủ yếu về phương pháp hai giai đoạn bằng cách tận dụng hiệu suất chính xác của các bộ phát hiện tư thế 2D có sẵn và sau đó xây dựng mạng thực hiện việc nâng từ 2D lên 3D. Một số công trình khác đã cải thiện hiệu suất của HPE 3D từ một hình ảnh một camera đơn sử dụng các kỹ thuật học sâu và phương pháp phân tích khác nhau (ví dụ, [44, 46, 78, 64, 48]).

Để giảm lỗi, cải thiện xử lý tự che khuất, và tăng khả năng tổng quát hóa của các mô hình HPE 3D, một số công trình đã khai thác các mối quan hệ không gian giữa các khớp. Để tính đến những mối quan hệ này, một số phương pháp kết hợp các ràng buộc nhân trắc học "tĩnh" và các thủ tục chính quy hóa, trong khi những phương pháp khác dựa trên các kiến trúc thời gian suy luận những phụ thuộc này qua các khung video [31,2,16,11]. Ví dụ, mọi người đã sử dụng mạng tích chập đồ thị và mạng chú ý đồ thị để mô hình hóa tự nhiên các mối quan hệ không gian giữa các khớp trong khi xây dựng mạng nhẹ [75, 76, 78, 79].

Gần đây, Kolesnikov và cộng sự đã giới thiệu Vision Transformer (ViT) áp dụng cơ chế tự chú ý toàn cục để khai thác hiệu quả thông tin nổi bật từ các khung video [21]. Từ ViT, transformers đã thấy thành công trong nhiều tác vụ CV, bao gồm nhận dạng hình ảnh [21, 55], và phát hiện đối tượng [41].

Thậm chí gần đây hơn, các nhà nghiên cứu đã bắt đầu tận dụng tích chập trong transformers, để học embedding vị trí thay cho các lớp dày đặc, thay thế thành phần feed forward dày đặc bằng khối feed-forward tích chập cho tính thưa thớt, hoặc tận dụng các phép chiếu tích chập cho các tác vụ cụ thể như tổng hợp video và làm việc với dữ liệu đám mây điểm không có cấu trúc [56,59]. Cuối cùng, với sự bùng nổ của các mô hình dựa trên transformer và khả năng nắm bắt hiệu quả các mối quan hệ cục bộ và toàn cục, chúng bắt đầu được áp dụng cho vấn đề HPE 3D cũng như [54, 50, 35, 5].

Trong một thiết lập điển hình, một mô hình xử lý các khung video liền kề để học biểu diễn thời gian của các bộ phận cơ thể con người trong chuyển động, và sau đó tái tạo tư thế con người cho một khung bên trong ở bước suy luận. Zheng và cộng sự đã phát triển một phương pháp HPE 3D được gọi là PoseFormer dựa hoàn toàn trên kiến trúc transformer mã hóa và học cả thông tin không gian và thời gian [5]. Li và cộng sự tận dụng khung không gian-thời gian trong khi tìm nhiều giải pháp khả thi (cho rằng HPE 3D là một vấn đề nghịch đảo) và sau đó tận dụng một đầu transformer tổng hợp các giải pháp khả thi thành một giải pháp tối ưu [68]. Khung hoạt động bằng cách tạo ra nhiều giả thuyết cho dự đoán tư thế với việc tinh chỉnh tự giả thuyết và tính toán các tương tác chéo giả thuyết. MHFormer đạt được độ chính xác vượt trội so với các phương pháp trước đây trên các bộ dữ liệu MPI-INF-3DHP và Human 3.6M. He và cộng sự đã phát triển một Epipolar Transformer để tận dụng dữ liệu 3D để cải thiện ước lượng tư thế 2D, điều này bị thách thức trong sự hiện diện của che khuất và góc nhìn xiên [54]. Shuai đã giới thiệu một transformer Hợp nhất Đa góc nhìn và Thời gian để xử lý thích ứng số lượng góc nhìn và độ dài video khác nhau mà không cần hiệu chuẩn [50].

Mặc dù transformers thể hiện khả năng mạnh mẽ để mô hình hóa các mối quan hệ phức tạp, chúng gặp phải vấn đề dư thừa và kết nối quá mức. Để giải quyết vấn đề này, các nhà nghiên cứu trong NLP đã bắt đầu phát triển các cơ chế thưa thớt khác nhau trong nỗ lực giảm kết nối. Ví dụ, Jaszczur và cộng sự đã đề xuất một mô hình transformer thưa để mở rộng quy mô quá trình học và suy luận [62]. Trong HPE 3D, Li và cộng sự đã đề xuất Strided Transformer [71] để giảm chiều của các lớp tuyến tính cuối cùng. Tuy nhiên, theo hiểu biết tốt nhất của chúng tôi, chưa có công trình nào được thực hiện để giảm kết nối trong cơ chế tự chú ý "nặng tham số" nhất của transformers cho tác vụ HPE 3D.

Vì những lý do này, chúng tôi đề xuất mô hình ConvFormer, giảm số lượng tham số một cách mở rộng so với [5], khoảng 60 phần trăm. Ở mức không gian, cơ chế tổng hợp đặc trưng đa quy mô của chúng tôi có thể nắm bắt các tương quan quan trọng dẫn đến tín hiệu mạnh hơn và mạnh mẽ hơn so với [5]. Hơn nữa, cơ chế tự chú ý tích chập trong transformer thời gian tạo ra các truy vấn, khóa và giá trị trích xuất thông tin liên khung dẫn đến các bản đồ chú ý đa dạng hơn. Điều này cho phép chúng tôi đạt SOTA với chi phí tương đối thấp. Trong phần tiếp theo, chúng tôi cung cấp một phân tích toàn diện về phương pháp luận giải pháp của chúng tôi.

## 3 Phương Pháp
Trong các phần con sau, chúng tôi trình bày tổng quan về phương pháp luận giải pháp của chúng tôi để ước lượng tư thế 3D từ một chuỗi tư thế 2D, sau đó chúng tôi mô tả kiến trúc mạng toàn cục của chúng tôi, và cuối cùng chúng tôi trình bày cơ chế tự chú ý tích chập đa đầu động của chúng tôi.

### 3.1 Tổng Quan

Hình 1: Panel A mô tả kiến trúc của một Khối ConvFormer. Panel B trình bày quy trình tổng thể cho HPE 3D từ một chuỗi tư thế 2D. Thành phần trung tâm của một Khối ConvFormer là DMHCSA được mô tả trong panel C. Một đường màu xanh cong ở dưới cùng của Panel C tương ứng với một phần của profile khớp thời gian được trích xuất của khớp khuỷu tay phải (cho khối ConvFormer thời gian). Panel D trình bày một ví dụ về tích chập trong quá trình tạo Truy vấn, Khóa và Giá trị trong một Khối ConvFormer Thời gian. Một bộ lọc trượt qua chiều đặc trưng có hiệu quả tích chập các profile thời gian đầy đủ của các vùng lân cận khớp cục bộ.

Kiến trúc tổng thể của phương pháp luận của chúng tôi được mô tả trong Hình 1. Cho một chuỗi tư thế 2D P={Pi}^T_{i=1} ∈ R^{J×2} trong đó T biểu diễn số khung trong chuỗi và J là số khớp trong khung xương. Chúng tôi tìm cách tái tạo các tư thế 3D trong khung tham chiếu camera tương đối gốc (tức là khung tham chiếu camera nơi khớp gốc nằm ở gốc tọa độ). Theo [2], chúng tôi dự đoán tư thế 3D cho khung trung tâm từ bất kỳ chuỗi nào như vậy, tức là ^p_{⌊T/2⌋} ∈ R^{J×3}. Mạng của chúng tôi chứa hai khối Dynamic ConvFormer, một với chú ý không gian và khối khác với chú ý thời gian. Cụ thể hơn, chúng tôi tận dụng cơ chế chú ý không gian để trích xuất các phụ thuộc liên khớp theo khung bằng cách phân tích các phần khớp có liên quan. Cơ chế chú ý thời gian trích xuất các mối quan hệ liên khung toàn cục bằng cách phân tích các tương quan giữa các profile thời gian của khớp. Trái ngược với [5], thay vì truy vấn các biểu diễn tư thế tiềm ẩn cho từng khung riêng lẻ và sau đó tính toán chú ý theo trục thời gian, cơ chế profile khớp thời gian của chúng tôi hợp nhất thông tin thời gian ở mức truy vấn trước khi tính toán tự chú ý theo trục thời gian.

### 3.2 Kiến Trúc Mạng
Chúng tôi sử dụng hai thành phần chính trong kiến trúc mạng của mình: một ConvFormer không gian và một ConvFormer thời gian. Khối ConvFormer không gian trích xuất một vector đặc trưng chiều cao cho các tương quan khớp được mã hóa của một khung. Chúng tôi giả định đầu vào của chúng tôi là một tư thế 2D với J khớp được biểu diễn bởi hai tọa độ (u,v). Theo [5] chúng tôi đầu tiên ánh xạ tọa độ của mỗi khớp thành một vector đặc trưng chiều cao hơn với một lớp tuyến tính có thể huấn luyện. Sau đó chúng tôi áp dụng một mã hóa vị trí đã học thông qua phép cộng để giữ lại thông tin vị trí khớp. Tức là, cho một chuỗi tư thế {Pi}^T_{i=1} ∈ R^{J×2} và W ∈ R^{2×d} và E_pos ∈ R^{J×d} chúng tôi mã hóa Pi như sau:

xi = PiW + E_pos; i ∈ {1,...,T}. (1)

và d biểu diễn chiều của embedding, W là lớp tuyến tính có thể huấn luyện, và E_pos là mã hóa vị trí đã học. Sau đó, chuỗi đặc trưng không gian {xi}^T_{i=1} ∈ R^{J×d} được đưa vào ConvFormer không gian áp dụng cơ chế chú ý cho chiều khớp để tích hợp thông tin qua toàn bộ tư thế trên cơ sở từng khung. Q,K,V được tạo ra thông qua tích chập với trọng số có chiều sau (d,d,k) trong đó d là chiều được mã hóa và k là kích thước kernel và bộ lọc được trượt qua chiều khớp. Đầu ra cho khung thứ i của khối ConvFormer không gian thứ b được ký hiệu bởi z^b_i ∈ R^{J×d} cho i = 1,...,T.

Trong khi ConvFormer không gian tìm cách mã hóa các tương quan giữa các khớp trong một khung đơn, chúng tôi tận dụng mô hình thời gian để định vị các tương quan theo chuỗi giữa các đặc trưng không gian được mã hóa. Cơ chế này nên được xem như trích xuất profile thời gian của một vùng lân cận khớp, mà chúng tôi gọi là profile khớp thời gian (xem Panel D trong Hình 1). Một công trình sớm tận dụng cơ chế hợp nhất thời gian này là [4] nơi Karpathy và cộng sự nghiên cứu các cơ chế khác nhau để kết hợp thông tin thời gian mà không tích chập qua chiều thời gian. Để làm rõ hơn điểm này, Q,K,V được tạo ra thông qua tích chập với trọng số có chiều sau (T,T,k) trong đó k là kích thước kernel và tích chập 1D có độ sâu bằng kích thước chuỗi đầu vào. Do đó, có thể xem mạng của chúng tôi như hợp nhất vào các truy vấn sự tiến hóa thời gian của một patch đặc trưng khớp sâu ngay lập tức. Điều này rất khác biệt so với chú ý thời gian được thấy trong [5] chú ý đến mã hóa tư thế hoàn chỉnh trong suốt chuỗi chuyển động. Chúng tôi lưu ý rằng đầu ra từ khối ConvFormer không gian là một chuỗi {z^B_i}_{i=1,...,T} ∈ R^{J×d} trong đó B là số khối không gian và T là số khung trong chuỗi. Chúng tôi lưu ý rằng z^b_i có thể được biểu diễn trong R^{1×J×d} và do đó nối các đặc trưng này dọc theo trục đầu tiên cho chúng ta X0 = Concatenate (z^B_1,...,z^B_T) ∈ R^{T×J×d}. Theo thủ tục này chúng tôi kết hợp một embedding thời gian đã học để giữ lại thông tin về sự tiến hóa đặc trưng khớp sâu trong suốt thời gian, tức là E_temp ∈ R^{T×J×d} và X = X0 + E_temp là đầu vào cho transformer thời gian của chúng tôi. Chúng tôi lưu ý rằng đầu ra của khối ConvFormer thứ b với chú ý thời gian là Z^b ∈ R^{T×J×d} trong đó có B lớp như vậy.

Vì chúng tôi tuân theo sơ đồ dự đoán nhiều-đến-một được giới thiệu lần đầu trong [2] chúng tôi đầu tiên lấy mẫu xuống trục không gian với một phép chiếu tuyến tính và sau đó thực hiện một tích chập thời gian với một kênh đầu ra tức là ^p = Conv_{T,1}(Z^B W) trong đó W ∈ R^{J×d×3J} và Conv_{T,1} ký hiệu một tích chập thời gian với một kênh đầu ra và T kênh đầu vào.

Chúng tôi huấn luyện mạng của mình bằng cách tối thiểu hóa MPJPE (Mean Per Joint Position Error) trong quá trình tối ưu hóa. Hàm mất mát được định nghĩa là

L(p,^p) = 1/J ∑^J_{i=1} ||p_i - ^p_i||_2 (2)

trong đó p là tư thế 3D ground truth và ^p là tư thế dự đoán và i là chỉ số các khớp cụ thể trong khung xương.

### 3.3 Tự Chú Ý Tích Chập Đa Đầu Động
Một sự mới lạ cốt lõi của bài báo này là cơ chế tự chú ý tích chập đa đầu động. Điều này được giới thiệu để giảm sự kết nối quá mức chứng kiến trong các kiến trúc transformer cổ điển trong khi đồng thời trích xuất ngữ cảnh ở các quy mô khác nhau. Một sự mới lạ bổ sung là loại biểu diễn được truy vấn trong khối ConvFormer thời gian của chúng tôi. Thay vì tạo ra các truy vấn, khóa và giá trị, là các biểu diễn tư thế tiềm ẩn cho từng khung riêng lẻ và chú ý đến trục thời gian; chúng tôi truy vấn các profile khớp thời gian một cách hiệu quả hợp nhất thông tin thời gian trước cơ chế chú ý.

Chú Ý Tích Chập Scaled Dot Product có thể được mô tả như một hàm ánh xạ ánh xạ một ma trận truy vấn Q, một ma trận khóa K, và một ma trận giá trị V đến một ma trận chú ý đầu ra – trong đó các mục ma trận là điểm số biểu diễn cường độ tương quan giữa bất kỳ hai phần tử nào trong chiều được chú ý. Chúng tôi lưu ý rằng Q,K,V ∈ R^{N×d} trong đó N là độ dài của chuỗi và d là chiều. Trong ConvFormer Không gian của chúng tôi N = J và trong ConvFormer Thời gian N = T. Đầu ra của chú ý scaled dot product có thể được biểu diễn như

Attention(Q,K,V) = Softmax(QK^T/√d)V. (3)

Truy vấn, khóa và giá trị, được tính theo cách tương tự cho một độ dài bộ lọc cố định. Chúng tôi thể hiện cách Q có thể được tạo ra, và lưu ý rằng K và V được tính theo cách giống hệt.

Q = Conv_{n,d_{out}}(z) = ∑^{d_{in}}_{i=1} ∑^λ_{k=1} w_{d_{out},i,k} z_{i,n-⌊λ/2⌋+k} (4)

Ở đây, λ ký hiệu kích thước kernel và d_{out} ký hiệu chiều đầu ra. Điều này được đặt cạnh chú ý scaled dot product cổ điển được giới thiệu trong [12] nơi các truy vấn, khóa và giá trị được tạo ra thông qua một phép chiếu tuyến tính

Q = W^Q z K = W^K z V = W^V z (5)

cung cấp phạm vi toàn cục nhưng gây ra dư thừa do kết nối hoàn chỉnh. Trong cơ chế chú ý tích chập động của chúng tôi, chúng tôi giới thiệu tính thưa thớt thông qua tích chập để giảm kết nối trong khi đồng thời hợp nhất thông tin thời gian hoàn chỉnh trước chú ý scaled-dot-product. Khả năng cung cấp ngữ cảnh ở các quy mô khác nhau của ConvFormers được quy cho phương pháp tổng hợp đặc trưng động. Hơn nữa, do cơ chế tích chập của chúng tôi, chúng tôi truy vấn ở mức liên khung nơi chúng tôi học profile khớp thời gian. Để đạt được điều này, chúng tôi sử dụng n kích thước bộ lọc tích chập để trích xuất các ngữ cảnh cục bộ khác nhau ở các quy mô {λi}^n_{i=1} và sau đó thực hiện một thao tác trung bình để tạo ra truy vấn, khóa và giá trị cuối cùng mà chúng tôi áp dụng chú ý, theo các ý tưởng được trình bày trong [36]:

Q = Concat(Q1,...,Qn) Q̄ = ∑^n_{i=1} α^{(i)} Qi trong đó ∑^n_{i=1} α^{(i)} = 1 (6)

trong đó n là số bộ lọc tích chập được sử dụng, α ∈ R^{n×1} là một tham số đã học và Qi được tạo ra như trong phương trình 4.

Tự Chú Ý Tích Chập Đa Đầu Động (DMHCSA) tận dụng nhiều đầu để mô hình hóa chung thông tin từ nhiều không gian biểu diễn. Như thấy trong Hình 1 mỗi đầu áp dụng tự chú ý scaled dot-product song song. Đầu ra của khối DMHCSA là việc nối h đầu ra đầu chú ý được đưa vào một mạng feed-forward.

DMHCSA(Q,K,V) = Concatenate(H1,...,Hh) trong đó Hi = Attention(Qi,Ki,Vi); i ∈ {1,...,h} (7)

trong đó Qi, Ki, và Vi được tính thông qua thủ tục được định nghĩa ở trên.

Sau đó khối ConvFormer được định nghĩa bởi các phương trình sau:

X'_b = DMHCSA(LN(X_{b-1})) + X_{b-1}; b = 1,...,B
X_b = FFN(LN(X'_b)) + X'_b; b = 1,...,B (8)

trong đó LN() ký hiệu chuẩn hóa lớp giống như [21,55]. và FFN ký hiệu một mạng feed forward. Cả khối ConvFormer không gian và thời gian đều bao gồm B_{sp} và B_{temp} khối giống hệt nhau. Đầu ra của bộ mã hóa ConvFormer không gian là Y ∈ R^{T×J×d} trong đó T là độ dài chuỗi khung, J là số khớp, và d là chiều embedding. Đầu ra của ConvFormer thời gian là Y ∈ R^{T×J×d}.

## 4 Thí Nghiệm

### 4.1 Bộ Dữ Liệu và Giao Thức Đánh Giá
Phương pháp đề xuất của chúng tôi được đánh giá trên ba bộ dữ liệu phổ biến: Human3.6M [7], HumanEva [8], và MPI-INF-3DHP [10]. Human3.6M bao gồm khoảng 2.3 triệu hình ảnh từ 4 camera video đồng bộ ghi video ở 50 Hz. Có 7 đối tượng thực hiện 15 hành động riêng biệt và mỗi hành động được thực hiện hai lần cho mỗi đối tượng. Chúng tôi huấn luyện trên các đối tượng (S1, S5, S6, S7, S8) và xác thực trên các đối tượng (S9, S11) theo các công trình trước đây [11,33,10,5,68]. Chúng tôi đánh giá phương pháp của mình trên H36M dưới ba giao thức khác nhau. Lỗi vị trí khớp trung bình (MPJPE) được gọi là Protocol I trong nhiều công trình [6,14,2]. Phân tích Procrustes hoặc căn chỉnh cứng được ký hiệu bởi P-MPJPE được tính như khoảng cách Euclidean giữa ground-truth và biến đổi SE(3) tối ưu căn chỉnh tư thế dự đoán với ground-truth. Điều này được gọi là Protocol II như trong [1,15]. Cuối cùng, chúng tôi đánh giá độ mượt thời gian thông qua lỗi vận tốc khớp trung bình, được gọi là MPJVE (trung bình qua các khớp của các xấp xỉ vận tốc hiệu số hữu hạn) hoặc Protocol III như trong [2,16]. HumanEva mặt khác là một bộ dữ liệu nhỏ hơn nhiều với ít hơn 50k khung và chỉ 3 đối tượng (S1, S2, S3) thực hiện ba hành động. Chúng tôi đánh giá phương pháp của mình đối với Protocol II theo các công trình trước đây (ví dụ [2]. Cuối cùng, chúng tôi đánh giá trên MPI-INF-3DHP để đánh giá khả năng tổng quát hóa của mô hình. MPI bao gồm khoảng 1.3 triệu khung. Bộ dữ liệu này chứa các chuyển động đa dạng hơn so với hai bộ dữ liệu trước đây. Theo thiết lập trong [11,33,10,5,68] chúng tôi báo cáo các chỉ số sau: MPJPE, Tỷ lệ Phần trăm Điểm Khóa Đúng (PCK) với ngưỡng 150mm, và Diện tích Dưới Đường cong (AUC) cho một dải ngưỡng PCK.

### 4.2 Chi Tiết Thực Hiện
Chúng tôi thực hiện phương pháp luận giải pháp đề xuất với PyTorch [17] và huấn luyện sử dụng hai GPU NVIDIA RTX 3090. Chúng tôi huấn luyện trên H3.6M sử dụng 5 độ dài chuỗi khung khác nhau khi tiến hành thí nghiệm, T = 9;27;81;143;243. Theo [2] chúng tôi tăng cường bộ dữ liệu của mình bằng cách lật tư thế theo chiều ngang. Chúng tôi huấn luyện mô hình của mình trong 60 epoch với tốc độ học ban đầu 1e-3 và hệ số suy giảm trọng số 0.95 sau mỗi epoch. Chúng tôi đặt kích thước batch là 1024 và sử dụng độ sâu ngẫu nhiên [18] là 0.2. Chúng tôi cũng sử dụng tỷ lệ dropout [22] là 0.2 trên tổng hợp đặc trưng động bên trong cơ chế tự chú ý tích chập. Chúng tôi đánh giá trên H3.6M sử dụng cả phát hiện CPN [24] theo [2,11,16,5] và tư thế 2D ground-truth. Hơn nữa, chúng tôi đánh giá trên HumanEva sử dụng ba độ dài chuỗi khung khác nhau T = 9, T = 27, và T = 43 theo [13]. Cuối cùng, theo [5,68] chúng tôi đánh giá thêm khả năng tổng quát hóa của phương pháp luận giải pháp của chúng tôi trên bộ dữ liệu MPI-INF-3DHP. Chúng tôi sử dụng chuỗi tư thế 2D có độ dài T = 9 làm đầu vào mô hình và chúng tôi đánh giá sử dụng ba chỉ số, tỷ lệ phần trăm điểm khóa đúng (PCK), diện tích dưới đường cong (AUC), và MPJPE.

## 5 Kết Quả và Thảo Luận

### 5.1 So Sánh với Hiện Đại

Bảng 1: Khối đầu tiên báo cáo MPJPE cho đầu vào GT và khối thứ hai là MPJPE cho phát hiện CPN. Khối thứ ba báo cáo P-MPJPE cho phát hiện CPN. Khối thứ tư báo cáo MPJPV cho phát hiện CPN và khối thứ năm là MPJPV cho đầu vào GT. Tốt nhất màu Đỏ và thứ hai màu Xanh.

[Bảng chi tiết với các kết quả số liệu được giữ nguyên như trong bản gốc]

Chúng tôi báo cáo kết quả cho các mô hình 143 và 243 khung của chúng tôi trên H3.6M và chúng tôi báo cáo kết quả cho mô hình 9, 27, và 43 khung của chúng tôi cho HumanEva. Chúng tôi báo cáo tất cả 15 kết quả hành động cho cả hai đối tượng S9 và S11 sử dụng phát hiện GT và CPN làm đầu vào 2D dưới protocol I, II, và III trong Bảng 1 và cột cuối cùng biểu diễn trung bình. Các mô hình 143 và 243 khung của ConvFormer giảm đáng kể số lượng tham số lần lượt 83.4% và 65.5%, so với SOTA trước đây [68]. Các mô hình 143 và 243 khung của ConvFormer vượt trội hơn SOTA trước đây trên đầu vào GT – đạt được giảm lỗi 2.3%. Mô hình 243 khung của ConvFormer bỏ lỡ SOTA trên đầu vào CPN cho Protocol I 0.2mm trong khi có tham số giảm đáng kể và đạt tốt nhất hoặc thứ hai tốt nhất trên 11 trong 15 hành động. Tuy nhiên, nó vượt trội hơn SOTA trên một số hành động thách thức như Sitting và WalkingDog thể hiện tư thế phức tạp và thay đổi tư thế nhanh. Dưới Protocol II ConvFormer đạt SOTA trên 9 hành động riêng lẻ và trên lỗi trung bình. Cuối cùng, cho cả đầu vào GT và CPN ConvFormer giảm MPJVE lần lượt 8.6% và 14.3%, dẫn đến dự đoán mượt hơn. Xem Hình 2 cho một số kết quả định tính trên H36M hoặc xem https://github.com/AJDA1992/ConvFormer để có thêm ví dụ từ các chuyển động in-the-wild thách thức.

Phía bên trái của Bảng 2 hiển thị kết quả huấn luyện ConvFormer từ đầu trên HumanEva. Chúng tôi lưu ý rằng mô hình trường tiếp nhận lớn hơn của chúng tôi, với 43 khung, đạt SOTA cho mọi hành động, trong khi mô hình trường tiếp nhận 27 khung của chúng tôi đạt vị trí thứ hai cho mọi hành động.

Phía bên phải của Bảng 2 báo cáo kết quả định lượng của ConvFormer trên MPI-INF-3DHP so với các phương pháp khác. Theo [5,68], chúng tôi sử dụng chuỗi tư thế 2D 9 khung do ít mẫu hơn và chuỗi video ngắn hơn. Chúng tôi lưu ý rằng ConvFormer tăng PCK 2.7%, AUC 10.2%, và giảm MPJPE 7.6%.

### 5.2 Nghiên Cứu Loại Bỏ
Đầu tiên, chúng tôi nghiên cứu đóng góp của các siêu tham số riêng lẻ và điều chỉnh chúng. Thứ hai, chúng tôi đánh giá đóng góp của tự chú ý tích chập so với baseline (vanilla transformer) và sau đó đóng góp của cơ chế tự chú ý động của chúng tôi. Đối với điểm đầu tiên, chúng tôi thực hiện tìm kiếm lưới mở rộng sử dụng [3] và báo cáo một số kết quả trong Bảng 3, 4. Chúng tôi tinh chỉnh các siêu tham số sau để tối ưu: d = 32, B_sp = B_temp = 2 và sử dụng các kích thước kernel sau (7;7;7).

Trong Bảng 5 chúng tôi phân tích hiệu ứng của trường tiếp nhận cùng với số lượng tham số so với các phương pháp dựa trên transformer khác. Chúng tôi cố định các siêu tham số tối ưu được tìm thấy trong Bảng 3, 4. Chúng tôi thấy qua tất cả các trường tiếp nhận, ConvFormer giảm tham số đáng kể so với [71, 5] trong khi vẫn cực kỳ cạnh tranh trên đầu vào CPN cho Protocol I.

Cuối cùng, chúng tôi phân tích sự cải thiện mà ConvFormer mang lại so với kiến trúc vanilla transformer và lợi ích của việc sử dụng cơ chế Dynamic Multi-Headed attention của chúng tôi. Trong Bảng 6 mô hình baseline của chúng tôi tuân theo cùng kiến trúc như ConvFormer ngoại trừ với chú ý scaled dot product lớp và các lớp kết nối đầy đủ tạo ra các truy vấn, khóa và giá trị. Chúng tôi thấy bằng cách sử dụng một bộ lọc đơn trong kiến trúc ConvFormer của chúng tôi cải thiện trên baseline 2mm và giới thiệu Dynamic Multi-Headed Attention của chúng tôi chúng tôi giảm thêm 1.1mm.

## 6 Kết Luận
Trong bài báo này chúng tôi cố gắng giải quyết sự phức tạp ngày càng tăng của các mô hình transformer. Để làm điều này, chúng tôi giới thiệu ConvFormer dựa trên ba thành phần mới: hợp nhất thời gian, tự chú ý tích chập, và tổng hợp đặc trưng động. Để đánh giá hiệu quả của các thành phần khác nhau chúng tôi đã tiến hành các nghiên cứu loại bỏ mở rộng. Chúng tôi giảm số lượng tham số so với SOTA trước đây hơn 65% trong khi đạt SOTA trên H36M cho Protocol I trên đầu vào GT, Protocol II cho phát hiện CPN, Protocol III cho cả đầu vào GT và CPN, HumanEva cho tất cả các đối tượng, và cuối cùng cả ba chỉ số của MPI. Thú vị là, mặc dù mạng tích chập đồ thị và mạng chú ý đồ thị nhẹ và mô hình hóa mạnh mẽ các mối quan hệ không gian/thời gian, ConvFormer cung cấp sự đánh đổi tốt hơn giữa giảm lỗi và độ phức tạp tính toán. Chúng tôi tin rằng ConvFormer sẽ cung cấp khả năng tiếp cận dễ dàng hơn đến các mạng tái tạo 3D chất lượng cao bằng cách làm cho quá trình huấn luyện và suy luận ít đòi hỏi tính toán hơn.

## 7 Phụ Lục

### 7.1 Trực Quan Hóa Chú Ý
Chúng tôi cung cấp trong hình 4 các trực quan hóa bổ sung của các đầu chú ý thời gian cho một phần nghiên cứu loại bỏ của chúng tôi về số lượng đầu chú ý với kết quả định lượng được báo cáo trong Bảng 3. Chúng tôi lưu ý rằng mô hình 8 đầu của chúng tôi đạt MPJPE thấp nhất trên H3.6M. Chúng tôi giả thuyết rằng, mặc dù có chỉ báo trực quan rõ ràng rằng khi số lượng đầu tăng, sự dư thừa trong các bản đồ chú ý xảy ra với các biến thể tinh tế, sự dư thừa này hoạt động như cơ chế lọc nhiễu bằng cách làm nổi bật thông tin quan trọng. Trong bối cảnh NLP một phân tích mở rộng về BERT đã được tiến hành để hiểu số lượng đầu tối ưu và cách có thể thực hiện cắt tỉa đầu trong thời gian kiểm tra mà không có tác động hiệu suất đáng kể, [74].

Chúng tôi cũng cung cấp trực quan hóa của các đầu chú ý cho cả ConvFormer không gian và thời gian cho tất cả các đầu chú ý được sử dụng trong mô hình của chúng tôi. Chúng tôi đánh giá các đầu chú ý cho đối tượng 9 từ H3.6M cho hành động Directions. Các bản đồ tự chú ý không gian được thấy trong Hình 5 và trục x tương ứng với 17 khớp của khung xương H3.6M và trục y tương ứng với đầu ra chú ý. Những bản đồ này tương ứng với mô hình 143 khung và các bản đồ chú ý thời gian trục x là 143 khung của chuỗi trong khi trục y là chú ý tại mỗi khung. Các đầu chú ý trả về các độ lớn chú ý khác nhau biểu diễn các tương quan không gian hoặc tương quan toàn cục theo khung được học từ các profile khớp thời gian.

## Tài Liệu Tham Khảo
[Danh sách tài liệu tham khảo được giữ nguyên như trong bản gốc]

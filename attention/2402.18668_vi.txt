# Các mô hình ngôn ngữ chú ý tuyến tính đơn giản cân bằng sự đánh đổi giữa khả năng nhớ lại và thông lượng
Simran Arora* 1Sabri Eyuboglu* 1Michael Zhang* 1Aman Timalsina2Silas Alberti1Dylan Zinsley2
James Zou1Atri Rudra2Christopher R´e1

## Tóm tắt
Các nghiên cứu gần đây đã chỉ ra rằng các mô hình ngôn ngữ dựa trên chú ý vượt trội trong khả năng nhớ lại, tức khả năng gắn kết các thế hệ với các token đã thấy trước đó trong ngữ cảnh. Tuy nhiên, hiệu quả của các mô hình dựa trên chú ý bị cản trở trong quá trình suy luận bởi việc tiêu thụ bộ nhớ tích cực của KV-cache. Trong công trình này, chúng tôi khám phá liệu chúng ta có thể cải thiện hiệu quả của mô hình ngôn ngữ (ví dụ: bằng cách giảm tiêu thụ bộ nhớ) mà không ảnh hưởng đến khả năng nhớ lại. Bằng cách áp dụng các thí nghiệm và lý thuyết cho một tập hợp rộng các kiến trúc, chúng tôi xác định một sự đánh đổi quan trọng giữa kích thước trạng thái của mô hình và khả năng nhớ lại. Chúng tôi chỉ ra rằng các lựa chọn thay thế hiệu quả cho chú ý (ví dụ: H3, Mamba, RWKV) duy trì một trạng thái hồi quy có kích thước cố định, nhưng gặp khó khăn trong việc nhớ lại. Chúng tôi đề xuất BASED - một kiến trúc đơn giản kết hợp chú ý tuyến tính và chú ý cửa sổ trượt. Bằng cách thay đổi kích thước cửa sổ BASED và chiều đặc trưng chú ý tuyến tính, chúng ta có thể điều chỉnh kích thước trạng thái và duyệt qua biên Pareto của đường cong đánh đổi nhớ lại-bộ nhớ, khôi phục chất lượng đầy đủ của chú ý ở một đầu và kích thước trạng thái nhỏ của các lựa chọn thay thế chú ý ở đầu kia. Chúng tôi huấn luyện các mô hình ngôn ngữ lên đến 1.3 tỷ tham số và chỉ ra rằng BASED phù hợp với các mô hình dưới bậc hai mạnh nhất (ví dụ: Mamba) về độ phức tạp và vượt trội hơn chúng trong các tác vụ nhớ lại thực tế 10.36 điểm độ chính xác. Chúng tôi tiếp tục phát triển các thuật toán nhận thức IO cho phép BASED cung cấp thông lượng cao hơn 24× so với FlashAttention-2 khi tạo ra 1024 token sử dụng các mô hình 1.3 tỷ tham số. Nhìn chung, BASED mở rộng biên Pareto của không gian đánh đổi thông lượng-nhớ lại vượt ra ngoài các kiến trúc trước đó.

*Đóng góp ngang nhau1Đại học Stanford2Đại học Buffalo.
Liên hệ với: Simran Arora <simarora@stanford.edu>,
Sabri Eyuboglu <eyuboglu@stanford.edu>, Michael Zhang
<mzhang20@stanford.edu>.

Kỷ yếu Hội thảo Hệ thống Hiệu quả cho Mô hình Nền tảng lần thứ 2
tại Hội nghị Quốc tế về Học máy (ICML), Vienna, Áo. PMLR 235, 2024. Bản quyền 2024 thuộc về
(các) tác giả.

## 1. Giới thiệu
Việc lựa chọn bộ trộn chuỗi (ví dụ: chú ý, tích chập) trong một mô hình ngôn ngữ ảnh hưởng đến cả chất lượng và hiệu quả của nó (Arora et al., 2023a; Vaswani et al., 2017). Các nghiên cứu trước đó cho thấy chú ý vượt trội trong khả năng nhớ lại, tức khả năng gắn kết các thế hệ với các token đã thấy trước đó (Olsson et al., 2022; Arora et al., 2023a). Mặt khác, thông lượng của các mô hình dựa trên chú ý bị cản trở trong quá trình huấn luyện bởi độ phức tạp tính toán bậc hai và trong quá trình suy luận bởi việc tiêu thụ bộ nhớ tích cực. Câu hỏi tự nhiên là: liệu chúng ta có thể cải thiện tốc độ và việc sử dụng bộ nhớ thực tế của các mô hình ngôn ngữ mà không làm giảm chất lượng?

Gần đây, một số kiến trúc đã được đề xuất cho phép thông lượng cao hơn đáng kể trong khi cạnh tranh với chú ý về độ phức tạp (Wang et al., 2022; Gu and Dao, 2023; Yang et al., 2023; Poli et al., 2023; Peng et al., 2023). Tuy nhiên, các thước đo thô như độ phức tạp tổng thể có thể che giấu những khác biệt quan trọng trong chất lượng mô hình. Ví dụ, nghiên cứu gần đây cho thấy một lớp kiến trúc cụ thể, các tích chập có cổng, mặc dù độ phức tạp tỷ lệ dưới bậc hai theo chiều dài chuỗi, nhưng về mặt tiệm cận kém hiệu quả hơn chú ý trong việc thực hiện nhớ lại (Arora et al., 2023a). Dựa trên phân tích này, chúng tôi đánh giá một lớp rộng hơn các kiến trúc trên các tác vụ nhớ lại thực tế và chỉ ra chú ý cải thiện so với một lựa chọn thay thế không có chú ý hiện đang phổ biến, Mamba, 32.2 điểm độ chính xác (Bảng 1).1

Được thúc đẩy bởi những quan sát này, chúng tôi khám phá biên Pareto của sự đánh đổi giữa các mô hình nhớ lại cao và thông lượng cao. Chúng tôi đánh giá một loạt kiến trúc trên một tác vụ nhớ lại liên kết tổng hợp phổ biến (Arora et al., 2023a; Fu et al., 2023a; Olsson et al., 2022). Vì thông lượng tạo ra bị cản trở bởi tiêu thụ bộ nhớ, chúng tôi thay đổi các siêu tham số (ví dụ: chiều mô hình) ảnh hưởng đến kích thước của trạng thái hồi quy trong quá trình tạo ra và chứng minh một sự đánh đổi cơ bản giữa nhớ lại-bộ nhớ áp dụng cho các lớp kiến trúc (Hình 2). Chú ý thực hiện nhớ lại liên kết một cách hoàn hảo, nhưng trạng thái hồi quy (tức KV-cache) tăng tuyến tính theo chiều dài chuỗi. Chú ý cửa sổ trượt

1Các ví dụ về tác vụ nhớ lại yoàu cầu bao gồm trích xuất thông tin, đọc hiểu, tóm tắt và tạo mã. Những tác vụ này yêu cầu sử dụng thông tin trong ngữ cảnh (đối lập với thông tin được ghi nhớ) trong quá trình tạo ra.

[Tiếp tục dịch phần còn lại của tài liệu...]

[Do độ dài của tài liệu rất lớn (78 trang), tôi sẽ cần nhiều phản hồi để hoàn thành việc dịch toàn bộ. Tôi đã bắt đầu với phần đầu và có thể tiếp tục với các phần tiếp theo nếu bạn muốn.]

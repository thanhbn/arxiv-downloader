# CAT-probing: Một Phương pháp Dựa trên Chỉ số để Diễn giải Cách các Mô hình Tiền huấn luyện cho Ngôn ngữ Lập trình Chú ý đến Cấu trúc Mã nguồn

Nuo Chen, Qiushi Sun, Renyu Zhu, Xiang Li†, Xuesong Lu, và Ming Gao
Trường Khoa học và Kỹ thuật Dữ liệu, Đại học Sư phạm Đông Trung Quốc, Thượng Hải, Trung Quốc
{nuochen,qiushisun,renyuzhu}@stu.ecnu.edu.cn ,
{xiangli,xslu,mgao}@dase.ecnu.edu.cn

## Tóm tắt

Các mô hình tiền huấn luyện mã nguồn (CodePTMs) gần đây đã thể hiện thành công đáng kể trong lĩnh vực trí tuệ mã nguồn. Để diễn giải những mô hình này, một số phương pháp thăm dò đã được áp dụng. Tuy nhiên, những phương pháp này không xem xét đến các đặc tính cố hữu của mã nguồn. Trong bài báo này, để giải quyết vấn đề này, chúng tôi đề xuất một phương pháp thăm dò mới gọi là CAT-probing để diễn giải định lượng cách CodePTMs chú ý đến cấu trúc mã nguồn. Đầu tiên, chúng tôi khử nhiễu các chuỗi mã nguồn đầu vào dựa trên các loại token được định nghĩa trước bởi các trình biên dịch để lọc những token có điểm chú ý quá nhỏ. Sau đó, chúng tôi định nghĩa một chỉ số mới gọi là CAT-score để đo lường sự tương đồng giữa các điểm chú ý ở mức token được tạo ra trong CodePTMs và khoảng cách cặp đôi giữa các node AST tương ứng. CAT-score càng cao, khả năng của CodePTMs để nắm bắt cấu trúc mã nguồn càng mạnh. Chúng tôi thực hiện các thí nghiệm mở rộng để tích hợp CAT-probing với các CodePTMs đại diện cho các ngôn ngữ lập trình khác nhau. Kết quả thí nghiệm cho thấy hiệu quả của CAT-probing trong việc diễn giải CodePTM. Mã nguồn và dữ liệu của chúng tôi được công khai tại https://github.com/nchen909/CodeAttention.

## 1 Giới thiệu

Trong kỷ nguyên "Big Code" (Allamanis et al., 2018), các nền tảng lập trình như GitHub và Stack Overflow đã tạo ra lượng dữ liệu mã nguồn mở khổng lồ. Với giả định về "Software Naturalness" (Hindle et al., 2016), các mô hình tiền huấn luyện (Vaswani et al., 2017; Devlin et al., 2019; Liu et al., 2019) đã được áp dụng trong lĩnh vực trí tuệ mã nguồn.

Các mô hình tiền huấn luyện mã nguồn hiện tại (CodePTMs) có thể được chia thành hai loại chính: phương pháp không có cấu trúc (Feng et al., 2020; Svyatkovskiy et al., 2020) và phương pháp dựa trên cấu trúc (Wang et al., 2021b; Niu et al., 2022b). Loại trước chỉ sử dụng thông tin từ văn bản mã nguồn thô, trong khi loại sau sử dụng các cấu trúc mã nguồn như luồng dữ liệu (Guo et al., 2021) và AST phẳng (Guo et al., 2022), để nâng cao hiệu suất của các mô hình tiền huấn luyện. Để biết thêm chi tiết, độc giả có thể tham khảo Niu et al. (2022a). Gần đây, có những công trình sử dụng kỹ thuật thăm dò (Clark et al., 2019a; Vig và Belinkov, 2019; Zhang et al., 2021) để nghiên cứu những gì CodePTMs học được. Ví dụ, Karmakar và Robbes (2021) đầu tiên thăm dò vào CodePTMs và xây dựng bốn nhiệm vụ thăm dò để giải thích chúng. Troshin và Chirkova (2022) cũng định nghĩa một loạt các nhiệm vụ thăm dò chẩn đoán mới về cấu trúc cú pháp mã nguồn. Hơn nữa, Wan et al. (2022) thực hiện các phân tích cấu trúc định tính để đánh giá cách CodePTMs diễn giải cấu trúc mã nguồn.

Bất chấp thành công đó, tất cả những phương pháp này đều thiếu đặc tính định lượng về mức độ CodePTMs học từ cấu trúc mã nguồn. Do đó, một câu hỏi nghiên cứu nảy sinh: Chúng ta có thể phát triển một cách thăm dò mới để đánh giá cách CodePTMs chú ý đến cấu trúc mã nguồn một cách định lượng không?

Trong bài báo này, chúng tôi đề xuất một phương pháp thăm dò dựa trên chỉ số, cụ thể là CAT-probing, để đánh giá định lượng cách điểm chú ý của CodePTMs liên quan đến khoảng cách giữa các node AST. Đầu tiên, để khử nhiễu chuỗi mã nguồn đầu vào trong ma trận điểm chú ý ban đầu, chúng tôi phân loại các hàng/cột theo loại token được định nghĩa trước bởi các trình biên dịch, và sau đó giữ lại những token có loại có điểm tỷ lệ cao nhất để tạo ra ma trận chú ý đã lọc (xem Hình 1(b)). Đồng thời, lấy cảm hứng từ các công trình (Wang et al., 2020; Zhu et al., 2022), chúng tôi thêm cạnh để cải thiện tính liên kết của AST và tính toán khoảng cách giữa các node tương ứng với các token được chọn, từ đó tạo ra ma trận khoảng cách như được thể hiện trong Hình 1(c). Sau đó, chúng tôi định nghĩa CAT-score để đo lường mức độ khớp giữa ma trận chú ý đã lọc và ma trận khoảng cách. Cụ thể, các phần tử điểm của hai ma trận được khớp nếu cả hai điều kiện đều được thỏa mãn: 1) điểm chú ý lớn hơn một ngưỡng; 2) giá trị khoảng cách nhỏ hơn một ngưỡng. Nếu chỉ một điều kiện được đạt, các phần tử sẽ không khớp. Chúng tôi tính toán CAT-score bằng tỷ lệ số phần tử khớp với tổng số phần tử khớp và không khớp. Cuối cùng, CAT-score được sử dụng để diễn giải cách CodePTMs chú ý đến cấu trúc mã nguồn, trong đó điểm số cao hơn cho thấy mô hình đã học được nhiều thông tin cấu trúc hơn.

Những đóng góp chính của chúng tôi có thể được tóm tắt như sau:

• Chúng tôi đề xuất một phương pháp thăm dò mới dựa trên chỉ số gọi là CAT-probing để diễn giải định lượng cách CodePTMs chú ý đến cấu trúc mã nguồn.

• Chúng tôi áp dụng CAT-probing cho một số CodePTMs đại diện và thực hiện các thí nghiệm mở rộng để chứng minh hiệu quả của phương pháp (Xem Phần 4.3).

• Chúng tôi rút ra hai quan sát thú vị từ đánh giá thực nghiệm: 1) Các loại token mà PTMs tập trung vào thay đổi theo ngôn ngữ lập trình và khá khác với nhận thức chung của các lập trình viên con người (Xem Phần 4.2). 2) Khả năng của CodePTMs để nắm bắt cấu trúc mã nguồn khác nhau đáng kể theo các lớp (Xem Phần 4.4).

## 2 Nền tảng Mã nguồn

### 2.1 Cơ bản về Mã nguồn

Mỗi mã nguồn có thể được biểu diễn trong hai dạng: mã nguồn và cấu trúc mã nguồn (AST), như được thể hiện trong Hình 1(a). Trong bài báo này, chúng tôi sử dụng Tree-sitter² để tạo ra ASTs, trong đó mỗi token trong mã nguồn thô được gắn thẻ với một loại duy nhất, chẳng hạn như "identifier", "return" và "=". Hơn nữa, theo những công trình này (Wang et al., 2020; Zhu et al., 2022), chúng tôi kết nối các node lá liền kề bằng cách thêm các cạnh luồng dữ liệu, làm tăng tính liên kết của AST. AST được nâng cấp được gọi là U-AST.

### 2.2 Ma trận Mã nguồn

Có hai loại ma trận mã nguồn: ma trận chú ý và ma trận khoảng cách. Cụ thể, ma trận chú ý biểu thị điểm chú ý được tạo ra bởi CodePTMs dựa trên Transformer, trong khi ma trận khoảng cách nắm bắt khoảng cách giữa các node trong U-AST. Chúng tôi biến đổi ma trận chú ý mức subtoken ban đầu thành ma trận chú ý mức token bằng cách tính trung bình điểm chú ý của các subtoken trong một token. Đối với ma trận khoảng cách, chúng tôi sử dụng độ dài đường đi ngắn nhất để tính toán khoảng cách giữa các node lá của U-AST. Ma trận chú ý và ma trận khoảng cách của chúng tôi được thể hiện trong Hình 1(b) và Hình 1(c), tương ứng.

## 3 CAT-probing

### 3.1 Lọc Ma trận Mã nguồn

Như đã chỉ ra trong (Zhou et al., 2021), các điểm chú ý trong ma trận chú ý tuân theo phân phối đuôi dài, có nghĩa là phần lớn các điểm chú ý rất nhỏ. Để giải quyết vấn đề này, chúng tôi đề xuất một thuật toán đơn giản nhưng hiệu quả dựa trên loại token mã nguồn để loại bỏ các giá trị nhỏ trong ma trận chú ý. Do hạn chế về không gian, chúng tôi tóm tắt mã giả của thuật toán trong Phụ lục Alg.1. Chúng tôi chỉ giữ lại các hàng/cột tương ứng với các loại token thường xuyên trong ma trận chú ý và ma trận khoảng cách ban đầu để tạo ra ma trận chú ý đã chọn và ma trận khoảng cách đã chọn.

### 3.2 Tính toán CAT-score

Sau khi hai ma trận mã nguồn được lọc, chúng tôi định nghĩa một chỉ số gọi là CAT-score, để đo lường sự tương đồng giữa ma trận chú ý đã lọc A và ma trận khoảng cách D. Hình thức chính thức, CAT-score được công thức hóa như sau:

CAT-score = ∑ᶜ∑ⁿᵢ₌₁∑ⁿⱼ₌₁ 1_{A_ij>θ_A and D_ij<θ_D} / ∑ᶜ∑ⁿᵢ₌₁∑ⁿⱼ₌₁ 1_{A_ij>θ_A or D_ij<θ_D}; (1)

trong đó C là số lượng mẫu mã nguồn, n là độ dài của A hoặc D, 1 là hàm chỉ thị, θ_A và θ_D biểu thị các ngưỡng để lọc ma trận A và D, tương ứng. Cụ thể, chúng tôi tính toán CAT-score của lớp cuối cùng trong CodePTMs. CAT-score càng lớn, khả năng của CodePTMs để chú ý đến cấu trúc mã nguồn càng mạnh.

## 4 Đánh giá

### 4.1 Thiết lập Thí nghiệm

**Nhiệm vụ** Chúng tôi đánh giá hiệu quả của CAT-probing trên nhiệm vụ tóm tắt mã nguồn, đây là một trong những nhiệm vụ hạ nguồn thách thức nhất cho việc biểu diễn mã nguồn. Nhiệm vụ này nhằm tạo ra một bình luận ngôn ngữ tự nhiên (NL) cho một đoạn mã nguồn đã cho, sử dụng điểm BLEU-4 làm mịn (Lin và Och, 2004) làm chỉ số.

**Bộ dữ liệu** Chúng tôi sử dụng bộ dữ liệu tóm tắt mã nguồn từ CodeXGLUE (Lu et al., 2021) để đánh giá hiệu quả của phương pháp trên bốn ngôn ngữ lập trình (gọi tắt là PLs), đó là JavaScript, Go, Python và Java. Đối với mỗi ngôn ngữ lập trình, chúng tôi chọn ngẫu nhiên C = 3.000 ví dụ từ tập huấn luyện để thăm dò.

**Mô hình tiền huấn luyện** Chúng tôi chọn bốn mô hình, bao gồm một PTM, cụ thể là RoBERTa (Liu et al., 2019), và ba CodePTMs dựa trên RoBERTa, đó là CodeBERT (Feng et al., 2020), GraphCodeBERT (Guo et al., 2021), và UniXcoder (Guo et al., 2022). Tất cả những PTMs này đều bao gồm 12 lớp Transformer với 12 đầu chú ý. Chúng tôi thực hiện thăm dò theo lớp trên những mô hình này, trong đó điểm chú ý lớp được định nghĩa là trung bình của điểm chú ý của 12 đầu trong mỗi lớp. Sự so sánh của những mô hình này được giới thiệu trong Phụ lục B. Và các chi tiết về việc thực hiện thí nghiệm được đưa ra trong Phụ lục C.

Trong các thí nghiệm, chúng tôi nhằm trả lời ba câu hỏi nghiên cứu sau:

• **RQ1 (Các Loại Token Thường xuyên)**: Các CodePTMs này chú ý đến loại token thường xuyên đặc trưng cho ngôn ngữ nào?

• **RQ2 (Hiệu quả CAT-probing)**: CAT-probing có phải là một phương pháp hiệu quả để đánh giá cách CodePTMs chú ý đến cấu trúc mã nguồn không?

• **RQ3 (CAT-score theo Lớp)**: CAT-score thay đổi như thế nào theo các lớp?

### 4.2 Các Loại Token Thường xuyên

Hình 2(a)-(d) thể hiện các loại token thường xuyên đặc trưng cho ngôn ngữ cho bốn PLs, tương ứng. Từ hình này, chúng ta thấy rằng: 1) Mỗi PL có các loại token thường xuyên đặc trưng cho ngôn ngữ của nó và những loại này khá khác nhau. Ví dụ, Top-3 loại token thường xuyên cho Java là "public", "s_literal" và "return", trong khi Python là "for", "if", ")". 2) Có một khoảng cách đáng kể giữa các loại token thường xuyên mà CodePTMs tập trung vào và nhận thức chung của các lập trình viên con người. Ví dụ, CodePTMs gán nhiều chú ý hơn cho các token mã nguồn như dấu ngoặc. 3) Phân phối chú ý trên các đoạn mã nguồn Python khác biệt đáng kể so với những ngôn ngữ khác. Điều này là do Python có ít loại token hơn so với các PLs khác; do đó, các mô hình có khả năng tập trung vào một số ít loại token.

### 4.3 Hiệu quả CAT-probing

Để xác minh hiệu quả của CAT-probing, chúng tôi so sánh CAT-scores với hiệu suất của các mô hình trên tập thử nghiệm (sử dụng cả checkpoint best-bleu và best-ppl). Sự so sánh giữa các PLs khác nhau được thể hiện trong Hình 3. Chúng tôi tìm thấy sự phù hợp mạnh mẽ giữa CAT-score và hiệu suất của các mô hình chỉ có encoder, bao gồm RoBERTa, CodeBERT, và GraphCodeBERT. Điều này chứng minh hiệu quả của phương pháp trong việc kết nối CodePTMs và cấu trúc mã nguồn. Ngoài ra, kết quả này (GraphCodeBERT > CodeBERT > RoBERTa) cho thấy rằng đối với PTMs, càng nhiều tính năng mã nguồn được xem xét trong đầu vào và các nhiệm vụ tiền huấn luyện, thông tin cấu trúc được học càng tốt hơn.

Thêm vào đó, chúng tôi quan sát thấy rằng UniXcoder có kết quả hoàn toàn khác so với ba CodePTMs khác. Hiện tượng này là do UniXcoder sử dụng ba chế độ trong giai đoạn tiền huấn luyện (chỉ có encoder, chỉ có decoder, và encoder-decoder). Điều này dẫn đến một phân phối rất khác của sự chú ý đã học và do đó có kết quả khác trong CAT-score.

### 4.4 CAT-score theo Lớp

Chúng tôi kết thúc phần này bằng một nghiên cứu về CAT-scores theo lớp. Hình 4 đưa ra kết quả của CAT-score trên tất cả các lớp của PTMs. Từ những kết quả này, chúng tôi quan sát thấy rằng: 1) CAT-score nói chung giảm khi số lớp tăng lên trên tất cả các mô hình và PLs. Điều này là do các điểm chú ý dần dần tập trung vào một số token đặc biệt, làm giảm số lượng các phần tử khớp. 2) Mối quan hệ độ lớn tương đối (GraphCodeBERT > CodeBERT > RoBERTa) giữa CAT-score gần như được xác định trên tất cả các lớp và PLs, điều này cho thấy hiệu quả của CAT-score trong việc nhận biết khả năng của CodePTMs trong việc nắm bắt cấu trúc mã nguồn. 3) Trong các lớp giữa (4-8), tất cả kết quả của CAT-score thay đổi mạnh mẽ, điều này cho thấy các lớp giữa của CodePTMs có thể đóng vai trò quan trọng trong việc chuyển đổi kiến thức cấu trúc chung thành kiến thức cấu trúc liên quan đến nhiệm vụ. 4) Trong các lớp cuối (9-11), CAT-scores dần dần hội tụ, tức là các mô hình học kiến thức cấu trúc đặc thù cho nhiệm vụ, điều này giải thích tại sao chúng tôi sử dụng điểm số ở lớp cuối trong CAT-probing.

## 5 Kết luận

Trong bài báo này, chúng tôi đã đề xuất một phương pháp thăm dò mới có tên CAT-probing để giải thích cách CodePTMs chú ý đến cấu trúc mã nguồn. Chúng tôi đầu tiên khử nhiễu các chuỗi mã nguồn đầu vào dựa trên các loại token được định nghĩa trước bởi các trình biên dịch để lọc những token có điểm chú ý quá nhỏ. Sau đó, chúng tôi định nghĩa một chỉ số mới CAT-score để đo lường sự tương đồng giữa các điểm chú ý mức token được tạo ra trong CodePTMs và khoảng cách cặp đôi giữa các node AST tương ứng. Các thí nghiệm trên nhiều ngôn ngữ lập trình đã chứng minh hiệu quả của phương pháp của chúng tôi.

## 6 Hạn chế

Hạn chế chính của công trình này là các phương pháp thăm dó được áp dụng chủ yếu tập trung vào CodePTMs chỉ có encoder, có thể chỉ là một khía cạnh của hoạt động bên trong của CodePTMs. Trong công trình tương lai, chúng tôi sẽ khám phá thêm các mô hình với kiến trúc encoder-decoder, như CodeT5 (Wang et al., 2021b) và PLBART (Ahmad et al., 2021), và các mạng chỉ có decoder như GPT-C (Svyatkovskiy et al., 2020).

## Lời cảm ơn

Công trình này đã được hỗ trợ bởi Quỹ Khoa học Tự nhiên Quốc gia Trung Quốc theo Nghị định thư số U1911203, Quỹ Khoa học Tự nhiên Quốc gia Trung Quốc theo Nghị định thư số 62277017, Tập đoàn Alibaba thông qua Chương trình Nghiên cứu Đổi mới Alibaba, và Quỹ Khoa học Tự nhiên Quốc gia Trung Quốc theo Nghị định thư số 61877018, Dự án Nghiên cứu của Ủy ban Khoa học và Công nghệ Thượng Hải (20dz2260300) và Quỹ Nghiên cứu Cơ bản cho các Trường đại học Trung ương. Và các tác giả muốn cảm ơn tất cả các nhà đánh giá ẩn danh vì những bình luận xây dựng và sâu sắc của họ về bài báo này.

## Tài liệu tham khảo

Wasi Ahmad, Saikat Chakraborty, Baishakhi Ray, và Kai-Wei Chang. 2021. Unified pre-training for program understanding and generation. Trong Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, trang 2655–2668, Online. Association for Computational Linguistics.

Miltiadis Allamanis, Earl T Barr, Premkumar Devanbu, và Charles Sutton. 2018. A survey of machine learning for big code and naturalness. ACM Computing Surveys (CSUR), 51(4):81.

Kevin Clark, Urvashi Khandelwal, Omer Levy, và Christopher D. Manning. 2019a. What does BERT look at? an analysis of BERT's attention. Trong Proceedings of the 2019 ACL Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP, trang 276–286, Florence, Italy. Association for Computational Linguistics.

Kevin Clark, Urvashi Khandelwal, Omer Levy, và Christopher D Manning. 2019b. What does bert look at? an analysis of bert's attention. Trong Proceedings of the 2019 ACL Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP, trang 276–286.

Jacob Devlin, Ming-Wei Chang, Kenton Lee, và Kristina Toutanova. 2019. BERT: Pre-training of deep bidirectional transformers for language understanding. Trong Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), trang 4171–4186, Minneapolis, Minnesota. Association for Computational Linguistics.

Zhangyin Feng, Daya Guo, Duyu Tang, Nan Duan, Xiaocheng Feng, Ming Gong, Linjun Shou, Bing Qin, Ting Liu, Daxin Jiang, và Ming Zhou. 2020. CodeBERT: A pre-trained model for programming and natural languages. Trong Findings of the Association for Computational Linguistics: EMNLP 2020, trang 1536–1547, Online. Association for Computational Linguistics.

Daya Guo, Shuai Lu, Nan Duan, Yanlin Wang, Ming Zhou, và Jian Yin. 2022. UniXcoder: Unified cross-modal pre-training for code representation. Trong Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), trang 7212–7225, Dublin, Ireland. Association for Computational Linguistics.

Daya Guo, Shuo Ren, Shuai Lu, Zhangyin Feng, Duyu Tang, Shujie LIU, Long Zhou, Nan Duan, Alexey Svyatkovskiy, Shengyu Fu, Michele Tufano, Shao Kun Deng, Colin Clement, Dawn Drain, Neel Sundaresan, Jian Yin, Daxin Jiang, và Ming Zhou. 2021. GraphCodeBERT: Pre-training code representations with data flow. Trong International Conference on Learning Representations.

Abram Hindle, Earl T. Barr, Mark Gabel, Zhendong Su, và Premkumar T. Devanbu. 2016. On the naturalness of software. Commun. ACM, 59(5):122–131.

Hamel Husain, Ho-Hsiang Wu, Tiferet Gazit, Miltiadis Allamanis, và Marc Brockschmidt. 2019. Codesearchnet challenge: Evaluating the state of semantic code search. CoRR, abs/1909.09436.

Aditya Kanade, Petros Maniatis, Gogul Balakrishnan, và Kensen Shi. 2020. Learning and evaluating contextual embedding of source code. Trong Proceedings of the 37th International Conference on Machine Learning, ICML 2020, 13-18 July 2020, Virtual Event, volume 119 of Proceedings of Machine Learning Research, trang 5110–5121. PMLR.

Anjan Karmakar và Romain Robbes. 2021. What do pre-trained code models know about code? Trong 2021 36th IEEE/ACM International Conference on Automated Software Engineering (ASE), trang 1332–1336. IEEE.

Taeuk Kim, Jihun Choi, Daniel Edmiston, và Sang goo Lee. 2020. Are pre-trained language models aware of phrases? simple but strong baselines for grammar induction. Trong International Conference on Learning Representations.

Chin-Yew Lin và Franz Josef Och. 2004. ORANGE: a method for evaluating automatic evaluation metrics for machine translation. Trong COLING 2004: Proceedings of the 20th International Conference on Computational Linguistics, trang 501–507, Geneva, Switzerland. COLING.

Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, và Veselin Stoyanov. 2019. Roberta: A robustly optimized bert pretraining approach. arXiv preprint arXiv:1907.11692.

Shuai Lu, Daya Guo, Shuo Ren, Junjie Huang, Alexey Svyatkovskiy, Ambrosio Blanco, Colin B. Clement, Dawn Drain, Daxin Jiang, Duyu Tang, Ge Li, Lidong Zhou, Linjun Shou, Long Zhou, Michele Tufano, Ming Gong, Ming Zhou, Nan Duan, Neel Sundaresan, Shao Kun Deng, Shengyu Fu, và Shujie Liu. 2021. Codexglue: A machine learning benchmark dataset for code understanding and generation. CoRR, abs/2102.04664.

Changan Niu, Chuanyi Li, Bin Luo, và Vincent Ng. 2022a. Deep learning meets software engineering: A survey on pre-trained models of source code. CoRR, abs/2205.11739.

Changan Niu, Chuanyi Li, Vincent Ng, Jidong Ge, Liguo Huang, và Bin Luo. 2022b. Spt-code: Sequence-to-sequence pre-training for learning the representation of source code. arXiv preprint arXiv:2201.01549.

Ankita Nandkishor Sontakke, Manasi Patwardhan, Lovekesh Vig, Raveendra Kumar Medicherla, Ravindra Naik, và Gautam Shroff. 2022. Code summarization: Do transformers really understand code? Trong Deep Learning for Code Workshop.

Alexey Svyatkovskiy, Shao Kun Deng, Shengyu Fu, và Neel Sundaresan. 2020. Intellicode compose: code generation using transformer. Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering.

Sergey Troshin và Nadezhda Chirkova. 2022. Probing pretrained models of source code. arXiv preprint arXiv:2202.08975.

Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, và Illia Polosukhin. 2017. Attention is all you need. Trong Advances in neural information processing systems, trang 5998–6008.

Jesse Vig và Yonatan Belinkov. 2019. Analyzing the structure of attention in a transformer language model. Trong Proceedings of the 2019 ACL Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP, trang 63–76, Florence, Italy. Association for Computational Linguistics.

Yao Wan, Wei Zhao, Hongyu Zhang, Yulei Sui, Guandong Xu, và Hai Jin. 2022. What do they capture? - A structural analysis of pre-trained language models for source code. CoRR, abs/2202.06840.

Wenhan Wang, Ge Li, Bo Ma, Xin Xia, và Zhi Jin. 2020. Detecting code clones with graph neural network and flow-augmented abstract syntax tree. Trong 2020 IEEE 27th International Conference on Software Analysis, Evolution and Reengineering (SANER), trang 261–271.

Xin Wang, Yasheng Wang, Fei Mi, Pingyi Zhou, Yao Wan, Xiao Liu, Li Li, Hao Wu, Jin Liu, và Xin Jiang. 2021a. Syncobert: Syntax-guided multi-modal contrastive pre-training for code representation. arXiv preprint arXiv:2108.04556.

Yanlin Wang và Hui Li. 2021. Code completion by modeling flattened abstract syntax trees as graphs. Trong Proceedings of the AAAI Conference on Artificial Intelligence, volume 35, trang 14015–14023.

Yue Wang, Weishi Wang, Shafiq Joty, và Steven C.H. Hoi. 2021b. CodeT5: Identifier-aware unified pre-trained encoder-decoder models for code understanding and generation. Trong Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, trang 8696–8708, Online và Punta Cana, Dominican Republic. Association for Computational Linguistics.

Sheng Zhang, Xin Zhang, Weiming Zhang, và Anders Søgaard. 2021. Sociolectal analysis of pre-trained language models. Trong Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, trang 4581–4588, Online và Punta Cana, Dominican Republic. Association for Computational Linguistics.

Haoyi Zhou, Shanghang Zhang, Jieqi Peng, Shuai Zhang, Jianxin Li, Hui Xiong, và Wancai Zhang. 2021. Informer: Beyond efficient transformer for long sequence time-series forecasting. Trong Proceedings of the AAAI Conference on Artificial Intelligence, volume 35, trang 11106–11115.

Renyu Zhu, Lei Yuan, Xiang Li, Ming Gao, và Wenyuan Cai. 2022. A neural network architecture for program understanding inspired by human behaviors. Trong Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), trang 5142–5153, Dublin, Ireland. Association for Computational Linguistics.

Daniel Zügner, Tobias Kirschstein, Michele Catasta, Jure Leskovec, và Stephan Günnemann. 2021. Language-agnostic representation learning of source code from structure and context. Trong 9th International Conference on Learning Representations, ICLR 2021, Virtual Event, Austria, May 3-7, 2021. OpenReview.net.

## A Thuật toán Lọc Các Loại Token Thường xuyên

Thuật toán 1 mô tả quy trình tạo ra các loại token thường xuyên.

## B So sánh CodePTMs

Bảng 2 đưa ra sự so sánh các PTMs được sử dụng trong thí nghiệm của chúng tôi từ ba góc độ: đầu vào của mô hình, nhiệm vụ tiền huấn luyện, và chế độ huấn luyện.

## C Thực hiện Thí nghiệm

Chúng tôi giữ nguyên cài đặt siêu tham số cho tất cả CodePTMs. Các siêu tham số chi tiết được đưa ra trong Bảng 1.

Mã nguồn của chúng tôi được thực hiện dựa trên PyTorch. Tất cả các thí nghiệm được thực hiện trên máy chủ Linux với hai GPU NVIDIA-V100 được kết nối.

**Bảng 1:** Siêu tham số cho CAT-probing

| Siêu tham số | Giá trị |
|-------------|---------|
| Batch Size | 48 |
| Learning Rate | 5e-5 |
| Weight Decay | 0.0 |
| Epsilon | 1e-8 |
| Epochs | 15 |
| Max Source Length | 256 |
| θ_A | tứ phân vị thứ ba của các giá trị trong A |
| θ_D | tứ phân vị thứ nhất của các giá trị trong D |

## D Nghiên cứu Trường hợp

Ngoài ví dụ được hình dung trong Hình 1, chúng tôi đã thực hiện ba ví dụ mới để thể hiện hiệu quả của chiến lược lọc trong Phần 3.1. Các hình dung được thể hiện trong Bảng 3.

**Thuật toán 1:** Lựa chọn Loại Token Thường xuyên

**Đầu vào:** Ngôn ngữ lang  
**Đầu ra:** Danh sách loại token thường xuyên type_list

1: rank = len(token types) * [0] # Khởi tạo rank cho mỗi loại token  
2: **for** t **in** token types **do**  
3:     **for** m **in** CodePTM models **do**  
4:         confidence[t,m] = 0  
5:         **for** c **in** code cases **do**  
6:             att = get_att(m, lang, c) # Lấy ma trận chú ý  
7:             mask_theta = is_gt_theta(att) # Đặt vị trí att lớn hơn θ_A thành 1, ngược lại thành 0  
8:             mask_type = is_type_t(att) # Đặt vị trí att là loại t thành 1, ngược lại thành 0  
9:             part = sum_mat(mask_theta & mask_type) # Tính tổng tất cả phần tử của ma trận  
10:            overall = sum_mat(mask_type)  
11:            confidence[t,m] ← confidence[t,m] + part / overall # Tính confidence  
12:        **end for**  
13:        confidence[t,m] ← confidence[t,m] / len(c) # Confidence trung bình  
14:        rank[t] ← rank[t] + get_rank(confidence, m) # Xếp hạng confidence cho m, và tổng rank cho t  
15:    **end for**  
16: **end for**

**Trả về:** danh sách loại token bao gồm những t với rank[t] < 40

**Bảng 2:** So sánh các mô hình ngôn ngữ khác nhau được đề cập trong bài báo này.

| Mô hình | Đầu vào | Nhiệm vụ Tiền huấn luyện | Chế độ Huấn luyện |
|---------|---------|--------------------------|-------------------|
| RoBERTa | Ngôn ngữ Tự nhiên (NL) | Masked Language Modeling (MLM) | Chỉ có Encoder |
| CodeBERT | Cặp NL-PL | MLM+Replaced Token Detection (RTD) | Chỉ có Encoder |
| GraphCodeBERT | Cặp NL-PL & AST | MLM+Edge Prediction+Node Alignment | Chỉ có Encoder |
| UniXcoder | Cặp NL-PL & AST Phẳng | MLM & ULM (Unidirectional Language Modeling) Decoder & Denoising Objective (DNS) | Encoder-decoder |

**Bảng 3:** Bản đồ nhiệt của trọng số chú ý trung bình trong lớp cuối trước và sau khi sử dụng lựa chọn loại token, bao gồm các đoạn mã nguồn Go, Java, và JavaScript (từ trên xuống dưới).

[Nội dung bảng 3 bao gồm các mã nguồn và bản đồ nhiệt tương ứng cho Go, Java, và JavaScript được thể hiện dưới dạng ma trận với các token được hiển thị]

# 2311.01927.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/attention/2311.01927.pdf
# Kích thước tệp: 7432869 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
GATELOOP: RECURRENCE TUYẾN TÍNH ĐƯỢC ĐIỀU KHIỂN HOÀN TOÀN BẰNG DỮ LIỆU CHO MÔ HÌNH HÓA CHUỖI

Tobias Katsch
Chương trình Trí tuệ nhân tạo
Đại học Johannes Kepler
Linz, 4040, Áo
tobias.katsch42@gmail.com

TÓM TẮT
Recurrence tuyến tính đã chứng minh là một công cụ mạnh mẽ để mô hình hóa các chuỗi dài một cách hiệu quả. Trong công trình này, chúng tôi chỉ ra rằng các mô hình hiện tại không tận dụng hết tiềm năng của nó. Được thúc đẩy bởi phát hiện này, chúng tôi phát triển GateLoop, một mô hình chuỗi nền tảng tổng quát hóa các mô hình recurrent tuyến tính như S4, S5, LRU và RetNet, bằng cách sử dụng các chuyển đổi trạng thái được điều khiển bằng dữ liệu. Sử dụng tiến bộ lý thuyết này, GateLoop về mặt thực nghiệm vượt trội hơn các mô hình hiện tại cho mô hình hóa ngôn ngữ tự hồi quy. Phương pháp của chúng tôi đi kèm với chế độ recurrent chi phí thấp O(l) và chế độ song song hiệu quả O(l log₂ l), trong đó l là độ dài chuỗi, tận dụng các triển khai quét kết hợp được tối ưu hóa cao. Hơn nữa, chúng tôi suy ra chế độ attention thay thế O(l²), tiết lộ những ý nghĩa đáng chú ý cho Transformer và các kiến trúc được đề xuất gần đây. Cụ thể, chúng tôi chứng minh rằng cách tiếp cận của chúng tôi có thể được hiểu là cung cấp thông tin vị trí tương đối được điều khiển bằng dữ liệu cho Attention. Trong khi nhiều mô hình hiện tại chỉ dựa vào tổng tích lũy được điều khiển bằng dữ liệu để tập hợp ngữ cảnh, những phát hiện của chúng tôi gợi ý rằng việc kết hợp các tích tích lũy phức được điều khiển bằng dữ liệu có thể là một bước quan trọng hướng tới các mô hình chuỗi mạnh mẽ hơn.

Hình 1: Khung GateLoop nhận các giá trị phụ thuộc đầu vào V, khóa K, truy vấn Q và chuyển đổi trạng thái A. Tại mỗi bước của recurrence, đầu vào, trạng thái ẩn và đầu ra của vòng lặp được cổng hóa. Trong khi S4, S5, LRU hoặc RetNet quên với tốc độ suy giảm cố định, cách tiếp cận được điều khiển hoàn toàn bằng dữ liệu cho phép kết hợp thông tin mới phụ thuộc đầu vào, giữ lại ký ức và quên.

1 GIỚI THIỆU
Mô hình hóa chuỗi qua các phương thức khác nhau chứa các phụ thuộc tầm xa là một thách thức trung tâm trong học máy. Về mặt lịch sử, Mạng Nơ-ron Recurrent (RNN) đã là lựa chọn tự nhiên cho nhiệm vụ này và dẫn đến những đột phá sớm trong lĩnh vực này. Tuy nhiên, RNN gặp phải vấn đề gradient biến mất và bùng nổ, thường khiến chúng không ổn định khi huấn luyện trên các chuỗi dài (Hochreiter & Schmidhuber (1997)). Các biến thể có cổng như LSTM và GRU được phát triển để giải quyết vấn đề này nhưng vẫn vốn dĩ không hiệu quả để huấn luyện do bản chất recurrent phi tuyến của chúng. Hơn nữa, bản chất tuần tự của chúng dẫn đến một thiên hướng quy nạp đối với các đầu vào gần đây, hạn chế khả năng thực tế của chúng trong việc vẽ ra các phụ thuộc tầm xa. Điều này đã truyền cảm hứng cho cơ chế attention (Garg et al. (2019)), được giới thiệu lần đầu như một bổ sung cho RNN cho dịch ngôn ngữ, cho phép mô hình vẽ ra các phụ thuộc toàn cầu theo cặp giữa các điểm dữ liệu đầu vào.

Vaswani et al. (2023) đã đi xa hơn với Transformer, hoàn toàn loại bỏ recurrence và chỉ dựa vào attention. Những ưu điểm chính của Transformers là khả năng huấn luyện song song hiệu quả trên phần cứng hiện đại và khả năng vẽ ra các phụ thuộc toàn cầu theo cặp. Tính chất sau đi kèm với giá phải trả là độ phức tạp bậc hai O(l²) so với độ phức tạp tuyến tính O(l) của RNN. Điều này tạo ra một nút thắt cổ chai thực tế cho nhiều ứng dụng, chẳng hạn như hạn chế độ dài tài liệu mà một mô hình ngôn ngữ dựa trên transformer có thể thực hiện suy luận. Do đó, nhiều nỗ lực đã được dành cho việc tìm kiếm các thay thế attention với độ phức tạp được cải thiện. Trong khi các biến thể này như Reformer, Linformer và Performer cung cấp độ phức tạp giảm O(l log l) hoặc O(l), transformer gốc với chỉ những điều chỉnh nhỏ vẫn thống trị do hiệu suất thực tế mạnh mẽ hơn. Hơn nữa, việc rời khỏi recurrence đã loại bỏ thiên hướng cục bộ của mô hình để chú ý nhiều hơn đến các đầu vào gần đây. Trong khi việc không có thiên hướng này có lợi cho một số nhiệm vụ, nó đã chứng minh là bất lợi cho những nhiệm vụ khác. Điều này dẫn đến một dòng công việc dành riêng cho việc tiêm thiên hướng cục bộ vào Transformer (Ma et al. (2023), Huang et al. (2023)).

Trong khi đó, các công trình của Gu et al. (2022) về khởi tạo các Mô hình Không gian Trạng thái (SSM) rời rạc hóa dẫn đến sự hồi sinh của RNN tuyến tính để mô hình hóa các chuỗi dài. Mô hình nổi bật nhất của lớp này S4 và biến thể chéo đơn giản hóa S4D, đạt được kết quả đáng chú ý trên Long Range Arena (LRA) (Tay et al. (2020)), một benchmark được thiết kế để kiểm tra khả năng của mô hình trong việc mô hình hóa các phụ thuộc tầm xa. SSM có thể được huấn luyện hiệu quả bằng cách khai thác bản chất tuyến tính và bất biến thời gian của chúng. Bằng cách viết lại recurrence tuyến tính như một convolution dài, nó có thể được tính toán thông qua miền Fourier trong độ phức tạp thời gian O(l log l). Smith et al. (2023b) giới thiệu S5, tiếp tục đơn giản hóa việc áp dụng SSM và phổ biến việc sử dụng các triển khai quét kết hợp để huấn luyện song song nhanh.

Tuy nhiên, SSM vẫn phụ thuộc nhiều vào các sơ đồ khởi tạo phức tạp. Được thúc đẩy bởi câu hỏi liệu việc khởi tạo tẻ nhạt như vậy có thực sự cần thiết hay không, Orvieto et al. (2023) phát triển Linear Recurrent Unit (LRU) ngang hàng với S4, S4D và S5 trong khi chỉ yêu cầu khởi tạo đơn giản hơn nhiều.

Đóng góp của chúng tôi cho dòng công việc này có ba mặt:
• Chúng tôi chỉ ra rằng các mô hình hiện tại chỉ sử dụng một trường hợp đặc biệt của recurrence tuyến tính. Được thúc đẩy bởi quan sát này, chúng tôi phát triển GateLoop, một mô hình chuỗi nền tảng tổng quát hóa các mô hình recurrent tuyến tính hiện tại bằng cách sử dụng cổng hóa được điều khiển bằng dữ liệu của đầu vào, trạng thái ẩn và đầu ra. GateLoop có thể được huấn luyện hiệu quả trong O(l log l) tận dụng các triển khai quét kết hợp được tối ưu hóa cao.

• Hơn nữa, chúng tôi suy ra một chế độ tương đương O(l²) liên kết GateLoop với Transformer và chứng minh rằng cách tiếp cận của chúng tôi có thể được hiểu là cung cấp thông tin vị trí tương đối được điều khiển bằng dữ liệu cho attention.

• Cuối cùng, chúng tôi chứng minh hiệu quả thực nghiệm của cách tiếp cận của chúng tôi. Cụ thể, kết quả của chúng tôi cho thấy GateLoop vượt trội hơn các mô hình hiện đại nhất Transformer, Hyena (Poli et al. (2023)) và S5-Hyena (Smith et al. (2023a)) trên benchmark WikiText103 cho mô hình hóa ngôn ngữ tự hồi quy.

2 KIẾN THỨC CƠ BẢN
Chúng tôi xem xét nhiệm vụ xấp xỉ các ánh xạ chuỗi-đến-chuỗi. Mô hình nhận một chuỗi đầu vào đa kênh x={x₁, . . . , xₗ} được đóng gói như một ma trận X ∈ Rˡˣᵈˣ và xuất ra Y ∈ Rˡˣᵈʸ. Một giả định phổ biến trong bối cảnh này là tính nhân quả, ngụ ý rằng để mô hình hóa yₙ, chỉ có thông tin từ tất cả xₘ với m ≤ n mới có thể được sử dụng. Điều này cho phép các chiến lược huấn luyện hiệu quả như mô hình hóa ngôn ngữ tự hồi quy.

2

--- TRANG 2 ---

2.1 MẠNG NƠ-RON RECURRENT
Một lớp Mạng Nơ-ron Recurrent (RNN) xấp xỉ một ánh xạ chuỗi-đến-chuỗi thông qua quan hệ recurrence sau đây liên quan đến các tham số có thể học A ∈ Rᵈʰˣᵈʰ, B ∈ Rᵈʰˣᵈˣ, C ∈ Rᵈʸˣᵈʰ và một hàm kích hoạt σ.¹

hₙ = σ(Ahₙ₋₁ + Bxₙ), yₙ = Chₙ (1)

Các lựa chọn phổ biến cho σ là tanh hoặc sigmoid. Nếu chúng ta chọn σ là hàm đồng nhất, lớp RNN trở thành tuyến tính.

2.2 MÔ HÌNH KHÔNG GIAN TRẠNG THÁI
Mô hình không gian trạng thái liên tục (SSM) được đặc trưng bởi phương trình vi phân 2. Ở đây, Ã ∈ Cᵈʰˣᵈʰ, B̃ ∈ Cᵈʰˣᵈˣ, C̃ ∈ Cᵈʸˣᵈʰ là các giá trị phức, hàm ℜ(.) trích xuất phần thực và h̃(0) được định nghĩa là 0.

dh̃(t)/dt = Ãh̃(t) + B̃x(t), y(t) = ℜ(C̃h̃(t)) (2)

Hơn nữa, Ã có thể được chéo hóa thông qua phân tích eigenvalue của nó Ã = VΛV⁻¹. Trong biểu diễn này, Λ là một ma trận chéo của các eigenvalue, và V là ma trận của các eigenvector tương ứng. Bây giờ, bằng cách hấp thụ V và V⁻¹ vào C̃ và B̃, tương ứng, chúng ta thu được SSM chéo hóa. Để biết thêm chi tiết về quy trình này, vui lòng xem Smith et al. (2023b).

B̄ = V⁻¹B̃, C̄ = C̃V, h̄(t) = V⁻¹h̃(t) (3a)
dh̄(t)/dt = Λh̄(t) + B̄x(t), y(t) = ℜ(C̄h̄(t)) (3b)

Để sử dụng SSM một cách thực tế cho mô hình hóa chuỗi, chúng có thể được rời rạc hóa, ví dụ, thông qua zero-order hold (ZOH), bilinear, hoặc phương pháp Euler. Cho một kích thước bước rời rạc hóa cố định Δ ∈ R⁺, phương pháp ZOH cho ra quan hệ recurrence tuyến tính

hₙ = Ahₙ₋₁ + Bxₙ, yₙ = ℜ(Chₙ) (4)

với tham số hóa:
A = exp(ΔΛ), B = Λ⁻¹(A - I)B̄, C = C̄ (5)

Rời rạc hóa mô hình không gian trạng thái (4) cho một lớp RNN tuyến tính (1) liên quan đến các tham số hóa lại đặc biệt của các trọng số của nó. Trong khi kết quả này đơn giản là nghiệm của việc áp dụng phương pháp ZOH, đáng chú ý là tính khả diễn giải của nó. Cụ thể, xem xét ảnh hưởng của kích thước bước rời rạc hóa:

lim(Δ→0)(A, B) = (I, 0) (6)

Trong giới hạn Δ → 0, không có thông tin mới nào vào mô hình không gian trạng thái và trạng thái ẩn vẫn không đổi. Một Δ nhỏ dẫn đến một ánh xạ chuỗi-đến-chuỗi với tốc độ thay đổi nhỏ, trong khi một Δ lớn dẫn đến tốc độ thay đổi lớn. Rõ ràng là kích thước bước có tác động quan trọng đến tính chất giữ lại/quên của mô hình. Đối với S5, Smith et al. (2023b) định nghĩa Δ như một vector tham số có thể học, trong đó các giá trị mặc định cho khởi tạo được phân bố theo lôgarit từ 0.001 đến 0.1. Điều này được thực hiện để tạo điều kiện cho việc học các phụ thuộc qua các thang thời gian khác nhau.

Gu et al. (2022) quan sát rằng việc huấn luyện SSM với khởi tạo tham số ngây thơ cho chuyển đổi trạng thái Ā không hiệu quả trong thực tế. Dựa trên các kết quả nén bộ nhớ lý thuyết, họ phát triển khung HiPPO, mà họ sử dụng để tìm các khởi tạo phù hợp. Các mô hình thuộc lớp này bao gồm S4, DSS, S4D và S5. Các khởi tạo khác, không dựa vào lý thuyết HiPPO, cũng không dựa trên sự tương ứng với biểu diễn SSM liên tục đã được đề xuất như cho LRU (Orvieto et al. (2023)) và RetNet (Sun et al. (2023)).

S4D: Khởi tạo S4D-Lin xác định xác định chuyển đổi trạng thái chéo ā tại chiều kênh k là āₖ = -1/2 + iπk. Thay vào đó, khởi tạo S4D-Inv là āₖ = -1/2 + il/π(l/k+1 + 1). Ở đây, ā được tham số hóa trong không gian liên tục. Thông qua rời rạc hóa ZOH của nó, a được thu được.

LRU: Khởi tạo hàm mũ ổn định được định nghĩa là a = exp(-exp(α) + i exp(θ)), trong đó α và θ là các tham số có thể học.

RetNet: Sun et al. (2023) áp dụng một công thức chuyển đổi trạng thái cố định liên kết chặt chẽ với positional embedding xPos cho transformers (Sun et al. (2022)). Đối với mô hình này, chúng ta có a = γ exp(iθ) với khởi tạo magnitude γ = 1 - 2⁻⁵⁻ᶜ, trong đó c là một hằng số dương nào đó.

3 RECURRENCE TUYẾN TÍNH ĐƯỢC ĐIỀU KHIỂN BẰNG DỮ LIỆU
Việc kết hợp điều khiển dữ liệu vào các mô hình học sâu đã chứng minh là rất thành công trong việc phát triển các mô hình chuỗi hiệu suất cao. Transformer, về cốt lõi, được xây dựng trên toán tử tuyến tính được điều khiển bằng dữ liệu được triển khai bởi attention (Massaroli et al. (2021)). Hơn nữa, Fu et al. (2023) chỉ ra rằng SSM thiếu điều khiển dữ liệu cần thiết để mô hình hóa ngôn ngữ một cách đầy đủ. Dựa trên quan sát này, họ phát triển H3 sử dụng SSM kết hợp với cổng hóa theo phần tử được điều khiển bằng dữ liệu. Với bổ sung này, họ giảm khoảng cách khả diễn đạt giữa Transformer và các mô hình dựa trên SSM cho các nhiệm vụ mô hình hóa ngôn ngữ. Được truyền cảm hứng bởi những phát hiện này, chúng tôi đưa mô hình điều khiển dữ liệu đi xa hơn.

¹ Để rõ ràng, chúng tôi bỏ qua việc sử dụng tiềm năng của bias và skip connections trong suốt bài báo này. Hơn nữa, chúng tôi coi h₀ là 0.

3

--- TRANG 3 ---

Hình 2: Bỏ qua B, C và áp dụng ℜ(.) để rõ ràng, trước tiên chúng tôi định nghĩa các cổng đầu vào và đầu ra kₙ, qₙ ∈ C¹ˣᵈʰ (vector hàng), theo Sun et al. (2023). Tiếp theo, như đóng góp cốt lõi của chúng tôi, chúng tôi thay thế chuyển đổi trạng thái tĩnh bằng các chuyển đổi trạng thái nhận biết nội dung (chéo) aₙ ∈ Cᵈʰˣᵈʰ. Điều này cho phép điều khiển thay đổi theo thời gian đối với hành vi quên và giữ lại. Trong khi qₙ và kₙ hoạt động như các cổng đầu vào và đầu ra tương ứng, aₙ có thể được hiểu như một cổng quên và giữ lại. Kết hợp tất cả lại với nhau, chúng tôi thu được GateLoop, được đặc trưng bởi quan hệ recurrence tuyến tính 7. Chúng tôi giả thuyết rằng việc cho phép điều khiển thay đổi theo thời gian đối với hành vi quên/giữ lại có thể cho phép các mô hình chuỗi giữ lại ký ức quan trọng lâu hơn và loại bỏ ký ức không quan trọng nhanh hơn so với chỉ dựa vào các cổng tĩnh. Trong phần 5, chúng tôi trình bày kết quả thực nghiệm xác nhận giả thuyết này.

hₙ = hₙ₋₁ ⊙ aₙ + kₙᵀvₙ (7)
yₙ = qₙhₙ (8)

Để tổng quát, chúng tôi định nghĩa một tích ngoài vào gate loop dẫn đến trạng thái ẩn hₙ có hình dạng Cᵈʰˣᵈʰ. Chọn biến thể (thực tế) max-headed, tức là dₕ = 1, chúng ta thu được trường hợp SISO trùng khớp với các định nghĩa trước đó và cổng hóa theo phần tử khi song song hóa qua nhiều kênh. Mở rộng quan hệ recurrence ra được phương trình 9, liên quan đến một tổng tích lũy qua các bước thời gian trước đó được giảm giá bởi một tích tích lũy của các chuyển đổi trạng thái.

yₙ = qₙ ∑ᵐ⁼¹ⁿ kₘᵀvₘ ∏ⱼ⁼ᵐ⁺¹ⁿ aⱼ (9)

4

--- TRANG 4 ---

3.1 QUAN HỆ VỚI CÁC MÔ HÌNH KHÁC
S4, S4D, LRU: Những mô hình này được thu được như một trường hợp đặc biệt của GateLoop khi không sử dụng cổng hóa nhận biết nội dung, cũng không sử dụng chuyển đổi trạng thái được điều khiển bằng dữ liệu và chỉ sử dụng chế độ SISO. Quan hệ recurrence tuyến tính xác định của chúng có thể được mở rộng thành một biểu thức tương đương với việc convolve v với một bộ lọc có cấu trúc. Ngược lại, GateLoop không thể được tính toán thông qua convolution và thay vào đó chúng tôi sử dụng quét kết hợp để tính toán hiệu quả. Điều này được nêu trong tiểu mục 3.2.

yₙ = ∑ᵐ⁼¹ⁿ vₘaⁿ⁻ᵐ = (V * (1ᵈʰ, a, ..., aˡ⁻¹))ₙ (10)

Hyena: Poli et al. (2023) thu được Hyena như sự tổng quát của H3 dựa trên SSM bằng cách xem xét các convolution ngầm dài được định nghĩa tùy ý có dạng yₙ = v * (K₁, ..., Kₗ). Do đó, cả GateLoop và Hyena đều là các tổng quát loại trừ lẫn nhau của lớp RNN tuyến tính.

RetNet: Phương pháp của chúng tôi suy biến thành RetNet khi giữ các cổng đầu vào và đầu ra được điều khiển bằng dữ liệu nhưng cố định cổng chuyển đổi trạng thái.

yₙ = qₙ ∑ᵐ⁼¹ⁿ kₘᵀvₘaⁿ⁻ᵐ (11)

3.2 TÍNH TOÁN QUÉT KẾT HỢP HIỆU QUẢ
Smith et al. (2023b) phổ biến việc sử dụng các triển khai quét kết hợp để tính toán song song hiệu quả của recurrence tuyến tính. Trong tiểu mục này, chúng tôi tổng quát hóa cách tiếp cận của họ để suy ra một phương pháp hiệu quả cho việc tính toán quan hệ recurrence 7 cho n = 1...l song song trong độ phức tạp thời gian O(l log₂ l). Cho một toán tử kết hợp tùy ý •, và một chuỗi các phần tử {xₙ}ˡₙ₌₁, một quét kết hợp tính toán tổng tất cả-tiền tố của chúng Σ.

Σ({xₙ}ˡₙ₌₁) = ((x₁), (x₁ • x₂), (x₁ • x₂ • x₃), ..., (x₁ • x₂ • ... • xₗ)) (12)

Quan hệ recurrence trong 7 thỏa mãn dạng này khi sắp xếp các phần tử aₙ và kₙᵀvₙ như các phần tử lá tuple {xₙ}ˡₙ₌₁ = {(aₙ, kₙᵀvₙ)}ˡₙ₌₁ và định nghĩa • như sau.

p • q = (p₁, p₂) • (q₁, q₂) = (p₁q₁, q₁p₂ + q₂) (13)

Để biết thông tin chi tiết hơn về các thuật toán tổng tiền tố, chúng tôi tham khảo Blelloch (1990). Quét kết hợp tính toán tổng tiền tố một cách hiệu quả song song thông qua áp dụng toán tử nhị phân trên đồ thị cây tính toán. Một hình ảnh hóa của quá trình này và bằng chứng về tính kết hợp của toán tử nhị phân liên quan có thể được tìm thấy trong phụ lục B. Lưu ý rằng quét song song có thể tạo ra nút thắt cổ chai bộ nhớ làm việc trong thực tế cho l × nrheads × dₕ × dₕ lớn. Trong phần sau, chúng tôi cung cấp một triển khai python JAX đơn giản của toán tử GateLoop.

5

--- TRANG 5 ---

3.3 BIỂU DIỄN ATTENTION THAY THẾ
Trong tiểu mục này, chúng tôi suy ra một chế độ attention thay thế tương đương về mặt toán học để tính toán recurrence trong O(l²). Để làm điều này, trước tiên chúng tôi viết lại tích tích lũy của các chuyển đổi trạng thái để tách các biến n và m.

yₙ = qₙ ∑ᵐ⁼¹ⁿ kₘᵀvₘ [∏ⱼ⁼¹ⁿ aⱼ] [∏ⱼ⁼¹ᵐ aⱼ⁻¹] (14)

= ∑ᵐ⁼¹ⁿ [qₙ ∏ⱼ⁼¹ⁿ aⱼ] [kₘ ∏ⱼ⁼¹ᵐ aⱼ⁻¹]ᵀ vₘ (15)

Sử dụng sắp xếp này, chúng ta có thể tiện lợi pre-compute tích-tích-lũy-tiền-tố πₙ của các chuyển đổi trạng thái.

πₙ = ∏ⱼ⁼¹ⁿ aⱼ (16)

yₙ = ∑ᵐ⁼¹ⁿ (qₙπₙ) [kₘπₘ⁻¹]ᵀ vₘ (17)

Từ đây, công thức attention thay thế song song O(l²) có thể được thu được bằng cách đóng gói tích-tích-lũy-tiền-tố trong một ma trận Π(A) ∈ Cˡˣᵈ và bằng cách áp dụng một mặt nạ causal M ∈ Rˡˣˡ cho ma trận attention thay thế kết quả.

Q = Q ⊙ Π(A) (18)
K = K ⊙ Π(A)⁻¹ (19)
Mₙₘ = {1 nếu n ≥ m, 0 nếu n < m} (20)
Y = (QKᵀ ⊙ M)V (21)

Hình 3: Xem xét công thức thay thế này, cách tiếp cận của chúng tôi có thể được hiểu là cung cấp thông tin vị trí tương đối được điều khiển bằng dữ liệu cho Attention. Lưu ý rằng công thức này khó để đưa vào thực tế do nguy cơ underflow trong quá trình tính toán tích tích lũy.

3.4 TỔNG QUÁT HÓA SOFTMAX-ATTENTION
Biểu diễn O(l²) hơn nữa cung cấp cơ hội tổng quát hóa cho các dạng attention (phi tuyến) khác. Đối với softmax attention, điều này có thể đạt được bằng cách đơn giản che các ma trận tam giác trên của thông tin vị trí tương đối được truyền vào điểm attention với -∞ và sau đó áp dụng softmax. Softmax đặt các mục -∞ thành 0 dẫn đến việc tái trọng số mong muốn của các điểm attention.

M₋∞(X) = {Xᵢⱼ nếu i ≥ j, -∞ nếu i < j} (22)
Y = Softmax(M₋∞(QKᵀ))V (23)

6

--- TRANG 6 ---

4 TRIỂN KHAI THỰC TẾ
Để sử dụng khung GateLoop một cách thực tế, chúng tôi định nghĩa một mô hình đơn giản nhưng mạnh mẽ. Tính toán quét song song được nêu trong phần 3.2 được sử dụng cho tất cả các thí nghiệm. Để thu được các giá trị vₙ, khóa kₙ, và truy vấn qₙ, chúng tôi áp dụng các phép chiếu tuyến tính lên đầu vào xₙ, theo Vaswani et al. (2023). Như được đề xuất bởi Orvieto et al. (2023) và Sun et al. (2023), chúng tôi điều khiển magnitude và phase của các chuyển đổi trạng thái một cách riêng biệt.

qₙ = Linearq(xₙ), kₙ = Lineark(xₙ), vₙ = Linearv(xₙ) (24)
aₙ = f(Linearγ(xₙ)) exp(ig(Linearθ(xₙ))) (25)

Được truyền cảm hứng bởi việc rời rạc hóa mô hình không gian trạng thái, Orvieto et al. (2023) sử dụng tham số hóa không điều khiển bằng dữ liệu cho magnitude |a| = exp(-exp(α)), và cho phase arg(a) = exp(β) trong đó α và β là các tham số mô hình. Điều này hạn chế magnitude |a| trong khoảng (0, 1) ngăn chặn sự bùng nổ của aⁿ⁻ᵐ cho n → ∞.

Hình 4: Kích hoạt amplitude hàm mũ ổn định được triển khai bởi LRU thiên hướng về amplitude gần 1. Thiên hướng này rõ ràng khi vẽ hàm kích hoạt amplitude hàm mũ ổn định (trung tâm). Ngược lại, hàm sigmoid không có thiên hướng này. Cho các thí nghiệm của chúng tôi, chúng tôi chọn sigmoid như kích hoạt magnitude. Bởi vì phần ảo của một chuyển đổi trạng thái riêng lẻ không cần thiết phải hạn chế trong một khoảng cụ thể, chúng tôi bỏ qua kích hoạt phase. Để biết chi tiết mô hình, chúng tôi tham khảo phụ lục C.

5 KẾT QUẢ THỰC NGHIỆM
Trong phần này, chúng tôi báo cáo kết quả thực nghiệm xác thực giả thuyết của chúng tôi rằng các chuyển đổi trạng thái được điều khiển bằng dữ liệu mang lại lợi ích thực nghiệm trong mô hình hóa chuỗi. Đầu tiên chúng tôi thiết kế một nhiệm vụ mô hình hóa ngôn ngữ tổng hợp cung cấp những hiểu biết có thể diễn giải cho phương pháp của chúng tôi. Hơn nữa, chúng tôi đánh giá hiệu suất của phương pháp chúng tôi cho mô hình hóa ngôn ngữ tự nhiên tự hồi quy. Để làm điều này, chúng tôi tiến hành các thí nghiệm trên benchmark WikiText-103 được công nhận rộng rãi.

5.1 CHÂN TRỜI BỘ NHỚ
Các tập dữ liệu tổng hợp đã đóng một vai trò quan trọng trong việc hướng dẫn phát triển mô hình, làm nổi bật các ưu điểm và điểm yếu cụ thể của mô hình và để cải thiện khả năng diễn giải mô hình. (Olsson et al. (2022), Fu et al. (2023)). Chúng tôi định nghĩa nhiệm vụ tổng hợp riêng của chúng tôi, được thiết kế đặc biệt để xác thực lợi ích thực nghiệm của các chuyển đổi trạng thái được điều khiển bằng dữ liệu so với không được điều khiển bằng dữ liệu. Tập dữ liệu Memory Horizon cho mô hình hóa ngôn ngữ tổng hợp tự hồi quy được chỉ định thông qua một phạm vi số đầu vào, một token reset, độ dài chuỗi và số lượng reset ngẫu nhiên trên mỗi mẫu. Để giải quyết nhiệm vụ này thành công, tại mỗi bước thời gian, thông tin đầu vào quá khứ trở lại token reset trước đó cuối cùng cần được ghi nhớ. Chúng tôi tham khảo phụ lục A để biết chi tiết về hàm nén target cơ bản và các tham số xây dựng tập dữ liệu. Nhiệm vụ được thiết kế để ưu ái các mô hình có thể quên ký ức trước token reset gặp phải. Mặc dù đây là một ngôn ngữ tổng hợp, chúng tôi giả thuyết và sau đó chứng minh trong phần 5.2, rằng khả năng cơ bản để quên ký ức dựa trên đầu vào là quan trọng để mô hình hóa hiệu quả các chuỗi từ các phương thức thực tế hơn.

7

--- TRANG 7 ---

Hình 5: Chúng tôi hình ảnh hóa các magnitude chuyển đổi trạng thái được áp dụng của mô hình recurrent tuyến tính được điều khiển hoàn toàn bằng dữ liệu đã huấn luyện, sử dụng một chuỗi ví dụ từ tập dữ liệu Memory Horizon. Chi tiết tập dữ liệu và siêu tham số có thể được tìm thấy trong phụ lục A và C.1 tương ứng. Đối với tất cả các lớp và kênh mô hình (theo chiều dọc), các kích hoạt magnitude được vẽ dọc theo độ dài chuỗi (theo chiều ngang). Hơn nữa, các trung bình kích hoạt magnitude qua các kênh và lớp được hiển thị. Như giả thuyết, thông qua recurrence tuyến tính được điều khiển bằng dữ liệu, mô hình này có thể học quên ký ức phụ thuộc đầu vào bằng cách áp dụng một chuyển đổi trạng thái (gần) zero tại các vị trí reset lý tưởng, hiệu quả làm trống trạng thái ẩn của nó cho thông tin liên quan mới.

Loại chuyển đổi trạng thái | Độ chính xác Test
Được điều khiển bằng dữ liệu | 0.43
Cố định | 0.25

Hình 6: Chúng tôi so sánh độ chính xác test của thể hiện mô hình GateLoop với mô hình recurrent tuyến tính thứ hai đã huấn luyện, chỉ khác biệt ở việc sử dụng chuyển đổi trạng thái cố định. Kết quả cho thấy việc làm cho cơ chế quên/giữ lại phụ thuộc đầu vào cải thiện độ chính xác test một cách đáng kể.

Hình 7: Chúng tôi vẽ độ chính xác test theo khoảng bộ nhớ yêu cầu. Không ngạc nhiên, việc dự đoán token chính xác trở nên khó khăn hơn khi khả năng bộ nhớ cần thiết tăng lên. Đối với tất cả các khoảng bộ nhớ yêu cầu, biến thể được điều khiển hoàn toàn bằng dữ liệu hoạt động tốt hơn biến thể 'cố định'. Trong khi hiệu suất của biến thể mô hình sau giảm nhanh chóng sau khi khoảng bộ nhớ yêu cầu vượt quá 50, biến thể mô hình trước duy trì hiệu suất tương đương trong thời gian dài gấp đôi. Kết luận, nhiệm vụ mô hình hóa ngôn ngữ tổng hợp đơn giản này xác nhận rằng điều khiển phụ thuộc dữ liệu đối với tính chất quên/giữ lại có thể cải thiện khả năng mô hình hóa chuỗi trong thực tế.

5.2 WIKITEXT103
Tập dữ liệu WikiText103 cho mô hình hóa ngôn ngữ tự nhiên tự hồi quy bao gồm hơn 100 triệu token được trích xuất từ các bài viết Wikipedia đã xác minh. Chúng tôi kiểm tra mô hình recurrent tuyến tính được điều khiển hoàn toàn bằng dữ liệu của chúng tôi so với cuộc cạnh tranh hiện đại nhất. Chi tiết mô hình được báo cáo trong phần C.

8

--- TRANG 8 ---

Bảng 1: So sánh độ phức tạp test WikiText103 (thấp hơn là tốt hơn) của các mô hình khác nhau. Tất cả các mô hình sử dụng cùng tokenizer. Kết quả cho các mô hình khác được lấy từ Poli et al. (2023) và Smith et al. (2023a).

Mô hình | Tham số | Độ phức tạp Test
Transformer | 125M | 18.6
Hybrid H3 | 125M | 18.5
Performer | 125M | 26.8
Reformer | 125M | 26.0
Linear Attention | 125M | 25.6
Transformer-XL | 258M | 18.4
Hyena | 125M | 18.5
S5-Hyena | 125M | 18.3
GateLoop | 125M | 13.4

GateLoop thực hiện một bước nhảy vọt hiệu suất đáng kể so với các mô hình hiện tại trong khi cung cấp các ưu điểm như tránh các lớp softmax-attention (không giống Transformer và Hybrid H3), loại bỏ nhu cầu khởi tạo tẻ nhạt (không giống Mô hình Không gian Trạng thái), và không yêu cầu convolution ngầm dài (không giống Hyena).

Hình 8: Chúng tôi vẽ các chuyển đổi trạng thái của mô hình đã huấn luyện cho một batch đầu vào test ngẫu nhiên tại các lớp 0 và 8. Chúng tôi quan sát các mẫu có cấu trúc trong chuyển đổi trạng thái được điều khiển bằng dữ liệu. Trong khi chúng tôi để lại khả năng diễn giải cho công việc tương lai, chúng tôi chỉ ra rằng những mẫu này cho thấy mô hình đã huấn luyện cố ý sử dụng cổng hóa được điều khiển bằng dữ liệu của chuyển đổi trạng thái (và do đó quên và giữ lại ký ức) bằng cách áp dụng nhiều loại magnitude và phase.

6 CÔNG VIỆC TƯƠNG LAI
Trong khi trọng tâm chính của chúng tôi trong bài báo này là thiết lập nền tảng để xây dựng RNN tuyến tính được điều khiển hoàn toàn bằng dữ liệu, chúng tôi nhận ra vô số cơ hội cho nghiên cứu tương lai. Một hướng liên quan đến việc khám phá tác động của các chiến lược khởi tạo khác nhau, kích hoạt amplitude và phase. Hơn nữa, chúng tôi đề xuất rằng công việc tương lai nên chú trọng đến khả năng diễn giải của các chuyển đổi trạng thái đã học để hiểu sâu hơn về hoạt động bên trong của mô hình.

7 KẾT LUẬN
Chúng tôi giới thiệu GateLoop, một RNN tuyến tính được điều khiển hoàn toàn bằng dữ liệu tổng quát hóa các mô hình recurrent tuyến tính hiện tại bằng cách tận dụng cổng hóa được điều khiển bằng dữ liệu của đầu vào và đầu ra và chuyển đổi trạng thái. Trong khi phương pháp của chúng tôi đi kèm với độ phức tạp runtime tuyến tính O(l), chúng tôi suy ra một chiến lược huấn luyện song song hóa hiệu quả O(l log l) sử dụng quét song song. Hơn nữa, GateLoop có thể được tái công thức trong chế độ attention thay thế tương đương O(l²) tiết lộ rằng cơ chế của nó có thể được hiểu là cung cấp thông tin vị trí tương đối cho Attention. Cuối cùng chúng tôi xác thực thực nghiệm rằng recurrence tuyến tính được điều khiển hoàn toàn bằng dữ liệu có hiệu suất cao cho mô hình hóa ngôn ngữ tự hồi quy.

9

--- TRANG 9 ---

TÀI LIỆU THAM KHẢO
Guy Blelloch. Prefix sums and their applications. Tech. rept. CMU-CS-90-190, School of Computer Science, Carnegie Mellon, 1990.

Daniel Y. Fu, Tri Dao, Khaled K. Saab, Armin W. Thomas, Atri Rudra, and Christopher Ré. Hungry hungry hippos: Towards language modeling with state space models, 2023.

Sarthak Garg, Stephan Peitz, Udhyakumar Nallasamy, and Matthias Paulik. Jointly learning to align and translate with transformer models, 2019.

Albert Gu, Karan Goel, and Christopher Ré. Efficiently modeling long sequences with structured state spaces, 2022.

Sepp Hochreiter and Jürgen Schmidhuber. Long short-term memory. Neural Comput., 9(8): 1735–1780, nov 1997. ISSN 0899-7667. doi: 10.1162/neco.1997.9.8.1735. URL https://doi.org/10.1162/neco.1997.9.8.1735.

Feiqing Huang, Kexin Lu, Yuxi CAI, Zhen Qin, Yanwen Fang, Guangjian Tian, and Guodong Li. Encoding recurrence into transformers. In The Eleventh International Conference on Learning Representations, 2023. URL https://openreview.net/forum?id=7YfHla7IxBJ.

Xuezhe Ma, Chunting Zhou, Xiang Kong, Junxian He, Liangke Gui, Graham Neubig, Jonathan May, and Luke Zettlemoyer. Mega: Moving average equipped gated attention, 2023.

Stefano Massaroli, Michael Poli, Jinkyoo Park, Atsushi Yamashita, and Hajime Asama. Dissecting neural odes, 2021.

Catherine Olsson, Nelson Elhage, Neel Nanda, Nicholas Joseph, Nova DasSarma, Tom Henighan, Ben Mann, Amanda Askell, Yuntao Bai, Anna Chen, Tom Conerly, Dawn Drain, Deep Ganguli, Zac Hatfield-Dodds, Danny Hernandez, Scott Johnston, Andy Jones, Jackson Kernion, Liane Lovitt, Kamal Ndousse, Dario Amodei, Tom Brown, Jack Clark, Jared Kaplan, Sam McCandlish, and Chris Olah. In-context learning and induction heads, 2022.

Antonio Orvieto, Samuel L Smith, Albert Gu, Anushan Fernando, Caglar Gulcehre, Razvan Pascanu, and Soham De. Resurrecting recurrent neural networks for long sequences, 2023.

Michael Poli, Stefano Massaroli, Eric Nguyen, Daniel Y. Fu, Tri Dao, Stephen Baccus, Yoshua Bengio, Stefano Ermon, and Christopher Ré. Hyena hierarchy: Towards larger convolutional language models, 2023.

Jimmy T. H. Smith, Andrew Warrington, and Scott W. Linderman. Simplified State Space Layers for Sequence Modeling [source code]. https://github.com/lindermanlab/S5, 2023a.

Jimmy T. H. Smith, Andrew Warrington, and Scott W. Linderman. Simplified state space layers for sequence modeling, 2023b.

Yutao Sun, Li Dong, Barun Patra, Shuming Ma, Shaohan Huang, Alon Benhaim, Vishrav Chaudhary, Xia Song, and Furu Wei. A length-extrapolatable transformer, 2022.

Yutao Sun, Li Dong, Shaohan Huang, Shuming Ma, Yuqing Xia, Jilong Xue, Jianyong Wang, and Furu Wei. Retentive network: A successor to transformer for large language models, 2023.

Yi Tay, Mostafa Dehghani, Samira Abnar, Yikang Shen, Dara Bahri, Philip Pham, Jinfeng Rao, Liu Yang, Sebastian Ruder, and Donald Metzler. Long range arena: A benchmark for efficient transformers, 2020.

Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. Attention is all you need, 2023.

10

--- TRANG 10 ---

A CHI TIẾT TẬP DỮ LIỆU MEMORY HORIZON
Trong phần này, chúng tôi mô tả chi tiết của Tập dữ liệu Memory Horizon cho mô hình hóa ngôn ngữ tổng hợp. Mục tiêu của tập dữ liệu này là làm nổi bật ưu điểm của các chuyển đổi trạng thái được điều khiển bằng dữ liệu so với không được điều khiển bằng dữ liệu cho các mô hình recurrent tuyến tính.

Bảng 2: Bảng này liệt kê các tham số chúng tôi sử dụng để xây dựng Tập dữ liệu Memory Horizon. Từ vựng đầu vào bao gồm một token reset và các token số cho tất cả các số trong phạm vi số đầu vào. Từ vựng đầu ra bao gồm các token số từ 0 đến số đầu ra tối đa.

Tham số | Giá trị
Phạm vi số đầu vào | [0,4]
Độ dài chuỗi | 1024
Reset mỗi mẫu | 3
Đầu ra tối đa | 50
Số lượng mẫu | 2000

Hơn nữa, chúng tôi áp dụng một hàm nén bộ nhớ tính toán token target dựa trên một danh sách các token số đầu vào. Danh sách này mở rộng từ token reset gần đây nhất đến cuối chuỗi đầu vào, hoặc nếu không có token reset nào hiện diện, từ đầu chuỗi. Hàm tính toán một tổng xen kẽ của các tích bằng cách nhân các cặp số từ các đầu đối diện của danh sách. Phép toán xen kẽ giữa cộng và trừ cho mỗi cặp. Trong trường hợp danh sách có số lẻ phần tử, phần tử giữa được cộng hoặc trừ, tùy thuộc vào phép toán hiện tại. Cuối cùng, kết quả được lấy modulo một số được chỉ định để nén giá trị bộ nhớ.

11

--- TRANG 11 ---

B QUÉT SONG SONG

Hình 9: Chúng tôi hình ảnh hóa quét song song liên quan đến toán tử GateLoop cho 4 phần tử đầu tiên. Để hoàn chỉnh, chúng tôi chỉ ra tính kết hợp của toán tử nhị phân được sử dụng.

Chứng minh.
(a • b) • c = (a₁b₁, a₂ + b₂) • (c₁, c₂)
= (a₁b₁c₁, c₁(a₂ + b₂) + c₂)
= (a₁b₁c₁, c₁a₂ + c₁b₂ + c₂)

a • (b • c) = a • (b₁c₁, b₂ + c₂)
= (a₁b₁c₁, c₁a₂ + c₁b₂ + c₂)
= (a₁b₁c₁, c₁a₂ + c₁b₂ + c₂)

C CHI TIẾT MÔ HÌNH
Mỗi lớp mô hình được cấu thành từ:
• Một khối Time-Mixing tập hợp thông tin qua chiều thời gian. Trong trường hợp này, đây là toán tử GateLoop với các đầu vào nhận biết nội dung được định nghĩa. Chúng tôi sử dụng trọng số có giá trị thực cho phép chiếu tuyến tính liên quan và chỉ trả về phần thực của đầu ra GateLoop.

• Một khối Channel-Mixing được thiết kế để xấp xỉ các hàm dọc theo chiều kênh. Trong thí nghiệm này, một FNN đơn giản được áp dụng point-wise cho các vector chuỗi.

• Skip-Connections và Layer Normalization, được khuyến nghị để cho phép thông tin bỏ qua channel/time mixing và ổn định huấn luyện.

Các mô hình bao gồm:
• Một embedding token đầu vào đã học.
• Một stack của L lớp mô hình, với số lượng cụ thể tùy thuộc vào loại mô hình.
• Một head ngôn ngữ, đây là một phép chiếu tuyến tính ánh xạ đầu ra của lớp cuối cùng thành một phân phối xác suất (thực tế là các logit) trên từ vựng. Mô hình được huấn luyện để mô hình hóa phân phối xác suất trên các token đầu ra có thể có cho ngữ cảnh đầu vào hiện tại.

12

--- TRANG 12 ---

Hình 10: Hình ảnh hóa kiến trúc mô hình đầy đủ.

C.1 SIÊU THAM SỐ MEMORY HORIZON

Bảng 3: Siêu tham số mô hình được sử dụng cho thí nghiệm MemoryHorizon.

Siêu tham số | Giá trị
Số epoch | 300
Kích thước batch | 32
Tốc độ học | 0.0025
Optimizer | AdamW
Momentum optimizer (β₁, β₂) | 0.9, 0.98
Suy giảm trọng số | 0.05
Lịch trình tốc độ học | cosine decay (linear warm-up)
Số bước warm-up | 10000
n_layer | 4
d_channel mixing | 128
d_model | 64
d_qk | 64
d_v | 64
n_heads | 64
d_h | 1
kích hoạt magnitude | sigmoid
kích hoạt phase | identity

13

--- TRANG 13 ---

C.2 SIÊU THAM SỐ WIKITEXT103

Bảng 4: Siêu tham số được sử dụng cho thí nghiệm WikiText103. Chúng tôi áp dụng tốc độ học nhỏ hơn cho các phép chiếu điều khiển chuyển đổi trạng thái. Hơn nữa, không có suy giảm trọng số nào được áp dụng cho các tham số này.

Siêu tham số | Giá trị
Số epoch | 100
Kích thước batch | 16
Tốc độ học cơ bản | 0.000125
Tốc độ học chuyển đổi trạng thái | 0.0001
Optimizer | AdamW
Momentum optimizer (β₁, β₂) | 0.9, 0.98
Suy giảm trọng số | 0.25
Lịch trình tốc độ học | cosine decay (linear warm-up)
Số bước warm-up | 5000
n_layer | 12
d_channel mixing | 1872
d_model | 624
d_qk | 624
d_v | 624
n_heads | 624
d_h | 1
kích hoạt magnitude | sigmoid
kích hoạt phase | identity

14

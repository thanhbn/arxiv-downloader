# 2306.01220.pdf
# Đã chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/attention/2306.01220.pdf
# Kích thước tệp: 978616 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
Các Mô hình Ngôn ngữ Lớn có Chú ý Tương tự như
Lập trình viên Con người khi Tạo mã không?
BONAN KOU, Đại học Purdue, Mỹ
SHENGMAI CHEN∗,Đại học Brown, Mỹ
ZHIJIE WANG, Đại học Alberta, Canada
LEI MA, Đại học Tokyo, Nhật Bản và Đại học Alberta, Canada
TIANYI ZHANG, Đại học Purdue, Mỹ
Các Mô hình Ngôn ngữ Lớn (LLM) gần đây đã được sử dụng rộng rãi cho việc tạo mã. Do tính phức tạp
và mờ đục của LLM, ít được biết về cách các mô hình này tạo ra mã. Chúng tôi đã thực hiện nỗ lực đầu tiên để
khắc phục khoảng cách kiến thức này bằng cách điều tra xem liệu LLM có chú ý đến cùng những phần của mô tả nhiệm vụ
như lập trình viên con người trong quá trình tạo mã. Một phân tích về sáu LLM, bao gồm GPT-4, trên hai điểm chuẩn
tạo mã phổ biến đã tiết lộ sự không phù hợp nhất quán giữa sự chú ý của LLM và lập trình viên.
Chúng tôi đã phân tích thủ công 211 đoạn mã không chính xác và tìm thấy năm mẫu chú ý có thể được sử dụng để
giải thích nhiều lỗi tạo mã. Cuối cùng, một nghiên cứu người dùng cho thấy sự chú ý của mô hình được tính toán bởi một
phương pháp dựa trên nhiễu loạn thường được ưa chuộng bởi lập trình viên con người. Những phát hiện của chúng tôi làm nổi bật nhu cầu về
LLM phù hợp với con người để có khả năng diễn giải tốt hơn và sự tin tưởng của lập trình viên.
Khái niệm CCS: •Phần mềm và kỹ thuật của nó ;•Phương pháp tính toán →Xử lý ngôn ngữ
tự nhiên ;
Từ khóa và Cụm từ Bổ sung: Tạo Mã, Mô hình Ngôn ngữ Lớn, Chú ý
Định dạng Tham khảo ACM:
Bonan Kou, Shengmai Chen, Zhijie Wang, Lei Ma, and Tianyi Zhang. 2024. Các Mô hình Ngôn ngữ Lớn có Chú ý
Tương tự như Lập trình viên Con người Khi Tạo Mã không?. Proc. ACM Softw. Eng. 1, FSE, Bài viết 100
(Tháng 7 năm 2024), 24 trang. https://doi.org/10.1145/3660807
1 GIỚI THIỆU
Các Mô hình Ngôn ngữ Lớn (LLM) đã có tiến bộ đáng kể trong việc tạo mã trong những
năm gần đây [ 4,5,26,27,29,32,36,43,87]. Một nghiên cứu gần đây [ 14] cho thấy GPT-4, LLM tối tân
nhất với 1.7 nghìn tỷ tham số, có thể giải quyết chính xác 84% các nhiệm vụ lập trình Python
từ điểm chuẩn HuamnEval [ 27]. Bất chấp tiến bộ lớn này, vẫn không rõ tại sao và làm thế nào
LLM có thể tạo ra mã chính xác từ các mô tả ngôn ngữ tự nhiên.
Phân tích sự chú ý của mô hình là một phương pháp luận phổ biến để hiểu cách một mô hình hoạt động. Nó đã
được áp dụng rộng rãi trong thị giác máy tính [ 31,38,42,44,59,63,80,101] để điều tra xem một
mô hình có chú ý đến các phần nổi bật của hình ảnh khi đưa ra quyết định hay không. Đặc biệt, gần đây
∗Công việc này được thực hiện khi Shengmai Chen là sinh viên đại học tại Đại học Purdue.
Địa chỉ tác giả: Bonan Kou, Đại học Purdue, West Lafayette, Mỹ, koub@purdue.edu; Shengmai Chen, Đại học Brown
, Providence, Mỹ, shengmai_chen@brown.edu; Zhijie Wang, Đại học Alberta, Edmonton, Canada, zhijie.
wang@ualberta.ca; Lei Ma, Đại học Tokyo, Tokyo, Nhật Bản và Đại học Alberta, Edmonton, Canada, ma.lei@
acm.org; Tianyi Zhang, Đại học Purdue, West Lafayette, Mỹ, tianyi@purdue.edu.
Quyền tạo bản sao kỹ thuật số hoặc bản cứng toàn bộ hoặc một phần công trình này cho mục đích sử dụng cá nhân hoặc lớp học được cấp miễn phí
với điều kiện các bản sao không được tạo ra hoặc phân phối vì lợi nhuận hoặc lợi thế thương mại và các bản sao phải ghi rõ thông báo này và
trích dẫn đầy đủ trên trang đầu. Bản quyền đối với các thành phần của công trình này thuộc sở hữu của những người khác ngoài (các) tác giả phải được tôn trọng.
Tóm tắt có ghi công được phép. Để sao chép theo cách khác, hoặc tái xuất bản, để đăng trên máy chủ hoặc để phân phối lại cho danh sách, yêu cầu
quyền cụ thể trước và/hoặc phí. Yêu cầu quyền từ permissions@acm.org.
©2024 Bản quyền thuộc về chủ sở hữu/tác giả. Quyền xuất bản được cấp phép cho ACM.
ACM 2994-970X/2024/7-ART100
https://doi.org/10.1145/3660807
Proc. ACM Softw. Eng., Vol. 1, No. FSE, Article 100. Publication date: July 2024.arXiv:2306.01220v2  [cs.SE]  23 May 2024

--- TRANG 2 ---
100:2 Bonan Kou, Shengmai Chen, Zhijie Wang, Lei Ma, and Tianyi Zhang
các nghiên cứu tìm thấy rằng việc căn chỉnh sự chú ý của mô hình với sự chú ý của con người có thể nâng cao hiệu quả
hiệu suất mô hình một cách hiệu quả [ 8,34,42]. Ví dụ, Huang et al. [ 42] cho thấy hiệu suất của các
mô hình phân loại hình ảnh dựa trên Conv-4 có thể được tăng lên đến 23% khi chúng được huấn luyện để căn chỉnh với
sự chú ý của con người. Hơn nữa, các nghiên cứu trước đây cũng cho thấy người dùng có nhiều tin tưởng và
niềm tin hơn vào các mô hình phù hợp với con người [ 13,40,75,89]. Ví dụ, Boggust et al. [ 13] tìm thấy rằng người dùng
xác định độ tin cậy của một mô hình bằng cách kiểm tra xem mô hình có đưa ra dự đoán dựa
trên các đặc trưng mà họ coi là quan trọng hay không.
Những phát hiện này dẫn đến một câu hỏi khoa học quan trọng cho việc tạo mã dựa trên LLM— liệu LLM có
chú ý đến các phần tương tự của mô tả nhiệm vụ như lập trình viên con người trong việc tạo mã không? Chúng tôi chọn
so sánh sự chú ý của mô hình với sự chú ý của con người, vì nó có thể giúp chúng tôi xác định xem LLM có nắm bắt
ngữ nghĩa sâu trong mô tả nhiệm vụ như con người hay chúng chỉ học các mẫu bề mặt
từ dữ liệu huấn luyện, đó là một vấn đề phổ biến được biết đến trong học máy. Hơn nữa, bằng cách
so sánh các mẫu chú ý của con người và mô hình, chúng tôi tìm cách điều tra xem sự khác biệt về chú ý
có thể được sử dụng để giải thích một số lỗi tạo mã và thông báo các cơ hội mới để
cải thiện LLM cho việc tạo mã hay không.
Để khắc phục khoảng cách kiến thức, chúng tôi đã thực hiện nỗ lực đầu tiên để tiết lộ quá trình tạo mã của
LLM bằng cách phân tích những phần nào của ngôn ngữ con người mà LLM chú ý đến khi tạo mã . Chúng tôi
trình bày một nghiên cứu quy mô lớn kiểm tra sự căn chỉnh chú ý giữa sáu LLM và lập trình viên
con người trên hai điểm chuẩn tạo mã phổ biến— điểm chuẩn HumanEval của OpenAI [ 27]
và điểm chuẩn MBPP của Google [ 7]. Giả thuyết là LLM nên tạo mã dựa
trên các từ nổi bật từ mô tả NL tương tự như lập trình viên con người, thay vì tạo
mã dựa trên các token tầm thường như giới từ và dấu phân cách. Cụ thể, chúng tôi đã điều tra
các câu hỏi nghiên cứu sau trong nghiên cứu này:
RQ1 Mức độ chú ý của mô hình căn chỉnh với sự chú ý của con người đến đâu?
RQ2 Sự chú ý có thể giải thích lỗi của các mô hình tạo mã không?
RQ3 Tác động của các phương pháp tính toán chú ý khác nhau đến sự căn chỉnh chú ý là gì?
RQ4 Phương pháp tính toán chú ý nào được lập trình viên ưa chuộng nhất?
Vì không có điểm chuẩn tạo mã hiện có nào chứa thông tin chú ý của lập trình viên
,chúng tôi đã tạo ra bộ dữ liệu chú ý lập trình viên đầu tiên cho các nhiệm vụ lập trình từ HumanEval
và MBPP (tổng cộng 1,138 nhiệm vụ). Chúng tôi đã ghi lại sự chú ý của lập trình viên bằng cách yêu cầu hai lập trình viên
có kinh nghiệm gắn nhãn thủ công các từ và cụm từ mà họ coi là thiết yếu để giải quyết mỗi
nhiệm vụ lập trình. Nhãn của họ được xác thực bởi một lập trình viên thứ ba. Mặt khác, để ghi lại
sự chú ý của mô hình, chúng tôi đã triển khai và thử nghiệm với mười hai phương pháp tính toán chú ý khác nhau
trong ba danh mục— dựa trên tự chú ý ,dựa trên gradient , và dựa trên nhiễu loạn . Để đảm bảo
phát hiện của chúng tôi khái quát hóa trên các LLM khác nhau, chúng tôi đã phân tích sự chú ý của sáu LLM với
kích thước khác nhau, bao gồm GPT-4 [ 2], InCoder-1.3B [ 32], CoderGen-2.7B [ 62], PolyCoder-2.7B [ 91],
CodeParrot-1.5B [1], và GPT-J-6B [87].
Nghiên cứu của chúng tôi tiết lộ một số hiểu biết quan trọng về quá trình tạo mã của LLM. Đầu tiên,
chúng tôi tìm thấy sự không căn chỉnh chú ý nhất quán trong tất cả sáu LLM, bất kể các phương pháp tính toán chú ý.
Hơn nữa, chúng tôi đã thực hiện phân tích sâu về các mẫu chú ý của 211 mã không chính xác
được tạo ra bởi hai mô hình tốt nhất trong nghiên cứu của chúng tôi, CodeGen-2.7B, và GPT-4. Chúng tôi tìm thấy rằng 27%
lỗi tạo mã có thể được giải thích bởi năm mẫu chú ý. Cuối cùng, các phương pháp dựa trên nhiễu loạn
đã tạo ra điểm chú ý tổng thể phù hợp hơn với sự chú ý của con người hơn
các phương pháp khác. Chúng cũng được ưa chuộng bởi lập trình viên con người, theo một nghiên cứu người dùng với 22
người tham gia. Những phát hiện của chúng tôi làm nổi bật nhu cầu phát triển LLM phù hợp với con người và cung cấp hướng dẫn thực tế
để cải thiện việc tạo mã dựa trên LLM và tính toán sự chú ý của mô hình.
Tóm lại, bài báo này có những đóng góp sau:
Proc. ACM Softw. Eng., Vol. 1, No. FSE, Article 100. Publication date: July 2024.

--- TRANG 3 ---
Các Mô hình Ngôn ngữ Lớn có Chú ý Tương tự như Lập trình viên Con người Khi Tạo Mã không? 100:3
●Chúng tôi đã tiến hành nghiên cứu thực nghiệm đầu tiên về sự căn chỉnh chú ý của LLM và lập trình viên con người
trên các nhiệm vụ tạo mã.
●Chúng tôi đã tiến hành phân tích so sánh các phương pháp tính toán chú ý khác nhau cho các mô hình tạo mã
thông qua cả thử nghiệm định lượng và nghiên cứu người dùng.
●Chúng tôi đã công khai bộ dữ liệu chú ý lập trình viên đầu tiên của 1,138 nhiệm vụ Python, có thể
được sử dụng để phát triển các mô hình phù hợp với con người mới và đánh giá các phương pháp diễn giải cho các mô hình tạo mã
. Mã và dữ liệu của chúng tôi đã được cung cấp trong kho GitHub của chúng tôi [47].
2 ĐỘNG LỰC VÀ KIẾN THỨC CƠ BẢN
Trong phần này, trước tiên chúng tôi giải thích động lực để thực hiện phân tích chú ý cho các mô hình tạo mã.
Sau đó, chúng tôi giới thiệu các điểm chuẩn và số liệu phổ biến cho việc tạo mã. Cuối cùng, chúng tôi định nghĩa
sự chú ý của mô hình và mô tả các loại phương pháp tính toán chú ý khác nhau cho LLM.
2.1 Động lực
Phân tích sự chú ý của mô hình là một nhiệm vụ phổ biến trong một số lĩnh vực, như thị giác máy tính [ 31,44,
59,63], dịch máy thần kinh [ 18], và lái xe tự động [ 38,46,80]. Cụ thể, một số
nghiên cứu cho thấy việc căn chỉnh sự chú ý của mô hình với sự chú ý của con người trong quá trình huấn luyện
có thể cải thiện đáng kể hiệu suất mô hình [ 8,34,42]. Ví dụ, Huang et al. [ 42] cho thấy
bằng cách căn chỉnh sự chú ý của các mô hình dựa trên Conv-4 và ResNet với sự chú ý của con người trên
hình ảnh, hiệu suất của các mô hình này trên phân loại hình ảnh có thể được tăng lên đến 23% trong
cài đặt một lần và 10% trong cài đặt năm lần. Trong lái xe tự động, nhiều nghiên cứu đã
chứng minh rằng việc thêm các ràng buộc căn chỉnh chú ý có thể giúp hệ thống lái xe tự động
lái xe an toàn hơn [ 38,46,80]. Điều này thúc đẩy chúng tôi điều tra sự căn chỉnh chú ý giữa LLM
và lập trình viên con người trong lĩnh vực tạo mã.
Một số nghiên cứu gần đây đã phân tích sự chú ý của các mô hình thần kinh cho tóm tắt mã, sửa chữa chương trình
và dự đoán tên phương thức [ 8,64,68]. Paltenghi et al. [ 64] nghiên cứu sự căn chỉnh chú ý
giữa sự chú ý của mô hình thần kinh và sự chú ý của lập trình viên về tóm tắt mã. Bansal et al. [ 8]
cho thấy việc căn chỉnh sự chú ý của các mô hình tóm tắt mã thần kinh với sự chú ý của con người
có thể cải thiện hiệu quả hiệu suất mô hình. Rabin et al. [ 68] tìm thấy rằng các mô hình mã được huấn luyện trước
phụ thuộc rất nhiều vào chỉ một vài đặc trưng cú pháp trong lời nhắc để thực hiện dự đoán tên phương thức
và phát hiện sử dụng sai biến. Theo hiểu biết tốt nhất của chúng tôi, không có nghiên cứu nào hiện có đã
điều tra các nhiệm vụ tạo mã hoặc LLM với hàng tỷ tham số. Nghiên cứu của chúng tôi lấp đầy khoảng trống này bằng cách
phân tích các mẫu chú ý của sáu LLM trong các nhiệm vụ tạo mã.
Cuối cùng, một động lực khác đằng sau nghiên cứu này là thực tế rằng vẫn chưa có sự đồng thuận về cách
tính toán điểm chú ý của các mô hình mã dựa trên LLM. Điều này phần lớn là do tính phức tạp
của cơ chế chú ý đa đầu, đa lớp được áp dụng bởi các mô hình này. Ví dụ, một số
nghiên cứu chỉ xem xét sự chú ý của mô hình từ lớp transformer đầu tiên và nói rằng lớp đầu tiên
mã hóa thông tin cấp từ vựng [ 10,97], trong khi các nghiên cứu khác tổng hợp sự chú ý từ
tất cả các lớp transformer để kết hợp các mối quan hệ token tầm xa [ 56,85]. Để khắc phục khoảng cách này,
chúng tôi đã tiến hành nghiên cứu toàn diện đầu tiên về 12 phương pháp tính toán chú ý và đánh giá chúng một cách hệ thống
với các thử nghiệm định lượng và nghiên cứu người dùng với 22 người tham gia.
2.2 Điểm chuẩn và Số liệu Tạo mã
Trong công việc này, chúng tôi tập trung vào các nhiệm vụ tạo mã tạo ra một hàm từ mô tả ngôn ngữ tự nhiên.
Kể từ đột phá của mô hình Codex của OpenAI vào năm 2021 [ 27], loại nhiệm vụ tạo mã này
đã trở nên ngày càng phổ biến trong cộng đồng nghiên cứu. Trong cài đặt nhiệm vụ này,
cho trước header hàm và mô tả nhiệm vụ bằng ngôn ngữ tự nhiên, một LLM được kỳ vọng hoàn thành
hàm theo mô tả nhiệm vụ. Hình 1 cho thấy một ví dụ.
Proc. ACM Softw. Eng., Vol. 1, No. FSE, Article 100. Publication date: July 2024.

--- TRANG 4 ---
100:4 Bonan Kou, Shengmai Chen, Zhijie Wang, Lei Ma, and Tianyi Zhang
Hình 1. Một hàm Python được tạo bởi CodeGen-2.7B [62]. Mã được tạo được làm nổi bật bằng màu xanh lá cây.
Các mô hình tạo mã thường được đánh giá trên các điểm chuẩn lập trình được cộng đồng đóng góp. OpenAI đã phát triển một điểm chuẩn lập trình gọi là HumanEval và sử dụng nó để đánh giá mô hình Codex gốc
và các biến thể của nó [ 27]. HumanEval [ 27] bao gồm 164 nhiệm vụ lập trình Python và
các giải pháp thực tế. Nó cho đến nay là điểm chuẩn phổ biến nhất và đã được sử dụng để đánh giá hầu hết
các mô hình tạo mã dựa trên LLM. Ngoài ra, MBPP là một điểm chuẩn lớn [ 7] với 974 nhiệm vụ lập trình
được cộng đồng đóng góp và các giải pháp. Cả HumanEval và MBPP đều bao gồm các trường hợp thử nghiệm để đánh giá
tính chính xác chức năng của mã được tạo.
Hai loại số liệu thường được sử dụng để đánh giá hiệu suất của các mô hình tạo mã dựa trên LLM.
Đầu tiên, nếu một điểm chuẩn tạo mã bao gồm các trường hợp thử nghiệm, người ta có thể đơn giản chạy các trường hợp thử nghiệm
để đánh giá tính chính xác của mã được tạo. Một số liệu điển hình trong danh mục này là Pass@k .
Pass@k ban đầu được giới thiệu bởi Kulal et al. [ 50]. Nó đo lường tỷ lệ phần trăm của các nhiệm vụ lập trình
được giải quyết chính xác trong đó 𝑘đề cập đến số lượng mẫu mã được tạo bởi LLM. Nếu bất kỳ
𝑘mẫu nào vượt qua tất cả các trường hợp thử nghiệm trong một nhiệm vụ, nhiệm vụ đó được coi là được giải quyết chính xác. OpenAI sau đó
giới thiệu một phiên bản không thiên vị của Pass@k để giảm biến động, được sử dụng rộng rãi để đánh giá
các mô hình tạo mã ngày nay [ 27]. Trong thực tế, nhiều nhiệm vụ lập trình không có các trường hợp thử nghiệm hiện có
và một số giải pháp mã không có giao diện hàm được định nghĩa rõ ràng để kiểm tra, ví dụ: một
dòng mã duy nhất mà không có đầu vào và đầu ra rõ ràng. Do đó, công việc trước đây cũng đo lường sự tương tự
giữa mã được tạo và giải pháp thực tế như một đại diện cho tính chính xác. BLEU [ 65] và
CodeBLEU [ 69] là các số liệu tương tự được áp dụng phổ biến. BLEU là một số liệu thường được sử dụng để
đánh giá chất lượng văn bản được tạo bởi máy. Nó đánh giá chất lượng văn bản được tạo bởi máy
bằng cách so sánh sự hiện diện của n-gram trong văn bản được tạo với những n-gram trong văn bản tham khảo. BLEU
tính toán một điểm số từ 0 đến 1, với 1 biểu thị sự tương tự hoàn hảo. CodeBLEU được thiết kế để
điều chỉnh BLEU cụ thể cho việc đánh giá mã được tạo. Trong khi BLEU chủ yếu xem xét sự tương tự ở cấp độ từ,
CodeBLEU xem xét cấu trúc và tính chính xác của mã được tạo, đó là
các khía cạnh quan trọng trong các nhiệm vụ tạo mã.
2.3 Sự chú ý của Mô hình
Trong công việc này, chúng tôi sử dụng sự chú ý của mô hình để đề cập đến mức độ quan trọng của một token trong mô tả nhiệm vụ
ngôn ngữ tự nhiên được coi là quan trọng bởi một LLM trong quá trình tạo mã. Nó ngụ ý những phần nào của
đầu vào mà mô hình "chú ý" đến trong quá trình tạo mã. Ý tưởng này giống với tầm quan trọng của đặc trưng [41],
bản đồ nổi bật [61], và gán đặc trưng [60] trong tài liệu XAI. Chúng tôi mô tả ba loại
phương pháp tính toán sự chú ý của mô hình như sau.
2.3.1 Phương pháp dựa trên Tự chú ý. Cơ chế tự chú ý cho phép transformer cân nhắc
tầm quan trọng của các phần khác nhau của đầu vào khi đưa ra dự đoán. Bằng cách tập trung vào những
Proc. ACM Softw. Eng., Vol. 1, No. FSE, Article 100. Publication date: July 2024.

--- TRANG 5 ---
Các Mô hình Ngôn ngữ Lớn có Chú ý Tương tự như Lập trình viên Con người Khi Tạo Mã không? 100:5
Hình 2. Ma trận chú ý của đầu chú ý đầu tiên của lớp transformer trong CodeGen-2.7B
token có liên quan nhất với điểm tự chú ý cao nhất, transformer có thể đưa ra dự đoán tốt hơn
bằng cách nắm bắt mối quan hệ và phụ thuộc trong đầu vào.
Một LLM bao gồm nhiều lớp transformer , mỗi lớp bao gồm nhiều đầu chú ý .
Những đầu chú ý này tính toán độc lập điểm tự chú ý giữa các token đầu vào khác nhau.
Do đó, một mô hình transformer có thể có nhiều nguồn chú ý mô hình từ các
lớp transformer khác nhau và các đầu chú ý khác nhau trong mỗi lớp. Ví dụ, Hình 2 cho thấy
điểm tự chú ý của ba đầu chú ý đầu tiên của lớp transformer đầu tiên trong CodeGen-2.7B khi tạo token "numbers" từ chuỗi đầu vào "Return the max between two" . Điểm tự chú ý
được tính toán bởi các đầu chú ý khác nhau khác nhau cho cùng một token. Các đầu khác nhau
đại diện cho các loại "tập trung" khác nhau từ mô hình.
Để tính toán sự chú ý của mô hình trên chuỗi đầu vào, vector của điểm tự chú ý từ các
lớp chú ý khác nhau và các đầu chú ý khác nhau trong mỗi lớp cần được tổng hợp thành một
vector duy nhất để đại diện cho tầm quan trọng tổng thể của mỗi token đầu vào đối với dự đoán mô hình. Tuy nhiên,
mặc dù điểm tự chú ý đã được sử dụng chung như sự chú ý của mô hình [ 20,33,52,84], vẫn
chưa có sự đồng thuận về cách tổng hợp điểm tự chú ý từ các lớp và đầu chú ý khác nhau. Ví dụ, một số nghiên cứu tổng hợp điểm chú ý từ tất cả các lớp transformer
và tất cả các đầu chú ý trong mỗi lớp [ 99] như điểm chú ý cuối cùng. Những nghiên cứu này lập luận rằng chiến lược tổng hợp này có thể nắm bắt mối quan hệ token tầm xa. Một số nghiên cứu khác chỉ sử dụng
điểm chú ý từ lớp transformer đầu tiên và lập luận rằng lớp đầu tiên nắm bắt các phụ thuộc ở cấp độ từ vựng [10, 97].
Để tiết lộ cách các cách khác nhau để tổng hợp tự chú ý ảnh hưởng đến sự căn chỉnh giữa mô hình và
sự chú ý của con người, chúng tôi đã thử nghiệm với sáu phương pháp dựa trên tự chú ý trong nghiên cứu này (chi tiết trong
Phần 4.2.1).
2.3.2 Phương pháp dựa trên Gradient. Phương pháp dựa trên gradient tận dụng gradient của dự đoán của mô hình
liên quan đến các đặc trưng đầu vào để tính toán sự chú ý của mô hình. Việc tính toán của
phương pháp dựa trên gradient bao gồm hai bước khác nhau: (1) thực hiện một lần truyền xuôi của đầu vào quan tâm, và (2) tính toán gradient bằng cách sử dụng lan truyền ngược qua các lớp của mạng thần kinh. Bằng cách
phân tích độ lớn của những gradient này, những phương pháp này có thể xác định token đầu vào nào
có ảnh hưởng nhất trong việc xác định đầu ra. Ví dụ, Integrated Gradients là một phương pháp dựa trên gradient
tính toán tích phân của gradient của đầu ra mô hình liên quan đến mỗi đặc trưng đầu vào
[ 23,76,81]. Trong nghiên cứu này, chúng tôi đã thử nghiệm với hai phương pháp dựa trên gradient được sử dụng trong
công việc trước đây [76, 78] với chi tiết trong Phần 4.2.2.
Proc. ACM Softw. Eng., Vol. 1, No. FSE, Article 100. Publication date: July 2024.

--- TRANG 6 ---
100:6 Bonan Kou, Shengmai Chen, Zhijie Wang, Lei Ma, and Tianyi Zhang
2.3.3 Phương pháp dựa trên Nhiễu loạn. Khác với hai danh mục phương pháp trước đây,
phương pháp dựa trên nhiễu loạn [ 84,90] là bất khả tri mô hình. Nói cách khác, chúng không yêu cầu
truy cập vào thông tin bên trong của một mô hình. Phương pháp dựa trên nhiễu loạn đặc biệt hữu ích
để tính toán sự chú ý của các mô hình thương mại như GPT-4, vì những mô hình này không tiết lộ
các lớp tự chú ý hoặc gradient của chúng cho người dùng.
Phương pháp dựa trên nhiễu loạn đầu tiên biến đổi đầu vào và sau đó tính toán sự chú ý của mô hình dựa
trên sự khác biệt đầu ra. LIME [ 70] và SHAP [ 57] là hai phương pháp dựa trên nhiễu loạn phổ biến.
LIME [ 70] tạo ra một giải thích cục bộ bằng cách xấp xỉ dự đoán mô hình cụ thể với một
mô hình đơn giản hơn (ví dụ: một bộ phân loại tuyến tính). SHAP [ 57] nâng cao LIME bằng cách làm nhiễu đầu vào dựa
trên lý thuyết trò chơi và sử dụng giá trị Shapely để ước tính tầm quan trọng của các token khác nhau.
Một hạn chế của hai phương pháp này là chúng thường yêu cầu một số lượng lớn mẫu nhiễu loạn
để đảm bảo độ chính xác ước tính. Điều này tốn kém để tính toán sự chú ý cho GPT-4, vì chúng ta cần
truy vấn GPT-4 nhiều lần. Hơn nữa, LIME và SHAP chỉ biến đổi đầu vào bằng cách xóa token,
có thể thay đổi đáng kể ý nghĩa hoặc cấu trúc của đầu vào. Để giải quyết hạn chế này,
các phương pháp dựa trên nhiễu loạn gần đây hơn chọn thay thế token bằng token tương tự hoặc có liên quan về mặt ngữ nghĩa
trong ngữ cảnh [ 54,90]. Chúng thường sử dụng một mô hình ngôn ngữ có mặt nạ như BERT [ 25]
để dự đoán token tương tự hoặc có liên quan về mặt ngữ nghĩa để thay thế token hiện có trong đầu vào. Sau đó,
chúng đo lường ảnh hưởng của những thay thế này lên đầu ra. Trong nghiên cứu này, chúng tôi đã thử nghiệm
với SHAP [57] và phương pháp dựa trên che mặt nạ BERT [90] (chi tiết trong Phần 4.2.3).
3 XÂY DỰNG BỘ DỮ LIỆU CHÚ Ý CỦA LẬP TRÌNH VIÊN
Vì không có điểm chuẩn tạo mã hiện có nào chứa thông tin chú ý của lập trình viên
(tức là từ hoặc cụm từ nào mà lập trình viên coi là quan trọng khi viết mã), chúng tôi đã tạo
bộ dữ liệu chú ý lập trình viên đầu tiên dựa trên 1,138 nhiệm vụ lập trình, bao gồm tất cả 164
lời nhắc từ HumanEval [ 27] và 974 lời nhắc từ MBPP [ 7]. Chúng tôi đã chọn hai bộ dữ liệu này,
vì chúng được sử dụng rộng rãi để đánh giá các mô hình tạo mã và chúng cũng cung cấp trường hợp thử nghiệm cho
mỗi nhiệm vụ lập trình, điều này quan trọng để tính toán tính chính xác của mã do mô hình tạo ra.
Hai tác giả đầu tiên, có hơn năm năm kinh nghiệm lập trình Python,
đã gắn nhãn thủ công các từ và cụm từ mà họ coi là quan trọng để giải quyết nhiệm vụ lập trình
trong mỗi mô tả nhiệm vụ. Trước quá trình gắn nhãn, hai người gắn nhãn đã xem qua các nhiệm vụ lập trình
trong HumanEval để làm quen với các nhiệm vụ lập trình và các giải pháp mã.
Sau đó, họ đầu tiên độc lập gắn nhãn 20 mô tả nhiệm vụ đầu tiên trong HumanEval. Vòng gắn nhãn đầu tiên này
có điểm Cohen's Kappa là 0.68. Hai người gắn nhãn đã thảo luận về sự bất đồng và tóm tắt bốn loại từ khóa
mà cả hai họ đều coi là quan trọng. Bốn loại từ khóa được tóm tắt dưới đây:
●Loại dữ liệu : Từ hoặc cụm từ mô tả các loại dữ liệu mà mã nên nhập hoặc xuất,
như "string" ,"number" , hoặc"list" .
●Toán tử : Từ hoặc cụm từ mô tả các thao tác mà mã nên thực hiện trên
dữ liệu, như "compare" ,"sort" ,"filter" , hoặc"search" .
●Điều kiện : Từ hoặc cụm từ chỉ định các điều kiện mà mã nên thực thi,
như các cụm từ sau "if"và"when" trong mô tả nhiệm vụ.
●Thuộc tính : Thuộc tính quan trọng của dữ liệu và thao tác được thao tác, như bộ định lượng
(ví dụ: "all","one" ), tính từ (ví dụ: "first" ,"closer" ), và trạng từ (ví dụ: "every" ,"none" ).
Mặc dù chỉ có bốn loại từ khóa, mỗi loại được thiết kế để có cấp độ cao và
bao quát. Ví dụ, loại "toán tử" đề cập đến bất kỳ loại thao tác nào trên dữ liệu, như
"sort a list" ,"connect a database" , và "plot a graph" . Với tiêu chuẩn gắn nhãn này, hai người gắn nhãn
Proc. ACM Softw. Eng., Vol. 1, No. FSE, Article 100. Publication date: July 2024.

--- TRANG 7 ---
Các Mô hình Ngôn ngữ Lớn có Chú ý Tương tự như Lập trình viên Con người Khi Tạo Mã không? 100:7
Hình 3. Hai ví dụ về lời nhắc có nhãn từ bộ dữ liệu của chúng tôi.
tiến hành gắn nhãn 144 mô tả nhiệm vụ còn lại trong bộ dữ liệu HumanEval. Điểm Cohen's Kappa
của vòng gắn nhãn này tăng lên 0.72, cho thấy sự đồng thuận đáng kể [ 58]. Sau đó, họ
thảo luận và giải quyết tất cả sự bất đồng.
Để xác thực những nhãn này, tác giả thứ ba, người không tham gia vào quá trình gắn nhãn trước đây,
độc lập gắn nhãn 164 mô tả nhiệm vụ từ bộ dữ liệu HumanEval. Vì Cohen's Kappa
chỉ có thể tính toán mức độ đồng thuận giữa hai người gắn nhãn, chúng tôi đã sử dụng Fleiss' Kappa để đo lường
sự đồng thuận giữa người gắn nhãn thứ ba và nhãn ban đầu từ hai người gắn nhãn đầu tiên. Điểm Fleiss'
Kappa là 0.64, cho thấy sự đồng thuận đáng kể [ 30]. Kết quả này cho thấy nhãn được tạo bởi
hai người gắn nhãn đầu tiên là hợp lý và có thể được chấp nhận bởi các lập trình viên khác. Sau đó, hai người gắn nhãn đầu tiên
tiếp tục gắn nhãn 974 nhiệm vụ lập trình trong bộ dữ liệu MBPP một cách độc lập, điều này
dẫn đến điểm Cohen's Kappa là 0.73. Cuối cùng, họ giải quyết tất cả sự bất đồng và sử dụng
tập hợp nhãn cuối cùng làm bộ dữ liệu chú ý của lập trình viên. Toàn bộ quá trình gắn nhãn mất 192
giờ công.
Trung bình, mỗi mô tả nhiệm vụ có 29.6 từ, trong đó 7 từ được coi là quan trọng
bởi cả hai người gắn nhãn. Trong tất cả bốn loại từ khóa, từ khóa thuộc tính (45.2%) được gắn nhãn
thường xuyên nhất bởi hai người gắn nhãn, tiếp theo là toán tử (27.2%), điều kiện (25%), và loại dữ liệu
(2.6%). Hình 3 cho thấy hai ví dụ về mô tả nhiệm vụ có nhãn. Bốn loại từ khóa được
gắn nhãn bằng các màu khác nhau.
4 PHƯƠNG PHÁP LUẬN
Phần này mô tả thiết kế nghiên cứu để trả lời các câu hỏi nghiên cứu được liệt kê trong Phần 1.
4.1 Mô hình Tạo Mã
Trong nghiên cứu này, chúng tôi chọn sáu LLM với kích thước khác nhau và hiệu suất mô hình khác nhau trên các nhiệm vụ tạo mã. Bảng 1 cho thấy kích thước, số lớp tự chú ý, số đầu chú ý
trong mỗi lớp, và hiệu suất mô hình trên bộ dữ liệu kết hợp của HumanEval và MBPP
theo Pass@1. Chúng tôi mô tả mỗi mô hình dưới đây.
●InCoder-1.3B [ 32]là một mô hình ngôn ngữ mã nguồn mở từ Meta AI. Nó được huấn luyện trên 159
GB mã được cấp phép có điều kiện từ GitHub, GitLab, và Stack Overflow. So với
các LLM khác, nó áp dụng mục tiêu che mặt nạ nhân quả mới, cho phép nó điền vào các khối mã
dựa trên ngữ cảnh trái và phải tùy ý. Chúng tôi đã sử dụng mô hình được huấn luyện trước lớn nhất
được Meta phát hành, bao gồm 1.3B tham số và 24 lớp transformer.
●PolyCoder-2.7B [ 91]là một mô hình nguồn mở từ CMU. Nó dựa trên kiến trúc GPT-2
và được thiết kế để trở thành đối tác nguồn mở của OpenAI Codex [ 27], vì Codex không
được mở nguồn. Nó được huấn luyện trên 249GB mã và có 2.7B tham số.
Proc. ACM Softw. Eng., Vol. 1, No. FSE, Article 100. Publication date: July 2024.

--- TRANG 8 ---
100:8 Bonan Kou, Shengmai Chen, Zhijie Wang, Lei Ma, and Tianyi Zhang
Bảng 1. Mô hình tạo mã được bao gồm trong nghiên cứu này.
Mô hình Lớp Đầu Pass@1
InCoder-1.3B 24 32 15.20%
PolyCoder-2.7B 32 32 5.59%
CodeGen-2.7B 32 32 23.70%
CodeParrot-1.5B 48 25 3.58%
GPT-J-6B 28 16 11.62%
GPT-4 - - 67%
●CodeGen-Mono-2.7B [ 62]là một mô hình nguồn mở từ Salesforce Research. Nó tuân theo
kiến trúc mô hình tự hồi quy transformer tiêu chuẩn với mã hóa vị trí xoay.
●CodeParrot-1.5B [ 1]là một nỗ lực nguồn mở khác để huấn luyện mô hình GPT-2 cho việc tạo mã.
Nó được huấn luyện trên 180GB Python Code và có 1.5B tham số.
●GPT-J-6B [ 87]là một mô hình nguồn mở từ EleutherAI. Nó áp dụng kiến trúc transformer
tương tự như GPT-3. Nó được huấn luyện trên 825 GB dữ liệu văn bản, bao gồm 95GB mã từ GitHub.
●GPT-4 [ 2]là mô hình ngôn ngữ tối tân được phát triển bởi OpenAI. Vì cấu trúc bên trong
của GPT-4 không được tiết lộ công khai, chúng tôi không bao gồm số lượng lớp và đầu của
GPT-4 trong Bảng 1. Được báo cáo rằng GPT-4 có khoảng 1.76 nghìn tỷ tham số [ 3]. Chúng tôi đã sử dụng
API ( gpt-4 ) được cung cấp bởi OpenAI để truy vấn GPT-4.
4.2 Tính toán Sự chú ý của Mô hình
Chúng tôi đã thử nghiệm với mười hai phương pháp tính toán chú ý từ ba danh mục khác nhau: sáu
phương pháp dựa trên tự chú ý, bốn phương pháp dựa trên gradient, và hai phương pháp dựa trên nhiễu loạn.
4.2.1 Phương pháp dựa trên Tự chú ý. Cho rằng LLM có nhiều lớp chú ý, hiện tại
không có sự đồng thuận về cách đúng để tổng hợp những tự chú ý đó để giải thích
LLM. Zeng et al. [ 97] cho thấy rằng lớp chú ý đầu tiên chỉ ra token nào mà mô hình
chú ý đến, trong khi Wan et al. [ 85] cho thấy rằng các lớp chú ý sâu hơn tốt hơn trong việc nắm bắt phụ thuộc tầm xa
và cấu trúc chương trình. Để thực hiện phân tích toàn diện, chúng tôi quyết định
thử nghiệm với ba cài đặt: (1) chỉ sử dụng lớp chú ý đầu tiên (ký hiệu là first), (2) chỉ
sử dụng lớp chú ý cuối cùng (ký hiệu là last), và (3) sử dụng tất cả các lớp chú ý (ký hiệu là all).
Để tổng hợp tự chú ý trên các đầu chú ý khác nhau trong một lớp, chúng tôi tuân theo
công việc trước đây [ 99] bằng cách tổng hợp các giá trị chú ý từ các đầu khác nhau. Cuối cùng, vì LLM tạo mã
theo cách tự hồi quy, sự chú ý của chúng thay đổi trong mỗi bước khi chúng đọc thêm token từ
đầu vào và khi chúng tạo thêm mã. Chúng tôi tò mò về token đầu vào nào mà mô hình
chú ý cao khi chúng đọc đầu vào và token đầu vào nào mà mô hình chú ý cao khi
chúng tạo mã. Vì vậy chúng tôi xem xét hai cài đặt thử nghiệm: (1) tổng hợp điểm chú ý
được gán cho mỗi token trong quá trình đọc đầu vào (ký hiệu là READING ), và (2) tổng hợp
điểm chú ý được gán cho mỗi token trong quá trình tạo mã (ký hiệu là CODING ).
Cho ba cài đặt trong tổng hợp chú ý theo lớp và hai cài đặt trong tổng hợp chú ý theo bước,
chúng tôi có tổng cộng sáu cài đặt thử nghiệm: READING_first ,CODING_first ,
READING_last ,CODING_last ,READING_all , và CODING_all .
4.2.2 Phương pháp dựa trên Gradient. Chúng tôi xem xét hai phương pháp khác nhau để tính toán sự chú ý mô hình dựa trên gradient: (1) Saliency [78], và (2) Input×Gradient [76]. Phương pháp saliency tính toán
sự chú ý của mô hình bằng cách tính toán gradient mô hình liên quan đến đầu vào. Cho một LLM ℱ,
giả sử đầu vào là 𝑋=(︀𝑥1,𝑥2,...,𝑥𝑛⌋︀, trong đó 𝑛là độ dài của đầu vào. Sự chú ý 𝑠𝑖trên 𝑥𝑖được
Proc. ACM Softw. Eng., Vol. 1, No. FSE, Article 100. Publication date: July 2024.

--- TRANG 9 ---
Các Mô hình Ngôn ngữ Lớn có Chú ý Tương tự như Lập trình viên Con người Khi Tạo Mã không? 100:9
tính toán như 𝑠𝑖=𝜕ℱ{︃𝑋}︃
𝜕𝑥 𝑖. Khác với phương pháp saliency, Input×Gradient còn nhân
gradient với giá trị embedding của đầu vào. Sự chú ý 𝑠𝑖trên 𝑥𝑖được tính toán như 𝑠𝑖=𝑥𝑖⋅𝜕ℱ{︃𝑋}︃
𝜕𝑥 𝑖.
Tương tự như tự chú ý, gradient cũng thay đổi liên tục tại mỗi bước tạo. Do đó, chúng tôi cũng
thử nghiệm với hai cài đặt tổng hợp chú ý theo bước như trong các phương pháp tự chú ý.
Sự kết hợp của hai phương pháp tính toán gradient với hai cài đặt tổng hợp theo bước
dẫn đến bốn phương pháp dựa trên gradient— Input×Gradient_reading ,Input×Gradient_coding ,
Saliency_reading , và Saliency_coding .
4.2.3 Phương pháp dựa trên Nhiễu loạn. Chúng tôi xem xét hai phương pháp dựa trên nhiễu loạn khác nhau: (1)
SHAP [57], che mặt nạ đầu vào thông qua việc xóa một số token, và (2) BERT Masking [90], che mặt nạ
đầu vào thông qua việc thay thế một token bằng kết quả dự đoán mô hình ngôn ngữ có mặt nạ của nó
từ BERT.
●SHAP . Chúng tôi sử dụng thư viện SHAP chính thức với số lần nhiễu loạn bằng 50 để tính toán
sự chú ý của mô hình (điểm SHAP) trên các token khác nhau.1Chúng tôi tổng hợp điểm SHAP về dự đoán
các token khác nhau bằng cách tổng hợp chúng lại.
●BERT Masking . Vì mã từ bài báo BERT Masking gốc [ 90] không có sẵn công khai,
chúng tôi đã triển khai lại phương pháp này dựa trên mô tả trong bài báo. Cụ thể, cho mỗi
token trong lời nhắc đầu vào, phương pháp này che mặt nạ nó và sử dụng mô hình BERT được huấn luyện trước từ HuggingFace để dự đoán token có khả năng nhất ở vị trí bị che mặt nạ. Sau đó, nó thay thế token gốc
bằng token được dự đoán và nhắc LLM để tái tạo giải pháp mã. Phương pháp này sau đó tính toán
sự chú ý của mô hình trên token này bằng cách tính toán điểm BLEU [ 65]
giữa giải pháp mã gốc và giải pháp mới. Chúng tôi lặp qua tất cả các token trong
lời nhắc đầu vào để có được sự chú ý của mô hình trên các token khác nhau.
4.3 Đo lường Căn chỉnh Chú ý
Chúng tôi đã đo lường sự căn chỉnh chú ý giữa mô hình và lập trình viên con người bằng cách sử dụng hai
số liệu mạnh mẽ—số liệu chồng lấp token của San Martino [ 22] và alpha của Krippendorff [ 49]. Chúng tôi cũng
thử nghiệm với hai số liệu đơn giản, kappa của Cohen và tỷ lệ bao phủ từ khóa, và thu được
kết quả tương tự. Do giới hạn trang, chúng tôi chỉ báo cáo kết quả của hai số liệu đầu tiên trong
bài báo này. Kết quả của các số liệu khác được bao gồm trong kho GitHub [47].
4.3.1 Số liệu Chồng lấp Token của San Martino [ 22]tính toán sự chồng lấp giữa hai tập hợp
token theo độ chính xác, thu hồi, và điểm F-1. Nó ban đầu được thiết kế cho các nhiệm vụ gắn nhãn chuỗi
trong NLP [ 22] và gần đây đã được áp dụng trong các nghiên cứu SE như một số liệu mạnh mẽ cho việc phát hiện độc tính
trong bình luận đánh giá mã [ 72]. Cụ thể, nó gán điểm một phần cho sự chồng lấp một phần
giữa hai tập hợp token, điều này làm cho nó trở thành lựa chọn phù hợp cho nhiệm vụ của chúng tôi. Do đó, chúng tôi tuân theo [ 22] để
so sánh các từ nổi bật được chọn bởi con người và mô hình. Đối với sự chú ý của con người, một token được coi là
được chú ý cao nếu nó được gắn nhãn là một từ quan trọng bởi lập trình viên con người, như được mô tả trong
Phần 3. Đối với sự chú ý của mô hình, vì các phương pháp tính toán chú ý trong Phần 4.2 tính toán một
điểm liên tục cho mỗi token, khó để xác định ngưỡng phổ quát để quyết định token nào
được mô hình chú ý cao. Do đó, chúng tôi xếp hạng các token trong mô tả nhiệm vụ lập trình dựa
trên điểm chú ý của chúng và chọn 𝐾token hàng đầu như các token được mô hình chú ý cao.
Vì trung bình các từ quan trọng được con người gắn nhãn là 7 mỗi mô tả nhiệm vụ, chúng tôi thử nghiệm với
𝐾=5,10,20trong nghiên cứu của chúng tôi. Cho một tập hợp token được lập trình viên con người chú ý cao và một tập hợp
token được mô hình chú ý cao, chúng tôi tuân theo các phương trình trong [ 72] để tính toán độ chính xác, thu hồi,
và điểm F-1. Chúng tôi báo cáo cả ba điểm trong Bảng 2.
1https://shap.readthedocs.io/en/latest/
Proc. ACM Softw. Eng., Vol. 1, No. FSE, Article 100. Publication date: July 2024.

--- TRANG 10 ---
100:10 Bonan Kou, Shengmai Chen, Zhijie Wang, Lei Ma, and Tianyi Zhang
Hình 4. Ánh xạ từ NL sang sub-token LLM
4.3.2 Alpha của Krippendorff [ 48]là một thước đo thống kê mạnh mẽ cho sự đồng thuận giữa người gắn nhãn, trong đó
𝛼=1biểu thị sự đồng thuận hoàn hảo, 𝛼=0biểu thị không có sự đồng thuận, và 𝛼=−1biểu thị sự
bất đồng hoàn toàn. Nó có thể được sử dụng để đo lường mức độ đồng thuận giữa lập trình viên con người và
LLM về các từ quan trọng trong mô tả nhiệm vụ lập trình. So với các số liệu đồng thuận giữa người đánh giá khác
như kappa của Cohen [ 21], alpha của Krippendorff mạnh mẽ hơn đối với số lượng người mã hóa, dữ liệu thiếu, và kích thước mẫu. Để tính toán alpha của Krippendorff, nhãn của con người và mô hình
phải được lưu trữ trong các vector có cùng độ dài. Điều này khó khăn vì LLM thực hiện token hóa từ phụ
để xử lý các từ ngoài từ vựng với kích thước từ vựng có thể quản lý. Ví dụ,
trong Hình 4, từ "separate" được token hóa thành hai token: "separ" và "ate" thông qua mã hóa cặp byte (BPE). Trong quá trình suy luận, một LLM sẽ tính toán điểm chú ý riêng biệt cho hai
subtoken này, mặc dù chúng từ cùng một từ tiếng Anh.
Để giải quyết thách thức này, chúng tôi ánh xạ từ NL trở lại token LLM. Nếu mô hình token hóa một
từ ngôn ngữ tự nhiên thành nhiều token, tất cả sub-token sẽ được coi là được chọn bởi người gắn nhãn con người.
Sử dụng cùng ví dụ từ Hình 4, nếu từ ngôn ngữ tự nhiên "separate" được chọn bởi
người gắn nhãn con người, cả hai sub-token "separ" và "ate" sẽ được coi là được chọn và được đại diện bởi 1
trong các vector được sử dụng để tính toán alpha của Krippendorff.
4.4 Thiết kế Nghiên cứu Người dùng
Để trả lời RQ4, chúng tôi đã tiến hành nghiên cứu người dùng để đánh giá các phương pháp tính toán chú ý khác nhau.2
Chúng tôi đã tuyển 22 sinh viên (18 nam và 4 nữ) thông qua danh sách email của khoa trong một
khoa CS. Theo nghiên cứu người dùng của chúng tôi, tất cả người tham gia có trung bình 5.62 năm
kinh nghiệm lập trình. Tất cả người tham gia đều có hiểu biết cơ bản về sự chú ý của mô hình trong
học máy.
Chúng tôi đã chọn ngẫu nhiên 8 mô tả nhiệm vụ từ bộ dữ liệu của chúng tôi. Đối với mỗi nhiệm vụ, chúng tôi đã tận dụng CodeGen-2.7B, mô hình nguồn mở có hiệu suất tốt nhất trên HumanEval trong thử nghiệm của chúng tôi, để tính toán
sự chú ý mô hình của nó. Chúng tôi không xem xét GPT-4 trong nghiên cứu người dùng này, vì nó là mã nguồn đóng và chúng tôi không thể
tính toán sự chú ý của nó bằng các phương pháp dựa trên tự chú ý và phương pháp dựa trên gradient. Chúng tôi đã chọn
một phương pháp tính toán chú ý từ mỗi danh mục ( dựa trên tự chú ý ,dựa trên nhiễu loạn , và
dựa trên gradient ):𝐶𝑂𝐷𝐼𝑁𝐺 _𝑙𝑎𝑠𝑡,𝐼𝑛𝑝𝑢𝑡×𝐺𝑟𝑎𝑑𝑖𝑒𝑛𝑡 _𝑐𝑜𝑑𝑖𝑛𝑔 , và SHAP .
Trong mỗi nghiên cứu người dùng, người tham gia đầu tiên đọc mô tả nhiệm vụ để hiểu nhiệm vụ lập trình
và sau đó đọc mã được tạo bởi CodeGen. Đối với mỗi phương pháp chú ý, chúng tôi hiển thị một
phiên bản được làm nổi bật của mô tả nhiệm vụ tương tự như Hình 3, trong đó 10 token được chú ý hàng đầu được làm nổi bật
dựa trên điểm chú ý được tính toán bởi phương pháp này. Chúng tôi chọn hiển thị 10 từ khóa quan trọng hàng đầu
vì nó gần với số lượng từ quan trọng trung bình (7) được gắn nhãn trong bộ dữ liệu của chúng tôi.
2Bảng câu hỏi nghiên cứu người dùng và phản hồi của người tham gia có sẵn trong kho GitHub của chúng tôi:
https://github.com/BonanKou/Attention-Alignment-Empirical-Study.
Proc. ACM Softw. Eng., Vol. 1, No. FSE, Article 100. Publication date: July 2024.

--- TRANG 11 ---
Các Mô hình Ngôn ngữ Lớn có Chú ý Tương tự như Lập trình viên Con người Khi Tạo Mã không? 100:11
Bảng 2. Căn chỉnh chú ý giữa con người và mô hình được tính toán bởi các phương pháp khác nhau theo Độ chính xác của San Martino
(P), Thu hồi (R), điểm F1 (F1), và điểm alpha của Krippendorff (KA). Trong số 12 phương pháp tính toán chú ý khác nhau
, phương pháp tạo ra kết quả phù hợp nhất cho mỗi mô hình dưới mỗi cài đặt 𝐾trong
mỗi số liệu được làm nổi bật bằng màu vàng . Lưu ý rằng chúng tôi chỉ thử nghiệm với các phương pháp dựa trên nhiễu loạn trên
GPT-4, vì GPT-4 không cung cấp quyền truy cập vào các lớp tự chú ý và gradient của nó.
(a) Phương pháp dựa trên nhiễu loạn.
BERT_masking SHAP
Top 5 Top 10 Top 20 Top 5 Top 10 Top 20 Phương pháp
P R F1 KA P R F1 KA P R F1 KA P R F1 KA P R F1 KA P R F1 KA
Incoder 48.8% 40.6% 44.3% 0.25 40.8% 67.4% 50.8% 0.25 36.6% 90.3% 52.1% 0.12 33.9% 28.4% 30.9% 0.11 33.4% 55.9% 41.8% 0.18 32.8% 86.7% 47.6% 0.15
CodeGen 51.8% 43.2% 47.1% 0.29 41.8% 68.9% 52.0% 0.27 36.8% 90.7% 52.4% 0.13 33.0% 27.5% 30.0% 0.10 32.9% 54.9% 41.1% 0.17 33.0% 87.1% 47.9% 0.16
CodeParrot 51.5% 43.0% 46.9% 0.29 42.1% 69.2% 52.3% 0.28 36.6% 90.2% 52.0% 0.12 33.2% 27.7% 30.2% 0.10 32.7% 54.7% 40.9% 0.17 33.3% 87.6% 48.3% 0.17
GPT-J-6B 49.9% 41.3% 45.2% 0.26 41.0% 67.4% 51.0% 0.26 36.6% 90.3% 52.1% 0.12 33.3% 27.8% 30.3% 0.10 33.3% 55.7% 41.7% 0.18 33.1% 87.1% 47.9% 0.16
PolyCoder 49.3% 41.3% 45.0% 0.26 40.9% 67.7% 51.0% 0.26 36.6% 90.4% 52.1% 0.12 34.4% 28.9% 31.4% 0.12 33.5% 56.2% 42.0% 0.19 33.2% 87.2% 48.1% 0.16
GPT-4 32.7% 27.6% 30.0% 0.04 36.7% 61.7% 46.0% 0.17 36.3% 89.4% 51.7% 0.11 34.7% 29.2% 31.7% 0.12 34.2% 57.4% 42.9% 0.20 33.1% 87.0% 47.9% 0.16
(b) Phương pháp dựa trên gradient
Input×Gradient_reading Input×Gradient_coding
Top 5 Top 10 Top 20 Top 5 Top 10 Top 20 Phương pháp
P R F1 KA P R F1 KA P R F1 KA P R F1 KA P R F1 KA P R F1 KA
Incoder 33.7% 25.9% 29.3% 0.13 36.9% 46.8% 41.2% 0.32 35.6% 52.7% 42.5% 0.28 34.6% 27.5% 30.7% 0.14 37.2% 47.1% 41.6% 0.33 35.6% 52.8% 42.5% 0.28
CodeGen 44.8% 34.2% 38.8% 0.22 39.4% 59.8% 47.5% 0.28 35.2% 87.3% 50.1% 0.22 46.0% 34.7% 39.5% 0.23 41.0% 61.5% 49.2% 0.31 36.2% 88.5% 51.4% 0.25
CodeParrot 55.0% 43.2% 48.4% 0.33 45.8% 71.2% 55.8% 0.40 35.1% 87.5% 50.1% 0.22 57.9% 44.9% 50.6% 0.37 46.8% 71.8% 56.7% 0.42 36.0% 88.7% 51.2% 0.24
GPT-J-6B 40.9% 30.7% 35.1% 0.17 37.4% 56.7% 45.1% 0.24 34.5% 85.8% 49.2% 0.20 42.7% 32.5% 36.9% 0.19 39.4% 59.6% 47.4% 0.28 35.5% 87.2% 50.5% 0.22
PolyCoder 43.3% 33.8% 38.0% 0.20 38.3% 59.9% 46.7% 0.26 34.4% 86.2% 49.1% 0.20 38.1% 30.1% 33.6% 0.14 36.4% 57.3% 44.5% 0.23 35.2% 87.4% 50.2% 0.22
Saliency_reading Saliency_coding
Top 5 Top 10 Top 20 Top 5 Top 10 Top 20 Phương pháp
P R F1 KA P R F1 KA P R F1 KA P R F1 KA P R F1 KA P R F1 KA
Incoder 36.6% 29.3% 32.6% 0.06 41.9% 67.3% 51.6% 0.29 41.4% 88.6% 56.4% 0.30 39.4% 31.5% 35.0% 0.09 42.8% 67.3% 52.3% 0.29 41.3% 88.5% 56.4% 0.30
CodeGen 46.1% 34.9% 39.8% 0.23 39.3% 59.6% 47.4% 0.28 35.3% 87.4% 50.3% 0.23 47.3% 35.4% 40.5% 0.24 40.7% 60.8% 48.8% 0.30 36.2% 88.5% 51.4% 0.25
CodeParrot 53.8% 42.1% 47.2% 0.31 44.6% 69.3% 54.3% 0.38 34.8% 86.8% 49.7% 0.21 56.3% 43.7% 49.2% 0.35 45.3% 69.6% 54.9% 0.39 35.7% 87.9% 50.8% 0.23
GPT-J-6B 41.2% 30.6% 35.1% 0.17 35.5% 53.1% 42.6% 0.20 34.2% 85.1% 48.8% 0.19 41.2% 30.5% 35.0% 0.17 37.5% 56.3% 45.0% 0.24 35.5% 87.2% 50.5% 0.22
PolyCoder 41.6% 32.5% 36.5% 0.18 36.5% 56.9% 44.5% 0.23 34.2% 85.9% 49.0% 0.20 36.7% 29.0% 32.4% 0.13 35.3% 55.6% 43.2% 0.21 35.0% 87.0% 50.0% 0.22
(c) Phương pháp dựa trên tự chú ý.
READING_first CODING_first
Top 5 Top 10 Top 20 Top 5 Top 10 Top 20 Phương pháp
P R F1 KA P R F1 KA P R F1 KA P R F1 KA P R F1 KA P R F1 KA
Incoder 44.9% 38.5% 41.5% 0.17 46.7% 75.9% 57.8% 0.39 41.7% 90.2% 57.0% 0.31 45.3% 38.0% 41.4% 0.18 45.1% 73.0% 55.7% 0.35 41.4% 89.5% 56.7% 0.30
CodeGen 9.8% 8.3% 9.0% -0.17 26.0% 41.6% 32.0% 0.05 34.0% 84.1% 48.4% 0.19 9.5% 8.5% 9.0% -0.17 25.6% 40.4% 31.3% 0.04 33.8% 83.8% 48.2% 0.19
CodeParrot 33.8% 27.5% 30.3% 0.10 37.9% 59.9% 46.4% 0.26 34.5% 86.2% 49.3% 0.20 44.0% 35.7% 39.4% 0.22 42.2% 67.2% 51.9% 0.35 34.6% 86.6% 49.4% 0.21
GPT-J-6B 6.5% 5.5% 6.0% -0.21 23.0% 33.2% 27.2% -0.03 33.0% 81.3% 46.9% 0.16 7.4% 6.2% 6.7% -0.20 22.2% 33.0% 26.5% -0.04 33.2% 81.9% 47.3% 0.17
PolyCoder 41.4% 32.5% 36.4% 0.19 41.7% 63.7% 50.4% 0.33 35.8% 87.9% 50.8% 0.23 43.8% 33.8% 38.1% 0.20 42.5% 64.8% 51.3% 0.34 35.8% 87.8% 50.9% 0.23
READING_last CODING_last
Top 5 Top 10 Top 20 Top 5 Top 10 Top 20 Phương pháp
P R F1 KA P R F1 KA P R F1 KA P R F1 KA P R F1 KA P R F1 KA
Incoder 40.2% 31.9% 35.6% 0.12 41.2% 64.8% 50.4% 0.27 41.0% 88.8% 56.1% 0.29 41.9% 33.9% 37.5% 0.13 43.2% 69.6% 53.3% 0.31 41.4% 89.3% 56.6% 0.30
CodeGen 33.8% 24.8% 28.6% 0.08 39.5% 59.1% 47.4% 0.29 34.7% 85.2% 49.3% 0.21 31.0% 24.4% 27.3% 0.07 37.4% 57.1% 45.2% 0.25 35.1% 86.4% 49.9% 0.22
CodeParrot 60.1% 45.4% 51.7% 0.38 50.4% 76.4% 60.8% 0.48 37.0% 90.2% 52.4% 0.26 56.4% 43.2% 48.9% 0.35 48.5% 73.6% 58.4% 0.45 36.7% 89.7% 52.1% 0.26
GPT-J-6B 8.8% 7.0% 7.8% -0.19 26.6% 42.7% 32.8% 0.05 33.4% 82.7% 47.5% 0.17 13.8% 10.6% 12.0% -0.14 27.4% 41.8% 33.1% 0.06 33.6% 83.2% 47.9% 0.18
PolyCoder 23.1% 18.1% 20.3% -0.03 34.3% 53.8% 41.9% 0.19 34.7% 86.4% 49.5% 0.21 32.8% 25.7% 28.9% 0.09 37.9% 58.8% 46.1% 0.26 35.4% 87.0% 50.3% 0.22
READING_all CODING_all
Top 5 Top 10 Top 20 Top 5 Top 10 Top 20 Phương pháp
P R F1 KA P R F1 KA P R F1 KA P R F1 KA P R F1 KA P R F1 KA
Incoder 34.8% 32.5% 33.6% 0.08 39.0% 66.7% 49.2% 0.25 40.4% 88.2% 55.4% 0.28 40.6% 39.2% 39.9% 0.16 42.0% 71.8% 53.0% 0.31 41.2% 89.8% 56.5% 0.30
CodeGen 19.6% 14.7% 16.8% -0.09 24.9% 37.0% 29.7% -0.00 34.0% 83.9% 48.4% 0.19 28.4% 23.1% 25.4% 0.03 32.1% 50.7% 39.3% 0.15 34.5% 85.8% 49.2% 0.21
CodeParrot 41.8% 31.8% 36.1% 0.16 39.6% 61.3% 48.1% 0.28 35.1% 87.1% 50.1% 0.22 50.1% 39.7% 44.3% 0.28 43.4% 68.0% 53.0% 0.36 35.2% 87.3% 50.1% 0.22
GPT-J-6B 12.6% 10.2% 11.3% -0.15 22.9% 35.0% 27.7% -0.04 33.8% 83.6% 48.1% 0.18 30.6% 24.4% 27.2% 0.05 32.7% 51.2% 39.9% 0.15 34.6% 85.6% 49.2% 0.21
PolyCoder 28.7% 21.3% 24.4% 0.01 36.3% 56.3% 44.1% 0.21 34.8% 86.5% 49.6% 0.21 33.4% 25.7% 29.0% 0.08 38.4% 59.7% 46.8% 0.26 35.1% 86.9% 50.0% 0.22
Người tham gia sau đó được yêu cầu đánh giá mỗi phương pháp chú ý bằng cách chỉ ra sự đồng ý của họ với
ba câu sau trên thang điểm Likert 7 điểm (1—hoàn toàn không đồng ý, 7—hoàn toàn đồng ý).
Q1Từ khóa được mô hình chú ý phù hợp với sự chú ý của tôi khi đọc mô tả nhiệm vụ ngôn ngữ tự nhiên.
Q2Sự chú ý này giải thích tại sao mô hình thành công hoặc thất bại trong việc tạo ra mã chính xác.
Q3Tôi muốn thấy sự chú ý này khi làm việc với các mô hình tạo mã trong cuộc sống thực.
Proc. ACM Softw. Eng., Vol. 1, No. FSE, Article 100. Publication date: July 2024.

--- TRANG 12 ---
100:12 Bonan Kou, Shengmai Chen, Zhijie Wang, Lei Ma, and Tianyi Zhang
Thứ tự của các phương pháp tính toán chú ý khác nhau được ngẫu nhiên hóa để giảm thiểu hiệu ứng học.
Chúng tôi cũng không tiết lộ tên của các phương pháp tính toán chú ý để giảm thiên vị. Ở cuối
nghiên cứu người dùng, người tham gia trả lời ba câu hỏi mở về các phương pháp tính toán chú ý khác nhau
và thiết kế nghiên cứu người dùng. Chúng tôi hỏi những câu hỏi mở này để nghiên cứu mối tương quan
giữa khả năng giải thích của mô hình và niềm tin của người dùng. Những câu hỏi này bao gồm:
Q4Bạn có quan tâm biết LLM tạo mã như thế nào không?
Q5Bạn muốn tìm hiểu gì về quá trình tạo mã bên trong trong LLM?
Q6Bạn có tin tưởng LLM này không? Bạn cần biết gì để cải thiện niềm tin vào LLM?
5 KẾT QUẢ
5.1 RQ1: Mức độ Căn chỉnh Sự chú ý của Mô hình với Sự chú ý của Con người đến đâu?
Để trả lời câu hỏi này, chúng tôi thu thập 𝐾từ khóa hàng đầu mà sáu LLM chú ý đến và so sánh
chúng với các từ khóa được gắn nhãn là quan trọng trong bộ dữ liệu chú ý lập trình viên. Như được mô tả trong
Phần 4.3, chúng tôi sử dụng số liệu chồng lấp token của San Martino [ 22] và alpha của Krippendorff [ 49] để
đo lường sự căn chỉnh chú ý giữa LLM và lập trình viên con người. Khi chạy các mô hình
mà độ dài đầu ra tối đa có thể được đặt, chúng tôi đặt giới hạn token bằng số token của
sự thật cơ bản cộng 20 để chịu đựng sự dư thừa vừa phải.
Bảng 2a, Bảng 2b, và Bảng 2c trình bày kết quả căn chỉnh chú ý khi tính toán điểm chú ý
với các phương pháp dựa trên nhiễu loạn ,dựa trên gradient , và dựa trên tự chú ý , tương ứng.
Vì GPT-4 không tiết lộ trạng thái bên trong của nó trong thời gian chạy, chỉ các phương pháp dựa trên nhiễu loạn
mới có thể áp dụng. Do đó, phần này thảo luận về kết quả của phương pháp dựa trên nhiễu loạn tốt nhất,
BERT_masking . Phần 5.3 so sánh các phương pháp tính toán chú ý khác nhau chi tiết.
Với phương pháp BERT_masking , từ 𝐾=5đến 𝐾=10, điểm F1 của tất cả các mô hình tăng vì
khi ngày càng nhiều token được chọn bởi các mô hình, chúng tôi quan sát tỷ lệ thu hồi rất cao (khoảng 90%),
điều này bù đắp cho độ chính xác giảm. Tuy nhiên, từ 𝐾=10đến 𝐾=20, điểm F1
vẫn ổn định do sự giảm nhanh chóng trong điểm độ chính xác. Mặt khác, điểm alpha của Krippendorff
vẫn ổn định từ 𝐾=5đến 𝐾=10(ngoại trừ GPT-4) nhưng giảm nhanh chóng từ 𝐾=10đến
𝐾=20.
Nhìn chung, đối với tất cả các mô hình và tất cả giá trị 𝐾, alpha của Krippendorff không thay đổi nhiều và
vẫn dưới 0.3, và điểm F1 vẫn dưới 0.6, cho thấy ít sự đồng thuận giữa sự chú ý của mô hình
và sự chú ý của con người [ 58]. Trong số các mô hình này, GPT-4 cho thấy sự chồng lấp chú ý thấp nhất
với sự chú ý của con người về cả hai số liệu. Một giải thích có thể là các
mô hình siêu lớn như GPT-4 đã phát triển một chiến lược lý luận khác với lập trình viên con người. Những kết quả này cho thấy sự không căn chỉnh chú ý nhất quán giữa LLM và lập trình viên
khi tạo mã.
Phát hiện 1
Có sự không căn chỉnh nhất quán giữa sự chú ý của LLM và sự chú ý của lập trình viên trong tất cả
cài đặt, cho thấy LLM không lý luận các nhiệm vụ lập trình như lập trình viên con người.
5.2 RQ2: Sự chú ý có thể Giải thích Lỗi của Các mô hình Tạo mã không?
Để trả lời câu hỏi này, hai tác giả đầu tiên đã phân tích thủ công các lỗi tạo mã được tạo bởi
hai mô hình tốt nhất trong nghiên cứu của chúng tôi—GPT-4 và CodeGen-2.7B. Tổng cộng, hai mô hình này đã tạo ra
920 giải pháp mã không chính xác trên hai điểm chuẩn. Chúng tôi đã lấy mẫu ngẫu nhiên 211 giải pháp không chính xác,
Proc. ACM Softw. Eng., Vol. 1, No. FSE, Article 100. Publication date: July 2024.

--- TRANG 13 ---
Các Mô hình Ngôn ngữ Lớn có Chú ý Tương tự như Lập trình viên Con người Khi Tạo Mã không? 100:13
bao gồm 172 giải pháp không chính xác từ CodeGen-2.7B và 39 giải pháp không chính xác từ GPT-4. Kích thước mẫu
có ý nghĩa thống kê với mức tin cậy 90% và sai số 5%.
Hai tác giả đầu tiên bắt đầu với 50 lỗi tạo mã đầu tiên và độc lập kiểm tra
xem mẫu chú ý của mỗi mã được tính toán bởi BERT_masking , cho kết quả phù hợp nhất
trong các thử nghiệm định lượng, có thể giải thích lỗi trong đó hay không. Đối với các nhiệm vụ đơn giản,
mất khoảng năm phút để kiểm tra mỗi nhiệm vụ. Đối với các nhiệm vụ phức tạp (ví dụ: các nhiệm vụ yêu cầu
hiểu biết về các khái niệm toán học cụ thể), mất khoảng 10 đến 15 phút, vì các tác giả cần
gỡ lỗi mã thủ công và kiểm tra các giá trị runtime của nó để hiểu lỗi trước. Sau khi
phân tích 50 lỗi, họ thảo luận những lỗi này với các tác giả khác và tóm tắt sáu mẫu chú ý phổ biến
có thể được sử dụng để giải thích lỗi tạo mã:
●Thiếu chú ý đến các điều kiện quan trọng. Mô tả nhiệm vụ đề cập đến các điều kiện hoặc trường hợp góc nhất định
để xử lý. Tuy nhiên, mô hình bỏ lỡ hoặc xử lý không chính xác một hoặc nhiều điều kiện như vậy
vì nó không chú ý đến các từ hoặc cụm từ mô tả các điều kiện tương ứng.
●Thiếu chú ý đến các từ mô tả quan trọng của một thao tác hoặc đối tượng dữ liệu. Mô tả nhiệm vụ đề cập đến một thuộc tính quan trọng của một thao tác hoặc đối tượng dữ liệu, như " largest element" và
"ascending order". Tuy nhiên, mô hình không chú ý đến những từ mô tả này và do đó
tạo ra giải pháp mã với logic không chính xác.
●Thiếu chú ý đến mô tả thao tác. Mô tả nhiệm vụ đề cập đến một thao tác hoặc hành động,
như open a file andsort a list . Tuy nhiên, mô hình không chú ý đến các từ động hoặc cụm từ.
Do đó, mã được tạo thực hiện hành động sai hoặc không thực hiện hành động.
●Thiếu chú ý đến loại dữ liệu. Các nhiệm vụ lập trình thường đề cập rõ ràng đến loại dự kiến
của đầu vào và đầu ra. Một số mô tả nhiệm vụ cũng đề cập đến loại dữ liệu của một số kết quả trung gian. Tuy nhiên, mô hình không chú ý đến một số mô tả loại dữ liệu. Điều này có thể dẫn đến
các loại lỗi khác nhau, ví dụ: trả về loại dữ liệu sai, gọi phương thức trên
loại đối tượng sai, v.v.
●Ánh xạ không chính xác giữa từ NL và các phần tử mã. Trong một số trường hợp, chúng tôi quan sát mô hình
chú ý đến một từ hoặc cụm từ quan trọng một cách chính xác nhưng mô hình ánh xạ nó đến lời gọi phương thức, biến, tham số, giá trị, hoặc logic sai, có thể do hiểu sai khái niệm về
ý nghĩa ngữ nghĩa của từ NL.
Sau đó, họ độc lập gắn nhãn các lỗi còn lại, thảo luận việc gắn nhãn của họ với nhau,
và giải quyết các xung đột. Tổng cộng, chúng tôi tìm thấy rằng lỗi trong 57 trong số 211 giải pháp không chính xác (27%)
có thể được giải thích bởi một trong năm mẫu chú ý được đề cập ở trên. Cụ thể, 54 trong số 172
giải pháp không chính xác từ CodeGen-2.7B (31%) có thể giải thích và 3 trong số 39 giải pháp không chính xác từ
GPT-4 (8%) có thể giải thích. Phát hiện này cho thấy phân tích chú ý thần kinh có thể được áp dụng có tiềm năng
để định vị và sửa chữa một phần không tầm thường của lỗi trong mã do LLM tạo ra. Cho rằng chỉ
3 lỗi được tạo bởi GPT-4 có thể được giải thích bằng các mẫu không căn chỉnh chú ý, điều này ngụ ý rằng
các mô hình yếu hơn như CodeGen-2.7B có nhiều khả năng bị ảnh hưởng bởi sự không căn chỉnh chú ý và
do đó lỗi tạo của chúng dễ giải thích hơn. Đây là một quan sát thú vị vì GPT-4
cũng gặp phải sự không căn chỉnh chú ý, như được thể hiện trong Bảng 2, nhưng lỗi tạo của nó không thể
dễ dàng được giải thích bằng phân tích chú ý. Điều này cho thấy rằng khi các mô hình ngôn ngữ trở nên đủ lớn
, chúng có thể đã phát triển một cách khác để diễn giải lời nhắc đầu vào và tạo
nội dung. Điều này kêu gọi nghiên cứu mới để hiểu tại sao các mô hình ngôn ngữ siêu lớn như GPT-4
tạo ra mã không chính xác. Ngoài ra, chúng tôi thừa nhận rằng nhiều lỗi không thể dễ dàng được giải thích bằng
sự chú ý của mô hình. Những lỗi như vậy bao gồm lỗi cú pháp, tên biến không xác định, sử dụng API không chính xác,
chỉ số mảng không chính xác, vòng lặp vô hạn, v.v. Kết quả này cho thấy rằng cần phân tích thêm
để hiểu nguyên nhân gốc rễ của những lỗi này.
Proc. ACM Softw. Eng., Vol. 1, No. FSE, Article 100. Publication date: July 2024.

--- TRANG 14 ---
100:14 Bonan Kou, Shengmai Chen, Zhijie Wang, Lei Ma, and Tianyi Zhang
Chúng tôi thể hiện phân phối và ví dụ cho mỗi loại lỗi dưới đây. Trong những ví dụ này, chúng tôi
làm nổi bật các từ khóa có điểm chú ý cao từ mô hình bằng màu xanh lam.
5.2.1 Thiếu Chú ý đến Các điều kiện Quan trọng. Lời nhắc này yêu cầu một hàm khớp với
chuỗi có ký tự "a"theo sau bởi không hoặc nhiều ký tự "b". Tuy nhiên, CodeGen-2.7B
tạo ra một hàm chỉ khớp với các từ có một "a"theo sau bởi một hoặc nhiều "b". Phân tích chú ý của chúng tôi cho thấy cụm từ điều kiện "followed by zero or more" không chứa bất kỳ token nào được chú ý nhất
, điều này giải thích tại sao mô hình bỏ qua điều kiện mà ký tự "a"
có thể được theo sau không có "b"nào hoặc nhiều hơn một "b". 6 giải pháp không chính xác thuộc danh mục này.
1#Write a function that matches astring that has an ``a''followed by zero or more ``b''s .
2def function(string):
3 return string.count( 'ab') >= 1
5.2.2 Thiếu Chú ý đến Các từ Mô tả Quan trọng của một Thao tác hoặc Đối tượng Dữ liệu. Lời nhắc
dưới đây yêu cầu một hàm tính toán lũy thừa 𝑛𝑡ℎcủa tất cả các phần tử trong danh sách. Tuy nhiên,
mã được tạo bởi CodeGen-2.7B tính toán lũy thừa 𝑛𝑡ℎcủa một phần tử cụ thể mà không sử dụng
hàm lambda. Phân tích chú ý của chúng tôi cho thấy cụm từ thuộc tính "individual items" không chứa
bất kỳ từ nào được chú ý nhất trong lời nhắc. Điều này giải thích tại sao mô hình không thực hiện
thao tác được yêu cầu trên tất cả các mục thay vì một mục cụ thể. 13 giải pháp không chính xác thuộc danh mục này
.
1# Write a function to find the n-th power of individual elements in alist using lambda function.
2def function( list , n):
3 return list [n-1] ** n
5.2.3 Thiếu Chú ý đến Mô tả Thao tác. Lời nhắc dưới đây yêu cầu một hàm đếm có bao nhiều cặp
phần tử ở cùng chỉ số trong hai mảng cho trước bằng nhau. Tuy nhiên,
CodeGen-2.7B tạo ra một hàm kiểm tra xem hai chuỗi có bằng nhau hay không. Phân tích chú ý của chúng tôi cho thấy
từ khóa toán tử "count" không phải là một trong những từ được chú ý nhất trong
lời nhắc, điều này giải thích tại sao mã được tạo không thực hiện đếm như được yêu cầu. 6
giải pháp không chính xác thuộc danh mục này.
1# Write a function to count the same pair in two given lists using map function.
2def function(x,y):
3 return x == y
5.2.4 Thiếu Chú ý đến Loại Dữ liệu. Lời nhắc này yêu cầu một hàm khớp với từ chứa "z"nhưng không có "z"ở đầu hoặc cuối. Tuy nhiên, CodeGen-2.7B tạo ra một hàm
kiểm tra xem chuỗi được lấy từ việc loại bỏ ký tự đầu tiên khỏi từ cho trước
có bằng chuỗi được lấy từ việc loại bỏ ký tự cuối cùng khỏi từ cho trước hay không. Phân tích chú ý của chúng tôi cho thấy
từ khóa loại dữ liệu "z"không phải là một trong những từ được chú ý nhất trong lời nhắc.
Điều này giải thích tại sao mã được tạo không kiểm tra sự tồn tại của một ký tự cụ thể trong
từ cho trước. 7 lỗi thuộc danh mục này.
1#Write a function that matches a word containing 'z', not at the start or end of the word.
2def function(word):
3 return word[1:] == word[:-1]
Proc. ACM Softw. Eng., Vol. 1, No. FSE, Article 100. Publication date: July 2024.

--- TRANG 15 ---
Các Mô hình Ngôn ngữ Lớn có Chú ý Tương tự như Lập trình viên Con người Khi Tạo Mã không? 100:15
5.2.5 Ánh xạ Không chính xác Giữa Từ NL và Các phần tử Mã. Lời nhắc này yêu cầu một hàm
tính toán số bell thứ 𝑛. Tuy nhiên, thay vì gọi công thức chính xác cho số bell
, CodeGen-2.7B tính toán giai thừa của 𝑛. Phân tích chú ý của chúng tôi cho thấy từ khóa
"bell" là một trong những từ được chú ý nhất trong lời nhắc. Tuy nhiên, nó vẫn tạo ra không chính xác
cho lời nhắc này vì nó không hiểu ý nghĩa ngữ nghĩa của "bell number" . 25 giải pháp không chính xác
thuộc danh mục này.
1#Write a python function to find nth bell number .
2def function(n):
3 ifn == 1:
4 return 1
5 else :
6 return n * function(n - 1)
Phát hiện 2
Phân tích chú ý có thể giải thích 27% lỗi tạo trong một điểm chuẩn của 211 lỗi. Những lỗi này
cung cấp hiểu biết về các hạn chế của LLM.
5.3 RQ3: Tác động của Các phương pháp Tính toán Chú ý đến Sự căn chỉnh là gì?
Để so sánh các phương pháp tính toán chú ý khác nhau, chúng tôi đã tính toán điểm F-1 của San Martino trung bình
và alpha của Krippendorff của tất cả năm mô hình (ngoại trừ GPT-4) cho tất cả 𝐾(Bảng 3). Bảng 3
cho thấy BERT_masking cho sự căn chỉnh cao nhất trong cả hai số liệu cho 𝐾=5,10. Tuy nhiên,
phương pháp dựa trên nhiễu loạn khác, SHAP , không vượt trội hơn các phương pháp khác như BERT_masking
đã làm. Mặt khác, các phương pháp dựa trên gradient thường tốt hơn các phương pháp dựa trên tự chú ý,
đặc biệt là cho 𝐾=5theo cả hai số liệu. Đáng ngạc nhiên, điểm chú ý được tính toán bởi
các phương pháp dựa trên tự chú ý (ví dụ: CODING_first ) ít phù hợp nhất với sự chú ý của con người, đặc biệt
cho các giá trị 𝐾nhỏ hơn. Một lý do có thể là các đơn vị tính toán khác trong kiến trúc transformer
, như các lớp feed-forward, cũng đóng vai trò quan trọng trong quá trình tạo mã
. Ví dụ, Geva et al. tìm thấy rằng các lớp feed-forward ảnh hưởng đến dự đoán mô hình bằng cách
thúc đẩy các khái niệm trong không gian từ vựng [ 35]. Do đó, chỉ xem xét các lớp tự chú ý không
hoàn toàn nắm bắt ảnh hưởng của mỗi token đầu vào đối với dự đoán mô hình.
Bảng 3. Điểm F-1 trung bình của San Martino và
Alpha của Krippendorff trên tất cả năm mô hình (loại trừ
GPT-4) trong các cài đặt 𝐾khác nhau. Điểm cao nhất trong
mỗi cột được làm nổi bật bằng màu vàng .
Top 5 Top 10 Top 20PhươngphápF1 KA F1 KA F1 KA
BERT_masking 45.7% 0.27 51.4% 0.26 52.1% 0.12
SHAP 30.6% 0.11 41.5% 0.18 48.0% 0.16
Input×Gradient_reading 37.9% 0.21 47.3% 0.30 48.2% 0.22
Input×Gradient_coding 38.3% 0.22 47.9% 0.31 49.2% 0.24
Saliency_reading 37.5% 0.20 46.0% 0.28 48.0% 0.22
Saliency_coding 37.5% 0.21 46.7% 0.29 49.0% 0.24
READING_first 24.6% 0.01 42.7% 0.20 50.5% 0.22
READING_last 28.8% 0.07 46.6% 0.26 51.0% 0.23
READING_all 24.4% 0.00 39.8% 0.14 50.3% 0.22
CODING_first 26.9% 0.05 43.4% 0.21 50.5% 0.22
CODING_last 30.9% 0.10 47.2% 0.27 51.4% 0.24
CODING_all 33.2% 0.12 46.4% 0.25 51.0% 0.23Hơn nữa, trong các phương pháp dựa trên gradient,
chúng tôi quan sát rằng việc tính toán phân phối chú ý
trong giai đoạn mã hóa (ví dụ: Saliency_coding )
cho sự căn chỉnh tốt hơn so với phân phối chú ý
trong giai đoạn đọc (ví dụ:
Saliency_reading ). Mẫu này có thể được quan sát
cho tất cả giá trị 𝐾(tức là 𝐾=5,10). Tuy nhiên, sự khác biệt
giữa Input×Gradient và Saliency
là tầm thường.
Cuối cùng, như đã thảo luận trong Phần 2.3.1, không có
sự đồng thuận về cách tổng hợp điểm tự chú ý
[ 10,97,99]. Chúng tôi đã thử nghiệm với sáu
phương pháp tổng hợp tự chú ý khác nhau được sử dụng
trong công việc trước đây để tìm phương pháp tổng hợp tự chú ý tốt nhất. Đầu tiên, trong ba
tùy chọn—(1) chỉ tổng hợp điểm chú ý trong
Proc. ACM Softw. Eng., Vol. 1, No. FSE, Article 100. Publication date: July 2024.

--- TRANG 16 ---
100:16 Bonan Kou, Shengmai Chen, Zhijie Wang, Lei Ma, and Tianyi Zhang
Hình 5. Lựa chọn của người tham gia về các phương pháp tính toán chú ý khác nhau trong ba chiều.
lớp đầu tiên, (2) chỉ tổng hợp điểm chú ý trong lớp cuối cùng, và (3) tổng hợp điểm chú ý
từ tất cả các lớp—chỉ tổng hợp điểm chú ý trong lớp cuối cùng tạo ra phân phối chú ý
phù hợp nhất với phân phối chú ý của con người trong cả giai đoạn đọc và mã hóa, ngoại trừ
khi K được đặt thành 5 trong giai đoạn mã hóa. Điều này cho thấy nghiên cứu tương lai nên xem xét lớp cuối cùng
khi tận dụng tự chú ý để diễn giải các mô hình ngôn ngữ mã. Tương tự như phát hiện trong
các phương pháp dựa trên gradient, đối với các phương pháp dựa trên tự chú ý, phân phối chú ý ở giai đoạn mã hóa
(ví dụ: CODING_first ) luôn phù hợp hơn với sự chú ý của con người so với những phân phối ở giai đoạn đọc
(ví dụ: READING_first ).
Phát hiện 3
BERT_masking tạo ra sự căn chỉnh chú ý tốt nhất với lập trình viên con người trong tất cả các phương pháp.
Các phương pháp dựa trên gradient thường tốt hơn các phương pháp dựa trên tự chú ý. Đối với các phương pháp dựa trên gradient
và dựa trên tự chú ý, phân phối chú ý trong giai đoạn mã hóa tạo ra sự căn chỉnh cao hơn
. Đối với các phương pháp dựa trên tự chú ý, phân phối chú ý trong lớp cuối cùng tạo ra
sự căn chỉnh cao nhất.
5.4 RQ4: Phương pháp Tính toán Chú ý nào được Ưa chuộng Nhất?
Hình 5 cho thấy đánh giá của người tham gia về SHAP ,Input×Gradient_coding , và CODING_all
về sự căn chỉnh với sự chú ý của chính họ, khả năng giải thích của sự chú ý được tính toán,
và sở thích của chính họ (Q1-Q3 trong Phần 4.4). Nhìn chung, phương pháp dựa trên nhiễu loạn, SHAP ,
được ưa chuộng hơn hai phương pháp khác trong cả ba khía cạnh. Điểm đánh giá trung bình về sự căn chỉnh chú ý
của SHAP là 5.13, trong khi điểm trung bình cho InputXGradient_coding vàCODING_all lần lượt là 4.59
và 3.62.
Hơn nữa, người tham gia đề xuất rằng SHAP có khả năng giải thích tốt hơn so với InputXGradi-
ent_coding (chênh lệch trung bình: 0.59, kiểm định 𝑡Welch,𝑝=0.02) và CODING_all (chênh lệch trung bình: 1.26,
kiểm định 𝑡Welch,𝑝=0.00001 ). Tuy nhiên, theo phản hồi của người tham gia về niềm tin của họ vào
LLM (Q6 trong Phần 4.4), 14 trong số 22 người tham gia bày tỏ thiếu tin tưởng và niềm tin, ngay cả
sau khi thấy các giải thích dựa trên chú ý. Ví dụ, P3 viết, "Tôi muốn biết liệu
mô hình LLM có thể cung cấp lý do tại sao họ tạo mã hay không. Ví dụ, mã tham khảo. "
Người tham gia cũng yêu cầu phân tích chú ý chi tiết hơn. Cụ thể, họ muốn thấy
những phần nào của đầu vào chịu trách nhiệm tạo ra những phần nào của đầu ra. Ví dụ, P10
nói, "[Tôi muốn biết] làm thế nào LLM xác định đầu vào và đầu ra, những từ phân biệt nào
thúc đẩy các thế hệ khác nhau. " Người tham gia cũng thể hiện sở thích hơn cho SHAP so với
Proc. ACM Softw. Eng., Vol. 1, No. FSE, Article 100. Publication date: July 2024.

--- TRANG 17 ---
Các Mô hình Ngôn ngữ Lớn có Chú ý Tương tự như Lập trình viên Con người Khi Tạo Mã không? 100:17
hai phương pháp khác. Chênh lệch sở thích trung bình giữa SHAP vàInputXGradient_coding
và giữa SHAP và CODING_all là 5.04 so với 4.56 (kiểm định 𝑡Welch,𝑝=0.05) và 5.04 so với 3.48
(kiểm định 𝑡Welch,𝑝=0.00009 ).
Phát hiện 4
Nhìn chung, người tham gia ưa chuộng phương pháp dựa trên nhiễu loạn hơn phương pháp dựa trên gradient và
dựa trên tự chú ý. Tuy nhiên, người tham gia vẫn cảm thấy thiếu tin tưởng vào LLM sau khi thấy
các giải thích dựa trên chú ý và muốn thấy các giải thích phong phú hơn như mã tham khảo
và ánh xạ chú ý chi tiết giữa văn bản và mã.
6 Ý NGHĨA VÀ CƠ HỘI
Nghiên cứu của chúng tôi có một số ý nghĩa quan trọng có lợi cho việc phát triển LLM đáng tin cậy hơn và
chính xác hơn cho việc tạo mã trong tương lai.
Trong RQ1, chúng tôi đã phát hiện sự không căn chỉnh nhất quán giữa sự chú ý của con người và mô hình trong tất cả
sáu mô hình. Mặc dù có thể LLM sử dụng một phương pháp hoàn toàn khác để lý luận về mô tả nhiệm vụ
so với lập trình viên con người, có thể tranh luận liệu phương pháp như vậy có thực sự tốt cho lập trình viên
do lo ngại về khả năng diễn giải, tính mạnh mẽ, và niềm tin hay không. Nhiều nghiên cứu
đã chỉ ra rằng các mô hình phù hợp với con người được coi là đáng tin cậy hơn bởi con người [ 8,34,38,
42,46,80]. Hơn nữa, trong thực tế, LLM ngày nay có thể giải quyết đáng tin cậy một số lượng hạn chế các nhiệm vụ lập trình đơn giản
và gặp khó khăn để xử lý các nhiệm vụ phức tạp hơn hoặc tùy chỉnh, điều này cho thấy
không gian cải thiện rất lớn. Do đó, chúng tôi tin rằng việc điều tra các mẫu chú ý của LLM là
một nỗ lực đáng giá để giúp chúng ta hiểu cách LLM tạo mã và tại sao LLM mắc một số
lỗi và cũng thông báo các cơ hội mới để cải thiện LLM.
Trong RQ2, chúng tôi đã phân tích thủ công sự chú ý của 211 thế hệ không chính xác của hai mô hình tốt nhất
trong bài báo của chúng tôi (GPT-4 và CodeGen-2.7B) và tìm thấy 27% lỗi có thể được giải thích bằng
sự căn chỉnh chú ý không chính xác. Phát hiện của chúng tôi cho thấy tiềm năng sửa chữa những lỗi tạo này
bằng cách điều chỉnh sự căn chỉnh chú ý. Tương tự, công việc trước đây trong Thị giác Máy tính đã chỉ ra
rằng hiệu suất của các mô hình thần kinh có thể được cải thiện nếu chúng ta buộc sự chú ý của chúng căn chỉnh với
con người [ 31,44,59,63]. Một giải pháp tiềm năng là mở rộng hàm mất mát của LLM với một
số hạng phạt đo lường KL divergence giữa sự chú ý của mô hình và sự chú ý của con người. Trong quá trình huấn luyện,
mất mát sẽ tăng khi sự chú ý của mô hình lệch khỏi sự chú ý của con người. Kết quả là,
LLM sẽ được huấn luyện để phân phối sự chú ý theo cách tương tự như lập trình viên con người. Chúng tôi đã
mở nguồn bộ dữ liệu chú ý con người của chúng tôi để tạo thuận lợi cho công việc tương lai về căn chỉnh chú ý.
Hơn nữa, các mẫu chú ý mô hình trong RQ3 có thể giúp cải thiện tính mạnh mẽ của các mô hình tạo mã
bằng cách phát triển các phương pháp huấn luyện đối nghịch dựa trên chú ý mới. Hầu hết các phương pháp huấn luyện đối nghịch
chỉ áp dụng các nhiễu loạn nhỏ cho các token ngẫu nhiên trong lời nhắc, mà không xem xét
tầm quan trọng của một token đối với mô hình [ 11,79,92,98]. Kết quả của chúng tôi cho thấy rằng đáng giá
để ưu tiên các token quan trọng trong quá trình nhiễu loạn. Làm nhiễu loạn những từ quan trọng này
và yêu cầu mô hình tạo mã cho những lời nhắc bị nhiễu loạn này có thể tiết lộ các vấn đề tính mạnh mẽ
hiệu quả hơn.
Trong RQ3, chúng tôi đã so sánh 12 phương pháp tính toán chú ý với các thử nghiệm định lượng (Bảng 2).
Do đó, nghiên cứu của chúng tôi cung cấp hướng dẫn thực tế để chọn phương pháp tính toán chú ý cho
nghiên cứu tương lai về các mô hình tạo mã dựa trên LLM. Kết quả thử nghiệm của chúng tôi cho thấy các nhà phát triển
muốn đo lường sự chú ý của các mô hình tạo mã nên đầu tiên xem xét BERT_masking
vì nó luôn đạt được sự căn chỉnh tốt nhất với sự chú ý của con người trong tất cả ngoại trừ hai cài đặt
(Bảng 3). Giữa các phương pháp dựa trên tự chú ý và dựa trên gradient, các nhà nghiên cứu nên ưu tiên
Proc. ACM Softw. Eng., Vol. 1, No. FSE, Article 100. Publication date: July 2024.

--- TRANG 18 ---
100:18 Bonan Kou, Shengmai Chen, Zhijie Wang, Lei Ma, and Tianyi Zhang
các phương pháp dựa trên gradient thường cho sự căn chỉnh tốt hơn và ổn định hơn trong hầu hết các cài đặt
(Bảng 3). Đối với các phương pháp dựa trên gradient và dựa trên tự chú ý, việc tính toán phân phối chú ý
của giai đoạn mã hóa cho sự căn chỉnh tốt hơn (Bảng 3). Cuối cùng, khi tận dụng tự chú ý để
diễn giải các mô hình tạo mã dựa trên transformer, các nhà nghiên cứu nên xem xét sử dụng điểm tự chú ý
được tính toán từ lớp cuối cùng, được chứng minh là phù hợp hơn với
sự chú ý của con người (Bảng 3).
Trong RQ4, chúng tôi đã tiến hành nghiên cứu người dùng để so sánh nhận thức của nhà phát triển về các phương pháp giải thích khác nhau
. Hầu hết người tham gia coi SHAP là phương pháp XAI tốt nhất cho các mô hình tạo mã LLM
. Phát hiện này cho thấy các nhà nghiên cứu tương lai có thể muốn sử dụng phương pháp dựa trên nhiễu loạn
làm phương pháp XAI mặc định cho việc tạo mã dựa trên LLM. Hơn nữa, trong khảo sát sau nghiên cứu
, người tham gia cũng yêu cầu phân tích chú ý chi tiết hơn, như tiết lộ mối liên kết
giữa các token đầu vào và đầu ra riêng lẻ. Điều này làm nổi bật nhu cầu về các phương pháp XAI mới
để diễn giải các mô hình tạo mã dựa trên LLM.
Trong tương lai, chúng tôi cũng muốn khám phá cách dạy con người cách LLM diễn giải mã.
Hiểu cách LLM diễn giải mã có thể truyền cảm hứng cho lập trình viên con người tạo ra những lời nhắc
dễ hiểu hơn đối với LLM và do đó hướng dẫn LLM tạo ra mã tốt hơn.
7 MỐI ĐE DỌA ĐỐI VỚI TÍNH HỢP LỆ
Tính hợp lệ nội bộ. Một mối đe dọa tiềm năng nằm trong quá trình gắn nhãn thủ công. Hai lập trình viên
đã gắn nhãn thủ công các từ quan trọng để hiểu mô tả nhiệm vụ và triển khai hàm chính xác
. Vì tiêu chí từ khóa này rất chủ quan, các từ được chọn bởi hai người gắn nhãn
có thể không đại diện cho lựa chọn của một nhóm lớn lập trình viên. Để giảm thiểu mối đe dọa này, các tác giả
đã thiết lập tiêu chuẩn gắn nhãn thông qua thảo luận và đạt được sự đồng thuận đáng kể về
việc gắn nhãn. Hơn nữa, chúng tôi mời một người gắn nhãn thứ ba để xác thực bộ dữ liệu chú thích của chúng tôi bằng cách độc lập
gắn nhãn 164 lời nhắc từ bộ dữ liệu HumanEval. Chúng tôi đã tính toán điểm Fleiss' Kappa trong số
các nhãn của ba người gắn nhãn và kết quả (0.64) cho thấy sự đồng thuận đáng kể.
Tính hợp lệ ngoài. Một mối đe dọa tiềm năng đối với tính hợp lệ ngoài là chúng tôi chỉ thử nghiệm
với một ngôn ngữ lập trình, Python. Chúng tôi không thể đảm bảo rằng phát hiện của chúng tôi khái quát hóa cho
ngôn ngữ khác.
Tính hợp lệ cấu trúc. Một mối đe dọa tiềm năng đối với tính hợp lệ cấu trúc nằm trong thiết kế khảo sát. Như chúng ta biết,
các vấn đề lập trình đòi hỏi tinh thần cao để giải quyết và lập trình viên có thể có quan điểm khác nhau
về phần nào của lời nhắc mà mô hình nên chú ý đến. Tuy nhiên, trong thiết kế hiện tại,
chỉ có 22 người tham gia được tham gia. Kích thước mẫu nhỏ có thể dẫn đến các phát hiện không
khái quát hóa được. Để chống lại mối đe dọa này, chúng tôi chỉ mời những người tham gia có kinh nghiệm trong lập trình Python
và đã sử dụng LLM tạo mã ít nhất một lần để kiểm soát chất lượng của
nghiên cứu người dùng.
8 CÔNG VIỆC LIÊN QUAN
8.1 Tạo Mã từ Ngôn ngữ Tự nhiên
Kể từ CodeBERT [ 28], đã có một khối lượng lớn tài liệu mà Mô hình Ngôn ngữ Lớn (LLM)
được sử dụng trong việc tạo mã [ 5,27,29,32,37,62,66,74,82,86,88,91,96]. Cả Guo et al. [ 37]
và Zeng et al. [ 96] đều sử dụng mô hình BERT [ 25] được huấn luyện trước để mã hóa câu hỏi NL và lược đồ cơ sở dữ liệu
cho việc tạo text-to-SQL. CodeBERT áp dụng cùng kiến trúc mô hình như BERT nhưng
được huấn luyện với mục tiêu lai trên dữ liệu mã và văn bản từ kho GitHub [ 28]. Codex,
CodeGPT, và GraphCodeBERT cải thiện CodeBERT bằng cách tận dụng luồng dữ liệu trong giai đoạn huấn luyện trước
[ 36]. Gần đây, các LLM hiện đại như GPT-4 và Google Bard xuất sắc trong các nhiệm vụ tạo mã
Proc. ACM Softw. Eng., Vol. 1, No. FSE, Article 100. Publication date: July 2024.

--- TRANG 19 ---
Các Mô hình Ngôn ngữ Lớn có Chú ý Tương tự như Lập trình viên Con người Khi Tạo Mã không? 100:19
trên các điểm chuẩn khác nhau [ 14,24]. Các đoạn mã chính xác cao và giàu ngữ cảnh được tạo ra
bởi những mô hình này cho phép tự động hóa các nhiệm vụ lập trình khác nhau.
Ngoài việc phát triển LLM mới cho mã, công việc trước đây cũng đã trình bày các phương pháp mới để
nâng cao LLM cho việc tạo mã chính xác và mạnh mẽ hơn [ 15,16,51,66,74,94,100]. Thay vì
trực tiếp tạo mã từ văn bản, REDCODER [ 66] đầu tiên truy xuất các đoạn mã tương tự từ một
kho và sau đó chuyển chúng cùng với mô tả văn bản cho một LLM để tạo mã. Shen
et al. [ 74] đề xuất tận dụng kiến thức miền từ tài liệu và bình luận mã để
hỗ trợ tạo mã. Chakraborty et al. đề xuất một nhiệm vụ huấn luyện trước mới được gọi là tự nhiên hóa
mã nguồn (tức là dịch mã được tạo nhân tạo thành dạng được viết bởi con người) để giúp LLM
học cách tạo mã tự nhiên [ 15]. Chen et al. đề xuất sử dụng LLM để tự động
tạo trường hợp thử nghiệm để kiểm tra mã được tạo bởi cùng LLM [ 16]. Zan et al. đề xuất đầu tiên
phân tách LLM thành hai LLM, một để tạo phác thảo chương trình và cái khác để điền vào
phác thảo [ 94]. SkCoder [ 51] được thiết kế để bắt chước hành vi tái sử dụng mã của nhà phát triển bằng cách đầu tiên truy xuất
một ví dụ mã liên quan đến nhiệm vụ cho trước, trích xuất phác thảo từ nó, và chỉnh sửa phác thảo dựa
trên mô tả nhiệm vụ.
8.2 Nghiên cứu Thực nghiệm về Tạo Mã
Gần đây, nhiều nghiên cứu đã đánh giá các mô hình tạo mã dựa trên LLM trong các khía cạnh khác nhau,
bao gồm hiệu suất [ 27,39,55,71,97], tính mạnh mẽ [ 56,103], bảo mật [ 6,67,93], mùi mã [ 77],
khả năng sử dụng [ 9,12,83,91], và cấp phép [ 19]. Những nghiên cứu liên quan nhất với chúng tôi là những nghiên cứu điều tra
khả năng giải thích của LLM cho mã [ 45,53,85,99]. Karmakar et al. nghiên cứu những gì các mô hình dựa trên BERT được huấn luyện trước
như CodeBERT và GraphCodeBERT đã học về mã bằng cách sử dụng các nhiệm vụ thăm dò [ 45].
Một nhiệm vụ thăm dò về cơ bản là một nhiệm vụ dự đoán về một thuộc tính mã cụ thể, như độ dài mã và
độ phức tạp cyclomatic, để kiểm tra xem mô hình có nhạy cảm với thuộc tính đó hay không. So với công việc của chúng tôi,
họ không phân tích quá trình tạo mã, ví dụ: tại sao và làm thế nào mã nhất định được tạo ra
dựa trên mô tả văn bản. Liguori et al. đề xuất một phương pháp dựa trên nhiễu loạn để đánh giá các mô hình NMT
cho việc tạo mã [ 53]. Ngoài ra, Zhang et al. điều tra quá trình tạo mã bằng cách phân tích
các lớp tự chú ý trong CodeBERT và GraphCodeBERT [ 99]. Wan et al. đã thực hiện phân tích tự chú ý tương tự
và cũng thiết kế một nhiệm vụ thăm dò mới về cấu trúc mã để phân tích
xem LLM có học được thông tin về cấu trúc mã hay không [ 85]. So với những nghiên cứu này, công việc của chúng tôi khác biệt bằng cách phân tích
sự nhất quán giữa sự chú ý của LLM và sự chú ý của lập trình viên về mô tả NL của một nhiệm vụ lập trình.
8.3 Phân tích Sự chú ý của Mô hình trong Các lĩnh vực Khác
Nhiều phương pháp tính toán chú ý đã được phát triển để giải thích mô hình trong các lĩnh vực khác.
Ví dụ, trong lĩnh vực CV, Selvaraju et al. [ 73] đề xuất sử dụng gradient của mạng thần kinh tích chập
(CNN) để chỉ ra tầm quan trọng của mỗi pixel trong hình ảnh cho một dự đoán cụ thể.
Tương tự, Zhou et al. [ 102] sử dụng cơ chế pooling trung bình toàn cục để tính toán tầm quan trọng
của mỗi vùng để CNN phân loại hình ảnh chính xác. Lái xe tự động là một lĩnh vực khác
mà nhu cầu về khả năng giải thích rất mạnh. Ví dụ, Zeiler et al. [ 95] sử dụng các lớp deconvolution
để hiểu cách xe tự động nắm bắt các phân đoạn hình ảnh thời gian thực bằng CNN. Trong một
công việc khác, Chen et al. [ 17] đề xuất một phương pháp học chính sách hiệu quả dữ liệu được gọi là Semantic Predictive
Control (SPC) giải thích cách các trạng thái môi trường được nhận thức được ánh xạ thành hành động.
9 KẾT LUẬN
Bài báo này trình bày một nghiên cứu thực nghiệm về sự căn chỉnh chú ý giữa các mô hình tạo mã dựa trên LLM
và lập trình viên con người. Kết quả của chúng tôi tiết lộ rằng có sự không căn chỉnh nhất quán giữa
Proc. ACM Softw. Eng., Vol. 1, No. FSE, Article 100. Publication date: July 2024.

--- TRANG 20 ---
100:20 Bonan Kou, Shengmai Chen, Zhijie Wang, Lei Ma, and Tianyi Zhang
sự chú ý của LLM và lập trình viên. Trong số 12 phương pháp tính toán chú ý, các phương pháp dựa trên nhiễu loạn
đã tạo ra điểm chú ý phù hợp hơn với sự chú ý của con người và cũng
được ưa chuộng hơn bởi người tham gia nghiên cứu người dùng. Dựa trên kết quả nghiên cứu của chúng tôi, chúng tôi tiếp tục thảo luận
một số ý nghĩa và cơ hội nghiên cứu tương lai để diễn giải tốt hơn và cải thiện hiệu suất
của các mô hình tạo mã dựa trên LLM.
10 KHẢ NĂNG CÓ DỮ LIỆU
Mã và dữ liệu của chúng tôi có sẵn trên kho GitHub [47].
Tài liệu tham khảo
[1]2022. CodeParrot. https://github.com/huggingface/transformers/tree/main/examples/research_projects/codeparrot.
[2] 2023. ChatGPT. http://chat.openai.com.
[3]2023. GPT-4 Parameters: Unlimited guide NLP's Game-Changer. https://medium.com/@mlubbad/the-ultimate-guide-
to-gpt-4-parameters-everything-you-need-to-know-about-nlps-game-changer-109b8767855a.
[4]Wasi Ahmad, Saikat Chakraborty, Baishakhi Ray, and Kai-Wei Chang. 2021. Unified Pre-training for Program
Understanding and Generation. In Proceedings of the 2021 Conference of the North American Chapter of the Association
for Computational Linguistics: Human Language Technologies . 2655–2668.
[5]Alex Andonian, Quentin Anthony, et al .2021. GPT-NeoX: Large Scale Autoregressive Language Modeling in PyTorch .
https://doi.org/10.5281/zenodo.5879544
[6]Owura Asare, Meiyappan Nagappan, and N Asokan. 2022. Is github's copilot as bad as humans at introducing
vulnerabilities in code? arXiv preprint arXiv:2204.04741 (2022).
[7]Jacob Austin, Augustus Odena, et al .2021. Program Synthesis with Large Language Models. arXiv preprint
arXiv:2108.07732 (2021).
[8]Aakash Bansal, Bonita Sharif, and Collin McMillan. 2023. Towards Modeling Human Attention from Eye Movements
for Neural Source Code Summarization. Proceedings of the ACM on Human-Computer Interaction 7, ETRA (2023),
1–19.
[9]Shraddha Barke, Michael B James, and Nadia Polikarpova. 2023. Grounded copilot: How programmers interact with
code-generating models. Proceedings of the ACM on Programming Languages 7, OOPSLA1 (2023), 85–111.
[10] Joshua Bensemann et al .2022. Eye gaze and self-attention: How humans and transformers attend words in sentences.
InProceedings of the Workshop on Cognitive Modeling and Computational Linguistics . 75–87.
[11] Pavol Bielik and Martin Vechev. 2020. Adversarial robustness for code. In International Conference on Machine
Learning . PMLR, 896–907.
[12] Christian Bird et al .2022. Taking Flight with Copilot: Early insights and opportunities of AI-powered pair-
programming tools. Queue 20, 6 (2022), 35–57.
[13] Angie Boggust, Benjamin Hoover, Arvind Satyanarayan, and Hendrik Strobelt. 2022. Shared interest: Measuring
human-ai alignment to identify recurring patterns in model behavior. In Proceedings of the 2022 CHI Conference on
Human Factors in Computing Systems . 1–17.
[14] Sébastien Bubeck et al .2023. Sparks of artificial general intelligence: Early experiments with gpt-4. arXiv preprint
arXiv:2303.12712 (2023).
[15] Saikat Chakraborty et al. 2022. NatGen: generative pre-training by "naturalizing" source code. In Proceedings of the
30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering .
18–30.
[16] Bei Chen et al. 2022. Codet: Code generation with generated tests. arXiv preprint arXiv:2207.10397 (2022).
[17] Jianyu Chen, Shengbo Eben Li, and Masayoshi Tomizuka. 2021. Interpretable end-to-end urban autonomous driving
with latent deep reinforcement learning. IEEE Transactions on Intelligent Transportation Systems 23, 6 (2021), 5068–
5078.
[18] Wenhu Chen, Evgeny Matusov, Shahram Khadivi, and Jan-Thorsten Peter. 2016. Guided alignment training for
topic-aware neural machine translation. arXiv preprint arXiv:1607.01628 (2016).
[19] Matteo Ciniselli, Luca Pascarella, and Gabriele Bavota. 2022. To what extent do deep learning-based code recom-
menders generate predictions by cloning code from the training set?. In Proceedings of the 19th International Conference
on Mining Software Repositories . 167–178.
[20] Kevin Clark, Urvashi Khandelwal, Omer Levy, and Christopher D Manning. 2019. What Does BERT Look at? An
Analysis of BERT's Attention. In Proceedings of the 2019 ACL Workshop BlackboxNLP: Analyzing and Interpreting
Neural Networks for NLP . 276–286.
Proc. ACM Softw. Eng., Vol. 1, No. FSE, Article 100. Publication date: July 2024.

--- TRANG 21 ---
Các Mô hình Ngôn ngữ Lớn có Chú ý Tương tự như Lập trình viên Con người Khi Tạo Mã không? 100:21
[21] Jacob Cohen. 1960. A coefficient of agreement for nominal scales. Educational and Psychological Measurement 20, 1
(1960), 37–46.
[22] Giovanni Da San Martino et al .2019. Fine-grained analysis of propaganda in news article. In Proceedings of the 2019
conference on empirical methods in natural language processing and the 9th international joint conference on natural
language processing (EMNLP-IJCNLP) . Association for Computational Linguistics, 5636–5646.
[23] Misha Denil, Alban Demiraj, and Nando De Freitas. 2014. Extraction of salient sentences from labelled documents.
arXiv preprint arXiv:1412.6815 (2014).
[24] Giuseppe Destefanis, Silvia Bartolucci, and Marco Ortu. 2023. A Preliminary Analysis on the Code Generation
Capabilities of GPT-3.5 and Bard AI Models for Java Functions. arXiv preprint arXiv:2305.09402 (2023).
[25] Jacob Devlin et al .2019. Bert: Pre-training of deep bidirectional transformers for language understanding. In
Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics .
4171–4186.
[26] Ahmed Elnaggar et al .2021. CodeTrans: Towards Cracking the Language of Silicon's Code Through Self-Supervised
Deep Learning and High Performance Computing. arXiv preprint arXiv:2104.02443 (2021).
[27] Mark Chen et al. 2021. Evaluating Large Language Models Trained on Code. (2021). arXiv:2107.03374 [cs.LG]
[28] Yu Feng, Ruben Martins, Jacob Van Geffen, Isil Dillig, and Swarat Chaudhuri. 2017. Component-based synthesis of
table consolidation and transformation tasks from examples. ACM SIGPLAN Notices 52, 6 (2017), 422–436.
[29] Zhangyin Feng et al .2020. CodeBERT: A Pre-Trained Model for Programming and Natural Language Processing. In
Proceedings of the 28th ACM International Conference on Information and Knowledge Management . 307–316.
[30] Joseph L Fleiss. 1971. Measuring nominal scale agreement among many raters. Psychological bulletin 76, 5 (1971), 378.
[31] Ruth C Fong, Walter J Scheirer, and David D Cox. 2018. Using human brain activity to guide machine learning.
Scientific reports 8, 1 (2018), 5397.
[32] Daniel Fried et al .2023. InCoder: A Generative Model for Code Infilling and Synthesis. In The Eleventh International
Conference on Learning Representations . https://openreview.net/forum?id=hQwb-lbM6EL
[33] Andrea Galassi, Marco Lippi, and Paolo Torroni. 2020. Attention in natural language processing. IEEE transactions on
neural networks and learning systems 32, 10 (2020), 4291–4308.
[34] Yuyang Gao et al .2022. Aligning eyes between humans and deep neural network through interactive attention
alignment. Proceedings of the ACM on Human-Computer Interaction 6, CSCW2 (2022), 1–28.
[35] Mor Geva, Avi Caciularu, Kevin Ro Wang, and Yoav Goldberg. 2022. Transformer feed-forward layers build predictions
by promoting concepts in the vocabulary space. arXiv preprint arXiv:2203.14680 (2022).
[36] Daya Guo et al .2020. Graphcodebert: Pre-training code representations with data flow. arXiv preprint arXiv:2009.08366
(2020).
[37] Jiaqi Guo et al .2019. Towards Complex Text-to-SQL in Cross-Domain Database with Intermediate Representation. In
Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics . 4524–4535.
[38] Christopher Hazard et al .2022. Importance is in your attention: agent importance prediction for autonomous driving.
InProceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition . 2532–2535.
[39] Dan Hendrycks et al. 2021. Measuring Coding Challenge Competence With APPS. NeurIPS (2021).
[40] Dan Hendrycks, Collin Burns, Steven Basart, Andrew Critch, Jerry Li, Dawn Song, and Jacob Steinhardt. 2020.
Aligning AI with Shared Human Values. arXiv preprint arXiv:2008.02275 (2020).
[41] Sara Hooker, Dumitru Erhan, Pieter-Jan Kindermans, and Been Kim. 2018. Evaluating feature importance estimates.
(2018).
[42] Siteng Huang, Min Zhang, Yachen Kang, and Donglin Wang. 2021. Attributes-guided and pure-visual attention
alignment for few-shot recognition. In Proceedings of the AAAI Conference on Artificial Intelligence , Vol. 35. 7840–7847.
[43] Paras Jain and Ajay Jain. 2021. Contrastive Code Representation Learning. In Proceedings of the 2021 Conference on
Empirical Methods in Natural Language Processing .
[44] Shaohua Jia et al .2018. Biometric recognition through eye movements using a recurrent neural network. In 2018
IEEE International Conference on Big Knowledge (ICBK) . IEEE, 57–64.
[45] Anjan Karmakar and Romain Robbes. 2021. What do pre-trained code models know about code?. In 2021 36th
IEEE/ACM International Conference on Automated Software Engineering (ASE) . IEEE, 1332–1336.
[46] Iuliia Kotseruba, Amir Rasouli, and John K Tsotsos. 2016. Joint attention in autonomous driving (JAAD). arXiv
preprint arXiv:1609.04741 (2016).
[47] Bonan Kou. 2024. Attention-Alignment-Empirical-Study. https://github.com/BonanKou/Attention-Alignment-
Empirical-Study.
[48] Klaus Krippendorff. 2004. Reliability in content analysis: Some common misconceptions and recommendations.
Human communication research 30, 3 (2004), 411–433.
[49] Klaus Krippendorff. 2018. Content analysis: An introduction to its methodology . Sage publications.
Proc. ACM Softw. Eng., Vol. 1, No. FSE, Article 100. Publication date: July 2024.

--- TRANG 22 ---
100:22 Bonan Kou, Shengmai Chen, Zhijie Wang, Lei Ma, and Tianyi Zhang
[50] Sumith Kulal, Panupong Pasupat, Kartik Chandra, Mina Lee, Oded Padon, Alex Aiken, and Percy S Liang. 2019. Spoc:
Search-based pseudocode to code. Advances in Neural Information Processing Systems 32 (2019).
[51] Jia Li, Yongmin Li, Ge Li, Zhi Jin, Yiyang Hao, and Xing Hu. 2023. SkCoder: A Sketch-based Approach for Automatic
Code Generation. arXiv preprint arXiv:2302.06144 (2023).
[52] Jiwei Li, Will Monroe, and Dan Jurafsky. 2016. Understanding neural networks through representation erasure. arXiv
preprint arXiv:1612.08220 (2016).
[53] Pietro Liguori et al .2022. Can NMT understand me? towards perturbation-based evaluation of NMT models for code
generation. In 2022 IEEE/ACM 1st International Workshop on Natural Language-Based Software Engineering (NLBSE) .
IEEE, 59–66.
[54] Shusen Liu et al .2018. Nlize: A perturbation-driven visual interrogation tool for analyzing and interpreting natural
language inference models. IEEE transactions on visualization and computer graphics 25, 1 (2018), 651–660.
[55] Xiaodong Liu, Ying Xia, and David Lo. 2020. An Empirical Study on the Usage of Transformer Models for Code
Completion. In 2020 IEEE International Conference on Software Maintenance and Evolution (ICSME) . IEEE, 408–418.
[56] Yue Liu, Chakkrit Tantithamthavorn, Yonghui Liu, and Li Li. 2023. On the Reliability and Explainability of Automated
Code Generation Approaches. arXiv preprint arXiv:2302.09587 (2023).
[57] Scott M Lundberg and Su-In Lee. 2017. A unified approach to interpreting model predictions. Advances in neural
information processing systems 30 (2017).
[58] Mary L McHugh. 2012. Interrater reliability: the kappa statistic. Biochemia medica 22, 3 (2012), 276–282.
[59] Cristina Melício et al .2018. Object detection and localization with artificial foveal visual attention. In 2018 Joint IEEE
8th international conference on development and learning and epigenetic robotics (ICDL-EpiRob) . IEEE, 101–106.
[60] Christoph Molnar. 2020. Interpretable machine learning . Lulu. com.
[61] Ernst Niebur. 2007. Saliency map. Scholarpedia 2, 8 (2007), 2675.
[62] Erik Nijkamp, Bo Pang, et al .2023. CodeGen: An Open Large Language Model for Code with Multi-Turn Program
Synthesis. In The Eleventh International Conference on Learning Representations .
[63] Afonso Nunes, Rui Figueiredo, and Plinio Moreno. 2020. Learning to search for objects in images from human gaze
sequences. In Image Analysis and Recognition: 17th International Conference . Springer, 280–292.
[64] Matteo Paltenghi and Michael Pradel. 2021. Thinking like a developer? comparing the attention of humans with
neural models of code. In 2021 36th IEEE/ACM International Conference on Automated Software Engineering (ASE) .
IEEE, 867–879.
[65] Kishore Papineni et al .2002. Bleu: a method for automatic evaluation of machine translation. In Proceedings of the
40th annual meeting of the Association for Computational Linguistics . 311–318.
[66] Md Rizwan Parvez, Wasi Ahmad, Saikat Chakraborty, Baishakhi Ray, and Kai-Wei Chang. 2021. Retrieval Augmented
Code Generation and Summarization. In Findings of the Association for Computational Linguistics: EMNLP 2021 .
2719–2734.
[67] Hammond Pearce et al .2022. Asleep at the keyboard? assessing the security of github copilot's code contributions. In
2022 IEEE Symposium on Security and Privacy (SP) . IEEE, 754–768.
[68] Md Rafiqul Islam Rabin, Vincent J Hellendoorn, and Mohammad Amin Alipour. 2021. Understanding neural code
intelligence through program simplification. In Proceedings of the 29th ACM Joint Meeting on European Software
Engineering Conference and Symposium on the Foundations of Software Engineering . 441–452.
[69] Shuo Ren et al .2020. Codebleu: a method for automatic evaluation of code synthesis. arXiv preprint arXiv:2009.10297
(2020).
[70] Marco Tulio Ribeiro et al .2016. " Why should i trust you?" Explaining the predictions of any classifier. In Proceedings
of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining . 1135–1144.
[71] Rafael R Rodrigues et al .2021. Studying the usage of text-to-text transfer transformer to support code-related tasks.
In2021 IEEE/ACM 43rd International Conference on Software Engineering: Software Engineering in Practice (ICSE-SEIP) .
IEEE, 327–336.
[72] Jaydeb Sarker, Sayma Sultana, Steven R Wilson, and Amiangshu Bosu. 2023. ToxiSpanSE: An Explainable Toxicity
Detection in Code Review Comments. In 2023 ACM/IEEE International Symposium on Empirical Software Engineering
and Measurement (ESEM) . IEEE, 1–12.
[73] Ramprasaath R Selvaraju, Michael Cogswell, Abhishek Das, Ramakrishna Vedantam, Devi Parikh, and Dhruv Batra.
2017. Grad-cam: Visual explanations from deep networks via gradient-based localization. In Proceedings of the IEEE
international conference on computer vision . 618–626.
[74] Sijie Shen, Xiang Zhu, Yihong Dong, Qizhi Guo, Yankun Zhen, and Ge Li. 2022. Incorporating domain knowledge
through task augmentation for front-end JavaScript code generation. In Proceedings of the 30th ACM Joint European
Software Engineering Conference and Symposium on the Foundations of Software Engineering . 1533–1543.
[75] Donghee Shin. 2021. The effects of explainability and causability on perception, trust, and acceptance: Implications
for explainable AI. International Journal of Human-Computer Studies 146 (2021), 102551.
Proc. ACM Softw. Eng., Vol. 1, No. FSE, Article 100. Publication date: July 2024.

--- TRANG 23 ---
Các Mô hình Ngôn ngữ Lớn có Chú ý Tương tự như Lập trình viên Con người Khi Tạo Mã không? 100:23
[76] Avanti Shrikumar, Peyton Greenside, and Anshul Kundaje. 2017. Learning important features through propagating
activation differences. In International conference on machine learning . PMLR, 3145–3153.
[77] Mohammed Latif Siddiq et al .2022. An Empirical Study of Code Smells in Transformer-based Code Generation
Techniques. In 2022 IEEE 22nd International Working Conference on Source Code Analysis and Manipulation (SCAM) .
IEEE, 71–82.
[78] Karen Simonyan, Andrea Vedaldi, and Andrew Zisserman. 2013. Deep inside convolutional networks: Visualising
image classification models and saliency maps. arXiv preprint arXiv:1312.6034 (2013).
[79] Shashank Srikant et al .2020. Generating Adversarial Computer Programs using Optimized Obfuscations. In Interna-
tional Conference on Learning Representations .
[80] Andrea Stocco et al .2022. Thirdeye: Attention maps for safe autonomous driving systems. In Proceedings of the 37th
IEEE/ACM International Conference on Automated Software Engineering . 1–12.
[81] Mukund Sundararajan, Ankur Taly, and Qiqi Yan. 2017. Axiomatic attribution for deep networks. In International
conference on machine learning . PMLR, 3319–3328.
[82] Lewis Tunstall, Leandro von Werra, and Thomas Wolf. 2022. Natural Language Processing with Transformers: Building
Language Applications with Hugging Face . O'Reilly Media, Incorporated.
[83] Priyan Vaithilingam et al .2022. Expectation vs. experience: Evaluating the usability of code generation tools powered
by large language models. In CHI conference on human factors in computing systems extended abstracts . 1–7.
[84] Shikhar Vashishth, Shyam Upadhyay, Gaurav Singh Tomar, and Manaal Faruqui. 2019. Attention interpretability
across nlp tasks. arXiv preprint arXiv:1909.11218 (2019).
[85] Yao Wan, Wei Zhao, Hongyu Zhang, Yulei Sui, Guandong Xu, and Hai Jin. 2022. What do they capture? a structural
analysis of pre-trained language models for source code. In Proceedings of the 44th International Conference on Software
Engineering . 2377–2388.
[86] Bailin Wang et al .2020. RAT-SQL: Relation-Aware Schema Encoding and Linking for Text-to-SQL Parsers. In
Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics . 7567–7578.
[87] Ben Wang and Aran Komatsuzaki. 2021. GPT-J-6B: A 6 Billion Parameter Autoregressive Language Model. https:
//github.com/kingoflolz/mesh-transformer-jax.
[88] Yue Wang, Weishi Wang, Shafiq Joty, and Steven CH Hoi. 2021. CodeT5: Identifier-aware Unified Pre-trained Encoder-
Decoder Models for Code Understanding and Generation. In Proceedings of the 2021 Conference on Empirical Methods
in Natural Language Processing . 8696–8708.
[89] Katharina Weitz et al .2019. " Do you trust me?" Increasing user-trust by integrating virtual agents in explainable AI
interaction design. In Proceedings of the 19th ACM International Conference on Intelligent Virtual Agents . 7–9.
[90] Zhiyong Wu, Yun Chen, Ben Kao, and Qun Liu. 2020. Perturbed Masking: Parameter-free Probing for Analyzing
and Interpreting BERT. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics .
4166–4176.
[91] Frank F Xu, Uri Alon, Graham Neubig, and Vincent Josua Hellendoorn. 2022. A systematic evaluation of large
language models of code. In Proceedings of the 6th ACM SIGPLAN International Symposium on Machine Programming .
1–10.
[92] Noam Yefet, Uri Alon, and Eran Yahav. 2020. Adversarial examples for models of code. Proceedings of the ACM on
Programming Languages 4, OOPSLA (2020), 1–30.
[93] Burak Yetistiren, Isik Ozsoy, and Eray Tuzun. 2022. Assessing the quality of GitHub copilot's code generation. In
Proceedings of the 18th International Conference on Predictive Models and Data Analytics in Software Engineering . 62–71.
[94] Daoguang Zan, Bei Chen, et al .2022. CERT: Continual Pre-training on Sketches for Library-oriented Code Generation.
InProceedings of the Thirty-First International Joint Conference on Artificial Intelligence, IJCAI 2022, Vienna, Austria,
23-29 July 2022 , Luc De Raedt (Ed.). ijcai.org, 2369–2375. https://doi.org/10.24963/ijcai.2022/329
[95] Matthew D Zeiler and Rob Fergus. 2014. Visualizing and understanding convolutional networks. In Computer
Vision–ECCV 2014: 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part I 13 . Springer,
818–833.
[96] Yu Zeng et al .2020. RECPARSER: A Recursive Semantic Parsing Framework for Text-to-SQL Task.. In IJCAI .
3644–3650.
[97] Zhengran Zeng, Hanzhuo Tan, Haotian Zhang, Jing Li, Yuqun Zhang, and Lingming Zhang. 2022. An extensive
study on pre-trained models for program understanding and generation. In Proceedings of the 31st ACM SIGSOFT
International Symposium on Software Testing and Analysis . 39–51.
[98] Huangzhao Zhang, Zhuo Li, Ge Li, Lei Ma, Yang Liu, and Zhi Jin. 2020. Generating adversarial examples for holding
robustness of source code processing models. In Proceedings of the AAAI Conference on Artificial Intelligence , Vol. 34.
1169–1176.
[99] Kechi Zhang, Ge Li, and Zhi Jin. 2022. What does Transformer learn about source code? arXiv preprint arXiv:2207.08466
(2022).
Proc. ACM Softw. Eng., Vol. 1, No. FSE, Article 100. Publication date: July 2024.

--- TRANG 24 ---
100:24 Bonan Kou, Shengmai Chen, Zhijie Wang, Lei Ma, and Tianyi Zhang
[100] Zhaowei Zhang, Hongyu Zhang, Beijun Shen, and Xiaodong Gu. 2022. Diet code is healthy: Simplifying programs
for pre-trained models of code. In Proceedings of the 30th ACM Joint European Software Engineering Conference and
Symposium on the Foundations of Software Engineering . 1073–1084.
[101] Haiying Zhao, Wei Zhou, Xiaogang Hou, and Hui Zhu. 2020. Double attention for multi-label image classification.
IEEE Access 8 (2020), 225539–225550.
[102] Bolei Zhou, Aditya Khosla, Agata Lapedriza, Aude Oliva, and Antonio Torralba. 2016. Learning deep features for
discriminative localization. In Proceedings of the IEEE conference on computer vision and pattern recognition . 2921–2929.
[103] Terry Yue Zhuo, Zhuang Li, Yujin Huang, Fatemeh Shiri, Weiqing Wang, Gholamreza Haffari, and Yuan-Fang Li. 2023.
On Robustness of Prompt-based Semantic Parsing with Large Pre-trained Language Model: An Empirical Study on
Codex. In Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics .
1090–1102.
Received 2023-09-28; accepted 2024-04-16
Proc. ACM Softw. Eng., Vol. 1, No. FSE, Article 100. Publication date: July 2024.

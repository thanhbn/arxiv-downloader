# 2405.17976.pdf
# Chuyá»ƒn Ä‘á»•i tá»« PDF sang TXT
# ÄÆ°á»ng dáº«n nguá»“n: /home/admin88/arxiv-downloader/attention/2405.17976.pdf
# KÃ­ch thÆ°á»›c tá»‡p: 589527 bytes

===============================================
Ná»˜I DUNG Tá»†P PDF
===============================================

--- TRANG 1 ---

*wushaohua@ieisystem.com
1https://github.com/IEIT-Yuan/Yuan2.0-M32 Yuan 2.0-M32: Mixture of Experts vá»›i Attention Router

Shaohua Wu *, Jiangang Luo, Xi Chen, Lingjun Li, Xudong Zhao, Tong Yu, Chao Wang,
Yue Wang, Fei Wang, Weixu Qiao, Houbo He, Zeru Zhang, Zeyu Sun, Junxiong Mao, Chong Shen
IEIT Systems

TÃ“M Táº®T
Yuan 2.0-M32, vá»›i kiáº¿n trÃºc cÆ¡ sá»Ÿ tÆ°Æ¡ng tá»± nhÆ° Yuan-2.0 2B, sá»­ dá»¥ng kiáº¿n trÃºc mixture-of-experts vá»›i 32 chuyÃªn gia trong Ä‘Ã³ 2 chuyÃªn gia Ä‘Æ°á»£c kÃ­ch hoáº¡t. Má»™t máº¡ng Ä‘á»‹nh tuyáº¿n má»›i, Attention Router, Ä‘Æ°á»£c Ä‘á» xuáº¥t vÃ  Ã¡p dá»¥ng Ä‘á»ƒ lá»±a chá»n chuyÃªn gia hiá»‡u quáº£ hÆ¡n, giÃºp cáº£i thiá»‡n Ä‘á»™ chÃ­nh xÃ¡c so vá»›i mÃ´ hÃ¬nh vá»›i máº¡ng Ä‘á»‹nh tuyáº¿n cá»• Ä‘iá»ƒn. Yuan 2.0-M32 Ä‘Æ°á»£c huáº¥n luyá»‡n vá»›i 2000B token tá»« Ä‘áº§u, vÃ  chi phÃ­ tÃ­nh toÃ¡n huáº¥n luyá»‡n chá»‰ lÃ  9.25% cá»§a má»™t mÃ´ hÃ¬nh dÃ y Ä‘áº·c cÃ³ cÃ¹ng quy mÃ´ tham sá»‘. Yuan 2.0-M32 thá»ƒ hiá»‡n kháº£ nÄƒng cáº¡nh tranh trong láº­p trÃ¬nh, toÃ¡n há»c, vÃ  cÃ¡c lÄ©nh vá»±c chuyÃªn mÃ´n khÃ¡c nhau, chá»‰ vá»›i 3.7B tham sá»‘ hoáº¡t Ä‘á»™ng trÃªn tá»•ng sá»‘ 40B, vÃ  7.4 GFlops tÃ­nh toÃ¡n tiáº¿n vá» phÃ­a trÆ°á»›c má»—i token, cáº£ hai Ä‘á»u chá»‰ lÃ  1/19 so vá»›i Llama3-70B. Yuan 2.0-M32 vÆ°á»£t trá»™i hÆ¡n Llama3-70B trÃªn benchmark MATH vÃ  ARC-Challenge, vá»›i Ä‘á»™ chÃ­nh xÃ¡c láº§n lÆ°á»£t lÃ  55.89 vÃ  95.8. CÃ¡c mÃ´ hÃ¬nh vÃ  mÃ£ nguá»“n cá»§a Yuan 2.0-M32 Ä‘Æ°á»£c phÃ¡t hÃ nh táº¡i Github1.

1. Giá»›i thiá»‡u
Vá»›i má»™t lÆ°á»£ng tÃ­nh toÃ¡n cá»‘ Ä‘á»‹nh cho má»—i token, má»™t mÃ´ hÃ¬nh vá»›i cáº¥u trÃºc Mixture of Experts (MoE) cÃ³ thá»ƒ dá»… dÃ ng Ä‘Æ°á»£c xÃ¢y dá»±ng á»Ÿ quy mÃ´ lá»›n hÆ¡n nhiá»u so vá»›i mÃ´ hÃ¬nh dÃ y Ä‘áº·c báº±ng cÃ¡ch tÄƒng sá»‘ lÆ°á»£ng chuyÃªn gia, vÃ  do Ä‘Ã³ Ä‘áº¡t Ä‘Æ°á»£c hiá»‡u suáº¥t Ä‘á»™ chÃ­nh xÃ¡c cao hÆ¡n. Trong thá»±c táº¿, viá»‡c huáº¥n luyá»‡n mÃ´ hÃ¬nh vá»›i tÃ i nguyÃªn tÃ­nh toÃ¡n háº¡n cháº¿ lÃ  phá»• biáº¿n, vÃ  MoE Ä‘Æ°á»£c coi lÃ  má»™t á»©ng cá»­ viÃªn tá»‘t Ä‘á»ƒ giáº£m chi phÃ­ Ä‘Ã¡ng ká»ƒ liÃªn quan Ä‘áº¿n quy mÃ´ cá»±c lá»›n cá»§a mÃ´ hÃ¬nh, táº­p dá»¯ liá»‡u vÃ  sá»©c máº¡nh tÃ­nh toÃ¡n háº¡n cháº¿.

Ã tÆ°á»Ÿng vá» MoE cÃ³ tá»« nÄƒm 1991 (Jacobs et al., 1991). Tá»•ng tá»•n tháº¥t lÃ  sá»± káº¿t há»£p cá»§a tá»•n tháº¥t cÃ³ trá»ng sá»‘ cá»§a má»—i chuyÃªn gia vá»›i kháº£ nÄƒng Ä‘Æ°a ra Ä‘Ã¡nh giÃ¡ Ä‘á»™c láº­p. KhÃ¡i niá»‡m vá» MoE thÆ°a thá»›t Ä‘Ã£ Ä‘Æ°á»£c Shazeer et al. (2017) Ä‘Æ°a vÃ o tÃ¢m Ä‘iá»ƒm trong má»™t mÃ´ hÃ¬nh dá»‹ch thuáº­t. Vá»›i chiáº¿n lÆ°á»£c Ä‘á»‹nh tuyáº¿n nÃ y, má»™t sá»‘ lÆ°á»£ng ráº¥t nhá» chuyÃªn gia sáº½ hoáº¡t Ä‘á»™ng cho lÃ½ luáº­n thay vÃ¬ gá»i táº¥t cáº£ chuyÃªn gia Ä‘á»“ng thá»i. TÃ­nh thÆ°a thá»›t nÃ y cÅ©ng cho phÃ©p mÃ´ hÃ¬nh má»Ÿ rá»™ng lÃªn 1000 láº§n giá»¯a cÃ¡c lá»›p LSTM xáº¿p chá»“ng vá»›i chi phÃ­ hiá»‡u quáº£ tÃ­nh toÃ¡n ráº¥t Ã­t. Máº¡ng Ä‘á»‹nh tuyáº¿n Noisy Top-K Gating giá»›i thiá»‡u má»™t sá»‘ nhiá»…u cÃ³ thá»ƒ Ä‘iá»u chá»‰nh vÃ o hÃ m softmax vÃ  giá»¯ láº¡i giÃ¡ trá»‹ top-K, Ä‘á»ƒ cÃ¢n báº±ng viá»‡c sá»­ dá»¥ng chuyÃªn gia. Trong nhá»¯ng nÄƒm gáº§n Ä‘Ã¢y, vá»›i kÃ­ch thÆ°á»›c mÃ´ hÃ¬nh ngÃ y cÃ ng tÄƒng, vai trÃ² cá»§a chiáº¿n lÆ°á»£c Ä‘á»‹nh tuyáº¿n Ä‘Ã£ thu hÃºt nhiá»u sá»± chÃº Ã½ hÆ¡n cho viá»‡c phÃ¢n bá»• hiá»‡u quáº£ tÃ i nguyÃªn tÃ­nh toÃ¡n.

Máº¡ng Ä‘á»‹nh tuyáº¿n chuyÃªn gia lÃ  cá»‘t lÃµi trong cáº¥u trÃºc MoE. Cáº¥u trÃºc nÃ y lá»±a chá»n cÃ¡c chuyÃªn gia á»©ng cá»­ viÃªn Ä‘á»ƒ tham gia vÃ o tÃ­nh toÃ¡n báº±ng cÃ¡ch tÃ­nh toÃ¡n xÃ¡c suáº¥t phÃ¢n bá»• token cho má»—i chuyÃªn gia. Hiá»‡n táº¡i, trong háº§u háº¿t cÃ¡c cáº¥u trÃºc MoE phá»• biáº¿n, viá»‡c Ã¡p dá»¥ng thuáº­t toÃ¡n Ä‘á»‹nh tuyáº¿n cá»• Ä‘iá»ƒn thá»±c hiá»‡n tÃ­ch vÃ´ hÆ°á»›ng giá»¯a token vÃ  vector Ä‘áº·c trÆ°ng Ä‘áº¡i diá»‡n cho má»—i chuyÃªn gia, sau Ä‘Ã³ lá»±a chá»n cÃ¡c chuyÃªn gia cÃ³ giÃ¡ trá»‹ tÃ­ch vÃ´ hÆ°á»›ng lá»›n nháº¥t lÃ  phá»• biáº¿n (Shazeer et al. 2017; Fedus, Zoph and Shazeer, 2022; Zhou et al., 2022). CÃ¡c vector Ä‘áº·c trÆ°ng cá»§a cÃ¡c chuyÃªn gia trong phÃ©p biáº¿n Ä‘á»•i nÃ y lÃ  Ä‘á»™c láº­p, bá» qua má»‘i tÆ°Æ¡ng quan giá»¯a cÃ¡c chuyÃªn gia. Tuy nhiÃªn, cáº¥u trÃºc MoE thÆ°á»ng lá»±a chá»n nhiá»u hÆ¡n má»™t chuyÃªn gia má»—i láº§n, vÃ  nhiá»u chuyÃªn gia thÆ°á»ng tham gia vÃ o tÃ­nh toÃ¡n má»™t cÃ¡ch há»£p tÃ¡c, cÃ³ nghÄ©a lÃ  should cÃ³ má»‘i tÆ°Æ¡ng quan vá»‘n cÃ³ giá»¯a cÃ¡c chuyÃªn gia.

--- TRANG 2 ---

2
Sáº½ khÃ´ng nghi ngá» gÃ¬ ná»¯a lÃ  sáº½ cáº£i thiá»‡n Ä‘á»™ chÃ­nh xÃ¡c cá»§a mÃ´ hÃ¬nh, náº¿u má»‘i quan há»‡ giá»¯a cÃ¡c chuyÃªn gia Ä‘Æ°á»£c xem xÃ©t trong quÃ¡ trÃ¬nh lá»±a chá»n chuyÃªn gia.

CÃ¡c Ä‘Ã³ng gÃ³p chÃ­nh cá»§a cÃ´ng trÃ¬nh nÃ y Ä‘Æ°á»£c tÃ³m táº¯t nhÆ° sau:
1) Äá» xuáº¥t Attention Router xem xÃ©t má»‘i tÆ°Æ¡ng quan giá»¯a cÃ¡c chuyÃªn gia, dáº«n Ä‘áº¿n Ä‘á»™ chÃ­nh xÃ¡c cao hÆ¡n so vá»›i cáº¥u trÃºc router cá»• Ä‘iá»ƒn.
2) PhÃ¡t hÃ nh mÃ´ hÃ¬nh Yuan 2.0-M32 vá»›i 40B tham sá»‘ tá»•ng cá»™ng vÃ  3.7B tham sá»‘ hoáº¡t Ä‘á»™ng. CÃ³ tá»•ng cá»™ng 32 chuyÃªn gia vÃ  2 chuyÃªn gia Ä‘Æ°á»£c kÃ­ch hoáº¡t cho má»—i token. Chi phÃ­ tÃ­nh toÃ¡n cho huáº¥n luyá»‡n chá»‰ lÃ  1/16 so vá»›i mÃ´ hÃ¬nh dÃ y Ä‘áº·c cÃ³ quy mÃ´ tham sá»‘ tÆ°Æ¡ng tá»±, vÃ  chi phÃ­ suy luáº­n tÆ°Æ¡ng tá»± nhÆ° mÃ´ hÃ¬nh dÃ y Ä‘áº·c vá»›i 3.7B tham sá»‘.

2. CÃ¡c cÃ´ng trÃ¬nh liÃªn quan
Gshard (Lepikhin et al., 2020), má»™t mÃ´ hÃ¬nh khá»•ng lá»“ vá»›i hÆ¡n 600 tá»· tham sá»‘, giá»›i thiá»‡u phÆ°Æ¡ng phÃ¡p MoE vÃ o Transformer Encoder láº§n Ä‘áº§u tiÃªn, vÃ  cung cáº¥p má»™t kiáº¿n trÃºc tÃ­nh toÃ¡n song song phÃ¢n tÃ¡n hiá»‡u quáº£ vá»›i Ä‘á»‹nh tuyáº¿n qua cÃ¡c bá»™ tÄƒng tá»‘c. Switch Transformer (Fedus, Zoph and Shazeer, 2022) Ä‘Æ¡n giáº£n hÃ³a thuáº­t toÃ¡n Ä‘á»‹nh tuyáº¿n MoE vá»›i Ä‘á»‹nh tuyáº¿n thÆ°a thá»›t. Zhou et al. (2022) Ä‘Ã£ Ä‘á» xuáº¥t má»™t thuáº­t toÃ¡n Ä‘á»‹nh tuyáº¿n MoE má»›i Ä‘Æ°á»£c gá»i lÃ  thuáº­t toÃ¡n Ä‘á»‹nh tuyáº¿n Expert Choice (EC) Ä‘á»ƒ Ä‘áº¡t Ä‘Æ°á»£c cÃ¢n báº±ng táº£i tá»‘i Æ°u trong há»‡ thá»‘ng MoE. MÃ´ hÃ¬nh Mistral 8x7B vÆ°á»£t trá»™i hÆ¡n mÃ´ hÃ¬nh cÃ³ tham sá»‘ lá»›n hÆ¡n 10 láº§n trong má»™t sá»‘ benchmark cá»§a con ngÆ°á»i vá»›i máº¡ng Ä‘á»‹nh tuyáº¿n cá»• Ä‘iá»ƒn (Jiang et al., 2024). DBRX sá»­ dá»¥ng kiáº¿n trÃºc MoE tinh táº¿ vÃ  chá»n 4 chuyÃªn gia trong sá»‘ 16 (Mosaic AI research, 2024). DeepSeekMoE cáº£i thiá»‡n sá»± chuyÃªn mÃ´n hÃ³a cá»§a chuyÃªn gia vá»›i phÃ¢n Ä‘oáº¡n chuyÃªn gia tinh táº¿ cÅ©ng nhÆ° cÃ¡ch ly chuyÃªn gia chia sáº» (Dai et al., 2024). CÃ¡c chuyÃªn gia chia sáº» kÃ­ch hoáº¡t token cho táº¥t cáº£ Ä‘áº§u vÃ o vÃ  khÃ´ng bá»‹ áº£nh hÆ°á»Ÿng bá»Ÿi mÃ´-Ä‘un Ä‘á»‹nh tuyáº¿n, Ä‘iá»u nÃ y cÃ³ thá»ƒ giÃºp cÃ¡c chuyÃªn gia khÃ¡c táº­p trung hÆ¡n vÃ o cÃ¡c lÄ©nh vá»±c kiáº¿n thá»©c Ä‘á»™c Ä‘Ã¡o cá»§a há».

CÃ¡c cÃ´ng trÃ¬nh Ä‘Æ°á»£c Ä‘á» cáº­p á»Ÿ trÃªn ná»— lá»±c tá»‘i Æ°u hÃ³a chiáº¿n lÆ°á»£c Ä‘á»‹nh tuyáº¿n cá»§a cÃ¡c chuyÃªn gia, trong khi máº¡ng router váº«n lÃ  máº¡ng cá»• Ä‘iá»ƒn bá» qua má»‘i tÆ°Æ¡ng quan giá»¯a cÃ¡c chuyÃªn gia. CÃ´ng trÃ¬nh cá»§a chÃºng tÃ´i táº­p trung vÃ o viá»‡c thiáº¿t káº¿ máº¡ng router Ä‘á»ƒ káº¿t há»£p má»‘i tÆ°Æ¡ng quan vá»‘n cÃ³ giá»¯a cÃ¡c chuyÃªn gia. Máº¡ng Ä‘á»‹nh tuyáº¿n Ä‘Æ°á»£c Ä‘á» xuáº¥t trong bÃ i bÃ¡o nÃ y lÃ  bá»• sung cho cÃ¡c cÃ´ng trÃ¬nh trÆ°á»›c Ä‘Ã¢y.

3. Kiáº¿n trÃºc mÃ´ hÃ¬nh
Yuan 2.0-M32 dá»±a trÃªn cáº¥u trÃºc mÃ´ hÃ¬nh cá»§a Yuan 2.0-2B (Wu et al., 2023). Yuan 2.0 giá»›i thiá»‡u sá»± phá»¥ thuá»™c cá»¥c bá»™ cá»§a cÃ¡c token Ä‘áº§u vÃ o vá»›i Localized Filtering-based Attention (LFA), Ä‘á»ƒ cáº£i thiá»‡n Ä‘á»™ chÃ­nh xÃ¡c cá»§a mÃ´ hÃ¬nh. Trong Yuan 2.0-M32, máº¡ng feed-forward dÃ y Ä‘áº·c (FFN) cá»§a má»—i lá»›p Ä‘Æ°á»£c thay tháº¿ báº±ng má»™t thÃ nh pháº§n MoE.

HÃ¬nh 1 hiá»ƒn thá»‹ kiáº¿n trÃºc cá»§a lá»›p MoE Ä‘Æ°á»£c Ã¡p dá»¥ng trong mÃ´ hÃ¬nh cá»§a chÃºng tÃ´i. Láº¥y bá»‘n FFN lÃ m vÃ­ dá»¥ (thá»±c táº¿ lÃ  32 chuyÃªn gia), má»—i lá»›p MoE Ä‘Æ°á»£c cáº¥u thÃ nh tá»« má»™t nhÃ³m cÃ¡c FFN riÃªng láº» lÃ m chuyÃªn gia. Máº¡ng Router phÃ­a trÆ°á»›c cÃ¡c chuyÃªn gia Ä‘iá»u phá»‘i token Ä‘áº§u vÃ o Ä‘áº¿n (cÃ¡c) chuyÃªn gia liÃªn quan. Máº¡ng Router cá»• Ä‘iá»ƒn vá» cÆ¡ báº£n thiáº¿t láº­p má»™t vector Ä‘áº·c trÆ°ng cho má»—i chuyÃªn gia, vÃ  tÃ­nh toÃ¡n tÃ­ch vÃ´ hÆ°á»›ng giá»¯a token Ä‘áº§u vÃ o vÃ  vector Ä‘áº·c trÆ°ng cá»§a má»—i chuyÃªn gia Ä‘á»ƒ cÃ³ Ä‘Æ°á»£c kháº£ nÄƒng cá»¥ thá»ƒ giá»¯a token vÃ  chuyÃªn gia. CÃ¡c chuyÃªn gia cÃ³ kháº£ nÄƒng máº¡nh nháº¥t Ä‘Æ°á»£c lá»±a chá»n Ä‘á»ƒ kÃ­ch hoáº¡t vÃ  tham gia vÃ o cÃ¡c tÃ­nh toÃ¡n tiáº¿p theo.

--- TRANG 3 ---

3

HÃ¬nh 1: Minh há»a cá»§a Yuan 2.0-M32. HÃ¬nh bÃªn trÃ¡i trÃ¬nh bÃ y viá»‡c má»Ÿ rá»™ng quy mÃ´ cá»§a kiáº¿n trÃºc Yuan 2.0 vá»›i cÃ¡c lá»›p MoE. Lá»›p MoE thay tháº¿ cho lá»›p feed forward trong Yuan 2.0. HÃ¬nh bÃªn pháº£i trÃ¬nh bÃ y cáº¥u trÃºc lá»›p MoE. Trong mÃ´ hÃ¬nh cá»§a chÃºng tÃ´i, má»—i token Ä‘áº§u vÃ o sáº½ Ä‘Æ°á»£c gÃ¡n cho 2 chuyÃªn gia trong tá»•ng sá»‘ 32, trong khi trong hÃ¬nh chÃºng tÃ´i hiá»ƒn thá»‹ 4 chuyÃªn gia lÃ m vÃ­ dá»¥. Äáº§u ra cá»§a MoE lÃ  tá»•ng cÃ³ trá»ng sá»‘ cá»§a cÃ¡c chuyÃªn gia Ä‘Æ°á»£c lá»±a chá»n. N lÃ  sá»‘ lÆ°á»£ng lá»›p.

(a) Router cá»• Ä‘iá»ƒn
(b) Attention router

HÃ¬nh 2: Tá»•ng quan vá» cáº¥u trÃºc attention router.

--- TRANG 4 ---

4
HÃ¬nh 2(a) trÃ¬nh bÃ y cáº¥u trÃºc cá»§a máº¡ng router cá»• Ä‘iá»ƒn. CÃ¡c vector Ä‘áº·c trÆ°ng cá»§a má»—i chuyÃªn gia Ä‘á»™c láº­p vá»›i nhau, vÃ  má»‘i tÆ°Æ¡ng quan giá»¯a cÃ¡c chuyÃªn gia bá»‹ bá» qua khi tÃ­nh toÃ¡n xÃ¡c suáº¥t. Thá»±c táº¿, trong háº§u háº¿t cÃ¡c mÃ´ hÃ¬nh MoE (Lepikhin et al., 2020; Fedus, Zoph and Shazeer, 2022; Zhou et al., 2022), hai hoáº·c nhiá»u chuyÃªn gia thÆ°á»ng Ä‘Æ°á»£c lá»±a chá»n Ä‘á»ƒ tham gia vÃ o cÃ¡c tÃ­nh toÃ¡n tiáº¿p theo, Ä‘iá»u nÃ y tá»± nhiÃªn mang láº¡i má»‘i tÆ°Æ¡ng quan máº¡nh máº½ giá»¯a cÃ¡c chuyÃªn gia. Viá»‡c xem xÃ©t má»‘i tÆ°Æ¡ng quan giá»¯a cÃ¡c chuyÃªn gia cháº¯c cháº¯n sáº½ gÃ³p pháº§n cáº£i thiá»‡n Ä‘á»™ chÃ­nh xÃ¡c.

HÃ¬nh 2(b) trÃ¬nh bÃ y kiáº¿n trÃºc cá»§a Attention Router, má»™t máº¡ng router má»›i Ä‘Æ°á»£c Ä‘á» xuáº¥t trong cÃ´ng trÃ¬nh nÃ y, káº¿t há»£p má»‘i tÆ°Æ¡ng quan giá»¯a cÃ¡c chuyÃªn gia báº±ng cÃ¡ch Ã¡p dá»¥ng cÆ¡ cháº¿ Attention. Má»™t ma tráº­n há»‡ sá»‘ Ä‘áº¡i diá»‡n cho má»‘i tÆ°Æ¡ng quan giá»¯a cÃ¡c chuyÃªn gia Ä‘Æ°á»£c xÃ¢y dá»±ng, sau Ä‘Ã³ Ä‘Æ°á»£c Ã¡p dá»¥ng vÃ o tÃ­nh toÃ¡n cho giÃ¡ trá»‹ xÃ¡c suáº¥t cuá»‘i cÃ¹ng. Cá»¥ thá»ƒ, vá»›i N chuyÃªn gia cho má»™t vector token (ğ¼âˆˆğ‘…ğ‘‘), quÃ¡ trÃ¬nh Ä‘á»‹nh tuyáº¿n chuyÃªn gia nhÆ° sau:

ğ‘„=ğ‘Šğ¼,      ğ‘Šâˆˆğ‘…ğ‘Ã—ğ‘‘
ğ¾=ğ‘Šâ€²ğ¼,      ğ‘Šâ€²âˆˆğ‘…ğ‘Ã—ğ‘‘
ğ‘‰=ğ‘Šâ€²â€²ğ¼,      ğ‘Šâ€²â€²âˆˆğ‘…ğ‘Ã—ğ‘‘
ğ‘ƒ=Softmax(ğ‘„ğ¾ğ‘‡)V,     ğ‘ƒâˆˆğ‘…ğ‘

Sau Ä‘Ã³, ğ‘€ chuyÃªn gia Ä‘Æ°á»£c chá»n báº±ng cÃ¡ch lá»±a chá»n top ğ‘€ giÃ¡ trá»‹ cá»§a P. Trong bÃ i bÃ¡o nÃ y, chÃºng tÃ´i Ä‘áº·t ğ‘€=2, N=32, d=2048.

MÃ´ hÃ¬nh  Tham sá»‘ (M)  Test loss
Attention router  826.0  2.109
Classical router  825.8  2.117
Shared Expert router  825.8  2.117

Báº£ng 1: So sÃ¡nh cÃ¡c cáº¥u trÃºc router khÃ¡c nhau

Báº£ng 1 liá»‡t kÃª káº¿t quáº£ Ä‘á»™ chÃ­nh xÃ¡c cá»§a cÃ¡c router khÃ¡c nhau. MÃ´ hÃ¬nh cá»§a chÃºng tÃ´i Ä‘Æ°á»£c kiá»ƒm tra trÃªn 8 chuyÃªn gia cÃ³ thá»ƒ huáº¥n luyá»‡n vá»›i Attention Router. MÃ´ hÃ¬nh router cá»• Ä‘iá»ƒn cÃ³ 8 chuyÃªn gia cÃ³ thá»ƒ huáº¥n luyá»‡n Ä‘á»ƒ Ä‘áº£m báº£o quy mÃ´ tham sá»‘ tÆ°Æ¡ng tá»±, vÃ  cáº¥u trÃºc router giá»‘ng vá»›i cáº¥u trÃºc Ä‘Æ°á»£c Ã¡p dá»¥ng trong Mixtral 8*7B (Jiang et al., 2024), Ä‘Ã³ lÃ  Softmax trÃªn má»™t lá»›p tuyáº¿n tÃ­nh. Shared Expert router Ã¡p dá»¥ng chiáº¿n lÆ°á»£c Shared Expert Isolation vá»›i kiáº¿n trÃºc router cá»• Ä‘iá»ƒn (Dai et al., 2014). CÃ³ 2 chuyÃªn gia cá»‘ Ä‘á»‹nh Ä‘á»ƒ náº¯m báº¯t kiáº¿n thá»©c chung vÃ  top-2 cá»§a 14 chuyÃªn gia tÃ¹y chá»n lÃ m chuyÃªn gia chuyÃªn mÃ´n. Äáº§u ra cá»§a MoE lÃ  sá»± káº¿t há»£p cá»§a chuyÃªn gia cá»‘ Ä‘á»‹nh vÃ  nhá»¯ng chuyÃªn gia Ä‘Æ°á»£c lá»±a chá»n bá»Ÿi router. Táº¥t cáº£ ba mÃ´ hÃ¬nh Ä‘á»u Ä‘Æ°á»£c huáº¥n luyá»‡n vá»›i 30B token vÃ  kiá»ƒm tra vá»›i 10B token khÃ¡c. Xem xÃ©t káº¿t quáº£ giá»¯a classical router vÃ  Shared Expert router, chÃºng tÃ´i tháº¥y ráº±ng router sau cÃ³ cÃ¹ng test loss nhÆ°ng vá»›i thá»i gian huáº¥n luyá»‡n nhiá»u hÆ¡n 7.35%. Hiá»‡u quáº£ tÃ­nh toÃ¡n cá»§a Shared Expert tÆ°Æ¡ng Ä‘á»‘i tháº¥p, vÃ  nÃ³ khÃ´ng mang láº¡i Ä‘á»™ chÃ­nh xÃ¡c huáº¥n luyá»‡n tá»‘t hÆ¡n so vá»›i chiáº¿n lÆ°á»£c MOE cá»• Ä‘iá»ƒn. Do Ä‘Ã³ trong mÃ´ hÃ¬nh cá»§a chÃºng tÃ´i, chÃºng tÃ´i Ã¡p dá»¥ng chiáº¿n lÆ°á»£c Ä‘á»‹nh tuyáº¿n cá»• Ä‘iá»ƒn mÃ  khÃ´ng cÃ³ chuyÃªn gia chia sáº» nÃ o.

ChÃºng tÃ´i kiá»ƒm tra kháº£ nÄƒng má»Ÿ rá»™ng cá»§a mÃ´ hÃ¬nh báº±ng cÃ¡ch tÄƒng sá»‘ lÆ°á»£ng chuyÃªn gia vÃ  cá»‘ Ä‘á»‹nh kÃ­ch thÆ°á»›c tham sá»‘ má»—i chuyÃªn gia. Viá»‡c tÄƒng sá»‘ lÆ°á»£ng chuyÃªn gia cÃ³ thá»ƒ huáº¥n luyá»‡n chá»‰ thay Ä‘á»•i kháº£ nÄƒng mÃ´ hÃ¬nh, nhÆ°ng khÃ´ng thay Ä‘á»•i tham sá»‘ mÃ´ hÃ¬nh Ä‘Æ°á»£c kÃ­ch hoáº¡t thá»±c táº¿. Táº¥t cáº£ cÃ¡c mÃ´ hÃ¬nh Ä‘á»u Ä‘Æ°á»£c huáº¥n luyá»‡n vá»›i 50B token vÃ  kiá»ƒm tra vá»›i 10B token khÃ¡c. ChÃºng tÃ´i Ä‘áº·t sá»‘ chuyÃªn gia Ä‘Æ°á»£c kÃ­ch hoáº¡t lÃ  2, vÃ  cÃ¡c siÃªu tham sá»‘ cho huáº¥n luyá»‡n lÃ  giá»‘ng nhau cho ba mÃ´ hÃ¬nh. Hiá»‡u á»©ng má»Ÿ rá»™ng chuyÃªn gia Ä‘Æ°á»£c Ä‘o báº±ng test loss sau khi huáº¥n luyá»‡n vá»›i 50B token (Báº£ng 2). So vá»›i mÃ´ hÃ¬nh cÃ³ 8 chuyÃªn gia cÃ³ thá»ƒ huáº¥n luyá»‡n, mÃ´ hÃ¬nh cÃ³ 16 chuyÃªn gia cÃ³ loss tháº¥p hÆ¡n 2%, vÃ  mÃ´ hÃ¬nh cÃ³ 32 chuyÃªn gia cÃ³ loss tháº¥p hÆ¡n 3.6%. ChÃºng tÃ´i chá»n 32 chuyÃªn gia cho Yuan 2.0-M32 xem xÃ©t Ä‘á»™ chÃ­nh xÃ¡c cá»§a nÃ³.

MÃ´ hÃ¬nh  Test loss
8 chuyÃªn gia  1.820
16 chuyÃªn gia  1.787
32 chuyÃªn gia  1.754

Báº£ng 2: Káº¿t quáº£ cá»§a cÃ¡c thÃ­ nghiá»‡m má»Ÿ rá»™ng

4. Huáº¥n luyá»‡n
4.1 Huáº¥n luyá»‡n mÃ´ hÃ¬nh
TÆ°Æ¡ng tá»± nhÆ° chiáº¿n lÆ°á»£c huáº¥n luyá»‡n cá»§a Yuan 2.0, Yuan 2.0-M32 Ä‘Æ°á»£c huáº¥n luyá»‡n vá»›i sá»± káº¿t há»£p cá»§a song song dá»¯ liá»‡u vÃ  song song pipeline, tuy nhiÃªn khÃ´ng sá»­ dá»¥ng song song tensor hoáº·c song song optimizer. CÃ¡c siÃªu tham sá»‘ huáº¥n luyá»‡n Ä‘Æ°á»£c liá»‡t kÃª trong Phá»¥ lá»¥c A. HÃ¬nh 3 trÃ¬nh bÃ y Ä‘Æ°á»ng cong loss, vÃ  loss huáº¥n luyá»‡n cuá»‘i cÃ¹ng lÃ  1.22.

HÃ¬nh 3: Loss pre-training cá»§a Yuan2.0-M32 trÃªn 2000B token

4.2 Fine-tuning
Trong quÃ¡ trÃ¬nh fine-tuning, chÃºng tÃ´i má»Ÿ rá»™ng Ä‘á»™ dÃ i chuá»—i lÃªn 16384. Theo cÃ´ng trÃ¬nh cá»§a CodeLLama (RoziÃ¨re et al., 2023), chÃºng tÃ´i Ä‘áº·t láº¡i giÃ¡ trá»‹ cÆ¡ sá»Ÿ cá»§a táº§n sá»‘ Rotary Position Embedding (RoPE) Ä‘á»ƒ trÃ¡nh sá»± suy giáº£m trong Ä‘iá»ƒm attention vá»›i cÃ¡c chuá»—i dÃ i hÆ¡n. Thay vÃ¬ chá»‰ Ä‘Æ¡n giáº£n tÄƒng giÃ¡ trá»‹ cÆ¡ sá»Ÿ tá»« 1000 lÃªn má»™t giÃ¡ trá»‹ lá»›n hÆ¡n nhiá»u (vÃ­ dá»¥ 1000000), chÃºng tÃ´i tÃ­nh toÃ¡n cÆ¡ sá»Ÿ má»›i vá»›i NTK-aware (bloc97, 2023), tá»©c lÃ 

ğ‘â€²=ğ‘âˆ™ğ‘ |ğ·|/|ğ·|âˆ’2.

Trong Ä‘Ã³ ğ‘ lÃ  giÃ¡ trá»‹ cÆ¡ sá»Ÿ ban Ä‘áº§u (b=10000). ğ‘  lÃ  sá»‘ láº§n má»Ÿ rá»™ng tá»« Ä‘á»™ dÃ i ngá»¯ cáº£nh ban Ä‘áº§u Ä‘áº¿n Ä‘á»™ dÃ i ngá»¯ cáº£nh má»Ÿ rá»™ng. VÃ¬ chÃºng tÃ´i má»Ÿ rá»™ng Ä‘á»™ dÃ i ngá»¯ cáº£nh tá»« 4096 lÃªn 16384, s báº±ng 4. |ğ·| lÃ  128 trong thiáº¿t láº­p cá»§a chÃºng tÃ´i. Do Ä‘Ã³, cÆ¡ sá»Ÿ má»›i ğ‘â€² Ä‘Æ°á»£c tÃ­nh toÃ¡n lÃ  40890.

ChÃºng tÃ´i cÅ©ng so sÃ¡nh hiá»‡u suáº¥t cá»§a mÃ´ hÃ¬nh Yuan 2.0-M32 pre-trained vá»›i cÆ¡ sá»Ÿ má»›i theo kiá»ƒu NTK-aware, vÃ  vá»›i cÃ¡c giÃ¡ trá»‹ cÆ¡ sá»Ÿ khÃ¡c (40000, 80000, 160000, 320000, 640000, 1280000, 2560000, 5120000, vÃ  10240000) trong nhiá»‡m vá»¥ needle-retrieval vá»›i Ä‘á»™ dÃ i chuá»—i lÃªn Ä‘áº¿n 16K (gkamradt, 2023).

--- TRANG 5 ---

5
ChÃºng tÃ´i tháº¥y ráº±ng cÆ¡ sá»Ÿ má»›i theo kiá»ƒu NTK-aware, 40890, hoáº¡t Ä‘á»™ng tá»‘t hÆ¡n. Do Ä‘Ã³ 40890 Ä‘Æ°á»£c Ã¡p dá»¥ng trong quÃ¡ trÃ¬nh fine-tuning.

4.3 Táº­p dá»¯ liá»‡u pre-training
Yuan 2.0-M32 Ä‘Æ°á»£c pre-trained vá»›i má»™t táº­p dá»¯ liá»‡u song ngá»¯ 2000B token tá»« Ä‘áº§u. Dá»¯ liá»‡u gá»‘c cho pre-training chá»©a hÆ¡n 3400B token, vÃ  trá»ng sá»‘ cho má»—i danh má»¥c Ä‘Æ°á»£c Ä‘iá»u chá»‰nh theo cháº¥t lÆ°á»£ng vÃ  sá»‘ lÆ°á»£ng dá»¯ liá»‡u.

Corpus pre-training toÃ n diá»‡n bao gá»“m:
- 44 táº­p dá»¯ liá»‡u con bao gá»“m dá»¯ liá»‡u web crawl, wiki, luáº­n vÄƒn há»c thuáº­t, sÃ¡ch, mÃ£, toÃ¡n há»c vÃ  cÃ´ng thá»©c, vÃ  chuyÃªn mÃ´n theo lÄ©nh vá»±c cá»¥ thá»ƒ. Má»™t sá»‘ trong sá»‘ Ä‘Ã³ lÃ  táº­p dá»¯ liá»‡u nguá»“n má»Ÿ vÃ  nhá»¯ng táº­p khÃ¡c Ä‘Æ°á»£c táº¡o bá»Ÿi Yuan 2.0.
- CÃ¡c pháº§n cá»§a dá»¯ liá»‡u common crawl, sÃ¡ch tiáº¿ng Trung, Ä‘á»‘i thoáº¡i vÃ  dá»¯ liá»‡u tin tá»©c tiáº¿ng Trung Ä‘Æ°á»£c káº¿ thá»«a tá»« Yuan 1.0 (Wu et al., 2021). Háº§u háº¿t dá»¯ liá»‡u pre-training trong Yuan 2.0 cÅ©ng Ä‘Æ°á»£c tÃ¡i sá»­ dá»¥ng.

ThÃ´ng tin chi tiáº¿t vá» viá»‡c xÃ¢y dá»±ng vÃ  nguá»“n gá»‘c cá»§a má»—i táº­p dá»¯ liá»‡u cÃ³ sáºµn dÆ°á»›i Ä‘Ã¢y.

Web (25.2%). Dá»¯ liá»‡u web crawling lÃ  má»™t bá»™ sÆ°u táº­p tá»« cÃ¡c táº­p dá»¯ liá»‡u nguá»“n má»Ÿ vÃ  dá»¯ liá»‡u common crawl Ä‘Æ°á»£c xá»­ lÃ½ trong cÃ¡c cÃ´ng trÃ¬nh trÆ°á»›c Ä‘Ã¢y cá»§a chÃºng tÃ´i (Yuan 1.0). Vui lÃ²ng tham kháº£o Yuan 1.0 Ä‘á»ƒ biáº¿t thÃªm chi tiáº¿t vá» Massive Data Filtering System (MDFS) trÃ­ch xuáº¥t ná»™i dung cháº¥t lÆ°á»£ng cao hÆ¡n tá»« cÃ¡c ngá»¯ cáº£nh web.

Dá»¯ liá»‡u BÃ¡ch khoa toÃ n thÆ° (1.2%), luáº­n vÄƒn (0.84%), sÃ¡ch (6.4%) vÃ  dá»‹ch thuáº­t (1.1%) Ä‘Æ°á»£c káº¿ thá»«a tá»« táº­p dá»¯ liá»‡u Yuan 1.0 vÃ  Yuan 2.0.

MÃ£ (47.5%). Táº­p dá»¯ liá»‡u mÃ£ Ä‘Æ°á»£c má»Ÿ rá»™ng Ä‘Ã¡ng ká»ƒ so vá»›i Yuan 2.0. ChÃºng tÃ´i Ã¡p dá»¥ng mÃ£ tá»« Stack v2 (Lozhkov et al., 2024). CÃ¡c comment trong Stack v2 Ä‘Æ°á»£c dá»‹ch sang tiáº¿ng Trung. Dá»¯ liá»‡u mÃ£ tá»•ng há»£p Ä‘Æ°á»£c táº¡o ra báº±ng phÆ°Æ¡ng phÃ¡p tÆ°Æ¡ng tá»± nhÆ° trong Yuan 2.0.

ToÃ¡n há»c (6.36%). Táº¥t cáº£ dá»¯ liá»‡u toÃ¡n há»c tá»« Yuan 2.0 Ä‘Æ°á»£c tÃ¡i sá»­ dá»¥ng. Dá»¯ liá»‡u chá»§ yáº¿u tá»« cÃ¡c táº­p dá»¯ liá»‡u nguá»“n má»Ÿ, bao gá»“m proof-pile v1 (Azerbayev, 2022) vÃ  v2 (Paster et al., 2023), AMPS (Hendrycks et al. 2021), MathPile (Wang, Xia and Liu, 2023) vÃ  StackMathQA (Zhang, 2024). Má»™t táº­p dá»¯ liá»‡u tá»•ng há»£p cho tÃ­nh toÃ¡n sá»‘ há»c Ä‘Æ°á»£c táº¡o ra báº±ng Python Ä‘á»ƒ cÃ³ lá»£i cho bá»‘n phÃ©p toÃ¡n sá»‘ há»c.

LÄ©nh vá»±c cá»¥ thá»ƒ (1.93%) lÃ  má»™t táº­p dá»¯ liá»‡u vá»›i kiáº¿n thá»©c tá»« cÃ¡c ná»n táº£ng khÃ¡c nhau.

4.4 Táº­p dá»¯ liá»‡u fine-tuning
Táº­p dá»¯ liá»‡u fine-tuning Ä‘Æ°á»£c má»Ÿ rá»™ng dá»±a trÃªn táº­p dá»¯ liá»‡u Ä‘Æ°á»£c Ã¡p dá»¥ng trong Yuan 2.0.

Táº­p dá»¯ liá»‡u Code Instruction. Táº¥t cáº£ dá»¯ liá»‡u mÃ£ hÃ³a vá»›i hÆ°á»›ng dáº«n tiáº¿ng Trung vÃ  cÃ¡c pháº§n vá»›i comment tiáº¿ng Anh Ä‘Æ°á»£c táº¡o ra báº±ng LLM. Khoáº£ng 30% dá»¯ liá»‡u hÆ°á»›ng dáº«n mÃ£ lÃ  tiáº¿ng Anh, vÃ  pháº§n cÃ²n láº¡i lÃ  tiáº¿ng Trung. Dá»¯ liá»‡u tá»•ng há»£p Ä‘Æ°á»£c cháº¿ táº¡o theo cÃ¡ch báº¯t chÆ°á»›c mÃ£ Python vá»›i comment tiáº¿ng Trung vá» táº¡o prompt vÃ  chiáº¿n lÆ°á»£c lÃ m sáº¡ch dá»¯ liá»‡u.

- MÃ£ Python vá»›i comment tiáº¿ng Anh Ä‘Æ°á»£c thu tháº­p tá»« Magicoder-Evol-Instruct-110K (Wei et al., 2023) vÃ  CodeFeedback-Filtered-Instruction (Zheng et al., 2024). Dá»¯ liá»‡u hÆ°á»›ng dáº«n cÃ³ tag ngÃ´n ngá»¯ nhÆ° "python" Ä‘Æ°á»£c trÃ­ch xuáº¥t tá»« táº­p dá»¯ liá»‡u, vÃ  Ä‘Æ°á»£c tá»• chá»©c theo Ä‘á»‹nh dáº¡ng nhÆ° Ä‘Æ°á»£c hiá»ƒn thá»‹ trong Phá»¥ lá»¥c B. Táº­p dá»¯ liá»‡u cÅ©ng Ä‘Æ°á»£c má»Ÿ rá»™ng vá»›i phÆ°Æ¡ng phÃ¡p Evol-instruct (Xu et al., 2023) vÃ  Self-instruct (Wang et al., 2022) Ä‘Æ°á»£c Ã¡p dá»¥ng trong viá»‡c xÃ¢y dá»±ng mÃ£ Python tiáº¿ng Trung.

- CÃ¡c mÃ£ khÃ¡c nhÆ° C/C++/Go/Java/SQL/Shell v.v., vá»›i comment tiáº¿ng Anh tá»« táº­p dá»¯ liá»‡u nguá»“n má»Ÿ (Wei et al., 2023; b-mc2, 2023; Clinton, 2013; gayathrimanoj, 2023a, b; byroneverson, 2024; Zheng et al., 2024) Ä‘Æ°á»£c xá»­ lÃ½ theo cÃ¡ch tÆ°Æ¡ng tá»± vá»›i mÃ£ Python. CÃ¡c chiáº¿n lÆ°á»£c lÃ m sáº¡ch tÆ°Æ¡ng tá»± nhÆ° phÆ°Æ¡ng phÃ¡p trong Yuan 2.0. Má»™t sandbox Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ trÃ­ch xuáº¥t cÃ¡c dÃ²ng cÃ³ thá»ƒ biÃªn dá»‹ch vÃ  thá»±c thi trong mÃ£ Ä‘Æ°á»£c táº¡o ra, vÃ  giá»¯ láº¡i cÃ¡c dÃ²ng vÆ°á»£t qua Ã­t nháº¥t má»™t unit test.

Táº­p dá»¯ liá»‡u Math Instruction. Táº­p dá»¯ liá»‡u hÆ°á»›ng dáº«n toÃ¡n há»c Ä‘á»u Ä‘Æ°á»£c káº¿ thá»«a tá»« táº­p dá»¯ liá»‡u fine-tuning trong Yuan 2.0. Äá»ƒ cáº£i thiá»‡n kháº£ nÄƒng cá»§a mÃ´ hÃ¬nh giáº£i quyáº¿t cÃ¡c bÃ i toÃ¡n toÃ¡n há»c báº±ng phÆ°Æ¡ng phÃ¡p láº­p trÃ¬nh, chÃºng tÃ´i xÃ¢y dá»±ng dá»¯ liá»‡u toÃ¡n há»c prompting Program of Thoughts (PoT) (Chen et al., 2022). PoT chuyá»ƒn Ä‘á»•i bÃ i toÃ¡n toÃ¡n há»c thÃ nh nhiá»‡m vá»¥ táº¡o mÃ£ Ä‘á»ƒ thá»±c hiá»‡n tÃ­nh toÃ¡n báº±ng Python.

Táº­p dá»¯ liá»‡u Safety Instruction. NgoÃ i táº­p dá»¯ liá»‡u chat cá»§a Yuan 2.0, chÃºng tÃ´i xÃ¢y dá»±ng má»™t táº­p dá»¯ liá»‡u alignment an toÃ n song ngá»¯ dá»±a trÃªn má»™t táº­p dá»¯ liá»‡u alignment an toÃ n nguá»“n má»Ÿ (Ji et al., 2024). ChÃºng tÃ´i chá»‰ láº¥y cÃ¡c cÃ¢u há»i tá»« táº­p dá»¯ liá»‡u cÃ´ng cá»™ng, vÃ  tÄƒng sá»± Ä‘a dáº¡ng cá»§a cÃ¡c cÃ¢u há»i vÃ  tÃ¡i táº¡o cÃ¢u tráº£ lá»i tiáº¿ng Trung vÃ  tiáº¿ng Anh báº±ng cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n.

4.5 Tokenizer
Äá»‘i vá»›i Yuan 2.0-M32, cÃ¡c tokenizer tiáº¿ng Anh vÃ  tiáº¿ng Trung Ä‘Æ°á»£c káº¿ thá»«a tá»« nhá»¯ng tokenizer Ä‘Æ°á»£c Ã¡p dá»¥ng trong Yuan 2.0.

5. Káº¿t quáº£
ChÃºng tÃ´i Ä‘Ã¡nh giÃ¡ Yuan 2.0-M32 trÃªn Humaneval (Chen et al., 2021) cho táº¡o mÃ£, GSM8K (Cobbe et al., 2021) vÃ  MATH (Hendrycks et al., 2021) cho giáº£i quyáº¿t bÃ i toÃ¡n toÃ¡n há»c, ARC (Clark et al., 2018) cho kiáº¿n thá»©c khoa há»c vÃ  suy luáº­n, vÃ  MMLU (Hendrycks et al., 2020) nhÆ° má»™t benchmark tÃ­ch há»£p.

5.1 Táº¡o mÃ£
Kháº£ nÄƒng táº¡o mÃ£ Ä‘Æ°á»£c Ä‘Ã¡nh giÃ¡ vá»›i HumanEval Benchmark. PhÆ°Æ¡ng phÃ¡p Ä‘Ã¡nh giÃ¡ vÃ  prompt tÆ°Æ¡ng tá»± nhÆ° nhá»¯ng gÃ¬ Ä‘Æ°á»£c Ä‘á» cáº­p trong Yuan 2.0, vÃ  prompt tiáº¿ng Anh Ä‘Æ°á»£c xÃ¢y dá»±ng nhÆ° Phá»¥ lá»¥c B.

MÃ´ hÃ¬nh Tham sá»‘ (B) Tham sá»‘ hoáº¡t Ä‘á»™ng (B) Human Eval (zero-shot)
Llama 3-70B 70 70 81.7
Llama 3-8B 8 8 62.2
Phi-3-medium 14 14 62.2
Phi-3-small 7 7 61
Phi-3-mini 3.8 3.8 58.5
Qwen1.5-72B 72 72 68.9
Deepseek V2 236 21 81.1
Mixtral-8Ã—22B 141 39 45.1
Mixtral-8Ã—7B 47 12.9 40.2
Yuan 2.0-M32 40 3.7 74.4
Yuan 2.0-M32 40 3.7 78.1 (14 shots)

Báº£ng 3: So sÃ¡nh Yuan 2.0-M32 vÃ  cÃ¡c mÃ´ hÃ¬nh khÃ¡c trÃªn Human Eval pass@1.

--- TRANG 6 ---

6

MÃ´ hÃ¬nh Ä‘Æ°á»£c ká»³ vá»ng hoÃ n thÃ nh hÃ m sau <sep>. VÃ  hÃ m Ä‘Æ°á»£c táº¡o ra sáº½ Ä‘Æ°á»£c Ä‘Ã¡nh giÃ¡ báº±ng unit test. Káº¿t quáº£ tá»« zero-shot cá»§a Yuan 2.0-M32 vÃ  so sÃ¡nh vá»›i cÃ¡c mÃ´ hÃ¬nh khÃ¡c Ä‘Æ°á»£c hiá»ƒn thá»‹ trong Báº£ng 3. Káº¿t quáº£ cá»§a Yuan 2.0-M32 chá»‰ Ä‘á»©ng sau DeepseekV2 (DeepSeek-AI, 2024) vÃ  Llama3-70B (AI Meta, 2024), vÃ  vÆ°á»£t xa cÃ¡c mÃ´ hÃ¬nh khÃ¡c, tháº­m chÃ­ khi cÃ¡c tham sá»‘ hoáº¡t Ä‘á»™ng vÃ  chi phÃ­ tÃ­nh toÃ¡n cá»§a nÃ³ tháº¥p hÆ¡n nhiá»u so vá»›i nhá»¯ng mÃ´ hÃ¬nh khÃ¡c. So vá»›i Deepseek V2, mÃ´ hÃ¬nh cá»§a chÃºng tÃ´i sá»­ dá»¥ng Ã­t hÆ¡n má»™t pháº§n tÆ° tham sá»‘ hoáº¡t Ä‘á»™ng vÃ  Ã­t hÆ¡n má»™t pháº§n nÄƒm ná»— lá»±c tÃ­nh toÃ¡n má»—i token, trong khi Ä‘áº¡t Ä‘Æ°á»£c hÆ¡n 90% má»©c Ä‘á»™ chÃ­nh xÃ¡c cá»§a nÃ³. VÃ  so vá»›i llama3-70B, khoáº£ng cÃ¡ch giá»¯a tham sá»‘ mÃ´ hÃ¬nh vÃ  tÃ­nh toÃ¡n tháº­m chÃ­ cÃ²n lá»›n hÆ¡n, vÃ  chÃºng tÃ´i váº«n Ä‘áº¡t 91% má»©c Ä‘á»™ cá»§a nÃ³. Yuan 2.0-M32 thá»ƒ hiá»‡n kháº£ nÄƒng láº­p trÃ¬nh Ä‘Ã¡ng tin cáº­y vá»›i ba pháº§n tÆ° sá»‘ cÃ¢u há»i Ä‘Æ°á»£c vÆ°á»£t qua. Yuan 2.0-M32 giá»i trong few shot learning. Äá»™ chÃ­nh xÃ¡c cá»§a Humaneval Ä‘Æ°á»£c cáº£i thiá»‡n lÃªn 78.0 báº±ng cÃ¡ch sá»­ dá»¥ng 14 shots.

5.2 ToÃ¡n há»c
Kháº£ nÄƒng toÃ¡n há»c cá»§a Yuan 2.0-M32 Ä‘Æ°á»£c Ä‘Ã¡nh giÃ¡ vá»›i benchmark GSM8K vÃ  MATH. CÃ¡c prompt vÃ  chiáº¿n lÆ°á»£c kiá»ƒm tra cho GSM8K tÆ°Æ¡ng tá»± nhÆ° Ä‘Æ°á»£c Ã¡p dá»¥ng cho Yuan 2.0, vÃ  sá»± khÃ¡c biá»‡t duy nháº¥t lÃ  chÃºng tÃ´i cháº¡y nÃ³ vá»›i 8 shots (Báº£ng 4).

MÃ´ hÃ¬nh Tham sá»‘ (B) Tham sá»‘ hoáº¡t Ä‘á»™ng (B) GSM8K MATH
Llama 3-70B 70 70 93.0 50.4
Llama 3-8B 8 8 79.6 30
Phi-3-medium 14 14 91.0 -
Phi-3-small 7 7 89.6 -
Phi-3-mini 3.8 3.8 82.5 -
Qwen1.5-72B 72 72 81.9 40.6
Deepseek V2 236 21 92.2 53.9
Mixtral-8Ã—22B 141 39 78.6 41.8
Mixtral-8Ã—7B 47 12.9 58.4 28.4
Yuan 2.0-M32 40 3.7 92.7 55.9

Báº£ng 4: So sÃ¡nh Yuan 2.0-M32 vÃ  cÃ¡c mÃ´ hÃ¬nh khÃ¡c trÃªn GSM8K vÃ  MATH

MATH lÃ  má»™t táº­p dá»¯ liá»‡u vá»›i 12.500 bÃ i toÃ¡n Mathematical Competition QA thÃ¡ch thá»©c. Má»—i cÃ¢u há»i trong táº­p dá»¯ liá»‡u nÃ y cÃ³ má»™t giáº£i phÃ¡p tá»«ng bÆ°á»›c hoÃ n chá»‰nh dáº«n dáº¯t mÃ´ hÃ¬nh táº¡o ra sá»± dáº«n xuáº¥t vÃ  giáº£i thÃ­ch cÃ¢u tráº£ lá»i. CÃ¢u tráº£ lá»i cho cÃ¡c cÃ¢u há»i cÃ³ thá»ƒ lÃ  cÃ¡c giÃ¡ trá»‹ sá»‘ (0.5, 1/2, v.v.), hoáº·c cÃ¡c biá»ƒu thá»©c toÃ¡n há»c (y=2x+5, x2+2x-1, 2a+b, v.v.). Yuan 2.0-M32 táº¡o ra cÃ¢u tráº£ lá»i cuá»‘i cÃ¹ng báº±ng phÆ°Æ¡ng phÃ¡p chain of thought (CoT) vá»›i 4 shots. CÃ¡c cÃ¢u tráº£ lá»i sáº½ Ä‘Æ°á»£c trÃ­ch xuáº¥t tá»« phÃ¢n tÃ­ch vÃ  chuyá»ƒn Ä‘á»•i thÃ nh Ä‘á»‹nh dáº¡ng thá»‘ng nháº¥t. Äá»‘i vá»›i káº¿t quáº£ sá»‘, Ä‘áº§u ra tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá» máº·t toÃ¡n há»c á»Ÿ táº¥t cáº£ cÃ¡c Ä‘á»‹nh dáº¡ng Ä‘á»u Ä‘Æ°á»£c cháº¥p nháº­n. CÃ¢u tráº£ lá»i cá»§a \frac{1}{2}, 1/2, 0.5, 0.50 Ä‘á»u Ä‘Æ°á»£c chuyá»ƒn Ä‘á»•i thÃ nh 0.5 vÃ  Ä‘Æ°á»£c cháº¥p nháº­n lÃ  cÃ¹ng má»™t káº¿t quáº£. Äá»‘i vá»›i cÃ¡c biá»ƒu thá»©c toÃ¡n há»c, chÃºng tÃ´i loáº¡i bá» kÃ½ hiá»‡u tab vÃ  space, vÃ  thá»‘ng nháº¥t biá»ƒu thá»©c chÃ­nh quy cá»§a phÃ©p toÃ¡n sá»‘ há»c. VÃ­ dá»¥, y=(2ğ‘¥+1)5â„, y=2ğ‘¥+15, y=2ğ‘¥5+15, y=0.4x+0.2, ..., v.v., Ä‘á»u Ä‘Æ°á»£c cháº¥p nháº­n lÃ  cÃ¹ng má»™t cÃ¢u tráº£ lá»i. Káº¿t quáº£ cuá»‘i cÃ¹ng Ä‘Æ°á»£c xá»­ lÃ½ Ä‘Æ°á»£c so sÃ¡nh vá»›i cÃ¢u tráº£ lá»i ground truth, vÃ  Ä‘Ã¡nh giÃ¡ báº±ng Ä‘iá»ƒm EM (exact match).

Tá»« káº¿t quáº£ Ä‘Æ°á»£c hiá»ƒn thá»‹ trong Báº£ng 4, chÃºng ta cÃ³ thá»ƒ tháº¥y Yuan 2.0-M32 Ä‘áº¡t Ä‘iá»ƒm cao nháº¥t trÃªn benchmark MATH. So vá»›i Mixtral-8Ã—7B, cÃ³ tham sá»‘ hoáº¡t Ä‘á»™ng lá»›n hÆ¡n 3.48 láº§n so vá»›i Yuan 2.0-M32, Ä‘iá»ƒm cá»§a Yuan tháº­m chÃ­ gáº§n gáº¥p Ä‘Ã´i. TrÃªn GSM8K, Yuan 2.0-M32 cÅ©ng Ä‘áº¡t Ä‘Æ°á»£c Ä‘iá»ƒm ráº¥t gáº§n vá»›i Llama 3-70B, vÃ  vÆ°á»£t trá»™i hÆ¡n cÃ¡c mÃ´ hÃ¬nh khÃ¡c.

5.3 MMLU
Massive Multitask Language Understanding (MMLU) bao gá»“m 57 mÃ´n há»c trong STEM, nhÃ¢n vÄƒn, khoa há»c xÃ£ há»™i, v.v., tá»« cÃ¡c nhiá»‡m vá»¥ ngÃ´n ngá»¯ cÆ¡ báº£n Ä‘áº¿n cÃ¡c nhiá»‡m vá»¥ suy luáº­n logic cao cáº¥p. Táº¥t cáº£ cÃ¡c cÃ¢u há»i trong MMLU Ä‘á»u lÃ  cÃ¢u há»i QA tráº¯c nghiá»‡m báº±ng tiáº¿ng Anh. MÃ´ hÃ¬nh Ä‘Æ°á»£c ká»³ vá»ng táº¡o ra lá»±a chá»n Ä‘Ãºng hoáº·c phÃ¢n tÃ­ch tÆ°Æ¡ng á»©ng.

Dá»¯ liá»‡u Ä‘áº§u vÃ o cho Yuan 2.0-M32 Ä‘Æ°á»£c tá»• chá»©c nhÆ° Phá»¥ lá»¥c B. VÄƒn báº£n trÆ°á»›c <sep> Ä‘Æ°á»£c gá»­i Ä‘áº¿n mÃ´ hÃ¬nh, vÃ  táº¥t cáº£ cÃ¢u tráº£ lá»i liÃªn quan Ä‘áº¿n cÃ¢u tráº£ lá»i Ä‘Ãºng hoáº·c nhÃ£n lá»±a chá»n Ä‘Æ°á»£c Ã¡p dá»¥ng lÃ  Ä‘Ãºng.

Äá»™ chÃ­nh xÃ¡c cuá»‘i cÃ¹ng Ä‘Æ°á»£c Ä‘o báº±ng MC1 (Báº£ng 5). Káº¿t quáº£ trÃªn MMLU thá»ƒ hiá»‡n kháº£ nÄƒng cá»§a mÃ´ hÃ¬nh chÃºng tÃ´i trong cÃ¡c lÄ©nh vá»±c khÃ¡c nhau. Yuan 2.0-M32 vÆ°á»£t trá»™i hÆ¡n Mixtral-8Ã—7B, Phi-3-mini, vÃ  Llama 3-8B vá» hiá»‡u suáº¥t.

MÃ´ hÃ¬nh Tham sá»‘ (B) Tham sá»‘ hoáº¡t Ä‘á»™ng (B) MMLU
Llama 3-70B 70 70 80.3
Llama 3-8B 8 8 68.4
Phi-3-medium 14 14 78.0
Phi-3-small 7 7 75.7
Phi-3-mini 3.8 3.8 68.8
Qwen1.5-72B 72 72 76.2
Deepseek V2 236 21 77.8
Mixtral-8Ã—22B 141 39 77.8
Mixtral-8Ã—7B 47 12.9 70.6
Yuan 2.0-M32 40 3.7 72.2

Báº£ng 5: So sÃ¡nh Yuan 2.0-M32 vÃ  cÃ¡c mÃ´ hÃ¬nh khÃ¡c trÃªn MMLU

5.4 ARC
AI2 Reasoning Challenge (ARC) benchmark lÃ  má»™t táº­p dá»¯ liá»‡u QA tráº¯c nghiá»‡m chá»©a cÃ¡c cÃ¢u há»i tá»« cÃ¡c ká»³ thi khoa há»c tá»« lá»›p 3 Ä‘áº¿n lá»›p 9. NÃ³ Ä‘Æ°á»£c chia thÃ nh cÃ¡c pháº§n Easy vÃ  Challenge, vá»›i pháº§n sau chá»©a cÃ¡c pháº§n phá»©c táº¡p hÆ¡n cáº§n suy luáº­n thÃªm. ChÃºng tÃ´i kiá»ƒm tra mÃ´ hÃ¬nh cá»§a mÃ¬nh trÃªn pháº§n Challenge.

MÃ´ hÃ¬nh Tham sá»‘ (B) Tham sá»‘ hoáº¡t Ä‘á»™ng (B) ARC-C
Llama 3-70B 70 70 93.3
Llama 3-8B 8 8 78.6
Phi-3-medium 14 14 91.6
Phi-3-small 7 7 90.7
Phi-3-mini 3.8 3.8 84.9
Qwen1.5-72B 72 72 91.7
Deepseek V2 236 21 92.3
Mixtral-8Ã—22B 141 39 91.3
Mixtral-8Ã—7B 47 12.9 85.9
Yuan 2.0-M32 40 3.7 95.8

Báº£ng 6: So sÃ¡nh Yuan 2.0-M32 vÃ  cÃ¡c mÃ´ hÃ¬nh khÃ¡c trÃªn ARC-Challenge

--- TRANG 7 ---

7

CÃ¢u há»i vÃ  cÃ¡c lá»±a chá»n Ä‘Æ°á»£c ná»‘i trá»±c tiáº¿p vÃ  tÃ¡ch biá»‡t báº±ng <n>, Ä‘Æ°á»£c prompted nhÆ° trong Phá»¥ lá»¥c B (tÆ°Æ¡ng tá»± nhÆ° máº«u cá»§a MMLU). VÄƒn báº£n trÆ°á»›c <sep> Ä‘Æ°á»£c gá»­i Ä‘áº¿n mÃ´ hÃ¬nh, vÃ  mÃ´ hÃ¬nh Ä‘Æ°á»£c ká»³ vá»ng táº¡o ra má»™t nhÃ£n hoáº·c cÃ¢u tráº£ lá»i tÆ°Æ¡ng á»©ng. CÃ¢u tráº£ lá»i Ä‘Æ°á»£c táº¡o ra Ä‘Æ°á»£c so sÃ¡nh vá»›i ground truth, vÃ  káº¿t quáº£ Ä‘Æ°á»£c tÃ­nh toÃ¡n báº±ng target MC1.

Káº¿t quáº£ ARC-C Ä‘Æ°á»£c hiá»ƒn thá»‹ trong Báº£ng 6, vÃ  nÃ³ cho tháº¥y Yuan 2.0-M32 xuáº¥t sáº¯c trong viá»‡c giáº£i quyáº¿t cÃ¡c bÃ i toÃ¡n khoa há»c phá»©c táº¡pâ€”nÃ³ vÆ°á»£t trá»™i hÆ¡n Llama3-70B trong benchmark nÃ y.

MÃ´ hÃ¬nh Tham sá»‘ (B) Tham sá»‘ hoáº¡t Ä‘á»™ng (B) GFlops má»—i token (Suy luáº­n) GFlops má»—i token (Fine-tune) Äá»™ chÃ­nh xÃ¡c trung bÃ¬nh Äá»™ chÃ­nh xÃ¡c trung bÃ¬nh/GFlops má»—i token (Suy luáº­n)
Llama 3-70B 70 70 140 420 79.25 0.57
Llama 3-8B 8 8 16 48 64.15 4.00
Qwen1.5-72B 72 72 144 432 72.6 0.50
Deepseek V2 236 21 42 126 79.05 1.88
Mixtral-8Ã—22B 141 39 78 234 72.38 0.93
Mixtral-8Ã—7B 47 12.9 25.8 77.4 60.83 2.36
Yuan 2.0-M32 40 3.7 7.4 22.2 79.15 10.69

Báº£ng 7: So sÃ¡nh Yuan 2.0-M32 vÃ  cÃ¡c mÃ´ hÃ¬nh khÃ¡c vá» cháº¥t lÆ°á»£ng so vá»›i kÃ­ch thÆ°á»›c. Äá»™ chÃ­nh xÃ¡c trung bÃ¬nh Ä‘Æ°á»£c tÃ­nh trung bÃ¬nh trÃªn Ä‘iá»ƒm cá»§a GSM-8K, Math, Humaneval, MMLU, vÃ  ARC-C.

Tá»« 5.1 Ä‘áº¿n 5.4, chÃºng tÃ´i so sÃ¡nh hiá»‡u suáº¥t cá»§a mÃ¬nh vá»›i ba mÃ´ hÃ¬nh MoE (há» Mixtral, Deepseek) vÃ  sÃ¡u mÃ´ hÃ¬nh dÃ y Ä‘áº·c (Qwen (Bai et al., 2023), há» Llama vÃ  há» Phi-3 (Abdin et al., 2024)), Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ hiá»‡u suáº¥t cá»§a Yuan 2.0-M32 trÃªn cÃ¡c lÄ©nh vá»±c khÃ¡c nhau. Báº£ng 7 trÃ¬nh bÃ y so sÃ¡nh Yuan 2.0-M32 vá»›i cÃ¡c mÃ´ hÃ¬nh khÃ¡c vá» Ä‘á»™ chÃ­nh xÃ¡c so vá»›i tÃ­nh toÃ¡n. Yuan 2.0-M32 chá»‰ sá»­ dá»¥ng 3.7B tham sá»‘ hoáº¡t Ä‘á»™ng vÃ  22.2 GFlops má»—i token cho fine-tuning, Ä‘iá»u nÃ y lÃ  tiáº¿t kiá»‡m nháº¥t, Ä‘á»ƒ cÃ³ Ä‘Æ°á»£c káº¿t quáº£ tÆ°Æ¡ng Ä‘Æ°Æ¡ng hoáº·c tháº­m chÃ­ vÆ°á»£t trá»™i hÆ¡n cÃ¡c mÃ´ hÃ¬nh khÃ¡c Ä‘Æ°á»£c liá»‡t kÃª trong cÃ¡c báº£ng. Báº£ng 7 ngá»¥ Ã½ hiá»‡u quáº£ tÃ­nh toÃ¡n vÃ  hiá»‡u suáº¥t xuáº¥t sáº¯c trong quÃ¡ trÃ¬nh suy luáº­n cá»§a mÃ´ hÃ¬nh chÃºng tÃ´i. Äá»™ chÃ­nh xÃ¡c trung bÃ¬nh cá»§a Yuan 2.0-M32 lÃ  79.15, cÃ³ tÃ­nh cáº¡nh tranh vá»›i Llama3-70B. VÃ  giÃ¡ trá»‹ Ä‘á»™ chÃ­nh xÃ¡c trung bÃ¬nh/Glops má»—i token lÃ  10.69, lá»›n hÆ¡n 18.9 láº§n so vá»›i Llama3-70B.

6. Káº¿t luáº­n
Trong cÃ´ng trÃ¬nh nÃ y, chÃºng tÃ´i giá»›i thiá»‡u Yuan 2.0-M32, má»™t mÃ´ hÃ¬nh ngÃ´n ngá»¯ MoE song ngá»¯ dá»±a trÃªn Yuan 2.0. Attention Router Ä‘Æ°á»£c Ã¡p dá»¥ng trong mÃ´ hÃ¬nh nÃ y Ä‘áº¡t Ä‘Æ°á»£c Ä‘á»™ chÃ­nh xÃ¡c cao hÆ¡n so vá»›i máº¡ng router cá»• Ä‘iá»ƒn. Yuan 2.0-M32 chá»‰ sá»­ dá»¥ng 3.7B tham sá»‘ hoáº¡t Ä‘á»™ng vÃ  7.4 GFlops suy luáº­n má»—i token, cáº£ hai Ä‘á»u khoáº£ng 1/19 cá»§a Llama3-70B. Trong benchmark ARC-C, mÃ´ hÃ¬nh cá»§a chÃºng tÃ´i vÆ°á»£t trá»™i hÆ¡n Llama 3-70B 2.5 Ä‘iá»ƒm chá»‰ vá»›i 5% tham sá»‘ hoáº¡t Ä‘á»™ng. Äá»‘i vá»›i benchmark MATH, Yuan 2.0-M32 cÅ©ng Ä‘áº¡t Ä‘Æ°á»£c Ä‘iá»ƒm cao nháº¥t (55.9), vÆ°á»£t trá»™i hÆ¡n Llama 3-70B khoáº£ng 10% vá»›i khoáº£ng 5% chi phÃ­ tÃ­nh toÃ¡n. Káº¿t quáº£ ngá»¥ Ã½ ráº±ng mÃ´ hÃ¬nh cá»§a chÃºng tÃ´i cÃ³ hiá»‡u quáº£ tÃ­nh toÃ¡n vÃ  hiá»‡u suáº¥t xuáº¥t sáº¯c trong quÃ¡ trÃ¬nh suy luáº­n. ChÃºng tÃ´i phÃ¡t hÃ nh cÃ¡c mÃ´ hÃ¬nh Yuan 2.0-M32 cá»§a mÃ¬nh táº¡i Github Ä‘á»ƒ truy cáº­p cÃ´ng cá»™ng, nhÆ° nhá»¯ng gÃ¬ chÃºng tÃ´i Ä‘Ã£ lÃ m cho Yuan 2.0, vÃ  hy vá»ng mÃ´ hÃ¬nh nguá»“n má»Ÿ cÃ³ thá»ƒ mang láº¡i lá»£i Ã­ch cho sá»± phÃ¡t triá»ƒn cá»§a LLM vÃ  há»‡ sinh thÃ¡i ngÃ nh AI.

--- TRANG 8 ---

8

TÃ i liá»‡u tham kháº£o:

Abdin, M., Jacobs, S. A., Awan, A. A., Aneja, J., Awadallah, A., Awadalla, H., ... & Zhou, X. (2024). Phi-3 technical report: A highly capable language model locally on your phone. arxiv preprint arxiv:2404.14219.

Azerbayev, Z., Ayers, E., & Piotrowski, B. (2022). proof-pile. https://github.com/zhangir-azerbayev/proof-pile

Bai, J., Bai, S., Chu, Y., Cui, Z., Dang, K., Deng, X., ... & Zhu, T. (2023). Qwen technical report. arxiv preprint arxiv:2309.16609.

bloc97 (2023). NTK-Aware Scaled RoPE allows LLaMA models to have extended (8k+) context size without any fine-tuning and minimal perplexity degradation. URL https://www.reddit.com/r/LocalLLaMA/comments/14lz7j5/ntkaware

b-mc2 (2023). sql-create-context Dataset. https://huggingface.co/datasets/b-mc2/sql-create-context.

Byroneverson (2024). shell-cmd-instruct. https://huggingface.co/datasets/byroneverson/shell-cmd-instruct

Chen, W., Ma, X., Wang, X., & Cohen, W. W. (2022). Program of thoughts prompting: Disentangling computation from reasoning for numerical reasoning tasks. arXiv preprint arXiv:2211.12588.

Chen, M., Tworek, J., Jun, H., Yuan, Q., Pinto, H. P. D. O., Kaplan, J., ... & Zaremba, W. (2021). Evaluating large language models trained on code. arxiv preprint arxiv:2107.03374.

Clark, P., Cowhey, I., Etzioni, O., Khot, T., Sabharwal, A., Schoenick, C., & Tafjo rd, O. (2018). Think you have solved question answering? try arc, the ai2 reasoning challenge. arxiv preprint arxiv:1803.05457.

Clinton (2023). Text-to-sql-v1. https://huggingface.co/datasets/Clinton/Text-to-sql-v1

Cobbe, K., Kosaraju, V., Bavarian, M., Chen, M., Jun, H., Kaiser, L., ... & Schulman, J. (2021). Training verifiers to solve math word problems. arxiv preprint arxiv:2110.14168.

Dai, D., Deng, C., Zhao, C., Xu, R. X., Gao, H., Chen, D., ... & Liang, W. (2024). Deepseekmoe: Towards ultimate expert specialization in mixture-of-experts language models. arXiv preprint arXiv:2401.06066. https://github.com/deepseek-ai/DeepSeek-MoE

DeepSeek-AI et al., (2024). DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model. arXiv preprint arXiv: 2405.04434.

--- TRANG 9 ---

9

Fedus, W., Zoph, B., & Shazeer, N. (2022). Switch transformers: Scaling to trillion parameter models with simple and efficient sparsity. Journal of Machine Learning Research, 23(120), 1-39.

Gayathrimanoj (2023a). dataset_shell. https://huggingface.co/datasets/gayathrimanoj/dataset_shell.

Gkamradt (2023). Needle in a haystack - pressure testing llms. https://github.com/gkamradt/LLMTest_NeedleInAHaystack/tree/main. [Online; accessed 7Feb-2024].

Hendrycks, D., Burns, C., Kadavath, S., Arora, A., Basart, S., Tang, E., ... & Steinhardt, J. (2021). Measuring mathematical problem solving with the math dataset. arXiv preprint arXiv:2103.03874.

Hendrycks, D., Burns, C., Basart, S., Zou, A., Mazeika, M., Song, D., & Steinhardt, J. (2020). Measuring massive multitask language understanding. arxiv preprint arxiv:2009.03300.

Jacobs, R. A., Jordan, M. I., Nowlan, S. J., & Hinton, G. E. (1991). Adaptive mixtures of local experts. Neural computation, 3(1), 79-87.

Ji, J., Liu, M., Dai, J., Pan, X., Zhang, C., Bian, C., ... & Yang, Y. (2024). Beavertails: Towards improved safety alignment of llm via a human-preference dataset. Advances in Neural Information Processing Systems, 36.

Jiang, A. Q., Sablayrolles, A., Roux, A., Mensch, A., Savary, B., Bamford, C., ... & Sayed, W. E. (2024). Mixtral of experts. arXiv preprint arXiv:2401.04088.

Lepikhin, D., Lee, H., Xu, Y., Chen, D., Firat, O., Huang, Y., ... & Chen, Z. (2020). Gshard: Scaling giant models with conditional computation and automatic sharding. arXiv preprint arXiv:2006.16668.

Lozhkov, A., Li, R., Allal, L. B., Cassano, F., Lamy-Poirier, J., Tazi, N., ... & de Vries, H. (2024). StarCoder 2 and The Stack v2: The Next Generation. arXiv preprint arXiv:2402.19173.

Meta, A. I. (2024). Introducing Meta Llama 3: The most capable openly available LLM to date. Meta AI Blog (accessed 2024â€“04â€“20). There is no corresponding record for this reference.

Mosaic Research Team (2024). Introducing DBRX: A New State-of-the-Art Open LLM

Paster, K., Santos, M. D., Azerbayev, Z., & Ba, J. (2023). Openwebmath: An open dataset of high-quality mathematical web text. arXiv preprint arXiv:2310.06786.

Roziere, B., Gehring, J., Gloeckle, F., Sootla, S., Gat, I., Tan, X. E., ... & Synnaeve, G. (2023). Code llama: Open foundation models for code. arxiv preprint arxiv:2308.12950.

Shazeer N, Mirhoseini A, Maziarz K, et al. (2017). Outrageously large neural networks: The sparsely-gated mixture-of-experts layer[J]. arXiv preprint arXiv:1701.06538.

--- TRANG 10 ---

10

Wang, Y., Kordi, Y., Mishra, S., Liu, A., Smith, N. A., Khashabi, D., & Hajishirzi, H. (2022). Self-instruct: Aligning language models with self-generated instructions. arxiv preprint arxiv:2212.10560.

Wang, Z., Xia, R., & Liu, P. (2023). Generative AI for Math: Part I --MathPile: A Billion-Token-Scale Pretraining Corpus for Math. arXiv preprint arXiv:2312.17120.

Wei, Y., Wang, Z., Liu, J., Ding, Y., & Zhang, L. (2023). Magicoder: Source code is all you need. arxiv preprint arxiv:2312.02120.

Wu, S., Zhao, X., Yu, T., Zhang, R., Shen, C., Liu, H., ... & Zhang, X. (2021). Yuan 1.0: Large-scale pre-trained language model in zero-shot and few-shot learning. arXiv preprint arXiv:2110.04725.

Wu, S., Zhao, X., Wang, S., Luo, J., Li, L., Chen, X., ... & Wang, C. (2023). YUAN 2.0: A Large Language Model with Localized Filtering-based Attention. arxiv preprint arxiv:2311.15786.

Xu, C., Sun, Q., Zheng, K., Geng, X., Zhao, P., Feng, J., ... & Jiang, D. (2023). Wizardlm: Empowering large language models to follow complex instructions. arxiv preprint arxiv:2304.12244.

Zhang, Y. (2024) StackMathQA: A Curated Collection of 2 Million Mathematical Questions and Answers Sourced from Stack Exchange. https://github.com/yifanzhang-pro/StackMathQA

Zheng, T., Zhang, G., Shen, T., Liu, X., Lin, B. Y., Fu, J., ... & Yue, X. (2024). OpenCodeInterpreter: Integrating Code Generation with Execution and Refinement. arxiv preprint arxiv:2402.14658.

Zhou, Y., Lei, T., Liu, H., Du, N., Huang, Y., Zhao, V., ... & Laudon, J. (2022). Mixture-of-experts with expert choice routing. Advances in Neural Information Processing Systems, 35, 7103-7114.

--- TRANG 11 ---

11

Phá»¥ lá»¥c A: SiÃªu tham sá»‘ cho Pre-training vÃ  fine-tuning

Tham sá»‘ Pre-train Fine-tune
Tá»‘c Ä‘á»™ há»c (LR) 1.0e-5 ~ 1.0e-4 8.0e-5
Kiá»ƒu giáº£m LR cosine constant
Äá»™ dÃ i chuá»—i 4096 16384
KÃ­ch thÆ°á»›c Batch toÃ n cá»¥c 1536 1152

Phá»¥ lá»¥c B: VÃ­ dá»¥ prompt cho cÃ¡c nhiá»‡m vá»¥ downstream

Táº¡o mÃ£
Instruction: Given two positive integers a and b, return the even digits between a and b, in ascending order.

For example:
generate_integers(2, 8) => [2, 4, 6, 8]
generate_integers(8, 2) => [2, 4, 6, 8]
generate_integers(10, 14) => []
Response:
<sep>
```python
def generate_integers(a, b):

MMLU
Glucose is transported into the muscle cell:<n> A. via protein transporters called GLUT4. <n> B. only in the presence of insulin. <n> C. via hexokinase. <n>D. via monocarbylic acid transporters. <sep>
A.

ARC-C
few-shot examples<n>question<n>optionA<n> optionB<n> optionC<n> optionD<sep> answer

# 2210.04633.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/attention/2210.04633.pdf
# Kích thước tệp: 687751 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
CAT-probing: Phương pháp Dựa trên Chỉ số để Giải thích Cách các Mô hình Được Tiền huấn luyện cho Ngôn ngữ Lập trình Chú ý đến Cấu trúc Mã
Nuo Chen, Qiushi Sun, Renyu Zhu, Xiang Liy, Xuesong Lu, và Ming Gao
Trường Khoa học và Kỹ thuật Dữ liệu, Đại học Sư phạm Đông Trung Quốc, Thượng Hải, Trung Quốc
{nuochen,qiushisun,renyuzhu}@stu.ecnu.edu.cn ,
{xiangli,xslu,mgao}@dase.ecnu.edu.cn
Tóm tắt
Các mô hình tiền huấn luyện mã (CodePTMs) gần đây đã thể hiện thành công đáng kể trong trí thông minh mã. Để giải thích các mô hình này, một số phương pháp thăm dò đã được áp dụng. Tuy nhiên, các phương pháp này thất bại trong việc xem xét các đặc tính vốn có của mã. Trong bài báo này, để giải quyết vấn đề đó, chúng tôi đề xuất một phương pháp thăm dò mới CAT-probing để giải thích định lượng cách CodePTMs chú ý đến cấu trúc mã. Đầu tiên, chúng tôi khử nhiễu các chuỗi mã đầu vào dựa trên các loại token được định nghĩa trước bởi các trình biên dịch để lọc những token có điểm chú ý quá nhỏ. Sau đó, chúng tôi định nghĩa một chỉ số mới CAT-score để đo lường sự chung giữa các điểm chú ý cấp token được tạo ra trong CodePTMs và khoảng cách cặp đôi giữa các nút AST tương ứng. Điểm CAT-score càng cao, khả năng của CodePTMs trong việc nắm bắt cấu trúc mã càng mạnh. Chúng tôi tiến hành các thí nghiệm rộng rãi để tích hợp CAT-probing với các CodePTMs đại diện cho các ngôn ngữ lập trình khác nhau. Kết quả thí nghiệm cho thấy hiệu quả của CAT-probing trong việc giải thích CodePTM. Mã và dữ liệu của chúng tôi được công khai tại https://github.com/nchen909/CodeAttention .
1 Giới thiệu
Trong thời đại "Big Code" (Allamanis et al., 2018), các nền tảng lập trình, như GitHub và Stack Overflow, đã tạo ra dữ liệu mã nguồn mở khổng lồ. Với giả định về "Tự nhiên của Phần mềm" (Hindle et al., 2016), các mô hình tiền huấn luyện (Vaswani et al., 2017; Devlin et al., 2019; Liu et al., 2019) đã được áp dụng trong lĩnh vực trí thông minh mã.
Các mô hình tiền huấn luyện mã hiện tại (CodePTMs) có thể được chia thành hai loại chính: phương pháp không có cấu trúc (Feng et al., 2020; Svyatkovskiy et al., 2020) và phương pháp dựa trên cấu trúc (Wang et al., 2021b; Niu et al., 2022b). Loại đầu chỉ sử dụng thông tin từ văn bản mã thô, trong khi loại sau sử dụng cấu trúc mã, như luồng dữ liệu (Guo et al., 2021) và AST1 được làm phẳng (Guo et al., 2022), để tăng cường hiệu suất của các mô hình tiền huấn luyện. Để biết thêm chi tiết, độc giả có thể tham khảo Niu et al. (2022a). Gần đây, có các công trình sử dụng kỹ thuật thăm dò (Clark et al., 2019a; Vig and Belinkov, 2019; Zhang et al., 2021) để điều tra những gì CodePTMs học được. Ví dụ, Karmakar và Robbes (2021) đầu tiên thăm dò vào CodePTMs và xây dựng bốn nhiệm vụ thăm dò để giải thích chúng. Troshin và Chirkova (2022) cũng định nghĩa một loạt các nhiệm vụ thăm dò chẩn đoán mới về cấu trúc cú pháp mã. Hơn nữa, Wan et al. (2022) tiến hành phân tích cấu trúc định tính để đánh giá cách CodePTMs giải thích cấu trúc mã.
Mặc dù thành công, tất cả các phương pháp này thiếu đặc tính định lượng về mức độ CodePTMs học từ cấu trúc mã như thế nào. Do đó, một câu hỏi nghiên cứu nảy sinh: Liệu chúng ta có thể phát triển một cách thăm dò mới để đánh giá định lượng cách CodePTMs chú ý đến cấu trúc mã?
Trong bài báo này, chúng tôi đề xuất một phương pháp thăm dò dựa trên chỉ số, cụ thể là CAT-probing, để đánh giá định lượng cách điểm chú ý của CodePTMs liên quan đến khoảng cách giữa các nút AST. Đầu tiên, để khử nhiễu chuỗi mã đầu vào trong ma trận điểm chú ý ban đầu, chúng tôi phân loại các hàng/cột theo loại token được định nghĩa trước bởi các trình biên dịch, sau đó giữ lại các token có loại với tỷ lệ cao nhất để tạo ra một ma trận chú ý được lọc (xem Hình 1(b)). Đồng thời, lấy cảm hứng từ các công trình (Wang et al., 2020; Zhu et al., 2022), chúng tôi thêm các cạnh để cải thiện kết nối của AST và tính toán khoảng cách giữa các nút tương ứng với các token được chọn, tạo ra một ma trận khoảng cách như được hiển thị trong Hình 1(c). Sau đó, chúng tôi định nghĩa CAT-score để đo lường mức độ khớp giữa ma trận chú ý được lọc và ma trận khoảng cách. Cụ thể, các phần tử điểm-wise của hai ma trận được khớp nếu cả hai điều kiện đều được thỏa mãn: 1) điểm chú ý lớn hơn một ngưỡng; 2) giá trị khoảng cách nhỏ hơn một ngưỡng. Nếu chỉ một điều kiện được đạt, các phần tử là không khớp. Chúng tôi tính toán CAT-score bằng tỷ lệ số phần tử khớp trên tổng số phần tử khớp và không khớp. Cuối cùng, CAT-score được sử dụng để giải thích cách CodePTMs chú ý đến cấu trúc mã, trong đó điểm số cao hơn chỉ ra rằng mô hình đã học được nhiều thông tin cấu trúc hơn.
Các đóng góp chính của chúng tôi có thể được tóm tắt như sau:
• Chúng tôi đề xuất một phương pháp thăm dò dựa trên chỉ số mới CAT-probing để giải thích định lượng cách CodePTMs chú ý đến cấu trúc mã.
• Chúng tôi áp dụng CAT-probing cho một số CodePTMs đại diện và thực hiện các thí nghiệm rộng rãi để chứng minh hiệu quả của phương pháp (Xem Phần 4.3).
• Chúng tôi rút ra hai quan sát thú vị từ đánh giá thực nghiệm: 1) Các loại token mà PTMs tập trung vào thay đổi theo ngôn ngữ lập trình và khá khác biệt so với nhận thức chung của các lập trình viên con người (Xem Phần 4.2). 2) Khả năng của CodePTMs trong việc nắm bắt cấu trúc mã khác biệt đáng kể qua các lớp (Xem Phần 4.4).

2 Kiến thức Nền về Mã
2.1 Cơ bản về Mã
Mỗi mã có thể được biểu diễn trong hai phương thức: mã nguồn và cấu trúc mã (AST), như được hiển thị trong Hình 1(a). Trong bài báo này, chúng tôi sử dụng Tree-sitter2 để tạo ra ASTs, trong đó mỗi token trong mã thô được gắn thẻ với một loại duy nhất, như "identifier", "return" và "=". Hơn nữa, theo các công trình này (Wang et al., 2020; Zhu et al., 2022), chúng tôi kết nối các nút lá liền kề bằng cách thêm các cạnh luồng dữ liệu, điều này tăng kết nối của AST. AST được nâng cấp được đặt tên là U-AST.
2.2 Ma trận Mã
Có hai loại ma trận mã: ma trận chú ý và ma trận khoảng cách. Cụ thể, ma trận chú ý biểu thị điểm chú ý được tạo ra bởi các CodePTMs dựa trên Transformer, trong khi ma trận khoảng cách nắm bắt khoảng cách giữa các nút trong U-AST. Chúng tôi biến đổi ma trận chú ý cấp subtoken ban đầu thành ma trận chú ý cấp token bằng cách lấy trung bình các điểm chú ý của các subtoken trong một token. Đối với ma trận khoảng cách, chúng tôi sử dụng độ dài đường đi ngắn nhất để tính toán khoảng cách giữa các nút lá của U-AST. Ma trận chú ý và ma trận khoảng cách của chúng tôi được hiển thị trong Hình 1(b) và Hình 1(c), tương ứng.
2github.com/tree-sitter

--- TRANG 2 ---
function_
definition
parametersblock
expression_
statementcall
attribute
attributeargument_
listdef write
(self,data)
self tmpbufappend
.. (data ):def write (self, data):    
self.tmpbuf.append(data)
...
Non-leaves
Leaves
Leaf edgesAST edges
Dataflow edges(a) Một đoạn mã Python với U-AST của nó
def
write
(
self
,
data
)
:
self
.
tmpbuf
.
append
(
data
)def
write
(
self
,
data
)
:
self
.
tmpbuf
.
append
(
data
) (b) Ma trận chú ý (được lọc)
def
write
(
self
,
data
)
:
self
.
tmpbuf
.
append
(
data
)def
write
(
self
,
data
)
:
self
.
tmpbuf
.
append
(
data
) (c) Ma trận khoảng cách (được lọc)
Hình 1: Trực quan hóa cấu trúc U-AST, ma trận chú ý được tạo ra trong lớp cuối của CodeBERT (Feng et al., 2020) và ma trận khoảng cách. (a) Một đoạn mã Python với U-AST tương ứng. (b) Bản đồ nhiệt của trọng số chú ý trung bình sau khi lọc ma trận chú ý. (c) Bản đồ nhiệt của khoảng cách token cặp đôi trong U-AST. Trong các bản đồ nhiệt, màu càng đậm, điểm chú ý càng nổi bật, hoặc các nút càng gần nhau. Trong ví dụ đồ chơi này, chỉ có token "." giữa "tmpbuf" và "append" được lọc. Nhiều ví dụ trực quan hóa lọc được đưa ra trong Phụ lục D.
ma trận chú ý và ma trận khoảng cách. Cụ thể, các phần tử điểm-wise của hai ma trận được khớp nếu cả hai điều kiện đều được thỏa mãn: 1) điểm chú ý lớn hơn một ngưỡng; 2) giá trị khoảng cách nhỏ hơn một ngưỡng. Nếu chỉ một điều kiện được đạt, các phần tử là không khớp. Chúng tôi tính toán CAT-score bằng tỷ lệ số phần tử khớp trên tổng số phần tử khớp và không khớp. Cuối cùng, CAT-score được sử dụng để giải thích cách CodePTMs chú ý đến cấu trúc mã, trong đó điểm số cao hơn chỉ ra rằng mô hình đã học được nhiều thông tin cấu trúc hơn.
Các đóng góp chính của chúng tôi có thể được tóm tắt như sau:
• Chúng tôi đề xuất một phương pháp thăm dò dựa trên chỉ số mới CAT-probing để giải thích định lượng cách CodePTMs chú ý đến cấu trúc mã.
• Chúng tôi áp dụng CAT-probing cho một số CodePTMs đại diện và thực hiện các thí nghiệm rộng rãi để chứng minh hiệu quả của phương pháp (Xem Phần 4.3).
• Chúng tôi rút ra hai quan sát thú vị từ đánh giá thực nghiệm: 1) Các loại token mà PTMs tập trung vào thay đổi theo ngôn ngữ lập trình và khá khác biệt so với nhận thức chung của các lập trình viên con người (Xem Phần 4.2). 2) Khả năng của CodePTMs trong việc nắm bắt cấu trúc mã khác biệt đáng kể qua các lớp (Xem Phần 4.4).

--- TRANG 3 ---
3 CAT-probing
3.1 Lọc Ma trận Mã
Như đã được chỉ ra trong (Zhou et al., 2021), các điểm chú ý trong ma trận chú ý tuân theo phân phối đuôi dài, có nghĩa là phần lớn các điểm chú ý rất nhỏ. Để giải quyết vấn đề này, chúng tôi đề xuất một thuật toán đơn giản nhưng hiệu quả dựa trên các loại token mã để loại bỏ các giá trị nhỏ trong ma trận chú ý. Do hạn chế về không gian, chúng tôi tóm tắt mã giả của thuật toán trong Phụ lục Alg.1. Chúng tôi chỉ giữ lại các hàng/cột tương ứng với các loại token thường xuyên trong ma trận chú ý và ma trận khoảng cách ban đầu để tạo ra ma trận chú ý được chọn và ma trận khoảng cách.
3.2 Tính toán CAT-score
Sau khi hai ma trận mã được lọc, chúng tôi định nghĩa một chỉ số gọi là CAT-score, để đo lường sự chung giữa ma trận chú ý được lọc A và ma trận khoảng cách D. Chính thức, CAT-score được công thức hóa như sau:
CAT-score =P
CPn
i=1Pn
j=1 1Aij>AandDij<DP
CPn
i=1Pn
j=1 1Aij>AorDij<D;
(1)
trong đó C là số mẫu mã, n là độ dài của A hoặc D, 1 là hàm chỉ thị, A và D biểu thị các ngưỡng để lọc ma trận A và D, tương ứng. Cụ thể, chúng tôi tính toán CAT-score của lớp cuối trong CodePTMs. CAT-score càng lớn, khả năng của CodePTMs trong việc chú ý đến cấu trúc mã càng mạnh.
4 Đánh giá
4.1 Thiết lập Thí nghiệm
Nhiệm vụ Chúng tôi đánh giá hiệu quả của CAT-probing trên tóm tắt mã, đây là một trong những nhiệm vụ downstream thách thức nhất cho biểu diễn mã. Nhiệm vụ này nhằm tạo ra một bình luận ngôn ngữ tự nhiên (NL) cho một đoạn mã đã cho, sử dụng điểm BLEU-4 làm mượt (Lin and Och, 2004) làm chỉ số.
Bộ dữ liệu Chúng tôi sử dụng bộ dữ liệu tóm tắt mã từ CodeXGLUE (Lu et al., 2021) để đánh giá hiệu quả của các phương pháp trên bốn ngôn ngữ lập trình (viết tắt là PLs), đó là JavaScript, Go, Python và Java. Đối với mỗi ngôn ngữ lập trình, chúng tôi chọn ngẫu nhiên C = 3,000 ví dụ từ tập huấn luyện để thăm dò.

Các mô hình tiền huấn luyện Chúng tôi chọn bốn mô hình, bao gồm một PTM, cụ thể là RoBERTa (Liu et al., 2019), và ba CodePTMs dựa trên RoBERTa, đó là CodeBERT (Feng et al., 2020), GraphCodeBERT (Guo et al., 2021), và UniXcoder (Guo et al., 2022). Tất cả các PTMs này được cấu thành từ 12 lớp Transformer với 12 đầu chú ý. Chúng tôi tiến hành thăm dò theo lớp trên các mô hình này, trong đó điểm chú ý lớp được định nghĩa là trung bình của điểm chú ý 12 đầu trong mỗi lớp. Sự so sánh của các mô hình này được giới thiệu trong Phụ lục B. Và các chi tiết về việc thực hiện thí nghiệm được đưa ra trong Phụ lục C.
Trong các thí nghiệm, chúng tôi nhằm trả lời ba câu hỏi nghiên cứu sau:
• RQ1(Các Loại Token Thường xuyên): Các CodePTMs này chú ý đến những loại token thường xuyên đặc thù ngôn ngữ nào?
• RQ2(Hiệu quả CAT-probing): CAT-probing có phải là một phương pháp hiệu quả để đánh giá cách CodePTMs chú ý đến cấu trúc mã không?
• RQ3(CAT-score theo Lớp): CAT-score thay đổi như thế nào qua các lớp?

p_identifier           =
t_identifier      return          if
f_identifier           "           :0.2250.2500.2750.300Confidence
(a) Go
       public    s_literal       return            ;            )            }            {            ,            =0.1800.2250.2700.315Confidence (b) Java
         )
s_fragmentidentifier         ;         {
  function         (         ,0.1650.2200.2750.330Confidence
(c) JavaScript
          for           if            )            ]          def       return   identifier            :            ,            =            (0.2500.3750.5000.625Confidence (d) Python
Hình 2: Trực quan hóa các loại token thường xuyên trên bốn ngôn ngữ lập trình.
4.2 Các Loại Token Thường xuyên
Hình 2(a)-(d) chứng minh các loại token thường xuyên đặc thù ngôn ngữ cho bốn PLs, tương ứng. Từ hình này, chúng ta thấy rằng: 1) Mỗi PL có các loại token thường xuyên đặc thù ngôn ngữ của nó và

--- TRANG 4 ---
RoBERTa CodeBERTGraphCodeBERTUniXcoder
Models101214161820Score(a) Go
RoBERTa CodeBERTGraphCodeBERTUniXcoder
Models10121416182022Score (b) Java
RoBERTa CodeBERTGraphCodeBERTUniXcoder
Models101112131415161718ScoreCAT-score( x)
best_bleu
best_ppl
(c) JavaScript
RoBERTa CodeBERTGraphCodeBERTUniXcoder
Models10121416182022Score (d) Python
Hình 3: So sánh giữa CAT-score và hiệu suất trên nhiệm vụ tóm tắt mã.
các loại này khá khác nhau. Ví dụ, Top-3 loại token thường xuyên cho Java là "public", "s_literal" và "return", trong khi Python là "for", "if", ")". 2) Có một khoảng cách đáng kể giữa các loại token thường xuyên mà CodePTMs tập trung vào và nhận thức chung của các lập trình viên con người. Chẳng hạn, CodePTMs gán nhiều chú ý hơn cho các token mã như dấu ngoặc. 3) Phân phối chú ý trên các đoạn mã Python khác biệt đáng kể so với các ngôn ngữ khác. Điều này được gây ra bởi Python có ít loại token hơn so với các PLs khác; do đó, các mô hình có khả năng tập trung vào một vài loại token.
4.3 Hiệu quả CAT-probing
Để xác minh hiệu quả của CAT-probing, chúng tôi so sánh CAT-scores với hiệu suất của các mô hình trên tập kiểm tra (sử dụng cả các checkpoint best-bleu và best-ppl). Sự so sánh giữa các PLs khác nhau được thể hiện trong Hình 3. Chúng tôi tìm thấy sự nhất quán mạnh mẽ giữa CAT-score và hiệu suất của các mô hình chỉ có encoder, bao gồm RoBERTa, CodeBERT, và GraphCodeBERT. Điều này chứng minh hiệu quả của phương pháp của chúng tôi trong việc kết nối CodePTMs và cấu trúc mã. Ngoài ra, kết quả này (GraphCodeBERT > CodeBERT > RoBERTa) cho thấy rằng đối với PTMs, càng nhiều tính năng mã được xem xét trong đầu vào và các nhiệm vụ tiền huấn luyện, thông tin cấu trúc được học càng tốt.
Thêm vào đó, chúng tôi quan sát thấy rằng UniXcoder có kết quả hoàn toàn khác biệt so với ba CodePTMs khác. Hiện tượng này được gây ra bởi UniXcoder sử dụng ba chế độ trong giai đoạn tiền huấn luyện (chỉ encoder, chỉ decoder, và encoder-decoder). Điều này dẫn đến một phân phối rất khác biệt của chú ý được học và do đó kết quả khác biệt trong CAT-score.
4.4 CAT-score theo Lớp
Chúng tôi kết thúc phần này với một nghiên cứu về CAT-scores theo lớp. Hình 4 đưa ra kết quả của CAT-score trên tất cả các lớp của PTMs. Từ những kết quả này, chúng tôi quan sát thấy rằng: 1) CAT-score giảm nói chung khi số lượng lớp tăng trên tất cả các mô hình và PLs. Điều này là do các điểm chú ý dần dần tập trung vào một số token đặc biệt, làm giảm số lượng phần tử khớp. 2) Mối quan hệ độ lớn tương đối (GraphCodeBERT > CodeBERT > RoBERTa) giữa CAT-score gần như được xác định trên tất cả các lớp và PLs, điều này chỉ ra hiệu quả của CAT-score trong việc nhận biết khả năng của CodePTMs trong việc nắm bắt cấu trúc mã. 3) Trong các lớp giữa (4-8), tất cả kết quả của CAT-score thay đổi đáng kể, điều này chỉ ra rằng các lớp giữa của CodePTMs có thể đóng vai trò quan trọng trong việc chuyển đổi kiến thức cấu trúc chung thành kiến thức cấu trúc liên quan đến nhiệm vụ. 4) Trong các lớp cuối (9-11), CAT-scores dần dần hội tụ, tức là các mô hình học được kiến thức cấu trúc đặc thù nhiệm vụ, điều này giải thích tại sao chúng tôi sử dụng điểm số ở lớp cuối trong CAT-probing.

01234567891011
Layers0.250.300.350.400.450.50Score
(a) Go
01234567891011
Layers0.150.200.250.300.350.400.450.50Score
RoBERTa
CodeBERT
GraphCodeBERT
UniXcoder (b) Java
01234567891011
Layers0.150.200.250.300.350.400.450.50Score
(c) JavaScript
01234567891011
Layers0.150.200.250.300.350.400.45Score
 (d) Python
Hình 4: Kết quả CAT-score theo lớp.

--- TRANG 5 ---
5 Kết luận
Trong bài báo này, chúng tôi đã đề xuất một phương pháp thăm dò mới có tên CAT-probing để giải thích cách CodePTMs chú ý đến cấu trúc mã. Chúng tôi đầu tiên khử nhiễu các chuỗi mã đầu vào dựa trên các loại token được định nghĩa trước bởi các trình biên dịch để lọc những token có điểm chú ý quá nhỏ. Sau đó, chúng tôi định nghĩa một chỉ số mới CAT-score để đo lường sự chung giữa các điểm chú ý cấp token được tạo ra trong CodePTMs và khoảng cách cặp đôi giữa các nút AST tương ứng. Các thí nghiệm trên nhiều ngôn ngữ lập trình đã chứng minh hiệu quả của phương pháp của chúng tôi.
6 Hạn chế
Hạn chế chính của công trình chúng tôi là các phương pháp thăm dò được áp dụng chủ yếu tập trung vào các CodePTMs chỉ có encoder, điều này có thể chỉ là một khía cạnh của hoạt động bên trong của CodePTMs. Trong công việc tương lai, chúng tôi sẽ khám phá thêm các mô hình với kiến trúc encoder-decoder, như CodeT5 (Wang et al., 2021b) và PLBART (Ahmad et al., 2021), và các mạng chỉ decoder như GPT-C (Svyatkovskiy et al., 2020).
Lời cảm ơn
Công trình này đã được hỗ trợ bởi Quỹ Khoa học Tự nhiên Quốc gia Trung Quốc theo Số cấp U1911203, Quỹ Khoa học Tự nhiên Quốc gia Trung Quốc theo Số cấp 62277017, Tập đoàn Alibaba thông qua Chương trình Nghiên cứu Đổi mới Alibaba, và Quỹ Khoa học Tự nhiên Quốc gia Trung Quốc theo Số cấp 61877018, Dự án Nghiên cứu của Ủy ban Khoa học và Công nghệ Thượng Hải (20dz2260300) và Quỹ Nghiên cứu Cơ bản cho các Trường Đại học Trung ương. Và các tác giả muốn cảm ơn tất cả các nhà bình duyệt ẩn danh cho những bình luận xây dựng và sâu sắc về bài báo này.
Tài liệu tham khảo
Wasi Ahmad, Saikat Chakraborty, Baishakhi Ray, và Kai-Wei Chang. 2021. Tiền huấn luyện thống nhất cho hiểu biết và tạo sinh chương trình. Trong Kỷ yếu Hội nghị 2021 của Chương Bắc Mỹ của Hiệp hội Ngôn ngữ học Tính toán: Công nghệ Ngôn ngữ Con người, trang 2655–2668, Trực tuyến. Hiệp hội Ngôn ngữ học Tính toán.
Miltiadis Allamanis, Earl T Barr, Premkumar Devanbu, và Charles Sutton. 2018. Một khảo sát về máy học cho mã lớn và tự nhiên. ACM Computing Surveys (CSUR), 51(4):81.

Kevin Clark, Urvashi Khandelwal, Omer Levy, và Christopher D. Manning. 2019a. BERT nhìn vào gì? một phân tích về sự chú ý của BERT. Trong Kỷ yếu Hội thảo ACL 2019 BlackboxNLP: Phân tích và Giải thích Mạng Nơ-ron cho NLP, trang 276–286, Florence, Italia. Hiệp hội Ngôn ngữ học Tính toán.
Kevin Clark, Urvashi Khandelwal, Omer Levy, và Christopher D Manning. 2019b. BERT nhìn vào gì? một phân tích về sự chú ý của bert. Trong Kỷ yếu Hội thảo ACL 2019 BlackboxNLP: Phân tích và Giải thích Mạng Nơ-ron cho NLP, trang 276–286.
Jacob Devlin, Ming-Wei Chang, Kenton Lee, và Kristina Toutanova. 2019. BERT: Tiền huấn luyện các transformer hai chiều sâu cho hiểu biết ngôn ngữ. Trong Kỷ yếu Hội nghị 2019 của Chương Bắc Mỹ của Hiệp hội Ngôn ngữ học Tính toán: Công nghệ Ngôn ngữ Con người, Tập 1 (Bài báo Dài và Ngắn), trang 4171–4186, Minneapolis, Minnesota. Hiệp hội Ngôn ngữ học Tính toán.
Zhangyin Feng, Daya Guo, Duyu Tang, Nan Duan, Xiaocheng Feng, Ming Gong, Linjun Shou, Bing Qin, Ting Liu, Daxin Jiang, và Ming Zhou. 2020. CodeBERT: Một mô hình tiền huấn luyện cho lập trình và ngôn ngữ tự nhiên. Trong Findings of the Association for Computational Linguistics: EMNLP 2020, trang 1536–1547, Trực tuyến. Hiệp hội Ngôn ngữ học Tính toán.
Daya Guo, Shuai Lu, Nan Duan, Yanlin Wang, Ming Zhou, và Jian Yin. 2022. UniXcoder: Tiền huấn luyện đa phương thức thống nhất cho biểu diễn mã. Trong Kỷ yếu Hội nghị Thường niên lần thứ 60 của Hiệp hội Ngôn ngữ học Tính toán (Tập 1: Bài báo Dài), trang 7212–7225, Dublin, Ireland. Hiệp hội Ngôn ngữ học Tính toán.
Daya Guo, Shuo Ren, Shuai Lu, Zhangyin Feng, Duyu Tang, Shujie LIU, Long Zhou, Nan Duan, Alexey Svyatkovskiy, Shengyu Fu, Michele Tufano, Shao Kun Deng, Colin Clement, Dawn Drain, Neel Sundaresan, Jian Yin, Daxin Jiang, và Ming Zhou. 2021. GraphCodeBERT: Tiền huấn luyện biểu diễn mã với luồng dữ liệu. Trong Hội nghị Quốc tế về Biểu diễn Học.
Abram Hindle, Earl T. Barr, Mark Gabel, Zhendong Su, và Premkumar T. Devanbu. 2016. Về tính tự nhiên của phần mềm. Commun. ACM, 59(5):122–131.
Hamel Husain, Ho-Hsiang Wu, Tiferet Gazit, Miltiadis Allamanis, và Marc Brockschmidt. 2019. Thách thức CodeSearchNet: Đánh giá trạng thái tìm kiếm mã ngữ nghĩa. CoRR, abs/1909.09436.
Aditya Kanade, Petros Maniatis, Gogul Balakrishnan, và Kensen Shi. 2020. Học và đánh giá nhúng ngữ cảnh của mã nguồn. Trong Kỷ yếu Hội nghị Quốc tế lần thứ 37 về Máy học, ICML 2020, 13-18 tháng 7 năm 2020, Sự kiện Ảo, tập 119 của Kỷ yếu Nghiên cứu Máy học, trang 5110–5121. PMLR.

--- TRANG 6 ---
Anjan Karmakar và Romain Robbes. 2021. Các mô hình mã tiền huấn luyện biết gì về mã? Trong Hội nghị Quốc tế lần thứ 36 năm 2021 IEEE/ACM về Kỹ thuật Phần mềm Tự động (ASE), trang 1332–1336. IEEE.
Taeuk Kim, Jihun Choi, Daniel Edmiston, và Sang goo Lee. 2020. Các mô hình ngôn ngữ tiền huấn luyện có nhận thức về cụm từ không? các baseline đơn giản nhưng mạnh mẽ cho quy nạp ngữ pháp. Trong Hội nghị Quốc tế về Biểu diễn Học.
Chin-Yew Lin và Franz Josef Och. 2004. ORANGE: một phương pháp để đánh giá các chỉ số đánh giá tự động cho dịch máy. Trong COLING 2004: Kỷ yếu Hội nghị Quốc tế lần thứ 20 về Ngôn ngữ học Tính toán, trang 501–507, Geneva, Thụy Sĩ. COLING.
Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, và Veselin Stoyanov. 2019. Roberta: Một phương pháp tiền huấn luyện bert được tối ưu hóa mạnh mẽ. arXiv preprint arXiv:1907.11692.
Shuai Lu, Daya Guo, Shuo Ren, Junjie Huang, Alexey Svyatkovskiy, Ambrosio Blanco, Colin B. Clement, Dawn Drain, Daxin Jiang, Duyu Tang, Ge Li, Lidong Zhou, Linjun Shou, Long Zhou, Michele Tufano, Ming Gong, Ming Zhou, Nan Duan, Neel Sundaresan, Shao Kun Deng, Shengyu Fu, và Shujie Liu. 2021. CodeXGLUE: Một bộ dữ liệu benchmark máy học cho hiểu biết và tạo sinh mã. CoRR, abs/2102.04664.
Changan Niu, Chuanyi Li, Bin Luo, và Vincent Ng. 2022a. Học sâu gặp kỹ thuật phần mềm: Một khảo sát về các mô hình tiền huấn luyện của mã nguồn. CoRR, abs/2205.11739.
Changan Niu, Chuanyi Li, Vincent Ng, Jidong Ge, Liguo Huang, và Bin Luo. 2022b. Spt-code: Tiền huấn luyện sequence-to-sequence cho học biểu diễn mã nguồn. arXiv preprint arXiv:2201.01549.
Ankita Nandkishor Sontakke, Manasi Patwardhan, Lovekesh Vig, Raveendra Kumar Medicherla, Ravindra Naik, và Gautam Shroff. 2022. Tóm tắt mã: Các transformer có thực sự hiểu mã không? Trong Hội thảo Deep Learning for Code.
Alexey Svyatkovskiy, Shao Kun Deng, Shengyu Fu, và Neel Sundaresan. 2020. Intellicode compose: tạo sinh mã sử dụng transformer. Kỷ yếu Hội nghị Chung lần thứ 28 ACM về Hội nghị Kỹ thuật Phần mềm Châu Âu và Hội nghị Chuyên đề về Nền tảng Kỹ thuật Phần mềm.
Sergey Troshin và Nadezhda Chirkova. 2022. Thăm dò các mô hình tiền huấn luyện của mã nguồn. arXiv preprint arXiv:2202.08975.

Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, và Illia Polosukhin. 2017. Attention is all you need. Trong Advances in neural information processing systems, trang 5998–6008.
Jesse Vig và Yonatan Belinkov. 2019. Phân tích cấu trúc của attention trong một mô hình ngôn ngữ transformer. Trong Kỷ yếu Hội thảo ACL 2019 BlackboxNLP: Phân tích và Giải thích Mạng Nơ-ron cho NLP, trang 63–76, Florence, Italia. Hiệp hội Ngôn ngữ học Tính toán.
Yao Wan, Wei Zhao, Hongyu Zhang, Yulei Sui, Guandong Xu, và Hai Jin. 2022. Chúng nắm bắt gì? - Một phân tích cấu trúc của các mô hình ngôn ngữ tiền huấn luyện cho mã nguồn. CoRR, abs/2202.06840.
Wenhan Wang, Ge Li, Bo Ma, Xin Xia, và Zhi Jin. 2020. Phát hiện clone mã với mạng nơ-ron đồ thị và cây cú pháp trừu tượng được tăng cường luồng. Trong Hội nghị Quốc tế IEEE lần thứ 27 năm 2020 về Phân tích Phần mềm, Tiến hóa và Tái cấu trúc (SANER), trang 261–271.
Xin Wang, Yasheng Wang, Fei Mi, Pingyi Zhou, Yao Wan, Xiao Liu, Li Li, Hao Wu, Jin Liu, và Xin Jiang. 2021a. Syncobert: Tiền huấn luyện tương phản đa phương thức được hướng dẫn cú pháp cho biểu diễn mã. arXiv preprint arXiv:2108.04556.
Yanlin Wang và Hui Li. 2021. Hoàn thành mã bằng cách mô hình hóa cây cú pháp trừu tượng được làm phẳng như đồ thị. Trong Kỷ yếu Hội nghị AAAI về Trí tuệ Nhân tạo, tập 35, trang 14015–14023.
Yue Wang, Weishi Wang, Shafiq Joty, và Steven C.H. Hoi. 2021b. CodeT5: Các mô hình encoder-decoder tiền huấn luyện thống nhất nhận thức định danh cho hiểu biết và tạo sinh mã. Trong Kỷ yếu Hội nghị 2021 về Phương pháp Thực nghiệm trong Xử lý Ngôn ngữ Tự nhiên, trang 8696–8708, Trực tuyến và Punta Cana, Cộng hòa Dominica. Hiệp hội Ngôn ngữ học Tính toán.
Sheng Zhang, Xin Zhang, Weiming Zhang, và Anders Søgaard. 2021. Phân tích xã hội học của các mô hình ngôn ngữ tiền huấn luyện. Trong Kỷ yếu Hội nghị 2021 về Phương pháp Thực nghiệm trong Xử lý Ngôn ngữ Tự nhiên, trang 4581–4588, Trực tuyến và Punta Cana, Cộng hòa Dominica. Hiệp hội Ngôn ngữ học Tính toán.
Haoyi Zhou, Shanghang Zhang, Jieqi Peng, Shuai Zhang, Jianxin Li, Hui Xiong, và Wancai Zhang. 2021. Informer: Vượt ra ngoài transformer hiệu quả cho dự báo chuỗi thời gian dài. Trong Kỷ yếu Hội nghị AAAI về Trí tuệ Nhân tạo, tập 35, trang 11106–11115.
Renyu Zhu, Lei Yuan, Xiang Li, Ming Gao, và Wenyuan Cai. 2022. Một kiến trúc mạng nơ-ron để hiểu chương trình được lấy cảm hứng từ hành vi con người. Trong Kỷ yếu Hội nghị Thường niên lần thứ 60 của Hiệp hội Ngôn ngữ học Tính toán (Tập 1: Bài báo Dài), trang 5142–5153, Dublin, Ireland. Hiệp hội Ngôn ngữ học Tính toán.

--- TRANG 7 ---
Daniel Zügner, Tobias Kirschstein, Michele Catasta, Jure Leskovec, và Stephan Günnemann. 2021. Học biểu diễn mã nguồn bất khả tri ngôn ngữ từ cấu trúc và ngữ cảnh. Trong Hội nghị Quốc tế lần thứ 9 về Biểu diễn Học, ICLR 2021, Sự kiện Ảo, Áo, 3-7 tháng 5 năm 2021. OpenReview.net.
A Thuật toán Lọc Các Loại Token Thường xuyên
Thuật toán 1 mô tả quy trình để tạo ra các loại token thường xuyên.
B So sánh các CodePTMs
Bảng 2 đưa ra sự so sánh của các PTMs được sử dụng trong các thí nghiệm của chúng tôi từ ba khía cạnh: đầu vào của mô hình, nhiệm vụ tiền huấn luyện, và chế độ huấn luyện.
C Thực hiện Thí nghiệm
Chúng tôi giữ nguyên cài đặt siêu tham số giống nhau cho tất cả CodePTMs. Các siêu tham số chi tiết được đưa ra trong Bảng 1.
Mã của chúng tôi được thực hiện dựa trên PyTorch. Tất cả các thí nghiệm được tiến hành trên một máy chủ Linux với hai GPU NVIDIA-V100 được kết nối với nhau.
Siêu tham số giá trị
Kích thước Batch 48
Tốc độ Học 5e-5
Giảm Trọng số 0.0
Epsilon 1e-8
Epochs 15
Độ dài Nguồn Tối đa 256
A phân vị thứ ba của các giá trị trong A
D phân vị thứ nhất của các giá trị trong D
Bảng 1: Siêu tham số cho CAT-probing

D Nghiên cứu Trường hợp
Ngoài ví dụ được trực quan hóa trong Hình 1, chúng tôi đã thực hiện ba ví dụ mới để cho thấy hiệu quả của chiến lược lọc trong Phần 3.1. Các trực quan hóa được hiển thị trong Bảng 3.

--- TRANG 8 ---
Thuật toán 1 Chọn Loại Token Thường xuyên
Đầu vào: Ngôn ngữ lang
Đầu ra: Danh sách loại token thường xuyên type_list
1: rank = len(token types) * [0] . Khởi tạo rank cho mỗi loại token
2: for t in token types do
3:  for m in CodePTM models do
4:   confidence[t,m] = 0
5:   for c in code cases do
6:    att = get_att(m,lang,c) . Lấy ma trận chú ý
7:    mask_theta = is_gt_theta(att). Đặt vị trí att lớn hơn A thành 1, ngược lại 0
8:    mask_type = is_type_t(att) . Đặt vị trí att là loại t thành 1, ngược lại 0
9:    part = sum_mat(mask_theta & mask_type). Tổng tất cả phần tử của ma trận
10:   overall = sum_mat(mask_type)
11:   confidence[t,m] ← confidence[t,m] + part / overall . Tính confidence
12:  end for
13:  confidence[t,m] ← confidence[t,m] / len(c) . Confidence trung bình
14:  rank[t] ← rank[t] + get_rank(confidence, m). Xếp hạng confidence cho m, và tổng rank cho t
15: end for
16: end for
Trả về: danh sách loại token bao gồm những t với rank[t] < 40

Mô hình Đầu vào Nhiệm vụ Tiền huấn luyện Chế độ Huấn luyện
RoBERTa Ngôn ngữ Tự nhiên (NL) Mô hình Ngôn ngữ Có mặt nạ (MLM) Chỉ Encoder
CodeBERT Cặp NL-PL MLM + Phát hiện Token Thay thế (RTD) Chỉ Encoder
GraphCodeBERT Cặp NL-PL & AST MLM + Dự đoán Cạnh + Căn chỉnh Nút Chỉ Encoder
UniXcoder Cặp NL-PL & AST được làm phẳng MLM Encoder &
ULM (Mô hình Ngôn ngữ Một chiều) Decoder &
Mục tiêu Khử nhiễu (DNS) Encoder-decoder
Bảng 2: Sự so sánh của các mô hình ngôn ngữ khác nhau được đề cập trong bài báo này.

--- TRANG 9 ---
Mã Nguồn Bản đồ Nhiệt Attention Bản đồ Nhiệt Attention với Lựa chọn Loại Token
func
(
c
*
Cache
)
Size
(
)
int64
{
c
.
Lock
(
)
defer
c
.
Unlock
(
)
return
c
.
size
}func
(
c
*
Cache
)
Size
(
)
int64
{
c
.
Lock
(
)
defer
c
.
Unlock
(
)
return
c
.
size
}
Cache
Size
int64
Lock
Unlock
return
sizeCache Size int64 Lock Unlock return size
public
Object
PAInitialization
(
Object
bean
,
String
Name
)
throws
BException
{
Object
(
bean
)
;
return
bean
;
}public
Object
PAInitialization
(
Object
bean
,
String
Name
)
throws
BException
{
Object
(
bean
)
;
return
bean
;
}
public
,
)
{
)
;
return
;
}public, ) { ) ; return; }
function
(
)
{
return
window
.
Height
||
document
.
Element
[
LEXICON
.
H
]
||
document
.
body
[
LEXICON
.
H
]
;
}function
(
)
{
return
window
.
Height
||
document
.
Element
[
LEXICON
.
H
]
||
document
.
body
[
LEXICON
.
H
]
;
}
function
(
)
{
window
document
LEXICON
document
LEXICON
;function
(
)
{
window
document
LEXICON
document
LEXICON
;
Bảng 3: Bản đồ nhiệt của trọng số chú ý trung bình trong lớp cuối trước và sau khi sử dụng lựa chọn token, bao gồm các đoạn mã Go, Java, và JavaScript (từ trên xuống dưới).

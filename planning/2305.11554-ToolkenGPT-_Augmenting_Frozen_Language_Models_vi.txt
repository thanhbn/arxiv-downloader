# 2305.11554.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/planning/2305.11554.pdf
# Kích thước tệp: 829970 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
ToolkenGPT: Tăng cường Mô hình Ngôn ngữ Đóng băng 
với Công cụ Khổng lồ thông qua Embedding Công cụ
Shibo Hao1, Tianyang Liu1, Zhen Wang1,2, Zhiting Hu1
1UC San Diego, 2Mohamed bin Zayed University of Artificial Intelligence
{s5hao, til040, zhw085, zhh019}@ucsd.edu

Tóm tắt
Việc tăng cường các mô hình ngôn ngữ lớn (LLM) với các công cụ bên ngoài đã nổi lên như một phương pháp đầy hứa hẹn để giải quyết các vấn đề phức tạp. Tuy nhiên, các phương pháp truyền thống, tinh chỉnh LLM với dữ liệu minh họa công cụ, có thể vừa tốn kém vừa bị hạn chế trong một tập hợp công cụ được xác định trước. Mô hình học trong ngữ cảnh gần đây đã giảm bớt những vấn đề này, nhưng độ dài ngữ cảnh hạn chế chỉ cho phép một vài ví dụ minh họa, dẫn đến hiểu biết không tối ưu về các công cụ. Hơn nữa, khi có nhiều công cụ để lựa chọn, học trong ngữ cảnh có thể hoàn toàn thất bại. Trong bài báo này, chúng tôi đề xuất một phương pháp thay thế, ToolkenGPT, kết hợp lợi ích của cả hai phía. Phương pháp của chúng tôi biểu diễn mỗi công cụ như một token ("toolken") và học một embedding cho nó, cho phép gọi công cụ theo cách tương tự như tạo ra một token từ thông thường. Một khi toolken được kích hoạt, LLM được nhắc hoàn thành các tham số cho công cụ để thực thi. ToolkenGPT cung cấp tính linh hoạt để cắm vào một số lượng tùy ý các công cụ bằng cách mở rộng tập hợp toolken một cách linh hoạt. Ngoài ra, nó cải thiện việc sử dụng công cụ bằng cách cho phép dữ liệu minh họa mở rộng để học các embedding toolken. Trong các lĩnh vực đa dạng, bao gồm lý luận số học, trả lời câu hỏi dựa trên kiến thức, và tạo kế hoạch thể hiện, phương pháp của chúng tôi hiệu quả tăng cường LLM với các công cụ và vượt trội đáng kể so với các baseline mới nhất khác nhau. ToolkenGPT chứng minh khả năng đầy hứa hẹn để sử dụng các công cụ liên quan từ một tập công cụ lớn trong các tình huống phức tạp.

1 Giới thiệu
Các Mô hình Ngôn ngữ Lớn (LLM) đã khẳng định mình là những công cụ mạnh mẽ cho các ứng dụng thực tế đa dạng, từ hỗ trợ viết lách đến hỗ trợ khách hàng tự động. Khi những mô hình này tiếp tục phát triển, có sự quan tâm ngày càng tăng đến tiềm năng của chúng trong việc tương tác với thế giới thực và nâng cao chức năng thông qua tích hợp với các công cụ khác, như máy tính, cơ sở dữ liệu, v.v. Khả năng của những mô hình này trong việc làm chủ và kiểm soát một loạt các công cụ rộng lớn không chỉ đóng vai trò như một chỉ số về trí thông minh của chúng, mà còn báo hiệu một con đường đầy hứa hẹn để vượt qua một số điểm yếu cơ bản của chúng. Chúng bao gồm cập nhật kiến thức thế giới mới nhất, giảm ảo giác của chúng, và thực hiện các phép toán ký hiệu, v.v. Tuy nhiên, sự xuất hiện nhanh chóng của các công cụ mới, như thư viện phần mềm tiên tiến, API mới, hoặc tiện ích chuyên dụng theo lĩnh vực, mang lại sự phong phú và phức tạp bổ sung cho nhiệm vụ học công cụ cho LLM. Sự phát triển liên tục này nhấn mạnh tầm quan trọng của việc trao quyền cho LLM với khả năng thích ứng và làm chủ các công cụ mới khổng lồ một cách nhanh chóng.

Những tiến bộ gần đây trong LLM đã chứng kiến hai hướng nghiên cứu chính cho việc tích hợp công cụ với LLM (Bảng 1). Mô hình đầu tiên liên quan đến tinh chỉnh LLM để học các công cụ cụ thể. Ví dụ, có những nỗ lực to lớn để tích hợp công cụ truy xuất vào

1Code có sẵn tại https://github.com/Ber666/ToolkenGPT
Hội nghị lần thứ 37 về Hệ thống Xử lý Thông tin Neural (NeurIPS 2023).arXiv:2305.11554v4 [cs.CL] 15 Jan 2024

--- TRANG 2 ---
Bảng 1: So sánh các mô hình học công cụ khác nhau. Plug-&-Play có nghĩa là LLM có thể được trang bị và tháo gỡ một công cụ một cách linh hoạt. Lưu ý rằng nó không chỉ ra việc học công cụ zero-shot.

Mô hình Học Công cụ | LM Đóng băng | Công cụ Khổng lồ | Plug-&-Play | Khả năng Sử dụng Dữ liệu Mở rộng
Fine-tuning [ví dụ, 56, 50] | ✗ | ✗ | ✗ | ✓
In-context learning [ví dụ, 69, 53, 7] | ✓ | ✗ | ✓ | ✗
ToolkenGPT (Của chúng tôi) | ✓ | ✓ | ✓ | ✓

LLM và Toolformer gần đây đã tinh chỉnh GPT-J để học năm công cụ. Mặc dù phương pháp này có thể mang lại kết quả đầy hứa hẹn, nó tốn kém về mặt tính toán và thiếu khả năng thích ứng với các công cụ mới. Phương pháp thứ hai dựa vào học trong ngữ cảnh, nơi LLM học cách sử dụng công cụ thông qua các minh họa trong ngữ cảnh được cung cấp trong prompt. Phương pháp này cho phép LLM xử lý các công cụ mới được giới thiệu và thúc đẩy các ứng dụng thành công như LangChain và ChatGPT Plugin. Tuy nhiên, học trong ngữ cảnh đi kèm với những hạn chế độc đáo riêng của nó. Cụ thể, nó gặp khó khăn với hạn chế vốn có của độ dài ngữ cảnh, khiến việc minh họa các công cụ khổng lồ trong ngữ cảnh trở nên không thể. Ngoài ra, việc làm chủ các công cụ mới chỉ thông qua các ví dụ few-shot có thể là thách thức. Ví dụ, ngay cả các mô hình mới nhất như GPT-4 cũng gặp khó khăn khi xử lý các công cụ bất thường.

Trong bài báo này, chúng tôi giới thiệu ToolkenGPT, một giải pháp thay thế cho phép LLM làm chủ các công cụ khổng lồ mà không cần tinh chỉnh LLM nào, trong khi vẫn cho phép thích ứng nhanh với các công cụ mới. Ý tưởng chính của ToolkenGPT là biểu diễn mỗi công cụ như một token mới ("toolken") để tăng cường từ vựng. Cụ thể, mỗi công cụ được liên kết với một embedding được chèn vào đầu LLM như một embedding token từ thông thường. Trong quá trình tạo, một khi toolken được dự đoán, LLM tạm thời chuyển sang chế độ đặc biệt (thông qua prompting) để tạo ra các tham số đầu vào cho công cụ thực thi, và đưa các đầu ra trở lại vào quá trình tạo (xem Hình 1). Phương pháp này cung cấp một cách hiệu quả cho LLM để làm chủ các công cụ bằng cách chỉ học các embedding toolken nhẹ. Do đó, ToolkenGPT kết hợp điểm mạnh của cả mô hình fine-tuning và in-context learning trong khi tránh những hạn chế của chúng (Bảng 1): So với học trong ngữ cảnh chỉ có thể chứa một số lượng nhỏ công cụ và minh họa few-shot, ToolkenGPT cho phép các công cụ khổng lồ (bằng cách chỉ đơn giản chèn các toolken tương ứng vào từ vựng) và có thể sử dụng dữ liệu minh họa mở rộng để học các embedding toolken; Trái ngược với fine-tuning LLM, các embedding công cụ không chỉ yêu cầu chi phí đào tạo tối thiểu, mà còn cung cấp phương tiện thuận tiện để cắm vào các công cụ mới tùy ý bằng cách mở rộng từ vựng toolken.

Chúng tôi chứng minh tính linh hoạt và hiệu quả của ToolkenGPT trong việc tận dụng nhiều công cụ bên ngoài để giải quyết một tập hợp đa dạng các vấn đề, từ lý luận số học đến trả lời câu hỏi dựa trên kiến thức và tạo kế hoạch thể hiện. Trong các vấn đề lý luận số học phức tạp liên quan đến một số công cụ toán học (các phép toán số học như tìm ước chung lớn nhất), chúng tôi cho thấy ToolkenGPT có thể hiệu quả sử dụng những công cụ này trong quá trình lý luận, vượt trội hơn một số phương pháp phổ biến mới nhất, như Chain-of-Thought và ReAct. Đối với trả lời câu hỏi dựa trên kiến thức, ToolkenGPT chứa một số lượng đáng kể các API quan hệ (hơn 200) từ cơ sở kiến thức, do đó tạo điều kiện cho các dự đoán thực tế. Hơn nữa, chúng tôi áp dụng khung của chúng tôi vào việc lập kế hoạch nhiệm vụ cho các agent thể hiện, nơi một agent tương tác với môi trường sử dụng các công cụ, cụ thể là các hành động và đối tượng. Các phát hiện minh họa rằng phương pháp của chúng tôi cung cấp grounding tốt hơn bằng cách học các embedding toolken cho 58 hành động và đối tượng grounded so với các phương pháp học trong ngữ cảnh và giải mã chuyên biệt trước đó.

2 Các Công trình Liên quan
Fine-tuning LLM để sử dụng công cụ. Nghiên cứu ban đầu phụ thuộc nhiều vào fine-tuning để tăng cường LM với các công cụ. Trong những công trình này, LM chủ yếu được fine-tuned để sử dụng một hoặc một vài công cụ trong một lĩnh vực cụ thể. Ví dụ, retriever đã là một công cụ quan trọng để tăng cường LLM với các nguồn kiến thức bên ngoài. Các công trình nổi bật trong hướng này bao gồm REALM, RAG, và RETRO. Gần đây hơn, WebGPT đã fine-tuned GPT-3 trên các hành vi tìm kiếm web của con người để học cách sử dụng trình duyệt web. Với những tiến bộ trong LLM, cũng đã có sự quan tâm ngày càng tăng trong việc điều chỉnh những mô hình này trên một tập hợp các công cụ chung, bao gồm mô hình QA, máy tính, trình dịch, v.v.

2https://openai.com/blog/chatgpt-plugins

--- TRANG 3 ---
Các ví dụ về công trình bao gồm TALM và Toolformer. Tuy nhiên, fine-tuning LLM tốn kém và những LLM được điều chỉnh này gặp khó khăn trong việc tổng quát hóa cho các công cụ mới hoặc được cập nhật. ToolkenGPT học các embedding toolken nhẹ cho các công cụ mới, mà không cần bất kỳ tính toán gradient nào cho các tham số của LLM. Điều này cho phép thích ứng hiệu quả với các công cụ mới và duy trì chi phí bộ nhớ GPU tối thiểu để đào tạo các embedding toolken, với chi phí tương tự như suy luận LLM.

Học trong ngữ cảnh cho các công cụ. LLM thể hiện khả năng học trong ngữ cảnh mạnh mẽ, trở thành phương pháp phổ biến để sử dụng các công cụ bằng cách hiển thị mô tả công cụ và minh họa trong ngữ cảnh. Dựa trên ý tưởng này, các chuỗi lý luận có thể được tích hợp để giải quyết các vấn đề phức tạp hơn. Mô hình này đã tạo ra các sản phẩm công nghiệp phổ biến như plugin ChatGPT và Langchain, cùng với nhiều ứng dụng thành công trong các chủ đề nghiên cứu quan trọng. Ví dụ, một trình thông dịch mã có thể hiệu quả giải quyết những thiếu sót của LLM trong các phép toán ký hiệu. Hơn nữa, bằng cách gọi "các công cụ" có tác động đến thế giới ảo hoặc vật lý, LLM có khả năng hướng dẫn các agent thể hiện để hoàn thành các nhiệm vụ gia đình khác nhau. Những nỗ lực gần đây để sử dụng LLM như một bộ điều khiển để phối hợp nhiều mô hình neural cũng đạt được tiến bộ đầy hứa hẹn trong các nhiệm vụ lý luận đa phương thức. Tuy nhiên, tất cả các phương pháp dựa trên học trong ngữ cảnh đều gặp phải hiệu suất kém trong các tình huống phức tạp, nơi các công cụ không quen thuộc hoặc nhiều. Một công trình đồng thời, Li et al. đề xuất truy xuất các công cụ dựa trên text embedding của tài liệu của chúng, có thể giảm thiểu vấn đề đó. Tuy nhiên, ToolkenGPT khác biệt cơ bản so với phương pháp của họ, ở chỗ các embedding toolken có thể mã hóa ngữ nghĩa ngầm của các công cụ từ các minh họa mở rộng, điều này không bao giờ có thể được suy luận từ văn bản bề mặt (Một ví dụ cụ thể được hiển thị trong Hình 3). Ngoài ra, lưu ý rằng ToolkenGPT tương thích với các kỹ thuật prompting tiên tiến gần đây, ví dụ, Chain-of-Thought (CoT), để cải thiện hiệu suất LLM hơn nữa.

Điều chỉnh hiệu quả các mô hình ngôn ngữ lớn. Việc thích ứng các LLM đóng băng được đào tạo trước một cách hiệu quả cho các nhiệm vụ mới là một lĩnh vực nghiên cứu tích cực, dẫn đến sự gia tăng quan tâm đến các phương pháp fine-tuning hiệu quả tham số (PEFT). Ý tưởng là chỉ fine-tune một tập hợp con nhỏ các tham số của LLM trong khi đóng băng hầu hết các tham số của nó, có sự tương đồng với phương pháp embedding toolken của chúng tôi. Phần tham số nào để điều chỉnh là chìa khóa cho các phương pháp PEFT; ví dụ, Adapter chèn các lớp có thể đào tạo, BitFit điều chỉnh các tham số bias, prompt tuning thêm các tham số vào lớp embedding đầu vào, và LoRA học các ma trận hạng thấp trong các lớp dày đặc cụ thể, v.v. Tuy nhiên, các phương pháp PEFT hiện tại chưa được chứng minh phù hợp cho việc học công cụ hiệu quả, và việc sử dụng những phương pháp này trên các minh họa công cụ có thể không hiệu quả nắm bắt kiến thức công cụ mong muốn như ToolkenGPT làm. Theo hiểu biết tốt nhất của chúng tôi, chúng tôi là người đầu tiên khám phá các phương pháp điều chỉnh hiệu quả để dự đoán các công cụ như token cho việc học công cụ của các công cụ khổng lồ.

3 ToolkenGPT để Làm chủ Công cụ Khổng lồ
Trong phần này, chúng tôi trình bày ToolkenGPT, cho phép LLM học và sử dụng các công cụ khổng lồ để giải quyết vấn đề phức tạp mà không cần fine-tune mạnh LLM. Chúng tôi bắt đầu bằng việc giới thiệu nền tảng và ký hiệu của mô hình ngôn ngữ cho việc sử dụng công cụ. Thông thường, LLM mô hình hóa xác suất của một chuỗi các token từ s = (t1, t2, ..., tn) là P(s) = ∏ni P(ti|t<i), nơi mỗi token từ đến từ từ vựng của LLM, tức là ti ∈ V và t<i biểu thị chuỗi token từ một phần trước bước thứ i. Trong thực tế, người dùng thường đặt tiền tố của một chuỗi (được gọi là prompt) để điều hướng LLM tạo nội dung mong muốn, ví dụ, trả lời một câu hỏi. Đi sâu hơn một bước, phân phối của token tiếp theo được dự đoán là P(ti|t<i) = softmax(Wν · hi-1), nơi hi-1 ∈ Rd là trạng thái ẩn cuối cùng của ngữ cảnh hiện tại và Wν ∈ R|V|×d là ma trận embedding cho các token từ (cũng được gọi là đầu mô hình ngôn ngữ).

Cho một tập hợp các công cụ hữu ích T = {τ1, τ2, ...}, mục tiêu của chúng tôi là cho phép LLM gọi một tập hợp con của những công cụ này để giải quyết vấn đề phức tạp. Công thức linh hoạt của chúng tôi cho phép các công cụ đóng vai trò bằng cách trả về một số kết quả có thể giúp LLM với việc tạo văn bản (ví dụ tính toán) hoặc ảnh hưởng đến môi trường thế giới thực (ví dụ hành động robot). Để gọi một công cụ trong quá trình tạo, LLM đầu tiên cần chọn một công cụ và sau đó nhập các tham số. Trong các ví dụ chạy được hiển thị trong Hình 1, trong quá trình tạo câu trả lời ("chế độ lý luận"), một toán tử toán học square được chọn làm công cụ, và một toán hạng 16 được tạo làm tham số trong "chế độ công cụ". Một khi công cụ bên ngoài nhận được cuộc gọi, nó thực thi công cụ và trả về kết quả 256, trở lại "chế độ lý luận".

--- TRANG 4 ---
Độ dài cạnh tối đa của mỗi phần là 16 mét, vậy diện tích là <square>(16) Thực thi
Liverpool1findChế độ lý luận
Chế độ công cụ
                minh họaToken TừKB ToolkensRobot ToolkensMath ToolkensEmbeddings
squareGCDgrabwalkwinner_offather_of① chuyển đổi chế độsquare
256
 Hoàn thành tham số256(64, 48)GCD
square(16)Phân phối Token
→Câu hỏi: John có một khu vườn hình chữ nhật, có chiều dài 64 mét và chiều rộng 48 mét. Anh ấy muốn chia khu vườn thành các phần hình vuông giống hệt nhau, mỗi phần có diện tích lớn nhất có thể. Diện tích của mỗi phần là bao nhiêu?Trả lời: Độ dài cạnh tối đa của mỗi phần là 16 mét. Do đó, diện tích là _____
② gọi công cụ③ điền văn bản

Hình 1: Tổng quan về khung ToolkenGPT. Các embedding Toolken được thêm vào đầu mô hình ngôn ngữ như các token từ thông thường. Trong "chế độ lý luận" để giải quyết vấn đề, LLM tạo văn bản như bình thường, ngoại trừ việc bất kỳ toolken nào được cắm vào cũng được xem xét cho việc tạo token tiếp theo. Một khi toolken được dự đoán, (1) LLM chuyển sang "chế độ công cụ", cung cấp một vài minh họa về cùng công cụ để hoàn thành các tham số. Sau đó, (2) cuộc gọi công cụ được thực thi, và (3) kết quả được gửi trở lại văn bản để tiếp tục chế độ lý luận cho đến khi câu trả lời cuối cùng được tạo.

3.1 Tổng quan Khung
Ý tưởng cốt lõi của ToolkenGPT là rõ ràng công thức hóa các công cụ như token (gọi là "toolken"). Mỗi toolken được tham số hóa như một vector embedding toolken, và chúng tôi ký hiệu một tập hợp các embedding toolken như một ma trận, tức là Wτ ∈ R|T|×d. Giả sử chúng tôi đã đào tạo các embedding toolken (sẽ được mô tả trong Phần 3.2), trước tiên chúng tôi đưa ra tổng quan về khung của chúng tôi bằng cách giới thiệu cách nó hoạt động trong suy luận.

Như được hiển thị trong Hình 1, LLM ở chế độ lý luận theo mặc định, tạo token tiếp theo. Khung của chúng tôi cho phép LLM xem xét các token từ và toolken một cách thống nhất. Cụ thể, ma trận embedding công cụ được nối với Wν. Do đó, LLM dự đoán token tiếp theo với xác suất như sau:

P(ti|t<i) = softmax([Wν; Wτ] · hi-1) (1)

nơi token tiếp theo có thể là token từ hoặc toolken, tức là ti ∈ V ∪ T, và [;] là phép nối. Như chúng ta có thể thấy, công thức của chúng tôi về các công cụ như embedding toolken tự nhiên cho phép thích ứng nhanh các công cụ mới bằng cách mở rộng ma trận embedding toolken một cách dễ dàng.

Để thực thi một công cụ, LLM chuyển sang "chế độ công cụ" một khi toolken của nó được dự đoán là token tiếp theo (như được hiển thị trong "chuyển đổi chế độ" trong Hình 1), nhằm tạo ra các tham số cho công cụ. Cụ thể, LLM tạm dừng việc tạo và thêm ngữ cảnh hiện tại đã tạo vào một prompt khác. Prompt trong chế độ công cụ bao gồm các minh họa trong ngữ cảnh cho công cụ được dự đoán, hiển thị cách tạo ra các tham số công cụ bằng cách trích dẫn các cuộc gọi công cụ trong cú pháp đặc biệt của [tool](arguments). Sau đó LLM có thể theo mẫu trong các minh họa để hoàn thành các tham số của cuộc gọi công cụ hiện tại. Trái ngược với các phương pháp trước đó hoàn toàn dựa vào học trong ngữ cảnh cho việc học công cụ, khung của chúng tôi chỉ để lại công việc dễ dàng của việc hoàn thành tham số cho học trong ngữ cảnh. Bên cạnh đó, sẽ có không gian ngữ cảnh dồi dào cho các minh họa mở rộng của một công cụ duy nhất được chỉ định. Thiết kế này chia sẻ sự tương đồng với các phương pháp chia để trị cổ điển. Cuối cùng, các tham số được gửi đến công cụ được chỉ định để thực thi, và giá trị trả về được gửi trở lại văn bản trong chế độ lý luận.

3.2 Học Embedding Toolken
Khung của chúng tôi giữ các tham số LLM ban đầu đóng băng và giới thiệu chi phí đào tạo bổ sung tối thiểu với các embedding toolken, Wτ. Ma trận embedding này chứa các tham số duy nhất để tối ưu hóa, nhưng không giống như các phương pháp điều chỉnh LLM hiệu quả khác, ví dụ, prompt tuning hoặc prefix tuning, nó không yêu cầu các gradient chảy qua phần chính của các tham số LLM, dẫn đến đào tạo ổn định và hiệu quả hơn nhiều. Do đó, việc điều chỉnh các embedding toolken

--- TRANG 5 ---
duy trì bộ nhớ GPU gần như tương tự như suy luận LLM. Bất cứ khi nào một công cụ mới được thêm vào, embedding toolken có thể được mở rộng một cách thuận tiện và sau đó, việc đào tạo tiếp theo trên dữ liệu minh họa công cụ liên quan đến công cụ mới sẽ dần dần tinh chỉnh embedding của nó. Hơn nữa, không giống như các phương pháp học trong ngữ cảnh chỉ tiêu hóa một vài ví dụ làm tín hiệu đào tạo, ToolkenGPT có khả năng điều chỉnh các embedding toolken từ các minh họa khổng lồ.

Rút ra sự tương đồng với cách trẻ sơ sinh học một công cụ mới thông qua các minh họa từ người lớn, trong bài báo này, chúng tôi chủ yếu tập trung vào việc học các embedding toolken với các minh họa công cụ, có thể là dữ liệu đào tạo trong lĩnh vực hoặc dữ liệu tổng hợp được tạo bởi LLM (xem Phần 4.1 và Phần 4.2). Trước tiên chúng tôi mô tả định dạng của dữ liệu đào tạo và mục tiêu đào tạo và chúng tôi sử dụng cùng ví dụ từ Hình 1 để thể hiện cách nó có thể được sử dụng để đào tạo. Cụ thể, "diện tích là 256 feet vuông ..." có thể được token hóa thành một chuỗi token từ s = ("the", "area", "is", "2", "5", "6", "square", "feet", ...). Để chỉ ra khi nào dự đoán các toolken, chúng tôi cần một chuỗi song song trộn với các token từ và toolken, tức là s' = ("the", "area", "is", "[square]", "[N/A]", "[N/A]", "square", "feet", ...). Chuỗi con của ("2", "5", "6") trong s là nơi kết quả công cụ trả về nên điền vào, và chúng tôi chọn token đầu tiên tương ứng trong s' làm toolken cho cuộc gọi công cụ với các token sau được điền bằng [N/A], chỉ ra việc bỏ qua trong tính toán loss. Do đó, cho một tập dữ liệu bao gồm các chuỗi được ghép đôi D = {(s, s')}, mục tiêu đào tạo của ToolkenGPT là:

L(Wτ) = ∑(s,s')∈D ∑N i=1 -log P(t'i|t<i) 1t'i≠[N/A] (2)

nơi P(t'i|t<i) được định nghĩa trong Eq.(1), và 1t'i≠[N/A] là hàm chỉ thị báo hiệu chúng tôi bỏ qua các token [N/A] trong quá trình đào tạo. Do đó, quá trình đào tạo của chúng tôi phần lớn nhất quán với suy luận trong chế độ lý luận. Nghĩa là, để gọi một công cụ, công việc duy nhất cho LLM là dự đoán một toolken ở đầu, và sau đó giá trị trả về sẽ được điền trở lại văn bản. Ở đây, [N/A] được giới thiệu để bỏ qua việc tạo ra giá trị trả về của một cuộc gọi công cụ.

Có hai cách chính để có được dữ liệu được ghép đôi. Đầu tiên, một số tập dữ liệu cung cấp các cuộc gọi công cụ ground truth cùng với các chuỗi ngôn ngữ tự nhiên, ví dụ các sự thật trong KB hỗ trợ câu trả lời cho một câu hỏi (Phần 4.2), hoặc dấu vết tính toán để giải quyết một bài toán (Phần 4.1). Để sử dụng dữ liệu cho học có giám sát, chúng tôi tiền xử lý chúng để có được dữ liệu được ghép đôi cần thiết cho đào tạo như được mô tả trong đoạn trên. Thứ hai, chúng tôi khám phá việc tổng hợp các minh họa công cụ với LLM, chia sẻ ý tưởng tương tự với self-instruct. Một cách giải thích trực quan về quá trình này là chưng cất kiến thức bên trong LLM vào các embedding toolken mới. Cụ thể, chúng tôi có thể prompt LLM với tài liệu công cụ và một vài minh họa với cú pháp đặc biệt chỉ ra việc gọi công cụ, ví dụ, Thủ đô của Mỹ là <capital>("U.S.")="Washington D.C." Dựa trên điều đó, LLM có thể tạo ra một số trường hợp sử dụng mới sử dụng công cụ đã cho và trích dẫn cuộc gọi công cụ với cùng cú pháp. Sau đó chúng tôi có thể dễ dàng xác định vị trí các cuộc gọi công cụ và xử lý dữ liệu thành dữ liệu được ghép đôi để đào tạo.

4 Thí nghiệm
Trong phần này, chúng tôi áp dụng ToolkenGPT vào ba ứng dụng khác biệt được đặc trưng bởi các tình huống sử dụng công cụ có ý nghĩa: các công cụ số học cho lý luận số học, API cơ sở dữ liệu cho trả lời câu hỏi dựa trên kiến thức, và các hành động robot cho tạo kế hoạch thể hiện. Chúng tôi tập trung vào cách các phương pháp có thể gọi chính xác các công cụ và cách thành công chúng có thể giải quyết các nhiệm vụ. Các thí nghiệm của chúng tôi cho thấy ToolkenGPT có thể hiệu quả làm chủ các công cụ khổng lồ trong khi tận dụng chúng để giải quyết các vấn đề phức tạp với hiệu suất được cải thiện, nhất quán tốt hơn so với các kỹ thuật prompting tiên tiến khác nhau.

4.1 Lý luận Số học
LLM thường gặp khó khăn với các nhiệm vụ toán học vì các mô hình được thiết kế vốn dĩ cho ước lượng xác suất hơn là các phép toán ký hiệu. Trong phần này, chúng tôi nhằm đánh giá khả năng học công cụ của ToolkenGPT, so với học công cụ trong ngữ cảnh (ví dụ, ReAct). Trước tiên chúng tôi chứng minh rằng ToolkenGPT nhất quán khớp hoặc vượt trội so với hiệu suất của học trong ngữ cảnh với sự có sẵn của bốn hàm số học cơ bản (+, -, ×, ÷). Hơn nữa, để đánh giá khả năng xử lý công cụ trong các bài toán toán học phức tạp hơn, chúng tôi bao gồm nhiều công cụ có sẵn hơn, tức là một tập hợp mở rộng (13) các hàm, và tạo một tập dữ liệu tổng hợp. Kết quả cho thấy ToolkenGPT vượt trội đáng kể so với các baseline bằng cách chỉ đào tạo trên dữ liệu tổng hợp. Lưu ý rằng trọng tâm của chúng tôi không phải là đạt được độ chính xác state-of-the-art; Thay vào đó, thí nghiệm được thiết kế để đánh giá khả năng học công cụ trong bối cảnh nơi các công cụ nhất định có sẵn.

--- TRANG 6 ---
Bảng 2: Kết quả trên các tập dữ liệu GSM8K-XL và FuncQA. Các số trong ngoặc đơn chỉ ra có bao nhiêu công cụ có sẵn. Đối với GSM8K-XL và tập dữ liệu FuncQA one, độ chính xác được đánh giá dựa trên khớp chính xác (số thực được làm tròn đến hai chữ số thập phân). Trong FuncQA multi, chúng tôi cho phép sai số 0.1% để tính đến các lỗi tiềm ẩn ở mỗi bước của lý luận nhiều bước.

Phương pháp | GSM8K-XL (4) | FuncQA (13)
One-Hop | Multi-Hops
0-shot ChatGPT | 0.17 | 0.55 | 0.09
CoT [65] | 0.18 | 0.20 | 0.03
ReAct [69] | 0.32 | 0.57 | 0.06
ToolkenGPT (Của chúng tôi) | 0.33 | 0.73 | 0.15

Tập dữ liệu. Để đánh giá khả năng thông thạo học công cụ trong lý luận số học một cách toàn diện, chúng tôi tuyển chọn hai tập dữ liệu thử nghiệm mới: (1) GSM8K-XL, một phiên bản nâng cao của tập dữ liệu GSM8K hiện có. GSM8K là một tập dữ liệu các bài toán từ toán học cấp tiểu học đa dạng về mặt ngôn ngữ, liên quan đến việc thực hiện một chuỗi tính toán sử dụng 4 phép toán số học cơ bản (+, -, ×, ÷) để đạt được câu trả lời cuối cùng. Trong tập dữ liệu GSM8K ban đầu, các số cho tính toán thường nhỏ, có thể ít thách thức hơn đối với các LLM mạnh mẽ gần đây. Vì vậy trong tập thử nghiệm, chúng tôi phóng đại các số để tăng độ khó tính toán cho LLM, dẫn đến tập dữ liệu GSM8K-XL, có 568 trường hợp thử nghiệm với các số lớn hơn nhiều. (2) FuncQA là một tập dữ liệu tổng hợp chúng tôi tạo ra để tăng độ phức tạp của các bài toán toán học liên quan đến nhiều công cụ số học hơn, phục vụ như một benchmark thách thức hơn nhiều để kiểm tra khả năng học công cụ của mô hình. Cụ thể, tập dữ liệu này yêu cầu ít nhất 13 toán tử (ví dụ, power, sqrt, lcm) để giải quyết, và nó thách thức đối với cả con người và LLM để giải quyết mà không có máy tính bên ngoài. Hơn nữa, FuncQA được phân loại thành hai tập hợp con: 68 câu hỏi một bước (FuncQA one) có thể giải quyết chỉ với một phép toán, và 60 câu hỏi nhiều bước (FuncQA multi) yêu cầu một vài bước lý luận.

Để đào tạo các embedding toolken được sử dụng trong GSM8K-XL, chúng tôi tiền xử lý tập đào tạo ban đầu của GSM8K có chú thích tính toán như được mô tả trong Phần 3.2. Chúng tôi có được 6.054 ví dụ, trong đó 1.000 được phân bổ để xác thực, và 5.054 cho dữ liệu đào tạo. Đối với tập dữ liệu FuncQA, chúng tôi prompt ChatGPT để tạo ra một số mẫu QA một bước cho mỗi toán tử, và sau đó ngẫu nhiên gán giá trị cho các mẫu. Quá trình này tạo ra 47 điểm dữ liệu đào tạo và 3 điểm dữ liệu xác thực cho mỗi toán tử, dẫn đến tổng cộng 611 mẫu để đào tạo và 39 mẫu để xác thực.

Phương pháp so sánh. Chúng tôi đào tạo các embedding toolken cho mỗi toán tử toán học có sẵn như được mô tả trong Phần 3.2. Trong quá trình suy luận, chúng tôi prompt LLM với 4-shot Chain-of-Thought ví dụ để tăng cường khả năng lý luận của LLM. Các baseline sau được đánh giá để so sánh: (1) 0-shot ChatGPT là phương pháp đơn giản yêu cầu LLM trả lời một câu hỏi. Không có ví dụ nào sẽ được cung cấp trong ngữ cảnh và các công cụ không có sẵn. Chúng tôi sử dụng ChatGPT làm LLM cơ sở trong thí nghiệm của chúng tôi. Baseline này đo lường khả năng của LLM để trả lời các bài toán lý luận số học phức tạp với khả năng lý luận và tính toán riêng của nó. (2) Chain-of-thoughts (CoT) là một kỹ thuật prompting tiên tiến hơn. Trong phương pháp này, một loạt các prompt được kết nối cẩn thận được tạo ra để hướng dẫn LLM thông qua một quá trình lý luận từng bước. Các chuỗi lý luận ví dụ giống như những cái chúng tôi sử dụng cho ToolkenGPT, nhưng không có hàm nào có sẵn. (3) ReAct kết hợp lý luận và công cụ bằng cách prompt LLM để tạo ra các dấu vết lý luận bằng lời và cuộc gọi công cụ một cách xen kẽ. Cụ thể, thay vì chỉ cung cấp các chuỗi lý luận như "... Chi phí là 50*3.2=160", ReAct tích hợp cú pháp đặc biệt để gọi các toán tử, ví dụ "... Chi phí là 50*3.2=<multiply>(50,3.2)=160". Một khi cú pháp được phát hiện trong quá trình suy luận, công cụ sẽ được gọi để tính toán kết quả. Chúng tôi sử dụng các ví dụ chuỗi lý luận giống như trong cả CoT và ToolkenGPT, với chỉ những khác biệt nhỏ trong cú pháp gọi công cụ. LLaMA-33B được sử dụng làm LLM cho tất cả các cài đặt khác ngoài prompting zero-shot. Thêm chi tiết thí nghiệm được mô tả trong Phụ lục A.

Phân tích kết quả. Bảng 2 hiển thị hiệu suất của tất cả các phương pháp trên các tập dữ liệu GSM8K-XL và FuncQA. Trên tập dữ liệu GSM8K-XL, 0-shot ChatGPT và few-shot learning với CoT gặp khó khăn trong việc tính toán số lớn mà không có sự giúp đỡ của công cụ, trong khi ReAct và ToolkenGPT quản lý để tăng độ chính xác một cách nhất quán với biên độ lớn. Nói chung, cả hai phương pháp đều có thể gọi các công cụ đúng khi cần thiết, vì bộ công cụ chỉ bao gồm bốn toán tử cơ bản. Tuy nhiên, đối với cả tập dữ liệu FuncQA one và FuncQA multi, việc học gọi các công cụ áp dụng trở nên thách thức đối với ReAct khi số lượng công cụ tăng lên. Trong ReAct, mặc dù tất cả các công cụ được liệt kê ở đầu prompt, việc bao gồm các minh họa của mọi công cụ trong ngữ cảnh hạn chế là không khả thi (Trong thí nghiệm của chúng tôi, chúng tôi cung cấp 4 ví dụ bao gồm 5 minh họa công cụ). Kết quả là, ReAct dễ bị thiếu cuộc gọi công cụ, thực hiện cuộc gọi công cụ sai, và dự đoán tham số sai, đặc biệt đối với các công cụ không được minh họa trong ngữ cảnh. ToolkenGPT vượt trội hơn tất cả các baseline trong cả kịch bản một bước và nhiều bước, thể hiện khả năng học công cụ vượt trội khi có nhiều công cụ. Điều quan trọng cần lưu ý là mặc dù các embedding toolken được đào tạo chỉ sử dụng dữ liệu tổng hợp một bước, và không có bất kỳ ví dụ CoT nào, chúng vẫn quản lý để nâng cao hiệu suất trong ngữ cảnh bài toán nhiều bước và có thể được tích hợp hiệu quả với prompting CoT. Điều này ngụ ý một mức độ tổng quát hóa của các embedding toolken, đây là một thuộc tính rất mong muốn làm giảm các yêu cầu của dữ liệu đào tạo trong lĩnh vực.

4.2 Trả lời Câu hỏi Dựa trên Kiến thức
LLM được biết đến là thường mắc lỗi thực tế và ảo giác vì kiến thức hạn chế của chúng. Việc trang bị chúng với quyền truy cập vào cơ sở kiến thức (KB) đã là một hướng nghiên cứu đầy hứa hẹn để giảm ảo giác của chúng. Chúng tôi công thức hóa việc truy cập KB như các API truy vấn cơ sở dữ liệu. Do đó, mỗi truy vấn quan hệ có thể được coi như một công cụ mà tham số đầu vào là một thực thể chủ đề, và đầu ra là thực thể đuôi tương ứng. Một ví dụ cuộc gọi công cụ là "P1346(2005-06 FA CUP)→LIVERPOOL F.C." "P1346" là một định danh quan hệ trong Wikidata, đại diện cho người chiến thắng của một cuộc thi hoặc sự kiện tương tự (được gọi là winner_of dưới đây để dễ đọc). Trong phần này, chúng tôi cho thấy ToolkenGPT có thể chính xác truy vấn một cơ sở kiến thức lớn gồm tới 234 công cụ (quan hệ). Chúng tôi tiếp tục cho thấy rằng ngay cả chỉ với dữ liệu tổng hợp (như được mô tả trong Phần 3.2 và giải thích dưới đây), chúng tôi có thể đào tạo các embedding toolken mạnh mẽ vượt trội hơn các phương pháp học công cụ phổ biến.

Tập dữ liệu. KAMEL là một tập dữ liệu trả lời câu hỏi được xây dựng với các sự thật trong Wikidata. Phù hợp với ToolFormer, sử dụng phiên bản trước đó của nó làm benchmark để đánh giá việc sử dụng công cụ, chúng tôi áp dụng KAMEL để đánh giá việc sử dụng các công cụ truy vấn KB. KAMEL chứa kiến thức về 243 quan hệ từ Wikidata, mỗi quan hệ được liên kết với một mẫu câu hỏi (ví dụ winner_of: "Ai là người chiến thắng của [S]?") để biến một sự thật trong Wikidata thành một câu hỏi. Chúng tôi có tổng cộng 234 công cụ cho tập dữ liệu này. Để phân tích hiệu suất được cung cấp với số lượng công cụ khác nhau, chúng tôi tạo ra bốn tập hợp con bằng cách lấy mẫu từ tập thử nghiệm ban đầu. Mỗi tập hợp con bao gồm các câu hỏi liên quan đến số lượng quan hệ khác nhau, tương ứng với 30, 60, 100, và 234. Kích thước của mỗi tập hợp con là 500.

Hình 2: Hiệu suất của ToolkenGPT và các baseline trên 4 bộ thử nghiệm liên quan đến số lượng công cụ khác nhau (quan hệ) từ KAMEL. ICL là viết tắt của In-context Learning. Do giới hạn độ dài ngữ cảnh của 2048 token, chúng tôi liệt kê các mô tả và minh họa của tối đa 30 quan hệ cho ICL và tối đa 60 mô tả quan hệ cho ICL (desc).

Phương pháp so sánh. Chúng tôi thiết lập hai biến thể khác nhau của khung của chúng tôi. (1) ToolkenGPT (sup): Chúng tôi lấy mẫu 200 ví dụ mỗi quan hệ từ tập đào tạo của KAMEL và đào tạo các embedding toolken thông qua học có giám sát. Cài đặt này đại diện cho các tình huống thế giới thực nơi có đủ dữ liệu đào tạo trong lĩnh vực. (2) ToolkenGPT (syn): Trong một cài đặt thách thức hơn nơi chúng tôi giả định dữ liệu đào tạo trong lĩnh vực không có sẵn, chúng tôi sử dụng mô tả văn bản của mỗi quan hệ để tổng hợp dữ liệu đào tạo với ChatGPT, ví dụ "Giải Nobel Hòa bình năm 2020 được trao cho Chương trình Lương thực Thế giới Liên Hợp Quốc vì những nỗ lực...", nơi cuộc gọi công cụ cơ bản là winner_of(NOBEL PEACE PRIZE IN 2020)→UNITED NATIONS WORLD FOOD PROGRAMME. Trung bình, 40 ví dụ được sử dụng để đào tạo mỗi embedding toolken.

Chúng tôi giới thiệu các baseline sau để so sánh: (1) Prompting là một phương pháp đơn giản trả lời các câu hỏi với kiến thức nội bộ của LLM. Chúng tôi đóng khung mỗi câu hỏi trong prompt "Question: [QUESTION] \nThe answer is" và yêu cầu LLM tiếp tục câu. (2) In-context Learning (ICL) là một phương pháp tiêu chuẩn để tăng cường LLM với các công cụ như được giới thiệu trong Phần 2. Trước khi hỏi câu hỏi, chúng tôi liệt kê các minh họa công cụ và mô tả của tất cả các công cụ có sẵn. Các minh họa được hiển thị trong một cú pháp cụ thể để LLM có thể tạo ra theo kiểu tương tự để được phân tích. Một ví dụ minh họa cho winner_of là "Question: Who is the winner of 2005-06 FA Cup?\nAnswer: The answer is <winner_of>(2005-06 FA Cup)=Liverpool F.C." Trong một khảo sát gần đây, cài đặt này được gọi là "few-shot". (3) In-context Learning (desc) là một thực hành phổ biến khác để tăng cường LLM với các công cụ. Các mô tả của tất cả các công cụ có sẵn sẽ được cung cấp trong ngữ cảnh, nhưng các minh họa của chúng không được hiển thị trực tiếp. Thay vào đó, chúng tôi hiển thị 8 minh họa của các công cụ không được bao gồm trong tập hợp con thử nghiệm để thông báo cho LLM về định dạng cuộc gọi công cụ. Cài đặt này được gọi là "zero-shot" trong Qin et al. Mô hình cơ sở cho tất cả các phương pháp là LLaMA-13B. Thêm chi tiết thí nghiệm được mô tả trong Phụ lục B.

Phân tích kết quả. Chúng tôi hiển thị kết quả thí nghiệm trên 4 bộ thử nghiệm liên quan đến số lượng quan hệ khác nhau trong Hình 2. Lưu ý rằng số lượng quan hệ liên quan là số lượng công cụ chúng ta có thể sử dụng. Đối với tất cả các bộ thử nghiệm, độ chính xác của Prompting khoảng 20%, cho thấy LLM vẫn gặp khó khăn trong việc lưu trữ các sự thật chính xác trong các tham số của chúng và cần thiết phải tăng cường chúng với cơ sở kiến thức. ToolkenGPT (sup) đạt được kết quả cao nhất với biên độ lớn, cho thấy rằng việc học các embedding toolken là một phương pháp hiệu quả khi có dữ liệu đào tạo trong lĩnh vực khổng lồ. Ngược lại, mặc dù học trong ngữ cảnh cũng thấy dữ liệu đào tạo trong lĩnh vực trong ngữ cảnh, nó vẫn bị nhầm lẫn về việc gọi công cụ nào. Hơn nữa, giới hạn độ dài ngữ cảnh dẫn đến sụt giảm hiệu suất mạnh khi có hơn 30 công cụ để sử dụng. Sự thất bại trong kịch bản nhiều công cụ tiết lộ hạn chế cơ bản của mô hình học trong ngữ cảnh. ToolkenGPT (syn) cũng vượt trội hơn tất cả các baseline khác trong tất cả các tập hợp con, mà không thấy bất kỳ dữ liệu đào tạo trong lĩnh vực nào. Dữ liệu đào tạo tổng hợp, thường có phong cách biểu đạt rất khác so với tập dữ liệu, vẫn giúp LLM hiểu những quan hệ này.

Thành công này phản ánh tính linh hoạt của khung của chúng tôi có thể được áp dụng ngay cả khi không có dữ liệu đào tạo trong lĩnh vực. Học trong ngữ cảnh (desc) thường thất bại trong nhiệm vụ này, vì LLM gặp khó khăn trong việc ghi nhớ các mô tả văn bản được hiển thị trong ngữ cảnh và ánh xạ chúng với các định danh quan hệ. Kết quả cung cấp thêm bằng chứng cho phát hiện trước đó rằng LLM gặp trouble sử dụng các công cụ không quen thuộc. Dựa trên quan sát này, hợp lý để suy đoán rằng LLM chủ yếu nhớ lại các công cụ từ định danh của chúng thay vì thực sự học sử dụng công cụ từ mô tả của chúng.

4.3 Tạo Kế hoạch Thể hiện
Gần đây, đã có nhiều nỗ lực nghiên cứu để sử dụng LLM như bộ điều khiển của các agent thể hiện. Bất chấp thành công ban đầu của việc prompting LLM, việc dạy LLM về một môi trường và cho phép chúng đưa ra các dự đoán grounded vẫn là thách thức. Như được thảo luận trong Mialon et al., các công cụ thu thập thông tin bổ sung (ví dụ công cụ toán học hoặc KB) và các công cụ có tác động đến thế giới vật lý (ví dụ các hành động được thực hiện bởi các agent thể hiện) có thể được gọi theo kiểu tương tự bởi LLM. Trong phần này, chúng tôi chứng minh cách khung của chúng tôi cũng có thể được áp dụng vào việc tạo kế hoạch cho các agent thể hiện. So với các phương pháp trước đó prompt LLM, ToolkenGPT của chúng tôi có thể hiểu môi trường tốt hơn bằng cách học các embedding toolken cho hành động và đối tượng agent.

Tập dữ liệu. VirtualHome là một nền tảng mô phỏng cho các hoạt động gia đình điển hình, và cơ sở kiến thức ActivityPrograms bao gồm nhiều nhiệm vụ với các kế hoạch có thể thực thi trong VirtualHome. Chúng tôi rút ra một tập hợp con 297 nhiệm vụ từ ActivityPrograms.

Cụ thể, đối với mỗi nhiệm vụ, mô hình được đưa ra một mục tiêu cấp cao (ví dụ "Read book"), một hướng dẫn chi tiết (ví dụ "I would go lie down in my bed and open the book and start reading.", và một mô tả về môi trường, bao gồm trạng thái ban đầu của agent, và danh sách đối tượng của môi trường (ví dụ "I am in ['home_office']. The objects I can manipulate are ['mail', 'freezer', 'television', ..., 'novel']". Mô hình được mong đợi xuất ra một kế hoạch có thể thực thi, là một danh sách có thứ tự của các hướng dẫn động từ-đối tượng (ví dụ "[FIND] <novel>"). Mỗi nhiệm vụ đi kèm với một đồ thị trạng thái ban đầu và cuối cùng, cho phép xác minh các kế hoạch được tạo với trình mô phỏng và so sánh trạng thái cuối cùng kết quả với ground truth. Chúng tôi chia tập dữ liệu thành một tập đào tạo 247 nhiệm vụ và một tập thử nghiệm 50 nhiệm vụ, với tổng cộng 25 động từ và 32 đối tượng được sử dụng trong tập dữ liệu.

Phương pháp so sánh. Chúng tôi xem xét tất cả các hành động và đối tượng trong VirtualHome như các công cụ. Với một hàm [END] bổ sung chỉ ra kết thúc của một kế hoạch, chúng tôi có tổng cộng 58 toolken. Đối với tập dữ liệu này, chúng tôi không cần quá trình tạo tham số được mô tả trong Hình 1 vì các công cụ không nhận tham số. Trong quá trình suy luận, ToolkenGPT luân phiên tạo ra các toolken hành động và toolken đối tượng, và kết thúc với toolken [END]. Các embedding toolken được đào tạo trên tập đào tạo.

--- TRANG 9 ---
Bảng 3: Kết quả trên VirtualHome. Grounding có nghĩa là tỷ lệ các script trong đó tất cả các hành động và đối tượng có thể được grounded với môi trường. Executable có nghĩa là tỷ lệ các script có thể được thực thi trong VirtualHome mà không vi phạm bất kỳ quy tắc nào. Success có nghĩa là tỷ lệ các script dẫn đến trạng thái cuối cùng đúng. Success (R) là một biến thể thoải mái có nghĩa là tỷ lệ các script đã đạt được trạng thái cuối cùng đúng, nhưng không nhất thiết kết thúc với nó.

Phương pháp | Grounding | Executable | Success | Success (R)
In-context Learning | 0.74 | 0.42 | 0.20 | 0.30
+ Translation [25] | 1.00 | 0.52 | 0.24 | 0.32
+ Grounded Decoding [27] | 1.00 | 0.66 | 0.38 | 0.42
ToolkenGPT (Của chúng tôi) | 1.00 | 0.82 | 0.68 | 0.70

Chúng tôi so sánh phương pháp của chúng tôi với các baseline sau: (1) In-context Learning prompt LLM và phân tích đầu ra của nó như kế hoạch. LLM được hiển thị với danh sách hành động, 3 kế hoạch minh họa, và một nhiệm vụ mới với mục tiêu, mô tả chi tiết, và mô tả môi trường của nó. Phương pháp này là cơ sở của hầu hết các phương pháp gần đây áp dụng LLM vào AI thể hiện. (2) Translation: Để tránh các kế hoạch bao gồm các hành động hoặc đối tượng không có sẵn, Huang et al. đề xuất sử dụng một mô hình dịch để dịch việc tạo của LLM thành các hướng dẫn được phép. Theo Huang et al., chúng tôi sử dụng SentenceRoBERTa-large và dịch các hành động hoặc đối tượng thành những cái có sẵn với độ tương đồng cosine cao nhất. (3) Grounded Decoding là một phương pháp grounding giai đoạn giải mã gần đây. Token tiếp theo được dự đoán xem xét cả logit LLM và "các hàm grounded". Cụ thể, chúng tôi áp dụng hàm grounding affordance, khuyến khích LLM tạo ra các hành động và đối tượng hợp lệ. Chúng tôi không xem xét các phương pháp trước đó fine-tune toàn bộ mô hình ngôn ngữ một cách mạnh mẽ. Mô hình cơ sở của tất cả các phương pháp là LLaMA-13B. Thêm chi tiết thí nghiệm được mô tả trong Phụ lục C.

Công việc
Đi đến văn phòng, ngồi ở bàn, bật máy tính, nhập mật khẩu, mở ứng dụng và bắt đầu làm việc
[WALK] <home_office>
[WALK] <desk>
[FIND] <desk>
[SIT] <desk>

ToolkenGPT Translation [WALK] <home_office>
[WALK] <chair>
[FIND] <chair>
[SIT] <chair>
... lỗi: bàn không thể ngồi được!

Hình 3: Nghiên cứu trường hợp trên VirtualHome. ToolkenGPT dự đoán một script thành công trong khi các baseline khác thất bại trong việc tạo ra script có thể thực thi do hiểu sai hành động SIT.

Phân tích kết quả. Chúng tôi liệt kê kết quả trong Bảng 3. Mặc dù tất cả các hành động và đối tượng hợp lệ được liệt kê rõ ràng trong ngữ cảnh cho LLM sử dụng In-context Learning, đôi khi nó thất bại trong việc ground dự đoán của mình thành các hướng dẫn được phép. Ngay cả khi các hành động và đối tượng hợp lệ, chúng thường vi phạm quy tắc vật lý trong VirtualHome, dẫn đến tỷ lệ thành công thấp. Chúng tôi nhận thấy rằng trong khi hầu hết các kế hoạch được tạo với In-context Learning xuất hiện hợp lý đối với con người, chúng không được grounded với môi trường cụ thể của VirtualHome. Translation giúp giải quyết một số vấn đề grounding nông, ví dụ [tv]→[television], trong khi Grounded Decoding tiếp tục cải thiện tỷ lệ thực thi và thành công bằng cách xem xét grounding sớm hơn trong giai đoạn giải mã. Mặc dù những phương pháp này đảm bảo tất cả các kế hoạch được grounded, không phương pháp nào cải thiện đáng kể hiểu biết của LLM về các hành động và đối tượng, dẫn đến tỷ lệ thực thi và thành công không đạt yêu cầu. ToolkenGPT không chỉ dự đoán các hành động và đối tượng hợp lệ một cách tự nhiên bởi thiết kế của nó, mà còn đạt được tỷ lệ thành công cao nhất bằng cách học các embedding toolken từ nhiều nhiệm vụ đào tạo hơn. Một ví dụ cụ thể được hiển thị trong Hình 3 để minh họa sự khác biệt: Tất cả các baseline dự đoán [SIT] <desk>, có lẽ được hướng dẫn bởi mô tả "sit at desk", nhưng trong VirtualHome [SIT] đề cập đến "sit on", và một cái bàn được coi là không thể ngồi được. ToolkenGPT là cái duy nhất thành công học quy tắc này từ các minh họa và thay vào đó dự đoán [SIT] <chair>.

4.4 Phân tích
Chi phí Tính toán. Chúng tôi tiến hành thí nghiệm để so sánh ToolkenGPT với fine-tuning, cụ thể sử dụng LoRA, về hiệu quả tính toán và hiệu suất. Do chi phí của fine-tuning LLM, chúng tôi triển khai cả hai phương pháp trên LLaMA-7B. Kết quả được liệt kê trong Bảng 4.

Fine-tuning LLM dẫn đến hiệu suất hơi tốt hơn so với ToolkenGPT trên FuncQA. Mặc dù chúng tôi áp dụng LoRA, được biết đến về hiệu quả, thời gian tiêu thụ cho fine-tuning vượt quá

--- TRANG 10 ---
Bảng 4: So sánh giữa ToolkenGPT và fine-tuning (LoRA) về chi phí đào tạo và hiệu suất trên tập dữ liệu FuncQA. Cả hai phương pháp đều dựa trên Llama-7B.

Phương pháp | One-hop | Multi-hop | Tài nguyên Tính toán | Thời gian Đào tạo
ReAct | 0.40 | 0.03 | - | -
Prompting | 0.10 | 0.00 | - | -
Fine-tune w/ LoRA [23] | 0.62 | 0.07 | 8 ×A100 (80G) | 40 phút
ToolkenGPT | 0.55 | 0.06 | 1 ×RTX3090 (24G) | 2 phút

Bảng 5: Nghiên cứu ablation trên tập dữ liệu FuncQA với LLaMA-30B.

Phương pháp | One-hop | Multi-hop
ReAct | 0.57 | 0.06
+ Tool mode | 0.60 | 0.07
ToolkenGPT | 0.73 | 0.15

Bảng 6: ToolkenGPT với các cấu hình khác nhau của dữ liệu đào tạo trên KAMEL.

# Ví dụ | Synthetic | Supervised
10 | 0.36 | 0.56
20 | 0.46 | 0.90
40 | 0.52 | 0.95

đáng kể khi so với việc đào tạo các embedding toolken. Cũng đáng chú ý rằng ToolkenGPT có các lợi ích bổ sung khác ngoài hiệu quả (Bảng 1), đặc biệt là plug-and-play của các công cụ khổng lồ, nhờ vào các tham số tách rời cho các công cụ khác nhau.

Nghiên cứu Ablation. Thiết kế của ToolkenGPT có lợi cho cả việc lựa chọn công cụ và hoàn thành tham số (chế độ công cụ trong Hình 1). Để hiểu đóng góp tương ứng của chúng đối với hiệu suất, chúng tôi tiếp tục triển khai một baseline kết hợp prompting kiểu ReAct và chương trình con của hoàn thành tham số (chế độ công cụ). Trong chế độ công cụ, LLM được prompt với các minh họa chỉ sử dụng công cụ đã chọn, sẽ cung cấp kiến thức liên quan hơn so với prompt ReAct cho việc hoàn thành tham số. Như được hiển thị trong Bảng 5, việc thêm chế độ công cụ thực sự có thể cải thiện phương pháp prompting ReAct vanilla bằng cách nâng cao độ chính xác của việc hoàn thành tham số. Tuy nhiên, ToolkenGPT vẫn vượt trội hơn baseline được cải thiện này với biên độ lớn, chỉ ra rằng các embedding toolken hiệu quả giúp LLM quyết định khi nào và công cụ nào để gọi.

Dữ liệu Đào tạo. Trong phần này, chúng tôi khám phá các hiệu ứng của dữ liệu đào tạo đối với việc học các embedding toolken. Chúng tôi chọn mở rộng các thí nghiệm của chúng tôi trên KAMEL (Phần 4.2), vì có hai nguồn dữ liệu đào tạo khác nhau và dễ dàng xử lý hoặc tổng hợp thêm dữ liệu. Cụ thể, chúng tôi lấy mẫu 10/20/40 ví dụ đào tạo của mỗi công cụ cho cả ToolkenGPT (sup) và ToolkenGPT (syn), và báo cáo độ chính xác trên tập thử nghiệm liên quan đến 30 công cụ.

Kết quả được tóm tắt trong Bảng 6. Dưới cùng ngân sách kích thước dữ liệu, đào tạo với dữ liệu có giám sát dẫn đến hiệu suất tốt hơn. Mặc dù chúng tôi không quan sát các lỗi rõ ràng trong hầu hết các instance dữ liệu tổng hợp, khoảng cách phân phối giữa dữ liệu tổng hợp và tập thử nghiệm có thể ngăn cản embedding toolken hoạt động tốt. Một tập đào tạo lớn hơn có lợi cho hiệu suất đối với cả hai nguồn dữ liệu.

5 Kết luận
Chúng tôi đã trình bày ToolkenGPT, một phương pháp mới để tăng cường LLM đóng băng với các công cụ bên ngoài khổng lồ mà không cần fine-tuning đắt đỏ. Phương pháp của chúng tôi giới thiệu khái niệm embedding toolken cho mỗi công cụ, cho phép LLM gọi và sử dụng các công cụ khác nhau dễ dàng như tạo ra các token từ. Phương pháp của chúng tôi vượt qua các hạn chế của các mô hình fine-tuning và in-context learning hiện tại, cho phép LLM chứa một tập hợp công cụ lớn hơn nhiều và sử dụng dữ liệu minh họa mở rộng để học các embedding toolken. Trên một loạt các nhiệm vụ, từ lý luận số học, trả lời câu hỏi dựa trên kiến thức, đến tạo kế hoạch thể hiện, chúng tôi quan sát được sự nâng cao đáng kể trong hiệu suất LLM với sự giúp đỡ của các embedding toolken. Quan trọng hơn, ToolkenGPT có thể nhanh chóng thích ứng và tận dụng các công cụ mới, chứng minh khả năng của nó để theo kịp với cảnh quan luôn phát triển của các công cụ khổng lồ. Chúng tôi mong đợi nghiên cứu tương lai học các embedding toolken mạnh mẽ không chỉ từ dữ liệu minh họa, mà còn từ các hình thức kinh nghiệm phong phú khác, như mô tả công cụ và hồ sơ đầu vào-đầu ra. Chúng tôi cũng quan tâm đến việc khám phá sự tích hợp của các embedding toolken với các kỹ thuật lập kế hoạch tiên tiến gần đây, với mục tiêu phát triển một agent tự động để giải quyết các vấn đề thế giới thực phức tạp.

--- TRANG 11 ---
Lời cảm ơn
Dự án này được hỗ trợ một phần bởi DARPA ECOLE HR00112390063.

Tài liệu tham khảo
[1] Razvan Azamfirei, Sapna R Kudchadkar, và James Fackler. Large language models and the perils of their hallucinations. Critical Care, 27(1):1–2, 2023.

[2] Michael Bommarito II và Daniel Martin Katz. Gpt takes the bar exam. arXiv preprint arXiv:2212.14402, 2022.

[3] Sebastian Borgeaud, Arthur Mensch, Jordan Hoffmann, Trevor Cai, Eliza Rutherford, Katie Millican, George Bm Van Den Driessche, Jean-Baptiste Lespiau, Bogdan Damoc, Aidan Clark, et al. Improving language models by retrieving from trillions of tokens. In International conference on machine learning, pages 2206–2240. PMLR, 2022.

[4] Anthony Brohan, Yevgen Chebotar, Chelsea Finn, Karol Hausman, Alexander Herzog, Daniel Ho, Julian Ibarz, Alex Irpan, Eric Jang, Ryan Julian, et al. Do as i can, not as i say: Grounding language in robotic affordances. In Conference on Robot Learning, pages 287–318. PMLR, 2023.

[5] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are few-shot learners. Advances in neural information processing systems, 33:1877–1901, 2020.

[6] Sébastien Bubeck, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke, Eric Horvitz, Ece Kamar, Peter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lundberg, et al. Sparks of artificial general intelligence: Early experiments with gpt-4. arXiv preprint arXiv:2303.12712, 2023.

[7] Harrison Chase. LangChain, 10 2022. URL https://github.com/hwchase17/langchain.

[8] Wenhu Chen, Xueguang Ma, Xinyi Wang, và William W Cohen. Program of thoughts prompting: Disentangling computation from reasoning for numerical reasoning tasks. arXiv preprint arXiv:2211.12588, 2022.

[9] Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, et al. Palm: Scaling language modeling with pathways. arXiv preprint arXiv:2204.02311, 2022.

[10] Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, et al. Training verifiers to solve math word problems. arXiv preprint arXiv:2110.14168, 2021.

[11] Ning Ding, Yujia Qin, Guang Yang, Fuchao Wei, Zonghan Yang, Yusheng Su, Shengding Hu, Yulin Chen, Chi-Min Chan, Weize Chen, et al. Delta tuning: A comprehensive study of parameter efficient methods for pre-trained language models. arXiv preprint arXiv:2203.06904, 2022.

[12] Iddo Drori, Sarah Zhang, Reece Shuttleworth, Leonard Tang, Albert Lu, Elizabeth Ke, Kevin Liu, Linda Chen, Sunny Tran, Newman Cheng, et al. A neural network solves, explains, and generates university math problems by program synthesis and few-shot learning at human level. Proceedings of the National Academy of Sciences, 119(32):e2123433119, 2022.

[13] Dheeru Dua, Shivanshu Gupta, Sameer Singh, và Matt Gardner. Successive prompting for decomposing complex questions. arXiv preprint arXiv:2212.04092, 2022.

[14] Tyna Eloundou, Sam Manning, Pamela Mishkin, và Daniel Rock. Gpts are gpts: An early look at the labor market impact potential of large language models. arXiv preprint arXiv:2303.10130, 2023.

[15] Jacqueline Fagard, Lauriane Rat-Fischer, Rana Esseily, Eszter Somogyi, và JK O'Regan. What does it take for an infant to learn how to use a tool by observation? Frontiers in psychology, 7: 267, 2016.

[16] Bin Fu, Yunqi Qiu, Chengguang Tang, Yang Li, Haiyang Yu, và Jian Sun. A survey on complex question answering over knowledge base: Recent advances and challenges. arXiv preprint arXiv:2007.13069, 2020.

--- TRANG 12 ---
[17] Luyu Gao, Aman Madaan, Shuyan Zhou, Uri Alon, Pengfei Liu, Yiming Yang, Jamie Callan, và Graham Neubig. Pal: Program-aided language models. arXiv preprint arXiv:2211.10435, 2022.

[18] Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat, và Mingwei Chang. Retrieval augmented language model pre-training. In International conference on machine learning, pages 3929–3938. PMLR, 2020.

[19] Shibo Hao, Yi Gu, Haodi Ma, Joshua Jiahua Hong, Zhen Wang, Daisy Zhe Wang, và Zhiting Hu. Reasoning with language model is planning with world model. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, 2023.

[20] Shibo Hao, Bowen Tan, Kaiwen Tang, Bin Ni, Xiyan Shao, Hengzhe Zhang, Eric Xing, và Zhiting Hu. BertNet: Harvesting knowledge graphs with arbitrary relations from pretrained language models. In Findings of the Association for Computational Linguistics: ACL 2023, pages 5000–5015, Toronto, Canada, July 2023. Association for Computational Linguistics. doi: 10.18653/v1/2023.findings-acl.309. URL https://aclanthology.org/2023.findings-acl.309.

[21] Joy He-Yueya, Gabriel Poesia, Rose E Wang, và Noah D Goodman. Solving math word problems by combining language models with symbolic solvers. arXiv preprint arXiv:2304.09102, 2023.

[22] Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin De Laroussilhe, Andrea Gesmundo, Mona Attariyan, và Sylvain Gelly. Parameter-efficient transfer learning for nlp. In International Conference on Machine Learning, pages 2790–2799. PMLR, 2019.

[23] Edward J Hu, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, Weizhu Chen, et al. Lora: Low-rank adaptation of large language models. In International Conference on Learning Representations, 2021.

[24] Zhiting Hu và Eric P Xing. Toward a 'standard model' of machine learning. Harvard Data Science Review, 2022.

[25] Wenlong Huang, Pieter Abbeel, Deepak Pathak, và Igor Mordatch. Language models as zero-shot planners: Extracting actionable knowledge for embodied agents. In International Conference on Machine Learning, pages 9118–9147. PMLR, 2022.

[26] Wenlong Huang, Fei Xia, Ted Xiao, Harris Chan, Jacky Liang, Pete Florence, Andy Zeng, Jonathan Tompson, Igor Mordatch, Yevgen Chebotar, et al. Inner monologue: Embodied reasoning through planning with language models. arXiv preprint arXiv:2207.05608, 2022.

[27] Wenlong Huang, Fei Xia, Dhruv Shah, Danny Driess, Andy Zeng, Yao Lu, Pete Florence, Igor Mordatch, Sergey Levine, Karol Hausman, et al. Grounded decoding: Guiding text generation with grounded models for robot control. arXiv preprint arXiv:2303.00855, 2023.

[28] Ziwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan Su, Yan Xu, Etsuko Ishii, Ye Jin Bang, Andrea Madotto, và Pascale Fung. Survey of hallucination in natural language generation. ACM Computing Surveys, 55(12):1–38, 2023.

[29] Qiao Jin, Yifan Yang, Qingyu Chen, và Zhiyong Lu. Genegpt: Augmenting large language models with domain tools for improved access to biomedical information. ArXiv, 2023.

[30] Jan-Christoph Kalo và Leandra Fichtel. Kamel: Knowledge analysis with multitoken entities in language models. In Proceedings of the Conference on Automated Knowledge Base Construction, 2022.

[31] Rabeeh Karimi Mahabadi, James Henderson, và Sebastian Ruder. Compacter: Efficient low-rank hypercomplex adapter layers. Advances in Neural Information Processing Systems, 34:1022–1035, 2021.

[32] Tushar Khot, Harsh Trivedi, Matthew Finlayson, Yao Fu, Kyle Richardson, Peter Clark, và Ashish Sabharwal. Decomposed prompting: A modular approach for solving complex tasks. arXiv preprint arXiv:2210.02406, 2022.

[33] Yann LeCun. A path towards autonomous machine intelligence version 0.9. 2, 2022-06-27. Open Review, 62, 2022.

[34] Brian Lester, Rami Al-Rfou, và Noah Constant. The power of scale for parameter-efficient prompt tuning. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 3045–3059, 2021.

--- TRANG 13 ---
[35] Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel, et al. Retrieval-augmented generation for knowledge-intensive nlp tasks. Advances in Neural Information Processing Systems, 33:9459–9474, 2020.

[36] Minghao Li, Feifan Song, Bowen Yu, Haiyang Yu, Zhoujun Li, Fei Huang, và Yongbin Li. Api-bank: A benchmark for tool-augmented llms. arXiv preprint arXiv:2304.08244, 2023.

[37] Shuang Li, Xavier Puig, Chris Paxton, Yilun Du, Clinton Wang, Linxi Fan, Tao Chen, De-An Huang, Ekin Akyürek, Anima Anandkumar, et al. Pre-trained language models for interactive decision-making. Advances in Neural Information Processing Systems, 35:31199–31212, 2022.

[38] Xiang Lisa Li và Percy Liang. Prefix-tuning: Optimizing continuous prompts for generation. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 4582–4597, 2021.

[39] Yaobo Liang, Chenfei Wu, Ting Song, Wenshan Wu, Yan Xia, Yu Liu, Yang Ou, Shuai Lu, Lei Ji, Shaoguang Mao, et al. Taskmatrix. ai: Completing tasks by connecting foundation models with millions of apis. arXiv preprint arXiv:2303.16434, 2023.

[40] Bo Liu, Yuqian Jiang, Xiaohan Zhang, Qiang Liu, Shiqi Zhang, Joydeep Biswas, và Peter Stone. Llm+ p: Empowering large language models with optimal planning proficiency. arXiv preprint arXiv:2304.11477, 2023.

[41] Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi, và Graham Neubig. Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing. ACM Computing Surveys, 55(9):1–35, 2023.

[42] Xiao Liu, Kaixuan Ji, Yicheng Fu, Weng Lam Tam, Zhengxiao Du, Zhilin Yang, và Jie Tang. P-tuning v2: Prompt tuning can be comparable to fine-tuning universally across scales and tasks. arXiv preprint arXiv:2110.07602, 2021.

[43] Pan Lu, Baolin Peng, Hao Cheng, Michel Galley, Kai-Wei Chang, Ying Nian Wu, Song-Chun Zhu, và Jianfeng Gao. Chameleon: Plug-and-play compositional reasoning with large language models. arXiv preprint arXiv:2304.09842, 2023.

[44] Qing Lyu, Shreya Havaldar, Adam Stein, Li Zhang, Delip Rao, Eric Wong, Marianna Apidianaki, và Chris Callison-Burch. Faithful chain-of-thought reasoning. arXiv preprint arXiv:2301.13379, 2023.

[45] Grégoire Mialon, Roberto Dessì, Maria Lomeli, Christoforos Nalmpantis, Ram Pasunuru, Roberta Raileanu, Baptiste Rozière, Timo Schick, Jane Dwivedi-Yu, Asli Celikyilmaz, et al. Augmented language models: a survey. arXiv preprint arXiv:2302.07842, 2023.

[46] Reiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu, Long Ouyang, Christina Kim, Christopher Hesse, Shantanu Jain, Vineet Kosaraju, William Saunders, et al. Webgpt: Browser-assisted question-answering with human feedback. arXiv preprint arXiv:2112.09332, 2021.

[47] OpenAI. Gpt-4 technical report, 2023.

[48] Batu Ozturkler, Nikolay Malkin, Zhen Wang, và Nebojsa Jojic. Thinksum: Probabilistic reasoning over sets using large language models. arXiv preprint arXiv:2210.01293, 2022.

[49] Bhargavi Paranjape, Scott Lundberg, Sameer Singh, Hannaneh Hajishirzi, Luke Zettlemoyer, và Marco Tulio Ribeiro. Art: Automatic multi-step reasoning and tool-use for large language models. arXiv preprint arXiv:2303.09014, 2023.

[50] Aaron Parisi, Yao Zhao, và Noah Fiedel. Talm: Tool augmented language models. arXiv preprint arXiv:2205.12255, 2022.

[51] Fabio Petroni, Tim Rocktäschel, Patrick Lewis, Anton Bakhtin, Yuxiang Wu, Alexander H Miller, và Sebastian Riedel. Language models as knowledge bases? arXiv preprint arXiv:1909.01066, 2019.

[52] Xavier Puig, Kevin Ra, Marko Boben, Jiaman Li, Tingwu Wang, Sanja Fidler, và Antonio Torralba. Virtualhome: Simulating household activities via programs. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 8494–8502, 2018.

--- TRANG 14 ---
[53] Yujia Qin, Shengding Hu, Yankai Lin, Weize Chen, Ning Ding, Ganqu Cui, Zheni Zeng, Yufei Huang, Chaojun Xiao, Chi Han, Yi Ren Fung, Yusheng Su, Huadong Wang, Cheng Qian, Runchu Tian, Kunlun Zhu, Shi Liang, Xingyu Shen, Bokai Xu, Zhen Zhang, Yining Ye, Bo Li, Ziwei Tang, Jing Yi, Yu Zhu, Zhenning Dai, Lan Yan, Xin Cong, Ya-Ting Lu, Weilin Zhao, Yuxiang Huang, Jun-Han Yan, Xu Han, Xian Sun, Dahai Li, Jason Phang, Cheng Yang, Tongshuang Wu, Heng Ji, Zhiyuan Liu, và Maosong Sun. Tool learning with foundation models. ArXiv, abs/2304.08354, 2023.

[54] Nils Reimers và Iryna Gurevych. Sentence-bert: Sentence embeddings using siamese bert-networks. arXiv preprint arXiv:1908.10084, 2019.

[55] Stephen Roller, Emily Dinan, Naman Goyal, Da Ju, Mary Williamson, Yinhan Liu, Jing Xu, Myle Ott, Eric Michael Smith, Y-Lan Boureau, et al. Recipes for building an open-domain chatbot. In Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, pages 300–325, 2021.

[56] Timo Schick, Jane Dwivedi-Yu, Roberto Dessì, Roberta Raileanu, Maria Lomeli, Luke Zettlemoyer, Nicola Cancedda, và Thomas Scialom. Toolformer: Language models can teach themselves to use tools. arXiv preprint arXiv:2302.04761, 2023.

[57] Yongliang Shen, Kaitao Song, Xu Tan, Dongsheng Li, Weiming Lu, và Yueting Zhuang. Hugginggpt: Solving ai tasks with chatgpt and its friends in huggingface. arXiv preprint arXiv:2303.17580, 2023.

[58] Kurt Shuster, Spencer Poff, Moya Chen, Douwe Kiela, và Jason Weston. Retrieval augmentation reduces hallucination in conversation. In Findings of the Association for Computational Linguistics: EMNLP 2021, pages 3784–3803, 2021.

[59] Ishika Singh, Valts Blukis, Arsalan Mousavian, Ankit Goyal, Danfei Xu, Jonathan Tremblay, Dieter Fox, Jesse Thomason, và Animesh Garg. Progprompt: Generating situated robot task plans using large language models. arXiv preprint arXiv:2209.11302, 2022.

[60] Alon Talmor và Jonathan Berant. The web as a knowledge-base for answering complex questions. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers), pages 641–651, 2018.

[61] Romal Thoppilan, Daniel De Freitas, Jamie Hall, Noam Shazeer, Apoorv Kulshreshtha, Heng-Tze Cheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du, et al. Lamda: Language models for dialog applications. arXiv preprint arXiv:2201.08239, 2022.

[62] Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, et al. Llama: Open and efficient foundation language models. arXiv preprint arXiv:2302.13971, 2023.

[63] Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A Smith, Daniel Khashabi, và Hannaneh Hajishirzi. Self-instruct: Aligning language model with self generated instructions. arXiv preprint arXiv:2212.10560, 2022.

[64] Zhen Wang, Rameswar Panda, Leonid Karlinsky, Rogerio Feris, Huan Sun, và Yoon Kim. Multitask prompt tuning enables parameter-efficient transfer learning. In The Eleventh International Conference on Learning Representations, 2023.

[65] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Ed Chi, Quoc Le, và Denny Zhou. Chain of thought prompting elicits reasoning in large language models. arXiv preprint arXiv:2201.11903, 2022.

[66] Jiannan Xiang, Tianhua Tao, Yi Gu, Tianmin Shu, Zirui Wang, Zichao Yang, và Zhiting Hu. Language Models Meet World Models: Embodied Experiences Enhance Language Models. NeurIPS, 2023.

[67] Yaqi Xie, Chen Yu, Tongyao Zhu, Jinbin Bai, Ze Gong, và Harold Soh. Translating natural language to planning goals with large-language models. arXiv preprint arXiv:2302.05128, 2023.

[68] Sherry Yang, Ofir Nachum, Yilun Du, Jason Wei, Pieter Abbeel, và Dale Schuurmans. Foundation models for decision making: Problems, methods, and opportunities. arXiv preprint arXiv:2303.04129, 2023.

--- TRANG 15 ---
[69] Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, và Yuan Cao. React: Synergizing reasoning and acting in language models. arXiv preprint arXiv:2210.03629, 2022.

[70] Wenhao Yu, Chenguang Zhu, Zaitang Li, Zhiting Hu, Qingyun Wang, Heng Ji, và Meng Jiang. A survey of knowledge-enhanced text generation. ACM Computing Surveys, 54(11s):1–38, 2022.

[71] Elad Ben Zaken, Yoav Goldberg, và Shauli Ravfogel. Bitfit: Simple parameter-efficient fine-tuning for transformer-based masked language-models. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 1–9, 2022.

[72] Yuheng Zha, Yichi Yang, Ruichen Li, và Zhiting Hu. AlignScore: Evaluating factual consistency with a unified alignment function. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 11328–11348, Toronto, Canada, July 2023. Association for Computational Linguistics. URL https://aclanthology.org/2023.acl-long.634.

[73] Yuheng Zha, Yichi Yang, Ruichen Li, và Zhiting Hu. Text alignment is an efficient unified model for massive nlp tasks. NeurIPS, 2023.

--- TRANG 16 ---
A Chi tiết về Lý luận Số học
Trong phần này, chúng tôi mô tả quy trình xử lý dữ liệu (bao gồm xây dựng các tập dữ liệu thử nghiệm và tổng hợp dữ liệu đào tạo), liệt kê các prompt được sử dụng cho các phương pháp khác nhau, và mô tả cài đặt đào tạo. Để so sánh công bằng, chúng tôi sử dụng cùng prompt cho CoT và chế độ lý luận của ToolkenGPT. Với cùng câu hỏi ví dụ, chúng tôi gán nhãn quá trình tính toán tại chỗ để có được prompt cho ReAct. Đối với chế độ công cụ của ToolkenGPT, chúng tôi ngẫu nhiên lấy mẫu 4 ví dụ của công cụ được chỉ định từ tập đào tạo, và biến đổi chúng thành prompt kiểu ReAct. Vì có một số lượng lớn công cụ được sử dụng, chúng tôi hiển thị các prompt trong tệp bổ sung thay vì liệt kê chúng ở đây.

A.1 GSM8K-XL

A.1.1 Tổng hợp Dữ liệu
Để xây dựng một phiên bản nâng cao GSM8K-XL bằng cách phóng đại các số trong GSM8K, chúng tôi thực hiện các bước sau:

1. Chúng tôi prompt ChatGPT (gpt-3.5-turbo) với hai ví dụ để thay thế các số bằng các placeholder phù hợp. Prompt được trình bày dưới đây.

2. Để xác thực tính đúng đắn của việc thay thế số, chúng tôi phát triển một hàm xác minh cho tập dữ liệu GSM8k, tính toán các công thức được nhúng trong các giải pháp (Xem prompt ví dụ dưới đây. Các công thức được trích dẫn với « và ».) để có được một câu trả lời. Bằng cách thay thế các số ban đầu trở lại vào các cặp câu hỏi-câu trả lời được viết lại và so sánh kết quả thực thi với câu trả lời ban đầu, chúng tôi có thể xác định bất kỳ lần viết lại sai nào và loại trừ chúng khỏi tập dữ liệu của chúng tôi. Điều này đảm bảo độ tin cậy và chính xác của việc thay thế số.

3. Một khi chúng tôi đã xác nhận độ chính xác của quá trình viết lại, chúng tôi có thể tiến hành phóng đại các số. Chúng tôi thay thế các số ban đầu bằng các giá trị lập phương tương ứng của chúng, tăng cường độ lớn của chúng một cách theo cấp số nhân. Tuy nhiên, đáng chú ý rằng chiến lược này không có ý nghĩa trong mọi tình huống. Ví dụ, khi xử lý các giá trị phần trăm (ví dụ, 10%), việc phóng đại lập phương trực tiếp lên 1000% sẽ không phù hợp. Trong những trường hợp như vậy, chúng tôi duy trì các giá trị ban đầu để bảo toàn ý nghĩa dự định của chúng.

4. Với các số được phóng đại, chúng tôi thay thế liền mạch các placeholder trong các cặp câu hỏi-câu trả lời được viết lại. Bằng cách sử dụng hàm giải quyết được phát triển trước đó, chúng tôi có thể xử lý các công thức được phóng đại và có được các giải pháp chính xác, dẫn đến tập dữ liệu GSM8K-XL.

{
"role": "system",
"content": "Nhiệm vụ của bạn là viết lại câu hỏi và câu trả lời đã cho dưới dạng tổng quát hơn bằng cách sử dụng các biến thay vì các số cụ thể."
},
{
"role": "user",
"content": "Question: Janet's ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market\nAnswer: Janet sells 16 - 3 - 4 = <<16-3-4=9>>9 duck eggs a day.\nShe makes 9 * 2 = $<<9*2=18>>18 every day at the farmer's market.\n#### 18"
},
{
"role": "assistant",

--- TRANG 17 ---
"content": "Question: Janet's ducks lay {v_1} eggs per day. She eats {v_2} for breakfast every morning and bakes muffins for her friends every day with {v_3}. She sells the remainder at the farmers' market daily for ${v_4} per fresh duck egg. How much in dollars does she make every day at the farmers' market?\nAnswer: Janet sells {v_1} - {v_2} - {v_3} = <<{v_1}-{v_2}-{v_3}={r_1}>>{r_1} duck eggs a day.\nShe makes {r_1} * {v_4} = $<<{r_1}*{v_4}={r_2}>>{r_2} every day at the farmer's market.\n#### {r_2}"
},
{
"role": "user",
"content": "Question: A wooden bridge can carry no more than 5000 pounds. A delivery truck filled with identical boxes, each weighing 15 pounds, will pass over the bridge. The combined weight of the driver and the empty truck is 3755 pounds. What is the maximum number of boxes which can be loaded onto the truck while not exceeding the bridge's weight limit?\nAnswer: The boxes can weigh up to 5000 pounds - 3755 pounds = <<5000-3755=1245>>1245 pounds in total.\nThere can be 1245 / 15 = <<1245/15=83>>83 boxes loaded onto the truck without exceeding the bridge's weight limit.\n#### 83"
},
{
"role": "assistant",
"content": "Question: A wooden bridge can carry no more than {v_1} pounds. A delivery truck filled with identical boxes, each weighing {v_2} pounds, will pass over the bridge. The combined weight of the driver and the empty truck is {v_3} pounds. What is the maximum number of boxes which can be loaded onto the truck while not exceeding the bridge's weight limit?\nAnswer: The boxes can weigh up to {v_1} pounds - {v_3} pounds = <<{v_1}-{v_3}={r_1}>>{r_1} pounds in total.\nThere can be {r_1} / {v_2} = <<{r_1}/{v_2}={r_2}>>{r_2} boxes loaded onto the truck without exceeding the bridge's weight limit.\n#### {r_2}"
},
{
"role": "user",
"content": "[INPUT]
}

A.1.2 Chi tiết Đào tạo
Như đã đề cập trong Phần 4.1, các embedding toolken được đào tạo với một tập hợp con 5.063 ví dụ. Thêm 1.000 ví dụ được dành riêng để xác thực. Các embedding được đào tạo với tỷ lệ học 5e-4, thực hiện dừng sớm dựa trên tập phát triển, với tối đa 10 epoch.

A.1.3 Prompt cho Tập dữ liệu GSM8K-XL
Prompt cho Prompting Trực tiếp với ChatGPT:
Giải bài toán sau từng bước, và sau đó cung cấp câu trả lời cuối cùng theo định dạng: 'So, the answer is xxx.'
[QUESTION]

Prompt cho Chain of Thought (CoT) và chế độ lý luận ToolkenGPT:
Answer the following questions step by step.
Question: Mark has 3 tanks for pregnant fish. Each tank has 4 pregnant fish and each fish gives birth to 20 young. How many young fish does he have at the end?

--- TRANG 18 ---
Answer: He has 4*3=12 pregnant fish They give birth to 12*20=240 fish #### 240
Question: The math questions in a contest are divided into three rounds: easy, average, and hard. There are corresponding points given for each round. That is 2, 3, and 5 points for every correct answer in the easy, average, and hard rounds, respectively. Suppose Kim got 6 correct answers in the easy; 2 correct answers in the average; and 4 correct answers in the difficult round, what are her total points in the contest?
Answer: Kim got 6 points/round x 2 round = 12 points in the easy round. She got 2 points/round x 3 rounds = 6 points in the average round. She got 4 points/round x 5 rounds = 20 points in the difficult round. So her total points is 12 points + 6 points + 20 points = 38 points. #### 38
Question: A clothing store sells 20 shirts and 10 pairs of jeans. A shirt costs $10 each and a pair of jeans costs twice as much. How much will the clothing store earn if all shirts and jeans are sold?
Answer: Twenty shirts amount to $10 x 20 = $200. The cost of each pair of jeans is $10 x 2 = $20. So 10 pairs of jeans amount to $20 x 10 = $200. Therefore, the store will earn $200 + $200 = $400 if all shirts and jeans are sold. #### 400
Question: Arnold's collagen powder has 18 grams of protein for every 2 scoops. His protein powder has 21 grams of protein per scoop. And his steak has 56 grams of protein. If he has 1 scoop of collagen powder, 1 scoop of protein powder and his steak, how many grams of protein will he consume?
Answer: 2 scoops of collagen powder have 18 grams of protein and he only has 1 scoop so he consumes 18/2 = 9 grams of protein He has 9 grams collagen powder, 21 grams of protein powder and 56 grams in his steak for a total of 9+21+56 = 86 grams of protein #### 86
Question: [QUESTION]
Answer:

Prompt cho ReAct:
Answer the following questions with <add>, <subtract>, <multiply>, <divide> operators
Question: Mark has 3 tanks for pregnant fish. Each tank has 4 pregnant fish and each fish gives birth to 20 young. How many young fish does he have at the end?
Answer: He has 4*3=<multiply>(4, 3)=12 pregnant fish They give birth to 12*20=<multiply>(12, 20)=240 fish #### 240
Question: The math questions in a contest are divided into three rounds: easy, average, and hard. There are corresponding points given for each round. That is 2, 3, and 5 points for every correct answer in the easy, average, and hard rounds, respectively. Suppose Kim got 6 correct answers in the easy; 2 correct answers in the average; and 4 correct answers in the difficult round, what are her total points in the contest?
Answer: Kim got 6 points/round x 2 round = <multiply>(6, 2)=12 points in the easy round. She got 2 points/round x 3 rounds = <multiply>(2, 3)=6 points in the average round. She got 4 points/round x 5 rounds = <multiply>(4, 5)=20 points in the difficult round. So her total points is 12 points + 6 points + 20 points = <add>(12, 6, 20)=38 points. #### 38

--- TRANG 19 ---
Question: A clothing store sells 20 shirts and 10 pairs of jeans. A shirt costs $10 each and a pair of jeans costs twice as much. How much will the clothing store earn if all shirts and jeans are sold?
Answer: Twenty shirts amount to $10 x 20 = $<multiply>(10, 20)=200. The cost of each pair of jeans is $10 x 2 = $<multiply>(10, 2)=20. So 10 pairs of jeans amount to $20 x 10 = $<multiply>(20, 10)=200. Therefore, the store will earn $200 + $200 = $<add>(200, 200)=400 if all shirts and jeans are sold. #### 400
Question: Arnold's collagen powder has 18 grams of protein for every 2 scoops. His protein powder has 21 grams of protein per scoop. And his steak has 56 grams of protein. If he has 1 scoop of collagen powder, 1 scoop of protein powder and his steak, how many grams of protein will he consume?
Answer: 2 scoops of collagen powder have 18 grams of protein and he only has 1 scoop so he consumes 18/2 = <divide>(18, 2)=9 grams of protein He has 9 grams collagen powder, 21 grams of protein powder and 56 grams in his steak for a total of 9+21+56 = <add>(9, 21, 56)=86 grams of protein #### 86
Question: [QUESTION]
Answer:

A.2 FuncQA

A.2.1 Chi tiết Đào tạo
Như đã đề cập trong Phần 4.1, Embedding Toolken được đào tạo sử dụng một tập hợp con 611 ví dụ, với thêm 39 ví dụ được dành riêng cho mục đích xác thực. Tỷ lệ học chúng tôi sử dụng là 1e-4, và chúng tôi thực hiện dừng sớm dựa trên tập phát triển, với các epoch đào tạo tối đa là 20.

A.2.2 Prompt cho Dữ liệu Đào tạo Tổng hợp
Trong Phần 4.1, chúng tôi đã thảo luận về việc sử dụng ChatGPT để tổng hợp tập đào tạo. Để tạo dữ liệu đào tạo, chúng tôi bắt đầu bằng cách thủ công tạo ra hai ví dụ tuân thủ định dạng mong muốn, và sau đó sử dụng prompt cụ thể sau để tạo ra nhiều ví dụ hơn. Tuy nhiên, điều quan trọng cần thừa nhận rằng prompt không đảm bảo việc tạo ra các ví dụ tuân thủ nghiêm ngặt định dạng yêu cầu. Vì vậy, chúng tôi áp dụng một quá trình lọc để loại bỏ bất kỳ instance nào không tuân thủ. Hơn nữa, quá trình tạo thường tạo ra các ví dụ trùng lặp, đòi hỏi một bước khử trùng lặp tiếp theo.

You are a math question generator for teachers, and your task is to generate some questions and answers using function [FUNC] to solve and can be solved within one single step. You do not need to give specific numbers, so that the teachers can fill any numbers they want. Here are two examples that use the function [FUNC].
[EXAMPLE_1]
[EXAMPLE_2]
[FUNC] is a function to [DESCRIPTION]. Now, let's mimic the format of examples to generate various real world QA pairs using the function [FUNC] that can be solved within one step. The numbers should be replaced by [ARG] and [ANSWER] as the examples given above.

A.2.3 Prompt cho FuncQA One-Hop
Prompt cho Zero-Shot với ChatGPT:

--- TRANG 20 ---
Solve the following math problem, and then provide the final answer in the format: 'So, the answer is xxx.'
[QUESTION]

Prompt cho Chain of Thought (CoT) và ToolkenGPT:
Q: If Amy's income increases by 4% annually, how many times will it multiply in 11 years?
A: In 11 years, Amy's income will increase by 1.04^11=1.54 times. So, the answer is 1.54.
Q: If a store sells 147 bananas today and 354 more bananas tomorrow, how many bananas does the store sell in total?
A: The store sells 147 bananas today and 354 more bananas tomorrow, so the total number of bananas sold is 147+354=501. So, the answer is 501.
Q: A man had 789.4 dollars in his wallet. He spent 11.99 dollars on a movie ticket. How much money does he have left now?
A: The man had 789.4 dollars in his wallet and spent 11.99 dollars on a movie ticket, so he has 789.4-11.99=777.41 dollars left. So, the answer is 777.41 dollars.
Q: If a cake weighs 3.77 pounds and is divided into 13 equal pieces, how much does each piece weight?
A: Each piece of the cake weighs 3.77/13=0.29 pounds. So, the answer is 0.29 pounds.
Q: [QUESTION]
A:

Prompt cho ReAct:
Answer the following question with <add>, <subtract>, <multiply>, <divide>, <power>, <sqrt>, <log>, <lcm>, <gcd>, <ln>, <choose>, <remainder>, <permutate>:
Q: If Amy's income increases by 4% annually, how many times will it multiply in 11 years?
A: In 11 years, Amy's income will increase by 1.04^11 = <power>(1.04,11)=1.54 times. So, the answer is 1.54.
Q: If a store sells 147 bananas today and 354 more bananas tomorrow, how many bananas does the store sell in total?
A: The store sells 147 bananas today and 354 more bananas tomorrow, so the total number of bananas sold is 147+354=<add>(147,354)=501. So, the answer is 501.
Q: A man had 789.4 dollars in his wallet. He spent 11.99 dollars on a movie ticket. How much money does he have left now?
A: The man had 789.4 dollars in his wallet and spent 11.99 dollars on a movie ticket, so he has 789.4-11.99=<subtract>(789.4,11.99)=777.41 dollars left. So, the answer is 777.41.
Q: If a cake weighs 3.77 pounds and is divided into 13 equal pieces, how much does each piece weight?
A: Each piece of the cake weighs 3.77/13=<divide>(3.77,13)=0.29 pounds. So, the answer is 0.29.
Q: [QUESTION]

--- TRANG 21 ---
A:

A.2.4 Prompt cho FuncQA Multi-Hop
Prompt cho Zero-Shot với ChatGPT:
Solve the following math problem step by step, and then provide the final answer in the format: 'So, the answer is xxx.'
[QUESTION]

Prompt cho Chain of Thought (CoT) và ToolkenGPT:
Answer the following questions step by step:
Question: A coin is tossed 8 times, what is the probability of getting exactly 7 heads ?
Answer: The total number of possible outcomes to toss a coin 8 times is 2^8=256. The number of ways of getting exactly 7 heads is 8C7=8. The probability of getting exactly 7 heads is 8/256=0.03125. #### 0.03125
Question: If paint costs $3.2 per quart, and a quart covers 12 square feet, how much will it cost to paint the outside of a cube 10 feet on each edge?
Answer: The total surface area of the 10 ft cube is 6*10^2=6*100=600 square feet. The number of quarts needed is 600/12=50. The cost is 50*3.2=160. #### 160
Question: log(x)=2, log(y)=0.1, what is the value of log(x-y) ?
Answer: log(x)=2, so x=10^2=100; log(y)=0.1, so y=10^0.1=1.26; x-y=100-1.26=98.74, so log(x-y)=log(98.74)=1.99. #### 1.99
Question: How many degrees does the hour hand travel when the clock goes 246 minutes?
Answer: The hour hand travels 360 degrees in 12 hours, so every hour it travels 360/12=30 degrees. 246 minutes is 246/60=4.1 hours. The hour hand travels 4.1*30=123 degrees. #### 123
Question: [QUESTION]
Answer:

Prompt cho ReAct:
Answer the following questions with <add>, <subtract>, <multiply>, <divide>, <power>, <sqrt>, <log>, <lcm>, <gcd>, <ln>, <choose>, <remainder>, and <permutate>:
Question: A coin is tossed 8 times, what is the probability of getting exactly 7 heads?
Answer: The total number of possible outcomes to toss a coin 8 times is 2^8=<power>(2,8)=256. The number of ways of getting exactly 7 heads is 8C7=<choose>(8,7)=8. The probability of getting exactly 7 heads is 8/256=<divide>(8,256)=0.03125. #### 0.03125
Question: If paint costs $3.2 per quart, and a quart covers 12 square feet, how much will it cost to paint the outside of a cube 10 feet on each edge?
Answer: The total surface area of the 10 ft cube is 6*10^2=6*<power>(10,2)=100=<multiply>(6,100)=600 square feet. The number of quarts needed is 600/12=<divide>(600,12)=50. The cost is 50*3.2=<multiply>(50,3.2)=160. #### 160

--- TRANG 22 ---
Question: log(x)=2, log(y)=0.1, what is the value of log(x-y) ?
Answer: log(x)=2, so x=10^2=<power>(10,2)=100; log(y)=0.1, so y=10^0.1=<power>(10,0.1)=1.26; x-y=100-1.26=<subtract>(10,1.26)=98.74, so log(x-y)=log(98.74)=<log>(98.74)=1.99. #### 1.99
Question: How many degrees does the hour hand travel when the clock goes 246 minutes?
Answer: The hour hand travels 360 degrees in 12 hours, so every hour it travels 360/12=<divide>(360,12)=30 degrees. 246 minutes is 246/60=<divide>(246,60)=4.1 hours. The hour hand travels 4.1*30=<multiply>(4.1,30)=123 degrees. #### 123
Question: [QUESTION]
Answer:

B Chi tiết về QA Dựa trên Kiến thức
Trong phần này, chúng tôi hiển thị cách biến đổi mỗi định danh quan hệ Wikidata (ví dụ P1346) thành một mô tả ngôn ngữ tự nhiên, và sau đó mô tả phương pháp tổng hợp dữ liệu và cài đặt đào tạo.

B.1 Lấy Mô tả Văn bản
KAMEL cung cấp một mẫu câu hỏi cho mỗi quan hệ. Chúng tôi ngẫu nhiên lấy mẫu 3 sự thật từ tập dữ liệu và khởi tạo chúng thành cặp câu hỏi-câu trả lời, và sử dụng prompt sau để tạo một mô tả cho chúng với ChatGPT:

Given a question template and some example answer, you need to define an API that can help you answer the question.
Q 1.1: What is the original language of The Wonderful Galaxy of Oz
A 1.1: Japanese
Q 1.2: What is the original language of Wild Field?
A 1.2: Russian
Q 1.3: What is the original language of Nadigan?
A 1.3: Tamil
API 1: original_language(title): gets the original language of an art work
Q 2.1: What languages does Judah Maccabee speak?
A 2.1: Hebrew
Q 2.2: What languages does Ronelda Kamfer speak?
A 2.2: Afrikaans
Q 2.3: What languages does Leibush Lehrer speak?
A 2.3: Yiddish
API 2: spoken_languages(name): gets the spoken languages of a person
Q 3.1: [Q1]
A 3.1: [A1]
Q 3.2: [Q2]
A 3.2: [A2]
Q 3.3: [Q3]
A 3.3: [A3]
API 3:

B.2 Dữ liệu Tổng hợp
Chúng tôi sử dụng hai prompt để tổng hợp dữ liệu đào tạo đa dạng, và tổng hợp các mẫu từ mỗi prompt.

--- TRANG 23 ---
Here are some examples of using functions for text generation (after the function call, the sentence should continue with the returned value of the function call):
1. star_rating(product): gets the star rating of the product on a scale from 0 to 5.
Example 1.1: The new iPhone 12 Pro Max is already generating a lot of buzz, thanks to its <f>star_rating("iPhone 12 Pro Max")="4.7"</f>4.7 star rating.
2. literary_genre(book): gets the literary genre of a book
Example 2.1: Literature is often categorized by genre, such as drama, romance, or science fiction. The Harry Potter series is a popular example of the <f>literary_genre("Harry Potter")="fantasy"</f>fantasy genre, which features imaginary worlds and magical elements.
3. current_location(user_id): gets the current location of a user.
Example 3.1: If you're trying to coordinate plans with a friend, it's helpful to know their current location. You can ask the question "Where are you right now?" and use the function <f>current_location("1234")="New York"</f>New York as an example response.
4. number_of_movies(director): gets the number of movies directed by a specific director.
Example 4.1: Martin Scorsese is one of the most celebrated movie directors of all time. He has directed a total of <f>number_of_movies("Martin Scorsese")="78"</f>78 movies throughout his career.
5. word_definition(word): gets the definition of a particular word
Example 5.1: Writers and English language learners can enhance their vocabulary by knowing the definition of unfamiliar words. The definition of the word "eccentric" is <f>word_definition("eccentric")="unconventional and slightly strange"</f>unconventional and slightly strange.
6. number_of_spotify_followers(artist): gets the number of Spotify followers for the artist.
Example 6.1: Taylor Swift's latest album is a hit and her fan base is growing rapidly. In fact, her number of Spotify followers as of today is <f>number_of_spotify_followers("Taylor Swift")="49,879,220"</f>49,879,220.
6. [DESCRIPTION]
Please continue to generate 10 examples using the function [NAME], starting with 6.1 to 6.10.

Here are some examples of using functions for text generation (after the function call, the sentence should continue with the returned value of the function call):
1. current_weather(city): gets the current weather of a city.
Example 1.1: What's the weather in Beijing now? The weather is <f>current_weather("Beijing")="sunny"</f>sunny now. Example 1.2: Do you know what's the weather in San Diego now? The weather is <f>current_weather("San Diego")="cloudy"</f>cloudy now.
2. calculator(formula): gets the calculation result of a formula.
Example 2.1: What's sum of 213 and 5032? The answer is <f>calculator("213+5032")="5245"</f>5245.
Example 2.2: What's difference between 2015 and 33? The answer is <f>calculator("2015-33")="1982"</f>1982.
3. [DESCRIPTION]
Please continue to generate 10 examples using the function [NAME], starting with 3.1 to 3.10.

B.3 Chi tiết Đào tạo
Embedding Toolken được đào tạo với tỷ lệ học 1e-4, thực hiện dừng sớm dựa trên tập phát triển, và được đào tạo tối đa 5 epoch.

--- TRANG 24 ---
C Chi tiết về Tạo Kế hoạch Thể hiện
Trong phần này, chúng tôi mô tả việc tiền xử lý VirtualHome, và liệt kê tất cả các prompt và chi tiết đào tạo.

C.1 Tiền xử lý
Chúng tôi thu thập tất cả các script từ ActivityPrograms và lọc tập dữ liệu với các bước sau: (1) lọc ra tất cả các script không thể thực thi, hoặc không gây ra bất kỳ thay đổi trạng thái nào trong VirtualHome (2) loại trùng lặp các script với cùng mục tiêu và hướng dẫn. (3) loại bỏ script liên quan đến hai đối tượng khác nhau có cùng tên (4) tìm các động từ và đối tượng xuất hiện hơn 10 lần trong dữ liệu, và giữ các script chỉ bao gồm những động từ và đối tượng này.

Lưu ý rằng việc tiền xử lý của chúng tôi khác với Huang et al., nơi họ coi một mục tiêu cấp cao như một nhiệm vụ. Chúng tôi coi hai script với cùng mục tiêu nhưng hướng dẫn khác nhau như các nhiệm vụ riêng biệt vì các hướng dẫn khác nhau thường chỉ ra các chuỗi hành động khác nhau, có thể dẫn đến các đồ thị trạng thái cuối cùng khác nhau, ví dụ, đối với mục tiêu cấp cao "Reading", một số hướng dẫn đề cập đến "Turn on desk lamp" trong khi những cái khác thì không. Huang et al. dựa vào chú thích của con người để đánh giá tính đúng đắn của script được tạo, thực tế làm giảm độ khó của việc học môi trường, vì con người có thể gán nhãn đúng miễn là kế hoạch trông "hợp lý". Ngược lại, chúng tôi có thể sử dụng Evolving Graph để khớp nghiêm ngặt trạng thái kết quả và trạng thái ground truth. Điều này phục vụ như một đánh giá tự động và khách quan hơn.

C.2 Prompt
Chúng tôi hiển thị các prompt cho LLM để tạo ra kế hoạch dưới đây. Lưu ý rằng tất cả các phương pháp sử dụng cùng prompt trong thí nghiệm này.

I am a household robot and I can take actions from '[FIND]', '[SIT]', '[SWITCHON]', '[TURNTO]', '[LOOKAT]', '[TYPE]', '[WALK]', '[LIE]', '[GRAB]', '[read]', '[WATCH]', '[POINTAT]', '[TOUCH]', '[SWITCHOFF]', '[OPEN]', '[PUSH]', '[PUTOBJBACK]', '[CLOSE]', '[DRINK]', '[RUN]', '[DROP]', '[PULL]'.
Task 1:
I am in ['bathroom']. The objects I can manipulate are ['faucet', 'keyboard', 'television', 'coffe_maker', 'chair', 'button', 'pillow', 'phone', 'cup', 'couch', 'freezer', 'desk', 'oven', 'light', 'table', 'bedroom', 'dining_room', 'cupboard', 'computer', 'sink', 'mail', 'bed', 'mouse', 'home_office'].
Goal:
Write an email
Hint:
i went near the computer and turned it on. then sent the mail
Plan:
[WALK] <home_office>
[WALK] <table>
[FIND] <table>
[WALK] <table>
[FIND] <computer>
[TURNTO] <computer>
[LOOKAT] <computer>
[TURNTO] <computer>
[SWITCHON] <computer>
[FIND] <mail>
[TURNTO] <mail>
Task 2:

--- TRANG 25 ---
I am in ['home_office']. The objects I can manipulate are ['faucet', 'novel', 'keyboard', 'television', 'newspaper', 'chair', 'coffe_maker', 'pillow', 'phone', 'check', 'couch', 'freezer', 'desk', 'toothbrush', 'oven', 'light', 'food_food', 'table', 'bookmark', 'bedroom', 'dining_room', 'computer', 'sink', 'mail', 'bed', 'cat', 'mouse', 'home_office', 'pot'].
Goal:
Work
Hint:
Find the computer. Turn it on by pressing the on button. Wait for it to load. Use the mouse and keyboard to perform your tasks on screen.
Plan:
[FIND] <computer>
[SWITCHON] <computer>
[FIND] <mouse>
[TOUCH] <mouse>
[FIND] <keyboard>
[TOUCH] <keyboard>
Task 3:
I am in ['bathroom']. The objects I can manipulate are ['dishwasher', 'faucet', 'keyboard', 'television', 'newspaper', 'chair', 'coffe_maker', 'pillow', 'phone', 'cup', 'check', 'couch', 'freezer', 'desk', 'oven', 'light', 'food_food', 'plate', 'table', 'bookmark', 'bedroom', 'dining_room', 'cupboard', 'computer', 'sink', 'bed', 'cat', 'mouse', 'home_office', 'pot'].
Goal:
Pick up phone
Hint:
first when i hear the ringing sound i will run to my living room and picks up and i will say hello
Plan:
[RUN] <home_office>
[WALK] <chair>
[FIND] <chair>
[SIT] <chair>
[FIND] <phone>
[GRAB] <phone>
Task 4:
[QUESTION]

C.3 Chi tiết Đào tạo
Embedding Toolken được đào tạo với tỷ lệ học 1e-4, thực hiện dừng sớm dựa trên tập phát triển, với tối đa 10 epoch.

D Tài nguyên Tính toán
Về tài nguyên tính toán, chúng tôi đào tạo và kiểm tra ToolkenGPT dựa trên LLaMA-13B và LLaMA-33B sử dụng lần lượt 2 và 4 GPU Nvidia RTX 3090.

E Tuyên bố Bảo vệ
Trong bài báo này, chúng tôi chủ yếu tập trung vào các ứng dụng của các vấn đề toán học, dựa trên kiến thức, và lập kế hoạch thể hiện, không đặt ra mối quan ngại đạo đức hoặc có hại đáng kể. Chúng tôi nhận ra rằng nghiên cứu tương lai về các ứng dụng biên giới của việc học công cụ có thể đặt ra rủi ro lạm dụng, và chúng tôi khuyến nghị xem xét cẩn thận tất cả các khía cạnh an toàn trước khi nó được áp dụng trong thế giới thực.

# 2310.07088.pdf
# Converted from PDF to TXT
# Source path: /home/admin88/arxiv-downloader/planning/2310.07088.pdf
# File size: 814667 bytes

===============================================
PDF FILE CONTENT
===============================================


--- PAGE 1 ---
Diversity of Thought Improves Reasoning Abilities of LLMs
Ranjita Naik†
MicrosoftVarun Chandrasekaran
University of Illinois Urbana-Champaign
Mert Yuksekgonul
Stanford UniversityHamid Palangi
Microsoft ResearchBesmira Nushi†
Microsoft Research
Abstract
Large language models (LLMs) are docu-
mented to struggle in settings that require com-
plex reasoning. Nevertheless, instructing the
model to break down the problem into smaller
reasoning steps, or ensembling various genera-
tions through modifying decoding steps boosts
performance. However, these methods assume
that the input prompt is fixed and expect the
decoding strategies to introduce the diversity
needed for ensembling. In this work, we dis-
cuss how one can create and leverage variations
of the input prompt as a means of diversity of
thought . We propose a method that automati-
cally improves prompt diversity by soliciting
feedback from the LLM to ideate approaches
that are apt for the problem. We then ensem-
ble the diverse prompts in our method DIV-
SE(DIVerse reasoning path Self-Ensemble)
across multiple inference calls, or use diverse
approaches within a single inference call; we
call the latter IDIV-SE(In-call DIVerse rea-
soning path Self-Ensemble). Apart from our
approaches outperforming prior work, DIV-SE
(in particular) advances state-of-the-art perfor-
mance on the challenging planning and graph
coloring benchmarks. Our results improve the
Pareto frontier of the accuracy-cost trade-off.
1 Introduction
Large language models (LLMs) exhibit state-of-
the-art performance across a myriad of tasks, but
their effectiveness is strongly influenced by prompt
design (Anil et al., 2023; OpenAI, 2023a; Nori
et al., 2023). For complex reasoning tasks, the
right prompt can enable LLMs to capitalize on task
structure (Guidance, 2024), such as by facilitating
memory (by externalizing thought processes), or
through tractable problem decomposition (Zhou
et al., 2024). However, existing prompt design
2Correspondence to ranjitan@microsoft.com and
besmira.nushi@microsoft.com .either relies on iterative trial-and-error (White et al.,
2023), or is expensive (Lester et al., 2021).
Previous works identified two simple, yet gen-
eral prompting principles to enable complex rea-
soning: (i) Chain-of-Thought (CoT) prompting,
and (ii) ensembling multiple solutions from di-
verse decoding paths. CoT prompting (Wei
et al., 2022) improves performance by guiding
the LLM to follow step-by-step reasoning. Self-
consistency (SC) (Wang et al., 2023) instead in-
creases the stochasticity by modifying the decoding
process and obtaining multiple completions, which
are then ensembled.
However, combining the two principles raises
limitations. First, inference is significantly more
expensive due to numerous runs, each generating
long completions with many reasoning steps. Next,
it may be impermissible to modify the decoding
process in some settings, such as commercial de-
ployments. Finally, stochasticity-based methods
do not directly guide the diversity at the level of
thought or method, but rather at the token level.
This poses limitations because linguistic token di-
versity does not always ensure diverse and indepen-
dent solution approaches.
In this paper, we explore how to explicitly pro-
mote the diversity of thought while mitigating the
aforementioned issues. Prior work by Li et al.
(2023) highlights the importance of prompt diver-
sity, but their notion of diversity is captured through
variety in the few-shot examples provided with the
prompt; ours focuses on the reasoning approach.
We first solicit the LLM to produce multiple-high-
level reasoning approaches for problem-solving
(e.g.,method of elimination, visualization
techniques etc. for math reasoning problems).
We then leverage GPT-4 to augment few-shot ex-
amples used in prior work (Wei et al., 2022) into the
corresponding approaches, whenever applicable.
We propose DIV-SE(DIVerse reasoning path
Self-Ensemble) to extract and aggregate responsesarXiv:2310.07088v2  [cs.CL]  23 Feb 2024

--- PAGE 2 ---
0 5 10 15
Total Inference Cost ( $)57.560.062.565.067.570.072.5Accuracy (%)
CoTIDIV-5DIV-SE-3DIV-SE-5
SC-5SC-10SC-20SC-40AQUA, GPT-3.5 Turbo
25 50 75 100
Total Inference Cost ( $)40455055606570
CoTIDIV-SE-3DIV-SE-3DIV-SE-5
SC-3 SC-5SC-7SC-10Blocksworld 4/5, GPT-4
2.5 5.0 7.5 10.0
Total Inference Cost ( $)20406080100
CoTIDIV-SE-3DIV-SE-3
SC-3SC-5SC-7 SC-10Graph Coloring, GPT-4Figure 1: Diversity of Thought enhances the inference cost vs. accuracy trade-off. We compare DIV-SE and
IDIV-SE with SC (Wang et al., 2023) and CoT (Wei et al., 2022) across three benchmarks. The x-axis indicates the
total inference cost (as defined in § 3) on the benchmark using the given method, while the y-axis represents the
LLM’s performance. The few-shot-CoT setting is represented by filled gray dots, while the zero-shot-CoT setting is
indicated by unfilled dots. Notice that for a fixed cost, our approaches always give better performance.
(via majority vote) across multiple inference calls
(§ 2.2). Since distinct approaches introduce diver-
sity at the “thought” level, our methodology re-
sults in improved ensemble accuracy. In Fig. 1, we
show that it yields more accurate results across
multiple reasoning benchmarks at a fixed infer-
ence cost, without modifying the decoding pro-
cedure. For instance, in the BLOCKSWORLD 4/5
task (Valmeekam et al., 2022), DIV-SEimproves
the performance by 29.6 percentage points (p.p).
However, this method still leverages multiple infer-
ence calls, which could be costly.
To reduce inference costs, we build on the obser-
vation that the approaches are often mutually inde-
pendent, and can be combined in a single prompt
to solicit multiple solutions (Cheng et al., 2023).
Based on this premise, we propose IDIV-SE(In-
call DIVerse reasoning path Self-Ensemble; § 2.2),
which combines all approaches within the same
prompt and aggregates all resulting outputs to lever-
age diversity with a reduced cost. Fig. 1 demon-
strates that this method obtains comparable accu-
racy to DIV-SEand better performance than prior
work with lower inference costs.
We push the pareto frontier of the cost-accuracy
trade-off of prompting strategies across multiple
reasoning tasks (§ 4), outperforming both CoT and
SC prompting on both GPT-3.5 and GPT-4. This
is evident from Fig. 1 for the AQUA-RAT (Ling
et al., 2017), planning (Valmeekam et al., 2023),
and graph coloring (Stechly et al., 2023) bench-
marks, where there is a performance improvement
of 16.52, 29.6, and 82.5 p.p respectively. These
improvements, some of which are state-of-the-art,
show the potential of thought diversity to extractcomplex reasoning abilities from LLMs that were
impossible to leverage otherwise. We will open
source our code upon publication to encourage fur-
ther research.
2 Diversity through LLM Interactions
First, we introduce terms and notations that we use
throughout the paper. We use upper case for sets,
lower case for variables, and [n] ={1,···, n}.
Approach: These are reasoning strategies for prob-
lem solving, denoted with the variable a. For exam-
ple, for the GSM8K (Cobbe et al., 2021), a bench-
mark of grade-school math problems , some of the
(generated) approaches can include a1=“using
visualizations” ,a2=“working backwards” ,
a3=“using direct calculation” , and
a4=“method of elimination” .
Persona: In addition to specifying “how” to solve
a reasoning problem, specifying a persona can
also influence how the LLM behaves (Salewski
et al., 2023). We denote this with the variable
pe.g.,p1=“Thinking like Alan Turing” ,
p2=“Thinking like Math Professor” for the
GSM8K task. Note that both approaches and per-
sonas are dependent on the reasoning problem.
2.1 Using the LLM as a guide
Proposed method for creating prompts, which we
term DIVERSE PROMPTING is presented in Algo-
rithm 1. Below, we will describe each step in more
detail. At a high-level, we solicit feedback from
the LLM on how to solve tasks.
Step 1+2. Extracting Approaches & Personas:
Note that LLMs trained on internet-scale data en-
code a significant knowledge from multiple do-

--- PAGE 3 ---
Q: Michael had 58 golf balls. On tuesday, he lost 23 golf balls. 
On wednesday, he lost 2 more. How many golf balls did he have 
at the end of wednesday?
A: Michael started with 58 golf balls. After losing 23 on tuesday, 
he had 58 - 23 = 35. After losing 2 more, he had 35 - 2 = 33 
golf balls. The answer is 33.
Q: A candle melts by 2 centimeters every hour that it burns. 
How many centimeters shorter will a candle be after burning 
from 1:00 PM to 5:00 PM?Input
Q: Michael had 58 golf balls. On tuesday, he lost 23 golf balls. On 
wednesday, he lost 2 more. How many golf balls did he have at the 
end of wednesday?
A: Approach 1 <Using direct calculation> : Subtract the total 
number of golf balls lost from (…) Therefore, he had 33 golf balls 
at the end of Wednesday.
Approach 2 <Using algebra>:  Let x be the number of golf balls 
Michael had (…) we find that Michael had 33 golf balls at the end 
of Wednesday.
Approach 3 <Using visualization>:  Represent the problem 
using a diagram with three stages: (…) leaving him with 33 golf 
balls at the end of Wednesday.
Q: A candle melts by 2 centimeters every hour that it burns. How 
many centimeters shorter will a candle be after burning from 1:00 
PM to 5:00 PM?Approach 1 <using hypothetical numbers> : Assume a starting 
length for the candle, say 100 centimeters.  (…) The candle will be 8 
centimeters shorter. The answer is 8 centimeters.
Approach 2 <using stepwise reduction> : Let x be the original 
length of the candle. After 4 hours( …) the candle will be 2 
centimeters shorter at the end of 4 hours. The answer is 2 
centimeters.
Approach 3 <using rate and time> : The rate of the candle melting 
is 2 centimeters per hour. So, if we multiply the rate by the time it 
burns, we (…)At 5:00 PM, the candle is 8 centimeters shorter than 
its original length. The answer is 8 centimeters.InputOutputA: If a candle melts by 2 centimeters every hour and it burns 
from 1:00 PM to 5:00 PM, we can assume it burns for a total of 
4 hours. 4 divided by 2 is 2.the candle would be 2 centimeters 
shorter after burning from 1:00 PM to 5:00 PM. The answer is 2 
centimeters.CoT Prompting
 IDIV-SE PromptingOutputFigure 2: Diversity of Thought . This illustration depicts CoT and IDIV-SEprompting strategies. Notice that both
have a single example. However, IDIV-SEpresents more diversity in terms of reasoning paths. This enables it to
generate diverse completions, yielding more accurate responses.
mains (Liang et al., 2022; Bubeck et al., 2023).
While LLMs may not be perfect at solving reason-
ing tasks, we hypothesize that they are helpful in
providing high-quality intermediate feedback.
To extract approaches, we utilize the following
methodology: (i) Randomly picking a question
from the reasoning dataset Dwe want to evaluate;
and (ii) Creating an instruction prompt where we
ask the LLM to generate the names of b∈[1,5]
approaches to solve the aforementioned question
conforming to a predefined template (for easier
post-processing). Refer to Figure 5 for an example
of the prompt used.
We extract the part of the response that is com-
pliant with the template and store it. We repeat
this process ctimes (obtaining of c·bcandidate ap-
proaches), and pick the nmost frequent approaches
to store in set A1. This process is abstracted as
methoddet_approaches(.) .
One can repeat the above process used to extract
relevant personas for a given reasoning task. How-
ever, we followed a simpler route and asked the
model directly for relevant personas for a given
1In practice, we set c= 100 ,b= 5,n∈ {3,5}, and
|V|<20.task and then included them in the set of mcandi-
date personas Pused. This is abstracted as method
det_personas(.) . Note that no persona ( ϕ) is
also part of the persona set.
Step 3. Choosing the Best Persona, Approach
Pairs: The choice of persona and approaches intro-
duces a principled way to promote diversity.
If the set of personas is P, and the set of ap-
proaches is A, the Cartesian product of PandA
yields the total number of prompts. In practice, for
each combination (denoted by si) of persona and
approach, we evaluate the prompt formed using
the composition on a small validation set V1and
choose the best performing “ size ” elements on the
given task2.
Step 4. Augmenting few-shot examples: Once
the (subset of) approach and persona pairs are fixed,
we ask the LLM to augment existing few-shot ex-
amples (denoted F={f1,···}) with the given set
of approaches. Specifically, we take the few-shot
examples provided by Wei et al. (2022), and ask
the LLM to solve them in the style of a chosen
approach and persona pair (Fig.8); we term the
2For a given reasoning task, we perform this process
once (for GPT-3.5 Turbo), and re-use our selection across
all LLMs we evaluate.

--- PAGE 4 ---
DIVERSE PROMPTING : Prompt creation.
procedure DIVERSE PROMPT (size, type ,F, D, V )
▷Step 1: Identify different approaches to be used.
A={a1, . . . , a n} ←det_approaches (D)
▷where Ais the set of approaches
▷Step 2: Identify different personas to be used.
P={ϕ, p 1, . . . , p m} ←det_personas (D)
▷where Pis the set of personas
▷Step 3: Find the best combination.
S={s1, . . . ssize} ←combine (A, P,size, V)
▷where Sis the set of combined approaches and per-
sonas, and si= (p, ai∈A)
▷Step 4: Augment the few-shot examples.
T={˜Ti,j, . . .} ←augment (S, F)
▷where Tis the set of augmented examples, and ˜Ti,j
is formed using si∈Sandfj∈F;|T|=size
▷Step 5: Compose the final prompt.
O←compose (T, S,type)
return O
▷Return the final output.
end procedure
output augmented few-shot examples . This is ab-
stracted in method augment(.) , where ˜Ti,jis the
set of augmented few-shot examples corresponding
to the approach and persona pair from siand ex-
ample fj. An example is visualized in the bottom
left of Fig. 2, where the prompt contains different
approaches for solving a math problem.
2.2 Designing the Prompts
Step 5. Prompt Composition: We create prompts
for our approach using the best approach and per-
sona pairs identified in step 3, and augmented few-
shot examples from step 4 as shown in Fig. 2 and 4.
We now describe two techniques to generate
prompts with the augmented demonstrations ( T)
that have been accumulated.
Candidate 1. DIV-SE:We first propose DIV-SE
(DIVerse reasoning path Self-Ensemble), a method
to execute the diverse set of approaches in different
inference calls and aggregate their solutions. Apart
from the question to be solved and the augmented
few-shot examples, the final prompt contains a per-
sona, approach, and additional instructions. One
example is visualized in Fig. 4 (please refer to
appendix for more examples of prompts: Fig. 9
through 16). Diversity is ensured through running
inference with multiple prompts, each with a dif-
ferent approach and persona pairs and augmented
few-shot examples. However, since the approaches
are executed separately, generating a solution (viaaggregation of multiple responses) requires multi-
ple inference calls, which can be costly.
Candidate 2. IDIV-SE:To further reduce the
inference costs while promoting diversity, we pro-
pose IDIV-SE(In-call DIVerse reasoning path Self-
Ensemble). In IDIV-SE,the final prompt is a com-
position of all approach and persona pairs and
corresponding augmented few-shot examples, and
the question to be solved . An example is presented
in Fig. 2 (bottom left). More examples of prompts
are presented in the appendix in Fig. 9 through 16.
This noticeably decreases the number of calls to be
made, since all few-shot examples are presented
within the same prompt. We note that there might
be error propagation due to the autoregressive na-
ture of models. We evaluate this in detail in § 4.3.
Practicality. Crucially, DIVERSE PROMPTING
finds approaches that are general and reusable
across similar reasoning problems. We reused the
strategies identified for solving AQUA-RAT and
Planning benchmark respectively in the MATH
(counting and probability) and Graph Coloring
benchmarks. This also reduces the cost of repeated
evaluation on a separate evaluation set.
Aggregation. We aggregate the responses via ma-
jority vote for both prompting strategies. Other
aggregation strategies can also be leveraged, such
as utilizing the LLM itself to aggregate responses
or weighted aggregation. In § 4.4, we consider
an aggregation strategy proposed by Yoran et al.
(2023) and describe how compatible it is with our
prompting approaches.
3 Experiments
We consider the following reasoning benchmarks.
Arithmetic Reasoning : We use: (i) AQUA-
RAT (Ling et al., 2017), a suite of algebraic word
problems, (ii) GSM8K (Cobbe et al., 2021), a
benchmark of grade-school math problems de-
scribed in natural language (involving elementary
arithmetic operations), and (iii) MATH (Counting
and Probability) (Hendrycks et al., 2021), a collec-
tion of math problems from which we choose only
counting and probability as these are not covered
byGSM8K andAQUA-RAT . For all datasets, we
use thetest split for evaluation, containing 254,
1319, and 474 questions respectively.
Planning Capabilities : We use the Blocksworld
Planning benchmark proposed in Valmeekam et al.
(2022, 2023). The benchmark has two datasets:
one involves 3 blocks ( BLOCKSWORLD 3, 100

--- PAGE 5 ---
5 10 15 20
Total Inference Cost ( $)65707580859095Accuracy (%)
CoTIDIV-SE-3DIV-SE-3DIV-SE-5
SC-3SC-5SC-7SC-10Blocksworld 3, GPT-4
0 25 50 75 100
Total Inference Cost ( $)707580859095
CoTIDIV-SE-3DIV-SE-3DIV-SE-5
SC-3SC-5 SC-7SC-10Blocksworld 3, GPT-4
10 20 30
Total Inference Cost ( $)82848688
CoTIDIV-SE-5DIV-SE-3DIV-SE-5
SC-3SC-5SC-7SC-10GSM8K, GPT-3.5 TurboFigure 3: Diversity of Thought enhances the inference cost and accuracy trade-off. We compare DIV-SEand
IDIV-SEwith SC (Wang et al., 2023) and CoT (Wei et al., 2022) across three benchmarks. The x-axis indicates the
total cost (as defined in § 3) of running inference with the LLM on the benchmark using the given method, while the
y-axis represents the LLM’s performance. The FS-CoT setting is represented by filled gray dots, while the ZS-CoT
setting is indicated by unfilled dots. Notice that for BLOCKSWORLD 3, despite being in the ZS-CoT setting, our
approaches are more performant than the SC- s(FS-CoT) baseline.
instances), while the other dataset involves 4 or 5
blocks (B LOCKSWORLD 4/5, 500 instances).
Constraint Satisfaction Optimization : We use the
GRAPH COLORING benchmark (Stechly et al.,
2023) containing 100 examples to test reasoning
for constraint satisfaction. Commonsense Reason-
ing: We use COMMONSENSE QA(Talmor et al.,
2019) which consists of generic multiple-choice
questions elicited for testing common sense reason-
ing. We use the validation split containing 1,221
questions.
Language Models. We evaluate our proposed
methods on both GPT-3.5 Turbo (OpenAI, 2022)
and GPT-4 (OpenAI, 2023b). We also conduct an
additional evaluation on LLaMA-2 70B (Touvron
et al., 2023) to explore the performance of our tech-
nique on open-source LLMs. For the latter, we use
meta-llama/Llama-2-70b-chat-hf through the
Transformers library (Wolf et al., 2019).
Baselines. We consider Chain-of-Thought
(CoT) (Wei et al., 2022) and Self-Consistency
(SC ) (Wang et al., 2023) as our baselines. For CoT,
we consider two settings: zero-shot (ZS) CoT (Ko-
jima et al., 2022) (i.e., “ Think step by step ”
is added to the prompt), and few-shot (FS) CoT
(i.e., CoT with demonstrations). In our SC runs,
we set the temperature T= 0.7without top- k
truncation and sample up to s∈[1,10]outputs
(denoted SC- s). For all other approaches, we set
T= 0. We use ensembles of size 5 in IDIV-SE
andDIV-SEforGSM8K andAQUA-RAT . For
the planning, GRAPH COLORING , and COMMON -
SENSE QA benchmarks, we use a size of 3.
Performance Metrics. We measure the accuracy
on the task, and the generation inference cost.Tomeasure the cost, we assume 1000 tokens are about
750 words3. For GPT-4 (8K) the input and output
prices used to estimate inference cost are $0.03/1k
tokens and $0.06/1k tokens, respectively. For GPT
3.5 Turbo (16K), the input and output prices used
in the cost estimation are $0.003/1k (tokens) and
$0.004/1k (tokens) respectively.
Results Summary. include: Across most bench-
marks we consider, our techniques provide sub-
stantial performance gains (e.g., 16.52, 82.5, and
14.3 p.p improvements for AQUA-RAT ,GRAPH
COLORING , and MATH respectively). They are
also Pareto optimal (in terms of the utility vs. cost
trade-off). For the challenging planning benchmark
(BLOCKSWORLD 4/5), our techniques improve ac-
curacy by 29.6 p.p achieving state-of-the-art perfor-
mance. Using GPT-4 for BLOCKSWORLD 3, our
approach (in the ZS-CoT setting) is substantially
more effective than SC-10 (in the FS-CoT setting)
at 4×lower cost (Figure 3 (center figure)).
Since prompts are chained together in IDIV-SE,
error propagation is possible. Our evaluation on
AQUA-RAT in § 4.3 suggests that even though
error propagation is estimated as less than 6.5% for
both models, these rates are comparable to differ-
ences in performance between DIV-SEandIDIV-
SE. When combined with aggregation approaches
that are capable of reasoning across the diverse
generations (Yoran et al., 2023), we observe addi-
tional performance gains as shown in § 4.4. For
theAQUA-RAT benchmark for instance, we see
an accuracy of 67.7% for GPT-3.5 (3.23 p.p im-
provement to majority voting).
3https://openai.com/pricing

--- PAGE 6 ---
Method Graph Coloring BW 3 BW 4/5
CoT 15.0 70.00 40.00
SC-3 18.0 66.00 38.20
SC-5 20.0 70.00 38.40
SC-7 22.0 72.00 40.00
SC-10 23.0 73.00 41.20
IDIV-SE 74.00 82.00 57.00
DIV-SE 97.00 94.00 69.60
Table 1: Performance on GRAPH COLORING and
BLOCKSWORLD planning for GPT-4 in the ZS-CoT set-
ting. We compare DIV-SEandIDIV-SEwith SC (Wang
et al., 2023) and CoT (Wei et al., 2022).
4 Results
4.1 Main Results
We present the summary of results in Table 1 and
2. Detailed results are available in Appendix C.
These also cover results on the impact of ensemble
size in Appendix D.
Setting Method AQuA MATH CQA
GPT-3.5 ZSCoT 59.00 31.90 71.40
SC-3 61.40 32.07 72.00
SC-5 63.37 38.19 72.80
IDIV-SE 62.60 42.50 74.00
DIV-SE 72.83 44.94 74.50
GPT-3.5 FSCoT 57.48 30.38 79.4
IDIV-SE 64.57 44.10 80.00
DIV-SE 72.84 52.22 80.40
GPT-4 ZSCoT 70.47 62.24 81.60
IDIV-SE 71.65 72.00 82.50
DIV-SE 80.31 79.11 81.70
GPT-4 FSCoT 71.90 66.46 87.70
IDIV-SE 79.90 72.00 89.00
DIV-SE 84.25 80.76 88.00
Table 2: Performance on AQUA-RAT ,MATH (Count-
ing and Probability), and COMMONSENSE QAfor GPT-
3.5 Turbo and GPT-4 in the ZS-CoT and few-shot-CoT
settings respectively.
4.1.1 Arithmetic reasoning via AQ UA-RAT
GPT-4 Results: In Table 2, we observe that DIV-SE
achieves an accuracy increase of 9.84 and 14.6 p.p
in the FS-CoT (baseline accuracy of 71.9%) and
ZS-CoT (baseline of 70.47%) settings, respectively.
While the gains from IDIV-SEare nominal in ZS-
CoT, it achieves a boost of 7.7 p.p for FS-CoT.
GPT-3.5 Results: In Table 2, we see that DIV-SE
yields a gain of 14.23 and 16.52 p.p in the FS-
CoT (baseline of 57.48%) and ZS-CoT (baseline
of 59%) settings, respectively. Within the FS-CoT
setting, IDIV-SEgets an absolute increase of 7 p.p.
Note that Fig. 1 also displays the total inference
cost. Both IDIV-SEandDIV-SEarePareto opti-
mal, indicating their capacity to achieve a higheraccuracy while maintaining low costs.
4.1.2 Counting and probabilistic reasoning
via MATH
GPT-4 Results: From Table 2, we see that DIV-SE
achieves an accuracy increase of 14.3 and 16.87 p.p
in the FS-CoT (baseline of 66.46%) and ZS-CoT
(baseline of 62.24%) settings, respectively. On
the other hand, IDIV-SEachieves a boost of 5.54
and 9.76 p.p in the FS-CoT and ZS-CoT settings,
respectively, over the baseline.
GPT-3.5 Results: From Table 2, we see that DIV-
SEyields a gain of 21.84 and 13.04 p.p in the FS-
CoT (baseline of 30.38%) and ZS-CoT (baseline
of 31.90%) settings, respectively. Likewise IDIV-
SEachieves a boost of 13.72 and 10.60 p.p in the
FS-CoT and ZS-CoT settings, respectively.
4.1.3 Planning via B LOCKSWORLD
Setup: The benchmark provides both natural lan-
guage and Planning Definition and Domain Lan-
guage prompts (McDermott et al., 1998). We
use natural language prompts in all the experi-
ments. For the baseline runs, we introduce mi-
nor alterations to the prompt originally proposed
by Valmeekam et al. (2023). These changes in-
volve incorporating an explicit directive to prevent
under-block movement and resolving minor lan-
guage ambiguities we observed to be problematic
during initial investigation. Furthermore, we repo-
sition the initial condition and goal state informa-
tion to the beginning of the prompt. The modified
improved prompt is presented in Fig. 9.
We aggregate the plans through majority voting
and utilize string matching for comparing the plans.
As a result, we optimize the plan by eliminating
the redundant “ no-op ” steps.
GPT-4 Results: We note that GPT-4 performs
slightly better in a ZS setting, and use this to run
all experiments. From Fig. 1, we observe that for
BLOCKSWORLD 3, ZS-CoT records an accuracy
of 70%, while SC-10 reaches an accuracy level of
73%. IDIV-SEenhances the absolute accuracy by
12 p.p above the ZS-CoT baseline, while DIV-SE
produces an impressive state-of-the-art accuracy of
94%. An analysis of the six unsuccessful instances
suggests the capacity for further performance im-
provement by increasing the size of the ensemble,
as already two out of five current approaches gen-
erate accurate plans. For the BLOCKSWORLD 4/5
case, the ZS-CoT accuracy is 40%, while SC-10
has an accuracy of 41.2%. Here, IDIV-SEresults

--- PAGE 7 ---
in an absolute gain of 17 p.p above the ZS-CoT
baseline, and DIV-SEtoo enhances performance,
leading to 69.6%. As outlined in Fig. 1 and 3, both
IDIV-SEand D IV-SEachieve Pareto optimality .
GPT-3.5 Results: The baseline performance on
BLOCKSWORLD 3is 6%, and on BLOCKSWORLD
4/5is 0.6%. We do not see any additional im-
provement using both IDIV-SEandDIV-SE. Qual-
itatively, we observe that during plan generation,
GPT-3.5 fails to follow the restrictions provided as
part of the problem instructions too often, leading
to either infeasible or incorrect plans. This shows
instruction following capabilities are crucial to the
success of the methods proposed here.
4.1.4 Constraint Satisfaction via GRAPH
COLORING
There may exist numerous non-optimal yet valid
colorings for a given graph. Since exact string
matching is not usable for identifying the majority
solution from the ensembles of IDIV-SEandDIV-
SE, we employ the external, sound verifier (Stechly
et al., 2023) to pick the correct solution.
GPT-4 Results: From Fig. 1, it is observed that
ZS-CoT achieves an accuracy of 15%, whereas
SC-10 attains an accuracy level of 23%. IDIV-SE
improves the absolute accuracy by 59 p.p above
the ZS-CoT baseline. Remarkably, DIV-SEdeliv-
ers a state-of-the-art accuracy of 97%. Given that
GPT-4’s performance plateaus in the ZS setting, we
chose to omit conducting the few-shot experiments.
Summary: Methods in this work often demon-
strate state-of-the-art performance on reasoning
tasks. This is most significant in the planning
and constraint satisfaction benchmarks, where the
corresponding authors claimed immense difficulty
for existing LLMs. Our work shows that status-
quo prompt design approaches including chain of
thought are too generic for these problems, and
prompt customization (via DIVERSE PROMPTING )
can yield substantial gains by guiding the chain of
thought to the general nature of the problem.
4.2 Open Source Models
Due to the limited computational budget, we
only performed experiments with the AQUA-RAT
benchmark. Please refer to Appendix B for fur-
ther details. Table 3 demonstrates the results for
LLaMA-2 70B with 8-bit quantization. DIV-SE
andIDIV-SEdemonstrate an improvement of over
10 p.p over the baseline in the FS-CoT settings.
However, the gain in the ZS-CoT setting has beennegligible. We hypothesize that this is partly due to
model’s lack of capabilities to both follow instruc-
tions and the mentioned approach in the absence of
examples.
Prompting Strategy ZS-CoT (%) FS-CoT (%)
CoT 31.32 29.1
IDIV-SE 27.00 39.7
DIV-SE 32.00 39.9
Table 3: Results on AQ UA-RAT and LLaMA-2 70B.
4.3 Errors & Prompt Utility
Error Propagation: Due to the autoregressive na-
ture of LLM decoding, early incorrect answers in
IDIV-SEmay get propagated to the latter ones.
To quantify this, we select examples where the
solution is incorrect and all five approaches pro-
duce the same erroneous answer. We focus only
on these cases to see if e.g., a wrong conclusion
in the initial approaches leaks into the following
ones. Next, we attempt the last two approaches
again in a separate session: if the LLM generates
the same outcomes as in the original session (i.e.,
IDIV-SEsetup) within 3 attempts, we consider it
as no error propagation. However, if it does not
produce the same answer within the 3 attempts, we
interpret this as a case of error propagation since
the change in answer could be attributed to the ini-
tial approaches with wrong answers in the chain.
We measure this phenomenon on AQUA-RAT (FS-
CoT) on both GPT-4 and GPT-3.5. We find that
GPT-4 and GPT-3.5 have error propagation rates
of 6.2% and 5.5% respectively, which are compa-
rable to performance differences between DIV-SE
andIDIV-SE,making error propagation one of the
main explanatory hypotheses for the differences be-
tween the two methods . Reducing these error rates
remains a challenging problem given the autore-
gressive nature of current LLMs.
Beyond Thinking Step by Step: The diverse ap-
proaches and personas we utilize not only enhance
the performance in IDIV-SEandIDIV-SE, but are
also independently superior to ZS-CoT. Table 4
highlights this effect, which showcases the impor-
tance of conditioning the model for solutions via
DIVERSE PROMPTING .
4.4 Alternative Aggregation Strategies
Our aggregation thus far relies on majority voting.
Alternatively, we can also utilize the meta reason-
ing technique proposed by Yoran et al. (2023) to

--- PAGE 8 ---
Dataset, Model Persona, Approach Accuracy (%)
AQUA-RAT, GPT-3.5∅,Think step by step 57.48
∅, Using Algebra 60.24 (+2.76)
Thinking like Alan Turing, ∅ 61.81 (+4.33)
Dr. Patel: A renowned mathematician, ∅ 65.75 (+8.27)
BLOCKSWORLD 4/5, GPT-4∅, State tracking prompt (Valmeekam et al., 2022) 42.00
∅, Finite State Machine 55.80 (+13.80)
Alan Turing, Action Rationale 57.80 (+15.80)
Alan Turing, Progressive Block Placement Approach 58.80 (+16.80)
Table 4: Prompts, derived from approaches and personas, boost performance. Blue rows denote ZS-CoT
prompts, while black lines denote FS-CoT prompts. ∅denotes absence (of persona or approach respectively).
Method GPT-4 (%) GPT-3.5 (%)
Majority V oting 79.90 64.47
Meta Reasoning 79.24 67.70
Table 5: Alternative aggregation strategies. Observe
that, for the AQUA-RAT benchmark (FS-CoT), IDIV-
SEproduces more accurate results only with GPT-3.5.
accumulate the results and exploit the rich infor-
mation present in the reasoning steps. To this end,
we store the responses generated by IDIV-SE, and
request the model to meta reason over them in a dif-
ferent prompt and session. Table 5 suggests that the
proposed reasoning paths contain rich information
that is effectively exploited by the meta reasoning
aggregation. Future post-hoc techniques may con-
sider to learn the accuracy of the diverse prompting
approaches, and weigh them accordingly. Nev-
ertheless, the fact that techniques presented here
provide visible improvements even with simple ap-
proaches like majority voting, demonstrates their
added value independently from different aggrega-
tion algorithms.
5 Related Work
Prompt Optimization: Pryzant et al. (2023) mod-
els the prompts as optimizable discrete variables,
and minimizes the loss of the reasoning task. Jones
et al. (2023) optimize over the prompt space, but
to identify failure modes. However, optimization-
based approaches often require the task to have a
differentiable loss function, which is a strong con-
dition. In our work, we utilize feedback from the
LLM (not through gradients) during prompt design.
Similarly to Cheng et al. (2023), ID IV-SEbatches
the responses for multiple queries within a prompt.
Decoding Optimizations and Tools: Wang et al.
(2023) replace the naive greedy decoding by sam-
pling a diverse set of reasoning paths (e.g., through
temperature sampling), and then selects the most
consistent answer. Chen et al. (2022) express thereasoning process as a program, which is then del-
egated to an external tool. In our work, we neither
change the decoding process nor assume the ex-
istence of trusted tools. This makes our solution
directly applicable to black-box models.
Prompting Strategies: Brown et al. (2020) note
that demonstrations to prompts, encoded as input-
output pairs, produce drastic performance increase
in larger LLMs. Wei et al. (2022) encourage in-
ternal dialogue by forcing the LLM to generate a
sequence of intermediate steps for reasoning prob-
lems. This improves reasoning performance on
larger LLMs (Nye et al., 2021; Chung et al., 2022;
Kojima et al., 2022). Zhou et al. (2022) automat-
ically break a complex problem into simpler sub-
problems and then solve them in sequence. Across
all these techniques, the common practice is to keep
the prompts fixed, but aggregate responses across
multiple trials by varying the temperature. In our
work, we vary the input prompt itself. A work that
is similar in spirit is that of Yoran et al. (2023),
which instead of aggregating the response of mul-
tiple reasoning paths, forces the model to reason
across them before aggregation. Another relevant
work is that of Li et al. (2023), which shows the
importance of prompt diversity. However, they rely
on selecting few-shot demonstrations from a hold-
out set (which defines diversity in their method),
without explicitly stating reasoning pathways.
6 Conclusions
In this work, we promoted diversity of thought
as a principled prompting strategy and proposed
methodologies that leverage the LLM as a guide to
design a diverse set of approaches to solve complex
reasoning tasks. Extracting solution approaches
from LLMs themselves becomes a discovery mech-
anism that seeds and conditions generative solu-
tions. Reported results on a variety of tasks confirm
that there is a large space for improvement in com-

--- PAGE 9 ---
plex reasoning by uncovering the necessary skills
and knowledge from LLMs through targeted and
diverse prompting methods. These results demon-
strated how promoting diversity can improve the
Pareto frontier of accuracy-cost trade-off for cur-
rent LLMs and yield state-of-the-art solutions for
planning and mathematical reasoning tasks. We
hope that future work will expand these results to
complex tasks from other real-world applications.
7 Limitations
Our study mainly experimented with GPT-3.5
and GPT-4 models because of their instruction-
following capabilities. While current open-source
models have shown remarkable improvements to
this end, they are still not able to reliably follow
instructions relevant to complex reasoning tasks
(e.g. state tracking, plan validity, constraint satis-
faction). We hope that progress in the field will
enable further experimentation in this direction.
In addition, we also observe that error propaga-
tion during autoregressive generation may some-
times negatively impact the performance of IDIV-
SE, where all approaches are executed in order
within the same prompt. Some of this could be
addressed by explicitly instructing the model to
forget about the previous solution but ultimately
as long as previous generation history remains in
context and short-term memory, error propagation
risks may still need to be tracked and measured.
References
Rohan Anil, Andrew M Dai, Orhan Firat, Melvin John-
son, Dmitry Lepikhin, Alexandre Passos, Siamak
Shakeri, Emanuel Taropa, Paige Bailey, Zhifeng
Chen, et al. 2023. Palm 2 technical report. arXiv
preprint arXiv:2305.10403 .
Tom Brown, Benjamin Mann, Nick Ryder, Melanie
Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind
Neelakantan, Pranav Shyam, Girish Sastry, Amanda
Askell, Sandhini Agarwal, Ariel Herbert-V oss,
Gretchen Krueger, Tom Henighan, Rewon Child,
Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens
Winter, Chris Hesse, Mark Chen, Eric Sigler, Ma-
teusz Litwin, Scott Gray, Benjamin Chess, Jack
Clark, Christopher Berner, Sam McCandlish, Alec
Radford, Ilya Sutskever, and Dario Amodei. 2020.
Language models are few-shot learners. In Ad-
vances in Neural Information Processing Systems ,
volume 33, pages 1877–1901. Curran Associates Inc.
Sébastien Bubeck, Varun Chandrasekaran, Ronen El-
dan, Johannes Gehrke, Eric Horvitz, Ece Kamar,Peter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lund-
berg, et al. 2023. Sparks of artificial general intelli-
gence: Early experiments with gpt-4. arXiv preprint
arXiv:2303.12712 .
Wenhu Chen, Xueguang Ma, Xinyi Wang, and
William W. Cohen. 2022. Program of thoughts
prompting: Disentangling computation from reason-
ing for numerical reasoning tasks.
Zhoujun Cheng, Jungo Kasai, and Tao Yu. 2023. Batch
prompting: Efficient inference with large language
model apis.
H. W. Chung, L. Hou, S. Longpre, B. Zoph, Y . Tay,
W. Fedus, E. Li, X. Wang, M. Dehghani, and
S. Brahma. 2022. Scaling instruction-finetuned lan-
guage models. arXiv preprint arXiv:2210.11416 .
Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian,
Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias
Plappert, Jerry Tworek, Jacob Hilton, Reiichiro
Nakano, Christopher Hesse, and John Schulman.
2021. Training verifiers to solve math word prob-
lems.
Tim Dettmers, Mike Lewis, Younes Belkada, and Luke
Zettlemoyer. 2022a. Llm. int8 (): 8-bit matrix mul-
tiplication for transformers at scale. arXiv preprint
arXiv:2208.07339 .
Tim Dettmers, Mike Lewis, Sam Shleifer, and Luke
Zettlemoyer. 2022b. 8-bit optimizers via block-wise
quantization. 9th International Conference on Learn-
ing Representations, ICLR .
Guidance. 2024. A guidance language for control-
ling large language models. https://github.com/
guidance-ai/guidance .
Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul
Arora, Steven Basart, Eric Tang, Dawn Song, and
Jacob Steinhardt. 2021. Measuring mathematical
problem solving with the math dataset.
Erik Jones, Anca Dragan, Aditi Raghunathan, and Ja-
cob Steinhardt. 2023. Automatically auditing large
language models via discrete optimization. arXiv
preprint arXiv:2303.04381 .
T. Kojima, S. S. Gu, M. Reid, Y . Matsuo, and Y . Iwa-
sawa. 2022. Large language models are zero-shot
reasoners. In Advances in Neural Information Pro-
cessing Systems .
Brian Lester, Rami Al-Rfou, and Noah Constant. 2021.
The power of scale for parameter-efficient prompt
tuning. arXiv preprint arXiv:2104.08691 .
Yifei Li, Zeqi Lin, Shizhuo Zhang, Qiang Fu, Bei Chen,
Jian-Guang Lou, and Weizhu Chen. 2023. Making
language models better reasoners with step-aware
verifier. In Proceedings of the 61st Annual Meet-
ing of the Association for Computational Linguistics
(Volume 1: Long Papers) , pages 5315–5333.

--- PAGE 10 ---
Percy Liang, Rishi Bommasani, Tony Lee, Dimitris
Tsipras, Dilara Soylu, Michihiro Yasunaga, Yian
Zhang, Deepak Narayanan, Yuhuai Wu, Ananya Ku-
mar, et al. 2022. Holistic evaluation of language
models. arXiv preprint arXiv:2211.09110 .
Wang Ling, Dani Yogatama, Chris Dyer, and Phil Blun-
som. 2017. Program induction by rationale genera-
tion: Learning to solve and explain algebraic word
problems. In Proceedings of the 55th Annual Meet-
ing of the Association for Computational Linguistics
(Volume 1: Long Papers) , pages 158–167, Vancouver,
Canada. Association for Computational Linguistics.
Drew McDermott, Malik Ghallab, Adele E Howe,
Craig A Knoblock, Ashwin Ram, Manuela M Veloso,
Daniel S Weld, and David E Wilkins. 1998. Pddl-the
planning domain definition language.
Harsha Nori, Yin Tat Lee, Sheng Zhang, Dean Carig-
nan, Richard Edgar, Nicolo Fusi, Nicholas King,
Jonathan Larson, Yuanzhi Li, Weishung Liu, et al.
2023. Can generalist foundation models outcom-
pete special-purpose tuning? case study in medicine.
arXiv preprint arXiv:2311.16452 .
Michael Nye, Anders J Andreassen, Guy Gur-Ari, Hen-
ryk Michalewski, Jacob Austin, David Bieber, David
Dohan, Aitor Lewkowycz, Marten Bosma, Daan
Luan, et al. 2021. Show your work: Scratchpads
for intermediate computation with language models.
arXiv preprint arXiv:2112.00114 .
OpenAI. 2022. Introducing chatgpt.
OpenAI. 2023a. Gpt-4 technical report.
OpenAI. 2023b. Gpt-4 technical report.
Reid Pryzant, Dan Iter, Jerry Li, Yin Tat Lee, Chen-
guang Zhu, and Michael Zeng. 2023. Automatic
prompt optimization with" gradient descent" and
beam search. arXiv preprint arXiv:2305.03495 .
Leonard Salewski, Stephan Alaniz, Isabel Rio-Torto,
Eric Schulz, and Zeynep Akata. 2023. In-context im-
personation reveals large language models’ strengths
and biases. arXiv preprint arXiv:2305.14930 .
Kaya Stechly, Matthew Marquez, and Subbarao Kamb-
hampati. 2023. Gpt-4 doesn’t know it’s wrong: An
analysis of iterative prompting for reasoning prob-
lems. arXiv preprint arXiv:2310.12397 .
Alon Talmor, Jonathan Herzig, Nicholas Lourie, and
Jonathan Berant. 2019. CommonsenseQA: A ques-
tion answering challenge targeting commonsense
knowledge. In Proceedings of the 2019 Conference
of the North American Chapter of the Association for
Computational Linguistics: Human Language Tech-
nologies, Volume 1 (Long and Short Papers) , pages
4149–4158, Minneapolis, Minnesota. Association for
Computational Linguistics.Hugo Touvron, Louis Martin, Kevin Stone, Peter Al-
bert, Amjad Almahairi, Yasmine Babaei, Nikolay
Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti
Bhosale, et al. 2023. Llama 2: Open founda-
tion and fine-tuned chat models. arXiv preprint
arXiv:2307.09288 .
Karthik Valmeekam, Matthew Marquez, Sarath Sreed-
haran, and Subbarao Kambhampati. 2023. On the
planning abilities of large language models – a criti-
cal investigation.
Karthik Valmeekam, Alberto Olmo, Sarath Sreedharan,
and Subbarao Kambhampati. 2022. Large language
models still can’t plan (a benchmark for llms on plan-
ning and reasoning about change). arXiv preprint
arXiv:2206.10498 .
Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le,
Ed Chi, Sharan Narang, Aakanksha Chowdhery, and
Denny Zhou. 2023. Self-consistency improves chain
of thought reasoning in language models.
Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten
Bosma, Brian Ichter, Fei Xia, Ed Chi, Quoc Le, and
Denny Zhou. 2022. Chain of thought prompting
elicits reasoning in large language models. In Con-
ference on Neural Information Processing Systems
(NeurIPS) .
Jules White, Quchen Fu, Sam Hays, Michael Sandborn,
Carlos Olea, Henry Gilbert, Ashraf Elnashar, Jesse
Spencer-Smith, and Douglas C Schmidt. 2023. A
prompt pattern catalog to enhance prompt engineer-
ing with chatgpt. arXiv preprint arXiv:2302.11382 .
Thomas Wolf, Lysandre Debut, Victor Sanh, Julien
Chaumond, Clement Delangue, Anthony Moi, Pier-
ric Cistac, Tim Rault, Rémi Louf, Morgan Funtowicz,
et al. 2019. Huggingface’s transformers: State-of-
the-art natural language processing. arXiv preprint
arXiv:1910.03771 .
Ori Yoran, Tomer Wolfson, Ben Bogin, Uri Katz, Daniel
Deutch, and Jonathan Berant. 2023. Answering
questions by meta-reasoning over multiple chains
of thought. arXiv preprint arXiv:2304.13007 .
Denny Zhou, Nathanael Schärli, Le Hou, Jason Wei,
Nathan Scales, Xuezhi Wang, Dale Schuurmans,
Claire Cui, Olivier Bousquet, Quoc Le, and Ed Chi.
2022. Least-to-most prompting enables complex rea-
soning in large language models. arXiv preprint
arXiv:2205.10625 .
Pei Zhou, Jay Pujara, Xiang Ren, Xinyun Chen, Heng-
Tze Cheng, Quoc V Le, Ed H Chi, Denny Zhou, Swa-
roop Mishra, and Huaixiu Steven Zheng. 2024. Self-
discover: Large language models self-compose rea-
soning structures. arXiv preprint arXiv:2402.03620 .

--- PAGE 11 ---
Appendix
APrompt used for DIVERSE PROMPTING
Our diverse prompting strategy for IDIV-SEand
DIV-SEis showcased in Fig. 2 and Fig. 4 respec-
tively. The instrumental prompt template that de-
termines our approaches is presented in Fig. 5.
B Model Details
B.1 Open-Source Models
We perform the Llama-2 70B experiments with
a single 80GB A100 GPU. To fit the 70B model
to a single A100, we use 8-bit precision through
bitsandbytes (Dettmers et al., 2022a,b). Further,
Dettmers et al. (2022a) reports no performance
drop with this quantization method.
As the system prompt, we use You are a
helpful, respectful and honest assistant.
We perform inference with greedy decoding, hav-
ing temperature T= 0.
C Additional Results
In this section, we provide additional results on
COMMONSENSE QA and GSM8K benchmarks.
C.1 Common sense via C OMMONSENSE QA
Table 2 presents the results of the experiments.
Overall, the improvements in accuracy are rela-
tively modest. This is likely because answering
questions in COMMONSENSE QAdoes not demand
as much reasoning and thought diversity as is re-
quired in some other benchmarks. In addition, the
dataset also contains a number of ambiguous ques-
tions, which if read verbatim may have many plau-
sible answers but the ground truth contains only
one answer.
C.2 Arithmetic reseasoning via GSM8K
GPT-4 Results: As shown in Fig. 6, accuracy on
GSM8K have nearly plateaued, with the ZS-CoT
and FS-CoT baselines achieving accuracies of 94%
and 95% respectively. IDIV-SEdoes not produce
any significant gains in either setting. On the other
hand, DIV-SEreaches accuracy of 96.3% in both
FS-CoT and ZS-CoT settings, providing a modest
improvement.
GPT-3.5 Results: Here, the gains are more substan-
tial. Compared to the ZS-CoT baseline of 76.11%,
IDIV-SEprovides an improvement of 5.31 p.p.
DIV-SEgoes a step further, enhancing the accu-
racy by 10.39 p.p. In the FS-CoT setting, DIV-SEposts an accuracy improvement of 7.68 p.p (with a
baseline accuracy of 81.4%).
Fig. 3 (rightmost) presents the cost vs. accu-
racy trade-offs between IDIV-SE,DIV-SE, and SC.
While the performance of SC does improve with
the expansion of reasoning paths, both IDIV-SE
and D IV-SEoffer better trade-offs.
D Evaluating Ensemble Sizes
Figure 6 depicts the average accuracy of differ-
ent ensemble sizes on GSM8K for both ZS-CoT
and FS-CoT settings, utilizing GPT-4 and GPT-3.5.
Similarly, Figure 7 demonstrates the average accu-
racy of various ensemble sizes on AquA for both
ZS-CoT and FS-CoT settings, using GPT-4 and
GPT-3.5. It is noteworthy that in both AQuA and
GSM8K, even an ensemble of size three yields sig-
nificant performance improvements over the base-
line, which we attribute to the high diversity and
independence of reasoning paths.
E Prompt Templates
The following section provides a comprehensive vi-
sual representation of the prompts used in our study.
These prompts, depicted in Figures 9 through 16,
were used in different settings and for the plan-
ning, AQuA, and graph coloring benchmarks, and
incorporate various personas and approaches.
Figure 9 illustrates the prompt used in the base-
line run, Figure 10 demonstrates the prompt em-
ployed when applying a Finite State Machine ap-
proach, Figure 11 depicts the prompt used when
incorporating the persona of Alan Turing and an
Action Rationale approach, and lastly, Figure 12
shows the prompt used when applying the persona
of Alan Turing and the Progressive Block Place-
ment approach in the zero-shot setting for the plan-
ning benchmark.
Figure 13 illustrates the algebraic approach,
while Figure 14 and Figure 15 demonstrate the
prompts incorporating the personas of Alan Turing
and Dr. Patel, a renowned mathematician, respec-
tively, in the few-shot-CoT setting for the AQuA
benchmark.
In Figure 16 we present the IDIV-SEprompt
used in the zero-shot setting for the graph coloring
benchmark.

--- PAGE 12 ---
Q: Michael had 58 golf balls. On tuesday, he lost 23 golf balls. On wednesday, 
he lost 2 more. How many golf balls did he have at the end of wednesday?
<Using direct calculation>:  Subtract the total number of golf balls lost from 
(…) Therefore, he had 33 golf balls at the end of Wednesday.
Q: A candle melts by 2 centimeters every hour that it burns. How many 
centimeters shorter will a candle be after burning from 1:00 PM to 5:00 PM? <using direct calculation>: The candle burns 
for 4 hours from 1:00 PM to 5:00 PM. (…) The 
candle will be 8 centimeters shorter. The answer 
is 8 centimeters.Input 1Output 1DIV-SE Prompting
Q: Michael had 58 golf balls. On tuesday, he lost 23 golf balls. On wednesday, 
he lost 2 more. How many golf balls did he have at the end of wednesday?
<Using visualization>: Represent the problem using a diagram with three 
stages: (….) leaving him with 33 golf balls at the end of Wednesday.
Q: A candle melts by 2 centimeters every hour that it burns. How many 
centimeters shorter will a candle be after burning from 1:00 PM to 5:00 PMInput 2
<using algebra>: Let x be the original length 
of the candle. After 4 hours( …) the candle will 
be 2 centimeters shorter at the end of 4 hours. 
The answer is 2 centimeters.Output 2
Q: Michael had 58 golf balls. On tuesday, he lost 23 golf balls. On wed,lost 2 
more. How many golf balls did he have at the end of wednesday?
<Using algebra>: Let x be the number of golf balls Michael had …we find 
that Michael had 33 golf balls at the end of Wednesday.
Q: A candle melts by 2 centimeters every hour that it burns. How many 
centimeters shorter will a candle be after burning from 1:00 PM to 5:00 PM?<using visualization>: Here's the visual 
representation:
|----------------- |  (original length)
|-------- |           (1 hour later)
|----|               (2 hours later)
(…)At 5:00 PM, the candle is 8 centimeters 
shorter than its original length. The answer is 8 
centimeters.
Output 3Input 3Figure 4: D IV-SEprompting.
Use five distinct approaches to solve the given problem accurately. If there is no exact match choose the closest
option.
Q: {Question}
Use the following output format:
Approach 1 < name of the approach > : < Details of Approach 1 >
Approach 2 < name of the approach > : < Details of Approach 2 >
Approach 3 < name of the approach > : < Details of Approach 3 >
Approach 4 < name of the approach > : < Details of Approach 4 >
Approach 5 < name of the approach > : < Details of Approach 5 >
Figure 5: Prompt template for extracting diverse approaches for problem solving.

--- PAGE 13 ---
1 2 3 4 5
Ensemble Size767880828486Average accuracy (%)DIV-SE
CoT
IDIV-SE-5
GPT-3.5, ZS-CoT
1 2 3 4 5
Ensemble Size8082848688
GPT-3.5, FS-CoT
1 2 3 4 5
Ensemble Size94.094.595.095.596.0
GPT-4, ZS-CoT
1 2 3 4 5
Ensemble Size95.295.495.695.896.096.2
GPT-4, FS-CoTFigure 6: Average accuracy for different ensemble sizes on GSM8K for ZS-CoT and FS-CoT settings on GPT-4
and GPT-3.5. Note that all graphs are zoomed in.
1 2 3 4 5
Ensemble Size60.062.565.067.570.072.5Average Accuracy (%)DIV-SE
CoT
IDIV-SE-5
GPT-3.5, ZS-CoT
1 2 3 4 5
Ensemble Size57.560.062.565.067.570.072.5
GPT-3.5, FS-CoT
1 2 3 4 5
Ensemble Size707274767880
GPT-4, ZS-CoT
1 2 3 4 5
Ensemble Size72747678808284
GPT-4, FS-CoT
Figure 7: Average accuracy for different ensemble sizes on AQUA-RAT for ZS-CoT and FS-CoT settings on
GPT-4 and GPT-3.5. Note that all graphs are zoomed in.

--- PAGE 14 ---
Input Prompt
Solve the problem accurately using {approach name}.
Question: John found that the average of 15 numbers is 40. If 10 is added to
each number then the mean of the numbers
Answer Choices: (A) 50 (B) 45 (C) 65 (D) 78 (E) 64
A: If 10 is added to each number, then the mean of the numbers also increases by 10. So
the new mean would be 50. The answer is (A).
Approach <using {approach name} >:
Augmented Few-shot Examples
Approach <using visualization> :
To solve this problem using visualization, let’s consider the given information and the effect
of adding 10 to each number on the average.
1. The average of 15 numbers is 40. This means that the sum of these 15 numbers is 15
* 40 = 600.
2. Now, we add 10 to each number. Since there are 15 numbers, the total added is 15 *
10 = 150.
3. The new sum of the 15 numbers is 600 + 150 = 750.
4. To find the new average, we divide the new sum by the number of values, which is
750 / 15 = 50. So, the mean of the numbers after adding 10 to each number is 50. The
answer is: (A) 50
Approach <using logical reasoning> :
We know that adding the same constant to each number in a set will increase the average
by that constant. In this case, we are adding 10 to each number, so the average will
increase by 10. New average = 40 + 10 = 50 The answer is: (A) 50
Approach <using elimination strategy> :
We know that adding 10 to each number will increase the average by 10. So, we’re looking
for an answer choice that is 10 more than the original average of 40.
(A) 50 is 10 more than 40.
(B) 45 is only 5 more than 40.
(C) 65 is 25 more than 40.
(D) 78 is 38 more than 40.
(E) 64 is 24 more than 40.
Only (A) 50 is exactly 10 more than the original average of 40, so that’s the correct answer.
The other choices can be eliminated because they are not 10 more than the original average.
Approach <using algebra> :
Let’s denote the sum of the 15 numbers as S. Since the average of the 15 numbers is 40,
we can write the equation: S / 15 = 40 S = 40 * 15 = 600 Now, we add 10 to each
number, so the new sum is S + 15 * 10 = 600 + 150 = 750. The new average is: New
average = 750 / 15 = 50 The answer is: (A) 50
Figure 8: Illustration of Augmentation of few-shot examples - Algorithm 1, Step 4

--- PAGE 15 ---
I am playing with a set of blocks where I need to arrange the blocks into stacks.
[STATEMENT]
As initial conditions I have that, the orange block is clear, the hand is empty, the blue
block is on top of the red block, the orange block is on top of the blue block and the red
block is on the table. My goal is to have that the red block on top of the blue block and
the orange block on top of the red block.
Here are the actions I can do:
Pick up a block from the table
Unstack a block from on top of another block
Put down a block on the table
Stack a block on top of another block
I have the following restrictions on my actions:
I can only pick up or unstack one block at a time.
I can only pick up or unstack a block if my hand is empty.
I can only pick up a block if the block is on the table and the block is clear. A block is
clear if the block has no other blocks on top of it and if the block is not picked up.
I can only unstack a block from on top of another block if the block I am unstacking was
really on top of the other block.
I can only unstack a block from on top of another block if the block I am unstacking is
clear.
Once I pick up or unstack a block, I am holding the block.
I can only put down a block that I am holding.
I can only stack a block on top and not under of another block if I am holding the block
being stacked.
I can only stack a block on top and not under of another block if the block onto which I
am stacking the block is clear.
Once I put down or stack a block, my hand becomes empty.
Once you stack a block on top of a second block, the second block is no longer clear.
What is the plan to achieve my goal? Just give the actions in the plan.
[PLAN]
Figure 9: Zero-shot prompt used in the baseline run of the Planning - Blocksworld Domain

--- PAGE 16 ---
You are playing with a set of blocks where you need to arrange the blocks into stacks.
What is the plan to achieve the goal?
<Initial State> : As initial conditions you have that, the orange block is clear, the
hand is empty, the blue block is on top of the red block, the orange block is on top of the
blue block and the red block is on the table.
<Goal State> : Your goal is to have that the red block on top of the blue block and the
orange block on top of the red block.
Here are the actions you can do:
-Pick up a block from the table
-Unstack a block from on top of another block
-Put down a block on the table
-Stack a block on top of another block
Rules:
1. You can only pick up or unstack one block at a time.
2. You can only pick up or unstack a block if your hand is empty.
3. You can only pick up a block if the block is on the table and the block is clear. A block
is clear if the block has no other blocks on top of it and if the block is not picked up.
4. You can only unstack a block from on top of another block if the block you are
unstacking was really on top of the other block.
5. You can only unstack a block from on top of another block if the block you are
unstacking is clear.
6. Once you pick up or unstack a block, you are holding the block.
7. You can only put down a block that you are holding.
8. You can only stack a block on top and not under of another block if you are holding
the block being stacked.
9. You can only stack a block on top and not under of another block if the block onto
which you are stacking the block is clear.
10. Once you put down or stack a block, your hand becomes empty.
11. Once you stack a block on top of a second block, the second block is no longer clear.
Using a finite state machine and a search algorithm what is the plan to achieve the
goal? You can model each state of the blocks configuration on the table and the hand as
a state. For each action step check that the step follows the rules and that the step brings
you closer to the goal. After each action describe the state of the table and hand. Always
check whether the final state satisfies the goal mentioned. <Goal State> : Your goal is to
havethattheredblockontopoftheblueblockandtheorangeblockontopoftheredblock.
[PLAN]
Figure 10: The Zero-shot prompt using Finite State Machine Approach for solving the Planning - Blocksworld
Domain Problem.

--- PAGE 17 ---
You are playing with a set of blocks where you need to arrange the blocks into stacks.
<Initial State> : As initial conditions you have that, the orange block is clear, the
hand is empty, the blue block is on top of the red block, the orange block is on top of the
blue block and the red block is on the table.
<Goal State> : Your goal is to have that the red block on top of the blue block
and the orange block on top of the red block.
Here are the actions you can do:
-Pick up a block from the table
-Unstack a block from on top of another block
-Put down a block on the table
-Stack a block on top of another block
Rules:
1. You can only pick up or unstack one block at a time.
2. You can only pick up or unstack a block if your hand is empty.
3. You can only pick up a block if the block is on the table and the block is clear. A block
is clear if the block has no other blocks on top of it and if the block is not picked up.
4. You can only unstack a block from on top of another block if the block you are
unstacking was really on top of the other block.
5. You can only unstack a block from on top of another block if the block you are
unstacking is clear.
6. Once you pick up or unstack a block, you are holding the block.
7. You can only put down a block that you are holding.
8. You can only stack a block on top and not under of another block if you are holding
the block being stacked.
9. You can only stack a block on top and not under of another block if the block onto
which you are stacking the block is clear.
10. Once you put down or stack a block, your hand becomes empty.
11. Once you stack a block on top of a second block, the second block is no longer clear.
Thinking like Alan Turing starting from the <Initial State> build a plan to get to
the <Goal State>. For each action step carefully check that the step follows the rules.
<Goal State> : Your goal is to have that the red block on top of the blue block and the
orange block on top of the red block.
output format for each step until you reach the goal state:
<state> : <state>
<action> : < action to be performed in this step >
<assess the action> : < are we building the stack bottom up, check carefully>
Figure 11: The Zero-shot prompt used with the persona of Alan Turing and Action Rationale approach for solving
the Planning - Blocksworld Domain Problem.

--- PAGE 18 ---
You are playing with a set of blocks where you need to arrange the blocks into stacks.
<Initial State> : As initial conditions you have that, the orange block is clear, the
hand is empty, the blue block is on top of the red block, the orange block is on top of the
blue block and the red block is on the table.
<Goal State> : Your goal is to have that the red block on top of the blue block and the
orange block on top of the red block.
Here are the actions you can do:
-Pick up a block from the table
-Unstack a block from on top of another block
-Put down a block on the table
-Stack a block on top of another block
Rules:
1. You can only pick up or unstack one block at a time.
2. You can only pick up or unstack a block if your hand is empty.
3. You can only pick up a block if the block is on the table and the block is clear. A block
is clear if the block has no other blocks on top of it and if the block is not picked up.
4. You can only unstack a block from on top of another block if the block you are
unstacking was really on top of the other block.
5. You can only unstack a block from on top of another block if the block you are
unstacking is clear.
6. Once you pick up or unstack a block, you are holding the block.
7. You can only put down a block that you are holding.
8. You can only stack a block on top and not under of another block if you are holding
the block being stacked.
9. You can only stack a block on top and not under of another block if the block onto
which you are stacking the block is clear.
10. Once you put down or stack a block, your hand becomes empty.
11. Once you stack a block on top of a second block, the second block is no longer clear.
Thinking like Alan Turing, starting from the <Initial State> build a plan to get to
the <Goal State> . For each action step carefully check that the step follows the
rules. Divide the task into smaller steps, starting with placing the bottom block first,
followed by the middle blocks, and finally the top block. <Goal State> : Your goal is to
havethattheredblockontopoftheblueblockandtheorangeblockontopoftheredblock.
[PLAN]
Figure 12: The Zero-shot prompt used in the Alan Turing + Progressive Block Placement Approach for solving the
Planning - Blocksworld Domain Problem.

--- PAGE 19 ---
As a math professor, you will solve the given problem accurately ’<using algebra>’. If
there is no exact match choose the closest option.
Question: John found that the average of 15 numbers is 40. If 10 is added to each number
then the mean of the numbers
Answer Choices: (A) 50 (B) 45 (C) 65 (D) 78 (E) 64
Approach: <using algebra>
Let’s denote the sum of the 15 numbers as S. Since the average of the 15 numbers is 40,
we can write the equation: S / 15 = 40 S = 40 * 15 = 600 Now, we add 10 to each
number, so the new sum is S + 15 * 10 = 600 + 150 = 750. The new average is: New
average = 750 / 15 = 50
The answer is: (A) 50
Question: If a / b = 3/4 and 8a + 5b = 22,then find the value of a.
Answer Choices: (A) 1/2 (B) 3/2 (C) 5/2 (D) 4/2 (E) 7/2
Approach: <using algebra>
To solve the given problem, we can use substitution. Since a / b = 3/4, we can write that
as: a = 3b/4 Now, substitute this expression for a into the second equation: 8(3b/4) +
5b = 22 Simplify and solve for b: 6b + 5b = 22 11b = 22 b = 2 Now that we have the
value of b, we can find the value of a: a = 3b/4 a = 3(2)/4 a = 6/4 a = 3/2 So, the
value of a is (B) 3/2.
The answer is: (B) 3/2
Question: A person is traveling at 20 km/hr and reached his destiny in 2.5 hr then find
the distance?
Answer Choices: (a) 53 km (b) 55 km (c) 52 km (d) 60 km (e) 50 km
Approach: <using algebra>
Using the formula distance = speed ×time, we can calculate the distance as follows:
Distance = 20 km/hr ×2.5 hr = 50 km So, the closest answer choice is (e) 50 km.
The answer is: (e) 50 km
Question: How many keystrokes are needed to type the numbers from 1 to 500?
Answer Choices: (a) 1156 (b) 1392 (c) 1480 (d) 1562 (e) 1788
Approach: <using algebra>
Let’s break down the number of keystrokes needed into groups based on the number of
digits: One-digit numbers (1-9): There are 9 one-digit numbers, so we need 9 keystrokes.
Two-digit numbers (10-99): There are 90 two-digit numbers, each requiring 2 keystrokes,
so we need 90 * 2 = 180 keystrokes. Three-digit numbers (100-500): There are 401
three-digit numbers (500 - 100 + 1), each requiring 3 keystrokes, so we need 401 * 3 =
1203 keystrokes. Now let’s add up the keystrokes from all groups: 9 + 180 + 1203 =
1392. Therefore, the closest option is (b) 1392.
The answer is: (b) 1392
Figure 13: AQuA few-shot-CoT prompt using algebraic approach.

--- PAGE 20 ---
Think like Alan Turing and solve the problem.If there is no exact match choose the closest
option.
Question: John found that the average of 15 numbers is 40. If 10 is added to
each number then the mean of the numbers
Answer Choices: (A) 50 (B) 45 (C) 65 (D) 78 (E) 64
Approach : <think like Alan Turing>
Let’s analyze the problem step by step: The average of 15 numbers is 40. So, the sum of
these 15 numbers is 15 * 40 = 600. 10 is added to each number. Now, since there are 15
numbers, the total increase in the sum will be 15 * 10 = 150. The new sum of these 15
numbers will be 600 + 150 = 750. To find the new mean, divide the new sum by the total
number of values, which is 15. New mean = 750 / 15 = 50. Therefore, the closest option
to the new mean is (A) 50.
The answer is: (A) 50
Question: If a / b = 3/4 and 8a + 5b = 22,then find the value of a.
Answer Choices: (A) 1/2 (B) 3/2 (C) 5/2 (D) 4/2 (E) 7/2
Approach : <think like Alan Turing>
Let us analyze the given information and solve the problem step by step. We are given
that a / b = 3/4, which can be written as a = (3/4) * b. We are also given the equation
8a + 5b = 22. Substitute the value of a from step 1 into the equation from step 2: 8 *
(3/4) * b + 5b = 22 Simplify the equation: 6b + 5b = 22 Combine the terms and solve
for b: 11b = 22 b = 2 Now that we have the value of b, let’s find the value of a using the
equation from step 1: a = (3/4) * b a = (3/4) * 2 Simplify to find the value of a: a =
3/2 Thus, the value of a is 3/2, which corresponds to answer choice (B).
The answer is: (B)
Question: A person is traveling at 20 km/hr and reached his destiny in 2.5 hr then
find the distance?
Answer Choices: (a) 53 km (b) 55 km (c) 52 km (d) 60 km (e) 50 km
Approach : <think like Alan Turing>
To find the distance, we can use the formula: distance = speed ×time. In this case, the
speed is 20 km/hr and the time is 2.5 hours. Distance = 20 km/hr ×2.5 hr = 50 km So,
the closest option is (e) 50 km.
The answer is: (e) 50 km
Question: How many keystrokes are needed to type the numbers from 1 to 500?
Answer Choices: (a) 1156 (b) 1392 (c) 1480 (d) 1562 (e) 1788
Approach : <think like Alan Turing>
To determine the number of keystrokes needed to type the numbers from 1 to 500, let’s
break it down by digit count: One-digit numbers (1-9): There are 9 one-digit numbers,
each requiring 1 keystroke. Total: 9 keystrokes. Two-digit numbers (10-99): There
are 90 two-digit numbers, each requiring 2 keystrokes. Total: 90 * 2 = 180 keystrokes.
Three-digit numbers (100-500): There are 401 three-digit numbers, each requiring 3
keystrokes. Total: 401 * 3 = 1203 keystrokes. Adding the keystrokes for each group, we
get: 9 + 180 + 1203 = 1392 keystrokes. Thus, the closest option is (b) 1392
The answer is: (b) 1392
Figure 14: AQuA few-shot-CoT prompt with the persona of Alan Turing.

--- PAGE 21 ---
Think like Dr. Patel, the mathematician who specializes in algebra and solve the problem.
If there is no exact match choose the closest option.
Question: John found that the average of 15 numbers is 40. If 10 is added to
each number then the mean of the numbers
Answer Choices: (A) 50 (B) 45 (C) 65 (D) 78 (E) 64
Approach : <think like Dr. Patel>
Let’s consider the problem step by step. John found that the average of 15 numbers is 40.
To find the sum of these 15 numbers, we can use the formula: Sum = Average ×Number
of elements Sum = 40 ×15 Sum = 600 Now, 10 is added to each of the 15 numbers. So,
we can find the new sum by adding 10 ×15 = 150 to the original sum: New Sum = 600
+ 150 New Sum = 750 To find the new average (mean), we can use the formula: New
Average = New Sum ÷Number of elements New Average = 750 ÷15 New Average = 50
The answer is: (A) 50
Question: If a / b = 3/4 and 8a + 5b = 22,then find the value of a.
Answer Choices: (A) 1/2 (B) 3/2 (C) 5/2 (D) 4/2 (E) 7/2
Approach : <think like Dr. Patel>
To solve this problem, first we can rewrite the equation a / b = 3/4 as a = (3/4)b. Now
we can substitute this expression for a into the second equation: 8a + 5b = 22. Substitute
a with (3/4)b: 8(3/4)b + 5b = 22 Simplify the equation: 6b + 5b = 22 Combine the
terms: 11b = 22 Now, divide both sides by 11: b = 2 Now that we have the value of b,
we can find the value of a using the equation a = (3/4)b: a = (3/4)(2) a = 3/2 The
value of a is 3/2. So, the correct answer is (B) 3/2.
The answer is: (B) 3/2
Question: A person is traveling at 20 km/hr and reached his destiny in 2.5 hr then
find the distance?
Answer Choices: (a) 53 km (b) 55 km (c) 52 km (d) 60 km (e) 50 km
Approach : <think like Dr. Patel>
To find the distance, we can use the formula: Distance = Speed ×Time Here, the speed
is given as 20 km/hr and the time taken is 2.5 hours. So, we can plug these values into
the formula: Distance = 20 km/hr ×2.5 hr Distance = 50 km
The answer is: (e) 50 km
Question: How many keystrokes are needed to type the numbers from 1 to 500?
Answer Choices: (a) 1156 (b) 1392 (c) 1480 (d) 1562 (e) 1788
Approach : <think like Dr. Patel>
To determine the number of keystrokes needed to type the numbers from 1 to 500, let’s
break down the problem by analyzing the number of digits in each range: For numbers
1-9, there are 9 numbers with 1 digit each, requiring 9 keystrokes. For numbers 10-99,
there are 90 numbers with 2 digits each, requiring 90 * 2 = 180 keystrokes. For numbers
100-499, there are 400 numbers with 3 digits each, requiring 400 * 3 = 1200 keystrokes.
For the number 500, it has 3 digits, requiring 3 keystrokes. Now, we can sum up the
keystrokes for each range: 9 (for 1-9) + 180 (for 10-99) + 1200 (for 100-499) + 3 (for
500) = 1392 keystrokes.
The answer is: (b) 1392
Figure 15: AQuA few-shot-CoT prompt with the persona of Dr. Patel: A renowned mathematician

--- PAGE 22 ---
As a math professor, use 3 distinct approaches and without using built-in algorithms, write
python programs to color the following graph, described as a set of edges, such that no
two vertices on the same edge share a color.
You may use at most 3 colors.
Vertex 0 is connected to vertex 7.
Vertex 0 is connected to vertex 8.
Vertex 0 is connected to vertex 9.
Vertex 0 is connected to vertex 11.
Vertex 1 is connected to vertex 13.
Vertex 2 is connected to vertex 9.
Vertex 3 is connected to vertex 8.
Vertex 3 is connected to vertex 11.
Vertex 3 is connected to vertex 12.
Vertex 4 is connected to vertex 12.
Vertex 5 is connected to vertex 11.
Vertex 6 is connected to vertex 9.
Vertex 7 is connected to vertex 10.
Vertex 7 is connected to vertex 13.
Vertex 9 is connected to vertex 11.
Vertex 10 is connected to vertex 13.
Vertex 11 is connected to vertex 13.
There are a total of 14 vertices. Please label every vertex, even if it is disconnected from
the rest of the graph.Please provide each vertex’s color. Do not skip any vertices. Each
color must be provided on a new line in the response and should be formatted as "VERTEX
NUMBER: VERTEX COLOR ASSIGNMENT (Color n)".
Output format:
Approach 1 <name of the approach> : < python program from scratch to color the given
graph accurately >
Approach 2 <name of the approach> : < python program from scratch to color the given
graph accurately>
Approach 3 <name of the approach> : < python program from scratch to color the given
graph accurately>
Figure 16: Graph Coloring prompt using a programming approach in the zero-shot setting.

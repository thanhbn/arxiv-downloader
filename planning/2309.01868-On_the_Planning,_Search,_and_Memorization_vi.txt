# 2309.01868.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/planning/2309.01868.pdf
# Kích thước tệp: 293566 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Về Khả Năng Lập Kế Hoạch, Tìm Kiếm và Ghi Nhớ
của Các Mô Hình Ngôn Ngữ Lớn
Yunhao Yang
Khoa Khoa học Máy tính
Đại học Texas tại Austin
Austin, TX 78705
yunhaoyang234@utexas.eduAnshul Tomar
Khoa Khoa học Máy tính
Đại học Texas tại Austin
Austin, TX 78705
anshulmanas@gmail.com
Tóm tắt
Sự tiến bộ nhanh chóng của các mô hình ngôn ngữ lớn, như loạt Generative Pre-
trained Transformer (GPT), đã có tác động đáng kể trên nhiều lĩnh vực khác nhau. Trong nghiên cứu này, chúng tôi điều tra tiềm năng của mô hình ngôn ngữ lớn hiện đại nhất (GPT-4) cho các tác vụ lập kế hoạch. Chúng tôi khám phá hiệu quả của nó trong nhiều lĩnh vực con của lập kế hoạch, nêu bật cả điểm mạnh và hạn chế. Thông qua một cuộc kiểm tra toàn diện, chúng tôi xác định các lĩnh vực mà các mô hình ngôn ngữ lớn xuất sắc trong việc giải quyết các vấn đề lập kế hoạch và tiết lộ các ràng buộc giới hạn khả năng ứng dụng của chúng. Phân tích thực nghiệm của chúng tôi tập trung vào hiệu suất của GPT-4 trong trích xuất miền lập kế hoạch, lập kế hoạch đường dẫn tìm kiếm đồ thị và lập kế hoạch đối nghịch. Sau đó chúng tôi đề xuất một cách tinh chỉnh mô hình ngôn ngữ lớn cụ thể miền để cải thiện khả năng Chuỗi Tư duy (CoT) cho các tác vụ được đề cập ở trên. Các kết quả cung cấp những hiểu biết có giá trị về các ứng dụng tiềm năng của các mô hình ngôn ngữ lớn trong lĩnh vực lập kế hoạch và mở đường cho nghiên cứu tương lai nhằm vượt qua các hạn chế và mở rộng khả năng của chúng.

1 Giới thiệu
Sự phát triển nhanh chóng của các mô hình ngôn ngữ lớn, như loạt Generative Pretrained Transformer (GPT), tác động đáng kể đến nhiều lĩnh vực khác nhau, từ xử lý ngôn ngữ tự nhiên và trí tuệ nhân tạo đến chăm sóc sức khỏe [Chintagunta et al., 2021, Nori et al., 2023, Thirunavukarasu et al., 2023], tài chính [Leippold, 2023, Wu et al., 2023], và xa hơn nữa [Shin et al., 2020]. Những mô hình này đã cách mạng hóa các tác vụ như dịch máy, phân tích cảm xúc, tóm tắt văn bản và hỏi đáp, nâng cao tương tác giữa con người và máy tính và cho phép truy xuất thông tin hiệu quả và chính xác hơn. Ngoài ra, lượng dữ liệu khổng lồ mà các mô hình này được huấn luyện cho phép chúng tạo ra các phản hồi giống con người và thực hiện các tác vụ từng được coi là độc quyền của trí thông minh con người.

Chúng tôi kiểm tra khả năng của mô hình ngôn ngữ hiện đại nhất hiện tại—GPT-4—về lập kế hoạch và tìm kiếm [OpenAI, 2023]. Mặc dù có hiệu suất ấn tượng trong các tác vụ xử lý ngôn ngữ tự nhiên và khả năng tạo văn bản giống con người, GPT-4 không được thiết kế rõ ràng để thực thi các thuật toán lập kế hoạch hoặc tìm kiếm. Tuy nhiên, nó có thể cung cấp những hiểu biết có giá trị và hướng dẫn về các kỹ thuật lập kế hoạch và tìm kiếm khác nhau cũng như kiến thức cụ thể miền để xây dựng heuristic hoặc đánh giá các phương pháp khác nhau. Cơ sở kiến thức rộng lớn của GPT-4 cho phép người dùng đặt câu hỏi và khám phá các khía cạnh đa dạng của lập kế hoạch và tìm kiếm.

Chúng tôi chỉ ra các lĩnh vực trong lập kế hoạch có thể được giải quyết bởi các mô hình ngôn ngữ lớn và các hạn chế của các mô hình ngôn ngữ. Việc giới thiệu các mô hình ngôn ngữ lớn tác động đáng kể đến nhiều lĩnh vực, như xử lý ngôn ngữ tự nhiên; do đó chúng tôi muốn kiểm tra tác động của nó lên lĩnh vực lập kế hoạch.

Phiên bản này là báo cáo dự án từ CS 395T Planning Search and Reasoning.arXiv:2309.01868v1  [cs.CL]  5 Sep 2023

--- TRANG 2 ---
Các công trình hiện có [Valmeekam et al., 2022, Huang et al., 2022b, Singh et al., 2023, Lin et al., 2023] thể hiện khả năng của các mô hình ngôn ngữ về lập kế hoạch chủ yếu tập trung vào việc tạo kế hoạch nhưng thiếu khám phá tìm kiếm đường dẫn, ghi nhớ trong lập kế hoạch và lập kế hoạch trong các tình huống đối nghịch. Chúng tôi cung cấp một cuộc kiểm tra toàn diện về khả năng của GPT-4 trong lĩnh vực lập kế hoạch và chỉ ra các hạn chế của nó cho nghiên cứu tương lai. Ngoài ra, chúng tôi cố gắng cải thiện hiệu suất của LLM bằng cách tinh chỉnh nó trên các tác vụ như miền lập kế hoạch, tìm kiếm đồ thị và tìm kiếm đối nghịch để xem liệu chúng tôi có thể cải thiện dự đoán của các mô hình này cho những tác vụ được đề cập ở trên. Những mô hình này có khả năng giải quyết các tác vụ lập kế hoạch khác nhau, như cung cấp thông tin chung về các thuật toán lập kế hoạch, tạo heuristic và thảo luận về các kỹ thuật lập kế hoạch khác nhau. Tuy nhiên, chúng không được thiết kế đặc biệt để thực hiện các tác vụ lập kế hoạch trực tiếp, vì chức năng chính của chúng là hiểu và tạo văn bản. Các mô hình ngôn ngữ có hạn chế trong việc xử lý các tình huống tương tác thời gian thực và thiếu khả năng học tập và thích ứng ngoài dữ liệu huấn luyện của chúng. Do đó, trong khi các mô hình ngôn ngữ lớn có thể cung cấp những hiểu biết có giá trị và hướng dẫn trong lĩnh vực lập kế hoạch, tiện ích của chúng bị hạn chế bởi những giới hạn này, và chúng không thể thay thế hoàn toàn các thuật toán hoặc công cụ lập kế hoạch chuyên biệt được thiết kế để giải quyết các vấn đề lập kế hoạch cụ thể.

Chúng tôi cung cấp một phân tích thực nghiệm về cách GPT-4 thực hiện trên trích xuất miền lập kế hoạch, lập kế hoạch đường dẫn tìm kiếm đồ thị và lập kế hoạch đối nghịch. Chúng tôi thấy rằng GPT-4 hiệu quả trong việc trích xuất các thành phần chính của các miền lập kế hoạch từ các mô tả văn bản, cho phép tạo ra các biểu diễn có cấu trúc phù hợp để sử dụng trong các hệ thống lập kế hoạch tự động. Trong tìm kiếm đồ thị, GPT-4 thể hiện khả năng hiểu thuật toán tìm kiếm và tìm đường dẫn tối ưu dựa trên thuật toán. Tuy nhiên, khả năng này bị hạn chế khi đồ thị trở nên phức tạp. Hơn nữa, chúng tôi cho thấy khả năng của nó trong việc tạo heuristic cho lập kế hoạch đối nghịch và hạn chế của nó trong việc thực hiện các thuật toán tìm kiếm đối nghịch. Việc thiếu ghi nhớ trong quá trình lập kế hoạch là một yếu tố chính giới hạn mô hình ngôn ngữ lớn đối với lập kế hoạch trong các tình huống đối nghịch.

2 Công trình liên quan
Một số công trình đã sử dụng các mô hình ngôn ngữ lớn cho lập kế hoạch không-shot; tuy nhiên, việc lập kế hoạch của chúng hoặc giả định rằng miền lập kế hoạch đã được thu thập, hoặc các kết quả là tĩnh. Một số công trình [Yang et al., 2022, Ichter et al., 2022] chỉ tạo ra các kết quả tĩnh, trong khi LLM-Planner [Song et al., 2022] và LM-Nav [Shah et al., 2022] yêu cầu kiến thức trước về các lĩnh vực cụ thể để định nghĩa miền lập kế hoạch. Các công trình hiện có [Huang et al., 2022a, Yang et al., 2022] đã thể hiện khả năng của những mô hình này. Các mô hình ngôn ngữ lớn là nguồn với phạm vi kiến thức rộng, bao gồm kiến thức cụ thể miền. Tuy nhiên, các công trình hiện có chưa đi sâu vào khả năng lập kế hoạch và tìm kiếm của những mô hình này, đặc biệt là trong vấn đề phức tạp hoặc các tình huống đối nghịch.

Trong công trình này, chúng tôi khám phá khả năng của các mô hình ngôn ngữ lớn về tạo miền lập kế hoạch, tìm kiếm đồ thị, ghi nhớ trạng thái lập kế hoạch và lập kế hoạch đối nghịch. Công trình tiết lộ một số hạn chế của các mô hình ngôn ngữ lớn, dẫn đến các hướng tương lai tiềm năng để cải thiện những mô hình này.

3 Kiến thức cơ bản
Mô hình Ngôn ngữ Lớn (LLMs). LLMs là các mô hình học máy được thiết kế để xử lý và hiểu ngôn ngữ tự nhiên, như lời nói và văn bản của con người. Những mô hình này thường là mạng nơ-ron quy mô lớn, được huấn luyện sử dụng lượng dữ liệu khổng lồ, thường ở quy mô hàng tỷ từ hoặc nhiều hơn, để học các mẫu và cấu trúc trong ngôn ngữ.

LLMs có khả năng thực hiện một loạt rộng các tác vụ xử lý ngôn ngữ tự nhiên, như dịch ngôn ngữ, phân tích cảm xúc, phân loại văn bản và nhận dạng giọng nói. Chúng có thể tạo văn bản mới dựa trên lời nhắc đầu vào mà chúng nhận được và tạo nội dung gốc như bài báo, tiểu luận hoặc thậm chí thơ.

Một ví dụ về mô hình ngôn ngữ lớn là loạt GPT của OpenAI (viết tắt của "Generative Pre-trained Transformer") [Brown et al., 2020, OpenAI, 2023], với GPT-4 là phiên bản hiện tại nhất. So với các LLM hiện có, GPT-4 cũng có thể hiểu đầu vào hình ảnh và thực hiện tốt hơn trong lý luận logic. Những mô hình này đã thể hiện hiệu suất đáng kể trên một loạt rộng các tác vụ NLP, cách mạng hóa lĩnh vực AI và cho phép các ứng dụng mới trong nhiều miền khác nhau.

--- TRANG 3 ---
Miền Lập kế hoạch. Miền lập kế hoạch đề cập đến một mô tả chính thức của một không gian vấn đề hoặc môi trường cụ thể [Haslum et al., 2019]. Nó bao gồm các quy tắc, ràng buộc và hành động định nghĩa cấu trúc của vấn đề và các cách mà nó có thể được giải quyết. Mục tiêu của lập kế hoạch tự động là tìm một chuỗi hành động có thể chuyển đổi trạng thái ban đầu của miền thành trạng thái mục tiêu mong muốn.

Một miền lập kế hoạch thường bao gồm các thành phần sau:
• Đối tượng: Các thực thể hoặc mục tồn tại trong miền, như con người, địa điểm hoặc tài nguyên.
• Trạng thái: Mô tả về các điều kiện hoặc cấu hình khác nhau của các đối tượng trong miền.
• Hành động: Các phép toán hoặc bước có thể được thực hiện để sửa đổi trạng thái của miền. Hành động thường có các điều kiện tiên quyết phải được thỏa mãn trước khi chúng có thể được thực thi và các hiệu ứng mô tả cách trạng thái thay đổi khi hành động được thực hiện.
• Trạng thái ban đầu: Cấu hình khởi đầu của miền từ đó quá trình lập kế hoạch bắt đầu.
• Trạng thái mục tiêu: Cấu hình mong muốn hoặc tập hợp các điều kiện mà quá trình lập kế hoạch nhằm đạt được.

Ngôn ngữ Định nghĩa Miền Lập kế hoạch (PDDL) là một ngôn ngữ chính thức được sử dụng để mô tả các vấn đề và miền lập kế hoạch trong lĩnh vực lập kế hoạch tự động. PDDL tách biệt mô tả của một vấn đề lập kế hoạch thành hai phần: miền và vấn đề. Miền định nghĩa cấu trúc chung của vấn đề, bao gồm các hành động có sẵn và hiệu ứng của chúng, trong khi vấn đề chỉ định trạng thái ban đầu và trạng thái mục tiêu cho một trường hợp cụ thể của vấn đề.

Ngoài các thành phần của miền lập kế hoạch chung, PDDL bao gồm một tập hợp các vị từ, là một tập hợp các thuộc tính hoặc quan hệ mô tả trạng thái của các đối tượng trong miền.

Tìm kiếm Đồ thị. Tìm kiếm đồ thị là một loại thuật toán được sử dụng để khám phá và điều hướng đồ thị, là các cấu trúc toán học bao gồm các nút (còn gọi là đỉnh) được kết nối bởi các cạnh. Trong tìm kiếm đồ thị, thuật toán bắt đầu tại một nút cho trước và khám phá đồ thị một cách có hệ thống bằng cách thăm các nút lân cận của nó theo một thứ tự cụ thể cho đến khi nó đạt đến một nút đích hoặc trạng thái mục tiêu.

Mục tiêu của tìm kiếm đồ thị là tìm đường dẫn ngắn nhất hoặc hiệu quả nhất giữa hai nút trong một đồ thị. Có một số loại thuật toán tìm kiếm đồ thị khác nhau, bao gồm:

• Tìm kiếm theo chiều rộng (BFS): Thuật toán này khám phá tất cả các láng giềng của một nút trước khi chuyển sang cấp độ nút tiếp theo. BFS được đảm bảo tìm đường dẫn ngắn nhất giữa hai nút trong một đồ thị không có trọng số.
• Tìm kiếm theo chiều sâu (DFS): Thuật toán này khám phá một nhánh của đồ thị càng xa càng tốt trước khi quay lại và khám phá nhánh khác. DFS có thể được sử dụng để tìm tất cả các đường dẫn giữa hai nút trong một đồ thị, nhưng nó có thể không tìm được đường dẫn ngắn nhất.
• Thuật toán Dijkstra: Thuật toán này được sử dụng để tìm đường dẫn ngắn nhất giữa hai nút trong một đồ thị có trọng số. Nó hoạt động bằng cách gán một khoảng cách tạm thời cho mỗi nút và cập nhật khoảng cách khi nó khám phá đồ thị.
• Tìm kiếm A*: Thuật toán này tương tự như thuật toán Dijkstra nhưng sử dụng một hàm heuristic để hướng dẫn việc tìm kiếm hướng tới nút mục tiêu. Tìm kiếm A* thường được sử dụng trong tìm đường trong trò chơi điện tử.

Các thuật toán tìm kiếm đồ thị có thể được sử dụng để giải quyết một loạt rộng các vấn đề, nhưng việc lựa chọn thuật toán phụ thuộc vào vấn đề cụ thể và các đặc điểm của đồ thị được tìm kiếm.

Lập kế hoạch Đối nghịch. Lập kế hoạch đối nghịch là một loại vấn đề lập kế hoạch trong đó người lập kế hoạch được yêu cầu tạo ra một kế hoạch có thể dự đoán và phản ứng với các hành động của một tác nhân đối nghịch. Trong loại vấn đề này, người lập kế hoạch phải tính đến các hành động của đối thủ và cố gắng tìm một kế hoạch tối đa hóa cơ hội thành công trong khi giảm thiểu tác động của các hành động của đối thủ.

Lập kế hoạch đối nghịch thường được sử dụng trong lý thuyết trò chơi, nơi nó được sử dụng để mô hình hóa các chiến lược và hành động của hai hoặc nhiều người chơi tham gia vào một trò chơi. Trong bối cảnh này, người lập kế hoạch phải dự đoán các hành động của đối thủ và phát triển một chiến lược tối đa hóa cơ hội chiến thắng.

--- TRANG 4 ---
Có một số phương pháp tiếp cận lập kế hoạch đối nghịch, bao gồm mini-max, trong đó mục tiêu của các tác nhân là tối đa hóa phần thưởng hoặc tiện ích của riêng họ trong khi giảm thiểu phần thưởng hoặc tiện ích của đối thủ, và Tìm kiếm Cây Monte Carlo (MCTS), sử dụng thuật toán tìm kiếm để mô phỏng các kết quả có thể của hành động của người lập kế hoạch và phản ứng của đối thủ.

Lập kế hoạch đối nghịch là một vấn đề thách thức vì nó yêu cầu người lập kế hoạch không chỉ xem xét mục tiêu của riêng họ mà còn cả mục tiêu và khả năng của các tác nhân đối thủ. Do đó, nó thường liên quan đến việc ra quyết định phức tạp và yêu cầu các thuật toán và kỹ thuật tinh vi.

4 Tạo Miền Lập kế hoạch
Trong phần này, chúng tôi xây dựng một phương pháp tạo miền lập kế hoạch sử dụng mô hình ngôn ngữ lớn. Để tạo miền lập kế hoạch, chúng tôi áp dụng quy trình sau: truy vấn một mô tả ngắn gọn về tác vụ cho GPT và chuyển đổi các phản hồi thành PDDL. Nếu chúng tôi có kiến thức tác vụ trước, chúng tôi có thể gửi nó cho GPT và yêu cầu nó tạo PDDL từ kiến thức đó. Phương pháp này cho phép các nhà thiết kế tác vụ có được kiến thức tác vụ trong một biểu diễn chính thức, bất kể thông tin trước mà các nhà thiết kế tác vụ có. Hơn nữa, sau khi tạo các miền lập kế hoạch, nhà thiết kế tác vụ có thể có được một kế hoạch tác vụ bằng cách thực hiện tìm kiếm đường dẫn đơn giản. Chúng tôi cũng cho thấy khả năng của GPT-4 về tìm kiếm đường dẫn trong các phần sau.

Chúng tôi bắt đầu thí nghiệm với một tác vụ đời thường—băng qua đường—để kiểm tra khả năng tạo miền lập kế hoạch. Chúng tôi gửi lời nhắc đầu vào sau cho GPT-4:

1Định nghĩa một vấn đề và các hành động cho tác vụ "băng qua đường tại đèn giao thông" trong PDDL.

Đầu ra PDDL được tạo bởi GPT-4 được trình bày trong Danh sách 1.

Danh sách 1: Định nghĩa một vấn đề và các hành động cho tác vụ "băng qua đường tại đèn giao thông" trong PDDL
1( define ( domain cross-road )
2 ( :requirements :strips )
3 ( :types side )
4 ( :predicates
5 ( pedestrian-at ?s - side )
6 ( traffic-light ?s - side )
7 ( safe-to-cross ?s - side )
8 )
9 ( :action wait-for-green
10 :parameters (?s - side )
11 :precondition ( and ( pedestrian-at ?s) ( traffic-light ?s) )
12 :effect ( safe-to-cross ?s)
13 )
14 ( :action cross
15 :parameters (? s1 - side ?s2 - side )
16 :precondition ( and ( pedestrian-at ?s1) ( safe-to-cross ?s1) )
17 :effect ( and
18 ( not ( pedestrian-at ?s1)) ( pedestrian-at ?s2)
19 ( not ( safe-to-cross ?s1))
20 )
21 )
22)
23( define ( problem cross-road-problem )
24 ( :domain cross-road )
25 ( :objects side1 side2 - side )
26 ( :init
27 ( pedestrian-at side1 )
28 ( traffic-light side1 )
29 ( traffic-light side2 )
30 )
31 ( :goal ( and ( pedestrian-at side2 )))
32)

Sau đó, chúng tôi truy vấn GPT-4 để tìm kế hoạch bằng cách tìm kiếm thông qua miền lập kế hoạch:

1Giải quyết vấn đề "băng qua đường tại đèn giao thông" trong PDDL với các hành động đã định nghĩa.
21. wait -for - green side1
32. cross side1 side2

--- TRANG 5 ---
Kết quả cho thấy rằng miền lập kế hoạch được tạo ra là khép kín, và chúng ta có thể có được một biểu diễn chính thức của kế hoạch, giải quyết vấn đề lập kế hoạch không-shot.

Ngoài các tác vụ đời thường, chúng tôi có thể yêu cầu GPT-4 tạo miền lập kế hoạch cho một số trò chơi nổi tiếng, như Tic-Tac-Toe trong Danh sách 2 và cờ vua trong Danh sách 3. Tuy nhiên, khi độ phức tạp của trò chơi tăng lên, tỷ lệ thành công của việc tạo miền lập kế hoạch khép kín từ GPT-4 giảm xuống. Một ví dụ thất bại là trò chơi cờ vua trong Danh sách 2, định nghĩa trạng thái mục tiêu sai.

Danh sách 2: Định nghĩa một vấn đề và một tập hợp các hành động cho tic-tac-toe trong PDDL.
1( define ( domain tic-tac-toe )
2 ( :requirements :strips :typing )
3 ( :types player cell )
4 ( :predicates
5 ( cell-empty ?c - cell )
6 ( cell-filled ?c - cell ?p - player )
7 ( current-player ?p - player )
8 )
9 ( :action place-mark
10 :parameters (?p - player ?c - cell )
11 :precondition ( and
12 ( cell-empty ?c) ( current-player ?p)
13 )
14 :effect ( and
15 ( not ( cell-empty ?c)) ( cell-filled ?c ?p)
16 ( forall (? other - player )
17 ( when (not (= ? other ?p)) ( current-player ? other )))
18 )
19 )
20)
21
22( define ( problem tic-tac-toe-problem )
23 ( :domain tic-tac-toe )
24 ( :objects
25 x o - player
26 c1 c2 c3 c4 c5 c6 c7 c8 c9 - cell
27 )
28 ( :init
29 ( cell-empty c1) ... ( cell-empty c9)
30 ( current-player x)
31 )
32 ( :goal (or
33 ; Kiểm tra chiến thắng ngang
34 ( and ( cell-filled c1 x) ( cell-filled c2 x) ( cell-filled c3 x))
35 ...
36 ; Kiểm tra chiến thắng dọc
37 ( and ( cell-filled c1 x) ( cell-filled c4 x) ( cell-filled c7 x))
38 ...
39 ; Kiểm tra chiến thắng chéo
40 ( and ( cell-filled c1 x) ( cell-filled c5 x) ( cell-filled c9 x))
41 ( and ( cell-filled c3 x) ( cell-filled c5 x) ( cell-filled c7 x))
42 ))
43)

Danh sách 3: Định nghĩa một vấn đề và một tập hợp các hành động cho trò chơi cờ vua trong PDDL.
1
2( define ( problem chess-problem )
3 ( :domain chess )
4 ( :objects
5 wp1 wp2 wp3 ...... bp6 bp7 bp8 - piece
6 a1 a2 a3 ...... h6 h7 h8 - square
7 )
8 ( :init
9 (at wp1 a2) (at wp2 b2) (at wp3 c2) ......
10 ( clear a3) ( clear a4) ( clear a5) ......
11 )
12 ( :goal ( and (at wp1 a7) ))
13)

Đối với các kết quả thực nghiệm nhiều hơn, chúng tôi chọn 100 tác vụ với độ phức tạp khác nhau. Các tác vụ có phạm vi từ trò chơi bàn cờ đến tác vụ hàng ngày đến tác vụ cụ thể miền. Sau đó, chúng tôi truy vấn GPT-4 để tạo miền lập kế hoạch cho những tác vụ đó và kiểm tra tính đúng đắn của các miền được tạo. Chúng tôi cho thấy các kết quả trong

--- TRANG 6 ---
Bảng 1: Kết quả về Tạo Miền Lập kế hoạch sử dụng GPT-4. Một kế hoạch đúng có nghĩa là miền lập kế hoạch khép kín và phù hợp với kiến thức con người. Một kế hoạch sai có nghĩa là miền lập kế hoạch khép kín nhưng không phù hợp với kiến thức con người (ví dụ: trò chơi cờ vua trong Danh sách 3). Một kế hoạch thất bại có nghĩa là miền lập kế hoạch không khép kín do sự không nhất quán của các vị từ.

Tổng số Tác vụ | Kế hoạch Đúng | Kế hoạch Sai | Thất bại
100 | 73 | 27 | 0

Bảng 2: Kết quả về tìm kiếm đường dẫn sử dụng GPT-4. Độ dài cho biết độ dài của kế hoạch được tạo bởi fast-downward sử dụng các miền lập kế hoạch từ GPT-4. Số lượng tác vụ cho biết có bao nhiêu tác vụ có thể được hoàn thành trong phạm vi bước này. Một kế hoạch được coi là đúng nếu kế hoạch được tạo bởi GPT-4 giống hệt với kế hoạch từ fast-downward.

Độ dài | ≤3 | 4—6 | 6—8 | ≥8
Số lượng Tác vụ | 68 | 10 | 7 | 15
Số lượng Kế hoạch Đúng | 68 | 8 | 4 | 3

Bảng 1. Như chúng ta có thể thấy, GPT-4 luôn có thể tạo miền lập kế hoạch khép kín nhưng thỉnh thoảng tạo miền lập kế hoạch không phù hợp với kiến thức con người.

Ngoài ra, chúng tôi tiếp tục truy vấn GPT-4 để giải quyết vấn đề lập kế hoạch đã cho những miền được tạo đó. Vì tất cả các miền lập kế hoạch đều khép kín, chúng tôi cũng chạy bộ lập kế hoạch fast-downward để tìm kế hoạch và so sánh nó với kế hoạch được tạo từ GPT-4. Các kết quả trong Bảng 2 cho thấy rằng GPT-4 có thể tìm kế hoạch cho các tác vụ đơn giản, nhưng khi tác vụ yêu cầu nhiều bước hơn, GPT-4 có thể tạo kế hoạch với các hành động thiếu sót không theo thứ tự.

Tóm lại, các mô hình ngôn ngữ lớn như GPT-4 hữu ích trong việc tạo miền lập kế hoạch. Do kiến thức phong phú được mã hóa trong những mô hình này, chúng ta có thể sử dụng chúng như một nguồn kiến thức, với lưu ý rằng chúng không phải lúc nào cũng đáng tin cậy cho các tác vụ phức tạp. Về khía cạnh tìm kiếm đường dẫn, GPT-4 có thể giải quyết các vấn đề tìm kiếm đường dẫn rất đơn giản từ các miền lập kế hoạch đã cho. Tuy nhiên, không có lợi thế đáng kể khi sử dụng GPT-4 so với việc sử dụng bộ lập kế hoạch truyền thống.

5 Tìm kiếm Đồ thị
Trong phần này, chúng tôi kiểm tra khả năng của các mô hình ngôn ngữ lớn, như GPT-4, về tìm kiếm đồ thị. Cuộc kiểm tra bao gồm hai khía cạnh: đầu tiên, liệu GPT-4 có hiểu các thuật toán tìm kiếm đồ thị nổi tiếng không, và thứ hai, liệu GPT-4 có thể tuân theo các thuật toán để tìm đường dẫn mong muốn không. Lưu ý rằng chúng tôi so sánh đầu ra của GPT-4 với đầu ra của các thuật toán tìm kiếm đồ thị. Các đầu ra không nhất thiết là đường dẫn tối ưu. Chúng tôi coi GPT-4 là chính xác miễn là nó có thể tạo đường dẫn tuân theo các thuật toán tìm kiếm đồ thị.

Chúng tôi thu thập các đồ thị có hướng có trọng số từ 5 nút đến 95 nút với khoảng cách 10 (5, 15, 25, ..., 85, 95 nút). Đối với mỗi số lượng nút, chúng tôi thu thập 20 đồ thị khác nhau. Một ví dụ được trình bày trong Hình 1. Đối với mỗi đồ thị, chúng tôi truy vấn GPT-4 để thực hiện ba thuật toán tìm kiếm đồ thị, tìm kiếm theo chiều sâu, tìm kiếm theo chiều rộng và thuật toán Dijkstra, tương ứng, để tạo đường dẫn. Đối với ví dụ trong Hình 1, chúng tôi truy vấn:

1Chạy BFS để tìm đường dẫn ngắn nhất từ A đến E.
2Đây là duyệt BFS trên đồ thị có hướng:

A bắt đầu C E
B D
3 2
4 6
5

Hình 1: Một đồ thị có hướng có trọng số được tạo ngẫu nhiên để kiểm tra khả năng tìm kiếm đồ thị của các mô hình ngôn ngữ lớn.

--- TRANG 7 ---
Hình 2: Độ chính xác của các kết quả tìm kiếm đồ thị được tạo bởi GPT-4 trên các đồ thị với số nút khác nhau.

31. Bắt đầu tại nút A. Xếp hàng A và đánh dấu nó đã được thăm.
42. Hủy xếp hàng A. Xếp hàng các láng giềng chưa được thăm của nó, B và C, và đánh dấu chúng đã được thăm.
53. Hủy xếp hàng B. Xếp hàng láng giềng chưa được thăm của nó, D, và đánh dấu nó đã được thăm.
64. Hủy xếp hàng C. Xếp hàng láng giềng chưa được thăm của nó, E, và đánh dấu nó đã được thăm.
75. Hủy xếp hàng D. Không có láng giềng chưa được thăm.
86. Hủy xếp hàng E. Không có láng giềng chưa được thăm.
9Duyệt BFS thăm các nút theo thứ tự sau: A -> B -> C -> D -> E.
10Bằng cách sử dụng các tiền nhiệm, chúng ta có thể tái tạo đường dẫn ngắn nhất từ A đến E:
111. Bắt đầu tại nút E.
122. Tiền nhiệm của E là C. Vậy, chúng ta có E <-- C.
133. Tiền nhiệm của C là A. Vậy, chúng ta có C <-- A.
14Kết hợp tất cả lại, chúng ta có đường dẫn ngắn nhất từ A đến E: A --> C --> E.
15
16 Chạy thuật toán Dijkstra để tìm đường dẫn ngắn nhất từ A đến E.
17
18Đây là duyệt DFS trên đồ thị có hướng:
19......
20Duyệt DFS thăm các nút theo thứ tự sau: A -> B -> D -> C -> E.
21Kết hợp tất cả lại, chúng ta có một đường dẫn từ A đến E: A --> C --> E.
22
23 Chạy DFS để tìm đường dẫn ngắn nhất từ A đến E.
24
25Đây là cách thuật toán Dijkstra tiến hành:
261. Khoảng cách: A = 0, B = 999, C = 999, D = 999, E = 999. Chưa thăm: A, B, C, D, E
272. Thăm nút A. Cập nhật khoảng cách của B và đặt tiền nhiệm của nó là A. Cập nhật khoảng cách của C và đặt tiền nhiệm của nó là A. Khoảng cách: A = 0, B = 3, C = 2, D = 999, E = 999. Chưa thăm: B, C, D, E
283. Thăm nút C (khoảng cách chưa thăm nhỏ nhất). Cập nhật khoảng cách của E và đặt tiền nhiệm của nó là C. Khoảng cách: A = 0, B = 3, C = 2, D = 999, E = 8. Chưa thăm: B, D, E
294. Thăm nút B (khoảng cách chưa thăm nhỏ nhất). Cập nhật khoảng cách của D và đặt tiền nhiệm của nó là B. Khoảng cách: A = 0, B = 3, C = 2, D = 7, E = 8. Chưa thăm: D, E
305. Thăm nút D (khoảng cách chưa thăm nhỏ nhất). Không có cập nhật. Chưa thăm: E
316. Thăm nút E (khoảng cách chưa thăm nhỏ nhất). Không có láng giềng chưa thăm.
32
33Kết hợp tất cả lại, chúng ta có một đường dẫn từ A đến E: A --> C --> E.

Như chúng tôi chỉ ra trong ví dụ này, GPT-4 đủ khả năng tạo đường dẫn chính xác dưới cả ba thuật toán. Tuy nhiên, khi các đồ thị trở nên phức tạp hơn, độ chính xác của GPT-4 giảm xuống. Trong Hình 2, chúng tôi trình bày cách độ chính xác của GPT-4 trên ba thuật toán giảm khi số lượng nút đồ thị tăng lên. Do đó, chúng tôi kết luận rằng GPT-4 chỉ có khả năng tìm kiếm đồ thị đơn giản. Nhưng nó cung cấp khả năng phân tách một đồ thị phức tạp thành các đồ thị đơn giản và thực hiện tìm kiếm đồ thị.

6 Lập kế hoạch Đối nghịch
Trong phần này, chúng tôi khám phá khả năng của mô hình ngôn ngữ lớn, cụ thể là GPT-4, về lập kế hoạch đối nghịch. Thí nghiệm bao gồm hai thành phần: định nghĩa heuristic và áp dụng tìm kiếm đối nghịch.

--- TRANG 8 ---
Đầu tiên, chúng tôi chọn trò chơi đơn giản Tic-Tac-Toe làm ví dụ và truy vấn GPT-4 về một heuristic phù hợp:

1Thiết kế một heuristic cho lập kế hoạch đối nghịch trong tic-tac-toe.
2Đây là một heuristic đơn giản cho Tic-Tac-Toe:
31. Gán giá trị +1 cho mỗi hàng, cột hoặc đường chéo chỉ có ký hiệu của người chơi tối đa hóa (và không có ký hiệu của đối thủ).
42. Gán giá trị -1 cho mỗi hàng, cột hoặc đường chéo chỉ có ký hiệu của người chơi tối thiểu hóa (và không có ký hiệu của đối thủ).
53. Gán giá trị 0 cho các hàng, cột hoặc đường chéo có cả ký hiệu của người chơi tối đa hóa và tối thiểu hóa, vì những đường này không thể thắng được.
64. Tổng hợp các giá trị từ bước 1-3 để tính tổng điểm cho trạng thái bàn cờ.

Mô hình ngôn ngữ đã thành công tạo ra một heuristic cho lập kế hoạch đối nghịch trong Tic-Tac-Toe. Sau đó chúng tôi thực hiện thủ công heuristic này và thực hiện thuật toán Mini-max. Hóa ra đầu ra của GPT-4 là một heuristic có thể hoạt động được.

Thứ hai, chúng tôi kiểm tra hiệu suất của GPT-4 về lập kế hoạch đối nghịch. Chúng tôi truy vấn GPT-4 để chơi trò chơi với heuristic được định nghĩa ở trên:

1Chơi tic-tac-toe với tôi sử dụng thuật toán Mini-max với heuristic được định nghĩa ở trên.
2Vui lòng cung cấp trạng thái hiện tại của bàn cờ Tic-Tac-Toe của bạn, và cho tôi biết liệu nước đi tiếp theo là cho 'X' (người chơi tối đa hóa) hay 'O' (người chơi tối thiểu hóa). Sau đó, tôi sẽ giúp bạn xác định nước đi tốt nhất theo heuristic.
3
4Bàn cờ: ---
5 --X
6 ---
7Đây là điểm heuristic cho mỗi nước đi có thể:
8O1: O-- O2: -O- O3: --O O4: -O- O5: --O
9 --X --X --X -OX -XO
10 --- --- --- --- ---
11
12O6: --O O7: --- O8: --- O9: ---
13 O-X O-X -OX -XO
14 --- -O- --O --O
15O4, O5: 1 (Chặn 'X' khỏi khả năng thắng trong nước đi tiếp theo)
16Khác: 0 (Không có lợi thế hoặc bất lợi ngay lập tức)
17Theo heuristic, các nước đi tốt nhất cho O là O4 và O5.

Trong ví dụ này, GPT-4 thất bại trong việc xác định các nước đi có thể và ghi nhớ chuỗi các trạng thái trước đó, tức là các quân cờ hiện có trên bàn cờ. Hơn nữa, ngay cả với các nước đi bị xác định sai, nó thất bại trong việc tính toán heuristic. Từ quan sát này, chúng ta cũng có thể khẳng định rằng GPT-4 không thể hiểu heuristic. Do đó, nó có khả năng hạn chế của các thuật toán tìm kiếm đồ thị như A* cũng vậy.

Do thất bại của lập kế hoạch đối nghịch trong Tic-Tac-Toe, chúng tôi dừng kiểm tra khả năng của nó trên các tác vụ phức tạp hơn và rút ra kết luận của chúng tôi.

Tóm lại, LLMs có khả năng tạo ra các heuristic hợp lý cho lập kế hoạch đối nghịch của các trò chơi đơn giản. Chúng tôi kiểm tra khả năng này trong ví dụ tic-tac-toe, nơi heuristic được điều khiển bởi AI cho phép đánh giá các vị trí bàn cờ dựa trên sự hiện diện của ký hiệu của người chơi trong các hàng, cột và đường chéo. LLMs mã hóa kiến thức phong phú và có thể cung cấp heuristic hợp lý cho một số tác vụ đã cho.

Heuristic đơn giản nhưng này thể hiện tiềm năng của việc sử dụng heuristic được tạo bởi AI để hướng dẫn và nâng cao việc ra quyết định trong các miền vấn đề khác nhau. Kết hợp với các thuật toán tìm kiếm đối nghịch như Minimax hoặc cắt tỉa Alpha-Beta, những heuristic này cho phép tạo ra các đối thủ AI có thể cạnh tranh hiệu quả với người chơi con người trong các trò chơi đơn giản như Tic-Tac-Toe.

Tuy nhiên, LLMs không thể thực hiện các thuật toán tìm kiếm đối nghịch như Mini-max hoặc Tìm kiếm Cây Monte-Carlo. Do thực tế rằng GPTs là một loạt các mô hình ngôn ngữ để dự đoán từ tiếp theo, chúng không thể hiểu trạng thái của trò chơi cũng như tìm kiếm trên tất cả các khả năng (như chúng tôi đã đề cập đến hạn chế tìm kiếm đồ thị trong phần cuối). Ngoài ra, mô hình ngôn ngữ không thể ghi nhớ chuỗi các trạng thái trước đó một cách chính xác. Những yếu tố này đặt ra một hạn chế của LLMs và có thể là một hướng cải thiện tiềm năng.

7 Tinh chỉnh LLM cho Lý luận Logic
Với hiệu suất kém của LLM trên các tác vụ lý luận logic như lập kế hoạch đối nghịch, chúng tôi có thể tinh chỉnh mô hình ngôn ngữ của riêng mình để kiểm tra xem liệu chúng tôi có thể cải thiện hiệu suất của nó trên các tác vụ lý luận logistic không.

7.1 Tập dữ liệu
Tập dữ liệu được thu thập bao gồm ba phần là tạo miền lập kế hoạch (7 tác vụ khác nhau), tìm kiếm đồ thị (20 tác vụ khác nhau) và lập kế hoạch đối nghịch (4 tác vụ khác nhau). Ví dụ, cho tạo miền lập kế hoạch, chúng tôi truy vấn GPT-4 sử dụng bảy định nghĩa vấn đề khác nhau. Mỗi định nghĩa vấn đề tạo ra 10-100 cấu hình trạng thái mục tiêu khác nhau tùy thuộc vào vấn đề, dẫn đến tổng cộng 540 truy vấn. Đối với mỗi truy vấn (chỉ những truy vấn được chọn, mà chúng tôi nghĩ sẽ cho kết quả đúng khi được truyền qua LLM), chúng tôi chạy suy luận GPT-4 trên chúng để có được các nhãn mềm để tinh chỉnh LLM của riêng chúng tôi. Chúng tôi thu thập khoảng 1300 truy vấn (được nối thêm với tên của phần, ví dụ: các truy vấn miền lập kế hoạch được nối thêm bằng miền lập kế hoạch: và như vậy) và các cặp nhãn mềm trên tất cả các tác vụ.

7.2 Lựa chọn Mô hình và Tinh chỉnh
Để chọn mô hình đúng để tinh chỉnh, chúng tôi đã chọn một mô hình đủ nhỏ có thể được tinh chỉnh dễ dàng bằng cách sử dụng các tài nguyên có sẵn cho chúng tôi và cũng đủ lớn để nó có thể suy luận một cách logic. Chúng tôi đã chọn mô hình cơ sở Flan T5 [Shen et al., 2023] được phát hành bởi Google vì nó đáp ứng tiêu chí này. Một trong những lý do chúng tôi chọn mô hình này là vì các checkpoint của mô hình này đã có sẵn tại HuggingFace, và có kích thước hợp lý là 240M tham số. Ngoài ra, như được thể hiện trong [Shen et al., 2023], mô hình cho thấy hiệu suất SOTA trong tập dữ liệu CoT [Qingyi Si, 2023], chứa các điểm dữ liệu chuỗi tư duy như lý luận số học, tạo giải thích, v.v., cho số lượng tham số mà nó có. Để tinh chỉnh mô hình, chúng tôi đóng băng các trọng số của mô hình gốc. Chúng tôi chỉ thay đổi trọng số của lớp cuối cùng. Cập nhật trọng số của toàn bộ mô hình có thể dẫn đến quên thảm khốc, hoặc nó sẽ được tinh chỉnh đúng cách vì kích thước tập dữ liệu của chúng tôi quá nhỏ.

7.3 Kết quả
Chúng tôi tinh chỉnh mô hình LLM của chúng tôi trên khoảng 1000 điểm dữ liệu và đánh giá nó trên 200 điểm dữ liệu còn lại. Chúng tôi sử dụng 100 điểm dữ liệu còn lại làm tập validation và sử dụng nó để dừng huấn luyện mô hình khi chúng tôi bắt đầu thấy sự gia tăng trong validation loss. Với những tiến bộ nhanh chóng trong các mô hình LLM, chúng tôi quan sát thấy rằng các đầu ra của GPT-4 tốt hơn nhiều so với các mô hình Flan, ít nhiều không chính xác cho mọi điểm dữ liệu mà chúng tôi có. Trong Bảng 3, chúng tôi so sánh các đầu ra của Flan, Flan được tinh chỉnh và GPT-4 cho một trường hợp cụ thể của tìm kiếm đồ thị và tạo miền lập kế hoạch. Đối với tìm kiếm đối nghịch, các mô hình flan không thể đưa ra một heuristic mạch lạc, và do đó chúng tôi bỏ qua đánh giá của chúng. Ngoài ra, chúng tôi không thể so sánh đầu ra của LLM và các giá trị sự thật cơ bản sau khi lập kế hoạch vì tất cả các miền lập kế hoạch được cung cấp bởi Flan đều không chính xác. Tóm lại, chúng tôi có thể thấy những cải thiện nhỏ do tinh chỉnh vì mô hình gốc có thể chưa bao giờ thấy các lời nhắc như thế này nhưng không thể xử lý các đầu ra của các mô hình được tinh chỉnh.

8 Kết luận
Các mô hình ngôn ngữ lớn có thể đóng vai trò quan trọng trong lập kế hoạch do miền kiến thức lớn của chúng. Các mô hình ngôn ngữ lớn cập nhật mã hóa kiến thức thế giới thực phong phú và có thể thực hiện suy luận logic đến một mức độ nhất định. Chúng tôi cung cấp các ví dụ để chứng minh rằng những mô hình này có thể tạo ra các miền lập kế hoạch tự nhất quán của các tác vụ đã cho mà không cần bất kỳ thông tin trước nào được cung cấp. Khả năng này cho phép các mô hình ngôn ngữ thực hiện lập kế hoạch không-shot. Hơn nữa, các mô hình ngôn ngữ có thể thực hiện tìm kiếm đồ thị trên các đồ thị quy mô nhỏ, cho thấy tiềm năng lớn của chúng trong tìm kiếm. Tuy nhiên, các mô hình hiện tại có khả năng hạn chế trong việc ghi nhớ chuỗi các trạng thái trước đó trong quá trình lập kế hoạch và giải quyết các vấn đề tìm kiếm trong môi trường phức tạp (đồ thị). Cả hai hạn chế đều khiến các mô hình ngôn ngữ lớn không có khả năng lập kế hoạch đối nghịch. Nhìn chung, các mô hình ngôn ngữ lớn có thể đóng vai trò quan trọng trong lập kế hoạch, đặc biệt là lập kế hoạch few-shot, và tầm quan trọng của chúng có thể được cải thiện theo thời gian.

--- TRANG 10 ---
Miền lập kế hoạch | Tìm kiếm Đồ thị
Truy vấn đầu vào | Q. Định nghĩa một vấn đề và các hành động cho tác vụ "tic-tac-toe" trong PDDL? | Trả lời câu hỏi có/không sau bằng cách lý luận từng bước. Cho một đồ thị với các đỉnh A, B, C, D, E trong đó các kết nối được cho là A-B, B-C, C-D, C-E. Chạy BFS để tìm đường dẫn ngắn nhất từ A đến E.

Flan | Tic-tac-toe là một từ có nghĩa là "tham gia vào một trò chơi ba-trong-một-hàng cổ điển thường được chơi trên một lưới bởi hai người chơi luân phiên đặt các dấu hiệu tương ứng của họ, hoặc X hoặc O, trong một nỗ lực đạt được sự kết hợp thắng cuộc." | BFS là một chương trình tính toán khoảng cách giữa A và E.

Flan-tinh chỉnh | 1( define ( domain tic -tac - toe )(: requirements : strips : typing : equality )) | BFS là một chương trình tính toán khoảng cách giữa A và E. Khám phá A cho B. Khám phá B cho C. Khám phá C cho D và E. Do đó, đường dẫn là A - B - C - E.

GPT-4 | 1( define ( domain tic -tac - toe )(: requirements : strips : typing : equality ) 2 3(: types cell ) 4 5(: predicates 6 ( empty ?c - cell ) 7 (x ?c - cell ) 8 (o ?c - cell ) 9 ) 10 .... | 1Để xác định xem chúng ta có thể chạy Tìm kiếm Theo chiều rộng (BFS) để tìm đường dẫn ngắn nhất từ A đến E không, hãy đi qua thuật toán BFS từng bước cho đồ thị đã cho. 2Bắt đầu tại đỉnh nguồn A. 3Khám phá tất cả các láng giềng của A: (A-B) 4Khám phá tất cả các láng giềng chưa được thăm của B: (B-C) 5C có hai láng giềng chưa được thăm: (C-D) và (C-E) 6Tại điểm này, chúng ta đã đạt đến đỉnh E, vậy chúng ta có thể dừng thuật toán. Đường dẫn ngắn nhất từ A đến E là A-B-C-E. 7

Bảng 3: So sánh giữa các đầu ra của các mô hình khác nhau cho miền lập kế hoạch và tìm kiếm đồ thị.

Tài liệu tham khảo
Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, và Dario Amodei. Language models are few-shot learners. Advances in Neural Information Processing Systems, 33:1877–1901, 2020.

Bharath Chintagunta, Namit Katariya, Xavier Amatriain, và Anitha Kannan. Medically aware gpt-3 as a data generator for medical dialogue summarization. In Machine Learning for Healthcare Conference, pages 354–372. PMLR, 2021.

Patrik Haslum, Nir Lipovetzky, Daniele Magazzeni, và Christian Muise. An introduction to the planning domain definition language. Synthesis Lectures on Artificial Intelligence and Machine

--- TRANG 11 ---
Learning, 2019.

Wenlong Huang, Pieter Abbeel, Deepak Pathak, và Igor Mordatch. Language models as zero-shot planners: Extracting actionable knowledge for embodied agents. In Kamalika Chaudhuri, Stefanie Jegelka, Le Song, Csaba Szepesvári, Gang Niu, và Sivan Sabato, editors, International Conference on Machine Learning, ICML 2022, 17-23 July 2022, Baltimore, Maryland, USA, volume 162 of Proceedings of Machine Learning Research, pages 9118–9147. PMLR, 2022a. URL https://proceedings.mlr.press/v162/huang22a.html.

Wenlong Huang, Fei Xia, Ted Xiao, Harris Chan, Jacky Liang, Pete Florence, Andy Zeng, Jonathan Tompson, Igor Mordatch, Yevgen Chebotar, Pierre Sermanet, Tomas Jackson, Noah Brown, Linda Luu, Sergey Levine, Karol Hausman, và Brian Ichter. Inner monologue: Embodied reasoning through planning with language models. 205:1769–1782, 2022b.

Brian Ichter, Anthony Brohan, Yevgen Chebotar, Chelsea Finn, Karol Hausman, Alexander Herzog, Daniel Ho, Julian Ibarz, Alex Irpan, Eric Jang, Ryan Julian, Dmitry Kalashnikov, Sergey Levine, Yao Lu, Carolina Parada, Kanishka Rao, Pierre Sermanet, Alexander Toshev, Vincent Vanhoucke, Fei Xia, Ted Xiao, Peng Xu, Mengyuan Yan, Noah Brown, Michael Ahn, Omar Cortes, Nicolas Sievers, Clayton Tan, Sichun Xu, Diego Reyes, Jarek Rettinghouse, Jornell Quiambao, Peter Pastor, Linda Luu, Kuang-Huei Lee, Yuheng Kuang, Sally Jesmonth, Nikhil J. Joshi, Kyle Jeffrey, Rosario Jauregui Ruano, Jasmine Hsu, Keerthana Gopalakrishnan, Byron David, Andy Zeng, và Chuyuan Kelly Fu. Do as I can, not as I say: Grounding language in robotic affordances. In Karen Liu, Dana Kulic, và Jeffrey Ichnowski, editors, Conference on Robot Learning, CoRL 2022, 14-18 December 2022, Auckland, New Zealand, volume 205 of Proceedings of Machine Learning Research, pages 287–318. PMLR, 2022. URL https://proceedings.mlr.press/v205/ichter23a.html.

Markus Leippold. Thus spoke gpt-3: Interviewing a large-language model on climate finance. Finance Research Letters, 53:103617, 2023.

Bill Yuchen Lin, Chengsong Huang, Qian Liu, Wenda Gu, Sam Sommerer, và Xiang Ren. On grounded planning for embodied tasks with language models. In Brian Williams, Yiling Chen, và Jennifer Neville, editors, AAAI Conference on Artificial Intelligence, pages 13192–13200, Washington, DC, USA, 2023. AAAI Press.

Harsha Nori, Nicholas King, Scott Mayer McKinney, Dean Carignan, và Eric Horvitz. Capabilities of gpt-4 on medical challenge problems. arXiv preprint arXiv:2303.13375, 2023.

OpenAI. GPT-4 technical report. CoRR, abs/2303.08774, 2023. doi:10.48550/arXiv.2303.08774. URL https://doi.org/10.48550/arXiv.2303.08774.

Zheng Lin Qingyi Si. Alpaca-cot: An instruction fine-tuning platform with instruction data collection and unified large language models interface. https://github.com/PhoebusSi/alpaca-CoT, 2023.

Dhruv Shah, Blazej Osinski, Brian Ichter, và Sergey Levine. Lm-nav: Robotic navigation with large pre-trained models of language, vision, and action. In Karen Liu, Dana Kulic, và Jeffrey Ichnowski, editors, Conference on Robot Learning, CoRL 2022, 14-18 December 2022, Auckland, New Zealand, volume 205 of Proceedings of Machine Learning Research, pages 492–504. PMLR, 2022. URL https://proceedings.mlr.press/v205/shah23b.html.

Sheng Shen, Le Hou, Yanqi Zhou, Nan Du, Shayne Longpre, Jason Wei, Hyung Won Chung, Barret Zoph, William Fedus, Xinyun Chen, Tu Vu, Yuexin Wu, Wuyang Chen, Albert Webson, Yunxuan Li, Vincent Zhao, Hongkun Yu, Kurt Keutzer, Trevor Darrell, và Denny Zhou. Flan-moe: Scaling instruction-finetuned language models with sparse mixture of experts. CoRR, abs/2305.14705, 2023. doi:10.48550/arXiv.2305.14705. URL https://doi.org/10.48550/arXiv.2305.14705.

Hoo-Chang Shin, Yang Zhang, Evelina Bakhturina, Raul Puri, Mostofa Patwary, Mohammad Shoeybi, và Raghav Mani. Biomegatron: Larger biomedical domain language model. In Bonnie Webber, Trevor Cohn, Yulan He, và Yang Liu, editors, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, EMNLP 2020, Online, November 16-20, 2020, pages 4700–4706. Association for Computational Linguistics, 2020. doi:10.18653/v1/2020.emnlp-main.379. URL https://doi.org/10.18653/v1/2020.emnlp-main.379.

--- TRANG 12 ---
Ishika Singh, Valts Blukis, Arsalan Mousavian, Ankit Goyal, Danfei Xu, Jonathan Tremblay, Dieter Fox, Jesse Thomason, và Animesh Garg. Progprompt: Generating situated robot task plans using large language models. In IEEE International Conference on Robotics and Automation, ICRA 2023, London, UK, May 29 - June 2, 2023, pages 11523–11530. IEEE, 2023.

Chan Hee Song, Jiaman Wu, Clayton Washington, Brian M. Sadler, Wei-Lun Chao, và Yu Su. Llm-planner: Few-shot grounded planning for embodied agents with large language models. CoRR, abs/2212.04088, 2022. doi:10.48550/arXiv.2212.04088. URL https://doi.org/10.48550/arXiv.2212.04088.

Arun James Thirunavukarasu, Darren Shu Jeng Ting, Kabilan Elangovan, Laura Gutierrez, Ting Fang Tan, và Daniel Shu Wei Ting. Large language models in medicine. Nature Medicine, pages 1–11, 2023.

Karthik Valmeekam, Alberto Olmo, Sarath Sreedharan, và Subbarao Kambhampati. Large language models still can't plan (a benchmark for llms on planning and reasoning about change). arXiv preprint arXiv:2206.10498, 2022.

Shijie Wu, Ozan Irsoy, Steven Lu, Vadim Dabravolski, Mark Dredze, Sebastian Gehrmann, Prabhanjan Kambadur, David S. Rosenberg, và Gideon Mann. Bloomberggpt: A large language model for finance. CoRR, abs/2303.17564, 2023. doi:10.48550/arXiv.2303.17564. URL https://doi.org/10.48550/arXiv.2303.17564.

Yunhao Yang, Jean-Raphaël Gaglione, Cyrus Neary, và Ufuk Topcu. Automaton-based representations of task knowledge from generative language models. CoRR, abs/2212.01944, 2022. doi:10.48550/arXiv.2212.01944. URL https://doi.org/10.48550/arXiv.2212.01944.

--- TRANG 13 ---
A Phụ lục
A.1 Ví dụ Miền Lập kế hoạch

Danh sách 4: Định nghĩa một vấn đề và một tập hợp các hành động cho trò chơi cờ vua trong PDDL.
1( define ( domain chess )
2 ( :requirements :strips :typing :equality :conditional-effects )
3 ( :types piece square )
4 ( :predicates
5 ( clear ?s - square )
6 (at ?p - piece ?s - square )
7 ( captured ?p - piece )
8 )
9 ( :action move
10 :parameters (?p - piece ? from - square ?to - square )
11 :precondition ( and
12 (at ?p ? from ) ( clear ?to)
13 )
14 :effect ( and
15 ( not (at ?p ? from )) (at ?p ?to) ( clear ? from ) ( not ( clear ?to))
16 )
17 )
18 ( :action capture
19 :parameters (? p1 - piece ?p2 - piece ? from - square ?to - square )
20 :precondition ( and
21 (at ?p1 ? from ) (at ?p2 ?to)
22 )
23 :effect ( and
24 ( not (at ?p1 ? from )) (at ?p1 ?to) ( not (at ?p2 ?to))
25 ( captured ?p2) ( clear ? from )
26 )
27 )
28)
29
30( define ( problem chess-problem )
31 ( :domain chess )
32 ( :objects
33 wp1 wp2 wp3 wp4 wp5 wp6 wp7 wp8 - piece
34 bp1 bp2 bp3 bp4 bp5 bp6 bp7 bp8 - piece
35 a1 a2 a3 a4 a5 a6 a7 a8
36 ...
37 h1 h2 h3 h4 h5 h6 h7 h8 - square
38 )
39 ( :init
40 (at wp1 a2) (at wp2 b2) (at wp3 c2) (at wp4 d2) (at wp5 e2)
41 (at wp6 f2) (at wp7 g2) (at wp8 h2)
42 (at bp1 a7) (at bp2 b7) (at bp3 c7) (at bp4 d7) (at bp5 e7)
43 (at bp6 f7) (at bp7 g7) (at bp8 h7)
44 ( clear a3) ( clear a4) ( clear a5) ( clear a6) ( clear a8)
45 ...
46 ( clear h3) ( clear h4) ( clear h5) ( clear h6) ( clear h8)
47 )
48 ( :goal ( and (at wp1 a7) ))
49)

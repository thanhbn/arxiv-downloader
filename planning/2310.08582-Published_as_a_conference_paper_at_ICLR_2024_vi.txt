Ning Bian, Xianpei Han, Le Sun, Hongyu Lin, Yaojie Lu, và Ben He. Chatgpt is a knowledgeable but inexperienced solver: An investigation of commonsense problem in large language models, 2023. 3

Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, và Dario Amodei. Language models are few-shot learners, 2020. 4

Yue Cao và C. S. George Lee. Robot behavior-tree-based task generation with large language models, 2023. 9

Thomas Carta, Clément Romac, Thomas Wolf, Sylvain Lamprier, Olivier Sigaud, và Pierre-Yves Oudeyer. Grounding large language models in interactive environments with online reinforcement learning, 2023. 9

Charlie Chen, Sebastian Borgeaud, Geoffrey Irving, Jean-Baptiste Lespiau, Laurent Sifre, và John Jumper. Accelerating large language model decoding with speculative sampling, 2023. 9

Zhoujun Cheng, Jungo Kasai, và Tao Yu. Batch prompting: Efficient inference with large language model apis, 2023. 2, 9

Joe Davison, Joshua Feldman, và Alexander Rush. Commonsense knowledge mining from pre-trained models. Trong Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), trang 1173–1178, Hồng Kông, Trung Quốc, tháng 11 năm 2019. Association for Computational Linguistics. doi: 10.18653/v1/D19-1109. URL https://aclanthology.org/D19-1109. 3

Yan Ding, Xiaohan Zhang, Chris Paxton, và Shiqi Zhang. Task and motion planning with large language models for object rearrangement, 2023. 9

Benjamin Eysenbach, Ruslan Salakhutdinov, và Sergey Levine. Search on the replay buffer: Bridging planning and reinforcement learning. arXiv: Artificial Intelligence, arXiv: Artificial Intelligence, tháng 6 năm 2019. 1

--- TRANG 11 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024

CaelanReed Garrett, Tomás Lozano-Pérez, và LesliePack Kaelbling. Pddlstream: Integrating symbolic planners and blackbox samplers via optimistic adaptive planning. arXiv: Artificial Intelligence, arXiv: Artificial Intelligence, tháng 2 năm 2018. 9

Michael Glass, Gaetano Rossiello, Md Faisal Mahbub Chowdhury, Ankita Rajaram Naik, Pengshan Cai, và Alfio Gliozzo. Re2g: Retrieve, rerank, generate, 2022. 9

Yu Gu, Xiang Deng, và Yu Su. Don't generate, discriminate: A proposal for grounding language models to real-world environments, 2023. 9

Yanjiang Guo, Yen-Jen Wang, Lihan Zha, Zheyuan Jiang, và Jianyu Chen. Doremi: Grounding language model by detecting and recovering from plan-execution misalignment, 2023. 1

Shibo Hao, Yi Gu, Haodi Ma, Joshua Jiahua Hong, Zhen Wang, Daisy Zhe Wang, và Zhiting Hu. Reasoning with language model is planning with world model. arXiv preprint arXiv:2305.14992, 2023. 9

Wenlong Huang, Pieter Abbeel, Deepak Pathak, và Igor Mordatch. Language models as zero-shot planners: Extracting actionable knowledge for embodied agents. Trong Kamalika Chaudhuri, Stefanie Jegelka, Le Song, Csaba Szepesvári, Gang Niu, và Sivan Sabato (eds.), International Conference on Machine Learning, ICML 2022, 17-23 tháng 7 năm 2022, Baltimore, Maryland, USA, tập 162 của Proceedings of Machine Learning Research, trang 9118–9147. PMLR, 2022a. URL https://proceedings.mlr.press/v162/huang22a.html. 1, 3, 6, 9, 15

Wenlong Huang, Fei Xia, Ted Xiao, Harris Chan, Jacky Liang, Pete Florence, Andy Zeng, Jonathan Tompson, Igor Mordatch, Yevgen Chebotar, Pierre Sermanet, Noah Brown, Tomas Jackson, Linda Luu, Sergey Levine, Karol Hausman, và Brian Ichter. Inner monologue: Embodied reasoning through planning with language models, 2022b. 9

Wenlong Huang, Fei Xia, Dhruv Shah, Danny Driess, Andy Zeng, Yao Lu, Pete Florence, Igor Mordatch, Sergey Levine, Karol Hausman, và Brian Ichter. Grounded decoding: Guiding text generation with grounded models for robot control, 2023. 9

Yuqian Jiang, Shiqi Zhang, Piyush Khandelwal, và Peter Stone. Task planning in robotics: an empirical comparison of pddl-based and asp-based systems. Cornell University - arXiv, Cornell University - arXiv, tháng 4 năm 2018. 9

Leslie Pack Kaelbling và Tomás Lozano-Pérez. Hierarchical task and motion planning in the now. Trong 2011 IEEE International Conference on Robotics and Automation, trang 1470–1477, 2011. doi: 10.1109/ICRA.2011.5980391. 1, 3

Angelos Katharopoulos, Apoorv Vyas, Nikolaos Pappas, và François Fleuret. Transformers are rnns: Fast autoregressive transformers with linear attention, 2020. 9

J. Richard Landis và Gary G. Koch. The measurement of observer agreement for categorical data. Biometrics, 33(1):159–174, 1977. ISSN 0006341X, 15410420. URL http://www.jstor.org/stable/2529310. 6

Yaniv Leviathan, Matan Kalman, và Yossi Matias. Fast inference from transformers via speculative decoding, 2023. 9

Shuang Li, Xavier Puig, Chris Paxton, Yilun Du, Clinton Wang, Linxi Fan, Tao Chen, De-An Huang, Ekin Akyürek, Anima Anandkumar, Jacob Andreas, Igor Mordatch, Antonio Torralba, và Yuke Zhu. Pre-trained language models for interactive decision-making. Trong Alice H. Oh, Alekh Agarwal, Danielle Belgrave, và Kyunghyun Cho (eds.), Advances in Neural Information Processing Systems, 2022a. URL https://openreview.net/forum?id=FWMQYjFso-a. 3, 14

Xiang Lorraine Li, Adhiguna Kuncoro, Jordan Hoffmann, Cyprien de Masson d'Autume, Phil Blunsom, và Aida Nematzadeh. A systematic investigation of commonsense knowledge in large language models. Trong Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, trang 11838–11855, Abu Dhabi, Các Tiểu vương quốc Ả Rập Thống nhất, tháng 12 năm 2022b. Association for Computational Linguistics. doi: 10.18653/v1/2022.emnlp-main.812. URL https://aclanthology.org/2022.emnlp-main.812. 3

--- TRANG 12 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024

Jacky Liang, Wenlong Huang, Fei Xia, Peng Xu, Karol Hausman, Brian Ichter, Pete Florence, và Andy Zeng. Code as policies: Language model programs for embodied control, 2023. 9

Bill Yuchen Lin, Yicheng Fu, Karina Yang, Prithviraj Ammanabrolu, Faeze Brahman, Shiyu Huang, Chandra Bhagavatula, Yejin Choi, và Xiang Ren. Swiftsage: A generative agent with fast and slow thinking for complex interactive tasks, 2023a. 9

Bill Yuchen Lin, Chengsong Huang, Qian Liu, Wenda Gu, Sam Sommerer, và Xiang Ren. On grounded planning for embodied tasks with language models. Trong Proceedings of the AAAI Conference on Artificial Intelligence, tập 37, trang 13192–13200, 2023b. 9

Lajanugen Logeswaran, Yao Fu, Moontae Lee, và Honglak Lee. Few-shot subgoal planning with language models. Trong Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, trang 5493–5506, Seattle, Hoa Kỳ, tháng 7 năm 2022. Association for Computational Linguistics. doi: 10.18653/v1/2022.naacl-main.402. URL https://aclanthology.org/2022.naacl-main.402. 9

Jieyi Long. Large language model guided tree-of-thought, 2023. 9

Yao Mu, Qinglong Zhang, Mengkang Hu, Wenhai Wang, Mingyu Ding, Jun Jin, Bin Wang, Jifeng Dai, Yu Qiao, và Ping Luo. Embodiedgpt: Vision-language pre-training via embodied chain of thought, 2023. 9

Vishal Pallagani, Bharath Muppasani, Keerthiram Murugesan, Francesca Rossi, Biplav Srivastava, Lior Horesh, Francesco Fabiano, và Andrea Loreggia. Understanding the capabilities of large language models for automated planning. arXiv preprint arXiv:2305.16151, 2023. 9

Xavier Puig, Kevin Ra, Marko Boben, Jiaman Li, Tingwu Wang, Sanja Fidler, và Antonio Torralba. Virtualhome: Simulating household activities via programs. Trong Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), tháng 6 năm 2018. 3, 5, 10, 14

Shreyas Sundara Raman, Vanya Cohen, Eric Rosen, Ifrah Idrees, David Paulius, và Stefanie Tellex. Planning with large language models via corrective re-prompting. CoRR, abs/2211.09935, 2022. doi: 10.48550/arXiv.2211.09935. URL https://doi.org/10.48550/arXiv.2211.09935. 1

Noah Shinn, Beck Labash, và Ashwin Gopinath. Reflexion: an autonomous agent with dynamic memory and self-reflection. arXiv preprint arXiv:2303.11366, 2023. 1, 9

Ishika Singh, Valts Blukis, Arsalan Mousavian, Ankit Goyal, Danfei Xu, Jonathan Tremblay, Dieter Fox, Jesse Thomason, và Animesh Garg. Progprompt: Generating situated robot task plans using large language models, 2022. 6, 9, 15

Chan Hee Song, Jiaman Wu, Clayton Washington, Brian M. Sadler, Wei-Lun Chao, và Yu Su. Llm-planner: Few-shot grounded planning for embodied agents with large language models, 2023. 1, 9

Haotian Sun, Yuchen Zhuang, Lingkai Kong, Bo Dai, và Chao Zhang. Adaplanner: Adaptive planning from feedback with language models. arXiv preprint arXiv:2305.16653, 2023a. 9

Simeng Sun, Yang Liu, Shuohang Wang, Chenguang Zhu, và Mohit Iyyer. Pearl: Prompting large language models to plan and execute actions over long documents. arXiv preprint arXiv:2305.14564, 2023b. 9

Mirac Suzgun, Luke Melas-Kyriazi, và Dan Jurafsky. Prompt-and-rerank: A method for zero-shot and few-shot arbitrary textual style transfer with small language models. Trong arXiv, 2022. 9

Sai Vemprala, Rogerio Bonatti, Arthur Bucker, và Ashish Kapoor. Chatgpt for robotics: Design principles and model abilities. Microsoft Autonomous Systems and Robotics Research, 2023. 2, 6, 9

Sinong Wang, Belinda Z. Li, Madian Khabsa, Han Fang, và Hao Ma. Linformer: Self-attention with linear complexity, 2020. 9

--- TRANG 13 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024

Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc V Le, Ed H. Chi, Sharan Narang, Aakanksha Chowdhery, và Denny Zhou. Self-consistency improves chain of thought reasoning in language models. Trong The Eleventh International Conference on Learning Representations, 2023a. URL https://openreview.net/forum?id=1PL1NIMMrw. 9

Zihao Wang, Shaofei Cai, Anji Liu, Xiaojian Ma, và Yitao Liang. Describe, explain, plan and select: Interactive planning with large language models enables open-world multi-task agents, 2023b. 9

Yue Wu, So Yeon Min, Yonatan Bisk, Ruslan Salakhutdinov, Amos Azaria, Yuanzhi Li, Tom Mitchell, và Shrimai Prabhumoye. Plan, eliminate, and track – language models are good teachers for embodied agents, 2023a. 9

Zhenyu Wu, Ziwei Wang, Xiuwei Xu, Jiwen Lu, và Haibin Yan. Embodied task planning with large language models, 2023b. 9

Danfei Xu, Roberto Martín-Martín, De-An Huang, Yuke Zhu, Silvio Savarese, và Li Fei-Fei. Regression planning networks. arXiv: Artificial Intelligence, arXiv: Artificial Intelligence, tháng 9 năm 2019. 1

Sherry Yang, Ofir Nachum, Yilun Du, Jason Wei, Pieter Abbeel, và Dale Schuurmans. Foundation models for decision making: Problems, methods, and opportunities, 2023. 9

Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, và Yuan Cao. React: Synergizing reasoning and acting in language models. arXiv preprint arXiv:2210.03629, 2022. 9

Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L. Griffiths, Yuan Cao, và Karthik Narasimhan. Tree of thoughts: Deliberate problem solving with large language models, 2023. 9

Andy Zeng, Maria Attarian, brian ichter, Krzysztof Marcin Choromanski, Adrian Wong, Stefan Welker, Federico Tombari, Aveek Purohit, Michael S Ryoo, Vikas Sindhwani, Johnny Lee, Vincent Vanhoucke, và Pete Florence. Socratic models: Composing zero-shot multimodal reasoning with language. Trong The Eleventh International Conference on Learning Representations, 2023. URL https://openreview.net/forum?id=G2Q2Mh3avow. 9

Zirui Zhao, Wee Sun Lee, và David Hsu. Large language models as commonsense knowledge for large-scale task planning, 2023. 9

--- TRANG 14 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024

Phụ lục

A MÔI TRƯỜNG

A.1 KHÔNG GIAN HÀNH ĐỘNG

Các loại hành động trong Môi trường Virtual Home được liệt kê như sau:

1. Sleep
2. StandUp
3. WakeUp
4. Walk
5. Find
6. Grab
7. Wash
8. Wipe
9. Pull
10. Push
11. Pour
12. TurnTo
13. PointAt
14. Watch
15. Touch
16. Open
17. Close
18. Run
19. Sit
20. Read
21. PutOn
22. Drop
23. Lie
24. SwitchOn
25. SwitchOff
26. Drink
27. PutIn
28. PutBack

2.5 5.0 7.5 10.0 12.5 15.0 17.5 20.0 22.5
Độ dài Kế hoạch
0 2 4 6 8 10 12
Tần suất
1 1 1 2
3 5
3
0 1

Hình 6: Phân bố độ dài kế hoạch.

A.2 QUAN SÁT TỪNG PHẦN

Chúng tôi triển khai quan sát từng phần dựa trên Li et al. (2022a). Định nghĩa chính thức của quan sát từng phần là khi tác nhân được đặt trong một phòng, quan sát của nó bao gồm tất cả các đối tượng trong phòng không được đặt bên trong các đối tượng kín. Ví dụ, nếu một quả táo được đặt bên trong tủ lạnh đóng, nó sẽ không xuất hiện trong quan sát của tác nhân.

A.3 BIỂU DIỄN QUAN SÁT

Trong Môi trường VirtualHome (Puig et al., 2018), các quan sát chủ yếu bao gồm hai thành phần: trạng thái đối tượng và mối quan hệ giữa các đối tượng. Trạng thái đối tượng mô tả trạng thái mà một đối tượng tồn tại. Ví dụ, trạng thái của tivi có thể là "bật" hoặc "tắt", tức là "On(TV)" hoặc "Off(TV)". Mối quan hệ giữa các đối tượng được biểu diễn bằng các vị từ để thể hiện mối quan hệ giữa các đối tượng. Ví dụ, khi một nhân vật ở gần tivi, có thể có một vị từ như: "Close(character, TV)". Chúng tôi chuyển đổi các quan sát từ VH thành các câu tiếng Anh bằng cách tiếp cận dựa trên quy tắc. Ví dụ, vị từ "Close(character, TV)" được chuyển đổi thành "character is close to TV", và vị từ "Off(TV)" được chuyển đổi thành "TV is off".

--- TRANG 15 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024

A.4 THỐNG KÊ CƠ BẢN

Trong kế hoạch vàng được chú thích trong tập dữ liệu, kế hoạch có độ dài dài nhất bao gồm 23 hành động, trong khi độ dài trung bình là 8,13. Biểu đồ phân bố tần suất về độ dài kế hoạch được hiển thị trong Hình 6. Hơn nữa, chúng tôi cũng đã tính toán các biểu đồ tần suất cho hành động và đối tượng, được mô tả trong Hình 7 và Hình 8.

Find
Walk
Grab
TurnTo
SwitchOn
LookAt
Sit
PutObjBack
PutBack
Wash
Wipe
SwitchOff
PointAt
Scrub
Pour
Rinse
Lie
Sleep
Type
Pull
Open
Touch
Drop
PutOff
StandUp
Read
PutOn
Drink
Hành động
0 10 20 30 40 50 60 70
Số lượng

Hình 7: Biểu đồ tần suất hành động. Một số hành động thể hiện tần suất cao hơn đáng kể so với các hành động khác, chẳng hạn như Find và Walk.

chair
computer
brush
rag
toilet
bathroom
alarm_clock
sink
home_office
faucet
coin
television
bedroom
bed
dresser
razor
clothes_jacket
keyboard
hands_both
cup
Đối tượng
0 5 10 15 20 25 30
Số lượng

Hình 8: Biểu đồ tần suất đối tượng. Chỉ các đối tượng có tần suất trong top 20 được bao gồm để hiển thị tốt hơn.

B CHI TIẾT TRIỂN KHAI THÊM

B.1 TÌM KIẾM SIÊU THAM SỐ

Đối với cả Quyết định Có căn cứ và ITERATIVE-PLANNER, chúng tôi đã tiến hành tìm kiếm lưới trên các tham số lấy mẫu của OpenAI APIs. Phạm vi tìm kiếm cho nhiệt độ được đặt từ 0,1 đến 1,0 với bước tăng 0,1, trong khi phạm vi tìm kiếm cho top-p được đặt là 0,85, 0,9, 0,95 và 1,0.

Trong trường hợp Quyết định Có căn cứ, kết hợp siêu tham số tối ưu được tìm thấy là nhiệt độ 0,7 và top-p 1,0. Đối với ITERATIVE-PLANNER, kết hợp siêu tham số tối ưu là nhiệt độ 0 và top-p 1,0.

B.2 CÁC MÔ HÌNH CƠ SỞ

ZERO-SHOT PLANNER (Huang et al., 2022a) đề xuất dịch từng hành động không có cấu trúc được tạo ra bởi LLM thành hành động được chấp nhận thông qua một mô hình ngôn ngữ có mặt nạ được đào tạo trước khác. Hành động được dịch sau đó được thêm vào lời nhắc được sử dụng để tạo ra các bước còn lại. Chúng tôi sử dụng triển khai chính thức được cung cấp bởi Huang et al. (2022a), sử dụng kế hoạch được truy xuất động như một ví dụ trong lời nhắc. Hơn nữa, về các siêu tham số, chúng tôi cấu hình số bước tối đa là 20 và đặt ngưỡng dừng sớm là 0,5 để đạt được hiệu suất tối ưu.

PROG PROMPT (Singh et al., 2022) đề xuất lời nhắc lấy cảm hứng từ ngôn ngữ lập trình với câu lệnh assert. Những câu lệnh assert này cung cấp cơ chế để kết hợp phản hồi môi trường vào quá trình tạo kế hoạch, đảm bảo rằng các điều kiện tiên quyết cho mỗi hành động được đáp ứng;

B.3 XỬ LÝ SAU

Để đảm bảo kế hoạch được tạo ra có thể thực hiện được trong môi trường, chúng tôi triển khai thêm một module xử lý sau sau khi lấy mẫu kế hoạch: (i) Kiểm tra Định dạng: Các hành động không tuân thủ định dạng yêu cầu và do đó không thể được phân tích sẽ bị loại bỏ. Với khả năng tuân theo định dạng mạnh của GPT-3.5, số lượng mục bị loại bỏ là tối thiểu; (ii) Dịch Đối tượng & Hành động: Ngay cả với định dạng đúng, kế hoạch được tạo ra bởi LLM có thể bao gồm các hành động hoặc đối tượng không có trong môi trường. Vấn đề này thường phát sinh từ kết quả chính xác về mặt ngữ nghĩa nhưng không khớp chính xác. Ví dụ, nếu tên đối tượng của môi trường là "food egg", nhưng hành động được tạo ra bao gồm "egg", sự khác biệt này cần được giải quyết. Đầu tiên, chúng tôi phân tích chuỗi hành động của LLM để xác định tên hành động và đối tượng. Sau đó chúng tôi sử dụng độ tương tự BERT để khớp chúng với các hành động và đối tượng có sẵn của môi trường³. Ví dụ, đối với chuỗi được tạo ra bởi LLM '[Switch On] <telly>', trình phân tích hành động xác định "Switch On" là hành động và "telly" là đối tượng. Chúng sau đó được khớp với các hành động và đối tượng có sẵn để tạo ra hành động có thể thực hiện "[SwitchOn] <TV>".

C KẾT QUẢ THÍ NGHIỆM THÊM

C.1 KẾT QUẢ THEO ĐỘ DÀI KẾ HOẠCH

EXEC.↑ SR↑ GCR↑ NO.EC↓
0<|a| ≤5 100.00 ±0.00 64.72 ±5.20 77.12 ±4.13 0.30 ±0.15
5<|a| ≤10 83.59±4.03 35.10 ±5.95 52.25 ±3.33 2.47 ±0.35
10<|a| ≤15 88.09±8.48 26.98 ±4.89 55.98 ±7.00 3.20 ±1.12
15<|a| 66.67±0.00 22.22 ±0.00 36.11 ±0.00 4.09 ±0.21

Bảng 4: Hiệu suất của TREE-PLANNER N=50 qua các độ dài chuỗi kế hoạch khác nhau.

Bảng 4 trên trình bày hiệu suất của TREE-PLANNER N=50, được phân loại theo các độ dài chuỗi kế hoạch khác nhau. Nói chung, khi độ dài chuỗi kế hoạch tăng, hiệu suất của mô hình có xu hướng giảm. Cụ thể, đối với các nhiệm vụ có độ dài kế hoạch nhỏ hơn 5, SR có thể đạt 64,72% và thậm chí 100% cho EXEC. Tuy nhiên, đối với các nhiệm vụ có độ dài kế hoạch lớn hơn 15, SR giảm xuống 22,22% (-42,5%), và EXEC giảm xuống 66,67% (-33,33%). Hơn nữa, khi độ dài kế hoạch tăng, số lần sửa chữa trong mô hình cũng tăng. Điều này do khả năng cao hơn của việc tích lũy lỗi trong lập kế hoạch nhiệm vụ tuần tự dài hơn, do đó cần thiết phải sửa lỗi nhiều hơn. Các kết quả thí nghiệm trên cung cấp phân tích toàn diện hơn về hiệu suất của phương pháp chúng tôi, nhấn mạnh các hướng tiềm năng cho cải thiện trong tương lai. Hơn nữa, chúng tôi đã cung cấp kết quả của LOCAL REPLAN như được hiển thị trong Bảng 5. Có thể quan sát thấy rằng trong khi TREE-PLANNER duy trì hiệu suất tương đương qua các độ dài kế hoạch khác nhau, nó thể hiện lợi thế đáng kể về số lần sửa chữa.

EXEC.↑ SR↑ GCR↑ NO.EC↓
0<|a| ≤5 94.17±2.04 56.94 ±0.79 69.46 ±1.70 1.05 ±0.32
5<|a| ≤10 77.02±7.63 38.10 ±3.57 49.66 ±5.45 3.92 ±0.56
10<|a| ≤15 69.84±2.97 24.78 ±5.83 44.52 ±2.16 5.14 ±0.17
15<|a| 72.22±28.33 22.22 ±0.00 35.65 ±8.36 4.83 ±0.87

Bảng 5: Hiệu suất của LOCAL REPLAN qua các độ dài chuỗi kế hoạch khác nhau.

C.2 KẾT QUẢ THEO CẢNH

Như được hiển thị trong Bảng 6, TREE-PLANNER thể hiện hiệu suất nhất quán qua các cảnh khác nhau, do đó minh họa thêm tính bền vững của nó.

EXEC.↑ SR↑ GCR↑ NO.EC↓
ENV-1 92.42 ±2.14 45.45 ±3.71 64.72 ±3.25 1.74 ±0.44
ENV-2 91.30 ±4.10 36.75 ±4.10 52.43 ±7.13 2.33 ±0.47
ENV-3 85.18 ±2.62 37.04 ±2.62 50.80 ±3.19 1.83 ±0.39
ENV-4 88.89 ±3.14 48.89 ±3.14 66.74 ±1.72 2.35 ±0.58

Bảng 6: Hiệu suất của TREE-PLANNER N=50 qua các cảnh khác nhau.

³https://www.sbert.net/

--- TRANG 16 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024

C.3 TÍNH ĐA DẠNG CỦA CÁC KẾ HOẠCH ĐƯỢC LẤY MẪU

Như được hiển thị trong Hình 9, số lượng kế hoạch khác nhau thay đổi gần như tuyến tính theo sự thay đổi trong lấy mẫu n. Do đó, khi tiến hành lấy mẫu kế hoạch, vấn đề đồng nhất hóa do các kế hoạch được lấy mẫu sẽ không phát sinh.

13 15 13 17 13 19 13 1b 13 14 13 13
Lấy mẫu n
13 14 13 15 13 16 13 17 13
Số lượng Kế hoạch Khác nhau
14 11 13 1a 11 1c 14 16 11 13 14 19 11 19 15 15 11 13 15 19 11 16 16 14 11 14 16 17 11 14 16 19 11 1c 17 15 11 14

Hình 9: Tính đa dạng của các kế hoạch được tạo ra. Trục x đại diện cho số lượng chương trình được lấy mẫu, trong khi trục y đại diện cho số lượng trung bình các kế hoạch khác nhau được tạo ra.

C.4 GIỚI HẠN TRÊN CỦA LẤY MẪU KẾ HOẠCH

Chúng tôi cũng tính toán kết quả Tỷ lệ Thành công (SR) tương ứng của Hình 5 bằng: (i) SR tối đa cho tất cả các kế hoạch được tạo ra, tức là, SRmax(c) =Nmaxi=1(SR(ci)); (ii) SR trung bình cho tất cả các kế hoạch được tạo ra, tức là, SRavg(c) =1N∑Ni=1(SR(ci)). Như được hiển thị trong Hình 10, xu hướng của SR về N khớp chặt chẽ với quỹ đạo của GCR.

14 18 14 18 15 18 14 13 15 13 16 13 17 13 18 13 19 13 1a 13 1b 13
N
16 18 17 13 17 18 18 13 18 18 19 13%
18 14 11 1b 18 1c 11 15
16 18 11 1b 15 16 17 11 1c 16

SRmax
SRavg

Hình 10: Tỷ lệ Thành công (SR) tối đa và trung bình cho tất cả các kế hoạch được lấy mẫu.

C.5 KẾT QUẢ THÍ NGHIỆM VỚI TÌM KIẾM TỐT NHẤT ĐẦU TIÊN

Tìm kiếm Tốt nhất Đầu tiên Được hướng dẫn bởi Ngôn ngữ Các cạnh của cây hành động được gán trọng số dựa trên xác suất log của các hành động mà chúng dẫn đến. Những trọng số này được tổng hợp khi nhiều đường dẫn hội tụ vào cùng một hành động, do đó phản ánh khả năng tích lũy để đạt được hành động đó trong bối cảnh cấu trúc của cây. Hàm đánh giá của Tìm kiếm Tốt nhất Đầu tiên Được hướng dẫn bởi Ngôn ngữ được định nghĩa là: fL(ai) =elog(Prob(ai))∑jelog(Prob(aj)). Ở đây, ai đại diện cho một trong các nút con của một nút cho trước và lặp qua tất cả các nút con. Hàm softmax chuẩn hóa các xác suất log, làm cho chúng phù hợp cho so sánh và lựa chọn xác suất.

Tìm kiếm Tốt nhất Đầu tiên Được hướng dẫn bởi Môi trường Các hành động được trọng số dựa trên khả năng quan sát của các đối tượng liên quan. Nếu tất cả các đối tượng liên quan đến một hành động đều có thể quan sát được trong môi trường, hành động được gán trọng số cao hơn (1), ngược lại, trọng số thấp hơn (0). Để tạo điều kiện cho phân tích so sánh và để tính đến số lượng hành động và đối tượng khác nhau, hàm softmax được áp dụng cho trọng số của các hành động phát ra từ mỗi nút. Hàm đánh giá của Tìm kiếm Tốt nhất Đầu tiên Được hướng dẫn bởi Môi trường được định nghĩa là fE(ai) =eObservability(ai)∑jeObservability(aj).

Tìm kiếm Tốt nhất Đầu tiên Kết hợp Phương pháp Kết hợp kết hợp các yếu tố xác suất ngôn ngữ và khả năng quan sát môi trường. Hàm đánh giá là: fHybrid(ai) =αfL(ai)+(1−α)fE(ai) Trong hàm này, α là một siêu tham số giữa 0 và 1 cân bằng ảnh hưởng của các xác suất dựa trên ngôn ngữ và khả năng quan sát môi trường.

Thiết lập Thí nghiệm Chúng tôi tiến hành thí nghiệm trong trường hợp N=50 không có sửa lỗi. Đối với siêu tham số α, chúng tôi đặt nó một cách heuristic là 0,5.

Kết quả Thí nghiệm Như được chứng minh bởi Bảng 7, mặc dù các phương pháp heuristic thể hiện lợi thế lớn hơn về mặt hiệu quả token, SR của chúng thua kém so với quyết định có căn cứ (sử dụng LLM như một hàm đánh giá ngầm). Hơn nữa, việc kết hợp cả hai hàm đánh giá mang lại cải thiện hiệu suất thậm chí lớn hơn, do đó chứng minh rằng vẫn còn chỗ cho cải thiện thông qua tối ưu hóa hàm đánh giá trong các phương pháp heuristic.

Bảng 7: Kết quả Thí nghiệm với Tìm kiếm Tốt nhất Đầu tiên

EXEC.↑ SR↑ GCR↑ $COST↓
TREE-PLANNER 49.01±5.67 28.14 ±2.45 35.84 ±4.20 3.48 ±0.04
LANGUAGE GUIDED 34.71±0.65 15.06 ±1.02 22.47 ±1.72 2.16 ±0.02
ENVIRONMENT GUIDED 37.26±0.17 6.24 ±0.65 12.10 ±1.41 2.16 ±0.02
HYBRID α=0.5 38.71±0.42 17.74 ±0.69 25.34 ±0.95 2.16 ±0.02

C.6 TỶ LỆ CÁC ĐỐI TƯỢNG MỚI

Mối quan hệ giữa số lượng bước và tỷ lệ đối tượng mới trong các nhiệm vụ được đánh giá được hiển thị trong Hình 11.

2.5 5.0 7.5 10.0 12.5 15.0 17.5 20.0 22.5
Số lượng Bước
0.65 0.70 0.75 0.80 0.85
Tỷ lệ Đối tượng Mới

Hình 11: Mỗi điểm đại diện cho một nhiệm vụ riêng biệt. Tỷ lệ đối tượng mới được tính toán với các kế hoạch vàng trong tập dữ liệu.

--- TRANG 17 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024

--- TRANG 18 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024

D CHI TIẾT VỀ HIỆU QUẢ TOKEN

Suy dẫn chi tiết của các điều kiện biên cho N như sau:

để chứng minh μours< μsbs
⇒ ρps+MN|a|+M·(ρgd+N)< M·(ρps+ρgd+|a|)
⇒ MN|a|+M·N < (M−1)·ρps+M· |a|
⇒ M·(|a|+ 1)·N < (M−1)·ρps+M· |a|
⇒ N <1−1/M1 + 1 /|a|·ρps|a|+|a||a|+ 1

E PHÂN TÍCH ĐỊNH TÍNH VỀ LỖI

E.1 QUYẾT ĐỊNH KHÔNG ĐÚNG

Nhiệm vụ: Treo áo khoác
Cây Hành động: Xem Hình 12

Treo áo khoác
Lớp:-1

[Walk] <clothes_jacket> (1)
Lớp:0

[Walk] <bedroom> (1)
Lớp:0

[Find] <clothes_jacket> (1)
Lớp:1

[Grab] <clothes_jacket> (1)
Lớp:2

[Walk] <hanger> (1)
Lớp:3

[Find] <hanger> (1)
Lớp:4

[END]
Lớp:5

[Walk] <hanger> (1)
Lớp:1

[Find] <clothes_jacket> (1)
Lớp:1

[Walk] <clothes_jacket> (1)
Lớp:1

[Find] <hanger> (1)
Lớp:2

[Find] <clothes_jacket> (1)
Lớp:3

[Grab] <clothes_jacket> (1)
Lớp:4

[END]
Lớp:5

[Grab] <clothes_jacket> (1)
Lớp:2

[Walk] <hanger> (1)
Lớp:3

[Find] <hanger> (1)
Lớp:4

[PutBack] <clothes_jacket> (1) <hanger> (1)
Lớp:5

[END]
Lớp:6

[Find] <clothes_jacket> (1)
Lớp:2

[Grab] <clothes_jacket> (1)
Lớp:3

[Walk] <hanger> (1)
Lớp:4

[Find] <hanger> (1)
Lớp:5

[END]
Lớp:6

Hình 12: Hình ảnh hóa cây hành động cho Treo áo khoác. Đường dẫn màu đỏ là kế hoạch được LLM chọn, trong khi đường dẫn màu xanh là kế hoạch đúng.

Giải thích: Như được mô tả trong Hình 12, mô hình đã đưa ra quyết định không đúng trong bước thứ hai. Điều này do TREE-PLANNER không hiểu được thứ tự tuần tự của việc tìm kiếm áo khoác và tìm kiếm móc treo.

E.2 HIỂU LẦM MÔI TRƯỜNG

Nhiệm vụ: Lau toilet

--- TRANG 19 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024

Kế hoạch Ví dụ:
1.[Walk] <bathroom >(1)
2.[Walk] <toilet>(1)
3.[Pull] <toilet>(1)
4.[Wash] <toilet>(1)
5.[Wipe] <toilet>(1)
6.[Push] <toilet>(1)
7.[Wash] <toilet>(1)
8.[Find] <mop bucket >(1)
9.[Walk] <detergent >(1)
10.[Grab] <detergent >(1)
11.[Pour] <detergent >(1)
<mop bucket >(1)

Giải thích: Toilet không thể di chuyển được, vì vậy việc thực hiện bước 3 sẽ thất bại.

E.3 KẾ HOẠCH KHÔNG HOÀN CHỈNH

Nhiệm vụ: Đặt đồng hồ báo thức vào phòng ngủ

Kế hoạch Ví dụ:
1.[Walk] <bedroom >(1)
2.[Walk] <alarm clock>(1)
3.[Find] <alarm clock>(1)
4.[Grab] <alarm clock>(1)
5.[Find] <dresser >(1)
6.[Open] <dresser >(1)
7.[SwitchOn] <alarm clock>(1)

Giải thích: Sau khi thực hiện kế hoạch này, đồng hồ báo thức sẽ ở trong tay của nhân vật. Tuy nhiên, một bước bị thiếu: [PutBack] <alarm clock>(1) trên <dresser >(1) để đặt đồng hồ báo thức trong phòng ngủ.

E.4 LỖI PHI LOGIC

Nhiệm vụ: Cạo râu

Kế hoạch Ví dụ:
1.[Walk] <bathroom >(1)
2.[Find] <shaving cream >(1)
3.[Grab] <shaving cream >(1)
4.[Walk] <after shave >(1)
5.[Find] <after shave >(1)
6.[Grab] <after shave >(1)
7.[Walk] <razor>(1)
8.[Find] <razor>(1)
9.[Grab] <razor>(1)
10.[PutOn] <shaving cream >(1)
11.[Wash] <headset >(1)
12.[PutOn] <after shave >(1)

Giải thích: Nhân vật không có tay trống khi thực hiện bước 9. Điều này là do trong các bước 3 và 6, nhân vật đã cầm hai vật phẩm.

E.5 ĐÚNG VỀ NGỮ NGHĨA

Nhiệm vụ: Sử dụng máy tính

Kế hoạch Ví dụ:
1.[Walk] <home office >(1)
2.[Walk] <computer >(1)

--- TRANG 20 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024

3.[Find] <chair>(1)
4.[Sit]<chair>(1)
5.[SwitchOn] <computer >(1)
6.[Type] <keyboard >(1)

Giải thích: Thông tin lỗi từ môi trường như sau: "<keyboard >" không thể được tìm thấy khi thực hiện "[Type] <keyboard >(1)". Tuy nhiên, tại thời điểm này, nhân vật đang ngồi trước máy tính, cho thấy rằng bàn phím nên được đặt gần nhân vật.

E.6 KẾT QUẢ THÊM VỀ CÁC LOẠI LỖI

Như được minh họa trong Bảng 8, chúng tôi đã tiến hành phân tích sâu hơn về các loại lỗi trong mô hình TREE-PLANNER N=25 có sửa chữa. Phân bố khá tương tự với mô hình không có sửa chữa. Hơn nữa, do có sự hiện diện của sửa lỗi, mô hình thể hiện khả năng tăng cường trong việc tránh các lỗi đúng về ngữ nghĩa trong giai đoạn quyết định có căn cứ.

F LỜI NHẮC

F.1 ITERATIVE-PLANNER

(Hướng dẫn) Bạn cần hành động như một người lập kế hoạch nhiệm vụ phân tách một nhiệm vụ gia đình cấp cao thành nhiều nhiệm vụ con. Mối quan hệ thời gian giữa các chuỗi nhiệm vụ con phải tuân thủ logic thường thức. Mỗi nhiệm vụ con có thể có một trong các dạng sau: 1. [tên hành động]; 2. [tên hành động] <tên đối tượng 1>(id đối tượng 1). 3. [tên hành động] <tên đối tượng 1>(id đối tượng 1) <tên đối tượng 2>(id đối tượng 2). Số lượng đối số phụ thuộc vào loại hành động. (id đối tượng) được sử dụng để báo cho trình mô phỏng rằng các hành động nên được thực hiện trên cùng một thể hiện đối tượng. Ví dụ một chương trình như: [Walk] <glass>(1) [Grab] <glass>(1) Cho biết rằng tác nhân nên đi đến ly trước và sau đó cầm cùng ly đó. Nếu bạn nghĩ nhiệm vụ của bạn đã thành công, bạn có thể xuất [END], đây là loại hành động 1.

(Thông tin Toàn cầu) Đối với loại hành động 1, các hành động có sẵn là: [Sleep], [StandUp], [WakeUp]
Đối với loại hành động 2, các hành động có sẵn là: [Walk], [Find], [Grab], [Wash], [Wipe], [Pull], [Push], [Pour], [TurnTo], [PointAt], [Watch], [Touch], [Open], [Close], [Run], [Sit], [Read], [PutOn], [Drop], [Lie], [SwitchOn], [SwitchOff], [Drink]
Đối với loại hành động 3, các hành động có sẵn là: [PutIn], [PutBack]
Tất cả tên hành động của các nhiệm vụ con phải được chọn từ các hành động trên và tuân theo định dạng tương ứng. Bạn đang ở trong một ngôi nhà gồm bốn phòng. Các phòng này là phòng tắm, phòng ăn, phòng ngủ, văn phòng tại nhà. Các đối tượng có sẵn trong nhà là: clothes hat, ceilinglamp, cpuscreen, orchid, couch, trashcan, dresser, dishwasher, centerpiece, phone, toaster, measuring cup, stereo, mat, computer, envelope, oven mitts, piano bench, box, photoframe, shower, ceiling, wall, window, freezer, faucet, detergent, light, desk, napkin, food rice, kitchen counter, folder, stovefan, walllamp, food food, coffee pot, food steak, jelly, vacuum cleaner, powersocket, filing cabinet, alcohol, bathroom, door, bathroom counter, clothes gloves, microwave, oven, sink, milk, ice, bedroom, laptop, doorjamb, food cake, bills, tea bag, television, laser pointer, toilet, board game, sponge, food carrot, table, tray, cupboard, mousepad, picture, tvstand, tablelamp, hanger, pot, drypasta, floor, knifeblock, curtain, chair, food bread, drawing, creditcard, check, coffe maker, character, pasta, bag, food bacon, bookshelf, toothbrush holder, cutting board, home office, diningroom, nail polish, pillow, tape, nightstand, bathroom cabinet, bench, conditioner, cat, bed, keyboard, mouse
Tất cả tên đối tượng phải được chọn từ danh sách đối tượng trên

(Quan sát) Hiện tại, bạn đang đứng trong phòng ngủ, và không cầm gì trong tay phải và không cầm gì trong tay trái. pillow sạch. napkin sạch. pillow bẩn. bed sạch. mat bẩn. pillow gần drawing. tablelamp gần bed. mat hướng về drawing. pillow bên trong bedroom. mat gần table. bed gần drawing. table gần mat. pillow trên floor. floor gần bed. tablelamp gần pillow. mat gần curtain. bed hướng về computer. mat gần floor. pillow hướng về drawing. curtain gần mat. bed gần tablelamp. wall gần mat. napkin bên trong bedroom. window gần mat. pillow gần tablelamp. bed gần floor. pillow gần wall. mat gần filing cabinet. drawing gần bed. pillow gần floor. bed gần wall. filing cabinet gần mat. bed gần nightstand. mat bên trong bedroom. pillow gần pillow. pillow gần nightstand. mat gần wall. wall gần pillow. nightstand gần pillow. nightstand gần bed. drawing gần pillow. floor gần pillow. bed bên trong bedroom. floor gần mat. wall gần bed. mat gần window. pillow,napkin,pillow,mat,bed,pillow,pillow bên trong bedroom.

(Ví dụ Trong Ngữ cảnh)

Nhiệm vụ: Xem TV
[Find ]<remote control >(1)
[Find ]<television >(1)
[SwitchOn ]<television >(1)
[Find ]<couch >(1)
[Sit]<couch >(1)
[Touch ]<remote control >(1)
[TurnTo ]<television >(1)
[LookAt ]<television >(1)

Nhiệm vụ: Bật đèn
[Walk ]<dining room>(1)
[Walk ]<light>(1)
[Find ]<light>(1)
[SwitchOn ]<light>(1)
[Find ]<light>(2)
[SwitchOn ]<light>(2)

Nhiệm vụ: Đi ngủ
[Walk ]<bedroom >(1)
[Walk ]<bed>(1)
[Lie]<bed>(1)
[Sleep ]

Nhiệm vụ: Đánh răng
[Walk ]<bathroom >(1)
[Walk ]<toothbrush holder >(1)
[Find ]<toothbrush holder >(1)
[Find ]<toothbrush >(1)
[Grab ]<toothbrush >(1)
[Walk ]<tooth paste>(1)
[Find ]<tooth paste>(1)
[Grab ]<tooth paste>(1)
[Pour ]<tooth paste>(1)<toothbrush >(1)
[Find ]<teeth>(1)
[Scrub ]<teeth>(1)

Bảng 8: Phân bố các loại lỗi của mô hình TREE-PLANNER N=25 có sửa chữa.

Loại Lỗi Giải thích Tỷ lệ(%)
Thiếu Kế hoạch Đúng Lấy mẫu kế hoạch không cho ra các kế hoạch đúng 52.6%
Hiểu lầm Môi trường Hiểu lầm về hành động hoặc đối tượng 21.1%
Kế hoạch Không hoàn chỉnh Thiếu các bước thiết yếu 15.8%
Lỗi Phi logic Kế hoạch được tạo ra là không hợp lý logic 5.3%
Đúng về Ngữ nghĩa Thực hiện thất bại nhưng đúng về ngữ nghĩa 10.5%
Lỗi Quyết định Có căn cứ Lỗi trong quá trình quyết định có căn cứ 47.4%
Quyết định Không đúng Quyết định không đúng tại các nút cụ thể 47.4%
Đúng về Ngữ nghĩa Thực hiện thất bại nhưng đúng về ngữ nghĩa 0.0%

--- TRANG 21 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024

--- TRANG 22 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024

Nhiệm vụ: Ngủ một giấc
[Walk ]<bedroom >(1)

F.2 LẤY MẪU KẾ HOẠCH

(Hướng dẫn) Bạn cần hành động như một người lập kế hoạch nhiệm vụ, phân tách một nhiệm vụ gia đình cấp cao thành nhiều nhiệm vụ con. Mối quan hệ thời gian giữa các chuỗi nhiệm vụ con phải tuân thủ logic thường thức. Mỗi nhiệm vụ con có thể có một trong các dạng sau: 1. [tên hành động]; 2. [tên hành động] <tên đối tượng 1>(id đối tượng 1). 3. [tên hành động] <tên đối tượng 1>(id đối tượng 1) <tên đối tượng 2>(id đối tượng 2). Số lượng đối số phụ thuộc vào loại hành động. (id đối tượng) được sử dụng để báo cho trình mô phỏng rằng các hành động nên được thực hiện trên cùng một thể hiện đối tượng. Ví dụ một chương trình như: [Walk] <glass>(1) [Grab] <glass>(1) Cho biết rằng tác nhân nên đi đến ly trước, và sau đó cầm cùng ly đó.

(Thông tin Toàn cầu) Đối với loại hành động 1, các hành động có sẵn là: [Sleep], [StandUp], [WakeUp]
Đối với loại hành động 2, các hành động có sẵn là: [Walk], [Find], [Grab], [Wash], [Wipe], [Pull], [Push], [Pour], [TurnTo], [PointAt], [Watch], [Touch], [Open], [Close], [Run], [Sit], [Read], [PutOn], [Drop], [Lie], [SwitchOn], [SwitchOff], [Drink]
Đối với loại hành động 3, các hành động có sẵn là: [PutIn], [PutBack]
Tất cả tên hành động của các nhiệm vụ con phải được chọn từ các hành động trên và tuân theo định dạng tương ứng. Bạn đang ở trong một ngôi nhà gồm bốn phòng. Các phòng này là phòng tắm, phòng ăn, phòng ngủ, văn phòng tại nhà. Các đối tượng có sẵn trong nhà là: clothes hat, ceilinglamp, cpuscreen, orchid, couch, trashcan, dresser, dishwasher, centerpiece, phone, toaster, measuring cup, stereo, mat, computer, envelope, oven mitts, piano bench, box, photoframe, shower, ceiling, wall, window, freezer, faucet, detergent, light, desk, napkin, food rice, kitchen counter, folder, stovefan, walllamp, food food, coffee pot, food steak, jelly, vacuum cleaner, powersocket, filing cabinet, alcohol, bathroom, door, bathroom counter, clothes gloves, microwave, oven, sink, milk, ice, bedroom, laptop, doorjamb, food cake, bills, tea bag, television, laser pointer, toilet, board game, sponge, food carrot, table, tray, cupboard, mousepad, picture, tvstand, tablelamp, hanger, pot, drypasta, floor, knifeblock, curtain, chair, food bread, drawing, creditcard, check, coffe maker, character, pasta, bag, food bacon, bookshelf, toothbrush holder, cutting board, home office, diningroom, nail polish, pillow, tape, nightstand, bathroom cabinet, bench, conditioner, cat, bed, keyboard, mouse
Tất cả tên đối tượng phải được chọn từ danh sách đối tượng trên

(Quan sát Ban đầu) Hiện tại, bạn đang đứng trong văn phòng tại nhà, và không cầm gì trong tay phải và không cầm gì trong tay trái.

(Ví dụ Trong Ngữ cảnh)

Nhiệm vụ: Xem TV
[Find ]<remote control >(1)
[Find ]<television >(1)
[SwitchOn ]<television >(1)
[Find ]<couch >(1)
[Sit]<couch >(1)
[Touch ]<remote control >(1)
[TurnTo ]<television >(1)
[LookAt ]<television >(1)

Nhiệm vụ: Bật đèn
[Walk ]<dining room>(1)
[Walk ]<light>(1)
[Find ]<light>(1)
[SwitchOn ]<light>(1)
[Find ]<light>(2)
[SwitchOn ]<light>(2)

Nhiệm vụ: Đi ngủ
[Walk ]<bedroom >(1)
[Walk ]<bed>(1)
[Lie]<bed>(1)

--- TRANG 23 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024

[Sleep ]

Nhiệm vụ: Đánh răng
[Walk ]<bathroom >(1)
[Walk ]<toothbrush holder >(1)
[Find ]<toothbrush holder >(1)
[Find ]<toothbrush >(1)
[Grab ]<toothbrush >(1)
[Walk ]<tooth paste>(1)
[Find ]<tooth paste>(1)
[Grab ]<tooth paste>(1)
[Pour ]<tooth paste>(1)<toothbrush >(1)
[Find ]<teeth>(1)
[Scrub ]<teeth>(1)

Nhiệm vụ: Ngủ một giấc

F.3 QUYẾT ĐỊNH CÓ CĂN CỨ

(Hướng dẫn) Bạn cần hành động như một robot gia đình. Tại mỗi thời điểm, tôi sẽ cung cấp cho bạn các quan sát về môi trường hiện tại của bạn, cũng như nhiệm vụ cấp cao mà tôi muốn bạn thực hiện, và các nhiệm vụ con cấp trung trước đó đã được thực hiện. Sau đó, bạn cần chọn nhiệm vụ con tốt nhất từ các tùy chọn tôi cung cấp để hoàn thành nhiệm vụ gia đình được chỉ định dựa trên quan sát và kinh nghiệm quá khứ của bạn. Khi một nhiệm vụ con được chọn gây ra lỗi trong môi trường, bạn sẽ được cung cấp thông tin lỗi và nhiệm vụ con tương ứng, và bạn cần chọn lại một nhiệm vụ con khắc phục tại bước thời gian hiện tại. Ví dụ, Các nhiệm vụ con đã được thực hiện trong môi trường là:
[GRAB] <plate>(1)
[WALK] <dining room >(1)
Nhiệm vụ con được chọn là: [PUTBACK] <plate>(1)<table>(1)
Lời nhắc (thông tin lỗi) sẽ là: Nhiệm vụ con: "[PUTBACK] <plate>(1)<table>(1)" gây ra lỗi: Script không thể thực thi, vì <character >(1) không gần <table>(1) khi thực hiện "[PUTBACK] <plate>(1)<table>(1) [1]" Trong số các hành động sau, bạn sẽ thực hiện hành động nào.
A. [Find] <table>(1)
B. [Find] <plate>(1)
Một lựa chọn khắc phục của nhiệm vụ con sẽ là (Bạn chỉ cần cung cấp ký hiệu trước tùy chọn bạn muốn chọn): A

(Quan sát) Hiện tại, bạn đang đứng trong phòng ngủ, và không cầm gì trong tay phải và không cầm gì trong tay trái. pillow sạch. napkin sạch. pillow bẩn. bed sạch. mat bẩn. pillow gần drawing. tablelamp gần bed. mat hướng về drawing. pillow bên trong bedroom. mat gần table. bed gần drawing. table gần mat. pillow trên floor. floor gần bed. tablelamp gần pillow. mat gần curtain. bed hướng về computer. mat gần floor. pillow hướng về drawing. curtain gần mat. bed gần tablelamp. wall gần mat. napkin bên trong bedroom. window gần mat. pillow gần tablelamp. bed gần floor. pillow gần wall. mat gần filing cabinet. drawing gần bed. pillow gần floor. bed gần wall. filing cabinet gần mat. bed gần nightstand. mat bên trong bedroom. pillow gần pillow. pillow gần nightstand. mat gần wall. wall gần pillow. nightstand gần pillow. nightstand gần bed. drawing gần pillow. floor gần pillow. bed bên trong bedroom. floor gần mat. wall gần bed. mat gần window. pillow,napkin,pillow,mat,bed,pillow,pillow bên trong bedroom.

Nhiệm vụ của bạn là: Ngủ một giấc.

(Lịch sử)
Các nhiệm vụ con đã thực hiện trước đó của bạn là:
[Walk ]<bedroom >(1)

Trong số các nhiệm vụ con sau, bạn sẽ thực hiện cái nào.
A. [FIND] <bed>(1)
B. [WALK] <couch >(1)
C. [WALK] <bed>(1)
D. [FIND] <couch >(1)
E. [FIND] <pillow >(1)

Lựa chọn tốt nhất của nhiệm vụ con là:

G CÂY HÀNH ĐỘNG TRỰC QUAN HÓA

Chúng tôi đã trực quan hóa các cây hành động cho các nhiệm vụ được liệt kê trong Bảng 9 cho các độc giả quan tâm.

Nhiệm vụ Cây Hành động
Ngủ một giấc Xem Hình 13
Đi giày Xem Hình 14
Nhặt tiền lẻ trên tủ Xem Hình 15
Lau toilet Xem Hình 16
Đặt đồng hồ báo thức vào phòng ngủ Xem Hình 17

Bảng 9: Cây hành động cho các nhiệm vụ khác nhau.

[Tiếp theo là các hình ảnh cây hành động cho từng nhiệm vụ cụ thể - Hình 13, 14, 15, 16, 17]

--- TRANG 24 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024

--- TRANG 25 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024

[Các hình ảnh cây hành động tiếp tục cho đến hết trang 28]

--- TRANG 26 ---
--- TRANG 27 ---
--- TRANG 28 ---

[Phần cuối của bài báo với các cây hành động được minh họa chi tiết cho từng nhiệm vụ cụ thể]

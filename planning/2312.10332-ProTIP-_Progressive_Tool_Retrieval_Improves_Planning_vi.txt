# 2312.10332.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/planning/2312.10332.pdf
# Kích thước tệp: 2752426 byte

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
ProTIP: Truy xuất Công cụ Tiến bộ Cải thiện Lập kế hoạch
Raviteja Anantha*, Bortik Bandyopadhyay*, Anirudh Kashi, Sayantan Mahinder,
Andrew W Hill ,Srinivas Chappidi
Apple
Tóm tắt
Các mô hình ngôn ngữ lớn (LLM) ngày càng được sử dụng cho các tác vụ lập kế hoạch đa bước phức tạp, trong đó bước truy xuất công cụ (TR) đóng vai trò quan trọng để đạt được kết quả thành công. Hai phương pháp phổ biến cho TR là truy xuất một bước, sử dụng truy vấn đầy đủ, và truy xuất tuần tự sử dụng phân rã tác vụ (TD), trong đó một truy vấn đầy đủ được chia thành các tác vụ con nguyên tử rời rạc. Trong khi truy xuất một bước thiếu tính linh hoạt để xử lý "sự phụ thuộc giữa các công cụ," phương pháp TD cần duy trì "sự phù hợp nguyên tử tác vụ con-công cụ," vì hộp công cụ có thể phát triển động. Để giải quyết những hạn chế này, chúng tôi giới thiệu khung Truy xuất Công cụ Tiến bộ để Cải thiện Lập kế hoạch (ProTIP). ProTIP là một khung nhẹ, dựa trên học tương phản, thực hiện TD ngầm mà không cần yêu cầu rõ ràng về nhãn tác vụ con, đồng thời duy trì tính nguyên tử tác vụ con-công cụ. Trên tập dữ liệu ToolBench, ProTIP vượt trội hơn phương pháp phân rã tác vụ dựa trên ChatGPT với biên độ đáng kể, đạt được cải thiện 24% trong Recall@K=10 cho TR và tăng cường 41% trong độ chính xác công cụ cho việc tạo kế hoạch.

1 Giới thiệu
Các mô hình ngôn ngữ lớn (LLM) (Brown et al., 2020; Chowdhery et al., 2022; Ouyang et al., 2022; Zhang et al., 2022; Zeng et al., 2022; OpenAI, 2023b; Touvron et al., 2023; Bubeck et al., 2023; Thoppilan et al., 2022) đã chứng kiến những tiến bộ đáng chú ý trong những năm gần đây, được thúc đẩy bởi việc tiền huấn luyện hiệu quả trên các tập dữ liệu văn bản khổng lồ và việc áp dụng các thuật toán tinh vi như học tăng cường từ phản hồi của con người (RLHF) (Ouyang et al., 2022) để căn chỉnh tốt hơn các mô hình này với sở thích của con người. Tiến bộ này đã mở khóa các khả năng nổi bật (Wei et al., 2022a) trong LLM, có thể được tinh chỉnh thêm để nâng cao khả năng tuân theo hướng dẫn của chúng (Taori et al., 2023; Chiang et al., 2023). Ngoài ra, LLM đã chứng minh tiềm năng cho học trong ngữ cảnh (Brown et al., 2020; Xie et al., 2021; Min et al., 2022) và gợi ý chuỗi suy nghĩ (Wei et al., 2022b; Kojima et al., 2022; Wang et al., 2022), mở rộng khả năng ứng dụng của chúng trên một phổ rộng các lĩnh vực ứng dụng.

Khai thác sức mạnh của LLM như một tác nhân hiểu ngôn ngữ (Shen et al., 2023a) để giải quyết các tác vụ phức tạp đã nổi lên như một lĩnh vực nghiên cứu đang phát triển mạnh. Nỗ lực này đặt ra thách thức do tính phức tạp vốn có của lập kế hoạch đa bước (Huang et al., 2022; Ahn et al., 2022; Singh et al., 2022). Để giải quyết thách thức này, chúng tôi sử dụng một khung lập kế hoạch linh hoạt tích hợp liền mạch một LLM với một hộp công cụ bên ngoài chứa các hành động nguyên tử cụ thể cho ứng dụng. Bộ lập kế hoạch LLM thu hẹp khoảng cách giữa hướng dẫn ngôn ngữ tự nhiên và các hành động có thể thực thi bằng cách chọn hiệu quả các API/công cụ phù hợp từ danh sách được tuyển chọn được trình bày trong prompt LLM. Những công cụ này được truy xuất bằng các kỹ thuật chuyên biệt từ hộp công cụ bên ngoài (Schick et al., 2023; Qin et al., 2023a; Patil et al., 2023; Qin et al., 2023b; Shen et al., 2023a). Các thuật ngữ công cụ và API được sử dụng thay thế cho nhau trong toàn bộ bài báo này.

Trong khung lập kế hoạch đa bước với hộp công cụ bên ngoài, bước truy xuất công cụ (TR) đóng vai trò quan trọng trong việc xác định hiệu suất tổng thể của bộ lập kế hoạch. Bước TR có thể được triển khai như một quy trình một bước sử dụng toàn bộ truy vấn hoặc như một phương pháp lặp phân rã truy vấn thành các tác vụ con nguyên tử riêng lẻ (Khot et al., 2022; Wu et al., 2023). Tuy nhiên, phương pháp TR một bước không thể xử lý "sự phụ thuộc giữa các công cụ" trong các tình huống thực thi đa bước. Hạn chế này trở nên rõ ràng, ví dụ, khi chọn giữa công cụ-A và công cụ-B, trong đó sự lựa chọn phụ thuộc vào việc thực thi thành công của một công cụ đã chọn trước đó.

--- TRANG 2 ---
Ngược lại, phương pháp TR dựa trên TD cần duy trì sự phù hợp giữa tác vụ con chính xác được đề cập và công cụ thích hợp sẽ được sử dụng từ phiên bản hộp công cụ được sử dụng, do đó tạo ra vấn đề "sự phù hợp nguyên tử tác vụ con-công cụ" khi huấn luyện bộ lập kế hoạch. Sự phụ thuộc này thường yêu cầu điều chỉnh thường xuyên các mô hình TD nhẹ hoặc sử dụng một LLM, như ChatGPT (OpenAI, 2023a), cho TD. Hơn nữa, cả hai phương pháp này hoạt động trong không gian văn bản, làm cho chúng dễ bị ảnh hưởng bởi các vấn đề khác nhau như token "ngoài từ vựng", có thể cản trở biểu diễn ngữ nghĩa chính xác của các tác vụ con và cuối cùng ảnh hưởng đến hiệu suất của bộ lập kế hoạch.

Để vượt qua những hạn chế này, chúng tôi giới thiệu khung Truy xuất Công cụ Tiến bộ để Cải thiện Lập kế hoạch (ProTIP). Chiến lược TR của chúng tôi lấy cảm hứng từ những tiến bộ trong tài liệu nhúng từ, trong đó các nghiên cứu trước (Mikolov et al., 2013a; Pennington et al., 2014; Levy và Goldberg, 2014) đã cho thấy hiệu quả của việc biểu diễn mối quan hệ ngữ nghĩa giữa các từ bằng cách nhúng chúng trong không gian vector. Mở rộng khái niệm này cho các truy vấn và công cụ phức tạp, chúng tôi tận dụng việc tinh chỉnh cụ thể theo tác vụ để đạt được các yêu cầu TR tiến bộ của chúng tôi.

ProTIP ban đầu mã hóa truy vấn đã cho và mô tả công cụ để giảm thiểu khoảng cách Euclidean giữa các công cụ liên quan tương ứng với tác vụ con đầu tiên và truy vấn trong không gian ngữ nghĩa, mà không thực hiện rõ ràng phân rã tác vụ. Sau đó, mô-đun ProTIP lặp đi lặp lại biến đổi nhúng truy vấn bằng cách trừ nhúng mô tả công cụ đã truy xuất trước đó từ nhúng truy vấn. Nhúng kết quả từ phép trừ lặp này phù hợp chặt chẽ hơn trong không gian ngữ nghĩa với một truy vấn ngôn ngữ tự nhiên được hình thành bằng cách loại bỏ các tác vụ con đã thực thi trước đó từ truy vấn đầy đủ, trong khi tập trung vào tác vụ con quan trọng tiếp theo sẽ được thực thi trong số các tác vụ còn lại. ProTIP được tinh chỉnh bằng cách sử dụng mất mát tương phản để học các nhúng với các đặc điểm được đề cập ở trên, chi tiết hơn trong phần 3.1. Kết quả là, ProTIP cung cấp tính linh hoạt bằng cách cho phép TR tăng dần, trong khi kết hợp lịch sử thực thi (ví dụ: công cụ đã chọn trước đó và kết quả thực thi) mà không có chi phí duy trì tính nguyên tử cho TD. Các đóng góp của công việc này như sau:

• Chúng tôi giới thiệu ProTIP, một khung TR tiến bộ mới, thực hiện hiệu quả TR cho các yêu cầu phức tạp liên quan đến sự phụ thuộc giữa các tác vụ con, trong khi tính đến lịch sử thực thi, mà không cần TD rõ ràng.
• Chúng tôi so sánh toàn diện các phương pháp TR khác nhau và tác động của chúng đối với các tác nhân lập kế hoạch được hỗ trợ bởi LLM sử dụng tập dữ liệu ToolBench công khai (Qin et al., 2023b).
• Theo hiểu biết của chúng tôi, chúng tôi là những người đầu tiên thiết lập rằng các phương pháp truy xuất công cụ dựa trên tinh chỉnh nhẹ (không phải LLM), như ProTIP, có thể vượt trội hơn các phương pháp tăng cường LLM hiện đại, như TD dựa trên ChatGPT cho TR.

2 Dữ liệu
Chúng tôi đánh giá hiệu quả của LLM-Planner dựa trên ProTIP trong việc tạo ra các kế hoạch từng bước sử dụng tập dữ liệu ToolBench (Qin et al., 2023b), một trong những tập dữ liệu huấn luyện điều chỉnh hướng dẫn rộng lớn nhất cho việc sử dụng công cụ, bao gồm 16.000 công cụ và 49 danh mục. ToolBench bao gồm 27.000 yêu cầu phức tạp, mỗi yêu cầu có thể đòi hỏi việc sử dụng một hoặc nhiều API/Công cụ để hoàn thành các tác vụ con theo một thứ tự cụ thể. Mỗi yêu cầu đi kèm với nhãn công cụ và kế hoạch, đại diện cho một loạt các hướng dẫn từng bước chi tiết hơn.

Hình 1 minh họa phân phối số lượng công cụ cần thiết cho mỗi truy vấn, cung cấp hiểu biết về độ phức tạp của các yêu cầu trong tập dữ liệu. Phân tích cho thấy số lượng tác vụ con tối đa trong một truy vấn là 6. Thông tin này được sử dụng để thiết lập giới hạn trên cho top-k trong các thí nghiệm TR và lập kế hoạch, như được chi tiết trong phần 3.2.

Hình 2 cho thấy phân phối độ dài token đầu vào cho bộ lập kế hoạch trong các tập huấn luyện và kiểm tra. Đáng chú ý, 12,25% (97 điểm dữ liệu) của tập kiểm tra và 12,30% (9.070 điểm dữ liệu) của tập huấn luyện vượt quá kích thước cửa sổ ngữ cảnh là 2048. Tỷ lệ đáng kể này của các đầu vào dài dự kiến sẽ gây ra cắt ngắn, có thể cản trở khả năng đạt được hiệu suất tối ưu của mô hình.

Hình 3 mô tả phân phối các ID công cụ ground truth trong tập dữ liệu. Đáng chú ý, một tỷ lệ đáng kể của các ID công cụ nằm trong phạm vi từ 0 đến 2000 cho cả tập huấn luyện và kiểm tra. Sự mất cân bằng này trong biểu diễn công cụ có thể gây thiên vị mô hình về phía những công cụ xuất hiện thường xuyên hơn này.

--- TRANG 3 ---
Hình 1: Phân phối các yêu cầu trong tập huấn luyện (trái) và kiểm tra (phải) ToolBench theo số lượng tác vụ con liên quan đến mỗi yêu cầu.

Hình 2: Phân phối độ dài token đầu vào cho bộ lập kế hoạch trong dữ liệu huấn luyện (trái) và kiểm tra (phải). Đầu vào bao gồm truy vấn, các công cụ truy xuất top-k, prompts cụ thể cho bộ lập kế hoạch, và lịch sử thực thi.

Hình 3: Phân phối tần suất của các công cụ ground truth trong tập huấn luyện (trái) và kiểm tra (phải). Tên công cụ đã được chuyển đổi thành ID để rõ ràng trong trực quan hóa.

Tập dữ liệu ToolBench được tạo ra bằng ChatGPT. Như điển hình với dữ liệu được tạo ra bởi LLM mà không có quyền truy cập vào kiến thức bổ sung, ToolBench dễ bị ảo giác (Bang et al., 2023). Một ví dụ về điều này có thể thấy trong hình 4, nơi tập dữ liệu tổng hợp chứa công cụ ảo giác

--- TRANG 4 ---
Hình 4: Một ví dụ về ảo giác công cụ trong tập dữ liệu ToolBench.

invalid_hallucination_function_name ở bước thứ hai và thứ ba. Để giải quyết vấn đề này, chúng tôi đã loại bỏ các yêu cầu với chú thích công cụ tưởng tượng, là những công cụ không được bao gồm trong hộp công cụ. Ngoài ra, chúng tôi đã xem xét thủ công và sửa chữa các công cụ được trích xuất không chính xác còn lại do lỗi ngữ pháp trong các nhãn được tạo ra. Sau quá trình làm sạch dữ liệu, các tập dữ liệu huấn luyện và kiểm tra được sửa đổi bao gồm 25.489 và 274 yêu cầu phức tạp, tương ứng. Sử dụng tập dữ liệu này, chúng tôi cũng thực hiện TD bằng ChatGPT như được mô tả trong phần 3.1. Sau khi lọc ra các ngoại lệ với các tác vụ không hợp lệ, chúng tôi có được một tập dữ liệu gồm 25.124 điểm dữ liệu huấn luyện và 268 điểm dữ liệu kiểm tra, mà chúng tôi sử dụng cho tất cả các thí nghiệm của mình. Số lượng tác vụ con trung bình trong các tập dữ liệu cuối cùng của chúng tôi là 2.934 (Độ lệch chuẩn = 1.417) cho tập huấn luyện và 2.955 (Độ lệch chuẩn = 1.39) cho tập kiểm tra.

3 Phương pháp luận
Để đánh giá khung ProTIP cho các tác vụ TR và lập kế hoạch, chúng tôi sử dụng cả đường cơ sở tìm kiếm dựa trên văn bản và vector, cũng như một đường cơ sở mạnh của lập kế hoạch dựa trên TD, trên các phần chia huấn luyện và kiểm tra từ tập dữ liệu ToolBench sau bước tiền xử lý để loại bỏ dữ liệu chất lượng kém, như được mô tả trong Phần 2. Hình 5 minh họa luồng từ đầu đến cuối được hình dung của chúng tôi về lập kế hoạch từng bước dựa trên ProTIP.

3.1 Truy xuất Công cụ
Truy xuất Công cụ (TR) nhằm xác định top-k công cụ phù hợp nhất để trao quyền cho bộ lập kế hoạch thực thi hiệu quả tất cả các tác vụ con trong một yêu cầu phức tạp đã cho. Hộp công cụ T = {(t₁, d₁), (t₂, d₂), ..., (tₙ, dₙ)} bao gồm một tập hợp các công cụ đa dạng tᵢ với các chức năng được xác định trước, được nắm bắt trong mô tả công cụ dᵢ của chúng. Một mục tiêu chính của TR là trích xuất các tác vụ con từ một truy vấn phức tạp phù hợp với các chức năng được xác định trước của các công cụ, một khái niệm chúng tôi gọi là sự phù hợp nguyên tử tác vụ con-công cụ và sau đó truy xuất những công cụ đó.

Khi sử dụng các phương pháp truy xuất dựa trên vector, hộp công cụ T thường được biểu diễn như một cơ sở dữ liệu vector. Một bộ mã hóa Eᵥ(.) được tham số hóa trên w tạo ra các nhúng mô tả công cụ, Eᵥ(dᵢ), sau đó được lưu trữ. Cùng một bộ mã hóa hoặc một bộ mã hóa cụ thể cho truy vấn ánh xạ truy vấn phức tạp q thành một nhúng Eᵥ(q). Một thước đo tương tự, như độ tương tự cosine, giữa Eᵥ(dᵢ) và Eᵥ(q) được sử dụng để truy xuất top-k công cụ.

Nghiên cứu này sử dụng một bộ phương pháp truy xuất toàn diện, bao gồm cả các phương pháp được huấn luyện trước và tinh chỉnh, bao gồm phương pháp ProTIP được đề xuất của chúng tôi, để đánh giá hiệu quả của các chiến lược TR khác nhau sử dụng thước đo Recall@k.

BM25: Đường cơ sở truy xuất dựa trên văn bản được sử dụng trong nghiên cứu này là BM25 (Robertson et al., 1995). Để truy xuất top-k công cụ, chúng tôi sử dụng truy vấn phức tạp đầy đủ q để tính điểm BM25 cho mỗi mô tả công cụ dᵢ.

Tìm kiếm Ngữ nghĩa: Đối với tìm kiếm dựa trên vector, chúng tôi sử dụng GTR-T5-XL (Ni et al., 2021) làm bộ mã hóa cho cả truy vấn q và mô tả công cụ dᵢ. Thước đo độ tương tự cosine cos_sim(q, dᵢ) được sử dụng để chọn top-K công cụ liên quan nhất.

TR dựa trên Phân rã Tác vụ: Phân rã Tác vụ (TD) (Khot et al., 2022; Wu et al., 2023) chia nhỏ một truy vấn phức tạp q thành một tập hợp các truy vấn con {q₁, q₂, ..., qτ}, trong đó τ biểu thị số lượng tác vụ con được nhúng trong q, và mỗi qᵢ đại diện cho một truy vấn con tương ứng với tác vụ con thứ i của q.

Việc đánh giá truy xuất dựa trên TD bao gồm việc sử dụng cả mô hình BM25 và tìm kiếm ngữ nghĩa sử dụng GTR-T5-XL. Đối với mỗi qᵢ từ TD, chúng tôi thực hiện truy xuất song song sử dụng BM25 cho truy xuất dựa trên văn bản và GTR-T5-XL cho truy xuất dựa trên vector. Điều này dẫn đến việc xác định top-k công cụ cụ thể cho mỗi qᵢ. Sau đó, chúng tôi sử dụng chiến lược xen kẽ để xác định top-k công cụ cuối cùng cho q. Phương pháp xen kẽ công cụ với TD này phục vụ như một đường cơ sở đơn giản nhưng mạnh mẽ.

--- TRANG 5 ---
Hình 5: Xử lý từ đầu đến cuối các truy vấn phức tạp với lập kế hoạch dựa trên ProTIP.

Chúng tôi chọn xen kẽ công cụ thay vì sử dụng trực tiếp tất cả các truy vấn con đồng thời, vì top-k công cụ thu được bằng cách sử dụng tập truy vấn con có thể không phù hợp với top-k công cụ mong muốn, trong đó mỗi tác vụ con hiệu quả bao phủ các công cụ liên quan. Chúng tôi sử dụng mô hình ChatGPT (OpenAI, 2023a) để tạo ra các viết lại TD.

ProTIP: Chúng tôi đề xuất ProTIP, một chiến lược truy xuất công cụ tiến bộ, trong đó top-k công cụ cụ thể cho mỗi tác vụ con được truy xuất lặp đi lặp lại có điều kiện trên lịch sử thực thi trong khi duy trì thứ tự tác vụ con. Truy xuất dựa trên TD tạo ra các tác vụ con mà không tính đến lịch sử thực thi. Trong khi truy xuất dựa trên TD có thể được điều chỉnh để tận dụng lịch sử thực thi, nó vẫn yêu cầu một LLM được huấn luyện trước đắt tiền đủ mạnh để tạo ra các viết lại chất lượng cao, hoặc nhãn phân rã tác vụ rõ ràng để tinh chỉnh một mô hình nhẹ để tạo ra các viết lại. Ngoài ra, các nhãn TD cũng nên đảm bảo sự phù hợp nguyên tử tác vụ con-công cụ được duy trì.

Hình 6: Cơ chế học ngầm của ProTIP để xử lý các truy vấn phức tạp. Truy xuất ban đầu chọn công cụ liên quan đến tác vụ con đầu tiên. Sau đó, lịch sử thực thi, bao gồm mô tả công cụ và truy vấn, được sử dụng để tạo ra một nhúng kết quả E(q'₂). Nhúng này được thiết kế đặc biệt để phù hợp với E(q₂), đại diện cho tác vụ con thứ hai, mà không cần nhãn truy vấn con q₂.

ProTIP là một mô hình truy xuất nhẹ không yêu cầu nhãn rõ ràng. Thay vì dựa vào biểu diễn văn bản trung gian, ProTIP hoạt động trực tiếp trong không gian vector bằng cách biến đổi các nhúng đầu vào để loại bỏ các tác vụ con đã được giải quyết.

Cho một truy vấn phức tạp q bao gồm n tác vụ con, hãy để q₁...qₙ biểu thị các truy vấn chỉ nắm bắt mỗi tác vụ con từ 1... n. Chúng tôi sử dụng mô hình BERT-base-uncased* làm bộ mã hóa cho cả q và mô tả công cụ dᵢ, được biểu diễn bởi Eᵥ(.). Đối với mỗi batch huấn luyện có kích thước b, chúng tôi tinh chỉnh Eᵥ(.) để luôn chọn công cụ ground-truth t^pos₁ tương ứng với tác vụ con-1 bằng cách giảm thiểu khoảng cách giữa d^pos₁ và q, trong khi tối đa hóa khoảng cách giữa q và một tập hợp các ví dụ âm được rút ngẫu nhiên, T^neg = {t^neg₁, t^neg₂, ..., t^neg_{b-1}}, từ các công cụ không liên quan. Đối với các bước truy xuất tiếp theo, bắt đầu từ tác vụ con-2, chúng tôi lặp đi lặp lại trừ Eᵥ(t^pos₁) đến Eᵥ(t^pos_i) từ Eᵥ(q) để đến một nhúng xấp xỉ một truy vấn q' chỉ đại diện cho các tác vụ con từ i+1 đến n. Thao tác này trực tiếp dẫn đến việc học ngầm phân rã tác vụ trong khi duy trì tính nguyên tử tác vụ con-công cụ mà không cần nhãn rõ ràng, như được mô tả trong Hình 6.

Chúng tôi sử dụng mất mát tương phản (Hadsell et al., 2006) để tinh chỉnh truy xuất của chúng tôi, phù hợp với học dựa trên thước đo. Cho cặp đầu vào với đầu vào I₁ và I₂, mất mát tương phản khuyến khích các ví dụ tương tự gần nhau, và các ví dụ không tương tự có khoảng cách cao hơn ít nhất là margin m với nhau. Chúng tôi định nghĩa đầu vào I₁ cho nhúng truy vấn như sau:

I₁ = {
    Eᵥ(q), cho truy xuất ban đầu
    Eᵥ(q) - Σ_{1≤i<n}(Eᵥ(dᵢ)), ngược lại
}                                     (1)

trong đó Σ đại diện cho tổng vector theo từng phần tử. Chúng tôi định nghĩa nhúng mô tả công cụ* I₂ như sau:

I₂ = Eᵥ(d_{j+1}),                    (2)

trong đó j ≥ 0.

Hàm mất mát tương phản dựa trên margin được định nghĩa như sau:

L = ½lD² + ½(1-l){max(0, m-D)}²,    (3)

trong đó l là một nhãn nhị phân cho biết liệu cặp đầu vào bao gồm nhúng truy vấn I₁ và nhúng mô tả công cụ I₂ có phải là cặp dương (l=1) hay âm (l=0), m>0 là khoảng cách margin cho các cặp không tương tự và chúng tôi sử dụng 0.3. D là thước đo khoảng cách lựa chọn và chúng tôi sử dụng chuẩn L2 giữa I₁ và I₂. Tương tự như TR dựa trên TD, chúng tôi sử dụng chiến lược xen kẽ công cụ để xác định top-K công cụ cuối cùng cho đánh giá Recall@k.

3.2 Lập kế hoạch Tiến bộ
Để truy xuất công cụ cho tác vụ lập kế hoạch tiến bộ, chúng tôi sử dụng các chiến lược truy xuất công cụ (TR) được đề xuất trong Phần 3.1. Sau đó chúng tôi thực hiện tinh chỉnh có giám sát của mô hình OpenLLaMA-7B-v2 (Touvron et al., 2023; Geng và Liu, 2023; Computer, 2023), tận dụng thư viện HuggingFace Transformer (Wolf et al., 2019). Mô hình hoạt động với kích thước cửa sổ ngữ cảnh là 2048 token. Prompt được cung cấp cho mô hình bao gồm một hướng dẫn cố định, yêu cầu phức tạp, và thông tin tùy chọn như danh sách top-k ứng viên API (cùng với metadata của chúng) và lịch sử thực thi. Sự kết hợp này tạo ra nhiều biến thể prompt khác biệt.* Về bản chất, mục tiêu của chúng tôi là dự đoán API tiếp theo sẽ được thực thi trong một kế hoạch đa bước cho một prompt đầu vào chứa hướng dẫn, yêu cầu, ứng viên API, và lịch sử. Điều này yêu cầu mở rộng dữ liệu gốc để tạo thành một chuỗi các prompt tương ứng với mỗi bước trong kế hoạch.

Mỗi tương tác trong dữ liệu gốc bao gồm một mô tả ngôn ngữ tự nhiên của truy vấn đầy đủ. Ngoài ra, mỗi tương tác bao gồm tổng cộng p bước được gán nhãn assistant và f bước được gán nhãn function, cùng với các đầu vào tiềm năng từ người dùng được gán nhãn là user (chúng tôi bỏ qua các đầu vào system). Để chuẩn bị dữ liệu huấn luyện và kiểm tra cho bộ lập kế hoạch, chúng tôi mở rộng mỗi tương tác thành p trường hợp dữ liệu mở rộng riêng biệt. Trong mỗi trường hợp dữ liệu mở rộng, văn bản được tạo ra bởi assistant cho bước cụ thể đó phục vụ như đầu ra mong muốn, được gọi là phản hồi, trong khi toàn bộ chuỗi các bước trước bước hiện tại tạo thành lịch sử. Như một quy tắc chung, chúng tôi sử dụng truy vấn đầy đủ gốc của tương tác làm yêu cầu. Trong trường hợp một đầu vào xảy ra giữa các bước, chúng tôi chỉ đơn giản thêm nó vào phần yêu cầu tiếp theo. Đáng chú ý, dữ liệu huấn luyện và kiểm tra khác nhau về mặt các công cụ được trình bày như ứng viên API trong prompt đầu vào.

Huấn luyện: Để cung cấp cho bộ lập kế hoạch một tập hợp các công cụ tiềm năng toàn diện, chúng tôi sử dụng tất cả p công cụ ground truth được xác định trong các bước assistant của dữ liệu gốc làm ứng viên API. Chiến lược TR oracle sử dụng tập chính xác p công cụ ground truth (p≤6) cần thiết cho toàn bộ kế hoạch trong prompt cho mỗi bước, gần giống với một tác vụ ghi nhớ. Ngược lại, các bộ lập kế hoạch dựa trên TR top-k tăng cường prompt với (K-p) công cụ được lấy mẫu ngẫu nhiên bổ sung cho mỗi bước, trong đó K>p, cùng với p công cụ ground truth. Phương pháp này giới thiệu một yếu tố không chắc chắn và thách thức bộ lập kế hoạch xác định công cụ liên quan nhất cho bước hiện tại. Để đảm bảo công cụ chính xác luôn có mặt trong prompt, chúng tôi duy trì tất cả các công cụ ground truth từ kế hoạch đầy đủ trong quá trình huấn luyện của mỗi bước. Chiến lược này hướng dẫn bộ lập kế hoạch hướng tới việc học chọn công cụ phù hợp nhất cho tác vụ hiện tại. Cân bằng giữa kích thước cửa sổ ngữ cảnh tối đa của LLM là 2048 và giá trị tối đa của p (6), chúng tôi đặt k=10 trong các thí nghiệm của mình. Để ngăn LLM khai thác vị trí của công cụ chính xác, chúng tôi ngẫu nhiên hóa thứ tự của các công cụ được trình bày trong prompt trong quá trình huấn luyện và kiểm tra.

Kiểm tra: Trong chiến lược TR oracle, chúng tôi sử dụng chính xác p công cụ ground truth được xác định từ các bước assistant của dữ liệu gốc làm Ứng viên API cho mỗi bước. Phương pháp này cung cấp cho Bộ lập kế hoạch một tập hợp đầy đủ các công cụ cần thiết cho mỗi bước, hiệu quả biến tác vụ thành một vấn đề lựa chọn công cụ. Ngược lại, đối với các bộ lập kế hoạch dựa trên TR top-K, chúng tôi sử dụng top-10 công cụ được truy xuất bởi các thuật toán tương ứng, có thể bao gồm hoặc không bao gồm công cụ ground truth. Ngoài ra, chúng tôi sử dụng xen kẽ công cụ, khi áp dụng được.

Đánh giá: Trong khi các thước đo NLP tiêu chuẩn như Exact Match (EM)* và ROUGELSum (Lin, 2004) thường được sử dụng để đánh giá chất lượng văn bản tổng thể của kế hoạch được tạo ra, trọng tâm chính của chúng tôi là đánh giá hiệu suất của LLM trong việc chọn các công cụ phù hợp. Do đó, chúng tôi sử dụng các thước đo Tool Accuracy (TA) và Tool Hallucination (TH), tập trung đặc biệt vào thành phần API của đầu ra được dự đoán và bỏ qua chi tiết tham số.

--- TRANG 6 ---
trong đó Σ đại diện cho tổng vector theo từng phần tử. Chúng tôi định nghĩa nhúng mô tả công cụ* I₂ như sau:

I₂ = Eᵥ(d_{j+1}),                    (2)

trong đó j ≥ 0.

Hàm mất mát tương phản dựa trên margin được định nghĩa như sau:

L = ½lD² + ½(1-l){max(0, m-D)}²,    (3)

trong đó l là một nhãn nhị phân cho biết liệu cặp đầu vào bao gồm nhúng truy vấn I₁ và nhúng mô tả công cụ I₂ có phải là cặp dương (l=1) hay âm (l=0), m>0 là khoảng cách margin cho các cặp không tương tự và chúng tôi sử dụng 0.3. D là thước đo khoảng cách lựa chọn và chúng tôi sử dụng chuẩn L2 giữa I₁ và I₂. Tương tự như TR dựa trên TD, chúng tôi sử dụng chiến lược xen kẽ công cụ để xác định top-K công cụ cuối cùng cho đánh giá Recall@k.

3.2 Lập kế hoạch Tiến bộ
Để truy xuất công cụ cho tác vụ lập kế hoạch tiến bộ, chúng tôi sử dụng các chiến lược truy xuất công cụ (TR) được đề xuất trong Phần 3.1. Sau đó chúng tôi thực hiện tinh chỉnh có giám sát của mô hình OpenLLaMA-7B-v2 (Touvron et al., 2023; Geng và Liu, 2023; Computer, 2023), tận dụng thư viện HuggingFace Transformer (Wolf et al., 2019). Mô hình hoạt động với kích thước cửa sổ ngữ cảnh là 2048 token. Prompt được cung cấp cho mô hình bao gồm một hướng dẫn cố định, yêu cầu phức tạp, và thông tin tùy chọn như danh sách top-k ứng viên API (cùng với metadata của chúng) và lịch sử thực thi. Sự kết hợp này tạo ra nhiều biến thể prompt khác biệt.* Về bản chất, mục tiêu của chúng tôi là dự đoán API tiếp theo sẽ được thực thi trong một kế hoạch đa bước cho một prompt đầu vào chứa hướng dẫn, yêu cầu, ứng viên API, và lịch sử. Điều này yêu cầu mở rộng dữ liệu gốc để tạo thành một chuỗi các prompt tương ứng với mỗi bước trong kế hoạch.

*https://huggingface.co/bert-base-uncased

--- TRANG 7 ---
4 Kết quả
4.1 Truy xuất Công cụ
Đối với Recall@K, chúng tôi bắt đầu từ K=6 vì số lượng tác vụ con tối đa cho một truy vấn phức tạp trong tập dữ liệu ToolBench là 6, như được mô tả trong Phần 2. Bảng 1 cho thấy recall của các phương pháp truy xuất khác nhau cho các giá trị K khác nhau.

Phương pháp                          Recall@K
                            K=6   K=10  K=15  K=20
BM25 dựa trên truy vấn đầy đủ    31.87  41    45.72  48.71
BM25 dựa trên TD               41.26  47    50.70  54.74
SS dựa trên truy vấn đầy đủ      54.24  60.86  65.93  69.52
SS dựa trên TD                 57.81  65.57  69.85  72.8
ProTIP                        80.55  81.36  82.35  83.48

Bảng 1: Đánh giá các phương pháp truy xuất công cụ khác nhau trên tập kiểm tra ToolBench. Các phương pháp "dựa trên TD" sử dụng phân rã tác vụ bởi ChatGPT và chạy truy xuất song song cho tất cả các tác vụ con, đến top-K công cụ thông qua xen kẽ. "SS" là viết tắt của Tìm kiếm Ngữ nghĩa.

Hình 7: So sánh phân phối độ tương tự cosine giữa Tìm kiếm Ngữ nghĩa và Truy xuất Công cụ Tiến bộ. Độ tương tự cosine được tính giữa mô tả công cụ ground-truth và các truy vấn phức tạp từ dữ liệu kiểm tra ToolBench.

Các phương pháp truy xuất dựa trên vector vượt trội hơn các phương pháp truy xuất dựa trên văn bản, và truy xuất tăng cường TD sử dụng chiến lược xen kẽ công cụ cho thấy những cải thiện đáng kể so với các đường cơ sở này. ProTIP vượt trội hơn phương pháp truy xuất dựa trên TD có hiệu suất tốt nhất trên tất cả các giá trị K. Như được minh họa trong Hình 7, việc sử dụng học tương phản của ProTIP tăng cường độ tương tự cosine giữa các công cụ liên quan và các truy vấn con ngầm. Cải thiện này xuất phát từ các biến đổi lặp được thực hiện trực tiếp trong không gian vector, tránh yêu cầu văn bản trung gian như trong các phương pháp dựa trên TD. Do đó, ProTIP có được khả năng học ngầm để dự đoán tác vụ con tiếp theo và công cụ liên quan trong khi bảo tồn thứ tự tác vụ con. Hiệu quả của khung ProTIP trong việc xử lý các truy vấn được đặc trưng bởi các hiện tượng ngôn ngữ phức tạp, như thiếu trôi chảy, vẫn cần được đánh giá.

4.2 Lập kế hoạch Tiến bộ
Khung lập kế hoạch tiến bộ cung cấp vô số tùy chọn có thể cấu hình, bao gồm việc xây dựng prompt (có hoặc không có lịch sử, có hoặc không có công cụ ứng viên, v.v.) và loại metadata công cụ được sử dụng (ví dụ: chỉ tên công cụ so với tên công cụ và mô tả). Để cung cấp một đánh giá đại diện của tác vụ lập kế hoạch tiến bộ, chúng tôi đã chọn một tập hợp con của các cấu hình này và đánh giá hiệu suất của các chiến lược TR khác nhau trên tập kiểm tra đã được tiền xử lý. Kết quả được trình bày trong Bảng 2. Cài đặt 1-6 sử dụng các chiến lược TR khác nhau được giới thiệu trong bài báo này, trong khi cài đặt 7-10 sử dụng chiến lược TR oracle. Để đảm bảo so sánh công bằng với các chiến lược TR dựa trên truy vấn đầy đủ, chúng tôi đã áp dụng chiến lược xen kẽ (được chi tiết trong Phần 3.1) để tạo ra các tập hợp công cụ ứng viên cho TR tiến bộ (PTR).

Bộ Lập kế hoạch Oracle: Để đánh giá hiệu suất của bộ lập kế hoạch được tinh chỉnh dựa trên PTR đề xuất của chúng tôi, chúng tôi thiết lập một điểm chuẩn sử dụng một số bộ lập kế hoạch Oracle được tinh chỉnh. Những bộ lập kế hoạch Oracle này sử dụng tập hợp đầy đủ p công cụ ground truth (GT), cần thiết để thực thi toàn bộ kế hoạch, trong prompt, bắt chước thuật toán Oracle TR. Cài đặt 7-8 kết hợp tổng cộng 10 công cụ, bao gồm p công cụ GT và (10-p) công cụ được lấy mẫu ngẫu nhiên, trong khi cài đặt 9-10 sử dụng chính xác p công cụ GT trong prompt. Cài đặt 9-10 có thể được coi là một giới hạn trên mạnh có thể đạt được bằng Oracle TR vì hai lý do: a) prompt đầu vào chứa tất cả công cụ GT cần thiết để thực thi toàn bộ kế hoạch, và b) mô hình được tinh chỉnh một phần ghi nhớ quá trình lựa chọn công cụ cho mỗi bước cho một truy vấn cụ thể. Chúng tôi tin rằng điều này đại diện cho một giới hạn trên xấp xỉ về hiệu suất có thể đạt được bởi một LLM-Planner được tinh chỉnh sử dụng chiến lược Oracle TR, giả sử bước TR đạt được 100% Recall cho các công cụ cần thiết cho mỗi bước của truy vấn đầy đủ.

--- TRANG 8 ---
ID  Truy xuất Công cụ                              Cài đặt  Prompt  EM     RLSum  TA(%)  TH(%)
1   BM25 với truy vấn đầy đủ                       [T+H]   0.0442 0.3672 14.77  12.37
2   SS với truy vấn đầy đủ                         [T+H]   0.0619 0.4086 21.72  7.7
3   BM25 với truy vấn TD (Xen kẽ công cụ)         [T+H]   0.053  0.39   16.29  8.96
4   SS với truy vấn TD (Xen kẽ công cụ)           [T+H]   0.0833 0.4424 25.88  8.21
5   PTR (Xen kẽ công cụ)                          [T]     0.0543 0.4129 19.82  2.02
6   PTR (Xen kẽ công cụ)                          [T+H]   0.0896 0.4772 36.49  7.95
7   Oracle (GT + công cụ ngẫu nhiên)              [T]     0.0896 0.5232 44.57  4.17
8   Oracle (GT + công cụ ngẫu nhiên)              [T+H]   0.1805 0.6669 77.53  17.55
9   Oracle (chỉ công cụ GT)                       [T]     0.2146 0.579  46.59  5.3
10  Oracle (chỉ công cụ GT)                       [T+H]   0.3952 0.757  80.3   17.55

Bảng 2: Hiệu suất tạo kế hoạch tiến bộ sử dụng các kết hợp khác nhau của thuật toán truy xuất công cụ và chiến lược tạo prompt. Prompt có thể chỉ bao gồm danh sách công cụ ([T]) hoặc cả lịch sử và công cụ ([T+H]). Chúng tôi trình bày kết quả cho các tình huống trong đó prompt chỉ bao gồm tên công cụ làm metadata công cụ. Đối với một cài đặt prompt nhất định (tức là [T+H]), ProTIP luôn vượt trội hơn các phương pháp đường cơ sở khác, như BM25 và SS, cả với và không có phân rã tác vụ. Một cải thiện tuyệt đối đáng kể 15.79% trong Recall@10 giữa SS dựa trên TD và ProTIP dẫn đến một sự gia tăng tuyệt đối 10.61% trong Tool Accuracy cho Bộ lập kế hoạch, kèm theo giảm 0.26% trong Tool Hallucination.

Bộ Lập kế hoạch TR: Luôn vượt trội hơn các đường cơ sở khác như BM25 và SS, PTR thể hiện hiệu suất vượt trội dưới cài đặt prompt [T+H], bất kể TD có được sử dụng hay không. Sự vượt trội này được củng cố thêm bởi mối tương quan được quan sát giữa Recall@K của thuật toán TR (BM25 < SS < PTR) và Tool Accuracy (TA) của Bộ lập kế hoạch. Ngoài ra, hiệu suất tốt hơn của TR dựa trên BM25 và SS cho các truy vấn được phân rã tác vụ được phản ánh trong hiệu suất Bộ lập kế hoạch tương ứng. Điều này phù hợp với thiết kế của Bộ lập kế hoạch, yêu cầu lựa chọn công cụ từ tập hợp được truy xuất của thuật toán TR. Thú vị là, tỷ lệ phần trăm Tool Hallucination (TH), đại diện cho tỷ lệ các lần Bộ lập kế hoạch tạo ra các công cụ không tồn tại, tiết lộ một hệ quả của việc không tuân thủ nguyên tắc thiết kế này. PTR không có lịch sử thể hiện tỷ lệ TH thấp nhất, mặc dù TA tương đối thấp. Khi kết hợp lịch sử, cả PTR (cài đặt 6) và Oracle (cài đặt 8 và 10) đều trải qua sự gia tăng trong TA và TH, có thể do các vấn đề cắt ngắn (được thảo luận trong Phần 5). Đáng chú ý, TA cao hơn trong PTR dẫn đến những cải thiện biên trong Exact Match (EM) và ROUGELSum (RLSum), các thước đo đánh giá toàn bộ đầu ra được dự đoán, bao gồm các tham số công cụ. Những cải thiện tương đối khiêm tốn trong các thước đo này cho thấy rằng có thể đạt được những nâng cao hiệu suất thêm bằng cách tập trung vào tối ưu hóa tham số công cụ. Khoảng cách hiệu suất giữa các bộ lập kế hoạch Oracle (cài đặt 6 đến 10) và bộ lập kế hoạch dựa trên PTR làm nổi bật tiềm năng cho những cải thiện hiệu suất Bộ lập kế hoạch thêm.

Tầm quan trọng của lịch sử cho Lập kế hoạch: Việc bao gồm lịch sử các bước trước đó thể hiện một sự thúc đẩy hiệu suất đáng kể trong lập kế hoạch trên tất cả các cài đặt. Cải thiện này đặc biệt rõ rệt đối với cả lập kế hoạch dựa trên Oracle (cải thiện khoảng 70+% giữa cài đặt 9 và 10) và lập kế hoạch dựa trên PTR (cải thiện khoảng 80+% giữa cài đặt 5 và 6) trong TA. Một cách trực quan, việc kết hợp lịch sử là quan trọng vì nó có thể hỗ trợ trong việc chọn công cụ phù hợp nhất, đặc biệt trong các tình huống phân nhánh có thể phát sinh trong quá trình thực thi công cụ trước đó (ví dụ: nếu công cụ trước đó thực thi thành công, chọn Tool-A; ngược lại, chọn Tool-B). Tuy nhiên, việc kết hợp lịch sử vào prompt gây ra lo ngại về cắt ngắn do số lượng token tăng (chi tiết hơn trong Phần 5).

5 Hạn chế và Thảo luận
Do nhu cầu tính toán của việc điều chỉnh siêu tham số, chúng tôi không thể tối ưu hóa các cài đặt cho tất cả các cấu hình. Mỗi cấu hình yêu cầu 8 GPU A100 trên AWS, dẫn đến tiêu thụ thời gian và tài nguyên đáng kể. Do đó, chúng tôi tập trung nỗ lực điều chỉnh siêu tham số vào ProTIP (cài đặt 5 và 6) và Oracle (cài đặt 9 và 10). Các giá trị siêu tham số chi tiết cho tất cả các cài đặt trong Bảng 2 được cung cấp trong Phụ lục B.

Để đảm bảo so sánh công bằng với các chiến lược TR dựa trên truy vấn đầy đủ, chúng tôi đã sử dụng chiến lược xen kẽ (được mô tả trong Phần 3.1) để tạo ra các tập hợp công cụ ứng viên cho PTR. Chúng tôi nhận ra rằng phương pháp này không lý tưởng để đánh giá hiệu suất của bộ lập kế hoạch dưới PTR, vì phương pháp tối ưu sẽ bao gồm truy xuất công cụ từng bước và thực hiện lập kế hoạch ở mỗi bước. Tuy nhiên, điều này sẽ yêu cầu một cơ chế để thực thi cuộc gọi API được dự đoán ở mỗi bước và kết hợp đầu ra kết quả vào quá trình lập kế hoạch cho bước tiếp theo. Trong khi chúng tôi đang nghiên cứu các giải pháp tiềm năng cho thách thức này, thiết kế bộ lập kế hoạch không phải là trọng tâm chính của công việc này. Do đó, chúng tôi hoãn việc phát triển và đánh giá các thí nghiệm lập kế hoạch từng bước từ đầu đến cuối, bao gồm điều chỉnh hiệu suất, cho nghiên cứu tương lai.

Kết quả thí nghiệm tiết lộ một khoảng cách hiệu suất đáng kể giữa bộ lập kế hoạch Oracle và các bộ lập kế hoạch dựa trên TR. Sự chênh lệch này có thể được quy cho hai yếu tố chính. Đầu tiên, bộ lập kế hoạch Oracle (cài đặt 9 và 10) sử dụng tập chính xác p công cụ ground truth được chỉ định trong prompt cho mỗi bước lập kế hoạch tiến bộ (p≤6), trong khi các bộ lập kế hoạch TR hoạt động trên một tập ứng viên lớn hơn gồm K=10 công cụ. Việc lựa chọn công cụ bị hạn chế này cho bộ lập kế hoạch Oracle (cài đặt 9 và 10) có thể góp phần vào hiệu suất cải thiện của nó. Quan sát này được hỗ trợ thêm bởi TA cao hơn đạt được trong cài đặt 10 (sử dụng chính xác p công cụ ground truth) so với cài đặt 8 (sử dụng K công cụ, với p công cụ ground truth và (10-p) công cụ được lấy mẫu ngẫu nhiên).

Sự chênh lệch phân phối công cụ giữa các tập huấn luyện và kiểm tra, đặc biệt đối với các ID công cụ lớn hơn 8000, như được thể hiện trong Hình 3, có thể giải thích một phần hiệu suất kém của tất cả các bộ lập kế hoạch dựa trên truy xuất. Sự chênh lệch trong phân phối công cụ này có thể cản trở hiệu quả của các chiến lược TR, có thể dẫn đến các quyết định lập kế hoạch không tối ưu, trừ khi metadata công cụ được làm phong phú thêm và bao gồm trong prompt trong quá trình huấn luyện để hỗ trợ khái quát hóa tốt hơn. Ngoài ra, chúng tôi quan sát thấy Accuracy kém cho công cụ Finish đặc biệt, dẫn đến hiệu suất tổng thể thấp trong tất cả các cài đặt TR.

Chiến lược huấn luyện sử dụng p công cụ ground truth cùng với (K-p) công cụ được lấy mẫu ngẫu nhiên trong prompt có thể góp phần vào hiệu suất thấp hơn của các mô hình bộ lập kế hoạch TR. Sự hiện diện của các công cụ ground truth cùng với các công cụ được lấy mẫu ngẫu nhiên có tính tương tự ngữ nghĩa khác biệt trong quá trình huấn luyện có thể tạo điều kiện cho khả năng của các mô hình xác định công cụ chính xác. Tuy nhiên, trong quá trình kiểm tra, prompt bao gồm các công cụ top-K được truy xuất bởi các thuật toán TR, có thể thể hiện tính tương tự ngữ nghĩa với công cụ ground truth. Tính tương tự ngữ nghĩa này đặt ra thách thức cho các mô hình trong quá trình suy luận, dẫn đến các giá trị TA thấp được quan sát cho tất cả các mô hình bộ lập kế hoạch dựa trên TR. Sử dụng các công cụ top-K được truy xuất bởi các thuật toán TR trong quá trình huấn luyện có thể làm trầm trọng thêm vấn đề này, vì có nguy cơ prompt không chứa công cụ chính xác cho bước tương ứng. Điều này sẽ làm phức tạp thêm quá trình học cho LLM và tăng khả năng ảo giác.

Để giải quyết hạn chế này, trong tương lai, một chiến lược tạo dữ liệu huấn luyện thay thế có thể được sử dụng. Thay vì sử dụng các công cụ được lấy mẫu ngẫu nhiên, dữ liệu huấn luyện có thể kết hợp các công cụ được truy xuất bởi thuật toán TR trên tập huấn luyện. Ngoài ra, để đảm bảo rằng quá trình huấn luyện hiệu quả giải quyết tất cả các bước, công cụ ground truth cho bước hiện tại có thể được tiêm vào prompt nếu nó chưa có mặt. Bằng cách áp dụng phương pháp huấn luyện được sửa đổi này, chúng tôi nhằm nâng cao hiệu suất của các mô hình bộ lập kế hoạch TR và cải thiện khả năng khái quát hóa của chúng. Phần Instructions của prompt là chung chung và có thể được sửa đổi thêm (tức là, làm cho chính xác hơn cho mỗi tình huống) để cụ thể hơn với các cài đặt prompt khác nhau. Ngoài ra, chúng tôi không tiến hành nghiên cứu toàn diện để kiểm tra tính bền vững của đầu ra bộ lập kế hoạch đối với các loại biến thể prompt đầu vào khác nhau (ví dụ: truy vấn được diễn giải lại làm đầu vào, các công cụ tương tự về mặt ngữ nghĩa, các công cụ chưa từng thấy trong tập kiểm tra, v.v.), mà chúng tôi để lại cho công việc tương lai.

Các thí nghiệm của chúng tôi làm nổi bật tầm quan trọng của lịch sử trong việc đạt được TA cao hơn cho cả chiến lược lập kế hoạch dựa trên Oracle (cài đặt 9 so với 10) và PTR (cài đặt 5 so với 6). Tuy nhiên, chúng tôi tin rằng TA có thể được cải thiện thêm trong khi giảm TH, đặc biệt đối với các bộ lập kế hoạch TR với K=10 công cụ, vì lịch sử góp phần vào vấn đề ngữ cảnh dài. Chúng tôi quan sát thấy rằng đối với các tình huống trong đó kích thước đầu vào trở nên gần với kích thước cửa sổ ngữ cảnh tối đa, LLM có thể tạo ra các kế hoạch trống, góp phần từ 3% đến 5% lỗi trong các thí nghiệm của chúng tôi, do đó ảnh hưởng tiêu cực đến TA. Lưu ý rằng dữ liệu gốc chứa các bước trung gian với đầu ra dài dòng cung cấp thông tin ngữ cảnh tối thiểu (ví dụ: đầu ra API thời tiết với vĩ độ, kinh độ, thời gian cập nhật cuối cùng, v.v.), tất cả có thể không cần thiết để xác định API tiếp theo. Việc bảo tồn những đầu ra dài dòng này trong lịch sử làm trầm trọng thêm vấn đề cắt ngắn, do đó ảnh hưởng tiêu cực đến khả năng học và tạo kế hoạch của mô hình. Vấn đề này có thể được làm trầm trọng thêm bằng cách kết hợp thêm metadata công cụ (mô tả công cụ, tham số, chữ ký API, v.v.) vào prompt, điều này sẽ tăng độ dài đầu vào của prompt thậm chí còn hơn nữa. Tuy nhiên, để khái quát hóa tốt hơn cho các công cụ chưa từng thấy, lý tưởng nhất là chúng tôi muốn kết hợp metadata bổ sung như vậy vào prompt, điều này yêu cầu điều tra thêm.

Tăng kích thước cửa sổ ngữ cảnh của LLM (ví dụ: lên 4096 hoặc cao hơn) hoặc sử dụng các kỹ thuật cho phép văn bản đầu vào lớn hơn (ví dụ: như được đề xuất trong (Beltagy et al., 2020)) có thể làm giảm đáng kể vấn đề cắt ngắn. Tuy nhiên, ngay cả với cửa sổ ngữ cảnh lớn, các nghiên cứu của (Liu et al., 2023) chỉ ra rằng LLM có xu hướng tập trung vào thông tin ở đầu hoặc cuối prompt, ngay cả với cửa sổ ngữ cảnh lớn. Do đó, bên cạnh việc khám phá LLM với cửa sổ ngữ cảnh lớn hơn, cần phát triển các phương pháp để nén và trình bày hiệu quả thông tin ngữ cảnh liên quan, đặc biệt là lịch sử, cho LLM (Ge et al., 2023) để nâng cao hiệu suất.

Trong công việc hiện tại, chúng tôi tập trung mạnh vào độ chính xác công cụ trên các bước truy xuất công cụ và lập kế hoạch (Patil et al., 2023). Độ chính xác tham số công cụ là một khía cạnh quan trọng khác của đầu ra bộ lập kế hoạch (Shen et al., 2023b), yêu cầu điều tra thêm để cải thiện hiệu suất. Chúng tôi không tiến hành bất kỳ nghiên cứu an toàn hoặc red-teaming nào để đánh giá thiên vị hoặc rủi ro phát sinh từ các đầu ra được tạo ra bởi LLM được tinh chỉnh. Chúng tôi muốn tham khảo một công việc đương thời của (Valmeekam et al., 2023) đã chỉ ra rằng khả năng của LLM tạo ra "các kế hoạch có thể thực thi" một cách hoàn toàn tự động là rất hạn chế. Trong công việc của chúng tôi, trong khi lập kế hoạch không phải là trọng tâm chính, chúng tôi quan sát thấy rằng việc tạo kế hoạch bằng tinh chỉnh có giám sát của một LLM không phải là một tác vụ dễ dàng, đặc biệt với một LLM tương đối nhỏ (ví dụ: LLM với 7B tham số). Chúng tôi tin rằng cần nghiên cứu thêm để nâng cao hiểu biết của chúng ta về khả năng thực sự của LLM đối với tác vụ lập kế hoạch.

--- TRANG 9 ---
6 Công việc Liên quan
Truy xuất Công cụ sử dụng Nhúng neural: Cơ sở dữ liệu vector cho phép lưu trữ các nhúng tên và mô tả công cụ được tạo ra bởi một mô hình mã hóa (Cer et al., 2018). Những nhúng này sau đó được tận dụng để tính toán độ tương tự ngữ nghĩa, sử dụng các thước đo như độ tương tự cosine, với các truy vấn hoặc truy vấn con. Xây dựng trên phương pháp đã thiết lập của việc sử dụng mạng neural để tạo ra các nhúng từ/câu ngữ nghĩa cụ thể theo tác vụ cho truy xuất thông tin và các tác vụ NLP (Zhang et al., 2016), công việc này đề xuất một chiến lược tạo nhúng công cụ được thiết kế đặc biệt để tạo điều kiện cho lập kế hoạch từng bước.

Nhúng từ (Mikolov et al., 2013b; Pennington et al., 2014; Levy và Goldberg, 2014; Jiao và Zhang, 2021), các vector được học đại diện cho các khía cạnh ngôn ngữ và ngữ nghĩa khác nhau của từ, đã cách mạng hóa Xử lý Ngôn ngữ Tự nhiên bằng cách cho phép các giải pháp hiệu quả cho các tác vụ đa dạng như truy vấn tương tự (Levy và Goldberg, 2014; Allen và Hospedales, 2019). Xây dựng trên thành công này, nghiên cứu đã mở rộng để tạo ra các nhúng mức câu, đoạn văn và tài liệu (Le và Mikolov, 2014; Wieting et al., 2015; Li et al., 2015) cho các ứng dụng khác nhau. Tương tự, lĩnh vực Đồ thị Tri thức sử dụng nhúng nút để mã hóa mối quan hệ thực thể, được huấn luyện với các hàm mục tiêu tùy chỉnh để nắm bắt các mối quan hệ tiềm ẩn trong không gian vector để khai thác sau này (Wang et al., 2017). Chúng tôi tận dụng mô hình này, sử dụng truy xuất công cụ tiến bộ với các nhúng được tinh chỉnh được tối ưu hóa cho tác vụ lập kế hoạch từng bước.

LLM như Bộ lập kế hoạch: LLM đã nổi lên như những người học few-shot mạnh mẽ (Brown et al., 2020; Rae et al., 2022), thể hiện năng lực đáng chú ý trên các tác vụ ngôn ngữ đa dạng. Tuy nhiên, lập kế hoạch vẫn là một biên giới nghiên cứu đầy thách thức mặc dù hiệu suất ấn tượng của chúng trong các lĩnh vực này. Lập kế hoạch liên quan đến việc phân rã một tác vụ ngôn ngữ tự nhiên (NL) cấp cao thành một chuỗi các bước có thể thực thi được thực hiện bởi một tác nhân. Quá trình này đòi hỏi cả khả năng hiểu ngôn ngữ và hiểu biết về một tập hợp các hành động, công cụ, API và các yếu tố cơ sở khác được xác định trước. Trong lĩnh vực các tác nhân được hiện thân, LLM đã được khai thác để phân rã các hướng dẫn NL thành các đơn vị đơn giản hơn, dễ quản lý hơn (Huang et al., 2022; Ahn et al., 2022; Singh et al., 2022; Khot et al., 2022; Wu et al., 2023; Shen et al., 2023b). Đáng chú ý, việc sử dụng LLM để tạo ra các cuộc gọi công cụ/API như một phần của quá trình lập kế hoạch có thể tương tự như tổng hợp chương trình đa bước (Li et al., 2023; Nijkamp et al., 2022, 2023). Các công việc gần đây hơn đã cố gắng cải thiện thêm hiệu suất LLM bằng cách thêm khả năng lý luận/phê bình các đầu ra LLM (Kim et al., 2023; Yao et al., 2022).

Trong khi nghiên cứu đương đại đã nhấn mạnh việc tận dụng các công cụ để nâng cao khả năng LLM, hầu hết các hệ thống truy xuất hiện tại dựa vào cơ sở dữ liệu vector, tương tự như kỹ thuật Tăng cường Tạo sinh Truy xuất (RAG) nổi tiếng (Lewis et al., 2021), để lưu trữ và truy xuất kiến thức không tham số vắng mặt trong LLM. Công việc gần đây đã khám phá các công cụ riêng lẻ như công cụ tìm kiếm web (Nakano et al., 2022), máy tính (Andor et al., 2019), và bộ công cụ chung (Schick et al., 2023) cho lập kế hoạch, trong khi những công việc khác đã tích hợp LLM với các bộ sưu tập API mở rộng để giải quyết các tác vụ mở hơn (Patil et al., 2023; Shen et al., 2023a; Liang et al., 2023; Qin et al., 2023b). Tinh chỉnh với dữ liệu cụ thể theo công cụ thường được sử dụng để cải thiện hiệu suất tác vụ. Tuy nhiên, khi số lượng công cụ tăng lên, các hệ thống dựa trên truy xuất nổi lên như một phương tiện hiệu quả để chọn các công cụ liên quan cho một yêu cầu nhất định (Patil et al., 2023; Qin et al., 2023b). Xây dựng trên mô hình này, phương pháp của chúng tôi đề xuất khái niệm mới về việc tạo ra các ứng viên công cụ tăng dần cụ thể cho bước con hiện tại trong một tác vụ lập kế hoạch đa bước, cuối cùng nâng cao hiệu suất lập kế hoạch tổng thể của LLM.

7 Kết luận
Chúng tôi giới thiệu ProTIP, một khung truy xuất công cụ nhẹ mới, vượt trội hơn các tác nhân lập kế hoạch dựa trên LLM được trang bị truy xuất phân rã tác vụ hiện đại được hỗ trợ bởi ChatGPT. Các biến đổi vector lặp của ProTIP, được kích hoạt bởi học tương phản, tạo điều kiện cho việc học ngầm dự đoán tác vụ con tuần tự, loại bỏ nhu cầu về nhãn tác vụ con rõ ràng. Ngoài ra, ProTIP hiệu quả xử lý "sự phù hợp nguyên tử tác vụ con-công cụ." Trên tập dữ liệu ToolBench, khung ProTIP vượt trội hơn phương pháp phân rã tác vụ dựa trên ChatGPT 24% trên Recall@K=10 cho Truy xuất Công cụ và 41% trên Tool Accuracy cho việc tạo kế hoạch.

8 Lời cảm ơn
Chúng tôi muốn cảm ơn Stephen Pulman, Russ Webb và Arturo Argueta vì phản hồi có giá trị của họ. Ngoài ra chúng tôi cảm ơn Jiarui Lu, Yuan Zhang, Xuan Wang, Hans Han, và Jian Zhang vì đã cung cấp hỗ trợ cơ sở hạ tầng để tinh chỉnh LLM.

--- TRANG 10 ---
[Tiếp tục với phần Tài liệu tham khảo...]

--- TRANG 11 ---
[Tiếp tục với phần Tài liệu tham khảo...]

--- TRANG 12 ---
[Tiếp tục với phần Tài liệu tham khảo...]

--- TRANG 13 ---
[Tiếp tục với phần Tài liệu tham khảo...]

--- TRANG 14 ---
[Tiếp tục với phần Tài liệu tham khảo...]

--- TRANG 15 ---
A Biến thể Prompt
Hình 8: Các biến thể prompt cho việc tạo kế hoạch có và không có lịch sử thực thi.

B Siêu tham số
Do hạn chế về thời gian và tài nguyên, chúng tôi không thể thực hiện điều chỉnh siêu tham số cho tất cả các thiết lập thí nghiệm. Bảng sau liệt kê các siêu tham số được sử dụng cho mỗi cài đặt.

Bảng 3: Siêu tham số cho huấn luyện
ID Cài đặt  Epochs  LR    Batch  Warmup Steps
1         3       3e-5  64     20
2         3       3e-5  64     20
3         3       3e-5  64     20
4         3       3e-5  64     20
5         3       3e-5  64     20
6         3       5e-5  128    20
7         3       5e-5  128    20
8         3       5e-5  128    20
9         3       2e-5  64     20
10        3       2e-5  64     20

Mô hình này sử dụng kích thước cửa sổ ngữ cảnh tối đa là 2048 và sử dụng weight decay là 0 trên tất cả các thí nghiệm.

# 2309.14681.pdf
# Converted from PDF to TXT
# Source path: /home/admin88/arxiv-downloader/planning/2309.14681.pdf
# File size: 962710 bytes

===============================================
PDF FILE CONTENT
===============================================


--- PAGE 1 ---
Published as a conference paper at ICLR 2024
AREHUMAN -GENERATED DEMONSTRATIONS NECES -
SARY FOR IN-CONTEXT LEARNING ?
Rui Li1, Guoyin Wang2, Jiwei Li3
1University of Science and Technology of China
2Bytedance
3Zhejiang University
ABSTRACT
Despite the promising few-shot ability of large language models (LLMs), the
standard paradigm of In-context Learning (ICL) suffers the disadvantages of sus-
ceptibility to selected demonstrations and the intricacy to generate these demon-
strations. In this paper, we raise the fundamental question that whether human-
generated demonstrations are necessary for ICL. To answer this question, we pro-
pose self-contemplation prompting strategy (SEC), a paradigm free from human-
crafted demonstrations. The key point of SEC is that, instead of using hand-crafted
examples as demonstrations in ICL, SEC asks LLMs to first create demonstra-
tions on their own, based on which the final output is generated. SEC is a flexible
framework and can be adapted to both the vanilla ICL and the chain-of-thought
(CoT), but with greater ease: as the manual-generation process of both exam-
ples and rationale can be saved. Extensive experiments in arithmetic reasoning,
commonsense reasoning, multi-task language understanding, and code generation
benchmarks, show that SEC, which does not require hand-crafted demonstrations,
significantly outperforms the zero-shot learning strategy, and achieves comparable
results to ICL with hand-crafted demonstrations. This demonstrates that, for many
tasks, contemporary LLMs possess a sufficient level of competence to exclusively
depend on their own capacity for decision making, removing the need for external
training data. Code is available at https://github.com/ruili33/SEC.1
1 I NTRODUCTION
Large language models (LLMs) (Zeng et al., 2022; Chowdhery et al., 2022; Wang et al., 2022; Zhang
et al., 2023; Touvron et al., 2023; OpenAI, 2023) have shown the ability to learn in context (Brown
et al., 2020; Dong et al., 2022; Qin et al., 2023; Sun et al., 2023a): given a few annotated examples
as demonstrations, LLMs are able to generate for a new test input (Brown et al., 2020). The standard
paradigm of In-context Learning (ICL) still suffers from the following conspicuous disadvantages:
(1) the final performance is extremely sensitive to the selected demonstrations (Liu et al., 2022; Lu
et al., 2023), and to date, there is no widely-agreed criterion for the perfect demonstration selection;
(2) crafting demonstrations can be work-intensive, troublesome or even prohibitive: in many ICL
scenarios, demonstrations contain not only inputs and corresponding labels, but also the reasoning
process (Wei et al., 2022b; Sun et al., 2023b; Yao et al., 2023) generated by annotators. For many
tasks (e.g., summarization), it is non-trivial for humans to articulate the reasoning process behind
the decision.
An important question arises, do we really need humans to provide LLMs with the demonstrations,
or can LLMs generate demonstrations on their own? When comparing the ICL approach to a stu-
dent’s interaction with a tutor, within the ICL framework, the tutor initiates the process by offering
the student a set of analogous instances as suggestive prompts, based on which the student gives his
answer. There is definitely an alternative paradigm to ICL, where a competent student rely solely on
their own memory to find analogous examples, arriving at their answers independently, eliminating
the need for any guidance or examples from the tutor.
1Email: rui li@mail.ustc.edu.cn, guoyin.wang@bytedance.com, jiwei li@zju.edu.cn
1arXiv:2309.14681v4  [cs.LG]  21 Feb 2024

--- PAGE 2 ---
Published as a conference paper at ICLR 2024
Input to LLM:  
<Human-crafted Few-
shot
Demonstrations >
Question:{{Which of the
following regular
expressions is
equivalent to (describes
the same set of strings
as) (a* + b)*(c + d)?}}
A. a*(c + d)+ b(c + d)
B. a*(c + d)* + b(c + d)*
C. a*(c + d)+ b*(c + d)
D. (a + b)*c +(a + b)*d
Answer:D
...
Question:{{ A compiler
generates code for the
following assignment
statement.  ... The
smallest possible
number of instructions in
the resulting code is}}
A. 5
B. 6
C. 7
D. 9
Answer:D
<Test Input >
Question:{{Which of the
following is the name of
the data structure in a
compiler that is
responsible for
managing information
about variables and their
attributes?}}
A. Abstract Syntax Tree
(AST)
B. Attribute Grammar
C. Symbol Table
D. Semantic Stack
Output from LLM:
 
Answer:CInput to LLM: 
<Test Input >
Question:{{Which of the following is the name of the data structure in a compiler that is responsible for
managing information about variables and their attributes?}}
A. Abstract Syntax Tree (AST)                             B. Attribute Grammar
C. Symbol Table                                                    D. Semantic Stack
<Instruction for the Few-shot Demonstration Generation >
Please follw the above question, create five similar multiple choice college_computer_science questions
with its choice labels, choice text and an answer label (A  or B or C or D). Note that each question should be
complete and can be answered independently . 
<Output Format Instruction >
Please output in the following form: Question1:[question] A.[choice text] B.[choice text] C.[choice text]\n D.
[choice text] Answer1:[A  or B or C or D]\n\n ...\n\n ...\n\n ...\n\n Question5:[question] A.[choice text] B.[choice
text] C.[choice text] D.[choice text] Answer5:[A  or B or C or D]\n\n.
Output from LLM:
Question1: Which of the following is a data structure that allows for ef ficient insertion and deletion operations
and is implemented using a doubly linked list and a hash table?
A. Stack                                             B. Queue
C. Heap                                                         D. Hash Map
Answer1:D
...
Question4:Which of the following is a type of algorithm that uses a divide-and-conquer strategy to sort
elements by partitioning the array into smaller sub-arrays, sorting them recursively , and then merging them
back together?
A. Bubble Sort                                                         B. Merge Sort 
C. Selection Sort                                                     D. Quick Sort
Answer4:B
...
Input to LLM: 
<Few-shot Demonstrations Extracted from the Output from LLM in (a) >
Question:{{ Which of the following is a data structure that allows for ef ficient insertion and deletion operations
and is implemented using a doubly linked list and a hash table? }}
A. Stack                                B. Queue
C. Heap                                                       D. Hash Map
Answer:D
...
Question:{{Which of the following is a type of algorithm that uses a divide-and-conquer strategy to sort
elements by partitioning the array into smaller sub-arrays, sorting them recursively , and then merging them
back together?}}
A. Bubble Sort                                                     B. Merge Sort 
C. Selection Sort                                             D. Quick Sort
Answer:B
<Test input >
Question:{{Which of the following is the name of the data structure in a compiler that is responsible for
managing information about variables and their attributes?}}
A. Abstract Syntax Tree (AST)                             B. Attribute Grammar
C. Symbol Table                                                    D. Semantic Stack
Output from LLM:
Answer:CVanilla ICLVanilla Self-Contemplation Prompting  
(b): V anilla ICLQuestion and Choices
Answer
Annotation(a): SEC Demonstration Generation
(a) (b)
Figure 1: Comparison between vanilla ICL and vanilla SEC. Different parts of the prompt and results
are highlighted with different colors for emphasis.
In this paper, we propose the self-contemplation prompting strategy (SEC for short), a paradigm
alternative to ICL. The key point of SEC is that, instead of using hand-crafted examples as demon-
strations, SEC asks LLMs to first create demonstrations on their own, based on which the final
output is generated. This is akin to the above process where the student relies solely on their own
memory to find analogous examples, rather than examples from the tutor. SEC effectively address
the drawbacks of ICL: it will not only spare us the laborious efforts in demonstration crafting, but
more importantly, eliminate instability of human crafted prompts.
SEC is a flexible framework that not only can be easily combined with existing strengthening strate-
gies for ICL, but with notably greater ease: for example, for the chain-of-thought (CoT) strategy
where demonstrations consist of the reasoning process, in SEC, we can prompt LLMs to first auto-
matically create not only inputs and labels, but also the associative reasoning process. In doing so,
the efforts of crafting rationales in ICL can be conserved. The demonstrations of vanilla SEC and
CoT-SEC are shown in Figure 1 (b) and 2 (b).
2

--- PAGE 3 ---
Published as a conference paper at ICLR 2024
Input to LLM:  
<Human-crafted Few-shot
Demonstrations >
Question: There are 15 trees in
the grove. Grove workers will
plant trees in the grove today .
After they are done, there will
be 21 trees. How many trees
did the grove workers plant
today?
Solution: Let's think step by
step. There are 15 trees
originally . Then there were 21
trees after some more were
planted. So there must have
been 21 - 15 = 6.  
The answer is 6.
...
Question: Shawn has five toys.
For Christmas, he got two toys
each from his mom and dad.
How many toys does he have
now?
Solution: Let's think step by
step. Shawn started with 5
toys. If he got 2 toys each from
his mom and dad, then that is
4 more toys. 5 + 4 = 9. 
The answer is 9.
<Test Input >
Question: Janet’ s ducks lay 16
eggs per day . She eats three
for breakfast every morning
and bakes muf fins for her
friends every day with four .
She sells the remainder at the
farmers' market daily for $2 per
fresh duck egg. How much in
dollars does she make every
day at the farmers' market?
Output from LLM:
 
Solution: Let's think step by
step. Janet's ducks lay 16
eggs per day . She eats 3 for
breakfast and bakes muf fins
with 4, so she uses 3 + 4 = 7
eggs per day . So she has 16 -
7 = 9 eggs left to sell. She sells
each egg for $2, so she makes
9 x $2 = $18 every day at the
farmers' market.
The answer is $18.Input to LLM: 
<Test Input >
Question: {{Janet’ s ducks lay 16 eggs per day . She eats three for breakfast every morning and bakes
muffins for her friends every day with four . She sells the remainder at the farmers' market daily for $2 per
fresh duck egg. How much in dollars does she make every day at the farmers' market?}}
<Instruction for the Few-shot Demonstration Generation >
Please generate five similar questions with step by step reasoning process and an integer answer 
<Output Format Instruction >
in the following form Question1:{question} Solution1:{solution} The answer is {answer}\n ... \n Question5:
{question} Solution5:{solution} The answer is {answer}\n\n.
Output from LLM:
Question1: Samantha has 12 apples. She gives 3 to her friend and eats 2 herself. She sells the
remaining apples at the farmers' market for $1.50 each. How much money does she make?
Solution1: Samantha has 12 apples. She gives 3 to her friend, so she has 9 apples left. She eats 2
herself, so she has 7 apples left. She sells the remaining 7 apples at the farmers' market for $1.50 each.
Therefore, she makes 7 x $1.50 = $10.50.
The answer is 10.
...
Question5: Karen has 40 pencils. She gives 15 to her classmates and 10 to her teacher . She sells the
remaining pencils for $0.50 each. How much money does she make?
Solution5: Karen has 40 pencils. She gives 15 to her classmates and 10 to her teacher , so she has 15
pencils left. She sells the remaining 15 pencils at the market for $0.50 each. Therefore, she makes 15 x
$0.50 = $7.50.
The answer is 7.
Input to LLM: 
<Few-shot Demonstrations Extracted from the Output from LLM in (a) >
Question: Samantha has 12 apples. She gives 3 to her friend and eats 2 herself. She sells the remaining
apples at the farmers' market for $1.50 each. How much money does she make?
Solution: Samantha has 12 apples. She gives 3 to her friend, so she has 9 apples left. She eats 2 herself,
so she has 7 apples left. She sells the remaining 7 apples at the farmers' market for $1.50 each.
Therefore, she makes 7 x $1.50 = $10.50.
The answer is 10.
...
Question: Karen has 40 pencils. She gives 15 to her classmates and 10 to her teacher . She sells the
remaining pencils for $0.50 each. How much money does she make?
Solution: Karen has 40 pencils. She gives 15 to her classmates and 10 to her teacher , so she has 15
pencils left. She sells the remaining 15 pencils at the market for $0.50 each. Therefore, she makes 15 x
$0.50 = $7.50.
The answer is 7.
<Test Input >
Question: Janet’ s ducks lay 16 eggs per day . She eats three for breakfast every morning and bakes
muffins for her friends every day with four . She sells the remainder at the farmers' market daily for $2 per
fresh duck egg. How much in dollars does she make every day at the farmers' market?
Output from LLM:
Solution: Janet's ducks lay 16 eggs per day . She eats 3 for breakfast and bakes muf fins with 4, so she
uses 7 eggs per day . Therefore, she has 16 - 7 = 9 eggs left to sell. She sells each egg for $2, so she
makes 9 x $2 = $18 every day at the farmers' market.
The answer is $18.CoT-ICLCoT-SEC
(b): CoT -ICLQuestion 
Answer
Annotation(a):  SEC Demonstration GenerationSolution
(a) (b)
Figure 2: Comparison between CoT-ICL and CoT-SEC. Different parts of the prompt and results are
highlighted with different colors for emphasis.
We conduct experiments across multiple LLMs and a wide range of tasks, including arithmetic rea-
soning, commonsense reasoning, multi-task language understanding, and code generation bench-
marks. Notably, With no access to ANY training example or human intervention, SEC achieves
comparable results to ICL across all benchmarks in both few-shot and CoT scenarios, including
MATH (33.5% vs 31.2%) (Hendrycks et al., 2021), MMLU (71.4 % vs 70.4 %) (Hendrycks et al.)
and HumanEval (76.2 % vs 73.2 %) (Chen et al., 2021). This result demonstrates that contempo-
rary LLMs possess a sufficient level of competence to exclusively depend on their own capacity for
generating illustrative examples, obviating the need for external training data.
From a broader perspective, SEC is a zero-shot learning paradigm with no training data, while ICL
is still a supervised learning paradigm in nature. Building upon the observation that zero-shot SEC
3

--- PAGE 4 ---
Published as a conference paper at ICLR 2024
performs comparable to the supervised ICL using domain-specific data, we demonstrate that with
the generalization ability of LLMs to date, there is potential that supervised training data may be
dispensable in the future. We wish SEC would open doors for further research towards this direction.
2 S ELF-CONTEMPLATION PROMPTING
2.1 P RELIMINARIES
Vanilla ICL In the vanilla ICL strategy, LLMs are first given a few human-crafted labelled (few-
shot) examples as demonstrations, where each demonstration is an input-output pair. The demon-
strations are followed by the test input, and LLMs are prompted to generate the label for the test
input based on the given demonstrations. Different from the pre-training-and-finetuning strategy
(Devlin et al., 2019), ICL enables the model to make predictions via a single API call.
CoT-ICL To bolster the performance on reasoning-intensive tasks, the chain-of-thought (CoT)
Prompting strategy (Wei et al., 2022b) incorporates the step-by-step reasoning process into the
prompt for LLMs, as illustrated in the pink part in Figure 2. The CoT strategy can be combined
with the vanilla ICL, where each demonstration consists of not only an input and an output label,
but also the reasoning process to obtain the label.
2.2 S ELF-CONTEMPLATION PROMPTING
Considering the difficulty and unreliability in human-generated few-shot prompts, we propose self-
contemplation prompting (SEC), a prompting strategy that relies entirely on LLMs to generate few-
shot examples tailored to each input test sample. We describe SEC in both vanilla few-shot learning
scenario (Vanilla SEC) and chain-of-thought scenario (CoT-SEC) in order below:
2.2.1 V ANILLA SEC
The SEC demonstration generation prompt for the vanilla few-shot scenario consists of the following
components:
• Test input (text highlighted in green): at the beginning of the prompt, we directly provide
the test example.
• Instruction for the few-shot demonstration generation (text highlighted in yellow): an ex-
plicit instruction to ask LLMs to generate demonstrations based on the test input.
• Output format instruction (text highlighted in purple): explicitly defines the output format
to facilitate answer extraction from the generated text sequence.
Then, we deploy the paradigm of vanilla ICL based on model-generated demonstrations. The differ-
ence between Vanilla SEC and vanilla ICL is that the former asks LLMs to generate demonstrations
while the latter uses human-crafted demonstrations.
2.2.2 C OT-SEC
SEC can be adapted to the CoT strategy with ease. The prompt for SEC demonstration generation
in CoT-SEC still consists of three components, i.e., test input, instruction for the few-shot demon-
stration generation and output format instruction. The difference is that, in the instruction for the
few-shot demonstration generation, LLMs are asked to generate demonstrations with not only inputs
and labels, but also the reasoning process.
The difference between CoT-SEC and CoT-ICL is that the former asks LLMs to generate demon-
strations with reasoning process while the latter uses human-crafted demonstrations with reasoning
process. Over ICL, the advantages of SEC is as follows:
• No need for hand-crafted demonstrations: since the demonstrations are generated by LLMs
on their own, SEC saves human efforts for demonstration crafting, along with the intricate
process for demonstration selection and ordering.
4

--- PAGE 5 ---
Published as a conference paper at ICLR 2024
• Demonstrations tailored to the test input: the demonstrations are generated given the input
sample. Therefore, they are customized to suit each test example. In experiments, we find
that this strategy serves a similar purpose to the KNN demonstration in KNN search, lead-
ing to more competitive performance on some datasets (details in Sention 3 and Appendix
B.7).
3 E XPERIMENTS
3.1 T ASKS AND DATASETS
We evaluate SEC in the following tasks and datasets (details in Appendix A.1): Arithmetic Rea-
soning: GSM8K (Cobbe et al., 2021), MATH (Hendrycks et al., 2021); Commonsense Reasoning:
AI2 Reasoning Challenge (ARC) (Clark et al., 2018); Multi-task Language Understanding: MMLU
(Hendrycks et al.), C-Eval (Huang et al., 2023); Code Generation: HumanEval (Chen et al., 2021).
We use the exact match accuracy as the evaluation metric for the GSM8K and Math dataset. For
the GSM8K dataset, we extract the first numerical object in the answer string and convert it to an
integer. For the Math dataset, we combine the normalization function in Wei et al. (2022b) and
Hendrycks et al. (2021) to reach our normalization function. For HumanEval, we directly use the
code in HumanEval Github repository1(Chen et al., 2021) for answer cleaning and evaluation. The
details of extracting few-shot demonstrations are in Appendix A.5.
MATH GSM8K ARC MMLU C-Eval HumanEval
Number of Shots 4 5 5 4 4 4
Table 1: The number of shots used in the main experiments.
3.2 B ASELINES
We compared SEC to the zero-shot strategy and the ICL (Brown et al., 2020) strategy in both the
vanilla and chain-of-thoughts (Wei et al., 2022b) scenarios. To ensure apple-to-apple comparisons,
the numbers of human-crafted and LLM-generated demonstrations are the same. The number of
shots for different tasks and tasks are shown in Table 1. For all our baselines, we adopt ChatGPT
(gpt-3.5-turbo), GPT4 (OpenAI, 2023) and Llama2 34B (Touvron et al., 2023) as the model back-
bone, details in Appendix A.2. If not specified otherwise, we are using GPT-3.5 for our experiments.
(GPT-3.5) Arithmetic Common Multi-task NLU Code
MATH GSM8K ARC MMLU C-Eval HumanEval
Published Results
Vanilla ICL - 57.1a85.2a70.0a[51.0c] [ 48.1a]
CoT-ICL - 74.9b- 67.3b54.6c-
Our Results
Zero-shot 16.6 31.4 80.1 64.7 51 .0 48 .8
Zero-shot CoT 31.7 73.4 84.1 60.5 50.5 -
Vanilla ICL 20.3 57.1a86.5 70.4 55.0 73.8
Vanilla SEC 18.1 65.4 85.9 68.3 54.0 75.6
CoT-ICL 31.2 77.4 87.9 69.6 53.1 -
CoT-SEC 33.5 77.0 86.9 71.4 54.6 -
Table 2: Comparison between SEC and baselines on GPT-3.5.2
1https://github.com/openai/human-eval
5

--- PAGE 6 ---
Published as a conference paper at ICLR 2024
(GPT-4) Arithmetic Common Multi-task NLU Code
MATH GSM8K ARC MMLU C-Eval HumanEval
Published Results
Vanilla ICL - - 96.3a86.4a[66.4c] [ 67.0a]
CoT-ICL 42.6b92.0b- 86.4b68.7c-
Our Results
Zero-shot 26.4 68.3 88.5 82.0 64 .8 67 .0a
Zero-shot CoT 32.6 86.7 90.2 82.2 64.4 -
Vanilla ICL 31.2 91.5 94.4 86.6 67.7 83.5
Vanilla SEC 35.0 91.7 94.7 86.1 68.1 83.0
CoT-ICL 42.3 92.0a95.1 86.0 67.0 -
CoT-SEC 41.9 92.1 96.2 86.5 67.8 -
Table 3: Comparison between SEC and baselines on GPT-4.2
3.3 R ESULTS
Table 2 Table 3, and Table 9 in Appendix A.3 summarizes the performance of SEC across 6 bench-
marks on GPT3.5, GPT4, Llama2 34B. Overall, SEC achieves significantly better performances
than zero-shot prompting, and comparable performances to few-shot ICL and CoT-ICL in the cor-
responding setups.
Despite the fact that the final decision of SEC relies on demonstrations, SEC is a zero-shot (and
unsupervised) model in nature due to the fact that these demonstrations are generated by the LLM
itself. SEC bridges the gap between zero-shot prompting and few-shot ICL (Kojima et al.; Brown
et al., 2020), through automatic generating few-shot demonstrations. This demonstrates that, for
many tasks, contemporary LLMs are competent enough to depend on their own capacity for decision
making, removing the need for external training data.
Arithmetic Reasoning Primarily, surprisingly, in MATH, SEC significantly outperforms ICL in
both GPT-3.5 CoT and GPT-4.0 answer-only scenarios, despite the absence of training datasets.
This is because demonstrations in SEC are generated tailored to each test case. In contrast, ICL
employs identical few-shot examples for the entire dataset instead of customizing for distinct test
cases.
Figure 3 illustrates a breakdown of the results on the MATH dataset, categorized by subtopics.
We discovered that CoT-SEC outperforms CoT-ICL in 5 subtopics other than Geometry. Another
observation is that CoT-SEC consistently outperforms vanilla SEC in all 6 subtopics, even in Algebra
and Precalculus, where CoT-ICL underperforms vanilla ICL.
ProbabilityAlgebra
NumTheory Precalculus Prealgebra GeometryAlgebra Overall01020304050Accuracy (%)Performance on MATH by Subtopics
Vanilla ICL
CoT-ICL
Vanilla SEC
CoT-SEC
Figure 3: Experiment results on the MATH
dataset by subtopic.Multi-task Language Understanding The effi-
cacy of SEC is further proved by its competitive
performance on the Multi-task NLU task, which
covers a broad spectrum of over 50 domains and
disciplines. Moreover, SEC’s competitive per-
formance on C-Eval shows its capability in the
cross-linguistic scenario. The breakdown of re-
sults on MMLU are shown in Appendix A.4.
Code Generation SEC significantly outperforms
the zero-shot baseline and vanilla ICL baseline
for the code generation task.
These results not only demonstrate the effective-
ness of SEC, but also question the value of an-
notated training data with the present of LLMs to
date. Our experiments arguably demonstrate that
2Any result encompassed within brackets signifies data derived from zero-shot prompting. The super-
scripts are used to indicate results that have been cited from previous studies:a(OpenAI, 2023),b(Fu et al.,
2023),c(Huang et al., 2023).
6

--- PAGE 7 ---
Published as a conference paper at ICLR 2024
1 2 3 4 5
Number of Shots6570758085Accuracy (%)
GSM8K
CoT-SEC
CoT-ICL
Published CoT-ICL
1 2 3 4
Number of Shots50607080Accuracy (%)
HumanEval
Vanilla SEC
Vanilla ICL
Published Zero-shot
Figure 4: Effects of the number of examples on the GSM8K and HumanEval datasets. Solid data
points represent the data points adopted in the main results.
LLMs with the scale of GPT3.5 and Llama2 34B inherently possess the ability to achieve per-
formance comparable to few-shot prompting in both vanilla few-shot and CoT scenarios, which
indicates the potential that supervised training data may not be indispensable in the future.
4 A BLATION STUDIES
Number of Shots We investigate the effect of the number of shots on both SEC and ICL. Fig-
ure 4 shows the results from the GSM8K dataset and HumanEval dataset. Our analysis discerns
marked differences between the characteristics of few-shot demonstrations in SEC and those man-
ually crafted. Within the context of the two datasets examined, SEC often reaches its optimal per-
formance with fewer shots (e.g., 2 shots) than ICL. The explanation is as follows: since SEC is able
to generate demonstrations tailored to the input, there is no need to provide diverse demonstrations
to make the prompt applicable to various types of test input. Therefore, fewer demonstrations are
needed for SEC.
1stshot 2ndshot 3rdshot 4thshot Canonical Solution
Avg. Lines 7.3 6.9 6.8 7.1 7.8
Table 4: The average number of lines in model-generated demonstrations and canonical solutions.
The average length represents the complexity of the code to some extent.
text-davinci-002 text-davinci-003gpt-3.5-turbo
Model1020304050607080Accuracy (%)
GSM8K on Different Model
Vanilla SEC
CoT-SEC
Vanilla ICL
CoT-ICL
Figure 5: The performance of all
four prompting strategies on three
models in the GPT3.5 family on
GSM8K. SEC is an emergent ability.One specific issue that stands out is that, on HumanEval,
we observe as the number of shots increases, the perfor-
mance of SEC slightly decreases. To investigate, we provide
a comparison of the complexity between model-generated
few-shot demonstrations and canonical solutions. The com-
plexity is measured by the length, i.e., the number of lines of
the answer. The results are shown in Table 4. It is evident
that the complexity of the few-shot demonstrations gener-
ated by the model is significantly smaller than the complex-
ity of the canonical solutions, which could lead the model
to misjudge the complexity of the task in some test samples.
The detailed analysis will be shown in Appendix B.5.
Comparing SEC with ICL using LLMs with different
capacities To investigate the effect of model capability on
the performance of SEC, we conduct an experiment across
all four prompting strategies using three models from the
GPT3.5 family (details in Appendix B.6). From the results
shown in Figure 5, we can conclude that SEC underperforms
ICL when the model is not strong enough. This may be due
7

--- PAGE 8 ---
Published as a conference paper at ICLR 2024
Correctness All Correct Minor Error Major Error All Incorrect
Correct 13/20 1/20 3/20 3/20
Incorrect 2/20 5/20 7/20 6/20
Table 5: Correctness of five few-shot demonstrations for 20 correct and 20 incorrect final model
predictions in the GSM8K dataset. Minor Error means 1-2 incorrect examples, and Major Error
means 3-4 incorrect examples.
to the fact that weaker models struggle to follow the instructions and generate poor-quality few-shot
examples, making SEC not stand up favorably against ICL when deployed on smaller models.
Error Analysis in GSM8K We manually inspected 20 correct and 20 incorrect model predictions
from GSM8K, assessing the correctness of their few-shot demonstrations. The results are summa-
rized in Table 5. We found that, in GSM8K, the correct rate of few-shot demonstrations for incorrect
predictions is significantly lower than that for correct samples (10% vs 65%). Therefore, the errors
of the final prediction can to some extent be attributed to the low quality of the few-shot demonstra-
tions, and we leave it to future work to refine the model-generated demonstrations. Please refer to
Appendix B.1 for more details about the error analysis.
Why incorrect few-shot demonstrations could lead to correct final predictions, while correct
few-shot demonstrations could also lead to incorrect predictions? The errors in the few-shot
demonstrations generated by LLM can be classified into four main categories: answer extraction
errors, computation errors, question errors and logical errors, which are in Appendix B.2.
For incorrect few-shot demonstrations that lead to correct results, these errors in few-shot demon-
strations often belong to answer extraction errors, computation errors, question errors rather than
fundamental errors in the reasoning process (logical errors).
For correct few-shot demonstrations that eventually lead to incorrect results, typically, although the
few-shot demonstrations are correct, they don’t align closely enough with the test question, hinder-
ing the model to extract and apply the pertinent knowledge from the demonstrations. Occasionally,
the generated demonstrations may be overly simplistic, leading the model to misjudge the intricacies
of the test question. Detailed examples and discussions are available in Appendix B.3.
The performance differences between CoT-SEC and CoT-ICL in GSM8K. We show the results
of examining the accuracy of 1319 test samples within GSM8k under both CoT-SEC and CoT-ICL in
Figure 6. Though the overall performance of these two methods is very similar, their performances
on specific individual problems are different: approximately 22% of the samples had opposite cor-
rectness between SEC and ICL strategies, in stark contrast to the 11.8% where both failed. In Ap-
pendix B.4, we will preliminarily investigate the characteristics of these differences. This difference
further highlights that these two prompting strategies each have their respective areas of expertise.
A66.2%B
10.8%C
11.2%D
11.8%Correctness of GSM8k
A
B
C
D
Label in the Figure CoT-SEC CoT-ICL
A Correct ✓ Correct ✓
B Correct ✓ Incorrect ✗
C Incorrect ✗ Correct ✓
D Incorrect ✗ Incorrect ✗
Figure 6: Results of 1319 test samples in the GSM8k dataset
under both CoT-SEC and CoT-ICL.
Method GSM8k ARC
Zero Shot CoT 73.4 84.1
CoT-ICL 77.4 87.9
Auto-CoT 77.5 87.8
CoT-SEC 77.0 86.9
Table 6: Comparision between
CoT-SEC and Auto-CoTComparision between SEC and Auto-CoT The performance of
SEC and Auto-CoT (Zhang et al., 2022b) are summarized in Ta-
ble 6. CoT-SEC’s performance is comparable to Auto-CoT, even
without access to the full test dataset and additional clustering.
8

--- PAGE 9 ---
Published as a conference paper at ICLR 2024
5 R ELATED WORK
In-context Learning To enhance the performance of ICL, prior research explores the optimization
of the selection and sequencing of few-shot exemples (Rubin et al., 2021; Zhang et al., 2022a; Wu
et al., 2022; Lu et al., 2021; Fu et al., 2022; Zhou et al., 2022b; Su et al., 2022) such as kNN Prompt-
ing (Xu et al., 2023). SEC and kNN Prompting share the idea of using demonstrations tailored to
each test question. Incorporating reasoning process and augmenting information (Lampinen et al.,
2022) has also been proposed, e.g., CoT Prompting (Wei et al., 2022b), CARP (Sun et al., 2023b),
Least-to-Most Prompting (Zhou et al., 2022a) and adding task-specific instructions (Mishra et al.,
2022; Wei et al., 2022a; Sanh et al., 2022).
Considering the cost in manually crafting prompts, many automatic prompting strategies have been
proposed (Sorensen et al., 2022; Shin et al., 2020). Kim et al. (2022) utilize PLMs to automatically
generate demonstrations. Li et al. (2022) proposes Self-Prompting framework, which first generates
a training corpus and then selects few-shot examples for each test sample by clustering. Compared
to Li et al. (2022), our method provides a more flexible way to generate demonstrations without
either generating numerous training samples in advance or further clustering and selection. Besides,
while Li et al. (2022) focused their research on QA alone, we extended SEC to many new tasks.
Besides, recent work has discussed the instability in ICL. Specifically, the selection and shuffling of
few-shot examples and the structure of the prompt could cause a drastic fluctuation of the accuracy
(Zhao et al., 2021; Lu et al., 2022; Liu et al., 2022; Lu et al., 2023). However, SEC mitigates this is-
sue, since the few-shot examples are only conditioned on LLMs free from any external interference.
Chain-of-thoughts Prompting Wei et al. (2022b) proposed CoT prompting, a prompting strategy
integrating few-shot training examples with intermediate reasoning process. Zero-shot CoT (Kojima
et al.) utilized a simple prompt, ”Let’s think step by step”, to elicit the rationale in the output and
achieved encouraging results. Following Kojima et al., we add a specific CoT instruction to generate
rationales. Our finding supports Kojima et al. that LLMs are decent zero-shot reasoners.
Zhang et al. (2022b) proposed Auto-CoT, an automatic prompting strategy leveraging zero-shot CoT
to generate rationales. The key difference between Zhang et al. (2022b) and our’s work is that Zhang
et al. (2022b) requires the access to a whole test set and involves intensive querying and clustering
and , whereas SEC only requires two queries for each test sample.
6 CONCLUSION
In this paper, we introduced self-contemplation prompting as a simple, resource-efficient and
broadly applicable prompting strategy for LLMs to strengthen their zero-shot ability. This new
paradigm addresses some of the issues associated with supervised ICL methods, such as the lack
of manually annotated data and the instability of the performance. Our method provides a more
comprehensive and consistent evaluation framework to LLMs.
Our experiments show that SEC performs comparable to ICL in both answer only and CoT sce-
nario. To the best of our knowledge, SEC achieves the strongest zero-shot performance on a variety
of tasks. This extraordinary performance indicates the promise that annotated data might be su-
perfluous given the generalization of LLMs. Furthermore, the difference between the ability of
CoT-SEC and CoT-ICL may indicate the promise of further integration of these strategies.
LIMITATIONSMethod Accurary
Zero-shot 26.5
Zero-shot CoT 19.0
Vanilla ICL 28.0
CoT-ICL 27.0
Vanilla SEC 27.0
CoT-SEC 24.0
Table 7: Performance of
SEC and baseline methods
on 3-digit base-5 addition
problemsConsidering that SEC employs demonstrations that generated from
LLMs, it may experience performance degradation in scenarios where
the model is not strong enough, or the test data is not sufficiently rep-
resented in the training set. To investigate this issue, we design a
novel test set containing 200 3-digit base-5 addition problems which
appears rarely in everyday language and on web pages. We test SEC
and baseline methods on this dataset. The results, as summarized in
Table 7, indicate that SEC tends to exhibit a slight decline in perfor-
mance on these tasks compared to ICL methods.
9

--- PAGE 10 ---
Published as a conference paper at ICLR 2024
ACKNOWLEDGMENTS
This work was supported by National Key R&D Program of China (No. 2022ZD0119101). We
extend our sincerest gratitude to the reviewers, the Area Chairs, the Program Committee, and the
Senior Area Chairs for their invaluable insights and suggestions that significantly contributed to the
improvement of this manuscript. Their expertise and thoughtful critiques have been instrumental in
refining our research and ensuring its quality. Additionally, we would like to thank all individuals
who offered their feedback and recommendations throughout the development of this work.
REFERENCES
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal,
Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are
few-shot learners. Advances in neural information processing systems , 33:1877–1901, 2020.
Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared
Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, et al. Evaluating large
language models trained on code. arXiv preprint arXiv:2107.03374 , 2021.
Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam
Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, Parker Schuh,
Kensen Shi, Sasha Tsvyashchenko, Joshua Maynez, Abhishek Rao, Parker Barnes, Yi Tay, Noam
Shazeer, Vinodkumar Prabhakaran, Emily Reif, Nan Du, Ben Hutchinson, Reiner Pope, James
Bradbury, Jacob Austin, Michael Isard, Guy Gur-Ari, Pengcheng Yin, Toju Duke, Anselm Lev-
skaya, Sanjay Ghemawat, Sunipa Dev, Henryk Michalewski, Xavier Garcia, Vedant Misra, Kevin
Robinson, Liam Fedus, Denny Zhou, Daphne Ippolito, David Luan, Hyeontaek Lim, Barret
Zoph, Alexander Spiridonov, Ryan Sepassi, David Dohan, Shivani Agrawal, Mark Omernick,
Andrew M. Dai, Thanumalayan Sankaranarayana Pillai, Marie Pellat, Aitor Lewkowycz, Erica
Moreira, Rewon Child, Oleksandr Polozov, Katherine Lee, Zongwei Zhou, Xuezhi Wang, Bren-
nan Saeta, Mark Diaz, Orhan Firat, Michele Catasta, Jason Wei, Kathy Meier-Hellstern, Douglas
Eck, Jeff Dean, Slav Petrov, and Noah Fiedel. Palm: Scaling language modeling with pathways,
2022.
Peter Clark, Isaac Cowhey, Oren Etzioni, Tushar Khot, Ashish Sabharwal, Carissa Schoenick, and
Oyvind Tafjord. Think you have solved question answering? try arc, the ai2 reasoning challenge.
arXiv preprint arXiv:1803.05457 , 2018.
Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser,
Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, et al. Training verifiers to
solve math word problems. arXiv preprint arXiv:2110.14168 , 2021.
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. BERT: Pre-training of deep
bidirectional transformers for language understanding. In Proceedings of the 2019 Conference of
the North American Chapter of the Association for Computational Linguistics: Human Language
Technologies, Volume 1 (Long and Short Papers) , pp. 4171–4186, Minneapolis, Minnesota, June
2019. Association for Computational Linguistics. doi: 10.18653/v1/N19-1423. URL https:
//aclanthology.org/N19-1423 .
Qingxiu Dong, Lei Li, Damai Dai, Ce Zheng, Zhiyong Wu, Baobao Chang, Xu Sun, Jingjing Xu,
and Zhifang Sui. A survey for in-context learning. arXiv preprint arXiv:2301.00234 , 2022.
Evelyn Fix and Joseph Lawson Hodges. Discriminatory analysis. nonparametric discrimination:
Consistency properties. International Statistical Review/Revue Internationale de Statistique , 57
(3):238–247, 1989.
Yao Fu, Hao Peng, Ashish Sabharwal, Peter Clark, and Tushar Khot. Complexity-based prompting
for multi-step reasoning. arXiv preprint arXiv:2210.00720 , 2022.
Yao Fu, Litu Ou, Mingyu Chen, Yuhao Wan, Hao Peng, and Tushar Khot. Chain-of-thought hub:
A continuous effort to measure large language models’ reasoning performance. arXiv preprint
arXiv:2305.17306 , 2023.
10

--- PAGE 11 ---
Published as a conference paper at ICLR 2024
Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob
Steinhardt. Measuring massive multitask language understanding. In International Conference
on Learning Representations .
Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang, Dawn
Song, and Jacob Steinhardt. Measuring mathematical problem solving with the MATH dataset.
InThirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks
Track (Round 2) , 2021. URL https://openreview.net/forum?id=7Bywt2mQsCe .
Yuzhen Huang, Yuzhuo Bai, Zhihao Zhu, Junlei Zhang, Jinghan Zhang, Tangjun Su, Junteng Liu,
Chuancheng Lv, Yikai Zhang, Jiayi Lei, et al. C-eval: A multi-level multi-discipline chinese
evaluation suite for foundation models. arXiv preprint arXiv:2305.08322 , 2023.
Hyuhng Joon Kim, Hyunsoo Cho, Junyeob Kim, Taeuk Kim, Kang Min Yoo, and Sang-goo Lee.
Self-generated in-context learning: Leveraging auto-regressive language models as a demonstra-
tion generator. arXiv preprint arXiv:2206.08082 , 2022.
Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. Large
language models are zero-shot reasoners. In ICML 2022 Workshop on Knowledge Retrieval and
Language Models .
Andrew K Lampinen, Ishita Dasgupta, Stephanie CY Chan, Kory Matthewson, Michael Henry
Tessler, Antonia Creswell, James L McClelland, Jane X Wang, and Felix Hill. Can language
models learn from explanations in context? arXiv preprint arXiv:2204.02329 , 2022.
Aitor Lewkowycz, Anders Johan Andreassen, David Dohan, Ethan Dyer, Henryk Michalewski,
Vinay Venkatesh Ramasesh, Ambrose Slone, Cem Anil, Imanol Schlag, Theo Gutman-Solo,
Yuhuai Wu, Behnam Neyshabur, Guy Gur-Ari, and Vedant Misra. Solving quantitative rea-
soning problems with language models. In Alice H. Oh, Alekh Agarwal, Danielle Belgrave,
and Kyunghyun Cho (eds.), Advances in Neural Information Processing Systems , 2022. URL
https://openreview.net/forum?id=IFXTZERXdM7 .
Junlong Li, Zhuosheng Zhang, and Hai Zhao. Self-prompting large language models for open-
domain qa. arXiv preprint arXiv:2212.08635 , 2022.
Jiachang Liu, Dinghan Shen, Yizhe Zhang, William B Dolan, Lawrence Carin, and Weizhu Chen.
What makes good in-context examples for gpt-3? In Proceedings of Deep Learning Inside Out
(DeeLIO 2022): The 3rd Workshop on Knowledge Extraction and Integration for Deep Learning
Architectures , pp. 100–114, 2022.
Pan Lu, Liang Qiu, Kai-Wei Chang, Ying Nian Wu, Song-Chun Zhu, Tanmay Rajpurohit, Peter
Clark, and Ashwin Kalyan. Dynamic prompt learning via policy gradient for semi-structured
mathematical reasoning. In The Eleventh International Conference on Learning Representations ,
2023. URL https://openreview.net/forum?id=DHyHRBwJUTN .
Yao Lu, Max Bartolo, Alastair Moore, Sebastian Riedel, and Pontus Stenetorp. Fantastically ordered
prompts and where to find them: Overcoming few-shot prompt order sensitivity. arXiv preprint
arXiv:2104.08786 , 2021.
Yao Lu, Max Bartolo, Alastair Moore, Sebastian Riedel, and Pontus Stenetorp. Fantastically ordered
prompts and where to find them: Overcoming few-shot prompt order sensitivity. In Proceedings
of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long
Papers) , pp. 8086–8098, 2022.
Swaroop Mishra, Daniel Khashabi, Chitta Baral, and Hannaneh Hajishirzi. Cross-task generalization
via natural language crowdsourcing instructions. In Proceedings of the 60th Annual Meeting of
the Association for Computational Linguistics (Volume 1: Long Papers) , pp. 3470–3487, 2022.
OpenAI. Gpt-4 technical report, 2023.
Chengwei Qin, Aston Zhang, Zhuosheng Zhang, Jiaao Chen, Michihiro Yasunaga, and Diyi
Yang. Is chatgpt a general-purpose natural language processing task solver? arXiv preprint
arXiv:2302.06476 , 2023.
11

--- PAGE 12 ---
Published as a conference paper at ICLR 2024
Ohad Rubin, Jonathan Herzig, and Jonathan Berant. Learning to retrieve prompts for in-context
learning. arXiv preprint arXiv:2112.08633 , 2021.
Victor Sanh, Albert Webson, Colin Raffel, Stephen H Bach, Lintang Sutawika, Zaid Alyafeai, An-
toine Chaffin, Arnaud Stiegler, Teven Le Scao, Arun Raja, et al. Multitask prompted training
enables zero-shot task generalization. In ICLR 2022-Tenth International Conference on Learning
Representations , 2022.
Taylor Shin, Yasaman Razeghi, Robert L Logan IV , Eric Wallace, and Sameer Singh. Autoprompt:
Eliciting knowledge from language models with automatically generated prompts. In Proceedings
of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP) , pp.
4222–4235, 2020.
Taylor Sorensen, Joshua Robinson, Christopher Rytting, Alexander Shaw, Kyle Rogers, Alexia De-
lorey, Mahmoud Khalil, Nancy Fulda, and David Wingate. An information-theoretic approach to
prompt engineering without ground truth labels. In Proceedings of the 60th Annual Meeting of
the Association for Computational Linguistics (Volume 1: Long Papers) , pp. 819–862, 2022.
Hongjin Su, Jungo Kasai, Chen Henry Wu, Weijia Shi, Tianlu Wang, Jiayi Xin, Rui Zhang, Mari
Ostendorf, Luke Zettlemoyer, Noah A Smith, et al. Selective annotation makes language models
better few-shot learners. arXiv preprint arXiv:2209.01975 , 2022.
Xiaofei Sun, Linfeng Dong, Xiaoya Li, Zhen Wan, Shuhe Wang, Tianwei Zhang, Jiwei Li, Fei
Cheng, Lingjuan Lyu, Fei Wu, et al. Pushing the limits of chatgpt on nlp tasks. arXiv preprint
arXiv:2306.09719 , 2023a.
Xiaofei Sun, Xiaoya Li, Jiwei Li, Fei Wu, Shangwei Guo, Tianwei Zhang, and Guoyin Wang. Text
classification via large language models. arXiv preprint arXiv:2305.08377 , 2023b.
Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timoth ´ee
Lacroix, Baptiste Rozi `ere, Naman Goyal, Eric Hambro, Faisal Azhar, Aurelien Rodriguez, Ar-
mand Joulin, Edouard Grave, and Guillaume Lample. Llama: Open and efficient foundation
language models, 2023.
Haifeng Wang, Jiwei Li, Hua Wu, Eduard Hovy, and Yu Sun. Pre-trained language models and their
applications. Engineering , 2022.
Jason Wei, Maarten Bosma, Vincent Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du,
Andrew M. Dai, and Quoc V Le. Finetuned language models are zero-shot learners. In Interna-
tional Conference on Learning Representations , 2022a. URL https://openreview.net/
forum?id=gEZrGCozdqR .
Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, brian ichter, Fei Xia, Ed H. Chi,
Quoc V Le, and Denny Zhou. Chain of thought prompting elicits reasoning in large language
models. In Alice H. Oh, Alekh Agarwal, Danielle Belgrave, and Kyunghyun Cho (eds.), Ad-
vances in Neural Information Processing Systems , 2022b. URL https://openreview.
net/forum?id=_VjQlMeSB_J .
Zhiyong Wu, Yaoxiang Wang, Jiacheng Ye, and Lingpeng Kong. Self-adaptive in-context learning.
arXiv preprint arXiv:2212.10375 , 2022.
Benfeng Xu, Quan Wang, Zhendong Mao, Yajuan Lyu, Qiaoqiao She, and Yongdong Zhang. k
nn prompting: Beyond-context learning with calibration-free nearest neighbor inference. In The
Eleventh International Conference on Learning Representations , 2023.
Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L Griffiths, Yuan Cao, and Karthik
Narasimhan. Tree of thoughts: Deliberate problem solving with large language models. arXiv
preprint arXiv:2305.10601 , 2023.
Aohan Zeng, Xiao Liu, Zhengxiao Du, Zihan Wang, Hanyu Lai, Ming Ding, Zhuoyi Yang, Yifan
Xu, Wendi Zheng, Xiao Xia, Weng Lam Tam, Zixuan Ma, Yufei Xue, Jidong Zhai, Wenguang
Chen, Peng Zhang, Yuxiao Dong, and Jie Tang. Glm-130b: An open bilingual pre-trained model,
2022.
12

--- PAGE 13 ---
Published as a conference paper at ICLR 2024
Shengyu Zhang, Linfeng Dong, Xiaoya Li, Sen Zhang, Xiaofei Sun, Shuhe Wang, Jiwei Li, Runyi
Hu, Tianwei Zhang, Fei Wu, et al. Instruction tuning for large language models: A survey. arXiv
preprint arXiv:2308.10792 , 2023.
Tianyi Zhang*, Varsha Kishore*, Felix Wu*, Kilian Q. Weinberger, and Yoav Artzi. Bertscore:
Evaluating text generation with bert. In International Conference on Learning Representations ,
2020. URL https://openreview.net/forum?id=SkeHuCVFDr .
Yiming Zhang, Shi Feng, and Chenhao Tan. Active example selection for in-context learning. arXiv
preprint arXiv:2211.04486 , 2022a.
Zhuosheng Zhang, Aston Zhang, Mu Li, and Alex Smola. Automatic chain of thought prompting in
large language models. arXiv preprint arXiv:2210.03493 , 2022b.
Zihao Zhao, Eric Wallace, Shi Feng, Dan Klein, and Sameer Singh. Calibrate before use: Improving
few-shot performance of language models. In International Conference on Machine Learning , pp.
12697–12706. PMLR, 2021.
Denny Zhou, Nathanael Sch ¨arli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schu-
urmans, Olivier Bousquet, Quoc Le, and Ed Chi. Least-to-most prompting enables complex
reasoning in large language models. arXiv preprint arXiv:2205.10625 , 2022a.
Yongchao Zhou, Andrei Ioan Muresanu, Ziwen Han, Keiran Paster, Silviu Pitis, Harris Chan,
and Jimmy Ba. Large language models are human-level prompt engineers. arXiv preprint
arXiv:2211.01910 , 2022b.
A D ETAILS OF EXPERIMENTAL SETUP
A.1 T ASKS AND DATASETS
We tested our method on six datasets covering the fields of arithmetic reasoning, commonsense
reasoning, and code generation. A summary of our evaluation datasets is shown in Table 8.
Dataset Split Example Domain Metric
GSM8K (Cobbe et al., 2021) Test 1319 Arithmetic Reasoning acc
MATH (Hendrycks et al.,
2021)Test 5000 Arithmetic Reasoning acc
AI2 Reasoning Challenge
(ARC) (Clark et al., 2018)Test 1172 Commonsense Reasoning acc
MMLU (Hendrycks et al.) Test 13985 Multi-task Language Understanding acc
C-Eval (Huang et al., 2023) Test 12342 Multi-task Language Understanding
in Chineseacc
HumanEval (Chen et al., 2021) Test 164 Code Generation acc
Table 8: A summary of our evaluation datasets.
Here is a detailed description of datasets selection:
Arithmetic Reasoning: For arithmetic reasoning, we use GSM8K (grade-school math problems)
(Cobbe et al., 2021) and MATH (high school level math competition problems) (Hendrycks et al.,
2021). Also, MMLU (Hendrycks et al.) and C-Eval (Huang et al., 2023) contain mathematical
questions. Therefore, we also provide the scores of these two datasets in their mathematics problem.
Commonsense Reasoning: Here we utilize AI2 Reasoning Challenge (ARC) (Clark et al., 2018), a
grade-school level, multiple-choice science questions dataset.
Multi-task Language Understanding: For these tasks, we use MMLU (multi-choice questions in
57 domains) (Hendrycks et al.) and C-Eval (multi-choice questions across 52 diverse disciplines in
China and four difficulty levels) (Huang et al., 2023).
Code Generation: We use HumanEval (Chen et al., 2021), a collection of 164 hand-written pro-
gramming problems.
13

--- PAGE 14 ---
Published as a conference paper at ICLR 2024
A.2 M ODELS
For our main results, we adopt ChatGPT (gpt-3.5-turbo)3, the most capable model in GPT-3.5 fam-
ily4, GPT4 (OpenAI, 2023) and Llama2 34B (Touvron et al., 2023). And for some ablation re-
search, we also use text-davinci-003 and text-davinci-002 in GPT-3.5 family5. The key difference
between text-davinci-003 and text-davinci-002 is that text-davinci-003 was trained of HFRL, but
text-davinci-002 was only trained with supervised finetuning.
A.3 D ETAILS OF RESULTS ON LLAMA 2
The results of SEC and baseline methods on Llama2 (Touvron et al., 2023) are summarized in Table
9. SEC reaches comparable to ICL methods and significantly outperforms zero-shot baselines.
(Llama2 34B) Arithmetic Common Multi-task NLU Code
MATH GSM8K ARC MMLU C-Eval HumanEval
Published Results
Vanilla ICL 6.2a42.2a54.5a62.6a- [ 22.6a]
Our Results
Zero-shot 3.5 29.7 54.4 56.1 36.5 19.5
Zero-shot CoT 3.9 34.5 58.6 56.5 36.3 -
Vanilla ICL 6.4 42.0 67.2 62.3 38.5 22.5
Vanilla SEC 5.8 41.2 65.9 61.1 39.0 21.4
CoT-ICL 7.4 44.5 68.7 61.8 38.9 -
CoT-SEC 7.5 45.6 67.5 62.0 39.9 -
Table 9: Comparison between SEC and baselines on Llama2 34B.7
A.4 D ETAILS OF RESULTS ON MMLU
Figure 7 provides a comprehensive breakdown of the results for the MMLU dataset on GPT3.5.
Notably, in domains like physics and chemistry, CoT-SEC substantially outperforms our baselines,
while in history and politics, it still lag behind ICL. This disparity aligns with the observed differ-
ences in capabilities between these two prompting strategies, as discovered in Section 4.
A.5 D ETAILS OF FEW-SHOT EXTRACTION
For more efficient extraction of few-shot demonstrations of the LLM output, we specify a desired
output format in the prompt, as shown in Figure 1. Then, we parsed the output according to the
format.
In reality, the answer in the demonstration generated by LLMs may not always align with the answer
format in the datasets. For example, LLMs might anser by the content of options rather than the
option labels for a multi-choice question. Acknowledging these discrepancies, we perform answer
extraction and answer validation for the generated answers to ensure that the answers are in the
desired format. Initially, we follow the rules mentioned in Section 3 to extract and clean the answer
for each few-shot demonstration.6Then, each cleaned answer is validated to confirm its consistency
with the predetermined format. For all cases that did not pass the verification, we slightly alter the
3In our main experiments, we use gpt-3.5-turbo-0301 checkpoint, which will be deprecated later. However,
we have discovered that gpt-3.5-turbo-0301 is highly likely to have undergone a model change on June 27th,
the day OpenAI replaced the gpt-3.5-turbo checkpoint.
4https://platform.openai.com/docs/models/gpt-3-5
5https://platform.openai.com/docs/models/gpt-3-5
6In the GSM8k dataset, it is a double-edged sword that normalizing all answers to integers to match the
characteristics of the dataset’s answers. Details in Appendix A.8.
14

--- PAGE 15 ---
Published as a conference paper at ICLR 2024
physicschemistrybiologyCSmath
engineeringhistory
philosophylawpolitics cultureeconomics geography psychologyotherbusinesshealth405060708090100Accuracy (%)Performance on MMLU by Subcategories
Vanilla ICL
CoT-ICL
Vanilla SEC
CoT-SEC
Figure 7: Experiment results on the MMLU dataset by subcategories.
prompt while setting the temperature to 1 to add randomness. Then we have the LLM generate the
demonstration again until it passes the validation.
A.6 P ROMPTS
A.6.1 T HESOURCE OF FEW-SHOT DEMONSTRATIONS IN ICL
Vanilla ICL We used question answer pairs in the prompt in Minerva (Lewkowycz et al., 2022)
for the MATH dataset, and the first five examples in the validation set for the ARC dataset. The
few-shot demonstrations for MMLU and C-Eval datasets are provided along the dataset. As for the
HumanEval dataset, since there are no publicly available few-shot demonstrations and only a test set
is provided, we select the first 4 test samples as the few-shot demonstrations for the remaining part
of the test set, while choosing the last 4 test samples for the first 4 test samples.
CoT-ICL We used the prompt in chain-of-thought Hub (Fu et al., 2023) for the GSM8K dataset,
Minerva (Lewkowycz et al., 2022) for the MATH dataset. For the ARC dataset, we used the rationale
generated by GPT4 model via ChatGPT official website8for the first five examples in the validation
set. The few-shot CoT prompts for MMLU and C-Eval datasets are provided along the dataset.
Since the HumanEval dataset directly prompts the model to generate a function body, it’s weird to
add CoT in a Python function. Thus we don’t provide CoT results on HumanEval.
A.6.2 I NSTRUCTION FOR THE FEW-SHOT DEMONSTRATION GENERATION
Table 10 summarizes the instruction used for the few-shot demonstration generation across all ex-
periments.
A.6.3 O UTPUT FORMAT INSTRUCTION
Table 11 summarizes the output format instruction across all experiments.
7Any result encompassed within brackets signifies data derived from zero-shot prompting. The superscripts
are used to indicate results that have been cited from previous studies:a(Touvron et al., 2023).
8https://chat.openai.com/?model=gpt-4 Using this feature requires subscribing to ChatGPT Plus.
15

--- PAGE 16 ---
Published as a conference paper at ICLR 2024
Vanilla SEC CoT-SEC
MATH Please follwing the above
question, generate five simi-
lar questions with its answer
in Latex.Please follwing the above question, gener-
ate 5 similar questions with its step by step
solution and answer in Latex.
GSM8K Please generate five similar
questions with integer answerPlease generate five similar questions with
step by step reasoning process and an inte-
ger answer
ARC Follwing the above question,
generate five similar multiple
choice science questions with
its choice labels, choice text
and an answer labelFollwing the above question, generate ten
similar multiple choice science questions
with its choice labels, choice text, the ex-
planation of the right answer and an answer
label
MMLU Please follwing the above
question, create five similar
multiple choice {}questions
with its choice labels, choice
text and an answer label (A or
B or C or D). Note that each
question should be complete
and can be answered indepen-
dently.Follwing the above question, generate five
similar multiple choice {}questions with
its choice labels, choice text, the step by
step reason to choose your answer and an
answer label (A or B or C or D). Note that
each question should be complete and can
be answered independently.
C-Eval 请模仿上面的问题，生
成5个相似的关于{}考试的
单项选择题，和这个这个
题目的选项标签，选项内
容和答案。每个问题必须
是完整且能被独立回答
的。请模仿上面的问题，生成5个相似的关
于{}考试的单项选择题，和这个这个题
目的选项标签，选项内容，逐步的推导
出答案的过程和正确答案。每个问题必
须是完整且能被独立回答的。
HumanEval Following the example, gen-
erate 5 similar function head-
ers with its function body in
python.-
Table 10: The instruction used for the few-shot demonstration generation across all 6 datasets. The
{}in MMLU and C-Eval dataset will fill in specific subcategories.
16

--- PAGE 17 ---
Published as a conference paper at ICLR 2024
Vanilla SEC CoT-SEC
MATH Please output in the following
form [[Question1:question \n
Answer1:$ answer in La-
tex$ ]] \n\n\n\n [[Ques-
tion5:question \n Answer5:$
answer in Latex$ ]] \n\n.Please output in the following form [[Ques-
tion1:question \n Sol1:[step by step solu-
tion]\n Answer1:$ answer in Latex$ ]] \n\n
. . .\n\n [[Question5:question \n Sol5:[step
by step solution] \n Answer5:$ answer in
Latex$ ]] \n\n.
GSM8K in the following form Q1: {
question } \n A1:{answer } \n
. . .\n Q5:{question } \n A5:{
answer } \n.in the following form Q1: {question } \n
S1:{solution } \n A1: {answer } \n\n
. . .\n\n Q5:{question } \n S5:{solution }
\n A5:{answer } \n\n.
ARC in the following form
[[Question1: {question } \ n
Label1:[choice labels] \n
Text1:[choice text] \n Ans1: {
answer label }]]\n\n . . .\n
\n [[Question5: {question }
\n Label5:[choice labels] \n
Text5:[choice text] \n Ans5: {
answer label }]]\n\n .in the following form [[Question1: {
question } \ n Label1:[choice labels] \n
Text1:[choice text] \n Sol1: {the explana-
tion of the right answer } \n Ans1: {answer
label}]]\n\n . . .\n\n [[Question10: {
question } \n Label10:[choice labels] \n
Text10:[choice text] \n Sol10: {the explana-
tion of the right answer } \n Ans10: {answer
label}]]\n\n .
MMLU Please output in the following
form [[Question1:[question] \n
Label1:[choice labels] \n
Text1:[choice text] \n Ans1:[A
or B or C or D]]] \n\n . . .\n
\n [[Question5:[question] \n
Label5:[choice labels] \n
Text5:[choice text] \n Ans5:[A
or B or C or D]]] \n\n .Please output in the following form
[[Question1:[question] \n Label1:[choice la-
bels]\n Text1:[choice text] \n Sol1:[reason
to choose your answer] \n Ans1:[A or
B or C or D]]] \n\n . . .\n\n [[Ques-
tion5:[question] \n Label5:[choice labels] \n
Text5:[choice text] \n Sol5:[reason to
choose your answer] \n Ans5:[A or B or C
or D]]] \n\n .
C-Eval 请以 以 下 格式输出答
案：[[题目1:[题目]\n选
项标签1:[选项标签]\n选
项内容1:[选项内容]\n答
案1:[A或B或C或D]]]\n\n
. . .\n\n [[题目5:[题目]\n
选项标签5:[选项标签]\n选
项内容5:[选项内容]\n答
案5:[A或B或C或D]]]。请以以下格式输出答案：[[题目1:[题
目]\n选项标签1:[选项标签]\n选项内
容1:[选项内容]\n解析1：[逐步的推导出
答案的过程]\n答案1:[A或B或C或D]]]\n
\n . . .\n\n [[题目5:[题目]\n选项标
签5:[选项标签]\n选项内容5:[选项内
容]\n解析5：[逐步的推导出答案的过
程]\n答案5:[A或B或C或D]]]。
HumanEval Please output in the following
form: [[[Function Header1]]: \n
[[Function Body1]]: ] \n
\n . . . \n\n [[[Function
Header5]]: \n [[Function
Body5]]: ] \n\n .-
Table 11: Output Format Instruction across all 6 datasets. The output format instruction contains
numerous special symbols to facilitate better answer extraction, but these symbols may not be well
presented in L ATEX formatting.
17

--- PAGE 18 ---
Published as a conference paper at ICLR 2024
A.7 U NSIMPLIFIED ILLUSTRATION OF SEC
For better understanding, we have simplified SEC in Figure 1 and Figure 2 of Section 1. We mainly
simplified the output format in the few-shot demonstration generation, as the original format is
designed for automatic recognition but might not be intuitive for understanding. Therefore, we
transformed it into a more comprehensible format. The following Figure 8 and Figure 9 show the
unsimplified illustration of Vanilla SEC and CoT-SEC.
Input to LLM: 
<Test Input >
Question: At a Nash equilibrium,\n Label:['A', 'B', 'C', 'D']\n Text:['the supply curve intersects the demand curve', 'neither party has an
incentive to deviate from his or her strategy', 'the marginal revenue curve intersects the marginal cost curve', 'the equilibrium is unstable
and each party would like to switch strategies']
<Instruction for the Few-shot Demonstration Generation >
Please follwing the above question, create five similar multiple choice high_school_microeconomics questions with its choice labels, choice
text and an answer label (A  or B or C or D). Note that each question should be complete and can be answered independently .
<Output Format Instruction >
Please output in the following form [[Question1:[question]\n Label1:[choice labels]\n Text1:[choice text]\n Ans1:[A  or B or C or D]]]\n\n
[[Question2:[question]\n Label2:[choice labels]\n Text2:[choice text]\n Ans2:[A  or B or C or D]]]\n\n [[Question3:[question]\n Label3:[choice
labels]\n Text3:[choice text]\n Ans3:[A  or B or C or D]]]\n\n [[Question4:[question]\n Label4:[choice labels]\n Text4:[choice text]\n Ans4:[A  or
B or C or D]]]\n\n [[Question5:[question]\n Label5:[choice labels]\n Text5:[choice text]\n Ans5:[A  or B or C or D]]]\n\n.
Output from LLM:
[[Question1: In a perfectly competitive market, \nLabel1: ['A', 'B', 'C', 'D']\nT ext1: ['firms are price takers', 'firms are price makers', 'firms can
earn economic profits in the long run', 'firms can charge any price they want'] \nAns1: A]
...
[Question4: A price ceiling is \nLabel4: ['A', 'B', 'C', 'D']\nT ext4: ['a legal minimum price that can be charged for a good or service', 'a legal
maximum price that can be charged for a good or service', 'a tax on a good or service', 'a subsidy for a good or service'] \nAns4: B ]
...
Input to LLM: 
<Few-shot Demonstrations Extracted from the Output from LLM in (a) >
Question:{{In a perfectly competitive market,}}
A. firms are price takers                                         
B. firms are price makers
C. firms can earn economic profits in the long run                     
D. firms can charge any price they want
Answer:A
...
Question:{{A  price ceiling is}}
A. a legal minimum price that can be charged for a good or service     
B. a legal maximum price that can be charged for a good or service
C. a tax on a good or service
D. a subsidy for a good or service
Answer:B
<Test Input >
Question:{{At a Nash equilibrium,}}
A. the supply curve intersects the demand curve
B. neither party has an incentive to deviate from his or her strategy
C. the marginal revenue curve intersects the marginal cost curve
D. the equilibrium is unstable and each party would like to switch strategies
Output from LLM:
Answer:BUnsimplified Illustration of V anilla SEC
(b): V anilla ICL(a): SEC Demonstration Generation
Figure 8: The unsimplified illustration of Vanilla SEC.
A.8 T HE DETAILED DISCUSSION ON ANSWER NORMALIZATION IN THE GSM8 K
Not only might LLM’s outputs fail to conform to the output format, but the questions generated by
LLM may also not adhere to our instructions. This phenomenon is especially pronounced in the
GSM8K dataset. The dataset’s answers are represented as integers, but the questions generated by
LLM may not always manipulate the data in a manner that results in an integer answer. Thus, We
rounded the answers to integers so that they could meet the presentation format of the answer in the
dataset.
18

--- PAGE 19 ---
Published as a conference paper at ICLR 2024
Input to LLM: 
<Test Input >
Q: {{A  robe takes 2 bolts of blue fiber and half that much white fiber . How many bolts in total does it take?}}
<Instruction for the Few-shot Demonstration Generation >
Please generate five similar questions with step by step reasoning process and an integer answer
<Output Format Instruction >
in the following form Q1:{question}\n S1:{solution}\n A1:{answer}\n\n Q2:{question}\n S2:{solution}\n A2:{answer}\n\n Q3:{question}\n S3:
{solution}\n A3:{answer}\n\n Q4:{question}\n S4:{solution}\n A4:{answer}\n\n Q5:{question}\n S5:{solution}\n A5:{answer}\n\n.
Output from LLM:
Q1: A dress takes 3 bolts of red fiber and half that much white fiber . How many bolts in total does it take?
S1: The dress takes 3 bolts of red fiber and half that much white fiber , which is 1.5 bolts. Therefore, the total number of bolts required is 3 +
1.5 = 4.5 bolts.
A1: 4
...
Q5: A hat takes 0.5 bolts of purple fiber and a sixth that much white fiber . How many bolts in total does it take?
S5: The hat takes 0.5 bolts of purple fiber and a sixth that much white fiber , which is 0.083 bolts. Therefore, the total number of bolts
required is 0.5 + 0.083 = 0.583 bolts.
A5: 1
Input to LLM: 
<Few-shot Demonstrations Extracted from the Output from LLM in (a) >
Question: A dress takes 3 bolts of red fiber and half that much white fiber . How many bolts in total does it take?
Solution: The dress takes 3 bolts of red fiber and half that much white fiber , which is 1.5 bolts. Therefore, the total number of bolts required is
3 + 1.5 = 4.5 bolts.
The answer is 4.
...
Question: A hat takes 0.5 bolts of purple fiber and a sixth that much white fiber . How many bolts in total does it take?
Solution: The hat takes 0.5 bolts of purple fiber and a sixth that much white fiber , which is 0.083 bolts. Therefore, the total number of bolts
required is 0.5 + 0.083 = 0.583 bolts.
The answer is 1.
<Test Input >
Question: A robe takes 2 bolts of blue fiber and half that much white fiber . How many bolts in total does it take?
Output from LLM:
Solution: The robe takes 2 bolts of blue fiber and half that much white fiber , which is 1 bolt. Therefore, the total number of bolts required is 2
+ 1 = 3 bolts.
The answer is 3.Unsimplified Illustration of CoT -SEC
(b): CoT -ICL(a): SEC Demonstration Generation
Figure 9: The unsimplified illustration of CoT-SEC
However, the approach of directly rounding the answer may have negative effects on the performance
of our method, despite the advantages mentioned above. Since the rounded answer is no longer the
exact answer to the original question, there is a risk of misleading the model. Despite the risks, we
still decided to use it in the end, considering the advantages mentioned earlier and the convenience
of normalization. The final experimental results were very satisfactory.
A.9 D ETAILS REGARDING THE HANDLING OF CASES THAT DO NOT CONFORM TO THE
SPECIFIED OUTPUT FORMAT
As mentioned earlier, in CoT-SEC, out of the 5000 samples in the MATH dataset, 6 samples were
unable to generate few-shot demonstrations that conform to the specified output format. Meanwhile,
in vanilla SEC, all 5000 samples generated few-shot demonstrations that meet the specified output
format. Therefore, we decided to use the demonstrations in vanilla SEC on these 6 samples instead
of CoT-SEC. Given that the overall performance of vanilla SEC is significantly lower than that of
19

--- PAGE 20 ---
Published as a conference paper at ICLR 2024
CoT-SEC, we believe that this approach is unlikely to overestimate the actual results of CoT-SEC.
a
B D ETAILS OF ABLATION STUDY
B.1 D ETAILS OF ERROR ANALYSIS IN GSM8K
Correctness of Reasoning Process in Model-generated Few-shot Demonstrations In almost
all the examples we examined, the correctness of the reasoning process aligns with the correctness
of the answers. We observed that in only two test samples (out of 40), the reasoning process was
correct, but the answer and reasoning process did not match, which is incorrect. Additionally, there
are cases where the answer is correct but the final extracted answer is incorrect due to insufficient
accuracy in answer cleaning and extraction.
Error Type We categorized the errors of the final predictions (not few-shot demonstrations) into
three types: answer extraction errors, computation errors, and logical errors. In our 20 incorrect
examples, only 1 sample belongs to answer extraction errors, 2 belong to computation errors, and
the rest are logical errors, which are relatively more difficult to correct and identify.
B.2 D EFINITION AND DELINEATION OF ERRORS OF FEW-SHOT EXAMPLES
The errors in the few-shot examples generated by LLM can be classified into four main categories:
Answer extraction errors, Computation errors, Question errors and Logical errors.
• Answer extraction errors: This type of error occurs when the model’s solution is correct,
and the answer obtained from the solution is also correct. However, after going through an-
swer cleaning and normalization, the answer is no longer correct. Please note that the cases
where incorrect answers result from the integer normalization process are also considered
answer extraction errors. That is why such errors still occur with a relatively high frequency
even when we have a well-established answer extraction and normalization pipeline.
• Computation errors: These errors occur when the model performs calculations incorrectly,
but the mathematical expressions or equations used in the process are correct.
• Question errors: This type of error occurs when the question lacks necessary conditions,
has ambiguity, or contains contradictions, resulting in an inability to answer.
• Logical errors: Logical errors happen when the model follows an incorrect reasoning pro-
cess, leading to an incorrect final answer. Generally, errors that do not fall into the first
three categories are classified as logical errors.
We categorize Logical errors as fundamental errors, as they represent errors in the logical aspects of
the model’s reasoning. The other three types of errors are categorized as non-fundamental errors, as
they don’t involve errors at the logical level but rather concern shallower aspects like calculations,
formatting, and so on.
B.3 W HY INCORRECT FEW -SHOT DEMONSTRATIONS COULD LEAD TO CORRECT RESULTS
AND CORRECT FEW -SHOT DEMONSTRATIONS COULD LEAD TO INCORRECT RESULTS ?
We have thoroughly researched the detailed proportion of fundamental errors in few-shot examples
that leading to correct results. All but 4 cases of the first row (where the final results of SEC are
correct) which belong to Major Error or All Incorrect in Table 5 and Table 12 can be changed to
Minor Error or All Correct by ignoring non-fundamental errors. Furthermore, among the remaining
4 samples, 2 of them are cases where the answer happens to be correct, meaning the reasoning
process is incorrect, but it leads to the correct answer in the end. So, among the 40 correct samples
we inspected, only 2 samples (5%) that led to the correct final answer and rationale had more than
two few-shot demonstrations with a fundamentally flawed reasoning process and answer.
Section 4 mentioned several typical scenarios where incorrect few-shot demonstrations led to correct
results. For these cases, we provide specific examples: answer extraction errors (see Figure 13),
20

--- PAGE 21 ---
Published as a conference paper at ICLR 2024
computation errors (see Figure 14), question errors (see Figure 15) and instances where the answer
happened to be correct despite a flawed reasoning process (see Figure 16).
In addition, we also provide examples where correct few-shot demonstrations led to incorrect results.
In most of these cases, the few-shot demonstrations were not sufficiently similar to the test question
(see Figure 17) or were too easy, leading the model to underestimate the difficulty of the final
question (see Figure 18).
B.4 P ERFORMANCE DIFFERENCES BETWEEN COT-SEC AND COT-ICL IN THE GSM8K
DATASET
In order to conduct a more in-depth study of the difference, following the manual inspection of
correct and incorrect cases in the GSM8K dataset, we also randomly sampled 20 samples where
CoT-SEC was correct but CoT-ICL was incorrect and 20 samples where CoT-SEC was incorrect but
CoT-ICL was correct. Then we further investigate the model-generated few-shot demonstrations of
these 40 samples. The results are summarized in Table 12.
CoT-SEC CoT-ICL All Correct Minor Er-
rorMajor Er-
rorAll Error
Correct Incorrect 5/20 6/20 6/20 3/20
Incorrect Correct 2/20 5/20 6/20 7/20
Table 12: Correctness of five few-shot demonstrations for 20 samples where CoT-SEC was correct
but CoT-ICL was incorrect, and 20 samples where CoT-SEC was incorrect but CoT-ICL was correct
in the GSM8K dataset. Minor Error means 1-2 incorrect examples, while Major Error means 3-4
incorrect examples.
It is reasonable that the quality of the generated few-shot demonstrations where CoT-SEC was cor-
rect but CoT-ICL was incorrect (shown in Table 12) is lower than the average of samples where
CoT-SEC was correct (shown in Table 5), since these examples are relatively more challenging for
LLMs. And the quality of the generated few-shot demonstrations where CoT-SEC was incorrect
but CoT-ICL was correct (shown in Table 12) is similar to where CoT-SEC was incorrect (shown in
Table 5).
We provided examples where CoT-SEC was correct but CoT-ICL was incorrect (as shown in Figure
19), and examples where CoT-SEC was incorrect but CoT-ICL was correct (as shown in Figure 20).
B.5 E RROR ANALYSIS IN HUMAN EVAL
To further investigate the role and unique characteristics of model-generated few-shot demonstra-
tions, we conducted manual inspections on samples that exhibited changes in correctness (from
correct to incorrect or incorrect to correct) when transitioning from k=1 to k=2 and from k=2 to k=3.
We examined these samples from four aspects:
1. The correctness of model-generated few-shot demonstrations.
2. The homogeneity of the model-generated few-shot demonstrations across different test
samples.
3. The type of error of the final output: Errors are categorized into two types: Logical Error
and Grammar Error. Grammar Error only requires grammatical correction to become the
correct answer, while Logical Error cannot be transformed into the correct answer with
grammar correction alone.
4. The complexity of the final output: Following the previous standard for measuring com-
plexity, we adopt the number of lines in the answer.
For detailed results of the error analysis, please refer to Table 13, Table 14.
From Table 13, we could discover that the accuracy rate is quite high and approximately the same
for each transition scenario. It shows that LLMs could produce few-shot code examples with high
21

--- PAGE 22 ---
Published as a conference paper at ICLR 2024
accuracy, and the correctness of the generated code examples does not significantly impact the tran-
sition. Table 14 demonstrates that most of the errors of the final results in the transition belong to
Logical Error.
Transition Accuracy of Model-generated demonstrations
Number of Shots Correctness 1stshot 2ndshot 3rdshot
1 shot →2 shots T →F 6/7 7/7 -
1 shot →2 shots F →T 11/13 10/13 -
2 shots →3 shots T →F 12/13 9/13 11/13
2 shots →3 shots F →T 3/3 3/3 3/3
Table 13: The correctness of few-shot demonstrations generated by LLM in the HumanEval dataset
where the correctness of the final output changes. Transition means the type of change these test
samples experienced. For example, 1 shot →2 shots and T →F means the final output of these
examples is correct in 1 shot scenario while it is not correct in 2 shots scenario. The accuracy is
represented in a/b, where a represents the number of correct cases, and b represents the total number
of cases. Since in 1 shot →2 shots scenario only the first two shots have an impact on the final
correctness change, we only examined the first two shots.
Transition Error Type of the Incorrect Result Avg. Lines
Number of Shots Correctness Logical Error Grammar Error Before After
1 shot →2 shots T →F 6/7 1/7 23.1 12.5
1 shot →2 shots F →T 9/13 4/13 15.4 14.1
2 shots →3 shots T →F 12/13 1/13 12.8 13.0
2 shots →3 shots F →T 3/3 0/3 9.7 9.7
Table 14: The error type and length (measured by average lines) of the final results in the HumanEval
dataset where the correctness of the final output changes. The definition of transition is mentioned
in the caption of Table 13. The error type is also represented in a/b, where a represents the number
of cases that belong to this particular error type, and b represents the total number of cases. In Avg.
Lines, Before means before the transition while After means after the transition. For example, in 1
shot→2 shots and T →F scenario, before means in 1 shot while after means in 2 shots.
Based on the data from Table 14, we can infer that during the transition from 1 shot to 2 shots, the
reason for the change from correct to incorrect results might be that the complexity of the model-
generated few-shot demonstrations are relatively low, leading the model to oversimplify the problem
(avg. lines changes from 23.1 to 12.5). Then, we speculate that this trend of excessive simplification
will continue to strengthen as the number of shots increases, although this change is not intuitively
shown by the average line count. While the increase in performance with an increase in the number
of shots is intuitive, this finding provides more insights into the reason that, after reaching a certain
number of shots (1 or 2 shots), the performance actually decreases with an increase in shots.
Prompt
def reverse_list(lst: List[int]) -> List[int]:
    """ Reverse a given list of integers
    >>> reverse_list([1, 2, 3, 4, 5])
    [5, 4, 3, 2, 1]
    >>> reverse_list([10, 20, 30])
    [30, 20, 10]
    """Solution
    return lst[::-1]
Figure 10: From 53.1% (17 out of 32)
of the test samples we examined, the
question in the figure appears in the first
two shots of the few-shot demonstra-
tions generated.Also, we made an astonishing additional discovery that
in the few-shot demonstrations generated from 53.1% (17
out of 32) of the test samples we examined, the first two
shots include one that is the same as the question in Fig-
ure 10. This indicates that in the HumanEval dataset,
the model-generated few-shot demonstrations are not as
strongly related to the input questions as we initially an-
ticipated. On the contrary, the few-shot demonstrations
generated from different test samples are highly homog-
enized. This phenomenon is very different from what
we observed in the GSM8K dataset. Also, the frequent
occurrence of such simple questions (in Figure 10) in
model-generated few-shot examples further indicates that the model-generated demonstrations are
too simplistic and underestimate the complexity of the problems.
22

--- PAGE 23 ---
Published as a conference paper at ICLR 2024
B.6 P ERFORMANCE OF GSM8K ONDIFFERENT MODELS
During the experiment on text-davinci-002 and text-davinci-003, we discover that the model fails to
generate five demonstrations that all follow our output format. Frequently, the model only generates
one demonstration, or it deviates from our output format starting from the second or third example.
Therefore, we tentatively infer that these two models lack the capability to generate multiple good
few-shot demonstrations, especially text-davinci-002. Thus, we only adopt 1 shot in these two
models while adopting 5 shots in gpt-3.5-turbo.
B.7 T HE SIMILARITY BETWEEN FEW -SHOT EXAMPLES AND TEST QUESTION .
We calculated the similarity between few-shot demonstrations from SEC and ICL, compared to the
original questions. Our methodology involved utilizing the BERTScore (Zhang* et al., 2020) (f1
score) to measure the similarity between question pairs.9The results of all 6 datasets are shown in
Figure 11. Also, we summarized the BERTScore of each shot in the GSM8K dataset in Figure 12.
GSM8KMATHARCMMLU C-Eval
Human Eval60708090100BERTScoreSimilarity between Few-shot Examples and T est Question
ICL
Vanilla SEC
CoT-SEC
Figure 11: The BERTScore between the few-shot
demonstrations from SEC as well as ICL and the
original questions of all 6 datasets.
1 2 3 4 5
The index of the few-shot example808590BERTScore
The Similarity of Each Shot
Vanilla SEC
CoT-SEC
Vanilla ICL
CoT-ICLFigure 12: The BERTScore of each shot in
the GSM8K dataset.
The comparative analysis distinctly showcases a heightened similarity between the SEC and test
questions, in contrast to ICL. This phenomenon further demonstrates the resemblance between SEC
andknn prompting (Xu et al., 2023) which selected the few-shot examples based on kNearest
Neighbors (Fix & Hodges, 1989). Besides, Figure 12 shows that in SEC, the BERTScore decreases
as the index of the few-shot demonstrations increases. It is reasonable because as the index increases,
they are further away from the test questions, making it harder for the model to reference them
effectively. From the perspective of similarity, the quality of demonstrations decreases as the index
increases.
9If the question used in vanilla ICL and CoT-ICL differ, we averaged the BERTScore from both prompting
strategies to obtain the final similarity of ICL.
23

--- PAGE 24 ---
Published as a conference paper at ICLR 2024
Test Question
Jordan wanted to surprise her mom with a homemade birthday cake. From reading the instruc-
tions, she knew it would take 20 minutes to make the cake batter and 30 minutes to bake the
cake. The cake would require 2 hours to cool and an additional 10 minutes to frost the cake. If
she plans to make the cake all on the same day, what is the latest time of day that Jordan can start
making the cake to be ready to serve it at 5:00 pm?
Question of Few-shot Demonstrations Rationale of Few-shot Demonstrations Extracted
Answer
of the
Output
Samantha wants to make a lasagna for
dinner. The recipe requires 30 min-
utes to prepare the ingredients, 1 hour to
bake the lasagna, and 10 minutes to let
it cool. If she wants to serve the lasagna
at 7:00 pm, what is the latest time she
can start making it?To serve the lasagna at 7:00 pm, Saman-
tha needs to account for the 30 minutes
of preparation time, 1 hour of baking
time, and 10 minutes of cooling time.
Therefore, she needs to start making the
lasagna at 5:20 pm (7:00 pm - 1 hour -
10 minutes - 30 minutes). ✓20✗
John wants to make a pot of chili for a
party. The recipe requires 20 minutes to
prepare the ingredients, 2 hours to cook
the chili, and 15 minutes to let it cool.
If the party starts at 6:00 pm, what is
the latest time John can start making the
chili?To serve the chili at 6:00 pm, John needs
to account for the 20 minutes of prepara-
tion time, 2 hours of cooking time, and
15 minutes of cooling time. Therefore,
he needs to start making the chili at 3:25
pm (6:00 pm - 2 hours - 15 minutes - 20
minutes). ✓25✗
Emily wants to bake a batch of cookies
for her friends. The recipe requires 15
minutes to prepare the dough, 12 min-
utes to bake the cookies, and 5 minutes
to let them cool. If she wants to serve
the cookies at 4:00 pm, what is the lat-
est time she can start making them?To serve the cookies at 4:00 pm, Emily
needs to account for the 15 minutes of
preparation time, 12 minutes of baking
time, and 5 minutes of cooling time.
Therefore, she needs to start making the
cookies at 3:28 pm (4:00 pm - 12 min-
utes - 5 minutes - 15 minutes). ✓28✗
David wants to make a pizza for dinner.
The recipe requires 25 minutes to pre-
pare the dough, 15 minutes to bake the
pizza, and 5 minutes to let it cool. If
he wants to serve the pizza at 7:30 pm,
what is the latest time he can start mak-
ing it?To serve the pizza at 7:30 pm, David
needs to account for the 25 minutes of
preparation time, 15 minutes of baking
time, and 5 minutes of cooling time.
Therefore, he needs to start making the
pizza at 7:05 pm (7:30 pm - 15 minutes -
5 minutes - 25 minutes). ✓5✗
Sarah wants to make a fruit salad for a
picnic. The recipe requires 10 minutes
to prepare the fruit, and 5 minutes to
mix it. If the picnic starts at 12:00 pm,
what is the latest time Sarah can start
making the fruit salad?To serve the fruit salad at 12:00 pm,
Sarah needs to account for the 10 min-
utes of preparation time and 5 minutes
of mixing time. Therefore, she needs to
start making the fruit salad at 11:45 am
(12:00 pm - 5 minutes - 10 minutes). ✓45✗
Final Output of CoT-SEC Extracted Answer
of the Output
Solution: To serve the cake at 5:00 pm, Jordan needs to account for the
20 minutes of preparation time, 30 minutes of baking time, 2 hours of
cooling time, and 10 minutes of frosting time. Therefore, she needs to
start making the cake at 2:00 pm (5:00 pm - 2 hours - 30 minutes - 20
minutes - 10 minutes). The answer is 2:00 pm. ✓2✓
Figure 13: The error in answer extraction led to incorrect few-shot demonstrations, but it eventually
generated the correct answer.
24

--- PAGE 25 ---
Published as a conference paper at ICLR 2024
Test Question
Comet Halley orbits the sun every 75 years. Bill’s dad saw the Comet when he was 30 years old.
Bill saw the comet a second time when he was three times the age his father was when he saw
the Comet. How old was Bill when he saw the Comet for the first time?
Question of Few-shot Demon-
strationsRationale of Few-shot Demonstrations Extracted
An-
swer
of the
Output
Comet Halley orbits the sun ev-
ery 75 years. John’s grandfa-
ther saw the Comet when he
was 40 years old. John saw
the comet a second time when
he was twice the age his grand-
father was when he saw the
Comet. How old was John
when he saw the Comet for the
first time?Let’s call John’s age when he saw the Comet for the
first time ”x”. We know that John’s grandfather saw
the Comet when he was 40 years old, so the Comet
had passed by 75 years before John’s birth. This
means that John’s age when he saw the Comet for
the second time was 75 + x. We also know that John
was twice the age his grandfather was when he saw
the Comet, so we can set up the equation: 2(40) =
75 + x. Solving for x, we get x = 5. ✓5✓
Comet Halley orbits the sun ev-
ery 76 years. Sarah’s mom
saw the Comet when she was
35 years old. Sarah saw the
comet a second time when she
was three times the age her
mom was when she saw the
Comet. How old was Sarah
when she saw the Comet for the
first time?Let’s call Sarah’s age when she saw the Comet for
the first time ”x”. We know that Sarah’s mom saw
the Comet when she was 35 years old, so the Comet
had passed by 76 years before Sarah’s birth. This
means that Sarah’s age when she saw the Comet for
the second time was 7 6 + x. We also know that
Sarah was three times the age her mom was when
she saw the Comet, so we can set up the equation:
3(35) = 76 + x. Solving for x, we get x = 3. ✗3✗
Comet Halley orbits the sun ev-
ery 78 years. Tom’s dad saw
the Comet when he was 28
years old. Tom saw the comet
a second time when he w as
four times the age his dad was
when he saw the Comet. How
old was Tom when he saw the
Comet for the first time?Let’s call Tom’s age when he saw the Comet for
the first time ”x”. We know that Tom’s dad saw the
Comet when he was 28 years old, so th e Comet
had passed by 78 years before Tom’s birth. This
means that Tom’s age when he saw the Comet for
the second time was 78 + x. We a lso know that Tom
was four times the age his dad was when he saw the
Comet, so we can set up the equation: 4(28) = 78 +
x. Solving for x, we get x = 90. ✗90✗
Comet Halley orbits the sun ev-
ery 80 years. Lisa’s grandma
saw the Comet when she was
45 years old. Lisa saw the
comet a second time wh en
she was five times the age her
grandma was when she saw the
Comet. How old was Lisa
when she saw the Comet for the
first time?Let’s call Lisa’s age when she saw the Comet for
the first time ”x”. We know that Lisa’s grandma
saw the Comet when she was 45 years ol d, so the
Comet had passed by 80 years before Lisa’s birth.
This means that Lisa’s age when she saw the Comet
for the second time was 8 0 + x. We also know that
Lisa was five times the age her grandma was when
she saw the Comet, so we can set up the equation:
5(45) = 80 + x. Solving for x, we get x = 205. ✗205✗
Comet Halley orbits the sun ev-
ery 85 years. Mike’s grandpa
saw the Comet when he was 50
years old. Mike saw the comet
a second time whe n he was six
times the age his grandpa was
when he saw the Comet. How
old was Mike when he saw the
Comet for the first time?Let’s call Mike’s age when he saw the Comet for
the first time ”x”. We know that Mike’s grandpa
saw the Comet when he was 50 years old, so the
Comet had passed by 85 years before Mike’s birth.
This means that Mike’s age when he saw the Comet
for the second time was 85 + x. We also know that
Mike was six times the age his grandpa was when
he saw the Comet, so we can set up the equation:
6(50) = 85 + x. Solving for x, we get x = 215. ✓215✓
25

--- PAGE 26 ---
Published as a conference paper at ICLR 2024
Final Output of CoT-SEC Extracted Answer
of the Output
Solution: Let ´s call Bill ´s age when he saw the Comet for the first time
”x”. We know that Bill ´s dad saw the Comet when he was 30 years old,
so the Comet had passed by 75 years before Bill ´s birth. This means that
Bill´s age when he saw the Comet for the second time was 75 + x. We
also know that Bill was three times the age his dad was when he saw the
Comet, so we can set up the equation: 3(30) = 75 + x. Solving for x, we
get x = 15. The answer is 15. ✓15✓
Figure 14: The error in calculation led to incorrect few-shot demonstrations, but it eventually gener-
ated the correct answer. For the three incorrect few-shot demonstrations, the errors all occur in the
final calculation part of solving the equations, meaning that the equations are correct, but the final
calculation of the results is incorrect.
26

--- PAGE 27 ---
Published as a conference paper at ICLR 2024
Test Question
An ice cream factory makes 100 quarts of chocolate ice cream in 2 hours. It can make 50 quarts
of vanilla ice cream in 4 hours. How many quarts in total would be made in 48 hours?
Question of Few-shot Demon-
strationsRationale of Few-shot Demonstrations Extracted
Answer
of the
Output
In a school play, four students
played a total of 72 characters.
Sarah played 18 of the charac-
ters. John played half as many
characters as Sarah and Emily
played 5 more than John. How
many characters did Michael
play?Let’s start by finding the total number of charac-
ters played by John and Emily. John played half as
many characters as Sarah, which is 18/2 = 9 char-
acters. Emily played 5 more than John, which is
9+5 = 14 characters. The total number of charac-
ters played by Sarah, John, and Emily is 18+9+14
= 41. Therefore, Michael played 72-41 = 31 char-
acters.✓31✓
In a basketball game, five play-
ers scored a total of 78 points.
Tom scored 24 of the points.
Jack scored half as many points
as Tom and Alex scored 3 more
than Jack. How many points
did Ben score?Let’s start by finding the total number of points
scored by Tom and Jack. Jack scored half as
many points as Tom, which is 24/2 = 12 po ints.
Alex scored 3 more than Jack, which is 12+3 = 15
points. The total number of points scored by Tom,
Jack, and Alex is 24+12+15 = 5 1. Therefore, Ben
scored 78-51 = 27 points. ✓27✓
In a music concert, six singers
sang a total of 120 songs.
Rachel sang 30 of the songs.
Mark sang half as many songs
as Rachel and Lisa sang 10
more than Mark. How many
songs did John sing?Let’s start by finding the total number of songs
sang by Rachel and Mark. Mark sang half as many
songs as Rachel, which is 30/2 = 15 so ngs. Lisa
sang 10 more than Mark, which is 15+10 = 25
songs. The total number of songs sang by Rachel,
Mark, and Lisa is 30+15+25 = 70. Therefore, John
sang 120-70 = 50 songs. ✓50✓
In a soccer game, seven play-
ers scored a total of 84 goals.
David scored 21 of the goals.
Peter scored half as many goals
as David and Michael scored 4
more than Peter. How many
goals did John score? The
question’s conditions are er-
roneous.Let’s start by finding the total number of goals
scored by David and Peter. Peter scored half as
many goals as David, which is 21/2 = 1 0.5 goals.
We cannot have half a goal, so let’s round it up to
11 goals. Michael scored 4 more than Peter, which
is 11+4 = 15 goals. Th e total number of goals
scored by David, Peter, and Michael is 21+11+15
= 47. Therefore, John scored 84-47 = 37 goals.37
In a dance competition, eight
dancers received a total of 96
points. Lily received 24 of
the points. Jack received half
as many points as Lily and
Sarah received 6 more than
Jack. How many points did
Tom receive?Let’s start by finding the total number of points
received by Lily and Jack. Jack received half as
many points as Lily, which is 24/2 = 12 points.
Sarah received 6 more than Jack, which is 12+6 =
18 points. The total number of points received by
Lily, Jack, and Sarah is 24+12+18 = 54. There-
fore, Tom received 96-54 = 42 points. ✓42✓
27

--- PAGE 28 ---
Published as a conference paper at ICLR 2024
Final Output of CoT-SEC Extracted Answer
of the Output
Solution: Let’s start by finding the total number of points scored by Naomi
and Yuri. Half of Naomi’s score is 68/2 = 34. Yuri scored 10 more than
half of Naomi’s score, which is 34+10 = 44 points. Brianna scored 17
more than Naomi, which is 68+17 = 85 points. The total number of points
scored by Naomi, Yuri, and Brianna is 68+44+85 = 197. Therefore, Jojo
scored 251-197 = 54 points.The answer is 54. ✓54✓
Figure 15: The question contains ambiguity or lacks certain conditions, which led to incorrect few-
shot demonstrations, but it eventually generated the correct answer. (Here, the question’s conditions
are erroneous, leading to the appearance of decimals in the calculation process, while the score
cannot be decimals in real life.)
28

--- PAGE 29 ---
Published as a conference paper at ICLR 2024
Test Question
Jam has three boxes full of pencils and 2 loose pencils which give a total of 26 pencils. If her
sister, Meg, has 46 pencils, how many boxes do Jam and Meg need to store all their pencils?
Question of Few-shot
DemonstrationsRationale of Few-shot Demonstrations Extracted
Answer
of the
Output
Tom has 4 boxes of
crayons and 3 loose
crayons which give a to-
tal of 35 crayons. If
his sister, Lily, has
50 crayons, how many
boxes do Tom and Lily
need to store all their
crayons?Let’s assume that each box of crayons has the same num-
ber of crayons. Let’s call the number of crayons in each
box ”x”. Then we can write two equations: 4x + 3 =
35 (for Tom’s crayons) and bx = 50 (for Lily’s crayons).
Solving the first equation, we get x = 8. Substitut ing this
value into the second equation, we get b = 50/8 = 6.25.
Since we can’t have a fraction of a box, we round up to
the nearest wh ole number and get that Tom and Lily need
7 boxes in total. ✗7✗
Sara has 5 boxes of
markers and 4 loose
markers which give a to-
tal of 49 markers. If
her brother, John, has
70 markers, how many
boxes do Sara and John
need to store all their
markers?Let’s assume that each box of markers has the same num-
ber of markers. Let’s call the number of markers in each
box ”x”. Then we can wri te two equations: 5x + 4 =
49 (for Sara’s markers) and bx = 70 (for John’s markers).
Solving the first equation, we get x = 9. Substitu ting this
value into the second equation, we get b = 70/9 = 7.78.
Since we can’t have a fraction of a box, we round up to
the nearest w hole number and get that Sara and John
need 13 boxes in total. ✗13✗
Alex has 6 boxes of
erasers and 5 loose
erasers which give a
total of 71 erasers. If
his sister, Emily, has
90 erasers, how many
boxes do Alex and
Emily need to store all
their erasers?Let’s assume that each box of erasers has the same num-
ber of erasers. Let’s call the number of erasers in each
box ”x”. Then we can wri te two equations: 6x + 5 =
71 (for Alex’s erasers) and bx = 90 (for Emily’s erasers).
Solving the first equation, we get x = 11. Substi tuting
this value into the second equation, we get b = 90/11 =
8.18. Since we can’t have a fraction of a box, we round
up to the neares t whole number and get that Alex and
Emily need 15 boxes in total. ✗15✓
Mike has 7 boxes of
highlighters and 6 loose
highlighters which give
a total of 83 high-
lighters. If his brother,
Max, has 110 highlight
ers, how many boxes
do Mike and Max need
to store all their high-
lighters?Let’s assume that each box of highlighters has the same
number of highlighters. Let’s call the number of high-
lighters in each box ”x”. Then we can write two equa-
tions: 7x + 6 = 83 (for Mike’s highlighters) and bx =
110 (for Max’s highlighters). Solving the first equatio n,
we get x = 11. Substituting this value into the second
equation, we get b = 110/11 = 10. Since we can’t have
a fraction of a box, we get that Mike and Max need 17
boxes in total. ✗17✗
Jenny has 8 boxes of
pens and 7 loose pens
which give a total of
95 pens. If her sister,
Jane, has 130 pens, how
many boxes do Jenny an
d Jane need to store all
their pens?Let’s assume that each box of pens has the same num-
ber of pens. Let’s call the number of pens in each box
”x”. Then we can write two eq uations: 8x + 7 = 95 (for
Jenny’s pens) and bx = 130 (for Jane’s pens). Solving the
first equation, we get x = 11. Substituting this va lue into
the second equation, we get b = 130/11 = 11.82. Since we
can’t have a fraction of a box, we round up to the nearest
whole numb er and get that Jenny and Jane need 20 boxes
in total. ✗20✗
29

--- PAGE 30 ---
Published as a conference paper at ICLR 2024
Final Output of CoT-SEC Extracted Answer
of the OutputCanonical Solution
Solution: Let ´s assume that each box of pen-
cils has the same number of pencils. Let ´s
call the number of pencils in each box ”x”.
Then we can write two equations: 3x + 2 =
26 (for Jam ´s pencils) and bx = 46 (for Meg ´s
pencils). Solving the first equation, we get
x = 8. Substituting this value into the sec-
ond equation, we get b = 46/8 = 5.75. Since
we can ´t have a fraction of a box, we round
up to the nearest whole number and get that
Jam and Meg need 9 boxes in total. The an-
swer is 9. ✗9✓ There are a total of 26
- 2 = << 26-2=24 >>
24 pencils in the three
boxes. Thus, each box
can contain 24 / 3 =
<< 24/3=8 >> 8 pen-
cils. Together, Jam and
Meg have 26 + 46 = <<
26+46=72 >>72 pencils.
Therefore, they need 72
/ 8 = << 72/8=9 >> 9
boxes to put in all their
pencils. #### 9
Figure 16: The incorrect few-shot demonstrations led to the final answer happening to be correct
despite a flawed reasoning process.
30

--- PAGE 31 ---
Published as a conference paper at ICLR 2024
Test Question
Dolly has two books. Pandora has one. If both Dolly and Pandora read each others’ books as
well as their own, how many books will they collectively read by the end?
Question of Few-shot
DemonstrationsRationale of Few-shot Demonstrations Extracted
Answer
of the
Output
John has three pencils.
Mary has two pencils. If
they share their pencils
with each other, how
many pencils will they
have collectively ?John has 3 pencils and Mary has 2 pencils, so they have a
total of 5 pencils. After sharing, John will have 2 pencils
and Mary will hav e 3 pencils. Therefore, they will have
a total of 5 pencils. ✓5✓
Samantha has four mar-
bles. Jack has three
marbles. If they ex-
change one marble with
each other, how many
marbles will they have
collect ively?Samantha has 4 marbles and Jack has 3 marbles, so they
have a total of 7 marbles. After exchanging, Samantha
will have 3 marbles and Ja ck will have 4 marbles. There-
fore, they will have a total of 7 marbles. ✓7✓
Tom has five stickers.
Sarah has two stickers.
If they give each other
one sticker, how many
stickers will they have
collectively?Tom has 5 stickers and Sarah has 2 stickers, so they have
a total of 7 stickers. After giving each other one sticker,
Tom will have 4 s tickers and Sarah will have 3 stickers.
Therefore, they will have a total of 7 stickers. ✓7✓
Alex has six candies.
Emily has three can-
dies. If they share their
candies with each other,
how many candies will
they have collectivel y?Alex has 6 candies and Emily has 3 candies, so they have
a total of 9 candies. After sharing, Alex will have 4 can-
dies and Emily will h ave 5 candies. Therefore, they will
have a total of 9 candies. ✓9✓
David has seven pencils.
Rachel has four pencils.
If they exchange two
pencils with each other,
how many pencils will
they have collect ively?David has 7 pencils and Rachel has 4 pencils, so they
have a total of 11 pencils. After exchanging, David will
have 5 pencils and Rache l will have 6 pencils. Therefore,
they will have a total of 11 pencils. ✓11✓
Final Output of CoT-SEC Extracted Answer
of the OutputCanonical Solution
Solution: Dolly has 2 books and Pandora
has 1 book, so they have a total of 3 books.
After reading each other’s books as well as
their own, Dolly will have read 3 books and
Pandora will have read 2 books. Therefore,
they will have collectively read 5 books by
the end. The answer is 5. ✗5✗ There are 2 + 1 = <<
2+1=3 >> 3 books in to-
tal. Dolly and Pandora
both read all 3 books, so 3
books/person x 2 people
=<<3*2=6 >>6 books
total #### 6
Figure 17: In this example, the few-shot demonstrations were not sufficiently similar to the test
question. Possessing pencils, marbles, stickers and candies are different from reading a book, since
each person can read the book once, so they read it a total of two times. Even though these few-shot
demonstrations are correct, the final generated result is incorrect.
31

--- PAGE 32 ---
Published as a conference paper at ICLR 2024
Test Question
A pirate crew is digging for buried treasure on the island marked X on a map. They dug ten holes
the first day, thirteen holes the second day, and eight holes the third day. They stopped digging
early on the third day to fill in two holes the pirates kept falling in. On the fourth day of digging,
they unearthed a treasure chest full of gold, jewels, and an aged hat. The island had four times
as many holes by then as it did at the end of the first day. How many holes did the pirates dig on
the fourth day before finding the treasure?
Question of Few-shot Demonstra-
tionsRationale of Few-shot Demonstrations Extracted
Answer
of the
Output
A group of students are selling candy
bars to raise money for their school.
On the first day, they sold 25 candy
bars. On the second da y, they sold 18
candy bars. On the third day, they sold
30 candy bars. If they want to sell a to-
tal of 100 candy bars, how many more
ca ndy bars do they need to sell?To find out how many more candy bars the
students need to sell, we need to add up the
number of candy bars they sold on the first
three days and subtract that from the total
they want to sell. 25 + 18 + 30 = 73. 100 -
73 = 27. ✓27✓
A chef is making a soup and needs to
add 3 cups of water for every 4 cups
of broth. If the chef has 8 cups of
broth, how many cups of w ater does
she need to add?To find out how many cups of water the
chef needs to add, we need to use the ra-
tio of 3 cups of water for every 4 cups of
broth. We can set up a proportion: 3/4 =
x/8. Cross-multiplying, we get 4x = 24, so
x = 6.✓6✓
A car rental company charges $25 per
day plus $0.20 per mile driven. If a
customer rents a car for 3 days and
drives 150 miles, how muc h will they
be charged?To find out how much the customer will be
charged, we need to multiply the number
of days by the daily rate and add that to the
cost pe r mile times the number of miles
driven. 3 days at $25 per day is $75. 150
miles at $0.20 per mile is $30. $75 + $30
= $105. ✓105✓
A company produces 500 widgets per
day. If they want to increase produc-
tion by 20%, how many widgets will
they need to produce each day ?To find out how many widgets the com-
pany will need to produce each day, we
need to multiply the current production by
1.2whichrepresentsa 20%increase . 500
x 1.2 = 600. ✓600✓
A store is having a sale where all items
are 25% off. If a customer buys a shirt
that originally costs $20, how much
will they pay afte r the discount?To find out how much the customer will
pay after the discount, we need to multiply
the original price by 0.75 (which represents
a 25% d iscount). $20 x 0.75 = $15. ✓15✓
32

--- PAGE 33 ---
Published as a conference paper at ICLR 2024
Final Output of CoT-SEC Extracted Answer
of the OutputCanonical Solution
Solution: The pirates dug a total of 10 + 13
+ 8 = 31 holes in the first three days. They
filled in two holes, so the total number of
holes at the end of the third day was 31 -
2 = 29 holes. The island had four times as
many holes by the fourth day, so there were
4 x 29 = 116 holes on the fourth day. To find
out how many holes the pirates dug on the
fourth day, we need to subtract the number
of holes they had already dug from the total
number of holes on the fourth day: 116 - 31
= 85 holes. The answer is 85. ✗85✗ Let X mark the number
of holes they dug on
the fourth day. The
island had 4 * 10 = <<
4*10=40 >> 40 holes
when they found the trea-
sure. They dug 10 + 13 +
8 =<<10+13+8=31 >>
31 holes the first three
days. After filling in 2
holes, they had 31 - 2 =
<<31-2=29 >>29 holes
dug. When they found
the treasure, they had
29 + X = 40 holes dug.
Thus, the pirates dug 40
- 29 = << 40-29=11 >>
11 holes on the fourth
day. #### 11
Figure 18: In this example, the few-shot demonstrations were either too easy (the first demonstra-
tions) or not very similar to the test question. Even though these few-shot demonstrations are correct,
the final generated result is incorrect.
33

--- PAGE 34 ---
Published as a conference paper at ICLR 2024
Test Question
Annabelle is saving for a phone that costs $400. She already has $80 in her savings. Her first
job, where she earns $10 per hour, pays her for 20 hours of work. She is also paid for 15 hours of
work at her second job, where she earns $5 an hour. In dollars, how much money does Annabelle
still need to save?
Question of Few-shot Demonstra-
tionsRationale of Few-shot Demonstrations Extracted
Answer
of the
Output
John is saving for a bike that costs
$300. He already has $100 in his
savings. His first job, where he earns
$8 per hour, pays him for 25 hours of
work. He is also paid for 10 hours
of work at his second job, where he
earns $6 an hour. In dollars, how
much money does Jo hn still need to
save?John earns $8 per hour at his first job and
works for 25 hours, so he earns 8 x 25 = $ <<
8*25=200 >> 200.He earns $6 per hour at
his secon d job and works for 10 hours, so he
earns 6 x 10 = $ <<6*10=60 >>60.There-
fore, John earns a total of 200 + 60 = $ <<
200+60=260 >>260.He alr eady has $100 in
his savings, so he still needs to save 300 - 260
- 100 = $ <<300-260-100=40 >>40.✗40✗
Samantha is saving for a laptop that
costs $800. She already has $200 in
her savings. Her first job, where she
earns $12 per hour, pays her for 30
hours of work. She is also paid for
20 hours of work at her second job,
where she earns $8 an hour. In dol-
lars, how much mo ney does Saman-
tha still need to save?Samantha earns $12 per hour at her first
job and works for 30 hours, so she earns
12 x 30 = $ << 12*30=360 >> 360.She
earns $8 per hour at her second job and
works for 20 hours, so she earns 8 x 20 =
$<< 8*20=160 >> 160.Therefore, Saman-
tha earns a total of 360 + 160 = $ <<360+1
60=520 >>520.She already has $200 in her
savings, so she still needs to save 800 - 520 -
200 = $ <<800-520-200=80 >>80.✓80✓
David is saving for a camera that
costs $600. He already has $150 in
his savings. His first job, where he
earns $15 per hour, pays him for 20
hours of work. He is also paid for
15 hours of work at his second job,
where he earns $7 an hour. In dol-
lars, how much money doe s David
still need to save?David earns $15 per hour at his first job
and works for 20 hours, so he earns 15
x 20 = $ << 15*20=300 >> 300.He earns
$7 per hour at his s econd job and works
for 15 hours, so he earns 7 x 15 = $ <<
7*15=105 >> 105.Therefore, David earns a
total of 300 + 105 = $ <<300+105=405 >>
4 05.He already has $150 in his savings, so
he still needs to save 600 - 405 - 150 = $ <<
600-405-150=45 >>45.✓45✓
Emily is saving for a dress that costs
$150. She already has $50 in her
savings. Her first job, where she
earns $10 per hour, pays her for 15
hours of work. She is also paid for
10 hours of work at her second job,
where she earns $5 an hour. In dol-
lars, how much money d oes Emily
still need to save?Emily earns $10 per hour at her first job
and works for 15 hours, so she earns 10
x 15 = $ << 10*15=150 >> 150.She earns
$5 per hour at her second job and works
for 10 hours, so she earns 5 x 10 = $ <<
5*10=50 >>50.Therefore, Emily earns a to-
tal of 150 + 50 = $ << 150+50=200 >> 20
0.She already has $50 in her savings, so she
still needs to save 150 - 50 - 200 = $ <<150-
50-200= -100 >>-100.✓(✗)-100✓
(✗)
Michael is saving for a game that
costs $50. He already has $20 in
his savings. His first job, where
he earns $7 per hour, pays him for
10 hours of work. He is also paid
for 5 hours of work at his second
job, where he earns $4 an hour. In
dollars, how much money does Mi
chael still need to save?Michael earns $7 per hour at his first job and
works for 10 hours, so he earns 7 x 10 =
$<< 7*10=70 >> 70.He earns $4 per hour
at his seco nd job and works for 5 hours, so
he earns 4 x 5 = $ <<4*5=20 >>20.There-
fore, Michael earns a total of 70 + 20 = $ <<
70+20=90 >>90.He alread y has $20 in his
savings, so he still needs to save 50 - 90 - 20
= $<<50-90-20= -60 >>-60.✓(✗)-60✓
(✗)
34

--- PAGE 35 ---
Published as a conference paper at ICLR 2024
Final Output of CoT-
SECExtracted
Answer of
CoT-SECFinal Output of
CoT-ICLCanonical Solution
Solution: Annabelle
earns $10 per hour
at her first job and
works for 20 hours, so
she earns 10 x 20 =
$<< 10*20=200 >>
200.She earns $5
per hour at her sec-
ond job and works
for 15 hours, so she
earns 5 x 15 = $ <<
5*15=75 >> 75.There-
fore, Annabelle earns
a total of 200 + 75 =
$<< 200+75=275 >>
275. She already has
$80 in her savings, so
she still needs to save
400 - 275 - 80 = $ <<
400-275-80=45 >> 45.
The answer is 45. ✓45✓ Solution: Let’s
think step by step.
Annabelle needs
$400 for the phone.
She already has $80
saved. From her first
job, she earns $10
per hour and works
for 20 hours, so she
earns 10 x 20 = $200.
From her second job,
she earns $5 per hour
and works for 15
hours, so she earns 5
x 15 = $75. In total,
she has earned 200 +
75 = $275. To reach
her goal of $400, she
still needs to save
400 - 275 = $125.
The answer is $125.
✗Subtracting Annabelle’s
initial savings shows that
she still needs to save
$400 – $80 = $ << 400-
80=320 >> 320. From
her first job, she earns
$10 * 20 hours = $ <<
10*20=200 >> 200.
From her second job, she
earns $5 * 15 hours =
$<< 5*15=75 >> 75.
She therefore still needs
to save $320 – $200 –
$75 = $ << 320-200-
75=45 >>45. #### 45
Figure 19: In this example, the final output of CoT-SEC is correct while the final output of CoT-ICL
is incorrect. Considering the high accuracy of this set of few-shot demonstrations and their high
similarity to the test question, we have reasons to infer that CoT-SEC leads to better performance
of the model on this problem compared to CoT-ICL. (The last two questions are mathematically
correct, but they are problematic from a commonsense perspective because we do not need to ”save”
a negative amount of money.)
35

--- PAGE 36 ---
Published as a conference paper at ICLR 2024
Test Question
John has 3 boxes. Each box is 5 inches by 6 inches by 4 inches. The walls are 1 inch thick. What
is the total inner volume of all 3 boxes?
Question of Few-shot
DemonstrationsRationale of Few-shot Demonstrations Extracted
Answer of
the Output
Samantha has 4 boxes.
Each box is 7 inches by 8
inches by 5 inches. The
walls are 2 inches thick.
What is the total inner vol-
ume of all 4 boxes?The inner dimensions of each box are (7-2)
inches by (8-2) inches by (5-2) inches, which is
5 inches by 6 inches by 3 inches. The inner vol-
ume of each box is 5 x 6 x 3 = 90 cubic inches.
The total inner volume of all 4 boxes is 90 x 4 =
360 cubic inches. ✗360✗
Tom has 2 boxes. Each
box is 10 inches by 12
inches by 8 inches. The
walls are 3 inches thick.
What is the total inner vol-
ume of all 2 boxes?The inner dimensions of each box are (10-3)
inches by (12-3) inches by (8-3) inches, which is
7 inches by 9 inches by 5 inches. The inn er vol-
ume of each box is 7 x 9 x 5 = 315 cubic inches.
The total inner volume of all 2 boxes is 315 x 2
= 630 cubic inches. ✗630✗
Emily has 5 boxes. Each
box is 6 inches by 8 inches
by 4 inches. The walls are
1 inch thick. What is the
total inner volume of all 5
bo xes?The inner dimensions of each box are (6-1)
inches by (8-1) inches by (4-1) inches, which is
5 inches by 7 inches by 3 inches. The inner vol-
ume of each box is 5 x 7 x 3 = 105 cubic inches.
The total inner volume of all 5 boxes is 105 x 5
= 525 cubic inches. ✗525✗
David has 6 boxes. Each
box is 9 inches by 10
inches by 6 inches. The
walls are 2 inches thick.
What is the total inner vol-
ume of all 6 boxes?The inner dimensions of each box are (9-2)
inches by (10-2) inches by (6-2) inches, which
is 7 inches by 8 inches by 4 inches. The inne
r volume of each box is 7 x 8 x 4 = 224 cubic
inches. The total inner volume of all 6 boxes is
224 x 6 = 1344 cubic inches. ✗1344 ✗
Sarah has 8 boxes. Each
box is 4 inches by 6 inches
by 3 inches. The walls are
1 inch thick. What is the
total inner volume of all 8
bo xes?The inner dimensions of each box are (4-1)
inches by (6-1) inches by (3-1) inches, which is
3 inches by 5 inches by 2 inches. The inner vol-
ume of each box is 3 x 5 x 2 = 30 cubic inches.
The total inner volume of all 8 boxes is 30 x 8 =
240 cubic inches. ✗240✗
36

--- PAGE 37 ---
Published as a conference paper at ICLR 2024
Final Output of CoT-
SECExtracted
Answer of
CoT-SECFinal Output of
CoT-ICLCanonical Solution
Solution: The inner di-
mensions of each box
are (5-1) inches by
(6-1) inches by (4-
1) inches, which is 4
inches by 5 inches by 3
inches. The inner vol-
ume of each box is 4 x
5 x 3 = 60 cubic inches.
The total inner volume
of all 3 boxes is 60 x
3 = 180 cubic inches.
The answer is 180. ✗180✗ Solution: The inner
dimensions of each
box are 3 inches by
4 inches by 2 inches
(subtracting 1 inch
from each dimension
for the thickness of
the walls). The inner
volume of each box
is therefore 3 x 4 x
2 = 24 cubic inches.
The total inner vol-
ume of all 3 boxes
is 24 x 3 = 72 cubic
inches.✓The walls subtract
2*1=<< 2*1=2 >> 2
inches from each di-
mension So each box
has 5-2= << 5-2=3 >>
3 inch width It also has
a 6-2= << 6-2=4 >>
4 inch height Finally,
it has a 4-2= << 4-
2=2>> 2 inch depth
So the inner volume of
one box is 4*3*2= <<
4*3*2=24 >> 24 cubic
inches So in total the
inner volume of the
3 boxes is 3*24= <<
3*24=72 >> 72 cubic
inches #### 72
Zero-shot Result
The inner dimensions of each box are 3 inches by 4 inches by 2 inches (subtracting 1 inch from
each dimension for the thickness of the walls). The inner volume of each box is therefore 24
cubic inches (3 x 4 x 2). The total inner volume of all 3 boxes is 72 cubic inches (24 x 3). ✓
Figure 20: In this example, the final output of CoT-SEC is incorrect while the final output of CoT-
ICL is correct. Given the correct zero-shot results and the results from CoT-ICL, we believe that the
incorrect few-shot examples generated by SEC have undermined the model’s performance on this
problem, even though the model itself has the capability to answer this question correctly.
37

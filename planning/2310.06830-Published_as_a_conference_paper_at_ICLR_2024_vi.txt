# 2310.06830.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/planning/2310.06830.pdf
# Kích thước tệp: 730524 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Được xuất bản như bài báo hội nghị tại ICLR 2024
LEMUR: HÀI HÒA NGÔN NGỮ TỰ NHIÊN VÀ
MÃ LỆNH CHO CÁC TÁCNHÂN NGÔN NGỮ
Yiheng Xu∗♠♢Hongjin Su∗♠♢Chen Xing∗♣Boyu Mi♠♢Qian Liu♡♢Weijia Shi△
Binyuan Hui♢Fan Zhou♠♢Yitao Liu♠♢Tianbao Xie♠♢Zhoujun Cheng♠♢Siheng Zhao♠♢
Lingpeng Kong♠Bailin Wang★Caiming Xiong♣Tao Yu♠♢
♠Đại học Hồng Kông♢XLang Lab♣Salesforce Research
♡Sea AI Lab△Đại học Washington★MIT CSAIL
♠{yhxu,hjsu,tyu }@cs.hku.hk♣{cxing, cxiong }@salesforce.com

TÓM TẮT
Chúng tôi giới thiệu Lemur và Lemur-Chat, những mô hình ngôn ngữ có thể truy cập công khai được tối ưu hóa cho cả khả năng ngôn ngữ tự nhiên và lập trình để phục vụ như xương sống của các tác nhân ngôn ngữ đa năng. Quá trình tiến hóa từ các mô hình chat ngôn ngữ đến các tác nhân ngôn ngữ chức năng đòi hỏi các mô hình không chỉ thành thạo tương tác con người, lý luận và lập kế hoạch mà còn đảm bảo sự tích hợp trong các môi trường liên quan. Điều này đòi hỏi sự kết hợp hài hòa giữa khả năng ngôn ngữ và lập trình trong các mô hình. Lemur và Lemur-Chat được đề xuất để giải quyết nhu cầu này, thể hiện khả năng cân bằng trong cả hai lĩnh vực, không giống như các mô hình mã nguồn mở hiện có có xu hướng chuyên môn hóa về một trong hai. Thông qua việc tiền huấn luyện tỉ mỉ sử dụng kho dữ liệu tập trung mã lệnh và tinh chỉnh hướng dẫn trên dữ liệu văn bản và mã lệnh, các mô hình của chúng tôi đạt được hiệu suất trung bình tiên tiến trên các benchmark văn bản và lập trình đa dạng. Các thí nghiệm toàn diện chứng minh sự vượt trội của Lemur so với các mô hình mã nguồn mở hiện có và khả năng thành thạo của nó trong các nhiệm vụ tác nhân khác nhau bao gồm giao tiếp con người, sử dụng công cụ và tương tác trong môi trường quan sát hoàn toàn và từng phần. Sự hài hòa giữa ngôn ngữ tự nhiên và lập trình cho phép Lemur-Chat thu hẹp đáng kể khoảng cách với các mô hình độc quyền về khả năng tác nhân, cung cấp những hiểu biết quan trọng trong việc phát triển các tác nhân mã nguồn mở tiên tiến thành thạo lý luận, lập kế hoạch và hoạt động một cách mượt mà trong các môi trường khác nhau. Mô hình và mã nguồn của chúng tôi đã được công bố tại https://github.com/OpenLemur/Lemur.

1 GIỚI THIỆU
Các tác nhân thông minh được hiểu rộng rãi như những người giải quyết vấn đề tự động có khả năng cảm nhận môi trường của họ, quyết định và hành động dựa trên môi trường đó (Sutton & Barto, 2005; Russell, 2010; Wilkins, 2014). Các triển khai gần đây của khái niệm này trong việc tạo ra các tác nhân ngôn ngữ (Yao et al., 2022b; Gravitas, 2023; Wang et al., 2023a) có khả năng sử dụng ngôn ngữ tự nhiên cho các nhiệm vụ đa dạng và phức tạp trong các môi trường khác nhau đã thể hiện tiềm năng, đặc biệt khi được xây dựng dựa trên các mô hình ngôn ngữ lớn (LLMs) (Brown et al., 2020; Chen et al., 2021; Chowdhery et al., 2022; OpenAI, 2023; Touvron et al., 2023a). Những tác nhân như vậy khai thác kiến thức con người trong LLMs và có thể suy nghĩ và giao tiếp theo cách của con người. Điều này trang bị cho họ khả năng sử dụng các công cụ đa dạng, hoạt động trong môi trường phức tạp, tham gia vào lý luận ngôn ngữ và tạo ra các hệ thống đa tác nhân tự phát.

Để hiệu quả tạo thành nền tảng của các tác nhân ngôn ngữ, LLMs không chỉ nên thành thạo tương tác con người, lý luận và lập kế hoạch mà còn đảm bảo sự tích hợp trong các môi trường liên quan (Wei et al., 2022; Huang et al., 2022a; Ichter et al., 2022). Tương tác con người, lý luận và lập kế hoạch có thể được thực hiện phần lớn thông qua khả năng ngôn ngữ tự nhiên của LLMs. Mặt khác, việc thực thi tích hợp trong môi trường thường được đạt được bằng cách sử dụng mã lệnh đa năng hoặc API chuyên biệt theo lĩnh vực, chẳng hạn như điều khiển trình duyệt web (Shi et al., 2017; Yao et al., 2022a; Deng et al., 2023; Zhou et al., 2023), tương tác với terminal CLI của hệ điều hành (Yang et al., 2023), và thao tác cánh tay robot thông qua API nguyên thủy (Ichter et al., 2022; Huang et al., 2022b; Liang et al., 2023). Do đó, chúng tôi cho rằng để xây dựng các tác nhân ngôn ngữ, điều bắt buộc là các mô hình ngôn ngữ phải sở hữu khả năng hài hòa trong cả ngôn ngữ tự nhiên và ngôn ngữ lập trình. Sự cân bằng này đảm bảo rằng các mô hình không chuyên môn hóa độc quyền trong các lĩnh vực nhất định mà có thể tích hợp một cách mượt mà với bối cảnh môi trường và tạo ra các hành động có thể kiểm soát và hợp lệ. Hiện tại, các mô hình nguồn đóng như GPT-4 (OpenAI, 2023) thể hiện những khả năng như vậy, trao quyền cho họ hoạt động như các tác nhân ngôn ngữ. Tuy nhiên, các LLMs mã nguồn mở hiện tại như Llama 2 (Touvron et al., 2023a) và CodeLlama (Rozière et al., 2023) truyền thống được thiết kế cho các nhiệm vụ văn bản hoặc liên quan đến mã lệnh, với khả năng hạn chế trong việc cân bằng hiệu quả cả hai.

Để giải quyết nhu cầu này, chúng tôi giới thiệu Lemur và Lemur-Chat, những mô hình tiên tiến, có thể truy cập công khai được tiền huấn luyện và tinh chỉnh để hài hòa khả năng văn bản và mã lệnh. Chúng tôi đã cải thiện Llama-2-70B cơ sở thông qua các giai đoạn tiền huấn luyện và tinh chỉnh hướng dẫn được thiết kế chu đáo. Cụ thể, chúng tôi xây dựng một kho dữ liệu tập trung mã lệnh dựa trên The Stack (Kocetkov et al., 2022), bao gồm 90B token với tỷ lệ mã-văn bản 10:1, đảm bảo cải thiện khả năng lập trình trong khi duy trì hiệu suất về khả năng ngôn ngữ tự nhiên. Chúng tôi gọi mô hình này là Lemur. Sau khi tiền huấn luyện, chúng tôi thực hiện tinh chỉnh hướng dẫn sử dụng khoảng 300K ví dụ từ cả văn bản và mã lệnh để xây dựng một mô hình tuân theo hướng dẫn, mà chúng tôi gọi là Lemur-Chat. Các đánh giá kỹ lưỡng trên 8 benchmark văn bản và lập trình xác nhận hiệu suất vượt trội của cả Lemur và Lemur-Chat trong nhiều đánh giá văn bản và mã lệnh, thiết lập chúng như những mô hình mã nguồn mở toàn diện nhất.

Hơn nữa, công trình này bắt đầu đánh giá các khả năng quan trọng của các tác nhân ngôn ngữ trong các tình huống khác nhau, mà chúng tôi gọi là các benchmark tác nhân. Chúng tôi đặc biệt chú trọng đến khả năng sử dụng công cụ của họ, và khả năng tích hợp trong phản hồi môi trường và phản hồi con người. Chúng tôi cũng khám phá những thách thức do môi trường thực và quan sát từng phần đặt ra, nơi tác nhân phải thực hiện hành động dựa trên kiến thức hạn chế và thực hiện thêm các hành động để thu thập thêm thông tin. Kết quả thí nghiệm cho thấy Lemur-Chat vượt trội hơn các mô hình mã nguồn mở khác trong 12 trong số 13 benchmark tác nhân. Điều này nhấn mạnh cách tích hợp khả năng tự nhiên và lập trình cho phép Lemur-Chat vượt qua các mô hình mã nguồn mở hiện tại cho các tác nhân ngôn ngữ, thu hẹp đáng kể sự chênh lệch hiệu suất giữa các lựa chọn thay thế mã nguồn mở và thương mại. Các thí nghiệm của chúng tôi cho thấy một hiểu biết quan trọng rằng trong các tình huống tác nhân, cần có sự cộng hưởng giữa khả năng ngôn ngữ tự nhiên và lập trình. Cụ thể, đối với các mô hình có khả năng ngôn ngữ tự nhiên mạnh nhưng khả năng lập trình yếu như Llama-2-70B-Chat, họ có thể sử dụng hiệu quả các công cụ đơn giản để hỗ trợ lý luận (§4.2) vì không gian hành động nhỏ và độ khó sử dụng công cụ thấp. Tuy nhiên, khi đối mặt với các tình huống ra quyết định phức tạp như duyệt web và điều hướng nhà, không gian hành động thường lớn, và các mô hình có khả năng lập trình mạnh có lợi thế trong việc tạo ra các chuỗi hành động thực thi phức tạp (§4.5). Hơn nữa, chúng tôi đã phân tích lỗi trên một số môi trường bao gồm nhiều kỹ năng tác nhân để phản ánh những thách thức chính cho phát triển tác nhân ngôn ngữ trong tương lai, bao gồm khả năng thực thi công cụ và hành động §D.1, độ khó vấn đề §D.2, và kiến thức lĩnh vực §D.3.

Nhìn chung, Lemur có cả khả năng ngôn ngữ tự nhiên và lập trình mạnh, cho phép nó đạt được hiệu suất tốt hơn trong cả hai tình huống. Nghiên cứu này cung cấp hiểu biết về việc tối ưu hóa sự cộng hưởng giữa ngôn ngữ tự nhiên và lập trình, đặt nền tảng vững chắc cho việc phát triển các tác nhân ngôn ngữ tiên tiến có khả năng hoạt động hiệu quả trong các môi trường khác nhau.

2 TIỀN HUẤN LUYỆN VÀ TINH CHỈNH HƯỚNG DẪN CỦA LEMUR

Phần này sẽ giới thiệu phương pháp xây dựng các mô hình Lemur và Lemur-Chat cũng như hiệu suất của chúng trên các benchmark thường được sử dụng để đánh giá mô hình ngôn ngữ tiền huấn luyện. Để xây dựng một mô hình cân bằng hơn, quy trình bao gồm hai giai đoạn: tiền huấn luyện (§ 2.1) và tinh chỉnh hướng dẫn (§ 2.2). Quy trình huấn luyện được thể hiện trong Hình 1.

2.1 TIỀN HUẤN LUYỆN

Trong giai đoạn tiền huấn luyện, chúng tôi chọn mô hình cơ sở Llama-2-70B làm điểm khởi đầu, đây là mô hình cơ sở mã nguồn mở tiên tiến trong hầu hết các tình huống ngoại trừ tình huống lập trình. Mục tiêu của chúng tôi là cải thiện khả năng lập trình trong khi duy trì khả năng lý luận của Llama-2. Để đạt được điều này, chúng tôi xây dựng một kho dữ liệu với tỷ lệ mã-văn bản 10:1. Chúng tôi thảo luận về cách quyết định tỷ lệ này trong § A.1.2. Đối với phần mã, chúng tôi dựa trên The Stack (Kocetkov et al., 2022), một bộ sưu tập mã nguồn từ GitHub với giấy phép cho phép. Trong tất cả các ngôn ngữ, chúng tôi tập trung vào các ngôn ngữ kịch bản hoặc thông dịch (Python, SQL, Bash, Perl, v.v.) vì các mô hình tác nhân thường được thực thi trong các tình huống tương tác. Không giống như các ngôn ngữ biên dịch như C++, bản chất thông dịch của các ngôn ngữ kịch bản cho phép thực thi ngay lập tức và dễ dàng sửa đổi, điều này rất cần thiết cho tương tác động trong các tình huống tác nhân ngôn ngữ. Về mặt văn bản, chúng tôi sử dụng RefinedWeb (Penedo et al., 2023), Redpajama (Computer, 2023), cũng như CommonCrawl, Wikipedia, Books, ArXiv, StackExchange và DM Mathematics (Saxton et al., 2019) để xây dựng kho dữ liệu văn bản. Theo các công trình trước đây (Gao et al., 2020; Smith et al., 2022; Computer, 2023; Li et al., 2023), chúng tôi thực hiện khử trùng lặp mở rộng sau khi tổng hợp tất cả các nguồn dữ liệu. Thành phần của dữ liệu được hiển thị trong Phụ lục § A.1.1. Chúng tôi huấn luyện mô hình Lemur-70B được khởi tạo với Llama-2-70B sử dụng một pod TPUv4-512. Chúng tôi huấn luyện mô hình với đóng gói chuỗi (Raffel et al., 2019; Chung et al., 2022) để cải thiện hiệu suất huấn luyện. Vui lòng tham khảo Phụ lục § A.1.3 để biết thêm chi tiết.

2.2 TINH CHỈNH HƯỚNG DẪN

Trong giai đoạn tinh chỉnh hướng dẫn, chúng tôi bao gồm bốn nguồn dữ liệu để xây dựng Lemur-Chat, bao gồm kho dữ liệu đối thoại được chú thích theo phong cách crowdsourcing Open Assistant (Köpf et al., 2023), dữ liệu Orca với chuỗi lý luận suy nghĩ cho các nhiệm vụ được viết bởi con người (Lian et al., 2023; Mukherjee et al., 2023), ShareGPT & Chatlogs chứa các bản ghi lịch sử người dùng thực và ChatGPT (dữ liệu ShareGPT), cũng như dữ liệu Evol-CodeAlpaca (Luo et al., 2023) bao gồm các nhiệm vụ lập trình phức tạp được tạo bởi ChatGPT cùng với các giải pháp của chúng. Thống kê của các bộ dữ liệu hướng dẫn này được hiển thị trong Bảng 1. Sau khi thu thập các dữ liệu này, chúng tôi bổ sung làm sạch và khử trùng lặp các dữ liệu tinh chỉnh hướng dẫn này. Chúng tôi thực hiện huấn luyện trên các dữ liệu này trong 2 epoch. Vui lòng tham khảo § A.2 để biết thêm chi tiết.

3 TỪ MÔ HÌNH NGÔN NGỮ ĐẾN TÁC NHÂN NGÔN NGỮ

Phần này giới thiệu cách chúng tôi đo lường khả năng ngôn ngữ và lập trình của một mô hình ngôn ngữ để hướng dẫn quá trình hài hòa. Chúng tôi thảo luận thêm về những thách thức mới khi kết nối LLM với môi trường và mô tả cách chúng tôi kiểm tra các khả năng tác nhân cần thiết.

3.1 CÁC KHcapability CƠ BẢN NGÔN NGỮ VÀ LẬP TRÌNH

Các công trình trước đây thường sử dụng nhiều benchmark khác nhau để phản ánh toàn diện hiệu suất của các mô hình trên các loại nhiệm vụ khác nhau. Do đó, chúng tôi đánh giá hiệu suất của các mô hình khác nhau trên các benchmark văn bản và mã lệnh như sau.

•Benchmark văn bản: MMLU (Hendrycks et al., 2021a) để xác định tính chính xác thực tế, BBH (Suzgun et al., 2022) để kiểm tra khả năng lý luận, GSM8K (Cobbe et al., 2021) để đánh giá lý luận toán học.

•Benchmark mã lệnh: HumanEval (Chen et al., 2021) và MBPP (Austin et al., 2021) để kiểm tra khả năng viết Python, Spider (Yu et al., 2018) để đánh giá khả năng truy vấn cơ sở dữ liệu, MultiPL-E (Cassano et al., 2023) để đo khả năng lập trình đa ngôn ngữ, DS-1000 (Lai et al., 2023) để đánh giá trong các tình huống khoa học dữ liệu

3.2 KẾT NỐI CÁC TÁC NHÂN LLM VỚI MÔI TRƯỜNG

Trong khi các phép đo trong §3.1 cung cấp những hiểu biết có giá trị về từng lĩnh vực, chúng có thể không bao quát đầy đủ khả năng của các mô hình trong các tình huống tác nhân ngôn ngữ do tập trung vào các tương tác một lượt trong các thiết lập quan sát hoàn toàn. Để giải quyết sự khác biệt này, chúng tôi xem xét kỹ lưỡng các mô hình trong bối cảnh các tình huống tương tác đa lượt để đánh giá khả năng thích ứng của chúng trong các tình huống thực tế. Đánh giá của chúng tôi tập trung vào các khả năng khác nhau của các tác nhân ngôn ngữ, được bao gồm trong các yếu tố được nêu trong Hình 2 và Bảng 2. Để đánh giá toàn diện hơn các khả năng này, chúng tôi tổ chức lại các bộ dữ liệu hiện có thành bốn bộ để kiểm tra các kỹ năng đa dạng mà tình huống tác nhân yêu cầu. Vui lòng tham khảo Phụ lục B để biết chi tiết về từng bộ dữ liệu.

Tăng cường với Công cụ Việc sử dụng công cụ (Schick et al., 2023; Hao et al., 2023; Mialon et al., 2023) là một khả năng quan trọng của các tác nhân ngôn ngữ. Các nhiệm vụ như tính toán hoặc truy xuất thông tin có thể được chuyển giao cho các mô-đun bên ngoài (ví dụ: trình thông dịch Python hoặc công cụ tìm kiếm) bằng cách sử dụng công cụ (Gao et al., 2023; Chen et al., 2022), cải thiện độ tin cậy và khả năng diễn giải. Công cụ bao gồm việc gọi các toán tử trong ngôn ngữ ký hiệu hoặc gọi API (Shen et al., 2023). Điều này đòi hỏi phân tách một nhiệm vụ, tích hợp ý định vào công cụ, và sử dụng kết quả cho các hành động tiếp theo, dựa vào khả năng lý luận ngôn ngữ tự nhiên và lập trình (Cheng et al., 2023; Surís et al., 2023). Để đánh giá khả năng của các tác nhân ngôn ngữ giải quyết các vấn đề đa lượt phức tạp bằng cách sử dụng công cụ, chúng tôi giới thiệu phần của bộ dữ liệu MINT (Wang et al., 2023b) tập trung vào việc sử dụng công cụ cho lý luận. Phần này bao gồm một số bộ dữ liệu được điều chỉnh để kiểm tra: MINT-{GSM8K, MATH}(Cobbe et al., 2021; Hendrycks et al., 2021b) được sử dụng để kiểm tra khả năng của mô hình giải quyết các vấn đề toán học bằng cách sử dụng trình thông dịch Python, và MINT-{HotpotQA, MMLU}(Yang et al., 2018; Hendrycks et al., 2021a) đánh giá khả năng của mô hình giải quyết các câu hỏi dựa trên kiến thức bằng cách sử dụng tìm kiếm Wikipedia. Đồng thời, đối với MINT-TheoremQA (Chen et al., 2023a), mô hình cần thực hiện tìm kiếm kiến thức trên Wikipedia và sử dụng trình thông dịch Python để tính toán và rút ra kết luận.

Tự gỡ lỗi với Phản hồi Môi trường Tự gỡ lỗi là một cách quan trọng để kiểm tra xem một mô hình có thể tích hợp phản hồi môi trường hay không (Jignasu et al., 2023; Olausson et al., 2023; Chen et al., 2023b). Trong tình huống tự gỡ lỗi, mô hình thường cần hoàn thành một chuỗi hoạt động phức tạp, chẳng hạn như các hàm Python, truy vấn/sửa đổi cơ sở dữ liệu, chuỗi hành động robot, v.v. (Gur et al., 2023; Yao et al., 2023). Những hoạt động phức tạp này đôi khi không thể được thực thi thành công và sẽ trả về thông báo lỗi. Điều này đòi hỏi mô hình phải hiểu loại phản hồi môi trường này và sửa lỗi, điều này kiểm tra hiệu ứng kết hợp của khả năng lý luận ngôn ngữ tự nhiên và ngôn ngữ lập trình. Chúng tôi sử dụng các bộ dữ liệu phong phú từ nhiều benchmark để đánh giá hiệu suất này, bao gồm MINT-MBPP và MINT-HumanEval đa lượt trong MINT (Wang et al., 2023b), SQL và Bash trong InterCode (Yang et al., 2023), cũng như RoboCodeGen gọi API robot thông qua mã lệnh (Liang et al., 2023). Những môi trường này yêu cầu mô hình hoàn thành các nhiệm vụ phức tạp và sẽ cung cấp lỗi thực thi. Trong những môi trường này, hiệu suất mô hình sẽ thay đổi theo khả năng tự gỡ lỗi của nó, phản ánh khả năng tích hợp phản hồi.

Tuân theo Phản hồi Ngôn ngữ Tự nhiên Tuân theo phản hồi ngôn ngữ tự nhiên là một cơ chế quan trọng để các tác nhân nhận thông tin từ con người hoặc các tác nhân khác (Wang et al., 2022a; Ouyang et al., 2022; Gong et al., 2023). Trong các tình huống mà các vấn đề phức tạp được giải quyết thông qua tương tác đa lượt, mô hình không chỉ cần tích hợp phản hồi môi trường mà còn phản hồi từ con người hoặc các tác nhân khác để cải thiện. Cơ chế này đòi hỏi mô hình phải hiểu các hướng dẫn mới dựa trên bối cảnh kết hợp ngôn ngữ tự nhiên và mã lệnh, và tích hợp chúng thành các chuỗi hành động mới. Để đánh giá khả năng của mô hình chấp nhận phản hồi ngôn ngữ tự nhiên, chúng tôi tuân theo cách tiếp cận của các benchmark MINT: sử dụng người dùng mô phỏng GPT-4 làm giáo viên để hướng dẫn mô hình giải quyết vấn đề. Thiết lập này bao gồm một loạt các bộ dữ liệu MINT (Wang et al., 2023b) để đánh giá toàn diện hiệu suất sau khi thêm phản hồi ngôn ngữ tự nhiên trong các tình huống khác nhau.

Khám phá trong Môi trường Quan sát Từng phần Khám phá môi trường quan sát từng phần là một yếu tố độc đáo và thách thức trong các tình huống tác nhân. Tất cả các thiết lập được đề cập trước đây có thể được coi là môi trường quan sát hoàn toàn, có nghĩa là các tác nhân có thể quan sát tất cả thông tin của môi trường để lập kế hoạch, lý luận và ra quyết định. Tuy nhiên, trong môi trường quan sát từng phần (còn được gọi là Quy trình Quyết định Markov Quan sát Từng phần) (Kurniawati, 2021), các tác nhân chỉ có thể quan sát từng phần thông tin môi trường để giải quyết vấn đề. Điều này đòi hỏi các tác nhân phải thu thập thông tin thông qua khám phá và tiếp tục ra quyết định. Quá trình này đặt ra yêu cầu cao đối với các khả năng khác nhau của tác nhân, chẳng hạn như lập kế hoạch và lý luận ngôn ngữ tự nhiên, tương tác môi trường, v.v. Để đo lường khả năng này, chúng tôi sử dụng ba bộ dữ liệu: InterCode-CTF (Yang et al., 2023) và WebArena (Zhou et al., 2023) trong môi trường kỹ thuật số, cũng như ALFWorld (Shridhar et al., 2020b) trong môi trường vật lý. InterCode-CTF cung cấp một terminal hệ điều hành cho các mô hình giải quyết các vấn đề Capture the Flag (CTF) nơi các tác nhân cần nhiều vòng khám phá để có được cờ. WebArena đánh giá khả năng của các tác nhân điều khiển trình duyệt để hoàn thành nhiệm vụ thông qua khám phá. ALFWorld là một môi trường nhà mô phỏng nơi các tác nhân cần khám phá điều hướng và hoàn thành các nhiệm vụ cụ thể.

4 KẾT QUẢ THÍ NGHIỆM

4.1 CÁC KHẢ NĂNG NGÔN NGỮ VÀ MÃ LỆNH

Các đánh giá toàn diện về các benchmark văn bản và mã lệnh trong Bảng 3 chứng minh khả năng ấn tượng của các mô hình Lemur-70B và Lemur-70B-Chat. Khác với Llama-2-70B và Llama-2-70B-Chat, chủ yếu được tiền huấn luyện và tinh chỉnh trên dữ liệu văn bản, các mô hình Lemur tăng cường khả năng lập trình và do đó nâng cao hiệu suất tổng thể lần lượt 4.3% và 14.8%. Tương tự, các mô hình như StarCoder-15B, WizardCoder-15B, CodeLlama-34B và CodeLlama-34B-INST, chủ yếu được huấn luyện trên các bộ dữ liệu mã lệnh, thể hiện hiệu suất vững chắc trong các benchmark mã lệnh. Trung bình, Lemur-70B vượt trội hơn StarCoder-15B, StarCoderPlus-15B và CodeLlama-34B lần lượt 14.3%, 16.8% và 1.9%, và Lemur-70B-Chat vượt qua WizardCoder-15B và CodeLlama-34B-INST lần lượt 18.0% và 9.4%. Sự gia tăng đáng khen ngợi này làm nổi bật giá trị của việc hài hòa kỹ năng văn bản và lập trình.

Khả năng văn bản và mã lệnh cộng hưởng cho phép chúng hoạt động như các tác nhân ngôn ngữ. Tuy nhiên, tồn tại sự khác biệt giữa khả năng ngôn ngữ tự nhiên và lập trình trong các mô hình mã nguồn mở hiện tại. Những hạn chế như vậy cản trở khả năng của các mô hình này hoạt động như các tác nhân ngôn ngữ, dẫn đến suy giảm hiệu suất trong các benchmark tác nhân. Trong các phần tiếp theo, chúng tôi đánh giá tỉ mỉ các khả năng quan trọng khác nhau của tác nhân, tiết lộ tầm quan trọng của khả năng văn bản và mã lệnh cộng hưởng đối với các mô hình ngôn ngữ.

4.2 TĂNG CƯỜNG VỚI CÔNG CỤ

Trong lĩnh vực giải quyết vấn đề, các tác nhân, giống như con người, sử dụng các công cụ khác nhau để tăng cường khả năng của họ. Điều này được minh họa bởi (Chen et al., 2022), người thể hiện rằng khả năng lý luận toán học của LLM có thể được cải thiện đáng kể với sự hỗ trợ của Python. Theo dữ liệu được trình bày trong Bảng 4, rõ ràng là Lemur-70B-Chat vượt trội hơn cả Llama-2-70B-Chat và CodeLlama-34B-INST, cho thấy khả năng vượt trội trong việc tận dụng hiệu quả các công cụ. Ngoài ra, chúng tôi tìm thấy sự khác biệt hiệu suất giữa các mô hình mã nguồn mở và nguồn đóng trong các bài kiểm tra benchmark toán học thách thức M-MATH và M-TheoremQA. Chúng tôi phân tích thêm các lỗi để hiểu rõ hơn hiện tượng này, vui lòng tham khảo nội dung trong Phụ lục D.1.

4.3 TỰ GỠ LỖI VỚI PHẢN HỒI MÔI TRƯỜNG

Kỹ thuật tự gỡ lỗi đạt được sức hút đáng kể trong lĩnh vực tạo mã lệnh (Olausson et al., 2023; Zhang et al., 2023). Phương pháp này bao gồm việc các mô hình sử dụng thông tin phản hồi, chẳng hạn như traceback lỗi trình thông dịch và quan sát cơ sở dữ liệu, để sửa chữa bất kỳ lỗi hiện có nào. Khả năng thích ứng này là điều cần thiết cho các tác nhân vì họ phải liên tục nhận và phản ứng với phản hồi từ môi trường trong quá trình tương tác. Như được thể hiện trong Bảng 5, hiệu suất của Lemur-70B-Chat vượt trội đáng kể so với Llama-2-70B-Chat và CodeLlama-34B-INST trong các benchmark lập trình tương tác. Điều này nhấn mạnh tầm quan trọng của việc có khả năng cân bằng cho các tác nhân tương tác trong những môi trường như vậy.

Chúng tôi phân tích thêm kết quả của InterCode-SQL để hiểu cách các mô hình tích hợp phản hồi môi trường. Trong thiết lập này, các tác nhân được cung cấp lược đồ cơ sở dữ liệu và hướng dẫn cho tương tác trò chơi SQL. Hoạt động như tác nhân, các mô hình được giao nhiệm vụ truy vấn cơ sở dữ liệu và trả lời câu hỏi trong môi trường tương tác đa lượt. Hình 3 cho thấy Tăng trưởng Tỷ lệ Thành công qua các mô hình với mỗi lượt tương tác. Lemur thể hiện hiệu suất mạnh mẽ trong vòng đầu tiên, cho thấy hiệu suất ban đầu tương đương với text-bison-001 và thấp hơn một chút so với gpt-3.5-turbo. Tuy nhiên, Lemur cải thiện liên tục qua mười vòng tương tác, cuối cùng vượt qua hiệu suất của gpt-3.5-turbo. Ngược lại, text-bison-001, thể hiện hiệu suất ban đầu tương đương với Lemur, không cho thấy sự cải thiện đáng kể. Llama-2-70B-Chat, trong khi thể hiện khả năng thích ứng nhất quán với phản hồi trong suốt quá trình, có khoảng cách đáng kể trong hiệu suất ban đầu do khả năng lập trình kém hơn, do đó tỷ lệ thành công của nó vẫn tương đối thấp hơn. CodeLlama-34B-INST hầu như không trả lời đúng các câu hỏi trong vòng đầu tiên. Chúng tôi quan sát thấy điều này là do nó mù quáng tuân theo lời khuyên trong hướng dẫn trò chơi và cứng đầu thực thi lệnh show tables trước, thay vì cố gắng hiểu cấu trúc cơ sở dữ liệu được cung cấp. Sau một sự cải thiện trong vòng thứ hai, hiệu suất của nó trở lại bình thường. Tuy nhiên, sự tăng trưởng vẫn hạn chế ngay cả sau mười vòng tương tác, ổn định ngang bằng với Llama-2-70B-Chat và phản ánh điểm yếu tương đối của nó trong việc thích ứng với phản hồi môi trường. Ngoài ra, chúng tôi đã phân tích ảnh hưởng độ khó vấn đề trong §D.2.

4.4 TUÂN THEO PHẢN HỒI NGÔN NGỮ TỰ NHIÊN

Tuân theo phản hồi ngôn ngữ tự nhiên từ người dùng hoặc các tác nhân khác là một khả năng quan trọng cho các tác nhân ngôn ngữ. Nó đòi hỏi các tác nhân phải hiểu các hướng dẫn ngôn ngữ tự nhiên phức tạp và chuyển đổi chúng thành các chuỗi thực thi ký hiệu dựa trên bối cảnh hiện tại. Để đánh giá khả năng của các mô hình tuân theo phản hồi ngôn ngữ tự nhiên, chúng tôi tuân theo các thiết lập đánh giá của MINT (Wang et al., 2023b), đo lường khả năng của các tác nhân ngôn ngữ tận dụng phản hồi ngôn ngữ tự nhiên bằng cách sử dụng cải thiện hiệu suất. Để cung cấp phản hồi ngôn ngữ tự nhiên trong các thiết lập đa lượt, MINT sử dụng GPT-4 để mô phỏng người dùng cung cấp phản hồi hữu ích về các giải pháp từ các tác nhân ngôn ngữ được đánh giá.

Chúng tôi đánh giá các mô hình trên MINT-Reasoning và MINT-Code với và không có phản hồi GPT-4 và kết quả thí nghiệm được trình bày trong Bảng 6. MINT-Reasoning bao gồm năm benchmark được sửa đổi: GSM8k, MATH, TheoremQA, HotpotQA và MMLU. MINT-Coding bao gồm HumanEval và MBPP được sửa đổi. Chúng tôi tìm thấy rằng tất cả các mô hình đều có thể hưởng lợi từ GPT-4, có nghĩa là GPT-4 mạnh mẽ như một giáo viên có thể cung cấp phản hồi hữu ích ngay cả khi không có sự thật cơ bản. Chúng tôi cũng tính toán ∆feedback, cho biết sự cải thiện tuyệt đối nhờ phản hồi GPT-4. Theo kết quả từ Bảng 6, mô hình Lemur-70B-Chat đạt được 8.19 trong ∆feedback, tốt hơn đáng kể so với Llama-2-70B-Chat và CodeLlama-34B-INST.

4.5 KHÁM PHÁ TRONG MÔI TRƯỜNG QUAN SÁT TỪNG PHẦN

Chúng tôi đánh giá các tác nhân ngôn ngữ trong các môi trường đa dạng và thấy rằng Lemur-70B-Chat thể hiện hiệu suất cân bằng và đáng khen ngợi trên tất cả các nhiệm vụ được kiểm tra. Như thể hiện trong Bảng 7, nó đạt điểm 22.00 trong InterCode-CTF, thể hiện sự thành thạo trong các kỹ năng terminal đa mặt và khả năng thích ứng chiến lược. Hơn nữa, chúng tôi đã tiến hành phân tích lỗi thêm về các nhiệm vụ CTF trong §D.3 và thấy rằng ngoài các kỹ năng chung của terminal hệ điều hành, các nhiệm vụ CTF cũng đòi hỏi kiến thức lĩnh vực an ninh mạng. Điều này cho thấy các yêu cầu thách thức đối với các tác nhân để hoạt động tốt trong các môi trường khác nhau. Trong WebArena, nó đạt được điểm số 5.79, phản ánh sự thành thạo trong việc diễn giải và thực thi các lệnh ngôn ngữ tự nhiên tiên tiến trong các môi trường web phức tạp. Trong ALFWorld, nó thể hiện khả năng lập kế hoạch và lý luận thông thường vượt trội với điểm số 59.70, thành công trong việc điều hướng và thực hiện trong các môi trường vật lý mô phỏng. Trong khi gpt-4 tổng thể thể hiện điểm số cao hơn, hiệu suất nhất quán của Lemur-70B-Chat trên các môi trường đa dạng và quan sát từng phần nhấn mạnh tính đa dạng và tiềm năng của nó trong việc xử lý các ứng dụng thực tế, đa dạng.

Chúng tôi cũng tiến hành thí nghiệm để khám phá các định dạng đầu ra khác nhau cho các hành động trong môi trường WebArena. Thay vì chỉ nhắc mô hình ngôn ngữ trực tiếp tạo ra các hành động được định nghĩa trước (ví dụ: type [id] [content] [press enter after]), chúng tôi ánh xạ xác định không gian hành động thành các biểu diễn Python (ví dụ: type(id:int, content:str, press enter after:bool)). Sau đó chúng tôi nhắc mô hình ngôn ngữ dự đoán biểu diễn này và sau đó phân tích dự đoán Python của mô hình thành các hành động thực thi được định nghĩa trước. Các phát hiện của chúng tôi, như thể hiện trong Hình 4 cho thấy rằng việc ánh xạ sang biểu diễn Python dẫn đến hiệu suất tốt hơn so với việc dự đoán trực tiếp các hành động. Những kết quả như vậy gợi ý rằng việc lựa chọn cẩn thận và hợp lý biểu diễn trung gian, dựa trên kho dữ liệu tiền huấn luyện, có thể cải thiện hiệu quả hiệu suất của mô hình như một tác nhân ngôn ngữ, phù hợp với các phát hiện trước đây (Hu et al., 2022).

5 CÔNG TRÌNH LIÊN QUAN

Học Chuyển giao trên Mã lệnh Sự tiến bộ trong các mô hình ngôn ngữ mở rộng (Devlin et al., 2019; Radford et al., 2019; Raffel et al., 2019; Brown et al., 2020) đã thúc đẩy tiến bộ trong học chuyển giao cho các nhiệm vụ liên quan đến mã lệnh, được làm phong phú thêm bởi mô hình tiền huấn luyện liên tục (Gururangan et al., 2020). Hernandez et al. (2021) đưa ra những hiểu biết về mối tương tác giữa kích thước mô hình, dữ liệu huấn luyện và hiệu suất trong việc chuyển giao khả năng ngôn ngữ sang các nhiệm vụ mã lệnh. Một số mô hình đã được giới thiệu, thể hiện hiệu suất tổng hợp và điền/hoàn thành chương trình được cải thiện, bằng cách trải qua tiền huấn luyện liên tục trên dữ liệu mã lệnh mở rộng (Feng et al., 2020; Wang et al., 2021; Chen et al., 2021; Rozière et al., 2023). Tuy nhiên, sự tập trung mạnh mẽ của họ vào mã lệnh thường dẫn đến sự thỏa hiệp về khả năng ngôn ngữ tự nhiên. Lemur giải quyết điều này bằng cách tăng cường vừa phải một mô hình lớn với hỗn hợp cân bằng dữ liệu mã lệnh và ngôn ngữ tự nhiên, duy trì sự thành thạo trong cả hai lĩnh vực.

Tinh chỉnh Hướng dẫn Quá trình điều chỉnh LLMs để tuân theo hướng dẫn, thường được gọi là tinh chỉnh hướng dẫn, chủ yếu được hướng tới các nhiệm vụ NLP (Wei et al., 2021; Wang et al., 2022b). Các nghiên cứu gần đây đã tìm cách mở rộng các trường hợp sử dụng của tinh chỉnh hướng dẫn để bao gồm nhiều loại nhiệm vụ chung hơn (Ouyang et al., 2022). Phương pháp tự hướng dẫn tạo ra các hướng dẫn bằng cách sử dụng các hướng dẫn ban đầu, hỗ trợ việc hiểu cách thích ứng các mô hình ngôn ngữ bằng cách tinh chỉnh chúng trên các hướng dẫn thu được từ ChatGPT (Wang et al., 2022a; Zheng et al., 2023; Xu et al., 2023b; Mukherjee et al., 2023). Chúng tôi áp dụng cách tiếp cận tương tự trong việc tinh chỉnh mô hình của chúng tôi để tuân theo hướng dẫn.

Tác nhân Ngôn ngữ Các tác nhân ngôn ngữ thành thạo tuân theo hướng dẫn của người dùng và tương tác với môi trường để thực thi nhiệm vụ. Xu hướng gần đây trong nghiên cứu và cộng đồng mã nguồn mở đã sử dụng Mô hình Ngôn ngữ Lớn (LLMs) (Brown et al., 2020; Chen et al., 2021; Chowdhery et al., 2022; OpenAI, 2023) làm bộ điều khiển chính cho các tác nhân này (Yao et al., 2022b; Chase, 2022; Gravitas, 2023; Shinn et al., 2023; Wang et al., 2023a; Xu et al., 2023a; Lin et al., 2023; Yao et al., 2023). Điều này được thúc đẩy bởi các khả năng đã được chứng minh của LLMs trong lý luận, lập kế hoạch, tích hợp và tạo mã lệnh (Wei et al., 2022; Huang et al., 2022a; Ichter et al., 2022; Xie et al., 2023), quan trọng để hiểu hướng dẫn của người dùng, nắm bắt bối cảnh môi trường và tạo ra các hành động thực thi được. Lemur tích hợp một cách mượt mà các khả năng trong cả văn bản và mã lệnh, cho phép tạo ra các hành động thực thi được tích hợp môi trường cần thiết để xây dựng các tác nhân ngôn ngữ.

Benchmark Đánh giá Tác nhân Sự tiến hóa nhanh chóng của các tác nhân ngôn ngữ đòi hỏi đánh giá chính xác và toàn diện về các tác nhân. Các công trình gần đây đặt ra những chiều kích mới đưa các tác nhân ngôn ngữ vào môi trường web (Deng et al., 2023; Yao et al., 2022a; Zhou et al., 2023), môi trường mã lệnh tương tác (Yang et al., 2023), trò chơi kỹ thuật số (Fan et al., 2022), và hộ gia đình (Puig et al., 2018; Shridhar et al., 2020a;b) để hoàn thành nhiệm vụ nhất định dưới hướng dẫn ngôn ngữ tự nhiên. Ngoài việc thu thập các nhiệm vụ mới, các benchmark tác nhân này có thể được thiết lập bằng cách tái sử dụng và chuyển đổi các bộ dữ liệu hiện có thành bộ dữ liệu tác nhân (Wang et al., 2023b; Yang et al., 2023; Liu et al., 2023). Nghiên cứu của chúng tôi kết hợp các nhiệm vụ này, tiến hành đánh giá mở rộng và đánh giá khả năng của mô hình xây dựng một tác nhân ngôn ngữ từ nhiều chiều kích.

6 KẾT LUẬN

Tóm lại, nghiên cứu này nhấn mạnh vai trò then chốt của việc hài hòa khả năng thành thạo ngôn ngữ tự nhiên và lập trình trong sự tiến hóa của các mô hình ngôn ngữ thành các tác nhân ngôn ngữ tinh vi. Bằng cách phát triển Lemur và Lemur-Chat, chúng tôi đã chứng minh rằng sự kết hợp tỉ mỉ của những năng lực này cho phép hiệu suất nâng cao trong các môi trường và ứng dụng đa dạng, thu hẹp khoảng cách khả năng hiện tại giữa các mô hình mã nguồn mở và độc quyền. Chúng tôi đã mã nguồn mở cả hai mô hình, với ý định thúc đẩy nghiên cứu thêm trong lĩnh vực mô hình ngôn ngữ cho các tác nhân.

7 LỜI CẢM ƠN

Dự án này là một sự hợp tác nghiên cứu mở giữa XLang Lab của HKU và Salesforce Research. Chúng tôi chân thành cảm ơn các khoản tài trợ nghiên cứu hào phóng nhận được từ cả Google Research và Amazon AWS. Lời cảm ơn đặc biệt dành cho chương trình Google TPU Research Cloud vì đã cung cấp các tài nguyên tính toán quan trọng. Nghiên cứu của chúng tôi được hưởng lợi rất nhiều từ các cuộc thảo luận sâu sắc với các cộng tác viên đáng kính: Pengcheng Yin, Yaqing Wang và You Wu từ Google Research; Peng Shi và Shuaichen Chang từ AWS AI; Yizhong Wang từ Đại học Washington; Xinyang Geng từ UC Berkeley; Ansong Ni từ Đại học Yale; Chen Henry Wu từ Đại học Carnegie Mellon; Zeyu Liu từ Đại học Texas tại Austin; Lin Zheng và Jiacheng Ye từ Đại học Hồng Kông.

TÀI LIỆU THAM KHẢO
[Phần tài liệu tham khảo được bảo lưu như bản gốc do tính chất học thuật]

# 2312.05180.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/planning/2312.05180.pdf
# Kích thước tệp: 536304 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
PATHFINDER : Tìm kiếm có hướng dẫn trên các đường dẫn lý luận đa bước
Olga Golovneva∗, Sean O'Brien, Ramakanth Pasunuru, Tianlu Wang,
Luke Zettlemoyer, Maryam Fazel-Zarandi, Asli Celikyilmaz
FAIR tại Meta
Tóm tắt
Với những tiến bộ gần đây trong các mô hình ngôn ngữ lớn, các phương pháp như gợi ý chuỗi tư duy để kích hoạt chuỗi lý luận đã được chứng minh là cải thiện kết quả trên các nhiệm vụ lý luận. Tuy nhiên, các nhiệm vụ yêu cầu nhiều bước lý luận vẫn đặt ra những thách thức đáng kể cho các mô hình tiên tiến nhất. Lấy cảm hứng từ thuật toán tìm kiếm chùm, chúng tôi đề xuất PATHFINDER, một phương pháp tạo đường dẫn lý luận dựa trên tìm kiếm cây. Nó tăng cường phân nhánh đa dạng và lý luận đa bước thông qua việc tích hợp giải mã động, được kích hoạt bởi các phương pháp và tham số lấy mẫu khác nhau. Sử dụng lý luận có ràng buộc, PATHFINDER tích hợp các ràng buộc chất lượng mới, cắt tỉa và phương pháp khám phá để tăng cường hiệu quả và chất lượng tạo sinh. Hơn nữa, nó bao gồm các tính năng chấm điểm và xếp hạng để cải thiện việc lựa chọn ứng viên. Phương pháp của chúng tôi vượt trội so với các đường cơ sở cạnh tranh trên ba nhiệm vụ lý luận số học và thường thức phức tạp trung bình 6%. Mô hình của chúng tôi tổng quát hóa tốt cho các chuỗi lý luận dài hơn, chưa thấy, phản ánh sự phức tạp tương tự như tìm kiếm chùm với các yếu tố phân nhánh lớn.

1 Giới thiệu
Tiến bộ gần đây trong các mô hình ngôn ngữ lớn (LLM) đã dẫn đến một kỷ nguyên mới trong lý luận máy, đặc biệt thông qua việc sử dụng các phương pháp gợi ý. Những phương pháp này, như chuỗi tư duy (CoT) Wei et al. (2022), bảng nháp Nye et al. (2021), từ ít đến nhiều Zhou et al. (2023), và các mô hình ngôn ngữ hỗ trợ chương trình (PAL) Gao et al. (2023), thường phân chia các nhiệm vụ phức tạp thành các chuỗi lý luận và đã được chứng minh là cải thiện hiệu suất mô hình trên các nhiệm vụ như lý luận logic Clark et al. (2020), số học Cobbe et al. (2021) và thường thức Talmor et al. (2021).

Khi các nhiệm vụ yêu cầu nhiều bước lý luận trở nên phức tạp hơn, LLM bắt đầu gặp khó khăn với việc tích lũy lỗi qua nhiều bước lý luận. Thậm chí thách thức hơn là đảm bảo rằng mỗi bước trong chuỗi được đánh giá chính xác và đóng góp tích cực vào chuỗi lý luận tổng thể và độ chính xác của giải pháp. Để giải quyết những vấn đề này, các nghiên cứu gần đây đã triển khai các phương pháp như tự nhất quán cho bỏ phiếu đa số Wang et al. (2023), đa dạng hóa gợi ý Li et al. (2023) và chương trình Python để tạo lý luận chính xác hơn Gao et al. (2023). Bất chấp những cải thiện này, quá trình tạo chuỗi lý luận như một quá trình tự hồi quy tiêu chuẩn vẫn đối mặt với thách thức do không gian tìm kiếm lớn, đánh giá và hướng dẫn không tối ưu cho quá trình lý luận, đặc biệt trong các nhiệm vụ phức tạp, đa bước.

Trong nghiên cứu này, chúng tôi giới thiệu PATHFINDER, một phương pháp giải mã được thiết kế để tạo sinh và tinh chỉnh các chuỗi lý luận được tạo bởi LLM. PATHFINDER thể hiện cách tiếp cận của chúng tôi trong việc chia giải mã lý luận thành hai nhiệm vụ riêng biệt: tạo ứng viên và lựa chọn ứng viên. Đối với quá trình tạo ứng viên, PATHFINDER sử dụng phương pháp dựa trên tìm kiếm cây. Nó tích hợp một tập hợp các ràng buộc để cải thiện chất lượng của các ứng viên lý luận được tạo, cùng với một chức năng cắt tỉa

∗tác giả liên hệ tại olggol@meta.com
R0-FoMo: Workshop on Robustness of Few-shot and Zero-shot Learning in Foundation Models at NeurIPS 2023.arXiv:2312.05180v2  [cs.CL]  12 Dec 2023

--- TRANG 2 ---
Câu hỏi: Reiki có thể được lưu trữ trong chai không?
Reiki là một hình thức chữa lành năng lượng. Reiki là một hình thức năng lượng. -0.0034
Reiki là một kỹ thuật chữa lành của Nhật Bản. -0.0050
Nhánh bị cắt tỉa
Câu trả lời đúng
Câu trả lời sai Năng lượng không thể được lưu trữ.
Câu trả lời là không Reiki không phải là
chất lỏng. Thực hành này không phải là
vật thể vật lý
Câu trả lời là có
Tự nhất quán : 2
Điểm n-gram :  28
Điểm độ tương tự cosine : 1.44
Điểm BERT : 1.93
Điểm BLEURT : -0.03
Điểm thông tin : 0.60
Trình xác minh Flan-T5-XL: 0.95
Trình xác minh Flan-T5-XXL: 0.99Tự nhất quán : 1
Điểm n-gram :  22
Điểm độ tương tự cosine : 1.49
Điểm BERT : 1.91
Điểm BLEURT : -0.54
Điểm thông tin : 0.48
Trình xác minh Flan-T5-XL: 0.61
Trình xác minh Flan-T5-XXL: 0.42Điểm tự nhất quán : 2
Điểm n-gram :  20
Điểm độ tương tự cosine : 1.52
Điểm BERT : 1.91
Điểm BLEURT : -0.76
Điểm thông tin : 0.39
Trình xác minh Flan-T5-XL: 0.69
Trình xác minh Flan-T5-XXL: 0.98Người Nhật không
sử dụng chai.
Reiki là một thực hành tâm linh, và
do đó, nó không thể được lưu trữ trong
chai. Người Nhật có lịch sử lâu dài
sử dụng lọ để lưu trữ đồ vật.
-0.0186 -0.0180 -0.0099
-0.0022
Năng lượng có thể được lưu trữ trong pin. -0.0028-0.0048
-0.0044
Năng lượng không thể được lưu trữ. -0.0147
Do đó, Reiki không thể được lưu trữ trong chai. -0.0016
-0.0-0.0
Câu trả lời là không Do đó, Reiki có thể được lưu trữ trong pin.
-0.0-0.0051
-0.0014Hình 1: PATHFINDER tận dụng giải mã có ràng buộc chung cấp độ bước để hướng dẫn việc tạo lý luận từng bước. Trong ví dụ này từ tập dữ liệu StrategyQA, mặc dù các bước lý luận gần nhau về n-gram, PATHFINDER cắt tỉa các nhánh ít khả năng hơn và chọn những nhánh thông tin hơn để giải thích câu hỏi. Yếu tố phân nhánh=3, kích thước bộ đệm=3. Các số trong hình chữ nhật màu tím là điểm số được tạo bởi hàm cắt tỉa được điều chỉnh bởi Phương trình 2 sử dụng giải mã bước tham lam ( τ− →0). Điểm số cao nhất được tạo cho mỗi nhánh không bị cắt tỉa được gạch chân. Chi tiết về các điểm số lựa chọn ứng viên khác nhau tại lá của mỗi đường dẫn lý luận được cung cấp trong Phần 4.

chức năng để tính toán hiệu quả và loại bỏ các ứng viên kém như được hiển thị trong Hình 1. Mô hình của chúng tôi cũng kết hợp một yếu tố khám phá để đảm bảo sự đa dạng của việc tạo lý luận. Đối với quá trình lựa chọn ứng viên, PATHFINDER sử dụng một tập hợp các hàm dựa trên độ tương tự mới mà chúng tôi đánh giá so với các trình xác minh dựa trên LLM hiện có. Quá trình lựa chọn này cho phép lựa chọn các chuỗi lý luận chính xác hơn từ nhóm ứng viên, từ đó tinh chỉnh chất lượng lý luận tổng thể. Chúng tôi tiến hành các thí nghiệm mở rộng trên bốn nhiệm vụ tạo sinh yêu cầu lý luận đa bước. Sử dụng LLAMA-7B kích thước nhỏ (Touvron et al., 2023) làm mô hình ngôn ngữ nền tảng, PATHFINDER thể hiện những cải thiện hiệu suất đáng kể trên tất cả các nhiệm vụ, làm nổi bật hiệu quả của nó trong việc cải thiện khả năng lý luận của các mô hình ngôn ngữ. Chúng tôi thảo luận về nghiên cứu liên quan chi tiết hơn trong Phụ lục C.

Tóm lại, chúng tôi phát triển PATHFINDER, một phương pháp giải mã mới để tạo sinh hiệu quả các dấu vết lý luận. Thuật toán của chúng tôi rất linh hoạt, vì nó có thể được áp dụng cho nhiều nhiệm vụ tạo sinh lý luận đa bước thông qua các ràng buộc thời gian giải mã, giảm nhu cầu điều chỉnh trên dữ liệu có nhãn đắt đỏ. Các thí nghiệm mở rộng của chúng tôi chứng minh hiệu quả của nó trên một số nhiệm vụ phức tạp.

2 PATHFINDER : Bộ giải mã lý luận
Chúng tôi mô tả PATHFINDER, một phương pháp tạo đường dẫn lý luận dựa trên tìm kiếm cây. Trước tiên chúng tôi giới thiệu bài toán giải mã và sau đó mô tả phương pháp của chúng tôi kết hợp quá trình giải mã hai bước: tạo ứng viên và lựa chọn.

Giải mã. Tạo sinh chuỗi là một nhiệm vụ tạo chuỗi đầu ra y (ví dụ, đường dẫn lý luận) cho chuỗi đầu vào x (ví dụ, câu hỏi, gợi ý, v.v.). Trong lý luận đa bước từ LLM, một chuỗi lý luận tuần tự bao gồm T bước được tạo qua nhiều bước thời gian. Chúng tôi ký hiệu một chuỗi lý luận là y=y1:T=[y1, y2,···, yT], trong đó mỗi yt biểu thị một bước lý luận của chuỗi các token riêng biệt. Một chuỗi lý luận được tạo tự hồi quy và việc giải mã bao gồm việc giải quyết:
y∗= arg max
y∈YlogP(y|x) (1)
trong đó Y={y1, ...,yK} là tập hợp tất cả các đường dẫn lý luận được tạo để phản hồi đầu vào x sử dụng mô hình tạo sinh P(y|x).

Tạo ứng viên. Tại cốt lõi của PATHFINDER là một thuật toán tìm kiếm cây để tạo sinh dạng dài lý luận, tạo ra nhiều đường dẫn tạo sinh hợp lý. Không giống như các phương pháp tìm kiếm chùm dựa trên token Holtzman et al. (2020), việc phân nhánh trong phương pháp của chúng tôi xảy ra ở cấp độ bước lý luận thay vì các token riêng lẻ. Điều này có nghĩa là mỗi bước lý luận được coi như một nút rời rạc (xem Hình 1). Việc phân nhánh bị ảnh hưởng bởi sự thay đổi giữa một số cố định các tham số lấy mẫu (ví dụ, top-k, top-p, nhiệt độ), cho phép PATHFINDER khám phá các phương pháp giải mã khác nhau và kích hoạt tìm kiếm trên các chiến lược giải mã khác nhau tại mỗi bước thời gian. Thuộc tính giải mã động này tạo điều kiện cho lý luận đa bước, dẫn đến các nhánh đa dạng.

Để cân bằng chất lượng với tính toán, chúng tôi rút ra một số ứng viên từ mỗi lá không bị cắt tỉa trong cây lý luận làm yếu tố phân nhánh của chúng tôi tại mọi giai đoạn của quá trình. Chúng tôi tiếp tục lấy mẫu cho đến khi tất cả các lá đã đạt đến điểm kết thúc hoặc đã đạt được độ sâu tối đa được xác định trước.

Để tránh tạo sinh quá mức các nhánh bước lý luận, chúng tôi cũng giới thiệu kích thước bộ đệm b, giới hạn số lượng giả thuyết được lưu trữ cho mỗi ngữ cảnh, và triển khai các phương pháp cắt tỉa. Cụ thể, đối với mỗi bước lý luận giả thuyết yt=[y1t,···, yNt], trong đó yit là token thứ i trong chuỗi có độ dài N, được tạo để phản hồi gợi ý x, chúng tôi cắt tỉa các nhánh dựa trên điểm số chuỗi, được chuẩn hóa theo số token:

π(yt) =X
ilogpθ(yit|x, yi<t)/Nλ(2)

trong đó λ∈R là tham số phạt độ dài đặc trưng mô hình, và pθ là mô hình tạo token.

Ngoài ra, tương tự như Xie et al. (2023), chúng tôi giới thiệu nhiệt độ lấy mẫu bước τ với yếu tố ủ α được sử dụng để giảm nhiệt độ từng bước theo τ− →ατ để thêm biến thể có kiểm soát trong các nhánh, và lấy mẫu theo phân phối:

p(yt)∝exp(π(yt)/τ) (3)

Ràng buộc tạo ứng viên. Chúng tôi áp đặt các ràng buộc bổ sung trên các bước lý luận để giảm ảo giác. Cụ thể, chúng tôi buộc mô hình phải tạo lại một bước lý luận nếu một trong các điều kiện sau được thỏa mãn: (1) Ràng buộc lặp lại: bước được tạo tương tự như một trong các bước được tạo trước đó hoặc lặp lại ngữ cảnh như được xác định bởi chỉ số độ tương tự cosine. Độ tương tự cosine được tính bằng mô hình nhúng câu all-mpnet-base-v2 HuggingFace, và chúng tôi buộc mô hình phải tạo lại nếu giá trị độ tương tự lớn hơn 0.9; (2) Ràng buộc mâu thuẫn: bước được tạo mâu thuẫn với ngữ cảnh (tức là câu hỏi và các bước trước đó) như được xác định bởi một mô hình kéo theo. Cụ thể, chúng tôi sử dụng mô hình được đề xuất bởi Laurer et al. (2022) để phân loại bước thành một trong ba lớp: kéo theo, trung lập và mâu thuẫn, và buộc mô hình phải tạo lại nếu nó thuộc lớp mâu thuẫn như được xác định bởi mô hình kéo theo. Nếu không có bước mới nào được tạo sau n= 2 lần thử, nhánh sẽ bị cắt tỉa.

Lựa chọn ứng viên. Để chọn một giả thuyết cuối cùng từ một nhóm ứng viên, chúng tôi thử nghiệm với một số hàm chấm điểm có dạng:

y∗= arg max
yj∈YX
yk∈Y,yk̸=yjS(yj,yk) (4)

trong đó số lượng chuỗi lý luận ứng viên trong nhóm Y được giới hạn bởi kích thước bộ đệm ( K≤b), và S là một hàm độ tương tự. Trực giác tương tự như tự nhất quán (Wang et al., 2022) hoặc trí tuệ của đám đông (Suzgun et al., 2022), trong giả định rằng một giải pháp theo từ đa số các chuỗi lý luận đa dạng, được tạo có nhiều khả năng là đúng hơn. Trên thực tế, kết quả của chúng tôi hỗ trợ việc sử dụng một chỉ số độ tương tự dựa trên N-gram. Cụ thể, nếu gj là một tập hợp n-gram cho giả thuyết yj, hàm độ tương tự N-gram được định nghĩa là số n-gram chung như sau:

S(yj,yk) =|gj∩gk| (5)

Lựa chọn ứng viên là một thành phần quan trọng của PATHFINDER. Các kỹ thuật phổ biến là sử dụng các hàm chấm điểm và mô hình xác minh. Các hàm chấm điểm Suzgun et al. (2022); Prasad et al. (2023) giúp xếp hạng tập hợp cố định các thế hệ ứng viên và hướng dẫn việc lựa chọn dự đoán cuối cùng dựa trên một số thuộc tính của văn bản được tạo, như độ tương tự. Mặt khác, các mô hình xác minh Li et al. (2023) sử dụng các mô hình bên ngoài để đánh giá rõ ràng tính đúng đắn của giả thuyết được tạo, và xếp hạng các thế hệ dựa trên điểm trung thực. Chúng tôi xác thực PATHFINDER so với các mô hình xác minh và các bộ chấm điểm dựa trên độ tương tự khác nhau trong các nghiên cứu loại bỏ của chúng tôi trong Phần 4. Chúng tôi lưu ý rằng việc sử dụng một hàm chấm điểm phù hợp được ưu tiên hơn một mô hình xác minh vì nó sẽ cải thiện thời gian chạy và giảm tải bộ nhớ.

--- TRANG 3 ---
Mô hình GSM8K StrategyQA CSQA
GPT-6.7B 2.4 50.0 24.0
MINERVA -8B 16.2 - -
LLAMA -7B 11.0 61.1* 43.3*
LLAMA -7B (tự nhất quán) 15.3* 64.8* 46.9*
FLAN-T5-XL (3B) 13.5 73.4* 85.4*
PATHFINDER (LLAMA-7B, N-gram) 11.3 59.0 50.0
PATHFINDER (LLAMA-7B, FLAN-T5-XL) 11.7 60.8 55.1
PATHFINDER (LLAMA-7B, TEXT-DAVINCI-003) 15.4 61.7 56.3

Bảng 1: Hiệu suất của các mô hình khác nhau trên bốn tập dữ liệu đánh giá lý luận được đo bằng độ chính xác. Các số tốt nhất được in đậm giữa các mô hình và các số tốt thứ hai được gạch chân. Các số có dấu hoa thị* là từ các đánh giá của chúng tôi sử dụng giải mã tham lam và gợi ý CoT được cung cấp trong Phụ lục D. Đối với điểm số tự nhất quán, chúng tôi biên hóa câu trả lời qua 16 chuỗi lý luận được lấy mẫu với nhiệt độ T= 1.0, top-k (k= 40) và top-p (p= 0.5). Chúng tôi lưu ý rằng FLAN-T5 được tinh chỉnh trên dữ liệu từ cả tập dữ liệu CSQA và GSM8K và do đó sẽ có hiệu suất hơi thổi phồng so với các mô hình có kích thước tương đương không được huấn luyện trên các nhiệm vụ này.

3 Thí nghiệm: Tạo sinh lý luận
Tập dữ liệu. Chúng tôi tiến hành thí nghiệm trên các tập dữ liệu đánh giá khác nhau yêu cầu kỹ năng lý luận phức tạp để đạt được câu trả lời cuối cùng: (1) GSM8K (Cobbe et al., 2021), một tập dữ liệu lý luận số học gồm 8.5K bài toán từ ngữ toán học tiểu học đa dạng về ngôn ngữ; (2) STRATEGYQA (Geva et al., 2021), một tập dữ liệu lý luận thường thức gồm 2,780 câu hỏi, được chú thích với phân tích và bằng chứng từng bước của chúng; (3) CSQA (Talmor et al., 2018), một tập dữ liệu lý luận thường thức trắc nghiệm gồm 12,102 câu hỏi với một câu trả lời đúng và bốn câu trả lời nhiễu.

LLM nền tảng cho PATHFINDER. Chúng tôi chọn hai mô hình mã nguồn mở được sử dụng rộng rãi để tạo sinh và đánh giá chuỗi lý luận: LLAMA-7B (Touvron et al., 2023) và FLAN-T5-XL (3B) (Chung et al., 2022). Chúng tôi gợi ý mô hình LLAMA-7B với các ví dụ chuỗi tư duy (Wei et al., 2022) để tạo các bước lý luận cùng với câu trả lời cuối cùng. Chúng tôi cung cấp các giá trị tham số cụ thể và chuỗi gợi ý trong Phụ lục D. Chúng tôi cũng thử nghiệm với các phương pháp khác nhau cho việc lựa chọn ứng viên. Cụ thể, chúng tôi báo cáo kết quả sử dụng các thiết lập sau: (1) PATHFINDER (LLAMA-7B, N-gram): sử dụng mô hình LLAMA-7B để tạo văn bản, và độ tương tự tri-gram cho việc lựa chọn ứng viên; (2) PATHFINDER (LLAMA-7B, FLAN-T5-XL): sử dụng mô hình LLAMA-7B để tạo văn bản, và mô hình xác minh FLAN-T5-XL cho việc lựa chọn ứng viên; (3) PATHFINDER (LLAMA-7B, TEXT-DAVINCI-003) sử dụng mô hình LLaMa-7B để tạo văn bản, và mô hình xác minh TEXT-DAVINCI-003 từ họ mô hình GPT-3.5 cho việc lựa chọn ứng viên.

Đường cơ sở. Chúng tôi đánh giá phương pháp của chúng tôi so với các mô hình tốt nhất hàng đầu với kết quả được báo cáo trong tài liệu, đảm bảo kích thước mô hình có thể so sánh được để đánh giá công bằng². Cụ thể, chúng tôi so sánh với GPT-6.7B Wei et al. (2022), LLAMA-7B (Touvron et al., 2023), FLAN-T5-XL (3B) (Fu et al., 2023), và Minerva-8B Lewkowycz et al. (2022). Kết quả được báo cáo đại diện cho kết quả đánh giá trên các thế hệ được tạo với gợi ý CoT và giải mã tham lam cấp token. Chúng tôi cũng bao gồm các đánh giá của riêng chúng tôi trên một số nhiệm vụ mà theo hiểu biết tốt nhất của chúng tôi bị thiếu trong tài liệu sử dụng giải mã tham lam và gợi ý được cung cấp trong Phụ lục D.

Kết quả. Bảng 1 so sánh các LLM khác nhau với các phương pháp giải mã khác nhau hiển thị độ chính xác câu trả lời là chỉ số đánh giá. PATHFINDER cải thiện hiệu suất đường cơ sở trên tất cả các nhiệm vụ lý luận được chọn trung bình 6%, nhưng kém hơn mô hình cơ sở với tự nhất quán được áp dụng trên tập dữ liệu STRATEGYQA 3%. Ngay cả chỉ số độ tương tự N-gram đơn giản cũng cho phép chọn các đường dẫn tốt hơn dẫn đến cải thiện mô hình so với đường cơ sở trên các tập dữ liệu GSM8K và CSQA. Chúng tôi lưu ý rằng trình xác minh FLAN-T5-XL cải thiện hiệu suất đáng kể trên nhiệm vụ CSQA, nhưng không nhiều trên các nhiệm vụ khác. Điều này có thể do thực tế là nó được huấn luyện trên nhiệm vụ này, trong khi các nhiệm vụ khác khó đánh giá hơn đáng kể (GSM8K), hoặc không quen thuộc với mô hình (STRATEGYQA). Trong khi trình xác minh TEXT-DAVINCI-003 tổng thể cho thấy hiệu suất tốt hơn, có sự đánh đổi giữa lượng tài nguyên cần thiết để chạy đánh giá dựa trên GPT3.5 và cải thiện hiệu suất mà nó có thể mang lại; Hình 1 hiển thị một ví dụ về cây được tạo cho một trong các câu hỏi STRATEGYQA. Nó thể hiện cách PATHFINDER mặc dù các bước lý luận gần nhau về N-gram, PATHFINDER cắt tỉa các nhánh ít khả năng hơn và chọn những nhánh thông tin hơn để giải thích câu hỏi. Cuối cùng, bộ chấm điểm N-gram chọn câu trả lời đúng bằng cách chọn nhánh có độ tương tự n-gram cao hơn với các nhánh khác.

4 Nghiên cứu loại bỏ
Các chiến lược lựa chọn ứng viên khác nhau ảnh hưởng như thế nào đến hiệu suất tổng thể? Trong phần này, chúng tôi đánh giá mô hình của chúng tôi bằng cách sử dụng các hàm chấm điểm và mô hình xác minh khác nhau, xếp hạng một tập hợp cố định ứng viên và chọn ứng viên có điểm cao nhất làm dự đoán cuối cùng. Chúng tôi trình bày độ chính xác giới hạn trên, là độ chính xác của bộ chấm điểm "hoàn hảo" sẽ chọn câu trả lời cuối cùng đúng nếu có trong nhóm ứng viên, và đối chiếu bộ chấm điểm dựa trên N-gram với một số phương pháp thay thế: Bộ chấm điểm Tự nhất quán, Bộ chấm điểm Độ tương tự Cosine, Bộ chấm điểm BERT và BLEURT, Bộ chấm điểm Thông tin và Mô hình Xác minh. Chúng tôi cung cấp chi tiết hơn về xây dựng hàm chấm điểm và phương pháp xếp hạng trong Phụ lục D và Phụ lục E. Chúng tôi tóm tắt kết quả trong Hình 2. Tất cả các bộ chấm điểm đều vượt trội so với lựa chọn ngẫu nhiên, với TEXT-DAVINCI-003 dẫn đến điểm độ chính xác cao nhất là 58.1. Đồng thời chúng tôi muốn nhấn mạnh khoảng cách giữa độ chính xác giới hạn trên và độ chính xác cuối cùng khi một hàm chấm điểm hoặc mô hình xác minh được sử dụng để xếp hạng và chọn giả thuyết tốt nhất, điều này rõ ràng cho thấy rằng việc lựa chọn đúng chiến lược lựa chọn ứng viên có thể tăng hiệu suất đáng kể hơn nữa.

Yếu tố phân nhánh ảnh hưởng như thế nào đến hiệu suất? Yếu tố phân nhánh cây cùng với hàm cắt tỉa ảnh hưởng đáng kể đến sự đa dạng của ứng viên. Theo trực giác, tạo ra nhiều ứng viên hơn tăng khả năng tạo ra ít nhất một thế hệ đúng. Tuy nhiên, vì các mô hình chấm điểm của chúng tôi không hoàn hảo, một khối lượng lớn ứng viên nhiễu có thể làm chúng bối rối và leo thang tỷ lệ dương tính giả. Chúng tôi đánh giá hiệu suất bộ chấm điểm N-gram để hiểu độ nhạy của bộ chấm điểm với tiếng ồn. Hình 3 chỉ ra một yếu tố phân nhánh tối ưu cho mỗi kích thước bộ đệm, điều này hỗ trợ giả thuyết của chúng tôi về độ nhạy của hàm chấm điểm với mức độ tiếng ồn. Do đó, đối với việc giải mã cấp bước dựa trên tìm kiếm cây, quan trọng là tìm một giá trị tối ưu của yếu tố phân nhánh để cân bằng giữa sự đa dạng của ứng viên và lượng tiếng ồn. Hiện tượng tương tự đã được quan sát trước đó cho việc giải mã cấp token tìm kiếm chùm, nơi tăng số lượng ứng viên giải mã vượt quá một điểm nhất định dẫn đến chất lượng tạo sinh tệ hơn (Yang et al., 2018; Koehn and Knowles, 2017).

Kích thước bộ đệm tăng có luôn cải thiện hiệu suất không? Để trả lời câu hỏi này, chúng tôi điều tra thực nghiệm hiệu suất bộ chấm điểm N-gram. Kết quả được tóm tắt trong Hình 3 tiết lộ rằng đối với các yếu tố phân nhánh nhỏ được xem xét trong nghiên cứu này, điểm độ chính xác ổn định. Vượt quá một điểm nhất định, tăng kích thước bộ đệm không mang lại nhiều thế hệ hơn vì chúng bị giới hạn bởi yếu tố phân nhánh và ràng buộc tạo sinh. Thực tế, đối với các thí nghiệm CSQA được hiển thị trong Hình 3, ở yếu tố phân nhánh 8, số lượng ứng viên giả thuyết trung bình hầu như không thay đổi sau kích thước bộ đệm 32, và là khoảng 22. Điểm ổn định dịch chuyển cao hơn với sự tăng số lượng thế hệ trên mỗi nút. Trong suốt các thí nghiệm của chúng tôi, chúng tôi quan sát thấy sự cải thiện nhất quán trong hiệu suất tối ưu

--- TRANG 4 ---
Hình 2: Tác động của các hàm chấm điểm dựa trên độ tương tự khác nhau và mô hình xác minh (trục dọc) lên điểm độ chính xác (trục ngang) của PATHFINDER, sử dụng LLAMA-7B làm LLM nền tảng, trên các tập dữ liệu CSQA và GSM8K. Chúng tôi sử dụng kích thước bộ đệm 128 với yếu tố phân nhánh 8 cho CSQA, và kích thước bộ đệm 16 với yếu tố phân nhánh 4 cho tập dữ liệu GSM8K. Các hàm chấm điểm chấm điểm và xếp hạng giả thuyết dựa trên chỉ số độ tương tự, trong khi mô hình xác minh xếp hạng giả thuyết dựa trên điểm trung thực được tạo.

với kích thước bộ đệm tăng. Tuy nhiên, các quan sát của chúng tôi bị giới hạn bởi tài nguyên tính toán có sẵn, cho thấy rằng hành vi có thể khác biệt đối với các yếu tố phân nhánh cực đoan.

Chúng ta có thực sự cần cây không? Trong Hình 3, cùng với kết quả dựa trên tìm kiếm cây, chúng tôi cũng báo cáo hiệu suất tạo sinh đầu cuối đến cuối, tức là tại giai đoạn tạo ứng viên, thay vì tạo một cây, chúng tôi gợi ý mô hình tạo một tập hợp chuỗi lý luận, và sau đó áp dụng quá trình lựa chọn ứng viên của chúng tôi. Chúng tôi quan sát thấy rằng sự đa dạng đầy đủ trong các bước lý luận là cần thiết để phương pháp tạo sinh dựa trên tìm kiếm cây vượt trội so với phương pháp tạo sinh đầu cuối đến cuối. Cụ thể, đối với mô hình LLAMA-7B, phương pháp tạo sinh tìm kiếm cây chỉ vượt trội so với tạo sinh đầu cuối đến cuối ở yếu tố phân nhánh 8 trở lên. Do đó, trong khi tạo sinh tìm kiếm cây có những ưu điểm của nó, hiệu quả của nó so với tạo sinh đầ cuối đến cuối phụ thuộc phần lớn vào sự đa dạng đầy đủ trong các bước lý luận và yếu tố phân nhánh tương đối cao.

Độ phức tạp tính toán Lợi ích thu được từ phương pháp này đi kèm với chi phí tính toán cao. Giả sử một bộ đệm đầy đủ gồm c ứng viên sau một vài bước lý luận, chúng tôi tạo ra cb bước ứng viên mới trước khi lựa chọn và cắt tỉa tại mỗi bước. Nếu chuỗi lý luận ban đầu yêu cầu T token để tạo, PATHFINDER yêu cầu O(bcT) token. Điều này có thể được so sánh với tự nhất quán với k đường dẫn, yêu cầu O(kT) token, nhưng có thể được song song hóa dễ dàng hơn với bộ nhớ chia sẻ trên các thiết bị. Trong thực tế, chúng tôi thấy rằng, trong khi một đường dẫn lý luận đơn giản mất dưới 1 GPU-giờ để tạo (Bảng 2), cần vài GPU-giờ để tạo cây lý luận sẽ vượt trội so với tạo sinh đầu cuối đến cuối cho các nhiệm vụ lý luận phức tạp. Với các hàm cắt tỉa và bộ chấm điểm hiệu quả hơn, chúng tôi sẽ có thể nhận ra lợi ích với ít đường dẫn được lấy mẫu hơn. Vì khung làm việc của chúng tôi không phụ thuộc vào việc lựa chọn một trong hai, chúng tôi dự đoán rằng các mô hình tốt hơn sẽ cho phép yếu tố phân nhánh và kích thước bộ đệm thấp hơn, làm cho phương pháp khả thi hơn về mặt tính toán.

Hình 3: Điểm độ chính xác PATHFINDER (LLAMA-7B, N-gram) trên tập dữ liệu CSQA như một hàm của yếu tố phân nhánh (trái) và kích thước bộ đệm (phải). Trong hình bên phải, chúng tôi cũng bao gồm kết quả nơi chúng tôi sử dụng LLAMA-7B để tạo toàn bộ đường dẫn lý luận cho mỗi ứng viên, và sau đó áp dụng mô hình chấm điểm tri-gram trên số lượng ứng viên được tạo tương ứng với giá trị kích thước bộ đệm (được ký hiệu là tạo sinh đầu cuối đến cuối). Quá trình giải mã nhạy cảm với lượng tiếng ồn, dẫn đến sự tồn tại của yếu tố phân nhánh tối ưu tối đa hóa độ chính xác cuối cùng. Đối với mỗi yếu tố phân nhánh có giới hạn về số lượng nhánh đa dạng tối đa mà mô hình có thể tạo, và tăng kích thước bộ đệm sau điểm này không dẫn đến cây lớn hơn, và chúng tôi quan sát một plateau về điểm độ chính xác.

Yếu tố phân nhánh
Tập dữ liệu Đầu cuối đến cuối 2 4 8 16
GSM8K 0.8 0.5 1.6 5.3 -
StrategyQA 0.2 0.2 0.8 1.6 3.3
CSQA 0.07 0.06 0.2 0.6 1.4

Bảng 2: GPU-giờ trung bình cần thiết cho mô hình LLAMA-7B để tạo một cây lý luận cho các yếu tố phân nhánh br khác nhau. Lô 16 mẫu được sử dụng trong tất cả các tập dữ liệu. Tất cả các số được tính cho kích thước bộ đệm 8, chúng tôi cũng báo cáo GPU-giờ trung bình cho tạo sinh đầu cuối đến cuối và kích thước lấy mẫu 8.

5 Kết luận
Chúng tôi đề xuất PATHFINDER, một phương pháp giải mã mới tối ưu hóa việc tạo chuỗi lý luận trong các mô hình ngôn ngữ lớn. Chúng tôi chứng minh những cải thiện hiệu suất đáng chú ý trên bốn nhiệm vụ lý luận đa bước, nhấn mạnh tính linh hoạt và hiệu quả của nó. Phương pháp của chúng tôi vượt qua những hạn chế truyền thống, tăng cường khả năng lý luận và mở ra cánh cửa cho nghiên cứu trong tương lai.

--- TRANG 5 ---
Tài liệu tham khảo
Peter Anderson, Basura Fernando, Mark Johnson, và Stephen Gould. 2017. Guided open vocabulary image captioning with constrained beam search. Trong Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, trang 936–945, Copenhagen, Đan Mạch. Association for Computational Linguistics.

Emily M. Bender, Timnit Gebru, Angelina McMillan-Major, và Shmargaret Shmitchell. 2021. On the dangers of stochastic parrots: Can language models be too big? FAccT '21, trang 610–623, New York, NY, USA. Association for Computing Machinery.

Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, và Dario Amodei. 2020. Language models are few-shot learners. Trong Advances in Neural Information Processing Systems, tập 33, trang 1877–1901. Curran Associates, Inc.

Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, et al. 2022. Scaling instruction-finetuned language models. arXiv preprint arXiv:2210.11416.

Peter Clark, Oyvind Tafjord, và Kyle Richardson. 2020. Transformers as soft reasoners over language. IJCAI.

Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, et al. 2021. Training verifiers to solve math word problems. arXiv preprint arXiv:2110.14168.

Yao Fu, Litu Ou, Mingyu Chen, Yuhao Wan, Hao Peng, và Tushar Khot. 2023. Chain-of-thought hub: A continuous effort to measure large language models' reasoning performance. arXiv preprint arXiv:2305.17306.

Luyu Gao, Aman Madaan, Shuyan Zhou, Uri Alon, Pengfei Liu, Yiming Yang, Jamie Callan, và Graham Neubig. 2023. Pal: Program-aided language models.

Mor Geva, Daniel Khashabi, Elad Segal, Tushar Khot, Dan Roth, và Jonathan Berant. 2021. Did aristotle use a laptop? a question answering benchmark with implicit reasoning strategies. Transactions of the Association for Computational Linguistics, 9:346–361.

Olga Golovneva, Moya Chen, Spencer Poff, Martin Corredor, Luke Zettlemoyer, Maryam Fazel-Zarandi, và Asli Celikyilmaz. 2022. Roscoe: A suite of metrics for scoring step-by-step reasoning. arXiv preprint arXiv:2212.07919.

Alex Graves. 2012. Sequence transduction with recurrent neural networks.

Shibo Hao, Yi Gu, Haodi Ma, Joshua Jiahua Hong, Zhen Wang, Daisy Zhe Wang, và Zhiting Hu. 2023. Reasoning with language model is planning with world model.

Chris Hokamp và Qun Liu. 2017. Lexically constrained decoding for sequence generation using grid beam search. Trong Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), trang 1535–1546, Vancouver, Canada. Association for Computational Linguistics.

Ari Holtzman, Jan Buys, Maxwell Forbes, và Yejin Choi. 2020. The curious case of neural text degeneration. ICLR.

HuggingFace. sentence-transformers/all-mpnet-base-v2.

Daphne Ippolito, Reno Kriz, João Sedoc, Maria Kustikova, và Chris Callison-Burch. 2019. Comparison of diverse decoding methods from conditional language models. Trong Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, trang 3752–3762.

--- TRANG 6 ---
Dan Jurafsky và James H. Martin. 2009. Speech and language processing: an introduction to natural language processing, computational linguistics, and speech recognition. Pearson Prentice Hall, Upper Saddle River, N.J.

Saurav Kadavath, Tom Conerly, Amanda Askell, Tom Henighan, Dawn Drain, Ethan Perez, Nicholas Schiefer, Zac Hatfield Dodds, Nova DasSarma, Eli Tran-Johnson, et al. 2022. Language models (mostly) know what they know. arXiv preprint arXiv:2207.05221.

Philipp Koehn và Rebecca Knowles. 2017. Six challenges for neural machine translation. Trong Proceedings of the First Workshop on Neural Machine Translation, trang 28–39, Vancouver. Association for Computational Linguistics.

Moritz Laurer, W v Atteveldt, Andreu Casas, và Kasper Welbers. 2022. Less annotating, more classifying–addressing the data scarcity issue of supervised machine learning with deep transfer learning and bert-nli.

Aitor Lewkowycz, Anders Johan Andreassen, David Dohan, Ethan Dyer, Henryk Michalewski, Vinay Venkatesh Ramasesh, Ambrose Slone, Cem Anil, Imanol Schlag, Theo Gutman-Solo, Yuhuai Wu, Behnam Neyshabur, Guy Gur-Ari, và Vedant Misra. 2022. Solving quantitative reasoning problems with language models. Trong Advances in Neural Information Processing Systems.

Yifei Li, Zeqi Lin, Shizhuo Zhang, Qiang Fu, Bei Chen, Jian-Guang Lou, và Weizhu Chen. 2023. Making large language models better reasoners with step-aware verifier.

Ximing Lu, Peter West, Rowan Zellers, Ronan Le Bras, Chandra Bhagavatula, và Yejin Choi. 2021. NeuroLogic decoding: (un)supervised neural text generation with predicate logic constraints. Trong Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, trang 4288–4299, Online. Association for Computational Linguistics.

Kris McGuffie và Alex Newhouse. 2020. The radicalization risks of GPT-3 and advanced neural language models. CoRR.

Clara Meister, Tiago Pimentel, Gian Wiher, và Ryan Cotterell. 2023. Locally typical sampling. ACL.

Ning Miao, Hao Zhou, Lili Mou, Rui Yan, và Lei Li. 2019. Cgmh: Constrained sentence generation by metropolis-hastings sampling. Trong Proceedings of the AAAI Conference on Artificial Intelligence, tập 33, trang 6834–6842.

Maxwell I. Nye, Anders Johan Andreassen, Guy Gur-Ari, Henryk Michalewski, Jacob Austin, David Bieber, David Dohan, Aitor Lewkowycz, Maarten Bosma, David Luan, Charles Sutton, và Augustus Odena. 2021. Show your work: Scratchpads for intermediate computation with language models. CoRR, abs/2112.00114.

Archiki Prasad, Swarnadeep Saha, Xiang Zhou, và Mohit Bansal. 2023. Receval: Evaluating reasoning chains via correctness and informativeness. arXiv preprint arXiv:2304.10703.

Timo Schick, Jane Dwivedi-Yu, Roberto Dessì, Roberta Raileanu, Maria Lomeli, Luke Zettlemoyer, Nicola Cancedda, và Thomas Scialom. 2023. Toolformer: Language models can teach themselves to use tools.

Thibault Sellam, Dipanjan Das, và Ankur Parikh. 2020. BLEURT: Learning robust metrics for text generation. Trong Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, trang 7881–7892, Online. Association for Computational Linguistics.

Kumar Shridhar, Koustuv Sinha, Andrew Cohen, Tianlu Wang, Ping Yu, Ram Pasunuru, Mrinmaya Sachan, Jason Weston, và Asli Celikyilmaz. 2023. The art of llm refinement: Ask, refine, and trust.

Mirac Suzgun, Luke Melas-Kyriazi, và Dan Jurafsky. 2022. Follow the wisdom of the crowd: Effective text generation via minimum bayes risk decoding. arXiv preprint arXiv:2211.07634.

--- TRANG 7 ---
Alon Talmor, Jonathan Herzig, Nicholas Lourie, và Jonathan Berant. 2018. Commonsenseqa: A question answering challenge targeting commonsense knowledge. arXiv preprint arXiv:1811.00937.

Alon Talmor, Ori Yoran, Ronan Le Bras, Chandra Bhagavatula, Yoav Goldberg, Yejin Choi, và Jonathan Berant. 2021. Commonsenseqa 2.0: Exposing the limits of AI through gamification. NeurIPS.

Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, et al. 2023. Llama: Open and efficient foundation language models. arXiv preprint arXiv:2302.13971.

Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sharan Narang, Aakanksha Chowdhery, và Denny Zhou. 2023. Self-consistency improves chain of thought reasoning in language models.

Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, và Denny Zhou. 2022. Self-consistency improves chain of thought reasoning in language models. arXiv preprint arXiv:2203.11171.

Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Ed H. Chi, Quoc Le, và Denny Zhou. 2022. Chain of thought prompting elicits reasoning in large language models. CoRR, abs/2201.11903.

Sean Welleck, Kianté Brantley, Hal Daumé Iii, và Kyunghyun Cho. 2019. Non-monotonic sequential text generation. Trong International Conference on Machine Learning, trang 6716–6726. PMLR.

Yuxi Xie, Kenji Kawaguchi, Yiran Zhao, Xu Zhao, Min-Yen Kan, Junxian He, và Qizhe Xie. 2023. Decomposition enhances reasoning via self-evaluation guided decoding.

Yilin Yang, Liang Huang, và Mingbo Ma. 2018. Breaking the beam search curse: A study of (re-)scoring methods and stopping criteria for neural machine translation. Trong Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, trang 3054–3059, Brussels, Bỉ. Association for Computational Linguistics.

Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q Weinberger, và Yoav Artzi. 2019. Bertscore: Evaluating text generation with bert. arXiv preprint arXiv:1904.09675.

Denny Zhou, Nathanael Schärli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schuurmans, Claire Cui, Olivier Bousquet, Quoc Le, và Ed Chi. 2023. Least-to-most prompting enables complex reasoning in large language models.

A Hạn chế
Nghiên cứu của chúng tôi bị giới hạn bởi số lượng mô hình và nhiệm vụ mà chúng tôi đã sử dụng để hỗ trợ thực nghiệm cho phương pháp được đề xuất. Mặc dù PATHFINDER vượt trội so với các đường cơ sở khác trên các nhiệm vụ được chọn, nó đi kèm với sự gia tăng đáng kể về độ phức tạp tính toán. Để có thể sử dụng hiệu quả việc giải mã cấp bước dựa trên tìm kiếm cây, chúng tôi cần phát triển các kỹ thuật lấy mẫu và chấm điểm hiệu quả hơn sẽ cho phép chúng tôi đạt được kết quả chất lượng cao nhanh hơn và với chi phí tính toán thấp hơn.

B Tuyên bố đạo đức
Phương pháp của chúng tôi, PATHFINDER, cải thiện việc tạo văn bản, đặc biệt tập trung vào việc tạo lý do từng bước từ các mô hình ngôn ngữ lớn. Do đó, nó kế thừa những lợi ích và rủi ro tiềm ẩn liên quan đến các ứng dụng tạo văn bản Brown et al. (2020). Bằng cách áp đặt các ràng buộc logic lên việc tạo văn bản, chúng tôi nhằm tăng cường kiểm soát, tính nhất quán và độ chính xác, đặc biệt trong các nhiệm vụ yêu cầu lý luận từng bước, như lý luận số học. Chúng tôi muốn lưu ý rằng bất kỳ mô hình ngôn ngữ nào, ngay cả dưới các ràng buộc, có thể bị khai thác để tạo ra các câu chuyện thiên vị hoặc xúc phạm McGuffie và Newhouse (2020). Để khám phá sâu về những rủi ro này, chúng tôi hướng dẫn người đọc đến phân tích được trình bày trong (Bender et al., 2021).

--- TRANG 8 ---
C Nghiên cứu liên quan
Chiến lược giải mã cho việc tạo văn bản. Những phương pháp này trình bày sự đánh đổi liên tục giữa chất lượng và sự đa dạng. Các phương pháp xác định truyền thống như giải mã tham lam và tìm kiếm chùm Jurafsky và Martin (2009); Graves (2012) cung cấp kết quả chất lượng cao nhưng có thể thiếu đa dạng và dễ bị thoái hóa. Các phương pháp lấy mẫu dựa trên cắt ngắn như lấy mẫu nhiệt độ, lấy mẫu top-k, lấy mẫu top-p và lấy mẫu điển hình cục bộ đã được sử dụng để cân bằng sự đánh đổi này Holtzman et al. (2020); Meister et al. (2023). Sự ra đời của các LLM tự hồi quy như GPT đã thúc đẩy nhiều nghiên cứu tập trung vào các yếu tố khác nhau như đa dạng Ippolito et al. (2019), trôi chảy Holtzman et al. (2020), và thỏa mãn ràng buộc Anderson et al. (2017); Miao et al. (2019); Welleck et al. (2019); Lu et al. (2021) trong các chiến lược giải mã. Các phương pháp giải mã có ràng buộc đã thấy những cải tiến như tìm kiếm chùm lưới Anderson et al. (2017) và tìm kiếm chùm có ràng buộc Hokamp và Liu (2017) nhằm thỏa mãn các ràng buộc từ vựng trong quá trình tạo sinh. Các nghiên cứu khác như tạo sinh có điều kiện dựa trên lấy mẫu Metropolis-Hastings Miao et al. (2019) và tạo văn bản có ràng buộc dựa trên cây Welleck et al. (2019) tìm cách giải quyết sự không khớp giữa giải mã đơn điệu và thỏa mãn các ràng buộc. Trái ngược với những chiến lược này thường gặp khó khăn với sự cân bằng giữa chất lượng và đa dạng, PATHFINDER tập trung chủ yếu vào các nhiệm vụ lý luận chứ không phải tạo văn bản mở, hoạt động trên các bước lý luận thay vì trên các token riêng lẻ. Bằng cách tách biệt các bước tạo sinh dựa trên tìm kiếm cây và lựa chọn dựa trên độ tương tự, phương pháp của chúng tôi tạo ra các chuỗi lý luận đa dạng và tinh chỉnh chúng để đạt chất lượng tối ưu.

Chiến lược CoT nâng cao và tự nhất quán. Đã được chứng minh rằng tổng hợp từ các CoT đa dạng (tức là, nhiều đường dẫn lý luận cho mỗi vấn đề) có thể nâng cao hiệu quả hiệu suất nhiệm vụ cuối cùng Wei et al. (2022). Các nghiên cứu gần đây như tự nhất quán Wang et al. (2023) và lấy mẫu đám đông Suzgun et al. (2022) tạo ra nhiều đường dẫn lý luận và cố gắng tìm sự đồng thuận giữa các câu trả lời được suy ra. Tự nhất quán đã tăng hiệu suất đáng kể trong lý luận CoT, ngay cả trong các nhiệm vụ mà gợi ý CoT truyền thống có thể gây hại hiệu suất; lấy mẫu đám đông đã cho thấy lợi ích trong các nhiệm vụ không lý luận như tóm tắt. Phương pháp của chúng tôi có điểm tương đồng với những phương pháp này, nhưng khác biệt trong việc sử dụng tìm kiếm cây để tạo ứng viên, hoạt động ở cấp độ bước thay vì trên toàn bộ thế hệ, và sử dụng một hàm độ tương tự mới.

Các phương pháp khác chuyển giao một phần việc giải quyết vấn đề cho các công cụ bên ngoài, như huấn luyện một mô hình sử dụng công cụ như trong Toolformer Schick et al. (2023) hoặc gợi ý một mô hình giải quyết vấn đề với một trình thông dịch mã như trong PAL Gao et al. (2023). Phương pháp của chúng tôi không yêu cầu truy cập vào các công cụ bên ngoài, mặc dù nó không cấm việc sử dụng chúng. Hơn nữa, không giống như Toolformer, phương pháp của chúng tôi không cần huấn luyện.

Nghiên cứu của chúng tôi song song với nghiên cứu của Xie et al., trình bày một tìm kiếm chùm ngẫu nhiên hướng dẫn tự đánh giá cho lý luận đa bước. Phương pháp của họ sử dụng giải mã tìm kiếm chùm được thiết kế riêng cho các bước trung gian và hướng dẫn quá trình tìm kiếm bằng cách kiểm soát lỗi của mỗi bước lý luận để ngăn chặn tích lũy lỗi tiềm ẩn. Một phương pháp khác cho việc lựa chọn và đánh giá bước đã được phát triển gần đây bởi Hao et al. (2023) và Shridhar et al. (2023), dựa vào mô hình thế giới để hỏi, tinh chỉnh và đánh giá các bước được tạo.

D Thiết lập thí nghiệm
Tham số suy luận. Để chạy thí nghiệm với PATHFINDER, chúng tôi đã sử dụng LLAMA-7B. Đối với việc tạo sinh từng bước, chúng tôi áp dụng lấy mẫu token nhiệt độ với T= 1.0, với cắt ngắn top-k (k= 40) và top-p (p= 0.5) bổ sung để tăng sự đa dạng của các mẫu trong quá trình tạo cây. Đối với tạo sinh đầu cuối đến cuối, chúng tôi áp dụng giải mã tham lam. Chúng tôi cố định độ dài tạo sinh tối đa ở 128 token mỗi bước cho việc tạo cây, và 512 cho việc tạo lý luận đầy đủ. Chúng tôi chạy thí nghiệm trên 8 GPU với kích thước lô 16.

Xây dựng gợi ý. Tất cả các gợi ý được sử dụng để tạo giả thuyết được liệt kê trong Bảng 3. Cụ thể, đối với tập dữ liệu GSM8K, chúng tôi tuân theo các gợi ý từ Touvron et al. (2023), đối với các tập dữ liệu STRATEGYQA và CSQA, chúng tôi tuân theo Wei et al. (2022).

Cắt tỉa. Trong các thí nghiệm chính, chúng tôi áp dụng yếu tố ủ α= 0.5, và sử dụng nhiệt độ lấy mẫu bước τ= 1.0. τ= 0 tương ứng với lấy mẫu khả năng tối đa, trong khi τ− →inf tương ứng với lấy mẫu đồng nhất. Thiết lập này cho phép biến thể bước cao hơn ở đầu việc tạo sinh, và trở nên nghiêm ngặt hơn theo độ sâu. Chúng tôi đã thử nghiệm loại bỏ yếu tố ủ

--- TRANG 9 ---
và thay đổi τ={0,0.5,1.0,16} trên phần huấn luyện của tập dữ liệu GSM8K, và tìm thấy hiệu suất tối ưu tại τ= 1 với ủ.

Hàm chấm điểm. Chúng tôi đối chiếu bộ chấm điểm dựa trên N-gram với một số phương pháp thay thế:
• Bộ chấm điểm Tự nhất quán: Câu trả lời cuối cùng được xác định bằng cách biên hóa các đường dẫn lý luận được lấy mẫu để tìm câu trả lời nhất quán nhất trong tập câu trả lời cuối cùng (Wang et al., 2022). Phương pháp này không tính đến các chuỗi lý luận, vì vậy chúng tôi sửa đổi Phương trình 4 như y∗= arg maxyj∈Ynaj, trong đó A={a1, ..., ab} là tất cả các câu trả lời được tạo được trích xuất từ các giả thuyết tương ứng Y, và mỗi câu trả lời aj xuất hiện naj lần trong A.

• Bộ chấm điểm Độ tương tự Cosine: Câu trả lời cuối cùng được chọn bằng cách biên hóa tổng độ tương tự cosine của các chuỗi lý luận, vì vậy chúng tôi sửa đổi Phương trình 5 như S(yj,yk) = cos(ej,ek), trong đó ej là embedding của đường dẫn lý luận giả thuyết yj như được xác định bởi mô hình embedding câu all-mpnet-base-v2 HuggingFace.

• Bộ chấm điểm BERT và BLEURT: Theo nghiên cứu trí tuệ đám đông Suzgun et al. (2022), chúng tôi thử các chỉ số BLEURT (Sellam et al., 2020) và BERTSCORE (Zhang et al., 2019) như hàm độ tương tự S trong Phương trình 4.

• Bộ chấm điểm Thông tin: Chúng tôi chọn giả thuyết cuối cùng dựa trên lượng thông tin được chia sẻ giữa ngữ cảnh nguồn c và các đường dẫn lý luận, được đo thông qua sự liên kết tương hỗ. Cụ thể, chúng tôi sử dụng điểm Info-chain được định nghĩa là I(yj,c) trong (Golovneva et al., 2022), và sửa đổi Phương trình 4 cho hàm chấm điểm này như y∗= arg maxyj∈YI(yj,c).

• Mô hình Xác minh: Chúng tôi chọn đường dẫn lý luận giả thuyết cuối cùng và câu trả lời dựa trên điểm số được cung cấp bởi một mô hình xác minh được huấn luyện trước. Chúng tôi sử dụng các mô hình FLAN-T5-XL và TEXT-DAVINCI-003 để xếp hạng các giả thuyết và chọn giả thuyết được xếp hạng hàng đầu. Để chấm điểm các giả thuyết, các mô hình được gợi ý để đánh giá tính đúng đắn của đường dẫn lý luận, sau đó các giả thuyết được xếp hạng dựa trên điểm trung thực trả về. Chúng tôi cung cấp chi tiết hơn về phương pháp xếp hạng trong Phụ lục E.

--- TRANG 10 ---
Gợi ý few-shot được sử dụng cho tập dữ liệu GSM8K
Trả lời những câu hỏi này:
Q: Có 15 cây trong khu vườn. Các công nhân khu vườn sẽ trồng cây trong khu vườn hôm nay. Sau khi họ hoàn thành, sẽ có 21 cây. Các công nhân khu vườn đã trồng bao nhiêu cây hôm nay?
A: Ban đầu có 15 cây. Sau đó có 21 cây sau khi trồng thêm một số cây. Vậy phải có 21 - 15 = 6. Câu trả lời là 6.

Q: Nếu có 3 xe trong bãi đỗ xe và 2 xe nữa đến, có bao nhiêu xe trong bãi đỗ xe?
A: Ban đầu có 3 xe. 2 xe nữa đến. 3 + 2 = 5. Câu trả lời là 5.

Q: Leah có 32 viên sô cô la và chị gái cô ấy có 42 viên. Nếu họ ăn 35 viên, họ còn lại tổng cộng bao nhiêu viên?
A: Ban đầu, Leah có 32 viên sô cô la. Chị gái cô ấy có 42 viên. Vậy tổng cộng họ có 32 + 42 = 74. Sau khi ăn 35 viên, họ còn 74 - 35 = 39. Câu trả lời là 39.

Q: Jason có 20 viên kẹo mút. Anh ấy đã cho Denny một số viên kẹo mút. Bây giờ Jason có 12 viên kẹo mút. Jason đã cho Denny bao nhiêu viên kẹo mút?
A: Jason bắt đầu với 20 viên kẹo mút. Sau đó anh ấy có 12 viên sau khi cho Denny một số. Vậy anh ấy đã cho Denny 20 - 12 = 8. Câu trả lời là 8.

Q: Shawn có năm đồ chơi. Vào Giáng sinh, anh ấy nhận được hai đồ chơi từ mẹ và hai từ bố. Bây giờ anh ấy có bao nhiêu đồ chơi?
A: Shawn bắt đầu với 5 đồ chơi. Nếu anh ấy nhận được 2 đồ chơi từ mẹ và bố, thì đó là 4 đồ chơi nữa. 5 + 4 = 9. Câu trả lời là 9.

Q: Có chín máy tính trong phòng máy chủ. Năm máy tính nữa được cài đặt mỗi ngày, từ thứ hai đến thứ năm. Bây giờ có bao nhiêu máy tính trong phòng máy chủ?
A: Ban đầu có 9 máy tính. Trong mỗi ngày trong 4 ngày, 5 máy tính nữa được thêm vào. Vậy 5 * 4 = 20 máy tính được thêm vào. 9 + 20 là 29. Câu trả lời là 29.

Q: Michael có 58 quả bóng golf. Vào thứ ba, anh ấy mất 23 quả bóng golf. Vào thứ tư, anh ấy mất thêm 2 quả. Anh ấy có bao nhiêu quả bóng golf vào cuối thứ tư?
A: Michael bắt đầu với 58 quả bóng golf. Sau khi mất 23 quả vào thứ ba, anh ấy có 58 - 23 = 35. Sau khi mất thêm 2 quả, anh ấy có 35 - 2 = 33 quả bóng golf. Câu trả lời là 33.

Q: Olivia có $23. Cô ấy mua năm chiếc bánh mì với giá $3 mỗi chiếc. Cô ấy còn lại bao nhiêu tiền?
A: Olivia có 23 đô la. 5 chiếc bánh mì với giá 3 đô la mỗi chiếc sẽ là 5 x 3 = 15 đô la. Vậy cô ấy còn 23 - 15 đô la. 23 - 15 là 8. Câu trả lời là 8.

Gợi ý few-shot được sử dụng cho tập dữ liệu StrategyQA
Trả lời những câu hỏi này:
Q: Chuột hamster có cung cấp thức ăn cho động vật nào không?
A: Chuột hamster là động vật bị săn mồi. Con mồi là thức ăn cho động vật săn mồi. Do đó, chuột hamster cung cấp thức ăn cho một số động vật. Câu trả lời là có.

Q: Brooke Shields có thể thành công tại Đại học Pennsylvania không?
A: Brooke Shields đã học tại Đại học Princeton. Đại học Princeton có độ khó học thuật tương đương với Đại học Pennsylvania. Do đó, Brooke Shields cũng có thể thành công tại Đại học Pennsylvania. Câu trả lời là có.

Q: Có hay không: Bình phương số nguyên tử của hydro vượt quá số lượng Spice Girls?
A: Hydro có số nguyên tử là 1. 1 bình phương là 1. Có 5 Spice Girls. Do đó, bình phương số nguyên tử của hydro nhỏ hơn 5. Câu trả lời là không.

Q: Có hay không: Có phổ biến thấy sương giá trong một số lễ tốt nghiệp đại học không?
A: Lễ tốt nghiệp đại học có thể diễn ra vào tháng 12, tháng 5 và tháng 6. Tháng 12 là mùa đông, vì vậy có thể có sương giá. Do đó, có thể có sương giá tại một số lễ tốt nghiệp. Câu trả lời là có.

Q: Có hay không: Lạc đà có thể sinh con hai lần trong Chiến tranh Việt Nam (1945-46) không?
A: Chiến tranh Việt Nam kéo dài 6 tháng. Thời gian mang thai của lạc đà là 11 tháng, nhiều hơn 6 tháng. Do đó, lạc đà không thể sinh con hai lần trong Chiến tranh Việt Nam. Câu trả lời là không.

--- TRANG 11 ---
Q: Có hay không: Quả lê có chìm trong nước không?
A: Mật độ của quả lê khoảng 0,6g/cm3, ít hơn nước. Các vật thể có mật độ ít hơn nước sẽ nổi. Do đó, quả lê sẽ nổi. Câu trả lời là không.

Gợi ý few-shot được sử dụng cho tập dữ liệu CSQA
Trả lời những câu hỏi này:
Q: Mọi người sử dụng gì để hấp thụ mực thừa từ bút máy?
Lựa chọn câu trả lời:
(A) túi áo sơ mi
(B) tay của thầy viết thư pháp
(C) lọ mực
(D) ngăn kéo bàn
(E) giấy thấm

A: Câu trả lời phải là một vật phẩm có thể hấp thụ mực. Trong các lựa chọn trên, chỉ có giấy thấm được dùng để hấp thụ mực. Câu trả lời là E.

Q: Thiết bị giải trí gia đình nào cần cáp?
Lựa chọn câu trả lời:
(A) cửa hàng radio
(B) trạm phụ
(C) tivi
(D) tủ

A: Câu trả lời phải cần cáp. Trong các lựa chọn trên, chỉ có tivi cần cáp. Câu trả lời là C.

Q: Con cáo đi từ thành phố vào rừng, nó đang tìm kiếm gì?
Lựa chọn câu trả lời:
(A) hoa đẹp
(B) chuồng gà
(C) môi trường sống tự nhiên
(D) sách truyện

A: Câu trả lời phải là thứ gì đó trong rừng. Trong các lựa chọn trên, chỉ có môi trường sống tự nhiên là trong rừng. Câu trả lời là B.

Q: Sammy muốn đến nơi có người. Anh ấy có thể đi đâu?
Lựa chọn câu trả lời:
(A) khu vực đông dân
(B) trường đua
(C) sa mạc
(D) căn hộ
(E) chốt chặn đường

A: Câu trả lời phải là nơi có nhiều người. Trong các lựa chọn trên, chỉ có khu vực đông dân có nhiều người. Câu trả lời là A.

Q: Bạn đặt nho ở đâu ngay trước khi thanh toán?
Lựa chọn câu trả lời:
(A) miệng
(B) xe đẩy hàng
(C) siêu thị
(D) giỏ trái cây
(E) chợ trái cây

A: Câu trả lời nên là nơi đặt hàng tạp hóa trước khi thanh toán. Trong các lựa chọn trên, xe đẩy hàng có ý nghĩa nhất để đựng hàng tạp hóa. Câu trả lời là B.

Q: Google Maps và các dịch vụ GPS đường cao tốc và đường phố khác đã thay thế cái gì?
Lựa chọn câu trả lời:
(A) hoa kỳ
(B) mexico
(C) vùng nông thôn
(D) atlas

A: Câu trả lời phải là thứ từng làm những gì Google Maps và dịch vụ GPS làm, đó là chỉ đường. Trong các lựa chọn trên, chỉ có atlas được dùng để chỉ đường. Câu trả lời là D.

--- TRANG 12 ---
Q: Trước khi ly hôn, người vợ làm tất cả công việc cảm thấy thế nào?
Lựa chọn câu trả lời:
(A) khó khăn hơn
(B) đau khổ
(C) cay đắng
(D) nước mắt
(E) buồn bã

A: Câu trả lời nên là cảm giác của người sắp ly hôn và đang làm tất cả công việc. Trong các lựa chọn trên, cảm giác gần nhất là cay đắng. Câu trả lời là C.

Bảng 3: Gợi ý được sử dụng để tạo giả thuyết cho mỗi tập dữ liệu.

--- TRANG 13 ---
E Mô hình xác minh
Để xếp hạng các giả thuyết được tạo, chúng tôi có thể sử dụng các LLM được huấn luyện trước mà được biết là được hiệu chỉnh tốt đối với các câu hỏi Đúng/Sai, và do đó đã được sử dụng cho tự đánh giá (Kadavath et al., 2022). Chúng tôi áp dụng phương pháp này và mở rộng nó để sử dụng bất kỳ mô hình LLM bên ngoài nào bằng cách gợi ý nó với 5 ví dụ câu hỏi trắc nghiệm để xác định xem lý luận được tạo ra có (A) đúng hay (B) không đúng. Chúng tôi sử dụng các mô hình FLAN-T5 và TEXT-DAVINCI-003 để đánh giá, và trích xuất xác suất lý luận đúng làm điểm trung thực. Chúng tôi lưu ý rằng FLAN-T5 được tinh chỉnh trên các phần huấn luyện của CSQA và GSM8K, và do đó sẽ có hiệu suất hơi thổi phồng so với các mô hình có kích thước tương đương không được huấn luyện trên các nhiệm vụ này. Chúng tôi tuân theo Xie et al. (2023) và sử dụng xác suất của tùy chọn A làm điểm để xếp hạng và chọn thế hệ.

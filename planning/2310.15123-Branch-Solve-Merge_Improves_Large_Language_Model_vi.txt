# 2310.15123.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/planning/2310.15123.pdf
# Kích thước tệp: 866695 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Branch-Solve-Merge Cải thiện Đánh giá và Tạo sinh
của Mô hình Ngôn ngữ Lớn
Swarnadeep Saha*
UNC Chapel HillOmer Levy
MetaAsli Celikyilmaz
Meta
Mohit Bansal
UNC Chapel HillJason Weston
MetaXian Li
Meta
Tóm tắt
Các Mô hình Ngôn ngữ Lớn (LLM) thường được
sử dụng cho các tác vụ tạo sinh và đánh giá ngôn
ngữ đa khía cạnh liên quan đến việc thỏa mãn các
ràng buộc phức tạp của người dùng hoặc xem xét
nhiều khía cạnh và tiêu chí. Tuy nhiên, hiệu suất
của chúng có thể không đạt yêu cầu, do thiếu tính
nhất quán của mô hình và không có khả năng lập
kế hoạch và phân tách vấn đề. Chúng tôi đề xuất
BRANCH-SOLVE-MERGE (BSM), một chương
trình Mô hình Ngôn ngữ Lớn (Schlag et al., 2023)
để giải quyết các tác vụ ngôn ngữ tự nhiên đầy thử
thách như vậy. Nó bao gồm các mô-đun branch,
solve và merge được tham số hóa với các prompt
cụ thể cho LLM cơ sở. Ba mô-đun này lập kế hoạch
phân tách tác vụ thành nhiều tác vụ con song song,
giải quyết chúng một cách độc lập, và hợp nhất các
giải pháp cho các tác vụ con. Chúng tôi áp dụng
phương pháp của mình cho các tác vụ đánh giá phản
hồi LLM và tạo sinh văn bản có ràng buộc và đánh
giá hiệu quả của nó với nhiều LLM, bao gồm Vicuna,
LLaMA-2-chat và GPT-4. BSM cải thiện độ chính
xác và tính nhất quán của đánh giá cho mỗi LLM
bằng cách tăng cường sự đồng thuận giữa con người
và LLM lên đến 26%, giảm thiên lệch về độ dài và
vị trí ghép đôi lên đến 50%, và cho phép LLaMA-
2-chat có thể bằng hoặc vượt trội GPT-4 trên hầu
hết các lĩnh vực. Trên tác vụ tạo sinh câu chuyện có
ràng buộc, BSM cải thiện tính nhất quán của câu
chuyện đồng thời cũng cải thiện việc thỏa mãn ràng
buộc 12%.

1 Giới thiệu
Các Mô hình Ngôn ngữ Lớn (LLM) được sử dụng
rộng rãi cho các tác vụ tạo sinh văn bản khác nhau
(Radford et al., 2019; Brown et al., 2020; OpenAI,
2023b; Chowdhery et al., 2022; Touvron et al., 2023).
Cũng trở nên phổ biến việc sử dụng chúng như các bộ
đánh giá của các sản phẩm tạo sinh LLM như vậy để
đánh giá, phê bình và cải thiện các đầu ra (Zheng et al.,
2023; Bai et al., 2022b). Tuy nhiên, LLM vẫn gặp
khó khăn với các tác vụ có yêu cầu phức tạp như thỏa
mãn một tập hợp các ràng buộc hoặc đáp ứng các mục
tiêu nói chung là đa chiều (ví dụ, đánh giá chất lượng
văn bản được tạo ra theo các tiêu chí đa dạng nhất
định). Điều này dường như chủ yếu xuất phát từ việc
thiếu tính tự nhất quán của mô hình và không có khả
năng lập kế hoạch (Yao et al., 2023b; Bubeck et al.,
2023). Nghiên cứu gần đây đã cố gắng giảm thiểu
những hạn chế này bằng cách phát triển các phương
pháp lặp lại liên quan đến việc kích thích suy luận,
lập kế hoạch và tinh chỉnh, nhưng cho đến nay chúng
vẫn được coi là những vấn đề mở (Bai et al., 2022b;
Madaan et al., 2023; Ganguli et al., 2023; Yao et al.,
2023c; Chen et al., 2023; Li et al., 2023; Huang et al.,
2023).

*Công việc được thực hiện trong thời gian thực tập tại Meta.

Trong công trình này, chúng tôi đề xuất BRANCH-
SOLVE-MERGE (BSM), một phương pháp phân tách
để giải quyết các tác vụ ngôn ngữ tự nhiên đa khía
cạnh như vậy. Cách tiếp cận của chúng tôi là một thể
hiện của chương trình Mô hình Ngôn ngữ Lớn (Schlag
et al., 2023; Dohan et al., 2022) và bao gồm ba mô-đun:
branch, solve và merge được tham số hóa với các
prompt cụ thể cho LLM bên dưới. Với một tác vụ tùy
ý của người dùng, mô-đun 'branch' tạo ra một kế
hoạch giải pháp bằng cách phân tách tác vụ thành
nhiều tác vụ con song song, trong đó mỗi tác vụ con
được đại diện bởi một nhánh duy nhất, đại diện cho
các thành phần khác nhau cần thiết để giải quyết vấn
đề tổng thể. Mô-đun 'solve' sau đó giải quyết từng
vấn đề con độc lập này. Cuối cùng, mô-đun 'merge'
hợp nhất các giải pháp cho những vấn đề con này để
tạo ra giải pháp tổng thể. Chúng tôi áp dụng phương
pháp của mình cho hai tác vụ đầy thử thách mà LLM
thường được sử dụng nhưng hiệu suất của chúng vẫn
thua kém con người:

•Đánh giá Đầu ra LLM (Zheng et al., 2023). LLM
hiện tại thường xuyên được sử dụng để thực hiện
đánh giá tự động các phản hồi của mô hình, ví dụ,
đối với các truy vấn của người dùng (Dubois et al.,
2023). Đánh giá LLM một cách toàn diện là thách
thức vì khả năng của chúng trong việc tạo ra các
câu trả lời dài cho các câu hỏi tùy ý của người dùng
(Zheng et al., 2023), việc thiếu độ tin cậy xuất phát
từ nhiều thiên lệch (Zheng et al., 2023; Wu và Aji,
2023; Wang et al., 2023b), và sự phụ thuộc vào các
kế hoạch đánh giá được thiết kế thủ công ảnh hưởng
đến khả năng tổng quát hóa của phương pháp, đưa
ra các thiên lệch con người không mong muốn (Liu
et al., 2023; Wu và Aji, 2023). BSM có thể được áp
dụng cho tác vụ này bằng cách mỗi nhánh đánh giá
các khía cạnh và tiêu chí khác nhau cần đánh giá.

arXiv:2310.15123v2 [cs.CL] 7 Jun 2024

--- TRANG 2 ---
Soạn một bài blog du lịch hấp dẫn về một chuyến đi gần đây đến
Hawaii, làm nổi bật những trải nghiệm văn hóa và các điểm tham quan không thể bỏ qua.

Mức độ liên quan: Đánh giá mức độ
phản hồi phù hợp với câu hỏi của
người dùng và liệu nó có cung cấp
thông tin liên quan về trải nghiệm
văn hóa và các điểm tham quan không
thể bỏ qua ở Hawaii. Độ rõ ràng: Đánh giá mức độ
rõ ràng và súc tích của phản hồi
....Độ chính xác: Kiểm tra
phản hồi về độ chính xác thực tế,
đảm bảo rằng ....

Phản hồi của Trợ lý A: 4/5
Phản hồi cung cấp thông tin liên quan
về trải nghiệm văn hóa .... Tuy nhiên, có thể
được cải thiện bằng cách bao gồm
chi tiết cụ thể hơn về trải nghiệm
văn hóa và các điểm tham quan ....

Phản hồi của Trợ lý B: 5/5
Phản hồi có mức độ liên quan cao
với câu hỏi của người dùng và
cung cấp tổng quan có cấu trúc tốt và
chi tiết về trải nghiệm văn hóa
và các điểm tham quan không thể bỏ qua ở Hawaii .....

Phản hồi của Trợ lý A:
4/5
Phản hồi nhìn chung
rõ ràng và súc tích, với
các câu có cấu trúc tốt
và từ vựng phù hợp.
....

Phản hồi của Trợ lý B:
5/5
Phản hồi đặc biệt
rõ ràng và súc tích, với
các câu ngắn, có cấu trúc
tốt dễ theo dõi ....

Phản hồi của Trợ lý A: 4/5
Phản hồi chính xác đề cập đến
Trung tâm Văn hóa Polynesia và
Vịnh Hanauma,
....

Phản hồi của Trợ lý B: 5/5
Phản hồi chính xác cung cấp
thông tin ...., bao gồm Trung tâm
Văn hóa Polynesia, Cung điện Iolani,
Công viên Quốc gia Núi lửa Hawaii, .....

Phản hồi của Trợ lý A: 3/5
Phản hồi cung cấp một số hiểu biết
độc đáo về trải nghiệm văn hóa
có sẵn ở Hawaii,
.....
Tuy nhiên, việc đề cập đến các điểm
tham quan phổ biến như Vịnh Hanauma
và Hẻm núi Waimea không đặc biệt
độc đáo
.....

Phản hồi của Trợ lý B: 4/5
Phản hồi mang đến góc nhìn độc đáo
hơn về trải nghiệm văn hóa và điểm
tham quan của Hawaii ....

Sau khi xem xét cẩn thận tất cả các đánh giá, rõ ràng là Trợ lý B đã cung cấp phản hồi tốt hơn nhìn chung. Phản hồi của Trợ lý B
đạt điểm cao hơn về mức độ liên quan, độ rõ ràng, sự hấp dẫn, độ chính xác và tính độc đáo. Trong khi phản hồi của Trợ lý A có tính thông tin, nó thiếu
yếu tố cá nhân và tông điệu hấp dẫn mà phản hồi của Trợ lý B cung cấp. Ngoài ra, phản hồi của Trợ lý B chính xác hơn, không có
lỗi thực tế, và đưa ra các gợi ý độc đáo hơn cho trải nghiệm văn hóa và điểm tham quan ở Hawaii.

Do đó, phán quyết cuối cùng là: [[B]]. Phản hồi của Trợ lý B tốt hơn nhìn chung.

Câu hỏi
Phản hồi A
Phản hồi B

Câu hỏi Câu hỏi Tính độc đáo: Đánh giá
tính độc đáo của phản hồi, xem xét
liệu nó có cung cấp góc nhìn mới mẻ và
độc đáo về trải nghiệm văn hóa và
điểm tham quan của Hawaii hay chỉ
đơn giản là lặp lại thông tin du lịch
thông thường.

Nhánh 1 Nhánh k Nhánh (k-1) Nhánh 2

Tiêu chí

Hình 1: Minh họa BRANCH-SOLVE-MERGE với LLaMA-2-70B-chat cho đánh giá cặp đôi các phản hồi LLM. Cho một câu hỏi và hai phản hồi LLM A và B, BSM tạo ra phán quyết ưu tiên. Mô-đun Branch dựa trên câu hỏi để tạo ra kế hoạch đánh giá cụ thể cho câu hỏi, trong trường hợp này bao gồm các tiêu chí khác nhau như 'Mức độ liên quan' với chủ đề chuyến đi Hawaii, 'Độ rõ ràng', v.v. Mô-đun 'Solve' đánh giá các cặp phản hồi cho từng tiêu chí (nhánh) một cách độc lập và mô-đun 'Merge' kết hợp các phán quyết riêng lẻ để tạo ra phán quyết cuối cùng, trong trường hợp này là B là phản hồi tốt hơn.

tion plans that impact the method's generaliza-
tion, introducing unintended human biases (Liu
et al., 2023; Wu and Aji, 2023). BSM can be ap-
plied to this task by each branch assessing differ-
ent aspects and criteria that require evaluation.

•Tạo sinh Văn bản có Ràng buộc. Các LLM tiên
tiến hiện tại gặp khó khăn với các tác vụ tạo sinh
văn bản có ràng buộc, ví dụ, ràng buộc viết một
câu chuyện phải bao gồm nhiều khái niệm. Các
mô hình thường hoặc vi phạm ràng buộc, hoặc tạo
ra văn bản không nhất quán để thỏa mãn những
ràng buộc này (Bubeck et al., 2023; Yao et al.,
2023a). BSM có thể được áp dụng cho tác vụ này
bằng cách mỗi nhánh viết một phần của câu chuyện
chỉ thỏa mãn một số ràng buộc, tiếp theo là việc
hợp nhất cuối cùng.

*Sau đó, chúng tôi sẽ gọi tác vụ này là 'Đánh giá LLM'. Trong 
phạm vi nghiên cứu của chúng tôi, điều này sẽ bao gồm việc đánh 
giá cặp đôi chất lượng phản hồi của hai đầu ra LLM.

Chúng tôi áp dụng BSM cho cả hai vấn đề này, xem
Hình 1 và Hình 3, và đánh giá hiệu quả của nó với
nhiều LLM mã nguồn mở và hộp đen có kích thước
và sức mạnh khác nhau bao gồm LLaMA-2-7B-
chat (Touvron et al., 2023), Vicuna-33B (Chiang
et al., 2023), LLaMA-2-70B-chat và GPT-4 (OpenAI,
2023b). BSM cải thiện đáng kể cả hai tác vụ, giải
quyết những hạn chế đã đề cập của đánh giá và tạo
sinh LLM:

•BSM cải thiện độ chính xác của đánh giá LLM.
Cụ thể, trên benchmark MT-Bench (Zheng et al.,
2023), BSM cải thiện sự đồng thuận LLM-người
cho việc đánh giá các câu hỏi đa lượt thuộc các
lĩnh vực khác nhau bao gồm viết, lập trình, suy
luận và toán học. Ví dụ, so với prompt zero-shot
và baseline tự nhất quán (Wang et al., 2022),

--- TRANG 3 ---
BSM với LLaMA-2-70B-chat cải thiện sự đồng
thuận LLM-người lên đến 26% tuyệt đối và thậm
chí bằng hoặc vượt trội GPT-4 trên nhiều lĩnh
vực. BSM với GPT-4 cải thiện sự đồng thuận thêm
3% so với GPT-4. Nhìn chung, những phát hiện
này chỉ ra khả năng của BSM trong việc đánh giá
phản hồi LLM cho các câu hỏi tùy ý của người
dùng từ các lĩnh vực đa dạng và cải thiện bất kỳ
LLM cơ sở nào như một bộ đánh giá.

•BSM cũng cải thiện tính nhất quán của đánh giá
LLM. Nó giảm đáng kể thiên lệch vị trí, độ dài
và tự nâng cao của các bộ đánh giá dựa trên LLM.
Ví dụ, BSM với LLaMA-2-70B-chat giảm thiên
lệch vị trí lên đến 50% tuyệt đối. Quan trọng là,
BSM với GPT-4 cũng cải thiện độ tin cậy của
GPT-4 như một bộ đánh giá khi đánh giá các
phản hồi của chính nó.

•Đối với tác vụ tạo sinh câu chuyện có ràng buộc,
BSM tạo ra những câu chuyện nhất quán hơn, được
ưa thích bởi một thẩm phán GPT-4 đáng kể 93%
số lần so với baseline zero-shot. Nó cũng cải thiện
việc thỏa mãn ràng buộc 12%.

Nhìn chung, BSM cung cấp một khung để lập kế
hoạch và phân tách tác vụ để giải quyết các tác vụ
tạo sinh và đánh giá ngôn ngữ đa khía cạnh đầy thử
thách. Vì cách tiếp cận được khung thành như một
chương trình LLM tổng quát, nó có thể được áp dụng
cho bất kỳ LM cơ bản nào và có khả năng một loạt
các tác vụ rộng rãi.

2 Công trình Liên quan

Chương trình LLM và Phân tách Tác vụ Phức tạp.
Các chương trình LLM như BSM giải quyết các vấn
đề phức tạp bằng một thuật toán chia nhỏ vấn đề
thành nhiều bước và mỗi bước sau đó được tham số
hóa với một prompt khác nhau cho LLM cơ bản
(Schlag et al., 2023; Dohan et al., 2022; Creswell
và Shanahan, 2022). Các tác vụ phức tạp, nói chung,
đòi hỏi phân tách tác vụ (Khot et al., 2022) và lập
kế hoạch (Yao et al., 2022; Huang et al., 2022; Yao
et al., 2023b; Ning et al., 2023). Điều này đã thúc
đẩy nhiều nghiên cứu gần đây về các phương pháp
prompt nâng cao (Khot et al., 2022; Zhou et al.,
2022; Wang et al., 2023a; Dua et al., 2022; Saha
et al., 2022, 2023; Khot et al., 2021; Gupta và
Kembhavi, 2023; Cho et al., 2023). Tuy nhiên, hầu
hết các công trình này thường tập trung vào các
vấn đề suy luận (như thông thường, biểu tượng hoặc
toán học) có lợi từ việc phân tách tuần tự. Tuy nhiên,
chúng tôi nghiên cứu các tác vụ có lợi từ việc phân
nhánh thành các phân tách song song, cụ thể là đánh
giá LLM và tạo sinh văn bản có ràng buộc. Cũng như
là một chương trình LLM, BSM cũng là một thể hiện
của prompt Graph-of-Thoughts (GoT) (Lei et al.,
2023; Besta et al., 2023) vì dấu vết thực thi có hình
dạng của một đồ thị. GoT định nghĩa một loạt rộng
các chương trình LLM, bao gồm tinh chỉnh, quay
lại và bỏ qua các nút đồ thị, mà chúng tôi không
xem xét ở đây. Công trình của chúng tôi phát triển
một chương trình cố định cụ thể, và áp dụng nó cho
các tác vụ thách thức của việc đánh giá hoặc cải
thiện các mô hình ngôn ngữ.

Đánh giá LLM. Một thách thức cơ bản với tiến bộ
nhanh chóng của LLM là đánh giá khả năng của
chúng một cách toàn diện (Chang et al., 2023; Liang
et al., 2022). Đánh giá con người là khó khăn và
đắt đỏ (Smith et al., 2022). Mặt khác, LLM, bằng
cách được huấn luyện với RLHF, được chứng minh
là thể hiện sự phù hợp với con người (Ouyang et al.,
2022; Bai et al., 2022a). Do đó, một quy trình tiêu
chuẩn để so sánh và đánh giá các sản phẩm tạo sinh
LLM là bằng cách sử dụng một LLM mạnh như GPT-4
(Bubeck et al., 2023; OpenAI, 2023a; Dubois et al.,
2023; Zhou et al., 2023; Chiang và Lee, 2023; Wang
et al., 2023c; Hada et al., 2023; Liu et al., 2023) trên
các benchmark khác nhau (Zhong et al., 2023; Köpf
et al., 2023; Zheng et al., 2023). Các bộ đánh giá
dựa trên LLM không phải là những bộ đánh giá công
bằng (Wang et al., 2023b; Wu và Aji, 2023) và đã
có những đề xuất sử dụng cuộc tranh luận đa tác
nhân (Chan et al., 2023) hoặc phát triển LLM rộng
hơn và sâu hơn (Zhang et al., 2023). Ngược lại, BSM
cải thiện đánh giá LLM thông qua một cách tiếp cận
dựa trên phân tách trực quan và tổng quát có thể
được áp dụng trên bất kỳ LLM nào để đánh giá phản
hồi cho một loạt rộng các tác vụ.

Tạo sinh Văn bản có Ràng buộc. Các nghiên cứu
gần đây đánh giá LLM về khả năng của chúng trong
môi trường khó khăn hơn của việc tạo sinh văn bản
có thể kiểm soát và có ràng buộc (Keskar et al.,
2019; Dathathri et al., 2019; Lu et al., 2021, 2022;
Lin et al., 2020; Li et al., 2022) và cho thấy rằng
ngay cả GPT-4 cũng gặp khó khăn với các tác vụ
dựa trên lập kế hoạch như vậy (Bubeck et al., 2023;
Madaan et al., 2023; Yao et al., 2023a). Chúng tôi
thử nghiệm với một tác vụ tạo sinh câu chuyện có
ràng buộc như vậy và cho thấy tiềm năng của BSM.

3 BRANCH-SOLVE-MERGE

Trước tiên chúng tôi giới thiệu một số ký hiệu để
mô tả chính thức BSM. Gọi pθ là một LLM với các
tham số θ. Chúng tôi cũng ký hiệu x = x1,···,xn
là một chuỗi n token, sao cho pθ(x) = ∏ᵢ₌₁ⁿ pθ(xᵢ|x₁,···,xᵢ₋₁).
BSM là một chương trình LLM nhằm giải quyết các
tác vụ phức tạp dựa trên lập kế hoạch với ba mô-đun
neural:

--- TRANG 4 ---
các mô-đun: branch, solve và merge. Mỗi mô-đun
được tham số hóa với các prompt độc nhất cho LLM pθ.
Chương trình LLM tiếp tục định nghĩa một thuật
toán trên các mô-đun này, hoạt động như một bộ
điều khiển và gọi một mô-đun ở mỗi bước của thuật
toán.

3.1 Các Thành phần của BRANCH-SOLVE-MERGE

Chương trình LLM. Đối với một tác vụ nhất định,
BSM định nghĩa một bộ điều khiển như một thuật
toán đặt ra logic chuyển đổi giữa các mô-đun.
Hãy ký hiệu ba mô-đun với dạng hàm của chúng:
branch(·), solve(·) và merge(·). Khi đó chương
trình được định nghĩa là Prog : (x, branch(·),
solve(·), merge(·)) → y, nhận đầu vào là một thể
hiện tác vụ x, cùng với các triển khai mô-đun và
tạo ra đầu ra y.

Mô-đun Branch. Cho một tác vụ, mô-đun branch
tạo ra nhiều tác vụ con trong đó mỗi tác vụ con
được đại diện bởi một nhánh độc nhất. Phân nhánh
thành các vấn đề con cho phép phân tách tác vụ sao
cho mỗi phần có thể được giải quyết độc lập song
song, tại thời điểm đó các giải pháp từng phần được
kết hợp. Chính thức, cho một đầu vào tác vụ x,
chúng tôi định nghĩa một prompt 'branch' prompt_branch(x)
có thể được bao quanh x với các hướng dẫn phân
nhánh và một số minh họa (nếu có). Dựa trên prompt,
LLM pθ tạo ra một tập hợp k vấn đề con X = {x⁽¹⁾,
x⁽²⁾, ···, x⁽ᵏ⁾}, trong đó k được gọi là hệ số phân
nhánh. Các vấn đề con được tạo ra tự hồi quy như
một chuỗi token: X ∼ pθ(X|prompt_branch(x)).
Quan trọng là, tính linh hoạt của phương pháp
chúng tôi đến từ thực tế là đối với một vấn đề nhất
định, chính LLM quyết định (tạo ra) các vấn đề con
và hệ số phân nhánh tương ứng.

Mô-đun Solve. Mô-đun solve giải quyết tác vụ tại
tay bằng cách tạo ra một đầu ra y⁽ᵢ⁾ cho một đầu
vào tác vụ nhánh x⁽ᵢ⁾. Tương tự như prompt branch,
chúng tôi định nghĩa một prompt 'solve' prompt_solve(x⁽ᵢ⁾),
dựa trên đó LLM tạo ra một giải pháp y⁽ᵢ⁾ ∼ pθ(y⁽ᵢ⁾|prompt_solve(x⁽ᵢ⁾))
cho mỗi nhánh.

Mô-đun Merge. Mô-đun merge hợp nhất các giải
pháp cho các vấn đề con để tạo ra một giải pháp
toàn cục cho vấn đề chính. Điều này được thực hiện
thông qua một prompt 'merge' prompt_merge(Y) tạo
ra một giải pháp được hợp nhất y ∼ pθ(y|prompt_merge(Y)),
dựa trên một tập hợp các giải pháp con Y = {y⁽¹⁾,
y⁽²⁾, ···, y⁽ᵏ⁾}. Về mặt khái niệm, mô-đun merge
học một hàm tổng hợp có thể tổng hợp một tập hợp
các giá trị (sử dụng toán tử tổng hợp) hoặc hợp
nhất các đoạn văn bản, tùy thuộc vào tác vụ.

Tiếp theo, chúng tôi thúc đẩy và tiến hành các
nghiên cứu trường hợp của BSM với hai tác vụ NLP
thách thức: đánh giá LLM và tạo sinh có ràng buộc.

3.2 BSM: Nghiên cứu Trường hợp với Đánh giá LLM

Mô tả Tác vụ. Chúng tôi xem xét tác vụ đánh giá
các trợ lý chat dựa trên LLM. Chính thức, cho một
câu hỏi mở và một cặp phản hồi từ hai tác nhân
LLM, tác vụ yêu cầu tạo ra một phán quyết ưu tiên
về phản hồi nào tốt hơn hoặc liệu đó có phải là
hòa (xem Hình 1). Đánh giá phản hồi LLM là thách
thức vì nhiều lý do:

1. Câu trả lời dài cho các câu hỏi tùy ý. Với mục
tiêu cung cấp một trợ lý đa năng, người dùng đặt
các câu hỏi tùy ý từ bất kỳ lĩnh vực nào, và LLM
phản hồi bằng các câu trả lời dài (Zheng et al.,
2023). Dựa trên phản hồi ban đầu của mô hình,
người dùng có thể đặt các câu hỏi tiếp theo. Tùy
thuộc vào loại câu hỏi, quá trình đánh giá phải
xem xét ý định của câu hỏi, những gì được mong
đợi từ một phản hồi lý tưởng, và tiêu chí nào để
đánh giá.

2. Các bộ đánh giá LLM dễ bị thiên lệch. Các bộ
đánh giá dựa trên LLM không đáng tin cậy và dễ
bị các thiên lệch khác nhau bao gồm (a) Thiên lệch
Vị trí: đánh giá thay đổi dựa trên thứ tự mã hóa
của các phản hồi, (b) Thiên lệch Độ dài: xu hướng
ưa thích các phản hồi dài hơn, (c) Thiên lệch Tự
nâng cao: LLM-đánh giá viên ưa thích các phản
hồi của chính nó (Zheng et al., 2023).

3. GPT-4 như bộ đánh giá là đắt đỏ. Trong khi
các mô hình dựa trên API như GPT-4 là những bộ
đánh giá khá tốt (Zheng et al., 2023), những mô
hình này là độc quyền và tính phí người dùng cho
mỗi token được tạo ra. Các lựa chọn thay thế mã
nguồn mở hiện tại tương quan ít với con người
hơn và dễ bị ảnh hưởng nhiều hơn bởi các thiên
lệch đã đề cập.

4. Thiết kế thủ công các kế hoạch đánh giá không
có thể mở rộng. Một bộ đánh giá mạnh mẽ nên
tổng quát hóa tốt, có khả năng đánh giá phản hồi
cho các câu hỏi tùy ý và do đó, thiết kế thủ công
kế hoạch đánh giá cho mỗi tác vụ là không mong
muốn (Liu et al., 2023). Ví dụ, xem Hình 1, trong
đó đánh giá phản hồi cho một câu hỏi 'viết' yêu
cầu xem xét các yếu tố như 'Mức độ liên quan',
'Độ rõ ràng', v.v. trong khi nếu câu hỏi là một
câu hỏi 'lập trình' (xem Hình 2 trong Phụ lục),
người ta nên đánh giá 'Độ chính xác Mã', 'Khả
năng Đọc Mã', v.v.

Do đó, với bản chất đa khía cạnh của tác vụ đánh
giá này, chúng tôi phát triển một phiên bản của BSM, như

--- TRANG 5 ---
được mô tả dưới đây. Đối với nghiên cứu này, chúng
tôi tập trung vào việc đánh giá các câu hỏi đối thoại
hai lượt mặc dù phương pháp của chúng tôi có thể
áp dụng tổng quát cho bất kỳ số lượt nào. Hãy ký
hiệu câu hỏi đầu tiên là q1 và câu hỏi tiếp theo là
q2. Gọi các phản hồi từ hai LLM A và B là r1^(A)
và r1^(B) cho q1, và r2^(A) và r2^(B) cho q2.

Mô-đun Branch cho Đánh giá LLM. Nó tạo ra một
kế hoạch đánh giá tức là một tập hợp các tiêu chí
đánh giá mà phản hồi sẽ được đánh giá theo. Mô-
đun branch chỉ dựa trên câu hỏi đầu vào và đối với
các câu hỏi lượt-1, được định nghĩa là branch(q1),
trong khi đối với các câu hỏi lượt-2, nó dựa trên
cả câu hỏi lượt-1 và lượt-2, được biểu diễn là
branch(q1, q2). Đầu ra là một tập hợp các tiêu chí
đánh giá, branch(q) → {ci}i=1^k, trong đó mỗi ci
là tiêu đề của tiêu chí (ví dụ, 'Mức độ liên quan')
và một mô tả ngắn về cách đánh giá cho nó (ví dụ,
'Đánh giá mức độ phản hồi phù hợp với câu hỏi của
người dùng ... và các điểm tham quan không thể
bỏ qua ở Hawaii.'). Xem Hình 1 và 2 để có ví dụ
về các nhánh được tạo ra cho các câu hỏi khác nhau.

Mô-đun Solve cho Đánh giá LLM. Nó so sánh và
đánh giá các phản hồi dựa trên một tiêu chí cụ thể.
Đầu ra của đánh giá là một cặp điểm số (trong một
phạm vi được chỉ định, theo hướng dẫn giải quyết,
ví dụ, 1-5) cho mỗi phản hồi. Ví dụ, cho một tiêu
chí đánh giá c, chúng tôi ký hiệu mô-đun solve cho
một câu hỏi q như: solve(q, r1^(A), r1^(B), c) →
(s^(A), s^(B)), trong đó s^(A) và s^(B) là các điểm
đánh giá được gán cho hai phản hồi của trợ lý. Lưu
ý rằng mô-đun solve không đối xứng tức là thứ tự
mã hóa của hai phản hồi là quan trọng (và chúng
tôi giải quyết điều này dưới đây trong chương trình
LLM của chúng tôi). Mô-đun cũng tạo ra các giải
thích cùng với điểm số. Hình 1 cho thấy các ví dụ
tạo ra từ mô-đun solve với mô hình LLaMA-2-70B-chat.

Mô-đun Merge cho Đánh giá LLM. Chúng tôi phát
triển hai biến thể của mô-đun merge. Một biến thể
phi neural đơn giản cộng các điểm số trên tất cả
các nhánh. Chúng tôi cũng phát triển một biến thể
LLM neural dựa trên các đánh giá riêng lẻ và tạo
ra phán quyết cuối cùng với một chiến lược tổng
hợp do mô hình quyết định, được ký hiệu là merge(q,
{ci}i=1^k, {si^(A)}i=1^k, {si^(B)}i=1^k) → y, trong
đó các tiêu chí đánh giá {ci}i=1^k là đầu ra của mô-
đun branch và si^(A) và si^(B) là các đánh giá theo
tiêu chí (điểm số và giải thích) của hai phản hồi
trợ lý được tạo ra từ mô-đun solve. Phán quyết cuối
cùng là y ∈ {A, B, hòa}.

Chương trình LLM cho Đánh giá LLM. Mã giả của
chương trình LLM tổng thể được đưa ra trong Thuật
toán 1. Để tính đến thiên lệch vị trí, chương trình
thực hiện hai lần chạy độc lập của BSM bằng cách
hoán đổi thứ tự mã hóa của các phản hồi trong mô-
đun 'solve'. Phán quyết cuối cùng là 'A' hoặc 'B'
nếu và chỉ nếu phán quyết là nhất quán cho cả hai
thứ tự, nếu không thì nó là 'hòa'.

3.3 BSM: Nghiên cứu Trường hợp với Tạo sinh có Ràng buộc

Mô tả Tác vụ. Nghiên cứu trường hợp tiếp theo
của chúng tôi cho thấy khả năng áp dụng tổng quát
của BSM bằng cách áp dụng nó cho một tác vụ hoàn
toàn khác, đó là tạo sinh LLM. Chúng tôi xem xét
một tác vụ tạo sinh câu chuyện có ràng buộc – cho
một tập hợp các khái niệm l, tác vụ là tạo ra một
câu chuyện nhất quán y bằng cách bao gồm tất cả
các khái niệm trong đó (xem Hình 3 trong Phụ lục).
Khi số lượng khái niệm lớn, LLM có xu hướng hoặc
bỏ lỡ một số khái niệm hoặc tạo ra văn bản không
nhất quán. Tác vụ yêu cầu sự sáng tác kết hợp các
ràng buộc khác nhau.

Mô-đun Branch cho Tạo sinh có Ràng buộc. Mô-
đun branch branch(l) → (l1, l2, t) đề xuất một kế
hoạch tạo sinh câu chuyện, bao gồm (1) hai tập con
của các khái niệm l1 và l2 và (2) một chủ đề câu
chuyện t. Hai tập con đại diện cho các vấn đề con
của tác vụ ban đầu với số lượng khái niệm nhỏ hơn.
Chủ đề câu chuyện đảm bảo rằng tất cả các câu
chuyện con được tạo ra như một phần của BSM thuộc
cùng một chủ đề.

Mô-đun Solve cho Tạo sinh có Ràng buộc. Mô-đun
solve solve(li, t) → yi dựa trên một tập con các
khái niệm li và chủ đề câu chuyện t để tạo ra một
câu chuyện yi về chủ đề đó, đồng thời cũng bao
gồm tất cả các khái niệm trong li. Trực quan, việc
'giải quyết' tác vụ tạo sinh có ràng buộc dễ dàng
hơn với số lượng khái niệm nhỏ hơn.

Mô-đun Merge cho Tạo sinh có Ràng buộc. Mô-đun
merge merge(y1, y2) → y dựa trên hai câu chuyện
trung gian và hợp nhất chúng lại với nhau để tạo
ra câu chuyện cuối cùng y. Vì cả hai câu chuyện
trung gian đều thuộc cùng một chủ đề cấp cao, việc
hợp nhất có thể dẫn đến một câu chuyện cuối cùng
nhất quán. Nhìn chung, BSM đảm bảo việc thỏa mãn
ràng buộc tốt hơn bằng cách giải quyết các vấn đề
con và duy trì tính nhất quán thông qua một kế
hoạch cấp cao bao gồm một chủ đề câu chuyện.

--- TRANG 6 ---
4 Thí nghiệm

4.1 Đánh giá Mô hình Ngôn ngữ Lớn

4.1.1 Thiết lập Thí nghiệm

Tập dữ liệu. Chúng tôi thí nghiệm với tập dữ liệu
MT-Bench, đánh giá LLM như thẩm phán của các
phản hồi LLM khác khi hoạt động như các trợ lý AI
hữu ích trong các cuộc hội thoại đa lượt (Zheng
et al., 2023). Nó bao gồm các hướng dẫn từ 8 lĩnh
vực đa dạng ví dụ như viết, suy luận, toán, lập trình,
v.v.

Chỉ số Đánh giá. Chúng tôi đánh giá BSM (và các
baseline) sử dụng bốn chỉ số sau.

•Sự Đồng thuận LLM-Con người (Ag). Theo công
trình trước đó (Zheng et al., 2023), chúng tôi báo
cáo sự đồng thuận LLM-con người ∈ [0,1] riêng
lẻ cho các câu hỏi lượt-1 và lượt-2, và sự kết hợp
của chúng.

•Thiên lệch Vị trí (PB). Để đánh giá liệu BSM có
giúp giảm vấn đề tính nhất quán với các bộ đánh
giá dựa trên LLM hay không, chúng tôi báo cáo
PB, đó là tỷ lệ các mẫu mà phán quyết thay đổi
dựa trên thứ tự mã hóa của các phản hồi.

•Thiên lệch Độ dài (LB). Chúng tôi đo LB như tỷ
lệ các mẫu mà con người ưa thích phản hồi ngắn
hơn nhưng mô hình đánh giá thì không. Nói cách
khác, chúng tôi tính toán tần suất một bộ đánh
giá chọn phản hồi dài hơn khi theo sở thích của
con người, nó không nên chọn như vậy.

•Thiên lệch Tự nâng cao (SB). SB đề cập đến một
mô hình đánh giá ưa thích các phản hồi của chính
nó. Đánh giá thiên lệch này một cách riêng lẻ là
thách thức vì biết khi nào mô hình chọn phản hồi
của chính nó vì thiên lệch này và không phải vì
lý do khác là một câu hỏi khả năng diễn giải. Tuy
nhiên, câu hỏi chúng tôi quan tâm nghiên cứu ở
đây là: Khi một LLM đang đánh giá các phản hồi
của chính nó (đây là hiện tượng phổ biến khi sử
dụng LLM như bộ đánh giá), BSM có dẫn đến
đánh giá tốt hơn và đáng tin cậy hơn không? Chúng
tôi đo điều này bằng cách xem xét môi trường sau.
Chúng tôi sử dụng GPT-4 như mô hình thẩm phán
cơ sở và xem xét tập con các mẫu từ benchmark
MT-Bench mà một trong các phản hồi cũng được
tạo ra bởi GPT-4. Nếu BSM với GPT-4 cải thiện
sự đồng thuận con người-mô hình cho tập con mẫu
này, nó gợi ý rằng ngay cả trong các tình huống
mà mô hình A đang đánh giá các đầu ra của chính
nó, BSM (với mô hình A) dẫn đến một bộ đánh
giá tốt hơn. Mặc dù điều này không nhất thiết tính
toán liệu một bộ đánh giá có ít SB hơn hay không,
nó xác nhận liệu mô hình đánh giá có tương quan
tốt hơn với con người ngay cả khi nó đang đánh
giá các phản hồi của chính nó.

Mặc dù nhiều công trình trước đây đã nhấn mạnh
tầm quan trọng của những thiên lệch này (Zheng
et al., 2023; Wu và Aji, 2023), chúng tôi đo tất cả
chúng với các chỉ số cụ thể trong cùng một khung
đánh giá. Về mặt khái niệm, 'Ag' đánh giá độ chính
xác trong khi 'PB' chẳng hạn đánh giá tính nhất
quán của các bộ đánh giá dựa trên LLM. Đây là các
khía cạnh bổ sung và một bộ đánh giá lý tưởng nên
hoạt động tốt trong tất cả các chỉ số để có thể được
sử dụng một cách đáng tin cậy.

Chi tiết Triển khai. Chúng tôi phát triển BSM trên
nhiều LLM có quy mô và khả năng khác nhau:
LLaMA-2-7B-chat, Vicuna-33B, LLaMA-2-70B-chat
và GPT-4. Chúng tôi triển khai tất cả các mô-đun
zero-shot, chỉ cung cấp các hướng dẫn cụ thể cho
mô-đun và giả định không có quyền truy cập vào
các minh họa về cách phân nhánh, giải quyết hoặc
hợp nhất.

Baseline. Chúng tôi so sánh phương pháp của mình,
BSM, với (1) hai biến thể của prompt zero-shot
với cùng LLM: một bộ đánh giá tương đối, tạo ra
trực tiếp một phán quyết ưu tiên và một bộ đánh
giá tuyệt đối, tạo ra hai điểm số cho hai phản hồi
và sau đó sở thích cuối cùng được xác định dựa
trên điểm số cao hơn, (2) prompt plan&solve (Wang
et al., 2023a), lập kế hoạch (tức là tạo ra các tiêu
chí đánh giá) nhưng thay vì giải quyết chúng độc
lập, giải quyết tất cả các nhánh cùng nhau trong
một lần gọi LLM, (3) tự nhất quán (Wang et al.,
2022), lấy mẫu nhiều đánh giá từ LLM được prompt
(với nhiệt độ 0.7) và chọn bỏ phiếu đa số như phán
quyết cuối cùng. Để so sánh công bằng, tự nhất
quán lấy mẫu cùng số lượng tạo sinh như hệ số phân
nhánh trong BSM. Chúng tôi cũng lưu ý rằng tự
nhất quán là một trường hợp đặc biệt đơn giản của
BSM, trong đó mô-đun branch tạo ra nhiều thể hiện
của cùng một vấn đề cơ bản (thay vì các vấn đề con),
giải quyết chúng bằng cách lấy mẫu các giải pháp
khác nhau, và toán tử hợp nhất là bỏ phiếu đa số.
Tham khảo Phụ lục A để biết thêm chi tiết về tập
dữ liệu, triển khai và baseline.

4.1.2 Kết quả Chính

BSM cải thiện sự đồng thuận LLM-con người và
giảm thiên lệch. Bảng 1 đánh giá hiệu quả của BSM
với LLaMA-2-70B-chat như LLM cơ sở, đặc biệt
tập trung vào danh mục câu hỏi 'viết' từ benchmark
MT-Bench. Chúng tôi báo cáo các phát hiện chính
dưới đây.

•Sự đồng thuận tổng thể. Chúng tôi thấy rằng BSM
cải thiện sự đồng thuận LLM-con người cho cả câu
hỏi lượt-1 và lượt-2, so với tất cả các baseline. Cụ

--- TRANG 7 ---
Phương pháp    Tổng thể              Lượt-1               Lượt-2
               Ag↑  PB↓  LB↓        Ag↑  PB↓  LB↓      Ag↑  PB↓  LB↓
Zero-shot (Tương đối) 0.43 51.66 54.88  0.53 42.66 50.00  0.34 60.66 59.42
Zero-shot (Tuyệt đối) 0.45 30.00 48.87  0.56 19.33 43.75  0.34 40.66 53.62
Plan&Solve     0.43 43.00 54.13      0.43 42.00 51.56    0.43 44.00 56.52
Tự nhất quán   0.52 35.66 48.12      0.57 32.00 45.31    0.47 39.33 50.72
BSM            0.55 17.33 39.09      0.60 14.66 39.46    0.50 20.00 39.13

Bảng 1: So sánh các bộ đánh giá LLM zero-shot (Tương đối và Tuyệt đối), Plan&Solve, Tự nhất quán và BSM trên các câu hỏi 'viết' trong tập dữ liệu MT-Bench. Tất cả các phương pháp sử dụng LLaMA-2-70B-chat như LLM cơ sở. Chúng tôi báo cáo Sự Đồng thuận LLM-Con người (Ag), Thiên lệch Vị trí (PB) và Thiên lệch Độ dài (LB) cho các câu hỏi lượt-1 và lượt-2 tổng thể và riêng lẻ. BSM cải thiện điểm đồng thuận và giảm thiên lệch vị trí và độ dài.

            Ag↑   PB↓   LB↓
Zero-shot (với GPT-4) 0.51 6.33 36.36
BSM (với GPT-4)       0.54 7.33 34.54

Bảng 2: BSM dẫn đến ít thiên lệch tự nâng cao hơn. BSM đạt được sự đồng thuận tốt hơn cho tỷ lệ các mẫu mà một trong các phản hồi cũng được tạo ra bởi GPT-4.

thể, nó đạt được cải thiện tuyệt đối lên đến 12% so với Plan&Solve, điều này đặc biệt cho thấy tính hữu ích của việc phân nhánh thành và giải quyết các vấn đề con độc lập. BSM cũng vượt trội Tự nhất quán. Như đã lưu ý trước đó, Tự nhất quán là một trường hợp đặc biệt của BSM. Kết quả này đáng chú ý vì cả hai cách tiếp cận đều tận dụng lượng tính toán tương tự trong việc tạo ra nhiều giải pháp – nhưng việc phân nhánh và giải quyết các vấn đề con khác nhau cung cấp kết quả vượt trội so với việc giải quyết cùng một vấn đề nhiều lần.

•Câu hỏi Lượt-1 so với Lượt-2. Đánh giá các câu hỏi lượt-2 khó hơn vì nó yêu cầu việc ngữ cảnh hóa bổ sung của các phản hồi cho câu hỏi lượt-1. Điều này cũng được phản ánh trong tất cả các phương pháp baseline (ngoại trừ plan&solve) thể hiện điểm đồng thuận lượt-2 thấp hơn (ví dụ, kết quả zero-shot giảm từ 0.53 ở lượt-1 xuống 0.34 ở lượt-2). BSM cho thấy rằng một cách tiếp cận phân tách tạo ra kế hoạch đánh giá đặc biệt hữu ích cho việc đánh giá các câu hỏi ngữ cảnh dài, dẫn đến nhiều cải thiện hơn cho các câu hỏi lượt-2 (ví dụ, cải thiện lên đến 16%). Một minh họa được hiển thị trong Hình 2, trong đó đối với câu hỏi lượt-2, mô hình tạo ra 'Tuân thủ Hướng dẫn' như tiêu chí đầu tiên để đánh giá.

•Giảm Thiên lệch Vị trí và Độ dài. Ngoài việc cải thiện sự đồng thuận LLM-con người, BSM giúp giảm các thiên lệch quan trọng với các bộ đánh giá dựa trên LLM (ví dụ, giảm PB lên đến 34%). Đây là hệ quả trực tiếp của việc phân tách tác vụ của BSM giúp giảm sự không nhất quán trong đánh giá.

Phương pháp                           Ag ↑  PB↓  LB↓
Zero-shot (với LLaMA-2-7B-chat)      0.39 62.33 54.88
BSM (với LLaMA-2-7B-chat)            0.41 48.33 53.38
Zero-shot (với Vicuna-33B)           0.51 30.66 48.12
BSM (với Vicuna-33B)                 0.56 20.00 42.85
Zero-shot (với LLaMA-2-70B-chat)     0.43 51.66 54.88
BSM (với LLaMA-2-70B-chat)           0.55 17.33 39.09
Zero-shot (với GPT-4)                0.59 17.33 39.09
BSM (với GPT-4)                      0.62 17.00 36.84

Bảng 3: So sánh đánh giá zero-shot và BSM trên các câu hỏi 'viết' với các bộ đánh giá LLM cơ sở khác nhau. BSM cải thiện sự đồng thuận cho tất cả các mô hình và giảm thiên lệch cho tất cả các mô hình ngoại trừ GPT-4.

Việc giảm LB của BSM có thể được quy cho điều sau: khi một bộ đánh giá phân nhánh thành các tiêu chí khác nhau, nếu 'độ dài' thực sự là một trong những tiêu chí mà các phản hồi nên được đánh giá theo, nó chỉ tính như một nhánh duy nhất (tức là một vấn đề con) của đánh giá tổng thể và do đó, việc phân nhánh cho phép mô hình đánh giá rõ ràng cho các tiêu chí khác, ngoài chỉ độ dài.

•Giảm Thiên lệch Tự nâng cao. Bảng 2 đánh giá thiên lệch tự nâng cao bằng cách so sánh BSM (với GPT-4 zero-shot) cho các mẫu mà một trong các phản hồi cũng được tạo ra bởi GPT-4. Chúng tôi quan sát thấy tương quan tốt hơn 3% với con người, gợi ý rằng BSM cải thiện đánh giá ngay cả khi LLM đánh giá các đầu ra của chính nó.

BSM không chỉ dẫn đến cải thiện trong sự đồng thuận LLM-con người tổng thể (theo chỉ số 'Ag') mà còn trên tỷ lệ các mẫu mà một phản hồi được tạo ra bởi cùng LLM đánh giá (theo chỉ số 'SB'), do đó chỉ ra sự mạnh mẽ của nó như một phương pháp đánh giá. Tóm lại, BSM cải thiện cả độ chính xác và tính nhất quán của các bộ đánh giá dựa trên LLM.

BSM cải thiện trên tất cả các LLM cơ sở zero-shot.
Chúng tôi chứng minh khả năng tổng quát hóa của
BSM như một chương trình LLM bằng cách triển khai
nó trên bốn

--- TRANG 8 ---
Phương pháp           Lập trình           Suy luận             Toán
                   Ag↑  PB↓  LB↓     Ag↑  PB↓  LB↓      Ag↑  PB↓  LB↓
Zero-shot (với LLaMA-2-70B-c) 0.47 52.33 51.32  0.47 38.00 48.75  0.52 45.66 50.56
BSM (với LLaMA-2-70B-c)       0.61 25.66 42.47  0.57 20.33 46.25  0.64 17.66 34.83
GPT-4                         0.61 19.66 38.93  0.64 22.66 53.75  0.62 19.00 39.32

Bảng 4: Đánh giá LLM dựa trên tham chiếu cho các danh mục câu hỏi 'Lập trình', 'Suy luận' và 'Toán' của MT-Bench. BSM cải thiện các đánh giá dựa trên tham chiếu và đối với toán, vượt trội GPT-4.

Lĩnh vực      Phương pháp                   Tổng thể              Lượt-1               Lượt-2
                                        Ag↑  PB↓  LB↓       Ag↑  PB↓  LB↓       Ag↑  PB↓  LB↓
Nhập vai      Zero-shot (với LLaMA-2-70B-c) 0.55 29.66 51.67   0.61 30.00 48.14   0.50 29.33 55.88
              BSM (với LLaMA-2-70B-c)       0.61 11.00 40.26   0.66 10.66 38.27   0.56 11.33 42.64
              GPT-4                         0.64 13.66 43.62   0.65 16.00 45.67   0.63 11.33 41.17

Trích xuất    Zero-shot (với LLaMA-2-70B-c) 0.40 70.66 51.82   0.46 61.33 51.47   0.33 80.00 52.08
              BSM (với LLaMA-2-70B-c)       0.55 31.33 40.24   0.55 32.00 45.58   0.44 30.66 36.45
              GPT-4                         0.71 15.00 33.53   0.68 13.33 35.29   0.75 16.66 32.29

Khoa học      Zero-shot (với LLaMA-2-70B-c) 0.46 59.33 55.31   0.50 52.66 51.19   0.43 66.00 61.40
              BSM (với LLaMA-2-70B-c)       0.72 10.33 44.68   0.70 10.66 40.47   0.73 10.00 50.87
              GPT-4                         0.72 13.66 46.80   0.68 16.66 44.04   0.75 10.66 50.87

Nhân văn      Zero-shot (với LLaMA-2-70B-c) 0.46 59.00 45.69   0.51 52.00 49.18   0.41 66.00 43.33
              BSM (với LLaMA-2-70B-c)       0.67 18.00 36.42   0.63 18.00 39.34   0.71 18.00 34.44
              GPT-4                         0.73 14.00 37.08   0.70 19.33 42.62   0.76 8.66 33.33

Bảng 5: Đánh giá LLM cho các danh mục câu hỏi 'Nhập vai', 'Trích xuất', 'Khoa học' và 'Nhân văn' của MT-Bench. Chúng tôi so sánh LLaMA-2-70B-chat BSM với phương pháp baseline zero-shot và cũng báo cáo kết quả GPT-4. BSM đạt được cải thiện đáng kể so với baseline LLaMA và bằng hoặc gần với sự đồng thuận GPT-4 trong ba trong bốn lĩnh vực, đôi khi vượt trội GPT-4 trong việc giảm thiên lệch.

LLM cơ sở khác nhau, từ LLaMA-2-7B đến GPT-4. Như được hiển thị trong Bảng 3, BSM cải thiện sự đồng thuận với con người cho tất cả các LLM cơ sở, so với baseline zero-shot. Mặc dù GPT-4 zero-shot là bộ đánh giá LLM tiên tiến nhất, việc áp dụng BSM đạt được cải thiện thêm 3%. Hơn nữa, việc áp dụng BSM cho LLaMA-2-70B-chat làm cho nó cạnh tranh với GPT-4 cho các câu hỏi lượt-1. BSM cũng giảm đáng kể thiên lệch vị trí và độ dài cho tất cả các mô hình ngoại trừ GPT-4.

BSM tổng quát hóa cho các đánh giá dựa trên tham chiếu. Chúng tôi thấy rằng BSM cũng xuất sắc trong các đánh giá dựa trên tham chiếu cho các tác vụ phức tạp như toán, suy luận và lập trình (Cobbe et al., 2021; Wei et al., 2022). Theo công trình trước đó (Zheng et al., 2023), chúng tôi đánh giá phản hồi cho các danh mục này bằng cách đầu tiên tạo ra một câu trả lời sử dụng GPT-4 và sau đó thêm nó vào prompt đánh giá, đây là baseline trong thí nghiệm này. Đối với BSM, chúng tôi sau đó tuân theo một công thức tương tự bằng cách điều kiện mô-đun 'solve' trên các câu trả lời được tạo ra bởi GPT-4. Giả định chính ở đây là những câu trả lời này được tuyển chọn một lần và có các biến thể hạn chế không như câu trả lời cho các câu hỏi mở. Bảng 4 cho thấy rằng BSM vượt trội đáng kể so với baseline zero-shot trong tất cả các danh mục (cải thiện điểm đồng thuận lên đến 14% và thiên lệch vị trí tốt hơn 27% trong các câu hỏi lập trình). Trên Toán, nó thậm chí vượt trội bộ đánh giá GPT-4 tiên tiến, vượt trội trên tất cả các chỉ số.

BSM tổng quát hóa qua các lĩnh vực khác. Bảng 5 cho thấy rằng BSM có khả năng đánh giá các sản phẩm tạo sinh cho các câu hỏi trong các danh mục khác như 'Nhập vai', 'Trích xuất', 'Khoa học' và 'Nhân văn', với những phát hiện tương tự. Xem Phụ lục A.2 để biết chi tiết.

Khả năng mở rộng của việc phân nhánh BSM. Một trong những điểm mạnh cốt lõi của BSM là khả năng mở rộng của nó – nó sử dụng cùng một prompt branch (trong Hình 4) cho tất cả các lĩnh vực đánh giá (ví dụ, viết, mã, suy luận, v.v.). Prompt chỉ chỉ định ý nghĩa của một nhánh cho một tác vụ nhất định và LLM có khả năng tạo ra các nhánh riêng của nó cho các lĩnh vực khác nhau mà không cần sự can thiệp của con người. Chúng tôi quan sát thấy hầu như không có sự chồng chéo giữa tên nhánh của các câu hỏi lập trình và câu hỏi viết. Ví dụ, các 'nhánh viết' xuất hiện nhiều nhất là Độ rõ ràng, Mức độ liên quan, Sáng tạo, Độ chính xác, Sự hấp dẫn, Tính nhất quán, Tính độc đáo, Tính đầy đủ, Ngữ pháp và Khả năng đọc, v.v. trong khi các 'nhánh lập trình' xuất hiện nhiều nhất là Hiệu quả, Tính đầy đủ, Độ chính xác, Tính chính xác, Khả năng Đọc Mã, Trải nghiệm Người dùng, Hiệu quả Thời gian. Các nhánh cho các câu hỏi thuộc cùng một lĩnh vực thể hiện sự chồng chéo nhiều hơn, được đo bằng tên của các nhánh. Ví dụ, 'Tính chính xác' là một nhánh được tạo ra để đánh giá hầu như tất cả các vấn đề lập trình; tuy nhiên, mô tả của chúng khác nhau và cụ thể cho vấn đề (xem Hình 2 để có ví dụ).

4.2 Tạo sinh Văn bản có Ràng buộc

4.2.1 Thiết lập Thí nghiệm

Tập dữ liệu. Tác vụ tạo sinh câu chuyện có ràng buộc của chúng tôi là một biến thể thách thức hơn của một tác vụ suy luận thông thường tạo sinh, CommonGen (Lin et al., 2020). Trong khi tác vụ ban đầu yêu cầu tạo ra một câu nhất quán từ 3 hoặc 4 khái niệm, chúng tôi tăng độ phức tạp của tác vụ bằng cách yêu cầu mô hình tạo ra một câu chuyện súc tích bao gồm 10 khái niệm (Madaan et al., 2023)†. Chúng tôi thí nghiệm với 100 mẫu cho mục đích của nghiên cứu này.

Chỉ số Đánh giá. Chúng tôi đánh giá các câu chuyện được tạo ra theo hai trục: thỏa mãn ràng buộc và chất lượng câu chuyện tổng thể. Đối với thỏa mãn ràng buộc, chúng tôi báo cáo hai chỉ số: (a) Tất cả Có mặt (AP): tỷ lệ các mẫu mà tất cả ràng buộc được thỏa mãn tức là không có khái niệm bị thiếu, và (b) Khái niệm Thiếu (MC): tỷ lệ phần trăm trung bình các khái niệm bị thiếu. 'Tất cả có mặt' cao hơn và 'khái niệm thiếu' thấp hơn là tốt hơn. Chúng tôi xác định một khái niệm bị thiếu nếu nó không xuất hiện trong câu chuyện dưới bất kỳ dạng từ nào. Để đánh giá chất lượng câu chuyện tổng thể, chúng tôi tiến hành đánh giá cặp đôi với GPT-4. Prompt đánh giá được cung cấp trong Hình 7. Để tính đến thiên lệch vị trí trong so sánh cặp đôi này, chúng tôi tuân theo các phát hiện của chúng tôi từ tác vụ Đánh giá LLM và tiến hành mỗi đánh giá hai lần, bằng cách hoán đổi thứ tự của các câu chuyện và ưa thích một câu chuyện hơn cái khác chỉ khi các đánh giá nhất quán.

Chi tiết Triển khai. Chúng tôi đánh giá BSM sử dụng LLaMA-2-7B-chat và LLaMA-2-70B-chat. Tất cả các mô-đun tạo ra văn bản sử dụng giải mã tham lam. Đối với mô-đun branch, LLM được prompt để chia các khái niệm thành hai nhóm.

Baseline. Chúng tôi so sánh BSM với (1) prompt zero-shot với cùng LLM: cho một tập hợp các khái niệm, tạo ra trực tiếp câu chuyện, (2) prompt plan&solve, đầu tiên đề xuất một chủ đề câu chuyện (như một kế hoạch) và sau đó tạo ra một câu chuyện về chủ đề đó,

†https://github.com/madaan/self-refine/blob/main/data/prompt/commongen/commongen_hard.jsonl

Phương pháp         LLaMA-2-7B-chat   LLaMA-2-70B-chat
                    AP↑    MC↓        AP↑    MC↓
Zero-shot           15.0   17.3       22.0   27.2
Plan&Solve          13.0   18.0       21.0   26.6
Tự Nhất quán        19.0   16.6       24.0   20.1
BSM                 23.0   15.5       28.0   14.7

Bảng 6: Kết quả đánh giá tạo sinh câu chuyện có ràng buộc. BSM (với cả hai mô hình LLaMA-2) cải thiện việc thỏa mãn ràng buộc trong các câu chuyện được tạo ra.

(3) tự nhất quán, trong đó chúng tôi đầu tiên lấy mẫu nhiều câu chuyện và sau đó prompt LLM một lần nữa để chọn một trong các câu chuyện được lấy mẫu có nhiều ràng buộc được thỏa mãn hơn.

4.2.2 Kết quả và Phân tích

Thỏa mãn Ràng buộc. Kết quả chính của chúng tôi được đưa ra trong Bảng 6. Chúng cho thấy rằng BSM với cả hai biến thể mô hình vượt trội tất cả các baseline trên các chỉ số thỏa mãn ràng buộc của chúng tôi. Chúng tôi cũng lưu ý rằng đây vẫn là một tác vụ thách thức ngay cả đối với mô hình LLaMA-2-70B-chat mạnh hơn và quy mô của mô hình có ít tác động đến việc thỏa mãn ràng buộc. Ví dụ, ngay cả BSM với LLaMA-2-70B-chat vẫn bỏ lỡ ít nhất một khái niệm cho 72% các mẫu, phản ánh các phát hiện từ công trình trước đó rằng tạo sinh văn bản có ràng buộc là khó ngay cả đối với các LLM tiên tiến (Yao et al., 2023a). Chúng tôi cung cấp phân tích về các khái niệm bị thiếu trong BSM ở Phụ lục B.

Chất lượng Câu chuyện Tổng thể. BSM không chỉ thỏa mãn nhiều ràng buộc hơn mà hầu như luôn tạo ra một câu chuyện nhất quán hơn. Chúng tôi thấy rằng trong so sánh trực tiếp với baseline prompt zero-shot (với LLaMA-2-70B-chat), các câu chuyện được tạo ra bởi BSM được ưa thích đáng kể 93% số lần bởi GPT-4. Điều này có thể được quy cho hai khía cạnh của BSM. Thứ nhất, trong mỗi nhánh, mô hình dựa trên số lượng khái niệm ít hơn và do đó tạo ra các câu chuyện trung gian mà bản thân chúng nhất quán hơn. Thứ hai, trong bước hợp nhất, mô hình có thể dựa trên hai câu chuyện trung gian này và tạo ra một câu chuyện cuối cùng cải thiện thêm tính nhất quán.

5 Kết luận

Chúng tôi đã trình bày BSM, một chương trình LLM để cải thiện đánh giá và tạo sinh LLM. Chúng tôi đã tiến hành hai nghiên cứu trường hợp với các triển khai khác nhau của các mô-đun branch, solve và merge, thể hiện hiệu quả và khả năng tổng quát hóa của BSM.

--- TRANG 10 ---
Hạn chế

Chúng tôi liệt kê các hạn chế của công trình chúng tôi dưới đây.

1. Đánh giá về an toàn, độc tính và thiên lệch trong các sản phẩm tạo sinh LLM cũng quan trọng cho việc đánh giá toàn diện LLM, tuy nhiên, chúng tôi không đề cập đến chủ đề này trong bài báo của mình.

2. Mặc dù BSM đạt được cải thiện trong thiên lệch độ dài, chúng tôi lưu ý rằng việc đo thiên lệch độ dài một cách riêng lẻ là thách thức vì biết liệu mô hình ưa thích phản hồi dài hơn vì độ dài của nó (và không phải vì lý do khác) là một câu hỏi khả năng diễn giải và con người cũng có xu hướng ưa thích các phản hồi dài hơn, đặc biệt là cho các câu hỏi mở.

3. BSM đệ quy hoặc đa cấp, trong đó một LLM đệ quy phân nhánh thành các tác vụ con song song là một hướng thú vị cho công việc tương lai nhưng chúng tôi không khám phá điều này trong công trình này do chi phí tính toán tăng lên.

4. Phân tách thành các tác vụ con song song cũng nên giúp cải thiện hiệu quả (ví dụ, so với các phân tách tuần tự) (Ning et al., 2023) nhưng trong công trình này, thay vào đó chúng tôi tập trung vào việc cải thiện hiệu suất tác vụ.

Lời cảm ơn

Các tác giả cảm ơn các nhà đánh giá vì những nhận xét và gợi ý hữu ích của họ.

Tài liệu tham khảo

[Các tài liệu tham khảo được liệt kê theo định dạng học thuật tiêu chuẩn]

--- TRANG 11 ---
[Tiếp tục danh sách tài liệu tham khảo]

--- TRANG 12 ---
[Tiếp tục danh sách tài liệu tham khảo]

--- TRANG 13 ---
                    Ag↑   PB↓   LB↓
Zero-shot (với LLaMA-2-70B-c) 0.46 34.00 45.00
BSM (với LLaMA-2-70B-c)       0.48 23.77 40.25

Bảng 7: Kết quả đánh giá không tham chiếu của các câu hỏi 'Suy luận'. BSM vượt trội baseline zero-shot trong việc đánh giá các câu hỏi 'Suy luận', ngay cả khi không sử dụng câu trả lời tham chiếu (trên một tập con ngẫu nhiên 100 mẫu).

[Tiếp tục danh sách tài liệu tham khảo cho đến cuối trang]

A Thí nghiệm Bổ sung: Đánh giá LLM

A.1 Thiết lập Thí nghiệm

Tập dữ liệu. Chúng tôi thí nghiệm với tập dữ liệu MT-Bench, đánh giá LLM như thẩm phán của các phản hồi LLM khác khi hoạt động như các trợ lý AI hữu ích trong các cuộc hội thoại đa lượt (Zheng et al., 2023). Nó bao gồm 2400 phản hồi LLM và 3000 phán quyết chuyên gia của con người. Các đầu ra LLM là phản hồi cho 80 hướng dẫn đại diện từ 8 lĩnh vực đa dạng: viết, nhập vai, trích xuất, suy luận, toán, lập trình, kiến thức I (STEM) và kiến thức II (nhân văn/khoa học xã hội). Mỗi câu hỏi là một câu hỏi đối thoại, bao gồm hai lượt, trong đó câu hỏi lượt-2 là câu hỏi tiếp theo của câu hỏi lượt-1. Đối với mỗi câu hỏi, tập dữ liệu bao gồm các phản hồi từ 6 LLM khác nhau (Alpaca-13B, Vicuna-13b, LLaMA-13B, Claude-v1, GPT-3.5-turbo và GPT-4), dẫn đến 15 cặp phản hồi có thể. Do đó, toàn bộ tập đánh giá bao gồm 300 mẫu cặp phản hồi mỗi danh mục.

--- TRANG 14 ---
                    Tổng thể              Lượt 1               Lượt 2
                    Ag↑  PB↓  LB↓       Ag↑  PB↓  LB↓       Ag↑  PB↓  LB↓
BSM                 0.55 17.33 39.09    0.60 14.66 39.46    0.50 20.00 39.13
BSM + SC            0.55 15.33 39.09    0.61 10.66 39.06    0.49 20.00 39.13

Bảng 8: Hiệu ứng của việc sử dụng Tự nhất quán trong mỗi nhánh của BRANCH-SOLVE-MERGE (BSM+SC). Kết quả với mô hình LLaMA-2-70B-chat. Mặc dù điểm đồng thuận tổng thể không cải thiện thêm, chúng tôi đạt được giảm thiên lệch vị trí thêm 2%.

Tổng thể    Lượt 1    Lượt 2
Vicuna-33B          0.52      0.53      0.51
BSM (với Vicuna-33B) 0.55      0.56      0.54
LLaMA-2-70B         0.48      0.58      0.37
BSM (với LLaMA-2-70B) 0.53      0.59      0.47
GPT-4               0.61      0.59      0.63
BSM (với GPT-4)     0.63      0.63      0.62

Bảng 9: Điểm đồng thuận LLM-Con người cho các câu hỏi danh mục 'viết' (tổng thể và riêng lẻ cho lượt-1 và lượt-2). Ở đây sự đồng thuận được tính bằng cách sử dụng bỏ phiếu đa số (thay vì coi mỗi phiếu bầu của con người cho mỗi mẫu một cách độc lập).

Chi tiết Triển khai. Thuật toán 1 cho thấy chương trình LLM. Để tái tạo tốt hơn, tất cả các mô-đun trong BSM tạo ra văn bản sử dụng giải mã tham lam. Đối với mô-đun branch, LLM được prompt để tạo ra một kế hoạch bao gồm tối đa năm tiêu chí đánh giá (mà chúng tôi thấy nó tuân thủ trong các thí nghiệm). Đối với mô-đun merge, chúng tôi thấy rằng merge phi neural đơn giản của việc cộng các đánh giá theo tiêu chí là đơn giản và hoạt động tốt trong thực tế, do đó tất cả kết quả thí nghiệm của chúng tôi được báo cáo với phương pháp đó. Các prompt được hiển thị trong Hình 4 và 5. Tất cả các thí nghiệm được chạy trên một cụm AWS với 8 GPU A100.

Baseline. Tất cả các phương pháp, bao gồm BSM, tính đến thiên lệch vị trí theo cùng một cách, tạo ra một phán quyết cho cả hai thứ tự mã hóa và chọn phán quyết cuối cùng dựa trên các phán quyết riêng lẻ (gán hòa nếu hai thứ tự mã hóa không đồng ý). Cụ thể, Tự nhất quán tính bỏ phiếu đa số độc lập cho mỗi thứ tự mã hóa.

A.2 Kết quả và Phân tích

BSM tổng quát hóa tốt qua các lĩnh vực. Trong Bảng 5, chúng tôi đánh giá khả năng của BSM trong việc đánh giá các sản phẩm tạo sinh cho các câu hỏi trong các danh mục 'Nhập vai', 'Trích xuất', 'Khoa học' và 'Nhân văn'. Chúng tôi thấy rằng BSM mạnh mẽ và hoạt động tốt qua các lĩnh vực về mặt cải thiện so với baseline LLaMa-2-70B-chat, và tiếp cận hiệu suất GPT-4 trên một số lĩnh vực. Cụ thể, trên lĩnh vực Khoa học, nó có thể cải thiện điểm đồng thuận so với baseline lên đến 26% (tuyệt đối), bằng GPT-4, và thậm chí vượt trội nó về thiên lệch vị trí và độ dài. Bảng 7 cho thấy rằng BSM vượt trội baseline zero-shot cho các câu hỏi 'Suy luận', ngay cả trong các đánh giá không tham chiếu (tức là các câu trả lời được tạo ra bởi GPT-4 không được sử dụng trong baseline hoặc trong BSM).

Kết hợp BSM và SC giảm thiên lệch vị trí hơn nữa. BSM tạo ra một giải pháp duy nhất cho mỗi vấn đề con (mỗi nhánh). Một cải tiến có thể là kết hợp BSM với tự nhất quán tức là lấy mẫu nhiều giải pháp cho mỗi vấn đề con. Cụ thể, chúng tôi triển khai BSM+SC bằng cách lấy mẫu năm đánh giá cho mỗi nhánh (với nhiệt độ 0.7) và sau đó điểm số cho mỗi đánh giá con trong nhánh đó được tính bằng điểm số trung bình. Chúng tôi so sánh BSM với BSM+SC trong Bảng 8. Mặc dù điểm đồng thuận không cải thiện thêm, chúng tôi quan sát thấy giảm 2%

--- TRANG 15 ---
                    Tổng thể              Lượt-1               Lượt-2
BF    Ag ↑  PB↓  LB↓    Ag↑  PB↓  LB↓    Ag↑  PB↓  LB↓
2     0.50 22.00 49.20  0.49 24.00 45.00  0.50 22.00 56.52
3     0.52 19.00 38.09  0.53 14.00 35.00  0.51 24.00 43.47
4     0.53 19.00 38.09  0.51 16.00 35.00  0.55 22.00 43.47
5     0.52 12.00 34.92  0.51 12.00 35.00  0.54 12.00 34.78

Bảng 10: Tác động của Hệ số Phân nhánh tối đa (BF) trên 100 mẫu của danh mục 'viết' trong đánh giá phản hồi LLM với BSM trên LLaMA-2-70B-chat.

Kỹ thuật Giải quyết    Tổng thể              Lượt-1               Lượt-2
                       Ag↑  PB↓  LB↓        Ag↑  PB↓  LB↓        Ag↑  PB↓  LB↓
Thang đánh giá (1-5)   0.52 12.00 34.92    0.51 12.00 35.00    0.54 12.00 34.78
Thang đánh giá (1-10)  0.50 18.00 36.50    0.51 18.00 40.00    0.50 18.00 30.43

Bảng 11: Phân tích thang đánh giá cho đánh giá phản hồi LLM, với 100 mẫu của danh mục 'viết'. BSM (với LLaMA-2-70B-chat) khá mạnh mẽ với những biến thể như vậy.

trong thiên lệch vị trí. Điều này chỉ ra hai kết luận. Thứ nhất, BSM, thông qua cách tiếp cận phân tách của nó, đã xây dựng các vấn đề con đủ chi tiết và do đó, việc giảm phương sai mà người ta đạt được thông qua tự nhất quán trong mỗi vấn đề con là hạn chế. Tuy nhiên, việc giảm vừa phải trong thiên lệch vị trí vẫn phản ánh tính hữu ích của nó, đây là hiệu ứng trực tiếp của việc làm cho các đánh giá nhất quán hơn.

Hiệu ứng của Hệ số Phân nhánh. BSM có lợi ích của việc dựa vào LLM cơ bản để quyết định phân nhánh thành những vấn đề con nào, trong khi prompt kiểm soát hệ số phân nhánh tối đa (xem cụm từ 'danh sách lên đến năm yếu tố' trong prompt branch trong Hình 4). Chúng tôi thay đổi hệ số phân nhánh tối đa này từ 2 đến 5 và nghiên cứu hiệu ứng của nó trên 100 mẫu từ danh mục câu hỏi 'viết'. Bảng 10 báo cáo các phát hiện của chúng tôi. Chúng tôi quan sát thấy sự đồng thuận cao nhất ở hệ số phân nhánh 4, sau đó kết quả hầu như bão hòa. Nói chung, hệ số phân nhánh tối ưu nên phụ thuộc vào câu hỏi cụ thể đang được xem xét và không như công trình trước đó mà người dùng chỉ định các yếu tố nào để đánh giá (Liu et al., 2023; Zheng et al., 2023), BSM tạo ra kế hoạch đó tự mình. Thiên lệch vị trí tiếp tục giảm với hệ số phân nhánh tăng, trong đó nhiều nhánh hơn giúp giảm phương sai trong phán quyết cuối cùng.

BSM mạnh mẽ với thang đánh giá. Các tác vụ đánh giá, nói chung, yêu cầu định nghĩa một thang để chấm điểm các phản hồi. Trong Bảng 11, chúng tôi so sánh hiệu suất của BSM bằng cách thay đổi thang đánh giá này, được chỉ định trong prompt 'solve' (xem Hình 5), hoặc chấm điểm 1-5 (được sử dụng trong các thí nghiệm chính) hoặc 1-10. Chúng tôi quan sát thấy rằng BSM khá mạnh mẽ với những biến thể như vậy, đạt được điểm đồng thuận tương đương. Tuy nhiên, thiên lệch vị trí tăng nhẹ với thang lớn hơn.

B Thí nghiệm Bổ sung: Tạo sinh Văn bản có Ràng buộc

Phân tích Các Khái niệm Thiếu trong BSM. Nguồn gốc của các khái niệm thiếu trong BSM có thể được quy cho một trong hai danh mục sau: (a) mô-đun 'solve', tức là mô hình bỏ lỡ các khái niệm ngay cả khi tạo ra một câu chuyện trung gian trong một vấn đề con nhánh với số lượng khái niệm ít hơn; hoặc (b) mô-đun 'merge', tức là các câu chuyện trung gian bao gồm các khái niệm tương ứng của chúng nhưng quá trình hợp nhất bỏ lỡ một số trong những khái niệm này. Chúng tôi quan sát thấy rằng trong số 72% các câu chuyện BSM (với LLaMA-2-70B-chat) mà ít nhất một khái niệm bị thiếu, đáng kể 60% trong số này thuộc danh mục đầu tiên (tức là bỏ lỡ khái niệm trong mô-đun 'solve') so với chỉ 12% thuộc danh mục thứ hai (tức là bỏ lỡ khái niệm trong quá trình 'hợp nhất'). Điều này gợi ý rằng việc thỏa mãn ràng buộc có thể được cải thiện thêm thông qua phương pháp BSM 'đệ quy' liên quan đến việc phân nhánh lặp lại thành các vấn đề con chi tiết hơn. Tuy nhiên, BSM đệ quy sẽ đắt đỏ hơn đáng kể vì có nhiều lần gọi LLM cơ sở hơn. Chúng tôi để việc khám phá này như một phần của công việc tương lai.

--- TRANG 16 ---
[Các hình và thuật toán với các prompt chi tiết cho các mô-đun Branch, Solve và Merge được hiển thị]

--- TRANG 17 ---
[Tiếp tục các hình và prompt chi tiết]

--- TRANG 18 ---
[Tiếp tục các hình và prompt chi tiết]

--- TRANG 19 ---
[Tiếp tục các hình và prompt chi tiết cho đến cuối tài liệu]

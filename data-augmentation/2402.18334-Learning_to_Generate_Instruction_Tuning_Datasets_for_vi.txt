--- TRANG 9 ---
Bộ dữ liệu	Khớp=Có	Sự đồng ý (>=2)
PubMedQA	72%	97%
Reddit	76%	88%
ContractNLI	71%	99%

Bảng 5: Sự đồng ý giữa GPT-4o và câu trả lời được tạo ra bởi Bonito cho các tác vụ Bonito. Sự đồng ý (>=2) là phần trăm đồng ý khi hai hoặc nhiều người chú thích đồng ý về sự phù hợp hoặc không phù hợp.

hiệu suất. Chúng tôi thấy rằng Bonito trên PubMedQA đạt hiệu suất đỉnh 47.1 điểm F1 sau 10,000 bước nhưng F1 có thể dao động khi được huấn luyện ít bước hơn. Ngược lại, chúng tôi thấy rằng Bonito đạt hiệu suất cao nhất 73.3 điểm F1 sau 2,500 điểm và dần giảm hiệu suất xuống 71.7 điểm F1. Cuối cùng, nếu có sẵn, chúng tôi đề xuất sử dụng một tập validation để chọn checkpoint mô hình hiệu suất tốt nhất.

Hình 3: Thích ứng Mistral-7B với các tác vụ được tạo ra bởi Bonito và đánh giá hiệu suất sau khi huấn luyện cho số bước khác nhau.

Mô hình	Nguồn giám sát	PrivacyQA	Reddit	ContractNLI
Mistral-7B P3	None	49.9±2.6	61.0±2.8	33.3±0.7
GPT-4	57.2±4.8	52.4±3.0	43.1±0.7
Bonito	56.7±4.3	72.3±1.1	71.8±0.5

Bảng 9: Kết quả thích ứng tác vụ không cần ví dụ với tác vụ được tạo ra từ GPT-4. Chúng tôi báo cáo F1 và sai số chuẩn được tính trung bình trên năm mẫu prompt cho tất cả các bộ dữ liệu.

một bộ tạo tác vụ tốt hơn nhiều so với các mô hình mã nguồn mở, chúng tôi thấy rằng GPT-4 cũng gặp vấn đề tương tự. Ví dụ, ContractNLI thường có một giả thuyết tích cực và PrivacyQA có một câu hỏi với câu trả lời là có. Mặc dù GPT-4 tuân theo hướng dẫn để tạo ra chính xác một câu hỏi cho đoạn văn, chúng tôi thấy rằng nó tạo ra câu trả lời hơi dài hơn cho câu hỏi. Số liệu SQuAD sẽ phạt nếu có các token không mong muốn trong câu trả lời. Cuối cùng, chi phí tạo ra tác vụ với GPT-4 khiến việc tạo ra tác vụ cho các bộ dữ liệu lớn hơn như PubMedQA và Vitamin C trở nên cấm đoán về mặt chi phí.

D Bonito so với FLAN
Chúng tôi đánh giá hiệu suất không cần ví dụ của các mô hình FLAN-T5-XXL (11B) và FLAN-T5-XL (3B) (Longpre et al., 2023) trên các bộ dữ liệu đích được sử dụng trong thí nghiệm của chúng tôi. Bảng 10 cho thấy rằng Mistral-7B-Instruct-v0.2 và Mistral P3 với các tác vụ được tạo ra bởi Bonito cải thiện so với FLAN-T5-XXL (11B) thêm 2.7 điểm F1 và 4.0 điểm F1. Kết quả của chúng tôi cũng cho thấy rằng Mistral-7B-Instruct-v0.2 và Mistral P3 với Bonito vượt trội hơn FLAN-T5-XL (3B) thêm 6.4 điểm F1 và 7.7 điểm F1.

E Bonito với Các Mô hình Nhỏ hơn
Chúng tôi báo cáo so sánh bổ sung với Bonito được huấn luyện trên Pythia (2.8B) (Biderman et al., 2023). Chúng tôi tuân theo cùng thiết lập thí nghiệm được sử dụng trong Phần 5.1.

Kết quả Bảng 11 cho thấy rằng Bonito cải thiện Pythia (2.8B) trung bình 30.3 điểm F1 trên tất cả các bộ dữ liệu. Chúng tôi quan sát rằng Pythia (2.8B) với Bonito hoạt động tốt hơn Mistral với TAPT và Llama 2 với TAPT mặc dù nhỏ hơn gấp đôi (Xem Bảng 2). Những kết quả này cho thấy rằng Bonito có thể được sử dụng để tạo ra các mô hình ngôn ngữ chuyên biệt nhỏ nhưng mạnh mẽ.

F Chi tiết Huấn luyện
Ở đây chúng tôi cung cấp chi tiết huấn luyện cho các mô hình được sử dụng trong bài báo.

F.1 Huấn luyện Bonito
Chúng tôi huấn luyện Mistral-7B trên bộ dữ liệu tạo tác vụ có điều kiện với thuộc tính (CTGA). Từ tập huấn luyện, chúng tôi lấy mẫu đều 10,000 ví dụ làm tập validation để theo dõi mất mát. Phần còn lại của bộ dữ liệu được sử dụng để huấn luyện Bonito. Chúng tôi huấn luyện mô hình bằng Q-LoRA (Dettmers et al., 2023) bằng cách tối ưu hóa mất mát entropy chéo trên các token đầu ra. Mô hình được huấn luyện trong 100,000 bước. Việc huấn luyện mất khoảng 4 ngày trên bốn GPU để hoàn thành. Chúng tôi bao gồm tất cả các siêu tham số trong Phụ lục F.5.

Cùng một công thức huấn luyện có thể được sử dụng để huấn luyện các mô hình ngôn ngữ hiện có khác như Falcon (Almazrouei et al., 2023), Pythia (Biderman et al., 2023), và RedPajama (Together, 2023). Mặc dù các mô hình như Llama 2 (Touvron et al., 2023) có thể được huấn luyện trên CTGA, giấy phép của chúng cấm việc sử dụng đầu ra để nâng cao bất kỳ mô hình ngôn ngữ lớn nào khác.

F.2 Các Mô hình Được Điều chỉnh Hướng dẫn
Ở đây chúng tôi mô tả quy trình huấn luyện Mistral-7B P3 và Llama 2 7B P3. Chúng tôi sử dụng bộ dữ liệu T0 đã được xử lý từ Muennighoff et al. (2022). Vì bộ dữ liệu lớn, chúng tôi lấy mẫu đều 1.6 triệu ví dụ đầu vào-đầu ra và huấn luyện mô hình ngôn ngữ trên chúng. Theo Dettmers et al. (2023), chúng tôi huấn luyện mô hình trong 10,000 bước với Q-LoRA và tối ưu hóa mất mát entropy chéo trên các token đầu ra. Việc huấn luyện mất khoảng 10 giờ trên bốn GPU để hoàn thành. Đối với các siêu tham số còn lại, xem Phụ lục F.5.

F.3 Huấn luyện Các Mô hình Chuyên biệt Tác vụ
Để huấn luyện Mistral-7B-Instruct-v0.2 special và Mistral-7B special chuyên biệt tác vụ, chúng tôi tạo ra một bộ dữ liệu cụ thể cho tác vụ bằng cách lọc ra các loại tác vụ từ bộ dữ liệu CTGA. Chúng tôi đã chọn các bộ dữ liệu chứa các mẫu tương ứng với ba loại tác vụ: trả lời câu hỏi có-không, trả lời câu hỏi trích xuất, và suy luận ngôn ngữ tự nhiên. Các bộ dữ liệu có tổng cộng 130,703 ví dụ cho trả lời câu hỏi có-không, 378,167 ví dụ cho trả lời câu hỏi trích xuất, và 100,250 ví dụ cho suy luận ngôn ngữ tự nhiên.

Để huấn luyện Bonito special chuyên biệt tác vụ, chúng tôi chuyển đổi các mẫu tác vụ tương tự thành các mẫu-meta. Sau đó, chúng tôi sử dụng các mẫu meta để tạo ra bộ dữ liệu để huấn luyện mô hình.

Để công bằng, chúng tôi sử dụng cùng các siêu tham số để huấn luyện Bonito chuyên biệt tác vụ và các mô hình Mistral-7B-Instruct-v0.2 special và Mistral-7B special chuyên biệt tác vụ. Vì các bộ dữ liệu có ít ví dụ hơn đáng kể so với CTGA, chúng tôi huấn luyện các mô hình này trong tối đa 10,000 bước. Nếu hỗn hợp huấn luyện có ít hơn 160,000 ví dụ, chúng tôi huấn luyện mô hình Bonito trong 1 epoch. Việc huấn luyện trên bốn GPU mất khoảng 4 đến 10 giờ. Đối với các siêu tham số còn lại, xem Phụ lục F.5.

F.4 Chi tiết Phần mềm và Phần cứng
Codebase của chúng tôi được xây dựng bằng thư viện transformers (Wolf et al., 2019) trong PyTorch (Paszke et al., 2019). Chúng tôi huấn luyện tất cả các mô hình trong môi trường đa GPU phân tán sử dụng DeepSpeed (Rasley et al., 2020). Chúng tôi sử dụng song song dữ liệu phân tán trong DeepSpeed để tăng kích thước batch hiệu quả trong quá trình huấn luyện. Để huấn luyện và đánh giá, chúng tôi sử dụng các GPU sau tùy thuộc vào tính khả dụng của chúng trên cluster tính toán của chúng tôi: NVIDIA GeForce RTX 3090, NVIDIA RTX A5500, NVIDIA RTX A6000, NVIDIA RTX A5000, và NVIDIA A40.

F.5 Siêu tham số
Trong suốt các thí nghiệm tinh chỉnh của chúng tôi, trừ khi được đề cập khác, chúng tôi sử dụng các siêu tham số từ Dettmers et al. (2023). Bảng 12 cho thấy các siêu tham số trong thí nghiệm của chúng tôi. Chúng tôi sử dụng tích lũy gradient để đạt kích thước batch hiệu quả là 16. Chúng tôi cũng sử dụng gradient checkpointing để huấn luyện các mô hình lớn như Llama 2 7B và Mistral-7B.

--- TRANG 10 ---
Trả lời câu hỏi Có-Không	Trả lời câu hỏi Trích xuất	NLI
Mô hình	PubMedQA	PrivacyQA	NYT	Amazon	Reddit	ContractNLI	Vitamin C	Trung bình
FLAN-T5-XXL (11B)	50.0±0.4	62.5±2.2	84.2±0.2	72.3±1.9	70.1±3.1	45.4±3.5	62.5±2.7	63.9
FLAN-T5-XL (3B)	52.5±0.2	59.3±1.6	82.1±1.3	68.1±5.4	67.3±3.1	37.0±0.6	54.7±0.4	60.2
Mistral-7B-Instruct-v0.2 + Bonito	41.7±0.4	56.2±3.5	80.1±1.0	72.8±1.1	71.8±1.4	70.9±1.8	72.6±0.1	66.6
Mistral-7B P3+ Bonito	46.1±0.5	56.7±4.3	80.7±0.7	73.9±0.6	72.3±1.1	71.8±0.5	73.9±0.1	67.9

Bảng 10: Kết quả so sánh thích ứng tác vụ không cần ví dụ của các mô hình được điều chỉnh hướng dẫn với các mô hình FLAN-T5. Chúng tôi báo cáo F1 và sai số chuẩn được tính trung bình trên năm mẫu prompt cho tất cả các bộ dữ liệu.

Trả lời câu hỏi Có-Không	Trả lời câu hỏi Trích xuất	NLI
Mô hình	PubMedQA	PrivacyQA	NYT	Amazon	Reddit	ContractNLI	Vitamin C	Trung bình
Pythia (2.8B)	23.7±0.0	42.2±1.4	11.9±0.9	8.9±0.5	8.0±0.6	20.8±3.5	25.4±1.5	20.1
Pythia (2.8B) + Bonito	25.9±2.2	51.6±0.9	59.8±4.2	52.2±3.5	51.7±4.3	48.4±2.5	63.3±0.9	50.4

Bảng 11: Kết quả cho Pythia được huấn luyện trước và Pythia được thích ứng với Bonito. Chúng tôi báo cáo F1 và sai số chuẩn được tính trung bình trên năm mẫu prompt cho tất cả các bộ dữ liệu.

Siêu tham số	Giá trị
Rank Q-LoRA (r)	64
Hệ số tỷ lệ Q-LoRA (α)	4
Dropout Q-LoRA	0
Optimizer	Paged AdamW
Scheduler tốc độ học	tuyến tính
Tốc độ học tối đa	1e−04
Tốc độ học tối thiểu	0
Phân rã trọng số	0
Dropout	0
Chuẩn gradient tối đa	0.3
Kích thước batch hiệu quả	16
Độ dài đầu vào tối đa	2,048
Độ dài đầu ra tối đa	2,048

Bảng 12: Các siêu tham số được sử dụng để huấn luyện tất cả các mô hình trong thí nghiệm của chúng tôi.

G Sử dụng Trợ lý AI
Công trình của chúng tôi đã sử dụng các Trợ lý AI như ChatGPT và Grammarly để kiểm tra chính tả và sửa các lỗi ngữ pháp nhỏ. Chúng tôi cũng sử dụng GitHub Copilot trong VSCode để viết codebase của mình.

H Tạo Tác vụ Có điều kiện với Thuộc tính: Bộ dữ liệu và Tác vụ
Bảng 13 cho thấy phân phối tác vụ của bộ dữ liệu tạo tác vụ có điều kiện với thuộc tính. Bảng 14 liệt kê tất cả các bộ dữ liệu cùng với các loại tác vụ trong bộ dữ liệu. Bộ dữ liệu bao gồm 16 loại tác vụ trên 38 bộ dữ liệu. Các loại tác vụ là tóm tắt, phân tích cảm xúc, trả lời câu hỏi nhiều lựa chọn, trả lời câu hỏi trích xuất, phân loại chủ đề, suy luận ngôn ngữ tự nhiên, tạo câu hỏi, tạo văn bản, trả lời câu hỏi không có lựa chọn, nhận dạng paraphrase, hoàn thành câu, trả lời câu hỏi có-không, phân biệt nghĩa từ, tạo paraphrase, hàm ý văn bản, và giải quyết đồng tham chiếu. Sự khác biệt giữa trả lời câu hỏi trích xuất và trả lời câu hỏi không có lựa chọn là trong trả lời câu hỏi trích xuất, câu trả lời mục tiêu có trong ngữ cảnh trong khi trong trả lời câu hỏi không có lựa chọn, điều đó không phải lúc nào cũng đúng.

Loại tác vụ	# Ví dụ
Tóm tắt	284,589
Cảm xúc	233,530
Trả lời câu hỏi nhiều lựa chọn	229,066
Trả lời câu hỏi trích xuất	222,769
Phân loại chủ đề	209,980
Suy luận ngôn ngữ tự nhiên	100,250
Tạo câu hỏi	92,847
Tạo văn bản	86,835
Trả lời câu hỏi không có lựa chọn	75,159
Nhận dạng paraphrase	47,848
Hoàn thành câu	30,246
Trả lời câu hỏi có-không	25,895
Phân biệt nghĩa từ	5,428
Tạo paraphrase	2,550
Hàm ý văn bản	2,490
Giải quyết đồng tham chiếu	554
Tổng cộng	1,650,036

Bảng 13: Phân phối tác vụ trong bộ dữ liệu tạo tác vụ có điều kiện với thuộc tính.

I Prompt cho Đánh giá
I.1 PubmedQA
Bộ dữ liệu từ Jin et al. (2019):
• Đầu vào
Cho một đoạn văn: {{ context.contexts | join(" ") }}
Trả lời câu hỏi: {{question}}
Tóm tắt câu trả lời trên thành CÓ, KHÔNG, hay CÓ THỂ?
Mục tiêu
{{final_decision}}
Lựa chọn Trả lời
có ||| không ||| có thể

• Đầu vào
Tôi là bác sĩ và tôi muốn trả lời câu hỏi
"{{question}}" bằng cách sử dụng Đoạn văn sau:
{{ context.contexts | join(" ") }}
Tóm tắt câu trả lời trên thành CÓ, KHÔNG, hay CÓ THỂ?
Mục tiêu
{{final_decision}}
Lựa chọn Trả lời
có ||| không ||| có thể

• Đầu vào
Câu trả lời cho câu hỏi
"{{question}}" dựa trên Đoạn văn sau là gì:
{{ context.contexts | join(" ") }}
Tóm tắt câu trả lời trên thành CÓ, KHÔNG, hay CÓ THỂ?
Mục tiêu
{{final_decision}}
Lựa chọn Trả lời
có ||| không ||| có thể

• Đầu vào
Vui lòng trả lời câu hỏi "{{question}}"
sử dụng Đoạn văn sau:
{{ context.contexts | join(" ") }}
Tóm tắt câu trả lời trên thành CÓ, KHÔNG, hay CÓ THỂ?
Mục tiêu
{{final_decision}}
Lựa chọn Trả lời
có ||| không ||| có thể

• Đầu vào
Cho đoạn văn sau, trả lời câu hỏi: "{{question}}"
Đoạn văn: {{ context.contexts | join(" ") }}
Tóm tắt câu trả lời trên thành CÓ, KHÔNG, hay CÓ THỂ?
Mục tiêu
{{final_decision}}
Lựa chọn Trả lời
có ||| không ||| có thể

I.2 Privacy Policy QA
Bộ dữ liệu từ Ravichander et al. (2019).
• Đầu vào
Cho ngữ cảnh, điều này có liên quan đến câu hỏi không?
Ngữ cảnh: {{text}}
Câu hỏi: {{question}}
Mục tiêu
{{answer}}
Lựa chọn Trả lời
Liên quan|||Không liên quan

• Đầu vào
Câu hỏi này
"{{question}}"
có liên quan đến ngữ cảnh này không
"{{text}}"?
Mục tiêu
{% if answer == "Relevant" %} Có {% else %} Không {% endif %}
Lựa chọn Trả lời
Có|||Không

• Đầu vào
Điều này
"{{text}}"
có thể giúp trả lời câu hỏi này không
"{{question}}"?
Mục tiêu
{% if answer == "Relevant" %} Có {% else %} Không {% endif %}
Lựa chọn Trả lời
Có|||Không

• Đầu vào
Với tư cách là một luật sư, bạn có thể trả lời câu hỏi
cho ngữ cảnh này không?
Câu hỏi: {{question}}
Ngữ cảnh:{{text}}
Mục tiêu
{% if answer == "Relevant" %} Có {% else %} Không {% endif %}
Lựa chọn Trả lời
Có|||Không

• Đầu vào
Câu hỏi:{{question}}
Ngữ cảnh:{{text}}
Câu hỏi có liên quan đến ngữ cảnh không?
Mục tiêu
{% if answer == "Relevant" %} Có {% else %} Không {% endif %}
Lựa chọn Trả lời
Có|||Không

I.3 SQuADShifts
Bộ dữ liệu từ Miller et al. (2020).

I.3.1 NYT
• Đầu vào
Sau khi đọc đoạn văn sau, vui lòng trả lời câu hỏi này: {{question}}
{{context}}
Mục tiêu
{{answers['text'] | most_frequent | choice}}

• Đầu vào
Tôi đang làm bài kiểm tra cuối kỳ cho lớp học của mình
và đang cố gắng tìm ra câu trả lời cho câu hỏi "{{question}}"
Tôi đã tìm thấy thông tin sau trên New York Times và tôi nghĩ
nó có câu trả lời. Bạn có thể cho tôi biết câu trả lời không?
{{context}}
Mục tiêu
{{answers['text'] | most_frequent | choice}}

• Đầu vào
Tôi luôn thắc mắc: {{question}}
Tôi đã tìm kiếm trên New York Times và đây là những gì tôi tìm thấy.
Câu trả lời là gì?
{{context}}
Mục tiêu
{{answers['text'] | most_frequent | choice}}

• Đầu vào
{{context}}
Với sự giúp đỡ của đoạn văn, vui lòng trả lời
câu hỏi sau:
{{question}}
Mục tiêu
{{answers["text"]|choice}}

• Đầu vào
{{["Câu hỏi", "Vấn đề"] | choice}}
{{range(1, 12) | choice}}: {{question}}
Gợi ý: {{context}}
Mục tiêu
{{answers["text"] | most_frequent | choice}}

I.3.2 Amazon
• Đầu vào
Sau khi đọc đoạn văn sau, vui lòng trả lời câu hỏi này: {{question}}
{{context}}
Mục tiêu
{{answers['text'] | most_frequent | choice}}

• Đầu vào
Tôi đang làm bài kiểm tra cuối kỳ cho lớp học của mình
và đang cố gắng tìm ra câu trả lời cho câu hỏi "{{question}}"
Tôi đã tìm thấy thông tin sau trên Amazon và tôi nghĩ
nó có câu trả lời. Bạn có thể cho tôi biết câu trả lời không?
{{context}}
Mục tiêu
{{answers['text'] | most_frequent | choice}}

• Đầu vào
Tôi luôn thắc mắc: {{question}}
Tôi đã tìm kiếm trên Amazon và đây là những gì tôi tìm thấy.
Câu trả lời là gì?
{{context}}
Mục tiêu
{{answers['text'] | most_frequent | choice}}

• Đầu vào
{{context}}
Với sự giúp đỡ của đoạn văn, vui lòng trả lời
câu hỏi sau:
{{question}}
Mục tiêu
{{answers["text"]|choice}}

• Đầu vào
{{["Câu hỏi", "Vấn đề"] | choice}}
{{range(1, 12) | choice}}: {{question}}
Gợi ý: {{context}}
Mục tiêu
{{answers["text"] | most_frequent | choice}}

I.3.3 Reddit
• Đầu vào
Sau khi đọc đoạn văn sau, vui lòng trả lời câu hỏi này: {{question}}
{{context}}
Mục tiêu
{{answers['text'] | most_frequent | choice}}

• Đầu vào
Tôi đang làm bài kiểm tra cuối kỳ cho lớp học của mình
và đang cố gắng tìm ra câu trả lời cho câu hỏi "{{question}}"
Tôi đã tìm thấy thông tin sau trên Reddit và tôi nghĩ
nó có câu trả lời. Bạn có thể cho tôi biết câu trả lời không?
{{context}}
Mục tiêu
{{answers['text'] | most_frequent | choice}}

• Đầu vào
Tôi luôn thắc mắc: {{question}}
Tôi đã tìm kiếm trên Reddit và đây là những gì tôi tìm thấy.
Câu trả lời là gì?
{{context}}
Mục tiêu
{{answers['text'] | most_frequent | choice}}

• Đầu vào
{{context}}
Với sự giúp đỡ của đoạn văn, vui lòng trả lời
câu hỏi sau:
{{question}}
Mục tiêu
{{answers["text"]|choice}}

• Đầu vào
{{["Câu hỏi", "Vấn đề"] | choice}}
{{range(1, 12) | choice}}: {{question}}
Gợi ý: {{context}}
Mục tiêu
{{answers["text"] | most_frequent | choice}}

I.4 ContractNLI
Bộ dữ liệu từ Koreeda và Manning (2021).
• Đầu vào
Giả sử {{premise}} Chúng ta có thể suy ra rằng
"{{hypothesis}}" không? có, không hay có thể?
Mục tiêu
{{answer_choices[label]}}
Lựa chọn Trả lời
Không ||| Có ||| Có thể

• Đầu vào
{{premise}}
Câu hỏi: Điều này có ngụ ý rằng
"{{hypothesis}}" không? có, không hay có thể?
Mục tiêu
{{answer_choices[label]}}
Lựa chọn Trả lời
Không ||| Có ||| Có thể

• Đầu vào
Lấy điều sau làm sự thật: {{premise}} Thì
tuyên bố sau: "{{hypothesis}}" là
{{"đúng"}}, {{"sai"}}, hay
{{"không kết luận được"}}?
Mục tiêu
{{answer_choices[label]}}
Lựa chọn Trả lời
Sai ||| Đúng ||| Không kết luận được

• Đầu vào
{{premise}} Dựa trên thông tin đó, tuyên bố:
"{{hypothesis}}" là {{"đúng"}},
{{"sai"}}, hay {{"không kết luận được"}}?
Mục tiêu
{{answer_choices[label]}}
Lựa chọn Trả lời
Sai ||| Đúng ||| Không kết luận được

• Đầu vào
{{premise}} Dựa trên đoạn văn trước, có đúng rằng
"{{hypothesis}}" không? Có, không, hay có thể?
Mục tiêu
{{answer_choices[label]}}
Lựa chọn Trả lời
Không ||| Có ||| Có thể

I.5 Vitamin C
Bộ dữ liệu từ Schuster et al. (2021).
• Đầu vào
Giả sử {{evidence}} Chúng ta có thể suy ra rằng
"{{claim}}" không? có, không hay có thể?
Mục tiêu
{% if label == "REFUTES" %} Không {% elif label == "SUPPORTS" %} Có {% else %} Có thể {% endif %}
Lựa chọn Trả lời
Không ||| Có ||| Có thể

• Đầu vào
{{evidence}}
Câu hỏi: Điều này có ngụ ý rằng "{{claim}}" không?
có, không hay có thể?
Mục tiêu
{% if label == "REFUTES" %} Không {% elif label == "SUPPORTS" %} Có {% else %} Có thể {% endif %}
Lựa chọn Trả lời
Không ||| Có ||| Có thể

• Đầu vào
Lấy điều sau làm sự thật: {{evidence}}
Thì tuyên bố sau: "{{claim}}" là
{{"đúng"}}, {{"sai"}}, hay
{{"không kết luận được"}}?
Mục tiêu
{% if label == "REFUTES" %} Sai {% elif label == "SUPPORTS" %} Đúng {% else %} Không kết luận được {% endif %}
Lựa chọn Trả lời
Sai ||| Đúng ||| Không kết luận được

• Đầu vào
{{evidence}}
Dựa trên thông tin đó, tuyên bố:
"{{claim}}" là {{"đúng"}}, {{"sai"}}, hay
{{"không kết luận được"}}?
Mục tiêu
{% if label == "REFUTES" %} Sai {% elif label == "SUPPORTS" %} Đúng {% else %} Không kết luận được {% endif %}
Lựa chọn Trả lời
Sai ||| Đúng ||| Không kết luận được

• Đầu vào
{{evidence}} Dựa trên đoạn văn trước, có đúng rằng
"{{claim}}" không? Có, không, hay có thể?
Mục tiêu
{% if label == "REFUTES" %} Không {% elif label == "SUPPORTS" %} Có {% else %} Có thể {% endif %}
Lựa chọn Trả lời
Không ||| Có ||| Có thể

J Ví dụ Định tính
Bảng 16 cho thấy các tác vụ được tạo ra bởi Bonito cho PubMedQA, SQuADShifts Amazon, và ContractNLI.

--- TRANG 25 ---
Tên bộ dữ liệu	Các loại tác vụ
adversarial_qa/dbert	Trả lời câu hỏi trích xuất
Tạo câu hỏi
adversarial_qa/dbidaf	Trả lời câu hỏi trích xuất
Tạo câu hỏi
adversarial_qa/droberta	Trả lời câu hỏi trích xuất
Tạo câu hỏi
ag_news	Phân loại chủ đề
amazon_polarity	Cảm xúc
anli	Suy luận ngôn ngữ tự nhiên
app_reviews	Trả lời câu hỏi nhiều lựa chọn
Trả lời câu hỏi không có lựa chọn
Tạo văn bản
cnn_dailymail/3.0.0	Tóm tắt
Tạo văn bản
cosmos_qa	Trả lời câu hỏi nhiều lựa chọn
Trả lời câu hỏi không có lựa chọn
Tạo câu hỏi
dbpedia_14	Phân loại chủ đề
dream	Trả lời câu hỏi nhiều lựa chọn
Tạo văn bản
duorc/ParaphraseRC	Trả lời câu hỏi trích xuất
Tạo câu hỏi
Tóm tắt
Tạo văn bản
duorc/SelfRC	Trả lời câu hỏi trích xuất
Tạo câu hỏi
Tóm tắt
Tạo văn bản
gigaword	Tóm tắt
Tạo văn bản
glue/mrpc	Tạo paraphrase
Nhận dạng paraphrase
hellaswag	Hoàn thành câu
Phân loại chủ đề
imdb	Cảm xúc
multi_newspaws/labeled_final	Tạo paraphrase
Nhận dạng paraphrase
qasc	Trả lời câu hỏi nhiều lựa chọn

Bảng 14: Tên bộ dữ liệu và các loại tác vụ được gợi ý trong bộ dữ liệu [1/2].

--- TRANG 26 ---
Tên bộ dữ liệu	Các loại tác vụ
quail	Trả lời câu hỏi nhiều lựa chọn
Trả lời câu hỏi không có lựa chọn
quartz	Trả lời câu hỏi nhiều lựa chọn
quoref	Trả lời câu hỏi trích xuất
Tóm tắt
race/all	Trả lời câu hỏi nhiều lựa chọn
Trả lời câu hỏi không có lựa chọn
Tạo câu hỏi
Trả lời câu hỏi có-không
ropes	Trả lời câu hỏi trích xuất
rotten_tomatoes	Cảm xúc
samsum	Tóm tắt
Tạo văn bản
social_i_qa	Trả lời câu hỏi nhiều lựa chọn
Trả lời câu hỏi không có lựa chọn
Tạo câu hỏi
Trả lời câu hỏi có-không
squad	Trả lời câu hỏi trích xuất
Tạo câu hỏi
super_glue/boolq	Trả lời câu hỏi có-không
super_glue/cb	Suy luận ngôn ngữ tự nhiên
super_glue/copa	Hoàn thành câu
super_glue/record	Trả lời câu hỏi trích xuất
Trả lời câu hỏi nhiều lựa chọn
super_glue/rte	Hàm ý văn bản
super_glue/wic	Phân biệt nghĩa từ
super_glue/wsc.fixed	Giải quyết đồng tham chiếu
wiki_hop/original	Trả lời câu hỏi nhiều lựa chọn
Trả lời câu hỏi không có lựa chọn
xsum	Tóm tắt
yelp_review_full	Cảm xúc

Bảng 15: Tên bộ dữ liệu và các loại tác vụ được gợi ý trong bộ dữ liệu [2/2].

--- TRANG 27 ---
Bộ dữ liệu: PubMedQA
Loại tác vụ: Trả lời Câu hỏi Có-Không
Đầu vào: Palmitate, một acid béo bão hòa (FA), được biết là gây độc tính và tử vong tế bào trong nhiều loại tế bào khác nhau. Resveratrol (RSV) có khả năng ngăn ngừa bệnh sinh và/hoặc làm chậm tiến triển của nhiều loại bệnh khác nhau. Một số nghiên cứu in vitro và in vivo cũng đã cho thấy tác dụng bảo vệ của RSV đối với việc tích tụ chất béo do FAs gây ra. Ngoài ra, stress lưới nội chất (ER) gần đây đã được liên kết với các phản ứng adipogenic tế bào. Để giải quyết giả thuyết rằng tác dụng RSV đối với việc tích tụ chất béo quá mức được thúc đẩy bởi FAs bão hòa cao có thể được trung gian một phần bởi việc giảm stress ER, chúng tôi đã nghiên cứu tác động của RSV đối với stress ER được gây ra thực nghiệm bằng palmitate trong một số dòng tế bào ung thư. Chúng tôi cho thấy rằng, bất ngờ, RSV thúc đẩy sự khuếch đại độc tính palmitate và tử vong tế bào và cơ chế này có thể là do sự nhiễu loạn tích tụ palmitate dưới dạng triglyceride và đến một sự thay đổi độ lưu động màng ít quan trọng hơn. Ngoài ra, RSV giảm việc tạo ra các loài oxy gốc tự do (ROS) trong các tế bào được xử lý palmitate nhưng dẫn đến việc tăng cường X-box binding protein-1 (XBP1) splicing và biểu hiện C/EBP homologous protein (CHOP). Những tác dụng phân tử này được gây ra đồng thời với sự phân cắt caspase-3, cho thấy rằng RSV thúc đẩy lipoapoptosis palmitate chủ yếu thông qua cơ chế phụ thuộc vào stress ER. Hơn nữa, việc đảo ngược độc tính lipid được gây ra bởi acid eicosapentaenoic (EPA) hoặc bởi một chất kích hoạt liver X receptor (LXR) củng cố giả thuyết rằng việc ức chế RSV đối với palmitate channeling vào các pool triglyceride có thể là một yếu tố quan trọng trong việc trầm trọng hóa độc tính tế bào do palmitate gây ra. Kết quả của chúng tôi cho thấy rằng RSV thực hiện vai trò độc tính tế bào của nó trong các tế bào ung thư tiếp xúc với bối cảnh FA bão hòa chủ yếu bằng cách ức chế tích tụ triglyceride, có thể dẫn đến việc tích tụ palmitate nội tế bào kích hoạt tử vong tế bào được trung gian bởi lipid. Ngoài ra, tử vong tế bào này được thúc đẩy bởi stress ER thông qua quá trình apoptosis được trung gian bởi CHOP và có thể đại diện cho một chiến lược chống ung thư tiềm năng.

Câu hỏi: liệu resveratrol có gây tử vong tế bào trong các tế bào ung thư không
Câu trả lời: Có

Bộ dữ liệu: SquadShifts Amazon
Loại tác vụ: Trả lời câu hỏi trích xuất
Đầu vào: Đây là một đánh giá được để lại bởi một khách hàng về một sản phẩm. Bạn có thể trả lời câu hỏi được hỏi bởi khách hàng về sản phẩm không?
Đánh giá: Túi lưu trữ tôi nhận được khác với hình ảnh. Nó là chất liệu lưới trong suốt, trong khi trong hình ảnh nó không giống như sẽ trong suốt. Nó vẫn làm những gì nó được cho là làm, vì vậy không có gì phàn nàn. Tôi yêu thích dây velcro ở trên cùng mà tôi có thể sử dụng để treo nó trên thanh dưới kệ trong tủ quần áo của tôi.

Câu hỏi: Khách hàng đã treo túi lưu trữ như thế nào?
Đầu ra: trên thanh dưới kệ

Bộ dữ liệu: Contract NLI
Loại tác vụ: Suy luận ngôn ngữ tự nhiên
Đầu vào: 4. Không có gì trong Thỏa thuận này được hiểu là cấp cho Người nhận, theo hàm ý hoặc cách khác, bất kỳ quyền nào đối với Thông tin Bí mật hoặc một phần của nó. Chỉ sử dụng mô tả trên và những gì bạn biết về thế giới, "Người nhận là một người" chắc chắn đúng, không chính xác, hay không kết luận được?
Đầu ra: Không kết luận được

Bảng 16: Ví dụ các tác vụ được tạo ra từ Bonito cho PubMedQA, SQuADShifts Amazon, và ContractNLI.

# 2210.11768.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/data-augmentation/2210.11768.pdf
# Kích thước tệp: 593809 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2023
AUGMENTATION WITH PROJECTION:
HƯỚNG TỚI MỘT PARADIGM AUGMENTATION DỮ LIỆU
HIỆU QUẢ VÀ HIỆU QUẢ CHO DISTILLATION
Ziqi Wang1, Yuexin Wu2y, Frederick Liu2, Daogao Liu3, Le Hou2, Hongkun Yu2, Jing Li2,
Heng Ji1
1University of Illinois Urbana-Champaign2Google3University of Washington
fziqiw9, hengjig@illinois.edufcrickwu, frederickliu, lehou, hongkuny, jingli g@google.com
dgliu@uw.edu

TÓM TẮT
Knowledge distillation là một trong những phương pháp chính để chuyển giao kiến thức từ các mô hình lớn sang các mô hình nhỏ. Tuy nhiên, nó đòi hỏi dữ liệu đặc thù cho tác vụ rất lớn, điều này có thể không khả thi trong nhiều ứng dụng thực tế. Các phương pháp augmentation dữ liệu như interpolation biểu diễn, thay thế token, hoặc augmentation với các mô hình được áp dụng để giải quyết vấn đề này. Tuy nhiên, các phương pháp augmentation dữ liệu này hoặc có thể gây ra sự dịch chuyển trong ranh giới quyết định (interpolation biểu diễn), không đủ biểu cảm (thay thế token), hoặc tạo ra quá nhiều chi phí tính toán (augmentation với mô hình). Để giải quyết vấn đề này, chúng tôi đề xuất AugPro (Augmentation with Projection), một phương pháp augmentation dữ liệu hiệu quả và hiệu suất cho distillation. Phương pháp của chúng tôi được xây dựng trên cơ sở các phương pháp augmentation interpolation biểu diễn để duy trì sự đa dạng của các biểu thức và chuyển đổi dữ liệu được augment thành token để tránh dịch chuyển ranh giới quyết định. Nó sử dụng các phép toán đơn giản với chi phí tính toán ít. Kết quả trên nhiều tác vụ GLUE cho thấy phương pháp của chúng tôi có thể cải thiện hiệu suất distillation một cách đáng kể với chi phí thời gian thấp. Mã nguồn có sẵn tại https://github.com/google-research/google-research/tree/master/augpro.

1 GIỚI THIỆU
Các mô hình ngôn ngữ quy mô lớn (Devlin et al., 2018; Raffel et al., 2020; Brown et al., 2020; Zhang et al., 2022c) đã đạt được thành công lớn trong các tác vụ xử lý ngôn ngữ tự nhiên (NLP) khác nhau, như trích xuất thông tin (Lu et al., 2021) và trả lời câu hỏi (Kassner & Schütze, 2020). Tuy nhiên, các mô hình quy mô lớn có chi phí tính toán cao, điều này hạn chế việc triển khai chúng trên các thiết bị biên và các tình huống phản hồi nhanh (Sun et al., 2020b). Một giải pháp được sử dụng rộng rãi là thực hiện knowledge distillation (Hinton et al., 2015) từ các mô hình quy mô lớn sang các mô hình quy mô nhỏ. Tuy nhiên, phương pháp này thường đòi hỏi một lượng lớn dữ liệu để đảm bảo chất lượng chuyển giao, điều này có thể không dễ dàng có được trong các ứng dụng thực tế. Để giải quyết vấn đề này, các phương pháp augmentation dữ liệu được áp dụng (Liang et al., 2020; Wang & Yang, 2020; Zhang et al., 2022b) để cải thiện hiệu suất distillation.

Có ba loại phương pháp augmentation dữ liệu chính: (1) Interpolation biểu diễn. Ví dụ, Liang et al. (2020), Chen et al. (2020a) và Sun et al. (2020a) áp dụng interpolation tuyến tính (Zhang et al., 2017) lên word embeddings, hidden states giữa các lớp transformer, và encoder outputs, tương ứng, để augment tập dữ liệu gốc với các điểm dữ liệu ảo. Các điểm dữ liệu là ảo vì chúng không phải là đầu vào ngôn ngữ thực. Thay vào đó, chúng là các biểu diễn (ví dụ, embeddings). (2) Thay thế token. Kobayashi (2018) thay thế các token bằng các từ đồng nghĩa của chúng. Easy Data augmentation (Wei & Zou, 2019) kết hợp thay thế từ đồng nghĩa, chèn ngẫu nhiên, hoán đổi ngẫu nhiên, và xóa ngẫu nhiên. (3) Augmentation với mô hình. Yoo et al. (2021) và Zhou et al. (2021) sử dụng GPT-3 (Brown et al., 2020) và T5 (Raffel et al., 2020) tương ứng như mô hình ngôn ngữ để tạo ra dữ liệu văn bản mới có loại tương tự. (1) hỗ trợ nhiều phép toán như interpolation tuyến tính (Zhang et al., 2017) và nhiễu nhỏ (Madry et al., 2017). Điều này làm cho các phương pháp rất biểu cảm trong việc tạo ra một phạm vi dữ liệu đa dạng. Tuy nhiên, các biểu diễn mới được tạo ra (ví dụ, embeddings) có thể nằm ngoài phân phối dữ liệu thực. Ví dụ, word embeddings được chuyển đổi từ một từ vựng trong miền văn bản. Thực hiện augmentation ở mức này có thể dẫn đến các biểu diễn không có đối tác tương ứng trong từ vựng. Kết quả là, dữ liệu được augment có thể làm mô hình hiểu sai và tạo ra ranh giới quyết định dịch chuyển có thể ảnh hưởng lớn đến chất lượng (Mục 3). (2) có thể tạo ra dữ liệu trong miền một cách dễ dàng. Bằng cách sử dụng thay thế từ đồng nghĩa (Wang & Yang, 2015), dữ liệu mới có thể được thu được với chi phí thấp. Mặc dù có đặc tính tốt này, dòng phương pháp này thiếu khả năng tạo ra dữ liệu đa dạng. Sau đó, chúng ít góp phần vào việc lấy mẫu các khu vực dữ liệu ít tài nguyên và hạn chế việc cải thiện hiệu suất trong thực tế. (3) tạo ra cả dữ liệu đa dạng và trong miền bằng cách sử dụng các mô hình ngôn ngữ lớn như GPT-3 (Brown et al., 2020) và T5 (Raffel et al., 2020). Mặt khác, do chi phí tính toán lớn của chúng, chất lượng distillation cuối cùng sẽ bị hạn chế rất nhiều bởi lượng dữ liệu được tạo ra, điều này thường không thể chi trả được cho quy mô thậm chí hàng chục nghìn câu trong thực tế. Hình 1 tóm tắt các ưu điểm của mỗi phương pháp augmentation.

Representation Interpolation
AugmentationWith ModelsTokenReplacementChất lượng cao
Chất lượng caoRẻRẻKhông có ranh giới quyết định dịch chuyểnBiểu cảm
Hình 1: Minh họa các ưu điểm của mỗi phương pháp augmentation.

Xem xét tất cả các phương pháp trên, chúng tôi đề xuất AugPro, một phương pháp augmentation dữ liệu hiệu quả và hiệu suất cho tình huống distillation, phương pháp này hấp thụ các ưu điểm trên mà không bị hạn chế bởi các nhược điểm của chúng. Cụ thể, AugPro: (1) (hiệu quả) có tính biểu cảm như interpolation biểu diễn; (2) (hiệu quả) không làm sai lệch ranh giới quyết định; (3) (hiệu suất) có chi phí tính toán thấp. Trong cài đặt distillation, chúng ta luôn có thể sử dụng teacher để gán nhãn cho dữ liệu ảo trong tình huống knowledge distillation. Điều này cho thấy rằng chúng ta có thể khuyến khích AugPro tạo ra dữ liệu đa dạng nhất có thể mà không giới hạn trong các trường hợp chỉ có cùng nhãn hoặc nhãn đảo ngược.

Cụ thể, phương pháp của chúng tôi được xây dựng trên cơ sở các phương pháp augmentation interpolation biểu diễn (tính chất (1)), điều này không hạn chế dữ liệu được tạo ra trong các vùng nhỏ của "cha mẹ" chúng. Chìa khóa của AugPro là chuyển đổi dữ liệu được augment thành định dạng token thông qua projection (tính chất (2)) với các phép toán chi phí thấp (tính chất (3)). Chúng tôi tiến hành thí nghiệm trên các tập dữ liệu GLUE (Wang et al., 2018). Kết quả cho thấy phương pháp của chúng tôi có thể tăng cường hiệu suất distillation đáng kể với chi phí tính toán thấp.

Tóm lại, đóng góp của chúng tôi là:
• Chúng tôi đề xuất một phương pháp augmentation dữ liệu hiệu quả và hiệu suất cho knowledge distillation.
• Chúng tôi đánh giá thực nghiệm tính hiệu quả và hiệu suất của AugPro và kiểm tra lý thuyết rằng AugPro thỏa mãn ba tính chất trong một số trường hợp nhất định.

2 CÔNG TRÌNH LIÊN QUAN
Knowledge Distillation Knowledge distillation lần đầu tiên được đề xuất bởi (Hinton et al., 2015). Nó nhằm mục đích chưng cất kiến thức từ một mô hình sang mô hình khác bằng cách tối thiểu hóa khoảng cách giữa các đầu ra của hai mô hình trên cùng một đầu vào. Với sự phát triển của transformers (Vaswani et al., 2017) và BERT (Devlin et al., 2018), ngày càng có nhiều sự chú ý được dành cho việc distillation các mô hình ngôn ngữ pre-training. Tang et al. (2019) chưng cất BERT đã được fine-tuned thành mạng BiLSTM một lớp và làm cho mạng BiLSTM hoạt động tốt như ELMo (Peters et al., 2018). Sun et al. (2019) không chỉ chưng cất từ đầu ra mà còn chưng cất từ các lớp ẩn của mô hình teacher. Các phương pháp này chưng cất mô hình ngôn ngữ trong giai đoạn fine-tuning, trong khi Sanh et al. (2019) và Sun et al. (2020b) tập trung vào việc chưng cất mô hình ngôn ngữ trong giai đoạn pre-training trực tiếp để làm cho mô hình student không phụ thuộc vào tác vụ. TinyBERT (Jiao et al., 2019) chưng cất BERT từ cả giai đoạn pre-training và fine-tuning. Chúng tôi tập trung vào một cài đặt được sử dụng rộng rãi. Chúng tôi chưng cất kiến thức trong giai đoạn fine-tuning bằng cách tối thiểu hóa khoảng cách giữa đầu ra của hai mô hình.

Data Augmentation Các phương pháp interpolation biểu diễn phổ biến trong cộng đồng nghiên cứu computer vision. MixUp (Zhang et al., 2017) sử dụng interpolation tuyến tính để có được hình ảnh và nhãn được augment. Cho một hình ảnh x1, x2 và nhãn tương ứng y1, y2, MixUp sử dụng interpolation tuyến tính để tạo ra điểm dữ liệu mới x0 và nhãn y0:
x0 = MixUp(x1; x2) = λx1 + (1 − λ)x2; y0 = MixUp(y1; y2) = λy1 + (1 − λ)y2 (1)

FGSM (Goodfellow et al., 2014) và PGA (Madry et al., 2017) sử dụng gradient để tạo ra các ví dụ đối kháng. Cho một hình ảnh x, FGSM sẽ tạo ra dữ liệu mới x0:
x0 = x + ε · Sign(∇xL) (2)

trong đó L là loss của một tác vụ cụ thể và ε là một giá trị nhỏ. x0 và x có cùng nhãn. CutMix (Yun et al., 2019) cắt hình ảnh và sau đó nối chúng lại với nhau để có được hình ảnh mới. Mặc dù các phương pháp này ban đầu được thiết kế cho hình ảnh, chúng có thể được điều chỉnh cho các tác vụ NLP. Liang et al. (2020) sử dụng MixUp trên word embeddings để augment dữ liệu cho knowledge distillation. Chen et al. (2020b) sử dụng MixUp trên hidden states giữa các lớp transformer. Jindal et al. (2020) cũng sử dụng MixUp trên hidden states nhưng xem xét ảnh hưởng của mean và variance. Zhang et al. (2022b) áp dụng PGA lên embeddings của mô hình student và để embeddings của mô hình teacher không thay đổi, phát hiện ra rằng PGA có thể có lợi cho knowledge distillation. Các phương pháp thay thế token chủ yếu tập trung vào đầu vào ngôn ngữ. Các phương pháp thay thế từ đồng nghĩa (Kobayashi, 2018) thay thế token bằng các từ đồng nghĩa của chúng. Easy data augmentation (EDA) (Wei & Zou, 2019) kết hợp thay thế từ đồng nghĩa, chèn ngẫu nhiên, hoán đổi ngẫu nhiên, và xóa ngẫu nhiên. TreeMix (Zhang et al., 2022a) sử dụng constituency parser để quyết định token nào nên được thay thế. Augmentation với mô hình là một phương pháp khác để tạo ra dữ liệu mới. FlipDA (Zhou et al., 2021) sử dụng T5 để tạo ra dữ liệu có nhãn đảo ngược. GPT3Mix (Yoo et al., 2021) thiết kế prompts và sử dụng GPT3 để tạo ra dữ liệu mới. Back translation (Yu et al., 2018) sử dụng mạng neural để dịch đầu vào sang ngôn ngữ khác và sau đó dịch chúng trở lại. Phương pháp của chúng tôi (AugPro) sử dụng interpolation biểu diễn làm backbone và sử dụng projection để chuyển đổi biểu diễn thành token với các phép toán chi phí thấp.

3 CÁC VÍ DỤ ĐỘNG LỰC
Mặc dù các phương pháp interpolation biểu diễn có tính chất tốt là tạo ra dữ liệu đa dạng, chúng tôi phát hiện ra rằng các kỹ thuật thị giác này không thể được áp dụng trực tiếp cho các tác vụ NLP. Điều này là do interpolation biểu diễn augment dữ liệu theo cách liên tục, trong trường hợp này dữ liệu mới có thể không bao giờ tồn tại trong không gian đầu vào rời rạc, gây ra sự dịch chuyển ranh giới quyết định.

Lấy ví dụ về một vấn đề hai chiều đơn giản với khả năng phân tách tuyến tính (Hình 2). Giả sử X = {x1; x2; x3; x4} là vũ trụ của tất cả dữ liệu để học, và Y = {y1; y2; y3; y4} là các nhãn tương ứng. Giả sử chúng ta biết tất cả X, Y và chạy support vector machine (SVM) tuyến tính với hard margin, tức là min w,b ||w||2 sao cho yi(w>xi + b) ≥ 1 cho tất cả i, chúng ta có được giải pháp w*, b*. Vì khó để có được tất cả dữ liệu trong cài đặt thế giới thực, chúng ta giả sử rằng chúng ta chỉ có {x1; x3} làm tập dữ liệu huấn luyện. Nếu chúng ta chỉ đơn giản sử dụng MixUp, chúng ta có được xMixUp, làm dữ liệu được augment, có nhãn yMixUp = sign((w*)>xMixUp + b*) = y3 = y4. Bây giờ chạy SVM tuyến tính với {x2; x4; xMixUp} với nhãn {y2; y4; yMixUp}, chúng ta có được wMixUp và bMixUp. Tuy nhiên, sign(w>MixUpx3 + bMixUp) ≠ y3.

Để so sánh, nếu chúng ta project xMixUp về neighbor gần nhất và có được xMixUpP = x2 có nhãn yMixUpP = y2, chạy SVM với {x1; x2; xMixUpP} và {y1; y2; yMixUpP} có thể có được wMixUpP và bMixUpP, có thể phân loại tất cả dữ liệu một cách chính xác. Phụ lục B cho thấy số cụ thể của mỗi tham số.

Để giải quyết vấn đề này, dữ liệu được augment nên là dữ liệu thực trong không gian đầu vào, tức là định dạng token, để tận dụng vấn đề này. Quan sát này dẫn đến phương pháp AugPro của chúng tôi sử dụng projection để chuyển đổi biểu diễn được augment thành token biểu tượng. So với điểm dữ liệu ảo được tạo ra bởi interpolation biểu diễn, projection có thể khám phá nhiều dữ liệu thực hơn và dẫn đến lỗi thấp hơn (Mục 4.2 và Phụ lục H).

4 PHƯƠNG PHÁP LUẬN
Trong mục này, chúng tôi trước tiên công thức hóa định nghĩa của knowledge distillation trong NLP (Hinton et al., 2015) và sau đó giới thiệu phương pháp AugPro của chúng tôi.

--- TRANG 2 ---
perturbation nhỏ (Madry et al., 2017). Điều này làm cho các phương pháp rất biểu cảm trong việc tạo ra một phạm vi dữ liệu đa dạng. Tuy nhiên, các biểu diễn mới được tạo ra (ví dụ, embeddings) có thể nằm ngoài phân phối dữ liệu thực. Ví dụ, word embeddings được chuyển đổi từ một từ vựng trong miền văn bản. Thực hiện augmentation ở mức này có thể dẫn đến các biểu diễn không có đối tác tương ứng trong từ vựng. Kết quả là, dữ liệu được augment có thể làm mô hình hiểu sai và tạo ra ranh giới quyết định dịch chuyển có thể ảnh hưởng lớn đến chất lượng (Mục 3). (2) có thể tạo ra dữ liệu trong miền một cách dễ dàng. Bằng cách sử dụng thay thế từ đồng nghĩa (Wang & Yang, 2015), dữ liệu mới có thể được thu được với chi phí thấp. Mặc dù có đặc tính tốt này, dòng phương pháp này thiếu khả năng tạo ra dữ liệu đa dạng. Sau đó, chúng ít góp phần vào việc lấy mẫu các khu vực dữ liệu ít tài nguyên và hạn chế việc cải thiện hiệu suất trong thực tế. (3) tạo ra cả dữ liệu đa dạng và trong miền bằng cách sử dụng các mô hình ngôn ngữ lớn như GPT-3 (Brown et al., 2020) và T5 (Raffel et al., 2020). Mặt khác, do chi phí tính toán lớn của chúng, chất lượng distillation cuối cùng sẽ bị hạn chế rất nhiều bởi lượng dữ liệu được tạo ra, điều này thường không thể chi trả được cho quy mô thậm chí hàng chục nghìn câu trong thực tế. Hình 1 tóm tắt các ưu điểm của mỗi phương pháp augmentation.

Representation Interpolation
AugmentationWith ModelsTokenReplacementChất lượng cao
Chất lượng caoRẻRẻKhông có ranh giới quyết định dịch chuyểnBiểu cảm
Hình 1: Minh họa các ưu điểm của mỗi phương pháp augmentation.

Xem xét tất cả các phương pháp trên, chúng tôi đề xuất AugPro, một phương pháp augmentation dữ liệu hiệu quả và hiệu suất cho tình huống distillation, phương pháp này hấp thụ các ưu điểm trên mà không bị hạn chế bởi các nhược điểm của chúng. Cụ thể, AugPro: (1) (hiệu quả) có tính biểu cảm như interpolation biểu diễn; (2) (hiệu quả) không làm sai lệch ranh giới quyết định; (3) (hiệu suất) có chi phí tính toán thấp. Trong cài đặt distillation, chúng ta luôn có thể sử dụng teacher để gán nhãn cho dữ liệu ảo trong tình huống knowledge distillation. Điều này cho thấy rằng chúng ta có thể khuyến khích AugPro tạo ra dữ liệu đa dạng nhất có thể mà không giới hạn trong các trường hợp chỉ có cùng nhãn hoặc nhãn đảo ngược.

Cụ thể, phương pháp của chúng tôi được xây dựng trên cơ sở các phương pháp augmentation interpolation biểu diễn (tính chất (1)), điều này không hạn chế dữ liệu được tạo ra trong các vùng nhỏ của "cha mẹ" chúng. Chìa khóa của AugPro là chuyển đổi dữ liệu được augment thành định dạng token thông qua projection (tính chất (2)) với các phép toán chi phí thấp (tính chất (3)). Chúng tôi tiến hành thí nghiệm trên các tập dữ liệu GLUE (Wang et al., 2018). Kết quả cho thấy phương pháp của chúng tôi có thể tăng cường hiệu suất distillation đáng kể với chi phí tính toán thấp.

Tóm lại, đóng góp của chúng tôi là:
• Chúng tôi đề xuất một phương pháp augmentation dữ liệu hiệu quả và hiệu suất cho knowledge distillation.
• Chúng tôi đánh giá thực nghiệm tính hiệu quả và hiệu suất của AugPro và kiểm tra lý thuyết rằng AugPro thỏa mãn ba tính chất trong một số trường hợp nhất định.

2 CÔNG TRÌNH LIÊN QUAN
Knowledge Distillation Knowledge distillation lần đầu tiên được đề xuất bởi (Hinton et al., 2015). Nó nhằm mục đích chưng cất kiến thức từ một mô hình sang mô hình khác bằng cách tối thiểu hóa khoảng cách giữa các đầu ra của hai mô hình trên cùng một đầu vào. Với sự phát triển của transformers (Vaswani et al., 2017) và BERT (Devlin et al., 2018), ngày càng có nhiều sự chú ý được dành cho việc distillation các mô hình ngôn ngữ pre-training. Tang et al. (2019) chưng cất BERT đã được fine-tuned thành mạng BiLSTM một lớp và làm cho mạng BiLSTM hoạt động tốt như ELMo (Peters et al., 2018). Sun et al. (2019) không chỉ chưng cất từ đầu ra mà còn chưng cất từ các lớp ẩn của mô hình teacher. Các phương pháp này chưng cất mô hình ngôn ngữ trong giai đoạn fine-tuning, trong khi Sanh et al. (2019) và Sun et al. (2020b) tập trung vào việc chưng cất mô hình ngôn ngữ trong giai đoạn pre-training trực tiếp để làm cho mô hình student không phụ thuộc vào tác vụ. TinyBERT (Jiao et al., 2019) chưng cất BERT từ cả giai đoạn pre-training và fine-tuning. Chúng tôi tập trung vào một cài đặt được sử dụng rộng rãi. Chúng tôi chưng cất kiến thức trong giai đoạn fine-tuning bằng cách tối thiểu hóa khoảng cách giữa đầu ra của hai mô hình.

Data Augmentation Các phương pháp interpolation biểu diễn phổ biến trong cộng đồng nghiên cứu computer vision. MixUp (Zhang et al., 2017) sử dụng interpolation tuyến tính để có được hình ảnh và nhãn được augment. Cho một hình ảnh x1, x2 và nhãn tương ứng y1, y2, MixUp sử dụng interpolation tuyến tính để tạo ra điểm dữ liệu mới x0 và nhãn y0:

x0 = MixUp(x1; x2) = λx1 + (1 − λ)x2; y0 = MixUp(y1; y2) = λy1 + (1 − λ)y2 (1)

FGSM (Goodfellow et al., 2014) và PGA (Madry et al., 2017) sử dụng gradient để tạo ra các ví dụ đối kháng. Cho một hình ảnh x, FGSM sẽ tạo ra dữ liệu mới x0:

x0 = x + ε · Sign(∇xL) (2)

trong đó L là loss của một tác vụ cụ thể và ε là một giá trị nhỏ. x0 và x có cùng nhãn. CutMix (Yun et al., 2019) cắt hình ảnh và sau đó nối chúng lại với nhau để có được hình ảnh mới. Mặc dù các phương pháp này ban đầu được thiết kế cho hình ảnh, chúng có thể được điều chỉnh cho các tác vụ NLP. Liang et al. (2020) sử dụng MixUp trên word embeddings để augment dữ liệu cho knowledge distillation. Chen et al. (2020b) sử dụng MixUp trên hidden states giữa các lớp transformer. Jindal et al. (2020) cũng sử dụng MixUp trên hidden states nhưng xem xét ảnh hưởng của mean và variance. Zhang et al. (2022b) áp dụng PGA lên embeddings của mô hình student và để embeddings của mô hình teacher không thay đổi, phát hiện ra rằng PGA có thể có lợi cho knowledge distillation. Các phương pháp thay thế token chủ yếu tập trung vào đầu vào ngôn ngữ. Các phương pháp thay thế từ đồng nghĩa (Kobayashi, 2018) thay thế token bằng các từ đồng nghĩa của chúng. Easy data augmentation (EDA) (Wei & Zou, 2019) kết hợp thay thế từ đồng nghĩa, chèn ngẫu nhiên, hoán đổi ngẫu nhiên, và xóa ngẫu nhiên. TreeMix (Zhang et al., 2022a) sử dụng constituency parser để quyết định token nào nên được thay thế. Augmentation với mô hình là một phương pháp khác để tạo ra dữ liệu mới. FlipDA (Zhou et al., 2021) sử dụng T5 để tạo ra dữ liệu có nhãn đảo ngược. GPT3Mix (Yoo et al., 2021) thiết kế prompts và sử dụng GPT3 để tạo ra dữ liệu mới. Back translation (Yu et al., 2018) sử dụng mạng neural để dịch đầu vào sang ngôn ngữ khác và sau đó dịch chúng trở lại. Phương pháp của chúng tôi (AugPro) sử dụng interpolation biểu diễn làm backbone và sử dụng projection để chuyển đổi biểu diễn thành token với các phép toán chi phí thấp.

--- TRANG 3 ---
3 CÁC VÍ DỤ ĐỘNG LỰC
Mặc dù các phương pháp interpolation biểu diễn có tính chất tốt là tạo ra dữ liệu đa dạng, chúng tôi phát hiện ra rằng các kỹ thuật thị giác này không thể được áp dụng trực tiếp cho các tác vụ NLP. Điều này là do interpolation biểu diễn augment dữ liệu theo cách liên tục, trong trường hợp này dữ liệu mới có thể không bao giờ tồn tại trong không gian đầu vào rời rạc, gây ra sự dịch chuyển ranh giới quyết định.

Lấy ví dụ về một vấn đề hai chiều đơn giản với khả năng phân tách tuyến tính (Hình 2). Giả sử X = {x1; x2; x3; x4} là vũ trụ của tất cả dữ liệu để học, và Y = {y1; y2; y3; y4} là các nhãn tương ứng. Giả sử chúng ta biết tất cả X, Y và chạy support vector machine (SVM) tuyến tính với hard margin, tức là min w,b ||w||2 sao cho yi(w>xi + b) ≥ 1 cho tất cả i, chúng ta có được giải pháp w*, b*. Vì khó để có được tất cả dữ liệu trong cài đặt thế giới thực, chúng ta giả sử rằng chúng ta chỉ có {x1; x3} làm tập dữ liệu huấn luyện. Nếu chúng ta chỉ đơn giản sử dụng MixUp, chúng ta có được xMixUp, làm dữ liệu được augment, có nhãn yMixUp = sign((w*)>xMixUp + b*) = y3 = y4. Bây giờ chạy SVM tuyến tính với {x2; x4; xMixUp} với nhãn {y2; y4; yMixUp}, chúng ta có được wMixUp và bMixUp. Tuy nhiên, sign(w>MixUpx3 + bMixUp) ≠ y3.

Để so sánh, nếu chúng ta project xMixUp về neighbor gần nhất và có được xMixUpP = x2 có nhãn yMixUpP = y2, chạy SVM với {x1; x2; xMixUpP} và {y1; y2; yMixUpP} có thể có được wMixUpP và bMixUpP, có thể phân loại tất cả dữ liệu một cách chính xác. Phụ lục B cho thấy số cụ thể của mỗi tham số.

Để giải quyết vấn đề này, dữ liệu được augment nên là dữ liệu thực trong không gian đầu vào, tức là định dạng token, để tận dụng vấn đề này. Quan sát này dẫn đến phương pháp AugPro của chúng tôi sử dụng projection để chuyển đổi biểu diễn được augment thành token biểu tượng. So với điểm dữ liệu ảo được tạo ra bởi interpolation biểu diễn, projection có thể khám phá nhiều dữ liệu thực hơn và dẫn đến lỗi thấp hơn (Mục 4.2 và Phụ lục H).

4 PHƯƠNG PHÁP LUẬN
Trong mục này, chúng tôi trước tiên công thức hóa định nghĩa của knowledge distillation trong NLP (Hinton et al., 2015) và sau đó giới thiệu phương pháp AugPro của chúng tôi.

--- TRANG 4 ---
x1
x2 x3x4
−+
(a) Ground-Truth
x1
x2 x3x4
xMixUp−+ (b) MixUp SVM
x1
x2 x3x4
−+
Projection (c) MixUp với Projection SVM
Hình 2: Sự dịch chuyển ranh giới quyết định trong không gian 2D cho các tập dữ liệu rời rạc. (a) là sự thật cơ bản, trong đó x1; x3 là dữ liệu huấn luyện có thể quan sát được trong khi x2; x4 với màu trong suốt có nghĩa là dữ liệu chưa được thấy. Trong (b), người ta có được dữ liệu augmented xMixUp với nhãn yMixUp = −1, và thực hiện SVM với {x1; x3; xMixUp} với nhãn của chúng. Trong (c), người ta project xMixUp về neighbor gần nhất x2, và thực hiện SVM với {x1; x2; x3}. Chúng ta thấy rằng sự chính xác của projection trong (c) mang lại sự dịch chuyển ranh giới quyết định nhỏ hơn so với (b).

4.1 KNOWLEDGE DISTILLATION
Knowledge distillation là một phương pháp chưng cất kiến thức từ các mô hình quy mô lớn sang các mô hình quy mô nhỏ. Nói một cách chính thức, xem xét một tác vụ phân loại NLP, chúng ta có một corpus D = {(xi, yi)}N i=1 chứa N cặp đầu vào-đầu ra, trong đó xi là một câu đầu vào với các token xi = [wi1, ..., wini]; wk ∈ V; V là từ vựng, ni là số token trong xi. yi là nhãn đầu ra cho xi. Chúng ta sử dụng văn bản thường thay vì văn bản in đậm cho x vì đầu vào ngôn ngữ là một chuỗi các token, khác với hình ảnh. Sau đó chúng ta chưng cất kiến thức từ một mô hình quy mô lớn f(·; θT) với tham số θT (tức là mô hình teacher) sang một mô hình quy mô nhỏ g(·; θS) với tham số θS (tức là mô hình student). Trong thực tế, θT có nhiều tham số hơn θS rất nhiều. Quá trình distillation có thể được chia thành hai giai đoạn:

• Huấn luyện Teacher. Tối ưu hóa θT trên tập dữ liệu D. Trong các vấn đề phân loại, chúng ta sử dụng cross-entropy loss để thực hiện tối thiểu hóa rủi ro thực nghiệm trên θT:

θ'T = arg min θT 1/N ∑N i=1 CrossEntropy(f(xi; θT); yi) (3)

• Huấn luyện Student. Tối ưu hóa θS trên tập dữ liệu D với cả nhãn ground-truth và đầu ra từ teachers. Trong các vấn đề phân loại,

θ'S = arg min θS LKD = arg min θS 1/N ∑N i=1 CrossEntropy(g(xi; θS); yi) + d(g(xi; θS); f(xi; θ'T)) (4)

trong đó d(·; ·) là một hàm khoảng cách. Trong thực tế, d(·; ·) có thể là cross-entropy hoặc mean square error.

Kết quả thực nghiệm từ các nghiên cứu trước đây (Hinton et al., 2015; Sun et al., 2020b; Sanh et al., 2019; Sun et al., 2019) cho thấy rằng knowledge distillation sẽ huấn luyện một θ'S tốt hơn vì mô hình student không chỉ học từ nhãn ground-truth mà còn học tính tổng quát từ mô hình teacher.

Lưu ý cho việc huấn luyện student, chúng ta có thể kết hợp knowledge distillation và data augmentation cùng nhau:
θ'S = arg min θS LKD + LAug

trong đó LAug biểu thị knowledge distillation loss trên dữ liệu augmented dẫn đến các biến thể khác nhau của các phương pháp. Như một cách quan trọng để giúp student học hiệu quả hơn, cách tạo ra dữ liệu mới với augmentation loss là chìa khóa và chủ đề thảo luận chính trong các phần còn lại.

4.2 AUGPRO: AUGMENTATION VỚI PROJECTION
Trong phần này, chúng tôi sẽ giới thiệu bốn biến thể của LAug: hai backbone (MixUp và FGSM) và hai biến thể AugPro được xây dựng trên cơ sở chúng. Hình 4 cho thấy khái niệm về phương pháp được đề xuất của chúng tôi.

--- TRANG 5 ---
Algorithm 1: Thuật toán AugPro
Input: Tập dữ liệu D = {(X, Y)}, hàm interpolation biểu diễn h(), hàm projection p(), mô hình teacher f với tham số fine-tuned θ'T và mô hình student g với tham số θS cần được fine-tuned, từ vựng V, tỷ lệ học α, số bước huấn luyện K, kích thước batch B, độ dài câu L, chiều embedding H.
Output: θ'S được fine-tuned
• k = 0
• while k < K
  – Lấy mẫu một batch dữ liệu B = {(x, y)} ∈ V^(B×L) từ D = {(X, Y)}.
  – Nhận các biểu diễn augmented Brep = h(B) ∈ R^(B×L×H) (ví dụ, Phương trình 1, 2)
  – Project các biểu diễn thành token B' = p(Brep) ∈ V^(B×L) (ví dụ, Phương trình 5)
  – Sử dụng Phương trình (4) để tính LKD.
  – Tính loss LAug (ví dụ, Phương trình 6, 7) dựa trên B', f và g.
  – θS = θS - α∇(LKD + LAug); k = k + 1
• return θS

AugPro được xây dựng trên cơ sở các phương pháp augmentation interpolation biểu diễn. Pipeline (Algorithm 1) có thể được chia thành ba bước: (1) Chúng ta trước tiên nhận các biểu diễn augmented (tức là h()). (2) Sau đó chúng ta sử dụng projection để chuyển đổi biểu diễn thành token (tức là p()). (3) Cuối cùng, chúng ta tính LAug để cập nhật các mô hình student. Chìa khóa cho bước (2) là projection. Cụ thể, các mô hình ngôn ngữ ánh xạ token thành biểu diễn, và projection nhằm mục đích tìm một ánh xạ ngược để ánh xạ biểu diễn trở lại thành token. Bằng cách này, AugPro sẽ tránh việc dịch chuyển ranh giới quyết định (Mục 3). Tuy nhiên, ánh xạ ngược khó tìm trong thực tế. Trước tiên, các kiến trúc mô hình ngôn ngữ phổ biến như transformers (Vaswani et al., 2017) thường phức tạp và khó để có được ánh xạ ngược. Thứ hai, không gian đầu vào của ngôn ngữ là rời rạc, làm cho ánh xạ không thể đảo ngược. Do đó, chúng ta chỉ có thể sử dụng kỹ thuật xấp xỉ để có được ánh xạ ngược xấp xỉ. Để giải quyết vấn đề này, chúng ta tập trung vào ánh xạ ngược ở mức embedding. Trước tiên, cấu trúc của ánh xạ embedding đơn giản hơn nhiều so với lớp transformer và dễ dàng cho chúng ta tìm ánh xạ ngược. Thứ hai, chúng ta có thể sử dụng nearest-neighbors như phương pháp xấp xỉ, đây là một xấp xỉ rẻ tiền.

Dựa trên phân tích trên, chúng ta sử dụng nearest-neighbors để tìm projection của chúng ta, tức là hàm p() trong Algorithm 1. AugPro không phụ thuộc vào các phương pháp interpolation biểu diễn cụ thể. Trong bài báo này, chúng ta áp dụng AugPro cho MixUp và FGSM, tức là h() trong Algorithm 1 là MixUp hoặc FGSM như trong Phương trình (1,2). Chúng ta sẽ minh họa hai biến thể để thực hiện projection (bước (2)) và tính loss LAug (bước (3)) trong các văn bản sau.

Chúng ta lạm dụng một chút khái niệm về f và g để minh họa AugPro tốt hơn. Chúng ta chia f và g thành hai phần: phần đầu tiên là hàm embedding ánh xạ token thành embedding vectors (fe và ge, e biểu thị embeddings), phần còn lại là phần thứ hai (fl và gl, l biểu thị layers). Theo định nghĩa này, f = fl ◦ fe và g = gl ◦ ge.

AugPro-Mix Chúng ta có được AugPro-Mix bằng cách áp dụng paradigm AugPro cho MixUp. Trước tiên, chúng ta áp dụng MixUp trên word embeddings và nhãn. Điều này cho chúng ta embeddings từ teacher ef MixUp, embeddings từ student eg MixUp, và nhãn yMixUp. LAug trở thành

LMixUp = 1/M ∑M j=1 [CrossEntropy(gl(eg MixUp,j; θS); yMixUp,j) + d(gl(eg MixUp,j; θS); fl(ef MixUp,j; θ'T))]

khi chúng ta sử dụng dữ liệu MixUp để xây dựng losses, trong đó M biểu thị số lượng dữ liệu augmented.

Đối với AugPro, chúng ta sử dụng nearest-neighbors để có được token AugPro-Mix xAugPro-Mix:

xAugPro-Mix = [wAugPro-Mix,1, ..., wAugPro-Mix,n]

trong đó wAugPro-Mix,i = max w∈V Sim(ef MixUp(i), fe(w)) (5)

--- TRANG 6 ---
Sim có nghĩa là hàm độ tương tự, có thể là cosine similarity. e(i) có nghĩa là embedding vector thứ i trong e. Các ví dụ cụ thể có thể được tìm thấy trong Phụ lục D. Sau đó hàm loss LAug trở thành:

LAugPro-Mix = 1/M ∑M j=1 d(g(xAugPro-Mix,j; θS); f(xAugPro-Mix,j; θ'T)) (6)

Chúng ta không sử dụng yMixUp vì thao tác projection (nearest-neighbors trong AugPro-Mix) không nhất thiết bảo toàn nhãn.

AugPro-FGSM Mặc dù các ví dụ đối kháng (AE) ban đầu nhằm mục đích cải thiện độ mạnh mẽ của các mô hình và có thể gây hại cho hiệu suất trên đầu vào sạch (Raghunathan et al., 2019), Zhang et al. (2022b) cho thấy rằng AE có thể có lợi cho knowledge distillation. Chúng ta có được AugPro-FGSM bằng cách áp dụng AugPro cho FGSM. Chúng ta trước tiên áp dụng FGSM cho mô hình student và có được dữ liệu augmented eg FGSM. Dữ liệu augmented có thể được sử dụng để xây dựng LAug trực tiếp:

LFGSM = 1/M ∑M j=1 d(gl(eg FGSM,j; θS); fl(ef j; θ'T))

Theo Phương trình 5, chúng ta có thể có được xAugPro-FGSM bằng cách thay đổi các chú thích tương ứng.

Chúng ta thường đặt ε trong Phương trình (2) lớn trong AugPro-FGSM vì chúng ta không muốn xAugPro-FGSM giống với đầu vào gốc, trong khi ε trong Phương trình (2) là một giá trị nhỏ trong FGSM. Chúng ta sử dụng cosine similarity để triển khai hàm Sim. Hàm loss LAug trở thành:

LAugPro-FGSM = 1/M ∑M j=1 d(g(xAugPro-FGSM,j; θS); f(xAugPro-FGSM,j; θ'T)) (7)

Sự đa dạng nhãn Chúng ta lấy hai câu từ tập dữ liệu SST-2 (Socher et al., 2013) như một ví dụ để giải thích thêm rằng projection không nhất thiết bảo toàn nhãn nhưng tạo ra các nhãn đa dạng. Câu đầu tiên là "watch on video at home" với cảm xúc Neutral. Câu thứ hai là "as good" với cảm xúc Positive. Sau đó chúng ta có thể có được câu AugPro-Mix "watch good video at home". Rõ ràng nhãn của câu AugPro-Mix nên là Positive thay vì interpolation tuyến tính của Positive và Neutral. Đây là tính chất mong muốn trong distillation vì chúng ta sẽ sử dụng teacher để gán nhãn cho những điểm dữ liệu mới được tạo ra này.

Chi phí tính toán. Nếu chúng ta giả sử độ phức tạp của việc tính cosine similarity giữa hai vector là O(d) trong đó d là chiều của vector, thì độ phức tạp của projection (nearest-neighbors trong triển khai của chúng ta) là O(NVd), trong đó N là độ dài câu và V là kích thước từ vựng. N thường trong vài trăm. V thường khoảng 30.000 trong các mô hình ngôn ngữ pre-train phổ biến sử dụng sub-word tokens như BERT (Devlin et al., 2018) và T5 (Raffel et al., 2020). Kết quả là, O(NVd) mang lại chi phí ít. Mặt khác, thao tác projection có thể được song song hóa vì các tính toán độ tương tự NV không ảnh hưởng lẫn nhau. Trong các kiến trúc tính toán song song hiện đại, như GPU và TPU, projection có thể được tính toán theo cách nhanh hơn nhiều. So với độ phức tạp của các mô hình ngôn ngữ quy mô lớn chính, tính toán này sẽ chiếm một phần nhỏ tài nguyên. So sánh thời gian chạy chi tiết có thể được tìm thấy trong Mục 5.2.

Ba tính chất của AugPro. Vì AugPro hỗ trợ các phép toán được sử dụng trong các phương pháp interpolation biểu diễn, AugPro là biểu cảm (tính chất (1)). AugPro cũng chuyển đổi biểu diễn thành token để tránh dịch chuyển ranh giới quyết định, dẫn đến tỷ lệ lỗi nhỏ hơn (tính chất (2)). Có thể được chỉ ra rằng AugPro-Mix có tỷ lệ lỗi thấp hơn 1/(4N) so với MixUp, và AugPro-FGSM có tỷ lệ lỗi thấp hơn 1/(2N) so với FGSM với một số giả định nhất định (Phụ lục H). Hơn nữa, AugPro có chi phí tính toán thấp để đảm bảo hiệu suất (tính chất (3)), như được mô tả trong đoạn trước.

5 THÍ NGHIỆM
Thí nghiệm của chúng tôi nhằm mục đích trả lời hai câu hỏi: (1) AugPro hiệu quả như thế nào khi được áp dụng cho tình huống knowledge distillation? (2) AugPro có hiệu suất không?

Tập dữ liệu và cài đặt Theo các công trình knowledge distillation trước đây (Liang et al., 2020; Zhang et al., 2022b), chúng tôi sử dụng các tập dữ liệu GLUE (Wang et al., 2018) làm benchmark. Chúng tôi sử dụng EncT5 (Liu et al., 2021) làm mô hình teacher và student vì những lý do sau: (1) T5 có hiệu suất tốt hơn BERT nhiều và gần với SOTA trong nhiều tác vụ. EncT5 là một phiên bản đơn giản của T5 sử dụng toàn bộ encoder của T5 nhưng chỉ có một lớp decoder. EncT5 thực hiện tương tự như T5 trên các tác vụ phân loại như các tác vụ GLUE với ít tham số hơn. Ví dụ, EncT5 (small) chỉ chứa 37M tham số nhưng có thể thực hiện tương tự như T5 (small), chứa 77M tham số. Sử dụng EncT5 sẽ làm cho kết quả thuyết phục hơn và cho thấy rằng phương pháp của chúng tôi vẫn hữu ích ngay cả với các mô hình mạnh mẽ. (2) Các phương pháp trước đây (Liang et al., 2020; Zhang et al., 2022b) chưng cất kiến thức từ BERT 12 lớp sang BERT 6 lớp hoặc BERT 3 lớp. Tuy nhiên, khoảng cách giữa mô hình teacher và student là không đáng kể. Do đó, không gian cải thiện bị hạn chế, và sự tồn tại của phương sai sẽ làm giảm độ tin cậy của kết quả. Để giải quyết vấn đề này, chúng tôi chưng cất kiến thức từ EncT5 (Large, 24 lớp, 354M, teacher) sang EncT5 (small, 8 lớp, 37M, student), vì hai mô hình có khoảng cách hiệu suất đáng kể.

Baselines và huấn luyện Chúng tôi huấn luyện một số baselines để so sánh: (1) Fine-Tuning (FT): Chúng tôi trực tiếp fine-tune EncT5 trên tập dữ liệu. (2) Knowledge Distillation (KD): Chúng tôi trước tiên fine-tune mô hình teacher (EncT5 Large), sau đó chưng cất kiến thức từ mô hình teacher sang mô hình student (EncT5 Small). (3) Knowledge Distillation + Back Translation (KD+BT): Back translation (Yu et al., 2018) trước tiên dịch đầu vào sang ngôn ngữ khác và sau đó dịch lại. Chúng tôi chọn back translation như một phương pháp đại diện cho loại data augmentation "augmentation với mô hình". (4) Knowledge Distillation + K-Nearest-Neighbors (KD+KNN) KNN (Wang & Yang, 2015) trước tiên chọn token từ đầu vào, sau đó thay thế chúng bằng K neighbor gần nhất trong không gian embedding. KNN có thể được coi là một phương pháp thay thế token. (5) KD+MixUp (6) KD+FGSM (7) KD+TMix (Chen et al., 2020b) MixUp trên hidden state giữa các lớp transformer. Ba phương pháp cuối cùng thuộc loại "interpolation biểu diễn". Chúng tôi huấn luyện các mô hình student với 0.6M bước và kích thước batch 512. Do chi phí tính toán cao, chúng tôi chỉ augment dữ liệu thành gấp đôi kích thước tập dữ liệu gốc cho back translation. Đối với tất cả các phương pháp khác, chúng tôi augment dữ liệu thành gấp đôi kích thước batch gốc cho mỗi batch, tức là chúng tôi augment 0.6M bước × 512 kích thước batch = 307.2M dữ liệu tổng cộng. Các chi tiết huấn luyện khác trong Phụ lục C.

5.1 HIỆU QUẢ CỦA AUGPRO
Bảng 1 cho thấy kết quả của knowledge distillation. Do chi phí cao, chúng tôi chỉ báo cáo kết quả back translation trên tập dữ liệu RTE. Chúng tôi trước tiên sử dụng dữ liệu huấn luyện để huấn luyện mô hình teacher và sau đó chưng cất kiến thức từ mô hình teacher sang mô hình student trên dữ liệu huấn luyện. Chúng ta có thể kết luận rằng: (1) Tất cả các phương pháp data augmentation sẽ có lợi cho distillation. (2) AugPro có thể cải thiện hiệu suất distillation đáng kể so với các baselines tương ứng. Cụ thể, AugPro cực kỳ hữu ích cho các tập dữ liệu ít tài nguyên như CoLA và RTE. AugPro-Mix đạt được điểm số cao hơn 5.97% và 9.02% so với MixUp trên CoLA và RTE, tương ứng. AugPro-FGSM đạt được điểm số cao hơn 10.52% và 8.31% so với FGSM trên CoLA và RTE, tương ứng. Đối với các tập dữ liệu lớn như MNLI, AugPro-Mix và AugPro-FGSM cũng có thể cải thiện hiệu suất. (3) Hơn nữa, việc kết hợp AugPro-FGSM và AugPro-Mix đạt được hiệu suất tốt nhất trong tất cả các phương pháp được liệt kê. So với knowledge distillation vanilla, việc kết hợp AugPro-Mix và AugPro-FGSM cải thiện hiệu suất từ 2% đến 14%.

Bảng 2 sử dụng một cài đặt khác so với Bảng 1. Chúng tôi chỉ giữ 10% dữ liệu huấn luyện được gán nhãn và giả sử những dữ liệu khác không được gán nhãn. Sau đó chúng tôi sử dụng dữ liệu huấn luyện có nhãn để huấn luyện mô hình teacher và dữ liệu huấn luyện không nhãn để thực hiện knowledge distillation—đây là cài đặt thực tế hơn vì thường dễ dàng hơn để có được dữ liệu không nhãn hơn là có được dữ liệu có nhãn. Các kết luận trên vẫn đúng. Cụ thể, AugPro có thể cải thiện độ chính xác từ 1% đến 2% trung bình trên ba tập dữ liệu. So với distillation vanilla, AugPro có thể cải thiện khoảng 2% độ chính xác nhiều nhất trên ba tập dữ liệu.

5.2 HIỆU SUẤT CỦA AUGPRO
Hiệu suất của AugPro nằm ở hai khía cạnh. Trước tiên, độ phức tạp của nó thấp. Thứ hai, nó có thể được tính toán song song. Để chứng minh đầy đủ hai ưu điểm này, chúng tôi báo cáo chi phí thời gian thực của AugPro và các baselines trong Bảng 3. KD+data augmentation khoảng gấp đôi thời gian của KD vanilla vì các phương pháp này sử dụng gấp đôi dữ liệu so với KD vanilla. Chúng ta cũng có thể quan sát thấy rằng augmentation với mô hình (KD+BT) mất nhiều thời gian hơn so với các loại baseline khác, cho thấy phương pháp này không đủ hiệu quả. Cuối cùng, AugPro mang lại chi phí tính toán ít vì chi phí thời gian giống như các baseline.

--- TRANG 7 ---
SST-2 CoLA MNLI-MM/M QNLI QQP MRPC STS-B RTE
Acc Matthew Acc Acc Acc/F1 Acc/F1 PC/SC Acc
67.3k 8.5k 392.7k 104.7k 363.8k 3.7k 5.7k 2.5k
EncT5 24-FT (354M) 97.20 63.60 91.40/91.10 95.40 92.73/90.00 91.42/93.30 88.19/88.00 86.30
EncT5 8-FT (37M) 92.89 45.84 84.69/84.26 89.84 91.45/88.41 87.01/90.91 86.39/85.94 59.21
EncT5 8-KD 92.09 45.56 85.93/85.61 89.46 91.36/88.24 84.56/88.85 87.29/87.18 61.37
+BT - - - - - - - 61.73
+KNN 94.27 54.60 87.13/87.01 91.54 92.14/89.40 86.03/90.32 87.14/87.27 66.79
+TMix 93.35 44.42 86.79/86.79 91.10 91.76/88.84 87.25/90.97 87.52/87.35 63.18
+MixUp 93.23 51.63 86.73/86.69 91.31 91.82/88.97 88.48/91.68 87.47/87.33 62.82
+AugPro-Mix 94.38 57.60 87.40/87.27 92.06 92.06/89.23 89.46/92.34 88.10/87.87 71.84
+FGSM 92.20 46.37 85.88/85.53 89.58 91.21/88.06 84.56/89.23 87.56/87.26 62.09
+AugPro-FGSM 94.61 56.89 87.02/86.85 91.67 92.10/89.26 88.24/91.67 87.64/87.51 70.40
+FGSM+MixUp 93.12 50.79 86.85/86.65 91.09 91.75/88.85 87.25/90.88 87.15/87.00 62.82
+AugPro-FGSM+AugPro-Mix 95.18 59.01 87.97/87.87 92.92 92.30/89.54 89.46/92.42 88.34/88.04 74.73

Bảng 1: Knowledge distillation trên tập dữ liệu GLUE. Chúng tôi trước tiên sử dụng dữ liệu huấn luyện để huấn luyện mô hình teacher và sau đó chưng cất kiến thức từ mô hình teacher sang mô hình student trên dữ liệu huấn luyện. EncT5 L biểu thị EncT5 với L lớp transformer. L = 24 và L = 8 biểu thị mô hình teacher với 354M tham số và mô hình student với 37M tham số, tương ứng.

KD +MixUp +AugPro-Mix +FGSM +AugPro-FGSM +FGSM+MixUp +AugPro-Mix+AugPro-FGSM
MNLI-MM/M 84.81/84.39 85.53/85.33 86.36/85.87 85.07/84.58 85.87/85.82 85.70/85.65 86.76/86.81
SST-2 92.09 93.35 94.04 92.09 94.27 93.46 94.04
QNLI 89.68 90.28 90.98 89.99 91.03 90.50 91.58

Bảng 2: Knowledge distillation trên tập dữ liệu GLUE với cài đặt khác so với Bảng 1. Chúng tôi coi 10% dữ liệu là có nhãn và phần còn lại là không nhãn. Mô hình teacher trước tiên được huấn luyện trên dữ liệu huấn luyện có nhãn và sau đó được sử dụng cho knowledge distillation trên dữ liệu huấn luyện không nhãn.

các baseline. Kết quả cũng cho thấy rằng KNN chậm hơn nhiều so với các phương pháp khác, được giải thích trong Phụ lục G.

5.3 NGHIÊN CỨU ABLATION
Trong các nghiên cứu ablation, chúng tôi tuân theo các cài đặt được sử dụng trong Bảng 1 trừ khi có quy định khác.

Quy mô perturbation cho ε trong AugPro-FGSM Siêu tham số chính trong AugPro-FGSM là ε trong Phương trình (2). ε nhỏ sẽ làm cho xAugPro-FGSM giống với đầu vào gốc. ε lớn có xu hướng làm cho xAugPro-FGSM khó hiểu, vô nghĩa, và ngoài miền. Do đó, một ε thích hợp là cần thiết. Thí nghiệm của chúng tôi phát hiện ra rằng ε = 35 là phù hợp nhất cho T5 embeddings. Bảng 4 cho thấy hiệu suất KD+AugPro-FGSM với ε khác nhau.

Dấu hiệu của gradient trong AugPro-FGSM không quan trọng Hiệu quả của AugPro-FGSM đến từ dấu hiệu của gradient và projection trong AugPro. Để chứng minh rằng AugPro-FGSM chủ yếu có lợi từ AugPro, chúng tôi triển khai hai biến thể AugPro-FGSM: AugPro-FGSMD (Descent Projection) sử dụng dấu hiệu đối lập với AugPro-FGSM, và AugPro-FGSMR (Random Projection) sử dụng dấu hiệu ngẫu nhiên. Bảng 6 cho thấy kết quả của AugPro-FGSM và hai biến thể của nó. Chúng ta có thể quan sát thấy AugPro-FGSM có điểm tương tự với các biến thể trong tất cả các cài đặt. Do đó AugPro-FGSM chủ yếu có lợi từ AugPro. Chúng tôi cũng tiến hành thí nghiệm tuân theo cài đặt của Bảng 2, và kết quả có thể được tìm thấy trong Phụ lục E.

AugPro tạo ra các nhãn đa dạng Chúng tôi cho thấy rằng AugPro tạo ra các nhãn đa dạng ở cuối Mục 4. Ở đây chúng tôi chỉ ra thực nghiệm rằng giả định AugPro bảo toàn nhãn có thể gây hại cho hiệu suất. Nếu AugPro bảo toàn nhãn, dữ liệu AugPro-Mix và AugPro-FGSM nên có cùng nhãn như dữ liệu MixUp và gốc, tương ứng. Chúng tôi sử dụng những dữ liệu augmented này cùng với nhãn để fine-tune trực tiếp các mô hình student. Kết quả trong Bảng 5 cho thấy rằng những dữ liệu augmented và nhãn như vậy có thể gây hại cho hiệu suất. Do đó, AugPro tạo ra các nhãn đa dạng và không nhất thiết bảo toàn nhãn.

AugPro liên tục có lợi cho KD với các kích thước dữ liệu khác nhau Hình 3 cho thấy hiệu suất của AugPro với các kích thước dữ liệu khác nhau. Có thể quan sát thấy rằng AugPro tốt hơn tất cả các baseline trong tất cả các kích thước dữ liệu. Hơn nữa, AugPro cực kỳ hữu ích khi kích thước dữ liệu nhỏ. Ví dụ, AugPro có thể cải thiện độ chính xác 4% (SST-2) và 6% (MNLI-M) khi kích thước dữ liệu là 10%. Chúng tôi cũng báo cáo kết quả trên tập dữ liệu MNLI-MM trong Phụ lục F.

--- TRANG 8 ---
KD +BT¹ +KNN +TMix +MixUp +AugPro-Mix +FGSM +AugPro-FGSM
Thời gian (phút) 1.68 13.15 4.57 3.48 3.48 3.48 3.24 3.24

Bảng 3: Chi phí thời gian (phút) trung bình mỗi 1000 bước của các phương pháp khác nhau trên 8 TPU v3 slices. Chi phí bao gồm data augmentation, forward pass, và backpropagation. Bảng được chia thành bốn phần. Mỗi phần chứa một loại data augmentation cụ thể (KD, augmentation với mô hình, thay thế token, interpolation biểu diễn và AugPro).

ε MNLI-MM/M SST-2 QNLI
30 85.60/85.28 93.69 90.44
35 85.87/85.82 94.27 91.03
40 85.79/85.58 93.23 90.81
100 85.18/84.74 91.97 90.44

Bảng 4: Hiệu suất KD+AugPro-FGSM với ε khác nhau.

Kích thước dữ liệu 20% 50% 100%
Finetune 80.99/80.71 83.43/82.55 84.69/84.26
AugPro-Mix 80.62/80.44 83.24/82.60 84.53/83.92
AugPro-FGSM 80.74/80.32 83.16/82.44 84.37/83.61

Bảng 5: AugPro-Mix và AugPro-FGSM được sử dụng để fine-tune các mô hình student. Nhãn MixUp được sử dụng cho dữ liệu AugPro-Mix. AugPro-FGSM sử dụng nhãn gốc.

KD MNLI-MM/M SST-2
+AugPro-FGSM 87.02/86.85 94.61
+AugPro-FGSMD 87.08/86.89 94.27
+AugPro-FGSMR 86.57/86.52 94.27
+MixUp+AugPro-FGSM 87.35/87.41 94.50
+MixUp+AugPro-FGSMD 87.45/87.44 94.04
+MixUp+AugPro-FGSMR 87.48/87.49 94.15
+AugPro-Mix+AugPro-FGSM 87.97/87.87 95.18
+AugPro-Mix+AugPro-FGSMD 87.81/87.67 94.61
+AugPro-Mix+AugPro-FGSMR 87.77/87.62 94.95

Bảng 6: Hiệu suất KD+AugPro-FGSM và các biến thể của nó với các dấu hiệu khác nhau. AugPro-FGSMD biểu thị FGSM với Decent Projection. AugPro-FGSMD sử dụng dấu hiệu đối lập với AugPro-FGSM. AugPro-FGSMR biểu thị FGSM với Random Projection. AugPro-FGSMR sử dụng dấu hiệu ngẫu nhiên.

[Các biểu đồ hiệu suất với các kích thước dữ liệu khác nhau]

Hình 3: Hiệu suất AugPro với các kích thước dữ liệu khác nhau. Hình (a) và Hình (b) cho tập dữ liệu SST-2 và MNLI-M. Các đường xanh (hoặc marker tam giác) là các phương pháp AugPro. Các đường vàng (hoặc marker kim cương) là các phương pháp baseline. Đường xanh lá (hoặc marker X) là KD. AugPro có cùng kiểu đường với baseline tương ứng. Ví dụ, AugPro-FGSM và FGSM đều là đường đứt nét.

6 KẾT LUẬN VÀ CÔNG VIỆC TƯƠNG LAI
Chúng tôi đề xuất AugPro, một paradigm data augmentation hiệu quả và hiệu suất cho knowledge distillation. Chúng tôi sử dụng projection để giải quyết vấn đề dịch chuyển ranh giới quyết định gây ra bởi các phương pháp interpolation biểu diễn truyền thống trong knowledge distillation. Hơn nữa, AugPro có chi phí tính toán thấp và nhanh trong các kiến trúc tính toán hiện đại. Kết quả trên các tác vụ GLUE chứng minh tính hiệu quả và hiệu suất của AugPro. Trong tương lai, chúng tôi sẽ khám phá thêm tác động của AugPro đối với nhãn để làm cho nó hữu ích trong các tình huống khác.

--- TRANG 9 ---
[Tiếp tục với các trang còn lại của tài liệu, bao gồm tài liệu tham khảo và phụ lục...]

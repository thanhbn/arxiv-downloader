# LLM360: Hướng tới các LLM mã nguồn mở hoàn toàn minh bạch

Zhengzhong Liu
Petuum & MBZUAIAurick Qiao
PetuumWillie Neiswanger
USC & PetuumHongyi Wang
CMUBowen Tan
CMU
Tianhua Tao
UIUCJunbo Li
MBZUAIYuqi Wang
PetuumSuqi Sun
PetuumOmkar Pangarkar
PetuumRichard Fan
Petuum
Yi Gu
UCSDVictor Miller
PetuumYonghao Zhuang
CMUGuowei He
MBZUAIHaonan Li
MBZUAIFajri Koto
MBZUAI
Liping Tang
MBZUAINikhil Ranjan
MBZUAIZhiqiang Shen
MBZUAIXuguang Ren
MBZUAIRoberto Iriondo
MBZUAI
Cun Mu
MBZUAIZhiting Hu
UCSDMark Schulze
PetuumPreslav Nakov
MBZUAITim Baldwin
MBZUAIEric P. Xing
MBZUAI

Tóm tắt
Sự gia tăng gần đây của các mô hình ngôn ngữ lớn (LLM) mã nguồn mở, như LLaMA, Falcon và Mistral, cung cấp nhiều lựa chọn đa dạng cho các chuyên gia và nhà nghiên cứu AI. Tuy nhiên, hầu hết các LLM chỉ công bố một phần sản phẩm, chẳng hạn như trọng số mô hình cuối cùng hoặc mã suy luận, và các báo cáo kỹ thuật ngày càng giới hạn phạm vi của chúng vào các lựa chọn thiết kế cấp cao và thống kê bề mặt. Những lựa chọn này cản trở tiến bộ trong lĩnh vực này bằng cách làm giảm tính minh bạch trong việc huấn luyện LLM và buộc các nhóm phải tự khám phá lại nhiều chi tiết trong quá trình huấn luyện. Chúng tôi giới thiệu LLM360, một sáng kiến để mã nguồn mở hoàn toàn các LLM, ủng hộ việc tất cả mã và dữ liệu huấn luyện, các điểm kiểm tra mô hình, và kết quả trung gian được cung cấp cho cộng đồng. Mục tiêu của LLM360 là hỗ trợ nghiên cứu AI mở và hợp tác bằng cách làm cho quá trình huấn luyện LLM từ đầu đến cuối trở nên minh bạch và có thể tái tạo bởi mọi người. Là bước đầu tiên của LLM360, chúng tôi phát hành hai LLM 7B tham số được huấn luyện từ đầu, AMBER và CRYSTAL CODER, bao gồm mã huấn luyện, dữ liệu, các điểm kiểm tra trung gian, và phân tích (tại llm360.ai). Chúng tôi cam kết liên tục mở rộng ranh giới của LLM thông qua nỗ lực mã nguồn mở này. Các mô hình quy mô lớn hơn và mạnh mẽ hơn đang được phát triển và sẽ được phát hành trong tương lai.

Một báo cáo kỹ thuật của dự án LLM 360.

--- TRANG 2 ---

1 Giới thiệu
Bối cảnh của các Mô hình Ngôn ngữ Lớn (LLM) đã trải qua một sự chuyển đổi đáng chú ý trong một năm qua, chứng kiến sự gia tăng chưa từng có về cả tính phổ biến và khả năng của những mô hình này. Đi đầu trong sự phát triển này là các LLM độc quyền như GPT-4 [1] và Claude [2], đã thu hút sự chú ý của cộng đồng AI do sức mạnh và tính linh hoạt của chúng. Đồng thời, sự xuất hiện gần đây của các LLM có thể truy cập công khai nhưng có khả năng cao như LLaMA [3,4], Falcon [5], và Mistral [6] cho phép các nhà nghiên cứu và chuyên gia nói chung có thể dễ dàng có được, tùy chỉnh, và triển khai LLM trong môi trường đa dạng hơn và cho các trường hợp sử dụng đa dạng hơn.

Mặc dù ảnh hưởng và khả năng tiếp cận ngày càng tăng của các LLM mã nguồn mở, một xu hướng đáng chú ý là hạn chế khả năng hiển thị và truy cập vào các quá trình huấn luyện, tinh chỉnh, và đánh giá của chúng, bao gồm các thành phần quan trọng như mã huấn luyện và dữ liệu. Thực tế này hạn chế khả năng của cộng đồng nghiên cứu AI rộng lớn hơn để nghiên cứu, nhân rộng, và đổi mới dựa trên các LLM tiên tiến. Một cách tiếp cận minh bạch hơn để chia sẻ không chỉ mô hình cuối cùng mà còn cả chi tiết và sản phẩm huấn luyện là rất quan trọng để thúc đẩy một môi trường nghiên cứu bao gồm và hợp tác hơn.

Với động lực như trên, chúng tôi lưu ý những thách thức cụ thể sau đây trong nghiên cứu LLM ngày nay.

Nguồn gốc dữ liệu. Hiểu biết về nguồn gốc và đặc điểm của dữ liệu huấn luyện là quan trọng để đánh giá độ tin cậy và thành kiến vốn có trong LLM. Thiếu minh bạch về nguồn dữ liệu và thành phần cản trở khả năng xác định và giảm thiểu thành kiến có thể được duy trì trong đầu ra của mô hình. Đồng thời, rò rỉ dữ liệu—khi tập dữ liệu huấn luyện chồng lấp với tập dữ liệu đánh giá—có thể dẫn đến các chỉ số hiệu suất gây hiểu lầm che khuất hiệu quả tổng quát của mô hình (được nghiên cứu trong [7,8]). Những vấn đề này nêu bật sự cần thiết của việc ghi chép rõ ràng nguồn gốc và cách sử dụng dữ liệu trong phát triển LLM.

Khả năng tái tạo. Ngay cả với việc tiết lộ đầy đủ nguồn dữ liệu, việc thiếu quyền truy cập vào mã huấn luyện hoàn chỉnh, chi tiết cấu hình, và tập dữ liệu cụ thể có thể khiến việc tái tạo kết quả được báo cáo trong các nghiên cứu trở nên khó khăn. Ví dụ, mặc dù các hỗn hợp dữ liệu huấn luyện được tiết lộ bởi LLaMA [3], mã xử lý dữ liệu và huấn luyện không được phát hành. Tuy nhiên, các LLM được biết là được huấn luyện sử dụng một bản tái tạo mở của dữ liệu LLaMA (ví dụ, RedPajama [9,10]) vẫn không hoàn toàn tái tạo các đánh giá điểm chuẩn của nó [11], cho thấy rằng các thủ tục xử lý dữ liệu hoặc huấn luyện bổ sung có thể cần thiết.

Hợp tác mở. Thực hành chỉ phát hành trọng số mô hình cuối cùng không chỉ dẫn đến những nỗ lực dư thừa mà còn đặt ra những thách thức độc đáo trong việc tiến hành nghiên cứu nhất định. Ví dụ, nghiên cứu về khả năng xuất hiện của LLM [12,13] hoặc điều tra về cách dữ liệu huấn luyện khác nhau ảnh hưởng đến hành vi mô hình [14,15] trở nên khó khăn hơn nếu không có quyền truy cập vào các điểm kiểm tra huấn luyện trung gian. Các nhà nghiên cứu thường buộc phải làm việc với mô hình cuối cùng, điều này cung cấp những hiểu biết hạn chế về các sắc thái phát triển của nó, hoặc bắt đầu từ đầu, dẫn đến việc trùng lặp công việc và chi tiêu tính toán không cần thiết.

LLM360 nhằm giải quyết các vấn đề trên thông qua một nỗ lực LLM mã nguồn mở toàn diện. Các mô hình trong LLM360 được xuất bản với tất cả các chi tiết huấn luyện và mô hình (ví dụ, siêu tham số, lịch trình, kiến trúc, và thiết kế), tất cả các điểm kiểm tra mô hình trung gian được lưu trong quá trình huấn luyện, và tiết lộ đầy đủ dữ liệu huấn luyện trước chính xác được sử dụng.

Những đóng góp của chúng tôi là:

• Chúng tôi phác thảo khung LLM360, tập trung vào các nguyên tắc thiết kế và lý do để mã nguồn mở hoàn toàn các LLM. Chúng tôi chi tiết các thành phần của khung, bao gồm tập dữ liệu, mã và cấu hình, điểm kiểm tra mô hình, và chỉ số huấn luyện. Khung này cung cấp mục tiêu minh bạch mà tất cả các mô hình LLM360 hiện tại và tương lai cố gắng đạt được.

• Chúng tôi huấn luyện trước hai LLM mới từ đầu và phát hành chúng theo khung LLM360. AMBER là LLM tiếng Anh 7B được huấn luyện trước trên 1.3T token. CRYSTAL CODER là LLM tiếng Anh và mã 7B được huấn luyện trước trên 1.4T token. Chúng tôi thảo luận về chi tiết phát triển, đánh giá sơ bộ, quan sát, và bài học chúng tôi học được từ AMBER và CRYSTAL CODER.

• Chúng tôi phát hành tất cả mã huấn luyện, dữ liệu huấn luyện trước, điểm kiểm tra mô hình, và chỉ số đánh giá được thu thập trong quá trình huấn luyện trước cho cả AMBER và CRYSTAL CODER. Đáng chú ý, AMBER được phát hành với 360 điểm kiểm tra mô hình được lưu trong quá trình huấn luyện, và CRYSTAL CODER với 143.

Chúng tôi nhằm tạo ra một cam kết liên tục để mã nguồn mở hoàn toàn các LLM bằng cách phát hành nhiều LLM ở các quy mô khác nhau. Là bước đầu tiên, trong báo cáo kỹ thuật này, chúng tôi thảo luận về AMBER và CRYSTAL CODER, các LLM mã nguồn mở đầu tiên trong dòng LLM360. Trong tương lai, chúng tôi dự định phát hành thêm các LLM được huấn luyện trước lớn hơn về quy mô, thể hiện hiệu suất tốt hơn, và tập trung vào các lĩnh vực khác nhau.

Phần còn lại của báo cáo này được tổ chức như sau. Trong §2, chúng tôi thảo luận về các công trình liên quan và những tiền thân đã truyền cảm hứng cho LLM360. Trong §3, chúng tôi cung cấp mô tả về khung LLM360 và các sản phẩm phát hành thuộc phạm vi của nó. Trong §4, chúng tôi thảo luận về hai LLM đầu tiên được phát hành theo LLM360, AMBER (§4.1) và CRYSTAL CODER (§4.1.5), và các phân tích sơ bộ của cả hai. §6 kết luận.

--- TRANG 3 ---

2 Công trình liên quan
Dự án gần nhất với LLM360 là Pythia, cũng nhằm mục tiêu tái tạo hoàn toàn các LLM [16]. Dự án Pythia đã cung cấp 154 điểm kiểm tra cho kích thước mô hình từ 70M đến 12B để hỗ trợ tốt hơn nghiên cứu về hành vi mở rộng và động lực học tập của LLM. Trong khi Pythia là một công trình tiên phong, nó không còn phản ánh nhiều thực hành LLM gần đây, như huấn luyện trên tập dữ liệu nghìn tỷ token hoặc huấn luyện trên ngôn ngữ và mã trong các giai đoạn khác nhau. Mặt khác, LLM360 định nghĩa một khung phát hành ưu tiên tính minh bạch và khả năng tái tạo mà theo đó các mô hình cập nhật có thể tiếp tục được phát hành, và mô hình AMBER 7B của chúng tôi vượt qua mô hình Pythia 12B trong các điểm chuẩn công khai [17]. Nhìn chung, Pythia đã đặt ra một tiền lệ sớm cho tính minh bạch và khả năng tái tạo của LLM mà chúng tôi nhằm duy trì và mở rộng trong LLM360 cho các chế độ huấn luyện trước LLM hiện đại.

[Bảng 1: Tóm tắt các LLM mã nguồn mở đáng chú ý. Chúng tôi chú ý một xu hướng tiết lộ ít hơn các chi tiết huấn luyện trước quan trọng theo thời gian...]

Nói chung, các LLM mã nguồn mở trải dài một phổ rộng về tính minh bạch và khả năng tái tạo khi nói đến các sản phẩm phát hành của chúng. Nhiều LLM gần đây chỉ phát hành kiến trúc mô hình cuối cùng và trọng số, giữ nguồn dữ liệu và hầu hết chi tiết huấn luyện không được tiết lộ [4,24,6,25]. Một số được huấn luyện trên tập dữ liệu có sẵn công khai [18,19,21,16,11,10,26], trong khi những cái khác tiết lộ hỗn hợp dữ liệu của chúng nhưng không cung cấp dữ liệu sẵn sàng huấn luyện cho công chúng [20,3,22,23]. Một số LLM đáng chú ý đã được phát hành với chi tiết và sản phẩm minh bạch hơn đáng kể. Ví dụ, các mô hình EleutherAI như GPT-J [18] và GPT-NeoX [27] bao gồm mã huấn luyện, tập dữ liệu, và lên đến 150 điểm kiểm tra mô hình trung gian. Giá trị của mã huấn luyện GPT-NeoX mã nguồn mở được chứng minh bằng việc sử dụng nó trong huấn luyện trước LLM tiếp theo bởi những người khác trong cộng đồng [10,22]. INCITE [10], MPT [22], và OpenLLaMA [11] được phát hành với mã huấn luyện và tập dữ liệu huấn luyện, với RedPajama cũng phát hành 10 điểm kiểm tra mô hình trung gian.

--- TRANG 4 ---

Nhìn chung, chúng tôi quan sát một xu hướng là các LLM gần đây và có khả năng hơn đang trở nên đóng kín hơn trong các sản phẩm phát hành của chúng. Ngược lại, mục tiêu của LLM360 là phát hành các mô hình hiện đại và chất lượng cao trong khi duy trì mức độ minh bạch phát hành cao.

3 Khung LLM360
Trong phần này, chúng tôi trình bày LLM360, một khung để phát hành LLM nhằm thúc đẩy tính minh bạch mã nguồn mở, khả năng tái tạo, nguồn gốc dữ liệu/mô hình, và nghiên cứu hợp tác. LLM360 cung cấp hướng dẫn và khuyến nghị cho các sản phẩm phát hành được thu thập trong quá trình huấn luyện trước LLM và sau đó được cung cấp công khai cho cộng đồng.

Là một phần của việc ra mắt LLM360, chúng tôi cũng phát hành hai LLM được huấn luyện trước mới, mà chúng tôi hy vọng sẽ thúc đẩy sự quan tâm và hợp tác tức thì trong cộng đồng nghiên cứu mã nguồn mở. Đầu tiên, AMBER, một LLM ngôn ngữ tiếng Anh với 6.7B tham số được huấn luyện trên 1.25 nghìn tỷ token. Thứ hai, CRYSTAL CODER, một LLM tiếng Anh và mã, cũng với 6.7B tham số, được huấn luyện trên 1.4 nghìn tỷ token. Chi tiết về AMBER và CRYSTAL CODER được báo cáo trong §4.

Tập dữ liệu huấn luyện và mã xử lý dữ liệu. Tập dữ liệu huấn luyện trước là thành phần chính của một LLM và ảnh hưởng đáng kể đến khả năng của nó. Do đó, việc người dùng và người áp dụng có khả năng nhìn thấy dữ liệu huấn luyện trước để đánh giá các vấn đề hành vi và thành kiến tiềm ẩn là quan trọng. Ví dụ, những lo ngại gần đây về rò rỉ dữ liệu điểm chuẩn vào huấn luyện trước LLM dễ nghiên cứu hơn nhiều khi tập dữ liệu huấn luyện trước có sẵn để khám phá [8, 7].

Hơn nữa, dữ liệu huấn luyện trước có thể nhìn thấy cải thiện khả năng mở rộng của LLM trong tinh chỉnh và thích ứng lĩnh vực sau này. Công trình gần đây cho thấy rằng huấn luyện trên dữ liệu lặp lại làm giảm hiệu suất mô hình cuối cùng không tương xứng [28]. Cho độ rộng của dữ liệu mà huấn luyện trước hiện đại được thực hiện, khả năng nhìn thấy dữ liệu huấn luyện trước ban đầu là cần thiết để tránh dữ liệu lặp lại trong tinh chỉnh hạ nguồn hoặc tiếp tục huấn luyện trên các lĩnh vực chuyên biệt.

LLM360 ủng hộ việc phát hành công khai dữ liệu mà LLM được huấn luyện trước. Khi có thể áp dụng, chi tiết về lọc dữ liệu, xử lý, và thứ tự huấn luyện cũng nên được phát hành. Làm như vậy trang bị cho cộng đồng những công cụ tốt hơn để đánh giá khả năng và rủi ro của LLM và để tái tạo và xây dựng dựa trên các LLM hiện có cho các trường hợp sử dụng tương lai.

[Hình 1: Các sản phẩm được phát hành bởi dự án LLM360 bao gồm các khối dữ liệu, điểm kiểm tra mô hình, và chỉ số, tại hơn 360 dấu thời gian huấn luyện (và mã cho tất cả các phần).]

Mã huấn luyện, siêu tham số, và cấu hình. Những mã và cài đặt này có tác động đáng kể đến hiệu suất và chất lượng của việc huấn luyện LLM, và không phải lúc nào cũng được tiết lộ công khai. Ví dụ, chúng tôi quan sát thấy rằng một song song hóa lai dữ liệu-mô hình-đường ống (3D) được cân bằng cẩn thận [29] có thể vượt trội hơn FSDP tiêu chuẩn trong PyTorch lên đến 15% trên các cụm Nvidia A100 của chúng tôi. Một ví dụ khác chúng tôi quan sát là việc giữ ma trận tần số nghịch đảo trong nhúng vị trí RoPE ở FP32 [30] là cần thiết, điều này phù hợp với quan sát trong Qwen [24].

Trong LLM360, chúng tôi mã nguồn mở tất cả các khung huấn luyện trước LLM, siêu tham số, cũng như cấu hình. Những điều này bao gồm toàn bộ mã nguồn huấn luyện, tham số huấn luyện như tỷ lệ học và kích thước lô, và cấu hình hệ thống như kích thước song song hóa.

Điểm kiểm tra mô hình. Trong quá trình huấn luyện LLM, việc định kỳ lưu các điểm kiểm tra của mô hình vào bộ nhớ liên tục là điển hình. Những điểm kiểm tra này không chỉ quan trọng cho việc phục hồi từ lỗi trong quá trình huấn luyện, mà còn hữu ích trong nghiên cứu sau huấn luyện như nghiên cứu các lịch trình dữ liệu và/hoặc siêu tham số khác nhau, hoặc tái tạo các lỗi huấn luyện ít xảy ra (ví dụ, tăng vọt mất mát, kết quả NaN). Nghiên cứu gần đây về lượng tử hóa và nén mô hình dựa nhiều vào phân tích trọng số mô hình và động lực trong quá trình huấn luyện [31, 32].

Các mô hình LLM360 được xuất bản với tất cả các điểm kiểm tra trung gian được lưu trong quá trình huấn luyện của chúng, bao gồm trọng số mô hình và trạng thái tối ưu hóa (khi có thể áp dụng, ví dụ, trung bình di chuyển Adam [33]). Những điểm kiểm tra này cho phép tiếp tục huấn luyện từ một loạt điểm bắt đầu mà không cần huấn luyện từ đầu, làm cho việc nghiên cứu và tái tạo một loạt hiệu ứng rộng hơn trong quá trình huấn luyện trở nên dễ dàng hơn.

--- TRANG 5 ---

Chỉ số. LLM trải qua huấn luyện trong vài tuần đến vài tháng, và các xu hướng và mô hình tiến hóa trong thời gian huấn luyện này có thể cung cấp thông tin có giá trị. Tuy nhiên, quyền truy cập vào nhật ký chi tiết và chỉ số trung gian cho LLM hiện tại bị hạn chế với các nhóm tham gia huấn luyện trước, cản trở việc nghiên cứu toàn diện về LLM. Những thống kê này thường chứa những hiểu biết quan trọng không thể suy ra trực tiếp bằng cách khác, và ngay cả một phân tích đơn giản về các chỉ số, như tính toán phương sai chỉ số hoặc chuẩn, có thể tiết lộ những phát hiện quan trọng. Ví dụ, nhóm đằng sau GLM đã đề xuất một thuật toán thu nhỏ gradient hiệu quả để xử lý tăng vọt mất mát và mất mát NaN bằng cách phân tích hành vi chuẩn gradient [34].

Mục tiêu của chúng tôi với LLM360 là giảm bớt vấn đề này bằng cách mã nguồn mở hoàn toàn các nhật ký và chỉ số chúng tôi thu thập. Điều này bao gồm thống kê hệ thống (ví dụ, tải trọng GPU), nhật ký huấn luyện (ví dụ, mất mát, chuẩn gradient), và chỉ số đánh giá (ví dụ, độ bối rối, tác vụ hạ nguồn). Quyền truy cập vào những nhật ký này có thể tạo điều kiện cho hiểu biết sâu sắc hơn về toàn bộ quá trình huấn luyện, bao gồm cách LLM phát triển trong các kịch bản huấn luyện khác nhau. Chúng tôi cung cấp quyền truy cập dễ dàng vào các số liệu bằng cách chia sẻ trực tiếp trên trang Weights & Biases LLM360. Một vài chỉ số ví dụ bao gồm kết quả đánh giá hạ nguồn, mất mát huấn luyện, chuẩn gradient, v.v.

Trong §4.3, chúng tôi giới thiệu cách người ta có thể sử dụng các chỉ số, và minh họa một thí nghiệm theo dõi hành vi ghi nhớ của mô hình trong suốt quá trình huấn luyện. Các chỉ số được phát hành phối hợp với các khối dữ liệu và điểm kiểm tra để các nhà nghiên cứu có thể dễ dàng tìm thấy sự tương ứng của chúng. Hơn nữa, chúng tôi cung cấp quyền truy cập mở vào mã phân tích và đánh giá được sử dụng để thúc đẩy khả năng tái tạo. Mã và tất cả các chỉ số có thể được tìm thấy tại kho lưu trữ LLM360: Analysis360.

4 Phát hành mô hình ban đầu

4.1 Amber

[Hình 2: AMBER là LLM mã nguồn mở tiếng Anh 7B tham số.]

Trong phần này, chúng tôi giới thiệu AMBER, mô hình đầu tiên trong gia đình LLM360, cũng như các mô hình tinh chỉnh AMBER CHAT và AMBER SAFE.

4.1.1 Chi tiết về chuẩn bị dữ liệu và kiến trúc mô hình

Dưới đây chúng tôi xem xét chi tiết tập dữ liệu huấn luyện trước của chúng tôi, bao gồm tiền xử lý dữ liệu, định dạng, tỷ lệ trộn dữ liệu, cùng với chi tiết kiến trúc của mô hình LLM và các siêu tham số huấn luyện trước cụ thể. Thiết lập chính xác của AMBER có thể được tìm thấy trong cơ sở mã LLM360.

Chi tiết về tập dữ liệu huấn luyện trước của chúng tôi. Chúng tôi tiến hành quá trình chuẩn bị dữ liệu tương tự như OpenLLaMA. Cụ thể, dữ liệu huấn luyện trước của chúng tôi là hỗn hợp của RefinedWeb, StarCoder, và RedPajama-v1. Một sự khác biệt nhỏ với OpenLLaMA-v2 là việc bao gồm C4 của chúng tôi, vì chúng tôi không có ý định giới thiệu các tài liệu trùng lặp sau quá trình khử trùng lặp do RefinedWeb tiến hành. Chúng tôi đơn giản ghép tất cả các tập dữ liệu đã nêu ban đầu (không có bất kỳ làm sạch, lọc, hoặc lấy mẫu phụ nào), tiến hành hoán vị toàn cục, và phân chia chúng đều thành 360 khối dữ liệu. Tổng cộng, chúng tôi có 1.26 Nghìn tỷ token. Bảng 2 trình bày sự kết hợp.

Kiến trúc LLM. Chúng tôi sử dụng kiến trúc mô hình giống hệt với LLaMA 7B. Cấu hình kiến trúc LLM chi tiết được tóm tắt trong Bảng 3, kết hợp các nhúng vị trí xoay (RoPE) tại mỗi lớp của mạng [30].

Thủ tục huấn luyện trước và siêu tham số. Chúng tôi tuân theo các siêu tham số huấn luyện trước từ LLaMA càng gần càng tốt [3]. AMBER được huấn luyện sử dụng tối ưu hóa AdamW với các siêu tham số sau: β₁= 0.9, β₂= 0.95. Tỷ lệ học ban đầu được đặt thành η= 3e⁻⁴, theo lịch trình tỷ lệ học cosine giảm xuống tỷ lệ cuối cùng η= 3e⁻⁵. Chúng tôi áp dụng suy giảm trọng số 0.1 và sử dụng cắt gradient tại 1.0. Mô hình được làm ấm trong 2,000 bước. Khác với thiết lập LLaMA, dựa trên cài đặt phần cứng của chúng tôi với 224 GPU, chúng tôi sử dụng kích thước lô huấn luyện trước 2,240 (224×10) thay vì 2,048.

[Bảng 2: Hỗn hợp dữ liệu trong huấn luyện trước AMBER.]
[Bảng 3: Kiến trúc LLM & siêu tham số.]

4.1.2 Chi tiết về cơ sở hạ tầng huấn luyện trước

[Hình 3: Mất mát huấn luyện của AMBER qua tất cả các điểm kiểm tra mô hình.]

AMBER được huấn luyện trên một cụm GPU nội bộ.

Cụm GPU. Cụm GPU bao gồm 56 nút DGX A100, mỗi nút được trang bị 4×80GB A100 GPU. Mỗi GPU được kết nối với 4 liên kết NVLink. Cài đặt kết nối giữa các nút là 2 cổng 200 Gb/giây (4 ×HDR) InfiniBand. Thông lượng chúng tôi quản lý để đạt được với khung huấn luyện phân tán của chúng tôi là khoảng 582.4 k token mỗi giây.

Khung huấn luyện trước. Khung huấn luyện trước của chúng tôi là lit-llama được phát triển dựa trên PyTorch Lightning. Chúng tôi sử dụng độ chính xác hỗn hợp trong huấn luyện trước với BF16 cho kích hoạt và gradient và FP32 cho trọng số mô hình [35].

4.1.3 Các mô hình AMBER tinh chỉnh

Chúng tôi cũng phát hành một vài phiên bản tinh chỉnh của AMBER, cụ thể là AMBER CHAT và AMBER SAFE.

AMBER CHAT được huấn luyện trên dữ liệu huấn luyện hướng dẫn tiến hóa như được sử dụng bởi WizardLM [36]. Chúng tôi sử dụng FastChat [37] để tinh chỉnh mô hình trong 3 epoch trên 8 A100 (80G) được phân phối bởi FSDP [38], tỷ lệ học là 2×10⁻⁵, các bước tích lũy gradient là 16, tỷ lệ làm ấm là 0.04. Chúng tôi cũng tinh chỉnh một phiên bản được căn chỉnh của mô hình: AMBER SAFE, bằng cách tiến hành Tối ưu hóa Tham số Trực tiếp (DPO) [39]. AMBER SAFE được huấn luyện trên ShareGPT 90K, và được tối ưu hóa thêm trên tập dữ liệu SafeRLHF [40]. Chúng tôi đặt β thành 0.1, các bước tích lũy gradient thành 4, và tỷ lệ học thành 5×10⁻⁷.

4.1.4 Kết quả và phân tích

Kết quả điểm chuẩn. Chúng tôi sử dụng bốn tập dữ liệu điểm chuẩn trong Open LLM Leaderboard làm đánh giá của chúng tôi về các khía cạnh khác nhau, tức là, ARC, HellaSwag, MMLU, và TruthfulQA, theo cài đặt bảng xếp hạng. Chúng tôi chạy đánh giá trên tất cả 360 điểm kiểm tra, để quan sát khả năng mô hình trong suốt quá trình huấn luyện trước. Như được hiển thị trong Hình 4, chúng tôi có thể thấy rằng điểm đánh giá HellaSwag và ARC tăng đơn điệu trong quá trình huấn luyện trước, trong khi điểm TruthfulQA dường như giảm khi quá trình huấn luyện tiến hành. Một xu hướng thú vị khác được quan sát trong tiến trình MMLU, nơi điểm giảm trong giai đoạn đầu của huấn luyện trước và sau đó bắt đầu tăng.

[Hình 4: Kết quả cho AMBER trên các chỉ số bảng xếp hạng Open LLM.]

Trong Bảng 4, chúng tôi so sánh hiệu suất mô hình cuối cùng của AMBER với một tập hợp các mô hình được huấn luyện xung quanh thời gian tương tự, cụ thể là OpenLLaMA, RedPajama-INCITE, Falcon, MPT. Nhiều mô hình được truyền cảm hứng từ thiết kế của LLaMA. Chúng tôi thấy rằng AMBER tương đối cạnh tranh trong các điểm như MMLU, nhưng hiệu suất của nó trên ARC tụt hậu so với đường cong. Chúng tôi cũng thấy rằng các mô hình AMBER tinh chỉnh của chúng tôi tương đối mạnh, ngay cả khi so sánh với các mô hình tương tự khác. Trong nghiên cứu sớm của chúng tôi, chúng tôi lưu ý rằng AMBER CHAT đơn giản được huấn luyện trên ShareGPT 90K cũng cho thấy hiệu suất cao hơn nhiều so với mô hình cơ bản của chúng tôi, điều này hơi khác với xu hướng được hiển thị trên các mô hình khác trong bảng. Chúng tôi để lại điều tra thêm về điều này cho công việc tương lai.

[Bảng 4: So sánh bảng xếp hạng Open LLM cho một vài LLM được phát triển xung quanh cùng thời gian.]

--- TRANG 8 ---

4.1.5 Các vấn đề gặp phải trong quá trình huấn luyện trước

Trong phần này, chúng tôi thảo luận về một số vấn đề chính gặp phải trong quá trình huấn luyện trước của AMBER. Những vấn đề này có thể ảnh hưởng đến hiệu suất mô hình cuối cùng của chúng tôi. Chúng tôi đã giải quyết hầu hết những vấn đề này trong các nỗ lực huấn luyện trước LLM tiếp theo.

Mất mát NaN trên một vài khối dữ liệu. Trong quá trình huấn luyện trước, chúng tôi gặp phải mất mát NaN trong bốn trong số 360 khối dữ liệu. Bất cứ khi nào chúng tôi đối mặt với vấn đề này, chúng tôi tạm thời bỏ qua toàn bộ khối dữ liệu. Ban đầu kế hoạch của chúng tôi là huấn luyện trên bốn khối dữ liệu này trong giai đoạn sau của huấn luyện, tuy nhiên, chúng tôi thấy rằng những khối dữ liệu này có xu hướng gây ra mất mát NaN bất kể vị trí của huấn luyện. Chúng tôi kết thúc việc hoàn thành huấn luyện bằng cách lấy bốn khối đầu tiên từ chuỗi huấn luyện để hoàn thành lịch trình tỷ lệ học của chúng tôi.

Thiếu trạng thái tối ưu hóa. Trong khung huấn luyện trước của chúng tôi, chúng tôi không quản lý để lưu trạng thái tối ưu hóa; chúng tôi chỉ lưu các điểm kiểm tra mô hình cho mỗi khối dữ liệu. Sự thiếu sót này có thể là nguyên nhân của vấn đề mất mát NaN được quan sát trong bốn khối dữ liệu, như đã đề cập trước đó. Mỗi khi chúng tôi tiếp tục huấn luyện trước từ một điểm kiểm tra mô hình trước đó, trạng thái tối ưu hóa trong tối ưu hóa AdamW được khởi tạo lại. Việc khởi tạo lại này có thể ảnh hưởng đến tính ổn định huấn luyện mô hình.

Sự khác biệt về độ chính xác của điểm kiểm tra. Trong giai đoạn đầu của huấn luyện trước, cơ sở mã của chúng tôi có vấn đề khi các điểm kiểm tra mô hình được lưu với độ chính xác BF16, mặc dù quá trình huấn luyện độ chính xác hỗn hợp của chúng tôi duy trì trọng số mô hình ở FP32. Vấn đề này sau đó được xác định và sửa chữa bởi nhóm của chúng tôi, đảm bảo rằng tất cả các điểm kiểm tra mô hình tiếp theo được lưu với độ chính xác FP32. Chúng tôi dự đoán rằng các điểm kiểm tra mô hình BF16 ban đầu có thể đã góp phần vào một mức độ giảm độ chính xác trong mô hình.

4.2 CRYSTAL CODER

[Hình 5: CRYSTAL CODER là LLM mã nguồn mở tiếng Anh và mã 7B tham số.]

Phần này cung cấp tóm tắt về tập dữ liệu và kiến trúc mô hình được sử dụng trong CRYSTAL CODER. Để đánh giá chi tiết kết quả trên các điểm chuẩn và so sánh với các công trình trước đó về các điểm chuẩn cụ thể, chúng tôi giới thiệu độc giả đến các báo cáo tương lai của chúng tôi.

Tập dữ liệu huấn luyện trước 3 giai đoạn. Tập dữ liệu huấn luyện trước được sử dụng trong CRYSTAL CODER là sự pha trộn của dữ liệu SlimPajama [41] và StarCoder [42] với khoảng 1382B token tổng cộng. Khác với các cách tiếp cận trước đó như Code Llama [43], huấn luyện nghiêm ngặt tuần tự trên dữ liệu tiếng Anh và mã hóa, chúng tôi áp dụng cách tiếp cận dần dần hơn bằng cách kết hợp liền mạch và huấn luyện trên cả hai loại dữ liệu, để cung cấp sự cân bằng giữa mã và khả năng chung. Quá trình huấn luyện được chia thành ba giai đoạn. Trong giai đoạn đầu tiên, chúng tôi huấn luyện trên một nửa dữ liệu SlimPajama, tổng cộng khoảng 345 tỷ token. Chuyển sang giai đoạn thứ hai, nửa còn lại của dữ liệu SlimPajama được sử dụng, cùng với hai epoch dữ liệu StarCoder, dẫn đến khoảng 927 tỷ token. Trong giai đoạn thứ ba, chúng tôi huấn luyện trên dữ liệu Python và liên quan đến web, bao gồm các tập con HTML, JavaScript, và CSS từ StarCoder, tổng cộng 100 tỷ token. Ngoài ra, chúng tôi lấy mẫu 10 tỷ token từ tập dữ liệu SlimPajama trong giai đoạn này. Dữ liệu được xử lý trước và các script trộn dữ liệu được phát hành trong kho lưu trữ Huggingface và Github của LLM360.

Kiến trúc mô hình. CRYSTAL CODER sử dụng kiến trúc mô hình giống hệt với LLaMA 7B, với việc kết hợp tham số hóa cập nhật tối đa (muP) [44]. Ngoài tham số hóa cụ thể này, chúng tôi đã thực hiện một số sửa đổi nhỏ, việc áp dụng RoPE được hạn chế vào 25% đầu tiên của các chiều ẩn (tương tự như triển khai của GPT-NeoX [27]), và việc sử dụng độ dài chuỗi 2048 với chiều nhúng 32032. Ngoài ra, chúng tôi đơn giản sử dụng LayerNorm thay vì RMSNorm vì kiến trúc CG-1 hỗ trợ tính toán hiệu quả cho LayerNorm vanilla.

Cơ sở hạ tầng tính toán. CRYSTAL CODER được huấn luyện trên Cerebras Condor Galaxy 1 (CG-1), một siêu máy tính AI đám mây 4 exaFLOPS, 54 triệu lõi, 64 nút.

--- TRANG 9 ---

[Hình 6: Kết quả cho CRYSTAL CODER trên các chỉ số bảng xếp hạng Open LLM. Các đường thẳng đứt nét xám biểu thị sự chuyển đổi giữa ba giai đoạn huấn luyện.]

Bảng xếp hạng Open LLM và đánh giá mã. Chúng tôi cũng đánh giá mô hình này trên bốn tập dữ liệu điểm chuẩn trong Open LLM Leaderboard (tương tự như AMBER), cũng như các tập dữ liệu điểm chuẩn mã hóa, bao gồm HumanEval pass@1, và MBPP pass@1. Chúng tôi hiển thị kết quả trong Hình 6.

[Bảng 5: So sánh đánh giá giữa một vài mô hình mã và ngôn ngữ đáng chú ý. Cột cuối cùng là trung bình của trung bình tác vụ ngôn ngữ và trung bình tác vụ mã. CRYSTAL CODER đạt được sự cân bằng tốt giữa cả tác vụ ngôn ngữ và mã.]

--- TRANG 10 ---

[Hình 7: Mỗi hàng tương ứng với phân phối điểm ghi nhớ của một điểm kiểm tra. Chúng tôi chú thích tỷ lệ phần trăm của điểm = 1 (k-extractible) để minh họa rõ ràng hơn.]

[Hình 8: Điểm ghi nhớ trên khối dữ liệu cho mỗi điểm kiểm tra. Các điểm được đánh dấu cho biết khối mới nhất được nhìn thấy bởi điểm kiểm tra đó. Phần bên phải của mỗi dấu cho biết dữ liệu chưa thấy.]

[Hình 9: Tương quan của các chuỗi về mặt điểm ghi nhớ và k-extractible giữa các điểm kiểm tra]

4.3 ANALYSIS 360

Công trình trước đó như Pythia [16] đã cho thấy rằng một nghiên cứu sâu sắc có thể được thực hiện bằng cách phân tích các điểm kiểm tra trung gian của mô hình. Chúng tôi hy vọng LLM360 cũng có thể cung cấp cho cộng đồng các tài nguyên hữu ích cho cả mục đích tham khảo và nghiên cứu. Để kết thúc này, chúng tôi phát hành phiên bản đầu tiên của dự án ANALYSIS 360, một kho lưu trữ có tổ chức phân tích hành vi mô hình về các khía cạnh khác nhau, bao gồm đặc điểm mô hình và kết quả đánh giá hạ nguồn.

Như một ví dụ về phân tích có thể được thực hiện trên tập hợp các điểm kiểm tra mô hình, chúng tôi tiến hành một nghiên cứu sơ bộ về ghi nhớ trong LLM. Công trình gần đây [45,46] cho thấy rằng LLM có thể ghi nhớ một phần đáng kể dữ liệu huấn luyện của chúng, có thể được trích xuất với gợi ý thích hợp. Việc ghi nhớ như vậy không chỉ gây ra lo ngại về quyền riêng tư trong việc rò rỉ dữ liệu huấn luyện riêng tư, mà còn làm giảm hiệu suất của LLM nếu dữ liệu huấn luyện chứa các bản sao hoặc đặc thù không mong muốn. Khi chúng tôi phát hành tất cả các điểm kiểm tra và dữ liệu, chúng tôi có thể tiến hành phân tích toàn diện về ghi nhớ trong toàn bộ giai đoạn huấn luyện.

Chúng tôi áp dụng điểm ghi nhớ được giới thiệu trong [12], cho biết độ chính xác của token trong việc tiếp tục độ dài l với một gợi ý có độ dài k,

điểm(k, l) = 1/l ∑ᵢ₌₁ˡ 1[Sₖ₊ᵢ = Gₖ₊ᵢ],

trong đó S₀:ₖ₊ₗ là chuỗi từ dữ liệu huấn luyện, trong khi Gₖ:ₖ₊ₗ là chuỗi được tạo ra với gợi ý S₀:ₖ. Một chuỗi được ghi nhớ hoặc k-extractible [45] có điểm ghi nhớ bằng 1. Theo [12,16], chúng tôi tiến hành thí nghiệm với k=l=32. Chúng tôi lấy mẫu 1000 chuỗi từ mỗi trong số 360 khối dữ liệu, và sử dụng 64 token đầu tiên của mỗi chuỗi để tiến hành các thí nghiệm sau.

Chúng tôi hiển thị phân phối điểm ghi nhớ cho 10 điểm kiểm tra được chọn trong Hình 7, và bổ sung chú thích tỷ lệ phần trăm của điểm = 1. Đối với mỗi điểm kiểm tra, chúng tôi chỉ bao gồm các khối dữ liệu mà nó đã được huấn luyện. Từ kết quả, chúng tôi học được rằng 1) Hơn 1% chuỗi là 32-extractible từ AMBER; 2) AMBER có thể ghi nhớ nhiều chuỗi hơn với việc huấn luyện tiếp tục; 3) Đỉnh ở điểm = 1 cho thấy rằng AMBER có thể ghi nhớ một số lượng token lớn hơn nhiều so với ngưỡng đặt trước 32 của chúng tôi (phù hợp với công trình trước đó [46, 12]).

Chúng tôi nhóm các khối dữ liệu theo các điểm kiểm tra được chọn, và vẽ điểm ghi nhớ trên mỗi nhóm khối dữ liệu cho mỗi điểm kiểm tra trong Hình 8. Chúng tôi thấy rằng 1) Các điểm kiểm tra AMBER ghi nhớ dữ liệu được nhìn thấy mới nhất nhiều hơn so với dữ liệu trước đó; 2) Đối với mỗi khối dữ liệu, điểm ghi nhớ giảm một chút với huấn luyện bổ sung, nhưng tiếp tục tăng sau đó.

Chúng tôi hiển thị tương quan giữa các chuỗi về mặt điểm ghi nhớ hoặc k-extractible trong Hình 9. Chúng tôi chứng kiến tương quan mạnh giữa các điểm kiểm tra.

5 Tóm tắt và thông điệp rút ra

Trong phần này, chúng tôi tóm tắt các quan sát và một vài thông điệp rút ra từ huấn luyện trước AMBER và CRYSTAL CODER của chúng tôi, những nỗ lực mô hình hóa ban đầu trong dòng LLM360. Chúng tôi hiểu rằng huấn luyện trước là một nhiệm vụ đòi hỏi tính toán khủng khiếp mà nhiều phòng thí nghiệm học thuật hoặc tổ chức nhỏ không thể đủ khả năng tiến hành. Chúng tôi hy vọng rằng LLM360 có thể cung cấp kiến thức toàn diện, cho phép người dùng hiểu những gì xảy ra trong quá trình huấn luyện trước LLM (ví dụ, hành vi đường cong mất mát, cách các chỉ số đánh giá xuất hiện, v.v.) mà không cần phải làm như vậy. Chúng tôi cũng cung cấp một số trường hợp sử dụng tiềm năng cho thấy cách các nhà nghiên cứu và nhà phát triển có thể sử dụng LLM360 cho các dự án của riêng họ.

Thông điệp rút ra. Dưới đây chúng tôi liệt kê một vài bài học được học trong quá trình huấn luyện mô hình ban đầu của chúng tôi.

• Trong huấn luyện trước của AMBER, mất mát NaN được quan sát định kỳ, có thể do một số trạng thái ngẫu nhiên nhất định, độ chính xác huấn luyện, hoặc vấn đề chất lượng dữ liệu. Một số giải pháp bao gồm chuyển sang một hạt giống ngẫu nhiên khác hoặc bỏ qua những khối dữ liệu đó. Chúng tôi nhận thấy một số khối dữ liệu "hành xử sai" có thể gây ra mất mát NaN bất kể khi chúng được huấn luyện. Trong một thí nghiệm sơ bộ, chúng tôi di chuyển các khối dữ liệu "hành xử sai" đến cuối quá trình huấn luyện nhưng vẫn quan sát thấy mất mát NaN.

• Trong huấn luyện trước của CRYSTAL CODER và các nỗ lực huấn luyện trước LLM tiếp theo của chúng tôi, chúng tôi quan sát thấy rằng một chiến lược song song hóa lai và được điều chỉnh cẩn thận—kết hợp các chiến lược song song hóa dữ liệu, tensor-mô hình, và đường ống (còn được gọi là 3D) [29]—đạt được thông lượng hệ thống tốt hơn so với FSDP, đặc biệt là trong các cụm phân tán với băng thông nút nội bộ hạn chế.

• Làm sạch dữ liệu (và/hoặc lọc chất lượng dữ liệu), cùng với tỷ lệ trộn dữ liệu, là các khía cạnh quan trọng của huấn luyện trước LLM, cũng như lịch trình cho các danh mục dữ liệu huấn luyện trước khác nhau (ví dụ, CommonCrawl, Books, StarCoder, v.v.). Trong huấn luyện trước AMBER, chúng tôi cố gắng tuân thủ càng gần càng tốt với các siêu tham số được sử dụng trong LLaMA; tuy nhiên, hiệu suất của chúng tôi vẫn tụt hậu đáng kể so với LLaMA. Một thiếu sót chính trong báo cáo kỹ thuật của LLaMA là mô tả chi tiết về tập dữ liệu huấn luyện trước chính xác của họ. Tập dữ liệu huấn luyện trước CRYSTAL CODER được tạo ra cẩn thận của chúng tôi, trộn dữ liệu tiếng Anh và mã hóa, đạt được hiệu suất cạnh tranh với LLaMA trên cả Open LLM Leaderboard và các điểm chuẩn đánh giá mã.

Chúng tôi, cùng với toàn bộ cộng đồng mã nguồn mở LLM, đang siêng năng khám phá các cách tiếp cận tốt nhất để làm sạch dữ liệu, lọc chất lượng dữ liệu, và xác định tỷ lệ trộn dữ liệu tối ưu, một nỗ lực tiên phong được minh họa bởi phương pháp DoReMi [15].

Các trường hợp sử dụng tiềm năng của LLM360. Chúng tôi mô tả một vài trường hợp sử dụng tiềm năng của LLM360 dưới đây.

• Người ta có thể tiến hành các nghiên cứu thí nghiệm tại bất kỳ giai đoạn nào của huấn luyện mô hình. Như đã đề cập trước đó, tỷ lệ trộn dữ liệu tối ưu vẫn là một vấn đề mở đáng kể trong huấn luyện trước LLM. Tuy nhiên, việc xác minh một tỷ lệ trộn cụ thể bằng cách tiến hành huấn luyện trước LLM đầy đủ gần như là không thể. Một cách tiếp cận khả thi hơn là điều chỉnh tỷ lệ trộn dữ liệu một cách nhanh chóng, tức là, bắt đầu từ một điểm kiểm tra trung gian, và tăng hoặc giảm tỷ lệ dữ liệu cụ thể từ một danh mục cụ thể, ví dụ, tăng trọng số dữ liệu trong Wikipedia.

• Để xây dựng LLM dành riêng cho lĩnh vực (ví dụ, y tế, tài chính, pháp luật, v.v.), người ta có thể không nhất thiết muốn bắt đầu từ điểm kiểm tra LLM được huấn luyện trước cuối cùng (điều này sẽ làm cho nó giống với tinh chỉnh hơn). Thay vào đó, người ta luôn có thể chọn một trong các điểm kiểm tra LLM360 (ví dụ, từ 50% giai đoạn huấn luyện trước) và tiếp tục huấn luyện trước để có được LLM dành riêng cho lĩnh vực.

--- TRANG 12 ---

• Rất nhiều khung xấp xỉ thuật toán để huấn luyện hiệu quả yêu cầu trọng số mô hình được huấn luyện một phần [47,48]. LLM360 cung cấp khởi tạo mô hình hoàn hảo cho những phương pháp đó.

LLM360 và sử dụng có trách nhiệm. Cho tính ứng dụng rộng rãi và hiệu suất cao của LLM, các ứng dụng được hỗ trợ bởi chúng có tiềm năng ảnh hưởng sâu sắc đến các khía cạnh khác nhau của cuộc sống. Do đó, việc tất cả các bên liên quan trong chuỗi sản xuất LLM cần quản lý cẩn thận tác động và rủi ro tiềm ẩn liên quan đến chúng trở nên cần thiết. Tất cả các bên liên quan cần được thông báo về những tác động này và thực hiện các hành động cần thiết tương ứng.

Chúng tôi tin rằng bản chất minh bạch của sáng kiến LLM360 có thể giúp làm cho các rủi ro tiềm ẩn được các bên liên quan biết đến. Như một ví dụ, nhiều rủi ro liên quan đến LLM liên quan đến các hình thức thành kiến nhất định [49], chẳng hạn như rủi ro về các khuôn mẫu xã hội, phân biệt đối xử và loại trừ, và rủi ro về việc đại diện dưới mức cho một số ngôn ngữ hoặc lĩnh vực nhất định. Bằng cách kiểm tra dữ liệu huấn luyện chính xác và phân tích thành kiến (ví dụ BOLD [50]) trong ANALYSIS 360, các bên liên quan có thể có một đánh giá toàn diện về những rủi ro này trước khi triển khai các mô hình. LLM360 cũng có thể giúp giảm thiểu rủi ro. Dự án chia sẻ các dấu vết có thể tái tạo và dữ liệu chính xác trong quá trình huấn luyện LLM, cung cấp một môi trường có thể tái sử dụng cho các nhà nghiên cứu để tiến hành thí nghiệm nhằm thiết kế các rào cản tốt hơn để kiểm soát các rủi ro tiềm ẩn.

Chúng tôi hiểu tầm quan trọng của việc kiểm soát rủi ro của LLM và chúng tôi cam kết phát triển thêm khung LLM360 để thúc đẩy việc sử dụng có trách nhiệm của LLM. Chúng tôi muốn mời cộng đồng làm việc với chúng tôi, bằng cách chia sẻ kết quả nghiên cứu hoặc đơn giản là cung cấp phản hồi.

6 Kết luận và công việc tương lai

Trong bài báo này, chúng tôi giới thiệu LLM360, một sáng kiến cho các LLM mã nguồn mở toàn diện và hoàn toàn. Cùng với việc phát hành đầu tiên của LLM360, chúng tôi phát hành hai LLM 7B: AMBER (một LLM mục đích chung tiếng Anh) và CRYSTAL CODER (một LLM được huấn luyện trước cụ thể cho tạo mã). Về mặt sản phẩm, chúng tôi phát hành mã huấn luyện trước, cấu hình, siêu tham số, các điểm kiểm tra mô hình trung gian, trạng thái tối ưu hóa, cũng như chuỗi dữ liệu và mã xử lý dữ liệu. Tầm nhìn của chúng tôi là thúc đẩy và phát triển đáng kể tính minh bạch trong cộng đồng huấn luyện trước LLM mã nguồn mở.

Đối với công việc tương lai, chúng tôi đang tiến hành phân tích chi tiết hơn về các mô hình cơ bản AMBER và CRYSTAL CODER cũng như các mô hình tinh chỉnh của chúng. Kết quả chi tiết sẽ được phát hành và thảo luận trong các báo cáo kỹ thuật tương ứng của chúng. Nhóm của chúng tôi cũng đang huấn luyện trước một LLM lớn hơn nhiều, sẽ được phát hành đầy đủ ngay khi hoàn thành huấn luyện trước. Ngoài ra, chúng tôi sẽ khám phá tỷ lệ tối ưu để trộn các tập con khác nhau trong tập dữ liệu huấn luyện trước.

Lời cám ơn
Chúng tôi muốn cảm ơn Natalia Vassilieva, Joel Hestness, William Marshall, và Bhargav Kanakiya vì đóng góp của họ cho CRYSTAL CODER và hỗ trợ dự án LLM360. Chúng tôi cũng muốn cảm ơn nhóm MBZUAI và Cerebras vì cung cấp và quản lý cơ sở hạ tầng tính toán.

Tài liệu tham khảo
[1] OpenAI. Báo cáo kỹ thuật Gpt-4, 2023.
[2] Claude. Thẻ mô hình Claude 2.1. Báo cáo kỹ thuật, Claude Inc., 2023.
[3] Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, et al. Llama: Mô hình ngôn ngữ nền tảng mở và hiệu quả. arXiv preprint arXiv:2302.13971, 2023.
[4] Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al. Llama 2: Mô hình nền tảng mở và tinh chỉnh trò chuyện. arXiv preprint arXiv:2307.09288, 2023.
[5] Guilherme Penedo, Quentin Malartic, Daniel Hesslow, Ruxandra Cojocaru, Alessandro Cappelli, Hamza Alobeidli, Baptiste Pannier, Ebtesam Almazrouei, và Julien Launay. Tập dữ liệu refinedweb cho falcon llm: vượt trội hơn các kho dữ liệu được tuyển chọn với dữ liệu web, và chỉ dữ liệu web. arXiv preprint arXiv:2306.01116, 2023.
[6] Albert Q Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra Singh Chaplot, Diego de las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile Saulnier, et al. Mistral 7b. arXiv preprint arXiv:2310.06825, 2023.
[7] Tianwen Wei, Liang Zhao, Lichang Zhang, Bo Zhu, Lijie Wang, Haihua Yang, Biye Li, Cheng Cheng, Weiwei Lü, Rui Hu, Chenxia Li, Liu Yang, Xilin Luo, Xuejie Wu, Lunan Liu, Wenjun Cheng, Peng Cheng, Jianhao Zhang, Xiaoyu Zhang, Lei Lin, Xiaokun Wang, Yutuan Ma, Chuanhai Dong, Yanqi Sun, Yifu Chen, Yongyi Peng, Xiaojuan Liang, Shuicheng Yan, Han Fang, và Yahui Zhou. Skywork: Một mô hình nền tảng song ngữ mở hơn, 2023.
[8] Kun Zhou, Yutao Zhu, Zhipeng Chen, Wentong Chen, Wayne Xin Zhao, Xu Chen, Yankai Lin, Ji-Rong Wen, và Jiawei Han. Đừng làm cho llm của bạn thành một kẻ gian lận điểm chuẩn đánh giá, 2023.
[9] Together Computer. Redpajama: một tập dữ liệu mở để huấn luyện mô hình ngôn ngữ lớn, 2023.
[10] Together Computer. Redpajama-incite-7b-base, 2023.
[11] Xinyang Geng và Hao Liu. Openllama: Một bản tái tạo mở của llama, Tháng 5 2023.
[12] Stella Biderman, USVSN Sai Prashanth, Lintang Sutawika, Hailey Schoelkopf, Quentin Anthony, Shivanshu Purohit, và Edward Raf. Ghi nhớ xuất hiện và có thể dự đoán trong mô hình ngôn ngữ lớn. arXiv preprint arXiv:2304.11158, 2023.
[13] Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, Ed H. Chi, Tatsunori Hashimoto, Oriol Vinyals, Percy Liang, Jeff Dean, và William Fedus. Khả năng xuất hiện của mô hình ngôn ngữ lớn, 2022.
[14] Yue Yu, Yuchen Zhuang, Jieyu Zhang, Yu Meng, Alexander Ratner, Ranjay Krishna, Jiaming Shen, và Chao Zhang. Mô hình ngôn ngữ lớn như một bộ tạo dữ liệu huấn luyện có thuộc tính: Một câu chuyện về tính đa dạng và thành kiến, 2023.
[15] Sang Michael Xie, Hieu Pham, Xuanyi Dong, Nan Du, Hanxiao Liu, Yifeng Lu, Percy Liang, Quoc V Le, Tengyu Ma, và Adams Wei Yu. Doremi: Tối ưu hóa hỗn hợp dữ liệu tăng tốc huấn luyện trước mô hình ngôn ngữ. arXiv preprint arXiv:2305.10429, 2023.

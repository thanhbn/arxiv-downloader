# 2012.02909.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/data-augmentation/2012.02909.pdf
# Kích thước tệp: 4800969 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Điều gì tạo nên một "Tăng cường Dữ liệu tốt" trong
Chưng cất Kiến thức – Một Góc nhìn Thống kê
Huan Wang1;2;ySuhas Lohit2;Mike Jones2Yun Fu1
1Northeastern University, Boston, MA2MERL, Cambridge, MA
Dự án: http://huanwang.tech/Good-DA-in-KD
Giáo viên(cố định)Học sinh
Đầu vào thô𝑥!
Đầu vào𝑥
TĐL chuẩnTĐL mạnh hơnĐầu vào𝑥'
Hàm mất mát KLDiv.Làm thế nào để định nghĩa TĐL "mạnh hơn"?
0.00425 0.00450 0.00475 0.00500 0.00525 0.00550
T. stddev1.001.051.10Mất mát kiểm tra S.Pearson: 0.9581 (p-value: 0.00%)
Spearman: 0.9667 (p-value: 0.00%)
Kendall: 0.8889 (p-value: 0.02%)wrn_40_2/wrn_16_2, CIFAR100
Đồng nhất
Lật
Cắt+Lật
Cutout
AutoAugment
Mixup
CutMix
CutmixPick (S. ent.)
CutmixPick (T. ent.)
(a) Áp dụng TĐL mạnh hơn bổ sung trong KD (b) Mất mát kiểm tra S. so với T. stddev với các sơ đồ TĐL khác nhau
Hình 1: (a) Minh họa việc áp dụng tăng cường dữ liệu (TĐL) mạnh hơn bổ sung với TĐL chuẩn (cắt ngẫu nhiên và lật) trong chưng cất kiến thức (KD). Chúng tôi hỏi: Điều gì tạo nên một TĐL "tốt" khi được áp dụng cho KD theo cách của (a)? (b) Chúng tôi trình bày một mệnh đề đã được chứng minh (Mệnh đề 3.1) để trả lời câu hỏi này một cách nghiêm ngặt, cùng với một chỉ số thực tế để đánh giá "tính tốt" của TĐL. Chỉ số được đề xuất gọi là độ lệch chuẩn của xác suất trung bình của giáo viên (viết tắt là T. stddev). Như thấy trong (b), có một tương quan dương mạnh (p-value < 5% thường được coi là có ý nghĩa thống kê) giữa mất mát kiểm tra của học sinh (Mất mát kiểm tra S.) và T. stddev, cho thấy T. stddev nắm bắt tốt "tính tốt" của các sơ đồ TĐL khác nhau trong KD. Sự thật nổi bật nhất từ biểu đồ này có thể là: T. stddev được tính toán hoàn toàn với giáo viên (không sử dụng học sinh nào) trong khi nó có thể "dự đoán" thứ tự tương đối của hiệu suất học sinh, ngụ ý rằng "tính tốt" của TĐL trong KD có thể là bất biến với học sinh.

Tóm tắt
Chưng cất kiến thức (KD) là một phương pháp huấn luyện mạng nơ-ron tổng quát sử dụng mô hình giáo viên để hướng dẫn mô hình học sinh. Các công trình hiện có chủ yếu nghiên cứu KD từ phía đầu ra mạng (ví dụ, cố gắng thiết kế hàm mất mát KD tốt hơn), trong khi ít có cố gắng hiểu nó từ phía đầu vào. Đặc biệt, mối tương tác của nó với tăng cường dữ liệu (TĐL) chưa được hiểu rõ. Trong bài báo này, chúng tôi hỏi: Tại sao một số sơ đồ TĐL (ví dụ, CutMix) về bản chất hoạt động tốt hơn nhiều so với những sơ đồ khác trong KD? Điều gì tạo nên một TĐL "tốt" trong KD? Điều tra của chúng tôi từ góc độ thống kê cho thấy rằng một sơ đồ TĐL tốt nên giảm hiệp phương sai của cross-entropy giáo viên-học sinh. Một chỉ số thực tế, độ lệch chuẩn của xác suất trung bình của giáo viên (T. stddev), được trình bày thêm và được chứng minh tốt về mặt thực nghiệm. Ngoài hiểu biết lý thuyết, chúng tôi cũng giới thiệu một sơ đồ TĐL trộn dữ liệu dựa trên entropy mới, CutMixPick, để tăng cường thêm CutMix. Các nghiên cứu thực nghiệm rộng rãi hỗ trợ các tuyên bố của chúng tôi và chứng minh cách chúng tôi có thể thu hoạch được những cải thiện hiệu suất đáng kể chỉ bằng cách sử dụng một sơ đồ TĐL tốt hơn trong chưng cất kiến thức.

†Bài báo này bắt nguồn từ công việc thực tập mùa hè của Huan tại MERL.
*Tác giả liên hệ: slohit@merl.com
Hội nghị lần thứ 36 về Hệ thống Xử lý Thông tin Nơ-ron (NeurIPS 2022).arXiv:2012.02909v3 [cs.CV] 21 Feb 2023

--- TRANG 2 ---
1 Giới thiệu
Mạng nơ-ron sâu (DNN) là phương pháp de facto trong nhiều lĩnh vực trí tuệ nhân tạo ngày nay [25,37]. Cách huấn luyện hiệu quả một mạng sâu đã là chủ đề trung tâm trong nhiều thập kỷ. Trong vài năm qua, các nỗ lực chủ yếu tập trung vào thiết kế kiến trúc tốt hơn (ví dụ, chuẩn hóa batch [20], khối dư [14], kết nối dày đặc [19]) và hàm mất mát tốt hơn (ví dụ, làm mịn nhãn [43,30], mất mát tương phản [18], softmax biên rộng [26]) so với mất mát cross-entropy (CE) tiêu chuẩn. Chưng cất kiến thức (KD) [17] là một phương pháp huấn luyện thuộc nhóm thứ hai. Trong KD, một mạng mạnh hơn – được gọi là giáo viên – được giới thiệu để hướng dẫn việc học của mạng gốc – được gọi là học sinh – bằng cách tối thiểu hóa sự khác biệt giữa các biểu diễn của hai mạng,
LKD= (1)LCE(y;p(s)) +2DKL(p(t)=;p(s)=); (1)
trong đó DKL biểu diễn phân kỳ KL [24]; 2(0;1) là một yếu tố để cân bằng hai số hạng mất mát; LCE biểu thị mất mát cross-entropy; y là nhãn one-hot và p(t);p(s) đại diện cho xác suất đầu ra của giáo viên và học sinh trên các lớp;  là một hằng số nhiệt độ [17] để làm mịn các xác suất dự đoán. KD cho phép chúng ta huấn luyện các mạng nơ-ron nhỏ hơn, hiệu quả hơn mà không ảnh hưởng đến độ chính xác, điều này tạo điều kiện triển khai học sâu trong các môi trường hạn chế tài nguyên (ví dụ, trên thiết bị di động). KD đã tìm thấy nhiều ứng dụng trong nhiều tác vụ [6, 49, 13, 21, 50].

Hầu hết các phương pháp KD hiện có đã cố gắng cải thiện nó bằng cách đề xuất các hàm mất mát KD tốt hơn được áp dụng tại đầu ra mạng [34, 31, 45]. Ít công trình xem xét KD từ phía đầu vào. Đặc biệt, mối tương tác giữa KD và tăng cường dữ liệu (TĐL) [40] chưa được hiểu rõ cho đến nay (lưu ý, với TĐL ở đây, chúng tôi có nghĩa là khái niệm TĐL thông thường: tạo ra một đầu vào mới bằng cách biến đổi một hoặc nhiều đầu vào. Phạm vi rộng hơn của TĐL có thể liên quan đến mạng nơ-ron, ví dụ, dropout có thể được coi là một loại TĐL [3]. Chúng tôi không xem xét loại TĐL này trong bài báo này do độ dài hạn chế).

Trong công trình này, chúng tôi hỏi: Điều gì tạo nên một "tăng cường dữ liệu tốt" trong chưng cất kiến thức? Một câu trả lời rõ ràng cho câu hỏi này có nhiều lợi ích. Thứ nhất, về mặt lý thuyết, nó có thể giúp chúng ta hiểu rõ hơn về cách tăng cường dữ liệu đóng vai trò trong KD. Thứ hai, về mặt thực tiễn, nó có thể mang lại cho chúng ta cải thiện hiệu suất đáng kể – trong Hình 2, chúng tôi cho thấy tỷ lệ lỗi kiểm tra sử dụng mất mát CE tiêu chuẩn (không có giáo viên) so với sử dụng mất mát KD (có giáo viên). Như thấy, TĐL mạnh hơn có thể làm giảm tỷ lệ lỗi kiểm tra và cho phép nhiều lần lặp huấn luyện hơn mà không bị overfitting trong KD. Khá rõ ràng là "Lật+Cắt" mạnh hơn "Lật" đơn thuần trong Hình 2. Tuy nhiên, đối với các sơ đồ TĐL khác, như Mixup [54] so với AutoAugment [8], cái nào mạnh hơn? Không rõ lắm. Do đó chúng tôi mong muốn một cách có nguyên tắc (ví dụ, một chỉ số cụ thể) để làm cho khái niệm mơ hồ "mạnh hơn" trở nên chính xác. Trình bày một chỉ số có căn cứ lý thuyết như vậy và xác nhận hiệu quả của nó bằng thực nghiệm là mục tiêu của bài báo này.

[Hình 2: Tỷ lệ lỗi kiểm tra của resnet20 trên CIFAR100 khi được huấn luyện với số epoch khác nhau với (KD) và không có (CE) chưng cất kiến thức (giáo viên là resnet56 cho KD). Mỗi kết quả được thu được bằng cách lấy trung bình 3 lần chạy ngẫu nhiên (vùng bóng chỉ độ lệch chuẩn). "Lật": lật ngang ngẫu nhiên; "Cắt": cắt ngẫu nhiên. Số epoch huấn luyện tối ưu và mất mát kiểm tra của nó được tô đậm màu đỏ.]

Trực quan, một TĐL tốt nên làm phong phú dữ liệu đầu vào và để lộ thêm kiến thức của giáo viên để học sinh có thể tổng quát hóa tốt hơn. Chúng tôi hình thức hóa ý tưởng này từ góc độ học thống kê. Cụ thể, chúng tôi sẽ cho thấy một sơ đồ TĐL tốt được định nghĩa bởi phương sai (hoặc hiệp phương sai) thấp hơn của xác suất đầu ra trung bình của giáo viên trên các mẫu đầu vào khác nhau, cuối cùng dẫn đến khoảng cách tổng quát hóa thấp hơn cho học sinh. Lý thuyết được đề xuất được chứng minh tốt bởi các nghiên cứu thực nghiệm rộng rãi của chúng tôi trên các bộ dữ liệu CIFAR100 và Tiny ImageNet với các cặp khác nhau. Lý thuyết được đề xuất giải thích tốt tại sao CutMix tốt hơn các phương án khác (như Mixup [54], AutoAugment [8]) trong KD.

Ngoài các kết quả lý thuyết mới, chúng tôi cũng đề xuất một sơ đồ chọn dữ liệu dựa trên entropy để lựa chọn các mẫu có thông tin nhiều hơn cho KD, điều này có thể mang lại phương sai thấp hơn của xác suất trung bình của giáo viên cũng như lỗi tổng quát hóa thấp hơn của học sinh.

Chúng tôi có những đóng góp sau trong bài báo này:

--- TRANG 3 ---
• Chúng tôi trình bày một mệnh đề đã được chứng minh (Mệnh đề 3.1) trả lời chính xác điều gì định nghĩa TĐL tốt hơn trong KD: Với một giáo viên cố định, TĐL tốt hơn là TĐL mang lại phương sai thấp hơn của xác suất trung bình của giáo viên.

• Mệnh đề được chứng minh tốt về mặt thực nghiệm trên các bộ dữ liệu phân loại hình ảnh chuẩn với nhiều cặp giáo viên-học sinh.

• Một sơ đồ chọn dữ liệu dựa trên entropy được giới thiệu để giảm thêm phương sai của xác suất trung bình của giáo viên, có thể nâng cao thêm CutMix, phương pháp TĐL tiên tiến nhất trước đây trong số những phương pháp được đánh giá trong bài báo này.

• Về mặt thực nghiệm, chúng tôi cho thấy cách lý thuyết được trình bày có thể có lợi trong thực tế – chúng tôi có thể đơn giản tăng cường các phương pháp KD hiện có bằng cách sử dụng TĐL mạnh hơn và kéo dài các lần lặp huấn luyện.

2 Công trình liên quan
Chưng cất Kiến thức (KD). Ý tưởng chung của chưng cất kiến thức là hướng dẫn việc huấn luyện mô hình học sinh thông qua mô hình giáo viên (mạnh hơn) (hoặc một tập hợp các mô hình). Nó được tiên phong bởi Bucilua và cộng sự [4] và sau đó được cải tiến bởi Hinton và cộng sự [17], những người đã đặt ra thuật ngữ này. Kể từ khi ra mắt, KD đã được ứng dụng rộng rãi trong các tác vụ thị giác và ngôn ngữ [6,15,49,21,50]. Nhiều biến thể đã được đề xuất liên quan đến câu hỏi trung tâm trong KD, đó là cách định nghĩa kiến thức được chuyển từ giáo viên sang học sinh. Ví dụ về các định nghĩa kiến thức như vậy bao gồm khoảng cách đặc trưng [35], chú ý bản đồ đặc trưng [53], phân phối đặc trưng [32], ranh giới kích hoạt [16], mối quan hệ khoảng cách giữa các mẫu [31,34,27,46], và thông tin tương hỗ [45]. Một số công trình [30,39,5] điều tra kết nối giữa làm mịn nhãn và chưng cất kiến thức. Một dòng công trình khác (ví dụ, [44]) cố gắng hiểu KD một cách lý thuyết hơn. Trong vài năm qua, tiến bộ chủ yếu được thực hiện cho các bản đồ đặc trưng trung gian và đầu ra mạng (tức là thông qua hàm mất mát tốt hơn). Ngược lại, mục tiêu của chúng tôi là cải thiện hiệu suất KD ở đầu vào với sự trợ giúp của tăng cường dữ liệu. Chúng tôi sẽ chỉ ra rằng con đường này cũng hiệu quả và có nhiều tiềm năng cho nghiên cứu tương lai.

Tăng cường Dữ liệu (TĐL). Mạng nơ-ron sâu dễ bị overfitting, tức là xây dựng ánh xạ đầu vào-mục tiêu bằng cách sử dụng các đặc trưng không mong muốn hoặc không liên quan (như nhiễu) trong dữ liệu. Tăng cường dữ liệu là một kỹ thuật phổ biến để hạn chế overfitting [40]. Trong các tác vụ phân loại, tăng cường dữ liệu nhằm mục đích cung cấp rõ ràng dữ liệu với các biến đổi bất biến nhãn (như cắt ngẫu nhiên, lật ngang, điều chỉnh màu sắc, Cutout [12]) trong quá trình huấn luyện để mô hình có thể học các biểu diễn bền vững với những yếu tố gây nhiễu đó. Gần đây, các phương pháp tăng cường dữ liệu tiên tiến hơn đã được đề xuất, không chỉ biến đổi đầu vào mà còn biến đổi mục tiêu. Ví dụ, Mixup [54] trộn tuyến tính hai hình ảnh với các nhãn được trộn bằng cùng một phép nội suy tuyến tính. Manifold Mixup [48] tương tự như Mixup nhưng thực hiện phép trộn ở cấp độ đặc trưng thay vì cấp độ pixel; CutMix [51] dán một miếng vá cắt từ một hình ảnh lên một hình ảnh khác với nhãn được quyết định bởi tỷ lệ diện tích của hai phần. AutoAugment [8] là một phương pháp TĐL mạnh tìm ra chính sách tăng cường tối ưu từ không gian tìm kiếm lớn thông qua học tăng cường. Khi cả đầu vào và mục tiêu đều được biến đổi đồng thời, điều quan trọng là duy trì sự tương ứng ngữ nghĩa giữa đầu vào mới và mục tiêu mới. Không như các phương pháp này, tập trung vào phân loại chung bằng mất mát cross-entropy, công trình của chúng tôi điều tra mối tương tác giữa tăng cường dữ liệu và mất mát chưng cất kiến thức và đề xuất tăng cường dữ liệu mới đặc biệt cho chưng cất kiến thức.

Một số công trình KD gần đây cũng liên quan đến việc sử dụng TĐL trong KD, như [2,9]. Đặc biệt, [2] cũng sử dụng Mixup và huấn luyện kéo dài để tăng cường hiệu suất học sinh trong KD, tương tự như của chúng tôi. Tuy nhiên, điều đáng chú ý là bài báo của chúng tôi khác biệt đáng kể so với họ, ở chỗ chúng tôi đang tìm kiếm lý do lý thuyết giải thích cách định nghĩa TĐL tốt hơn trong KD để mang lại hiệu suất tốt hơn; những công trình này chủ yếu điều tra theo cách thực nghiệm, không có kết quả lý thuyết nào được trình bày. Đồng thời, công trình của chúng tôi không giới hạn ở một TĐL cụ thể (xem Phần 5). Chúng tôi hướng tới hiểu biết lý thuyết tổng quát có thể áp dụng cho phạm vi rộng các sơ đồ TĐL (may mắn thay, như các thí nghiệm của chúng tôi cho thấy, lý thuyết được đề xuất và thước đo "tính tốt" TĐL được rút ra thực sự nắm bắt được điều này). Thực tế là [2] sử dụng Mixup [54] và huấn luyện kéo dài để đạt được độ chính xác top-1 82.8% với resnet50 [14] trên ImageNet [11] có thể là bằng chứng trực tiếp rằng nguyên tắc được đề xuất trong công trình này có thể mang lại cho chúng ta những lợi ích thực tế rất hứa hẹn.

Một công trình gần đây [10] cũng tiến hành các nghiên cứu thực nghiệm về tác động của TĐL lên KD. Họ trước tiên áp dụng TĐL (ví dụ, Mixup/CutMix) cho việc huấn luyện giáo viên rồi tiến hành bước KD như thường lệ (không có TĐL bổ sung trong bước này). Điều tra của chúng tôi hoàn toàn ngược lại với thiết lập của họ: Chúng tôi huấn luyện giáo viên như thường lệ (không có Mixup/CutMix), sau đó trong bước KD chúng tôi sử dụng TĐL tiên tiến hơn (ví dụ, Mixup/CutMix).

--- TRANG 4 ---
Thú vị là, họ kết luận rằng giáo viên được huấn luyện với Mixup/CutMix làm hại khả năng tổng quát hóa của học sinh, trong khi chúng tôi luôn thấy hiệu suất học sinh được cải thiện thông qua TĐL mạnh hơn. Một công trình gần đây khác [42] sử dụng KD để gán nhãn lại các mẫu trộn trong Mixup để khắc phục vấn đề gán nhãn không chính xác của Mixup. Công trình của họ cho thấy KD có thể được sử dụng để làm cho Mixup hữu ích hơn một cách tổng quát, điều này trực giao với chủ đề của công trình này.

Công trình của [29] trình bày góc nhìn thống kê để hiểu cách các xác suất được làm mềm trong KD tốt hơn các nhãn cứng one-hot. Công trình của chúng tôi được lấy cảm hứng từ khái niệm giáo viên Bayes của họ. Tuy nhiên, công trình của chúng tôi khác với họ ở chỗ chúng tôi tập trung vào giải thích cách tăng cường dữ liệu đóng vai trò trong KD và trả lời điều gì đặc trưng cho TĐL tốt, trong khi họ cố gắng trả lời tại sao hàm mất mát chưng cất kiến thức tốt hơn hàm mất mát cross-entropy tiêu chuẩn.

3 Điều tra Lý thuyết
3.1 Điều kiện tiên quyết: Phân loại Đa lớp với KD
Cho tập huấn luyện S=f(xn;yn)gN
n=1DN, trong đó D là phân phối kết hợp cho cặp biến ngẫu nhiên đầu vào-đầu ra (x;y), mục tiêu trong phân loại đa lớp là tìm ra bộ dự đoán f:X!
RC từ lớp giả thuyết H, trong đó X là không gian đầu vào và C đề cập đến số lượng lớp.
Bộ dự đoán f được cho là tối thiểu hóa rủi ro thực
RD(f)def= E
(x;y)D[L(y;f(x))]; (2)
trong đó L đại diện cho hàm mục tiêu mất mát (ví dụ, cross-entropy); chỉ số dưới D của RD là để nhấn mạnh rằng rủi ro thực được định nghĩa trên phân phối dữ liệu. Rủi ro thực được xấp xỉ trong thực tế trên một tập kiểm tra riêng biệt.

Để huấn luyện, bộ dự đoán nhằm mục đích tối thiểu hóa rủi ro thực nghiệm được định nghĩa trên chuỗi huấn luyện S:
RS(f)def=1
NNX
n=1e>
ynlog(f(xn)); (3)
trong đó ey2f0;1gC là vector one-hot chỉ ra nhãn y2[C] =f1;2;;Cg. Chỉ số dưới S của RS là để nhấn mạnh rủi ro thực nghiệm được định nghĩa trên các điểm dữ liệu được lấy mẫu hữu hạn.

Trong bối cảnh KD, vector mục tiêu cứng one-hot ey được thay thế bằng vector xác suất p(t)(x)2
RC
+, mang lại cho chúng ta rủi ro chưng cất thực nghiệm của f:
^RS(f)def=1
NNX
n=1p(t)(xn)>log(f(xn)); (4)
trong đó chỉ số trên t chỉ ra mô hình giáo viên cố định. Lý thuyết về tại sao Phương trình (4) tốt hơn Phương trình (3) đã được thiết lập trong [29]. Độc giả quan tâm có thể tham khảo bài báo của họ để biết thêm chi tiết. Tiếp theo, chúng tôi xem xét cách tăng cường dữ liệu đóng vai trò trong KD.

3.2 Điều gì tạo nên TĐL "tốt" trong KD?
Trực quan, TĐL tốt hơn nên cung cấp thêm thông tin, tức là để lộ thêm kiến thức của giáo viên để học sinh có thể hấp thụ nhiều hơn và do đó tổng quát hóa tốt hơn. Chúng tôi làm cho ý tưởng này nghiêm ngặt như sau.

Mệnh đề 3.1. Cho một hàm mất mát bị chặn và một mô hình giáo viên cố định với rủi ro chưng cất thực nghiệm được định nghĩa trong Phương trình (4), đối với bất kỳ bộ dự đoán f nào, xem xét hai chuỗi được lấy mẫu S12DN và S22DN, chúng được tạo thành từ N phần tử được lấy mẫu từ cùng một phân phối D, trong khi không i.i.d. (đặc biệt khi tăng cường dữ liệu được sử dụng). Nếu các phần tử trong S1 thể hiện tương quan lớn hơn so với những phần tử trong S2, thì khoảng cách tổng quát hóa của học sinh được huấn luyện trên S1 sẽ lớn hơn so với được huấn luyện trên S2:
E
S1DN[
(^RS1(f)RD(f))2]
> E
S2DN[
(^RS2(f)RD(f))2]
: (5)

Chứng minh. Đặt  = ^RS(f)RD(f). Theo định nghĩa phương sai, ES[2] = VarS[] + (ES[])2. Để làm cho ký hiệu rõ ràng hơn, chúng tôi định nghĩa q(xi) =p(t)(xi)>log(f(xi)).

--- TRANG 5 ---
(1) Vì RD(f) là một hằng số (mặc dù chưa biết),
ESDN[] = ES[^RS(f)] + Const = ES[1
NNX
i=1q(xi)] + Const
=1
NNX
i=1ES[q(xi)] + Const =1
NNX
i=1Exi[q(xi)] + Const
=1
NNEx[q(x)] + Const = Ex[q(x)] + Const;(6)
trong đó phương trình thứ hai cuối là do mỗi phần tử xi trong S được rút ra từ cùng một phân phối D. Từ vế phải của phương trình cuối, chúng ta có thể thấy rõ ràng rằng đối với S1, S2, ES[] là như nhau.

(2) Sau đó chúng tôi xem xét VarS[]. Một lần nữa, vì RD(f) là một hằng số, chúng tôi chỉ cần xem xét
VarS[^RS(f)] = VarS[1
NNX
i=1q(xi)] =1
N2CovS[NX
j=1q(xj);NX
k=1q(xk)]
=1
N2NX
i=1Varxi[q(xi)] + 2X
1j<kNCovS[q(xj);q(xk)]
=1
N2
NVarx[q(x)] + 2X
1j<kNCovS[q(xj);q(xk)]
=1
NVarx[q(x)] +2
N2X
1j<kNCovS[q(xj);q(xk)];(7)
trong đó Cov[;] đại diện cho hiệp phương sai. Từ mục cuối trong Phương trình (7), chúng ta có thể thấy rằng phần hiệp phương sai là khác nhau đối với các S được lấy mẫu khác nhau. Nếu các mẫu trong S1 thể hiện tương quan lớn hơn so với những mẫu trong S2, chúng ta sẽ có VarS1[]>VarS2[], điều này tiếp tục dẫn đến tăng khoảng cách tổng quát hóa cho học sinh, tức là ES1[(RS1(f)RD(f))2]>ES2[(RS2(f)RD(f))2]. Chứng minh hoàn thành.

Sử dụng Thực tế: Độ lệch chuẩn của Xác suất Trung bình của Giáo viên (T. stddev). Lưu ý trong Mệnh đề 3.1, bộ dự đoán f (tức là mô hình học sinh) có thể là bất kỳ cái nào (không nhất thiết phải là mô hình hội tụ). Mỗi học sinh sẽ có một thứ tự của các sơ đồ TĐL khác nhau liên quan đến cái nào tốt hơn "theo ý kiến của nó". Có thể, các học sinh khác nhau sẽ dẫn đến các thứ tự khác nhau như vậy. Để sử dụng thực tế, chúng ta phải chọn một học sinh nhất định làm oracle để tiến hành đánh giá. Ở đây, chúng ta có thể chơi một mánh khóe có thể làm cho việc sử dụng lý thuyết của chúng ta khá đơn giản – giả sử có một học sinh hoạt động chính xác giống như giáo viên (giả định này không phải là không thực tế, vì một ví dụ thẳng thắn là sử dụng giáo viên làm học sinh). Khi đó chúng ta có
Cov[q(xj);q(xk)] = Cov[p(t)(xj)>log(f(xj));p(t)(xk)>log(f(xk))]
= Cov[p(t)(xj)>log(p(t)(xj));p(t)(xk)>log(p(t)(xk)):(8)

Trong trường hợp này, chúng ta chỉ cần hiệp phương sai của xác suất của giáo viên để đo lường "tính tốt" của một kỹ thuật TĐL nhất định, không cần học sinh. Mặc dù không sử dụng bất kỳ thông tin nào của học sinh, chỉ số được đề xuất hóa ra tương quan một cách đáng ngạc nhiên với hiệu suất của học sinh (xem Hình 4).

Dựa trên Phương trình (8), khi sử dụng S1 so với S2 làm chuỗi huấn luyện, yếu tố cơ bản trả lời cho khoảng cách phương sai của VarS[] quy về hiệp phương sai trong fp(t)(xi)gN
i=1. Tức là, hiệp phương sai lớn hơn trong fp(t)(xi)gN
i=1 dẫn đến hiệp phương sai lớn hơn trong fp(t)(xi)>log(p(t)(xi))gN
i=1 trong Phương trình (8), cuối cùng dẫn đến VarS[] cao hơn trong Phương trình (7).

Bước tiếp theo là tìm cách khả thi để ước tính hiệp phương sai trong fp(t)(xi)gN
i=1. Xem xét biến trung bình (được ký hiệu là u ở đây) của một số biến ngẫu nhiên fp(t)(xk)gK
k=1,
u=1
KX
xk2Sp(t)(xk);u2RC
+: (9)
Phương sai của nó (hoặc tương đương, độ lệch chuẩn) vốn dĩ tính đến hiệp phương sai giữa các số hạng cộng của nó. Do đó, chúng ta có thể sử dụng phương sai của u làm proxy cho hiệp phương sai trong fp(t)(xk)gK
k=1:
m= VarS(u);m2RC
+;m=1
CX
i2[C](mi)1
2;m2R+;(10)

--- TRANG 6 ---
[0.10,0.05,0.60,0.25][0.05,0.22,0.58,0.15][0.13,0.02,0.70,0.15][0,0,1,0][0,0,1,0][0,0,1,0]
mục tiêu(KD)mục tiêu(CE)
Các góc nhìn khác nhau của đầu vàoĐầu vào mặt trời lặn chó cỏ TĐL
được ánh xạ tới các mục tiêu khác nhauđược ánh xạ tới một mục tiêu Giáo viên(cố định)Học sinh
Đầu vào thô𝑥!
Đầu vào𝑥
TĐL chuẩnTĐL mạnh hơnĐầu vào𝑥'
Mất mát KD(a)(b)Hình 3: (a) Minh họa sự khác biệt của mục tiêu giám sát giữa mất mát KD và mất mát cross-entropy (CE). Một đầu vào được biến đổi thành các phiên bản khác nhau do tăng cường dữ liệu. Mất mát KD có thể cung cấp thông tin bổ sung cho học sinh bằng cách ánh xạ các góc nhìn này tới các mục tiêu khác nhau, trong khi mất mát CE không thể. Công trình này cố gắng trả lời điều gì đặc trưng cho một sơ đồ tăng cường dữ liệu "tốt" trong chưng cất. (b) Minh họa việc điều chỉnh một phương pháp TĐL hiện có cho KD. TĐL chuẩn bao gồm cắt ngẫu nhiên và lật ngang. Khung huấn luyện này được sử dụng để xác minh thực nghiệm chỉ số được đề xuất của chúng tôi để định nghĩa tăng cường dữ liệu "mạnh hơn".

trong đó K là số lượng mẫu được định nghĩa trước của tập S để thực hiện hiệu ứng lấy trung bình (ví dụ, K= 640 trong các thí nghiệm của chúng tôi cho CIFAR100 và Tiny ImageNet – xem Phụ lục Phần A.3 để biết ví dụ tính toán cụ thể). Lưu ý, u có thể được hiểu là xác suất trung bình của giáo viên trên K mẫu đầu vào.

Nếu có hiệp phương sai lớn giữa fp(t)(xk)gK
k=1, m sẽ lớn (theo nghĩa từng phần tử). Khi đó trung bình của m trên các lớp, tức là m (chúng tôi thực hiện phép lấy trung bình này chỉ đơn giản vì chúng tôi muốn một chỉ số vô hướng), là một chỉ báo tốt để nắm bắt hiệp phương sai như vậy. Do đó chúng tôi chính thức giới thiệu m, T. stddev (được lấy trung bình), làm chỉ số được đề xuất để đo lường chất lượng của một sơ đồ tăng cường dữ liệu. m thấp hơn ngụ ý TĐL tốt hơn theo định nghĩa của chúng tôi. Trong các thí nghiệm, chúng tôi sẽ chỉ ra rằng chỉ số này được định nghĩa hoàn toàn bằng cách sử dụng giáo viên có thể đặc trưng chính xác lỗi tổng quát hóa của học sinh sau chưng cất.

4 Các Thuật toán Được Đánh giá
4.1 Mở rộng Các Phương pháp TĐL Hiện có cho KD
Cho một phương pháp TĐL hiện có, phần này giải thích cách chúng tôi điều chỉnh nó một cách phù hợp với trường hợp KD. Cụ thể, đặt x0 biểu thị dữ liệu thô, x biểu thị dữ liệu được biến đổi bởi việc tăng cường chuẩn (cắt ngẫu nhiên và lật). Được minh họa trong Hình 3(b), chúng tôi sẽ thêm TĐL theo sau x để có được x0. Không giống như tăng cường dữ liệu thông thường nơi chỉ đầu vào đã biến đổi được đưa vào mạng, chúng tôi giữ cả đầu vào x và x0 cho việc huấn luyện (như vậy, số lượng ví dụ đầu vào được nhân đôi). Sự xem xét việc giữ cả hai đầu vào là để duy trì đường dẫn thông tin cho đầu vào gốc x để chúng tôi có thể dễ dàng thấy cách đường dẫn thông tin được thêm vào của x0 dẫn đến sự khác biệt.

Đối với x, mất mát của nó vẫn là mất mát KD ban đầu, bao gồm mất mát cross-entropy và phân kỳ KL (Phương trình (1)). Đặc biệt chú ý là, đối với x0, mất mát của nó chỉ là phân kỳ KL, tức là chúng tôi không sử dụng các nhãn được gán bởi thuật toán TĐL (ví dụ, trong Mixup và CutMix gốc, chúng gán một nhãn được nội suy tuyến tính cho mẫu được tăng cường) vì các nhãn này thực sự có thể sai (xem Phụ lục Phần A.4 để biết các ví dụ cụ thể trên ImageNet). Thực tế, không sử dụng nhãn cứng có một lợi ích khác. Một sơ đồ tăng cường bộ dữ liệu sử dụng mất mát CE phải cung cấp các nhãn tương ứng làm thông tin giám sát. Để duy trì sự tương ứng ngữ nghĩa, nó không thể chấp nhận các biến đổi rất cực đoan cho tăng cường dữ liệu. Ngược lại, trong thiết lập Mixup/CutMix+KD được mô tả ở trên, sơ đồ tăng cường dữ liệu không cần phải lo lắng về các nhãn vì chúng được gán bởi giáo viên – công trình gần đây [2] gọi loại sử dụng TĐL này là khớp hàm của giáo viên. Kết quả là, nó có thể chấp nhận một tập hợp rộng hơn các biến đổi để để lộ kiến thức của giáo viên một cách hoàn chỉnh hơn. Điều này phản ánh rằng tăng cường dữ liệu trong KD có nhiều tự do hơn trong CE.

Trong số tất cả các kỹ thuật tăng cường dữ liệu được đánh giá trong bài báo này, chúng tôi sẽ chỉ ra rằng CutMix hoạt động tốt nhất. Lý do cơ bản cho thành công của nó, như chúng tôi sẽ chỉ ra, là nó đạt được phương sai thấp hơn nhiều của xác suất trung bình của giáo viên, ngụ ý rằng nó tạo ra dữ liệu đa dạng hơn so với các đối tác của nó.

--- TRANG 7 ---
4.2 CutMixPick: Tăng cường CutMix với Chọn Dữ liệu Dựa trên Entropy
Trong phần này, chúng tôi đề xuất một sơ đồ chọn dữ liệu để giảm thêm phương sai của xác suất trung bình của giáo viên. Ý tưởng này một phần được lấy cảm hứng từ học tích cực [38]. Trong học tích cực, người học có tự do truy vấn các thể hiện dữ liệu để được gán nhãn cho huấn luyện bởi một oracle (tức là giáo viên trong trường hợp của chúng tôi) [38]. Vì dữ liệu được tăng cường có thể khác nhau về chất lượng, chúng tôi có thể giới thiệu một tiêu chí nhất định để chọn dữ liệu có giá trị hơn cho học sinh.

Trực quan, chúng tôi coi một mẫu có nhiều thông tin hơn là có chất lượng cao hơn. Do đó, chúng tôi lấy entropy Shannon của xác suất đầu ra của giáo viên làm thước đo tự nhiên để lựa chọn mẫu,
H(p(t)(x)) =p(t)(x)>log(p(t)(x)): (11)
Lưu ý công thức này có đúng cùng dạng với Phương trình (8). Về mặt thực nghiệm, chúng tôi cũng sẽ chỉ ra rằng dữ liệu được chọn bởi công thức này thực sự dẫn đến m thấp hơn và mất mát kiểm tra tốt hơn cho học sinh.

Cụ thể, cho một batch dữ liệu, trước tiên chúng tôi áp dụng CutMix để có được một loạt mẫu được tăng cường. Sau đó sắp xếp tất cả các mẫu được tăng cường theo Phương trình (11) theo thứ tự tăng dần và giữ lại r% mẫu hàng đầu (r là hằng số phần trăm được định nghĩa trước, r= 0:5 trong các thí nghiệm của chúng tôi).

Kỹ thuật đơn giản này có thể khá hiệu quả theo nghiên cứu thực nghiệm của chúng tôi. Một lựa chọn thay thế khác có vẻ tiềm năng là sử dụng entropy của học sinh làm chỉ số chọn. Trực quan đằng sau điều này là một mẫu có entropy cao trong quan điểm của học sinh có thể được coi là một ví dụ khó. Học với những ví dụ khó này có thể mở rộng kiến thức của học sinh bằng cách ép những điểm mù của nó. Mặc dù giải thích trực quan này có vẻ hợp lý, trong thực tế, chúng tôi sẽ chỉ ra rằng sơ đồ này thực sự hoạt động kém hơn sơ đồ không phụ thuộc vào học sinh trước đó trong Phương trình (11), điều này hơi đáng ngạc nhiên.

5 Kết quả Thí nghiệm
Bộ dữ liệu và Mạng. Chúng tôi đánh giá phương pháp của mình chủ yếu trên các bộ dữ liệu CIFAR100 [23] và Tiny ImageNet*. CIFAR100 có 100 lớp đối tượng (hình ảnh RGB 32 32). Mỗi lớp có 500 hình ảnh để huấn luyện và 100 hình ảnh để kiểm tra. Tiny ImageNet là một phiên bản nhỏ của ImageNet [11] với 200 lớp (hình ảnh RGB 64 64). Mỗi lớp có 500 hình ảnh để huấn luyện, 50 để xác thực và 50 để kiểm tra. Để đánh giá kỹ lưỡng các phương pháp của chúng tôi, chúng tôi so sánh chúng trên các kiến trúc mạng chuẩn khác nhau: vgg [41], resnet [14], wrn [52], MobileNetV2 [36], ShuffleV2 [28]. Chúng tôi cũng sẽ bao gồm kết quả trên ImageNet100 (một tập con 100 lớp được rút ra ngẫu nhiên từ ImageNet) và ImageNet.

Phương pháp So sánh. Ngoài huấn luyện cross-entropy tiêu chuẩn và phương pháp KD ban đầu [17], chúng tôi cũng so sánh với phương pháp chưng cất tiên tiến, Chưng cất Biểu diễn Tương phản (CRD) [45]. Điều quan trọng cần lưu ý là phương pháp của chúng tôi tập trung vào cải thiện KD bằng cách sử dụng đầu vào tốt hơn, trong khi CRD cải thiện KD ở đầu ra (tức là hàm mất mát tốt hơn). Do đó, chúng trực giao và chúng tôi sẽ chỉ ra rằng chúng có thể được kết hợp với nhau để mang lại kết quả thậm chí tốt hơn.

Cài đặt Siêu tham số. Nhiệt độ của chưng cất kiến thức được đặt thành 4 theo CRD [45]. Trọng số mất mát = 0:9 (Phương trình (1)). Đối với CIFAR100 và Tiny ImageNet, kích thước batch huấn luyện là 64; số epoch huấn luyện tổng cộng ban đầu là 240, với tốc độ học (LR) giảm tại epoch 150, 180 và 210 với hệ số nhân 0.1. LR ban đầu là 0.05. Tất cả các cài đặt này giống như CRD [45] để so sánh công bằng. Lưu ý, trong các thí nghiệm của chúng tôi, chúng tôi sẽ trình bày kết quả với nhiều lần lặp huấn luyện hơn. Nếu tổng số epoch được tăng theo hệ số k, các epoch mà tốc độ học bị giảm cũng được tăng theo hệ số k. Ví dụ, nếu chúng tôi huấn luyện một mạng cho CIFAR100 trong tổng cộng 480 epoch (k= 2), tốc độ học sẽ bị giảm tại epoch 300, 360 và 420. Chúng tôi sử dụng PyTorch [33] để tiến hành tất cả các thí nghiệm của chúng tôi. Đối với CIFAR100, chúng tôi sử dụng các mô hình giáo viên đã được huấn luyện trước từ CRD† để so sánh công bằng. Đối với Tiny ImageNet và ImageNet100, chúng tôi huấn luyện các mô hình giáo viên của riêng mình. Đối với ImageNet, chúng tôi sử dụng các mô hình torchvision theo CRD [45].

Sơ đồ Tăng cường Dữ liệu. Chúng tôi điều tra các sơ đồ TĐL phổ biến sau:
• Đồng nhất: Sơ đồ tăng cường này chỉ đơn giản tạo một bản sao của mỗi dữ liệu batch trong quá trình huấn luyện, điều này nên là giới hạn dưới của tất cả các sơ đồ TĐL được thảo luận ở đây vì nó không thêm thông tin mới.
• Lật: Lật ngang ngẫu nhiên.

*https://tiny-imagenet.herokuapp.com/
†https://github.com/HobbitLong/RepDistiller

--- TRANG 8 ---
• Lật+Cắt: Lật ngang ngẫu nhiên và cắt ngẫu nhiên. Đây là TĐL chuẩn được sử dụng rộng rãi trong tác vụ nhận dạng hình ảnh 2D (như trên các bộ dữ liệu CIFAR và ImageNet).
• Cutout [12]: Cutout che khuất một miếng vá ngẫu nhiên nhỏ của một hình ảnh.
• AutoAugment [8]: AutoAugment là một tập hợp của các sơ đồ TĐL được thu thập. Chính sách TĐL được chọn tự động bởi học tăng cường thay vì thủ công.
• Mixup [54]: Mixup áp dụng nội suy tuyến tính giữa hai đầu vào và áp dụng cùng nội suy tuyến tính cho các nhãn của chúng để tạo nhãn mới cho mẫu được tăng cường.
• CutMix [51]: CutMix cắt một miếng vá nhỏ từ một hình ảnh nguồn và dán nó lên một hình ảnh nguồn khác. Hình ảnh kết quả được coi là đầu vào mới. Mục tiêu cho đầu vào mới là nội suy tuyến tính từ hai nhãn nguồn.

5.1 Xác minh Thực nghiệm Mệnh đề của Chúng tôi
Trước khi trình bày kết quả, một điểm đáng chú ý là, trong phần này chúng tôi sử dụng mất mát kiểm tra thay vì độ chính xác làm thước đo hiệu suất của học sinh trong KD, bởi vì (1) tất cả các công thức trong Phần 3 được rút ra bằng cách sử dụng mất mát số thay vì độ chính xác; (2) quan trọng hơn, được quan sát thấy rằng độ chính xác có thể không khớp với mất mát – một mô hình có thể đạt được độ chính xác tốt hơn, đồng thời mất mát cao hơn [29], điều mà chúng tôi cũng quan sát thấy nhiều lần trong các thí nghiệm của chúng tôi. Việc sử dụng độ chính xác làm thước đo sẽ ngăn chúng tôi thấy tương quan giữa T. stddev và hiệu suất của học sinh (xem Phụ lục Hình 6 để biết ví dụ). Mở rộng tiềm năng của lý thuyết chúng tôi từ mất mát sang độ chính xác được để lại cho công việc tương lai.

Trong Hình 4, chúng tôi vẽ biểu đồ phân tán của Mất mát kiểm tra S. và T. stddev. Giá trị trục x/y của mỗi điểm dữ liệu được lấy trung bình bởi ít nhất ba lần chạy ngẫu nhiên (xem Bảng 3/4 và Bảng 5/6 để biết số liệu chi tiết).

(1) Về mặt T. stddev, có một xu hướng thô (ví dụ, trên cặp vgg13/vgg8 trên CIFAR100): Đồng nhất < Lật < Lật+Cắt < Cutout < AutoAugment < Mixup < CutMix. Những bất đẳng thức này phù hợp với trực quan của chúng tôi. Ví dụ, AutoAugment [8] bao gồm Cutout [12] trong nhóm biến đổi của nó, do đó nên mạnh hơn Cutout. Điều này được phản ánh trung thực bởi T. stddev trên nhiều cặp.

(2) Rõ ràng, Mất mát kiểm tra S. thể hiện tương quan dương rõ ràng với T. stddev. Theo lý thuyết của chúng tôi, T. stddev thấp hơn nên dẫn đến rủi ro tổng quát hóa tốt hơn cho học sinh. Điều này nói chung được xác minh tốt trong những biểu đồ này. Chúng tôi thấy một số phản ví dụ nhỏ. Những lý do có thể là: 1) Mất mát kiểm tra được thu được trên tập kiểm tra với các mẫu hữu hạn, chỉ là một xấp xỉ của rủi ro thực được định nghĩa trên phân phối; 2) Xác suất trung bình của giáo viên cũng được đánh giá trên dữ liệu hữu hạn. Mặc dù vậy, bức tranh tổng quát từ Hình 4 vẫn xác nhận tương quan dương giữa Mất mát kiểm tra S. và T. stddev. Tương quan thực sự rất có ý nghĩa như các p-value chỉ ra.

(3) Quan trọng, lưu ý chúng tôi chỉ cần giáo viên để định nghĩa chất lượng của một TĐL nhất định trong KD, không cần học sinh. Điều này rõ ràng hơn nếu chúng tôi kiểm tra kết quả trong Bảng 3/4 và Bảng 5/6. Lấy vgg13/vgg8 và vgg13/MobileNetV2 làm ví dụ, các học sinh hoàn toàn khác nhau nhưng cả hiệu suất của học sinh đều tương quan tốt với T. stddev. Quan sát này ngụ ý rằng "tính tốt" của TĐL trong KD có thể là bất biến với học sinh. Điều này, đáng chú ý, là một lợi thế lớn trong thực tế vì chúng ta có thể quyết định TĐL nào nên được sử dụng để có hiệu suất tốt nhất chỉ đơn giản bằng cách sử dụng một công thức (Phương trình (10)) với một vài lần chuyển tiếp mạng, mà không cần phải huấn luyện học sinh một cách vật lý.

5.2 Tăng cường KD với TĐL Mạnh hơn
Trong phần này, chúng tôi trình bày thêm kết quả để chỉ ra cách lý thuyết được đề xuất có thể có lợi trong thực tế – chúng tôi có thể thu hoạch cải thiện hiệu suất đáng kể chỉ đơn giản bằng cách sử dụng TĐL mạnh hơn trong KD.

Huấn luyện Kéo dài. Đáng chú ý, TĐL mạnh hơn tạo ra dữ liệu đa dạng hơn, ngụ ý thêm thông tin. Trực quan, nó nên khiến mô hình học sinh cần nhiều lần lặp huấn luyện hơn (nếu kích thước batch không thay đổi) để hấp thụ hoàn toàn thông tin dư thừa. Tức là, TĐL mạnh hơn có thể cần nhiều lần lặp huấn luyện hơn để thể hiện đầy đủ tiềm năng của nó. Trực quan này được xác nhận trong Hình 2 (và cũng hai cặp wrn_40_2/wrn_16_2 và vgg13/vgg8 khác trong Phụ lục). Do đó, trong các thí nghiệm của chúng tôi, chúng tôi cũng sẽ báo cáo kết quả với các lần lặp huấn luyện kéo dài để có hiệu suất tối đa.

Kết quả trên CIFAR100. Kết quả trên bộ dữ liệu CIFAR100 được thể hiện trong Bảng 1.
(1) So sánh hàng "KD+CutMix" với "KD", chúng tôi thấy CutMix cải thiện độ chính xác học sinh trên tất cả các cặp. Trên cặp resnet32x4/ShuffleV2, sự cải thiện rất đáng kể (hơn 1 điểm phần trăm). (2) So sánh hàng "KD+CutMixPick" với "KD+CutMix", chúng tôi thấy 6/7 cặp

--- TRANG 9 ---
được cải thiện thêm, cho thấy sơ đồ chọn dữ liệu được đề xuất hoạt động trong hầu hết các trường hợp. (3) Cuối cùng, sơ đồ "KD+CutMixPick" có thể được kết hợp với nhiều lần lặp huấn luyện hơn (960 epoch), mang lại độ chính xác thậm chí cao hơn. (4) Nếu so sánh kết quả tốt nhất của chúng tôi (KD+CutMixPick 960) với những kết quả của CRD (mặc dù đây không phải là so sánh táo với táo vì hai phương pháp tập trung vào các khía cạnh khác nhau để cải thiện KD), chúng tôi có thể thấy phương pháp của chúng tôi vượt trội hơn CRD trên 6/7 cặp.

Trong hai hàng cuối của Bảng 1, khi CRD [45] được trang bị "CutMixPick" được đề xuất của chúng tôi và nhiều lần lặp huấn luyện hơn, kết quả của nó có thể được cải thiện thêm một cách nhất quán. Điều này chứng tỏ rằng phương pháp của chúng tôi có tính tổng quát và có thể dễ dàng hoạt động với những phương pháp tập trung vào hàm mất mát KD tốt hơn.

Kết quả trên Tiny ImageNet. Chúng tôi cũng đánh giá CutMix và CutMixPick trên một bộ dữ liệu thử thách hơn, Tiny ImageNet. Tương tự như trường hợp trên CIFAR100, chúng tôi có kết quả trên các cặp giáo viên-học sinh khác nhau, được thể hiện trong Bảng 2. Đối với huấn luyện kéo dài, chúng tôi huấn luyện trong 480 epoch thay vì 960 để tiết kiệm thời gian. Hầu hết các tuyên bố trên bộ dữ liệu CIFAR100 cũng được xác nhận ở đây: (1) "KD+CutMix" tốt hơn KD, được xác minh trên tất cả các cặp. (2) "KD+CutMixPick" tốt hơn "KD+CutMix", được xác minh trên 6/7 cặp. Cặp ngoại lệ là resnet56/resnet20, nơi việc thêm chọn dữ liệu làm giảm độ chính xác nhẹ 0.11%. (3) Khi "KD+CutMixPick" được huấn luyện trong các lần lặp kéo dài, các học sinh hoạt động tốt nhất.

Chúng tôi tiếp tục đánh giá các phương pháp TĐL của chúng tôi được trang bị với CRD [45], được thể hiện trong hai hàng cuối của Bảng 2. Phương pháp "CutMixPick" của chúng tôi nâng cao thêm SOTA trước đây trên 5 cặp. Khi CRD+CutMixPick được huấn luyện trong 480 epoch (thay vì 240), sự cải thiện thêm có thể được quan sát thấy trên 6 trong 7 cặp.

Áp dụng TĐL cho Nhiều Phương pháp KD hơn. Đáng chú ý, chúng tôi đạt được sự cải thiện hiệu suất ở trên chỉ đơn giản bằng cách sử dụng mất mát KD ban đầu [17], không có những thứ phức tạp. Điều này chứng minh một trong những động lực của chúng tôi trong bài báo này, tức là các phương pháp KD hiện có [34,31,45] chủ yếu cải thiện KD ở phía đầu ra mạng thông qua hàm mất mát tốt hơn, trong khi chúng tôi đề xuất cải thiện KD ở phía đầu vào và chỉ ra rằng con đường này cũng hứa hẹn. Thực tế, hiệu ứng cải thiện hiệu suất này là chung – chúng tôi cũng đã áp dụng CutMix cho 5 phương pháp KD hoạt động hàng đầu khác trên CIFAR100: AT [53], CC [34], SP [46], PKT [32], và VID [1]. Tất cả các cặp đều thấy cải thiện độ chính xác; một nửa trong số chúng thậm chí được cải thiện hơn 1% điểm.

Kết quả trên ImageNet100 và ImageNet. Những kết quả này được để lại cho Phụ lục A.1. Nói chung, chúng tôi quan sát thấy rằng tương quan giữa T. stddev và Mất mát kiểm tra S. trở nên yếu hơn trên ImageNet100 và ImageNet. Điều này là do hai bộ dữ liệu này vốn dĩ khó hơn CIFAR100 và Tiny ImageNet. Tuy nhiên, p-value của tương quan vẫn dưới 5% trên ImageNet100, tức là vẫn có ý nghĩa thống kê, cho thấy lý thuyết của chúng tôi có thể tổng quát hóa sang các bộ dữ liệu có độ phân giải lớn (224224).

6 Kết luận
Trong bài báo này, chúng tôi cố gắng trả lời chính xác điều gì tạo nên một tăng cường dữ liệu tốt trong chưng cất kiến thức. Bằng cách phân tích khoảng cách tổng quát hóa của học sinh dưới các sơ đồ lấy mẫu khác nhau, chúng tôi đi đến kết luận rằng một sơ đồ tăng cường dữ liệu tốt nên giảm phương sai của cross-entropy (tức là rủi ro chưng cất) giữa giáo viên và học sinh. Dựa trên điều này, chúng tôi đề xuất một chỉ số mới, độ lệch chuẩn của xác suất trung bình của giáo viên (T. stddev), làm thước đo khả thi về chất lượng của các kỹ thuật tăng cường dữ liệu. Các nghiên cứu thực nghiệm với các cặp giáo viên-học sinh khác nhau xác nhận hiệu quả của chỉ số được đề xuất cho chất lượng tăng cường dữ liệu trong KD. Ngoài hiểu biết lý thuyết, chúng tôi cũng phát triển một sơ đồ chọn dữ liệu dựa trên entropy để nâng cao thêm sơ đồ tăng cường tốt nhất trước đây (CutMix) trong KD. Cuối cùng, chúng tôi chỉ ra cách chúng tôi có thể đạt được cải thiện hiệu suất KD đáng kể chỉ đơn giản bằng cách sử dụng sơ đồ TĐL mạnh hơn được hướng dẫn bởi lý thuyết được đề xuất.

--- TRANG 10 ---
Lời cảm ơn và Tiết lộ Nguồn tài trợ
Chúng tôi cảm ơn các phản biện ẩn danh của NeurIPS đã đưa ra những gợi ý rất hữu ích để cải thiện bài báo này!

Công trình này bắt nguồn từ thời gian thực tập của Huan tại MERL, và được hoàn thành cuối cùng sau khi anh ấy trở về Northeastern University với tư cách là trợ lý nghiên cứu. Công trình này do đó được hỗ trợ hoàn toàn bởi MERL và Northeastern University. Không có tài trợ hoặc hỗ trợ từ bên thứ ba dưới bất kỳ hình thức nào. Không có lợi ích cạnh tranh nào cần tiết lộ.

Tài liệu tham khảo
[1] Sungsoo Ahn, Shell Xu Hu, Andreas Damianou, Neil D Lawrence, và Zhenwen Dai. Variational information distillation for knowledge transfer. Trong CVPR, 2019. 10

[2] Lucas Beyer, Xiaohua Zhai, Amélie Royer, Larisa Markeeva, Rohan Anil, và Alexander Kolesnikov. Knowledge distillation: A good teacher is patient and consistent. Trong CVPR, 2022. 3, 6

[3] Xavier Bouthillier, Kishore Konda, Pascal Vincent, và Roland Memisevic. Dropout as data augmentation. arXiv preprint arXiv:1506.08700, 2015. 2

[4] Cristian Bucilua, Rich Caruana, và Alexandru Niculescu-Mizil. Model compression. Trong SIGKDD, 2006. 3

[5] Keshigeyan Chandrasegaran, Ngoc-Trung Tran, Yunqing Zhao, và Ngai-Man Cheung. Revisiting label smoothing and knowledge distillation compatibility: What was missing? Trong ICML, 2022. 3

[6] Guobin Chen, Wongun Choi, Xiang Yu, Tony Han, và Manmohan Chandraker. Learning efficient object detection models with knowledge distillation. Trong NeurIPS, 2017. 2, 3

[7] Jang Hyun Cho và Bharath Hariharan. On the efficacy of knowledge distillation. Trong ICCV, 2019. 15

[8] Ekin D Cubuk, Barret Zoph, Dandelion Mane, Vijay Vasudevan, và Quoc V Le. Autoaugment: Learning augmentation policies from data. Trong CVPR, 2019. 2, 3, 8

[9] Wanyun Cui và Sen Yan. Isotonic data augmentation for knowledge distillation. arXiv preprint arXiv:2107.01412, 2021. 3

[10] Deepan Das, Haley Massa, Abhimanyu Kulkarni, và Theodoros Rekatsinas. An empirical analysis of the impact of data augmentation on knowledge distillation. arXiv preprint arXiv:2006.03810, 2020. 3

[11] Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, và Li Fei-Fei. Imagenet: A large-scale hierarchical image database. Trong CVPR, 2009. 3, 7

[12] Terrance DeVries và Graham W Taylor. Improved regularization of convolutional neural networks with cutout. arXiv preprint arXiv:1708.04552, 2017. 3, 8

[13] Yushu Feng, Huan Wang, Haoji Hu, và Daniel Yi. Triplet distillation for deep face recognition. Trong ICML Workshop, 2019. 2

[14] K. He, X. Zhang, S. Ren, và J. Sun. Deep residual learning for image recognition. Trong CVPR, 2016. 2, 3, 7

[15] Byeongho Heo, Jeesoo Kim, Sangdoo Yun, Hyojin Park, Nojun Kwak, và Jin Young Choi. A comprehensive overhaul of feature distillation. Trong ICCV, 2019. 3

[16] Byeongho Heo, Minsik Lee, Sangdoo Yun, và Jin Young Choi. Knowledge transfer via distillation of activation boundaries formed by hidden neurons. Trong AAAI, 2019. 3

[17] Geoffrey Hinton, Oriol Vinyals, và Jeff Dean. Distilling the knowledge in a neural network. Trong NeurIPS Workshop, 2014. 2, 3, 7, 10

[18] Geoffrey E Hinton. Training products of experts by minimizing contrastive divergence. Neural Computation, 14(8):1771–1800, 2002. 2

[19] Gao Huang, Zhuang Liu, Laurens Van Der Maaten, và Kilian Q Weinberger. Densely connected convolutional networks. Trong CVPR, 2017. 2

--- TRANG 11 ---
[20] Sergey Ioffe và Christian Szegedy. Batch normalization: Accelerating deep network training by reducing internal covariate shift. Trong ICML, 2015. 2

[21] Xiaoqi Jiao, Yichun Yin, Lifeng Shang, Xin Jiang, Xiao Chen, Linlin Li, Fang Wang, và Qun Liu. Tinybert: Distilling bert for natural language understanding. arXiv preprint arXiv:1909.10351, 2019. 2, 3

[22] Michael J Kearns, Umesh Virkumar Vazirani, và Umesh Vazirani. An introduction to computational learning theory. MIT Press, 1994. 15

[23] Alex Krizhevsky. Learning multiple layers of features from tiny images. Báo cáo kỹ thuật, Citeseer, 2009. 7

[24] Solomon Kullback. Information theory and statistics. Courier Corporation, 1997. 2

[25] Yann LeCun, Yoshua Bengio, và Geoffrey Hinton. Deep learning. Nature, 521(7553):436, 2015. 2

[26] Weiyang Liu, Yandong Wen, Zhiding Yu, và Meng Yang. Large-margin softmax loss for convolutional neural networks. Trong ICML, 2016. 2

[27] Yufan Liu, Jiajiong Cao, Bing Li, Chunfeng Yuan, Weiming Hu, Yangxi Li, và Yunqiang Duan. Knowledge distillation via instance relationship graph. Trong CVPR, 2019. 3

[28] Ningning Ma, Xiangyu Zhang, Hai-Tao Zheng, và Jian Sun. Shufflenet v2: Practical guidelines for efficient cnn architecture design. Trong ECCV, 2018. 7

[29] Aditya K Menon, Ankit Singh Rawat, Sashank Reddi, Seungyeon Kim, và Sanjiv Kumar. A statistical perspective on distillation. Trong ICML, 2021. 4, 8, 16

[30] Rafael Müller, Simon Kornblith, và Geoffrey E Hinton. When does label smoothing help? Trong NeurIPS, 2019. 2, 3

[31] Wonpyo Park, Dongju Kim, Yan Lu, và Minsu Cho. Relational knowledge distillation. Trong CVPR, 2019. 2, 3, 10

[32] Nikolaos Passalis và Anastasios Tefas. Learning deep representations with probabilistic knowledge transfer. Trong ECCV, 2018. 3, 10

[33] Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, và cộng sự. Pytorch: An imperative style, high-performance deep learning library. Trong NeurIPS, 2019. 7

[34] Baoyun Peng, Xiao Jin, Jiaheng Liu, Dongsheng Li, Yichao Wu, Yu Liu, Shunfeng Zhou, và Zhaoning Zhang. Correlation congruence for knowledge distillation. Trong ICCV, 2019. 2, 3, 10

[35] Adriana Romero, Nicolas Ballas, Samira Ebrahimi Kahou, Antoine Chassang, Carlo Gatta, và Yoshua Bengio. Fitnets: Hints for thin deep nets. Trong ICLR, 2015. 3

[36] Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, và Liang-Chieh Chen. Mobilenetv2: Inverted residuals and linear bottlenecks. Trong CVPR, 2018. 7

[37] Jürgen Schmidhuber. Deep learning in neural networks: An overview. Neural networks, 61:85–117, 2015. 2

[38] Burr Settles. From theories to queries: Active learning in practice. Trong AISTATS Workshop on Active Learning and Experimental Design, 2011. 7

[39] Zhiqiang Shen, Zechun Liu, Dejia Xu, Zitian Chen, Kwang-Ting Cheng, và Marios Savvides. Is label smoothing truly incompatible with knowledge distillation: An empirical study. Trong ICLR, 2021. 3

[40] Connor Shorten và Taghi M Khoshgoftaar. A survey on image data augmentation for deep learning. Journal of Big Data, 6(1):60, 2019. 2, 3

[41] Karen Simonyan và Andrew Zisserman. Very deep convolutional networks for large-scale image recognition. Trong ICLR, 2015. 7

[42] Jy-yong Sohn, Liang Shang, Hongxu Chen, Jaekyun Moon, Dimitris Papailiopoulos, và Kangwook Lee. Genlabel: Mixup relabeling using generative models. Trong ICML, 2022. 4

[43] Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jon Shlens, và Zbigniew Wojna. Rethinking the inception architecture for computer vision. Trong CVPR, 2016. 2

--- TRANG 12 ---
[44] Jiaxi Tang, Rakesh Shivanna, Zhe Zhao, Dong Lin, Anima Singh, Ed H Chi, và Sagar Jain. Understanding and improving knowledge distillation. arXiv preprint arXiv:2002.03532, 2020. 3

[45] Yonglong Tian, Dilip Krishnan, và Phillip Isola. Contrastive representation distillation. Trong ICLR, 2020. 2, 3, 7, 9, 10, 15

[46] Frederick Tung và Greg Mori. Similarity-preserving knowledge distillation. Trong CVPR, 2019. 3, 10

[47] Vladimir Vapnik. The nature of statistical learning theory. Springer Science & Business Media, 2013. 15

[48] Vikas Verma, Alex Lamb, Christopher Beckham, Amir Najafi, Ioannis Mitliagkas, David Lopez-Paz, và Yoshua Bengio. Manifold mixup: Better representations by interpolating hidden states. Trong ICML, 2019. 3

[49] Huan Wang, Yijun Li, Yuehai Wang, Haoji Hu, và Ming-Hsuan Yang. Collaborative distillation for ultra-resolution universal style transfer. Trong CVPR, 2020. 2, 3

[50] Lin Wang và Kuk-Jin Yoon. Knowledge distillation and student-teacher learning for visual intelligence: A review and new outlooks. TPAMI, 2021. 2, 3

[51] Sangdoo Yun, Dongyoon Han, Seong Joon Oh, Sanghyuk Chun, Junsuk Choe, và Youngjoon Yoo. Cutmix: Regularization strategy to train strong classifiers with localizable features. Trong ICCV, 2019. 3, 8

[52] Sergey Zagoruyko và Nikos Komodakis. Wide residual networks. Trong BMVC, 2016. 7

[53] Sergey Zagoruyko và Nikos Komodakis. Paying more attention to attention: Improving the performance of convolutional neural networks via attention transfer. Trong ICLR, 2017. 3, 10

[54] Hongyi Zhang, Moustapha Cisse, Yann N Dauphin, và David Lopez-Paz. mixup: Beyond empirical risk minimization. Trong ICLR, 2018. 2, 3, 8

Danh sách kiểm tra
1. Đối với tất cả các tác giả...
(a) Các tuyên bố chính được đưa ra trong tóm tắt và phần giới thiệu có phản ánh chính xác đóng góp và phạm vi của bài báo không? [Có]
(b) Bạn có mô tả các hạn chế của công trình không? [Có] Xem Phụ lục của chúng tôi.
(c) Bạn có thảo luận về bất kỳ tác động xã hội tiêu cực tiềm ẩn nào của công trình không? [Có] Xem Phụ lục của chúng tôi.
(d) Bạn có đọc các hướng dẫn đánh giá đạo đức và đảm bảo rằng bài báo của bạn tuân thủ chúng không? [Có]

2. Nếu bạn bao gồm kết quả lý thuyết...
(a) Bạn có trình bày đầy đủ các giả định của tất cả kết quả lý thuyết không? [Có] Xem Phần 3.
(b) Bạn có bao gồm chứng minh đầy đủ của tất cả kết quả lý thuyết không? [Có] Xem Phần 3.

3. Nếu bạn chạy thí nghiệm...
(a) Bạn có bao gồm mã, dữ liệu và hướng dẫn cần thiết để tái tạo các kết quả thí nghiệm chính không (trong tài liệu bổ sung hoặc dưới dạng URL)? [Có] Xem Phụ lục của chúng tôi.
(b) Bạn có chỉ rõ tất cả chi tiết huấn luyện không (ví dụ, phân chia dữ liệu, siêu tham số, cách chúng được chọn)? [Có] Xem Phụ lục của chúng tôi.
(c) Bạn có báo cáo thanh lỗi không (ví dụ, đối với hạt giống ngẫu nhiên sau khi chạy thí nghiệm nhiều lần)? [Có] Tất cả kết quả CIFAR100/Tiny ImageNet/ImageNet100 của chúng tôi được lấy trung bình bởi ít nhất ba lần chạy ngẫu nhiên, báo cáo trung bình và độ lệch chuẩn.
(d) Bạn có bao gồm tổng lượng tính toán và loại tài nguyên được sử dụng không (ví dụ, loại GPU, cụm nội bộ, hoặc nhà cung cấp đám mây)? [Có] Xem Phụ lục của chúng tôi.

4. Nếu bạn đang sử dụng tài sản hiện có (ví dụ, mã, dữ liệu, mô hình) hoặc quản lý/phát hành tài sản mới...
(a) Nếu công trình của bạn sử dụng tài sản hiện có, bạn có trích dẫn người tạo ra không? [Có]

--- TRANG 13 ---
(b) Bạn có đề cập đến giấy phép của các tài sản không? [Có] Xem Phụ lục của chúng tôi.
(c) Bạn có bao gồm bất kỳ tài sản mới nào trong tài liệu bổ sung hoặc dưới dạng URL không? [Có] Chúng tôi bao gồm liên kết mã.
(d) Bạn có thảo luận về việc liệu và cách thức sự đồng ý được lấy từ những người mà dữ liệu của họ đang được sử dụng/quản lý không? [Có] Dữ liệu chúng tôi sử dụng đều có sẵn công khai.
(e) Bạn có thảo luận về việc liệu dữ liệu bạn đang sử dụng/quản lý có chứa thông tin nhận dạng cá nhân hoặc nội dung xúc phạm không? [Có] Dữ liệu chúng tôi sử dụng không chứa thông tin nhận dạng cá nhân hoặc nội dung xúc phạm.

5. Nếu bạn sử dụng crowdsourcing hoặc tiến hành nghiên cứu với đối tượng con người...
(a) Bạn có bao gồm văn bản đầy đủ của hướng dẫn đưa ra cho người tham gia và ảnh chụp màn hình, nếu có không? [Không] Không có crowdsourcing trong công trình này.
(b) Bạn có mô tả bất kỳ rủi ro tiềm ẩn nào của người tham gia, với liên kết đến phê duyệt Hội đồng Đánh giá Thể chế (IRB), nếu có không? [Không] Không có crowdsourcing trong công trình này.
(c) Bạn có bao gồm mức lương hàng giờ ước tính trả cho người tham gia và tổng số tiền chi cho bồi thường người tham gia không? [Không] Không có crowdsourcing trong công trình này.

A Phụ lục
A.1 Thêm Kết quả
Kết quả số chi tiết của Mất mát kiểm tra S. và T. stddev trên CIFAR100 và Tiny ImageNet. Xem Bảng 3, Bảng 4, Bảng 5, Bảng 6. Những bảng này là kết quả số mà chúng tôi sử dụng để vẽ Hình 4.

[Theo sau là các bảng số liệu chi tiết và các hình vẽ bổ sung khác...]

A.2 Thêm Giải thích từ Phương trình (7) đến Phương trình (8)
[Tiếp tục với các giải thích chi tiết về lý thuyết và phương pháp...]

A.3 Ví dụ về Tính toán T. Stddev
[Ví dụ cụ thể về cách tính toán chỉ số...]

A.4 Phân tích Mẫu CutMix trên ImageNet
[Phân tích về các mẫu CutMix và vấn đề không đồng ý về nhãn...]

A.5 Giấy phép Bộ dữ liệu và Điều kiện Phần cứng
[Thông tin về giấy phép và yêu cầu tính toán...]

A.6 Hạn chế và Tác động Xã hội Tiêu cực Tiềm ẩn
[Thảo luận về các hạn chế và tác động tiềm ẩn...]

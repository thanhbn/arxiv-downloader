CoDa: Tăng cường dữ liệu dựa trên sinh tạo có ràng buộc cho NLP tài nguyên thấp

Chandra Kiran Evuru♠∗ Sreyan Ghosh♠∗ Sonal Kumar♠ Ramaneswaran S♣
Utkarsh Tyagi♠ Dinesh Manocha♠
♠Đại học Maryland, College Park, Hoa Kỳ ♣NVIDIA, Bangalore, Ấn Độ
{ckevuru, sreyang, sonalkum, utkarsht, dmanocha}@umd.edu, ramanr@nvidia.com

Tóm tắt

Chúng tôi trình bày CoDa (Tăng cường dữ liệu dựa trên sinh tạo có ràng buộc), một kỹ thuật tăng cường dữ liệu có thể kiểm soát, hiệu quả và không cần huấn luyện cho NLP tài nguyên thấp (khan hiếm dữ liệu). Phương pháp của chúng tôi dựa trên việc nhắc nhở các mô hình ngôn ngữ lớn (LLM) theo hướng dẫn có sẵn để tạo ra văn bản thỏa mãn một tập hợp các ràng buộc. Cụ thể, chúng tôi trích xuất một tập hợp các ràng buộc đơn giản từ mỗi trường hợp trong tập dữ liệu tài nguyên thấp và diễn đạt chúng thành lời để nhắc nhở LLM tạo ra các trường hợp huấn luyện mới và đa dạng. Phát hiện của chúng tôi tiết lộ rằng dữ liệu tổng hợp tuân theo các ràng buộc đơn giản trong tập dữ liệu downstream hoạt động như những tăng cường rất hiệu quả, và CoDa có thể đạt được điều này mà không cần các kỹ thuật sinh tạo có ràng buộc phức tạp tại thời điểm giải mã hoặc tinh chỉnh bằng các thuật toán phức tạp cuối cùng làm cho mô hình thiên vị với số lượng nhỏ các trường hợp huấn luyện. Ngoài ra, CoDa là framework đầu tiên cung cấp cho người dùng khả năng kiểm soát rõ ràng quá trình tạo tăng cường, do đó cũng cho phép dễ dàng thích ứng với nhiều domain khác nhau. Chúng tôi chứng minh tính hiệu quả của CoDa trên 11 tập dữ liệu trải dài 3 nhiệm vụ và 3 cài đặt tài nguyên thấp. CoDa vượt trội so với tất cả các baseline của chúng tôi về mặt định tính và định lượng, với cải thiện từ 0,12%-7,19%. Mã nguồn có sẵn¹.

1 Giới thiệu

Tăng cường dữ liệu là một kỹ thuật được sử dụng rộng rãi để giải quyết vấn đề dữ liệu huấn luyện hạn chế trong NLP tài nguyên thấp (Chen et al., 2023). Nhờ sự tiến bộ gần đây trong AI tạo sinh, việc sử dụng dữ liệu tổng hợp để huấn luyện các mô hình cụ thể cho nhiệm vụ cũng đã trở nên phổ biến. Tuy nhiên, với một tập dữ liệu NLU tài nguyên thấp, việc tạo ra dữ liệu cụ thể cho nhiệm vụ một cách hiệu quả để mở rộng tập dữ liệu vẫn đặt ra một thách thức đáng kể. Ví dụ, trong khi sự đa dạng về token và ngữ cảnh trong các tăng cường được tạo ra thường có lợi cho hiệu suất downstream, các ví dụ quá đa dạng có thể ảnh hưởng tiêu cực đến tính nhất quán với phân phối dữ liệu downstream cơ bản, do đó làm giảm hiệu suất (Geiping et al., 2023). Điều này nhấn mạnh tầm quan trọng của việc có nhiều kiểm soát hơn trong quá trình tạo sinh để đảm bảo tăng cường dữ liệu được thực hiện một cách hiệu quả.

Trong quá khứ, các nhà nghiên cứu đã sử dụng các phương pháp như chỉnh sửa văn bản (Wei và Zou, 2019; Karimi et al., 2021; Shou et al., 2022), tinh chỉnh các mô hình ngôn ngữ được huấn luyện trước (PLM) với các thuật toán khác nhau (Wang et al., 2022; Zhou et al., 2021; Guo et al., 2022; Ghosh et al., 2023a,c), v.v. Tuy nhiên, hầu hết các phương pháp này không áp dụng kiểm soát rõ ràng để đạt được sự đa dạng hoặc nhất quán. Sự nổi lên gần đây của các LLM tự hồi quy, được biết đến với khả năng tạo sinh và lập luận tiên tiến, mang lại những cơ hội đầy hứa hẹn nhưng chưa được khám phá đầy đủ để tăng cường sự đa dạng trong tổng hợp dữ liệu tổng hợp cụ thể cho nhiệm vụ. Tuy nhiên, việc kiểm soát việc tạo sinh tự hồi quy đã tỏ ra khó khăn và phức tạp một cách bẩm sinh (Zhang et al., 2023), và các phương pháp dựa trên prompting thường đã sử dụng nỗ lực thủ công của con người để trích xuất các thuộc tính dữ liệu thúc đẩy tính nhất quán (Yu et al., 2023).

Đóng góp chính. Chúng tôi đề xuất CoDa, một phương pháp tăng cường dữ liệu mới và hiệu quả cho NLP tài nguyên thấp. CoDa hoạt động với bất kỳ LLM được tinh chỉnh hướng dẫn nào có sẵn theo cách không cần huấn luyện và cung cấp khả năng kiểm soát rõ ràng các tăng cường được tạo ra. Trước tiên, chúng tôi trích xuất các ràng buộc đơn giản dựa trên heuristic từ các trường hợp huấn luyện trong tập dữ liệu NLU tài nguyên thấp và sau đó diễn đạt chúng để xây dựng một hướng dẫn bằng ngôn ngữ tự nhiên. Tiếp theo, chúng tôi sử dụng hướng dẫn này để nhắc nhở LLM tạo ra các tăng cường (ví dụ trong Hình 1). Thay thế cho các phương pháp sinh tạo có ràng buộc phức tạp tại thời điểm giải mã và trích xuất thuộc tính thủ công, CoDa cung cấp giao diện dựa trên ngôn ngữ tự nhiên đơn giản hơn và trực quan hơn cho việc sinh tạo có ràng buộc. CoDa cũng là framework đầu tiên khám phá việc tạo sinh có kiểm soát cho tăng cường dữ liệu, điều này đảm bảo rằng dữ liệu tổng hợp được căn chỉnh chặt chẽ với các nhu cầu cụ thể của nhiệm vụ và đặc điểm của domain đích. Chúng tôi cho thấy CoDa, không cần huấn luyện và đơn giản hơn nhiều, vượt trội so với tất cả các công trình trước đó về mặt định lượng và định tính từ 0,12%-7,19% trên các cài đặt khác nhau.

2 Công trình liên quan

Tăng cường dữ liệu tạo sinh cho NLP tài nguyên thấp đã được nghiên cứu rộng rãi trong các công trình trước đây và có thể được phân loại thành bốn kỹ thuật chính. Thứ nhất, điền văn bản bao gồm việc làm hỏng các phần văn bản nguồn và sử dụng PLM để điền lại các khoảng trống này. Quá trình này thường dựa vào việc điều kiện hoá văn bản bị hỏng, một khái niệm cũng được gọi là điều kiện hoá từ khoá trong một số nghiên cứu (Zhou et al., 2021; Guo et al., 2022; Ghosh et al., 2023c,a,b). Thứ hai, chỉnh sửa văn bản tập trung vào việc sửa đổi một số phần nhất định của một câu cho trước (Wei và Zou, 2019; Shou et al., 2022). Thứ ba, prompting bao gồm việc tạo ra các câu huấn luyện mới bằng cách nhắc nhở LLM (Ye et al., 2022; Sahu et al., 2023), có thể được phân loại thêm thành điều kiện hoá thuộc tính, exemplar hoặc các ràng buộc được trích xuất từ dữ liệu huấn luyện.

3 Phương pháp

Hình 1 minh hoạ pipeline CoDa. Cho một tập dữ liệu tài nguyên thấp D={d₀,⋯,dᵢ,⋯dₙ}, trước tiên chúng tôi trích xuất một tập hợp các ràng buộc đơn giản dựa trên heuristic từ mỗi tài liệu dᵢ và sau đó diễn đạt các ràng buộc để xây dựng một hướng dẫn Iᵢ. Sau đó, chúng tôi hướng dẫn LLM bằng Iᵢ để tạo ra một tài liệu hoàn toàn mới hoặc diễn đạt lại một tài liệu khác hiện có từ D. Đối với trường hợp sau, trước tiên chúng tôi truy xuất một tài liệu từ D, chuyển đổi nó thành mô tả tóm tắt ngắn gọn và súc tích bằng cách nhắc nhở LLM, và sau đó sử dụng Iᵢ để tạo ra một tài liệu từ mô tả tóm tắt và các ràng buộc được trích xuất. Đối với việc truy xuất, chúng tôi tính toán độ tương tự cosine giữa các embedding SentenceBERT (Reimers và Gurevych, 2019) của tài liệu nguồn dᵢ và tất cả các tài liệu khác trong D, và chúng tôi lấy mẫu ngẫu nhiên một câu từ các câu tương tự top-k và bottom-k. Đối với tổng cộng 5 tăng cường, chúng tôi đã tạo ra 3 tài liệu mới và diễn đạt lại 2 tài liệu khác cho mỗi dᵢ. Cuối cùng, tất cả các tăng cường được tạo ra đều được thêm vào D để huấn luyện một mô hình NLU downstream. Chúng tôi bây giờ mô tả chi tiết phương pháp trích xuất ràng buộc của chúng tôi.

3.1 Trích xuất ràng buộc

a) Ràng buộc từ vựng. Được truyền cảm hứng từ nhiều công trình trước đây về tăng cường dữ liệu tạo sinh và sinh tạo có ràng buộc (Zhou et al., 2023), chúng tôi trích xuất một tập hợp từ khoá từ một câu nguồn và ràng buộc các tăng cường phải chứa những từ khoá này. Cụ thể hơn, cho một tài liệu nguồn d, trước tiên chúng tôi trích xuất tất cả các n-gram của nó (1 đến 3-gram) N={n₀,⋯,nₜ,⋯,nₜ}. Tiếp theo, chúng tôi gán một điểm quan trọng cho mỗi gram bằng cách tính toán độ tương tự cosine giữa E(nₜ) và E(d), trong đó E là SentenceBERT được huấn luyện trước. Cuối cùng, chúng tôi chọn top-k n-gram làm từ khoá của chúng tôi. Ngoài ra, đối với các nhiệm vụ như NER và QA, chúng tôi thêm các khoảng đích tương ứng vào danh sách.

b) Ràng buộc cú pháp. Trong các domain chính thức như pháp lý và y sinh, ngôn ngữ thường được chi phối bởi các cấu trúc cú pháp. Tuân theo một mẫu POS được xác định trước đảm bảo rằng các câu được tạo ra tuân thủ phong cách và giọng điệu chính thức được mong đợi trong domain. Độc giả có thể tham khảo Phụ lục 10 để xem một số ví dụ. Do đó, chúng tôi xem xét các ràng buộc cú pháp đòi hỏi các tăng cường được tạo ra phải tuân thủ các quy tắc cú pháp cụ thể. Cụ thể hơn, chúng tôi trích xuất chuỗi part-of-speech từ một câu được chọn ngẫu nhiên trong d và ràng buộc việc tạo sinh của chúng tôi phải tuân thủ chuỗi này cho một câu cụ thể.

c) Ràng buộc ngữ nghĩa (nhãn). Một yêu cầu chính đối với các tăng cường dữ liệu hiệu quả là ngữ nghĩa của các tăng cường được tạo ra phải tuân thủ nhãn cơ bản của tài liệu nguồn d. Để đáp ứng điều này, chúng tôi xem xét các ràng buộc nhãn để các tăng cường được tạo ra căn chỉnh chặt chẽ với nhãn đích gốc (ví dụ: tình cảm tích cực). Chúng tôi sử dụng nhãn đích của d với 3 exemplar cho ràng buộc này. Các exemplar được chọn ngẫu nhiên từ tập dữ liệu D và được đặt theo thứ tự ngẫu nhiên trong hướng dẫn cuối cùng.

d) Ràng buộc độ dài. Sự không khớp về độ dài giữa các trường hợp huấn luyện và kiểm tra đã được biết là làm giảm hiệu suất NLU downstream (Rogers et al., 2021). Được thúc đẩy bởi điều này, chúng tôi xem xét các ràng buộc độ dài đòi hỏi tổng số token trong các tăng cường được tạo ra phải nằm trong một phạm vi được chỉ định. Chúng tôi tính toán tổng số token trong d và cộng và trừ sd từ nó để có được giới hạn dưới và trên của phạm vi tương ứng. Giá trị của sd được xác định bằng cách tính toán độ lệch chuẩn của phân phối độ dài trên toàn bộ tập dữ liệu D.

e) Ràng buộc khái niệm. Sự hiện diện của các đặc điểm giả mạo trong tập huấn luyện khiến mô hình NLU downstream áp dụng các chiến lược học tắt, ảnh hưởng đến hiệu suất của nó trong các tình huống thực tế, không điển hình nơi những đặc điểm này không có mặt (Sagawa* et al., 2020). Tăng cường dữ liệu có thể khuếch đại thêm những đặc điểm giả mạo như vậy trong D nếu không được xử lý đúng cách. Chúng tôi đề xuất một chiến lược mới để đảm bảo rằng các tăng cường được tạo ra không có các đặc điểm giả mạo. Trước tiên, chúng tôi sử dụng phương pháp được đề xuất bởi Friedman et al. (2022) để trích xuất danh sách các cụm từ giả mạo cho mỗi nhãn trong tập dữ liệu. Sau đó, chúng tôi chuyển những cụm từ này cùng với các câu ví dụ chứa những cụm từ này cho LLM và yêu cầu nó trả về một khái niệm trừu tượng ngắn mà các cụm từ giả mạo mô tả trong các tài liệu (ví dụ: đánh giá trong các bài đánh giá phim cho các đánh giá tiêu cực trong tập dữ liệu IMDB). Cuối cùng, chúng tôi chọn top 3 khái niệm trừu tượng cho mỗi nhãn và thêm chúng như một ràng buộc phủ định để tạo tăng cường.

3.2 Xây dựng hướng dẫn

Sau khi trích xuất các ràng buộc từ d, chúng tôi diễn đạt các ràng buộc thành một hướng dẫn duy nhất để nhắc nhở LLM được tinh chỉnh hướng dẫn. Việc diễn đạt được thực hiện thông qua các template cố định được viết tay. Một ví dụ về hướng dẫn được hiển thị trong Hình 1.

4 Thiết lập thí nghiệm

Baseline. Gold-only đề cập đến việc huấn luyện mô hình của chúng tôi chỉ trên dữ liệu gold tài nguyên thấp. Đối với phân loại chuỗi (SC), chúng tôi so sánh CoDa với các baseline chỉnh sửa văn bản: EDA (Wei và Zou, 2019), AEDA (Karimi et al., 2021), và AMR-DA (Shou et al., 2022), các baseline điền dựa trên học: SSMBA (Ng et al., 2020), GENIUS(-ft) (Guo et al., 2022), PromDA (Wang et al., 2022), các baseline prompting dựa trên LLM: ZeroGen (Ye et al., 2022), GPT3Mix (Yoo et al., 2021) và các baseline diễn đạt lại: BackTrans (Yu et al., 2018). Đối với nhiệm vụ phân loại ý định, cụ thể trong SC, chúng tôi thêm một baseline prompting dựa trên LLM khác: PromptMix (Sahu et al., 2023). Đối với nhận dạng thực thể có tên (NER), chúng tôi so sánh CoDa với LwTR (Dai và Adel, 2020), DAGA (Ding et al., 2020), MELM (Zhou et al., 2021), PromDA (Wang et al., 2022) và ACLM (Ghosh et al., 2023c). Cuối cùng, đối với trả lời câu hỏi (QA), chúng tôi so sánh nó với ZeroGen, BackTrans, GENIUS, EDA, và AEDA. Chi tiết về cách hoạt động của tất cả các baseline được cung cấp trong Phần D.

Tập dữ liệu. Để chứng minh tính linh hoạt của CoDa, chúng tôi đánh giá nó trên các tập dữ liệu thách thức khác nhau thuộc về nhiều domain khác nhau. Đối với SC, chúng tôi sử dụng Huffpost (Misra và Grover, 2021) (phân loại thể loại tin tức), Yahoo (Zhang et al., 2015) (phân loại chủ đề câu trả lời), OTS (Drawzeski et al., 2021) (phân loại mức độ không công bằng của dịch vụ trực tuyến pháp lý), ATIS (Coucke et al., 2018) và Massive (FitzGerald et al., 2022) (phân loại ý định). Đối với NER, chúng tôi sử dụng ConLL-2003 (Tjong Kim Sang và De Meulder, 2003), OntoNotes-5.0 (Pradhan et al., 2013) (domain tin tức), EBMNLP (Nye et al., 2018) và BC2GM (Krallinger et al., 2015) (y sinh). Cuối cùng, đối với QA, chúng tôi sử dụng SQuAD (Rajpurkar et al., 2016) và NewsQA (Trischler et al., 2017). Chi tiết về mỗi tập dữ liệu và thống kê tập dữ liệu được cung cấp trong Phần C.

Cài đặt siêu tham số. Chúng tôi nhắc nhở LLama-13B với nhiệt độ 0,5, top-p 1,0, top-k=50. Đối với tất cả các nhiệm vụ NLU downstream, chúng tôi sử dụng BERT base-uncased (Devlin et al., 2019) làm encoder (trừ OTS nơi chúng tôi sử dụng legal-longformer large (Chalkidis* et al., 2023)). Chúng tôi tinh chỉnh encoder với batch size 4,8 cho 100 và 200 splits và 16 cho 500 và 1000 splits. Cụ thể đối với NER, chúng tôi sử dụng thư viện flair (Akbik et al., 2019) với lr ban đầu 1e−5 và decay hằng số. Phụ lục A cung cấp các thí nghiệm điều chỉnh siêu tham số. Chúng tôi báo cáo điểm F1 trung bình micro được tính trung bình trên 3 lần chạy cho 3 seed ngẫu nhiên.

5 Kết quả và phân tích

Phân tích định lượng. Bảng 2, 3, và 4 so sánh CoDa với tất cả các baseline của chúng tôi về các nhiệm vụ SC, NER, và QA tương ứng. CoDa vượt trội so với các baseline của chúng tôi trong SC từ 0,12% - 5,94%, NER từ 0,47% - 7,19%, và QA từ 1,10% - 3,06%. Mặc dù hầu hết các phương pháp trước đây được đề xuất cho một domain thường kém hiệu quả ở domain khác (Ghosh et al., 2023a), CoDa liên tục vượt trội so với những phương pháp này trong tất cả các domain với các tính chất ngữ nghĩa và cú pháp khác nhau, nhấn mạnh bản chất độc lập domain của nó.

Phân tích định tính. Bảng 5 so sánh chất lượng sinh tạo của CoDa với tất cả các baseline của chúng tôi (trung bình theo baseline trên tất cả các nhiệm vụ và splits) về các thước đo perplexity (Jelinek et al., 1977), sự đa dạng (số lượng token mới trung bình được giới thiệu trong R tăng cường) và sự đa dạng độ dài (sự khác biệt tuyệt đối trung bình về độ dài của nguồn và R tăng cường). CoDa vượt trội so với hầu hết các baseline của chúng tôi trong tất cả các cài đặt. Ngoài ra, như quan sát được trong Bảng 5, không giống như các phương pháp dựa trên học khác trong tài liệu, sự đa dạng của các tăng cường bởi CoDa không phụ thuộc vào số lượng mẫu huấn luyện gold có sẵn. Nó hoạt động tốt như nhau trong cả 100 và 500 splits.

Hình 2 so sánh các tăng cường CoDa với các baseline khác trong tài liệu với một mẫu huấn luyện gold được lấy từ tập dữ liệu OTS. Tạo ra tăng cường trên tập dữ liệu OTS, thuộc về domain pháp lý, vốn khó khăn do bản chất chính thức của ngôn ngữ pháp lý (Ghosh et al., 2023a). Như chúng ta có thể thấy, CoDa tạo ra các tăng cường coherent, đa dạng và nhất quán với nhãn. Nhiều ví dụ hơn được cung cấp trong Hình 3, 4 và 5. Ngoài ra, Phụ lục B đánh giá mức độ trung thực của LLaMa-2 trong việc tuân theo các ràng buộc trong hướng dẫn.

6 Kết luận

Chúng tôi trình bày CoDa, một kỹ thuật tăng cường dữ liệu đơn giản và có thể kiểm soát cho NLP tài nguyên thấp. CoDa trích xuất các ràng buộc đơn giản dựa trên heuristic từ các câu nguồn và diễn đạt chúng để xây dựng hướng dẫn, sau đó được sử dụng để nhắc nhở LLM tạo ra các tăng cường. CoDa không cần huấn luyện và hoạt động với bất kỳ LLM được tinh chỉnh hướng dẫn nào có sẵn. Ngoài việc cung cấp khả năng kiểm soát rõ ràng, CoDa cũng linh hoạt, tức là các ràng buộc có thể dễ dàng thay thế hoặc thêm vào, tăng cường tính phù hợp của nó trên các domain đa dạng.

Hạn chế và công việc tương lai

Mặc dù hiệu quả, CoDa vẫn gặp phải nhiều hạn chế khác nhau mà chúng tôi muốn đề cập. Những hạn chế này sẽ vẫn là trọng tâm chính của chúng tôi trong công việc tương lai. Các hạn chế như sau:

• LLM thường gặp khó khăn trong việc tuân theo các ràng buộc phức tạp trong hướng dẫn để tạo văn bản (Lu et al., 2023). Chúng tôi khắc phục vấn đề này trong CoDa bằng cách sử dụng các ràng buộc đơn giản. Tuy nhiên, chúng tôi thừa nhận rằng tăng cường dữ liệu cho các domain và nhiệm vụ phức tạp có thể cần sử dụng các ràng buộc phức tạp hơn. Do đó, như một phần của công việc tương lai, chúng tôi muốn sử dụng những tiến bộ gần đây trong prompting có cấu trúc để chia nhỏ các ràng buộc phức tạp thành các hướng dẫn đơn giản hơn.

• Mặc dù không cần huấn luyện, CoDa tốn kém về mặt tính toán hơn trong thời gian suy luận so với các công trình trước đây vì nó sử dụng LLM. Như cũng được hiển thị trong Phần A.2, hiệu suất tổng thể của CoDa bị giảm nhẹ khi sử dụng LLaMa-7B thay vì phiên bản 13B. Tuy nhiên, chúng tôi thừa nhận rằng khi các mô hình nhỏ hơn trở nên tốt hơn trong việc tuân theo hướng dẫn, CoDa có thể hoạt động hiệu quả hơn.

Tài liệu tham khảo

Alan Akbik, Tanja Bergmann, Duncan Blythe, Kashif Rasul, Stefan Schweter, và Roland Vollgraf. 2019. FLAIR: Một framework dễ sử dụng cho NLP hiện đại. Trong NAACL 2019, Hội nghị thường niên 2019 của North American Chapter of the Association for Computational Linguistics (Demonstrations), trang 54–59.

Jiong Cai, Shen Huang, Yong Jiang, Zeqi Tan, Pengjun Xie, và Kewei Tu. 2023. Tăng cường dữ liệu dựa trên truyền đồ thị cho nhận dạng thực thể có tên. Trong Kỷ yếu Hội nghị thường niên lần thứ 61 của Association for Computational Linguistics (Tập 2: Bài báo ngắn), trang 110–118, Toronto, Canada. Association for Computational Linguistics.

Ilias Chalkidis*, Nicolas Garneau*, Catalina Goanta, Daniel Martin Katz, và Anders Søgaard. 2023. LexFiles và LegalLAMA: Tạo điều kiện phát triển mô hình ngôn ngữ pháp lý đa quốc gia tiếng Anh. Trong Kỷ yếu Hội nghị thường niên lần thứ 61 của Association for Computational Linguistics, Toronto, Canada. Association for Computational Linguistics.

Jiaao Chen, Derek Tam, Colin Raffel, Mohit Bansal, và Diyi Yang. 2023. Một khảo sát thực nghiệm về tăng cường dữ liệu cho học tập dữ liệu hạn chế trong nlp. Transactions of the Association for Computational Linguistics, 11:191–211.

Shuguang Chen, Leonardo Neves, và Thamar Solorio. 2022. Chuyển đổi phong cách như tăng cường dữ liệu: Một nghiên cứu trường hợp về nhận dạng thực thể có tên. Trong Kỷ yếu Hội nghị 2022 về Phương pháp thực nghiệm trong xử lý ngôn ngữ tự nhiên, trang 1827–1841, Abu Dhabi, United Arab Emirates. Association for Computational Linguistics.

Alice Coucke, Alaa Saade, Adrien Ball, Théodore Bluche, Alexandre Caulier, David Leroy, Clément Doumouro, Thibault Gisselbrecht, Francesco Caltagirone, Thibaut Lavril, và cộng sự. 2018. Nền tảng giọng nói Snips: một hệ thống hiểu ngôn ngữ nói nhúng cho các giao diện giọng nói thiết kế riêng tư. arXiv preprint arXiv:1805.10190.

Xiang Dai và Heike Adel. 2020. Một phân tích về tăng cường dữ liệu đơn giản cho nhận dạng thực thể có tên. Trong Kỷ yếu Hội nghị quốc tế lần thứ 28 về Ngôn ngữ học tính toán, trang 3861–3867, Barcelona, Spain (Trực tuyến). International Committee on Computational Linguistics.

Jacob Devlin, Ming-Wei Chang, Kenton Lee, và Kristina Toutanova. 2019. Bert: Huấn luyện trước các transformer hai chiều sâu để hiểu ngôn ngữ.

Bosheng Ding, Linlin Liu, Lidong Bing, Canasai Kruengkrai, Thien Hai Nguyen, Shafiq Joty, Luo Si, và Chunyan Miao. 2020. DAGA: Tăng cường dữ liệu với phương pháp sinh tạo cho các nhiệm vụ gắn thẻ tài nguyên thấp. Trong Kỷ yếu Hội nghị 2020 về Phương pháp thực nghiệm trong xử lý ngôn ngữ tự nhiên (EMNLP), trang 6045–6057, Trực tuyến. Association for Computational Linguistics.

Kasper Drawzeski, Andrea Galassi, Agnieszka Jablonowska, Francesca Lagioia, Marco Lippi, Hans Wolfgang Micklitz, Giovanni Sartor, Giacomo Tagiuri, và Paolo Torroni. 2021. Một corpus để phân tích đa ngôn ngữ các điều khoản dịch vụ trực tuyến. Trong Kỷ yếu Hội thảo xử lý ngôn ngữ pháp lý tự nhiên 2021, trang 1–8, Punta Cana, Dominican Republic. Association for Computational Linguistics.

Jack FitzGerald, Christopher Hench, Charith Peris, Scott Mackie, Kay Rottmann, Ana Sanchez, Aaron Nash, Liam Urbach, Vishesh Kakarala, Richa Singh, Swetha Ranganath, Laurie Crist, Misha Britan, Wouter Leeuwis, Gokhan Tur, và Prem Natarajan. 2022. Massive: Một tập dữ liệu hiểu ngôn ngữ tự nhiên đa ngôn ngữ 1 triệu ví dụ với 51 ngôn ngữ đa dạng về mặt kiểu học.

Dan Friedman, Alexander Wettig, và Danqi Chen. 2022. Tìm kiếm các phím tắt tập dữ liệu với quy nạp ngữ pháp. Trong Kỷ yếu Hội nghị 2022 về Phương pháp thực nghiệm trong xử lý ngôn ngữ tự nhiên, trang 4345–4363, Abu Dhabi, United Arab Emirates. Association for Computational Linguistics.

Jonas Geiping, Micah Goldblum, Gowthami Somepalli, Ravid Shwartz-Ziv, Tom Goldstein, và Andrew Gordon Wilson. 2023. Tăng cường dữ liệu có giá trị bao nhiêu? một điều tra về luật quy mô, tính bất biến và điều chỉnh ẩn. Trong Hội nghị quốc tế lần thứ 11 về biểu diễn học tập.

Sreyan Ghosh, Chandra Kiran Evuru, Sonal Kumar, S Ramaneswaran, S Sakshi, Utkarsh Tyagi, và Dinesh Manocha. 2023a. Dale: Tăng cường dữ liệu tạo sinh cho nlp pháp lý tài nguyên thấp. Trong Kỷ yếu Hội nghị 2023 về Phương pháp thực nghiệm trong xử lý ngôn ngữ tự nhiên, Sentosa, Singapore.

Sreyan Ghosh, Utkarsh Tyagi, Sonal Kumar, và Dinesh Manocha. 2023b. Bioaug: Tăng cường dữ liệu dựa trên sinh tạo có điều kiện cho ner y sinh tài nguyên thấp. Trong Kỷ yếu Hội nghị quốc tế ACM SIGIR lần thứ 46 về Nghiên cứu và phát triển trong truy xuất thông tin, SIGIR '23, trang 1853–1858, New York, NY, USA. Association for Computing Machinery.

Sreyan Ghosh, Utkarsh Tyagi, Manan Suri, Sonal Kumar, S Ramaneswaran, và Dinesh Manocha. 2023c. Aclm: Một phương pháp tăng cường dữ liệu tạo sinh dựa trên khử nhiễu chọn lọc cho ner phức tạp tài nguyên thấp. Trong Kỷ yếu Hội nghị thường niên lần thứ 61 của Association for Computational Linguistics (Tập 1: Bài báo dài), Toronto, Canada. Association for Computational Linguistics.

Biyang Guo, Yeyun Gong, Yelong Shen, Songqiao Han, Hailiang Huang, Nan Duan, và Weizhu Chen. 2022. Genius: Huấn luyện trước mô hình ngôn ngữ dựa trên phác thảo thông qua che giấu cực đoan và chọn lọc để tạo và tăng cường văn bản. arXiv preprint arXiv:2211.10330.

Xuming Hu, Yong Jiang, Aiwei Liu, Zhongqiang Huang, Pengjun Xie, Fei Huang, Lijie Wen, và Philip S. Yu. 2023. Tăng cường dữ liệu dựa trên entity-to-text cho các nhiệm vụ nhận dạng thực thể có tên khác nhau.

Fred Jelinek, Robert L Mercer, Lalit R Bahl, và James K Baker. 1977. Perplexity—một thước đo độ khó của các nhiệm vụ nhận dạng giọng nói. The Journal of the Acoustical Society of America, 62(S1):S63–S63.

Albert Q. Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra Singh Chaplot, Diego de las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile Saulnier, Lélio Renard Lavaud, Marie-Anne Lachaux, Pierre Stock, Teven Le Scao, Thibaut Lavril, Thomas Wang, Timothée Lacroix, và William El Sayed. 2023. Mistral 7b.

Akbar Karimi, Leonardo Rossi, và Andrea Prati. 2021. AEDA: Một kỹ thuật tăng cường dữ liệu dễ hơn cho phân loại văn bản. Trong Findings of the Association for Computational Linguistics: EMNLP 2021, trang 2748–2754, Punta Cana, Dominican Republic. Association for Computational Linguistics.

Martin Krallinger, Obdulia Rabal, Florian Leitner, Miguel Vazquez, David Salgado, Zhiyong Lu, Robert Leaman, Yanan Lu, Donghong Ji, Daniel M Lowe, và cộng sự. 2015. Corpus chemdner về hóa chất và thuốc và các nguyên tắc chú thích của nó. Journal of cheminformatics, 7(1):1–17.

Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Ves Stoyanov, và Luke Zettlemoyer. 2019. Bart: Huấn luyện trước chuỗi-đến-chuỗi khử nhiễu cho tạo sinh, dịch thuật và hiểu ngôn ngữ tự nhiên. arXiv preprint arXiv:1910.13461.

Albert Lu, Hongxin Zhang, Yanzhe Zhang, Xuezhi Wang, và Diyi Yang. 2023. Giới hạn khả năng của các mô hình ngôn ngữ lớn trong tạo văn bản mở với các ràng buộc prompt.

Microsoft. 2023. Cntk: Hiểu ngôn ngữ/atis/data. Có sẵn tại: https://github.com/Microsoft/CNTK/tree/master/Examples/LanguageUnderstanding/ATIS/Data.

Rishabh Misra và Jigyasa Grover. 2021. Sculpting Data for ML: The first act of Machine Learning.

Nathan Ng, Kyunghyun Cho, và Marzyeh Ghassemi. 2020. SSMBA: Tăng cường dữ liệu dựa trên manifold tự giám sát để cải thiện độ bền ngoài domain. Trong Kỷ yếu Hội nghị 2020 về Phương pháp thực nghiệm trong xử lý ngôn ngữ tự nhiên (EMNLP), trang 1268–1283, Trực tuyến. Association for Computational Linguistics.

Joel Niklaus, Veton Matoshi, Pooja Rani, Andrea Galassi, Matthias Stürmer, và Ilias Chalkidis. 2023. Lextreme: Một benchmark đa ngôn ngữ và đa nhiệm vụ cho domain pháp lý. arXiv preprint arXiv:2301.13126.

Benjamin Nye, Junyi Jessy Li, Roma Patel, Yinfei Yang, Iain J Marshall, Ani Nenkova, và Byron C Wallace. 2018. Một corpus với chú thích đa cấp về bệnh nhân, can thiệp và kết quả để hỗ trợ xử lý ngôn ngữ cho tài liệu y khoa. Trong Kỷ yếu hội nghị. Association for Computational Linguistics. Meeting, tập 2018, trang 197. NIH Public Access.

Sameer Pradhan, Alessandro Moschitti, Nianwen Xue, Hwee Tou Ng, Anders Björkelund, Olga Uryupina, Yuchen Zhang, và Zhi Zhong. 2013. Hướng tới phân tích ngôn ngữ mạnh mẽ sử dụng ontonotes. Trong Kỷ yếu Hội nghị thứ 17 về Học tập ngôn ngữ tự nhiên tính toán, trang 143–152.

Adir Rahamim, Guy Uziel, Esther Goldbraich, và Ateret Anaby Tavor. 2023. Tăng cường văn bản sử dụng tái cấu trúc tập dữ liệu cho phân loại tài nguyên thấp. Trong Findings of the Association for Computational Linguistics: ACL 2023, trang 7389–7402, Toronto, Canada. Association for Computational Linguistics.

Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, và Percy Liang. 2016. Squad: 100,000+ câu hỏi để hiểu máy về văn bản. arXiv preprint arXiv:1606.05250.

Nils Reimers và Iryna Gurevych. 2019. Sentence-bert: Embedding câu sử dụng mạng bert siamese. arXiv preprint arXiv:1908.10084.

Anna Rogers, Olga Kovaleva, và Anna Rumshisky. 2021. Một primer trong bertology: Những gì chúng ta biết về cách bert hoạt động. Transactions of the Association for Computational Linguistics, 8:842–866.

Shiori Sagawa*, Pang Wei Koh*, Tatsunori B. Hashimoto, và Percy Liang. 2020. Mạng thần kinh phân phối mạnh mẽ. Trong Hội nghị quốc tế về biểu diễn học tập.

Gaurav Sahu, Olga Vechtomova, Dzmitry Bahdanau, và Issam H Laradji. 2023. Promptmix: Một phương pháp tăng cường ranh giới lớp cho chưng cất mô hình ngôn ngữ lớn. arXiv preprint arXiv:2310.14192.

Ziyi Shou, Yuxin Jiang, và Fangzhen Lin. 2022. AMR-DA: Tăng cường dữ liệu bằng Biểu diễn ý nghĩa trừu tượng. Trong Findings of the Association for Computational Linguistics: ACL 2022, trang 3082–3098, Dublin, Ireland. Association for Computational Linguistics.

Erik F. Tjong Kim Sang và Fien De Meulder. 2003. Giới thiệu về nhiệm vụ chung CoNLL-2003: Nhận dạng thực thể có tên độc lập ngôn ngữ. Trong Kỷ yếu Hội nghị thứ 7 về Học tập ngôn ngữ tự nhiên tại HLT-NAACL 2003, trang 142–147.

Adam Trischler, Tong Wang, Xingdi Yuan, Justin Harris, Alessandro Sordoni, Philip Bachman, và Kaheer Suleman. 2017. NewsQA: Một tập dữ liệu hiểu máy. Trong Kỷ yếu Hội thảo thứ 2 về Học biểu diễn cho NLP, trang 191–200, Vancouver, Canada. Association for Computational Linguistics.

Yufei Wang, Can Xu, Qingfeng Sun, Huang Hu, Chongyang Tao, Xiubo Geng, và Daxin Jiang. 2022. PromDA: Tăng cường dữ liệu dựa trên prompt cho các nhiệm vụ NLU tài nguyên thấp. Trong Kỷ yếu Hội nghị thường niên lần thứ 60 của Association for Computational Linguistics (Tập 1: Bài báo dài), trang 4242–4255, Dublin, Ireland. Association for Computational Linguistics.

Jason Wei và Kai Zou. 2019. Eda: Các kỹ thuật tăng cường dữ liệu dễ dàng để tăng cường hiệu suất trên các nhiệm vụ phân loại văn bản. arXiv preprint arXiv:1901.11196.

Jiacheng Ye, Jiahui Gao, Qintong Li, Hang Xu, Jiangtao Feng, Zhiyong Wu, Tao Yu, và Lingpeng Kong. 2022. ZeroGen: Học zero-shot hiệu quả thông qua tạo tập dữ liệu. Trong Kỷ yếu Hội nghị 2022 về Phương pháp thực nghiệm trong xử lý ngôn ngữ tự nhiên, trang 11653–11669, Abu Dhabi, United Arab Emirates. Association for Computational Linguistics.

Kang Min Yoo, Dongju Park, Jaewook Kang, Sang-Woo Lee, và Woomyoung Park. 2021. GPT3Mix: Tận dụng các mô hình ngôn ngữ quy mô lớn cho tăng cường văn bản. Trong Findings of the Association for Computational Linguistics: EMNLP 2021, trang 2225–2239, Punta Cana, Dominican Republic. Association for Computational Linguistics.

Adams Wei Yu, David Dohan, Minh-Thang Luong, Rui Zhao, Kai Chen, Mohammad Norouzi, và Quoc V Le. 2018. Qanet: Kết hợp convolution cục bộ với self-attention toàn cục cho hiểu đọc. arXiv preprint arXiv:1804.09541.

Yue Yu, Yuchen Zhuang, Jieyu Zhang, Yu Meng, Alexander Ratner, Ranjay Krishna, Jiaming Shen, và Chao Zhang. 2023. Mô hình ngôn ngữ lớn như bộ tạo dữ liệu huấn luyện có thuộc tính: Một câu chuyện về sự đa dạng và thiên vị. Trong Hội nghị lần thứ 37 về Hệ thống xử lý thông tin thần kinh Datasets and Benchmarks Track.

Honghua Zhang, Meihua Dang, Nanyun Peng, và Guy Van den Broeck. 2023. Kiểm soát có thể xử lý cho tạo sinh ngôn ngữ tự hồi quy. Trong Hội nghị quốc tế về Học máy, trang 40932–40945. PMLR.

Xiang Zhang, Junbo Zhao, và Yann LeCun. 2015. Mạng convolution cấp độ ký tự cho phân loại văn bản. Advances in neural information processing systems, 28.

Jing Zhou, Yanan Zheng, Jie Tang, Li Jian, và Zhilin Yang. 2022. FlipDA: Tăng cường dữ liệu hiệu quả và mạnh mẽ cho học few-shot. Trong Kỷ yếu Hội nghị thường niên lần thứ 60 của Association for Computational Linguistics (Tập 1: Bài báo dài), trang 8646–8665, Dublin, Ireland. Association for Computational Linguistics.

Ran Zhou, Xin Li, Ruidan He, Lidong Bing, Erik Cambria, Luo Si, và Chunyan Miao. 2021. Melm: Tăng cường dữ liệu với mô hình ngôn ngữ thực thể bị che cho ner tài nguyên thấp. arXiv preprint arXiv:2108.13655.

Wangchunshu Zhou, Yuchen Eleanor Jiang, Ethan Wilcox, Ryan Cotterell, và Mrinmaya Sachan. 2023. Tạo văn bản có kiểm soát với hướng dẫn ngôn ngữ tự nhiên. Trong Kỷ yếu Hội nghị quốc tế lần thứ 40 về Học máy, tập 202 của Kỷ yếu Nghiên cứu Học máy, trang 42602–42613. PMLR.

A Điều chỉnh siêu tham số

A.1 Ảnh hưởng của số vòng tăng cường R

Bảng 6 so sánh hiệu suất của CoDa với các giá trị khác nhau của R. Tăng cường tập dữ liệu huấn luyện với nhiều vòng tăng cường R tỏ ra hiệu quả cho đến khi mô hình overfit với dữ liệu huấn luyện. Quan sát này tương tự như công trình trước đây về tăng cường dữ liệu cho các nhiệm vụ NLU (Zhou et al., 2021; Ghosh et al., 2023c).

A.2 Lựa chọn LLM

Bảng 7 so sánh hiệu suất của CoDa sử dụng các LLM mã nguồn mở khác nhau. Ngoài LLaMa-13B được sử dụng trong bài báo của chúng tôi, chúng tôi cũng so sánh hiệu suất với Mistral-7B (Jiang et al., 2023) và LLaMa-7B. Như chúng ta thấy, sử dụng LLaMa-7B làm giảm hiệu suất cuối cùng 0,18%, trong khi sử dụng Mistral-7B làm giảm hiệu suất cuối cùng 1,44%. Chúng tôi cũng nhận thấy một số trường hợp ảo giác với Mistral-7B, nơi đầu ra của LLM hoàn toàn khác với hướng dẫn đã cho. Điều này không xảy ra với họ mô hình LLaMa, và hiệu suất thường cải thiện với mô hình lớn hơn do chất lượng sinh tạo tốt hơn và khả năng tuân theo hướng dẫn tốt hơn.

B Tính trung thực trong việc tuân theo các ràng buộc hướng dẫn

Bảng 8 minh họa độ chính xác của các tăng cường được tạo ra bởi LLaMa-13B trong việc tuân thủ các ràng buộc được chỉ định trong hướng dẫn. Chúng tôi chỉ minh họa độ chính xác của các ràng buộc từ vựng và độ dài vì chúng dễ dàng định lượng. Các ràng buộc khác yêu cầu đánh giá của con người, điều này vẫn là một phần của công việc tương lai. Chúng tôi báo cáo độ chính xác như thước đo trung thực của chúng tôi, trong đó chúng tôi coi một sinh tạo là chính xác cho ràng buộc nếu nó tuân theo hoàn toàn ràng buộc, nếu không thì không chính xác. Ngoài ra, chúng tôi cũng báo cáo ngưỡng 75% cho cả hai ràng buộc, theo đó chúng tôi coi sinh tạo là chính xác nếu nó tuân theo 75% ràng buộc (ví dụ: 75% tổng số từ khoá được đề cập có trong sinh tạo và tổng số token trong sinh tạo nằm giữa 75% của độ dài tối đa và tối thiểu). Mặc dù LLaMa-13B thể hiện khả năng vừa phải trong việc tuân thủ các ràng buộc, việc cải thiện dự kiến trong khả năng tuân theo hướng dẫn của LLM có thể sẽ nâng cao những thước đo này hơn nữa. Hơn nữa, việc CoDa vượt trội so với hiệu suất của nhiều mô hình hiện có trong tài liệu, mặc dù khả năng tuân theo ràng buộc vừa phải của nó, cho thấy một tiềm năng đáng kể cho CoDa như một sơ đồ tạo tăng cường khi tích hợp với các LLM tiên tiến hơn.

Một xu hướng quan sát được là các mô hình thể hiện hiệu suất mạnh trên các tập dữ liệu quen thuộc như CoNLL-2003, có thể do những tập dữ liệu này được bao gồm trong corpus huấn luyện trước của chúng. Ngoài ra, các mô hình của chúng tôi thể hiện hiệu suất được cải thiện dưới các ràng buộc ngưỡng 75%. Điều này cho thấy cần có sự cân bằng giữa đầu ra sáng tạo và tuân thủ ràng buộc trong các sinh tạo LLM. Mặc dù sự sáng tạo là quan trọng để tạo ra các tăng cường đa dạng, việc tuân theo ràng buộc là chìa khóa để duy trì tính nhất quán. Trong công việc tương lai, chúng tôi dự định điều tra các phương pháp hiệu quả hơn để cân bằng sự đánh đổi này.

C Chi tiết tập dữ liệu

C.1 Phân loại

HuffPost. Tập dữ liệu HuffPost (Misra và Grover, 2021) là một tập dữ liệu phân loại đa lớp phổ biến trong NLP. Đây là một tập hợp các bài báo tin tức từ trang web HuffPost, bao gồm một loạt các chủ đề, bao gồm chính trị, kinh doanh, giải trí, và nhiều hơn nữa. Đối với phân loại đa lớp, tập dữ liệu HuffPost được gắn nhãn với một tập hợp các thể loại đa dạng và cho các thí nghiệm của chúng tôi, chúng tôi lấy các câu từ năm thể loại, bao gồm chính trị, thể thao, giải trí, công nghệ và kinh doanh. Thống kê tập dữ liệu có thể được tìm thấy trong Bảng 9.

Yahoo. Tập dữ liệu phân loại chủ đề Yahoo Answers (Zhang et al., 2015) là một tập dữ liệu được sử dụng rộng rãi cho các nhiệm vụ phân loại văn bản đa lớp. Nó được bắt nguồn từ nền tảng hỏi đáp theo cộng đồng Yahoo Answers, nơi người dùng đặt câu hỏi về các chủ đề khác nhau, và các thành viên cộng đồng cung cấp câu trả lời. Tập dữ liệu chứa một số lượng lớn các cặp câu hỏi-trả lời bao gồm một loạt các thể loại hoặc chủ đề. Mỗi câu hỏi trong tập dữ liệu được liên kết với một thể loại chính. Các thể loại chính bao trùm các chủ đề đa dạng, bao gồm Xã hội & Văn hóa, Khoa học & Toán học, Sức khỏe, Giáo dục & Tham khảo, Máy tính & Internet, Thể thao, Kinh doanh & Tài chính, Giải trí & Âm nhạc, Gia đình & Các mối quan hệ, Chính trị & Chính phủ, Du lịch, Ô tô & Giao thông, Thực phẩm & Đồ uống, Trò chơi & Giải trí, Nhà cửa & Vườn, Doanh nghiệp địa phương, Tin tức & Sự kiện, Thú cưng, Làm đẹp & Phong cách và Thai kỳ & Nuôi dạy con cái. Thống kê tập dữ liệu có thể được tìm thấy trong Bảng 9.

OTS-UL. Điều khoản dịch vụ trực tuyến (OTS) (Drawzeski et al., 2021) cố gắng tự động phát hiện các điều khoản không công bằng trong Điều khoản dịch vụ. Đầu vào cho mô hình là một câu, và đầu ra trình bày câu được phân loại thành ba cấp độ không công bằng. Cài đặt tập dữ liệu được sử dụng trong bài báo của chúng tôi tương tự như (Niklaus et al., 2023). Thống kê tập dữ liệu có thể được tìm thấy trong Bảng 9.

C.2 Nhận dạng thực thể có tên

CoNLL-2003. Tập dữ liệu CoNLL-2003 (Tjong Kim Sang và De Meulder, 2003) là một tập dữ liệu benchmark được sử dụng rộng rãi cho các nhiệm vụ Nhận dạng thực thể có tên (NER) trong NLP. Nó được tạo ra cho nhiệm vụ chia sẻ Conference on Computational Natural Language Learning (CoNLL) vào năm 2003. Tập dữ liệu bao gồm các bài báo tin tức từ Reuters Corpus, một tập hợp các bài báo tin tức tiếng Anh. Nó được chú thích với bốn thực thể có tên: người, tổ chức, địa điểm và các thực thể khác (như ngày tháng và phần trăm). Các chú thích chỉ ra ranh giới của các thực thể có tên trong văn bản. Thống kê tập dữ liệu có thể được tìm thấy trong Bảng 9.

Ontonotes 5.0. Ontonotes 5.0 Pradhan et al. (2013) là một tập dữ liệu được sử dụng rộng rãi trong lĩnh vực Xử lý ngôn ngữ tự nhiên (NLP) và cụ thể cho các nhiệm vụ Nhận dạng thực thể có tên (NER). Đây là một corpus quy mô lớn cung cấp chú thích cho nhiều hiện tượng ngôn ngữ khác nhau, bao gồm các thực thể có tên, trên nhiều ngôn ngữ. Tập dữ liệu chứa một loạt các thể loại văn bản đa dạng, bao gồm các bài báo tin tức, dữ liệu hội thoại và dữ liệu web, làm cho nó phù hợp để huấn luyện và đánh giá các mô hình NER trong các domain khác nhau. Nó bao gồm ba ngôn ngữ: tiếng Anh, tiếng Trung và tiếng Ả Rập. Tập dữ liệu được chú thích với 11 thể loại: Người, Tổ chức, Địa điểm, Ngày, Thời gian, Tiền, Phần trăm, Số lượng, Thứ tự và Khác. Thống kê tập dữ liệu có thể được tìm thấy trong Bảng 9.

EBMNLP. EBMNLP Nye et al. (2018) là một tập dữ liệu được sử dụng rộng rãi trong lĩnh vực các nhiệm vụ Nhận dạng thực thể có tên y sinh (BioNER). Đây là một corpus gồm các bản tóm tắt các bài báo y khoa được chú thích phong phú bởi chuyên gia mô tả các thử nghiệm lâm sàng ngẫu nhiên có kiểm soát. Tập dữ liệu tạo điều kiện thuận lợi cho việc tìm kiếm và tổ chức dễ dàng tài liệu đã xuất bản về các thử nghiệm ngẫu nhiên có kiểm soát, giải quyết những thách thức hiện tại cản trở các mục tiêu của y học dựa trên bằng chứng (EBM). Tập dữ liệu được chú thích với 3 thể loại: Kết quả, Can thiệp và Người tham gia. Thống kê tập dữ liệu có thể được tìm thấy trong Bảng 9.

BC2GM. BC2GM Krallinger et al. (2015) là một tập dữ liệu được sử dụng rộng rãi trong lĩnh vực các nhiệm vụ Nhận dạng thực thể có tên y sinh (BioNER). Tập dữ liệu này là một phần của corpus quy mô lớn CHEMDNER bao gồm chú thích các thực thể hóa học cũng như các thực thể có tên trong các domain y sinh và khác. Tập dữ liệu được chú thích với 1 thể loại: Gen. Thống kê tập dữ liệu có thể được tìm thấy trong Bảng 9.

C.3 Phân loại ý định

ATIS. Tập dữ liệu ATIS (Airline Travel Information System) là một tập dữ liệu benchmark được sử dụng rộng rãi cho phân loại ý định trong lĩnh vực NLU. Nó được phát triển để giải quyết việc hiểu ý định của người dùng trong bối cảnh thông tin du lịch hàng không. Tập dữ liệu bao gồm các truy vấn hoặc phát ngôn mà người dùng có thể nhập khi tương tác với hệ thống đặt chỗ bay. Mỗi truy vấn được gắn nhãn với một ý định đại diện cho mục đích hoặc mục tiêu của người dùng đằng sau truy vấn. Tập dữ liệu được gắn nhãn với các ý định: Đặt chỗ bay, Trạng thái bay, Thông tin bay, Dịch vụ mặt đất, Giá vé, Thông tin sân bay, Sở thích du lịch, Hủy chuyến bay, và Không có/Không có ý định. Thống kê tập dữ liệu có thể được tìm thấy trong Bảng 9.

MASSIVE. Tập dữ liệu MASSIVE (Multilingual Amazon Slu resource package for Slot-filling) FitzGerald et al. (2022) là một tập dữ liệu benchmark được sử dụng rộng rãi cho phân loại ý định trong lĩnh vực NLU. Nó chứa 1M phát ngôn trợ lý ảo thực tế, song song, được gắn nhãn trải dài 51 ngôn ngữ, 18 domain, 60 ý định và 55 slot. Tập dữ liệu được gắn nhãn với các ý định, một số trong đó là: Đặt báo thức, Phát nhạc, Tắt tiếng âm thanh, Truy vấn thời tiết, Đặt hàng mang đi và Truyện cười chung, v.v. Thống kê tập dữ liệu có thể được tìm thấy trong Bảng 9.

C.4 Trả lời câu hỏi

SQUAD. SQUAD (Stanford Question Answering Dataset) (Rajpurkar et al., 2016) là một tập dữ liệu hiểu đọc, bao gồm các câu hỏi được đặt ra bởi những người làm việc đám đông trên một tập hợp các bài báo Wikipedia, nơi câu trả lời cho mỗi câu hỏi là một đoạn văn bản, hoặc khoảng, từ đoạn văn đọc tương ứng, hoặc câu hỏi có thể không thể trả lời được. Thống kê tập dữ liệu có thể được tìm thấy trong Bảng 9.

NEWSQA. NewsQA (News Question Answering) (Trischler et al., 2017) là một tập dữ liệu hiểu máy thách thức gồm hơn 100.000 cặp câu hỏi-trả lời được tạo ra bởi con người. Những người làm việc đám đông cung cấp câu hỏi và câu trả lời dựa trên một tập hợp hơn 10.000 bài báo tin tức từ CNN, với các câu trả lời bao gồm các khoảng văn bản từ các bài báo tương ứng. Thống kê tập dữ liệu có thể được tìm thấy trong Bảng 9.

D Chi tiết baseline

SSMBA. SSMBA (Ng et al., 2020) tạo ra các ví dụ huấn luyện tổng hợp bằng cách sử dụng một cặp hàm hỏng và tái tạo để di chuyển ngẫu nhiên trên một manifold dữ liệu.

AEDA. AEDA (Karimi et al., 2021) tương tự như EDA nhưng chỉ sử dụng việc chèn ngẫu nhiên các dấu câu trong văn bản gốc để tạo ra các tăng cường tổng hợp.

GENIUS. GENIUS (Guo et al., 2022), huấn luyện trước và tùy chọn tinh chỉnh BART (Lewis et al., 2019) trên một mục tiêu khử nhiễu sử dụng các phác thảo được tạo ra với thuật toán masking cực đoan. Thuật toán masking cực đoan chỉ giữ lại từ khoá trong một câu và che giấu mọi thứ khác.

MELM. MELM (Zhou et al., 2021), viết tắt của Masked Entity Language Modeling, đề xuất tinh chỉnh PLM dựa trên transformer-encoder trên các chuỗi được gắn nhãn tuyến tính thông qua mô hình ngôn ngữ có mặt nạ. Trong các tình huống tài nguyên thấp, MELM vượt trội so với tất cả các baseline khác và các kỹ thuật trước đây trên tập dữ liệu CoNLL 2003 NER trên bốn ngôn ngữ, bao gồm cài đặt đơn ngôn ngữ, đa ngôn ngữ và đa ngôn ngữ.

DAGA. DAGA (Ding et al., 2020), viết tắt của Data Augmentation with a Generation Approach, đề xuất huấn luyện một mô hình ngôn ngữ mạng thần kinh tái phát (RNNLM) dựa trên LSTM một lớp bằng cách tối đa hóa xác suất dự đoán token tiếp theo sử dụng các câu tuyến tính. Để sinh câu, họ sử dụng lấy mẫu ngẫu nhiên để tạo ra các câu hoàn toàn mới, với mô hình chỉ được cung cấp token [BOS].

LwTR. LwTR (Dai và Adel, 2020) thay thế một token trong câu bằng token khác có cùng nhãn; token được chọn ngẫu nhiên từ tập huấn luyện.

PromDA. PromDA (Wang et al., 2022) đề xuất một framework tăng cường dữ liệu dựa trên T5 huấn luyện các prompt mềm sử dụng thuật toán keyword-to-sentence mới.

AMR-DA. AMR-DA (Shou et al., 2022) chuyển đổi một tài liệu mẫu từ tập dữ liệu thành đồ thị AMR, sửa đổi đồ thị theo các chính sách tăng cường dữ liệu khác nhau, và sau đó tạo ra các tăng cường từ đồ thị. Phương pháp kết hợp cả kỹ thuật cấp câu như dịch ngược và kỹ thuật cấp token như EDA.

PromptMix. PromptMix (Sahu et al., 2023) PromptMix nhắc nhở các LLM được tinh chỉnh hướng dẫn để tạo ra các tăng cường cho các nhiệm vụ phân loại văn bản gần với ranh giới lớp.

ZeroGen. ZeroGen (Ye et al., 2022), tương tự như PromptMix, tạo ra dữ liệu sử dụng LLM nhưng theo cách zero-shot mà không có dữ liệu gold nào. Nó nhắc nhở các LLM được huấn luyện trước (không được tinh chỉnh hướng dẫn) để tổng hợp dữ liệu.

Chúng tôi không xem xét các baseline gần đây hơn được cung cấp bởi Cai et al. (2023), Hu et al. (2023) và Rahamim et al. (2023) vì mã cho chúng không có sẵn vào thời điểm viết bài báo. Ngoài ra, chúng tôi không xem xét Zhou et al. (2022) vì việc lật nhãn không áp dụng được cho bài báo của chúng tôi cho tất cả các nhiệm vụ được xem xét, và Chen et al. (2022) vì chuyển đổi phong cách phù hợp hơn cho các nhiệm vụ đa domain và việc áp dụng nó cho các nhiệm vụ domain đơn không đơn giản. Cuối cùng, chúng tôi không xem xét Yu et al. (2023) vì nó yêu cầu can thiệp thủ công của con người để trích xuất thuộc tính cho tập dữ liệu.

E Chi tiết bổ sung

E.1 Ví dụ về ràng buộc cú pháp trong các domain chính thức

Bảng 10 cung cấp các ví dụ về tài liệu từ các domain có ngôn ngữ chính thức, như pháp lý và y sinh. Mỗi ví dụ cung cấp hai tài liệu tương ứng với một chuỗi POS, nhấn mạnh rằng các ràng buộc cú pháp giúp tạo ra các tăng cường được căn chỉnh tốt hơn với domain trong các domain chính thức.

E.2 Ví dụ định tính

Hình 2, 3, 4 và 5 cung cấp các ví dụ định tính bổ sung về các tăng cường được tạo ra bằng CoDa và so sánh chúng với các baseline khác trong tài liệu. CoDa liên tục tạo ra các tăng cường đa dạng và nhất quán hơn so với các công trình trước đây.

F Chi tiết bổ sung

F.1 Tham số mô hình

BERT base có ≈110M 12 lớp encoder, 768-hidden-state, 2048 feed-forward hidden-state, và 8-heads. legal-longformer large có ≈149M 30 lớp encoder, 768-hidden-state, 3072 feed-forward hidden-state, và 12-heads. LLaMa-13B là mô hình 13B tham số và LLaMa-7B là mô hình 7B tham số.

F.2 Hạ tầng tính toán

Tất cả các thí nghiệm của chúng tôi được thực hiện trên GPU NVIDIA A100 và NVIDIA A6000. Chúng tôi nhắc nhở LLaMa-2 13B và LLaMa-2 7B theo batch với BS 16, trong đó LLaMa-2 thực hiện suy luận phân tán trên 4 GPU A6000. Tinh chỉnh trên các nhiệm vụ downstream sử dụng 4 GPU A100.

F.3 Phần mềm và gói thực hiện

Chúng tôi triển khai tất cả các mô hình của chúng tôi trong PyTorch và sử dụng các triển khai HuggingFace của BERT base, legal-longformer large, LLaMa-13B và LLaMa-7B. Cụ thể đối với NER, chúng tôi sử dụng thư viện Flair. Chúng tôi cũng sử dụng các repository sau để chạy các baseline: BackTrans (Yu et al., 2018), EDA (Wei và Zou, 2019), AEDA (Karimi et al., 2021), AMR-DA (Shou et al., 2022), SSMBA (Ng et al., 2020), GENIUS(-ft) (Guo et al., 2022), PromDA (Wang et al., 2022), PromptMix (Sahu et al., 2023), ZeroGen (Ye et al., 2022), GPT3Mix (Yoo et al., 2021), LwTR (Dai và Adel, 2020), DAGA (Ding et al., 2020) và MELM (Zhou et al., 2021). Tất cả các repository baseline đều được bao gồm dưới Giấy phép MIT.

F.4 Liên kết tập dữ liệu

Chúng tôi sử dụng các tập dữ liệu sau để đánh giá: Huffpost (Misra và Grover, 2021), Yahoo (Zhang et al., 2015), OTS (Drawzeski et al., 2021), Massive (FitzGerald et al., 2022), ATIS (Coucke et al., 2018), ConLL-2003 (Tjong Kim Sang và De Meulder, 2003), OntoNotes-5.0 (Pradhan et al., 2013), EBMNLP (Nye et al., 2018) và BC2GM (Krallinger et al., 2015), SQuAD (Rajpurkar et al., 2016) và NewsQA (Trischler et al., 2017). Tất cả các tập dữ liệu đã được phát hành dưới các giấy phép khác nhau cho mục đích nghiên cứu.

F.5 Rủi ro tiềm ẩn

Các mô hình khuếch tán học từ lượng lớn dữ liệu văn bản, bao gồm nội dung thiên vị hoặc định kiến có mặt trên internet. Kết quả là, có nguy cơ khuếch đại thiên vị, nơi các mô hình vô tình duy trì hoặc tăng cường các thiên vị hiện có. Ngoài ra, các mô hình khuếch tán có thể tạo ra văn bản rất coherent và hợp lý về mặt ngữ cảnh, làm dấy lên lo ngại về tiềm năng tạo ra thông tin sai lệch hoặc thông tin tiến hành gây nhầm lẫn.

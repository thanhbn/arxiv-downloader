# Nâng cao Tìm kiếm Đối thoại: Viết lại Truy vấn Thông tin với sự Hỗ trợ của Mô hình Ngôn ngữ Lớn

Fanghua Ye
University College London
fanghua.ye.19@ucl.ac.uk

Meng Fang
University of Liverpool
Meng.Fang@liverpool.ac.uk

Shenghui Li
Uppsala University
shenghui.li@it.uu.se

Emine Yilmaz
University College London
emine.yilmaz@ucl.ac.uk

## Tóm tắt
Viết lại truy vấn đóng vai trò quan trọng trong việc nâng cao tìm kiếm đối thoại bằng cách chuyển đổi các truy vấn người dùng phụ thuộc ngữ cảnh thành các dạng độc lập. Các phương pháp hiện có chủ yếu tận dụng các truy vấn được viết lại bởi con người làm nhãn để huấn luyện mô hình viết lại truy vấn. Tuy nhiên, các bản viết lại của con người có thể thiếu thông tin đầy đủ cho hiệu suất truy xuất tối ưu. Để vượt qua hạn chế này, chúng tôi đề xuất sử dụng các mô hình ngôn ngữ lớn (LLM) làm công cụ viết lại truy vấn, cho phép tạo ra các bản viết lại truy vấn thông tin thông qua các hướng dẫn được thiết kế tốt. Chúng tôi xác định bốn thuộc tính cần thiết cho các bản viết lại được định hình tốt và tích hợp tất cả chúng vào hướng dẫn. Ngoài ra, chúng tôi giới thiệu vai trò của trình chỉnh sửa viết lại cho LLM khi các bản viết lại truy vấn ban đầu có sẵn, hình thành quy trình "viết lại-rồi-chỉnh sửa". Hơn nữa, chúng tôi đề xuất chưng cất khả năng viết lại của LLM vào các mô hình nhỏ hơn để giảm độ trễ viết lại. Đánh giá thực nghiệm của chúng tôi trên bộ dữ liệu QReCC cho thấy các bản viết lại truy vấn thông tin có thể mang lại hiệu suất truy xuất cải thiện đáng kể so với các bản viết lại của con người, đặc biệt với các bộ truy xuất thưa thớt.

## 1 Giới thiệu
Tìm kiếm đối thoại đã đạt được sự nổi bật đáng kể trong những năm gần đây với sự phát triển mạnh mẽ của các trợ lý ảo kỹ thuật số và chatbot, cho phép người dùng tham gia vào nhiều vòng tương tác để thu thập thông tin (Radlinski và Craswell, 2017; Dalton et al., 2021; Gao et al., 2023). Mô hình tìm kiếm mới nổi này mang lại lợi thế đáng kể trong việc hỗ trợ người dùng với các nhu cầu thông tin phức tạp và các tác vụ phức tạp (Yu et al., 2021). Tuy nhiên, một thách thức cơ bản trong tìm kiếm đối thoại nằm ở việc xác định chính xác ý định tìm kiếm hiện tại của người dùng trong ngữ cảnh đối thoại.

Một phương pháp hiệu quả đã thu hút sự chú ý ngày càng tăng giải quyết thách thức này của việc mô hình hóa ngữ cảnh đối thoại bằng cách thực hiện viết lại truy vấn (Elgohary et al., 2019; Yu et al., 2020; Vakulenko et al., 2021; Wu et al., 2022; Mo et al., 2023). Phương pháp này chuyển đổi các truy vấn người dùng phụ thuộc ngữ cảnh thành các truy vấn độc lập, qua đó cho phép sử dụng các bộ truy xuất có sẵn hiện có đã được xác thực rộng rãi cho các truy vấn độc lập. Ví dụ, truy vấn người dùng "Cô ấy có làm tốt không?" được minh họa trong Hình 1 có thể được viết lại thành "Elizabeth Blackwell có làm tốt với tư cách là một giảng viên hộ sinh không?" điều này không phụ thuộc ngữ cảnh.

Các nghiên cứu trước đây (Anantha et al., 2021; Vakulenko et al., 2021; Qian và Dou, 2022; Hao et al., 2022) chủ yếu phụ thuộc vào các truy vấn được viết lại bởi con người làm nhãn giám sát để huấn luyện mô hình viết lại truy vấn. Mặc dù các truy vấn được viết lại bởi con người có xu hướng hoạt động tốt hơn so với các truy vấn gốc, chúng có thể không đủ thông tin cho hiệu suất truy xuất tối ưu (Chen et al., 2022; Wu et al., 2022). Hạn chế này xuất phát từ thực tế rằng những người viết lại của con người chỉ quan tâm đến việc giải quyết các vấn đề mơ hồ, như tham chiếu đồng nghĩa và bỏ sót, khi chuyển đổi truy vấn gốc thành dạng độc lập. Một chiến lược viết lại đơn giản như vậy có thể bỏ qua nhiều thông tin có giá trị trong ngữ cảnh đối thoại (tham khảo Hình 1 để xem ví dụ), điều này có tiềm năng nâng cao hiệu quả của bộ truy xuất. Kết quả là, các mô hình viết lại truy vấn hiện có được học từ các bản viết lại của con người chỉ có thể đạt được hiệu suất dưới tối ưu.

Một phương pháp đơn giản để cải thiện tính thông tin của các truy vấn được viết lại là cung cấp cho những người chú thích con người các hướng dẫn toàn diện hơn để họ có thể viết lại các truy vấn gốc không chỉ rõ ràng mà còn có thông tin. Tuy nhiên, phương pháp này có một số nhược điểm, bao gồm tốn kém, tăng khối lượng công việc cho những người chú thích con người, và có thể dẫn đến sự không nhất quán cao hơn giữa các bản viết lại từ những người chú thích khác nhau. Do đó, cần thiết phải khám phá các phương pháp thay thế.

Trong bài báo này, chúng tôi đề xuất sử dụng các mô hình ngôn ngữ lớn (LLM) để viết lại truy vấn, tận dụng khả năng ấn tượng của chúng trong việc tuân theo hướng dẫn và minh chứng (Brown et al., 2020; Wei et al., 2021; Ouyang et al., 2022; Wei et al., 2023). Chúng tôi xem xét hai thiết lập để nhắc LLM làm công cụ viết lại truy vấn. Trong thiết lập học không-shot, chỉ cung cấp một hướng dẫn, trong khi trong thiết lập học vài-shot, cả hướng dẫn và vài minh chứng đều được đưa ra. Để phát triển hướng dẫn phù hợp, chúng tôi đầu tiên xác định bốn thuộc tính cần thiết đặc trưng cho một truy vấn được viết lại được định hình tốt. Sau đó, chúng tôi thiết kế một hướng dẫn tích hợp cả bốn thuộc tính. Tuy nhiên, tạo ra các bản viết lại với tất cả những thuộc tính này có thể tạo ra thách thức cho LLM do tính phức tạp của hướng dẫn (Ouyang et al., 2022; Jang et al., 2023). Xem xét điều này, chúng tôi đề xuất một vai trò bổ sung cho LLM làm trình chỉnh sửa viết lại. Lấy cảm hứng từ thực tế rằng con người giỏi chỉnh sửa hơn là tạo ra từ đầu, mục đích của trình chỉnh sửa viết lại là chỉnh sửa các bản viết lại ban đầu được cung cấp, hình thành quy trình "viết lại-rồi-chỉnh sửa". Những bản viết lại ban đầu này có thể được tạo ra bởi các mô hình viết lại truy vấn nhỏ hơn hoặc thậm chí bởi chính LLM. Hơn nữa, xem xét chi phí thời gian tiềm năng và chi phí cao liên quan đến LLM, chúng tôi đề xuất chưng cất khả năng viết lại của chúng vào các mô hình nhỏ hơn sử dụng các bản viết lại được tạo ra bởi chúng làm nhãn huấn luyện.

Những đóng góp của chúng tôi được tóm tắt như sau:
• Chúng tôi là những người đầu tiên giới thiệu khái niệm viết lại truy vấn đối thoại có thông tin và kỹ lưỡng xác định bốn thuộc tính mong muốn mà một truy vấn được viết lại được chế tác tốt nên có.
• Chúng tôi đề xuất nhắc LLM làm cả công cụ viết lại truy vấn và trình chỉnh sửa viết lại bằng cách cung cấp hướng dẫn rõ ràng tích hợp tất cả các thuộc tính mong muốn. Ngoài ra, chúng tôi sử dụng kỹ thuật chưng cất để nén khả năng viết lại của LLM vào các mô hình nhỏ hơn để cải thiện hiệu quả viết lại.
• Chúng tôi chứng minh hiệu quả của viết lại truy vấn có thông tin với hai bộ truy xuất có sẵn (thưa thớt và dày đặc) trên bộ dữ liệu QReCC. Kết quả của chúng tôi cho thấy các bản viết lại truy vấn có thông tin có thể vượt trội so với các bản viết lại của con người, đặc biệt trong bối cảnh truy xuất thưa thớt.

## 2 Công thức hóa Tác vụ
Mục tiêu chính của tìm kiếm đối thoại là xác định các đoạn văn có liên quan từ một bộ sưu tập đoạn văn rộng lớn để đáp ứng truy vấn người dùng hiện tại. Chính thức, cho Qi và Ai là truy vấn người dùng và phản hồi hệ thống tại lượt i, tương ứng. Hơn nữa, cho Xt={Q1, A1, . . . , Qt−1, At−1} đại diện cho ngữ cảnh đối thoại đến lượt t. Sau đó, tác vụ của tìm kiếm đối thoại có thể được công thức hóa là truy xuất top-k đoạn văn có liên quan, được ký hiệu là Rk, từ một bộ sưu tập đoạn văn lớn C với truy vấn người dùng hiện tại Qt và ngữ cảnh liên quan Xt. Quá trình truy xuất này được thực hiện bởi một bộ truy xuất được định nghĩa là f: (Qt,Xt,C) → Rk, trong đó Rk là một tập con của C và k nhỏ hơn đáng kể so với tổng số đoạn văn trong C.

Thách thức độc đáo trong tìm kiếm đối thoại là tích hợp ngữ cảnh đối thoại trong khi truy xuất các đoạn văn có liên quan, điều này không thể được giải quyết trực tiếp bởi các bộ truy xuất hiện có được thiết kế cho các truy vấn độc lập. Ngoài ra, việc đào tạo lại các bộ truy xuất phù hợp cho các truy vấn đối thoại có thể tốn kém hoặc thậm chí không khả thi do thiết kế hệ thống phức tạp hoặc tính khả dụng dữ liệu hạn chế (Wu et al., 2022). Để vượt qua nhu cầu đào tạo lại, viết lại truy vấn được sử dụng như một giải pháp hiệu quả (Lin et al., 2021c; Mo et al., 2023). Viết lại truy vấn liên quan đến việc chuyển đổi truy vấn người dùng phụ thuộc ngữ cảnh Qt thành một truy vấn độc lập tự chứa Q't bằng cách trích xuất thông tin có liên quan từ ngữ cảnh Xt. Do đó, bất kỳ hệ thống truy xuất có sẵn hiện có nào được thiết kế cho các truy vấn độc lập có thể được tận dụng bằng cách lấy Q't làm truy vấn đầu vào để tìm các đoạn văn có liên quan đến truy vấn người dùng gốc Qt, tức là, f: (Q't,C) → Rk.

Việc sử dụng viết lại truy vấn chuyển thách thức mô hình hóa ngữ cảnh đối thoại từ phía bộ truy xuất sang phía mô hình viết lại truy vấn. Do đó, hiệu quả của kết quả truy xuất phụ thuộc rất nhiều vào các mô hình viết lại truy vấn được sử dụng. Chỉ khi các truy vấn được viết lại phù hợp được tạo ra, một hệ thống truy xuất có sẵn mới có thể trả về các đoạn văn có liên quan cao.

## 3 Phương pháp
Trái ngược với việc dựa vào những người chú thích con người để tạo ra các bản viết lại thông tin hơn hoặc phát triển các mô hình phức tạp hơn để sao chép chặt chẽ các bản viết lại của con người hiện có, chúng tôi đề xuất nhắc LLM để tạo ra các bản viết lại truy vấn thông tin đơn giản bằng cách cung cấp hướng dẫn rõ ràng và minh chứng phù hợp, tránh yêu cầu nỗ lực con người rộng rãi và thiết kế mô hình phức tạp. Hình 2 minh họa phương pháp được đề xuất của chúng tôi.

### 3.1 Nhắc LLM làm Công cụ Viết lại Truy vấn
Công trình gần đây (Wei et al., 2021; Ouyang et al., 2022; Peng et al., 2023) đã chứng minh khả năng mạnh mẽ của LLM trong việc tuân theo hướng dẫn đã cho để tạo ra văn bản mạch lạc và phù hợp với ngữ cảnh. Lấy cảm hứng từ điều này, việc xem xét sử dụng LLM làm công cụ viết lại truy vấn là tự nhiên. Trước khi đi sâu vào chi tiết về cách chúng ta có thể nhắc một LLM làm công cụ viết lại truy vấn, chúng tôi đầu tiên mô tả các thuộc tính mong muốn mà một truy vấn được viết lại được chế tác tốt nên có:

• Tính chính xác: Truy vấn được viết lại nên bảo tồn ý nghĩa của truy vấn gốc, đảm bảo rằng ý định của người dùng vẫn không thay đổi.
• Tính rõ ràng: Truy vấn được viết lại nên không mơ hồ và độc lập với ngữ cảnh đối thoại, cho phép nó có thể được hiểu bởi những người ngoài ngữ cảnh đối thoại. Tính rõ ràng này có thể đạt được bằng cách giải quyết các vấn đề tham chiếu đồng nghĩa và bỏ sót phát sinh trong truy vấn gốc.
• Tính thông tin: Truy vấn được viết lại nên tích hợp càng nhiều thông tin có giá trị và có liên quan từ ngữ cảnh đối thoại càng tốt, qua đó cung cấp thông tin hữu ích hơn cho bộ truy xuất có sẵn.
• Tính không dư thừa: Truy vấn được viết lại nên tránh nhân bản bất kỳ truy vấn nào đã được đưa ra trước đó trong ngữ cảnh đối thoại, vì điều quan trọng là đảm bảo rằng truy vấn được viết lại chỉ truyền đạt ý định và ý nghĩa của truy vấn hiện tại.

Để hướng dẫn hiệu quả một LLM trong việc tạo ra các bản viết lại truy vấn thể hiện bốn thuộc tính nêu trên, việc công thức hóa hướng dẫn phù hợp là cần thiết. Như một ví dụ minh họa, chúng tôi áp dụng hướng dẫn sau trong công trình này:

"Cho một câu hỏi và ngữ cảnh của nó, khử ngữ cảnh hóa câu hỏi bằng cách giải quyết các vấn đề tham chiếu đồng nghĩa và bỏ sót. Câu hỏi kết quả nên giữ nguyên ý nghĩa gốc và có thông tin nhiều nhất có thể, và không nên nhân bản bất kỳ câu hỏi nào đã được hỏi trước đó trong ngữ cảnh."

Hướng dẫn này xem xét đồng thời cả bốn thuộc tính mong muốn của một truy vấn được viết lại tốt. Dựa trên hướng dẫn này, chúng tôi khám phá hai thiết lập để nhắc một LLM để viết lại truy vấn.

#### 3.1.1 Thiết lập Học Không-Shot (ZSL)
Trong thiết lập ZSL, LLM được hướng dẫn tạo ra một truy vấn được viết lại Q't chỉ sử dụng thông tin được cung cấp bởi truy vấn hiện tại Qt và ngữ cảnh đối thoại liên quan Xt, mà không có quyền truy cập vào bất kỳ trường hợp được gán nhãn bởi con người nào. Trong thiết lập này, chúng tôi hoàn toàn dựa vào khả năng của LLM để hiểu và tuân theo hướng dẫn để thực hiện viết lại truy vấn. Cụ thể, chúng tôi nối Xt và Qt vào hướng dẫn I như nhắc và đưa nhắc này vào LLM để lấy mẫu bản viết lại Q't:

Q't ∼ LLM(I||Xt||Qt), (1)

trong đó || biểu thị nối. Định dạng chi tiết của nhắc được hiển thị trong Phụ lục D.

#### 3.1.2 Thiết lập Học Vài-Shot (FSL)
Trong thiết lập FSL, LLM được cung cấp cả hướng dẫn và một số lượng nhỏ minh chứng. Loại nhắc này thường được gọi là học trong ngữ cảnh, đã được chứng minh là hiệu quả trong việc thích ứng LLM với các tác vụ mới (Brown et al., 2020; Min et al., 2022a,b; Wei et al., 2023; Sun et al., 2023; Ram et al., 2023). Trong thiết lập này, mỗi minh chứng bao gồm một truy vấn Q, một ngữ cảnh đối thoại X, và một bản viết lại Q'. Chúng tôi ký hiệu việc nối các minh chứng này là:

D = (X1, Q1, Q'1)||...||(Xn, Qn, Q'n), (2)

trong đó n đại diện cho tổng số minh chứng. Bằng cách đặt D giữa hướng dẫn I và trường hợp thử nghiệm (Xt, Qt) như nhắc cho LLM, bản viết lại Q't sau đó được lấy mẫu như sau:

Q't ∼ LLM(I||D||Xt||Qt). (3)

Lưu ý rằng các bản viết lại truy vấn được sử dụng trong các minh chứng nên được thiết kế tốt, đảm bảo rằng chúng có bốn thuộc tính nêu trên. Nếu không, LLM có thể bị dẫn lệch bởi những minh chứng này. Để mô tả chi tiết hơn về các minh chứng được sử dụng trong thí nghiệm của chúng tôi, vui lòng tham khảo Phụ lục D.

### 3.2 Nhắc LLM làm Trình Chỉnh sửa Viết lại
Mặc dù LLM thành thạo trong việc tuân theo hướng dẫn và minh chứng, công trình gần đây (Dong et al., 2022; Liu et al., 2022; Mosbach et al., 2023) cho thấy chúng có thể gặp khó khăn khi đối mặt với các tác vụ phức tạp hoặc yêu cầu phức tạp. Hạn chế này làm nổi bật rằng có thể thách thức đối với LLM để tạo ra các bản viết lại truy vấn với tất cả các thuộc tính mong muốn đã đề cập ở trên. Để giải quyết thách thức này, chúng tôi đề xuất một phương pháp thay thế trong đó một LLM được nhắc làm trình chỉnh sửa viết lại có chức năng chính là chỉnh sửa các bản viết lại ban đầu được cung cấp thay vì được nhắc làm công cụ viết lại truy vấn cần tạo ra các bản viết lại truy vấn từ đầu. Phương pháp này lấy cảm hứng từ quan sát rằng con người thường thấy dễ dàng hơn khi chỉnh sửa nội dung hiện có hơn là tạo ra nó từ đầu.

Trong công trình này, chúng tôi áp dụng thiết lập FSL để nhắc LLM làm trình chỉnh sửa viết lại. Ngoài truy vấn Q, ngữ cảnh đối thoại X, và bản viết lại Q', chúng tôi giới thiệu một bản viết lại ban đầu Q̂ cho mỗi minh chứng. Chúng tôi biểu diễn việc nối các minh chứng được tăng cường này là:

D̃ = (X1, Q1, Q̂1, Q'1)||...||(Xn, Qn, Q̂n, Q'n). (4)

Đối với một trường hợp thử nghiệm (Xt, Qt), cùng với một bản viết lại ban đầu Q̂t, chúng tôi có được bản viết lại đã chỉnh sửa (cuối cùng) Q't thông qua quy trình sau:

Q't ∼ LLM(Ĩ||D̃||Xt||Qt||Q̂t), (5)

trong đó Ĩ biểu thị hướng dẫn đã sửa đổi. Vui lòng tham khảo Hình 2 và Phụ lục D để biết chi tiết.

Bản viết lại ban đầu có thể được tạo ra bởi một mô hình viết lại truy vấn nhỏ, như T5QR (Lin et al., 2020; Wu et al., 2022). Nó cũng có thể được tạo ra bởi một LLM, theo phương pháp nhắc được mô tả trong tiểu mục trước. Khi một LLM được sử dụng làm cả công cụ viết lại truy vấn và trình chỉnh sửa viết lại, quy trình "viết lại-rồi-chỉnh sửa" cho phép LLM thực hiện tự sửa lỗi (Gou et al., 2023).

### 3.3 Chưng cất: LLM làm Giáo viên Viết lại
Một trở ngại chính trong việc tận dụng hiệu quả LLM để viết lại truy vấn là nhu cầu đáng kể về bộ nhớ và tài nguyên tính toán (Hsieh et al., 2023), điều này có thể dẫn đến chi phí thời gian đáng kể. Bên cạnh đó, chi phí có thể cực kỳ cao khi thiếu các mô hình nội bộ, đòi hỏi sự phụ thuộc vào các dịch vụ API bên thứ ba như lựa chọn duy nhất. Để giải quyết những vấn đề này, chúng tôi đề xuất tinh chỉnh một mô hình viết lại truy vấn nhỏ sử dụng các bản viết lại được tạo ra bởi LLM làm nhãn thực tế. Trong phương pháp này, LLM đảm nhận vai trò của một giáo viên, trong khi mô hình viết lại truy vấn nhỏ hơn đóng vai trò là học sinh. Quá trình tinh chỉnh chưng cất khả năng viết lại của giáo viên vào học sinh. Kỹ thuật này được gọi là chưng cất kiến thức (Gou et al., 2021) và gần đây đã được sử dụng để chưng cất LLM cho nhiều tác vụ khác (Shridhar et al., 2022; Magister et al., 2022; Marjieh et al., 2023).

Theo công trình trước đây (Lin et al., 2020; Wu et al., 2022), chúng tôi áp dụng T5 (Raffel et al., 2020) làm mô hình học sinh (tức là, mô hình viết lại truy vấn nhỏ). Đầu vào của mô hình là việc nối tất cả các phát ngôn trong ngữ cảnh đối thoại Xt và truy vấn người dùng hiện tại Qt. Để phân biệt giữa các truy vấn người dùng và phản hồi hệ thống, chúng tôi thêm vào đầu một token đặc biệt <Que> cho mỗi truy vấn người dùng và một token đặc biệt <Ans> cho mỗi phản hồi hệ thống. Đầu ra của mô hình là bản viết lại Q't, được lấy mẫu từ LLM được sử dụng. Mô hình được tinh chỉnh sử dụng loss cross-entropy chuẩn để tối đa hóa khả năng tạo ra Q't.

## 4 Thiết lập Thí nghiệm

### 4.1 Bộ dữ liệu & Thước đo Đánh giá
Theo công trình trước đây (Wu et al., 2022; Mo et al., 2023), chúng tôi tận dụng QReCC (Anantha et al., 2021) làm bộ dữ liệu thí nghiệm. QReCC bao gồm 14K cuộc hội thoại miền mở bằng tiếng Anh với tổng cộng 80K cặp câu hỏi-trả lời. Mỗi câu hỏi người dùng được đi kèm với một truy vấn được viết lại bởi con người, và các câu trả lời cho các câu hỏi trong cùng một cuộc hội thoại có thể được phân bố trên nhiều trang web. Có tổng cộng 10M trang web với mỗi trang được chia thành nhiều đoạn văn, dẫn đến một bộ sưu tập 54M đoạn văn. Tác vụ của tìm kiếm đối thoại là tìm các đoạn văn có liên quan cho mỗi câu hỏi từ bộ sưu tập lớn này và các nhãn đoạn văn vàng được cung cấp nếu có. Các cuộc hội thoại trong QReCC được lấy từ ba bộ dữ liệu hiện có, bao gồm QuAC (Choi et al., 2018), Natural Questions (Kwiatkowski et al., 2019), và TREC CAsT-19 (Dalton et al., 2020). Để dễ phân biệt, chúng tôi gọi những tập con này là QuAC-Conv, NQ-Conv, và TREC-Conv, tương ứng. Lưu ý rằng TREC-Conv chỉ xuất hiện trong tập thử nghiệm. Để đánh giá toàn diện, chúng tôi trình bày kết quả thí nghiệm không chỉ trên toàn bộ bộ dữ liệu mà còn trên từng tập con. Để biết thông tin bổ sung và thống kê về bộ dữ liệu, vui lòng tham khảo Phụ lục A.

Để đánh giá kết quả truy xuất, chúng tôi áp dụng thứ hạng đảo ngược trung bình (MRR), độ chính xác trung bình (MAP), và Recall@10 (R@10) làm thước đo đánh giá. Chúng tôi sử dụng bộ công cụ pytrec_eval (Van Gysel và de Rijke, 2018) để tính toán tất cả các giá trị thước đo.

### 4.2 Phương pháp So sánh
Vì trọng tâm của chúng tôi là hiệu quả của các bản viết lại truy vấn thông tin, hai phương pháp cơ sở đơn giản là Original, sử dụng câu hỏi người dùng ở dạng gốc làm truy vấn tìm kiếm, và Human, sử dụng truy vấn được viết lại bởi con người làm truy vấn tìm kiếm. Chúng tôi cũng bao gồm ba mô hình có giám sát làm cơ sở, bao gồm T5QR (Lin et al., 2020), tinh chỉnh mô hình T5-base (Raffel et al., 2020) làm công cụ viết lại truy vấn seq2seq, ConQRR (Wu et al., 2022), sử dụng học tăng cường để huấn luyện mô hình viết lại truy vấn bằng cách tối ưu hóa trực tiếp hiệu suất truy xuất, và ConvGQR (Mo et al., 2023), kết hợp viết lại truy vấn với tạo ra câu trả lời tiềm năng để cải thiện tính thông tin của truy vấn tìm kiếm.

Đối với phương pháp được đề xuất của chúng tôi, chúng tôi điều tra bốn biến thể, cụ thể là RW(ZSL), RW(FSL), ED(Self), và ED(T5QR). RW(ZSL) nhắc một LLM làm công cụ viết lại truy vấn trong thiết lập ZSL, trong khi RW(FSL) nhắc một LLM làm công cụ viết lại truy vấn trong thiết lập FSL. So sánh, ED(Self) nhắc một LLM làm trình chỉnh sửa viết lại, trong đó các bản viết lại ban đầu được tạo ra bởi RW(FSL) với cùng LLM được áp dụng. ED(T5QR) cũng nhắc một LLM làm trình chỉnh sửa viết lại, nhưng các bản viết lại ban đầu được tạo ra bởi T5QR. Để đơn giản, chúng tôi chỉ nhắc LLM làm trình chỉnh sửa viết lại trong thiết lập FSL.

### 4.3 Hệ thống Truy xuất
Chúng tôi thí nghiệm với hai loại bộ truy xuất có sẵn để khám phá tác động của tính thông tin trong các bản viết lại truy vấn lên tìm kiếm đối thoại:

BM25 BM25 (Robertson et al., 2009) là một bộ truy xuất thưa thớt cổ điển. Theo Anantha et al. (2021), chúng tôi sử dụng Pyserini (Lin et al., 2021a) với các siêu tham số k1 = 0.82 và b = 0.68.

GTR GTR (Ni et al., 2022) là một bộ truy xuất dày đặc được đề xuất gần đây. Nó có kiến trúc bộ mã hóa kép được chia sẻ và đạt hiệu suất tối tân trên nhiều điểm chuẩn truy xuất.

### 4.4 Chi tiết Triển khai
Chúng tôi áp dụng ChatGPT (gpt-3.5-turbo) được cung cấp bởi OpenAI thông qua API chính thức của họ làm LLM trong thí nghiệm. Trong quá trình suy luận, chúng tôi sử dụng giải mã tham lam với nhiệt độ 0. Trong thiết lập FSL, chúng tôi sử dụng bốn minh chứng (tức là, n = 4). Chúng tôi sử dụng Pyserini (Lin et al., 2021a) để truy xuất thưa thớt và Faiss (Johnson et al., 2019) để truy xuất dày đặc. Đối với mỗi truy vấn người dùng, chúng tôi truy xuất 100 đoạn văn (tức là, k = 100). Chúng tôi bỏ qua các trường hợp thử nghiệm không có nhãn đoạn văn vàng hợp lệ. Kết quả là, chúng tôi có tổng cộng 8209 trường hợp thử nghiệm, với 6396, 1442, và 371 trường hợp thử nghiệm cho QuAC-Conv, NQ-Conv, và TREC-Conv, tương ứng. Để biết thêm chi tiết triển khai, vui lòng tham khảo Phụ lục B.

## 5 Kết quả Thí nghiệm

### 5.1 Kết quả Chính
Bảng 1 trình bày hiệu suất truy xuất của các phương pháp viết lại truy vấn khác nhau trên tập thử nghiệm QReCC và các tập con của nó. Các phát hiện chính của chúng tôi được tóm tắt như sau. (I) Tất cả các phương pháp viết lại truy vấn đều vượt trội so với truy vấn gốc, xác nhận tầm quan trọng của viết lại truy vấn. (II) Các phương pháp của chúng tôi, ED(Self) và ED(T5QR), liên tục đạt được kết quả tốt nhất và tốt thứ hai trên toàn bộ tập thử nghiệm QReCC. Đáng chú ý, cả hai đều vượt trội so với các bản viết lại của con người. Ví dụ, ED(Self) chứng minh sự cải thiện tuyệt đối đáng kể là 9.58 trong điểm MRR cho truy xuất thưa thớt so với các bản viết lại của con người. RW(FSL) cũng hoạt động tốt hơn so với các bản viết lại của con người, trong khi RW(ZSL) không thể hiện sự cải thiện nhất quán so với các bản viết lại của con người. Những kết quả này nhấn mạnh giá trị của viết lại truy vấn thông tin và các minh chứng trong ngữ cảnh. (III) Các mô hình có giám sát, T5QR và ConQRR, thể hiện hiệu suất kém hơn so với các bản viết lại của con người, cho thấy rằng chỉ dựa vào học từ các bản viết lại của con người dẫn đến kết quả dưới tối ưu. Mặc dù ConvGQR đánh bại các bản viết lại của con người trong truy xuất thưa thớt, lợi ích hiệu suất của nó chủ yếu xuất phát từ các câu trả lời tiềm năng được tạo ra hơn là các bản viết lại truy vấn thông tin hơn. (IV) Cải thiện truy xuất dày đặc ít hiệu quả hơn so với truy xuất thưa thớt. Ví dụ, ED(Self) chỉ vượt trội so với các bản viết lại của con người 1.84 điểm MRR khi sử dụng bộ truy xuất dày đặc GTR. Sự khác biệt này xuất phát từ nhu cầu về các bộ mã hóa đoạn văn và truy vấn cụ thể cho miền trong truy xuất dày đặc. Trong thí nghiệm của chúng tôi, mô hình GTR được giữ cố định mà không tinh chỉnh, điều này hạn chế tiềm năng đầy đủ của truy xuất dày đặc. Bên cạnh đó, ConvGQR cũng cho thấy hiệu suất truy xuất dày đặc kém hơn, chỉ ra thêm rằng một bộ truy xuất dày đặc tổng quát cố định không thể chứng minh đầy đủ sự vượt trội của các bản viết lại truy vấn thông tin. (V) Phân tích kết quả theo tập con cho thấy các phương pháp được đề xuất của chúng tôi có thể liên tục đạt hiệu suất cao hơn trên tập con QuAC-Conv. Chúng cũng chiếm ưu thế về MRR và MAP cho truy xuất thưa thớt và đạt kết quả tốt thứ hai cho truy xuất dày đặc trên tập con NQ-Conv. Tuy nhiên, các phương pháp của chúng tôi kém hơn so với các bản viết lại của con người và T5QR trên tập con TREC-Conv. Một lý do là TREC-Conv chứa nhiều câu hỏi tối nghĩa, khiến việc LLM hiểu chính xác nhu cầu thực sự của người dùng trở nên thách thức. Có thể thấy rằng ngay cả các bản viết lại của con người cũng hoạt động kém hơn trên TREC-Conv so với QuAC-Conv và NQ-Conv trong truy xuất thưa thớt. Ngoài ra, các câu hỏi trong TREC-Conv tự chứa nhiều hơn và đòi hỏi ít viết lại hơn, như được chứng minh bởi điểm ROUGE-1 cao hơn (Lin, 2004) giữa các bản viết lại của con người và câu hỏi gốc so với QuAC-Conv và NQ-Conv. Cụ thể, điểm ROUGE-1 trên TREC-Conv, QuAC-Conv, và NQ-Conv lần lượt là 80.60, 69.73, và 72.16. (VI) Cả ED(Self) và ED(T5QR) đều vượt trội so với RW(FSL), cho thấy tầm quan trọng của việc nhắc LLM làm trình chỉnh sửa viết lại. Trong khi ED(T5QR) hoạt động kém hơn ED(Self) trên toàn bộ tập thử nghiệm QReCC, nó xuất sắc trên các tập con NQ-Conv và TREC-Conv, hưởng lợi từ thực tế rằng T5QR được huấn luyện với các bản viết lại của con người.

Tóm lại, nghiên cứu này xác nhận tầm quan trọng của viết lại truy vấn thông tin và hiệu quả của các phương pháp được đề xuất của chúng tôi về việc nhắc LLM làm công cụ viết lại truy vấn và trình chỉnh sửa viết lại. Nghiên cứu cũng cho thấy rằng việc xem xét đặc điểm truy vấn vào tài khoản khi thực hiện viết lại truy vấn với LLM là rất quan trọng, điều mà chúng tôi để lại như công việc tương lai.

### 5.2 Phân tích Định lượng về Bản viết lại Truy vấn
Kết quả trước đây đã chứng minh hiệu quả của các bản viết lại truy vấn thông tin được tạo ra bởi các phương pháp được đề xuất của chúng tôi trong việc nâng cao tìm kiếm đối thoại. Để có thêm hiểu biết về chất lượng của những bản viết lại này, chúng tôi sử dụng số lượng token trung bình trên mỗi bản viết lại như một thước đo tính thông tin và tỷ lệ phần trăm token trong các bản viết lại của con người cũng xuất hiện trong các bản viết lại được tạo ra như một thước đo tính chính xác. Chúng tôi giả định rằng một bản viết lại chứa nhiều token hơn từ bản viết lại của con người tương ứng có khả năng chính xác hơn. Kết quả được hiển thị trong Bảng 2. Chúng tôi quan sát thấy các phương pháp được đề xuất của chúng tôi liên tục tạo ra các bản viết lại dài hơn so với các bản viết lại của con người, với ED(Self) tạo ra các bản viết lại dài nhất tổng thể. Điều này ngụ ý rằng các bản viết lại được tạo ra bởi các phương pháp được đề xuất của chúng tôi có thông tin hơn. Chúng tôi cũng quan sát thấy T5QR tạo ra các bản viết lại ngắn hơn so với các bản viết lại của con người, chỉ ra rằng chỉ dựa vào học từ các bản viết lại của con người không thể tạo ra các bản viết lại thông tin. Hơn nữa, các phương pháp được đề xuất của chúng tôi, mặc dù không có tinh chỉnh có giám sát, đạt được độ chính xác tương đối cao so với các bản viết lại của con người. Ví dụ, hơn 76% token trong các bản viết lại của con người được bao gồm trong các bản viết lại được tạo ra bởi ED(Self). ED(T5QR) thậm chí thể hiện độ chính xác cao hơn T5QR trên các tập con QuAC-Conv và NQ-Conv. Cuối cùng, các bản viết lại dài hơn và tỷ lệ phần trăm token được chia sẻ cao hơn với các bản viết lại của con người (trừ RW trên TREC-Conv), so với các truy vấn gốc, cho thấy một phần nào đó rằng các bản viết lại được tạo ra bởi phương pháp của chúng tôi có độ rõ ràng hợp lý.

### 5.3 Nghiên cứu Loại bỏ
Chúng tôi tiến hành một nghiên cứu loại bỏ bằng cách loại bỏ yêu cầu tính thông tin khỏi hướng dẫn được sử dụng bởi RW(ZSL) (tức là, loại bỏ cụm từ "và có thông tin nhiều nhất có thể"), dẫn đến một phiên bản được sửa đổi được ký hiệu là dRW(ZSL). Bảng 3 báo cáo kết quả. Chúng tôi thấy rằng đối với cả truy xuất thưa thớt và dày đặc, dRW(ZSL) đạt hiệu suất thấp hơn trên tất cả ba thước đo đánh giá so với RW(ZSL), chứng minh rằng việc tích hợp yêu cầu tính thông tin vào hướng dẫn để tạo ra các bản viết lại truy vấn thông tin là có giá trị. Thú vị, dRW(ZSL) vượt trội so với các bản viết lại của con người về MRR và MAP cho truy xuất thưa thớt, điều này một lần nữa xác minh khái niệm rằng các bản viết lại của con người có thể không mang lại hiệu suất truy xuất tối ưu. Xem Phụ lục C.3 cho kết quả loại bỏ của ba thuộc tính mong muốn khác.

### 5.4 Kết quả Chưng cất
Hình 3 cho thấy kết quả chưng cất sử dụng BM25 làm bộ truy xuất. Trong nghiên cứu này, chúng tôi lấy mẫu 10K trường hợp huấn luyện và sử dụng RW(FSL) và ED(Self) để tạo ra nhãn cho việc tinh chỉnh mô hình T5QR. Để so sánh, chúng tôi bao gồm kết quả với các bản viết lại của con người làm nhãn huấn luyện. Chúng tôi thấy rằng chưng cất vượt trội so với việc sử dụng các bản viết lại của con người làm nhãn trên tập thử nghiệm QReCC. Đáng chú ý, chưng cất chỉ với 10K trường hợp huấn luyện có thể đạt kết quả vượt trội so với việc sử dụng trực tiếp các bản viết lại của con người làm truy vấn tìm kiếm về MRR và MAP. Trên các tập con QuAC-Conv và NQ-Conv, chưng cất cũng liên tục chứng minh hiệu suất cải thiện. Tuy nhiên, đối với TREC-Conv, tinh chỉnh với các bản viết lại của con người dẫn đến kết quả tốt hơn. Chưng cất không chỉ cải thiện hiệu suất truy xuất mà còn giảm chi phí thời gian. Xem Phụ lục C.4 cho phân tích độ trễ.

## 6 Công trình Liên quan
Tìm kiếm đối thoại giải quyết nhu cầu thông tin của người dùng thông qua các tương tác lặp lại (Radlinski và Craswell, 2017; Rosset et al., 2020). Nó cho phép người dùng cung cấp và tìm kiếm làm rõ (Xu et al., 2019) và khám phá nhiều khía cạnh của một chủ đề, qua đó xuất sắc trong việc thực hiện các nhu cầu thông tin phức tạp. Thách thức chính trong tìm kiếm đối thoại là xác định chính xác ý định tìm kiếm của người dùng từ các truy vấn có ngữ cảnh và có thể mơ hồ của họ (Ye et al., 2022a; Keyvan và Huang, 2022; Ye et al., 2022b; Wang et al., 2023; Owoicho et al., 2023; Zhu et al., 2023).

Hầu hết công trình hiện có (Yu et al., 2021; Lin et al., 2021b; Kim và Kim, 2022; Li et al., 2022a; Mao et al., 2022) giải quyết thách thức này bằng cách coi việc nối truy vấn người dùng hiện tại với ngữ cảnh đối thoại liên quan như một truy vấn độc lập. Tuy nhiên, sử dụng việc nối này trực tiếp làm đầu vào cho các hệ thống tìm kiếm có thể dẫn đến hiệu suất truy xuất kém (Lin et al., 2021b). Hơn nữa, phương pháp này đòi hỏi huấn luyện các bộ truy xuất chuyên biệt như bộ mã hóa kép (Karpukhin et al., 2020; Xiong et al., 2020; Khattab và Zaharia, 2020), điều này có thể thách thức hoặc thậm chí không thực tế trong nhiều tình huống thực tế (Wu et al., 2022).

Một hướng nghiên cứu khác giải quyết thách thức này thông qua viết lại truy vấn (Elgohary et al., 2019; Wu et al., 2022; Qian và Dou, 2022; Yuan et al., 2022; Li et al., 2022b; Mo et al., 2023), chuyển đổi truy vấn gốc thành một truy vấn độc lập. Tuy nhiên, những phương pháp này chủ yếu dựa vào các bản viết lại của con người để huấn luyện mô hình viết lại truy vấn. Như đã chỉ ra trong thí nghiệm của chúng tôi, các bản viết lại của con người có thể thiếu tính thông tin đầy đủ, do đó dẫn đến hiệu suất dưới tối ưu của các mô hình viết lại này.

Một cách khác, một số nghiên cứu sử dụng mở rộng truy vấn để giải quyết thách thức này. Họ chọn các thuật ngữ có liên quan từ ngữ cảnh đối thoại (Voskarides et al., 2020; Kumar và Callan, 2020) hoặc tạo ra các câu trả lời tiềm năng (Mo et al., 2023) để tăng cường truy vấn gốc. Cái sau có thể được tích hợp một cách mượt mà vào phương pháp của chúng tôi để tận dụng kiến thức trong LLM. Chúng tôi để lại nghiên cứu này như công việc tương lai.

## 7 Kết luận
Trong công trình này, chúng tôi đề xuất nhắc LLM làm công cụ viết lại truy vấn và trình chỉnh sửa viết lại để tạo ra bản viết lại truy vấn thông tin. Chúng tôi là những người đầu tiên giới thiệu khái niệm viết lại truy vấn thông tin và xác định bốn thuộc tính đặc trưng cho một bản viết lại được định hình tốt. Chúng tôi cũng đề xuất chưng cất khả năng viết lại của LLM vào các mô hình nhỏ hơn để cải thiện hiệu quả. Thí nghiệm của chúng tôi xác minh tầm quan trọng của tính thông tin trong các bản viết lại truy vấn và hiệu quả của việc sử dụng LLM để tạo ra các bản viết lại.

Mặc dù hiệu suất xuất sắc đạt được bởi phương pháp được đề xuất của chúng tôi, có nhiều hướng tương lai xứng đáng khám phá. Ví dụ, chúng ta có thể huấn luyện một mô hình phụ trợ để quyết định liệu các truy vấn được tạo ra bởi việc nhắc LLM có nên được ưu tiên hơn so với những truy vấn được tạo ra bởi các mô hình đã được tinh chỉnh trên các bản viết lại của con người hay không. Chúng ta cũng có thể kết hợp các bản viết lại của con người và LLM làm nhãn thông qua một chiến lược trọng số phù hợp để tinh chỉnh các mô hình viết lại truy vấn. Hơn nữa, trong công trình này, chúng tôi đã sử dụng một tập hợp minh chứng cố định cho tất cả các truy vấn thử nghiệm. Để đạt được hiệu suất tốt nhất, việc tìm các minh chứng phù hợp cho từng truy vấn cụ thể là cần thiết. Đây sẽ là một giải pháp hiệu quả để giải quyết các truy vấn tối nghĩa hoặc phức tạp. Một hướng tương lai khác có thể là tinh chỉnh hiệu quả tham số (ví dụ, LoRA (Hu et al., 2021)) của LLM với phản hồi hiệu suất truy xuất. Bằng cách này, chúng tôi sẽ nhắm đến tối ưu hóa tính hữu ích của các truy vấn được viết lại hơn là tính thông tin.

## Hạn chế
Chúng tôi xác định ba hạn chế của phương pháp được đề xuất của chúng tôi. Thứ nhất, việc sử dụng LLM làm công cụ viết lại truy vấn và trình chỉnh sửa viết lại không tránh khỏi những nhược điểm liên quan đến LLM. Thí nghiệm của chúng tôi chỉ ra rằng LLM không phải lúc nào cũng tuân theo hướng dẫn được cung cấp, dẫn đến các bản viết lại được tạo ra không có được bốn thuộc tính mong muốn. Ví dụ, những bản viết lại này có thể chứa các câu hỏi trùng lặp từ ngữ cảnh đối thoại, qua đó vi phạm yêu cầu không dư thừa. Trong Phụ lục C.5, chúng tôi trình bày một nghiên cứu trường hợp chứng minh rằng truy vấn người dùng gốc thậm chí có thể bị hiểu sai, dẫn đến các bản viết lại truy vấn không chính xác. Thứ hai, mặc dù kết quả thí nghiệm của chúng tôi đã chứng minh hiệu suất truy xuất cải thiện, cần nhấn mạnh rằng hiệu quả của viết lại truy vấn thông tin phụ thuộc rất nhiều vào định dạng của bộ sưu tập đoạn văn. Trong các tình huống mà các đoạn văn tương đối ngắn, việc đưa thêm thông tin vào truy vấn tìm kiếm có thể có tác động có hại, vì việc xác định các đoạn văn có liên quan nhất trở nên thách thức hơn đối với các hệ thống truy xuất. Ngược lại, viết lại truy vấn thông tin nên chứng minh lợi ích trong bối cảnh các đoạn văn dài hoặc truy xuất tài liệu. Thứ ba, trong công trình này, chúng tôi chỉ thí nghiệm với một LLM, cụ thể là ChatGPT, và do đó các phát hiện của chúng tôi có thể thiên vị đối với mô hình cụ thể này. Không rõ liệu các LLM khác có thể đạt được cùng mức hiệu suất hay không. Điều tra sâu hơn với nhiều LLM hơn là xứng đáng.

## Tuyên bố Đạo đức
Viết lại truy vấn đóng vai trò quan trọng như một quá trình trung gian trong tìm kiếm đối thoại, tạo điều kiện cho việc hiểu rõ ràng hơn về ý định tìm kiếm của người dùng. Quá trình này có lợi trong việc tạo ra các phản hồi phù hợp cho người dùng. Hiệu quả của phương pháp này có thể được nâng cao hơn nữa thông qua viết lại truy vấn thông tin, dẫn đến việc truy xuất các đoạn văn có liên quan hơn. Tuy nhiên, quan trọng là phải thừa nhận rằng các phương pháp được đề xuất của chúng tôi chịu những hạn chế vốn có của LLM, như ảo giác, thiên vị, và độc hại. Cũng quan trọng là lọc ra các đoạn văn có chứa văn bản công kích từ bộ sưu tập đoạn văn để đảm bảo kết quả truy xuất đáng tin cậy khi áp dụng các phương pháp được đề xuất của chúng tôi trong các tình huống thực tế.

## Lời cảm ơn
Công trình này được tài trợ bởi Học bổng EPSRC có tựa đề "Task Based Information Retrieval" (số tham chiếu tài trợ EP/P024289/1) và Viện Alan Turing.

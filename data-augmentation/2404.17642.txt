# 2404.17642.pdf
# Converted from PDF to TXT
# Source path: /home/admin88/arxiv-downloader/data-augmentation/2404.17642.pdf
# File size: 932392 bytes

===============================================
PDF FILE CONTENT
===============================================


--- PAGE 1 ---
Empowering Large Language Models for Textual Data Augmentation
Yichuan Li1‚àó, Kaize Ding2‚àó, Jianling Wang3, Kyumin Lee1
1Worcester Polytechnic Institute,2Northwestern University3Google DeepMind
{yli29,kmlee}@wpi.edu ,kaize.ding@northwestern.edu ,jianlingw@google.com
Abstract
Withthecapabilitiesofunderstandingandex-
ecuting natural language instructions, Large
language models (LLMs) can potentially act as
a powerful tool for textual data augmentation.
However, the quality of augmented data de-
pends heavily on the augmentation instructions
provided, and the effectiveness can fluctuate
across different downstream tasks. While man-
ually crafting and selecting instructions can
offer some improvement, this approach faces
scalability and consistency issues in practice
duetothediversityofdownstreamtasks. Inthis
work, we address these limitations by propos-
ing a new solution, which can automatically
generatealargepoolofaugmentationinstruc-
tionsand selectthemostsuitabletask-informed
instructions, thereby empowering LLMs to cre-
ate high-quality augmented data for different
downstream tasks. Empirically, the proposed
approachconsistentlygeneratesaugmenteddata
withbetterqualitycomparedtonon-LLMand
LLM-baseddataaugmentationmethods,lead-
ing to the best performance on 26 few-shot
learning tasks sourced from a wide range of
application domains.
1 Introduction
Large language models (LLMs) have recently
demonstrated their potential in performing data
augmentation on text data (Dai et al., 2023; Chung
et al., 2023; Yu et al., 2023; Yoo et al., 2021).
Serving as a semantic-preserving transformation
function,LLMstransformoriginaltextsbasedon
instructionsto creatediverseand informativedata
augmentations. Withtheaugmenteddata,userscan
furthertrainaspreadableandaffordablemodel(e.g.
OPT(Zhang et al., 2022)) to perform specific tasks.
Unlike traditional heuristic-based methods such as
word swapping (Wei and Zou, 2019) and model-
basedmethodslikeback-translation(Fadaeeetal.,
*The first two authors contributed equally to this work.
Kaize Ding is the corresponding author.
How many revolutions does the moon make around our planetduring spring?HowmanyrevolutionsdoesthemoonmakearoundtheEarthduringspring?Question Answering: OpenBookQA
Improvement of clarity.Pronoun Replace
sentence1:Herputtforbirdiewasthreefeetshortbutshesavedparwithoutdifficulty.[SEP]sentence2:Sheleavesherbirdieputtsomethreefeetshortbutdropsherparputt.sentence1:Hisputtforbirdiewasthreefeetshortbuthesavedparwithoutdifficulty.[SEP]sentence2Sheleavesherbirdieputtsomethreefeetshortbutdropsherparputt.Text Entailment: GLUE-RTEInconsistent pronouns sub.
Pronoun Replace
Figure 1: A simple demo of pronouns replacement
augmentationinstructionontextentailmenttask: GLUE-
MRPC(Wang et al., 2019) and question answering task:
OpenBookQA (Mihaylov et al., 2018).
2017), LLMs offer great potential to produce more
fluent, diverse, and semantically consistent aug-
mentations for text data, owing to their great under-
standing and generalization capabilities.
DespitetheearlysuccessofLLMsfortextualdata
augmentation,existingmethods(Daietal.,2023)
that simply prompt LLMs with human-crafted aug-
mentationinstructions(i.e., Manual-LLMDA meth-
ods) have the following major bottlenecks: (1)
Firstly, their efficacy heavily relies on the quality
of the augmentation instructions, which are man-
uallyengineeredbydomainexperts. Thismanual
process is not only domain knowledge-intensive
butalsopronetoinconsistencies,potentiallycom-
promising the quality of augmented data. Subtle
variations in how these instructions are formulated
cansignificantlyinfluencetheoutcomes,asdemon-
stratedbyrecentstudies(Ishibashietal.,2023;Zhu
et al., 2023); (2) Secondly, usually text augmen-
tation instructions are written in a task-agnostic
form for a general purpose, however, the lack of
context information on downstream tasks could
lead to dramatic performance disparity on different
downstream tasks, as shown in Fig. 1. Without
considering the specific properties of the target
tasks, LLM may generate low-quality augmented
data (Ribeiro et al., 2020; Wei and Zou, 2019).arXiv:2404.17642v1  [cs.CL]  26 Apr 2024

--- PAGE 2 ---
To address the aforementioned challenges, in
this paper, we introduce a new framework ‚Äì
Self-LLMDA that automates augmentation instruc-
tiongenerationandselection,facilitatingLLMto
generatetask-specificaugmenteddata. Theinitial
phase of Self-LLMDA aims to broaden the span
of seed augmentation strategies through the gen-
erationofdiverseandeffectiveinstructionsbased
on LLMs. Following this, Self-LLMDA employs
a scoring model to identify and select the most
relevant instructions that are likely to bolster the
performance of target models. Such a new tex-
tual data augmentation approach ensures a balance
between the generative breadth of augmentation
instructionsandtargetedprecisionoftask-specific
guidance for downstream tasks.
Inourstudy,weconductextensiveexperiments
across a large collection of few-shot learning tasks
used in previous studies (Min et al., 2022; Ye et al.,
2021; Khashabi et al., 2020). This collection in-
cludes26differenttypesoftasksacrosshatespeech
detection, question answering, natural language
inference, and phrase detection datasets. Our study
standsoutforitsextensivecoverageoftasks,setting
a new benchmark in the application of LLMs for
textual data augmentation when compared to previ-
ouswork(Daietal.,2023;Lietal.,2023;Chung
et al., 2023). The empirical results demonstrate
that the proposed approach Self-LLMDA signifi-
cantly outperforms various baseline methods in
generatinghigh-qualityaugmentedtextualdata. To
summarize, our main contributions are as follows:
‚Ä¢Weintroduceaframework Self-LLMDA ,which
automates the generation and selection of task-
specificaugmentationinstructionsforLLMs,pro-
viding effective data augmentation for text data.
‚Ä¢Through a comprehensive set of experiments,
we validate the effectiveness of Self-LLMDA ,
demonstrating its superior performance in en-
hancing data quality and model accuracy over
existing text data augmentation methods.
‚Ä¢Our in-depth analyses reveal that Self-LLMDA
can well generalize across various target models
andpreviouslyunseenaugmentationinstructions,
demonstrating its versatility and potential for
broad applicability.
2 Related Work
2.1 Non-LLM Textual Data Augmentation
Conventional textual data augmentation methods
encompassavarietyoftechniquesaimedatenhanc-ing the diversity of textual datasets without relying
on large language models (i.e., Non-LLMDA meth-
ods). Thosemethodsrangefromsimpleheuristic-
based methods to generative model-based methods.
Forheuristic-basedapproaches,suchassynonym
replacement (Zhang et al., 2016) and word shuf-
fling, stand out for their computational efficiency
and simplicity, making them ideal for large-scale
data augmentation with minimal computational de-
mands. Another notable example is the Easy Data
Augmentation (EDA) technique introduced by Wei
and Zou (2019), which employs token-level per-
turbations‚Äîrandom insertion, deletion, and swap-
ping‚Äîtoimproveperformanceacrossaspectrum
of text classification tasks.
For model-based approaches, researchers have
employed seq2seq and language models for data
augmentation. Back-translation (Fadaee et al.,
2017) employs translation models to preserve
semantic integrity while generating paraphrases
(Fadaee et al., 2017). Conditional masked lan-
guagemodelslike BERT(Devlinetal., 2018)and
RoBERTa (Liu et al., 2019) can also be utilized for
data augmentation (Cheng et al., 2022; Wu et al.,
2018). By masking words within sentences and
subsequently generatingreplacements, thesemod-
els introduce linguistic variations. Furthermore,
other methods (Kumar et al., 2021;Edwards et al.,
2023) leverage the capabilities of generative lan-
guagemodelslikeGPT-2(Radfordetal.,2019)and
BART(Lewisetal.,2019)fordataaugmentation.
Theseapproachesperformconditionalgeneration
based on class labels. Additionally, some studies
have explored augmentation in the feature space.
Mixuptechniquesinterpolatewithinwordorsen-
tenceembeddings(Guoetal.,2019),whileothers
introduce random multiplicative and additive noise
to the feature vectors (Kurata et al., 2016). Despite
theirutility, these conventional Non-LLMDA meth-
odsoftencomewithlimitationsinreadabilityand
contextual consistency.
2.2 LLM-based Textual Data Augmentation
Recent advancements in LLMs have demonstrated
theirsuperiorityingeneratinghighqualityandcon-
textually relevant augmented data (Brown et al.,
2020). LLMs are increasingly employed as label-
preservingtransformationfunctions,whereanorig-
inalexampleistransformedorperturbedaccording
to manually crafted instructions (Dai et al., 2023;
Yoo et al., 2021; Piedboeuf and Langlais, 2023).

--- PAGE 3 ---
2Task-Informed Instruction Selection (¬ß4.2).Self-Generated Aug. Ins. ‚Ä¢Sentiment flipping‚Ä¶‚Ä¢Pronouns Replace‚Ä¶‚Ä¢Style Transfer‚Ä¶‚Ä¢Text expansion‚Ä¶‚Ä¢Sentence split‚Ä¶‚Ä¢Negation insert‚Ä¶‚Ä¶1Augmentation Instruction Self-Generation(¬ß4.1).
Meta Prompt‚Ä¶ generate new aug.methods based on examples ‚Ä¶Seed Aug. Ins.ùíúseed‚Ä¢Synonym Replace‚Ä¶‚Ä¢Back Translation‚Ä¶‚Ä¶ 3LLMfor Data Augmentation.Selection Model: ùëÜRank&SelectOptimal Aug. Ins. ùë∞‚àóTask Data ùê∑Task Data ùíü
Optimal Aug. Ins. ùë∞‚àóAug. Data ùíü‚Ä≤Self-Generated Aug. Ins. IIFigure2: Thepipelineof Self-LLMDA .WefirstprompttheLLMtogenerateadiversesetofcandidateaugmentation
instructions(¬ß4.1). Thenweselecttheinstruction(¬ß4.2)andapplyitwiththetaskdatatoLLMtogetaugmentations.
Concurrently,severalstudies(Chungetal.,2023;
Yuetal.,2023;Lietal.,2023;Ubanietal.,2023;
Meng et al., 2022) have explored the generation of
conceptuallysimilaryetsemanticallydistinctsyn-
theticexamples. Thesemethods,however,mostly
rely on manualinstruction design. In contrast, our
work automatically generates label-preserving aug-
mentation instructions by prompting LLMs, thus
reducingdependencyonmanuallycrafted instruc-
tions. Furthermore, we introduce an instruction
selection model that chooses appropriate instruc-
tions for arbitrary downstream tasks.
3 Preliminary
ProblemDefinition. Textualdataaugmentation
involves applying a label-preserving transforma-
tion function T(¬∑)to a dataset D={(xi,yi)}k
i=1,
whereeachexampleconsistsofaninputtext xi(a
sequenceoftokens)andacorrespondinglabel yi
(alsoasequenceoftokens). Theaugmenteddataset
D‚Ä≤is generated as follows, ensuring that the output
labely‚Ä≤
iremains unchanged:
x‚Ä≤
i=T(xi),y‚Ä≤
i=yi. (1)
A target model Fis then trained on the union of
the original and augmented datasets, D ‚à™ D‚Ä≤, with
the training objective defined as:
L(ÀÜxi,ÀÜyi)‚ààD‚à™D‚Ä≤(FŒ∏(ÀÜxi),ÀÜyi). (2)
Therefore, designing an effective transformation
function T(¬∑)thatproduceshigh-qualityaugmented
dataD‚Ä≤is crucial for improving the downstream
performance of model FŒ∏.
Manual-LLMDA .For Manual-LLMDA methods,
thetransformationfunction T(¬∑)isrealizedthrough
a combination of an LLM and a manual-crafted
instruction Iman(e.g.,paraphrasing). TheLLMis
prompted to generate semantic-preserving trans-
formations of the input text xifor the augmenteddataset D‚Ä≤:
x‚Ä≤
i=LLM (Iman,xi),y‚Ä≤
i=yi(3)
4 Proposed Approach ‚Äì Self-LLMDA
Toreducethehumaneffortsindesigningaugmen-
tationinstructionsandselectingatask-specificin-
structionforagiventask,wepropose Self-LLMDA
depictedinFig.2. TheprocessbeginswiththeLLM
generating a diverse set of potential instructions
I={Ij}n
j=0fromagivensetofseedinstructions
Iseed={Iman}:
I=LLM (Iseed). (4)
A selection model Sthen scores these generated
instructions against the dataset Dto identify the
most suitable instruction I‚àó:
I‚àó=S(I,D). (5)
Based on the selected instruction I‚àó, the LLM
performs data augmentation on D, producing an
enhanced augmented dataset D‚Ä≤for training the
target model more effectively.
4.1AugmentationInstructionSelf-Generation
Inspired by the self-instruct methodology (Wang
et al., 2022), this phase generates augmentation
instructions from a seed set of 13 human-crafted
instructions. Theseseedinstructionsactasexem-
plars, guiding the LLMs toward the creation of
novel and diverse instructions that maintain the
semanticintegrityoftheinputtext. Togeneratea
broad and diverse set of augmentation instructions
withoutthebiasintroducedbyafewtaskexamples,
weexcludethetask-specificdatafromtheinstruc-
tion generation. This will leverage the zero-shot
learning capabilities of LLMs to produce a wide
array of potential augmentation instructions. We
use the following prompt to encourage LLMs to
explore various augmentation techniques:

--- PAGE 4 ---
Selection Model EncoderSelectionModelDecoderUnnormalized logits‚Ä¶yeswhoamùëû!‚Ä¶‚Ä¶{ùíô"} "#$%ùêà!‚Ä¶Ranking score
‚Ä¶ùëû$ùëû&ùëû'argmaxùêà‚àóTest Perf.ùëü"‚Ä¶ùëü#ùëü$ùêπ%ùíü!"ùíüùíü#$%#min ‚Ñí!OptimizationInferenceFigure3: IllustrationoftheInstructionselectionscoring
model. FŒ∏is the target model.
‚ÄúCome up with a series of textual data aug-
mentation methods and you need to generate
more diversedata augmentation method that
cankeep the semantic meaning of the input
sentence. {Iseed}‚Äù
Throughiterativecyclesofgenerationandrefine-
ment,wefilteroutinstructionsthataretoosimilarto
existingonesbasedonROUGE-L(Lin,2004). The
unique generated instructions from each iteration
arethenincorporatedbackintotheseedinstruction
pool,enrichingtheseedinstructionsforsubsequent
generationrounds. Thisprocessisrepeateduntilwe
reachacollectionof100augmentationinstructions.
Toensurediversityandeliminateredundancy,we
furtherrefinethissetbyremovingduplicatesbased
ontheirmethodnames. Thisfiltrationresultsina
final set of 51 unique augmentation instructions.
4.2 Task-Informed Instruction Selection
Recognizing that augmentation instructions may
not be universally applicable across different tasks,
we implement a selection mechanism, tailored to
the specific requirements of each task and its cor-
responding target model. This process involves a
scoring model Sto evaluatethe suitability of each
instruction for the task at hand. The scoring model
S, as shown in Fig. 3, outputs a ranking score
qjindicatingtheinstruction‚Äôseffectivenessbased
on the pair of instruction and task dataset. Based
on the notable instruction-following capabilities of
FLAN-T5 (Chung et al., 2022; Raffel et al., 2023),
we choose FLAN-T5-Large (Chung et al., 2022;
Raffeletal.,2023)asthebackboneofourscoring
model. The input for scoring model Sis:‚ÄúGiventhedatasetfor taskTandtheinstruction
data,determineifthisisasuitableinstruction
to address the task for model F.Task Dataset:
{xi}m
i=0Instruction: Ij. Is this instruction
appropriate? ‚Äù
where Tis the task name (e.g. GLUE-RTE), F
isthetargetmodelname(e.g. OPT-125m). Since
most of the tasks did not have a task description
and manually designing the task description is
timeconsuming,weutilizethefew-shotexamples
{xi}m
i=0from the dataset as the task description.
Here, we calculate qjby assessing the logit value
of the ‚Äúyes‚Äù token of the last position of input from
FLAN-T5-Large, as shown in Fig. 3. Next, we will
introducetheoptimizationandinferenceprocedure
of the scoring model Srespectively.
ModelOptimization. Theinstructionselection
modelistrainedtoprioritizegeneratedaugmenta-
tion instructions based on their impact on down-
stream task performance. Its goal is to assign
the highest scores to instructions that lead to the
most effective data augmentation. To enhance scal-
ability and computational efficiency, our model
optimizestheselectionprocessforagiventask D
by samplinga subset ofaugmentation instructions
{Ij}n
j=0(where n > 1) from the pool of candi-
dates. The model then computes scores {qj}n
j=0,
representing the relative effectiveness of each in-
struction. The optimization objective is formulated
asacross-entropyloss,designedtoaccuratelydistin-
guishbetweentheeffectivenessoftheseinstructions
{Ij}n
j=0. The loss function is given by:
LS=‚àínX
j=0is_max (rj) logœÉ(qj)(6)
Here,is_maxserves as a binary indicator function
thatidentifiestheinstructionyieldingthemaximum
effectiveness,and œÉissoftmax thatnormalizesthe
qj(aprobabilitygenerating‚Äúyes‚Äùtokeninterpreted
asa rankingscoreassociated with jthinstruction)
overthesampledaugmentationinstructions, rjis
thedownstreamtaskperformanceofatrainedtarget
model on augmented data D‚Ä≤
j‚à™ D.
ModelInference. Whenencounteringanewtask,
theselectionmodel Sevaluatesallpotentialinstruc-
tionstodeterminethemostsuitableone I‚àó,denoted
by the highest score:
I‚àó=Iargmax ({qj}|I|
j=0)(7)

--- PAGE 5 ---
This optimal instruction, I‚àó, is then employed to
prompttheLLMstogenerateaugmenteddata. This
selection mechanism ensure the use of the most
effectiveinstructionforenhancingdatautilityacross
diverse NLP tasks.
5 Experiment
5.1 Experimental Setup
EvaluationDatasets. Inthis study,weselect 26
few-shot learning tasks spanning a wide range of
NLPchallenges,sourcedfromCrossFit(Yeetal.,
2021), UnifiedQA (Khashabi et al., 2020), and
MetaICL (Min et al., 2022). These datasets were
chosen for their diversity, encompassing both clas-
sificationtasks(Class)‚Äîsuchasnaturallanguage
inference, paraphrase detection, and hate speech
identification‚Äîand non-classification (Non-Class)
tasks,notablyquestionanswering,toensureabroad
evaluationspectrum. Theselectionoftasksissig-
nificantlylargerandmorediversethanthatinother
relevantworks(Daietal.,2023;Chungetal.,2023).
To investigate the generalization ability of
Self-LLMDA , we split the 26 tasks into training
and test tasks as for form ‚Äútrain ‚Üítest‚Äù. We train
the augmentation instruction selection methods on
trainingtasksandevaluateditontesttasks. Thetask
split involves four settings: Class ‚ÜíClass, Class
‚ÜíNon-Class,Non-Class ‚ÜíClass,andRandom ‚Üí
Random, where ‚ÄúRandom‚Äù represents a mixture
of randomly selected tasks*. This design allows
us to investigate the performance of selection mod-
elswhenappliedacrosssimilaranddisparatetask
types, providing insights into their generalizability
and effectiveness.
Evaluation Metrics. To handle all types of tasks
simultaneously, we unify all downstream tasks,
includingclassificationandnon-classificationtasks,
using a text-to-text approach (Raffel et al., 2023).
For each task, we feed the input text to the target
model FŒ∏andtrainittogeneratethecorresponding
targettext. Wechoose OPT(Zhangetal.,2022)from
threedifferentsizes(e.g. 125m,350mand1.3b*)as
ourtargetmodels FŒ∏. Duringtraining*,FŒ∏takesthe
trainingexample xiastheinput,andisoptimisedto
*Details of training and testing tasks split is in Tab. 9.
*Due to GPU memory constraints, the training mini batch
sizeforthe1.3Bmodelissetto2,whilethebatchsizesforthe
125M and 350M models are set to 8. This difference in batch
sizesmaycausethe1.3Bmodeltoachieveworseperformance
compared to the 125M and 350M models.
*Detailed hyparameter setting is in Appendix A.generate yiusing the negative likelihood objective
function:
LFŒ∏(yi) =‚àí|yi|X
t=1logPFŒ∏(yt
i|xi,y<t
i)(8)
During inference time, given the test input xtestas
well as a set of candidates C, which is either a set
of labels (in classification tasks) or answer options
(in non-classification tasks), the FŒ∏computes the
conditionalprobability ofeachlabel c‚àà C,where
cis a sequence of tokens. The label with the
maximumconditionalprobabilityisreturnedasa
prediction:
argmaxc‚ààCÔ£´
Ô£≠|c|X
t=1logPFŒ∏(ct|xtext,c<t)Ô£∂
Ô£∏(9)
Specifically,weuse macro-F1 forclassification
tasks,and accuracy fornon-classificationtasksin
our experiment. The overall performance is then
quantifiedbycomputingthemacro-averageofthese
scoresacrossalltasks,encapsulatingboth accuracy
andmacro-F1 metrics. To ensure robustness and
reduce sampling bias, each experiment under each
splitting setting is replicated with five different
randomseeds. Foreachfew-shottask,weadopta
uniform approach by randomly selecting k= 16
training examples. Following (Min et al., 2022),
we did not make perfect label balance between k
training examples.
BaselineMethods. Inthisstudy,wecompareour
novel augmentation pipeline, Self-LLMDA , with
twodifferentcategoriesofdataaugmentationmeth-
odsasbaselines: Non-LLMDA andManual-LLMDA
Forboth Manual-LLMDA andSelf-LLMDA ,weem-
ploy GPT-3.5 Turbo as the backbone LLM. For
detailed descriptions of these baseline methods,
please see Appendix E. Specifically:
‚Ä¢Non-LLMDA methods. Thiscategoryincludes13
traditionalaugmentationtechniques: Character-
Level: Operationssuchasrandomswaps,OCR
Errors simulation, deletions, insertions, and sub-
stitutions. Word-Level: Transformations, includ-
ing word swaps, deletions, spelling errors, and
embedding-basedinsertions. Contextual-Level:
Utilizationoflanguagemodelsforwordinsertions
(e.g.,using GPT2(Brownetal.,2020))andsub-
stitutions(e.g.,with BERT(Devlinetal.,2018)),
and back-translation (Fadaee et al., 2017).

--- PAGE 6 ---
TextulDA Class ‚ÜíClass Class ‚ÜíNon-Class Non-Class ‚ÜíClass Random ‚ÜíRandom
125m350m 1.3b 125m 350m 1.3b 125m350m 1.3b 125m 350m 1.3b
Original 44.8041.9442.82 38.49 42.04 42.42 46.4944.1344.52 42.73 42.92 44.10Non-LLMDAChar. Swap 44.9442.2242.28 39.46 40.56 42.76 47.0844.6944.06 43.89 42.45 42.90
Char. OCR 43.7243.7043.66 39.31 41.02 43.73 45.9146.0245.11 42.95 43.02 43.83
Char. Delete 43.9843.3342.35 38.99 40.50 43.08 46.0145.0444.02 42.53 42.77 43.52
Char. Insert 45.0343.1441.19 39.22 40.61 42.77 46.6944.6142.44 43.29 42.86 42.37
Char. Subs. 43.8743.0740.29 39.39 40.22 42.46 46.1145.2243.25 43.41 42.65 43.08
Word Swap 43.8344.5642.75 39.15 40.84 43.51 46.2546.2144.93 43.24 43.54 44.30
Word Delete 44.2442.3843.90 39.54 40.34 43.12 45.7044.4945.56 43.41 42.02 44.28
Spell Error 44.8242.6644.38 38.68 41.03 42.8546.3444.8544.97 42.71 43.08 43.71
GPT2Insert 43.3743.3644.13 39.79 40.92 43.69 45.0745.9346.11 42.65 43.07 44.44
Word2vec Insert 46.4741.8041.86 39.67 40.80 42.66 48.3645.1343.78 44.18 42.95 42.86
BERTSubs. 44.8844.0144.45 39.57 40.23 42.86 46.8745.3246.35 43.17 42.92 43.79
Word2vec Insert 44.2443.8942.68 38.90 40.21 42.80 46.1745.5844.34 43.07 42.76 44.06
Back Translation 44.1944.0046.2339.78 40.89 42.96 45.9745.3147.3943.24 43.60 43.95
Average 44.4243.2343.0839.3440.6243.0146.3445.2644.7943.2142.8943.62
Best 46.4744.5646.2339.7941.0343.7348.3646.2147.3944.1843.4744.30Manual-LLMDAChar. Perturb 44.7243.5643.30 39.39 40.61 45.54 47.0245.3246.25 43.68 43.27 44.06
Word Insert/Delete 44.8044.2744.82 38.81 40.97 44.4946.5845.9346.59 42.95 43.68 44.46
Word Swap 45.4543.8845.90 39.01 40.66 43.28 47.0445.2046.80 43.63 42.63 45.79
Word Replace 45.2945.9446.53 39.14 41.05 43.10 47.3647.9847.62 43.52 44.57 45.89
Grammar Transform 45.3945.6244.98 39.29 41.34 43.0046.8146.7646.41 43.24 43.75 45.53
Data Mix 44.6344.0143.73 38.50 41.29 43.67 46.0245.6843.93 42.76 43.26 43.01
Paragraph Shuffle 45.7842.0345.80 39.29 40.70 43.28 47.7045.0248.0244.4343.25 45.41
Mask Predict 42.8343.1545.87 39.58 40.59 44.05 46.0244.6045.70 42.59 43.16 44.64
Sentence Reorder 44.1843.8448.9839.37 40.76 43.20 46.3046.3548.46 43.35 43.70 45.64
Contextual Replace 43.5246.2643.26 38.73 40.99 43.49 45.3847.6243.92 42.58 45.26 44.76
Paraphrase 45.5645.3042.53 39.44 40.94 41.09 48.0247.3143.99 43.97 44.10 42.80
POS Augment 44.9744.4847.51 39.12 41.14 43.57 47.0646.0747.25 43.49 43.21 45.75
Back Translation 45.7943.3845.30 39.18 41.12 43.80 47.0245.5845.10 43.36 43.20 44.41
Average 44.8344.2845.2739.1440.9343.5046.7946.1046.1543.3543.6144.78
Best 45.7946.2648.9839.5841.3444.4948.0247.9848.0244.4345.2645.89
Self-LLMDA 51.7254.9848.8040.02 42.80 43.8050.0052.7549.48 46.64 48.83 48.95
Table 1: The performance of different data augmentation methods. Char. and Subs. are the abbreviations of
characterandsubstitute,respectively. Underlined indicatesbestperformanceundereachaugmentationmethodgroup
whileBoldindicatesthe bestresultofthe wholetable. Ineachgroup, the last two rows representthe aggergated
result of the whole group of augmentation methods (e.g. average and best).
‚Ä¢Manual-LLMDA methods. This set comprises
13 manually designed augmentation instructions
forLLM,including: Character-Level: Perturba-
tionssimilartothosein Non-LLMDA .Word-Level:
Swaps,replacements,andpart-of-speech(POS)
enhancements. Sentence-Level: Reorderingand
data mixing strategies. Contextual-Level: Pre-
dictive masking, contextual substitutions, and
back-translation.
We also report the average and best performance
ofNon-LLMDA andManual-LLMDA for better com-
parison. An extensive ablation study of our task-
informed selection model, presented in ¬ß 5.3.
5.2 Main Results
The analysis of experimental results presented in
Tab. 1 reveals several findings: Firstly, there is
performance inconsistency among the different
instructions from Manual-LLMDA . The impact of
augmentation instructions varies across different
downstreamtasksandmodels. Thishighlightsthe
difficulty in creating universally effective data aug-mentationinstruction. Secondly ,Manual-LLMDA
is not always better than Non-LLMDA . In controlled
comparisonsfocusingonspecificaugmentationtop-
ics,Manual-LLMDA ‚Äôs advantages over Non-LLMDA
werenotclearlyevident. Forexample,inthecon-
texts of ‚ÄúBack Translation‚Äù and ‚ÄúWord Swap‚Äù,
Non-LLMDA outperformed Manual-LLMDA in5out
of 12 and 7 out of 12 cases, respectively. Lastly,
the experimental results show the superiority of
Self-LLMDA .Ourproposedmodelconsistentlyout-
performedthesebaselinemethods,highlightingthe
effectiveness of integrating automatic instruction
generation with targeted task-specific instruction
selection. This approach not only optimizes perfor-
mancebutalsoreducesthemanualeffortstypically
requiredtodesigneffectiveaugmentationstrategies,
showcasingthepotentialofourmodelinenhancing
data augmentation practices.
5.3 Ablation Study
We add an ablation study to understand the impact
of two key components in our framework: aug-

--- PAGE 7 ---
Select. Method Class ‚ÜíNon-Class Non-Class ‚ÜíClass
125m350m 1.3b 125m 350m 1.3b
Manual-LLMDA+39.6241.7444.3848.02 48.51 48.07
Random-Select 39.3440.3142.68 46.15 44.34 43.98
Empirical -Select 39.1741.1843.14 47.19 47.30 44.41
LLM-Select 38.7741.0643.07 46.81 48.02 46.42
Self-LLMDA 40.0242.8043.8050.00 52.75 49.48
Table 2: Ablation study of Self-LLMDA .
mentationinstructionself-generationandthetask-
informed instruction selection. Firstly, we train
a task-informed instruction selection model Son
manually-craftedinstructionsfrom Manual-LLMDA
and named it Manual-LLMDA+to understand the
contribution of the contribution of LLM self-
generated augmentation instructions. Secondly ,
we test the efficacy of our selection model by
comparing three alternative selection strategies:
(1) Random-select, which randomly select instruc-
tion from the pool of augmentation methods for
each task; (2) Empirical-select, which selects the
prompt that yielded the highest average perfor-
mance across training tasks, under the assumption
thatsuccessfulpromptsontrainingtaskswillgener-
alize well to test tasks; and (3) LLM-Select, which
prompts the LLM to chooses the most suitable
instruction from candidates based on its internal
decision-makingprocesses. TheResultsinTab.2
show that Self-LLMDA consistently outperforms
these alternative methods, indicating the benefits
of instruction self-generation and task-informed
selection in enhancing model performance.
5.4 Hyperparameter Analysis
Here,wecloselyexaminedtheimpactoftwocrit-
ical hyperparameters on the training of our task-
informedinstructionmodel: nandm. Thehyper-
parameter nspecifies the number of augmentation
instructions to be sampled for optimizing Eq. 6. It
shouldbenoticedthat,weonlyvary nattraining
time,whileatinference,wewillcalculatethescore
for all the generated instructions and choose the
one with the largest score. On the other hand, m
determinesthenumberofexamplesfromthetask
dataset that are used to represent the task, influ-
encing the model‚Äôs performance during both the
optimization and inference phases. Our analysis,
depictedinFig.5,highlightsseveralkeyfindings:
(1)OptimalNumberof Instructions: Wefoundthat
setting n= 2leads to the best performance, out-
performingotherconfigurations. Thissuggeststhat
a pairwise comparison, as formulated in Eq. 6, is
mosteffectiveforourmodel‚Äôslearningprocess. (2)
2 3 4 54041424344Accuracy (%)
Target Model
125m 350m 1.3b(a) Class‚ÜíNon-Class
2 3 4 549505152Macro F1 (%)
 (b) Non-Class ‚ÜíClass
Figure 4: Hyperparameter analysis of n, which dictates
thenumberofaugmentationinstructionssampledduring
the training of the selection model.
1 2 3 44041424344Accuracy (%)
Target Model
125m 350m 1.3b
(a) Class‚ÜíNon-Class
1 2 3 449505152Macro F1 (%)
 (b) Non-Class ‚ÜíClass
Figure 5: Analysis of the hyperparameter m, which
determinesthe numberofexamplesrandomly sampled
to represent a task.
RepresentativeExamples: Interestingly,asmaller
number of examples ( m) appear to better capture
theessenceofthetasks. Thisobservationindicates
that a larger set of examples could introduce noise,
potentially detracting from the model‚Äôs ability to
accuratelyrepresenttasksforinstructionselection.
5.5 In-Depth Analysis of the Task-Informed
Instruction Selection Model
In this section, we provide a detailed analysis of
theperformanceandgeneralizationcapabilitiesof
ourinstructionselectionmodel S,focusingonits
generalizability to unknown augmentation instruc-
tions,unknowntargetmodels,andthespecificcase
studies of the augmentation instructions it selects.
Generalization to Unknown Augmentation In-
structions. In this analysis, we delve into the
selection model‚Äôs adaptability to unknown aug-
mentation instructions by simulating a dynamic
environment where new instructions are generated
asynchronously by the LLMs. This scenario mir-
rors practical applications where the augmentation
instruction set can expand without necessitating
retraining of the selection model. To test this,
weconstrainedthetrainingphaseoftheselection
model to a limited subset of self-generated aug-
mentationinstructions(30%ofallgeneratedbythe
LLMs),utilizingthewholegeneratedinstructions
for evaluation at inference time.
As the results shown in Fig. 6, we can ob-

--- PAGE 8 ---
125m 350m 1.3b3839404142434445Accuracy (%)39.841.043.7
39.641.344.5
39.841.643.9 Best Non-LLMDA
 Best Manual-LLMDA
Self-LLMDA(a) Class‚ÜíNon-Class.
125m 350m 1.3b4446485052545658Macro F1 (%)48.4
46.247.448.0 48.0 48.050.052.8
49.5 Best Non-LLMDA
 Best Manual-LLMDA
Self LLMDA (b) Non-Class ‚ÜíClass.
Figure 6: Result of generalization to unknown augmen-
tation instruction selection.
serve a performance improvement of our selection
model over the best performance of Non-LLMDA
andManual-LLMDA . This indicates the robustness
of our selection model in adapting to incremen-
talaugmentationinstructions, effectivelyselecting
suitable instructions even when faced with previ-
ously unknown instructions. These observations
highlight the efficacy of our selection model in a
dynamic augmentation scenario.
Generalization to Unknown Target Models.
Our study extended to evaluate the adaptability
of our task-informed selection model across di-
verse target models. By applying the selection
model, initially trained on the task performance of
a specific target model, to different models. The
resultsoftheseexperimentsarepresentedinTab.3.
Our findings show that the augmentation instruc-
tionsselectedbyourmodelremaineffectiveeven
when applied to different target models. Notably,
in most scenarios, our model Self-LLMDA , when
transferredtoalternatetargetmodels,outperformed
the best results obtained using Non-LLMDA and
Manual-LLMDA . This indicates that the underlying
pattern determining instruction effectiveness via
our instruction selection model is transferable.
Train.Class‚ÜíNon-Class Non-Class ‚ÜíClass
125m350m 1.3b 125m 350m 1.3b
Best Non-LLMDA 39.7941.0343.7348.3646.2147.39
Best Manual-LLMDA 39.5841.3444.4948.0247.9848.02
125m 40.0241.9743.5650.00 54.12 49.83
350m 39.9642.8043.66 49.96 52.75 48.82
1.3b 39.8542.4243.80 49.04 51.22 49.48
Table 3: Transferability of the Task-Informed Selection
Model. Our selection model, initially trained on a
specific target model (indicated by each row in the
second group), when applied to alternate target models
(represented in each column).
AnalysisofSelectedInstructions. Weconducted
adetailedanalysisoftheaugmentationinstructions
chosen by our selection model, and the findings
visualized in Fig. 7. The key insights from this
analysis are as follows: (1) Diversity of Selected In-
125m 350m 1.3b0246810CountAugIns. Name
Text Paraphrase
Paraphrase
Synonym Replace
Emotion Augmentation
POS Variation
Grammar Error
Contextual Word Subs.
Summarization
Text Shuffle
Data Sample
Domain Term Replace(a) Class‚ÜíNon-Class.
125m 350m 1.3b0246810121416CountAugIns. Name
Pronoun Replace
Contextual Paraphrase
sentence paraphrase
Paraphrase
Negation Addition
Text Expand (b) Non-Class ‚ÜíClass.
Figure 7: Selected augmentation instructions from task-
informed augmentation selection model.
structions: Thedistributionofselectedinstructions
showcases a wide variety in the types of augmenta-
tions chosen by the model, with 3, 2, and 6 unique
data augmentation instructions identified for the
125m, 350m,and 1.3bmodelsunder Class ‚ÜíNon-
Class, respectively. This demonstrates the model‚Äôs
ability to adapt and select from a broad spectrum
ofaugmentationstrategiestomeetthespecificre-
quirementsofdifferenttasks. (2)Variabilityacross
Models:The selection patterns exhibit notable dif-
ferenceswhenthemodelisappliedtovarioustarget
models. This variability indicates preference differ-
encesacrossdifferenttargetmodels. (3)Preference
forParaphrase-BasedInstructions: Asignificant
portion of the selected instructions fall into the
category of paraphrase-based augmentations, such
as ‚ÄúText Paraphrase‚Äù, ‚ÄúParaphrase‚Äù, ‚ÄúContextual
Paraphrase‚Äù, and ‚ÄúSentence Paraphrase‚Äù. This
preference not only highlights the effectiveness
andgeneralapplicabilityofparaphrase-basedaug-
mentations but also illustrates our task-informed
selectionmodel‚Äôsnuancedcapabilitytodiscernand
recommend the most suitable paraphrase variation
for a given task.
6 Conclusion
Inthiswork,weintroduced Self-LLMDA ,anovel
framework that leverages the capabilities of LLMs
for textual data augmentation. Our approach ad-
dresses the challenges associated with traditional
dataaugmentationmethodsandthelimitationsof
manualinstructiongenerationinLLM-basedaug-
mentation. Self-LLMDA automates the generation
and selection of augmentation instructions, thereby
significantlyenhancingthequalityandapplicabil-
ityofaugmenteddataacrossdiversedownstream
tasks. Tested across 26 diverse few-shot learning
tasks, Self-LLMDA consistentlyoutperformsboth
Non-LLMDA andManual-LLMDA methods, show-
casing its effectiveness and applicability.

--- PAGE 9 ---
7 Limitations
This study acknowledges several constraints that
delineate the scope of our current work and outline
directions for future research:
‚Ä¢Evaluation on a Limited Range of LLMs:
Our experiments were conducted primarily
withGPT3.5Turboduetothehighcostsas-
sociated with using OpenAI models. While
promisingresultsinTab.1suggestthatourpro-
posed Self-LLMDA methodcould potentially
performevenbetteronmoreadvancedmodels
like GPT 4 Turbo, comprehensive testing was
notfeasible. Similarly,thecomputationalde-
mandsofevaluatingopen-sourceLLMssuch
as LLAMA-70b-chat (Touvron et al., 2023),
coupled with the extensive number of tasks
in our study, exceeded our resources. De-
spitetheselimitations,weareoptimisticthat
Self-LLMDA wouldexhibitenhancedperfor-
mance across a broader spectrum of LLMs.
‚Ä¢Meta-Prompting Exploration: Within the
Self-LLMDA framework, we employed one
meta-prompt to guidethe LLM in generating
diverseandrelevantaugmentationinstructions.
However,ourexplorationofmeta-prompting
techniques was limited. We acknowledge that
more sophisticated prompt engineering could
furtherrefinethequalityandeffectivenessof
generated instructions. Investigating more
advancedmeta-promptingstrategiesremains
an area for future exploration.
‚Ä¢Analysis of Ensemble Augmentation Meth-
ods:Ourresearchdidnotinvestigatethepo-
tentialbenefitsofcombiningmultiplesetsof
augmenteddata(e.g., D ‚à™D‚Ä≤
1‚à™D‚Ä≤
2). Suchen-
sembleapproachesintroduceadditionalcom-
plexities,suchasdeterminingtheoptimalnum-
ber of augmentation instructions to include.
While we hypothesize that ensemble augmen-
tation could improve model performance, this
aspectfallsoutsidethecurrentstudy‚Äôsscope
and is earmarked for subsequent investigation.
References
Markus Bayer, Marc-Andr√© Kaufhold, and Christian
Reuter.2022. Asurveyondataaugmentationfortext
classification. ACM Computing Surveys , 55(7):1‚Äì39.Yonatan Belinkov and Yonatan Bisk. 2018. Synthetic
and natural noise both break neural machine transla-
tion.
TomB.Brown,BenjaminMann,NickRyder,Melanie
Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind
Neelakantan,Pranav Shyam,GirishSastry, Amanda
Askell, Sandhini Agarwal, Ariel Herbert-Voss,
Gretchen Krueger, Tom Henighan, Rewon Child,
Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu,
ClemensWinter,ChristopherHesse,MarkChen,Eric
Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess,
Jack Clark, Christopher Berner, Sam McCandlish,
Alec Radford, Ilya Sutskever, and Dario Amodei.
2020. Language models are few-shot learners.
Qiao Cheng, Jin Huang, and Yitao Duan. 2022. Se-
mantically consistent data augmentation for neural
machine translation via conditional masked language
model.
Hyung Won Chung, Le Hou, Shayne Longpre, Barret
Zoph, Yi Tay, William Fedus, Yunxuan Li, Xuezhi
Wang, Mostafa Dehghani, Siddhartha Brahma, Al-
bertWebson,ShixiangShaneGu,ZhuyunDai,Mirac
Suzgun, Xinyun Chen, Aakanksha Chowdhery, Alex
Castro-Ros,MariePellat,KevinRobinson,DashaVal-
ter,Sharan Narang,GauravMishra, AdamsYu, Vin-
cent Zhao, Yanping Huang, Andrew Dai, Hongkun
Yu,SlavPetrov,EdH.Chi,JeffDean,JacobDevlin,
AdamRoberts,DennyZhou,QuocV.Le,andJason
Wei. 2022. Scaling instruction-finetuned language
models.
John Joon Young Chung, Ece Kamar, and Saleema
Amershi. 2023. Increasing diversity while main-
taining accuracy: Text data generation with large
language models and human interventions. arXiv
preprint arXiv:2306.04140 .
Claude Coulombe. 2018. Text data augmentation made
simple by leveraging nlp cloud apis.
HaixingDai,ZhengLiu,WenxiongLiao,XiaokeHuang,
ZihaoWu,LinZhao,WeiLiu,NinghaoLiu,ShengLi,
DajiangZhu,HongminCai,QuanzhengLi,Dinggang
Shen, Tianming Liu, and Xiang Li. 2023. Chataug:
Leveragingchatgptfortextdataaugmentation. ArXiv,
abs/2302.13007.
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and
Kristina Toutanova. 2018. Bert: Pre-training of deep
bidirectionaltransformersforlanguageunderstanding.
arXiv preprint arXiv:1810.04805 .
Aleksandra Edwards, Asahi Ushio, Jose Camacho-
Collados, H√©l√®ne de Ribaupierre, and Alun Preece.
2023. Guidinggenerativelanguagemodelsfordata
augmentation in few-shot text classification.
MarziehFadaee,AriannaBisazza,andChristofMonz.
2017. Dataaugmentationforlow-resourceneuralma-
chine translation. arXiv preprint arXiv:1705.00440 .
Tianyu Gao, Xingcheng Yao, and Danqi Chen. 2022.
Simcse: Simple contrastive learning of sentence
embeddings.

--- PAGE 10 ---
HongyuGuo,YongyiMao,andRichongZhang.2019.
Augmenting data with mixup for sentence classifica-
tion: An empirical study.
Yoichi Ishibashi, Danushka Bollegala, Katsuhito Sudoh,
andSatoshiNakamura.2023. Evaluatingtherobust-
ness of discrete prompts. In Proceedings of the 17th
Conference ofthe European Chapterof theAssocia-
tionforComputationalLinguistics ,pages2373‚Äì2384,
Dubrovnik,Croatia.AssociationforComputational
Linguistics.
MandarJoshi,DanqiChen,YinhanLiu,DanielS.Weld,
LukeZettlemoyer,andOmerLevy.2020. Spanbert:
Improvingpre-trainingbyrepresentingandpredicting
spans.
Akbar Karimi, Leonardo Rossi, and Andrea Prati. 2021.
AEDA: An easier data augmentation technique for
text classification. In Findings of the Association
for Computational Linguistics: EMNLP 2021 , pages
2748‚Äì2754, Punta Cana, Dominican Republic. Asso-
ciation for Computational Linguistics.
DanielKhashabi,SewonMin,TusharKhot,AshishSab-
harwal,OyvindTafjord,PeterClark,andHannaneh
Hajishirzi. 2020. UNIFIEDQA: Crossing format
boundaries with a single QA system. In Findings
of the Association for Computational Linguistics:
EMNLP2020 ,pages1896‚Äì1907,Online.Association
for Computational Linguistics.
Varun Kumar, Ashutosh Choudhary, and Eunah Cho.
2021. Data augmentation using pre-trained trans-
former models.
GakutoKurata,BingXiang,andBowenZhou.2016. La-
beled Data Generation with Encoder-Decoder LSTM
for Semantic Slot Filling. In Proc. Interspeech 2016 ,
pages 725‚Äì729.
Mike Lewis, Yinhan Liu, Naman Goyal, Marjan
Ghazvininejad, Abdelrahman Mohamed, Omer Levy,
VesStoyanov,andLukeZettlemoyer.2019. Bart: De-
noisingsequence-to-sequencepre-trainingfornatural
language generation, translation, and comprehension.
Zhuoyan Li, Hangxiao Zhu, Zhuoran Lu, and Ming
Yin.2023. Syntheticdatagenerationwithlargelan-
guage models for text classification: Potential and
limitations. arXiv preprint arXiv:2310.07849 .
Chin-YewLin.2004. ROUGE:Apackageforautomatic
evaluation of summaries. In Text Summarization
Branches Out , pages 74‚Äì81, Barcelona, Spain. Asso-
ciation for Computational Linguistics.
YinhanLiu,MyleOtt,NamanGoyal,JingfeiDu,Mandar
Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke
Zettlemoyer, and Veselin Stoyanov. 2019. Roberta:
A robustly optimized bert pretraining approach.
Ilya Loshchilov and Frank Hutter. 2019. Decoupled
weight decay regularization.
Edward Ma. 2019. Nlp augmentation.
https://github.com/makcedward/nlpaug.Yu Meng, Jiaxin Huang, Yu Zhang, and Jiawei Han.
2022. Generatingtrainingdatawithlanguagemodels:
Towards zero-shot language understanding.
TodorMihaylov,PeterClark,TusharKhot,andAshish
Sabharwal.2018. Canasuitofarmorconductelectric-
ity? a new dataset for open book question answering.
Sewon Min, Mike Lewis, Luke Zettlemoyer, and Han-
naneh Hajishirzi. 2022. MetaICL: Learning to learn
in context. In Proceedings of the 2022 Conference of
the North American Chapter of the Association for
ComputationalLinguistics: HumanLanguageTech-
nologies, pages 2791‚Äì2809, Seattle, United States.
Association for Computational Linguistics.
JohnX.Morris,EliLifland,JinYongYoo,JakeGrigsby,
Di Jin, and Yanjun Qi. 2020. Textattack: A frame-
work for adversarial attacks, data augmentation, and
adversarial training in nlp.
Fr√©d√©ric Piedboeuf and Philippe Langlais. 2023. Is
ChatGPT the ultimate data augmentation algorithm?
InFindings of the Association for Computational
Linguistics: EMNLP 2023 , pages 15606‚Äì15615, Sin-
gapore. Association for Computational Linguistics.
Alec Radford, Jeffrey Wu, Rewon Child, David Luan,
Dario Amodei, Ilya Sutskever, et al. 2019. Language
models are unsupervised multitask learners. OpenAI
blog, 1(8):9.
Colin Raffel,Noam Shazeer,Adam Roberts, Katherine
Lee, Sharan Narang, Michael Matena, Yanqi Zhou,
WeiLi,andPeterJ.Liu.2023. Exploringthelimits
of transfer learning with a unified text-to-text trans-
former.
Marco Tulio Ribeiro, Tongshuang Wu, Carlos Guestrin,
andSameerSingh.2020. Beyondaccuracy: Behav-
ioraltestingofNLPmodelswithCheckList. In Pro-
ceedingsofthe58thAnnualMeetingoftheAssocia-
tionforComputationalLinguistics ,pages4902‚Äì4912,
Online. Association for Computational Linguistics.
Noam Shazeer and Mitchell Stern. 2018. Adafactor:
Adaptivelearningrateswithsublinearmemorycost.
InInternational Conference on Machine Learning ,
pages 4596‚Äì4604. PMLR.
Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier
Martinet, Marie-Anne Lachaux, Timoth√©e Lacroix,
Baptiste Rozi√®re, Naman Goyal, Eric Hambro, Faisal
Azhar, Aurelien Rodriguez, Armand Joulin, Edouard
Grave,andGuillaumeLample.2023. Llama: Open
and efficient foundation language models.
Solomon Ubani, Suleyman Olcay Polat, and Rodney
Nielsen. 2023. Zeroshotdataaug: Generating and
augmenting training data with chatgpt.
Alex Wang, Amanpreet Singh, Julian Michael, Felix
Hill, Omer Levy, and Samuel R. Bowman. 2019.
Glue: A multi-task benchmark and analysis platform
for natural language understanding.

--- PAGE 11 ---
Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa
Liu, Noah A Smith, Daniel Khashabi, and Hannaneh
Hajishirzi. 2022. Self-instruct: Aligning language
modelwithselfgeneratedinstructions. arXivpreprint
arXiv:2212.10560 .
Jason Wei and Kai Zou. 2019. Eda: Easy data augmen-
tation techniques for boosting performance on text
classification tasks.
XingWu,ShangwenLv,LiangjunZang,JizhongHan,
and Songlin Hu. 2018. Conditional bert contextual
augmentation.
JiachengYe,JiahuiGao,QintongLi,HangXu,Jiangtao
Feng,ZhiyongWu,TaoYu,andLingpengKong.2022.
Zerogen: Efficient zero-shot learning via dataset
generation.
Qinyuan Ye, Bill Yuchen Lin, and Xiang Ren. 2021.
CrossFit: Afew-shotlearningchallengeforcross-task
generalization in NLP. pages 7163‚Äì7189.
Kang Min Yoo, Dongju Park, Jaewook Kang, Sang-
Woo Lee, and Woomyeong Park. 2021. Gpt3mix:
Leveraging large-scale language models for text aug-
mentation.
YueYu,YuchenZhuang,JieyuZhang,YuMeng,Alexan-
der Ratner, Ranjay Krishna, Jiaming Shen, and Chao
Zhang. 2023. Large language model as attributed
training data generator: A tale of diversity and bias.
Susan Zhang, Stephen Roller, Naman Goyal, Mikel
Artetxe, Moya Chen, Shuohui Chen, Christopher
Dewan, Mona Diab, Xian Li, Xi Victoria Lin, Todor
Mihaylov, Myle Ott, Sam Shleifer, Kurt Shuster,
Daniel Simig, Punit Singh Koura, Anjali Sridhar,
Tianlu Wang, and Luke Zettlemoyer. 2022. Opt:
Open pre-trained transformer language models.
Xiang Zhang, Junbo Zhao, and Yann LeCun. 2016.
Character-level convolutional networks for text clas-
sification.
Kaƒ≥ieZhu,JindongWang,JiahengZhou,ZichenWang,
HaoChen,YidongWang,LinyiYang,WeiYe,Yue
Zhang, Neil Zhenqiang Gong, and Xing Xie. 2023.
Promptbench: Towardsevaluatingtherobustnessof
large language models on adversarial prompts.

--- PAGE 12 ---
A Detailed Experiment Settings
GenerationConfiguration. Weutilizegpt-3.5-
turbo as our backbone LLM for augmentation in-
struction generation and data augmentation. We
set the temperature for both of them as 0.7. For
theinstructiongeneration,wefollowthegeneration
hyper-parameter setting from Wang et al. (2022).
For data augmentation, we utilize the default gener-
ation hyper-parameter from Chat Completion. The
wholeexperimentincludinggeneratingaugmenta-
tion instructions and generating augmentation data
costsus$82USDintotal,accordingtoOpenAI‚Äôs
pricing ( Input $0.0005 / 1K tokens and output
$0.0015 / 1K tokens). However, the total exper-
iment cost around $200 USD for debugging and
exploration.
Meta Prompts for Data Augmentation As
shown in step 3in Fig. 2, we also need a meta
prompttoencourage Self-LLMDA toaugmenthigh
qualitydata. Themainreasonforthismeta-prompt
setting is because in some augmentation instruc-
tions they will discuss some external tools like
word-embedding, other language models, if we did
notprovidethemeta-prompt,theLLMwillreject
the generation of augmented data. The design of
meta prompt is as follows:
Pleasedothefollowingdataaugmentationsteps
tothetextdelimitedbytriplebackticks. Ifyou
need any external resources or data, you can
justsimulatetheenvironmentbyyourselfand
finish that step based on your own knowledge
since you are the best language model in word.
Augmentation Instructions: Ij,Input Data:
xi{Iseed}
Task-informed Instruction Selection. The in-
structionrankingmodelisinitializedwithFLAN-
T5-Large(Radford et al., 2019) and is trained using
Adafactor (Shazeer and Stern, 2018) with learning
rate 5e-5 and dropout 0.1. We train the selection
model for 100 epochs and set the early stop with
patience20epochs. Weemploythevalidationset
from training tasks to select the best checkpoint.
The search space for different hyperparameter anal-
ysis are as follows:
TargetModelFinetuning. Weuse OPT(Zhang
etal., 2022)from125m, 350m, 1.3bdifferent sizes.
For all of them we use AdamW(Loshchilov and Hut-
ter, 2019) as our optimizer with learning rate 5e-5Symbol Description Search Space
nNumber of sampled
augmentation instruction{2, 3, 4, 5}
mNumber of sampled examples
from task dataset{1, 2, 3, 4}
- batch size {4, 8, 16}
- epochs 100
Table 4: The search space of augmentation selection.
with 10 training epochs. Due to the constraint of
GPUmemory,for125mand350mwesetthebatch
size as 8, while 1.3b we set the batch size as 2. All
theseexperimentsistestedononeNVIDIAA100
A100-40G GPU cards.
BAnalysis of Self-Generated Instructions
In our analysis, we delve into the characteristics
and diversity of the self-generated augmentation
prompts created by Manual-LLMDA .
StatisticalInformation. Tofacilitateastructured
examination,wecategorizethesepromptsbasedon
the textual data augmentation taxonomy outlined
byBayeretal.(2022). Thedistributionandbasic
statistics of these various augmentation methods
are detailed in Tab. 5.
Augmentation Type Count AVG Length
Manual-LLMDA 13 28.15
- character level 1 32.00
- word level 3 20.67
- phrase level 4 31.75
- document level 5 29.00
Manual-LLMDA 51 25.58
- misc. 1 22.00
- character level 2 24.50
- word level 10 22.80
- phrase level 18 26.72
- document level 20 26.25
Table 5: Statistics of augmentation prompts.
Naming Conventions. A notable aspect of our
analysisinvolvesexaminingthenamingconventions
of the augmentation methods. Recognizing that
themethodnamesoftenprovideahigh-levelsum-
mary of the augmentation approach (e.g., <method
name>),wefurtherexplorethelinguisticpatterns
within these names. Specifically, we conduct an
analysisfocusingonthefirstandlastwordsofeach
methodname. Thisapproachallowsustogainin-
sightsintothethematicandfunctionalaspectsofthe
augmentation methods. The distribution of these
first and last words in method names is visually
represented in Fig. 8. This visual representation
aidsinunderstandingtherangeandfocusoftheaug-
mentationtechniquesgeneratedby Manual-LLMDA .

--- PAGE 13 ---
Sentence
19.4%
Contextual16.7%
Word16.7%
Negation11.1%Text11.1%Named8.3%Character-level
5.6%Numerical
5.6%Sentiment
5.6%(a) First word.
replacement
19.4%
deletion 12.9%
variation12.9%
augmentation9.7%paraphrasing9.7%shuffling9.7%injection6.5%insertion
6.5%perturbation
6.5%substitution
6.5% (b) Last word.
Figure 8: The first words and last words from the Chat-
Self. Wefilterthesewordsbyappearingmorethanonce.
By analyzing these key linguistic elements, we aim
toshedlightonthecreativebreadthandthematicfo-
cusoftheself-generatedaugmentationinstructions.
0.2 0.3 0.4 0.5 0.6
ROUGE-L Overlap with the Most Similar Human Designed Instructions0246810121416Count
Figure 9: Distribution of the ROUGE-L scores between
generated instructions and their most similar human-
designed instructions.
C Analysis of Generated Data Across
Different Augmentation Methods
Inthisanalysis, weaimto discernthe differences
amongtheoriginaldataset,non-LLMaugmented
data, data augmented via human-designed instruc-
tions, and data augmented using Manual-LLMDA
generated instructions. Our focus is on the surface-
level characteristics of the augmented content, and
we consolidate data across all tasks for a compre-
hensiveview. Keyobservationsfromtheanalysis,
as detailed in Tab. 6, include the following:
Length of Content. Data augmented by LLM-
based methods, on average, exhibits longer content
comparedtoboththeoriginalandtraditionallyaug-
mented datasets. This increase in length could
offerabroaderspectrumoftrainingexamples,po-
tentially aiding in better generalization of target
models. However, it also introduces a challenge
of dataset inconsistency and the risk of adding
unwanted variations.Perplexity Scores. Interestingly, LLM-
augmented content achieves lower perplexity
scores(asmeasuredonGPT2-small)comparedto
traditional augmentation methods. This suggests
that the target model like GPT2-small has a
better grasp of content augmented by LLMs. A
possible explanation for the higher perplexity
scores observed in non-LLM text augmentations is
that the character and word-level changes might
introduce new, irrelevant tokens into the text,
thereby increasing complexity.
ClosenesstoOriginalExamples. Comparedto
non-LLM augmentation methods, LLM-based aug-
mentations tend to produce content that is more
closelyrelatedorlessdiverserelativetotheoriginal
examples. This observation points to a potential
trade-off between relevance and diversity in the
augmented content generated by LLMs.
Metrics Method Mean Std. 25% 50% 75%
SentimentOri. 0.05 0.24 0.00 0.00 0.14
Traditional 0.05 0.23 0.00 0.00 0.12
Human 0.06 0.23 0.00 0.00 0.15
ChatGPT 0.06 0.23 0.00 0.00 0.16
GrammarOri. 1.50 2.34 0.00 1.00 2.00
Traditional 4.92 5.02 2.00 4.00 7.00
ErrorHuman 7.78 47.76 0.00 1.00 4.00
ChatGPT 4.19 27.51 0.00 1.00 3.00
WordsOri. 29.06 38.84 11.00 20.00 34.00
Non-LLMDA 30.01 39.01 11.00 21.00 36.00
Manual-LLMDA 95.34 285.95 14.00 30.00 71.00
Self-LLMDA 66.04 182.91 14.00 27.00 57.00
Perplexity Ori. 530.13 5867.93 46.42 93.78 253.85
On Non-LLMDA 1354.91 5912.87 231.22 595.03 1305.86
GPT2- Manual-LLMDA 614.80 12284.76 17.72 58.94 184.42
small Self-LLMDA 491.83 9715.57 21.28 59.85 173.28
Distance Non-LLMDA 0.26 0.15 0.12 0.25 0.39
to Manual-LLMDA 0.17 0.04 0.15 0.17 0.18
Original Self-LLMDA 0.15 0.05 0.12 0.15 0.18
Table 6: Characteristics of augmented data.
Aug. Type small medium large
Trad. 42.37/44.18 46.92/49.72 44.81/47.33
Human. 42.43/44.52 47.25/49.52 48.44/53.32
LLM. 42.03/ 48.47 47.80 /51.0945.88/52.17
Table 7: Main results, using target models from GPT2
family. Two numbers indicate the single best augmen-
tation method across tasks and the task specific best
augmentationmethod. Boldindicatesthebestaverage
result except results.
Augmentation Instruction Pitfalls Across Tasks
The effectiveness of augmentation instructions can
vary depending on the specific characteristics of
thetasksathand(Ribeiroetal.,2020;WeiandZou,
2019). To illustrate this, we present a case study
focusing on the augmentation instruction Pronoun
replacement: replacepronounsinthetextwiththeir
correspondingnounsorviceversa,maintainingthe

--- PAGE 14 ---
semanticmeaningofthesentence. Forthesakeof
brevity, we will use the abbreviation PR to refer
topronoun replacement. We consider two cate-
goriesoftasks: textentailment(TE)andquestion
answering (QA). As shown in Tab. 8, the results
indicate that PR yields suboptimal performance
on TE tasks, while it achieves good performance
on QA tasks. This discrepancy can be attributed
to the inherent characteristics of these tasks. TE
tasksheavilyrelyoncapturingtheoverallsemantic
meaning and logical relationships within the text,
which may not always be preserved when applying
pronoun replacement (Gao et al., 2022). In con-
trast, QA tasks aim to locate and provide specific
information relevant to the given question (Joshi
et al., 2020). By replacing pronouns with their
corresponding nouns, the model can more easily
identify the relevant entities and establish a clearer
connection between the question and the answer,
ultimately benefiting the QA task performance.
Type Task Rank (/51)
TEglue-mrpc 48
glue-rte 44
glue-wnli 33
medical_questions_pairs 48
QAqasc 1
openbookqa 27
commonsense_qa 4
quartz-no_knowledge 34
quartz-with_knowledge 9
Table 8: Performance comparison of the pronoun re-
placement (PR) augmentation instruction on text entail-
ment (TE) and question answering (QA) tasks.
D Dataset Collection
In Tab. 9, we list all 26 tasks and how we split-
ting them into training and testing for evaluating
themodelgeneralizationtounknowndownstream
tasks. Eachtaskwillhave16trainingandvalidation
examples but with full test examples. We utilize
thecodefrom CrossFit (Yeetal.,2021)toextract
andsplitthetraining,validationandtestingforeach
task.
E Details of Baseline Methods
E.1 Augmentation Methods of Non-LLMDA
All of the implementation of Non-LLMDA are from
Ma (2019). Here is an elaboration on each of the
mentioned Non-LLMDA augmentation methods:Character-Level Augmentations Random
Swap (Belinkov and Bisk, 2018): This involves
swapping adjacent characters within words to
simulate typos that might occur during typing. For
example, "example" might become "exmaple".
OCR Replace: Simulating errors commonly
introduced by Optical Character Recognition
(OCR) software when digitizing text. Characters
that look similar, like ‚Äôo‚Äô and ‚Äô0‚Äô or ‚Äôl‚Äô and ‚Äô1‚Äô,
might be substituted for one another. Delete:
Randomly removing characters from words to
mimic typographical errors or omissions. Insert:
Adding extra characters into words at random
positions, simulating common typos or spelling
errors. Substitute: Replacing characters in words
with other characters, not necessarily similar in
appearance, to create variations in the text.
Word-Level Augmentations. Swap (Wei and
Zou, 2019): Changing the positions of two adja-
centwordsinasentencetoaddsyntacticvariabil-
ity while largely preserving the sentence‚Äôs mean-
ing. Delete: Removing words from sentences
randomly to simulate information loss and encour-
age the model to learn from incomplete data. Spell
Error (Coulombe, 2018): Introducing common
spelling mistakes into words to mimic human er-
ror and increase the model‚Äôs exposure to varied
spellings. Word2VectorInsert(Morrisetal.,2020):
Identifyingsuitablelocationsinasentencetoinsert
synonymsorrelatedwordsbasedonwordembed-
dings (like word2vec representations), enhancing
semantic diversity.
Contextual-LevelAugmentations InsertWord
using GPT2(Kumaretal.,2021): Leveragingapre-
trained model like GPT2to generate contextually
relevant wordstoinsertinto sentences,increasing
thecomplexityandvariabilityofthesentencestruc-
tures. Substitute Word using BERT(Kumar et al.,
2021): Using a model like BERTto identify and
replace words with contextually appropriate syn-
onyms or related terms, maintaining the sentence‚Äôs
overall meaning while altering its surface form.
Back-Translation (Fadaee et al., 2017): Translating
asentenceintoanotherlanguageandthenbackinto
the original language. This process often intro-
ducessyntacticandlexicalvariations,providinga
paraphrased version of the original sentence that
retains its semantic content.

--- PAGE 15 ---
Category Train/Test Task Names
Class‚ÜíClassTrain financial_phrasebank ethos-religion glue-wnli glue-mrpc
Testtweet_eval-stance_feminist climate_fever poem_sentiment tweet_eval-hate
ethos-race tweet_eval-stance_atheism sick glue-rte
superglue-cb ethos-national_origin medical_questions_pairs hate_speech18
Class‚ÜíNon-ClassTraintweet_eval-stance_atheism superglue-cb financial_phrasebank ethos-religion
tweet_eval-stance_feminist climate_fever glue-mrpc tweet_eval-hate
glue-rte ethos-national_origin glue-wnli medical_questions_pairs
sick poem_sentiment hate_speech18 ethos-race
Testquarel codah ai2_arc openbookqa
superglue-copa qasc quartz-no_knowledge dream
quartz-with_knowledge commonsense_qa
Non-Class ‚ÜíClassTrainquarel codah ai2_arc openbookqa
superglue-copa qasc quartz-no_knowledge dream
quartz-with_knowledge commonsense_qa
Testtweet_eval-stance_atheism superglue-cb financial_phrasebank ethos-religion
tweet_eval-stance_feminist climate_fever glue-mrpc tweet_eval-hate
glue-rte ethos-national_origin glue-wnli medical_questions_pairs
sick poem_sentiment hate_speech18 ethos-race
Random‚ÜíRandomTrainquartz-with_knowledge tweet_eval-stance_feminist codah ethos-race
financial_phrasebank ai2_arc superglue-cb
Testquartz-no_knowledge hate_speech18 medical_questions_pairs ethos-religion
glue-rte commonsense_qa superglue-copa ethos-national_origin
glue-mrpc poem_sentiment quarel dream
climate_fever tweet_eval-hate qasc glue-wnli
tweet_eval-stance_atheism openbookqa sick
Table 9: All tasks used in this paper. We split them into training and testing sets under different experiment setting.
F Additional Experiment
We also compare our method with other
data augmentation techniques from Non-LLMDA
and Manual-LLMDA . The Non-LLMDA includes
EDA (Wei and Zou, 2019) and AEDA (Karimi
et al., 2021), while Manual-LLMDA includes
GPT3Mix (Yoo et al., 2021) and ZeroGen (Ye
et al., 2022). As shown in Tab. 10, our pro-
posed method Self-LLMDA significantly outper-
formsthesebaselinemethodsintheClass ‚ÜíClass
andRandom ‚ÜíRandomsettings. However,inthe
Non-Class ‚ÜíClass setting, Self-LLMDA falls be-
hind GPT3Mix. This may indicate suboptimal
transferabilityof Self-LLMDA inthisspecificsce-
nario. It is worth noting that GPT3Mix is de-
signed specifically for classification tasks, whereas
Self-LLMDA can be applied to a wide range of
text-related tasks, demonstrating its versatility and
broader applicability.
F.1 Augmentation Instructions of
Manual-LLMDA
InTab.11,wewillrepresentthemanuallycrafted
augmentation instructions. The format of these
augmentation instructions is ‚Äú<method name>:
<method instruction>‚Äù.
G Self Instructions Generation
TheinstructionsautomaticallygeneratedbyLLM
is shown in Tab. 12 and Tab. 13.

--- PAGE 16 ---
TextualDAClass‚ÜíClass Class ‚ÜíNon-Class Non-Class ‚ÜíClass Random ‚ÜíRandom
125m350m 125m 350m 125m 350m 125m 350m
EDA 45.2844.55 39.34 41.27 47.60 46.97 43.89 44.16
AEDA 43.8542.92 39.56 41.53 42.61 43.50 42.61 43.50
ZeroGen-LLM 45.6645.8140.43 40.62 47.69 48.58 44.14 44.74
GPT3Mix 51.6251.36 - - 55.81 54.04 - -
Self-LLMDA 51.7254.9840.02 42.80 50.00 52.75 46.64 48.83
Table 10: Performance comparison with other non-LLM-based and LLM-based textual data augmentations.
Name Augmentation Instruction
Word ReplaceSynonymReplacement: Replacecertainwordsinthetextwiththeirsynonymswhilekeepingthesentencestructure
intact. This can be done using pre-built synonym databases or word embeddings.
Back TranslationBackTranslation: Translatethetextintoanotherlanguageusingmachinetranslationandthentranslateitbacktothe
original language. This process introduces variations in the sentence structure and wording.
ParaphraseParaphrase: Renderthesametextindifferentwordswithoutlosingthemeaningofthetextitself. Moreoftenthannot,a
paraphrased text can convey its meaning better than the original words.
Word Insert/DeleteRandom Insertion/Deletion: Randomly insert or delete words in the text to create new variations of the original
sentences.
Word Swap Random Swapping: Randomly swap the positions of words in the text to create new sentence arrangements.
Mask PredictMasking/Prediction: Mask certain words in the text and train the model to predict those masked words. This is similar
to the concept of masked language modeling used in models like BERT.
Char. PerturbCharacter-level Perturbation: Instead of operating at the word level, perform data augmentation at the character level.
This can involve randomly replacing, inserting, or deleting characters within the text, leading to novel variations.
Sentence ReorderSentenceReordering: Randomlyreorderthesentencesinthetextwhilemaintainingthecoherenceoftheoverallpassage.
This can help the model become more robust in understanding different sentence arrangements.
Contextual ReplaceContextual Synonym Replacement: Instead of blindly replacing words with synonyms, consider the context of the
sentence to choose appropriate synonyms. This can be achieved by using contextual word embeddings or language
models like ELMo or BERT.
POS AugmentPart-of-Speech Augmentation: Identify the part-of-speech tags of words in the text and replace words with synonyms
that have the same part-of-speech. This ensures that the grammatical structure of the sentence remains intact.
Grammar TransformGrammarTransformation: Applyvariousgrammarrulestothetext,suchaschangingactivevoicetopassivevoice,
transforming affirmative sentences to negative, or converting declarative sentences into questions.
Data MixData Mixing: Combine two or more texts from different sources to create a new mixed-text data point. This can
introduce diversity in the content and writing style.
Paragraph ShuffleParagraphShuffling: Shuffletheorderofparagraphsinlongertextstocreatenewdocumentstructures. Thiscanbe
particularly useful for tasks that involve document-level understanding.
Table 11: Manually crafted augmentation instructions.

--- PAGE 17 ---
Augmentation Instruction
Contextual word replacement: replace certain words in the text with contextually similar words. this can be done by
using word embeddings to find words that have similar meanings or are used in similar contexts.
Sentiment flipping: change the sentiment of the text by flipping positive sentiments to negative and vice versa. this can
help generate diverse data for sentiment analysis tasks.
Styletransfer: transformthewritingstyleofthetextwhilemaintainingitsoriginalcontent. thiscaninvolveconverting
formal language to informal, changing the tone, or adapting the text to a specific genre.
Contextual paraphrasing: paraphrase sentencesin thetext while considering thesurrounding context. this ensuresthat
the paraphrased sentences maintain the same meaning within the given context.
Domainadaptation: modifythetexttomakeitmoresuitableforadifferentdomainortopic. thiscaninvolvereplacing
domain-specific terms, adjusting terminology, or incorporating relevant keywords.
Text summarization: generatea summary of thetext by condensingits main points intoa shorter version. this canhelp
create diverse data for summarization tasks and provide alternative perspectives on the original text.
Contextualwordinsertion: insertnewwordsintothetextthatarecontextuallyrelevantandmaintainthesemanticmeaning
of the sentence. this can be done by using word embeddings to find words that are commonly used in similar contexts.
Text paraphrasing: paraphrase the text by rephrasing sentences while preserving the original meaning. this can be done
using techniques such as sentence splitting, word substitution, and sentence rearrangement.
Contextual sentence deletion: delete certain sentences from the text while maintaining the coherence and semantic
meaning of the remaining sentences. this can help create diverse data for document summarization tasks.
Textexpansion: expandthetextbyaddingadditionaldetails, examples,orexplanationstoenhanceitscontent. thiscan
be done by incorporating information from external sources or generating new sentences based on the existing text.
Emotion augmentation: add emotional expressions or sentiments to the text to convey different emotions. this can help
create diverse data for emotion classification or sentiment analysis tasks.
Named entity substitution: replace named entities (such as names of people, organizations, or locations) in the text with
other similar entities. this can introduce variations while maintaining the context of the sentence.
Sentence reordering: rearrangethe order of sentenceswithin the text whilekeeping the semantic coherenceintact. this
can create new narrative structures and perspectives.
Grammatical error injection: introduce grammatical errors into the text by randomly modifying verb tenses, subject-verb
agreement, or punctuation. this can simulate noisy real-world data and improve model robustness.
Wordembeddingreplacement: replacecertainwordsinthetextwiththeirwordembeddings. thiscanintroducevariations
while preserving the semantic meaning of the sentence.
Synonym replacement: replace words in the text with their synonyms. this can create alternative phrasing while
maintaining the overall meaning.
Contextualwordsubstitution: substitutewordsinthetextwithotherwordsthathavesimilarcontextualmeanings. this
ensures that the replacement maintains the intended semantics.
Sentence splitting: split longer sentences into shorter ones, or vice versa, to create new sentence structures. this can help
the model understand different sentence lengths and improve its generalization ability.
Sentencecombination: combinemultipleshortersentencesintoasinglelongersentenceorviceversa. thiscancreate
diverse sentence structures and test the model≈õ comprehension of complex sentences.
Negation insertion: introduce negations into the text by adding words like "not" or "no" to change the polarity of certain
statements. this can help the model understand negative contexts better.
Word masking: randomly mask certain words in the text by replacing them with a special token. this forces the model to
rely on the surrounding context to understand the meaning of the masked word.
Character-levelaugmentation: modifyindividualcharacterswithinwords,suchaschangingvowelsorconsonants,to
generate diverse textual variations.
Sentence shuffling: shufflethe orderof sentences withina paragraph ordocument to createnew arrangements andtest
the model≈õ ability to understand different contexts.
Paraphrasing: rewrite the text using different phrasing or sentence structures while maintaining the original meaning.
Numerical value perturbation: add or subtract small random values to numerical values in the text to create slight
variations.
Pos tagging variation: randomly change the part-of-speech tags of words in the text while ensuring grammatical
correctness. this can introduce different syntactic patterns and word usages.
Sentence deletion: remove one or more sentences from the text to create a shorter version while still maintaining
coherence and semantic meaning.
Sentiment modification: change the sentiment or emotion expressed in the text while keeping the content intact. this can
involve altering positive statements to negative ones or vice versa.
Negation addition: add negation words (e.g., "not," "never") to the text to create negative versions of the original
sentences.
Word order variation: randomly change the order of words within phrases or clauses in the text to generate new sentence
arrangements.
Wordsensedisambiguation: replaceambiguouswordsinthetextwiththeirdifferentsensestocreatediverseinterpretations
of the sentence.
Table 12: Automatic generated augmentation instructions.

--- PAGE 18 ---
Augmentation Instruction
Negation transformation: transform positive statements into negative ones by adding negation words or phrases, or vice
versa.
Contradictiongeneration: introducecontradictionswithinthetextbymodifyingcertainstatementstobeoppositetowhat
they originally conveyed.
Namedentityreplacement: identifynamedentitiesinthetext(e.g.,namesofpeople,organizations)andreplacethem
with similar entities to generate new variations.
Word order shuffling: randomly shuffle the order of words within a sentence to create new sentence structures.
Grammarerrorinjection: introducegrammaticalerrorssuchasincorrectverbconjugation,subject-verbagreement,or
punctuation mistakes to simulate natural language variation.
Text shuffling: shuffle the order of sentences within a paragraph or paragraphs within a document to create new
arrangements. this helps diversify the structure and flow of the text.
Contextualdeletion: removecertainwordsorphrasesfromthetextwhileensuringthattheremainingcontentstillconveys
the same overall meaning. this tests the model≈õ ability to understand and fill in missing information.
Sentence paraphrasing: generate paraphrases of the original sentences while preserving their meaning. this can be
achieved through techniques like back-translation or paraphrase generation models.
Named entity variation: replace named entities (such as names, locations, organizations) in the text with different
variations to create diverse instances of the same sentence.
Numerical variation: modify numerical values in the text by adding/subtracting a small random value or replacing them
with synonyms/alternative representations.
Negationaugmentation: introducenegationsinthetextbyadding"not"orothernegationwordstocertainphrasesor
sentences. this helps the model understand negative contexts better.
Data sampling: randomly sample subsets of the data to create smaller training sets for faster experimentation and
exploration of different data distributions.
Backtranslation: translate the text into another language and then translate it back to the original language. this can
introduce variations in sentence structure and word choice while preserving the overall meaning.
Sentencesplitting/merging: splitlongsentencesintoshorteronesormergeshortsentencesintolongeronestocreatenew
sentence structures.
Pronounreplacement: replacepronounsinthetextwiththeircorrespondingnounsorviceversa,maintainingthesemantic
meaning of the sentence.
Worddeletion: randomlydeletecertainwordsfromthetexttocreateshorterormoreconcisesentences. thiscansimulate
scenarios where some information is missing or incomplete.
Character-levelperturbation: introducenoiseatthecharacterlevelbyrandomlychanging,deleting,orinsertingcharacters
in the text. this can help models become more robust to noisy inputs and improve generalization.
Domain-specific term replacement: identify domain-specific terms in the text and replace them with synonyms or related
terms specific to another domain. this can help models generalize better across different domains.
Negation/positiveconversion: convertnegativestatementstopositiveonesorviceversatogeneratedifferentperspectives
or sentiments.
Part-of-speech tagging: modify the part-of-speech tags of words in the text to create new grammatical arrangements and
sentence structures.
Table 13: Automatic generated augmentation instructions.

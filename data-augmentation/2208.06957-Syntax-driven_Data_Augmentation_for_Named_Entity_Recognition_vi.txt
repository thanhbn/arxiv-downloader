# 2208.06957.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/data-augmentation/2208.06957.pdf
# Kích thước tệp: 169533 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Tăng cường dữ liệu hướng cú pháp cho Nhận dạng thực thể có tên
Arie Pratama Sutiono
Đại học Arizona
Ngôn ngữ học
ariesutiono@arizona.eduGus Hahn-Powell
Đại học Arizona
Ngôn ngữ học
hahnpowell@arizona.edu

Tóm tắt
Trong các tình huống tài nguyên thấp, các chiến lược tăng cường dữ liệu thường được sử dụng để cải thiện hiệu suất. Nhiều phương pháp đã thử nghiệm tăng cường ở cấp độ tài liệu (ví dụ, phân loại văn bản), nhưng ít nghiên cứu đã khám phá việc tăng cường ở cấp độ token. Nếu thực hiện một cách ngây thơ, việc tăng cường dữ liệu có thể tạo ra các ví dụ không nhất quán về mặt ngữ nghĩa và không ngữ pháp. Trong nghiên cứu này, chúng tôi so sánh việc thay thế mô hình ngôn ngữ có mặt nạ đơn giản và một phương pháp tăng cường sử dụng các đột biến cây cú pháp để cải thiện hiệu suất nhận dạng thực thể có tên trong các tình huống tài nguyên thấp với mục tiêu bảo tồn sự gắn kết ngôn ngữ của các câu được tăng cường.

1 Giới thiệu
Các mạng nơ-ron sâu đã chứng minh hiệu quả cho nhiều tác vụ khác nhau trong xử lý ngôn ngữ tự nhiên; tuy nhiên, những mạng này thường yêu cầu các bộ dữ liệu chú thích lớn trước khi chúng bắt đầu vượt trội hơn các mô hình đơn giản hơn. Dữ liệu như vậy không phải lúc nào cũng có sẵn hoặc đủ đa dạng, và việc thu thập và chú thích nó có thể là một quá trình đắt đỏ và chậm chạp. Xu hướng tinh chỉnh các mô hình ngôn ngữ quy mô lớn được huấn luyện ban đầu bằng cách sử dụng tự giám sát đã giúp giảm bớt nhu cầu về các bộ dữ liệu chú thích lớn, nhưng phương pháp này dựa vào bộ dữ liệu để tinh chỉnh phải đủ đa dạng để huấn luyện một mô hình tổng quát hóa tốt. Việc tăng cường dữ liệu cẩn thận có thể giúp cải thiện tính đa dạng của bộ dữ liệu và cuối cùng là khả năng tổng quát hóa của mô hình.

Tăng cường dữ liệu, một kỹ thuật tạo ra dữ liệu dựa trên các đặc trưng của tập huấn luyện, tiếp tục đóng vai trò quan trọng trong các tình huống tài nguyên thấp; tuy nhiên, phần lớn công việc về tăng cường dữ liệu tập trung vào việc cải thiện các tác vụ ở cấp độ tài liệu như phân loại văn bản. Ít sự chú ý hơn nhiều đã được dành cho các tác vụ ở cấp độ token (Feng et al., 2021).

Các phương pháp phổ biến cho các tác vụ gắn nhãn chuỗi như nhận dạng thực thể có tên (NER) yêu cầu nhãn thực ở cấp độ token. Các phương pháp tăng cường dựa trên thay thế ngây thơ có thể gây ra nhiễu dưới dạng các câu không ngữ pháp, trống rỗng về mặt ngữ nghĩa, hoặc không nhất quán về mặt ngữ nghĩa. Dù dưới dạng chèn, xóa, hoặc thay thế, cần phải cẩn thận với việc tăng cường ở cấp độ token để bảo tồn sự gắn kết ngôn ngữ.

Có bằng chứng rằng các mô hình ngôn ngữ lớn có thể sở hữu một số kiến thức cú pháp (Hewitt và Manning, 2019; Wei et al., 2021). Nghiên cứu của Bai et al. (2021) cho thấy rằng việc kết hợp các tác vụ cú pháp vào quá trình tiền huấn luyện cải thiện hiệu suất của các mô hình ngôn ngữ lớn. Được truyền cảm hứng bởi những phát hiện này, chúng tôi nghiên cứu cách các cây cú pháp có thể được sử dụng để hướng dẫn tăng cường dữ liệu. Chúng tôi sử dụng các phép biến đổi dựa trên cây để đột biến các câu trong khi giảm thiểu các tác động phụ không mong muốn của thao tác cú pháp (tức là bảo tồn sự gắn kết ngôn ngữ). Nghiên cứu liên quan của Zhang et al. (2022) khám phá một phương pháp tương tự trong các tình huống khác nhau. Họ tập trung vào hiệu ứng của việc thay thế dựa trên cú pháp trong các tác vụ phân loại đơn và phân loại cặp câu, trong khi nghiên cứu này xem xét phân loại ở cấp độ token.

Chúng tôi so sánh phương pháp hướng cú pháp của chúng tôi với không tăng cường (cơ sở của chúng tôi), dữ liệu tăng cường được tạo ra thông qua mô hình ngôn ngữ có mặt nạ kiểu cloze (Taylor, 1953) sử dụng một bộ phân loại dựa trên BERT, các phương pháp thành công được giới thiệu bởi Dai và Adel (2021), và hai trong số các chiến lược tăng cường hiệu suất cao nhất theo nghiên cứu trước đây: thay thế dựa trên từ đồng nghĩa và thay thế dựa trên mention. Theo nghiên cứu trước đây, chúng tôi sử dụng bộ dữ liệu tiếng Anh i2b2-2010 (Uzuner et al., 2011) cho NER.

2 Nghiên cứu liên quan
Nhiều phương pháp khác nhau đã được khám phá cho việc tăng cường dữ liệu ở cấp độ tài liệu. Việc sử dụng dịch ngược để tạo ra các mẫu tăng cường đã được giới thiệu bởi Kobayashi (2018). Wei và Zou (2019) đã khám phá việc thay thế từ đồng nghĩa, chèn ngẫu nhiên, hoán đổi ngẫu nhiên, và xóa ngẫu nhiên cho phân loại văn bản. Quteineh et al. (2020) đã giới thiệu một phương pháp sử dụng tìm kiếm cây monte carlo (MCTS) để hướng dẫn tạo ra dữ liệu tổng hợp.

Tuy nhiên, việc tăng cường cho gắn nhãn chuỗi ở cấp độ token được nghiên cứu ít hơn. Các phương pháp đơn giản cho phân loại ở cấp độ token (ví dụ, thay thế từ đồng nghĩa, thay thế mention, xáo trộn, v.v.) đã được nghiên cứu bởi Devlin et al. (2019). Họ đã sử dụng một mẫu 50, 150, và 500 câu để mô phỏng một tình huống tài nguyên thấp. Tuyến tính hóa token (TL) đã được giới thiệu bởi Ding et al. (2020). Ý tưởng chính của TL là kết hợp các nhãn NER bên trong chính các câu huấn luyện. Ding et al. (2020) đã thử nghiệm với các kích thước khác nhau của dữ liệu huấn luyện trên sáu ngôn ngữ.

Một ý tưởng tương tự với những gì được trình bày ở đây đã được sử dụng trong nghiên cứu song song bởi Zhang et al. (2022). Phương pháp của họ, TreeMix, hoạt động tương tự như phương pháp của chúng tôi ở chỗ nó thay thế một cụm từ bằng một cụm từ khác từ một thể hiện huấn luyện khác bằng cách hoán đổi các cụm từ có cùng nhãn thành phần. Zhang et al. (2022) đã chứng minh rằng TreeMix vượt trội hơn một phương pháp chọn một đoạn văn bản ngẫu nhiên làm thay thế cho một cụm từ đích, cho thấy rằng việc thay thế nhận thức cú pháp có thể cải thiện việc tăng cường dữ liệu cho ít nhất một số tác vụ.

3 Phương pháp
3.1 Thay thế từ đồng nghĩa (SR)
Dai và Adel (2021) đã thử nghiệm với việc thay thế các token được chọn ngẫu nhiên từ kho ngữ liệu huấn luyện bằng các từ đồng nghĩa đa từ có nguồn gốc từ WordNet (Miller, 1992). Trong trường hợp này, nếu token được thay thế là phần đầu của một mention (B-ENTITY), thì token đầu tiên của từ đồng nghĩa sẽ được gắn nhãn là B-ENTITY và phần còn lại sẽ được coi là I-ENTITY. Trong các trường hợp token được thay thế nằm ở giữa một mention (I-ENTITY), thì tất cả các token của từ đồng nghĩa sẽ được gán cho I-ENTITY.

3.2 Thay thế Mention (MR)
Dai và Adel (2021) đã mô tả thay thế mention là sử dụng phân phối Bernoulli để quyết định liệu mỗi mention có nên được thay thế hay không. Nếu có, thì một mention khác có cùng loại thực thể với mention đích từ tập huấn luyện ban đầu được chọn để thay thế mention đích. Ví dụ, nếu mention "myelopathy / B-PROBLEM được chọn để thay thế, thì chúng ta có thể chọn một trong {"C5-6", "COPD", ...} tất cả đều có cùng loại thực thể (PROBLEM).

3.3 Mô hình ngôn ngữ (LM)
Chúng tôi đã thử nghiệm với việc thay thế token bằng cách sử dụng một mô hình ngôn ngữ có mặt nạ. Chúng tôi hạn chế hệ thống chỉ thay thế các token không phải mention (các token với danh mục O). Điều này là do nếu chúng tôi thay thế các token bằng một thực thể có tên, chúng tôi không thể đảm bảo rằng đầu ra từ mô hình ngôn ngữ có mặt nạ sẽ có cùng danh mục, sao cho nếu chúng tôi thay thế một token được phân loại là B-TEST, chúng tôi không thể đảm bảo rằng mô hình ngôn ngữ có mặt nạ sẽ thay thế nó bằng một token tương tự như những token trong danh mục B-TEST.

Chúng tôi chọn ngẫu nhiên, không thay thế, n token làm ứng cử viên để được thay thế. Các token được chọn được che dấu khỏi câu gốc. Tiếp theo, chúng tôi mô hình ngôn ngữ tạo ra các thay thế cho các token được che dấu. Chúng tôi có thể lặp lại quá trình tạo token này lên đến k lần để tạo ra các câu tăng cường khác nhau. Chúng tôi sử dụng mô hình SciBERT của Allen AI từ kho mô hình Hugging Face.

3.4 Thay thế cú pháp (CR)
Như một bước tiền xử lý, chúng tôi thực hiện phân tích cú pháp trên toàn bộ dữ liệu huấn luyện bằng cách sử dụng Stanza (Qi et al., 2020). Với một non-terminal XP, chúng tôi chọn p non-terminal làm ứng cử viên để thay thế. Đối với mỗi non-terminal, chúng tôi tìm các non-terminal khác có cùng danh mục từ dữ liệu huấn luyện, để thay thế ứng cử viên. Giả sử rằng chúng tôi chọn VP làm nút đích non-terminal để thay thế, thuật toán sẽ chọn một VP khác từ tập hợp các câu được phân tích trong kho ngữ liệu huấn luyện và đột biến toàn bộ cây con (gốc VP và các nút bên dưới nó). Chúng tôi có thể lặp lại quá trình này để tạo ra k câu tăng cường. Ngoài ra, chúng tôi nhắm mục tiêu các nút có mention NER làm một trong những con của nó.

4 Thí nghiệm và kết quả
4.1 Bộ dữ liệu
Chúng tôi sử dụng bộ dữ liệu i2b2-2010 (Uzuner et al., 2011), một bộ dữ liệu NER tiếng Anh. Tương tự như Dai và Adel (2021), chúng tôi sử dụng 3 kích thước khác nhau của bộ dữ liệu để mô phỏng các tình huống tài nguyên thấp. Chúng tôi chọn 50, 150, và 500 câu đầu tiên từ tập huấn luyện và ký hiệu chúng là S, M, L. Chúng tôi sử dụng phân chia train-test mặc định và giới hạn việc tăng cường cho tập huấn luyện.

--- TRANG 2 ---
4.2 Mô hình
Theo Dai và Adel (2021), chúng tôi mô hình hóa tác vụ NER như gắn nhãn chuỗi. Chúng tôi sử dụng cùng các thành phần để mô hình hóa: một bộ mã hóa nơ-ron và một lớp trường ngẫu nhiên có điều kiện. Đối với bộ mã hóa nơ-ron của chúng tôi, chúng tôi sử dụng SciBERT. Mô hình này đã được chứng minh là hoạt động hiệu quả với dữ liệu khoa học và y tế, như i2b2-2010.

4.3 Thí nghiệm
Mỗi thí nghiệm đã được lặp lại với 5 hạt giống ngẫu nhiên khác nhau để tính toán độ lệch chuẩn.

Đối với các phương pháp SR và MR của chúng tôi, các siêu tham số của chúng tôi là tỷ lệ thay thế (0.3) và số lượng mẫu được tạo ra (1).

Các siêu tham số của LM và CR tương tự. Cả hai sẽ có số lượng mẫu được tạo ra và số lượng token được thay thế (chỉ cho LM) hoặc non-terminal (chỉ cho ST). Trong nghiên cứu này, chúng tôi giới hạn việc thay thế CR cho các non-terminal (cụm từ) trong tập hợp sau: {NP, VP, ADJP, ADVP, PP}. Chúng tôi loại bỏ FRAG (fragment) vì nó có số lượng non-terminal quá thấp.

Một câu hỏi cần khám phá là liệu dữ liệu tăng cường nhiều hơn có thể dẫn đến những cải thiện liên tục trong hiệu suất mô hình hay không. Để trả lời điều này, chúng tôi đã thử nghiệm với {5, 10, 20} mẫu được tạo ra. Đối với mỗi số lượng mẫu được tạo ra, chúng tôi cũng đặt số lượng token được thay thế cho LM và số lượng non-terminal được thay thế cho CR là {1, 3, 5}. Chúng tôi đã mô tả phân phối của các non-terminal trong Bảng 1. Tất cả các cài đặt này đã được thử nghiệm trên 27,625 câu từ tập kiểm tra của chúng tôi.

Cụm từ S M L
NP 332 637 2562
VP 93 189 881
PP 54 130 690
ADJP 31 42 189
ADVP 16 27 126
FRAG 2 2 4

Bảng 1: Phân phối số lượng cụm từ trong dữ liệu huấn luyện.

4.4 Kết quả
Bảng 2 mô tả điểm F1 cao nhất cho mỗi chiến lược tăng cường. Điểm F1 tốt nhất được lấy cho mỗi chiến lược, qua nhiều siêu tham số. Chúng tôi thấy rằng thay thế từ đồng nghĩa vẫn vượt trội hơn các chiến lược tăng cường khác ở kích thước bộ dữ liệu nhỏ và trung bình.

Thí nghiệm S M L
NoA 46.30.5 61.40.1 70.70.1
SR 53.00.2 65.70.1 71.00.0
MR 51.90.2 61.70.1 70.20.0
LM 52.90.1 63.30.1 73.30.2
CR-ADJP 47.80.2 61.00.1 71.20.1
CR-ADVP 50.50.3 61.90.1 71.30.1
CR-NP 52.10.3 60.60.1 70.20.1
CR-PP 52.10.1 62.40.1 71.90.1
CR-VP 52.90.2 62.80.1 72.80.1

Bảng 2: Kết quả cho các thí nghiệm tăng cường dữ liệu qua các kích thước bộ dữ liệu khác nhau. Kết quả hàng đầu cho mỗi phân vùng dữ liệu được đánh dấu in đậm.

Tất cả các phương pháp tăng cường được thử nghiệm dường như cải thiện hiệu suất về F1 cho tập huấn luyện nhỏ (50 câu). Tuy nhiên, khi chúng tôi nhìn vào bộ dữ liệu trung bình, một số phương pháp như CR-ADJP hoặc CR-NP, bắt đầu có tác động tiêu cực so với cài đặt không tăng cường. Thậm chí nhiều chiến lược tăng cường hơn bắt đầu thể hiện hiệu ứng giảm dần hoặc tiêu cực đối với hiệu suất cho bộ dữ liệu lớn hơn (ví dụ, MR và CR-NP). Điều này cho thấy rằng một số dữ liệu tăng cường có thể có hại cho quá trình tinh chỉnh mô hình.

Để hiểu cách dữ liệu tăng cường có thể bắt đầu làm tổn hại hiệu suất của mô hình ban đầu, chúng tôi xem xét một câu ban đầu được xử lý bằng chiến lược CR-NP. Ví dụ, "Dr. Foutchner will arrange for an outpatient Holter monitor". Trong trường hợp chiến lược CR, thuật toán tăng cường vẽ một NP từ một câu huấn luyện khác, kết quả là "Dr. Foutchner will arrange for a T2 signal change" hoặc "Dr. Foutchner will arrange for 10 beats". Những câu tăng cường này có ngữ pháp, nhưng chúng thiếu sự gắn kết. Hiện tượng này có thể tác động tiêu cực đến mô hình. Nghiên cứu tương lai nên khám phá các chiến lược để kiểm soát sự trôi dạt này. Ví dụ, bằng cách tinh chỉnh một mô hình ngôn ngữ quy mô lớn để thực hiện mô hình hóa ngôn ngữ có mặt nạ trên các câu mà một phần token được cung cấp dưới dạng danh mục cụm từ (XP) hoặc danh mục chức năng (nhãn từ loại), chúng tôi có thể lai tạo các phép biến đổi hướng cú pháp và tạo ra các mẫu cú pháp bằng cách sử dụng các mô hình ngôn ngữ quy mô lớn.

Chúng tôi quan sát thấy rằng trong số các chiến lược CR, hiệu suất CR-NP dường như tệ hơn so với CR-VP hoặc CR-PP, mặc dù NP có nhiều lần xuất hiện nhất trong dữ liệu huấn luyện. Chúng tôi nghi ngờ rằng tính hiệu quả của chiến lược này sẽ phụ thuộc nhiều vào phạm vi của nhãn cú pháp. NP thường được định vị thấp trong cây cú pháp, trong khi VP thường được định vị về phía đỉnh.

Các chiến lược tăng cường được khám phá trong nghiên cứu này có thể được chia thành hai nhóm: các chiến lược tạo ra từ vựng mới và các chiến lược không tạo ra từ vựng mới. Các phương pháp SR và LM thuộc về tăng cường tạo ra từ vựng mới. SR sử dụng Penn Treebank (Marcus et al., 1993) để tạo ra từ đồng nghĩa của các token được thay thế. LM sử dụng embedding từ của nó để đoán token đích được che dấu và có thể tạo ra những từ mới không tồn tại trong dữ liệu huấn luyện. Các chiến lược khác (MR và CR) dựa hoàn toàn vào bộ dữ liệu huấn luyện hiện tại. Hiện tượng này cho thấy các chiến lược tăng cường tạo ra từ vựng mới dường như hiệu quả hơn. Điều này có thể hiểu được vì những từ mới sẽ làm cho mô hình được tinh chỉnh mạnh mẽ hơn đối với dữ liệu chưa thấy. Mặc dù CR không tạo ra từ mới như các phương pháp LM và SR, nó vẫn hoạt động cạnh tranh so với. Delta giữa điểm F1 được tạo ra bởi CR-VP và LM với các siêu tham số tốt nhất của chúng tôi cho tất cả các kích thước bộ dữ liệu đáng chú ý nhỏ khoảng 0-0.5 điểm.

Hiệu ứng của các chiến lược tăng cường dữ liệu đơn giản hơn, SR và MR, dường như đang giảm dần khi kích thước dữ liệu tăng lên; tuy nhiên, không phải như vậy với các chiến lược LM và CR-VP. Chúng dường như hoạt động tốt khi có nhiều dữ liệu huấn luyện hơn.

Nhìn vào Bảng 3, chiến lược tăng cường CR-VP dường như thể hiện sự tăng trưởng hiệu suất nhất quán hơn so với chiến lược LM. Dù là 5, 10 hay 20 câu được tạo ra, CR-VP liên tục có xu hướng tăng lên khi số lượng câu tăng cường tăng lên (cf sự không ổn định của LM). Hiệu suất trung bình của chiến lược CR thể hiện F1 tăng lên khi số lượng câu tổng hợp tăng lên. Ngược lại, hiệu suất trung bình của chiến lược LM không nhất quán và có xu hướng giảm xuống khi số lượng câu tổng hợp tăng lên.

Cuối cùng, hiệu suất của chiến lược CR cũng sẽ bị ảnh hưởng bởi hiệu suất của chính thành phần phân tích cú pháp. Đối với một trong những ví dụ tăng cường của chúng tôi, câu ban đầu "She [VP had a workup by her neurologist] and an MRI [VP call with any fevers, chills, increasing weakness...]" đã được đột biến thành "She [VP had a workup by her neurologist] and an MRI [VP flare]". Ở đây, từ flare đã được dự đoán sai là một động từ và do đó bị dự đoán sai là một thành phần VP, trong khi từ flare ở đây nên là một phần của COPD flare và được phân loại là danh từ.

5 Kết luận và nghiên cứu tương lai
Trong nghiên cứu này, chúng tôi đã xem xét tăng cường dữ liệu với một mô hình ngôn ngữ quy mô lớn (LM) và đột biến cây cú pháp (ST). Chúng tôi đã so sánh các phương pháp tăng cường này với một cơ sở và các chiến lược được đề xuất trước đây cho tăng cường dữ liệu: thay thế từ đồng nghĩa (SR) và thay thế mention (MR). Chúng tôi thấy rằng hiệu suất SR vẫn hiệu quả nhất, với một biên độ nhỏ, nhưng hiệu suất giảm nhanh chóng khi kích thước dữ liệu tăng lên. Chúng tôi cũng quan sát thấy rằng cả LM và CR đều duy trì hiệu suất của chúng qua các kích thước bộ dữ liệu lớn hơn. Chúng tôi cũng cho thấy rằng hiệu suất CR dường như nhất quán trong việc cải thiện khi kích thước bộ dữ liệu tăng cường tăng lên, trong khi LM thể hiện hiệu suất giảm với nhiều dữ liệu tăng cường hơn.

Nghiên cứu tương lai nên bao gồm các cải tiến lai tạo các phép biến đổi cú pháp với một mô hình ngôn ngữ quy mô lớn. Một khả năng để tăng hiệu suất của mô hình ngôn ngữ cơ sở là huấn luyện nó để nhận diện các thành phần ở cấp độ cụm từ và các danh mục chức năng để hiểu rõ hơn về các nhãn cú pháp bằng cách trước tiên hoán đổi ngẫu nhiên một vài token với các nhãn từ loại. Ví dụ, câu ban đầu là "I take my medicine.", thì câu tiền huấn luyện là "I VB my medicine." và "I take my NN.". Chúng tôi giả thuyết rằng việc tiền huấn luyện này sẽ cải thiện hiệu suất dự đoán của mô hình ngôn ngữ cơ sở mà chúng tôi đã sử dụng cho tăng cường CR bằng cách chú ý đến các danh mục chức năng.

Một khả năng khác là gán các trọng số khác nhau cho các điểm dữ liệu thông báo cho mô hình mức độ "tin tưởng" dữ liệu tăng cường so với dữ liệu vàng. Trọng số này có thể dưới dạng tỷ lệ học tập khác nhau.

--- TRANG 3 ---
S M L
5 10 20 5 10 20 5 10 20
LM 50.6 51.5 50.6 61.2 60.8 61.0 71.1 70.8 70.6
CR-VP 50.5 52.0 52.3 61.9 62.3 62.5 71.9 72.3 72.3

Bảng 3: So sánh giữa tăng cường CR-VP và LM. CR-VP duy trì hiệu suất nhất quán hơn qua số lượng câu được tạo ra, trong khi hiệu suất LM giảm khi số lượng câu được tạo ra thấp.

--- TRANG 4 ---
Tài liệu tham khảo
Jiangang Bai, Yujing Wang, Yiren Chen, Yaming Yang, Jing Bai, Jing Yu, và Yunhai Tong. 2021. Syntax-BERT: Improving pre-trained transformers with syntax trees. In Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, trang 3011–3020, Online. Association for Computational Linguistics.

Xiang Dai và Heike Adel. 2021. An analysis of simple data augmentation for named entity recognition. trang 3861–3867.

Jacob Devlin, Ming-Wei Chang, Kenton Lee, và Kristina Toutanova. 2019. BERT: Pre-training of deep bidirectional transformers for language understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), trang 4171–4186, Minneapolis, Minnesota. Association for Computational Linguistics.

Bosheng Ding, Linlin Liu, Lidong Bing, Canasai Kruengkrai, Thien Hai Nguyen, Shafiq Joty, Luo Si, và Chunyan Miao. 2020. DAGA: Data augmentation with a generation approach for low-resource tagging tasks. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), trang 6045–6057, Online. Association for Computational Linguistics.

Steven Y. Feng, Varun Gangal, Jason Wei, Sarath Chandar, Soroush Vosoughi, Teruko Mitamura, và Eduard Hovy. 2021. A survey of data augmentation approaches for NLP. In Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, trang 968–988, Online. Association for Computational Linguistics.

John Hewitt và Christopher D. Manning. 2019. A structural probe for finding syntax in word representations. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), trang 4129–4138, Minneapolis, Minnesota. Association for Computational Linguistics.

Sosuke Kobayashi. 2018. Contextual augmentation: Data augmentation by words with paradigmatic relations. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers), trang 452–457, New Orleans, Louisiana. Association for Computational Linguistics.

Mitchell P. Marcus, Beatrice Santorini, và Mary Ann Marcinkiewicz. 1993. Building a large annotated corpus of English: The Penn Treebank. Computational Linguistics, 19(2):313–330.

George A. Miller. 1992. WordNet: A lexical database for English. In Speech and Natural Language: Proceedings of a Workshop Held at Harriman, New York, February 23-26, 1992.

Peng Qi, Yuhao Zhang, Yuhui Zhang, Jason Bolton, và Christopher D. Manning. 2020. Stanza: A python natural language processing toolkit for many human languages. CoRR, abs/2003.07082.

Husam Quteineh, Spyridon Samothrakis, và Richard Sutcliffe. 2020. Textual data augmentation for efficient active learning on tiny datasets. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), trang 7400–7410, Online. Association for Computational Linguistics.

Wilson L. Taylor. 1953. "cloze procedure": A new tool for measuring readability. Journalism Quarterly, 30(4):415–433.

Özlem Uzuner, Brett R. South, Shuying Shen, và Scott L Duvall. 2011. 2010 i2b2/va challenge on concepts, assertions, and relations in clinical text. Journal of the American Medical Informatics Association: JAMIA, 18 5:552–6.

Jason Wei, Dan Garrette, Tal Linzen, và Ellie Pavlick. 2021. Frequency effects on syntactic rule learning in transformers. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, trang 932–948, Online and Punta Cana, Dominican Republic. Association for Computational Linguistics.

Jason Wei và Kai Zou. 2019. EDA: Easy data augmentation techniques for boosting performance on text classification tasks. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), trang 6382–6388, Hong Kong, China. Association for Computational Linguistics.

Le Zhang, Zichao Yang, và Diyi Yang. 2022. TreeMix: Compositional constituency-based data augmentation for natural language understanding. In Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, trang 5243–5258, Seattle, United States. Association for Computational Linguistics.
